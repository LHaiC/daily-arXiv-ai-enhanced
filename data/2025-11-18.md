<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 295]
- [cs.CL](#cs.CL) [Total: 7]
- [eess.SP](#eess.SP) [Total: 23]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.GT](#cs.GT) [Total: 8]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.RO](#cs.RO) [Total: 55]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 21]
- [cs.NE](#cs.NE) [Total: 6]
- [cs.DC](#cs.DC) [Total: 40]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 19]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.MA](#cs.MA) [Total: 11]
- [cs.SI](#cs.SI) [Total: 6]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.AR](#cs.AR) [Total: 14]
- [cs.LO](#cs.LO) [Total: 4]
- [quant-ph](#quant-ph) [Total: 78]
- [eess.SY](#eess.SY) [Total: 41]
- [cs.ET](#cs.ET) [Total: 4]
- [physics.app-ph](#physics.app-ph) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Psychological stress during Examination and its estimation by handwriting in answer script](https://arxiv.org/abs/2511.11633)
*Abhijeet Kumar,Chetan Agarwal,Pronoy B. Neogi,Mayank Goswami*

Main category: cs.CV

TL;DR: 本研究利用手写笔迹的字体特征和人工智能来量化学生的心理压力水平。


<details>
  <summary>Details</summary>
Motivation: 通过分析学生手写的考试试卷，利用字体特征和人工智能来量化学生的心理压力水平。

Method: 利用光学字符识别和基于Transformer的感情分析模型，并结合高分辨率图像处理、TrOCR和基于RoBERTa模型的感情熵融合，生成一个数字化的压力指数。通过五模型投票机制和无监督异常检测来实现方法的稳健性。

Result: 提出了一种数据驱动的方法，超越了传统的评分系统，提供了对考试期间认知和情感状态更深入的见解。

Conclusion: 该方法是一种创新的学术取证框架，通过结合字体特征、人工智能、图像处理和感情分析来量化学生的心理压力水平。

Abstract: This research explores the fusion of graphology and artificial intelligence to quantify psychological stress levels in students by analyzing their handwritten examination scripts. By leveraging Optical Character Recognition and transformer based sentiment analysis models, we present a data driven approach that transcends traditional grading systems, offering deeper insights into cognitive and emotional states during examinations. The system integrates high resolution image processing, TrOCR, and sentiment entropy fusion using RoBERTa based models to generate a numerical Stress Index. Our method achieves robustness through a five model voting mechanism and unsupervised anomaly detection, making it an innovative framework in academic forensics.

</details>


### [2] [Real-time pothole detection with onboard sensors and camera on vehicles](https://arxiv.org/abs/2511.11643)
*Aswath Muthuselvam,Jeevak Raj S,Mohanaprasad K*

Main category: cs.CV

TL;DR: 利用车载传感器和SVM分类器实现路面坑洼的实时检测，准确率达98.1%。


<details>
  <summary>Details</summary>
Motivation: 随着车辆数量的增加，需要频繁监测路况以确保交通顺畅，尤其是识别道路裂缝和坑洼。

Method: 使用车载传感器收集数据，并利用支持向量机（SVM）分类器来检测坑洼。

Result: 在收集到的2公里道路数据中，成功识别出26个坑洼，准确率达到98.1%。

Conclusion: 该方法能够有效地实时检测路面坑洼，为大规模道路管理提供数据支持。

Abstract: Road conditions play an important role in our everyday commute. With the proliferating number of vehicles on the road each year, it has become necessary to access the road conditions very frequently, this would ensure that the traffic also flows smoothly. Even the smallest crack in the road could be easily be chipped into a large pothole due to changing surface temperatures of the road and from the force of vehicles riding over it. In this paper, we have addressed how we could better identify these potholes in realtime with the help of onboard sensors in vehicles so that the data could be useful for analysis and better management of potholes on a large scale. For the implementation, we used an SVM classifier to detect potholes, we achieved 98.1% accuracy based on data collected from a local road for about 2 km which had 26 potholes distributed along the road. Code is available at: https://github.com/aswathselvam/Potholes

</details>


### [3] [A Method for Identifying Farmland System Habitat Types Based on the Dynamic-Weighted Feature Fusion Network Model](https://arxiv.org/abs/2511.11659)
*Kesong Zheng,Zhi Song,Peizhou Li,Shuyi Yao,Zhenxing Bian*

Main category: cs.CV

TL;DR: 本研究提出了一种动态加权特征融合网络（DWFF-Net），用于解决耕地生态系统生境分类体系不完善、特征融合效果不佳等问题。该网络使用DINOv3提取基础特征，并引入数据级自适应动态加权策略和多层特征融合，以提高分割精度，特别是在田埂等微生境的识别上。实验结果表明，DWFF-Net在自建数据集上取得了0.6979的mIoU和0.8049的F1分数，优于基线网络，为精细化耕地景观监测提供了技术支持。


<details>
  <summary>Details</summary>
Motivation: 现有耕地生态系统栖息地分类系统缺乏标准化，现有模型在融合语义和纹理特征方面存在不足，导致多尺度栖息地分割精度不高，边界模糊。

Method: 提出一种动态加权特征融合网络（DWFF-Net），其中编码器使用冻结的DINOv3提取基础特征，并引入数据级自适应动态加权策略融合特征。解码器采用动态权重计算网络进行多层特征融合，并使用混合损失函数进行优化。同时，构建了一个包含15类耕地系统栖息地的超高分辨率遥感图像数据集。

Result: 在构建的数据集上，DWFF-Net实现了0.6979的平均交并比（mIoU）和0.8049的F1分数，分别比基线网络提高了0.021和0.0161。消融实验证明了多层特征融合能有效提升田埂等微生境类别的IoU。

Conclusion: 本研究建立了一个基于自适应多层特征融合的耕地系统栖息地识别框架，实现了低成本、亚米级的栖息地测绘，为耕地景观的精细化栖息地监测提供了有力的技术支撑。

Abstract: Addressing the current lack of a standardized habitat classification system for cultivated land ecosystems, incomplete coverage of habitat types, and the inability of existing models to effectively integrate semantic and texture features-resulting in insufficient segmentation accuracy and blurred boundaries for multi-scale habitats (e.g., large-scale field plots and micro-habitats)-this study developed a comprehensively annotated ultra-high-resolution remote sensing image dataset encompassing 15 categories of cultivated land system habitats. Furthermore, we propose a Dynamic-Weighted Feature Fusion Network (DWFF-Net). The encoder of this model utilizes a frozen-parameter DINOv3 to extract foundational features. By analyzing the relationships between different category images and feature maps, we introduce a data-level adaptive dynamic weighting strategy for feature fusion. The decoder incorporates a dynamic weight computation network to achieve thorough integration of multi-layer features, and a hybrid loss function is adopted to optimize model training. Experimental results on the constructed dataset demonstrate that the proposed model achieves a mean Intersection over Union (mIoU) of 0.6979 and an F1-score of 0.8049, outperforming the baseline network by 0.021 and 0.0161, respectively. Ablation studies further confirm the complementary nature of multi-layer feature fusion, which effectively improves the IoU for micro-habitat categories such as field ridges. This study establishes a habitat identification framework for cultivated land systems based on adaptive multi-layer feature fusion, enabling sub-meter precision habitat mapping at a low cost and providing robust technical support for fine-grained habitat monitoring in cultivated landscapes.

</details>


### [4] [AGENet: Adaptive Edge-aware Geodesic Distance Learning for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2511.11662)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: 医学图像分割因需要大量标注数据而面临瓶颈。本文提出AGENet，一种结合了空间关系和边缘感知测地线距离学习的新框架，以解决医学图像中精确边界描绘的挑战。该框架通过迭代快速行进细化来学习边缘感知测地线距离，通过空间加权聚合进行自适应原型提取，并通过自适应参数学习来自动调整到不同的器官特征。实验证明AGENet在减少边界误差和保持计算效率方面优于现有方法，适合在标注数据有限的临床应用中使用。


<details>
  <summary>Details</summary>
Motivation: 现有的少样本分割方法在医学图像的精确边界描绘方面表现不佳，尤其是在缺乏足够空间信息的类似解剖区域。因此，需要一种能够学习最小样本并精确描绘医学图像边界的方法。

Method: AGENet框架包含三个主要部分：(1) 一个边缘感知测地线距离学习模块，通过迭代快速行进细化来尊重解剖边界；(2) 一个自适应原型提取模块，通过空间加权聚合来捕获全局结构和局部边界细节；(3) 一个自适应参数学习模块，能够自动适应不同的器官特征。

Result: 在多种医学成像数据集上的广泛实验表明，AGENet相比于最先进的方法有所改进。具体来说，该方法减少了边界错误，并且在计算上保持了效率。

Conclusion: AGENet通过整合空间关系和边缘感知测地线距离学习，能够从有限的标注数据中学习并精确分割医学图像。该方法在减少边界误差和保持计算效率方面表现出色，使其成为临床应用中处理标注数据有限问题的理想选择。

Abstract: Medical image segmentation requires large annotated datasets, creating a significant bottleneck for clinical applications. While few-shot segmentation methods can learn from minimal examples, existing approaches demonstrate suboptimal performance in precise boundary delineation for medical images, particularly when anatomically similar regions appear without sufficient spatial context. We propose AGENet (Adaptive Geodesic Edge-aware Network), a novel framework that incorporates spatial relationships through edge-aware geodesic distance learning. Our key insight is that medical structures follow predictable geometric patterns that can guide prototype extraction even with limited training data. Unlike methods relying on complex architectural components or heavy neural networks, our approach leverages computationally lightweight geometric modeling. The framework combines three main components: (1) An edge-aware geodesic distance learning module that respects anatomical boundaries through iterative Fast Marching refinement, (2) adaptive prototype extraction that captures both global structure and local boundary details via spatially-weighted aggregation, and (3) adaptive parameter learning that automatically adjusts to different organ characteristics. Extensive experiments across diverse medical imaging datasets demonstrate improvements over state-of-the-art methods. Notably, our method reduces boundary errors compared to existing approaches while maintaining computational efficiency, making it highly suitable for clinical applications requiring precise segmentation with limited annotated data.

</details>


### [5] [EPSegFZ: Efficient Point Cloud Semantic Segmentation for Few- and Zero-Shot Scenarios with Language Guidance](https://arxiv.org/abs/2511.11700)
*Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee*

Main category: cs.CV

TL;DR: 本文提出了一种无需预训练的EPSegFZ网络，通过ProERA和DRPE模块增强特征提取和查询-原型对应，并通过LGPE模块利用文本信息，提高了少样本和零样本语义分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有少样本3D点云语义分割方法依赖预训练，限制了模型的灵活性和适应性；未预训练的方法信息捕捉不足；现有方法仅关注视觉信息，忽视了文本注释等其他有用数据，影响了性能和零样本能力。

Method: 1. 引入无需预训练的EPSegFZ网络。 2. 采用原型增强寄存器注意力（ProERA）模块和基于双相对位置编码（DRPE）的交叉注意力机制，用于特征提取和查询-原型对应。 3. 采用语言引导原型嵌入（LGPE）模块，利用文本信息增强少样本性能和实现零样本推理。

Result: 在S3DIS和ScanNet数据集上，EPSegFZ的性能分别优于最先进的方法5.68%和3.82%。

Conclusion: EPSegFZ网络成功解决了现有少样本3D点云语义分割方法在预训练依赖、信息利用和零样本能力方面的局限性，并在实验中取得了显著的性能提升。

Abstract: Recent approaches for few-shot 3D point cloud semantic segmentation typically require a two-stage learning process, i.e., a pre-training stage followed by a few-shot training stage. While effective, these methods face overreliance on pre-training, which hinders model flexibility and adaptability. Some models tried to avoid pre-training yet failed to capture ample information. In addition, current approaches focus on visual information in the support set and neglect or do not fully exploit other useful data, such as textual annotations. This inadequate utilization of support information impairs the performance of the model and restricts its zero-shot ability. To address these limitations, we present a novel pre-training-free network, named Efficient Point Cloud Semantic Segmentation for Few- and Zero-shot scenarios. Our EPSegFZ incorporates three key components. A Prototype-Enhanced Registers Attention (ProERA) module and a Dual Relative Positional Encoding (DRPE)-based cross-attention mechanism for improved feature extraction and accurate query-prototype correspondence construction without pre-training. A Language-Guided Prototype Embedding (LGPE) module that effectively leverages textual information from the support set to improve few-shot performance and enable zero-shot inference. Extensive experiments show that our method outperforms the state-of-the-art method by 5.68% and 3.82% on the S3DIS and ScanNet benchmarks, respectively.

</details>


### [6] [Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement](https://arxiv.org/abs/2511.11702)
*Lian He,Meng Liu,Qilang Ye,Yu Zhou,Xiang Deng,Gangyi Ding*

Main category: cs.CV

TL;DR: TASA是一个新颖的几何优化框架，通过结合2D语义线索和3D几何推理，实现了3D场景级可达性分割，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理3D场景级可达性分割时存在局限，例如仅关注物体级可达性、将2D预测提升到3D，以及忽略点云中的几何结构信息，导致计算成本高。

Method: TASA框架采用粗到精的方式，结合2D语义线索和3D几何推理。它包括一个任务感知的2D可达性检测模块，用于从语言和视觉输入中识别可操作点，并指导任务相关视图的选择；以及一个3D可达性细化模块，用于整合2D语义先验和局部3D几何信息，生成准确且空间一致的3D可达性掩码。

Result: TASA在SceneFun3D数据集上进行了实验，结果表明该方法在场景级可达性分割的准确性和效率方面均显著优于基线方法。

Conclusion: TASA框架能够有效地解决3D场景级可达性分割的挑战，通过结合2D语义信息和3D几何推理，在准确性和效率方面都取得了显著的提升。

Abstract: Understanding 3D scene-level affordances from natural language instructions is essential for enabling embodied agents to interact meaningfully in complex environments. However, this task remains challenging due to the need for semantic reasoning and spatial grounding. Existing methods mainly focus on object-level affordances or merely lift 2D predictions to 3D, neglecting rich geometric structure information in point clouds and incurring high computational costs. To address these limitations, we introduce Task-Aware 3D Scene-level Affordance segmentation (TASA), a novel geometry-optimized framework that jointly leverages 2D semantic cues and 3D geometric reasoning in a coarse-to-fine manner. To improve the affordance detection efficiency, TASA features a task-aware 2D affordance detection module to identify manipulable points from language and visual inputs, guiding the selection of task-relevant views. To fully exploit 3D geometric information, a 3D affordance refinement module is proposed to integrate 2D semantic priors with local 3D geometry, resulting in accurate and spatially coherent 3D affordance masks. Experiments on SceneFun3D demonstrate that TASA significantly outperforms the baselines in both accuracy and efficiency in scene-level affordance segmentation.

</details>


### [7] [Enhancing Road Safety Through Multi-Camera Image Segmentation with Post-Encroachment Time Analysis](https://arxiv.org/abs/2511.12018)
*Shounak Ray Chaudhuri,Arash Jahangiri,Christopher Paolini*

Main category: cs.CV

TL;DR: 本研究提出了一种利用多摄像头计算机视觉技术实时评估信号交叉口交通安全的新框架，通过计算越线时间（PET）来识别高风险区域。


<details>
  <summary>Details</summary>
Motivation: 传统的基于碰撞的研究存在数据稀疏和延迟的问题，本研究旨在提供一种更实时、精细化的交通安全评估方法。

Method: 该框架使用四个同步摄像头捕捉图像，并通过YOLOv11分割算法进行车辆检测。利用单应性矩阵将检测到的车辆多边形转换为鸟瞰图，并应用新颖的像素级PET算法来精确计算车辆位置，从而生成高分辨率的动态热力图。

Result: 实验结果表明，该框架能够以亚秒级精度和边缘设备的实时吞吐量识别高风险区域，生成的800 x 800像素对数热力图平均帧率为2.68 FPS。

Conclusion: 本研究验证了分布式视觉PET分析在智能交通系统中的可行性，为高分辨率、实时、可扩展的交叉口安全评估提供了一种可复制的方法。

Abstract: Traffic safety analysis at signalized intersections is vital for reducing vehicle and pedestrian collisions, yet traditional crash-based studies are limited by data sparsity and latency. This paper presents a novel multi-camera computer vision framework for real-time safety assessment through Post-Encroachment Time (PET) computation, demonstrated at the intersection of H Street and Broadway in Chula Vista, California. Four synchronized cameras provide continuous visual coverage, with each frame processed on NVIDIA Jetson AGX Xavier devices using YOLOv11 segmentation for vehicle detection. Detected vehicle polygons are transformed into a unified bird's-eye map using homography matrices, enabling alignment across overlapping camera views. A novel pixel-level PET algorithm measures vehicle position without reliance on fixed cells, allowing fine-grained hazard visualization via dynamic heatmaps, accurate to 3.3 sq-cm. Timestamped vehicle and PET data is stored in an SQL database for long-term monitoring. Results over various time intervals demonstrate the framework's ability to identify high-risk regions with sub-second precision and real-time throughput on edge devices, producing data for an 800 x 800 pixel logarithmic heatmap at an average of 2.68 FPS. This study validates the feasibility of decentralized vision-based PET analysis for intelligent transportation systems, offering a replicable methodology for high-resolution, real-time, and scalable intersection safety evaluation.

</details>


### [8] [LE-CapsNet: A Light and Enhanced Capsule Network](https://arxiv.org/abs/2511.11708)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: LE-CapsNet 是一个轻量级、增强型且更准确的胶囊网络变体，在 CIFAR-10 数据集上以 4 倍的速度实现了 76.73% 的准确率，在 AffNIST 数据集上实现了 94.3% 的准确率。


<details>
  <summary>Details</summary>
Motivation: 胶囊网络（CapsNet）虽然在图像分类方面优于卷积神经网络（CNN），尤其是在处理重叠类别和变换图像方面，但其计算速度慢、参数多、资源消耗大，并且在准确性方面也存在不足。

Method: 提出了一种名为 LE-CapsNet 的轻量级、增强型且更准确的胶囊网络变体，并通过实验验证了其在 CIFAR-10 和 AffNIST 数据集上的性能。

Result: LE-CapsNet 在 CIFAR-10 数据集上取得了 76.73% 的准确率，推理速度比 CapsNet 快 4 倍。在 AffNIST 数据集上，LE-CapsNet 的准确率为 94.3%，优于 CapsNet 的 90.52%。

Conclusion: LE-CapsNet 作为 CapsNet 的一种轻量级、增强型变体，在保持高准确率的同时，显著提高了运行速度和对仿射变换的鲁棒性。

Abstract: Capsule Network (CapsNet) classifier has several advantages over CNNs, including better detection of images containing overlapping categories and higher accuracy on transformed images. Despite the advantages, CapsNet is slow due to its different structure. In addition, CapsNet is resource-hungry, includes many parameters and lags in accuracy compared to CNNs. In this work, we propose LE-CapsNet as a light, enhanced and more accurate variant of CapsNet. Using 3.8M weights, LECapsNet obtains 76.73% accuracy on the CIFAR-10 dataset while performing inference 4x faster than CapsNet. In addition, our proposed network is more robust at detecting images with affine transformations compared to CapsNet. We achieve 94.3% accuracy on the AffNIST dataset (compared to CapsNet 90.52%).

</details>


### [9] [Target-Balanced Score Distillation](https://arxiv.org/abs/2511.11710)
*Zhou Xu,Qi Wang,Yuxiao Yang,Luyuan Zhang,Zhang Liang,Yang Li*

Main category: cs.CV

TL;DR: SDS存在饱和和模糊问题，引入负面提示可缓解但会影响纹理优化或形状保真度。本文提出TBSD，通过多目标优化和自适应策略解决此问题，实现高保真纹理和几何形状。


<details>
  <summary>Details</summary>
Motivation: SDS方法在3D资产生成中存在过饱和和过平滑问题，现有负面提示方法在纹理优化和形状保真度之间存在权衡。

Method: 提出目标平衡得分蒸馏（TBSD），将生成视为多目标优化问题，并引入自适应策略来解决纹理和形状之间的权衡问题。

Result: TBSD在多个实验中显著优于现有最先进方法，生成的3D资产具有高保真纹理和几何形状。

Conclusion: TBSD能够有效解决SDS方法中的纹理优化和形状保真度之间的权衡问题，生成高质量的3D资产。

Abstract: Score Distillation Sampling (SDS) enables 3D asset generation by distilling priors from pretrained 2D text-to-image diffusion models, but vanilla SDS suffers from over-saturation and over-smoothing. To mitigate this issue, recent variants have incorporated negative prompts. However, these methods face a critical trade-off: limited texture optimization, or significant texture gains with shape distortion. In this work, we first conduct a systematic analysis and reveal that this trade-off is fundamentally governed by the utilization of the negative prompts, where Target Negative Prompts (TNP) that embed target information in the negative prompts dramatically enhancing texture realism and fidelity but inducing shape distortions. Informed by this key insight, we introduce the Target-Balanced Score Distillation (TBSD). It formulates generation as a multi-objective optimization problem and introduces an adaptive strategy that effectively resolves the aforementioned trade-off. Extensive experiments demonstrate that TBSD significantly outperforms existing state-of-the-art methods, yielding 3D assets with high-fidelity textures and geometrically accurate shape.

</details>


### [10] [CompressNAS : A Fast and Efficient Technique for Model Compression using Decomposition](https://arxiv.org/abs/2511.11716)
*Sudhakar Sah,Nikhil Chabbra,Matthieu Durnerin*

Main category: cs.CV

TL;DR: CNN模型在嵌入式设备上部署困难，CompressNAS通过全局搜索低秩张量分解的秩来解决此问题，实现了有效的模型压缩。


<details>
  <summary>Details</summary>
Motivation: 深度卷积神经网络（CNN）因其日益增长的尺寸和计算需求，在微控制器（MCU）和轻量级神经网络处理单元（NPU）上的部署越来越困难。

Method: CompressNAS是一个受MicroNAS启发的框架，将秩选择视为一个全局搜索问题，并使用快速准确率估计器来评估候选分解，从而在内存和准确率的约束下进行高效的秩探索。

Result: 在ImageNet上，CompressNAS将ResNet-18压缩了8倍，准确率下降不到4%；在COCO上，将YOLOv5s压缩了2倍，准确率无下降；将YOLOv5n压缩了2倍，准确率下降2.5%。此外，还提出了一种新的压缩模型系列STResNet。

Conclusion: CompressNAS能够有效地压缩CNN模型，在保持可接受的准确率损失的同时，显著减小模型尺寸和计算需求，适用于资源受限的设备。

Abstract: Deep Convolutional Neural Networks (CNNs) are increasingly difficult to deploy on microcontrollers (MCUs) and lightweight NPUs (Neural Processing Units) due to their growing size and compute demands. Low-rank tensor decomposition, such as Tucker factorization, is a promising way to reduce parameters and operations with reasonable accuracy loss. However, existing approaches select ranks locally and often ignore global trade-offs between compression and accuracy. We introduce CompressNAS, a MicroNAS-inspired framework that treats rank selection as a global search problem. CompressNAS employs a fast accuracy estimator to evaluate candidate decompositions, enabling efficient yet exhaustive rank exploration under memory and accuracy constraints. In ImageNet, CompressNAS compresses ResNet-18 by 8x with less than 4% accuracy drop; on COCO, we achieve 2x compression of YOLOv5s without any accuracy drop and 2x compression of YOLOv5n with a 2.5% drop. Finally, we present a new family of compressed models, STResNet, with competitive performance compared to other efficient models.

</details>


### [11] [AdaptFly: Prompt-Guided Adaptation of Foundation Models for Low-Altitude UAV Networks](https://arxiv.org/abs/2511.11720)
*Jiao Chen,Haoyi Wang,Jianhua Tang,Junyi Wang*

Main category: cs.CV

TL;DR: AdaptFly是一个用于低空无人机网络的即时学习框架，通过提示引导的测试时自适应来提高语义分割的鲁棒性。它为资源受限和资源丰富的无人机提供了不同的自适应模式，并通过跨无人机知识库实现了高效的协同。


<details>
  <summary>Details</summary>
Motivation: 低空无人机网络的语义分割模型在天气、光照和视角变化时性能会下降。资源受限的无人机无法进行基于梯度的测试时自适应，而资源丰富的无人机则独立自适应，浪费了共享经验。为了解决这些问题，需要一种新的自适应方法。

Method: AdaptFly提出了一种提示引导的测试时自适应框架，无需更新模型权重。它包含两种自适应模式：对于资源受限的无人机，采用轻量级的token-prompt检索；对于资源丰富的无人机，采用无梯度稀疏视觉提示优化（Covariance Matrix Adaptation Evolution Strategy）。通过激活统计检测器触发自适应，并利用跨无人机知识池整合提示知识，实现无人机集群的协同，同时将带宽开销降至最低。

Result: 在UAVid和VDD数据集以及真实无人机部署的实验中，AdaptFly在各种天气条件下显著提高了语义分割的准确性和鲁棒性，优于静态模型和现有的TTA基线方法。

Conclusion: AdaptFly为新兴的低空经济提供了一条实用且通信高效的感知路径，能够实现弹性、可靠的语义分割，即使在严苛的环境下也能保持高性能。

Abstract: Low-altitude Unmanned Aerial Vehicle (UAV) networks rely on robust semantic segmentation as a foundational enabler for distributed sensing-communication-control co-design across heterogeneous agents within the network. However, segmentation foundation models deteriorate quickly under weather, lighting, and viewpoint drift. Resource-limited UAVs cannot run gradient-based test-time adaptation, while resource-massive UAVs adapt independently, wasting shared experience. To address these challenges, we propose AdaptFly, a prompt-guided test-time adaptation framework that adjusts segmentation models without weight updates. AdaptFly features two complementary adaptation modes. For resource-limited UAVs, it employs lightweight token-prompt retrieval from a shared global memory. For resource-massive UAVs, it uses gradient-free sparse visual prompt optimization via Covariance Matrix Adaptation Evolution Strategy. An activation-statistic detector triggers adaptation, while cross-UAV knowledge pool consolidates prompt knowledge and enables fleet-wide collaboration with negligible bandwidth overhead. Extensive experiments on UAVid and VDD benchmarks, along with real-world UAV deployments under diverse weather conditions, demonstrate that AdaptFly significantly improves segmentation accuracy and robustness over static models and state-of-the-art TTA baselines. The results highlight a practical path to resilient, communication-efficient perception in the emerging low-altitude economy.

</details>


### [12] [Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video](https://arxiv.org/abs/2511.11725)
*Zekai Shi,Zhixi Cai,Kalin Stefanov*

Main category: cs.CV

TL;DR: 儿童通过将口语与视觉指代物联系起来学习词语，但新词的理解存在歧义。本研究提出了一种自监督、生物学可行的策略，利用具有人类视觉盲点知识的掩码自动编码器来学习视觉表征。该方法通过掩码和重建来模仿人脑的视觉信息填充机制，并应用于视频-文本模型以学习词语-指代物映射。


<details>
  <summary>Details</summary>
Motivation: 解决儿童在缺乏先验知识的情况下，如何从模糊的输入中学习词语与视觉指代物之间映射的问题，并提出一种生物学上可行的视觉表征学习策略。

Method: 提出一种基于掩码自动编码器的视觉主干网络，其掩码策略结合了人类眼睛的盲点知识，模仿人脑的视觉信息填充机制。然后，将预训练的编码器应用于基于对比学习的视频-文本模型，以学习词语-指代物映射。

Result: 所提出的生物学掩码策略在学习词语-指代物映射方面，与随机掩码策略的效果相当，甚至更优。

Conclusion: 模仿人类视觉系统（如盲点处理）的生物学策略，是学习强大视觉表征并最终实现词语-指代物映射的有效途径。

Abstract: Typically, children start to learn their first words between 6 and 9 months, linking spoken utterances to their visual referents. Without prior knowledge, a word encountered for the first time can be interpreted in countless ways; it might refer to any of the objects in the environment, their components, or attributes. Using longitudinal, egocentric, and ecologically valid data from the experience of one child, in this work, we propose a self-supervised and biologically plausible strategy to learn strong visual representations. Our masked autoencoder-based visual backbone incorporates knowledge about the blind spot in human eyes to define a novel masking strategy. This mask and reconstruct approach attempts to mimic the way the human brain fills the gaps in the eyes' field of view. This represents a significant shift from standard random masking strategies, which are difficult to justify from a biological perspective. The pretrained encoder is utilized in a contrastive learning-based video-text model capable of acquiring word-referent mappings. Extensive evaluation suggests that the proposed biologically plausible masking strategy is at least as effective as random masking for learning word-referent mappings from cross-situational and temporally extended episodes.

</details>


### [13] [Co-Layout: LLM-driven Co-optimization for Interior Layout](https://arxiv.org/abs/2511.12474)
*Chucheng Xiang,Ruchao Bao,Biyin Feng,Wenzheng Wu,Zhongyuan Liu,Yirui Guan,Ligang Liu*

Main category: cs.CV

TL;DR: 提出了一种结合大语言模型（LLM）和基于网格的整数规划的新型自动化室内设计框架，用于联合优化房间布局和家具摆放。


<details>
  <summary>Details</summary>
Motivation: 解决现有两阶段设计流程在解决方案质量和计算效率方面的不足。

Method: 1. LLM驱动的代理工作流提取设计约束。2. 采用受“Modulor”启发的统一网格表示。3. 考虑了走廊连通性、房间可达性、空间排他性和用户偏好等设计要求。4. 采用粗粒度到细粒度的优化策略以提高计算效率。

Result: 在各种场景下，联合优化方法在解决方案质量上显著优于现有的两阶段设计流程，并通过粗粒度到细粒度策略实现了显著的计算效率。

Conclusion: 所提出的联合优化方法在自动化室内设计方面取得了高质量和高效率的结果。

Abstract: We present a novel framework for automated interior design that combines large language models (LLMs) with grid-based integer programming to jointly optimize room layout and furniture placement. Given a textual prompt, the LLM-driven agent workflow extracts structured design constraints related to room configurations and furniture arrangements. These constraints are encoded into a unified grid-based representation inspired by ``Modulor". Our formulation accounts for key design requirements, including corridor connectivity, room accessibility, spatial exclusivity, and user-specified preferences. To improve computational efficiency, we adopt a coarse-to-fine optimization strategy that begins with a low-resolution grid to solve a simplified problem and guides the solution at the full resolution. Experimental results across diverse scenarios demonstrate that our joint optimization approach significantly outperforms existing two-stage design pipelines in solution quality, and achieves notable computational efficiency through the coarse-to-fine strategy.

</details>


### [14] [GROVER: Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion](https://arxiv.org/abs/2511.11730)
*Yongjun Xiao,Dian Meng,Xinlei Huang,Yanran Liu,Shiwei Ruan,Ziyue Qiao,Xubin Zheng*

Main category: cs.CV

TL;DR: GROVER框架通过图卷积网络和对比学习融合多组学空间数据，解决了模态间异质性和分辨率不匹配问题，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 空间组学数据（转录组学、蛋白质组学、表观基因组学）缺乏病理形态学背景，因此需要与组织病理学图像整合以进行全面的疾病组织分析。然而，组学、成像和空间模态之间存在显著的异质性，以及分辨率不匹配和样本制备过程中的生物扰动等挑战。

Method: 提出GROVER（Graph-guided Representation of Omics and Vision with Expert Regulation）框架。该框架利用基于Kolmogorov-Arnold网络的图卷积网络编码器来捕捉各模态与其相关空间结构的非线性依赖关系，生成模态特定的嵌入。通过引入点-特征对对比学习策略来优化跨模态在每个点上的对应关系。设计动态专家路由机制，为每个点自适应地选择信息模态，同时抑制噪声或低质量输入。

Result: 在真实世界空间组学数据集上的实验表明，GROVER的性能优于最先进的基线方法。

Conclusion: GROVER为多模态空间组学数据的整合提供了一个鲁棒且可靠的解决方案。

Abstract: Effectively modeling multimodal spatial omics data is critical for understanding tissue complexity and underlying biological mechanisms. While spatial transcriptomics, proteomics, and epigenomics capture molecular features, they lack pathological morphological context. Integrating these omics with histopathological images is therefore essential for comprehensive disease tissue analysis. However, substantial heterogeneity across omics, imaging, and spatial modalities poses significant challenges. Naive fusion of semantically distinct sources often leads to ambiguous representations. Additionally, the resolution mismatch between high-resolution histology images and lower-resolution sequencing spots complicates spatial alignment. Biological perturbations during sample preparation further distort modality-specific signals, hindering accurate integration. To address these challenges, we propose Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion (GROVER), a novel framework for adaptive integration of spatial multi-omics data. GROVER leverages a Graph Convolutional Network encoder based on Kolmogorov-Arnold Networks to capture the nonlinear dependencies between each modality and its associated spatial structure, thereby producing expressive, modality-specific embeddings. To align these representations, we introduce a spot-feature-pair contrastive learning strategy that explicitly optimizes the correspondence across modalities at each spot. Furthermore, we design a dynamic expert routing mechanism that adaptively selects informative modalities for each spot while suppressing noisy or low-quality inputs. Experiments on real-world spatial omics datasets demonstrate that GROVER outperforms state-of-the-art baselines, providing a robust and reliable solution for multimodal integration.

</details>


### [15] [Exposing DeepFakes via Hyperspectral Domain Mapping](https://arxiv.org/abs/2511.11732)
*Aditya Mehta,Swarnim Chaudhary,Pratik Narang,Jagat Sesh Challa*

Main category: cs.CV

TL;DR: 该研究提出了一种名为HSI-Detect的超光谱成像技术，用于检测深度伪造图像。该技术通过将RGB图像重建为31通道的超光谱图像，并在超光谱域中进行检测，能够放大并检测到在RGB域中难以察觉的伪造痕迹，并在FaceForensics++数据集上取得了优于RGB方法的检测效果。


<details>
  <summary>Details</summary>
Motivation: 当前生成和扩散模型生成的逼真图像能够误导人类和自动化检测系统，而大多数现有检测方法仅限于RGB空间（三个光谱通道）进行分析，无法有效检测到细微的伪造痕迹。

Method: HSI-Detect是一个两阶段的管道。首先，它从标准的RGB输入重建一个31通道的超光谱图像。然后，在超光谱域中进行检测。通过扩展输入表示到更密集的频谱带，可以放大伪造的痕迹，这些痕迹在RGB域中通常很弱或不可见，尤其是在特定的频率带中。

Result: 在FaceForensics++数据集上的评估显示，HSI-Detect在检测深度伪造图像方面，相较于仅使用RGB的方法，取得了持续的改进。

Conclusion: 将频谱域映射应用于深度伪造检测具有潜力，HSI-Detect通过在超光谱域中进行分析，能够更有效地检测到经过篡改的图像。

Abstract: Modern generative and diffusion models produce highly realistic images that can mislead human perception and even sophisticated automated detection systems. Most detection methods operate in RGB space and thus analyze only three spectral channels. We propose HSI-Detect, a two-stage pipeline that reconstructs a 31-channel hyperspectral image from a standard RGB input and performs detection in the hyperspectral domain. Expanding the input representation into denser spectral bands amplifies manipulation artifacts that are often weak or invisible in the RGB domain, particularly in specific frequency bands. We evaluate HSI-Detect across FaceForensics++ dataset and show the consistent improvements over RGB-only baselines, illustrating the promise of spectral-domain mapping for Deepfake detection.

</details>


### [16] [Lightweight Optimal-Transport Harmonization on Edge Devices](https://arxiv.org/abs/2511.12785)
*Maria Larchenko,Dmitry Guskov,Alexander Lobashev,Georgy Derevyanko*

Main category: cs.CV

TL;DR: MKL-Harmonizer 算法提出了一种轻量级的颜色协调方法，适用于增强现实 (AR) 应用，通过利用最优输运理论，实现了实时性能和高合成图像质量。


<details>
  <summary>Details</summary>
Motivation: 当前 AR 流程中缺乏实时颜色协调解决方案，阻碍了其集成。

Method: 利用经典最优输运理论，训练了一个紧凑的编码器来预测 Monge-Kantorovich 输运图，实现了轻量级且支持设备端推理的方法。

Result: MKL-Harmonizer 算法在真实合成 AR 图像上取得了优于现有最先进方法的综合得分，证明了其有效性。

Conclusion: 所提出的轻量级颜色协调方法能够满足 AR 应用的实时性要求，并能生成高质量的合成图像。此外，发布的数据集和工具包将有助于该领域的研究。

Abstract: Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.

</details>


### [17] [Toward bilipshiz geometric models](https://arxiv.org/abs/2511.11735)
*Yonatan Sverdlov,Eitan Rosen,Nadav Dym*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Many neural networks for point clouds are, by design, invariant to the symmetries of this datatype: permutations and rigid motions. The purpose of this paper is to examine whether such networks preserve natural symmetry aware distances on the point cloud spaces, through the notion of bi-Lipschitz equivalence. This inquiry is motivated by recent work in the Equivariant learning literature which highlights the advantages of bi-Lipschitz models in other scenarios.
  We consider two symmetry aware metrics on point clouds: (a) The Procrustes Matching (PM) metric and (b) Hard Gromov Wasserstien distances. We show that these two distances themselves are not bi-Lipschitz equivalent, and as a corollary deduce that popular invariant networks for point clouds are not bi-Lipschitz with respect to the PM metric. We then show how these networks can be modified so that they do obtain bi-Lipschitz guarantees. Finally, we provide initial experiments showing the advantage of the proposed bi-Lipschitz model over standard invariant models, for the tasks of finding correspondences between 3D point clouds.

</details>


### [18] [PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos](https://arxiv.org/abs/2511.12935)
*Dianbing Xi,Guoyuan An,Jingsen Zhu,Zhijian Liu,Yuan Liu,Ruiyuan Zhang,Jiayuan Lu,Rui Wang,Yuchi Huo*

Main category: cs.CV

TL;DR: PFAvatar是一种从OOTD照片重建高质量3D头像的新方法，通过两阶段进行：1. 几张OOTD照片微调姿势感知的扩散模型；2. 蒸馏神经辐射场（NeRF）表示的3D头像。该方法避免了图像分解，端到端学习细节，实现了48倍的加速。与网格表示相比，NeRF表示能更好地处理遮挡和高频纹理。实验证明，PFAvatar在重建保真度、细节保留和鲁棒性方面优于现有方法，并支持虚拟试穿、动画等下游应用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从OOTD照片重建3D头像时，通常将图像分解为各个组件进行3D组装，容易导致不一致性。此外，网格表示在处理遮挡和高频纹理时存在局限性。因此，需要一种能够直接建模全身外观、处理遮挡和保留高频细节，并实现快速个性化的方法。

Method: PFAvatar方法包括两个阶段：1. 姿势感知扩散模型微调：利用几张OOTD照片，集成预训练的ControlNet进行姿态估计，并引入条件先验保持损失（CPPL）来促进端到端学习和减少语言漂移。2. NeRF表示的3D头像蒸馏：使用基于NeRF的头像表示，通过标准SMPL-X空间采样和多分辨率3D-SDS进行优化，以保留高频纹理并正确处理遮挡。

Result: PFAvatar在重建保真度、细节保留和对遮挡/截断的鲁棒性方面优于最先进的方法。与基于网格的表示相比，其连续辐射场能够保留高频纹理（如头发）并正确处理遮挡。该方法实现了5分钟的个性化，速度比以前的方法快48倍。

Conclusion: PFAvatar是一种有效且快速的3D头像重建方法，能够从OOTD照片中生成高质量的3D头像。它通过创新的两阶段方法克服了现有技术的局限性，并在重建保真度、细节保留和处理遮挡方面表现出色。该方法具有广泛的下游应用潜力，证明了其在实际3D头像生成中的价值。

Abstract: We propose PFAvatar (Pose-Fusion Avatar), a new method that reconstructs high-quality 3D avatars from ``Outfit of the Day'' (OOTD) photos, which exhibit diverse poses, occlusions, and complex backgrounds. Our method consists of two stages: (1) fine-tuning a pose-aware diffusion model from few-shot OOTD examples and (2) distilling a 3D avatar represented by a neural radiance field (NeRF). In the first stage, unlike previous methods that segment images into assets (e.g., garments, accessories) for 3D assembly, which is prone to inconsistency, we avoid decomposition and directly model the full-body appearance. By integrating a pre-trained ControlNet for pose estimation and a novel Condition Prior Preservation Loss (CPPL), our method enables end-to-end learning of fine details while mitigating language drift in few-shot training. Our method completes personalization in just 5 minutes, achieving a 48$\times$ speed-up compared to previous approaches. In the second stage, we introduce a NeRF-based avatar representation optimized by canonical SMPL-X space sampling and Multi-Resolution 3D-SDS. Compared to mesh-based representations that suffer from resolution-dependent discretization and erroneous occluded geometry, our continuous radiance field can preserve high-frequency textures (e.g., hair) and handle occlusions correctly through transmittance. Experiments demonstrate that PFAvatar outperforms state-of-the-art methods in terms of reconstruction fidelity, detail preservation, and robustness to occlusions/truncations, advancing practical 3D avatar generation from real-world OOTD albums. In addition, the reconstructed 3D avatar supports downstream applications such as virtual try-on, animation, and human video reenactment, further demonstrating the versatility and practical value of our approach.

</details>


### [19] [Concept-RuleNet: Grounded Multi-Agent Neurosymbolic Reasoning in Vision Language Models](https://arxiv.org/abs/2511.11751)
*Sanchit Sinha,Guangzhi Xiong,Zhenghao He,Aidong Zhang*

Main category: cs.CV

TL;DR: Concept-RuleNet是一个多智能体系统，通过从图像数据中挖掘视觉概念来增强符号推理的可解释性和视觉基础，从而提高视觉语言模型的准确性并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLM）在预测准确性方面表现出色，但在解释其决策原因方面却很薄弱，尤其是在处理分布外数据时，容易产生幻觉。现有的神经符号框架虽然提供了可解释性，但其符号提取仅依赖于任务标签，导致与底层视觉数据的关联较弱。

Method: Concept-RuleNet首先利用一个多模态概念生成器从训练图像中挖掘具有区分性的视觉概念。然后，利用这些视觉概念来指导符号的发现，使之与真实的图像统计数据相关联，并减轻标签偏见。接着，一个大型语言模型（LLM）推理代理将符号组合成可执行的一阶规则。在推理过程中，一个视觉验证代理量化每个符号存在的程度，并与黑盒神经网络模型的输出来协同触发规则的执行，从而提供具有明确推理路径的预测。

Result: 在五个基准测试（包括两个医学成像任务和三个自然图像数据集）上的实验表明，Concept-RuleNet将最先进的神经符号基线平均提高了5%，同时将规则中幻觉符号的出现频率降低了高达50%。

Conclusion: Concept-RuleNet通过引入视觉基础和可解释的推理，成功地解决了现有VLM的局限性，在提高预测准确性的同时，显著减少了不准确信息的产生。

Abstract: Modern vision-language models (VLMs) deliver impressive predictive accuracy yet offer little insight into 'why' a decision is reached, frequently hallucinating facts, particularly when encountering out-of-distribution data. Neurosymbolic frameworks address this by pairing black-box perception with interpretable symbolic reasoning, but current methods extract their symbols solely from task labels, leaving them weakly grounded in the underlying visual data. In this paper, we introduce a multi-agent system - Concept-RuleNet that reinstates visual grounding while retaining transparent reasoning. Specifically, a multimodal concept generator first mines discriminative visual concepts directly from a representative subset of training images. Next, these visual concepts are utilized to condition symbol discovery, anchoring the generations in real image statistics and mitigating label bias. Subsequently, symbols are composed into executable first-order rules by a large language model reasoner agent - yielding interpretable neurosymbolic rules. Finally, during inference, a vision verifier agent quantifies the degree of presence of each symbol and triggers rule execution in tandem with outputs of black-box neural models, predictions with explicit reasoning pathways. Experiments on five benchmarks, including two challenging medical-imaging tasks and three underrepresented natural-image datasets, show that our system augments state-of-the-art neurosymbolic baselines by an average of 5% while also reducing the occurrence of hallucinated symbols in rules by up to 50%.

</details>


### [20] [SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression](https://arxiv.org/abs/2511.13264)
*Keshav Gupta,Akshat Sanghvi,Shreyas Reddy Palley,Astitva Srivastava,Charu Sharma,Avinash Sharma*

Main category: cs.CV

TL;DR: 3D高斯泼溅技术的内存占用随场景复杂度的增加而急剧增加，本文提出了一种名为SymGS的新型压缩框架，通过引入可学习的镜像来消除冗余的3D高斯泼溅图元，实现了高达108倍的压缩率，同时保持了渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅压缩方法内存占用依然过高，需要更有效的压缩策略。

Method: 提出了一种名为SymGS的新型压缩框架，该框架通过引入可学习的镜像来识别和消除场景中的反射冗余，从而实现对3D高斯泼溅图元的压缩。SymGS可以作为现有先进压缩方法的即插即用增强模块。

Result: 与现有的HAC压缩方法相比，SymGS在基准数据集上实现了1.66倍的压缩率（在大型场景中高达3倍）。平均而言，SymGS能够实现108倍的3D高斯泼溅场景压缩，同时保持渲染质量。

Conclusion: SymGS通过利用对称性，特别是镜像对称性，显著提高了3D高斯泼溅的压缩效率，为处理复杂场景提供了有效的解决方案。

Abstract: 3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, \textbf{\textit{SymGS}}, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \times$ compression across benchmark datasets (upto $3\times$ on large-scale scenes). On an average, SymGS enables $\bf{108\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at \textbf{\color{cyan}{symgs.github.io}}

</details>


### [21] [Batch Transformer Architecture: Case of Synthetic Image Generation for Emotion Expression Facial Recognition](https://arxiv.org/abs/2511.11754)
*Stanislav Selitskiy*

Main category: cs.CV

TL;DR: 该论文提出了一种新的隐式稀疏风格Transformer变体架构，称为Batch Transformers。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统Transformer在处理序列或批次实体时的瓶颈问题，该架构通过只关注“重要”维度（主要成分）来优化注意力机制。

Method: Batch Transformers 架构只对 "重要" 维度（特征选择）进行注意力计算，从而减小了编码器-解码器人工神经网络架构中的瓶颈尺寸。

Result: 在人脸识别任务的合成图像生成（针对化妆和遮挡数据集）中进行了测试，能够增加有限的原始数据集的多样性。

Conclusion: Batch Transformers 架构通过关注重要维度，有效解决了传统Transformer的瓶颈问题，并提高了数据集的多样性。

Abstract: A novel Transformer variation architecture is proposed in the implicit sparse style. Unlike "traditional" Transformers, instead of attention to sequential or batch entities in their entirety of whole dimensionality, in the proposed Batch Transformers, attention to the "important" dimensions (primary components) is implemented. In such a way, the "important" dimensions or feature selection allows for a significant reduction of the bottleneck size in the encoder-decoder ANN architectures. The proposed architecture is tested on the synthetic image generation for the face recognition task in the case of the makeup and occlusion data set, allowing for increased variability of the limited original data set.

</details>


### [22] [Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing](https://arxiv.org/abs/2511.11780)
*Hossein Mohebbi,Mohammed Abdulrahman,Yanting Miao,Pascal Poupart,Suraj Kothawade*

Main category: cs.CV

TL;DR: Image-POSER是一个基于强化学习的框架，通过组合和调度现有的文本到图像和图像到图像模型来处理长而复杂的指令，以生成高质量的图像。


<details>
  <summary>Details</summary>
Motivation: 当前的文本到图像生成模型在处理长而复杂的指令方面存在不足，无法满足创意工作流的需求。

Method: Image-POSER采用反射式强化学习，将图像生成和编辑视为马尔可夫决策过程。它动态地将长指令分解为子任务，并通过视觉-语言模型的反馈进行监督，以自适应地组合不同模型的优势。

Result: Image-POSER在行业标准和自定义基准测试中，在图像的对齐度、保真度和美学方面均优于现有模型。在人类评估中也更受青睐。

Conclusion: 强化学习可以使人工智能系统具备自主分解、重组和组合视觉模型的能力，从而朝着通用视觉助手的方向发展。

Abstract: Recent advances in text-to-image generation have produced strong single-shot models, yet no individual system reliably executes the long, compositional prompts typical of creative workflows. We introduce Image-POSER, a reflective reinforcement learning framework that (i) orchestrates a diverse registry of pretrained text-to-image and image-to-image experts, (ii) handles long-form prompts end-to-end through dynamic task decomposition, and (iii) supervises alignment at each step via structured feedback from a vision-language model critic. By casting image synthesis and editing as a Markov Decision Process, we learn non-trivial expert pipelines that adaptively combine strengths across models. Experiments show that Image-POSER outperforms baselines, including frontier models, across industry-standard and custom benchmarks in alignment, fidelity, and aesthetics, and is consistently preferred in human evaluations. These results highlight that reinforcement learning can endow AI systems with the capacity to autonomously decompose, reorder, and combine visual models, moving towards general-purpose visual assistants.

</details>


### [23] [SOTFormer: A Minimal Transformer for Unified Object Tracking and Trajectory Prediction](https://arxiv.org/abs/2511.11824)
*Zhongping Dong,Pengyang Yu,Shuangjian Li,Liming Chen,Mohand Tahar Kechadi*

Main category: cs.CV

TL;DR: SOTFormer是一个轻量级的Transformer模型，可以在实时感知中统一目标检测、跟踪和短期运动预测，解决了遮挡、尺度变化和时间漂移等挑战。


<details>
  <summary>Details</summary>
Motivation: 在遮挡、尺度变化和时间漂移等挑战下，准确的单目标跟踪和短期运动预测仍然具有挑战性，这会破坏实时感知所需的时间连贯性。

Method: SOTFormer是一个最小的、具有恒定内存的Transformer模型，它在一个端到端的框架中统一了目标检测、跟踪和短期轨迹预测。该模型使用一个真实目标驱动的内存和一个专门用于稳定初始化的burn-in anchor loss来实现稳定的身份传播。单个轻量级的时间注意力层跨帧优化嵌入，可以实现实时推理和固定的GPU内存使用。

Result: 在Mini-LaSOT（20%）基准上，SOTFormer达到了76.3 AUC和53.7 FPS（AMP，4.3 GB VRAM），在快速运动、尺度变化和遮挡方面优于TrackFormer和MOTRv2等Transformer基线。

Conclusion: SOTFormer通过其创新的内存和损失机制，有效地解决了单目标跟踪和短期运动预测中的关键挑战，并在性能和效率上取得了显著的改进。

Abstract: Accurate single-object tracking and short-term motion forecasting remain challenging under occlusion, scale variation, and temporal drift, which disrupt the temporal coherence required for real-time perception. We introduce \textbf{SOTFormer}, a minimal constant-memory temporal transformer that unifies object detection, tracking, and short-horizon trajectory prediction within a single end-to-end framework. Unlike prior models with recurrent or stacked temporal encoders, SOTFormer achieves stable identity propagation through a ground-truth-primed memory and a burn-in anchor loss that explicitly stabilizes initialization. A single lightweight temporal-attention layer refines embeddings across frames, enabling real-time inference with fixed GPU memory. On the Mini-LaSOT (20%) benchmark, SOTFormer attains 76.3 AUC and 53.7 FPS (AMP, 4.3 GB VRAM), outperforming transformer baselines such as TrackFormer and MOTRv2 under fast motion, scale change, and occlusion.

</details>


### [24] [MP-GFormer: A 3D-Geometry-Aware Dynamic Graph Transformer Approach for Machining Process Planning](https://arxiv.org/abs/2511.11837)
*Fatemeh Elhambakhsh,Gaurav Ameta,Aditi Roy,Hyunwoong Ko*

Main category: cs.CV

TL;DR: 该研究提出了MP-GFormer，一个能够整合三维几何信息和动态图学习的Transformer模型，用于优化机械加工过程规划中的加工操作序列预测，相比现有方法提高了24%的主操作预测准确性和36%的子操作预测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习方法在处理机械加工过程规划（MP）中的动态依赖性时，未能有效整合零件的三维几何信息，导致领域认知不足。

Method: 提出了一种名为MP-GFormer的新模型，该模型利用三维几何感知动态图Transformer，通过注意力机制将演变的三维几何表示整合到动态图学习中，用于预测加工操作序列。该方法使用立体光刻曲面网格来表示每次加工操作后的零件三维几何形状，并采用边界表示法处理初始三维设计。

Result: MP-GFormer在合成数据集上的评估显示，与现有最先进的方法相比，主操作预测的准确性提高了24%，子操作预测的准确性提高了36%。

Conclusion: MP-GFormer通过整合三维几何信息，显著提高了动态图学习在机械加工过程规划中的预测能力，为解决该领域的挑战提供了新的解决方案。

Abstract: Machining process planning (MP) is inherently complex due to structural and geometrical dependencies among part features and machining operations. A key challenge lies in capturing dynamic interdependencies that evolve with distinct part geometries as operations are performed. Machine learning has been applied to address challenges in MP, such as operation selection and machining sequence prediction. Dynamic graph learning (DGL) has been widely used to model dynamic systems, thanks to its ability to integrate spatio-temporal relationships. However, in MP, while existing DGL approaches can capture these dependencies, they fail to incorporate three-dimensional (3D) geometric information of parts and thus lack domain awareness in predicting machining operation sequences. To address this limitation, we propose MP-GFormer, a 3D-geometry-aware dynamic graph transformer that integrates evolving 3D geometric representations into DGL through an attention mechanism to predict machining operation sequences. Our approach leverages StereoLithography surface meshes representing the 3D geometry of a part after each machining operation, with the boundary representation method used for the initial 3D designs. We evaluate MP-GFormer on a synthesized dataset and demonstrate that the method achieves improvements of 24\% and 36\% in accuracy for main and sub-operation predictions, respectively, compared to state-of-the-art approaches.

</details>


### [25] [Defending Unauthorized Model Merging via Dual-Stage Weight Protection](https://arxiv.org/abs/2511.11851)
*Wei-Jia Chen,Min-Yen Tsai,Cheng-Yi Lee,Chia-Mu Yu*

Main category: cs.CV

TL;DR: 模型合并存在知识产权和所有权风险，MergeGuard框架通过破坏合并兼容性来保护模型，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并实践存在未经授权的合并问题，侵犯知识产权，损害模型所有权和问责制。

Method: MergeGuard是一个双阶段保护框架：第一阶段通过L2正则化优化重新分配层间任务相关信息，分散梯度；第二阶段注入结构化扰动，错开任务子空间，破坏损失景观的曲率兼容性。

Result: MergeGuard成功将合并模型的准确率降低高达90%，同时保护后的模型性能损失小于1.5%。

Conclusion: MergeGuard能够有效防止未经授权的模型合并，同时最大限度地减少对原始模型性能的影响。

Abstract: The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual property rights but also undermines model ownership and accountability. To address this issue, we present MergeGuard, a proactive dual-stage weight protection framework that disrupts merging compatibility while maintaining task fidelity. In the first stage, we redistribute task-relevant information across layers via L2-regularized optimization, ensuring that important gradients are evenly dispersed. In the second stage, we inject structured perturbations to misalign task subspaces, breaking curvature compatibility in the loss landscape. Together, these stages reshape the model's parameter geometry such that merged models collapse into destructive interference while the protected model remains fully functional. Extensive experiments on both vision (ViT-L-14) and language (Llama2, Gemma2, Mistral) models demonstrate that MergeGuard reduces merged model accuracy by up to 90% with less than 1.5% performance loss on the protected model.

</details>


### [26] [FocusSDF: Boundary-Aware Learning for Medical Image Segmentation via Signed Distance Supervision](https://arxiv.org/abs/2511.11864)
*Muzammal Shafique,Nasir Rahim,Jamil Ahmad,Mohammad Siadat,Khalid Malik,Ghaus Malik*

Main category: cs.CV

TL;DR: FocusSDF是一种新的损失函数，通过关注边界区域来提高医学图像分割的准确性，并在多种任务和数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割模型在明确编码边界信息方面存在不足，导致边界保留效果不佳，而准确的分割对于临床诊断和治疗至关重要。

Method: 提出了一种基于符号距离函数（SDF）的新型损失函数FocusSDF。该函数通过自适应地为靠近病变或器官边界的像素分配更高的权重，引导网络关注边界区域，从而实现边界感知。

Result: 在包括MedSAM在内的五个最先进的医学图像分割模型上进行了广泛的实验评估。使用四种基于距离的损失函数，并涵盖了脑动脉瘤、中风、肝脏和乳腺肿瘤分割等多种任务和成像模态。结果一致表明，FocusSDF在医学图像分割任务中优于现有的基于距离变换的损失函数。

Conclusion: FocusSDF通过将焦点放在边界区域，有效解决了医学图像分割中的边界保持问题，并在广泛的评估中展现出优越的性能。

Abstract: Segmentation of medical images constitutes an essential component of medical image analysis, providing the foundation for precise diagnosis and efficient therapeutic interventions in clinical practices. Despite substantial progress, most segmentation models do not explicitly encode boundary information; as a result, making boundary preservation a persistent challenge in medical image segmentation. To address this challenge, we introduce FocusSDF, a novel loss function based on the signed distance functions (SDFs), which redirects the network to concentrate on boundary regions by adaptively assigning higher weights to pixels closer to the lesion or organ boundary, effectively making it boundary aware. To rigorously validate FocusSDF, we perform extensive evaluations against five state-of-the-art medical image segmentation models, including the foundation model MedSAM, using four distance-based loss functions across diverse datasets covering cerebral aneurysm, stroke, liver, and breast tumor segmentation tasks spanning multiple imaging modalities. The experimental results consistently demonstrate the superior performance of FocusSDF over existing distance transform based loss functions.

</details>


### [27] [Lacking Data? No worries! How synthetic images can alleviate image scarcity in wildlife surveys: a case study with muskox (Ovibos moschatus)](https://arxiv.org/abs/2511.11882)
*Simon Durand,Samuel Foucher,Alexandre Delplanque,Joëlle Taillon,Jérôme Théau*

Main category: cs.CV

TL;DR: 利用合成图像（SI）技术，即使在真实数据稀缺的情况下，也能有效训练深度学习目标检测模型（ODMs），以提升对麝牛等稀疏物种的检测能力，为野生动物监测提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 野生动物管理需要准确的人口估计，但传统的调查方法（如航空计数和GNSS遥测）资源消耗大且后勤困难。深度学习目标检测模型（ODMs）在处理小数据集时效果有限，而麝牛等物种的训练数据尤为稀少。因此，本研究旨在探索使用合成图像（SI）来补充有限的训练数据，以提高在零样本（ZS）和少样本（FS）场景下麝牛的检测性能。

Method: 本研究比较了一个仅使用真实图像训练的基线模型，以及五个在训练集中逐步增加合成图像（SI）的零样本（ZS）模型和五个少样本（FS）模型。在ZS模型中，训练集不包含任何真实图像；在FS模型中，则结合了真实图像和SI。研究人员评估了不同比例SI对模型在精度、召回率和F1分数等指标上的影响。

Result: 在零样本（ZS）模型中，添加SI能够提高检测性能，并且随着SI的增加，精度、召回率和F1分数均有所提升，但当SI超过基线模型训练数据集的100%时，性能提升逐渐趋于平缓。在少样本（FS）模型中，结合真实图像和SI相比仅使用真实图像，能够提高召回率并略微提升整体准确性，但这种改进在统计学上不显著。

Conclusion: 合成图像（SI）在数据稀缺的情况下，能够有效地训练出准确的目标检测模型（ODMs），为野生动物监测提供了重要的思路。该方法不仅能够监测稀有或难以到达的物种，还能提高监测频率。此外，该方法还能在没有真实数据的情况下启动ODMs，并随着时间的推移和真实图像的获取而不断优化模型。

Abstract: Accurate population estimates are essential for wildlife management, providing critical insights into species abundance and distribution. Traditional survey methods, including visual aerial counts and GNSS telemetry tracking, are widely used to monitor muskox populations in Arctic regions. These approaches are resource intensive and constrained by logistical challenges. Advances in remote sensing, artificial intelligence, and high resolution aerial imagery offer promising alternatives for wildlife detection. Yet, the effectiveness of deep learning object detection models (ODMs) is often limited by small datasets, making it challenging to train robust ODMs for sparsely distributed species like muskoxen. This study investigates the integration of synthetic imagery (SI) to supplement limited training data and improve muskox detection in zero shot (ZS) and few-shot (FS) settings. We compared a baseline model trained on real imagery with 5 ZS and 5 FS models that incorporated progressively more SI in the training set. For the ZS models, where no real images were included in the training set, adding SI improved detection performance. As more SI were added, performance in precision, recall and F1 score increased, but eventually plateaued, suggesting diminishing returns when SI exceeded 100% of the baseline model training dataset. For FS models, combining real and SI led to better recall and slightly higher overall accuracy compared to using real images alone, though these improvements were not statistically significant. Our findings demonstrate the potential of SI to train accurate ODMs when data is scarce, offering important perspectives for wildlife monitoring by enabling rare or inaccessible species to be monitored and to increase monitoring frequency. This approach could be used to initiate ODMs without real data and refine it as real images are acquired over time.

</details>


### [28] [Advancing Annotat3D with Harpia: A CUDA-Accelerated Library For Large-Scale Volumetric Data Segmentation](https://arxiv.org/abs/2511.11890)
*Camila Machado de Araujo,Egon P. B. S. Borges,Ricardo Marcelo Canteiro Grangeiro,Allan Pinto*

Main category: cs.CV

TL;DR: Harpia是一个新的CUDA库，用于大规模3D医学图像的交互式分割，通过高效的内存控制、分块执行和GPU加速工具，提高了处理速度和内存效率，适用于HPC和远程协作环境。


<details>
  <summary>Details</summary>
Motivation: 高分辨率体积成像技术产生的数据集越来越大，对现有工具的处理、分割和交互式探索能力提出了挑战。

Method: 提出Harpia，一个基于CUDA的库，支持大规模、交互式的3D数据集分割工作流，采用内存控制、分块执行、GPU加速过滤、注释和量化工具。

Result: 与NVIDIA cuCIM和scikit-image等框架相比，Harpia在处理速度、内存效率和可扩展性方面取得了显著的改进。

Conclusion: Harpia的交互式、人机协同界面和高效的GPU资源管理，使其特别适合在共享HPC基础设施中进行协作科学成像工作流。

Abstract: High-resolution volumetric imaging techniques, such as X-ray tomography and advanced microscopy, generate increasingly large datasets that challenge existing tools for efficient processing, segmentation, and interactive exploration. This work introduces new capabilities to Annotat3D through Harpia, a new CUDA-based processing library designed to support scalable, interactive segmentation workflows for large 3D datasets in high-performance computing (HPC) and remote-access environments. Harpia features strict memory control, native chunked execution, and a suite of GPU-accelerated filtering, annotation, and quantification tools, enabling reliable operation on datasets exceeding single-GPU memory capacity. Experimental results demonstrate significant improvements in processing speed, memory efficiency, and scalability compared to widely used frameworks such as NVIDIA cuCIM and scikit-image. The system's interactive, human-in-the-loop interface, combined with efficient GPU resource management, makes it particularly suitable for collaborative scientific imaging workflows in shared HPC infrastructures.

</details>


### [29] [Prompt Triage: Structured Optimization Enhances Vision-Language Model Performance on Medical Imaging Benchmarks](https://arxiv.org/abs/2511.11898)
*Arnav Singhvi,Vasiliki Bikia,Asad Aali,Akshay Chaudhari,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 本研究将DSPy框架应用于医学影像任务，通过自动化提示优化显著提升了视觉语言模型(VLMs)的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLMs在医学领域表现不佳，而微调需要大量数据和计算资源，手动提示工程难以推广且不适用于所有医疗机构。因此，需要一种无需人工设计提示即可利用模型内置知识并实现可扩展、与权重无关的性能提升的方法。

Method: 研究人员将DSPy框架应用于结构化自动提示优化，针对放射学、胃肠病学和皮肤病学中的五个医学影像任务，评估了10个开源VLMs和4种提示优化技术。

Result: 与零样本提示基线相比，优化后的提示流水线在中位值上实现了53%的相对性能提升，在零样本性能较低的任务上，提升幅度高达300%至3,400%。

Conclusion: 自动化提示优化在医学AI领域具有巨大潜力，可以显著提高基于视觉的应用的性能，使临床医生能够专注于患者护理。此外，该方法具有可扩展性、保护数据隐私，并能提升开源VLMs的性能。研究人员公开了评估流水线以支持可复现的研究。

Abstract: Vision-language foundation models (VLMs) show promise for diverse imaging tasks but often underperform on medical benchmarks. Prior efforts to improve performance include model finetuning, which requires large domain-specific datasets and significant compute, or manual prompt engineering, which is hard to generalize and often inaccessible to medical institutions seeking to deploy these tools. These challenges motivate interest in approaches that draw on a model's embedded knowledge while abstracting away dependence on human-designed prompts to enable scalable, weight-agnostic performance improvements. To explore this, we adapt the Declarative Self-improving Python (DSPy) framework for structured automated prompt optimization in medical vision-language systems through a comprehensive, formal evaluation. We implement prompting pipelines for five medical imaging tasks across radiology, gastroenterology, and dermatology, evaluating 10 open-source VLMs with four prompt optimization techniques. Optimized pipelines achieved a median relative improvement of 53% over zero-shot prompting baselines, with the largest gains ranging from 300% to 3,400% on tasks where zero-shot performance is low. These results highlight the substantial potential of applying automated prompt optimization to medical AI systems, demonstrating significant gains for vision-based applications requiring accurate clinical image interpretation. By reducing dependence on prompt design to elicit intended outputs, these techniques allow clinicians to focus on patient care and clinical decision-making. Furthermore, our experiments offer scalability and preserve data privacy, demonstrating performance improvement on open-source VLMs. We publicly release our evaluation pipelines to support reproducible research on specialized medical tasks, available at https://github.com/DaneshjouLab/prompt-triage-lab.

</details>


### [30] [PI-NAIM: Path-Integrated Neural Adaptive Imputation Model](https://arxiv.org/abs/2511.11908)
*Afifa Khaled,Ebrahim Hamid Sumiea*

Main category: cs.CV

TL;DR: PI-NAIM是一个新颖的框架，用于解决医学成像和多模态临床设置中的缺失模态挑战，通过动态路由到优化的插补方法，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的插补方法在表示能力或计算成本方面存在不足，无法有效处理医学成像和多模态临床设置中常见的缺失模态问题。

Method: PI-NAIM采用一种新颖的双路径架构，根据缺失的复杂性动态地将样本路由到优化的插补方法。它包括：1）智能路径路由，将低缺失样本路由到MICE（一种统计插补方法），将复杂模式路由到GAIN（一种结合时间分析的神经网络）；2）跨路径注意力融合，利用感知缺失的嵌入来智能地组合两个分支；3）联合优化插补精度和下游任务性能的端到端优化。

Result: 在MIMIC-III和多模态基准上的广泛实验表明，PI-NAIM取得了最先进的性能，RMSE为0.108（相比之下，基线方法的RMSE为0.119-0.152），并在下游任务中取得了显著的提升，例如在死亡率预测任务中的AUROC为0.812。

Conclusion: PI-NAIM的模块化设计使其能够无缝集成到处理不完整传感器测量、缺失模态或损坏输入的视觉管道中，为真实世界的场景提供了一个统一的解决方案。

Abstract: Medical imaging and multi-modal clinical settings often face the challange of missing modality in their diagnostic pipelines. Existing imputation methods either lack representational capacity or are computationally expensive. We propose PI-NAIM, a novel dual-path architecture that dynamically routes samples to optimized imputation approaches based on missingness complexity. Our framework integrates: (1) intelligent path routing that directs low missingness samples to efficient statistical imputation (MICE) and complex patterns to powerful neural networks (GAIN with temporal analysis); (2) cross-path attention fusion that leverages missingness-aware embeddings to intelligently combine both branches; and (3) end-to-end joint optimization of imputation accuracy and downstream task performance. Extensive experiments on MIMIC-III and multimodal benchmarks demonstrate state-of-the-art performance, achieving RMSE of 0.108 (vs. baselines' 0.119-0.152) and substantial gains in downstream tasks with an AUROC of 0.812 for mortality prediction. PI-NAIM's modular design enables seamless integration into vision pipelines handling incomplete sensor measurements, missing modalities, or corrupted inputs, providing a unified solution for real-world scenario. The code is publicly available at https://github.com/AfifaKhaled/PI-NAIM-Path-Integrated-Neural-Adaptive-Imputation-Model

</details>


### [31] [Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models](https://arxiv.org/abs/2511.11910)
*Siyou Li,Huanan Wu,Juexi Shao,Yinghao Ma,Yujian Gan,Yihao Luo,Yuwei Wang,Dong Nie,Lu Wang,Wengqing Wu,Le Zhang,Massimo Poesio,Juntao Yu*

Main category: cs.CV

TL;DR: QTSplus是一个轻量级视觉令牌选择模块，通过动态选择与文本查询最相关的视觉证据，显著减少了长视频理解中的计算成本和延迟，同时保持了接近原始模型的准确性，并在特定任务上取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 长视频理解对多模态大语言模型（MLLMs）仍是挑战，主要是因为视觉令牌数量随视频长度线性增长，导致注意力成本、内存和延迟急剧增加。

Method: 提出QTSplus模块，通过交叉注意力对视觉令牌打分，根据查询复杂性预测令牌保留预算，并使用可微分的直通估计器（训练时）和硬门控（推理时）选择Top-n令牌。此外，使用小型再编码器结合绝对时间信息来保持时间顺序，实现秒级定位和全局覆盖。

Result: QTSplus将视觉流压缩高达89%，将长视频的端到端延迟降低28%。在八个长视频理解基准测试中，准确性与原始Qwen模型接近，在TempCompass的方向和顺序准确性上分别提升了+20.5和+5.6。在长视频场景下，QTSplus有效且通用，能在保持任务相关证据的同时扩展MLLMs。

Conclusion: QTSplus是一种有效且通用的机制，可以在保持任务相关证据的同时，将MLLMs扩展到实际的长视频场景。

Abstract: Despite the recent advances in the video understanding ability of multimodal large language models (MLLMs), long video understanding remains a challenge. One of the main issues is that the number of vision tokens grows linearly with video length, which causes an explosion in attention cost, memory, and latency. To solve this challenge, we present Query-aware Token Selector (\textbf{QTSplus}), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder and LLMs. Given a text query and video tokens, QTSplus dynamically selects the most important visual evidence for the input text query by (i) scoring visual tokens via cross-attention, (ii) \emph{predicting} an instance-specific retention budget based on the complexity of the query, and (iii) \emph{selecting} Top-$n$ tokens with a differentiable straight-through estimator during training and a hard gate at inference. Furthermore, a small re-encoder preserves temporal order using absolute time information, enabling second-level localization while maintaining global coverage.
  Integrated into Qwen2.5-VL, QTSplus compresses the vision stream by up to \textbf{89\%} and reduces end-to-end latency by \textbf{28\%} on long videos. The evaluation on eight long video understanding benchmarks shows near-parity accuracy overall when compared with the original Qwen models and outperforms the original model by \textbf{+20.5} and \textbf{+5.6} points respectively on TempCompass direction and order accuracies. These results show that QTSplus is an effective, general mechanism for scaling MLLMs to real-world long-video scenarios while preserving task-relevant evidence.
  We will make all code, data, and trained models' weights publicly available.

</details>


### [32] [From Events to Clarity: The Event-Guided Diffusion Framework for Dehazing](https://arxiv.org/abs/2511.11944)
*Ling Wang,Yunfan Lu,Wenzong Ma,Huizai Yao,Pengteng Li,Hui Xiong*

Main category: cs.CV

TL;DR: 使用事件相机和扩散模型进行雾天去雾。


<details>
  <summary>Details</summary>
Motivation: 现有基于RGB帧的去雾方法由于动态范围的限制，容易丢失结构和光照细节，导致去雾问题不适定。事件相机具有高动态范围和微秒级延迟，更适合雾天场景。

Method: 提出了一种事件引导的扩散模型，利用事件相机的高动态范围信息来指导图像恢复。具体地，设计了一个事件引导模块，将稀疏的事件特征（如边缘、角点）映射到扩散模型的潜在空间，为图像生成提供精确的结构指导。

Result: 在两个基准数据集和收集的无人机数据集上实现了最先进的去雾效果。

Conclusion: 事件相机与扩散模型相结合，为解决雾天去雾问题提供了一种有效的新方法，能够更好地保留图像的结构和光照细节。

Abstract: Clear imaging under hazy conditions is a critical task. Prior-based and neural methods have improved results. However, they operate on RGB frames, which suffer from limited dynamic range. Therefore, dehazing remains ill-posed and can erase structure and illumination details. To address this, we use event cameras for dehazing for the \textbf{first time}. Event cameras offer much higher HDR ($120 dBvs.60 dB$) and microsecond latency, therefore they suit hazy scenes. In practice, transferring HDR cues from events to frames is hard because real paired data are scarce. To tackle this, we propose an event-guided diffusion model that utilizes the strong generative priors of diffusion models to reconstruct clear images from hazy inputs by effectively transferring HDR information from events. Specifically, we design an event-guided module that maps sparse HDR event features, \textit{e.g.,} edges, corners, into the diffusion latent space. This clear conditioning provides precise structural guidance during generation, improves visual realism, and reduces semantic drift. For real-world evaluation, we collect a drone dataset in heavy haze (AQI = 341) with synchronized RGB and event sensors. Experiments on two benchmarks and our dataset achieve state-of-the-art results.

</details>


### [33] [Evaluation of Attention Mechanisms in U-Net Architectures for Semantic Segmentation of Brazilian Rock Art Petroglyphs](https://arxiv.org/abs/2511.11959)
*Leonardi Melo,Luís Gustavo,Dimmy Magalhães,Lucciani Vieira,Mauro Araújo*

Main category: cs.CV

TL;DR: 本文比较了三种基于U-Net的语义分割模型在巴西岩画图像上的表现，其中Attention-Residual BEGL-UNet效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了提升岩画数字保护的准确性，本文旨在比较几种先进的U-Net架构在岩画语义分割任务上的性能。

Method: 本文使用了三种U-Net变体（BEGL-UNet、Attention-Residual BEGL-UNet、Spatial Channel Attention BEGL-UNet），并结合了BEGL损失函数，在巴西考古遗址的岩画图像上进行了5折交叉验证实验。

Result: Attention-Residual BEGL-UNet取得了最好的总体性能（Dice Score: 0.710），Spatial Channel Attention BEGL-UNet表现相当（DSC: 0.707），均优于基线BEGL-UNet（DSC: 0.690）。

Conclusion: 注意力机制能够有效提升岩画语义分割的性能，为考古遗产的数字化保护提供了有效手段。

Abstract: This study presents a comparative analysis of three U-Net-based architectures for semantic segmentation of rock art petroglyphs from Brazilian archaeological sites. The investigated architectures were: (1) BEGL-UNet with Border-Enhanced Gaussian Loss function; (2) Attention-Residual BEGL-UNet, incorporating residual blocks and gated attention mechanisms; and (3) Spatial Channel Attention BEGL-UNet, which employs spatial-channel attention modules based on Convolutional Block Attention Module. All implementations employed the BEGL loss function combining binary cross-entropy with Gaussian edge enhancement. Experiments were conducted on images from the Poço da Bebidinha Archaeological Complex, Piauí, Brazil, using 5-fold cross-validation. Among the architectures, Attention-Residual BEGL-UNet achieved the best overall performance with Dice Score of 0.710, validation loss of 0.067, and highest recall of 0.854. Spatial Channel Attention BEGL-UNet obtained comparable performance with DSC of 0.707 and recall of 0.857. The baseline BEGL-UNet registered DSC of 0.690. These results demonstrate the effectiveness of attention mechanisms for archaeological heritage digital preservation, with Dice Score improvements of 2.5-2.9% over the baseline.

</details>


### [34] [From Classification to Cross-Modal Understanding: Leveraging Vision-Language Models for Fine-Grained Renal Pathology](https://arxiv.org/abs/2511.11984)
*Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Junchao Zhu,Haibo Wang,Daniel Reisenbüchler,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Steven Salvatoree,Surya Seshane,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 该研究将细粒度肾小球亚型分类建模为临床上现实的少样本问题，评估了专业和通用视觉-语言模型（VLMs）在数据约束下的表现。研究结果表明，病理学专业VLMs在微调后是最有效的起点，即使在每个亚型只有4-8个标注样本的情况下，也能显著提高区分度和校准度。研究还强调了正负样本区分与图像-文本对齐同等重要，并为模型选择、适应策略和标注投入提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有计算病理学方法倾向于在全监督下评估粗粒度疾病分类，缺乏针对数据约束下细粒度肾小球亚型分类的临床价值标签。因此，需要探索视觉-语言模型（VLMs）如何在数据有限的情况下进行临床有意义的亚型分类。

Method: 将细粒度肾小球亚型分类建模为临床现实的少样本问题，并在此设置下系统地评估了病理学专业和通用视觉-语言模型。研究评估了分类性能（准确率、AUC、F1），并检查了学习表示的几何结构，包括图像和文本嵌入之间的特征对齐以及肾小球亚型的可分离性。通过联合分析样本数量、模型架构和领域知识以及适应策略，为临床数据约束下的模型选择和训练提供指导。

Result: 研究结果表明，病理学专业视觉-语言模型在进行简单微调后是最有效的起点。即使每个肾小球亚型只有4-8个标注样本，这些模型也能开始捕捉区分特征，并在区分度和校准度方面显示出显著的收益，尽管额外的监督可以带来渐进的改进。研究还发现，正负样本之间的区分与图像-文本对齐同等重要。

Conclusion: 监督水平和适应策略共同影响诊断性能和多模态结构。该研究为模型选择、适应策略和标注投入提供了指导，以应对临床数据约束下的细粒度肾小球亚型分类挑战。

Abstract: Fine-grained glomerular subtyping is central to kidney biopsy interpretation, but clinically valuable labels are scarce and difficult to obtain. Existing computational pathology approaches instead tend to evaluate coarse diseased classification under full supervision with image-only models, so it remains unclear how vision-language models (VLMs) should be adapted for clinically meaningful subtyping under data constraints. In this work, we model fine-grained glomerular subtyping as a clinically realistic few-shot problem and systematically evaluate both pathology-specialized and general-purpose vision-language models under this setting. We assess not only classification performance (accuracy, AUC, F1) but also the geometry of the learned representations, examining feature alignment between image and text embeddings and the separability of glomerular subtypes. By jointly analyzing shot count, model architecture and domain knowledge, and adaptation strategy, this study provides guidance for future model selection and training under real clinical data constraints. Our results indicate that pathology-specialized vision-language backbones, when paired with the vanilla fine-tuning, are the most effective starting point. Even with only 4-8 labeled examples per glomeruli subtype, these models begin to capture distinctions and show substantial gains in discrimination and calibration, though additional supervision continues to yield incremental improvements. We also find that the discrimination between positive and negative examples is as important as image-text alignment. Overall, our results show that supervision level and adaptation strategy jointly shape both diagnostic performance and multimodal structure, providing guidance for model selection, adaptation strategies, and annotation investment.

</details>


### [35] [BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups](https://arxiv.org/abs/2511.11989)
*Songsong Zhang,Chuanqi Tang,Hongguang Zhang,Guijian Tang,Minglong Li,Xueqiong Li,Shaowu Yang,Yuanxi Peng,Wenjing Yang,Jing Zhao*

Main category: cs.CV

TL;DR: 该研究提出了一种身份保持个性化生成（IPPG）新方法，解决了现有技术过度依赖面部特写的问题，实现了身份保真度和场景语义创建的协同优化。


<details>
  <summary>Details</summary>
Motivation: 现有IPPG方法过度关注面部区域，导致生成内容以面部特写为主，视觉叙事性差，且在复杂文本提示下语义一致性不足，主要原因是身份（ID）特征嵌入削弱了生成模型的语义表达能力。

Method: 提出了一种双线推理（DLI）流水线，实现了身份-语义分离，解决了传统单线架构中ID和语义的表示冲突。设计了身份自适应融合（IdAF）策略，将ID-语义融合推迟到噪声预测阶段，结合自适应注意力融合和噪声决策掩蔽，避免了ID嵌入对语义的干扰。引入了身份聚合预处理（IdAP）模块，聚合ID信息并替代随机初始化，增强身份保持能力。

Result: 实验结果表明，该方法在IPPG任务中表现稳定有效，能够生成超越面部特写的图像，且无需手动掩蔽或微调即可高效生成。

Conclusion: 该IPPG方法有效解决了现有技术的局限性，能够生成更丰富的面部细节，并能在现有IPPG框架中即插即用，为影视级角色-场景创作提供了更强的能力。

Abstract: Identity-Preserving Personalized Generation (IPPG) has advanced film production and artistic creation, yet existing approaches overemphasize facial regions, resulting in outputs dominated by facial close-ups.These methods suffer from weak visual narrativity and poor semantic consistency under complex text prompts, with the core limitation rooted in identity (ID) feature embeddings undermining the semantic expressiveness of generative models. To address these issues, this paper presents an IPPG method that breaks the constraint of facial close-ups, achieving synergistic optimization of identity fidelity and scene semantic creation. Specifically, we design a Dual-Line Inference (DLI) pipeline with identity-semantic separation, resolving the representation conflict between ID and semantics inherent in traditional single-path architectures. Further, we propose an Identity Adaptive Fusion (IdAF) strategy that defers ID-semantic fusion to the noise prediction stage, integrating adaptive attention fusion and noise decision masking to avoid ID embedding interference on semantics without manual masking. Finally, an Identity Aggregation Prepending (IdAP) module is introduced to aggregate ID information and replace random initializations, further enhancing identity preservation. Experimental results validate that our method achieves stable and effective performance in IPPG tasks beyond facial close-ups, enabling efficient generation without manual masking or fine-tuning. As a plug-and-play component, it can be rapidly deployed in existing IPPG frameworks, addressing the over-reliance on facial close-ups, facilitating film-level character-scene creation, and providing richer personalized generation capabilities for related domains.

</details>


### [36] [Dynamic Parameter Optimization for Highly Transferable Transformation-Based Attacks](https://arxiv.org/abs/2511.11993)
*Jiaming Liang,Chi-Man Pun*

Main category: cs.CV

TL;DR: 深度神经网络易受攻击，特别是基于变换的攻击。现有攻击在参数优化方面存在不足，限制了其潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络应用广泛，但其漏洞引起了社会担忧。现有的基于变换的攻击在迁移攻击方面取得了显著成功，但存在参数优化方面的盲点，限制了其全部潜力。

Method: 提出了一种新颖的同心衰减模型（CDM）来解释动态模式，并提出了一种基于升后降模式的高效动态参数优化（DPO）方法，将复杂度从O(mn)降低到O(nlogm)。

Result: 实验表明，DPO能显著提高现有基于变换的攻击在不同模型、迭代次数和任务上的迁移能力。

Conclusion: 该研究通过实证研究和提出的CDM与DPO，解决了现有基于变换的攻击在参数优化方面的局限性，显著提升了其迁移能力。

Abstract: Despite their wide application, the vulnerabilities of deep neural networks raise societal concerns. Among them, transformation-based attacks have demonstrated notable success in transfer attacks. However, existing attacks suffer from blind spots in parameter optimization, limiting their full potential. Specifically, (1) prior work generally considers low-iteration settings, yet attacks perform quite differently at higher iterations, so characterizing overall performance based only on low-iteration results is misleading. (2) Existing attacks use uniform parameters for different surrogate models, iterations, and tasks, which greatly impairs transferability. (3) Traditional transformation parameter optimization relies on grid search. For n parameters with m steps each, the complexity is O(mn). Large computational overhead limits further optimization of parameters. To address these limitations, we conduct an empirical study with various transformations as baselines, revealing three dynamic patterns of transferability with respect to parameter strength. We further propose a novel Concentric Decay Model (CDM) to effectively explain these patterns. Building on these insights, we propose an efficient Dynamic Parameter Optimization (DPO) based on the rise-then-fall pattern, reducing the complexity to O(nlogm). Comprehensive experiments on existing transformation-based attacks across different surrogate models, iterations, and tasks demonstrate that our DPO can significantly improve transferability.

</details>


### [37] [LithoSeg: A Coarse-to-Fine Framework for High-Precision Lithography Segmentation](https://arxiv.org/abs/2511.12005)
*Xinyu He,Botong Zhao,Bingbing Li,Shujing Lyu,Jiwei Shen,Yue Lu*

Main category: cs.CV

TL;DR: LithoSeg是一个用于光刻扫描电镜图像分割的粗到精网络，通过结合人机交互和1D回归，在精度和鲁棒性方面优于现有方法，并减少了监督需求。


<details>
  <summary>Details</summary>
Motivation: 现有的光刻分割方法在精度和鲁棒性方面存在不足，限制了其在半导体制造中的实际应用。

Method: 提出LithoSeg，一个粗到精的网络。粗略阶段：使用人机交互引导分割任何模型（SAM）以实现最小监督下的鲁棒性。精细阶段：将2D分割重塑为1D回归问题，通过采样沟槽法线轮廓并使用轻量级MLP进行逐点优化。

Result: LithoSeg在分割精度和测量精度方面均优于先前的方法，同时需要更少的监督。

Conclusion: LithoSeg为实际应用提供了有前景的解决方案，在分割精度、测量精度和监督需求方面都取得了改进。

Abstract: Accurate segmentation and measurement of lithography scanning electron microscope (SEM) images are crucial for ensuring precise process control, optimizing device performance, and advancing semiconductor manufacturing yield. Lithography segmentation requires pixel-level delineation of groove contours and consistent performance across diverse pattern geometries and process window. However, existing methods often lack the necessary precision and robustness, limiting their practical applicability. To overcome this challenge, we propose LithoSeg, a coarse-to-fine network tailored for lithography segmentation. In the coarse stage, we introduce a Human-in-the-Loop Bootstrapping scheme for the Segment Anything Model (SAM) to attain robustness with minimal supervision. In the subsequent fine stage, we recast 2D segmentation as 1D regression problem by sampling groove-normal profiles using the coarse mask and performing point-wise refinement with a lightweight MLP. LithoSeg outperforms previous approaches in both segmentation accuracy and metrology precision while requiring less supervision, offering promising prospects for real-world applications.

</details>


### [38] [Uncertainty-Guided Selective Adaptation Enables Cross-Platform Predictive Fluorescence Microscopy](https://arxiv.org/abs/2511.12006)
*Kai-Wen K. Yang,Andrew Bai,Alexandra Bermudez,Yunqi Hong,Zoe Latham,Iris Sloan,Michael Liu,Vishrut Goyal,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.CV

TL;DR: 通过仅调整早期卷积层并冻结更深层，可以实现可靠的显微镜图像域自适应，并提出了一种名为SIT-ADDA-Auto的自适应框架，该框架利用预测不确定性自动选择适应深度，无需目标标签。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性域自适应方法（如ADDA）在应用于新仪器或采集设置的显微镜图像时，通常需要重新训练整个网络，这可能会破坏已学习的语义表示。然而，本研究提出了一种新的范式，通过仅适应最早的卷积层并冻结更深层来克服这一挑战，从而实现更可靠的迁移。

Method: 提出了一种名为子网络图像转换对抗性域自适应（SIT-ADDA-Auto）的自配置框架。该框架将浅层对抗性对齐与预测不确定性相结合，能够在没有目标标签的情况下自动选择适应深度。通过多指标评估、盲法专家评估和不确定性-深度消融研究来验证其鲁棒性。

Result: SIT-ADDA在曝光和照明变化、跨仪器迁移以及多种染色条件下，相比于完整的编码器适应和非对抗性基线，在重建和下游分割方面均表现出改进。此外，该方法还能减少语义特征的漂移。

Conclusion: 研究结果为显微镜图像的无标签自适应提供了设计原则，并为实际应用场景提供了一种解决方案，其代码已公开可用。

Abstract: Deep learning is transforming microscopy, yet models often fail when applied to images from new instruments or acquisition settings. Conventional adversarial domain adaptation (ADDA) retrains entire networks, often disrupting learned semantic representations. Here, we overturn this paradigm by showing that adapting only the earliest convolutional layers, while freezing deeper layers, yields reliable transfer. Building on this principle, we introduce Subnetwork Image Translation ADDA with automatic depth selection (SIT-ADDA-Auto), a self-configuring framework that integrates shallow-layer adversarial alignment with predictive uncertainty to automatically select adaptation depth without target labels. We demonstrate robustness via multi-metric evaluation, blinded expert assessment, and uncertainty-depth ablations. Across exposure and illumination shifts, cross-instrument transfer, and multiple stains, SIT-ADDA improves reconstruction and downstream segmentation over full-encoder adaptation and non-adversarial baselines, with reduced drift of semantic features. Our results provide a design rule for label-free adaptation in microscopy and a recipe for field settings; the code is publicly available.

</details>


### [39] [LIHE: Linguistic Instance-Split Hyperbolic-Euclidean Framework for Generalized Weakly-Supervised Referring Expression Comprehension](https://arxiv.org/abs/2511.12020)
*Xianglong Shi,Silin Cheng,Sirui Zhao,Yunhan Jiang,Enhong Chen,Yang Liu,Sebastien Ourselin*

Main category: cs.CV

TL;DR: 现有的弱监督指代表达理解（WREC）方法存在一对一映射的局限性，无法处理零个或多个目标的现实场景。为此，我们提出了弱监督广义指代表达理解（WGREC）任务，并引入了LIHE框架来解决这一问题。LIHE通过“Referential Decoupling”预测目标数量并将复杂表达分解为子表达，再通过“Referent Grounding”利用HEMix混合相似性模块进行精确定位，该模块结合了欧几里得距离和双曲几何的优势，有效避免了语义塌陷。LIHE在gRefCOCO和Ref-ZOM上建立了首个有效的弱监督WGREC基线，HEMix在标准REC基准上也取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督指代表达理解（WREC）方法受一对一映射的限制，无法处理零个或多个目标的现实场景。本研究旨在扩展WREC到更实际的WGREC任务，以应对这些挑战。

Method: 提出了一种名为LIHE的两阶段框架。第一阶段“Referential Decoupling”预测目标数量并分解表达。第二阶段“Referent Grounding”使用HEMix混合相似性模块（结合欧几里得距离和双曲几何）进行定位。

Result: LIHE在gRefCOCO和Ref-ZOM上建立了首个有效的弱监督WGREC基线。HEMix在标准REC基准上将IoU@0.5提高了2.5%。

Conclusion: LIHE框架及其HEMix模块能够有效解决弱监督广义指代表达理解中的挑战，并取得了优于现有方法的性能。

Abstract: Existing Weakly-Supervised Referring Expression Comprehension (WREC) methods, while effective, are fundamentally limited by a one-to-one mapping assumption, hindering their ability to handle expressions corresponding to zero or multiple targets in realistic scenarios. To bridge this gap, we introduce the Weakly-Supervised Generalized Referring Expression Comprehension task (WGREC), a more practical paradigm that handles expressions with variable numbers of referents. However, extending WREC to WGREC presents two fundamental challenges: supervisory signal ambiguity, where weak image-level supervision is insufficient for training a model to infer the correct number and identity of referents, and semantic representation collapse, where standard Euclidean similarity forces hierarchically-related concepts into non-discriminative clusters, blurring categorical boundaries. To tackle these challenges, we propose a novel WGREC framework named Linguistic Instance-Split Hyperbolic-Euclidean (LIHE), which operates in two stages. The first stage, Referential Decoupling, predicts the number of target objects and decomposes the complex expression into simpler sub-expressions. The second stage, Referent Grounding, then localizes these sub-expressions using HEMix, our innovative hybrid similarity module that synergistically combines the precise alignment capabilities of Euclidean proximity with the hierarchical modeling strengths of hyperbolic geometry. This hybrid approach effectively prevents semantic collapse while preserving fine-grained distinctions between related concepts. Extensive experiments demonstrate LIHE establishes the first effective weakly supervised WGREC baseline on gRefCOCO and Ref-ZOM, while HEMix achieves consistent improvements on standard REC benchmarks, improving IoU@0.5 by up to 2.5\%. The code is available at https://anonymous.4open.science/r/LIHE.

</details>


### [40] [Null-Space Diffusion Distillation for Efficient Photorealistic Lensless Imaging](https://arxiv.org/abs/2511.12024)
*Jose Reinaldo Cunha Santos A V Silva Neto,Hodaka Kawachi,Yasushi Yagi,Tomoya Nakamura*

Main category: cs.CV

TL;DR: 本研究提出了一种名为NSDD的新方法，用于从透镜成像的测量数据中进行真实感重建，无需配对的透镜/无透镜监督，从而避免了领域不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 传统的透镜相机重建方法依赖于配对的透镜/无透镜监督，这可能导致模型偏差。而现有的无监督扩散先验方法在处理透镜成像的复杂性（噪声大、多路复用、病态）时效果不佳。

Method: NSDD将Range-space约束与Null-space扩散先验更新分离开来。它通过蒸馏迭代DDNM+求解器的Null-space分量来实现，该模型以无透镜测量值和Range-space锚点作为条件。这是一种单通道的学生模型。

Result: NSDD能够保持测量一致性，并生成真实感强的重建结果，且无需配对监督。在Lensless-FFHQ和PhlatCam数据集上，NSDD的运行速度仅次于Wiener方法，感知质量接近DDNM+（LPIPS排名第二），优于DPS和传统的凸优化基线方法。

Conclusion: NSDD为实现快速、无监督、真实感的无透镜成像提供了一条可行的途径。

Abstract: State-of-the-art photorealistic reconstructions for lensless cameras often rely on paired lensless-lensed supervision, which can bias models due to lens-lensless domain mismatch. To avoid this, ground-truth-free diffusion priors are attractive; however, generic formulations tuned for conventional inverse problems often break under the noisy, highly multiplexed, and ill-posed lensless deconvolution setting. We observe that methods which separate range-space enforcement from null-space diffusion-prior updates yield stable, realistic reconstructions. Building on this, we introduce Null-Space Diffusion Distillation (NSDD): a single-pass student that distills the null-space component of an iterative DDNM+ solver, conditioned on the lensless measurement and on a range-space anchor. NSDD preserves measurement consistency and achieves photorealistic results without paired supervision at a fraction of the runtime and memory. On Lensless-FFHQ and PhlatCam, NSDD is the second fastest, behind Wiener, and achieves near-teacher perceptual quality (second-best LPIPS, below DDNM+), outperforming DPS and classical convex baselines. These results suggest a practical path toward fast, ground-truth-free, photorealistic lensless imaging.

</details>


### [41] [Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark](https://arxiv.org/abs/2511.12026)
*Rulin Zhou,Wenlong He,An Wang,Jianhang Zhang,Xuanhui Zeng,Xi Zhang,Chaowei Zhu,Haijun Hu,Hongliang Ren*

Main category: cs.CV

TL;DR: VL-SurgPT是一个包含754个组织追踪和154个器械追踪视频片段的大规模多模态数据集，首次将视觉追踪与点状态的文本描述相结合，旨在解决手术环境中因烟雾遮挡、镜面反射和组织变形等复杂视觉条件造成的点追踪难题。


<details>
  <summary>Details</summary>
Motivation: 现有手术追踪数据集缺乏理解追踪失败机制所需的语义信息，而准确的点追踪在手术环境中至关重要。

Method: 构建了一个包含908个体内视频片段的大规模多模态数据集VL-SurgPT，并提出了一个利用文本描述来提高追踪鲁棒性的新方法TG-SurgPT。

Result: 在八种先进的追踪方法和提出的TG-SurgPT方法上进行了基准测试，结果表明，结合点状态信息可以显著提高追踪的准确性和可靠性，特别是在传统纯视觉方法难以应对的视觉挑战场景中。

Conclusion: VL-SurgPT数据集通过融合视觉和语言模态，为开发能够应对挑战性术中条件的上下文感知追踪系统铺平了道路，这对推进计算机辅助手术应用至关重要。

Abstract: Accurate point tracking in surgical environments remains challenging due to complex visual conditions, including smoke occlusion, specular reflections, and tissue deformation. While existing surgical tracking datasets provide coordinate information, they lack the semantic context necessary to understand tracking failure mechanisms. We introduce VL-SurgPT, the first large-scale multimodal dataset that bridges visual tracking with textual descriptions of point status in surgical scenes. The dataset comprises 908 in vivo video clips, including 754 for tissue tracking (17,171 annotated points across five challenging scenarios) and 154 for instrument tracking (covering seven instrument types with detailed keypoint annotations). We establish comprehensive benchmarks using eight state-of-the-art tracking methods and propose TG-SurgPT, a text-guided tracking approach that leverages semantic descriptions to improve robustness in visually challenging conditions. Experimental results demonstrate that incorporating point status information significantly improves tracking accuracy and reliability, particularly in adverse visual scenarios where conventional vision-only methods struggle. By bridging visual and linguistic modalities, VL-SurgPT enables the development of context-aware tracking systems crucial for advancing computer-assisted surgery applications that can maintain performance even under challenging intraoperative conditions.

</details>


### [42] [GCAgent: Long-Video Understanding via Schematic and Narrative Episodic Memory](https://arxiv.org/abs/2511.12027)
*Jeong Hun Yeo,Sangyun Chung,Sungjune Park,Dae Hoe Kim,Jinyoung Moon,Yong Man Ro*

Main category: cs.CV

TL;DR: GCAgent通过引入结构化记忆（Schematic and Narrative Episodic Memory）解决了长视频理解中的长期依赖问题，并通过感知-行动-反思循环实现了上下文感知推理，在Video-MME长视频理解任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 长视频理解因其固有的token限制和捕捉长期时间依赖的复杂性，对多模态大语言模型（MLLMs）来说仍然是一个重大挑战。现有方法往往无法捕捉深度视频推理所需的全局上下文和复杂事件关系。

Method: 提出GCAgent框架，其核心是“图式与叙事情节记忆”（Schematic and Narrative Episodic Memory），该记忆结构化地将事件及其因果、时间关系建模成简洁、有序的上下文，从根本上解决了长期依赖问题。GCAgent在多阶段的“感知-行动-反思”循环中运行，并利用记忆管理器检索相关情节上下文以进行稳健、上下文感知的推理。

Result: GCAgent在长视频理解方面显著提升了性能，在Video-MME长视频划分任务上相比强大的MLLM基线，准确率提升高达23.5%。该框架在同类7B规模MLLM中也达到了最先进的性能，在Long划分任务上准确率为73.4%，在Video-MME基准测试中整体平均准确率最高（71.9%）。

Conclusion: GCAgent的基于代理的推理范式和结构化记忆在认知启发式长视频理解方面验证了其有效性，显著提高了长视频理解能力。

Abstract: Long-video understanding remains a significant challenge for Multimodal Large Language Models (MLLMs) due to inherent token limitations and the complexity of capturing long-term temporal dependencies. Existing methods often fail to capture the global context and complex event relationships necessary for deep video reasoning. To address this, we introduce GCAgent, a novel Global-Context-Aware Agent framework that achieves comprehensive long-video understanding. Our core innovation is the Schematic and Narrative Episodic Memory. This memory structurally models events and their causal and temporal relations into a concise, organized context, fundamentally resolving the long-term dependency problem. Operating in a multi-stage Perception-Action-Reflection cycle, our GCAgent utilizes a Memory Manager to retrieve relevant episodic context for robust, context-aware inference. Extensive experiments confirm that GCAgent significantly enhances long-video understanding, achieving up to 23.5\% accuracy improvement on the Video-MME Long split over a strong MLLM baseline. Furthermore, our framework establishes state-of-the-art performance among comparable 7B-scale MLLMs, achieving 73.4\% accuracy on the Long split and the highest overall average (71.9\%) on the Video-MME benchmark, validating our agent-based reasoning paradigm and structured memory for cognitively-inspired long-video understanding.

</details>


### [43] [VPHO: Joint Visual-Physical Cue Learning and Aggregation for Hand-Object Pose Estimation](https://arxiv.org/abs/2511.12030)
*Jun Zhou,Chi Xu,Kaifeng Tang,Yuting Ge,Tingrui Guo,Li Cheng*

Main category: cs.CV

TL;DR: 本文提出了一种结合视觉和物理线索的单一RGB图像手部和物体三维姿态估计新框架，通过联合视觉-物理线索学习和候选姿态聚合，有效解决了现有方法存在的物理约束冲突和端到端可训练性问题，并在精度和物理合理性方面均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 估计单一RGB图像中的手部和物体三维姿态是一个基础性但充满挑战的问题，在增强现实和人机交互等领域具有广泛的应用前景。现有方法主要依赖视觉线索，容易产生违反物理约束（如相互穿透或非接触）的结果。

Method: 提出了一种新框架，通过联合视觉和物理线索来估计手部和物体的姿态。具体包括两个关键部分：1）联合视觉-物理线索学习：模型同时提取2D视觉线索和3D物理线索，以实现对手部-物体交互更全面的表征学习；2）候选姿态聚合：利用视觉和物理预测，通过一种新颖的精炼过程聚合多个扩散生成的候选姿态，得到既视觉一致又物理上合理的最终估计。

Result: 实验结果表明，该方法在姿态准确性和物理合理性方面均显著优于现有的最先进方法。

Conclusion: 该框架成功地集成了视觉和物理线索，克服了现有方法的局限性，实现了更准确、更符合物理规律的手部和物体三维姿态估计。

Abstract: Estimating the 3D poses of hands and objects from a single RGB image is a fundamental yet challenging problem, with broad applications in augmented reality and human-computer interaction. Existing methods largely rely on visual cues alone, often producing results that violate physical constraints such as interpenetration or non-contact. Recent efforts to incorporate physics reasoning typically depend on post-optimization or non-differentiable physics engines, which compromise visual consistency and end-to-end trainability. To overcome these limitations, we propose a novel framework that jointly integrates visual and physical cues for hand-object pose estimation. This integration is achieved through two key ideas: 1) joint visual-physical cue learning: The model is trained to extract 2D visual cues and 3D physical cues, thereby enabling more comprehensive representation learning for hand-object interactions; 2) candidate pose aggregation: A novel refinement process that aggregates multiple diffusion-generated candidate poses by leveraging both visual and physical predictions, yielding a final estimate that is visually consistent and physically plausible. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches in both pose accuracy and physical plausibility.

</details>


### [44] [Improved Masked Image Generation with Knowledge-Augmented Token Representations](https://arxiv.org/abs/2511.12032)
*Guotao Liang,Baoquan Zhang,Zhiyuan Wen,Zihao Han,Yunming Ye*

Main category: cs.CV

TL;DR: 通过引入知识图谱增强掩码图像生成，提高了图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有掩码图像生成方法难以仅凭模型自身学习视觉令牌序列中的语义依赖，因为单个令牌缺乏明确的语义含义且序列通常很长。

Method: 提出了一种名为KA-MIG的新颖的知识增强掩码图像生成框架，该框架引入了令牌级语义依赖的显式知识（即从训练数据中提取）作为先验，以学习更丰富的表示来提高性能。具体来说，我们探索并识别了三种有利的令牌知识图谱（即共现图、语义相似性图和位置-令牌不兼容图）。基于三个先验知识图谱，我们设计了一个图感知编码器来学习令牌和位置感知的表示。然后，引入了一个轻量级的融合机制，将这些丰富的表示整合到现有的掩码图像生成方法中。

Result: 实验结果表明，我们的方法在ImageNet上的类别条件图像生成方面优于现有的掩码图像生成方法。

Conclusion: KA-MIG通过利用先验知识图谱，有效增强了模型捕获语义依赖的能力，从而提高了生成质量。

Abstract: Masked image generation (MIG) has demonstrated remarkable efficiency and high-fidelity images by enabling parallel token prediction. Existing methods typically rely solely on the model itself to learn semantic dependencies among visual token sequences. However, directly learning such semantic dependencies from data is challenging because the individual tokens lack clear semantic meanings, and these sequences are usually long. To address this limitation, we propose a novel Knowledge-Augmented Masked Image Generation framework, named KA-MIG, which introduces explicit knowledge of token-level semantic dependencies (\emph{i.e.}, extracted from the training data) as priors to learn richer representations for improving performance. In particular, we explore and identify three types of advantageous token knowledge graphs, including two positive and one negative graphs (\emph{i.e.}, the co-occurrence graph, the semantic similarity graph, and the position-token incompatibility graph). Based on three prior knowledge graphs, we design a graph-aware encoder to learn token and position-aware representations. After that, a lightweight fusion mechanism is introduced to integrate these enriched representations into the existing MIG methods. Resorting to such prior knowledge, our method effectively enhances the model's ability to capture semantic dependencies, leading to improved generation quality. Experimental results demonstrate that our method improves upon existing MIG for class-conditional image generation on ImageNet.

</details>


### [45] [Calibrated Multimodal Representation Learning with Missing Modalities](https://arxiv.org/abs/2511.12034)
*Xiaohao Liu,Xiaobo Xia,Jiaheng Wei,Shuo Yang,Xiu Su,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 为了解决多模态表示学习中普遍存在的模态缺失问题，该研究提出了CalMRL方法，通过校准不完整的对齐来弥补缺失模态的影响，并在理论和实验上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态对齐方法需要所有模态都存在，难以处理普遍存在的模态缺失数据集。

Method: 提出CalMRL方法，从锚点偏移角度分析问题，通过表示层插补缺失模态，并采用双步学习法和共享潜变量后验分布的闭式解进行优化。

Result: CalMRL成功缓解了锚点偏移问题，并具有良好的收敛性。实验证明，该方法能有效处理模态缺失数据，提升了多模态表示学习的灵活性和性能。

Conclusion: CalMRL为处理模态缺失的多模态学习提供了新的解决方案，显著优于现有方法。

Abstract: Multimodal representation learning harmonizes distinct modalities by aligning them into a unified latent space. Recent research generalizes traditional cross-modal alignment to produce enhanced multimodal synergy but requires all modalities to be present for a common instance, making it challenging to utilize prevalent datasets with missing modalities. We provide theoretical insights into this issue from an anchor shift perspective. Observed modalities are aligned with a local anchor that deviates from the optimal one when all modalities are present, resulting in an inevitable shift. To address this, we propose CalMRL for multimodal representation learning to calibrate incomplete alignments caused by missing modalities. Specifically, CalMRL leverages the priors and the inherent connections among modalities to model the imputation for the missing ones at the representation level. To resolve the optimization dilemma, we employ a bi-step learning method with the closed-form solution of the posterior distribution of shared latents. We validate its mitigation of anchor shift and convergence with theoretical guidance. By equipping the calibrated alignment with the existing advanced method, we offer new flexibility to absorb data with missing modalities, which is originally unattainable. Extensive experiments and comprehensive analyses demonstrate the superiority of CalMRL. Our code, model checkpoints, and evaluation raw data will be publicly available.

</details>


### [46] [SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images](https://arxiv.org/abs/2511.12040)
*Xinyuan Hu,Changyue Shi,Chuxiao Yang,Minghao Chen,Jiajun Ding,Tao Wei,Chen Wei,Zhou Yu,Min Tan*

Main category: cs.CV

TL;DR: SRSplat是一个前馈3D重建框架，利用外部参考图像和内部纹理线索来恢复低分辨率输入图像中的精细纹理细节。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从稀疏、低分辨率（LR）图像进行前馈3D重建时，往往无法恢复精细的纹理细节，因为LR输入本身缺乏高频信息。本研究旨在解决此问题。

Method: SRSplat框架首先利用多模态大语言模型（MLLMs）和扩散模型为每个场景生成一个场景特定的参考图库。然后，利用参考引导特征增强（RGFE）模块将LR输入图像及其对应的参考图像的特征进行对齐和融合。接着，训练一个解码器来预测高斯图元。最后，通过纹理感知密度控制（TADC）模块根据LR输入的内部纹理丰富度自适应地调整高斯密度，以进一步优化预测的高斯图元。

Result: 实验结果表明，SRSplat在RealEstate10K、ACID和DTU等数据集上优于现有方法，并表现出强大的跨数据集和跨分辨率泛化能力。

Conclusion: SRSplat通过结合外部参考和内部纹理线索，成功地实现了从稀疏、低分辨率图像进行高质量3D重建，并在多个基准测试中取得了领先的性能。

Abstract: Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

</details>


### [47] [FedSDA: Federated Stain Distribution Alignment for Non-IID Histopathological Image Classification](https://arxiv.org/abs/2511.12044)
*Cheng-Chang Tsai,Kai-Wen Cheng,Chun-Shien Lu*

Main category: cs.CV

TL;DR: FedSDA通过调整客户端数据分布来解决非IID组织病理学图像的联邦学习问题，利用扩散模型和染色分离技术对齐染色分布，有效提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 非IID（非独立同分布）数据是联邦学习（FL）中的一个挑战，尤其是在组织病理学图像中，其特征分布存在偏移。

Method: 提出了一种名为FedSDA（Federated Stain Distribution Alignment）的方法，该方法利用扩散模型和染色分离技术，通过调整所有客户端的数据分布来解决非IID问题，具体做法是对齐各个客户端的染色分布以匹配目标分布，从而减轻分布偏移。为避免在FL中直接训练扩散模型带来的隐私泄露风险，FedSDA在实现对齐的同时规避了该问题。

Result: 实验结果表明，FedSDA不仅能提升那些旨在减轻客户端模型更新差异的基线方法的性能，而且在解决非IID数据问题的角度上优于其他基线方法。

Conclusion: FedSDA为计算病理学领域提供了有价值的实践见解，有效解决了联邦学习中非IID组织病理学图像带来的挑战。

Abstract: Federated learning (FL) has shown success in collaboratively training a model among decentralized data resources without directly sharing privacy-sensitive training data. Despite recent advances, non-IID (non-independent and identically distributed) data poses an inevitable challenge that hinders the use of FL. In this work, we address the issue of non-IID histopathological images with feature distribution shifts from an intuitive perspective that has only received limited attention. Specifically, we address this issue from the perspective of data distribution by solely adjusting the data distributions of all clients. Building on the success of diffusion models in fitting data distributions and leveraging stain separation to extract the pivotal features that are closely related to the non-IID properties of histopathological images, we propose a Federated Stain Distribution Alignment (FedSDA) method. FedSDA aligns the stain distribution of each client with a target distribution in an FL framework to mitigate distribution shifts among clients. Furthermore, considering that training diffusion models on raw data in FL has been shown to be susceptible to privacy leakage risks, we circumvent this problem while still effectively achieving alignment. Extensive experimental results show that FedSDA is not only effective in improving baselines that focus on mitigating disparities across clients' model updates but also outperforms baselines that address the non-IID data issues from the perspective of data distribution. We show that FedSDA provides valuable and practical insights for the computational pathology community.

</details>


### [48] [DCMM-Transformer: Degree-Corrected Mixed-Membership Attention for Medical Imaging](https://arxiv.org/abs/2511.12047)
*Huimin Cheng,Xiaowei Yu,Shushan Wu,Luyang Fang,Chao Cao,Jing Zhang,Tianming Liu,Dajiang Zhu,Wenxuan Zhong,Ping Ma*

Main category: cs.CV

TL;DR: DCMM-Transformer是一种新的ViT架构，用于医学图像分析，通过将度量混合模型（DCMM）作为自注意力中的附加偏置来解决标准ViT无法利用潜在解剖结构的问题。


<details>
  <summary>Details</summary>
Motivation: 标准ViT无法利用医学图像中存在的潜在解剖结构（如器官、组织和病变区域）。

Method: 将度量混合模型（DCMM）作为附加偏置引入自注意力机制，以一种完全可微分且可解释的方式引入社群结构和度量异质性。

Result: 在包括大脑、胸部、乳腺和眼科等多种医学成像数据集上的实验表明，该方法优于现有方法，并具有良好的泛化性。学习到的群组结构和结构化注意力调制通过产生解剖学上有意义且语义上连贯的注意力图，大大增强了可解释性。

Conclusion: DCMM-Transformer在医学图像分析方面表现出优越的性能和可解释性，克服了现有方法的局限性。

Abstract: Medical images exhibit latent anatomical groupings, such as organs, tissues, and pathological regions, that standard Vision Transformers (ViTs) fail to exploit. While recent work like SBM-Transformer attempts to incorporate such structures through stochastic binary masking, they suffer from non-differentiability, training instability, and the inability to model complex community structure. We present DCMM-Transformer, a novel ViT architecture for medical image analysis that incorporates a Degree-Corrected Mixed-Membership (DCMM) model as an additive bias in self-attention. Unlike prior approaches that rely on multiplicative masking and binary sampling, our method introduces community structure and degree heterogeneity in a fully differentiable and interpretable manner. Comprehensive experiments across diverse medical imaging datasets, including brain, chest, breast, and ocular modalities, demonstrate the superior performance and generalizability of the proposed approach. Furthermore, the learned group structure and structured attention modulation substantially enhance interpretability by yielding attention maps that are anatomically meaningful and semantically coherent.

</details>


### [49] [DeiTFake: Deepfake Detection Model using DeiT Multi-Stage Training](https://arxiv.org/abs/2511.12048)
*Saksham Kumar,Ashish Singh,Srinivasarao Thota,Sunil Kumar Singh,Chandan Kumar*

Main category: cs.CV

TL;DR: DeiTFake是一个基于DeiT的Transformer模型，采用两阶段渐进式训练策略，能够有效检测Deepfakes，准确率高达99.22%。


<details>
  <summary>Details</summary>
Motivation: Deepfakes对数字媒体的完整性构成了重大威胁，需要有效的检测方法。

Method: 提出了一种基于DeiT的Transformer模型（DeiTFake），并采用了一种新颖的两阶段渐进式训练策略，逐步增加数据增强的复杂度。第一阶段使用标准的迁移学习和数据增强，第二阶段在此基础上进行微调，并加入更高级的仿射变换和Deepfake特定数据增强。DeiT的知识蒸馏模型能够捕捉到细微的篡改痕迹，提高了检测模型的鲁棒性。

Result: 在OpenForensics数据集（190,335张图像）上训练后，DeiTFake在第一阶段达到了98.71%的准确率，在第二阶段达到了99.22%的准确率，AUROC值为0.9997，优于最新的OpenForensics基线模型。对数据增强和训练计划的影响进行了分析，并提供了面部Deepfake检测的实用基准。

Conclusion: DeiTFake通过其两阶段渐进式训练策略和DeiT的知识蒸馏能力，在Deepfake检测方面取得了优异的性能，并且通过分析验证了其方法的有效性。

Abstract: Deepfakes are major threats to the integrity of digital media. We propose DeiTFake, a DeiT-based transformer and a novel two-stage progressive training strategy with increasing augmentation complexity. The approach applies an initial transfer-learning phase with standard augmentations followed by a fine-tuning phase using advanced affine and deepfake-specific augmentations. DeiT's knowledge distillation model captures subtle manipulation artifacts, increasing robustness of the detection model. Trained on the OpenForensics dataset (190,335 images), DeiTFake achieves 98.71\% accuracy after stage one and 99.22\% accuracy with an AUROC of 0.9997, after stage two, outperforming the latest OpenForensics baselines. We analyze augmentation impact and training schedules, and provide practical benchmarks for facial deepfake detection.

</details>


### [50] [UniABG: Unified Adversarial View Bridging and Graph Correspondence for Unsupervised Cross-View Geo-Localization](https://arxiv.org/abs/2511.12054)
*Cuiqun Chen,Qi Chen,Bin Yang,Xingyi Zhang*

Main category: cs.CV

TL;DR: UniABG是一个新颖的无监督跨视图地理定位框架，通过对抗性视图桥接和基于图的对应校准来提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的监督方法需要大量标注数据，而无监督方法则存在伪标签噪声问题。UniABG旨在解决这些局限性。

Method: 该框架包括两个阶段：1. 视图感知对抗桥接（VAAB），用于学习视图不变特征并增强伪标签。 2. 异构图过滤校准（HGFC），通过构建双视角结构图来优化跨视图关联。

Result: 在University-1652和SUES-200数据集上，UniABG的无监督性能达到了最先进水平，并将Satellite→Drone的AP分别提高了+10.63%和+16.73%，甚至超过了监督基线。

Conclusion: UniABG通过结合对抗性视图桥接和图卷积网络，有效地解决了无监督跨视图地理定位中的挑战，并在多个数据集上取得了优越的性能。

Abstract: Cross-view geo-localization (CVGL) matches query images ($\textit{e.g.}$, drone) to geographically corresponding opposite-view imagery ($\textit{e.g.}$, satellite). While supervised methods achieve strong performance, their reliance on extensive pairwise annotations limits scalability. Unsupervised alternatives avoid annotation costs but suffer from noisy pseudo-labels due to intrinsic cross-view domain gaps. To address these limitations, we propose $\textit{UniABG}$, a novel dual-stage unsupervised cross-view geo-localization framework integrating adversarial view bridging with graph-based correspondence calibration. Our approach first employs View-Aware Adversarial Bridging (VAAB) to model view-invariant features and enhance pseudo-label robustness. Subsequently, Heterogeneous Graph Filtering Calibration (HGFC) refines cross-view associations by constructing dual inter-view structure graphs, achieving reliable view correspondence. Extensive experiments demonstrate state-of-the-art unsupervised performance, showing that UniABG improves Satellite $\rightarrow$ Drone AP by +10.63\% on University-1652 and +16.73\% on SUES-200, even surpassing supervised baselines. The source code is available at https://github.com/chenqi142/UniABG

</details>


### [51] [PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling](https://arxiv.org/abs/2511.12056)
*Sijie Wang,Qiang Wang,Shaohuai Shi*

Main category: cs.CV

TL;DR: 提出了一种名为PipeDiT的新型流水线框架，通过序列并行（PipeSP）、解耦扩散与VAE模块（DeDiVAE）以及注意力协同处理（Aco）等技术，显著加速了基于DiT的视频生成，并降低了内存消耗，在实际应用中取得了1.06x至4.02x的加速效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于DiT的视频生成模型存在推理速度慢和内存消耗高的问题，限制了其实际应用。

Method: 设计了用于序列并行的流水线算法PipeSP，实现了潜变量生成和多GPU通信的流水线化；提出了DeDiVAE，将扩散模块和VAE模块分离到不同的GPU组并进行流水线执行，以减少内存和延迟；提出了注意力协同处理（Aco）方法，以进一步优化VAE组的GPU资源利用并降低整体延迟。

Result: 将PipeDiT集成到OpenSoraPlan和HunyuanVideo中，在8-GPU系统上进行了广泛实验。结果表明，在多种分辨率和时间步配置下，PipeDiT相比OpenSoraPlan和HunyuanVideo实现了1.06x至4.02x的加速。

Conclusion: PipeDiT通过创新的流水线技术有效解决了DiT模型在视频生成中的性能瓶颈，显著提高了生成速度和资源利用率。

Abstract: Video generation has been advancing rapidly, and diffusion transformer (DiT) based models have demonstrated remark- able capabilities. However, their practical deployment is of- ten hindered by slow inference speeds and high memory con- sumption. In this paper, we propose a novel pipelining frame- work named PipeDiT to accelerate video generation, which is equipped with three main innovations. First, we design a pipelining algorithm (PipeSP) for sequence parallelism (SP) to enable the computation of latent generation and commu- nication among multiple GPUs to be pipelined, thus reduc- ing inference latency. Second, we propose DeDiVAE to de- couple the diffusion module and the variational autoencoder (VAE) module into two GPU groups, whose executions can also be pipelined to reduce memory consumption and infer- ence latency. Third, to better utilize the GPU resources in the VAE group, we propose an attention co-processing (Aco) method to further reduce the overall video generation latency. We integrate our PipeDiT into both OpenSoraPlan and Hun- yuanVideo, two state-of-the-art open-source video generation frameworks, and conduct extensive experiments on two 8- GPU systems. Experimental results show that, under many common resolution and timestep configurations, our PipeDiT achieves 1.06x to 4.02x speedups over OpenSoraPlan and HunyuanVideo.

</details>


### [52] [MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity](https://arxiv.org/abs/2511.12061)
*Zhichen Lai,Hua Lu,Huan Li,Jialiang Li,Christian S. Jensen*

Main category: cs.CV

TL;DR: MovSemCL是一个用于轨迹相似性计算的移动语义对比学习框架，解决了现有方法的局限性，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的轨迹相似性计算方法在轨迹语义和层级建模、计算成本以及数据增强的物理合理性方面存在不足。

Method: MovSemCL将原始GPS轨迹转换为移动语义特征，并进行分块。利用内部和跨块注意力机制对局部和全局轨迹模式进行编码，实现高效的层级表示并降低计算成本。采用曲率引导的数据增强策略，保留关键转弯和交叉路口等信息丰富的片段，并掩码冗余片段，生成物理上合理的增强视图。

Result: MovSemCL在真实世界数据集上的实验结果表明，其在相似性搜索任务上的表现优于现有最先进的方法，平均排名接近理想值1，在启发式近似方面有高达20.3%的提升，同时推理延迟降低了高达43.4%。

Conclusion: MovSemCL通过引入移动语义、层级表示和曲率引导增强，有效解决了现有方法的局限性，在轨迹相似性计算方面取得了显著的性能提升和效率改进。

Abstract: Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.

</details>


### [53] [DCA-LUT: Deep Chromatic Alignment with 5D LUT for Purple Fringing Removal](https://arxiv.org/abs/2511.12066)
*Jialang Lu,Shuning Sun,Pu Wang,Chen Wu,Feng Gao,Lina Gong,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: DCA-LUT 是第一个用于去除紫色条纹的深度学习框架，通过 CA-CT 模块学习图像自适应颜色空间，分离并学习“紫色条纹通道”，然后使用学习到的 5D LUT 进行颜色校正。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖昂贵的 APO 镜头硬件和手工提取的特征，忽略了数据驱动的方法来解决相机镜头中由纵向色差 (LCA) 引起的紫色条纹问题。

Method: 提出了一种新颖的色差感知坐标变换 (CA-CT) 模块，该模块学习图像自适应颜色空间以分离和隔离条纹，然后学习一个精确的“紫色条纹通道”来指导亮度通道的精确恢复，最后通过学习到的 5D LUT 进行颜色校正。

Result: 在合成和真实世界的数据集上进行了广泛的实验，表明该方法在去除紫色条纹方面取得了最先进的性能。

Conclusion: DCA-LUT 框架通过新颖的 CA-CT 模块和 5D LUT 实现了高效、强大的非线性颜色映射，能够有效地去除紫色条纹，并达到了最先进的性能。

Abstract: Purple fringing, a persistent artifact caused by Longitudinal Chromatic Aberration (LCA) in camera lenses, has long degraded the clarity and realism of digital imaging. Traditional solutions rely on complex and expensive apochromatic (APO) lens hardware and the extraction of handcrafted features, ignoring the data-driven approach. To fill this gap, we introduce DCA-LUT, the first deep learning framework for purple fringing removal. Inspired by the physical root of the problem, the spatial misalignment of RGB color channels due to lens dispersion, we introduce a novel Chromatic-Aware Coordinate Transformation (CA-CT) module, learning an image-adaptive color space to decouple and isolate fringing into a dedicated dimension. This targeted separation allows the network to learn a precise ``purple fringe channel", which then guides the accurate restoration of the luminance channel. The final color correction is performed by a learned 5D Look-Up Table (5D LUT), enabling efficient and powerful% non-linear color mapping. To enable robust training and fair evaluation, we constructed a large-scale synthetic purple fringing dataset (PF-Synth). Extensive experiments in synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance in purple fringing removal.

</details>


### [54] [Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound](https://arxiv.org/abs/2511.12077)
*Dengming Zhang,Weitao You,Jingxiong Li,Weishen Lin,Wenda Shi,Xue Zhao,Heda Zuo,Junxian Wu,Lingyun Sun*

Main category: cs.CV

TL;DR: VAEmotionLLM是一个两阶段框架，通过有限的音频预训练教会视觉语言模型（VLM）“看”以“听”，并理解跨模态的情感。它在ArtEmoBenchmark上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 情绪理解对于使大型语言模型（LLM）更加通用、可靠和符合人类期望至关重要。艺术通过视觉和听觉元素的联合设计来传达情感，但以往的工作要么以人为中心，要么是单模态的，忽略了艺术品所表达的情感。此外，当前的视听语言模型（AVLMs）通常需要大规模的音频预训练，这限制了可扩展性。

Method: VAEmotionLLM是一个两阶段框架。第一阶段，视觉引导音频对齐（VG-Align）通过对齐同步音视频片段上共享LLM的下一个词元分布，将冻结的视觉通路提炼到新的音频通路中，从而在没有大型音频数据集的情况下实现“听”的能力。第二阶段，轻量级的跨模态情感适配器（EmoAdapter），由情感增强器和情感监督器组成，注入情感敏感的残差并应用情感监督来增强跨模态情感理解。此外，还构建了ArtEmoBenchmark，这是一个以艺术为中心的基准，用于评估在仅音频、仅视觉和视听输入下的内容和情感理解。

Result: VAEmotionLLM在ArtEmoBenchmark上取得了最先进的成果，在仅音频、仅视觉和视听基线方面均表现优异。消融实验表明，所提出的组件是互补的。

Conclusion: VAEmotionLLM通过新颖的VG-Align和EmoAdapter模块，有效地实现了在有限音频预训练下视听情感理解，并在ArtEmoBenchmark上取得了优异表现。

Abstract: Emotion understanding is critical for making Large Language Models (LLMs) more general, reliable, and aligned with humans. Art conveys emotion through the joint design of visual and auditory elements, yet most prior work is human-centered or single-modality, overlooking the emotion intentionally expressed by the artwork. Meanwhile, current Audio-Visual Language Models (AVLMs) typically require large-scale audio pretraining to endow Visual Language Models (VLMs) with hearing, which limits scalability. We present Vision Anchored Audio-Visual Emotion LLM (VAEmotionLLM), a two-stage framework that teaches a VLM to hear by seeing with limited audio pretraining and to understand emotion across modalities. In Stage 1, Vision-Guided Audio Alignment (VG-Align) distills the frozen visual pathway into a new audio pathway by aligning next-token distributions of the shared LLM on synchronized audio-video clips, enabling hearing without a large audio dataset. In Stage 2, a lightweight Cross-Modal Emotion Adapter (EmoAdapter), composed of the Emotion Enhancer and the Emotion Supervisor, injects emotion-sensitive residuals and applies emotion supervision to enhance cross-modal emotion understanding. We also construct ArtEmoBenchmark, an art-centric emotion benchmark that evaluates content and emotion understanding under audio-only, visual-only, and audio-visual inputs. VAEmotionLLM achieves state-of-the-art results on ArtEmoBenchmark, outperforming audio-only, visual-only, and audio-visual baselines. Ablations show that the proposed components are complementary.

</details>


### [55] [Point Cloud Quantization through Multimodal Prompting for 3D Understanding](https://arxiv.org/abs/2511.12079)
*Hongxuan Li,Wencheng Zhu,Huiying Xu,Xinzhong Zhu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的、基于多模态提示的矢量量化框架，用于点云分析，解决了现有基于原型的方法在代表性和可解释性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于原型的方法（例如，可训练向量或聚类质心）在代表性和可解释性方面存在不足，而多模态对齐在视觉-语言模型中显示出了潜力。本文旨在解决这些限制。

Method: 提出了一种基于多模态提示的矢量量化框架。利用预训练模型的文本嵌入作为原型先验，并通过多模态提示自适应地优化这些原型，以弥合视觉-语言语义鸿沟。框架采用双约束量化空间（紧凑性和分离性正则化），并使用 Gumbel-Softmax 技巧实现可微分离散化。

Result: 所提出的方法在 ModelNet40 和 ScanObjectNN 数据集上进行了广泛的实验评估，结果表明其优越性。

Conclusion: 所提出的多模态提示驱动的量化框架能够有效地融合视觉和原型特征，生成同时编码几何和语义信息的混合表示，并在点云分析任务中取得优异性能。

Abstract: Vector quantization has emerged as a powerful tool in large-scale multimodal models, unifying heterogeneous representations through discrete token encoding. However, its effectiveness hinges on robust codebook design. Current prototype-based approaches relying on trainable vectors or clustered centroids fall short in representativeness and interpretability, even as multimodal alignment demonstrates its promise in vision-language models. To address these limitations, we propose a simple multimodal prompting-driven quantization framework for point cloud analysis. Our methodology is built upon two core insights: 1) Text embeddings from pre-trained models inherently encode visual semantics through many-to-one contrastive alignment, naturally serving as robust prototype priors; and 2) Multimodal prompts enable adaptive refinement of these prototypes, effectively mitigating vision-language semantic gaps. The framework introduces a dual-constrained quantization space, enforced by compactness and separation regularization, which seamlessly integrates visual and prototype features, resulting in hybrid representations that jointly encode geometric and semantic information. Furthermore, we employ Gumbel-Softmax relaxation to achieve differentiable discretization while maintaining quantization sparsity. Extensive experiments on the ModelNet40 and ScanObjectNN datasets clearly demonstrate the superior effectiveness of the proposed method.

</details>


### [56] [Supervised Multilabel Image Classification Using Residual Networks with Probabilistic Reasoning](https://arxiv.org/abs/2511.12082)
*Lokender Singh,Saksham Kumar,Chandan Kumar*

Main category: cs.CV

TL;DR: 该研究提出了一种使用概率推理的改进ResNet-101模型用于多标签图像分类，在COCO-2014数据集上取得了0.794 mAP的性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于其在计算机视觉中的广泛应用，多标签图像分类引起了广泛关注。

Method: 提出了一种使用概率推理、模拟标签依赖和不确定性来改进预测精度的方法，并使用修改后的ResNet-101架构。

Result: 在COCO-2014数据集上，该模型取得了0.794 mAP的成绩，优于ResNet-SRN（0.771）和Vision Transformer基线（0.785）。

Conclusion: 该研究通过将概率推理集成到深度学习模型中，有效解决了多标签场景的挑战，并在多标签图像分类任务上取得了最先进的成果。

Abstract: Multilabel image categorization has drawn interest recently because of its numerous computer vision applications. The proposed work introduces a novel method for classifying multilabel images using the COCO-2014 dataset and a modified ResNet-101 architecture. By simulating label dependencies and uncertainties, the approach uses probabilistic reasoning to improve prediction accuracy. Extensive tests show that the model outperforms earlier techniques and approaches to state-of-the-art outcomes in multilabel categorization. The work also thoroughly assesses the model's performance using metrics like precision-recall score and achieves 0.794 mAP on COCO-2014, outperforming ResNet-SRN (0.771) and Vision Transformer baselines (0.785). The novelty of the work lies in integrating probabilistic reasoning into deep learning models to effectively address the challenges presented by multilabel scenarios.

</details>


### [57] [SemanticStitch: Enhancing Image Coherence through Foreground-Aware Seam Carving](https://arxiv.org/abs/2511.12084)
*Ji-Ping Jin,Chen-Bin Feng,Rui Fan,Chi-Man Vong*

Main category: cs.CV

TL;DR: 我们提出了SemanticStitch，一个结合了语义信息和深度学习的图像拼接框架，解决了传统方法中因视角、位置和物体移动导致的对齐问题和视觉不一致性。


<details>
  <summary>Details</summary>
Motivation: 传统图像拼接方法忽略了语义信息，导致前景的连续性被破坏。本研究旨在通过引入语义先验来解决这个问题。

Method: 我们提出了一个名为SemanticStitch的深度学习框架，该框架利用前景对象的语义先验来保持其完整性并增强视觉连贯性。我们还开发了一种新的损失函数，以强调显著对象的前景完整性。

Result: 与传统技术相比，我们提出的方法在实验中显示出显著的改进，并且在两个专门构建的真实世界数据集上进行了评估。

Conclusion: SemanticStitch通过结合语义信息显著提高了图像拼接的质量，为实际应用提供了有力的支持。

Abstract: Image stitching often faces challenges due to varying capture angles, positional differences, and object movements, leading to misalignments and visual discrepancies. Traditional seam carving methods neglect semantic information, causing disruptions in foreground continuity. We introduce SemanticStitch, a deep learning-based framework that incorporates semantic priors of foreground objects to preserve their integrity and enhance visual coherence. Our approach includes a novel loss function that emphasizes the semantic integrity of salient objects, significantly improving stitching quality. We also present two specialized real-world datasets to evaluate our method's effectiveness. Experimental results demonstrate substantial improvements over traditional techniques, providing robust support for practical applications.

</details>


### [58] [Teaching Prompts to Coordinate: Hierarchical Layer-Grouped Prompt Tuning for Continual Learning](https://arxiv.org/abs/2511.12090)
*Shengqin Jiang,Tianqi Kong,Yuankai Qi,Haokui Zhang,Lina Yao,Quan Z. Sheng,Qingshan Liu,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: Prompt-based continual learning methods freeze pre-trained models and fine-tune task-specific prompts. While effective, independent prompts per layer can lead to catastrophic forgetting due to overly flexible tuning. This paper proposes a hierarchical layer-grouped prompt tuning method that shares prompts within layer groups (adjusted by position encoding) and uses a root prompt to generate sub-prompts, enhancing stability and reducing forgetting. Experiments show favorable performance.


<details>
  <summary>Details</summary>
Motivation: Existing prompt-based continual learning methods fine-tune independent prompts per layer, which, despite offering flexibility, can lead to overly adaptable layers and catastrophic forgetting by overwriting essential features of previous tasks. The goal is to improve model stability and mitigate this risk.

Method: The proposed method is a hierarchical layer-grouped prompt tuning approach. It works by (i) making layers within the same group share prompts adjusted by position encoding to preserve pre-trained model's intrinsic feature relationships and propagation pathways, and (ii) using a single task-specific root prompt to generate sub-prompts for each layer group, enhancing prompt synergy and reducing their independence.

Result: Extensive experiments were conducted across four benchmarks. The proposed hierarchical layer-grouped prompt tuning method achieved favorable performance compared to several state-of-the-art methods.

Conclusion: The proposed hierarchical layer-grouped prompt tuning method effectively improves model stability in continual learning by preserving intrinsic feature relationships and reducing prompt independence, thereby mitigating catastrophic forgetting and achieving competitive performance.

Abstract: Prompt-based continual learning methods fine-tune only a small set of additional learnable parameters while keeping the pre-trained model's parameters frozen. It enables efficient adaptation to new tasks while mitigating the risk of catastrophic forgetting. These methods typically attach one independent task-specific prompt to each layer of pre-trained models to locally modulate its features, ensuring that the layer's representation aligns with the requirements of the new task. However, although introducing learnable prompts independently at each layer provides high flexibility for adapting to new tasks, this overly flexible tuning could make certain layers susceptible to unnecessary updates. As all prompts till the current task are added together as a final prompt for all seen tasks, the model may easily overwrite feature representations essential to previous tasks, which increases the risk of catastrophic forgetting. To address this issue, we propose a novel hierarchical layer-grouped prompt tuning method for continual learning. It improves model stability in two ways: (i) Layers in the same group share roughly the same prompts, which are adjusted by position encoding. This helps preserve the intrinsic feature relationships and propagation pathways of the pre-trained model within each group. (ii) It utilizes a single task-specific root prompt to learn to generate sub-prompts for each layer group. In this way, all sub-prompts are conditioned on the same root prompt, enhancing their synergy and reducing independence. Extensive experiments across four benchmarks demonstrate that our method achieves favorable performance compared with several state-of-the-art methods.

</details>


### [59] [Learning from Dense Events: Towards Fast Spiking Neural Networks Training via Event Dataset Distillatio](https://arxiv.org/abs/2511.12095)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Kun Wang,Xudong Jiang*

Main category: cs.CV

TL;DR: PACE是一个针对事件相机和脉冲神经网络（SNN）的首次数据集蒸馏框架，通过ST-DSM和PEQ-N模块，将大型训练数据集压缩成小型合成数据集，从而实现快速SNN训练，并显著降低了训练时间和存储成本。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其仿生动力学特性而备受关注，与脉冲神经网络（SNN）的结合为传统视觉系统提供了节能的替代方案。然而，SNN的训练成本高昂，限制了其广泛应用。本研究旨在降低SNN的训练成本。

Method: PACE框架包含两个核心模块：ST-DSM（空间时间-事件数据流内存）和PEQ-N（概率整数量化器）。ST-DSM利用残余膜电位增强事件基特征（SDR），并进行精细的时空幅度-相位匹配（ST-SM）。PEQ-N提供了一个即插即用的直通式概率整数量化器，可兼容标准的事件帧处理流程。

Result: 在DVS-Gesture、CIFAR10-DVS和N-MNIST数据集上，PACE的表现优于现有的数据集核心选择和数据集蒸馏基线方法。尤其在动态事件流和低/中等IPC（每秒事件数）设置下，PACE取得了显著的性能提升。例如，在N-MNIST数据集上，PACE达到了84.4%的准确率，接近完整训练集性能的85%，同时训练时间缩短了50倍以上，存储成本降低了6000倍，实现了分钟级SNN训练和高效的边缘部署。

Conclusion: PACE是首个用于SNN和事件视觉的数据集蒸馏框架，通过其创新的ST-DSM和PEQ-N模块，能够有效地压缩数据集，实现快速的SNN训练，并大幅降低训练时间和存储成本，为SNN在资源受限的边缘设备上的部署提供了可行方案。

Abstract: Event cameras sense brightness changes and output binary asynchronous event streams, attracting increasing attention. Their bio-inspired dynamics align well with spiking neural networks (SNNs), offering a promising energy-efficient alternative to conventional vision systems. However, SNNs remain costly to train due to temporal coding, which limits their practical deployment. To alleviate the high training cost of SNNs, we introduce \textbf{PACE} (Phase-Aligned Condensation for Events), the first dataset distillation framework to SNNs and event-based vision. PACE distills a large training dataset into a compact synthetic one that enables fast SNN training, which is achieved by two core modules: \textbf{ST-DSM} and \textbf{PEQ-N}. ST-DSM uses residual membrane potentials to densify spike-based features (SDR) and to perform fine-grained spatiotemporal matching of amplitude and phase (ST-SM), while PEQ-N provides a plug-and-play straight through probabilistic integer quantizer compatible with standard event-frame pipelines. Across DVS-Gesture, CIFAR10-DVS, and N-MNIST datasets, PACE outperforms existing coreset selection and dataset distillation baselines, with particularly strong gains on dynamic event streams and at low or moderate IPC. Specifically, on N-MNIST, it achieves \(84.4\%\) accuracy, about \(85\%\) of the full training set performance, while reducing training time by more than \(50\times\) and storage cost by \(6000\times\), yielding compact surrogates that enable minute-scale SNN training and efficient edge deployment.

</details>


### [60] [Sparse by Rule: Probability-Based N:M Pruning for Spiking Neural Networks](https://arxiv.org/abs/2511.12097)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Xudong Jiang,Dacheng Tao*

Main category: cs.CV

TL;DR: SpikeNM是一种新的SNN剪枝框架，可以从头开始学习稀疏SNN，实现高稀疏度和硬件可加速性。


<details>
  <summary>Details</summary>
Motivation: 现有的SNN剪枝方法要么难以在通用硬件上加速，要么在匹配的稀疏度下准确率下降。需要一种能够实现高稀疏度且易于部署的SNN剪枝方法。

Method: SpikeNM是一种半结构化N:M剪枝框架，采用M路基数-logit参数化和可微分top-k采样器，将每块的复杂度线性化到O(M)，并引入了受神经科学启发的“合格性启发蒸馏”（EID）来稳定搜索过程。

Result: 在2:4稀疏度下，SpikeNM在准确率上与现有方法相当甚至有所提升，并生成了易于硬件加速的稀疏模式。

Conclusion: SpikeNM是一种有效的SNN半结构化剪枝框架，能够实现高稀疏度、硬件可加速性和良好的准确率，为SNN在边缘设备的部署提供了新的解决方案。

Abstract: Brain-inspired Spiking neural networks (SNNs) promise energy-efficient intelligence via event-driven, sparse computation, but deeper architectures inflate parameters and computational cost, hindering their edge deployment. Recent progress in SNN pruning helps alleviate this burden, yet existing efforts fall into only two families: \emph{unstructured} pruning, which attains high sparsity but is difficult to accelerate on general hardware, and \emph{structured} pruning, which eases deployment but lack flexibility and often degrades accuracy at matched sparsity. In this work, we introduce \textbf{SpikeNM}, the first SNN-oriented \emph{semi-structured} \(N{:}M\) pruning framework that learns sparse SNNs \emph{from scratch}, enforcing \emph{at most \(N\)} non-zeros per \(M\)-weight block. To avoid the combinatorial space complexity \(\sum_{k=1}^{N}\binom{M}{k}\) growing exponentially with \(M\), SpikeNM adopts an \(M\)-way basis-logit parameterization with a differentiable top-\(k\) sampler, \emph{linearizing} per-block complexity to \(\mathcal O(M)\) and enabling more aggressive sparsification. Further inspired by neuroscience, we propose \emph{eligibility-inspired distillation} (EID), which converts temporally accumulated credits into block-wise soft targets to align mask probabilities with spiking dynamics, reducing sampling variance and stabilizing search under high sparsity. Experiments show that at \(2{:}4\) sparsity, SpikeNM maintains and even with gains across main-stream datasets, while yielding hardware-amenable patterns that complement intrinsic spike sparsity.

</details>


### [61] [DINOv3-Guided Cross Fusion Framework for Semantic-aware CT generation from MRI and CBCT](https://arxiv.org/abs/2511.12098)
*Xianhao Zhou,Jianghao Wu,Ku Zhao,Jinlong He,Huangxuan Zhao,Lei Chen,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: DGCF框架通过结合DINOv3 Transformer和CNN，在医学图像翻译任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的模型缺乏全局语义理解，而Transformer容易在小型医学数据集上过拟合。本研究提出了一种新的框架来解决这些限制。

Method: 提出了一种DINOv3-Guided Cross Fusion (DGCF)框架，该框架整合了一个冻结的自监督DINOv3 Transformer和一个可训练的CNN编码器-解码器。通过一个可学习的交叉融合模块，分层融合了Transformer的全局表示和CNN的局部特征，实现了局部外观和上下文表示的平衡。此外，还引入了一种多层次DINOv3感知(MLDP)损失，以鼓励在DINOv3特征空间中合成CT与真实CT之间的语义相似性。

Result: 在SynthRAD2023盆腔数据集的MRI→CT和CBCT→CT翻译任务中，DGCF在MS-SSIM、PSNR和基于分割的指标方面取得了最先进的性能。

Conclusion: DGCF框架成功地利用了DINOv3表示来进行医学图像翻译，证明了自监督Transformer在语义感知CT合成中的潜力。

Abstract: Generating synthetic CT images from CBCT or MRI has a potential for efficient radiation dose planning and adaptive radiotherapy. However, existing CNN-based models lack global semantic understanding, while Transformers often overfit small medical datasets due to high model capacity and weak inductive bias. To address these limitations, we propose a DINOv3-Guided Cross Fusion (DGCF) framework that integrates a frozen self-supervised DINOv3 Transformer with a trainable CNN encoder-decoder. It hierarchically fuses global representation of Transformer and local features of CNN via a learnable cross fusion module, achieving balanced local appearance and contextual representation. Furthermore, we introduce a Multi-Level DINOv3 Perceptual (MLDP) loss that encourages semantic similarity between synthetic CT and the ground truth in DINOv3's feature space. Experiments on the SynthRAD2023 pelvic dataset demonstrate that DGCF achieved state-of-the-art performance in terms of MS-SSIM, PSNR and segmentation-based metrics on both MRI$\rightarrow$CT and CBCT$\rightarrow$CT translation tasks. To the best of our knowledge, this is the first work to employ DINOv3 representations for medical image translation, highlighting the potential of self-supervised Transformer guidance for semantic-aware CT synthesis. The code is available at https://github.com/HiLab-git/DGCF.

</details>


### [62] [Adaptive Begin-of-Video Tokens for Autoregressive Video Diffusion Models](https://arxiv.org/abs/2511.12099)
*Tianle Cheng,Zeyan Zhang,Kaifeng Gao,Jun Xiao*

Main category: cs.CV

TL;DR: VDMs通过自回归方式生成长视频，现有方法存在延迟、误差累积、脆弱一致性及运动动态差等问题。本文提出Ada-BOV（Adaptive Begin-of-Video Tokens）来提升长视频生成质量，通过自适应地吸收先前帧来保持全局一致性，同时通过流式去噪的改进来增强局部动态和整体成像质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型（VDMs）在生成长视频时面临自回归的挑战，如延迟、误差累积、脆弱的一致性以及运动动态不佳。本研究旨在解决这些问题，以生成更高质量、更连贯的长视频。

Method: 提出Ada-BOV（Adaptive Begin-of-Video Tokens）机制，通过特殊的学习嵌入自适应地吸收先前去噪的帧，以保持全局一致性并允许在动态场景中灵活调整。同时，改进流式去噪策略，解耦采样轨迹长度与注意力窗口大小的限制，以提升局部动态和整体成像质量。此外，引入扰动增强训练噪声调度，以平衡收敛速度和模型鲁棒性。

Result: 在多个评估指标上，本文提出的方法在定性和定量评估中均取得了优越的结果，证明了其在生成长视频方面的有效性。

Conclusion: Ada-BOV 和改进的流式去噪策略能够有效克服现有自回归VDMs的局限性，显著提高长视频生成的全局一致性、局部动态和整体质量。

Abstract: Recent advancements in diffusion-based video generation have produced impressive and high-fidelity short videos. To extend these successes to generate coherent long videos, most video diffusion models (VDMs) generate videos in an autoregressive manner, i.e., generating subsequent frames conditioned on previous ones. There are generally two primary paradigms: chunk-based extension and stream denoising. The former directly concatenates previous clean frames as conditioning, suffering from denoising latency and error accumulation. The latter maintains the denoising sequence with monotonically increasing noise levels. In each denoising iteration, one clean frame is produced while a new pure noise is simultaneously appended, enabling live-stream sampling. However, it struggles with fragile consistency and poor motion dynamics. In this paper, we propose Adaptive Begin-of-Video Tokens (ada-BOV) for autoregressive VDMs. The BOV tokens are special learnable embeddings on VDMs. They adaptively absorb denoised preceding frames via an adaptive-layer-norm-like modulation. This design preserves the global consistency while allowing for flexible conditioning in dynamic scenarios. To ensure the quality of local dynamics essential in modulating BOV tokens, we further propose a refinement strategy for stream denoising. It decouples the sampling trajectory length from the attention window size constraint, leading to improved local guidance and overall imaging quality. We also propose a disturbance-augmented training noise schedule, which balances the convergence speed with model robustness for the stream denoising. Extensive experiments demonstrate that our method achieves compelling qualitative and quantitative results across multiple metrics.

</details>


### [63] [Did Models Sufficient Learn? Attribution-Guided Training via Subset-Selected Counterfactual Augmentation](https://arxiv.org/abs/2511.12100)
*Yannan Chen,Ruoyu Chen,Bin Zeng,Wei Wang,Shiming Liu,Qunli Zhang,Zheng Hu,Laiyuan Wang,Yaowei Wang,Xiaochun Cao*

Main category: cs.CV

TL;DR: 当前模型训练依赖的因果线索不足，导致泛化能力差。提出SS-CA方法，结合LIMA归因和数据增强，通过移除关键区域并替换为背景来训练模型，提升模型在ID和OOD数据上的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型训练依赖的因果线索不足，导致模型对分布变化敏感，且属性方法生成的反事实样本无法有效提高模型泛化能力。

Method: 提出SS-CA方法，首先利用Counterfactual LIMA识别最小的、移除后可以改变模型预测的空间区域集合，然后将这些区域替换为自然背景作为数据增强，最后将增强后的样本与原始样本一起训练模型。

Result: SS-CA方法在多个ImageNet变体上进行实验，证明该方法在ID测试数据上提高了泛化能力，并在ImageNet-R和ImageNet-S等OOD基准上取得了优越的性能。在噪声等扰动下，SS-CA训练的模型也表现出更强的泛化能力。

Conclusion: SS-CA方法能有效利用可解释性洞察来纠正模型的不足，提高模型的性能和鲁棒性。

Abstract: In current visual model training, models often rely on only limited sufficient causes for their predictions, which makes them sensitive to distribution shifts or the absence of key features. Attribution methods can accurately identify a model's critical regions. However, masking these areas to create counterfactuals often causes the model to misclassify the target, while humans can still easily recognize it. This divergence highlights that the model's learned dependencies may not be sufficiently causal. To address this issue, we propose Subset-Selected Counterfactual Augmentation (SS-CA), which integrates counterfactual explanations directly into the training process for targeted intervention. Building on the subset-selection-based LIMA attribution method, we develop Counterfactual LIMA to identify minimal spatial region sets whose removal can selectively alter model predictions. Leveraging these attributions, we introduce a data augmentation strategy that replaces the identified regions with natural background, and we train the model jointly on both augmented and original samples to mitigate incomplete causal learning. Extensive experiments across multiple ImageNet variants show that SS-CA improves generalization on in-distribution (ID) test data and achieves superior performance on out-of-distribution (OOD) benchmarks such as ImageNet-R and ImageNet-S. Under perturbations including noise, models trained with SS-CA also exhibit enhanced generalization, demonstrating that our approach effectively uses interpretability insights to correct model deficiencies and improve both performance and robustness.

</details>


### [64] [BdSL-SPOTER: A Transformer-Based Framework for Bengali Sign Language Recognition with Cultural Adaptation](https://arxiv.org/abs/2511.12103)
*Sayad Ibna Azad,Md. Atiqur Rahman*

Main category: cs.CV

TL;DR: BdSL-SPOTER是一个基于姿态的Transformer框架，用于准确高效地识别孟加拉手语(BdSL)。


<details>
  <summary>Details</summary>
Motivation: 为准确高效地识别孟加拉手语（BdSL）提供一个实用且可扩展的框架，特别是在数据有限的情况下。

Method: 使用文化特定预处理、紧凑的四层Transformer编码器、优化的可学习位置编码和课程学习来扩展SPOTER范例。

Result: 在BdSLW60基准测试中，BdSL-SPOTER实现了97.92%的Top-1验证准确率，比Bi-LSTM基线提高了22.82%，同时计算成本较低。

Conclusion:  BdSL-SPOTER是一个实用的框架，可用于现实世界的辅助功能应用，并且可以作为其他低资源区域性手语的可扩展模型。

Abstract: We introduce BdSL-SPOTER, a pose-based transformer framework for accurate and efficient recognition of Bengali Sign Language (BdSL). BdSL-SPOTER extends the SPOTER paradigm with cultural specific preprocessing and a compact four-layer transformer encoder featuring optimized learnable positional encodings, while employing curriculum learning to enhance generalization on limited data and accelerate convergence. On the BdSLW60 benchmark, it achieves 97.92% Top-1 validation accuracy, representing a 22.82% improvement over the Bi-LSTM baseline, all while keeping computational costs low. With its reduced number of parameters, lower FLOPs, and higher FPS, BdSL-SPOTER provides a practical framework for real-world accessibility applications and serves as a scalable model for other low-resource regional sign languages.

</details>


### [65] [TEMPO: Global Temporal Building Density and Height Estimation from Satellite Imagery](https://arxiv.org/abs/2511.12104)
*Tammy Glazer,Gilles Q. Hacheme,Akram Zaytar,Luana Marotti,Amy Michaels,Girmaw Abebe Tadesse,Kevin White,Rahul Dodhia,Andrew Zolli,Inbal Becker-Reshef,Juan M. Lavista Ferres,Caleb Robinson*

Main category: cs.CV

TL;DR: TEMPO是一个利用深度学习模型从高分辨率卫星图像生成的大规模、时间解析的建筑密度和高度数据集，覆盖2018年第一季度至2025年第二季度，并能捕捉季度变化，计算成本低。


<details>
  <summary>Details</summary>
Motivation: 为了实现大规模的开发模式和气候影响监测，以支持全球韧性和适应性，需要一个能捕捉建筑密度和高度的时间解析数据集。

Method: 使用深度学习模型，将现有的建筑足迹和高度数据与PlanetScope卫星图像相结合，训练一个多任务深度学习模型，以37.6米/像素的分辨率预测建筑密度和高度。

Result: 生成了2018年第一季度至2025年第二季度的全球、时间序列建筑密度和高度图。与现有建筑足迹数据集的比较显示，F1分数在85%至88%之间，五年趋势一致性得分为0.96。

Conclusion: TEMPO数据集能够以较低的计算成本捕捉到建造区域的季度变化，为大规模监测开发模式和气候影响提供了有效工具，对于全球韧性和适应性至关重要。

Abstract: We present TEMPO, a global, temporally resolved dataset of building density and height derived from high-resolution satellite imagery using deep learning models. We pair building footprint and height data from existing datasets with quarterly PlanetScope basemap satellite images to train a multi-task deep learning model that predicts building density and building height at a 37.6-meter per pixel resolution. We apply this model to global PlanetScope basemaps from Q1 2018 through Q2 2025 to create global, temporal maps of building density and height. We validate these maps by comparing against existing building footprint datasets. Our estimates achieve an F1 score between 85% and 88% on different hand-labeled subsets, and are temporally stable, with a 0.96 five-year trend-consistency score. TEMPO captures quarterly changes in built settlements at a fraction of the computational cost of comparable approaches, unlocking large-scale monitoring of development patterns and climate impacts essential for global resilience and adaptation efforts.

</details>


### [66] [Fine-Grained DINO Tuning with Dual Supervision for Face Forgery Detection](https://arxiv.org/abs/2511.12107)
*Tianxiang Zhang,Peipeng Yu,Zhihua Xia,Longchen Dai,Xiaoyu Zhou,Hui Gao*

Main category: cs.CV

TL;DR: DFF-Adapter是一种用于DINOv2的轻量级适配器，可以同时进行真实性检测和精细的操纵类型分类，通过多任务协同优化来提高检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测方法通常将DINOv2视为通用二元分类器，忽略了不同伪造方法产生的独特伪影。

Method: 提出了一种深度伪造精细适配器（DFF-Adapter），它将轻量级多头LoRA模块集成到DINOv2的每个Transformer块中，并引入了一个共享分支来传播精细操纵线索到真实性头部，实现多任务协同优化。

Result: DFF-Adapter仅使用350万可训练参数，在检测精度上达到了与现有复杂最先进方法相当甚至更优的水平。

Conclusion: DFF-Adapter通过精细的操纵类型分类增强了伪影敏感性，利用特定于操纵的知识明确提高了真实性辨别能力，是一种参数高效且性能优越的深度伪造检测方法。

Abstract: The proliferation of sophisticated deepfakes poses significant threats to information integrity. While DINOv2 shows promise for detection, existing fine-tuning approaches treat it as generic binary classification, overlooking distinct artifacts inherent to different deepfake methods. To address this, we propose a DeepFake Fine-Grained Adapter (DFF-Adapter) for DINOv2. Our method incorporates lightweight multi-head LoRA modules into every transformer block, enabling efficient backbone adaptation. DFF-Adapter simultaneously addresses authenticity detection and fine-grained manipulation type classification, where classifying forgery methods enhances artifact sensitivity. We introduce a shared branch propagating fine-grained manipulation cues to the authenticity head. This enables multi-task cooperative optimization, explicitly enhancing authenticity discrimination with manipulation-specific knowledge. Utilizing only 3.5M trainable parameters, our parameter-efficient approach achieves detection accuracy comparable to or even surpassing that of current complex state-of-the-art methods.

</details>


### [67] [MediRound: Multi-Round Entity-Level Reasoning Segmentation in Medical Images](https://arxiv.org/abs/2511.12110)
*Qinyue Tong,Ziqian Lu,Jun Liu,Rui Zuo,Zheming Lu*

Main category: cs.CV

TL;DR: MEMR-Seg是一个新的医学图像分割任务，通过多轮查询和实体级推理生成分割掩码。MR-MedSeg是支持该任务的数据集，包含17.7万个多轮医学分割对话。MediRound是提出的基线模型，具有判断与纠正机制以缓解误差传播。实验证明该方法优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法多为任务特定且缺乏交互性。基于文本提示的方法虽然增强了用户驱动和推理，但仅限于单轮对话，无法进行多轮推理。

Method: 提出MEMR-Seg任务，构建MR-MedSeg数据集，并提出MediRound模型，包含判断与纠正机制以缓解误差传播。

Result: 实验结果表明，所提出的方法能有效处理MEMR-Seg任务，并且优于传统的医学指代表达式分割方法。

Conclusion: MEMR-Seg任务和MR-MedSeg数据集为多轮推理医学分割提供了支持，所提出的MediRound模型及其判断与纠正机制能有效解决该任务。

Abstract: Despite the progress in medical image segmentation, most existing methods remain task-specific and lack interactivity. Although recent text-prompt-based segmentation approaches enhance user-driven and reasoning-based segmentation, they remain confined to single-round dialogues and fail to perform multi-round reasoning. In this work, we introduce Multi-Round Entity-Level Medical Reasoning Segmentation (MEMR-Seg), a new task that requires generating segmentation masks through multi-round queries with entity-level reasoning. To support this task, we construct MR-MedSeg, a large-scale dataset of 177K multi-round medical segmentation dialogues, featuring entity-based reasoning across rounds. Furthermore, we propose MediRound, an effective baseline model designed for multi-round medical reasoning segmentation. To mitigate the inherent error propagation in the chain-like pipeline of multi-round segmentation, we introduce a lightweight yet effective Judgment & Correction Mechanism during model inference. Experimental results demonstrate that our method effectively addresses the MEMR-Seg task and outperforms conventional medical referring segmentation methods.

</details>


### [68] [RadarMP: Motion Perception for 4D mmWave Radar in Autonomous Driving](https://arxiv.org/abs/2511.12117)
*Ruiqi Cheng,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: RadarMP是一种用于精确3D场景运动感知的创新方法，它利用连续两帧的4D毫米波雷达回波信号，通过联合建模目标检测和运动估计任务，实现了点云生成和3D场景流预测的一致性，并采用基于多普勒频移和回波强度引导的自监督损失函数，在各种天气和光照条件下均表现出色。


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达在全天候自动驾驶中至关重要，但雷达点云稀疏且有噪声，导致运动感知不精确，尤其在恶劣天气条件下影响更大。现有方法将雷达目标检测和运动估计分开处理，限制了感知能力。

Method: RadarMP联合建模雷达目标检测和运动估计任务，在一个统一的架构中实现点云生成和3D场景流预测。设计了基于多普勒频移和回波强度引导的自监督损失函数，以监督空间和运动一致性，无需显式标注。

Result: RadarMP在公开数据集上的广泛实验表明，该方法在各种天气和光照条件下均能实现可靠的运动感知，并且优于基于雷达解耦运动感知的现有方法。

Conclusion: RadarMP通过联合建模和新颖的自监督学习方法，有效解决了4D毫米波雷达运动感知的挑战，提高了自动驾驶系统在全场景下的感知能力，尤其是在恶劣天气条件下。

Abstract: Accurate 3D scene motion perception significantly enhances the safety and reliability of an autonomous driving system. Benefiting from its all-weather operational capability and unique perceptual properties, 4D mmWave radar has emerged as an essential component in advanced autonomous driving. However, sparse and noisy radar points often lead to imprecise motion perception, leaving autonomous vehicles with limited sensing capabilities when optical sensors degrade under adverse weather conditions. In this paper, we propose RadarMP, a novel method for precise 3D scene motion perception using low-level radar echo signals from two consecutive frames. Unlike existing methods that separate radar target detection and motion estimation, RadarMP jointly models both tasks in a unified architecture, enabling consistent radar point cloud generation and pointwise 3D scene flow prediction. Tailored to radar characteristics, we design specialized self-supervised loss functions guided by Doppler shifts and echo intensity, effectively supervising spatial and motion consistency without explicit annotations. Extensive experiments on the public dataset demonstrate that RadarMP achieves reliable motion perception across diverse weather and illumination conditions, outperforming radar-based decoupled motion perception pipelines and enhancing perception capabilities for full-scenario autonomous driving systems.

</details>


### [69] [OAD-Promoter: Enhancing Zero-shot VQA using Large Language Models with Object Attribute Description](https://arxiv.org/abs/2511.12131)
*Quanxing Xu,Ling Zhou,Feifei Zhang,Jinyu Tian,Rubing Huang*

Main category: cs.CV

TL;DR: LLM在视觉问答（VQA）中处理知识密集型问题时会继承语言偏见，导致预测不可靠且难以泛化到分布外（OOD）数据。我们提出了OAD-Promoter，包含OEG、MKA和OAD Prompt三个模块，用于减轻语言偏见和提高领域迁移鲁棒性。实验表明，OAD-Promoter在少样本或零样本VQA场景下显著提升了LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在视觉问答（VQA）中处理知识密集型问题时，会继承训练数据中的语言偏见，导致预测结果不可靠，并且难以泛化到分布外（OOD）的数据。现有的方法在利用LLM处理VQA问题时，面临着偏见利用和OOD泛化能力不足的挑战。

Method: 我们提出了OAD-Promoter，它包含三个组件：1. 对象集中示例生成（OEG）模块，用于生成全局标题和对象集中样本，通过全局和区域视觉线索的互补来增强LLM的视觉信息输入并减轻偏见。2. 记忆知识辅助（MKA）模块，通过检索存储示例中的相关知识来帮助LLM处理OOD样本。3. OAD Prompt，整合前两个模块的输出来优化LLM推理。

Result: 实验结果表明，OAD-Promoter显著提高了LLM在少样本或零样本VQA设置下的性能，并达到了新的最先进水平。

Conclusion: OAD-Promoter能够有效地减轻LLM在VQA任务中继承的语言偏见，并提高其在分布外数据上的泛化能力，在少样本和零样本场景下取得了优异的表现。

Abstract: Large Language Models (LLMs) have become a crucial tool in Visual Question Answering (VQA) for handling knowledge-intensive questions in few-shot or zero-shot scenarios. However, their reliance on massive training datasets often causes them to inherit language biases during the acquisition of knowledge. This limitation imposes two key constraints on existing methods: (1) LLM predictions become less reliable due to bias exploitation, and (2) despite strong knowledge reasoning capabilities, LLMs still struggle with out-of-distribution (OOD) generalization. To address these issues, we propose Object Attribute Description Promoter (OAD-Promoter), a novel approach for enhancing LLM-based VQA by mitigating language bias and improving domain-shift robustness. OAD-Promoter comprises three components: the Object-concentrated Example Generation (OEG) module, the Memory Knowledge Assistance (MKA) module, and the OAD Prompt. The OEG module generates global captions and object-concentrated samples, jointly enhancing visual information input to the LLM and mitigating bias through complementary global and regional visual cues. The MKA module assists the LLM in handling OOD samples by retrieving relevant knowledge from stored examples to support questions from unseen domains. Finally, the OAD Prompt integrates the outputs of the preceding modules to optimize LLM inference. Experiments demonstrate that OAD-Promoter significantly improves the performance of LLM-based VQA methods in few-shot or zero-shot settings, achieving new state-of-the-art results.

</details>


### [70] [Compression and Inference of Spiking Neural Networks on Resource-Constrained Hardware](https://arxiv.org/abs/2511.12136)
*Karol C. Jurzec,Tomasz Szydlo,Maciej Wielgosz*

Main category: cs.CV

TL;DR: 本文提出了一个轻量级的C语言SNN运行时和优化方法，用于在边缘设备上实现SNN推理，并在N-MNIST和ST-MNIST数据集上实现了显著的加速和内存缩减。


<details>
  <summary>Details</summary>
Motivation: Spiking neural networks (SNNs)在时间处理和能效方面具有优势，但训练和部署具有挑战性。需要一个轻量级的运行时和优化方法来克服这些挑战。

Method: 将SNNTorch导出的模型转换为紧凑的C语言表示；使用静态、对缓存友好的数据布局和预分配来避免解释器和分配开销；利用稀疏脉冲活动来修剪非活动神经元和突触，以减少计算量。

Result: 在N-MNIST和ST-MNIST数据集上实现了与Python基线相当的功能，同时在桌面CPU上实现了约10倍的加速，并且通过修剪实现了额外的性能提升。内存占用也大幅减少，使得模型可以在微控制器（Arduino Portenta H7）上部署。

Conclusion: 通过优化的运行时和面向脉冲的剪枝，SNN可以在传统的嵌入式平台上高效运行。

Abstract: Spiking neural networks (SNNs) communicate via discrete spikes in time rather than continuous activations. Their event-driven nature offers advantages for temporal processing and energy efficiency on resource-constrained hardware, but training and deployment remain challenging. We present a lightweight C-based runtime for SNN inference on edge devices and optimizations that reduce latency and memory without sacrificing accuracy. Trained models exported from SNNTorch are translated to a compact C representation; static, cache-friendly data layouts and preallocation avoid interpreter and allocation overheads. We further exploit sparse spiking activity to prune inactive neurons and synapses, shrinking computation in upstream convolutional layers. Experiments on N-MNIST and ST-MNIST show functional parity with the Python baseline while achieving ~10 speedups on desktop CPU and additional gains with pruning, together with large memory reductions that enable microcontroller deployment (Arduino Portenta H7). Results indicate that SNNs can be executed efficiently on conventional embedded platforms when paired with an optimized runtime and spike-driven model compression. Code: https://github.com/karol-jurzec/snn-generator/

</details>


### [71] [MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering](https://arxiv.org/abs/2511.12142)
*Seokwon Song,Minsu Park,Gunhee Kim*

Main category: cs.CV

TL;DR: MAVIS是一个评估多模态源归因系统的基准，解决了多模态视觉问答中的引用问题，并提出了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有源归因方法主要关注文本，忽略了多模态的作用。MAVIS旨在解决这一问题，通过包含视觉问答的引用来提高AI答案的可靠性。

Method: MAVIS数据集包含157K个视觉问答实例，每个答案都附有指向多模态文档的事实级引用。研究者还开发了自动评估指标，包括信息量、基础性和流畅性。

Result: 研究发现，多模态检索增强学习模型（LVLMs）在信息量和流畅性方面优于单一模态模型，但在图像文档的基础性方面表现较弱。此外，在相同的多模态文档下，不同提示方法在信息量和基础性之间存在权衡。研究还强调了减轻图像文档解释中的上下文偏见的重要性。

Conclusion: MAVIS填补了多模态源归因领域的空白，并为未来的研究指明了方向，特别是在处理图像文档的上下文偏见方面。

Abstract: Source attribution aims to enhance the reliability of AI-generated answers by including references for each statement, helping users validate the provided answers. However, existing work has primarily focused on text-only scenario and largely overlooked the role of multimodality. We introduce MAVIS, the first benchmark designed to evaluate multimodal source attribution systems that understand user intent behind visual questions, retrieve multimodal evidence, and generate long-form answers with citations. Our dataset comprises 157K visual QA instances, where each answer is annotated with fact-level citations referring to multimodal documents. We develop fine-grained automatic metrics along three dimensions of informativeness, groundedness, and fluency, and demonstrate their strong correlation with human judgments. Our key findings are threefold: (1) LVLMs with multimodal RAG generate more informative and fluent answers than unimodal RAG, but they exhibit weaker groundedness for image documents than for text documents, a gap amplified in multimodal settings. (2) Given the same multimodal documents, there is a trade-off between informativeness and groundedness across different prompting methods. (3) Our proposed method highlights mitigating contextual bias in interpreting image documents as a crucial direction for future research. The dataset and experimental code are available at https://github.com/seokwon99/MAVIS

</details>


### [72] [OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding](https://arxiv.org/abs/2511.12614)
*Artem Moroz,Vít Zeman,Martin Mikšík,Elizaveta Isianova,Miroslav David,Pavel Burget,Varun Burde*

Main category: cs.CV

TL;DR: We present an integrated framework for object detection and pose estimation using a transformer-based approach (OPFormer) that leverages neural representations (NeRF) and 3D geometric priors (NOCS).


<details>
  <summary>Details</summary>
Motivation: To create a unified, end-to-end framework for object detection and pose estimation that is versatile and can handle cases with and without traditional 3D CAD models.

Method: The framework integrates object detection (CNOS detector) and pose estimation (OPFormer). OPFormer uses a transformer architecture, a foundation model for feature extraction, learns object representations from multiple template views, and incorporates NOCS for 3D geometric priors. It reconstructs NeRFs for objects lacking CAD models. It establishes 2D-3D correspondences for pose determination.

Result: The system achieves a strong balance between accuracy and efficiency on the BOP benchmarks, demonstrating practical applicability in both model-based and model-free scenarios.

Conclusion: The proposed unified framework effectively combines object detection and pose estimation, offering a practical and efficient solution for real-world applications, adaptable to different object representation availability.

Abstract: We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.

</details>


### [73] [Breaking the Modality Wall: Time-step Mixup for Efficient Spiking Knowledge Transfer from Static to Event Domain](https://arxiv.org/abs/2511.12150)
*Yuqi Xie,Shuhan Ye,Yi Yu,Chong Wang,Qixin Zhang,Jiazhen Xu,Le Shen,Yuanbin Qian,Jiangbo Qian,Guoqi Li*

Main category: cs.CV

TL;DR: event cameras and SNNs are energy-efficient but limited by scarce data and modality gap. TMKT framework with TSM and MAG/MRP objectives bridges this gap for better SNN training.


<details>
  <summary>Details</summary>
Motivation: Scarce event data and the distribution gap between RGB and DVS hinder effective training of event cameras and SNNs, leading to underperformance in prior knowledge transfer methods.

Method: Proposed Time-step Mixup Knowledge Transfer (TMKT) framework with a probabilistic Time-step Mixup (TSM) strategy. TSM interpolates RGB and DVS inputs at various time steps for SNNs, creating a smooth curriculum. Introduced Modality Aware Guidance (MAG) for per-frame supervision and Mixup Ratio Perception (MRP) for sequence-level mix ratio estimation.

Result: TMKT enables smoother knowledge transfer, mitigates modality mismatch, and achieves superior performance in spiking image classification tasks.

Conclusion: TMKT framework effectively bridges the modality gap between RGB and DVS data for SNN training, demonstrating superior performance across various benchmarks and SNN backbones through TSM, MAG, and MRP strategies.

Abstract: The integration of event cameras and spiking neural networks (SNNs) promises energy-efficient visual intelligence, yet scarce event data and the sparsity of DVS outputs hinder effective training. Prior knowledge transfers from RGB to DVS often underperform because the distribution gap between modalities is substantial. In this work, we present Time-step Mixup Knowledge Transfer (TMKT), a cross-modal training framework with a probabilistic Time-step Mixup (TSM) strategy. TSM exploits the asynchronous nature of SNNs by interpolating RGB and DVS inputs at various time steps to produce a smooth curriculum within each sequence, which reduces gradient variance and stabilizes optimization with theoretical analysis. To employ auxiliary supervision from TSM, TMKT introduces two lightweight modality-aware objectives, Modality Aware Guidance (MAG) for per-frame source supervision and Mixup Ratio Perception (MRP) for sequence-level mix ratio estimation, which explicitly align temporal features with the mixing schedule. TMKT enables smoother knowledge transfer, helps mitigate modality mismatch during training, and achieves superior performance in spiking image classification tasks. Extensive experiments across diverse benchmarks and multiple SNN backbones, together with ablations, demonstrate the effectiveness of our method.

</details>


### [74] [FIA-Edit: Frequency-Interactive Attention for Efficient and High-Fidelity Inversion-Free Text-Guided Image Editing](https://arxiv.org/abs/2511.12151)
*Kaixiang Yang,Boyang Shen,Xin Li,Yuchen Dai,Yuxuan Luo,Yueran Ma,Wei Fang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: FIA-Edit是一个新颖的、无反演的文本引导图像编辑框架，通过频率交互注意力实现了高保真和语义精确的编辑，在保持背景和空间一致性方面表现优于现有方法，并首次将文本引导图像编辑应用于临床医学图像的出血变化合成。


<details>
  <summary>Details</summary>
Motivation: 现有的基于流的无反演文本引导图像编辑方法在整合源信息方面存在不足，导致背景保留效果差、空间不一致以及过度编辑。本研究旨在解决这些问题，提出一种能够高保真且语义精确地进行编辑的框架。

Method: 提出了一种名为FIA-Edit的新颖无反演框架，其核心是频率交互注意力机制。该机制包含两个关键组件：(1) 频率表示交互（FRI）模块，通过在自注意力机制中交换源和目标特征的频率成分来增强跨域对齐；(2) 特征注入（FIJ）模块，将源侧的查询、键、值以及文本嵌入显式地整合到目标分支的交叉注意力中，以保留结构和语义。

Result: FIA-Edit 在保持高视觉质量、背景保真度和可控性的同时，实现了低计算成本（在RTX 4090上编辑一张512*512图像约需6秒）。实验结果表明，FIA-Edit 在各种任务上持续优于现有方法。此外，FIA-Edit 首次将文本引导图像编辑扩展到临床应用，能够合成解剖学上一致的术中出血变化，为医学数据增强开辟了新途径，并在下游出血分类任务中取得了显著的提升。

Conclusion: FIA-Edit 通过其创新的频率交互注意力和特征注入机制，有效解决了现有无反演图像编辑方法的局限性，实现了高保真、语义精确的编辑，并且计算效率高。该方法在通用图像编辑和医学图像分析领域均展现出强大的能力和广泛的应用前景。

Abstract: Text-guided image editing has advanced rapidly with the rise of diffusion models. While flow-based inversion-free methods offer high efficiency by avoiding latent inversion, they often fail to effectively integrate source information, leading to poor background preservation, spatial inconsistencies, and over-editing due to the lack of effective integration of source information. In this paper, we present FIA-Edit, a novel inversion-free framework that achieves high-fidelity and semantically precise edits through a Frequency-Interactive Attention. Specifically, we design two key components: (1) a Frequency Representation Interaction (FRI) module that enhances cross-domain alignment by exchanging frequency components between source and target features within self-attention, and (2) a Feature Injection (FIJ) module that explicitly incorporates source-side queries, keys, values, and text embeddings into the target branch's cross-attention to preserve structure and semantics. Comprehensive and extensive experiments demonstrate that FIA-Edit supports high-fidelity editing at low computational cost (~6s per 512 * 512 image on an RTX 4090) and consistently outperforms existing methods across diverse tasks in visual quality, background fidelity, and controllability. Furthermore, we are the first to extend text-guided image editing to clinical applications. By synthesizing anatomically coherent hemorrhage variations in surgical images, FIA-Edit opens new opportunities for medical data augmentation and delivers significant gains in downstream bleeding classification. Our project is available at: https://github.com/kk42yy/FIA-Edit.

</details>


### [75] [Codebook-Centric Deep Hashing: End-to-End Joint Learning of Semantic Hash Centers and Neural Hash Function](https://arxiv.org/abs/2511.12162)
*Shuo Yin,Zhiyuan Yin,Yuqing Hou,Rui Liu,Yong Chen,Dell Zhang*

Main category: cs.CV

TL;DR: CRH是一种端到端的深度哈希框架，通过动态重分配哈希中心来优化哈希函数，解决了现有方法中哈希中心初始化不当和分阶段优化带来的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于哈希中心的方法在初始化时忽略了类间语义关系，而现有的两阶段方法则引入了额外的复杂性和计算开销。CRH旨在解决这些问题。

Method: CRH提出了一种端到端的框架，在联合优化哈希函数的同时，动态地从预设的代码库中重新分配哈希中心。它还采用了一种多头机制来增强哈希中心的表征能力。

Result: CRH在三个基准测试中表现优于最先进的深度哈希方法，证明了其能够学习到具有语义意义的哈希中心。

Conclusion: CRH通过动态重分配哈希中心和多头机制，能够有效地学习语义信息，并在图像检索任务中取得领先的性能。

Abstract: Hash center-based deep hashing methods improve upon pairwise or triplet-based approaches by assigning fixed hash centers to each class as learning targets, thereby avoiding the inefficiency of local similarity optimization. However, random center initialization often disregards inter-class semantic relationships. While existing two-stage methods mitigate this by first refining hash centers with semantics and then training the hash function, they introduce additional complexity, computational overhead, and suboptimal performance due to stage-wise discrepancies. To address these limitations, we propose $\textbf{Center-Reassigned Hashing (CRH)}$, an end-to-end framework that $\textbf{dynamically reassigns hash centers}$ from a preset codebook while jointly optimizing the hash function. Unlike previous methods, CRH adapts hash centers to the data distribution $\textbf{without explicit center optimization phases}$, enabling seamless integration of semantic relationships into the learning process. Furthermore, $\textbf{a multi-head mechanism}$ enhances the representational capacity of hash centers, capturing richer semantic structures. Extensive experiments on three benchmarks demonstrate that CRH learns semantically meaningful hash centers and outperforms state-of-the-art deep hashing methods in retrieval tasks.

</details>


### [76] [Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views](https://arxiv.org/abs/2511.12878)
*Junyi Ma,Wentao Bao,Jingyi Xu,Guanzhong Sun,Yu Zheng,Erhang Zhang,Xieyuanli Chen,Hesheng Wang*

Main category: cs.CV

TL;DR: 该研究提出了一个名为EgoLoc的零样本方法，用于在第一人称视角视频中定位手-物体接触和分离的时间戳，解决了现有方法在物体识别和精度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注“如何交互”，而忽略了“何时交互”这一关键的精细化问题，即手-物体接触和分离的关键时刻的捕捉，这对于沉浸式混合现实体验和机器人运动规划至关重要。

Method: 提出了一种名为EgoLoc的新型零样本方法。该方法利用手部动力学引导的采样生成高质量视觉提示，并利用视觉-语言模型识别接触/分离属性、定位具体时间戳，并通过闭环反馈进行优化。EgoLoc无需物体掩码和动词-名词分类，实现了通用的零样本能力。

Result: 在公开数据集和新构建的基准测试上进行了广泛实验，结果表明EgoLoc能够为第一人称视角视频实现合理的时间交互定位（TIL），并有效促进了第一人称视觉和机器人操作任务中的多个下游应用。

Conclusion: EgoLoc是一种创新的零样本方法，能够有效地在第一人称视角视频中定位手-物体交互的关键时间点，解决了现有技术的局限性，并在下游应用中展现了其实用性。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [77] [Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective](https://arxiv.org/abs/2511.12170)
*Wang Luo,Di Wu,Hengyuan Na,Yinlin Zhu,Miao Hu,Guocong Quan*

Main category: cs.CV

TL;DR: 通过基于校正的范式，使用PGNet从部分点云生成完整3D形状。


<details>
  <summary>Details</summary>
Motivation: 现有的点云补全方法（基于修复范式）在处理严重遮挡和几何缺失时，常因有限的几何和语义约束而导致结构不一致和拓扑失真。而作者提出的基于校正的范式，通过对预先生成的完整形状进行校正，可以实现结构一致且与观察一致的重建。

Method: 提出了一种名为PGNet的多阶段框架，该框架采用双特征编码来约束生成先验，合成一个粗糙但结构对齐的支架，并通过分层校正逐步完善几何细节。

Result: PGNet在ShapeNetViPC数据集上的实验结果显示，在平均Chamfer距离（-23.5%）和F-score（+7.1%）方面优于最先进的方法。

Conclusion: 作者提出的基于校正的范式，并以PGNet为实现，能够有效地解决点云补全中的结构不一致和拓扑失真问题，实现更优的重建效果。

Abstract: Point cloud completion aims to reconstruct complete 3D shapes from partial observations, which is a challenging problem due to severe occlusions and missing geometry. Despite recent advances in multimodal techniques that leverage complementary RGB images to compensate for missing geometry, most methods still follow a Completion-by-Inpainting paradigm, synthesizing missing structures from fused latent features. We empirically show that this paradigm often results in structural inconsistencies and topological artifacts due to limited geometric and semantic constraints. To address this, we rethink the task and propose a more robust paradigm, termed Completion-by-Correction, which begins with a topologically complete shape prior generated by a pretrained image-to-3D model and performs feature-space correction to align it with the partial observation. This paradigm shifts completion from unconstrained synthesis to guided refinement, enabling structurally consistent and observation-aligned reconstruction. Building upon this paradigm, we introduce PGNet, a multi-stage framework that conducts dual-feature encoding to ground the generative prior, synthesizes a coarse yet structurally aligned scaffold, and progressively refines geometric details via hierarchical correction. Experiments on the ShapeNetViPC dataset demonstrate the superiority of PGNet over state-of-the-art baselines in terms of average Chamfer Distance (-23.5%) and F-score (+7.1%).

</details>


### [78] [DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation](https://arxiv.org/abs/2511.13047)
*Yan Gong,Jianli Lu,Yongsheng Gao,Jie Zhao,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.CV

TL;DR: DiffPixelFormer是一个用于RGB-D室内场景分割的差分像素感知Transformer，通过IIMIB和DSIM模块增强了模态内表示和模态间交互，实现了更精确的特征对齐和更强的区分性表示，在SUN RGB-D和NYUDv2基准测试中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-D融合室内语义分割方法依赖于计算密集型跨注意力机制，并且不能充分模拟模态内和模态间特征关系，导致特征对齐不精确和区分性表示有限。

Method: 提出了一种差分像素感知Transformer（DiffPixelFormer），包含一个内部-外部模态交互块（IIMIB）来捕捉模态内长程依赖关系，以及一个差分共享模态间（DSIM）模块来解开模态特定的和共享的线索，从而实现细粒度的像素级跨模态对齐。此外，采用动态融合策略来平衡模态贡献并充分利用RGB-D信息。

Result: 在SUN RGB-D和NYUDv2基准测试上，DiffPixelFormer-L的mIoU得分分别为54.28%和59.95%，分别比DFormer-L高出1.78%和2.75%。

Conclusion: DiffPixelFormer在RGB-D室内场景分割任务上实现了最先进的性能，证明了其在增强模态内表示和模态间交互方面的有效性。

Abstract: Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.

</details>


### [79] [MixAR: Mixture Autoregressive Image Generation](https://arxiv.org/abs/2511.12181)
*Jinyuan Hu,Jiayou Zhang,Shaobo Cui,Kun Zhang,Guangyi Chen*

Main category: cs.CV

TL;DR: MixAR框架通过混合训练范式，利用离散标记作为先验引导，实现了连续自回归建模，解决了离散化和连续表示的挑战，提高了图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有自回归方法在图像生成中存在信息丢失和连续表示难以建模的挑战，本研究旨在提高生成质量并解决这些问题。

Method: MixAR框架采用混合训练策略，包括自注意力（DC-SA）、交叉注意力（DC-CA）和混合（DC-Mix），并提出训练-推理混合（TI-Mix）策略以实现训练和推理分布的一致性。

Result: 实验证明，DC-Mix策略在计算效率和生成保真度之间取得了良好的平衡，TI-Mix策略也取得了持续改进。

Conclusion: MixAR框架通过结合离散标记和连续表示，有效解决了图像生成中的挑战，提高了生成质量和效率。

Abstract: Autoregressive (AR) approaches, which represent images as sequences of discrete tokens from a finite codebook, have achieved remarkable success in image generation. However, the quantization process and the limited codebook size inevitably discard fine-grained information, placing bottlenecks on fidelity. Motivated by this limitation, recent studies have explored autoregressive modeling in continuous latent spaces, which offers higher generation quality. Yet, unlike discrete tokens constrained by a fixed codebook, continuous representations lie in a vast and unstructured space, posing significant challenges for efficient autoregressive modeling. To address these challenges, we introduce MixAR, a novel framework that leverages mixture training paradigms to inject discrete tokens as prior guidance for continuous AR modeling. MixAR is a factorized formulation that leverages discrete tokens as prior guidance for continuous autoregressive prediction. We investigate several discrete-continuous mixture strategies, including self-attention (DC-SA), cross-attention (DC-CA), and a simple approach (DC-Mix) that replaces homogeneous mask tokens with informative discrete counterparts. Moreover, to bridge the gap between ground-truth training tokens and inference tokens produced by the pre-trained AR model, we propose Training-Inference Mixture (TI-Mix) to achieve consistent training and generation distributions. In our experiments, we demonstrate a favorable balance of the DC-Mix strategy between computational efficiency and generation fidelity, and consistent improvement of TI-Mix.

</details>


### [80] [MMRINet: Efficient Mamba-Based Segmentation with Dual-Path Refinement for Low-Resource MRI Analysis](https://arxiv.org/abs/2511.12193)
*Abdelrahman Elsayed,Ahmed Jaheen,Mohammad Yaqub*

Main category: cs.CV

TL;DR: MMRINet是一个轻量级网络，使用Mamba状态空间模型替代二次复杂度注意力机制，并结合了双通路特征细化（DPFR）和渐进特征聚合（PFA）模块，在BraTS-Lighthouse SSA 2025中实现了高效准确的脑肿瘤分割，参数量仅约250万，适用于资源受限的临床环境。


<details>
  <summary>Details</summary>
Motivation: 资源受限环境下，计算成本高昂的3D深度网络难以实现自动化的脑肿瘤分割。因此，需要开发计算效率高且性能优越的模型。

Method: 提出了一种名为MMRINet的轻量级网络架构。该架构采用线性复杂度的Mamba状态空间模型来替代计算复杂度为二次的注意力机制，以实现高效的体积上下文建模。此外，还设计了新颖的双通路特征细化（DPFR）模块来最大化特征多样性，以及渐进特征聚合（PFA）模块来实现有效的多尺度特征融合。

Result: 在BraTS-Lighthouse SSA 2025竞赛中，MMRINet取得了优异的性能，平均Dice分数为0.752，平均HD95评分为12.23。该模型的参数量仅约250万，证明了其在低资源临床环境下的高效性和准确性。

Conclusion: MMRINet通过采用Mamba状态空间模型、DPFR和PFA模块，成功解决了资源受限环境下脑肿瘤分割的挑战，实现了计算效率和分割精度的良好平衡，为低资源临床应用提供了可行方案。

Abstract: Automated brain tumor segmentation in multi-parametric MRI remains challenging in resource-constrained settings where deep 3D networks are computationally prohibitive. We propose MMRINet, a lightweight architecture that replaces quadratic-complexity attention with linear-complexity Mamba state-space models for efficient volumetric context modeling. Novel Dual-Path Feature Refinement (DPFR) modules maximize feature diversity without additional data requirements, while Progressive Feature Aggregation (PFA) enables effective multi-scale fusion. In the BraTS-Lighthouse SSA 2025, our model achieves strong performance with an average Dice score of (0.752) and an average HD95 of (12.23) with only ~2.5M parameters, demonstrating efficient and accurate segmentation suitable for low-resource clinical environments. Our GitHub repository can be accessed here: github.com/BioMedIA-MBZUAI/MMRINet.

</details>


### [81] [PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image](https://arxiv.org/abs/2511.13648)
*Ziang Cao,Fangzhou Hong,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: PhysX-Anything是一个首个支持物理模拟的3D生成框架，可以将单张图像转换为包含几何、关节和物理属性的、可直接用于模拟的3D资产，通过高效的3D表示和新的数据集PhysX-Mobility克服了现有方法的局限性，并在机器人策略学习等领域展现了应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法忽略了物理和关节属性，限制了其在具身AI中的应用。

Method: 提出首个基于视觉语言模型（VLM）的物理3D生成模型，以及一种高效的3D表示方法（将token数量减少193倍），并构建了包含2K+常见现实世界物体及其物理注释的新数据集PhysX-Mobility。

Result: PhysX-Anything能够生成高质量的、可用于模拟的3D资产，并在PhysX-Mobility和真实图像上展现了强大的生成性能和泛化能力。在MuJoCo风格环境中进行的仿真实验验证了其生成的3D资产可直接用于机器人策略学习。

Conclusion: PhysX-Anything有望极大促进具身AI和基于物理的模拟等领域的广泛应用。

Abstract: 3D modeling is shifting from static visual representations toward physical, articulated assets that can be directly used in simulation and interaction. However, most existing 3D generation methods overlook key physical and articulation properties, thereby limiting their utility in embodied AI. To bridge this gap, we introduce PhysX-Anything, the first simulation-ready physical 3D generative framework that, given a single in-the-wild image, produces high-quality sim-ready 3D assets with explicit geometry, articulation, and physical attributes. Specifically, we propose the first VLM-based physical 3D generative model, along with a new 3D representation that efficiently tokenizes geometry. It reduces the number of tokens by 193x, enabling explicit geometry learning within standard VLM token budgets without introducing any special tokens during fine-tuning and significantly improving generative quality. In addition, to overcome the limited diversity of existing physical 3D datasets, we construct a new dataset, PhysX-Mobility, which expands the object categories in prior physical 3D datasets by over 2x and includes more than 2K common real-world objects with rich physical annotations. Extensive experiments on PhysX-Mobility and in-the-wild images demonstrate that PhysX-Anything delivers strong generative performance and robust generalization. Furthermore, simulation-based experiments in a MuJoCo-style environment validate that our sim-ready assets can be directly used for contact-rich robotic policy learning. We believe PhysX-Anything can substantially empower a broad range of downstream applications, especially in embodied AI and physics-based simulation.

</details>


### [82] [Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System](https://arxiv.org/abs/2511.12196)
*Aditi Bhalla,Christian Hellert,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的框架，通过对比学习和信息瓶颈损失来联合解决驾驶员分心识别中的跨视图和跨模态域适应问题，从而提高模型在不同摄像头视角和传感器类型下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习方法在识别驾驶员分心方面存在跨视图（摄像头视角变化）和域移位（传感器类型或环境变化）的挑战，阻碍了其在现实世界中的应用。现有方法通常只解决其中一个问题，而没有联合处理。

Method: 提出一个两阶段的框架：第一阶段，利用对比学习学习视图不变且动作可区分的特征；第二阶段，利用信息瓶颈损失进行跨模态域适应，无需新领域标签数据。

Result: 在Drive&Act数据集上，该框架与state-of-the-art视频Transformer（Video Swin, MViT）结合使用，相比仅基于对比学习的跨视图方法，在RGB视频数据上的top-1准确率提高了近50%；相比仅进行无监督域适应的方法，准确率提高了高达5%。

Conclusion: 该联合框架能有效解决跨视图和跨模态的域适应问题，显著提升了驾驶员分心识别的准确性和鲁棒性，为在多样化的车辆配置和环境中部署模型提供了解决方案。

Abstract: Driver distraction remains a leading cause of road traffic accidents, contributing to thousands of fatalities annually across the globe. While deep learning-based driver activity recognition methods have shown promise in detecting such distractions, their effectiveness in real-world deployments is hindered by two critical challenges: variations in camera viewpoints (cross-view) and domain shifts such as change in sensor modality or environment. Existing methods typically address either cross-view generalization or unsupervised domain adaptation in isolation, leaving a gap in the robust and scalable deployment of models across diverse vehicle configurations. In this work, we propose a novel two-phase cross-view, cross-modal unsupervised domain adaptation framework that addresses these challenges jointly on real-time driver monitoring data. In the first phase, we learn view-invariant and action-discriminative features within a single modality using contrastive learning on multi-view data. In the second phase, we perform domain adaptation to a new modality using information bottleneck loss without requiring any labeled data from the new domain. We evaluate our approach using state-of-the art video transformers (Video Swin, MViT) and multi modal driver activity dataset called Drive&Act, demonstrating that our joint framework improves top-1 accuracy on RGB video data by almost 50% compared to a supervised contrastive learning-based cross-view method, and outperforms unsupervised domain adaptation-only methods by up to 5%, using the same video transformer backbone.

</details>


### [83] [Scaling Spatial Intelligence with Multimodal Foundation Models](https://arxiv.org/abs/2511.13719)
*Zhongang Cai,Ruisi Wang,Chenyang Gu,Fanyi Pu,Junxiang Xu,Yubo Wang,Wanqi Yin,Zhitao Yang,Chen Wei,Qingping Sun,Tongxi Zhou,Jiaqi Li,Hui En Pang,Oscar Qian,Yukun Wei,Zhiqian Lin,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Xiangyu Fan,Hanming Deng,Lewei Lu,Liang Pan,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: 尽管多模态基础模型在空间智能方面仍有不足，但SenseNova-SI模型家族通过扩展模型规模和精心策划的800万个空间能力相关数据，在VSI-Bench、MMSI、MindCube、ViewSpatial和SITE等基准测试中取得了领先性能，同时保持了强大的多模态理解能力。此外，该研究还探讨了数据扩展的影响、涌现的泛化能力、过拟合和语言捷径的风险，并初步研究了空间链式思考推理和下游应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态基础模型在空间智能方面存在明显短板，需要进行扩展以提升这方面的能力。

Method: 构建了SenseNova-SI模型家族，基于Qwen3-VL和InternVL3等视觉理解模型以及Bagel统一理解和生成模型。通过系统性地策划包含800万个多样化数据样本、遵循严格的空间能力分类法的数据集SenseNova-SI-8M，来构建高性能、鲁棒的空间智能模型。

Result: SenseNova-SI在VSI-Bench（68.7%）、MMSI（43.3%）、MindCube（85.6%）、ViewSpatial（54.6%）和SITE（50.1%）等空间智能基准测试中取得了前所未有的性能，同时在MMBench-En（84.9%）等通用多模态理解任务上保持了强大能力。

Conclusion: 扩展多模态基础模型并结合精心策划的大规模空间数据集是提升模型空间智能的有效途径。SenseNova-SI模型家族展示了在空间智能任务上的巨大潜力，并且通过分析数据扩展、泛化能力、过拟合风险、空间链式思考推理以及下游应用，为该领域的研究提供了重要见解。研究成果和模型已公开，以促进进一步研究。

Abstract: Despite remarkable progress, multimodal foundation models still exhibit surprising deficiencies in spatial intelligence. In this work, we explore scaling up multimodal foundation models to cultivate spatial intelligence within the SenseNova-SI family, built upon established multimodal foundations including visual understanding models (i.e., Qwen3-VL and InternVL3) and unified understanding and generation models (i.e., Bagel). We take a principled approach to constructing high-performing and robust spatial intelligence by systematically curating SenseNova-SI-8M: eight million diverse data samples under a rigorous taxonomy of spatial capabilities. SenseNova-SI demonstrates unprecedented performance across a broad range of spatial intelligence benchmarks: 68.7% on VSI-Bench, 43.3% on MMSI, 85.6% on MindCube, 54.6% on ViewSpatial, and 50.1% on SITE, while maintaining strong general multimodal understanding (e.g., 84.9% on MMBench-En). More importantly, we analyze the impact of data scaling, discuss early signs of emergent generalization capabilities enabled by diverse data training, analyze the risk of overfitting and language shortcuts, present a preliminary study on spatial chain-of-thought reasoning, and validate the potential downstream application. SenseNova-SI is an ongoing project, and this report will be updated continuously. All newly trained multimodal foundation models are publicly released to facilitate further research in this direction.

</details>


### [84] [Bridging Granularity Gaps: Hierarchical Semantic Learning for Cross-domain Few-shot Segmentation](https://arxiv.org/abs/2511.12200)
*Sujun Sun,Haowen Gu,Cheng Xie,Yanxu Ren,Mingwu Ren,Haofeng Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为“分层语义学习”（HSL）的框架，用于解决跨域少样本分割（CD-FSS）任务中存在的粒度差距问题，通过引入“双风格随机化”（DSR）和“分层语义挖掘”（HSM）模块来增强模型对不同粒度语义的识别能力，并使用“原型置信度调制阈值”（PCMT）模块来处理前景和背景相似度高的情况，在四个数据集上的实验结果表明该方法达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有CD-FSS方法主要关注风格差异，忽视了粒度差异，导致在目标域中对新类别的语义区分能力不足。

Method: 提出分层语义学习（HSL）框架，包括双风格随机化（DSR）和分层语义挖掘（HSM）模块。DSR通过前景和全局风格随机化来模拟目标域数据；HSM利用多尺度超像素来指导模型挖掘不同粒度的类内一致性和类间区分度。此外，还提出了原型置信度调制阈值（PCMT）模块来处理前景和背景相似度高的情况。

Result: 在四个流行的目标域数据集上进行了广泛的实验，结果表明该方法取得了最先进的性能。

Conclusion: 所提出的HSL框架能够有效地增强模型识别不同粒度语义的能力，从而提高CD-FSS任务的性能。

Abstract: Cross-domain Few-shot Segmentation (CD-FSS) aims to segment novel classes from target domains that are not involved in training and have significantly different data distributions from the source domain, using only a few annotated samples, and recent years have witnessed significant progress on this task. However, existing CD-FSS methods primarily focus on style gaps between source and target domains while ignoring segmentation granularity gaps, resulting in insufficient semantic discriminability for novel classes in target domains. Therefore, we propose a Hierarchical Semantic Learning (HSL) framework to tackle this problem. Specifically, we introduce a Dual Style Randomization (DSR) module and a Hierarchical Semantic Mining (HSM) module to learn hierarchical semantic features, thereby enhancing the model's ability to recognize semantics at varying granularities. DSR simulates target domain data with diverse foreground-background style differences and overall style variations through foreground and global style randomization respectively, while HSM leverages multi-scale superpixels to guide the model to mine intra-class consistency and inter-class distinction at different granularities. Additionally, we also propose a Prototype Confidence-modulated Thresholding (PCMT) module to mitigate segmentation ambiguity when foreground and background are excessively similar. Extensive experiments are conducted on four popular target domain datasets, and the results demonstrate that our method achieves state-of-the-art performance.

</details>


### [85] [OmniSparse: Training-Aware Fine-Grained Sparse Attention for Long-Video MLLMs](https://arxiv.org/abs/2511.12201)
*Feng Chen,Yefei He,Shaoxuan He,Yuanyu He,Jing Liu,Lequan Lin,Akide Liu,Zhaoyang Li,Jiyuan Zhang,Zhenbang Sun,Bohan Zhuang,Qi Wu*

Main category: cs.CV

TL;DR: OmniSparse是一个用于长视频多模态大语言模型的训练感知细粒度稀疏注意力框架，可在训练和推理时动态分配标记预算，实现性能与效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏注意力方法主要在推理时加速，但存在训练-推理不匹配、细粒度选择能力不足的问题，导致性能不佳和加速效果有限。

Method: OmniSparse包含查询选择（通过惰性-激活分类）、键值（KV）选择（通过头级动态预算分配）和KV缓存瘦身（根据头级解码查询模式选择性获取视觉KV缓存）三种机制。

Result: 实验结果表明，OmniSparse在性能上可媲美全注意力机制，在预填充时速度提升高达2.7倍，在解码时内存减少2.4倍。

Conclusion: OmniSparse通过训练感知、细粒度稀疏注意力机制，有效解决了长视频多模态大语言模型中的效率问题，实现了显著的加速和内存节省。

Abstract: Existing sparse attention methods primarily target inference-time acceleration by selecting critical tokens under predefined sparsity patterns. However, they often fail to bridge the training-inference gap and lack the capacity for fine-grained token selection across multiple dimensions such as queries, key-values (KV), and heads, leading to suboptimal performance and limited acceleration gains. In this paper, we introduce OmniSparse, a training-aware fine-grained sparse attention framework for long-video MLLMs, which operates in both training and inference with dynamic token budget allocation. Specifically, OmniSparse contains three adaptive and complementary mechanisms: (1) query selection via lazy-active classification, retaining active queries that capture broad semantic similarity while discarding most lazy ones that focus on limited local context and exhibit high functional redundancy; (2) KV selection with head-level dynamic budget allocation, where a shared budget is determined based on the flattest head and applied uniformly across all heads to ensure attention recall; and (3) KV cache slimming to reduce head-level redundancy by selectively fetching visual KV cache according to the head-level decoding query pattern. Experimental results show that OmniSparse matches the performance of full attention while achieving up to 2.7x speedup during prefill and 2.4x memory reduction during decoding.

</details>


### [86] [LSS3D: Learnable Spatial Shifting for Consistent and High-Quality 3D Generation from Single-Image](https://arxiv.org/abs/2511.12202)
*Zhuojiang Cai,Yiheng Zhang,Meitong Guo,Mingdao Wang,Yuwang Wang*

Main category: cs.CV

TL;DR: LSS3D是一种高质量的图像到3D生成方法，通过可学习的空间偏移来解决多视图不一致和非正面输入视图的问题，从而生成细节完整、纹理清晰的3D模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多视图扩散3D生成方法存在视图间形状和纹理对齐不一致的问题，导致3D生成结果质量不高，几何细节不完整，纹理出现重影。部分方法仅针对正面视图优化，对斜侧视图鲁棒性差。

Method: 提出了一种名为LSS3D的高质量图像到3D方法，该方法采用可学习的空间偏移（learnable spatial shifting）来显式且有效地处理多视图不一致和非正面输入视图。具体来说，为每个视图分配可学习的空间偏移参数，并在重建网格的指导下，将每个视图调整到一个空间一致的目标，从而实现细节更完整、纹理更清晰的高质量3D生成。此外，将输入视图作为额外的优化约束，增强了对非正面输入角度的鲁棒性，特别是对于俯视输入的视图。

Result: 通过实验证明，LSS3D在几何和纹理评估指标上始终能取得领先的性能，并且能够处理更多灵活的输入视角。

Conclusion: LSS3D通过引入可学习的空间偏移和将输入视图作为约束，有效解决了现有方法在多视图3D生成中的挑战，实现了高质量、高鲁棒性的3D生成。

Abstract: Recently, multi-view diffusion-based 3D generation methods have gained significant attention. However, these methods often suffer from shape and texture misalignment across generated multi-view images, leading to low-quality 3D generation results, such as incomplete geometric details and textural ghosting. Some methods are mainly optimized for the frontal perspective and exhibit poor robustness to oblique perspective inputs. In this paper, to tackle the above challenges, we propose a high-quality image-to-3D approach, named LSS3D, with learnable spatial shifting to explicitly and effectively handle the multiview inconsistencies and non-frontal input view. Specifically, we assign learnable spatial shifting parameters to each view, and adjust each view towards a spatially consistent target, guided by the reconstructed mesh, resulting in high-quality 3D generation with more complete geometric details and clean textures. Besides, we include the input view as an extra constraint for the optimization, further enhancing robustness to non-frontal input angles, especially for elevated viewpoint inputs. We also provide a comprehensive quantitative evaluation pipeline that can contribute to the community in performance comparisons. Extensive experiments demonstrate that our method consistently achieves leading results in both geometric and texture evaluation metrics across more flexible input viewpoints.

</details>


### [87] [GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction](https://arxiv.org/abs/2511.12204)
*Jiaqi Wu,Yaosen Chen,Shuyuan Zhu*

Main category: cs.CV

TL;DR: 本研究提出了一种几何引导的多视图扩散模型，通过整合几何信息提取、解耦的几何增强注意力机制、自适应学习策略和迭代优化过程，解决了现有单图像扩展方法在跨视图一致性和高分辨率生成上面临的计算挑战，从而生成细节丰富且视图间一致的多视图图像。


<details>
  <summary>Details</summary>
Motivation: 现有基于单图像扩展的多视图生成方法在保持跨视图一致性和生成高分辨率图像方面存在计算挑战。

Method: 提出几何引导的多视图扩散模型，包含：1.多视图几何信息提取模块（利用深度图、法线图、前景分割掩模构建共享几何结构）。2.解耦的几何增强注意力机制（增强模型对关键几何细节的关注）。3.自适应学习策略（优化生成视图间的空间关系和视觉连贯性）。4.迭代优化过程（多阶段逐步提升图像质量）。5.动态几何信息强度调整机制（自适应调节几何数据的影响）。

Result: 生成的图像在视图间保持一致，并且细节丰富，提高了图像质量和细节保留能力。

Conclusion: 几何引导的多视图扩散模型有效解决了现有方法的局限性，能够生成高质量、视图间一致且细节丰富的多视图图像。

Abstract: Multi-view image generation holds significant application value in computer vision, particularly in domains like 3D reconstruction, virtual reality, and augmented reality. Most existing methods, which rely on extending single images, face notable computational challenges in maintaining cross-view consistency and generating high-resolution outputs. To address these issues, we propose the Geometry-guided Multi-View Diffusion Model, which incorporates mechanisms for extracting multi-view geometric information and adjusting the intensity of geometric features to generate images that are both consistent across views and rich in detail. Specifically, we design a multi-view geometry information extraction module that leverages depth maps, normal maps, and foreground segmentation masks to construct a shared geometric structure, ensuring shape and structural consistency across different views. To enhance consistency and detail restoration during generation, we develop a decoupled geometry-enhanced attention mechanism that strengthens feature focus on key geometric details, thereby improving overall image quality and detail preservation. Furthermore, we apply an adaptive learning strategy that fine-tunes the model to better capture spatial relationships and visual coherence between the generated views, ensuring realistic results. Our model also incorporates an iterative refinement process that progressively improves the output quality through multiple stages of image generation. Finally, a dynamic geometry information intensity adjustment mechanism is proposed to adaptively regulate the influence of geometric data, optimizing overall quality while ensuring the naturalness of generated images. More details can be found on the project page: https://github.com/SobeyMIL/GeoMVD.com.

</details>


### [88] [A Novel AI-Driven System for Real-Time Detection of Mirror Absence, Helmet Non-Compliance, and License Plates Using YOLOv8 and OCR](https://arxiv.org/abs/2511.12206)
*Nishant Vasantkumar Hegde,Aditi Agarwal,Minal Moharir*

Main category: cs.CV

TL;DR: 本研究提出一个AI系统，利用YOLOv8和EasyOCR技术自动检测摩托车未戴头盔和缺少后视镜的违规行为，并通过OCR识别车牌，旨在提高执法效率和道路安全。


<details>
  <summary>Details</summary>
Motivation: 手动执法摩托车头盔佩戴和车辆安全标准（如后视镜）耗时耗力且不一致，亟需自动化解决方案以提高执法效率和道路安全。

Method: 使用YOLOv8进行物体检测，EasyOCR进行车牌识别。对自定义数据集进行增强训练，以识别未戴头盔、缺少后视镜的违规行为并提取车牌号码。采用Streamlit构建用户界面，并进行图像预处理以提高车牌识别能力。

Result: 模型在评估中达到0.9147的总体精确率，0.886的召回率，以及0.843的mAP@50。mAP@50 95为0.503，表明在更严格的IoU阈值下仍有强大的检测能力。

Conclusion: 该研究展示了一个实际有效且可部署的自动化交通违规执法解决方案，能够显著提升道路安全和执法效率。

Abstract: Road safety is a critical global concern, with manual enforcement of helmet laws and vehicle safety standards (e.g., rear-view mirror presence) being resource-intensive and inconsistent. This paper presents an AI-powered system to automate traffic violation detection, significantly enhancing enforcement efficiency and road safety. The system leverages YOLOv8 for robust object detection and EasyOCR for license plate recognition. Trained on a custom dataset of annotated images (augmented for diversity), it identifies helmet non-compliance, the absence of rear-view mirrors on motorcycles, an innovative contribution to automated checks, and extracts vehicle registration numbers. A Streamlit-based interface facilitates real-time monitoring and violation logging. Advanced image preprocessing enhances license plate recognition, particularly under challenging conditions. Based on evaluation results, the model achieves an overall precision of 0.9147, a recall of 0.886, and a mean Average Precision (mAP@50) of 0.843. The mAP@50 95 of 0.503 further indicates strong detection capability under stricter IoU thresholds. This work demonstrates a practical and effective solution for automated traffic rule enforcement, with considerations for real-world deployment discussed.

</details>


### [89] [Mixture of States: Routing Token-Level Dynamics for Multimodal Generation](https://arxiv.org/abs/2511.12207)
*Haozhe Liu,Ding Liu,Mingchen Zhuge,Zijian Zhou,Tian Xie,Sen He,Yukang Yang,Shuming Liu,Yuren Cong,Jiadong Guo,Hongyu Xu,Ke Xu,Kam-Woh Ng,Juan C. Pérez,Juan-Manuel~Pérez-Rúa,Tao Xiang,Wei Liu,Shikun Liu,Jürgen Schmidhuber*

Main category: cs.CV

TL;DR: MoS是一种新颖的多模态融合范式，用于扩散模型，通过基于状态的交互来融合模态。它使用一个可学习的、逐令牌的路由器，该路由器根据去噪时间步和输入创建模态隐藏状态之间的交互，从而实现令牌级特征与扩散轨迹的精确对齐。该路由器采用ε-greedy策略进行训练，以最少的参数和可忽略的计算开销，有效地选择上下文特征。MoS在文本到图像生成和编辑任务上达到了最先进的性能，并且参数量更少。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的多模态融合范式，用于扩散模型，以实现更灵活、更高效的模态交互和特征对齐。

Method: 引入MoS（Mixture of States）框架，其核心是一个可学习的、逐令牌的路由器，该路由器根据去噪时间步和输入动态地选择和交互模态的隐藏状态，采用ε-greedy策略进行训练。

Result: 在文本到图像生成和编辑任务上取得了最先进的性能，并且在参数量较少的情况下（3B-5B）能够媲美甚至超越参数量大4倍的同类模型。

Conclusion: MoS是一种灵活且计算高效的范式，适用于扩展多模态扩散模型。

Abstract: We introduce MoS (Mixture of States), a novel fusion paradigm for multimodal diffusion models that merges modalities using flexible, state-based interactions. The core of MoS is a learnable, token-wise router that creates denoising timestep- and input-dependent interactions between modalities' hidden states, precisely aligning token-level features with the diffusion trajectory. This router sparsely selects the top-$k$ hidden states and is trained with an $ε$-greedy strategy, efficiently selecting contextual features with minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to $4\times$ larger. These findings establish MoS as a flexible and compute-efficient paradigm for scaling multimodal diffusion models.

</details>


### [90] [FaNe: Towards Fine-Grained Cross-Modal Contrast with False-Negative Reduction and Text-Conditioned Sparse Attention](https://arxiv.org/abs/2511.12215)
*Peng Zhang,Zhihui Lai,Wenting Chen,Xu Wu,Heng Kong*

Main category: cs.CV

TL;DR: FaNe框架通过语义感知正例挖掘和文本条件稀疏注意力池化模块，解决了医疗VLP中的假阴性问题和跨模态对齐不足问题，在多个下游任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗视觉语言预训练（VLP）方法受到语义相似文本引起的假阴性（FaNe）和不足的细粒度跨模态对齐的限制。

Method: 提出了一种名为FaNe的语义增强VLP框架。通过基于文本-文本相似度的自适应归一化策略来挖掘语义感知的正例对，以减轻假阴性。设计了一个文本条件稀疏注意力池化模块，通过文本线索引导的局部视觉表示来实现细粒度的图像-文本对齐。开发了一种硬负例感知对比损失，以自适应地重新加权语义相似的负例，从而增强模态内区分。 

Result: 在五个下游医疗成像基准测试中，FaNe在图像分类、目标检测和语义分割方面均取得了最先进的性能。

Conclusion: FaNe框架通过解决假阴性和增强细粒度对齐问题，有效提升了医疗VLP的性能，并在多个下游任务上取得了SOTA成果。

Abstract: Medical vision-language pre-training (VLP) offers significant potential for advancing medical image understanding by leveraging paired image-report data. However, existing methods are limited by Fa}lse Negatives (FaNe) induced by semantically similar texts and insufficient fine-grained cross-modal alignment. To address these limitations, we propose FaNe, a semantic-enhanced VLP framework. To mitigate false negatives, we introduce a semantic-aware positive pair mining strategy based on text-text similarity with adaptive normalization. Furthermore, we design a text-conditioned sparse attention pooling module to enable fine-grained image-text alignment through localized visual representations guided by textual cues. To strengthen intra-modal discrimination, we develop a hard-negative aware contrastive loss that adaptively reweights semantically similar negatives. Extensive experiments on five downstream medical imaging benchmarks demonstrate that FaNe achieves state-of-the-art performance across image classification, object detection, and semantic segmentation, validating the effectiveness of our framework.

</details>


### [91] [Suppressing VLM Hallucinations with Spectral Representation Filtering](https://arxiv.org/abs/2511.12220)
*Ameen Ali,Tamim Zoabi,Lior Wolf*

Main category: cs.CV

TL;DR: VLMs 容易产生幻觉，因为它们过度依赖语言先验和不精确的跨模态关联。我们提出了一种名为 Spectral Representation Filtering (SRF) 的方法，这是一种轻量级、无需训练的后处理技术，用于分析和纠正模型表示的协方差结构，从而抑制幻觉。SRF 通过对真实和幻觉字幕的特征之间的协方差进行特征值分解来识别低秩幻觉模式，揭示了特征空间中的结构化偏差。然后，一个软谱滤波器会削弱这些模式在更深层 vLLM 层的馈入投影权重，从而在保持语义保真度的同时均衡特征方差。SRF 是一种纯粹的后处理方法，不涉及解码或再训练，并且不会增加推理开销或需要架构修改。在 LLaVA-1.5、MiniGPT-4 和 mPLUG-Owl2 等 VLM 系列上，SRF 在 MSCOCO、POPE-VQA 等视觉任务基准上持续降低幻觉率，在不损害字幕质量的情况下实现了最先进的忠实度。


<details>
  <summary>Details</summary>
Motivation: Vision-language models (VLMs) 经常产生幻觉，这是因为它们过度依赖语言先验和不精确的跨模态关联。

Method: SRF 通过分析和纠正模型表示的协方差结构来抑制幻觉。它通过对真实和幻觉字幕的特征之间的协方差进行特征值分解来识别低秩幻觉模式，揭示了特征空间中的结构化偏差。然后，一个软谱滤波器会削弱这些模式在更深层 vLLM 层的馈入投影权重，从而在保持语义保真度的同时均衡特征方差。

Result: SRF 在 LLaVA-1.5、MiniGPT-4 和 mPLUG-Owl2 等 VLM 系列上，在 MSCOCO、POPE-VQA 等视觉任务基准上持续降低幻觉率，实现了最先进的忠实度，同时没有降低字幕质量。

Conclusion: SRF 是一种有效的、无需训练的后处理方法，可以减轻 VLM 中的幻觉，其性能优于现有的方法，并且不会带来额外的推理开销或需要架构修改。

Abstract: Vision-language models (VLMs) frequently produce hallucinations in the form of descriptions of objects, attributes, or relations that do not exist in the image due to over-reliance on language priors and imprecise cross-modal grounding. We introduce Spectral Representation Filtering (SRF), a lightweight, training-free method to suppress such hallucinations by analyzing and correcting the covariance structure of the model's representations. SRF identifies low-rank hallucination modes through eigendecomposition of the covariance of the differences between features collected for truthful and hallucinatory captions, revealing structured biases in the feature space. A soft spectral filter then attenuates these modes in the feed-forward projection weights of deeper vLLM layers, equalizing feature variance while preserving semantic fidelity. Unlike decoding or retraining-based approaches, SRF operates entirely post-hoc, incurs zero inference overhead, and requires no architectural modifications. Across three families of VLMs (LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2), SRF consistently reduces hallucination rates on MSCOCO, POPE-VQA, and other visual tasks benchmarks, achieving state-of-the-art faithfulness without degrading caption quality.

</details>


### [92] [Model Inversion Attack Against Deep Hashing](https://arxiv.org/abs/2511.12233)
*Dongdong Zhao,Qiben Xu,Ranxin Fang,Baogang Song*

Main category: cs.CV

TL;DR: 深度哈希模型存在严重隐私风险，攻击者可能通过哈希码重建原始训练数据，导致身份伪造和隐私泄露。本研究提出首个针对深度哈希的扩散模型反演框架DHMI，通过聚类辅助数据集获得语义哈希中心，并引入一种新颖的攻击指标（融合分类一致性和哈希邻近性）来指导去噪优化，从而在黑盒设置下成功重建高分辨率、高质量的图像，证明了深度哈希系统的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 深度哈希模型在提高检索效率的同时，带来了严重且常被忽视的隐私风险。攻击者可能通过哈希码重建原始训练数据，引发身份伪造和隐私泄露。然而，针对深度哈希模型的模型反演攻击尚未被充分研究，其安全影响有待审视。

Method: 提出首个针对深度哈希的扩散模型反演框架DHMI。DHMI首先通过聚类辅助数据集获得语义哈希中心作为替代锚点。然后，引入一种替代引导的去噪优化方法，利用新颖的攻击指标（融合分类一致性和哈希邻近性）来动态选择候选样本。最后，通过一组替代模型指导这些候选样本的精炼，确保生成高保真且语义一致的图像。

Result: 在多个数据集上的实验表明，DHMI即使在没有任何训练哈希码可用、最具挑战性的黑盒设置下，也能成功重建高分辨率、高质量的图像。与现有的黑盒场景下的模型反演攻击相比，DHMI表现更优，证明了其有效性和深度哈希系统固有的严峻隐私风险。

Conclusion: DHMI是首个针对深度哈希的扩散模型反演框架，能够有效重建图像并揭示深度哈希系统的隐私风险。在黑盒设置下，DHMI的性能优于现有最先进的模型反演攻击方法。

Abstract: Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.

</details>


### [93] [Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets](https://arxiv.org/abs/2511.12255)
*Huy M. Le,Dat Tien Nguyen,Phuc Binh Nguyen,Gia-Bao Le-Tran,Phu Truong Thien,Cuong Dinh,Minh Nguyen,Nga Nguyen,Thuy T. N. Nguyen,Huy Gia Ngo,Tan Nhat Nguyen,Binh T. Nguyen,Monojit Choudhury*

Main category: cs.CV

TL;DR: Fusionista2.0是一个为视频检索设计的、经过优化的、快速且用户友好的系统，其核心模块经过重新设计以提高效率，从而在视频浏览器挑战赛（VBS）等严苛条件下实现准确的检索。


<details>
  <summary>Details</summary>
Motivation: 为了满足视频浏览器挑战赛（VBS）在严格的时间限制下进行准确检索的要求，需要一个优化速度和可用性的视频检索系统。

Method: Fusionista2.0对所有核心模块进行了效率再工程：预处理利用ffmpeg进行快速关键帧提取，OCR采用Vintern-1B-v3.5进行多语言文本识别，ASR使用faster-whisper进行实时转录。问答部分则采用轻量级视觉-语言模型以降低成本。此外，还重新设计了用户界面以提高响应速度、可访问性和工作流效率。

Result: 与之前的版本相比，Fusionista2.0将检索时间缩短了高达75%，同时提高了准确性和用户满意度。

Conclusion: Fusionista2.0通过技术升级和用户界面改进，成为一个有竞争力且用户友好的大规模视频搜索系统，能够快速检索相关内容。

Abstract: The Video Browser Showdown (VBS) challenges systems to deliver accurate results under strict time constraints. To meet this demand, we present Fusionista2.0, a streamlined video retrieval system optimized for speed and usability. All core modules were re-engineered for efficiency: preprocessing now relies on ffmpeg for fast keyframe extraction, optical character recognition uses Vintern-1B-v3.5 for robust multilingual text recognition, and automatic speech recognition employs faster-whisper for real-time transcription. For question answering, lightweight vision-language models provide quick responses without the heavy cost of large models. Beyond these technical upgrades, Fusionista2.0 introduces a redesigned user interface with improved responsiveness, accessibility, and workflow efficiency, enabling even non-expert users to retrieve relevant content rapidly. Evaluations demonstrate that retrieval time was reduced by up to 75% while accuracy and user satisfaction both increased, confirming Fusionista2.0 as a competitive and user-friendly system for large-scale video search.

</details>


### [94] [Prompt-Conditioned FiLM and Multi-Scale Fusion on MedSigLIP for Low-Dose CT Quality Assessment](https://arxiv.org/abs/2511.12256)
*Tolga Demiroglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出一个基于MedSigLIP的、由文本提示条件化的框架，通过FiLM和多尺度池化注入文本先验，以实现数据高效学习和快速适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据效率和快速适应性方面存在不足，需要一种能够注入文本先验以指导模型学习的方法。

Method: 提出一个基于MedSigLIP的框架，使用FiLM和多尺度（全局、局部、纹理感知）池化来注入文本提示的先验知识，并通过轻量级MLP和成对排序损失进行训练。

Result: 在LDCTIQA2023数据集上，使用1000张训练图像，取得了PLCC = 0.9575, SROCC = 0.9561, KROCC = 0.8301的性能，超越了公开的挑战赛的顶尖提交结果。

Conclusion: 所提出的文本提示引导方法在低剂量CT图像质量评估任务上是有效的，并且能够实现数据高效学习和快速适应。

Abstract: We propose a prompt-conditioned framework built on MedSigLIP that injects textual priors via Feature-wise Linear Modulation (FiLM) and multi-scale pooling. Text prompts condition patch-token features on clinical intent, enabling data-efficient learning and rapid adaptation. The architecture combines global, local, and texture-aware pooling through separate regression heads fused by a lightweight MLP, trained with pairwise ranking loss. Evaluated on the LDCTIQA2023 (a public LDCT quality assessment challenge) with 1,000 training images, we achieve PLCC = 0.9575, SROCC = 0.9561, and KROCC = 0.8301, surpassing the top-ranked published challenge submissions and demonstrating the effectiveness of our prompt-guided approach.

</details>


### [95] [A Disease-Aware Dual-Stage Framework for Chest X-ray Report Generation](https://arxiv.org/abs/2511.12259)
*Puzhen Wu,Hexin Dong,Yi Lin,Yihao Ding,Yifan Peng*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的双阶段、疾病感知的框架，用于从胸部X光片生成放射学报告，旨在提高临床准确性和语言质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在疾病感知视觉表示和视觉-语言对齐方面存在不足，导致模型忽略关键病理特征并生成不准确的报告。

Method: 该框架分为两个阶段：第一阶段学习与特定病理类别对应的疾病感知语义标记（DAST），并通过跨注意力和多标签分类进行训练，同时利用对比学习对齐视觉和语言表示。第二阶段引入疾病-视觉注意力融合（DVAF）模块整合疾病感知表示和视觉特征，并使用双模态相似性检索（DMSR）机制结合视觉和疾病特定相似性来检索相关样本，为报告生成提供上下文指导。

Result: 在CheXpert Plus、IU X-ray和MIMIC-CXR等基准数据集上进行的大量实验表明，该疾病感知框架在胸部X光片报告生成方面取得了最先进的性能。

Conclusion: 所提出的疾病感知框架显著提高了胸部X光片报告生成的临床准确性和语言质量。

Abstract: Radiology report generation from chest X-rays is an important task in artificial intelligence with the potential to greatly reduce radiologists' workload and shorten patient wait times. Despite recent advances, existing approaches often lack sufficient disease-awareness in visual representations and adequate vision-language alignment to meet the specialized requirements of medical image analysis. As a result, these models usually overlook critical pathological features on chest X-rays and struggle to generate clinically accurate reports. To address these limitations, we propose a novel dual-stage disease-aware framework for chest X-ray report generation. In Stage~1, our model learns Disease-Aware Semantic Tokens (DASTs) corresponding to specific pathology categories through cross-attention mechanisms and multi-label classification, while simultaneously aligning vision and language representations via contrastive learning. In Stage~2, we introduce a Disease-Visual Attention Fusion (DVAF) module to integrate disease-aware representations with visual features, along with a Dual-Modal Similarity Retrieval (DMSR) mechanism that combines visual and disease-specific similarities to retrieve relevant exemplars, providing contextual guidance during report generation. Extensive experiments on benchmark datasets (i.e., CheXpert Plus, IU X-ray, and MIMIC-CXR) demonstrate that our disease-aware framework achieves state-of-the-art performance in chest X-ray report generation, with significant improvements in clinical accuracy and linguistic quality.

</details>


### [96] [CrossVid: A Comprehensive Benchmark for Evaluating Cross-Video Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2511.12263)
*Jingyao Li,Jingyun Wang,Molin Tan,Haochen Wang,Cilin Yan,Likun Shi,Jiayin Cai,Xiaolong Jiang,Yao Hu*

Main category: cs.CV

TL;DR: CrossVid 是首个用于评估多模态大语言模型 (MLLMs) 跨视频推理能力的基准，包含了 5331 个视频和 9015 个问答对，任务涵盖四个维度和十个具体任务，旨在解决现有基准在 CVR 场景评估中的不足。实验表明，Gemini-2.5-Pro 在该基准上表现最佳，但大多数 MLLMs 仍难以有效整合和比较来自多个视频的证据进行推理。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要关注单视频分析，未能充分评估 MLLMs 在跨视频推理 (CVR) 方面的能力，尤其是在需要聚合和比较多视频信息时。现有的多视角视频基准任务有限，也无法全面反映真实世界的 CVR 场景。

Method: 提出 CrossVid 基准，该基准包含 5331 个视频和 9015 个问答对（单选、多选、开放式），涵盖了四个高层维度和十个具体任务，以全面评估 MLLMs 的空间-时间推理能力。在 CrossVid 上进行了广泛的实验，以评估各种 MLLMs 的性能，并通过案例研究深入分析了模型在 CVR 任务中的表现。

Result: 在 CrossVid 基准上，Gemini-2.5-Pro 取得了最佳平均准确率 50.4%。案例研究发现，当前大多数 MLLMs 在 CVR 任务中表现不佳，主要原因是它们难以整合或比较分布在多个视频中的证据来进行推理。

Conclusion: CrossVid 是一个全面的 CVR 基准，可用于评估和指导 MLLMs 的发展。现有 MLLMs 在 CVR 任务上面临严峻挑战，主要瓶颈在于跨视频信息整合与比较能力不足，这为未来 MLLMs 在 CVR 领域的研究指明了方向。

Abstract: Cross-Video Reasoning (CVR) presents a significant challenge in video understanding, which requires simultaneous understanding of multiple videos to aggregate and compare information across groups of videos. Most existing video understanding benchmarks focus on single-video analysis, failing to assess the ability of multimodal large language models (MLLMs) to simultaneously reason over various videos. Recent benchmarks evaluate MLLMs' capabilities on multi-view videos that capture different perspectives of the same scene. However, their limited tasks hinder a thorough assessment of MLLMs in diverse real-world CVR scenarios. To this end, we introduce CrossVid, the first benchmark designed to comprehensively evaluate MLLMs' spatial-temporal reasoning ability in cross-video contexts. Firstly, CrossVid encompasses a wide spectrum of hierarchical tasks, comprising four high-level dimensions and ten specific tasks, thereby closely reflecting the complex and varied nature of real-world video understanding. Secondly, CrossVid provides 5,331 videos, along with 9,015 challenging question-answering pairs, spanning single-choice, multiple-choice, and open-ended question formats. Through extensive experiments on various open-source and closed-source MLLMs, we observe that Gemini-2.5-Pro performs best on CrossVid, achieving an average accuracy of 50.4%. Notably, our in-depth case study demonstrates that most current MLLMs struggle with CVR tasks, primarily due to their inability to integrate or compare evidence distributed across multiple videos for reasoning. These insights highlight the potential of CrossVid to guide future advancements in enhancing MLLMs' CVR capabilities.

</details>


### [97] [ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks](https://arxiv.org/abs/2511.12267)
*Ruixun Liu,Bowen Fu,Jiayi Song,Kaiyu Li,Wanchen Li,Lanxuan Xue,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.CV

TL;DR: 本文提出了一种新的主动感知范式，用于处理超高分辨率遥感图像，并介绍了LRS-GRO数据集和ZoomEarth框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理超高分辨率遥感图像时存在冗余问题，需要一种更主动的感知方式。

Method: 提出LRS-GRO数据集和ZoomEarth框架，采用Region-Guided奖励、SFT和GRPO进行训练。

Result: ZoomEarth在LRS-GRO和三个公共UHR遥感基准上都取得了最先进的性能，并在零样本设置下表现出色。

Conclusion: ZoomEarth框架具有很强的通用性和可扩展性，可以无缝集成到各种下游任务中。

Abstract: Ultra-high-resolution (UHR) remote sensing (RS) images offer rich fine-grained information but also present challenges in effective processing. Existing dynamic resolution and token pruning methods are constrained by a passive perception paradigm, suffering from increased redundancy when obtaining finer visual inputs. In this work, we explore a new active perception paradigm that enables models to revisit information-rich regions. First, we present LRS-GRO, a large-scale benchmark dataset tailored for active perception in UHR RS processing, encompassing 17 question types across global, region, and object levels, annotated via a semi-automatic pipeline. Building on LRS-GRO, we propose ZoomEarth, an adaptive cropping-zooming framework with a novel Region-Guided reward that provides fine-grained guidance. Trained via supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), ZoomEarth achieves state-of-the-art performance on LRS-GRO and, in the zero-shot setting, on three public UHR remote sensing benchmarks. Furthermore, ZoomEarth can be seamlessly integrated with downstream models for tasks such as cloud removal, denoising, segmentation, and image editing through simple tool interfaces, demonstrating strong versatility and extensibility.

</details>


### [98] [TM-UNet: Token-Memory Enhanced Sequential Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.12270)
*Yaxuan Jiao,Qing Xu,Yuxiang Luo,Xiangjian He,Zhen Chen,Wenting Duan*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Medical image segmentation is essential for clinical diagnosis and treatment planning. Although transformer-based methods have achieved remarkable results, their high computational cost hinders clinical deployment. To address this issue, we propose TM-UNet, a novel lightweight framework that integrates token sequence modeling with an efficient memory mechanism for efficient medical segmentation. Specifically, we introduce a multi-scale token-memory (MSTM) block that transforms 2D spatial features into token sequences through strategic spatial scanning, leveraging matrix memory cells to selectively retain and propagate discriminative contextual information across tokens. This novel token-memory mechanism acts as a dynamic knowledge store that captures long-range dependencies with linear complexity, enabling efficient global reasoning without redundant computation. Our MSTM block further incorporates exponential gating to identify token effectiveness and multi-scale contextual extraction via parallel pooling operations, enabling hierarchical representation learning without computational overhead. Extensive experiments demonstrate that TM-UNet outperforms state-of-the-art methods across diverse medical segmentation tasks with substantially reduced computation cost. The code is available at https://github.com/xq141839/TM-UNet.

</details>


### [99] [D$^{3}$ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs](https://arxiv.org/abs/2511.12280)
*Shuochen Chang,Xiaofeng Zhang,Qingyang Liu,Li Niu*

Main category: cs.CV

TL;DR: D3ToM是一种引导式动态令牌合并方法，可加速扩散多模态大语言模型的推理，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 扩散多模态大语言模型（Diffusion MLLMs）在视觉和语言任务中展现出强大的非自回归生成能力，但其推理速度比自回归模型慢得多，因为每个去噪步骤都需要对整个序列进行完全的双向自注意力计算，导致立方解码复杂度，这在处理数千个视觉令牌时计算上不切实际。

Method: D3ToM采用引导式动态令牌合并方法，在不同的去噪步骤中动态合并冗余的视觉令牌以加速Diffusion MLLMs的推理。在每个去噪步骤中，D3ToM利用前一个去噪步骤生成的引导令牌来构建所有视觉令牌的重要性图，然后保留一部分最显著的令牌，并通过基于相似度的聚合来合并剩余的令牌。该模块可插入单个Transformer层，在不改变模型参数的情况下，实际缩短了所有后续层的视觉令牌序列。此外，D3ToM采用与每个去噪步骤动态变化的合并比率，与Diffusion MLLMs的本地解码过程保持一致。

Result: 通过大量实验证明，D3ToM在加速推理的同时保持了具有竞争力的性能。

Conclusion: D3ToM通过动态合并冗余视觉令牌，有效解决了Diffusion MLLMs推理速度慢的问题，实现了加速和性能的平衡。

Abstract: Diffusion-based multimodal large language models (Diffusion MLLMs) have recently demonstrated impressive non-autoregressive generative capabilities across vision-and-language tasks. However, Diffusion MLLMs exhibit substantially slower inference than autoregressive models: Each denoising step employs full bidirectional self-attention over the entire sequence, resulting in cubic decoding complexity that becomes computationally impractical with thousands of visual tokens. To address this challenge, we propose D$^{3}$ToM, a Decider-guided dynamic token merging method that dynamically merges redundant visual tokens at different denoising steps to accelerate inference in Diffusion MLLMs. At each denoising step, D$^{3}$ToM uses decider tokens-the tokens generated in the previous denoising step-to build an importance map over all visual tokens. Then it maintains a proportion of the most salient tokens and merges the remainder through similarity-based aggregation. This plug-and-play module integrates into a single transformer layer, physically shortening the visual token sequence for all subsequent layers without altering model parameters. Moreover, D$^{3}$ToM employs a merge ratio that dynamically varies with each denoising step, aligns with the native decoding process of Diffusion MLLMs, achieving superior performance under equivalent computational budgets. Extensive experiments show that D$^{3}$ToM accelerates inference while preserving competitive performance. The code is released at https://github.com/bcmi/D3ToM-Diffusion-MLLM.

</details>


### [100] [One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving](https://arxiv.org/abs/2511.12291)
*Andrea Bertogalli,Giacomo Boracchi,Luca Magri*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的多模态外参标定框架，能够同时估计事件相机、LiDAR 和 RGB 相机之间的相对位姿，特别关注事件相机的标定。


<details>
  <summary>Details</summary>
Motivation: 现有的多传感器标定方法通常依赖于成对的标定，而没有考虑事件相机。本研究旨在开发一种能够同时标定这三种传感器的框架。

Method: 使用一种新颖的 3D 标定目标，该目标包含平面、ChArUco 和 LED 模式，可被所有三种传感器感知。通过单次联合标定过程来估计传感器之间的外参。

Result: 通过在自定义数据集上进行的大量实验验证，证明了该方法的准确性和鲁棒性。

Conclusion: 所提出的框架能够准确、鲁棒地完成事件相机、LiDAR 和 RGB 相机的联合外参标定，这对于自动驾驶等应用至关重要。

Abstract: We present a novel multi-modal extrinsic calibration framework designed to simultaneously estimate the relative poses between event cameras, LiDARs, and RGB cameras, with particular focus on the challenging event camera calibration. Core of our approach is a novel 3D calibration target, specifically designed and constructed to be concurrently perceived by all three sensing modalities. The target encodes features in planes, ChArUco, and active LED patterns, each tailored to the unique characteristics of LiDARs, RGB cameras, and event cameras respectively. This unique design enables a one-shot, joint extrinsic calibration process, in contrast to existing approaches that typically rely on separate, pairwise calibrations. Our calibration pipeline is designed to accurately calibrate complex vision systems in the context of autonomous driving, where precise multi-sensor alignment is critical. We validate our approach through an extensive experimental evaluation on a custom built dataset, recorded with an advanced autonomous driving sensor setup, confirming the accuracy and robustness of our method.

</details>


### [101] [Rethinking Bias in Generative Data Augmentation for Medical AI: a Frequency Recalibration Method](https://arxiv.org/abs/2511.12301)
*Chi Liu,Jincheng Liu,Congcong Zhu,Minghao Wang,Sheng Shen,Jia Gu,Tianqing Zhu,Wanlei Zhou*

Main category: cs.CV

TL;DR: 生成数据增强（GDA）在医学图像领域存在数据稀疏性问题，但可能引入偏差。本文提出频率校准（FreRec）方法，通过（1）统计高频替换（SHR）和（2）重建高频映射（RHM）来解决GDA中的频率失准问题，提高合成图像的可靠性。实验证明，FreRec能显著提升下游医学图像分类性能，且可兼容任何生成模型。


<details>
  <summary>Details</summary>
Motivation: 医学AI发展面临数据稀缺性挑战，生成数据增强（GDA）虽能合成图像，但易引入偏差，损害下游任务。本文旨在解决GDA中频率分布不匹配的问题。

Method: 提出频率校准（FreRec）方法，包括统计高频替换（SHR）和重建高频映射（RHM），以减少合成图像与真实图像之间的高频成分差异。

Result: 在脑部MRI、胸部X光和眼底图像等多个医学数据集上进行的大量实验表明，与未经校准的AI合成样本相比，FreRec显著提高了下游医学图像分类性能。

Conclusion: FreRec是一种独立的后处理步骤，可与任何生成模型兼容，并能无缝集成到常见的医学GDA流程中，有效解决了GDA中的频率失准问题，提高了医学图像合成的可靠性。

Abstract: Developing Medical AI relies on large datasets and easily suffers from data scarcity. Generative data augmentation (GDA) using AI generative models offers a solution to synthesize realistic medical images. However, the bias in GDA is often underestimated in medical domains, with concerns about the risk of introducing detrimental features generated by AI and harming downstream tasks. This paper identifies the frequency misalignment between real and synthesized images as one of the key factors underlying unreliable GDA and proposes the Frequency Recalibration (FreRec) method to reduce the frequency distributional discrepancy and thus improve GDA. FreRec involves (1) Statistical High-frequency Replacement (SHR) to roughly align high-frequency components and (2) Reconstructive High-frequency Mapping (RHM) to enhance image quality and reconstruct high-frequency details. Extensive experiments were conducted in various medical datasets, including brain MRIs, chest X-rays, and fundus images. The results show that FreRec significantly improves downstream medical image classification performance compared to uncalibrated AI-synthesized samples. FreRec is a standalone post-processing step that is compatible with any generative model and can integrate seamlessly with common medical GDA pipelines.

</details>


### [102] [LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors](https://arxiv.org/abs/2511.12304)
*Qifeng Chen,Jiarun Liu,Rengan Xie,Tao Tang,Sicong Du,Yiru Zhao,Yuchi Huo,Sheng Yang*

Main category: cs.CV

TL;DR: GS-based rendering 渲染技术在 LiDAR 领域取得进展，但单次扫描重建不完整会导致新视角合成出现伪影。LiDAR-GS++ 通过引入扩散先验来增强 LiDAR 高斯渲染，解决了这一问题，可在实时和高保真度下进行城市道路的重新模拟。该方法通过条件化粗略外插渲染的可控 LiDAR 生成模型来生成额外的几何一致性扫描，并采用有效的蒸馏机制进行扩展重建，以确保外插新视角的全局几何一致性，同时保留传感器捕获的细节。实验证明，LiDAR-GS++ 在插值和外插视角下均达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 GS 的渲染方法在 LiDAR 新视角合成中存在伪影问题，因为单次扫描重建不完整。

Method: 提出 LiDAR-GS++，一种通过扩散先验增强的 LiDAR 高斯渲染方法。引入可控 LiDAR 生成模型，以粗略外插渲染为条件，生成额外的几何一致性扫描，并采用有效的蒸馏机制进行扩展重建。

Result: LiDAR-GS++ 扩展了重建范围，解决了欠拟合区域的问题，确保了外插新视角的全局几何一致性，同时保留了传感器捕获的详细场景表面。在多个公共数据集上的实验表明，LiDAR-GS++ 在插值和外插视角下均取得了最先进的性能。

Conclusion: LiDAR-GS++ 通过结合扩散先验和 LiDAR 高斯渲染，有效解决了现有方法的局限性，实现了高质量、高保真的 LiDAR 新视角合成。

Abstract: Recent GS-based rendering has made significant progress for LiDAR, surpassing Neural Radiance Fields (NeRF) in both quality and speed. However, these methods exhibit artifacts in extrapolated novel view synthesis due to the incomplete reconstruction from single traversal scans. To address this limitation, we present LiDAR-GS++, a LiDAR Gaussian Splatting reconstruction method enhanced by diffusion priors for real-time and high-fidelity re-simulation on public urban roads. Specifically, we introduce a controllable LiDAR generation model conditioned on coarsely extrapolated rendering to produce extra geometry-consistent scans and employ an effective distillation mechanism for expansive reconstruction. By extending reconstruction to under-fitted regions, our approach ensures global geometric consistency for extrapolative novel views while preserving detailed scene surfaces captured by sensors. Experiments on multiple public datasets demonstrate that LiDAR-GS++ achieves state-of-the-art performance for both interpolated and extrapolated viewpoints, surpassing existing GS and NeRF-based methods.

</details>


### [103] [Learning Time in Static Classifiers](https://arxiv.org/abs/2511.12321)
*Xi Ding,Lei Wang,Piotr Koniusz,Yongsheng Gao*

Main category: cs.CV

TL;DR: 通过引入支持-示例-查询（SEQ）学习范式，在不修改模型架构或引入循环模块的情况下，为前馈分类器增加了时间推理能力，从而在静态和时间任务中都取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 传统分类器假设时间独立性，难以捕捉数据随时间变化的动态，限制了其在现实世界视觉数据上的表现。

Method: 提出了一种新颖的支持-示例-查询（SEQ）学习范式，将训练数据构建成时间连贯的轨迹，学习特定类别的时序原型，并通过可微的soft-DTW损失对预测序列进行对齐，同时使用多项式目标函数来增强语义一致性和时间平滑性。

Result: 在图像分类任务（包括细粒度和超细粒度）上提升了性能，并在视频异常检测任务中实现了精确且时间一致的预测。

Conclusion: 该方法通过损失函数设计引入了强大的时间归纳偏置，能够以模块化、数据高效的方式融合静态和时间学习，仅需在预提取的特征之上添加一个简单的分类器即可。

Abstract: Real-world visual data rarely presents as isolated, static instances. Instead, it often evolves gradually over time through variations in pose, lighting, object state, or scene context. However, conventional classifiers are typically trained under the assumption of temporal independence, limiting their ability to capture such dynamics. We propose a simple yet effective framework that equips standard feedforward classifiers with temporal reasoning, all without modifying model architectures or introducing recurrent modules. At the heart of our approach is a novel Support-Exemplar-Query (SEQ) learning paradigm, which structures training data into temporally coherent trajectories. These trajectories enable the model to learn class-specific temporal prototypes and align prediction sequences via a differentiable soft-DTW loss. A multi-term objective further promotes semantic consistency and temporal smoothness. By interpreting input sequences as evolving feature trajectories, our method introduces a strong temporal inductive bias through loss design alone. This proves highly effective in both static and temporal tasks: it enhances performance on fine-grained and ultra-fine-grained image classification, and delivers precise, temporally consistent predictions in video anomaly detection. Despite its simplicity, our approach bridges static and temporal learning in a modular and data-efficient manner, requiring only a simple classifier on top of pre-extracted features.

</details>


### [104] [SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models](https://arxiv.org/abs/2511.12331)
*Sepehr Kazemi Ranjbar,Kumail Alhamoud,Marzyeh Ghassemi*

Main category: cs.CV

TL;DR: VLN模型在处理否定提示时存在不足，现有方法通过大规模负面数据集微调虽能提升性能，但会损害模型的零样本能力。本文提出一种无需训练的框架，将否定视为联合嵌入空间中的子空间而非单点。该方法通过构建以肯定和否定提示的嵌入为中心的球帽区域，并根据图像在区域内的中心方向进行评分，从而在检索、选择题和文生图等任务上平均提升约30%的否定理解能力，同时保持了模型的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在处理否定提示时存在不足，例如在“检索或生成一个没有行人的街道场景”时，模型往往无法正确理解“不”的含义。现有的解决方法是使用大规模的否定数据集进行微调，但这种方法会损害模型在肯定提示上的零样本性能。

Method: 本文提出了一种无需训练的框架，利用VLMs（如CLIP）的嵌入空间可以被划分为语义一致子空间的特性。该框架将否定概念建模为联合嵌入空间中的一个子空间，而不是一个单一的点。对于“A但非N”这类提示，模型构建以A和N的嵌入为中心的两个球面帽，并通过评分图像与A的中心方向接近且与N的中心方向远离的程度来寻找匹配图像。

Result: 在检索、多项选择题和文本到图像生成等任务中，该方法平均将否定理解能力提高了约30%，优于先前的方法。该方法缩小了肯定提示和否定提示之间的性能差距，同时保持了微调模型无法维持的零样本性能。

Conclusion: 本文提出的无需训练的框架通过将否定概念建模为联合嵌入空间中的子空间，有效解决了VLN模型在处理否定提示时的不足，并在多项任务上取得了显著的性能提升，同时保留了模型的零样本能力。

Abstract: Vision-Language Models (VLMs) struggle with negation. Given a prompt like "retrieve (or generate) a street scene without pedestrians," they often fail to respect the "not." Existing methods address this limitation by fine-tuning on large negation datasets, but such retraining often compromises the model's zero-shot performance on affirmative prompts. We show that the embedding space of VLMs, such as CLIP, can be divided into semantically consistent subspaces. Based on this property, we propose a training-free framework that models negation as a subspace in the joint embedding space rather than a single point (Figure 1). To find the matching image for a caption such as "A but not N," we construct two spherical caps around the embeddings of A and N, and we score images by the central direction of the region that is close to A and far from N. Across retrieval, MCQ, and text-to-image tasks, our method improves negation understanding by about 30% on average over prior methods. It closes the gap between affirmative and negated prompts while preserving the zero-shot performance that fine-tuned models fail to maintain. Code will be released upon publication.

</details>


### [105] [Ground Plane Projection for Improved Traffic Analytics at Intersections](https://arxiv.org/abs/2511.12342)
*Sajjad Pakdamansavoji,Kumar Vaibhav Jha,Baher Abdulhai,James H Elder*

Main category: cs.CV

TL;DR: 使用3D坐标分析交通流量比2D图像更准确


<details>
  <summary>Details</summary>
Motivation: 准确的交叉口转向计数对于信号控制、交通管理和城市规划至关重要。

Method: 将车辆从基础摄像头投影回地面进行分析，并融合来自多个摄像头的信息。

Result: 单摄像头和多摄像头（弱融合）的投影方法都比仅使用图像平面进行分析更准确。

Conclusion: 建议在地面平面而不是图像平面上分析交通流量。

Abstract: Accurate turning movement counts at intersections are important for signal control, traffic management and urban planning. Computer vision systems for automatic turning movement counts typically rely on visual analysis in the image plane of an infrastructure camera. Here we explore potential advantages of back-projecting vehicles detected in one or more infrastructure cameras to the ground plane for analysis in real-world 3D coordinates. For single-camera systems we find that back-projection yields more accurate trajectory classification and turning movement counts. We further show that even higher accuracy can be achieved through weak fusion of back-projected detections from multiple cameras. These results suggeest that traffic should be analyzed on the ground plane, not the image plane

</details>


### [106] [CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification](https://arxiv.org/abs/2511.12346)
*Asmit Bandyopadhyay,Anindita Das Bhattacharjee,Rakesh Das*

Main category: cs.CV

TL;DR: CLAReSNet是一种结合了卷积和Transformer的新型混合架构，通过多尺度卷积和自适应潜在注意力机制有效解决了高光谱图像分类中的高维性、光谱-空间相关性以及样本数量有限和类别不平衡等问题，并在Indian Pines和Salinas数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像（HSI）分类面临高光谱维度、复杂的光谱-空间相关性以及有限且类别不平衡的训练样本等挑战。单独使用CNN或Transformer效果不佳，前者存在二次复杂度问题，后者归纳偏见不足。

Method: 提出CLAReSNet（卷积潜在注意力残差光谱网络），一种混合架构，通过自适应潜在瓶颈整合多尺度卷积提取和Transformer风格的注意力。模型使用多尺度卷积词干、深度残差块和增强的卷积块注意力模块来提取分层空间特征，然后是结合双向RNN（LSTM/GRU）和多尺度光谱潜在注意力（MSLA）的光谱编码器层。MSLA通过自适应潜在令牌分配（8-64个令牌）将复杂度从O(T^2D)降低到O(Tlog(T)D)，从而实现与序列长度的对数缩放。分层交叉注意力融合动态聚合多层表示以实现稳健分类。

Result: 在Indian Pines和Salinas数据集上的实验表明，CLAReSNet取得了最先进的性能，总体准确率分别为99.71%和99.96%，显著优于HybridSN、SSRN和SpectralFormer。学习到的嵌入表现出优越的类间可分离性和紧凑的类内聚类，验证了CLAReSNet在有限样本和严重类别不平衡情况下的有效性。

Conclusion: CLAReSNet通过融合多尺度卷积和Transformer的优势，并引入创新的MSLA机制，有效解决了高光谱图像分类中的关键挑战，并在实际数据集上取得了卓越的性能。

Abstract: Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\mathcal{O}(T^2D)$ to $\mathcal{O}(T\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under limited samples and severe class imbalance.

</details>


### [107] [Explainable AI-Generated Image Detection RewardBench](https://arxiv.org/abs/2511.12363)
*Michael Yang,Shijian Deng,William T. Doan,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian*

Main category: cs.CV

TL;DR: 该研究提出了XAIGID-RewardBench，一个用于评估多模态大语言模型（MLLM）判断AI生成图像检测解释质量的基准。研究发现，尽管现有最佳模型得分率达到88.76%，但与人类98.30%的一致性相比，仍存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 传统的AI生成图像检测方法缺乏可解释性，降低了其可信度。虽然MLLM被认为是解决方案，但评估其判断生成图像检测解释质量的能力的研究不足。

Method: 构建了包含约3000个标注三元组的XAIGID-RewardBench基准，用于评估MLLM作为评判者（reward model）的能力，并分析了模型常见的错误。

Result: 在XAIGID-RewardBench基准上，最佳奖励模型的得分率为88.76%，而人类标注者的一致性为98.30%，表明MLLM在这一能力上与人类存在差距。研究还分析了模型常见的错误。

Conclusion: XAIGID-RewardBench是首个用于评估MLLM在AI生成图像检测解释质量判断方面能力的基准。现有MLLM在这一能力上与人类水平仍有差距，但该基准为进一步研究和改进提供了基础。

Abstract: Conventional, classification-based AI-generated image detection methods cannot explain why an image is considered real or AI-generated in a way a human expert would, which reduces the trustworthiness and persuasiveness of these detection tools for real-world applications. Leveraging Multimodal Large Language Models (MLLMs) has recently become a trending solution to this issue. Further, to evaluate the quality of generated explanations, a common approach is to adopt an "MLLM as a judge" methodology to evaluate explanations generated by other MLLMs. However, how well those MLLMs perform when judging explanations for AI-generated image detection generated by themselves or other MLLMs has not been well studied. We therefore propose \textbf{XAIGID-RewardBench}, the first benchmark designed to evaluate the ability of current MLLMs to judge the quality of explanations about whether an image is real or AI-generated. The benchmark consists of approximately 3,000 annotated triplets sourced from various image generation models and MLLMs as policy models (detectors) to assess the capabilities of current MLLMs as reward models (judges). Our results show that the current best reward model scored 88.76\% on this benchmark (while human inter-annotator agreement reaches 98.30\%), demonstrating that a visible gap remains between the reasoning abilities of today's MLLMs and human-level performance. In addition, we provide an analysis of common pitfalls that these models frequently encounter. Code and benchmark are available at https://github.com/RewardBench/XAIGID-RewardBench.

</details>


### [108] [Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2511.12365)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: DT-R1是一个利用强化学习和数字孪生表示进行视觉推理的框架，能够统一处理多种视觉推理任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉推理方法需要针对不同任务设计不同的模型和训练方式，限制了跨任务和跨模态的泛化能力。

Method: DT-R1框架使用强化学习（GRPO）训练大型语言模型，构建复杂多模态视觉输入的数字孪生表示，并在此基础上进行推理。该框架使用一种新颖的奖励机制来同时验证结构完整性和输出准确性。

Result: 在六个涵盖两种模态和四种任务类型的视觉推理基准测试中，DT-R1的表现优于当前最先进的专用模型。

Conclusion: DT-R1为视觉推理开辟了新方向，即通过强化学习和数字孪生表示实现视觉推理。

Abstract: Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

</details>


### [109] [Fast Reasoning Segmentation for Images and Videos](https://arxiv.org/abs/2511.12368)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: FastReasonSeg通过使用数字孪生来更有效地蒸馏大型模型，实现了高效的推理分割，即使在资源受限的环境中也能实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理分割方法需要庞大的模型，无法在资源受限的边缘设备上运行；现有的蒸馏方法无法有效迁移推理分割所需的多步推理能力。

Method: 提出FastReasonSeg，利用数字孪生解耦感知和推理，通过监督微调（教师生成的推理链）和强化微调（分割精度和推理质量对齐的联合奖励）进行蒸馏。

Result: 在JiTBench、RVTBench、ReasonSeg和LLM-Seg40K等基准测试中，FastReasonSeg取得了最先进的推理分割性能。0.6B的蒸馏模型在参数量是其20倍的模型的20倍以上，吞吐量为7.79 FPS，内存消耗仅为2.1GB。

Conclusion: FastReasonSeg通过有效的蒸馏实现了高效的推理分割，能够部署在资源受限的环境中，支持实时推理分割。

Abstract: Reasoning segmentation enables open-set object segmentation via implicit text queries, therefore serving as a foundation for embodied agents that should operate autonomously in real-world environments. However, existing methods for reasoning segmentation require multimodal large language models with billions of parameters that exceed the computational capabilities of edge devices that typically deploy the embodied AI systems. Distillation offers a pathway to compress these models while preserving their capabilities. Yet, existing distillation approaches fail to transfer the multi-step reasoning capabilities that reasoning segmentation demands, as they focus on matching output predictions and intermediate features rather than preserving reasoning chains. The emerging paradigm of reasoning over digital twin representations presents an opportunity for more effective distillation by re-framing the problem. Consequently, we propose FastReasonSeg, which employs digital twin representations that decouple perception from reasoning to enable more effective distillation. Our distillation scheme first relies on supervised fine-tuning on teacher-generated reasoning chains. Then it is followed by reinforcement fine-tuning with joint rewards evaluating both segmentation accuracy and reasoning quality alignment. Experiments on two video (JiTBench, RVTBench) and two image benchmarks (ReasonSeg, LLM-Seg40K) demonstrate that our FastReasonSeg achieves state-of-the-art reasoning segmentation performance. Moreover, the distilled 0.6B variant outperforms models with 20 times more parameters while achieving 7.79 FPS throughput with only 2.1GB memory consumption. This efficiency enables deployment in resource-constrained environments to enable real-time reasoning segmentation.

</details>


### [110] [Changes in Real Time: Online Scene Change Detection with Multi-View Fusion](https://arxiv.org/abs/2511.12370)
*Chamuditha Jayanga Galappaththige,Jason Lai,Lloyd Windrim,Donald Dansereau,Niko Sünderhauf,Dimity Miller*

Main category: cs.CV

TL;DR: 提出了一种新颖的在线场景变换检测方法，该方法具有姿态无关、无标签、多视角一致性，速度超过10 FPS，并且性能优于现有的在线和离线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的在线场景变换检测（SCD）方法在准确性方面远不如离线方法，并且需要处理来自非约束视角的实时场景变化检测的挑战。

Method: 该方法引入了一种新的自监督融合损失，用于从多个线索和观测中推断场景变换。此外，它还采用基于PnP的快速姿态估计来与参考场景进行比较，并使用快速的变换引导更新策略来更新3D高斯泼溅场景表示。

Result: 该方法在复杂真实世界数据集上的大量实验表明，其性能优于在线和离线基线方法。

Conclusion: 该方法是第一个实现姿态无关、无标签和多视角一致性的在线SCD方法，在速度和准确性方面均达到了新的最先进水平，甚至超越了最先进的离线方法。

Abstract: Online Scene Change Detection (SCD) is an extremely challenging problem that requires an agent to detect relevant changes on the fly while observing the scene from unconstrained viewpoints. Existing online SCD methods are significantly less accurate than offline approaches. We present the first online SCD approach that is pose-agnostic, label-free, and ensures multi-view consistency, while operating at over 10 FPS and achieving new state-of-the-art performance, surpassing even the best offline approaches. Our method introduces a new self-supervised fusion loss to infer scene changes from multiple cues and observations, PnP-based fast pose estimation against the reference scene, and a fast change-guided update strategy for the 3D Gaussian Splatting scene representation. Extensive experiments on complex real-world datasets demonstrate that our approach outperforms both online and offline baselines.

</details>


### [111] [Reasoning Text-to-Video Retrieval via Digital Twin Video Representations and Large Language Models](https://arxiv.org/abs/2511.12371)
*Yiqing Shen,Chenxiao Fan,Chenjia Li,Mathias Unberath*

Main category: cs.CV

TL;DR: 本研究提出了一种新的文本到视频检索方法，能够处理需要推理的隐式文本查询，并提供对象级别的定位掩码。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频检索方法无法处理需要推理的隐式文本查询，本研究旨在解决这一问题。

Method: 提出了一种将视频内容表示为数字孪生（结构化场景表示）的方法，然后利用大型语言模型进行推理，并通过“即时精炼”来弥补信息不足。该框架分为两个阶段：1. 候选视频识别（基于子查询和数字孪生表示的组合对齐）；2. 大型语言模型推理（结合即时精炼）。

Result: 在ReasonT2VBench-135基准上达到了81.2%的R@1，超过了最强的基线超过50个百分点。在ReasonT2VBench-1000基准上保持了81.7%的R@1。在MSR-VTT、MSVD和VATEX三个传统基准上也取得了最先进的结果。

Conclusion: 所提出的推理文本到视频检索方法在处理隐式文本查询方面取得了显著的成功，并在多个基准上取得了最先进的性能。

Abstract: The goal of text-to-video retrieval is to search large databases for relevant videos based on text queries. Existing methods have progressed to handling explicit queries where the visual content of interest is described explicitly; however, they fail with implicit queries where identifying videos relevant to the query requires reasoning. We introduce reasoning text-to-video retrieval, a paradigm that extends traditional retrieval to process implicit queries through reasoning while providing object-level grounding masks that identify which entities satisfy the query conditions. Instead of relying on vision-language models directly, we propose representing video content as digital twins, i.e., structured scene representations that decompose salient objects through specialist vision models. This approach is beneficial because it enables large language models to reason directly over long-horizon video content without visual token compression. Specifically, our two-stage framework first performs compositional alignment between decomposed sub-queries and digital twin representations for candidate identification, then applies large language model-based reasoning with just-in-time refinement that invokes additional specialist models to address information gaps. We construct a benchmark of 447 manually created implicit queries with 135 videos (ReasonT2VBench-135) and another more challenging version of 1000 videos (ReasonT2VBench-1000). Our method achieves 81.2% R@1 on ReasonT2VBench-135, outperforming the strongest baseline by greater than 50 percentage points, and maintains 81.7% R@1 on the extended configuration while establishing state-of-the-art results in three conventional benchmarks (MSR-VTT, MSVD, and VATEX).

</details>


### [112] [AGGRNet: Selective Feature Extraction and Aggregation for Enhanced Medical Image Classification](https://arxiv.org/abs/2511.12382)
*Ansh Makwe,Akansh Agrawal,Prateek Jain,Akshan Agrawal,Priyanka Bagade*

Main category: cs.CV

TL;DR: AGGRNet通过提取信息和非信息特征来改进细粒度医学图像分类


<details>
  <summary>Details</summary>
Motivation: 现有基于注意力机制的模型在区分细粒度医学图像类别时面临挑战，因为它们难以捕捉类间相似性和类内变异性。

Method: 提出AGGRNet框架，以提取信息性和非信息性特征，从而有效理解细粒度视觉模式并改进分类。

Result: AGGRNet在多个医学影像数据集上取得了最先进的性能，在Kvasir数据集上的提升幅度最大，超过了最先进的模型5%。

Conclusion: AGGRNet框架能够有效提取细粒度视觉特征，提高医学图像分类任务的准确性。

Abstract: Medical image analysis for complex tasks such as severity grading and disease subtype classification poses significant challenges due to intricate and similar visual patterns among classes, scarcity of labeled data, and variability in expert interpretations. Despite the usefulness of existing attention-based models in capturing complex visual patterns for medical image classification, underlying architectures often face challenges in effectively distinguishing subtle classes since they struggle to capture inter-class similarity and intra-class variability, resulting in incorrect diagnosis. To address this, we propose AGGRNet framework to extract informative and non-informative features to effectively understand fine-grained visual patterns and improve classification for complex medical image analysis tasks. Experimental results show that our model achieves state-of-the-art performance on various medical imaging datasets, with the best improvement up to 5% over SOTA models on the Kvasir dataset.

</details>


### [113] [Leveraging Quantum-Based Architectures for Robust Diagnostics](https://arxiv.org/abs/2511.12386)
*Shabnam Sodagari,Tommy Long*

Main category: cs.CV

TL;DR: 该研究提出了一种结合经典深度学习和量子计算的混合方法，用于通过CT图像诊断肾脏疾病（结石、囊肿、肿瘤）。


<details>
  <summary>Details</summary>
Motivation: 利用混合量子-经典框架，结合预训练的ResNet50编码器和量子卷积神经网络（QCNN），以提高肾脏疾病诊断的准确性。

Method: 对肾脏CT图像进行去噪和对比度增强预处理，然后使用ResNet50提取特征，并将特征编码为量子比特，最后通过QCNN进行处理。通过数据增强和加权采样解决类别不平衡问题，并在8比特和12比特的QCNN配置下进行评估。

Result: 两种QCNN配置均实现了快速收敛和稳定的学习曲线，训练和验证性能高度一致。模型在测试集上达到了0.99的准确率，其中12比特配置在召回率和精确率方面表现更优，尤其在囊肿和肿瘤检测上，囊肿召回率达到100%，肿瘤F1分数达到0.9956。混淆矩阵分析显示分类行为可靠。

Conclusion: 将经典预处理和深度特征提取与量子电路相结合，能够提升医学诊断性能。

Abstract: The objective of this study is to diagnose and differentiate kidney stones, cysts, and tumors using Computed Tomography (CT) images of the kidney. This study leverages a hybrid quantum-classical framework in this regard. We combine a pretrained ResNet50 encoder, with a Quantum Convolutional Neural Network (QCNN) to explore quantum-assisted diagnosis. We pre-process the kidney images using denoising and contrast limited adaptive histogram equalization to enhance feature extraction. We address class imbalance through data augmentation and weighted sampling. Latent features extracted by the encoder are transformed into qubits via angle encoding and processed by a QCNN. The model is evaluated on both 8-qubit and 12-qubit configurations. Both architectures achieved rapid convergence with stable learning curves and high consistency between training and validation performance. The models reached a test accuracy of 0.99, with the 12-qubit configuration providing improvements in overall recall and precision, particularly for Cyst and Tumor detection, where it achieved perfect recall for Cysts and a tumor F1-score of 0.9956. Confusion matrix analysis further confirmed reliable classification behavior across all classes, with very few misclassifications. Results demonstrate that integrating classical pre-processing and deep feature extraction with quantum circuits enhances medical diagnostic performance.

</details>


### [114] [Calibrated Decomposition of Aleatoric and Epistemic Uncertainty in Deep Features for Inference-Time Adaptation](https://arxiv.org/abs/2511.12389)
*Divake Kumar,Patrick Poggi,Sina Tayebati,Devashri Naik,Nilesh Ahuja,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“不确定性引导推理时间选择”（Uncertainty-Guided Inference-Time Selection, UGITS）的框架，用于区分和利用 aleatoric 和 epistemic 不确定性，以优化深度学习模型的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有的模型通常将所有不确定性模式合并为单一置信度分数，这阻碍了在需要分配更多计算资源或调整推理时的可靠决策。本研究旨在解决这一问题，提出一种能够区分不同不确定性来源并加以利用的方法。

Method: UGITS 框架在深度特征空间中直接分离 aleatoric（数据驱动）不确定性和 epistemic（模型驱动）不确定性。aleatoric 不确定性通过正则化的全局密度模型进行估计；epistemic 不确定性则由三个互补的成分组成，分别捕捉局部支持不足、流形频谱坍塌和跨层特征不一致性。这些成分是经验上正交的，并且不需要采样、集成或额外的正向传播。

Result: 该方法将分解后的不确定性集成到无分布的保形校准流程中，在匹配覆盖率的情况下显著缩小了预测区间。在 MOT17 数据集上，使用这些不确定性成分进行引导的自适应模型选择，可以将计算量减少约 60%，同时准确率损失可忽略不计。此外，消融研究表明，所提出的正交不确定性分解在所有 MOT17 序列中始终能带来更高的计算节省，比总不确定性基线提高了 13.6 个百分点。

Conclusion: UGITS 框架能够有效地区分和利用 aleatoric 和 epistemic 不确定性，通过自适应模型选择显著降低了推理计算量，同时保持了高准确率，为实际应用中的自调节视觉推理提供了可能。

Abstract: Most estimators collapse all uncertainty modes into a single confidence score, preventing reliable reasoning about when to allocate more compute or adjust inference. We introduce Uncertainty-Guided Inference-Time Selection, a lightweight inference time framework that disentangles aleatoric (data-driven) and epistemic (model-driven) uncertainty directly in deep feature space. Aleatoric uncertainty is estimated using a regularized global density model, while epistemic uncertainty is formed from three complementary components that capture local support deficiency, manifold spectral collapse, and cross-layer feature inconsistency. These components are empirically orthogonal and require no sampling, no ensembling, and no additional forward passes. We integrate the decomposed uncertainty into a distribution free conformal calibration procedure that yields significantly tighter prediction intervals at matched coverage. Using these components for uncertainty guided adaptive model selection reduces compute by approximately 60 percent on MOT17 with negligible accuracy loss, enabling practical self regulating visual inference. Additionally, our ablation results show that the proposed orthogonal uncertainty decomposition consistently yields higher computational savings across all MOT17 sequences, improving margins by 13.6 percentage points over the total-uncertainty baseline.

</details>


### [115] [MSLoRA: Multi-Scale Low-Rank Adaptation via Attention Reweighting](https://arxiv.org/abs/2511.12400)
*Xu Yang,Gady Agam*

Main category: cs.CV

TL;DR: MSLoRA是一种参数高效的适配器，通过重新加权特征响应而非重新调整骨干网络来统一CNN和ViT的适配。


<details>
  <summary>Details</summary>
Motivation: 现有低秩适应方法主要局限于视觉变换器（ViTs），并且难以跨越不同架构进行泛化。MSLoRA旨在统一卷积神经网络（CNN）和ViT的适配。 

Method: MSLoRA结合了低秩线性投影和多尺度非线性变换，通过逐点乘法和残差连接融合这两个组件，从而产生一个轻量级模块，在保持预训练权重冻结的情况下转移特征注意力。

Result: MSLoRA在分类、检测和分割任务的迁移性能方面取得了持续的改进，其参数量约占骨干网络参数量的5%以下。此外，该设计还实现了稳定的优化、快速的收敛和强大的跨架构泛化能力。

Conclusion: 通过重新加权而非重新调整，MSLoRA为冻结的视觉骨干网络提供了一种简单而通用的高效适配方法。

Abstract: We introduce MSLoRA, a backbone-agnostic, parameter-efficient adapter that reweights feature responses rather
  than re-tuning the underlying backbone. Existing low-rank adaptation methods are mostly confined to vision
  transformers (ViTs) and struggle to generalize across architectures. MSLoRA unifies adaptation for both convolutional neural networks (CNNs) and
  ViTs by combining a low-rank linear projection with a multi-scale nonlinear transformation that jointly
  modulates spatial and channel attention. The two components are fused through pointwise multiplication and
  a residual connection, yielding a lightweight module that shifts feature attention while keeping pretrained
  weights frozen.
  Extensive experiments demonstrate that MSLoRA consistently improves transfer performance on classification,
  detection, and segmentation tasks with roughly less than 5\% of backbone parameters.
  The design further enables stable optimization, fast convergence, and strong cross-architecture
  generalization. By reweighting rather than re-tuning, MSLoRA provides a simple and universal approach
  for efficient adaptation of frozen vision backbones.

</details>


### [116] [VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving](https://arxiv.org/abs/2511.12405)
*Hyunki Seong,Seongwoo Moon,Hojin Ahn,Jehun Kang,David Hyunchul Shim*

Main category: cs.CV

TL;DR: VLA-R是一个开放世界端到端自动驾驶框架，通过结合开放世界感知和新颖的视觉-动作检索范式，实现了在非结构化和未见过环境中的强大泛化和探索能力。


<details>
  <summary>Details</summary>
Motivation: 端到端地探索开放世界场景是一个有前景但充满挑战的任务，特别是对于在训练期间未遇到过条件的非结构化室外环境的端到端自动驾驶。现有的方法在泛化能力方面存在不足。

Method: 提出了一种名为VLA-R的开放世界端到端自动驾驶框架。该框架集成了开放世界感知和新的视觉-动作检索范式。利用冻结的视觉-语言模型进行开放世界检测和分割，以获得多尺度、提示引导和可解释的感知特征，无需领域特定调优。使用Q-Former瓶颈聚合细粒度的视觉表示和与语言对齐的视觉特征，以连接感知和动作域。引入了视觉-动作对比学习方案，以学习可迁移的驾驶行为，将视觉-语言和动作嵌入对齐，以实现有效的开放世界推理和动作检索。

Result: 在真实机器人平台上进行了实验，证明了在非结构化、未见过环境中的强大泛化和探索性能，即使数据有限。

Conclusion: VLA-R框架在开放世界端到端自动驾驶方面表现出色，尤其是在非结构化和未见过环境中，具有强大的泛化和探索能力，为未来的研究提供了新的方向。

Abstract: Exploring open-world situations in an end-to-end manner is a promising yet challenging task due to the need for strong generalization capabilities. In particular, end-to-end autonomous driving in unstructured outdoor environments often encounters conditions that were unfamiliar during training. In this work, we present Vision-Language Action Retrieval (VLA-R), an open-world end-to-end autonomous driving (OW-E2EAD) framework that integrates open-world perception with a novel vision-action retrieval paradigm. We leverage a frozen vision-language model for open-world detection and segmentation to obtain multi-scale, prompt-guided, and interpretable perception features without domain-specific tuning. A Q-Former bottleneck aggregates fine-grained visual representations with language-aligned visual features, bridging perception and action domains. To learn transferable driving behaviors, we introduce a vision-action contrastive learning scheme that aligns vision-language and action embeddings for effective open-world reasoning and action retrieval. Our experiments on a real-world robotic platform demonstrate strong generalization and exploratory performance in unstructured, unseen environments, even with limited data. Demo videos are provided in the supplementary material.

</details>


### [117] [Self-Supervised Visual Prompting for Cross-Domain Road Damage Detection](https://arxiv.org/abs/2511.12410)
*Xi Xiao,Zhuxuanzi Wang,Mingqiao Mo,Chen Liu,Chenrui Ma,Yanshu Li,Smita Krishnaswamy,Xiao Wang,Tianyang Wang*

Main category: cs.CV

TL;DR: 提出了一种名为 PROBE 的自监督学习框架，用于提高路面缺陷检测的跨域泛化能力。PROBE 通过无标签的目标域数据生成‘缺陷感知’的提示，并对源域和目标域的表示进行对齐，从而在无需重新标注的情况下实现有效的迁移学习。


<details>
  <summary>Details</summary>
Motivation: 目前的自动化道路病害检测方法在跨域泛化能力方面存在不足。有监督方法在特定域内表现良好，但需要昂贵的重新标注；标准的自监督方法捕捉通用特征，容易受域漂移影响。

Method: PROBE 框架包含一个自监督提示增强模块（SPEM），用于从无标签的目标数据中提取对病害敏感的提示，以指导冻结的 ViT 主干网络；以及一个域感知提示对齐（DAPA）目标，用于对齐受提示引导的源域和目标域的表示。

Result: 在四个具有挑战性的基准测试中，PROBE 持续优于强大的有监督、自监督和迁移学习基线方法，展现了鲁棒的零样本迁移能力，提高了对域变化的适应性，并在少样本适应中具有高数据效率。

Conclusion: 自监督提示学习为构建可扩展和自适应的视觉检测系统提供了一个切实可行的方向。

Abstract: The deployment of automated pavement defect detection is often hindered by poor cross-domain generalization. Supervised detectors achieve strong in-domain accuracy but require costly re-annotation for new environments, while standard self-supervised methods capture generic features and remain vulnerable to domain shift. We propose \ours, a self-supervised framework that \emph{visually probes} target domains without labels. \ours introduces a Self-supervised Prompt Enhancement Module (SPEM), which derives defect-aware prompts from unlabeled target data to guide a frozen ViT backbone, and a Domain-Aware Prompt Alignment (DAPA) objective, which aligns prompt-conditioned source and target representations. Experiments on four challenging benchmarks show that \ours consistently outperforms strong supervised, self-supervised, and adaptation baselines, achieving robust zero-shot transfer, improved resilience to domain variations, and high data efficiency in few-shot adaptation. These results highlight self-supervised prompting as a practical direction for building scalable and adaptive visual inspection systems. Source code is publicly available: https://github.com/xixiaouab/PROBE/tree/main

</details>


### [118] [Towards Rotation-only Imaging Geometry: Rotation Estimation](https://arxiv.org/abs/2511.12415)
*Xinrui Li,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 该研究提出了一种基于旋转的运动恢复结构（SfM）框架，通过将平移量表示为旋转量的函数，将成像几何表示压缩到旋转流形上，实现了更准确、鲁棒的3D场景重建。


<details>
  <summary>Details</summary>
Motivation: 受先前姿态无关成像几何研究的启发，本文旨在探索场景结构、旋转和平移之间的关键关系，并将成像几何表示压缩到旋转流形上，以提高SfM性能。

Method: 提出了一种基于重投影误差的纯旋转优化框架，用于两视图和多视图的运动恢复结构问题，其中平移量可以由旋转量导出。

Result: 实验结果表明，该方法在纯旋转估计方面优于现有最先进的方法，其精度和鲁棒性甚至可与多次捆绑调整迭代的结果相媲美。

Conclusion: 该研究为更准确、高效和可靠的3D视觉计算做出了贡献，通过引入一种新颖的纯旋转优化框架来解决运动恢复结构问题。

Abstract: Structure from Motion (SfM) is a critical task in computer vision, aiming to recover the 3D scene structure and camera motion from a sequence of 2D images. The recent pose-only imaging geometry decouples 3D coordinates from camera poses and demonstrates significantly better SfM performance through pose adjustment. Continuing the pose-only perspective, this paper explores the critical relationship between the scene structures, rotation and translation. Notably, the translation can be expressed in terms of rotation, allowing us to condense the imaging geometry representation onto the rotation manifold. A rotation-only optimization framework based on reprojection error is proposed for both two-view and multi-view scenarios. The experiment results demonstrate superior accuracy and robustness performance over the current state-of-the-art rotation estimation methods, even comparable to multiple bundle adjustment iteration results. Hopefully, this work contributes to even more accurate, efficient and reliable 3D visual computing.

</details>


### [119] [Seeing Through the Rain: Resolving High-Frequency Conflicts in Deraining and Super-Resolution via Diffusion Guidance](https://arxiv.org/abs/2511.12419)
*Wenjie Li,Jinglei Shi,Jin Han,Heng Guo,Zhanyu Ma*

Main category: cs.CV

TL;DR: DHGM模型通过结合扩散模型和高通滤波器，在去除图像雨水的同时保留并增强了高频细节，实现了清晰、高分辨率的图像生成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 真实世界图像常受恶劣天气影响，而现有去天气和超分辨率方法可能冲突，影响小目标检测等视觉任务。需要一种能同时去除天气噪声并保留高频细节的方法。

Method: 提出DHGM（Diffusion-based High-frequency Guided Model），该模型集成预训练的扩散模型先验知识和高通滤波器，同时去除雨水伪影并增强结构细节。

Result: 实验证明DHGM在去除雨水和提高图像分辨率方面效果优于现有方法，且计算成本更低。

Conclusion: DHGM能够有效解决去天气和超分辨率之间的冲突，生成高质量的图像，为依赖高频细节的视觉任务提供了更好的解决方案。

Abstract: Clean images are crucial for visual tasks such as small object detection, especially at high resolutions. However, real-world images are often degraded by adverse weather, and weather restoration methods may sacrifice high-frequency details critical for analyzing small objects. A natural solution is to apply super-resolution (SR) after weather removal to recover both clarity and fine structures. However, simply cascading restoration and SR struggle to bridge their inherent conflict: removal aims to remove high-frequency weather-induced noise, while SR aims to hallucinate high-frequency textures from existing details, leading to inconsistent restoration contents. In this paper, we take deraining as a case study and propose DHGM, a Diffusion-based High-frequency Guided Model for generating clean and high-resolution images. DHGM integrates pre-trained diffusion priors with high-pass filters to simultaneously remove rain artifacts and enhance structural details. Extensive experiments demonstrate that DHGM achieves superior performance over existing methods, with lower costs.

</details>


### [120] [MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation](https://arxiv.org/abs/2511.12422)
*Nuolin Sun,Linyuan Wang,Haonan Wei,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: ResNet可以通过残差连接实现，并可被视为离散的常微分方程（ODEs）。受此启发，提出一种名为MFI-ResNet的新模型，它结合了MeanFlow和ResNet的优点，通过压缩-扩展策略提高参数效率和识别性能。实验表明，MFI-ResNet在CIFAR-10和CIFAR-100数据集上参数减少了约46%，同时提高了准确率。


<details>
  <summary>Details</summary>
Motivation: 文章旨在探索生成模型（MeanFlow）与判别模型（ResNet）之间的联系，并提出一种新的模型（MFI-ResNet）来提高ResNet的参数效率和识别性能。

Method: MFI-ResNet采用压缩-扩展策略：首先，用少量MeanFlow模块替换ResNet的多个残差块，构建一个轻量级元模型（压缩）；然后，选择性地将前三个阶段扩展回残差块结构，最后一个阶段保持MeanFlow形式，并进行微调（扩展）。

Result: 在CIFAR-10和CIFAR-100数据集上，MFI-ResNet的参数量相比ResNet-50减少了46.28%和45.59%，但准确率分别提高了0.23%和0.17%。

Conclusion: 生成流场可以有效地表征ResNet中的特征变换过程，为理解生成建模和判别学习之间的关系提供了新的视角。

Abstract: ResNet has achieved tremendous success in computer vision through its residual connection mechanism. ResNet can be viewed as a discretized form of ordinary differential equations (ODEs). From this perspective, the multiple residual blocks within a single ResNet stage essentially perform multi-step discrete iterations of the feature transformation for that stage. The recently proposed flow matching model, MeanFlow, enables one-step generative modeling by learning the mean velocity field to transform distributions. Inspired by this, we propose MeanFlow-Incubated ResNet (MFI-ResNet), which employs a compression-expansion strategy to jointly improve parameter efficiency and discriminative performance. In the compression phase, we simplify the multi-layer structure within each ResNet stage to one or two MeanFlow modules to construct a lightweight meta model. In the expansion phase, we apply a selective incubation strategy to the first three stages, expanding them to match the residual block configuration of the baseline ResNet model, while keeping the last stage in MeanFlow form, and fine-tune the incubated model. Experimental results show that on CIFAR-10 and CIFAR-100 datasets, MFI-ResNet achieves remarkable parameter efficiency, reducing parameters by 46.28% and 45.59% compared to ResNet-50, while still improving accuracy by 0.23% and 0.17%, respectively. This demonstrates that generative flow-fields can effectively characterize the feature transformation process in ResNet, providing a new perspective for understanding the relationship between generative modeling and discriminative learning.

</details>


### [121] [RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning](https://arxiv.org/abs/2511.12428)
*Jingqi Xu,Jingxi Lu,Chenghao Li,Sreetama Sarkar,Souvik Kundu,Peter A. Beerel*

Main category: cs.CV

TL;DR: 红VTP是一种响应驱动的视觉标记修剪策略，通过在第一步推理后修剪不重要的视觉标记来提高扩散视觉语言模型（DVLMs）的推理效率，从而在不影响准确性的情况下提高吞吐量和降低延迟。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLMs）在多模态推理和生成方面取得了显著进展，但其高计算需求仍然是一个主要挑战。扩散视觉语言模型（DVLMs）通过并行令牌解码具有吸引力，但大量的视觉令牌仍然严重影响其推理效率。现有的视觉令牌修剪方法主要针对自回归VLMs（AVLMs），而对DVLMs的探索不足。

Method: 提出了一种名为RedVTP的响应驱动的视觉令牌修剪策略，该策略利用DVLMs的推理动态。该方法利用来自掩码响应令牌的注意力来估计视觉令牌的重要性。由于这些重要性分数在步骤之间保持一致，RedVTP在第一步推理后修剪了掩码令牌中不太重要的视觉令牌。

Result: 实验表明，RedVTP将LLaDA-V和LaViDa的令牌生成吞吐量分别提高了186%和28.05%，并将推理延迟分别降低了64.97%和21.87%，同时不影响准确性，在某些情况下甚至提高了准确性。

Conclusion: RedVTP是一种有效的视觉令牌修剪策略，可以显著提高DVLMs的推理效率，而不会损害模型的准确性。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in multimodal reasoning and generation, yet their high computational demands remain a major challenge. Diffusion Vision-Language Models (DVLMs) are particularly attractive because they enable parallel token decoding, but the large number of visual tokens still significantly hinders their inference efficiency. While visual token pruning has been extensively studied for autoregressive VLMs (AVLMs), it remains largely unexplored for DVLMs. In this work, we propose RedVTP, a response-driven visual token pruning strategy that leverages the inference dynamics of DVLMs. Our method estimates visual token importance using attention from the masked response tokens. Based on the observation that these importance scores remain consistent across steps, RedVTP prunes the less important visual tokens from the masked tokens after the first inference step, thereby maximizing inference efficiency. Experiments show that RedVTP improves token generation throughput of LLaDA-V and LaViDa by up to 186% and 28.05%, respectively, and reduces inference latency by up to 64.97% and 21.87%, without compromising-and in some cases improving-accuracy.

</details>


### [122] [Text-Guided Channel Perturbation and Pretrained Knowledge Integration for Unified Multi-Modality Image Fusion](https://arxiv.org/abs/2511.12432)
*Xilai Li,Xiaosong Li,Weijun Jiang*

Main category: cs.CV

TL;DR: UP-Fusion框架通过通道扰动和预训练知识集成解决了多模态图像融合中的梯度冲突和泛化能力问题。


<details>
  <summary>Details</summary>
Motivation: 多模态图像融合通过结合互补信息来增强场景感知。然而，模态差异过大导致的梯度冲突限制了统一模型的性能。现有的特定模态编码器策略虽然能提升融合质量，但牺牲了跨任务的泛化能力。因此，需要一种能克服这些限制的统一框架。

Method: 提出了一种基于通道扰动和预训练知识集成的统一多模态图像融合框架（UP-Fusion）。该框架包含三个关键模块：1. 语义感知通道剪枝模块（SCPM），利用预训练模型的语义感知能力过滤和增强特征通道，抑制冗余信息。2. 几何仿射调制模块（GAM），利用原始模态特征对初始融合特征进行仿射变换，保持编码器的模态判别力。3. 文本引导通道扰动模块（TCPM），在解码阶段重塑通道分布，减少对特定模态通道的依赖。

Result: 在多模态图像融合和下游任务上的大量实验表明，该算法优于现有的方法。

Conclusion: UP-Fusion框架通过SCPM、GAM和TCPM模块的有效结合，成功解决了多模态图像融合中的挑战，并在多个任务上取得了优越的性能。

Abstract: Multi-modality image fusion enhances scene perception by combining complementary information. Unified models aim to share parameters across modalities for multi-modality image fusion, but large modality differences often cause gradient conflicts, limiting performance. Some methods introduce modality-specific encoders to enhance feature perception and improve fusion quality. However, this strategy reduces generalisation across different fusion tasks. To overcome this limitation, we propose a unified multi-modality image fusion framework based on channel perturbation and pre-trained knowledge integration (UP-Fusion). To suppress redundant modal information and emphasize key features, we propose the Semantic-Aware Channel Pruning Module (SCPM), which leverages the semantic perception capability of a pre-trained model to filter and enhance multi-modality feature channels. Furthermore, we proposed the Geometric Affine Modulation Module (GAM), which uses original modal features to apply affine transformations on initial fusion features to maintain the feature encoder modal discriminability. Finally, we apply a Text-Guided Channel Perturbation Module (TCPM) during decoding to reshape the channel distribution, reducing the dependence on modality-specific channels. Extensive experiments demonstrate that the proposed algorithm outperforms existing methods on both multi-modality image fusion and downstream tasks.

</details>


### [123] [Real-Time Drivers' Drowsiness Detection and Analysis through Deep Learning](https://arxiv.org/abs/2511.12438)
*ANK Zaman,Prosenjit Chatterjee,Rajat Sharma*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度卷积神经网络（DCNN）和OpenCV的实时驾驶员疲劳检测系统，通过分析驾驶员的面部特征（如眼睛睁度和打哈欠的嘴部动作）来识别疲劳状态，并在检测到疲劳时发出警报，以提高道路安全。


<details>
  <summary>Details</summary>
Motivation: 长途驾驶可能导致驾驶员疲劳，增加事故风险，因此需要一个实时系统来检测驾驶员的疲劳状态。

Method: 使用DCNN和OpenCV，通过摄像头实时捕捉驾驶员的面部图像，提取面部地标（如眼睛睁度和嘴部动作），并利用预训练模型判断驾驶员是否疲劳，若疲劳则触发警报。

Result: 该模型在NTHU-DDD数据集上达到了99.6%的准确率，在Yawn-Eye-Dataset数据集上达到了97%的准确率。

Conclusion: 所提出的基于DCNN的疲劳检测系统是一种非侵入性、经济高效的方法，可以有效检测驾驶员的疲劳状态，有可能挽救生命。

Abstract: A long road trip is fun for drivers. However, a long drive for days can be tedious for a driver to accommodate stringent deadlines to reach distant destinations. Such a scenario forces drivers to drive extra miles, utilizing extra hours daily without sufficient rest and breaks. Once a driver undergoes such a scenario, it occasionally triggers drowsiness during driving. Drowsiness in driving can be life-threatening to any individual and can affect other drivers' safety; therefore, a real-time detection system is needed. To identify fatigued facial characteristics in drivers and trigger the alarm immediately, this research develops a real-time driver drowsiness detection system utilizing deep convolutional neural networks (DCNNs) and OpenCV.Our proposed and implemented model takes real- time facial images of a driver using a live camera and utilizes a Python-based library named OpenCV to examine the facial images for facial landmarks like sufficient eye openings and yawn-like mouth movements. The DCNNs framework then gathers the data and utilizes a per-trained model to detect the drowsiness of a driver using facial landmarks. If the driver is identified as drowsy, the system issues a continuous alert in real time, embedded in the Smart Car technology.By potentially saving innocent lives on the roadways, the proposed technique offers a non-invasive, inexpensive, and cost-effective way to identify drowsiness. Our proposed and implemented DCNNs embedded drowsiness detection model successfully react with NTHU-DDD dataset and Yawn-Eye-Dataset with drowsiness detection classification accuracy of 99.6% and 97% respectively.

</details>


### [124] [CoTBox-TTT: Grounding Medical VQA with Visual Chain-of-Thought Boxes During Test-time Training](https://arxiv.org/abs/2511.12446)
*Jiahe Qian,Yuhao Shen,Zhangtianyi Chen,Juexiao Zhou,Peisong Wang*

Main category: cs.CV

TL;DR: CoTBox-TTT是一种即插即用的即时训练方法，可以通过更新软提示来适应医疗VQA模型，以应对领域转移问题，同时保持模型骨干冻结。


<details>
  <summary>Details</summary>
Motivation: 解决当前医疗视觉问答系统在领域转移下表现不佳以及答案与图像证据关联性弱的问题，尤其是在部署时难以进行再训练或添加标签的情况下。

Method: 提出CoTBox-TTT，一种首次测试时训练的方法。该方法在推理时调整视觉语言模型，同时保持所有骨干网络冻结，仅更新一小部分连续的软提示。通过视觉思维链信号识别与问题相关的区域，并鼓励原始图像和局部裁剪图像之间答案的一致性。该方法无需标签，并且可以与不同的骨干网络即插即用。

Result: 在医疗VQA的实验中，该方法在pathVQA数据集上，将LLaVA的封闭式准确率提高了12.3%。

Conclusion: CoTBox-TTT是一种实用的、无需标签的方法，可以提高医疗VQA系统在实际部署中的可靠性，特别是在领域转移的情况下。

Abstract: Medical visual question answering could support clinical decision making, yet current systems often fail under domain shift and produce answers that are weakly grounded in image evidence. This reliability gap arises when models attend to spurious regions and when retraining or additional labels are impractical at deployment time. We address this setting with CoTBox-TTT, an evidence-first test-time training approach that adapts a vision-language model at inference while keeping all backbones frozen. The method updates only a small set of continuous soft prompts. It identifies question-relevant regions through a visual chain-of-thought signal and encourages answer consistency across the original image and a localized crop. The procedure is label free, and plug and play with diverse backbones. Experiments on medical VQA show that the approach is practical for real deployments. For instance, adding CoTBox-TTT to LLaVA increases closed-ended accuracy by 12.3% on pathVQA.

</details>


### [125] [MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2511.12449)
*Zhanheng Nie,Chenghan Fu,Daoze Zhang,Junxian Wu,Wanxian Guan,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON2.0是一个用于电商产品理解的动态模态平衡多模态表示学习框架，解决了模态不平衡、内在对齐关系利用不足和噪声处理有限等问题。它通过模态驱动的MoE模块、双层对齐方法和基于MLLM的图文协同增强策略来提升性能，并在MBE2.0基准和其他公共数据集上取得了最先进的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 电商的快速发展需要能够理解丰富的视觉和文本产品信息的模型。现有的多模态大语言模型（MLLM）在电商领域虽然表现出强大的表示学习能力，但在模态不平衡、视觉和文本信息内在对齐关系利用不足以及电商多模态数据噪声处理能力有限等方面仍面临挑战。

Method: MOON2.0框架包括：1. 模态驱动的混合专家（MoE）模块，根据输入的模态构成自适应地处理样本，实现多模态联合学习以缓解模态不平衡；2. 双层对齐方法，以更好地利用单个产品内部的语义对齐特性；3. 基于MLLM的图文协同增强策略，结合文本丰富和视觉扩展，并辅以动态样本过滤以提高训练数据质量。此外，还引入了MBE2.0，一个用于电商表示学习和评估的协同增强多模态表示基准。

Result: MOON2.0在MBE2.0和多个公共数据集上实现了最先进的零样本性能。基于注意力的热力图可视化提供了MOON2.0改进的多模态对齐的定性证据。

Conclusion: MOON2.0通过其创新的模块和策略，有效解决了电商产品理解中的关键挑战，并在多个数据集上取得了优越的性能，证明了其在电商多模态表示学习领域的有效性。

Abstract: The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.

</details>


### [126] [DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions](https://arxiv.org/abs/2511.12452)
*Xiaoyu Lin,Aniket Ghorpade,Hansheng Zhu,Justin Qiu,Dea Rrozhani,Monica Lama,Mick Yang,Zixuan Bian,Ruohan Ren,Alan B. Hong,Jiatao Gu,Chris Callison-Burch*

Main category: cs.CV

TL;DR: 该研究提出了一个名为DenseAnnotate的音频驱动在线标注平台，用于高效创建图像和3D资源的密集、细粒度标注，解决了现有数据集标注稀疏且依赖手动输入的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型（MLLMs）训练数据存在标注稀疏、无法充分捕捉图像内容、以及传统文本标注方式在表达、速度和覆盖面上的局限性，尤其在多元文化和3D资产标注方面。

Method: DenseAnnotate平台允许标注人员通过口述来标注图像或3D场景中的区域，并实时将语音与图像区域或3D场景部分关联起来。该平台集成了语音转文本和注意力区域标记功能。

Result: 通过对1,000多名标注者的案例研究，创建了一个包含3,531张图像、898个3D场景和7,460个3D对象的标注数据集。使用此数据集训练的模型在多语言理解（+5%）、文化对齐（+47%）和3D空间能力（+54%）方面均有显著提升。

Conclusion: DenseAnnotate平台为未来视觉-语言研究提供了一种可行的方法，能够高效地生成高质量、多语言的密集标注数据，适用于多种任务和数据类型。

Abstract: With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.

</details>


### [127] [MaskAnyNet: Rethinking Masked Image Regions as Valuable Information in Supervised Learning](https://arxiv.org/abs/2511.12480)
*Jingshan Hong,Haigen Hu,Huihuang Zhang,Qianwei Zhou,Zhao Li*

Main category: cs.CV

TL;DR: MaskAnyNet将掩码图像建模（MIM）的思想应用于传统的图像掩蔽方法，通过重新学习被掩盖的内容来利用被掩盖区域的语义多样性，从而丰富特征并保留细粒度细节，在CNN和Transformer骨干网络上均取得了改进。


<details>
  <summary>Details</summary>
Motivation: 传统的监督学习图像掩蔽方法存在丢弃像素导致信息丢失、掩蔽可能移除关键小目标的问题。MIM方法表明掩盖区域可以从部分输入中重建，揭示了掩盖区域包含丰富的上下文信息和语义多样性。因此，需要一种新的方法来利用这些被掩盖区域的信息。

Method: 提出MaskAnyNet，结合掩蔽和再学习机制，将掩盖内容视为辅助知识而非忽略。该方法增加一个分支来联合学习重构的掩盖区域，可以轻松扩展到任何模型，以利用掩盖区域的语义多样性来丰富特征并保留细粒度细节。

Result: 在CNN和Transformer骨干网络上进行了实验，证明了该方法在多个基准测试上具有持续的性能提升。进一步的分析证实，所提出的方法通过重用被掩盖的内容提高了语义多样性。

Conclusion: MaskAnyNet通过将掩盖内容作为辅助知识，并结合再学习机制，有效利用了掩盖区域的语义多样性，解决了传统图像掩蔽方法的局限性，并在各种模型和基准测试上取得了显著的性能提升。

Abstract: In supervised learning, traditional image masking faces two key issues: (i) discarded pixels are underutilized, leading to a loss of valuable contextual information; (ii) masking may remove small or critical features, especially in fine-grained tasks. In contrast, masked image modeling (MIM) has demonstrated that masked regions can be reconstructed from partial input, revealing that even incomplete data can exhibit strong contextual consistency with the original image. This highlights the potential of masked regions as sources of semantic diversity. Motivated by this, we revisit the image masking approach, proposing to treat masked content as auxiliary knowledge rather than ignored. Based on this, we propose MaskAnyNet, which combines masking with a relearning mechanism to exploit both visible and masked information. It can be easily extended to any model with an additional branch to jointly learn from the recomposed masked region. This approach leverages the semantic diversity of the masked regions to enrich features and preserve fine-grained details. Experiments on CNN and Transformer backbones show consistent gains across multiple benchmarks. Further analysis confirms that the proposed method improves semantic diversity through the reuse of masked content.

</details>


### [128] [Towards Temporal Fusion Beyond the Field of View for Camera-based Semantic Scene Completion](https://arxiv.org/abs/2511.12498)
*Jongseong Bae,Junwoo Ha,Jinnyeong Heo,Yeongin Lee,Ha Young Kim*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 C3DFusion 的新模块，用于改进基于相机的 3D 语义场景补全（SSC）方法。该模块通过融合当前和历史帧的特征来解决现有方法在重建被遮挡区域（尤其是在车辆侧面）时遇到的困难。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的 3D 语义场景补全（SSC）方法在利用时间信息来增强当前帧的特征时，主要关注帧内区域，而忽略了包含重要上下文信息的帧外区域。

Method: C3DFusion 模块通过显式地对齐来自当前帧和历史帧的 3D 特征点，生成关注隐藏区域的 3D 特征几何。它采用两种互补的技术：历史上下文模糊（通过衰减历史特征点的尺度来抑制不准确的扭曲带来的噪声）和以当前为中心的特征致密化（通过增加当前特征点的体素贡献来增强它们）。

Result: C3DFusion 模块可以轻松集成到标准的 SSC 架构中，并在 SemanticKITTI 和 SSCBench-KITTI-360 数据集上显著优于现有最先进的方法。此外，该方法还表现出强大的泛化能力，应用于其他基线模型时也能获得显著的性能提升。

Conclusion: C3DFusion 模块通过有效的时态融合策略，显著提高了 3D 语义场景补全的性能，尤其是在处理被遮挡区域方面，并且具有良好的泛化性。

Abstract: Recent camera-based 3D semantic scene completion (SSC) methods have increasingly explored leveraging temporal cues to enrich the features of the current frame. However, while these approaches primarily focus on enhancing in-frame regions, they often struggle to reconstruct critical out-of-frame areas near the sides of the ego-vehicle, although previous frames commonly contain valuable contextual information about these unseen regions. To address this limitation, we propose the Current-Centric Contextual 3D Fusion (C3DFusion) module, which generates hidden region-aware 3D feature geometry by explicitly aligning 3D-lifted point features from both current and historical frames. C3DFusion performs enhanced temporal fusion through two complementary techniques-historical context blurring and current-centric feature densification-which suppress noise from inaccurately warped historical point features by attenuating their scale, and enhance current point features by increasing their volumetric contribution. Simply integrated into standard SSC architectures, C3DFusion demonstrates strong effectiveness, significantly outperforming state-of-the-art methods on the SemanticKITTI and SSCBench-KITTI-360 datasets. Furthermore, it exhibits robust generalization, achieving notable performance gains when applied to other baseline models.

</details>


### [129] [Visible Structure Retrieval for Lightweight Image-Based Relocalisation](https://arxiv.org/abs/2511.12503)
*Fereidoon Zangeneh,Leonard Bruns,Amit Dekel,Alessandro Pieropan,Patric Jensfelt*

Main category: cs.CV

TL;DR: 本文提出了一种新的视觉重定位方法，通过学习从图像到可见场景结构的直接映射，来减小2D-3D对应搜索空间，从而提高定位精度并降低计算和存储成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于结构的方法在大型场景中进行姿态估计时，面临搜索效率和存储成本的问题，现有方法依赖启发式搜索或图像检索，但这会增加管道复杂性或存储需求。

Method: 提出了一种新的方法，通过学习一个紧凑的神经网络，直接从图像观测映射到可见的场景结构。该网络能够预测图像所见的3D结构点子集，从而缩小2D-3D对应搜索的范围。

Result: 实验证明，该方法在定位精度上达到与现有技术水平相当的水平，同时在计算和存储方面表现更优。

Conclusion: 本文提出的方法通过直接学习图像到可见结构点云的映射，成功解决了大规模场景中视觉重定位的效率和存储问题，在精度和资源消耗方面都取得了良好效果。

Abstract: Accurate camera pose estimation from an image observation in a previously mapped environment is commonly done through structure-based methods: by finding correspondences between 2D keypoints on the image and 3D structure points in the map. In order to make this correspondence search tractable in large scenes, existing pipelines either rely on search heuristics, or perform image retrieval to reduce the search space by comparing the current image to a database of past observations. However, these approaches result in elaborate pipelines or storage requirements that grow with the number of past observations. In this work, we propose a new paradigm for making structure-based relocalisation tractable. Instead of relying on image retrieval or search heuristics, we learn a direct mapping from image observations to the visible scene structure in a compact neural network. Given a query image, a forward pass through our novel visible structure retrieval network allows obtaining the subset of 3D structure points in the map that the image views, thus reducing the search space of 2D-3D correspondences. We show that our proposed method enables performing localisation with an accuracy comparable to the state of the art, while requiring lower computational and storage footprint.

</details>


### [130] [DINO-Detect: A Simple yet Effective Framework for Blur-Robust AI-Generated Image Detection](https://arxiv.org/abs/2511.12511)
*Jialiang Shen,Jiyang Zheng,Yunqi Xue,Huajie Chen,Yu Yao,Hui Kang,Ruiqi Liu,Helin Gong,Yang Yang,Dadong Wang,Tongliang Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种基于师生知识蒸馏的模糊鲁棒AI生成图像检测框架，通过教师模型（DINOv3）提供指导，学生模型在模糊图像上进行训练，以提高在真实世界图像退化（尤其是运动模糊）下的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的AI生成图像（AIGI）检测器在处理运动模糊等真实世界退化时性能下降严重，因为运动模糊会扭曲纹理并抑制高频伪影。

Method: 利用师生知识蒸馏，一个在清晰图像上训练的高容量教师模型（DINOv3）提供其特征和logit响应，一个在模糊图像上训练的学生模型通过蒸馏来学习，以生成在运动模糊下的鲁棒表示。

Result: 所提出的方法在运动模糊和清晰条件下均达到了最先进的性能，证明了其泛化能力和在真实世界应用中的有效性。

Conclusion: 所提出的模糊鲁棒AIGI检测框架通过知识蒸馏有效解决了运动模糊问题，提高了AIGI检测器的鲁棒性和泛化能力。

Abstract: With growing concerns over image authenticity and digital safety, the field of AI-generated image (AIGI) detection has progressed rapidly. Yet, most AIGI detectors still struggle under real-world degradations, particularly motion blur, which frequently occurs in handheld photography, fast motion, and compressed video. Such blur distorts fine textures and suppresses high-frequency artifacts, causing severe performance drops in real-world settings. We address this limitation with a blur-robust AIGI detection framework based on teacher-student knowledge distillation. A high-capacity teacher (DINOv3), trained on clean (i.e., sharp) images, provides stable and semantically rich representations that serve as a reference for learning. By freezing the teacher to maintain its generalization ability, we distill its feature and logit responses from sharp images to a student trained on blurred counterparts, enabling the student to produce consistent representations under motion degradation. Extensive experiments benchmarks show that our method achieves state-of-the-art performance under both motion-blurred and clean conditions, demonstrating improved generalization and real-world applicability. Source codes will be released at: https://github.com/JiaLiangShen/Dino-Detect-for-blur-robust-AIGC-Detection.

</details>


### [131] [MdaIF: Robust One-Stop Multi-Degradation-Aware Image Fusion with Language-Driven Semantics](https://arxiv.org/abs/2511.12525)
*Jing Li,Yifan Wang,Jiafeng Yan,Renlong Zhang,Bin Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 MdaIF 的一体化、退化感知图像融合框架，用于处理多种恶劣天气条件下的图像融合问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态图像融合方法未能充分考虑恶劣天气（如雾、雨、雪）导致的图像退化，且依赖固定的网络结构，适应性差，这限制了融合性能。本研究旨在解决这些问题，提出一个能适应不同退化场景的图像融合框架。

Method: 提出了一种名为 MdaIF 的一体化退化感知图像融合框架。该框架采用混合专家（MoE）系统来处理不同退化场景（雾、雨、雪）的图像融合。利用预训练的视觉-语言模型（VLM）提取语义先验，以适应性地获取不同退化场景的知识和场景特征。基于此语义先验，设计了退化感知通道注意力模块（DCAM），通过通道域的特征交互进行多模态融合。最后，利用语义先验和通道域特征来指导 MoE 进行专家路由，实现鲁棒的图像融合。

Result: 通过大量实验证明，MdaIF 框架在复杂退化场景下能够实现有效的图像融合，并且性能优于现有最先进的方法。

Conclusion: MdaIF 框架通过结合混合专家系统、视觉-语言模型和退化感知通道注意力机制，能够有效处理多种恶劣天气条件下的图像退化问题，显著提升了图像融合的性能和鲁棒性。

Abstract: Infrared and visible image fusion aims to integrate complementary multi-modal information into a single fused result. However, existing methods 1) fail to account for the degradation visible images under adverse weather conditions, thereby compromising fusion performance; and 2) rely on fixed network architectures, limiting their adaptability to diverse degradation scenarios. To address these issues, we propose a one-stop degradation-aware image fusion framework for multi-degradation scenarios driven by a large language model (MdaIF). Given the distinct scattering characteristics of different degradation scenarios (e.g., haze, rain, and snow) in atmospheric transmission, a mixture-of-experts (MoE) system is introduced to tackle image fusion across multiple degradation scenarios. To adaptively extract diverse weather-aware degradation knowledge and scene feature representations, collectively referred to as the semantic prior, we employ a pre-trained vision-language model (VLM) in our framework. Guided by the semantic prior, we propose degradation-aware channel attention module (DCAM), which employ degradation prototype decomposition to facilitate multi-modal feature interaction in channel domain. In addition, to achieve effective expert routing, the semantic prior and channel-domain modulated features are utilized to guide the MoE, enabling robust image fusion in complex degradation scenarios. Extensive experiments validate the effectiveness of our MdaIF, demonstrating superior performance over SOTA methods.

</details>


### [132] [D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation](https://arxiv.org/abs/2511.12528)
*Zheyuan Zhang,Jiwei Zhang,Boyu Zhou,Linzhimeng Duan,Hong Chen*

Main category: cs.CV

TL;DR: D2-VPR是一个基于蒸馏和可变形注意力的方法，通过知识蒸馏和设计新的模块，在保持DINOv2强大特征提取能力的同时，显著减少了模型参数和计算量，实现了更好的性能-效率权衡，并在视觉地点识别任务上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉基础模型（如DINOv2）的视觉地点识别方法虽然性能强大，但模型复杂度和计算开销大，难以在资源受限设备上部署。

Method: 提出D2-VPR框架，采用两阶段训练策略（知识蒸馏和微调），并引入蒸馏恢复模块（DRM）以更好地对齐教师和学生模型的特征空间；设计了基于Top-Down注意力的可变形聚合器（TDDA），利用全局语义特征自适应调整感兴趣区域（ROI）用于聚合。

Result: D2-VPR相比CricaVPR，参数量减少约64.2%，FLOPs减少约62.6%，同时实现了有竞争力的性能。

Conclusion: D2-VPR在视觉地点识别任务上，通过知识蒸馏和可变形聚合，有效降低了模型复杂度和计算成本，实现了优越的性能-效率折衷。

Abstract: Visual Place Recognition (VPR) aims to determine the geographic location of a query image by retrieving its most visually similar counterpart from a geo-tagged reference database. Recently, the emergence of the powerful visual foundation model, DINOv2, trained in a self-supervised manner on massive datasets, has significantly improved VPR performance. This improvement stems from DINOv2's exceptional feature generalization capabilities but is often accompanied by increased model complexity and computational overhead that impede deployment on resource-constrained devices. To address this challenge, we propose $D^{2}$-VPR, a $D$istillation- and $D$eformable-based framework that retains the strong feature extraction capabilities of visual foundation models while significantly reducing model parameters and achieving a more favorable performance-efficiency trade-off. Specifically, first, we employ a two-stage training strategy that integrates knowledge distillation and fine-tuning. Additionally, we introduce a Distillation Recovery Module (DRM) to better align the feature spaces between the teacher and student models, thereby minimizing knowledge transfer losses to the greatest extent possible. Second, we design a Top-Down-attention-based Deformable Aggregator (TDDA) that leverages global semantic features to dynamically and adaptively adjust the Regions of Interest (ROI) used for aggregation, thereby improving adaptability to irregular structures. Extensive experiments demonstrate that our method achieves competitive performance compared to state-of-the-art approaches. Meanwhile, it reduces the parameter count by approximately 64.2% and FLOPs by about 62.6% (compared to CricaVPR).Code is available at https://github.com/tony19980810/D2VPR.

</details>


### [133] [ReaSon: Reinforced Causal Search with Information Bottleneck for Video Understanding](https://arxiv.org/abs/2511.12530)
*Yuan Zhou,Litao Hua,Shilong Jin,Wentao Huang,Haoran Duan*

Main category: cs.CV

TL;DR: ReaSon框架通过引入因果信息瓶颈（CIB）来优化视频关键帧选择，以满足预测充分性和因果必要性。


<details>
  <summary>Details</summary>
Motivation: 视频理解需要有效捕捉信息且具有因果决定性的关键帧，以应对视觉-语言模型（VLMs）的输入限制和信息的时间稀疏性。

Method: ReaSon框架使用可学习策略网络选择候选帧以捕捉预测充分性，并通过反事实干预评估因果必要性，利用强化学习和CIB原则的复合奖励来指导选择策略。

Result: 在NExT-QA、EgoSchema和Video-MME数据集上的实验表明，ReaSon在有限帧数设置下持续优于现有最先进方法。

Conclusion: ReaSon框架在视频关键帧选择方面是有效且泛化能力强的。

Abstract: Keyframe selection has become essential for video understanding with vision-language models (VLMs) due to limited input tokens and the temporal sparsity of relevant information across video frames. Video understanding often relies on effective keyframes that are not only informative but also causally decisive. To this end, we propose Reinforced Causal Search with Information Bottleneck (ReaSon), a framework that formulates keyframe selection as an optimization problem with the help of a novel Causal Information Bottleneck (CIB), which explicitly defines keyframes as those satisfying both predictive sufficiency and causal necessity. Specifically, ReaSon employs a learnable policy network to select keyframes from a visually relevant pool of candidate frames to capture predictive sufficiency, and then assesses causal necessity via counterfactual interventions. Finally, a composite reward aligned with the CIB principle is designed to guide the selection policy through reinforcement learning. Extensive experiments on NExT-QA, EgoSchema, and Video-MME demonstrate that ReaSon consistently outperforms existing state-of-the-art methods under limited-frame settings, validating its effectiveness and generalization ability.

</details>


### [134] [HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models](https://arxiv.org/abs/2511.12547)
*Zhiguang Lu,Qianqian Xu,Peisong Wen,Siran Da,Qingming Huang*

Main category: cs.CV

TL;DR: HiGFA是一种新的数据增强方法，通过利用扩散采样过程中的时序动态，并结合文本、轮廓和细粒度分类器引导，能够生成多样化且忠实的合成图像，在细粒度视觉分类任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 标准的文本条件生成模型在细粒度任务中存在挑战，因为它们难以确保生成的图像包含细微的类别定义特征，可能产生误导性样本，从而影响分类器性能。

Method: HiGFA利用扩散采样的时序动态，在早期和中期采用固定强度的文本和变换轮廓引导来建立整体场景、风格和结构，在后期激活专门的细粒度分类器引导，并根据预测置信度动态调整所有引导信号的强度。

Result: HiGFA能够生成多样化且忠实的合成图像，通过智能地平衡全局结构形成和精确细节优化，在多个细粒度视觉分类（FGVC）数据集上进行了实验验证。

Conclusion: HiGFA通过分层、置信度驱动的引导策略，有效解决了细粒度图像生成中的挑战，提高了数据增强的质量和有效性。

Abstract: Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.

</details>


### [135] [EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis](https://arxiv.org/abs/2511.12554)
*Yijie Guo,Dexiang Hong,Weidong Chen,Zihan She,Cheng Ye,Xiaojun Chang,Zhendong Mao*

Main category: cs.CV

TL;DR: EmoVerse是一个大型开放数据集，通过多层、知识图谱启发的注释，实现可解释的视觉情感分析，将情绪分解为背景-属性-主体（B-A-S）三元组，并为分类情感状态（CES）和维度情感空间（DES）提供双重注释，同时引入了一个可解释模型。


<details>
  <summary>Details</summary>
Motivation: 现有视觉情感分析（VEA）研究因缺乏开源、可解释的数据集而受限，通常只为整张图像分配单一离散情感标签，无法深入了解视觉元素如何影响情感。

Method: 通过将情感分解为背景-属性-主体（B-A-S）三元组，并将每个元素与视觉区域关联，EmoVerse实现了词级别和主体级别的で情感推理。该数据集包含超过21.9万张图像，并提供分类情感状态（CES）和维度情感空间（DES）的双重注释。采用新颖的多阶段流程确保了高注释可靠性。此外，还引入了一个可解释模型，将视觉线索映射到DES表示，并提供详细的归因解释。

Result: EmoVerse数据集包含超过21.9万张图像，并提供CES和DES双重注释，支持离散和连续的情感表示。引入的可解释模型能够将视觉线索映射到DES表示，并提供详细的归因解释。

Conclusion: EmoVerse数据集、新颖的注释流程和可解释模型共同为推进可解释的高层次情感理解奠定了全面的基础。

Abstract: Visual Emotion Analysis (VEA) aims to bridge the affective gap between visual content and human emotional responses. Despite its promise, progress in this field remains limited by the lack of open-source and interpretable datasets. Most existing studies assign a single discrete emotion label to an entire image, offering limited insight into how visual elements contribute to emotion. In this work, we introduce EmoVerse, a large-scale open-source dataset that enables interpretable visual emotion analysis through multi-layered, knowledge-graph-inspired annotations. By decomposing emotions into Background-Attribute-Subject (B-A-S) triplets and grounding each element to visual regions, EmoVerse provides word-level and subject-level emotional reasoning. With over 219k images, the dataset further includes dual annotations in Categorical Emotion States (CES) and Dimensional Emotion Space (DES), facilitating unified discrete and continuous emotion representation. A novel multi-stage pipeline ensures high annotation reliability with minimal human effort. Finally, we introduce an interpretable model that maps visual cues into DES representations and provides detailed attribution explanations. Together, the dataset, pipeline, and model form a comprehensive foundation for advancing explainable high-level emotion understanding.

</details>


### [136] [SEMC: Structure-Enhanced Mixture-of-Experts Contrastive Learning for Ultrasound Standard Plane Recognition](https://arxiv.org/abs/2511.12559)
*Qing Cai,Guihao Yan,Fan Zhang,Cheng Zhang,Zhi Liu*

Main category: cs.CV

TL;DR: SEMC通过结合语义-结构融合模块（SSFM）和混合专家对比识别模块（MCRM），提出了一种新的超声标准平面识别框架，以解决现有方法在利用浅层结构信息和捕捉细粒度语义差异方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有超声标准平面识别方法未能有效利用浅层结构信息，并难以通过对比样本捕捉细粒度的语义差异，导致对结构和区分性细节的识别效果不佳。

Method: 提出了一种新的结构增强混合专家对比学习框架（SEMC），结合了结构感知特征融合和专家指导的对比学习。具体来说，首先引入了一个新的语义-结构融合模块（SSFM），用于利用多尺度结构信息，并通过有效对齐浅层和深层特征来增强模型感知细粒度结构细节的能力。然后，设计了一个新的混合专家对比识别模块（MCRM），利用混合专家（MoE）机制在多层次特征上执行分层对比学习和分类，进一步提高了类可分离性和识别性能。此外，还整理了一个包含六个标准平面的大规模、精心标注的肝脏超声数据集。

Result: 在内部数据集和两个公共数据集上的大量实验结果表明，SEMC在各种指标上均优于最近的最先进方法。

Conclusion: SEMC框架通过其创新的SSFM和MCRM模块，在超声标准平面识别任务上取得了显著的性能提升，证明了其在捕捉结构信息和提高类可分离性方面的有效性。

Abstract: Ultrasound standard plane recognition is essential for clinical tasks such as disease screening, organ evaluation, and biometric measurement. However, existing methods fail to effectively exploit shallow structural information and struggle to capture fine-grained semantic differences through contrastive samples generated by image augmentations, ultimately resulting in suboptimal recognition of both structural and discriminative details in ultrasound standard planes. To address these issues, we propose SEMC, a novel Structure-Enhanced Mixture-of-Experts Contrastive learning framework that combines structure-aware feature fusion with expert-guided contrastive learning. Specifically, we first introduce a novel Semantic-Structure Fusion Module (SSFM) to exploit multi-scale structural information and enhance the model's ability to perceive fine-grained structural details by effectively aligning shallow and deep features. Then, a novel Mixture-of-Experts Contrastive Recognition Module (MCRM) is designed to perform hierarchical contrastive learning and classification across multi-level features using a mixture-of-experts (MoE) mechanism, further improving class separability and recognition performance. More importantly, we also curate a large-scale and meticulously annotated liver ultrasound dataset containing six standard planes. Extensive experimental results on our in-house dataset and two public datasets demonstrate that SEMC outperforms recent state-of-the-art methods across various metrics.

</details>


### [137] [Through-Foliage Surface-Temperature Reconstruction for early Wildfire Detection](https://arxiv.org/abs/2511.12572)
*Mohamed Youssef,Lukas Brunner,Klaus Rundhammer,Gerald Czech,Oliver Bimber*

Main category: cs.CV

TL;DR: 本研究提出一种结合信号处理与机器学习的新方法，用于重建被森林植被遮挡的表面温度，以实现全自动航拍野火监测和早期火灾探测。


<details>
  <summary>Details</summary>
Motivation: 为了实现能够早期探测到烟雾或火焰可见之前的地面火灾的全自动航拍野火监测，特别是在有森林植被遮挡的情况下。

Method: 利用视觉状态空间模型从经过去模糊处理的合成孔径（SA）传感器数据中恢复部分遮挡的土壤和火点热信号。通过将潜在扩散模型整合到向量量化器中，并结合温度增强和程序化热力森林模拟，生成了大量的真实表面温度模拟数据，以克服真实世界训练数据稀缺的挑战。

Result: 在模拟数据上，该方法将均方根误差（RMSE）降低了2到2.5倍。在实地实验中，与传统热成像相比，RMSE提高了12.8倍，与未校正的SA图像相比，RMSE提高了2.6倍。此外，该方法能够重建完整的火灾和人类信号形态，克服了部分遮挡的问题，并证明了其对其他热信号（如搜救中的人类信号）的泛化能力。

Conclusion: 该方法能够有效解决森林植被遮挡问题，精确重建表面温度，并在野火探测和搜救等领域具有显著优势。

Abstract: We introduce a novel method for reconstructing surface temperatures through occluding forest vegetation by combining signal processing and machine learning. Our goal is to enable fully automated aerial wildfire monitoring using autonomous drones, allowing for the early detection of ground fires before smoke or flames are visible. While synthetic aperture (SA) sensing mitigates occlusion from the canopy and sunlight, it introduces thermal blur that obscures the actual surface temperatures. To address this, we train a visual state space model to recover the subtle thermal signals of partially occluded soil and fire hotspots from this blurred data. A key challenge was the scarcity of real-world training data. We overcome this by integrating a latent diffusion model into a vector quantized to generated a large volume of realistic surface temperature simulations from real wildfire recordings, which we further expanded through temperature augmentation and procedural thermal forest simulation. On simulated data across varied ambient and surface temperatures, forest densities, and sunlight conditions, our method reduced the RMSE by a factor of 2 to 2.5 compared to conventional thermal and uncorrected SA imaging. In field experiments focused on high-temperature hotspots, the improvement was even more significant, with a 12.8-fold RMSE gain over conventional thermal and a 2.6-fold gain over uncorrected SA images. We also demonstrate our model's generalization to other thermal signals, such as human signatures for search and rescue. Since simple thresholding is frequently inadequate for detecting subtle thermal signals, the morphological characteristics are equally essential for accurate classification. Our experiments demonstrated another clear advantage: we reconstructed the complete morphology of fire and human signatures, whereas conventional imaging is defeated by partial occlusion.

</details>


### [138] [Beyond Pixels: Semantic-aware Typographic Attack for Geo-Privacy Protection](https://arxiv.org/abs/2511.12575)
*Jiayi Zhu,Yihao Huang,Yue Cao,Xiaojun Jia,Qing Guo,Felix Juefei-Xu,Geguang Pu,Bin Wang*

Main category: cs.CV

TL;DR: 大型视觉语言模型（LVLM）可能泄露用户地理位置，现有对抗性扰动方法会损害图像质量。本文提出一种基于文本的对抗性攻击方法，通过添加具有欺骗性语义的文本来保护用户地理位置隐私，该方法在不损害图像视觉质量的情况下，有效降低了LVLM的地理位置预测精度。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLM）能够从图像中推断用户地理位置，对用户隐私构成威胁。现有的基于图像扰动的隐私保护方法需要较强的失真才能有效，这会明显降低图像质量。因此，需要一种既能有效保护隐私又不损害图像视觉质量的方法。

Method: 提出一种基于文本的“印刷攻击”（typographical attacks），通过在图像外部添加文本来干扰LVLM的地理位置推断。设计了一种两阶段、语义感知的印刷攻击方法，生成欺骗性的文本来保护用户隐私。

Result: 在三个数据集上的广泛实验表明，该方法显著降低了五个最先进的商用LVLM的地理位置预测准确率，提供了一种实用且视觉上无损的隐私保护策略。

Conclusion: 基于文本的印刷攻击是一种有效的、视觉上无损的保护用户地理位置隐私免受LVLM威胁的策略。

Abstract: Large Visual Language Models (LVLMs) now pose a serious yet overlooked privacy threat, as they can infer a social media user's geolocation directly from shared images, leading to unintended privacy leakage. While adversarial image perturbations provide a potential direction for geo-privacy protection, they require relatively strong distortions to be effective against LVLMs, which noticeably degrade visual quality and diminish an image's value for sharing. To overcome this limitation, we identify typographical attacks as a promising direction for protecting geo-privacy by adding text extension outside the visual content. We further investigate which textual semantics are effective in disrupting geolocation inference and design a two-stage, semantics-aware typographical attack that generates deceptive text to protect user privacy. Extensive experiments across three datasets demonstrate that our approach significantly reduces geolocation prediction accuracy of five state-of-the-art commercial LVLMs, establishing a practical and visually-preserving protection strategy against emerging geo-privacy threats.

</details>


### [139] [TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction](https://arxiv.org/abs/2511.12578)
*Yukuo Ma,Cong Liu,Junke Wang,Junqi Liu,Haibin Huang,Zuxuan Wu,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TempoMaster通过将长视频生成视为下一帧率预测来工作，首先生成低帧率的粗略视频，然后逐步提高帧率以完善细节和运动连续性，实现了长视频生成的最优效果。


<details>
  <summary>Details</summary>
Motivation: 长视频生成，具体而言，我们首先生成低帧率的剪辑，作为整个视频序列的粗略蓝图，然后逐步提高帧率以完善视觉细节和运动连续性。

Method: TempoMaster采用双向注意力和跨帧率的自回归来实现高效和并行的合成。

Result: TempoMaster在长视频生成方面确立了新的最先进水平，在视觉和时间质量方面均表现出色。

Conclusion: TempoMaster通过将长视频生成视为下一帧率预测，实现了长视频生成的最优效果。

Abstract: We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.

</details>


### [140] [Rank-Aware Agglomeration of Foundation Models for Immunohistochemistry Image Cell Counting](https://arxiv.org/abs/2511.12588)
*Zuqi Huang,Mengxin Tian,Huan Liu,Wentao Li,Baobao Liang,Jie Wu,Fang Yan,Zhaoqing Tang,Zhongyu Li*

Main category: cs.CV

TL;DR: CountIHC是一个用于免疫组织化学(IHC)图像的多类别细胞计数框架，通过知识蒸馏和视觉-语言对齐解决了细胞重叠和染色变异性等挑战。


<details>
  <summary>Details</summary>
Motivation: 免疫组织化学(IHC)图像中的细胞计数对于量化蛋白质表达和辅助癌症诊断至关重要，但面临细胞重叠、染色变异和形态多样性等挑战。现有方法在处理重叠细胞和进行多类别计数方面存在局限性。

Method: 提出了一种秩感知聚合框架，通过秩感知教师选择(RATS)策略从多个基础模型中蒸馏知识，并引入视觉-语言对齐微调阶段，利用离散语义锚点进行多类别细胞计数。

Result: CountIHC在12种IHC生物标志物和5种组织类型上超越了最先进的方法，并与病理学家的评估高度一致。该方法在苏木精-伊红(H&E)染色数据上也表现出有效性。

Conclusion: CountIHC通过创新的知识蒸馏和多类别计数策略，有效解决了IHC图像细胞计数中的关键挑战，并且具有良好的可扩展性。

Abstract: Accurate cell counting in immunohistochemistry (IHC) images is critical for quantifying protein expression and aiding cancer diagnosis. However, the task remains challenging due to the chromogen overlap, variable biomarker staining, and diverse cellular morphologies. Regression-based counting methods offer advantages over detection-based ones in handling overlapped cells, yet rarely support end-to-end multi-class counting. Moreover, the potential of foundation models remains largely underexplored in this paradigm. To address these limitations, we propose a rank-aware agglomeration framework that selectively distills knowledge from multiple strong foundation models, leveraging their complementary representations to handle IHC heterogeneity and obtain a compact yet effective student model, CountIHC. Unlike prior task-agnostic agglomeration strategies that either treat all teachers equally or rely on feature similarity, we design a Rank-Aware Teacher Selecting (RATS) strategy that models global-to-local patch rankings to assess each teacher's inherent counting capacity and enable sample-wise teacher selection. For multi-class cell counting, we introduce a fine-tuning stage that reformulates the task as vision-language alignment. Discrete semantic anchors derived from structured text prompts encode both category and quantity information, guiding the regression of class-specific density maps and improving counting for overlapping cells. Extensive experiments demonstrate that CountIHC surpasses state-of-the-art methods across 12 IHC biomarkers and 5 tissue types, while exhibiting high agreement with pathologists' assessments. Its effectiveness on H&E-stained data further confirms the scalability of the proposed method.

</details>


### [141] [Fine-Grained Representation for Lane Topology Reasoning](https://arxiv.org/abs/2511.12590)
*Guoqing Xu,Yiheng Li,Yang Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为TopoFG的细粒度车道拓扑推理框架，用于解决现有方法在复杂车道结构中拓扑预测不可靠的问题。TopoFG通过分层先验提取器（HPE）、区域聚焦解码器（RFD）和鲁棒边界点拓扑推理（RBTR）三个阶段，从BEV特征到拓扑预测进行细粒度推理。HPE提取全局空间先验和局部序列先验，RFD整合这些先验构建细粒度查询并细化表示，RBTR基于边界点查询和拓扑去噪策略进行连接性建模。实验结果表明，TopoFG在OpenLane-V2基准测试中取得了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以精确建模复杂车道结构，导致拓扑预测不可靠，需要更精确的车道拓扑建模以支持自动驾驶的导航和控制决策。

Method: TopoFG框架包括三个阶段：1. 分层先验提取器（HPE）：提取BEV掩码的全局空间先验和车道内关键点序列的局部序列先验。2. 区域聚焦解码器（RFD）：通过融合空间和序列先验来构建细粒度查询，并在RoI区域采样参考点，利用交叉注意力机制细化每个车道的查询表示。3. 鲁棒边界点拓扑推理（RBTR）：基于边界点查询特征进行车道连接性建模，并采用拓扑去噪策略减少匹配歧义。

Result: TopoFG方法通过整合先验信息到细粒度查询和采用去噪策略，能够精确建模复杂车道结构并提供可信的拓扑预测。在OpenLane-V2基准测试的subsetA上达到了48.0%的OLS，在subsetB上达到了45.4%的OLS，取得了新的最先进性能。

Conclusion: TopoFG框架通过引入细粒度查询和多阶段推理机制，有效解决了复杂车道拓扑建模的挑战，并在实验中证明了其优越性，为自动驾驶提供了更可靠的车道拓扑信息。

Abstract: Precise modeling of lane topology is essential for autonomous driving, as it directly impacts navigation and control decisions.Existing methods typically represent each lane with a single query and infer topological connectivity based on the similarity between lane queries.However, this kind of design struggles to accurately model complex lane structures, leading to unreliable topology prediction.In this view, we propose a Fine-Grained lane topology reasoning framework (TopoFG).It divides the procedure from bird's-eye-view (BEV) features to topology prediction via fine-grained queries into three phases, i.e., Hierarchical Prior Extractor (HPE), Region-Focused Decoder (RFD), and Robust Boundary-Point Topology Reasoning (RBTR).Specifically, HPE extracts global spatial priors from the BEV mask and local sequential priors from in-lane keypoint sequences to guide subsequent fine-grained query modeling.RFD constructs fine-grained queries by integrating the spatial and sequential priors. It then samples reference points in RoI regions of the mask and applies cross-attention with BEV features to refine the query representations of each lane.RBTR models lane connectivity based on boundary-point query features and further employs a topological denoising strategy to reduce matching ambiguity.By integrating spatial and sequential priors into fine-grained queries and applying a denoising strategy to boundary-point topology reasoning, our method precisely models complex lane structures and delivers trustworthy topology predictions.Extensive experiments on the OpenLane-V2 benchmark demonstrate that TopoFG achieves new state-of-the-art performance, with an OLS of 48.0% on subsetA and 45.4% on subsetB.

</details>


### [142] [Seg-VAR: Image Segmentation with Visual Autoregressive Modeling](https://arxiv.org/abs/2511.12594)
*Rongkun Zheng,Lu Qi,Xi Chen,Yi Wang,Kun Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Seg-VAR 将分割视为条件自回归掩码生成问题，通过引入图像编码器、空间感知 seglat 编码器和解码器，在分割任务上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉自回归模型（VAR）在图像生成方面取得了进展，但尚未在需要精细低级空间感知的分割任务上得到探索。

Method: Seg-VAR 框架将分割视为一个条件自回归掩码生成问题，通过（1）图像编码器提取图像的潜在先验；（2）空间感知 seglat 编码器将分割掩码映射到离散的潜在令牌（使用位置敏感的颜色映射来区分实例）；（3）解码器从这些潜在令牌中重建掩码。采用多阶段训练策略：首先通过图像-seglat 联合训练学习 seglat 表示，然后优化潜在转换，最后对齐图像编码器提取的潜在令牌与 seglat 分布。

Result: Seg-VAR 在多个分割任务和验证基准上，超越了之前的判别式和生成式方法。

Conclusion: Seg-VAR 通过将分割构建为顺序分层预测任务，为将自回归推理集成到空间感知视觉系统开辟了新途径。

Abstract: While visual autoregressive modeling (VAR) strategies have shed light on image generation with the autoregressive models, their potential for segmentation, a task that requires precise low-level spatial perception, remains unexplored. Inspired by the multi-scale modeling of classic Mask2Former-based models, we propose Seg-VAR, a novel framework that rethinks segmentation as a conditional autoregressive mask generation problem. This is achieved by replacing the discriminative learning with the latent learning process. Specifically, our method incorporates three core components: (1) an image encoder generating latent priors from input images, (2) a spatial-aware seglat (a latent expression of segmentation mask) encoder that maps segmentation masks into discrete latent tokens using a location-sensitive color mapping to distinguish instances, and (3) a decoder reconstructing masks from these latents. A multi-stage training strategy is introduced: first learning seglat representations via image-seglat joint training, then refining latent transformations, and finally aligning image-encoder-derived latents with seglat distributions. Experiments show Seg-VAR outperforms previous discriminative and generative methods on various segmentation tasks and validation benchmarks. By framing segmentation as a sequential hierarchical prediction task, Seg-VAR opens new avenues for integrating autoregressive reasoning into spatial-aware vision systems. Code will be available at https://github.com/rkzheng99/Seg-VAR.

</details>


### [143] [LoRA-Enhanced Vision Transformer for Single Image based Morphing Attack Detection via Knowledge Distillation from EfficientNet](https://arxiv.org/abs/2511.12602)
*Ria Shekhawat,Sushrut Patwardhan,Raghavendra Ramachandra,Praveen Kumar Chandaliya,Kishor P. Upla*

Main category: cs.CV

TL;DR: 提出了一种名为 S-MAD 的新颖单图像变形攻击检测方法，该方法使用教师-学生框架，并通过 LoRA 提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的面部识别系统（FRS）容易受到变形攻击，这会对安全系统构成威胁。

Method: 提出了一种利用教师-学生框架的新颖单图像变形攻击检测（S-MAD）方法，其中基于 CNN 的教师模型用于改进基于 ViT 的学生模型。为了提高效率，集成了低秩自适应（LoRA）进行微调。

Result: 所提出的方法在从三个公开可用的面部数据集中构建的变形数据集上进行了广泛的实验，并结合了十种不同的变形生成算法，以评估其稳健性。与六种最先进的 S-MAD 技术相比，该方法在检测性能和计算效率方面均表现出优越性。

Conclusion: S-MAD 方法能够有效检测单图像变形攻击，并具有出色的计算效率，能够应对各种变形生成技术。

Abstract: Face Recognition Systems (FRS) are critical for security but remain vulnerable to morphing attacks, where synthetic images blend biometric features from multiple individuals. We propose a novel Single-Image Morphing Attack Detection (S-MAD) approach using a teacher-student framework, where a CNN-based teacher model refines a ViT-based student model. To improve efficiency, we integrate Low-Rank Adaptation (LoRA) for fine-tuning, reducing computational costs while maintaining high detection accuracy. Extensive experiments are conducted on a morphing dataset built from three publicly available face datasets, incorporating ten different morphing generation algorithms to assess robustness. The proposed method is benchmarked against six state-of-the-art S-MAD techniques, demonstrating superior detection performance and computational efficiency.

</details>


### [144] [Pixels or Positions? Benchmarking Modalities in Group Activity Recognition](https://arxiv.org/abs/2511.12606)
*Drishya Karki,Merey Ramazanova,Anthony Cioppa,Silvio Giancola,Bernard Ghanem*

Main category: cs.CV

TL;DR: Tracking data is more effective and efficient for group activity recognition (GAR) than video data, as shown by the new SoccerNet-GAR dataset and benchmark.


<details>
  <summary>Details</summary>
Motivation: The paper aims to compare the effectiveness of video and tracking data for group activity recognition (GAR) and to establish a standardized benchmark for this comparison, as existing research has primarily focused on video data, leaving tracking data under-explored.

Method: The authors introduce SoccerNet-GAR, a multimodal dataset synchronized with broadcast videos and player tracking data from the 2022 Football World Cup, annotated with 94,285 group activities across 10 categories. They also define a unified evaluation protocol to benchmark video-based and tracking-based classifiers, with a specific focus on a novel role-aware graph architecture for tracking-based GAR that encodes tactical structure through positional edges and temporal attention.

Result: The tracking-based model, particularly the novel role-aware graph architecture, achieved 67.2% balanced accuracy, significantly outperforming the best video-based baseline at 58.1%. Furthermore, the tracking model trained 4.25 times faster and used 438 times fewer parameters (197K vs. 86.3M).

Conclusion: The study highlights that tracking data, when modeled with role-aware graph architectures, is superior to video data for group activity recognition in terms of both accuracy and efficiency. It emphasizes the importance of modality choice and specialized modeling for effective GAR.

Abstract: Group Activity Recognition (GAR) is well studied on the video modality for surveillance and indoor team sports (e.g., volleyball, basketball). Yet, other modalities such as agent positions and trajectories over time, i.e. tracking, remain comparatively under-explored despite being compact, agent-centric signals that explicitly encode spatial interactions. Understanding whether pixel (video) or position (tracking) modalities leads to better group activity recognition is therefore important to drive further research on the topic. However, no standardized benchmark currently exists that aligns broadcast video and tracking data for the same group activities, leading to a lack of apples-to-apples comparison between these modalities for GAR. In this work, we introduce SoccerNet-GAR, a multimodal dataset built from the $64$ matches of the football World Cup 2022. Specifically, the broadcast videos and player tracking modalities for $94{,}285$ group activities are synchronized and annotated with $10$ categories. Furthermore, we define a unified evaluation protocol to benchmark two strong unimodal approaches: (i) a competitive video-based classifiers and (ii) a tracking-based classifiers leveraging graph neural networks. In particular, our novel role-aware graph architecture for tracking-based GAR directly encodes tactical structure through positional edges and temporal attention. Our tracking model achieves $67.2\%$ balanced accuracy compared to $58.1\%$ for the best video baseline, while training $4.25 \times$ faster with $438 \times$ fewer parameters ($197K$ \vs $86.3M$). This study provides new insights into the relative strengths of pixels and positions for group activity recognition. Overall, it highlights the importance of modality choice and role-aware modeling for GAR.

</details>


### [145] [Open-World Test-Time Adaptation with Hierarchical Feature Aggregation and Attention Affine](https://arxiv.org/abs/2511.12607)
*Ziqiong Liu,Yushun Tang,Junyang Ji,Zhihai He*

Main category: cs.CV

TL;DR: 本文提出了一种分层梯形网络（Hierarchical Ladder Network, HLN）用于测试时域自适应（TTA），以解决模型在面对未见过的（OOD）类别时性能下降的问题。该网络通过聚合所有Transformer层的类令牌来提取OOD特征，并结合原始模型预测进行加权概率融合以增强OOD检测能力。此外，还引入了注意力仿射网络（Attention Affine Network, AAN）来适应域漂移，并采用加权熵机制来抑制低置信度样本的影响。实验证明该方法在常用分类数据集上显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时域自适应（TTA）方法在面对未见过的（OOD）类别时，性能会显著下降，并且可能导致对后续同类（ID）样本的错误适应。

Method: 提出分层梯形网络（HLN）提取OOD特征，并与原始模型预测进行加权概率融合。引入注意力仿射网络（AAN）自适应调整自注意力机制以应对域漂移。采用加权熵机制动态抑制低置信度样本的影响。

Result: 在常用分类数据集的实验中，所提出的方法显著提升了性能。

Conclusion: 该研究提出的分层梯形网络（HLN）结合注意力仿射网络（AAN）和加权熵机制，能够有效解决TTA在面对OOD样本和域漂移时的性能下降问题，并提升模型的整体分类表现。

Abstract: Test-time adaptation (TTA) refers to adjusting the model during the testing phase to cope with changes in sample distribution and enhance the model's adaptability to new environments. In real-world scenarios, models often encounter samples from unseen (out-of-distribution, OOD) categories. Misclassifying these as known (in-distribution, ID) classes not only degrades predictive accuracy but can also impair the adaptation process, leading to further errors on subsequent ID samples. Many existing TTA methods suffer substantial performance drops under such conditions. To address this challenge, we propose a Hierarchical Ladder Network that extracts OOD features from class tokens aggregated across all Transformer layers. OOD detection performance is enhanced by combining the original model prediction with the output of the Hierarchical Ladder Network (HLN) via weighted probability fusion. To improve robustness under domain shift, we further introduce an Attention Affine Network (AAN) that adaptively refines the self-attention mechanism conditioned on the token information to better adapt to domain drift, thereby improving the classification performance of the model on datasets with domain shift. Additionally, a weighted entropy mechanism is employed to dynamically suppress the influence of low-confidence samples during adaptation. Experimental results on benchmark datasets show that our method significantly improves the performance on the most widely used classification datasets.

</details>


### [146] [C3Net: Context-Contrast Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12627)
*Baber Jan,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: C3Net是一个用于检测伪装物体的模型，它通过创新的双通路解码器架构解决了内 in 相似性、边缘中断、极端尺度变化、环境复杂性、上下文依赖性和显著伪装物体消歧这六个核心挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的分割方法和现代基础模型在伪装物体检测（COD）任务上表现不佳，因为这些物体与周围环境在颜色、纹理和模式上高度相似，并且存在边缘中断、尺度变化、环境复杂性、上下文依赖性以及显著伪装物体消歧等固有挑战。

Method: C3Net采用一种特殊的双通路解码器架构：边缘细化通路（Edge Refinement Pathway）使用梯度初始化的边缘增强模块来恢复精确的边界；上下文定位通路（Contextual Localization Pathway）利用基于图像的上下文引导机制（Image-based Context Guidance）来实现内在显著性抑制；注意力融合模块（Attentive Fusion Module）通过空间门控机制协同融合两个通路的信息。

Result: C3Net在COD10K、CAMO和NC4K数据集上取得了最先进的性能，S度量分别达到了0.898、0.904和0.913，同时保持了高效的处理速度。

Conclusion: 复杂的、多方面的检测挑战需要架构创新，C3Net证明了专门的组件协同工作可以实现全面的覆盖，而不仅仅是孤立的改进。

Abstract: Camouflaged object detection identifies objects that blend seamlessly with their surroundings through similar colors, textures, and patterns. This task challenges both traditional segmentation methods and modern foundation models, which fail dramatically on camouflaged objects. We identify six fundamental challenges in COD: Intrinsic Similarity, Edge Disruption, Extreme Scale Variation, Environmental Complexities, Contextual Dependencies, and Salient-Camouflaged Object Disambiguation. These challenges frequently co-occur and compound the difficulty of detection, requiring comprehensive architectural solutions. We propose C3Net, which addresses all challenges through a specialized dual-pathway decoder architecture. The Edge Refinement Pathway employs gradient-initialized Edge Enhancement Modules to recover precise boundaries from early features. The Contextual Localization Pathway utilizes our novel Image-based Context Guidance mechanism to achieve intrinsic saliency suppression without external models. An Attentive Fusion Module synergistically combines the two pathways via spatial gating. C3Net achieves state-of-the-art performance with S-measures of 0.898 on COD10K, 0.904 on CAMO, and 0.913 on NC4K, while maintaining efficient processing. C3Net demonstrates that complex, multifaceted detection challenges require architectural innovation, with specialized components working synergistically to achieve comprehensive coverage beyond isolated improvements. Code, model weights, and results are available at https://github.com/Baber-Jan/C3Net.

</details>


### [147] [Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation](https://arxiv.org/abs/2511.12631)
*Yushe Cao,Dianxi Shi,Xing Fu,Xuechao Zou,Haikuo Peng,Xueqi Li,Chun Yu,Junliang Xing*

Main category: cs.CV

TL;DR: MDiTFace是一个创新的多模态面部生成框架，通过统一的标记化策略和新颖的解耦注意力机制，实现了高效的跨模态交互，显著提高了面部保真度和条件一致性，同时大幅降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态面部生成方法在融合语义掩码和文本描述时，由于跨模态交互不充分，导致生成效果不佳。

Method: 提出了一种名为MDiTFace的定制化扩散Transformer框架，它采用统一的标记化策略处理语义掩码和文本输入，并通过堆叠新设计的多元Transformer块促进跨模态特征的同步交互。此外，设计了一种解耦注意力机制，将掩码标记和时间嵌入的隐式依赖分离，分为动态和静态路径，实现了静态路径特征的缓存和重用，从而在不影响性能的情况下将掩码条件引入的额外计算开销减少了94%以上。

Result: 通过大量实验证明，MDiTFace在面部保真度和条件一致性方面显著优于其他现有方法。

Conclusion: MDiTFace通过有效的跨模态交互和优化的计算策略，成功解决了现有方法在多模态面部生成中的不足，取得了领先的性能。

Abstract: While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.

</details>


### [148] [Denoising Vision Transformer Autoencoder with Spectral Self-Regularization](https://arxiv.org/abs/2511.12633)
*Xunzhi Xiang,Xingye Tian,Guiyu Zhang,Yabo Chen,Shaofeng Zhang,Xuebo Wang,Xin Tao,Qi Fan*

Main category: cs.CV

TL;DR: 高维潜在空间中的冗余高频分量会阻碍生成模型的训练收敛，导致生成质量下降。本文提出了一种谱自正则化策略来抑制这种噪声，并引入了谱对齐策略来促进Denoising-VAE的优化，最终实现了更快的收敛速度和更好的生成质量。


<details>
  <summary>Details</summary>
Motivation: 在高维潜在空间中，提高重建保真度和生成性能之间存在优化困境。现有方法通过引入外部视觉基础模型（VFMs）来规范化高维潜在空间，但其对生成模型优化的影响尚不明确。

Method: 提出了一种谱自正则化策略来抑制高维潜在空间中的冗余高频分量，同时保持重建质量。在此基础上，设计了一个基于ViT的自编码器（Denoising-VAE），无需依赖VFMs。此外，还提出了一种谱对齐策略来促进Denoising-VAE的优化。

Result: Denoising-VAE生成的潜在空间噪声更少，从而提高了生成质量和优化收敛速度。与SD-VAE相比，该方法使扩散模型收敛速度大约快2倍，并在ImageNet 256x256基准上取得了最先进的重建质量（rFID = 0.28, PSNR = 27.26）和具有竞争力的生成性能（gFID = 1.82）。

Conclusion: 本文首次揭示了高维潜在空间中的冗余高频分量会阻碍扩散模型的训练收敛和生成质量。所提出的谱自正则化和谱对齐策略能够有效解决这一问题，从而实现更高质量和更快速的生成模型优化。

Abstract: Variational autoencoders (VAEs) typically encode images into a compact latent space, reducing computational cost but introducing an optimization dilemma: a higher-dimensional latent space improves reconstruction fidelity but often hampers generative performance. Recent methods attempt to address this dilemma by regularizing high-dimensional latent spaces using external vision foundation models (VFMs). However, it remains unclear how high-dimensional VAE latents affect the optimization of generative models. To our knowledge, our analysis is the first to reveal that redundant high-frequency components in high-dimensional latent spaces hinder the training convergence of diffusion models and, consequently, degrade generation quality. To alleviate this problem, we propose a spectral self-regularization strategy to suppress redundant high-frequency noise while simultaneously preserving reconstruction quality. The resulting Denoising-VAE, a ViT-based autoencoder that does not rely on VFMs, produces cleaner, lower-noise latents, leading to improved generative quality and faster optimization convergence. We further introduce a spectral alignment strategy to facilitate the optimization of Denoising-VAE-based generative models. Our complete method enables diffusion models to converge approximately 2$\times$ faster than with SD-VAE, while achieving state-of-the-art reconstruction quality (rFID = 0.28, PSNR = 27.26) and competitive generation performance (gFID = 1.82) on the ImageNet 256$\times$256 benchmark.

</details>


### [149] [Medical Knowledge Intervention Prompt Tuning for Medical Image Classification](https://arxiv.org/abs/2511.12639)
*Ye Du,Nanxi Yu,Shujun Wang*

Main category: cs.CV

TL;DR: CILMP通过整合大型语言模型（LLM）和视觉语言模型（VLM）来改进医学图像分类中的提示调优，利用LLM的医学知识生成更具适应性的提示，并在各种数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的提示调优方法在区分不同医学概念和利用特定疾病特征方面存在不足，而大型语言模型（LLM）在这方面具有优势。因此，需要一种方法来将LLM的医学知识融入提示调优过程。

Method: 提出CILMP（Conditional Intervention of Large Language Models for Prompt Tuning），一种将LLM和VLM相结合的方法。CILMP从LLM中提取疾病特定表示，在低秩线性子空间中进行干预，并生成特定于疾病的提示。此外，引入条件机制，根据每个医学图像调整提示，实现实例自适应。

Result: 在各种医学图像数据集上的大量实验表明，CILMP的性能持续优于最先进的提示调优方法。

Conclusion: CILMP有效地利用LLM的医学知识来增强VLM在医学图像分类任务中的提示调优，通过生成特定于疾病和实例的自适应提示，提高了模型的性能和适应性。

Abstract: Vision-language foundation models (VLMs) have shown great potential in feature transfer and generalization across a wide spectrum of medical-related downstream tasks. However, fine-tuning these models is resource-intensive due to their large number of parameters. Prompt tuning has emerged as a viable solution to mitigate memory usage and reduce training time while maintaining competitive performance. Nevertheless, the challenge is that existing prompt tuning methods cannot precisely distinguish different kinds of medical concepts, which miss essentially specific disease-related features across various medical imaging modalities in medical image classification tasks. We find that Large Language Models (LLMs), trained on extensive text corpora, are particularly adept at providing this specialized medical knowledge. Motivated by this, we propose incorporating LLMs into the prompt tuning process. Specifically, we introduce the CILMP, Conditional Intervention of Large Language Models for Prompt Tuning, a method that bridges LLMs and VLMs to facilitate the transfer of medical knowledge into VLM prompts. CILMP extracts disease-specific representations from LLMs, intervenes within a low-rank linear subspace, and utilizes them to create disease-specific prompts. Additionally, a conditional mechanism is incorporated to condition the intervention process on each individual medical image, generating instance-adaptive prompts and thus enhancing adaptability. Extensive experiments across diverse medical image datasets demonstrate that CILMP consistently outperforms state-of-the-art prompt tuning methods, demonstrating its effectiveness. Code is available at https://github.com/usr922/cilmp.

</details>


### [150] [DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry](https://arxiv.org/abs/2511.12653)
*Cheng Liao*

Main category: cs.CV

TL;DR: DPVO-QAT++框架通过异构精度和CUDA核函数融合技术，在保持高精度视觉里程计性能的同时，显著降低了计算开销，使其适用于资源受限的平台。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的视觉SLAM系统计算开销大，难以部署于资源受限的自主平台。

Method: 提出DPVO-QAT++框架，采用可学习尺度参数化、VO前后端异构精度设计（前端使用FP16/FP32虚量化，后端使用全精度）以及虚量化操作的GPU原生核函数融合（自定义CUDA核函数）。

Result: 在TartanAir数据集上，FPS平均提升52.1%，中值延迟降低29.1%，峰值GPU显存占用减少64.9%；在EuRoC数据集上，FPS平均提升30.1%，中值延迟降低23.1%，峰值GPU显存占用减少37.7%。两种数据集的轨迹精度（ATE）与原DPVO模型相当。

Conclusion: DPVO-QAT++框架有效解决了高精度深度视觉里程计与实际部署效率之间的矛盾，为该技术在嵌入式平台上的应用提供了可行的工程范式。

Abstract: Deep learning-based Visual SLAM (vSLAM) systems exhibit exceptional geometric reasoning capabilities, yet their prohibitive computational overhead severely restricts deployment on resource-constrained autonomous platforms. This paper presents a hierarchical quantization optimization framework, DPVO-QAT++ (DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry). Through the synergistic integration of learnable scale parameterization, a heterogeneous precision design for the Visual Odometry (VO) front-end and back-end (front-end floating-point fake quantization with FP16/FP32; back-end full precision), and GPU-native kernel fusion for fake quantization (custom CUDA kernels), our framework significantly reduces memory footprint and increases processing speed while preserving the trajectory accuracy of the original model. On the TartanAir dataset, our framework achieves an average FPS increase of 52.1%, a 29.1% reduction in median latency, and a 64.9% reduction in peak GPU memory reservation, while maintaining trajectory accuracy (ATE) comparable to the original DPVO model across 32 validation sequences. On the EuRoC dataset, it realizes an average FPS increase of 30.1%, a 23.1% reduction in median latency, and a 37.7% reduction in peak GPU memory reservation, maintaining comparable trajectory accuracy (ATE) across 11 validation sequences. Experimental results demonstrate that DPVO-QAT++ effectively bridges the gap between high-precision deep VO and the efficiency requirements for practical deployment, offering a viable engineering paradigm for the application of this technology on real-world embedded platforms.
  Keywords: Visual Odometry, Heterogeneous Precision Architecture, Quantization-Aware Training, CUDA Kernel Fusion, Scale-Only Training, Deep Patch Visual Odometry, GPU-Native Kernel Fusion.

</details>


### [151] [Toward Real-world Text Image Forgery Localization: Structured and Interpretable Data Synthesis](https://arxiv.org/abs/2511.12658)
*Zeqin Yu,Haotao Xie,Jian Zhang,Jiangqun Ni,Wenkan Su,Jiwu Huang*

Main category: cs.CV

TL;DR: FSTS是一个用于合成篡改文本图像的框架，通过分析真实篡改痕迹来生成更多样化和逼真的训练数据，从而提高现有文本图像篡改定位方法的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文本图像篡改定位（T-IFL）方法由于真实数据集规模有限以及合成数据与真实世界篡改的复杂性之间存在分布差距，通常泛化能力较差。

Method: FSTS首先收集了16,750个真实世界的篡改实例，涵盖五种代表性篡改类型，利用多格式日志（如视频、PSD和编辑日志）记录人工编辑痕迹。通过分析这些收集到的参数并识别个体和群体层面的重复行为模式，构建了一个分层建模框架。其中，每个单独的篡改参数被表示为基础操作-参数配置的紧凑组合，而群体层面的分布则通过聚合这些行为来构建。该方法从傅里叶级数中汲取灵感，通过基函数及其学习到的权重实现可解释的近似。通过从该建模分布中采样，FSTS合成了更多样化和逼真的训练数据，更好地反映了现实世界的篡改痕迹。

Result: 通过FSTS合成的数据训练的模型在真实世界数据集上的泛化能力显著提高，在四个评估协议上的广泛实验证明了这一点。

Conclusion: FSTS框架通过分析真实篡改痕迹并从建模的分布中采样，能够合成更多样化和逼真的训练数据，显著提高了文本图像篡改定位方法的泛化能力。

Abstract: Existing Text Image Forgery Localization (T-IFL) methods often suffer from poor generalization due to the limited scale of real-world datasets and the distribution gap caused by synthetic data that fails to capture the complexity of real-world tampering. To tackle this issue, we propose Fourier Series-based Tampering Synthesis (FSTS), a structured and interpretable framework for synthesizing tampered text images. FSTS first collects 16,750 real-world tampering instances from five representative tampering types, using a structured pipeline that records human-performed editing traces via multi-format logs (e.g., video, PSD, and editing logs). By analyzing these collected parameters and identifying recurring behavioral patterns at both individual and population levels, we formulate a hierarchical modeling framework. Specifically, each individual tampering parameter is represented as a compact combination of basis operation-parameter configurations, while the population-level distribution is constructed by aggregating these behaviors. Since this formulation draws inspiration from the Fourier series, it enables an interpretable approximation using basis functions and their learned weights. By sampling from this modeled distribution, FSTS synthesizes diverse and realistic training data that better reflect real-world forgery traces. Extensive experiments across four evaluation protocols demonstrate that models trained with FSTS data achieve significantly improved generalization on real-world datasets. Dataset is available at \href{https://github.com/ZeqinYu/FSTS}{Project Page}.

</details>


### [152] [Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans](https://arxiv.org/abs/2511.12662)
*Hongbin Huang,Junwei Li,Tianxin Xie,Zhuang Li,Cekai Weng,Yaodong Yang,Yue Luo,Li Liu,Jing Tang,Zhijing Shao,Zeyu Wang*

Main category: cs.CV

TL;DR: 开发了一个结合了视觉逼真度、情感化语音合成和知识驱动对话生成的高保真、实时对话数字人系统，通过异步执行管道和检索增强方法实现了低延迟交互。


<details>
  <summary>Details</summary>
Motivation: 实现高视觉真实感和实时响应的交互式数字人系统。 

Method: 提出了一种异步执行管道来协调多模态组件，以最小化延迟。并利用了包括历史增强和基于意图的路由在内的检索增强方法。

Result: 该系统支持唤醒词检测、情感化韵律和上下文感知响应生成等高级功能，实现了低延迟交互。

Conclusion: 所提出的集成系统能够实现响应迅速且可信的数字人，适用于通信、教育和娱乐等沉浸式应用。

Abstract: High-fidelity digital humans are increasingly used in interactive applications, yet achieving both visual realism and real-time responsiveness remains a major challenge. We present a high-fidelity, real-time conversational digital human system that seamlessly combines a visually realistic 3D avatar, persona-driven expressive speech synthesis, and knowledge-grounded dialogue generation. To support natural and timely interaction, we introduce an asynchronous execution pipeline that coordinates multi-modal components with minimal latency. The system supports advanced features such as wake word detection, emotionally expressive prosody, and highly accurate, context-aware response generation. It leverages novel retrieval-augmented methods, including history augmentation to maintain conversational flow and intent-based routing for efficient knowledge access. Together, these components form an integrated system that enables responsive and believable digital humans, suitable for immersive applications in communication, education, and entertainment.

</details>


### [153] [DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality](https://arxiv.org/abs/2511.12671)
*Tushar Anand,Advik Sinha,Abhijit Das*

Main category: cs.CV

TL;DR: 该研究提出了一种准确且实时的光流和视差估计模型，通过在提出的非因果选择性状态空间中融合配对输入图像，以实现密集感知任务。


<details>
  <summary>Details</summary>
Motivation: 为了实现准确且实时的光流和视差估计，同时满足实时应用程序的约束。

Method: 提出了一种基于非因果Mamba块的模型，该模型快速高效，并能管理实时应用中的约束。

Result: 所提出的模型在保持高准确率和低GPU占用的同时，减少了推理时间，并能生成光流和视差图。

Conclusion: 在真实场景中的结果、分析和验证表明，所提出的模型可用于统一的实时、准确的3D密集感知估计任务。

Abstract: In this work, we propose an accurate and real-time optical flow and disparity estimation model by fusing pairwise input images in the proposed non-causal selective state space for dense perception tasks. We propose a non-causal Mamba block-based model that is fast and efficient and aptly manages the constraints present in a real-time applications. Our proposed model reduces inference times while maintaining high accuracy and low GPU usage for optical flow and disparity map generation. The results and analysis, and validation in real-life scenario justify that our proposed model can be used for unified real-time and accurate 3D dense perception estimation tasks. The code, along with the models, can be found at https://github.com/vimstereo/DensePerceptNCSSD

</details>


### [154] [Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis](https://arxiv.org/abs/2511.12675)
*Saar Stern,Ido Sobol,Or Litany*

Main category: cs.CV

TL;DR: 生成式模型（特别是基于扩散的方法）在novel view synthesis (NVS) 方面取得了显著进步，但评估生成图像的真实性和对源视图及视角变换的忠实度仍然是一个挑战。现有的评估指标未能准确捕捉这种细微关系。


<details>
  <summary>Details</summary>
Motivation: 评估新视角合成（NVS）中生成图像的可靠性是一个重大挑战，现有的评估指标未能准确捕捉生成图像与源视图及预期视角变换之间的细微关系。

Method: 提出一个任务感知评估框架，利用强大的NVS基础模型Zero123的特征，并结合轻量级微调步骤来增强判别力。在此基础上，引入两个互补的评估指标：一个基于参考的得分 $D_{	ext{PRISM}}$，一个无参考的得分 $	ext{MMD}_{	ext{PRISM}}$。

Result: 所提出的评估指标能够可靠地识别不正确的生成结果，并且在模型排名上与人类偏好研究一致。在Toys4K、GSO和OmniObject3D三个基准测试中，无参考指标 $	ext{MMD}_{	ext{PRISM}}$ 对六种NVS方法产生了清晰稳定的排名，得分越低表示模型性能越强。

Conclusion: 所提出的评估框架为评估NVS的合成质量提供了一个原则性且实用的方法，有助于推动NVS领域的可靠进展。

Abstract: The goal of Novel View Synthesis (NVS) is to generate realistic images of a given content from unseen viewpoints. But how can we trust that a generated image truly reflects the intended transformation? Evaluating its reliability remains a major challenge. While recent generative models, particularly diffusion-based approaches, have significantly improved NVS quality, existing evaluation metrics struggle to assess whether a generated image is both realistic and faithful to the source view and intended viewpoint transformation. Standard metrics, such as pixel-wise similarity and distribution-based measures, often mis-rank incorrect results as they fail to capture the nuanced relationship between the source image, viewpoint change, and generated output. We propose a task-aware evaluation framework that leverages features from a strong NVS foundation model, Zero123, combined with a lightweight tuning step to enhance discrimination. Using these features, we introduce two complementary evaluation metrics: a reference-based score, $D_{\text{PRISM}}$, and a reference-free score, $\text{MMD}_{\text{PRISM}}$. Both reliably identify incorrect generations and rank models in agreement with human preference studies, addressing a fundamental gap in NVS evaluation. Our framework provides a principled and practical approach to assessing synthesis quality, paving the way for more reliable progress in novel view synthesis. To further support this goal, we apply our reference-free metric to six NVS methods across three benchmarks: Toys4K, Google Scanned Objects (GSO), and OmniObject3D, where $\text{MMD}_{\text{PRISM}}$ produces a clear and stable ranking, with lower scores consistently indicating stronger models.

</details>


### [155] [BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections](https://arxiv.org/abs/2511.12676)
*Subin Varghese,Joshua Gao,Asad Ur Rahman,Vedhus Hoskere*

Main category: cs.CV

TL;DR: 本研究提出了一个名为BridgeEQA的新基准，用于在现实世界的桥梁检查场景中进行开放词汇的具身问答 (EQA)。该基准包含2200个问题-答案对，并利用国家桥梁检查标准 (NBI) 进行评估。为了解决现有模型的不足，研究者还提出了Embodied Memory Visual Reasoning (EMVR) 模型，该模型通过在基于图像的场景图中进行序列导航来解决检查问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界的具身智能体在理解周围环境并回答相关问题方面仍然面临挑战，这主要是因为缺乏能够真实反映实际操作条件的基准。因此，本研究提出将基础设施检查作为开放词汇具身问答的一个有吸引力的应用领域。

Method: 研究者引入了BridgeEQA基准，该基准包含2200个问题-答案对，基于专业检查报告，覆盖200个现实世界的桥梁场景，平均每个场景有47.93张图像。问题需要整合来自多张图像的视觉证据，并将答案与NBI条件评分对齐。此外，研究者还提出了一个新的EQA指标Image Citation Relevance，用于评估模型引用相关图像的能力。为了解决现有模型的性能差距，研究者提出了Embodied Memory Visual Reasoning (EMVR) 模型，该模型将检查过程构建为在基于图像的场景图上进行序列导航，并通过马尔可夫决策过程进行推理。

Result: 对最先进的视觉-语言模型的评估显示，在情景记忆EQA设置下存在显著的性能差距。EMVR模型在评估中表现出比基线模型更强的性能。

Conclusion: 本研究提出的BridgeEQA基准和EMVR模型为具身问答领域带来了新的进展，尤其是在需要多尺度推理、空间理解和语义关联的复杂现实世界场景中。研究者公开发布了数据集和代码，以促进该领域的研究。

Abstract: Deploying embodied agents that can answer questions about their surroundings in realistic real-world settings remains difficult, partly due to the scarcity of benchmarks that faithfully capture practical operating conditions. We propose infrastructure inspection as a compelling domain for open-vocabulary Embodied Question Answering (EQA): it naturally demands multi-scale reasoning, long-range spatial understanding, and complex semantic relationships, while offering unique evaluation advantages via standardized National Bridge Inventory (NBI) condition ratings (0-9), professional inspection reports, and egocentric imagery.
  We introduce BridgeEQA, a benchmark of 2,200 open-vocabulary question-answer pairs (in the style of OpenEQA) grounded in professional inspection reports across 200 real-world bridge scenes with 47.93 images on average per scene. Questions require synthesizing visual evidence across multiple images and aligning responses with NBI condition ratings. We further propose a new EQA metric Image Citation Relevance to evaluate the ability of a model to cite relevant images.
  Evaluations of state-of-the-art vision-language models reveal substantial performance gaps under episodic memory EQA settings. To address this, we propose Embodied Memory Visual Reasoning (EMVR), which formulates inspection as sequential navigation over an image-based scene graph: images are nodes, and an agent takes actions to traverse views, compare evidence, and reason within a Markov decision process. EMVR shows strong performance over the baselines. We publicly release both the dataset and code.

</details>


### [156] [R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection](https://arxiv.org/abs/2511.12691)
*Shuaike Shen,Ke Liu,Jiaqing Xie,Shangde Gao,Chunhua Shen,Ge Liu,Mireia Crispin-Ortuzar,Shangqi Gao*

Main category: cs.CV

TL;DR: R$^{2}$Seg是一个无需训练的框架，通过“推理-拒绝”两阶段过程，利用LLM引导的规划和统计检验来提高医学图像分割中肿瘤分割对分布外（OOD）移位的鲁棒性，有效减少虚假阳性。


<details>
  <summary>Details</summary>
Motivation: 由于分布外（OOD）移位，医学图像分割的基础模型在分割OOD肿瘤时常出现碎片化的假阳性。本研究旨在解决这一问题，提高OOD肿瘤分割的鲁棒性。

Method: R$^{2}$Seg框架包含两个阶段：1. 推理阶段：使用LLM引导的解剖推理规划器来定位器官锚点并生成多尺度感兴趣区域（ROIs）。2. 拒绝阶段：对来自冻结的基础模型（BiomedParse）在这些ROIs中生成的候选分割结果，应用双样本统计检验，仅保留与正常组织有显著差异的候选分割，从而有效抑制假阳性。

Result: 在多中心、多模态肿瘤分割基准测试中，R$^{2}$Seg在Dice、特异性和敏感性方面显著优于强基线模型和原始基础模型。该框架无需参数更新，兼容无需更新的测试时间增强，并避免了灾难性遗忘。

Conclusion: R$^{2}$Seg通过其两阶段的“推理-拒绝”过程，有效解决了基础模型在OOD场景下的分割挑战，显著提高了肿瘤分割的准确性和鲁棒性，且无需进行模型训练或更新。

Abstract: Foundation models for medical image segmentation struggle under out-of-distribution (OOD) shifts, often producing fragmented false positives on OOD tumors. We introduce R$^{2}$Seg, a training-free framework for robust OOD tumor segmentation that operates via a two-stage Reason-and-Reject process. First, the Reason step employs an LLM-guided anatomical reasoning planner to localize organ anchors and generate multi-scale ROIs. Second, the Reject step applies two-sample statistical testing to candidates generated by a frozen foundation model (BiomedParse) within these ROIs. This statistical rejection filter retains only candidates significantly different from normal tissue, effectively suppressing false positives. Our framework requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center and multi-modal tumor segmentation benchmarks, R$^{2}$Seg substantially improves Dice, specificity, and sensitivity over strong baselines and the original foundation models. Code are available at https://github.com/Eurekashen/R2Seg.

</details>


### [157] [HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models](https://arxiv.org/abs/2511.12693)
*Sushant Gautam,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: HEDGE是一个统一的框架，用于检测视觉语言模型（VLMs）的幻觉，通过结合视觉扰动、语义聚类和不确定性度量来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在开放式视觉问答方面容易出现幻觉，需要一个有效的检测框架。

Method: HEDGE框架整合了采样、失真合成、聚类（基于蕴含和嵌入）以及度量计算，形成一个可复现的流水线，适用于不同的多模态架构。

Result: 在VQA-RAD和KvasirVQA-x1数据集上，针对LLaVA-Med、Med-Gemma和Qwen2.5-VL三种代表性VLMs的评估显示，幻觉的可检测性与模型架构和提示密切相关。统一融合模型（如Qwen2.5-VL）的可检测性最高，而受限的（如Med-Gemma）最低。嵌入式聚类在直接应用于生成答案时效果更好，而NLI聚类则在LLaVA-Med和句子级响应中更具优势。VASE度量结合嵌入式聚类和适度的采样预算（n ~ 10-15）时，提供了最稳健的幻觉信号。简洁的标签式输出比单句响应更清晰。

Conclusion: HEDGE将幻觉检测视为一个受采样规模、提示结构、模型架构和聚类策略共同影响的几何鲁棒性问题，为评估多模态可靠性提供了原则性、计算感知的基础。

Abstract: Vision-language models (VLMs) enable open-ended visual question answering but remain prone to hallucinations. We present HEDGE, a unified framework for hallucination detection that combines controlled visual perturbations, semantic clustering, and robust uncertainty metrics. HEDGE integrates sampling, distortion synthesis, clustering (entailment- and embedding-based), and metric computation into a reproducible pipeline applicable across multimodal architectures.
  Evaluations on VQA-RAD and KvasirVQA-x1 with three representative VLMs (LLaVA-Med, Med-Gemma, Qwen2.5-VL) reveal clear architecture- and prompt-dependent trends. Hallucination detectability is highest for unified-fusion models with dense visual tokenization (Qwen2.5-VL) and lowest for architectures with restricted tokenization (Med-Gemma). Embedding-based clustering often yields stronger separation when applied directly to the generated answers, whereas NLI-based clustering remains advantageous for LLaVA-Med and for longer, sentence-level responses. Across configurations, the VASE metric consistently provides the most robust hallucination signal, especially when paired with embedding clustering and a moderate sampling budget (n ~ 10-15). Prompt design also matters: concise, label-style outputs offer clearer semantic structure than syntactically constrained one-sentence responses.
  By framing hallucination detection as a geometric robustness problem shaped jointly by sampling scale, prompt structure, model architecture, and clustering strategy, HEDGE provides a principled, compute-aware foundation for evaluating multimodal reliability. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE .

</details>


### [158] [X-VMamba: Explainable Vision Mamba](https://arxiv.org/abs/2511.12694)
*Mohamed A. Mabrok,Yalda Zafari*

Main category: cs.CV

TL;DR: Mamba等视觉状态空间模型(SSM)在序列建模中显示出潜力，但其空间信息处理方式仍不透明。本文提出了一种基于可控性的可解释性框架，通过量化输入序列部分对SSM内部状态动力学的影响来解决此问题。该框架包含基于雅可比矩阵和格拉姆矩阵的两种方法，具有线性复杂度和无需修改模型架构的优点。实验表明，SSM在医学影像处理中具有层级特征提炼能力，并且其分析结果与诊断标准和扫描策略相关。该框架可应用于多种领域，为SSM提供统一的可解释性范式。


<details>
  <summary>Details</summary>
Motivation: 为了解决视觉状态空间模型(SSM)（如Mamba）在处理空间信息方面缺乏透明度和可解释性的问题，本文提出了一种基于可控性的可解释性框架。

Method: 提出两种互补的SSM可解释性方法：1. 基于雅可比矩阵的方法，适用于任何SSM架构，通过状态传播链测量影响。2. 基于格拉姆矩阵的方法，适用于对角线SSM，通过解析解实现更快的速度。这两种方法均可在单次前向传播中完成，具有线性复杂度，无需修改模型架构或调整超参数。

Result: 通过在三种不同的医学影像模态上进行实验验证，结果表明SSM能够自然地实现从早期层面的弥散低级纹理到后期层面聚焦的、具有临床意义的模式的层级特征提炼。分析揭示了与诊断标准一致的领域特定可控性特征、跨越网络层级的渐进式空间选择性，以及扫描策略对注意力模式的显著影响。

Conclusion: 所提出的基于可控性的可解释性框架能够量化输入序列部分对SSM内部状态动力学的影响，揭示了SSM在医学影像等领域的层级特征提炼能力、领域特定特征以及对扫描策略的敏感性。该框架为SSM提供了一种统一、基础性的可解释性范式，并可扩展到计算机视觉、自然语言处理等多个领域。

Abstract: State Space Models (SSMs), particularly the Mamba architecture, have recently emerged as powerful alternatives to Transformers for sequence modeling, offering linear computational complexity while achieving competitive performance. Yet, despite their effectiveness, understanding how these Vision SSMs process spatial information remains challenging due to the lack of transparent, attention-like mechanisms. To address this gap, we introduce a controllability-based interpretability framework that quantifies how different parts of the input sequence (tokens or patches) influence the internal state dynamics of SSMs. We propose two complementary formulations: a Jacobian-based method applicable to any SSM architecture that measures influence through the full chain of state propagation, and a Gramian-based approach for diagonal SSMs that achieves superior speed through closed-form analytical solutions. Both methods operate in a single forward pass with linear complexity, requiring no architectural modifications or hyperparameter tuning. We validate our framework through experiments on three diverse medical imaging modalities, demonstrating that SSMs naturally implement hierarchical feature refinement from diffuse low-level textures in early layers to focused, clinically meaningful patterns in deeper layers. Our analysis reveals domain-specific controllability signatures aligned with diagnostic criteria, progressive spatial selectivity across the network hierarchy, and the substantial influence of scanning strategies on attention patterns. Beyond medical imaging, we articulate applications spanning computer vision, natural language processing, and cross-domain tasks. Our framework establishes controllability analysis as a unified, foundational interpretability paradigm for SSMs across all domains. Code and analysis tools will be made available upon publication

</details>


### [159] [Counting Through Occlusion: Framework for Open World Amodal Counting](https://arxiv.org/abs/2511.12702)
*Safaeid Hossain Arib,Rabeya Akter,Abdul Monaf Chowdhury,Md Jubair Ahmed Sourov,Md Mehedi Hasan*

Main category: cs.CV

TL;DR: CountOCC是一个新的模型，用于在遮挡情况下进行物体计数，它通过重建被遮挡物体的特征来解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有物体计数方法在处理遮挡问题时表现不佳，因为骨干网络会将遮挡物体的特征编码为目标物体，从而破坏了准确计数的特征表示。

Method: CountOCC通过分层多模态引导来显式地重建被遮挡物体的特征。它整合了可见碎片、文本和视觉嵌入的空间上下文，以合成完整的、具有类区分性的特征。此外，它还引入了一个视觉等价性目标，以确保被遮挡和未被遮挡的场景的注意力图在空间上对齐。

Result: CountOCC在FSC 147数据集上实现了最先进的性能，在验证集和测试集上的平均绝对误差（MAE）分别降低了26.72%和20.80%。该模型还在CARPK数据集上取得了49.89%的MAE降低，在CAPTUREReal数据集上取得了28.79%的MAE降低，证明了其在不同视觉领域下鲁棒的非模型计数能力。

Conclusion: CountOCC通过集成上下文信息和强制对齐的注意力图，有效地解决了遮挡物体计数的问题，并在多个数据集上取得了最先进的性能。

Abstract: Object counting has achieved remarkable success on visible instances, yet state-of-the-art (SOTA) methods fail under occlusion, a pervasive challenge in real world deployment. This failure stems from a fundamental architectural limitation where backbone networks encode occluding surfaces rather than target objects, thereby corrupting the feature representations required for accurate enumeration. To address this, we present CountOCC, an amodal counting framework that explicitly reconstructs occluded object features through hierarchical multimodal guidance. Rather than accepting degraded encodings, we synthesize complete representations by integrating spatial context from visible fragments with semantic priors from text and visual embeddings, generating class-discriminative features at occluded locations across multiple pyramid levels. We further introduce a visual equivalence objective that enforces consistency in attention space, ensuring that both occluded and unoccluded views of the same scene produce spatially aligned gradient-based attention maps. Together, these complementary mechanisms preserve discriminative properties essential for accurate counting under occlusion. For rigorous evaluation, we establish occlusion-augmented versions of FSC 147 and CARPK spanning both structured and unstructured scenes. CountOCC achieves SOTA performance on FSC 147 with 26.72% and 20.80% MAE reduction over prior baselines under occlusion in validation and test, respectively. CountOCC also demonstrates exceptional generalization by setting new SOTA results on CARPK with 49.89% MAE reduction and on CAPTUREReal with 28.79% MAE reduction, validating robust amodal counting across diverse visual domains. Code will be released soon.

</details>


### [160] [FSDAM: Few-Shot Driving Attention Modeling via Vision-Language Coupling](https://arxiv.org/abs/2511.12708)
*Kaiser Hamid,Can Cui,Khandakar Ashrafi Akbar,Ziran Wang,Nade Liang*

Main category: cs.CV

TL;DR: FSDAM是一个新框架，使用少量（约100个）标注示例即可实现驾驶员视线预测和意图解释的联合生成，远少于现有方法所需的数量。它通过一个双通路架构，结合空间预测和图像描述生成，并通过跨模态对齐来保持语义一致性。FSDAM在视线预测方面表现具有竞争力，生成的解释连贯且符合上下文，并在多个驾驶基准测试中展现了强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 理解驾驶员的视线和注意力转移对于能够解读人类意图并为其行为辩护的自主系统至关重要。现有的大部分模型依赖于大规模的注视数据集，但这些数据集的收集和整理成本高昂且耗时。

Method: 提出了一种名为FSDAM（少样本驾驶员注意力建模）的框架，该框架采用双通路架构。独立模块分别处理空间预测和图像描述生成，并通过跨模态对齐来保持语义一致性。

Result: FSDAM在注意力预测方面取得了有竞争力的性能，并能生成连贯且符合上下文的解释。该模型在多个驾驶基准测试中表现出强大的零样本泛化能力。

Conclusion: 该研究表明，在监督有限的情况下，仍然可以实现有效的注意力条件生成，为在数据受限场景下部署可解释的驾驶员注意力系统开辟了新的可能性。

Abstract: Understanding where drivers look and why they shift their attention is essential for autonomous systems that read human intent and justify their actions. Most existing models rely on large-scale gaze datasets to learn these patterns; however, such datasets are labor-intensive to collect and time-consuming to curate. We present FSDAM (Few-Shot Driver Attention Modeling), a framework that achieves joint attention prediction and caption generation with approximately 100 annotated examples, two orders of magnitude fewer than existing approaches. Our approach introduces a dual-pathway architecture where separate modules handle spatial prediction and caption generation while maintaining semantic consistency through cross-modal alignment. Despite minimal supervision, FSDAM achieves competitive performance on attention prediction, generates coherent, and context-aware explanations. The model demonstrates robust zero-shot generalization across multiple driving benchmarks. This work shows that effective attention-conditioned generation is achievable with limited supervision, opening new possibilities for practical deployment of explainable driver attention systems in data-constrained scenarios.

</details>


### [161] [Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning](https://arxiv.org/abs/2511.12735)
*Ankita Raj,Chetan Arora*

Main category: cs.CV

TL;DR: 本文首次研究了开放词汇目标检测器（OVOD）的后门攻击，提出了一种名为TrAP的新型攻击方法，该方法通过优化图像和文本提示参数以及视觉触发器来注入恶意行为，实现了轻量级、可学习的后门植入，并在多个数据集上取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 随着OVOD在机器人、自动驾驶和监控等高风险领域的应用日益广泛，理解其安全风险变得至关重要。因此，研究OVOD的后门攻击是必要的。

Method: 提出TrAP（Trigger-Aware Prompt tuning）攻击策略，该策略联合优化图像和文本模态的提示参数以及视觉触发器，利用轻量级、可学习的提示令牌植入恶意行为，而不重新训练基础模型权重。采用基于课程的学习策略逐步缩小触发器尺寸，以实现在推理时使用小型触发器块有效激活后门。

Result: TrAP在多个数据集上实现了高攻击成功率，能够同时实现目标误分类和目标消失攻击。此外，与零样本设置相比，TrAP在下游数据集上的干净图像性能也有所提升。

Conclusion: TrAP是一种有效的多模态后门注入策略，能够针对OVOD植入隐蔽的后门，同时保持模型的泛化能力和在干净图像上的性能。

Abstract: Open-vocabulary object detectors (OVODs) unify vision and language to detect arbitrary object categories based on text prompts, enabling strong zero-shot generalization to novel concepts. As these models gain traction in high-stakes applications such as robotics, autonomous driving, and surveillance, understanding their security risks becomes crucial. In this work, we conduct the first study of backdoor attacks on OVODs and reveal a new attack surface introduced by prompt tuning. We propose TrAP (Trigger-Aware Prompt tuning), a multi-modal backdoor injection strategy that jointly optimizes prompt parameters in both image and text modalities along with visual triggers. TrAP enables the attacker to implant malicious behavior using lightweight, learnable prompt tokens without retraining the base model weights, thus preserving generalization while embedding a hidden backdoor. We adopt a curriculum-based training strategy that progressively shrinks the trigger size, enabling effective backdoor activation using small trigger patches at inference. Experiments across multiple datasets show that TrAP achieves high attack success rates for both object misclassification and object disappearance attacks, while also improving clean image performance on downstream datasets compared to the zero-shot setting.

</details>


### [162] [Direct Visual Grounding by Directing Attention of Visual Tokens](https://arxiv.org/abs/2511.12738)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 视觉语言模型（VLM）在处理涉及图像的问题时，存在视觉信息注意力分配不足的问题。本研究提出了一种新的KL散度注意力损失（KLAL），以更直接地监督视觉标记的注意力，从而提高VLM在各种视觉任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在最终层中，尽管视觉标记与查询最相关，但它们获得的注意力却很少，这可能导致视觉问答错误。这表明标准的下一个标记预测（NTP）损失不足以引导模型关注视觉标记。

Method: 提出了一种新的KL散度注意力损失（KLAL），该损失直接监督视觉标记的注意力，通过将视觉标记的注意力分布与真实注意力图进行对齐来实现。真实注意力图可以从合成数据中的任务几何或真实图像中的标准标注（如边界框或点标注）获得。KLAL与NTP结合使用，旨在鼓励VLM在生成答案标记时关注相关的视觉标记。

Result: KLAL与NTP结合使用，在几何任务、指向任务和指代表达理解任务上，无论是在合成数据还是真实世界数据上，都取得了显著的性能提升。此外，研究还引入了一个新的数据集，用于评估VLM的线条追踪能力，并发现即使是商业VLM在该任务上的表现也不佳。

Conclusion: 通过直接监督视觉标记的注意力，KLAL能够有效地解决VLM在视觉任务中注意力分配不足的问题，从而显著提高其性能。

Abstract: Vision Language Models (VLMs) mix visual tokens and text tokens. A puzzling issue is the fact that visual tokens most related to the query receive little to no attention in the final layers of the LLM module of VLMs from the answer tokens, where all tokens are treated equally, in particular, visual and language tokens in the LLM attention layers. This fact may result in wrong answers to visual questions, as our experimental results confirm. It appears that the standard next-token prediction (NTP) loss provides an insufficient signal for directing attention to visual tokens. We hypothesize that a more direct supervision of the attention of visual tokens to corresponding language tokens in the LLM module of VLMs will lead to improved performance on visual tasks. To demonstrate that this is indeed the case, we propose a novel loss function that directly supervises the attention of visual tokens. It directly grounds the answer language tokens in images by directing their attention to the relevant visual tokens. This is achieved by aligning the attention distribution of visual tokens to ground truth attention maps with KL divergence. The ground truth attention maps are obtained from task geometry in synthetic cases or from standard grounding annotations (e.g., bounding boxes or point annotations) in real images, and are used inside the LLM for attention supervision without requiring new labels. The obtained KL attention loss (KLAL) when combined with NTP encourages VLMs to attend to relevant visual tokens while generating answer tokens. This results in notable improvements across geometric tasks, pointing, and referring expression comprehension on both synthetic and real-world data, as demonstrated by our experiments. We also introduce a new dataset to evaluate the line tracing abilities of VLMs. Surprisingly, even commercial VLMs do not perform well on this task.

</details>


### [163] [Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests](https://arxiv.org/abs/2511.12740)
*Amirhossein Hassanzadeh,Bartosz Krawczyk,Michael Saunders,Rob Wible,Keith Krause,Dimah Dera,Jan van Aardt*

Main category: cs.CV

TL;DR: 该研究提出了一种基于KPConv的多目标回归方法，利用低级别体素内容（如目标占用百分比）来推断高级别体素化LiDAR点云数据，以解决体素化带来的信息损失问题。研究通过成本敏感学习（DBR）和加权MSE、FocalR、正则化等方法处理类别不平衡问题，并进行了体素尺寸（0.25-2米）的敏感性分析。结果表明，较大的体素尺寸（2米）误差较低，而较小的体素尺寸（0.25或0.5米）误差较高，尤其是在冠层区域。这表明体素尺寸的选择取决于具体应用。该研究填补了森林LiDAR点云多目标回归和深度不平衡学习模型的空白。


<details>
  <summary>Details</summary>
Motivation: 体素化虽然能降低LiDAR数据处理成本，但会损失精细的结构信息。本研究旨在探索是否能从高级别体素化LiDAR数据中推断出低级别的体素内容信息（如目标占用百分比），以弥补信息损失。

Method: 提出了一种基于KPConv的多目标回归方法，并结合成本敏感学习（DBR）来处理类别不平衡问题。采用了加权MSE、Focal Regression（FocalR）和正则化等技术来优化KPConv模型。此外，还进行了体素尺寸（0.25-2米）的敏感性分析。

Result: 敏感性分析表明，较大的体素尺寸（如2米）由于变异性降低而导致较低的误差，而较小的体素尺寸（如0.25或0.5米）则导致较高的误差，尤其是在冠层区域，因为该区域的变异性最大。对于树皮和树叶目标，较小体素尺寸数据集（0.25和0.5米）的误差值明显高于较大体素尺寸数据集（2米），这凸显了在精细分辨率下准确估计冠层内体素内容物的难度。

Conclusion: 研究结果表明，体素尺寸的选择是应用驱动的，需要根据具体需求进行权衡。较小的体素尺寸虽然能保留更多细节，但在处理高变异性区域（如森林冠层）时，估计体素内容物的准确性会受到影响。本研究为森林LiDAR点云的多目标回归和深度不平衡学习模型提供了新的解决方案。

Abstract: Voxelization is an effective approach to reduce the computational cost of processing Light Detection and Ranging (LiDAR) data, yet it results in a loss of fine-scale structural information. This study explores whether low-level voxel content information, specifically target occupancy percentage within a voxel, can be inferred from high-level voxelized LiDAR point cloud data collected from Digital Imaging and remote Sensing Image Generation (DIRSIG) software. In our study, the targets include bark, leaf, soil, and miscellaneous materials. We propose a multi-target regression approach in the context of imbalanced learning using Kernel Point Convolutions (KPConv). Our research leverages cost-sensitive learning to address class imbalance called density-based relevance (DBR). We employ weighted Mean Saquared Erorr (MSE), Focal Regression (FocalR), and regularization to improve the optimization of KPConv. This study performs a sensitivity analysis on the voxel size (0.25 - 2 meters) to evaluate the effect of various grid representations in capturing the nuances of the forest. This sensitivity analysis reveals that larger voxel sizes (e.g., 2 meters) result in lower errors due to reduced variability, while smaller voxel sizes (e.g., 0.25 or 0.5 meter) exhibit higher errors, particularly within the canopy, where variability is greatest. For bark and leaf targets, error values at smaller voxel size datasets (0.25 and 0.5 meter) were significantly higher than those in larger voxel size datasets (2 meters), highlighting the difficulty in accurately estimating within-canopy voxel content at fine resolutions. This suggests that the choice of voxel size is application-dependent. Our work fills the gap in deep imbalance learning models for multi-target regression and simulated datasets for 3D LiDAR point clouds of forests.

</details>


### [164] [SAGE: Saliency-Guided Contrastive Embeddings](https://arxiv.org/abs/2511.12744)
*Colton R. Crum,Adam Czajka*

Main category: cs.CV

TL;DR: 本研究提出SAGE，一种利用人类视觉显著性引导的对比学习嵌入方法，用于改进神经网络的泛化能力和分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有将人类感知先验（如视觉显著性）融入神经网络训练的方法，常依赖于模型内部机制，而这可能并不可靠。然而，将人类感知先验集成到模型训练中可以提高模型的泛化能力，作为有效的正则化器，并使模型与高风险领域的人类专业知识保持一致。

Method: SAGE通过在模型的潜在空间（而非图像空间）使用对比学习嵌入来整合人类显著性。具体方法包括：1. 应用保持和降级显著性的信号增强技术到输入数据。2. 捕捉增强对模型嵌入和logits的影响。3. 使用对比三元组损失，引导模型关注显著特征，远离非显著特征。4. 通过对logits分布进行健全性检查，确保模型输出与基于显著性的增强相匹配。

Result: SAGE在开放集和闭集场景下均提升了分类性能，优于现有的基于显著性的方法。实验证明了SAGE在不同骨干网络上的有效性，并表明其在多种任务上具有广泛的泛化能力。

Conclusion: SAGE通过将人类显著性引导移至模型的潜在空间并利用对比学习，能够有效提升神经网络的分类性能和泛化能力，并且在不同模型和任务上都表现出良好的适应性。

Abstract: Integrating human perceptual priors into the training of neural networks has been shown to raise model generalization, serve as an effective regularizer, and align models with human expertise for applications in high-risk domains. Existing approaches to integrate saliency into model training often rely on internal model mechanisms, which recent research suggests may be unreliable. Our insight is that many challenges associated with saliency-guided training stem from the placement of the guidance approaches solely within the image space. Instead, we move away from the image space, use the model's latent space embeddings to steer human guidance during training, and we propose SAGE (Saliency-Guided Contrastive Embeddings): a loss function that integrates human saliency into network training using contrastive embeddings. We apply salient-preserving and saliency-degrading signal augmentations to the input and capture the changes in embeddings and model logits. We guide the model towards salient features and away from non-salient features using a contrastive triplet loss. Additionally, we perform a sanity check on the logit distributions to ensure that the model outputs match the saliency-based augmentations. We demonstrate a boost in classification performance across both open- and closed-set scenarios against SOTA saliency-based methods, showing SAGE's effectiveness across various backbones, and include experiments to suggest its wide generalization across tasks.

</details>


### [165] [Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion](https://arxiv.org/abs/2511.12757)
*Nicholas Karris,Luke Durell,Javier Flores,Tegan Emerson*

Main category: cs.CV

TL;DR: Stable Diffusion的CLIP嵌入具有排列不变性，可将嵌入视为Wasserstein空间中的点云，而非欧氏空间中的矩阵。这促使我们将提示之间的插值问题重新构建为最优传输问题，通过计算嵌入之间的最短路径（测地线）来生成更平滑、更连贯的中间图像。实验证明，基于最优传输的方法产生的图像插值效果优于标准方法。


<details>
  <summary>Details</summary>
Motivation: Stable Diffusion的CLIP嵌入的排列不变性这一新颖的观察结果，促使我们探索一种新的视角来理解嵌入空间的几何结构，并利用这种结构来改进图像生成过程。

Method: 将CLIP嵌入视为Wasserstein空间中的点云，并将提示之间的插值问题重新构建为最优传输问题，计算嵌入之间的最短路径（测地线）。

Result: 与标准插值方法相比，所提出的基于最优传输的方法产生了更平滑、更连贯的中间图像。

Conclusion: 将CLIP嵌入视为点云而非矩阵，更能体现和利用嵌入空间的几何结构，并且基于最优传输的插值方法能够生成更高质量的图像。

Abstract: It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.

</details>


### [166] [RoCoISLR: A Romanian Corpus for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.12767)
*Cătălin-Alexandru Rîpanu,Andrei-Theodor Hotnog,Giulia-Stefania Imbrea,Dumitru-Clementin Cercel*

Main category: cs.CV

TL;DR: 该研究介绍了 RoCoISLR 数据集，这是一个包含 9000 多个视频的罗马尼亚手语识别语料库，并对七种先进的视频识别模型进行了基准测试，其中基于 Transformer 的模型表现更好，Swin Transformer 达到了 34.1% 的准确率。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏大规模、标准化的罗马尼亚手语识别 (RoISLR) 数据集，这阻碍了该领域的研究进展。

Method: 创建了一个名为 RoCoISLR 的新语料库，包含 9000 多个视频，涵盖近 6000 个标准化手语词汇。评估了 I3D、SlowFast、Swin Transformer、TimeSformer、Uniformer、VideoMAE 和 PoseConv3D 七种先进的视频识别模型，并在一致的实验设置下进行了比较。

Result: 基于 Transformer 的架构优于卷积基线，其中 Swin Transformer 取得了 34.1% 的 Top-1 准确率。研究还强调了低资源手语中长尾类分布带来的挑战。

Conclusion: RoCoISLR 数据集为 RoISLR 的系统性研究奠定了基础，并突显了低资源手语识别的挑战。

Abstract: Automatic sign language recognition plays a crucial role in bridging the communication gap between deaf communities and hearing individuals; however, most available datasets focus on American Sign Language. For Romanian Isolated Sign Language Recognition (RoISLR), no large-scale, standardized dataset exists, which limits research progress. In this work, we introduce a new corpus for RoISLR, named RoCoISLR, comprising over 9,000 video samples that span nearly 6,000 standardized glosses from multiple sources. We establish benchmark results by evaluating seven state-of-the-art video recognition models-I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D-under consistent experimental setups, and compare their performance with that of the widely used WLASL2000 corpus. According to the results, transformer-based architectures outperform convolutional baselines; Swin Transformer achieved a Top-1 accuracy of 34.1%. Our benchmarks highlight the challenges associated with long-tail class distributions in low-resource sign languages, and RoCoISLR provides the initial foundation for systematic RoISLR research.

</details>


### [167] [Enhancing Neuro-Oncology Through Self-Assessing Deep Learning Models for Brain Tumor Unified Model for MRI Segmentation](https://arxiv.org/abs/2511.12801)
*Andrew Zhou*

Main category: cs.CV

TL;DR: 该研究提出了一个不确定性感知框架，用于准确分割脑肿瘤及其周围健康脑结构，并提供不确定性估计，以提高临床决策的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前脑肿瘤分割方法在临床应用中存在不确定性估计不足和无法同时分割健康脑结构的问题，限制了其在诊断、手术规划和治疗监测中的作用。

Method: 研究提出了一种不确定性感知框架，该框架在nnUNet的基础上增加了一个体素级不确定性通道，并结合了正常和癌症数据集，实现了肿瘤定位与解剖结构信息的统一。

Result: 该框架在BraTS2023数据集上实现了0.750的相关性和0.047的均方根偏差，同时不影响肿瘤分割的准确性。对于全脑分割，模型在脑结构和肿瘤上的DSC分别达到0.81和0.86。不确定性图谱能够提供关键的洞察，评估预测结果并修复错误。

Conclusion: 该研究成功开发了首个能够输出肿瘤及其周围自然环境的分割图谱，并叠加了不确定性图谱的模型。不确定性估计有助于评估预测的可靠性，为外科手术决策提供信息支持。

Abstract: Accurate segmentation of brain tumors is vital for diagnosis, surgical planning, and treatment monitoring. Deep learning has advanced on benchmarks, but two issues limit clinical use: no uncertainty estimates for errors and no segmentation of healthy brain structures around tumors for surgery. Current methods fail to unify tumor localization with anatomical context and lack confidence scores. This study presents an uncertainty-aware framework augmenting nnUNet with a channel for voxel-wise uncertainty. Trained on BraTS2023, it yields a correlation of 0.750 and RMSD of 0.047 for uncertainty without hurting tumor accuracy. It predicts uncertainty in one pass, with no extra networks or inferences, aiding clinical decisions. For whole-brain context, a unified model combines normal and cancer datasets, achieving a DSC of 0.81 for brain structures and 0.86 for tumor, with robust key-region performance. Combining both innovations gives the first model outputting tumor in natural surroundings plus an overlaid uncertainty map. Visual checks of outputs show uncertainty offers key insights to evaluate predictions and fix errors, helping informed surgical decisions from AI.

</details>


### [168] [MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12810)
*Leena Alghamdi,Muhammad Usman,Hafeez Anwar,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: 本研究提出了一种新的多尺度递归网络（MSRNet）来解决伪装目标检测中的挑战，特别是在复杂场景下的小型和多个目标检测问题。


<details>
  <summary>Details</summary>
Motivation: 现有的伪装目标检测方法在处理低光照、遮挡、小目标、复杂背景以及多目标等挑战时仍存在不足，尤其是在检测小型和多个伪装目标方面。因此，需要改进现有方法以提高检测精度。

Method: 提出了一种多尺度递归网络（MSRNet）。该网络使用金字塔视觉变换器（PVT）作为骨干网络提取多尺度特征，并通过注意力机制的尺度集成单元（ASIU）将这些特征选择性地融合。此外，使用多粒度融合单元（MGFU）和新颖的递归反馈解码策略来递归地细化特征，增强全局上下文理解，以实现更精确的目标检测。

Result: 所提出的MSRNet在两个伪装目标检测基准数据集上取得了最先进的成果，并在另外两个数据集上排名第二。该模型成功地检测了小型和多个伪装目标，证明了其有效性。

Conclusion: 通过结合多尺度学习和递归特征优化，所提出的MSRNet能够有效克服伪装目标检测中的挑战，尤其是在处理小型和多个目标方面，并在多个基准数据集上取得了优异的性能。

Abstract: Camouflaged object detection is an emerging and challenging computer vision task that requires identifying and segmenting objects that blend seamlessly into their environments due to high similarity in color, texture, and size. This task is further complicated by low-light conditions, partial occlusion, small object size, intricate background patterns, and multiple objects. While many sophisticated methods have been proposed for this task, current methods still struggle to precisely detect camouflaged objects in complex scenarios, especially with small and multiple objects, indicating room for improvement. We propose a Multi-Scale Recursive Network that extracts multi-scale features via a Pyramid Vision Transformer backbone and combines them via specialized Attention-Based Scale Integration Units, enabling selective feature merging. For more precise object detection, our decoder recursively refines features by incorporating Multi-Granularity Fusion Units. A novel recursive-feedback decoding strategy is developed to enhance global context understanding, helping the model overcome the challenges in this task. By jointly leveraging multi-scale learning and recursive feature optimization, our proposed method achieves performance gains, successfully detecting small and multiple camouflaged objects. Our model achieves state-of-the-art results on two benchmark datasets for camouflaged object detection and ranks second on the remaining two. Our codes, model weights, and results are available at \href{https://github.com/linaagh98/MSRNet}{https://github.com/linaagh98/MSRNet}.

</details>


### [169] [SAGA: Source Attribution of Generative AI Videos](https://arxiv.org/abs/2511.12834)
*Rohit Kundu,Vishal Mohanty,Hao Xiong,Shan Jia,Athula Balachandran,Amit K. Roy-Chowdhury*

Main category: cs.CV

TL;DR: SAGA框架能够识别生成式AI视频的具体来源，并提供多层级的溯源信息，解决了现有技术无法区分视频来源的问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI视频的滥用风险日益增加，现有的二元真/假检测方法已不足以应对超写实合成视频的挑战，因此需要对生成式AI视频进行来源溯源。

Method: 提出了一种名为SAGA的全新框架，该框架使用新颖的视频Transformer架构，结合强大的视觉基础模型提取时空伪影特征。并采用数据高效的预训练-溯源策略，以及时间注意力签名（T-Sigs）方法进行模型可解释性分析。

Result: SAGA在公开数据集上实现了最先进的视频生成模型溯源能力，即使在仅使用0.5%的标注数据的情况下，也能达到完全监督的性能。T-Sigs方法能够可视化不同视频生成器之间的时域差异，为区分它们提供了可解释的依据。

Conclusion: SAGA是首个大规模生成式AI视频来源溯源框架，其多层级的溯源能力和可解释性为取证和监管应用提供了关键的见解，设定了合成视频溯源的新基准。

Abstract: The proliferation of generative AI has led to hyper-realistic synthetic videos, escalating misuse risks and outstripping binary real/fake detectors. We introduce SAGA (Source Attribution of Generative AI videos), the first comprehensive framework to address the urgent need for AI-generated video source attribution at a large scale. Unlike traditional detection, SAGA identifies the specific generative model used. It uniquely provides multi-granular attribution across five levels: authenticity, generation task (e.g., T2V/I2V), model version, development team, and the precise generator, offering far richer forensic insights. Our novel video transformer architecture, leveraging features from a robust vision foundation model, effectively captures spatio-temporal artifacts. Critically, we introduce a data-efficient pretrain-and-attribute strategy, enabling SAGA to achieve state-of-the-art attribution using only 0.5\% of source-labeled data per class, matching fully supervised performance. Furthermore, we propose Temporal Attention Signatures (T-Sigs), a novel interpretability method that visualizes learned temporal differences, offering the first explanation for why different video generators are distinguishable. Extensive experiments on public datasets, including cross-domain scenarios, demonstrate that SAGA sets a new benchmark for synthetic video provenance, providing crucial, interpretable insights for forensic and regulatory applications.

</details>


### [170] [Video Finetuning Improves Reasoning Between Frames](https://arxiv.org/abs/2511.12868)
*Ruiqi Yang,Tian Yun,Zihan Wang,Ellie Pavlick*

Main category: cs.CV

TL;DR: 视频微调的多模态大语言模型（LLMs）能够隐式地捕捉帧间过渡，vCoT能够提升纯图像模型的长视频问答能力，并且视频模型能够将时间推理能力迁移到静态场景。


<details>
  <summary>Details</summary>
Motivation: 探究视频微调对多模态大语言模型的影响，并提出一种显式的视频推理方法vCoT。

Method: 提出视觉链式思考（vCoT），生成连续帧之间的事件描述，并在此基础上比较了纯图像模型和视频微调模型的性能。

Result: vCoT显著提升了纯图像模型在长视频问答任务上的表现，而对视频微调模型的提升效果不明显。视频模型将时间推理能力迁移到静态场景，在关系视觉推理任务上超越了纯图像模型。

Conclusion: 视频微调已经使多模态大语言模型隐式地学习到了帧间过渡，vCoT对于提升纯图像模型的视频理解能力尤为重要，并且视频模型具备迁移学习的能力。

Abstract: Multimodal large language models (LLMs) have made rapid progress in visual understanding, yet their extension from images to videos often reduces to a naive concatenation of frame tokens. In this work, we investigate what video finetuning brings to multimodal LLMs. We propose Visual Chain-of-Thought (vCoT), an explicit reasoning process that generates transitional event descriptions between consecutive frames. Using vCoT, we systematically compare image-only LVLMs with their video-finetuned counterparts, both with and without access to these transitional cues. Our experiments show that vCoT significantly improves the performance of image-only models on long-form video question answering, while yielding only marginal gains for video-finetuned models. This suggests that the latter already capture frame-to-frame transitions implicitly. Moreover, we find that video models transfer this temporal reasoning ability to purely static settings, outperforming image models' baselines on relational visual reasoning tasks.

</details>


### [171] [View-aware Cross-modal Distillation for Multi-view Action Recognition](https://arxiv.org/abs/2511.12870)
*Trung Thanh Nguyen,Yasutomo Kawanishi,Vijay John,Takahiro Komamizu,Ichiro Ide*

Main category: cs.CV

TL;DR: 现有的多视角动作识别方法主要关注传感器完全重叠的情况，而部分重叠（动作只在部分视角可见）的场景研究不足。


<details>
  <summary>Details</summary>
Motivation: 解决在传感器部分重叠、模态和标注有限的真实世界场景中，多视角动作识别的挑战。

Method: 提出了一种名为ViCoKD的框架，通过跨模态知识蒸馏，利用一个多模态教师模型来指导一个模态和标注受限的学生模型。该框架包含一个跨模态适配器（利用跨模态注意力）和一个视角感知一致性模块（解决视角不匹配问题），该模块利用了人体检测掩码和置信度加权的Jensen-Shannon散度来强制对齐预测。

Result: 在真实世界的MultiSensor-Home数据集上，ViCoKD在多种骨干网络和环境下，持续优于竞争性蒸馏方法，并在有限条件下超越了教师模型。

Conclusion: ViCoKD框架能够有效地从教师模型中蒸馏知识，即使在模态和标注受限且传感器部分重叠的情况下，也能在多视角动作识别任务上取得优异表现。

Abstract: The widespread use of multi-sensor systems has increased research in multi-view action recognition. While existing approaches in multi-view setups with fully overlapping sensors benefit from consistent view coverage, partially overlapping settings where actions are visible in only a subset of views remain underexplored. This challenge becomes more severe in real-world scenarios, as many systems provide only limited input modalities and rely on sequence-level annotations instead of dense frame-level labels. In this study, we propose View-aware Cross-modal Knowledge Distillation (ViCoKD), a framework that distills knowledge from a fully supervised multi-modal teacher to a modality- and annotation-limited student. ViCoKD employs a cross-modal adapter with cross-modal attention, allowing the student to exploit multi-modal correlations while operating with incomplete modalities. Moreover, we propose a View-aware Consistency module to address view misalignment, where the same action may appear differently or only partially across viewpoints. It enforces prediction alignment when the action is co-visible across views, guided by human-detection masks and confidence-weighted Jensen-Shannon divergence between their predicted class distributions. Experiments on the real-world MultiSensor-Home dataset show that ViCoKD consistently outperforms competitive distillation methods across multiple backbones and environments, delivering significant gains and surpassing the teacher model under limited conditions.

</details>


### [172] [Simple Lines, Big Ideas: Towards Interpretable Assessment of Human Creativity from Drawings](https://arxiv.org/abs/2511.12880)
*Zihao Lin,Zhenshan Shi,Sasa Zhao,Hanwei Zhu,Lingyu Zhu,Baoliang Chen,Lei Mo*

Main category: cs.CV

TL;DR: 提出了一种自动评估创意绘画的框架，结合了内容和风格分析。


<details>
  <summary>Details</summary>
Motivation: 现有的创意评估方法依赖于主观专家评分，效率低下且存在主观性。

Method: 提出一个多模态、多任务学习框架，结合内容类别和风格特征来预测创造力分数，并引入条件学习机制以适应性地提取与创造力相关的视觉信号。

Result: 实验结果表明，该模型在创造力评估方面优于现有的基于回归的方法，并能提供与人类判断一致的可视化解释。

Conclusion: 该数据驱动的框架能够自动、可解释地从绘画中评估创造力，并将在代码库中公开可用。

Abstract: Assessing human creativity through visual outputs, such as drawings, plays a critical role in fields including psychology, education, and cognitive science. However, current assessment practices still rely heavily on expert-based subjective scoring, which is both labor-intensive and inherently subjective. In this paper, we propose a data-driven framework for automatic and interpretable creativity assessment from drawings. Motivated by the cognitive understanding that creativity can emerge from both what is drawn (content) and how it is drawn (style), we reinterpret the creativity score as a function of these two complementary dimensions.Specifically, we first augment an existing creativity labeled dataset with additional annotations targeting content categories. Based on the enriched dataset, we further propose a multi-modal, multi-task learning framework that simultaneously predicts creativity scores, categorizes content types, and extracts stylistic features. In particular, we introduce a conditional learning mechanism that enables the model to adapt its visual feature extraction by dynamically tuning it to creativity-relevant signals conditioned on the drawing's stylistic and semantic cues.Experimental results demonstrate that our model achieves state-of-the-art performance compared to existing regression-based approaches and offers interpretable visualizations that align well with human judgments. The code and annotations will be made publicly available at https://github.com/WonderOfU9/CSCA_PRCV_2025

</details>


### [173] [ActVAR: Activating Mixtures of Weights and Tokens for Efficient Visual Autoregressive Generation](https://arxiv.org/abs/2511.12893)
*Kaixin Zhang,Ruiqing Yang,Yuan Zhang,Shan You,Tao Huang*

Main category: cs.CV

TL;DR: ActVAR是一种动态激活框架，通过在模型权重和令牌序列中引入双重稀疏性来提高视觉自回归模型的效率，同时保持其容量。它通过将前馈网络分解为轻量级专家子网络并使用可学习路由器来动态选择令牌特定的专家子集来实现这一点。此外，一个门控令牌选择器会识别高更新潜力的令牌进行计算，同时重建未选中的令牌以保持全局上下文和序列对齐。该模型在ImageNet 256x256基准测试中实现了高达21.2%的FLOPs缩减，且性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉自回归（VAR）模型虽然可以通过预测下一个尺度来实现高效的图像生成，但随着序列长度的增加，计算成本会急剧上升。然而，现有的静态剪枝方法通过永久移除权重或令牌来损害预训练的依赖关系，从而降低了性能。

Method: ActVAR通过分解前馈网络（FFNs）为轻量级专家子网络，并使用可学习的路由器根据内容动态选择令牌特定的专家子集。同时，门控令牌选择器识别高更新潜力的令牌进行计算，并重建未选中的令牌以保持全局上下文和序列对齐。训练采用两阶段知识蒸馏策略，由原始VAR模型监督路由和门控策略的学习，以保持预训练知识。

Result: 在ImageNet 256x256基准测试上，ActVAR实现了高达21.2%的FLOPs缩减，同时性能下降极小。

Conclusion: ActVAR通过引入动态双重稀疏性，在不牺牲模型容量的情况下显著提高了视觉自回归模型的效率，为解决VAR模型计算成本不断增长的问题提供了一个有前景的解决方案。

Abstract: Visual Autoregressive (VAR) models enable efficient image generation via next-scale prediction but face escalating computational costs as sequence length grows. Existing static pruning methods degrade performance by permanently removing weights or tokens, disrupting pretrained dependencies. To address this, we propose ActVAR, a dynamic activation framework that introduces dual sparsity across model weights and token sequences to enhance efficiency without sacrificing capacity. ActVAR decomposes feedforward networks (FFNs) into lightweight expert sub-networks and employs a learnable router to dynamically select token-specific expert subsets based on content. Simultaneously, a gated token selector identifies high-update-potential tokens for computation while reconstructing unselected tokens to preserve global context and sequence alignment. Training employs a two-stage knowledge distillation strategy, where the original VAR model supervises the learning of routing and gating policies to align with pretrained knowledge. Experiments on the ImageNet $256\times 256$ benchmark demonstrate that ActVAR achieves up to $21.2\%$ FLOPs reduction with minimal performance degradation.

</details>


### [174] [Reconstructing 3D Scenes in Native High Dynamic Range](https://arxiv.org/abs/2511.12895)
*Kaixuan Zhang,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为NH-3DGS的新方法，可以直接从单一曝光的HDR（高动态范围）数据中进行3D场景重建，解决了现有方法在处理HDR数据时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景重建方法主要基于LDR（低动态范围）数据，这限制了它们在电影制作、虚拟制片和照片级渲染等专业领域的应用。现有的HDR重建方法依赖于多曝光融合或逆色调映射，增加了拍摄复杂性并且需要合成监督。随着能够直接捕获原生HDR数据的相机的出现，需要一种可以直接处理这些数据的方法。

Method: NH-3DGS方法直接对原生HDR观测数据进行建模，其关键技术贡献在于提出了一种新颖的亮度-色度分解颜色表示方法，可以直接从原生HDR相机数据中进行优化。

Result: 在合成和真实的多视图HDR数据集上，NH-3DGS的重建质量和动态范围保留效果显著优于现有方法。

Conclusion: NH-3DGS实现了从原生HDR捕获中直接进行专业级3D重建，能够更好地保留图像的动态范围，为专业媒体创作提供了新的解决方案。

Abstract: High Dynamic Range (HDR) imaging is essential for professional digital media creation, e.g., filmmaking, virtual production, and photorealistic rendering. However, 3D scene reconstruction has primarily focused on Low Dynamic Range (LDR) data, limiting its applicability to professional workflows. Existing approaches that reconstruct HDR scenes from LDR observations rely on multi-exposure fusion or inverse tone-mapping, which increase capture complexity and depend on synthetic supervision. With the recent emergence of cameras that directly capture native HDR data in a single exposure, we present the first method for 3D scene reconstruction that directly models native HDR observations. We propose {\bf Native High dynamic range 3D Gaussian Splatting (NH-3DGS)}, which preserves the full dynamic range throughout the reconstruction pipeline. Our key technical contribution is a novel luminance-chromaticity decomposition of the color representation that enables direct optimization from native HDR camera data. We demonstrate on both synthetic and real multi-view HDR datasets that NH-3DGS significantly outperforms existing methods in reconstruction quality and dynamic range preservation, enabling professional-grade 3D reconstruction directly from native HDR captures. Code and datasets will be made available.

</details>


### [175] [FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI](https://arxiv.org/abs/2511.12899)
*Hao Li,Zhenfeng Zhuang,Jingyu Lin,Yu Liu,Yifei Chen,Qiong Peng,Lequan Yu,Liansheng Wang*

Main category: cs.CV

TL;DR: 由于脑部MRI标注数据稀缺且解剖结构多样，本研究提出了一种新颖的无监督异常检测（UAD）方法，该方法利用频率域分析来区分正常脑部结构和病变。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督异常检测方法通过模拟噪声来训练模型，但模拟的异常缺乏真实临床病变的生物物理保真度和形态复杂性。因此，有必要开发更有效的方法来提高脑部MRI异常检测的准确性。

Method: 本研究首先进行了系统的频率域分析，发现了异常信号的独特频率模式和正常解剖结构在低频信号的稳定性。基于这些发现，研究者提出了频率分解预处理（FDP）框架，这是一种利用频率域重建来同时抑制病变和保留解剖结构的新型UAD方法。

Result: FDP框架能够无缝集成现有的异常模拟技术，在多种模型架构上持续提升检测性能，并保持诊断保真度。实验结果表明，FDP与LDM结合使用时，DICE评分提高了17.63%，并在多个基线模型上实现了稳健的性能提升。

Conclusion: FDP框架通过在频率域进行分析和重建，有效解决了现有无监督异常检测方法在脑部MRI应用中的局限性，显著提高了异常检测的准确性和可靠性。

Abstract: Due to the diversity of brain anatomy and the scarcity of annotated data, supervised anomaly detection for brain MRI remains challenging, driving the development of unsupervised anomaly detection (UAD) approaches. Current UAD methods typically utilize artificially generated noise perturbations on healthy MRIs to train generative models for normal anatomy reconstruction, enabling anomaly detection via residual mapping. However, such simulated anomalies lack the biophysical fidelity and morphological complexity characteristic of true clinical lesions. To advance UAD in brain MRI, we conduct the first systematic frequency-domain analysis of pathological signatures, revealing two key properties: (1) anomalies exhibit unique frequency patterns distinguishable from normal anatomy, and (2) low-frequency signals maintain consistent representations across healthy scans. These insights motivate our Frequency-Decomposition Preprocessing (FDP) framework, the first UAD method to leverage frequency-domain reconstruction for simultaneous pathology suppression and anatomical preservation. FDP can integrate seamlessly with existing anomaly simulation techniques, consistently enhancing detection performance across diverse architectures while maintaining diagnostic fidelity. Experimental results demonstrate that FDP consistently improves anomaly detection performance when integrated with existing methods. Notably, FDP achieves a 17.63% increase in DICE score with LDM while maintaining robust improvements across multiple baselines. The code is available at https://github.com/ls1rius/MRI_FDP.

</details>


### [176] [DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2511.12908)
*Junbo Zou,Haotian Xia,Zhen Ye,Shengjie Zhang,Christopher Lai,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: DeepSport是首个端到端训练的多模态大语言模型框架，专门用于多任务、多运动视频理解，通过迭代推理和工具使用来解决运动视频理解的挑战，并在基准测试中取得最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有体育视频理解方法存在局限性，如仅关注单一运动、任务受限或缺乏有效的学习推理过程。DeepSport旨在解决这些问题，为多任务、多运动视频理解提供一个端到端的解决方案。

Method: DeepSport框架通过数据蒸馏管道合成高质量的思维链（CoT）轨迹，创建了包含78,000个训练数据的数据集。采用监督微调（SFT）和强化学习（RL）的两阶段训练策略，并引入新颖的门控工具使用奖励来优化模型推理过程。该模型能够通过专门的帧提取工具动态查询内容，实现迭代推理。

Result: 在包含6,700个问题的测试基准上，DeepSport实现了最先进的性能，显著优于专有模型和开源模型的基线。

Conclusion: DeepSport为领域特定的视频推理奠定了新基础，能够有效应对多样化体育运动的复杂性。

Abstract: Sports video understanding presents unique challenges, requiring models to perceive high-speed dynamics, comprehend complex rules, and reason over long temporal contexts. While Multimodal Large Language Models (MLLMs) have shown promise in genral domains, the current state of research in sports remains narrowly focused: existing approaches are either single-sport centric, limited to specific tasks, or rely on training-free paradigms that lack robust, learned reasoning process. To address this gap, we introduce DeepSport, the first end-to-end trained MLLM framework designed for multi-task, multi-sport video understanding. DeepSport shifts the paradigm from passive frame processing to active, iterative reasoning, empowering the model to ``think with videos'' by dynamically interrogating content via a specialized frame-extraction tool. To enable this, we propose a data distillation pipeline that synthesizes high-quality Chain-of-Thought (CoT) trajectories from 10 diverse data source, creating a unified resource of 78k training data. We then employ a two-stage training strategy, Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) with a novel gated tool-use reward, to optimize the model's reasoning process. Extensive experiments on the testing benchmark of 6.7k questions demonstrate that DeepSport achieves state-of-the-art performance, significantly outperforming baselines of both proprietary model and open-source models. Our work establishes a new foundation for domain-specific video reasoning to address the complexities of diverse sports.

</details>


### [177] [CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection](https://arxiv.org/abs/2511.12909)
*Yaohua Zha,Xue Yuerong,Chunlin Fan,Yuansong Wang,Tao Dai,Ke Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: CASL框架通过多尺度曲率提示引导U-Net进行点云重建，实现了先进的3D异常检测和良好的泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有3D异常检测方法通用性不足，而经典的自监督模型在异常检测任务上表现不佳，因此需要开发更通用的3D模型。

Method: 提出CASL框架，基于U-Net架构，引入多尺度曲率提示引导解码器预测点云空间坐标，并使用简单的异常分类微调。

Result: CASL框架的异常检测性能优于现有模型，并且学习到的表征在点云分类等任务上表现良好。仅使用曲率作为异常分数的方法也优于许多经典模型。

Conclusion: CASL框架在无需特定异常检测机制的情况下，通过简单的微调即可实现领先的3D异常检测性能，并具有良好的任务泛化能力。曲率在3D异常检测中起着关键作用。

Abstract: Deep learning-based 3D anomaly detection methods have demonstrated significant potential in industrial manufacturing. However, many approaches are specifically designed for anomaly detection tasks, which limits their generalizability to other 3D understanding tasks. In contrast, self-supervised point cloud models aim for general-purpose representation learning, yet our investigation reveals that these classical models are suboptimal at anomaly detection under the unified fine-tuning paradigm. This motivates us to develop a more generalizable 3D model that can effectively detect anomalies without relying on task-specific designs. Interestingly, we find that using only the curvature of each point as its anomaly score already outperforms several classical self-supervised and dedicated anomaly detection models, highlighting the critical role of curvature in 3D anomaly detection. In this paper, we propose a Curvature-Augmented Self-supervised Learning (CASL) framework based on a reconstruction paradigm. Built upon the classical U-Net architecture, our approach introduces multi-scale curvature prompts to guide the decoder in predicting the spatial coordinates of each point. Without relying on any dedicated anomaly detection mechanisms, it achieves leading detection performance through straightforward anomaly classification fine-tuning. Moreover, the learned representations generalize well to standard 3D understanding tasks such as point cloud classification. The code is available at https://github.com/zyh16143998882/CASL.

</details>


### [178] [Explore How to Inject Beneficial Noise in MLLMs](https://arxiv.org/abs/2511.12917)
*Ruishu Zhu,Sida Huang,Ziheng Jiao,Hongyuan Zhang*

Main category: cs.CV

TL;DR: 通过注入有益的随机噪声，MuNG实现了对冻结的多模态大语言模型（MLLMs）的高效微调，从而提高了跨模态表示的一致性，并最终增强了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM微调方法往往忽略了跨模态的异质性，限制了其全部潜力。

Method: 提出了一种新颖的微调策略，通过注入有益的随机噪声，设计了一个多模态噪声生成器（MuNG），该生成器动态分析图像-文本对中的跨模态关系，以生成任务自适应的有益噪声。将此噪声注入MLLMs，以抑制不相关的语义成分。

Result: 在QwenVL和LLaVA两个主流MLLMs上进行实验，结果表明，MuNG仅调整约1-2%的附加参数，就能在性能上超越全参数微调和其他现有方法。

Conclusion: MuNG通过注入定制化噪声，为MLLMs提供了一种高效的微调范式，能够有效解决跨模态异质性问题，提高模型性能，并且具有参数高效性。

Abstract: Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\sim2\%$ additional parameters. The relevant code is uploaded in the supplementary.

</details>


### [179] [CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation](https://arxiv.org/abs/2511.12919)
*Dexin Zuo,Ang Li,Wei Wang,Wenxian Yu,Danping Zou*

Main category: cs.CV

TL;DR: CoordAR是一种新颖的自回归框架，用于对未知物体进行一次参考6D姿态估计，通过将3D-3D对应关系制定为离散令牌图，并采用概率性自回归方式获得，从而解决了现有方法对3D模型依赖和全局一致性不足的问题，并在多个基准测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 减少对3D模型在机器人和增强现实应用中6D姿态估计的依赖，特别是在处理新颖物体时。

Method: 提出了一种名为CoordAR的新颖自回归框架，将3D-3D对应关系表示为离散令牌图，并通过以下方式实现准确的对应回归：1) 新颖的坐标图令牌化，实现离散3D空间上的概率预测；2) 分离编码RGB外观和坐标线索的模态解耦编码策略；3) 受位置对齐查询特征和部分生成的令牌序列制约的自回归Transformer解码器。

Result: CoordAR在多个基准测试中显著优于现有方法，并证明了其在对称、遮挡等具有挑战性的真实世界测试中的鲁棒性。

Conclusion: CoordAR通过其新颖的自回归框架、坐标图令牌化、模态解耦编码和Transformer解码器，成功解决了现有方法在单参考6D姿态估计中的局限性，并在各种挑战性场景下取得了优越的性能。

Abstract: Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.

</details>


### [180] [Generative Photographic Control for Scene-Consistent Video Cinematic Editing](https://arxiv.org/abs/2511.12921)
*Huiqiang Sun,Liao Shen,Zhan Peng,Kun Wang,Size Wu,Yuhang Zang,Tianqi Liu,Zihao Huang,Xingyu Zeng,Zhiguo Cao,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: CineCtrl是首个提供专业相机参数（如散景、快门速度）精细控制的视频电影编辑框架，通过解耦的交叉注意力机制和创新的数据生成策略，实现了在不影响场景一致性的前提下，独立控制摄影效果，并生成高保真视频。


<details>
  <summary>Details</summary>
Motivation: 当前生成视频模型在控制摄影效果（如景深、曝光）方面存在挑战，多数方法仅限于相机运动控制。本研究旨在解决这一难题，实现对专业相机参数的精细控制。

Method: 提出CineCtrl框架，采用解耦的交叉注意力机制分离相机运动与摄影输入，实现独立控制；同时开发数据生成策略，利用模拟和真实世界数据构建大规模数据集。

Result: 实验证明，CineCtrl能够生成高保真视频，并精确控制用户指定的摄影相机效果。

Conclusion: CineCtrl在视频电影编辑领域实现了对专业相机参数（如散景、快门速度）的精细控制，有效解决了现有方法的局限性，并能生成高质量、可控的视频内容。

Abstract: Cinematic storytelling is profoundly shaped by the artful manipulation of photographic elements such as depth of field and exposure. These effects are crucial in conveying mood and creating aesthetic appeal. However, controlling these effects in generative video models remains highly challenging, as most existing methods are restricted to camera motion control. In this paper, we propose CineCtrl, the first video cinematic editing framework that provides fine control over professional camera parameters (e.g., bokeh, shutter speed). We introduce a decoupled cross-attention mechanism to disentangle camera motion from photographic inputs, allowing fine-grained, independent control without compromising scene consistency. To overcome the shortage of training data, we develop a comprehensive data generation strategy that leverages simulated photographic effects with a dedicated real-world collection pipeline, enabling the construction of a large-scale dataset for robust model training. Extensive experiments demonstrate that our model generates high-fidelity videos with precisely controlled, user-specified photographic camera effects.

</details>


### [181] [Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes](https://arxiv.org/abs/2511.12932)
*Feng Lv,Haoxuan Feng,Zilu Zhang,Chunlong Xia,Yanfeng Li*

Main category: cs.CV

TL;DR: 该研究提出了一种统一的文本驱动框架，用于生成和编辑交通场景图像，解决了现有技术在语义丰富度、视角多样性、视觉保真度和文本-图像一致性方面存在的不足。


<details>
  <summary>Details</summary>
Motivation: 智能交通系统快速发展，需要丰富的、可控的视觉场景数据。现有文本-驱动图像生成和编辑技术在生成交通元素的语义丰富度、视角、视觉保真度和文本-图像一致性方面存在挑战。

Method: 提出一个统一的文本驱动框架，结合可控掩码机制实现图像生成和编辑。利用车端和路侧多视角数据增强几何多样性。采用两阶段训练策略：首先使用大规模粗粒度文本-图像数据进行概念学习，然后使用细粒度描述性数据进行微调，以增强文本-图像一致性和细节质量。引入掩码区域加权损失，动态强调小的关键区域，提高小规模交通元素的生成保真度。

Result: 实验证明，所提出的方法在交通场景的文本驱动图像生成和编辑方面取得了领先的性能。

Conclusion: 所提出的统一框架通过引入可控掩码机制、多视角数据、两阶段训练策略和掩码区域加权损失，有效地解决了现有文本驱动图像生成和编辑技术的局限性，并在交通场景中实现了先进的性能。

Abstract: With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.

</details>


### [182] [ProtoAnomalyNCD: Prototype Learning for Multi-class Novel Anomaly Discovery in Industrial Scenarios](https://arxiv.org/abs/2511.12938)
*Botong Zhao,Qijun Shi,Shujing Lyu,Yue Lu*

Main category: cs.CV

TL;DR: ProtoAnomalyNCD是一个基于原型学习的框架，用于发现和分类多种未知的工业异常类型，通过利用Grounded SAM定位对象区域和引入引导注意力的模块来增强异常特征。


<details>
  <summary>Details</summary>
Motivation: 现有的工业异常检测方法主要关注是否检测到异常，但实际应用需要发现和分类多种类型的异常。由于工业异常语义微妙且现有方法未能充分利用图像先验，直接聚类方法效果不佳。

Method: 利用Grounded SAM和文本提示定位对象区域作为异常分类网络的先验。引入异常图引导注意力模块，其中区域引导因子帮助区分背景、对象区域和异常区域。在原型学习框架下，发现和聚类未知的异常类别，并实现多类型异常分类和未见异常离群点检测。

Result: 该方法在MVTec AD、MTD和Real-IAD数据集上超越了现有技术水平。

Conclusion: ProtoAnomalyNCD成功地发现了未知的异常类别，并实现了多类型异常的分类，同时还能检测未知的离群点，实现了任务级别的统一。

Abstract: Existing industrial anomaly detection methods mainly determine whether an anomaly is present. However, real-world applications also require discovering and classifying multiple anomaly types. Since industrial anomalies are semantically subtle and current methods do not sufficiently exploit image priors, direct clustering approaches often perform poorly. To address these challenges, we propose ProtoAnomalyNCD, a prototype-learning-based framework for discovering unseen anomaly classes of multiple types that can be integrated with various anomaly detection methods. First, to suppress background clutter, we leverage Grounded SAM with text prompts to localize object regions as priors for the anomaly classification network. Next, because anomalies usually appear as subtle and fine-grained patterns on the product, we introduce an Anomaly-Map-Guided Attention block. Within this block, we design a Region Guidance Factor that helps the attention module distinguish among background, object regions, and anomalous regions. By using both localized product regions and anomaly maps as priors, the module enhances anomalous features while suppressing background noise and preserving normal features for contrastive learning. Finally, under a unified prototype-learning framework, ProtoAnomalyNCD discovers and clusters unseen anomaly classes while simultaneously enabling multi-type anomaly classification. We further extend our method to detect unseen outliers, achieving task-level unification. Our method outperforms state-of-the-art approaches on the MVTec AD, MTD, and Real-IAD datasets.

</details>


### [183] [Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking](https://arxiv.org/abs/2511.12939)
*Wei Jiang,Jiahao Cui,Yizheng Wu,Zhan Peng,Zhiyu Pan,Zhiguo Cao*

Main category: cs.CV

TL;DR: 通过使用不确定性掩码来提高半监督HDR重建的性能，从而减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 难以获得成对的低动态范围（LDR）和高动态范围（HDR）图像，因此需要研究如何用有限的HDR真实值（GT）来实现可比的性能。

Method: 提出了一种半监督学习方法，其中教师模型为没有GT的LDR样本生成伪HDR GT，然后学生模型从这些伪GT中学习。为了解决确认偏差（学生可能从伪HDR GT的伪影中学习）问题，提出了一种基于不确定性的掩码过程，在像素和块级别上丢弃不可靠的伪GT部分，以便学生可以从可信区域中学习。

Result: 与以前的标注效率低下的HDR重建算法相比，该方法取得了更好的性能。通过仅使用6.7%的HDR GT，实现了与最新的全监督方法相当的性能。

Conclusion: 提出的半监督HDR重建方法，通过不确定性掩码解决了确认偏差问题，在标注效率和性能上都优于现有方法，并能与全监督方法相媲美。

Abstract: Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.

</details>


### [184] [Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention](https://arxiv.org/abs/2511.12940)
*Taiye Chen,Zihan Ding,Anjian Li,Christina Zhang,Zeqi Xiao,Yisen Wang,Chi Jin*

Main category: cs.CV

TL;DR: 提出了一种名为RAD的新型生成模型，它结合了循环神经网络（RNN）和扩散transformer，用于生成长视频。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在处理长视频时存在记忆压缩和检索效率低的问题，容易导致信息遗忘和时空不一致。现有模型通常使用局部全注意力机制，难以在固定内存预算内有效保留历史信息，这限制了它们在长视频生成方面的性能。

Method: 通过将LSTM（长短期记忆网络）引入扩散transformer框架，并设计了一个名为RAD（Recurrent Autoregressive Diffusion）的新框架，该框架在训练和推理时都实现了逐帧的自回归记忆更新和检索，以解决训练-推理差异和窗口重叠不足的问题。

Result: 在Memory Maze和Minecraft数据集上的实验表明，RAD在长视频生成方面表现优于现有技术，并证明了LSTM在序列建模中的有效性。

Conclusion: RAD框架通过结合RNN和扩散transformer，能够有效地生成长视频，解决了现有模型在长视频生成中的局限性，并展示了LSTM在序列建模方面的强大能力。

Abstract: Recent advancements in video generation have demonstrated the potential of using video diffusion models as world models, with autoregressive generation of infinitely long videos through masked conditioning. However, such models, usually with local full attention, lack effective memory compression and retrieval for long-term generation beyond the window size, leading to issues of forgetting and spatiotemporal inconsistencies. To enhance the retention of historical information within a fixed memory budget, we introduce a recurrent neural network (RNN) into the diffusion transformer framework. Specifically, a diffusion model incorporating LSTM with attention achieves comparable performance to state-of-the-art RNN blocks, such as TTT and Mamba2. Moreover, existing diffusion-RNN approaches often suffer from performance degradation due to training-inference gap or the lack of overlap across windows. To address these limitations, we propose a novel Recurrent Autoregressive Diffusion (RAD) framework, which executes frame-wise autoregression for memory update and retrieval, consistently across training and inference time. Experiments on Memory Maze and Minecraft datasets demonstrate the superiority of RAD for long video generation, highlighting the efficiency of LSTM in sequence modeling.

</details>


### [185] [T2I-Based Physical-World Appearance Attack against Traffic Sign Recognition Systems in Autonomous Driving](https://arxiv.org/abs/2511.12956)
*Chen Ma,Ningfei Wang,Junhao Zheng,Qing Guo,Qian Wang,Qi Alfred Chen,Chao Shen*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为DiffSign的新型文本到图像（T2I）生成对抗性攻击框架，用于识别交通标志（TSR）系统。该框架旨在生成物理鲁棒、高效、可转移、实用且隐蔽的对抗性外观攻击。DiffSign通过集成CLIP损失和掩码提示来提高攻击的专注度和可控性，并引入了两种新颖的风格定制方法来改善域外交通标志的攻击泛化能力和隐蔽性。实验证明，DiffSign在真实世界条件下实现了83.3%的平均物理世界攻击成功率，展示了其在攻击可转移性方面的高效性。


<details>
  <summary>Details</summary>
Motivation: 现有交通标志识别（TSR）系统易受物理世界对抗性外观攻击，但现有方法存在隐蔽性差、对特定模型过拟合、泛化能力不足等问题。本研究旨在开发一种更有效、更具鲁棒性和隐蔽性的外观攻击方法。

Method: 提出DiffSign框架，该框架集成CLIP损失和掩码提示，并引入两种风格定制方法，以生成针对TSR系统的对抗性外观攻击。

Result: DiffSign在真实世界条件下实现了83.3%的平均物理世界攻击成功率，证明了其在不同距离、角度、光照条件和交通标志类别下的有效性、可转移性和隐蔽性。

Conclusion: DiffSign是一种有效且实用的T2I对抗性外观攻击框架，能够成功攻击TSR系统，克服了现有方法的局限性。

Abstract: Traffic Sign Recognition (TSR) systems play a critical role in Autonomous Driving (AD) systems, enabling real-time detection of road signs, such as STOP and speed limit signs. While these systems are increasingly integrated into commercial vehicles, recent research has exposed their vulnerability to physical-world adversarial appearance attacks. In such attacks, carefully crafted visual patterns are misinterpreted by TSR models as legitimate traffic signs, while remaining inconspicuous or benign to human observers. However, existing adversarial appearance attacks suffer from notable limitations. Pixel-level perturbation-based methods often lack stealthiness and tend to overfit to specific surrogate models, resulting in poor transferability to real-world TSR systems. On the other hand, text-to-image (T2I) diffusion model-based approaches demonstrate limited effectiveness and poor generalization to out-of-distribution sign types.
  In this paper, we present DiffSign, a novel T2I-based appearance attack framework designed to generate physically robust, highly effective, transferable, practical, and stealthy appearance attacks against TSR systems. To overcome the limitations of prior approaches, we propose a carefully designed attack pipeline that integrates CLIP-based loss and masked prompts to improve attack focus and controllability. We also propose two novel style customization methods to guide visual appearance and improve out-of-domain traffic sign attack generalization and attack stealthiness. We conduct extensive evaluations of DiffSign under varied real-world conditions, including different distances, angles, light conditions, and sign categories. Our method achieves an average physical-world attack success rate of 83.3%, leveraging DiffSign's high effectiveness in attack transferability.

</details>


### [186] [EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics](https://arxiv.org/abs/2511.12962)
*Daniel Cavadia*

Main category: cs.CV

TL;DR: EndoSight AI是一个深度学习模型，可以实时、准确地检测和分割结肠息肉，mAP为88.3%，Dice系数为69%，推理速度超过35 FPS。


<details>
  <summary>Details</summary>
Motivation: 在内窥镜检查中精确、实时地检测胃肠息肉对于结直肠癌的早期诊断和预防至关重要。

Method: 利用公开的Hyper-Kvasir数据集，训练了一个深度学习模型（EndoSight AI），并采用了新颖的热感知程序来提高模型的鲁棒性和效率。

Result: 该模型在息肉检测方面达到了88.3%的平均精度（mAP），在分割方面达到了69%的Dice系数，在GPU上的推理速度超过了每秒35帧。

Conclusion: EndoSight AI是一个集成的人工智能解决方案，旨在无缝部署到内窥镜检查流程中，有望提高胃肠道医疗保健的诊断准确性和临床决策能力。

Abstract: Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer. This work presents EndoSight AI, a deep learning architecture developed and evaluated independently to enable accurate polyp localization and detailed boundary delineation. Leveraging the publicly available Hyper-Kvasir dataset, the system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, alongside real-time inference speeds exceeding 35 frames per second on GPU hardware. The training incorporates clinically relevant performance metrics and a novel thermal-aware procedure to ensure model robustness and efficiency. This integrated AI solution is designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.

</details>


### [187] [CalibrateMix: Guided-Mixup Calibration of Image Semi-Supervised Models](https://arxiv.org/abs/2511.12964)
*Mehrab Mustafy Rahman,Jayanth Mohan,Tiberiu Sosea,Cornelia Caragea*

Main category: cs.CV

TL;DR: CalibrateMix 是一种基于 mixup 的方法，通过混合“易学”和“难学”的样本来提高半监督学习（SSL）模型的校准性能和分类准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 SSL 方法在校准方面表现不佳，模型预测过于自信。虽然 mixup 在有监督学习中能改善校准，但由于伪标签的不可靠性，直接将其应用于 SSL 存在挑战。

Method: CalibrateMix 利用训练动态识别“易学”和“难学”的样本，并对它们进行有针对性的 mixup 混合。

Result: 在多个基准图像数据集上的实验表明，CalibrateMix 相比于现有的 SSL 方法，具有更低的期望校准误差（ECE）和更高的准确性。

Conclusion: CalibrateMix 能够有效提高 SSL 模型的校准性能，同时保持或提升分类准确性。

Abstract: Semi-supervised learning (SSL) has demonstrated high performance in image classification tasks by effectively utilizing both labeled and unlabeled data. However, existing SSL methods often suffer from poor calibration, with models yielding overconfident predictions that misrepresent actual prediction likelihoods. Recently, neural networks trained with {\tt mixup} that linearly interpolates random examples from the training set have shown better calibration in supervised settings. However, calibration of neural models remains under-explored in semi-supervised settings. Although effective in supervised model calibration, random mixup of pseudolabels in SSL presents challenges due to the overconfidence and unreliability of pseudolabels. In this work, we introduce CalibrateMix, a targeted mixup-based approach that aims to improve the calibration of SSL models while maintaining or even improving their classification accuracy. Our method leverages training dynamics of labeled and unlabeled samples to identify ``easy-to-learn'' and ``hard-to-learn'' samples, which in turn are utilized in a targeted mixup of easy and hard samples. Experimental results across several benchmark image datasets show that our method achieves lower expected calibration error (ECE) and superior accuracy compared to existing SSL approaches.

</details>


### [188] [GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.12968)
*Ning Han,Zhenyu Ge,Feng Han,Yuhua Sun,Chengqing Li,Jingjing Chen*

Main category: cs.CV

TL;DR: GrOCE是一个无需训练的框架，通过图结构来精确、自适应地擦除文本到图像扩散模型中的概念，解决了现有方法需要昂贵微调或语义分离粗糙的问题。


<details>
  <summary>Details</summary>
Motivation: 现有概念擦除方法存在需要昂贵微调或语义分离粗糙，导致擦除不精确、不适应新概念集的问题，因此需要更优的方法。

Method: 提出GrOCE框架，构建概念及其关系的动态语义图，通过（1）动态拓扑图构建、（2）自适应聚类识别、（3）选择性边切断来实现精确、自适应的概念擦除，且无需重新训练。

Result: 在概念相似性（CS）和Fréchet Inception Distance（FID）指标上达到了最先进的性能。

Conclusion: GrOCE在不重新训练的情况下，实现了高效、精确、稳定的概念擦除，有效解决了现有方法的局限性。

Abstract: Concept erasure aims to remove harmful, inappropriate, or copyrighted content from text-to-image diffusion models while preserving non-target semantics. However, existing methods either rely on costly fine-tuning or apply coarse semantic separation, often degrading unrelated concepts and lacking adaptability to evolving concept sets. To alleviate this issue, we propose Graph-Guided Online Concept Erasure (GrOCE), a training-free framework that performs precise and adaptive concept removal through graph-based semantic reasoning. GrOCE models concepts and their interrelations as a dynamic semantic graph, enabling principled reasoning over dependencies and fine-grained isolation of undesired content. It comprises three components: (1) Dynamic Topological Graph Construction for incremental graph building, (2) Adaptive Cluster Identification for multi-hop traversal with similarity-decay scoring, and (3) Selective Edge Severing for targeted edge removal while preserving global semantics. Extensive experiments demonstrate that GrOCE achieves state-of-the-art performance on Concept Similarity (CS) and Fréchet Inception Distance (FID) metrics, offering efficient, accurate, and stable concept erasure without retraining.

</details>


### [189] [HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology](https://arxiv.org/abs/2511.12969)
*Ziqiao Weng,Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee AD Cooper,Weidong Cai,Bo Zhou*

Main category: cs.CV

TL;DR: HiFusion是一个深度学习框架，通过整合层级内斑点建模和上下文感知跨尺度融合，从H&E染色切片图像预测空间转录组学数据，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的计算方法在从H&E染色切片图像预测基因表达时，难以捕捉斑点内的生物异质性，并且容易受到形态学噪声的影响。HiFusion旨在克服这些限制。

Method: HiFusion包含两个主要模块：1. 层级内斑点建模模块：通过多分辨率子斑块分解提取细粒度形态学特征，并使用特征对齐损失确保跨尺度的语义一致性。2. 上下文感知跨尺度融合模块：利用交叉注意力选择性地整合具有生物学意义的区域上下文信息，增强表示能力。

Result: 在两个基准空间转录组学数据集上进行了广泛的实验，HiFusion在2D和3D场景下均取得了最先进的性能。

Conclusion: HiFusion是一个强大、准确且可扩展的解决方案，可以从常规组织病理学图像进行空间转录组学推断，为克服空间转录组学在临床应用中的技术复杂性和成本障碍提供了潜力。

Abstract: Spatial transcriptomics (ST) bridges gene expression and tissue morphology but faces clinical adoption barriers due to technical complexity and prohibitive costs. While computational methods predict gene expression from H&E-stained whole-slide images (WSIs), existing approaches often fail to capture the intricate biological heterogeneity within spots and are susceptible to morphological noise when integrating contextual information from surrounding tissue. To overcome these limitations, we propose HiFusion, a novel deep learning framework that integrates two complementary components. First, we introduce the Hierarchical Intra-Spot Modeling module that extracts fine-grained morphological representations through multi-resolution sub-patch decomposition, guided by a feature alignment loss to ensure semantic consistency across scales. Concurrently, we present the Context-aware Cross-scale Fusion module, which employs cross-attention to selectively incorporate biologically relevant regional context, thereby enhancing representational capacity. This architecture enables comprehensive modeling of both cellular-level features and tissue microenvironmental cues, which are essential for accurate gene expression prediction. Extensive experiments on two benchmark ST datasets demonstrate that HiFusion achieves state-of-the-art performance across both 2D slide-wise cross-validation and more challenging 3D sample-specific scenarios. These results underscore HiFusion's potential as a robust, accurate, and scalable solution for ST inference from routine histopathology.

</details>


### [190] [MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning](https://arxiv.org/abs/2511.12976)
*Yoonjae Seo,Ermal Elbasani,Jaehong Lee*

Main category: cs.CV

TL;DR: MCAQ-YOLO是一种形态复杂度感知量化框架，通过自适应分配比特精度来优化目标检测的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法在不同空间区域采用统一比特精度，忽略了视觉数据复杂度的异质性，导致量化效率低下。

Method: MCAQ-YOLO利用分形维度、纹理熵、梯度方差、边缘密度和轮廓复杂度五种形态学指标来表征局部视觉形态，并根据量化敏感性动态调整比特精度。同时，采用基于课程的学习策略进行量化感知训练，以稳定优化和加速收敛。

Result: 实验证明，形态复杂度与量化敏感性之间存在强相关性。MCAQ-YOLO在安全设备数据集上达到了85.6% mAP@0.5，平均比特数为4.2 bits，压缩比为7.6x，在仅增加1.8 ms运行时开销的情况下，mAP比均匀4比特量化高3.5个百分点。在COCO和Pascal VOC数据集上的验证也证实了其性能提升。

Conclusion: 形态学驱动的空间量化能够提高计算受限、安全关键型视觉识别任务的效率和鲁棒性。

Abstract: Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.

</details>


### [191] [ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes](https://arxiv.org/abs/2511.12977)
*Yixuan Yang,Luyang Xie,Zhen Luo,Zixiang Zhao,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: ArtiWorld是一个场景感知管道，可以从文本描述中识别可关节动的物体，并将其转换为URDF模型，以创建交互式机器人模拟环境。


<details>
  <summary>Details</summary>
Motivation: 手动将现有的3D资产转换为可动的模拟对象成本高昂且耗时，因此需要一种自动化的方法来解决这个问题。

Method: ArtiWorld利用3D点云、大型语言模型（LLM）的先验知识以及面向URDF的提示设计，将刚性物体转换为可动的URDF模型，同时保持其3D形状。

Result: 在3D模拟对象、3D模拟场景和真实世界扫描场景的评估中，ArtiWorld的表现优于现有方法，能够保留物体几何形状并捕捉其交互性。

Conclusion: ArtiWorld为直接从现有的3D资产构建交互式、机器人就绪的模拟环境提供了一条实用的途径。

Abstract: Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

</details>


### [192] [Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach](https://arxiv.org/abs/2511.12978)
*Aishwarya Agarwal,Srikrishna Karanam,Vineet Gandhi*

Main category: cs.CV

TL;DR: 本文提出了一种名为 Cluster-based Concept Importance (CCI) 的新方法，用于解释对比视觉语言模型 (VLM) 的决策过程，特别是解决它们对背景的过度依赖问题。CCI 通过分析 CLIP 的内部表征来识别和量化不同空间区域（patch）的重要性。此外，研究人员还引入了一个名为 COVAR 的新基准，用于更全面地评估 VLM 的鲁棒性，并在此基础上对十八种不同的 CLIP 模型进行了详尽的分析。


<details>
  <summary>Details</summary>
Motivation: 现有的对比视觉语言模型 (VLM) 虽然在零样本识别方面表现出色，但容易受到虚假相关性的影响，尤其是过度依赖背景信息。因此，需要一种新的方法来理解和解决这个问题。

Method:  CCI 首先利用 CLIP 的 patch 嵌入将空间块聚类成语义相关的分组，然后通过遮蔽这些分组并评估模型预测的变化来衡量其相对重要性。CCI 与 GroundedSAM 结合，可以自动区分预测是由前景或背景驱动的。此外，研究人员还提出了 COVAR 基准，用于系统地改变物体的前景和背景，以区分不同类型的错误（如背景相关性、视角变化、尺度变化和细粒度混淆）。

Result: CCI 在模型可解释性基准测试中取得了新的最先进成果，在删除-AUC 指标上比现有方法有显著提升（在 MS COCO 检索任务上提升超过一倍）。研究人员利用 CCI 和 COVAR 对十八种 CLIP 变体进行了全面评估，提供了方法学上的进步和实证证据，为开发更鲁棒的 VLM 指明了方向。

Conclusion: CCI 是一种有效的方法，可以解释 VLM 的决策过程并解决其对背景的过度依赖问题。COVAR 基准为评估 VLM 的鲁棒性提供了更全面的视角。通过结合 CCI 和 COVAR，可以更深入地理解 VLM 的行为，并指导未来 VLM 的发展，使其更加鲁棒和可靠。

Abstract: Contrastive vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition yet remain vulnerable to spurious correlations, particularly background over-reliance. We introduce Cluster-based Concept Importance (CCI), a novel interpretability method that uses CLIP's own patch embeddings to group spatial patches into semantically coherent clusters, mask them, and evaluate relative changes in model predictions. CCI sets a new state of the art on faithfulness benchmarks, surpassing prior methods by large margins; for example, it yields more than a twofold improvement on the deletion-AUC metric for MS COCO retrieval. We further propose that CCI, when combined with GroundedSAM, automatically categorizes predictions as foreground- or background-driven, providing a crucial diagnostic ability. Existing benchmarks such as CounterAnimals, however, rely solely on accuracy and implicitly attribute all performance degradation to background correlations. Our analysis shows this assumption to be incomplete, since many errors arise from viewpoint variation, scale shifts, and fine-grained object confusions. To disentangle these effects, we introduce COVAR, a benchmark that systematically varies object foregrounds and backgrounds. Leveraging CCI with COVAR, we present a comprehensive evaluation of eighteen CLIP variants, offering methodological advances and empirical evidence that chart a path toward more robust VLMs.

</details>


### [193] [UNSEEN: Enhancing Dataset Pruning from a Generalization Perspective](https://arxiv.org/abs/2511.12988)
*Furui Xu,Shaobo Wang,Jiajun Zhang,Chenghao Sun,Haixiang Tang,Linfeng Zhang*

Main category: cs.CV

TL;DR: 通过从泛化角度进行数据集剪枝，提出 UNSEEN 框架，解决现有方法在训练阶段评分导致样本区分度低的问题，并在多步场景下进行增量选择，显著提升剪枝效果。


<details>
  <summary>Details</summary>
Motivation: 现有数据集剪枝方法主要在模型训练阶段（拟合阶段）评估样本得分，导致样本得分分布集中，区分度低，影响剪枝效果。因此需要一种从泛化角度（在未见过的模型上评估）进行数据集剪枝的方法。

Method: 提出 UNSEEN 框架，该框架可以即插即用地集成到现有数据集剪枝方法中。UNSEEN 从泛化角度评估样本，即基于未在训练期间见过这些样本的模型来对样本进行评分。此外，将 UNSEEN 扩展到多步场景，通过在不同核心集上训练的评分模型进行增量选择，动态优化核心集的质量。

Result: 在 CIFAR-10、CIFAR-100 和 ImageNet-1K 数据集上，UNSEEN 方法显著优于现有的 SOTA 方法。特别是在 ImageNet-1K 数据集上，UNSEEN 在数据量减少 30% 的情况下实现了无损性能。

Conclusion: UNSEEN 框架通过从泛化角度进行数据集剪枝，并结合多步增量选择技术，有效解决了现有方法的局限性，显著提高了数据集剪枝的效率和效果，尤其在大型数据集上表现突出。

Abstract: The growing scale of datasets in deep learning has introduced significant computational challenges. Dataset pruning addresses this challenge by constructing a compact but informative coreset from the full dataset with comparable performance. Previous approaches typically establish scoring metrics based on specific criteria to identify representative samples. However, these methods predominantly rely on sample scores obtained from the model's performance during the training (i.e., fitting) phase. As scoring models achieve near-optimal performance on training data, such fitting-centric approaches induce a dense distribution of sample scores within a narrow numerical range. This concentration reduces the distinction between samples and hinders effective selection. To address this challenge, we conduct dataset pruning from the perspective of generalization, i.e., scoring samples based on models not exposed to them during training. We propose a plug-and-play framework, UNSEEN, which can be integrated into existing dataset pruning methods. Additionally, conventional score-based methods are single-step and rely on models trained solely on the complete dataset, providing limited perspective on the importance of samples. To address this limitation, we scale UNSEEN to multi-step scenarios and propose an incremental selection technique through scoring models trained on varying coresets, and optimize the quality of the coreset dynamically. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art (SOTA) methods on CIFAR-10, CIFAR-100, and ImageNet-1K. Notably, on ImageNet-1K, UNSEEN achieves lossless performance while reducing training data by 30\%.

</details>


### [194] [Semantic Prioritization in Visual Counterfactual Explanations with Weighted Segmentation and Auto-Adaptive Region Selection](https://arxiv.org/abs/2511.12992)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.CV

TL;DR: 本研究提出了一种名为WSAE-Net的新方法，用于解决非生成式视觉反事实解释中语义相关性不足和编辑效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 传统视觉反事实解释方法在替换图像区域时，忽略了替换区域与目标对象的语义相关性，导致模型可解释性差，编辑流程效率低下。

Method: WSAE-Net包含两个主要创新：1. 加权语义图：最大化减少需要计算的非语义特征单元，提高计算效率。2. 自适应候选编辑序列：确定特征单元处理的最佳计算顺序，保证在保持语义相关性的同时，高效生成反事实解释。

Result: 通过广泛的实验证明，WSAE-Net在视觉反事实解释方面表现出优越性能。

Conclusion: WSAE-Net通过引入加权语义图和自适应候选编辑序列，提高了视觉反事实解释的效率和语义相关性，从而增强了模型的可解释性。

Abstract: In the domain of non-generative visual counterfactual explanations (CE), traditional techniques frequently involve the substitution of sections within a query image with corresponding sections from distractor images. Such methods have historically overlooked the semantic relevance of the replacement regions to the target object, thereby impairing the model's interpretability and hindering the editing workflow. Addressing these challenges, the present study introduces an innovative methodology named as Weighted Semantic Map with Auto-adaptive Candidate Editing Network (WSAE-Net). Characterized by two significant advancements: the determination of an weighted semantic map and the auto-adaptive candidate editing sequence. First, the generation of the weighted semantic map is designed to maximize the reduction of non-semantic feature units that need to be computed, thereby optimizing computational efficiency. Second, the auto-adaptive candidate editing sequences are designed to determine the optimal computational order among the feature units to be processed, thereby ensuring the efficient generation of counterfactuals while maintaining the semantic relevance of the replacement feature units to the target object. Through comprehensive experimentation, our methodology demonstrates superior performance, contributing to a more lucid and in-depth understanding of visual counterfactual explanations.

</details>


### [195] [PerTouch: VLM-Driven Agent for Personalized and Semantic Image Retouching](https://arxiv.org/abs/2511.12998)
*Zewei Chang,Zheng-Peng Duan,Jianxing Zhang,Chun-Le Guo,Siyu Liu,Hyungju Chun,Hyunhee Park,Zikun Liu,Chongyi Li*

Main category: cs.CV

TL;DR: PerTouch是一个统一的、基于扩散的图像修复框架，它支持语义级别的图像修复，同时保持全局美感，并能处理自然语言指令。


<details>
  <summary>Details</summary>
Motivation: 为了解决图像修复中可控性和主观性之间的平衡挑战，并满足用户个性化的美学偏好。

Method: PerTouch使用包含特定语义区域属性值的参数图作为输入，构建显式的参数到图像的映射，以实现细粒度的图像修复。通过引入语义替换和参数扰动机制来提高语义边界感知能力。开发了一个视觉语言模型（VLM）驱动的代理，能够处理强弱用户指令，并结合反馈驱动的再思考和场景感知记忆机制，以更好地与用户意图保持一致并捕捉长期偏好。

Result: 大量实验证明了该框架中每个组件的有效性以及PerTouch在个性化图像修复方面的优越性能。

Conclusion: PerTouch成功实现了语义级别的图像修复，并能根据用户的个性化美学偏好和自然语言指令进行调整。

Abstract: Image retouching aims to enhance visual quality while aligning with users' personalized aesthetic preferences. To address the challenge of balancing controllability and subjectivity, we propose a unified diffusion-based image retouching framework called PerTouch. Our method supports semantic-level image retouching while maintaining global aesthetics. Using parameter maps containing attribute values in specific semantic regions as input, PerTouch constructs an explicit parameter-to-image mapping for fine-grained image retouching. To improve semantic boundary perception, we introduce semantic replacement and parameter perturbation mechanisms in the training process. To connect natural language instructions with visual control, we develop a VLM-driven agent that can handle both strong and weak user instructions. Equipped with mechanisms of feedback-driven rethinking and scene-aware memory, PerTouch better aligns with user intent and captures long-term preferences. Extensive experiments demonstrate each component's effectiveness and the superior performance of PerTouch in personalized image retouching. Code is available at: https://github.com/Auroral703/PerTouch.

</details>


### [196] [Medal S: Spatio-Textual Prompt Model for Medical Segmentation](https://arxiv.org/abs/2511.13001)
*Pengcheng Shi,Jiawei Chen,Jiaqi Liu,Xinglin Zhang,Tao Chen,Lei Li*

Main category: cs.CV

TL;DR: Medal S是一个医学分割基础模型，支持原生分辨率空间和文本提示，通过通道对齐解决分辨率不匹配问题，实现高效的多类别分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理医学图像分割时，文本提示缺乏空间感知能力，容易因分辨率不匹配导致不准确。Medal S旨在解决这一问题，通过结合空间和文本提示，提高分割精度和效率。

Method: Medal S通过通道对齐技术整合了体积提示和文本嵌入，保留了完整的3D上下文，能够并行处理多个原生分辨率掩码。它还引入了一个轻量级3D卷积模块，用于基于两种提示类型进行精确的体素空间细化。此外，Medal S提出了两种提示模式（纯文本模式和混合模式）、动态重采样、优化的文本预处理、两阶段推理策略和后处理技术，以提高效率和准确性。

Result: Medal S在BiomedSegFM数据集上，支持CT、MRI、PET、超声和显微镜等多种模态，可处理多达243个类别。在24类分割任务中，并行空间提示的推理时间比顺序提示减少了90%以上。与SAT相比，Medal S在验证集的五模态平均评估中，DSC提高了6.61%，NSD提高了6.28%，F1提高了13.36%，DSC TP提高了18.49%。

Conclusion: Medal S通过融合空间精度和语义文本引导，在多类别医学分割任务中展现了优于顺序提示方法的效率和准确性。

Abstract: We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.

</details>


### [197] [Infinite-Story: A Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2511.13002)
*Jihun Park,Kyoungmin Lee,Jongmin Gim,Hyeonseo Jo,Minseok Oh,Wonhyeok Choi,Kyumin Hwang,Jaeyeul Kim,Minwoo Choi,Sunghoon Im*

Main category: cs.CV

TL;DR: Infinite-Story是一个无需训练的框架，用于在多提示故事场景中进行一致的文本到图像生成。它通过身份提示替换和统一的注意力引导机制（包括自适应风格注入和同步引导适应）来解决身份和风格不一致的问题，实现了高身份和风格一致性，并且推理速度比现有模型快6倍以上。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成方法在处理多提示故事场景时，存在身份和风格不一致的问题，并且一些方法需要微调或推理速度慢。

Method: Infinite-Story采用基于尺度自动回归的模型，并引入了三种技术：1. 身份提示替换：减少文本编码器的上下文偏差，对齐身份属性。2. 自适应风格注入：强制执行全局风格一致性。3. 同步引导适应：强制执行身份外观一致性，同时保持提示保真度。

Result: 该方法在文本到图像生成方面达到了最先进的性能，实现了高身份和风格一致性，并且推理速度比现有最快的模型快6倍以上（每张图像1.72秒）。

Conclusion: Infinite-Story是一个有效且实用的无需训练的框架，能够为多提示故事场景生成具有高身份和风格一致性的图像，并且推理速度快。

Abstract: We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.

</details>


### [198] [SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias](https://arxiv.org/abs/2511.13005)
*Wenqian Ye,Di Wang,Guangtao Zheng,Bohan Liu,Aidong Zhang*

Main category: cs.CV

TL;DR: CLIP等大型视觉-语言模型通过在共享嵌入空间中对齐图像和文本，在零次学习分类方面表现出强大的性能。然而，CLIP模型经常产生多模态的虚假偏差，即模型倾向于依赖虚假特征。例如，CLIP可能根据频繁出现的背景而不是对象的核心特征来推断图像中的对象类型。这种偏差会严重影响预训练CLIP模型在分布外数据上的鲁棒性，因为在这种数据上，跨模态关联不再成立。现有的减轻多模态虚假偏差的方法通常需要对下游数据进行微调或预先了解偏差，这会影响CLIP的即用性。本文首先从理论上分析了多模态虚假偏差对零次学习分类的影响。基于此，我们提出了一种简单有效的方法——虚假偏差感知引导探索（SAGE），通过引导式提示词选择来减轻虚假偏差。SAGE无需训练、微调或外部注释。它探索提示词模板空间，并选择能引起类别之间最大语义分离的提示词，从而提高最差分组的鲁棒性。在四个真实世界基准数据集和五个流行骨干模型上的大量实验表明，SAGE在零次学习性能和泛化能力方面始终优于以前的零次学习方法，而无需任何外部知识或模型更新。


<details>
  <summary>Details</summary>
Motivation: CLIP等大型视觉-语言模型在零次学习分类任务中表现出色，但容易受到多模态虚假偏差的影响，即模型可能依赖于与类别不相关的特征（如背景）进行判断，这在分布外数据上会导致性能下降。现有的偏差缓解方法需要微调或外部知识，限制了模型的可用性。

Method: 提出了一种名为“虚假偏差感知引导探索（SAGE）”的新方法。该方法通过探索提示词模板空间，并选择能够最大化类别间语义分离的提示词，从而在无需训练、微调或外部注释的情况下减轻多模态虚假偏差，提高模型的鲁棒性。

Result: 在四个真实世界基准数据集和五个流行骨干模型上的实验表明，SAGE方法能够持续提升模型的零次学习性能和泛化能力，并且优于先前不依赖外部知识或模型更新的零次学习方法。

Conclusion: SAGE是一种无需训练、微调或外部知识即可有效减轻CLIP模型多模态虚假偏差的实用方法，通过引导式提示词选择提高了模型的鲁棒性和泛化能力。

Abstract: Large vision-language models, such as CLIP, have shown strong zero-shot classification performance by aligning images and text in a shared embedding space. However, CLIP models often develop multimodal spurious biases, which is the undesirable tendency to rely on spurious features. For example, CLIP may infer object types in images based on frequently co-occurring backgrounds rather than the object's core features. This bias significantly impairs the robustness of pre-trained CLIP models on out-of-distribution data, where such cross-modal associations no longer hold. Existing methods for mitigating multimodal spurious bias typically require fine-tuning on downstream data or prior knowledge of the bias, which undermines the out-of-the-box usability of CLIP. In this paper, we first theoretically analyze the impact of multimodal spurious bias in zero-shot classification. Based on this insight, we propose Spuriousness-Aware Guided Exploration (SAGE), a simple and effective method that mitigates spurious bias through guided prompt selection. SAGE requires no training, fine-tuning, or external annotations. It explores a space of prompt templates and selects the prompts that induce the largest semantic separation between classes, thereby improving worst-group robustness. Extensive experiments on four real-world benchmark datasets and five popular backbone models demonstrate that SAGE consistently improves zero-shot performance and generalization, outperforming previous zero-shot approaches without any external knowledge or model updates.

</details>


### [199] [Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis](https://arxiv.org/abs/2511.13011)
*Qingsen Ma,Chen Zou,Dianyun Wang,Jia Wang,Liuyu Xiang,Zhaofeng He*

Main category: cs.CV

TL;DR: DTGS是一个统一的框架，结合了受Retinex启发的照明分解和热引导的3D高斯泼溅，用于在极低光照条件下进行不变的几何重建。


<details>
  <summary>Details</summary>
Motivation: 在极低光照条件下，新视角合成（NVS）在几何、颜色一致性和辐射稳定性方面存在严重退化。标准3D高斯泼溅（3DGS）直接应用于曝光不足的输入时会失败，因为跨视图的独立增强会导致照明不一致和几何失真。

Method: DTGS通过循环增强-重建机制，对增强、几何和热量监督进行联合优化。一个热量监督分支通过动态平衡增强、结构和热量损失来稳定颜色恢复和几何学习。此外，嵌入3DGS循环中的基于Retinex的分解模块提供了可解释的反射率-照明分离，确保了跨视点的颜色和纹理一致性。

Result: DTGS在RGBT-LOW数据集上进行了评估，该数据集捕获了严重的照明退化。实验表明，DTGS在辐射一致性、几何保真度和颜色稳定性方面显著优于现有的低光增强和3D重建方法。

Conclusion: DTGS通过联合优化照明分解、几何重建和热量监督，有效地解决了极低光照条件下NVS的挑战，实现了不变的几何重建。

Abstract: Under extremely low-light conditions, novel view synthesis (NVS) faces severe degradation in terms of geometry, color consistency, and radiometric stability. Standard 3D Gaussian Splatting (3DGS) pipelines fail when applied directly to underexposed inputs, as independent enhancement across views causes illumination inconsistencies and geometric distortion. To address this, we present DTGS, a unified framework that tightly couples Retinex-inspired illumination decomposition with thermal-guided 3D Gaussian Splatting for illumination-invariant reconstruction. Unlike prior approaches that treat enhancement as a pre-processing step, DTGS performs joint optimization across enhancement, geometry, and thermal supervision through a cyclic enhancement-reconstruction mechanism. A thermal supervisory branch stabilizes both color restoration and geometry learning by dynamically balancing enhancement, structural, and thermal losses. Moreover, a Retinex-based decomposition module embedded within the 3DGS loop provides physically interpretable reflectance-illumination separation, ensuring consistent color and texture across viewpoints. To evaluate our method, we construct RGBT-LOW, a new multi-view low-light thermal dataset capturing severe illumination degradation. Extensive experiments show that DTGS significantly outperforms existing low-light enhancement and 3D reconstruction baselines, achieving superior radiometric consistency, geometric fidelity, and color stability under extreme illumination.

</details>


### [200] [You Only Look Omni Gradient Backpropagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2511.13013)
*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: BP-FPN是一种新颖的特征金字塔架构，通过反向传播优化红外小目标检测，解决了现有方法在单帧特征表示上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在红外小目标检测中，虽然关注时空特征聚合，但性能提升有限，根本瓶颈在于模糊的单帧特征表示，而非时空建模本身。

Method: 提出了一种名为BP-FPN的反向传播驱动特征金字塔架构，引入了梯度隔离低层快捷连接（GILS）来有效融合目标细节，并使用方向梯度正则化（DGR）来强制执行层级特征一致性。

Result: 在多个公开数据集上的大量实验表明，BP-FPN能够持续取得新的最先进性能。

Conclusion: BP-FPN是第一个完全从反向传播角度为红外小目标检测设计的特征金字塔网络（FPN），它通过新颖的机制解决了单帧特征表示的根本问题，并带来了显著的性能提升。

Abstract: Moving infrared small target detection is a key component of infrared search and tracking systems, yet it remains extremely challenging due to low signal-to-clutter ratios, severe target-background imbalance, and weak discriminative features. Existing deep learning methods primarily focus on spatio-temporal feature aggregation, but their gains are limited, revealing that the fundamental bottleneck lies in ambiguous per-frame feature representations rather than spatio-temporal modeling itself. Motivated by this insight, we propose BP-FPN, a backpropagation-driven feature pyramid architecture that fundamentally rethinks feature learning for small target. BP-FPN introduces Gradient-Isolated Low-Level Shortcut (GILS) to efficiently incorporate fine-grained target details without inducing shortcut learning, and Directional Gradient Regularization (DGR) to enforce hierarchical feature consistency during backpropagation. The design is theoretically grounded, introduces negligible computational overhead, and can be seamlessly integrated into existing frameworks. Extensive experiments on multiple public datasets show that BP-FPN consistently establishes new state-of-the-art performance. To the best of our knowledge, it is the first FPN designed for this task entirely from the backpropagation perspective.

</details>


### [201] [Geometry Meets Light: Leveraging Geometric Priors for Universal Photometric Stereo under Limited Multi-Illumination Cues](https://arxiv.org/abs/2511.13015)
*King-Man Tam,Satoshi Ikehata,Yuta Asano,Zhaoyi An,Rei Kawakami*

Main category: cs.CV

TL;DR: GeoUniPS通过整合合成监督和预训练的3D重建模型的几何先验知识，解决了通用光度立体法在复杂场景下对多光照线索不可靠的问题，并在PS-Perp数据集上进行了优化，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 通用光度立体法在无严格光照假设下恢复表面法线方面很有前景，但在复杂野外场景的多光照线索不可靠时（如光照偏差、阴影或自遮挡区域）表现不佳。

Method: 提出GeoUniPS网络，整合合成监督和来自大规模3D重建模型的预训练高层几何先验。设计了光-几何双分支编码器，提取多光照线索和几何先验。引入PS-Perp数据集，使用逼真的透视投影替代传统的正交投影假设。

Result: GeoUniPS在多个数据集上展现了最先进的性能，定量和定性评估结果均优于现有方法，尤其在复杂的野外场景中表现突出。

Conclusion: GeoUniPS通过利用预训练3D重建模型的几何知识和引入透视投影数据，有效克服了现有通用光度立体法的局限性，并在复杂场景下实现了高性能。

Abstract: Universal Photometric Stereo is a promising approach for recovering surface normals without strict lighting assumptions. However, it struggles when multi-illumination cues are unreliable, such as under biased lighting or in shadows or self-occluded regions of complex in-the-wild scenes. We propose GeoUniPS, a universal photometric stereo network that integrates synthetic supervision with high-level geometric priors from large-scale 3D reconstruction models pretrained on massive in-the-wild data. Our key insight is that these 3D reconstruction models serve as visual-geometry foundation models, inherently encoding rich geometric knowledge of real scenes. To leverage this, we design a Light-Geometry Dual-Branch Encoder that extracts both multi-illumination cues and geometric priors from the frozen 3D reconstruction model. We also address the limitations of the conventional orthographic projection assumption by introducing the PS-Perp dataset with realistic perspective projection to enable learning of spatially varying view directions. Extensive experiments demonstrate that GeoUniPS delivers state-of-the-arts performance across multiple datasets, both quantitatively and qualitatively, especially in the complex in-the-wild scenes.

</details>


### [202] [MeanFlow Transformers with Representation Autoencoders](https://arxiv.org/abs/2511.13019)
*Zheyuan Hu,Chieh-Hsin Lai,Ge Wu,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.CV

TL;DR: 本文提出了一种在表示自编码器（RAE）潜在空间中训练和采样的方法，用于MeanFlow（MF）扩散模型，旨在提高训练效率和采样速度，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: MeanFlow（MF）模型在训练和采样过程中存在计算成本高、训练不稳定、需要复杂的引导超参数等问题。特别是在利用预训练的Stable Diffusion变分自编码器（SD-VAE）时，SD-VAE解码器是生成成本的主要部分。因此，需要一种更高效的MF训练和采样方案。

Method: 本文提出了一种在表示自编码器（RAE）潜在空间中训练和采样MF的新方法。RAE利用预训练的视觉编码器（如DINO）提供丰富的潜在表示，并结合轻量级解码器。为了解决MF在RAE潜在空间中训练时梯度爆炸的问题，采用了以下策略：1. 使用一致性中期训练（Consistency Mid-Training）进行轨迹感知初始化。2. 采用两阶段训练：首先，通过蒸馏预训练的流匹配教师模型来加速收敛并降低方差；然后，可选地进行自举阶段，使用单点速度估计器来进一步减小与真实MF的偏差。这种方法消除了对引导的需求，简化了训练配置，并降低了训练和采样的计算量。

Result: 在ImageNet 256数据集上，该方法实现了1步FID为2.03，优于原始MF的3.43；同时采样GFLOPS降低了38%，总训练成本降低了83%。在ImageNet 512数据集上，实现了1步FID为3.23，且GFLOPS最低。

Conclusion: 本文提出的在RAE潜在空间中训练和采样MF的方法，显著提高了训练效率和采样速度，降低了计算成本，并在图像生成任务中取得了优于现有方法的性能。该方法简化了MF的使用，使其在处理高维数据时更加高效可行。

Abstract: MeanFlow (MF) is a diffusion-motivated generative model that enables efficient few-step generation by learning long jumps directly from noise to data. In practice, it is often used as a latent MF by leveraging the pre-trained Stable Diffusion variational autoencoder (SD-VAE) for high-dimensional data modeling. However, MF training remains computationally demanding and is often unstable. During inference, the SD-VAE decoder dominates the generation cost, and MF depends on complex guidance hyperparameters for class-conditional generation. In this work, we develop an efficient training and sampling scheme for MF in the latent space of a Representation Autoencoder (RAE), where a pre-trained vision encoder (e.g., DINO) provides semantically rich latents paired with a lightweight decoder. We observe that naive MF training in the RAE latent space suffers from severe gradient explosion. To stabilize and accelerate training, we adopt Consistency Mid-Training for trajectory-aware initialization and use a two-stage scheme: distillation from a pre-trained flow matching teacher to speed convergence and reduce variance, followed by an optional bootstrapping stage with a one-point velocity estimator to further reduce deviation from the oracle mean flow. This design removes the need for guidance, simplifies training configurations, and reduces computation in both training and sampling. Empirically, our method achieves a 1-step FID of 2.03, outperforming vanilla MF's 3.43, while reducing sampling GFLOPS by 38% and total training cost by 83% on ImageNet 256. We further scale our approach to ImageNet 512, achieving a competitive 1-step FID of 3.23 with the lowest GFLOPS among all baselines. Code is available at https://github.com/sony/mf-rae.

</details>


### [203] [SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction](https://arxiv.org/abs/2511.13020)
*Yufei Wen,Yuting Zhang,Jingdan Kang,Hao Ren,Weibin Cheng,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: 光谱适应：一种半监督域适应框架，用于从RGB图像重建高光谱医学图像，通过光谱密度掩蔽和光谱端元表示对齐来克服数据稀缺和域转移问题。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像（HSI）在医疗保健领域具有巨大潜力，但数据获取成本高昂且技术要求高。从RGB等易获取的模态中恢复HSI数据（高光谱图像重建）是一种实用的解决方案。然而，通用领域的数据集充足，但人类HSI数据的稀缺限制了其在医学应用中的进展。

Method: 提出了一种名为SpectralAdapt的半监督域适应（SSDA）框架，以弥合通用和以人为中心的高光谱数据集之间的域差距。为了充分利用有限的标签和大量的未标记数据，通过引入光谱密度掩蔽（SDM）来增强光谱推理，该掩蔽根据RGB通道的光谱复杂度自适应地掩蔽它们，鼓励在一致性训练期间从互补线索中恢复信息区域。此外，还引入了光谱端元表示对齐（SERA），它从有价值的标记像素中提取物理上可解释的端元，并使用它们作为域不变锚点来指导未标记的预测，并进行动量更新以确保适应性和稳定性。

Result: 实验表明，SpectralAdapt在光谱保真度、跨域泛化和训练稳定性方面取得了持续改进，证明了SSDA作为高光谱成像在医疗保健领域的一种有效解决方案的潜力。

Conclusion: SpectralAdapt框架通过SDM和SERA有效缓解了HSI重建中的域转移、光谱退化和数据稀缺问题，在减少领域差距方面取得了显著效果。

Abstract: Hyperspectral imaging (HSI) holds great potential for healthcare due to its rich spectral information. However, acquiring HSI data remains costly and technically demanding. Hyperspectral image reconstruction offers a practical solution by recovering HSI data from accessible modalities, such as RGB. While general domain datasets are abundant, the scarcity of human HSI data limits progress in medical applications. To tackle this, we propose SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework that bridges the domain gap between general and human-centered HSI datasets. To fully exploit limited labels and abundant unlabeled data, we enhance spectral reasoning by introducing Spectral Density Masking (SDM), which adaptively masks RGB channels based on their spectral complexity, encouraging recovery of informative regions from complementary cues during consistency training. Furthermore, we introduce Spectral Endmember Representation Alignment (SERA), which derives physically interpretable endmembers from valuable labeled pixels and employs them as domain-invariant anchors to guide unlabeled predictions, with momentum updates ensuring adaptability and stability. These components are seamlessly integrated into SpectralAdapt, a spectral prior-guided framework that effectively mitigates domain shift, spectral degradation, and data scarcity in HSI reconstruction. Experiments on benchmark datasets demonstrate consistent improvements in spectral fidelity, cross-domain generalization, and training stability, highlighting the promise of SSDA as an efficient solution for hyperspectral imaging in healthcare.

</details>


### [204] [REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding](https://arxiv.org/abs/2511.13026)
*Jiaze Li,Hao Yin,Wenhui Tan,Jingyang Chen,Boshen Xu,Yuxun Qu,Yijing Chen,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: 纯文本反思机制在长视频理解中存在局限，REVISOR框架通过引入视觉信息和跨模态交互来增强多模态大模型（MLLM）的能力，并使用DADR机制优化奖励，在多个基准测试中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 纯文本反思机制在长视频理解中存在局限，因为长视频包含动态视觉信息且文本反思缺乏跨模态交互能力，无法充分整合视觉信息。

Method: 提出REVISOR（REflective VIsual Segment Oriented Reasoning）框架，一个工具增强的多模态反思框架，使MLLM能够跨文本和视觉模态进行内省式反思，并设计了双重归因解耦奖励（DADR）机制，用于强化学习，确保模型准确审查与问题高度相关的视频片段，并将其集成到GRPO训练策略中，以实现因果对齐。

Result: REVISOR框架在没有额外监督微调或外部模型的情况下，显著增强了MLLM的长视频理解能力，在VideoMME、LongVideoBench、MLVU和LVBench四个基准测试中取得了显著成果。

Conclusion: REVISOR框架通过结合文本和视觉反思，并利用DADR机制优化奖励，有效解决了现有纯文本反思机制在长视频理解中的不足，展示了其在提升MLLM长视频理解能力方面的潜力。

Abstract: Self-reflection mechanisms that rely on purely text-based rethinking processes perform well in most multimodal tasks. However, when directly applied to long-form video understanding scenarios, they exhibit clear limitations. The fundamental reasons for this lie in two points: (1)long-form video understanding involves richer and more dynamic visual input, meaning rethinking only the text information is insufficient and necessitates a further rethinking process specifically targeting visual information; (2) purely text-based reflection mechanisms lack cross-modal interaction capabilities, preventing them from fully integrating visual information during reflection. Motivated by these insights, we propose REVISOR (REflective VIsual Segment Oriented Reasoning), a novel framework for tool-augmented multimodal reflection. REVISOR enables MLLMs to collaboratively construct introspective reflection processes across textual and visual modalities, significantly enhancing their reasoning capability for long-form video understanding. To ensure that REVISOR can learn to accurately review video segments highly relevant to the question during reinforcement learning, we designed the Dual Attribution Decoupled Reward (DADR) mechanism. Integrated into the GRPO training strategy, this mechanism enforces causal alignment between the model's reasoning and the selected video evidence. Notably, the REVISOR framework significantly enhances long-form video understanding capability of MLLMs without requiring supplementary supervised fine-tuning or external models, achieving impressive results on four benchmarks including VideoMME, LongVideoBench, MLVU, and LVBench.

</details>


### [205] [Towards 3D Object-Centric Feature Learning for Semantic Scene Completion](https://arxiv.org/abs/2511.13031)
*Weihua Wang,Yubo Cui,Xiangru Lin,Zhiheng Li,Zheng Fang*

Main category: cs.CV

TL;DR: Ocean是一个以物体为中心的3D语义场景补全框架，通过实例分割、物体中心特征聚合和局部扩散，提高了复杂场景下语义和几何预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于鸟瞰图的3D语义场景补全方法主要关注整个场景，忽略了物体级别的细节，导致在复杂环境中存在语义和几何模糊性。

Method: 1. 使用MobileSAM进行实例分割，提取物体实例。 2. 引入3D语义组注意力模块，利用线性注意力聚合物体中心特征。 3. 设计全局相似性引导注意力模块，处理分割错误和缺失的实例。 4. 提出实例感知局部扩散模块，通过生成过程改进物体特征，并在BEV空间中细化场景表示。

Result: 在SemanticKITTI和SSCBench-KITTI360基准测试中，Ocean分别取得了17.40和20.28的mIoU分数，达到了最先进的性能。

Conclusion: Ocean通过分解场景为单独的物体实例，并利用物体中心特征聚合和局部扩散，有效解决了现有方法的局限性，提高了3D语义场景补全的准确性。

Abstract: Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.

</details>


### [206] [Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts](https://arxiv.org/abs/2511.13032)
*Sheng Liu,Yuanzhi Liang,Jiepeng Wang,Sidan Du,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Uni-Inter是一个统一的框架，用于在单一、与任务无关的架构中生成支持广泛交互场景（包括人与人、人与物、人与场景）的人类运动。它引入了统一交互体积（UIV）的体积表示，将异构交互实体编码到共享空间场中，从而实现一致的关系推理和复合交互建模。运动生成被表述为在UIV上的联合式概率预测，能够捕捉细粒度的空间依赖性并产生连贯的、上下文感知的行为。实验表明，Uni-Inter在三种代表性的交互任务中取得了有竞争力的性能，并且能够很好地泛化到新颖的实体组合。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于特定任务的设计，泛化能力有限，而Uni-Inter旨在通过一个统一的、与任务无关的架构来解决这个问题，以支持广泛的交互场景。

Method: Uni-Inter引入了统一交互体积（UIV），这是一种体积表示，将异构交互实体编码到共享空间场中。运动生成被表述为在UIV上的联合式概率预测。

Result: 实验表明，Uni-Inter在三种代表性的交互任务中取得了有竞争力的性能，并且能够很好地泛化到新颖的实体组合。

Conclusion: 统一建模复合交互为在复杂环境中进行可扩展的运动合成提供了一个有前途的方向。

Abstract: We present Uni-Inter, a unified framework for human motion generation that supports a wide range of interaction scenarios: including human-human, human-object, and human-scene-within a single, task-agnostic architecture. In contrast to existing methods that rely on task-specific designs and exhibit limited generalization, Uni-Inter introduces the Unified Interactive Volume (UIV), a volumetric representation that encodes heterogeneous interactive entities into a shared spatial field. This enables consistent relational reasoning and compound interaction modeling. Motion generation is formulated as joint-wise probabilistic prediction over the UIV, allowing the model to capture fine-grained spatial dependencies and produce coherent, context-aware behaviors. Experiments across three representative interaction tasks demonstrate that Uni-Inter achieves competitive performance and generalizes well to novel combinations of entities. These results suggest that unified modeling of compound interactions offers a promising direction for scalable motion synthesis in complex environments.

</details>


### [207] [uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data](https://arxiv.org/abs/2511.13036)
*Dahyun Chung,Donghyun Shin,Yujin Sung,Seunggi Moon,Jinwoo Jeon,Byung-Jun Lee*

Main category: cs.CV

TL;DR: CLIP在视觉任务上表现出色，但由于多语言图像-文本数据的稀缺，其在低资源语言上的表现受限。本文提出了一种轻量级、数据高效的框架，通过训练一个小的投影模块，利用英语表征作为语义锚点，实现了对五种代表性不足的语言的有效对齐，显著提高了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的光度多语言视觉-语言模型在捷克语、芬兰语、克罗地亚语、匈牙利语和罗马尼亚语等代表性不足的语言上表现不佳，并且需要大量的多语言图像-文本数据。而本文旨在解决低资源语言下多语言视觉-语言模型的性能瓶颈，提出一种无需图像-文本对或文本-文本对，并且冻结预训练图像编码器和多语言文本编码器的轻量级、数据高效的框架。

Method: 本文提出了一种轻量级、数据高效的框架，该框架在训练过程中冻结了预训练的图像编码器和多语言文本编码器，仅训练一个参数量为1.7M的投影模块。该模块利用对比损失和英语表征作为语义锚点，以实现多语言的视觉-语言对齐。

Result: 提出的框架在五种代表性不足的语言上取得了显著的性能提升，解决了现有模型在这些语言上表现不佳的问题。该框架在多个多语言检索基准上进行了评估，证明了其有效性。

Conclusion: 本文提出的基于枢轴的、参数高效的对齐策略能够有效地进行多语言视觉-语言对齐，尤其是在低资源语言的场景下，为包容性的多模态学习提供了有效的解决方案。

Abstract: Contrastive Language-Image Pre-training (CLIP) has demonstrated strong generalization across a wide range of visual tasks by leveraging large-scale English-image pairs. However, its extension to low-resource languages remains limited due to the scarcity of high-quality multilingual image-text data. Existing multilingual vision-language models exhibit consistently low retrieval performance in underrepresented languages including Czech, Finnish, Croatian, Hungarian, and Romanian on the Crossmodal-3600 (XM3600) benchmark. To address this, we propose a lightweight and data-efficient framework for multilingual vision-language alignment. Our approach requires no image-text pairs or text-text pairs and freezes both the pretrained image encoder and multilingual text encoder during training. Only a compact 1.7M-parameter projection module is trained, using a contrastive loss over English representations as semantic anchors. This minimal training setup enables robust multilingual alignment even for languages with limited supervision. Extensive evaluation across multiple multilingual retrieval benchmarks confirms the effectiveness of our method, showing significant gains in five underrepresented languages where existing models typically underperform. These findings highlight the effectiveness of our pivot-based, parameter-efficient alignment strategy for inclusive multimodal learning.

</details>


### [208] [MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization](https://arxiv.org/abs/2511.13039)
*Zhenying Fang,Richang Hong*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Open-Vocabulary Temporal Action Localization (OV-TAL) aims to recognize and localize instances of any desired action categories in videos without explicitly curating training data for all categories. Existing methods mostly recognize action categories at a single granularity, which degrades the recognition accuracy of both base and novel action categories. To address these issues, we propose a Multi-Grained Category-Aware Network (MGCA-Net) comprising a localizer, an action presence predictor, a conventional classifier, and a coarse-to-fine classifier. Specifically, the localizer localizes category-agnostic action proposals. For these action proposals, the action presence predictor estimates the probability that they belong to an action instance. At the same time, the conventional classifier predicts the probability of each action proposal over base action categories at the snippet granularity. Novel action categories are recognized by the coarse-to-fine classifier, which first identifies action presence at the video granularity. Finally, it assigns each action proposal to one category from the coarse categories at the proposal granularity. Through coarse-to-fine category awareness for novel actions and the conventional classifier's awareness of base actions, multi-grained category awareness is achieved, effectively enhancing localization performance. Comprehensive evaluations on the THUMOS'14 and ActivityNet-1.3 benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, our MGCA-Net achieves state-of-the-art results under the Zero-Shot Temporal Action Localization setting.

</details>


### [209] [ViSS-R1: Self-Supervised Reinforcement Video Reasoning](https://arxiv.org/abs/2511.13054)
*Bo Fang,Yuxin Song,Qiangqiang Wu,Haoyuan Sun,Wenhao Wu,Antoni B. Chan*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Pretext-GRPO的自监督强化学习算法和 ViSS-R1框架，旨在提升多模态大语言模型(MLLMs)在视频理解任务中的视觉信息利用率，减少幻觉，并提高推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于R1的方法在视频任务中过度依赖文本信息，忽视了丰富的视觉信息，容易导致捷径学习和幻觉。

Method: 引入Pretext-GRPO算法，通过对视频进行变换并设计相应的“借口任务”（pretext tasks）来奖励模型，促使模型深入理解视觉信息。在此基础上，提出ViSS-R1框架，将借口任务学习整合到MLLM的R1训练后阶段，强制模型在回答用户问题时，同时处理变换后的视觉输入和借口任务问题，从而识别变换并重建视频以给出准确答案。

Result: 在六个广泛使用的视频推理和理解基准测试中，所提出的Pretext-GRPO算法和ViSS-R1框架均展现出有效性和优越性。

Conclusion: ViSS-R1框架通过整合Pretext-GRPO，有效提升了MLLM在复杂视频推理任务中的视觉感知和推理能力。

Abstract: Complex video reasoning remains a significant challenge for Multimodal Large Language Models (MLLMs), as current R1-based methodologies often prioritize text-centric reasoning derived from text-based and image-based developments. In video tasks, such strategies frequently underutilize rich visual information, leading to potential shortcut learning and increased susceptibility to hallucination. To foster a more robust, visual-centric video understanding, we start by introducing a novel self-supervised reinforcement learning GRPO algorithm (Pretext-GRPO) within the standard R1 pipeline, in which positive rewards are assigned for correctly solving pretext tasks on transformed visual inputs, which makes the model to non-trivially process the visual information. Building on the effectiveness of Pretext-GRPO, we further propose the ViSS-R1 framework, which streamlines and integrates pretext-task-based self-supervised learning directly into the MLLM's R1 post-training paradigm. Instead of relying solely on sparse visual cues, our framework compels models to reason about transformed visual input by simultaneously processing both pretext questions (concerning transformations) and true user queries. This necessitates identifying the applied transformation and reconstructing the original video to formulate accurate final answers. Comprehensive evaluations on six widely-used video reasoning and understanding benchmarks demonstrate the effectiveness and superiority of our Pretext-GRPO and ViSS-R1 for complex video reasoning. Our codes and models will be publicly available.

</details>


### [210] [Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries](https://arxiv.org/abs/2511.13055)
*Ruixin Liu,Zejian Yuan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为MonoUnc的新型单目3D车道线检测方法，通过显式建模局部车道结构的不确定性来解决车道线检测中的不确定性问题，并在两个公开数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单目3D车道线检测中未能充分捕捉真实世界场景中的结构变化和固有不确定性，因为它们依赖于简化的几何假设。

Method: MonoUnc将3D车道线投影到前视（FV）空间并用参数化曲线逼近，然后动态生成曲线点查询嵌入以进行3D空间中的车道点预测。每个由相邻点形成的线段被建模为3D高斯分布，并联合优化参数，采用新颖的3D高斯匹配损失。

Result: 在ONCE-3DLanes和OpenLane数据集上的实验表明，MonoUnc在更严格的评估标准下，在所有基准测试中均优于现有的最先进方法。

Conclusion: MonoUnc通过显式建模局部车道结构的不确定性，成功解决了单目3D车道线检测中的不确定性问题，并在多个数据集上取得了领先的性能。

Abstract: Monocular 3D lane detection is challenged by aleatoric uncertainty arising from inherent observation noise. Existing methods rely on simplified geometric assumptions, such as independent point predictions or global planar modeling, failing to capture structural variations and aleatoric uncertainty in real-world scenarios. In this paper, we propose MonoUnc, a bird's-eye view (BEV)-free 3D lane detector that explicitly models aleatoric uncertainty informed by local lane structures. Specifically, 3D lanes are projected onto the front-view (FV) space and approximated by parametric curves. Guided by curve predictions, curve-point query embeddings are dynamically generated for lane point predictions in 3D space. Each segment formed by two adjacent points is modeled as a 3D Gaussian, parameterized by the local structure and uncertainty estimations. Accordingly, a novel 3D Gaussian matching loss is designed to constrain these parameters jointly. Experiments on the ONCE-3DLanes and OpenLane datasets demonstrate that MonoUnc outperforms previous state-of-the-art (SoTA) methods across all benchmarks under stricter evaluation criteria. Additionally, we propose two comprehensive evaluation metrics for ONCE-3DLanes, calculating the average and maximum bidirectional Chamfer distances to quantify global and local errors. Codes are released at https://github.com/lrx02/MonoUnc.

</details>


### [211] [FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation](https://arxiv.org/abs/2511.13063)
*Zhenghua Li,Hang Chen,Zihao Sun,Kai Li,Xiaolin Hu*

Main category: cs.CV

TL;DR: 通过利用视觉基础模型SAM2的强大特征并引入特征引导注意力模块和双亲和力解码器，本研究有效解决了神经科学中电镜图像分割的挑战，在冻结SAM2权重时达到SOTA性能，并在微调后显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 电镜图像神经结构分割面临形态复杂、信噪比低、标注稀疏等挑战，现有方法在准确性和泛化性上受限。本研究旨在利用视觉基础模型在海量自然图像上学习到的先验知识来应对这些挑战。

Method: 提出了一种新颖的框架，将预训练在自然图像上的SAM2模型迁移至电镜领域。具体包括：1. 使用SAM2提取通用特征；2. 引入特征引导注意力模块，利用SAM2的语义线索指导轻量级编码器（FGE）关注难点区域，以弥合领域差距；3. 设计双亲和力解码器生成粗略和精炼的亲和力图。

Result: 在电镜数据上进行实验，结果表明：1. 在冻结SAM2权重的情况下，本方法达到了与SOTA相当的性能；2. 在对电镜数据进行进一步微调后，本方法显著优于现有的SOTA方法。

Conclusion: 本研究验证了将预训练在自然图像上的表示，通过有针对性的领域自适应引导进行迁移，能够有效解决神经分割中的特定挑战。

Abstract: Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.

</details>


### [212] [RobustGait: Robustness Analysis for Appearance Based Gait Recognition](https://arxiv.org/abs/2511.13065)
*Reeshoon Sayera,Akash Kumar,Sirshapan Mitra,Prudvi Kamtam,Yogesh S Rawat*

Main category: cs.CV

TL;DR: RobustGait框架对基于外观的步态识别系统进行了细粒度鲁棒性评估，涵盖了扰动类型、轮廓提取方法、模型架构和部署场景，并在三个数据集上进行了评估，发现了RGB噪声、轮廓提取器偏差、扰动类型和架构设计对鲁棒性的影响，并探索了增强鲁棒性的策略。


<details>
  <summary>Details</summary>
Motivation: 现有的基于外观的步态识别方法在受控数据集上表现良好，但缺乏对其在真实世界干扰和轮廓变化方面鲁棒性的系统评估。

Method: 提出RobustGait框架，从扰动类型（数字、环境、时间、遮挡）、轮廓提取方法（分割和解析网络）、步态识别模型的架构能力以及各种部署场景四个维度对基于外观的步态识别系统进行细粒度鲁棒性评估。在CASIA-B、CCPG和SUSTech1K数据集上引入了15种不同严重程度的腐败类型，并在MEVID上进行了野外验证，同时评估了六种最先进的步态识别系统。

Result: 研究发现，RGB层面的噪声比其他层面的噪声更能反映真实世界的退化情况，并揭示了失真如何通过轮廓提取传播到下游步态识别系统。步态识别的准确性对轮廓提取器的偏差高度敏感，这表明存在被忽视的基准偏差来源。鲁棒性同时取决于扰动类型和架构设计。噪声感知训练和知识蒸馏可以提高性能。

Conclusion: 噪声感知训练和知识蒸馏等策略能够提高步态识别系统的性能，并使其更接近可部署状态。

Abstract: Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward deployment-ready systems.

</details>


### [213] [Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.13079)
*Jiacheng Tang,Mingyue Feng,Jiachao Liu,Yaonong Wang,Jian Pu*

Main category: cs.CV

TL;DR: 为了解决自动驾驶规划中过度依赖自身状态的问题，提出了一种名为AdaptiveAD的新架构，通过双分支和多上下文融合策略，将场景感知和自身状态显式解耦，并在nuScenes数据集上取得了最先进的开放式规划性能，显著提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶模块化设计过度依赖自身状态，限制了泛化能力和场景理解能力，原因是自身状态信息在早期BEV编码器中过早融合，成为下游规划模块的捷径。

Method: 提出AdaptiveAD架构，采用双分支结构，显式解耦场景感知和自身状态。一个分支进行场景驱动推理（省略自身状态），另一个分支进行仅基于规划任务的自身状态驱动推理。通过场景感知融合模块自适应整合两个分支的决策。引入路径注意力机制和BEV单向蒸馏、自回归在线映射辅助任务来保证多任务学习效果。

Result: 在nuScenes数据集上进行了广泛评估，AdaptiveAD实现了最先进的开放式规划性能。

Conclusion: AdaptiveAD成功缓解了对自身状态的过度依赖，并展现出在各种场景下的出色泛化能力。

Abstract: Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.

</details>


### [214] [Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations](https://arxiv.org/abs/2511.13081)
*Yehonatan Elisha,Seffi Cohen,Oren Barkan,Noam Koenigstein*

Main category: cs.CV

TL;DR: Saliency maps缺乏统一的解释目标，阻碍了评估和应用。本文提出了RFxG（参考系×粒度）分类法，区分了“为何是这个？”（点式）和“为何是这个而非其他？”（对比式）以及“为何是哈士奇？”（类级别）和“为何是狗？”（组级别）的解释。现有的评估指标大多只关注点式忠实度，忽略了对比推理和语义粒度。为此，本文提出了四种新的忠实度指标，并构建了一个评估框架，在三种数据集和四种模型上评估了十种SOTA显着性方法。本文主张以用户意图为导向的评估，为开发与人类理解相符的视觉解释提供了理论基础和实践工具。


<details>
  <summary>Details</summary>
Motivation: Saliency maps缺乏统一的解释目标，阻碍了评估和应用。

Method: 提出RFxG（参考系×粒度）分类法，区分了“为何是这个？”（点式）和“为何是这个而非其他？”（对比式）以及“为何是哈士奇？”（类级别）和“为何是狗？”（组级别）的解释。并提出四种新的忠实度指标，构建了一个评估框架。

Result: 现有的评估指标大多只关注点式忠实度，忽略了对比推理和语义粒度。所提出的评估框架在三种数据集和四种模型上评估了十种SOTA显着性方法。

Conclusion: 主张以用户意图为导向的评估，为开发与人类理解相符的视觉解释提供了理论基础和实践工具。

Abstract: Saliency maps are widely used for visual explanations in deep learning, but a fundamental lack of consensus persists regarding their intended purpose and alignment with diverse user queries. This ambiguity hinders the effective evaluation and practical utility of explanation methods.We address this gap by introducing the Reference-Frame $\times$ Granularity (RFxG) taxonomy, a principled conceptual framework that organizes saliency explanations along two essential axes:Reference-Frame: Distinguishing between pointwise ("Why this prediction?") and contrastive ("Why this and not an alternative?") explanations.Granularity: Ranging from fine-grained class-level (e.g., "Why Husky?") to coarse-grained group-level (e.g., "Why Dog?") interpretations.Using the RFxG lens, we demonstrate critical limitations in existing evaluation metrics, which overwhelmingly prioritize pointwise faithfulness while neglecting contrastive reasoning and semantic granularity. To systematically assess explanation quality across both RFxG dimensions, we propose four novel faithfulness metrics. Our comprehensive evaluation framework applies these metrics to ten state-of-the-art saliency methods, four model architectures, and three datasets.By advocating a shift toward user-intent-driven evaluation, our work provides both the conceptual foundation and the practical tools necessary to develop visual explanations that are not only faithful to the underlying model behavior but are also meaningfully aligned with the complexity of human understanding and inquiry.

</details>


### [215] [MergeSlide: Continual Model Merging and Task-to-Class Prompt-Aligned Inference for Lifelong Learning on Whole Slide Images](https://arxiv.org/abs/2511.13099)
*Doanh C. Bui,Ba Hung Ngo,Hoai Luan Pham,Khang Nguyen,Maï K. Nguyen,Yasuhiko Nakashima*

Main category: cs.CV

TL;DR: MergeSlide是一个将终身学习视为模型合并问题的框架，利用视觉-语言病理基础模型，通过正交持续合并策略来合并新任务，并使用TCP推理方法在CLASS-IL设置下进行推理。


<details>
  <summary>Details</summary>
Motivation: 减少处理和传输WSIs（癌症全切片图像）数据所需的资源和精力，尤其是在处理GB级别大小的WSIs时，通过在癌症相关任务上顺序训练或微调统一模型来实现终身学习。

Method: MergeSlide框架将终身学习视为模型合并问题。新任务的处理流程为：1）使用类别感知提示（class-aware prompts）定义任务；2）使用无MLP骨干（MLP-free backbone）进行少量epoch的微调；3）使用正交持续合并策略（orthogonal continual merging strategy）将新任务合并到统一模型中。在CLASS-IL设置下的推理，引入任务到类别提示对齐（Task-to-Class Prompt-aligned, TCP）推理方法，首先使用任务级提示识别相关任务，然后应用相应的类别感知提示进行预测。

Result: 在六个TCGA数据集流上的实验表明，MergeSlide的性能优于基于样本保留的持续学习方法和视觉-语言零样本基线方法。

Conclusion: MergeSlide通过将终身学习视为模型合并问题，并结合类别感知提示、MLP-free微调和正交持续合并策略，有效解决了癌症全切片图像终身学习中的性能保持和灾难性遗忘问题，并在CLASS-IL设置下通过TCP推理实现了优于现有方法的性能。

Abstract: Lifelong learning on Whole Slide Images (WSIs) aims to train or fine-tune a unified model sequentially on cancer-related tasks, reducing the resources and effort required for data transfer and processing, especially given the gigabyte-scale size of WSIs. In this paper, we introduce MergeSlide, a simple yet effective framework that treats lifelong learning as a model merging problem by leveraging a vision-language pathology foundation model. When a new task arrives, it is: 1) defined with class-aware prompts, 2) fine-tuned for a few epochs using an MLP-free backbone, and 3) merged into a unified model using an orthogonal continual merging strategy that preserves performance and mitigates catastrophic forgetting. For inference under the class-incremental learning (CLASS-IL) setting, where task identity is unknown, we introduce Task-to-Class Prompt-aligned (TCP) inference. Specifically, TCP first identifies the most relevant task using task-level prompts and then applies the corresponding class-aware prompts to generate predictions. To evaluate MergeSlide, we conduct experiments on a stream of six TCGA datasets. The results show that MergeSlide outperforms both rehearsal-based continual learning and vision-language zero-shot baselines. Code and data are available at https://github.com/caodoanh2001/MergeSlide.

</details>


### [216] [CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation](https://arxiv.org/abs/2511.13102)
*Yu Zhu,Dan Zeng,Shuiwang Li,Qijun Zhao,Qiaomu Shen,Bo Tang*

Main category: cs.CV

TL;DR: 该论文提出了一种新的类别无关姿态估计（CAPE）框架CapeNext，通过融合分层跨模态交互和双流特征细化来克服现有静态联合嵌入方法的局限性，提高了姿态估计的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有类别无关姿态估计（CAPE）方法依赖于固定的文本关键点描述作为语义先验，存在多义性导致的跨类别模糊以及对类别内部细微差别的区分能力不足的问题。

Method: 提出了一种新的框架，该框架创新性地融合了分层跨模态交互和双流特征细化，利用文本描述和特定图像中的类别级和实例级线索来增强联合嵌入。

Result: 在MP-100数据集上的实验表明，CapeNext在不同网络骨干下均显著优于现有的CAPE方法。

Conclusion: 所提出的CapeNext框架通过引入分层跨模态交互和双流特征细化，有效解决了现有CAPE 方法中的多义性和区分度不足的问题，并在实验中取得了优越性能。

Abstract: Recent research in Category-Agnostic Pose Estimation (CAPE) has adopted fixed textual keypoint description as semantic prior for two-stage pose matching frameworks. While this paradigm enhances robustness and flexibility by disentangling the dependency of support images, our critical analysis reveals two inherent limitations of static joint embedding: (1) polysemy-induced cross-category ambiguity during the matching process(e.g., the concept "leg" exhibiting divergent visual manifestations across humans and furniture), and (2) insufficient discriminability for fine-grained intra-category variations (e.g., posture and fur discrepancies between a sleeping white cat and a standing black cat). To overcome these challenges, we propose a new framework that innovatively integrates hierarchical cross-modal interaction with dual-stream feature refinement, enhancing the joint embedding with both class-level and instance-specific cues from textual description and specific images. Experiments on the MP-100 dataset demonstrate that, regardless of the network backbone, CapeNext consistently outperforms state-of-the-art CAPE methods by a large margin.

</details>


### [217] [PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking](https://arxiv.org/abs/2511.13105)
*Seungjae Kim,SeungJoon Lee,MyeongAh Cho*

Main category: cs.CV

TL;DR: 本文提出了一种名为PlugTrack的新框架，用于解决多目标跟踪（MOT）中运动预测的挑战。该框架通过自适应融合卡尔曼滤波器和数据驱动的运动预测器，有效结合了线性和非线性运动模式的优点，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多目标跟踪（MOT）方法在运动预测方面存在局限性。基于卡尔曼滤波的方法计算效率高，但无法处理非线性运动；而数据驱动的方法虽然能捕捉非线性动态，但存在泛化能力不足和计算开销大的问题。本文旨在解决这一矛盾，提出一种能够融合两种方法优点的框架。

Method: 本文提出PlugTrack框架，通过多感知运动理解，自适应地融合卡尔曼滤波器和数据驱动的运动预测器。该框架利用多感知运动分析生成自适应融合因子，以结合两种预测方法的优点。

Result: PlugTrack框架在MOT17/MOT20数据集上取得了显著的性能提升，并在DanceTrack数据集上达到了最先进水平。实验证明，即使在以非线性运动为主的数据集中，卡尔曼滤波器在多达34%的情况下也优于数据驱动的预测器，表明真实世界的跟踪场景同时包含线性和非线性运动模式。

Conclusion: PlugTrack是第一个通过自适应融合来连接MOT中经典和现代运动预测范式的框架。该方法通过自适应融合卡尔曼滤波器和数据驱动的运动预测器，有效解决了MOT中的运动预测问题，并在多个基准测试中取得了优异的性能。

Abstract: Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.

</details>


### [218] [Low-Level Dataset Distillation for Medical Image Enhancement](https://arxiv.org/abs/2511.13106)
*Fengzhi Xu,Ziyuan Yang,Mengyu Sun,Joey Tianyi Zhou,Yi Zhang*

Main category: cs.CV

TL;DR: 低级别医学图像增强的数据集蒸馏方法，通过利用解剖学先验和保持结构的个性化生成，解决了现有方法的局限性，同时保护患者隐私。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像增强方法需要大量数据，成本高昂。数据集蒸馏（DD）可以缓解这个问题，但现有DD方法主要针对高级任务，而低级别任务（如医学图像增强）的数据集蒸馏是一个未定问题，需要像素级保真度。

Method: 提出首个低级别DD方法，利用解剖学相似性构建共享先验，并通过保持结构的个性化生成（SPG）模块进行个性化。将任务特定的高低质量训练对与患者特异性知识相结合，通过梯度对齐实现。

Result: 该方法能够生成包含抽象训练信息的蒸馏数据集，在不共享原始患者数据的情况下，保护了患者隐私，并实现了医学图像增强。

Conclusion: 提出的低级别DD方法解决了医学图像增强中的挑战，通过利用解剖学先验、SPG模块和梯度对齐，有效压缩了数据，降低了成本，并保护了患者隐私。

Abstract: Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.

</details>


### [219] [DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection](https://arxiv.org/abs/2511.13108)
*Jiazhen Yan,Ziqiang Li,Fan Wang,Boyu Wang,Zhangjie Fu*

Main category: cs.CV

TL;DR: DGS-Net 通过在梯度空间中进行分解，区分并抑制与任务无关的成分，从而在保留预训练模型（如CLIP）的通用表征能力的同时，有效地检测 AI 生成的图像。


<details>
  <summary>Details</summary>
Motivation: 现有的 AI 图像检测方法在微调大型多模态模型（如 CLIP）时，会因灾难性遗忘而损害预训练知识，并限制跨域泛化能力。因此，需要一种能够保留可迁移的预训练先验知识，同时抑制与任务无关成分的检测框架。

Method: 提出了一种名为 DGS-Net 的新框架，该框架在梯度空间中进行分解，将有害和有益的下降方向分离。通过将任务梯度投影到与有害方向正交的补空间，并与从冻结的 CLIP 编码器蒸馏出的有益方向对齐，DGS-Net 实现了先验知识保留和无关成分抑制的统一优化。

Result: 在 50 种生成模型上的大量实验表明，DGS-Net 的性能优于最先进的方法，平均领先 6.6，在各种生成技术上实现了卓越的检测性能和泛化能力。

Conclusion: DGS-Net 能够有效地保留预训练模型的通用表征能力，同时抑制与任务无关的成分，从而在 AI 生成图像检测方面取得优异的性能和泛化能力。

Abstract: The rapid progress of generative models such as GANs and diffusion models has led to the widespread proliferation of AI-generated images, raising concerns about misinformation, privacy violations, and trust erosion in digital media. Although large-scale multimodal models like CLIP offer strong transferable representations for detecting synthetic content, fine-tuning them often induces catastrophic forgetting, which degrades pre-trained priors and limits cross-domain generalization. To address this issue, we propose the Distillation-guided Gradient Surgery Network (DGS-Net), a novel framework that preserves transferable pre-trained priors while suppressing task-irrelevant components. Specifically, we introduce a gradient-space decomposition that separates harmful and beneficial descent directions during optimization. By projecting task gradients onto the orthogonal complement of harmful directions and aligning with beneficial ones distilled from a frozen CLIP encoder, DGS-Net achieves unified optimization of prior preservation and irrelevant suppression. Extensive experiments on 50 generative models demonstrate that our method outperforms state-of-the-art approaches by an average margin of 6.6, achieving superior detection performance and generalization across diverse generation techniques.

</details>


### [220] [Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing](https://arxiv.org/abs/2511.13110)
*Shuaibin Fan,Senming Zhong,Wenchao Yan,Minglong Xue*

Main category: cs.CV

TL;DR: 该论文提出了一种无监督的神经退化表示方法，用于从受雾霾影响的图像中恢复清晰的图像。


<details>
  <summary>Details</summary>
Motivation: 现有图像去雾方法在处理复杂场景时，难以平衡非均匀雾霾分布的细粒度特征表示和全局一致性建模。该研究旨在学习雾霾的空间变化规律，并提出一种无监督的去雾方法。

Method: 1. 提出一种结合通道独立和通道依赖机制的算法，以增强学习非线性依赖关系的能力，从而在复杂场景中获得良好的视觉感知。2. 设计了一种隐式神经表示，将雾霾退化建模为连续函数，消除了对显式特征提取和物理模型的依赖。3. 设计了一个密集残差增强模块，以消除冗余信息，实现高质量的图像恢复。

Result: 实验结果表明，该方法在各种公共和真实数据集上实现了具有竞争力的去雾性能。

Conclusion: 所提出的无监督隐式神经退化表示方法能够有效处理复杂场景下的雾霾问题，并实现高质量的图像恢复。

Abstract: Image dehazing is an important task in the field of computer vision, aiming at restoring clear and detail-rich visual content from haze-affected images. However, when dealing with complex scenes, existing methods often struggle to strike a balance between fine-grained feature representation of inhomogeneous haze distribution and global consistency modeling. Furthermore, to better learn the common degenerate representation of haze in spatial variations, we propose an unsupervised dehaze method for implicit neural degradation representation. Firstly, inspired by the Kolmogorov-Arnold representation theorem, we propose a mechanism combining the channel-independent and channel-dependent mechanisms, which efficiently enhances the ability to learn from nonlinear dependencies. which in turn achieves good visual perception in complex scenes. Moreover, we design an implicit neural representation to model haze degradation as a continuous function to eliminate redundant information and the dependence on explicit feature extraction and physical models. To further learn the implicit representation of the haze features, we also designed a dense residual enhancement module from it to eliminate redundant information. This achieves high-quality image restoration. Experimental results show that our method achieves competitive dehaze performance on various public and real-world datasets. This project code will be available at https://github.com/Fan-pixel/NeDR-Dehaze.

</details>


### [221] [Semantics and Content Matter: Towards Multi-Prior Hierarchical Mamba for Image Deraining](https://arxiv.org/abs/2511.13113)
*Zhaocheng Yu,Kui Jiang,Junjun Jiang,Xianming Liu,Guanglu Sun,Yi Xiao*

Main category: cs.CV

TL;DR: MPHM网络是一种新的图像去雨方法，它结合了CLIP和DINOv2的先验知识，并通过PFI融合这些先验，同时使用HMM进行特征提取，在Rain200H数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的图像去雨方法在处理真实世界的雨水场景时，往往难以保持语义和空间细节的完整性。

Method: 提出了一种名为多先验分层曼巴（MPHM）网络的新架构。该网络集成了宏观语义文本先验（CLIP）和微观结构视觉先验（DINOv2），并设计了一种渐进式的先验融合注入（PFI）机制来融合这些异构先验。同时，骨干网络采用了分层曼巴模块（HMM），该模块具有傅里叶增强的双路径设计，用于同时处理全局上下文建模和局部细节恢复。

Result: MPHM在Rain200H数据集上取得了0.57 dB的PSNR增益，并在真实世界的雨水场景中表现出优越的泛化能力，达到了最先进的性能。

Conclusion: MPHM网络通过结合多种先验知识和创新的网络结构，有效地解决了现有图像去雨方法的局限性，并在性能和泛化能力上取得了显著的突破。

Abstract: Rain significantly degrades the performance of computer vision systems, particularly in applications like autonomous driving and video surveillance. While existing deraining methods have made considerable progress, they often struggle with fidelity of semantic and spatial details. To address these limitations, we propose the Multi-Prior Hierarchical Mamba (MPHM) network for image deraining. This novel architecture synergistically integrates macro-semantic textual priors (CLIP) for task-level semantic guidance and micro-structural visual priors (DINOv2) for scene-aware structural information. To alleviate potential conflicts between heterogeneous priors, we devise a progressive Priors Fusion Injection (PFI) that strategically injects complementary cues at different decoder levels. Meanwhile, we equip the backbone network with an elaborate Hierarchical Mamba Module (HMM) to facilitate robust feature representation, featuring a Fourier-enhanced dual-path design that concurrently addresses global context modeling and local detail recovery. Comprehensive experiments demonstrate MPHM's state-of-the-art performance, achieving a 0.57 dB PSNR gain on the Rain200H dataset while delivering superior generalization on real-world rainy scenarios.

</details>


### [222] [A Lightweight 3D Anomaly Detection Method with Rotationally Invariant Features](https://arxiv.org/abs/2511.13115)
*Hanzhe Liang,Jie Zhou,Can Gao,Bingyang Guo,Jinbao Wang,Linlin Shen*

Main category: cs.CV

TL;DR: 提出了一种新颖的旋转不变特征（RIF）框架，用于处理3D点云异常检测中的方向和位置变化问题，并通过PCM技术和CTF-Net提取旋转不变特征，实验证明该方法在Anomaly-ShapeNet和Real3D-AD数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D异常检测方法在处理方向和位置变化的3D点云数据时，由于特征表示的变化可能面临挑战。

Method: 提出了一种旋转不变特征（RIF）框架，包括点坐标映射（PCM）技术以去除点云数据变化的影响，以及轻量级卷积变换特征网络（CTF-Net）来提取旋转不变特征，并引入迁移学习和3D数据增强来预训练特征提取器。

Result: 在Anomaly-ShapeNet数据集上，平均P-AUROC提高了17.7%；在Real3D-AD数据集上，平均P-AUROC提高了1.6%。

Conclusion: RIF框架具有强大的泛化能力，可与传统特征提取方法结合，在工业应用中具有巨大潜力。

Abstract: 3D anomaly detection (AD) is a crucial task in computer vision, aiming to identify anomalous points or regions from point cloud data. However, existing methods may encounter challenges when handling point clouds with changes in orientation and position because the resulting features may vary significantly. To address this problem, we propose a novel Rotationally Invariant Features (RIF) framework for 3D AD. Firstly, to remove the adverse effect of variations on point cloud data, we develop a Point Coordinate Mapping (PCM) technique, which maps each point into a rotationally invariant space to maintain consistency of representation. Then, to learn robust and discriminative features, we design a lightweight Convolutional Transform Feature Network (CTF-Net) to extract rotationally invariant features for the memory bank. To improve the ability of the feature extractor, we introduce the idea of transfer learning to pre-train the feature extractor with 3D data augmentation. Experimental results show that the proposed method achieves the advanced performance on the Anomaly-ShapeNet dataset, with an average P-AUROC improvement of 17.7\%, and also gains the best performance on the Real3D-AD dataset, with an average P-AUROC improvement of 1.6\%. The strong generalization ability of RIF has been verified by combining it with traditional feature extraction methods on anomaly detection tasks, demonstrating great potential for industrial applications.

</details>


### [223] [CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model](https://arxiv.org/abs/2511.13121)
*Yuqi Zhang,Guanying Chen,Jiaxing Chen,Chuanyu Fu,Chuan Huang,Shuguang Cui*

Main category: cs.CV

TL;DR: 使用基于点的视频扩散模型，通过分层扭曲、遮挡感知噪声抑制和全局结构引导来从稀疏输入视图合成近景新视图。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在近景场景中处理稀疏视图和捕捉细节。

Method: 提出了一种名为CloseUpShot的基于扩散的框架，该框架采用点条件视频扩散。关键技术包括：1. 分层扭曲和遮挡感知噪声抑制，以提高条件图像的质量和完整性。2. 全局结构引导，利用密集的融合点云来提供一致的几何上下文，以弥补稀疏条件输入的全局一致性3D约束的不足。

Result: 在多个数据集上的大量实验表明，该方法在近景新视图合成方面优于现有方法。

Conclusion: 所提出的方法通过分层扭曲、遮挡感知噪声抑制和全局结构引导，有效地解决了稀疏视图近景新视图合成的挑战。

Abstract: Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.

</details>


### [224] [Region-Point Joint Representation for Effective Trajectory Similarity Learning](https://arxiv.org/abs/2511.13125)
*Hao Long,Silin Zhou,Lisi Chen,Shuo Shang*

Main category: cs.CV

TL;DR: RePo方法通过联合编码区域和点特征来提升轨迹相似度计算的准确性，并超越了现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法未能充分利用轨迹信息的完整频谱进行相似度建模。

Method: RePo方法联合编码区域特征（将GPS轨迹映射到网格序列，并融合结构特征、视觉语义特征）和点特征（通过三个专家网络提取局部、相关和连续运动模式），然后使用路由器网络自适应融合点特征，并通过交叉注意力与区域特征结合，生成最终的轨迹嵌入。使用带有困难负样本的对比损失进行训练。

Result: RePo在所有评估指标上的平均准确率比SOTA基线提高了22.2%。

Conclusion: RePo通过结合区域和点特征，有效提升了轨迹相似度计算的性能。

Abstract: Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \textbf{RePo}, a novel method that jointly encodes \textbf{Re}gion-wise and \textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\% over SOTA baselines across all evaluation metrics.

</details>


### [225] [VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language](https://arxiv.org/abs/2511.13127)
*Zonghao Ying,Moyang Chen,Nizhang Li,Zhiqiang Wang,Wenxin Zhang,Quanchen Zou,Zonglei Jing,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: 隐蔽的提示词能够诱导文本到视频模型生成不安全视频，VEIL框架通过结合中性场景锚点、潜在听觉触发器和风格调节器，利用跨模态关联模式实现此目的，并在商业模型上取得了显著的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有针对文本到视频模型的越狱攻击通常采用明显的危险提示词，容易被检测和防御。本研究旨在探索一种更隐蔽的方法，利用看似无害的提示词来生成不安全视频。

Method: 提出VEIL框架，该框架包含三个模块：1. 中性场景锚点：提取被阻止意图的表面场景描述以保持合理性。2. 潜在听觉触发器：描述无害的音频事件，利用音视频共同出现的先验知识偏向模型生成特定的不安全视觉概念。3. 风格调节器：电影化指令（如镜头、氛围）来放大和稳定潜在触发器的效果。攻击生成被形式化为在上述模块化提示空间上的约束优化问题，并通过引导搜索过程来解决。

Result: 在7个文本到视频模型上进行了广泛的实验，证明了该攻击的有效性，在商业模型上的平均攻击成功率提高了23%。

Conclusion: VEIL框架能够有效地利用文本到视频模型的跨模态关联模式，通过精心设计的隐蔽提示词生成不安全视频，显著提高了攻击成功率，暴露了当前模型在安全防护上的不足。

Abstract: Jailbreak attacks can circumvent model safety guardrails and reveal critical blind spots. Prior attacks on text-to-video (T2V) models typically add adversarial perturbations to obviously unsafe prompts, which are often easy to detect and defend. In contrast, we show that benign-looking prompts containing rich, implicit cues can induce T2V models to generate semantically unsafe videos that both violate policy and preserve the original (blocked) intent. To realize this, we propose VEIL, a jailbreak framework that leverages T2V models' cross-modal associative patterns via a modular prompt design. Specifically, our prompts combine three components: neutral scene anchors, which provide the surface-level scene description extracted from the blocked intent to maintain plausibility; latent auditory triggers, textual descriptions of innocuous-sounding audio events (e.g., creaking, muffled noises) that exploit learned audio-visual co-occurrence priors to bias the model toward particular unsafe visual concepts; and stylistic modulators, cinematic directives (e.g., camera framing, atmosphere) that amplify and stabilize the latent trigger's effect. We formalize attack generation as a constrained optimization over the above modular prompt space and solve it with a guided search procedure that balances stealth and effectiveness. Extensive experiments over 7 T2V models demonstrate the efficacy of our attack, achieving a 23 percent improvement in average attack success rate in commercial models.

</details>


### [226] [Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack](https://arxiv.org/abs/2511.13132)
*Chenyang Li,Wenbing Tang,Yihao Huang,Sinong Simon Zhan,Ming Hu,Xiaojun Jia,Yang Liu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ILA的黑盒对抗性攻击框架，通过操纵室内照明来扰乱视觉-语言导航（VLN）智能体，揭示了VLN智能体在真实室内光照变化下存在的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有VLN的鲁棒性研究不足，对抗性评估依赖于不切实际的纹理扰动；而室内光照是影响导航的内在因素，却被忽视了。本研究旨在探索室内光照对VLN的影响，并提出相应的攻击方法。

Method: 提出ILA（Indoor Lighting-based Adversarial Attack）框架，通过操纵全局光照来干扰VLN智能体。包含两种攻击模式：SILA（静态室内光照攻击）和DILA（动态室内光照攻击）。

Result: 在两个最先进的VLN模型和三个导航任务上的评估显示，ILA显著增加了失败率并降低了轨迹效率，揭示了VLN智能体在真实室内光照变化下存在的漏洞。

Conclusion: 室内光照是影响VLN智能体鲁棒性的重要因素，现有的VLN模型在这种变化下表现脆弱。ILA框架能够有效地暴露这些漏洞。

Abstract: Vision-and-Language Navigation (VLN) agents have made remarkable progress, but their robustness remains insufficiently studied. Existing adversarial evaluations often rely on perturbations that manifest as unusual textures rarely encountered in everyday indoor environments. Errors under such contrived conditions have limited practical relevance, as real-world agents are unlikely to encounter such artificial patterns. In this work, we focus on indoor lighting, an intrinsic yet largely overlooked scene attribute that strongly influences navigation. We propose Indoor Lighting-based Adversarial Attack (ILA), a black-box framework that manipulates global illumination to disrupt VLN agents. Motivated by typical household lighting usage, we design two attack modes: Static Indoor Lighting-based Attack (SILA), where the lighting intensity remains constant throughout an episode, and Dynamic Indoor Lighting-based Attack (DILA), where lights are switched on or off at critical moments to induce abrupt illumination changes. We evaluate ILA on two state-of-the-art VLN models across three navigation tasks. Results show that ILA significantly increases failure rates while reducing trajectory efficiency, revealing previously unrecognized vulnerabilities of VLN agents to realistic indoor lighting variations.

</details>


### [227] [MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation](https://arxiv.org/abs/2511.13135)
*Junjie Yang,Yuhao Yan,Gang Wu,Yuxuan Wang,Ruoyu Liang,Xinjie Jiang,Xiang Wan,Fenglei Fan,Yongquan Zhang,Feiwei Qin,Changmiao Wan*

Main category: cs.CV

TL;DR: MedGEN-Bench是一个包含6422个图像-文本对的多模态基准，涵盖6种成像模式、16个临床任务和28个子任务，旨在解决现有医学视觉基准的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉基准在查询相关性、诊断推理复杂性和评估范式方面存在不足，无法满足临床工作流程中对AI生成医学图像的需求。

Method: MedGEN-Bench包含视觉问答、图像编辑和上下文多模态生成三种格式，其特点是使用需要复杂跨模态推理和开放式生成输出的上下文指令。评估框架包含像素级指标、语义文本分析和专家临床相关性评分。

Result: 对10个组件框架、3个统一模型和5个视觉语言模型进行了评估。

Conclusion: MedGEN-Bench通过提供一个全面的多模态基准和创新的评估框架，推动了医学AI在图像生成和跨模态推理方面的研究。

Abstract: As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.

</details>


### [228] [WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection](https://arxiv.org/abs/2511.13138)
*Longhui Zheng,Qiming Xia,Xiaolu Chen,Zhaoliang Liu,Chenglu Wen*

Main category: cs.CV

TL;DR: WinMamba是一种新颖的基于Mamba的3D特征编码骨干网络，通过窗口自适应和可学习的位置编码来提高3D目标检测的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D目标检测方法在计算效率和捕捉长距离空间依赖性之间存在挑战。Mamba模型虽然能以较低的成本捕捉长距离依赖性，但现有的基于Mamba的方法在扫描时会丢失空间信息。

Method: 提出WinMamba骨干网络，包含堆叠的WinMamba块。WinMamba块包含一个窗口自适应模块（WSF）来补偿不同分辨率下的体素特征，以及一个可学习的位置编码和窗口移位策略（AWF）来获取丰富的上下文线索。

Result: 在KITTI和Waymo数据集上的实验表明，WinMamba显著优于基线模型。消融研究验证了WSF和AWF模块对提高检测精度的贡献。

Conclusion: WinMamba通过其新颖的设计，在3D目标检测任务中实现了效率和准确性的良好平衡，并有效解决了现有方法的不足。

Abstract: 3D object detection is critical for autonomous driving, yet it remains fundamentally challenging to simultaneously maximize computational efficiency and capture long-range spatial dependencies. We observed that Mamba-based models, with their linear state-space design, capture long-range dependencies at lower cost, offering a promising balance between efficiency and accuracy. However, existing methods rely on axis-aligned scanning within a fixed window, inevitably discarding spatial information. To address this problem, we propose WinMamba, a novel Mamba-based 3D feature-encoding backbone composed of stacked WinMamba blocks. To enhance the backbone with robust multi-scale representation, the WinMamba block incorporates a window-scale-adaptive module that compensates voxel features across varying resolutions during sampling. Meanwhile, to obtain rich contextual cues within the linear state space, we equip the WinMamba layer with a learnable positional encoding and a window-shift strategy. Extensive experiments on the KITTI and Waymo datasets demonstrate that WinMamba significantly outperforms the baseline. Ablation studies further validate the individual contributions of the WSF and AWF modules in improving detection accuracy. The code will be made publicly available.

</details>


### [229] [Automated Road Distress Detection Using Vision Transformersand Generative Adversarial Networks](https://arxiv.org/abs/2511.13145)
*Cesar Portocarrero Rodriguez,Laura Vandeweyen,Yosuke Yamamoto*

Main category: cs.CV

TL;DR: 美国基础设施状况不佳，道路管理效率低下。本项目利用计算机视觉技术，特别是生成对抗网络（GANs）和卷积神经网络（CNNs），以及MaskFormer模型，对道路病害进行分割，旨在提高道路监测效率和数据准确性。


<details>
  <summary>Details</summary>
Motivation: 道路是区域经济的重要组成部分，但目前的人工或激光检测方法成本高昂且耗时。本项目旨在利用日益增长的自动驾驶汽车实时视觉数据，通过计算机视觉技术改进道路监测，为基础设施修复提供依据。

Method: 本项目首先评估了使用生成对抗网络（GANs）生成的合成数据在模型训练中的有效性。随后，应用卷积神经网络（CNNs）进行道路病害分割，并进一步研究了基于Transformer的模型MaskFormer。

Result: 研究结果表明，GAN生成的合成数据能够提升模型的性能。在道路病害分割任务中，MaskFormer模型在mAP50和IoU两个评估指标上均优于CNN模型。

Conclusion: 利用GAN生成数据和MaskFormer模型可以有效提升道路病害分割的准确性和效率，为改善道路基础设施管理提供了一种有前景的方法。

Abstract: The American Society of Civil Engineers has graded Americas infrastructure condition as a C, with the road system receiving a dismal D. Roads are vital to regional economic viability, yet their management, maintenance, and repair processes remain inefficient, relying on outdated manual or laser-based inspection methods that are both costly and time-consuming. With the increasing availability of real-time visual data from autonomous vehicles, there is an opportunity to apply computer vision (CV) methods for advanced road monitoring, providing insights to guide infrastructure rehabilitation efforts. This project explores the use of state-of-the-art CV techniques for road distress segmentation. It begins by evaluating synthetic data generated with Generative Adversarial Networks (GANs) to assess its usefulness for model training. The study then applies Convolutional Neural Networks (CNNs) for road distress segmentation and subsequently examines the transformer-based model MaskFormer. Results show that GAN-generated data improves model performance and that MaskFormer outperforms the CNN model in two metrics: mAP50 and IoU.

</details>


### [230] [Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification](https://arxiv.org/abs/2511.13150)
*Rifen Lin,Alex Jinpeng Wang,Jiawei Mo,Min Li*

Main category: cs.CV

TL;DR: 本文提出了首个基于骨骼的视频行人重识别（ReID）的预训练框架CSIP-ReID，通过骨骼序列和视频帧的对比学习，并结合动态原型融合和骨骼引导的时间建模，有效捕捉运动和外观线索，在多个基准测试中取得了最先进的成果，并能在仅骨骼的ReID任务中展现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于视频-文本的行人重识别（ReID）预训练方法存在真正的多模态预训练不足以及文本难以捕捉细粒度运动信息的问题。

Method: 提出了一种名为CSIP-ReID的新型两阶段方法，第一阶段利用对比学习对齐骨骼和视觉特征序列，第二阶段引入动态原型融合更新器（PFU）来融合运动和外观线索，并提出骨骼引导时间建模（SGTM）模块来提取和融合骨骼数据中的时间线索。

Result: CSIP-ReID在MARS、LS-VID、iLIDS-VID等视频ReID基准测试中取得了新的最先进成果，并在BIWI、IAS等骨骼ReID任务上表现出强大的泛化能力，显著优于先前的方法。

Conclusion: CSIP-ReID开创了一种无需标注、感知运动的ReID预训练范式，为多模态表示学习开辟了新方向。

Abstract: Multimodal pretraining has revolutionized visual understanding, but its impact on video-based person re-identification (ReID) remains underexplored. Existing approaches often rely on video-text pairs, yet suffer from two fundamental limitations: (1) lack of genuine multimodal pretraining, and (2) text poorly captures fine-grained temporal motion-an essential cue for distinguishing identities in video. In this work, we take a bold departure from text-based paradigms by introducing the first skeleton-driven pretraining framework for ReID. To achieve this, we propose Contrastive Skeleton-Image Pretraining for ReID (CSIP-ReID), a novel two-stage method that leverages skeleton sequences as a spatiotemporally informative modality aligned with video frames. In the first stage, we employ contrastive learning to align skeleton and visual features at sequence level. In the second stage, we introduce a dynamic Prototype Fusion Updater (PFU) to refine multimodal identity prototypes, fusing motion and appearance cues. Moreover, we propose a Skeleton Guided Temporal Modeling (SGTM) module that distills temporal cues from skeleton data and integrates them into visual features. Extensive experiments demonstrate that CSIP-ReID achieves new state-of-the-art results on standard video ReID benchmarks (MARS, LS-VID, iLIDS-VID). Moreover, it exhibits strong generalization to skeleton-only ReID tasks (BIWI, IAS), significantly outperforming previous methods. CSIP-ReID pioneers an annotation-free and motion-aware pretraining paradigm for ReID, opening a new frontier in multimodal representation learning.

</details>


### [231] [SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration](https://arxiv.org/abs/2511.13168)
*Haodong Wang,Tao Zhuo,Xiuwei Zhang,Hanlin Yin,Wencong Wu,Yanning Zhang*

Main category: cs.CV

TL;DR: SOMA是一个集成了结构梯度先验的深度学习框架，通过特征梯度增强器（FGE）和全局-局部仿射流匹配器（GLAM）来提升SAR和光学图像的像素级配准精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在SAR和光学图像配准任务上的表现仍不理想，传统梯度信息在深度学习框架中未被有效利用，限制了配准性能。

Method: 提出SOMA框架，包含特征梯度增强器（FGE）和全局-局部仿射流匹配器（GLAM）。FGE通过多尺度、多方向梯度滤波器增强特征区分度；GLAM结合仿射变换和流场细化，实现粗到精的配准。

Result: SOMA在SEN1-2数据集上将CMR@1px提高了12.29%，在GFGE_SO数据集上提高了18.50%，显著提升了配准精度，并展现出良好的鲁棒性和泛化能力。

Conclusion: SOMA框架通过有效融合梯度信息和深度特征，克服了SAR和光学图像配准的挑战，实现了高精度、鲁棒和泛化的配准效果。

Abstract: Achieving pixel-level registration between SAR and optical images remains a challenging task due to their fundamentally different imaging mechanisms and visual characteristics. Although deep learning has achieved great success in many cross-modal tasks, its performance on SAR-Optical registration tasks is still unsatisfactory. Gradient-based information has traditionally played a crucial role in handcrafted descriptors by highlighting structural differences. However, such gradient cues have not been effectively leveraged in deep learning frameworks for SAR-Optical image matching. To address this gap, we propose SOMA, a dense registration framework that integrates structural gradient priors into deep features and refines alignment through a hybrid matching strategy. Specifically, we introduce the Feature Gradient Enhancer (FGE), which embeds multi-scale, multi-directional gradient filters into the feature space using attention and reconstruction mechanisms to boost feature distinctiveness. Furthermore, we propose the Global-Local Affine-Flow Matcher (GLAM), which combines affine transformation and flow-based refinement within a coarse-to-fine architecture to ensure both structural consistency and local accuracy. Experimental results demonstrate that SOMA significantly improves registration precision, increasing the CMR@1px by 12.29% on the SEN1-2 dataset and 18.50% on the GFGE_SO dataset. In addition, SOMA exhibits strong robustness and generalizes well across diverse scenes and resolutions.

</details>


### [232] [THIR: Topological Histopathological Image Retrieval](https://arxiv.org/abs/2511.13170)
*Zahra Tabatabaei,Jon Sporring*

Main category: cs.CV

TL;DR: THIR是一个新的基于内容的医学图像检索框架，它使用拓扑数据分析（特别是贝蒂数）来检索组织病理学图像，无需监督学习，速度快，效果好。


<details>
  <summary>Details</summary>
Motivation: 早期诊断和准确的临床决策对于降低乳腺癌的死亡率至关重要。

Method: 提出THIR框架，利用拓扑数据分析（贝蒂数）从RGB组织病理学图像中提取拓扑特征，然后通过比较这些特征的距离来进行图像检索。

Result: 在BreaKHis数据集上，THIR的性能优于现有的监督和无监督方法，并且在标准CPU上处理整个数据集仅需20分钟。

Conclusion: THIR提供了一种快速、可扩展且无需训练的临床图像检索解决方案。

Abstract: According to the World Health Organization, breast cancer claimed the lives of approximately 685,000 women in 2020. Early diagnosis and accurate clinical decision making are critical in reducing this global burden. In this study, we propose THIR, a novel Content-Based Medical Image Retrieval (CBMIR) framework that leverages topological data analysis specifically, Betti numbers derived from persistent homology to characterize and retrieve histopathological images based on their intrinsic structural patterns. Unlike conventional deep learning approaches that rely on extensive training, annotated datasets, and powerful GPU resources, THIR operates entirely without supervision. It extracts topological fingerprints directly from RGB histopathological images using cubical persistence, encoding the evolution of loops as compact, interpretable feature vectors. The similarity retrieval is then performed by computing the distances between these topological descriptors, efficiently returning the top-K most relevant matches.
  Extensive experiments on the BreaKHis dataset demonstrate that THIR outperforms state of the art supervised and unsupervised methods. It processes the entire dataset in under 20 minutes on a standard CPU, offering a fast, scalable, and training free solution for clinical image retrieval.

</details>


### [233] [HDW-SR: High-Frequency Guided Diffusion Model based on Wavelet Decomposition for Image Super-Resolution](https://arxiv.org/abs/2511.13175)
*Chao Yang,Boqian Zhang,Jinghao Xu,Guang Jiang*

Main category: cs.CV

TL;DR: HDW-SR利用小波分解和高频引导的扩散模型解决了单一图像超分辨率中的模糊细节问题，通过仅在残差图上进行扩散并使用小波实现多尺度分解，从而有效恢复高频细节。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的方法在单一图像超分辨率（SISR）中存在不足，容易因高频域引导不足导致细节模糊。HDW-SR旨在通过引入高频引导机制来解决这个问题。

Method: HDW-SR使用基于小波分解的U-Net替代传统骨干网络，仅对残差图进行扩散以聚焦高频信息恢复。它采用小波下采样进行多尺度频率分解，并通过稀疏交叉注意力机制引导高频子带和低频子带的交互，同时引入动态阈值块（DTB）优化高频选择。小波变换的可逆性保证了上采样过程中特征的低损耗重建。

Result: 实验结果表明，HDW-SR在合成和真实世界数据集上都取得了具有竞争力的超分辨率性能，特别是在恢复精细图像细节方面表现出色。

Conclusion: HDW-SR通过高频引导和多尺度分析，有效解决了现有扩散模型在SISR中恢复细节不足的问题，实现了优于以往方法的性能。

Abstract: Diffusion-based methods have shown great promise in single image super-resolution (SISR); however, existing approaches often produce blurred fine details due to insufficient guidance in the high-frequency domain. To address this issue, we propose a High-Frequency Guided Diffusion Network based on Wavelet Decomposition (HDW-SR), which replaces the conventional U-Net backbone in diffusion frameworks. Specifically, we perform diffusion only on the residual map, allowing the network to focus more effectively on high-frequency information restoration. We then introduce wavelet-based downsampling in place of standard CNN downsampling to achieve multi-scale frequency decomposition, enabling sparse cross-attention between the high-frequency subbands of the pre-super-resolved image and the low-frequency subbands of the diffused image for explicit high-frequency guidance. Moreover, a Dynamic Thresholding Block (DTB) is designed to refine high-frequency selection during the sparse attention process. During upsampling, the invertibility of the wavelet transform ensures low-loss feature reconstruction. Experiments on both synthetic and real-world datasets demonstrate that HDW-SR achieves competitive super-resolution performance, excelling particularly in recovering fine-grained image details. The code will be available after acceptance.

</details>


### [234] [GenTract: Generative Global Tractography](https://arxiv.org/abs/2511.13183)
*Alec Sargood,Lemuel Puglisi,Elinor Thompson,Mirco Musolesi,Daniel C. Alexander*

Main category: cs.CV

TL;DR: GenTract是一个首创的全局追踪生成模型，通过直接从dMRI数据生成解剖学上合理的纤维束，提高了追踪精度，尤其是在低分辨率和噪声环境下。


<details>
  <summary>Details</summary>
Motivation: 传统的局部追踪方法容易出错，而全局方法计算成本高。本研究旨在解决这些挑战，提出一种新的全局追踪方法。

Method: GenTract将追踪视为一个生成任务，学习从dMRI到完整、解剖学上合理的纤维束的直接映射。该模型结合了基于扩散和流匹配的方法。

Result: GenTract的精确率是次优方法TractOracle的2.1倍，在低分辨率和噪声数据下，其性能比竞争方法高出一个数量级。

Conclusion: GenTract在研究级数据上实现了高精度，并能可靠地处理不完美、低分辨率的数据，为全局追踪提供了一个有前景的解决方案。

Abstract: Tractography is the process of inferring the trajectories of white-matter pathways in the brain from diffusion magnetic resonance imaging (dMRI). Local tractography methods, which construct streamlines by following local fiber orientation estimates stepwise through an image, are prone to error accumulation and high false positive rates, particularly on noisy or low-resolution data. In contrast, global methods, which attempt to optimize a collection of streamlines to maximize compatibility with underlying fiber orientation estimates, are computationally expensive. To address these challenges, we introduce GenTract, the first generative model for global tractography. We frame tractography as a generative task, learning a direct mapping from dMRI to complete, anatomically plausible streamlines. We compare both diffusion-based and flow matching paradigms and evaluate GenTract's performance against state-of-the-art baselines. Notably, GenTract achieves precision 2.1x higher than the next-best method, TractOracle. This advantage becomes even more pronounced in challenging low-resolution and noisy settings, where it outperforms the closest competitor by an order of magnitude. By producing tractograms with high precision on research-grade data while also maintaining reliability on imperfect, lower-resolution data, GenTract represents a promising solution for global tractography.

</details>


### [235] [Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework](https://arxiv.org/abs/2511.13189)
*Diego Ortego,Marlon Rodríguez,Mario Almagro,Kunal Dahiya,David Jiménez,Juan C. SanMiguel*

Main category: cs.CV

TL;DR: 大型语言模型在极端多标签分类（XMC）中取得了显著进展，通过结合大型解码器模型和视觉信息，ViXML框架在保持效率的同时显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决在极端多标签分类（XMC）任务中有效利用大型解码器模型和视觉信息以提高效率和性能的挑战。

Method: 提出ViXML框架，该框架将大型解码器模型与通过池化单个图像嵌入来整合基础视觉模型相结合，以保持计算效率并实现多模态能力。

Result: ViXML框架在P@1指标上超越了现有技术，在最大数据集上的提升高达+8.21%。即使是小型编码器，ViXML也常常优于纯文本解码器。引入了利用视觉元数据的扩展文本数据集。

Conclusion: 大型解码器模型和视觉信息对于XMC至关重要，ViXML框架有效地结合了这两者，在保持计算效率的同时取得了最先进的性能。

Abstract: Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.

</details>


### [236] [Video Spatial Reasoning with Object-Centric 3D Rollout](https://arxiv.org/abs/2511.13190)
*Haoran Tang,Meng Cao,Ruyang Liu,Xiaoxi Liang,Linglong Li,Ge Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: OCR通过在训练期间对3D几何进行结构化扰动来改进视频空间推理，从而实现对整个场景的整体推理，并在VSI-Bench上达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在视频空间推理方面存在局限性，它们往往只关注提示中明确提到的物体，而忽略了关键的上下文线索。

Method: 提出了一种名为OCR（Object-Centric 3D Rollout）的新策略，通过在训练期间对选定物体的3D几何进行结构化扰动，并结合基于滚动的训练流程，共同优化空间推理轨迹。

Result: OCR在VSI-Bench上取得了最先进的性能，其3B参数模型达到了47.5%的准确率，优于几个7B基线模型。消融实验也证实了OCR优于之前的滚动策略。

Conclusion: OCR是一种有效的方法，可以提高MLLMs在视频空间推理方面的能力，使其能够更好地理解动态3D场景中的物体位置、方向和相互关系。

Abstract: Recent advances in Multi-modal Large Language Models (MLLMs) have showcased remarkable capabilities in vision-language understanding. However, enabling robust video spatial reasoning-the ability to comprehend object locations, orientations, and inter-object relationships in dynamic 3D scenes-remains a key unsolved challenge. Existing approaches primarily rely on spatially grounded supervised fine-tuning or reinforcement learning, yet we observe that such models often exhibit query-locked reasoning, focusing narrowly on objects explicitly mentioned in the prompt while ignoring critical contextual cues. To address this limitation, we propose Object-Centric 3D Rollout (OCR), a novel strategy that introduces structured perturbations to the 3D geometry of selected objects during training. By degrading object-specific visual cues and projecting the altered geometry into 2D space, OCR compels the model to reason holistically across the entire scene. We further design a rollout-based training pipeline that jointly leverages vanilla and region-noisy videos to optimize spatial reasoning trajectories. Experiments demonstrate state-of-the-art performance: our 3B-parameter model achieves 47.5% accuracy on VSI-Bench, outperforming several 7B baselines. Ablations confirm OCR's superiority over prior rollout strategies (e.g., T-GRPO, NoisyRollout).

</details>


### [237] [Birth of a Painting: Differentiable Brushstroke Reconstruction](https://arxiv.org/abs/2511.13191)
*Ying Jiang,Jiayin Lu,Yunuo Chen,Yumeng He,Kui Wu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 该研究提出了一个可微分的笔触重建框架，用于逼真地模拟人类绘画和涂抹过程，能够生成具有流畅的色调过渡和丰富风格化外观的数字绘画。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在绘画合成方面存在不足，未能显式处理笔触结构，且难以生成平滑自然的阴影效果。

Method: 研究提出了一个可微分的笔触重建框架，首先通过并行可微分绘画渲染器优化贝塞尔曲线笔触，然后利用风格生成模块合成几何条件纹理，并引入可微分涂抹算子来实现颜色混合和阴影效果，最后结合粗到精的优化策略，在几何和语义引导下联合优化笔触几何、颜色和纹理。

Result: 该方法在油画、水彩画、墨水画和数字绘画等多种类型画作上进行了广泛的实验，结果表明该方法能够生成逼真且富有表现力的笔触重建，实现平滑的色调过渡和丰富的风格化外观。

Conclusion: 该方法为表达性数字绘画创作提供了一个统一的模型，能够真实地再现绘画-涂抹循环，生成高质量的绘画作品。

Abstract: Painting embodies a unique form of visual storytelling, where the creation process is as significant as the final artwork. Although recent advances in generative models have enabled visually compelling painting synthesis, most existing methods focus solely on final image generation or patch-based process simulation, lacking explicit stroke structure and failing to produce smooth, realistic shading. In this work, we present a differentiable stroke reconstruction framework that unifies painting, stylized texturing, and smudging to faithfully reproduce the human painting-smudging loop. Given an input image, our framework first optimizes single- and dual-color Bezier strokes through a parallel differentiable paint renderer, followed by a style generation module that synthesizes geometry-conditioned textures across diverse painting styles. We further introduce a differentiable smudge operator to enable natural color blending and shading. Coupled with a coarse-to-fine optimization strategy, our method jointly optimizes stroke geometry, color, and texture under geometric and semantic guidance. Extensive experiments on oil, watercolor, ink, and digital paintings demonstrate that our approach produces realistic and expressive stroke reconstructions, smooth tonal transitions, and richly stylized appearances, offering a unified model for expressive digital painting creation. See our project page for more demos: https://yingjiang96.github.io/DiffPaintWebsite/.

</details>


### [238] [Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection](https://arxiv.org/abs/2511.13195)
*Soyul Lee,Seungmin Baek,Dongbo Min*

Main category: cs.CV

TL;DR: MonoDLGD通过难度感知标签引导去噪，自适应扰动和重建地面真实标签，以提高单目3D对象检测的准确性和鲁棒性，并在KITTI基准测试中达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D对象检测成本低，但由于深度线索的模糊性而本质上是不适定的。现有方法难以处理深度估计不准确以及遮挡、距离和截断等实例级检测难度。

Method: MonoDLGD框架自适应地根据检测不确定性扰动和重建地面真实标签。它对更简单的实例应用更强的扰动，对更难的实例应用更弱的扰动，然后进行重建以提供显式的几何监督。通过联合优化标签重建和3D对象检测，鼓励几何感知表示学习。

Result: 在KITTI基准测试上的广泛实验表明，MonoDLGD在所有难度级别上都实现了最先进的性能。

Conclusion: MonoDLGD通过难度感知标签引导去噪，有效地解决了单目3D对象检测中的深度不确定性和实例级检测难度问题，提高了模型的性能和鲁棒性。

Abstract: Monocular 3D object detection is a cost-effective solution for applications like autonomous driving and robotics, but remains fundamentally ill-posed due to inherently ambiguous depth cues. Recent DETR-based methods attempt to mitigate this through global attention and auxiliary depth prediction, yet they still struggle with inaccurate depth estimates. Moreover, these methods often overlook instance-level detection difficulty, such as occlusion, distance, and truncation, leading to suboptimal detection performance. We propose MonoDLGD, a novel Difficulty-Aware Label-Guided Denoising framework that adaptively perturbs and reconstructs ground-truth labels based on detection uncertainty. Specifically, MonoDLGD applies stronger perturbations to easier instances and weaker ones into harder cases, and then reconstructs them to effectively provide explicit geometric supervision. By jointly optimizing label reconstruction and 3D object detection, MonoDLGD encourages geometry-aware representation learning and improves robustness to varying levels of object complexity. Extensive experiments on the KITTI benchmark demonstrate that MonoDLGD achieves state-of-the-art performance across all difficulty levels.

</details>


### [239] [Self-Supervised Ultrasound Screen Detection](https://arxiv.org/abs/2511.13197)
*Alberto Gomez,Jorge Oliveira,Ramon Casero,Agis Chartsias*

Main category: cs.CV

TL;DR: 从超声仪显示器照片中提取超声图像，以绕过DICOM限制，并允许快速的算法测试。


<details>
  <summary>Details</summary>
Motivation: 为了克服超声图像传输到医院系统的DICOM限制，并为新算法的快速测试和原型设计提供便利。

Method: 提出一个自监督流水线，用于从超声仪显示器照片中提取和校正超声图像。

Result: 在概念验证研究中，校正后的图像在分类心脏视图方面达到了0.79的平衡准确率（与本地DICOM图像相比）。

Conclusion: 所提出的自监督流水线能够从显示器照片中提取出视觉保真度足够的超声图像，从而支持算法的快速测试和开发。

Abstract: Ultrasound (US) machines display images on a built-in monitor, but routine transfer to hospital systems relies on DICOM. We propose a self-supervised pipeline to extract the US image from a photograph of the monitor. This removes the DICOM bottleneck and enables rapid testing and prototyping of new algorithms. In a proof-of-concept study, the rectified images retained enough visual fidelity to classify cardiac views with a balanced accuracy of 0.79 with respect to the native DICOMs.

</details>


### [240] [RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2511.13204)
*Junhee Lee,ChaeBeen Bang,MyoungChul Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: RefineVAD 通过结合运动信息和语义类别来改进弱监督视频异常检测，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测方法将所有异常视为单一类别，忽略了异常的多样性，因此提出一种新的框架来模拟人类的分析方式，通过联合分析运动模式和语义结构来解决这个问题。

Method: 提出一个名为 RefineVAD 的新框架，包含两个核心模块：1. 运动感知时间注意力和再校准 (MoTAR)：估计运动显著性并通过基于移位的注意力和基于 Transformer 的全局模型动态调整时间焦点。 2. 类别导向优化 (CORE)：通过将片段级特征与可学习的类别原型对齐，将软异常类别先验注入到表示空间。

Result: 在 WVAD 基准测试上进行了广泛的实验，结果验证了 RefineVAD 的有效性，并强调了整合语义上下文来指导特征优化以获得与异常相关的模式的重要性。

Conclusion: RefineVAD 通过显式建模运动演变方式和其所属的语义类别，有效地提高了弱监督视频异常检测的性能，证明了整合语义信息进行特征优化的重要性。

Abstract: Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both "how" motion evolves and "what" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.

</details>


### [241] [End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer](https://arxiv.org/abs/2511.13208)
*Yonghui Yu,Jiahang Cai,Xun Wang,Wenwu Yang*

Main category: cs.CV

TL;DR: PAVE-Net是一个全端到端的视频多视角2D人体姿态估计框架，通过姿态感知注意力机制解决了跨帧个体关联问题，并在PoseTrack2017上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频多视角2D人体姿态估计方法依赖于检测、RoI裁剪和NMS等启发式操作，限制了准确性和效率。本文旨在提出一种全端到端的方法，消除这些操作。

Method: 本文提出了PAVE-Net，一个包含空间编码器（用于建模帧内关系）和时空姿态解码器（用于捕捉跨帧全局依赖）的框架。通过姿态感知注意力机制实现跨帧个体关联，并显式建模姿态关键点之间的时空依赖性。

Result: PAVE-Net在PoseTrack2017上比之前的端到端图像方法提高了6.0 mAP，准确性与最先进的两阶段视频方法相当，同时效率更高。

Conclusion: PAVE-Net是首个用于多视角2D人体姿态估计的全端到端方法，能够有效处理复杂的跨帧个体关联问题，并在准确性和效率上均有显著优势。

Abstract: Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet

</details>


### [242] [3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale](https://arxiv.org/abs/2511.13211)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: 3DAlign-DAER是一个新框架，通过动态注意力策略和高效检索策略来对齐文本和3D几何，解决了现有方法在细粒度语义和大规模数据库对齐方面的不足，并在Align3D-2M数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度文本-3D几何对齐和大规模数据库检索方面存在性能瓶颈。

Method: 提出动态注意力策略（DAP），包括分层注意力融合（HAF）和蒙特卡洛树搜索，以学习细粒度注意力权重。引入高效检索策略（ERS）以在大规模嵌入空间中进行高效检索。

Result: 在Align3D-2M（200万文本-3D对）数据集上进行了广泛实验，证明了3DAlign-DAER在各种基准测试中优于现有方法，在准确性和效率方面均有提升。

Conclusion: 3DAlign-DAER在细粒度文本-3D对齐和大规模检索方面取得了显著进展，通过动态注意力策略和高效检索策略克服了现有方法的局限性。

Abstract: Despite recent advancements in 3D-text cross-modal alignment, existing state-of-the-art methods still struggle to align fine-grained textual semantics with detailed geometric structures, and their alignment performance degrades significantly when scaling to large-scale 3D databases. To overcome this limitation, we introduce 3DAlign-DAER, a unified framework designed to align text and 3D geometry via the proposed dynamic attention policy and the efficient retrieval strategy, capturing subtle correspondences for diverse cross-modal retrieval and classification tasks. Specifically, during the training, our proposed dynamic attention policy (DAP) employs the Hierarchical Attention Fusion (HAF) module to represent the alignment as learnable fine-grained token-to-point attentions. To optimize these attentions across different tasks and geometric hierarchies, our DAP further exploits the Monte Carlo tree search to dynamically calibrate HAF attention weights via a hybrid reward signal and further enhances the alignment between textual descriptions and local 3D geometry. During the inference, our 3DAlign-DAER introduces an Efficient Retrieval Strategy (ERS) to leverage efficient hierarchical searching in the large-scale embedding spaces, outperforming traditional methods (e.g., KNN) in accuracy and efficiency. Furthermore, to facilitate text-3D alignment research and train our 3DAlign-DAER, we construct Align3D-2M, a large-scale dataset featuring 2M text-3D pairs, to provide sufficient fine-grained cross-modal annotations. Extensive and comprehensive experiments demonstrate the superior performance of our 3DAlign-DAER on diverse benchmarks. We will release our codes, models, and datasets.

</details>


### [243] [Hybrid-Domain Adaptative Representation Learning for Gaze Estimation](https://arxiv.org/abs/2511.13222)
*Qida Tan,Hongyu Yang,Wenchao Du*

Main category: cs.CV

TL;DR: HARL框架通过多源混合数据集学习鲁棒的注视表征，解决了跨域评估中的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于外观的注视估计方法在跨域评估时，会受到表情、可穿戴设备和图像质量等无关因素的干扰，导致性能下降。

Method: 提出HARL框架，通过无监督域自适应方法对齐高质量近眼图像和低质量面部图像的特征，解耦注视相关表征。设计稀疏图融合模块，利用头部姿态与注视方向之间的几何约束。

Result: 在EyeDiap、MPIIFaceGaze和Gaze360数据集上分别达到5.02°、3.36°和9.26°的准确率，并在跨数据集评估中表现出竞争力。

Conclusion: HARL框架能够学习鲁棒的注视表征，有效缓解了跨域评估中的性能下降问题，并取得了最先进的准确率。

Abstract: Appearance-based gaze estimation, aiming to predict accurate 3D gaze direction from a single facial image, has made promising progress in recent years. However, most methods suffer significant performance degradation in cross-domain evaluation due to interference from gaze-irrelevant factors, such as expressions, wearables, and image quality. To alleviate this problem, we present a novel Hybrid-domain Adaptative Representation Learning (shorted by HARL) framework that exploits multi-source hybrid datasets to learn robust gaze representation. More specifically, we propose to disentangle gaze-relevant representation from low-quality facial images by aligning features extracted from high-quality near-eye images in an unsupervised domain-adaptation manner, which hardly requires any computational or inference costs. Additionally, we analyze the effect of head-pose and design a simple yet efficient sparse graph fusion module to explore the geometric constraint between gaze direction and head-pose, leading to a dense and robust gaze representation. Extensive experiments on EyeDiap, MPIIFaceGaze, and Gaze360 datasets demonstrate that our approach achieves state-of-the-art accuracy of $\textbf{5.02}^{\circ}$ and $\textbf{3.36}^{\circ}$, and $\textbf{9.26}^{\circ}$ respectively, and present competitive performances through cross-dataset evaluation. The code is available at https://github.com/da60266/HARL.

</details>


### [244] [MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI](https://arxiv.org/abs/2511.13232)
*Malek Al Abed,Sebiha Demir,Anne Groteklaes,Elodie Germani,Shahrooz Faghihroohi,Hemmen Sabir,Shadi Albarqouni*

Main category: cs.CV

TL;DR: MRIQT是一个3D条件扩散框架，用于将超低场MRI（uLF-MRI）图像提升至高场（HF）MRI的质量，解决了uLF-MRI信噪比低和诊断质量差的问题。


<details>
  <summary>Details</summary>
Motivation: 便携式超低场MRI（uLF-MRI）虽然能用于新生儿护理，但其信号噪声比低，诊断质量不如高场（HF）MRI，限制了其应用。

Method: MRIQT是一个3D条件扩散框架，结合了用于物理一致性uLF模拟的k空间退化，用于稳定图像到图像生成的v-预测和分类器自由引导，以及用于解剖保真度的信噪比加权3D感知损失。该模型利用基于体注意力的UNet架构，从带噪声的uLF输入中去噪，同时保留结构。

Result: MRIQT在PSNR上比最新的GAN和CNN基线提高了15.3%，并且在30.7%的基线上提高了1.78%。医生评估其85%的输出具有良好的质量，并且病理清晰可见。

Conclusion: MRIQT能够基于扩散实现高保真度的便携式超低场（uLF）MRI增强，用于可靠的新生儿脑评估。

Abstract: Portable ultra-low-field MRI (uLF-MRI, 0.064 T) offers accessible neuroimaging for neonatal care but suffers from low signal-to-noise ratio and poor diagnostic quality compared to high-field (HF) MRI. We propose MRIQT, a 3D conditional diffusion framework for image quality transfer (IQT) from uLF to HF MRI. MRIQT combines realistic K-space degradation for physics-consistent uLF simulation, v-prediction with classifier-free guidance for stable image-to-image generation, and an SNR-weighted 3D perceptual loss for anatomical fidelity. The model denoises from a noised uLF input conditioned on the same scan, leveraging volumetric attention-UNet architecture for structure-preserving translation. Trained on a neonatal cohort with diverse pathologies, MRIQT surpasses recent GAN and CNN baselines in PSNR 15.3% with 1.78% over the state of the art, while physicians rated 85% of its outputs as good quality with clear pathology present. MRIQT enables high-fidelity, diffusion-based enhancement of portable ultra-low-field (uLF) MRI for deliable neonatal brain assessment.

</details>


### [245] [MMD-Thinker: Adaptive Multi-Dimensional Thinking for Multimodal Misinformation Detection](https://arxiv.org/abs/2511.13242)
*Junjie Wu,Guohong Fu*

Main category: cs.CV

TL;DR: MMD-Thinker是一个创新的两阶段框架，通过自适应多维度思考来检测多模态错误信息。该框架通过定制思维模式、指令调优和强化学习策略来增强通用多模态大语言模型的推理能力，并在MMR数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的通用多模态大语言模型在检测多模态错误信息时存在推理能力不足和推理偏差的问题，难以应对低成本、高欺骗性的AIGC时代的多模态错误信息。因此，需要一种能够注入任务特定知识和增强推理能力的检测方法。

Method: MMD-Thinker框架包含两个阶段：1. 开发针对多模态错误信息检测的定制思维模式。2. 采用任务特定的指令调优，将定制思维模式注入通用多模态大语言模型。3. 利用具有混合优势函数的强化学习策略，激励推理能力。此外，构建了包含8K+图像-文本对的多模态错误信息推理（MMR）数据集。

Result: 实验结果表明，MMD-Thinker在同域和跨域基准数据集上均实现了最先进的性能，同时保持了灵活的推理和代币使用。

Conclusion: MMD-Thinker通过自适应多维度思考有效地解决了通用多模态大语言模型在多模态错误信息检测中的局限性，并在推理能力和检测性能方面取得了显著提升。

Abstract: Multimodal misinformation floods on various social media, and continues to evolve in the era of AI-generated content (AIGC). The emerged misinformation with low creation cost and high deception poses significant threats to society. While recent studies leverage general-purpose multimodal large language models (MLLMs) to achieve remarkable results in detection, they encounter two critical limitations: (1) Insufficient reasoning, where general-purpose MLLMs often follow the uniform reasoning paradigm but generate inaccurate explanations and judgments, due to the lack of the task-specific knowledge of multimodal misinformation detection. (2) Reasoning biases, where a single thinking mode make detectors a suboptimal path for judgment, struggling to keep pace with the fast-growing and intricate multimodal misinformation. In this paper, we propose MMD-Thinker, a two-stage framework for multimodal misinformation detection through adaptive multi-dimensional thinking. First, we develop tailor-designed thinking mode for multimodal misinformation detection. Second, we adopt task-specific instruction tuning to inject the tailored thinking mode into general-purpose MLLMs. Third, we further leverage reinforcement learning strategy with a mixed advantage function, which incentivizes the reasoning capabilities in trajectories. Furthermore, we construct the multimodal misinformation reasoning (MMR) dataset, encompasses more than 8K image-text pairs with both reasoning processes and classification labels, to make progress in the relam of multimodal misinformation detection. Experimental results demonstrate that our proposed MMD-Thinker achieves state-of-the-art performance on both in-domain and out-of-domain benchmark datasets, while maintaining flexible inference and token usage. Code will be publicly available at Github.

</details>


### [246] [Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention](https://arxiv.org/abs/2511.13249)
*Yu Wen,Shuyong Gao,Shuping Zhang,Miao Huang,Lili Tao,Han Yang,Haozhe Xing,Lihe Zhang,Boxue Hou*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Referring camouflaged object detection (Ref-COD) aims to identify hidden objects by incorporating reference information such as images and text descriptions. Previous research has transformed reference images with salient objects into one-dimensional prompts, yielding significant results. We explore ways to enhance performance through multi-context fusion of rich salient image features and camouflaged object features. Therefore, we propose RFMNet, which utilizes features from multiple encoding stages of the reference salient images and performs interactive fusion with the camouflage features at the corresponding encoding stages. Given that the features in salient object images contain abundant object-related detail information, performing feature fusion within local areas is more beneficial for detecting camouflaged objects. Therefore, we propose an Overlapped Windows Cross-attention mechanism to enable the model to focus more attention on the local information matching based on reference features. Besides, we propose the Referring Feature Aggregation (RFA) module to decode and segment the camouflaged objects progressively. Extensive experiments on the Ref-COD benchmark demonstrate that our method achieves state-of-the-art performance.

</details>


### [247] [GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models](https://arxiv.org/abs/2511.13259)
*Yushuo Zheng,Jiangyong Ying,Huiyu Duan,Chunyi Li,Zicheng Zhang,Jing Liu,Xiaohong Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: GeoX-Bench是一个包含全景-卫星图像对和问答对的基准，用于评估和提升大型多模态模型（LMM）在跨视角地理定位和姿态估计方面的能力。该基准包含10,859张全景-卫星图像对，覆盖49个国家的128个城市，以及755,976个问答对。现有LMM在地理定位方面表现出色，但在姿态估计方面表现不佳，而指令微调可以显著提高其跨视角地理感知能力。


<details>
  <summary>Details</summary>
Motivation: 目前大型多模态模型（LMM）在跨视角地理定位和姿态估计方面的能力仍未得到探索，尽管这些能力在导航、自动驾驶和户外机器人等领域具有潜在的应用价值。

Method: 提出GeoX-Bench基准，包含10,859张全景-卫星图像对（覆盖128个城市，49个国家）和755,976个问答对，其中42,900个用于基准测试，其余用于增强LMM能力。在GeoX-Bench上评估25个最先进的LMM，并探索指令微调的增强能力。

Result: 评估结果显示，现有LMM在地理定位任务上表现出色，但在更复杂的姿态估计任务上性能显著下降。指令微调LMM在GeoX-Bench的训练数据上可以显著提高跨视角地理感知能力。

Conclusion: GeoX-Bench为评估LMM在跨视角地理定位和姿态估计方面的能力提供了一个全面的基准，并揭示了现有模型的优势和劣势，指明了未来研究方向，同时证明了指令微调对提升LMM地理感知能力的效果。

Abstract: Large multimodal models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks, however their knowledge and abilities in the cross-view geo-localization and pose estimation domains remain unexplored, despite potential benefits for navigation, autonomous driving, outdoor robotics, \textit{etc}. To bridge this gap, we introduce \textbf{GeoX-Bench}, a comprehensive \underline{Bench}mark designed to explore and evaluate the capabilities of LMMs in \underline{cross}-view \underline{Geo}-localization and pose estimation. Specifically, GeoX-Bench contains 10,859 panoramic-satellite image pairs spanning 128 cities in 49 countries, along with corresponding 755,976 question-answering (QA) pairs. Among these, 42,900 QA pairs are designated for benchmarking, while the remaining are intended to enhance the capabilities of LMMs. Based on GeoX-Bench, we evaluate the capabilities of 25 state-of-the-art LMMs on cross-view geo-localization and pose estimation tasks, and further explore the empowered capabilities of instruction-tuning. Our benchmark demonstrate that while current LMMs achieve impressive performance in geo-localization tasks, their effectiveness declines significantly on the more complex pose estimation tasks, highlighting a critical area for future improvement, and instruction-tuning LMMs on the training data of GeoX-Bench can significantly improve the cross-view geo-sense abilities. The GeoX-Bench is available at \textcolor{magenta}{https://github.com/IntMeGroup/GeoX-Bench}.

</details>


### [248] [Building Egocentric Procedural AI Assistant: Methods, Benchmarks, and Challenges](https://arxiv.org/abs/2511.13261)
*Junlong Li,Huaiyuan Xu,Sijie Cheng,Kejun Wu,Kim-Hui Yap,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 该论文提出了一个名为 EgoProceAssist 的概念，旨在利用第一人称视角和视觉语言模型（VLMs）为日常程序性任务提供分步支持。


<details>
  <summary>Details</summary>
Motivation: 为了在第一人称视角下为日常程序性任务提供分步支持，受 VLM 和自我感知研究的推动。

Method: 对三个核心任务进行了分类：自我感知程序性错误检测、自我感知程序性学习和自我感知程序性问答。对现有技术、数据集和评估指标进行了全面审查。通过引入新颖的实验和对代表性 VLM 方法的综合评估，阐述了 EgoProceAssist 与现有 VLM AI 助手之间的差距。

Result: 评估了代表性的 VLM 方法。

Conclusion: 讨论了未来的挑战和研究方向，并提供了一个包含最新研究的公共存储库。

Abstract: Driven by recent advances in vision language models (VLMs) and egocentric perception research, we introduce the concept of an egocentric procedural AI assistant (EgoProceAssist) tailored to step-by-step support daily procedural tasks in a first-person view. In this work, we start by identifying three core tasks: egocentric procedural error detection, egocentric procedural learning, and egocentric procedural question answering. These tasks define the essential functions of EgoProceAssist within a new taxonomy. Specifically, our work encompasses a comprehensive review of current techniques, relevant datasets, and evaluation metrics across these three core areas. To clarify the gap between the proposed EgoProceAssist and existing VLM-based AI assistants, we introduce novel experiments and provide a comprehensive evaluation of representative VLM-based methods. Based on these findings and our technical analysis, we discuss the challenges ahead and suggest future research directions. Furthermore, an exhaustive list of this study is publicly available in an active repository that continuously collects the latest work: https://github.com/z1oong/Building-Egocentric-Procedural-AI-Assistant

</details>


### [249] [Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation](https://arxiv.org/abs/2511.13269)
*Lingfeng Zhang,Yuchen Zhang,Hongsheng Li,Haoxiang Fu,Yingbo Tang,Hangjun Ye,Long Chen,Xiaojun Liang,Xiaoshuai Hao,Wenbo Ding*

Main category: cs.CV

TL;DR: 本论文提出SpatialSky-Bench基准和Sky-VLM模型，以评估和提升视觉语言模型（VLM）在无人机（UAV）导航中的空间智能能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在UAV导航中的空间智能能力未被充分探索，可能影响其在动态环境中的导航和理解能力。

Method: 提出SpatialSky-Bench基准，包含环境感知和场景理解两类13个子任务（如边界框、颜色、距离、高度、着陆安全分析等）。构建了包含1M个样本的SpatialSky-Dataset数据集。基于该数据集，开发了专门用于UAV空间推理的Sky-VLM模型。

Result: 对主流VLM在SpatialSky-Bench基准上的评估显示，它们在复杂的UAV导航场景中表现不佳。Sky-VLM在所有基准任务上均达到最先进的性能。

Conclusion: SpatialSky-Bench和Sky-VLM的提出填补了UAV领域VLM空间智能评估和应用的空白，为开发适用于UAV场景的VLM铺平了道路。

Abstract: Vision-Language Models (VLMs), leveraging their powerful visual perception and reasoning capabilities, have been widely applied in Unmanned Aerial Vehicle (UAV) tasks. However, the spatial intelligence capabilities of existing VLMs in UAV scenarios remain largely unexplored, raising concerns about their effectiveness in navigating and interpreting dynamic environments. To bridge this gap, we introduce SpatialSky-Bench, a comprehensive benchmark specifically designed to evaluate the spatial intelligence capabilities of VLMs in UAV navigation. Our benchmark comprises two categories-Environmental Perception and Scene Understanding-divided into 13 subcategories, including bounding boxes, color, distance, height, and landing safety analysis, among others. Extensive evaluations of various mainstream open-source and closed-source VLMs reveal unsatisfactory performance in complex UAV navigation scenarios, highlighting significant gaps in their spatial capabilities. To address this challenge, we developed the SpatialSky-Dataset, a comprehensive dataset containing 1M samples with diverse annotations across various scenarios. Leveraging this dataset, we introduce Sky-VLM, a specialized VLM designed for UAV spatial reasoning across multiple granularities and contexts. Extensive experimental results demonstrate that Sky-VLM achieves state-of-the-art performance across all benchmark tasks, paving the way for the development of VLMs suitable for UAV scenarios. The source code is available at https://github.com/linglingxiansen/SpatialSKy.

</details>


### [250] [Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models](https://arxiv.org/abs/2511.13276)
*Noam Tsfaty,Avishai Weizman,Liav Cohen,Moshe Tshuva,Yehudit Aperstein*

Main category: cs.CV

TL;DR: We propose a dual-backbone framework using convolutional and transformer representations with top-k pooling for detecting rare and diverse anomalies in surveillance videos, achieving 90.7% AUC on the UCF-Crime dataset using only video-level supervision.


<details>
  <summary>Details</summary>
Motivation: The challenge of detecting rare and diverse anomalies in surveillance videos using only video-level supervision.

Method: A dual-backbone framework that combines convolutional and transformer representations through top-k pooling.

Result: Achieved 90.7% AUC on the UCF-Crime dataset.

Conclusion: The proposed dual-backbone framework is effective for detecting rare and diverse anomalies in surveillance videos with video-level supervision.

Abstract: We address the challenge of detecting rare and diverse anomalies in surveillance videos using only video-level supervision. Our dual-backbone framework combines convolutional and transformer representations through top-k pooling, achieving 90.7% area under the curve (AUC) on the UCF-Crime dataset.

</details>


### [251] [SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting](https://arxiv.org/abs/2511.13278)
*Zihan Li,Tengfei Wang,Wentian Gan,Hao Zhan,Xin Wang,Zongqian Zhan*

Main category: cs.CV

TL;DR: SF-Recon可以直接从多视图图像中重建轻量级建筑模型，无需后期网格简化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在重建轻量级建筑表面模型时存在繁琐、质量敏感等问题，本文提出SF-Recon直接重建轻量级建筑表面。

Method: 首先训练3D高斯泼溅场获得视图一致表示，然后通过法线-梯度引导的高斯优化提取建筑结构，并进行多视图边缘一致性剪枝，最后通过多视图深度约束Delaunay三角化生成轻量级、结构忠实的建筑网格。

Result: SF-Recon可以直接从多视图影像中重建轻量级建筑模型，面数和顶点数大大减少，同时保持计算效率。

Conclusion: SF-Recon是一种直接从多视图图像重建轻量级建筑表面的方法，无需后期网格简化，能够生成面数和顶点数更少但结构忠实的建筑网格。

Abstract: Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/

</details>


### [252] [Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space](https://arxiv.org/abs/2511.13282)
*Kaiwen Wang,Kaili Zheng,Yiming Shi,Chenyi Guo,Ji Wu*

Main category: cs.CV

TL;DR: 本文提出了一种名为DTO（Depth-conditioned Translation Optimization）的新方法，用于解决单张图像中多人网格恢复的难题。该方法通过联合优化场景中所有个体的相机空间平移，利用人体测量学先验和单目深度估计器提供的深度线索，在最大后验（MAP）框架下求解场景一致的物体放置。基于DTO，作者构建了一个名为DTO-Humans的大规模数据集。此外，还提出了一种名为Metric-Aware HMR的端到端网络，能够直接以度量尺度估计人体网格和相机参数，并在相对深度推理和人体网格恢复方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有技术在生成野外多人网格伪地面真实（pGT）时，通常将每个人单独处理，缺乏场景级的一致性，导致同一图像中的个体在深度和尺度上存在冲突。

Method: DTO（Depth-conditioned Translation Optimization）是一种基于优化的新方法，通过利用人体测量学先验和单目深度估计器提供的深度线索，在最大后验（MAP）框架下，联合优化场景中所有个体的相机空间平移，以实现场景一致的物体放置。Metric-Aware HMR是一种端到端网络，包含一个相机分支和一个新颖的相对度量损失，能够直接以度量尺度估计人体网格和相机参数。

Result: 作者基于DTO方法构建了一个名为DTO-Humans的大规模数据集，包含56万张高质量、场景一致的多人图像。在消融实验中，Metric-Aware HMR在相对深度推理和人体网格恢复方面取得了最先进的性能。

Conclusion: 所提出的DTO方法和Metric-Aware HMR网络能够有效地解决单张图像中多人网格恢复的挑战，生成场景一致且度量精确的结果，并在相关任务上达到了最先进的水平。

Abstract: Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a novel relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code and data will be released publicly.

</details>


### [253] [TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing](https://arxiv.org/abs/2511.13283)
*Jongha Kim,Minseong Bae,Sanghyeok Lee,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: TabFlash提出了一种高效且强大的MLLM，通过渐进式问题条件、剪枝策略和标记关注来优化表格理解，取得了最先进的性能，同时减少了计算和内存资源。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM在处理表格图像时存在问题，因为它们无法有效关注问题相关信息并处理冗余背景，导致视觉表示信息不足且冗余。本研究旨在生成信息丰富且紧凑的视觉特征，以改进表格理解。

Method: 提出渐进式问题条件（progressive question conditioning），将问题逐渐注入Vision Transformer层；提出剪枝策略（pruning strategy），移除背景标记以减少冗余；提出标记关注（token focusing）训练策略，使模型将关键信息集中在保留的标记上。结合这些方法，提出了TabFlash模型。

Result: TabFlash在表格理解任务上取得了最先进的性能，优于现有的开源和闭源MLLM。与第二优的MLLM相比，TabFlash的计算量（FLOPs）减少了27%，内存使用量减少了30%。

Conclusion: TabFlash通过结合渐进式问题条件、剪枝策略和标记关注，能够生成信息丰富且紧凑的视觉特征，从而在表格理解任务上实现了高效且强大的性能，并显著降低了计算和内存资源消耗。

Abstract: Table images present unique challenges for effective and efficient understanding due to the need for question-specific focus and the presence of redundant background regions. Existing Multimodal Large Language Model (MLLM) approaches often overlook these characteristics, resulting in uninformative and redundant visual representations. To address these issues, we aim to generate visual features that are both informative and compact to improve table understanding. We first propose progressive question conditioning, which injects the question into Vision Transformer layers with gradually increasing frequency, considering each layer's capacity to handle additional information, to generate question-aware visual features. To reduce redundancy, we introduce a pruning strategy that discards background tokens, thereby improving efficiency. To mitigate information loss from pruning, we further propose token focusing, a training strategy that encourages the model to concentrate essential information in the retained tokens. By combining these approaches, we present TabFlash, an efficient and effective MLLM for table understanding. TabFlash achieves state-of-the-art performance, outperforming both open-source and proprietary MLLMs, while requiring 27% less FLOPs and 30% less memory usage compared to the second-best MLLM.

</details>


### [254] [SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design](https://arxiv.org/abs/2511.13285)
*Yunjie Yu,Jingchen Wu,Junchen Zhu,Chunze Lin,Guibin Chen*

Main category: cs.CV

TL;DR: SkyReels-Text是一个新颖的、字体可控的精确海报文本编辑框架，能够同时编辑具有不同字体样式的多个文本区域，同时保留非编辑区域的视觉外观。


<details>
  <summary>Details</summary>
Motivation: 现代图像编辑模型在细粒度的、字体感知的文本操纵方面仍然不足，限制了它们在海报编辑等专业设计工作流程中的应用。

Method: SkyReels-Text框架，用户只需提供所需字体对应的裁剪字形图块，即可实现多文本区域的同时编辑，且在推理过程中无需字体标签或微调。

Result: 在多个数据集（包括手写文本基准）上的大量实验表明，SkyReels-Text在文本保真度和视觉真实度方面均达到了最先进的性能，并提供了对字体系列和样式细微差别的空前控制。

Conclusion: 该工作弥合了通用图像编辑与专业级字体设计之间的差距。

Abstract: Artistic design such as poster design often demands rapid yet precise modification of textual content while preserving visual harmony and typographic intent, especially across diverse font styles. Although modern image editing models have grown increasingly powerful, they still fall short in fine-grained, font-aware text manipulation, limiting their utility in professional design workflows such as poster editing. To address this issue, we present SkyReels-Text, a novel font-controllable framework for precise poster text editing. Our method enables simultaneous editing of multiple text regions, each rendered in distinct typographic styles, while preserving the visual appearance of non-edited regions. Notably, our model requires neither font labels nor fine-tuning during inference: users can simply provide cropped glyph patches corresponding to their desired typography, even if the font is not included in any standard library. Extensive experiments on multiple datasets, including handwrittent text benchmarks, SkyReels-Text achieves state-of-the-art performance in both text fidelity and visual realism, offering unprecedented control over font families, and stylistic nuances. This work bridges the gap between general-purpose image editing and professional-grade typographic design.

</details>


### [255] [CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving](https://arxiv.org/abs/2511.13297)
*Enhui Ma,Lijun Zhou,Tao Tang,Jiahuan Zhang,Junpeng Jiang,Zhan Zhang,Dong Han,Kun Zhan,Xueyang Zhang,XianPeng Lang,Haiyang Sun,Xia Zhou,Di Lin,Kaicheng Yu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CorrectAD的自动驾驶系统，利用基于扩散的世界模型和3D布局来解决长尾问题，通过PM-Agent模拟产品经理收集数据，并使用DriveSora生成高保真度、时空一致的视频。该系统可以改进任何端到端规划器，并在两个数据集上显著减少碰撞率。


<details>
  <summary>Details</summary>
Motivation: 数据驱动的自动驾驶方法在处理罕见但关键的失败案例（长尾问题）时鲁棒性不足。

Method: 提出PM-Agent来识别数据需求，并使用DriveSora生成与3D布局匹配的高保真度、时空一致的视频。将这些组件集成到名为CorrectAD的自校正代理系统中，以改进端到端规划器。

Result: CorrectAD能够纠正62.5%（nuScenes）和49.8%（内部数据集）的失败案例，并将碰撞率分别降低39%和27%。

Conclusion: 所提出的基于扩散的世界模型和3D布局的自校正系统CorrectAD能够有效地解决自动驾驶中的长尾问题，并提高端到端规划器的安全性。

Abstract: End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.

</details>


### [256] [DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving](https://arxiv.org/abs/2511.13309)
*Kaiwen Cai,Xinze Liu,Xia Zhou,Hengtong Hu,Jie Xiang,Luyao Zhang,Xueyang Zhang,Kun Zhan,Yifei Zhan,Xianpeng Lang*

Main category: cs.CV

TL;DR: DriveLiDAR4D是一个新颖的激光雷达点云生成流程，它使用多模态条件和新颖的序列噪声预测模型LiDAR4DNet，能够生成时间一致、前景物体可控、背景真实的激光雷达场景。


<details>
  <summary>Details</summary>
Motivation: 现有的3D激光雷达点云生成方法在序列生成、前景物体精确定位和背景真实感方面存在不足，限制了其实际应用。

Method: 提出了一种名为DriveLiDAR4D的新型激光雷达生成流程，该流程包含多模态条件和名为LiDAR4DNet的新型序列噪声预测模型。

Result: 在nuScenes和KITTI数据集上进行了评估，在nuScenes数据集上取得了743.13的FRD得分和16.96的FVD得分，优于当前SOTA方法UniScene，FRD和FVD分别提升了37.2%和24.1%。

Conclusion: DriveLiDAR4D是第一个以端到端方式解决激光雷达场景序列生成和全场景操控问题的研究，并在多个数据集上取得了SOTA的性能。

Abstract: The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.

</details>


### [257] [Computer Vision based group activity detection and action spotting](https://arxiv.org/abs/2511.13315)
*Narthana Sivalingam,Santhirarajah Sivasthigan,Thamayanthi Mahendranathan,G. M. R. I. Godaliyadda,M. P. B. Ekanayake,H. M. V. R. Herath*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度学习和图神经网络的计算机视觉框架，用于在多人场景中进行群体活动识别和动作检测。


<details>
  <summary>Details</summary>
Motivation: 识别多人场景中的群体活动面临着复杂的相互作用、遮挡和外观随时间变化的挑战。

Method: 该系统首先使用 Mask R-CNN 进行演员定位，然后利用多种骨干网络（如 Inception V3、MobileNet、VGG16）提取特征图。通过 RoIAlign 和掩模信息融合来获得每个演员的精炼掩模特征表示。接着，构建演员关系图来编码个体间的相似性和位置关系，并使用图卷积网络在这些图上进行推理，以预测个体动作和群体活动。

Result: 在 Collective Activity 数据集上的实验表明，该方法在拥挤和非拥挤场景下均能提高识别性能。

Conclusion: 将分割、特征提取和关系图推理相结合，为复杂的视频理解任务提供了潜力。

Abstract: Group activity detection in multi-person scenes is challenging due to complex human interactions, occlusions, and variations in appearance over time. This work presents a computer vision based framework for group activity recognition and action spotting using a combination of deep learning models and graph based relational reasoning. The system first applies Mask R-CNN to obtain accurate actor localization through bounding boxes and instance masks. Multiple backbone networks, including Inception V3, MobileNet, and VGG16, are used to extract feature maps, and RoIAlign is applied to preserve spatial alignment when generating actor specific features. The mask information is then fused with the feature maps to obtain refined masked feature representations for each actor. To model interactions between individuals, we construct Actor Relation Graphs that encode appearance similarity and positional relations using methods such as normalized cross correlation, sum of absolute differences, and dot product. Graph Convolutional Networks operate on these graphs to reason about relationships and predict both individual actions and group level activities. Experiments on the Collective Activity dataset demonstrate that the combination of mask based feature refinement, robust similarity search, and graph neural network reasoning leads to improved recognition performance across both crowded and non crowded scenarios. This approach highlights the potential of integrating segmentation, feature extraction, and relational graph reasoning for complex video understanding tasks.

</details>


### [258] [YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection](https://arxiv.org/abs/2511.13344)
*Ori Meiraz,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出了一种新颖的混合专家模型用于目标检测，通过在多个 YOLOv9-T 专家之间进行自适应路由，实现了动态特征专化，从而在 mAP 和 AR 方面优于单一 YOLOv9-T 模型。


<details>
  <summary>Details</summary>
Motivation: 目标检测任务的性能提升需求。

Method: 提出了一种新颖的混合专家（MoE）框架，其中包含自适应路由机制，该机制能够动态地在多个 YOLOv9-T 专家之间进行选择和分配。

Result: 与单一 YOLOv9-T 模型相比，该混合专家框架在 mAP 和 AR 指标上都取得了更高的性能。

Conclusion: 所提出的混合专家框架通过自适应路由实现了动态特征专化，有效提升了目标检测的性能。

Abstract: This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.

</details>


### [259] [Semi-Supervised Multi-Task Learning for Interpretable Quality As- sessment of Fundus Images](https://arxiv.org/abs/2511.13353)
*Lucas Gabriel Telesco,Danila Nejamkin,Estefanía Mata,Francisco Filizzola,Kevin Wignall,Lucía Franco Troilo,María de los Angeles Cenoz,Melissa Thompson,Mercedes Leguía,Ignacio Larrabide,José Ignacio Orlando*

Main category: cs.CV

TL;DR: 本研究提出了一种混合半监督学习方法，用于视网膜图像质量评估（RIQA），旨在提供可解释的图像质量反馈，指导图像重新拍摄，而无需昂贵的详细标注。


<details>
  <summary>Details</summary>
Motivation: 现有的RIQA工具主要评估整体图像质量，缺乏对具体成像缺陷的识别能力，这主要是由于详细标注成本高昂。本研究旨在弥补这一不足，提供更具可解释性的RIQA模型。

Method: 提出了一种混合半监督学习方法，在多任务框架下结合了整体图像质量的手动标签和图像质量细节的伪标签。通过教师模型生成伪标签，然后用于微调预训练模型。使用ResNet-18作为骨干网络。

Result: 在EyeQ数据集上，F1分数从0.863提高到0.875；在DeepDRiD数据集上，F1分数从0.763提高到0.778，性能与现有方法相当或更优。多任务模型在大多数细节预测任务上表现与教师模型相当（p > 0.05）。在新标注的EyeQ子集上，模型表现与专家水平相当。

Conclusion: 所提出的半监督方法不仅提高了整体图像质量评估的性能，还能提供关于成像条件（如光照、清晰度、对比度）的可解释反馈，从而无需额外的标注成本即可增强模型的可解释性，并提供临床上可操作的输出以指导图像重新拍摄。

Abstract: Retinal image quality assessment (RIQA) supports computer-aided diagnosis of eye diseases. However, most tools classify only overall image quality, without indicating acquisition defects to guide recapture. This gap is mainly due to the high cost of detailed annotations. In this paper, we aim to mitigate this limitation by introducing a hybrid semi-supervised learning approach that combines manual labels for overall quality with pseudo-labels of quality details within a multi-task framework. Our objective is to obtain more interpretable RIQA models without requiring extensive manual labeling. Pseudo-labels are generated by a Teacher model trained on a small dataset and then used to fine-tune a pre-trained model in a multi-task setting. Using a ResNet-18 backbone, we show that these weak annotations improve quality assessment over single-task baselines (F1: 0.875 vs. 0.863 on EyeQ, and 0.778 vs. 0.763 on DeepDRiD), matching or surpassing existing methods. The multi-task model achieved performance statistically comparable to the Teacher for most detail prediction tasks (p > 0.05). In a newly annotated EyeQ subset released with this paper, our model performed similarly to experts, suggesting that pseudo-label noise aligns with expert variability. Our main finding is that the proposed semi-supervised approach not only improves overall quality assessment but also provides interpretable feedback on capture conditions (illumination, clarity, contrast). This enhances interpretability at no extra manual labeling cost and offers clinically actionable outputs to guide image recapture.

</details>


### [260] [Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model](https://arxiv.org/abs/2511.13387)
*Fei Kong*

Main category: cs.CV

TL;DR: 本论文提出了一种名为gDDCM的通用扩散模型压缩方法，该方法扩展了现有的DDCM，可以应用于包括DDPM、Score-Based Models、Consistency Models和Rectified Flow在内的多种主流扩散模型，并在CIFAR-10和LSUN Bedroom数据集上取得了改进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有DDCM方法仅限于DDPM，限制了其应用范围。

Method: 提出通用扩散模型压缩（gDDCM），将DDCM扩展到包括DDPM、Score-Based Models、Consistency Models和Rectified Flow在内的多种主流扩散模型及其变体。

Result: 在CIFAR-10和LSUN Bedroom数据集上的实验结果表明，gDDCM成功地将DDCM推广到上述模型，并取得了性能提升。

Conclusion: gDDCM能够有效地将DDCM扩展到多种主流扩散模型，并在图像压缩任务上实现性能的提升。

Abstract: Recently, the Denoising Diffusion Codebook Models (DDCM) was proposed. DDCM leverages the Denoising Diffusion Probabilistic Model (DDPM) and replaces the random noise in the backward process with noise sampled from specific sets according to a predefined rule, thereby enabling image compression. However, DDCM cannot be applied to methods other than DDPM. In this paper, we propose the generalized Denoising Diffusion Compression Model (gDDCM), which extends DDCM to mainstream diffusion models and their variants, including DDPM, Score-Based Models, Consistency Models, and Rectified Flow. We evaluate our method on CIFAR-10 and LSUN Bedroom datasets. Experimental results demonstrate that our approach successfully generalizes DDCM to the aforementioned models and achieves improved performance.

</details>


### [261] [Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)](https://arxiv.org/abs/2511.13397)
*Nikos Theodoridis,Tim Brophy,Reenu Mohandas,Ganesh Sistu,Fiachra Collins,Anthony Scanlan,Ciaran Eising*

Main category: cs.CV

TL;DR: 该研究提出了一个名为DTPQA的新基准，用于评估视觉语言模型（VLMs）在自动驾驶场景中的感知能力，特别关注远距离物体的识别和理解。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要VLMs具备鲁棒的感知能力，尤其是在处理复杂交通场景和识别远距离物体方面。因此，有必要在隔离其他技能（如推理或世界知识）的情况下，单独评估VLMs的感知能力。

Method: DTPQA基准包含两部分：一个使用模拟器创建的合成基准（DTP-Synthetic）和一个基于真实交通场景图像构建的真实世界基准（DTP-Real）。该基准还包含物体距离的标注，允许分析模型性能随距离的退化情况。研究提供了数据集和用于生成数据的Python脚本。

Result: DTPQA基准包含图像、问题、基本答案和物体距离标注，能够评估VLMs在不同距离下的感知能力，并分析其性能随距离的变化。

Conclusion: DTPQA基准为评估和改进VLMs在自动驾驶感知任务中的表现提供了一个有价值的工具，尤其是在远距离物体识别方面。

Abstract: The remarkable progress of Vision-Language Models (VLMs) on a variety of tasks has raised interest in their application to automated driving. However, for these models to be trusted in such a safety-critical domain, they must first possess robust perception capabilities, i.e., they must be capable of understanding a traffic scene, which can often be highly complex, with many things happening simultaneously. Moreover, since critical objects and agents in traffic scenes are often at long distances, we require systems with not only strong perception capabilities at close distances (up to 20 meters), but also at long (30+ meters) range. Therefore, it is important to evaluate the perception capabilities of these models in isolation from other skills like reasoning or advanced world knowledge. Distance-Annotated Traffic Perception Question Answering (DTPQA) is a Visual Question Answering (VQA) benchmark designed specifically for this purpose: it can be used to evaluate the perception systems of VLMs in traffic scenarios using trivial yet crucial questions relevant to driving decisions. It consists of two parts: a synthetic benchmark (DTP-Synthetic) created using a simulator, and a real-world benchmark (DTP-Real) built on top of existing images of real traffic scenes. Additionally, DTPQA includes distance annotations, i.e., how far the object in question is from the camera. More specifically, each DTPQA sample consists of (at least): (a) an image, (b) a question, (c) the ground truth answer, and (d) the distance of the object in question, enabling analysis of how VLM performance degrades with increasing object distance. In this article, we provide the dataset itself along with the Python scripts used to create it, which can be used to generate additional data of the same kind.

</details>


### [262] [TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing](https://arxiv.org/abs/2511.13399)
*Yuchen Bao,Yiting Wang,Wenjian Huang,Haowei Wang,Shen Chen,Taiping Yao,Shouhong Ding,Jianguo Zhang*

Main category: cs.CV

TL;DR: TripleFDS是一个用于场景文本编辑（STE）的新框架，通过解耦文本风格、内容和背景三个属性，实现了更精细的控制和视觉一致性。它引入了SCB Synthesis数据集和“SCB Group”概念，并采用对比学习和正交性约束来提升模型性能。实验证明，TripleFDS在图像保真度和文本准确性方面达到了最先进水平，并支持风格替换和背景迁移等新操作。


<details>
  <summary>Details</summary>
Motivation: 现有场景文本编辑方法在解耦可编辑属性方面存在不足，往往只能处理单一属性（如文本内容），导致可控性和视觉一致性受限。

Method: 提出TripleFDS框架，它包含解耦的模块化属性，并利用SCB Synthesis数据集。SCB Synthesis数据集通过“SCB Group”将三个属性（文本风格、内容、背景）组合，用于训练。TripleFDS首先进行三元特征解耦，利用组间对比正则化确保语义准确性，并通过样本内多特征正交性减少冗余。在合成阶段，通过特征重映射防止重建过程中的“捷径”现象和缓解特征泄漏。

Result: 在主流STE基准测试中，TripleFDS在125,000个SCB Group上训练后，实现了最先进的图像保真度（SSIM为44.54）和文本准确性（ACC为93.58%）。

Conclusion: TripleFDS框架在场景文本编辑方面取得了最先进的性能，显著提高了图像保真度和文本准确性，并且通过其解耦的属性编辑能力，支持了风格替换和背景迁移等新的编辑功能。

Abstract: Scene Text Editing (STE) aims to naturally modify text in images while preserving visual consistency, the decisive factors of which can be divided into three parts, i.e., text style, text content, and background. Previous methods have struggled with incomplete disentanglement of editable attributes, typically addressing only one aspect - such as editing text content - thus limiting controllability and visual consistency. To overcome these limitations, we propose TripleFDS, a novel framework for STE with disentangled modular attributes, and an accompanying dataset called SCB Synthesis. SCB Synthesis provides robust training data for triple feature disentanglement by utilizing the "SCB Group", a novel construct that combines three attributes per image to generate diverse, disentangled training groups. Leveraging this construct as a basic training unit, TripleFDS first disentangles triple features, ensuring semantic accuracy through inter-group contrastive regularization and reducing redundancy through intra-sample multi-feature orthogonality. In the synthesis phase, TripleFDS performs feature remapping to prevent "shortcut" phenomena during reconstruction and mitigate potential feature leakage. Trained on 125,000 SCB Groups, TripleFDS achieves state-of-the-art image fidelity (SSIM of 44.54) and text accuracy (ACC of 93.58%) on the mainstream STE benchmarks. Besides superior performance, the more flexible editing of TripleFDS supports new operations such as style replacement and background transfer. Code: https://github.com/yusenbao01/TripleFDS

</details>


### [263] [What Color Is It? A Text-Interference Multimodal Hallucination Benchmark](https://arxiv.org/abs/2511.13400)
*Jinkun Zhao,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: MLMs容易受到视觉感知信息干扰，尤其是在颜色感知方面，这会增加幻觉的风险。为了验证这一假设，我们引入了“What Color Is It”数据集，这是一个使用简单方法触发MLM单模态视觉幻觉的新型基准。在此数据集的基础上，我们进一步研究了MLM视觉模态中幻觉的根本原因，并提出了增强其鲁棒性的潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型（MLMs）在视觉感知方面存在信息干扰问题，尤其是在颜色感知方面，这增加了模型产生幻觉的风险。

Method: 创建了一个名为“What Color Is It”的新数据集，用于触发和研究MLM在颜色感知方面的单模态视觉幻觉。

Result: 通过“What Color Is It”数据集，研究了MLM视觉模态中产生幻觉的原因。

Conclusion: 提出了增强MLM视觉模态鲁棒性的潜在解决方案。

Abstract: With the rapid advancement of Large Models, numerous text-and-vision-fused Multimodal Large Models (MLMs) have emerged. However, these MLMs remain susceptible to informational interference in visual perception, particularly in color perception, which introduces an additional risk of hallucination. To validate this hypothesis, we introduce the "What Color Is It" dataset, a novel benchmark constructed using a simple method to trigger single-modality visual hallucination in MLMs. Based on this dataset, we further investigate the underlying causes of hallucination in the visual modality of MLMs and propose potential solutions to enhance their robustness.

</details>


### [264] [Delineate Anything Flow: Fast, Country-Level Field Boundary Detection from Any Source](https://arxiv.org/abs/2511.13417)
*Mykola Lavreniuk,Nataliia Kussul,Andrii Shelestov,Yevhenii Salii,Volodymyr Kuzin,Sergii Skakun,Zoltan Szantoi*

Main category: cs.CV

TL;DR: DelAnyFlow是一种分辨率无关的方法，通过结合DelAny实例分割模型和结构化后处理，能够大规模、高精度地绘制农田边界，显著优于现有方法，并已成功应用于乌克兰。


<details>
  <summary>Details</summary>
Motivation: 现有的农田边界绘制方法在完整性、精度和可扩展性方面存在不足，需要一种更有效的方法来支持土地管理和作物监测。

Method: 提出DelAnyFlow方法，该方法结合了基于YOLOv11骨干的DelAny实例分割模型（在FBIS 22M数据集上训练）以及结构化后处理、合并和矢量化流程，以生成拓扑一致的矢量边界。FBIS 22M是最大的同类数据集，包含大量多分辨率图像和已验证的田野实例。

Result: DelAny模型实现了最先进的精度，mAP比SAM2高100%以上，推理速度快400倍。DelAnyFlow成功生成了乌克兰（603,000平方公里）的完整农田边界层，耗时不到六小时。与Sinergise Solutions和NASA Harvest的运营产品相比，DelAnyFlow的边界完整性显著提高，特别是在小农和碎片化系统中。在乌克兰，DelAnyFlow在5米和2.5米分辨率下分别绘制了3.75M和5.15M个田野，而Sinergise Solutions和NASA Harvest分别检测到2.66M和1.69M个田野。

Conclusion: DelAnyFlow提供了一种可扩展、成本效益高的方法，用于在缺乏数字地籍数据的地区进行农田边界绘制，解决了现有方法的局限性。

Abstract: Accurate delineation of agricultural field boundaries from satellite imagery is essential for land management and crop monitoring, yet existing methods often produce incomplete boundaries, merge adjacent fields, and struggle to scale. We present the Delineate Anything Flow (DelAnyFlow) methodology, a resolution-agnostic approach for large-scale field boundary mapping. DelAnyFlow combines the DelAny instance segmentation model, based on a YOLOv11 backbone and trained on the large-scale Field Boundary Instance Segmentation-22M (FBIS 22M) dataset, with a structured post-processing, merging, and vectorization sequence to generate topologically consistent vector boundaries. FBIS 22M, the largest dataset of its kind, contains 672,909 multi-resolution image patches (0.25-10m) and 22.9million validated field instances. The DelAny model delivers state-of-the-art accuracy with over 100% higher mAP and 400x faster inference than SAM2. DelAny demonstrates strong zero-shot generalization and supports national-scale applications: using Sentinel 2 data for 2024, DelAnyFlow generated a complete field boundary layer for Ukraine (603,000km2) in under six hours on a single workstation. DelAnyFlow outputs significantly improve boundary completeness relative to operational products from Sinergise Solutions and NASA Harvest, particularly in smallholder and fragmented systems (0.25-1ha). For Ukraine, DelAnyFlow delineated 3.75M fields at 5m and 5.15M at 2.5m, compared to 2.66M detected by Sinergise Solutions and 1.69M by NASA Harvest. This work delivers a scalable, cost-effective methodology for field delineation in regions lacking digital cadastral data. A project landing page with links to model weights, code, national-scale vector outputs, and dataset is available at https://lavreniuk.github.io/Delineate-Anything/.

</details>


### [265] [VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task](https://arxiv.org/abs/2511.13420)
*Xingming Long,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: 大多数关于大型视觉-语言模型（LVLM）幻觉的研究都集中在不允许图像中任何缺失的输出的事实描述任务上。然而，对于故事写作等自愿想象任务中的幻觉，人们很少关注，在这些任务中，模型应该生成图像之外的新内容。在这些任务中，简单地将这种想象出的新内容视为幻觉是不恰当的。为了解决这一局限性，我们提出了自愿想象对象存在评估（VOPE）——一种通过存在评估来评估自愿想象任务中 LVLM 幻觉的新颖方法。具体来说，VOPE 通过重新检查问题来评估 LVLM 如何解释其自身响应中想象对象的存在。然后，模型解释与图像中对象存在之间的一致性被用来确定模型在生成响应时是否产生幻觉。我们将 VOPE 应用于几种主流的 LVLM 和幻觉缓解方法，揭示了两个关键发现：(1) 大多数 LVLM 在自愿想象期间会产生大量幻觉，并且它们在想象对象上的存在评估表现明显较差；(2) 现有的幻觉缓解方法在自愿想象任务中的效果有限，这使得该领域成为未来研究的重要方向。


<details>
  <summary>Details</summary>
Motivation: 大多数关于大型视觉-语言模型（LVLM）幻觉的研究都集中在不允许图像中任何缺失的输出的事实描述任务上。然而，对于故事写作等自愿想象任务中的幻觉，人们很少关注，在这些任务中，模型应该生成图像之外的新内容。在这些任务中，简单地将这种想象出的新内容视为幻觉是不恰当的。因此，需要一种新的方法来评估LVLM在自愿想象任务中的幻觉。

Method: 提出了一种名为自愿想象对象存在评估（VOPE）的新颖方法，该方法通过存在评估来评估自愿想象任务中的 LVLM 幻觉。VOPE 通过重新检查问题来评估 LVLM 如何解释其自身响应中想象对象的存在。然后，模型解释与图像中对象存在之间的一致性被用来确定模型在生成响应时是否产生幻觉。

Result: 将 VOPE 应用于几种主流的 LVLM 和幻觉缓解方法，揭示了两个关键发现：(1) 大多数 LVLM 在自愿想象期间会产生大量幻觉，并且它们在想象对象上的存在评估表现明显较差；(2) 现有的幻觉缓解方法在自愿想象任务中的效果有限。

Conclusion: 大多数 LVLM 在自愿想象期间会产生大量幻觉，并且它们在想象对象上的存在评估表现明显较差。现有的幻觉缓解方法在自愿想象任务中的效果有限，这使得该领域成为未来研究的重要方向。

Abstract: Most research on hallucinations in Large Vision-Language Models (LVLMs) focuses on factual description tasks that prohibit any output absent from the image. However, little attention has been paid to hallucinations in voluntary imagination tasks, e.g., story writing, where the models are expected to generate novel content beyond the given image. In these tasks, it is inappropriate to simply regard such imagined novel content as hallucinations. To address this limitation, we introduce Voluntary-imagined Object Presence Evaluation (VOPE)-a novel method to assess LVLMs' hallucinations in voluntary imagination tasks via presence evaluation. Specifically, VOPE poses recheck-based questions to evaluate how an LVLM interprets the presence of the imagined objects in its own response. The consistency between the model's interpretation and the object's presence in the image is then used to determine whether the model hallucinates when generating the response. We apply VOPE to several mainstream LVLMs and hallucination mitigation methods, revealing two key findings: (1) most LVLMs hallucinate heavily during voluntary imagination, and their performance in presence evaluation is notably poor on imagined objects; (2) existing hallucination mitigation methods show limited effect in voluntary imagination tasks, making this an important direction for future research.

</details>


### [266] [FUSE: A Flow-based Mapping Between Shapes](https://arxiv.org/abs/2511.13431)
*Lorenzo Olearo,Giulio Viganò,Daniele Baieri,Filippo Maggioli,Simone Melzi*

Main category: cs.CV

TL;DR: 使用流匹配模型在3D形状之间进行新颖的神经表示，无需大规模训练或数据驱动过程即可进行跨表示形状匹配。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的神经表示方法，用于在3D形状之间建立映射，该方法计算效率高，并支持跨表示的形状匹配，无需大规模训练或数据驱动。

Method: 将3D形状表示为由从固定锚点分布到连续且可逆的流映射引起的概率分布。通过将源的逆流（源到锚点）与正向流（锚点到目标）组合，可以在两个表面之间连续地映射点。通过对形状进行特定于任务的逐点嵌入编码，此构造提供了形状之间映射的可逆且特定于模态的表示，适用于点云、网格、符号距离场（SDF）和体积数据。

Result: 该表示在形状匹配方面，在各种基准测试和具有挑战性的设置中，持续实现高覆盖率和准确性。此外，该框架在UV映射和人体原始点云扫描配准等任务中也显示出有前景的结果。

Conclusion: 提出的基于流匹配的3D形状神经表示方法，能够高效、准确地进行跨表示的形状匹配，并在UV映射和点云配准等任务中展现出潜力。

Abstract: We introduce a novel neural representation for maps between 3D shapes based on flow-matching models, which is computationally efficient and supports cross-representation shape matching without large-scale training or data-driven procedures. 3D shapes are represented as the probability distribution induced by a continuous and invertible flow mapping from a fixed anchor distribution. Given a source and a target shape, the composition of the inverse flow (source to anchor) with the forward flow (anchor to target), we continuously map points between the two surfaces. By encoding the shapes with a pointwise task-tailored embedding, this construction provides an invertible and modality-agnostic representation of maps between shapes across point clouds, meshes, signed distance fields (SDFs), and volumetric data. The resulting representation consistently achieves high coverage and accuracy across diverse benchmarks and challenging settings in shape matching. Beyond shape matching, our framework shows promising results in other tasks, including UV mapping and registration of raw point cloud scans of human bodies.

</details>


### [267] [Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline](https://arxiv.org/abs/2511.13442)
*Rui Zuo,Qinyue Tong,Zhe-Ming Lu,Ziqian Lu*

Main category: cs.CV

TL;DR: Foresee是一个无需训练的基于多模态大语言模型（MLLM）的图像伪造检测与定位（IFDL）方法，能够有效处理各种篡改类型，并提供丰富的文本解释，同时具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的图像伪造检测方法泛化能力差且可解释性有限，而基于MLLM的方法计算成本高昂且未能充分发掘其潜力。

Method: Foresee提出了一种无需训练的、基于MLLM的图像伪造分析流程，采用类型先验驱动策略和灵活特征检测（FFD）模块来处理复制-移动篡改，以发挥原始MLLM在取证领域的潜力。

Result: Foresee在篡改定位精度和文本解释丰富度方面均超越了现有的基于MLLM的方法，并在包括复制-移动、拼接、移除、局部增强、深度伪造和AIGC编辑在内的各种篡改类型上表现出比现有IFDL方法更强的泛化能力。

Conclusion: Foresee成功地利用了原始MLLM的能力，提供了一种高效、准确且可解释的图像伪造检测与定位解决方案，并展现了优越的泛化性能。

Abstract: With the rapid advancement of artificial intelligence-generated content (AIGC) technologies, including multimodal large language models (MLLMs) and diffusion models, image generation and manipulation have become remarkably effortless. Existing image forgery detection and localization (IFDL) methods often struggle to generalize across diverse datasets and offer limited interpretability. Nowadays, MLLMs demonstrate strong generalization potential across diverse vision-language tasks, and some studies introduce this capability to IFDL via large-scale training. However, such approaches cost considerable computational resources, while failing to reveal the inherent generalization potential of vanilla MLLMs to address this problem. Inspired by this observation, we propose Foresee, a training-free MLLM-based pipeline tailored for image forgery analysis. It eliminates the need for additional training and enables a lightweight inference process, while surpassing existing MLLM-based methods in both tamper localization accuracy and the richness of textual explanations. Foresee employs a type-prior-driven strategy and utilizes a Flexible Feature Detector (FFD) module to specifically handle copy-move manipulations, thereby effectively unleashing the potential of vanilla MLLMs in the forensic domain. Extensive experiments demonstrate that our approach simultaneously achieves superior localization accuracy and provides more comprehensive textual explanations. Moreover, Foresee exhibits stronger generalization capability, outperforming existing IFDL methods across various tampering types, including copy-move, splicing, removal, local enhancement, deepfake, and AIGC-based editing. The code will be released in the final version.

</details>


### [268] [Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling](https://arxiv.org/abs/2511.13478)
*Adam Hazimeh,Ke Wang,Mark Collier,Gilles Baechler,Efi Kokiopoulou,Pascal Frossard*

Main category: cs.CV

TL;DR: SliDer框架使用视觉语言模型将幻灯片图像转换为可编辑的SVG格式，解决了传统方法无法保留高层结构的问题。


<details>
  <summary>Details</summary>
Motivation: 传统几何栅格矢量化方法在处理幻灯片等复杂文档时，无法保留高层结构，导致语义信息丢失，因此需要开发新的方法来恢复文档的可编辑性。

Method: SliDer框架利用视觉语言模型（VLMs）来识别和提取栅格图像中的文本和图像元素及其属性，并将它们组织成结构化的SVG格式。该模型在推理过程中会迭代地优化预测，以更精确地重建原始栅格图像。

Result: SliDer在重建LPIPS方面达到了0.069，并且在人类评估中，82.9%的情况下优于最强的零样本VLM基线。

Conclusion: SliDer框架通过引入VLMs和迭代优化，成功解决了幻灯片等文档的语义文档解渲染问题，能够生成更精确、可编辑的SVG表示。同时，Slide2SVG数据集的发布将有助于该领域的未来研究。

Abstract: Multimedia documents such as slide presentations and posters are designed to be interactive and easy to modify. Yet, they are often distributed in a static raster format, which limits editing and customization. Restoring their editability requires converting these raster images back into structured vector formats. However, existing geometric raster-vectorization methods, which rely on low-level primitives like curves and polygons, fall short at this task. Specifically, when applied to complex documents like slides, they fail to preserve the high-level structure, resulting in a flat collection of shapes where the semantic distinction between image and text elements is lost. To overcome this limitation, we address the problem of semantic document derendering by introducing SliDer, a novel framework that uses Vision-Language Models (VLMs) to derender slide images as compact and editable Scalable Vector Graphic (SVG) representations. SliDer detects and extracts attributes from individual image and text elements in a raster input and organizes them into a coherent SVG format. Crucially, the model iteratively refines its predictions during inference in a process analogous to human design, generating SVG code that more faithfully reconstructs the original raster upon rendering. Furthermore, we introduce Slide2SVG, a novel dataset comprising raster-SVG pairs of slide documents curated from real-world scientific presentations, to facilitate future research in this domain. Our results demonstrate that SliDer achieves a reconstruction LPIPS of 0.069 and is favored by human evaluators in 82.9% of cases compared to the strongest zero-shot VLM baseline.

</details>


### [269] [InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE](https://arxiv.org/abs/2511.13488)
*Lipeng Wang,Hongxing Fan,Haohua Chen,Zehuan Huang,Lu Sheng*

Main category: cs.CV

TL;DR: InterMoE是一个利用动态时间选择混合专家模型生成高保真人际交互的新框架，能够保留个体特征并遵循文本描述，在InterHuman和InterX数据集上均达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成高保真人际交互时，难以保留独特的个体特征并完全遵循文本描述。

Method: 提出InterMoE框架，核心是利用高层文本语义和低层运动上下文的路由机制，将时态运动特征分配给专门的专家，使专家能动态确定选择能力并专注于关键时态特征。

Result: InterMoE在InterHuman数据集上FID分数降低了9%，在InterX数据集上降低了22%，达到了在个体特定高保真3D人际交互生成方面的最先进性能。

Conclusion: InterMoE能够保留个体特征，同时保证高语义保真度，在人际交互生成方面表现优异。

Abstract: Generating high-quality human interactions holds significant value for applications like virtual reality and robotics. However, existing methods often fail to preserve unique individual characteristics or fully adhere to textual descriptions. To address these challenges, we introduce InterMoE, a novel framework built on a Dynamic Temporal-Selective Mixture of Experts. The core of InterMoE is a routing mechanism that synergistically uses both high-level text semantics and low-level motion context to dispatch temporal motion features to specialized experts. This allows experts to dynamically determine the selection capacity and focus on critical temporal features, thereby preserving specific individual characteristic identities while ensuring high semantic fidelity. Extensive experiments show that InterMoE achieves state-of-the-art performance in individual-specific high-fidelity 3D human interaction generation, reducing FID scores by 9% on the InterHuman dataset and 22% on InterX.

</details>


### [270] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: LGIP基准测试用于评估视觉语言模型（VLM）在处理语言扰动时的鲁棒性，特别是对保持含义的改写和改变含义的语义翻转的反应。


<details>
  <summary>Details</summary>
Motivation: 评估现有视觉语言模型（VLM）在面对有控制的语言扰动（如改写和语义翻转）时的可靠性。

Method: 使用MS COCO数据集和人类编写的标题，自动生成保持含义的改写和改变含义的语义翻转（涉及对象类别、颜色或数量），并引入LGIP基准测试来衡量模型的行为。

Result: EVA02-CLIP和大型OpenCLIP变体在不变性-敏感性权衡方面表现优异。SigLIP和SigLIP2则表现出较大的不变性误差，并且经常优先选择被翻转的标题，尤其是在对象和颜色编辑方面。

Conclusion: LGIP提供了一个模型无关的诊断工具，可以评估VLM的语言鲁棒性，超越了传统的准确性指标，揭示了标准检索指标可能忽视的模型弱点。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [271] [Mapping the Vanishing and Transformation of Urban Villages in China](https://arxiv.org/abs/2511.13507)
*Wenyu Zhang,Yao Tong,Yiqiu Liu,Rui Cao*

Main category: cs.CV

TL;DR: 中国城中村拆除重建后的土地再利用评估缺乏系统性，本研究提出一种基于深度学习的框架，利用遥感影像语义分割技术，监测城中村的时空变化及其拆除后的土地利用。研究选取了中国四个经济区域的四个代表性城市（广州、郑州、西安、哈尔滨）进行分析，结果显示城中村的重建过程普遍耗时较长，重建主要发生在城市外围区域，并揭示了同步重建、延迟重建和渐进优化三种时空转型路径。研究强调了城中村重建的碎片化、复杂性和非线性特征，呼吁制定分层和因地制宜的规划策略，为更具包容性、效率和可持续性的城市更新提供实证支持，并为全球范围内非正规住区转型提供参考。


<details>
  <summary>Details</summary>
Motivation: 中国城中村（UVs）在城市化进程中被大规模拆除和重建，但其拆除后的土地是否得到有效再利用，以及重建实践的可持续性，一直缺乏系统的评估。本研究旨在填补这一空白，系统地评估中国城中村拆除后的土地再利用情况。

Method: 本研究提出一个基于深度学习的框架，首先利用多时相遥感影像进行语义分割，绘制城中村不断变化的边界。然后，根据“保留-拆除-再开发”的阶段，将拆除后的土地利用分为六类：不完全拆除、空地、建筑工地、建筑物、绿地和其他。研究选取了中国四个经济区域的四个代表性城市（广州、郑州、西安、哈尔滨）作为研究区域。

Result: 研究结果表明：1) 城中村的重建过程普遍耗时较长；2) 重建转型主要发生在城市外围区域，而城市核心区相对稳定；3) 揭示了同步重建、延迟重建和渐进优化三种时空转型路径。

Conclusion: 本研究揭示了城中村重建的碎片化、复杂和非线性特征，强调了制定分层和因地制宜的规划策略的必要性。通过将空间动态与重建政策背景相结合，研究结果为更具包容性、效率和可持续性的城市更新提供了有价值的实证见解，并为全球非正规住区转型提供了更广泛的理解。

Abstract: Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the "remained-demolished-redeveloped" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.

</details>


### [272] [Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems](https://arxiv.org/abs/2511.13533)
*Jeffrey Wen,Rizwan Ahmad,Philip Schniter*

Main category: cs.CV

TL;DR: Conformal prediction is extended for uncertainty quantification in ill-posed imaging inverse problems with multiple estimation targets, providing tight prediction intervals and joint marginal coverage.


<details>
  <summary>Details</summary>
Motivation: Uncertainty quantification is a significant challenge in ill-posed imaging inverse problems, particularly for safety-critical applications. Existing conformal prediction methods only handle scalar estimation targets, while practical applications often require multiple targets.

Method: The paper proposes an asymptotically minimax approach to multi-target conformal prediction that ensures joint marginal coverage and provides tight prediction intervals. This approach is then applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition.

Result: The proposed minimax method demonstrates numerical benefits over existing multi-target conformal prediction methods using both synthetic and MRI data.

Conclusion: The developed asymptotically minimax approach effectively addresses multi-target uncertainty quantification in inverse imaging problems, offering tighter prediction intervals and joint marginal coverage, with demonstrated advantages in practical applications.

Abstract: In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data.

</details>


### [273] [Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew](https://arxiv.org/abs/2511.13535)
*Farhin Farhad Riya,Shahinul Hoque,Jinyuan Stella Sun,Olivera Kotevska*

Main category: cs.CV

TL;DR: 在联邦学习设置中，可以通过小的颜色扰动来攻击模型的解释性，而不会影响准确性。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越多地应用于安全关键领域，视觉解释技术对于支持透明度至关重要。本研究揭示了一类新的攻击，它在不影响准确性的情况下破坏了模型的解释性。

Method: 提出了一种名为“色度扰动模块”的、用于生成对抗性样本的框架，通过改变前景和背景之间的颜色对比度来破坏解释的保真度。

Result: 该攻击在保持分类准确性高于 96% 的同时，将 Grad-CAM 解释中的峰值激活重叠减少了高达 35%。

Conclusion: 解释性本身可能成为攻击的途径，并且在联邦学习环境中，解释性的退化更难被察觉和防御。

Abstract: As machine learning models are increasingly deployed in safety-critical domains, visual explanation techniques have become essential tools for supporting transparency. In this work, we reveal a new class of attacks that compromise model interpretability without affecting accuracy. Specifically, we show that small color perturbations applied by adversarial clients in a federated learning setting can shift a model's saliency maps away from semantically meaningful regions while keeping the prediction unchanged. The proposed saliency-aware attack framework, called Chromatic Perturbation Module, systematically crafts adversarial examples by altering the color contrast between foreground and background in a way that disrupts explanation fidelity. These perturbations accumulate across training rounds, poisoning the global model's internal feature attributions in a stealthy and persistent manner. Our findings challenge a common assumption in model auditing that correct predictions imply faithful explanations and demonstrate that interpretability itself can be an attack surface. We evaluate this vulnerability across multiple datasets and show that standard training pipelines are insufficient to detect or mitigate explanation degradation, especially in the federated learning setting, where subtle color perturbations are harder to discern. Our attack reduces peak activation overlap in Grad-CAM explanations by up to 35% while preserving classification accuracy above 96% on all evaluated datasets.

</details>


### [274] [BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse](https://arxiv.org/abs/2511.13539)
*Yuanchao Wang,Tian Qin,Eduardo Valle,Bruno Abrahao*

Main category: cs.CV

TL;DR: BootOOD是一个全自监督的OOD检测框架，它仅利用ID数据进行引导，旨在解决语义上相似的OOD样本检测难题。


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测方法在处理与ID类别语义相似的OOD样本时存在困难，而BootOOD旨在解决这一挑战。

Method: BootOOD通过对ID表示进行简单变换来合成伪OOD特征，并利用神经坍缩（NC）特性。它引入一个轻量级辅助头，通过基于半径的特征范数进行分类，将OOD检测与主分类器解耦，并放宽要求：OOD样本的学习目标是具有比ID样本更小的特征范数。

Result: BootOOD在CIFAR-10、CIFAR-100和ImageNet-200数据集上进行了实验，其OOD检测性能优于现有的事后方法，并且在不使用异常值暴露的情况下优于基于训练的方法，同时在ID准确率方面与最先进的异常值暴露方法具有竞争力。

Conclusion: BootOOD通过一种新颖的、基于特征范数半径分类的方法，有效地实现了对语义上相似的OOD样本的检测，并在保持ID准确率的同时，在多个基准测试中取得了优于现有方法的性能。

Abstract: Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.

</details>


### [275] [Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks](https://arxiv.org/abs/2511.13545)
*Md. Iqbal Hossain,Afia Sajeeda,Neeresh Kumar Perla,Ming Shao*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的策略，用于增强多模态对比学习模型（如CLIP）的鲁棒性，以抵御后门攻击。该方法能够高效地识别后门触发器、受害者样本和标签，并通过修正受污染的模型来消除后门效应。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态深度学习模型（如CLIP）易受后门攻击，而现有的防御方法通常需要从头开始训练或使用大型数据集进行微调，且无法精确定位受影响的标签。

Method: 提出一种创新的策略，引入图像分割“oracle”作为受污染CLIP模型输出的监督器。开发了两种算法：1）区分CLIP和Oracle的知识以识别潜在的触发器；2）精确定位受影响的标签和受害者样本，并策划一个精 Compact 的微调数据集，以修正受污染的CLIP模型，消除后门效应。

Result: 通过在视觉识别基准上的大量实验证明，该策略在基于CLIP的后门防御中是有效的。

Conclusion: 本研究提出的策略能够有效识别后门触发器、受害者样本和标签，并成功修正受污染的CLIP模型，从而消除后门效应，提高了模型的鲁棒性。

Abstract: The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.

</details>


### [276] [TSE-Net: Semi-supervised Monocular Height Estimation from Single Remote Sensing Images](https://arxiv.org/abs/2511.13552)
*Sining Chen,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 TSE-Net 的半监督学习框架，用于单目高度估计，以解决标注数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 单目高度估计在遥感领域具有重要意义，但现有深度学习方法受限于昂贵且难以大规模获取的标注数据。

Method: TSE-Net 采用自训练方法，包含教师网络、学生网络和考试网络。学生网络利用教师网络生成的伪标签在无标签数据上进行训练。教师网络结合了回归和分类模型，回归分支预测高度值作为伪标签，分类分支预测高度值类别及类别概率，用于过滤伪标签。为处理高度分布的长尾问题，采用了分层双剪策略定义高度类别，并通过 Plackett-Luce 模型校准类别概率以反映伪标签的预期准确性。考试网络作为学生网络的时序集成以稳定性能。

Result: 在三个不同分辨率和成像模式的数据集上进行了评估。

Conclusion: TSE-Net 通过利用大量无标签数据，有效克服了标注数据稀缺的限制，提高了单目高度估计的性能和泛化能力。

Abstract: Monocular height estimation plays a critical role in 3D perception for remote sensing, offering a cost-effective alternative to multi-view or LiDAR-based methods. While deep learning has significantly advanced the capabilities of monocular height estimation, these methods remain fundamentally limited by the availability of labeled data, which are expensive and labor-intensive to obtain at scale. The scarcity of high-quality annotations hinders the generalization and performance of existing models. To overcome this limitation, we propose leveraging large volumes of unlabeled data through a semi-supervised learning framework, enabling the model to extract informative cues from unlabeled samples and improve its predictive performance. In this work, we introduce TSE-Net, a self-training pipeline for semi-supervised monocular height estimation. The pipeline integrates teacher, student, and exam networks. The student network is trained on unlabeled data using pseudo-labels generated by the teacher network, while the exam network functions as a temporal ensemble of the student network to stabilize performance. The teacher network is formulated as a joint regression and classification model: the regression branch predicts height values that serve as pseudo-labels, and the classification branch predicts height value classes along with class probabilities, which are used to filter pseudo-labels. Height value classes are defined using a hierarchical bi-cut strategy to address the inherent long-tailed distribution of heights, and the predicted class probabilities are calibrated with a Plackett-Luce model to reflect the expected accuracy of pseudo-labels. We evaluate the proposed pipeline on three datasets spanning different resolutions and imaging modalities. Codes are available at https://github.com/zhu-xlab/tse-net.

</details>


### [277] [Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation](https://arxiv.org/abs/2511.13571)
*Ziyang Huang,Jiagang Chen,Jin Liu,Shunping Ji*

Main category: cs.CV

TL;DR: 3DGS优化存在陷入局部最优和收敛质量不足的问题。本文提出Opt3DGS框架，通过两阶段优化：自适应探索（SGLD）和曲率引导利用（L-BFGS-Adam），提升3DGS的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS优化过程容易陷入局部最优，且收敛质量有待提高。

Method: 提出Opt3DGS框架，采用两阶段优化：第一阶段使用自适应加权随机梯度 Langevin 动力学（SGLD）增强全局搜索以跳出局部最优；第二阶段使用局部拟牛顿方向引导的Adam优化器，利用曲率信息进行精确高效收敛。

Result: 在多个基准数据集上的大量实验表明，Opt3DGS通过改进3DGS优化过程，在不修改其底层表示的情况下，实现了最先进的渲染质量。

Conclusion: Opt3DGS通过自适应探索和曲率引导利用的两阶段优化策略，有效解决了3DGS优化中的局部最优和收敛质量问题，达到了领先的渲染效果。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading framework for novel view synthesis, yet its core optimization challenges remain underexplored. We identify two key issues in 3DGS optimization: entrapment in suboptimal local optima and insufficient convergence quality. To address these, we propose Opt3DGS, a robust framework that enhances 3DGS through a two-stage optimization process of adaptive exploration and curvature-guided exploitation. In the exploration phase, an Adaptive Weighted Stochastic Gradient Langevin Dynamics (SGLD) method enhances global search to escape local optima. In the exploitation phase, a Local Quasi-Newton Direction-guided Adam optimizer leverages curvature information for precise and efficient convergence. Extensive experiments on diverse benchmark datasets demonstrate that Opt3DGS achieves state-of-the-art rendering quality by refining the 3DGS optimization process without modifying its underlying representation.

</details>


### [278] [Hierarchical Prompt Learning for Image- and Text-Based Person Re-Identification](https://arxiv.org/abs/2511.13575)
*Linhan Zhou,Shuang Li,Neng Dong,Yonghang Tai,Yafei Zhang,Huafeng Li*

Main category: cs.CV

TL;DR: 该论文提出了一种名为 HPL 的分层提示学习框架，用于统一处理图像检索（I2I）和文本到图像检索（T2I）两种任务。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常将 I2I 和 T2I 任务分开处理，可能导致表示的纠缠和次优性能。

Method: HPL 框架利用任务感知的提示建模来联合优化这两个任务。具体来说，它引入了一个任务路由 Transformer，将双分类令牌纳入共享视觉编码器，分别路由 I2I 和 T2I 分支的特征。在此基础上，开发了一种分层提示生成方案，将身份级别的可学习令牌与实例级别的伪文本令牌相结合。这些伪令牌通过特定模态的逆转换网络从图像或文本特征中提取，将细粒度的、实例特定的语义注入到提示中。此外，还提出了一种跨模态提示正则化策略，以在提示令牌空间中强制执行语义对齐，确保伪提示保留源模态的特征，同时增强跨模态的可迁移性。

Result: 在多个 ReID 基准测试上的大量实验验证了该方法的有效性，在 I2I 和 T2I 任务上均取得了最先进的性能。

Conclusion: HPL 框架通过联合优化 I2I 和 T2I 任务，并引入创新的提示学习机制，有效解决了现有方法的局限性，并在 ReID 任务上取得了显著成果。

Abstract: Person re-identification (ReID) aims to retrieve target pedestrian images given either visual queries (image-to-image, I2I) or textual descriptions (text-to-image, T2I). Although both tasks share a common retrieval objective, they pose distinct challenges: I2I emphasizes discriminative identity learning, while T2I requires accurate cross-modal semantic alignment. Existing methods often treat these tasks separately, which may lead to representation entanglement and suboptimal performance. To address this, we propose a unified framework named Hierarchical Prompt Learning (HPL), which leverages task-aware prompt modeling to jointly optimize both tasks. Specifically, we first introduce a Task-Routed Transformer, which incorporates dual classification tokens into a shared visual encoder to route features for I2I and T2I branches respectively. On top of this, we develop a hierarchical prompt generation scheme that integrates identity-level learnable tokens with instance-level pseudo-text tokens. These pseudo-tokens are derived from image or text features via modality-specific inversion networks, injecting fine-grained, instance-specific semantics into the prompts. Furthermore, we propose a Cross-Modal Prompt Regularization strategy to enforce semantic alignment in the prompt token space, ensuring that pseudo-prompts preserve source-modality characteristics while enhancing cross-modal transferability. Extensive experiments on multiple ReID benchmarks validate the effectiveness of our method, achieving state-of-the-art performance on both I2I and T2I tasks.

</details>


### [279] [Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images](https://arxiv.org/abs/2511.13586)
*Yinuo Xu,Yan Cui,Mingyao Li,Zhi Huang*

Main category: cs.CV

TL;DR: NuClass是一个细胞级多尺度集成框架，结合了核形态和微环境背景，以提高细胞类型识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于图块的模型在整合细胞功能和身份识别的关键组织背景信息方面存在不足，同时，可用的人类注释粒度粗糙且分布不均，难以获得细粒度的亚型监督。NuClass旨在解决这些限制。

Method: NuClass框架包含两个主要组件：Path local（关注224x224像素裁剪的核形态）和Path global（建模1024x1024像素的邻域）。一个可学习的门控模块自适应地平衡局部细节和上下文线索。为了鼓励互补学习，该框架引入了一个不确定性引导目标，引导全局路径优先处理局部路径不确定的区域。此外，还提供了校准置信度估计和Grad-CAM可视化以增强可解释性。为了解决高质量注释不足的问题，研究人员构建了一个基于Xenium空间转录组学测定的标记引导数据集，为八个器官和16个类别中的两百多万个细胞提供了单细胞分辨率的标签。

Result: 在三个完全保留的队列上评估，NuClass在其表现最佳的类别中达到了96%的F1分数，优于强有力的基线模型。实验结果表明，多尺度、不确定性感知融合能够弥合幻灯片级病理基础模型与可靠的细胞级表型预测之间的差距。

Conclusion: NuClass通过多尺度、不确定性感知融合，有效解决了现有模型在整合组织背景信息和处理标注不足问题上的局限性，显著提高了细胞类型识别的准确性和可解释性。

Abstract: Identifying cell types and subtypes from routine histopathology images is essential for improving the computational understanding of human disease. Existing tile-based models can capture detailed nuclear morphology but often fail to incorporate the broader tissue context that influences a cell's function and identity. In addition, available human annotations are typically coarse-grained and unevenly distributed across studies, making fine-grained subtype-level supervision difficult to obtain.
  To address these limitations, we introduce NuClass, a pathologist workflow inspired framework for cell-wise multi-scale integration of nuclear morphology and microenvironmental context. NuClass includes two main components: Path local, which focuses on nuclear morphology from 224-by-224 pixel crops, and Path global, which models the surrounding 1024-by-1024 pixel neighborhood. A learnable gating module adaptively balances local detail and contextual cues. To encourage complementary learning, we incorporate an uncertainty-guided objective that directs the global path to prioritize regions where the local path is uncertain. We also provide calibrated confidence estimates and Grad-CAM visualizations to enhance interpretability.
  To overcome the lack of high-quality annotations, we construct a marker-guided dataset from Xenium spatial transcriptomics assays, yielding single-cell resolution labels for more than two million cells across eight organs and 16 classes. Evaluated on three fully held-out cohorts, NuClass achieves up to 96 percent F1 for its best-performing class, outperforming strong baselines. Our results show that multi-scale, uncertainty-aware fusion can bridge the gap between slide-level pathological foundation models and reliable, cell-level phenotype prediction.

</details>


### [280] [VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping](https://arxiv.org/abs/2511.13587)
*Haotian Dong,Ye Li,Rongwei Lu,Chen Tang,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: 通过引入验证跳过机制，VVS框架在视觉自回归模型生成中实现了2.8倍的加速，同时保持了生成质量，为加速视觉生成模型提供了新的范式。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉自回归模型推理速度慢，而现有加速方法（如推测性解码）存在局限性。本文旨在通过验证跳过机制来减少前向传播次数，以降低推理延迟。

Method: 提出了一种名为VVS的新型推测性解码框架，该框架通过（1）具有动态截断的无验证标记选择器、（2）标记级特征缓存和重用、（3）细粒度跳过步骤调度这三个模块来实现部分验证跳过。

Result: VVS将目标模型的前向传播次数减少了2.8倍，同时保持了与传统方法相当的生成质量，提供了优于传统推测性解码框架的速度-质量权衡。

Conclusion: VVS通过引入验证跳过机制，有效降低了视觉自回归模型的推理延迟，并在速度和生成质量之间取得了优越的平衡，展示了其重塑推测性解码范式的潜力。

Abstract: Visual autoregressive (AR) generation models have demonstrated strong potential for image generation, yet their next-token-prediction paradigm introduces considerable inference latency. Although speculative decoding (SD) has been proven effective for accelerating visual AR models, its "draft one step, then verify one step" paradigm prevents a direct reduction of the forward passes, thus restricting acceleration potential. Motivated by the visual token interchangeability, we for the first time to explore verification skipping in the SD process of visual AR model generation to explicitly cut the number of target model forward passes, thereby reducing inference latency. Based on an analysis of the drafting stage's characteristics, we observe that verification redundancy and stale feature reusability are key factors to retain generation quality and speedup for verification-free steps. Inspired by these two observations, we propose a novel SD framework VVS to accelerate visual AR generation via partial verification skipping, which integrates three complementary modules: (1) a verification-free token selector with dynamical truncation, (2) token-level feature caching and reuse, and (3) fine-grained skipped step scheduling. Consequently, VVS reduces the number of target model forward passes by a factor of $2.8\times$ relative to vanilla AR decoding while maintaining competitive generation quality, offering a superior speed-quality trade-off over conventional SD frameworks and revealing strong potential to reshape the SD paradigm.

</details>


### [281] [ICLR: Inter-Chrominance and Luminance Interaction for Natural Color Restoration in Low-Light Image Enhancement](https://arxiv.org/abs/2511.13607)
*Xin Xu,Hao Liu,Wei Liu,Wei Wang,Jiayi Wu,Kui Jiang*

Main category: cs.CV

TL;DR: 该研究提出了一种名为ICLR的低光图像增强框架，通过DIEM模块增强亮度和色度特征的互补性，并利用CCL损失来解决亮度和色度分支之间的分布差异和梯度冲突问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法在HVI颜色空间下，亮度和色度分支的分布差异和亮度误差传递限制了互补特征提取；色度分支之间在同色区域弱相关导致传统逐像素损失产生梯度冲突。因此，需要新的方法来解决这些问题。

Method: 提出ICLR框架，包含DIEM模块（通过融合和增强两个维度来提取互补信息）和CCL损失（利用亮度残差统计惩罚色度误差，并通过约束色度分支协方差来平衡梯度冲突）。

Result: 在多个数据集上的实验结果表明，所提出的ICLR框架在低光图像增强任务上优于现有最先进的方法。

Conclusion: ICLR框架通过DIEM和CCL的有效结合，成功解决了低光图像增强中亮度和色度特征提取的挑战，实现了优于现有方法的性能。

Abstract: Low-Light Image Enhancement (LLIE) task aims at improving contrast while restoring details and textures for images captured in low-light conditions. HVI color space has made significant progress in this task by enabling precise decoupling of chrominance and luminance. However, for the interaction of chrominance and luminance branches, substantial distributional differences between the two branches prevalent in natural images limit complementary feature extraction, and luminance errors are propagated to chrominance channels through the nonlinear parameter. Furthermore, for interaction between different chrominance branches, images with large homogeneous-color regions usually exhibit weak correlation between chrominance branches due to concentrated distributions. Traditional pixel-wise losses exploit strong inter-branch correlations for co-optimization, causing gradient conflicts in weakly correlated regions. Therefore, we propose an Inter-Chrominance and Luminance Interaction (ICLR) framework including a Dual-stream Interaction Enhancement Module (DIEM) and a Covariance Correction Loss (CCL). The DIEM improves the extraction of complementary information from two dimensions, fusion and enhancement, respectively. The CCL utilizes luminance residual statistics to penalize chrominance errors and balances gradient conflicts by constraining chrominance branches covariance. Experimental results on multiple datasets show that the proposed ICLR framework outperforms state-of-the-art methods.

</details>


### [282] [AtlasMorph: Learning conditional deformable templates for brain MRI](https://arxiv.org/abs/2511.13609)
*Marianne Rakic,Andrew Hoopes,S. Mazdak Abulnaga,Mert R. Sabuncu,John V. Guttag,Adrian V. Dalca*

Main category: cs.CV

TL;DR: We developed a machine learning framework using convolutional neural networks to create adaptive anatomical templates conditioned on subject attributes (e.g., age, sex). These templates improve registration accuracy and are more representative of specific populations compared to traditional static templates.


<details>
  <summary>Details</summary>
Motivation: The creation of deformable templates (atlases) for medical image analysis is computationally expensive, leading to the use of sub-optimal, non-representative templates, especially for populations with significant variations. This hinders accurate analysis.

Method: A machine learning framework employing convolutional registration neural networks was used to learn a function that generates templates conditioned on subject-specific attributes (age, sex). The framework also leverages segmentations to create probabilistic anatomical label maps for the generated templates and can be used for registering subject images to these templates.

Result: The framework was demonstrated on 3D brain MRI datasets, successfully learning high-quality, representative templates. Conditional templates, especially when annotated, showed superior registration performance compared to unlabeled unconditional templates and other template construction methods.

Conclusion: The proposed machine learning framework efficiently learns conditional anatomical templates that are representative of specific populations, leading to improved registration accuracy and outperforming existing methods.

Abstract: Deformable templates, or atlases, are images that represent a prototypical anatomy for a population, and are often enhanced with probabilistic anatomical label maps. They are commonly used in medical image analysis for population studies and computational anatomy tasks such as registration and segmentation. Because developing a template is a computationally expensive process, relatively few templates are available. As a result, analysis is often conducted with sub-optimal templates that are not truly representative of the study population, especially when there are large variations within this population. We propose a machine learning framework that uses convolutional registration neural networks to efficiently learn a function that outputs templates conditioned on subject-specific attributes, such as age and sex. We also leverage segmentations, when available, to produce anatomical segmentation maps for the resulting templates. The learned network can also be used to register subject images to the templates. We demonstrate our method on a compilation of 3D brain MRI datasets, and show that it can learn high-quality templates that are representative of populations. We find that annotated conditional templates enable better registration than their unlabeled unconditional counterparts, and outperform other templates construction methods.

</details>


### [283] [Tissue Aware Nuclei Detection and Classification Model for Histopathology Images](https://arxiv.org/abs/2511.13615)
*Kesi Xu,Eleni Chiou,Ali Varamesh,Laura Acqualagna,Nasir Rajpoot*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate nuclei detection and classification are fundamental to computational pathology, yet existing approaches are hindered by reliance on detailed expert annotations and insufficient use of tissue context. We present Tissue-Aware Nuclei Detection (TAND), a novel framework achieving joint nuclei detection and classification using point-level supervision enhanced by tissue mask conditioning. TAND couples a ConvNeXt-based encoder-decoder with a frozen Virchow-2 tissue segmentation branch, where semantic tissue probabilities selectively modulate the classification stream through a novel multi-scale Spatial Feature-wise Linear Modulation (Spatial-FiLM). On the PUMA benchmark, TAND achieves state-of-the-art performance, surpassing both tissue-agnostic baselines and mask-supervised methods. Notably, our approach demonstrates remarkable improvements in tissue-dependent cell types such as epithelium, endothelium, and stroma. To the best of our knowledge, this is the first method to condition per-cell classification on learned tissue masks, offering a practical pathway to reduce annotation burden.

</details>


### [284] [A Real-Time Driver Drowsiness Detection System Using MediaPipe and Eye Aspect Ratio](https://arxiv.org/abs/2511.13618)
*Ashlesha G. Sawant,Shreyash S. Kamble,Raj S. Kanade,Raunak N. Kanugo,Tanishq A. Kapse,Karan A. Bhapse*

Main category: cs.CV

TL;DR: 该研究开发了一个基于网络摄像头和面部地标检测的驾驶员嗜睡检测系统，通过监测眼睛的纵横比（EAR）来识别疲劳迹象，并发出声音警报，以提高道路安全。


<details>
  <summary>Details</summary>
Motivation: 由于驾驶员疲劳是导致道路交通事故的主要原因之一，每年造成数千人伤亡，因此有必要开发一个系统来提高道路安全。

Method: 该系统使用标准网络摄像头跟踪驾驶员的面部特征，重点是使用眼睛纵横比（EAR）方法检查眼球运动。它利用 MediaPipe 的 Face Mesh 框架来准确高效地识别面部地标，并使用 OpenCV 来处理图像。

Result: 实验分析表明，该系统非常准确且响应迅速，能够检测到长时间闭眼或眨眼频率低的迹象，并通过声音警报提醒驾驶员。

Conclusion: 该系统是一种高性能、低成本的驾驶员监控解决方案，可以作为现有高级驾驶辅助系统（ADAS）的组成部分。

Abstract: One of the major causes of road accidents is driver fatigue that causes thousands of fatalities and injuries every year. This study shows development of a Driver Drowsiness Detection System meant to improve the safety of the road by alerting drivers who are showing signs of being drowsy. The system is based on a standard webcam that tracks the facial features of the driver with the main emphasis on the examination of eye movements that can be conducted with the help of the Eye Aspect Ratio (EAR) method. The Face Mesh by MediaPipe is a lightweight framework that can identify facial landmarks with high accuracy and efficiency, which is considered to be important in real time use. The system detects the moments of long eye shutdowns or a very low rate of blinking which are manifestations of drowsiness and alerts the driver through sound to get her attention back. This system achieves a high-performance and low-cost driver monitoring solution with the help of the computational power of OpenCV to process the image and the MediaPipe to identify faces. Test data experimental analyses indicate that the system is very accurate and responds quicker; this confirms that it can be a component of the current Advanced Driving Assistance System (ADAS).

</details>


### [285] [Alpha Divergence Losses for Biometric Verification](https://arxiv.org/abs/2511.13621)
*Dimitrios Koutsianos,Ladislav Mosner,Yannis Panagakis,Themos Stafylakis*

Main category: cs.CV

TL;DR: 提出了两种新的基于 α-散度且包含角度边界的损失函数 Q-Margin 和 A3M，用于人脸和说话人识别。


<details>
  <summary>Details</summary>
Motivation: 现有的基于余弦的损失函数（如 CosFace 和 ArcFace）在人脸和说话人识别任务中表现优异，但 α-散度损失函数在引入角度边界时存在困难。

Method: 通过在参考测度或对数似然分数上引入角度边界，推导了 Q-Margin 和 A3M 两种新的损失函数。针对 A3M 训练不稳定的问题，提出了一种原型重新初始化策略。

Result: Q-Margin 和 A3M 在 IJB-B 和 IJB-C 人脸识别基准测试以及 VoxCeleb 说话人识别测试中取得了显著的性能提升，尤其是在低误识率（FAR）下表现更优。

Conclusion: 提出的 Q-Margin 和 A3M 损失函数在人脸和说话人识别任务中，尤其是在高安全性应用中，能够有效提升性能，降低误识率。

Abstract: Performance in face and speaker verification is largely driven by margin based softmax losses like CosFace and ArcFace. Recently introduced $α$-divergence loss functions offer a compelling alternative, particularly for their ability to induce sparse solutions (when $α>1$). However, integrating an angular margin-crucial for verification tasks-is not straightforward. We find this integration can be achieved in at least two distinct ways: via the reference measure (prior probabilities) or via the logits (unnormalized log-likelihoods). In this paper, we explore both pathways, deriving two novel margin-based $α$-divergence losses: Q-Margin (margin in the reference measure) and A3M (margin in the logits). We identify and address a critical training instability in A3M-caused by the interplay of penalized logits and sparsity-with a simple yet effective prototype re-initialization strategy. Our methods achieve significant performance gains on the challenging IJB-B and IJB-C face verification benchmarks. We demonstrate similarly strong performance in speaker verification on VoxCeleb. Crucially, our models significantly outperform strong baselines at low false acceptance rates (FAR). This capability is crucial for practical high-security applications, such as banking authentication, when minimizing false authentications is paramount.

</details>


### [286] [CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding](https://arxiv.org/abs/2511.13644)
*Shrenik Patel,Daivik Patel*

Main category: cs.CV

TL;DR: CacheFlow通过动态令牌丢弃（DTD）和压缩的长期记忆来解决长视频问答中的计算效率问题，实现了高效且上下文感知的视频理解。


<details>
  <summary>Details</summary>
Motivation: 长视频问答（VQA）对当前的视觉语言模型（VLMs）造成了巨大的计算压力，因为注意力和键值（KV）缓存会随着运行时间而增长，这导致了昂贵的推理成本或近视的滑动窗口方法。因此，需要一种能够处理长视频并保持高准确性的高效 VLM 方法。

Method: CacheFlow 引入了一个训练无关的流水线，该流水线结合了动态令牌丢弃（DTD）和压缩的长期记忆。DTD 通过计算当前帧与前一帧的余弦相似度来在线修剪每个图像块的令牌，并将存活下来的令牌打包成固定大小的块。在处理块时，每个块的键由一个小型循环编码器进行摘要，形成一个检索索引，同时块的完整 KV 对被卸载并稍后重新水合以进行生成，从而保持答案的准确性。在推理时，一个基于共识的检索机制仅检索 Top-K 个最相关的块，并同时关注检索到的和本地的上下文以进行精确的长距离推理。

Result: CacheFlow 在离线和流式 VQA 基准测试中均优于当前强大的基线模型，同时处理的令牌数量减少了 87%。

Conclusion: CacheFlow 是一种即插即用、与架构无关且无需微调的解决方案，它使 VLM 能够兼顾效率和上下文感知，为实际的长视频理解开辟了道路。

Abstract: Long-form video question answering (VQA) overwhelms current vision-language models (VLMs) because attention and key-value (KV) caches grow with runtime, forcing either expensive inference or near-sighted sliding windows. We introduce CacheFlow, a training-free pipeline that pairs Dynamic Token Dropping (DTD) with a compressive long-term memory. DTD prunes per-patch tokens online via cosine similarity to the previous frame, and surviving tokens are packed into fixed-size blocks. This online, per-frame processing makes our approach fundamentally suited for live streaming VQA. As blocks are processed, each one's keys are summarized by a tiny recurrent encoder to form a retrieval index, while the block's full KV pairs are offloaded and later rehydrated for generation, preserving answer fidelity. At inference, a consensus-based retrieval mechanism retrieves only the Top-K most relevant blocks and attends over both the retrieved and local context for precise, long-range reasoning. CacheFlow is drop-in, architecture-agnostic, and requires no fine-tuning. Experiments on both offline and streaming VQA benchmarks demonstrate that CacheFlow outperforms current strong baselines, while processing up to 87% less tokens. Our dual approach enables VLMs to be both efficient and context-aware, paving the way for practical long-form video understanding.

</details>


### [287] [Part-X-MLLM: Part-aware 3D Multimodal Large Language Model](https://arxiv.org/abs/2511.13647)
*Chunshi Wang,Junliang Ye,Yunhan Yang,Yang Li,Zizhuo Lin,Jun Zhu,Zhuo Chen,Yawei Luo,Chunchao Guo*

Main category: cs.CV

TL;DR: Part-X-MLLM是一个统一3D任务的原生3D多模态大语言模型，通过将其制定为结构化、可执行的语法程序来实现。


<details>
  <summary>Details</summary>
Motivation: 统一各种3D任务，通过生成包含部件级边界框、语义描述和编辑命令的单一、连贯的令牌序列，作为驱动下游几何感知模块的接口。

Method: 预训练一个双编码器架构来分离结构和语义，并在大规模、以部件为中心的数据集上进行指令调整。

Result: 在基础问答、组合生成和局部编辑方面表现出色，通过一个统一的接口实现了最先进的性能。

Conclusion: 该模型通过将符号规划与几何合成分离，允许通过单一的、原生语言的前端来控制任何兼容的几何引擎。

Abstract: We introduce Part-X-MLLM, a native 3D multimodal large language model that unifies diverse 3D tasks by formulating them as programs in a structured, executable grammar. Given an RGB point cloud and a natural language prompt, our model autoregressively generates a single, coherent token sequence encoding part-level bounding boxes, semantic descriptions, and edit commands. This structured output serves as a versatile interface to drive downstream geometry-aware modules for part-based generation and editing. By decoupling the symbolic planning from the geometric synthesis, our approach allows any compatible geometry engine to be controlled through a single, language-native frontend. We pre-train a dual-encoder architecture to disentangle structure from semantics and instruction-tune the model on a large-scale, part-centric dataset. Experiments demonstrate that our model excels at producing high-quality, structured plans, enabling state-of-the-art performance in grounded Q\&A, compositional generation, and localized editing through one unified interface. Project page: https://chunshi.wang/Part-X-MLLM/

</details>


### [288] [Distribution Matching Distillation Meets Reinforcement Learning](https://arxiv.org/abs/2511.13649)
*Dengyang Jiang,Dongyang Liu,Zanyi Wang,Qilong Wu,Xin Jin,David Liu,Zhen Li,Mengmeng Wang,Peng Gao,Harry Yang*

Main category: cs.CV

TL;DR: 通过结合强化学习（RL）技术，提出了一种名为DMDR的新型框架，用于将预训练的多步扩散模型蒸馏到少步模型，以提高推理效率，同时克服性能瓶颈。


<details>
  <summary>Details</summary>
Motivation: 为了提高少步扩散模型的推理效率，同时克服其性能受限于多步教师模型的瓶颈。

Method: 将强化学习（RL）技术融入蒸馏过程，利用DMD损失作为RL的正则化项，并设计了动态分布指导和动态重噪采样训练策略。

Result: DMDR在少步扩散模型方面取得了领先的视觉质量和提示一致性，并且性能超越了多步教师模型。

Conclusion: DMDR框架通过同时进行蒸馏和RL，有效释放了少步生成器的潜力，实现了高效且高质量的图像生成。

Abstract: Distribution Matching Distillation (DMD) distills a pre-trained multi-step diffusion model to a few-step one to improve inference efficiency. However, the performance of the latter is often capped by the former. To circumvent this dilemma, we propose DMDR, a novel framework that combines Reinforcement Learning (RL) techniques into the distillation process. We show that for the RL of the few-step generator, the DMD loss itself is a more effective regularization compared to the traditional ones. In turn, RL can help to guide the mode coverage process in DMD more effectively. These allow us to unlock the capacity of the few-step generator by conducting distillation and RL simultaneously. Meanwhile, we design the dynamic distribution guidance and dynamic renoise sampling training strategies to improve the initial distillation process. The experiments demonstrate that DMDR can achieve leading visual quality, prompt coherence among few-step methods, and even exhibit performance that exceeds the multi-step teacher.

</details>


### [289] [OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation](https://arxiv.org/abs/2511.13655)
*Henry Herzog,Favyen Bastani,Yawen Zhang,Gabriel Tseng,Joseph Redmon,Hadrien Sablon,Ryan Park,Jacob Morrison,Alexandra Buraczynski,Karen Farley,Joshua Hansen,Andrew Howe,Patrick Alan Johnson,Mark Otterlee,Ted Schmitt,Hunter Pitelka,Stephen Daspit,Rachel Ratner,Christopher Wilhelm,Sebastian Wood,Mike Jacobi,Hannah Kerner,Evan Shelhamer,Ali Farhadi,Ranjay Krishna,Patrick Beukema*

Main category: cs.CV

TL;DR: OlmoEarth是一个用于地球观测的多模态、时空基础模型，在多项基准和实际任务中均表现出色，并被整合到一个平台中，以支持非营利组织。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据具有空间性、序列性和多模态性，这给数据处理带来了独特的挑战。

Method: 提出了一种新颖的自监督学习方法，包括掩码策略和损失函数，专门针对地球观测领域设计，并构建了一个包含数据收集、标注、训练和推理的端到端平台。

Result: OlmoEarth在24项评估任务中的15项以及29项完全微调任务中的19项上取得了最佳性能，优于12种其他基础模型。

Conclusion: OlmoEarth为地球观测领域提供了一个强大的基础模型和平台，能够支持非营利组织应对全球性挑战。

Abstract: Earth observation data presents a unique challenge: it is spatial like images, sequential like video or text, and highly multimodal. We present OlmoEarth: a multimodal, spatio-temporal foundation model that employs a novel self-supervised learning formulation, masking strategy, and loss all designed for the Earth observation domain. OlmoEarth achieves state-of-the-art performance compared to 12 other foundation models across a variety of research benchmarks and real-world tasks from external partners. When evaluating embeddings OlmoEarth achieves the best performance on 15 out of 24 tasks, and with full fine-tuning it is the best on 19 of 29 tasks. We deploy OlmoEarth as the backbone of an end-to-end platform for data collection, labeling, training, and inference of Earth observation models. The OlmoEarth Platform puts frontier foundation models and powerful data management tools into the hands of non-profits and NGOs working to solve the world's biggest problems. OlmoEarth source code, training data, and pre-trained weights are available at $\href{https://github.com/allenai/olmoearth_pretrain}{\text{https://github.com/allenai/olmoearth_pretrain}}$.

</details>


### [290] [Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting](https://arxiv.org/abs/2511.13684)
*Jiangnan Ye,Jiedong Zhuang,Lianrui Mu,Wenjie Zheng,Jiaqi Hu,Xingze Zou,Jing Wang,Haoji Hu*

Main category: cs.CV

TL;DR: GS-Light是一个用于3D高斯喷溅场景的文本引导光照调整管线，能够高效地生成符合用户期望的光照效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理3D场景的文本引导光照调整时，难以精确控制光照方向和细节，且通常需要复杂的训练过程。本研究旨在提出一种无需训练、高效且能精确控制光照效果的方法。

Method: GS-Light通过以下步骤实现文本引导光照调整：1. 使用大型视觉语言模型（LVLM）解析用户输入的文本提示，提取光照先验信息。2. 利用现成的几何和语义估计器（深度、法线、语义分割）获取场景的几何和语义信息。3. 融合光照先验和视图-几何约束，计算光照图并生成多视图初始潜在编码。4. 将初始潜在编码输入到多视图光照调整模型中，生成高保真度的光照调整图像。5. 通过调整高斯喷溅场景的外观，获得完全光照调整后的3D场景。

Result: GS-Light在室内外场景的评估中，与现有方法（包括逐视图光照调整、视频光照调整和场景编辑方法）相比，在多视图一致性、图像质量、美学评分、语义相似性等方面均表现出持续的改进。用户研究也证实了其优越性。

Conclusion: GS-Light是一种有效且无需训练的文本引导3D场景光照调整方法，能够根据用户提示生成精确、高质量的光照效果，并在多项评估指标上超越现有技术。

Abstract: We introduce GS-Light, an efficient, textual position-aware pipeline for text-guided relighting of 3D scenes represented via Gaussian Splatting (3DGS). GS-Light implements a training-free extension of a single-input diffusion model to handle multi-view inputs. Given a user prompt that may specify lighting direction, color, intensity, or reference objects, we employ a large vision-language model (LVLM) to parse the prompt into lighting priors. Using off-the-shelf estimators for geometry and semantics (depth, surface normals, and semantic segmentation), we fuse these lighting priors with view-geometry constraints to compute illumination maps and generate initial latent codes for each view. These meticulously derived init latents guide the diffusion model to generate relighting outputs that more accurately reflect user expectations, especially in terms of lighting direction. By feeding multi-view rendered images, along with the init latents, into our multi-view relighting model, we produce high-fidelity, artistically relit images. Finally, we fine-tune the 3DGS scene with the relit appearance to obtain a fully relit 3D scene. We evaluate GS-Light on both indoor and outdoor scenes, comparing it to state-of-the-art baselines including per-view relighting, video relighting, and scene editing methods. Using quantitative metrics (multi-view consistency, imaging quality, aesthetic score, semantic similarity, etc.) and qualitative assessment (user studies), GS-Light demonstrates consistent improvements over baselines. Code and assets will be made available upon publication.

</details>


### [291] [TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models](https://arxiv.org/abs/2511.13704)
*Harold Haodong Chen,Disen Lan,Wen-Jie Shu,Qingyang Liu,Zihan Wang,Sirui Chen,Wenkai Cheng,Kanghao Chen,Hongfei Zhang,Zixin Zhang,Rongjin Guo,Yu Cheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: TiViBench是一个新的基准，用于评估视频生成模型的推理能力，并提出了VideoTPO测试时优化策略，以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型在物理和逻辑一致性方面取得了进展，但其推理能力仍不清楚。现有的基准主要评估视觉保真度和时间连贯性，未能捕捉更高级的推理能力。

Method: TiViBench是一个分层基准，评估结构推理与搜索、空间与视觉模式推理、符号与逻辑推理、动作规划与任务执行四个维度。VideoTPO是一种测试时策略，通过LLM自我分析来识别生成视频的优缺点，以提高推理性能。

Result: 商业模型（如Sora 2，Veo 3.1）表现出更强的推理潜力。开源模型虽然有潜力，但受到训练规模和数据多样性的限制。VideoTPO策略在不进行额外训练的情况下，显著提高了推理性能。

Conclusion: TiViBench和VideoTPO为评估和推进视频生成模型的推理能力奠定了基础，为该新兴领域未来的研究铺平了道路。

Abstract: The rapid evolution of video generative models has shifted their focus from producing visually plausible outputs to tackling tasks requiring physical plausibility and logical consistency. However, despite recent breakthroughs such as Veo 3's chain-of-frames reasoning, it remains unclear whether these models can exhibit reasoning capabilities similar to large language models (LLMs). Existing benchmarks predominantly evaluate visual fidelity and temporal coherence, failing to capture higher-order reasoning abilities. To bridge this gap, we propose TiViBench, a hierarchical benchmark specifically designed to evaluate the reasoning capabilities of image-to-video (I2V) generation models. TiViBench systematically assesses reasoning across four dimensions: i) Structural Reasoning & Search, ii) Spatial & Visual Pattern Reasoning, iii) Symbolic & Logical Reasoning, and iv) Action Planning & Task Execution, spanning 24 diverse task scenarios across 3 difficulty levels. Through extensive evaluations, we show that commercial models (e.g., Sora 2, Veo 3.1) demonstrate stronger reasoning potential, while open-source models reveal untapped potential that remains hindered by limited training scale and data diversity. To further unlock this potential, we introduce VideoTPO, a simple yet effective test-time strategy inspired by preference optimization. By performing LLM self-analysis on generated candidates to identify strengths and weaknesses, VideoTPO significantly enhances reasoning performance without requiring additional training, data, or reward models. Together, TiViBench and VideoTPO pave the way for evaluating and advancing reasoning in video generation models, setting a foundation for future research in this emerging field.

</details>


### [292] [Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine](https://arxiv.org/abs/2511.13713)
*Xincheng Shuai,Zhenyuan Qin,Henghui Ding,Dacheng Tao*

Main category: cs.CV

TL;DR: FFSE是一个3D感知自回归框架，可以直接在真实世界图像上进行对象编辑，实现平移、缩放和旋转等操作，同时保持逼真的背景效果和全局场景一致性。该框架通过一个名为3DObjectEditor的新混合数据集进行训练，并在单轮和多轮3D感知编辑场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在3D感知对象操作方面存在不足，作者希望提出一种能够进行直观、物理一致的对象编辑的框架。

Method: FFSE将编辑建模为一系列学习到的3D变换，并引入了一个名为3DObjectEditor的混合数据集来训练模型进行多轮3D感知对象操作。

Result: FFSE在单轮和多轮3D感知编辑场景中均显著优于现有方法。

Conclusion: FFSE能够有效地进行3D感知对象编辑，并能保持逼真的背景效果和全局场景一致性。

Abstract: Recent advances in text-to-image (T2I) diffusion models have significantly improved semantic image editing, yet most methods fall short in performing 3D-aware object manipulation. In this work, we present FFSE, a 3D-aware autoregressive framework designed to enable intuitive, physically-consistent object editing directly on real-world images. Unlike previous approaches that either operate in image space or require slow and error-prone 3D reconstruction, FFSE models editing as a sequence of learned 3D transformations, allowing users to perform arbitrary manipulations, such as translation, scaling, and rotation, while preserving realistic background effects (e.g., shadows, reflections) and maintaining global scene consistency across multiple editing rounds. To support learning of multi-round 3D-aware object manipulation, we introduce 3DObjectEditor, a hybrid dataset constructed from simulated editing sequences across diverse objects and scenes, enabling effective training under multi-round and dynamic conditions. Extensive experiments show that the proposed FFSE significantly outperforms existing methods in both single-round and multi-round 3D-aware editing scenarios.

</details>


### [293] [UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity](https://arxiv.org/abs/2511.13714)
*Junwei Yu,Trevor Darrell,XuDong Wang*

Main category: cs.CV

TL;DR: UnSAMv2通过无监督的自监督学习方法，实现了对分割粒度的任意控制，显著提升了SAM-2在多种分割任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的分割模型（如SAM）在控制分割粒度方面存在局限，用户需要手动调整，成本高且效果不确定。

Method: UnSAMv2在UnSAM的基础上，扩展了分而治之策略，发现了更多的掩码-粒度对，并引入了新的粒度控制嵌入，实现了对分割尺度的精确、连续控制。

Result: 在仅使用6K无标签图像和0.02%额外参数的情况下，UnSAMv2显著增强了SAM-2，在交互式、全图和视频分割任务上实现了任意粒度的分割。在11个基准测试中，UnSAMv2在NoC90（5.69->4.75）、1-IoU（58.0->73.1）和AR1000（49.6->68.3）上均有提升。

Conclusion: 少量的无标签数据配合感知粒度的自监督学习方法，可以充分挖掘视觉基础模型的潜力。

Abstract: The Segment Anything Model (SAM) family has become a widely adopted vision foundation model, but its ability to control segmentation granularity remains limited. Users often need to refine results manually - by adding more prompts or selecting from pre-generated masks - to achieve the desired level of detail. This process can be ambiguous, as the same prompt may correspond to several plausible masks, and collecting dense annotations across all granularities is prohibitively expensive, making supervised solutions infeasible. To address this limitation, we introduce UnSAMv2, which enables segment anything at any granularity without human annotations. UnSAMv2 extends the divide-and-conquer strategy of UnSAM by discovering abundant mask-granularity pairs and introducing a novel granularity control embedding that enables precise, continuous control over segmentation scale. Remarkably, with only $6$K unlabeled images and $0.02\%$ additional parameters, UnSAMv2 substantially enhances SAM-2, achieving segment anything at any granularity across interactive, whole-image, and video segmentation tasks. Evaluated on over $11$ benchmarks, UnSAMv2 improves $\text{NoC}_{90}$ (5.69 $\rightarrow$ 4.75), 1-IoU (58.0 $\rightarrow$ 73.1), and $\text{AR}_{1000}$ (49.6 $\rightarrow$ 68.3), showing that small amounts of unlabeled data with a granularity-aware self-supervised learning method can unlock the potential of vision foundation models.

</details>


### [294] [Segment Anything Across Shots: A Method and Benchmark](https://arxiv.org/abs/2511.13715)
*Hengrui Hu,Kaining Ying,Henghui Ding*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为SAAS的多镜头视频对象分割模型，并引入了一种名为Cut-VOS的新基准，以解决现有模型在处理镜头切换时的不足，从而提高了模型在真实世界场景下的适用性。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割（VOS）方法主要关注单镜头视频，在处理多镜头视频时，尤其是在镜头切换处，分割效果会受到很大影响，限制了其在真实世界中的应用。因此，需要新的方法来解决多镜头视频对象分割（MVOS）中的镜头不连续性问题。

Method: 提出了一种过渡模仿数据增强策略（TMA），仅使用单镜头数据即可实现跨镜头泛化，以缓解多镜头标注数据稀疏的问题。同时，提出了Segment Anything Across Shots (SAAS) 模型，该模型能够有效检测和理解镜头转换。此外，还引入了一个名为Cut-VOS的新MVOS基准，包含密集掩码标注、多样的对象类别和高频过渡，以支持MVOS的评估和未来研究。

Result: 在YouMVOS和Cut-VOS基准上的大量实验表明，所提出的SAAS模型通过有效模仿、理解和分割复杂的过渡，实现了最先进的性能。

Conclusion: 所提出的SAAS模型和TMA策略能够有效处理多镜头视频对象分割中的镜头切换问题，提高了分割的准确性和鲁棒性，为该领域的研究提供了新的方向和工具。

Abstract: This work focuses on multi-shot semi-supervised video object segmentation (MVOS), which aims at segmenting the target object indicated by an initial mask throughout a video with multiple shots. The existing VOS methods mainly focus on single-shot videos and struggle with shot discontinuities, thereby limiting their real-world applicability. We propose a transition mimicking data augmentation strategy (TMA) which enables cross-shot generalization with single-shot data to alleviate the severe annotated multi-shot data sparsity, and the Segment Anything Across Shots (SAAS) model, which can detect and comprehend shot transitions effectively. To support evaluation and future study in MVOS, we introduce Cut-VOS, a new MVOS benchmark with dense mask annotations, diverse object categories, and high-frequency transitions. Extensive experiments on YouMVOS and Cut-VOS demonstrate that the proposed SAAS achieves state-of-the-art performance by effectively mimicking, understanding, and segmenting across complex transitions. The code and datasets are released at https://henghuiding.com/SAAS/.

</details>


### [295] [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720)
*Tianhong Li,Kaiming He*

Main category: cs.CV

TL;DR: 本文提出的JiT模型直接预测清晰图像，而非噪声，在ImageNet上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型不直接预测清晰图像，而是预测噪声或含噪声量，这与自然数据在低维流形上的假设相悖。

Method: 提出JiT（Just image Transformers）模型，直接在像素上操作，使用大块Transformer，无需分词器、预训练或额外损失。

Result: 在ImageNet上，使用16和32的块大小，在256和512分辨率下，JiT模型取得了有竞争力的结果，并表明直接预测含噪声量可能会导致灾难性失败。

Conclusion: JiT模型通过直接预测清晰数据，回归到基于流形假设的Transformer扩散基本范式，证明了简单模型在处理高维原始数据时的有效性。

Abstract: Today's denoising diffusion models do not "denoise" in the classical sense, i.e., they do not directly predict clean images. Rather, the neural networks predict noise or a noised quantity. In this paper, we suggest that predicting clean data and predicting noised quantities are fundamentally different. According to the manifold assumption, natural data should lie on a low-dimensional manifold, whereas noised quantities do not. With this assumption, we advocate for models that directly predict clean data, which allows apparently under-capacity networks to operate effectively in very high-dimensional spaces. We show that simple, large-patch Transformers on pixels can be strong generative models: using no tokenizer, no pre-training, and no extra loss. Our approach is conceptually nothing more than "$\textbf{Just image Transformers}$", or $\textbf{JiT}$, as we call it. We report competitive results using JiT with large patch sizes of 16 and 32 on ImageNet at resolutions of 256 and 512, where predicting high-dimensional noised quantities can fail catastrophically. With our networks mapping back to the basics of the manifold, our research goes back to basics and pursues a self-contained paradigm for Transformer-based diffusion on raw natural data.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [296] [Towards Autoformalization of LLM-generated Outputs for Requirement Verification](https://arxiv.org/abs/2511.11829)
*Mihir Gupte,Ramesh S*

Main category: cs.CL

TL;DR: LLM驱动的自动形式化工具可用于验证LLM生成输出的准确性和逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在将非形式化语句转换为形式逻辑方面显示出潜力，但目前缺乏验证这些输出准确性的正式方法。

Method: 利用一个简单的基于LLM的自动形式化工具，将自然语言（NL）要求与LLM生成的输出进行比较，以进行一致性和逻辑一致性检查。

Result: 实验表明，该自动形式化工具可以识别出两个不同措辞的NL要求在逻辑上是等价的，还可以识别出给定的NL要求和LLM生成的输出之间的逻辑不一致性。

Conclusion: 自动形式化有潜力确保LLM生成输出的保真度和逻辑一致性，为未来更广泛的研究奠定了基础。

Abstract: Autoformalization, the process of translating informal statements into formal logic, has gained renewed interest with the emergence of powerful Large Language Models (LLMs). While LLMs show promise in generating structured outputs from natural language (NL), such as Gherkin Scenarios from NL feature requirements, there's currently no formal method to verify if these outputs are accurate. This paper takes a preliminary step toward addressing this gap by exploring the use of a simple LLM-based autoformalizer to verify LLM-generated outputs against a small set of natural language requirements. We conducted two distinct experiments. In the first one, the autoformalizer successfully identified that two differently-worded NL requirements were logically equivalent, demonstrating the pipeline's potential for consistency checks. In the second, the autoformalizer was used to identify a logical inconsistency between a given NL requirement and an LLM-generated output, highlighting its utility as a formal verification tool. Our findings, while limited, suggest that autoformalization holds significant potential for ensuring the fidelity and logical consistency of LLM-generated outputs, laying a crucial foundation for future, more extensive studies into this novel application.

</details>


### [297] [Evaluating Autoformalization Robustness via Semantically Similar Paraphrasing](https://arxiv.org/abs/2511.12784)
*Hayden Moore,Asfahan Shah*

Main category: cs.CL

TL;DR: LLMs在自动形式化方面表现出色，但在处理经过释义的自然语言输入时，其形式化证明的生成仍存在不稳定性，即使释义保留了大部分语义。本研究通过在MiniF2F和ProofNet基准测试中使用两种现代LLM，并进行跨模型评估，验证了这一现象。


<details>
  <summary>Details</summary>
Motivation: 探究LLM在自动形式化领域对释义输入的敏感性，以评估其生成形式化证明的鲁棒性。

Method: 使用MiniF2F和ProofNet基准测试，通过两种现代LLM生成释义后的自然语言表述，并进行跨模型评估，衡量生成证明的语义和编译有效性。

Result: 研究结果表明，LLM在处理释义输入的性能存在显著差异，细微的自然语言表述变化会严重影响模型输出。

Conclusion: LLM在自动形式化领域对释义输入的敏感性，需要进一步研究以提高其鲁棒性。

Abstract: Large Language Models (LLMs) have recently emerged as powerful tools for autoformalization. Despite their impressive performance, these models can still struggle to produce grounded and verifiable formalizations. Recent work in text-to-SQL, has revealed that LLMs can be sensitive to paraphrased natural language (NL) inputs, even when high degrees of semantic fidelity are preserved (Safarzadeh, Oroojlooyjadid, and Roth 2025). In this paper, we investigate this claim in the autoformalization domain. Specifically, we evaluate the robustness of LLMs generating formal proofs with semantically similar paraphrased NL statements by measuring semantic and compilation validity. Using the formal benchmarks MiniF2F (Zheng, Han, and Polu 2021) and Lean 4 version of ProofNet (Xin et al. 2024), and two modern LLMs, we generate paraphrased natural language statements and cross-evaluate these statements across both models. The results of this paper reveal performance variability across paraphrased inputs, demonstrating that minor shifts in NL statements can significantly impact model outputs.

</details>


### [298] [Toward Reliable Ad-hoc Scientific Information Extraction: A Case Study on Two Materials Datasets](https://arxiv.org/abs/2406.05348)
*Satanu Ghosh,Neal R. Brodnik,Carolina Frey,Collin Holgate,Tresa M. Pollock,Samantha Daly,Samuel Carton*

Main category: cs.CL

TL;DR: GPT-4在科学文献的特定模式信息提取任务上表现出潜力，但需要改进以提高准确性，特别是在处理复杂或不规范的材料科学数据时。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-4在根据特定模式从科学文献中提取信息的能力，并与现有手动提取的数据集进行比较，以识别其优势和劣势。

Method: 使用基础提示方法，让GPT-4尝试重现两个已有的材料科学数据集，并由材料科学家进行详细的手动错误分析，以确定模型在信息提取过程中遇到的问题。

Result: GPT-4在信息提取任务上取得了一定程度的成功，能够部分重现现有数据集，但仍存在错误，尤其是在处理不规范或复杂的数据时。

Conclusion: GPT-4在科学文献信息提取方面展现了前景，但为了实现广泛应用，需要进一步的研究来解决其在准确性和鲁棒性方面存在的不足，特别是在材料科学领域。

Abstract: We explore the ability of GPT-4 to perform ad-hoc schema based information extraction from scientific literature. We assess specifically whether it can, with a basic prompting approach, replicate two existing material science datasets, given the manuscripts from which they were originally manually extracted. We employ materials scientists to perform a detailed manual error analysis to assess where the model struggles to faithfully extract the desired information, and draw on their insights to suggest research directions to address this broadly important task.

</details>


### [299] [Seeing is Believing: Rich-Context Hallucination Detection for MLLMs via Backward Visual Grounding](https://arxiv.org/abs/2511.12140)
*Pinxue Guo,Chongruo Wu,Xinyu Zhou,Lingyi Hong,Zhaoyu Chen,Jinglun Li,Kaixun Jiang,Sen-ching Samson Cheung,Wei Zhang,Wenqiang Zhang*

Main category: cs.CL

TL;DR: VBackChecker是一个创新的无参考幻觉检测框架，通过像素级接地语言模型来验证多模态大语言模型（MLLM）生成响应与视觉输入的一致性，有效解决了MLLM的幻觉问题，并在新的基准测试R²-HalBench上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLM）虽然功能强大，但幻觉问题严重，准确检测幻觉对于其实际应用至关重要。

Method: 提出了一种名为VBackChecker的无参考幻觉检测框架，利用像素级接地语言模型（具备推理和指代分割能力）来验证MLLM生成响应与视觉输入的一致性。设计了R-Instruct数据生成流程，包含富文本描述、接地掩码和负样本。构建了R²-HalBench基准测试集。

Result: VBackChecker超越了先前复杂的框架，在R²-HalBench上达到了最先进的性能，甚至在幻觉检测方面与GPT-4o相当。在像素级接地任务上也取得了超过10%的提升。

Conclusion: VBackChecker是一种有效且可解释的无参考幻觉检测方法，通过利用像素级接地语言模型来解决MLLM的幻觉问题，并在新的基准测试和任务上展示了优越的性能。

Abstract: Multimodal Large Language Models (MLLMs) have unlocked powerful cross-modal capabilities, but still significantly suffer from hallucinations. As such, accurate detection of hallucinations in MLLMs is imperative for ensuring their reliability in practical applications. To this end, guided by the principle of "Seeing is Believing", we introduce VBackChecker, a novel reference-free hallucination detection framework that verifies the consistency of MLLMgenerated responses with visual inputs, by leveraging a pixellevel Grounding LLM equipped with reasoning and referring segmentation capabilities. This reference-free framework not only effectively handles rich-context scenarios, but also offers interpretability. To facilitate this, an innovative pipeline is accordingly designed for generating instruction-tuning data (R-Instruct), featuring rich-context descriptions, grounding masks, and hard negative samples. We further establish R^2 -HalBench, a new hallucination benchmark for MLLMs, which, unlike previous benchmarks, encompasses real-world, rich-context descriptions from 18 MLLMs with high-quality annotations, spanning diverse object-, attribute, and relationship-level details. VBackChecker outperforms prior complex frameworks and achieves state-of-the-art performance on R^2 -HalBench, even rivaling GPT-4o's capabilities in hallucination detection. It also surpasses prior methods in the pixel-level grounding task, achieving over a 10% improvement. All codes, data, and models are available at https://github.com/PinxueGuo/VBackChecker.

</details>


### [300] [Uni-MoE-2.0-Omni: Scaling Language-Centric Omnimodal Large Model with Advanced MoE, Training and Data](https://arxiv.org/abs/2511.12609)
*Yunxin Li,Xinyu Chen,Shenyuan Jiang,Haoyuan Shi,Zhenyu Liu,Xuanyu Zhang,Nanhao Deng,Zhenran Xu,Yicheng Ma,Meishan Zhang,Baotian Hu,Min Zhang*

Main category: cs.CL

TL;DR: Uni-MoE 2.0 是一个开源的全模态大模型，在语言中心的多模态理解、推理和生成方面取得了显著进展，在 85 个基准测试中表现出色，尤其在视频理解、全模态理解和视听推理方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在显著提升全模态大模型在语言中心的多模态理解、推理和生成能力。

Method: 通过设计动态容量的混合专家（MoE）模型、采用渐进式训练策略（结合迭代强化策略）以及精心策划的多模态数据匹配技术，从 Qwen2.5-7B 基础架构上构建 Uni-MoE 2.0。

Result: Uni-MoE 2.0 在 85 个基准测试中达到了最先进或具有竞争力的性能，在 76 个基准测试中的 50 多个超过了 Qwen2.5-Omni，在视频理解、全模态理解和视听推理方面取得了显著提升，并在语音处理和图像生成方面表现优异。

Conclusion: Uni-MoE 2.0 通过其创新的 MoE 架构、先进的训练策略和高效的数据处理，成功实现了全模态理解和生成能力的飞跃，并在多项关键任务上超越了现有模型。

Abstract: We present Uni-MoE 2.0 from the Lychee family. As a fully open-source omnimodal large model (OLM), it substantially advances Lychee's Uni-MoE series in language-centric multimodal understanding, reasoning, and generating. Based on the Qwen2.5-7B dense architecture, we build Uni-MoE-2.0-Omni from scratch through three core contributions: dynamic-capacity Mixture-of-Experts (MoE) design, a progressive training strategy enhanced with an iterative reinforcement strategy, and a carefully curated multimodal data matching technique. It is capable of omnimodal understanding, as well as generating images, text, and speech. Architecturally, our new MoE framework balances computational efficiency and capability for 10 cross-modal inputs using shared, routed, and null experts, while our Omni-Modality 3D RoPE ensures spatio-temporal cross-modality alignment in the self-attention layer. For training, following cross-modal pretraining, we use a progressive supervised fine-tuning strategy that activates modality-specific experts and is enhanced by balanced data composition and an iterative GSPO-DPO method to stabilise RL training and improve reasoning. Data-wise, the base model, trained on approximately 75B tokens of open-source multimodal data, is equipped with special speech and image generation tokens, allowing it to learn these generative tasks by conditioning its outputs on linguistic cues. Extensive evaluation across 85 benchmarks demonstrates that our model achieves SOTA or highly competitive performance against leading OLMs, surpassing Qwen2.5-Omni (trained with 1.2T tokens) on over 50 of 76 benchmarks. Key strengths include video understanding (+7% avg. of 8), omnimodallity understanding (+7% avg. of 4), and audiovisual reasoning (+4%). It also advances long-form speech processing (reducing WER by 4.2%) and leads in low-level image processing and controllable generation across 5 metrics.

</details>


### [301] [From Perception to Reasoning: Deep Thinking Empowers Multimodal Large Language Models](https://arxiv.org/abs/2511.12861)
*Wenxin Zhu,Andong Chen,Yuchen Song,Kehai Chen,Conghui Zhu,Ziyan Chen,Tiejun Zhao*

Main category: cs.CL

TL;DR: 本篇论文对多模态大语言模型（MCoT）进行了系统性综述，重点关注其推理能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有MLLMs推理路径不透明和泛化能力不足的问题，借鉴语言模型中CoT的成功经验，将其扩展到多模态领域以提升推理能力。

Method: 从CoT范式、训练后阶段和推理阶段三个方面介绍主流MCoT方法，并分析其机制。同时，总结了现有的评估基准、指标和应用场景。

Result: MCoT在提升多模态大语言模型推理能力方面展现出潜力，但仍面临挑战。

Conclusion: MCoT是提升多模态大语言模型推理能力的重要方向，未来研究应关注克服现有挑战并探索新的研究方向。

Abstract: With the remarkable success of Multimodal Large Language Models (MLLMs) in perception tasks, enhancing their complex reasoning capabilities has emerged as a critical research focus. Existing models still suffer from challenges such as opaque reasoning paths and insufficient generalization ability. Chain-of-Thought (CoT) reasoning, which has demonstrated significant efficacy in language models by enhancing reasoning transparency and output interpretability, holds promise for improving model reasoning capabilities when extended to the multimodal domain. This paper provides a systematic review centered on "Multimodal Chain-of-Thought" (MCoT). First, it analyzes the background and theoretical motivations for its inception from the perspectives of technical evolution and task demands. Then, it introduces mainstream MCoT methods from three aspects: CoT paradigms, the post-training stage, and the inference stage, while also analyzing their underlying mechanisms. Furthermore, the paper summarizes existing evaluation benchmarks and metrics, and discusses the application scenarios of MCoT. Finally, it analyzes the challenges currently facing MCoT and provides an outlook on its future research directions.

</details>


### [302] [Crossing Borders: A Multimodal Challenge for Indian Poetry Translation and Image Generation](https://arxiv.org/abs/2511.13689)
*Sofia Jamil,Kotla Sai Charan,Sriparna Saha,Koustava Goswami,Joseph K J*

Main category: cs.CL

TL;DR: 该研究提出了一个名为TAI的框架，利用LLM和LDM来翻译和生成印度诗歌的图像，以提高其可及性，并发布了一个包含21种印度语言的诗歌数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的诗歌作品在很大程度上忽视了印度语言的诗歌，而印度诗歌因其语言复杂性和深厚的文化底蕴而具有丰富的文化意义，这给理解带来了挑战，特别是对于非母语者或不熟悉其背景和语言的读者。

Method: 提出了一种名为TAI（Translation and Image Generation）的框架，该框架利用大型语言模型（LLMs）和潜在扩散模型（LDMs）以及适当的提示调整。该框架包括一个使用优势比偏好对齐算法（Odds Ratio Preference Alignment Algorithm）将形态丰富的诗歌准确翻译成英语的翻译模块，以及一个使用语义图来捕捉诗歌中比喻及其含义之间的代币、依赖关系和语义关系，从而生成有意义的视觉表征的图像生成模块。此外，还引入了一个名为MorphoVerse的数据集，其中包含21种低资源印度语言的1570首诗歌。

Result: TAI Diffusion在诗歌图像生成任务上表现优于其他基线模型，这在包括人类和定量评估在内的全面实验评估中得到了证明。

Conclusion: 该研究通过TAI框架解决了诗歌翻译和视觉理解方面的不足，旨在扩大印度诗歌的可及性并丰富读者的体验。该框架支持联合国可持续发展目标，即优质教育（SDG 4）和减少不平等（SDG 10）。

Abstract: Indian poetry, known for its linguistic complexity and deep cultural resonance, has a rich and varied heritage spanning thousands of years. However, its layered meanings, cultural allusions, and sophisticated grammatical constructions often pose challenges for comprehension, especially for non-native speakers or readers unfamiliar with its context and language. Despite its cultural significance, existing works on poetry have largely overlooked Indian language poems. In this paper, we propose the Translation and Image Generation (TAI) framework, leveraging Large Language Models (LLMs) and Latent Diffusion Models through appropriate prompt tuning. Our framework supports the United Nations Sustainable Development Goals of Quality Education (SDG 4) and Reduced Inequalities (SDG 10) by enhancing the accessibility of culturally rich Indian-language poetry to a global audience. It includes (1) a translation module that uses an Odds Ratio Preference Alignment Algorithm to accurately translate morphologically rich poetry into English, and (2) an image generation module that employs a semantic graph to capture tokens, dependencies, and semantic relationships between metaphors and their meanings, to create visually meaningful representations of Indian poems. Our comprehensive experimental evaluation, including both human and quantitative assessments, demonstrates the superiority of TAI Diffusion in poem image generation tasks, outperforming strong baselines. To further address the scarcity of resources for Indian-language poetry, we introduce the Morphologically Rich Indian Language Poems MorphoVerse Dataset, comprising 1,570 poems across 21 low-resource Indian languages. By addressing the gap in poetry translation and visual comprehension, this work aims to broaden accessibility and enrich the reader's experience.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [303] [Inverted C-Shaped Slots Loaded Exponential Tapered Triple Band Notched Ultra Wideband (UWB) Antenna](https://arxiv.org/abs/2511.11844)
*Olaoluwa A. Adegboye,Kufre M. Udofia,Akaninyene Obot*

Main category: eess.SP

TL;DR: 本文提出了一种指数渐变的三陷波超宽带天线设计策略，利用指数渐变变压器匹配微带线馈电和辐射贴片，并通过在辐射贴片上切割倒C形槽和在馈线上蚀刻U形槽来实现多频段的陷波，同时最小化了交叉耦合。


<details>
  <summary>Details</summary>
Motivation: 设计一款具有特定频段陷波功能的天线，以满足超宽带（UWB）应用的需求，并解决潜在的干扰问题。

Method: 采用指数渐变变压器进行微带线馈电和辐射贴片的匹配，并通过在辐射贴片上切割倒C形槽和在馈线上蚀刻U形槽来实现多频段（Wi-MAX、WLAN、X波段）的陷波，同时优化设计以最小化交叉耦合。

Result: 成功设计、仿真并测量了一款天线，该天线在3.5 GHz、5.5 GHz和7.5 GHz三个频段实现了有效的信号陷波，且满足超宽带设计要求。

Conclusion: 所提出的指数渐变的三陷波超宽带天线设计方案是可靠的，能够满足实际应用中的频段选择性需求。

Abstract: This research presents a simple strategy for designing an exponentially tapered, triple-notched ultrawideband antenna. The antenna's microstrip line feed and radiating patch are matched using an exponential tapered transformer. This method inserts antenna notch elements, by cutting two inverted C-shaped slots in the radiating patch; frequency rejection can be achieved for WI-MAX and wireless LAN. The X-band is rejected by etching a U-shaped slot in the feedline. When embedding the notch elements, cross-coupling was minimized. The desired antenna was designed, simulated, and measured. The measured results and graphs show that our proposed design is reliable. This band notched antenna rejects 3.5 GHz (Wi-MAX band, 3.3 to 3.7 GHz), 5.5 GHz (WLAN 2 band, 5.15 to 5.825 GHz), and 7.5 GHz (for satellite downlink X - band-7.25 GHz to 7.75 GHz). The proposed antenna meets UWB design requirements.

</details>


### [304] [AI-Open-RAN for Non-Terrestrial Networks](https://arxiv.org/abs/2511.11947)
*Tri Nhu Do*

Main category: eess.SP

TL;DR: 本论文提出了一种统一的、基于开放架构和人工智能（AI）功能的一体化无线接入网（RAN）概念，称为 AIO-RAN-NTN，用于非地面网络（NTN）。


<details>
  <summary>Details</summary>
Motivation: 为了提高下一代通信的互操作性、灵活性和智能性。

Method: 首先，概述了 Open-RAN 和 AI-RAN 的最新架构。然后，提出 AIO-RAN-NTN 蓝图，并应用 AIO-RAN 和 3GPP 的接口到 NTN 环境。使用 OpenAirInterface 平台为独立（SA）新无线（NR）5G 系统实现了一个测试传输，并对 KPI 进行了 AI 模型训练预测。

Result: 实验表明，AIO-RAN-NTN 架构对移动性很敏感，即使在低速下也是如此，但可以通过 AI 驱动的 KPI 预测来缓解。

Conclusion: AI 驱动的 KPI 预测可以缓解 AIO-RAN-NTN 架构对移动性的敏感性问题。

Abstract: In this paper, we propose the concept of AIO-RAN-NTN, a unified all-in-one Radio Access Network (RAN) for Non-Terrestrial Networks (NTNs), built on an open architecture that leverages open interfaces and artificial intelligence (AI)-based functionalities. This approach advances interoperability, flexibility, and intelligence in next-generation telecommunications. First, we provide a concise overview of the state-of-the-art architectures for Open-RAN and AI-RAN, highlighting key network functions and infrastructure elements. Next, we introduce our integrated AIO-RAN-NTN blueprint, emphasizing how internal and air interfaces from AIO-RAN and the 3rd Generation Partnership Project (3GPP) can be applied to emerging environments such as NTNs. To examine the impact of mobility on AIO-RAN, we implement a testbed transmission using the OpenAirInterface platform for a standalone (SA) New Radio (NR) 5G system. We then train an AI model on realistic data to forecast key performance indicators (KPIs). Our experiments demonstrate that the AIO-based SA architecture is sensitive to mobility, even at low speeds, but this limitation can be mitigated through AI-driven KPI forecasting.

</details>


### [305] [Temporal Micro-Doppler Spectrogram-based ViT Multiclass Target Classification](https://arxiv.org/abs/2511.11951)
*Nghia Thinh Nguyen,Tri Nhu Do*

Main category: eess.SP

TL;DR: 提出一种新的T-MDS-ViT模型，用于处理毫米波FMCW雷达微多普勒功率谱图，以实现多类别目标分类。该模型利用Transformer架构，通过多轴注意力机制显式建模MDS数据的序列特性，并结合移动感知约束处理目标重叠和遮挡问题。此外，还应用可解释机制分析模型注意力机制，并与现有CNN方法进行对比，证明了T-MDS-ViT在分类精度、数据效率和实时部署方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 开发一种用于毫米波FMCW雷达微多普勒（MDS）功率谱图的多类别目标分类新方法，以解决目标重叠和部分遮挡情况下的分类问题。

Method: 提出一种新的T-MDS-ViT模型，该模型利用Transformer架构处理堆叠的RVA（距离-速度-角度）时空张量。通过块嵌入和交叉轴注意力机制来显式建模MDS数据在多个帧中的序列特性。在注意力层中利用移动感知约束来保持目标分离性，以应对目标重叠和部分遮挡。此外，还引入了一个可解释机制来检查注意力层如何聚焦于MDS表示的高能量区域及其对特定类别运动学特征的影响。

Result: 与现有的基于CNN的方法相比，T-MDS-ViT在分类精度方面表现更优，同时在数据效率和实时部署方面也具有优势。

Conclusion: T-MDS-ViT在处理毫米波FMCW雷达MDS功率谱图进行多类别目标分类方面，尤其是在存在目标重叠和部分遮挡的情况下，优于现有的基于CNN的方法，并且具有更好的数据效率和实时部署能力。

Abstract: In this paper, we propose a new Temporal MDS-Vision Transformer (T-MDS-ViT) for multiclass target classification using millimeter-wave FMCW radar micro-Doppler spectrograms. Specifically, we design a transformer-based architecture that processes stacked range-velocity-angle (RVA) spatiotemporal tensors via patch embeddings and cross-axis attention mechanisms to explicitly model the sequential nature of MDS data across multiple frames. The T-MDS-ViT exploits mobility-aware constraints in its attention layer correspondences to maintain separability under target overlaps and partial occlusions. Next, we apply an explainable mechanism to examine how the attention layers focus on characteristic high-energy regions of the MDS representations and their effect on class-specific kinematic features. We also demonstrate that our proposed framework is superior to existing CNN-based methods in terms of classification accuracy while achieving better data efficiency and real-time deployability.

</details>


### [306] [Resource Allocation for Transmissive RIS Transceiver Enabled SWIPT Systems](https://arxiv.org/abs/2511.11980)
*Yuan Guo,Wen Chen,Xudong Bai,Chong He,Qiong Wu*

Main category: eess.SP

TL;DR: 提出了一种基于新型透射式可重构智能表面（TRIS）收发器赋能的联合无线信息与能量传输（SWIPT）框架，通过优化TRIS收发器的波束成形来最大化信息解码（ID）用户的和速率，同时满足能量收集（EH）用户的能量收集质量和每天线功率约束。为解决该非凸问题，开发了一种有效的优化算法，首先将原问题重构为半定规划（SDP）问题，然后结合罚函数法和逐次凸逼近（SCA）技术来求解。数值结果验证了该算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 提出了一种用于联合无线信息与能量传输（SWIPT）的新型框架，旨在最大化信息解码（ID）用户的和速率，并满足能量收集（EH）用户的能量收集质量和功率约束。

Method: 将TRIS收发器集成了SWIPT框架中，并通过优化波束成形来解决非凸优化问题。具体方法包括：1. 将问题重构为半定规划（SDP）问题。2. 结合罚函数法和逐次凸逼近（SCA）技术来求解SDP问题。

Result: 开发了一种有效的优化算法，并通过数值结果验证了其在最大化和速率和满足约束方面的有效性。

Conclusion: 所提出的TRIS收发器赋能的SWIPT框架和优化算法能够有效地解决联合信息与能量传输问题，并在实际应用中具有潜力。

Abstract: A novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) framework is proposed. The sum-rate of the information decoding (ID) users is maximized by optimizing the TRIS transceiver's beamforming, subject to the energy harvesting (EH) users' quality-of-harvest and the per-antenna power constraints. To solve this non-convex problem, we develop an efficient optimization algorithm. First, the original problem is reformulated as a semi-definite programming (SDP) problem. The resulting SDP problem is then addressed using successive convex approximation (SCA) combined with a penalty-based method. Numerical results demonstrate the effectiveness of the algorithm.

</details>


### [307] [Beamforming for Transmissive RIS Transmitter Enabled Simultaneous Wireless Information and Power Transfer Systems](https://arxiv.org/abs/2511.11985)
*Yuan Guo,Wen Chen,Yanze Zhu,Zhendong Li,Qiong Wu,Kunlun Wang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于 TRIS 收发器和 SWIPT 的系统，并通过 WMMSE 和 MM 方法优化和解决了一个复杂的优化问题，最终通过 ADMM 方法提出了一种低复杂度、可并行化的算法，在数值结果中验证了其有效性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于解决一个复杂的优化问题，该问题旨在通过设计 TRIS 收发器的有源波束赋形来最大化所有 ID 用户的总速率，同时满足 TRIS 收发器的单天线功率限制以及所有 EH 用户的最小能量收集需求。由于目标函数和能量收集约束的非凸性，该问题难以直接求解。

Method: 本研究首先将加权最小均方误差（WMMSE）框架与 majorization-minimization（MM）方法相结合，提出了一种基于二阶锥规划（SOCP）的算法来解决优化问题。然而，由于每根天线功率约束引入了大量的约束条件，问题变得更加复杂。为了应对这一挑战，研究人员采用了交替方向乘子法（ADMM）来开发一种解析、计算效率高且高度可并行的算法。

Result: 通过数值结果验证了所提出算法的收敛性和有效性。结果表明，该低复杂度算法在不牺牲性能的情况下显著降低了计算复杂度。

Conclusion: 该研究成功地提出了一种基于 TRIS 收发器和 SWIPT 的优化方法，并通过 WMMSE、MM 和 ADMM 等先进算法解决了复杂的非凸优化问题。所提出的低复杂度算法在保证性能的同时，提高了计算效率和可并行性。

Abstract: This paper investigates a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) system with multiple information decoding (ID) and energy harvesting (EH) users. Under the considered system model, we formulate an optimization problem that maximizes the sum-rate of all ID users via the design of the TRIS transceiver's active beamforming. The design is constrained by per-antenna power limits at the TRIS transceiver and by the minimum harvested energy demand of all EH users. Due to the non-convexity of the objective function and the energy harvesting constraint, the sum-rate problem is difficult to tackle. To solve this challenging optimization problem, by leveraging the weighted minimum mean squared error (WMMSE) framework and the majorization-minimization (MM) method, we propose a second-order cone programming (SOCP)-based algorithm. Per-element power constraints introduce a large number of constraints, making the problem considerably more difficult. By applying the alternating direction method of multipliers (ADMM) method, we successfully develop an analytical, computationally efficient, and highly parallelizable algorithm to address this challenge. Numerical results are provided to validate the convergence and effectiveness of the proposed algorithms. Furthermore, the low-complexity algorithm significantly reduces computational complexity without performance degradation.

</details>


### [308] [MUSTEM: A Dual-Modality System for Vibrotactile and Visual Translation of Music as an Assistive Technology](https://arxiv.org/abs/2511.12045)
*Paloma Sette,Maria Werneck,William Barbosa,Ana Loubacker*

Main category: eess.SP

TL;DR: MUSTEM系统通过将音乐转换为触觉和视觉信号，为聋哑人群提供了新的音乐体验方式，并已获得初步积极的用户反馈。


<details>
  <summary>Details</summary>
Motivation: 解决聋哑人群在理解和体验音乐时面临的情感和结构障碍。

Method: 开发了一个包含硬件原型（将音频频率映射到振动触觉）和软件模拟（将音乐成分解码为视觉界面）的双模态系统MUSTEM。

Result: 硬件原型能够实时分析音频，并将不同频段映射到振动触觉系统；软件模拟展示了完整的视觉翻译潜力，并将其解码为直观的视觉界面。七名聋哑用户初步反馈认为触觉映射是可感知和引人入胜的。

Conclusion: MUSTEM提供了一个全面的感官替代框架，为聋哑人群提供了一种可行且可及的途径，让他们能够将音乐体验为结构化、有根据且富有情感共鸣的视觉和触觉语言。

Abstract: The emotional and structural experience of music remains a significant accessibility challenge for the deaf and hard of hearing community. This paper introduces MUSTEM (Multisensorial Emotional Translation), a novel system designed to translate music into a rich, coherent, and scientifically-grounded sensory experience. We present a dual-modality approach addressing this challenge through two interconnected components. First, a low-cost, portable hardware prototype that performs real-time audio analysis, mapping distinct frequency bands (sub-bass, bass, mid-range, treble) to a four-channel vibrotactile system, allowing users to feel the music's rhythmic and foundational structure. Second, to overcome the processing limitations of embedded hardware, we developed a high-fidelity software simulation that demonstrates the full potential of the visual translation. This assistive dashboard decodes musical components - such as rhythm, harmony, and frequency spectrum - into an intuitive and educational visual interface. MUSTEM offers a comprehensive framework for sensory substitution, presenting a viable and accessible pathway for the deaf community to experience music not just as vibration, but as a structured, substantiated and emotionally resonant visual and tactile language. Preliminary feedback from seven deaf users suggests the system's spatial vibrotactile mapping is perceptible and engaging. All source code and hardware designs are released as open-source. Video demonstrations and open-source code are available on the project's official channel.

</details>


### [309] [Near-Real-Time InSAR Phase Estimation for Large-Scale Surface Displacement Monitoring](https://arxiv.org/abs/2511.12051)
*Scott Staniewicz,Sara Mirzaee,Heresh Fattahi,Talib Oliver-Cabrera,Emre Havazli,Geoffrey Gunter,Se-Yeon Jeon,Mary Grace Bato,Jinwoo Kim,Simran S. Sangha,Bruce Chapman,Alexander L. Handwerger,Marin Govorcin,Piyush Agram,David Bekaert*

Main category: eess.SP

TL;DR: 开发了一种新的InSAR处理算法，能够近乎实时地监测地表形变，并成功应用于北美大陆尺度的地表位移产品（OPERA）。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够高效处理新采集数据且无需重新处理历史存档的InSAR处理算法，以实现近乎实时的地表形变监测。

Method: 提出了一种顺序相位连接方法，利用压缩的单视复数影像（SLCs），并通过引入小堆栈参考方案、在线持久散射体和分布式散射体识别方法、多项像素质量指标以及L1范数网络反演来维持相位一致性并限制解包裹误差的传播。

Result: 成功开发了OPERA地表形变产品，并在北美大陆范围内进行了应用。通过与GPS测量和InSAR残差分析进行验证，证明了该算法在不同环境条件下速度估计具有毫米级精度。算法能够成功恢复基拉韦厄火山2018年喷发期间米级的同震形变，并检测到Three Sisters火山的微小抬升。

Conclusion: 所提出的InSAR处理算法能够近乎实时地监测地表形变，并且算法和所有软件已开源，为科学界处理大规模InSAR数据集提供了重要的支持。

Abstract: Operational near-real-time monitoring of Earth's surface deformation using Interferometric Synthetic Aperture Radar (InSAR) requires processing algorithms that efficiently incorporate new acquisitions without reprocessing historical archives. We present sequential phase linking approach using compressed single-look-complex images (SLCs) capable of producing surface displacement estimates within hours of the time of a new acquisition. Our key algorithmic contribution is a mini-stack reference scheme that maintains phase consistency across processing batches without adjusting or re-estimating previous time steps, enabling straightforward operational deployment. We introduce online methods for persistent and distributed scatterer identification that adapt to temporal changes in surface properties through incremental amplitude statistics updates. The processing chain incorporates multiple complementary metrics for pixel quality that are reliable for small SLC stack sizes, and an L1-norm network inversion to limit propagation of unwrapping errors across the time series. We use our algorithm to produce OPERA Surface Displacement from Sentinel-1 product, the first continental-scale surface displacement product over North America. Validation against GPS measurements and InSAR residual analysis demonstrates millimeter-level agreement in velocity estimates in varying environmental conditions. We demonstrate our algorithm's capabilities with a successful recovery of meter-scale co-eruptive displacement at Kilauea volcano during the 2018 eruption, as well as detection of subtle uplift at Three Sisters volcano, Oregon- a challenging environment for C-band InSAR due to dense vegetation and seasonal snow. We have made all software available as open source libraries, providing a significant advancement to the open scientific community's ability to process large InSAR data sets in a cloud environment.

</details>


### [310] [Informed Bootstrap Augmentation Improves EEG Decoding](https://arxiv.org/abs/2511.12073)
*Woojae Jeong,Wenhui Cui,Kleanthis Avramidis,Takfarinas Medani,Shrikanth Narayanan,Richard Leahy*

Main category: eess.SP

TL;DR: 加权引导法通过优先选择更可靠的样本来提高EEG信号的解码精度。


<details>
  <summary>Details</summary>
Motivation: 传统的EEG信号数据增强方法（如均匀平均）忽略了不同试验信息量的差异，可能导致代表性质量下降。因此，需要一种新的数据增强方法来提高EEG信号的解码性能。

Method: 提出一种加权引导（weighted bootstrapping）方法，该方法根据试验的可靠性分配权重，优先选择信息量更多的试验来生成更高质量的增强样本。在句子评估范式中，试验权重基于相对ERP差异计算，并用于概率抽样和平均。

Result: 与未加权的引导法相比，加权引导法在句子评估范式中的解码精度有所提高（最佳情况从68.35%提高到71.25%），表明这种方法能够增强代表性质量。

Conclusion: 基于可靠性的数据增强方法能够产生更鲁棒、更具区分性的EEG信号代表。

Abstract: Electroencephalography (EEG) offers detailed access to neural dynamics but remains constrained by noise and trial-by-trial variability, limiting decoding performance in data-restricted or complex paradigms. Data augmentation is often employed to enhance feature representations, yet conventional uniform averaging overlooks differences in trial informativeness and can degrade representational quality. We introduce a weighted bootstrapping approach that prioritizes more reliable trials to generate higher-quality augmented samples. In a Sentence Evaluation paradigm, weights were computed from relative ERP differences and applied during probabilistic sampling and averaging. Across conditions, weighted bootstrapping improved decoding accuracy relative to unweighted (from 68.35% to 71.25% at best), demonstrating that emphasizing reliable trials strengthens representational quality. The results demonstrate that reliability-based augmentation yields more robust and discriminative EEG representations. The code is publicly available at https://github.com/lyricists/NeuroBootstrap.

</details>


### [311] [Bayesian Learning Aided Simultaneous Sparse Estimation of Dual-Wideband THz Channels in Multi-User Hybrid MIMO Systems](https://arxiv.org/abs/2511.12102)
*Abhisha Garg,Akash Kumar,Suraj Srivastava,Nimish Yadav,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 该研究提出了一种贝叶斯组稀疏回归（BGSR）方法，用于在多用户（MU）太赫兹（THz）混合MIMO场景中估计双宽带（空间和频率）信道。


<details>
  <summary>Details</summary>
Motivation: 为了应对太赫兹通信高采样率和大规模天线数量带来的功耗和硬件复杂度问题，研究人员采用了低分辨率ADC，并提出了BGSR方法来学习量化后的信道。

Method: 该研究首先构建了一个包含吸收损耗、反射损耗、散射射线建模以及到达/离开角度（AoAs/AoDs）的实用双宽带太赫兹信道模型。然后，利用Bussgang分解将量化后的MU太赫兹MIMO模型线性化，并采用BGSR信道学习框架，实现了跨不同子载波的稀疏性，其中每个子载波都有其独特的字典矩阵。最后，推导了贝叶斯Cramér Rao界（BCRB）来约束归一化均方误差（NMSE）性能。

Result: 通过广泛的仿真评估，结果表明所提出的BGSR方法在NMSE和比特错误率（BER）方面优于其他稀疏估计技术。

Conclusion: BGSR方法为在低分辨率ADC条件下进行双宽带太赫兹信道估计提供了一种有效且实用的解决方案。

Abstract: This work conceives the Bayesian Group-Sparse Regression (BGSR) for the estimation of a spatial and frequency wideband, i.e., a dual wideband channel in Multi-User (MU) THz hybrid MIMO scenarios. We develop a practical dual wideband THz channel model that incorporates absorption losses, reflection losses, diffused ray modeling and angles of arrival/departure (AoAs/AoDs) using a Gaussian Mixture Model (GMM). Furthermore, a low-resolution analog-to-digital converter (ADC) is employed at each RF chain, which is crucial for wideband THz massive MIMO systems to reduce power consumption and hardware complexity, given the high sampling rates and large number of antennas involved. The quantized MU THz MIMO model is linearized using the popular Bussgang decomposition followed by BGSR based channel learning framework that results in sparsity across different subcarriers, where each subcarrier has its unique dictionary matrix. Next, the Bayesian Cramér Rao Bound (BCRB) is devised for bounding the normalized mean square error (NMSE) performance. Extensive simulations were performed to assess the performance improvements achieved by the proposed BGSR method compared to other sparse estimation techniques. The metrics considered for quantifying the performance improvements include the NMSE and bit error rate (BER).

</details>


### [312] [A 24-GHz CMOS Transformer-Based Three-Tline Series Doherty Power Amplifier Achieving 39% PAE](https://arxiv.org/abs/2511.12137)
*Zheng Wang,Yifu Li,Yuchao Mei,Xinyu Sui,Qingbin Li,Xu Luo,Rui Wang,Dongxin Ni,Jian Pang*

Main category: eess.SP

TL;DR: 该论文提出了一种基于变压器三传输线（Tline）串联Doherty功率放大器（PA），采用65nm CMOS技术，面向宽带K/Ka波段应用。


<details>
  <summary>Details</summary>
Motivation: 通过在输出匹配结构中集成阻抗变换网络，该设计能够实现有效的负载调制，并在使用堆叠共源共栅晶体管时降低功率回退时的阻抗变换比（ITR）。

Method: 提出的Doherty PA采用了变压器三传输线（Tline）串联结构，并集成了阻抗变换网络。

Result: PA在22至32.5 GHz频带内实现了-3 dB的小信号增益带宽，饱和输出功率（Psat）为21.6 dBm，峰值功率附加效率（PAE）为39%。在6dB回退时，PAE仍保持在24%以上。

Conclusion: 该PA的性能验证了其在高效率毫米波相控阵发射器中的应用潜力，适用于下一代无线系统。

Abstract: This paper presents a transformer-based three- transmission-line (Tline) series Doherty power amplifier (PA) implemented in 65-nm CMOS, targeting broadband K/Ka-band applications. By integrating an impedance-scaling network into the output matching structure, the design enables effective load modulation and reduced impedance transformation ratio (ITR) at power back-off when employing stacked cascode transistors. The PA demonstrates a -3-dB small-signal gain bandwidth from 22 to 32.5 GHz, a saturated output power (Psat) of 21.6 dBm, and a peak power-added efficiency (PAE) of 39%. At 6dB back-off, the PAE remains above 24%, validating its suitability for high- efficiency mm-wave phased-array transmitters in next-generation wireless systems.

</details>


### [313] [A Linear Implementation of an Analog Resonate-and-Fire Neuron](https://arxiv.org/abs/2511.12297)
*Angqi Liu,Filippo Moro,Sebastian Billaudelle,Melika Payvand*

Main category: eess.SP

TL;DR: 本工作介绍了一种符合状态空间模型（SSM）原则的共振发放（RAF）神经元电路，该电路在22nm FD-SOI技术下实现，并保留了事件驱动通信的效率。


<details>
  <summary>Details</summary>
Motivation: 为了将有效的SSM线性递推原理与具有稀疏事件驱动通信的RAF神经元结合，同时克服早期RAF电路的非线性耦合和工艺敏感性问题。

Method: 设计并制造了一种基于22nm FD-SOI技术的RAF神经元电路，分析了其动态特性、线性度以及对工艺、电压和温度（PVT）变化的鲁棒性，并在系统级模拟中评估了其在关键词识别任务中的性能。

Result: 所提出的RAF神经元电路在系统级模拟中被用于关键词识别任务，并且其非理想特性并未对性能产生负面影响，同时在功耗、性能和面积方面表现出良好的权衡。

Conclusion: RAF神经元是用于神经形态硬件的稳健且节能的计算基元。

Abstract: Oscillatory dynamics have recently proven highly effective in machine learning (ML), particularly through State-Space-Models (SSM) that leverage structured linear recurrences for long-range temporal processing. Resonate-and-Fire neurons capture such oscillatory behavior in a spiking framework, offering strong expressivity with sparse event-based communication. While early analog RAF circuits employed nonlinear coupling and suffered from process sensitivity, modern ML practice favors linear recurrence. In this work, we introduce a resonate-and-fire (RAF) neuron, built in 22nm Fully-Depleted Silicon-on-Insulator technology, that aligns with SSM principles while retaining the efficiency of spike-based communication. We analyze its dynamics, linearity, and resilience to Process, Voltage, and Temperature variations, and evaluate its power, performance, and area trade-offs. We map the characteristics of our circuit into a system-level simulation where our RAF neuron is utilized in a keyword-spotting task, showing that its non-idealities do not hinder performance. Our results establish RAF neurons as robust, energy-efficient computational primitives for neuromorphic hardware.

</details>


### [314] [ISAC with Affine Frequency Division Multiplexing: An FMCW-Based Signal Processing Perspective](https://arxiv.org/abs/2511.12308)
*Jiajun Zhu,Yanqun Tang,Cong Yi,Haoran Yin,Yuanhan Ni,Fan Liu,Zhiqiang Wei,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本论文研究了高移动性集成传感与通信（ISAC）中，从雷达波形角度出发的仿射频分复用（AFDM）传感潜力。


<details>
  <summary>Details</summary>
Motivation: 从雷达波形角度研究高移动性ISAC中AFDM的传感潜力。

Method: 提出了一种新颖的参数选择标准，建立了AFDM子载波与奈奎斯特采样调频连续波（FMCW）之间的精确数学等价性，并构建了DD-DAFT域中的输入输出模型，最后设计了两种匹配滤波传感算法。

Result: 仿真结果表明，所提出的算法能够实现有效的无导频传感，并展示了传感性能、通信开销和计算复杂度之间的基本权衡。AFDM在大多数场景下优于经典的AFDM及其变体。

Conclusion: AFDM在集成传感与通信（ISAC）在高移动性场景下具有优越的传感潜力，所提出的方法和算法能够有效解决DD耦合问题并实现高性能的传感。

Abstract: This paper investigates the sensing potential of affine frequency division multiplexing (AFDM) in high-mobility integrated sensing and communication (ISAC) from the perspective of radar waveforms. We introduce an innovative parameter selection criterion that establishes a precise mathematical equivalence between AFDM subcarriers and Nyquist-sampled frequency-modulated continuous-wave (FMCW). This connection not only provides a clear physical insight into AFDM's sensing mechanism but also enables a direct mapping from the DAFT index to delay-Doppler (DD) parameters of wireless channels. Building on this, we develop a novel input-output model in a DD-parameterized DAFT (DD-DAFT) domain for AFDM, which explicitly reveals the inherent DD coupling effect arising from the chirp-channel interaction. Subsequently, we design two matched-filtering sensing algorithms. The first is performed in the time-frequency domain with low complexity, while the second is operated in the DD-DAFT domain to precisely resolve the DD coupling. Simulations show that our algorithms achieve effective pilot-free sensing and demonstrate a fundamental trade-off between sensing performance, communication overhead, and computational complexity. The proposed AFDM outperforms classical AFDM and other variants in most scenarios.

</details>


### [315] [Toward ISAC-empowered subnetworks: Cooperative localization and iterative node selection](https://arxiv.org/abs/2511.12348)
*Mostafa Nozari,Israel Leyva-Mayorga,Fabio Saggese,Gilberto Berardinelli*

Main category: eess.SP

TL;DR: 提出一种低复杂度迭代节点选择算法，用于在资源受限情况下最大化ISAC子网的定位精度，实现了高精度和高吞吐量的权衡。


<details>
  <summary>Details</summary>
Motivation: 解决集成传感与通信（ISAC）赋能的子网中，单站目标定位的传感-通信权衡问题。

Method: 提出一种低复杂度迭代节点选择算法，该算法利用子网部署的空间分集，并动态优化传感子集以在资源受限的情况下最大化定位精度。

Result: 在加性白高斯噪声（AWGN）信道中，算法在仅三次迭代内实现了低于7厘米的精度，与最优基准相比提高了97%以上。增加空间分集（通过更多天线和子网）可提高传感鲁棒性，尤其是在衰落信道中。量化了传感-通信权衡，表明减少传感迭代次数和传感子网数量可以在牺牲定位精度的前提下提高吞吐量。

Conclusion: 所提出的低复杂度迭代节点选择算法在ISAC子网中有效解决了传感-通信权衡问题，能够在高精度和高吞吐量之间取得良好的平衡。

Abstract: This paper tackles the sensing-communication trade-off in integrated sensing and communication (ISAC)-empowered subnetworks for mono-static target localization. We propose a low-complexity iterative node selection algorithm that exploits the spatial diversity of subnetwork deployments and dynamically refines the set of sensing subnetworks to maximize localization accuracy under tight resource constraints. Simulation results show that our method achieves sub-7 cm accuracy in additive white Gaussian noise (AWGN) channels within only three iterations, yielding over 97% improvement compared to the best-performing benchmark under the same sensing budget. We further demonstrate that increasing spatial diversity through additional antennas and subnetworks enhances sensing robustness, especially in fading channels. Finally, we quantify the sensing-communication trade-off, showing that reducing sensing iterations and the number of sensing subnetworks improves throughput at the cost of reduced localization precision.

</details>


### [316] [Cross-Layer Design for Near-Field mmWave Beam Management and Scheduling under Delay-Sensitive Traffic](https://arxiv.org/abs/2511.12470)
*Zijun Wang,Anjali Omer,Jacob Chakareski,Nicholas Mastronarde,Rui Zhang*

Main category: eess.SP

TL;DR: 下一代无线网络将依赖毫米波/亚太赫兹频谱和极大规模天线阵列（ELAA）。这将推动其运行进入近场，导致远场波束管理性能下降，波束训练成本更高且需要更频繁地进行。由于 ELAA 训练和数据传输会消耗能量，而训练会影响服务时间，因此我们提出了一个跨层控制问题，将物理层波束管理与 MAC 层服务相结合，以处理延迟敏感流量。控制器在分配传输功率的同时，决定何时重新训练以及训练的强度（导频数量和稀疏度），明确地平衡导频开销、数据阶段速率和能量，以减少待传输的 MAC 层帧/数据包的排队延迟。我们采用深度强化学习来解决部分可观察马尔可夫决策过程模型。在具有现实近场信道、不同移动性和流量负载的模拟中，所学策略在可比的能量消耗下，性能优于强大的 5G-NR 风格基线：吞吐量比 DFT 扫描高 85.5%，溢出率降低 78%。这些结果表明，通过一种考虑开销和适应流量的近场波束管理实用方法，可以为数字孪生、空间计算和沉浸式通信等新兴的低延迟、高吞吐量下一代应用带来启示。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络将依赖毫米波/亚太赫兹频谱和极大规模天线阵列（ELAA），这将导致其运行进入近场。在这种情况下，传统的远场波束管理性能会下降，并且波束训练的成本会增加，需要更频繁地进行。由于 ELAA 的训练和数据传输会消耗能量，并且训练会影响服务时间，因此需要一种新的方法来解决这一问题。

Method: 提出一个跨层控制问题，将物理层波束管理与 MAC 层服务相结合，以处理延迟敏感流量。控制器在分配传输功率的同时，决定何时重新训练以及训练的强度（导频数量和稀疏度），明确地平衡导频开销、数据阶段速率和能量，以减少待传输的 MAC 层帧/数据包的排队延迟。该问题被建模为一个部分可观察马尔可夫决策过程，并使用深度强化学习进行求解。

Result: 在具有现实近场信道、不同移动性和流量负载的模拟中，所学策略在可比的能量消耗下，性能优于强大的 5G-NR 风格基线：吞吐量比 DFT 扫描高 85.5%，溢出率降低 78%。

Conclusion: 所学策略表明，存在一种实用的、考虑开销和适应流量的近场波束管理方法，这对于数字孪生、空间计算和沉浸式通信等新兴的低延迟、高吞吐量下一代应用具有重要意义。

Abstract: Next-generation wireless networks will rely on mmWave/sub-THz spectrum and extremely large antenna arrays (ELAAs). This will push their operation into the near field where far-field beam management degrades and beam training becomes more costly and must be done more frequently. Because ELAA training and data transmission consume energy and training trades off with service time, we pose a cross-layer control problem that couples PHY-layer beam management with MAC-layer service under delay-sensitive traffic. The controller decides when to retrain and how aggressively to train (pilot count and sparsity) while allocating transmit power, explicitly balancing pilot overhead, data-phase rate, and energy to reduce the queueing delay of MAC-layer frames/packets to be transmitted. We model the problem as a partially observable Markov decision process and solve it with deep reinforcement learning. In simulations with a realistic near-field channel and varying mobility and traffic load, the learned policy outperforms strong 5G-NR--style baselines at a comparable energy: it achieves 85.5% higher throughput than DFT sweeping and reduces the overflow rate by 78%. These results indicate a practical path to overhead-aware, traffic-adaptive near-field beam management with implications for emerging low-latency, high-rate next-generation applications such as digital twin, spatial computing, and immersive communication.

</details>


### [317] [Lightweight Deep Autoencoder for ECG Denoising with Morphology Preservation and Near Real-Time Hardware Deployment](https://arxiv.org/abs/2511.12478)
*Mahdi Pirayesh Shirazi Nejad,David Hicks,Matt Valentine,Ki H. Chon*

Main category: eess.SP

TL;DR: 提出了一种轻量级深度学习ECG去噪框架，能在恶劣噪声条件下有效去噪，同时保持心律特征，并已在树莓派上验证其实时性。


<details>
  <summary>Details</summary>
Motivation: ECG信号常被噪声干扰，影响临床诊断，需要有效的去噪方法。

Method: 提出了一种紧凑的自编码器架构的轻量级深度学习去噪框架，在严苛噪声条件下（信噪比-5 dB）进行训练，并使用多个噪声配置和信噪比水平进行评估。

Result: 该模型在不同噪声和信噪比下表现出稳定去噪性能，最小化形态失真，有效抑制噪声同时保留VT和VF等心律失常特征。在树莓派4上的推理延迟为1.41秒/14秒ECG片段，证明了其在边缘设备的近实时应用潜力。

Conclusion: 该研究介绍了一种轻量级、硬件验证、形态可靠的ECG去噪解决方案，适用于便携式或可穿戴医疗保健系统。

Abstract: Electrocardiogram (ECG) signals are often degraded by various noise sources such as baseline wander, motion artifacts, and electromyographic interference, posing a major challenge in clinical settings. This paper presents a lightweight deep learning-based denoising framework, forming a compact autoencoder architecture. The model was trained under severe noise conditions (-5 dB signal-to-noise ratio (SNR)) using a rigorously partitioned dataset to ensure no data leakage and robust generalization. Extensive evaluations were conducted across seven noise configurations and three SNR levels (-5 dB, 0 dB, and +5 dB), showing consistent denoising performance with minimal morphological distortion, critical for maintaining diagnostic integrity. In particular, tests on clinically vital rhythms such as ventricular tachycardia (VT) and ventricular fibrillation (VF) confirm that the proposed model effectively suppresses noise without altering arrhythmic features essential for diagnosis. Visual and quantitative assessments, including SNR improvement, RMSE, and correlation metrics, validate the model's efficacy in preserving waveform fidelity. To demonstrate real-world applicability, the model was deployed on a Raspberry Pi 4 using TensorFlow Lite with float16 precision. Inference latency was measured at just 1.41 seconds per 14-second ECG segment, indicating feasibility for near-real-time use in edge devices. Overall, this study introduces a lightweight, hardware-validated, and morphologically reliable ECG denoising solution suitable for integration into portable or wearable healthcare systems.

</details>


### [318] [Robust Radar HRRP Recognition under Non-uniform Jamming Based on Complex-valued Frequency Attention Network](https://arxiv.org/abs/2511.12508)
*Yanhao Wang,Lei Wang,Jie Wang,Yimin Liu*

Main category: eess.SP

TL;DR: 提出了一种端到端训练的雷达目标识别网络，该网络通过CFA模块自适应地滤除干扰，提高了在复杂电磁环境下的识别精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 复杂的电磁环境和多干扰源导致接收信号的频率光谱非均匀，严重扭曲目标的高分辨距离多普勒（HRRP）特征，损害传统基于HRRP的目标识别方法的性能。

Method: 提出了一种新颖的端到端训练网络，其核心是CFA模块。该模块直接处理接收回波的复频谱，学习生成自适应的频域滤波器，为受强干扰的频段分配较低权重，同时保留干净频段的关键目标信息。过滤后的频谱随后被输入分类器骨干网络进行识别。

Result: 在模拟的HRRP数据和各种干扰组合的实验中，证明了该方法的优越性。尤其是在严重干扰条件下，该模型的识别精度比传统基于模型的方法高出近9%，计算开销可忽略不计。

Conclusion: 所提出的方法在严峻的干扰环境下表现出优异的性能和鲁棒性，能够有效应对复杂电磁环境下的雷达目标识别挑战。

Abstract: Complex electromagnetic environments, often containing multiple jammers with different jamming patterns, produce non-uniform jamming power across the frequency spectrum. This spectral non-uniformity directly induces severe distortion in the target's HRRP, consequently compromising the performance and reliability of conventional HRRP-based target recognition methods. This paper proposes a novel, end-to-end trained network for robust radar target recognition. The core of our model is a CFA module that operates directly on the complex spectrum of the received echo. The CFA module learns to generate an adaptive frequency-domain filter, assigning lower weights to bands corrupted by strong jamming while preserving critical target information in cleaner bands. The filtered spectrum is then fed into a classifier backbone for recognition. Experimental results on simulated HRRP data with various jamming combinations demonstrate our method's superiority. Notably, under severe jamming conditions, our model achieves a recognition accuracy nearly 9% higher than traditional model-based approaches, all while introducing negligible computational overhead. This highlights its exceptional performance and robustness in challenging jamming environments.

</details>


### [319] [A mixed-signal analogue front-end for brain-implantable neural interfaces using a digital fixed-point IIR filter and bulk offset cancellation](https://arxiv.org/abs/2511.12540)
*Dimitris Antoniadis,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 该论文提出了一种用于神经接口的混合信号前端（AFE），能够同时记录胞外动作电位（EAPs）和局部场电位（LFPs），并实现了低功耗、小面积和宽频带的神经信号监测。


<details>
  <summary>Details</summary>
Motivation: 推动用于神经系统疾病治疗的脑机接口技术发展，实现对神经信号的精确记录。

Method: 设计了一个混合信号模拟前端（AFE），包括低噪声放大器（LNA）和逐次逼近寄存器（SAR）模数转换器（ADC），并结合无限脉冲响应（IIR）切比雪夫II型低通滤波器来抑制低频成分。

Result: AFE实现了41.42dB的增益，每通道功耗为2.178uA，面积为0.198mm2，支持0.1Hz到10kHz的神经信号监测，输入参考噪声为3.59uVrms。

Conclusion: 所提出的AFE在功耗、面积和性能方面取得了优异的平衡，为开发更先进的临床脑机接口提供了基础。

Abstract: Advances in miniaturised implantable neural electronics have paved the way for therapeutic brain-computer interfaces with clinical potential for movement disorders, epilepsy, and broader neurological applications. This paper presents a mixed-signal analogue front end (AFE) designed to record both extracellular action potentials (EAPs) and local field potentials (LFPs). The feedforward path integrates a low-noise amplifier (LNA) and a successive-approximation-register (SAR) analogue-to-digital converter (ADC), while the feedback path employs a fixed-point infinite-impulse-response (IIR) Chebyshev Type II low-pass filter to suppress sub-mHz components via bulk-voltage control of the LNA input differential pair using two R-2R pseudo-resistor digital-to-analogue converters (DACs). The proposed AFE achieves up to 41.42dB gain, consumes 2.178uA per channel, occupies 0.198mm2 per channel, and supports neural signal monitoring from 0.1Hz to 10kHz with 3.59uVrms input-referred integrated noise.

</details>


### [320] [Near Field Tapering with Slepian Window: Balancing the Range Angle Sidelobe Trade off](https://arxiv.org/abs/2511.12733)
*Ahmed Hussain,Ahmed Sultan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: Slepian-based amplitude tapering effectively reduces near-field sidelobes in both range and angle, outperforming conventional methods.


<details>
  <summary>Details</summary>
Motivation: Conventional amplitude tapering is insufficient for simultaneous near-field axial and lateral sidelobe suppression, leading to interference susceptibility and degraded detection. This paper aims to address this limitation.

Method: A Slepian-based amplitude tapering approach is proposed to maximize mainlobe energy concentration, thereby reducing sidelobes in both axial and lateral dimensions.

Result: The proposed taper achieves approximately 24 dB of peak sidelobe suppression in the lateral domain and 10 dB in the axial domain compared to a uniform window.

Conclusion: The Slepian-based amplitude tapering approach is an effective method for simultaneously suppressing near-field sidelobes in both range and angle, significantly improving detection performance over conventional techniques.

Abstract: Near-field beamforming enables target discrimination in both range (axial) and angle (lateral) dimensions. Elevated sidelobes along either dimension, however, increase susceptibility to interference and degrade detection performance. Conventional amplitude tapering techniques, designed for far-field scenarios, cannot simultaneously suppress axial and lateral sidelobes in near-field. In this letter, we propose a Slepian-based amplitude tapering approach that maximizes mainlobe energy concentration, achieving significant sidelobe reduction in both dimensions. Numerical results show that the proposed taper improves peak sidelobe suppression by approximately 24 dB in the lateral domain and 10 dB in the axial domain compared to a conventional uniform window.

</details>


### [321] [Uniform Circular Arrays in Near-Field: Omnidirectional Coverage with Limited Capacity](https://arxiv.org/abs/2511.12750)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 均匀圆阵（UCA）与均匀直线阵（ULA）在辐射近场区域的角向覆盖范围和空间复用性能方面的比较。ULA在固定天线单元数下具有更优的性能，而UCA在固定孔径长度下具有轻微优势。


<details>
  <summary>Details</summary>
Motivation: 探究均匀圆阵（UCA）是否能通过增强的角向覆盖范围来提升空间复用性能，并与均匀直线阵（ULA）进行比较。

Method: 引入角度相关的度量标准——有效波束聚焦瑞利距离（EBRD），以界定波束聚焦有效的空间区域。推导了UCA的波束深度和EBRD的解析表达式，并通过仿真验证了分析结果。

Result: 在固定天线单元数下，ULA实现了更窄的波束深度和更长的EBRD，并获得了更高的总和速率。在固定孔径长度下，UCA的波束深度略窄，EBRD略长，性能增益不明显。

Conclusion: 固定天线单元数时，ULA在空间复用性能上优于UCA。固定孔径长度时，UCA性能提升有限。

Abstract: Recent studies suggest that uniform circular arrays (UCAs) can extend the angular coverage of the radiative near field region. This work investigates whether such enhanced angular coverage translates into improved spatial multiplexing performance when compared to uniform linear arrays (ULAs). To more accurately delineate the effective near field region, we introduce the effective beamfocusing Rayleigh distance (EBRD), an angle dependent metric that bounds the spatial region where beamfocusing remains effective. Closed form expressions for both beamdepth and EBRD are derived for UCAs. Our analysis shows that, under a fixed antenna element count, ULAs achieve narrower beamdepth and a longer EBRD than UCAs. Conversely, under a fixed aperture length, UCAs provide slightly narrower beamdepth and a marginally longer EBRD. Simulation results further confirm that ULAs achieve higher sum rate under the fixed element constraint, while UCAs offer marginal performance gain under the fixed aperture constraint.

</details>


### [322] [Distributed Multisensor ISAC](https://arxiv.org/abs/2511.13104)
*Reiner Thomä,Michael Döbereiner,Reza Faramarzahangari,Jonas Gedschold. Marc Francisco Colaco Miranda,Saw James Myint,Steffen Schieler,Christian Schneider,Sebastian Semper,Carsten Smeenk,Gerd Sommerkorn,Zhixiang Zhao*

Main category: eess.SP

TL;DR: ISAC可以利用未来的移动通信网络进行雷达类传感，从而实现分布式传感网络。


<details>
  <summary>Details</summary>
Motivation: ISAC的优势在于可以重复利用移动通信网络和无线接入资源，用于照明、传感、数据传输、计算和融合，从而构建可适应多种无线传感任务和服务的分布式、泛在传感网络。

Method: 本文提出了多传感器ISAC（MS-ISAC）的原理，将其与分布式MIMO雷达联系起来，并提出了一种通用的MS-ISAC架构。此外，本文还讨论了多径传播、多站目标反射率、多链路接入、协调、预编码、链路自适应方案、稀疏OFDMA/TDMA帧的延迟/多普勒估计和跟踪，以及合作无源相干定位（CPCL）、多传感器节点同步和分布式数据融合等问题。

Result: 本文介绍了MS-ISAC的基本架构原理和应用场景，并提出了相应的技术方案和解决策略。

Conclusion: MS-ISAC是未来移动通信网络的重要发展方向，具有广阔的应用前景。

Abstract: Integrated Sensing and Communications (ISAC) will become a service in future mobile communication networks. It enables the detection and recognition of passive objects and environments using radar-like sensing. The ultimate advantage is the reuse of the mobile network and radio access resources for scene illumination, sensing, data transportation, computation, and fusion. It enables building a distributed, ubiquitous sensing network that can be adapted for a variety of radio sensing tasks and services.
  In this article, we develop the principles of multi-sensor ISAC (MS-ISAC). MS-ISAC corresponds to multi-user MIMO communication, which in radar terminology is known as distributed MIMO radar. \ First, we develop basic architectural principles for MS-ISAC and link them to example use cases. We then propose a generic MS-ISAC architecture. After a brief reference to multipath propagation and multistatic target reflectivity issues, we outline multilink access, coordination, precoding and link adaptation schemes for MS-ISAC. Moreover, we review model-based estimation and tracking of delay~/~Doppler from sparse OFDMA~/~TDMA frames. We emphasize Cooperative Passive Coherent Location (CPCL) for bistatic correlation and synchronization. Finally, issues of multisensor node synchronization and distributed data fusion are addressed.

</details>


### [323] [Autonomous Sensing UAV for Accurate Multi-User Identification and Localization in Cellular Networks](https://arxiv.org/abs/2511.13171)
*Niccolò Paglierani,Francesco Linsalata,Vineeth Teeda,Davide Scazzoli,Maurizio Magarini*

Main category: eess.SP

TL;DR: 本篇论文提出了一个自主传感框架，利用非接入网的无人机（UAV）在5G网络中识别和定位多用户。


<details>
  <summary>Details</summary>
Motivation: 传统的空中节点需要与网络基础设施进行协调，而本研究提出的无人机则被设计为被动传感，无需网络协调，专注于捕获上行链路（UL）探测参考信号（SRS），以实现用户识别和定位。

Method: 该框架开发了一个完整的信号处理链，包括同步、用户识别和定位，所有这些都在无人机飞行过程中进行。系统能够自主规划和调整任务流程，在单次部署中估计多个用户的位置，并将飞行控制与实时传感相结合。

Result: 通过广泛的仿真和低空实验，在农村地区测试中定位误差小于3米，在城市模拟场景中定位误差小于8米，并能可靠地识别用户。

Conclusion: 研究结果证明了独立于基础设施的传感无人机在新兴低空经济（LAE）中作为核心元素的可能性，能够支持在紧急或连接受限环境中的态势感知和快速部署。

Abstract: This paper presents an autonomous sensing frame- work for identifying and localizing multiple users in Fifth Generation (5G) networks using an Unmanned Aerial Vehicle (UAV) that is not part of the serving access network. Unlike conventional aerial serving nodes, the proposed UAV operates passively and is dedicated solely to sensing. It captures Uplink (UL) Sounding Reference Signals (SRS), and requires virtually no coordination with the network infrastructure. A complete signal processing chain is proposed and developed, encompassing synchronization, user identification, and localization, all executed onboard UAV during flight. The system autonomously plans and adapts its mission workflow to estimate multiple user positions within a single deployment, integrating flight control with real-time sensing. Extensive simulations and a full-scale low- altitude experimental campaign validate the approach, showing localization errors below 3 m in rural field tests and below 8 m in urban simulation scenarios, while reliably identifying each user. The results confirm the feasibility of infrastructure-independent sensing UAVs as a core element of the emerging Low Altitude Economy (LAE), supporting situational awareness and rapid deployment in emergency or connectivity-limited environments.

</details>


### [324] [Pinching-Antenna-Enabled Cognitive Radio Networks](https://arxiv.org/abs/2511.13272)
*Zeyang Sun,Xidong Mu,Shuai Han,Sai Xu,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文提出了一种基于捏缩天线（PA）的认知无线电网络，通过优化波束成形和功率控制，实现了更高的频谱效率和干扰抑制。


<details>
  <summary>Details</summary>
Motivation: 在认知无线电网络中，需要解决频谱共享带来的干扰问题，并提高频谱利用效率。

Method: 提出了一种三阶段优化算法，分别优化PT和ST的捏缩波束成形和ST功率控制。在波束成形优化中，首先在波导层面确定PA的粗略位置，然后通过波长层面的优化实现信号的有效叠加和干扰抑制。对于ST功率控制，推导了闭式解。

Result: 仿真结果表明，PA相比传统天线能显著提高频谱效率，所提出的捏缩波束成形设计能有效抑制干扰，并且三阶段优化算法能够实现近乎正交的传输。

Conclusion: PA是一种有效的天线技术，可以显著提高认知无线电网络的频谱效率和性能。所提出的优化算法能够有效地解决频谱共享带来的挑战。

Abstract: This paper investigates a pinching-antenna (PA)-enabled cognitive radio network, where both the primary transmitter (PT) and secondary transmitter (ST) are equipped with a single waveguide and multiple PAs to facilitate simultaneous spectrum sharing. Under a general Ricean fading channel model, a closed-form analytical expression for the average spectral efficiency (SE) achieved by PAs is first derived. Based on this, a sum-SE maximization problem is formulated to jointly optimize the primary and secondary pinching beamforming, subject to system constraints on the transmission power budgets, minimum antenna separation requirements, and feasible PA deployment regions. To address this non-convex problem, a three-stage optimization algorithm is developed to sequentially optimize both the PT and ST pinching beamforming, and the ST power control. For the PT and ST pinching beamforming optimization, the coarse positions of PA are first determined at the waveguide-level. Then, wavelength-level refinements achieve constructive signal combination at the intended user and destructive superposition at the unintended user. For the ST power control, a closed-form solution is derived. Simulation results demonstrate that i) PAs can achieve significant SE improvements over conventional fixed-position antennas; ii) the proposed pinching beamforming design achieves effective interference suppression and superior performance for both even and odd numbers of PAs; and iii) the developed three-stage optimization algorithm enables nearly orthogonal transmission between the primary and secondary networks.

</details>


### [325] [Sensing-enabled Secure Rotatable Array System Enhanced by Multi-Layer Transmitting RIS](https://arxiv.org/abs/2511.13336)
*Maolin Li,Feng Shu,Minghao Chen,Cunhua Pan,Fuhui Zhou,Yongpeng Wu,Liang Yang*

Main category: eess.SP

TL;DR: 通过联合优化阵列姿态、天线分布、RIS相位矩阵和波束成形矩阵，提出了一种两阶段在线算法和一种基于多智能体深度确定性策略梯度的离线算法，以在双基站协作感知和通信的场景下，在满足感知信噪比要求和离散约束的条件下最大化保密率，并取得了约22%的保密率提升。


<details>
  <summary>Details</summary>
Motivation: 研究旋转阵列系统的安全性，尤其是在传感器位于主要通信链路上的情况下，以解决安全通信的挑战。

Method: 提出了一种两阶段在线算法（基于广义瑞利商）和一种离线算法（基于多智能体深度确定性策略梯度），用于联合优化阵列姿态、天线分布、多层RIS相位矩阵和波束成形矩阵，以解决非凸优化问题。

Result: 仿真结果表明，与不进行阵列姿态调整的传统方案相比，所提出的方法将保密率提高了约22%，并且阵列旋转比位置变化能带来更高的性能增益。

Conclusion: 所提出的优化方法和算法能够有效地提高双基站协作感知和通信系统的保密率，并且阵列旋转是一种有效的提升性能的手段。

Abstract: Programmable metasurfaces and adjustable antennas are promising technologies. The security of a rotatable array system is investigated in this paper. A dual-base-station (BS) architecture is adopted, in which the BSs collaboratively perform integrated sensing of the eavesdropper (the target) and communication tasks. To address the security challenge when the sensing target is located on the main communication link, the problem of maximizing the secrecy rate (SR) under sensing signal-to-interference-plus-noise ratio requirements and discrete constraints is formulated. This problem involves the joint optimization of the array pose, the antenna distribution on the array surface, the multi-layer transmitting RIS phase matrices, and the beamforming matrices, which is non-convex. To solve this challenge, an two-stage online algorithm based on the generalized Rayleigh quotient and an offline algorithm based on the Multi-Agent Deep Deterministic Policy Gradient are proposed. Simulation results validate the effectiveness of the proposed algorithms. Compared to conventional schemes without array pose adjustment, the proposed approach achieves approximately 22\% improvement in SR. Furthermore, array rotation provides higher performance gains than position changes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [326] [Learning Conjugate Direction Fields for Planar Quadrilateral Mesh Generation](https://arxiv.org/abs/2511.11865)
*Jiong Tao,Yong-Liang Yang,Bailin Deng*

Main category: cs.GR

TL;DR: 本文提出一种基于神经网络的数据驱动方法，用于从自由曲面和用户笔触中学习并融合特征，以高效生成符合用户指导的共轭方向场（CDF），进而生成平面四边形（PQ）网格，解决了传统方法计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过复杂的非线性优化来生成共轭方向场（CDF），以获得平面四边形（PQ）网格，但该过程计算成本高昂，难以实现交互式设计。

Method: 提出一种基于神经网络的数据驱动方法，学习自由曲面和用户笔触的特征，生成满足用户需求的CDF。

Result: 构建了一个包含50000多个自由曲面及其对应CDF的数据集，并提出了一套量化评估指标。实验证明了该方法在效率和效果上的优越性。

Conclusion: 所提出的数据驱动方法能够有效学习并融合曲面和用户笔触的特征，高效生成高质量的CDF，为PQ网格的生成提供了一种更优的解决方案。

Abstract: Planar quadrilateral (PQ) mesh generation is a key process in computer-aided design, particularly for architectural applications where the goal is to discretize a freeform surface using planar quad faces. The conjugate direction field (CDF) defined on the freeform surface plays a significant role in generating a PQ mesh, as it largely determines the PQ mesh layout. Conventionally, a CDF is obtained by solving a complex non-linear optimization problem that incorporates user preferences, i.e., aligning the CDF with user-specified strokes on the surface. This often requires a large number of iterations that are computationally expensive, preventing the interactive CDF design process for a desirable PQ mesh. To address this challenge, we propose a data-driven approach based on neural networks for controlled CDF generation. Our approach can effectively learn and fuse features from the freeform surface and the user strokes, and efficiently generate quality CDF respecting user guidance. To enable training and testing, we also present a dataset composed of 50000+ freeform surfaces with ground-truth CDFs, as well as a set of metrics for quantitative evaluation. The effectiveness and efficiency of our work are demonstrated by extensive experiments using testing data, architectural surfaces, and general 3D shapes.

</details>


### [327] [Locomotion in CAVE: Enhancing Immersion through Full-Body Motion](https://arxiv.org/abs/2511.12251)
*Xiaohui Li,Xiaolong Liu,Zhongchen Shi,Wei Chen,Liang Xie,Meng Gai,Jun Cao,Suxia Zhang,Erwei Yin*

Main category: cs.GR

TL;DR: 本研究提出了一种改进的CAVE虚拟现实沉浸式体验的移动框架，通过优化人体运动识别技术来增强沉浸感，并有效减少了晕动症。


<details>
  <summary>Details</summary>
Motivation: CAVE设备在提供沉浸式虚拟环境方面存在不足，主要是因为其移动方式的交互不自然，严重影响了用户体验和沉浸感。

Method: 研究构建了一个四面显示CAVE系统，采用基于Perspective-n-Point的动态方法校准相机，获取相机内外参数，并利用动作识别架构识别用户动作，最后将动作类别转化为图形工作站的显示效果。

Result: 通过用户研究验证，与传统方法相比，该方法在虚拟环境的真实感和自我临场感方面有显著提升，并有效减少了晕动症。

Conclusion: 本研究提出的基于人体运动识别的移动框架能够显著提升CAVE环境下的沉浸式移动体验，解决了现有技术中存在的交互不自然的问题，并对减少用户晕动症有积极作用。

Abstract: Cave Automatic Virtual Environment (CAVE) is one of the virtual reality (VR) immersive devices currently used to present virtual environments. However, the locomotion methods in the CAVE are limited by unnatural interaction methods, severely hindering the user experience and immersion in the CAVE. We proposed a locomotion framework for CAVE environments aimed at enhancing the immersive locomotion experience through optimized human motion recognition technology. Firstly, we construct a four-sided display CAVE system, then through the dynamic method based on Perspective-n-Point to calibrate the camera, using the obtained camera intrinsics and extrinsic parameters, and an action recognition architecture to get the action category. At last, transform the action category to a graphical workstation that renders display effects on the screen. We designed a user study to validate the effectiveness of our method. Compared to the traditional methods, our method has significant improvements in realness and self-presence in the virtual environment, effectively reducing motion sickness.

</details>


### [328] [TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting](https://arxiv.org/abs/2511.13009)
*Yong Liu,Keyang Ye,Tianjia Shao,Kun Zhou*

Main category: cs.GR

TL;DR: TR-Gaussians是一种新的3D高斯表示方法，用于高保真渲染室内场景中的平面透射和反射。


<details>
  <summary>Details</summary>
Motivation: 室内场景中普遍存在的平面透射和反射的渲染是一个具有挑战性的问题，需要能够处理视点相关的反射强度和复杂外观效果的方法。

Method: TR-Gaussians将3D高斯与可学习的反射平面相结合，显式地建模玻璃平面。透射和反射分量分别由3D高斯和镜像高斯表示，并根据基于菲涅尔效应的视点相关加权方案进行混合。采用多阶段优化框架进行优化。

Result: TR-Gaussians能够在包含平面透射和反射的场景中实现实时、高保真的新视图合成。

Conclusion: TR-Gaussians在定量和定性上均优于现有方法，能够忠实地合成复杂的外观效果，并在不同视点下保持一致。

Abstract: We propose Transmission-Reflection Gaussians (TR-Gaussians), a novel 3D-Gaussian-based representation for high-fidelity rendering of planar transmission and reflection, which are ubiquitous in indoor scenes. Our method combines 3D Gaussians with learnable reflection planes that explicitly model the glass planes with view-dependent reflectance strengths. Real scenes and transmission components are modeled by 3D Gaussians and the reflection components are modeled by the mirrored Gaussians with respect to the reflection plane. The transmission and reflection components are blended according to a Fresnel-based, view-dependent weighting scheme, allowing for faithful synthesis of complex appearance effects under varying viewpoints. To effectively optimize TR-Gaussians, we develop a multi-stage optimization framework incorporating color and geometry constraints and an opacity perturbation mechanism. Experiments on different datasets demonstrate that TR-Gaussians achieve real-time, high-fidelity novel view synthesis in scenes with planar transmission and reflection, and outperform state-of-the-art approaches both quantitatively and qualitatively.

</details>


### [329] [Force-Aware 3D Contact Modeling for Stable Grasp Generation](https://arxiv.org/abs/2511.13247)
*Zhuo Chen,Zhongqun Zhang,Yihua Cheng,Ales Leonardis,Hyung Jin Chang*

Main category: cs.GR

TL;DR: 本文提出了一种考虑接触力的稳定抓取生成方法，通过显式预测接触力来提高抓取稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有抓取生成方法主要关注物体几何结构，忽略了接触力，导致抓取稳定性不足。

Method: 1. 定义力感知接触表示，将法向力值离散化并进行独热编码。 2. 引入力感知稳定性约束，将稳定性问题定义为加速度最小化任务，并通过物理约束将稳定性与接触几何联系起来。 3. 提出一个姿态优化器，整合接触表示和稳定性约束，实现稳定抓取。

Result: 该方法在两个公开数据集上进行了实验，抓取稳定性指标提高了约20%，并且能够很好地适应新物体。

Conclusion: 所提出的力感知接触表示和稳定性约束能够识别出对稳定性至关重要的接触点，并为优化提供有效的初始化和指导，从而实现稳定抓取。

Abstract: Contact-based grasp generation plays a crucial role in various applications. Recent methods typically focus on the geometric structure of objects, producing grasps with diverse hand poses and plausible contact points. However, these approaches often overlook the physical attributes of the grasp, specifically the contact force, leading to reduced stability of the grasp. In this paper, we focus on stable grasp generation using explicit contact force predictions. First, we define a force-aware contact representation by transforming the normal force value into discrete levels and encoding it using a one-hot vector. Next, we introduce force-aware stability constraints. We define the stability problem as an acceleration minimization task and explicitly relate stability with contact geometry by formulating the underlying physical constraints. Finally, we present a pose optimizer that systematically integrates our contact representation and stability constraints to enable stable grasp generation. We show that these constraints can help identify key contact points for stability which provide effective initialization and guidance for optimization towards a stable grasp. Experiments are carried out on two public benchmarks, showing that our method brings about 20% improvement in stability metrics and adapts well to novel objects.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [330] [Collusion-proof Auction Design using Side Information](https://arxiv.org/abs/2511.12456)
*Sukanya Kudva,Anil Aswani*

Main category: cs.GT

TL;DR: 该论文研究了带合谋出价者的拍卖设计问题，提出了一种混合VCG（H-VCG）机制，该机制结合了VCG和限价机制，并利用合谋检测算法，在合谋存在的情况下提高了福利和收入保障。


<details>
  <summary>Details</summary>
Motivation: 经典的VCG机制在存在合谋时效率低下，而完全防合谋的机制效率不高。本研究旨在设计一种在合谋存在时也能获得良好福利和收入保障的拍卖机制。

Method: 首先，分析了合谋出价者在VCG机制下的策略行为，证明他们会通过压低价格来出价。然后，提出了一种混合VCG（H-VCG）机制，它将VCG应用于非合谋出价者，并将限价机制应用于合谋出价者，同时假设存在一个合谋检测算法。最后，通过数值实验评估了H-VCG机制的性能。

Result: 合谋出价者在VCG机制下会压低价格。H-VCG机制被证明是事后占优策略激励兼容（DSIC）的，并且在已知和未知的估值分布下都具有期望福利和收入的概率保证。数值实验表明，H-VCG的表现优于仅应用于非合谋出价者的VCG，并接近理想VCG机制的性能。

Conclusion: 提出了一种结合合谋检测的机制设计框架，为设计抗合谋拍卖提供了新的思路。H-VCG机制，在合谋存在的情况下能够提高福利和收入。

Abstract: We study the problem of auction design in the presence of bidder collusion. Specifically, we consider a multi-unit auction of identical items with single-minded bidders, where a subset of bidders may collude by coordinating bids and transferring payments and items among themselves. While the classical Vickrey-Clarke-Groves (VCG) mechanism achieves efficient and truthful outcomes, it is highly vulnerable to collusion. In contrast, fully collusion-proof mechanisms are limited to posted-price formats, which fail to guarantee even approximate efficiency. This paper aims to bridge this gap by designing auctions that achieve good welfare and revenue guarantees even when some bidders collude. We first characterize the strategic behavior of colluding bidders under VCG and prove that such bidders optimally bid shade: they never overbid or take additional items, but instead reduce the auction price. This characterization enables a Bulow-Klemperer type result: adding colluding bidders can only improve welfare and revenue relative to running VCG on the non-colluding group alone. We then propose a Hybrid VCG (H-VCG) mechanism that combines VCG applied to non-colluding bidders with a posted-price mechanism for colluding bidders, assuming access to a black-box collusion detection algorithm. We show that H-VCG is ex-post dominant-strategy incentive compatible (DSIC) and derive probabilistic guarantees on expected welfare and revenue under both known and unknown valuation distributions. Numerical experiments across several distributions demonstrate that H-VCG consistently outperforms VCG restricted to non-colluding bidders and approaches the performance of the ideal VCG mechanism assuming universal truthfulness. Our results provide a principled framework for incorporating collusion detection into mechanism design, offering a step toward collusion-resistant auctions.

</details>


### [331] [Perturbing Best Responses in Zero-Sum Games](https://arxiv.org/abs/2511.12523)
*Adam Dziwoki,Rostislav Horcik*

Main category: cs.GT

TL;DR: 对双对策和假想博弈中基于最佳响应的算法进行扰动分析，发现扰动能减少迭代次数，甚至达到对数级别。


<details>
  <summary>Details</summary>
Motivation: 研究在零和博弈中，扰动如何影响双对策和假想博弈这两种逼近纳什均衡的基于最佳响应的算法。

Method: 在计算最佳响应时引入了效用扰动。

Result: 证明了扰动可以减少这两种算法的迭代次数，在某些情况下，迭代次数甚至可以达到对数级别。

Conclusion: 虽然效用扰动计算成本高，但在具有内在结构的策略博弈中可以高效实现。

Abstract: This paper investigates the impact of perturbations on the best-response-based algorithms approximating Nash equilibria in zero-sum games, namely Double Oracle and Fictitious Play. More precisely, we assume that the oracle computing the best responses perturbs the utilities before selecting the best response. We show that using such an oracle reduces the number of iterations for both algorithms. For some cases, suitable perturbations ensure the expected number of iterations is logarithmic. Although the utility perturbation is computationally demanding as it requires iterating through all pure strategies, we demonstrate that one can efficiently perturb the utilities in games where pure strategies have further inner structure.

</details>


### [332] [Bandit Learning in Housing Markets](https://arxiv.org/abs/2511.12629)
*Shiyun Lin*

Main category: cs.GT

TL;DR: We introduce a statistical learning model for the housing market where preferences are learned through repeated interactions using the multi-player multi-armed bandit framework. We propose core regret as the market objective and achieve order-optimal regret bounds in both centralized and decentralized settings.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the lack of attention paid to housing market models where agent preferences are unknown and must be learned through repeated interactions, a common scenario in real-world exchange economies.

Method: We model the housing market as a multi-player multi-armed bandit problem where agents learn their preferences over goods from stochastic rewards. We analyze both centralized and decentralized learning approaches and derive regret bounds.

Result: We establish $O(N 	ext{ log } T / Δ^2)$ upper bounds on core regret for both centralized and decentralized approaches. For the decentralized setting, we also provide a matching lower bound, indicating that our proposed algorithm is order-optimal.

Conclusion: The paper demonstrates that it is possible to efficiently learn preferences and achieve core-stable allocations in housing markets even when preferences are initially unknown, with proposed algorithms being order-optimal in decentralized settings.

Abstract: The housing market, also known as one-sided matching market, is a classic exchange economy model where each agent on the demand side initially owns an indivisible good (a house) and has a personal preference over all goods. The goal is to find a core-stable allocation that exhausts all mutually beneficial exchanges among subgroups of agents. While this model has been extensively studied in economics and computer science due to its broad applications, little attention has been paid to settings where preferences are unknown and must be learned through repeated interactions. In this paper, we propose a statistical learning model within the multi-player multi-armed bandit framework, where players (agents) learn their preferences over arms (goods) from stochastic rewards. We introduce the notion of core regret for each player as the market objective. We study both centralized and decentralized approaches, proving $O(N \log T / Δ^2)$ upper bounds on regret, where $N$ is the number of players, $T$ is the time horizon and $Δ$ is the minimum preference gap among players. For the decentralized setting, we also establish a matching lower bound, demonstrating that our algorithm is order-optimal.

</details>


### [333] [Rethinking Data Value: Asymmetric Data Shapley for Structure-Aware Valuation in Data Markets and Machine Learning Pipelines](https://arxiv.org/abs/2511.12863)
*Xi Zheng,Yinghui Huang,Xiangyu Chang,Ruoxi Jia,Yong Tan*

Main category: cs.GT

TL;DR: ADS是一种新的数据估值框架，用于解决传统DS对称性假设的局限性，考虑了现代ML/AI流程中的方向和时间依赖性。


<details>
  <summary>Details</summary>
Motivation: 传统数据Shapley（DS）在数据估值中至关重要，但其对称性假设无法捕捉现代ML/AI工作流中的方向和时间依赖性。

Method: 提出不对称数据Shapley（ADS）框架，通过仅在与应用特定数据组排序一致的排列上平均边际贡献来放松对称性，同时保持效率、线性、组内对称性和跨组的方向优先性。开发了两种计算方法：蒙特卡洛估计器（MC-ADS）和k近邻代理（KNN-ADS）。

Result: ADS在具有方向和时间依赖性的代表性环境中，通过区分新颖贡献与冗余贡献并尊重训练的顺序性，一致优于基准方法。

Conclusion: ADS是一个原则性强且实用的方法，可用于数据市场和复杂ML/AI流程中的公平数据估值。

Abstract: Rigorous valuation of individual data sources is critical for fair compensation in data markets, informed data acquisition, and transparent development of ML/AI models. Classical Data Shapley (DS) provides a essential axiomatic framework for data valuation but is constrained by its symmetry axiom that assumes interchangeability of data sources. This assumption fails to capture the directional and temporal dependencies prevalent in modern ML/AI workflows, including the reliance of duplicated or augmented data on original sources and the order-specific contributions in sequential pipelines such as federated learning and multi-stage LLM fine tuning. To address these limitations, we introduce Asymmetric Data Shapley (ADS), a structure-aware data valuation framework for modern ML/AI pipelines. ADS relaxes symmetry by averaging marginal contributions only over permutations consistent with an application-specific ordering of data groups. It preserves efficiency and linearity, maintains within group symmetry and directional precedence across groups, and reduces to DS when the ordering collapses to a single group. We develop two complementary computational procedures for ADS: (i) a Monte Carlo estimator (MC-ADS) with finite-sample accuracy guarantees, and (ii) a k-nearest neighbor surrogate (KNN-ADS) that is exact and efficient for KNN predictors. Across representative settings with directional and temporal dependence, ADS consistently outperforms benchmark methods by distinguishing novel from redundant contributions and respecting the sequential nature of training. These results establish ADS as a principled and practical approach to equitable data valuation in data markets and complex ML/AI pipelines.

</details>


### [334] [Resilient and Efficient Allocation for Large-Scale Autonomous Fleets via Decentralized Coordination](https://arxiv.org/abs/2511.12879)
*Ashish Kumar Perukari,Polina Khoroshevskaya*

Main category: cs.GT

TL;DR: 该论文提出了一种能够处理不确定性、可扩展的资源分配方法，用于大规模自主车队管理。


<details>
  <summary>Details</summary>
Motivation: 大规模自主车队在资源（如能源、燃料、充电桩、维护、时间窗口、通信带宽）分配上面临速度、弹性和不确定性带来的挑战。

Method: 提出了一种结合了分布预测和去中心化协调的、感知侧信息的资源分配方法。利用局部侧信息构建每个代理的风险模型，并通过故障机会约束进行耦合。使用轻量级的共识-ADMM算法在稀疏通信图上协调代理，以实现接近集中式的性能并避免单点故障。

Result: 在真实城市道路网络和卫星星座上进行了验证，与贪婪、无侧信息和最优集中式基线进行了比较。与基线相比，该方法在相同成本下将故障率降低了 30-55%，并且能够以高概率保证可行性，同时还能扩展到数千个代理，运行时长接近线性。

Conclusion: 该方法通过结合侧信息、分布预测和去中心化协调，成功解决了大规模自主车队资源分配的挑战，显著降低了故障率，并保证了模型的可扩展性和鲁棒性。

Abstract: Operating large autonomous fleets demands fast, resilient allocation of scarce resources (such as energy and fuel, charger access and maintenance slots, time windows, and communication bandwidth) under uncertainty. We propose a side-information-aware approach for resource allocation at scale that combines distributional predictions with decentralized coordination. Local side information shapes per-agent risk models for consumption, which are coupled through chance constraints on failures. A lightweight consensus-ADMM routine coordinates agents over a sparse communication graph, enabling near-centralized performance while avoiding single points of failure. We validate the framework on real urban road networks with autonomous vehicles and on a representative satellite constellation, comparing against greedy, no-side-information, and oracle central baselines. Our method reduces failure rates by 30-55% at matched cost and scales to thousands of agents with near-linear runtime, while preserving feasibility with high probability.

</details>


### [335] [An FPTAS for 7/9-Approximation to Maximin Share Allocations](https://arxiv.org/abs/2511.13056)
*Xin Huang,Shengwei Zhou*

Main category: cs.GT

TL;DR: 我们提出了一种新的算法，在具有加性估值的不可分割物品的最高保证份额（MMS）分配中实现了 7/9 的近似比，优于当前最佳的 10/13 的近似比。


<details>
  <summary>Details</summary>
Motivation: 在具有加性估值的不可分割物品的最高保证份额（MMS）分配中，将近似比从 10/13 提高到 7/9。

Method: 开发了一种新的分析框架，并基于此框架设计了一种新的算法，同时还得到一个 FPTAS。

Result: 实现了 7/9 的近似比，并且得到了一个 7/9-ε 的 FPTAS，其运行时间为 1/ε * poly(n,m)。

Conclusion: 我们提出了一种更简单但近似比更高的算法，并在理论上提供了一个高效的近似方案。

Abstract: We present a new algorithm that achieves a $\frac{7}{9}$-approximation for the maximin share (MMS) allocation of indivisible goods under additive valuations, improving the current best ratio of $\frac{10}{13}$ (Heidari et al., SODA 2026). Building on a new analytical framework, we further obtain an FPTAS that achieves a $\frac{7}{9}-\varepsilon$ approximation in $\tfrac{1}{\varepsilon} \cdot \mathrm{poly}(n,m)$ time. Compared with prior work (Heidari et al., SODA 2026), our algorithm is substantially simpler.

</details>


### [336] [MEV in Multiple Concurrent Proposer Blockchains](https://arxiv.org/abs/2511.13080)
*Steven Landers,Benjamin Marsh*

Main category: cs.GT

TL;DR: 多提议者区块链中的MEV分析，考虑了并发性带来的新MEV渠道，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 分析在多个区块在最终执行顺序确定之前变得数据可用的多提议者区块链中的最大可提取价值（MEV）。

Method: 开发了延迟和包含的风险归一化模型，推导了延迟包络线M(τ)，并对审查、重复和拍卖博弈进行了均衡分析。

Result: 表明确定性优先DAG调度和考虑重复的支付可以消除相同tick的MEV，同时保持吞吐量。

Conclusion: 确定了简单的协议配置，可以在没有中心化构建者的情况下缓解MCP特定的提取。

Abstract: We analyze maximal extractable value in multiple concurrent proposer blockchains, where multiple blocks become data available before their final execution order is determined. This concurrency breaks the single builder assumption of sequential chains and introduces new MEV channels, including same tick duplicate steals, proposer to proposer auctions, and timing races driven by proof of availability latency. We develop a hazard normalized model of delay and inclusion, derive a closed form delay envelope \(M(τ)\), and characterize equilibria for censorship, duplication, and auction games. We show how deterministic priority DAG scheduling and duplicate aware payouts neutralize same tick MEV while preserving throughput, identifying simple protocol configurations to mitigate MCP specific extraction without centralized builders.

</details>


### [337] [The Publication Choice Problem](https://arxiv.org/abs/2511.13678)
*Haichuan Wang,Yifan Wu,Haifeng Xu*

Main category: cs.GT

TL;DR: 研究者在选择论文发表地点时会考虑如何最大化论文影响力，而这一决策又会反过来影响发表期刊的影响因子。本文提出了一个博弈论模型来分析这种双向互动关系，并证明了该模型存在唯一均衡解。研究结果表明，期刊的“重点推荐”标签可能会降低社区内其他期刊的整体影响力，而竞争力较弱的期刊则会产生相反的影响。


<details>
  <summary>Details</summary>
Motivation: 分析研究者发表选择与期刊影响因子之间的双向互动关系，以及“重点推荐”标签对期刊社区整体影响力的影响。

Method: 构建了一个博弈论模型（Publication Choice Problem），分析了其中存在的纯策略均衡及其唯一性，并在此基础上对均衡性质进行了刻画。

Result: 证明了Publication Choice Problem存在纯策略均衡，并且在二元研究者类型下是唯一的。研究了均衡性质如何揭示研究者的影响力水平。分析了“重点推荐”标签对期刊社区影响因子的影响，发现竞争激烈的期刊采用此标签可能降低社区整体影响力，而竞争力较弱的期刊则相反。

Conclusion: 研究者的发表选择与期刊影响力相互影响。期刊的“重点推荐”策略对社区整体影响力的影响取决于期刊本身的竞争力。

Abstract: Researchers strategically choose where to submit their work in order to maximize its impact, and these publication decisions in turn determine venues' impact factors. To analyze how individual publication choices both respond to and shape venue impact, we introduce a game-theoretic framework, coined the Publication Choice Problem, that captures this two-way interplay. We show the existence of a pure-strategy equilibrium in the Publication Choice Problem and its uniqueness under binary researcher types. Our characterizations of the equilibrium properties offer insights about what publication behaviors better indicate a researcher's impact level. Through equilibrium analysis, we further investigate how labeling papers with ``spotlight'' affects the impact factor of venues in the research community. Our analysis shows that competitive venue labeling top papers with ``spotlight'' may decrease the overall impact of other venues in the community, while less competitive venues with ``spotlight'' labeling have the opposite impact.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [338] [Enhancing PINN Accuracy for the RLW Equation: Adaptive and Conservative Approaches](https://arxiv.org/abs/2511.11638)
*Aamir Shehzad*

Main category: cs.LG

TL;DR: PINN在求解RLW方程时存在误差，本文提出自适应PINN和保守PINN两种改进方法，并通过三个基准测试验证了其有效性，结果表明PINN的有效性具有问题特异性。自适应PINN在处理复杂的非线性相互作用（如双孤子碰撞）方面优于保守PINN和标准PINN，而保守PINN在处理孤子传播和无浪镗演化等长期行为方面表现更好。研究还发现，强制执行守恒定律可能会损害高度非线性系统的优化，需要特殊的训练方法。改进后的PINN方法在各项测试中均能达到$O(10^{-5})$的精度，证明了PINN在无网格情况下求解复杂偏微分方程的潜力。


<details>
  <summary>Details</summary>
Motivation: 标准物理信息神经网络（PINN）在求解正则化长波（RLW）方程时存在较大的误差，因此需要改进PINN方法以提高其求解精度和适用性。

Method: 提出两种改进的PINN方法：一种是具有自适应损失加权的自适应方法，另一种是强制执行显式守恒定律的保守方法。通过三个基准测试（单孤子传播、双孤子相互作用、无浪镗演化）来评估这两种方法的有效性。

Result: 自适应PINN在解决复杂的非线性相互作用问题（如双孤子碰撞）方面显著优于保守PINN和标准PINN。保守PINN在解决涉及单孤子长期行为和无浪镗演化的问题方面表现更好。两种改进方法都能在$O(10^{-5})$的误差范围内获得精确解，证明了PINN的无网格求解能力。研究发现，强制执行守恒定律可能对高度非线性系统的优化产生负面影响。

Conclusion: PINN的有效性是问题特异性的。强制执行守恒定律并非总是能改善PINN的性能，并且可能损害高度非线性系统的优化。本文的研究结果为设计特定问题的PINN提供了指导。

Abstract: Standard physics-informed neural network implementations have produced large error rates when using these models to solve the regularized long wave (RLW) equation. Two improved PINN approaches were developed in this research: an adaptive approach with self-adaptive loss weighting and a conservative approach enforcing explicit conservation laws. Three benchmark tests were used to demonstrate how effective PINN's are as they relate to the type of problem being solved (i.e., time dependent RLW equation). The first was a single soliton traveling along a line (propagation), the second was the interaction between two solitons, and the third was the evolution of an undular bore over the course of $t=250$. The results demonstrated that the effectiveness of PINNs are problem specific. The adaptive PINN was significantly better than both the conservative PINN and the standard PINN at solving problems involving complex nonlinear interactions such as colliding two solitons. The conservative approach was significantly better at solving problems involving long term behavior of single solitons and undular bores. However, the most important finding from this research is that explicitly enforcing conservation laws may be harmful to optimizing the solution of highly nonlinear systems of equations and therefore requires special training methods. The results from our adaptive and conservative approaches were within $O(10^{-5})$ of established numerical solutions for the same problem, thus demonstrating that PINNs can provide accurate solutions to complex systems of partial differential equations without the need for a discretization of space or time (mesh free). Moreover, the finding from this research challenges the assumptions that conservation enforcement will always improve the performance of a PINN and provides researchers with guidelines for designing PINNs for use on specific types of problems.

</details>


### [339] [On the Dimension-Free Approximation of Deep Neural Networks for Symmetric Korobov Functions](https://arxiv.org/abs/2511.12398)
*Yulong Lu,Tong Mao,Jinchao Xu,Yahong Yang*

Main category: cs.LG

TL;DR: 深度神经网络在逼近对称Korobov函数方面表现出良好的收敛性和泛化能力，且不受维度诅咒的影响。


<details>
  <summary>Details</summary>
Motivation: 研究如何构建对称深度神经网络以逼近具有内在物理结构（如排列对称性）的函数，并提供其收敛性和泛化能力的理论保证。

Method: 构建对称深度神经网络来逼近对称Korobov函数，并推导其收敛率和泛化误差率。

Result: 证明了所提出的神经网络逼近对称Korobov函数的收敛率和常数前因子最多与环境维度成多项式关系，避免了维度诅咒。推导出的学习误差率也避免了维度诅咒。

Conclusion: 深度神经网络可以有效地学习对称Korobov函数，并且在理论上避免了维度诅咒，这对于处理具有对称性的高维函数具有重要意义。

Abstract: Deep neural networks have been widely used as universal approximators for functions with inherent physical structures, including permutation symmetry. In this paper, we construct symmetric deep neural networks to approximate symmetric Korobov functions and prove that both the convergence rate and the constant prefactor scale at most polynomially with respect to the ambient dimension. This represents a substantial improvement over prior approximation guarantees that suffer from the curse of dimensionality. Building on these approximation bounds, we further derive a generalization-error rate for learning symmetric Korobov functions whose leading factors likewise avoid the curse of dimensionality.

</details>


### [340] [Sound Logical Explanations for Mean Aggregation Graph Neural Networks](https://arxiv.org/abs/2511.11593)
*Matthew Morris,Ian Horrocks*

Main category: cs.LG

TL;DR: GNNs常用于知识图谱补全，但其黑盒性质限制了可解释性。本文研究了带有均值聚合和非负权重的GNN（MAGNN），并证明了其精确的单调规则类别，同时提供了一个受限的一阶逻辑片段来解释任何MAGNN预测。实验表明，非负权重可以提高或保持性能，并且生成的规则具有可解释性，甚至能暴露模型问题。


<details>
  <summary>Details</summary>
Motivation: GNNs常用于知识图谱补全，但其黑盒性质限制了可解释性。特别是，带有均值聚合函数的GNN缺乏可解释性和表达能力的结果。

Method: 研究带有均值聚合和非负权重的GNN（MAGNN），证明其精确的单调规则类别，并提供一个受限的一阶逻辑片段来解释任何MAGNN预测。

Result: 实验表明，非负权重可以提高或保持在标准归纳基准上的性能。生成的规则在实践中是可靠的，并且可以提供有见地的解释，甚至暴露模型中的问题。

Conclusion: 将GNN限制为具有非负权重的均值聚合可以获得可靠且有见地的解释，并有可能暴露模型中的问题。

Abstract: Graph neural networks (GNNs) are frequently used for knowledge graph completion. Their black-box nature has motivated work that uses sound logical rules to explain predictions and characterise their expressivity. However, despite the prevalence of GNNs that use mean as an aggregation function, explainability and expressivity results are lacking for them. We consider GNNs with mean aggregation and non-negative weights (MAGNNs), proving the precise class of monotonic rules that can be sound for them, as well as providing a restricted fragment of first-order logic to explain any MAGNN prediction. Our experiments show that restricting mean-aggregation GNNs to have non-negative weights yields comparable or improved performance on standard inductive benchmarks, that sound rules are obtained in practice, that insightful explanations can be generated in practice, and that the sound rules can expose issues in the trained models.

</details>


### [341] [Self-Organization of Attractor Landscapes in High-Capacity Kernel Logistic Regression Hopfield Networks](https://arxiv.org/abs/2511.13053)
*Akira Tamamori*

Main category: cs.LG

TL;DR: Kernel-based Hopfield networks store more information due to a geometric energy landscape, with a novel 


<details>
  <summary>Details</summary>
Motivation: The dynamical mechanism behind the storage capacity enhancement in kernel-based Hopfield networks is poorly understood.

Method: Geometric analysis of the network's energy landscape, introducing a novel metric 

Result: A rich phase diagram of attractor shapes was uncovered by varying kernel width and storage load. A key finding is the 

Conclusion: The study reveals a sophisticated self-organization mechanism where kernel-based Hopfield networks adaptively use inter-pattern interactions as a cooperative feedback control system to create a robust energy landscape, enhancing the stability of high-capacity associative memories and offering design principles.

Abstract: Kernel-based learning methods can dramatically increase the storage capacity of Hopfield networks, yet the dynamical mechanism behind this enhancement remains poorly understood. We address this gap by conducting a geometric analysis of the network's energy landscape. We introduce a novel metric, ``Pinnacle Sharpness,'' to quantify the local stability of attractors. By systematically varying the kernel width and storage load, we uncover a rich phase diagram of attractor shapes. Our central finding is the emergence of a ``ridge of optimization,'' where the network maximizes attractor stability under challenging high-load and global-kernel conditions. Through a theoretical decomposition of the landscape gradient into a direct ``driving'' force and an indirect ``feedback'' force, we reveal the origin of this phenomenon. The optimization ridge corresponds to a regime of strong anti-correlation between the two forces, where the direct force, amplified by the high storage load, dominates the opposing collective feedback force. This demonstrates a sophisticated self-organization mechanism: the network adaptively harnesses inter-pattern interactions as a cooperative feedback control system to sculpt a robust energy landscape. Our findings provide a new physical picture for the stability of high-capacity associative memories and offer principles for their design.

</details>


### [342] [Expressive Temporal Specifications for Reward Monitoring](https://arxiv.org/abs/2511.12808)
*Omar Adalat,Francesco Belardinelli*

Main category: cs.LG

TL;DR: 使用 LTLf 综合量化奖励监控器来解决强化学习中的稀疏奖励问题，并在性能和收敛性方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，设计信息丰富且密集的奖励函数是影响训练效率的关键挑战。稀疏奖励在长 horizonte 决策中尤其普遍。

Method: 利用量化线性时间逻辑（LTLf[F]）来综合奖励监控器，该监控器为运行时可观察的状态轨迹生成密集的奖励流。该框架独立于算法，仅依赖状态标注函数，并能处理非马尔可夫属性。

Result: 与传统的布尔监控器相比，量化监控器在最大化任务完成的量化度量和减少收敛时间方面表现出一致的优越性，并在某些环境中表现更好。

Conclusion: 通过提供细致的反馈，这些量化奖励监控器能够有效地指导智能体走向最优行为，并缓解稀疏奖励问题，从而提高强化学习的训练效率。

Abstract: Specifying informative and dense reward functions remains a pivotal challenge in Reinforcement Learning, as it directly affects the efficiency of agent training. In this work, we harness the expressive power of quantitative Linear Temporal Logic on finite traces (($\text{LTL}_f[\mathcal{F}]$)) to synthesize reward monitors that generate a dense stream of rewards for runtime-observable state trajectories. By providing nuanced feedback during training, these monitors guide agents toward optimal behaviour and help mitigate the well-known issue of sparse rewards under long-horizon decision making, which arises under the Boolean semantics dominating the current literature. Our framework is algorithm-agnostic and only relies on a state labelling function, and naturally accommodates specifying non-Markovian properties. Empirical results show that our quantitative monitors consistently subsume and, depending on the environment, outperform Boolean monitors in maximizing a quantitative measure of task completion and in reducing convergence time.

</details>


### [343] [A neural optimization framework for free-boundary diffeomorphic mapping problems and its applications](https://arxiv.org/abs/2511.11679)
*Zhehao Xu,Lok Ming Lui*

Main category: cs.LG

TL;DR: 传统的自由边界可微同胚优化方法存在对标称条件和梯度优化不兼容的限制。本文提出了一种基于谱拉普拉斯网络（SBN）的神经代理模型，并构建了SBN优化框架（SBN-Opt），以解决自由边界可微同胚优化问题，并显式控制局部几何畸变。实验证明，SBN-Opt在密度均衡映射和不一致表面配准方面优于传统算法。


<details>
  <summary>Details</summary>
Motivation: 自由边界可微同胚优化在表面映射问题中至关重要，但由于边界约束的缺失和需要保持大变形下的局部双射性，该问题一直难以解决。传统的数值最小二乘拟共形（LSQC）理论虽然提供了数学上的解决方案，但需要标称条件且不能用于基于梯度的优化。

Method: 提出了一种名为谱拉普拉斯网络（SBN）的神经代理模型，该模型将LSQC能量嵌入到多尺度网格-谱架构中。在此基础上，构建了SBN优化框架（SBN-Opt），用于优化自由边界可微同胚，并显式控制局部几何畸变。

Result: 通过在密度均衡映射和不一致表面配准上的广泛实验，证明了SBN-Opt在性能上优于传统的数值算法。

Conclusion: SBN-Opt为解决自由边界可微同胚优化问题提供了一种有效且可控的解决方案，尤其在需要显式控制局部几何畸变的场景下，展现出优越性。

Abstract: Free-boundary diffeomorphism optimization is a core ingredient in the surface mapping problem but remains notoriously difficult because the boundary is unconstrained and local bijectivity must be preserved under large deformation. Numerical Least-Squares Quasiconformal (LSQC) theory, with its provable existence, uniqueness, similarity-invariance and resolution-independence, offers an elegant mathematical remedy. However, the conventional numerical algorithm requires landmark conditioning, and cannot be applied into gradient-based optimization. We propose a neural surrogate, the Spectral Beltrami Network (SBN), that embeds LSQC energy into a multiscale mesh-spectral architecture. Next, we propose the SBN guided optimization framework SBN-Opt which optimizes free-boundary diffeomorphism for the problem, with local geometric distortion explicitly controllable. Extensive experiments on density-equalizing maps and inconsistent surface registration demonstrate our SBN-Opt's superiority over traditional numerical algorithms.

</details>


### [344] [Aspiration-based Perturbed Learning Automata in Games with Noisy Utility Measurements. Part A: Stochastic Stability in Non-zero-Sum Games](https://arxiv.org/abs/2511.11602)
*Georgios C. Chasparis*

Main category: cs.LG

TL;DR: 该论文提出了一种新的支付驱动的学习算法APLA，用于解决分布式优化问题。与传统的基于强化学习的方法不同，APLA考虑了玩家的期望水平，这有助于提高在存在噪声观测时的收敛性。该研究还通过将无限维马尔可夫链与有限维马尔可夫链进行比较，为通用非零和博弈中的随机稳定性提供了理论分析。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的优化方法在分布式设置中存在局限性，尤其是在多方弱循环博弈中，独立学习动态可能无法保证收敛到纯纳什均衡。现有研究仅限于一小类博弈。

Method: 提出了一种新的支付驱动的学习方案，称为“基于期望的受扰学习自动机”（APLA）。在该方案中，玩家选择动作的概率分布不仅受到重复选择的强化，还受到捕获玩家满意度水平的期望因素的影响。

Result: 在多方正效用博弈中，在存在噪声观测的情况下，对APLA进行了随机稳定性分析。该研究通过建立诱导的无限维马尔可夫链与有限维马尔可夫链的等价性，首次表征了通用非零和博弈中的随机稳定性。

Conclusion: APLA是一种新颖的支付驱动的学习算法，能够解决分布式优化问题，并且在存在噪声观测的情况下具有良好的随机稳定性。该研究为通用非零和博弈中的随机稳定性提供了理论分析。

Abstract: Reinforcement-based learning has attracted considerable attention both in modeling human behavior as well as in engineering, for designing measurement- or payoff-based optimization schemes. Such learning schemes exhibit several advantages, especially in relation to filtering out noisy observations. However, they may exhibit several limitations when applied in a distributed setup. In multi-player weakly-acyclic games, and when each player applies an independent copy of the learning dynamics, convergence to (usually desirable) pure Nash equilibria cannot be guaranteed. Prior work has only focused on a small class of games, namely potential and coordination games. To address this main limitation, this paper introduces a novel payoff-based learning scheme for distributed optimization, namely aspiration-based perturbed learning automata (APLA). In this class of dynamics, and contrary to standard reinforcement-based learning schemes, each player's probability distribution for selecting actions is reinforced both by repeated selection and an aspiration factor that captures the player's satisfaction level. We provide a stochastic stability analysis of APLA in multi-player positive-utility games under the presence of noisy observations. This is the first part of the paper that characterizes stochastic stability in generic non-zero-sum games by establishing equivalence of the induced infinite-dimensional Markov chain with a finite dimensional one. In the second part, stochastic stability is further specialized to weakly acyclic games.

</details>


### [345] [MACKO: Sparse Matrix-Vector Multiplication for Low Sparsity](https://arxiv.org/abs/2511.13061)
*Vladimír Macko,Vladimír Boža*

Main category: cs.LG

TL;DR: MACKO-SpMV是一种新的GPU优化格式和内核，可高效处理LLM中常见的低、非结构化稀疏性，实现显著的内存和速度提升，且无需专用硬件。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏矩阵-向量乘积（SpMV）方法在低且非结构化的稀疏性（30-90%）下表现不佳，限制了非结构化剪枝在稀疏大语言模型（LLM）中的应用。因此，需要一种新的方法来提高稀疏LLM的内存效率和计算速度。

Method: 提出了一种名为MACKO-SpMV的GPU优化格式和内核，它在减少存储开销的同时保持了与GPU执行模型的兼容性，无需专用硬件或预计算。

Result: 在50%稀疏度下，MACKO-SpMV实现了1.5倍的内存缩减和1.2-1.5倍的速度提升。与其他SpMV基线相比，它在cuSPARSE上实现了2.8-13.0倍的加速，在Sputnik上实现了1.9-2.6倍的加速，在DASP上实现了2.2-2.5倍的加速。将MACKO应用于剪枝后的Llama2-7B模型，在fp16精度下实现了1.5倍的内存缩减和1.5倍的推理加速。

Conclusion: MACKO-SpMV的提出使得在实际LLM应用中，50%稀疏度的非结构化剪枝成为一种可行且有益的优化手段。

Abstract: Sparse Matrix-Vector Multiplication (SpMV) is a fundamental operation in the inference of sparse Large Language Models (LLMs). Because existing SpMV methods perform poorly under the low and unstructured sparsity (30-90%) commonly observed in pruned LLMs, unstructured pruning provided only limited memory reduction and speedup. We propose MACKO-SpMV, a GPU-optimized format and kernel co-designed to reduce storage overhead while preserving compatibility with the GPU's execution model. This enables efficient SpMV for unstructured sparsity without specialized hardware units (e.g., tensor cores) or format-specific precomputation. Empirical results show that at sparsity 50%, MACKO is the first approach with significant 1.5x memory reduction and 1.2-1.5x speedup over dense representation. Speedups over other SpMV baselines: 2.8-13.0x over cuSPARSE, 1.9-2.6x over Sputnik, and 2.2-2.5x over DASP. Applied to Llama2-7B pruned with Wanda to sparsity 50%, it delivers 1.5x memory reduction and 1.5x faster inference at fp16 precision. Thanks to MACKO, unstructured pruning at 50% sparsity is now justified in real-world LLM workloads.

</details>


### [346] [On the Trade-Off Between Transparency and Security in Adversarial Machine Learning](https://arxiv.org/abs/2511.11842)
*Lucas Fenaux,Christopher Srinivasa,Florian Kerschbaum*

Main category: cs.LG

TL;DR: 透明度与安全性在AI对抗性攻击中可能存在冲突，攻击者在模仿防御者决策时更易成功，表明模型隐藏性对防御者有利。通过博弈论分析，发现仅了解防御模型是否被防御就可能损害其安全性，揭示了AI透明度与安全性的普遍权衡。


<details>
  <summary>Details</summary>
Motivation: 研究在对抗性环境中，透明度对AI代理的影响，特别是在可迁移对抗样本攻击的背景下。

Method: 通过大规模实证评估（九种攻击，181个模型）和博弈论（纳什均衡和斯塔克尔伯格博弈）来分析透明度与安全性的权衡。

Result: 攻击者在模仿防御者决策时攻击更成功，模型隐藏性对防御者有利。仅了解防御模型的防御状态就可能对其安全性造成损害。

Conclusion: AI系统的透明度可能与其安全性相冲突，并且博弈论可用于揭示这种冲突。

Abstract: Transparency and security are both central to Responsible AI, but they may conflict in adversarial settings. We investigate the strategic effect of transparency for agents through the lens of transferable adversarial example attacks. In transferable adversarial example attacks, attackers maliciously perturb their inputs using surrogate models to fool a defender's target model. These models can be defended or undefended, with both players having to decide which to use. Using a large-scale empirical evaluation of nine attacks across 181 models, we find that attackers are more successful when they match the defender's decision; hence, obscurity could be beneficial to the defender. With game theory, we analyze this trade-off between transparency and security by modeling this problem as both a Nash game and a Stackelberg game, and comparing the expected outcomes. Our analysis confirms that only knowing whether a defender's model is defended or not can sometimes be enough to damage its security. This result serves as an indicator of the general trade-off between transparency and security, suggesting that transparency in AI systems can be at odds with security. Beyond adversarial machine learning, our work illustrates how game-theoretic reasoning can uncover conflicts between transparency and security.

</details>


### [347] [Hierarchical Frequency-Decomposition Graph Neural Networks for Road Network Representation Learning](https://arxiv.org/abs/2511.12507)
*Jingtian Ma,Jingyuan Wang,Leong Hou U*

Main category: cs.LG

TL;DR: HiFiNet是一种新型分层频率分解图神经网络，通过构建多级虚拟节点和采用分解-更新-重建框架，结合拓扑感知图Transformer，有效融合了空间和频谱建模，解决了现有图神经网络在道路网络建模中的空间-频谱不匹配问题，并在多个下游任务中取得了优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在道路网络建模中存在空间-频谱不匹配问题，限制了其对道路网络复杂交互的建模能力。

Method: HiFiNet构建多级虚拟节点以实现局部频率分析，并采用分解-更新-重建框架，结合拓扑感知图Transformer来分别建模和融合低频和高频信号。

Result: HiFiNet在多个真实世界数据集的四个下游任务中，在捕获有效的道路网络表示方面展示了优越的性能和泛化能力。

Conclusion: HiFiNet成功地融合了空间和频谱建模，有效解决了道路网络建模中的挑战，并具有出色的性能和泛化能力。

Abstract: Road networks are critical infrastructures underpinning intelligent transportation systems and their related applications. Effective representation learning of road networks remains challenging due to the complex interplay between spatial structures and frequency characteristics in traffic patterns. Existing graph neural networks for modeling road networks predominantly fall into two paradigms: spatial-based methods that capture local topology but tend to over-smooth representations, and spectral-based methods that analyze global frequency components but often overlook localized variations. This spatial-spectral misalignment limits their modeling capacity for road networks exhibiting both coarse global trends and fine-grained local fluctuations. To bridge this gap, we propose HiFiNet, a novel hierarchical frequency-decomposition graph neural network that unifies spatial and spectral modeling. HiFiNet constructs a multi-level hierarchy of virtual nodes to enable localized frequency analysis, and employs a decomposition-updating-reconstruction framework with a topology-aware graph transformer to separately model and fuse low- and high-frequency signals. Theoretically justified and empirically validated on multiple real-world datasets across four downstream tasks, HiFiNet demonstrates superior performance and generalization ability in capturing effective road network representations.

</details>


### [348] [Efficient Calibration for Decision Making](https://arxiv.org/abs/2511.13699)
*Parikshit Gopalan,Konstantinos Stavropoulos,Kunal Talwar,Pranay Tankala*

Main category: cs.LG

TL;DR: 该论文提出了一种衡量预测器校准程度的新方法，称为校准决策损失（CDL），并研究了在特定函数族 K 下计算 CDL 的可处理性，为机器学习中的一些重校准方法提供了理论保证。


<details>
  <summary>Details</summary>
Motivation: Hu and Wu (FOCS'24) 定义了CDL来衡量预测器校准，但它在离线设置中难以计算。本研究旨在解决CDL的可计算性问题。

Method: 研究在特定结构化后处理函数族 K 下，CDL的可信息论和计算可处理性，并为自然函数类K推导了上下界。

Result: 在特定函数族 K 下，CDL 是可处理的，并推导出了相应的上下界，为一些常用的机器学习重校准方法提供了严格的保证。

Conclusion: 该研究为决策制定中的校准理论引入了新的定义和算法技术，并为一些广泛使用的机器学习重校准程序提供了严格的保证。

Abstract: A decision-theoretic characterization of perfect calibration is that an agent seeking to minimize a proper loss in expectation cannot improve their outcome by post-processing a perfectly calibrated predictor. Hu and Wu (FOCS'24) use this to define an approximate calibration measure called calibration decision loss ($\mathsf{CDL}$), which measures the maximal improvement achievable by any post-processing over any proper loss. Unfortunately, $\mathsf{CDL}$ turns out to be intractable to even weakly approximate in the offline setting, given black-box access to the predictions and labels.
  We suggest circumventing this by restricting attention to structured families of post-processing functions $K$. We define the calibration decision loss relative to $K$, denoted $\mathsf{CDL}_K$ where we consider all proper losses but restrict post-processings to a structured family $K$. We develop a comprehensive theory of when $\mathsf{CDL}_K$ is information-theoretically and computationally tractable, and use it to prove both upper and lower bounds for natural classes $K$. In addition to introducing new definitions and algorithmic techniques to the theory of calibration for decision making, our results give rigorous guarantees for some widely used recalibration procedures in machine learning.

</details>


### [349] [Convergence of Multiagent Learning Systems for Traffic control](https://arxiv.org/abs/2511.11654)
*Sayambhu Sen,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 本文从理论上分析了用于交通信号控制的多智能体强化学习（MARL）算法的收敛性，解决了先前研究中实证有效性与理论分析之间的差距。


<details>
  <summary>Details</summary>
Motivation:  Bangalore等城市快速的城市化进程导致了严重的交通拥堵，使得高效的交通信号控制（TSC）至关重要。虽然多智能体强化学习（MARL）已被证明能有效减少平均通勤延误，但对其稳定性和收敛性缺乏严格的理论分析。

Method: 利用随机近似方法，对多智能体交通信号控制算法的学习动态进行了正式分析，并证明了其在特定条件下可以收敛，从而将单智能体异步值迭代的收敛性证明扩展到了多智能体场景。

Result: 证明了所使用的多智能体强化学习算法在交通控制任务中具有收敛性。

Conclusion: 本文为多智能体强化学习在交通信号控制领域的应用提供了重要的理论基础，证明了该算法在特定条件下的收敛性。

Abstract: Rapid urbanization in cities like Bangalore has led to severe traffic congestion, making efficient Traffic Signal Control (TSC) essential. Multi-Agent Reinforcement Learning (MARL), often modeling each traffic signal as an independent agent using Q-learning, has emerged as a promising strategy to reduce average commuter delays. While prior work Prashant L A et. al has empirically demonstrated the effectiveness of this approach, a rigorous theoretical analysis of its stability and convergence properties in the context of traffic control has not been explored. This paper bridges that gap by focusing squarely on the theoretical basis of this multi-agent algorithm. We investigate the convergence problem inherent in using independent learners for the cooperative TSC task. Utilizing stochastic approximation methods, we formally analyze the learning dynamics. The primary contribution of this work is the proof that the specific multi-agent reinforcement learning algorithm for traffic control is proven to converge under the given conditions extending it from single agent convergence proofs for asynchronous value iteration.

</details>


### [350] [On the Fundamental Limits of LLMs at Scale](https://arxiv.org/abs/2511.12869)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Zeeshan Memon,Muhammad Ibtsaam Qadir,Sagnik Bhattacharya,Hassan Rizwan,Abhiram R. Gorle,Maahe Zehra Kazmi,Ayesha Mohsin,Muhammad Usman Rafique,Zihao He,Pulkit Mehta,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.LG

TL;DR: LLMs因规模扩大而受益匪浅，但面临幻觉、上下文压缩、推理下降、检索脆弱和多模态不对齐等基本限制。本研究提出了一个统一的、基于证明的框架，将这些限制与计算、信息和学习的基础理论联系起来，并提出了缓解方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的调查主要基于经验，缺乏对LLM规模化收益基本限制的严格理论分析。本研究旨在弥合这一差距，提供一个统一的、基于证明的框架，将LLM规模化的理论上限形式化。

Method: 本研究通过结合计算理论、信息论和统计学，提出了一个统一的框架。它运用了对角线化、可计算性和不可计算性、信息论约束、几何效应和计算效应来分析LLM的局限性。此外，还通过理论和经验证据相结合的方式，概述了规模化 LLM 的进展、饱和点和瓶颈。

Result: 本研究揭示了LLM规模化面临的五大基本限制：幻觉、上下文压缩、推理下降、检索脆弱和多模态不对齐。研究结果表明，对角线化保证了总会存在某些模型无法处理的输入，不可判定查询会导致所有可计算预测器出现无限的失败集。信息论和统计约束限制了可判定任务的准确性，有限的描述长度导致压缩错误，长尾事实知识需要极高的样本复杂度。几何和计算效应导致长上下文的压缩，基于似然的训练偏向于模式完成而非推理，检索在有限的token下会受到语义漂移和耦合噪声的影响，多模态规模化继承了浅层跨模态对齐。理论分析和经验证据都表明了规模化作用的边界。

Conclusion: 本研究提出了一个统一的、基于证明的框架，为LLM规模化提供了理论基础，解释了其局限性，并提出了实用的缓解方法，如边界预言检索、位置课程和稀疏或分层注意力。

Abstract: Large Language Models (LLMs) have benefited enormously from scaling, yet these gains are bounded by five fundamental limitations: (1) hallucination, (2) context compression, (3) reasoning degradation, (4) retrieval fragility, and (5) multimodal misalignment. While existing surveys describe these phenomena empirically, they lack a rigorous theoretical synthesis connecting them to the foundational limits of computation, information, and learning. This work closes that gap by presenting a unified, proof-informed framework that formalizes the innate theoretical ceilings of LLM scaling. First, computability and uncomputability imply an irreducible residue of error: for any computably enumerable model family, diagonalization guarantees inputs on which some model must fail, and undecidable queries (e.g., halting-style tasks) induce infinite failure sets for all computable predictors. Second, information-theoretic and statistical constraints bound attainable accuracy even on decidable tasks, finite description length enforces compression error, and long-tail factual knowledge requires prohibitive sample complexity. Third, geometric and computational effects compress long contexts far below their nominal size due to positional under-training, encoding attenuation, and softmax crowding. We further show how likelihood-based training favors pattern completion over inference, how retrieval under token limits suffers from semantic drift and coupling noise, and how multimodal scaling inherits shallow cross-modal alignment. Across sections, we pair theorems and empirical evidence to outline where scaling helps, where it saturates, and where it cannot progress, providing both theoretical foundations and practical mitigation paths like bounded-oracle retrieval, positional curricula, and sparse or hierarchical attention.

</details>


### [351] [Transformer-Based Scalable Multi-Agent Reinforcement Learning for Networked Systems with Long-Range Interactions](https://arxiv.org/abs/2511.13103)
*Vidur Sinha,Muhammed Ustaomeroglu,Guannan Qu*

Main category: cs.LG

TL;DR: STACCA是一个基于Transformer的MARL框架，用于网络控制，能够处理长期依赖并跨网络拓扑泛化。


<details>
  <summary>Details</summary>
Motivation: 现有MARL方法在处理网络控制中的长期依赖（如级联故障、疫情爆发）和跨网络拓扑的泛化能力方面存在局限性。

Method: STACCA采用共享Transformer Actor-Critic（STACCA）框架，包含一个集中的图Transformer Critic来建模长期依赖并提供系统级反馈，以及一个共享的图Transformer Actor来学习可泛化的策略。此外，STACCA还集成了一个新的反事实优势估计器来改进训练中的信用分配。

Result: 在疫情控制和谣言传播网络控制任务上，STACCA表现出改进的性能、网络泛化能力和可扩展性。

Conclusion: 基于Transformer的MARL架构有潜力实现大规模网络系统中的可扩展和可泛化控制。

Abstract: Multi-agent reinforcement learning (MARL) has shown promise for large-scale network control, yet existing methods face two major limitations. First, they typically rely on assumptions leading to decay properties of local agent interactions, limiting their ability to capture long-range dependencies such as cascading power failures or epidemic outbreaks. Second, most approaches lack generalizability across network topologies, requiring retraining when applied to new graphs. We introduce STACCA (Shared Transformer Actor-Critic with Counterfactual Advantage), a unified transformer-based MARL framework that addresses both challenges. STACCA employs a centralized Graph Transformer Critic to model long-range dependencies and provide system-level feedback, while its shared Graph Transformer Actor learns a generalizable policy capable of adapting across diverse network structures. Further, to improve credit assignment during training, STACCA integrates a novel counterfactual advantage estimator that is compatible with state-value critic estimates. We evaluate STACCA on epidemic containment and rumor-spreading network control tasks, demonstrating improved performance, network generalization, and scalability. These results highlight the potential of transformer-based MARL architectures to achieve scalable and generalizable control in large-scale networked systems.

</details>


### [352] [KForge: Program Synthesis for Diverse AI Hardware Accelerators](https://arxiv.org/abs/2511.13274)
*Taras Sereda,Tom St. John,Burak Bartan,Natalie Serrino,Sachin Katti,Zain Asgar*

Main category: cs.LG

TL;DR: KForge是一个平台无关的框架，利用两个协同工作的LLM驱动的代理来优化GPU内核，该框架通过迭代改进和跨平台知识转移，可以有效地为NVIDIA CUDA和Apple Metal等不同的并行计算平台生成和优化程序。


<details>
  <summary>Details</summary>
Motivation: GPU内核对ML性能至关重要，但在不同加速器上进行优化非常困难。

Method: KForge使用一个生成代理（通过编译和正确性反馈迭代改进程序）和一个性能分析代理（解释分析数据以指导优化），它们协同工作，仅需一次性示例即可针对新平台进行优化。该框架包含一个迭代改进系统，两个代理通过功能和优化通道协同工作，解释各种分析数据以生成指导程序综合的建议。

Result: 实验证明，生成代理能够有效地利用跨平台知识转移，并且KForge在NVIDIA CUDA和Apple Metal平台上均能有效进行程序综合，验证了其平台无关性。

Conclusion: KForge通过其创新的代理架构和跨平台知识转移能力，为在不同加速器上优化GPU内核提供了一种有效且平台无关的解决方案。

Abstract: GPU kernels are critical for ML performance but difficult to optimize across diverse accelerators. We present KForge, a platform-agnostic framework built on two collaborative LLM-based agents: a generation agent that produces and iteratively refines programs through compilation and correctness feedback, and a performance analysis agent that interprets profiling data to guide optimization. This agent-based architecture requires only a single-shot example to target new platforms.
  We make three key contributions: (1) introducing an iterative refinement system where the generation agent and performance analysis agent collaborate through functional and optimization passes, interpreting diverse profiling data (from programmatic APIs to GUI-based tools) to generate actionable recommendations that guide program synthesis for arbitrary accelerators; (2) demonstrating that the generation agent effectively leverages cross-platform knowledge transfer, where a reference implementation from one architecture substantially improves generation quality for different hardware targets; and (3) validating the platform-agnostic nature of our approach by demonstrating effective program synthesis across fundamentally different parallel computing platforms: NVIDIA CUDA and Apple Metal.

</details>


### [353] [Predicting Grain Growth in Polycrystalline Materials Using Deep Learning Time Series Models](https://arxiv.org/abs/2511.11630)
*Eliane Younes,Elie Hachem,Marc Bernacki*

Main category: cs.LG

TL;DR: 深度学习模型，特别是LSTM，可以准确预测晶粒生长过程中的晶粒尺寸分布，比传统模拟方法更高效。


<details>
  <summary>Details</summary>
Motivation: 晶粒生长对材料力学行为有重要影响，预测其在微观结构工程中至关重要。

Method: 利用RNN、LSTM、TCN和Transformer等深度学习模型，基于高保真模拟提取的均值场统计描述符，从历史晶粒尺寸分布预测未来的晶粒尺寸分布。

Result: LSTM模型达到了90%以上的高准确率和稳定的性能，能够进行长期的物理一致性预测，并将计算时间从每个序列约20分钟缩短到几秒钟。其他模型在长期预测时趋于发散。

Conclusion: 低维描述符和基于LSTM的预测方法在高效准确的微观结构预测方面具有巨大潜力，可用于数字孪生和工艺优化。

Abstract: Grain Growth strongly influences the mechanical behavior of materials, making its prediction a key objective in microstructural engineering. In this study, several deep learning approaches were evaluated, including recurrent neural networks (RNN), long short-term memory (LSTM), temporal convolutional networks (TCN), and transformers, to forecast grain size distributions during grain growth. Unlike full-field simulations, which are computationally demanding, the present work relies on mean-field statistical descriptors extracted from high-fidelity simulations. A dataset of 120 grain growth sequences was processed into normalized grain size distributions as a function of time. The models were trained to predict future distributions from a short temporal history using a recursive forecasting strategy. Among the tested models, the LSTM network achieved the highest accuracy (above 90\%) and the most stable performance, maintaining physically consistent predictions over extended horizons while reducing computation time from about 20 minutes per sequence to only a few seconds, whereas the other architectures tended to diverge when forecasting further in time. These results highlight the potential of low-dimensional descriptors and LSTM-based forecasting for efficient and accurate microstructure prediction, with direct implications for digital twin development and process optimization.

</details>


### [354] [Physics-Constrained Adaptive Neural Networks Enable Real-Time Semiconductor Manufacturing Optimization with Minimal Training Data](https://arxiv.org/abs/2511.12788)
*Rubén Darío Guerrero*

Main category: cs.LG

TL;DR: 该研究提出了一个物理约束自适应学习框架，用于解决EUV光刻优化中的计算危机，通过可学习参数自动校准电磁近似，同时最小化边缘放置误差（EPE），实现了亚纳米级精度。


<details>
  <summary>Details</summary>
Motivation: 传统的光刻优化方法计算成本高昂且精度不足，无法满足半导体行业对EUV光刻亚纳米级精度的需求，存在学术界的物理信息神经网络与工业界实际应用之间的差距。

Method: 提出一个物理约束自适应学习框架，集成了可微的菲涅尔衍射、材料吸收、点扩散函数模糊、相移和对比度调制模块，并结合直接几何图案匹配目标，通过可学习参数 $\boldsymbolθ = \{θ_d, θ_a, θ_b, θ_p, θ_c\}$ 自动校准电磁近似，以最小化模拟图像和目标光掩模之间的EPE。

Result: 在15个代表性图案上进行了训练，实现了0.664-2.536 nm范围内的EPE，平均比无物理约束的CNN基线提高了69.9%，且所需的训练样本数量减少了90%。

Conclusion: 物理约束自适应学习框架能够有效地解决EUV光刻优化中的计算挑战，通过联合物理校准和制造精度目标，为半导体制造业的实时优化奠定了基础。

Abstract: The semiconductor industry faces a computational crisis in extreme ultraviolet (EUV) lithography optimization, where traditional methods consume billions of CPU hours while failing to achieve sub-nanometer precision. We present a physics-constrained adaptive learning framework that automatically calibrates electromagnetic approximations through learnable parameters $\boldsymbolθ = \{θ_d, θ_a, θ_b, θ_p, θ_c\}$ while simultaneously minimizing Edge Placement Error (EPE) between simulated aerial images and target photomasks. The framework integrates differentiable modules for Fresnel diffraction, material absorption, optical point spread function blur, phase-shift effects, and contrast modulation with direct geometric pattern matching objectives, enabling cross-geometry generalization with minimal training data. Through physics-constrained learning on 15 representative patterns spanning current production to future research nodes, we demonstrate consistent sub-nanometer EPE performance (0.664-2.536 nm range) using only 50 training samples per pattern. Adaptive physics learning achieves an average improvement of 69.9\% over CNN baselines without physics constraints, with a significant inference speedup over rigorous electromagnetic solvers after training completion. This approach requires 90\% fewer training samples through cross-geometry generalization compared to pattern-specific CNN training approaches. This work establishes physics-constrained adaptive learning as a foundational methodology for real-time semiconductor manufacturing optimization, addressing the critical gap between academic physics-informed neural networks and industrial deployment requirements through joint physics calibration and manufacturing precision objectives.

</details>


### [355] [Benchmarking GNNs for OOD Materials Property Prediction with Uncertainty Quantification](https://arxiv.org/abs/2511.11697)
*Liqin Tan,Pin Chen,Menghan Liu,Xiean Wang,Jianhuan Cen,Qingsong Zou*

Main category: cs.LG

TL;DR: MatUQ是一个用于评估图神经网络(GNNs)在外部分布(OOD)材料性质预测和不确定性量化(UQ)的基准框架。


<details>
  <summary>Details</summary>
Motivation: 提出MatUQ基准框架，用于评估GNNs在外部分布材料性质预测和不确定性量化方面的性能。

Method: 使用SOAP-LOCO策略构建1,375个OOD预测任务，并采用结合蒙特卡洛Dropout和深度证据回归(DER)的统一不确定性感知训练协议，以及新的不确定性指标D-EviU。

Result: 不确定性感知训练显著提高了模型准确性（平均减少70.6%的误差），且不同GNN模型在不同任务上表现各异，没有单一模型能完全胜出。

Conclusion: 不确定性感知训练对提高OOD场景下的GNN模型性能至关重要，并且需要根据具体材料性质和分布变化来选择合适的模型。

Abstract: We present MatUQ, a benchmark framework for evaluating graph neural networks (GNNs) on out-of-distribution (OOD) materials property prediction with uncertainty quantification (UQ). MatUQ comprises 1,375 OOD prediction tasks constructed from six materials datasets using five OFM-based and a newly proposed structure-aware splitting strategy, SOAP-LOCO, which captures local atomic environments more effectively. We evaluate 12 representative GNN models under a unified uncertainty-aware training protocol that combines Monte Carlo Dropout and Deep Evidential Regression (DER), and introduce a novel uncertainty metric, D-EviU, which shows the strongest correlation with prediction errors in most tasks. Our experiments yield two key findings. First, the uncertainty-aware training approach significantly improves model prediction accuracy, reducing errors by an average of 70.6\% across challenging OOD scenarios. Second, the benchmark reveals that no single model dominates universally: earlier models such as SchNet and ALIGNN remain competitive, while newer models like CrystalFramer and SODNet demonstrate superior performance on specific material properties. These results provide practical insights for selecting reliable models under distribution shifts in materials discovery.

</details>


### [356] [Learning the relative composition of EEG signals using pairwise relative shift pretraining](https://arxiv.org/abs/2511.11940)
*Christopher Sandino,Sayeri Lala,Geeling Chau,Melika Ayoughi,Behrooz Mahasseni,Ellen Zippi,Ali Moin,Erdrin Azemi,Hanlin Goh*

Main category: cs.LG

TL;DR: PARS是一种新的自监督学习前置任务，通过预测随机采样脑电图窗口对之间的相对时间偏移来学习脑电图表示，在标签效率和迁移学习方面优于现有的前置任务。


<details>
  <summary>Details</summary>
Motivation: 现有的脑电图自监督学习方法主要使用掩码重建策略，可能无法有效捕捉长程依赖关系，而位置预测前置任务仍未被充分探索。

Method: 提出了一种名为PARS（配对相对移位）的新型前置任务，该任务通过预测随机采样脑电图窗口对之间的相对时间偏移来学习脑电图表示。

Result: 在各种脑电图解码任务上的综合评估表明，经过PARS预训练的Transformer在标签效率和迁移学习方面始终优于现有的预训练策略。

Conclusion: PARS为自监督脑电图表示学习建立了一个新的范例，能够有效捕捉神经信号中的相对时间组成和长程依赖关系。

Abstract: Self-supervised learning (SSL) offers a promising approach for learning electroencephalography (EEG) representations from unlabeled data, reducing the need for expensive annotations for clinical applications like sleep staging and seizure detection. While current EEG SSL methods predominantly use masked reconstruction strategies like masked autoencoders (MAE) that capture local temporal patterns, position prediction pretraining remains underexplored despite its potential to learn long-range dependencies in neural signals. We introduce PAirwise Relative Shift or PARS pretraining, a novel pretext task that predicts relative temporal shifts between randomly sampled EEG window pairs. Unlike reconstruction-based methods that focus on local pattern recovery, PARS encourages encoders to capture relative temporal composition and long-range dependencies inherent in neural signals. Through comprehensive evaluation on various EEG decoding tasks, we demonstrate that PARS-pretrained transformers consistently outperform existing pretraining strategies in label-efficient and transfer learning settings, establishing a new paradigm for self-supervised EEG representation learning.

</details>


### [357] [DIVIDE: A Framework for Learning from Independent Multi-Mechanism Data Using Deep Encoders and Gaussian Processes](https://arxiv.org/abs/2511.12745)
*Vivek Chawla,Boris Slautin,Utkarsh Pratiush,Dayakar Penumadu,Sergei Kalinin*

Main category: cs.LG

TL;DR: DIVIDE是一个框架，通过集成特定机制的深度编码器和结构化高斯过程，在联合潜空间中分离科学数据中的多个独立机制（如空间、类别或结构效应），从而能够进行可解释的、面向机制的预测和主动学习。


<details>
  <summary>Details</summary>
Motivation: 科学数据通常由空间、类别或结构效应等多种独立机制产生，这些机制的组合影响会掩盖它们各自的贡献。本研究旨在解决这一问题，提出一种能够分离这些影响的方法。

Method: 本研究引入了一个名为DIVIDE的框架，该框架通过在联合潜空间中集成特定机制的深度编码器和结构化高斯过程来实现解缠。该框架分离不同的机制，并使用高斯过程捕捉它们在具有校准不确定性的情况下的组合效应。该架构支持结构化先验，能够进行可解释的、面向机制的预测和高效的主动学习。

Result: DIVIDE在结合了类别图像块和非线性空间场的合成数据集、铁电模式的FerroSIM自旋晶格模拟以及PbTiO3薄膜的实验PFM滞后回线等基准测试中进行了演示。结果表明，DIVIDE能够分离机制、重现加性和缩放交互作用，并在噪声下保持鲁棒性。

Conclusion: DIVIDE框架成功地将科学数据中的独立生成因素分离开来，并能自然地扩展到包含多种响应（如机械、电磁或光学）的多功能数据集。

Abstract: Scientific datasets often arise from multiple independent mechanisms such as spatial, categorical or structural effects, whose combined influence obscures their individual contributions. We introduce DIVIDE, a framework that disentangles these influences by integrating mechanism-specific deep encoders with a structured Gaussian Process in a joint latent space. Disentanglement here refers to separating independently acting generative factors. The encoders isolate distinct mechanisms while the Gaussian Process captures their combined effect with calibrated uncertainty. The architecture supports structured priors, enabling interpretable and mechanism-aware prediction as well as efficient active learning. DIVIDE is demonstrated on synthetic datasets combining categorical image patches with nonlinear spatial fields, on FerroSIM spin lattice simulations of ferroelectric patterns, and on experimental PFM hysteresis loops from PbTiO3 films. Across benchmarks, DIVIDE separates mechanisms, reproduces additive and scaled interactions, and remains robust under noise. The framework extends naturally to multifunctional datasets where mechanical, electromagnetic or optical responses coexist.

</details>


### [358] [Chicken Swarm Kernel Particle Filter: A Structured Rejuvenation Approach with KLD-Efficient Sampling](https://arxiv.org/abs/2511.12222)
*Hangshuo Tian*

Main category: cs.LG

TL;DR: 本文研究了粒子滤波器（PF）与鸡群优化（CSO）算法结合用于粒子 पुनर्जन्म，以及 Kullback-Leibler 散度（KLD）采样用于自适应调整粒子集大小之间的理论互动。


<details>
  <summary>Details</summary>
Motivation: 现有的粒子滤波与智能优化算法（如CSO）的结合，以及KLD采样在自适应调整粒子集大小方面的应用，其理论相互作用尚不明确。

Method: 通过简化的模型分析CSO पुनर्जन्म步骤对粒子集分布的影响，提出CSO的适应性更新可近似视为均方收缩，导致粒子分布比基线PF更集中。利用Karamata不等式分析，表明CSO增强的PF（CPF）在满足相同统计误差边界时，所需的预期粒子数低于标准PF。

Result: 分析表明，CSO的适应性更新近似于均方收缩，使得粒子分布比基线PF更集中。研究推断，在CSO-PF（CPF）中，满足相同的统计误差界限所需的预期粒子数量可能少于标准PF。

Conclusion: 本文提供了一个理论框架，用于解释结合CSO和KLD采样技术时的计算效率，并为设计更有效的自适应滤波器提供了起点。

Abstract: Particle filters (PFs) are often combined with swarm intelligence (SI) algorithms, such as Chicken Swarm Optimization (CSO), for particle rejuvenation. Separately, Kullback--Leibler divergence (KLD) sampling is a common strategy for adaptively sizing the particle set. However, the theoretical interaction between SI-based rejuvenation kernels and KLD-based adaptive sampling is not yet fully understood.
  This paper investigates this specific interaction. We analyze, under a simplified modeling framework, the effect of the CSO rejuvenation step on the particle set distribution. We propose that the fitness-driven updates inherent in CSO can be approximated as a form of mean-square contraction. This contraction tends to produce a particle distribution that is more concentrated than that of a baseline PF, or in mathematical terms, a distribution that is plausibly more ``peaked'' in a majorization sense.
  By applying Karamata's inequality to the concave function that governs the expected bin occupancy in KLD-sampling, our analysis suggests a connection: under the stated assumptions, the CSO-enhanced PF (CPF) is expected to require a lower \emph{expected} particle count than the standard PF to satisfy the same statistical error bound. The goal of this study is not to provide a fully general proof, but rather to offer a tractable theoretical framework that helps to interpret the computational efficiency empirically observed when combining these techniques, and to provide a starting point for designing more efficient adaptive filters.

</details>


### [359] [Cross-Learning from Scarce Data via Multi-Task Constrained Optimization](https://arxiv.org/abs/2511.13680)
*Leopoldo Agorio,Juan Cerviño,Miguel Calvo-Fullana,Alejandro Ribeiro,Juan Andrés Bazerque*

Main category: cs.LG

TL;DR: 通过多任务联合学习来解决数据稀疏性问题，在有限数据下实现更准确的参数估计。


<details>
  <summary>Details</summary>
Motivation: 当数据有限时，学习到的模型无法泛化到训练中未见过的情况。本研究旨在克服数据稀疏性问题。

Method: 提出一个多任务的交叉学习框架，将联合参数估计表述为一个约束优化问题，约束条件确保了不同模型参数的相似性，从而实现跨任务的信息整合。

Result: 在具有高斯数据的受控框架下提供了理论保证，并在图像分类和传染病传播等真实数据应用中证明了交叉学习方法的有效性。

Conclusion: 该框架能够将在数据充足的任务中学到的知识迁移到数据稀疏的任务中，从而获得更准确、更可靠的参数估计，为从有限数据中进行参数推理的关键场景提供了解决方案。

Abstract: A learning task, understood as the problem of fitting a parametric model from supervised data, fundamentally requires the dataset to be large enough to be representative of the underlying distribution of the source. When data is limited, the learned models fail generalize to cases not seen during training. This paper introduces a multi-task \emph{cross-learning} framework to overcome data scarcity by jointly estimating \emph{deterministic} parameters across multiple, related tasks. We formulate this joint estimation as a constrained optimization problem, where the constraints dictate the resulting similarity between the parameters of the different models, allowing the estimated parameters to differ across tasks while still combining information from multiple data sources. This framework enables knowledge transfer from tasks with abundant data to those with scarce data, leading to more accurate and reliable parameter estimates, providing a solution for scenarios where parameter inference from limited data is critical. We provide theoretical guarantees in a controlled framework with Gaussian data, and show the efficiency of our cross-learning method in applications with real data including image classification and propagation of infectious diseases.

</details>


### [360] [The Anatomy of a Triton Attention Kernel](https://arxiv.org/abs/2511.11581)
*Burkhard Ringlein,Jan van Lunteren,Radu Stoica,Thomas Parnell*

Main category: cs.LG

TL;DR: 通过使用 Triton 语言开发 Paged Attention 核心，实现了跨 NVIDIA 和 AMD GPU 的 LLM 高效推理。


<details>
  <summary>Details</summary>
Motivation: 开发一个可以在不同硬件上运行、无需底层手动调优且效率高 LLM 推理平台。

Method: 使用 Triton 语言开发 Paged Attention 核心，并进行参数自动调优，然后集成到推理服务器。

Result: 在 NVIDIA 和 AMD GPU 上实现了先进的性能，将通用 Triton 注意力内核的性能从理论最佳的 19.7% 提高到 105.9%。

Conclusion: 开源特定领域语言（如 Triton）可以实现跨 GPU 供应商的模型可移植性和高性能。

Abstract: A long-standing goal in both industry and academia is to develop an LLM inference platform that is portable across hardware architectures, eliminates the need for low-level hand-tuning, and still delivers best-in-class efficiency. In this work, we demonstrate that portable, efficient cross-platform LLM inference is indeed possible and share our experience. We develop a state-of-the-art paged attention kernel, the core performance-critical component of many LLM deployments, that builds exclusively on the domain-specific just-in-time compiled language Triton to achieve state-of-the-art performance on both NVIDIA and AMD GPUs. We describe our high-level approach, the key algorithmic and system-level improvements, the parameter auto-tuning required to unlock efficiency, and the integrations into a popular inference server that are necessary to bring the performance of a generic Triton attention kernel from 19.7% of the state-of-the-art to 105.9%. Our results highlight how open-source domain-specific languages can be leveraged to unlock model portability across different GPU vendors.

</details>


### [361] [Parameter-Efficient and Personalized Federated Training of Generative Models at the Edge](https://arxiv.org/abs/2511.11585)
*Kabir Khan,Manju Sarkar,Anita Kar,Suresh Ghosh*

Main category: cs.LG

TL;DR: FedGen-Edge框架通过仅联合轻量级适配器来解决跨设备联邦设置中大型生成模型的训练和适应难题，显著减少了通信开销，提高了稳定性和个性化能力。


<details>
  <summary>Details</summary>
Motivation: 大型生成模型（如语言和扩散模型）在跨设备联邦环境中训练和适应困难，因为存在计算量大、通信开销高以及数据和系统异构性问题。

Method: 提出FedGen-Edge框架，将预训练的全局主干模型冻结，仅联合训练轻量级的客户端适配器。利用低秩适配（LoRA）技术将客户端更新约束在紧凑的子空间内，以减少通信量、稳定聚合并支持个性化。

Result: 在语言建模（PTB）和图像生成（CIFAR-10）任务上，FedGen-Edge的困惑度/FID更低，收敛速度更快。LoRA秩对性能影响显著，且本地迭代次数与客户端漂移之间存在权衡。

Conclusion: FedGen-Edge为在异构边缘设备上实现隐私保护、资源感知和个性化的生成式人工智能提供了一条切实可行的路径。

Abstract: Large generative models (for example, language and diffusion models) enable high-quality text and image synthesis but are hard to train or adapt in cross-device federated settings due to heavy computation and communication and statistical/system heterogeneity. We propose FedGen-Edge, a framework that decouples a frozen, pre-trained global backbone from lightweight client-side adapters and federates only the adapters. Using Low-Rank Adaptation (LoRA) constrains client updates to a compact subspace, which reduces uplink traffic by more than 99 percent versus full-model FedAvg, stabilizes aggregation under non-IID data, and naturally supports personalization because each client can keep a locally tuned adapter. On language modeling (PTB) and image generation (CIFAR-10), FedGen-Edge achieves lower perplexity/FID and faster convergence than strong baselines while retaining a simple FedAvg-style server. A brief ablation shows diminishing returns beyond moderate LoRA rank and a trade-off between local epochs and client drift. FedGen-Edge offers a practical path toward privacy-preserving, resource-aware, and personalized generative AI on heterogeneous edge devices.

</details>


### [362] [Federated Learning for Pediatric Pneumonia Detection: Enabling Collaborative Diagnosis Without Sharing Patient Data](https://arxiv.org/abs/2511.11714)
*Daniel M. Jimenez-Gutierrez,Enrique Zuazua,Joaquin Del Rio,Oleksii Sliusarenko,Xabi Uribe-Etxebarria*

Main category: cs.LG

TL;DR: 本研究利用联邦学习（FL）平台，使多家医院能够协作训练肺炎检测的胸部X光（CXR）分类器，同时保护数据隐私和就地性，并在不传输任何患者CXR数据的情况下，显著提高了模型的准确性和ROC-AUC。


<details>
  <summary>Details</summary>
Motivation: 早期准确地从CXR检测肺炎至关重要，但由于数据分散、医院间差异大、隐私法规严格以及数据传输成本高等限制，AI模型开发面临挑战。

Method: 研究采用Sherpa.ai FL平台，模拟跨医院协作，在非独立同分布（non-IID）数据集上训练CXR分类器，以解决真实世界中的数据变异性问题。

Result: 与单医院模型相比，联邦学习模型在准确率和ROC-AUC方面分别取得了0.900和0.966的成绩，性能显著提升了47.5%和50.0%。

Conclusion: 联邦学习能够实现跨医疗网络的高性能、泛化性强、安全且私密的肺炎检测，特别适用于数据稀疏的罕见病领域，能够加速诊断和治疗开发。

Abstract: Early and accurate pneumonia detection from chest X-rays (CXRs) is clinically critical to expedite treatment and isolation, reduce complications, and curb unnecessary antibiotic use. Although artificial intelligence (AI) substantially improves CXR-based detection, development is hindered by globally distributed data, high inter-hospital variability, and strict privacy regulations (e.g., HIPAA, GDPR) that make centralization impractical. These constraints are compounded by heterogeneous imaging protocols, uneven data availability, and the costs of transferring large medical images across geographically dispersed sites.
  In this paper, we evaluate Federated Learning (FL) using the Sherpa.ai FL platform, enabling multiple hospitals (nodes) to collaboratively train a CXR classifier for pneumonia while keeping data in place and private. Using the Pediatric Pneumonia Chest X-ray dataset, we simulate cross-hospital collaboration with non-independent and non-identically distributed (non-IID) data, reproducing real-world variability across institutions and jurisdictions. Our experiments demonstrate that collaborative and privacy-preserving training across multiple hospitals via FL led to a dramatic performance improvement achieving 0.900 Accuracy and 0.966 ROC-AUC, corresponding to 47.5% and 50.0% gains over single-hospital models (0.610; 0.644), without transferring any patient CXR. These results indicate that FL delivers high-performing, generalizable, secure and private pneumonia detection across healthcare networks, with data kept local. This is especially relevant for rare diseases, where FL enables secure multi-institutional collaboration without data movement, representing a breakthrough for accelerating diagnosis and treatment development in low-data domains.

</details>


### [363] [Fast 3D Surrogate Modeling for Data Center Thermal Management](https://arxiv.org/abs/2511.11722)
*Soumyendu Sarkar,Antonio Guillen-Perez,Zachariah J Carmichael,Avisek Naug,Refik Mert Cam,Vineet Gundecha,Ashwin Ramesh Babu,Sahand Ghorbanpour,Ricardo Luna Gutierrez*

Main category: cs.LG

TL;DR: 通过基于视觉的代理模型，实现数据中心温度的实时预测，可将能耗降低7%，并大幅提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 数据中心能耗和碳排放对可持续性和运营效率构成挑战，需要实时温度预测来实现节能和优化。现有计算流体动力学（CFD）方法计算成本高昂，不适用于实时应用。

Method: 开发了一个基于视觉的代理建模框架，直接处理数据中心的3D体素表示，整合服务器负载、风扇速度和HVAC设定点。评估了3D CNN U-Net、3D傅里叶神经算子和3D视觉转换器等多种架构。

Result: 代理模型在不同的数据中心配置下表现出良好的泛化能力，实现了高达20,000倍的速度提升（从数小时缩短至数百毫秒）。

Conclusion: 该框架能够快速准确地估计热点和温度分布，从而实现实时冷却控制和工作负载重新分配，有效降低能耗（7%）和碳排放。

Abstract: Reducing energy consumption and carbon emissions in data centers by enabling real-time temperature prediction is critical for sustainability and operational efficiency. Achieving this requires accurate modeling of the 3D temperature field to capture airflow dynamics and thermal interactions under varying operating conditions. Traditional thermal CFD solvers, while accurate, are computationally expensive and require expert-crafted meshes and boundary conditions, making them impractical for real-time use. To address these limitations, we develop a vision-based surrogate modeling framework that operates directly on a 3D voxelized representation of the data center, incorporating server workloads, fan speeds, and HVAC temperature set points. We evaluate multiple architectures, including 3D CNN U-Net variants, a 3D Fourier Neural Operator, and 3D vision transformers, to map these thermal inputs to high-fidelity heat maps. Our results show that the surrogate models generalize across data center configurations and achieve up to 20,000x speedup (hundreds of milliseconds vs. hours). This fast and accurate estimation of hot spots and temperature distribution enables real-time cooling control and workload redistribution, leading to substantial energy savings (7\%) and reduced carbon footprint.

</details>


### [364] [A Closer Look at Personalized Fine-Tuning in Heterogeneous Federated Learning](https://arxiv.org/abs/2511.12695)
*Minghui Chen,Hrad Ghoukasian,Ruinan Jin,Zehua Wang,Sai Praneeth Karimireddy,Xiaoxiao Li*

Main category: cs.LG

TL;DR: LP-FT通过分阶段更新参数来解决联邦学习中的特征失真问题，以平衡全局泛化和本地个性化。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在保持隐私的同时实现了去中心化的模型训练，但在处理非相同的数据分布时，难以平衡全局泛化和本地个性化。现有的个性化微调（PFT）方法容易在客户端分布倾斜时过拟合，或在发生域迁移时失败。

Method: 将线性探测（LP）和全模型微调（FT）相结合，提出了一种名为LP-FT的集中式策略，用于解决联邦学习中的特征失真问题。

Result: 在七个数据集和六种PFT变体上的系统评估表明，LP-FT在平衡本地个性化和全局泛化方面优于其他方法。该研究还发现了联邦特征失真现象，并从理论上阐述了LP-FT如何通过分阶段参数更新来缓解此问题。

Conclusion: LP-FT通过分阶段更新参数，有效缓解了联邦学习中的特征失真问题，在提高模型泛化能力的同时，也增强了本地个性化。研究还明确了LP-FT优于标准微调的条件，为在联邦学习中部署鲁棒的个性化提供了指导。

Abstract: Federated Learning (FL) enables decentralized, privacy-preserving model training but struggles to balance global generalization and local personalization due to non-identical data distributions across clients. Personalized Fine-Tuning (PFT), a popular post-hoc solution, fine-tunes the final global model locally but often overfits to skewed client distributions or fails under domain shifts. We propose adapting Linear Probing followed by full Fine-Tuning (LP-FT), a principled centralized strategy for alleviating feature distortion (Kumar et al., 2022), to the FL setting. Through systematic evaluation across seven datasets and six PFT variants, we demonstrate LP-FT's superiority in balancing personalization and generalization. Our analysis uncovers federated feature distortion, a phenomenon where local fine-tuning destabilizes globally learned features, and theoretically characterizes how LP-FT mitigates this via phased parameter updates. We further establish conditions (e.g., partial feature overlap, covariate-concept shift) under which LP-FT outperforms standard fine-tuning, offering actionable guidelines for deploying robust personalization in FL.

</details>


### [365] [Fusion-ResNet: A Lightweight multi-label NILM Model Using PCA-ICA Feature Fusion](https://arxiv.org/abs/2511.12139)
*Sahar Moghimian Hoosh,Ilia Kamyshev,Henni Ouerdane*

Main category: cs.LG

TL;DR: 该研究提出了一种用于非侵入式负荷监测（NILM）的端到端框架，通过融合ICA和PCA特征以及轻量级神经网络（Fusion-ResNet），提高了分类准确性，并增强了模型在处理大量并发电器时的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有非侵入式负荷监测（NILM）技术在实际应用中面临过拟合、模型泛化能力低以及同时解算大量电器功耗的挑战。

Method: 提出一个包含高频标记数据、特征提取方法和轻量级神经网络的端到端NILM分类框架。特征提取方法融合了独立成分分析（ICA）和主成分分析（PCA）特征。轻量级神经网络模型为Fusion-ResNet。

Result: 所提出的基于特征的模型在平均F1分数上优于现有最先进的NILM分类器，同时减少了训练和推理时间。Fusion-ResNet在最多15个并发活动电器的情况下，对压力条件表现出相对鲁棒性。

Conclusion: 该研究提出的Fusion-ResNet框架通过融合ICA和PCA特征以及采用轻量级神经网络，有效解决了现有NILM技术面临的挑战，在提高分类精度和模型泛化能力方面取得了显著成效，并能在高并发电器场景下保持鲁棒性。

Abstract: Non-intrusive load monitoring (NILM) is an advanced load monitoring technique that uses data-driven algorithms to disaggregate the total power consumption of a household into the consumption of individual appliances. However, real-world NILM deployment still faces major challenges, including overfitting, low model generalization, and disaggregating a large number of appliances operating at the same time. To address these challenges, this work proposes an end-to-end framework for the NILM classification task, which consists of high-frequency labeled data, a feature extraction method, and a lightweight neural network. Within this framework, we introduce a novel feature extraction method that fuses Independent Component Analysis (ICA) and Principal Component Analysis (PCA) features. Moreover, we propose a lightweight architecture for multi-label NILM classification (Fusion-ResNet). The proposed feature-based model achieves a higher $F1$ score on average and across different appliances compared to state-of-the-art NILM classifiers while minimizing the training and inference time. Finally, we assessed the performance of our model against baselines with a varying number of simultaneously active devices. Results demonstrate that Fusion-ResNet is relatively robust to stress conditions with up to 15 concurrently active appliances.

</details>


### [366] [SCI: An Equilibrium for Signal Intelligence](https://arxiv.org/abs/2511.12240)
*Vishal Joshua Meesala*

Main category: cs.LG

TL;DR: SCI是一个控制理论框架，将可解释性建模为一种受调节的状态，通过参数更新来最小化解释误差，并在多个领域实现了更稳定、更可靠的可解释性。


<details>
  <summary>Details</summary>
Motivation: 将可解释性建模为一种受调节的状态，以实现更稳定、更可靠的可解释性。

Method: SCI框架通过三个组件实现：1. 靠性加权的、多尺度的特征；2. 知识引导的解释器；3. Lyapunov引导的控制器，具备回滚、信任区域安全措施和下降条件。

Result: SCI在生物医学、工业和环境领域将解释误差降低了25-42%（平均38%），同时将SP方差从0.030降低到0.011，表明解释更加稳定。

Conclusion: 将可解释性建模为控制目标可以产生更稳定、恢复更快、更值得信赖的可解释行为，适用于各种信号。

Abstract: We present SCI, a closed-loop, control-theoretic framework that models interpretability as a regulated state. SCI formalizes the interpretive error Delta SP and actively drives SP(t) in [0, 1] ("Surgical Precision") toward a target via a projected update on the parameters Theta under a human-gain budget. The framework operates through three coordinated components: (1) reliability-weighted, multiscale features P(t, s); (2) a knowledge-guided interpreter psi_Theta that emits traceable markers and rationales; and (3) a Lyapunov-guided controller equipped with rollback, trust-region safeguards, and a descent condition. Across biomedical (EEG/ECG/ICU), industrial (bearings/tool wear), and environmental (climate/seismic) domains, SCI reduces interpretive error by 25-42% (mean 38%, 95% confidence interval 22-43%) relative to static explainers while maintaining AUC/F1 within approximately 1-2 percentage points of baseline. SCI also reduces SP variance from 0.030 to 0.011, indicating substantially more stable explanations. Modeling interpretability as a control objective yields steadier, faster-recovering, and more trustworthy interpretive behavior across diverse signal regimes.

</details>


### [367] [Logarithmic Regret and Polynomial Scaling in Online Multi-step-ahead Prediction](https://arxiv.org/abs/2511.12467)
*Jiachen Qian,Yang Zheng*

Main category: cs.LG

TL;DR: 本文研究未知线性随机系统的在线多步预测问题，并提出一种在线最小二乘算法。


<details>
  <summary>Details</summary>
Motivation: 研究在线多步预测问题，特别是针对未知线性随机系统。

Method: 利用条件分布理论推导出预测策略的线性函数参数化，并提出一种在线最小二乘算法来学习该策略。

Result: 分析了该算法相对于最优基于模型的预测器的遗憾界，证明了其在多步设置下具有对数遗憾界，并建立了几乎确定的遗憾界，同时发现遗憾界的常数因子随预测时界H的增大而多项式增长。

Conclusion: 提出的在线最小二乘算法在未知线性随机系统的在线多步预测问题上表现良好，具有对数遗憾界，并对遗憾界的增长行为进行了深入分析。

Abstract: This letter studies the problem of online multi-step-ahead prediction for unknown linear stochastic systems. Using conditional distribution theory, we derive an optimal parameterization of the prediction policy as a linear function of future inputs, past inputs, and past outputs. Based on this characterization, we propose an online least-squares algorithm to learn the policy and analyze its regret relative to the optimal model-based predictor. We show that the online algorithm achieves logarithmic regret with respect to the optimal Kalman filter in the multi-step setting. Furthermore, with new proof techniques, we establish an almost-sure regret bound that does not rely on fixed failure probabilities for sufficiently large horizons $N$. Finally, our analysis also reveals that, while the regret remains logarithmic in $N$, its constant factor grows polynomially with the prediction horizon $H$, with the polynomial order set by the largest Jordan block of eigenvalue 1 in the system matrix.

</details>


### [368] [PID-controlled Langevin Dynamics for Faster Sampling of Generative Models](https://arxiv.org/abs/2511.12603)
*Hongyi Chen,Jianhai Shu,Jingtao Ding,Yong Li,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: PIDLD是一种新的采样加速算法，通过控制理论原理改进了Langevin动力学采样，在图像生成和推理任务中显著提高了采样速度和质量。


<details>
  <summary>Details</summary>
Motivation: Langevin动力学采样速度慢，需要大量迭代才能收敛到目标分布。

Method: PIDLD将能量梯度视为反馈信号，结合历史梯度（积分项）和梯度趋势（微分项）来加速能量景观的遍历和自适应稳定。

Result: PIDLD在图像生成和推理任务中实现了更快的采样速度和更高的样本质量，减少了迭代次数。

Conclusion: PIDLD是一种无需额外训练、数据集或先验信息即可与任何基于Langevin的方法集成的采样加速算法，使得基于Langevin的生成模型在效率要求高的应用中更加实用。

Abstract: Langevin dynamics sampling suffers from extremely low generation speed, fundamentally limited by numerous fine-grained iterations to converge to the target distribution. We introduce PID-controlled Langevin Dynamics (PIDLD), a novel sampling acceleration algorithm that reinterprets the sampling process using control-theoretic principles. By treating energy gradients as feedback signals, PIDLD combines historical gradients (the integral term) and gradient trends (the derivative term) to efficiently traverse energy landscapes and adaptively stabilize, thereby significantly reducing the number of iterations required to produce high-quality samples. Our approach requires no additional training, datasets, or prior information, making it immediately integrable with any Langevin-based method. Extensive experiments across image generation and reasoning tasks demonstrate that PIDLD achieves higher quality with fewer steps, making Langevin-based generative models more practical for efficiency-critical applications. The implementation can be found at \href{https://github.com/tsinghua-fib-lab/PIDLD}{https://github.com/tsinghua-fib-lab/PIDLD}.

</details>


### [369] [From Black-Box to White-Box: Control-Theoretic Neural Network Interpretability](https://arxiv.org/abs/2511.12852)
*Jihoon Moon*

Main category: cs.LG

TL;DR: 该研究提出了一种基于控制理论的框架，将训练好的神经网络视为非线性状态空间系统，以分析其内部计算过程。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽然性能优越，但难以从机制上进行解释。

Method: 通过局部线性化、可控性和可观测性格拉姆矩阵以及汉克尔奇异值来分析神经网络。具体来说，将神经网络视为非线性状态空间系统，通过局部线性化构建状态空间模型，并计算格拉姆矩阵和汉克尔奇异值来评估神经元和通路的重要性。

Result: 该框架能够识别神经元和通路的重要性，并解释激活饱和等现象对网络行为的影响。实验表明，激活饱和会降低可控性，减小主导汉克尔奇异值，并将主导内部模式转移到不同的神经元子集。

Conclusion: 该方法将神经网络转化为一系列局部的白盒动力学模型，并为剪枝或约束提供候选方向，以增强可解释性。

Abstract: Deep neural networks achieve state of the art performance but remain difficult to interpret mechanistically. In this work, we propose a control theoretic framework that treats a trained neural network as a nonlinear state space system and uses local linearization, controllability and observability Gramians, and Hankel singular values to analyze its internal computation. For a given input, we linearize the network around the corresponding hidden activation pattern and construct a state space model whose state consists of hidden neuron activations. The input state and state output Jacobians define local controllability and observability Gramians, from which we compute Hankel singular values and associated modes. These quantities provide a principled notion of neuron and pathway importance: controllability measures how easily each neuron can be excited by input perturbations, observability measures how strongly each neuron influences the output, and Hankel singular values rank internal modes that carry input output energy. We illustrate the framework on simple feedforward networks, including a 1 2 2 1 SwiGLU network and a 2 3 3 2 GELU network. By comparing different operating points, we show how activation saturation reduces controllability, shrinks the dominant Hankel singular value, and shifts the dominant internal mode to a different subset of neurons. The proposed method turns a neural network into a collection of local white box dynamical models and suggests which internal directions are natural candidates for pruning or constraints to improve interpretability.

</details>


### [370] [DiffFP: Learning Behaviors from Scratch via Diffusion-based Fictitious Play](https://arxiv.org/abs/2511.13186)
*Akash Karthikeyan,Yash Vardhan Pant*

Main category: cs.LG

TL;DR: 该研究提出了一种名为DiffFP的博弈论框架，利用生成模型来解决多智能体强化学习在连续决策空间中的挑战，提高了学习效率和策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的自博弈强化学习在连续决策空间中学习复杂策略面临挑战，导致收敛缓慢、无法达到纳什均衡，并容易被对手利用。

Method: 提出DiffFP框架，使用扩散策略来估计对未知对手的最佳响应，并学习鲁棒且多模态的行为策略。

Result: 实验证明，DiffFP框架在连续空间零和博弈中可以收敛到ε-纳什均衡，并在赛车和多粒子零和博弈等复杂环境中表现出良好的鲁棒性和稳定性，收敛速度比基线方法快3倍，成功率平均高30倍。

Conclusion: DiffFP框架能有效解决多智能体强化学习在连续决策空间中的挑战，提高了学习效率和策略鲁棒性，在复杂博弈环境中表现优于现有方法。

Abstract: Self-play reinforcement learning has demonstrated significant success in learning complex strategic and interactive behaviors in competitive multi-agent games. However, achieving such behaviors in continuous decision spaces remains challenging. Ensuring adaptability and generalization in self-play settings is critical for achieving competitive performance in dynamic multi-agent environments. These challenges often cause methods to converge slowly or fail to converge at all to a Nash equilibrium, making agents vulnerable to strategic exploitation by unseen opponents. To address these challenges, we propose DiffFP, a fictitious play (FP) framework that estimates the best response to unseen opponents while learning a robust and multimodal behavioral policy. Specifically, we approximate the best response using a diffusion policy that leverages generative modeling to learn adaptive and diverse strategies. Through empirical evaluation, we demonstrate that the proposed FP framework converges towards $ε$-Nash equilibria in continuous- space zero-sum games. We validate our method on complex multi-agent environments, including racing and multi-particle zero-sum games. Simulation results show that the learned policies are robust against diverse opponents and outperform baseline reinforcement learning policies. Our approach achieves up to 3$\times$ faster convergence and 30$\times$ higher success rates on average against RL-based baselines, demonstrating its robustness to opponent strategies and stability across training iterations

</details>


### [371] [Naga: Vedic Encoding for Deep State Space Models](https://arxiv.org/abs/2511.13510)
*Melanie Schaller,Nick Janssen,Bodo Rosenhahn*

Main category: cs.LG

TL;DR: Naga是一种受吠陀数学启发的深度状态空间模型（SSM），通过双向处理和哈达玛积交互来增强时间序列建模能力，在多个基准测试中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了增强模型捕捉远程时间依赖性的能力，并提供一种可解释且计算高效的序列建模方法。

Method: 提出了一种名为Naga的深度状态空间模型（SSM）编码方法，该方法受吠陀数学的结构启发，通过联合处理前向和时间反转的输入序列来引入时间序列的双向表示，然后通过逐元（哈达玛）交互结合这些表示。

Result: Naga在多个长期时间序列预测（LTSF）基准测试（包括ETTh1、ETTh2、ETTm1、ETTm2、Weather、Traffic和ILI）上进行了评估，其表现优于28个现有最先进模型，并且与现有的基于SSM的深度方法相比，效率有所提高。

Conclusion: 结合结构化的、受吠陀启发的分解可以为长程序列建模提供一种可解释且计算高效的替代方案。

Abstract: This paper presents Naga, a deep State Space Model (SSM) encoding approach inspired by structural concepts from Vedic mathematics. The proposed method introduces a bidirectional representation for time series by jointly processing forward and time-reversed input sequences. These representations are then combined through an element-wise (Hadamard) interaction, resulting in a Vedic-inspired encoding that enhances the model's ability to capture temporal dependencies across distant time steps. We evaluate Naga on multiple long-term time series forecasting (LTSF) benchmarks, including ETTh1, ETTh2, ETTm1, ETTm2, Weather, Traffic, and ILI. The experimental results show that Naga outperforms 28 current state of the art models and demonstrates improved efficiency compared to existing deep SSM-based approaches. The findings suggest that incorporating structured, Vedic-inspired decomposition can provide an interpretable and computationally efficient alternative for long-range sequence modeling.

</details>


### [372] [Enhancing Reinforcement Learning in 3D Environments through Semantic Segmentation: A Case Study in ViZDoom](https://arxiv.org/abs/2511.11703)
*Hugo Huang*

Main category: cs.LG

TL;DR: 通过引入基于语义分割的输入表示（SS-only 和 RGB+SS），在高维 3D 环境中降低了强化学习的内存消耗并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维 3D 环境中强化学习（RL）因内存缓冲区导致的内存消耗高和部分可观察马尔可夫决策过程（POMDPs）学习复杂度高的问题。

Method: 提出两种新的输入表示：SS-only 和 RGB+SS，均采用 RGB 彩色图像的语义分割。在 ViZDoom 的死亡竞赛中进行了实验，并使用密度热力图可视化 RL 代理的移动模式。

Result: SS-only 将内存缓冲区内存消耗至少减少了 66.6%，应用游程长度编码后可达 98.6%。RGB+SS 通过增加的语义信息显著提高了 RL 代理的性能。密度热力图可用于评估数据收集的适用性。

Conclusion: 所提出的语义分割方法有效解决了在 ViZDoom 等 3D 环境中应用语义分割的常见问题，在降低内存消耗和提高 RL 代理性能方面取得了显著成效。

Abstract: Reinforcement learning (RL) in 3D environments with high-dimensional sensory input poses two major challenges: (1) the high memory consumption induced by memory buffers required to stabilise learning, and (2) the complexity of learning in partially observable Markov Decision Processes (POMDPs). This project addresses these challenges by proposing two novel input representations: SS-only and RGB+SS, both employing semantic segmentation on RGB colour images. Experiments were conducted in deathmatches of ViZDoom, utilizing perfect segmentation results for controlled evaluation. Our results showed that SS-only was able to reduce the memory consumption of memory buffers by at least 66.6%, and up to 98.6% when a vectorisable lossless compression technique with minimal overhead such as run-length encoding is applied. Meanwhile, RGB+SS significantly enhances RL agents' performance with the additional semantic information provided. Furthermore, we explored density-based heatmapping as a tool to visualise RL agents' movement patterns and evaluate their suitability for data collection. A brief comparison with a previous approach highlights how our method overcame common pitfalls in applying semantic segmentation in 3D environments like ViZDoom.

</details>


### [373] [Are LLMs The Way Forward? A Case Study on LLM-Guided Reinforcement Learning for Decentralized Autonomous Driving](https://arxiv.org/abs/2511.12751)
*Timur Anvar,Jeffrey Chen,Yuyan Wang,Rohan Chandra*

Main category: cs.LG

TL;DR: 小型本地化大语言模型（LLM）可以通过奖励塑造而非直接控制来辅助自动驾驶，但存在效率和稳定性的挑战。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，强化学习（RL）对奖励函数的依赖性不足以处理语义和社会复杂性，而直接使用大语言模型（LLM）存在不稳定性、不一致性和高成本问题。因此，研究小型本地化LLM是否能通过奖励塑造来支持自动驾驶。

Method: 通过一个案例研究，比较了纯RL、纯LLM和混合方法。在训练过程中，LLM通过评估状态-动作转换来增强RL奖励，而在测试时使用标准的RL策略。

Result: 纯RL方法的成功率在73-89%之间，效率尚可。纯LLM方法的成功率最高可达94%，但速度性能严重下降。混合方法介于两者之间。LLM影响的方法存在系统性的保守偏见，且模型依赖性变异性大，影响了效率。

Conclusion: 尽管小型LLM在奖励塑造方面有潜力，但它们在安全关键控制任务中存在效率和稳定性问题，表现出保守偏见，这限制了其在自动驾驶中的直接应用。

Abstract: Autonomous vehicle navigation in complex environments such as dense and fast-moving highways and merging scenarios remains an active area of research. A key limitation of RL is its reliance on well-specified reward functions, which often fail to capture the full semantic and social complexity of diverse, out-of-distribution situations. As a result, a rapidly growing line of research explores using Large Language Models (LLMs) to replace or supplement RL for direct planning and control, on account of their ability to reason about rich semantic context. However, LLMs present significant drawbacks: they can be unstable in zero-shot safety-critical settings, produce inconsistent outputs, and often depend on expensive API calls with network latency. This motivates our investigation into whether small, locally deployed LLMs (< 14B parameters) can meaningfully support autonomous highway driving through reward shaping rather than direct control. We present a case study comparing RL-only, LLM-only, and hybrid approaches, where LLMs augment RL rewards by scoring state-action transitions during training, while standard RL policies execute at test time. Our findings reveal that RL-only agents achieve moderate success rates (73-89%) with reasonable efficiency, LLM-only agents can reach higher success rates (up to 94%) but with severely degraded speed performance, and hybrid approaches consistently fall between these extremes. Critically, despite explicit efficiency instructions, LLM-influenced approaches exhibit systematic conservative bias with substantial model-dependent variability, highlighting important limitations of current small LLMs for safety-critical control tasks.

</details>


### [374] [Quantum Machine Learning via Contrastive Training](https://arxiv.org/abs/2511.13497)
*Liudmila A. Zhukas,Vivian Ni Zhang,Qiang Miao,Qingfeng Wang,Marko Cetina,Jungsang Kim,Lawrence Carin,Christopher Monroe*

Main category: cs.LG

TL;DR: 通过在量子计算机上使用无标签数据进行预训练，可以提高量子机器学习模型在标签数据稀疏时的图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 为解决量子机器学习模型在面对标签数据稀疏问题时的挑战，引入一种新的自监督预训练方法。

Method: 在可编程离子阱量子计算机上实现量子表征的自监督预训练，将图像编码为量子态，并利用量子重叠度量来学习不变量。

Result: 与随机初始化的模型相比，经过预训练的模型在图像分类任务中表现出更高的平均测试准确性和更低的运行间变异性，尤其在标签数据有限的情况下。

Conclusion: 该方法为量子表征学习提供了一条标签效率的途径，适用于量子原生数据集，并为处理更大的经典输入提供了清晰的路径。

Abstract: Quantum machine learning (QML) has attracted growing interest with the rapid parallel advances in large-scale classical machine learning and quantum technologies. Similar to classical machine learning, QML models also face challenges arising from the scarcity of labeled data, particularly as their scale and complexity increase. Here, we introduce self-supervised pretraining of quantum representations that reduces reliance on labeled data by learning invariances from unlabeled examples. We implement this paradigm on a programmable trapped-ion quantum computer, encoding images as quantum states. In situ contrastive pretraining on hardware yields a representation that, when fine-tuned, classifies image families with higher mean test accuracy and lower run-to-run variability than models trained from random initialization. Performance improvement is especially significant in regimes with limited labeled training data. We show that the learned invariances generalize beyond the pretraining image samples. Unlike prior work, our pipeline derives similarity from measured quantum overlaps and executes all training and classification stages on hardware. These results establish a label-efficient route to quantum representation learning, with direct relevance to quantum-native datasets and a clear path to larger classical inputs.

</details>


### [375] [Learning with Preserving for Continual Multitask Learning](https://arxiv.org/abs/2511.11676)
*Hanchen David Wang,Siwoo Bae,Zirong Chen,Meiyi Ma*

Main category: cs.LG

TL;DR: LwP框架通过保持共享表示空间的几何结构来解决持续多任务学习中的灾难性遗忘问题，并在各种基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法在持续多任务学习（CMTL）设置中常常失败，因为它们学习的特定任务特征会相互干扰，导致遗忘先前学到的能力。

Method: 提出了一种名为LwP的新颖框架，它通过动态加权距离保持（DWDP）损失来保持表示空间的几何结构，该损失通过正则化潜在数据表示之间的成对距离来防止表示漂移，而无需重放缓冲区。

Result: LwP不仅减轻了灾难性遗忘，而且在CMTL任务中持续优于最先进的基线，并且在时间序列和图像基准测试中都表现出色。

Conclusion: LwP通过保持共享表示空间的几何结构来有效解决CMTL中的灾难性遗忘问题，并且在实际应用中表现出优于单任务学习的性能和对分布变化的鲁棒性。

Abstract: Artificial intelligence systems in critical fields like autonomous driving and medical imaging analysis often continually learn new tasks using a shared stream of input data. For instance, after learning to detect traffic signs, a model may later need to learn to classify traffic lights or different types of vehicles using the same camera feed. This scenario introduces a challenging setting we term Continual Multitask Learning (CMTL), where a model sequentially learns new tasks on an underlying data distribution without forgetting previously learned abilities. Existing continual learning methods often fail in this setting because they learn fragmented, task-specific features that interfere with one another. To address this, we introduce Learning with Preserving (LwP), a novel framework that shifts the focus from preserving task outputs to maintaining the geometric structure of the shared representation space. The core of LwP is a Dynamically Weighted Distance Preservation (DWDP) loss that prevents representation drift by regularizing the pairwise distances between latent data representations. This mechanism of preserving the underlying geometric structure allows the model to retain implicit knowledge and support diverse tasks without requiring a replay buffer, making it suitable for privacy-conscious applications. Extensive evaluations on time-series and image benchmarks show that LwP not only mitigates catastrophic forgetting but also consistently outperforms state-of-the-art baselines in CMTL tasks. Notably, our method shows superior robustness to distribution shifts and is the only approach to surpass the strong single-task learning baseline, underscoring its effectiveness for real-world dynamic environments.

</details>


### [376] [Probabilistic Wildfire Susceptibility from Remote Sensing Using Random Forests and SHAP](https://arxiv.org/abs/2511.11680)
*Udaya Bhasker Cheerala,Varun Teja Chirukuri,Venkata Akhil Kumar Gummadi,Jintu Moni Bhuyan,Praveen Damacharla*

Main category: cs.LG

TL;DR: 该研究利用随机森林（RF）和可解释人工智能（XAI）技术（SHAP）为加利福尼亚创建了一个全面的野火风险地图，识别了关键风险驱动因素和高风险区域，为野火风险管理提供了工具。


<details>
  <summary>Details</summary>
Motivation: 加利福尼亚野火频发，对生态系统构成重大威胁，因此需要开发全面的野火风险评估方法。

Method: 研究应用随机森林（RF）算法构建野火风险模型，并结合Shapley Additive exPlanations（SHAP）进行模型解释，最后进行空间和时间验证，并分析了不同生态系统（森林和草原）的风险驱动因素和区域分布。

Result: RF模型在预测草原（AUC=0.996）和森林（AUC=0.997）野火风险方面表现出优异的性能。空间交叉验证显示模型具有中等的迁移能力（森林ROC-AUC=0.6155，草原ROC-AUC=0.5416），而时间分割验证显示出更好的泛化能力（森林ROC-AUC=0.6615，PR-AUC=0.8423）。SHAP分析确定了森林和草原的关键风险驱动因素，如土壤有机碳、树木覆盖率、NDVI、地表温度和海拔。风险地图显示，Central Valley和Northern Buttes地区草原火灾风险最高，Northern Buttes和North Coast Redwoods地区森林火灾风险最高。

Conclusion: RF-SHAP框架为野火风险评估提供了一种强大、可解释且适应性强的方法，能够支持制定有针对性的减灾策略。

Abstract: Wildfires pose a significant global threat to ecosystems worldwide, with California experiencing recurring fires due to various factors, including climate, topographical features, vegetation patterns, and human activities. This study aims to develop a comprehensive wildfire risk map for California by applying the random forest (RF) algorithm, augmented with Explainable Artificial Intelligence (XAI) through Shapley Additive exPlanations (SHAP), to interpret model predictions. Model performance was assessed using both spatial and temporal validation strategies. The RF model demonstrated strong predictive performance, achieving near-perfect discrimination for grasslands (AUC = 0.996) and forests (AUC = 0.997). Spatial cross-validation revealed moderate transferability, yielding ROC-AUC values of 0.6155 for forests and 0.5416 for grasslands. In contrast, temporal split validation showed enhanced generalization, especially for forests (ROC-AUC = 0.6615, PR-AUC = 0.8423). SHAP-based XAI analysis identified key ecosystem-specific drivers: soil organic carbon, tree cover, and Normalized Difference Vegetation Index (NDVI) emerged as the most influential in forests, whereas Land Surface Temperature (LST), elevation, and vegetation health indices were dominant in grasslands. District-level classification revealed that Central Valley and Northern Buttes districts had the highest concentration of high-risk grasslands, while Northern Buttes and North Coast Redwoods dominated forested high-risk areas. This RF-SHAP framework offers a robust, comprehensible, and adaptable method for assessing wildfire risks, enabling informed decisions and creating targeted strategies to mitigate dangers.

</details>


### [377] [MPCM-Net: Multi-scale network integrates partial attention convolution with Mamba for ground-based cloud image segmentation](https://arxiv.org/abs/2511.11681)
*Penghui Niu,Jiashuai She,Taotao Cai,Yajuan Zhang,Ping Zhang,Junhua Gu,Jianxin Li*

Main category: cs.LG

TL;DR: MPCM-Net通过结合局部注意力和Mamba架构来提高云图像分割的准确性和效率，并引入新的CSRC数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在云图像分割方面存在多尺度上下文提取不足、特征增强效率不高以及解码器无法建立全局依赖等问题。

Method: 提出MPCM-Net，编码器使用包含ParCM和ParSM的MPAC块进行空间交互和特征提取，解码器使用M2B模块和SSHD进行上下文损失的缓解和深层特征聚合。

Result: MPCM-Net在CSRC数据集上取得了优于现有方法的性能，实现了准确性和推理速度的最佳平衡。

Conclusion: MPCM-Net在云图像分割任务中展现出优越的性能，并提出了新的CSRC数据集以推动该领域的研究。

Abstract: Ground-based cloud image segmentation is a critical research domain for photovoltaic power forecasting. Current deep learning approaches primarily focus on encoder-decoder architectural refinements. However, existing methodologies exhibit several limitations:(1)they rely on dilated convolutions for multi-scale context extraction, lacking the partial feature effectiveness and interoperability of inter-channel;(2)attention-based feature enhancement implementations neglect accuracy-throughput balance; and (3)the decoder modifications fail to establish global interdependencies among hierarchical local features, limiting inference efficiency. To address these challenges, we propose MPCM-Net, a Multi-scale network that integrates Partial attention Convolutions with Mamba architectures to enhance segmentation accuracy and computational efficiency. Specifically, the encoder incorporates MPAC, which comprises:(1)a MPC block with ParCM and ParSM that enables global spatial interaction across multi-scale cloud formations, and (2)a MPA block combining ParAM and ParSM to extract discriminative features with reduced computational complexity. On the decoder side, a M2B is employed to mitigate contextual loss through a SSHD that maintains linear complexity while enabling deep feature aggregation across spatial and scale dimensions. As a key contribution to the community, we also introduce and release a dataset CSRC, which is a clear-label, fine-grained segmentation benchmark designed to overcome the critical limitations of existing public datasets. Extensive experiments on CSRC demonstrate the superior performance of MPCM-Net over state-of-the-art methods, achieving an optimal balance between segmentation accuracy and inference speed. The dataset and source code will be available at https://github.com/she1110/CSRC.

</details>


### [378] [Stratified Knowledge-Density Super-Network for Scalable Vision Transformers](https://arxiv.org/abs/2511.11683)
*Longhua Li,Lei Qi,Xin Geng*

Main category: cs.LG

TL;DR: 本文提出了一种将预训练ViT模型转换为分层知识密度超网的方法，通过WPAC和PIAD技术实现知识的压缩和分层组织，从而能够灵活提取适应不同资源约束的子网络，并能在模型压缩和扩展方面提供优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为解决训练和部署多种ViT模型以适应不同资源约束所带来的高成本和低效率问题。

Method: 提出了一种将预训练ViT模型转换为分层知识密度超网络的方法。引入了加权PCA注意力收缩（WPAC）技术，将知识集中到关键权重中，并通过注入变换和逆变换矩阵来保留原始网络功能。同时，提出了渐进重要性感知丢弃（PIAD）技术，通过评估权重组的重要性并进行相应的丢弃，来促进知识的分层组织。

Result: WPAC在知识集中优于现有的剪枝标准。WPAC与PIAD结合后，在模型压缩和模型扩展方面提供了优于现有最先进方法的强大替代方案。

Conclusion: WPAC和PIAD技术能够有效地将ViT模型压缩并组织成一个分层知识密度的超网络，从而能够灵活地提取适应不同模型尺寸的子网络，并在模型压缩和扩展方面展现出优越的性能。

Abstract: Training and deploying multiple vision transformer (ViT) models for different resource constraints is costly and inefficient. To address this, we propose transforming a pre-trained ViT into a stratified knowledge-density super-network, where knowledge is hierarchically organized across weights. This enables flexible extraction of sub-networks that retain maximal knowledge for varying model sizes. We introduce \textbf{W}eighted \textbf{P}CA for \textbf{A}ttention \textbf{C}ontraction (WPAC), which concentrates knowledge into a compact set of critical weights. WPAC applies token-wise weighted principal component analysis to intermediate features and injects the resulting transformation and inverse matrices into adjacent layers, preserving the original network function while enhancing knowledge compactness. To further promote stratified knowledge organization, we propose \textbf{P}rogressive \textbf{I}mportance-\textbf{A}ware \textbf{D}ropout (PIAD). PIAD progressively evaluates the importance of weight groups, updates an importance-aware dropout list, and trains the super-network under this dropout regime to promote knowledge stratification. Experiments demonstrate that WPAC outperforms existing pruning criteria in knowledge concentration, and the combination with PIAD offers a strong alternative to state-of-the-art model compression and model expansion methods.

</details>


### [379] [Hierarchical Schedule Optimization for Fast and Robust Diffusion Model Sampling](https://arxiv.org/abs/2511.11688)
*Aihua Zhu,Rui Su,Qinglin Zhao,Li Feng,Meng Shen,Shibo He*

Main category: cs.LG

TL;DR: 通过分层优化框架HSO，实现了扩散模型在极低函数评估次数（NFE）下的采样加速，显著提高了样本质量，且计算成本极低。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型加速方法在有效性、自适应性、鲁棒性和效率方面存在不足，无法同时满足所有核心原则，因此需要更先进的解决方案。

Method: 提出了一种名为HSO（Hierarchical-Schedule-Optimizer）的新型分层优化框架，通过迭代交替的上下两层优化来寻找全局最优采样时间表：上层进行全局搜索以确定最优初始化策略，下层进行局部优化以精炼时间表。该框架引入了中期误差代理（MEP）和间隔惩罚适应度（SPF）函数，分别用于有效优化和提高鲁棒性。

Result: HSO在极低NFE的条件下取得了最先进的性能。例如，在仅使用5次函数评估（NFE=5）的情况下，HSO在LAION-Aesthetics数据集上使用Stable Diffusion v2.1模型达到了11.94的FID分数。

Conclusion: HSO是一种高效且实用的扩散模型加速范式，它通过一次性优化（成本低于8秒）即可在极低NFE下实现顶尖的采样性能，无需进行昂贵的重新训练。

Abstract: Diffusion probabilistic models have set a new standard for generative fidelity but are hindered by a slow iterative sampling process. A powerful training-free strategy to accelerate this process is Schedule Optimization, which aims to find an optimal distribution of timesteps for a fixed and small Number of Function Evaluations (NFE) to maximize sample quality. To this end, a successful schedule optimization method must adhere to four core principles: effectiveness, adaptivity, practical robustness, and computational efficiency. However, existing paradigms struggle to satisfy these principles simultaneously, motivating the need for a more advanced solution. To overcome these limitations, we propose the Hierarchical-Schedule-Optimizer (HSO), a novel and efficient bi-level optimization framework. HSO reframes the search for a globally optimal schedule into a more tractable problem by iteratively alternating between two synergistic levels: an upper-level global search for an optimal initialization strategy and a lower-level local optimization for schedule refinement. This process is guided by two key innovations: the Midpoint Error Proxy (MEP), a solver-agnostic and numerically stable objective for effective local optimization, and the Spacing-Penalized Fitness (SPF) function, which ensures practical robustness by penalizing pathologically close timesteps. Extensive experiments show that HSO sets a new state-of-the-art for training-free sampling in the extremely low-NFE regime. For instance, with an NFE of just 5, HSO achieves a remarkable FID of 11.94 on LAION-Aesthetics with Stable Diffusion v2.1. Crucially, this level of performance is attained not through costly retraining, but with a one-time optimization cost of less than 8 seconds, presenting a highly practical and efficient paradigm for diffusion model acceleration.

</details>


### [380] [Doubly Debiased Test-Time Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2511.11690)
*Fei Song,Yi Li,Rui Wang,Jiahuan Zhou,Changwen Zheng,Jiangmeng Li*

Main category: cs.LG

TL;DR: 通过引入动态检索增强的调制模块和可靠性感知的提示优化模块，提出了一种双重去偏的测试时间提示调整方法（DB-TTPT），以解决视觉-语言模型在零样本设置下测试时间提示调整中的优化偏见问题，并在15个基准数据集上取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 测试时间提示调整（TTPT）在零样本设置下表现出强大的泛化能力，但仅基于无标签测试数据调整可学习提示会导致优化偏见，从而影响下游任务的性能。该工作旨在分析并解决这一优化偏见问题。

Method: 提出了一种双重去偏的测试时间提示调整（DB-TTPT）方法。首先，引入了一个动态检索增强的调制模块，该模块使用测试图像特征作为查询，从动态知识库中检索高置信度知识，并用以调整模型预测。然后，在此基础上，开发了一个可靠性感知的提示优化模块，结合了基于置信度的加权集成和跨模态一致性蒸馏，在提示调整过程中施加正则化约束。

Result: 在涉及自然分布变化和跨数据集泛化的15个基准数据集上的广泛实验表明，所提出的DB-TTPT方法在减轻提示优化偏见方面优于现有基线方法。

Conclusion: 所提出的DB-TTPT方法能够有效地减轻测试时间提示调整中的优化偏见，并在各种数据集和分布变化下提高模型的性能。

Abstract: Test-time prompt tuning for vision-language models has demonstrated impressive generalization capabilities under zero-shot settings. However, tuning the learnable prompts solely based on unlabeled test data may induce prompt optimization bias, ultimately leading to suboptimal performance on downstream tasks. In this work, we analyze the underlying causes of prompt optimization bias from both the model and data perspectives. In terms of the model, the entropy minimization objective typically focuses on reducing the entropy of model predictions while overlooking their correctness. This can result in overconfident yet incorrect outputs, thereby compromising the quality of prompt optimization. On the data side, prompts affected by optimization bias can introduce misalignment between visual and textual modalities, which further aggravates the prompt optimization bias. To this end, we propose a Doubly Debiased Test-Time Prompt Tuning method. Specifically, we first introduce a dynamic retrieval-augmented modulation module that retrieves high-confidence knowledge from a dynamic knowledge base using the test image feature as a query, and uses the retrieved knowledge to modulate the predictions. Guided by the refined predictions, we further develop a reliability-aware prompt optimization module that incorporates a confidence-based weighted ensemble and cross-modal consistency distillation to impose regularization constraints during prompt tuning. Extensive experiments across 15 benchmark datasets involving both natural distribution shifts and cross-datasets generalization demonstrate that our method outperforms baselines, validating its effectiveness in mitigating prompt optimization bias.

</details>


### [381] [AnchorDS: Anchoring Dynamic Sources for Semantically Consistent Text-to-3D Generation](https://arxiv.org/abs/2511.11692)
*Jiayin Zhu,Linlin Yang,Yicong Li,Angela Yao*

Main category: cs.LG

TL;DR: SDS忽略了源动态，导致了“语义过平滑”的伪影。本文提出了一种新的文本到3D优化方法，将动态演化的源分布映射到固定目标分布，并通过引入AnchorDS来改进SDS，以实现更精细的细节、更自然的颜色和更强的语义一致性。


<details>
  <summary>Details</summary>
Motivation: SDS方法在文本到3D优化中忽略了源动态，导致了“语义过平滑”等伪影，抑制或合并了语义线索，产生了不一致的轨迹。

Method: 将文本到3D优化重新定义为动态演化的源分布到固定目标分布的映射。在文本提示和中间渲染图像的联合条件下，将问题纳入一个对偶条件潜在空间。引入AnchorDS，一种改进的得分蒸馏机制，提供具有图像条件的、状态锚定的引导，并稳定生成。通过惩罚错误的源估计和设计轻量级的过滤和微调策略来优化锚点。

Result: AnchorDS在细节、颜色和语义一致性方面取得了显著的改进，尤其是在处理复杂提示时，同时保持了效率。实验表明，该方法在质量和效率上均优于现有方法。

Conclusion: AnchorDS通过引入状态锚定的引导和对偶条件潜在空间，成功解决了SDS在文本到3D优化中存在的“语义过平滑”问题，提高了生成质量和效率。

Abstract: Optimization-based text-to-3D methods distill guidance from 2D generative models via Score Distillation Sampling (SDS), but implicitly treat this guidance as static. This work shows that ignoring source dynamics yields inconsistent trajectories that suppress or merge semantic cues, leading to "semantic over-smoothing" artifacts. As such, we reformulate text-to-3D optimization as mapping a dynamically evolving source distribution to a fixed target distribution. We cast the problem into a dual-conditioned latent space, conditioned on both the text prompt and the intermediately rendered image. Given this joint setup, we observe that the image condition naturally anchors the current source distribution. Building on this insight, we introduce AnchorDS, an improved score distillation mechanism that provides state-anchored guidance with image conditions and stabilizes generation. We further penalize erroneous source estimates and design a lightweight filter strategy and fine-tuning strategy that refines the anchor with negligible overhead. AnchorDS produces finer-grained detail, more natural colours, and stronger semantic consistency, particularly for complex prompts, while maintaining efficiency. Extensive experiments show that our method surpasses previous methods in both quality and efficiency.

</details>


### [382] [Toward Dignity-Aware AI: Next-Generation Elderly Monitoring from Fall Detection to ADL](https://arxiv.org/abs/2511.11696)
*Xun Shao,Aoba Otani,Yuto Hirasuka,Runji Cai,Seng W. Loke*

Main category: cs.LG

TL;DR: 本论文提出了一个面向未来的、超越传统的跌倒检测、旨在实现日常生活活动（ADL）识别的老年人监测系统。该系统将利用隐私保护、边缘部署和联邦式人工智能技术，以鲁棒地识别和理解老年人的日常活动，从而在老龄化社会中维护其独立性和尊严。


<details>
  <summary>Details</summary>
Motivation: 当前，专门用于ADL识别的数据集仍在收集阶段。因此，本文旨在通过使用SISFall数据集及其GAN增强变体进行跌倒检测的实验来初步论证其可行性，并将跌倒检测作为一项代理任务。

Method: 本文采用了联邦学习的方法，并在非独立同分布（non-IID）的条件下进行了实验，同时还在Jetson Orin Nano设备上进行了嵌入式部署实验。

Result: 初步实验结果表明，在非独立同分布条件下进行联邦学习是可行的，并且在Jetson Orin Nano设备上实现了嵌入式部署。

Conclusion: 本文指出了在实现全面的ADL监测过程中面临的挑战，包括域漂移、数据稀缺和隐私风险，并提出了在智能房间环境中实现全面ADL监测的方向。该研究强调了从单一任务检测向综合性日常活动识别的转变，为可持续和以人为本的老年护理人工智能提供了早期证据和发展蓝图。

Abstract: This position paper envisions a next-generation elderly monitoring system that moves beyond fall detection toward the broader goal of Activities of Daily Living (ADL) recognition. Our ultimate aim is to design privacy-preserving, edge-deployed, and federated AI systems that can robustly detect and understand daily routines, supporting independence and dignity in aging societies. At present, ADL-specific datasets are still under collection. As a preliminary step, we demonstrate feasibility through experiments using the SISFall dataset and its GAN-augmented variants, treating fall detection as a proxy task. We report initial results on federated learning with non-IID conditions, and embedded deployment on Jetson Orin Nano devices. We then outline open challenges such as domain shift, data scarcity, and privacy risks, and propose directions toward full ADL monitoring in smart-room environments. This work highlights the transition from single-task detection to comprehensive daily activity recognition, providing both early evidence and a roadmap for sustainable and human-centered elderly care AI.

</details>


### [383] [Simple Vision-Language Math Reasoning via Rendered Text](https://arxiv.org/abs/2511.11704)
*Matvey Skripkin,Elizaveta Goncharova,Andrey Kuznetsov*

Main category: cs.LG

TL;DR: 通过将LaTeX编码的方程渲染成图像并结合结构化的思维链提示，提出了一种轻量级但有效的训练视觉-语言模型解决数学问题的方法，在不牺牲通用领域能力的情况下，达到了最先进的推理准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在提高视觉-语言模型在解决数学问题方面的能力，同时保持其通用领域能力。

Method: 将LaTeX编码的方程渲染成图像，并与结构化的思维链提示配对，用于训练视觉-语言模型。

Result: 所提出的方法在广泛使用的基准测试上，在数学推理准确性方面匹配或超过了现有的开源和专有模型，并在MMM, ChartQA和DocVQA等任务上取得了高达20%的提升，同时保持了广泛的通用领域能力。

Conclusion: 渲染保真度和提示设计是影响模型性能的关键因素。该方法简单有效，能够显著提高数学问题的视觉-语言模型推理能力。

Abstract: We present a lightweight yet effective pipeline for training vision-language models to solve math problems by rendering LaTeX encoded equations into images and pairing them with structured chain-of-thought prompts. This simple text-to-vision augmentation enables compact multimodal architectures to achieve state-of-the-art reasoning accuracy. Through systematic ablations, we find that rendering fidelity and prompt design are the primary drivers of performance. Despite its simplicity, our approach consistently matches or surpasses both open-source and proprietary math-focused vision-language solvers on widely used benchmarks, while preserving broad general-domain competence - showing gains on tasks such as MMMU, ChartQA, and DocVQA of up to 20%.

</details>


### [384] [Multimodal ML: Quantifying the Improvement of Calorie Estimation Through Image-Text Pairs](https://arxiv.org/abs/2511.11705)
*Arya Narang*

Main category: cs.LG

TL;DR: 该模型结合了图像和文本（菜肴名称）进行卡路里估算，在Nutrition5k数据集上，平均绝对误差（MAE）从84.76 kcal降低到83.70 kcal，改进率为1.25%。


<details>
  <summary>Details</summary>
Motivation: 确定了短文本输入（在此案例中是菜肴名称）在多大程度上可以改善与仅图像基线模型相比的卡路里估算，以及这种改进是否具有统计学意义。

Method: 利用TensorFlow库和Nutrition5k数据集（由Google策划）来训练仅图像的CNN和接受文本和图像作为输入的、多模态的CNN。

Result: 结合文本和图像的多模态模型将估算卡路里的平均绝对误差（MAE）从84.76 kcal降低了1.06 kcal，降至83.70 kcal（改进率为1.25%）。

Conclusion: 与仅图像模型相比，结合菜肴名称的文本信息可以轻微但有意义地提高卡路里估算的准确性。

Abstract: This paper determines the extent to which short textual inputs (in this case, names of dishes) can improve calorie estimation compared to an image-only baseline model and whether any improvements are statistically significant. Utilizes the TensorFlow library and the Nutrition5k dataset (curated by Google) to train both an image-only CNN and multimodal CNN that accepts both text and an image as input. The MAE of calorie estimations was reduced by 1.06 kcal from 84.76 kcal to 83.70 kcal (1.25% improvement) when using the multimodal model.

</details>


### [385] [Context-Aware Multimodal Representation Learning for Spatio-Temporally Explicit Environmental modelling](https://arxiv.org/abs/2511.11706)
*Julia Peters,Karin Mora,Miguel D. Mahecha,Chaonan Ji,David Montero,Clemens Mosig,Guido Kraemer*

Main category: cs.LG

TL;DR: 该研究提出了一个高时空分辨率的地球观测基础模型框架，能够整合不同传感器的遥感数据，生成可用于生态系统动力学分析的通用嵌入式数据集。


<details>
  <summary>Details</summary>
Motivation: 现有地球观测基础模型在固定空间或时间尺度上运行，限制了它们在需要精细空间细节和高时间保真度的生态学分析中的应用。本研究旨在克服这些限制，提出一个能够整合不同地球观测模态到统一高时空分辨率特征空间中的表示学习框架。

Method: 该框架首先独立建模Sentinel-1和Sentinel-2数据以捕捉其特定传感器特征，然后将这些表示组合到一个共享模型中。这种两阶段设计允许对特定模态进行优化，并能轻松扩展到新传感器，同时保留预训练编码器，仅重新训练融合层。

Result: 学习到的嵌入式数据在异构景观中表现出高空间和语义一致性。在估算初级生产力（Gross Primary Production）的定量评估中，这些嵌入式数据能够编码具有生态学意义的模式，并保留足够的时间保真度以支持精细尺度分析。

Conclusion: 该框架提供了一种灵活、可分析的表示学习方法，适用于需要不同空间和时间分辨率的环境应用。

Abstract: Earth observation (EO) foundation models have emerged as an effective approach to derive latent representations of the Earth system from various remote sensing sensors. These models produce embeddings that can be used as analysis-ready datasets, enabling the modelling of ecosystem dynamics without extensive sensor-specific preprocessing. However, existing models typically operate at fixed spatial or temporal scales, limiting their use for ecological analyses that require both fine spatial detail and high temporal fidelity. To overcome these limitations, we propose a representation learning framework that integrates different EO modalities into a unified feature space at high spatio-temporal resolution. We introduce the framework using Sentinel-1 and Sentinel-2 data as representative modalities. Our approach produces a latent space at native 10 m resolution and the temporal frequency of cloud-free Sentinel-2 acquisitions. Each sensor is first modeled independently to capture its sensor-specific characteristics. Their representations are then combined into a shared model. This two-stage design enables modality-specific optimisation and easy extension to new sensors, retaining pretrained encoders while retraining only fusion layers. This enables the model to capture complementary remote sensing data and to preserve coherence across space and time. Qualitative analyses reveal that the learned embeddings exhibit high spatial and semantic consistency across heterogeneous landscapes. Quantitative evaluation in modelling Gross Primary Production reveals that they encode ecologically meaningful patterns and retain sufficient temporal fidelity to support fine-scale analyses. Overall, the proposed framework provides a flexible, analysis-ready representation learning approach for environmental applications requiring diverse spatial and temporal resolutions.

</details>


### [386] [Optimizing Input of Denoising Score Matching is Biased Towards Higher Score Norm](https://arxiv.org/abs/2511.11727)
*Tongda Xu*

Main category: cs.LG

TL;DR: 利用去噪分数匹配优化扩散模型条件输入会破坏其与精确分数匹配的等价性，导致分数范数增大，并影响多个领域的研究。


<details>
  <summary>Details</summary>
Motivation: 许多近期工作利用去噪分数匹配来优化扩散模型的条件输入，但这种优化方式存在问题。

Method: 分析了利用去噪分数匹配优化扩散模型条件输入时，其与精确分数匹配的等价性被破坏的现象，并证明了这种偏差会导致分数范数增大。此外，还研究了使用预训练扩散模型优化数据分布时出现的类似偏差。

Result: 证明了优化扩散模型条件输入会破坏其与精确分数匹配的等价性；证明了这种偏差会导致分数范数增大；观察到使用预训练扩散模型优化数据分布时存在类似偏差。

Conclusion: 优化扩散模型条件输入的行为会引入偏差，增加分数范数，并影响包括MAR、PerCo和DreamFusion在内的多个领域的研究。

Abstract: Many recent works utilize denoising score matching to optimize the conditional input of diffusion models. In this workshop paper, we demonstrate that such optimization breaks the equivalence between denoising score matching and exact score matching. Furthermore, we show that this bias leads to higher score norm. Additionally, we observe a similar bias when optimizing the data distribution using a pre-trained diffusion model. Finally, we discuss the wide range of works across different domains that are affected by this bias, including MAR for auto-regressive generation, PerCo for image compression, and DreamFusion for text to 3D generation.

</details>


### [387] [Improving a Hybrid Graphsage Deep Network for Automatic Multi-objective Logistics Management in Supply Chain](https://arxiv.org/abs/2511.11753)
*Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar*

Main category: cs.LG

TL;DR: 本文提出了一种混合图神经网络（H-GSN）来优化供应链物流管理，通过预测货运类型、延迟和交通状况，提高了供应链的韧性和可持续性。


<details>
  <summary>Details</summary>
Motivation: 提高供应链的韧性和可持续性，通过优化物流、运输和仓储管理。

Method: 提出了一种混合图神经网络（H-GSN）用于多任务物流管理，以预测货运类型、货运状态、交通状况、物流ID和物流延迟。

Result: 在三个不同的Kaggle数据库（DataCo、Shipping和Smart Logistics）上进行了评估。Smart Logistics数据集上的物流ID和交通状况预测平均准确率分别为97.8%和100%。DataCo数据集上的货运类型预测平均准确率为98.7%，Shipping数据集上的物流延迟预测平均准确率为99.4%。

Conclusion: 所提出的H-GSN方法在提高供应链韧性和可持续性方面是有效的，其在不同物流场景下的评估指标证实了其效率。

Abstract: Systematic logistics, conveyance amenities and facilities as well as warehousing information play a key role in fostering profitable development in a supply chain. The aim of transformation in industries is the improvement of the resiliency regarding the supply chain. The resiliency policies are required for companies to affect the collaboration with logistics service providers positively. The decrement of air pollutant emissions is a persistent advantage of the efficient management of logistics and transportation in supply chain. The management of shipment type is a significant factor in analyzing the sustainability of logistics and supply chain. An automatic approach to predict the shipment type, logistics delay and traffic status are required to improve the efficiency of the supply chain management. A hybrid graphsage network (H-GSN) is proposed in this paper for multi-task purpose of logistics management in a supply chain. The shipment type, shipment status, traffic status, logistics ID and logistics delay are the objectives in this article regarding three different databases including DataCo, Shipping and Smart Logistcis available on Kaggle as supply chain logistics databases. The average accuracy of 97.8% and 100% are acquired for 10 kinds of logistics ID and 3 types of traffic status prediction in Smart Logistics dataset. The average accuracy of 98.7% and 99.4% are obtained for shipment type prediction in DataCo and logistics delay in Shipping database, respectively. The evaluation metrics for different logistics scenarios confirm the efficiency of the proposed method to improve the resilience and sustainability of the supply chain.

</details>


### [388] [Coordinate Descent for Network Linearization](https://arxiv.org/abs/2511.11781)
*Vlad Rakhlin,Amir Jevnisek,Shai Avidan*

Main category: cs.LG

TL;DR: ReLU 激活函数是基于 ResNet 网络的私有推理的主要瓶颈，因为它会带来显著的推理延迟。ReLU 数量的减少是一个离散优化问题，有两种常见的解决方法。大多数当前最先进的方法都基于平滑近似，同时优化网络精度和 ReLU 预算。然而，优化过程的最后一个硬阈值步骤通常会导致较大的性能损失。我们采用了一种替代方法，通过利用坐标下降作为我们的优化框架，直接在离散域中进行操作。与以前的方法不同，这种方法在设计上产生了稀疏的解决方案。通过广泛的实验证明，我们的方法在常用基准测试中达到了最先进水平。


<details>
  <summary>Details</summary>
Motivation: ReLU 激活函数在基于 ResNet 的私有推理中造成了显著的推理延迟，是主要的性能瓶颈。因此，减少 ReLU 的数量是一个重要的优化问题。

Method: 提出了一种直接在离散域中进行操作的优化方法，利用坐标下降作为优化框架，以解决 ReLU 数量的离散优化问题。这种方法在设计上产生了稀疏的解决方案。

Result: 通过广泛的实验证明，该方法在常用基准测试中达到了最先进水平。

Conclusion: 所提出的基于坐标下降的离散优化方法能够有效减少 ReLU 的数量，从而提高私有推理的性能，并在常用基准测试中取得了最先进的结果。

Abstract: ReLU activations are the main bottleneck in Private Inference that is based on ResNet networks. This is because they incur significant inference latency. Reducing ReLU count is a discrete optimization problem, and there are two common ways to approach it. Most current state-of-the-art methods are based on a smooth approximation that jointly optimizes network accuracy and ReLU budget at once. However, the last hard thresholding step of the optimization usually introduces a large performance loss. We take an alternative approach that works directly in the discrete domain by leveraging Coordinate Descent as our optimization framework. In contrast to previous methods, this yields a sparse solution by design. We demonstrate, through extensive experiments, that our method is State of the Art on common benchmarks.

</details>


### [389] [Transformers vs. Recurrent Models for Estimating Forest Gross Primary Production](https://arxiv.org/abs/2511.11880)
*David Montero,Miguel D. Mahecha,Francesco Martinuzzi,César Aybar,Anne Klosterhalfen,Alexander Knohl,Jesús Anaya,Clemens Mosig,Sebastian Wieneke*

Main category: cs.LG

TL;DR: EC塔在估算森林总初级生产力（GPP）方面存在空间覆盖有限的挑战，而传统遥感方法难以捕捉GPP复杂的时间动态。本研究旨在比较两种深度学习模型（GPT-2和LSTM）在利用多模态数据预测GPP方面的性能，并分析模型架构、上下文长度和输入特征对预测结果的影响。


<details>
  <summary>Details</summary>
Motivation: 现有技术在利用遥感数据进行大规模GPP估算时，在捕捉GPP时间动态方面存在局限性。深度学习和数据融合技术为改进GPP预测提供了新的机遇，但关于不同深度学习模型在多模态GPP预测方面的比较评估仍然不足。

Method: 本研究使用多变量输入（包括来自EC塔的数据以及Sentinel-1、Sentinel-2、MODIS等传感器的数据），比较了两种代表性深度学习模型：GPT-2（Transformer架构）和LSTM（循环神经网络）在预测GPP方面的性能。此外，还分析了不同时间上下文长度对模型精度的影响，并进行了特征重要性分析。

Result: GPT-2和LSTM在GPP预测方面达到了相似的准确度。LSTM在整体表现上略优，而GPT-2在极端事件预测方面表现更佳。LSTM在达到相似精度的情况下，所需的输入时间窗口比GPT-2短，表明两者在精度-效率之间存在权衡。特征重要性分析表明，辐射是主要的预测因子，其次是Sentinel-2、MODIS陆表温度和Sentinel-1。

Conclusion: 模型架构、上下文长度和多模态输入共同决定了GPP预测的性能。GPT-2和LSTM在GPP预测方面各有优劣，LSTM在整体效率上更优，而GPT-2在处理极端事件方面表现突出。研究结果为未来开发用于监测陆地碳动态的深度学习框架提供了指导。

Abstract: Monitoring the spatiotemporal dynamics of forest CO$_2$ uptake (Gross Primary Production, GPP), remains a central challenge in terrestrial ecosystem research. While Eddy Covariance (EC) towers provide high-frequency estimates, their limited spatial coverage constrains large-scale assessments. Remote sensing offers a scalable alternative, yet most approaches rely on single-sensor spectral indices and statistical models that are often unable to capture the complex temporal dynamics of GPP. Recent advances in deep learning (DL) and data fusion offer new opportunities to better represent the temporal dynamics of vegetation processes, but comparative evaluations of state-of-the-art DL models for multimodal GPP prediction remain scarce. Here, we explore the performance of two representative models for predicting GPP: 1) GPT-2, a transformer architecture, and 2) Long Short-Term Memory (LSTM), a recurrent neural network, using multivariate inputs. Overall, both achieve similar accuracy. But, while LSTM performs better overall, GPT-2 excels during extreme events. Analysis of temporal context length further reveals that LSTM attains similar accuracy using substantially shorter input windows than GPT-2, highlighting an accuracy-efficiency trade-off between the two architectures. Feature importance analysis reveals radiation as the dominant predictor, followed by Sentinel-2, MODIS land surface temperature, and Sentinel-1 contributions. Our results demonstrate how model architecture, context length, and multimodal inputs jointly determine performance in GPP prediction, guiding future developments of DL frameworks for monitoring terrestrial carbon dynamics.

</details>


### [390] [A Systematic Analysis of Out-of-Distribution Detection Under Representation and Training Paradigm Shifts](https://arxiv.org/abs/2511.11934)
*C. César Claros Olivares,Austin J. Brockmeier*

Main category: cs.LG

TL;DR: 本文系统比较了不同OOD检测方法在不同CLIP分层模型下的表现，使用AURC和AUGRC作为主要评估指标。


<details>
  <summary>Details</summary>
Motivation: 在分布外(OOD)检测领域，缺乏对不同方法在不同表征学习范式下性能的系统性比较，特别是使用统一的评估指标和统计检验方法。

Method: 本文采用了基于多重比较控制的、基于排名的评估流程（Friedman检验与Conover-Holm事后检验）以及Bron-Kerbosch算法来系统性地比较不同OOD检测方法的性能。评估对象包括从头训练的CNN和微调的Vision Transformer (ViT)，在CIFAR-10/100、SuperCIFAR-100和TinyImageNet数据集上进行测试。

Result: 研究发现，学习到的特征空间对OOD检测效果有显著影响。对于CNN和ViT，概率分数（如MSR, GEN）在检测误分类（ID）方面表现优异。在更强的分布偏移下，几何感知分数（如NNGuide, fDBD, CTM）在CNN上表现突出，而在ViT上，GradNorm和KPCA重构误差则持续具有竞争力。此外，还发现Monte-Carlo Dropout（MCD）存在类别数量依赖的权衡，并且简单的PCA投影能提升多种检测器的性能。

Conclusion: OOD检测的效果很大程度上取决于所使用的表征学习方法。研究结果为在分布偏移情况下选择合适的方法提供了统计学依据，并强调了以表征为中心的OOD检测观点。

Abstract: We present a systematic comparison of out-of-distribution (OOD) detection methods across CLIP-stratified regimes using AURC and AUGRC as primary metrics. Experiments cover two representation paradigms: CNNs trained from scratch and a fine-tuned Vision Transformer (ViT), evaluated on CIFAR-10/100, SuperCIFAR-100, and TinyImageNet. Using a multiple-comparison-controlled, rank-based pipeline (Friedman test with Conover-Holm post-hoc) and Bron-Kerbosch cliques, we find that the learned feature space largely determines OOD efficacy. For both CNNs and ViTs, probabilistic scores (e.g., MSR, GEN) dominate misclassification (ID) detection. Under stronger shifts, geometry-aware scores (e.g., NNGuide, fDBD, CTM) prevail on CNNs, whereas on ViTs GradNorm and KPCA Reconstruction Error remain consistently competitive. We further show a class-count-dependent trade-off for Monte-Carlo Dropout (MCD) and that a simple PCA projection improves several detectors. These results support a representation-centric view of OOD detection and provide statistically grounded guidance for method selection under distribution shift.

</details>


### [391] [Selecting Fine-Tuning Examples by Quizzing VLMs](https://arxiv.org/abs/2511.12002)
*Tenghao Ji,Eytan Adar*

Main category: cs.LG

TL;DR: QZLoRA使用QuizRank方法来自动选择用于文本到图像扩散模型微调的图像，以提高生成图像的质量和代表性。


<details>
  <summary>Details</summary>
Motivation: 从质量参差不齐的图像集（如维基共享资源）进行微调通常会导致模型生成效果不佳。然而，使用能够充分体现目标概念（例如，雌性山蓝鸟）的训练图像，可以确保生成图像具有代表性（例如，具有典型的蓝色翅膀和灰色胸部）。

Method: 提出QZLoRA框架，该框架利用QuizRank方法，通过将图像视为“教育干预”并对视觉语言模型（VLM）进行“测验”来自动对图像进行排名，从而选择用于低秩自适应（LoRA）的图像。

Result: QZLoRA能够用更少的样本生成与主题更契合、更逼真的图像，并且能够生成同样具有代表性的风格化图像（例如，插图）。

Conclusion: 将自动视觉推理与参数高效微调相结合，在主题自适应生成模型方面显示出巨大潜力。

Abstract: A challenge in fine-tuning text-to-image diffusion models for specific topics is to select good examples. Fine-tuning from image sets of varying quality, such as Wikipedia Commons, will often produce poor output. However, training images that \textit{do} exemplify the target concept (e.g., a \textit{female Mountain Bluebird}) help ensure that the generated images are similarly representative (e.g., have the prototypical blue-wings and gray chest). In this work, we propose QZLoRA, a framework to select images for low-rank adaptation (LoRA). The approach leverages QuizRank, a method to automatically rank images by treating them as an `educational intervention' and `quizzing' a VLM. We demonstrate that QZLoRA can produce better aligned, photorealistic images with fewer samples. We also show that these fine-tuned models can produce stylized that are similarly representative (i.e., illustrations). Our results highlight the promise of combining automated visual reasoning with parameter-efficient fine-tuning for topic-adaptive generative modeling.

</details>


### [392] [Variation-Bounded Loss for Noise-Tolerant Learning](https://arxiv.org/abs/2511.12143)
*Jialiang Wang,Xiong Zhou,Xianming Liu,Gangfeng Hu,Deming Zhai,Junjun Jiang,Haoliang Li*

Main category: cs.LG

TL;DR: 提出一种名为变差有界损失（VBL）的新型鲁棒损失函数族，通过界定变差比来提高损失函数的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决监督学习中有噪声标签的负面影响问题，提出鲁棒损失函数。

Method: 提出变差比（Variation Ratio）作为衡量损失函数鲁棒性的新指标，并基于此提出变差有界损失（VBL）。对变差比进行理论分析，证明更小的变差比能带来更好的鲁棒性，并展示变差比如何放宽对称条件和实现非对称条件。将常用损失函数改写为变差有界形式。

Result: 在多个数据集上进行实验，验证了该方法的有效性和灵活性。

Conclusion: 变差有界损失（VBL）及其变差比指标能够有效提高损失函数的鲁棒性，并且具有良好的通用性和实用性。

Abstract: Mitigating the negative impact of noisy labels has been aperennial issue in supervised learning. Robust loss functions have emerged as a prevalent solution to this problem. In this work, we introduce the Variation Ratio as a novel property related to the robustness of loss functions, and propose a new family of robust loss functions, termed Variation-Bounded Loss (VBL), which is characterized by a bounded variation ratio. We provide theoretical analyses of the variation ratio, proving that a smaller variation ratio would lead to better robustness. Furthermore, we reveal that the variation ratio provides a feasible method to relax the symmetric condition and offers a more concise path to achieve the asymmetric condition. Based on the variation ratio, we reformulate several commonly used loss functions into a variation-bounded form for practical applications. Positive experiments on various datasets exhibit the effectiveness and flexibility of our approach.

</details>


### [393] [Calibrated Adversarial Sampling: Multi-Armed Bandit-Guided Generalization Against Unforeseen Attacks](https://arxiv.org/abs/2511.12265)
*Rui Wang,Zeming Wei,Xiyue Zhang,Meng Sun*

Main category: cs.LG

TL;DR: 对抗性训练（AT）框架无法处理所有实际攻击类型，我们提出了CAS来提高DNN的整体鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AT框架通常只关注有限的攻击类型，导致DNN容易受到未考虑到的攻击。

Method: 提出了一种名为CAS的有效微调方法，该方法从多臂老虎机框架的优化角度出发，考虑了多重鲁棒性维度的动态和相互依赖特性，通过动态设计奖励和平衡探索与利用来提升鲁棒性。

Result: CAS在基准数据集上实现了优越的整体鲁棒性，同时保持了高清洁准确率。

Conclusion: CAS为DNN的鲁棒泛化提供了一个新范式。

Abstract: Deep Neural Networks (DNNs) are known to be vulnerable to various adversarial perturbations. To address the safety concerns arising from these vulnerabilities, adversarial training (AT) has emerged as one of the most effective paradigms for enhancing the robustness of DNNs. However, existing AT frameworks primarily focus on a single or a limited set of attack types, leaving DNNs still exposed to attack types that may be encountered in practice but not addressed during training. In this paper, we propose an efficient fine-tuning method called Calibrated Adversarial Sampling (CAS) to address these issues. From the optimization perspective within the multi-armed bandit framework, it dynamically designs rewards and balances exploration and exploitation by considering the dynamic and interdependent characteristics of multiple robustness dimensions. Experiments on benchmark datasets show that CAS achieves superior overall robustness while maintaining high clean accuracy, providing a new paradigm for robust generalization of DNNs.

</details>


### [394] [BSO: Binary Spiking Online Optimization Algorithm](https://arxiv.org/abs/2511.12502)
*Yu Liang,Yu Yang,Wenjie Wei,Ammar Belatreche,Shuai Wang,Malu Zhang,Yang Yang*

Main category: cs.LG

TL;DR: BSO是一种新的在线训练算法，可显著减少BSNN的训练内存，而T-BSO通过利用时间动态来进一步提高性能。


<details>
  <summary>Details</summary>
Motivation: BSNNs虽然高效，但其训练算法需要大量的内存来存储潜在权重和处理时间信息。本研究旨在解决这一问题。

Method: 提出了一种名为BSO的新型在线训练算法，它在在线训练框架下直接通过翻转信号更新权重，当梯度动量和权重的乘积超过阈值时触发这些信号，从而无需在训练期间存储潜在权重。此外，还提出了一种名为T-BSO的时间感知变体，它通过跨时间步捕获梯度信息来调整阈值，以利用BSNN的内在时间动态。

Result: 理论分析保证了BSO和T-BSO的收敛性，并提供了描述其收敛速度的正式遗憾界限。实验证明，与现有的BSNN训练方法相比，BSO和T-BSO都取得了更优的优化性能。

Conclusion: BSO和T-BSO算法在减少BSNN训练内存和提高优化性能方面表现出色，为高效训练BSNN提供了有前景的解决方案。

Abstract: Binary Spiking Neural Networks (BSNNs) offer promising efficiency advantages for resource-constrained computing. However, their training algorithms often require substantial memory overhead due to latent weights storage and temporal processing requirements. To address this issue, we propose Binary Spiking Online (BSO) optimization algorithm, a novel online training algorithm that significantly reduces training memory. BSO directly updates weights through flip signals under the online training framework. These signals are triggered when the product of gradient momentum and weights exceeds a threshold, eliminating the need for latent weights during training. To enhance performance, we propose T-BSO, a temporal-aware variant that leverages the inherent temporal dynamics of BSNNs by capturing gradient information across time steps for adaptive threshold adjustment. Theoretical analysis establishes convergence guarantees for both BSO and T-BSO, with formal regret bounds characterizing their convergence rates. Extensive experiments demonstrate that both BSO and T-BSO achieve superior optimization performance compared to existing training methods for BSNNs. The codes are available at https://github.com/hamings1/BSO.

</details>


### [395] [Linear time small coresets for k-mean clustering of segments with applications](https://arxiv.org/abs/2511.12564)
*David Denisov,Shlomi Dolev,Dan Felmdan,Michael Segal*

Main category: cs.LG

TL;DR: 本研究提出了一种用于k-means聚类问题的coreset构造方法，该方法能够处理任意的输入线段，并在常数k和ε下，构造出大小为O(log^2 n)且可在O(nd)时间内计算的coreset。实验证明了该方法在视频跟踪等应用中的有效性。


<details>
  <summary>Details</summary>
Motivation: k-means聚类问题通常是针对点集进行的，本研究将问题扩展到线段集合，并提出了一种能够处理任意输入线段的coreset构造方法。

Method: 提出了一种coreset构造方法，该方法能够处理任意的输入线段，并在常数k和ε下，构造出大小为O(log^2 n)且可在O(nd)时间内计算的coreset。

Result: 所提出的coreset构造方法能够在O(nd)时间内生成大小为O(log^2 n)的coreset，并且在实际应用（如视频跟踪）中能够实现显著的加速，同时保持较小的聚类精度损失。

Conclusion: 本研究提出的coreset构造方法在理论上和实践上都证明了其有效性，能够高效地解决线段集合的k-means聚类问题。

Abstract: We study the $k$-means problem for a set $\mathcal{S} \subseteq \mathbb{R}^d$ of $n$ segments, aiming to find $k$ centers $X \subseteq \mathbb{R}^d$ that minimize
  $D(\mathcal{S},X) := \sum_{S \in \mathcal{S}} \min_{x \in X} D(S,x)$, where $D(S,x) := \int_{p \in S} |p - x| dp$
  measures the total distance from each point along a segment to a center. Variants of this problem include handling outliers, employing alternative distance functions such as M-estimators, weighting distances to achieve balanced clustering, or enforcing unique cluster assignments. For any $\varepsilon > 0$, an $\varepsilon$-coreset is a weighted subset $C \subseteq \mathbb{R}^d$ that approximates $D(\mathcal{S},X)$ within a factor of $1 \pm \varepsilon$ for any set of $k$ centers, enabling efficient streaming, distributed, or parallel computation. We propose the first coreset construction that provably handles arbitrary input segments. For constant $k$ and $\varepsilon$, it produces a coreset of size $O(\log^2 n)$ computable in $O(nd)$ time. Experiments, including a real-time video tracking application, demonstrate substantial speedups with minimal loss in clustering accuracy, confirming both the practical efficiency and theoretical guarantees of our method.

</details>


### [396] [Functional Mean Flow in Hilbert Space](https://arxiv.org/abs/2511.12898)
*Zhiqi Li,Yuchen Sun,Greg Turk,Bo Zhu*

Main category: cs.LG

TL;DR: Functional Mean Flow (FMF)是一个新的单步生成模型，适用于函数域，能够处理时间序列、图像、偏微分方程和3D几何等多种数据。它通过理论和实践的结合，提供了一种有效的训练和采样方法，并引入了一种改进稳定性的x1-预测变体。


<details>
  <summary>Details</summary>
Motivation: 将单步生成模型（Mean Flow）扩展到函数域，以解决函数数据生成任务。

Method: 提出Functional Flow Matching理论和FMF模型，并实现x1-预测变体以提高稳定性。

Result: FMF模型在处理时间序列、图像、偏微分方程和3D几何等函数数据生成任务上表现出有效性。

Conclusion: FMF为函数数据生成提供了一种实用且有效的单步流匹配方法。

Abstract: We present Functional Mean Flow (FMF) as a one-step generative model defined in infinite-dimensional Hilbert space. FMF extends the one-step Mean Flow framework to functional domains by providing a theoretical formulation for Functional Flow Matching and a practical implementation for efficient training and sampling. We also introduce an $x_1$-prediction variant that improves stability over the original $u$-prediction form. The resulting framework is a practical one-step Flow Matching method applicable to a wide range of functional data generation tasks such as time series, images, PDEs, and 3D geometry.

</details>


### [397] [Angular Gradient Sign Method: Uncovering Vulnerabilities in Hyperbolic Networks](https://arxiv.org/abs/2511.12985)
*Minsoo Jo,Dongyoon Yang,Taesup Kim*

Main category: cs.LG

TL;DR: 通过利用双曲空间的几何特性，提出了一种新的对抗性攻击方法，该方法在图像分类和跨模态检索任务中比传统方法具有更高的欺骗率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在双曲网络中没有考虑到双曲结构，可能导致攻击效率低下或几何不一致。因此，需要重新评估非欧几里几何中的攻击策略。

Method: 该方法在双曲空间的切空间中计算损失函数的梯度，并将其分解为径向（深度）和角向（语义）分量，仅从角向分量推导出扰动，从而在语义敏感的方向上生成对抗样本。

Result: 与传统对抗性攻击相比，该方法在图像分类、跨模态检索任务和网络架构方面实现了更高的欺骗率。

Conclusion: 该工作强调了几何感知对抗策略在弯曲表示空间中的重要性，并为攻击层次嵌入提供了一个原则性框架。

Abstract: Adversarial examples in neural networks have been extensively studied in Euclidean geometry, but recent advances in \textit{hyperbolic networks} call for a reevaluation of attack strategies in non-Euclidean geometries. Existing methods such as FGSM and PGD apply perturbations without regard to the underlying hyperbolic structure, potentially leading to inefficient or geometrically inconsistent attacks. In this work, we propose a novel adversarial attack that explicitly leverages the geometric properties of hyperbolic space. Specifically, we compute the gradient of the loss function in the tangent space of hyperbolic space, decompose it into a radial (depth) component and an angular (semantic) component, and apply perturbation derived solely from the angular direction. Our method generates adversarial examples by focusing perturbations in semantically sensitive directions encoded in angular movement within the hyperbolic geometry. Empirical results on image classification, cross-modal retrieval tasks and network architectures demonstrate that our attack achieves higher fooling rates than conventional adversarial attacks, while producing high-impact perturbations with deeper insights into vulnerabilities of hyperbolic embeddings. This work highlights the importance of geometry-aware adversarial strategies in curved representation spaces and provides a principled framework for attacking hierarchical embeddings.

</details>


### [398] [Real-time prediction of breast cancer sites using deformation-aware graph neural network](https://arxiv.org/abs/2511.13082)
*Kyunghyun Lee,Yong-Min Shin,Minwoo Shin,Jihun Kim,Sunghwan Lim,Won-Yong Shin,Kyungho Yoon*

Main category: cs.LG

TL;DR: 本研究提出了一种基于图神经网络（GNN）的模型，用于在磁共振成像（MRI）引导的活检过程中实时预测乳腺癌病灶的变形，提高了诊断的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 早期诊断乳腺癌对于制定治疗计划和改善患者预后至关重要。尽管MRI引导的活检效果良好，但其过程耗时且成本高。间接MRI引导的活检虽然可以在MRI室外进行，但在创建准确的实时可变形乳腺模型方面仍存在挑战。

Method: 本研究开发了一个基于图神经网络（GNN）的模型，该模型能够准确地实时预测活检过程中变形的乳腺癌病灶位置。研究人员首先构建了个体化的有限元（FE）模型，结合了乳腺和肿瘤的MR图像结构信息来模拟变形行为。然后，利用GNN模型处理表面位移和基于距离的图数据，以准确预测包括肿瘤区域变形在内的整体组织位移。

Result: 该模型在幻影和真实患者数据集上进行了验证，在肿瘤节点位移方面达到了0.2毫米（mm）的准确率（RMSE），在与实际癌变区域的空间重叠方面取得了0.977的Dice相似系数（DSC）。此外，模型实现了实时推理，与传统的FE模拟相比，计算成本提高了4000多倍。

Conclusion: 研究提出的变形感知GNN模型为乳腺癌活检中的实时肿瘤位移预测提供了一个有前景的解决方案，具有高精度和实时能力。将其整合到临床实践中，有望显著提高乳腺癌诊断的精确度和效率。

Abstract: Early diagnosis of breast cancer is crucial, enabling the establishment of appropriate treatment plans and markedly enhancing patient prognosis. While direct magnetic resonance imaging-guided biopsy demonstrates promising performance in detecting cancer lesions, its practical application is limited by prolonged procedure times and high costs. To overcome these issues, an indirect MRI-guided biopsy that allows the procedure to be performed outside of the MRI room has been proposed, but it still faces challenges in creating an accurate real-time deformable breast model. In our study, we tackled this issue by developing a graph neural network (GNN)-based model capable of accurately predicting deformed breast cancer sites in real time during biopsy procedures. An individual-specific finite element (FE) model was developed by incorporating magnetic resonance (MR) image-derived structural information of the breast and tumor to simulate deformation behaviors. A GNN model was then employed, designed to process surface displacement and distance-based graph data, enabling accurate prediction of overall tissue displacement, including the deformation of the tumor region. The model was validated using phantom and real patient datasets, achieving an accuracy within 0.2 millimeters (mm) for cancer node displacement (RMSE) and a dice similarity coefficient (DSC) of 0.977 for spatial overlap with actual cancerous regions. Additionally, the model enabled real-time inference and achieved a speed-up of over 4,000 times in computational cost compared to conventional FE simulations. The proposed deformation-aware GNN model offers a promising solution for real-time tumor displacement prediction in breast biopsy, with high accuracy and real-time capability. Its integration with clinical procedures could significantly enhance the precision and efficiency of breast cancer diagnosis.

</details>


### [399] [Uncovering and Mitigating Transient Blindness in Multimodal Model Editing](https://arxiv.org/abs/2511.13243)
*Xiaoqi Han,Ru Li,Ran Yi,Hongye Tan,Zhuomin Liang,Víctor Gutiérrez-Basulto,Jeff Z. Pan*

Main category: cs.LG

TL;DR: 现有的多模态模型编辑评估方法会因为使用低相似度或随机输入而高估模型性能，并掩盖过拟合现象。本文提出了一个全面的局部性评估框架，包含随机图像、无图像和一致图像三种局部性，并通过七种不同数据类型进行操作化，以实现对多模态编辑的详细、结构化分析。此外，本文还引入了动态评估方法De-VQA，发现了“瞬时失明”现象——模型会过分拟合编辑后的文本而忽略图像。实验表明，本文提出的方法通过引入感知局部性的对抗性损失，能够有效缓解“瞬时失明”，平均提高17%的局部性。


<details>
  <summary>Details</summary>
Motivation: 现有的评估方法无法准确评估多模态模型编辑的真实性能，容易导致过拟合，需要新的评估框架。

Method: 提出包含随机图像、无图像和一致图像三种局部性的评估框架，并引入De-VQA评估方法，以及基于感知局部性的对抗性损失。

Result: 新评估框架和方法能有效发现并缓解“瞬时失明”现象，平均提高17%的局部性，优于现有基线方法。

Conclusion: 本文提出的多模态模型编辑局部性评估框架和方法能够更准确地评估模型性能，并有效提升模型的泛化能力。

Abstract: Multimodal Model Editing (MMED) aims to correct erroneous knowledge in multimodal models. Existing evaluation methods, adapted from textual model editing, overstate success by relying on low-similarity or random inputs, obscure overfitting. We propose a comprehensive locality evaluation framework, covering three key dimensions: random-image locality, no-image locality, and consistent-image locality, operationalized through seven distinct data types, enabling a detailed and structured analysis of multimodal edits. We introduce De-VQA, a dynamic evaluation for visual question answering, uncovering a phenomenon we term transient blindness, overfitting to edit-similar text while ignoring visuals. Token analysis shows edits disproportionately affect textual tokens. We propose locality-aware adversarial losses to balance cross-modal representations. Empirical results demonstrate that our approach consistently outperforms existing baselines, reducing transient blindness and improving locality by 17% on average.

</details>


### [400] [Tuning for Two Adversaries: Enhancing the Robustness Against Transfer and Query-Based Attacks using Hyperparameter Tuning](https://arxiv.org/abs/2511.13654)
*Pascal Zimmer,Ghassan Karame*

Main category: cs.LG

TL;DR: 该研究首次详细分析了优化超参数（如学习率、权重衰减、动量和批大小）如何影响对迁移攻击和查询攻击的鲁棒性。研究结果显示，降低学习率可显著提高对迁移攻击的鲁棒性（最高达64%），而提高学习率则可提高对查询攻击的鲁棒性（最高达28%）。通过调整超参数，可以同时缓解这两种攻击类型，其中分布式模型在这种超参数调整中获益最大。


<details>
  <summary>Details</summary>
Motivation: 研究旨在分析优化超参数对模型在迁移攻击和查询攻击下的鲁棒性影响，并探索如何通过调整这些超参数来同时提高模型对两种攻击的防御能力。

Method: 通过理论和实验相结合的方式，在中心化训练、集成学习和分布式训练等多种实际部署场景下，分析了学习率、权重衰减、动量和批大小等优化超参数对模型鲁棒性的影响。

Result: 研究发现，降低学习率能显著提高模型对迁移攻击的鲁棒性（最高提升64%），而提高学习率则能提高模型对查询攻击的鲁棒性（最高提升28%）。分布式模型在超参数调整方面表现最佳，能够同时有效地减轻两种攻击类型。

Conclusion: 优化超参数对于提高模型对迁移攻击和查询攻击的鲁棒性至关重要，并且存在相互制约的关系。通过精细调整超参数，特别是针对分布式训练模型，可以实现对两种攻击的有效防御，取得显著的性能提升。

Abstract: In this paper, we present the first detailed analysis of how optimization hyperparameters -- such as learning rate, weight decay, momentum, and batch size -- influence robustness against both transfer-based and query-based attacks. Supported by theory and experiments, our study spans a variety of practical deployment settings, including centralized training, ensemble learning, and distributed training. We uncover a striking dichotomy: for transfer-based attacks, decreasing the learning rate significantly enhances robustness by up to $64\%$. In contrast, for query-based attacks, increasing the learning rate consistently leads to improved robustness by up to $28\%$ across various settings and data distributions. Leveraging these findings, we explore -- for the first time -- the optimization hyperparameter design space to jointly enhance robustness against both transfer-based and query-based attacks. Our results reveal that distributed models benefit the most from hyperparameter tuning, achieving a remarkable tradeoff by simultaneously mitigating both attack types more effectively than other training setups.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [401] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 该论文提出了一种分层框架来解决大规模多无人机系统中实时性、对抗鲁棒性和隐私保护之间的权衡问题，解决了现有框架计算复杂度高和缺乏拜占庭容错的问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模多无人机系统中实时性、对抗鲁棒性和隐私保护之间的权衡问题，并提供拜占庭容错能力。

Method: 提出一个三层架构：包含基于图注意力（<10ms延迟）的局部层、基于稀疏注意力和异步联邦学习（O(nk)复杂度）的区域层、以及基于Hashgraph协议的全局层。采用自适应差分隐私机制动态调整噪声水平，并使用基于DHT的轻量级审计日志替代区块链共识。

Result: 在500架无人机的仿真场景下，实现了<2.0%的碰撞率和f<n/3的拜占庭容错能力，且中位数成本在50ms内获得95%置信区间的决策。

Conclusion: 所提出的分层框架通过分层设计，有效解决了大规模多无人机系统中实时性、对抗鲁棒性和隐私保护之间的权衡问题，并实现了可扩展性和拜占庭容错能力。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [402] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 提出一种基于机器人手臂的系统，用于收集服装的触觉数据，并通过机器学习证明了运动相关标签对表征服装触觉感知的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了揭示使服装舒适的物理特性，需要系统地收集滑动过程中的触觉数据。

Method: 提出一个基于机器人手臂的系统，使用模拟指尖进行扫掠测量，并精确控制速度和方向，以创建带运动标签的多模态触觉数据库。

Result: 机器学习评估显示，加入运动相关参数能够提高音频和加速度数据的识别准确性，证明了运动相关标签在表征服装触觉感知方面的有效性。

Conclusion: 该系统提供了一种可扩展的、非破坏性的服装触觉数据捕获方法，有助于未来织物感知和再现的研究。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [403] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 使用基于图像的方法通过3D分段闭合曲线模型来分析植物卷须在机械刺激下的形状变化。


<details>
  <summary>Details</summary>
Motivation: 尽管攀缘植物已被研究了很长时间，但要提取有关时间形状变化、触发事件及其接触位置之间关系的信息仍然具有挑战性。

Method: 提出一种基于图像的方法，使用3D分段闭合曲线模型来分析植物卷须在机械刺激下的形状变化。

Result: 该方法具有很高的鲁棒性和可靠性，精度 R2 > 0.99。与基于深度学习的方法相比，该方法具有数据需求少、计算成本低和可解释性强等优点。分析显示，植物卷须的顶端部分响应性更高。

Conclusion: 该研究提供了一种获得对植物生物力学新见解的方法，并为设计和开发受攀缘植物启发的智能机器人系统奠定了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [404] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: ExpertAD是一个利用MoE架构提升自动驾驶系统性能的新框架，通过PA和MoSE模块解决语义模糊、任务干扰和推理延迟问题，实验表明能显著降低碰撞率和延迟。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统在处理复杂场景时，面临语义理解不准确、多任务规划干扰以及推理延迟过高的问题，影响了决策的可靠性和安全性。

Method: 提出ExpertAD框架，采用MoE架构。引入感知适配器（PA）增强关键特征，采用稀疏专家混合（MoSE）减少任务间干扰，实现高效规划。

Result: ExpertAD将平均碰撞率降低高达20%，推理延迟减少25%。在罕见场景（如事故、为紧急车辆让行）和未见过的城市环境中表现出强大的泛化能力和多技能规划能力。

Conclusion: ExpertAD通过MoE架构有效解决了自动驾驶中的关键挑战，提高了感知和规划的准确性与效率，并在复杂和罕见场景下展现出优越的性能和泛化能力。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [405] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: LLM与3D视觉的融合正在改变机器人传感技术，实现了更强的环境理解和交互能力。


<details>
  <summary>Details</summary>
Motivation: 人工智能和机器人技术的快速发展，需要更强的机器人传感技术来感知、推理和与复杂环境交互。

Method: 综述了LLM和3D视觉的融合方法，包括3D数据表示、3D感知技术、场景理解、文本到3D生成、物体定位、具身代理、多模态融合等，并介绍了相关的基准数据集和评估指标。

Result: LLM与3D视觉的融合在场景理解、文本到3D生成、物体定位和具身代理方面取得了显著进展，多模态融合技术增强了机器人对环境的理解和决策能力。

Conclusion: LLM与3D视觉的融合为下一代机器人传感技术指明了方向，未来的研究应关注自适应模型架构、跨模态对齐和实时处理能力，以实现更智能、更具上下文感知能力和自主性的机器人传感系统。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [406] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: 当不确定性高时，自动驾驶汽车可以寻求远程人工操作员的帮助，以获得高层指导。为解决网络延迟和人工响应时间带来的关键决策时机问题，我们提出了 LAVQA，一个集成了视觉问答（VQA）和时空风险可视化的延迟感知共享自主框架。LAVQA 通过延迟诱导碰撞图（LICOM）增强了视觉查询，LICOM 是一个动态演变的地图，同时表示时间延迟和空间不确定性。这使得远程操作员能够观察到在动态障碍物和延迟响应存在的情况下，车辆安全区域随时间的推移而变化。在 CARLA 中进行的闭环模拟表明，与忽略延迟的基线方法相比，LAVQA 可将碰撞率降低 8 倍以上。


<details>
  <summary>Details</summary>
Motivation: 当自动驾驶汽车面临高度不确定性时，它们可能需要暂停以确保安全，并能够从远程人工操作员那里获得高层指导。这种称为“共享自主”的模式允许自动驾驶汽车和远程操作员共同制定适当的响应。然而，由于网络延迟和人工响应时间可变，关键决策的时机成为了一个挑战。因此，有必要开发一种能够处理这些不确定性的框架。

Method: 本文提出了一种名为 LAVQA 的延迟感知共享自主框架。该框架集成了视觉问答（VQA）和时空风险可视化。LAVQA 的核心是延迟诱导碰撞图（LICOM），它是一个动态演变的地图，能够同时表示时间延迟和空间不确定性。通过 LICOM，LAVQA 增强了对车辆周围环境的视觉查询，使远程操作员能够观察到车辆安全区域如何随时间变化，特别是在存在动态障碍物和通信延迟的情况下。

Result: 在 CARLA（自动驾驶汽车模拟的实际标准）中进行的闭环模拟表明，LAVQA 框架能够显著降低碰撞率。与忽略延迟的基线方法相比，LAVQA 可以将碰撞率降低 8 倍以上。

Conclusion: LAVQA 框架通过集成 VQA 和时空风险可视化，并引入延迟诱导碰撞图（LICOM），有效地解决了自动驾驶汽车在不确定性和网络延迟下的共享自主问题。模拟结果表明，该框架能够显著提高安全性，降低碰撞率，为自动驾驶汽车在复杂环境下的可靠运行提供了有力的支持。

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [407] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: 该研究提出了一种集成了SLAM和基于Soar的认知架构的自主水下认知系统(AUCS)，以应对深海探索中的导航挑战。


<details>
  <summary>Details</summary>
Motivation: 深海探索面临失联、迷航、导航失败等严峻挑战，需要更智能的自主导航系统。

Method: AUCS融合了声纳、激光雷达、惯性测量单元和多普勒计程仪等多传感器数据，并结合了感知、注意、规划和学习的认知推理模块，实现了语义理解、自适应传感器管理和基于记忆的学习。

Result: AUCS能够区分动态和静态物体，减少错误的闭环，提高地图长期一致性，并实现完整的感知-认知-行动-学习循环。

Conclusion: 该系统为下一代认知潜水器系统奠定了基础，提高了深海探索的安全性和自主性。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [408] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: MATT-Diff是一个多模态主动目标跟踪的扩散策略，能够捕捉探索、专注跟踪和重新获取目标等多种行为模式，实现无需预先了解目标数量、状态或动态的智能体控制。


<details>
  <summary>Details</summary>
Motivation: 有效的目标跟踪需要平衡对未探测到或丢失目标的探索与对已探测到但不确定目标的跟踪。

Method: 提出了一种利用视觉变换器进行自我中心地图标记和注意力机制来整合高斯密度表示的可变目标估计的控制策略。该策略作为扩散模型进行训练，通过去噪过程学习生成多模态动作序列。

Result: 评估结果表明，MATT-Diff在多种目标运动情况下，其跟踪性能优于专家和行为克隆基线。

Conclusion: MATT-Diff在目标跟踪方面表现出优越的性能，验证了其在多目标跟踪方面的优势。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [409] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 该研究系统地研究了不同螺旋桨配置在干沙、湿沙、饱和沙和水等介质中的移动性能，并提出了基于传热器设计的优化螺旋桨壳体和自适应移动策略。


<details>
  <summary>Details</summary>
Motivation: 需要优化两栖移动的推进系统，以应对在水、沙地等多种环境下的移动挑战。

Method: 通过原理优先的方法分析螺旋桨性能，并引入了借鉴优化散热器设计的参数来表征螺旋桨在不同介质中的性能。

Result: 确定了影响螺旋桨性能的关键参数，并根据介质不同，提出了使用借鉴散热器设计的参数来对性能进行分类。

Conclusion: 研究结果为优化螺旋桨外壳设计和开发自适应移动策略以增强螺旋桨推进系统在两栖应用中的性能提供了指导。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [410] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 该论文提出了一种用于解决通信受限和间歇性连接下的多机器人探索（MRE-CCIC）问题的新方法，该方法结合了混合整数线性规划（MILP）来生成汇合计划，以及基于“未知场景下的汇合跟踪”（RTUS）机制的策略来执行计划，解决了先前工作中计划生成不最优和无法处理现实轨迹的问题，并在 Gazebo 仿真中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有通信受限的多机器人探索（MRE）系统在现实部署中面临的挑战，特别是需要预先了解环境信息的问题，以及先前工作中计划生成不最优和无法处理现实轨迹的局限性。

Method: 提出 MRE-CCIC 问题，并采用混合整数线性规划（MILP）进行汇合计划生成，以及基于“未知场景下的汇合跟踪”（RTUS）的策略来执行计划，RTUS 是一种允许机器人在未知条件下遵循既定计划的简单规则。

Result: 在 Gazebo 仿真环境中进行了大规模评估，结果表明所提出的方法能够及时地遵循计划并有效地完成任务。

Conclusion: 所提出的结合 MILP 计划生成和 RTUS 策略的方法能够有效地解决通信受限和间歇性连接下的多机器人探索问题，并能及时遵循计划以高效完成任务。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [411] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 该研究提出了一种框架，将大型语言模型（LLM）转变为随机语义传感器，用于机器人导航中的安全高效任务执行。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要集中在让机器人理解“做什么”而非“如何安全高效地做”，尤其是在复杂的、以人为中心的、富含语义的空间中。本研究旨在填补这一空白。

Method: 提出一个框架，将LLM作为随机语义传感器，其输出可以调节经典规划器。该方法结合了自然语言提示、语义地图，通过多次LLM“危险”判断，并利用贝叶斯bootstrap来近似风险的后验分布。基于后验的统计信息，构建了一个势能成本函数，用于路径规划问题。

Result: 在模拟环境和基于BIM的数字孪生中，该方法能够根据明确的提示和隐含的上下文信息自适应地调整机器人的移动方式。研究提供了定性和定量结果来支持其有效性。

Conclusion: 本研究提出的框架能够有效地利用LLM的语义理解能力，提升机器人在复杂环境中进行安全、高效导航的能力，并能根据自然语言提示进行自适应调整。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [412] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: ARCSnake V2是一种两栖、螺旋推进的蛇形机器人，适用于陆地、沙地和水下环境的探索，具有高机动性和地形适应性。


<details>
  <summary>Details</summary>
Motivation: 传统的轮式或腿式机器人难以在洞穴、海洋和行星表面等极端环境的多变地形中进行有效的移动。本研究旨在设计一种能够克服这些挑战的机器人。

Method: 提出ARCSnake V2，一种结合了超冗余蛇形机器人高机动性和阿基米德螺旋推进技术的地形适应性机器人。其设计包括水密机械结构、串联连接的螺旋和关节驱动、集成浮力控制系统，并可通过手持控制器进行遥操作。机器人支持螺旋、轮式和侧滚等多种运动模式，并可在模式间平稳切换。

Result: 实验验证了ARCSnake V2在水下机动性、通信鲁棒性和力反馈控制方面的能力。

Conclusion: ARCSnake V2是一个多功能的机器人平台，适用于多域环境下的探索、搜索救援和环境监测。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [413] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: SBAMP 结合 RRT* 和 SEDS，实现自主机器人实时自适应运动规划，无需预训练数据，并能在动态环境中保持全局最优路径。


<details>
  <summary>Details</summary>
Motivation: 传统基于采样的方法在动态环境中适应性不足，而基于学习的方法泛化能力受限。需要一种能够克服这些限制的运动规划方法。

Method: 提出了一种名为 SBAMP 的新框架，它集成了 RRT* 的全局路径规划能力和 SEDS 的局部控制器，用于连续自适应轨迹调整。该方法不依赖预训练数据集，并通过 Lyaponuv 保证维持稳定性。

Result: 在模拟环境和 RoboRacer 硬件平台上进行了验证，SBAMP 在动态障碍物场景、快速恢复和急转弯处理方面表现出优越性能。

Conclusion: SBAMP 框架能够在动态环境中进行实时自适应运动规划，同时不牺牲全局路径的优化性，为非结构化环境提供了可扩展的解决方案。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [414] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 行为克隆（BC）是一种数据驱动的监督学习方法，在机器人操作领域，扩散策略（DP）及其两种变体DP-CNN（DP-C）和DP-Transformer（DP-T）是最有效和广泛采用的模型。然而，DP和BC方法都受到配对训练数据稀缺的限制，并且DP的内部机制仍未得到充分理解，导致泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决行为克隆（BC）方法在机器人操作领域中，特别是扩散策略（DP）模型，面临的训练数据稀缺、内部机制理解不足、泛化能力有限以及缺乏原则性设计等问题。

Method: 提出了一种解耦的训练方法，利用接近免费的运动学生成轨迹作为无观察数据来预训练一个通用的动作头（动作生成器），然后冻结该预训练的动作头并通过特征调制适应新任务。此外，还提出了DP-MLP，用简单的MLP块替换DP-C的U-Net骨干网络。

Result: 实验证明了该方法在分布内和分布外场景中的可行性。解耦训练提高了训练效率，DP-C的训练速度最多提高了41%。DP-MLP在正常训练下实现了83.9%的训练速度提升，在解耦训练下实现了89.1%的训练速度提升。

Conclusion: 解耦训练方法提高了训练效率，并且动作生成骨干网络在机器人操作中的作用有限。DP-MLP模型通过使用更简单的MLP块，在保持性能的同时显著提高了训练速度。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [415] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: 使用NEAT算法进化动态步态参数，实现平面蛇形机器人在密集障碍环境下的避障跟踪控制，计算效率高，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发一种资源高效的解决方案，用于在密集障碍环境中对平面蛇形机器人进行避障跟踪控制。

Method: 采用Neuro-Evolution of Augmenting Topologies (NEAT)算法生成动态步态参数，并将其应用于蛇形步态函数，通过控制关节角度来控制机器人沿期望的动态路径移动。输入层包括关节角度、连杆位置、头部连杆位置以及附近障碍物位置；输出层包括控制机器人速度和航向的频率和偏移角度。利用LiDAR、机器人传感器数据、目标位置和时间参数化奖励函数，通过选择性传播优越的神经网络进行最大化。

Result: 所提出的方法在计算上是高效的，尤其是在具有许多障碍物的大型环境中。与现有的最先进的方法相比，该方法显示出更优越的结果，并且与最近的CBRL方法相比具有可比性，同时计算开销显著降低。

Conclusion: NEAT算法能够有效地生成平面蛇形机器人的动态步态参数，实现高计算效率的避障跟踪控制，并在模拟研究中取得了优于现有方法的结果。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [416] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: 这是一个关于在动态和不确定的环境中为多智能体系统提供安全、鲁棒和可扩展运动规划的框架，名为RE-DPG。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在动态和不确定的环境中面临安全、鲁棒和可扩展运动规划的挑战，这些挑战源于复杂的交互、随机干扰和模型不确定性。

Method: 提出了一种可达性增强的动态势博弈（RE-DPG）框架，将博弈论协调与可达性分析相结合。通过邻域主导迭代最佳响应（ND-iBR）方案实现可扩展性和去中心化执行，该方案基于保证收敛到ε-NE的迭代ε-BR（iε-BR）过程。通过将多智能体前向可达集（MA-FRS）机制集成到成本函数中来确保安全性，明确模拟不确定性传播并强制执行碰撞避免约束。

Result: 通过在2D和3D环境中进行模拟和真实世界实验，验证了RE-DPG在各种操作场景下的有效性。

Conclusion: RE-DPG框架能够为多智能体系统在动态和不确定的环境中提供安全、鲁棒和可扩展的运动规划。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [417] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 为了解决浮动基底机器人系统中的安全性和干扰问题，研究了具有浮动基底的超额机器人腿（SRL）系统的动力学模型，并设计了一种混合位置/力阻抗控制器。通过动态调整阻抗参数，开发了一种高效的可变阻抗控制（VIC）方法来增强人机交互，特别是在外部力干扰的情况下，以适应不同状态下未知的环境干扰。为SRL设计了一个实时稳定保证的阻抗参数生成网络，以实现减震和高刚度支撑。


<details>
  <summary>Details</summary>
Motivation: 在人机系统中，确保在存在内部和外部干扰的情况下进行力控制的安全性至关重要。作为一种典型的松散耦合浮动基底机器人系统，超额机器人腿（SRL）系统特别容易受到内部干扰的影响。

Method: 研究了松散耦合SRL的动力学模型，并设计了一种混合位置/力阻抗控制器来适应动态扭矩输入。开发了一种高效的可变阻抗控制（VIC）方法，通过动态调整阻抗参数来增强人机交互，以适应不同状态下未知的环境干扰。为SRL设计了一个实时稳定保证的阻抗参数生成网络。

Result: 仿真和实验验证了该系统的有效性，展示了其在柔性状态下保持平稳信号过渡，并在刚性状态下提供强大支撑力的能力。

Conclusion: 该方法为适应交互中的个体步态变化提供了一种实用的解决方案，并显著提高了人机系统的安全性和适应性。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [418] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: 提出一种多目标优化（MOO）设计理论，用于设计通用型超额机器人肢体（SRLs），该理论整合了抓握工作空间相似性、行走工作空间相似性、用于坐到站（STS）运动的支撑力以及整体质量和惯性，并提出了一种基于火萤算法的优化方法，实验结果表明抓握成功率、行走和STS任务中的肌肉活动均得到改善。


<details>
  <summary>Details</summary>
Motivation: 设计一种通用型SRL设备，满足上下肢的多样化功能需求，并寻求一个统一的理论框架。

Method: 提出一种多目标优化（MOO）设计理论，整合抓握工作空间相似性、行走工作空间相似性、坐到站（STS）支撑力、质量和惯性。开发了使用椭球体表示工作空间的几何向量量化方法。采用多亚群修正火萤算法处理MOO任务。

Result: 在六名健康参与者和两名瘫痪患者的实验中，与优化前相比，平均抓握成功率提高了7.2%，行走和STS任务中的肌肉活动分别平均降低了12.7%和25.1%。

Conclusion: 所提出的设计理论为多功能SRL机构的设计提供了一种有效的方法。

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [419] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 提出一种统一的方法来解决机器人路径规划中的约束位移问题，通过位移约束或障碍物来实现可行路径。该方法包括两个阶段：首先计算穿过障碍物的轨迹并最小化目标函数，然后位移障碍物以使轨迹无碰撞。该方法已在两类约束位移问题上成功验证。


<details>
  <summary>Details</summary>
Motivation: 解决机器人路径规划中的约束位移问题，实现可行路径的寻找。

Method: 提出一个两阶段过程：1. 计算穿过障碍物的轨迹并最小化目标函数。2. 位移障碍物，使轨迹无碰撞。

Result: 在两类约束位移问题上成功演示了所提出的方法。

Conclusion: 该方法为约束位移问题提供了一个统一且有效的解决方案。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [420] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: SocialNav-Map是一个零样本的社会导航框架，结合了动态人类轨迹预测和占用映射，无需针对特定环境的训练即可实现安全高效的导航，并在实验中显著优于最先进的强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于强化学习的社交导航方法需要长时间的训练（2000+小时），并且在不熟悉的环境中泛化能力差，限制了其实际应用。需要一种无需环境特定训练即可实现安全高效导航的新方法。

Method: SocialNav-Map框架首先将任务目标位置转换为构建的地图坐标系。然后，它创建一个动态占用地图，将预测的动态人类运动纳入其中作为动态障碍物。该框架采用两种互补的人类轨迹预测方法：历史预测和方向预测。通过将这些预测的轨迹整合到占用地图中，机器人可以主动避免与人类潜在的碰撞，同时高效地导航到目的地。

Result: 在Social-HM3D和Social-MP3D数据集上进行的广泛实验表明，SocialNav-Map在避免碰撞方面比需要2396小时GPU训练的最先进的强化学习方法提高了10%以上，并且在新的环境中无需任何训练。

Conclusion: SocialNav-Map通过消除对特定环境训练的需求，实现了卓越的导航性能，能够安全高效地在具有多样化人类行为的真实环境中进行导航。

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [421] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: SAC-MoE是一种结合了Soft Actor-Critic（SAC）和混合专家（MoE）的模型，用于处理具有潜在和不可观察事件的混合动力系统。通过学习路由器自适应地选择专家，并结合基于课程的训练算法，该模型在处理未见过的模式和切换位置方面表现出更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的模型控制方法和无模型强化学习方法在处理具有潜在参数和不可观察事件的混合动力系统时存在不足，导致泛化能力差。特别是在 legged robots, vehicles and aircrafts 等系统中。SAC-MoE旨在克服这些挑战。

Method: 提出了一种名为SAC-MoE的框架，该框架将SAC的Actor建模为混合专家（MoE）模型，并包含一个学习到的路由器，该路由器能够自适应地选择不同的专家。此外，还开发了一种基于课程的学习算法，用于在具有挑战性的环境中优先收集数据，以提高泛化能力。

Result: 在混合动力自动赛车和自主运动任务的模拟研究中，SAC-MoE在零样本泛化到未见过的环境方面，相比基线方法表现出高达6倍的性能提升。所提出的课程策略在所有评估的策略中一致地提高了性能。模型的可解释性体现在路由器能够为不同的潜在模式激活不同的专家。

Conclusion: SAC-MoE在处理具有潜在参数和不可观察事件的混合动力系统方面，通过MoE架构和课程学习策略，显著提高了泛化能力和鲁棒性。该方法在模拟环境中取得了优异的性能，并展现出良好的可解释性。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [422] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 利用压电聚偏二氟乙烯（PVDF）的多层驱动器有望提高软微型机器人系统的性能。本研究开发并表征了具有平行电压分布的多层PVDF驱动器，填补了脆性高力PZT堆叠和柔性但低带宽的软聚合物驱动器之间的设计空间。


<details>
  <summary>Details</summary>
Motivation: 开发和表征具有平行电压分布的多层PVDF驱动器，以填补现有驱动器技术的空白。

Method: 通过改变层厚和层数来研究驱动器性能，并与第一性原理模型进行比较。

Result: 实现了>3毫米的自由偏转、>20毫牛的阻力力和>=500赫兹的频率响应，同时工作电压低至150伏。

Conclusion: 多层PVDF驱动器在性能（偏转、力和频率）和工作电压方面表现出色，并已成功集成到共振驱动的微型机器人中，证明了其在机器人集成方面的潜力。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [423] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: MAML-TRPO在Meta-World ML10机器人操作基准上进行了评估，证明了其在少样本适应方面的潜力，但也揭示了泛化差距和任务适应性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人系统能够快速适应新任务并最少化数据需求，本文评估了模型无关元学习（MAML）与信任域策略优化（TRPO）的结合。

Method: 在Meta-World ML10基准上，包含推、抓取和抽屉操作等十种不同的机器人操作任务，实现并分析了MAML-TRPO学习通用初始化的能力，以促进跨语义操作行为的少样本适应。

Result: MAML在一次梯度更新后能实现有效的一次性适应，训练任务成功率为21.0%，测试任务成功率为13.2%。然而，在元训练过程中出现了泛化差距，测试任务性能趋于平稳，而训练任务性能仍在提高。不同操作任务的适应性效果差异很大，成功率在0%到80%之间。

Conclusion: 基于梯度的元学习在多样的机器人操作任务中展现出巨大潜力，但也存在泛化差距和任务适应性方差大的局限性。未来的工作应专注于任务感知适应和结构化策略架构。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [424] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 该研究提出了一种基于学习的神经遥操作框架，用于控制人形机器人进行复杂操作。


<details>
  <summary>Details</summary>
Motivation: 传统的遥操作系统依赖逆运动学（IK）求解器和手动调整的PD控制器，难以处理外部力、适应不同用户以及在动态条件下产生自然的运动。

Method: 该框架使用强化学习训练的策略来直接映射VR控制器输入到机器人关节指令，从而取代了传统的IK+PD流程。策略在模拟环境中进行训练，并结合了力随机化和轨迹平滑度奖励进行微调。

Result: 与IK基线相比，所提出的学习策略在Unitree G1人形机器人上的实验中，实现了34%的更低跟踪误差、45%的更平滑运动以及更优越的力适应性，同时保持了实时性能（50Hz控制频率）。

Conclusion: 基于学习的方法可以显著提高人形遥操作系统的自然度和鲁棒性，并已在物体抓取、开门和双臂协调等操作任务中得到验证。

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [425] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: RoboAfford++是一个包含86.9万张图像和200万个问答注释的多模态数据集，用于机器人操作和导航的通用学习。RoboAfford-Eval是一个包含338个注释样本的基准，用于评估真实世界场景中的通用预测。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在推断物理交互的可行位置（如抓握点和放置区域）方面存在不足，因为它们的训练数据缺乏细粒度的物体和空间通用性注释。

Method: 提出RoboAfford++数据集（包含869,987张图像和200万个问答注释）和RoboAfford-Eval基准（包含338个注释样本），以解决多模态通用性学习的挑战。

Result: 实验证明，现有的VLMs在通用性学习方面存在不足，但使用RoboAfford++数据集进行微调可以显著提高它们对物体和空间通用性的推理能力，验证了该数据集的有效性。

Conclusion: RoboAfford++数据集和RoboAfford-Eval基准能够有效提升机器人完成操作和导航任务的能力。

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [426] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [427] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 使用机器人辅助收集数据以监测受气候变化威胁的欧洲山地生境


<details>
  <summary>Details</summary>
Motivation: 欧洲山地生境的生物多样性丧失和环境退化问题日益严重，但传统的监测方法依赖于需要大量资源和时间的、由高技能科学家进行的野外考察。

Method: 部署ANYmal C机器人，并利用深度学习技术来检测和分类关键的植物物种，以协助植物学家收集数据和识别物种。

Result: 敏捷的机器人可以在复杂的地形中导航，并提高山地生境监测的频率和效率。将机器人与传统的植物群落调查相结合，可以简化野外作业，并改进数据的获取、存储和使用。

Conclusion: 机器人辅助协议为环境科学中的机器人技术提供了一种更全面、可持续的山地生境监测和保护方法。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [428] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: EcoFlight是一种新的无人机避障路径规划算法，它通过考虑无人机推进系统和飞行动力学来优化能耗，并在各种障碍物密度下优于现有算法，尤其是在高密度环境中。


<details>
  <summary>Details</summary>
Motivation: 大多数飞行路径规划方案很少考虑无人机（UAV）的避障问题，尽管障碍物是现实存在的。避障会消耗大量能量，因此成为无人机高效点对点飞行的关键因素。

Method: EcoFlight算法模拟了无人机的能量消耗，包括推进系统和飞行动力学，以在存在障碍物的3D空间中确定最低能耗的路线。

Result: 在各种障碍物密度下进行的大量评估和仿真结果表明，EcoFlight 能够持续找到比现有算法（如直接飞行和最短距离方案）能耗更低的路径，尤其是在高密度环境中。此外，研究还表明，合适的飞行速度可以进一步节省能量。

Conclusion: EcoFlight 成功地解决了无人机避障路径规划中的能耗问题，为无人机在高密度障碍环境中实现高效飞行提供了有效的解决方案。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [429] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: 强化学习（RL）被用于优化平面机器人操作器的形态。在2R操作器跟踪圆形路径的案例中，RL成功地重新发现了已知的最佳解（连杆长度相等且第二关节与第一关节正交），验证了RL在仅使用奖励反馈的情况下寻找最优解的能力。


<details>
  <summary>Details</summary>
Motivation: 大多数形态设计任务缺乏封闭解，并且随着维度的增加，网格搜索或启发式搜索的成本会急剧升高。因此，本文探索了使用强化学习（RL）作为一种可扩展的替代方案来解决这些问题。

Method: 本文使用了 Yoshikawa 的可操作性指标，并将强化学习（RL）作为一种框架来优化平面机器人操作器的形态。首先，研究了一个 2R 操作器跟踪圆形末端执行器路径的案例，因为该案例存在已知的解析最优解。然后，将此方法扩展到椭圆形和矩形路径，并扩展了动作空间以包含完整的形态向量（L1、L2、theta2）。

Result: 在圆形路径案例中，所有三种 RL 算法（SAC、DDPG 和 PPO）与网格搜索和黑盒优化器一起，都成功收敛到了解析最优解。在非解析设置（椭圆形和矩形路径）中，RL 也能可靠收敛，而网格搜索和黑盒方法需要更大的评估预算。

Conclusion: 强化学习（RL）可以有效地用于重新发现已知的最优解，并解决没有解析解的形态优化问题，为形态设计提供了一种可扩展的解决方案。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [430] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR: 本研究提出了一种名为ICRL的新方法，用于在推理时进行少样本、提示驱动的领域自适应（DA），以解决自动驾驶中的闭环问题，特别是在恶劣天气条件下。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶端到端系统在领域自适应方面存在挑战，尤其是在不同天气条件下。传统的解决方案（如收集更多数据或重新训练模型）在大规模和复杂性增加时变得不切实际。基于LLM和VLM的少样本/零样本提示驱动DA方法虽然有前景，但仅限于感知任务且需要专家数据，限制了其在闭环驾驶中的应用。

Method: 提出了一种名为ICRL（in-context reinforcement learning）的新方法，该方法在推理时进行少样本、提示驱动的领域自适应。与现有方法不同，ICRL不需要更新模型参数或收集目标域的额外数据。它通过在提示中加入上下文中的强化学习来实现，并将通用轨迹作为上下文信息，从而扩展到闭环驾驶。

Result: 在CARLA模拟器上的实验表明，与最先进的提示驱动DA基线相比，ICRL在目标域中实现了更安全、更高效、更舒适的驾驶策略。

Conclusion: ICRL成功地将少样本、提示驱动的领域自适应扩展到了闭环自动驾驶，并在恶劣天气条件下取得了优于现有方法的性能，为自动驾驶的鲁棒性和适应性提供了新的解决方案。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [431] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR. Nav 是一种创新的自主导航方法，能在存在死胡同且需要恢复的非结构化环境中运行，通过融合RGB-LiDAR数据和注意力机制来预测死胡同并规划更安全的路径，显著提高了导航的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中，机器人自主导航面临死胡同检测和恢复的挑战，尤其是在有角落、植被遮挡和阻塞路口的场景下。现有的方法通常只考虑可通行性，未能充分处理死胡同的风险。

Method: DR. Nav 提出了一种主动的导航策略，通过生成单一的、实时的语义成本地图来统一死胡同预测和恢复。该方法利用跨模态RGB-LiDAR融合和基于注意力机制的滤波来估计每个单元的死胡同可能性以及恢复点，并通过贝叶斯推理进行连续更新以增强鲁棒性。与仅编码可通行性的方法不同，DR. Nav 将恢复感知风险显式地纳入导航成本地图。

Result: 在密集的室内和室外场景评估中，DR. Nav 的死胡同检测准确率提高了 83.33%，达到目标时间（路径效率）的效率提高了 52.4%，优于 DWA、MPPI 和 Nav2 DWB 等现有规划器。此外，死胡同分类器功能。

Conclusion: DR. Nav 通过整合死胡同预测和恢复，并生成包含恢复感知风险的成本地图，显著提高了机器人在复杂非结构化环境中的导航性能，在准确性和效率方面均优于现有方法。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [432] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 为了解决机器人抓取密集杂乱环境中的物体这一难题，提出了一种基于能量的模型用于抓取姿态生成，并结合一种主动视角选择方法来估计抓取分布的信息增益。该方法考虑了SE(3)流形上抓取分布的多模态性质，并通过将能量水平与抓取成功率校准，使得预测分布与真实分布对齐。通过对校准后的分布进行信息增益估计，从而选择下一个最佳视角，有效引导机器人探索目标物体的可及部分。实验结果表明，该模型在杂乱环境中，以有限的视角预算，相比现有最先进的模型，能够成功抓取物体。


<details>
  <summary>Details</summary>
Motivation: 之前的机器人抓取方法在面对密集杂乱环境时，要么忽视了抓取分布对信息增益估计的重要性，要么依赖于抓取分布的投影，忽略了SE(3)流形上抓取姿态的结构。本研究旨在解决这些挑战。

Method: 提出了一种校准的基于能量的模型用于抓取姿态生成，并提出了一种主动视角选择方法，该方法从抓取分布中估计信息增益。所提出的能量模型能够捕捉SE(3)流形上抓取分布的多模态性质，并将能量水平校准至抓取成功率，以使预测分布与真实分布对齐。通过估计校准后的分布中抓取的信息增益来选择下一个最佳视角，从而能够有效地引导机器人探索目标物体可及的部分。

Result: 在模拟环境和真实机器人设置中的实验表明，与之前最先进的模型相比，我们的模型能够在杂乱环境中，以有限的视角预算成功抓取物体。我们的模拟环境可以为未来主动抓取的研究提供一个可复现的平台。

Conclusion: 该方法能够成功抓取密集杂乱环境中的物体，并且所提出的模拟环境可为未来研究提供支持。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [433] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 本研究提出了一种结构化模仿学习框架，用于学习需要与人类在共享空间进行交互且无明确通信的策略，解决了现有方法在处理高复杂度多智能体交互时的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型方法在模仿学习方面取得了显著成果，但模仿学习交互式策略（尤其是在无明确通信的多智能体交互场景下）仍然面临挑战，因为其行为复杂度远高于非交互式任务。

Method: 该方法将学习过程分为两步：首先，利用标准的模仿学习方法从多智能体演示中学习个体行为模式；然后，通过求解逆博弈问题来结构化地学习智能体间的依赖关系。

Result: 在合成的 5 个智能体社会导航任务的初步结果表明，该方法显著优于非交互式策略，并且在仅使用 50 个演示的情况下，其性能与真实交互式策略相当。

Conclusion: 该研究结果凸显了结构化模仿学习在交互式场景中的潜力。

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [434] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: MTV-World通过引入多视角轨迹视频控制，解决了现有具身世界模型在低级动作到精确机器人运动的翻译问题，提高了视觉运动预测的准确性，并在复杂双臂场景中实现了精确控制和物理交互建模。


<details>
  <summary>Details</summary>
Motivation: 现有具身世界模型在将低级动作（如关节位置）转换为预测帧中的精确机器人运动方面存在困难，导致与现实物理交互不一致。

Method: 提出MTV-World，一种引入多视角轨迹视频控制（Multi-view Trajectory-Video control）的具身世界模型。该模型使用通过相机内外参数和笛卡尔空间变换获得的轨迹视频作为控制信号，并通过多视角框架来补偿3D到2D投影造成的空间信息损失。

Result: MTV-World在复杂的双臂场景中实现了精确的控制执行和准确的物理交互建模。其评估管线利用多模态大型模型和参考视频对象分割模型来衡量运动精确性和对象交互准确性，并使用 Jaccard 指数来衡量空间一致性。

Conclusion: MTV-World通过多视角轨迹视频控制，有效解决了现有模型的局限性，实现了更精确的机器人运动和物理交互预测。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [435] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 本文提出了一种基于气室的软体六轴力/力矩传感器，并结合分层结构实现了解耦，能够满足软体交互的需求。


<details>
  <summary>Details</summary>
Motivation: 为了实现安全精确的力交互，需要能够捕获六轴力的传感器，但现有技术存在标定难、精度低等问题。

Method: 提出了一种包含16通道气压计的软体气室式六轴力/力矩传感器。并提出一种基于刚软分层结构的有效解耦方法，将六轴解耦问题简化为两个三轴解耦问题。

Result: 仿真和实验结果表明该方法可行。原型机在50N力和1Nm力矩范围内，平均偏差、重复性、非线性、迟滞性分别为4.9%、2.7%、5.8%和6.7%，满足软体传感器性能要求。

Conclusion: 该软体六轴力/力矩传感器具有良好的传感性能，同时保持了软体气室的柔软性。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [436] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 该研究提出了一个名为TOPP-DWR的算法，用于解决差速驱动轮式机器人（DWR）的时间最优轨迹参数化（TOPP）问题。该算法考虑了角速度和关节速度等实际约束，并将其统一表示为线速度约束，通过引入松弛变量将其转化为二阶锥规划（SOCP）问题，以提高计算效率。实验结果表明，TOPP-DWR在满足所有约束条件下实现了时间最优，并在实际自主导航实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有移动机器人控制方法通常忽略了角速度和关节速度约束，导致在实际应用中控制性能下降。本研究旨在提出一种能够考虑这些约束的TOPP算法，以提高DWR的控制性能。

Method: 1. 采用非均匀B样条表示初始轨迹。 2. 考虑角速度、关节速度、线速度和线加速度约束。 3. 将所有约束统一表示为线速度约束。 4. 引入松弛变量将问题转化为二阶锥规划（SOCP）问题。 5. 进行对比实验和实地自主导航实验验证算法性能。

Result: TOPP-DWR算法在满足所有约束条件下实现了时间最优，并在实际自主导航实验中表现出良好的实用性。

Conclusion: 所提出的TOPP-DWR算法系统且实用，能够有效地处理差速驱动轮式机器人的时间最优路径参数化问题，并考虑了实际的约束条件，提高了控制性能和导航的实用性。

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [437] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: DiffuDepGrasp是一个创新的sim2real框架，通过在模拟环境中训练策略，并利用扩散模型生成逼真的模拟深度图，实现了高效的零样本迁移，解决了数据效率和部署复杂性的挑战，在机器人抓取任务中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 真实深度图中的传感器伪影（如空洞和噪声）在将模拟训练的策略迁移到物理机器人时，会产生显著的sim2real差距，严重阻碍抓取策略的迁移。现有方法在数据效率和部署复杂性方面存在不足。

Method: 提出DiffuDepGrasp框架，其核心是扩散深度生成器，包含两个模块：1. 扩散深度模块：利用时间几何先验，高效训练条件扩散模型，捕捉复杂的传感器噪声分布。2. 噪声嫁接模块：在注入感知伪影时保持度量精度。该框架仅在部署时使用原始深度输入，无需额外的计算开销。

Result: DiffuDepGrasp在12个物体的抓取任务中实现了95.7%的平均成功率，实现了零样本迁移，并对未见过的物体表现出强大的泛化能力，同时消除了部署时的计算开销。

Conclusion: DiffuDepGrasp通过其创新的扩散深度生成器，能够高效地生成逼真的传感器噪声，从而实现模拟到真实世界的零样本迁移，解决了机器人抓取领域中sim2real差距带来的挑战，并在实际应用中取得了显著的成功。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [438] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: GUIDE使用3D高斯进行实例检测和占用预测，并在nuScenes数据集上实现了50%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用3D边界框表示障碍物，无法捕捉现实世界中不规则形状的复杂性。

Method: 提出GUIDE框架，使用3D高斯进行实例检测和占用预测，并具有跟踪能力。采用稀疏表示策略，通过高斯到体素的渲染（Gaussian-to-Voxel Splatting）提供细粒度的实例级别占用数据，避免了密集体素网格的计算成本。

Result: 在nuScenes数据集上，实例占用mAP达到21.61，比现有方法提高了50%，并具有具有竞争力的跟踪能力。

Conclusion: GUIDE在精度和计算效率方面取得了良好平衡，为自动驾驶感知系统设定了新的基准。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [439] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: SplatSearch 是一种利用稀疏视图 3D 高斯泼溅重建来解决实例图像导航问题的新架构，通过渲染多视角图像并利用多视角扩散模型来补全缺失区域，实现鲁棒的特征匹配，并引入新的前沿探索策略，提高了导航成功率和路径长度。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，机器人需要仅凭单张目标图像在稀疏视图场景重建中搜索特定目标，这是一个具有挑战性的问题。

Method: SplatSearch 架构利用稀疏视图 3D 高斯泼溅重建，渲染候选物体周围的多个视角，并使用多视角扩散模型补全图像缺失区域以进行特征匹配。引入了新的前沿探索策略，结合合成视角和目标图像的语义信息来评估前沿位置。

Result: 在模拟和真实环境中进行的大量实验表明，SplatSearch 在成功率和成功路径长度方面优于现有最先进的方法。

Conclusion: SplatSearch 的设计选择得到了验证，证明了其在实例图像导航方面的有效性。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [440] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 提出一个结合安全路径生成、自适应置信度更新和置信度感知探索策略的框架，以解决行星探索机器人导航中的高程不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂地形（如陨石坑附近）的高程估计不确定性、减少不确定性的探索策略以及高程不确定性对导航安全和地图质量的影响方面存在不足。

Method: 使用基于卡尔曼滤波的高程估计，生成地形可通行性和置信度得分，并将其整合到基于图的探索规划器（GBP）中，优先探索可通行的低置信度区域。

Result: 通过模拟月球实验，使用新颖的低置信度区域比率指标，与基线GBP相比，不确定性降低了69%；在任务成功率方面，我们的方法达到了100%，而基线GBP为0%。

Conclusion: 该框架提高了探索安全性，增强了地图的可靠性，特别是在处理高程不确定性方面。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [441] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 该论文提出了一种名为APP的A*后处理算法，用于优化机器人路径规划，减少路径长度和转向次数，提高路径平滑度。


<details>
  <summary>Details</summary>
Motivation: A*等图搜索规划器生成的路径通常不是最短的，并且存在不必要的转向（锯齿形），不符合人类直觉，因此需要一种后处理算法来优化这些路径。

Method: APP算法包括两个主要部分：1. 双向顶点约简算法，采用前向和后向约简以及全面的捷径策略来缩短路径并避免不必要的转向。2. 迭代路径扰动算法，用于局部减少转向次数并提高路径平滑度。该算法基于成本地图。

Result: APP算法在规划时间、路径长度和不必要转向次数方面优于现有方法。实地导航实验也验证了其可行性。

Conclusion: APP是一种系统性的后处理算法，能够有效优化A*等图搜索算法生成的路径，提高路径质量和机器人导航的效率与平稳性。

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [442] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 提出一种用于半结构化环境的全局路径规划方法，该方法考虑交通规则以平衡路径长度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有全局路径规划方法在自由空间和结构化环境中存在不足，例如忽略交通规则导致频繁重规划和碰撞风险，或过于严格遵守规则导致路径过长影响效率。本文旨在解决这些问题，提出一种通用的、系统的改进全局路径规划性能的方法。

Method: 构建单向道路网络表示交通约束，并采用混合策略实现规划。允许在起点和终点进行道路跨越以缩短路径。提出两层势场图以处理起点和终点位于复杂交叉口的情况。

Result: 与现有技术相比，所提出的方法在路径长度和道路网络一致性之间取得了更好的平衡。

Conclusion: 所提出的方法在半结构化环境中提供了改进的全局路径规划性能，能够有效平衡路径长度和交通规则遵从性。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [443] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 本文提出一种无需预先了解传感器方向即可在静态条件下估计加速度计偏差的无模型学习方法，以克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有低成本微机电加速度计的性能常因偏差误差而受损。为了消除确定性偏差项，需要进行静态条件下的校准，但这需要加速度计调平或复杂的依赖于方向的校准程序。本文旨在克服这些要求。

Method: 提出一种无模型、基于学习的校准方法，在静态条件下估计加速度计偏差，无需了解传感器方向，也无需旋转传感器。

Result: 实验结果表明，与传统技术相比，该方法在13.39小时的数据集上，误差水平持续降低了52%以上。

Conclusion: 该方法为在无方向要求的场景下实现精确校准提供了一种快速、实用且可扩展的解决方案，提高了低成本惯性传感器在各种科学和工业应用中的可靠性，并消除了对调平校准的需要。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [444] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: ResAlignNet是一种基于数据驱动的1D ResNet-18架构，能够快速（秒级）且无需外部传感器或复杂机动即可实现AUV的INS和DVL传感器框架的精确对齐，实现了Sim2Real迁移，并将对齐时间缩短了65%。


<details>
  <summary>Details</summary>
Motivation: 传统的基于模型的对齐方法收敛时间长，依赖于特定的运动模式和外部辅助传感器，限制了AUV在水下导航中的操作灵活性。

Method: 提出了一种名为ResAlignNet的数据驱动方法，该方法利用1D ResNet-18架构将对齐问题转化为深度神经网络优化问题，仅使用AUV上安装的传感器进行原地对齐。

Result: ResAlignNet能够在大约25秒内实现0.8°的对齐精度，比传统的基于速度的方法快65%。该方法不依赖于特定的运动模式，并且能够实现Sim2Real迁移。

Conclusion: ResAlignNet通过一种无需外部传感器或复杂运动的传感器无关的对齐方法，显著提高了AUV导航的效率和灵活性，并且具有良好的可扩展性，能够适应不同的操作场景和传感器规格。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [445] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 该研究提出了一种名为“sysname”的基于事件相机的无人机传感方法，通过精确测量螺旋桨转速来提高无人机传感性能。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用的普及，从地面进行非接触式无人机传感变得至关重要。

Method: 该方法名为“sysname”，包含两个部分：‘Count Every Rotation’用于精确估算转速，‘Every Rotation Counts’利用转速推断无人机动力学。

Result: 在实际的无人机配送场景中，‘sysname’实现了3毫秒的传感延迟和0.23%的转速估算误差，同时能以96.5%的精度推断飞行指令，并将无人机跟踪精度提高了22%。

Conclusion: 基于事件相机的‘sysname’通过精确的螺旋桨转速测量，显著提高了无人机的传感性能，并在无人机配送等实际应用中展现了优越的效果。

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [446] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 提出了集成驱动、传感的软体机器人积木单元（MU），并建立了参数化设计框架，实现了可重复、可扩展的设计。


<details>
  <summary>Details</summary>
Motivation: 为软体机器人开发一种集成驱动、传感的积木单元，并研究其可重复性和可扩展性。

Method: 1. 提出MU单元，集成气动驱动、柔性晶格和光学波导传感位点。2. 建立参数化设计框架，连接驱动腔尺寸和晶格单元尺寸。3. 通过实验均化获取晶格材料的有效属性，用于有限元模拟。4. 在模拟环境中，将传感器布局视为离散优化问题，评估候选波导路径，选择能将基线力学性能偏差最小化的布局。5. 制造优化后的模型并进行实验表征。6. 将工作流程扩展到更大尺寸单元和双指夹爪，验证MU概念的通用性。

Result: 优化后的MU单元在嵌入传感的同时，力学性能保持不变。该方法适用于不同尺寸的单元和多单元集成（如双指夹爪）。

Conclusion: MU单元通过可重复的协同设计规则和仿真驱动的传感器集成，推动了软体机器人的整体设计，实现了集成驱动和传感的设计。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [447] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 该论文提出了一种用于自主移动机器人（AMR）的集成导航框架，统一了环境表示、轨迹生成和模型预测控制（MPC）。


<details>
  <summary>Details</summary>
Motivation: 该方法旨在通过结合安全区域提取、连通性图构建、轨迹生成和B样条平滑，实现高效可靠的导航，而无需直接对障碍物进行编码。

Method: 该框架使用基于四叉树的方法从占用图中生成结构化的、轴对齐的无碰撞区域，并将其作为安全走廊的基础和MPC公式中的线性约束。

Result: 实验结果表明，与基线方法相比，该方法在复杂环境中具有持续的成功和优越的性能。

Conclusion: 该集成导航框架能够有效地在复杂环境中实现自主移动机器人的导航。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [448] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: PIGEON是一种利用视觉语言模型（VLM）进行物体导航的方法，通过识别和利用兴趣点（PoI）来提高决策频率和导航效率，并生成适合模拟器的RLVR数据，在经典物体导航基准测试中取得了最先进的零样本迁移性能。


<details>
  <summary>Details</summary>
Motivation: 现有的导航方法在决策频率和智能性之间难以平衡，导致决策缺乏远见或动作不连续。

Method: 提出PIGEON方法，在探索过程中维护一个轻量级且语义对齐的快照记忆，作为探索策略的语义输入。利用视觉语言模型（VLM）PIGEON-VL选择探索过程中形成的兴趣点（PoI），并采用低级规划器输出动作，从而提高决策频率。该方法还能够生成适用于模拟器的可验证奖励强化学习（RLVR）数据。

Result: 在经典的物体导航基准测试中，PIGEON的零样本迁移方法取得了最先进的性能。RLVR进一步增强了模型在实时导航过程中的语义引导能力和深度推理能力。

Conclusion: PIGEON通过利用VLM选择和利用兴趣点，有效解决了现有物体导航方法的局限性，提高了导航效率和智能性，并通过RLVR进一步提升了模型的性能。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [449] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: GaRLILEO是一个新颖的雷达-腿部-惯性里程计框架，通过解耦IMU速度并利用激光雷达和相机之外的重力向量估计来提高垂直姿态估计的准确性，尤其是在楼梯和斜坡等具有挑战性的地形上。


<details>
  <summary>Details</summary>
Motivation: 在具有挑战性的地形（例如楼梯、斜坡和非结构化环境）中，基于腿部的机器人比基于轮式的机器人更受欢迎。在这些场景中，准确的里程计估计是稳定运动、定位和映射的初步要求。传统的本体感觉方法（依赖于腿部运动学和惯性传感）会受到垂直漂移的影响，而现有的方法（结合了激光雷达或摄像头）在特征稀疏或重复的场景中会受到限制。

Method: GaRLILEO框架通过从雷达多普勒和腿部运动学信息中构建连续时间的自身速度样条来解耦IMU速度，从而实现传感器融合，减轻了里程计失真。此外，GaRLILEO利用新颖的软S2约束重力因子来捕捉准确的重力向量，从而提高了垂直姿态估计的准确性，而无需依赖激光雷达或摄像头。

Result: 在收集的真实世界数据集上进行评估，GaRLILEO在垂直姿态估计方面展示了最先进的准确性，尤其是在楼梯和斜坡上。

Conclusion: GaRLILEO是一个新颖的、重力对齐的、连续时间的雷达-腿部-惯性里程计框架，它通过解耦IMU速度并利用重力向量估计来提高垂直姿态估计的准确性，即使在具有挑战性的地形上也能表现出色。所收集的数据集和算法已开源，以促进腿部机器人里程计和SLAM的进一步研究。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [450] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 本论文提出将扩散模型应用于机器人操作策略，结合视觉和文本信息生成机器人轨迹，以实现更通用的多任务操作。


<details>
  <summary>Details</summary>
Motivation: 为了让机器人能够理解自然语言并执行物理任务，需要将其视觉和文本理解能力结合起来，用于生成精确的机器人轨迹。

Method: 利用参考演示进行训练，通过结合改进的嵌入和借鉴图像生成的扩散模型技术，使模型能够执行文本指令所指定的操纵任务。

Result: 在CALVIN数据集上进行了评估，在多项操纵任务和长序列任务的成功率方面均有提升。

Conclusion: 所提出的方法证明了扩散模型的有效性，并为实现通用的多任务操作做出了贡献。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [451] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: ZeroDexGrasp是一个零样本任务导向的灵巧抓取框架，通过结合多模态大语言模型和抓取优化，实现了对不同物体和任务指令的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在泛化到不同物体和任务指令方面存在挑战，因为它们依赖昂贵的标记数据进行特定任务的语义对齐。

Method: ZeroDexGrasp采用基于提示的多阶段语义推理来推断初始抓取配置和物体接触信息，然后利用接触引导的抓取优化来完善抓取姿态，以实现物理可行性和任务对齐。

Result: 实验结果表明，ZeroDexGrasp能够在多样化的未见物体类别和复杂任务需求上实现高质量的零样本灵巧抓取。

Conclusion: ZeroDexGrasp在实现更具泛化性和智能性的机器人抓取方面取得了进展。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [452] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 本研究提出了一种结合了近端策略优化（PPO）和运动原语的机器人任务空间能量安全框架，用于解决接触丰富的操作任务，并在实验中证明了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 机器人强化学习（RL）方法通常在关节空间中应用，并且依赖有限的任务信息和对3D环境的部分感知。现有的方法忽视了任务空间操作中的接触丰富信息，特别是在考虑接触安全性和鲁棒性方面。因此，需要一种能够处理接触丰富操作任务，并在任务空间中生成可靠且安全轨迹的方法。

Method: 该研究提出了一种任务空间、能量安全框架，结合了近端策略优化（PPO）和运动原语来生成可靠且安全的任务空间轨迹。此外，还引入了一个能量感知的笛卡尔阻抗控制目标，以确保机器人与环境之间的安全交互。

Result: 实验结果表明，所提出的框架在处理3D环境中各种表面上的任务时，性能优于现有方法，实现了高成功率、平滑的轨迹和能量安全交互。

Conclusion: 本研究提出的结合了PPO和运动原语的任务空间能量安全框架，能够有效地处理接触丰富的机器人操作任务，并在安全性、平滑性和成功率方面取得了显著的改进。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [453] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 该论文提出了一个用于收集多模态数据的协议，旨在模拟社交焦虑在人机交互中的表现，以克服现有数据集的不足。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种普遍存在的状况，会影响人际交往和社交功能。然而，目前缺乏包含音频、视频和生理信号的多模态数据集来准确检测与社交焦虑相关的状态和行为，这阻碍了该领域的研究和应用。

Method: 本研究提出的协议将收集至少70名参与者的同步音频、视频和生理记录。参与者将被分为不同的社交焦虑水平组，并在受控的实验条件下，与Furhat社交机器人进行大约10分钟的交互式“绿野仙踪”角色扮演。此外，还将收集上下文数据以深入了解个体社交焦虑反应的差异。

Result: 该协议旨在创建一个多模态数据集，其中包含音频、视频和生理信号，以及上下文数据，用于分析社交焦虑在人机交互中的表现。

Conclusion: 这项工作通过提供支持社交焦虑稳健多模态检测的数据集，有助于开发能够适应情感的人机交互研究。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [454] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个包含专家职能治疗师示范日常生活活动（ADLs）的多模态数据集，旨在推动机器人护理领域的发展。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习领域缺乏大规模、多样化且由专家驱动的数据集来应对现实世界中的护理任务，这些任务涉及复杂的人机物理交互、遮挡下的精确感知、安全接触和长期规划。

Method: 收集了21名职能治疗师在两个假人上执行15项ADL任务的数据。数据集包含RGB-D视频、姿态追踪、眼动追踪、任务和动作注解以及触觉传感五种模态。

Result: OpenRoboCare包含五种模态的数据，提供了关于护理者运动、注意力、力应用和任务执行策略的丰富见解。同时，分析了专家护理原则和策略，并评估了该数据集对现有机器人感知和人类活动识别方法的挑战性。

Conclusion: OpenRoboCare数据集为机器人护理研究提供了宝贵的资源，其多样化的数据和对现有方法的挑战性，有助于推动安全、自适应的辅助机器人的发展。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [455] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 通过改进灵巧手尖部几何形状并优化控制策略，实现了灵巧手同时进行力量抓握和精确抓握的能力。


<details>
  <summary>Details</summary>
Motivation: 当前多指灵巧手机器人擅长力量抓握，但在需要精确操控的任务中，平行夹爪仍更常用，这凸显了现有机器人设计在单一系统中难以兼顾稳定力量抓握和精细操作的局限性。

Method: 提出一种轻量级的指尖几何形状修改方案，将其表示为接触平面，并与相应的控制策略进行联合优化。控制策略能在力量抓握和精确抓握之间动态切换，并将精确控制简化为拇指和食指的平行运动，以实现良好的仿真到现实迁移。利用可微分神经物理代理模型，通过大规模仿真优化指尖几何形状。

Result: 在仿真到现实的精确抓握任务中，对未见过的物体实现了82.5%的零样本成功率；在现实世界的面包捏取等挑战性任务中，成功率达到93.3%。

Conclusion: 提出的联合设计框架能够显著提升多指灵巧手的精细操作能力，同时不影响其进行力量抓握的能力。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [456] [Transition from MOS to Ideal Capacitor Behavior Triggered by Tunneling in the Inversion Population Regime](https://arxiv.org/abs/2511.11637)
*Pedro Pereyra*

Main category: cond-mat.mtrl-sci

TL;DR: 文章导出了非线性泊松方程的解析解，用于描述金属-氧化物-半导体（MOS）结构中的反型层，解决了1955年提出的一个基本挑战。该解能够得到反型层宽度、电势和电荷分布等物理量随栅极电压、距离和掺杂浓度变化的显式表达式。在反型早期，这些量变化迅速，但在栅极电压超过阈值电压后会饱和。当隧穿发生时，界面附近的电荷累积增加，电荷分布变为二维，电势降从半导体转移到氧化层，类似平行板电容器的特性。研究详细分析了该机制，并通过计算证明，隧穿电流变得主导，取代了经典反型行为。这些结果为器件建模提供了新的解析基础，并为下一代MOSFET和隧穿FET的设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 解决1955年提出的关于金属-氧化物-半导体（MOS）结构中反型层行为的非线性泊松方程的基本挑战。

Method: 推导了非线性泊松方程的解析解，并得到了反型层宽度、电势和电荷分布等物理量关于栅极电压、距离和掺杂浓度的显式表达式。分析了隧穿机制对反型层行为的影响，并通过计算证明了隧穿电流的主导地位。

Result: 得到了反型层宽度、电势和电荷分布的显式表达式，揭示了这些量在超过阈值电压后的饱和现象。分析表明，隧穿效应导致电荷重新分布，电势降转移到氧化层，类似于平行板电容器。计算结果证实隧穿电流在反型过程中占主导地位。

Conclusion: 该解析解为量子效应器件建模提供了新的理论基础，并为下一代MOSFET和隧穿FET的设计提供了指导。隧穿效应在MOS结构的反型过程中起着关键作用，并显著改变了器件的行为。

Abstract: An analytical solution to the nonlinear Poisson equation governing the inversion layer in metal-oxide-semiconductor (MOS) structures has recently been obtained, resolving a fundamental challenge in semiconductor theory first identified in 1955. This breakthrough enables the derivation of explicit expressions for relevant physical quantities, such as the inversion-layer width, electric potential, and charge distribution, as functions of gate voltage $V_G$, distance from oxide-semiconductor interface and impurity concentration. These quantities exhibit rapid variation during early-stage inversion but saturate once the gate voltage exceeds the threshold voltage by a few tenths of a volt signaling a transition in the MOS response to $V_G$. The onset of tunneling through the Esaki barrier leads to increased charge accumulation near the interface, reshaping the charge distribution into a two-dimensional profile and shifting the potential drop from the semiconductor to the oxide layer. This reconfiguration resembles the behavior of an ideal parallel-plate capacitor, with charge confined at the interface and the voltage drop localized across the oxide. We analyze this mechanism in detail and demonstrate, through explicit calculations, that the tunneling current through the Esaki-like barrier formed during inversion becomes dominant, effectively superseding classical inversion behavior. These results offer a new analytical foundation for quantum-aware device modeling and inform the design of next-generation MOSFET and tunneling FET architectures.

</details>


### [457] [Edwards Localization](https://arxiv.org/abs/2511.11771)
*Riccardo Fantoni*

Main category: cond-mat.mtrl-sci

TL;DR: 本文研究了量子随机力学中的局域化问题，证明了在一维方势阱中，粒子在任意但固定位置的狄拉克δ散射中心作用下的基态波函数存在静态局域化，并且局域化程度随耦合常数g的增加而增强。当散射中心位置取为均匀分布的伪随机数时，基态的平均值表现出更强的局域化。文章还讨论了该平均过程与粒子在非相互作用玻色-爱因斯坦凝聚中的图像的一致性，并研究了基态波函数动力学。最后，讨论了Lax模型的仿射量子化版本。


<details>
  <summary>Details</summary>
Motivation: 研究量子力学中的局域化问题，特别是在存在散射中心的情况下。

Method: 从Edwards模型出发，证明了一维方势阱中粒子在狄拉克δ散射中心作用下的基态波函数的静态局域化，并分析了耦合常数g和散射中心位置对局域化的影响。考虑了散射中心位置的伪随机分布情况，并讨论了其与玻色-爱因斯坦凝聚的联系。研究了基态波函数的动力学，并讨论了Lax模型的仿射量子化版本。

Result: 证明了基态波函数存在静态局域化，局域化程度随耦合常数g增加而增强。散射中心位置的伪随机分布增加了平均基态的局域化。发现了仿射量子化版本的Lax模型与耦合常数g无关。

Conclusion: 量子随机力学中的局域化问题可以通过Edwards模型得到解释，并且可以通过调整参数（如耦合常数和散射中心位置）来控制局域化程度。仿射量子化版本的Lax模型提供了一个与耦合常数无关的简化模型。

Abstract: We study the localization problem in quantum stochastic mechanics. We start from the Edwards model for a particle in a bath of scattering centers and prove static localization of the ground state wavefunction of the particle in a one dimensional square well coupled to Dirac delta like scattering centers in arbitrary but fixed positions. We see how the localization increases for increasing coupling $g$. Then we choose the scattering centers positions as pseudo random numbers with a uniform probability distribution and observe an increase in the localization of the average of the ground state over the many positions realizations. We discuss how this averaging procedure is consistent with a picture of a particle in a Bose-Einstein condensate of of non interacting boson scattering centers interacting with the particle with Dirac delta functions pair potential. We then study the dynamics of the ground state wave function. We conclude with a discussion of the affine quantization version of the Lax model which reduces to a system of contiguous square wells with walls in arbitrary positions independently of the coupling constant $g$.

</details>


### [458] [Layer breathing Raman mode in two-dimensional van der Waals material $\mathrm{Cr_2Ge_2Te_6}$](https://arxiv.org/abs/2511.11852)
*Nilesh Choudhury,Sandeep,Neesha Yadav,Mayank Shukla,Pintu Das*

Main category: cond-mat.mtrl-sci

TL;DR: Cr2Ge2Te6的拉曼光谱研究揭示了层数对其层间耦合和磁相互作用的影响。


<details>
  <summary>Details</summary>
Motivation: 理解二维范德华磁性材料的层数、晶格动力学和磁相互作用之间的关系对于开发新型磁电和自旋电子器件至关重要。

Method: 利用拉曼光谱技术观察了少层Cr2Ge2Te6的层呼吸模式（LBM），并通过线性链模型（LCM）定量提取了层间力常数（Kc）。

Result: 观察到了Cr2Ge2Te6的LBM，并发现其频率随层数增加呈现软化趋势，表明层间耦合减弱。通过LCM模型得到了层间力常数Kc。

Conclusion: Cr2Ge2Te6的LBM可以作为层间耦合和晶格对称性的直接指纹。层数是影响Cr2Ge2Te6层间耦合和晶格动力学的重要因素。

Abstract: Two-dimensional (2D) van der Waals (vdW) magnetic materials have emerged as key materials for next-generation magneto-electric and spintronic devices, where understanding the relationship between layer number, lattice dynamics, and magnetic interactions is very important. In this work, we report the observation of the layer breathing mode (LBM) in few-layer $\mathrm{Cr_2Ge_2Te_6}$, a ferromagnetic semiconductor with thickness dependent electronic, magnetic and optical properties, using Raman spectroscopy, which serves as a direct fingerprint of interlayer coupling and lattice symmetry. Group-theoretical symmetry analysis confirms that the CGT falls under the non-polar category of layered material. The evolution of the LBM-frequency with increasing layer number (N) reveals a distinct softening trend, characteristic of weakening restoring forces in thicker flakes. By fitting the experimental Raman data using the Linear Chain Model (LCM), we quantitatively extract the interlayer force constant ($\mathrm{K_c}$), providing a measure of the vdW coupling strength between layers.

</details>


### [459] [Effects of Yttrium Doping on Oxygen Conductivity in Ba(Fe, Co, Zr, Y)O_{3-δ} Cathode Materials for Proton Ceramic Fuel Cells](https://arxiv.org/abs/2511.11889)
*Chiyoung Kim,Ryan Jacobs,Jack H. Duffy,Kyle S. Brinkman,Harry W. Abernathy,Dane Morgan*

Main category: cond-mat.mtrl-sci

TL;DR: Y掺杂对质子陶瓷燃料电池阴极材料BCFZY的氧传输性能有影响，但具体影响机制尚不明确。本研究通过实验和理论计算，探究了不同Y含量对BCFZY氧电导率的影响，并提出了考虑晶界影响的等效电路模型来解释实验结果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在明确Y掺杂在BCFZY材料中对氧传输性能的影响，为优化质子陶瓷燃料电池的阴极性能提供指导。

Method: 本研究结合了实验测量和从头算分子动力学模拟。通过测量不同Y含量的BCFZY材料在不同温度下的氧电导率，并利用从头算分子动力学模拟计算氧扩散系数和迁移能。此外，还估算了氧缺陷浓度，并结合实验数据，分析了Y掺杂对氧电导率的影响。最后，构建了一个包含体相电导率和晶界电阻的等效电路模型，以模拟实验结果。

Result: Y掺杂对BCFZY材料的氧电导率有抑制作用。随着Y含量的增加，氧电导率从BCFZ的337 mS/cm下降到BCZY0.1的203 mS/cm，再到BCFY的99 mS/cm (在500°C时)。同时，活化能也随之增加。计算得到的体相电导率高于实验值，表明晶界对氧传输存在显著的限制作用。等效电路模型能够较好地拟合实验数据。

Conclusion: Y掺杂会降低BCFZY材料的氧电导率，这主要是由于Y掺杂影响了氧缺陷的浓度和迁移能。晶界对氧传输也起着关键的限制作用。本研究提出的等效电路模型能够半定量地描述实验结果，并为未来设计高性能的PCFC阴极材料提供了参考。

Abstract: Proton ceramic fuel cells (PCFCs) achieve high efficiency at reduced operating temperatures, but their performance is often limited by slow oxygen reduction reaction (ORR) kinetics at the cathode. The BaCoFeZrY (BCFZY) perovskite family is a promising triple-conducting air-electrode material, yet the role of Y dopants in governing oxygen transport remains unclear. In this study, we examine the effect of Y content on oxygen conductivity in three compositions: BCFZ, BCFZY0.1, and BCFY. Oxygen conductivity was evaluated from the product of oxygen tracer diffusivity and oxygen defect concentration. Ab initio molecular dynamics simulations were used to determine tracer diffusivity and migration energies, while defect concentrations were estimated from reference data. Y doping slightly decreases oxygen conductivity from BCFZ to BCFZY0.1, from 337 to 203 mS/cm at 500 C, with activation energies of 0.155 and 0.172 eV. BCFY shows much lower conductivity (99 mS/cm) and a higher activation energy of 0.261 eV. Computed conductivities are higher and more Arrhenius-like than experimental values, suggesting that microstructural features such as grain boundaries strongly limit oxygen transport in real materials. A series-circuit model combining bulk conductivity and fitted grain-boundary parameters provides semi-quantitative agreement with experiment. These results clarify the role of Y doping in oxygen transport and provide insight for optimizing cathode performance in PCFCs.

</details>


### [460] [Ionic Interdiffusion at Cathode-Solid-Electrolyte Interface: A Machine Learning-Assisted Multiscale Investigation and Mitigation Strategies](https://arxiv.org/abs/2511.11976)
*Musawenkosi K. Ncube,Pallab Barai,Selva Chandrasekaran Selvaraj,Larry A. Curtiss,Anh T. Ngo,Venkat Srinivasan*

Main category: cond-mat.mtrl-sci

TL;DR: 固态电解质在锂电池中具有潜力，但与氧化物阴极的热力学不稳定性是一个挑战。


<details>
  <summary>Details</summary>
Motivation: 研究LiCoO2（LCO）阴极与Li10GeP2S12（LGPS）固态电解质界面的稳定性，并提出解决方案。

Method: 使用从头分子动力学（AIMD）、机器学习分子动力学（MLMD）和连续介质模型研究LCO|LGPS界面的离子互扩散、钝化层形成和电池性能衰减。并研究了LiNb0.5Ta0.5O3（LNTO）作为保护层的有效性。

Result: MLMD模拟表明，LCO|LGPS界面存在离子互扩散，形成电阻性中间相，导致容量快速衰减。LNTO层可阻止离子互扩散，但其较高的机械刚度可能导致界面分层，降低保护层效果。

Conclusion: 需要开发一种兼具低离子互扩散和低机械刚度的新型界面层材料。

Abstract: Future lithium-based batteries are expected to use solid electrolytes to achieve higher energy density and fast charge capabilities. The majority of solid electrolytes are thermodynamically unstable against layered oxide cathodes. Here, the stability of LiCoO2 (LCO) cathode with Li10GeP2S12 (LGPS) solid electrolyte is investigated using ab initio molecular dynamics (AIMD) and machine learning molecular dynamics (MLMD). The propensity of ionic interdiffusion, formation of a passivation layer, and corresponding decay in cell performance is addressed using a continuum model. The large-scale MLMD simulations confirm that the LCO|LGPS interface permits interdiffusion of Co and other ionic species, leading to the formation and growth of a resistive interphase and dramatic capacity fade even in the first cycle. We then examine the literature evidence that incorporating a thin layer of LiNb0.5Ta0.5O3 (LNTO) between LCO and LGPS prevents the interdiffusion of ions. Atomistic simulations suggest that the substitution of Li in LNTO with Co is not thermodynamically favorable, which helps to minimize the ionic interdiffusion process. The stable Nb/Ta5+ states form a rigid metal-oxide framework, which consequently also prevents the substitution of Nb/Ta. However, continuum level analysis suggests that due to the higher mechanical stiffness of LNTO, interfacial delamination between the LCO and LNTO is possible, which can minimize the effectiveness of the protective layer. This paper suggests the need for the development of novel interlayers that balance low interdiffusion with low stiffness.

</details>


### [461] [Ba-substitution induced evolution of structural and magnetic properties of La2-xBaxCoIrO6 double perovskites](https://arxiv.org/abs/2511.12128)
*C. A. S. Vieira,B. J. Santos,J. G. Duque,E. M. Bittar,L. Bufaiçal*

Main category: cond-mat.mtrl-sci

TL;DR: La2-xBaxCoIrO6的磁性行为随着Ba浓度的增加而变化，从亚铁磁性演变为反铁磁性，这与结构和电子性质的变化以及Ir的自旋-轨道耦合有关。


<details>
  <summary>Details</summary>
Motivation: 研究La2-xBaxCoIrO6中Ir与Co的耦合，以了解强自旋-轨道耦合对5d离子非传统物理学的影响。

Method: 通过X射线粉末衍射和磁测量研究了La2-xBaxCoIrO6（x = 0, 0.5, 0.75和1.0）的结构、电子和磁性。

Result: 随着Ba浓度的增加，晶体结构从单斜P2_1/n演变为三斜I-1空间群。x = 0, 0.5和0.75的化合物表现出亚铁磁性，这可能是由于Co2+/3+和Ir4+之间的反铁磁耦合。然而，在x = 1.0时，观察到Co2+离子的反铁磁特性，这是由于Ir5+磁矩的猝灭。

Conclusion: La2-xBaxCoIrO6的磁性质的演变可以用结构和电子性质的变化以及Ir的自旋-轨道耦合来解释。

Abstract: The Iridium-based oxides are the subject of great recent interest due to the non-conventional physics that may emerge from the strong spin-orbit coupling present in 5d ions. Here, we explore the coupling between Ir and Co in the La2-xBaxCoIrO6 perovskites (x = 0, 0.5, 0.75 and 1.0), where the structural, electronic, and magnetic properties of the series are investigated by means of x-ray powder diffraction and magnetometry. The system's crystal structure evolves from the monoclinic P2_1/n to the triclinic I-1 space group as the Ba concentration increases. Measurements of magnetization revealed ferrimagnetic behavior in x = 0, 0.5 and 0.75 compounds, possibly resulting from antiferromagnetic coupling between Co2+/3+ and Ir4+. In contrast, for x = 1.0 a clear collinear antiferromagnetic character is observed for the Co2+ ions, resulting from the quenching of the Ir5+ magnetic moment. The evolution of the magnetic properties of the series is discussed in terms of the structural and electronic changes, as well as the spin-orbit coupling in Ir.

</details>


### [462] [Rapid Machine Learning-Driven Detection of Pesticides and Dyes Using Raman Spectroscopy](https://arxiv.org/abs/2511.12167)
*Quach Thi Thai Binh,Thuan Phuoc,Xuan Hai,Thang Bach Phan,Vu Thi Hanh Thu,Nguyen Tuan Hung*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种名为MLRaman的深度学习框架，结合ResNet-18特征提取和XGBoost/SVM分类器，用于从拉曼光谱中检测农药和染料，实现了97.4%的预测准确率和1.0的AUC，并开发了用户友好的Streamlit应用程序，在食品安全和环境监测领域具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 鉴于农药和合成染料对食品安全、人类健康和环境可持续性构成的威胁，以及现有拉曼光谱技术的局限性（光谱噪声、荧光背景和波段重叠），需要快速可靠的检测方法。

Method: 提出了一种基于ResNet-18特征提取和XGBoost、SVM及其混合集成的高级分类器的深度学习框架（MLRaman），用于从拉曼光谱中检测农药和染料。

Result: MLRaman结合CNN-XGBoost模型实现了97.4%的预测准确率和1.0的AUC，结合CNN-SVM模型也提供了具有稳健类区分能力的有竞争力结果。降维分析（PCA、t-SNE、UMAP）证实了10种分析物（7种农药和3种染料）的拉曼嵌入具有可分离性。所开发的Streamlit应用程序能够实时预测，并成功识别了独立实验和文献来源的未知拉曼光谱，显示出强大的泛化能力。

Conclusion: 该研究建立了一个可扩展、实用的MLRaman模型，用于多残留污染物监测，在食品安全和环境监测方面具有显著的应用潜力。

Abstract: The extensive use of pesticides and synthetic dyes poses critical threats to food safety, human health, and environmental sustainability, necessitating rapid and reliable detection methods. Raman spectroscopy offers molecularly specific fingerprints but suffers from spectral noise, fluorescence background, and band overlap, limiting its real-world applicability. Here, we propose a deep learning framework based on ResNet-18 feature extraction, combined with advanced classifiers, including XGBoost, SVM, and their hybrid integration, to detect pesticides and dyes from Raman spectroscopy, called MLRaman. The MLRaman with the CNN-XGBoost model achieved a predictive accuracy of 97.4% and a perfect AUC of 1.0, while it with the CNN-SVM model provided competitive results with robust class-wise discrimination. Dimensionality reduction analyses (PCA, t-SNE, UMAP) confirmed the separability of Raman embeddings across 10 analytes, including 7 pesticides and 3 dyes. Finally, we developed a user-friendly Streamlit application for real-time prediction, which successfully identified unseen Raman spectra from our independent experiments and also literature sources, underscoring strong generalization capacity. This study establishes a scalable, practical MLRaman model for multi-residue contaminant monitoring, with significant potential for deployment in food safety and environmental surveillance.

</details>


### [463] [Equivariant Atomic and Lattice Modeling Using Geometric Deep Learning for Crystal Structure Optimization](https://arxiv.org/abs/2511.12243)
*Ziduo Yang,Yi-Ming Zhao,Xian Wang,Wei Zhuo,Xiaoqing Liu,Lei Shen*

Main category: cond-mat.mtrl-sci

TL;DR: E3Relax是一个端到端的等变图神经网络，可以直接将未弛豫的晶体映射到其弛豫结构，解决了传统从头算方法的计算密集性问题，并克服了现有机器学习模型在处理晶格向量和工作流程方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统从头算方法（如DFT）在进行可靠的材料性质计算时，其结构优化过程计算成本高昂，而机器学习方法虽然有所缓解，但存在只关注原子而忽略晶格向量以及工作流程非端到端易累积误差等问题。

Method: 提出了一种名为E3Relax的端到端等变图神经网络，将原子和晶格向量作为具有双重标量-向量特征的图节点，实现了原子位移和晶格变形的统一和对称性保持建模。采用分层监督策略，使网络的每一层都能进行有物理意义的精炼，从而在保持端到端流程的同时，模拟了DFT的增量收敛过程。

Result: 在四个基准数据集上进行了评估，E3Relax在准确性和效率方面均表现出色。通过DFT验证，E3Relax预测的结构具有能量优势，可作为加速DFT计算的高质量初始构型。

Conclusion: E3Relax通过端到端的等变图神经网络方法，成功地解决了传统结构优化计算成本高和现有机器学习模型局限性问题，能够直接预测材料的弛豫结构，并能作为加速DFT计算的有效初始构型。

Abstract: Structure optimization, which yields the relaxed structure (minimum-energy state), is essential for reliable materials property calculations, yet traditional ab initio approaches such as density-functional theory (DFT) are computationally intensive. Machine learning (ML) has emerged to alleviate this bottleneck but suffers from two major limitations: (i) existing models operate mainly on atoms, leaving lattice vectors implicit despite their critical role in structural optimization; and (ii) they often rely on multi-stage, non-end-to-end workflows that are prone to error accumulation. Here, we present E3Relax, an end-to-end equivariant graph neural network that maps an unrelaxed crystal directly to its relaxed structure. E3Relax promotes both atoms and lattice vectors to graph nodes endowed with dual scalar-vector features, enabling unified and symmetry-preserving modeling of atomic displacements and lattice deformations. A layer-wise supervision strategy forces every network depth to make a physically meaningful refinement, mimicking the incremental convergence of DFT while preserving a fully end-to-end pipeline. We evaluate E3Relax on four benchmark datasets and demonstrate that it achieves remarkable accuracy and efficiency. Through DFT validations, we show that the structures predicted by E3Relax are energetically favorable, making them suitable as high-quality initial configurations to accelerate DFT calculations.

</details>


### [464] [Reinforcement Learning for Chemical Ordering in Alloy Nanoparticles](https://arxiv.org/abs/2511.12260)
*Jonas Elsborg,Arghya Bhowmik*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究将寻找双金属纳米颗粒（NPs）中最佳元素排序的问题转化为强化学习（RL）问题，并构建了一个RL代理，利用NPs的几何图表示来学习执行这种全局优化。


<details>
  <summary>Details</summary>
Motivation: 将寻找最佳元素排序的问题构建为强化学习问题，以优化双金属纳米颗粒的结构。

Method: 使用几何图表示和基于原子交换动作的强化学习代理来优化纳米颗粒的元素排序。

Result: 训练的RL代理能够发现先前已知的金银纳米颗粒（AgXAu309-X）基态结构，并且对不同的初始构型具有鲁棒性。该策略还可以推广到不同尺寸的纳米颗粒，但在多组分合金中效果有限。

Conclusion: 强化学习结合预训练的等变图编码可以有效地在纳米颗粒尺度上导航组合排序空间，并提供一种可迁移的优化策略，有望实现跨组分的泛化并降低重复搜索成本。

Abstract: We approach the search for optimal element ordering in bimetallic alloy nanoparticles (NPs) as a reinforcement learning (RL) problem, and have built an RL agent that learns to perform such global optimisation using the geometric graph representation of the NPs. To demonstrate the effectiveness, we train an RL agent to perform composition-conserving atomic swap actions on the icosahedral nanoparticle structure. Trained once on randomised $Ag_{X}Au_{309-X}$ compositions and orderings, the agent discovers previously established ground state structure. We show that this optimization is robust to differently ordered initialisations of the same NP compositions. We also demonstrate that a trained policy can extrapolate effectively to NPs of unseen size. However, the efficacy is limited when multiple alloying elements are involved. Our results demonstrate that RL with pre-trained equivariant graph encodings can navigate combinatorial ordering spaces at the nanoparticle scale, and offer a transferable optimisation strategy with the potential to generalise across composition and reduce repeated individual search cost.

</details>


### [465] [Stoichiometry and Phase Control in K$_{1-x}$CrSe$_2$ via Self-Flux Synthesis](https://arxiv.org/abs/2511.12338)
*Felix Eder,Catherine Witteveen,Enrico Giannini,Fabian O. von Rohr*

Main category: cond-mat.mtrl-sci

TL;DR: KCrSe2在不同淬火温度下会形成不同的相，其中全化学计量相KCrSe2的磁性表现出场依赖性，表明淬火温度可以调控材料的化学计量比和磁性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决合成、结构类型控制和非化学计量学在层状类 स्थिरता石磁体（如KCrSe2）研究中面临的挑战，并探索通过调控合成参数来控制材料的磁性能。

Method: 通过改变淬火温度，从相同的K:Cr:Se = 8:1:8的自熔剂成分中分离出三种不同的K1-xCrSe2相（x = 0, 0.13-0.17, 0.32-0.35），每种相具有不同的结构类型。随后，成功生长出全化学计量相KCrSe2的单晶，并进行依赖于方向的磁化测量。

Result: 研究发现了三种不同的K1-xCrSe2相，其结构类型随淬火温度变化。全化学计量相KCrSe2的磁化测量显示出与低外磁场相关的明显 Néel 温度依赖性以及较弱的亚磁转变。

Conclusion: 合成过程中简单的淬火温度调控即可控制化学计量比、相形成，并最终调节层状类 स्थिरता石材料的磁性能。

Abstract: Layered delafossite-type magnetic materials, such as KCrSe$_2$, are promising platforms for studying magnetic systems and potential frustration on triangular lattices. Synthesis, structure-type control, and off-stoichiometries remain major challenges in the investigation of these delafossite-type magnets. Starting from the same self-flux composition (K:Cr:Se = 8:1:8), we isolated three distinct K$_{1-x}$CrSe$_2$ phases with $x$ = 0, 0.13--0.17, and 0.32--0.35, each adopting a different structure type depending on the quenching temperature applied. The phase evolution indicates a sequence of transformations during synthesis between compounds with varying degrees of potassium deficiency. Building on these insights into phase stability and crystal growth, we successfully grew single crystals of full-stoichiometric KCrSe$_2$ -- enabling direction-dependent magnetization measurements. These measurements reveal a pronounced field dependence of the Néel temperature at low external fields, as well as a weak metamagnetic transition. Our findings demonstrate that even a simple parameter -- such as quenching temperature -- can be used to control stoichiometry, direct phase formation, and ultimately tune the magnetic properties of delafossite-type materials.

</details>


### [466] [Chemical-space completeness: a new strategy for crystalline materials exploration](https://arxiv.org/abs/2511.12420)
*Fengyu Xie,Ruoyu Wang,Taoyuze Lv,Yuxiang Gao,Hongyu Wu,Zhicheng Zhong*

Main category: cond-mat.mtrl-sci

TL;DR: 深度学习在材料科学中的应用仍受限于组合爆炸，本文提出一种以化学系统为中心、结合生成模型和机器学习力场的策略，以提高探索效率和准确性，并成功应用于Li-P-S体系，实现了数据高效的闭环收敛，并展示了其在相图构建、离子扩散筛选和电子结构预测等方面的应用。


<details>
  <summary>Details</summary>
Motivation: 深度学习在理解和探索晶体材料方面取得了进展，但跨元素探索受限于组合爆炸，难以平衡准确性和效率。本文旨在利用化学直觉，提出一种新的策略来解决这一挑战。

Method: 提出一种以化学系统为中心的策略，将生成模型与机器学习力场结合，通过生成、评估和微调的闭环循环进行迭代优化，以快速评估能量。

Result: 在Li-P-S三元体系的案例研究中，该方法在最小化第一性原理数据的情况下，捕捉到了局部环境的多样性，并保持了结构的创造性，实现了在有界化学空间内向化学完整性的闭环收敛。此外，还展示了其在相图构建、离子扩散筛选和电子结构预测等下游应用。

Conclusion: 该策略提供了一个系统化、数据高效的框架，用于在定义的化学空间内对原子和电子结构进行建模，平衡了准确性和效率，为可扩展的、人工智能驱动的、具有人类水平创造力和第一性原理保真度的晶体材料发现铺平了道路。

Abstract: The emergence of deep learning has brought the long-standing goal of comprehensively understanding and exploring crystalline materials closer to reality. Yet, universal exploration across all elements remains hindered by the combinatorial explosion of possible chemical environments, making it difficult to balance accuracy and efficiency. Crucially, within any finite set of elements, the diversity of short-range bonding types and local geometric motifs is inherently limited. Guided by this chemical intuition, we propose a chemical-system-centric strategy for crystalline materials exploration. In this framework, generative models are coupled with machine-learned force fields as fast energy evaluators, and both are iteratively refined in a closed-loop cycle of generation, evaluation, and fine-tuning. Using the Li-P-S ternary system as a case study, we show that this approach captures the diversity of local environments with minimal additional first-principles data while maintaining structural creativity, achieving closed-loop convergence toward chemical completeness within a bounded chemical space. We further demonstrate downstream applications, including phase-diagram construction, ionic-diffusivity screening, and electronic-structure prediction. Together, this strategy provides a systematic and data-efficient framework for modeling both atomistic and electronic structures within defined chemical spaces, bridging accuracy and efficiency, and paving the way toward scalable, AI-driven discovery of crystalline materials with human-level creativity and first-principles fidelity.

</details>


### [467] [An Active Learning Interatomic Potential For Defect-Engineered CoCrFeMnNi High-Entropy Alloy](https://arxiv.org/abs/2511.12514)
*Manish Sahoo,Akash Deshmukh,Yash Kokane,Jayaprakash H M,Raghavan Ranganathan*

Main category: cond-mat.mtrl-sci

TL;DR: 本工作利用机器学习和BFGS算法开发了一种用于CoCrFeMnNi高熵合金的力矩张量势(MTP)，并将其集成到LAMMPS中。


<details>
  <summary>Details</summary>
Motivation: 机器学习方法加速了新型合金的发现，但缺乏原子间势是发现新合金成分和测量性质的挑战。本研究旨在开发一种高精度、计算效率高的原子间势，以克服这一挑战。

Method: 使用机器学习方法和BFGS无约束优化算法，并结合包含各种缺陷（空位、位错、堆积层错）的训练集，为CoCrFeMnNi高熵合金开发了力矩张量势(MTP)。采用主动学习方案对势进行再训练，以在非平衡模拟中动态添加训练数据。

Result: 开发出的MTP势在预测物理性质方面优于MEAM势，并且在精度和计算速度方面表现出色。

Conclusion: 所开发的MTP势是一种高精度、高计算效率的原子间势，可用于CoCrFeMnNi高熵合金的研究，并已集成到LAMMPS中，供公众使用。

Abstract: High-entropy alloys (HEAs) exhibit exceptional properties arising from a combination of thermodynamic, kinetic and structural factors and have found applications in numerous fields such as aerospace, energy, chemical industries, hydrogen storage, and ocean engineering. However, a large compositional space remains to be explored. Unlike conventional approaches, computational methods have shown accelerated discovery of novel alloys in a short time. However, the lack of interatomic potentials have posed a challenge in discovering new alloy compositions and property measurements. In the present work, we have developed a Moment Tensor Potential (MTP) trained by Machine Learning based approach using the BFGS unconstrained optimization algorithm for the CoCrFeMnNi High-entropy alloy. Our training set consists of various defects induced configurations such as vacancies, dislocations and stacking-faults. An active learning scheme to re-train the potential was undertaken to dynamically to add training data upon encountering extrapolative configurations during non-equilibrium simulations. A thorough investigation of the error metrics, equation of state, uniaxial tensile deformation, nano-indentation and solid-liquid interface stability for this alloy was carried out, and it is seen that the MTP potential outperforms the popular Modified Embedded Atom Method (MEAM) potential on physical properties prediction. The accuracy and high computational speed are discussed using scaling performance. The potential is prepared for public use by embedding it into the Large-scale Atomic/Molecular Massively Parallel Simulator (LAMMPS) code.

</details>


### [468] [Distortion-Driven Carrier Decoupling in Doped LiMgPO4](https://arxiv.org/abs/2511.12674)
*Zhihua Zheng,Xiaolong Yao,Cailian Yu,Menghao Gao,Fangping Ouyang,Shiwu Gao*

Main category: cond-mat.mtrl-sci

TL;DR: 在碱金属掺杂的LiMgPO4中，载流子解耦机制由晶格畸变驱动，电子被捕获形成小极化子，而空穴形成更具迁移性的极化子，从而抑制了复合，增强了储能。


<details>
  <summary>Details</summary>
Motivation: 解释了为什么在碱金属掺杂的LiMgPO4中，剂量学响应会显著增强，但其微观起源尚不清楚。

Method: 使用非绝热分子动力学模拟，揭示了由晶格畸变驱动的载流子解耦机制。

Result: 电子在超快时间尺度上局域化形成稳定的极小化极化子，而空穴形成更分散的极化子，有效地通过被全局应变平滑的晶格迁移。这种电子和空穴动力学的巨大差异解释了复合的抑制和能量存储的增强。

Conclusion: 揭示了多尺度晶格畸变如何独立控制电子和空穴传输，为理解复杂材料中的极化子物理学提供了新的见解。

Abstract: The interplay between lattice distortions and charge carriers governs the properties of many functional oxides. In alkali-doped LiMgPO4, a significant enhancement in dosimetric response is observed, but its microscopic origin is not understood. Using non-adiabatic molecular dynamics, we reveal a fundamental mechanism of carrier decoupling driven by a hierarchy of lattice distortions. We show that electrons localize into stable small polarons on an ultrafast timescale, trapped by the strong local potential induced by the dopant, while holes form more delocalized polarons that migrate efficiently through a lattice smoothed by global strain. The stark contrast between the dynamics of trapped electrons and mobile holes explains the suppressed recombination and enhanced energy storage. These results present a clear physical picture of how multiscale lattice distortions can independently control electron and hole transport, offering new insights into the physics of polarons in complex materials.

</details>


### [469] [Lattice Thermal Transport Beyond the Quasiparticle Approximation: Nontrivial Spectral Competition between Three- and Four-Phonon Interactions](https://arxiv.org/abs/2511.12790)
*Yi Xia*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种超越准粒子近似（BQPA）的方法，结合了三声子（3ph）和四声子（4ph）相互作用，用于计算强非谐材料中的晶格热导率（κL）。研究应用于MgO、PbTe和AgCl三种材料，发现BQPA在考虑3ph相互作用时会增加κL，但加入4ph相互作用后会抑制这种增加，使BQPA和QPA的预测结果趋于一致。研究强调了在强非谐材料中准确模拟κL需要同时考虑完整的声子谱函数和高阶非谐性。


<details>
  <summary>Details</summary>
Motivation: 传统的第一性原理框架在强非谐材料中无法准确预测晶格动力学和热输运，因为其基于准粒子近似（QPA）。需要更高级的框架来处理非谐性。

Method: 开发了一种超越准粒子近似（BQPA）的方法，该方法同时考虑了三声子（3ph）和四声子（4ph）相互作用。将该方法应用于MgO、PbTe和AgCl三种材料，研究它们的晶格热导率（κL）。

Result: 在只考虑3ph相互作用时，BQPA比QPA预测的κL有所增加，这是由于声子软化。然而，当同时考虑4ph相互作用时，声子谱变硬，抑制了κL的增强，使得BQPA和QPA的预测结果在所有三种材料中都非常接近。这表明存在一种微妙的谱竞争效应。

Conclusion: 准确模拟强非谐材料中的κL需要同时考虑完整的声子谱函数和高阶非谐性。该研究建立了一个系统性的框架，用于模拟具有过阻尼声子的体系中的热输运，并为超越传统声子输运理论的材料设计提供了重要见解。

Abstract: The breakdown of the quasiparticle approximation (QPA) for phonons in strongly anharmonic materials necessitates advanced first-principles frameworks for accurate lattice dynamics and thermal transport predictions. We develop a comprehensive beyond-quasiparticle approximation (BQPA) approach incorporating both three- (3ph) and four-phonon (4ph) interactions and apply it to investigate lattice thermal conductivity ($κ_{\rm L}$) in MgO, PbTe, and AgCl -- materials that span a broad spectrum of anharmonicity, from weak to severe anharmonic regimes with overdamped phonons. We reveal that while BQPA consistently increases $κ_{\rm L}$ relative to QPA due to phonon softening when considering only 3ph interactions, the inclusion of additional 4ph interactions hardens the phonon spectrum and suppresses this enhancement, bringing BQPA and QPA predictions into close agreement via subtle spectral competition effects across all three compounds. These findings highlight that accurate modeling of $κ_{\rm L}$ in strongly anharmonic materials requires treating both full phonon spectral function and higher-order anharmonicity on equal footing. Our work establishes a systematic framework for modeling thermal transport in systems with overdamped phonons and provides critical insights for materials design beyond the limits of conventional phonon transport theory.

</details>


### [470] [Unraveling the Surface Stability and Chemical Reactivity of Aza-Triphenylene Monolayer under O$_2$ and H$_2$O Exposure](https://arxiv.org/abs/2511.12697)
*Soumendra Kumar Das,Prasanjit Samal,Brahmananda Chakraborty,Sridhar Sahu*

Main category: cond-mat.mtrl-sci

TL;DR: 环境氧化会影响二维材料的性质，但2D aza-triphenylene单层膜对氧气和水的吸附和离解有很强的抵抗力，表明其在器件应用中的稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究环境氧化（O2和H2O吸附和离解）对2D aza-triphenylene单层膜的影响，并评估其在纳米工程器件中的应用稳定性。

Method: 使用第一性原理计算和CINEB方法研究O2和H2O在2D aza-triphenylene单层膜表面的吸附和离解过程。

Result: O2和H2O分子与单层膜弱相互作用（吸附能分别为-0.16 eV和-0.37 eV），但离解过程需要较高的能量势垒（O2为0.16 eV和1.22 eV，H2O为2.3 eV和0.86 eV）。离解后的产物（原子氧、H+、OH-）与单层膜发生强化学吸附，并导致带隙增大。

Conclusion: 2D aza-triphenylene单层膜对氧气和水暴露具有良好的稳定性，适用于器件应用。

Abstract: Environmental oxidation has a great impact in tuning the physical, chemical and electronic properties of two-dimensional (2D) monolayers which can affect their practical applications in nanoscale engineering devices under ambient conditions. aza-triphenylene is a recently synthesized 2D materials whose practcal applications have not been systematically studied yet. In this study, we report for the first time, the adsorption and dissociation of O$_2$ and H$_2$O molecules on the surface of 2D aza-triphenylene monolayer through first principles calculations in combination with climbing image nudged elastic band (CINEB) method. The results indicates that both the O$_2$ and H$_2$O molecules weakly interact over the monolayer surface with an adsorption energy -0.16 eV and -0.37 eV respectively. In contrast, both the molecules exhibit resistance for dissociation due to the formation of energy barriers. The transition path indicates that molecular oxygen experience two energy barriers (0.16 ev and 1.22 eV) before getting dissociated atomic oxygen. However, the dissociation of H$_2$O requires larger energy barrier (2.3 eV and 0.86 eV) due to breaking of covalent bonds and transfer of hydrogen. The strong chemical adsorption of atomic oxygen and H$^+$/OH$^-$ ions is due to the significant charge transfer from monolayer to the adsorbate as evidenced from the charge density difference and Bader charge analysis. Moreover, the dissociated configuration exhibit a larger band gap as compared to the pristine aza-triphenylene due to the strong hybridization between the p states of carbon and oxygen. our work predicts the robustness of azatriphylene monolayer against oxygen/water exposer thus ensuring their stability for device applications using these materials.

</details>


### [471] [XPS Analysis of Surface Chemical Transformations in ZBLAN Glass under Thermal and Vibrational Stimuli](https://arxiv.org/abs/2511.12989)
*Ayush Subedi,Anthony Torres,Jeff Ganley*

Main category: cond-mat.mtrl-sci

TL;DR: ZBLAN玻璃对热和机械刺激敏感，但表面化学变化仍不清楚。XPS测量显示，热处理和振动辅助处理会提高ZBLAN的表面结构有序度，但不会改变其化学状态。


<details>
  <summary>Details</summary>
Motivation: ZBLAN玻璃对热和机械刺激的敏感性与其表面化学变化之间的关系尚不清楚。

Method: 使用X射线光电子能谱（XPS）测量了不同结构状态（完全非晶态、初始结晶态、高度结晶态）的ZBLAN样品。这些样品通过在250°C和350°C进行热处理，以及在400°C进行低（L2）和高（H5）振动水平下的振动辅助处理来制备。

Result: 高分辨率的F 1s、Zr 3d、Hf 4f、Ba 3d、La 3d和Na 1s光谱显示，随着温度和振动的增加，峰变尖锐，强度增强，表明表面无序性降低，局部结构有序性增强。在高振动（400°C）下变化最明显。未检测到结合能移动，证实所有元素的氧化态不变，变化仅反映结构而非化学变化。

Conclusion: 热机械输入可增强ZBLAN的表面有序性，这与其在红外光学应用中的结晶行为相关。

Abstract: ZBLAN glass is highly sensitive to thermal and mechanical stimuli, yet the associated surface chemical changes remain poorly understood. X-Ray Photoelectron Spectroscopy (XPS) measurements were performed on multiple ZBLAN samples representing distinct structural states: fully amorphous, incipiently crystalline, and highly crystalline, produced through thermal treatments at 250C and 350C and vibration-assisted processing at 400C under low (L2) and high (H5) vibration levels. High-resolution F 1s, Zr 3d, Hf 4f, Ba 3d, La 3d, and Na 1s spectra show progressive peak sharpening and intensity enhancement with increasing temperature and vibration, indicating reduced surface disorder and greater local structural ordering. The most pronounced changes occur under high vibration at 400C. No binding-energy shifts were detected, confirming that all elements retain their expected oxidation states and that the observed evolution reflects structural rather than chemical changes. These results provide direct evidence that thermomechanical input enhances surface ordering in ZBLAN and clarify its role in crystallization behavior relevant to infrared optical applications.

</details>


### [472] [Revealing the dynamic responses of Pb under shock loading based on DFT-accuracy machine learning potential](https://arxiv.org/abs/2511.12995)
*Enze Hou,Xiaoyang Wang,Han Wang*

Main category: cond-mat.mtrl-sci

TL;DR: Lead (Pb)在冲击加载下的动态行为，特别是塑性变形和相变，其机制尚不明确。本研究使用新开发的机器学习势能，通过非平衡分子动力学模拟（NEMD）研究了不同冲击方向下Pb的微观结构演化。结果显示，[001]方向的冲击引起了快速、可逆的相变和层错演化，且无孪晶现象；[011]方向的冲击则导致缓慢、不可逆的塑性变形以及局部化的FCC-BCC相变。


<details>
  <summary>Details</summary>
Motivation: 阐明铅（Pb）在冲击加载下的动态力学行为，特别是塑性变形和冲击诱导相变的基本机制，因为这些机制的理解仍然不足，且实验方法难以揭示。

Method: 利用新开发的用于Pb-Sn合金的机器学习势能，采用非平衡分子动力学（NEMD）模拟方法，研究了在不同冲击方向（[001]和[011]）下Pb的微观结构演化。

Result: 在[001]方向的冲击下，观察到Pb发生了快速、可逆的大规模相变和层错演化，且塑性变形过程中未出现孪晶。而在[011]方向的冲击下，Pb表现出缓慢、不可逆的塑性变形，并在Pitsch取向关系下发生了局部化的FCC-BCC相变。

Conclusion: 本研究通过先进的计算模拟，为理解铅在极端条件下的动态力学响应提供了重要的理论见解，特别是揭示了不同冲击方向对相变和塑性变形机制的影响，并为理解微观结构与性能的关系提供了理论基础。

Abstract: Lead (Pb) is a typical low-melting-point ductile metal and serves as an important model material in the study of dynamic responses. Under shock-wave loading, its dynamic mechanical behavior comprises two key phenomena: plastic deformation and shock induced phase transitions. The underlying mechanisms of these processes are still poorly understood. Revealing these mechanisms remains challenging for experimental approaches. Non-equilibrium molecular dynamics (NEMD) simulations are an alternative theoretical tool for studying dynamic responses, as they capture atomic-scale mechanisms such as defect evolution and deformation pathways. However, due to the limited accuracy of empirical interatomic potentials, the reliability of previous NEMD studies is questioned. Using our newly developed machine learning potential for Pb-Sn alloys, we revisited the microstructure evolution in response to shock loading under various shock orientations. The results reveal that shock loading along the [001] orientation of Pb exhibits a fast, reversible, and massive phase transition and stacking fault evolution. The behavior of Pb differs from previous studies by the absence of twinning during plastic deformation. Loading along the [011] orientation leads to slow, irreversible plastic deformation, and a localized FCC-BCC phase transition in the Pitsch orientation relationship. This study provides crucial theoretical insights into the dynamic mechanical response of Pb, offering a theoretical input for understanding the microstructure-performance relationship under extreme conditions.

</details>


### [473] [Accelerated Prediction of Temperature-Dependent Lattice Thermal Conductivity via Ensembled Machine Learning Models](https://arxiv.org/abs/2511.13202)
*Piyush Paliwal,Aftab Alam*

Main category: cond-mat.mtrl-sci

TL;DR: 提出一种机器学习方法，可以准确预测晶格热导率，加速热电材料的发现。


<details>
  <summary>Details</summary>
Motivation: 计算材料的晶格热导率（κL）通常比计算电子输运更耗时，限制了材料的发现。因此，需要一种更有效的方法来预测κL。

Method: 使用机器学习模型（特别是Extra Trees Regressor，ETR）来预测κL。该模型在来自文献的密度泛函理论（DFT）计算数据上进行训练，并在各种温度下进行了测试。

Result: ETR模型在预测κL方面表现出很高的准确性，R²为0.9994，均方根误差为0.0466 W m⁻¹ K⁻¹。该模型还能很好地泛化到未见过和具有不同对称性的化合物。研究人员使用该模型筛选了潜在的热电材料，并在具有可用实验κL的数据集上进行了测试。

Conclusion: 所提出的机器学习方法可以准确预测κL，并且能够有效地筛选具有所需热电特性的材料。

Abstract: Lattice thermal conductivity ($κ_L$) is a key physical property governing heat transport in solids, with direct relevance to thermoelectrics, thermal barrier coatings, and heat management applications. However, while experimental determination of $κ_L$ is challenging, its theoretical calculation via ab initio methods particularly using density functional theory (DFT) is computationally intensive, often more demanding than electronic transport calculations by an order of magnitude. In this work, we present a machine learning (ML) approach to predict $κ_L$ with DFT-level accuracy over a wide temperature range (100-1000 K). Among various models trained on DFT-calculated data \textcolor{black}{obtained} from literature, the Extra Trees Regressor (ETR) yielded the best performance on log-scaled $κ_L$, achieving an average $R^2$ of 0.9994 and a root mean square error (RMSE) of 0.0466 $W\,m^{-1}\,K^{-1}$. The ETR model also generalized well to twelve previously unseen (randomly chosen) low and high $κ_L$ compounds with diverse space group symmetries, reaching an $R^2$ of 0.961 against DFT benchmarks. Notably, the model excels in predicting $κ_L$ for both low- and high-symmetry compounds, enabling efficient high-throughput screening. We also demonstrate this capability by screening ultralow and ultrahigh $κ_L$ candidates among 960 half-Heusler \textcolor{black}{compounds} and 60,000 ICSD compounds from the AFLOW database. This result shows reliability of model developed for screening of potential thermoelectric materials. At the end, we have tested model's prediction ability on systems that have experimental $κ_L$ available that shows model's ability to search material that has desirable experimental $κ_L$ for thermoelectric applications.

</details>


### [474] [Variationally Consistent Framework for Finite-Strain Microelasticity](https://arxiv.org/abs/2511.13210)
*Tushar Jogi*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种变分一致的有限应变微弹性框架，用于模拟大应变下的显微结构演化，解决了现有方法在宏观边界条件处理上的不足，并通过FFT-Newton算法实现了高效求解，成功应用于模拟镁的形变孪晶过程。


<details>
  <summary>Details</summary>
Motivation: 现有的大应变显微弹性方法在处理宏观边界条件时存在启发式应用的问题，这导致应力松弛不当和宏观均匀化中的Hill-Mandel功当量关系失效，从而可能错误地表示有限应变下的应力状态和相变路径。

Method: 提出了一种变分一致的有限应变微弹性框架，该框架通过单一能量泛函将微观和宏观力学平衡耦合起来。利用交错式FFT-Newton算法求解得到的欧拉-拉格朗日条件（周期性微平衡和宏观应力平衡），该算法结合了用于局部场的谱不动点更新和用于均匀化变形梯度的牛顿步。该方法能够处理一般的超弹性本构律和任意的相变梯度。

Result: 该框架能够准确地恢复小应变下的Eshelby解，并在大变形时显示出系统性的非线性偏差。应用于镁的形变孪晶，该框架能够重现实验观察到的透镜状形貌、应力再分配以及更快的侧向生长速率。

Conclusion: 该研究建立了一个严格且可扩展的有限应变相场模拟基础，能够处理一般应力或混合边界条件下的相干相变问题。

Abstract: Modeling microstructural evolution at large strains requires mechanical formulations that remain thermodynamically consistent while capturing significant lattice rotations and transformation-induced stresses. However, most existing finite-strain microelasticity and phase-field approaches apply macroscopic boundary conditions heuristically, preventing proper stress relaxation and violating the Hill-Mandel work equivalence required for homogenization. These limitations can misrepresent stress states and transformation pathways under finite strains. Here a variationally consistent finite-strain microelasticity framework is presented that couples microscopic and macroscopic mechanical equilibrium through a single energy functional. The resulting Euler-Lagrange conditions, periodic micro-equilibrium and macroscopic stress balance, are solved using a staggered FFT-Newton algorithm that combines a spectral fixed-point update for local fields with a Newton step for the homogenized deformation gradient. The formulation accommodates general hyperelastic constitutive laws and arbitrary transformation gradients. Benchmarks demonstrate accurate recovery of small-strain Eshelby solutions and systematic nonlinear deviations at large dilatations. Applied to deformation twinning in magnesium, the framework reproduces lenticular morphology, stress redistribution, and faster lateral growth consistent with experiments. This approach establishes a rigorous and scalable foundation for finite-strain phase-field simulations of coherent transformations under general stress or mixed boundary conditions.

</details>


### [475] [Local indirect magnetoelectric coupling at twin walls in CaMnO$_3$](https://arxiv.org/abs/2511.13506)
*Ida C. Skogvoll,Benjamin A. D. Williamson,Sverre M. Selbach*

Main category: cond-mat.mtrl-sci

TL;DR: Ferroelastic twin walls in centrosymmetric perovskites like CaMnO3 can exhibit polar and magnetic properties not found in the bulk material, driven by symmetry breaking and octahedral distortions at the walls, leading to emergent magnetoelectric coupling.


<details>
  <summary>Details</summary>
Motivation: The motivation is to investigate the emergence of polar and magnetic properties at ferroelastic twin walls in centrosymmetric perovskites, specifically CaMnO3, which are symmetry-forbidden in the bulk.

Method: Density functional theory (DFT) calculations were used to study the geometry and magnetic properties of ferroelastic domain walls in orthorhombic CaMnO3. Noncollinear calculations were employed to reveal magnetic moments.

Result: The calculations showed that at the twin walls, inversion symmetry breaking induces local polar distortions coupled to magnetic order through octahedral distortions. Enhanced out-of-plane magnetic moments and a local, finite magnetization confined to the wall were observed. This leads to the coexistence of polarization and magnetization and a magnetoelectric response absent in bulk CaMnO3.

Conclusion: Strain fields across twin walls in centrosymmetric antiferromagnets can lead to emergent magnetoelectric coupling and the coexistence of polarization and magnetization, even when these phenomena are symmetry-forbidden in the bulk material.

Abstract: Ferroelastic twin walls in centrosymmetric perovskites can host emergent polar and magnetic properties forbidden in the bulk. We use density functional theory calculations to study the geometry and magnetic properties of ferroelastic domain walls in orthorhombic CaMnO$_3$, which belongs to the most common perovskite space group, $Pnma$. At the wall, the inherent inversion symmetry-breaking induces local polar distortions dependent on the wall geometry, which couple to the magnetic order through the octahedral distortions. Noncollinear calculations reveal enhanced out-of-plane magnetic moments on the Mn atoms and a local, finite magnetization confined to the wall. Strain fields across twin walls thus give rise to coexistence of polarization and magnetization as well as magnetoelectric response that is absent and symmetry-forbidden in bulk CaMnO$_3$. We propose that magnetoelectric coupling and coexisting polarization and magnetization can emerge at twin walls in bulk centrosymmetric antiferromagnets.

</details>


### [476] [First Principles study of Photocatalytic Water Splitting in BO Monolayer: Effect of Strain and Surface Functionalization](https://arxiv.org/abs/2511.13556)
*Soumendra Kumar Das,Smruti Ranjan Parida,Prasanjit Samal,Brahmananda Chakraborty,Sridhar Sahu*

Main category: cond-mat.mtrl-sci

TL;DR: BO单层材料是光催化分解水的有前途的材料，但其吸收在紫外区域。通过应变工程和单/双原子修饰，可以将其光吸收红移到可见光区域，从而提高光催化效率。


<details>
  <summary>Details</summary>
Motivation: 探索新型二维材料BO单层在光催化分解水领域的应用潜力。

Method: 使用第一性原理计算，研究了应变和表面修饰（单原子和双原子C, N, Si, Ge, P, As）对BO单层光催化活性的影响。

Result: 原始BO单层具有3.8 eV的间接带隙，但光吸收在紫外区域（~4.5 eV）。应变工程可调节带隙和带对齐，但对光吸收影响很小。单原子修饰可能导致金属性或绝缘性，并部分改变光吸收。双原子修饰可显著降低带隙，改善带对齐，并将光吸收红移到可见光区域（1.6至3.2 eV）。所有修饰配置均具有负形成能和良好的稳定性。

Conclusion: BO单层的表面功能化（特别是双原子修饰）可以显著提高其光催化活性，使其能够利用可见光进行水分解产氢。

Abstract: Light element based two dimensional (2D) materials are promising photocatalysts for hydrogen production via water splitting. Boron oxide (BO) is a recently synthesized 2D monolayer which has yet to be thoroughly explored for its potential applications. In this article, using first principles calculations, we report, for the first time, the visible-light photocatalytic activity of a BO monolayer for water splitting under mechanical strain and surface modification with single- and double-atom decorations (C, N, Si, Ge, P, As). The pristine BO monolayer exhibits an indirect band gap of 3.8 eV with band edges spanning the water redox potentials, but its optical absorption lies in the UV region (~ 4.5 eV). Strain engineering tunes the band gap and band alignment with a minimal shifting in the optical absorption (~0.5 eV). Single atom decoration produces a metallic state for elements like N, P, As, and an insulating state for single C, Si, Ge with a partial shifting in optical absorption. In contrast, double atom decoration produces substantial band gap reduction, improved band alignment, a pronounced red-shift in optical absorption into the visible range (1.6 to 3.2 eV) thus satisfying the criteria for water splitting. The stability of all the adsorbed configurations was confirmed by negative formation energy and ab-initio molecular dynamics simulations. These findings suggest BO monolayer functionalization can improve photocatalytic efficiency, providing hydrogen generation insights.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [477] [Phase-Coded Memory and Morphological Resonance: A Next-Generation Retrieval-Augmented Generator Architecture](https://arxiv.org/abs/2511.11848)
*Denis V. Saklakov*

Main category: cs.NE

TL;DR: 该论文提出了一种认知检索增强生成（RAG）模型，通过相位编码记忆和形态-语义共振来突破Transformer的上下文长度限制。该模型将输入编码为具有幅度和相位结构的复杂波形，并使用三层设计：形态映射器、场记忆层和非上下文生成器。这种方法消除了对顺序令牌的依赖，显著降低了计算和内存开销，并通过基于频率的语义访问实现了无限的有效上下文。


<details>
  <summary>Details</summary>
Motivation: Transformer模型存在上下文长度限制，需要更高效的模型来处理长序列和减少计算开销。

Method: 提出了一种认知RAG架构，使用相位编码记忆和形态-语义共振。其三层设计包括：1. 形态映射器：将输入转换为语义波形。2. 场记忆层：以分布式全息痕迹的形式存储知识，并通过相位干扰检索。3. 非上下文生成器：通过共振生成连贯的输出。

Result: 该方法消除了对顺序令牌的依赖，大幅降低了内存和计算开销，并通过基于频率的语义访问实现了无限的有效上下文。实验证明了在能量、存储和时间方面的节省。

Conclusion: 所提出的认知RAG模型通过其新颖的内存和生成机制，有效解决了现有Transformer模型的局限性，并在效率和性能上展现出巨大潜力。

Abstract: This paper introduces a cognitive Retrieval-Augmented Generator (RAG) architecture that transcends transformer context-length limitations through phase-coded memory and morphological-semantic resonance. Instead of token embeddings, the system encodes meaning as complex wave patterns with amplitude-phase structure. A three-tier design is presented: a Morphological Mapper that transforms inputs into semantic waveforms, a Field Memory Layer that stores knowledge as distributed holographic traces and retrieves it via phase interference, and a Non-Contextual Generator that produces coherent output guided by resonance rather than fixed context. This approach eliminates sequential token dependence, greatly reduces memory and computational overhead, and enables unlimited effective context through frequency-based semantic access. The paper outlines theoretical foundations, pseudocode implementation, and experimental evidence from related complex-valued neural models, emphasizing substantial energy, storage, and time savings.

</details>


### [478] [Benchmarking that Matters: Rethinking Benchmarking for Practical Impact](https://arxiv.org/abs/2511.12264)
*Anna V. Kononova,Niki van Stein,Olaf Mersmann,Thomas Bäck,Thomas Bartz-Beielstein,Tobias Glasmachers,Michael Hellwig,Sebastian Krey,Jakub Kůdela,Boris Naujoks,Leonard Papenmeier,Elena Raponi,Quentin Renau,Jeroen Rook,Lennart Schäpermeier,Diederick Vermetten,Daniela Zaharie*

Main category: cs.NE

TL;DR: 当前的进化计算基准测试方法无法满足现实世界的需求，需要建立一个能与现实世界见解同步发展的、包含真实世界启发式基准测试、易于使用的特征空间以及社区维护的性能数据库的基准测试生态系统。


<details>
  <summary>Details</summary>
Motivation: 当前的进化计算基准测试方法无法满足现实世界的需求，导致了其被误用于竞赛、自动算法选择和工业决策等场景。

Method: 提出建立一个包含真实世界启发式基准测试、易于使用的特征空间以及社区维护的性能数据库的基准测试生态系统。

Result: 当前的进化计算基准测试方法无法满足现实世界的需求，存在真实世界启发式问题可用性有限、高级功能缺失以及多目标和噪声环境下的挑战等问题。

Conclusion: 为了实现真正的进展，需要协调一致的努力，建立一个与现实世界见解同步发展的、包含真实世界启发式基准测试、易于使用的特征空间以及社区维护的性能数据库的基准测试生态系统。

Abstract: Benchmarking has driven scientific progress in Evolutionary Computation, yet current practices fall short of real-world needs. Widely used synthetic suites such as BBOB and CEC isolate algorithmic phenomena but poorly reflect the structure, constraints, and information limitations of continuous and mixed-integer optimization problems in practice. This disconnect leads to the misuse of benchmarking suites for competitions, automated algorithm selection, and industrial decision-making, despite these suites being designed for different purposes.
  We identify key gaps in current benchmarking practices and tooling, including limited availability of real-world-inspired problems, missing high-level features, and challenges in multi-objective and noisy settings. We propose a vision centered on curated real-world-inspired benchmarks, practitioner-accessible feature spaces and community-maintained performance databases. Real progress requires coordinated effort: A living benchmarking ecosystem that evolves with real-world insights and supports both scientific understanding and industrial use.

</details>


### [479] [Random-Key Metaheuristic and Linearization for the Quadratic Multiple Constraints Variable-Sized Bin Packing Problem](https://arxiv.org/abs/2511.12367)
*Natalia A. Santos,Marlon Jeske,Antonio A. Chaves*

Main category: cs.NE

TL;DR: 本文针对具有多重约束的二次变量大小箱包装问题（QMC-VSBPP），提出了一种线性化数学模型和一种基于蚁群优化的随机键合优化算法（RKO-ACO），在计算下界和求解问题方面均取得了 SOTA 结果。


<details>
  <summary>Details</summary>
Motivation: 解决具有多重约束的二次变量大小箱包装问题（QMC-VSBPP），该问题是经典的箱包装问题的泛化，具有挑战性。

Method: 提出一个线性化数学模型来消除二次项，并开发一种改进的随机键合优化（RKO）框架下的连续域蚁群优化（ACO）算法，该算法包含自适应Q学习参数控制和有效的局部搜索。

Result: 线性化模型产生的下界比原始二次公式更紧密；RKO-ACO 算法在处理大规模实例时，持续匹配或改进了文献中所有已知的最佳解决方案，并建立了新的上界。

Conclusion: 所提出的方法为 QMC-VSBPP 提供了新的参考值，并证明了进化算法和随机键合元启发式方法在解决复杂的二次包装问题方面的有效性。

Abstract: This paper addresses the Quadratic Multiple Constraints Variable-Sized Bin Packing Problem (QMC-VSBPP), a challenging combinatorial optimization problem that generalizes the classical bin packing by incorporating multiple capacity dimensions, heterogeneous bin types, and quadratic interaction costs between items. We propose two complementary methods that advance the current state-of-the-art. First, a linearized mathematical formulation is introduced to eliminate quadratic terms, enabling the use of exact solvers such as Gurobi to compute strong lower bounds - reported here for the first time for this problem. Second, we develop RKO-ACO, a continuous-domain Ant Colony Optimization algorithm within the Random-Key Optimization framework, enhanced with adaptive Q-learning parameter control and efficient local search. Extensive computational experiments on benchmark instances show that the proposed linearized model produces significantly tighter lower bounds than the original quadratic formulation, while RKO-ACO consistently matches or improves upon all best-known solutions in the literature, establishing new upper bounds for large-scale instances. These results provide new reference values for future studies and demonstrate the effectiveness of evolutionary and random-key metaheuristic approaches for solving complex quadratic packing problems. Source code and data available at https://github.com/nataliaalves03/RKO-ACO

</details>


### [480] [Evolving Prompts for Toxicity Search in Large Language Models](https://arxiv.org/abs/2511.12487)
*Onkar Shelar,Travis Desell*

Main category: cs.NE

TL;DR: 大型语言模型(LLM)在安全对齐后仍易受诱导产生有毒内容的对抗性提示的影响。ToxSearch 是一个黑盒进化框架，通过同步稳态循环演化提示来测试模型安全性。该系统采用词法替换、否定、反向翻译、释义和两种语义交叉等多种算子，并由审核员提供适应度指导。算子级分析显示了异构行为：词法替换提供最佳的收益-方差权衡，语义相似性交叉作为精确的低吞吐量插入器，全局重写则表现出高方差和较高的拒绝成本。通过在 LLaMA 3.1 8B 上演化的精英提示，我们观察到有意义但减弱的跨模型迁移，大多数目标的毒性大约减半，较小的 LLaMA 3.2 变体表现出最强的抵抗力，一些跨架构模型保留了较高的毒性。这些结果表明，小型、可控的扰动是系统化红队测试的有效载体，并且防御措施应预期对抗性提示的跨模型重用，而不是仅关注单一模型加固。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型(LLM)在安全对齐后仍易受诱导产生有毒内容的对抗性提示的影响。

Method: ToxSearch 是一个黑盒进化框架，通过同步稳态循环演化提示来测试模型安全性。该系统采用词法替换、否定、反向翻译、释义和两种语义交叉等多种算子，并由审核员提供适应度指导。

Result: 通过在 LLaMA 3.1 8B 上演化的精英提示，我们观察到有意义但减弱的跨模型迁移，大多数目标的毒性大约减半，较小的 LLaMA 3.2 变体表现出最强的抵抗力，一些跨架构模型保留了较高的毒性。

Conclusion: 小型、可控的扰动是系统化红队测试的有效载体，并且防御措施应预期对抗性提示的跨模型重用，而不是仅关注单一模型加固。

Abstract: Large Language Models remain vulnerable to adversarial prompts that elicit toxic content even after safety alignment. We present ToxSearch, a black-box evolutionary framework that tests model safety by evolving prompts in a synchronous steady-state loop. The system employs a diverse set of operators, including lexical substitutions, negation, back-translation, paraphrasing, and two semantic crossover operators, while a moderation oracle provides fitness guidance. Operator-level analysis shows heterogeneous behavior: lexical substitutions offer the best yield-variance trade-off, semantic-similarity crossover acts as a precise low-throughput inserter, and global rewrites exhibit high variance with elevated refusal costs. Using elite prompts evolved on LLaMA 3.1 8B, we observe practically meaningful but attenuated cross-model transfer, with toxicity roughly halving on most targets, smaller LLaMA 3.2 variants showing the strongest resistance, and some cross-architecture models retaining higher toxicity. These results suggest that small, controllable perturbations are effective vehicles for systematic red-teaming and that defenses should anticipate cross-model reuse of adversarial prompts rather than focusing only on single-model hardening.

</details>


### [481] [On Counts and Densities of Homogeneous Bent Functions: An Evolutionary Approach](https://arxiv.org/abs/2511.12652)
*Claude Carlet,Marko Ðurasevic,Domagoj Jakobovic,Luca Mariot,Stjepan Picek,Alexandr Polujan*

Main category: cs.NE

TL;DR: 本论文研究如何利用进化算法（EA）设计具有强密码学性质（高非线性度和高代数次数）的齐次（代数范式中仅包含相同次数单项式）且最大非线性的布尔函数，并提出了齐次耐力函数密度（density of homogeneous bent functions）的概念，以在不同数量变量的情况下寻找二次和三次耐力函数。


<details>
  <summary>Details</summary>
Motivation: 设计具有强密码学性质（高非线性度和高代数次数）的布尔函数，以增强流密码和分组密码的安全性。

Method: 利用进化算法（EA）来演化齐次耐力布尔函数，并引入了齐次耐力函数密度的概念。

Result: 成功寻找到了不同数量变量下的二次和三次齐次耐力布尔函数。

Conclusion: 齐次耐力布尔函数可以通过进化算法和密度概念进行设计，并且在不同变量数下可以找到二次和三次耐力函数。

Abstract: Boolean functions with strong cryptographic properties, such as high nonlinearity and algebraic degree, are important for the security of stream and block ciphers. These functions can be designed using algebraic constructions or metaheuristics. This paper examines the use of Evolutionary Algorithms (EAs) to evolve homogeneous bent Boolean functions, that is, functions whose algebraic normal form contains only monomials of the same degree and that are maximally nonlinear. We introduce the notion of density of homogeneous bent functions, facilitating the algorithmic design that results in finding quadratic and cubic bent functions in different numbers of variables.

</details>


### [482] [DS-ATGO: Dual-Stage Synergistic Learning via Forward Adaptive Threshold and Backward Gradient Optimization for Spiking Neural Networks](https://arxiv.org/abs/2511.13050)
*Jiaqiang Jiang,Wenfeng Xu,Jing Fan,Rui Yan*

Main category: cs.NE

TL;DR: SNNs在神经拟态计算中具有潜力，但其训练面临挑战。本文提出了一种新颖的双阶段协同学习算法，通过前向自适应阈值和后向动态SGs来解决这些问题，提高了SNNs的性能。


<details>
  <summary>Details</summary>
Motivation: SNNs的直接训练依赖于替代梯度（SG）学习，但神经元膜电位分布的变化和固定阈值可能导致脉冲发放不平衡和梯度信号减弱，影响SNNs的性能。

Method: 提出了一种新颖的双阶段协同学习算法：前向传播中，根据每个时间步的膜电位动力学（MPD）分布自适应地调整阈值，以丰富神经元多样性并平衡发放率；后向传播中，动态优化SG以增强梯度估计，减轻梯度信息丢失。

Result: 实验结果表明，该方法显著提高了性能，使得神经元在每个时间步能稳定发放一定比例的脉冲，并增加了在更深层获得梯度的神经元的比例。

Conclusion: 所提出的双阶段协同学习算法能够有效解决SNNs训练中的挑战，提高其性能和训练稳定性。

Abstract: Brain-inspired spiking neural networks (SNNs) are recognized as a promising avenue for achieving efficient, low-energy neuromorphic computing. Direct training of SNNs typically relies on surrogate gradient (SG) learning to estimate derivatives of non-differentiable spiking activity. However, during training, the distribution of neuronal membrane potentials varies across timesteps and progressively deviates toward both sides of the firing threshold. When the firing threshold and SG remain fixed, this may lead to imbalanced spike firing and diminished gradient signals, preventing SNNs from performing well. To address these issues, we propose a novel dual-stage synergistic learning algorithm that achieves forward adaptive thresholding and backward dynamic SG. In forward propagation, we adaptively adjust thresholds based on the distribution of membrane potential dynamics (MPD) at each timestep, which enriches neuronal diversity and effectively balances firing rates across timesteps and layers. In backward propagation, drawing from the underlying association between MPD, threshold, and SG, we dynamically optimize SG to enhance gradient estimation through spatio-temporal alignment, effectively mitigating gradient information loss. Experimental results demonstrate that our method achieves significant performance improvements. Moreover, it allows neurons to fire stable proportions of spikes at each timestep and increases the proportion of neurons that obtain gradients in deeper layers.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [483] [ACE-GNN: Adaptive GNN Co-Inference with System-Aware Scheduling in Dynamic Edge Environments](https://arxiv.org/abs/2511.11586)
*Ao Zhou,Jianlei Yang,Tong Qiao,Yingjie Qi,Xinming Wei,Cenlin Duan,Weisheng Zhao,Chunming Hu*

Main category: cs.DC

TL;DR: ACE-GNN是一个首个为动态边缘环境量身定制的自适应GNN协同推理框架，通过系统级抽象和新颖的预测方法实现性能感知，并引入数据并行（DP）机制以实现流水线并行（PP）和DP之间的自适应调度，从而在广泛的应用和边缘设置中显著提高系统性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的设备-边缘协同推理方法（如离线模型拆分和流水线并行PP）在动态环境（如网络波动和多设备访问）下性能会受到显著影响，缺乏有效的解决方案。

Method: ACE-GNN通过系统级抽象和两种新颖的预测方法实现性能感知，从而能够快速进行运行时方案优化。此外，ACE-GNN在运行时优化中引入了数据并行（DP）机制，实现了PP和DP之间的自适应调度。该框架还包括高效的批推理策略和专门的通信中间件。

Result: 与GCoDE相比，ACE-GNN实现了高达12.7倍的加速和82.3%的能耗节省。与Fograph相比，ACE-GNN的能效提高了11.7%。

Conclusion: ACE-GNN通过其自适应能力，在动态边缘环境中显著提高了GNN协同推理的性能和稳定性，克服了现有静态部署方法的局限性。

Abstract: The device-edge co-inference paradigm effectively bridges the gap between the high resource demands of Graph Neural Networks (GNNs) and limited device resources, making it a promising solution for advancing edge GNN applications. Existing research enhances GNN co-inference by leveraging offline model splitting and pipeline parallelism (PP), which enables more efficient computation and resource utilization during inference. However, the performance of these static deployment methods is significantly affected by environmental dynamics such as network fluctuations and multi-device access, which remain unaddressed. We present ACE-GNN, the first Adaptive GNN Co-inference framework tailored for dynamic Edge environments, to boost system performance and stability. ACE-GNN achieves performance awareness for complex multi-device access edge systems via system-level abstraction and two novel prediction methods, enabling rapid runtime scheme optimization. Moreover, we introduce a data parallelism (DP) mechanism in the runtime optimization space, enabling adaptive scheduling between PP and DP to leverage their distinct advantages and maintain stable system performance. Also, an efficient batch inference strategy and specialized communication middleware are implemented to further improve performance. Extensive experiments across diverse applications and edge settings demonstrate that ACE-GNN achieves a speedup of up to 12.7x and an energy savings of 82.3% compared to GCoDE, as well as 11.7 better energy efficiency than Fograph.

</details>


### [484] [Distributed Q-learning-based Shortest-Path Tree Construction in IoT Sensor Networks](https://arxiv.org/abs/2511.11598)
*Van-Vi Vo,Tien-Dung Nguyen,Duc-Tai Le,Hyunseung Choo*

Main category: cs.DC

TL;DR: 本论文提出了一种基于Q学习的分布式路由框架，用于优化物联网传感器网络的路由选择，实现高效、低延迟和低能耗的通信。


<details>
  <summary>Details</summary>
Motivation: 传统中心化路由算法在物联网环境中存在计算密集、不适应动态性和分布式特性等问题。因此，需要一种新的方法来解决这些挑战。

Method: 提出了一种分布式的Q学习框架，传感器节点利用局部信息独立学习最优的下一跳选择。状态定义包括节点位置和路由历史，奖励函数用于激励向汇聚节点移动并惩罚低效路径。在一个包含100到500个节点的模拟网络中进行了训练和测试。

Result: 该框架在模拟网络中表现出接近最优的路由准确性（超过99%的准确性，对于超过300个节点的网络），并且在较小的网络中只带来1-2个额外跳数。与中心化和泛洪方法相比，该方法显著减少了通信开销，能够适应拓扑变化，提高了可扩展性和能源效率。

Conclusion: Q学习在资源受限的物联网网络中具有自主、鲁棒路由的巨大潜力，为传统协议提供了一种可扩展的替代方案。

Abstract: Efficient routing in IoT sensor networks is critical for minimizing energy consumption and latency. Traditional centralized algorithms, such as Dijkstra's, are computationally intensive and ill-suited for dynamic, distributed IoT environments. We propose a novel distributed Q-learning framework for constructing shortest-path trees (SPTs), enabling sensor nodes to independently learn optimal next-hop decisions using only local information. States are defined based on node positions and routing history, with a reward function that incentivizes progression toward the sink while penalizing inefficient paths. Trained on diverse network topologies, the framework generalizes effectively to unseen networks. Simulations across 100 to 500 nodes demonstrate near-optimal routing accuracy (over 99% for networks with more than 300 nodes), with minor deviations (1-2 extra hops) in smaller networks having negligible impact on performance. Compared to centralized and flooding-based methods, our approach reduces communication overhead, adapts to topology changes, and enhances scalability and energy efficiency. This work underscores the potential of Q-learning for autonomous, robust routing in resource-constrained IoT networks, offering a scalable alternative to traditional protocols.

</details>


### [485] [Mind the Gap: Revealing Inconsistencies Across Heterogeneous AI Accelerators](https://arxiv.org/abs/2511.11601)
*Elliott Wen,Sean Ma,Ewan Tempero,Jens Dietrich,Daniel Luo,Jiaxing Shen,Kaiqi Zhao,Bruce Sham,Yousong Song,Jiayi Hua,Jia Hong*

Main category: cs.DC

TL;DR: 虽然英伟达在云数据中心的人工智能加速器市场占据主导地位，但AMD、Intel、Mac和华为等新兴供应商提供了具有成本效益的替代方案，并声称具有兼容性和性能。本文提出了第一个实证研究，研究机器学习模型在异构人工智能加速器中的差异。我们利用自动化流程，合成了源自4000个真实世界模型的100,000多个变体模型，并在五个不同的企业级加速器上执行了它们。我们的研究结果表明，Mac和华为较新的人工智能平台支持的算子比英伟达少至少17%。这些平台还表现出更高的输出差异率（超过5%），这源于算子实现、数值异常值处理和指令调度的差异。它们在基于模型的编译加速过程中也更容易出现故障，在某些情况下，编译后的模型产生的输出与使用标准执行模式生成的输出明显不同。此外，我们发现PyTorch有7个实现缺陷，以及跨供应商的40个特定平台问题。这些结果凸显了在日益多样化的硬件生态系统中实现机器学习行为一致性所面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究机器学习模型在异构人工智能加速器中的差异，以应对日益多样化的硬件生态系统带来的挑战。

Method: 利用自动化流程，合成源自4000个真实世界模型的100,000多个变体模型，并在五个不同的企业级加速器上执行。

Result: Mac和华为较新的人工智能平台支持的算子比英伟达少至少17%。这些平台还表现出更高的输出差异率（超过5%），这源于算子实现、数值异常值处理和指令调度的差异。它们在基于模型的编译加速过程中也更容易出现故障，在某些情况下，编译后的模型产生的输出与使用标准执行模式生成的输出明显不同。此外，还发现了PyTorch的7个实现缺陷和跨供应商的40个特定平台问题。

Conclusion: 在日益多样化的硬件生态系统中实现机器学习行为一致性所面临的挑战。

Abstract: While NVIDIA remains the dominant provider of AI accelerators within cloud data center, emerging vendors such as AMD, Intel, Mac, and Huawei offer cost-effective alternatives with claims of compatibility and performance. This paper presents the first empirical study investigating divergence in machine learning model across heterogeneous AI accelerators. Utilizing an automated pipeline, we synthesize over 100,000 variant models derived from 4,000 real-world models and execute them across five different enterprise-grade accelerators. Our findings suggest that newer AI platforms from Mac and Huawei support at least 17\% fewer operators than NVIDIA. These platforms also exhibit a higher rate of output discrepancies (exceeding 5\%), which stem from differences in operator implementations, handling of exceptional numerical values, and instruction scheduling. They are also more susceptible to failures during model compilation-based acceleration, and in some cases, the compiled models produce outputs that differ noticeably from those generated using the standard execution mode. In addition, we identify 7 implementation flaws in PyTorch and 40 platform-specific issues across vendors. These results underscore the challenges of achieving consistent machine learning behavior in an increasingly diverse hardware ecosystem.

</details>


### [486] [Machine learning-based cloud resource allocation algorithms: a comprehensive comparative review](https://arxiv.org/abs/2511.11603)
*Deep Bodra,Sushil Khairnar*

Main category: cs.DC

TL;DR: 本论文比较了人工智能和机器学习算法在云资源分配中的性能，发现混合方法优于单一方法，特别是在边缘计算环境中。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以满足云资源分配对多目标优化的需求。

Method: 本研究系统评估了10种算法，涵盖深度强化学习、神经网络、传统机器学习增强方法和多智能体系统。

Result: 与传统方法相比，所评估的算法在缩短任务完成时间、优化成本和提高能源效率方面表现出显著的性能提升。混合架构的性能优于单一方法。

Conclusion: 混合人工智能和机器学习技术在云资源分配中表现出最佳性能，尤其是在边缘计算场景下，这为开发下一代资源分配策略提供了关键见解。

Abstract: Cloud resource allocation has emerged as a major challenge in modern computing environments, with organizations struggling to manage complex, dynamic workloads while optimizing performance and cost efficiency. Traditional heuristic approaches prove inadequate for handling the multi-objective optimization demands of existing cloud infrastructures. This paper presents a comparative analysis of state-of-the-art artificial intelligence and machine learning algorithms for resource allocation. We systematically evaluate 10 algorithms across four categories: Deep Reinforcement Learning approaches, Neural Network architectures, Traditional Machine Learning enhanced methods, and Multi-Agent systems. Analysis of published results demonstrates significant performance improvements across multiple metrics including makespan reduction, cost optimization, and energy efficiency gains compared to traditional methods. The findings reveal that hybrid architectures combining multiple artificial intelligence and machine learning techniques consistently outperform single-method approaches, with edge computing environments showing the highest deployment readiness. Our analysis provides critical insights for both academic researchers and industry practitioners seeking to implement next-generation cloud resource allocation strategies in increasingly complex and dynamic computing environments.

</details>


### [487] [PACE Solver Description: twin_width_fmi](https://arxiv.org/abs/2511.11605)
*David Balaban,Adrian Miclăuş*

Main category: cs.DC

TL;DR: 该论文提出了用于 PACE 2025 竞赛的新启发式算法 hedom5 来解决最小支配集问题。


<details>
  <summary>Details</summary>
Motivation: 在 PACE 2025 竞赛的启发式方法赛道上，为最小支配集问题提供一个高性能的求解器。

Method: 论文首先实现了一个基线贪心算法 greedy-ln。然后，在此基础上进行模拟退火局部搜索。最终提交的 hedom5 算法结合了迭代贪心、图的压缩表示 (CSR)、图简化（处理孤立点和叶子邻居）、基于优先队列的延迟增益贪心阶段、反向删除剪枝以及预算为1的交换局部改进，最后进行安全修补以确保完全支配。

Result: hedom5 在 PACE 2025 竞赛的启发式方法赛道上取得了最佳性能。

Conclusion: hedom5 算法通过结合多种技术（如图简化、延迟增益贪心、反向剪枝和局部搜索），能够有效地解决最小支配集问题，并在竞赛中表现出色。

Abstract: In this paper we present \texttt{twin\_width\_fmi}'s solver for the heuristic track of PACE's 2025 competition on Minimum Dominating Set.
  As a baseline, we implement \texttt{greedy-ln}, a standard greedy dominating-set heuristic that repeatedly selects the vertex that newly dominates the largest number of currently undominated vertices. We then use this greedy solution as the starting point for a simulated annealing local search: we attempt vertex removals and exchanges and accept worsening moves with decaying probability, in order to escape local minima while preserving domination.
  Our best-performing component, which we ultimately submitted, is \texttt{hedom5}. The design of \texttt{hedom5} is inspired by recent iterative-greedy style domination heuristics~\cite{IterativeGreedy22} that alternate between constructive steps, pruning, and focused repair rather than relying on a single pass. In \texttt{hedom5}, the input graph is first stored in a compact CSR structure and simplified using fast reductions such as forcing neighbors of leaves and handling isolates. We then run a lazy gain-based greedy stage using a priority queue: each candidate vertex is scored by how many currently undominated vertices its closed neighborhood would newly dominate, and scores are only recomputed when necessary. After this constructive phase, we perform an aggressive backward pruning pass that iterates over the chosen dominators in reverse insertion order and deletes any vertex whose closed neighborhood is still fully dominated by the remaining set. Finally, we run a budgeted 1-swap local improvement step that attempts to replace a dominator by an alternative vertex that covers all of its uniquely covered vertices, thereby reducing the size of the dominating set. A brief safety patch at the end guarantees full domination.

</details>


### [488] [Why Should the Server Do It All?: A Scalable, Versatile, and Model-Agnostic Framework for Server-Light DNN Inference over Massively Distributed Clients via Training-Free Intermediate Feature Compression](https://arxiv.org/abs/2511.11608)
*Mingyu Sung,Suhwan Im,Daeho Bang,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.DC

TL;DR: SLICER通过压缩中间特征来减少边缘-云模型分割中的通信和服务器负载，从而提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的边缘-云模型分割方案（MP）由于静态分割点导致边缘计算资源利用不足，并将延迟和能耗集中在服务器端。这在自回归（AR）大语言模型（LLM）推理中尤为严重，因为逐令牌的前向传播会反复生成大量的中间特征（IFs）。

Method: SLICER是一种无需重新训练、与模型结构无关的框架，它通过以下方法压缩IFs：(i) 不对称Top-K过滤（ATKF）稀疏化低幅度激活值；(ii) 幅度分裂（MS）将剩余的非零值分组为等基数块；(iii) 自适应比特量化（ABQ）在失真预算内为每块选择比特宽度。

Result: SLICER在标准的视觉和LLM工作负载（如ImageNet/COCO；HellaSwag、PIQA、ARC-E/C、GSM8K、HumanEval）上，将上行链路传输量减少了高达10倍，将服务器GPU时间减少了高达4.4倍，同时将任务质量损失控制在基线水平约0-3个百分点以内。在多设备设置和AR LLM中，SLICER通过将有意义的计算转移到边缘，并降低每令牌比特数和每令牌服务器时间，实现了可扩展性，并稳定了每步通信量。

Conclusion: SLICER作为一个编解码器，可以在无需重新训练或修改模型结构的情况下，集成到现有的模型中，为实现可扩展、低延迟的分布式推理提供了一种即插即用的解决方案。

Abstract: Modern DNNs often rely on edge-cloud model partitioning (MP), but widely used schemes fix shallow, static split points that underutilize edge compute and concentrate latency and energy on the server. The problem is exacerbated in autoregressive (AR) LLM inference, where per-token forward passes repeatedly generate bulky intermediate features (IFs). We introduce SLICER, a retraining-free, architecture-agnostic framework that compresses IFs to reduce both communication and server load in split computing. SLICER combines (i) asymmetric top-K filtering (ATKF) to sparsify low-magnitude activations, (ii) magnitude-splitting (MS) to group the remaining non-zeros into equal-cardinality blocks, and (iii) adaptive bit quantization (ABQ) that selects per-block bitwidths under a distortion budget. Across standard vision and LLM workloads (e.g., ImageNet/COCO; HellaSwag, PIQA, ARC-E/C, GSM8K, HumanEval), SLICER reduces uplink volume by up to 10x and server GPU time by up to 4.4x, while keeping task quality within ~0-3 pp of baseline. In multi-device settings and AR LLMs, SLICER scales by shifting meaningful compute to the edge and lowering bits-per-token and server time per token, stabilizing per-step traffic. The codec attaches to off-the-shelf models without retraining or architectural changes, offering a plug-and-play path to scalable, low-latency distributed inference. Code is provided in the supplementary material.

</details>


### [489] [Evaluating Large Language Models for Workload Mapping and Scheduling in Heterogeneous HPC Systems](https://arxiv.org/abs/2511.11612)
*Aasish Kumar Sharma,Julian Kunkel*

Main category: cs.DC

TL;DR: LLM在解决计算优化问题方面表现出潜力，但仍需改进精确性和约束执行能力。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在处理基于约束的优化问题（特别是HPC工作负载映射和调度）方面的能力。

Method: 使用包含系统节点、任务需求和调度约束的自然语言描述，评估了21个LLM在HPC工作负载映射和调度问题上的表现，并与手动计算的最优解进行了比较。

Result: 3个LLM完美复现了最优解，12个LLM的结果接近最优解，6个LLM则出现了错误。所有模型都生成了可行的任务映射，但只有约一半的模型严格遵守了所有约束。19个模型生成了部分可执行的验证代码，18个模型提供了清晰的推理过程。

Conclusion: LLM在组合优化方面展现出强大的潜力，能够直接从自然语言中重建最优调度，但大多数模型在精确计时、数据传输计算和依赖关系强制执行方面仍存在挑战。LLM更适合作为可解释的辅助工具，而非独立的优化求解器。

Abstract: Large language models (LLMs) are increasingly explored for their reasoning capabilities, yet their ability to perform structured, constraint-based optimization from natural language remains insufficiently understood. This study evaluates twenty-one publicly available LLMs on a representative heterogeneous high-performance computing (HPC) workload mapping and scheduling problem. Each model received the same textual description of system nodes, task requirements, and scheduling constraints, and was required to assign tasks to nodes, compute the total makespan, and explain its reasoning. A manually derived analytical optimum of nine hours and twenty seconds served as the ground truth reference. Three models exactly reproduced the analytical optimum while satisfying all constraints, twelve achieved near-optimal results within two minutes of the reference, and six produced suboptimal schedules with arithmetic or dependency errors. All models generated feasible task-to-node mappings, though only about half maintained strict constraint adherence. Nineteen models produced partially executable verification code, and eighteen provided coherent step-by-step reasoning, demonstrating strong interpretability even when logical errors occurred. Overall, the results define the current capability boundary of LLM reasoning in combinatorial optimization: leading models can reconstruct optimal schedules directly from natural language, but most still struggle with precise timing, data transfer arithmetic, and dependency enforcement. These findings highlight the potential of LLMs as explainable co-pilots for optimization and decision-support tasks rather than autonomous solvers.

</details>


### [490] [Beyond the GPU: The Strategic Role of FPGAs in the Next Wave of AI](https://arxiv.org/abs/2511.11614)
*Arturo Urías Jiménez*

Main category: cs.DC

TL;DR: FPGAs are a flexible and efficient alternative to GPUs for AI acceleration, offering lower latency, energy efficiency, and customization, especially for edge computing and specialized data center tasks.


<details>
  <summary>Details</summary>
Motivation: The limitations of fixed GPU architectures for AI acceleration, particularly concerning latency, energy efficiency, and hardware control, necessitate alternative solutions.

Method: FPGAs enable direct mapping of AI algorithms into device logic, allowing for parallel pipelines, deterministic timing, and reduced power consumption. They offer reconfigurability, integration with embedded processors, and support for partial reconfiguration and compilation flows from AI frameworks for hardware-algorithm co-design.

Result: FPGAs provide a strategic option for AI workloads demanding predictable performance and deep customization. They reduce latency and bandwidth requirements, improve privacy by enabling near-sensor inference, and offload specialized tasks from data centers.

Conclusion: FPGAs represent a powerful and adaptable platform for AI acceleration, overcoming the limitations of traditional hardware and paving the way for more efficient, customized, and high-performance AI deployments, especially at the edge.

Abstract: AI acceleration has been dominated by GPUs, but the growing need for lower latency, energy efficiency, and fine-grained hardware control exposes the limits of fixed architectures. In this context, Field-Programmable Gate Arrays (FPGAs) emerge as a reconfigurable platform that allows mapping AI algorithms directly into device logic. Their ability to implement parallel pipelines for convolutions, attention mechanisms, and post-processing with deterministic timing and reduced power consumption makes them a strategic option for workloads that demand predictable performance and deep customization.
  Unlike CPUs and GPUs, whose architecture is immutable, an FPGA can be reconfigured in the field to adapt its physical structure to a specific model, integrate as a SoC with embedded processors, and run inference near the sensor without sending raw data to the cloud. This reduces latency and required bandwidth, improves privacy, and frees GPUs from specialized tasks in data centers. Partial reconfiguration and compilation flows from AI frameworks are shortening the path from prototype to deployment, enabling hardware--algorithm co-design.

</details>


### [491] [AnchorTP: Resilient LLM Inference with State-Preserving Elastic Tensor Parallelism](https://arxiv.org/abs/2511.11617)
*Wendong Xu,Chujie Chen,He Xiao,Kuan Li,Jing Xiong,Chen Zhang,Wenyong Zhou,Chaofan Tao,Yang Bai,Bei Yu,Ngai Wong*

Main category: cs.DC

TL;DR: AnchorTP是一个弹性张量并行框架，通过在多GPU环境中保持模型状态并最小化数据移动来实现LLM推理服务的快速恢复，显著减少了故障后的停机时间和恢复时间。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）推理服务需要高可用性和低延迟，但多GPU张量并行（TP）容易因单GPU故障而中断服务。

Method: AnchorTP实现了弹性张量并行（ETP），支持不等宽分区、任意数量的GPU以及混合专家（MoE）模型。它通过一个独立的守护进程将模型参数和KV缓存保留在GPU内存中。为了减少停机时间，AnchorTP采用基于连续最小迁移（CMM）算法的带宽感知规划器来最小化重载字节，并结合流水线化点对点传输与重载的执行调度器。

Result: AnchorTP在典型故障场景下，与重启和重新加载相比，将首次成功时间（TFS）缩短高达11倍，峰值恢复时间（TTP）缩短高达59%。

Conclusion: AnchorTP通过其弹性张量并行、状态保持机制和优化的恢复策略，有效解决了多GPU LLM推理中的单点故障问题，实现了快速、低损耗的服务恢复，而无需改变服务接口。

Abstract: Large Language Model (LLM) inference services demand exceptionally high availability and low latency, yet multi-GPU Tensor Parallelism (TP) makes them vulnerable to single-GPU failures. We present AnchorTP, a state-preserving elastic TP framework for fast recovery. It (i) enables Elastic Tensor Parallelism (ETP) with unequal-width partitioning over any number of GPUs and compatibility with Mixture-of-Experts (MoE), and (ii) preserves model parameters and KV caches in GPU memory via a daemon decoupled from the inference process. To minimize downtime, we propose a bandwidth-aware planner based on a Continuous Minimal Migration (CMM) algorithm that minimizes reload bytes under a byte-cost dominance assumption, and an execution scheduler that pipelines P2P transfers with reloads. These components jointly restore service quickly with minimal data movement and without changing service interfaces. In typical failure scenarios, AnchorTP reduces Time to First Success (TFS) by up to 11x and Time to Peak (TTP) by up to 59% versus restart-and-reload.

</details>


### [492] [DIAP: A Decentralized Agent Identity Protocol with Zero-Knowledge Proofs and a Hybrid P2P Stack](https://arxiv.org/abs/2511.11619)
*Yuanjie Liu,Wenpeng Xing,Ye Zhou,Gaowei Chang,Changting Lin,Meng Han*

Main category: cs.DC

TL;DR: DIAP是一个用于自主代理的去中心化通信框架，使用IPFS/IPNS和零知识证明实现持久、可验证和无需信任的互操作性。


<details>
  <summary>Details</summary>
Motivation: 当前去中心化通信协议在可验证性和隐私保护方面存在挑战，现有系统依赖中心化中介或缺乏去中心化身份解析机制。

Method: 提出DIAP框架，将代理身份绑定到IPFS/IPNS标识符，利用零知识证明进行所有权验证。提供Rust SDK，集成Noir、DID-Key、IPFS和Libp2p GossipSub/Iroh。采用零依赖的ZKP部署模型。

Result: DIAP提供了一种无需依赖外部工具链即可实现即时、可验证和隐私保护的身份证明的方法。

Conclusion: DIAP为下一代自主代理生态系统和代理间经济奠定了实际、高性能的基础。

Abstract: The absence of a fully decentralized, verifiable, and privacy-preserving communication protocol for autonomous agents remains a core challenge in decentralized computing. Existing systems often rely on centralized intermediaries, which reintroduce trust bottlenecks, or lack decentralized identity-resolution mechanisms, limiting persistence and cross-network interoperability.
  We propose the Decentralized Interstellar Agent Protocol (DIAP), a novel framework for agent identity and communication that enables persistent, verifiable, and trustless interoperability in fully decentralized environments. DIAP binds an agent's identity to an immutable IPFS or IPNS content identifier and uses zero-knowledge proofs (ZKP) to dynamically and statelessly prove ownership, removing the need for record updates.
  We present a Rust SDK that integrates Noir (for zero-knowledge proofs), DID-Key, IPFS, and a hybrid peer-to-peer stack combining Libp2p GossipSub for discovery and Iroh for high-performance, QUIC based data exchange. DIAP introduces a zero-dependency ZKP deployment model through a universal proof manager and compile-time build script that embeds a precompiled Noir circuit, eliminating the need for external ZKP toolchains. This enables instant, verifiable, and privacy-preserving identity proofs.
  This work establishes a practical, high-performance foundation for next-generation autonomous agent ecosystems and agent-to-agent (A to A) economies.

</details>


### [493] [AIvailable: A Software-Defined Architecture for LLM-as-a-Service on Heterogeneous and Legacy GPUs](https://arxiv.org/abs/2511.11621)
*Pedro Antunes,Ana Rita Ortigoso,Gabriel Vieira,Daniel Fuentes,Luís Frazão,Nuno Costa,António Pereira*

Main category: cs.DC

TL;DR: AIvailable是一个低成本、高可用性的LLMaaS平台，通过软件定义的方法，在异构和遗留的GPU节点（包括NVIDIA和AMD）上运行LLM，最大限度地利用每个节点的显存。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）推理框架通常假设硬件资源丰富且同质，这在学术界或资源受限的环境中并不现实。因此，需要一个可扩展、高性能且经济高效的LLM推理解决方案。

Method: AIvailable采用软件定义的方法，实现了跨异构GPU节点（NVIDIA和AMD）的LLM推理。它包括客户端接口、服务前端、SDAI控制器和服务后端四个组件，能够进行动态的、显存感知的模型分配和重新分配，实现全GPU加速推理，无CPU回退。

Result: 该平台能够完全利用节点的显存，通过统一的客户端接口实现对所有部署LLM的无缝交互。它通过抽象GPU细节和动态资源管理，实现了资源的有效利用以及对故障或工作负载波动的弹性。

Conclusion: AIvailable通过重新利用遗留GPU，支持多样化的开源LLM，旨在为学术实验室、私营公司和资源受限的组织提供低成本、高可用的LLMaaS服务，从而推动生成式AI的普及。

Abstract: The rise of Large Language Models (LLM) has increased the need for scalable, high-performance inference systems, yet most existing frameworks assume homogeneous, resource-rich hardware, often unrealistic in academic, or resource-constrained settings. We introduce AIvailable, a low-cost, highly available LLM-as-a-Service (LLMaaS) platform, that uses a software-defined approach for running LLMs across heterogeneous and legacy GPU nodes, including NVIDIA and AMD devices, with a focus on fully utilizing each node's VRAM. AIvailable operates as a fully GPU-accelerated inference without CPU fallbacks, featuring a unified client interface that allows seamless interaction with all deployed LLMs through a single logical unit. The architecture comprises four main components: the Client Interface for user access, the Service Frontend for secure request routing and load balancing, the SDAI Controller for orchestration, deployment, and monitoring, and the Service Backend of heterogeneous GPU nodes executing workloads. By abstracting GPU-specific details and providing dynamic, VRAM-aware allocation and reallocation of models, AIvailable ensures efficient use of resources and resilience against failures or workload fluctuations. Targeting academic labs, private companies, and other constrained organizations, it supports diverse open LLMs helping democratize generative AI through the repurposing of legacy GPUs.

</details>


### [494] [Characterizing and Understanding Energy Footprint and Efficiency of Small Language Model on Edges](https://arxiv.org/abs/2511.11624)
*Md Romyull Islam,Bobin Deng,Nobel Dhar,Tu N. Nguyen,Selena He,Yong Shi,Kun Suo*

Main category: cs.DC

TL;DR: 该研究评估了 Llama 3.2、Phi-3 Mini、TinyLlama 和 Gemma 2 等小型语言模型 (SLM) 在 Raspberry Pi 5、Jetson Nano 和 Jetson Orin Nano 上的能效。结果表明，Jetson Orin Nano 的 GPU 加速在能效方面表现最佳。Llama 3.2 在准确性和能效之间取得了最佳平衡，而 TinyLlama 则适合低功耗环境，但准确性有所降低。Phi-3 Mini 尽管准确性高，但能耗最高。GPU 加速、内存带宽和模型架构是影响推理能效的关键因素。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署小型语言模型 (SLM) 具有低延迟和网络连接独立性等优势，但受限于计算资源和能耗预算。本研究旨在评估不同 SLM 在不同边缘设备上的能效表现，为在能源受限环境中进行权衡提供实践指导。

Method: 在 Raspberry Pi 5、Jetson Nano 和 Jetson Orin Nano（CPU 和 GPU 配置）上评估了五种代表性 SLM（Llama 3.2、Phi-3 Mini、TinyLlama 和 Gemma 2）的能效。

Result: Jetson Orin Nano 搭配 GPU 加速实现了最高的能效比。Llama 3.2 在准确性和能效之间取得了最佳平衡。TinyLlama 适合低功耗场景，但准确性较低。Phi-3 Mini 能耗最高，但准确性也高。GPU 加速、内存带宽和模型架构是影响推理能效的关键因素。

Conclusion: GPU 加速、内存带宽和模型架构对 SLM 的推理能效至关重要。Llama 3.2 在准确性和能效之间提供了良好的折衷，而 TinyLlama 则适用于低功耗场景。本研究为在能源受限环境中进行 AI、智能系统和移动 ad-hoc 平台的部署提供了实际指导，指导了优化推理能效的见解。

Abstract: Cloud-based large language models (LLMs) and their variants have significantly influenced real-world applications. Deploying smaller models (i.e., small language models (SLMs)) on edge devices offers additional advantages, such as reduced latency and independence from network connectivity. However, edge devices' limited computing resources and constrained energy budgets challenge efficient deployment. This study evaluates the power efficiency of five representative SLMs - Llama 3.2, Phi-3 Mini, TinyLlama, and Gemma 2 on Raspberry Pi 5, Jetson Nano, and Jetson Orin Nano (CPU and GPU configurations). Results show that Jetson Orin Nano with GPU acceleration achieves the highest energy-to-performance ratio, significantly outperforming CPU-based setups. Llama 3.2 provides the best balance of accuracy and power efficiency, while TinyLlama is well-suited for low-power environments at the cost of reduced accuracy. In contrast, Phi-3 Mini consumes the most energy despite its high accuracy. In addition, GPU acceleration, memory bandwidth, and model architecture are key in optimizing inference energy efficiency. Our empirical analysis offers practical insights for AI, smart systems, and mobile ad-hoc platforms to leverage tradeoffs from accuracy, inference latency, and power efficiency in energy-constrained environments.

</details>


### [495] [Mixture-of-Schedulers: An Adaptive Scheduling Agent as a Learned Router for Expert Policies](https://arxiv.org/abs/2511.11628)
*Xinbo Wang,Shian Jia,Ziyang Huang,Jing Cao,Mingli Song*

Main category: cs.DC

TL;DR: 操作系统调度器通过动态选择最佳策略组合来适应不同工作负载，以提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的操作系统调度器采用单一、静态的策略，难以在多样化和动态化的工作负载下实现最佳性能，导致公平性、吞吐量和延迟方面出现妥协。

Method: 提出了一种自适应调度代理（ASA）框架，通过机器学习模型识别工作负载模式，并结合加权概率投票和硬件特定的映射表，在运行时动态选择最合适的调度策略。

Result: 在以用户体验指标为重点的新型基准测试中，ASA在86.4%的场景中优于默认的Linux调度器（EEVDF），并且在78.6%的场景中选择的调度器排名前三。

Conclusion: ASA方法为实现更智能、自适应和响应迅速的操作系统调度器提供了一条可行的路径。

Abstract: Modern operating system schedulers employ a single, static policy, which struggles to deliver optimal performance across the diverse and dynamic workloads of contemporary systems. This "one-policy-fits-all" approach leads to significant compromises in fairness, throughput, and latency, particularly with the rise of heterogeneous hardware and varied application architectures.
  This paper proposes a new paradigm: dynamically selecting the optimal policy from a portfolio of specialized schedulers rather than designing a single, monolithic one. We present the Adaptive Scheduling Agent (ASA), a lightweight framework that intelligently matches workloads to the most suitable "expert" scheduling policy at runtime. ASA's core is a novel, low-overhead offline/online approach. First, an offline process trains a universal, hardware-agnostic machine learning model to recognize abstract workload patterns from system behaviors. Second, at runtime, ASA continually processes the model's predictions using a time-weighted probability voting algorithm to identify the workload, then makes a scheduling decision by consulting a pre-configured, machine-specific mapping table to switch to the optimal scheduler via Linux's sched_ext framework. This decoupled architecture allows ASA to adapt to new hardware platforms rapidly without expensive retraining of the core recognition model.
  Our evaluation, based on a novel benchmark focused on user-experience metrics, demonstrates that ASA consistently outperforms the default Linux scheduler (EEVDF), achieving superior results in 86.4% of test scenarios. Furthermore, ASA's selections are near-optimal, ranking among the top three schedulers in 78.6% of all scenarios. This validates our approach as a practical path toward more intelligent, adaptive, and responsive operating system schedulers.

</details>


### [496] [Exploring Parallelism in FPGA-Based Accelerators for Machine Learning Applications](https://arxiv.org/abs/2511.11640)
*Sed Centeno,Christopher Sprague,Arnab A Purkayastha,Ray Simar,Neeraj Magotra*

Main category: cs.DC

TL;DR: Speculative backpropagation accelerates neural network training by overlapping forward and backward passes using speculative weight updates. Implemented on MNIST with OpenMP, it achieves up to 24% speedup on CPU and shows potential for FPGA hardware acceleration.


<details>
  <summary>Details</summary>
Motivation: To accelerate neural network training by overlapping forward and backward passes using speculative backpropagation.

Method: Implemented speculative backpropagation on MNIST using OpenMP for multi-threading, enabling simultaneous forward and backward steps. Evaluated on CPU and planned for FPGA synthesis.

Result: Achieved a maximum speedup of 24% in execution time with a threshold of 0.25, while maintaining accuracy within 3-4% of the baseline. Individual step execution showed a maximum speedup of 35%.

Conclusion: Speculative backpropagation effectively speeds up training by overlapping passes, with significant execution time improvements demonstrated on CPU and promising potential for hardware acceleration on FPGAs.

Abstract: Speculative backpropagation has emerged as a promising technique to accelerate the training of neural networks by overlapping the forward and backward passes. Leveraging speculative weight updates when error gradients fall within a specific threshold reduces training time without substantially compromising accuracy. In this work, we implement speculative backpropagation on the MNIST dataset using OpenMP as the parallel programming platform. OpenMP's multi-threading capabilities enable simultaneous execution of forward and speculative backpropagation steps, significantly improving training speed. The application is planned for synthesis on a state-of-the-art FPGA to demonstrate its potential for hardware acceleration. Our CPU-based experimental results demonstrate that speculative backpropagation achieves a maximum speedup of 24% in execution time when using a threshold of 0.25, and accuracy remaining within 3-4% of the baseline across various epochs. Additionally, when comparing individual step execution time, speculative backpropagation yields a maximum speedup of 35% over the baseline, demonstrating the effectiveness of overlapping forward and backward passes.

</details>


### [497] [HeteroSTA: A CPU-GPU Heterogeneous Static Timing Analysis Engine with Holistic Industrial Design Support](https://arxiv.org/abs/2511.11660)
*Zizheng Guo,Haichuan Liu,Xizhe Shi,Shenglu Hua,Zuodong Zhang,Chunyuan Zhao,Runsheng Wang,Yibo Lin*

Main category: cs.DC

TL;DR: HeteroSTA是一个CPU-GPU异构时序分析引擎，支持多种精度-速度选择的延迟计算模型、行业标准格式（包括.sdc约束）以及端到端的图和路径时序查询GPU加速，提供零开销的API。


<details>
  <summary>Details</summary>
Motivation: 介绍HeteroSTA，首个CPU-GPU异构时序分析引擎。

Method: HeteroSTA支持一套延迟计算模型，提供精度-速度选择；支持.sdc约束；对图和路径时序查询进行端到端GPU加速，通过零开销的API暴露。

Result: HeteroSTA在作为独立工具、DREAMPlace 4.0集成和全局路由集成等用例中，展示了显著的运行时加速和可比的质量。

Conclusion: HeteroSTA是一个高效的CPU-GPU异构时序分析引擎，具有多种功能和广泛的应用潜力。

Abstract: We introduce in this paper, HeteroSTA, the first CPU-GPU heterogeneous timing analysis engine that efficiently supports: (1) a set of delay calculation models providing versatile accuracy-speed choices without relying on an external golden tool, (2) robust support for industry formats, including especially the .sdc constraints containing all common timing exceptions, clock domains, and case analysis modes, and (3) end-to-end GPU-acceleration for both graph-based and path-based timing queries, all exposed as a zero-overhead flattened heterogeneous application programming interface (API). HeteroSTA is publicly available with both a standalone binary executable and an embeddable shared library targeting ubiquitous academic and industry applications. Example use cases as a standalone tool, a timing-driven DREAMPlace 4.0 integration, and a timing-driven global routing integration have all demonstrated remarkable runtime speed-up and comparable quality.

</details>


### [498] [Range Asymmetric Numeral Systems-Based Lightweight Intermediate Feature Compression for Split Computing of Deep Neural Networks](https://arxiv.org/abs/2511.11664)
*Mingyu Sung,Suhwan Im,Vikas Palakonda,Jae-Mo Kang*

Main category: cs.DC

TL;DR: 本研究提出一种基于rANS编码、非对称整数量化和稀疏张量表示的轻量级压缩框架，用于解决分割计算中的通信瓶颈，实现低延迟、高压缩率，并保持模型精度。


<details>
  <summary>Details</summary>
Motivation: 分割计算在边缘设备和云服务器之间分配深度神经网络推理，但中间特征传输面临通信瓶颈。

Method: 提出一种结合非对称整数量化和稀疏张量表示的轻量级压缩框架，利用rANS编码技术。

Result: 该框架在ResNet、VGG16等多种模型和CIFAR100、ImageNet等基准上实现了高压缩率，同时保持了接近基线的准确率。在自然语言处理任务（Llama2 7B/13B）上也验证了其有效性，并且实现了低于1毫秒的编码/解码延迟。

Conclusion: 提出的框架有效解决了分割计算中的通信瓶颈问题，在不损害模型性能的情况下，显著降低了传输开销，具有广泛的应用前景。

Abstract: Split computing distributes deep neural network inference between resource-constrained edge devices and cloud servers but faces significant communication bottlenecks when transmitting intermediate features. To this end, in this paper, we propose a novel lightweight compression framework that leverages Range Asymmetric Numeral Systems (rANS) encoding with asymmetric integer quantization and sparse tensor representation to reduce transmission overhead dramatically. Specifically, our approach combines asymmetric integer quantization with a sparse representation technique, eliminating the need for complex probability modeling or network modifications. The key contributions include: (1) a distribution-agnostic compression pipeline that exploits inherent tensor sparsity to achieve bandwidth reduction with minimal computational overhead; (2) an approximate theoretical model that optimizes tensor reshaping dimensions to maximize compression efficiency; and (3) a GPU-accelerated implementation with sub-millisecond encoding/decoding latency. Extensive evaluations across diverse neural architectures (ResNet, VGG16, MobileNetV2, SwinT, DenseNet121, EfficientNetB0) demonstrate that the proposed framework consistently maintains near-baseline accuracy across CIFAR100 and ImageNet benchmarks. Moreover, we validated the framework's effectiveness on advanced natural language processing tasks by employing Llama2 7B and 13B on standard benchmarks such as MMLU, HellaSwag, ARC, PIQA, Winogrande, BoolQ, and OpenBookQA, demonstrating its broad applicability beyond computer vision. Furthermore, this method addresses a fundamental bottleneck in deploying sophisticated artificial intelligence systems in bandwidth-constrained environments without compromising model performance.

</details>


### [499] [OSGym: Super-Scalable Distributed Data Engine for Generalizable Computer Agents](https://arxiv.org/abs/2511.11672)
*Zengyi Qin,Jinyuan Chen,Yunze Man,Shengcao Cao,Ziqi Pang,Zhuoyuan Wang,Xin Sun,Gen Lin,Han Fang,Ling Zhu,Zixin Xie,Zibu Wei,Tianshu Ran,Haoran Geng,Xander Wu,Zachary Bright,Qizhen Sun,Rui Wang,Yuyang Cai,Song Wang,Jiace Zhao,Han Cao,Yeyang Zhou,Tianrui Liu,Ray Pan,Chongye Yang,Xiang Ren,Bo Zhang,Yutong Ban,Jitendra Malik,Brian Anthony,Pieter Abbeel*

Main category: cs.DC

TL;DR: OSGym是一个可扩展的分布式数据引擎，用于在各种计算机相关任务中训练智能体。它能够以较低的成本扩展到超过一千个操作系统副本，并支持多种任务和训练算法，同时保持高效运行。


<details>
  <summary>Details</summary>
Motivation: 训练智能体需要大量的计算资源和多样化的环境，现有的解决方案在可扩展性、通用性和成本方面存在挑战。

Method: OSGym通过并行化运行大量操作系统副本（超过一千个）来提供动态运行时环境，支持广泛的任务（如工具使用、软件工程等）和灵活的模型训练算法，并利用经济实惠的按需计算资源。

Result: OSGym能够高效地生成多轮对话轨迹，支持全面的数据收集、监督微调和强化学习流程。使用OSGym训练的模型优于现有最先进的模型。

Conclusion: OSGym在可扩展性、通用性和经济性方面取得了显著进展，有望推动未来智能体研究的发展。

Abstract: We introduce OSGym, a super-scalable distributed data engine for training agents across diverse computer-related tasks. OSGym efficiently scales to over a thousand operating system (OS) replicas at an academia-affordable cost, serving as dynamic runtime environments for intelligent agents. It offers three key advantages. (1) Scalability: Despite the intensive resource requirements of running multiple OS replicas, OSGym parallelizes over a thousand instances while maintaining operational efficiency under constrained resources, generating up to 1420 multi-turn trajectories per minute. (2) Generality and Customizability: OSGym supports a broad spectrum of tasks that run on OS platforms, including tool use, browser interactions, software engineering, and office applications, with flexible support for diverse model training algorithms. (3) Economic Viability: OSGym operates at only 0.2-0.3 USD per day per OS replica using accessible on-demand compute providers. It is fully open-source and freely available for both research and commercial use. Experiments show that OSGym enables comprehensive data collection, supervised fine-tuning, and reinforcement learning pipelines for computer agents. Models trained with OSGym outperform state-of-the-art baselines, demonstrating its potential to advance scalability and universality in future agent research.

</details>


### [500] [A Structure-Agnostic Co-Tuning Framework for LLMs and SLMs in Cloud-Edge Systems](https://arxiv.org/abs/2511.11678)
*Yuze Liu,Yunhan Wang,Tiehua Zhang,Zhishu Shen,Cheng Peng,Libing Wu,Feng Xia,Jiong Jin*

Main category: cs.DC

TL;DR: 云边协同的语言模型训练框架Co-PLMs解决了云服务器带宽限制和用户数据隐私问题，通过异构模型协同学习提升了推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前云边协同的LLM应用面临带宽限制、隐私泄露和模型异构性带来的性能提升挑战。

Method: 提出Co-PLMs框架，采用蒸馏代理模型（DPMs）作为桥梁，实现大型语言模型（LLMs）和小型语言模型（SLMs）在结构无关的情况下进行知识迁移和协同训练。

Result: Co-PLMs框架在Rouge-L和EM指标上分别取得了平均5.38%和4.88%的提升，优于现有最先进的方法。

Conclusion: Co-PLMs框架通过协同训练和知识迁移，有效解决了云边协同LLM应用中的性能和隐私问题，并在实验中取得了显著的效果。

Abstract: The surge in intelligent applications driven by large language models (LLMs) has made it increasingly difficult for bandwidth-limited cloud servers to process extensive LLM workloads in real time without compromising user data privacy. To solve these problems, recent research has focused on constructing cloud-edge consortia that integrate server-based LLM with small language models (SLMs) on mobile edge devices. Furthermore, designing collaborative training mechanisms within such consortia to enhance inference performance has emerged as a promising research direction. However, the cross-domain deployment of SLMs, coupled with structural heterogeneity in SLMs architectures, poses significant challenges to enhancing model performance. To this end, we propose Co-PLMs, a novel co-tuning framework for collaborative training of large and small language models, which integrates the process of structure-agnostic mutual learning to realize knowledge exchange between the heterogeneous language models. This framework employs distilled proxy models (DPMs) as bridges to enable collaborative training between the heterogeneous server-based LLM and on-device SLMs, while preserving the domain-specific insights of each device. The experimental results show that Co-PLMs outperform state-of-the-art methods, achieving average increases of 5.38% in Rouge-L and 4.88% in EM.

</details>


### [501] [ECCENTRIC: Edge-Cloud Collaboration Framework for Distributed Inference Using Knowledge Adaptation](https://arxiv.org/abs/2511.11719)
*Mohammad Mahdi Kamani,Zhongwei Cheng,Lin Chen*

Main category: cs.DC

TL;DR: Eccentric框架是一种新颖的边缘-云端推理系统压缩方法，通过学习不同权衡的模型，在降低计算和通信成本的同时，最大化模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着边缘AI的广泛应用，云端推理的计算和通信成本随着边缘设备数量的增加而急剧上升，存在计算、通信和性能之间的权衡。因此，需要一种方法来解决这一权衡问题。

Method: 提出了一种名为Eccentric的新颖框架，该框架通过学习不同权衡的模型来适应知识从边缘模型到云端模型，以减少推理过程中的计算和通信成本。

Result: 在分类和目标检测任务上的实证研究证明了该框架的有效性。

Conclusion: Eccentric框架可以被视为一种新的压缩方法，适用于边缘-云端推理系统，能够同时减少计算和通信成本。

Abstract: The massive growth in the utilization of edge AI has made the applications of machine learning models ubiquitous in different domains. Despite the computation and communication efficiency of these systems, due to limited computation resources on edge devices, relying on more computationally rich systems on the cloud side is inevitable in most cases. Cloud inference systems can achieve the best performance while the computation and communication cost is dramatically increasing by the expansion of a number of edge devices relying on these systems. Hence, there is a trade-off between the computation, communication, and performance of these systems. In this paper, we propose a novel framework, dubbed as Eccentric that learns models with different levels of trade-offs between these conflicting objectives. This framework, based on an adaptation of knowledge from the edge model to the cloud one, reduces the computation and communication costs of the system during inference while achieving the best performance possible. The Eccentric framework can be considered as a new form of compression method suited for edge-cloud inference systems to reduce both computation and communication costs. Empirical studies on classification and object detection tasks corroborate the efficacy of this framework.

</details>


### [502] [A Meta-Heuristic Load Balancer for Cloud Computing Systems](https://arxiv.org/abs/2511.11721)
*Leszek Sliwko,Vladimir Getov*

Main category: cs.DC

TL;DR: 该论文提出了一种在不使节点过载的情况下分配云系统服务、保持系统稳定并最小化成本的策略。


<details>
  <summary>Details</summary>
Motivation: 在云系统中，如何在不使节点过载的情况下分配服务，同时保持系统稳定并最小化成本，这是一个关键问题。

Method: 提出一个云资源利用的抽象模型，该模型包括多种类型的资源，并考虑了服务迁移成本。开发了一个原型元启发式负载均衡器，并进行了实验。

Result: 实验结果表明，所提出的策略能够有效地在不使节点过载的情况下分配云系统服务，同时保持系统稳定并最小化成本。

Conclusion: 所提出的基于遗传算法的元启发式负载均衡器是一种有效的解决方案，可以解决云系统中的服务分配问题。

Abstract: This paper presents a strategy to allocate services on a Cloud system without overloading nodes and maintaining the system stability with minimum cost. We specify an abstract model of cloud resources utilization, including multiple types of resources as well as considerations for the service migration costs. A prototype meta-heuristic load balancer is demonstrated and experimental results are presented and discussed. We also propose a novel genetic algorithm, where population is seeded with the outputs of other meta-heuristic algorithms.

</details>


### [503] [Noise-Aware Optimization in Nominally Identical Manufacturing and Measuring Systems for High-Throughput Parallel Workflows](https://arxiv.org/abs/2511.11739)
*Christina Schenk,Miguel Hernández-del-Valle,Luis Calero-Lumbreras,Marcus Noack,Maciej Haranczyk*

Main category: cs.DC

TL;DR: 设备间的实验噪声差异会严重影响可重复性，尤其是在自动化、高通量系统中。本研究提出了一个噪声感知决策算法，该算法量化和建模设备特定的噪声分布，以自适应地管理变异性，通过使用分布分析和聚类来选择单设备或多设备贝叶斯优化策略，从而提高性能、可重复性和效率。


<details>
  <summary>Details</summary>
Motivation: 设备间的实验噪声差异会严重影响可重复性，尤其是在自动化、高通量系统中，在建筑3D打印等规模化应用中，噪声可能导致结构或经济失败。

Method: 使用分布分析和成对发散度量与聚类来选择单设备和鲁棒的多设备贝叶斯优化策略。

Result: 通过对三个相同的3D打印机进行实验研究，证明了该框架能够减少冗余、降低资源消耗并提高可靠性。

Conclusion: 该框架为可扩展的自动化实验平台中的精度和资源感知优化建立了范例。

Abstract: Device-to-device variability in experimental noise critically impacts reproducibility, especially in automated, high-throughput systems like additive manufacturing farms. While manageable in small labs, such variability can escalate into serious risks at larger scales, such as architectural 3D printing, where noise may cause structural or economic failures. This contribution presents a noise-aware decision-making algorithm that quantifies and models device-specific noise profiles to manage variability adaptively. It uses distributional analysis and pairwise divergence metrics with clustering to choose between single-device and robust multi-device Bayesian optimization strategies. Unlike conventional methods that assume homogeneous devices or generic robustness, this framework explicitly leverages inter-device differences to enhance performance, reproducibility, and efficiency. An experimental case study involving three nominally identical 3D printers (same brand, model, and close serial numbers) demonstrates reduced redundancy, lower resource usage, and improved reliability. Overall, this framework establishes a paradigm for precision- and resource-aware optimization in scalable, automated experimental platforms.

</details>


### [504] [Harli: Harvest Underutilized Resources in LLM Serving with Finetuning Tasks](https://arxiv.org/abs/2511.11729)
*Ao Xu,Han Zhao,Weihao Cui,Quan Chen,Yukang Chen,Shulai Zhang,Shuang Chen,Jiemin Jiang,Zhibin Yu,Minyi Guo*

Main category: cs.DC

TL;DR: Harli通过将参数高效微调（PEFT）任务与LLM解码实例共置，提高了GPU利用率和微调吞吐量，同时满足了严格的QoS要求。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM服务系统在 disaggregating 预填充和解码阶段时，由于解码实例的内存瓶颈和动态工作负载下的批处理不足，导致GPU利用率低下。

Method: Harli通过引入一个统一的内存分配器、一个两阶段延迟预测器和一个QoS保证的吞吐量最大化调度器，将PEFT任务与LLM解码实例共置，以应对内存限制和不可预测的干扰。

Result: 实验结果表明，Harli将微调吞吐量平均提高了46.2%（最高可达92.0%），同时保证了推理解码的严格QoS。

Conclusion: Harli成功地提高了LLM服务系统的GPU利用率和吞吐量，通过将计算密集型的PEFT任务与内存密集型的LLM解码实例共置，有效解决了资源利用率低的问题。

Abstract: Large language models (LLMs) are increasingly deployed under the Model-as-a-Service (MaaS) paradigm. To meet stringent quality-of-service (QoS) requirements, existing LLM serving systems disaggregate the prefill and decode phases of inference. However, decode instances often experience low GPU utilization due to their memory-bound nature and insufficient batching in dynamic workloads, leaving compute resources underutilized.
  We introduce Harli, a serving system that improves GPU utilization by co-locating parameter-efficient finetuning (PEFT) tasks with LLM decode instances. PEFT tasks are compute-bound and memory-efficient, making them ideal candidates for safe co-location. Specifically, Harli addresses key challenges--limited memory and unpredictable interference--using three components: a unified memory allocator for runtime memory reuse, a two-stage latency predictor for decode latency modeling, and a QoS-guaranteed throughput-maximizing scheduler for throughput maximization. Experimental results show that Harli improves the finetune throughput by 46.2% on average (up to 92.0%) over state-of-the-art serving systems, while maintaining strict QoS guarantees for inference decode.

</details>


### [505] [Speculative Decoding in Decentralized LLM Inference: Turning Communication Latency into Computation Throughput](https://arxiv.org/abs/2511.11733)
*Jingwei Song,Wanyi Chen,Xinyuan Song,Max,Chris Tong,Gufeng Chen,Tianyi Zhao,Eric Yang,Bill Shi,Lynn Ai*

Main category: cs.DC

TL;DR: Speculative decoding is enhanced for decentralized LLM inference through a framework called DSD, which parallelizes token verification across nodes and uses an adaptive strategy to improve speed by 15-20% without retraining, achieving up to 2.59x speedup on benchmarks.


<details>
  <summary>Details</summary>
Motivation: The behavior of speculative decoding in decentralized systems, where network latency is a major bottleneck, was under-characterized. This paper aims to address this by adapting speculative decoding for decentralized inference.

Method: The paper introduces Decentralized Speculative Decoding (DSD), a plug-and-play framework that enables parallel verification of multiple candidate tokens across distributed nodes. It also incorporates an adaptive speculative verification strategy that adjusts acceptance thresholds based on token-level semantic importance.

Result: DSD theoretically reduces cross-node communication cost and practically achieves up to 2.56x speedup on HumanEval and 2.59x on GSM8K, outperforming the Eagle3 baseline while maintaining accuracy. The adaptive strategy provides an additional 15% to 20% end-to-end speedup without retraining.

Conclusion: Adapting speculative decoding for decentralized execution is a system-level optimization that converts network stalls into throughput, enabling faster distributed LLM inference without requiring model retraining or architectural changes.

Abstract: Speculative decoding accelerates large language model (LLM) inference by using a lightweight draft model to propose tokens that are later verified by a stronger target model. While effective in centralized systems, its behavior in decentralized settings, where network latency often dominates compute, remains under-characterized. We present Decentralized Speculative Decoding (DSD), a plug-and-play framework for decentralized inference that turns communication delay into useful computation by verifying multiple candidate tokens in parallel across distributed nodes. We further introduce an adaptive speculative verification strategy that adjusts acceptance thresholds by token-level semantic importance, delivering an additional 15% to 20% end-to-end speedup without retraining. In theory, DSD reduces cross-node communication cost by approximately (N-1)t1(k-1)/k, where t1 is per-link latency and k is the average number of tokens accepted per round. In practice, DSD achieves up to 2.56x speedup on HumanEval and 2.59x on GSM8K, surpassing the Eagle3 baseline while preserving accuracy. These results show that adapting speculative decoding for decentralized execution provides a system-level optimization that converts network stalls into throughput, enabling faster distributed LLM inference with no model retraining or architectural changes.

</details>


### [506] [How Machine Learning-Data Driven Replication Strategies Enhance Fault Tolerance in Large-Scale Distributed Systems](https://arxiv.org/abs/2511.11749)
*Almond Kiruthu Murimi*

Main category: cs.DC

TL;DR: 机器学习驱动的数据复制策略可以提高大规模分布式系统的容错能力，通过预测故障和实时优化数据放置来应对动态工作负载和意外故障。


<details>
  <summary>Details</summary>
Motivation: 传统的数据复制方法依赖于静态配置，难以适应动态工作负载和意外故障，导致资源利用率低下和停机时间延长。

Method: 研究采用预测分析和强化学习等机器学习技术，提出自适应复制机制，能够预测系统故障并实时优化数据放置。

Result: 通过文献综述、定性分析和与传统方法的比较评估，该研究确定了现有复制策略的关键局限性，并强调了机器学习在创建更具弹性、自优化系统方面的变革潜力。

Conclusion: 研究结果强调了在实际环境中实施机器学习驱动的解决方案的希望和挑战，并为未来研究以及在云和企业系统中的实际部署提供了建议。

Abstract: This research paper investigates how machine learning-driven data replication strategies can enhance fault tolerance in large-scale distributed systems. Traditional replication methods, which rely on static configurations, often struggle to adapt to dynamic workloads and unexpected failures, leading to inefficient resource utilization and prolonged downtime. By integrating machine learning techniques-specifically predictive analytics and reinforcement learning. The study proposes adaptive replication mechanisms capable of forecasting system failures and optimizing data placement in real time. Through an extensive literature review, qualitative analysis, and comparative evaluations with traditional approaches, the paper identifies key limitations in existing replication strategies and highlights the transformative potential of machine learning in creating more resilient, self-optimizing systems. The findings underscore both the promise and the challenges of implementing ML-driven solutions in real-world environments, offering recommendations for future research and practical deployment in cloud-based and enterprise systems.

</details>


### [507] [TD-Orch: Scalable Load-Balancing for Distributed Systems with Applications to Graph Processing](https://arxiv.org/abs/2511.11843)
*Yiwei Zhao,Qiushi Lin,Hongbo Kang,Guy E. Blelloch,Laxman Dhulipala,Charles McGuffey,Phillip B. Gibbons*

Main category: cs.DC

TL;DR: TD-Orch是一个高效可扩展的任务-数据编排框架，通过一种推拉技术来平衡负载和最小化通信开销，可以为分布式应用程序带来显著的性能提升。TDO-GP是基于TD-Orch的分布式图处理系统，相比现有的系统有更快的处理速度。


<details>
  <summary>Details</summary>
Motivation: 为了支持图处理和键值存储等多种分布式应用，需要一个能够处理任务和数据分布在多台机器上的任务-数据编排抽象。

Method: TD-Orch采用分布式推拉技术，双向移动任务和数据以实现跨机器的负载均衡，即使在数据热点的情况下也能保证最小的通信开销。TDO-GP在此框架上构建，并采用了三种实现技术来利用TD-Orch的执行流。

Result: TD-Orch的实验结果显示，其速度比现有的分布式调度基线快2.7倍。TDO-GP的实验结果显示，其在通用图处理方面的平均速度比现有的开源分布式图处理系统快4.1倍。

Conclusion: TD-Orch框架高效且可扩展，能够为分布式应用程序带来显著的性能提升。TDO-GP在TD-Orch框架的基础上，为通用图处理提供了比现有系统更快的性能。

Abstract: In this paper, we highlight a task-data orchestration abstraction that supports a range of distributed applications, including graph processing and key-value stores. Given a batch of tasks each requesting one or more data items, where both tasks and data are distributed across multiple machines, each task must get co-located with its target data (by moving tasks and/or data) and executed. We present TD-Orch, an efficient and scalable orchestration framework featuring a simple application developer interface. TD-Orch employs a distributed push-pull technique, leveraging the bidirectional f low of both tasks and data to achieve scalable load balance across machines even under highly skewed data request (data hot spots), with minimal communication overhead. Experimental results show that TD-Orch achieves up to 2.7x speedup over existing distributed scheduling baselines. Building on TD-Orch, we present TDO-GP, a distributed graph processing system for general graph problems, demonstrating the effectiveness of the underlying framework. We design three families of implementation techniques to fully leverage the execution flow provided by TD-Orch. Experimental results show that TDO-GP achieves an average speedup of 4.1x over the best prior open-source distributed graph systems for general graph processing.

</details>


### [508] [Design of A Low-Latency and Parallelizable SVD Dataflow Architecture on FPGA](https://arxiv.org/abs/2511.12461)
*Fangqiang Du,Sixuan Chong,Zixuan Huang,Rui Qin,Fengnan Mi,Caibao Hu,Jiangang Chen*

Main category: cs.DC

TL;DR: 该研究提出了一种名为 DSB Jacobi 的数据流 SVD 处理算法，以应对大规模数据集 SVD 计算的挑战，尤其是在实时处理场景下。


<details>
  <summary>Details</summary>
Motivation: 传统 SVD 方法在处理大规模矩阵时计算成本高，现有硬件加速方案存在可扩展性差、内存消耗大以及忽略数据传输挑战等问题，不适用于嵌入式系统中的大规模实时数据流处理。

Method: 提出一种数据流 SVD 处理算法（DSB Jacobi），旨在减少片上 BRAM 消耗并提高计算速度。

Result: 与现有方法相比，DSB Jacobi 算法将片上 RAM 消耗降低了 41.5%，计算效率提高了 23 倍。

Conclusion: DSB Jacobi 算法为大规模数据流的实时 SVD 计算提供了一个实际可行的解决方案，显著减少了片上内存使用并提高了计算速度。

Abstract: Singular value decomposition (SVD) is widely used for dimensionality reduction and noise suppression, and it plays a pivotal role in numerous scientific and engineering applications. As the dimensions of the matrix grow rapidly, the computational cost increases significantly, posing a serious challenge to the efficiency of data analysis and signal processing systems,especially in time-sensitive scenarios with large-scale datasets. Although various dedicated hardware architectures have been proposed to accelerate the computation of intensive SVD, many of these designs suffer from limited scalability and high consumption of on-chip memory resources. Moreover, they typically overlook the computational and data transfer challenges associated with SVD, enabling them unsuitable for real-time processing of large-scale data stream matrices in embedded systems. In this express, we propose a Data Stream-Based SVD processing algorithm (DSB Jacobi), which significantly reduces on-chip BRAM usage while improving computational speed, offering a practical solution for real-time SVD computation of large-scale data streams. Compared with previous works, our experimental results indicate that the proposed method reduces on-chip RAM consumption by 41.5 percent and improves computational efficiency by 23 times.

</details>


### [509] [Flash-Fusion: Enabling Expressive, Low-Latency Queries on IoT Sensor Streams with LLMs](https://arxiv.org/abs/2511.11885)
*Kausar Patherya,Ashutosh Dhekne,Francisco Romero*

Main category: cs.DC

TL;DR: Flash-Fusion是一个结合了边缘计算和云计算的系统，旨在简化物联网（IoT）数据分析，特别是针对自然语言查询。它通过在边缘端对数据进行统计摘要（减少73.5%的数据量）和在云端进行查询规划（聚类行为数据并构建上下文提示）来解决数据量大和分析缓慢的问题。在实际的大学公交车队部署中，Flash-Fusion实现了95%的延迟降低和98%的代币使用量及成本节约，同时保持了高质量的响应，使不同领域的用户能高效地查询IoT数据。


<details>
  <summary>Details</summary>
Motivation: 现有的智能城市和物联网数据分析方法在处理海量、低级传感器数据时面临数据采集成本高、数据过于精细以及分析缓慢、需要技术专长等挑战。直接将所有遥测数据输入大型语言模型（LLMs）因上下文窗口限制、高昂的代币成本和延迟而不切实际。因此，缺乏一个能够解析用户查询、选择相关数据切片、选择正确表示形式并最终调用LLM的系统。

Method: Flash-Fusion系统采用两个核心原则：1. 基于边缘的统计摘要，旨在解决数据量大的问题，并实现了73.5%的数据缩减。2. 基于云的查询规划，通过对行为数据进行聚类并组装上下文丰富的提示，来解决数据解释的问题。

Result: 在大学公交车队的部署和评估中，Flash-Fusion相较于直接将原始数据输入先进LLM的基线方法，实现了95%的延迟降低和98%的代币使用量及成本节约，同时保持了高质量的响应。

Conclusion: Flash-Fusion是一个端到端的边缘-云系统，它通过边缘端的统计摘要和云端的查询规划，显著降低了物联网数据的采集和分析负担，解决了数据量和分析效率的挑战，并使用户能够高效地查询物联网数据，而无需手动进行查询编写或预处理。

Abstract: Smart cities and pervasive IoT deployments have generated interest in IoT data analysis across transportation and urban planning. At the same time, Large Language Models offer a new interface for exploring IoT data - particularly through natural language. Users today face two key challenges when working with IoT data using LLMs: (1) data collection infrastructure is expensive, producing terabytes of low-level sensor readings that are too granular for direct use, and (2) data analysis is slow, requiring iterative effort and technical expertise. Directly feeding all IoT telemetry to LLMs is impractical due to finite context windows, prohibitive token costs at scale, and non-interactive latencies. What is missing is a system that first parses a user's query to identify the analytical task, then selects the relevant data slices, and finally chooses the right representation before invoking an LLM.
  We present Flash-Fusion, an end-to-end edge-cloud system that reduces the IoT data collection and analysis burden on users. Two principles guide its design: (1) edge-based statistical summarization (achieving 73.5% data reduction) to address data volume, and (2) cloud-based query planning that clusters behavioral data and assembles context-rich prompts to address data interpretation. We deploy Flash-Fusion on a university bus fleet and evaluate it against a baseline that feeds raw data to a state-of-the-art LLM. Flash-Fusion achieves a 95% latency reduction and 98% decrease in token usage and cost while maintaining high-quality responses. It enables personas across disciplines - safety officers, urban planners, fleet managers, and data scientists - to efficiently iterate over IoT data without the burden of manual query authoring or preprocessing.

</details>


### [510] [KVSwap: Disk-aware KV Cache Offloading for Long-Context On-device Inference](https://arxiv.org/abs/2511.11907)
*Huawei Zhang,Chunwei Xia,Zheng Wang*

Main category: cs.DC

TL;DR: KV cache on disk for long-context LM inference on mobile devices.


<details>
  <summary>Details</summary>
Motivation: On-device AI applications using LMs require processing long contexts, but the KV cache causes memory issues. KVSwap aims to solve this by offloading the KV cache to disk.

Method: KVSwap stores the full KV cache on disk, uses in-memory metadata to predict critical entries, overlaps computation with disk access, and optimizes read patterns for storage devices.

Result: KVSwap improves throughput on memory-constrained devices while preserving generation quality, outperforming existing methods.

Conclusion: KVSwap effectively breaks the memory wall for long-context LM inference on mobile devices by offloading the KV cache to disk.

Abstract: Language models (LMs) underpin emerging mobile and embedded AI applications like meeting and video summarization and document analysis, which often require processing multiple long-context inputs. Running an LM locally on-device improves privacy, enables offline use, and reduces cost, but long-context inference quickly hits a \emph{memory capacity wall} as the key-value (KV) cache grows linearly with context length and batch size.
  We present KVSwap, a software framework to break this memory wall by offloading the KV cache to non-volatile secondary storage (disk). KVSwap leverages the observation that only a small, dynamically changing subset of KV entries is critical for generation. It stores the full cache on disk, uses a compact in-memory metadata to predict which entries to preload, overlaps computation with hardware-aware disk access, and orchestrates read patterns to match storage device characteristics. Our evaluation shows that across representative LMs and storage types, KVSwap delivers higher throughput under tight memory budgets while maintaining the generation quality when compared with existing KV cache offloading schemes.

</details>


### [511] [High-Performance N-Queens Solver on GPU: Iterative DFS with Zero Bank Conflicts](https://arxiv.org/abs/2511.12009)
*Guangchao Yao,Yali Li*

Main category: cs.DC

TL;DR: 通过使用NVIDIA GPU平台上的迭代深度优先搜索（DFS）算法，成功在28.4天内验证了27路易斯问题，并预测11个月内可解决28路易斯问题，同时实现了对现有GPU方法的10倍到26倍的加速。 


<details>
  <summary>Details</summary>
Motivation: N路易斯问题是一个经典的NP完全问题，其计算复杂度极高，目前仅能验证到N<=26的解。之前的研究（如2016年PreuBer团队使用FPGA）虽然解决了27路易斯问题，但耗时一年且未经独立验证。近期GPU并行计算的研究表明，验证27路易斯问题仍需17个月，成本过高。

Method: 提出了一种创新的NVIDIA GPU平台并行计算方法，包括：1. 迭代深度优先搜索（DFS）算法；2. 将堆栈结构完全映射到GPU共享内存；3. 通过精心设计的内存访问模式有效避免银行冲突；4. 采用多种优化技术以实现最佳性能。

Result: 在提出的优化框架下，使用8块RTX 5090 GPU，在28.4天内成功验证了27路易斯问题，确认了PreuBer计算结果的正确性。同时，将28路易斯问题的预计求解时间缩短至约11个月，使其在计算上变得可行。

Conclusion: 该方法在NVIDIA GPU平台上实现了对N路易斯问题的显著加速，验证了27路易斯问题的解，并使28路易斯问题的解决成为可能。与现有GPU方法相比，在相同硬件配置（8块A100）下实现了超过10倍的加速，在使用8块RTX 5090 GPU时更是实现了超过26倍的加速，为该长期停滞的问题带来了新的解决方案。

Abstract: The counting of solutions to the N-Queens problem is a classic NP-complete problem with extremely high computational complexity. As of now, the academic community has rigorously verified the number of solutions only up to N <= 26. In 2016, the research team led by PreuBer solved the 27-Queens problem using FPGA hardware, which took approximately one year, though the result remains unverified independently. Recent studies on GPU parallel computing suggest that verifying the 27-Queens solution would still require about 17 months, indicating excessively high time and computational resource costs. To address this challenge, we propose an innovative parallel computing method on NVIDIA GPU platform, with the following core contributions: (1) An iterative depth-first search (DFS) algorithm for solving the N-Queens problem; (2) Complete mapping of the required stack structure to GPU shared memory; (3) Effective avoidance of bank conflicts through meticulously designed memory access patterns; (4) Various optimization techniques are employed to achieve optimal performance. Under the proposed optimization framework, we successfully verified the 27-Queens problem in just 28.4 days using eight RTX 5090 GPUs, thereby confirming the correctness of PreuBer's computational results. Moreover, we have reduced the projected solving time for the next open case-the 28-Queens problem-to approximately 11 months, making its resolution computationally feasible. Compared to the state-of-the-art GPU methods, our method achieves over 10x speedup on identical hardware configurations (8 A100), while delivering over 26x acceleration when utilizing 8 RTX 5090 GPUs, and brings fresh perspectives to this long-stagnant problem.

</details>


### [512] [A Quick and Exact Method for Distributed Quantile Computation](https://arxiv.org/abs/2511.12025)
*Ivan Cao,Jaromir J. Saloni,David A. G. Harrison*

Main category: cs.DC

TL;DR: Spark 的 GK Select 算法能在保证精确性的前提下，通过避免全局排序和仅在局部数据上操作，实现与 GK Sketch 相当的性能。


<details>
  <summary>Details</summary>
Motivation: 在 Spark 中，精确计算分位数通常需要昂贵的全局排序，而现有的近似方法 GK Sketch 无法满足需要精确结果的场景。因此，需要一种能够同时保证精确性并提高计算效率的方法。

Method: GK Select 算法首先利用 GK Sketch 确定一个近似目标枢纽值，然后在每个分区内线性时间提取误差范围内的候选值，最后通过树归约（tree-reduce）合并这些候选集以获得精确分位数。这种方法避免了全数据混洗（shuffle），并且仅需常数次操作。

Result: GK Select 算法在理论上实现了与 GK Sketch 相同的执行器侧时间复杂度，但能返回精确分位数。在实验中，该算法在处理 10^9 个数据点、跨越 120 个分区时，实现了与 GK Sketch 相当的延迟，并且比 Spark 的全局排序方法快约 10.5 倍。

Conclusion: GK Select 算法成功地解决了 Spark 中精确计算分位数效率低下的问题，提供了一种兼具精确性和高性能的解决方案，在实际应用中具有显著优势。

Abstract: Quantile computation is a core primitive in large-scale data analytics. In Spark, practitioners typically rely on the Greenwald-Khanna (GK) Sketch, an approximate method. When exact quantiles are required, the default option is an expensive global sort. We present GK Select, an exact Spark algorithm that avoids full-data shuffles and completes in a constant number of actions. GK Select leverages GK Sketch to identify a near-target pivot, extracts all values within the error bound around this pivot in each partition in linear time, and then tree-reduces the resulting candidate sets. We show analytically that GK Select matches the executor-side time complexity of GK Sketch while returning the exact quantile. Empirically, GK Select achieves sketch-level latency and outperforms Spark's full sort by approximately 10.5x on 10^9 values across 120 partitions on a 30-core AWS EMR cluster.

</details>


### [513] [Striking the Right Balance between Compute and Copy: Improving LLM Inferencing Under Speculative Decoding](https://arxiv.org/abs/2511.12031)
*Arun Ramachandran,Ramaswamy Govindarajan,Murali Annavaram,Prakash Raghavendra,Hossein Entezari Zarch,Lei Gao,Chaoyi Jiang*

Main category: cs.DC

TL;DR: KV cache更新的开销很大，BMC通过r次迭代分配一次KV张量来减少内存开销，并利用多余的行进行投机解码，从而提高LLM推理效率。


<details>
  <summary>Details</summary>
Motivation: 随着GPU成本的飙升，使用CPU进行LLM推理变得非常必要。然而，KV cache更新的开销很大，尤其是在序列长度增加时。

Method: BMC提出了一种新的KV cache分配机制，该机制每r次迭代分配一次具有r个冗余行的KV张量，允许在这些迭代中进行原地更新，而没有复制开销，并利用多余的行进行投机解码。

Result: BMC的平均吞吐量加速最高可达3.2倍（相比基线HuggingFace），与投机解码结合使用时，额外的加速可达1.39倍。与vLLM和DeepSpeed相比，BMC的加速分别可达1.36倍和2.29倍。BMC在CPU和GPU上都表现良好。

Conclusion: BMC通过平衡内存和计算，有效解决了KV cache更新的开销问题，并能与投机解码结合使用，显著提高了LLM推理的效率。

Abstract: With the skyrocketing costs of GPUs and their virtual instances in the cloud, there is a significant desire to use CPUs for large language model (LLM) inference. KV cache update, often implemented as allocation, copying, and in-place strided update for each generated token, incurs significant overhead. As the sequence length increases, the allocation and copy overheads dominate the performance. Alternate approaches may allocate large KV tensors upfront to enable in-place updates, but these matrices (with zero-padded rows) cause redundant computations. In this work, we propose a new KV cache allocation mechanism called Balancing Memory and Compute (BMC). BMC allocates, once every r iterations, KV tensors with r redundant rows, allowing in-place update without copy overhead for those iterations, but at the expense of a small amount of redundant computation. Second, we make an interesting observation that the extra rows allocated in the KV tensors and the resulting redundant computation can be repurposed for Speculative Decoding (SD) that improves token generation efficiency. Last, BMC represents a spectrum of design points with different values of r. To identify the best-performing design point(s), we derive a simple analytical model for BMC. The proposed BMC method achieves an average throughput acceleration of up to 3.2x over baseline HuggingFace (without SD). Importantly when we apply BMC with SD, it results in an additional speedup of up to 1.39x, over and above the speedup offered by SD. Further, BMC achieves a throughput acceleration of up to 1.36x and 2.29x over state-of-the-art inference servers vLLM and DeepSpeed, respectively. Although the BMC technique is evaluated extensively across different classes of CPUs (desktop and server class), we also evaluate the scheme with GPUs and demonstrate that it works well for GPUs.

</details>


### [514] [Combining Serverless and High-Performance Computing Paradigms to support ML Data-Intensive Applications](https://arxiv.org/abs/2511.12185)
*Mills Staylor,Arup Kumar Sarker,Gregor von Laszewski,Geoffrey Fox,Yue Cheng,Judy Fox*

Main category: cs.DC

TL;DR: 该论文介绍了一个名为 Cylon 的高性能分布式数据框解决方案，旨在解决无服务器函数在处理大数据集时的通信和性能问题。


<details>
  <summary>Details</summary>
Motivation: 传统数据工程、机器学习和人工智能工作负载在数据中心运行，成本高昂。虽然公有云和无服务器函数（如 AWS Lambda）提供了可扩展性和便利性，但在处理大数据集时，其外部存储的访问速度远慢于高性能计算集群的直接通信。

Method: 论文提出了一种受 FMI 库启发的无服务器通信器设计，通过 NAT Traversal TCP Hole Punching 技术实现直接通信，以解决无服务器函数在处理大数据集时的通信和性能瓶颈。

Result: 通过 Cylon 解决方案，实验证明了在强扩展性实验中，AWS Lambda 的性能可以达到与服务器 AWS (EC2) 和高性能计算集群相媲美的水平，其性能差距缩小到 1% 以内。

Conclusion: Cylon 作为一个高性能分布式数据框解决方案，通过创新的无服务器通信器设计，有效解决了无服务器函数在大数据处理中的性能和通信挑战，为在大规模数据集上利用无服务器技术提供了新的可能性。

Abstract: Data is found everywhere, from health and human infrastructure to the surge of sensors and the proliferation of internet-connected devices. To meet this challenge, the data engineering field has expanded significantly in recent years in both research and industry. Traditionally, data engineering, Machine Learning, and AI workloads have been run on large clusters within data center environments, requiring substantial investment in hardware and maintenance. With the rise of the public cloud, it is now possible to run large applications across nodes without owning or maintaining hardware. Serverless functions such as AWS Lambda provide horizontal scaling and precise billing without the hassle of managing traditional cloud infrastructure. However, when processing large datasets, users often rely on external storage options that are significantly slower than direct communication typical of HPC clusters. We introduce Cylon, a high-performance distributed data frame solution that has shown promising results for data processing using Python. We describe how we took inspiration from the FMI library and designed a serverless communicator to tackle communication and performance issues associated with serverless functions. With our design, we demonstrate that the performance of AWS Lambda falls below one percent of strong scaling experiments compared to serverful AWS (EC2) and HPCs based on implementing direct communication via NAT Traversal TCP Hole Punching.

</details>


### [515] [Distributed Seasonal Temporal Pattern Mining](https://arxiv.org/abs/2511.12216)
*Van Ho-Long,Nguyen Ho,Anh-Vu Dinh-Duc,Ha Manh Tran,Ky Trung Nguyen,Tran Dung Pham,Quoc Viet Hung Nguyen*

Main category: cs.DC

TL;DR: 该论文提出了一种名为DSTPM的分布式季节性时间模式挖掘框架，解决了传统方法在处理海量时间序列数据时的效率和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据量爆炸性增长，但传统挖掘方法难以有效提取季节性模式，且无法扩展到大规模数据集。

Method: 提出DSTPM分布式框架，利用分布式分层查找哈希结构进行高效计算。

Result: 实验证明DSTPM在运行时和内存使用方面显著优于顺序基线，并且能够有效地扩展到非常大的数据集。

Conclusion: DSTPM是第一个用于从时间序列中挖掘季节性时间模式的分布式框架，解决了现有方法的局限性。

Abstract: The explosive growth of IoT-enabled sensors is producing enormous amounts of time series data across many domains, offering valuable opportunities to extract insights through temporal pattern mining. Among these patterns, an important class exhibits periodic occurrences, referred to as \textit{seasonal temporal patterns} (STPs). However, mining STPs poses challenges, as traditional measures such as support and confidence cannot capture seasonality, and the lack of the anti-monotonicity property results in an exponentially large search space. Existing STP mining methods operate sequentially and therefore do not scale to large datasets. In this paper, we propose the Distributed Seasonal Temporal Pattern Mining (DSTPM), the first distributed framework for mining seasonal temporal patterns from time series. DSTPM leverages efficient data structures, specifically distributed hierarchical lookup hash structures, to enable efficient computation. Extensive experimental evaluations demonstrate that DSTPM significantly outperforms sequential baselines in runtime and memory usage, while scaling effectively to very large datasets.

</details>


### [516] [A Decentralized Root Cause Localization Approach for Edge Computing Environments](https://arxiv.org/abs/2511.12486)
*Duneesha Fernando,Maria A. Rodriguez,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 该论文提出了一种去中心化的边缘计算根因定位（RCL）方法，利用个性化 PageRank（PPR）算法在边缘设备层面直接执行定位，减少了延迟和通信开销，并在 MicroCERCL 数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 边缘计算环境中日益复杂的微服务化物联网应用容易出现性能异常，且这些异常会跨服务传播。现有的云环境 RCL 方法不适用于边缘计算，因为它们依赖中心化分析，会导致高延迟和通信开销。因此，需要一种适用于边缘计算环境的去中心化 RCL 方法。

Method: 该方法首先将微服务聚类成通信和共同定位的集群，以限制异常传播。然后在每个集群内本地执行 PPR 算法进行根因定位。对于跨集群传播的异常，采用一种轻量级的集群间点对点近似协同机制。此外，还提出了一种新颖的异常评分机制，以适应异构边缘环境中多层面的异常触发器。

Result: 在 MicroCERCL 数据集上的评估结果显示，该去中心化方法实现了与中心化方法相当或更高的定位准确性，同时将定位时间减少了高达 34%。

Conclusion: 去中心化的基于图的 RCL 方法为资源受限的边缘环境提供了一种实用且高效的异常诊断解决方案。

Abstract: Edge computing environments host increasingly complex microservice-based IoT applications, which are prone to performance anomalies that can propagate across dependent services. Identifying the true source of such anomalies, known as Root Cause Localization (RCL), is essential for timely mitigation. However, existing RCL approaches are designed for cloud environments and rely on centralized analysis, which increases latency and communication overhead when applied at the edge. This paper proposes a decentralized RCL approach that executes localization directly at the edge device level using the Personalized PageRank (PPR) algorithm. The proposed method first groups microservices into communication- and colocation-aware clusters, thereby confining most anomaly propagation within cluster boundaries. Within each cluster, PPR is executed locally to identify the root cause, significantly reducing localization time. For the rare cases where anomalies propagate across clusters, we introduce an inter-cluster peer-to-peer approximation process, enabling lightweight coordination among clusters with minimal communication overhead. To enhance the accuracy of localization in heterogeneous edge environments, we also propose a novel anomaly scoring mechanism tailored to the diverse anomaly triggers that arise across microservice, device, and network layers. Evaluation results on the publicly available edge dataset, MicroCERCL, demonstrate that the proposed decentralized approach achieves comparable or higher localization accuracy than its centralized counterpart while reducing localization time by up to 34%. These findings highlight that decentralized graph-based RCL can provide a practical and efficient solution for anomaly diagnosis in resource-constrained edge environments.

</details>


### [517] [Iris: First-Class Multi-GPU Programming Experience in Triton](https://arxiv.org/abs/2511.12500)
*Muhammad Awad,Muhammad Osama,Brandon Potter*

Main category: cs.DC

TL;DR: Iris是一个用Python和Triton编写的多GPU通信库，它通过提供自然对齐Triton编程模型的基于平铺的对称内存抽象，实现了计算和通信的无缝交织，从而消除了在性能和可编程性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 传统的多GPU编程需要在性能和可编程性之间进行复杂的权衡。高性能实现通常依赖于低级的HIP/CUDA通信库，这需要大量的工程努力，而更简单的抽象则牺牲了性能。Iris旨在消除这种权衡。

Method: Iris是一个完全用Python和Triton实现的库，它提供基于平铺的对称内存抽象，这些抽象与Triton的编程模型自然对齐，允许开发者编写单源内核，无缝地交织计算和通信。Iris还实现了一个计算-通信重叠模式的分类，可以很容易地在Iris中实现。

Result: Iris在微基准测试中实现了接近最优的带宽利用率，并在GEMM+All-Scatter工作负载上比PyTorch和RCCL实现了高达1.79倍的加速。

Conclusion: Iris证明了高级实现可以匹配甚至超越高度优化的库，同时大大简化了多GPU编程。

Abstract: Multi-GPU programming traditionally requires developers to navigate complex trade-offs between performance and programmability. High-performance implementations typically rely on low-level HIP/CUDA communication libraries that demand substantial engineering effort for even basic overlap patterns, while simpler abstractions often sacrifice performance. We present Iris, a multi-GPU communication library implemented entirely in Python and Triton that eliminates this trade-off. Iris provides tile-based symmetric memory abstractions that naturally align with Triton's programming model, enabling developers to write single-source kernels that seamlessly interleave computation and communication. We demonstrate a taxonomy of compute-communication overlap patterns--from bulk-synchronous to fine-grained workgroup specialization--that can be implemented with minimal code changes in Iris, often requiring just a few additional lines within the same Triton kernel. Our evaluation shows that Iris achieves near-optimal bandwidth utilization in microbenchmarks and delivers up to 1.79x speedup over PyTorch and RCCL for GEMM+All-Scatter workloads, demonstrating that high-level implementations can match or exceed heavily-optimized libraries while dramatically simplifying multi-GPU programming.

</details>


### [518] [Artifact for A Non-Intrusive Framework for Deferred Integration of Cloud Patterns in Energy-Efficient Data-Sharing Pipelines](https://arxiv.org/abs/2511.12667)
*Sepideh Masoudi,Mark Edward Michael Daly,Jannis Kiesel*

Main category: cs.DC

TL;DR: 组织在数据网格架构中构建特定消费者的数据共享管道，但传统云设计模式会降低服务重用性。我们提出了一个基于Kubernetes的工具，可以在不修改服务代码的情况下，实现设计模式的非侵入式、延迟应用，并自动化模式注入和收集能源指标，从而在保持服务可重用性的同时，支持节能决策。


<details>
  <summary>Details</summary>
Motivation: 在数据网格架构日益普及的背景下，组织面临着如何提高数据共享管道中可重用转换服务的成本和能源效率的挑战，同时避免传统云设计模式降低服务重用性的问题。

Method: 提出一个基于Kubernetes的工具，该工具能够非侵入式地、延迟地应用设计模式，而无需修改服务代码。该工具能够自动化模式注入，并收集能源使用指标。

Result: 该工具能够在不修改服务代码的情况下，实现设计模式的非侵入式、延迟应用，并能自动化模式注入和收集能源指标，从而在保持转换服务在各种管道结构中的可重用性的同时，支持与能源相关的决策。

Conclusion: 提出的Kubernetes工具通过实现设计模式的非侵入式、延迟应用，解决了数据网格架构中服务可重用性和能源效率的问题，从而支持组织做出更明智的节能决策。

Abstract: As data mesh architectures grow, organizations increasingly build consumer-specific data-sharing pipelines from modular, cloud-based transformation services. While reusable transformation services can improve cost and energy efficiency, applying traditional cloud design patterns can reduce reusability of services in different pipelines. We present a Kubernetes-based tool that enables non-intrusive, deferred application of design patterns without modifying services code. The tool automates pattern injection and collects energy metrics, supporting energy-aware decisions while preserving reusability of transformation services in various pipeline structures.

</details>


### [519] [The Time to Consensus in a Blockchain: Insights into Bitcoin's "6 Blocks Rule''](https://arxiv.org/abs/2511.12687)
*Partha S. Dey,Aditya S. Gopalan,Vijay G. Subramanian*

Main category: cs.DC

TL;DR: 研究者们研究了Nakamoto链在诚实和对抗两种增长模型下的共识时间，并使用排队技术来确定诚实模型永久超过对抗模型的时间。


<details>
  <summary>Details</summary>
Motivation: 确定Nakamoto链的共识时间，特别是在诚实和对抗增长模型下的时间，并找到诚实模型永久超过对抗模型的时间点。

Method: 使用排队技术来分析两个竞争增长过程（诚实和对抗），并计算共识时间的拉普拉斯变换，最后通过模拟进行验证。

Result: 计算了诚实增长过程（受随机延迟影响）的共识时间的拉普拉斯变换，并通过模拟进行了验证。

Conclusion: 通过排队技术和模拟，研究了Nakamoto链在不同增长模型下的共识时间，并为诚实模型何时永久超过对抗模型提供了理论依据。

Abstract: We investigate the time to consensus in Nakamoto blockchains. Specifically, we consider two competing growth processes, labeled \emph{honest} and \emph{adversarial}, and determine the time after which the honest process permananetly exceeds the adversarial process. This is done via queueing techniques. The predominant difficulty is that the honest growth process is subject to \emph{random delays}. In a stylized Bitcoin model, we compute the Laplace transform for the time to consensus and verify it via simulation.

</details>


### [520] [Learning Process Energy Profiles from Node-Level Power Data](https://arxiv.org/abs/2511.13155)
*Jonathan Bader,Julius Irion,Jannis Kappel,Joel Witzke,Niklas Fomin,Diellza Sherifi,Odej Kao*

Main category: cs.DC

TL;DR: 数据中心能耗需求增长，现有技术测量粗粒度，提出新方法通过eBPF和perf收集资源指标，并结合节点级能耗测量，利用回归模型进行更细粒度的每进程能耗预测。


<details>
  <summary>Details</summary>
Motivation: 为了提高数据中心的能源效率，必须获得能源消耗的进程级见解。现有的每进程能源使用估算方法（如Intel RAPL）仅限于特定硬件，并且只提供粗粒度的域级测量。

Method: 通过利用eBPF和perf收集的细粒度进程级资源指标，并与从附加电源分配单元获得的节点级能耗测量同步，对每进程能耗配置文件进行建模。通过回归模型统计学习进程级资源使用与节点级能耗之间的关系。

Result: 实现更细粒度的每进程能耗预测。

Conclusion: 所提出的方法通过利用细粒度的进程级资源指标，并结合节点级能耗测量，能够实现更准确、更细粒度的每进程能耗预测，从而为提高数据中心能源效率提供支持。

Abstract: The growing demand for data center capacity, driven by the growth of high-performance computing, cloud computing, and especially artificial intelligence, has led to a sharp increase in data center energy consumption. To improve energy efficiency, gaining process-level insights into energy consumption is essential. While node-level energy consumption data can be directly measured with hardware such as power meters, existing mechanisms for estimating per-process energy usage, such as Intel RAPL, are limited to specific hardware and provide only coarse-grained, domain-level measurements. Our proposed approach models per-process energy profiles by leveraging fine-grained process-level resource metrics collected via eBPF and perf, which are synchronized with node-level energy measurements obtained from an attached power distribution unit. By statistically learning the relationship between process-level resource usage and node-level energy consumption through a regression-based model, our approach enables more fine-grained per-process energy predictions.

</details>


### [521] [Pico-Cloud: Cloud Infrastructure for Tiny Edge Devices](https://arxiv.org/abs/2511.13253)
*Mordechai Guri*

Main category: cs.DC

TL;DR: Pico-Cloud是一种基于树莓派Zero等超小型硬件平台的微边缘云架构，提供容器化虚拟化、服务发现和轻量级编排，可在设备层实现低延迟、低功耗的本地运行，无需中心化数据中心。它适用于农村连接、教育集群和边缘AI推理等场景，并分析了计算、网络、存储和电源管理的设计挑战。结果表明Pico-Cloud是网络边缘轻量级分布式工作负载的经济高效、去中心化和可持续的平台。


<details>
  <summary>Details</summary>
Motivation: 介绍Pico-Cloud微边缘云架构，解决在超小型硬件上实现容器化虚拟化、服务发现和轻量级编排的需求，以支持低延迟、低功耗的本地运行，摆脱对中心化数据中心的依赖。

Method: 提出Pico-Cloud架构模型，并概述了农村连接、教育集群和边缘AI推理等代表性用例。对计算、网络、存储和电源管理的设计挑战进行了分析。

Result: Pico-Cloud被证明是网络边缘轻量级分布式工作负载的经济高效、去中心化和可持续的平台。

Conclusion: Pico-Cloud为网络边缘的轻量级分布式工作负载提供了一种经济高效、去中心化且可持续的解决方案。

Abstract: This paper introduces the Pico-Cloud, a micro-edge cloud architecture built on ultra-minimal hardware platforms such as the Raspberry Pi Zero and comparable single-board computers. The Pico-Cloud delivers container-based virtualization, service discovery, and lightweight orchestration directly at the device layer, enabling local operation with low latency and low power consumption without reliance on centralized data centers. We present its architectural model, outline representative use cases including rural connectivity, educational clusters, and edge AI inference, and analyze design challenges in computation, networking, storage, and power management. The results highlight Pico-Clouds as a cost-effective, decentralized, and sustainable platform for lightweight distributed workloads at the network edge.

</details>


### [522] [Distributed Hierarchical Machine Learning for Joint Resource Allocation and Slice Selection in In-Network Edge Systems](https://arxiv.org/abs/2511.13313)
*Sulaiman Muhammad Rashid,Ibrahim Aliyu,Jaehyung Park,Jinsul Kim*

Main category: cs.DC

TL;DR: Metaverse对延迟和资源的要求很高，传统优化方法难以满足。本研究提出了一种结合计算网络(COIN)和多路接入边缘计算(MEC)的切片感知网络内边缘架构，并通过深度学习模型DeepSets-S解决了资源管理和切片选择问题。


<details>
  <summary>Details</summary>
Motivation: Metaverse应用对低延迟和高资源的需求给传统优化技术带来了挑战。

Method: 将联合资源管理和切片选择问题建模为混合整数非线性规划(MINLP)，并分解为三个子问题。利用离线最优解训练了一个基于DeepSets的分布式分层模型(DeepSets-S)，该模型具有新颖的归一化机制和置换等变性。

Result: DeepSets-S在SP1/SP2上达到了接近最优的精度(Acc1 = 95.26%, 95.67%)，在SP3上提高了多类卸载精度(Acc = 0.7486; 二进制本地/卸载Acc = 0.8824)。与精确求解器相比，该方法将执行时间缩短了86.1%，同时最优系统成本的跟踪误差在6.1%以内。与基线模型相比，DeepSets-S在COIN/MEC资源利用率和成本比方面表现更优。

Conclusion: DeepSets-S模型能够高效地解决Metaverse边缘计算中的资源管理和切片选择问题，在保证近乎最优的性能的同时，显著降低了计算复杂度。

Abstract: The Metaverse promises immersive, real-time experiences; however, meeting its stringent latency and resource demands remains a major challenge. Conventional optimization techniques struggle to respond effectively under dynamic edge conditions and high user loads. In this study, we explore a slice-enabled in-network edge architecture that combines computing-in-the-network (COIN) with multi-access edge computing (MEC). In addition, we formulate the joint problem of wireless and computing resource management with optimal slice selection as a mixed-integer nonlinear program (MINLP). Because solving this model online is computationally intensive, we decompose it into three sub-problems (SP1) intra-slice allocation, (SP2) inter-slice allocation, and (SP3) offloading decision and train a distributed hierarchical DeepSets-based model (DeepSets-S) on optimal solutions obtained offline. In the proposed model, we design a slack-aware normalization mechanism for a shared encoder and task-specific decoders, ensuring permutation equivariance over variable-size wireless device (WD) sets. The learned system produces near-optimal allocations with low inference time and maintains permutation equivariance over variable-size device sets. Our experimental results show that DeepSets-S attains high tolerance-based accuracies on SP1/SP2 (Acc1 = 95.26% and 95.67%) and improves multiclass offloading accuracy on SP3 (Acc = 0.7486; binary local/offload Acc = 0.8824). Compared to exact solvers, the proposed approach reduces the execution time by 86.1%, while closely tracking the optimal system cost (within 6.1% in representative regimes). Compared with baseline models, DeepSets-S consistently achieves higher cost ratios and better utilization across COIN/MEC resources.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [523] [Effective Hamiltonians for Ge/Si core/shell nanowires from higher order perturbation theory](https://arxiv.org/abs/2511.11809)
*Sebastian Miles,A. Mert Bozkurt,Dániel Varjas,Michael Wimmer*

Main category: cond-mat.mes-hall

TL;DR: 我们使用摄动理论研究了Ge/Si核/壳纳米线中空穴的电子结构，得到了几阶低能模型，并解决了有效质量依赖于磁场的交叉项等高阶问题。我们发现低对称生长方向的轨道反转会改变低阶有效系数，并降低Rashba自旋-轨道相互作用。此外，我们发现空穴的有效质量会发散，形成准平带，这对于关联态很有趣。我们还展示了如何选择性地调整单自旋能带的有效质量。


<details>
  <summary>Details</summary>
Motivation: 本文旨在理论上探索圆柱形锗/硅核/壳纳米线中空穴的电子结构，特别是要理解在不同生长方向下，有效质量、自旋-轨道相互作用和能带行为。

Method: 采用摄动理论方法，得到最高到五阶的低能有效模型，以解释实验相关的生长方向。

Result: 推导了低能有效模型，揭示了低对称生长方向的轨道反转现象，并观察到Rashba自旋-轨道相互作用的降低。此外，还发现空穴有效质量发散导致准平带的形成，并提出可以调控单自旋能带的有效质量。

Conclusion: 该研究为理解和调控纳米线中的空穴电子结构提供了理论基础，特别是对于设计具有特定电子和自旋特性的量子器件具有重要意义。

Abstract: We theoretically explore the electronic structure of holes in cylindrical Germanium/Silicon core/shell nanowires using a perturbation theory approach. The approach yields a set of interpretable and transferable effective low-energy models for the lowest few sub-bands up to fifth order for experimentally relevant growth directions. In particular, we are able to resolve higher order cross terms e.g., the dependency of the effective mass on the magnetic field. Our study reveals orbital inversions of the lowest sub-bands for low-symmetry growth directions, leading to significant changes of the lower order effective coefficients. We demonstrate a reduction of the direct Rashba spin-orbit interaction due to competing symmetry effects for low-symmetry growth directions. Finally, we find that the effective mass of the confined holes can diverge yielding quasi flat bands interesting for correlated states. We show how one can tune the effective mass of a single spin band allowing one to tune the effective mass selectively to its divergent points.

</details>


### [524] [Acoustic Metamaterials with Positive and Negative Couplings: Modular and One Piece Architectures for Topological Models](https://arxiv.org/abs/2511.11876)
*Jackson Saunders,Camelia Prodan*

Main category: cond-mat.mes-hall

TL;DR: 我们提出了两种3D打印声学超材料紧束缚模型的方法，一种是模块化设计，另一种是集成式设计。


<details>
  <summary>Details</summary>
Motivation: 实现声学超材料中的紧束缚模型，并通过几何控制实现正负耦合，以精确模拟拓扑模型。

Method: 采用3D打印技术，结合模块化设计和集成式设计，并通过调整耦合长度（CL）和总耦合面积（TCA）来控制模型。

Result: 在SSH和Kitaev链模型中发现了中带边缘和界面态，验证了拓扑行为。

Conclusion: 所提出的3D打印平台能够精确实现声学紧束缚模型，并可用于研究拓扑物理现象。

Abstract: We describe two 3D-printing approaches for realizing tight-binding models in acoustic metamaterials using H-shaped resonators: a modular system with tunable interconnections and an integrated one-piece design for reducing dissipation. The platform supports both positive and negative coupling through geometric control, enabling accurate acoustic analogs of topological models. By tuning the coupling length (CL), we eliminate detuning effects and preserve particle-hole symmetry. We further quantify the influence of the Total Coupling Area (TCA) on band topology and derive conditions for constant-area coupling. The system was tested on SSH and Kitaev chains, revealing midgap edge and interface states, confirming topological behavior in both configurations.

</details>


### [525] [Probing Electrocatalytic Gas Evolution Reaction at Pt by Force Noise Measurements. Part 2. Oxygen](https://arxiv.org/abs/2511.12067)
*Nataraju Bodappa,Gregory Jerkiewicz,Peter Grutter*

Main category: cond-mat.mes-hall

TL;DR: 氧气气泡在电催化界面上成核、生长和脱离，研究氧析出反应（OER）的机制。


<details>
  <summary>Details</summary>
Motivation: 理解O2气泡的成核和生长对于理解其对催化活性位点的影响至关重要，需要精确描绘电催化界面处的纳米级动态变化。

Method: 结合原子力显微镜（AFM）和铂超微电极，研究O2气泡的成核、生长和脱离过程。

Result: AFM结果显示，O2气泡在台阶边缘成核，并与催化活性位点发生相互作用，导致高过电位下电流密度降低。

Conclusion: 该研究揭示了气体在催化表面上产生过程中复杂的现象，特别是催化位点与气泡成核位点之间的相互作用是电流密度下降的主要原因。

Abstract: Understanding O2 bubble nucleation and growth during the oxygen evolution reaction (OER) is crucial to comprehend their influences on catalytically active sites in the process. To achieve this goal, mapping the spatial variation of nanoscale dynamic individual steps at the electrocatalytic interfaces is vital, as it further enables a detailed understanding of the mechanism of the process. Here, we combined tapping mode AFM imaging with a Pt ultramicroelectrode to investigate oxygen bubble nucleation, growth, and detachment. Our AFM feedback error signal and topography data reveal that bubbles of O2 gas nucleate at the step edge sites and interact with the catalytically active sites. This interaction between primary catalytic sites and bubble nucleation sites is the primary reason for a decrease in the current density at a given high overpotential of the OER. Our findings advance the understanding of the complexity of phenomena involved in gas evolution on catalytic surfaces.

</details>


### [526] [Inter-flake transport and humidity response of Ti3C2Tx MXene at the nanoscale](https://arxiv.org/abs/2511.12105)
*Oriane de Leuze,Maxime Berthe,Sophie Hermans,Benoît Hackens*

Main category: cond-mat.mes-hall

TL;DR: 电荷传输主要受限于二维晶体网络中的片间结，这对于 MXene 基设备（如化学电阻器）的传感动力学至关重要。


<details>
  <summary>Details</summary>
Motivation: 需要理解二维晶体网络（特别是 MXene）中的电荷传输，以区分片内和片间电阻的贡献，从而开发可靠的应用。

Method: 利用扫描探针测量来研究 Ti3C2Tx（一种 MXene）多片导电通路中的电荷传输，量化片间结电阻，并将各向同性行为与电压降定位在片间结的现象联系起来。此外，还研究了湿度对单片、多片和整个薄膜网络传感响应的影响。

Result: 研究表明，Ti3C2Tx 网络中的电荷传输主要由片间结决定，其中单个薄片表现为等电位域，电压降集中在片间结。湿度传感动力学也受到这些结的显著影响。

Conclusion: 片间结在二维晶体网络（特别是 MXene）的电荷传输和传感能力中起着至关重要的作用，需要对其进行仔细研究以优化设备性能。

Abstract: Understanding charge transport in networks of two-dimensional crystals is essential for developing reliable applications such as chemiresistors or electromagnetic shields. For this purpose, intra- and inter-flake contributions to the network resistance must be disentangled. MXenes, such as Ti3C2Tx, are prime examples of 2D crystals often employed as thin networks of interconnected flakes deposited on substrates to realize functional devices. While a significant number of studies focused on transport in individual MXene flakes, inter-flake transport remains scarcely explored. Here, we demonstrate that charge transport in multi-flake conductive paths of Ti3C2Tx is dominated by interflake junctions and provide quantitative estimates of junction resistances. Scanning probe measurements reveal that in a MXene multi-flake conductive path, individual flakes behave as isopotential domains, since the voltage drop is localized precisely at the inter-flake junctions. We further investigate the chemiresistive response to humidity at the single flake, multi-flake and flake network scale, evidencing the leading impact of junctions on sensing kinetics. These findings underline the crucial role of junctions in charge transport and sensing capabilities of MXenes.

</details>


### [527] [Acoustically-Coupled MEMS Transducer Pairs with Loss and Gain](https://arxiv.org/abs/2511.12125)
*Samer Houri,Rachid Haouari,Bart P. Weekers,Veronique Rochus*

Main category: cond-mat.mes-hall

TL;DR: 本研究调查了浸入水中并通过流体介质声耦合的微机电超声换能器（MUT）对的动力学。


<details>
  <summary>Details</summary>
Motivation: 研究浸入水中并通过流体介质声耦合的微机电超声换能器（MUT）对的动力学，并探索耦合系数的形成。

Method: 制造和测量了一系列具有不同直径和间距的换能器对。对一个设备对施加增益反馈回路，研究了声耦合增益-损耗系统的动力学，并利用了精点的形成或霍普夫分岔来量化耦合系数。

Result: 研究了MUT换能器对的声耦合及其对间距的依赖性，并探索了精点的形成。

Conclusion: 本研究提供了对MUT换能器声耦合的实验研究，并对声耦合MEMS换能器中精点的形成进行了探索。

Abstract: This work treats the dynamics of pairs of microelectromechanical ultrasound transducers (MUTs) that are immersed in water and acoustically coupled through the fluid medium. A series of these transducer pairs with varying diameters (and thus resonance frequency) and pitch separation (and thus coupling strength) are fabricated and measured. The work presented here models and quantifies the open-loop coupling between the MEMS transducer pairs and its dependence on pitch. Furthermore, a gain feedback loop is systematically applied to one of the device pair and the dynamics of the acoustically-coupled gain-loss system is investigated, and the formation of an exceptional-point or of an Hopf bifurcation is equally used to quantify the coupling coefficient. This work provides an experimental study of acoustic coupling in MUT transducers, as well as an exploration of the formation of exceptional points in acoustically-coupled MEMS transducers.

</details>


### [528] [Fractional Chern Insulators Transition in Non-ideal Flat Bands of Twisted Mono-bilayer Graphene](https://arxiv.org/abs/2511.12231)
*Moru Song,Kai Chang*

Main category: cond-mat.mes-hall

TL;DR: 扭曲单层-双层石墨烯中的分数陈绝缘体(FCI)可以通过连续相变稳定，该相变由连续模型参数κ控制，并由Bloch波函数的几何不稳定性引起。


<details>
  <summary>Details</summary>
Motivation: 在现实的摩尔体系中，非理想的量子几何会使分数陈绝缘体(FCI)的稳定机制复杂化，导致其稳定机制尚不完全清楚。

Method: 使用扭曲单层-双层石墨烯(tMBG)作为平台，通过改变连续模型参数κ来研究FCI的形成和稳定机制，并引入弱垂直磁场作为“颜色分离器”来可视化理想子组件。

Result: 观察到两个FCI，它们由一个连续相变连接，该相变由连续模型参数κ控制。在相变以下，目标C=2传导带在几何上是稳定的，可以分解为两个独立的C=1颜色扇区，并由非手性Halperin-(112)态解释。相变以上，系统进入Laughlin-1/3相。该图像通过引入颜色分离机制得到证实，其中相互作用将非理想的平坦能带动态地分裂成一个理想的子组件和一个或多个非理想的残余组件。

Conclusion: 已确定两种由非理想平坦能带稳定FCI的途径，扩展了其可行的参数空间，并阐明了几何与拓扑阶之间的相互作用。

Abstract: Fractional Chern insulators (FCIs) in ideal $|C|>1$ flat bands can be viewed as color-entangled composites of $C$ lowest Landau levels, but in realistic moiré systems non-ideal quantum geometry complicates this picture, leaving their stabilization mechanism incompletely understood. Using twisted monolayer-bilayer graphene (tMBG) as a platform, we observe two FCIs joined by a continuous transition controlled by continuum model parameter $κ$, arising from a geometric instability of the Bloch wave functions. For $κ$ below the transition, the target $C=2$ conduction band is geometrically stable and effectively decomposes into two independent $C=1$ color sectors. Although the flat band is non-ideal, the resulting fractional phase is naturally accounted for by the non-chiral Halperin-(112) state with counterpropagating edge modes. Above the transition, the system enters a Laughlin-$1/3$ phase that persists despite further degradation of quantum-geometry indicators. To account for this robustness, we propose a color-separation mechanism beyond global geometric indicators: when the Bloch wave function is geometrically unstable, interactions dynamically split a non-ideal flat band into an ideal subcomponent that hosts the FCI and non-ideal remnants. We corroborate this picture by applying a weak perpendicular magnetic field that acts as a "color separator," explicitly visualizing the ideal subcomponent at the single-particle level. Together, these results establish two different routes by which non-ideal flat bands stabilize FCIs, expanding their viable parameter space and clarifying the interplay between geometry and topological order.

</details>


### [529] [Direct vs. Indirect Measurement of the Effective Electronic Temperature in Quantum Dot Solids](https://arxiv.org/abs/2511.12307)
*Anton Kompatscher,Morteza Shokrani,Johanna Feurstein,Martijn Kemerink*

Main category: cond-mat.mes-hall

TL;DR: 非晶半导体中载流子在光吸收或高电场下的热化过程很慢，这会影响其电导率。本文研究了在量子点固体（以氧化锌为例）中，场依赖的有效电子温度T_eff是否适用。


<details>
  <summary>Details</summary>
Motivation: 文章旨在验证有效电子温度T_eff概念在量子点固体中的适用性，并结合直接和间接测量手段来确认T_eff的物理真实性。

Method: 通过测量氧化锌量子点固体的电导率变化，计算得到T_eff，并将其与通过塞贝克效应直接测量的电子温度进行比较。

Result: 研究结果证实了有效电子温度T_eff概念在量子点固体中的适用性，并表明T_eff的测量值与塞贝克效应的测量值一致。

Conclusion: 有效电子温度T_eff概念不仅适用于量子点固体，而且具有普遍的物理现实意义，为进一步研究无序介质中的电荷载流子（去）局域化打开了新的途径。

Abstract: One of the characteristics of disordered semiconductors is the slow thermalization of charge carriers after excitation due to photoabsorption or high electric fields. An elegant way to capture the effects of the latter on the conductivity is through a field-dependent effective electronic temperature T_eff that can significantly exceed that of the lattice. Despite its elegance, its actual use has been limited, which, at least in part, can be attributed to the concept originating from computer simulations; experimental confirmations have largely been indirect (through scaling of conductivity) and did not establish that T_eff equals the real temperature of the electron distribution. Moreover, it has hardly been tested for important classes of disordered materials, including quantum dot solids. Here, we investigate whether the effective temperature concept is applicable to quantum dot solids, using zinc oxide as relevant model system. To verify that field-driven conductivity increases indeed reflect an actual increase of the electronic temperature, we combine direct and indirect measurements of T_eff: we convert conductivity changes at high fields to an effective temperature that we show to be consistent with a direct measurement of the electronic temperature using the Seebeck effect. These results not only confirm the relevance of the effective temperature concept to quantum dot solids but also confirm its general physical reality and open the way to systematic investigations into charge carrier (de)localization in disordered media.

</details>


### [530] [Deterministic Switching of Perpendicular Ferromagnets by Higher-order Spin-orbit Torque in Noncentrosymmetric Weyl Semimetals](https://arxiv.org/abs/2511.12324)
*Naomi Fokkens,Fei Xue*

Main category: cond-mat.mes-hall

TL;DR: 在不破坏对称性的情况下，可以通过高阶自旋-轨道力矩确定性地切换垂直铁磁体。


<details>
  <summary>Details</summary>
Motivation: 实现无外场驱动的确定性磁化切换，以应对自旋电子学应用的挑战。

Method: 利用矢量球谐函数展开，证明高阶力矩项能产生额外的赤道外固定点，从而实现可靠的磁化反转。通过第一性原理计算，在非中心对称的Weyl铁磁体PrAlGe中说明了这一机制。

Result: 在PrAlGe中，由于Weyl节点带拓扑和强自旋-轨道耦合，产生了显著的高阶自旋-轨道力矩分量。这些高阶力矩与相对较弱的低阶力矩竞争，重塑磁化动力学，实现了确定性切换。

Conclusion: 高阶自旋-轨道力矩是理解和控制拓扑及自旋电子材料中磁化动力学的关键因素。

Abstract: Field-free deterministic switching of perpendicular ferromagnets is a central challenge for spintronics applications, typically requiring explicit symmetry breaking. Here we show that deterministic switching can instead be achieved through higher-order (in magnetization angles) spin-orbit torques, even in systems that preserve in-plane mirror symmetry. Using a vector spherical harmonics expansion, we demonstrate that higher-order torque terms naturally give rise to additional out-of-equator fixed points, enabling reliable magnetization reversal when their magnitude is comparable to conventional lowest-order torques. We illustrate this mechanism with first-principles calculations on the noncentrosymmetric Weyl ferromagnet PrAlGe, where the combination of Weyl-node band topology and strong spin-orbit coupling produces sizable higher-order torque components. Because the Fermi surface is small, the conventional lowest-order torques are relatively weak, allowing the higher-order harmonics to compete on equal footing and strongly reshape the magnetization dynamics. The resulting spin dynamics confirm deterministic switching without additional symmetry breaking. Our results establish higher-order spin-orbit torque as a key ingredient for understanding and controlling magnetization dynamics in topological and spintronic materials.

</details>


### [531] [Topological Valley Transport in Bilayer Graphene Induced by Interlayer Sliding](https://arxiv.org/abs/2511.12427)
*Jie Pan,Huanhuan Wang,Lin Zou,Xiaoyu Wang,Lihao Zhang,Xueyan Dong,Haibo Xie,Yi Ding,Yuze Zhang,Takashi Taniguchi,Kenji Watanabe,Shuxi Wang,Zhe Wang*

Main category: cond-mat.mes-hall

TL;DR: Bilayer graphene's interlayer sliding, controlled by bending, creates topological states and valley transport, which can be used to tune electronic properties.


<details>
  <summary>Details</summary>
Motivation: Interlayer sliding and twist angle are crucial for 2D material homobilayer properties. This paper explores the effect of interlayer sliding on bilayer graphene.

Method: Theoretically demonstrated interlayer sliding-induced Berry curvature reversals and topological states. Experimentally realized sliding by bending bilayer graphene across a nanoridge and performed electronic transport measurements.

Result: Observed topological valley transport when the Fermi energy is in the band gap, consistent with theoretical predictions of eight topological channels.

Conclusion: Interlayer sliding is a powerful tool for tuning bilayer graphene's electronic properties and has potential for other 2D material systems.

Abstract: Interlayer sliding, together with twist angle, is a crucial parameter that defines the atomic registry and thus determines the properties of two-dimensional (2D) material homobilayers. Here, we theoretically demonstrate that controlled interlayer sliding in bilayer graphene induces Berry curvature reversals, leading to topological states confined within a one-dimensional moiré channel. We experimentally realize interlayer sliding by bending the bilayer graphene geometry across a nanoridge. Systematic electronic transport measurements reveal topological valley transport when the Fermi energy resides within the band gap, consistent with theoretical predictions of eight topological channels. Our findings establish interlayer sliding as a powerful tool for tuning the electronic properties of bilayer graphene and underscore its potential for broad application across 2D material systems.

</details>


### [532] [Electron Tunneling Enhances Thermal Conductance through Metal-Insulator-Semiconductor Junctions](https://arxiv.org/abs/2511.12604)
*Yizhe Liu,Bo Sun*

Main category: cond-mat.mes-hall

TL;DR: 电子热隧穿效应显著提升界面热导，且不依赖界面结构。


<details>
  <summary>Details</summary>
Motivation: 半导体器件中的界面显著阻碍热传输，但现有技术难以在不改变界面结构的情况下提升界面热传输。

Method: 通过光激发或偏置电压，利用电子量子隧穿效应开辟新的热传输通道，并建立隧道失配模型描述增强的热导。

Result: 在金属-绝缘体-半导体结中，通过光激发或偏置电压观察到显著的热导增加，证明了电子热隧穿效应的存在。

Conclusion: 电子热隧穿是一种新的界面热传输机制，可以有效提高界面热导，且不依赖界面结构，并强调了理解半导体在实际工作条件下的热特性至关重要。

Abstract: The presence of interfaces in semiconductor devices substantially hinders thermal transport, contributing disproportionately to the overall thermal resistance. However, approaches to enhance interfacial thermal transport remain scarce without changing the interface structure, as the intrinsic electron and phonon properties of constituent materials set an upper limit. Here, we find a new thermal transport pathway, electronic heat tunneling, to enhance interfacial thermal conductance through metal-insulator-semiconductor junctions. By applying photoexcitation or bias voltage, we observe remarkable thermal conductance increases in operando, opening a new channel for efficient interfacial heat dissipation. The electron quantum tunneling pathway is parallel to conventional phonon-mediated interfacial thermal transport, and violates the Wiedemann-Franz law since this pathway deviates from the paradigm of diffusive transport. Moreover, we develop a tunneling mismatch model to describe the enhanced thermal conductance, originating from tunneling heat flux. Our Letter demonstrates a previously unexplored heat transport mechanism to enhance thermal conductance, bypassing the need for interface engineering. These findings emphasize the essential need to understand semiconductor thermal properties under realistic operating conditions.

</details>


### [533] [Inverse determination of light-matter coupling in disordered systems from transmittance spectra](https://arxiv.org/abs/2511.12647)
*Thales F. Macedo,Julián Faúndez,Antônio S. Coelho,Caio Lewenkopf,Mauro S. Ferreira,Felipe A. Pinheiro,Natanael C. Costa*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了强耦合到光学腔的一维电子无序系统中的量子逆问题，并提出了一种从透射光谱中提取电子-光子耦合强度的逆算法。


<details>
  <summary>Details</summary>
Motivation: 研究强耦合到光学腔的一维电子无序系统中的量子逆问题，并提出一种从透射光谱中提取电子-光子耦合强度的逆算法。

Method: 使用非平衡格林函数形式主义，并实现了一种基于反演的方法来提取电子-光子耦合强度。

Result: 安德森模型中的腔耦合作用较小，参数估计宽泛但精确；而奥布里-安德烈-哈珀模型中，腔耦合导致了更显著的光谱变化，使得反演解更加精确。

Conclusion: 量子逆问题为量子材料提供了一种强大的诊断工具，对于表现出金属-绝缘体转变的系统尤其有效。

Abstract: We investigate quantum inverse problems in one-dimensional (1D) electronic disordered systems strongly coupled to optical cavities. More specifically, we consider the Anderson and the Aubry-Andre-Harper models connected to electronic reservoirs and embedded in a single-mode optical cavity. The light-matter interaction enables photon-assisted hopping processes that significantly modify the transmittance spectrum. Within the nonequilibrium Green's function formalism, we implement an inversion-based approach capable of accurately extracting the electron-photon coupling strength directly from transmittance spectra. While cavity coupling acts as a minor perturbation within the Anderson model, yielding broad yet precise parameter estimates, its influence is markedly different in the Aubry-André-Harper model. The latter exhibits a sharp metal-insulator transition in 1D, thus resulting in more pronounced cavity-induced spectral changes. This renders even more accurate inverse solutions, offering unparalleled precision in the characterization of low-dimensional disordered systems. Altogether, our results demonstrate that the quantum inverse problem provides a robust diagnostic tool for quantum materials, particularly effective for systems exhibiting metal-insulator transitions.

</details>


### [534] [Bloch diode](https://arxiv.org/abs/2511.12719)
*M. Houzet,T. Vakhtel,J. S. Meyer*

Main category: cond-mat.mes-hall

TL;DR: SQUID 和 Cooper 对晶体管中存在非互易性效应，表现为临界电流或电压的不对称性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨 SQUID 和 Cooper 对晶体管中的 Josephson 二极管效应及其变体，即 Bloch 二极管效应，并提出实现 Bloch 二极管效应的方案。

Method: 研究了 SQUID 和 Cooper 对晶体管的电流-电压特性，分析了多重 Josephson 谐波、结不对称性以及 Bloch 谱带不对称性在产生非互易性效应中的作用。

Result: 1. SQUID 在偏离半整数磁通量时表现出 Josephson 二极管效应，表现为临界电流的不对称性。 2. 提出了一种 Bloch 二极管效应，在 Cooper 对晶体管偏离半整数栅电荷时，表现为临界电压的不对称性。 3. 建议使用 Josephson 结阵列来实现 Bloch 二极管效应。

Conclusion: Josephson 二极管效应和 Bloch 二极管效应都是由非互易性引起的，并且可以在超导量子电路中实现。

Abstract: In a SQUID tuned away from half-integer flux (in units of the superconducting flux quantum), the concurrence of multiple Josephson harmonics and an asymmetry between the junctions leads to the Josephson diode effect -- a nonreciprocal current-voltage characteristic manifested as an asymmetry of critical currents at opposite polarities. We predict a dual version of this effect in a gate-tunable Cooper pair transistor placed in series with a highly resistive environment. When tuned away from half-integer gate charge (in units of the Cooper pair charge) it shows an asymmetry of critical voltages at opposite polarities -- a dual diode effect we refer to as the Bloch diode effect. It arises from an asymmetry in the dispersion of the transistor's Bloch bands. A highly resistive environment can be realized with a Josephson junction array, suggesting that such a diode could be implemented using conventional superconducting quantum circuits.

</details>


### [535] [Tunneling in multi-site mesoscopic quantum Hall circuits](https://arxiv.org/abs/2511.12933)
*D. B. Karki*

Main category: cond-mat.mes-hall

TL;DR: The study analyzes transport properties of multi-site quantum Hall (QH) circuits, finding unique quantum critical behaviors in four-site circuits and exploring tunneling phenomena in multichannel QH circuits.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the transport properties of multi-site QH circuits, especially those with four or more sites, and to investigate their unique quantum critical behaviors and tunneling phenomena.

Method: The paper exploits the mapping to the boundary sine-Gordon model and analyzes backscattering perturbations in single- and two-site QH circuits. It then extends this analysis to multi-site circuits, with a special focus on four-site circuits, to explore their transport properties and quantum critical behaviors.

Result: The results indicate that higher-order backscattering processes, which are exactly marginal in three-site circuits, become crucial in four or more site circuits, leading to unique quantum critical behaviors. Tunneling phenomena in multichannel QH circuits are also investigated.

Conclusion: The paper offers a promising route to realizing different aspects of quantum critical phenomena through the study of multi-site QH circuits and their unique quantum critical behaviors and tunneling phenomena.

Abstract: Transport properties of the single- and two-site mesoscoipc quantum Hall (QH) circuits at high transparencies can be described in terms of the lowest-order backscattering perturbations, and mapping to the boundary sine-Gordon model can be exploited in full generality. While the higher-order backscattering processes are exactly marginal in the case of corresponding three-site circuits, they become crucial in a device with four or more sites. Here, we explore the transport properties of a multi-site QH circuit with special focus on that with four sites, and report their unique quantum critical behaviors that can be accessed via transport measurements. Tunneling phenomena in multichannel QH circuits based on multi-site geometry are also investigated, and a promising route to realizing different aspects of quantum critical phenomena is offered

</details>


### [536] [Signatures of magnetism in zigzag graphene nanoribbon embedded in h-BN lattice](https://arxiv.org/abs/2511.13075)
*Chengxin Jiang,Hui Shan Wang,Chen Chen,Lingxiu Chen,Xiujun Wang,Yibo Wang,Ziqiang Kong,Yuhan Feng,Yixin Liu,Yu Feng,Chenxi Liu,Yu Zhang,Zhipeng Wei,Maosen Guo,Aomei Tong,Gang Mu,Yumeng Yang,Kenji Watanabe,Takashi Taniguchi,Wangzhou Shi,Haomin Wang*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯锯齿边缘因费米能级附近的磁性电子态而具有独特的自旋电子学潜力，但此前尚未有实验报道。本研究首次在氮化硼（h-BN）基底的锯齿形石墨烯纳米带（zGNRs）中观测到磁性特征。


<details>
  <summary>Details</summary>
Motivation: 观测石墨烯锯齿边缘的磁性电子态，探索其在自旋电子学中的应用潜力。

Method: 利用扫描NV色心显微镜确认zGNRs的磁性；制备宽约9 nm，沟道长度小于50 nm的zGNRs晶体管；在4开尔文下进行磁输运测量，观察法布里-珀罗干涉和磁阻效应；研究磁阻效应的磁场方向各向异性及其温度依赖性。

Result: 成功观测到zGNRs的磁性；在低温下观察到法布里-珀罗干涉，表明沟道内的相干输运；观测到约175欧姆的磁阻效应，相对变化约为1.3%；发现磁输运信号具有显著的磁场方向各向异性，且该信号存在于高于室温的温度下。

Conclusion: 实验证实了zGNRs边缘态具有鲁棒的磁有序性，并且嵌入h-BN的zGNRs为未来探索石墨烯基自旋电子器件提供了有效的平台。

Abstract: Zigzag edges of graphene have long been predicted to exhibit magnetic electronic state near the Fermi level, which can cause spin-related phenomena and offer unique potentials for graphene-based spintronics. However, the magnetic conduction channels along these edges have yet been reported experimentally. Here, we report the observation on signatures of magnetism in zigzag graphene nanoribbons (zGNRs) embedded in hexagonal boron nitride (h-BN). The in-plane bonding with BN can stabilize the edges of zGNRs, and thus enable a direct probing of the intrinsic magnetism. Firstly, the presence of magnetism of a zGNR was confirmed by scanning NV center microscopy. And then, zGNR was fabricated into a transistor with a width of ~9 nm wide and a channel length of sub-50 nm. By performing magneto-transport measurements, Fabry-Pérot interference patterns were observed in the transistor at 4 Kelvin, which indicates a coherent transport through the channel. A large magnetoresistance of ~175 Ω, corresponding to a ratio of ~1.3 %, was observed at the same temperature. More importantly, such magneto-transport signal is highly anisotropic on the magnetic field direction, and its appearance extends well above room temperature. All these evidences corroborate the existence of robust magnetic ordering in the edge state of zGNR. The findings on zGNR embedded in h-BN provide an effective platform for the future exploration of graphene-based spintronic devices.

</details>


### [537] [Numerical investigation of electrostatically confined excitons in monolayer $\text{MoSe}_2$](https://arxiv.org/abs/2511.13177)
*Lefan Dolg,Moritz Scharfstädt,Andrea Bergschneider,Dante M. Kennes,Silvia Viola-Kusminskiy*

Main category: cond-mat.mes-hall

TL;DR: 通过p-i-n结的量子限制来实现单分子层MoSe2中的激子限制，并对限制态的光谱进行了研究。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索单分子层MoSe2中激子在p-i-n结量子限制下的行为，并为理解和利用受限激子态提供理论支持。

Method: 采用有效质量激子模型，并结合考虑了实验装置几何形状的数值求解方法，以研究整个受限态光谱。

Result: 研究发现了明亮态和暗淡态激子，其中暗淡态具有微小但有限的振动子强度。该模型能够重现近期实验中测量的亮态激子光谱。

Conclusion: 本研究为理解受限激子态（包括基态以上）提供了理论见解，并为开发新的限制方案和探测未被发现的暗态开辟了道路。

Abstract: We investigate exciton confinement to a quantum wire in monolayer $\text{MoSe}_2$ where the confinement is achieved by a p-i-n junction. We employ an effective-mass exciton model and solve the problem numerically, reflecting device geometries found in experimental state-of-the-art set up. Our method allows us to investigate the entire spectrum of confined states. We show the emergence of quantum confinement and study the dependence of the confined states as a function of electrical gate voltages, which are experimentally tunable parameters. We find that the confined states can be divided into bright and dark states with the dark states having small but finite oscillator strengths. Their oscillator strengths are low enough that they have not yet been detected in experiments, whereas the spectrum of the bright exciton states reproduces recent experimental measurements. Our results provide insight into the theoretical background of confined exciton states beyond the ground state and pave the way for the development of new confinement schemes as well as avenues to access the previously not detected dark states.

</details>


### [538] [Nontrivial flat bands and quantum Hall crossovers in square-octagon lattice materials](https://arxiv.org/abs/2511.13349)
*Amrita Mukherjee,Rahul Verma,Pritesh Srivastava,Bahadur Singh*

Main category: cond-mat.mes-hall

TL;DR: 本研究探索了具有非平凡拓扑和电子平坦带的方格-八边形晶格，并考虑了自旋-轨道耦合和磁通量的影响。


<details>
  <summary>Details</summary>
Motivation: 研究方格-八边形晶格中固有的自旋-轨道耦合（SOC）和 the staggered magnetic flux 对其拓扑和能带特性的影响。

Method: 使用包含 SOC 和磁通量的紧束缚模型对该晶格进行研究。

Result: 发现了量子自旋霍尔相（Cs=1）、量子反常霍尔相（C=1 和 C=2）以及具有量化四极角电荷的高阶拓扑绝缘体相。最初的平带演变成具有均匀量子几何和高平坦度比的准平带，有利于分数陈绝缘体态。

Conclusion: 确定了具有潜在实现可调谐拓扑相和能带物理的材料候选物，如辛烯、过渡金属二卤化物、合成 MoSi2N4 和磁性 α-MnO2，为量子关联拓扑物质开辟了新途径。

Abstract: Coexistence of nontrivial topology and flat electronic bands in low-energy lattices provides a fertile platform for correlated quantum states. The square-octagon lattice hosts Dirac nodes and flat bands at half-filling, yet the influence of intrinsic spin-orbit coupling (SOC) and staggered magnetic flux on its topological and flat-band properties remains largely unexplored. Here, we examine this lattice using tight-binding models that include SOC and magnetic flux, uncovering a quantum spin Hall phase with spin Chern number $C_s=1$, crossovers to quantum anomalous Hall phases with $C=1$ and $C=2$, and higher-order topological insulator phases carrying quantized quadrupolar corner charges. The initially dispersionless flat bands evolve into quasi-flat, topologically nontrivial bands with uniform quantum geometry and large flatness ratios, conducive to fractional Chern insulator states. We further identify realistic material candidates, including octagraphene, transition-metal dichalcogenides, synthetic $\mathrm{MoSi_2N_4}$, and magnetic $α$-MnO$_2$, as potential candidates for realizing tunable topological phases intertwined with flat-band physics, opening new opportunities for correlated topological matter.

</details>


### [539] [A High-Efficiency Three-Stroke Quantum Isochoric Heat Engine: From Infinite Potential Wells to Magic Angle Twisted Bilayer Graphene](https://arxiv.org/abs/2511.13652)
*Hadi Mohammed Soufy,Colin Benjamin*

Main category: cond-mat.mes-hall

TL;DR: 我们提出了一种三冲程量子等容循环，可作为在两个热库之间运行的热机。它在量子体系中优于经典和之前的量子模型，特别是在魔角扭曲双层石墨烯（MATBG）中表现出色。


<details>
  <summary>Details</summary>
Motivation: 量子热力学器件的控制复杂性高，难以实现。本研究旨在设计一种更简单、更高效的量子热机循环，并探索其实验可行性。

Method: 提出并实现了一个三冲程量子等容循环，并在量子体系（一维无限深势阱、石墨烯体系）中进行了分析和性能评估，与经典模型和之前的量子模型进行了比较。

Result: 量子等容循环的效率优于经典三冲程三角和等容发动机，也优于三冲程量子等能循环。在石墨烯体系中，魔角扭曲双层石墨烯（MATBG）在固定功输出下效率最高。

Conclusion: 三冲程量子等容循环因其结构简单，控制复杂度低，在量子热力学器件的实验实现方面比传统四冲程结构更具优势。魔角扭曲双层石墨烯（MATBG）是量子热力学应用的有前景平台。

Abstract: We introduce a three-stroke quantum isochoric cycle that functions as a heat engine operating between two thermal reservoirs. Implemented for a particle confined in a one-dimensional infinite potential well, the cycle's performance is benchmarked against the classical three-stroke triangular and isochoric engines. We find that the quantum isochoric cycle achieves a higher efficiency than both classical counterparts and also surpasses the efficiency of the recently proposed three-stroke quantum isoenergetic cycle. Owing to its reduced number of strokes, the design substantially lowers control complexity in nanoscale thermodynamic devices, offering a more feasible route to experimental realization compared to conventional four-stroke architectures. We further evaluate the cycle in graphene-based systems under an external magnetic field, including monolayer graphene (MLG), AB-stacked bilayer graphene (BLG), and twisted bilayer graphene (TBG) at both magic and non-magic twist angles. Among these platforms, magic-angle twisted bilayer graphene (MATBG) attains the highest efficiency at fixed work output, highlighting its promise for quantum thermodynamic applications.

</details>


### [540] [Spin Accumulation based deep MOKE Microscopy](https://arxiv.org/abs/2511.13468)
*Jean Rodriguez,Holger Grisk,Alberto Anadón,Harjinder Singh,Gregory Malinowski,Michel Hehn,Javier Curiale,Jon Gorchon*

Main category: cond-mat.mes-hall

TL;DR: 提出一种基于自旋积累的磁光克尔效应显微镜技术，可用于成像被厚而不透明金属层覆盖的磁性薄膜。


<details>
  <summary>Details</summary>
Motivation: 光学技术在成像深埋层时失效，需要一种新的成像技术。

Method: 通过光激发和探测瞬态自旋积累来成像磁性薄膜。

Result: 所提出的SA-MOKE技术能够成像高达数百纳米的铜覆盖层下的磁性薄膜，远超光学穿透深度。

Conclusion: 该SA-MOKE技术能够克服光学技术的局限性，为包含电极的表面材料的磁性成像提供一种新的解决方案。

Abstract: Magnetic imaging techniques are widespread critical tools used in fields such as magnetism, spintronics or even superconductivity. Among them, one of the most versatile methods is the magneto-optical Kerr effect. However, as soon as light is blocked from interacting with the magnetic layer, such as in deeply buried layers, optical techniques become ineffective. In this work, we present a spin-accumulation based magneto-optical Kerr effect (SA-MOKE) microscopy technique that enables imaging of a magnetic thin-films covered by thick and opaque metallic layers. The technique is based on the generation and detection of transient spin-accumulations that propagate through the thick metallic layer. These spin-accumulation signals are directly triggered and detected optically on the same side, lifting any substrate transparency requirements. The spin-accumulation signals detected on a Cu layer decay with a characteristic length of 60 nm, much longer than the 12 nm optical penetration depth, allowing for detection of magnetic contrast with Cu capping layers up to hundreds of nm. This method should enable magnetic imaging in a wide-range of experiments where the surface of interest is covered by electrodes.

</details>


### [541] [Tuning of Weyl point emergence in multi-terminal Josephson junctions using quantum point contacts](https://arxiv.org/abs/2511.13493)
*Kento Takemura,Mikio Eto,Tomohiro Yokoyama*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了一种包含量子点接触结构的多终端约瑟夫森结，理论上研究了增加通道数对韦尔点出现概率的影响，发现增加通道数可以显著提高韦尔点的出现概率，但通道数不平衡会抑制这种提高。


<details>
  <summary>Details</summary>
Motivation: 多端约瑟夫森结是调控奇异电子态的有吸引力的量子系统，特别是四端约瑟夫森结可以在无需外延材料的情况下出现拓扑保护的零能态（韦尔物理）。

Method: 本文理论研究了在四端约瑟夫森结中，通过量子点接触结构调节超导端与介观正常区之间的导电通道数量，并分析通道数变化对韦尔点出现概率的影响。

Result: 增加导电通道数量会增加系统中的安德烈结束态数量，进而提高韦尔点出现的概率。当所有端点都具有两个通道时，出现概率可达17%，是单通道结的四倍。然而，当通道数量不平衡时，出现概率的增加会被抑制。

Conclusion: 通过量子点接触结构调控多端约瑟夫森结的导电通道数量，可以有效调控韦尔点的出现概率，为实现和利用韦尔物理提供了新的途径。

Abstract: Multi-terminal Josephson junction with three or more superconductors is an attractive quantum system to emerge and tune exotic electronic states. In four terminal Josephson junctions, the Weyl physics, namely topologically protected zero energy state, emerges without assuming any exotic materials. In this study, we consider the four-terminal Josephson junction with the quantum point contact structures between the mesoscopic normal region and four superconducting terminals. The quantum point contacts can tune electrically the number of conduction channels. We theoretically investigate an effect of the increase of channels on the emergence of Weyl points. The increase of channels causes the increase of Andreev bound states in the system, which increase the emergence probability of Weyl points. When all terminals have two channels, the emergence probability is up to 17\%, which is about four times larger than that for all single channel junctions. We consider the balance of the number of conduction channels in the four terminals. When the number of channels is unbalanced, the increase of emergence probability is suppressed.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [542] [Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy](https://arxiv.org/abs/2511.11816)
*Andrea Brunello,Luca Geatti,Michele Mignani,Angelo Montanari,Nicola Saccomanno*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在自然语言到一阶逻辑（NL-FOL）翻译方面表现出强大的能力，尤其是在新的评估协议下，能够区分真正的语义理解和表面模式识别，而以嵌入为中心的模型表现较差。


<details>
  <summary>Details</summary>
Motivation: 自然语言到一阶逻辑（NL-FOL）翻译是一个长期存在的挑战，尽管大型语言模型（LLMs）的出现带来了希望，但现有文献对其能力的评估结果不一，需要更准确的评估方法。

Method: 提出了一种新的评估协议，旨在区分真正的语义理解和表面模式识别、记忆及数据集污染，并使用该协议评估了两种类型的LLMs（对话型和以嵌入为中心型）。

Result: 新的评估结果显示，对话型LLMs在NL-FOL翻译方面表现出强大的能力和对句子级逻辑的真正理解，而以嵌入为中心的模型表现明显较差。

Conclusion: 尽管存在挑战，但经过改进的评估方法表明，先进的对话型LLMs在NL-FOL翻译任务上具有真正的逻辑理解能力。

Abstract: Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.

</details>


### [543] [Looking Forward: Challenges and Opportunities in Agentic AI Reliability](https://arxiv.org/abs/2511.11921)
*Liudong Xing,Janet,Lin*

Main category: cs.AI

TL;DR: 本章探讨了构建可靠的人工智能系统（特别是代理AI系统）的挑战和未来发展方向，讨论了与减少级联故障风险相关的开放性研究问题，并关注了动态环境、不一致的任务执行、不可预测的涌现行为以及资源密集型可靠性机制等方面的研究挑战和机遇。此外，还讨论了几种测试和评估代理AI系统可靠性的研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨构建可靠的AI系统（特别是代理AI系统）所面临的挑战和未来发展方向，重点关注减少级联故障风险、应对动态环境、不一致的任务执行、不可预测的涌现行为以及资源密集型可靠性机制等问题。

Method: 通过讨论与减少级联故障风险相关的开放性研究问题，以及在动态环境、不一致的任务执行、不可预测的涌现行为和资源密集型可靠性机制等方面的研究挑战和机遇，并探讨测试和评估代理AI系统可靠性的研究方向。

Result: 本章提出了在构建可靠的AI系统（特别是代理AI系统）方面的挑战和未来发展方向，并讨论了相关的研究问题、挑战、机遇和研究方向。

Conclusion: 构建可靠的AI系统，特别是代理AI系统，面临着多方面的挑战，包括减少级联故障风险、适应动态环境、确保一致的任务执行、控制不可预测的涌现行为以及优化资源密集型的可靠性机制。未来的研究应关注这些领域，并探索有效的测试和评估方法，以提高代理AI系统的可靠性。

Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.

</details>


### [544] [MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications](https://arxiv.org/abs/2511.13131)
*Gagan Raj Gupta,Anshul Kumar,Manish Rai,Apu Chakraborty,Ashutosh Modi,Abdelaali Chaoub,Soumajit Pramanik,Moyank Giri,Yashwanth Holla,Sunny Kumar,M. V. Kiran Sooraj*

Main category: cs.AI

TL;DR: MM-Telco 是一个包含文本和图像任务的基准套件，旨在帮助将大型语言模型（LLM）应用于电信领域。它还包括对当前多模态 LLM 的分析，以指导未来的研究。


<details>
  <summary>Details</summary>
Motivation: 电信行业面临着部署大型语言模型的特定挑战，需要专门的适应。MM-Telco 旨在通过提供量身定制的基准和模型来克服这些挑战。

Method: MM-Telco 基准套件包含各种文本和图像任务，以解决电信领域的实际用例，例如网络运营、网络管理、文档质量改进和相关文本/图像检索。我们还对各种 LLM 和 VLM 进行了基线实验。

Result: 在 MM-Telco 数据集上进行微调的模型在性能上有了显著提升。实验还揭示了当前最先进的多模态 LLM 的薄弱环节。

Conclusion: MM-Telco 证明了针对电信领域进行微调可以显著提高多模态 LLM 的性能，并为该领域的进一步研究和开发提供了方向。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.

</details>


### [545] [Quantifying Skill and Chance: A Unified Framework for the Geometry of Games](https://arxiv.org/abs/2511.11611)
*David H. Silver*

Main category: cs.AI

TL;DR: 提出一个量化框架，通过将游戏建模为随机决策树的互补控制源，来区分技能和运气。


<details>
  <summary>Details</summary>
Motivation: 在游戏中分离技能和运气，以量化玩家的影响力、游戏平衡和预测稳定性。

Method: 通过将游戏结果分解为技能杠杆K和运气杠杆L，定义技能-运气指数S(G)在[-1, 1]之间。引入波动性Sigma来量化连续轮次中的结果不确定性。

Result: 将该框架应用于30种游戏，揭示了从纯运气（S=-1）到混合领域（如双陆棋，S=0）再到纯技能（如国际象棋，S=+1）的连续谱。扑克显示出中等技能优势（S=0.33）。

Conclusion: 该框架可扩展到一般随机决策系统，并可应用于游戏设计、人工智能评估和风险评估。

Abstract: We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.

</details>


### [546] [KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything](https://arxiv.org/abs/2511.12089)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: KrwEmd是一种用于解决德州扑克等游戏中过度抽象问题的算法，通过引入k-recall胜率特征和使用earth mover's distance进行聚类，有效提升了AI在复杂游戏中的表现。


<details>
  <summary>Details</summary>
Motivation: 在德州扑克等游戏中，过度抽象（尤其是完全丢弃历史信息的无记忆抽象）会严重影响AI的性能，这是一个关键的挑战。

Method: 提出k-recall胜率特征，该特征利用未来和历史信息来区分和量化观察信息集之间的相似性。在此基础上，开发了KrwEmd算法，使用earth mover's distance来衡量特征差异并对观察信息集进行聚类。

Result: 实验结果表明，KrwEmd相比现有算法显著提升了AI的游戏性能。

Conclusion: KrwEmd是第一个解决大型不完美信息游戏中过度抽象问题的实用算法，通过结合历史和未来信息来改进AI的表现。

Abstract: Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.

</details>


### [547] [Multi-agent Self-triage System with Medical Flowcharts](https://arxiv.org/abs/2511.12439)
*Yujia Liu,Sophia Yu,Hongyue Jin,Jessica Wen,Alexander Qian,Terrence Lee,Mattheus Ramsis,Gi Won Choi,Lianhui Qin,Xin Liu,Edward J. Wang*

Main category: cs.AI

TL;DR: LLM驱动的AI分诊系统，结合了100个AMA流程图，达到了95%以上的分诊准确率，旨在提高医疗决策支持的透明度和效率。


<details>
  <summary>Details</summary>
Motivation: 在线健康资源和LLM在医疗决策中存在准确性低、透明度差、信息未经核实等问题。

Method: 提出一个多代理框架，包括检索代理、决策代理和聊天代理，利用100个AMA流程图来指导LLM进行患者自我分诊。

Result: 在模拟对话中，流程图检索的top-3准确率为95.29%（N=2,000），流程图导航的准确率为99.10%（N=37,200）。

Conclusion: 结合LLM的灵活性和标准化临床协议的严谨性，该方法展示了透明、准确、可泛化的AI辅助自我分诊的可行性，有望支持患者的明智决策并提高医疗资源利用率。

Abstract: Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.

</details>


### [548] [Adaptively Coordinating with Novel Partners via Learned Latent Strategies](https://arxiv.org/abs/2511.12754)
*Benjamin Li,Shuyang Shi,Lucia Romero,Huao Li,Yaqi Xie,Woojun Kim,Stefanos Nikolaidis,Michael Lewis,Katia Sycara,Simon Stepputtis*

Main category: cs.AI

TL;DR: 该研究提出了一种策略条件合作框架，用于实时学习、分类和适应异构团队成员的策略，以提高人机协作的有效性。


<details>
  <summary>Details</summary>
Motivation: 在人机协作中，特别是面临时间压力和复杂策略空间的任务时，让AI能够实时适应人类伙伴独特的、动态变化的偏好和策略是一个巨大的挑战。

Method: 该框架使用变分自编码器（VAE）来学习潜在策略空间，通过聚类识别不同的策略类型，并训练一个条件合作者。对于在线适应，采用了固定共享后悔最小化算法来动态推断和调整伙伴策略估计。

Result: 在修改后的Overcooked域（一个复杂的多人协作烹饪环境）中的实验以及在线用户研究表明，该方法在与新颖的人类或AI队友配对时，实现了比现有基线更优越的性能。

Conclusion: 提出的策略条件合作框架能够有效地学习、分类和适应潜在的伙伴策略，显著提高了在复杂协作任务中人机交互的性能，并在与新队友的交互中表现出色。

Abstract: Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.

</details>


### [549] [MedDCR: Learning to Design Agentic Workflows for Medical Coding](https://arxiv.org/abs/2511.13361)
*Jiyang Zheng,Islam Nassar,Thanh Vu,Xu Zhong,Yang Lin,Tongliang Liu,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: MedDCR是一个闭环框架，通过学习来设计医疗编码工作流，提高了自动化系统的可靠性和可信度。


<details>
  <summary>Details</summary>
Motivation: 医疗编码是将自由文本临床笔记转换为标准化诊断和程序代码的过程，这对于计费、医院运营和医学研究至关重要。与普通的文本分类不同，它需要多步骤推理，并且需要解决手动设计的工作流无法捕捉真实世界文档的细微差别和可变性的问题。

Method: MedDCR框架包含一个设计者（提出工作流）、一个编码者（执行工作流）和一个反思者（评估预测并提供反馈），并利用记忆库来保存先前设计以供重用和迭代优化。

Result: MedDCR在基准数据集上超越了最先进的基线，并产生了可解释、适应性强且更能反映实际编码实践的工作流。

Conclusion: MedDCR通过将工作流设计视为一个学习问题，提高了医疗编码自动化系统的可靠性和可信度。

Abstract: Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.

</details>


### [550] [Towards autonomous quantum physics research using LLM agents with access to intelligent tools](https://arxiv.org/abs/2511.11752)
*Sören Arlt,Xuemei Gu,Mario Krenn*

Main category: cs.AI

TL;DR: AI-Mandel是一个能够生成和执行量子物理学研究想法的LLM代理，能够加速科学发现并揭示通用人工智能的挑战。


<details>
  <summary>Details</summary>
Motivation: 自动化科学中的想法生成和执行，以转变人类在科学过程中的作用。

Method: AI-Mandel利用文献资料生成研究想法，并使用特定领域的AI工具将这些想法转化为可行的实验设计。

Result: AI-Mandel能够生成科学上有价值的想法，包括量子传送的新变体、不确定因果顺序中的量子网络原语，以及基于量子信息传输闭合循环的几何相位新概念。其中两个想法已促成独立的科学后续论文。

Conclusion: AI-Mandel展示了AI物理学家的原型，能够生成和执行具体的、可操作的想法，这不仅能加速科学发展，还能揭示实现类人人工智能科学家所面临的挑战。

Abstract: Artificial intelligence (AI) is used in numerous fields of science, yet the initial research questions and targets are still almost always provided by human researchers. AI-generated creative ideas in science are rare and often vague, so that it remains a human task to execute them. Automating idea generation and implementation in one coherent system would significantly shift the role of humans in the scientific process. Here we present AI-Mandel, an LLM agent that can generate and implement ideas in quantum physics. AI-Mandel formulates ideas from the literature and uses a domain-specific AI tool to turn them into concrete experiment designs that can readily be implemented in laboratories. The generated ideas by AI-Mandel are often scientifically interesting - for two of them we have already written independent scientific follow-up papers. The ideas include new variations of quantum teleportation, primitives of quantum networks in indefinite causal orders, and new concepts of geometric phases based on closed loops of quantum information transfer. AI-Mandel is a prototypical demonstration of an AI physicist that can generate and implement concrete, actionable ideas. Building such a system is not only useful to accelerate science, but it also reveals concrete open challenges on the path to human-level artificial scientists.

</details>


### [551] [Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation](https://arxiv.org/abs/2511.11693)
*Xin Zhao,Xiaojun Chen,Bingshan Liu,Zeyao Liu,Zhendong Zhao,Xiaoyan Gu*

Main category: cs.AI

TL;DR: VALOR是一个用于安全、有帮助的文本到图像生成的框架，它通过多层提示分析和对齐人类价值观的推理，能够有效检测并重写不安全或不恰当的内容，同时保持生成质量和用户意图。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型（如Stable Diffusion）在生成不安全、冒犯性或文化不当内容方面存在风险，而现有的防御措施在保证生成质量的同时，难以实现与人类价值观的对齐。

Method: VALOR是一个模块化的、零样本的智能体框架。它结合了分层提示分析和人类价值观推理：一个多层NSFW检测器过滤词汇和语义风险；一个文化价值观对齐模块识别社会规范、合法性和代表性伦理的违规行为；一个意图歧义消除器检测细微或间接的不安全含义。当检测到不安全内容时，由大型语言模型根据动态的、特定角色的指令重写提示，以在强制对齐的同时保留用户意图。如果生成的图像仍未通过安全检查，VALOR可以选择性地执行风格化再生，以引导输出朝着更安全的视觉领域发展，而不改变核心语义。

Result: 在对抗性、歧义性和价值敏感性提示的实验中，VALOR能够将不安全输出显著减少高达100.00%，同时保持提示的有用性和创造性。

Conclusion: VALOR为在开放世界环境中部署安全、对齐且有用的图像生成系统提供了一种可扩展且有效的方法。

Abstract: Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.

</details>


### [552] [TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models](https://arxiv.org/abs/2511.11831)
*Wenhao Zhou,Hao Zheng,Rong Zhao*

Main category: cs.AI

TL;DR: TopoPerception基准测试揭示了大型视觉语言模型(LVLM)在全局视觉感知方面存在严重缺陷，即使是最强大的模型也表现不佳，表明需要新的训练范式或架构。


<details>
  <summary>Details</summary>
Motivation: 评估大型视觉语言模型(LVLM)的全局视觉感知能力，解决现有基准测试中存在的局部捷径问题，并揭示当前LVLM的瓶颈。

Method: 提出TopoPerception基准测试，利用拓扑属性评估LVLM的全局视觉感知能力，并测试了最先进的模型。

Result: 在TopoPerception基准测试中，所有模型在最粗略的感知粒度上表现均不优于随机猜测，表明其缺乏全局视觉特征感知能力。模型能力越强，准确率越低。

Conclusion: 当前LVLM在全局视觉感知方面存在严重缺陷，仅仅扩大模型规模是不足以解决这个问题的，反而可能加剧问题。需要新的训练范式或架构来改进LVLM的全局视觉感知能力。TopoPerception基准测试为评估和改进LVLM的全局视觉感知提供了方向。

Abstract: Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.

</details>


### [553] [End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction](https://arxiv.org/abs/2511.11899)
*Xi Li,Nicholas Matsumoto,Ujjwal Pasupulety,Atharva Deo,Cherine Yang,Jay Moran,Miguel E. Hernandez,Peter Wager,Jasmine Lin,Jeanine Kim,Alvin C. Goh,Christian Wagner,Geoffrey A. Sonn,Andrew J. Hung*

Main category: cs.AI

TL;DR: F2O系统将手术视频转化为手势序列，识别与术后结果相关的模式，可用于手术反馈和临床决策支持。


<details>
  <summary>Details</summary>
Motivation: 分析术中行为及其对患者结局的影响是一个长期存在的挑战。

Method: 提出F2O系统，该系统将组织解剖视频转化为手势序列，并利用基于Transformer的时空建模和逐帧分类，检测机器人辅助根治性前列腺切除术中神经保留步骤的手势。

Result: F2O系统能够可靠地检测手势（帧级AUC：0.80；视频级AUC：0.81），其提取的特征（手势频率、持续时间和转换）在预测术后结局方面的准确性与人工标注相当（0.79 vs. 0.75）。25个共享特征显示出一致的效应大小方向（差异约0.07）和强相关性（r=0.96, p<1e-14）。F2O还识别出与勃起功能恢复相关的关键模式，如长时间组织剥离和减少能量使用。

Conclusion: F2O系统通过实现自动可解释的评估，为数据驱动的手术反馈和前瞻性临床决策支持奠定了基础。

Abstract: Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.

</details>


### [554] [Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models](https://arxiv.org/abs/2511.12008)
*Yunqi Hong,Johnson Kao,Liam Edwards,Nein-Tzu Liu,Chung-Yen Huang,Alex Oliveira-Kowaleski,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.AI

TL;DR: RECAP-PATH是一个可解释的框架，能够让AI在不进行白盒访问或权重更新的情况下，仅使用少量标记数据就能对癌症进行诊断，并提供与专家评估一致的解释，从而提高诊断准确性。


<details>
  <summary>Details</summary>
Motivation: AI在病理学领域的应用虽然提高了筛查通量、标准化了量化，并揭示了预后模式，但由于大多数系统缺乏人类可读的推理能力来审计决策和防止错误，因此推广应用仍然受限。

Method: RECAP-PATH框架采用两阶段学习过程：首先通过多样化扩展病理学风格的解释，然后通过优化来提高解释的准确性，从而自主推导出诊断标准。该方法仅需要少量标记数据，无需白盒访问或权重更新。

Result: 在乳腺癌和前列腺癌数据集上评估，RECAP-PATH生成的解释与专家评估一致，并在诊断准确性方面显著优于基线方法。

Conclusion: RECAP-PATH通过结合视觉理解和推理能力，提供了临床上值得信赖的AI，并展示了一条通往基于证据的解释的通用路径。

Abstract: AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.

</details>


### [555] [AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos](https://arxiv.org/abs/2511.12241)
*Junhyuk Seo,Hyeyoon Moon,Kyu-Hwan Jung,Namkee Oh,Taerim Kim*

Main category: cs.AI

TL;DR: 通过使用文本到视频扩散模型生成合成视频数据，开发了一个名为 AURA 的视觉风险检测系统，用于实时检测ICU中的意外拔管事件。


<details>
  <summary>Details</summary>
Motivation: 意外拔管（UE）是ICU患者安全的一个关键问题，但由于数据隐私和伦理问题，实时检测面临挑战。

Method: 提出了一种名为 AURA 的视觉风险检测系统，该系统利用姿态估计来识别两种高风险运动模式：碰撞（手进入气管附近的空间区域）和激动（通过跟踪的解剖关键点的速度量化）。该系统完全在完全合成的视频数据集上进行开发和验证，该数据集利用文本到视频扩散模型生成。

Result: 专家评估证实了合成数据的真实性，性能评估显示碰撞检测准确率高，激动识别性能中等。

Conclusion: 这项工作展示了一种开发可隐私保护、可重复的患者安全监控系统的新途径，有可能在重症监护环境中部署。

Abstract: Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.

</details>


### [556] [Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models](https://arxiv.org/abs/2511.12937)
*Guoyan Wang,Yanyan Huang,Chunlin Chen,Lifeng Wang,Yuxiang Sun*

Main category: cs.AI

TL;DR: Yanyun-3是一个通用的智能体框架，它首次实现了跨平台策略游戏的自主操作，整合了Qwen2.5-VL的视觉-语言推理能力和UI-TARS的精确执行能力，成功完成了目标定位、战斗资源分配和区域控制等核心任务。通过消融研究，我们发现融合多图像和视频数据并混合静态图像的混合策略（MV+S）显著优于完全融合，推理时间减少了63%，BLEU-4分数提高了12倍。该框架通过闭环流程实现了强大的实时性能和跨平台泛化能力，为策略游戏自动化提供了解决方案，并为增强VLM性能提供了新的范式。


<details>
  <summary>Details</summary>
Motivation: 自动化跨平台策略游戏需要智能体能够处理多样化的用户界面和动态战场条件。尽管视觉-语言模型（VLMs）在多模态推理方面展现出潜力，但它们在策略游戏等复杂人机交互场景中的应用仍有待探索。

Method: 开发了一个名为Yanyun-3的通用智能体框架，集成了Qwen2.5-VL的视觉-语言推理能力和UI-TARS的精确执行能力，实现了跨三个异构策略游戏环境的自主操作。通过消融研究评估了不同多模态数据组合（静态图像、多图像序列、视频）的影响，并提出了组合粒度概念来区分样本内融合和样本间混合策略。

Result: 混合策略（MV+S）显著优于完全融合，推理时间减少了63%，BLEU-4分数从4.81%提高到62.41%（约12.98倍）。该智能体通过闭环流程（屏幕捕获、模型推理、动作执行）展现了强大的实时性能和跨平台泛化能力。

Conclusion: Yanyun-3框架通过结构化的多模态数据组织，有效提升了VLM在策略游戏自动化中的性能，并为具身智能中静态感知与动态推理的相互作用提供了新的见解。该工作为策略游戏自动化提供了一个有效的解决方案，并建立了一个增强VLM性能的通用范式。

Abstract: Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.

</details>


### [557] [MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements](https://arxiv.org/abs/2511.13087)
*SeokJoo Kwak,Jihoon Kim,Boyoun Kim,Jung Jae Yoon,Wooseok Jang,Jeonghoon Hong,Jaeho Yang,Yeong-Dae Kwon*

Main category: cs.AI

TL;DR: MEGA-GUI是一个多阶段框架，通过区域选择和元素定位来改进GUI基础，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI基础系统缺乏模块化，在视觉混乱和指令模糊的情况下表现不佳。需要一种更强大的方法来提高准确性。

Method: MEGA-GUI采用多阶段方法，首先选择大的感兴趣区域（ROI），然后进行精细的元素定位。它使用双向ROI缩放算法来减少空间稀释，并使用上下文感知重写代理来减少语义歧义。

Result: MEGA-GUI在ScreenSpot-Pro基准上达到73.18%的准确率，在OSWorld-G基准上达到68.63%的准确率，优于现有方法。

Conclusion: MEGA-GUI通过其模块化结构和专门的视觉语言代理，在GUI基础方面取得了显著的改进，尤其是在处理视觉密集和语义复杂的场景时。

Abstract: Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.

</details>


### [558] [DAP: A Discrete-token Autoregressive Planner for Autonomous Driving](https://arxiv.org/abs/2511.13306)
*Bowen Ye,Bin Zhang,Hang Zhao*

Main category: cs.AI

TL;DR: DAP是一个离散标记的自回归规划器，通过联合预测BEV语义和ego轨迹，并结合强化学习进行微调，实现了最先进的开放式和具有竞争力的封闭式性能，参数量仅为1.6亿。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶规划方法在扩展数据和模型预算以获得可持续性能提升方面仍面临挑战，单独预测ego轨迹存在监督稀疏和场景约束不足的问题。

Method: 提出了一种名为DAP的离散标记自回归规划器，该规划器联合预测BEV语义和ego轨迹，并结合基于强化学习的微调。

Result: DAP在开放式指标上达到了最先进的性能，并在NAVSIM基准上取得了具有竞争力的封闭式结果，同时模型参数量仅为1.6亿。

Conclusion: DAP提供了一种紧凑且可扩展的自动驾驶规划范式，其完全离散标记的自回归方法可同时处理栅格化BEV和ego动作。

Abstract: Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [559] [MALBO: Optimizing LLM-Based Multi-Agent Teams via Multi-Objective Bayesian Optimization](https://arxiv.org/abs/2511.11788)
*Antonio Sabbatella*

Main category: cs.MA

TL;DR: MALBO框架通过多目标贝叶斯优化自动化LLM团队的组合，实现了在保持性能的同时显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中优化大型语言模型（LLM）的分配是一个重大挑战，现有方法无法处理这种多智能体、多目标问题。

Method: 提出MALBO（Multi-Agent LLM Bayesian Optimization）框架，将LLM团队的分配问题形式化为多目标优化问题，利用具有独立高斯过程代理模型的多目标贝叶斯优化（MOBO）在LLM的连续特征空间上进行搜索，以最大化超体积改进。

Result: MALBO框架生成了一个包含最优团队配置的帕累托前沿。与随机搜索相比，贝叶斯优化阶段在保持相似平均性能的同时，将平均配置成本降低了45%以上。与同质化基线相比，MALBO识别出的异构团队成本降低高达65.8%，同时保持了最高性能。

Conclusion: MALBO提供了一种原则性的自动化方法，用于高效地组合基于LLM的智能体团队，在部署经济高效且高度专业化的多智能体AI系统方面，提供了一个数据驱动的工具。

Abstract: The optimal assignment of Large Language Models (LLMs) to specialized roles in multi-agent systems is a significant challenge, defined by a vast combinatorial search space, expensive black-box evaluations, and an inherent trade-off between performance and cost. Current optimization methods focus on single-agent settings and lack a principled framework for this multi-agent, multi-objective problem.
  This thesis introduces MALBO (Multi-Agent LLM Bayesian Optimization), a systematic framework designed to automate the efficient composition of LLM-based agent teams. We formalize the assignment challenge as a multi-objective optimization problem, aiming to identify the Pareto front of configurations between task accuracy and inference cost. The methodology employs multi-objective Bayesian Optimization (MOBO) with independent Gaussian Process surrogate models. By searching over a continuous feature-space representation of the LLMs, this approach performs a sample-efficient exploration guided by the expected hypervolume improvement.
  The primary contribution is a principled and automated methodology that yields a Pareto front of optimal team configurations. Our results demonstrate that the Bayesian optimization phase, compared to an initial random search, maintained a comparable average performance while reducing the average configuration cost by over 45%. Furthermore, MALBO identified specialized, heterogeneous teams that achieve cost reductions of up to 65.8% compared to homogeneous baselines, all while maintaining maximum performance. The framework thus provides a data-driven tool for deploying cost-effective and highly specialized multi-agent AI systems.

</details>


### [560] [From Single to Societal: Analyzing Persona-Induced Bias in Multi-Agent Interactions](https://arxiv.org/abs/2511.11789)
*Jiayi Li,Xiao Liu,Yansong Feng*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Model (LLM)-based multi-agent systems are increasingly used to simulate human interactions and solve collaborative tasks. A common practice is to assign agents with personas to encourage behavioral diversity. However, this raises a critical yet underexplored question: do personas introduce biases into multi-agent interactions? This paper presents a systematic investigation into persona-induced biases in multi-agent interactions, with a focus on social traits like trustworthiness (how an agent's opinion is received by others) and insistence (how strongly an agent advocates for its opinion). Through a series of controlled experiments in collaborative problem-solving and persuasion tasks, we reveal that (1) LLM-based agents exhibit biases in both trustworthiness and insistence, with personas from historically advantaged groups (e.g., men and White individuals) perceived as less trustworthy and demonstrating less insistence; and (2) agents exhibit significant in-group favoritism, showing a higher tendency to conform to others who share the same persona. These biases persist across various LLMs, group sizes, and numbers of interaction rounds, highlighting an urgent need for awareness and mitigation to ensure the fairness and reliability of multi-agent systems.

</details>


### [561] [Conflict-Free Flight Scheduling Using Strategic Demand Capacity Balancing for Urban Air Mobility Operations](https://arxiv.org/abs/2511.11854)
*Vahid Hemmati,Yonas Ayalew,Ahmad Mohammadi,Reza Ahmari,Parham Kebria,Abdollah Homaifar,Mehrdad Saif*

Main category: cs.MA

TL;DR: 该研究提出了一种冲突 free 的多智能体飞行调度方法，通过延迟起飞来确保城市空中交通（UAM）的运行安全。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市空中交通（UAM）应用中约束空域内鲁棒间隔保证的问题。

Method: 首先，提出基于延迟起飞的成对冲突避免（PCA）方法，利用运动学原理保持安全距离。然后，将PCA扩展到多智能体场景，通过优化方法系统地确定起飞时间，以应对日益增长的交通密度。

Result: 通过在不同多智能体环境和实际UAM用例中的数值模拟，该方法显著减少了总延迟，并确保了无碰撞运行。

Conclusion: 该方法为新兴的城市空中交通系统提供了一个可扩展的框架。

Abstract: In this paper, we propose a conflict-free multi- agent flight scheduling that ensures robust separation in con- strained airspace for Urban Air Mobility (UAM) operations application. First, we introduce Pairwise Conflict Avoidance (PCA) based on delayed departures, leveraging kinematic principles to maintain safe distances. Next, we expand PCA to multi-agent scenarios, formulating an optimization approach that systematically determines departure times under increasing traffic densities. Performance metrics, such as average delay, assess the effectiveness of our solution. Through numerical simulations across diverse multi-agent environments and real- world UAM use cases, our method demonstrates a significant reduction in total delay while ensuring collision-free operations. This approach provides a scalable framework for emerging urban air mobility systems.

</details>


### [562] [Goal-Oriented Multi-Agent Reinforcement Learning for Decentralized Agent Teams](https://arxiv.org/abs/2511.11992)
*Hung Du,Hy Nguyen,Srikanth Thudumu,Rajesh Vasa,Kon Mouzakis*

Main category: cs.MA

TL;DR: 提出一个去中心化的多智能体强化学习（MARL）框架，使车辆能够根据局部目标和观测进行选择性通信，以应对动态、不可预测且通信受限的真实世界环境中的协调挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的车辆（陆地、水域、空中）面临动态、不可预测、通信受限、无中心控制和部分可观察的环境，这对追求个体目标的车辆的协调提出了重大挑战。

Method: 提出一个去中心化的多智能体强化学习（MARL）框架，其中智能体（车辆）根据局部目标和观测进行选择性通信，只共享相关信息，以增强协作并尊重可见性限制。

Result: 在具有障碍物和动态智能体种群的复杂多智能体导航任务中，该方法显著提高了任务成功率，缩短了达到目标的时间，并且随着智能体数量的增加，任务性能保持稳定，证明了其可扩展性。

Conclusion: 去中心化的、以目标为驱动的MARL有潜力支持在不同领域运行的现实多车辆系统中进行有效协调。

Abstract: Connected and autonomous vehicles across land, water, and air must often operate in dynamic, unpredictable environments with limited communication, no centralized control, and partial observability. These real-world constraints pose significant challenges for coordination, particularly when vehicles pursue individual objectives. To address this, we propose a decentralized Multi-Agent Reinforcement Learning (MARL) framework that enables vehicles, acting as agents, to communicate selectively based on local goals and observations. This goal-aware communication strategy allows agents to share only relevant information, enhancing collaboration while respecting visibility limitations. We validate our approach in complex multi-agent navigation tasks featuring obstacles and dynamic agent populations. Results show that our method significantly improves task success rates and reduces time-to-goal compared to non-cooperative baselines. Moreover, task performance remains stable as the number of agents increases, demonstrating scalability. These findings highlight the potential of decentralized, goal-driven MARL to support effective coordination in realistic multi-vehicle systems operating across diverse domains.

</details>


### [563] [FINRS: A Risk-Sensitive Trading Framework for Real Financial Markets](https://arxiv.org/abs/2511.12599)
*Bijia Liu,Ronghao Dang*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have shown strong reasoning capabilities and are increasingly explored for financial trading. Existing LLM-based trading agents, however, largely focus on single-step prediction and lack integrated mechanisms for risk management, which reduces their effectiveness in volatile markets. We introduce FinRS, a risk-sensitive trading framework that combines hierarchical market analysis, dual-decision agents, and multi-timescale reward reflection to align trading actions with both return objectives and downside risk constraints. Experiments on multiple stocks and market conditions show that FinRS achieves superior profitability and stability compared to state-of-the-art methods.

</details>


### [564] [ENGRAM: Effective, Lightweight Memory Orchestration for Conversational Agents](https://arxiv.org/abs/2511.12960)
*Daivik Patel,Shrenik Patel*

Main category: cs.MA

TL;DR: ENGRAM是一个轻量级的记忆系统，通过单一的路由器和检索器将对话组织成三种规范的记忆类型（情景、语义和程序），在LoCoMo和LongMemEval基准上达到了最先进的性能，同时显著减少了代币使用量。


<details>
  <summary>Details</summary>
Motivation: 当前的记忆系统通常采用复杂的架构，如知识图谱、多阶段检索管道和操作系统风格的调度器，这会带来工程复杂性和可重复性挑战。因此，需要一个更简单、更有效的记忆系统来支持LLM的长远一致性。

Method: ENGRAM将每次用户交互转换为具有规范模式和嵌入的类型化记忆记录，并存储在数据库中。在查询时，它检索每种类型的top-k密集邻居，使用简单的集合操作合并结果，并将最相关的证据提供给模型作为上下文。

Result: ENGRAM在LoCoMo（一个用于长远记忆的多会话对话QA基准）上取得了最先进的成果，并且在LongMemEval上比全上下文基线高出15个点，同时只使用了大约1%的代币。

Conclusion: 仔细的记忆类型划分和直接的密集检索可以实现语言模型中有效的长期记忆管理，而无需复杂的架构。

Abstract: Large language models (LLMs) deployed in user-facing applications require long-horizon consistency: the ability to remember prior interactions, respect user preferences, and ground reasoning in past events. However, contemporary memory systems often adopt complex architectures such as knowledge graphs, multi-stage retrieval pipelines, and OS-style schedulers, which introduce engineering complexity and reproducibility challenges. We present ENGRAM, a lightweight memory system that organizes conversation into three canonical memory types (episodic, semantic, and procedural) through a single router and retriever. Each user turn is converted into typed memory records with normalized schemas and embeddings and stored in a database. At query time, the system retrieves top-k dense neighbors for each type, merges results with simple set operations, and provides the most relevant evidence as context to the model. ENGRAM attains state-of-the-art results on LoCoMo, a multi-session conversational QA benchmark for long-horizon memory, and exceeds the full-context baseline by 15 points on LongMemEval while using only about 1% of the tokens. These results show that careful memory typing and straightforward dense retrieval can enable effective long-term memory management in language models without requiring complex architectures.

</details>


### [565] [Reuse, Don't Recompute: Efficient Large Reasoning Model Inference via Memory Orchestration](https://arxiv.org/abs/2511.12987)
*Daivik Patel,Shrenik Patel*

Main category: cs.MA

TL;DR: 大型推理模型（LRM）通过增加推理过程中的token数量和采样多个解决方案来提高准确性，但成本高昂。本文提出ENGRAM-R，一种推理时记忆层，通过结合类型化检索、紧凑的事实卡片表示和显式引用控制，来提高推理效率。ENGRAM-R在LoCoMo基准测试中，相比完整上下文，输入token减少了85%，推理token减少了75%，同时保持了高准确性。在LongMemEval基准测试的多跳部分，ENGRAM-R在相似的效率下取得了显著的准确性提升。这表明记忆不仅对长距离推理的正确性至关重要，而且在计算、内存和延迟预算有限的情况下，也是提高推理效率的实用手段。


<details>
  <summary>Details</summary>
Motivation: 目前的大型推理模型（LRM）虽然可以通过增加token数量或采样多个解决方案来提高准确性，但成本高昂。本文认为记忆是高效推理的核心要素，当已有证据时，模型应通过重用结构化记忆来减少计算量，而不是重新推导。

Method: 提出ENGRAM-R，一种推理时记忆层，集成了类型化检索、紧凑的事实卡片表示和显式引用控制。

Result: 在LoCoMo基准测试中，ENGRAM-R相比完整上下文，输入token减少了85%，推理token减少了75%，同时保持了高准确性。在LongMemEval基准测试的多跳部分，ENGRAM-R在相似的效率下取得了显著的准确性提升。

Conclusion: 记忆不仅对长距离推理的正确性至关重要，而且在计算、内存和延迟预算有限的情况下，也是提高推理效率的实用手段。

Abstract: Large reasoning models (LRMs) achieve strong accuracy through test-time scaling, generating longer chains of thought or sampling multiple solutions, but at steep costs in tokens and latency. We argue that memory is a core ingredient for efficient reasoning: when evidence already exists, models should think less by reusing structured memory instead of recomputing derivations. We present ENGRAM-R, an inference-time memory layer that integrates typed retrieval with compact fact card representations and explicit citation control. On the LoCoMo benchmark, ENGRAM-R reduces input tokens by 85% and reasoning tokens by 75% compared to full context while maintaining high accuracy. On a multi-hop slice of the LongMemEval benchmark, it achieves similar efficiency with substantial accuracy gains. These results show that memory is not only critical for long-horizon correctness but also a practical lever for efficient reasoning under tight compute, memory, and latency budgets.

</details>


### [566] [LLM-based Multi-Agent System for Simulating Strategic and Goal-Oriented Data Marketplaces](https://arxiv.org/abs/2511.13233)
*Jun Sashihara,Yukihisa Fujita,Kota Nakamura,Masahiro Kuwahara,Teruaki Hayashi*

Main category: cs.MA

TL;DR: LLM驱动的多代理系统（LLM-MAS）被提出用于数据市场，以更真实地模拟交易模式和市场动态，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据市场研究缺乏对市场参与者、数据和法规之间交互的系统性理解。

Method: 构建一个由LLM驱动的买卖双方代理组成的系统（LLM-MAS），使代理能够自主地进行规划、搜索、定价和更新等策略性行为，并通过自然语言推理适应市场变化。

Result: 通过模拟实验，使用购买次数/数据集、购买次数/买家和重复购买次数三个指标评估，LLM-MAS比传统方法更能准确地再现真实数据市场的交易模式，并捕捉到市场趋势的出现和演变。

Conclusion: LLM-MAS为数据市场提供了一个更强大、更具适应性的模拟框架，能够更真实地反映市场行为和动态。

Abstract: Data marketplaces, which mediate the purchase and exchange of data from third parties, have attracted growing attention for reducing the cost and effort of data collection while enabling the trading of diverse datasets. However, a systematic understanding of the interactions between market participants, data, and regulations remains limited. To address this gap, we propose a Large Language Model-based Multi-Agent System (LLM-MAS) for data marketplaces. In our framework, buyer and seller agents powered by LLMs operate with explicit objectives and autonomously perform strategic actions, such as planning, searching, purchasing, pricing, and updating data. These agents can reason about market dynamics, forecast future demand, and adjust strategies accordingly. Unlike conventional model-based simulations, which are typically constrained to predefined rules, LLM-MAS supports broader and more adaptive behavior selection through natural language reasoning. We evaluated the framework via simulation experiments using three distribution-based metrics: (1) the number of purchases per dataset, (2) the number of purchases per buyer, and (3) the number of repeated purchases of the same dataset. The results demonstrate that LLM-MAS more faithfully reproduces trading patterns observed in real data marketplaces compared to traditional approaches, and further captures the emergence and evolution of market trends.

</details>


### [567] [How Hard is it to Explain Preferences Using Few Boolean Attributes?](https://arxiv.org/abs/2511.13445)
*Clemens Anzinger,Jiehua Chen,Christian Hatschka,Manuel Sorge,Alexander Temper*

Main category: cs.MA

TL;DR: 本研究探讨了通过布尔属性模型（BAM）解释偏好数据的计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是现有的关于属性模型的研究，这些模型在理解偏好结构和支持更有效的决策方面显示出巨大潜力。

Method: 在BAM中，每个备选项都有一组布尔属性，每个选民都关心一组属性，并且选民偏好具有更多他们所需属性的备选项。BAM问题的目标是，在给定偏好列表和数字k的情况下，判断是否存在一个布尔k-属性模型可以解释该偏好列表。

Result: 研究结果揭示了属性数量k的计算复杂性二分法：当k≤2时，BAM问题可以在线性时间内解决；当k≥3时，该问题是NP完全的。即使在偏好顺序长度为2的情况下，该问题仍然是困难的。另一方面，当参数为备选项数量m时，BAM问题是固定参数可处理的。对于只有两个选民的特殊情况，研究提供了一种线性时间算法。此外，研究还分析了包含部分信息的变体：在已知选民偏好属性（BAM WITH CARES）或已指定备选项属性（BAM WITH HAS）的情况下，研究表明，对于大多数参数，BAM WITH CARES比BAM WITH HAS更难处理，而BAM WITH HAS更易于处理，但即使只有一个选民，该问题也是NP难的。

Conclusion: 研究得出了关于BAM问题的计算复杂性的明确结论，并提出了针对不同参数和变体的有效算法和困难性结果。

Abstract: We study the computational complexity of explaining preference data through Boolean attribute models (BAMs), motivated by extensive research involving attribute models and their promise in understanding preference structure and enabling more efficient decision-making processes. In a BAM, each alternative has a subset of Boolean attributes, each voter cares about a subset of attributes, and voters prefer alternatives with more of their desired attributes. In the BAM problem, we are given a preference profile and a number k, and want to know whether there is a Boolean k-attribute model explaining the profile.
  We establish a complexity dichotomy for the number of attributes k: BAM is linear-time solvable for $k \le 2$ but NP-complete for $k \ge 3$. The problem remains hard even when preference orders have length two. On the positive side, BAM becomes fixed-parameter tractable when parameterized by the number of alternatives m. For the special case of two voters, we provide a linear-time algorithm.
  We also analyze variants where partial information is given: When voter preferences over attributes are known (BAM WITH CARES) or when alternative attributes are specified (BAM WITH HAS), we show that for most parameters BAM WITH CARES is more difficult whereas BAM WITH HAS is more tractable except for being NP-hard even for one voter.

</details>


### [568] [Asymptotic analysis of cooperative censoring policies in sensor networks](https://arxiv.org/abs/2511.13492)
*Jesus Fernandez-Bes,Rocío Arroyo-Valles,Jesús Cid-Sueiro*

Main category: cs.MA

TL;DR: 本篇论文研究了电池供电的多跳传感器网络中的协作数据审查问题，提出了一种基于马尔可夫决策过程的联合优化策略，并找到了近似的最优审查阈值，实验证明该方法能有效节省能源并优于非协作方案。


<details>
  <summary>Details</summary>
Motivation: 本篇论文旨在解决电池供电的多跳传感器网络中的协作数据审查问题，以节省能源，确保节点能够进行更长时间的通信。

Method: 本篇论文使用联合马尔可夫决策过程对整个网络动态进行建模，并找到了一个理论上最优的审查策略，该策略可以最大化长期奖励。尽管最优审查规则在计算上是难以实现的，但论文提出了一种计算这些阈值的中心化算法，并且发现，在某些条件下，最优规则可以由有限的常量阈值规则集合来近似。

Result: 实验模拟表明，协作审查策略具有节能性，并且优于其他非协作方案。

Conclusion: 本篇论文提出了一种用于电池供电的多跳传感器网络的协作数据审查方法，该方法通过最大化长期奖励来优化能源使用，并找到了可行的近似最优阈值，实验结果验证了该方法的有效性。

Abstract: The problem of cooperative data censoring in battery-powered multihop sensor networks is analyzed in this paper. We are interested in scenarios where nodes generate messages (which are related to the sensor measurements) that can be graded with some importance value. Less important messages can be censored in order to save energy for later communications. The problem is modeled using a joint Markov Decision Process of the whole network dynamics, and a theoretically optimal censoring policy, which maximizes a long-term reward, is found. Though the optimal censoring rules are computationally prohibitive, our analysis suggests that, under some conditions, they can be approximated by a finite collection of constant-threshold rules. A centralized algorithm for the computation of these thresholds is proposed. The experimental simulations show that cooperative censoring policies are energy-efficient, and outperform other non-cooperative schemes.

</details>


### [569] [Market-Dependent Communication in Multi-Agent Alpha Generation](https://arxiv.org/abs/2511.13614)
*Jerick Shi,Burton Hollifield*

Main category: cs.MA

TL;DR: 通信能提高对冲基金的表现，但最佳通信方式取决于市场特征。竞争性对话适用于波动性大的科技股，协作性对话适用于稳定的一般股票，而金融股则对所有通信干预都不敏感。


<details>
  <summary>Details</summary>
Motivation: 研究对冲基金中交易策略分析师之间的通信方式选择，以及不同通信结构对基金表现的影响。

Method: 使用基于LLM的5个代理交易系统进行450次实验，比较了从孤立基线到协作和竞争性对话的五种组织结构。

Result: 通信能提高业绩，但最佳通信设计取决于市场特征。竞争性对话在波动性大的科技股中表现最佳，协作性对话在稳定的普通股中表现最佳。金融股对所有通信干预都不敏感。所有结构（包括孤立代理）都趋向于相似的策略。业绩差异源于行为机制：竞争性代理关注股票分配，协作性代理开发技术框架。对话质量与回报不相关。

Conclusion: 最优通信设计必须与市场波动性特征相匹配，并且复杂的讨论并不一定能带来更好的表现。

Abstract: Multi-strategy hedge funds face a fundamental organizational choice: should analysts generating trading strategies communicate, and if so, how? We investigate this using 5-agent LLM-based trading systems across 450 experiments spanning 21 months, comparing five organizational structures from isolated baseline to collaborative and competitive conversation. We show that communication improves performance, but optimal communication design depends on market characteristics. Competitive conversation excels in volatile technology stocks, while collaborative conversation dominates stable general stocks. Finance stocks resist all communication interventions. Surprisingly, all structures, including isolated agents, converge to similar strategy alignments, challenging assumptions that transparency causes harmful diversity loss. Performance differences stem from behavioral mechanisms: competitive agents focus on stock-level allocation while collaborative agents develop technical frameworks. Conversation quality scores show zero correlation with returns. These findings demonstrate that optimal communication design must match market volatility characteristics, and sophisticated discussions don't guarantee better performance.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [570] [Dynamic Graph Recommendation via Sparse Augmentation and Singular Adaptation](https://arxiv.org/abs/2511.11969)
*Zhen Tao,Yuehang Cao,Yang Fang,Yunhui Liu,Xiang Zhao,Tieke He*

Main category: cs.SI

TL;DR: GraphSASA通过测试时增强和奇异值分解实现了动态推荐的高效微调。


<details>
  <summary>Details</summary>
Motivation: 现有动态推荐方法在处理大规模图数据时计算资源需求大，且长尾分布导致稀疏交互节点表示不足，微调效率低。

Method: GraphSASA利用节点表示分布相似性进行测试时增强，并通过冻结原始向量矩阵、仅对奇异值矩阵进行微调来减少参数负担和提高微调适应性。

Result: 在三个大规模数据集上取得了最先进的性能。

Conclusion: GraphSASA能够有效解决现有动态推荐方法面临的计算资源和表示不足的挑战，并在大规模数据集上实现了高性能。

Abstract: Dynamic recommendation, focusing on modeling user preference from historical interactions and providing recommendations on current time, plays a key role in many personalized services. Recent works show that pre-trained dynamic graph neural networks (GNNs) can achieve excellent performance. However, existing methods by fine-tuning node representations at large scales demand significant computational resources. Additionally, the long-tail distribution of degrees leads to insufficient representations for nodes with sparse interactions, posing challenges for efficient fine-tuning. To address these issues, we introduce GraphSASA, a novel method for efficient fine-tuning in dynamic recommendation systems. GraphSASA employs test-time augmentation by leveraging the similarity of node representation distributions during hierarchical graph aggregation, which enhances node representations. Then it applies singular value decomposition, freezing the original vector matrix while focusing fine-tuning on the derived singular value matrices, which reduces the parameter burden of fine-tuning and improves the fine-tuning adaptability. Experimental results demonstrate that our method achieves state-of-the-art performance on three large-scale datasets.

</details>


### [571] [Quantifying and Minimizing Perception Gap in Social Networks](https://arxiv.org/abs/2511.12106)
*Hemant Kumar Gehlot,Mohammad Shirzadi,Junhao Gan,Ahad N. Zehmakan*

Main category: cs.SI

TL;DR: 社交媒体虽然改变了全球通讯，但其网络结构可能通过多数幻觉和回声室效应等扭曲人们的认知。我们提出了感知差距指数（perception gap index），这是一种基于图的度量，用于量化局部-全局意见差异，可以看作是连续环境中多数幻觉的推广。我们利用谱图理论证明，更高的连通性使网络更能抵抗感知扭曲。然而，我们对随机块模型的分析表明，显著的社群结构会增加网络的脆弱性。我们还研究了在固定预算下，通过链接推荐来最小化感知差距的问题，并证明了除非P=NP，否则该问题不存在能在多项式时间内解决的、具有任意有界近似比的算法。尽管如此，我们提出了一系列有效的启发式方法，并在真实网络数据上证明了它们能产生近乎最优的解决方案。


<details>
  <summary>Details</summary>
Motivation: 社交媒体的网络结构可能导致认知扭曲，例如多数幻觉和回声室效应，这会影响我们对全球信息的理解。因此，有必要量化和理解这种认知扭曲的程度，并探索减少它的方法。

Method: 该研究引入了感知差距指数（perception gap index），这是一种基于图的度量，用于量化局部意见与全局意见之间的差异。研究利用了谱图理论来分析网络连通性对感知扭曲的抵抗能力，并通过分析随机块模型来研究社群结构的影响。此外，研究还探讨了在有限预算下，通过链接推荐最小化感知差距的问题，并提出了启发式算法来解决NP难题。

Result: 研究发现，更高的网络连通性可以增强网络抵抗感知扭曲的能力。然而，显著的社群结构会增加网络的脆弱性。在最小化感知差距的问题上，研究证明了其计算的困难性（NP难题），但提出了一系列有效的启发式方法，并在实际网络数据上验证了这些方法的有效性，能够得到近乎最优的解决方案。

Conclusion: 感知差距指数是一种有效的工具，可以量化社交网络中的认知扭曲。虽然网络连通性有助于减少这种扭曲，但社群结构可能会加剧它。最小化感知差距是一个具有挑战性的计算问题，但提出的启发式方法为在实际应用中解决该问题提供了可行的途径。

Abstract: Social media has transformed global communication, yet its network structure can systematically distort perceptions through effects like the majority illusion and echo chambers. We introduce the perception gap index, a graph-based measure that quantifies local-global opinion divergence, which can be viewed as a generalization of the majority illusion to continuous settings. Using techniques from spectral graph theory, we demonstrate that higher connectivity makes networks more resilient to perception distortion. Our analysis of stochastic block models, however, shows that pronounced community structure increases vulnerability. We also study the problem of minimizing the perception gap via link recommendation with a fixed budget. We prove that this problem does not admit a polynomial-time algorithm for any bounded approximation ratio, unless P = NP. However, we propose a collection of efficient heuristic methods that have been demonstrated to produce near-optimal solutions on real-world network data.

</details>


### [572] [Learning to Control Misinformation: a Closed-loop Approach for Misinformation Mitigation over Social Networks](https://arxiv.org/abs/2511.12393)
*Nicolo' Pagan,Andreas Philippou,Giulia De Pasquale*

Main category: cs.SI

TL;DR: 该研究提出了一种控制框架，通过惩罚极端负面情绪和新颖性等易被虚假信息利用的内容特征，在降低虚假信息传播的同时保持用户参与度。


<details>
  <summary>Details</summary>
Motivation: 当前推荐系统优先考虑用户参与度，无意中放大了虚假信息的传播。

Method: 扩展了Friedkin-Johnsen模型，纳入了减少虚假信息传播和最大化用户参与度的控制策略，并通过LIAR2数据集和大型语言模型提取的情感特征进行了模拟验证。

Result: 在不同的网络配置中，模型无关和模型两类控制策略均能减少高达76%的虚假信息传播。在存在激进用户的情况下，即使虚假信息减少，用户参与度也有所提高。

Conclusion: 该框架通过平衡虚假信息抑制和用户参与度目标，为平台运营商提供了实际指导，尤其是在激进用户占比较高的网络中，内容审核可以提高非极端用户的讨论质量。

Abstract: Modern social networks rely on recommender systems that inadvertently amplify misinformation by prioritizing engagement over content veracity. We present a control framework that mitigates misinformation spread while maintaining user engagement by penalizing content characteristics commonly exploited by false information, specifically, extreme negative sentiment and novelty. We extend the closed-loop Friedkin-Johnsen model to incorporate the mitigation of misinformation together with the maximization of user engagement. Both model-free and model-based control strategies demonstrate up to 76% reduction in misinformation propagation across diverse network configurations, validated through simulations using the LIAR2 dataset with sentiment features extracted via large language models. Analysis of engagement-misinformation trade-offs reveals that in networks with radical users, median engagement improves even as misinformation decreases, suggesting content moderation enhances discourse quality for non-extremist users. The framework provides practical guidance for platform operators in balancing misinformation suppression with engagement objectives.

</details>


### [573] [Designed to Spread: Generative Approaches to Enhance Information Diffusion](https://arxiv.org/abs/2511.12516)
*Ziqing Qian,Jiaying Lei,Shengqi Dang,Nan Cao*

Main category: cs.SI

TL;DR: 研究提出了一种新的文档级内容生成（DOCG）任务，旨在自动生成能在社交媒体上广泛传播的内容，并提出了一种信息增强算法来优化内容传播效果。该方法不依赖网络拓扑结构，通过影响指标评估内容传播潜力，并利用强化学习驱动的信息编辑器探索可解释的编辑策略，生成既忠实于原文语义又符合目标受众的内容。


<details>
  <summary>Details</summary>
Motivation: 现有研究在社交媒体内容传播方面，主要关注网络结构和临界点识别，缺乏自动生成病毒式传播内容的工具。

Method: 提出DOCG任务和信息增强算法。算法包含一个影响指标，用于在不访问网络拓扑的情况下评估内容传播能力；一个信息编辑器，利用强化学习探索可解释的编辑策略，并结合生成模型生成忠实于原文语义、面向特定受众的文本或视觉内容。

Result: 在真实社交媒体数据集上的实验和用户研究表明，该方法在提高内容传播有效性的同时，能保持原文的核心语义。

Conclusion: 所提出的DOCG任务和信息增强算法能够显著提高社交媒体内容的传播效果，并保持内容的语义完整性。

Abstract: Social media has fundamentally transformed how people access information and form social connections, with content expression playing a critical role in driving information diffusion. While prior research has focused largely on network structures and tipping point identification, it provides limited tools for automatically generating content tailored for virality within a specific audience. To fill this gap, we propose the novel task of DOCG and introduce an information enhancement algorithm for generating content optimized for diffusion. Our method includes an influence indicator that enables content-level diffusion assessment without requiring access to network topology, and an information editor that employs reinforcement learning to explore interpretable editing strategies. The editor leverages generative models to produce semantically faithful, audience-aware textual or visual content. Experiments on real-world social media datasets and user study demonstrate that our approach significantly improves diffusion effectiveness while preserving the core semantics of the original content.

</details>


### [574] [Rethinking the filter bubble? Developing a research agenda for the protective filter bubble](https://arxiv.org/abs/2511.12873)
*Jacob Erickson*

Main category: cs.SI

TL;DR: 文章主要探讨了过滤气泡的负面影响，但也提出了其对边缘化群体和新闻自由度低国家/地区居民的保护性益处，并建议重新审视过滤气泡及其未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注过滤气泡的负面影响，而忽视了其对边缘化群体和新闻自由度低国家/地区居民的保护性益处，因此有必要重新审视过滤气泡。

Method: 通过回顾关于数字安全空间和保护性过滤气泡的文献，提出新的观点和未来研究方向。

Result: 过滤气泡可能具有保护性益处，尤其对边缘化群体和新闻自由度低国家/地区居民而言。

Conclusion: 需要重新审视过滤气泡的定义和影响，并探索其保护性益处及其在不同社群中的应用，同时指出未来研究方向。

Abstract: Filter bubbles and echo chambers have received global attention from scholars, media organizations, and the general public. Filter bubbles have primarily been regarded as intrinsically negative, and many studies have sought to minimize their influence. The detrimental influence of filter bubbles is well-studied. Filter bubbles may, for example, create information silos, amplify misinformation, and promote hatred and extremism. However, comparatively few studies have considered the other side of the filter bubble; its protective benefits, particularly to marginalized communities and those living in countries with low levels of press freedom. Through a review of the literature on digital safe spaces and protective filter bubbles, this commentary suggests that there may be a need to rethink the filter bubble, and it proposes several areas for future research.

</details>


### [575] [Unifying points of interest taxonomies: mapping OpenStreetMap tags to the Foursquare category system](https://arxiv.org/abs/2511.13369)
*Lilou Soulas,Lorenzo Lucchini,Maurizio Napolitano,Sebastiano Bontorin,Simone Centellegher,Bruno Lepri,Riccardo Gallotti,Eleonora Andreotti*

Main category: cs.SI

TL;DR: 该论文提出了一种开放的基准和映射框架，用于对齐开放街图(OSM)标签和Foursquare(FS)分类，以解决POI（兴趣点）分类异构性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: POI分类异构性给城市数据集成和基于位置的服务带来挑战，OSM的灵活标签系统和FS的层级结构存在差异。

Method: 构建了一个手动策划的基准作为黄金标准，评估了预训练文本嵌入模型进行OSM标签和FS类别的语义对齐，并引入了一个LLM（大语言模型）进行优化，以提高鲁棒性和适应性。

Result: 开发了一个集成了OSM数据丰富性和FS层级结构的资源，支持可复现和可互操作的城市分析，并评估了嵌入和LLM对齐策略，同时提供了一个可扩展的更新流程。

Conclusion: 该方法为分类统一提供了可扩展且可复现的解决方案，可直接应用于城市分析、移动性研究和智慧城市服务。

Abstract: The heterogeneity of Point of Interest (POI) taxonomies is a persistent challenge for the integration of urban datasets and the development of location-based services. OpenStreetMap (OSM) adopts a flexible, community-driven tagging system, while Foursquare (FS) relies on a curated hierarchical structure. Here we present an openly available benchmark and mapping framework that aligns OSM tags with the FS taxonomy. This resource integrates the richness of community-driven OSM data with the hierarchical structure of FS, enabling reproducible and interoperable urban analytics. The dataset is complemented by an evaluation of embedding and LLM-based alignment strategies and a pipeline that supports scalable updates as OSM evolves. Together, these elements provide both a robust reference resource and a practical tool for the community. Our approach is structured around three components: the construction of a manually curated benchmark as a gold standard, the evaluation of pretrained text embedding models for semantic alignment between OSM tags and FS categories, and an LLM-based refinement stage that enhances robustness and adaptability. The proposed methodology provides a scalable and reproducible solution for taxonomy unification, with direct applications to urban analytics, mobility studies, and smart city services.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [576] [An improved approximation algorithm for k-Median](https://arxiv.org/abs/2511.12230)
*Neal E. Young*

Main category: cs.DS

TL;DR: 提供了一个针对k-Median问题的多项式时间近似算法，其近似比小于1 + 2ln(n/k)，并且在解的大小和成本上都优于已知的Set Cover问题的界限。


<details>
  <summary>Details</summary>
Motivation: 为了解决k-Median问题，特别是其非度量情况，并寻求比现有算法更好的近似比。

Method: 设计了一个多项式时间近似算法。

Result: 该算法是一个α-大小近似算法，其中α < 1 + 2ln(n/k)。它保证解的大小最多为α * k，成本不超过任何大小为k的解的成本。该算法的运行时间为O(k * m * log(n/k) * log m)。

Conclusion: 该算法是第一个能够匹配未加权Set Cover问题的已知界限（HΔ和1 + ln(n/k)）常数因子内的多项式时间近似算法，并且在这些界限内匹配因子2。

Abstract: We give a polynomial-time approximation algorithm for the (not necessarily metric) $k$-Median problem. The algorithm is an $α$-size-approximation algorithm for $α< 1 + 2 \ln(n/k)$. That is, it guarantees a solution having size at most $α\times k$, and cost at most the cost of any size-$k$ solution. This is the first polynomial-time approximation algorithm to match the well-known bounds of $H_Δ$ and $1 + \ln(n/k)$ for unweighted Set Cover (a special case) within a constant factor. It matches these bounds within a factor of 2. The algorithm runs in time $O(k m \log(n/k) \log m)$, where $n$ is the number of customers and $m$ is the instance size.

</details>


### [577] [Shortcutting for Negative-Weight Shortest Path](https://arxiv.org/abs/2511.12714)
*George Z. Li,Jason Li,Satish Rao,Junkai Zhang*

Main category: cs.DS

TL;DR: 单源最短路径问题在具有实值边权重all的定向图上得到了解决，时间复杂度为 O(n^2.5 log^4.5 n)，优于先前在稠密图上的工作。


<details>
  <summary>Details</summary>
Motivation: 研究单源最短路径问题在具有实值边权重all的定向图上的解决方案。

Method: 使用一种迭代缩短程序，将负权边沿最短路径的数量减少恒定因子。

Result: 在稠密图上，时间复杂度为 O(n^2.5 log^4.5 n)，优于 Fineman (STOC 2024) 和 Huang-Jin-Quanrud (SODA 2025, 2026) 的先前工作。

Conclusion: 提出的方法在解决单源最短路径问题上取得了显著的性能提升，特别是在稠密图的情况下。

Abstract: Consider the single-source shortest paths problem on a directed graph with real-valued edge weights. We solve this problem in $O(n^{2.5}\log^{4.5}n)$ time, improving on prior work of Fineman (STOC 2024) and Huang-Jin-Quanrud (SODA 2025, 2026) on dense graphs. Our main technique is an shortcutting procedure that iteratively reduces the number of negative-weight edges along shortest paths by a constant factor.

</details>


### [578] [Indirect Coflow Scheduling](https://arxiv.org/abs/2511.12854)
*Alexander Lindermayr,Kirk Pruhs,Andréa W. Richa,Tegan Wilson*

Main category: cs.DS

TL;DR: The paper studies coflow scheduling in reconfigurable networks, focusing on scenarios with small data transfer sizes, and designs algorithms that outperform existing methods designed for large transfers.


<details>
  <summary>Details</summary>
Motivation: The existing literature on coflow scheduling generally assumes large data transfer amounts, which may not be suitable for scenarios with smaller data transfers. This work aims to address this gap.

Method: The paper investigates the use of fractional matchings and/or indirect routing to handle coflow scheduling with small data transfer sizes and designs new algorithms tailored for these scenarios.

Result: The designed algorithms perform significantly better for small data transfers compared to existing algorithms intended for large data transfers.

Conclusion: The study highlights the ineffectiveness of traditional large-data-centric coflow scheduling algorithms when dealing with small data transfers and proposes improved algorithms for such cases.

Abstract: We consider routing in reconfigurable networks, which is also known as coflow scheduling in the literature. The algorithmic literature generally (perhaps implicitly) assumes that the amount of data to be transferred is large. Thus the standard way to model a collection of requested data transfers is by an integer demand matrix $D$, where the entry in row $i$ and column $j$ of $D$ is an integer representing the amount of information that the application wants to send from machine/node $i$ to machine/node $j$. A feasible coflow schedule is then a sequence of matchings, which represent the sequence of data transfers that covers $D$. In this work, we investigate coflow scheduling when the size of some of the requested data transfers may be small relative to the amount of data that can be transferred in one round. fractional matchings and/or that employ indirect routing, and compare the relative utility of these options. We design algorithms that perform much better for small demands than the algorithms in the literature that were designed for large data transfers.

</details>


### [579] [Maximal Palindromes in MPC: Simple and Optimal](https://arxiv.org/abs/2511.13014)
*Solon P. Pissis*

Main category: cs.DS

TL;DR: 本文提出了一个在MPC模型中以O(1)轮解决最长回文子串问题的简单且最优的算法，总时间和内存复杂度为O(n)，每台机器的内存复杂度为O(n^{1-ε})，适用于任何ε∈(0,0.5]。该算法还能计算所有最大的回文子串，并放宽了对ε的限制。


<details>
  <summary>Details</summary>
Motivation: 为解决经典的最长回文子串（LPS）问题，特别是针对其在Massively Parallel Computation（MPC）模型下的计算效率问题，提出一个新的算法。

Method: 提出一个简单且最优的算法，在MPC模型中以O(1)轮解决LPS问题，同时能够计算所有最大的回文子串。算法的总时间和内存复杂度为O(n)，每台机器的内存复杂度为O(n^{1-ε})，适用于任何ε∈(0,0.5]。此外，该算法还放宽了在自适应MPC模型中对ε的限制。

Result: 算法在MPC模型中实现了O(1)轮的最长回文子串问题的求解，总内存和时间复杂度为O(n)，每台机器内存复杂度为O(n^{1-ε})。同时，该算法能计算所有最大回文子串，并消除了对ε取值的限制。

Conclusion: 本文提出的算法在MPC模型中以O(1)轮的复杂度解决了最长回文子串问题，并能同时找出所有最大回文子串，在计算效率和通用性上均有提升。

Abstract: In the classical longest palindromic substring (LPS) problem, we are given a string $S$ of length $n$, and the task is to output a longest palindromic substring in $S$. Gilbert, Hajiaghayi, Saleh, and Seddighin [SPAA 2023] showed how to solve the LPS problem in the Massively Parallel Computation (MPC) model in $\mathcal{O}(1)$ rounds using $\mathcal{\widetilde{O}}(n)$ total memory, with $\mathcal{\widetilde{O}}(n^{1-ε})$ memory per machine, for any $ε\in (0,0.5]$.
  We present a simple and optimal algorithm to solve the LPS problem in the MPC model in $\mathcal{O}(1)$ rounds. The total time and memory are $\mathcal{O}(n)$, with $\mathcal{O}(n^{1-ε})$ memory per machine, for any $ε\in (0,0.5]$. A key attribute of our algorithm is its ability to compute all maximal palindromes in the same complexities. Furthermore, our new insights allow us to bypass the constraint $ε\in (0,0.5]$ in the Adaptive MPC model. Our algorithms and the one proposed by Gilbert et al. for the LPS problem are randomized and succeed with high probability.

</details>


### [580] [Greedy matroid base packings with applications to dynamic graph density and orientations](https://arxiv.org/abs/2511.13205)
*Pavel Arkhipov,Vladimir Kolmogorov*

Main category: cs.DS

TL;DR: 本文研究了贪心最小权重生成树打包在一般拟阵中的应用，并将其应用于动态稠密子图问题，取得了比现有算法更好的ε依赖性。同时，研究还提供了关于贪心树打包的组合学结果，改进了已有界限。


<details>
  <summary>Details</summary>
Motivation: 研究贪心最小权重生成树打包在一般拟阵中的应用，并探索其在算法上的应用，特别是在动态稠密子图问题上。

Method: 通过贪心打包伪森林来解决动态稠密子图问题，并维护动态变化图中的最小权重伪森林。对于一般拟阵，给出了基打包极限的两种刻画。

Result: 在 bicircular 拟阵中，得到一个算法，可以维护稠密子图密度的 $(1+\varepsilon)$ 近似值，其最坏情况更新时间优于现有技术。另外，将贪心树打包中的树数量界限从 $O(λ^7\log^3 m)$ 改进到 $O(λ^5\log m)$，并加强了边负载收敛速率的下界。

Conclusion: 贪心最小权重生成树打包在一般拟阵和算法应用，特别是动态稠密子图问题方面具有重要价值，并且在组合学方面也取得了理论上的改进。

Abstract: Greedy minimum weight spanning tree packings have proven to be useful in connectivity-related problems. We study the process of greedy minimum weight base packings in general matroids and explore its algorithmic applications.
  When specialized to bicircular matroids, our results yield an algorithm for the approximate fully-dynamic densest subgraph density $ρ$. We maintain a $(1+\varepsilon)$-approximation of the density with a worst-case update time $O((ρ\varepsilon^{-2}+\varepsilon^{-4})ρ\log^3 m)$. It improves the dependency on $\varepsilon$ from the current state-of-the-art worst-case update time complexity $O(\varepsilon^{-6}\log^3 n\logρ)$ [Chekuri, Christiansen, Holm, van der Hoog, Quanrud, Rotenberg, Schwiegelshohn, SODA'24]. We also can maintain an implicit fractional out-orientation with a guarantee that all out-degrees are at most $(1+\varepsilon)ρ$.
  Our algorithms above work by greedily packing pseudoforests, and require maintenance of a minimum-weight pseudoforest in a dynamically changing graph. We show that this problem can be solved in $O(\log n)$ worst-case time per edge insertion or deletion.
  For general matroids, we observe two characterizations of the limit of the base packings (``the vector of ideal loads''), which imply the characterizations from [Cen, Fleischmann, Li, Li, Panigrahi, FOCS'25], namely, their entropy-minimization theorem and their bottom-up cut hierarchy.
  Finally, we give combinatorial results on the greedy tree packings. We show that a tree packing of $O(λ^5\log m)$ trees contains a tree crossing some min-cut once, which improves the bound $O(λ^7\log^3 m)$ from [Thorup, Combinatorica'07]. We also strengthen the lower bound on the edge load convergence rate from [de Vos, Christiansen, SODA'25], showing that Thorup's upper bound is tight up to a logarithmic factor.

</details>


### [581] [A Complexity Analysis of the c-Closed Vertex Deletion Problem](https://arxiv.org/abs/2511.13301)
*Lisa Lehner,Christian Komusiewicz,Luca Pascal Staus*

Main category: cs.DS

TL;DR: 该论文研究了c-闭合图删除问题，并分析了其NP-hard性和参数化复杂性。


<details>
  <summary>Details</summary>
Motivation: 研究c-闭合图删除问题的NP-hard性和参数化复杂性，为解决此类问题提供理论基础。

Method: 通过引入新参数x（坏对的数量）并分析其问题核大小，以及研究在单位区间图上的可解性和针对邻域多样性的固定参数可处理性。

Result: 证明了c-闭合图删除问题在某些特定图（如最大度有界的二分图）上是NP-hard的，并得到了问题核大小的上界和下界。此外，还提出了针对新参数x的算法，并在单位区间图上实现了多项式时间解法。

Conclusion: c-闭合图删除问题在不同图类和参数下具有不同的计算复杂性，为进一步研究提供了方向。

Abstract: A graph is $c$-closed when every pair of nonadjacent vertices has at most $c-1$ common neighbors. In $c$-Closed Vertex Deletion, the input is a graph $G$ and an integer $k$ and we ask whether $G$ can be transformed into a $c$-closed graph by deleting at most $k$ vertices. We study the classic and parameterized complexity of $c$-Closed Vertex Deletion. We obtain, for example, NP-hardness for the case that $G$ is bipartite with bounded maximum degree. We also show upper and lower bounds on the size of problem kernels for the parameter $k$ and introduce a new parameter, the number $x$ of vertices in bad pairs, for which we show a problem kernel of size $\mathcal{O}(x^3 + x^2\cdot c))$. Here, a pair of nonadjacent vertices is bad if they have at least $c$ common neighbors. Finally, we show that $c$-Closed Vertex Deletion can be solved in polynomial time on unit interval graphs with depth at most $c+1$ and that it is fixed-parameter tractable with respect to the neighborhood diversity of $G$.

</details>


### [582] [Dimension-Free Correlated Sampling for the Hypersimplex](https://arxiv.org/abs/2511.13573)
*Joseph,Naor,Nitya Raju,Abhishek Shetty,Aravind Srinivasan,Renata Valieva,David Wajc*

Main category: cs.DS

TL;DR: 本文提出了一种从给定向量的超单纯形中采样集合的算法，在保证样本集重叠度的同时，将重叠度与输入向量的 $\ell_1$ 距离之比的因子从 $O(\log n)$ 优化至 $O(\log k)$，并且该算法还具有输入稀疏采样时间、对数并行深度、动态更新时间和保持子模目标等优点。


<details>
  <summary>Details</summary>
Motivation: 最大化重叠度地从多个分布中进行采样，特别是从概率单纯形中进行相关采样，已成为理论计算机科学中的一个重要问题。本文将该问题推广到从超单纯形中的给定向量采样集合，旨在最大化采样集合的重叠度。

Method: 本文提出了一种新的算法，能够从给定向量的超单纯形中采样集合，并保证两个输出集合之间的期望差异最多是它们输入向量 $\ell_1$ 距离的 $O(\log k)$ 倍。该算法的采样时间与输入稀疏度成正比，具有对数并行深度和动态更新时间，并能保持子模目标。

Result: 本文算法将重叠度与输入向量 $\ell_1$ 距离之比的因子从已知的 $O(\log n)$ 优化至 $O(\log k)$，实现了独立于维度 $n$ 的优化。此外，该算法在采样时间、并行深度、动态更新和保持子模目标方面也表现出色。

Conclusion: 本文提出的算法在从超单纯形采样集合以最大化重叠度方面取得了显著进展，将性能因子从 $O(\log n)$ 提升至 $O(\log k)$，并具备多种优良的计算特性。该算法有望在在线分页、度量多标签近似和多场景子模福利重新分配等领域得到广泛应用。

Abstract: Sampling from multiple distributions so as to maximize overlap has been studied by statisticians since the 1950s. Since the 2000s, such correlated sampling from the probability simplex has been a powerful building block in disparate areas of theoretical computer science. We study a generalization of this problem to sampling sets from given vectors in the hypersimplex, i.e., outputting sets of size (at most) some $k$ in $[n]$, while maximizing the sampled sets' overlap. Specifically, the expected difference between two output sets should be at most $α$ times their input vectors' $\ell_1$ distance. A value of $α=O(\log n)$ is known to be achievable, due to Chen et al.~(ICALP'17). We improve this factor to $O(\log k)$, independent of the ambient dimension~$n$. Our algorithm satisfies other desirable properties, including (up to a $\log^* n$ factor) input-sparsity sampling time, logarithmic parallel depth and dynamic update time, as well as preservation of submodular objectives. Anticipating broader use of correlated sampling algorithms for the hypersimplex, we present applications of our algorithm to online paging, offline approximation of metric multi-labeling and swift multi-scenario submodular welfare approximating reallocation.

</details>


### [583] [The Merkle Mountain Belt](https://arxiv.org/abs/2511.13582)
*Alfonso Cevallos,Robert Hambrock,Alistair Stewart*

Main category: cs.DS

TL;DR: Merkle 树结构在区块链应用中作为承诺方案的性能比较，并提出了一种新的 Merkle 结构 MMB，实现了简洁、增量和最优可加性。


<details>
  <summary>Details</summary>
Motivation: 为了提高区块链应用的轻客户端协议的效率，特别是加快用户从智能手机验证交易的速度。

Method: 比较了 Merkle 树、Merkle 链和 Merkle 树山 (MMR) 等不同的 Merkle 结构作为承诺方案的性能。引入了新的 Merkle 结构，如 Merkle 树山带 (MMB) 及其异步变体 UMMB。

Result: MMR 结构具有简洁性，适用于首次同步的轻客户端。Merkle 链结构是增量的，适用于频繁同步的轻客户端，并且是可加的。MMB 结构首次实现了简洁性、增量性和最优可加性的结合。UMMB 变体还支持异步操作。新结构提供的成员证明长度与项目添加时间相关，有利于查询最近生成的数据。

Conclusion: MMB 及其变体 UMMB 在简洁性、增量性和可加性方面提供了优于现有 Merkle 结构的性能，特别是在轻客户端协议和处理近期数据查询的区块链应用中具有优势。

Abstract: Merkle structures are widely used as commitment schemes: they allow a prover to publish a compact commitment to an ordered list $X$ of items, and then efficiently prove to a verifier that $x_i\in X$ is the $i$-th item in it. We compare different Merkle structures and their corresponding properties as commitment schemes in the context of blockchain applications. Our primary goal is to speed up light client protocols so that, e.g., a user can verify a transaction efficiently from their smartphone.
  For instance, the Merkle Mountain Range (MMR) yields a succinct scheme: a light client synchronizing for the first time can do so with a complexity sublinear in $|X|$. On the other hand, the Merkle chain, traditionally used to commit to block headers, is not succinct, but it is incremental - a light client resynchronizing frequently can do so with constant complexity - and optimally additive - the structure can be updated in constant time when a new item is appended to list $X$.
  We introduce new Merkle structures, most notably the Merkle Mountain Belt (MMB), the first to be simultaneously succinct, incremental and optimally additive. A variant called UMMB is also asynchronous: a light client may continue to interact with the network even when out of sync with the public commitment. Our Merkle structures are slightly unbalanced, so that items recently appended to $X$ receive shorter membership proofs than older items. This feature reduces a light client's expected costs, in applications where queries are biased towards recently generated data.

</details>


### [584] [Chasing Submodular Objectives, and Submodular Maximization via Cutting Planes](https://arxiv.org/abs/2511.13605)
*Niv Buchbinder,Joseph,Naor,David Wajc*

Main category: cs.DS

TL;DR: 本论文提出“子模目标追逐问题”，旨在动态序列子模最大化问题中平衡解的近似度和修改成本，并针对基数约束和分割拟阵约束提出了最优算法。


<details>
  <summary>Details</summary>
Motivation: 解决在动态序列子模最大化问题中，如何在保证解的近似度同时最小化修改成本的问题。

Method: 提出一种新的元算法“近似或分离”，用于在一般约束下近似最大化多线性扩展，该算法改进了“轮分离”方法，并结合了切割平面法和分离预言机。

Result: 针对基数约束和分割拟阵约束，提出了同时达到最优 $(1-1/e-ε)$-近似度和最优竞争性追索成本的算法。

Conclusion: 该研究为动态序列子模最大化问题提供了一个有效的解决方案，并展示了切割平面法在约束子模最大化问题中的应用潜力，同时为静态算法和通信复杂度协议提供了进一步的应用。

Abstract: We introduce the \emph{submodular objectives chasing problem}, which generalizes many natural and previously-studied problems: a sequence of constrained submodular maximization problems is revealed over time, with both the objective and available ground set changing at each step. The goal is to maintain solutions of high approximation and low total \emph{recourse} (number of changes), compared with exact offline algorithms for the same input sequence. For the central cardinality constraint and partition matroid constraints we provide polynomial-time algorithms achieving both optimal $(1-1/e-ε)$-approximation and optimal competitive recourse for \emph{any} constant-approximation.
  Key to our algorithm's polynomial time, and of possible independent interest, is a new meta-algorithm for $(1-1/e-ε)$-approximately maximizing the multilinear extension under general constraints, which we call {\em approximate-or-separate}. Our algorithm relies on an improvement of the round-and-separate method [Gupta-Levin SODA'20], inspired by an earlier proof by [Vondrák, PhD~Thesis'07]. The algorithm, whose guarantees are similar to the influential {\em continuous greedy} algorithm [Calinescu-Chekuri-Pál-Vondrák SICOMP'11], can use any cutting plane method and separation oracle for the constraints. This allows us to introduce cutting plane methods, used for exact unconstrained submodular minimization since the '80s [Grötschel/Lovász/Schrijver Combinatorica'81], as a useful method for (optimal approximate) constrained submodular maximization. We show further applications of this approach to static algorithms with curvature-sensitive approximation, and to communication complexity protocols.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [585] [Uncertainty-Guided Live Measurement Sequencing for Fast SAR ADC Linearity Testing](https://arxiv.org/abs/2511.11895)
*Thorben Schey,Khaled Karoonlatifi,Michael Weyrich,Andrey Morozov*

Main category: cs.AR

TL;DR: 本论文提出了一种新颖的闭环测试方法，用于高效测试高分辨率SAR ADC的线性度，通过实时更新的EKF行为模型和自适应测量点选择，减少测试时间和计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有ADC线性度测试方法（如直方图法、正弦波测试、模型驱动重建）存在测试时间长、复杂度高等问题，需要大量数据采集和离线后处理。

Method: 提出一种自适应方法，利用扩展卡尔曼滤波器（EKF）实时更新行为模型，直接估计决定INL行为的电容失配参数，并根据模型不确定性动态选择测量点。

Result: 实验结果表明，该方法能够显著减少总测试时间和计算开销，适用于生产环境。

Conclusion: 提出的闭环测试方法通过实时行为模型和自适应采样，克服了传统方法的局限性，能高效地进行SAR ADC的线性度测试。

Abstract: This paper introduces a novel closed-loop testing methodology for efficient linearity testing of high-resolution Successive Approximation Register (SAR) Analog-to-Digital Converters (ADCs). Existing test strategies, including histogram-based approaches, sine wave testing, and model-driven reconstruction, often rely on dense data acquisition followed by offline post-processing, which increases overall test time and complexity. To overcome these limitations, we propose an adaptive approach that utilizes an iterative behavioral model refined by an Extended Kalman Filter (EKF) in real time, enabling direct estimation of capacitor mismatch parameters that determine INL behavior. Our algorithm dynamically selects measurement points based on current model uncertainty, maximizing information gain with respect to parameter confidence and narrowing sampling intervals as estimation progresses. By providing immediate feedback and adaptive targeting, the proposed method eliminates the need for large-scale data collection and post-measurement analysis. Experimental results demonstrate substantial reductions in total test time and computational overhead, highlighting the method's suitability for integration in production environments.

</details>


### [586] [FERMI-ML: A Flexible and Resource-Efficient Memory-In-Situ SRAM Macro for TinyML acceleration](https://arxiv.org/abs/2511.12544)
*Mukul Lokhande,Akash Sankhe,S. V. Jaya Chand,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: FERMI-ML是一种用于TinyML的内存片上SRAM宏，可在AIoT设备上实现低功耗、高能效的推理。


<details>
  <summary>Details</summary>
Motivation: AIoT设备对低功耗、小面积TinyML推理的需求日益增长，需要最小化数据移动并保持高计算效率的内存架构。

Method: 提出了一种基于9T XNOR的RX9T位单元，集成了5T存储单元和4T XNOR计算单元，实现了内存片上（MIS）SRAM宏，支持可变精度MAC和CAM操作。采用C22T压缩树累加器实现对数1-64位MAC计算。

Result: 该4KB宏在65nm工艺下，0.9V电压下可达350MHz，吞吐量为1.93 TOPS，能效为364 TOPS/W。在InceptionV4和ResNet-18上保持了超过97.5%的性能。并且实现了片上计算和CAM查找的双功能，支持Posit-4或FP-4精度。

Conclusion: FERMI-ML是一种紧凑、可重构、注重能耗的数字片上内存宏，能够支持混合精度TinyML工作负载。

Abstract: The growing demand for low-power and area-efficient TinyML inference on AIoT devices necessitates memory architectures that minimise data movement while sustaining high computational efficiency. This paper presents FERMI-ML, a Flexible and Resource-Efficient Memory-In-Situ (MIS) SRAM macro designed for TinyML acceleration. The proposed 9T XNOR-based RX9T bit-cell integrates a 5T storage cell with a 4T XNOR compute unit, enabling variable-precision MAC and CAM operations within the same array. A 22-transistor (C22T) compressor-tree-based accumulator facilitates logarithmic 1-64-bit MAC computation with reduced delay and power compared to conventional adder trees. The 4 KB macro achieves dual functionality for in-situ computation and CAM-based lookup operations, supporting Posit-4 or FP-4 precision. Post-layout results at 65 nm show operation at 350 MHz with 0.9 V, delivering a throughput of 1.93 TOPS and an energy efficiency of 364 TOPS/W, while maintaining a Quality-of-Result (QoR) above 97.5% with InceptionV4 and ResNet-18. FERMI-ML thus demonstrates a compact, reconfigurable, and energy-aware digital Memory-In-Situ macro capable of supporting mixed-precision TinyML workloads.

</details>


### [587] [Advanced Strategies for Uncertainty-Guided Live Measurement Sequencing in Fast, Robust SAR ADC Linearity Testing](https://arxiv.org/abs/2511.11917)
*Thorben Schey,Khaled Karoonlatifi,Michael Weyrich,Andrey Morozov*

Main category: cs.AR

TL;DR: 该研究提出了一种增强的UGLMS方法，用于加速SAR ADC的线性度测试，同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: 为了在实时生产环境中更有效地测试SAR ADC的线性度，需要一种比现有方法更快、更精确的测试策略。

Method: 该研究在UGLMS方法的基础上进行了改进，包括：1. 使用秩-1 EKF更新来加速计算。2. 引入测量对齐的协方差膨胀策略来加速收敛。3. 扩展了静态失配模型，加入了低阶多项式以捕捉非线性。4. 采用基于迹的终止条件来优化测试长度。

Result: 增强的UGLMS方法在16位和18位ADC测试中显著缩短了测试时间（分别为36毫秒和70毫秒），同时保持了高精度。对于16位ADC，其测试速度比以前快8倍。

Conclusion: 增强的UGLMS方法通过引入一系列优化，实现了SAR ADC实时、生产就绪的线性度测试。

Abstract: This paper builds on our Uncertainty-Guided Live Measurement Sequencing (UGLMS) method. UGLMS is a closed-loop test strategy that adaptively selects SAR ADC code edges based on model uncertainty and refines a behavioral mismatch model in real time via an Extended Kalman Filter (EKF), eliminating full-range sweeps and offline post-processing. We introduce an enhanced UGLMS that delivers significantly faster test runtimes while maintaining estimation accuracy. First, a rank-1 EKF update replaces costly matrix inversions with efficient vector operations, and a measurement-aligned covariance-inflation strategy accelerates convergence under unexpected innovations. Second, we extend the static mismatch model with a low-order carrier polynomial to capture systematic nonlinearities beyond pure capacitor mismatch. Third, a trace-based termination adapts test length to convergence, preventing premature stops and redundant iterations. Simulations show the enhanced UGLMS reconstructs full Integral- and Differential-Non-Linearity (INL/DNL) in just 36 ms for 16-bit and under 70 ms for 18-bit ADCs (120 ms with the polynomial extension). Combining the faster convergence from covariance inflation with reduced per-iteration runtime from the rank-1 EKF update, the method reaches equal accuracy 8x faster for 16-bit ADCs. These improvements enable real-time, production-ready SAR ADC linearity testing.

</details>


### [588] [TIMERIPPLE: Accelerating vDiTs by Understanding the Spatio-Temporal Correlations in Latent Space](https://arxiv.org/abs/2511.12035)
*Wenxuan Miao,Yulin Sun,Aiyue Chen,Jing Lin,Yiwu Yao,Yiming Gan,Jieru Zhao,Jingwen Leng,Mingyi Guo,Yu Feng*

Main category: cs.AR

TL;DR: 通过利用潜在空间中的时空相关性来加速视频扩散 Transformer (vDiT) 中的自注意力机制，通过重用部分注意力分数来实现显著的计算节省，同时保持视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有的视频生成模型（主要基于 vDiT）存在推理延迟大的问题，而以往的研究未能充分利用视频流固有的时空相关性。

Method: 提出了一种轻量级、自适应的重用策略，通过重用空间或时间上相关的令牌在单个通道上的部分注意力分数来近似注意力计算。

Result: 与最先进的技术相比，在 4 个 vDiT 模型上实现了 85% 的计算节省，视频质量损失小于 0.06%（在 VBench 上）。

Conclusion: 所提出的方法有效地利用了 vDiT 中的时空相关性，显著提高了推理速度，同时保持了视频质量。

Abstract: The recent surge in video generation has shown the growing demand for high-quality video synthesis using large vision models. Existing video generation models are predominantly based on the video diffusion transformer (vDiT), however, they suffer from substantial inference delay due to self-attention. While prior studies have focused on reducing redundant computations in self-attention, they often overlook the inherent spatio-temporal correlations in video streams and directly leverage sparsity patterns from large language models to reduce attention computations.
  In this work, we take a principled approach to accelerate self-attention in vDiTs by leveraging the spatio-temporal correlations in the latent space. We show that the attention patterns within vDiT are primarily due to the dominant spatial and temporal correlations at the token channel level. Based on this insight, we propose a lightweight and adaptive reuse strategy that approximates attention computations by reusing partial attention scores of spatially or temporally correlated tokens along individual channels. We demonstrate that our method achieves significantly higher computational savings (85\%) compared to state-of-the-art techniques over 4 vDiTs, while preserving almost identical video quality ($<$0.06\% loss on VBench).

</details>


### [589] [A digital SRAM-based compute-in-memory macro for weight-stationary dynamic matrix multiplication in Transformer attention score computation](https://arxiv.org/abs/2511.12152)
*Jianyi Yu,Yuxuan Wang,Xiang Fu,Fei Qiao,Ying Wang,Rui Yuan,Liyuan Liu,Cong Shi*

Main category: cs.AR

TL;DR: 该论文提出了一种数字计算内存（CIM）宏，用于高效计算Transformer注意力机制，通过重构计算过程和优化电路设计，实现了高能效和高面积效率，优于现有CPU、GPU及其他Transformer-CIM设计。


<details>
  <summary>Details</summary>
Motivation: 为了在能量效率和性能上满足AI处理器对Transformer注意力机制的需求，并解决传统CIM处理动态矩阵乘法不适用的问题。

Method: 提出了一种数字CIM宏，通过将注意力分数计算重构为基于组合QK权重矩阵的计算，实现了输入直接送入CIM单元获取分数。同时，将二项式矩阵乘法分解为位串行移位和加法操作，并采用零值位跳过、数据驱动字线激活、读写分离的6T单元以及位交替的14T/28T加法器等优化技术。

Result: 所提出的CIM宏在65nm工艺下，面积为0.35 mm2，峰值性能为42.27 GOPS，功耗为1.24 mW（1.0 V供电，100 MHz时钟），能效比为34.1 TOPS/W，面积效率为120.77 GOPS/mm2。与CPU和GPU相比，能效分别提高了25倍和13倍。与同技术节点下的其他Transformer-CIMs相比，能效和面积效率分别提高了至少7倍和2倍。

Conclusion: 所提出的CIM宏在Transformer注意力计算方面具有显著的能效和面积效率优势，在边缘AI应用中具有巨大潜力。

Abstract: Compute-in-memory (CIM) techniques are widely employed in energy-efficient artificial intelligent (AI) processors. They alleviate power and latency bottlenecks caused by extensive data movements between compute and storage units. This work proposes a digital CIM macro to compute Transformer attention. To mitigate dynamic matrix multiplication that is unsuitable for the common weight-stationary CIM paradigm, we reformulate the attention score computation process based on a combined QK-weight matrix, so that inputs can be directly fed to CIM cells to obtain the score results. Moreover, the involved binomial matrix multiplication operation is decomposed into 4 groups of bit-serial shifting and additions, without costly physical multipliers in the CIM. We maximize the energy efficiency of the CIM circuit through zero-value bit-skipping, data-driven word line activation, read-write separate 6T cells and bit-alternating 14T/28T adders. The proposed CIM macro was implemented using a 65-nm process. It occupied only 0.35 mm2 area, and delivered a 42.27 GOPS peak performance with 1.24 mW power consumption at a 1.0 V power supply and a 100 MHz clock frequency, resulting in 34.1 TOPS/W energy efficiency and 120.77 GOPS/mm2 area efficiency. When compared to the CPU and GPU, our CIM macro is 25x and 13x more energy efficient on practical tasks, respectively. Compared with other Transformer-CIMs, our design exhibits at least 7x energy efficiency and at least 2x area efficiency improvements when scaled to the same technology node, showcasing its potential for edge-side intelligent applications.

</details>


### [590] [Sangam: Chiplet-Based DRAM-PIM Accelerator with CXL Integration for LLM Inferencing](https://arxiv.org/abs/2511.12286)
*Khyati Kiyawat,Zhenxing Fan,Yasas Seneviratne,Morteza Baradaran,Akhil Shekar,Zihan Xia,Mingu Kang,Kevin Skadron*

Main category: cs.AR

TL;DR: LLMs 内存瓶颈通过基于 chiplet 的 PIM 内存模块 Sangam 解决，该模块在 LLaMA、Mistral 和 LLaMA 3 上实现了显著的性能提升和能耗降低。


<details>
  <summary>Details</summary>
Motivation: LLMs 随着模型规模和上下文长度的增加，内存消耗急剧增长，导致内存带宽成为推理瓶颈。现有 PIM 解决方案因集成成本和技术限制而受损。

Method: 提出了一种基于 chiplet 的内存模块 Sangam，将逻辑和内存分离到异构技术节点中，并通过互连器连接。该模块集成了先进的处理组件，如 systolic arrays 和基于 SRAM 的缓冲区，以加速内存密集型 GEMM 内核。

Result: Sangam 在 LLaMA 2-7B、Mistral-7B 和 LLaMA 3-70B 上，与 H100 GPU 相比，在查询延迟方面实现了 3.93x、4.22x 和 2.82x 的加速，在解码吞吐量方面实现了 10.3x、9.5x 和 6.36x 的加速，并实现了数量级的节能。

Conclusion: Sangam 作为一个 CXL 连接的 PIM chiplet 内存模块，通过解决现有 PIM 架构的局限性，显著提高了 LLMs 的性能和能效，并可作为 GPU 的替代品或与其协同工作。

Abstract: Large Language Models (LLMs) are becoming increasingly data-intensive due to growing model sizes, and they are becoming memory-bound as the context length and, consequently, the key-value (KV) cache size increase. Inference, particularly the decoding phase, is dominated by memory-bound GEMV or flat GEMM operations with low operational intensity (OI), making it well-suited for processing-in-memory (PIM) approaches. However, existing in/near-memory solutions face critical limitations such as reduced memory capacity due to the high area cost of integrating processing elements (PEs) within DRAM chips, and limited PE capability due to the constraints of DRAM fabrication technology. This work presents a chiplet-based memory module that addresses these limitations by decoupling logic and memory into chiplets fabricated in heterogeneous technology nodes and connected via an interposer. The logic chiplets sustain high bandwidth access to the DRAM chiplets, which house the memory banks, and enable the integration of advanced processing components such as systolic arrays and SRAM-based buffers to accelerate memory-bound GEMM kernels, capabilities that were not feasible in prior PIM architectures. We propose Sangam, a CXL-attached PIM-chiplet based memory module that can either act as a drop-in replacement for GPUs or co-executes along side the GPUs. Sangam achieves speedup of 3.93, 4.22, 2.82x speedup in end-to-end query latency, 10.3, 9.5, 6.36x greater decoding throughput, and order of magnitude energy savings compared to an H100 GPU for varying input size, output length, and batch size on LLaMA 2-7B, Mistral-7B, and LLaMA 3-70B, respectively.

</details>


### [591] [Pushing the Memory Bandwidth Wall with CXL-enabled Idle I/O Bandwidth Harvesting](https://arxiv.org/abs/2511.12349)
*Divya Kiran Kadiyala,Alexandros Daglis*

Main category: cs.AR

TL;DR: 服务器CPU核心数量的不断增加对内存系统提出了更高的要求，而内存系统受限于有限的芯片引脚和数据传输速率的可扩展性。因此，高端处理器通常每个核心的内存带宽较低，这不利于内存密集型工作负载。我们提出通过提高CPU有限引脚的利用率来缓解这一挑战。在一个典型的CPU设计过程中，可用的引脚被分配给内存和I/O流量，两者各占总芯片外带宽可用性的一半。因此，除非内存和I/O同时被高度利用，否则这种碎片化会导致宝贵的芯片外带宽资源利用不足。理想的架构将提供I/O和内存带宽的可替代性，允许根据每种工作负载的需要来使用总的芯片外带宽。在本工作中，我们引入了SURGE，一种软件支持的架构技术，通过挽救闲置的I/O带宽资源来提高内存带宽的可用性。SURGE利用了像CXL这样的通用互连技术的强大功能，可以在同一处理器接口上动态地多路复用内存和I/O流量。我们证明了增强SURGE的架构可以将带宽受限服务器上的内存密集型工作负载加速高达1.3倍。


<details>
  <summary>Details</summary>
Motivation: 随着服务器CPU核心数量的不断增加，内存系统面临着带宽瓶颈，因为每个核心的内存带宽会降低，这会影响内存密集型工作负载的性能。然而，CPU的芯片外引脚数量有限，并且这些引脚通常被平均分配给内存和I/O流量，导致在任一流量不满载时带宽资源利用不足。因此，有必要提高芯片外带宽的利用率，使其能够根据需要灵活地用于内存或I/O流量。

Method: SURGE是一种软件支持的架构技术，它利用CXL等通用互连技术，允许在同一处理器接口上动态地多路复用内存和I/O流量。通过这种方式，SURGE可以将闲置的I/O带宽资源用于内存访问，从而提高内存带宽的可用性。

Result: SURGE技术可以将内存密集型工作负载在带宽受限服务器上的性能提高高达1.3倍。

Conclusion: SURGE是一种有效的技术，通过动态复用内存和I/O流量来提高CPU芯片外带宽的利用率，从而显著加速内存密集型工作负载的性能。

Abstract: The continual increase of cores on server-grade CPUs raises demands on memory systems, which are constrained by limited off-chip pin and data transfer rate scalability. As a result, high-end processors typically feature lower memory bandwidth per core, at the detriment of memory-intensive workloads. We propose alleviating this challenge by improving the utility of the CPU's limited pins. In a typical CPU design process, the available pins are apportioned between memory and I/O traffic, each accounting for about half of the total off-chip bandwidth availability. Consequently, unless both memory and I/O are simultaneously highly utilized, such fragmentation leads to underutilization of the valuable off-chip bandwidth resources. An ideal architecture would offer I/O and memory bandwidth fungibility, allowing use of the aggregate off-chip bandwidth in the form required by each workload.
  In this work, we introduce SURGE, a software-supported architectural technique that boosts memory bandwidth availability by salvaging idle I/O bandwidth resources. SURGE leverages the capability of versatile interconnect technologies like CXL to dynamically multiplex memory and I/O traffic over the same processor interface. We demonstrate that SURGE-enhanced architectures can accelerate memory-intensive workloads on bandwidth-constrained servers by up to 1.3x.

</details>


### [592] [SynapticCore-X: A Modular Neural Processing Architecture for Low-Cost FPGA Acceleration](https://arxiv.org/abs/2511.12616)
*Arya Parameshwara*

Main category: cs.AR

TL;DR: SynapticCore-X是一个模块化、资源高效的神经处理架构，针对低成本FPGA平台进行了优化，支持可配置的神经网络计算和硬件软件协同设计。


<details>
  <summary>Details</summary>
Motivation: 为低成本FPGA平台提供一个模块化、资源高效且可完全开源的神经处理架构，以降低神经微架构研究的门槛。

Method: 集成轻量级RISC-V控制核心和可配置的神经计算瓦片，支持矩阵、激活和数据移动操作的融合。提供完全开源的SystemVerilog微架构，允许调整并行度、片上内存深度和DMA突发行为。

Result: 在Zynq-7020上实现了100 MHz的时序收敛，资源占用率低（6.1% LUTs, 32.5% DSPs, 21.4% BRAMs）。硬件验证确认了寄存器级执行、确定性控制流和循环精确的性能。

Conclusion: SynapticCore-X证明了能在普通的教育FPGA上原型化开发高能效的类NPU加速器，有效降低了学术界和开放硬件在神经微架构研究领域的入门门槛。

Abstract: This paper presents SynapticCore-X, a modular and resource-efficient neural processing architecture optimized for deployment on low-cost FPGA platforms. The design integrates a lightweight RV32IMC RISC-V control core with a configurable neural compute tile that supports fused matrix, activation, and data-movement operations. Unlike existing FPGA accelerators that rely on heavyweight IP blocks, SynapticCore-X provides a fully open-source SystemVerilog microarchitecture with tunable parallelism, scratchpad memory depth, and DMA burst behavior, enabling rapid exploration of hardware-software co-design trade-offs. We document an automated, reproducible Vivado build pipeline that achieves timing closure at 100 MHz on the Zynq-7020 while consuming only 6.1% LUTs, 32.5% DSPs, and 21.4% BRAMs. Hardware validation on PYNQ-Z2 confirms correct register-level execution, deterministic control-path behavior, and cycle-accurate performance for matrix and convolution kernels. SynapticCore-X demonstrates that energy-efficient NPU-like acceleration can be prototyped on commodity educational FPGAs, lowering the entry barrier for academic and open-hardware research in neural microarchitectures.

</details>


### [593] [Dissecting and Re-architecting 3D NAND Flash PIM Arrays for Efficient Single-Batch Token Generation in LLMs](https://arxiv.org/abs/2511.12860)
*Yongjoo Jang,Sangwoo Hwang,Hojin Lee,Sangwoo Jung,Donghun Lee,Wonbo Shim,Jaeha Kung*

Main category: cs.AR

TL;DR: 提出将大语言模型（LLM）的单批次token生成任务卸载到3D NAND闪存处理内存（PIM）设备上，以克服DRAM容量限制和GPU成本问题。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型参数量巨大，对内存和计算资源需求极高，在传统硬件上部署面临DRAM容量不足和GPU成本高昂的挑战。

Method: 提出将LLM的单批次token生成任务卸载到3D NAND闪存PIM设备，利用其高存储密度解决DRAM容量瓶颈。探索了3D NAND闪存配置，并提出了一种改进的PIM阵列结构（H形树网络）以优化延迟和密度。开发了LLM层级的操作分块和映射方法。

Result: 使用所提出的3D NAND闪存PIM架构，实现了比使用4块RTX4090（结合vLLM）快2.4倍的性能，并实现了与4块A100相当的性能，同时延迟开销仅为4.9%。详细的面积分析表明，该PIM架构可以在4.98mm2的芯片面积内集成，且无额外面积开销。

Conclusion: 所提出的3D NAND闪存PIM架构能够有效解决大语言模型部署中的内存容量和成本问题，并在性能和面积效率上展现出显著优势。

Abstract: The advancement of large language models has led to models with billions of parameters, significantly increasing memory and compute demands. Serving such models on conventional hardware is challenging due to limited DRAM capacity and high GPU costs. Thus, in this work, we propose offloading the single-batch token generation to a 3D NAND flash processing-in-memory (PIM) device, leveraging its high storage density to overcome the DRAM capacity wall. We explore 3D NAND flash configurations and present a re-architected PIM array with an H-tree network for optimal latency and cell density. Along with the well-chosen PIM array size, we develop operation tiling and mapping methods for LLM layers, achieving a 2.4x speedup over four RTX4090 with vLLM and comparable performance to four A100 with only 4.9% latency overhead. Our detailed area analysis reveals that the proposed 3D NAND flash PIM architecture can be integrated within a 4.98mm2 die area under the memory array, without extra area overhead.

</details>


### [594] [Neo: Real-Time On-Device 3D Gaussian Splatting with Reuse-and-Update Sorting Acceleration](https://arxiv.org/abs/2511.12930)
*Changhun Oh,Seongryong Oh,Jinwoo Hwang,Yoonsung Kim,Hardik Sharma,Jongse Park*

Main category: cs.AR

TL;DR: Neo通过引入复用和更新排序算法及专用硬件加速器，显著提升了3D高斯溅射在资源受限设备上的实时渲染性能，解决了现有方案在高分辨率渲染时帧率不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的设备上实现3D高斯溅射（3DGS）的实时渲染对于提供沉浸式AR/VR体验至关重要，但现有方法在高分辨率渲染时难以达到高帧率。

Method: Neo引入了一种复用和更新排序算法，该算法利用了连续帧之间高斯排序的时间冗余，并设计了一个针对该算法优化的硬件加速器。通过有效地跟踪和更新高斯深度排序，而不是从头开始重新排序，Neo显著减少了冗余计算和内存带宽压力。

Result: 实验结果表明，Neo的吞吐量相比最先进的边缘GPU和ASIC解决方案分别提高了10.0倍和5.6倍，同时DRAM流量分别减少了94.5%和81.3%。

Conclusion: Neo通过减少冗余计算和内存带宽压力，使得高质量、低延迟的设备端3D渲染更加实用。

Abstract: 3D Gaussian Splatting (3DGS) rendering in real-time on resource-constrained devices is essential for delivering immersive augmented and virtual reality (AR/VR) experiences. However, existing solutions struggle to achieve high frame rates, especially for high-resolution rendering. Our analysis identifies the sorting stage in the 3DGS rendering pipeline as the major bottleneck due to its high memory bandwidth demand. This paper presents Neo, which introduces a reuse-and-update sorting algorithm that exploits temporal redundancy in Gaussian ordering across consecutive frames, and devises a hardware accelerator optimized for this algorithm. By efficiently tracking and updating Gaussian depth ordering instead of re-sorting from scratch, Neo significantly reduces redundant computations and memory bandwidth pressure. Experimental results show that Neo achieves up to 10.0x and 5.6x higher throughput than state-of-the-art edge GPU and ASIC solution, respectively, while reducing DRAM traffic by 94.5% and 81.3%. These improvements make high-quality and low-latency on-device 3D rendering more practical.

</details>


### [595] [Think with Self-Decoupling and Self-Verification: Automated RTL Design with Backtrack-ToT](https://arxiv.org/abs/2511.13139)
*Zhiteng Chao,Yonghao Wang,Xinyu Zhang,Jiaxin Zhou,Tenghui Hua,Husheng Han,Tianmeng Yang,Jianan Mu,Bei Yu,Rui Zhang,Jing Ye,Huawei Li*

Main category: cs.AR

TL;DR: VeriBToT是一种新的LLM推理范式，用于自动化Verilog生成，通过集成自顶向下和DFV方法，实现中间步骤的自解耦和自验证，并构建具有形式化算子的思想回溯树，相比传统的CoT范式，它提高了Verilog生成的质量，同时通过灵活的模块化、层次化和可重用性优化了代币成本。


<details>
  <summary>Details</summary>
Motivation: 在自动化集成电路（IC）工程中使用大型语言模型（LLM）生成硬件描述语言（HDL）如Verilog时，面临着生成质量不高，复杂设计难以一次性生成，以及解耦子任务难以验证等挑战。传统的链式思考（CoT）方法在IC设计工作流中效果不佳，需要人工干预，主要原因是无法控制CoT推理的方向和步骤粒度，这与RTL设计专家的知识不匹配。

Method: VeriBToT通过集成自顶向下（Top-down）和面向验证的设计（DFV）方法，实现了中间步骤的自解耦和自验证，并构建了具有形式化算子的思想回溯树（Backtrack Tree of Thought）。

Result: 与传统的CoT范式相比，VeriBToT在Verilog生成方面表现更优，同时通过灵活的模块化、层次化和可重用性优化了代币成本。

Conclusion: VeriBToT通过其独特的设计，有效解决了自动化Verilog生成中的质量和效率问题，为LLM在IC工程领域的应用提供了新的解决方案。

Abstract: Large language models (LLMs) hold promise for automating integrated circuit (IC) engineering using register transfer level (RTL) hardware description languages (HDLs) like Verilog. However, challenges remain in ensuring the quality of Verilog generation. Complex designs often fail in a single generation due to the lack of targeted decoupling strategies, and evaluating the correctness of decoupled sub-tasks remains difficult. While the chain-of-thought (CoT) method is commonly used to improve LLM reasoning, it has been largely ineffective in automating IC design workflows, requiring manual intervention. The key issue is controlling CoT reasoning direction and step granularity, which do not align with expert RTL design knowledge. This paper introduces VeriBToT, a specialized LLM reasoning paradigm for automated Verilog generation. By integrating Top-down and design-for-verification (DFV) approaches, VeriBToT achieves self-decoupling and self-verification of intermediate steps, constructing a Backtrack Tree of Thought with formal operators. Compared to traditional CoT paradigms, our approach enhances Verilog generation while optimizing token costs through flexible modularity, hierarchy, and reusability.

</details>


### [596] [Coliseum project: Correlating climate change data with the behavior of heritage materials](https://arxiv.org/abs/2511.13343)
*A Cormier,David Roqui,Fabrice Surma,Martin Labouré,Jean-Marc Vallet,Odile Guillon,N Grozavu,Ann Bourgès*

Main category: cs.AR

TL;DR: 该COLISEUM项目提出了一种在法国三个遗址收集数据的方法，利用人工智能计算机模型预测文物材料的行为，以应对气候变化对文物的影响。


<details>
  <summary>Details</summary>
Motivation: 气候变化正在影响文物材料，气候变化增加了石化程度，缩短了纪念碑的使用寿命。由于风化取决于许多因素，因此很难将其进展与气候变化联系起来。为了预测风化，必须收集气候数据，同时监测风化进展。所收集数据的多模态性质（图像、文本等）使得相关性难以确定，尤其是在不同的时间尺度上。

Method: COLISEUM项目提出了一种在法国三个遗址收集数据的方法，利用人工智能计算机模型预测文物材料的行为。该方法包括在斯特拉斯堡大教堂、比布拉克特考古遗址和圣皮埃尔教堂进行现场监测，并收集气候数据和病害数据。通过计算风化指数，将数据收集到风化矩阵中，以实施风化模型。

Result: 该文章介绍了仪器方法、初步诊断以及斯特拉斯堡大教堂现场的第一个示例结果。在每个地点，微气候传感器会持续记录随时间变化的参数。通过化学分析、绘图测量和科学成像活动，定期监测风化状态。

Conclusion: 该COLISEUM项目旨在通过利用人工智能计算机模型预测文物材料的行为，来应对气候变化对文物的影响。通过收集和分析来自不同气候变化情景的已知数据，预测模型将能够预测材料的未来行为。

Abstract: Heritage materials are already affected by climate change, and increasing climatic variations reduces the lifespan of monuments. As weathering depends on many factors, it is also difficult to link its progression to climatic changes. To predict weathering, it is essential to gather climatic data while simultaneously monitoring the progression of deterioration. The multimodal nature of collected data (images, text{\ldots}) makes correlations difficult, particularly on different time scales. To address this issue, the COLISEUM project proposes a methodology for collecting data in three French sites to predict heritage material behaviour using artificial intelligence computer models. Over time, prediction models will allow the prediction of future material behaviours using known data from different climate change scenarios by the IPCC (Intergovernmental Panel on Climate Change). Thus, a climate monitoring methodology has been set up in three cultural sites in France: Notre-Dame cathedral in Strasbourg ( 67), Bibracte archaeological site (71), and the Saint-Pierre chapel in Villefranche-sur-Mer (06). Each site has a different climate and specific materials. In situ, microclimatic sensors continuously record variations parameters over time. The state of alteration is monitored at regular intervals by means of chemical analyses, cartographic measurements and scientific imaging campaigns. To implement weathering models, data is gathered in alteration matrix by mean of a calculated weathering index. This article presents the instrumentation methodology, the initial diagnostic and the first results with the example of Strasbourg Cathedral site.

</details>


### [597] [T-SAR: A Full-Stack Co-design for CPU-Only Ternary LLM Inference via In-Place SIMD ALU Reorganization](https://arxiv.org/abs/2511.13676)
*Hyunwoo Oh,KyungIn Nam,Rajat Bhattacharjya,Hanning Chen,Tamoghno Das,Sanggeon Yun,Suyeon Jang,Andrew Ding,Nikil Dutt,Mohsen Imani*

Main category: cs.AR

TL;DR: T-SAR是一个在CPU上进行可扩展三元LLM推理的框架，通过在寄存器文件中动态生成查找表来克服内存瓶颈，实现高效率和低功耗。


<details>
  <summary>Details</summary>
Motivation: 现有的边缘计算平台（主要使用CPU）在部署大型语言模型（LLM）时面临计算和内存能力的挑战。虽然三元量化能节省资源，但现有的CPU解决方案依赖内存查找表（LUT），这限制了可扩展性，而FPGA或GPU则不适用于边缘设备。

Method: T-SAR框架通过重新利用SIMD寄存器文件来动态生成片内LUT，无需进行大规模硬件修改，从而实现了可扩展的三元LLM推理。

Result: T-SAR消除了内存瓶颈并最大化了数据级并行性，在GEMM延迟方面实现了5.6-24.5倍的提升，在GEMV吞吐量方面实现了1.1-86.2倍的提升，同时在SIMD单元上仅增加了3.2%的功耗和1.4%的面积开销。与NVIDIA Jetson AGX Orin相比，T-SAR的能效最高可提高2.5-4.9倍。

Conclusion: T-SAR为在边缘平台上实现高效LLM推理提供了一种实用的方法，通过在CPU上实现可扩展的三元LLM推理，显著提高了性能并降低了功耗。

Abstract: Recent advances in LLMs have outpaced the computational and memory capacities of edge platforms that primarily employ CPUs, thereby challenging efficient and scalable deployment. While ternary quantization enables significant resource savings, existing CPU solutions rely heavily on memory-based lookup tables (LUTs) which limit scalability, and FPGA or GPU accelerators remain impractical for edge use. This paper presents T-SAR, the first framework to achieve scalable ternary LLM inference on CPUs by repurposing the SIMD register file for dynamic, in-register LUT generation with minimal hardware modifications. T-SAR eliminates memory bottlenecks and maximizes data-level parallelism, delivering 5.6-24.5x and 1.1-86.2x improvements in GEMM latency and GEMV throughput, respectively, with only 3.2% power and 1.4% area overheads in SIMD units. T-SAR achieves up to 2.5-4.9x the energy efficiency of an NVIDIA Jetson AGX Orin, establishing a practical approach for efficient LLM inference on edge platforms.

</details>


### [598] [QUILL: An Algorithm-Architecture Co-Design for Cache-Local Deformable Attention](https://arxiv.org/abs/2511.13679)
*Hyunwoo Oh,Hanning Chen,Sanggeon Yun,Yang Ni,Wenjun Huang,Tamoghno Das,Suyeon Jang,Mohsen Imani*

Main category: cs.AR

TL;DR: Deformable transformers are powerful for detection but inefficient on hardware. QUILL is a new accelerator that makes deformable attention more hardware-friendly by optimizing memory access and computation, achieving significant speedups and energy efficiency improvements.


<details>
  <summary>Details</summary>
Motivation: Deformable transformers achieve state-of-the-art results in object detection but suffer from poor hardware performance due to irregular memory access and low arithmetic intensity.

Method: The paper introduces QUILL, a schedule-aware accelerator that optimizes deformable attention for hardware. It uses a core technique called Distance-based Out-of-Order Querying (DOOQ) to order queries by spatial proximity and prefetch data into an alternate buffer. This creates a prefetch loop that overlaps memory access and computation. A fused MSDeformAttn engine performs interpolation, Softmax, aggregation, and projection in a single pass, keeping small tensors on-chip and running dense layers on integrated GEMMs.

Result: Quill achieves up to 7.29x higher throughput and 47.3x better energy efficiency compared to an RTX 4090. It also outperforms prior accelerators by 3.26-9.82x in throughput and 2.01-6.07x in energy efficiency. With mixed-precision quantization, accuracy remains within 0.9 AP of FP32 performance across different Deformable and Sparse DETR variants.

Conclusion: Quill effectively converts sparsity into locality, and locality into utilization, resulting in consistent end-to-end speedups for deformable transformers. The accelerator significantly improves hardware efficiency for these models.

Abstract: Deformable transformers deliver state-of-the-art detection but map poorly to hardware due to irregular memory access and low arithmetic intensity. We introduce QUILL, a schedule-aware accelerator that turns deformable attention into cache-friendly, single-pass work. At its core, Distance-based Out-of-Order Querying (DOOQ) orders queries by spatial proximity; the look-ahead drives a region prefetch into an alternate buffer--forming a schedule-aware prefetch loop that overlaps memory and compute. A fused MSDeformAttn engine executes interpolation, Softmax, aggregation, and the final projection (W''m) in one pass without spilling intermediates, while small tensors are kept on-chip and surrounding dense layers run on integrated GEMMs. Implemented as RTL and evaluated end-to-end, QUILL achieves up to 7.29x higher throughput and 47.3x better energy efficiency than an RTX 4090, and exceeds prior accelerators by 3.26-9.82x in throughput and 2.01-6.07x in energy efficiency. With mixed-precision quantization, accuracy tracks FP32 within <=0.9 AP across Deformable and Sparse DETR variants. By converting sparsity into locality--and locality into utilization--QUILL delivers consistent, end-to-end speedups.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [599] [A Logspace Constructive Proof of L=SL](https://arxiv.org/abs/2511.12011)
*Sam Buss,Anant Dhayal,Valentine Kabanets,Antonina Kolokolova,Sasank Mouli*

Main category: cs.LO

TL;DR: 本文在有界算术理论VL中形式化了Reingold定理SL=L的证明，该定理对应于“logspace推理”。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是在有界算术理论VL中形式化Reingold定理SL=L的证明，并解决Kolokolova关于VL=VSL的遗留问题。

Method: 通过利用Rozenman-Vadhan的Reingold定理替代证明，并结合Buss-Kabanets-Kolokolova-Koucký的结果，避免了特征值和特征向量的推理，从而在VL中进行图扩张的组合推理。

Result: 本文证明了VL=VSL，其中VSL是有界算术理论中的“对称logspace推理”。

Conclusion: 本文成功地在有界算术理论VL中形式化了Reingold定理SL=L的证明，并解决了VSL理论与VL理论相等的问题。

Abstract: We formalize the proof of Reingold's Theorem that SL=L [Rei05] in the theory of bounded arithmetic VL, which corresponds to ``logspace reasoning''. As a consequence, we get that VL=VSL, where VSL is the theory of bounded arithmetic for ``symmetric-logspace reasoning''. This resolves in the affirmative an old open question from Kolokolova [Kol05] (see also Cook-Nguyen [NC10]).
  Our proof relies on the Rozenman-Vadhan alternative proof of Reingold's Theorem ([RV05]). To formalize this proof in VL, we need to avoid reasoning about eigenvalues and eigenvectors (common in both original proofs of SL=L). We achieve this by using some results from Buss-Kabanets-Kolokolova-Koucký [Bus+20] that allow VL to reason about graph expansion in combinatorial terms.

</details>


### [600] [Proceedings Seventh International Workshop on Formal Methods for Autonomous Systems](https://arxiv.org/abs/2511.13245)
*Matt Luckcuck,Maike Schwammberger,Mengwei Xu*

Main category: cs.LO

TL;DR: 本 EPTCS 体积包含第七届自动化系统形式化方法国际研讨会 (FMAS 2025) 的论文，该研讨会于 2025 年 11 月 17 日至 19 日举行。FMAS 研讨会系列旨在汇集致力于解决自主系统带来的独特挑战的形式化方法的研究人员，以便他们能够与日益壮大的研究界发表和讨论他们的工作。FMAS 2025 与第 20 届集成形式化方法国际会议 (iFM'25) 同地举行，由法国 Inria Paris 在 Inria Paris 中心主办。


<details>
  <summary>Details</summary>
Motivation: FMAS 研讨会系列旨在汇集致力于解决自主系统带来的独特挑战的形式化方法的研究人员，以便他们能够与日益壮大的研究界发表和讨论他们的工作。

Method: 本 EPTCS 体积包含第七届自动化系统形式化方法国际研讨会 (FMAS 2025) 的论文，该研讨会于 2025 年 11 月 17 日至 19 日举行。FMAS 2025 共收到来自加拿大、中国、法国、德国、爱尔兰、意大利、日本、荷兰、葡萄牙、瑞典、美国和英国机构的 16 篇投稿。

Result: FMAS 2025 共收到来自加拿大、中国、法国、德国、爱尔兰、意大利、日本、荷兰、葡萄牙、瑞典、美国和英国机构的 16 篇投稿。尽管投稿数量少于去年，但投稿来自多个国家，这令人鼓舞。投稿作者既有 FMAS 的老作者，也有新作者，这表明现有的社区赞赏 FMAS 7 年来建立的网络，而新作者也表明 FMAS 社区具有巨大的增长潜力。

Conclusion: FMAS 2025 吸引了来自多个国家的投稿，并且作者群体既有老成员也有新成员，这表明了社区的稳定性和增长潜力。

Abstract: This EPTCS volume contains the papers from the Seventh International Workshop on Formal Methods for Autonomous Systems (FMAS 2025), which was held between the 17th and 19th of November 2025. The goal of the FMAS workshop series is to bring together leading researchers who are using formal methods to tackle the unique challenges that autonomous systems present, so that they can publish and discuss their work with a growing community of researchers. FMAS 2025 was co-located with the 20th International Conference on integrated Formal Methods (iFM'25), hosted by Inria Paris, France at the Inria Paris Center. 
  In total, FMAS 2025 received 16 submissions from researchers at institutions in: Canada, China, France, Germany, Ireland, Italy, Japan, the Netherlands, Portugal, Sweden, the United States of America, and the United Kingdom. Though we received fewer submissions than last year, we are encouraged to see the submissions being sent from a wide range of countries. Submissions come from both past and new FMAS authors, which shows us that the existing community appreciates the network that FMAS has built over the past 7 years, while new authors also show the FMAS community's great potential of growth.

</details>


### [601] [Multi-Objective Statistical Model Checking using Lightweight Strategy Sampling (extended version)](https://arxiv.org/abs/2511.13460)
*Pedro R. D'Argenio,Arnd Hartmanns,Patrick Wienhöft,Mark van Wijk*

Main category: cs.LO

TL;DR: 本研究提出了一种新的多目标统计模型检测方法，用于在有限时间内找到最优权衡的帕累托前沿，并实现了效率上的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的统计模型检测方法一次只能评估一个属性值，无法满足实际问题中寻找多目标帕累托前沿的需求。

Method: 提出了一种增量式方案，利用轻量级策略采样来优化模型的不确定性选择，该方案几乎可以肯定地收敛于统计上可靠的置信带，并从两侧包围真实的帕累托前沿。为了在有限时间内获得真实前沿的近似下界，还提出了三种启发式方法来处理预定的采样预算。

Result: 实现了统计上可靠的置信带，可以从两侧包围真实的帕累托前沿，并提出了三种启发式方法在有限时间内获得真实前沿的近似下界。

Conclusion: 提出的多目标统计模型检测方法能够有效地处理多目标优化问题，并在定量验证基准测试中显示出其有效性。

Abstract: Statistical model checking delivers quantitative verification results with statistical guarantees by applying Monte Carlo simulation to formal models. It scales to model sizes and model types that are out of reach for exhaustive, analytical techniques. So far, it has been used to evaluate one property value at a time only. Many practical problems, however, require finding the Pareto front of optimal tradeoffs between multiple possibly conflicting optimisation objectives. In this paper, we present the first statistical model checking approach for such multi-objective Pareto queries, using lightweight strategy sampling to optimise over the model's nondeterministic choices. We first introduce an incremental scheme that almost surely converges to a statistically sound confidence band bounding the true Pareto front from both sides in the long run. To obtain a close underapproximation of the true front in finite time, we then propose three heuristic approaches that try to make the best of an a-priori fixed sampling budget. We implement our new techniques in the Modest Toolset's 'modes' simulator, and experimentally show their effectiveness on quantitative verification benchmarks.

</details>


### [602] [Subgraph Isomorphism: Prolog vs. Conventional](https://arxiv.org/abs/2511.13600)
*Claire Y. Yin,Peter M. Kogge*

Main category: cs.LO

TL;DR: 在具有挑战性的图问题中，逻辑编程比传统编程更有效。


<details>
  <summary>Details</summary>
Motivation: 探索逻辑编程与传统编程在解决复杂图问题时的性能差异。

Method: 将图模式转换为Prolog逻辑语句，并分析随着图大小增加而产生的特征。

Result: 逻辑编程方法在处理复杂图问题时显示出效率。

Conclusion: 逻辑编程是一种处理复杂图问题的有效方法。

Abstract: Subgraph Isomorphism uses a small graph as a pattern to identify within a larger graph a set of vertices that have matching edges. This paper addresses a logic program written in Prolog for a specific relatively complex graph pattern for which multiple conventional implementations (including parallel) exist. The goal is to understand the complexity differences between programming logically and programming conventionally. Discussion includes the process of converting the graph pattern into logic statements in Prolog, and the resulting characteristics as the size of the graph increased. The analysis shows that using a logic paradigm is an efficient way to attack complex graph problems.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [603] [Enhanced Digitized Adiabatic Quantum Factorization Algorithm Using Null-Space Encoding](https://arxiv.org/abs/2511.11747)
*Felip Pellicer*

Main category: quant-ph

TL;DR: 本工作提出了一种简化的基于QAOA的整数分解协议，通过仅包含二体相互作用项，降低了实验复杂度，并在模拟中显示出与标准协议相当或更高的保真度，同时需要更少的量子资源和更快的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 由于Shor算法在通用量子计算机上效率高，而近地量子设备需要替代方法，因此需要研究适用于NISQ时代的整数分解方法。现有的Adiabatic Factorization Algorithm及其数字化版本存在高阶多体相互作用的实现困难。

Method: 提出了一种修改后的基于QAOA的因子分解协议，将相互作用的哈密顿量简化为只包含二体项。对该方法进行了数值模拟，并分析了哈密顿量修改引入的特征保真度行为。此外，还模拟了使用替代成本函数定义。

Result: 数值模拟显示，该方法实现了与标准协议相当或更高的保真度，同时需要更少的量子资源，并且对于多达八个量子比特的问题实例收敛速度更快。还发现了替代成本函数定义通常能带来性能改进。

Conclusion: 所提出的简化的基于QAOA的因子分解协议在NISQ设备上比标准协议更具可行性，因为它降低了实验复杂度，同时保持或提高了性能，并减少了资源需求。

Abstract: Integer factorization is a computational problem of fundamental importance in cybersecurity and secure communications, as its difficulty form the basis of modern public-key cryptography. While Shor's algorithm can solve this problem efficiently on a universal quantum computer, near-term devices require alternative approaches. The Adiabatic Factorization Algorithm and its digitized counterparts offer a promising NISQ-era pathway but suffer from high-order many-body interactions that are difficult to implement. In this work, we propose a modified QAOA-based factorization protocol that simplifies the interacting Hamiltonian to include only two-body terms, significantly reducing its experimental complexity. Numerical simulations show that this method achieves comparable or higher fidelities than the standard protocol, while requiring fewer quantum resources and converging more rapidly for problem instances up to eight qubits. We analyze the characteristic fidelity behavior introduced by the Hamiltonian modification. Additionally, we report on simulations with alternative cost-function definitions that frequently yielded improved performance.

</details>


### [604] [2025 Quantum Diamond Workshop Findings Report](https://arxiv.org/abs/2511.11791)
*Danielle A. Braje,Matthew L. Markham,Jennifer M. Schloss,Michael A. Slocum,Ronald L. Walsworth*

Main category: quant-ph

TL;DR: 量子金刚石技术研讨会总结了近期进展、挑战和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 旨在评估量子金刚石技术的应用前景，识别技术和结构性障碍，并为材料、设备和应用开发提供协调路径。

Method: 通过技术演示和开放讨论，探讨了短期演示和长期基础设施需求，强调了供应链各方协调的重要性。

Result: 识别了加速量子金刚石技术成熟和商业化的关键主题、挑战和战略行动。

Conclusion: 建议政府、行业和学术界共同努力，以加速量子金刚石技术的进步。

Abstract: This report synthesizes the outcomes of a two-day workshop held in Washington, D.C. in May, 2025 that convened researchers, industry representatives, and government stakeholders to examine the current state and future directions of quantum diamond technologies. The workshop's goals were to assess the most promising use cases, to identify the key technical and structural challenges limiting adoption, and to chart potential pathways for aligning application needs with diamond material and device development. Through a series of technical presentations and open discussions, participants explored both near-term demonstrations and long-term infrastructure needs, highlighting the critical role of coordination between material suppliers, device engineers, and end users. The goal of this report is to distill those insights into a coherent set of cross-cutting themes, challenges, and strategic actions that can guide government, industry, and academic efforts to accelerate the maturation and commercialization of quantum diamond technologies.

</details>


### [605] [Sample-based training of quantum generative models](https://arxiv.org/abs/2511.11802)
*Maria Demidik,Cenk Tüysüz,Michele Grossi,Karl Jansen*

Main category: quant-ph

TL;DR: 该研究提出了一种名为对比度衰减的训练框架，用于解决量子生成模型训练中的挑战，通过优化电路结构实现可扩展训练，并能在模拟环境中达到与基于似然的优化相当的准确性，同时所需采样数量更少。


<details>
  <summary>Details</summary>
Motivation: 量子计算机在采样方面具有优势，可用于量子生成模型，但实际训练面临梯度计算效率低下和噪声等挑战。

Method: 提出一种将对比度衰减原理扩展到量子模型的训练框架，通过推导电路结构和提供构建方法，使量子电路能够生成参数更新所需的样本，实现了与前向传播相似的常数级扩展性。

Result: 数值结果表明，该框架在准确性上可与基于似然的优化相媲美，但所需的采样数量大大减少。

Conclusion: 该框架为直接在量子硬件上训练表达性量子生成模型提供了一条可扩展的途径。

Abstract: Quantum computers can efficiently sample from probability distributions that are believed to be classically intractable, providing a foundation for quantum generative modeling. However, practical training of such models remains challenging, as gradient evaluation via the parameter-shift rule scales linearly with the number of parameters and requires repeated expectation-value estimation under finite-shot noise. We introduce a training framework that extends the principle of contrastive divergence to quantum models. By deriving the circuit structure and providing a general recipe for constructing it, we obtain quantum circuits that generate the samples required for parameter updates, yielding constant scaling with respect to the cost of a forward pass, analogous to backpropagation in classical neural networks. Numerical results demonstrate that it attains comparable accuracy to likelihood-based optimization while requiring substantially fewer samples. The framework thereby establishes a scalable route to training expressive quantum generative models directly on quantum hardware.

</details>


### [606] [Relativistic Maxwell-Bloch Equations with Applications to Astrophysics](https://arxiv.org/abs/2511.11861)
*Ningyan Fang,Martin Houde,Fereshteh Rajabi,Victor Botez*

Main category: quant-ph

TL;DR: 该论文推导了相对论性麦克斯韦-布洛赫方程，并研究了天体环境中可能发生的光谱放大和迪克超辐射等辐射过程。


<details>
  <summary>Details</summary>
Motivation: 研究天体环境中发生的辐射过程，包括光谱放大和迪克超辐射。

Method: 推导相对论性麦克斯韦-布洛赫方程，并推导了适用于稳态条件下的光谱放大方程。

Result: 证明了在不同相对速度下，辐射系统的响应保持不变，而相关时间尺度和辐射强度会根据相对论进行转换。同时，不同速度发射器群体之间的相干性在所有参考系中保持不变。

Conclusion: 研究结果表明，相对论效应对光谱放大和迪克超辐射等辐射过程有重要的影响，并且在天体环境中具有潜在应用价值。

Abstract: We derive relativistic Maxwell-Bloch equations for potential applications in astronomical environments, where various radiative processes are known to occur, including the maser action and Dicke's superradiance. We show that for both phenomena a radiating system's response is preserved at different relative velocities between the system's rest frame and the observer, while the relevant timescales and the radiation intensity transform as expected from relativistic considerations. We verify that the level of coherence between groups of emitters travelling at different speeds is unchanged in all reference frames. We also derive relativistic versions of the maser equations applicable in the steady-state regime.

</details>


### [607] [Compact cavity-dressed Hamiltonian framework at arbitrarily strong light-matter coupling](https://arxiv.org/abs/2511.11903)
*Jakub Garwoła,Dvira Segal*

Main category: quant-ph

TL;DR: 提出一种非微扰哈密顿映射方法，用于处理强耦合于量化场模式（腔）的量子系统，以紧凑的闭式形式表示光-物质混合系统。该方法通过对光子和原子自由度进行纠缠变换，并截断由此产生的腔-缀哈密顿量（CDH）到更大的激发扇区，构建了一系列收敛于精确极限的紧凑模型，在共振和超强光-物质耦合等挑战性条件下，其效率超越了传统方法。该映射原理也适用于多模腔通过非对易算符与物质的耦合以及耗散腔。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为强耦合光-物质混合系统提供一种新的计算方法，以克服传统方法的局限性，并获得紧凑的解析表达，从而促进对这类系统的理解和研究。

Method: 提出一种非微扰哈密顿映射方法，该方法基于对光子和原子自由度的纠缠变换，构建腔-缀哈密顿量（CDH）。通过截断CDH到不同的激发扇区，得到一系列模型，并研究其收敛性。该方法适用于单模、多模、非对易算符耦合以及耗散腔系统。通过对量子Rabi模型和Dicke-Heisenberg格子模型进行基准测试，验证了CDH框架的准确性和效率。

Result: 在量子Rabi模型中，CDH框架在弱耦合和强耦合两种情况下都能够准确预测光谱，并且在基态和热力学可观测量方面也表现出良好的收敛性。在Dicke-Heisenberg格子模型中，研究确定了共振和强光-物质耦合下的相图，并在计算效率上显著优于暴力模拟法，同时能够解析和数值地识别腔介导的自旋相关性。

Conclusion: CDH方法提供了一种紧凑的闭式表示，既能提供物理洞见，又能提高计算效率，为研究强耦合光-物质混合系统提供了有力的工具。

Abstract: We present a non-perturbative Hamiltonian mapping method for quantum systems strongly coupled to a quantized field mode (cavity), yielding compact closed-form representations of hybrid light-matter systems. The mapping method builds on an entangling transformation of photonic and atomic degrees of freedom. By truncating the resulting cavity-dressed Hamiltonian (CDH) to successively larger excitation sectors, we construct a series of compact models that converge to the exact limit, outpacing conventional approaches even in the challenging resonant and ultrastrong light-matter regime. The mapping principle also applies to multimode cavities coupled to matter through noncommuting operators and to leaky cavities. We benchmark the CDH framework on the quantum Rabi model, demonstrating accurate spectral predictions in both weak and strong coupling regimes, together with converging ground-state and thermal observables. We study the Dicke-Heisenberg lattice model and determine its phase diagram under resonant and strong light-matter coupling, achieving significant computational savings over brute-force simulations and identifying cavity-mediated spin correlations both analytically and numerically. The closed-form and compactness of the CDH provide both physical insight and enhanced computational efficiency, facilitating studies of strongly coupled hybrid light-matter systems.

</details>


### [608] [Error-Mitigation Enabled Multicomponent Quantum Simulations Beyond the Born-Oppenheimer Approximation](https://arxiv.org/abs/2511.11941)
*Delmar G. A. Cabral,Brandon Allen,Fabijan Pavošević,Sharon Hammes-Schiffer,Pablo Díez-Valle,Jack S. Baker,Gaurav Saxena,Thi Ha Kyaw,Victor S. Batista*

Main category: quant-ph

TL;DR: 开发了一种多组分幺正耦合簇框架，用于在量子计算机上模拟包含核-电子量子效应的分子系统，并成功应用于氢化正电子鎓和含量子质子的分子氢，同时考虑了误差缓解。


<details>
  <summary>Details</summary>
Motivation: 在量子计算机上模拟包含核-电子量子效应的分子系统，以超越绝热近似。

Method: 开发了多组分幺正耦合簇（mcUCC）方法，并结合了核-电子轨道（NEO）形式主义。使用了局域幺正簇Jastrow（LUcJ）ansatz来降低资源成本，并在IBM Q的Heron量子硬件上进行了实验。应用了受物理启发的外插（PIE）误差缓解协议。

Result: 在量子硬件上成功演示了误差缓解的多组分相关模拟，计算出的基态能量在化学精度范围内，与不确定性水平一致。

Conclusion: 该研究为实现统一电子和核自由度的可扩展算法提供了一条途径。

Abstract: We introduce a multicomponent unitary coupled cluster framework for quantum simulations of molecular systems that incorporate both electronic and nuclear quantum effects beyond the Born-Oppenheimer approximation. Using the nuclear-electronic orbital formalism, we construct mcUCC ansätze for positronium hydride and molecular hydrogen with a quantum proton, and analyze hardware requirements for different excitation truncations. To further reduce resource costs effectively, we employ the local unitary cluster Jastrow ansatz and implement it experimentally on IBM Q's Heron superconducting hardware. With the Physics-Inspired Extrapolation error mitigation protocol, the computed ground-state energies remain within chemical accuracy, consistent with the stated uncertainty level. These results provide the first demonstration of error-mitigated multicomponent correlated simulations on quantum hardware and outline a path toward scalable algorithms unifying electronic and nuclear degrees of freedom.

</details>


### [609] [Emergent synchronization mode in coupled Rydberg atomic chains](https://arxiv.org/abs/2511.11987)
*Weilun Jiang*

Main category: quant-ph

TL;DR: 文章发现了一种新的多链原子振荡模式，与之前的反铁磁同步不同，它具有π相位差，并且是连续时间晶体的共存。


<details>
  <summary>Details</summary>
Motivation: 探索耦合耗散里德堡原子链在调制间距下的新同步模式。

Method: 通过理论分析和仿真，发现了具有π相位差的新型振荡模式，并将其与反铁磁同步区分开。研究了该系统相图，发现了两种连续时间晶体的共存，并识别了Hopf和pitchfork分岔。将结论推广到多链系统并验证了新同步模式的唯一性，同时讨论了实验可行性。

Result: 发现了一种具有π相位差的新型振荡模式，并存在两种连续时间晶体的共存。该模型适用于多链系统，并具有实验可行性。

Conclusion: 文章成功识别了一种新的多链原子振荡模式，并深入分析了其理论基础和实验可行性，为相关领域的研究提供了新的方向。

Abstract: We report a new oscillatory form in the two coupled dissipative Rydberg atomic chains by modulating its spacing. Such oscillation has $π$-phase difference between two neighboring sites, which distinguishes itself from antiferromagnetic-type synchronization in the previous studies. Theoretically, we find a phase with coexisting two types of continuous time crystals, and recognize that the transition belongs to Hopf and pitchfork bifurcation. Furthermore, we generalize the conclusion to multiple chains and verify the uniqueness of the new synchronization mode. We also discuss its experimental feasibility.

</details>


### [610] [Measurement-Based Quantum Computation Using the Spin-1 XXZ Model with Uniaxial Anisotropy](https://arxiv.org/abs/2511.12000)
*Hiroki Ohta,Aaron Merlin Müller,Shunji Tsuchiya*

Main category: quant-ph

TL;DR: 该论文证明了具有单轴各向异性的自旋1 XXZ链（即Haldane相内的单离子各向异性D和Ising各向异性J）的基态可作为实现单量子比特门测量型量子计算的资源态。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机在于探索具有特定各向异性的自旋1 XXZ链基态作为量子计算资源态的可能性，特别是其在Haldane相内的表现，并评估其实现单量子比特门的能力。

Method: 通过理论分析和数值评估，推导了旋转门保真度的解析表达式，并研究了D或J的取值对保真度的影响。分析了反铁磁（AFM）关联的增强如何抑制失败态，从而提高保真度。

Result: 当D或J适当调整时，基本旋转门和由绕x、y和z轴旋转组成的通用单量子比特酉门保真度超过0.99。在$\mathbb Z_2\times\mathbb Z_2$-保护的Haldane相内，保真度由测量后的自旋-自旋关联函数和失败概率决定。

Conclusion: 该研究表明，通过调整单轴各向异性，自旋1 XXZ链的基态可以作为一种高保真度的量子计算资源，特别是在Haldane相内。反铁磁关联的增强是实现高保真度的关键因素。

Abstract: We demonstrate that the ground state of a spin-1 XXZ chain with uniaxial anisotropies, single-ion anisotropy $D$ and Ising anisotropy $J$, within the Haldane phase can serve as a resource state for measurement-based quantum computation implementing single-qubit gates. The gate fidelity of both elementary rotation gates and general single-qubit unitary gates composed of rotations about the $x$-, $y$-, and $z$-axes is evaluated, and is found to exceed 0.99 when $D$ or $J$ is appropriately tuned. Furthermore, we derive an analytic expression for the rotation-gate fidelity under the assumption that the state lies within the $\mathbb Z_2\times\mathbb Z_2$-protected Haldane phase, showing that it is determined by the post-measurement spin-spin correlation function and the failure probability. The observed enhancement of gate fidelity in the spin-1 XXZ chain originates from the strengthening of antiferromagnetic (AFM) correlations near the AFM phase, which effectively suppresses failure states.

</details>


### [611] [Quantum Amplitude-Amplification Eigensolver: A State-Learning-Assisted Approach beyond Energy-Gradient-Based Heuristics](https://arxiv.org/abs/2511.12062)
*Kyunghyun Baek,Seungjin Lee,Joonsuk Huh,Dongkeun Lee,Jinhyoung Lee,M. S. Kim,Jeongho Bang*

Main category: quant-ph

TL;DR: QAAE是一种新的量子算法，用于在近期量子计算机上进行基态估计，它不依赖于变分能量最小化，而是通过量子幅度放大相干地驱动试探态趋向于基态。


<details>
  <summary>Details</summary>
Motivation: 近期量子模拟中的基态估计通常采用变分能量最小化方法，这会受到特定能量景观的挑战。

Method: QAAE算法的每个幅度放大轮次包括关于学习到的试探态的反射操作和在归一化哈密顿量下进行短时演化，并通过辅助比特读出增强的纯目标态，然后通过状态学习步骤重新编码到模型电路中，用于下一轮迭代，整个过程无需计算能量梯度。

Result: QAAE算法在IBM量子处理器上进行了验证，并在H2、LiH和10量子比特的纵横场伊辛模型上进行了数值基准测试，结果表明QAAE可以集成化学启发和硬件高效的量子电路，并且在精度和稳定性方面优于基于梯度的变分量子算法。

Conclusion: QAAE算法是一种不依赖变分方法且兼容硬件的基态估计新途径，适用于近期的量子模拟。

Abstract: Ground-state estimation lies at the heart of a broad range of quantum simulations. Most near-term approaches are cast as variational energy minimization and thus inherit the challenges of problem-specific energy landscapes. We develop the quantum amplitude-amplification eigensolver (QAAE), which departs from the variational paradigm and instead coherently drives a trial state toward the ground state via quantum amplitude amplification. Each amplitude-amplification round interleaves a reflection about the learned trial state with a controlled short-time evolution under a normalized Hamiltonian; an ancilla readout yields an amplitude-amplified pure target state that a state-learning step then re-encodes into an ansatz circuit for the next round -- without evaluating the energy gradients. Under standard assumptions (normalized $\hat{H}$, a nondegenerate ground-state, and a learning update), the ground-state overlap increases monotonically per round and the procedure converges; here, a per-round depth bound in terms of the ansatz depth and Hamiltonian-simulation cost establishes hardware compatibility. Cloud experiments on IBMQ processor verify our amplification mechanism on a two-level Hamiltonian and a two-qubit Ising model, and numerical benchmarks on $\mathrm{H}_2$, $\mathrm{LiH}$, and a $10$-qubit longitudinal-and-transverse-field Ising model show that QAAE integrates with chemistry-inspired and hardware-efficient circuits and can surpass gradient-based VQE in accuracy and stability. These results position QAAE as a variational-free and hardware-compatible route to ground-state estimation for near-term quantum simulation.

</details>


### [612] [Enhanced Nonreciprocal Quantum Battery Performance via Nonlinear Two-Photon Driving](https://arxiv.org/abs/2511.12118)
*Luxin Xu,Changliang Ren*

Main category: quant-ph

TL;DR: 提出一种非线性双光子驱动量子电池模型，通过环境工程实现高效单向充电，并分析了其动力学和效率。


<details>
  <summary>Details</summary>
Motivation: 量子电池作为高效的量子储能装置引起了广泛关注。

Method: 使用马尔可夫主方程方法推导出系统动力学的解析解，并确定了实现动力学平衡的参数范围，研究了双光子驱动与单光子驱动的对比以及系统-浴耦合的优化。

Result: 结果表明，提高驱动强度可以提高能量转换和存储效率，但会增加达到平衡所需的时间。与单光子驱动相比，双光子过程在能量容量和熵调节方面具有显著优势，在更强的驱动下这种优势更加明显。通过优化系统-浴耦合可以进一步提高性能。

Conclusion: 该模型在能量转换效率、存储容量和熵调节方面表现出优越性，并且具有实验可行性，可应用于多种量子平台。

Abstract: Quantum batteries have attracted significant attention as efficient quantum energy storage devices.In this work, we propose a nonlinear two-photon driving quantum battery model featuring nonreciprocal dynamics that enables a highly efficient unidirectional charging mechanism through environmental engineering. Using a Markovian master-equation approach, we derive analytical solutions for the system dynamics and identify the parameter regime required for dynamical equilibration. Our results reveal that increasing the driving strength enhances both energy conversion and storage efficiency, albeit at the cost of longer equilibration times. Compared with single-photon driving, the two-photon process exhibits a pronounced advantage in energy capacity and entropy regulation, which becomes more prominent under stronger driving. Under asymmetric dissipation, optimizing the system-bath coupling can further improve performance. The proposed model is experimentally feasible and can be implemented across multiple quantum platforms, including photonic systems, superconducting circuits, and magnonic devices.

</details>


### [613] [Application of optical squeezing to microresonator based optical sensors](https://arxiv.org/abs/2511.12138)
*Dariya Salykina,Daniil Shakhbaziants,Igor Bilenko,Farid Khalili*

Main category: quant-ph

TL;DR: 高Q值光学微腔可用于构建超越标准量子极限的超灵敏度光学传感器，通过使用压缩态光和腔内压缩技术，可以进一步提高传感器的灵敏度并降低损耗的影响。


<details>
  <summary>Details</summary>
Motivation: 光学微腔的损耗低、能量集中，是光学传感器的理想平台。然而，现有传感器的灵敏度受限于标准量子极限（散粒噪声极限）。

Method: 通过制备压缩态（squeezed state）的光来探测微腔，并探索了腔内压缩技术以减小损耗的影响。

Result: 使用压缩态光可以超越散粒噪声极限，实现的灵敏度仅受限于光学损耗和可用的压缩度。腔内压缩技术可以进一步降低损耗的影响。

Conclusion: 通过使用压缩态光和腔内压缩技术，可以实现超越标准量子极限的高灵敏度光学传感，并且该方法有望进一步提高传感器的性能。

Abstract: High-Q optical microresonators combine low losses and high optical energy concentration in a small effective mode volume, making them an attractive platform for optical sensors. While light is confined in the microresonator by total internal reflection, a portion of the optical field, known as the evanescent field, extends outside. This makes the mode's resonant frequency sensitive to changes in the surrounding environment.
  In this work, we explore the quantum sensitivity limits of this type of sensors. We demonstrate that by preparing the probe light in a squeezed quantum state, it is possible to surpass the shot-noise limit. The resulting sensitivity is constrained only by optical losses and the available degree of squeezing. The influence of the losses can be reduced using additional squeezing of the light inside the microresonator.

</details>


### [614] [Stochastic Shadow Descent: Training Parametrized Quantum Circuits with Shadows of Gradients](https://arxiv.org/abs/2511.12168)
*Sayantan Pramanik,M Girish Chandra*

Main category: quant-ph

TL;DR: 本论文提出了一种名为随机投影梯度下降（SSD）的新优化算法，用于优化参数化量子电路（PQC）。与SPSA等现有算法相比，SSD通过使用参数偏移规则和量子信号处理技术，能够更有效地计算梯度，避免了因中心差分估计产生的偏差，从而提高了训练的稳定性，并证明了算法的收敛性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有PQC优化算法（如SPSA）在每次迭代中仅执行两次电路，无论参数数量多少，且使用中心差分法计算有偏梯度估计，这可能导致训练不稳定。

Method: 提出了一种名为随机投影梯度下降（SSD）的新算法。SSD利用参数偏移规则和量子信号处理技术，构建量子电路来计算梯度无偏估计，从而迭代更新PQC参数。

Result: 理论和数值上证明了SSD算法的收敛性，并给出了最坏情况下的迭代次数界限，同时通过数值实验证明了其有效性。

Conclusion: SSD算法通过计算梯度无偏估计，解决了现有PQC优化算法训练不稳定的问题，并证明了其理论上的收敛性和实际的有效性。

Abstract: In this paper, we focus on the task of optimizing the parameters in Parametrized Quantum Circuits (PQCs). While popular algorithms, such as Simultaneous Perturbation Stochastic Approximation (SPSA), limit the number of circuit-execution to two per iteration, irrespective of the number of parameters in the circuit, they have their own challenges. These methods use central-differences to calculate biased estimates of directional derivatives. We show, both theoretically and numerically, that this may lead to instabilities in \emph{training} the PQCs. To remedy this, we propose Stochastic Shadow Descent (\texttt{SSD}), which uses random-projections (or \emph{shadows}) of the gradient to update the parameters iteratively. We eliminate the bias in directional derivatives by employing the Parameter-Shift Rule, along with techniques from Quantum Signal Processing, to construct a quantum circuit that parsimoniously computes \emph{unbiased estimates} of directional derivatives. Finally, we prove the convergence of the \texttt{SSD} algorithm, provide worst-case bounds on the number of iterations, and numerically demonstrate its efficacy.

</details>


### [615] [Quantum Hyperdimensional Computing: a foundational paradigm for quantum neuromorphic architectures](https://arxiv.org/abs/2511.12664)
*Fabio Cumbo,Rui-Hao Li,Bryan Raubenolt,Jayadev Joshi,Abu Kaisar Mohammad Masum,Sercan Aygun,Daniel Blankenberg*

Main category: quant-ph

TL;DR: QHDC是一种新的量子计算范式，它将HDC的类脑模型与量子计算的本地操作相结合，通过量子态、LCU、OAA、量子相位预言、QFT和Hadamard测试等操作实现HDC的核心功能，并在符号类比推理和监督分类任务中进行了验证，证明了其在实际量子硬件上的可行性。


<details>
  <summary>Details</summary>
Motivation: 许多现有的量子机器学习模型是经典框架的复杂改编，与量子原理不完全契合。HDC模型具有简洁的类脑机制，适合量子本地实现。

Method: 将HDC中的超向量映射到量子态；将捆绑操作实现为基于LCU和OAA的量子平均过程；将绑定操作通过量子相位预言实现；将置换操作通过QFT实现；将向量相似度计算通过基于Hadamard测试的量子态保真度测量实现。

Result: 成功实现了QHDC框架，并通过符号类比推理和监督分类任务进行了验证。与经典计算和理想量子模拟的结果进行了比较分析，并在156位IBM Heron r3量子处理器上进行了实际执行。

Conclusion: QHDC是一种物理上可实现的量子计算技术，它提供了一种新的量子神经形态算法类别，并为解决经典系统难以处理的复杂认知和生物医学问题开辟了新的途径。

Abstract: A significant challenge in quantum computing (QC) is developing learning models that truly align with quantum principles, as many current approaches are complex adaptations of classical frameworks. In this work, we introduce Quantum Hyperdimensional Computing (QHDC), a fundamentally new paradigm. We demonstrate that the core operations of its classical counterpart, Hyperdimensional Computing (HDC), a brain-inspired model, map with remarkable elegance and direct correspondence onto the native operations of a QC. This suggests HDC is exceptionally well-suited for a quantum-native implementation. We establish a direct, resource-efficient mapping: (i) hypervectors are mapped to quantum states, (ii) the bundling operation is implemented as a quantum-native averaging process using a Linear Combination of Unitaries (LCU) and Oblivious Amplitude Amplification (OAA), (iii) the binding operation is realized via quantum phase oracles, (iv) the permutation operation is implemented using the Quantum Fourier Transform (QFT), and (v) vector similarity is calculated using quantum state fidelity measurements based on the Hadamard Test. We present the first-ever implementation of this framework, validated through symbolic analogical reasoning and supervised classification tasks. The viability of QHDC is rigorously assessed via a comparative analysis of results from classical computation, ideal quantum simulation, and execution of a 156-qubit IBM Heron r3 quantum processor. Our results validate the proposed mappings and demonstrate the versatility of the framework, establishing QHDC as a physically realizable technology. This work lays the foundation for a new class of quantum neuromorphic algorithms and opens a promising avenue for tackling complex cognitive and biomedical problems intractable for classical systems.

</details>


### [616] [Reinforcement Learning for Charging Optimization of Inhomogeneous Dicke Quantum Batteries](https://arxiv.org/abs/2511.12176)
*Xiaobin Song,Siyuan Bai,Da-Wei Wang,Hanxiao Tao,Xizhe Wang,Rebing Wu,Benben Jiang*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Charging optimization is a key challenge to the implementation of quantum batteries, particularly under inhomogeneity and partial observability. This paper employs reinforcement learning to optimize piecewise-constant charging policies for an inhomogeneous Dicke battery. We systematically compare policies across four observability regimes, from full-state access to experimentally accessible observables (energies of individual two-level systems (TLSs), first-order averages, and second-order correlations). Simulation results demonstrate that full observability yields near-optimal ergotropy with low variability, while under partial observability, access to only single-TLS energies or energies plus first-order averages lags behind the fully observed baseline. However, augmenting partial observations with second-order correlations recovers most of the gap, reaching 94%-98% of the full-state baseline. The learned schedules are nonmyopic, trading temporary plateaus or declines for superior terminal outcomes. These findings highlight a practical route to effective fast-charging protocols under realistic information constraints.

</details>


### [617] [Approximate Message Passing for Quantum State Tomography](https://arxiv.org/abs/2511.12857)
*Noah Siekierski,Kausthubh Chandramouli,Christian Kümmerle,Bojko N. Bakalov,Dror Baron*

Main category: quant-ph

TL;DR: AMP可用于低秩量子态层析成像，可显著提高重构精度并考虑噪声影响。


<details>
  <summary>Details</summary>
Motivation: 由于量子态层析成像（QST）的成本随系统规模呈指数增长，因此需要针对具有特定结构（如低秩态）的量子态开发专门的方法。

Method: 本文提出使用压缩感知技术中的近似消息传递（AMP）算法来进行低秩量子态层析成像。

Result: 通过精心设计的AMP算法，与现有的低秩QST方法相比，重构保真度降低了一个数量级以上。实验证明了该方法在IBM Kingston上的有效性，并考虑了器件噪声对状态制备保真度预测可靠性的影响。

Conclusion: AMP为低秩QST提供了一种强大的工具，具有渐近最优的性能保证，并且可以减少重构失真，有望应用于其他量子层析成像协议。

Abstract: Quantum state tomography (QST) is an indispensable tool for characterizing many-body quantum systems. However, due to the exponential scaling cost of the protocol with system size, many approaches have been developed for quantum states with specific structure, such as low-rank states. In this paper, we show how approximate message passing (AMP), a compressed sensing technique, can be used to perform low-rank QST. AMP provides asymptotically optimal performance guarantees for large systems, which suggests its utility for QST. We discuss the design challenges that come with applying AMP to QST, and show that by properly designing the AMP algorithm, we can reduce the reconstruction infidelity by over an order of magnitude compared to existing approaches to low-rank QST. We also performed tomographic experiments on IBM Kingston and considered the effect of device noise on the reliability of the predicted fidelity of state preparation. Our work advances the state of low-rank QST and may be applicable to other quantum tomography protocols.

</details>


### [618] [Skyrmionic qubits stabilized by Dzyaloshinskii-Moriya interaction as platforms for qubits and quantum gates](https://arxiv.org/abs/2511.12250)
*Doru Sticlet,Romulus Tetean,Coriolan Tiusan*

Main category: quant-ph

TL;DR: 基于DMI的量子天体子模型，在特定条件下可用于量子比特实现，但存在退相干问题。


<details>
  <summary>Details</summary>
Motivation: 探索基于拓扑非平凡磁态（如天体子）的量子比特实现方案，特别是利用DMI相互作用。

Method: 采用精确对角化方法，在周期性（PBC）和开边界条件（OBC）下，对包含交换相互作用、磁各向异性、塞曼耦合和DMI的二维自旋晶格模型进行求解。

Result: PBC条件下出现量子天体子相，OBC条件下则出现拓扑保护的经典类天体子。两种天体子均可实现量子逻辑门操作。能量密度和纠缠熵分析表明，量子天体子易受DMI驱动的退相干影响，保真度较低，而经典类天体子更稳定。量子比特动力学模拟显示可调谐的非谐能量水平和布洛赫球面上的相干操控。

Conclusion: DMI在稳定天体子量子比特的同时，也会在门操作期间引入退相干。经典类天体子比量子天体子更稳定，但两种状态都显示出作为量子比特的潜力，能够实现相干操控。

Abstract: Quantum computation departs from the classical paradigm of deterministic, bit-based processing by exploiting inherently quantum phenomena such as superposition and entanglement. We propose a framework for qubit realization based on skyrmionic states stabilized by the Dzyaloshinskii-Moriya interaction (DMI) in two-dimensional spin lattices. The model incorporates competing exchange interactions, perpendicular magnetic anisotropy, and Zeeman coupling, solved via exact diagonalization under periodic (PBC) and open boundary conditions (OBC). A quantum skyrmionic phase emerges for PBC within a parameter space defined by DMI, exchange, field, and anisotropy, while OBC favor classical-like, topologically protected skyrmions. Quantum logic gates (Pauli X, Y, Z, Hadamard) are implemented on both skyrmion types. Energy density and entanglement entropy analyses reveal that quantum skyrmions suffer from DMI-driven decoherence and reduced gate fidelity, whereas classical-like skyrmions maintain stability. Exact simulations of qubit dynamics, including drive effects and Lindblad decoherence, demonstrate tunable anharmonic energy levels and coherent Bloch-sphere manipulation, making these skyrmionic states promising candidates for qubit implementation. Overall, the Dzyaloshinskii-Moriya interaction plays a dual role-stabilizing skyrmionic qubits while simultaneously inducing decoherence during gate operations.

</details>


### [619] [Channel-Constrained Markovian Quantum Diffusion Model from Open System Perspective](https://arxiv.org/abs/2511.12221)
*Qin-Sheng Zhu,Geng Chen,Lian-Hui Yu,Xiaodong Xing,Xiao-Yu Li*

Main category: quant-ph

TL;DR: 我们提出了一个通道约束的马尔可夫量子扩散（CCMQD）模型，通过将生成过程严格框定在开放量子系统的动力学中来制备量子态。


<details>
  <summary>Details</summary>
Motivation: 该模型将前向扩散过程解释为使用量子主方程的自然退相干，而反向去噪则通过学习反向量子通道来实现。

Method: 核心创新在于一个全面的通道约束框架：将扩散和去噪步骤建模为由Kraus算符定义的量子通道，通过在Stiefel流形上进行优化来确保其物理有效性，并引入定制的训练策略和损失函数，以利用这种约束结构实现高保真度的状态重建。

Result: 在从单量子比特到7量子比特纠缠态的系统上进行的实验验证表明，在高保真度的状态生成方面取得了成功，在随机和退火噪声条件下保真度均超过0.998。

Conclusion: 这项工作证实了量子扩散可以表征为受控的马尔可夫演化，并表明环境相互作用不仅是退相干的来源，还可以用于实现高保真度的量子态合成。

Abstract: We present a channel-constrained Markovian quantum diffusion (CCMQD) model that prepares quantum states by rigorously framing the generative process within the dynamics of open quantum systems. Our model interprets the forward diffusion process as natural decoherence using quantum master equations, whereas the reverse denoising is achieved by learning inverse quantum channels. Our core innovation is a comprehensive channel-constrained framework: we model the diffusion and denoising steps as quantum channels defined by Kraus operators, ensure their physical validity through optimization on the Stiefel manifold, and introduce tailored training strategies and loss functions that leverage this constrained structure for high-fidelity state reconstruction. Experimental validation on systems ranging from single qubits to entangled states $7$ -qubits demonstrates high-fidelity state generation, achieving fidelities exceeding $0.998$ under both random and depolarizing noise conditions. This work confirms that quantum diffusion can be characterized as a controlled Markov evolution, demonstrating that environmental interactions are not limited to being a source of decoherence but can also be utilized to achieve high-fidelity quantum state synthesis.

</details>


### [620] [HPC-Accelerated Simulation and Calibration for Silicon Quantum Dots](https://arxiv.org/abs/2511.13330)
*Dhilan Nag,Suhun Kim,Cole Johnson,Collin Sumrell*

Main category: quant-ph

TL;DR: Qalibrate是一个JAX加速的模拟器，可以为量子比特生成高保真度脉冲，其速度比现有模拟器快34倍。


<details>
  <summary>Details</summary>
Motivation: 设计用于实现量子比特上幺正变换的鲁棒静电脉冲是实现量子计算技术的一个重大挑战。加速这一过程对于实验者至关重要。

Method: 使用JAX实现了一个名为Qalibrate的快速模拟器，并生成了一个模拟三电子自旋量子比特时间演化的传播器。通过使用Magnus展开式来近似时间演化并解决Lindblad主方程，可以并行化模拟过程。

Result: Qalibrate在生成脉冲方面比现有的ODE模拟器快了34倍。

Conclusion: Qalibrate的开发和实现为生成鲁棒的n量子比特系统脉冲方面取得了进展，有望加速量子计算技术的发展。

Abstract: Quantum computers (QCs) have the potential to solve critical problems significantly faster than today's most advanced supercomputers. One major challenge in realizing this technology is designing robust electrostatic pulses to realize unitaries on qubits. Current practice when calibrating unitaries involves recursive experimentation to find the highest-fidelity pulses. To accelerate this process for experimentalists, we implement Qalibrate, a fast, JAX-enabled simulator that generates pulses given target unitaries. Specifically, we generate a propagator that models the time evolution of three-electron spin qubits and integrate our gradient-based optimizer to generate the pulses. The simulation involves solving the Lindblad master equation, which we parallelize by employing an approximation of the time evolution called the Magnus expansion. Qalibrate shows up to a 34x speedup compared to an existing ODE simulator, making progress towards generating robust pulses for n-qubit systems.

</details>


### [621] [Scalable quantum error mitigation with phase-cycled dynamical decoupling](https://arxiv.org/abs/2511.12227)
*Weibin Ni,Zhijie Li,Guanyu Qu,Zhecheng Sun,Jiale Dai,Fazhan Shi,Lei Sun*

Main category: quant-ph

TL;DR: 量子时代，量子比特退相干和控制错误是主要挑战，动力学解耦是常用技术，但易受控制错误影响。本文提出Hadamard相位相差循环作为一种非马尔可夫量子错误缓解方法，用于动力学解耦，能够精确测量退相干时间，并提升量子比特保真度。


<details>
  <summary>Details</summary>
Motivation: 量子比特退相干和控制错误是实现量子技术的根本挑战，现有的动力学解耦技术易受控制错误影响，导致对退相干时间的估计不准确。

Method: 构建Hadamard相位相差循环作为一种非马尔可夫量子错误缓解方法，用于动力学解耦。该方法利用群结构设计等效系综量子电路的相位配置，有效消除由错误动力学产生的电路输出，并与电路深度呈线性扩展。

Result: 将Hadamard相位相差循环应用于固态电子自旋量子比特和金刚石中的氮-空位（NV）色心，实现了退相干时间的精确获取。同时，该方法也有效保持了单阱离子和超导transmon量子比特在动力学解耦过程中的状态保真度。

Conclusion: 可扩展的量子错误缓解和抑制技术的集成将促进具有噪声量子比特和控制硬件的量子技术的发展。

Abstract: The realization of quantum technologies in the Noisy Intermediate-Scale Quantum era is severely constrained by qubit decoherence and control errors, presenting fundamental challenges to achieving quantum advantages. Dynamical decoupling is a widely used, powerful technique for decoherence error suppression. However, it is susceptible to control errors, making non-robust sequences like UDD impractical to implement and robust ones like CPMG to significantly overestimate decoherence times. This overestimation issue remains largely unexplored in the past few decades, leading to many reports of exceptionally long yet plausible decoherence times across various qubit platforms. Here, we construct Hadamard phase cycling as a non-Markovian quantum error mitigation method for dynamical decoupling. This method exploits group structure to design phase configurations of equivalent ensemble quantum circuits, effectively eliminates circuit outputs generated from erroneous dynamics, and scales linearly with circuit depth. Harnessing its error mitigation capability for ensemble solid-state electron spin qubits embedded in paramagnetic molecules and nitrogen-vacancy centers in diamond enables accurate acquisition of decoherence times. Applying Hadamard phase cycling on single trapped ion and superconducting transmon qubits effectively preserves their state fidelity during dynamical decoupling. The integration of scalable quantum error mitigation and suppression would facilitate the development of quantum technologies with noisy qubits and control hardware.

</details>


### [622] [Survival of Hermitian Criticality in the Non-Hermitian Framework](https://arxiv.org/abs/2511.12246)
*Fei Wang,Guoying Liang,Zecheng Zhao,Lin-Yue Luo,Da-Jian Zhang,Bao-Ming Xu*

Main category: quant-ph

TL;DR: 本工作在复值横向场作用下，研究一维各向异性XY模型的多体相变，并表明其相变特征在非厄米体系中得以保留。


<details>
  <summary>Details</summary>
Motivation: 探索在开放量子系统中，通常易受退相干和环境干扰影响的量子相变。

Method: 在双正交框架下，计算基态关联函数和纠缠熵，并通过对称性（Z2和U(1)对称性的保持、出现和破坏）和能谱简并性来表征铁磁相和Luttinger液体相，并利用绕着奇异点（EP）的缠绕数来表征Luttinger液体相的拓扑性质。

Result: 计算结果表明，与厄米XY模型相比，其关联函数和纠缠熵的标度行为保持不变。铁磁相源于Z2对称性的破坏，而Luttinger液体相则源于U(1)对称性的出现和能谱实部的简并。

Conclusion: 非厄米体系中的对称性保护机制使得该模型能够保留厄米体系中的相变特征，为在开放量子系统中研究量子相变提供了新的途径。

Abstract: In this work, we investigate many-body phase transitions in a one-dimensional anisotropic XY model subject to a complex-valued transverse field. Within the biorthogonal framework, we calculate the ground-state correlation functions and entanglement entropy, confirming that their scaling behavior remains identical to that in the Hermitian XY model. The preservation of Hermitian phase transition features in the non-Hermitian setting is rooted in the persistence and emergence of symmetries and their breaking. Specifically, the ferromagnetic (FM) phase arises from the breaking of a $Z_2$ symmetry, while the Luttinger liquid (LL) phase is enabled by the emergence of a $U(1)$ symmetry together with the degeneracy of the real part of the energy spectrum. The nontrivial topology of the LL phase are characterized by the winding number around the exceptional point (EP). Given that non-Hermitian systems are inherently open, this research opens a new avenue for exploring conventional quantum phase transitions that are typically vulnerable to decoherence and environmental disruption in open quantum systems.

</details>


### [623] [Transitional Bell Correlation from Dirac Wavepackets](https://arxiv.org/abs/2511.12258)
*Ju Gao,Fang Shen*

Main category: quant-ph

TL;DR: 贝尔参数随空间重叠度变化，量子增强源于横向重叠。


<details>
  <summary>Details</summary>
Motivation: 探索纠缠粒子在不同空间重叠度下的贝尔-CHSH关联，并与传统独立于距离的结果进行对比。

Method: 使用真实的狄拉克波包和局部探测，推导出纠缠的、反向传播的电子的贝尔-CHSH关联的闭式表达式。

Result: 与传统结果不同，贝尔参数从量子边界 $2
varchar{2}$ 连续演变为经典极限 $2$，具体取决于两个波的重叠程度。量子增强完全来自横向重叠。

Conclusion: 贝尔违背反映了传播的狄拉克波的局部重叠，而不是任何超距作用。

Abstract: We derive a closed-form expression for the Bell--CHSH correlation of entangled, counter-propagating electrons using realistic Dirac wavepackets and localized detection. In contrast to the conventional distance-independent result, the Bell parameter evolves continuously from the quantum bound $2\sqrt{2}$ to the classical limit $2$ as the spatial overlap of the two waves decreases. The quantum enhancement arises entirely from transverse overlap, showing that the Bell violation reflects the local overlap of propagating Dirac waves rather than any action at a distance.

</details>


### [624] [An Improved Quantum Anonymous Notification Protocol for Quantum-Augmented Networks](https://arxiv.org/abs/2511.12313)
*Nitin Jha,Abhishek Parakh,Mahadevan Subramaniam*

Main category: quant-ph

TL;DR: 当前量子网络的扩展性受限于有噪声的量子组件和高昂的实施成本。量子增强网络（QuANets）通过将量子组件集成到经典网络基础设施中来提高鲁棒性和端到端安全性。量子匿名通知（QAN）是一种匿名通知接收者有关传入量子通信的方法。本文提出了一种改进的QAN协议，利用共享GHZ状态上的旋转操作在n用户量子增强网络中产生匿名通知，并观察到其在退相干噪声模型下比早期QAN方法具有更强的抗虚假通知能力。最后，将QAN框架与机器学习分类器集成，并讨论了该通知层如何与QuANets集成以实现更安全的量子通信。


<details>
  <summary>Details</summary>
Motivation: 当前量子网络的扩展性受噪声和高成本的限制，这限制了其安全优势。现有的量子匿名通知（QAN）协议在常见的信道噪声下容易受到攻击。

Method: 提出了一种改进的QAN协议，利用共享GHZ状态上的旋转操作在n用户量子增强网络中产生匿名通知，并研究了该协议在退相干噪声模型下的行为。

Result: 改进的QAN协议在退相干噪声模型下表现出比早期QAN方法更强的抗虚假通知能力。将QAN框架与机器学习分类器集成，形成增强的量子增强网络。

Conclusion: 所提出的改进QAN协议能够更有效地处理量子噪声，并且通过与机器学习的结合，可以进一步增强量子增强网络（QuANets）的鲁棒性和安全性。这种通知层的集成可以减少信息泄露和对交换机的针对性干扰。

Abstract: The scalability of current quantum networks is limited due to noisy quantum components and high implementation costs, thereby limiting the security advantages that quantum networks provide over their classical counterparts. Quantum Augmented Networks (QuANets) address this by integrating quantum components in classical network infrastructure to improve robustness and end-to-end security. To enable such integration, Quantum Anonymous Notification (QAN) is a method to anonymously inform a receiver of an incoming quantum communication. Therefore, several quantum primitives will serve as core tools, namely, quantum voting, quantum anonymous protocols, quantum secret sharing, etc. However, all current quantum protocols can be compromised in the presence of several common channel noises. In this work, we propose an improved quantum anonymous notification (QAN) protocol that utilizes rotation operations on shared GHZ states to produce an anonymous notification in an n-user quantum-augmented network. We study the behavior of this modified QAN protocol under the dephasing noise model and observe stronger resilience to false notifications than earlier QAN approaches. The QAN framework is also proposed to be integrated with a machine-learning classifier, enhanced quantum-augmented network. Finally, we discuss how this notification layer integrates with QuANets so that receivers can allow switch-bypass handling of quantum payloads, reducing header-based information leakage and vulnerability to targeted interference at compromised switches.

</details>


### [625] [QMA Complete Quantum-Enhanced Kyber: Provable Security Through CHSH Nonlocality](https://arxiv.org/abs/2511.12318)
*Ilias Cherkaoui,Indrakshi Dey*

Main category: quant-ph

TL;DR: To address the limitations of purely computational post-quantum cryptography, this paper introduces a hybrid scheme that combines lattice-based cryptography with quantum non-locality verification, offering enhanced security.


<details>
  <summary>Details</summary>
Motivation: Current post-quantum cryptography (PQC) schemes like CRYSTALS-Kyber, while efficient, rely on computational hardness assumptions vulnerable to hybrid classical-quantum attacks. There is a need for PQC that incorporates information-theoretic security guarantees.

Method: The paper proposes the first Clauser-Horne-Shimony-Holt (CHSH)-certified Kyber protocol. This scheme embeds quantum non-locality verification using Einstein-Podolsky-Rosen (EPR) pairs directly into the key exchange phase. It integrates CHSH entanglement tests to achieve quantum advantage values exceeding classical correlation limits, thus combining information-theoretic quantum guarantees with lattice-based computational security. The construction is compatible with the Fujisaki-Okamoto (FO) transform for chosen-ciphertext attack (CCA) security.

Result: The proposed CHSH-augmented Kyber scheme provides a hybrid post-quantum framework. Formal reductions show that breaking this KEM requires solving either the Module Learning With Errors (Module-LWE) problem or a Quantum Merlin-Arthur (QMA)-complete instance of the 2-local Hamiltonian problem, assuming QMA $\subset$ NP. The scheme maintains Kyber's efficiency and CCA security.

Conclusion: The CHSH-augmented Kyber protocol establishes a mathematically rigorous, hybrid post-quantum security framework by unifying lattice cryptography and quantum non-locality. This achieves verifiable, composable, and forward-secure key agreement, offering a more robust security solution against quantum adversaries.

Abstract: Post-quantum cryptography (PQC) must secure large-scale communication systems against quantum adversaries where classical hardness alone is insufficient and purely quantum schemes remain impractical. Lattice-based key encapsulation mechanisms (KEMs) such as CRYSTALS-Kyber provide efficient quantum-resistant primitives but rely solely on computational hardness assumptions that are susceptible to hybrid classical-quantum attacks. To overcome this limitation, we introduce the first Clauser-Horne-Shimony-Holt (CHSH)-certified Kyber protocol, which embeds quantum non-locality verification directly within the key exchange phase. The proposed design integrates CHSH entanglement tests using Einstein-Podolsky-Rosen (EPR) pairs to yield measurable quantum advantage values exceeding classical correlation limits, thereby coupling information--theoretic quantum guarantees with lattice-based computational security. Formal reductions demonstrate that any polynomial-time adversary breaking the proposed KEM must either solve the Module Learning With Errors (Module-LWE) problem or a Quantum Merlin-Arthur (QMA)-complete instance of the 2-local Hamiltonian problem, under the standard complexity assumption QMA $\subset$ NP. The construction remains fully compatible with the Fujisaki-Okamoto (FO) transform, preserving chosen-ciphertext attack (CCA) security and Kyber's efficiency profile. The resulting CHSH-augmented Kyber scheme therefore establishes a mathematically rigorous, hybrid post-quantum framework that unifies lattice cryptography and quantum non-locality to achieve verifiable, composable, and forward-secure key agreement.

</details>


### [626] [Stimulated Hawking effect and quasinormal mode resonance in a polariton simulator of field theory on curved spacetime](https://arxiv.org/abs/2511.12339)
*Mattheus Burkhard,Malte Kroj,Kévin Falque,Alberto Bramati,Iacopo Carusotto,Maxime J Jacquet*

Main category: quant-ph

TL;DR: 该论文研究了在极化子模拟器中，通过相干探测器诱导的霍金效应，并发现其表现为负能量的有效传播，且传播峰值出现在视界附近的准正规模式频率。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是研究霍金效应（在黑洞和模拟平台中都存在）如何被诱导，并利用极化子模拟器进行数值检验。

Method: 采用实验上可行的有效时空模型，并利用相干探测器从外部入射到视界。

Result: 研究发现，诱导霍金效应表现为进入视界内部的负能量的有效传播，这与伪幺正的有效散射一致。此外，跨越视界的传播峰值出现在准正规模式频率。

Conclusion: 计算出的光谱特征为未来实验研究霍金效应及其与准正规模式的相互作用提供了实践指导，这是一个在弯曲时空中量子场论领域悬而未决的问题。

Abstract: The Hawking effect amplifies fluctuations in the vicinity of horizons, both in black holes and in analogue platforms.
  Here, we consider a polariton simulator and numerically examine the \emph{stimulated} Hawking effect using a coherent probe incident on the horizon from the exterior.
  We implement an experimentally realistic effective spacetime that supports a quasinormal mode (QNM) in the vicinity of the horizon.
  We find that the stimulated Hawking effect manifests as transmission into a negative-energy Bogoliubov channel inside the horizon, consistent with pseudo-unitary Bogoliubov scattering.
  Moreover, transmission across the horizon peaks at the QNM frequency.
  The computed spectral signatures provide a practical guide for future experimental investigations of the Hawking effect and its interplay with QNMs, an open question in quantum field theory in curved spacetime.

</details>


### [627] [Optimal Multiparameter Quantum Estimation of Magnonic Couplings in a Magnomechanical Cavity](https://arxiv.org/abs/2511.12352)
*Adnan Naimy,Abdallah Slaoui,Abderrahim Lakhfif,Rachid Ahl Laamara*

Main category: quant-ph

TL;DR: 本研究提出了一种实验上可行的方案，利用外差探测来提高 $G_{mc}$ 和 $G_{mb}$ 耦合参数的同步估计精度，并与单独估计进行了比较。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于提高量子系统中耦合参数 $G_{mc}$ 和 $G_{mb}$ 的同步估计精度，并探索外差探测在该过程中的性能。

Method: 本研究通过计算对称对数导数（SLD）和右对数导数（RLD）的量子费雪信息矩阵（QFIM），比较了同步估计和单独估计策略的性能，并分析了拉比频率、腔损耗率、光子和声子数量、机械阻尼和温度等参数对估计精度的影响。

Result: 结果显示，同步估计策略相比单独估计具有明显优势。RLD 对应的量子克拉美-罗界（QCRB）始终低于 SLD 对应的 QCRB，表明估计精度更高。增加拉比频率、腔损耗率、光子和声子数量，同时减少机械阻尼和温度，可以提高系统对耦合参数的灵敏度。外差探测在特定条件下可以接近 QFIM 设定的极限精度。

Conclusion: 本研究提出了一种有效的提高耦合参数估计精度的方案，并表明外差探测是一种实用且高效的测量策略，有望用于高精度混合量子传感器的开发。

Abstract: In this work, we introduce an experimentally viable scheme to enhance the simultaneous estimation precision of the couplings $G_{mc}$ and $G_{mb}$, with a particular focus on the performance of heterodyne detection. By comparing simultaneous and individual estimation strategies, we demonstrate that the simultaneous approach offers a notable advantage in our system. To support this, we compute the quantum Fisher information matrices (QFIMs) based on the symmetric logarithmic derivative (SLD) and the right logarithmic derivative (RLD). Our results show that the quantum Cramér Rao bound (QCRB) associated with the RLD is consistently lower than that of the SLD, indicating superior estimation precision. From a physical standpoint, this improvement reflects the system's enhanced capacity to encode, transfer, and extract quantum information while allowing optimal control of fundamental interactions. We show that increasing the Rabi frequency, cavity loss rate, and the average number of photons and phonons, combined with reduced mechanical damping and temperature, enhances the system's sensitivity to the coupling parameters. These mechanisms act on the available quantum resources, such as entanglement, squeezing, and state purity, leading to more precise estimations. Furthermore, our analysis reveals that under certain conditions, heterodyne detection can closely approach the ultimate precision set by the QFIM. This suggests that a measurement strategy based on heterodyne detection can offer an efficient and practical route for estimating the couplings $G_{mc}$ and $G_{mb}$, paving the way for high precision hybrid quantum sensors.

</details>


### [628] [Quantum Optimization Algorithms](https://arxiv.org/abs/2511.12379)
*Jonas Stein,Maximilian Zorn,Leo Sünkel,Thomas Gabor*

Main category: quant-ph

TL;DR: QAOA是一种量子优化算法，适用于门控量子计算机，可解决工业界问题。本文讨论了QAOA的实现、参数训练和约束处理，并概述了VQE作为其推广。


<details>
  <summary>Details</summary>
Motivation: 量子优化在解决某些工业问题上能提供指数级的量子加速，QAOA是其中的关键算法。

Method: 本文详细介绍了QAOA的量子电路实现，包括高阶伊辛模型的哈密顿模拟和参数迁移规则，并通过Pennylane的源代码实现了一个最大割问题的示例。

Result: 通过Pennylane实现最大割问题，并展示了如何使用Grover混合器将约束条件纳入QAOA，以限制搜索空间。

Conclusion: QAOA是一种有前景的量子优化算法，VQE是其推广，两者在NISQ时代都有巨大潜力，但仍需解决训练和线路设计等挑战。

Abstract: Quantum optimization allows for up to exponential quantum speedups for specific, possibly industrially relevant problems. As the key algorithm in this field, we motivate and discuss the Quantum Approximate Optimization Algorithm (QAOA), which can be understood as a slightly generalized version of Quantum Annealing for gate-based quantum computers. We delve into the quantum circuit implementation of the QAOA, including Hamiltonian simulation techniques for higher-order Ising models, and discuss parameter training using the parameter shift rule. An example implementation with Pennylane source code demonstrates practical application for the Maximum Cut problem. Further, we show how constraints can be incorporated into the QAOA using Grover mixers, allowing to restrict the search space to strictly valid solutions for specific problems. Finally, we outline the Variational Quantum Eigensolver (VQE) as a generalization of the QAOA, highlighting its potential in the NISQ era and addressing challenges such as barren plateaus and ansatz design.

</details>


### [629] [Nonlocal action in Everettian Quantum Mechanics](https://arxiv.org/abs/2511.12403)
*Mordecai Waegell,Kelvin J. McQueen*

Main category: quant-ph

TL;DR: Everettian quantum mechanics (EQM) is often considered local because it doesn't involve nonlocal action at a distance like collapse theories. However, this paper argues that EQM *is* nonlocal because actions on one system can change the global state of entangled systems, which should count as a nonlocal action. The paper refutes the counterargument that such changes are merely extrinsic, arguing that the intrinsic-extrinsic distinction is flawed and that global states, when essential for explanations, signify nonlocal actions. In EQM, the global state is crucial for explaining how Alice's measurement outcome influences Bob's, demonstrating nonlocality.


<details>
  <summary>Details</summary>
Motivation: The common view holds that Everettian quantum mechanics (EQM) is local, which is seen as an advantage. This paper challenges this view by arguing that EQM is, in fact, nonlocal.

Method: The paper analyzes the concept of nonlocal action in EQM by examining how actions on one system can affect the global state of entangled systems. It refutes the intrinsic-extrinsic distinction as a means to deny nonlocality in EQM and proposes that global state changes constitute nonlocal actions when these states are essential explanatory mechanisms within the theory.

Result: The paper argues that EQM is not local. It demonstrates that actions on one part of an entangled system can change the global state, which should be considered a nonlocal action. This is exemplified by how the global state in EQM explains the correlation between Alice's and Bob's measurement outcomes in an anti-correlated Bell state.

Conclusion: Everettian quantum mechanics (EQM) should be considered a nonlocal theory because changes to the global state of entangled systems, even if not affecting individual remote systems intrinsically, constitute nonlocal actions when these global states are essential for the theory's explanations. The distinction between intrinsic and extrinsic changes is problematic and cannot be used to preserve the locality of EQM.

Abstract: According to a common view, Everettian quantum mechanics (EQM) is a local theory because it avoids nonlocal action at a distance, and this is an important point in EQM's favor. Unlike collapse theories, EQM does not allow an action on one system to change the reduced density matrix (RDM) of a remote entangled system - a clear case of nonlocal action. However, EQM does allow an action on one system to change the global state of the system and its remote entangled partners. We argue that such changes should also count as nonlocal actions, meaning EQM is not local after all. First, we consider an argument to the contrary, which deems such global changes to be mere extrinsic changes, whereas nonlocal action requires intrinsic changes to the remote system. We respond that the intrinsic-extrinsic distinction is problematic and cannot hold the weight of this argument. We then try to clarify when actions that change global states count as nonlocal actions. We argue that it is when the global states are essential explanatory mechanisms of the theory. In EQM, the global state is needed to explain why, in an anti-correlated Bell state, Alice's measuring spin-up ensures that she encounters only the branch where Bob measures spin-down.

</details>


### [630] [Enhancing Chemistry on Quantum Computers with Fermionic Linear Optical Simulation](https://arxiv.org/abs/2511.12416)
*Zack Hassman,Oliver Reardon-Smith,Gokul Subramanian Ravi,Frederic T. Chong,Kevin J. Sung*

Main category: quant-ph

TL;DR: 提供一个用于模拟包含无源费米子线性光学元件和受控-相移门电路的开源模拟器，支持精确和近似计算，后者在特定条件下比传统方法更有效，并已成功应用于分子基态能量估计。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够模拟特定费米子线性光学电路的模拟器，特别是那些传统状态向量方法难以处理的系统，并将其应用于提高量子化学计算的准确性。

Method: 提出并开源一个模拟器，该模拟器可以计算给定电路的玻色规则概率。它支持精确和近似计算，其中近似计算的运行时复杂度仅取决于受控-相移门的角度幅度，而不是量子比特数量。通过将此模拟器与本地酉簇Jastrow (LUCJ)波函数和样本为基础的量子对角化 (SQD) 方法相结合，以提高分子基态能量估计的精度。

Result: 该模拟器在模拟LUCJ波函数和SQD结合方面显示出实用性。在应用于52量子比特的N2分子系统时，与基线SQD方法相比，精度提高了46%，而计算开销可忽略不计。

Conclusion: 该模拟器是一个高效且灵活的费米子电路模拟工具，为在化学和相关领域中改进近期量子算法提供了新的机会。

Abstract: We present and open source a simulator for circuits composed of passive fermionic linear optical elements and controlled-phase gates. Given such a circuit, our simulator can compute Born-rule probabilities for samples drawn from it. Our simulator supports both exact and approximate probability calculation, allowing users to trade accuracy for efficiency as needed. For approximate Born-rule probability calculation, our simulator's runtime is exponential only in the magnitudes of the angles of the circuit's controlled-phase gates. This makes our simulator useful for simulating certain systems that are beyond the reach of conventional state vector methods. We demonstrate our simulator's utility by simulating the local unitary cluster Jastrow (LUCJ) ansatz and integrating it with sample-based quantum diagonalization (SQD) to improve the accuracy of molecular ground-state energy estimates. Applied to a 52-qubit $N_2$ system, we observe accuracy improvements of up to $46\%$ over the baseline SQD implementation with negligible computational overhead. As an efficient and flexible tool for simulating fermionic circuits, our simulator enables new opportunities for enhancing near-term quantum algorithms in chemistry and related domains.

</details>


### [631] [Machine Learning Framework for Efficient Prediction of Quantum Wasserstein Distance](https://arxiv.org/abs/2511.12443)
*Changchun Feng,Xinyu Qiu,Laifa Tao,Lin Chen*

Main category: quant-ph

TL;DR: 机器学习可有效预测量子 Wasserstein 距离，为量子纠错提供新途径。


<details>
  <summary>Details</summary>
Motivation: 计算多量子比特系统的量子 Wasserstein 距离在量子纠错中至关重要，但现有方法面临计算挑战。

Method: 提出一种机器学习框架，通过提取 Pauli 测量、统计矩、量子保真度和纠缠度等物理特征来预测量子 W-距离，并采用经典神经网络和传统机器学习模型。

Result: 所提出的随机森林模型在三量子比特系统上实现了近乎完美的准确率（R^2 = 0.9999），平均绝对误差数量级为 10^-5，并成功验证了两个量子信息理论命题。

Conclusion: 机器学习为量子 W-距离的计算提供了一种可行的、可扩展的替代方案，有望用于 NISQ 设备中的实时量子电路评估和纠错协议设计。

Abstract: The quantum Wasserstein distance (W-distance) is a fundamental metric for quantifying the distinguishability of quantum operations, with critical applications in quantum error correction. However, computing the W-distance remains computationally challenging for multiqubit systems due to exponential scaling. We present a machine learning framework that efficiently predicts the quantum W-distance by extracting physically meaningful features from quantum state pairs, including Pauli measurements, statistical moments, quantum fidelity, and entanglement measures. Our approach employs both classical neural networks and traditional machine learning models. On three-qubit systems, the best-performing Random Forest model achieves near-perfect accuracy ($R^2 = 0.9999$) with mean absolute errors on the order of $10^{-5}$. We further validate the framework's practical utility by successfully verifying two fundamental theoretical propositions in quantum information theory: the bound on measurement probability differences between unitary operations and the $W_1$ gate error rate bound. The results establish machine learning as a viable and scalable alternative to traditional numerical methods for W-distance computation, with particular promise for real-time quantum circuit assessment and error correction protocol design in NISQ devices.

</details>


### [632] [Discovering autonomous quantum error correction via deep reinforcement learning](https://arxiv.org/abs/2511.12482)
*Yue Yin,Tailong Xiao,Xiaoyang Deng,Ming He,Jianping Fan,Guihua Zeng*

Main category: quant-ph

TL;DR: 利用课程学习和深度强化学习发现新的量子纠错码，以抵抗单光子和双光子损耗。


<details>
  <summary>Details</summary>
Motivation: 标准的量子纠错方法可能引入额外错误，而自主量子纠错（AQEC）虽然能避免，但寻找实际编码具有挑战性。本研究旨在利用先进的机器学习技术发现新的AQEC编码。

Method: 采用课程学习和深度强化学习来发现满足近似AQEC框架的量子码，以抵抗单光子和双光子损耗。首先分析了主方程在近似条件下的解析解以加速训练，然后使用两阶段训练策略：第一阶段快速探索以识别突破盈亏平衡点的编码子空间，第二阶段精细调整策略以维持性能。

Result: 通过深度强化学习，发现了基于 Fock 态 $\ket{4}$ 和 $\ket{7}$ 的最优编码，能够抵抗单光子和双光子损耗。该编码在更长的演化时间内超越了盈亏平衡阈值，并达到了最先进的性能。此外，还分析了该编码对相位阻尼和幅度阻尼噪声的鲁棒性。

Conclusion: 课程学习驱动的深度强化学习在发现最优量子纠错码方面具有巨大潜力，特别是在早期容错量子系统中。

Abstract: Quantum error correction is essential for fault-tolerant quantum computing. However, standard methods relying on active measurements may introduce additional errors. Autonomous quantum error correction (AQEC) circumvents this by utilizing engineered dissipation and drives in bosonic systems, but identifying practical encoding remains challenging due to stringent Knill-Laflamme conditions. In this work, we utilize curriculum learning enabled deep reinforcement learning to discover Bosonic codes under approximate AQEC framework to resist both single-photon and double-photon losses. We present an analytical solution of solving the master equation under approximation conditions, which can significantly accelerate the training process of reinforcement learning. The agent first identifies an encoded subspace surpassing the breakeven point through rapid exploration within a constrained evolutionary time-frame, then strategically fine-tunes its policy to sustain this performance advantage over extended temporal horizons. We find that the two-phase trained agent can discover the optimal set of codewords, i.e., the Fock states $\ket{4}$ and $\ket{7}$ considering the effect of both single-photon and double-photon loss. We identify that the discovered code surpasses the breakeven threshold over a longer evolution time and achieve the state-of-art performance. We also analyze the robustness of the code against the phase damping and amplitude damping noise. Our work highlights the potential of curriculum learning enabled deep reinforcement learning in discovering the optimal quantum error correct code especially in early fault-tolerant quantum systems.

</details>


### [633] [Autonomously Designed Pulses for Precise, Site-Selective Control of Atomic Qubits](https://arxiv.org/abs/2511.12524)
*Sanghyo Park,Seuk Lee,Keunyoung Lee,Minhyeok Kim,Donggyu Kim*

Main category: quant-ph

TL;DR: AI框架通过设计复合脉冲，将冷原子量子计算机的局部控制保真度提高了十倍，克服了现有硬件的限制，并提高了对光学像差和光束未对准的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 冷原子量子计算机的保真度受限于低保真度的位点选择性局域控制，而长期发展的容错操作受到此瓶颈的制约。

Method: 利用深度神经网络，以原子-激光动力学为训练数据，自主设计复合脉冲，以提高局域控制保真度。

Result: 所提出的AI框架将局部控制保真度提高了十倍，并展示了脉冲对光学像差和光束未对准的鲁棒性。

Conclusion: AI训练的脉冲编译是实现高保真度量子比特控制的一种可行方法，并且可以应用于其他类原子量子平台。

Abstract: Quantum computers based on cold-atom arrays offer long-lived qubits with programmable connectivity, yet their progress toward fault-tolerant operation is limited by the relatively low fidelity of site-selective local control. We introduce an artificial-intelligence (AI) framework that overcomes this limitation. Trained on atom-laser dynamics, a deep neural network autonomously designs composite pulses that improve local control fidelities tenfold while remaining compatible with existing control hardware. We further demonstrate the robustness of these pulses against optical aberrations and beam misalignment. This approach establishes AI-trained pulse compilation for high-fidelity qubit control and can be readily extended to other atom-like platforms, such as trapped ions and solid-state color centers.

</details>


### [634] [Minute-Scale Photonic Quantum Memory](https://arxiv.org/abs/2511.12537)
*You-Cai Lv,Yu-Jia Zhu,Zong-Quan Zhou,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 在151Eu3+:Y2SiO5晶体中，通过结合光子回声协议和绝热脉冲动力学解耦序列，实现了分钟级长寿命单光子存储，保真度达到88.0±2.1%，存储寿命达到27.6±0.6秒，为构建全球量子网络和深空量子实验奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 实现长距离量子通信和量子物理基础检验，需要秒至分钟级的量子存储，但现有光子量子存储寿命不足。

Method: 在‘魔幻’磁场下，利用151Eu3+:Y2SiO5晶体，结合利用晶体自然吸收进行光子存储的光子回声协议，以及包含绝热脉冲以保护核自旋相干性的动力学解耦序列。

Result: 在5.6秒的存储时间下，实现了88.0±2.1%的时间-二能级量子比特存储保真度，超越了经典策略的最大保真度。存储寿命的1/e衰减时间为27.6±0.6秒，实现了大于1的信噪比下长达42秒的单光子存储。

Conclusion: 该研究在分钟尺度上实现了光子量子存储，为全球量子网络和深空量子实验提供了坚实基础。

Abstract: Long-lived storage of single photons is a fundamental requirement for enabling quantum communication and foundational tests of quantum physics over extended distances. While the implementation of a global-scale quantum network requires quantum storage times on the order of seconds to minutes, existing photonic quantum memories have so far been limited to subsecond lifetimes. Although $^{151}$Eu$^{3+}$:Y$_2$SiO$_5$ crystals exhibit substantially extended spin coherence times at the `magic' magnetic field, the concomitant weak optical absorption has until now prevented single-photon storage. Here, we overcome this challenge by integrating a noiseless photon echo protocol -- which makes full use of the crystal's natural absorption for photonic storage -- with a universally robust dynamical decoupling sequence incorporating adiabatic pulses to protect nuclear spin coherence, enabling long-lived quantum storage at the `magic' magnetic field. At a storage time of 5.6 s, we achieve a time-bin qubit storage fidelity of 88.0 $\pm$ 2.1%, surpassing the maximum fidelity attainable via classical strategies. Our device reaches a $1/e$ storage lifetime of 27.6 $\pm$ 0.6 s, enabling single-photon-level storage for 42 s with a signal-to-noise ratio greater than unity. This work establishes photonic quantum memory in the minute-scale regime, laying a solid foundation for global-scale quantum network and deep-space quantum experiments.

</details>


### [635] [Sparsity-Driven Entanglement Detection in High-Dimensional Quantum States](https://arxiv.org/abs/2511.12546)
*Stav Lotan,Hugo Defienne,Ronen Talmon,Guy Bartal*

Main category: quant-ph

TL;DR: 本文提出一种基于稀疏性的新框架，用于增强高维量子纠缠的检测和认证，尤其适用于空间纠缠光子对。该方法通过对样本协方差矩阵进行$\|1$-正则化重建，能在抑制噪声的同时提升相关性信号的可见度，并成功通过EPR纠缠判据认证了更高的纠缠维度，且该方法具有良好的可扩展性、易用性，并兼容现有量子光学平台。


<details>
  <summary>Details</summary>
Motivation: 高维量子纠缠的表征对于高级量子计算和量子信息算法至关重要，但传统方法受限于数据采集和实验噪声。

Method: 利用$\|1$-正则化重建对自发参量下转换（SPDC）测量得到的样本协方差矩阵进行处理，并通过位置-动量EPR纠缠判据进行验证。

Result: 该稀疏性框架能够提升相关性信号的可见度并抑制噪声，成功认证了在无正则化情况下无法达到的纠缠维度。

Conclusion: 该方法具有可扩展、易用且兼容现有平台，为高效、实时的-高维量子态分析开辟了道路。

Abstract: The characterization of high-dimensional quantum entanglement is crucial for advanced quantum computing and quantum information algorithms. Traditional methods require extensive data acquisition and suffer from limited visibility due to experimental noise. Here, we introduce a sparsity-driven framework to enhance the detection and certification of high-dimensional entanglement in spatially entangled photon pairs. By applying $\ell_1$-regularized reconstruction to sample covariance matrices obtained from measurements on photons produced via spontaneous parametric down-conversion (SPDC) measurements, we enhance the visibility of the correlation signal while suppressing noise. We demonstrate, using a position-momentum Einstein-Podolsky-Rosen (EPR) entanglement criterion, that this approach enables certification of an entanglement dimensionality that cannot be achieved without regularization. Our method is scalable, simple to use and compatible with existing quantum-optics platforms, thus paves the way for efficient, real-time analysis of high-dimensional quantum states.

</details>


### [636] [Charge-state stability of single NV centers in HPHT-type IIa diamond](https://arxiv.org/abs/2511.12591)
*Darya Meniailava,Michael Petrov,Josef Soucek,Milos Nesladek*

Main category: quant-ph

TL;DR: 本研究在弱掺杂的HPHT IIa型金刚石中，使用Ti/Al共面电极和氧终止表面，研究了外加电场和光学激发如何共同控制氮-空位(NV)中心的电荷转换，并揭示了电场可以提高NV-的比例并增强自旋读数，同时发现了电荷转换的动力学行为，并证明了残余硼受主在决定电荷态稳定性中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 研究弱掺杂金刚石中NV中心的电荷态稳定性，以及电场和光学激发对其电荷转换的影响。

Method: 结合了电压依赖光致发光、实时电荷态监测、激光功率饱和与光谱分解以及时间分辨测量，并使用了Ti/Al共面电极。

Result: 外加电场可以显著提高NV-比例并增强自旋读数；在低激发功率下，NV-比例的演化遵循压缩指数动力学，与慢速空间电荷重排一致；在脉冲激发下，观察到由空穴捕获驱动的数百纳秒的NV-/NV0转换，并被偏压强烈抑制。

Conclusion: 残余硼受主在决定电荷态稳定性中起关键作用，并且电场可以可靠地稳定弱掺杂块状金刚石中的NV-。

Abstract: This is a preliminary version. Improvements and additional analysis will be included in a revised manuscript. We investigate the charge-state stability of individual nitrogen-vacancy (NV) centers in weakly doped HPHT IIa diamond containing sub-ppm concentrations of boron and nitrogen. Using Ti/Al coplanar electrodes on an oxygen-terminated surface, we study how applied electric fields and optical excitation jointly govern NV charge conversion. By combining voltage-dependent photoluminescence, real-time charge-state monitoring, laser-power saturation with spectral decomposition, and time-resolved measurements, we reveal that electric fields several micrometers from the contacts significantly increase the NV- population and enhance spin readout. At low excitation powers, the NV- population evolves on minute timescales following compressed-exponential kinetics, consistent with slow space-charge rearrangement in ultra-insulating diamond. Under pulsed excitation, we observe hundreds-of-nanoseconds NV-/NV0 conversion driven by hole capture, which is strongly suppressed by applied bias. Our results demonstrate that residual boron acceptors play a key role in determining charge-state stability and show how electrical bias can reliably stabilize NV- in weakly doped bulk diamond.

</details>


### [637] [Quantum Orthogonal Separable Physics-Informed Neural Networks](https://arxiv.org/abs/2511.12613)
*Pietro Zanotta,Ljubomir Budinski,Caglar Aytekin,Valtteri Lahtinen*

Main category: quant-ph

TL;DR: 这是一个关于量子正交可分物理信息神经网络（QO-SPINNs）的摘要，该网络利用量子计算加速偏微分方程（PDE）的求解和不确定性量化（UQ）。


<details>
  <summary>Details</summary>
Motivation: 当前求解偏微分方程的经典方法存在计算瓶颈，需要更高效的解决方案。

Method: 提出了一种名为QO-SPINNs的新型神经网络架构，通过在量子层面加速矩阵乘法（复杂度为 O(d log d/ε^2)）来解决计算瓶颈。该方法使用保持汉明重量的量子电路和一元基进行数据编码。此外，利用量子电路的固有正交性（保证谱范数为1），提出了一种新的不确定性量化方法，该方法改编自SPINNs的谱归一化高斯过程，无需进行计算成本高昂的谱归一化步骤。

Result: 通过在经典模拟器上运行量子电路，对QO-SPINNs求解正向和逆向PDE问题以及进行不确定性量化的能力进行了数值验证。结果表明，与经典方法相比，该模型在计算效率和不确定性量化方面都有显著优势。

Conclusion: QO-SPINNs提供了一个解决偏微分方程和进行不确定性量化的有效且高效的框架，并且是第一个专门为可分物理信息神经网络设计的不确定性量化方法。

Abstract: This paper introduces Quantum Orthogonal Separable Physics-Informed Neural Networks (QO-SPINNs), a novel architecture for solving Partial Differential Equations, integrating quantum computing principles to address the computational bottlenecks of classical methods. We leverage a quantum algorithm for accelerating matrix multiplication within each layer, achieving a $\mathcal O(d\log d/ε^2)$ complexity, a significant improvement over the classical $\mathcal O(d^2)$ complexity, where $d$ is the dimension of the matrix, $ε$ the accuracy level. This is accomplished by using a Hamming weight-preserving quantum circuit and a unary basis for data encoding, with a comprehensive theoretical analysis of the overall architecture provided. We demonstrate the practical utility of our model by applying it to solve both forward and inverse PDE problems. Furthermore, we exploit the inherent orthogonality of our quantum circuits (which guarantees a spectral norm of 1) to develop a novel uncertainty quantification method. Our approach adapts the Spectral Normalized Gaussian Process for SPINNs, eliminating the need for the computationally expensive spectral normalization step. By using a Quantum Orthogonal SPINN architecture based on stacking, we provide a robust and efficient framework for uncertainty quantification (UQ) which, to our knowledge, is the first UQ method specifically designed for Separable PINNs. Numerical results based on classical simulation of the quantum circuits, are presented to validate the theoretical claims and demonstrate the efficacy of the proposed method.

</details>


### [638] [Stability of intrinsic localized modes on the lattice with competing power nonlinearities](https://arxiv.org/abs/2511.12649)
*Georgy L. Alfimov,Pavel A. Korchagin,Dmitry E. Pelinovsky*

Main category: quant-ph

TL;DR: We analyze the discrete nonlinear Schrodinger equation with competing powers (p,q) where 2 <= p < q. We found that intrinsic localized modes are compact and can be classified by codes. Larger states of the same sign are stable, while smaller states with alternating signs are spectrally stable but have negative Krein signature. We also numerically identified stable stacked combinations of these states.


<details>
  <summary>Details</summary>
Motivation: The paper studies the discrete nonlinear Schrodinger equation with competing powers (p,q) to understand the behavior of intrinsic localized modes.

Method: The study uses spectral stability analysis to prove stability properties of the localized modes and numerical identification for stable stacked combinations.

Result: We proved that codes for larger states of the same sign are spectrally and nonlinearly stable. Codes for smaller states of alternating signs are spectrally stable but have eigenvalues of negative Krein signature. We numerically identified spectrally stable codes consisting of stacked combinations of larger and smaller states.

Conclusion: The discrete nonlinear Schrodinger equation with competing powers exhibits complex localized modes with different stability properties based on their configuration and signs. Larger states of the same sign are stable, while smaller alternating sign states are spectrally stable but have negative Krein signature. Stable stacked combinations of these states were also identified numerically.

Abstract: We study the discrete nonlinear Schrodinger equation with competing powers (p,q) satisfying 2 <= p < q. The physically relevant cases are given by (p,q) = (2,3), (p,q) = (3,4), and (p,q) = (3,5). In the anticontinuum limit, all intrinsic localized modes are compact and can be classified by their codes, which record one of two nonzero (smaller and larger) states and their sign alternations. By using the spectral stability analysis, we prove that the codes for larger states of the same sign are spectrally and nonlinearly (orbitally) stable, whereas the codes for smaller states of the alternating signs are spectrally stable but have eigenvalues of negative Krein signature. We also identify numerically the spectrally stable codes which consist of stacked combinations of the sign-definite larger states and the sign-alternating smaller states.

</details>


### [639] [Dissipative Dynamics of Charged Graphene Quantum Batteries](https://arxiv.org/abs/2511.12666)
*Disha Verma,Indrajith VS,R. Sankaranarayanan*

Main category: quant-ph

TL;DR: 石墨烯量子电池的耗散动力学：相干性和非马尔可夫性是关键资源。


<details>
  <summary>Details</summary>
Motivation: 研究石墨烯基量子电池在耗散环境下的动力学行为，重点关注相干性和非马尔可夫性对电池性能的影响。

Method: 将石墨烯量子电池建模为四能级自旋谷系统，通过高斯脉冲充电，并在振幅阻尼、退相干以及马尔可夫和非马尔可夫两种类型的耗散环境下进行演化，分析能量损耗和功提取能力。

Result: 振幅阻尼导致能量损失但能稳定非被动稳态并产生有限的有效能；纯退相干抑制相干性并消除功提取；非马尔可夫记忆效应能减缓有效能的损失，并通过信息回流实现部分恢复。

Conclusion: 相干性和耗散环境的非马尔可夫记忆是提高石墨烯量子电池长期性能的关键资源。

Abstract: We investigate dissipative dynamics in a graphene-based quantum battery modeled as a four level spin valley system. The battery is charged via a Gaussian pulse and subsequently evolves under amplitude damping, dephasing, and both Markovian and non Markovian reservoirs. We find that amplitude damping, while inducing energy loss, can stabilize non passive steady states with finite ergotropy, whereas pure dephasing suppresses coherence and eliminates work extraction. On the other hand, non-Markovian memory slows ergotropy loss and enables partial recovery through information backflow. These results identify coherence and reservoir memory as essential resources for enhancing the long-time performance of graphene quantum batteries.

</details>


### [640] [Moments of quantum channel ensembles](https://arxiv.org/abs/2511.12700)
*Matthew Duschenes,Diego García-Martín,Zoë Holmes,M. Cerezo*

Main category: quant-ph

TL;DR: 该论文提出了一个计算量子信道系综矩算子的理论框架，重点关注确定参考系综，并定义了信道t-设计。研究表明，不同类型的噪声会影响矩算子的范数，并推广了噪声诱导的浓度现象。


<details>
  <summary>Details</summary>
Motivation: 量子信道系综的矩算子在量子信息中具有重要作用，但对其性质的研究不如量子位系综充分。

Method: 开发了一个理论框架来计算所有阶数t的量子信道系综的矩算子，并通过不等式推导了系综之间的层级关系，从而定义了信道t-设计。

Result: 研究了不同类型噪声（如退化噪声和幅度衰减噪声）对矩算子范数的影响，并推广了噪声诱导的浓度现象。发现了一个块正交排列基，简化了分析。

Conclusion: 该工作为理解和设计量子信道提供了新的工具和见解，尤其是在处理随机动力学和噪声方面。

Abstract: Moments of ensembles of unitaries play a central role in quantum information theory as they capture the statistical properties of dynamics of systems with some form of randomness. Indeed, concepts such as approximate $t$-designs arise when comparing how close an associated moment operator of a given unitary ensemble is to that of another, reference ensemble. Despite the importance of moment operators, their properties have not been as explored for quantum channels. In this work we develop a theoretical framework to compute moment operators for ensembles of quantum channels, for all moment orders $t$, with a special focus on determining ensembles that can be used as points of reference. By deriving hierarchies between ensembles, via inequalities of their moment operator norms, we give them operational meaning, and define useful concepts such as that of channel $t$-designs. Finally, we perform theoretical and numerical studies which show that different types of noise can decrease the norm of the moment operators (e.g., depolarizing noise), as well as increase it (e.g., amplitude damping), and generalize noise-induced concentration phenomena to channel-design-induced phenomena. Along the way, we find a block-orthogonal basis for permutations, which greatly simplifies our analyses, and may be of independent interest.

</details>


### [641] [The role of averages in CV-QKD over fast fading channels](https://arxiv.org/abs/2511.12721)
*Miguel Castillo-Celeita,Matteo Schiavon*

Main category: quant-ph

TL;DR: 本研究探讨了在自由空间通信链路中常见的快速衰落信道上的连续变量量子密钥分发（CV-QKD）协议。


<details>
  <summary>Details</summary>
Motivation: 评估CV-QKD协议在快速衰落信道下的安全性，并考虑了两种不同的窃听模型：Holevo界平均（HBA）和协方差矩阵平均（CMA）。

Method: 为HBA和CMA两种策略开发了解析表达式，并分析了它们在计算合法方之间互信息方面的差异。

Result: 结果表明，安全密钥率（SKR）在很大程度上受到信道起伏处理方式的影响。

Conclusion: 选择最能描述协议实际实现的模型对于CV-QKD协议的安全性至关重要。

Abstract: This work presents a study of continuous-variable quantum key distribution (CV-QKD) protocols over fast-fading channels, typically found in free-space communication links. Two eavesdropping models are considered to evaluate their security under collective attacks: \textit{Holevo bound average} (HBA) and \textit{covariance matrix average} (CMA). In the HBA approach, the Holevo bound is averaged over the channel transmittance. In contrast, the CMA method calculates the Holevo bound from the average covariance matrix. Analytical expressions are developed for both strategies. The two methods also differ in how they calculate the mutual information between the legitimate parties. The results demonstrate that the SKR is significantly influenced by how you treat channel fluctuations, highlighting the importance of choosing the model that better describes the actual implementation of the protocol.

</details>


### [642] [Sdim: A Qudit Stabilizer Simulator](https://arxiv.org/abs/2511.12777)
*Adeeb Kabir,Steven Nguyen,Sohan Ghosh,Tijil Kiran,Isaac H. Kim,Yipeng Huang*

Main category: quant-ph

TL;DR: 有了一个新的开源模拟器，可以模拟所有维度上的 qudit 量子计算，从而为 qudit 量子纠错的研究铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 鉴于目前缺乏广泛使用的 qudit 稳定器模拟器，而 qudit 对于量子算法和容错量子计算 (FTQC) 具有吸引力。

Method: 介绍并开源了第一个适用于所有维度的 qudit 稳定器模拟器。通过与现有的状态向量模拟器进行正确性验证，并对量子电路进行评估和采样来测试其性能。

Result: 该模拟器已被证明是正确的，并且在性能基准测试中表现良好，为 qudit 量子纠错的研究提供了计算基础。

Conclusion: 该模拟器是探索新颖 qudit 量子纠错的关键计算基础设施，类似于早期稳定器模拟器对量子比特的作用。

Abstract: Quantum computers have steadily improved over the last decade, but developing fault-tolerant quantum computing (FTQC) techniques, required for useful, universal computation remains an ongoing effort. Key elements of FTQC such as error-correcting codes and decoding are supported by a rich bed of stabilizer simulation software such as Stim and CHP, which are essential for numerically characterizing these protocols at realistic scales. Recently, experimental groups have built nascent high-dimensional quantum hardware, known as qudits, which have a myriad of attractive properties for algorithms and FTQC. Despite this, there are no widely available qudit stabilizer simulators. We introduce the first open-source realization of such a simulator for all dimensions. We demonstrate its correctness against existing state vector simulations and benchmark its performance in evaluating and sampling quantum circuits. This simulator is the essential computational infrastructure to explore novel qudit error correction as earlier stabilizer simulators have been for qubits.

</details>


### [643] [Verified Implementation of GRAPE Pulse Optimization for Quantum Gates with Hardware-Representative Noise Models](https://arxiv.org/abs/2511.12799)
*Rylan Malarchick*

Main category: quant-ph

TL;DR: QubitPulseOpt是一个用于量子计算的Python框架，旨在通过硬件代表性最优控制来弥合模拟与现实之间的差距，从而解决NISQ计算机中的门保真度问题。


<details>
  <summary>Details</summary>
Motivation: NISQ计算机中的门保真度是实际量子计算的主要瓶颈，而现有的量子最优控制（QOC）方法通常在理想化的模拟环境中运行，未能解决“模拟到现实”的差距。

Method: 提出一个名为QubitPulseOpt的开源Python框架，该框架通过硬件代表性最优控制来弥合模拟与现实之间的差距。该框架演示了与IQM的Garnet量子处理器的API连接，并通过硬件代表性参数构建高保真度“数字孪生”。

Result: 使用QubitPulseOpt框架，与标准的Gaussian脉冲相比，GRAPE优化的脉冲在模拟中实现了77倍的门保真度提升。该框架通过659个测试用例和符合NASA JPL安全关键编码标准的验证确保了可靠性。

Conclusion: QubitPulseOpt为可信赖的量子控制软件设定了新范式，通过硬件代表性最优控制解决了NISQ计算机中的门保真度问题，并展示了模拟到现实的差距可以被有效缩小。

Abstract: Gate fidelity in noisy intermediate-scale quantum (NISQ) computers remains the primary bottleneck limiting practical quantum computation, constrained by decoherence and control noise. Quantum optimal control (QOC) techniques, such as the gradient ascent pulse engineering (GRAPE) algorithm, offer a powerful approach to designing noise-robust pulses that actively mitigate these effects. However, most QOC implementations operate in idealized simulation environments that fail to capture the real-time parameter drift inherent to physical quantum hardware, creating a critical ``sim-to-real'' gap. In this work, I present QubitPulseOpt, an open-source, rigorously-tested Python framework designed to bridge this gap through hardware-representative optimal control. The framework demonstrates API connectivity to IQM's Garnet quantum processor (20-qubit superconducting device) and implements a workflow that constructs a high-fidelity ``digital twin'' using hardware-representative parameters. Using this simulation framework, I demonstrate that GRAPE-optimized pulses achieve a simulated gate error reduction of 77$\times$ compared to standard Gaussian pulses. The framework's reliability is ensured through a 659-test verification suite (59\% code coverage) and adherence to NASA JPL Power-of-10 safety-critical coding standards, establishing a new paradigm for trustworthy quantum control software. All results are from verified GRAPE optimizations with full provenance documentation.

</details>


### [644] [Pulsation of quantum walk between two arbitrary graphs with weakly connected bridge](https://arxiv.org/abs/2511.12872)
*Taisuke Hosaka,Etsuo Segawa*

Main category: quant-ph

TL;DR: 该研究探讨了在由两张图通过一座桥连接而成的图上进行Grover walk。当桥的连接强度ε足够小时，量子行走机会呈现脉动现象，即量子行走者在两张图之间周期性地转移。研究推导了ε趋近于0时，量子行走者在两张图上概率的渐近表达式，并发现该脉动现象仅取决于图的边数，而与图的具体结构无关。此外，研究还发现量子行走者转移的周期约为O(ε^{-1/2})，并且当两图的边数相等时，量子行走者几乎会完全转移到另一张图上。


<details>
  <summary>Details</summary>
Motivation: 研究Grover walk在特定图结构上的行为，特别是探索连接强度对量子行走者行为的影响，并揭示其与图结构无关的普适性规律。

Method: 考虑由两张图通过一座桥连接而成的图上的Grover walk，桥的连接强度参数为ε。当ε足够小时，分析量子行走者在两张图之间的转移行为，并推导相关概率的渐近表达式。

Result: 发现了量子行走者在两张图之间周期性转移的脉动现象。推导出的渐近表达式表明，脉动现象仅依赖于图的边数，与图的具体结构无关。转移周期约为O(ε^{-1/2})。当两图边数相等时，量子行走者几乎完全转移。

Conclusion: 该研究揭示了在具有桥连接的图上，Grover walk的脉动现象是一种普遍存在的行为，其表现形式（转移概率和周期）仅由图的边数决定，并且在特定条件下（边数相等）可以实现近乎完全的量子行走者转移。

Abstract: We consider the Grover walk on a finite graph composed of two arbitrary simple graphs connected by one edge, referred to as a bridge. The parameter $ε>0$ assigned at the bridge represents the strength of connectivity: if $ε=0$, then the graph is completely separated. We show that for sufficiently small values of $ε$, a phenomenon called pulsation occurs. The pulsation is characterized by the periodic transfer of the quantum walker between the two graphs. An asymptotic expression with respect to small $ε$ for the probability of finding the walker on either of the two graphs is derived. This expression reveals that the pulsation depends solely on the number of edges in each graph, regardless of their structure. In addition, we obtain that the quantum walker is transferred periodically between the two graphs, with a period of order $O(ε^{-1/2})$. Furthermore, when the number of edges of two graphs is equal, the quantum walker is almost completely transferred.

</details>


### [645] [A note on Schmidt-number witnesses based on symmetric measurements](https://arxiv.org/abs/2511.12887)
*Xiao-Qian Mu,Hao-Fan Wang,Shao-Ming Fei*

Main category: quant-ph

TL;DR: 通过利用基于对称测量的k-正线性映射，我们提出了新的(k+1)类Schmidt数见证，以更好地表征量子态的Schmidt数，并提出Fedorov比率作为实验验证工具。


<details>
  <summary>Details</summary>
Motivation: 量子纠缠的Schmidt数对于量子信息处理任务至关重要，高Schmidt数在其中展现出优势。

Method: 推导了基于对称测量的k-正线性映射，并基于此提出了(k+1)类Schmidt数见证。

Result: 提出的Schmidt数见证能更好地表征高维系统量子态的Schmidt数，并且Fedorov比率可以作为实验验证工具。

Conclusion: 新提出的Schmidt数见证在表征量子态的Schmidt数方面优于现有方法，并且Fedorov比率提供了一种可行的实验验证途径。

Abstract: The Schmidt number is an important kind of characterization of quantum entanglement. Quantum states with higher Schmidt numbers demonstrate significant advantages in various quantum information processing tasks. By deriving a class of k-positive linear maps based on symmetric measurements, we present new Schmidt-number witnesses of class (k + 1). By detailed example, we show that our Schmidt number witnesses identify better the Schmidt number of quantum states in high-dimensional systems. Furthermore, we note that the Fedorov ratio, which coincides with the Schmidt number for pure Gaussian states and provides a close approximation in non-Gaussian cases such as spontaneous parametric down-conversion, serves as an experimentally accessible tool for validating the proposed (k +1)-class Schmidt-number witnesses.

</details>


### [646] [Fast Quantum Many Body State Synthesis](https://arxiv.org/abs/2511.12923)
*Prashasti Tiwari,Dylan Lewis,Sougato Bose*

Main category: quant-ph

TL;DR: 通过优化一个“solver”哈密顿量，在短时间内演化一个初始态，来制备量子多体系统的基态。


<details>
  <summary>Details</summary>
Motivation: 制备多体系统的基态对于量子传感、非平衡量子动力学以及模拟量子过程等研究至关重要，但传统的绝热演化方法耗时且易引入退相干。

Method: 利用一个“solver”哈密顿量在短固定时间内（单位时间）演化一个初始态，并通过经典优化“solver”哈密顿量的参数来最小化能量，以期获得目标“problem”哈密顿量的基态。

Result: 研究了多达10个量子比特的系统，展示了该方法在制备多体纠缠基态方面的潜力。

Conclusion: 该方法提供了一种在短时间内制备多体纠缠基态的替代方案，有望克服传统方法的局限性。

Abstract: Quantum Mechanical ground states of many-body systems can be important resources for various investigations: for quantum sensing, as the initial state for nonequilibrium quantum dynamics following quenches, and the simulation of quantum processes that start by coupling systems in ground states, eg, could be a process in quantum chemistry. However, to prepare ground states can be challenging; for example, requires adiabatic switching of Hamiltonian terms slower than an inverse gap, which can be time consuming and bring in decoherence. Here we investigate the possibility of preparing a many-body entangled ground state of a certain Hamiltonian, which can be called a quantum ``problem'' Hamiltonian, using the time evolution of an initial fiducial state by another ``solver'' Hamiltonian/s for a very short fixed (unit) time. The parameters of the solver Hamiltonian are optimised classically using energy minimisation as the cost function. We present a study of up to n=10 qubit many-body states prepared using this methodology.

</details>


### [647] [A Global Spacetime Optimization Approach to the Real-Space Time-Dependent Schrödinger Equation](https://arxiv.org/abs/2511.12983)
*Enze Hou,Yuzhi Liu,Lei Wang,Han Wang*

Main category: quant-ph

TL;DR: 提出了一种名为“Fermionic Antisymmetric Spatio-Temporal Network”的通用神经网络框架，用于解决实空间中的时相关薛定谔方程（TDSE），能够处理复杂费米子系统的时变多体关联和反对称波函数。


<details>
  <summary>Details</summary>
Motivation: 为了解决求解复杂费米子系统时相关薛定谔方程（TDSE）的挑战，特别是捕捉时变多体关联和处理反对称波函数的问题。

Method: 将TDSE构建为一个全局优化问题，将时间作为显式输入与空间坐标一起处理，从而实现统一的时空表示，并支持高度可并行的训练。

Result: 在四个基准问题（一维谐振子、时变谐振子中的相互作用费米子、三维氢轨道动力学、激光驱动的H2分子）上取得了与参考解的优异一致性，验证了该方法的准确性、可扩展性和灵活性。

Conclusion: 该框架提供了一种比传统方法更具表达力的替代方案，能够准确模拟复杂系统中的长时间动力学，为量子动力学、分子控制和超快光谱学等领域的从头算模拟开辟了新可能性。

Abstract: The time-dependent Schrödinger equation (TDSE) in real space is fundamental to understanding the dynamics of many-electron quantum systems, with applications ranging from quantum chemistry to condensed matter physics and materials science. However, solving the TDSE for complex fermionic systems remains a significant challenge, particularly due to the need to capture the time-evolving many-body correlations, while the antisymmetric nature of fermionic wavefunctions complicates the function space in which these solutions must be represented. We propose a general-purpose neural network framework for solving the real-space TDSE, Fermionic Antisymmetric Spatio-Temporal Network, which treats time as an explicit input alongside spatial coordinates, enabling a unified spatiotemporal representation of complex, antisymmetric wavefunctions for fermionic systems. This approach formulates the TDSE as a global optimization problem, avoiding step-by-step propagation and supporting highly parallelizable training. The method is demonstrated on four benchmark problems: a 1D harmonic oscillator, interacting fermions in a time-dependent harmonic trap, 3D hydrogen orbital dynamics, and a laser-driven H$_2$ molecule, achieving excellent agreement with reference solutions across all cases. These results confirm our method's scalability, accuracy, and flexibility across various dimensions and interaction regimes, while demonstrating its ability to accurately simulate long-time dynamics in complex systems. Our framework offers a highly expressive alternative to traditional basis-dependent or mean-field methods, opening new possibilities for ab initio simulations of time-dependent quantum systems, with applications in quantum dynamics, molecular control, and ultrafast spectroscopy.

</details>


### [648] [ZX-DB: A Graph Database for Quantum Circuit Simplification and Rewriting via the ZX-Calculus](https://arxiv.org/abs/2511.13033)
*Valter Uotila,Cong Yu,Bo Zhao*

Main category: quant-ph

TL;DR: ZX-DB 是一个利用 ZX-calculus 在图数据库中进行量子电路简化和重写的数据驱动系统。


<details>
  <summary>Details</summary>
Motivation: 量子计算有潜力超越经典计算机，但需要对量子电路进行优化和适配，而 ZX-DB 旨在通过数据管理技术解决这一挑战。

Method: ZX-DB 将 ZX-calculus 重写规则编码为 openCypher 查询，并在图数据库引擎（如 Memgraph）上执行，以实现大规模量子电路的数据库原生转换。它还集成了张量和图等价性检查以验证正确性。

Result: 与 PyZX 相比，ZX-DB 在独立重写方面实现了数量级上的加速，但也暴露了当前图数据库引擎在模式匹配方面的瓶颈。

Conclusion: ZX-DB 将量子编译与图数据管理相结合，为可扩展的、数据库支持的量子计算流水线开辟了新的系统方向。

Abstract: Quantum computing is an emerging computational paradigm with the potential to outperform classical computers in solving a variety of problems. To achieve this, quantum programs are typically represented as quantum circuits, which must be optimized and adapted for target hardware through quantum circuit compilation. We introduce ZX-DB, a data-driven system that performs quantum circuit simplification and rewriting inside a graph database using ZX-calculus, a complete graphical formalism for quantum mechanics. ZX-DB encodes ZX-calculus rewrite rules as standard openCypher queries and executes them on an example graph database engine, Memgraph, enabling efficient, database-native transformations of large-scale quantum circuits. ZX-DB integrates correctness validation via tensor and graph equivalence checks and is evaluated against the state-of-the-art PyZX framework. Experimental results show that ZX-DB achieves up to an order-of-magnitude speedup for independent rewrites, while exposing pattern-matching bottlenecks in current graph database engines. By uniting quantum compilation and graph data management, ZX-DB opens a new systems direction toward scalable, database-supported quantum computing pipelines.

</details>


### [649] [A Fractional Calculus Framework for Open Quantum Dynamics: From Liouville to Lindblad to Memory Kernels](https://arxiv.org/abs/2511.13038)
*Bo Peng,Yu Zhang*

Main category: quant-ph

TL;DR: 分数阶微积分可用于描述具有长程记忆的开放量子系统的动力学，统一了酉演化、马尔可夫和非马尔可夫动力学。


<details>
  <summary>Details</summary>
Motivation: 许多物理系统表现出非马尔可夫特征，如代数弛豫和相干回流，这些特征超出了半群演化的范围。

Method: 通过分数阶时间导数引入幂律时间核，将分数阶量子主方程嵌入开放系统动力学的更广泛图景中，并将其表示为Lindblad半群的平均值。

Result: 分数阶量子主方程是记忆核模型的一个结构化子类，当分数阶为1时可简化为GKSL形式。该框架解释了长时衰减的代数起源，并连接了酉、马尔可夫和结构化非马尔可夫体系。

Conclusion: 分数阶微积分可以作为具有内在记忆的量子动力学的严谨统一语言，为理论分析和量子模拟开辟了新方向。

Abstract: Open quantum systems exhibit dynamics ranging from purely unitary evolution to irreversible dissipative relaxation. The Gorini--Kossakowski--Sudarshan--Lindblad (GKSL) equation uniquely characterizes Markovian dynamics that are completely positive and trace-preserving (CPTP), yet many physical systems display non-Markovian features such as algebraic relaxation and coherence backflow beyond the reach of semigroup evolution. Fractional calculus provides a natural framework for describing such long-memory behavior through power-law temporal kernels introduced by fractional time derivatives. Here we establish a unified hierarchy that embeds fractional quantum master equations within the broader landscape of open system dynamics. The fractional master equation forms a structured subclass of memory-kernel models, reducing to the GKSL form at unit fractional order. Through Bochner--Phillips subordination, fractional evolution is expressed as an average over Lindblad semigroups weighted by a power-law waiting-time distribution. This construction ensures physical consistency, explains the algebraic origin of long-time decay, and bridges unitary, Markovian, and structured non-Markovian regimes. The resulting framework positions fractional calculus as a rigorous and unifying language for quantum dynamics with intrinsic memory, enabling new directions for theoretical analysis and quantum simulation.

</details>


### [650] [Quantum lattice Boltzmann method for several time steps: A local Carleman linearization algorithm](https://arxiv.org/abs/2511.13072)
*Antonio David Bastida Zamora,Ljubomir Budinski,Valtteri Lahtinen,Pierre Sagaut*

Main category: quant-ph

TL;DR: 该研究提出了一种使用Carleman线性化进行量子格子Boltzmann方法的新型编码，实现了局部碰撞规则和高精度（约为10^-2）。


<details>
  <summary>Details</summary>
Motivation: 与先前工作不同，本研究提出的编码允许局部碰撞规则，同时保持获得正确结果的较高概率（约为10^-2）。

Method: 采用Carleman线性化对量子格子Boltzmann方法进行编码。

Result: 该算法每个时间步的计算复杂度为O(log_2^3(N)+Q^4)，其中N是2D格点的数量，Q是通道的数量，并且在使用动态电路时保持恒定的量子比特数。

Conclusion: 本研究提出的新型编码方案在量子格子Boltzmann方法中具有局部碰撞规则和高精度的优点。

Abstract: This article presents a novel encoding for quantum Lattice Boltzmann method algorithm using Carleman linearization. In contrast to previous articles \cite{Sanavio2024LatticeBC,sanavio2025carleman}, the encoding used allows for local collision rules while keeping a higher probability to obtain the right result, which is of the order of $10^{-2}$. The algorithm scales as $O(log_2^3(N)+Q^4)$ each time step with $N$ the number of lattice sites of the 2D lattice and $Q$ the number of channels with a constant number of qubits when using dynamical circuits.

</details>


### [651] [Topological enhancement of a PT-symmetric Su-Schrieffer-Heeger quantum battery](https://arxiv.org/abs/2511.13088)
*A-Long Zhou,Ya-Wen Xiao,Nuo Xu,Li-Li Gao,Long-Jie Li,Hang Zhou,Zi-Min Li,Chuan-Cun Shu*

Main category: quant-ph

TL;DR: 该研究提出了一种基于SSH模型的非厄米量子电池，通过PT对称协议进行充电，并在拓扑和非拓扑两种情况下比较了其储能和充电速度。


<details>
  <summary>Details</summary>
Motivation: 研究量子电池的性能提升机制，特别是利用非厄米性和拓扑性质。

Method: 构建并模拟了一个基于SSH模型的非厄米量子电池，采用PT对称协议进行充电，并分析了其在拓扑和非拓扑情况下的储能和充电动力学。

Result: 在拓扑区域，由于边缘态的非厄米性增强，量子电池的充电速度更快，存储的能量也更高。

Conclusion: 拓扑性质是提升量子电池性能的有效物理资源。

Abstract: We investigate a non-Hermitian quantum battery based on the Su-Schrieffer-Heeger (SSH) lattice, charged through a PT-symmetric protocol that alternates gain and loss between the two sublattices. The interplay between lattice topology and non-Hermiticity gives rise to both bulk and edge exceptional points (EPs), which govern the charging dynamics. In the topological regime, an edge-state EP emerges at an exponentially small non-Hermitian strength, resulting in early PT-symmetry breaking and rapid energy accumulation. This topological enhancement originates from the PT-symmetric non-Hermitian dynamics, in which the broken-symmetry edge mode with the largest imaginary part of the eigenvalue dominates the time evolution. Consequently, the topological phase consistently yields higher stored energy and faster saturation than the trivial configuration across all parameter regimes and system sizes. These findings demonstrate that topology constitutes a genuine physical resource for enhancing the performance of quantum batteries.

</details>


### [652] [Fractional Contribution of Dynamical and Geometric Phases in Quantum Evolution](https://arxiv.org/abs/2511.13090)
*Arun Kumar Pati,Vlatko Vedral*

Main category: quant-ph

TL;DR: 量子演化相位可由Bargmann角度唯一确定，实现几何与动力学的精确划分，并应用于量子门设计与相干控制。


<details>
  <summary>Details</summary>
Motivation: 区分量子演化总相位的几何与动力学组成部分是量子物理中的一个核心问题。

Method: 提出一个普适性定律，证明该划分仅由Bargmann角度（Bures角度）这一单一几何量决定。

Result: 证明了Bargmann角度是区分量子演化总相位的几何与动力学组成部分的唯一决定因素，并建立了量子演化动力学与状态空间几何之间新的量化联系。

Conclusion: 该发现可实时量化演化的几何性质，有助于设计高保真度和鲁棒性优化的几何量子门，并为量子速度极限和相干控制开辟新途径。

Abstract: The fundamental division of the total quantum evolution phase into geometric and dynamical components is a central problem in quantum physics. Here, we prove a remarkably simple and universal law demonstrating that this partitioning is governed, at every instant, solely by a single geometric quantity: the Bargmann angle (Bures angle). This result provides a universally applicable and rigorous way to define the exact fraction of the total phase that is geometric versus dynamical in origin, thereby establishing a new quantitative link between the dynamics of quantum evolution and the geometry of the state space. This finding has immediate practical consequences, furnishing a real-time measure of the geometricity of an evolution for designing high-fidelity geometric quantum gates with optimized robustness, and opening new avenues for quantum speed limit and coherent control.

</details>


### [653] [Quantum Mpemba Effect Induced by Non-Markovian Exceptional Point](https://arxiv.org/abs/2511.13173)
*Ze-Zhou Zhang,Hong-Gang Luo,Wei Wu*

Main category: quant-ph

TL;DR: 马潘巴效应在非马尔可夫情况下仍可实现，并可能加速量子系统中的能量和信息传输。


<details>
  <summary>Details</summary>
Motivation: 马潘巴效应在非平衡热力学领域具有基本意义，但其在非马尔可夫体系下的机制尚不明确。

Method: 提出了一种通过非马尔可夫奇异点实现量子马潘巴效应的机制，并在耗散量子谐振子模型中进行了验证。

Result: 验证了所提出的机制在耗散量子谐振子模型中的可行性。

Conclusion: 该研究为理解量子马潘巴效应提供了新的视角，并为加速量子系统的能量和信息传输开辟了道路。

Abstract: Quantum Mpemba effect describes an anomalous phenomenon of accelerated relaxation which is of fundamental interest in the field of nonequilibrium thermodynamics. Conventional theories on this phenomenon strongly rely on the Born-Markovian approximation, but this effect is not well understood in non-Markovian regimes. By investigating the relaxation process within the framework of a general non-Markovian dynamics, we propose a mechanism of realizing the quantum Mpemba effect via non-Markovian exceptional points. We verify the feasibility of this mechanism in a dissipative quantum harmonic oscillator model. Providing a new insight into the interesting non-equilibrium dynamics phenomenon, our work paves a way to accelerate the transfer of energy and information in quantum systems.

</details>


### [654] [The correlated matching decoder for the 4.8.8 color code](https://arxiv.org/abs/2511.13192)
*Yantong Liu,Junjie Wu,Lingling Lao*

Main category: quant-ph

TL;DR: 本文提出了一种用于4.8.8色码的关联解码器，通过利用受限格之间的相关性，提高了解码性能，并在理论和数值上都优于现有的解码器。


<details>
  <summary>Details</summary>
Motivation: 现有的基于匹配的色码解码器（如受限解码器）性能有限，但色码具有高编码率和横向实现克利福德门等优点。受统一解码器全局解码思想的启发，需要改进解码性能。

Method: 将用于表面码的关联匹配解码器映射到色码格上，从而得到色码的关联解码器，该解码器利用受限格之间的相关性。

Result: 关联解码器在理论阈值上优于受限解码器和统一解码器，并且在极低的物理错误率下能达到与统一解码器相当的性能。在比特翻转错误模型下，色码的阈值估计为10.38%，在现象学噪声模型下为3.13%。通过表面-色码映射，表面码在去极化噪声下的阈值分别为16.62%和3.52%。

Conclusion: 所提出的关联解码器能够有效提高色码的解码性能，克服了现有解码器的局限性，并在理论和数值模拟中得到了验证。

Abstract: Color codes present distinct advantages for fault-tolerant quantum computing, such as high encoding rates and the transversal implementation of Clifford gates. However, existing matching-based decoders for the color codes such as the restricted decoder (Kubica and Delfosse, 2023), suffer from limited decoding performance. Inspired by the global decoding insight of the unified decoder (Benhemou et al., 2023), this paper introduces a correlated decoder for the 4.8.8 color code, which improves upon the conventional restricted decoder by leveraging correlations between restricted lattices, and is derived by mapping the correlated matching decoder for the surface code onto the color code lattice. Analytical and numerical results show that the correlated decoder achieves higher thresholds than the restricted and unified decoders, while matching the performance of the unified decoder at very low physical error rates. Under the code capacity and phenomenological noise models, the estimated thresholds for the color code against bit-flip error are 10.38% and 3.13%, respectively. Furthermore, by applying the surface-color code mapping, the thresholds of 16.62% and 3.52% are obtained for the surface code against depolarizing noise.

</details>


### [655] [Topological quantum compilation for non-semisimple Ising anyons via monte carlo simulations](https://arxiv.org/abs/2511.13194)
*Jiangwei Long,Yizhi Li,Jianxin Zhong,Lijun Meng*

Main category: quant-ph

TL;DR: 利用非半单性伊辛任意子模型，通过MC-增强SKA算法，实现了高保真度的H门和T门近似，仅需三层递归即可满足容错量子计算的要求。在特定参数下，单个编织操作可高精度近似CNOT门，最终构建了{H, T, CNOT}通用门集。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索基于非半单性伊辛任意子模型的通用量子门集构建方法，以实现高保真度的量子计算。

Method: 使用蒙特卡洛增强的Solovay-Kitaev算法（MC-enhanced SKA）和非半单性伊辛任意子模型的初等编织矩阵（EBMs），对标准单量子比特门（H门和T门）进行高保真度近似。

Result: 在递归层数为三的情况下，实现了满足容错量子计算保真度要求的高精度H门和T门近似。在特定参数 α ∈ [2, 2.031] 下，单个编织操作可高精度近似CNOT门。在 α = 2.031, 2.047, 2.063 时，成功构建了高精度的{H, T, CNOT}通用门集。

Conclusion: 本研究为使用非半单性伊辛任意子实现通用量子计算提供了新的途径，证明了其在构建高保真度量子门集方面的潜力。

Abstract: We present a systematic numerical construction of a universal quantum gate set for topological quantum computation based on the non-semisimple Ising anyons model. Using the elementary braiding matrices (EBMs) of this model by the Monte Carlo-enhanced Solovay-Kitaev algorithm (MC-enhanced SKA), we achieve high-fidelity approximations of standard one-qubit gates (Hadamard H-gate and phase T-gate). Remarkably, a recursion level of just three suffices to meet the fidelity requirements for fault-tolerant quantum computation. Our numerical results demonstrate that for the parameter α /in (2, 2.031], a single braiding operation can approximate the local equivalence class [CNOT] with high precision and great unitary measurement. Specifically, at α = 2.031, 2.047, and 2.063, we successfully construct a universal gate set {H-gate, T-gate, CNOT-gate} with high accuracy. This work establishes a new pathway towards universal quantum computation using non-semisimple Ising anyons.

</details>


### [656] [Data-driven adaptive quantum error mitigation for probability distribution](https://arxiv.org/abs/2511.13231)
*Rion Shimazu,Suguru Endo,Shigeo Hakkaku,Shinobu Saito*

Main category: quant-ph

TL;DR: 提出两种基于软件工程的量子概率分布纠错协议，通过N版本编程排除异常值，并选择具有最小方差的外插策略以提高精度。


<details>
  <summary>Details</summary>
Motivation: 量子纠错（QEM）旨在减少量子计算中的错误，尤其是在估算期望值和概率分布方面。本文提出两种改进 QEM 估算量子概率分布准确性的方法。

Method: 1. N版本编程：通过比较不同 QEM 策略产生的概率分布，排除异常值，以认证纠错后分布的可行性。 2. 一致性选择外插策略：准备K个不同错误率的数据点，选择L个进行外插，评估所有可能的组合，选择方差最小的外插方法。此方法也可逐比特位应用。

Result: 提出的 N 版本编程方法可以认证纠错后概率分布的可行性。一致性选择外插策略的方法能够选择出最优外插方法，减小纠错结果的方差，并能实现自适应纠错。

Conclusion: 本文提出的两种方法可以提高量子概率分布估算的准确性，为量子计算的应用提供了更可靠的手段。

Abstract: Quantum error mitigation (QEM) has been proposed as a class of hardware-friendly error suppression techniques. While QEM has been primarily studied for mitigating errors in the estimation of expectation values of observables, recent works have explored its application to estimating noiseless probability distributions. In this work, we propose two protocols to improve the accuracy of QEM for probability distributions, inspired by techniques in software engineering. The first is the N-version programming method, which compares probability distributions obtained via different QEM strategies and excludes the outlier distribution, certifying the feasibility of the error-mitigated distributions. The second is a consistency-based method for selecting an appropriate extrapolation strategy. Specifically, we prepare $K$ data points at different error rates, choose $L<K$ of them for extrapolation, and evaluate error-mitigated results for all $\binom{K}{L}$ possible choices. We then select the extrapolation method that yields the smallest variance in the error-mitigated results. This procedure can also be applied bitstring-wise, enabling adaptive error mitigation for each probability in the distribution.

</details>


### [657] [Depth Optimization of Ansatz Circuits for Variational Quantum Algorithms](https://arxiv.org/abs/2511.13256)
*Spyros Tserkis,Muhammad Umer,Dimitris G. Angelakis*

Main category: quant-ph

TL;DR: 通过增加量子比特、测量和经典控制操作来减少量子电路深度，以降低变分量子算法的噪声和错误。


<details>
  <summary>Details</summary>
Motivation: 由于物理量子比特的相干时间有限，量子电路深度的增加会限制量子算法的执行，并导致计算过程中出现噪声和错误。

Method: 通过引入额外的量子比特、进行测量和执行经典控制操作来减少量子电路的深度，并研究了非单一量子电路在模拟 Burgers 方程中的表示能力，同时考虑了噪声的影响。

Result: 非单一量子电路可以有效地表示流体流动配置，并且在两比特门错误率远低于空闲错误率时具有优势。

Conclusion: 所提出的非单一量子电路可以有效地减少变分量子算法的电路深度，并在噪声环境中具有实际应用价值，特别是在计算流体动力学领域。

Abstract: The increasing depth of quantum circuits presents a major limitation for the execution of quantum algorithms, as the limited coherence time of physical qubits leads to noise that manifests as errors during computation. In this work, we focus on circuits relevant to variational quantum algorithms and demonstrate that their depth can be reduced by introducing additional qubits, mid-circuit measurements, and classically controlled operations. As an illustrative example, we consider nonlinear dynamics governed by the one-dimensional Burgers' equation, which has broad applications in computational fluid dynamics. In particular, we show that the proposed non-unitary quantum circuits can efficiently represent fluid flow configurations in both laminar and turbulent regimes. Furthermore, we demonstrate that, when noise is taken into account, these circuits are advantageous in regimes where two-qubit gate error rates are relatively low compared to idling error rates.

</details>


### [658] [Restart Belief: A General Quantum LDPC Decoder](https://arxiv.org/abs/2511.13281)
*Lorenzo Valentini,Diego Forlivesi,Andrea Talarico,Marco Chiani*

Main category: quant-ph

TL;DR: RB译码器是目前最快、最准确的QLDPC译码算法，能够接近码距离的纠错能力。


<details>
  <summary>Details</summary>
Motivation: 量子退化会阻止BP算法可靠收敛，RB译码器旨在克服这一限制。

Method: RB译码器是一种基于BP的迭代算法，借鉴了分支定界优化的思想。

Result: RB译码器是目前最快、最准确的QLDPC译码算法。

Conclusion: RB译码器是目前最快、最准确的QLDPC译码算法，旨在接近码距离的纠错能力。

Abstract: Hardware-friendly quantum low-density parity-check (QLDPC) decoders are commonly built upon belief propagation (BP) processing. Yet, quantum degeneracy often prevents BP from achieving reliable convergence. To overcome this fundamental limitation, we propose the restart belief (RB) decoder, an iterative BP-based algorithm inspired by branch-and-bound optimization principles. From our analysis we find that the RB decoder represents both the fastest and most accurate decoding algorithm applicable to QLDPC codes to date, conceived with the explicit goal of approaching error correction up to the code distance.

</details>


### [659] [Switching rates in Kerr resonator with two-photon dissipation and driving](https://arxiv.org/abs/2511.13308)
*V. Yu. Mylnikov,S. O. Potashin,M. S. Ukhtary,G. S. Sokolovskii*

Main category: quant-ph

TL;DR: 该研究使用Kramer理论和P-表示法，在有限失谐和双光子耗散的条件下，分析了双光子驱动的Kerr振荡器中的开关速率和比特翻转错误率。研究发现，开关速率与失谐、非线性强度等参数之间存在复杂关系，并提出了优化量子比特性能的关键条件。


<details>
  <summary>Details</summary>
Motivation: 研究双光子驱动的Kerr振荡器中的开关速率和比特翻转错误率，以优化量子比特性能和设计可扩展的超导玻色子量子架构。

Method: 利用Kramer理论和P-表示法，在势垒近似下推导出比特翻转错误率的解析表达式，并通过与Liouvillian超算子对角化得到的数值模拟进行比较。

Result: 在纯耗散极限下，开关速率随失谐单调递增。在强Kerr非线性存在下，开关速率是失谐的非单调函数，在有限失谐处达到最小值。理论计算与数值模拟结果吻合良好。

Conclusion: 研究结果为优化临界cat量子比特的性能和设计可扩展的超导玻色子量子架构提供了关键条件和指导。

Abstract: We analytically investigate the switching rate in a two-photon driven Kerr oscillator with finite detuning and two-photon dissipation. This system exhibits quantum bistability and supports a logical manifold for a bosonic qubit. Using Kramer's theory together with the $P$-representation, we derive an analytical expression for the bit-flip error rate within the potential-barrier approximation. The agreement is demonstrated between analytical calculations and numerical simulations obtained by diagonalization of the Liouvillian superoperator. In the purely dissipative limit, the switching rate increases monotonically with detuning, as the two metastable states approach each other in phase space. However, the exponential contribution to the bit-flip rate exhibits a nontrivial dependence on system parameters, extending beyond the naive scaling with the average photon number. In the presence of large Kerr nonlinearity, the switching rate becomes a nonmonotonic function of the detuning and reaches a minimum at a finite detuning. This effect arises because detuning lowers the activation barrier for weak nonlinearity but increases it for large ones, ensuring a minimum of the switching-rate at nonzero detuning. These results establish key conditions for optimizing the performance of critical cat qubits and are directly relevant for the design of scalable superconducting bosonic quantum architectures.

</details>


### [660] [Floquet Recurrences in the Double Kicked Top](https://arxiv.org/abs/2511.13342)
*Avadhut V. Purohit,Udaysinh T. Bhosale*

Main category: quant-ph

TL;DR: 双踢翻滚体(DKT)模型中的精确量子周期性被解析地证明，并独立于kθ。通过纠缠和保真度速率函数，在特定条件下发现了动力学量子相变(DQPT)。水平统计分析表明，随着kr的变化，系统可以从可积过渡到非可积。


<details>
  <summary>Details</summary>
Motivation: 研究双踢翻滚体(DKT)模型，这是一个驱动的自旋模型，通过引入额外的时序对称性破坏踢来扩展量子踢翻滚体(QKT)。

Method: 通过重构其动力学为有效参数kr和kθ，解析地证明了Floquet算子的精确周期性。通过分析纠缠和保真度速率函数，以及水平统计，研究动力学量子相变和系统的可积性。

Result: 对于kr = jπ/2和kr = jπ/4，Floquet算子具有确定的周期性，并且独立于kθ。在特定条件下，动力学量子相变(DQPT)被发现。通过水平统计，观察到从可积到非可积的平滑过渡。

Conclusion: 双踢翻滚体(DKT)模型中的精确量子周期性和动力学量子相变(DQPT)现象被揭示。通过调控kr和kθ，可以控制任何系统大小的规则和混沌状态，这使得DKT成为量子控制和信息处理应用的有用平台。

Abstract: We study exact quantum recurrences in the double kicked top (DKT), a driven spin model that extends the quantum kicked top (QKT) by introducing an additional time-reversal symmetry-breaking kick. Reformulating its dynamics in terms of effective parameters $k_r$ and $k_θ$, we analytically show exact periodicity of the Floquet operator for $k_r = jπ/2$ and $k_r = jπ/4$ with distinct periods for integer and half-odd integer $j$. These exact recurrences were found to be independent of $k_θ$. The long-time-averaged entanglement and fidelity rate function show dynamical quantum phase transition (DQPT) for $k_r = jπ/2$ at time-reversal symmetric cases $k_θ= \pm k_r$. In the other time-reversal symmetric case $k_θ= 0$, the DQPT exists only for a half-odd integer $j$. Using level statistics, a smooth transition is observed from integrable to non-integrable nature as $k_r$ is changed away from $jπ/2$. Our work demonstrates that regular and chaotic regimes can be controlled for any system size by tuning $k_r$ and $k_θ$, making the DKT a useful platform for quantum control and information processing applications.

</details>


### [661] [The Intrinsic Angular - Momentum of Particles and the Resolution of the Spin-Statistics Theorem](https://arxiv.org/abs/2511.13360)
*Enrico Santamato,Francesco De Martini*

Main category: quant-ph

TL;DR: WIQM理论成功解决了SQM理论无法解决的自旋统计问题，并提出了新的量子力学理论。


<details>
  <summary>Details</summary>
Motivation: SQM理论无法解决自旋统计问题，特别是保利不相容原理。

Method: 提出WIQM理论，该理论提供了SQM的Weyl规范不变表述，并自然引入了“内禀螺旋度”或“内禀角动量”的概念，从而解决了SSC问题。

Result: WIQM理论成功解决了自旋统计问题，并能重现SQM的各项内容，如薛定谔方程、海森堡不确定性关系以及EPR关联等。

Conclusion: WIQM理论是一个更完整（在EPR意义上）的量子力学理论，它考虑了SQM忽略的粒子内禀属性，并正确地连接了自旋和统计力学。

Abstract: The traditional Standard Quantum Mechanics (SQM) theory is unable to solve the Spin-s problem, i.e., to justify the utterly important "Pauli Exclusion Principle". A complete and straightforward solution of the Spin-Statistics problem is presented based on the "Weyl Integrable Quantum Mechanics" (WIQM) theory. This theory provides a Weyl-gauge invariant formulation of the Standard Quantum Mechanics and reproduces successfully, with no restrictions, the full set of the quantum mechanical processes, including the formulation of Dirac's or Schrödinger's equation, of Heisenberg's uncertainty relations, and of the nonlocal EPR correlations. etc. When the Weyl Integrable Quantum Mechanics is applied to a system made of many identical particles with spin, an additional constant property of all elementary particles enters naturally into play: the "intrinsic helicity", or the "intrinsic angular - momentum". This additional particle property, not considered by Standard Quantum Mechanics, determines the correct Spin-Statistics Connection (SSC) observed in Nature. All this leads to the consideration of a novel, most complete (in the EPR sense) quantum mechanical theory.

</details>


### [662] [Above-Unity Coherent Cooperativity of Tin-Vacancy Centers in Diamond Photonic Crystal Cavities](https://arxiv.org/abs/2511.13375)
*Nina Codreanu,Tim Turan,Daniel Bedialauneta Rodriguez,Matteo Pasini,Lorenzo de Santis,Maximilian Ruf,Christian F. Primavera,Leonardo G. C. Wienhoven,Caroline E. Smulders,Simon Gröblacher,Ronald Hanson*

Main category: quant-ph

TL;DR: 锡空位（SnV）中心与光子晶体腔（PCC）耦合，实现了相干协合度高于1的优异光学和自旋特性，为量子网络应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 利用SnV中心优异的光学和自旋特性，通过与PCC耦合来增强其光-物质相互作用，并实现纠缠生成协议。

Method: 制备了自由悬挂的PCC，并在室温下对327个腔进行了表征，测量了其质量因子。选取了两个腔耦合的SnV发射体进行详细研究，测量了其质量因子、Purcell因子降低的寿命、腔透射率的调制对比度以及相干协合度。

Result: 在两个样品中，PCC的平均质量因子超过了1.0(3) x 10^4。两个详细研究的腔耦合SnV发射体的质量因子高达25.4(4) x 10^3，Purcell因子降低的寿命对应的协合度高达20.6(11)。SnV的线宽测量显示，在两个器件中都实现了高于1的相干协合度，最高值为8.3(12)。SnV在谐振时腔透射率的消光比高达98.8(4)%。

Conclusion: 实现了SnV中心与PCC耦合的相干协合度高于1，证明了其作为高效、相干光-物质接口在未来量子网络中的应用潜力。

Abstract: The tin-vacancy center in diamond (SnV) has emerged as a compelling building block for realizing next-generation quantum networks thanks to its excellent optical and spin properties. Coupling to photonic crystal cavities (PCCs) promises to further enhance the SnV light-matter interface and unlock a diverse range of entanglement generation protocols. Recent pioneering experiments showing Purcell enhancement of SnV centers in PCCs underscore this potential. However, optical coupling that is coherent - the key ingredient for use in quantum protocols - has so far remained elusive. Here, we demonstrate above-unity coherent cooperativity of SnV centers embedded in photonic crystal cavities. We fabricate free-standing PCCs using a quasi-isotropic undercut. Across two samples, we conduct room-temperature characterizations, measuring resonances for 327 cavities, with an average quality factor exceeding $Q = 1.0(3) \times 10^4$. Two cavity-coupled emitters are examined in detail, exhibiting quality factors up to $Q = 25.4(4) \times 10^3$ and Purcell-reduced lifetimes corresponding to cooperativities up to $C = 20.6(11)$. Furthermore, the single SnVs are observed to strongly modulate the cavity transmission with an extinction contrast up to $98.8(4) \%$ on resonance. Finally, SnV linewidth measurements reveal above-unity coherent cooperativities in both devices, with the highest value being $C_\mathrm{coh} = 8.3(12)$. These results open the door to using cavity-coupled SnV centers as efficient, coherent light-matter interfaces for future quantum networks.

</details>


### [663] [Efficient algorithm for fidelity estimation of two quantum states](https://arxiv.org/abs/2511.13383)
*Anumita Mukhopadhyay,Shibdas Roy,Arun Kumar Pati*

Main category: quant-ph

TL;DR: 提出一种高效的量子算法来估算混合态量子态保真度。


<details>
  <summary>Details</summary>
Motivation: 混合态量子态保真度估算是量子计算和信息科学中的关键问题，但目前缺乏有效的方法，尤其是在处理混合态和高维密度矩阵时。

Method: 提出一种基于密度矩阵指数化和干涉测量方案的高效量子算法，适用于混合态，时间复杂度为 O(N^2/ε^7)。

Result: 该算法可以作为一种资源高效的技术，用于推断任意两个（纯态或混合态）未知或已知量子态的保真度，前提是量子态的密度矩阵相互交换。

Conclusion: 所提出的算法为混合态量子态保真度的估算提供了一种有效的方法。

Abstract: The fidelity estimation between two quantum states is crucial for quantum computation and information science. However, an efficacious method for this, especially for mixed states and higher-dimensional density matrices, remains elusive. While there are many existing algorithms on computing the fidelity between two pure states, there is not much work on how to obtain the fidelity between two mixed states. Here, we propose an efficient quantum algorithm for the fidelity estimation, based primarily on the density matrix exponentiation and interferometeric scheme for mixed states, with a time complexity of $O(N^2/ε^7)$, where $N$ is the system size and $ε$ is a precision error. Our algorithm may serve as a resource-efficient technique to deduce fidelity of any two (pure or mixed) unknown or known quantum states, when the density matrices of the quantum states commute with each other.

</details>


### [664] [Taming Barren Plateaus in Arbitrary Parameterized Quantum Circuits Without Sacrificing Expressibility](https://arxiv.org/abs/2511.13408)
*Zhenyu Chen,Yuguo Shao,Zhengwei Liu,Zhaohui Wei*

Main category: quant-ph

TL;DR: 通过在参数化量子电路 (PQC) 中插入量子通道层来消除“バレン高原”现象，从而实现有效的参数优化。


<details>
  <summary>Details</summary>
Motivation: 现有的参数化量子电路（PQC）架构面临“バレン高原”等挑战，导致损失函数随系统规模指数增长，阻碍参数优化。

Method: 提出一种通用且硬件高效的方法，通过在任意 PQC 中插入一层量子通道（每个通道需要一个辅助量子比特和四个额外的门）来修改 PQC，得到 MPQC。该方法保证 MPQC 的表达能力至少与原 PQC 相同，并且在温和假设下可消除バレン高原，使所有参数可训练。

Result: 修改后的 MPQC 在高达 100 个量子比特和 2400 个层的情况下，有效消除了バレン高原，并成功应用于热态制备的 PQC，而原始 PQC 则出现梯度消失。

Conclusion: 所提出的 MPQC 方法能够有效消除バレン高原，提高参数可训练性，并且对噪声具有鲁棒性，可直接应用于当前的 NISQ 硬件。

Abstract: Quantum algorithms based on parameterized quantum circuits (PQCs) have enabled a wide range of applications on near-term quantum devices. However, existing PQC architectures face several challenges, among which the ``barren plateaus" phenomenon is particularly prominent. In such cases, the loss function concentrates exponentially with increasing system size, thereby hindering effective parameter optimization. To address this challenge, we propose a general and hardware-efficient method for eliminating barren plateaus in an arbitrary PQC. Specifically, our approach achieves this by inserting a layer of easily implementable quantum channels into the original PQC, each channel requiring only one ancilla qubit and four additional gates, yielding a modified PQC (MPQC) that is provably at least as expressive as the original PQC and, under mild assumptions, is guaranteed to be free from barren plateaus. Furthermore, by appropriately adjusting the structure of MPQCs, we rigorously prove that any parameter in the original PQC can be made trainable. Importantly, the absence of barren plateaus in MPQCs is robust against realistic noise, making our approach directly applicable to current noisy intermediate-scale quantum (NISQ) hardware. Numerically, we demonstrate the practicality of our method by modifying a commonly used PQC for thermal-state preparation. The results show that {barren plateaus are effectively eliminated} in this class of circuits with up to 100 qubits and 2400 layers, whereas the original ansatz suffers from severe gradient vanishing.

</details>


### [665] [Emulation of the Six-State Quantum Key Distribution Protocol with Pulsed Lasers](https://arxiv.org/abs/2511.13413)
*Sara P. Gandelman,Georgi Gary Rozenman*

Main category: quant-ph

TL;DR: 该论文提出了一个结合光学实验和计算分析的六状态量子密钥分发协议框架，用于探索和测试量子通信协议。


<details>
  <summary>Details</summary>
Motivation: 提供一个清晰易懂的框架来探索六状态量子密钥分发协议，该协议是BB84方案的扩展，并结合了光学实验和计算分析。

Method: 通过结合光学实验和计算分析来探索六状态量子密钥分发协议，该协议是BB84方案的一个三基扩展。

Result: 该框架提供了一个健壮且成本效益高的平台，用于测试量子通信协议，突出了多基编码的基本原理，并展示了实验测量如何在受控的实验环境中直接连接到理论预期。

Conclusion: 该框架为理解和演示量子密钥分发的原理，特别是六状态协议，提供了一个有效的工具。

Abstract: Quantum cryptography remains a topic of enduring scientific and educational interest. Here, we present a clear and accessible framework for exploring the six-state quantum key distribution protocol, an enhanced three-basis extension of the BB84 scheme that combines optical experiments with computational analysis. Designed for testing quantum communication protocols through emulation, this approach provides a robust and cost-effective platform that highlights the fundamental principles of multi-basis encoding and demonstrates how experimental measurements connect directly to theoretical expectations in a controlled tabletop setting.

</details>


### [666] [Probing parameters estimation with Gaussian non-commutative measurements](https://arxiv.org/abs/2511.13451)
*Alice P. G. Hall,Carlos H. S. Vieira,Jonas F. G. Santos*

Main category: quant-ph

TL;DR: 该研究提出了一种利用非对易高斯测量来增强高斯量子信道参数估计的方法，并通过量子Fisher信息（QFI）进行了量化。


<details>
  <summary>Details</summary>
Motivation: 高斯量子态和通道在量子信息处理、量子热力学和量子计算等领域至关重要，但对其参数估计的优化研究不足。

Method: 研究人员设计了一种包含两个非对易高斯测量的探针态制备方案，并分析了该方案对量子Fisher信息（QFI）的影响。他们还研究了探针态初态为热态时产生的量子相干性对QFI的影响及其变化率。最后，将该方案应用于衰减器和放大器这两种单模高斯通道。

Result: 通过调整探针态制备中的不确定性参数，可以提高表征高斯量子信道的QFI。此外，量子相干性的量和它随参数的变化率都对QFI的提升有贡献。该方案在衰减器和放大器通道上得到了验证。

Conclusion: 该研究提出了一种利用非对易高斯测量和量子相干性来提升高斯量子信道参数估计精度的方法，为量子计量学中的相干性应用提供了新的思路，并且具有实验可行性。

Abstract: Gaussian quantum states and channels are pivotal across many branches of quantum science and their applications, including the processing and storage of quantum information, the investigation of thermodynamics in the quantum regime, and quantum computation. The great advantage is that Gaussian states are experimentally accessible via their first and second statistical moments. In this work, we investigate parameter estimation for Gaussian states, in which the probe-state preparation stage involves two noncommutative Gaussian measurements on the position and momentum observables, introducing tunable parameters. The influence of these noncommutative Gaussian measurements is investigated through the quantum Fisher information (QFI). We showed that the QFI for characterizing Gaussian channels can be increased by adjusting the uncertainty parameters in the preparation of the probe state. Furthermore, if the probe is initially in a thermal state, probe-state preparation may generate quantum coherence in its energy basis. We showed that not only does the amount of coherence affect the improvement of the QFI, but also the rate of change of the coherence with respect to the parameter to be estimated. The proposed probe-state protocol is applied to two paradigmatic single-mode Gaussian channels, the attenuator and amplification channels, which are building blocks of Gaussian quantum information. Our results contribute to the use of coherence in quantum metrology and are experimentally feasible in quantum-optical devices.

</details>


### [667] [Machine learning inspired photon number resolution in superconducting nanowire single-photon detectors](https://arxiv.org/abs/2511.13475)
*I. S. Kuijf,F. B. Baalbergen,L. Seldenthuis,E. P. L. van Nieuwenburg,M. J. A. de Dood*

Main category: quant-ph

TL;DR: SNSPD在光子数分辨方面取得进展，引入了基于PCA和Bhattacharyya系数的新分析方法，实现了可扩展的实时光子计数。


<details>
  <summary>Details</summary>
Motivation: SNSPD在光子数分辨方面缺乏系统性的解释和基准化框架。

Method: 结合主成分分析（PCA）和一种新的读出技术来探索SNSPD的光子数分辨能力，并引入基于Bhattacharyya系数的置信度指标来量化该能力。

Result: 发现光子数信息包含在一个单一主成分中，该成分近似于平均响应迹线的时间导数。所提出的方法表明，通过中等的硬件要求（5 GSample/sec采样率和3 GHz模拟带宽）即可实现SNSPD的光子数分辨，并可在FPGA上实现，从而为实时光子计数提供高度可扩展的解决方案。

Conclusion: 所提出的分析框架和方法为SNSPD的光子数分辨能力提供了量化和基准化的途径，并指出了实现该能力的硬件可行性。

Abstract: Photon-number resolved detection with superconducting nanowire single-photon detectors (SNSPDs) attracts increasing interest, but lacks a systematic framework for interpreting and benchmarking this capability. In this work, we combine principal component analysis (PCA) with a new readout technique to explore the photon-number resolving capabilities of SNSPDs and find that the information of the photon number is contained in a single principal component which approximates the time derivative of the average response trace. We introduce a new confidence metric based on the Bhattacharyya coefficient to quantify the photon-number-resolving capabilities of a detector system and show that this metric can be used to compare different systems. Our analysis and interpretation of the principal components imply that photon-number resolution in SNSPDs can be achieved with moderate hardware requirements in terms of both sample rate (5 GSample/sec) and analog bandwidth (3 GHz) and could be implemented in an FPGA, giving a highly scalable solution for real-time photon counting.

</details>


### [668] [Spin-Adapted Fermionic Unitaries: From Lie Algebras to Compact Quantum Circuits](https://arxiv.org/abs/2511.13485)
*Ilias Magoulas,Francesco A. Evangelista*

Main category: quant-ph

TL;DR: 通过利用李代数技术，我们推导了表示对称性自适应酉变换的精确乘积公式，从而设计出迄今为止最高效的保持对称性的量子电路，并引入了最小通用对称性自适应算符池以进一步减少所需的量子资源。


<details>
  <summary>Details</summary>
Motivation: 为了在经典和量子模拟多体系统中有效处理对称性，需要设计能够强制执行化学中所有对称性的高效量子电路，但这因点群和自旋对称性的相互作用而变得困难。

Method: 利用李代数技术推导出表示对称性自适应酉变换的精确乘积公式，并设计了保持对称性的量子电路，同时引入了最小通用对称性自适应算符池。

Result: 我们设计出了迄今为止最高效的保持对称性的量子电路，并通过引入最小通用对称性自适应算符池进一步减少了所需的量子资源。

Conclusion: 李代数技术可用于设计高效的对称性自适应量子电路，并能通过最小通用对称性自适应算符池进一步优化量子资源利用率。

Abstract: Conservation of symmetries plays a crucial role in both classical and quantum simulations of many-body systems, enabling the tracking of states with specific symmetry properties and leading to substantial reductions in the number of optimization parameters. The design of efficient quantum circuits that enforce all symmetries typically encountered in chemistry has remained elusive, mainly due to the interplay of point group and spin symmetries. By exploiting Lie algebraic techniques, we derive exact product formulas representing symmetry-adapted unitaries. These decompositions allow us to design the most efficient symmetry-preserving quantum circuits to date. Finally, we introduce a minimum universal symmetry-adapted operator pool to further reduce the required quantum resources.

</details>


### [669] [Towards Quantum Software for Quantum Simulation](https://arxiv.org/abs/2511.13520)
*Maja Franz,Lukas Schmidbauer,Joshua Ammermann,Ina Schaefer,Wolfgang Mauerer*

Main category: quant-ph

TL;DR: 该论文提出了一种基于模型驱动工程（MDE）的方法，以解决当前量子模拟软件栈中存在的关键问题，旨在为可扩展、跨平台的量子模拟工作流提供支持。


<details>
  <summary>Details</summary>
Motivation: 当前的量子模拟技术主要局限于基础科学研究，缺乏通用的基础设施和建模抽象，特别是模型规范、哈密顿量构建和硬件感知映射方面的通用框架。这阻碍了量子模拟在更广泛领域的应用。

Method: 提出并倡导采用模块化的模型驱动工程（MDE）方法，支持不同类型的量子模拟（数字和模拟），并促进自动化、性能评估和可重用性。通过一个高能物理学的例子来说明该方法的潜力。

Result: 识别出量子模拟软件栈中模型规范、哈密顿量构建和硬件感知映射方面的关键缺失。提出了一种MDE方法，并勾画了一个能够支持可扩展、跨平台模拟工作流的量子模拟框架愿景。

Conclusion: 模块化的模型驱动工程（MDE）方法是弥合当前量子模拟软件栈差距、实现可扩展、跨平台模拟工作流的关键。

Abstract: Quantum simulation is a leading candidate for demonstrating practical quantum advantage over classical computation, as it is believed to provide exponentially more compute power than any classical system. It offers new means of studying the behaviour of complex physical systems, for which conventionally software-intensive simulation codes based on numerical high-performance computing are used. Instead, quantum simulations map properties and characteristics of subject systems, for instance chemical molecules, onto quantum devices that then mimic the system under study.
  Currently, the use of these techniques is largely limited to fundamental science, as the overall approach remains tailored for specific problems: We lack infrastructure and modelling abstractions that are provided by the software engineering community for other computational domains.
  In this paper, we identify critical gaps in the quantum simulation software stack-particularly the absence of general-purpose frameworks for model specification, Hamiltonian construction, and hardware-aware mappings. We advocate for a modular model-driven engineering (MDE) approach that supports different types of quantum simulation (digital and analogue), and facilitates automation, performance evaluation, and reusability. Through an example from high-energy physics, we outline a vision for a quantum simulation framework capable of supporting scalable, cross-platform simulation workflows.

</details>


### [670] [Simultaneous variances of Pauli strings, weighted independence numbers, and a new kind of perfection of graphs](https://arxiv.org/abs/2511.13531)
*Zhen-Peng Xu,Jie Wang,Qi Ye,Gereon Koßmann,René Schwonnek,Andreas Winter*

Main category: quant-ph

TL;DR: Pauli strings can be analyzed using frustration graphs, which connect graph theory and quantum information. This paper introduces a new class of graphs called 'hbar-perfect' graphs, which have connections to spin systems and graph topology. These graphs enable efficient entanglement detection, shadow tomography, uncertainty relations, and lower bounds for ground state energies. They also lead to quantum algorithms for computing the independence number, with a logarithmic qubit requirement. The paper also studies how 'hbar-perfectness' behaves under graph operations and how common these graphs are.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the interface between graph theory and quantum information using Pauli strings and their commutativity structure encoded by frustration graphs. Specifically, the paper introduces and investigates a new class of graphs called 'hbar-perfect' graphs that have tight connections to spin systems and graph topology.

Method: The paper investigates the interface between graph theory and quantum information using frustration graphs for Pauli strings. It introduces and defines a new class of graphs called 'hbar-perfect' graphs, which extend perfect and h-perfect graphs. The study explores applications of these graphs in entanglement detection, shadow tomography, uncertainty relations, and computing ground state energies. It also develops quantum algorithms for computing the independence number and analyzes the properties of 'hbar-perfect' graphs under graph operations.

Result: The paper establishes 'hbar-perfect' graphs as a class with applications in efficient entanglement detection, shadow tomography, uncertainty relations, and lower bounds for ground state energies. It also presents quantum algorithms for computing the independence number, demonstrating a logarithmic qubit scaling. The behavior of 'hbar-perfectness' under graph operations and their prevalence are also determined.

Conclusion: The introduction of 'hbar-perfect' graphs provides a valuable framework connecting graph theory and quantum information, leading to practical applications in quantum information processing and algorithms. The study deepens the understanding of this interface and suggests potential avenues for future research in quantum algorithms and complexity.

Abstract: A set of Pauli stings is well characterized by the graph that encodes its commutatitivity structure, i.e., by its frustration graph. This graph provides a natural interface between graph theory and quantum information, which we explore in this work. We investigate all aspects of this interface for a special class of graphs that bears tight connections between the groundstate structures of a spin systems and topological structure of a graph. We call this class $\hbar$-perfect, as it extends the class of perfect and $h$-perfect graphs.
  Having an $\hbar$-perfect graph opens up several applications: we find efficient schemes for entanglement detection, a connection to the complexity of shadow tomography, tight uncertainty relations and a construction for computing good lower on bounds ground state energies. Conversely this also induces quantum algorithms for computing the independence number. Albeit those algorithms do not immediately promise an advantage in runtime, we show that an approximate Hamilton encoding of the independence number can be achieved with an amount of qubits that typically scales logarithmically in the number of vertices. We also we also determine the behavior of $\hbar$-perfectness under basic graph operations and evaluate their prevalence among all graphs.

</details>


### [671] [Measurement-based Dynamical Decoupling for Fidelity Preservation on Large-scale Quantum Processors](https://arxiv.org/abs/2511.13532)
*Jeongwoo Jae,Changwon Lee,Juzar Thingna,Yeong-Dae Kwon,Daniel K. Park*

Main category: quant-ph

TL;DR: MDD是一种测量式动态解耦协议，可以通过测量噪声子系统来确定控制单元门，其测量开销与子系统数量成线性关系。MDD在局部能量弛豫和退相干噪声下，其纠缠保真度可达任意动态解耦方案（基于bang-bang操作）的一阶近似上限。


<details>
  <summary>Details</summary>
Motivation: 为了抑制量子算法中的退相干，提高其性能。

Method: MDD协议通过对噪声子系统进行部分测量来确定控制单元门。

Result: 在IBM Eagle处理器上，MDD将14量子比特量子傅里叶变换的成功概率提高了450倍，并在56量子比特样本对角化算法中提高了N2的基态能量估计精度，优于标准的XX脉冲动态解耦。

Conclusion: MDD是一种可扩展且有效的抑制大规模量子算法中退相干的方法。

Abstract: Dynamical decoupling (DD) is a key technique for suppressing decoherence and preserving the performance of quantum algorithms. We introduce a measurement-based DD (MDD) protocol that determines control unitary gates from partial measurements of noisy subsystems, with measurement overhead scaling linearly with the number of subsystems. We prove that, under local energy relaxation and dephasing noise, MDD achieves the maximum entanglement fidelity attainable by any DD scheme based on bang-bang operations to first order in evolution time. On the IBM Eagle processor, MDD achieved up to a $450$-fold improvement in the success probability of a $14$-qubit quantum Fourier transform, and improved the accuracy of ground-state energy estimation for $N_2$ in the $56$-qubit sample-based quantum diagonalization compared with the standard XX-pulse DD. These results establish MDD as a scalable and effective approach for suppressing decoherence in large-scale quantum algorithms.

</details>


### [672] [Sequences of Bivariate Bicycle Codes from Covering Graphs](https://arxiv.org/abs/2511.13560)
*Benjamin C. B. Symons,Abhishek Rajput,Dan E. Browne*

Main category: quant-ph

TL;DR: 该论文提出了一种生成无限序列双变量自行车（BB）码的方法，并研究了h-覆盖码的代数条件及其与基码的（上）同调映射。


<details>
  <summary>Details</summary>
Motivation: 现有BB码的搜索空间巨大，本研究旨在通过覆盖图和代数条件来缩小搜索范围，并寻找具有优良性能的BB码。

Method: 1. 定义h-覆盖码，并给出其代数条件。 2. 利用覆盖图映射的链映射性质，研究（上）同调映射。 3. 搜索具有重量8校验的BB码，并找到一些例子。 4. 证明h-覆盖码的参数界限，并提出猜想。 5. 讨论该方法在其他类型编码上的普适性。

Result: 1. 找到了许多有趣的BB码例子，如[[144,12,12]] gross code。 2. 找到了具有重量8校验的BB码，包括[[64,14,8]]和[[144,14,14]]码。 3. 证明了h-覆盖码的参数满足 $k_h 
less k$ 和 $d_h 
less hd$ （h为奇数）。 4. 提出了h-覆盖码参数的猜想：$[[n_h = hn, k_h 
less k, d 
less d_h 
less hd]]$。

Conclusion: 该研究提供了一种系统地生成和搜索BB码的方法，通过覆盖图和代数条件，有效缩小了搜索空间，并发现了具有优良性能的BB码。该方法有望推广到其他类型的编码。

Abstract: We show that given an instance of a bivariate bicycle (BB) code, it is possible to generate an infinite sequence of new BB codes using increasingly large covering graphs of the original code's Tanner graph. When a BB code has a Tanner graph that is a $h$-fold covering of the base BB code's Tanner graph, we refer to it as a $h$-cover code. We show that for a BB code to be a $h$-cover code, its lattice parameters and defining polynomials must satisfy simple algebraic conditions relative to those of the base code. By extending the graph covering map to a chain map, we show there are induced projection and lifting maps on (co)homology that enable the projection and lifting of logical operators and, in certain cases, automorphisms between the base and the cover code. The search space of cover codes is considerably reduced compared to the full space of possible polynomials and we find that many interesting examples of BB codes, such as the $[[144,12,12]]$ gross code, can be viewed as cover codes. We also apply our method to search for BB codes with weight 8 checks and find many codes, including a $[[64,14,8]]$ and $[[144,14,14]]$ code. For an $h$-cover code of an $[[n,k,d]]$ BB code with parameters $[[n_h = hn, k_h, d_h]]$, we prove that $k_h \geq k$ and $d_h \leq hd$ when $h$ is odd. Furthermore if $h$ is odd and $k_h = k$, we prove the lower bound $d \leq d_h$. We conjecture it is always true that an $h$-cover BB code of a base $[[n,k,d]]$ BB code has parameters $[[n_h = hn, k_h \geq k, d \leq d_h \leq hd]]$. While the focus of this work is on bivariate bicycle codes, we expect these methods to generalise readily to many group algebra codes and to certain code constructions involving hypergraph, lifted, and balanced products.

</details>


### [673] [Qudit-native simulation of the Potts model](https://arxiv.org/abs/2511.13572)
*Maxim A. Gavreev,Evgeniy O. Kiktenko,Aleksey K. Fedorov,Anastasiia S. Nikolaeva*

Main category: quant-ph

TL;DR: 利用 qudit 量子计算机模拟量子多体系统，特别是高维的 Potts 模型。


<details>
  <summary>Details</summary>
Motivation: 模拟高维物理对象组成的量子多体系统，特别是 Potts 模型，是量子计算中的一个挑战。

Method: 提出基于 Suzuki-Trotter 分解的 qudit 系统模拟方法，并设计了两种 qudit 原生分解方案：一种利用 Molmer-Sorensen 门和局部能级编码相互作用，另一种利用 light-shift 门。该方法将 Potts 模型动力学映射到硬件高效的 qudit 门序列，并结合 Suzuki-Trotter 近似和 evolution-into-gates 框架来检测动力学量子相变。

Result: 实现了 qudit 量子模拟 Potts 模型，并展示了使用 Suzuki-Trotter 近似和 evolution-into-gates 框架检测动力学量子相变的方法。

Conclusion: 为基于 qudit 的数字量子模拟多体模型提供了途径，并为探测高维量子多体模型中的非解析行为提供了新视角。

Abstract: Simulating entangled, many-body quantum systems is notoriously hard, especially in the case of high-dimensional nature of physical underlying objects. In this work, we propose an approach for simulating the Potts model based on the Suzuki-Trotter decomposition that we construct for qudit systems. Specifically, we introduce two qudit-native decomposition schemes: (i) the first utilizes Molmer-Sorensen gate and additional local levels to encode the Potts interactions, while (ii) the second employs an light-shift gate that naturally fits qudit architectures. These decompositions enable a direct and efficient mapping of the Potts model dynamics into hardware-efficient qudit gate sequences for trapped-ion platform. Furthermore, we demonstrate the use of a Suzuki-Trotter approximation with our evolution-into-gates framework, for detecting the dynamical quantum phase transition. Our results establish a pathway toward qudit-based digital quantum simulation of many-body models and provide a new perspective on probing nonanalytic behavior in high-dimensional quantum many-body models.

</details>


### [674] [Long-range entanglement and quantum correlations in a multi-frequency comb system](https://arxiv.org/abs/2511.13604)
*Sahil Pontula,Debasmita Banerjee,Marin Soljacic,Yannick Salamin*

Main category: quant-ph

TL;DR: 该论文探索了一种生成多模量子光的新方法，利用非线性耦合的频率梳系统，实现了从紫外到中红外的大范围光谱调谐，并有望应用于量子传感和通信领域。


<details>
  <summary>Details</summary>
Motivation: 现有技术在生成跨多个频率梳的量子光方面存在局限性，本研究旨在探索一种能够生成多模量子光的方法。

Method: 利用单个闲置梳作为媒介，通过级联三波上转换和下转换过程，理论上探索了一种生成一系列非线性耦合频率梳的机制，并实现了梳内和梳间的两模压缩和纠缠。

Result: 该系统能够生成跨越从紫外到中红外频率的大范围光谱的梳内和梳间两模压缩和纠缠，并且可以通过协方差矩阵优化来按需生成多模量子光。

Conclusion: 本研究提出的多模量子光生成机制为实现可调谐宽带鬼成像光谱、压缩增强泵浦探测测量以及光谱复用量子信息宽带纠缠等应用提供了新的可能性。

Abstract: Frequency combs are multimode photonic systems that underlie countless precision sensing and metrology applications. Since their invention over two decades ago, numerous efforts have pushed frequency combs to broader bandwidths and more stable operation. More recently, quantum squeezing and entanglement have been explored in single frequency comb systems for quantum advantages in sensing and signal multiplexing. However, the production of quantum light across multiple frequency combs remains unexplored. In this work, we theoretically explore a mechanism that generates a series of nonlinearly coupled frequency combs through cascaded three-wave upconversion and downconversion processes mediated by a single idler comb. We show how this system generates inter- and intracomb two-mode squeezing and entanglement spanning a very large spectral range, from ultraviolet to mid-IR frequencies. Finally, we show how this system can be engineered to produce on-demand multimode quantum light through covariance matrix optimization. Our findings could enable tunable broadband ghost spectroscopy protocols, squeezing-enhanced pump-probe measurements, and broadband entanglement between spectrally-multiplexed quanta of information.

</details>


### [675] [Modeling Quantum Noise in Nanolasers using Markov Chains](https://arxiv.org/abs/2511.13622)
*Matias Bundgaard-Nielsen,Gian Luca Lippi,Jesper Mørk*

Main category: quant-ph

TL;DR: 激光量子噪声可以通过离散的马尔可夫链模型精确计算，适用于不同尺寸和激励水平的激光器，尤其在纳秒激光器和激光阈值以下表现优于兰之万方程。


<details>
  <summary>Details</summary>
Motivation: 随机自发辐射导致激光输出波动，现有兰之万力方法不适用于纳秒激光器。本研究旨在为广泛的激光器提供一种量化计算激光量子噪声的新方法。

Method: 从简单的速率方程出发，假设光子数和激发电子数是离散的，构建一个马尔可夫链模型来计算激光量子噪声，并与主方程和兰之万方程进行比较。

Result: 所提出的马尔可夫链模型在所有泵浦值和激光尺寸下（排除集体发射体效应时）都能准确计算量子噪声，特别是在激光阈值以下比兰之万方程更准确，在多光子极限下可简化为兰之万方程。

Conclusion: 离散的马尔可夫链模型是一种通用且准确的激光量子噪声计算方法，为从纳秒激光器到宏观激光器等不同系统提供了最佳的噪声计算方案。

Abstract: The random nature of spontaneous emission leads to unavoidable fluctuations in a laser's output. This is often included through random Langevin forces in laser rate equations, but this approach falls short for nanolasers. In this paper, we show that the laser quantum noise can be quantitatively computed for a very broad class of lasers by starting from simple and intuitive rate equations and merely assuming that the number of photons and excited electrons only takes discrete values. The success of the model is explained by showing that it constitutes a Markov chain, which can be derived from the full master equations. We show that in the many-photon limit, the model simplifies to Langevin equations. We perform an extensive comparison of different approaches for computing quantum noise in lasers, identifying the best approach for different system sizes, ranging from nanolasers to macroscopic lasers, and different levels of excitation, i.e., cavity photon number. In particular, we find that the numerical solution to the Langevin equations is inaccurate below the laser threshold, while the laser Markov chain model, on the other hand, is accurate for all pump values and laser sizes when collective emitter effects are excluded.

</details>


### [676] [Architectural Approaches to Fault-Tolerant Distributed Quantum Computing and Their Entanglement Overheads](https://arxiv.org/abs/2511.13657)
*Nitish Kumar Chandra,Eneet Kaur,Kaushik P. Seshadreesan*

Main category: quant-ph

TL;DR: 该论文对三种不同类型的容错分布式量子计算（DQC）架构进行了资源需求和噪声阈值的评估，重点关注了其在量子比特数量和贝尔对生成次数方面的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 随着量子硬件向模块化和网络化架构发展，需要评估不同容错DQC方案的资源需求和噪声阈值，以确定适合近期硬件和资源限制的架构。

Method: 通过分析基于平面表面码和环形码的代表性示例，研究了三种DQC架构类型（基于GHZ态连接的小型量子节点、分布式大错误纠正码块、将码块分配给不同模块）的资源需求（贝尔对数量、平均生成次数）与代码距离的关系。

Result: 论文分析了不同DQC架构类型在增加代码距离时，资源需求（贝尔对数量、平均生成次数）的扩展情况，为选择合适的容错DQC架构提供了依据。

Conclusion: 该分析为了解在近期硬件和资源限制下，适合容错分布式量子计算的架构提供了宝贵的见解。

Abstract: Fault tolerant quantum computation over distributed quantum computing (DQC) platforms requires careful evaluation of resource requirements and noise thresholds. As quantum hardware advances toward modular and networked architectures, various fault tolerant DQC schemes have been proposed, which can be broadly categorized into three architectural types. Type 1 architectures consist of small quantum nodes connected via Greenberger-Horne-Zeilinger (GHZ) states, enabling nonlocal stabilizer measurements. Type 2 architectures distribute a large error correcting code block across multiple modules, with most stabilizer measurements remaining local, except for a small subset at patch boundaries that are performed using nonlocal CNOT gates. Type 3 architectures assign code blocks to distinct modules and can perform fault tolerant operations such as transversal gates, lattice surgery, and teleportation to implement logical operations between code blocks. Using the planar surface code and toric code as representative examples, we analyze how the resource requirements, particularly the number of Bell pairs and the average number of generation attempts, scale with increasing code distance across different architectural designs. This analysis provides valuable insights for identifying architectures well suited to fault tolerant distributed quantum computation under near term hardware and resource constraints.

</details>


### [677] [Quantum Advantage in Learning Mixed Unitary Channels](https://arxiv.org/abs/2511.13683)
*Yue Tu,Liang Jiang*

Main category: quant-ph

TL;DR: We study learning mixed unitary channels using Fisher information and find the sample complexity scales as r/(d*epsilon^2), highlighting the importance of ancilla and channel rank. We also show that random mixed unitary channels are easy to learn.


<details>
  <summary>Details</summary>
Motivation: The paper aims to understand the learning of mixed unitary quantum channels under various resource constraints, specifically focusing on the role of ancilla and concatenation in determining sample complexity.

Method: The study employs Fisher information as a tool to analyze the learning process. It derives an expression for the asymptotic sample complexity, which is found to be proportional to r/(d*epsilon^2), where r is the channel rank, d is the system dimension, and epsilon^2 is the mean-square error. The paper also explores the learnability of random mixed unitary channels.

Result: The derived sample complexity for learning mixed unitary channels is $rac{r}{dinom{2}{ 	imes 	ext{error}}}$, indicating that both the ancilla (implicitly, as it affects r) and the rank of the channel (r) are critical resources. Furthermore, the results show that random mixed unitary channels are practically learnable.

Conclusion: The paper concludes that Fisher information provides a precise understanding of the resources required for learning mixed unitary channels, with ancilla and channel rank being key factors. The learnability of random mixed unitary channels is also established, suggesting their practical relevance.

Abstract: We study the task of learning mixed unitary channels using Fisher information, under different quantum resource assumptions including ancilla and concatenation. Our result shows that the asymptotic sample complexity scales as $\frac{r}{d\varepsilon^2}$, where $r$ is the rank of the channel (i.e.\ the number of different unitaries), $d$ is the dimension of the system, and $\varepsilon^2$ is the mean-square error. Thus the critical resource is the ancilla, which mirrors the result in~\cite{chen2022quantum} but in a more precise form, as we point out that $r$ is also important. Additionally, we demonstrate the practical potential of mixed unitary channels by showing that random mixed unitary channels are easy to learn.

</details>


### [678] [Network Operations Scheduling for Distributed Quantum Computing](https://arxiv.org/abs/2511.13687)
*Nitish Kumar Chandra,Eneet Kaur,Kaushik P. Seshadreesan*

Main category: quant-ph

TL;DR: 分布式量子计算架构的关键在于调度器，它协调量子网络上的操作以实现跨量子处理单元（QPU）的非局域纠缠门。本文比较了两种最小化调度跨度的方法：基于资源受限项目调度（RCPSP）框架的方法和基于贪婪启发式算法的方法。通过对量子傅里叶变换算法的实例分析，我们发现RCPSP方法在某些情况下优于贪婪启发式算法，而在另一些情况下两者表现相当，这表明了RCPSP框架的有效性以及贪婪启发式算法的相关性和实用性。


<details>
  <summary>Details</summary>
Motivation: 扩展量子计算能力需要分布式架构，而协调量子网络操作以实现跨QPU的非局域纠缠门是其中的关键。最小化调度跨度对于在资源受限的网络中有效利用资源至关重要。

Method: 1. 使用METIS等工具将计算电路分区并分配给不同的QPU，以最小化跨分区数量的非局域纠缠门，并使QPU的量子比特负载接近均匀。2. 识别跨分区所需的非局域纠缠门，并将其映射到实现QPU之间必要纠缠的网络操作序列。3. 最小化调度网络操作，以缩短总执行时间（跨度）。4. 比较了基于RCPSP框架的方法和贪婪启发式算法在解决调度跨度最小化问题上的表现。5. 以量子傅里叶变换算法为例，分析了在中心辐射型（星型）网络架构上的实现情况。

Result: 通过对量子傅里叶变换算法在中心辐射型网络架构上的实例分析，发现在一个实例中RCPSP方法优于贪婪启发式算法，而在另一个实例中两者表现相当。

Conclusion: RCPSP框架在分布式量子计算的调度跨度最小化问题上显示出有效性，同时贪婪启发式算法也具有其相关性和实用性。

Abstract: Realizing distributed architectures for quantum computing is crucial to scaling up computational power. A key component of such architectures is a scheduler that coordinates operations over a short-range quantum network required to enable the necessary non-local entangling gates between quantum processing units (QPUs). It is desirable to determine schedules of minimum make span, which in the case of networks with constrained resources hinges on their efficient usage. Here we compare and contrast two approaches to solving the make span minimization problem, an approach based on the resource constrained project scheduling (RCPSP) framework, and another based on a greedy heuristic algorithm. The workflow considered is as follows. Firstly, the computational circuit is partitioned and assigned to different QPUs such that the number of nonlocal entangling gates acting across partitions is minimized while the qubit load is nearly uniform on the individual QPUs, which can be accomplished using, e.g., the METIS solver. Secondly, the nonlocal entangling gate requirements with respect to the partitions are identified, and mapped to network operation sequences that deliver the necessary entanglement between the QPUs. Finally, the network operations are scheduled such that the make span is minimized. As illustrative examples, we analyze the implementation of a small instance of the Quantum Fourier Transform algorithm over instances of a simple hub and spoke (star) network architecture comprised of a quantum switch as the hub and QPUs as spokes, each with a finite qubit resource budget. In one instance, our results show the RCPSP approach outperforming the greedy heuristic. In another instance, we find the two performing equally well. Our results thus illustrate the effectiveness of the RCPSP framework, while also underlining the relevance and usefulness of greedy heuristics.

</details>


### [679] [Ultra Low Overhead Syndrome Extraction for the Steane code](https://arxiv.org/abs/2511.13700)
*Boldizsár Poór,Benjamin Rodatz,Aleks Kissinger*

Main category: quant-ph

TL;DR: 该研究提出了一个用于[[7, 1, 3]] Steane码的容错性综合提取新基准，采用动态协议。


<details>
  <summary>Details</summary>
Motivation: 为了提高[[7, 1, 3]] Steane码的容错性综合提取的效率和准确性。

Method: 通过两种高度优化的量子电路实现：一个包含14个CNOTs的容错电路和一个包含11个CNOTs的高效非容错恢复电路。该协议能够自适应地响应内部故障，丢弃标记的测量结果，并回退到恢复电路来纠正潜在的错误。

Result: 与优化的Steane方法相比，逻辑错误率平均降低了约14.3%；与Reichardt的三比特方法相比，逻辑错误率平均降低了约17.7%。

Conclusion: 提出的动态协议在[[7, 1, 3]] Steane码的容错性综合提取方面比现有技术更有效。

Abstract: We establish a new performance benchmark for the fault-tolerant syndrome extraction of [[7, 1, 3]] Steane code with a dynamic protocol. Our method is built on two highly optimized circuits derived using fault-equivalent ZX-rewrites: a primary fault-tolerant circuit with 14 CNOTs and an efficient non-fault-tolerant recovery circuit with 11 CNOTs. The protocol uses an adaptive response to internal faults, discarding flagged measurements and falling back to the recovery circuit to correct potentially detrimental errors. Monte Carlo simulations confirm the efficiency of our protocol, reducing the logical error rate per cycle by an average of ~14.3% relative to the optimized Steane method [arXiv:2506.17181] and ~17.7% compared to the Reichardt's three-qubit method [arXiv:1804.06995], the leading prior techniques.

</details>


### [680] [Quantum Error Correction Codes for Truncated SU(2) Lattice Gauge Theories](https://arxiv.org/abs/2511.13721)
*Xiaojun Yao*

Main category: quant-ph

TL;DR: 构建了两种适用于纯SU(2)格子规范理论的量子纠错码，适用于准一维、二维和三维晶格。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是为纯SU(2)格子规范理论构建量子纠错码，该理论在纯SU(2)格子规范理论的电基截断在电通量$j_{\max}=1/2$。

Method: 第一种编码将每个顶点的Gauss定律转换为稳定子，第二种编码仅使用一半顶点，并且在局部是碳编码。两种编码都能纠正单量子比特错误。SU(2)哈密顿量的电和磁项用两种编码中的逻辑门表示。

Result: 第一种编码的逻辑门哈密顿量与先前工作中发现的规范单态的自旋哈密顿量精确匹配。

Conclusion: 所提出的两种量子纠错码能够纠正单量子比特错误，并且能够处理SU(2)哈密顿量的电和磁项。

Abstract: We construct two quantum error correction codes for pure SU(2) lattice gauge theory in the electric basis truncated at the electric flux $j_{\rm max}=1/2$, which are applicable on quasi-1D plaquette chains, 2D honeycomb and 3D triamond and hyperhoneycomb lattices. The first code converts Gauss's law at each vertex into a stabilizer while the second only uses half vertices and is locally the carbon code. Both codes are able to correct single-qubit errors. The electric and magnetic terms in the SU(2) Hamiltonian are expressed in terms of logical gates in both codes. The logical-gate Hamiltonian in the first code exactly matches the spin Hamiltonian for gauge singlet states found in previous work.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [681] [Neural Network-Augmented Iterative Learning Control for Friction Compensation of Motion Control Systems with Varying Disturbances](https://arxiv.org/abs/2511.11850)
*Ali Mashhadireza,Ali Sadighi*

Main category: eess.SY

TL;DR: 本研究提出一种结合迭代学习控制（ILC）和简单横向神经网络的鲁棒控制策略，用于提高线性洛伦兹力致动器在摩擦和模型不确定性下的轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 在存在摩擦和模型不确定性的情况下，提高线性洛伦兹力致动器的轨迹跟踪性能。

Method: 将迭代学习控制（ILC）与简单的横向神经网络相结合，ILC补偿非线性摩擦效应，神经网络估计变化的参考指令的非线性ILC补偿。

Result: 通过动态调整ILC补偿，该方法能够适应时变摩擦，减少参考指令变化时的误差，并加速收敛。与使用复杂神经网络的先前方法相比，该方法简化了在线训练和实现。

Conclusion: 实验结果证实了该方法在具有不同参考轨迹的多个任务中实现精确跟踪的有效性。

Abstract: This paper proposes a robust control strategy that integrates Iterative Learning Control (ILC) with a simple lateral neural network to enhance the trajectory tracking performance of a linear Lorentz force actuator under friction and model uncertainties. The ILC compensates for nonlinear friction effects, while the neural network estimates the nonlinear ILC effort for varying reference commands. By dynamically adjusting the ILC effort, the method adapts to time-varying friction, reduces errors at reference changes, and accelerates convergence. Compared to previous approaches using complex neural networks, this method simplifies online training and implementation, making it practical for real-time applications. Experimental results confirm its effectiveness in achieving precise tracking across multiple tasks with different reference trajectories.

</details>


### [682] [Emulation-based Neuromorphic Control for the Stabilization of LTI Systems](https://arxiv.org/abs/2511.11875)
*Elena Petri,Koen J. A. Scheres,Erik Steur,W. P. M. H.,Heemels*

Main category: eess.SY

TL;DR: Brain-inspired SNNs offer advantages for control systems, but design methods are lacking. This paper presents a systematic approach to stabilize LTI systems using SNN controllers by emulating continuous signals and introducing a new stability notion (iSISS).


<details>
  <summary>Details</summary>
Motivation: Classical digital systems lack the low-latency, low-energy, and adaptive control capabilities offered by neuromorphic engineering and SNNs. However, systematic methods for designing and analyzing neuron-inspired spiking controllers are currently missing.

Method: A two-step procedure: 1. Establish conditions for neuron parameters to emulate continuous-time signals accurately using a special metric. 2. Introduce and prove a new stability notion, integral spiking-input-to-state stability (iSISS), based on this metric. Demonstrate that asymptotically stable LTI systems possess this property.

Result: A certifiable practical stability property of the closed-loop system can be established by combining the two design steps. The approach is demonstrated to be effective through a numerical case study.

Conclusion: This paper introduces a systematic approach for designing SNN-based controllers to stabilize LTI systems, addressing the lack of such methods. The proposed technique ensures emulation of continuous signals and establishes a novel stability notion (iSISS), leading to certifiable practical stability for closed-loop systems.

Abstract: Brain-inspired neuromorphic technologies can offer important advantages over classical digital clock-based technologies in various domains, including systems and control engineering. Indeed, neuromorphic engineering could provide low-latency, low-energy and adaptive control systems in the form of spiking neural networks (SNNs) exploiting spike-based control and communication. However, systematic methods for designing and analyzing neuron-inspired spiking controllers are currently lacking. This paper presents a new systematic approach for stabilizing linear time-invariant (LTI) systems using SNN-based controllers, designed as a network of integrate-and-fire neurons, whose input is the measured output from the plant and generating spiking control signals. The new approach consists of a two-step emulation-based design procedure. In the first step, we establish conditions on the neuron parameters to ensure that the spiking signal generated by a pair of neurons emulates any continuous-time signal input to the neurons with arbitrary accuracy in terms of a special metric for spiky signals. In the second step, we propose a novel stability notion, called integral spiking-input-to-state stability (iSISS) building on this special metric. We prove that an asymptotically stable LTI system has this iSISS property. By combining these steps, a certifiable practical stability property of the closed-loop system can be established. Generalizations are discussed and the effectiveness of the approach is illustrated in a numerical case study.

</details>


### [683] [Sampling-Aware Control Barrier Functions for Safety-Critical and Finite-Time Constrained Control](https://arxiv.org/abs/2511.11897)
*Shuo Liu,Wei Xiao,Calin A. Belta*

Main category: eess.SY

TL;DR: 该论文提出了一种名为采样感知控制障碍函数（SACBF）的新框架，用于解决安全关键控制系统中的采样数据实现问题。


<details>
  <summary>Details</summary>
Motivation: 现有的控制障碍函数（CBF）框架在实际应用中存在安全性和可行性问题，尤其是在零阶保持（ZOH）控制器下，由于采样效应和多约束冲突，可能导致不安全或不可行。

Method: SACBF框架通过估计和包含基于泰勒展开的障碍函数演化上界来考虑采样效应和高相对度约束，确保了在ZOH控制器下的安全性和有限时间可达性。此外，还提出了一个名为r-SACBF的松弛变体，通过引入松弛变量来处理多约束问题。

Result: SACBF保证了安全集和有限时间可达集的连续时间前向不变性。仿真结果表明，SACBF在传统HOCBF方法失效的情况下，仍能实现安全可行的性能。

Conclusion: SACBF提供了一个统一的框架，能够有效地处理采样效应和多约束问题，提高了安全关键控制系统的安全性和可行性。

Abstract: In safety-critical control systems, ensuring both safety and feasibility under sampled-data implementations is crucial for practical deployment. Existing Control Barrier Function (CBF) frameworks, such as High-Order CBFs (HOCBFs), effectively guarantee safety in continuous time but may become unsafe when executed under zero-order-hold (ZOH) controllers due to inter-sampling effects. Moreover, they do not explicitly handle finite-time reach-and-remain requirements or multiple simultaneous constraints, which often lead to conflicts between safety and reach-and-remain objectives, resulting in feasibility issues during control synthesis. This paper introduces Sampling-Aware Control Barrier Functions (SACBFs), a unified framework that accounts for sampling effects and high relative-degree constraints by estimating and incorporating Taylor-based upper bounds on barrier evolution between sampling instants. The proposed method guarantees continuous-time forward invariance of safety and finite-time reach-and-remain sets under ZOH control. To further improve feasibility, a relaxed variant (r-SACBF) introduces slack variables for handling multiple constraints realized through time-varying CBFs. Simulation studies on a unicycle robot demonstrate that SACBFs achieve safe and feasible performance in scenarios where traditional HOCBF methods fail.

</details>


### [684] [On The Detection of Minimum Forecast Horizon For Real-Time Scheduling of Energy Storage Systems in Smart Grid](https://arxiv.org/abs/2511.12029)
*Nicholas Tetteh Ofoe,Weilun Wang,Lei Wu*

Main category: eess.SY

TL;DR: 本论文提出了一种基于轨迹对齐的最小预测时域定义，并提出了一种算法来识别最小规划时域，使所有滚动时域控制决策与全时域全局优化相匹配。


<details>
  <summary>Details</summary>
Motivation: 随着储能系统（ESSs）越来越多地整合到电网中，在不确定和波动的电力价格下，需要有效的实时控制策略。储能系统模型预测控制的一个重要问题是确定精确模拟全局最优控制轨迹所需的最小预测时域。现有文献中的方法仅提供充分条件，并可能忽略控制动作中的实际不一致性。

Method: 提出一种基于轨迹对齐的最小预测时域定义，并提出一种算法来识别最小规划时域。

Result: 使用来自Nord Pool日内市场丹麦DK1投标区的实际价格数据和现实的ESS模型，说明60小时的预测时域可以精确模拟全局控制序列和经济结果。在其他参数配置下，没有预测时域能确保完全收敛，这表明预测时域的存在对各种参数很敏感。

Conclusion: 研究结果为储能调度中的最小预测时域检测提供了一个运行上重要的框架，并为这一重要规划措施的分析描述铺平了道路。

Abstract: The increasing integration of energy storage systems (ESSs) into power grids has necessitated effective real-time control strategies under uncertain and volatile electricity prices. An important problem of model predictive control of ESSs is identifying the minimum forecast horizon needed to exactly simulate the globally optimal control trajectory. Existing methods in the literature provide only sufficient conditions and might ignore real-world inconsistencies in control actions. In this paper, we introduce a trajectory-alignment-based definition of the minimum forecast horizon and propose an algorithm that identifies the minimum planning horizon for which all rolling-horizon control decisions match those of the full-horizon global optimization. Using real price data from the bidding zone DK1 in Denmark of the Nord Pool day-ahead market and a realistic ESS model, we illustrate that $60$ hours of forecast horizon allows us to exactly simulate the global control sequence and economic outcomes. In addition, we illustrate that under other parameter configurations, no forecast horizon ensures full convergence, demonstrating the sensitivity of the existence of a forecast horizon to various parameters. Our findings provide an operationally significant framework for minimum forecast horizon detection in storage scheduling and pave the way for the analytical description of this important planning measure.

</details>


### [685] [Real-Time Physics-Aware Battery Health Monitoring from Partial Charging Profiles via Physics-Informed Neural Networks](https://arxiv.org/abs/2511.12053)
*Xubo Gu,Xun Huan,Yao Ren,Wenqing Zhou,Weiran Jiang,Ziyou Song*

Main category: eess.SY

TL;DR: 通过参数化物理信息神经网络（P-PINNSPM）在单粒子模型关键老化相关参数空间上，实现了电池内部状态的快速、高精度预测和健康状态（SOH）估计的提升。


<details>
  <summary>Details</summary>
Motivation: 现有电池健康监测方法在评估速度和诊断深度之间存在权衡，难以在快速评估的同时精确识别内部退化状态，而深入了解退化机制对电池管理至关重要。

Method: 开发了一种参数化物理信息神经网络（P-PINNSPM），在单粒子模型（SPM）的关键老化相关参数空间上进行建模，能够预测内部变量并识别内部参数。

Result: P-PINNSPM模型能在约30秒内识别内部参数，速度比有限体积法快47倍，同时保持高精度。该模型将电池健康状态（SOH）估计精度至少提高了60.61%，并能外推至未见的SOH水平，支持在不同充电和操作条件下进行鲁棒估计。

Conclusion: 基于物理信息机器学习的方法在开发实时、数据高效、物理感知（physics-aware）的电池管理系统方面具有巨大潜力。

Abstract: Monitoring battery health is essential for ensuring safe and efficient operation. However, there is an inherent trade-off between assessment speed and diagnostic depth-specifically, between rapid overall health estimation and precise identification of internal degradation states. Capturing detailed internal battery information efficiently remains a major challenge, yet such insights are key to understanding the various degradation mechanisms. To address this, we develop a parameterized physics-informed neural network (P-PINNSPM) over the key aging-related parameter space for a single particle model. The model can accurately predict internal battery variables across the parameter space and identifies internal parameters in about 30 seconds-achieving a 47x speedup over the finite volume method-while maintaining high accuracy. These parameters improve the battery state-of-health (SOH) estimation accuracy by at least 60.61%, compared to models without parameter incorporation. Moreover, they enable extrapolation to unseen SOH levels and support robust estimation across diverse charging profiles and operating conditions. Our results demonstrate the strong potential of physics-informed machine learning to advance real-time, data-efficient, and physics-aware battery management systems.

</details>


### [686] [Tight displacement-based formation control under bounded disturbances. A set-theoretic perspective](https://arxiv.org/abs/2511.12163)
*Vlad-Matei Angheluţă,Bogdan Gheorghe,Daniel Ioan,Ionela Prodan,Florin Stoican*

Main category: eess.SY

TL;DR: 本研究提出了一种确定性方法，利用集论概念和不变集原理，来综合考虑有界扰动（如测量噪声）下基于位移的编队控制器的合成，并提供了保证预定性能边界的优化参数选择方法。


<details>
  <summary>Details</summary>
Motivation: 现有文献多使用随机框架处理有界扰动下的编队控制问题，本研究旨在提出一种基于集论概念的确定性方法。

Method: 利用不变集原理，将最终有界理论应用于基于位移的编队动力学，并为控制律参数提供了优化选择框架。

Result: 该方法能够严格分析系统在持续扰动下的行为，并成功应用于多障碍环境中保持紧密编队的挑战性场景。

Conclusion: 基于集论的方法为有界扰动下基于位移的编队控制提供了一种严谨且可优化的解决方案。

Abstract: This paper investigates the synthesis of controllers for displacement-based formation control in the presence of bounded disturbances, specifically focusing on uncertainties originating from measurement noise. While the literature frequently addresses such problems using stochastic frameworks, this work proposes a deterministic methodology grounded in set-theoretic concepts. By leveraging the principles of set invariance, we adapt the theory of ultimate boundedness to the specific dynamics of displacement-based formations. This approach provides a rigorous method for analyzing the system's behavior under persistent disturbances. Furthermore, this set-theoretic framework allows for the optimized selection of the proposed control law parameters to guarantee pre-specified performance bounds. The efficacy of the synthesized controller is demonstrated in the challenging application of maintaining tight formations in a multi-obstacles environment.

</details>


### [687] [AI-Enhanced IoT Systems for Predictive Maintenance and Affordability Optimization in Smart Microgrids: A Digital Twin Approach](https://arxiv.org/abs/2511.12175)
*Koushik Ahmed Kushal,Florimond Gueniat*

Main category: eess.SY

TL;DR: 该研究提出了一种增强型物联网框架，通过数字孪生模型实现智能微电网的预测性维护和可负担性优化。


<details>
  <summary>Details</summary>
Motivation: 为了提高分布式微电网环境的可靠性和能源效率，需要一种能够整合实时传感器数据、基于机器学习的故障预测和成本感知运营分析的系统。

Method: 提出了一种结合数字孪生和物联网的框架，该框架同步物理微电网组件和虚拟数字孪生，以实现组件退化、动态负载管理和优化维护计划的早期检测。

Result: 实验评估证明，与基线微电网管理方法相比，预测准确性得到提高，运行停机时间减少，并且实现了可衡量的成本节约。

Conclusion: 研究结果强调了数字孪生驱动的物联网架构作为下一代智能和可负担能源系统的可扩展解决方案的潜力。

Abstract: This study presents an AI enhanced IoT framework for predictive maintenance and affordability optimization in smart microgrids using a Digital Twin modeling approach. The proposed system integrates real time sensor data, machine learning based fault prediction, and cost aware operational analytics to improve reliability and energy efficiency in distributed microgrid environments. By synchronizing physical microgrid components with a virtual Digital Twin, the framework enables early detection of component degradation, dynamic load management, and optimized maintenance scheduling. Experimental evaluations demonstrate improved predictive accuracy, reduced operational downtime, and measurable cost savings compared to baseline microgrid management methods. The findings highlight the potential of Digital Twin driven IoT architectures as a scalable solution for next generation intelligent and affordable energy systems.

</details>


### [688] [Microwave-acoustic-driven power electronics](https://arxiv.org/abs/2511.13412)
*Liyang Jin,Zichen Xi,Joseph G. Thomas,Jun Ji,Yuanzhi Zhang,Nuo Chen,Yizheng Zhu,Linbo Shao,Liyan Zhu*

Main category: eess.SY

TL;DR: 使用基于铌酸锂的微波表面声波(SAW)器件实现了高压、低容值的机械隔离栅驱动器，并展示了其在GaN器件和降压转换器中的应用，同时具有超宽温度范围和电磁干扰（EMI）免疫能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以通过统一通道同时传输功率和信号，同时实现电气隔离。

Method: 基于铌酸锂的微波表面声波（SAW）器件，利用1.25毫米的机械传播长度实现了2.75千伏的隔离电压和0.032皮法的隔离电容。

Result: 实现了13.4伏的开路电压和44.4毫安的短路电流，驱动了氮化镓（GaN）高迁移率晶体管，开关时间为108.8纳秒，并成功应用于降压转换器。器件在0.5 K至544 K的超宽温度范围内工作。

Conclusion: 所提出的微波SAW器件为先进电力电子领域提供了紧凑、高性能的隔离电源和信号传输解决方案，具有固有电磁干扰（EMI）免疫能力和异构集成潜力。

Abstract: Electrical isolation is critical to ensure safety and minimize electromagnetic interference (EMI), yet existing methods struggle to simultaneously transmit power and signals through a unified channel. Here we demonstrate a mechanically-isolated gate driver based on microwave-frequency surface acoustic wave (SAW) device on lithium niobate that achieves galvanic isolation of 2.75 kV with ultralow isolation capacitance (0.032 pF) over 1.25 mm mechanical propagation length, delivering 13.4 V open-circuit voltage and 44.4 mA short-circuit current. We demonstrate isolated gate driving for a gallium nitride (GaN) high-electron-mobility transistor, achieving a turn-on time of 108.8 ns comparable to commercial drivers and validate its operation in a buck converter. In addition, our SAW device operates over an ultrawide temperature range from 0.5 K (-272.6 °C) to 544 K (271 °C). The microwave-frequency SAW devices offer inherent EMI immunity and potential for heterogeneous integration on multiple semiconductor platforms, enabling compact, high-performance isolated power and signal transmission in advanced power electronics.

</details>


### [689] [DataOps-driven CI/CD for analytics repositories](https://arxiv.org/abs/2511.12277)
*Dmytro Valiaiev*

Main category: eess.SY

TL;DR: SQL开发缺乏规范导致数据治理困难，本文提出一种基于DataOps的数据验证框架，通过十二项控制和CI/CD流水线来提升数据质量和可追溯性。


<details>
  <summary>Details</summary>
Motivation: SQL在数据处理中的广泛应用缺乏传统软件开发的严谨性，导致了各自为政、逻辑重复和风险增加，严重阻碍了数据治理和验证。

Method: 提出一个DataOps驱动的验证框架，该框架包含一个源自多方文献综述的DataOps控制评分卡（包含十二项可测试的控制），并将其映射到一个模块化的、可扩展的CI/CD流水线框架（包含Lint, Optimize, Parse, Validate, Observe五个阶段），最后通过需求可追溯性矩阵（RTM）来确保高层控制的具体执行。

Result: 设计了一个包含十二项控制和五阶段CI/CD流水线的DataOps数据验证框架，并用RTM验证了其有效性。

Conclusion: 该框架通过结构化的方法增强了数据质量、治理和协作，使得团队能够透明且可控地扩展分析开发。

Abstract: The proliferation of SQL for data processing has often occurred without the rigor of traditional software development, leading to siloed efforts, logic replication, and increased risk. This ad-hoc approach hampers data governance and makes validation nearly impossible. Organizations are adopting DataOps, a methodology combining Agile, Lean, and DevOps principles to address these challenges to treat analytics pipelines as production systems. However, a standardized framework for implementing DataOps is lacking. This perspective proposes a qualitative design for a DataOps-aligned validation framework. It introduces a DataOps Controls Scorecard, derived from a multivocal literature review, which distills key concepts into twelve testable controls. These controls are then mapped to a modular, extensible CI/CD pipeline framework designed to govern a single source of truth (SOT) SQL repository. The framework consists of five stages: Lint, Optimize, Parse, Validate, and Observe, each containing specific, automated checks. A Requirements Traceability Matrix (RTM) demonstrates how each high-level control is enforced by concrete pipeline checks, ensuring qualitative completeness. This approach provides a structured mechanism for enhancing data quality, governance, and collaboration, allowing teams to scale analytics development with transparency and control.

</details>


### [690] [Target Defense against Sequentially Arriving Intruders: Algorithm for Agents with Dubins Dynamics](https://arxiv.org/abs/2511.12329)
*Arman Pourghorban,Dipankar Maity*

Main category: eess.SY

TL;DR: 在此论文中，我们研究了一种目标防御问题变体，其中一名防御者需要拦截一系列入侵者。防御者和入侵者都具有非完整动力学。入侵者的目标是在不被防御者捕获的情况下突破目标区域，而防御者的目标是尽可能多地捕获入侵者。在一个入侵者被捕获或突破后，下一个入侵者会在一个固定的圆圈上随机出现。我们根据玩家获得的信息将入侵者-防御者交互分为部分信息和完全信息两个阶段。我们使用 Dubins 路径和守护弧的概念来解决入侵者的可捕获性问题。我们量化了有限和无限序列入侵者的捕获率。最后，通过蒙特卡洛类型的随机实验数值示例验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 研究具有非完整动力学的防御者和入侵者之间的目标防御问题，并量化防御者的捕获能力。

Method: 将交互分为部分信息和完全信息两个阶段，并利用 Dubins 路径和守护弧的概念来分析可捕获性。

Result: 量化了有限和无限序列入侵者的捕获率，并通过数值示例进行了验证。

Conclusion: 通过数值示例验证了所提出的方法和理论结果，展示了在不同场景下防御者的捕获能力。

Abstract: We consider a variant of the target defense problem where a single defender is tasked to capture a sequence of incoming intruders. Both the defender and the intruders have non-holonomic dynamics. The intruders' objective is to breach the target perimeter without being captured by the defender, while the defender's goal is to capture as many intruders as possible. After one intruder breaches or is captured, the next appears randomly on a fixed circle surrounding the target. Therefore, the defender's final position in one game becomes its starting position for the next. We divide an intruder-defender engagement into two phases, partial information and full information, depending on the information available to the players. We address the capturability of an intruder by the defender using the notions of Dubins path and guarding arc. We quantify the percentage of capture for both finite and infinite sequences of incoming intruders. Finally, the theoretical results are verified through numerical examples using Monte-Carlo-type random trials of experiments.

</details>


### [691] [DER Day-Ahead Offering: A Neural Network Column-and-Constraint Generation Approach](https://arxiv.org/abs/2511.12384)
*Weiqi Meng,Hongyi Li,Bai Cui*

Main category: eess.SY

TL;DR: 该研究提出了一种两阶段鲁棒自适应随机优化模型来解决分布式能源聚合商日前能量市场的报价问题，该模型能够同时处理日前价格和分布式能源发电的不确定性，并使用神经网络加速的列和约束生成方法来解决复杂的优化问题，在数值研究中显示出比现有方法更高的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 分布式能源聚合商在日前能量市场中，需要在价格和数量不确定性实现之前提交报价，这对他们提出了挑战。

Method: 提出了一种两阶段鲁棒自适应随机优化模型。第一阶段确定报价，第二阶段根据不确定性实现情况做出运行承诺决策。使用随机规划处理日前价格不确定性，使用鲁棒优化处理分布式能源发电不确定性。为解决第二阶段问题的最大最小结构，开发了一种神经网络加速的列和约束生成方法，并训练神经网络来近似价值函数。

Result: 数值研究表明，该方法在1028节点合成配电网络上，与Gurobi和其他经典方法相比，效率提高了100倍和33倍，并能获得高质量的解决方案。

Conclusion: 该研究提出了一种高效且准确的优化模型，能够有效应对日前能量市场中的不确定性，为分布式能源聚合商提供了有效的决策支持。

Abstract: In the day-ahead energy market, the offering strategy of distributed energy resource (DER) aggregators must be submitted before the uncertainty realization in the form of price-quantity pairs. This work addresses the day-ahead offering problem through a two-stage robust adaptive stochastic optimization model, wherein the first-stage price-quantity pairs and second-stage operational commitment decisions are made before and after DER uncertainty is realized, respectively. Uncertainty in day-ahead price is addressed using a stochastic programming, while uncertainty of DER generation is handled through robust optimization. To address the max-min structure of the second-stage problem, a neural network-accelerated column-and-constraint generation method is developed. A dedicated neural network is trained to approximate the value function, while optimality is maintained by the design of the network architecture. Numerical studies indicate that the proposed method yields high-quality solutions and is up to 100 times faster than Gurobi and 33 times faster than classical column-and-constraint generation on the same 1028-node synthetic distribution network.

</details>


### [692] [Online Adaptive Probabilistic Safety Certificate with Language Guidance](https://arxiv.org/abs/2511.12431)
*Zhuoyuan Wang,Xiyu Deng,Hikaru Hoshino,Yorie Nakahira*

Main category: eess.SY

TL;DR: 本研究提出了一种语言引导的自适应概率安全证书（PSC）框架，用于在不确定或极端环境下实现对随机系统的长期安全保证，并能适应人类偏好和风险容忍度的变化。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长期安全保证与快速实时控制之间存在权衡，且无法适应人类偏好或风险容忍度的变化。

Method: 提出了一种语言引导的自适应概率安全证书（PSC）框架，该框架整合了来自用户的自然语言输入和对环境的贝叶斯估计，以生成自适应安全证书。该证书明确考虑了用户偏好、系统动态和量化的不确定性。关键技术创新在于利用概率不变性（probabilistic invariance）——前向不变性（forward invariance）在概率空间上的推广——来获得具有长期安全保证的近视安全条件。

Result: 通过在不确定的极端道路条件下进行带有“人机协同”指导的自主车道保持的数值模拟，验证了该框架的有效性。模拟结果表明，该框架能够提高安全性-性能的权衡，适应变化的环境，并实现个性化以满足不同用户的偏好。

Conclusion: 本研究提出的PSC框架能够有效解决现有方法在长期安全保证、适应人类偏好变化方面的局限性，在复杂环境下为自主系统提供可靠的安全保障。

Abstract: Achieving long-term safety in uncertain or extreme environments while accounting for human preferences remains a fundamental challenge for autonomous systems. Existing methods often trade off long-term guarantees for fast real-time control and cannot adapt to variability in human preferences or risk tolerance. To address these limitations, we propose a language-guided adaptive probabilistic safety certificate (PSC) framework that guarantees long-term safety for stochastic systems under environmental uncertainty while accommodating diverse human preferences. The proposed framework integrates natural-language inputs from users and Bayesian estimators of the environment into adaptive safety certificates that explicitly account for user preferences, system dynamics, and quantified uncertainties. Our key technical innovation leverages probabilistic invariance--a generalization of forward invariance to a probability space--to obtain myopic safety conditions with long-term safety guarantees that integrate language guidance, model information, and quantified uncertainty. We validate the framework through numerical simulations of autonomous lane-keeping with human-in-the-loop guidance under uncertain and extreme road conditions, demonstrating enhanced safety-performance trade-offs, adaptability to changing environments, and personalization to different user preferences.

</details>


### [693] [One Request, Multiple Experts: LLM Orchestrates Domain Specific Models via Adaptive Task Routing](https://arxiv.org/abs/2511.12484)
*Xu Yang,Chenhui Lin,Haotian Liu,Qi Wang,Yue Yang,Wenchuan Wu*

Main category: eess.SY

TL;DR: 本文提出了一种名为ADN-Agent的架构，利用大型语言模型（LLM）来协调多个领域特定模型（DSM），以解决主动配电网（ADN）复杂的多场景、多目标运行问题。该架构能够自适应地识别意图、分解任务和调用DSM，并通过新颖的通信机制统一不同DSM的接口。此外，还提出了一种自动化训练流程来微调小型语言模型，以增强解决语言密集型子任务的能力。实验结果验证了该方法的有效性，并表明ADN-Agent优于现有的LLM应用范式。


<details>
  <summary>Details</summary>
Motivation: 主动配电网（ADN）的运行日益复杂，涉及海量分布式能源和新型市场实体，导致其运行成为一个多场景、多目标问题。尽管存在许多领域特定模型（DSM）来解决具体技术问题，但对这些异构DSM的掌握、集成和协调给ADN运营商带来了巨大的负担。因此，迫切需要一种能够统一DSM并实现高效协调的智能方法。

Method: 提出了一种名为ADN-Agent的架构，该架构利用通用的LLM来协调多个DSM，实现自适应的意图识别、任务分解和DSM调用。在ADN-Agent内部，设计了一种新颖的通信机制，为各种异构DSM提供了一个统一且灵活的接口。最后，针对一些语言密集型的子任务，提出了一种自动化训练流程来微调小型语言模型，以有效提升系统的整体问题解决能力。

Result: 通过全面的比较和消融实验，验证了所提出方法的有效性，并证明ADN-Agent架构在性能上优于现有的LLM应用范式。

Conclusion: ADN-Agent架构通过利用LLM协调异构DSM，能够有效应对ADN复杂的多场景、多目标运行挑战，并优于现有方法。

Abstract: With the integration of massive distributed energy resources and the widespread participation of novel market entities, the operation of active distribution networks (ADNs) is progressively evolving into a complex multi-scenario, multi-objective problem. Although expert engineers have developed numerous domain specific models (DSMs) to address distinct technical problems, mastering, integrating, and orchestrating these heterogeneous DSMs still entail considerable overhead for ADN operators. Therefore, an intelligent approach is urgently required to unify these DSMs and enable efficient coordination. To address this challenge, this paper proposes the ADN-Agent architecture, which leverages a general large language model (LLM) to coordinate multiple DSMs, enabling adaptive intent recognition, task decomposition, and DSM invocation. Within the ADN-Agent, we design a novel communication mechanism that provides a unified and flexible interface for diverse heterogeneous DSMs. Finally, for some language-intensive subtasks, we propose an automated training pipeline for fine-tuning small language models, thereby effectively enhancing the overall problem-solving capability of the system. Comprehensive comparisons and ablation experiments validate the efficacy of the proposed method and demonstrate that the ADN-Agent architecture outperforms existing LLM application paradigms.

</details>


### [694] [Density-Driven Multi-Agent Coordination for Efficient Farm Coverage and Management in Smart Agriculture](https://arxiv.org/abs/2511.12492)
*Sungjun Seo,Kooktae Lee*

Main category: eess.SY

TL;DR: 该研究提出了一种密度驱动最优控制（D2OC）框架，利用最优输运（OT）理论和多无人机协同技术，实现了大规模农业喷洒的智能化、自适应和节能。


<details>
  <summary>Details</summary>
Motivation: 传统农业病虫草害管理方法（如手动检查和农药 blanket 喷洒）效率低下、资源浪费且对环境造成影响。现有无人机（UAV）精准农业方法受电池寿命、载荷和可扩展性限制，在处理大规模农田和考虑实际作业因素（如侵染严重程度、UAV 动力学、资源分配和节能）方面存在不足。

Method: 提出了一种结合最优输运（OT）理论和多无人机协同覆盖控制的密度驱动最优控制（D2OC）框架。该框架能够根据病虫害强度进行非均匀、有优先级的资源分配，并考虑无人机的动力学模型（线性时变系统LTV），通过拉格朗日力学推导出 D2OC 控制律，实现高效协同、负载均衡和任务时长优化。

Result: 仿真结果表明，与均匀喷洒和光谱多尺度覆盖（SMC）方法相比，D2OC 框架在覆盖效率、化学品减量和作业可持续性方面表现更优。

Conclusion: D2OC 框架为智能农业提供了一个可扩展的解决方案，能够有效应对大规模农田的病虫草害管理挑战。

Abstract: The growing scale of modern farms has increased the need for efficient and adaptive multi-agent coverage strategies for pest, weed, and disease management. Traditional methods such as manual inspection and blanket pesticide spraying often lead to excessive chemical use, resource waste, and environmental impact. While unmanned aerial vehicles (UAVs) offer a promising platform for precision agriculture through targeted spraying and improved operational efficiency, existing UAV-based approaches remain limited by battery life, payload capacity, and scalability, especially in large fields where single-UAV or uniformly distributed spraying is insufficient. Although multi-UAV coordination has been explored, many current frameworks still assume uniform spraying and do not account for infestation severity, UAV dynamics, non-uniform resource allocation, or energy-efficient coordination.
  To address these limitations, this paper proposes a Density-Driven Optimal Control (D2OC) framework that integrates Optimal Transport (OT) theory with multi-UAV coverage control for large-scale agricultural spraying. The method supports non-uniform, priority-aware resource allocation based on infestation intensity, reducing unnecessary chemical application. UAVs are modeled as a linear time-varying (LTV) system to capture variations in mass and inertia during spraying missions. The D2OC control law, derived using Lagrangian mechanics, enables efficient coordination, balanced workload distribution, and improved mission duration. Simulation results demonstrate that the proposed approach outperforms uniform spraying and Spectral Multiscale Coverage (SMC) in coverage efficiency, chemical reduction, and operational sustainability, providing a scalable solution for smart agriculture.

</details>


### [695] [On hyperexponential stabilization of a chain of integrators in continuous and discrete time subject to unmatched perturbations](https://arxiv.org/abs/2511.12567)
*Moussa Labbadi,Denis Efimov*

Main category: eess.SY

TL;DR: 该研究提出了一种用于具有不匹配扰动的积分器链的递归时变状态反馈控制器，在连续时间和离散时间下均实现了指数级收敛。


<details>
  <summary>Details</summary>
Motivation: 解决具有不匹配扰动的积分器链的控制问题，并实现状态变量的快速收敛。

Method: 提出一种递归时变状态反馈控制器，并通过饱和控制增益来保证状态的有界性。在离散时间下，采用隐式欧拉离散化来保持收敛性。

Result: 在连续时间下，第一个状态变量实现了超指数级收敛，第二个状态变量保持有界，其他状态变量通过饱和控制增益实现了ISS（输入状态稳定性）性质。在离散时间下，通过隐式欧拉离散化保持了超指数级收敛性。

Conclusion: 所提出的控制器能够有效地处理具有不匹配扰动的积分器链，并在连续时间和离散时间下均实现了期望的收敛性能。

Abstract: A recursive time-varying state feedback is presented for a chain of integrators with unmatched perturbations in continuous and discrete time. In continuous time, it is shown that hyperexponential convergence is achieved for the first state variable \(x_1\), while the second state \(x_2\) remains bounded. For the other states, we establish ISS {\cb property} by saturating the growing {\cb control} gain. In discrete time, we use implicit Euler discretization to {\cb preserve} hyperexponential convergence. The main results are demonstrated through several examples of the proposed control laws, illustrating the conditions established for both continuous and discrete-time systems.

</details>


### [696] [On two-degrees-of-freedom agreement protocols](https://arxiv.org/abs/2511.12632)
*Gal Barkai,Leonid Mirkin,Daniel Zelazo*

Main category: eess.SY

TL;DR: 提出了一种分布式两自由度（2DOF）架构，用于驱动自主异构智能体达成一致。


<details>
  <summary>Details</summary>
Motivation: 为了解决标准扩散耦合无法解决的、驱动智能体达成一致的问题，特别是当存在干扰导致不稳定的一致极点时。

Method: 提出了一种分布式两自由度（2DOF）架构，该架构模仿了经典的伺服结构，将局部反馈与网络滤波分离开来。这种分离允许独立进行网络滤波设计以实现预期的噪声衰减，并允许控制器异构性来抑制局部干扰。

Result: 通过两个数值示例说明了该框架的潜力。

Conclusion: 该分布式2DOF架构能够有效地驱动自主异构智能体达成一致，即使在存在干扰导致不稳定一致极点的情况下也能实现噪声衰减和局部干扰抑制。

Abstract: We propose a distributed two-degrees-of-freedom (2DOF) architecture for driving autonomous, possibly heterogeneous, agents to agreement. The scheme mirrors classical servo structures, separating local feedback from network filtering. This separation enables independent network-filter design for prescribed noise attenuation and allows controller heterogeneity to reject local disturbances, including disturbances exciting unstable agreement poles -- which is known to be impossible via standard diffusive couplings. The potential of the framework is illustrated via two numerical examples.

</details>


### [697] [Visibility-aware Satellite Selection and Resource Allocation in Multi-Orbit LEO Networks](https://arxiv.org/abs/2511.12678)
*Yingzhuo Sun,Yulan Gao,Ming Xiao,Zhu Han,Octavia A. Dobre*

Main category: eess.SY

TL;DR: 本文提出了一种考虑动态可见性的多轨道卫星选择框架，以优化低地球轨道（LEO）卫星通信中的卫星选择、关联控制和资源调度问题。该框架利用马尔可夫近似和匹配博弈论来解决NP难问题，通过交替优化用户关联、带宽分配和功率分配，最终实现了更高的系统和速率。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道（LEO）卫星通信旨在提供全球覆盖，但现有的优化设计未能有效解决多轨道星座中卫星选择、关联控制和资源调度等问题，尤其是在考虑动态可见性方面。

Method: 提出了一种动态可见性感知多轨道卫星选择框架，结合了马尔可夫近似和匹配博弈论。具体来说，将问题建模为组合优化问题，通过块坐标下降法交替求解用户关联、带宽分配和功率分配。

Result: 仿真结果表明，该算法在所有场景下均收敛至次优解，并且与现有算法相比，平均实现了约7.85%的更高和速率。

Conclusion: 所提出的动态可见性感知多轨道卫星选择框架能够有效地优化LEO卫星通信的性能，显著提高系统和速率。

Abstract: Multi orbit low earth orbit (LEO) satellites communication is envisioned as a key infrastructure to deliver global coverage, enabling future services from space air ground integrated networks.However, the optimized design of LEO which jointly addresses satellite selection, association control, and resource scheduling while accounting for dynamic visibility in multi orbit constellations still remains open. Satellites moving along distinct orbital planes yield phase shifted ground tracks and heterogeneous, time varying coverage patterns that significantly complicate the optimization.To bridge the gap, we propose a dynamic visibility aware multi orbit satellite selection framework which can determine the optimal serving satellites across orbital layers. The framework is built upon Markov approximation and matching game theory. Specifically, we formulate a combinatorial optimization problem that maximizes the sum rate under per satellite power budgets. The problem is NP hard , combining discrete user association (UA) decisions with continuous power allocation, and an inherently non convex sum rate maximization objective. We address it through a problem specific Markov approximation. Moreover, we alternately solve UA or bandwidth allocation via a matching game and power allocation via a Lagrangian dual program, which together form a block coordinate descent method tailored to this problem. Simulation results show that the proposed algorithm converges to a suboptimal solution across all scenarios. Extensive experiments against four state of the art baselines further demonstrate that our algorithm achieves, on average, approximately 7.85% higher sum rate than the best performing baseline.

</details>


### [698] [Density-Driven Optimal Control for Non-Uniform Area Coverage in Decentralized Multi-Agent Systems Using Optimal Transport](https://arxiv.org/abs/2511.12756)
*Sungjun Seo,Kooktae Lee*

Main category: eess.SY

TL;DR: 该研究提出了一种名为 D2OC（Density-Driven Optimal Control）的新框架，用于解决多智能体系统中的非均匀区域覆盖问题，并考虑了实际应用中的各种约束。


<details>
  <summary>Details</summary>
Motivation: 现有均匀覆盖策略无法满足现实世界中不同区域需要不同关注度的需求，而现有的非均匀方法缺乏最优性保证或未能考虑智能体动力学、有限操作时间、智能体数量和分布式执行等现实约束。

Method: D2OC 框架结合了最优输运理论和多智能体覆盖控制，使每个智能体能够根据任务特定的参考密度图调整其轨迹。该方法通过解决一个包含物理和操作约束的约束优化问题来确立最优性，并从拉格朗日方程中推导出控制输入，从而得到线性系统的闭式解和非线性系统的通用结构。此外，还开发了一种去中心化的数据共享机制来实现智能体间的协调。

Result: 仿真研究表明，与现有方法相比，D2OC 在非均匀区域覆盖方面取得了显著的性能提升，同时保持了可扩展性和去中心化实施的可行性。

Conclusion: D2OC 框架能够有效地解决多智能体系统中的非均匀区域覆盖问题，并在考虑各种实际约束的情况下提供最优解，同时支持去中心化和可扩展的部署。

Abstract: This paper addresses the fundamental problem of non-uniform area coverage in multi-agent systems, where different regions require varying levels of attention due to mission-dependent priorities. Existing uniform coverage strategies are insufficient for realistic applications, and many non-uniform approaches either lack optimality guarantees or fail to incorporate crucial real-world constraints such as agent dynamics, limited operation time, the number of agents, and decentralized execution.
  To resolve these limitations, we propose a novel framework called Density-Driven Optimal Control (D2OC). The central idea of D2OC is the integration of optimal transport theory with multi-agent coverage control, enabling each agent to continuously adjust its trajectory to match a mission-specific reference density map. The proposed formulation establishes optimality by solving a constrained optimization problem that explicitly incorporates physical and operational constraints. The resulting control input is analytically derived from the Lagrangian of the objective function, yielding closed-form optimal solutions for linear systems and a generalizable structure for nonlinear systems. Furthermore, a decentralized data-sharing mechanism is developed to coordinate agents without reliance on global information.
  Comprehensive simulation studies demonstrate that D2OC achieves significantly improved non-uniform area coverage performance compared to existing methods, while maintaining scalability and decentralized implementability.

</details>


### [699] [On Boundedness of Quadratic Dynamics with Energy-Preserving Nonlinearity](https://arxiv.org/abs/2511.12758)
*Shih-Chi Liao,Maziar S. Hemati,Peter Seiler*

Main category: eess.SY

TL;DR: 虽然充分条件成立，但必要条件在三维系统中失效，表明需要进一步研究来弥合理论差距。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨具有能量守恒非线性的二次动力学系统的有界性。

Method: 利用独立的证明方法，证实了该必要条件对于二维系统成立。但通过构造一个三维反例，证明了该条件在高维空间中不成立。

Result: 二维系统满足该必要条件，但三维系统存在反例。

Conclusion: 该研究揭示了有界性分析中的理论缺口，并为解决保守性问题指明了未来的研究方向。

Abstract: Boundedness is an important property of many physical systems. This includes incompressible fluid flows, which are often modeled by quadratic dynamics with an energy-preserving nonlinearity. For such systems, Schlegel and Noack proposed a sufficient condition for boundedness utilizing quadratic Lyapunov functions. They also propose a necessary condition for boundedness aiming to provide a more complete characterization of boundedness in this class of models. The sufficient condition is based on Lyapunov theory and is true. Our paper focuses on this necessary condition. We use an independent proof to show that the condition is true for two dimensional systems. However, we provide a three dimensional counterexample to illustrate that the necessary condition fails to hold in higher dimensions. Our results highlight a theoretical gap in boundedness analysis and suggest future directions to address the conservatism.

</details>


### [700] [Discrete-Time Stability Analysis of ReLU Feedback Systems via Integral Quadratic Constraints](https://arxiv.org/abs/2511.12826)
*Sahel Vahedi Noori,Bin Hu,Geir Dullerud,Peter Seiler*

Main category: eess.SY

TL;DR: 本论文针对具有ReLU非线性的离散时间反馈系统，利用新的动态积分二次约束（IQCs）和耗散不等式，推导出LMI条件来证明内部稳定性，该方法比现有方法（如Zames-Falb IQCs和静态二次约束）更不保守。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机源于循环神经网络（RNNs）的内部稳定性分析。

Method: 本文首先回顾了现有的用于斜率限制非线性的静态二次约束（QCs）。然后，利用有限脉冲响应滤波器和结构化矩阵，为ReLU推导出了硬积分二次约束（IQCs）。这些IQCs与耗散不等式结合，得到了一个证明内部稳定性的LMI条件。

Result: 数值结果表明，所提出的硬IQCs比Zames-Falb乘数和先前的静态QC方法具有更小的保守性稳定性裕度，有时甚至非常显著。

Conclusion: 本文提出的动态IQCs为ReLU提供了一种比现有方法更精确的内部稳定性分析工具，能够获得更优的稳定性裕度。

Abstract: This paper analyzes internal stability of a discrete-time feedback system with a ReLU nonlinearity. This feedback system is motivated by recurrent neural networks. We first review existing static quadratic constraints (QCs) for slope-restricted nonlinearities. Next, we derive hard integral quadratic constraints (IQCs) for scalar ReLU by using finite impulse filters and structured matrices. These IQCs are combined with a dissipation inequality leading to an LMI condition that certifies internal stability. We show that our new dynamic IQCs for ReLU are a superset of the well-known Zames-Falb IQCs specified for slope-restricted nonlinearities. Numerical results show that the proposed hard IQCs give less conservative stability margins than Zames-Falb multipliers and prior static QC methods, sometimes dramatically so.

</details>


### [701] [Green Emergency Communications in RIS- and MA-Assisted Multi-UAV SAGINs: A Partially Observable Reinforcement Learning Approach](https://arxiv.org/abs/2511.12892)
*Liangshun Wu,Wen Chen,Shunqing Zhang,Yajun Wang,Kunlun Wang*

Main category: eess.SY

TL;DR: 在灾后无人机通信网络中，提出了一种基于时空 A2C 的新方法，以应对通信受限的局部可观测性问题，提高了通信效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在灾后空间-天-地一体化网络（SAGINs）中，地面基础设施往往受损，无人机（UAVs）需要在城市环境中快速恢复通信，但面临通信受限和局部可观测性问题，现有方法难以应对。

Method: 提出一种时空 A2C 方法，通过无人机传输包含局部状态、策略指纹和循环信念的先验决策消息，并结合空间折扣来塑造价值目标，以解决通信受限的局部可观测性问题。

Result: 实验结果表明，该方法优于 IA2C、ConseNet、FPrint、DIAL 和 CommNet 等方法，实现了更快的收敛速度、更高的渐近奖励、更低的 TD/advantage 误差，并改善了通信吞吐量-能量的权衡。

Conclusion: 所提出的时空 A2C 方法能够有效解决灾后 SAGINs 中的通信受限和局部可观测性问题，提高无人机的通信性能和训练稳定性。

Abstract: In post-disaster space-air-ground integrated networks (SAGINs), terrestrial infrastructure is often impaired, and unmanned aerial vehicles (UAVs) must rapidly restore connectivity for mission-critical ground terminals in cluttered non-line-of-sight (NLoS) urban environments. To enhance coverage, UAVs employ movable antennas (MAs), while reconfigurable intelligent surfaces (RISs) on surviving high-rises redirect signals. The key challenge is communication-limited partial observability, leaving each UAV with a narrow, fast-changing neighborhood view that destabilizes value estimation. Existing multi-agent reinforcement learning (MARL) approaches are inadequate--non-communication methods rely on unavailable global critics, heuristic sharing is brittle and redundant, and learnable protocols (e.g., CommNet, DIAL) lose per-neighbor structure and aggravate non-stationarity under tight bandwidth. To address partial observability, we propose a spatiotemporal A2C where each UAV transmits prior-decision messages with local state, a compact policy fingerprint, and a recurrent belief, encoded per neighbor and concatenated. A spatial discount shapes value targets to emphasize local interactions, while analysis under one-hop-per-slot latency explains stable training with delayed views. Experimental results show our policy outperforms IA2C, ConseNet, FPrint, DIAL, and CommNet--achieving faster convergence, higher asymptotic reward, reduced Temporal-Difference(TD)/advantage errors, and a better communication throughput-energy trade-off.

</details>


### [702] [Wide-Area Feedback Control for Renewables-Heavy Power Systems: A Comparative Study of Reinforcement Learning and Lyapunov-Based Design](https://arxiv.org/abs/2511.12911)
*Muhammad Nadeem,MirSaleh Bahavarnia,Ahmad F. Taha*

Main category: eess.SY

TL;DR: 为应对可再生能源发电带来的电网动力学建模复杂性增加的问题，以及实时监测数据日益可用，本文提出了一种从基于模型和Lyapunov的控制器设计转向无模型控制器设计的趋势。文章将强化学习（RL）作为一种关键的无模型控制器设计工具，并将其应用于含大量可再生能源的电力系统，该系统由一组非线性微分代数方程（NDAE）定义。通过RL和基于Lyapunov稳定性理论的模型驱动方法来解决最优反馈控制问题，并对两种方法的优缺点进行了详细分析，以探索数据驱动控制在电网中的应用前景。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源发电的普及，电力系统动力学建模日趋复杂，而实时监测数据日益可用，这促使研究者从传统的基于模型和Lyapunov的控制器设计方法转向无模型方法，特别是利用强化学习（RL）来设计控制器。

Method: 本文提出将强化学习（RL）作为一种完全无模型的设计方法，并与基于Lyapunov稳定性理论的模型驱动方法相结合，来解决含大量可再生能源的电力系统（由一组非线性微分代数方程（NDAE）定义）的最优反馈控制问题。

Result: 文章通过理论推导和详尽的案例研究，对RL（数据驱动）和Lyapunov理论（模型驱动）两种方法在含大量可再生能源的电网中的应用进行了探索和比较。

Conclusion: 文章旨在探讨数据驱动的反馈控制（如RL）是否应在电网中优先于其模型驱动的对应物，并对两种方法在可再生能源占比高的电网中的优势和劣势进行了详细分析。

Abstract: As renewable energy sources become more prevalent, accurately modeling power grid dynamics is becoming increasingly more complex. Concurrently, data acquisition and realtime system state monitoring are becoming more available for control centers. This motivates shifting from \textit{model- and Lyapunov-based} feedback controller designs toward \textit{model-free} ones. Reinforcement learning (RL) has emerged as a key tool for designing model-free controllers. Various studies have been carried out to study voltage/frequency control strategies via RL. However, usually a simplified system model is used neglecting detailed dynamics of solar, wind, and composite loads -- and damping system-wide oscillations and modeling power flows are all usually ignored. To that end, we pose an optimal feedback control problem for a detailed renewables-heavy power system, defined by a set of nonlinear differential algebraic equations (NDAE). The control problem is solved using a completely model-free design via RL as well as using a model-based approach built upon the Lyapunov stability theory with guarantees. The paper in its essence seeks to explore whether data-driven feedback control should be used in power grids over its model-driven counterpart. Theoretical developments and thorough case studies are presented with an eye on this exploration. Finally, a detailed analysis is provided to delineate the strengths and weaknesses of both approaches for renewables-heavy grids.

</details>


### [703] [Cooperative ISAC for LAE: Joint Trajectory Planning, Power allocation, and Dynamic Time Division](https://arxiv.org/abs/2511.13006)
*Fangzhi Li,Zhichu Ren,Cunhua Pan,Hong Ren,Jing Jin,Qixing Wang,Jiangzhou Wang*

Main category: eess.SY

TL;DR: 该论文提出了一种集成传感与通信（ISAC）框架，用于多无人机系统，以提高空地网络的性能。通过优化无人机轨迹、通信与传感功率分配以及动态时分比率，在满足总传感互信息要求的同时，最大化通信速率。


<details>
  <summary>Details</summary>
Motivation: 为了增强空地网络的性能，并解决多无人机系统中通信与传感的权衡问题。

Method: 提出了一种集成传感与通信（ISAC）框架，采用交替优化（AO）方法来解决联合优化无人机轨迹、通信与传感功率分配以及动态时分比率的非凸优化问题。

Result: 仿真结果表明，所提出的联合设计显著优于具有静态或部分优化资源的基准方案，并揭示了动态轨迹和资源管理在应对传感-通信权衡中的关键作用。

Conclusion: 动态轨迹和资源管理对于有效应对传感-通信权衡至关重要，尤其是在严格的功率或传感约束下。

Abstract: To enhance the performance of aerial-ground networks, this paper proposes an integrated sensing and communication (ISAC) framework for multi-UAV systems. In our model, ground base stations (BSs) cooperatively serve multiple unmanned aerial vehicles (UAVs), and employ a time-division strategy in which beam scanning for sensing comes before data communication in each time slot. To maximize the sum communication rate while satisfying the total sensing mutual information (MI) requirement, we jointly optimize the UAV trajectories, communication and sensing power allocation, and the dynamic time-division ratio. The resulting non-convex optimization problem is efficiently solved using an alternating optimization (AO) framework. Simulation results demonstrate that our proposed joint design significantly outperforms benchmark schemes with static or partially optimized resources. The findings also reveal the critical importance of dynamic trajectory and resource management for effectively navigating the sensing-communication trade-off, especially under stringent power or sensing constraints.

</details>


### [704] [An Online Multiobjective Policy Gradient for Long-run Average-reward Markov Decision Process](https://arxiv.org/abs/2511.13034)
*Rahul Misra,Manuela L. Bujorianu,Rafał Wisniewski*

Main category: eess.SY

TL;DR: 该研究提出了一种基于强化学习（RL）的多目标决策框架，旨在优化奖励向量而非单一标量值，并确保时间平均奖励向量渐近收敛到预定目标集。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习算法主要针对标量奖励进行优化，无法直接处理多目标决策问题，因此需要一种新的方法来处理奖励向量的优化。

Method: 提出了一种动态标量化机制，该机制以Blackwell的方法可达性定理为指导，能够自适应地更新标量化向量，以保证收敛到目标集。该算法利用平稳分布的性质，通过策略梯度方法和标量化向量的迭代更新，确保长期平均奖励向量收敛到目标集。

Result: 理论上证明了该框架能够实现长期平均奖励向量向目标集的收敛，并通过数值算例进行了验证。

Conclusion: 所提出的强化学习框架能够有效地处理多目标决策问题，并通过动态标量化机制和策略梯度方法的结合，实现了奖励向量向目标集的渐近收敛。

Abstract: We propose a reinforcement learning (RL) framework for multi-objective decision-making, where the agent seeks to optimize a vector of rewards rather than a single scalar value. The objective is to ensure that the time-averaged reward vector converges asymptotically to a predefined target set. Since standard RL algorithms operate on scalar rewards, we introduce a dynamic scalarization mechanism guided by Blackwell's Approachability Theorem. This theorem enables adaptive updates of the scalarization vector to guarantee convergence toward the target set. Assuming ergodicity, the Markov chain induced by the learned policies admits a stationary distribution, ensuring all states recur with finite return times. Our algorithm exploits this property by defining an inner loop that applies a policy gradient method (with baseline) between successive visits to a designated recurrent state, enforcing Blackwell's condition at each iteration. An outer loop then updates the scalarization vector after each recurrence. We establish theoretical convergence of the long-run average reward vector to the target set and validate the approach through a numerical example.

</details>


### [705] [A Comprehensive Review of Advancements in Powering and Charging Systems for Unmanned Aerial Vehicles](https://arxiv.org/abs/2511.13122)
*Harsh Abhinandan,Aditya Dhanraj,Aryan Katoch,R. Raja Singh*

Main category: eess.SY

TL;DR: 无人机应用广泛但受限于续航，本文综述了无人机的能源和充电技术。


<details>
  <summary>Details</summary>
Motivation: 无人机因其有限的续航能力，需要新的能源和充电策略来实现更长的自主飞行。

Method: 本文综述了无人机的能源（电池、燃料电池、混合系统）和充电技术（手动更换电池、自动对接站、无线充电（近场和远场）），并讨论了相关的电力电子转换器拓扑、电池管理系统和控制方法。

Result: 文章分析了不同能源的优缺点，并探讨了多种充电方式，特别是无线充电技术，同时涉及了相关的电力电子技术和控制策略。

Conclusion: 无人机能源和充电技术面临技术、经济和社会方面的挑战，但仍有广阔的研究前景，本文为相关领域的研究者、工程师和政策制定者提供了参考。

Abstract: Unmanned Aerial Vehicles (UAVs) or drones have witnessed a spectacular surge in applications for military, commercial, and civilian purposes. However, their potential for flight is always limited by the finite power budget of their onboard power supplies. The limited flight time problem has led to intensive research into new sources of power and innovative charging strategies to enable protracted, autonomous flight. This paper gives a comparative summary of the current state-of-the-art in UAV power and refuelling technology. The paper begins with an analysis of the variety of energy sources, from classical batteries to fuel cells and hybrid systems, based on their relative advantages and disadvantages in energy density, weight, and safety. Subsequently, the review explores a spectrum of replenishment options, from simple manual battery swapping to sophisticated high-tech automatic docking stations and smart contact-based charging pads. Most of the review is dedicated to the newer technology of wireless power transfer, which involves near-field (inductive, capacitive) and far-field (laser, microwave) technology. The article also delves into the most important power electronic converter topologies, battery management systems, and control approaches that form the core of these charging systems. Finally, it recapitulates the most significant challenges in technical, economic, and social aspects for promising avenues of future research. The comprehensive review is a valuable guide for researchers, engineers, and policymakers striving to enhance UAV operational performance.

</details>


### [706] [Initial Excitation-based Adaptive Observers for Discrete-Time LTI Systems](https://arxiv.org/abs/2511.13117)
*Anchita Dey,Soutrik Bandyopadhyay,Shubhendu Bhasin*

Main category: eess.SY

TL;DR: 本文提出了一种基于初始激励的离散时间自适应观测器，用于解决实际应用中状态和参数估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 实际应用中，控制算法的有效性依赖于对系统参数和状态的准确了解，但这些信息通常难以获得。自适应观测器通过仅使用输入输出测量来进行同步状态和参数估计来解决此问题。

Method: 提出了一种基于初始激励（IE）的离散时间自适应观测器，采用两层滤波结构和基于归一化梯度下降的学习律来更新未知参数，并修改回归量以加快收敛速度。

Result: 理论分析保证了在IE条件下，状态和参数估计的有界性和指数收敛性，仿真结果验证了所提出设计的有效性。

Conclusion: 与依赖持续激励和无限控制输入的传统方法相比，该方法不需要无限时间的激励，因此在稳定化任务中更具实用性。

Abstract: In practical applications, the efficacy of a control algorithm relies critically on the accurate knowledge of the parameters and states of the underlying system. However, obtaining these quantities in practice is often challenging. Adaptive observers address this issue by performing simultaneous state and parameter estimation using only input-output measurements. While many adaptive observer designs exist for continuous-time systems, their discrete-time counterparts remain relatively unexplored. This paper proposes an initial excitation (IE)-based adaptive observer for discrete-time linear time-invariant systems. In contrast to conventional designs that rely on the persistence of excitation condition, which requires continuous excitation and infinite control effort, the proposed method does not require excitation for infinite time, thus making it more practical for stabilization tasks. We employ a two-layer filtering structure and a normalized gradient descent-based update law for learning the unknown parameters. We also propose modifying the regressors to enhance information extraction, leading to faster convergence. Rigorous theoretical analysis guarantees bounded and exponentially converging estimates of both states and parameters under the IE condition, and simulation results validate the efficacy of the proposed design.

</details>


### [707] [Carbon Reduction Potential and Sensitivity Analysis of Rural Integrated Energy System with Carbon Trading and Coordinated Electric-Thermal Demand Response](https://arxiv.org/abs/2511.13119)
*Xuxin Yang,Xue Yuan,Donghan Feng,Siru Chen,Yuanhao Feng*

Main category: eess.SY

TL;DR: 本研究提出了一种结合宏观和微观分析的方法来优化农村综合能源系统（RIES）的低碳运行，以解决现有研究中忽视需求侧灵活性和外部碳交易机制协同减排效应的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的农村综合能源系统（RIES）脱碳研究主要集中在宏观层面的系统设备优化运行，未能充分考虑需求侧柔性负荷和外部碳交易机制的协同减排效应，并且对微观层面设备参数的碳敏感性及其减排潜力研究不足。

Method: 本研究融合了宏观和微观层面的分析。在宏观层面，开发了一个多能源耦合的低碳最优运行框架，整合了协调的电热需求响应（DR）和碳交易。在微观层面，建立了RIES组件的碳排放模型，并对28个碳相关参数进行了敏感性分析，以识别减排效果的关键决定因素。

Result: 基于中国北方某农村地区的典型运行数据进行的案例研究表明，协调的电热需求响应（DR）和碳交易可以实现最大的减排潜力。此外，识别出的高敏感性参数为增强RIES的脱碳潜力提供了重要的理论指导。

Conclusion: 通过整合宏观（需求响应和碳交易）和微观（碳排放模型和敏感性分析）层面的方法，本研究为实现农村综合能源系统的低碳运行提供了有效的解决方案，并指出了关键的优化方向。

Abstract: Constructing clean and low-carbon rural integrated energy system (RIES) is a fundamental requirement for supporting China's rural modernization and new-type urbanization. Existing research on RIES decarbonization primarily focuses on the optimal low-carbon operation of system-level energy devices at the macro level, while the synergistic carbon-reduction effects of demand-side flexible loads and external carbon trading mechanisms have not been fully explored. Meanwhile, at the micro level, the carbon sensitivity of device parameters and their potential contribution to emission reduction remain insufficiently investigated. To address these gaps, this study integrates macro- and micro-level analyses. At the macro level, a multi-energy-coupled low-carbon optimal operation framework is developed, incorporating coordinated electric-thermal demand response (DR) and carbon trading. At the micro level, a carbon emission model for RIES components is established, and sensitivity analysis is conducted on 28 carbon-related parameters to identify highly sensitive determinants of emission reduction. Case studies based on typical operation data from a rural region in northern China demonstrate that coordinated electric-thermal DR and carbon trading can achieve maximum carbon-reduction potential. Furthermore, the identified high-sensitivity parameters provide essential theoretical guidance for enhancing the decarbonization potential of RIES.

</details>


### [708] [Cyber-Resilient Fault Diagnosis Methodology in Inverter-Based Resource-Dominated Microgrids with Single-Point Measurement](https://arxiv.org/abs/2511.13162)
*Yifan Wang,Yiyao Yu,Yang Xia,Yan Xu*

Main category: eess.SY

TL;DR: 该研究提出了一种名为FO-MADS的新型分数阶记忆增强攻击诊断方案，仅需一个电压、有功功率和无功功率（VPQ）测量点，即可实现对逆变器主导的微电网（IBR-dominated microgrids）的网络攻击进行实时定位和诊断，提高了系统的网络物理弹性。


<details>
  <summary>Details</summary>
Motivation: 现有的微电网网络攻击诊断方法要么需要昂贵的仪器设备，要么依赖于严格但不可行的模型假设。本研究旨在提出一种仅需单点测量即可有效诊断网络攻击的方法。

Method: 提出了一种分数阶记忆增强攻击诊断方案（FO-MADS），该方案首先利用Caputo和Grünwald-Letnikov导数构建双分数阶特征库，放大VPQ信号的微小扰动和缓慢漂移。然后，采用两阶段分层分类器来定位受影响的逆变器并隔离故障的IGBT开关。此外，通过渐进式记忆回放对抗训练（PMR-AT）增强鲁棒性，并利用在线硬样本挖掘（OHEM）动态重加权攻击感知损失，优先处理最困难的样本。

Result: 在包含1个正常和24个故障类别、四种攻击场景的四逆变器IBR主导微电网测试台上进行实验，在偏置、噪声、数据替换和重放攻击下的诊断准确率分别为96.6%、94.0%、92.8%和95.7%，在无攻击条件下的准确率为96.7%。

Conclusion: FO-MADS是一种经济高效且易于部署的解决方案，可显著增强IBR主导微电网的网络物理弹性。

Abstract: Cyber-attacks jeopardize the safe operation of inverter-based resource-dominated microgrids (IBR-dominated microgrids). At the same time, existing diagnostic methods either depend on expensive multi-point instrumentation or stringent modeling assumptions that are untenable under single-point measurement constraints. This paper proposes a Fractional-Order Memory-Enhanced Attack-Diagnosis Scheme (FO-MADS) that achieves timely fault localization and cyber-resilient fault diagnosis using only one VPQ (voltage, active power, reactive power) measurement point. FO-MADS first constructs a dual fractional-order feature library by jointly applying Caputo and Grünwald-Letnikov derivatives, thereby amplifying micro-perturbations and slow drifts in the VPQ signal. A two-stage hierarchical classifier then pinpoints the affected inverter and isolates the faulty IGBT switch, effectively alleviating class imbalance. Robustness is further strengthened through Progressive Memory-Replay Adversarial Training (PMR-AT), whose attack-aware loss is dynamically re-weighted via Online Hard Example Mining (OHEM) to prioritize the most challenging samples. Experiments on a four-inverter IBR-dominated microgrid testbed comprising 1 normal and 24 fault classes under four attack scenarios demonstrate diagnostic accuracies of 96.6% (bias), 94.0% (noise), 92.8% (data replacement), and 95.7% (replay), while sustaining 96.7% under attack-free conditions. These results establish FO-MADS as a cost-effective and readily deployable solution that markedly enhances the cyber-physical resilience of IBR-dominated microgrids.

</details>


### [709] [Event-Triggered Regulation of Mixed-Autonomy Traffic Under Varying Traffic Conditions](https://arxiv.org/abs/2511.13206)
*Yihuai Zhang,Huan Yu*

Main category: eess.SY

TL;DR: 本文提出了一种基于事件触发控制（ETC）的框架，用于缓解由人类驾驶车辆（HVs）和自动驾驶车辆（AVs）组成的混合交通系统中的交通拥堵。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶技术的发展，混合自主交通系统的建模和拥堵缓解变得越来越重要。

Method: 该框架使用扩展的Aw-Rascle-Zhang（ARZ）模型（耦合的4x4双曲偏微分方程）进行建模，并采用匝道计量作为边界驱动机制。基于反步法设计了ETC策略，并结合了基于观测器的ETC来实现实际应用，以减少计算和通信负担，并避免过度的匝道信号变化。

Result: 通过Lyapunov分析确保了指数收敛和避免了芝诺行为。仿真结果表明，ETC能够稳定混合交通流，显著减少控制更新次数，提高驾驶员舒适度和道路安全。AVs的渗透率越高，释放时间和触发事件越少，表明AVs在缓解交通拥堵和减少计算资源使用方面的积极作用。与连续反步控制器相比，ETC在接近的稳定性能下实现了更少的控制器更新次数和更长的信号释放时间。

Conclusion: 所提出的ETC方法在混合交通管理中具有巨大潜力，能够有效缓解交通拥堵，同时减少计算和通信负担，并提高安全性和驾驶员舒适度。

Abstract: Modeling and congestion mitigation of mixed-autonomy traffic systems consisting of human-driven vehicles (HVs) and autonomous vehicles (AVs) have become increasingly critical with the rapid development of autonomous driving technology. This paper develops an event-triggered control (ETC) framework for mitigating congestion in such systems, which are modeled using an extended Aw-Rascle-Zhang (ARZ) formulation consisting of coupled 4 x 4 hyperbolic partial differential equations (PDEs). Ramp metering is employed as the boundary actuation mechanism. To reduce computational and communication burdens while avoiding excessive ramp signal changes, we design the ETC strategy based on the backstepping method, together with an observer-based ETC formulation for practical implementation under limited sensing. Rigorous Lyapunov analysis ensures exponential convergence and avoidance of Zeno behavior. Extensive simulations validate the proposed approach under diverse traffic scenarios, including varying AV penetration rates, different spacing policies, multiple demand levels, and non-recurrent congestion patterns. Results show that ETC not only stabilizes mixed traffic flows but also significantly reduces control updates, improving driver comfort, and roadway safety. Higher AV penetration rates lead to longer release time and fewer triggering events, indicating the positive impact of AVs in mitigating traffic congestion while reducing computational resource usage. Compared to continuous backstepping controllers, the proposed ETC achieves near-equivalent stabilization performance with far fewer controller updates, resulting in longer signal release time that reduces driver distraction, which demonstrates great potential for ETC applications in traffic management.

</details>


### [710] [Robust Control Design Using a Hybrid-Gain Finite-Time Sliding-Mode Controller](https://arxiv.org/abs/2511.13260)
*Amit Shivam,Kiran Kumari,Fernando A. C. C. Fontes*

Main category: eess.SY

TL;DR: 该研究提出了一种混合增益有限时间滑模控制（HG-FTSMC）策略，用于解决一类受扰动的非线性系统。


<details>
  <summary>Details</summary>
Motivation: 为了在有限时间内解决受扰动的非线性系统控制问题，并在此过程中限制控制器的输出。

Method: 该控制器结合了有限时间趋近律和内部混合功率/指数律。趋近律将滑动变量驱动到预定义边界层，而内部律则确保在边界层内快速收敛，并保持控制动作的平滑和有界。

Result: 该控制器在扰动的单积分器模型和欧拉-拉格朗日（EL）系统上进行了分析。与现有方法相比，该控制器实现了可比的收敛时间，同时显著减少了控制输出。在双连杆机械臂上的轨迹跟踪仿真进一步验证了其鲁棒性和实际可行性。

Conclusion: 所提出的HG-FTSMC策略能够实现有限时间收敛和对匹配干扰的鲁棒性，同时有效限制了控制器的输出，并在机器人和机械系统等实际应用中具有可行性。

Abstract: This paper proposes a hybrid-gain finite-time sliding-mode control (HG-FTSMC) strategy for a class of perturbed nonlinear systems. The controller combines a finite-time reaching law that drives the sliding variable to a predefined boundary layer with an inner mixed-power or exponential law that guarantees rapid convergence within the layer while maintaining smooth and bounded control action. The resulting control design achieves finite-time convergence and robustness to matched disturbances, while explicitly limits the control effort. The control framework is first analyzed on a perturbed first-order integrator model, and then extended to Euler-Lagrange (EL) systems, representing a broad class of robotic and mechanical systems. Comparative simulations demonstrate that the proposed controller achieves settling times comparable to recent finite-time approaches [1], while substantially reducing the control effort. Finally, trajectory-tracking simulations on a two-link manipulator further validate the robustness and practical feasibility of the proposed HG-FTSMC approach.

</details>


### [711] [Beyond Energy Functions and Numerical Integration: A New Methodology to Determine Transient Stability at the Initial State](https://arxiv.org/abs/2511.13289)
*Wenhao Wu,Dan Wu,Bin Wang,Jiabing Hu*

Main category: eess.SY

TL;DR: 该研究提出了一种新的暂态稳定分析（TSA）方法，通过构建依赖于轨迹的稳定性指标函数，并应用时间收缩映射，将TSA转化为极点配置检测问题。该方法利用初始状态的高阶导数进行有理函数逼近，从而直接且高效地预测系统的暂态稳定性，并在基准系统上进行了数值验证。


<details>
  <summary>Details</summary>
Motivation: 现有的暂态稳定分析（TSA）方法存在顺序数值积分和能量函数法的局限性，本研究旨在提出一种新的方法来克服这些限制。

Method: 首先构建依赖于轨迹的稳定性指标函数来区分系统的状态。然后应用时间收缩映射来分析无限时间时的渐进行为。最后，将TSA重新构建为指标函数的极点配置检测问题，并通过利用初始状态的高阶导数得到有理函数逼近。

Result: 数值验证表明，该方法不仅为电力系统中的TSA提供了一个直接的数学捷径，而且为评估广泛的非线性动力系统的暂态稳定性建立了一种新的有前景的方法论。

Conclusion: 本研究提出了一种新颖的暂态稳定分析方法，该方法通过构建稳定性指标函数和应用时间收缩映射，将TSA转化为极点配置检测问题，并实现了高效的数学预测。该方法在基准系统上得到了验证，证明了其有效性，并为非线性动力系统的暂态稳定性评估提供了新的途径。

Abstract: This paper presents a novel method for transient stability analysis (TSA) that circumvents the limitations of sequential numerical integration and energy functions. The proposed method begins by constructing a trajectory-dependent stability indicator function to distinguish the system's destiny. To overcome the difficulty in analyzing the asymptotic behavior at infinite time, a strategic time contraction mapping is then applied. This allows TSA to be recast as a pole-placement detection problem for the indicator function. By leveraging high-order derivatives at the initial state, a rational function approximation is derived, yielding a mathematically direct and computationally efficient prediction. Numerical validations on benchmark systems demonstrate that the method not only provides a direct mathematical shortcut for TSA in power systems but also establishes a promising new methodology for evaluating the transient stability of a broad class of nonlinear dynamical systems.

</details>


### [712] [Event-triggered Dual Gradient Tracking for Distributed Resource Allocation](https://arxiv.org/abs/2511.13362)
*Xiayan Xu,Xiaomeng Chen,Dawei Shi,Ling Shi*

Main category: eess.SY

TL;DR: 提出了一种新颖的事件触发式对偶梯度跟踪算法，以降低分布式资源分配中通信成本，特别是在不平衡有向网络中。


<details>
  <summary>Details</summary>
Motivation: 高通信成本是分布式资源分配在不平衡有向网络中的主要瓶颈。传统方法通信开销大。

Method: 提出一种事件触发式对偶梯度跟踪算法，只有当局部状态偏差超过预定阈值时，代理才会通信。推导了该算法的收敛性。

Result: 证明了该算法对于非凸对偶目标具有次线性收敛性，对于满足Polyak-Łojasiewicz条件的函数具有线性收敛性。对于一般强凸代价函数，证明了次线性收敛性，对于满足Lipschitz光滑条件的强凸函数，证明了线性收敛性。数值实验表明，与周期性方法相比，该方法显著减少了通信事件，同时保持了可比的收敛性能。

Conclusion: 事件触发式算法在显著降低通信成本的同时，能够保持与传统周期性方法相当的收敛性能。

Abstract: High communication costs create a major bottleneck for distributed resource allocation over unbalanced directed networks. Conventional dual gradient tracking methods, while effective for problems on unbalanced digraphs, rely on periodic communication that creates significant overhead in resource-constrained networks. This paper introduces a novel event-triggered dual gradient tracking algorithm to mitigate this limitation, wherein agents communicate only when local state deviations surpass a predefined threshold. We establish comprehensive convergence guarantees for this approach. First, we prove sublinear convergence for non-convex dual objectives and linear convergence under the Polyak-Łojasiewicz condition. Building on this, we demonstrate that the proposed algorithm achieves sublinear convergence for general strongly convex cost functions and linear convergence for those that are also Lipschitz-smooth. Numerical experiments confirm that our event-triggered method significantly reduces communication events compared to periodic schemes while preserving comparable convergence performance.

</details>


### [713] [High-resolution hierarchical PV system performance modeling in urban environments](https://arxiv.org/abs/2511.13424)
*Bowen Tian,Roel C. G. M. Loonen,Roland M. E. Valckenborg,Jan L. M. Hensen*

Main category: eess.SY

TL;DR: 该研究提出了一种高分辨率、分层建模框架，用于精确模拟城市环境中具有复杂局部遮挡问题的光伏系统性能。


<details>
  <summary>Details</summary>
Motivation: 城市环境中光伏系统性能建模面临局部遮挡问题的严峻挑战。

Method: 开发了一个从太阳能电池到系统级别的高分辨率、分层建模框架，并使用现场测试数据进行了严格验证。

Result: 该模型能够高精度地预测分钟级动态电特性（R2 > 0.90），并准确量化失配损耗和旁路二极管激活等时变现象。与传统模型相比，该模型在遮挡条件下避免了高达163%的功率和54%的月度能量产量估算误差。此外，研究表明组件级电力电子设备（MLPEs）可将重度遮挡组串的月度能量产量提高20%以上。

Conclusion: 该研究提供了一个可靠的工具，用于城市环境中光伏系统的可靠设计、精确的功率预测和优化。

Abstract: Accurate performance modeling of PV systems in urban environments is a significant challenge due to complex partial shading. This study introduces a high-resolution, hierarchical modeling framework that provides detailed insights from the solar cell to the system level. Rigorously validated against field-test data from calibrated equipment, the model demonstrates high accuracy in predicting minute-wised dynamic electrical characteristics (R2 > 0.90). A key finding is the critical shortcoming of conventional, coarser-resolution models under realistic shading; these are shown to overestimate the actual string operating power by up to 163% and the monthly energy yield by up to 54%. The proposed framework avoids these errors by precisely capturing mismatch losses and the time-varying phenomena of system components, such as bypass diode activations. Furthermore, the model accurately quantifies the effectiveness of mitigation technologies, showing that Module-Level Power Electronics (MLPEs) can increase the monthly energy yield of a heavily shaded string by over 20%. This research provides a crucial tool for reliable system design, accurate power forecasting, and the optimization of PV systems in complex urban settings.

</details>


### [714] [Handover-Aware URLLC UAV Trajectory Planning: A Continuous-Time Trajectory Optimization via Graphs of Convex Sets](https://arxiv.org/abs/2511.13429)
*Yuqi Ping,Tingting Zhang,Tianhao Liang*

Main category: eess.SY

TL;DR: 本文研究了在通信和运动约束下，如何优化无人机（UAV）的飞行轨迹和基站（BS）关联，以最小化切换次数、路径长度和飞行时间，同时保证超可靠低延迟通信（URLLC）。


<details>
  <summary>Details</summary>
Motivation: 无人机长距离飞行中频繁的基站切换会带来延迟和同步开销，需要优化轨迹和基站关联以解决此问题。

Method: 将URLLC需求转化为每个基站的可行飞行区域，并构建包含起点和终点的图。通过Bézier曲线和单调Bézier缩放来参数化轨迹，并引入连续性和速度约束。通过单位流约束确保单路径，并结合二进制边缘选择变量和凸约束得到混合整数凸规划（MICP）。对MICP进行凸松弛和舍入，最后进行精炼以获得平滑、动态可行的轨迹。

Result: 所提出的方法在保证URLLC连通性的同时，实现了切换次数和飞行效率之间的权衡。

Conclusion: 仿真结果验证了该方法能够有效减少无人机的基站切换次数，并提高飞行效率，同时保持通信的可靠性。

Abstract: In this paper, we study a cellular-connected unmanned aerial vehicle (UAV) which aims to fly between two predetermined locations while maintaining ultra-reliable low-latency communications (URLLC) for command-and-control (C2) links with terrestrial base stations (BSs). Long-range flights often trigger frequent inter-cell handovers, which may introduce delays and synchronization overhead. We jointly optimize the continuous trajectory and BS association to minimize handovers, path length, and flying time, subject to communication reliability and kinematic constraints. To address this problem, we reformulate it as an optimization based on the graph of convex sets (GCS). First, the URLLC requirement is translated into spatially feasible regions in the flight plane for each BS. And an intersection graph is constructed including the start and goal points. Each graph node is associated with a smooth and dynamically feasible trajectory segment. The trajectory is parameterized in space by Bézier curves and in time by a monotonic Bézier scaling, together with convex constraints that ensure continuity and enforce speed bounds. Next, we impose unit-flow constraints to enforce a single path, and by coupling the resulting binary edge-selection variables with the convex constraints, we obtain a mixed-integer convex program (MICP). Applying a convex relaxation and rounding to the mixed-integer convex program produces nearly globally optimal routes, and a final refinement yields smooth, dynamically feasible trajectories. Simulations verify that the method preserves URLLC connectivity while achieving a clear trade-off between fewer handovers and flight efficiency.

</details>


### [715] [The Liquid Buffer: Multi-Year Storage for Defossilization and Energy Security under Climate Uncertainty](https://arxiv.org/abs/2511.13513)
*Leonard Göke,Jan Wohland,Stefano Moret,André Bardow*

Main category: eess.SY

TL;DR: 多年代际储能（液态碳氢化合物）是应对净零能源系统气候不确定性、确保能源安全的关键。


<details>
  <summary>Details</summary>
Motivation: 应对净零能源系统中由气候驱动的可再生发电和电力需求的不确定性，以确保能源安全。

Method: 通过引入一个可扩展的随机模型，该模型隐含地考虑了51840个气候年份，识别了液态碳氢化合物的多年代际储能作为一种管理气候不确定性和确保能源安全的关键选择。

Result: 在欧洲，多年代际储能可将系统成本降低4.1%，化石燃料进口减少86%，弃电量减少60%。所需的液态碳氢化合物储能容量为525 TWh，相当于欧盟目前石油和天然气储量的四分之一，另需116 TWh用于储氢。供需保障保持高位，未供应能量仅占0.0035/千，远低于通常的0.02/千目标。

Conclusion: 多年代际储能（液态碳氢化合物）能够有效管理气候不确定性，降低成本，减少对化石燃料的依赖，并确保能源安全，在净零能源系统中具有重要意义。

Abstract: The climate-driven uncertainty of renewable generation and electricity demand challenges energy security in net-zero energy systems. By introducing a scalable stochastic model that implicitly accounts for 51'840 climate years, this paper identifies multi-year storage of liquid hydrocarbons as a key option for managing climate uncertainty and ensuring energy security. In Europe, multi-year storage reduces system costs by 4.1%, fossil imports by 86%, and curtailment by 60%. The benefit of multi-year storage is that a renewable surplus in one year is not curtailed but converted to synthetic oil, with hydrogen as an intermediate product, and stored to balance a future deficit. We find that the required energy capacity for liquid hydrocarbons is 525 TWh, a quarter of the European Union's current oil and gas reserves, complemented by 116 TWh for hydrogen storage. Security of supply remains high and unserved energy only amounts to 0.0035 per thousand, well below the common target of 0.02 per thousand.

</details>


### [716] [On the controller form for linear hyperbolic MIMO systems with dynamic boundary conditions](https://arxiv.org/abs/2511.13546)
*Stefan Ecklebe,Frank Woittennek*

Main category: eess.SY

TL;DR: 本文提出了一种代数方法，用于为一类线性双曲MIMO系统获得控制器形式，该系统在非驱动边界处与线性ODE系统进行双向耦合。


<details>
  <summary>Details</summary>
Motivation: 现有控制器形式（SISO和MIMO ODE以及SISO双曲PDE系统）的局限性促使了对更复杂系统的控制器形式的研究。

Method: 采用基于代数的设置，使用具有实数指数的广义多项式来描述系统的预测和延迟，并提出了一个基于新颖平坦性计算的方案来计算控制器形式。

Result: 所提出的算法已应用于提出的双向耦合MIMO系统示例，并成功计算了其控制器形式。

Conclusion: 本文成功地为一类复杂的线性双曲MIMO系统开发了一种新的代数方法和基于平坦性的计算方案，以获得其控制器形式。

Abstract: This contribution develops an algebraic approach to obtain a controller form for a class of linear hyperbolic MIMO systems, bidirectionally coupled with a linear ODE system at the unactuated boundary. After a short summary of established controller forms for SISO and MIMO ODE as well as SISO hyperbolic PDE systems, it is shown that the direct ap- proach to state a controller form fails already for a very simple MIMO example. Next, a generalised hyperbolic controller form with different variants is proposed and a new flatnesss-based scheme to compute said form is presented. Therein, the system is treated in an algebraic setting where generalised polynomials with real exponents are used to describe the predictions and delays in the system. The proposed algorithm is then applied to the motivating example.

</details>


### [717] [Data-driven Acceleration of MPC with Guarantees](https://arxiv.org/abs/2511.13588)
*Agustin Castellano,Shijie Pan,Enrique Mallada*

Main category: eess.SY

TL;DR: We developed a data-driven framework to speed up Model Predictive Control (MPC) by using a learned policy instead of online optimization, making it much faster for real-time applications while maintaining good performance.


<details>
  <summary>Details</summary>
Motivation: Model Predictive Control (MPC) is computationally expensive and too slow for low-latency applications.

Method: We propose a data-driven framework that replaces online MPC optimization with a nonparametric policy. This policy is derived from offline MPC solutions and uses a greedy approach based on an upper bound of the cost-to-go. It functions as a fast lookup rule.

Result: The proposed policy is significantly faster (100-1000x) than standard MPC, with a small reduction in optimality. It is recursively feasible and has a provable, bounded optimality gap under sufficient data coverage, which allows for a trade-off between data amount and bound tightness.

Conclusion: The data-driven policy accelerates MPC, making it suitable for real-time control tasks by offering a substantial speed improvement with only a minor impact on optimality.

Abstract: Model Predictive Control (MPC) is a powerful framework for optimal control but can be too slow for low-latency applications. We present a data-driven framework to accelerate MPC by replacing online optimization with a nonparametric policy constructed from offline MPC solutions. Our policy is greedy with respect to a constructed upper bound on the optimal cost-to-go, and can be implemented as a nonparametric lookup rule that is orders of magnitude faster than solving MPC online. Our analysis shows that under sufficient coverage condition of the offline data, the policy is recursively feasible and admits provable, bounded optimality gap. These conditions establish an explicit trade-off between the amount of data collected and the tightness of the bounds. Our experiments show that this policy is between 100 and 1000 times faster than standard MPC, with only a modest hit to optimality, showing potential for real-time control tasks.

</details>


### [718] [Physics-Informed Neural Networks for Nonlinear Output Regulation](https://arxiv.org/abs/2511.13595)
*Sebastiano Mengozzi,Giovanni B. Esposito,Michelangelo Bin,Andrea Acquaviva,Andrea Bartolini,Lorenzo Marconi*

Main category: eess.SY

TL;DR: 本文提出一种基于物理信息神经网络（PINN）的方法来求解非线性系统的全信息输出调节问题，通过直接学习零调节误差流形和前馈输入，实现了对外部系统变化的鲁棒性，并在直升机垂直动力学同步任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 解决非线性系统的全信息输出调节问题，即在已知植物和外部系统状态的情况下，实现完美的跟踪或抑制。

Method: 利用物理信息神经网络（PINN）直接逼近零调节误差流形 π(w) 和前馈输入 c(w)，通过最小化残差并满足边界和可行性条件来求解调节方程，无需预计算轨迹或标记数据。

Result: 学习到的算子能够实现实时推理，并能推广到具有不同初始条件和参数的外部系统家族。在直升机垂直动力学同步任务中，PINN求解器高保真地重建了零误差流形，并在外部系统变化下保持了调节性能。

Conclusion: 基于学习的求解器在非线性输出调节问题上展现出巨大潜力，该方法可广泛应用于承认输出调节问题解的非线性系统。

Abstract: This work addresses the full-information output regulation problem for nonlinear systems, assuming the states of both the plant and the exosystem are known. In this setting, perfect tracking or rejection is achieved by constructing a zero-regulation-error manifold π(w) and a feedforward input c(w) that render such manifold invariant. The pair (π(w), c(w)) is characterized by the regulator equations, i.e., a system of PDEs with an algebraic constraint. We focus on accurately solving the regulator equations introducing a physics-informed neural network (PINN) approach that directly approximates π(w) and c(w) by minimizing the residuals under boundary and feasibility conditions, without requiring precomputed trajectories or labeled data. The learned operator maps exosystem states to steady state plant states and inputs, enables real-time inference and, critically, generalizes across families of the exosystem with varying initial conditions and parameters. The framework is validated on a regulation task that synchronizes a helicopter's vertical dynamics with a harmonically oscillating platform. The resulting PINN-based solver reconstructs the zero-error manifold with high fidelity and sustains regulation performance under exosystem variations, highlighting the potential of learning-enabled solvers for nonlinear output regulation. The proposed approach is broadly applicable to nonlinear systems that admit a solution to the output regulation problem.

</details>


### [719] [Scalable Iterative Algorithm for Solving Optimal Transmission Switching with De-energization](https://arxiv.org/abs/2511.13662)
*Benoît Jeanson,Mathieu Tanneau,Simon Tindemans*

Main category: eess.SY

TL;DR: RTE的输电操作背景下，本文提出了最优潮流开关（OTSD）问题，考虑了潮流元件失灵后可能导致的连接丢失（局部停电）情况。该问题因其在实际操作中的相关性而受到关注，但文献研究较少。本文提出了一种新的混合整数线性规划模型，可以在不引入额外二进制变量的情况下，表示事件后的连接丢失情况。在此基础上，提出了一种快速的迭代启发式算法。计算结果表明，使用Gurobi等优化器求解OTSD问题效率低下，而所提出的启发式算法能在更短的时间内找到高质量的可行解，速度提升100-1000倍。


<details>
  <summary>Details</summary>
Motivation: RTE的次级输电操作中，需要考虑潮流元件失灵后可能导致的连接丢失（局部停电）情况，并在此基础上进行最优潮流开关操作。

Method: 提出了一种新的混合整数线性规划模型，用于表示事件后的连接丢失情况，并在此基础上开发了一种快速的迭代启发式算法。

Result: 计算结果表明，所提出的启发式算法在求解OTSD问题方面比现有的优化器（如Gurobi）效率更高，速度提升100-1000倍，并且能找到高质量的可行解。

Conclusion: 所提出的OTSD混合整数线性规划模型和迭代启发式算法能够有效地解决实际输电操作中的最优潮流开关问题，并显著提高了求解效率。

Abstract: Transmission System Operators routinely use transmission switching as a tool to manage congestion and ensure system security. Motivated by sub-transmission operations at RTE, this paper considers the Optimal Transmission Switching with De-energization (OTSD), which captures potential loss of connectivity (and therefore localized blackout) following loss of transmission elements. While directly relevant to real-life operations, this problem has received very little attention in the literature. The paper proposes a new mixed-integer linear programming formulation for OTSD that represents post-contingency loss of connectivity without requiring additional binary variables. This new formulation provides the foundation for a fast, iterative heuristic algorithm. Computational experiments confirms that state-of-the-art optimization solvers struggle to solve the extensive formulation of OTSD, often failing to find even trivial solutions within reasonable time. In contrast, numerical results demonstrate the efficiency of the proposed heuristic, which finds high-quality feasible solutions 100-1000x faster than using Gurobi.

</details>


### [720] [Novel Stability Criteria for Discrete and Hybrid Systems via Ramanujan Inner Products](https://arxiv.org/abs/2511.13690)
*Shyam Kamal,Sunidhi Pandey,Thach Ngoc Dinh*

Main category: eess.SY

TL;DR: 本文提出了一种基于拉马努金内积及其范数的系统稳定性分析新框架，可用于混合和离散时间系统，并提供了比传统欧氏度量更优越的鲁棒性保证。


<details>
  <summary>Details</summary>
Motivation: 为了提供一种替代传统欧氏度量的系统稳定性分析方法，并探索系统稳定性与数论性质之间的联系。

Method: 提出并应用拉马努金内积及其范数来建立新的ε-δ稳定性条件，并利用拉马努金求和及其与数论概念的关系。

Result: 通过理论证明和数值算例仿真，验证了该方法在系统稳定性分析中的有效性，并展示了其增强的鲁棒性保证。

Conclusion: 所提出的基于拉马努金内积的系统稳定性分析方法是有效的，并揭示了系统动力学中的算术性质与系统稳定性之间的深刻联系。

Abstract: This paper introduces a Ramanujan inner product and its corresponding norm, establishing a novel framework for the stability analysis of hybrid and discrete-time systems as an alternative to traditional Euclidean metrics. We establish new $ε$-$δ$ stability conditions that utilize the unique properties of Ramanujan summations and their relationship with number-theoretic concepts. The proposed approach provides enhanced robustness guarantees and reveals fundamental connections between system stability and arithmetic properties of the system dynamics. Theoretical results are rigorously proven, and simulation results on numerical examples are presented to validate the efficacy of the proposed approach.

</details>


### [721] [Resilient Distribution Network Planning against Dynamic Malicious Power Injection Attacks](https://arxiv.org/abs/2511.13698)
*Hampei Sasahara,Tatsuya Yamada,Jun-ichi Imura,Henrik Sandberg*

Main category: eess.SY

TL;DR: 该研究提出了一种基于配电网规划的电网级防御策略，以提高电网抵御网络攻击的能力。该策略将安全需求纳入现有规划方法，确保在面对动态恶意注入功率时，电压偏差保持在可容忍范围内。通过将问题转化为混合整数线性规划，并利用图论和线性动力系统理论，研究发现攻击的严重性仅取决于路径上的累积电抗，从而将问题简化。最终，通过数值模拟验证，该方法在提高电网韧性的同时，经济成本仅略有增加。


<details>
  <summary>Details</summary>
Motivation: 由于集成了多样化的网络组件，支持可再生能源双向电力交换的主动配电网容易受到网络攻击。本研究旨在提高电网抵御网络攻击的能力。

Method: 提出了一种将安全需求纳入现有配电网规划的方法，确保电压偏差在可容忍范围内。通过利用线性动力系统理论和图论，将无限维双层优化问题转化为混合整数线性规划。研究还发现攻击的严重性仅取决于路径上的累积电抗，从而将问题简化。最后，通过最短路径算法技术将双层优化问题简化为单层优化问题。

Result: 通过在 54 节点配电网络基准上的大量数值模拟，所提出的方法在经济成本仅增加 2.1% 的情况下，韧性显著提高了 29.3%。

Conclusion: 所提出的基于配电网规划的电网级防御策略能够有效提高电网抵御网络攻击的能力，并在经济成本可接受的范围内实现了显著的韧性提升。

Abstract: Active distribution networks facilitating bidirectional power exchange with renewable energy resources are susceptible to cyberattacks due to integration of a diverse array of cyber components. This study introduces a grid-level defense strategy aimed at enhancing attack resiliency based on distribution network planning. Our proposed framework imposes a security requirement into existing planning methodologies, ensuring that voltage deviation from its rated value remains within a tolerable range against dynamically and maliciously injected power at end-user nodes. Unfortunately, the formulated problem in its original form is intractable because it is an infinite-dimensional bi-level optimization problem over a function space. To address this complexity, we develop an equivalent transformation into a tractable form as mixed-integer linear program leveraging linear dynamical system theory and graph theory. Notably, our investigation reveals that the severity of potential attacks hinges solely on the cumulative reactances over the path from the substation to the targeted node, thereby reducing the problem to a finite-dimensional problem. Further, the bi-level optimization problem is reduced to a single-level optimization problem by using a technique utilized in solving the shortest path problem. Through extensive numerical simulations conducted on a 54-node distribution network benchmark, our proposed methodology exhibits a noteworthy 29.3% enhancement in the resiliency, with a mere 2.1% uptick in the economic cost.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [722] [Evolution of A4L: A Data Architecture for AI-Augmented Learning](https://arxiv.org/abs/2511.11877)
*Ploy Thajchayapong,Suzanne Carbonaro,Tim Couper,Blaine Helmick,Spencer Rugaber,Ashok Goel*

Main category: cs.ET

TL;DR: A4L2.0是一个利用开放标准实现互联互通的数据管道，用于大规模成人在线教育的个性化学习。


<details>
  <summary>Details</summary>
Motivation: 随着AI在教育中的应用日益加深，对支持个性化学习和提供有价值的学习者洞察的可扩展解决方案的需求不断增长。

Method: A4L2.0利用1EdTech联盟的开放标准（如Edu-API、Caliper Analytics和LTI）来整合来自SIS、LMS和AI工具的数据。数据管道包括数据摄取、预处理、组织、分析和可视化模块。

Result: A4L2.0能够安全、互通地整合来自不同教育系统的数据，支持对在线成人学习者进行数据分析和个性化学习。

Conclusion: A4L2.0通过采用开放标准和模块化的数据管道，为实现大规模成人在线教育的个性化学习提供了一个强大的框架。

Abstract: As artificial intelligence (AI) becomes more deeply integrated into educational ecosystems, the demand for scalable solutions that enable personalized learning continues to grow. These architectures must support continuous data flows that power personalized learning and access to meaningful insights to advance learner success at scale. At the National AI Institute for Adult Learning and Online Education (AI-ALOE), we have developed an Architecture for AI-Augmented Learning (A4L) to support analysis and personalization of online education for adult learners. A4L1.0, an early implementation by Georgia Tech's Design Intelligence Laboratory, demonstrated how the architecture supports analysis of meso- and micro-learning by integrating data from Learning Management Systems (LMS) and AI tools. These pilot studies informed the design of A4L2.0. In this chapter, we describe A4L2.0 that leverages 1EdTech Consortium's open standards such as Edu-API, Caliper Analytics, and Learning Tools Interoperability (LTI) to enable secure, interoperable data integration across data systems like Student Information Systems (SIS), LMS, and AI tools. The A4L2.0 data pipeline includes modules for data ingestion, preprocessing, organization, analytics, and visualization.

</details>


### [723] [QPU Micro-Kernels for Stencil Computation](https://arxiv.org/abs/2511.12617)
*Stefano Markidis,Luca Pennati,Marco Pasquale,Gilbert Netzer,Ivy Peng*

Main category: cs.ET

TL;DR: QPU微内核是一种用于求解偏微分方程的浅层量子电路，它充当采样加速器，将计算任务分解为局部更新，并能有效处理各种科学计算问题。


<details>
  <summary>Details</summary>
Motivation: 为了提高求解偏微分方程（PDE）的效率，提出了一种新的计算范式，即将量子处理单元（QPU）作为采样加速器，用于执行偏微分方程的局部更新。

Method: 提出并实现了两种QPU微内核（Bernoulli和分支），它们能够执行浅层量子电路以获得蒙特卡洛估计。这些微内核被设计为可以直接处理偏微分方程的离散化网格点更新，并且其资源占用与网格大小无关。通过对热方程和粘性Burgers方程的测试，验证了该方法的有效性，并比较了两种微内核的性能。

Result: 在量子电路模拟器上，随着采样数的增加，精度有所提高。在IBM Brisbane量子计算机上，对于单步扩散测试，Bernoulli微内核在相同的采样预算下表现出比分支微内核更低的误差，并且QPU微内核的执行时间占主导地位。

Conclusion: QPU微内核方法为求解偏微分方程提供了一种新颖且有前景的途径，它通过将计算分解为可并行的局部更新，并利用QPU的采样加速能力，在资源效率和求解精度方面都显示出潜力。

Abstract: We introduce QPU micro-kernels: shallow quantum circuits that perform a stencil node update and return a Monte Carlo estimate from repeated measurements. We show how to use them to solve Partial Differential Equations (PDEs) explicitly discretized on a computational stencil. From this point of view, the QPU serves as a sampling accelerator. Each micro-kernel consumes only stencil inputs (neighbor values and coefficients), runs a shallow parameterized circuit, and reports the sample mean of a readout rule. The resource footprint in qubits and depth is fixed and independent of the global grid. This makes micro-kernels easy to orchestrate from a classical host and to parallelize across grid points. We present two realizations. The Bernoulli micro-kernel targets convex-sum stencils by encoding values as single-qubit probabilities with shot allocation proportional to stencil weights. The branching micro-kernel prepares a selector over stencil branches and applies addressed rotations to a single readout qubit. In contrast to monolithic quantum PDE solvers that encode the full space-time problem in one deep circuit, our approach keeps the classical time loop and offloads only local updates. Batching and in-circuit fusion amortize submission and readout overheads. We test and validate the QPU micro-kernel method on two PDEs commonly arising in scientific computing: the Heat and viscous Burgers' equations. On noiseless quantum circuit simulators, accuracy improves as the number of samples increases. On the IBM Brisbane quantum computer, single-step diffusion tests show lower errors for the Bernoulli realization than for branching at equal shot budgets, with QPU micro-kernel execution dominating the wall time.

</details>


### [724] [Segmented Exponent Alignment and Dynamic Wordline Activation for Floating-Point Analog CIM Macros](https://arxiv.org/abs/2511.12624)
*Weiping Yang,Shilin Zhou,Hui Xu,Jiawei Xue,Changlin Chen*

Main category: cs.ET

TL;DR: 通过提出分段指数对齐（SEA）和动态字线激活（DWA）策略，优化了 CIM 加速器中的浮点乘加（FP-MAC）运算，显著降低了功耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 神经元网络中，浮点乘加（FP-MAC）运算因其比整数运算更高的精度而受到关注。然而，指数比较和尾数对齐带来的硬件开销以及位串行输入方法引入的延迟，阻碍了 FP-MAC 的高效实现。

Method: 提出分段指数对齐（SEA）和动态字线激活（DWA）策略。SEA 利用输入指数常聚集在零附近或窄范围内这一特点，通过分割指数空间并相应地对齐尾数，无需最大指数检测，减少输入尾数移位，从而降低处理延迟。DWA 进一步根据 SEA 定义的指数段激活字线，以降低延迟并保持精度。

Result: 与传统的基于比较树的最大指数对齐方法相比，该方法在 VGG16-CIFAR10 基准测试中节省了 63.8% 的功耗，并实现了 40.87% 的延迟降低。

Conclusion: SEA 和 DWA 策略能够高效地实现 CIM 加速器中的 FP-MAC 运算，显著优于现有方法。

Abstract: With the rise of compute-in-memory (CIM) accelerators, floating-point multiply-and-accumulate (FP-MAC) operations have gained extensive attention for their higher accuracy over integer MACs in neural networks. However, the hardware overhead caused by exponent comparison and mantissa alignment, along with the delay introduced by bit-serial input methods, remains a hinder to implement FP-MAC efficiently. In view of this, we propose Segmented Exponent Alignment (SEA) and Dynamic Wordline Activation (DWA) strategies. SEA exploits the observation that input exponents are often clustered around zero or within a narrow range. By segmenting the exponent space and aligning mantissas accordingly, SEA eliminates the need for maximum exponent detection and reduces input mantissa shifting, and thus reduces the processing latency. DWA further reduces latency and maintains accuracy by activating wordlines based on the exponent segments defined by SEA. Simulation results demonstrate that, when compared with conventional comparison tree based maximum exponent alignment method, our approach saves 63.8\% power consumption, and achieves a 40.87\% delay reduction on the VGG16-CIFAR10 benchmark.

</details>


### [725] [PolicyBot - Reliable Question Answering over Policy Documents](https://arxiv.org/abs/2511.13489)
*Gautam Nagarajan,Omir Kumar,Sudarsun Santhiappan*

Main category: cs.ET

TL;DR: PolicyBot是一个检索增强生成（RAG）系统，用于回答关于政策文件的问题，具有透明度和可复用性。它结合了领域特定的语义分块、多语言密集嵌入、多阶段检索与重排以及源感知生成，以提供基于原始文件的答案。通过实现引用追踪来减少幻觉并提高用户信任度。


<details>
  <summary>Details</summary>
Motivation: 法律和政策文件通常冗长、复杂且难以理解，给公民查找和理解相关信息带来了挑战。

Method: 该系统结合了领域特定的语义分块、多语言密集嵌入、多阶段检索与重排以及源感知生成，并实现了引用追踪来减少幻觉并提高用户信任度。

Result: PolicyBot系统能够提供基于原始政策文件的、可追溯的答案，减少了信息检索的难度，并提高了用户信任度。

Conclusion: PolicyBot是一个在治理相关背景下部署可信赖RAG系统的实用解决方案，强调了设计考量、实际挑战和经验教训。

Abstract: All citizens of a country are affected by the laws and policies introduced by their government. These laws and policies serve essential functions for citizens. Such as granting them certain rights or imposing specific obligations. However, these documents are often lengthy, complex, and difficult to navigate, making it challenging for citizens to locate and understand relevant information. This work presents PolicyBot, a retrieval-augmented generation (RAG) system designed to answer user queries over policy documents with a focus on transparency and reproducibility. The system combines domain-specific semantic chunking, multilingual dense embeddings, multi-stage retrieval with reranking, and source-aware generation to provide responses grounded in the original documents. We implemented citation tracing to reduce hallucinations and improve user trust, and evaluated alternative retrieval and generation configurations to identify effective design choices. The end-to-end pipeline is built entirely with open-source tools, enabling easy adaptation to other domains requiring document-grounded question answering. This work highlights design considerations, practical challenges, and lessons learned in deploying trustworthy RAG systems for governance-related contexts.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [726] [Data-Driven Design Rules for TADF Emitters from a High-Throughput Screening of 747 Molecules](https://arxiv.org/abs/2511.11606)
*Jean-Pierre Tchapet Njafa,Elvira Vanelle Kameni Tcheuffa,Aissatou Maghame,Serge Guy Nana Engo*

Main category: physics.app-ph

TL;DR: 通过分析747个已知的TADF分子，我们建立了分子结构、构象和电子结构影响光物理性质的大规模定量设计原则。D-A-D结构在减小单重态-三重态能隙（ΔE_ST）方面表现更优，并且发现50-90度是实现小ΔE_ST和有效反向系间窜越（RISC）的理想扭转角。MR发射体是高效蓝光发射的独特范例。最终，我们提出了可操作的设计规则，并筛选出127个有潜力的候选分子。


<details>
  <summary>Details</summary>
Motivation: 目前，热激活延迟荧光（TADF）发射体的理性设计受到热力学和动力学因素复杂相互作用的阻碍，需要建立大规模、定量的设计原理来解决这一挑战。

Method: 对747个实验上已知的TADF分子进行全面的计算分析，采用经过验证的半经验方案，系统地研究分子结构、构象几何和电子结构如何影响光物理性质。利用数据驱动的聚类进一步识别高性能TADF分子家族，并确认多共振（MR）发射体作为高效蓝光发射的独特范式。

Result: D-A-D结构在减小ΔE_ST方面具有统计学上的优势。确定了50-90度的最佳D-A扭转角窗口，该窗口能在减小ΔE_ST和提高RISC效率之间取得平衡。识别出了一类独特的MR发射体，它们在高效蓝光发射方面表现突出。初步筛选出127个具有ΔE_ST < 0.1 eV和振荡器强度f > 0.1的高优先级候选分子。

Conclusion: 这项工作提供了一个数据驱动的框架，整合了热力学和动力学原理，以加速下一代TADF发射体的发现，并提出了一套可操作的设计规则。

Abstract: The rational design of thermally activated delayed fluorescence (TADF) emitters is hindered by a complex interplay of thermodynamic and kinetic factors. To unravel these relationships, we performed a comprehensive computational analysis of \num{747} experimentally known TADF molecules to establish large-scale, quantitative design principles. Our validated semi-empirical protocol systematically reveals how molecular architecture, conformational geometry, and electronic structure govern photophysical properties. We establish a clear performance hierarchy, with Donor-Acceptor-Donor (D-A-D) architectures being statistically superior for minimizing the singlet-triplet energy gap ($ΔE_{\text{ST}}$). Crucially, we identify an optimal D-A torsional angle window of \qtyrange{50}{90}{\degree} that resolves the key trade-off between a small $ΔE_{\text{ST}}$ and the non-zero spin-orbit coupling (SOC) required for efficient reverse intersystem crossing (RISC). Data-driven clustering further identifies a distinct family of high-performance candidates and confirms Multi-Resonance (MR) emitters as a unique paradigm for high-efficiency blue emission. These findings culminate in a set of actionable design rules and the identification of \num{127} high-priority candidates predicted to have $ΔE_{\text{ST}}< \qty{0.1}{\electronvolt}$ and oscillator strength $f \num{> 0.1}$. This work provides a data-driven framework that unifies thermodynamic and kinetic principles to accelerate the discovery of next-generation TADF emitters.

</details>


### [727] [Phase-field modeling of cyclic behavior in quasi-brittle materials: a micromechanics-based approach](https://arxiv.org/abs/2511.11838)
*Mina Sarem,Nuhamin Eshetu Deresse,Els Verstrynge,Stijn François*

Main category: physics.app-ph

TL;DR: 本文将基于微观力学的相场断裂模型扩展到包含棘轮效应的循环塑性，特别关注低周疲劳下的不均匀应变累积。通过棘轮应变演化来捕捉这种塑性行为，该模型能够独立控制偏应变和体积棘轮分量，并能确保自由能及其导数的光滑演化。数值模拟结果表明，该模型能准确描述单调和循环加载下的材料响应，并评估棘轮效应对材料行为的影响。


<details>
  <summary>Details</summary>
Motivation: 低周疲劳下，棘轮效应（不均匀应变累积）对最终失效过程至关重要，需要新的模型来捕捉这种现象。

Method: 通过棘轮应变演化的方式，将棘轮效应纳入基于微观力学的相场断裂模型。扩展的塑性势能允许独立控制偏应变和体积棘轮分量，以实现自由能及其导数的光滑演化。

Result: 数值模拟结果展示了模型在单调和循环加载下的有效性，并量化了棘轮效应对材料响应的影响。

Conclusion: 所提出的模型能够有效地模拟包含棘轮效应的循环塑性，为理解和预测低周疲劳下的断裂行为提供了新的工具。

Abstract: In this paper, we extend the micromechanics-based phase-field modeling of fatigue fracture to capture cyclic plasticity with ratcheting. This mechanism is particularly important for low-cycle fatigue, where the accumulation of inelastic strains plays an important role in the progression to final failure. The ratcheting contribution is formulated through the evolution of ratcheting strain, which accumulates over loading cycles and captures the inelastic strain growth characteristic of cyclic plasticity in a thermodynamically consistent manner. The extended plastic potential allows independent control over deviatoric and volumetric ratcheting components, ensuring smooth evolution of the free energy and its derivatives. Numerical simulations are performed to evaluate the model under both monotonic and cyclic loading and to assess the influence of ratcheting on material response.

</details>


### [728] [Mechanosensitive polymer matrices of biologically-relevant compliance based on upconverting nanoparticles](https://arxiv.org/abs/2511.11858)
*Cindy H. Shi,Mia C. Cano,Jason R. Casar,Parivash Moradifar,Beatriz G. Robinson,Julia A. Kaltschmidt,Miriam B. Goodman,Jennifer A. Dionne*

Main category: physics.app-ph

TL;DR: 该研究将上转换纳米粒子（UCNPs）嵌入三种不同硬度的聚合物基质中（环氧树脂、聚二甲基硅氧烷和海藻酸盐水凝胶），并研究了两种不同的核壳结构SrLuF基UCNPs，以提高其力传感性能。研究结果表明，环氧树脂中的SrLuF:Yb0.28Er0.025Mn0.013（具有SrYF惰性壳）表现出最高的发光颜色变化（每微牛顿12 Delta % IRed:IGreen），并且在鸡翅骨关节处进行了宏观力传感测试，证明了其在生物系统中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 聚合物UCNP复合材料在具有不同机械特性的生物组织中的应用受到聚合物硬度的限制。本研究旨在通过将UCNPs嵌入具有不同硬度的聚合物基质中，并优化UCNP的核壳结构和掺杂浓度，来扩展聚合物UCNP复合材料在不同生物组织中的应用，并提高其力传感的灵敏度。

Method: 1. 将UCNPs嵌入环氧树脂、聚二甲基硅氧烷和海藻酸盐水凝胶三种不同硬度的聚合物基质中。 2. 研究两种不同的SrLuF基UCNPs（掺杂Yb, Er, Mn）的核壳结构。 3. 使用原子力显微镜和共聚焦显微镜对聚合物UCNP复合材料进行力学传感校准。 4. 使用红绿发光比（Delta % IRed:IGreen）作为力读数。 5. 在鸡翅骨关节处进行宏观力传感测试。

Result: 1. 环氧树脂中的SrLuF:Yb0.28Er0.025Mn0.013（具有SrYF惰性壳）表现出最高的发光颜色变化（12 Delta % IRed:IGreen / µN）。 2. 成功在鸡翅骨关节处进行了宏观力传感测试，证明了其在原位测量压力能力。

Conclusion: UCNP聚合物复合材料系统具有良好的实用性和模块化，可用于在几何和力学上多样化的生物系统中进行力传感。通过选择合适的聚合物基质和UCNP结构，可以优化复合材料的力传感性能，并将其应用于更广泛的生物力学测量。

Abstract: Upconverting nanoparticles (UCNPs) are promising optical biomechanical force sensors due to their near infrared excitation, low toxicity, photostability, and linear colorimetric sensitivity to micronewtons of force. Recently, a composite force sensor based on UCNPs embedded in a polystyrene microbead enabled the first real time measurement of feeding forces in living nematodes. However, the comparatively large stiffness of polystyrene only makes it relevant to biomedical application in a small subset of biological tissue. To facilitate deployment of UCNPs into biological tissues with a range of mechanical properties, we expand upon polymer UCNP composite systems by embedding UCNPs in three polymer matrices with varying stiffnesses (epoxy resin, polydimethylsiloxane, and alginate hydrogels). Furthermore, to enhance these composites mechanosensitivity, we methodically investigate using two different core-shell architectures of SrLuF based UCNPs doped with ytterbium, erbium, and varying manganese concentrations. We calibrate polymer UCNP composite optical force sensitivity with colocalized atomic force and confocal microscopy. Using the red to green emission ratio (Delta Percent IRed:IGreen) as the force read-out, we determine that SrLuF:Yb0.28Er0.025Mn0.013 with SrYF inert shell dispersed in epoxy resin exhibits the greatest emission color change (12 Delta Percent IRed:IGreen per microNewton). Finally, we map forces in the epoxy UCNP composite on the macroscale between the joint of a chicken wing bone using a commercially available wide field microscope, thereby demonstrating its ability to optically measure pressures in situ. This work establishes the utility and modularity of the UCNP polymer composite system for force sensing in geometrically and mechanically diverse biological systems.

</details>


### [729] [Orthogonal Photoelastic Imaging for Three-Dimensional Stress Estimation in a Transparent Cubical Block](https://arxiv.org/abs/2511.11868)
*Dhiraj K. Singh*

Main category: physics.app-ph

TL;DR: 本研究提出了一种基于立方光弹性模型的立方体光弹性模型，可以通过三个正交视图进行精确的条纹级次估计，从而实现三维应力状态的重建。


<details>
  <summary>Details</summary>
Motivation: 现有的光弹性方法主要局限于二维应力可视化，无法满足生物力学和动态力学分析中对低应力水平下三维力相互作用的高灵敏度捕获需求。

Method: 使用结合透射和反射光弹性成像的透明、低弹性的无预应力环氧树脂立方体模型，同时记录三个相互正交的等色条纹场。采用峰谷强度法进行图像分析，提取亚条纹级次，以最小的噪声分辨低应力情况。

Result: 立方体在所有方向上均产生高质量的条纹图样，可以分离切向和法向应力分量。独立的正交视图证实了方向敏感性，并在低负载下产生了稳定一致的条纹级次估计，响应时间约为几十微秒。

Conclusion: 本研究确立了一种从正交视图进行三维光弹性应力测量的实用方法，为实现全矢量力重建奠定了基础，在生物医学应用和动态载荷研究方面具有巨大潜力。

Abstract: Conventional photoelastic methods are largely limited to two-dimensional stress visualization, leaving a gap in techniques that can capture three-dimensional force interactions with high sensitivity at low stress levels, a capability that is critical for biomechanics and dynamic force analysis. This study develops and demonstrates a cubic photoelastic model that enables accurate fringe-order estimation from three orthogonal views, providing a foundation for reconstructing full three-dimensional stress states. A transparent, low-elasticity epoxy cube, free of prestress, was fabricated and examined using combined transmission and reflection photoelastic imaging. Three mutually orthogonal isochromatic fringe fields were recorded simultaneously under a single applied load. Image analysis employed a peak-valley intensity method to extract sub-fringe orders and to resolve low-stress cases with minimal noise. The cubic block produced high-quality fringe patterns in all directions, enabling separation of tangential and normal stress components. Independent orthogonal views confirmed directional sensitivity and yielded consistent fringe-order estimates under low loading, with response times on the order of tens of microseconds. These results establish a practical approach for three-dimensional photoelastic stress measurement from orthogonal views and create a pathway toward full vector force reconstruction with strong potential for biomedical applications and studies of dynamic loading.

</details>


### [730] [A High-Efficiency Microwave Power Combining System Based on Frequency-Tuning Injection-Locked Magnetrons](https://arxiv.org/abs/2511.13516)
*Xiaojie Chen,Bo Yang,Naoki Shinohara,Changjun Liu*

Main category: physics.app-ph

TL;DR: 本研究提出并验证了一种1千瓦S波段磁控管微波功率合成系统，采用波导魔Tee实现功率合成和参考信号通路，并通过频率调谐实现高合成效率，实验结果表明合成效率达到94.5%，为未来低损耗大功率微波合成系统提供了指导。


<details>
  <summary>Details</summary>
Motivation: 为了提高注入锁定磁控管的功率水平和能量利用率。

Method: 提出并验证了一种双路1千瓦S波段磁控管微波功率合成系统，使用波导魔Tee实现功率合成和参考信号通路，并利用魔Tee的功率分配特性锁定两台磁控管。通过频率调谐来调整两台磁控管信号的相位差，以实现高功率合成效率。

Result: 实验结果表明，该微波功率合成系统的功率合成效率达到94.5%。微波功率损耗仅由波导和魔Tee引起。

Conclusion: 本研究为未来低损耗的大功率微波合成系统提供了指导。

Abstract: To increase the power level and energy utilization rate of injection-locked magnetron sources, a dual way 1-kW S-band magnetron microwave power combining system with high combining efficiency was proposed and validated. A waveguide magic-Tee was used to achieve power combining and to provide a pathway for the reference signal. This system utilizes the power-dividing characteristic of a magic-Tee to lock two magnetrons. Frequency tuning is applied to adjust the phase difference between the two magnetrons' signals so as to achieve a high combining efficiency. Experimental results indicate that the microwave power combining efficiency of the proposed system reaches 94.5%. The attenuation of microwave power is caused only by the waveguides and magic-Tee. Our investigation provides a guideline for future high-power microwave combining systems with low losses.

</details>


### [731] [In-memory phononic learning toward cognitive mechanical intelligence](https://arxiv.org/abs/2511.13543)
*Yuning Zhang,K. W. Wang*

Main category: physics.app-ph

TL;DR: 本研究提出了一种名为“ in-memory phononic learning”的新范式，通过在声子超结构中集成非易失性机械记忆和基于波的感知，实现了机械域内的记忆、感知、学习和决策，无需额外电子元件。


<details>
  <summary>Details</summary>
Motivation: 为了满足现代自主系统对具有内置智能（记忆、感知、学习、决策）的自适应材料和结构的需求，克服现有技术在效率、可扩展性、可解释性、透明度和对额外电子元件的依赖性方面的局限性。

Method: 提出了一种新的“in-memory phononic learning”范式，将非易失性机械记忆与声子超结构中的波基感知相结合。该系统将空间信息编码为机械记忆的稳定结构状态，直接调整其弹性波传播特性。通过优化输入波形来选择性地探测这些特征以进行记忆模式分类，并直接从输出波能量推断决策，从而在机械层面完成整个信息处理循环。

Result: 该框架通过频率选择性波局域化有效地实现了感官感知，将复杂模式分解为信息丰富的几何特征。学习通过优化输入波形来实现，决策直接从输出波能量中推断，整个过程无需隐藏架构或电子元件，实现了高效且物理上透明的机制。

Conclusion: 这项工作将‘计算材料’的范式提升至能够解释动态环境的认知物质，为未来低功耗、与周围环境更直接的交互、以及在恶劣条件下增强的网络安全和韧性的智能结构-材料系统铺平了道路。

Abstract: Modern autonomous systems are driving the critical need for next-generation adaptive materials and structures with embodied intelligence, i.e., the embodiment of memory, perception, learning, and decision-making within the mechanical domain. A fundamental challenge is the seamless and efficient integration of memory with information processing in a physically interpretable way that enables cognitive learning and decision-making under uncertainty. Prevailing paradigms, from intricate logic cascades to black-box morphological computing or physical neural networks, are seriously limited by trade-offs among efficiency, scalability, interpretability, transparency, and reliance on additional electronics. Here, we introduce in-memory phononic learning, a paradigm-shifting framework that unifies nonvolatile mechanical memory with wave-based perception within a phononic metastructure. Our system encodes spatial information into stable structural states as mechanical memory that directly programs its elastic wave-propagation landscape. This memory/wave-dynamics coupling enables effective sensory perception, decomposing complex patterns into informative geometric features through frequency-selective wave localization. Learning is created by optimizing input waveforms to selectively probe these features for memory-pattern classification, with decisions inferred directly from the output wave energy, thereby completing the entire information loop mechanically through an efficient and physically transparent mechanism without hidden architectures or electronics. This work transcends the paradigm of 'materials that compute' to cognitive matter capable of interpreting dynamic environments, paving the way for future intelligent structural-material systems with low power consumption, more direct interaction with surroundings, and enhanced cybersecurity and resilience in harsh conditions.

</details>


### [732] [Ultrafast propagation of magnon-polaritons](https://arxiv.org/abs/2511.13636)
*Ondřej Wojewoda,Miela J. Gross,Jan Klíma,Jaganandha Panda,Jakub Krčma,Jakub Holobrádek,Kristýna Davídková,Andrii V. Chumak,Philipp Pirro,Roman Verba,Sebastian Wintz,Qi Wang,Caroline A. Ross,Michal Urbánek*

Main category: physics.app-ph

TL;DR: 文章展示了混合准粒子“磁振极化激子”在铁磁薄膜中能够以超过100公里/秒的速度传播，远超传统自旋波，并能在长距离上传播，有潜力用于未来自旋电子学。


<details>
  <summary>Details</summary>
Motivation: 探索比传统自旋波传播速度更快的磁激发传播方式，以克服现有自旋电子学和宏观子学技术的性能瓶颈。

Method: 利用时间分辨和相位分辨布里渊光散射显微镜以及时间分辨扫描透射显微镜，研究了掺杂和未掺杂的钇铁石榴石薄膜中磁振极化激子的传播动力学。并通过基于延迟麦克斯韦方程和Polder张量形式的解析模型进行验证。

Result: 在不同类型的钇铁石榴石薄膜（YIG, Bi:YIG, Ga:YIG）中观察到磁振极化激子，其传播速度超过100公里/秒，传播距离超过40微米。模型验证了其混合性质、色散和衰减特性。磁振极化激子能保持高初始磁化振幅和长衰减长度，能够移动磁畴壁或稳定非线性磁化过程。

Conclusion: 磁振极化激子具有前所未有高传播速度和长传播距离，是未来自旋计算架构中高速信息传输的有希望的候选者，有望解决宏观子逻辑电路中长期存在的群延迟瓶颈。

Abstract: The manipulation of magnetization lies at the heart of spintronic and magnonic technologies, with the ultimate performance of such systems limited by the velocity at which magnetic excitations can propagate. Here, we demonstrate ultrafast propagation of magnon-polaritons-hybrid quasiparticles arising from the coupling between spin waves and electromagnetic fields in thin pure, bismuth-, and gallium substituted yttrium iron garnet (YIG, Bi:YIG and Ga:YIG) films. Using time- and phase-resolved Brillouin light scattering microscopy and time-resolved scanning transmission microscopy, we show that magnon-polaritons can propagate faster than 100 km/s, nearly three orders of magnitude more than conventional spin waves, and can be observed at distances exceeding 40 micrometers in 20 nm thick films. Analytical modeling based on retarded Maxwell equations and Polder tensor formalism confirms the hybridized nature of the excitations and captures the nontrivial dispersion and attenuation profiles. Notably, the magnon-polaritons maintain high initial magnetization amplitudes and long decay lengths, enabling ultrafast manipulation of the magnetization far away from the excitation source. We show, that they can move domain walls or stabilize nonlinear magnetization processes. The unprecedentedly high propagation velocities make magnon-polaritons promising candidates for high-speed information transfer in future spin-based computing architectures, potentially overcoming long-standing group delay bottlenecks in magnonic logic circuits.

</details>
