<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 221]
- [cs.CL](#cs.CL) [Total: 157]
- [cs.GR](#cs.GR) [Total: 8]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 18]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 40]
- [cs.SI](#cs.SI) [Total: 5]
- [eess.SP](#eess.SP) [Total: 32]
- [eess.SY](#eess.SY) [Total: 33]
- [cs.GT](#cs.GT) [Total: 9]
- [physics.app-ph](#physics.app-ph) [Total: 11]
- [cs.DS](#cs.DS) [Total: 12]
- [cs.AR](#cs.AR) [Total: 5]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.AI](#cs.AI) [Total: 73]
- [cs.LO](#cs.LO) [Total: 9]
- [cs.LG](#cs.LG) [Total: 231]
- [quant-ph](#quant-ph) [Total: 72]
- [cs.RO](#cs.RO) [Total: 78]
- [cs.DC](#cs.DC) [Total: 14]
- [cs.MA](#cs.MA) [Total: 9]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TinyViT-Batten: Few-Shot Vision Transformer with Explainable Attention for Early Batten-Disease Detection on Pediatric MRI](https://arxiv.org/abs/2510.09649)
*Khartik Uppalapati,Bora Yimenicioglu,Shakeel Abdulkareem,Adan Eftekhari,Bhavya Uppalapati,Viraj Kamath*

Main category: cs.CV

TL;DR: Batten病是一种罕见的儿童神经退行性疾病，其早期MRI迹象不明显且常被忽略。我们提出了TinyViT-Batten，一个少样本Vision Transformer（ViT）框架，用于从有限的儿科脑部MRI中检测早期Batten病。我们将一个大型教师ViT蒸馏到一个500万参数的TinyViT，并使用基于度量的少样本学习（具有5次样本的prototypical loss）对其进行微调。我们的模型在一个包含79例基因确诊的Batten病MRI（27例CLN3，32例CLN2，12例早期表现的CLN2病例，以及8例公共Radiopaedia扫描）和90例年龄匹配的对照组的多中心数据集上，实现了高准确率（约91%）和至少0.95的ROC下面积，优于3D-ResNet和Swin-Tiny基线模型。我们还集成了Gradient-weighted Class Activation Mapping（Grad-CAM）来突出与疾病相关的脑部区域，从而实现可解释的预测。该模型的小尺寸和强劲性能（敏感度大于90%，特异度约90%）证明了其在早期Batten病检测方面具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: Batten病是一种罕见的儿童神经退行性疾病，其早期MRI迹象不明显且常被忽略，因此需要一种能够从有限的训练样本中检测早期Batten病的AI解决方案。

Method: 我们提出了TinyViT-Batten，一个少样本Vision Transformer（ViT）框架。首先，我们将一个大型教师ViT蒸馏到一个500万参数的TinyViT。然后，使用基于度量的少样本学习（具有5次样本的prototypical loss）对其进行微调。最后，集成Grad-CAM以实现可解释的预测。

Result: 在包含79例基因确诊的Batten病MRI和90例年龄匹配的对照组的多中心数据集上，TinyViT-Batten实现了约91%的准确率和至少0.95的ROC下面积。模型的敏感度大于90%，特异度约90%。该模型优于3D-ResNet和Swin-Tiny基线模型，并能通过Grad-CAM突出与疾病相关的脑部区域。

Conclusion: TinyViT-Batten是一个小尺寸、高性能的AI解决方案，能够从有限的儿科脑部MRI样本中有效检测早期Batten病，并提供可解释的预测。

Abstract: Batten disease (neuronal ceroid lipofuscinosis) is a rare pediatric
neurodegenerative disorder whose early MRI signs are subtle and often missed.
We propose TinyViT-Batten, a few-shot Vision Transformer (ViT) framework to
detect early Batten disease from pediatric brain MRI with limited training
cases. We distill a large teacher ViT into a 5 M-parameter TinyViT and
fine-tune it using metric-based few-shot learning (prototypical loss with
5-shot episodes). Our model achieves high accuracy (approximately 91%) and area
under ROC of at least 0.95 on a multi-site dataset of 79 genetically confirmed
Batten-disease MRIs (27 CLN3 from the Hochstein natural-history study, 32 CLN2
from an international longitudinal cohort, 12 early-manifestation CLN2 cases
reported by Cokal et al., and 8 public Radiopaedia scans) together with 90
age-matched controls, outperforming a 3D-ResNet and Swin-Tiny baseline. We
further integrate Gradient-weighted Class Activation Mapping (Grad-CAM) to
highlight disease-relevant brain regions, enabling explainable predictions. The
model's small size and strong performance (sensitivity greater than 90%,
specificity approximately 90%) demonstrates a practical AI solution for early
Batten disease detection.

</details>


### [2] [Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition](https://arxiv.org/abs/2510.09653)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: 本文全面回顾了 Ultralytics YOLO 系列目标检测器的发展历程，重点介绍了 YOLOv26 的创新点，如移除 DFL、原生 NMS-free 推理、ProgLoss、STAL 和 MuSGD 优化器。文章追溯了 YOLO11、YOLOv8 和 YOLOv5 的演进，并对 YOLOv5、v8、v11、v26 在 MS COCO 数据集上的性能进行了基准测试和比较。此外，文章还讨论了部署和应用前景，以及未来面临的挑战和发展方向。


<details>
  <summary>Details</summary>
Motivation: 本文旨在全面概述 Ultralytics YOLO 系列目标检测器的架构演变、基准测试、部署前景和未来挑战。

Method: 文章首先介绍了最新的 YOLOv26 及其创新点，然后追溯了 YOLO11、YOLOv8 和 YOLO5 的发展。在 MS COCO 数据集上对 YOLOv5、YOLOv8、YOLO11 和 YOLOv26 进行了基准测试，并与其他模型进行了比较。最后，讨论了部署和应用前景，以及未来的挑战和方向。

Result: 在 MS COCO 数据集上，对 YOLOv5、YOLOv8、YOLO11 和 YOLOv26 进行了详细的量化比较，并与其他模型进行了交叉比较。分析了精度、召回率、F1 分数、平均精度均值和推理速度等指标，强调了准确性和效率之间的权衡。部署和应用前景也得到了讨论。

Conclusion: 文章识别了密集场景的局限性、混合 CNN-Transformer 集成、开放词汇检测和边缘感知训练方法等挑战和未来方向。

Abstract: This paper presents a comprehensive overview of the Ultralytics YOLO(You Only
Look Once) family of object detectors, focusing the architectural evolution,
benchmarking, deployment perspectives, and future challenges. The review begins
with the most recent release, YOLO26 (YOLOv26), which introduces key
innovations including Distribution Focal Loss (DFL) removal, native NMS-free
inference, Progressive Loss Balancing (ProgLoss), Small-Target-Aware Label
Assignment (STAL), and the MuSGD optimizer for stable training. The progression
is then traced through YOLO11, with its hybrid task assignment and
efficiency-focused modules; YOLOv8, which advanced with a decoupled detection
head and anchor-free predictions; and YOLOv5, which established the modular
PyTorch foundation that enabled modern YOLO development. Benchmarking on the MS
COCO dataset provides a detailed quantitative comparison of YOLOv5, YOLOv8,
YOLO11, and YOLO26, alongside cross-comparisons with YOLOv12, YOLOv13, RT-DETR,
and DEIM. Metrics including precision, recall, F1 score, mean Average
Precision, and inference speed are analyzed to highlight trade-offs between
accuracy and efficiency. Deployment and application perspectives are further
discussed, covering export formats, quantization strategies, and real-world use
in robotics, agriculture, surveillance, and manufacturing. Finally, the paper
identifies challenges and future directions, including dense-scene limitations,
hybrid CNN-Transformer integration, open-vocabulary detection, and edge-aware
training approaches.

</details>


### [3] [TreeNet: Layered Decision Ensembles](https://arxiv.org/abs/2510.09654)
*Zeshan Khan*

Main category: cs.CV

TL;DR: TreeNet是一种新的分层决策集成学习方法，用于医学图像分析，通过结合神经网络、集成学习和基于树的决策模型来提高准确性，并具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分析方法（神经网络、决策树、集成学习）在数据充足时表现良好，但在医疗图像分析中普遍存在数据量有限和数据置信度低的问题。

Method: 提出了一种名为TreeNet的新型分层决策集成学习方法，该方法整合了神经网络、集成学习和基于树的决策模型的关键特征。

Result: TreeNet在完整训练数据下达到了0.85的F1分数，在使用50%训练数据时为0.77，F1分数下降了0.08。模型处理速度为32帧/秒，可满足实时应用需求。

Conclusion: TreeNet是一种有效且可适应的模型，在复杂的医学图像分析任务中表现出色，具有良好的可解释性和实时分析能力。

Abstract: Within the domain of medical image analysis, three distinct methodologies
have demonstrated commendable accuracy: Neural Networks, Decision Trees, and
Ensemble-Based Learning Algorithms, particularly in the specialized context of
genstro institutional track abnormalities detection. These approaches exhibit
efficacy in disease detection scenarios where a substantial volume of data is
available. However, the prevalent challenge in medical image analysis pertains
to limited data availability and data confidence. This paper introduces
TreeNet, a novel layered decision ensemble learning methodology tailored for
medical image analysis. Constructed by integrating pivotal features from neural
networks, ensemble learning, and tree-based decision models, TreeNet emerges as
a potent and adaptable model capable of delivering superior performance across
diverse and intricate machine learning tasks. Furthermore, its interpretability
and insightful decision-making process enhance its applicability in complex
medical scenarios. Evaluation of the proposed approach encompasses key metrics
including Accuracy, Precision, Recall, and training and evaluation time. The
methodology resulted in an F1-score of up to 0.85 when using the complete
training data, with an F1-score of 0.77 when utilizing 50\% of the training
data. This shows a reduction of F1-score of 0.08 while in the reduction of 50\%
of the training data and training time. The evaluation of the methodology
resulted in the 32 Frame per Second which is usable for the realtime
applications. This comprehensive assessment underscores the efficiency and
usability of TreeNet in the demanding landscape of medical image analysis
specially in the realtime analysis.

</details>


### [4] [OmniSAT: Compact Action Token, Faster Auto Regression](https://arxiv.org/abs/2510.09667)
*Huaihai Lyu,Chaofan Chen,Senwei Xie,Pengwei Wang,Xiansheng Chen,Shanghang Zhang,Changsheng Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种名为Omni Swift Action Tokenizer (OmniSAT) 的新方法，用于压缩和表示动作序列，以提高Vision-Language-Action (VLA) 模型的效率。OmniSAT通过B样条编码和多阶段残差量化将动作表示为紧凑的离散令牌，实现了6.8倍的序列缩短和更低的熵。该方法还通过跨体学习策略，利用机器人和人类演示来增强模型性能，并在实际机器人和模拟实验中证明了其在提高压缩率、保持重建质量和加速训练方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的Vision-Language-Action (VLA) 模型在压缩动作序列时存在重建效果差或压缩效率低的问题。本研究旨在解决这些问题，提出一种更有效的动作表示方法。

Method: 1. 使用B样条编码对动作进行归一化处理，使其具有统一的表示。 2. 对位置、旋转和夹爪子空间应用多阶段残差量化，生成具有粗粒到细粒粒度的离散令牌。 3. 提出一种跨体学习策略，利用机器人和人类演示来增强模型。

Result: OmniSAT将训练序列缩短了6.8倍，降低了目标熵。在实际机器人和模拟实验中，OmniSAT在保持重建质量的同时实现了更高的压缩率，从而加快了AR训练的收敛速度和模型性能。

Conclusion: OmniSAT是一种有效的动作压缩和表示方法，通过学习紧凑、可转移的动作表示，显著提高了VLA模型的效率，并能在跨体学习中有效利用不同来源的数据，最终提升模型性能。

Abstract: Existing Vision-Language-Action (VLA) models can be broadly categorized into
diffusion-based and auto-regressive (AR) approaches: diffusion models capture
continuous action distributions but rely on computationally heavy iterative
denoising. In contrast, AR models enable efficient optimization and flexible
sequence construction, making them better suited for large-scale pretraining.
To further improve AR efficiency, particularly when action chunks induce
extended and high-dimensional sequences, prior work applies entropy-guided and
token-frequency techniques to shorten the sequence length. However, such
compression struggled with \textit{poor reconstruction or inefficient
compression}. Motivated by this, we introduce an Omni Swift Action Tokenizer,
which learns a compact, transferable action representation. Specifically, we
first normalize value ranges and temporal horizons to obtain a consistent
representation with B-Spline encoding. Then, we apply multi-stage residual
quantization to the position, rotation, and gripper subspaces, producing
compressed discrete tokens with coarse-to-fine granularity for each part. After
pre-training on the large-scale dataset Droid, the resulting discrete
tokenization shortens the training sequence by 6.8$\times$, and lowers the
target entropy. To further explore the potential of OmniSAT, we develop a
cross-embodiment learning strategy that builds on the unified action-pattern
space and jointly leverages robot and human demonstrations. It enables scalable
auxiliary supervision from heterogeneous egocentric videos. Across diverse
real-robot and simulation experiments, OmniSAT encompasses higher compression
while preserving reconstruction quality, enabling faster AR training
convergence and model performance.

</details>


### [5] [EvoCAD: Evolutionary CAD Code Generation with Vision Language Models](https://arxiv.org/abs/2510.11631)
*Tobias Preintner,Weixuan Yuan,Adrian König,Thomas Bäck,Elena Raponi,Niki van Stein*

Main category: cs.CV

TL;DR: EvoCAD是一种结合大型语言模型（LLM）和进化计算的方法，用于生成计算机辅助设计（CAD）对象。


<details>
  <summary>Details</summary>
Motivation: 结合LLM的生成和上下文学习能力与进化算法的优势，探索CAD对象生成的新方向。

Method: EvoCAD通过视觉语言模型和进化优化，利用符号表示来生成CAD对象。具体方法是先采样多个CAD对象，然后使用包含视觉和推理语言模型的进化方法进行优化。

Result: 使用GPT-4V和GPT-4o评估EvoCAD在CADPrompt基准数据集上的表现，并与先前方法进行比较。引入了基于欧拉示性数定义的拓扑属性的两个新指标，用于衡量3D对象的语义相似性。结果表明，EvoCAD在多个指标上优于先前方法，尤其在生成拓扑正确的对象方面。

Conclusion: EvoCAD在生成拓扑正确的CAD对象方面表现出色，并且所提出的新拓扑指标能够有效补充现有空间指标，实现高效评估。

Abstract: Combining large language models with evolutionary computation algorithms
represents a promising research direction leveraging the remarkable generative
and in-context learning capabilities of LLMs with the strengths of evolutionary
algorithms. In this work, we present EvoCAD, a method for generating
computer-aided design (CAD) objects through their symbolic representations
using vision language models and evolutionary optimization. Our method samples
multiple CAD objects, which are then optimized using an evolutionary approach
with vision language and reasoning language models. We assess our method using
GPT-4V and GPT-4o, evaluating it on the CADPrompt benchmark dataset and
comparing it to prior methods. Additionally, we introduce two new metrics based
on topological properties defined by the Euler characteristic, which capture a
form of semantic similarity between 3D objects. Our results demonstrate that
EvoCAD outperforms previous approaches on multiple metrics, particularly in
generating topologically correct objects, which can be efficiently evaluated
using our two novel metrics that complement existing spatial metrics.

</details>


### [6] [Knowledge-Aware Mamba for Joint Change Detection and Classification from MODIS Times Series](https://arxiv.org/abs/2510.09679)
*Zhengsen Xu,Yimin Zhu,Zack Dewis,Mabel Heffring,Motasem Alkayid,Saeid Taleghanidoozdoozan,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为KAMamba的新方法，用于提高MODIS时间序列的变化检测能力，解决了混合像元、时空谱信息耦合和背景类别异质性等挑战。


<details>
  <summary>Details</summary>
Motivation: MODIS时间序列变化检测在环境监测中至关重要，但面临混合像元、时空谱信息耦合效应和背景类别异质性等挑战。

Method: 研究设计了一种知识驱动的、基于转移矩阵的方法，提出了知识感知转移损失（KAT-loss）；设计了多任务学习方法，包含变化前分类损失（PreC-loss）、变化后分类损失（PostC-loss）和变化检测损失（Chg-loss）；设计了新颖的时空谱Mamba（SSTMamba）模块来解耦MODIS时间序列信息；并采用了稀疏可变形Mamba（SDMamba）骨干网络以提高效率并降低计算成本。

Result: 在加拿大萨斯喀彻温省的MODIS数据集上，KAMamba在土地覆盖变化检测方面，平均F1分数相比基线提高了1.5-6%；在土地利用/覆盖（LULC）分类方面，OA、AA和Kappa值分别提高了约2%。

Conclusion: KAMamba在MODIS时间序列变化检测和LULC分类任务上均取得了显著的性能提升。

Abstract: Although change detection using MODIS time series is critical for
environmental monitoring, it is a highly challenging task due to key MODIS
difficulties, e.g., mixed pixels, spatial-spectral-temporal information
coupling effect, and background class heterogeneity. This paper presents a
novel knowledge-aware Mamba (KAMamba) for enhanced MODIS change detection, with
the following contributions. First, to leverage knowledge regarding class
transitions, we design a novel knowledge-driven transition-matrix-guided
approach, leading to a knowledge-aware transition loss (KAT-loss) that can
enhance detection accuracies. Second, to improve model constraints, a
multi-task learning approach is designed, where three losses, i.e., pre-change
classification loss (PreC-loss), post-change classification loss (PostC-loss),
and change detection loss (Chg-loss) are used for improve model learning.
Third, to disentangle information coupling in MODIS time series, novel
spatial-spectral-temporal Mamba (SSTMamba) modules are designed. Last, to
improve Mamba model efficiency and remove computational cost, a sparse and
deformable Mamba (SDMamba) backbone is used in SSTMamba. On the MODIS
time-series dataset for Saskatchewan, Canada, we evaluate the method on
land-cover change detection and LULC classification; results show about 1.5-6%
gains in average F1 for change detection over baselines, and about 2%
improvements in OA, AA, and Kappa for LULC classification.

</details>


### [7] [NNDM: NN_UNet Diffusion Model for Brain Tumor Segmentation](https://arxiv.org/abs/2510.09681)
*Sashank Makanaboyina*

Main category: cs.CV

TL;DR: NNDM结合了NN-UNet和扩散模型，通过迭代去噪来提高脑肿瘤MRI分割的准确性和边界精度，并在BraTS 2021数据集上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的脑肿瘤MRI分割模型（如U-Net）在泛化性、边界精度和数据多样性方面存在挑战。

Method: 提出了一种名为NNDM的混合框架，该框架结合了NN-UNet的特征提取能力和扩散模型的生成能力。扩散模型通过学习预测掩码和真实掩码之间的残差误差分布来逐步优化NN-UNet生成的分割掩码，通过迭代去噪来纠正结构不一致性和提高边界清晰度。

Result: 在BraTS 2021数据集上，NNDM在Dice系数和Hausdorff距离等指标上优于传统的U-Net和基于Transformer的模型，并且能够提高跨模态和跨肿瘤亚区域的分割鲁棒性。

Conclusion: NNDM为结合确定性分割网络和随机扩散模型提供了一个新的方向，推动了脑肿瘤自动分析的进展。

Abstract: Accurate detection and segmentation of brain tumors in magnetic resonance
imaging (MRI) are critical for effective diagnosis and treatment planning.
Despite advances in convolutional neural networks (CNNs) such as U-Net,
existing models often struggle with generalization, boundary precision, and
limited data diversity. To address these challenges, we propose NNDM (NN\_UNet
Diffusion Model)a hybrid framework that integrates the robust feature
extraction of NN-UNet with the generative capabilities of diffusion
probabilistic models. In our approach, the diffusion model progressively
refines the segmentation masks generated by NN-UNet by learning the residual
error distribution between predicted and ground-truth masks. This iterative
denoising process enables the model to correct fine structural inconsistencies
and enhance tumor boundary delineation. Experiments conducted on the BraTS 2021
datasets demonstrate that NNDM achieves superior performance compared to
conventional U-Net and transformer-based baselines, yielding improvements in
Dice coefficient and Hausdorff distance metrics. Moreover, the diffusion-guided
refinement enhances robustness across modalities and tumor subregions. The
proposed NNDM establishes a new direction for combining deterministic
segmentation networks with stochastic diffusion models, advancing the state of
the art in automated brain tumor analysis.

</details>


### [8] [Adaptive Fusion Network with Temporal-Ranked and Motion-Intensity Dynamic Images for Micro-expression Recognition](https://arxiv.org/abs/2510.09730)
*Thi Bich Phuong Man,Luu Tu Nguyen,Vu Tram Anh Khuong,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 该研究提出了一种新的微表情识别（MER）方法，通过结合时间排序和运动强度动态图像，并利用自适应融合网络（AFN）优化特征提取，在三个基准数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 微表情（MEs）虽然强度低、转瞬即逝，但能揭示真实情感，在测谎、行为分析和心理评估等领域具有重要价值。然而，由于其低强度和短暂性，微表情识别仍然是一个挑战。

Method: 提出了一种新的微表情识别方法，包含两个主要部分：1. 两种互补的表示方法：时间排序动态图像（强调时间进程）和运动强度动态图像（通过包含运动强度的帧重排机制突出细微运动）。2. 自适应融合网络（AFN）：自动学习并融合这两种表示，以增强区分性特征并抑制噪声。

Result: 在CASME-II数据集上，AFN达到了93.95%的准确率和0.897的UF1分数，创下新的最优记录。在SAMM数据集上，该方法获得了82.47%的准确率和0.665的UF1分数。在MMEW数据集上，模型准确率达到了76.00%。

Conclusion: 实验结果表明，所提出的输入表示和AFN架构在提高微表情识别性能方面发挥着重要作用，为情感计算、测谎和人机交互等领域的进一步研究和实际应用奠定了坚实的基础。

Abstract: Micro-expressions (MEs) are subtle, transient facial changes with very low
intensity, almost imperceptible to the naked eye, yet they reveal a person
genuine emotion. They are of great value in lie detection, behavioral analysis,
and psychological assessment. This paper proposes a novel MER method with two
main contributions. First, we propose two complementary representations -
Temporal-ranked dynamic image, which emphasizes temporal progression, and
Motion-intensity dynamic image, which highlights subtle motions through a frame
reordering mechanism incorporating motion intensity. Second, we propose an
Adaptive fusion network, which automatically learns to optimally integrate
these two representations, thereby enhancing discriminative ME features while
suppressing noise. Experiments on three benchmark datasets (CASME-II, SAMM and
MMEW) demonstrate the superiority of the proposed method. Specifically, AFN
achieves 93.95 Accuracy and 0.897 UF1 on CASME-II, setting a new
state-of-the-art benchmark. On SAMM, the method attains 82.47 Accuracy and
0.665 UF1, demonstrating more balanced recognition across classes. On MMEW, the
model achieves 76.00 Accuracy, further confirming its generalization ability.
The obtained results show that both the input and the proposed architecture
play important roles in improving the performance of MER. Moreover, they
provide a solid foundation for further research and practical applications in
the fields of affective computing, lie detection, and human-computer
interaction.

</details>


### [9] [Multi Camera Connected Vision System with Multi View Analytics: A Comprehensive Survey](https://arxiv.org/abs/2510.09731)
*Muhammad Munsif,Waqas Ahmad,Amjid Ali,Mohib Ullah,Adnan Hussain,Sung Wook Baik*

Main category: cs.CV

TL;DR: 本篇论文是首个全面综述多视角多摄像头（MVMC）连接视觉系统（CVS）的文献，该系统整合了跟踪、重识别（Re-ID）和行为理解（AU），旨在解决现实世界中的遮挡、视角多样性和环境变化等挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注跟踪、Re-ID和AU的孤立任务，并且忽视了多摄像头协同和多视角数据分析的复杂性。因此，需要一篇综述来整合这些任务并全面分析MVMC CVS。

Method: 提出了一种独特的分类法，将CVS分为四个关键部分：MVMC跟踪、Re-ID、AU和组合方法。系统地总结了最新的数据集、方法、结果和评估指标，并讨论了开放性研究问题、挑战以及新兴技术，如终身学习、隐私和联邦学习。

Result: 对MVMC CVS的最新研究进行了系统性梳理和总结，识别了该领域的进展、挑战和未来研究方向。

Conclusion: 为增强CVS在复杂现实应用中的鲁棒性、效率和适应性，指明了关键的研究方向，并希望激发创新解决方案，指导未来研究。

Abstract: Connected Vision Systems (CVS) are transforming a variety of applications,
including autonomous vehicles, smart cities, surveillance, and human-robot
interaction. These systems harness multi-view multi-camera (MVMC) data to
provide enhanced situational awareness through the integration of MVMC
tracking, re-identification (Re-ID), and action understanding (AU). However,
deploying CVS in real-world, dynamic environments presents a number of
challenges, particularly in addressing occlusions, diverse viewpoints, and
environmental variability. Existing surveys have focused primarily on isolated
tasks such as tracking, Re-ID, and AU, often neglecting their integration into
a cohesive system. These reviews typically emphasize single-view setups,
overlooking the complexities and opportunities provided by multi-camera
collaboration and multi-view data analysis. To the best of our knowledge, this
survey is the first to offer a comprehensive and integrated review of MVMC that
unifies MVMC tracking, Re-ID, and AU into a single framework. We propose a
unique taxonomy to better understand the critical components of CVS, dividing
it into four key parts: MVMC tracking, Re-ID, AU, and combined methods. We
systematically arrange and summarize the state-of-the-art datasets,
methodologies, results, and evaluation metrics, providing a structured view of
the field's progression. Furthermore, we identify and discuss the open research
questions and challenges, along with emerging technologies such as lifelong
learning, privacy, and federated learning, that need to be addressed for future
advancements. The paper concludes by outlining key research directions for
enhancing the robustness, efficiency, and adaptability of CVS in complex,
real-world applications. We hope this survey will inspire innovative solutions
and guide future research toward the next generation of intelligent and
adaptive CVS.

</details>


### [10] [Constructive Distortion: Improving MLLMs with Attention-Guided Image Warping](https://arxiv.org/abs/2510.09741)
*Dwip Dalal,Gautam Vashishtha,Utkarsh Mishra,Jeonghwan Kim,Madhav Kanda,Hyeonjeong Ha,Svetlana Lazebnik,Heng Ji,Unnat Jain*

Main category: cs.CV

TL;DR: AttWarp通过引导模型注意力来重新分配图像分辨率，优先处理与查询相关的内容，从而提高MLLMs在处理复杂场景时的细粒度感知能力，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理拥挤场景下的细节和空间关系时存在不足，容易出现细粒度感知错误。

Method: AttWarp是一种轻量级方法，它利用MLLM在测试时的跨模态注意力机制，对输入图像进行校直扭曲，将更多的分辨率分配给模型认为重要的区域，同时压缩信息量较少的区域，并且在整个过程中保持全局上下文。此方法无需改变模型权重或架构。

Result: 在TextVQA、GQA、DocVQA、POPE和MMMU五个基准测试以及LLaVA、Qwen-VL、InternVL和InstructBLIP四种MLLMs上，AttWarp一致性地提高了准确性，增强了组合推理能力，并减少了幻觉，其性能优于其他四种在测试时操纵原始图像的基线方法。

Conclusion: 注意力引导的扭曲方法能够优先处理与查询相关的信息，同时保持上下文的完整性，并且在给定这种扭曲输入的情况下，相同的MLLMs可以获得更好的性能。

Abstract: Multimodal large language models (MLLMs) often miss small details and spatial
relations in cluttered scenes, leading to errors in fine-grained perceptual
grounding. We introduce AttWarp, a lightweight method that allocates more
resolution to query-relevant content while compressing less informative areas,
all while preserving global context. At test time, the approach uses an MLLM's
cross-modal attention to perform rectilinear warping of the input image,
reallocating spatial resolution toward regions the model deems important,
without changing model weights or architecture. This attention-guided warping
preserves all original image information but redistributes it non-uniformly, so
small objects and subtle relationships become easier for the same model to read
while the global layout remains intact. Across five benchmarks (TextVQA, GQA,
DocVQA, POPE, MMMU) and four MLLMs (LLaVA, Qwen-VL, InternVL, and
InstructBLIP), AttWarp consistently improves accuracy, strengthens
compositional reasoning, and reduces hallucinations, outperforming four
competitive baselines that manipulate raw images at test time. Together, these
results show that attention-guided warping prioritizes information relevant to
the query while preserving context, and that the same MLLMs perform better when
given such warped inputs.

</details>


### [11] [A Framework for Low-Effort Training Data Generation for Urban Semantic Segmentation](https://arxiv.org/abs/2510.11567)
*Denis Zavadski,Damjan Kalšan,Tim Küchler,Haebom Lee,Stefan Roth,Carsten Rother*

Main category: cs.CV

TL;DR: 使用伪标签和扩散模型，将合成数据适配到特定城市领域，以提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据集在城市场景识别中广泛应用，但与真实图像存在差距，尤其在特定领域（如Cityscapes）适配时，这种差距会限制模型性能。然而，通过更精细的3D建模来缩小这种差距成本高昂。

Method: 提出一种新框架，利用仅有的不完美伪标签来适配现有的扩散模型到特定目标领域。该框架能够从任何合成数据集中生成高保真、与目标对齐的图像，即使是低成本、快速创建的数据集。它通过过滤不佳的生成结果、修正图像-标签错位以及统一不同数据集的语义来实现这一目标。

Result: 在五个合成数据集和两个真实目标数据集上的实验表明，与最先进的图像翻译方法相比，该方法在mIoU上最多可提高+8.0%点。这使得快速构建的合成数据集与需要大量人力设计的高成本、耗时合成数据集一样有效。

Conclusion: 该研究展示了一种有价值的协作模式：快速的语义原型设计与生成模型相结合，可以实现可扩展、高质量的城市场景理解训练数据的创建。

Abstract: Synthetic datasets are widely used for training urban scene recognition
models, but even highly realistic renderings show a noticeable gap to real
imagery. This gap is particularly pronounced when adapting to a specific target
domain, such as Cityscapes, where differences in architecture, vegetation,
object appearance, and camera characteristics limit downstream performance.
Closing this gap with more detailed 3D modelling would require expensive asset
and scene design, defeating the purpose of low-cost labelled data. To address
this, we present a new framework that adapts an off-the-shelf diffusion model
to a target domain using only imperfect pseudo-labels. Once trained, it
generates high-fidelity, target-aligned images from semantic maps of any
synthetic dataset, including low-effort sources created in hours rather than
months. The method filters suboptimal generations, rectifies image-label
misalignments, and standardises semantics across datasets, transforming weak
synthetic data into competitive real-domain training sets. Experiments on five
synthetic datasets and two real target datasets show segmentation gains of up
to +8.0%pt. mIoU over state-of-the-art translation methods, making rapidly
constructed synthetic datasets as effective as high-effort, time-intensive
synthetic datasets requiring extensive manual design. This work highlights a
valuable collaborative paradigm where fast semantic prototyping, combined with
generative models, enables scalable, high-quality training data creation for
urban scene understanding.

</details>


### [12] [Towards Understanding Ambiguity Resolution in Multimodal Inference of Meaning](https://arxiv.org/abs/2510.09815)
*Yufei Wang,Adriana Kovashka,Loretta Fernández,Marc N. Coutanche,Seth Wiener*

Main category: cs.CV

TL;DR: 用户可以通过结合图像和文本来学习外语单词，研究发现某些特征对学习效果影响显著，同时AI在理解学习者表现方面有待提高。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索一种新的外语学习模式，即学习者通过结合图像和文本线索来推断生词的含义。

Method: 通过招募学习者参与实验，并分析其在图像-文本配对环境中推断生词含义的表现，研究者们收集并分析了相关数据（图像和文本特征、学习者背景等），并评估了AI系统在预测学习者表现方面的能力。

Result: 研究结果表明，并非所有直观的特征都与学习者的表现有强相关性，这暗示了需要进一步挖掘预测学习效果的关键特征。同时，AI系统在理解和预测学习者表现方面展现出一定的潜力，但仍有改进空间。

Conclusion: 为了提高外语学习效率，需要更深入地研究能够预测学习者成功的关键特征。此外，AI在辅助外语学习和理解学习者认知过程方面具有广阔的发展前景，尤其是在提升其推理能力方面。

Abstract: We investigate a new setting for foreign language learning, where learners
infer the meaning of unfamiliar words in a multimodal context of a sentence
describing a paired image. We conduct studies with human participants using
different image-text pairs. We analyze the features of the data (i.e., images
and texts) that make it easier for participants to infer the meaning of a
masked or unfamiliar word, and what language backgrounds of the participants
correlate with success. We find only some intuitive features have strong
correlations with participant performance, prompting the need for further
investigating of predictive features for success in these tasks. We also
analyze the ability of AI systems to reason about participant performance, and
discover promising future directions for improving this reasoning ability.

</details>


### [13] [Task-Aware Resolution Optimization for Visual Large Language Models](https://arxiv.org/abs/2510.09822)
*Weiqing Luo,Zhen Tan,Yifan Li,Xinyu Zhao,Kwonjoon Lee,Behzad Dariush,Tianlong Chen*

Main category: cs.CV

TL;DR: 大多数现有的视觉语言模型（VLLM）在处理下游任务时假定固定的分辨率，这会导致性能不佳。本文研究了不同视觉语言任务的分辨率偏好，并提出了一种确定最佳分辨率的经验公式。此外，还提出了一种新的参数高效微调技术，以将预训练VLLM的视觉输入分辨率扩展到确定的最佳分辨率。


<details>
  <summary>Details</summary>
Motivation: 现实世界的视觉语言应用需要不同程度的感知粒度，但现有VLLM通常假定固定分辨率，导致性能不佳。

Method: 1. 调查了不同视觉语言任务的分辨率偏好，发现了分辨率偏好与图像复杂度以及VLLM在不同输入分辨率下的不确定性方差之间的相关性。 2. 提出了一种经验公式来确定给定任务的最佳分辨率。 3. 提出了一种新的参数高效微调技术，将预训练VLLM的视觉输入分辨率扩展到最佳分辨率。

Result: 在各种视觉语言任务上的广泛实验验证了所提出方法的有效性。

Conclusion: 提出的方法通过确定任务的最佳分辨率并有效扩展VLLM的输入分辨率，可以提高视觉语言应用的性能。

Abstract: Real-world vision-language applications demand varying levels of perceptual
granularity. However, most existing visual large language models (VLLMs), such
as LLaVA, pre-assume a fixed resolution for downstream tasks, which leads to
subpar performance. To address this problem, we first conduct a comprehensive
and pioneering investigation into the resolution preferences of different
vision-language tasks, revealing a correlation between resolution preferences
with image complexity, and uncertainty variance of the VLLM at different image
input resolutions. Building on this insight, we propose an empirical formula to
determine the optimal resolution for a given vision-language task, combining
these two factors. Second, based on rigorous experiments, we propose a novel
parameter-efficient fine-tuning technique to extend the visual input resolution
of pre-trained VLLMs to the identified optimal resolution. Extensive
experiments on various vision-language tasks validate the effectiveness of our
method.

</details>


### [14] [Post Processing of image segmentation using Conditional Random Fields](https://arxiv.org/abs/2510.09833)
*Aashish Dhawan,Pankaj Bodani,Vishal Garg*

Main category: cs.CV

TL;DR: 本研究旨在为卫星图像分割寻找合适的条件随机场（CRF）以提高图像清晰度。


<details>
  <summary>Details</summary>
Motivation: 由于卫星图像的特征质量较低，其分割输出通常不够清晰。本研究的目的是找到一种合适的条件随机场（CRF）来提高分割后图像的清晰度。

Method: 研究人员评估了不同类型的CRF，以确定哪种最适合他们的目的。他们使用包含低质量特征的卫星图像和高质量航空照片的两个不同数据集对他们的方法进行了评估。在此过程中，他们试验了各种CRF，并对结果进行了比较，以展示不同方法的优缺点。

Result: 研究人员在包含低质量特征的卫星图像和高质量航空照片这两个不同的数据集上评估了他们的方法。他们通过比较不同CRF在这些数据集上的表现来展示不同方法的优缺点。

Conclusion: 通过评估不同类型的CRF在低质量卫星图像和高质量航空照片上的表现，本研究旨在确定最适合提高图像分割清晰度的CRF模型。

Abstract: The output of image the segmentation process is usually not very clear due to
low quality features of Satellite images. The purpose of this study is to find
a suitable Conditional Random Field (CRF) to achieve better clarity in a
segmented image. We started with different types of CRFs and studied them as to
why they are or are not suitable for our purpose. We evaluated our approach on
two different datasets - Satellite imagery having low quality features and high
quality Aerial photographs. During the study we experimented with various CRFs
to find which CRF gives the best results on images and compared our results on
these datasets to show the pitfalls and potentials of different approaches.

</details>


### [15] [Exploration of Incremental Synthetic Non-Morphed Images for Single Morphing Attack Detection](https://arxiv.org/abs/2510.09836)
*David Benavente-Rios,Juan Ruiz Rodriguez,Gustavo Gatica*

Main category: cs.CV

TL;DR: 本研究使用合成人脸数据来提升单图人脸攻击检测（S-MAD）的性能，以解决真实人脸图像因隐私问题导致的数据集规模受限问题。


<details>
  <summary>Details</summary>
Motivation: 隐私顾虑导致大规模真实人脸图像数据集难以获得，限制了单图人脸攻击检测（S-MAD）的发展。

Method: 利用多种人脸变形工具和跨数据集评估方案，并采用增量测试协议，逐步增加合成图像以评估泛化能力。

Result: 实验表明，在现有数据集基础上可控地引入合成图像，或在训练中逐步添加真实图像，可以提高S-MAD的泛化能力。然而，盲目使用合成数据可能导致性能不佳。仅使用合成数据（包括变形和非变形图像）会产生最高的等错误率（EER）。

Conclusion: 在实际应用中，不应仅依赖合成数据进行S-MAD。通过谨慎地将适量的合成数据融入训练过程，或在训练中逐步加入真实数据，可以有效提升S-MAD的泛化能力。

Abstract: This paper investigates the use of synthetic face data to enhance
Single-Morphing Attack Detection (S-MAD), addressing the limitations of
availability of large-scale datasets of bona fide images due to privacy
concerns. Various morphing tools and cross-dataset evaluation schemes were
utilized to conduct this study. An incremental testing protocol was implemented
to assess the generalization capabilities as more and more synthetic images
were added. The results of the experiments show that generalization can be
improved by carefully incorporating a controlled number of synthetic images
into existing datasets or by gradually adding bona fide images during training.
However, indiscriminate use of synthetic data can lead to sub-optimal
performance. Evenmore, the use of only synthetic data (morphed and non-morphed
images) achieves the highest Equal Error Rate (EER), which means in operational
scenarios the best option is not relying only on synthetic data for S-MAD.

</details>


### [16] [Cell Instance Segmentation: The Devil Is in the Boundaries](https://arxiv.org/abs/2510.09848)
*Peixian Liang,Yifan Ding,Yizhe Zhang,Jianxu Chen,Hao Zheng,Hongxiao Wang,Yejia Zhang,Guangyu Meng,Tim Weninger,Michael Niemier,X. Sharon Hu,Danny Z Chen*

Main category: cs.CV

TL;DR: Ceb是一种利用细胞边界特征和标签将前景像素分割成细胞实例的新型像素聚类方法，在细胞实例分割任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的细胞实例分割方法将实例信息分解为像素级目标，可能会丢失细胞形状、曲率和凸性等几何属性。本研究旨在提出一种新的像素聚类方法，以利用细胞边界特征和标签来解决这一挑战。

Method: Ceb方法首先从语义分割生成概率图，然后使用改进的Watershed算法提取前景-前景边界。通过采样边界像素及其邻近的背景-前景边界来构建边界特征表示（边界签名）。接着，使用边界分类器基于边界签名预测二元边界标签。最后，根据预测的边界标签分割或合并相邻区域以获得细胞实例。

Result: Ceb在六个数据集上的实验表明，其在基于语义分割概率图的像素聚类方面优于现有方法，并且在细胞实例分割任务上取得了具有高度竞争力的性能。

Conclusion: Ceb通过利用细胞边界特征和标签，能够有效解决现有像素级方法丢失细胞几何属性的问题，并在细胞实例分割任务上取得了优于现有方法的性能。

Abstract: State-of-the-art (SOTA) methods for cell instance segmentation are based on
deep learning (DL) semantic segmentation approaches, focusing on distinguishing
foreground pixels from background pixels. In order to identify cell instances
from foreground pixels (e.g., pixel clustering), most methods decompose
instance information into pixel-wise objectives, such as distances to
foreground-background boundaries (distance maps), heat gradients with the
center point as heat source (heat diffusion maps), and distances from the
center point to foreground-background boundaries with fixed angles (star-shaped
polygons). However, pixel-wise objectives may lose significant geometric
properties of the cell instances, such as shape, curvature, and convexity,
which require a collection of pixels to represent. To address this challenge,
we present a novel pixel clustering method, called Ceb (for Cell boundaries),
to leverage cell boundary features and labels to divide foreground pixels into
cell instances. Starting with probability maps generated from semantic
segmentation, Ceb first extracts potential foreground-foreground boundaries
with a revised Watershed algorithm. For each boundary candidate, a boundary
feature representation (called boundary signature) is constructed by sampling
pixels from the current foreground-foreground boundary as well as the
neighboring background-foreground boundaries. Next, a boundary classifier is
used to predict its binary boundary label based on the corresponding boundary
signature. Finally, cell instances are obtained by dividing or merging
neighboring regions based on the predicted boundary labels. Extensive
experiments on six datasets demonstrate that Ceb outperforms existing pixel
clustering methods on semantic segmentation probability maps. Moreover, Ceb
achieves highly competitive performance compared to SOTA cell instance
segmentation methods.

</details>


### [17] [Cluster-Aware Prompt Ensemble Learning for Few-Shot Vision-Language Model Adaptation](https://arxiv.org/abs/2510.09867)
*Zhi Chen,Xin Yu,Xiaohui Tao,Yan Li,Zi Huang*

Main category: cs.CV

TL;DR: CAPEL通过在分类logits空间中进行提示集成，并引入聚类感知正则化和自适应提示加权，来改进CLIP等视觉-语言模型（VLM）的零样本迁移性能。


<details>
  <summary>Details</summary>
Motivation: 传统的上下文提示集成方法（如特征平均）会使类别中心偏离真实的类别分布，导致次优结果。

Method: 提出了一种名为CAPEL的框架，该框架保留了上下文提示的聚类性质。CAPEL在分类logits空间中进行提示集成，而不是在特征空间中进行。此外，还引入了聚类保留正则化和自适应提示加权技术来优化提示微调，并处理有缺陷或模糊的提示。

Result: CAPEL在分类logits空间中进行集成，更好地与视觉特征分布对齐，并通过聚类保留正则化确保提示的区分性，通过自适应提示加权提高鲁棒性。

Conclusion: CAPEL通过在分类logits空间中进行提示集成，并结合聚类感知正则化和自适应提示加权，能够有效地解决传统提示集成方法的局限性，从而提升VLM在各种任务上的零样本迁移性能。

Abstract: Vision-language models (VLMs) such as CLIP achieve zero-shot transfer across
various tasks by pre-training on numerous image-text pairs. These models often
benefit from using an ensemble of context prompts to represent a class. Despite
being effective, conventional prompt ensembling that averages textual features
of context prompts often yields suboptimal results. This is because feature
averaging shifts the class centroids away from the true class distribution. To
address this issue, we propose the Cluster-Aware Prompt Ensemble Learning
(CAPEL) framework, which preserves the cluster nature of context prompts. CAPEL
classifies images into one of several class clusters, each represented by a
distinct prompt. Instead of ensembling prompts in the feature space, we perform
ensembling in the classification logits space, aligning better with the visual
feature distribution. To further optimize prompt fine-tuning while maintaining
cluster-specific discriminative power, we introduce a cluster-preserving
regularization term. This ensures that prompts remain distinct and specialized
for different clusters, preventing collapse into a uniform direction.
Additionally, we integrate an adaptive prompt weighting technique to
dynamically adjust the attention weights for flawed or ambiguous prompts,
ensuring robust performance across diverse datasets and tasks.

</details>


### [18] [Fast Self-Supervised depth and mask aware Association for Multi-Object Tracking](https://arxiv.org/abs/2510.09878)
*Milad Khanchi,Maria Amer,Charalambos Poullis*

Main category: cs.CV

TL;DR: 结合深度和掩码特征的自监督学习方法，用于多目标跟踪（MOT），在分割掩码不精确或遮挡时，优于基于 IoU 的方法，并在运动场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的多目标跟踪（MOT）方法在处理相似或被遮挡物体时，依赖于交并比（IoU）关联的方法效果不佳，并且计算分割掩码的 IoU 计算成本高昂。

Method: 提出了一种新的 MOT 方法，该方法利用分割掩码捕捉物体形状，但不计算分割掩码的 IoU。具体来说，它融合了深度图和掩码特征，并通过一个经过自监督学习训练的紧凑型编码器进行处理，以生成稳定的物体表征。这些表征与边界框 IoU 和重新识别特征一起，作为额外的相似性线索用于匹配。深度图由零样本深度估计器生成，物体掩码由可提示的视觉分割模型生成，以获得细粒度的空间线索。

Result: 实验证明，该方法在 SportsMOT 和 DanceTrack 等具有非线性运动、遮挡和拥挤场景的具有挑战性的基准测试中，其跟踪 by 检测（TBD）方法在大多数指标上都优于 TBD 的最新技术水平。在 MOT17 等具有线性运动的较简单基准测试中，也取得了有竞争力的性能。

Conclusion: 本研究提出的方法是第一个使用自监督学习编码器来改进分割掩码而不计算掩码 IoU 的 MOT 方法。通过融合深度和掩码特征，并利用自监督学习，该方法在多目标跟踪任务中提供了更稳定和准确的物体表征，尤其是在复杂场景下。

Abstract: Multi-object tracking (MOT) methods often rely on Intersection-over-Union
(IoU) for association. However, this becomes unreliable when objects are
similar or occluded. Also, computing IoU for segmentation masks is
computationally expensive. In this work, we use segmentation masks to capture
object shapes, but we do not compute segmentation IoU. Instead, we fuse depth
and mask features and pass them through a compact encoder trained
self-supervised. This encoder produces stable object representations, which we
use as an additional similarity cue alongside bounding box IoU and
re-identification features for matching. We obtain depth maps from a zero-shot
depth estimator and object masks from a promptable visual segmentation model to
obtain fine-grained spatial cues. Our MOT method is the first to use the
self-supervised encoder to refine segmentation masks without computing masks
IoU. MOT can be divided into joint detection-ReID (JDR) and
tracking-by-detection (TBD) models. The latter are computationally more
efficient. Experiments of our TBD method on challenging benchmarks with
non-linear motion, occlusion, and crowded scenes, such as SportsMOT and
DanceTrack, show that our method outperforms the TBD state-of-the-art on most
metrics, while achieving competitive performance on simpler benchmarks with
linear motion, such as MOT17.

</details>


### [19] [CHUG: Crowdsourced User-Generated HDR Video Quality Dataset](https://arxiv.org/abs/2510.09879)
*Shreshth Saini,Alan C. Bovik,Neil Birkbeck,Yilin Wang,Balu Adsumilli*

Main category: cs.CV

TL;DR: 该论文提出了CHUG数据集，这是第一个针对用户生成内容HDR视频质量评估的大规模众包数据集，旨在解决现有数据集主要关注专业生成内容而忽视UGC-HDR退化的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的HDR视频质量评估（HDR-VQA）数据集主要关注专业生成内容（PGC），未能充分涵盖用户生成内容（UGC）在不同拍摄条件、编辑和压缩失真下的独特挑战，导致在理解真实世界UGC-HDR退化方面存在差距。

Method: 收集了856个UGC-HDR源视频，并将其转码为多种分辨率和比特率以模拟真实场景，总计5,992个视频。通过Amazon Mechanical Turk进行大规模众包研究，收集了211,848个感知评分。

Result: 创建了CHUG：众包用户生成HDR视频质量数据集，包含5,992个视频和211,848个感知评分，为UGC-HDR视频质量分析提供了基准。

Conclusion: CHUG数据集的建立填补了UGC-HDR视频质量评估的空白，为分析UGC特有的失真提供了基准，并有望推动无参考（NR）HDR-VQA研究的发展，因为它提供了一个大规模、多样化且真实的UGC数据集。

Abstract: High Dynamic Range (HDR) videos enhance visual experiences with superior
brightness, contrast, and color depth. The surge of User-Generated Content
(UGC) on platforms like YouTube and TikTok introduces unique challenges for HDR
video quality assessment (VQA) due to diverse capture conditions, editing
artifacts, and compression distortions. Existing HDR-VQA datasets primarily
focus on professionally generated content (PGC), leaving a gap in understanding
real-world UGC-HDR degradations. To address this, we introduce CHUG:
Crowdsourced User-Generated HDR Video Quality Dataset, the first large-scale
subjective study on UGC-HDR quality. CHUG comprises 856 UGC-HDR source videos,
transcoded across multiple resolutions and bitrates to simulate real-world
scenarios, totaling 5,992 videos. A large-scale study via Amazon Mechanical
Turk collected 211,848 perceptual ratings. CHUG provides a benchmark for
analyzing UGC-specific distortions in HDR videos. We anticipate CHUG will
advance No-Reference (NR) HDR-VQA research by offering a large-scale, diverse,
and real-world UGC dataset. The dataset is publicly available at:
https://shreshthsaini.github.io/CHUG/.

</details>


### [20] [Geometry-Aware Scene Configurations for Novel View Synthesis](https://arxiv.org/abs/2510.09880)
*Minkwan Kim,Changwoon Choi,Young Min Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose scene-adaptive strategies to efficiently allocate representation
capacity for generating immersive experiences of indoor environments from
incomplete observations. Indoor scenes with multiple rooms often exhibit
irregular layouts with varying complexity, containing clutter, occlusion, and
flat walls. We maximize the utilization of limited resources with guidance from
geometric priors, which are often readily available after pre-processing
stages. We record observation statistics on the estimated geometric scaffold
and guide the optimal placement of bases, which greatly improves upon the
uniform basis arrangements adopted by previous scalable Neural Radiance Field
(NeRF) representations. We also suggest scene-adaptive virtual viewpoints to
compensate for geometric deficiencies inherent in view configurations in the
input trajectory and impose the necessary regularization. We present a
comprehensive analysis and discussion regarding rendering quality and memory
requirements in several large-scale indoor scenes, demonstrating significant
enhancements compared to baselines that employ regular placements.

</details>


### [21] [LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates](https://arxiv.org/abs/2510.09881)
*Minkwan Kim,Seungmin Lee,Junho Kim,Young Min Kim*

Main category: cs.CV

TL;DR: LTGS是一种高效的场景表示方法，可以处理因稀疏视图更新而导致的日常场景变化，即使在初始输入图像不完整或非结构化的情况下也能稳健地模拟场景的长期变化。


<details>
  <summary>Details</summary>
Motivation: 日常环境的视觉合成因频繁的场景变化而面临挑战，这需要空间和时间上的密集观测。现有的方法难以处理由稀疏的、非结构化的捕捉组成的非约束性场景。

Method: LTGS通过将对象构建为模板高斯，并对这些模板进行进一步的细化，以适应基于少量观测的时间变化环境。该框架通过简单的变换即可跨多个时间步进行泛化，从而提高了3D环境时间演变的扩展性。

Result: 实验证明，LTGS框架在重建质量上优于其他基线方法，并且能够实现快速、轻量级的更新。

Conclusion: LTGS提供了一种高效且可扩展的解决方案，用于从稀疏的、非结构化的捕捉中进行新视角合成，能够有效处理日常场景的长期变化。

Abstract: Recent advances in novel-view synthesis can create the photo-realistic
visualization of real-world environments from conventional camera captures.
However, acquiring everyday environments from casual captures faces challenges
due to frequent scene changes, which require dense observations both spatially
and temporally. We propose long-term Gaussian scene chronology from sparse-view
updates, coined LTGS, an efficient scene representation that can embrace
everyday changes from highly under-constrained casual captures. Given an
incomplete and unstructured Gaussian splatting representation obtained from an
initial set of input images, we robustly model the long-term chronology of the
scene despite abrupt movements and subtle environmental variations. We
construct objects as template Gaussians, which serve as structural, reusable
priors for shared object tracks. Then, the object templates undergo a further
refinement pipeline that modulates the priors to adapt to temporally varying
environments based on few-shot observations. Once trained, our framework is
generalizable across multiple time steps through simple transformations,
significantly enhancing the scalability for a temporal evolution of 3D
environments. As existing datasets do not explicitly represent the long-term
real-world changes with a sparse capture setup, we collect real-world datasets
to evaluate the practicality of our pipeline. Experiments demonstrate that our
framework achieves superior reconstruction quality compared to other baselines
while enabling fast and light-weight updates.

</details>


### [22] [An uncertainty-aware framework for data-efficient multi-view animal pose estimation](https://arxiv.org/abs/2510.09903)
*Lenny Aharon,Keemin Lee,Karan Sikka,Selmaan Chettih,Cole Hurwitz,Liam Paninski,Matthew R Whiteway*

Main category: cs.CV

TL;DR: 该框架结合了新的训练和后处理技术以及模型蒸馏，以提高多视角动物姿态估计的准确性和不确定性估计，即使在标记数据有限的情况下也能实现。


<details>
  <summary>Details</summary>
Motivation: 当前的多视角动物姿态估计方法在标记数据有限的情况下难以实现精确跟踪，并且不确定性估计较差。

Method: 提出了一种结合了新的训练和后处理技术以及模型蒸馏的综合框架。该框架包括多视角Transformer（MVT）、补丁掩码方案、几何一致性（通过3D增强和三角测量损失）、扩展的集成卡尔曼平滑器（EKS）后处理器以及方差膨胀技术。此外，还设计了一种利用改进的EKS预测和不确定性估计来生成高质量伪标签的模型蒸馏程序。

Result: 该框架在三类不同的动物（苍蝇、老鼠、山雀）上的表现优于现有方法，每个组件都提供了互补的优势。

Conclusion: 该框架是一个实用的、可感知的系统，用于可靠的姿态估计，能够在实际数据约束下进行下游行为分析。

Abstract: Multi-view pose estimation is essential for quantifying animal behavior in
scientific research, yet current methods struggle to achieve accurate tracking
with limited labeled data and suffer from poor uncertainty estimates. We
address these challenges with a comprehensive framework combining novel
training and post-processing techniques, and a model distillation procedure
that leverages the strengths of these techniques to produce a more efficient
and effective pose estimator. Our multi-view transformer (MVT) utilizes
pretrained backbones and enables simultaneous processing of information across
all views, while a novel patch masking scheme learns robust cross-view
correspondences without camera calibration. For calibrated setups, we
incorporate geometric consistency through 3D augmentation and a triangulation
loss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to
the nonlinear case and enhance uncertainty quantification via a variance
inflation technique. Finally, to leverage the scaling properties of the MVT, we
design a distillation procedure that exploits improved EKS predictions and
uncertainty estimates to generate high-quality pseudo-labels, thereby reducing
dependence on manual labels. Our framework components consistently outperform
existing methods across three diverse animal species (flies, mice, chickadees),
with each component contributing complementary benefits. The result is a
practical, uncertainty-aware system for reliable pose estimation that enables
downstream behavioral analyses under real-world data constraints.

</details>


### [23] [SpectralCA: Bi-Directional Cross-Attention for Next-Generation UAV Hyperspectral Vision](https://arxiv.org/abs/2510.09912)
*D. V. Brovko*

Main category: cs.CV

TL;DR: 本文提出了一种集成高光谱成像（HSI）的深度学习架构，用于增强无人机（UAV）在复杂环境下的感知能力，以实现导航、物体检测和地形分类。


<details>
  <summary>Details</summary>
Motivation: 无人机在复杂环境中可靠导航的需求日益增长，而传统导航方法受干扰、可见性差或伪装等因素影响。高光谱成像（HSI）为无人机计算机视觉提供了独特的机会，能够进行精细的材料识别和物体区分，这对于导航、监视、农业和环境监测至关重要。

Method: 通过修改 Mobile 3D Vision Transformer (MDvT)，引入了提出的 SpectralCA 模块。该模块采用双向交叉注意力融合光谱和空间特征，从而在减少参数和推理时间的同时提高精度。

Result: 在 WHU-Hi-HongHu 数据集上进行了实验评估，并使用总体准确率、平均准确率和 Kappa 系数评估结果。实验结果表明，所提出的架构提高了无人机的感知效率。

Conclusion: 所提出的深度学习架构能够有效提升无人机在复杂环境下的导航、物体识别和环境监测任务的效率，并支持实时操作。

Abstract: The relevance of this research lies in the growing demand for unmanned aerial
vehicles (UAVs) capable of operating reliably in complex environments where
conventional navigation becomes unreliable due to interference, poor
visibility, or camouflage. Hyperspectral imaging (HSI) provides unique
opportunities for UAV-based computer vision by enabling fine-grained material
recognition and object differentiation, which are critical for navigation,
surveillance, agriculture, and environmental monitoring. The aim of this work
is to develop a deep learning architecture integrating HSI into UAV perception
for navigation, object detection, and terrain classification. Objectives
include: reviewing existing HSI methods, designing a hybrid 2D/3D convolutional
architecture with spectral-spatial cross-attention, training, and benchmarking.
The methodology is based on the modification of the Mobile 3D Vision
Transformer (MDvT) by introducing the proposed SpectralCA block. This block
employs bi-directional cross-attention to fuse spectral and spatial features,
enhancing accuracy while reducing parameters and inference time. Experimental
evaluation was conducted on the WHU-Hi-HongHu dataset, with results assessed
using Overall Accuracy, Average Accuracy, and the Kappa coefficient. The
findings confirm that the proposed architecture improves UAV perception
efficiency, enabling real-time operation for navigation, object recognition,
and environmental monitoring tasks.
  Keywords: SpectralCA, deep learning, computer vision, hyperspectral imaging,
unmanned aerial vehicle, object detection, semi-supervised learning.

</details>


### [24] [HeadsUp! High-Fidelity Portrait Image Super-Resolution](https://arxiv.org/abs/2510.09924)
*Renjie Li,Zihao Zhu,Xiaoyu Wang,Zhengzhong Tu*

Main category: cs.CV

TL;DR: 该研究提出了HeadsUp，一个用于人像图像超分辨率的单步扩散模型，解决了现有方法的边界伪影问题，并通过面部监督和参考机制提升了人像恢复效果，同时发布了PortraitSR-4K数据集。


<details>
  <summary>Details</summary>
Motivation: 现有图像超分辨率技术在处理包含人脸和自然背景的人像照片时，通常需要结合通用模型和人脸专用模型，这种混合方法会在人脸区域周围产生不自然的边界伪影，而人脸的保真度对人类感知尤为重要。

Method: 提出了一种名为HeadsUp的单步扩散模型，通过引入面部监督机制来指导模型关注人脸区域，并结合基于参考的机制来辅助身份恢复，减少低质量人脸恢复中的模糊性。此外，还构建了一个名为PortraitSR-4K的高质量4K人像图像超分辨率数据集。

Result: HeadsUp在PortraitISR任务上取得了最先进的性能，同时在通用图像和已对齐人脸数据集上也保持了相当或更高的性能。

Conclusion: HeadsUp作为一个单一模型，能够端到端地无缝恢复和放大高质量的人像图像，有效解决了现有混合方法的局限性，并在多个数据集上展现出优越的性能。

Abstract: Portrait pictures, which typically feature both human subjects and natural
backgrounds, are one of the most prevalent forms of photography on social
media. Existing image super-resolution (ISR) techniques generally focus either
on generic real-world images or strictly aligned facial images (i.e., face
super-resolution). In practice, separate models are blended to handle portrait
photos: the face specialist model handles the face region, and the general
model processes the rest. However, these blending approaches inevitably
introduce blending or boundary artifacts around the facial regions due to
different model training recipes, while human perception is particularly
sensitive to facial fidelity. To overcome these limitations, we study the
portrait image supersolution (PortraitISR) problem, and propose HeadsUp, a
single-step diffusion model that is capable of seamlessly restoring and
upscaling portrait images in an end-to-end manner. Specifically, we build our
model on top of a single-step diffusion model and develop a face supervision
mechanism to guide the model in focusing on the facial region. We then
integrate a reference-based mechanism to help with identity restoration,
reducing face ambiguity in low-quality face restoration. Additionally, we have
built a high-quality 4K portrait image ISR dataset dubbed PortraitSR-4K, to
support model training and benchmarking for portrait images. Extensive
experiments show that HeadsUp achieves state-of-the-art performance on the
PortraitISR task while maintaining comparable or higher performance on both
general image and aligned face datasets.

</details>


### [25] [Denoising Diffusion as a New Framework for Underwater Images](https://arxiv.org/abs/2510.09934)
*Nilesh Jain,Elie Alhajjar*

Main category: cs.CV

TL;DR: Underwater images are essential for ocean research but suffer from poor quality. This paper proposes expanding datasets with diverse image types (stereo, wide-angled, etc.) using denoising diffusion models and enhancing images with Controlnet to improve marine ecosystem studies.


<details>
  <summary>Details</summary>
Motivation: Underwater images are crucial for ocean research but are often of poor quality due to environmental factors, limiting their usefulness. Existing datasets also lack diversity and quality, hindering research.

Method: The paper proposes using a denoising diffusion model to expand image datasets with various types (stereo, wide-angled, macro, close-up) and employing Controlnet to enhance image quality for better dataset evaluation.

Result: The proposed methods aim to overcome limitations of current underwater image datasets by increasing diversity and quality, thereby improving the study of marine ecosystems.

Conclusion: By expanding datasets with diverse image types using denoising diffusion models and enhancing images with Controlnet, this paper offers a new approach to improve the quality and utility of underwater images for marine ecosystem research.

Abstract: Underwater images play a crucial role in ocean research and marine
environmental monitoring since they provide quality information about the
ecosystem. However, the complex and remote nature of the environment results in
poor image quality with issues such as low visibility, blurry textures, color
distortion, and noise. In recent years, research in image enhancement has
proven to be effective but also presents its own limitations, like poor
generalization and heavy reliance on clean datasets. One of the challenges
herein is the lack of diversity and the low quality of images included in these
datasets. Also, most existing datasets consist only of monocular images, a fact
that limits the representation of different lighting conditions and angles. In
this paper, we propose a new plan of action to overcome these limitations. On
one hand, we call for expanding the datasets using a denoising diffusion model
to include a variety of image types such as stereo, wide-angled, macro, and
close-up images. On the other hand, we recommend enhancing the images using
Controlnet to evaluate and increase the quality of the corresponding datasets,
and hence improve the study of the marine ecosystem.
  Tags - Underwater Images, Denoising Diffusion, Marine ecosystem, Controlnet

</details>


### [26] [Semi-disentangled spatiotemporal implicit neural representations of longitudinal neuroimaging data for trajectory classification](https://arxiv.org/abs/2510.09936)
*Agampreet Aulakh,Nils D. Forkert,Matthias Wilms*

Main category: cs.CV

TL;DR: 本研究提出一种新颖的、完全数据驱动的方法，利用隐式神经表征（INR）对大脑衰老轨迹进行建模和分类，克服了传统深度学习方法在处理离散、不规则采样神经影像数据方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于个体和人群之间在时间、空间采样模式上的差异，传统深度学习方法难以处理离散的纵向神经影像数据，无法有效表征连续的生物学过程，因此需要新的方法来解决这些挑战。

Method: 提出了一种新颖的INR架构，能够部分解耦空间和时间轨迹参数，并设计了一个直接在INR参数空间操作的高效框架，用于对大脑衰老轨迹进行分类。使用生物学启发的轨迹模拟生成了规则和不规则采样的时间点上的T1加权3D MRI数据，用于训练和评估。

Result: 在不规则采样实验中，所提出的INR方法在大脑衰老轨迹分类任务上达到了81.3%的准确率，优于标准的深度学习基线模型（73.7%）。

Conclusion: 本研究提出的基于INR的方法能够有效地表示和分类大脑衰老轨迹，尤其是在处理不规则采样数据方面，为分析纵向神经影像数据提供了一种有前景的新途径。

Abstract: The human brain undergoes dynamic, potentially pathology-driven, structural
changes throughout a lifespan. Longitudinal Magnetic Resonance Imaging (MRI)
and other neuroimaging data are valuable for characterizing trajectories of
change associated with typical and atypical aging. However, the analysis of
such data is highly challenging given their discrete nature with different
spatial and temporal image sampling patterns within individuals and across
populations. This leads to computational problems for most traditional deep
learning methods that cannot represent the underlying continuous biological
process. To address these limitations, we present a new, fully data-driven
method for representing aging trajectories across the entire brain by modelling
subject-specific longitudinal T1-weighted MRI data as continuous functions
using Implicit Neural Representations (INRs). Therefore, we introduce a novel
INR architecture capable of partially disentangling spatial and temporal
trajectory parameters and design an efficient framework that directly operates
on the INRs' parameter space to classify brain aging trajectories. To evaluate
our method in a controlled data environment, we develop a biologically grounded
trajectory simulation and generate T1-weighted 3D MRI data for 450 healthy and
dementia-like subjects at regularly and irregularly sampled timepoints. In the
more realistic irregular sampling experiment, our INR-based method achieves
81.3% accuracy for the brain aging trajectory classification task,
outperforming a standard deep learning baseline model (73.7%).

</details>


### [27] [Explainable Human-in-the-Loop Segmentation via Critic Feedback Signals](https://arxiv.org/abs/2510.09945)
*Pouya Shaeri,Ryan T. Woo,Yasaman Mohammadpour,Ariane Middel*

Main category: cs.CV

TL;DR: 提出一种包含人类反馈的交互式分割框架，通过纠正模型错误来提高分割鲁棒性，减少标注成本。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型在真实世界中表现不佳，依赖虚假关联而非真实物体边界。

Method: 将人类纠正视为干预信号，通过在视觉相似图像间传播修正信息，引导模型关注语义特征而非数据集特定伪影。通过迭代反馈，系统不断优化表示，提高泛化能力。

Result: 在 cubemap 数据上分割精度提高最多 9 mIoU 点（相对提高 12-15%），标注成本降低 3-4 倍，同时在基准数据集上保持竞争力。

Conclusion: 该框架提供了一种实用方法，用于构建准确、鲁棒、数据高效且能适应真实世界应用的分割系统。

Abstract: Segmentation models achieve high accuracy on benchmarks but often fail in
real-world domains by relying on spurious correlations instead of true object
boundaries. We propose a human-in-the-loop interactive framework that enables
interventional learning through targeted human corrections of segmentation
outputs. Our approach treats human corrections as interventional signals that
show when reliance on superficial features (e.g., color or texture) is
inappropriate. The system learns from these interventions by propagating
correction-informed edits across visually similar images, effectively steering
the model toward robust, semantically meaningful features rather than
dataset-specific artifacts. Unlike traditional annotation approaches that
simply provide more training data, our method explicitly identifies when and
why the model fails and then systematically corrects these failure modes across
the entire dataset. Through iterative human feedback, the system develops
increasingly robust representations that generalize better to novel domains and
resist artifactual correlations. We demonstrate that our framework improves
segmentation accuracy by up to 9 mIoU points (12-15\% relative improvement) on
challenging cubemap data and yields 3-4$\times$ reductions in annotation effort
compared to standard retraining, while maintaining competitive performance on
benchmark datasets. This work provides a practical framework for researchers
and practitioners seeking to build segmentation systems that are accurate,
robust to dataset biases, data-efficient, and adaptable to real-world domains
such as urban climate monitoring and autonomous driving.

</details>


### [28] [A Multi-Strategy Framework for Enhancing Shatian Pomelo Detection in Real-World Orchards](https://arxiv.org/abs/2510.09948)
*Pan Wang,Yihao Hu,Xiaodong Bai,Aiping Yang,Xiangxiang Li,Meiping Ding,Jianguo Yao*

Main category: cs.CV

TL;DR: Shatian pomelo的自动化检测是满足商业需求的必要条件。本研究提出了一个多策略框架来解决成像设备、光照条件、尺度变化和遮挡等挑战。通过构建STP-AgriData数据集、应用数据增强、设计REAS-Det网络（包含RFAConv、C3RFEM、MultiSEAM模块）和soft-NMS，显著提高了检测精度。实验结果显示，本方法在精度、召回率和mAP方面均优于现有SOTA方法。


<details>
  <summary>Details</summary>
Motivation: Shatian pomelo作为一种具有大市场规模的特产农产品，其自动化检测对于确保数量准确性和满足精益生产的商业需求至关重要。现有方法在真实场景下性能会下降，因此有必要进行改进。

Method: 1. 构建了一个包含真实果园图像和网络数据的多场景数据集STP-AgriData，以解决不同成像设备和复杂环境带来的色调变化问题。
2. 应用了调整对比度和改变亮度等数据增强方法，以模拟不稳定的光照条件。
3. 设计了一个REAS-Det网络来处理尺度变化和遮挡问题：
    - 针对尺度变化，设计了RFAConv和C3RFEM模块来扩展和增强感受野。
    - 针对遮挡问题，引入了MultiSEAM（多尺度、多头特征选择结构）和soft-NMS来提高对遮挡的处理能力。

Result: 实验结果达到了87.6%的精度(P)，74.9%的召回率(R)，82.8%的mAP@.50，以及53.3%的mAP@.50:.95。所提出的网络在性能上优于其他最先进的检测方法。

Conclusion: 本研究提出的多策略框架和REAS-Det网络能够有效解决Shatian pomelo在实际应用中面临的成像设备、光照、尺度变化和遮挡等挑战，并取得了优于现有方法的检测性能。

Abstract: As a specialty agricultural product with a large market scale, Shatian pomelo
necessitates the adoption of automated detection to ensure accurate quantity
and meet commercial demands for lean production. Existing research often
involves specialized networks tailored for specific theoretical or dataset
scenarios, but these methods tend to degrade performance in real-world. Through
analysis of factors in this issue, this study identifies four key challenges
that affect the accuracy of Shatian pomelo detection: imaging devices, lighting
conditions, object scale variation, and occlusion. To mitigate these
challenges, a multi-strategy framework is proposed in this paper. Firstly, to
effectively solve tone variation introduced by diverse imaging devices and
complex orchard environments, we utilize a multi-scenario dataset,
STP-AgriData, which is constructed by integrating real orchard images with
internet-sourced data. Secondly, to simulate the inconsistent illumination
conditions, specific data augmentations such as adjusting contrast and changing
brightness, are applied to the above dataset. Thirdly, to address the issues of
object scale variation and occlusion in fruit detection, an REAS-Det network is
designed in this paper. For scale variation, RFAConv and C3RFEM modules are
designed to expand and enhance the receptive fields. For occlusion variation, a
multi-scale, multi-head feature selection structure (MultiSEAM) and soft-NMS
are introduced to enhance the handling of occlusion issues to improve detection
accuracy. The results of these experiments achieved a precision(P) of 87.6%, a
recall (R) of 74.9%, a mAP@.50 of 82.8%, and a mAP@.50:.95 of 53.3%. Our
proposed network demonstrates superior performance compared to other
state-of-the-art detection methods.

</details>


### [29] [J-RAS: Enhancing Medical Image Segmentation via Retrieval-Augmented Joint Training](https://arxiv.org/abs/2510.09953)
*Salma J. Ahmed,Emad A. Mohammed,Azam Asilian Bidgoli*

Main category: cs.CV

TL;DR: J-RAS是一种联合训练方法，通过结合分割模型和检索模型来改进医学图像分割，解决了数据量不足和泛化能力差的问题，并在多个数据集和模型上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 手动分割耗时、昂贵且易出错，AI方法需要大量标注数据且泛化能力不足。

Method: 提出联合检索增强分割（J-RAS）方法，联合优化分割模型和检索模型，使分割模型能利用检索到的图像-掩模对来丰富其解剖学理解，检索模型则学习超越简单视觉相似性的分割相关特征。

Result: 在ACDC和M&Ms数据集上，J-RAS与U-Net、TransUNet、SAM和SegFormer等多种分割模型结合使用，均显示出持续的性能提升。例如，在ACDC数据集上，SegFormer结合J-RAS后的平均Dice分数从0.8708提高到0.9115，平均Hausdorff距离从1.8130降低到1.1489。

Conclusion: J-RAS方法在医学图像分割任务中展现出有效性和跨模型、跨数据集的泛化能力。

Abstract: Image segmentation, the process of dividing images into meaningful regions,
is critical in medical applications for accurate diagnosis, treatment planning,
and disease monitoring. Although manual segmentation by healthcare
professionals produces precise outcomes, it is time-consuming, costly, and
prone to variability due to differences in human expertise. Artificial
intelligence (AI)-based methods have been developed to address these
limitations by automating segmentation tasks; however, they often require
large, annotated datasets that are rarely available in practice and frequently
struggle to generalize across diverse imaging conditions due to inter-patient
variability and rare pathological cases. In this paper, we propose Joint
Retrieval Augmented Segmentation (J-RAS), a joint training method for guided
image segmentation that integrates a segmentation model with a retrieval model.
Both models are jointly optimized, enabling the segmentation model to leverage
retrieved image-mask pairs to enrich its anatomical understanding, while the
retrieval model learns segmentation-relevant features beyond simple visual
similarity. This joint optimization ensures that retrieval actively contributes
meaningful contextual cues to guide boundary delineation, thereby enhancing the
overall segmentation performance. We validate J-RAS across multiple
segmentation backbones, including U-Net, TransUNet, SAM, and SegFormer, on two
benchmark datasets: ACDC and M&Ms, demonstrating consistent improvements. For
example, on the ACDC dataset, SegFormer without J-RAS achieves a mean Dice
score of 0.8708$\pm$0.042 and a mean Hausdorff Distance (HD) of
1.8130$\pm$2.49, whereas with J-RAS, the performance improves substantially to
a mean Dice score of 0.9115$\pm$0.031 and a mean HD of 1.1489$\pm$0.30. These
results highlight the method's effectiveness and its generalizability across
architectures and datasets.

</details>


### [30] [Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making](https://arxiv.org/abs/2510.09981)
*Fan Zuo,Donglin Zhou,Jingqin Gao,Kaan Ozbay*

Main category: cs.CV

TL;DR: 该研究提出了一个端到端的AI框架，利用现有的交通摄像头基础设施进行大规模、高分辨率的纵向交通流量分析。通过微调的YOLOv11模型提取交通密度和分类指标，并引入基于图的视点归一化方法来处理动态摄像头视图，同时集成领域特定的LLM来处理海量视频数据并生成交通模式的自动摘要。在纽约市拥堵收费计划初期进行了验证，结果显示了该框架在政策相关交通监测方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有交通监测方法成本高昂，且基于视频分析的方法在处理动态摄像头和海量数据时存在困难。因此，需要一种经济高效且可扩展的解决方案来利用现有的交通摄像头基础设施进行大规模、高分辨率的交通流量分析。

Method: 1. 使用在本地化城市场景上微调的YOLOv11模型，实时提取多模态交通密度和分类指标。
2. 引入一种新颖的基于图的视点归一化方法，以解决非固定（平移-倾斜-变焦）摄像头带来的不一致性。
3. 集成领域特定的LLM，处理来自全天候视频流的海量数据，生成不断变化的交通模式的自动化摘要。
4. 使用来自约1000个交通摄像头的超过900万张图像，在纽约市拥堵收费计划的早期推广阶段进行了系统验证。

Result: 1. 纽约市拥堵缓解区内工作日载客车辆密度下降了9%。
2. 早期卡车通行量有所减少，但有反弹迹象。
3. 在走廊和区域尺度上，行人与骑行者活动持续增加。
4. 基于示例的提示提高了LLM的数值准确性并减少了幻觉。

Conclusion: 该AI框架是一个切实可行、适用于现有基础设施的解决方案，能够以很少的人工干预进行大规模、政策相关的交通监测。

Abstract: Accurate, scalable traffic monitoring is critical for real-time and long-term
transportation management, particularly during disruptions such as natural
disasters, large construction projects, or major policy changes like New York
City's first-in-the-nation congestion pricing program. However, widespread
sensor deployment remains limited due to high installation, maintenance, and
data management costs. While traffic cameras offer a cost-effective
alternative, existing video analytics struggle with dynamic camera viewpoints
and massive data volumes from large camera networks. This study presents an
end-to-end AI-based framework leveraging existing traffic camera infrastructure
for high-resolution, longitudinal analysis at scale. A fine-tuned YOLOv11
model, trained on localized urban scenes, extracts multimodal traffic density
and classification metrics in real time. To address inconsistencies from
non-stationary pan-tilt-zoom cameras, we introduce a novel graph-based
viewpoint normalization method. A domain-specific large language model was also
integrated to process massive data from a 24/7 video stream to generate
frequent, automated summaries of evolving traffic patterns, a task far
exceeding manual capabilities. We validated the system using over 9 million
images from roughly 1,000 traffic cameras during the early rollout of NYC
congestion pricing in 2025. Results show a 9% decline in weekday passenger
vehicle density within the Congestion Relief Zone, early truck volume
reductions with signs of rebound, and consistent increases in pedestrian and
cyclist activity at corridor and zonal scales. Experiments showed that
example-based prompts improved LLM's numerical accuracy and reduced
hallucinations. These findings demonstrate the framework's potential as a
practical, infrastructure-ready solution for large-scale, policy-relevant
traffic monitoring with minimal human intervention.

</details>


### [31] [FlareX: A Physics-Informed Dataset for Lens Flare Removal via 2D Synthesis and 3D Rendering](https://arxiv.org/abs/2510.09995)
*Lishen Qu,Zhihao Liu,Jinshan Pan,Shihao Zhou,Jinglei Shi,Duosheng Chen,Jufeng Yang*

Main category: cs.CV

TL;DR: 提出了一种新的物理信息方法来生成镜头眩光数据，并创建了一个名为 FlareX 的混合 2D/3D 数据集，以解决现有合成数据缺乏多样性和物理真实性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据集通过叠加 2D 人工眩光模板来合成，缺乏眩光多样性且忽视物理原理，导致模型泛化能力差。

Method: 提出了一种新的物理信息方法，包括参数化模板创建、光照感知 2D 合成和基于物理引擎的 3D 渲染，最终生成包含 2D 和 3D 数据的 FlareX 数据集。

Result: FlareX 数据集包含 9,500 个 2D 模板和 3,000 个 3D 渲染图像对。还设计了一种掩蔽方法来评估真实世界图像上的模型性能。实验证明了该方法和数据集的有效性。

Conclusion: 所提出的物理信息方法和 FlareX 数据集能够有效地解决现有镜头眩光数据集的局限性，并提高模型在真实世界场景中的泛化能力。

Abstract: Lens flare occurs when shooting towards strong light sources, significantly
degrading the visual quality of images. Due to the difficulty in capturing
flare-corrupted and flare-free image pairs in the real world, existing datasets
are typically synthesized in 2D by overlaying artificial flare templates onto
background images. However, the lack of flare diversity in templates and the
neglect of physical principles in the synthesis process hinder models trained
on these datasets from generalizing well to real-world scenarios. To address
these challenges, we propose a new physics-informed method for flare data
generation, which consists of three stages: parameterized template creation,
the laws of illumination-aware 2D synthesis, and physical engine-based 3D
rendering, which finally gives us a mixed flare dataset that incorporates both
2D and 3D perspectives, namely FlareX. This dataset offers 9,500 2D templates
derived from 95 flare patterns and 3,000 flare image pairs rendered from 60 3D
scenes. Furthermore, we design a masking approach to obtain real-world
flare-free images from their corrupted counterparts to measure the performance
of the model on real-world images. Extensive experiments demonstrate the
effectiveness of our method and dataset.

</details>


### [32] [BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes](https://arxiv.org/abs/2510.09996)
*Lishen Qu,Zhihao Liu,Shihao Zhou,Yaqi Luo,Jie Liang,Hui Zeng,Lei Zhang,Jufeng Yang*

Main category: cs.CV

TL;DR: 本篇论文提出了一种名为BurstDeflicker的数据集，用于解决短曝光图像中由滚动快门相机和交流电照明引起的闪烁问题，并为闪烁去除研究提供了基准。


<details>
  <summary>Details</summary>
Motivation: 交流电照明下的滚动快门相机拍摄的短曝光图像存在闪烁伪影，影响图像质量和目标检测等高级任务，但缺乏大规模真实数据集阻碍了相关研究。

Method: 提出了一种名为BurstDeflicker的数据集，该数据集通过三种策略构建：1. 基于Retinex的合成管线，用于生成具有可控属性（强度、区域、频率）的闪烁模式；2. 捕捉4000张真实世界闪烁图像，以学习闪烁的空间和时间特征；3. 提出一种绿幕方法，用于在动态场景中引入运动并保留闪烁退化。

Result: 通过全面的实验证明了该数据集的有效性及其在推动闪烁去除研究方面的潜力。

Conclusion: 所提出的BurstDeflicker数据集能够有效应对闪烁伪影问题，并为相关研究提供了一个可扩展的基准。

Abstract: Flicker artifacts in short-exposure images are caused by the interplay
between the row-wise exposure mechanism of rolling shutter cameras and the
temporal intensity variations of alternating current (AC)-powered lighting.
These artifacts typically appear as uneven brightness distribution across the
image, forming noticeable dark bands. Beyond compromising image quality, this
structured noise also affects high-level tasks, such as object detection and
tracking, where reliable lighting is crucial. Despite the prevalence of
flicker, the lack of a large-scale, realistic dataset has been a significant
barrier to advancing research in flicker removal. To address this issue, we
present BurstDeflicker, a scalable benchmark constructed using three
complementary data acquisition strategies. First, we develop a Retinex-based
synthesis pipeline that redefines the goal of flicker removal and enables
controllable manipulation of key flicker-related attributes (e.g., intensity,
area, and frequency), thereby facilitating the generation of diverse flicker
patterns. Second, we capture 4,000 real-world flicker images from different
scenes, which help the model better understand the spatial and temporal
characteristics of real flicker artifacts and generalize more effectively to
wild scenarios. Finally, due to the non-repeatable nature of dynamic scenes, we
propose a green-screen method to incorporate motion into image pairs while
preserving real flicker degradation. Comprehensive experiments demonstrate the
effectiveness of our dataset and its potential to advance research in flicker
removal.

</details>


### [33] [MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output](https://arxiv.org/abs/2510.10011)
*Yanyuan Chen,Dexuan Xu,Yu Huang,Songkun Zhan,Hanpin Wang,Dongxue Chen,Xueping Wang,Meikang Qiu,Hang Li*

Main category: cs.CV

TL;DR: MIMO模型通过多模态输入和输出解决了医学视觉问答的局限性，实现了视觉线索和文本指令的结合以及文本输出与图像关键区域的关联。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型在输入端仅依赖文本指令，缺乏对图像视觉线索的直接理解；在输出端仅提供文本答案，缺乏与图像关键区域的关联。MIMO旨在解决这些问题。

Method: 提出了一种名为MIMO的统一医学视觉语言模型，采用了视觉指代的**多模态输入**（Multimodal Input with visual referring）和像素接地（pixel grounding）的**多模态输出**（Multimodal Output）。为克服数据稀缺性，提出了包含895K样本的MIMOSeg数据集。

Result: 实验证明，MIMO模型能够独特地结合视觉指代和像素接地能力，这是先前模型所不具备的。MIMO在多个下游医学多模态任务上进行了验证，取得了良好的效果。

Conclusion: MIMO模型通过引入视觉指代的多模态输入和像素接地的多模态输出，有效地解决了现有医学视觉语言模型的局限性，并提供了强大的医学多模态数据集MIMOSeg。

Abstract: Currently, medical vision language models are widely used in medical vision
question answering tasks. However, existing models are confronted with two
issues: for input, the model only relies on text instructions and lacks direct
understanding of visual clues in the image; for output, the model only gives
text answers and lacks connection with key areas in the image. To address these
issues, we propose a unified medical vision language model MIMO, with visual
referring Multimodal Input and pixel grounding Multimodal Output. MIMO can not
only combine visual clues and textual instructions to understand complex
medical images and semantics, but can also ground medical terminologies in
textual output within the image. To overcome the scarcity of relevant data in
the medical field, we propose MIMOSeg, a comprehensive medical multimodal
dataset including 895K samples. MIMOSeg is constructed from four different
perspectives, covering basic instruction following and complex question
answering with multimodal input and multimodal output. We conduct experiments
on several downstream medical multimodal tasks. Extensive experimental results
verify that MIMO can uniquely combine visual referring and pixel grounding
capabilities, which are not available in previous models.

</details>


### [34] [Q-Adapter: Visual Query Adapter for Extracting Textually-related Features in Video Captioning](https://arxiv.org/abs/2510.10022)
*Junan Chen,Trung Thanh Nguyen,Takahiro Komamizu,Ichiro Ide*

Main category: cs.CV

TL;DR: 提出了一种名为Q-Adapter的轻量级视觉适配器模块，用于视频描述任务，通过引入可学习的查询令牌和门控层来增强多模态大语言模型（MLLM），实现了参数高效的微调，并在MSR-VTT和MSVD数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频描述方法依赖于大规模预训练模型，但全模型微调的计算成本随着模型规模的增加而变得过高。参数高效微调（PEFT）方法虽然有前景，但主要关注多模态大语言模型（MLLM）的语言部分，对视觉信息的理解不足。因此，需要一种能够有效处理视觉信息并实现参数高效微调的方法。

Method: 提出Q-Adapter，一个轻量级的视觉适配器模块。该模块在视觉编码器中引入了可学习的查询令牌和门控层，能够有效地提取与字幕相关的稀疏特征，而无需外部文本监督。通过这种方式，Q-Adapter能够对MLLM进行高效微调，以适应视频描述任务。

Result: 在MSR-VTT和MSVD两个视频描述数据集上进行了评估。Q-Adapter在BLEU@4、METEOR、ROUGE-L和CIDEr等指标上，达到了参数高效微调方法（PEFT）中的最先进性能。与全模型微调方法相比，Q-Adapter仅使用了1.4%的参数，却取得了具有竞争力的性能。此外，还分析了关键超参数和设计选择对微调效果的影响。

Conclusion: Q-Adapter在平衡描述质量和参数效率方面展现出巨大潜力，证明了其在视频-语言建模任务中的可扩展性。该方法为在不显著增加计算成本的情况下，提高大型多模态模型的性能提供了一种有效的途径。

Abstract: Recent advances in video captioning are driven by large-scale pretrained
models, which follow the standard "pre-training followed by fine-tuning"
paradigm, where the full model is fine-tuned for downstream tasks. Although
effective, this approach becomes computationally prohibitive as the model size
increases. The Parameter-Efficient Fine-Tuning (PEFT) approach offers a
promising alternative, but primarily focuses on the language components of
Multimodal Large Language Models (MLLMs). Despite recent progress, PEFT remains
underexplored in multimodal tasks and lacks sufficient understanding of visual
information during fine-tuning the model. To bridge this gap, we propose
Query-Adapter (Q-Adapter), a lightweight visual adapter module designed to
enhance MLLMs by enabling efficient fine-tuning for the video captioning task.
Q-Adapter introduces learnable query tokens and a gating layer into Vision
Encoder, enabling effective extraction of sparse, caption-relevant features
without relying on external textual supervision. We evaluate Q-Adapter on two
well-known video captioning datasets, MSR-VTT and MSVD, where it achieves
state-of-the-art performance among the methods that take the PEFT approach
across BLEU@4, METEOR, ROUGE-L, and CIDEr metrics. Q-Adapter also achieves
competitive performance compared to methods that take the full fine-tuning
approach while requiring only 1.4% of the parameters. We further analyze the
impact of key hyperparameters and design choices on fine-tuning effectiveness,
providing insights into optimization strategies for adapter-based learning.
These results highlight the strong potential of Q-Adapter in balancing caption
quality and parameter efficiency, demonstrating its scalability for
video-language modeling.

</details>


### [35] [P-4DGS: Predictive 4D Gaussian Splatting with 90$\times$ Compression](https://arxiv.org/abs/2510.10030)
*Henan Wang,Hanxin Zhu,Xinliang Gong,Tianyu He,Xin Li,Zhibo Chen*

Main category: cs.CV

TL;DR: P-4DGS通过利用空间-时间预测和自适应量化来压缩动态3D场景表示，实现了先进的重建质量和渲染速度，同时显著减小了存储空间。


<details>
  <summary>Details</summary>
Motivation: 现有动态3DGS方法在处理动态场景时存在显著的时空冗余，导致内存消耗过大。

Method: 提出了一种基于3D锚点空间-时间预测的模块，用于提取3D高斯图元之间的时空相关性，并结合自适应量化和基于上下文的熵编码来压缩锚点。

Result: P-4DGS在合成和真实世界数据集上实现了最先进的重建质量和最快的渲染速度，存储占用量平均约为1MB，分别在合成和真实世界场景中实现了高达40倍和90倍的压缩。

Conclusion: P-4DGS是一种有效的动态3D高斯图元压缩方法，能够显著减少存储需求，同时保持高质量的重建和实时渲染性能。

Abstract: 3D Gaussian Splatting (3DGS) has garnered significant attention due to its
superior scene representation fidelity and real-time rendering performance,
especially for dynamic 3D scene reconstruction (\textit{i.e.}, 4D
reconstruction). However, despite achieving promising results, most existing
algorithms overlook the substantial temporal and spatial redundancies inherent
in dynamic scenes, leading to prohibitive memory consumption. To address this,
we propose P-4DGS, a novel dynamic 3DGS representation for compact 4D scene
modeling. Inspired by intra- and inter-frame prediction techniques commonly
used in video compression, we first design a 3D anchor point-based
spatial-temporal prediction module to fully exploit the spatial-temporal
correlations across different 3D Gaussian primitives. Subsequently, we employ
an adaptive quantization strategy combined with context-based entropy coding to
further reduce the size of the 3D anchor points, thereby achieving enhanced
compression efficiency. To evaluate the rate-distortion performance of our
proposed P-4DGS in comparison with other dynamic 3DGS representations, we
conduct extensive experiments on both synthetic and real-world datasets.
Experimental results demonstrate that our approach achieves state-of-the-art
reconstruction quality and the fastest rendering speed, with a remarkably low
storage footprint (around \textbf{1MB} on average), achieving up to
\textbf{40$\times$} and \textbf{90$\times$} compression on synthetic and
real-world scenes, respectively.

</details>


### [36] [Complementary and Contrastive Learning for Audio-Visual Segmentation](https://arxiv.org/abs/2510.10051)
*Sitong Gong,Yunzhi Zhuge,Lu Zhang,Pingping Zhang,Huchuan Lu*

Main category: cs.CV

TL;DR: CCFormer是一个新颖的音频-视觉分割框架，通过早期融合、多查询Transformer和双模态对比学习来克服现有方法的局限性，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN和Transformer的方法在音频-视觉分割（AVS）中存在局限性，包括CNN的局部感受野受限以及Transformer提取多模态系数和时域动态的能力不足。

Method: 提出了一种名为CCFormer的新颖框架，包含三个主要组件：1. 早期集成模块（EIM），采用并行双边架构融合多尺度视觉特征和音频数据，增强跨模态互补性。2. 多查询Transformer模块（MTM），提取帧内空间特征并感知时域连贯性，动态赋予音频查询学习能力，同时模拟帧级和视频级关系。3. 双模态对比学习（BCL），促进统一特征空间中的跨模态对齐。

Result: CCFormer在S4、MS3和AVSS数据集上设定了新的最先进基准。

Conclusion: CCFormer通过有效结合早期融合、多查询Transformer和双模态对比学习，能够全面捕捉时空上下文，并在音频-视觉分割任务中取得了优越的性能。

Abstract: Audio-Visual Segmentation (AVS) aims to generate pixel-wise segmentation maps
that correlate with the auditory signals of objects. This field has seen
significant progress with numerous CNN and Transformer-based methods enhancing
the segmentation accuracy and robustness. Traditional CNN approaches manage
audio-visual interactions through basic operations like padding and
multiplications but are restricted by CNNs' limited local receptive field. More
recently, Transformer-based methods treat auditory cues as queries, utilizing
attention mechanisms to enhance audio-visual cooperation within frames.
Nevertheless, they typically struggle to extract multimodal coefficients and
temporal dynamics adequately. To overcome these limitations, we present the
Complementary and Contrastive Transformer (CCFormer), a novel framework adept
at processing both local and global information and capturing spatial-temporal
context comprehensively. Our CCFormer initiates with the Early Integration
Module (EIM) that employs a parallel bilateral architecture, merging
multi-scale visual features with audio data to boost cross-modal
complementarity. To extract the intra-frame spatial features and facilitate the
perception of temporal coherence, we introduce the Multi-query Transformer
Module (MTM), which dynamically endows audio queries with learning capabilities
and models the frame and video-level relations simultaneously. Furthermore, we
propose the Bi-modal Contrastive Learning (BCL) to promote the alignment across
both modalities in the unified feature space. Through the effective combination
of those designs, our method sets new state-of-the-art benchmarks across the
S4, MS3 and AVSS datasets. Our source code and model weights will be made
publicly available at https://github.com/SitongGong/CCFormer

</details>


### [37] [Think Twice to See More: Iterative Visual Reasoning in Medical VLMs](https://arxiv.org/abs/2510.10052)
*Kaitao Chen,Shaohao Rui,Yankai Jiang,Jiamin Wu,Qihao Zheng,Chunfeng Song,Xiaosong Wang,Mu Zhou,Mianxin Liu*

Main category: cs.CV

TL;DR: ViTAR是一个创新的医学视觉语言模型（VLM）框架，通过模拟人类专家的“思考-行动-反思-回答”的迭代推理过程，解决了现有VLM依赖单次推理且忽略局部视觉线索的问题。该模型通过交互式地处理医学图像，并结合精心策划的指令数据集和视觉问答训练数据，以及两阶段的训练策略（监督微调+强化学习），显著优于现有模型。实验证明，ViTAR能够将视觉注意力集中在临床关键区域，提高了模型性能和可信度。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型（VLM）在图像-文本理解方面表现出色，但通常依赖单次推理，忽略了局部视觉线索。然而，在临床实践中，人类专家通过反复扫描、聚焦和细化感兴趣的区域来做出最终诊断。为了缩小这种机器-人类感知差距，有必要开发能够模拟人类迭代推理过程的VLM。

Method: 提出ViTAR框架，模仿人类专家的“思考-行动-反思-回答”认知链，实现多步视觉推理。利用包含1K个交互式示例的指令数据集和16K个用于细粒度视觉诊断的视觉问答训练数据。采用两阶段训练策略：首先进行监督微调以指导认知轨迹，然后进行强化学习以优化决策。

Result: ViTAR在评估中表现优于现有最先进的模型。通过视觉注意力分析发现，在“思考”到“反思”的轮次中，ViTAR将视觉基础逐渐锚定在临床关键区域，并在推理过程中保持对视觉标记的高注意力分配，为性能提升提供了机制性见解。

Conclusion: 将专家风格的迭代思考链嵌入VLM可以提高医学人工智能的性能和可信度。ViTAR通过模拟人类专家的迭代推理过程，有效解决了现有模型忽略局部视觉线索的问题，并在医学图像理解任务中取得了显著的成果。

Abstract: Medical vision-language models (VLMs) excel at image-text understanding but
typically rely on a single-pass reasoning that neglects localized visual cues.
In clinical practice, however, human experts iteratively scan, focus, and
refine the regions of interest before reaching a final diagnosis. To narrow
this machine-human perception gap, we introduce ViTAR, a novel VLM framework
that emulates the iterative reasoning process of human experts through a
cognitive chain of "think-act-rethink-answer". ViTAR treats medical images as
interactive objects, enabling models to engage multi-step visual reasoning. To
support this approach, we curate a high-quality instruction dataset comprising
1K interactive examples that encode expert-like diagnostic behaviors. In
addition, a 16K visual question answering training data has been curated
towards fine-grained visual diagnosis. We introduce a two-stage training
strategy that begins with supervised fine-tuning to guide cognitive
trajectories, followed by the reinforcement learning to optimize
decision-making. Extensive evaluations demonstrate that ViTAR outperforms
strong state-of-the-art models. Visual attention analysis reveals that from the
"think" to "rethink" rounds, ViTAR increasingly anchors visual grounding to
clinically critical regions and maintains high attention allocation to visual
tokens during reasoning, providing mechanistic insight into its improved
performance. These findings demonstrate that embedding expert-style iterative
thinking chains into VLMs enhances both performance and trustworthiness of
medical AI.

</details>


### [38] [DREAM: A Benchmark Study for Deepfake REalism AssessMent](https://arxiv.org/abs/2510.10053)
*Bo Peng,Zichuan Wang,Sheng Yu,Xiaochuan Jin,Wei Wang,Jing Dong*

Main category: cs.CV

TL;DR: 本篇论文提出了DREAM基准，用于评估深度伪造视频的视觉真实感，该基准包含数据集、大规模标注和方法评估，旨在为深度伪造的真实感评估和生成提供新方向。


<details>
  <summary>Details</summary>
Motivation: 深度伪造（deepfakes）视频引发了对信息可信度的担忧。除了检测技术，研究深度伪造的主观感知（视觉真实感）也至关重要，这有助于评估其质量、欺骗性，预测其在互联网上的影响力，并改进生成过程。

Method: 提出一个名为DREAM（Deepfake REalism AssessMent）的基准，包括：1. 一个包含各种质量的深度伪造视频数据集。2. 大规模标注，包含140,000个真实感分数和来自3,500名标注者的文本描述。3. 对16种代表性真实感评估方法的全面评估和分析，包括基于视觉语言模型的方法和新提出的描述对齐CLIP方法。

Result: 在DREAM基准上对16种真实感评估方法进行了全面的评估和分析，并提供了相关见解。

Conclusion: DREAM基准的提出和其中包含的见解，为深度伪造视觉真实感评估这一新方向以及相关领域未来的研究奠定了基础。

Abstract: Deep learning based face-swap videos, widely known as deepfakes, have drawn
wide attention due to their threat to information credibility. Recent works
mainly focus on the problem of deepfake detection that aims to reliably tell
deepfakes apart from real ones, in an objective way. On the other hand, the
subjective perception of deepfakes, especially its computational modeling and
imitation, is also a significant problem but lacks adequate study. In this
paper, we focus on the visual realism assessment of deepfakes, which is defined
as the automatic assessment of deepfake visual realism that approximates human
perception of deepfakes. It is important for evaluating the quality and
deceptiveness of deepfakes which can be used for predicting the influence of
deepfakes on Internet, and it also has potentials in improving the deepfake
generation process by serving as a critic. This paper prompts this new
direction by presenting a comprehensive benchmark called DREAM, which stands
for Deepfake REalism AssessMent. It is comprised of a deepfake video dataset of
diverse quality, a large scale annotation that includes 140,000 realism scores
and textual descriptions obtained from 3,500 human annotators, and a
comprehensive evaluation and analysis of 16 representative realism assessment
methods, including recent large vision language model based methods and a newly
proposed description-aligned CLIP method. The benchmark and insights included
in this study can lay the foundation for future research in this direction and
other related areas.

</details>


### [39] [Collaborative Learning of Semantic-Aware Feature Learning and Label Recovery for Multi-Label Image Recognition with Incomplete Labels](https://arxiv.org/abs/2510.10055)
*Zhi-Fen He,Ren-Dong Xie,Bo Li,Bin Liu,Jin-Yan Hu*

Main category: cs.CV

TL;DR: CLSL通过统一语义感知特征学习和标签恢复来解决多标签图像识别中的不完整标签问题，并在公共数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多标签图像识别中不完整标签所面临的语义感知特征学习和缺失标签恢复两大核心挑战。

Method: 提出了一种名为CLSL的新型方法，该方法将语义感知特征学习和标签恢复统一在一个学习框架中。具体包括一个语义相关特征学习模块，一个语义引导特征增强模块，以及一个整合了特征学习和标签恢复的协同学习框架。

Result: 在MS-COCO、VOC2007和NUS-WIDE三个公共数据集上的广泛实验表明，CLSL的性能优于现有的不完整标签多标签图像识别方法。

Conclusion: CLSL通过协同学习框架，能够动态增强语义感知特征的可区分性，并自适应地推断和恢复缺失的标签，形成一个相互促进的循环。

Abstract: Multi-label image recognition with incomplete labels is a critical learning
task and has emerged as a focal topic in computer vision. However, this task is
confronted with two core challenges: semantic-aware feature learning and
missing label recovery. In this paper, we propose a novel Collaborative
Learning of Semantic-aware feature learning and Label recovery (CLSL) method
for multi-label image recognition with incomplete labels, which unifies the two
aforementioned challenges into a unified learning framework. More specifically,
we design a semantic-related feature learning module to learn robust
semantic-related features by discovering semantic information and label
correlations. Then, a semantic-guided feature enhancement module is proposed to
generate high-quality discriminative semantic-aware features by effectively
aligning visual and semantic feature spaces. Finally, we introduce a
collaborative learning framework that integrates semantic-aware feature
learning and label recovery, which can not only dynamically enhance the
discriminability of semantic-aware features but also adaptively infer and
recover missing labels, forming a mutually reinforced loop between the two
processes. Extensive experiments on three widely used public datasets (MS-COCO,
VOC2007, and NUS-WIDE) demonstrate that CLSL outperforms the state-of-the-art
multi-label image recognition methods with incomplete labels.

</details>


### [40] [Probabilistic Hyper-Graphs using Multiple Randomly Masked Autoencoders for Semi-supervised Multi-modal Multi-task Learning](https://arxiv.org/abs/2510.10068)
*Pîrvu Mihai-Cristian,Leordeanu Marius*

Main category: cs.CV

TL;DR: PHG-MAE是一个结合了神经图和MAE的新模型，通过掩码模态来学习超图，并将预训练和微调合并在一个训练循环中，同时支持推理时集成和知识蒸馏，适用于UAV、自动驾驶等领域。


<details>
  <summary>Details</summary>
Motivation: 在大规模数据和自监督预训练（如MAE）已成为计算机视觉主流的背景下，需要一种新的模型来统一神经图和MAE的理论框架，并提升模型性能。

Method: 提出了一种名为PHG-MAE的新模型，它通过随机掩码整个模态来学习超图的超边分布，并将MAE的预训练和微调合并在一个训练循环中。此外，该模型还支持推理时集成和知识蒸馏。

Result: PHG-MAE模型通过推理时集成和知识蒸馏，在UAV场景下展示了性能提升和一致性，即使是参数量小于1M的模型也能取得良好效果。同时，还发布了一个用于整合外部预训练模型的工具以及一个扩展的数据集。

Conclusion: PHG-MAE模型是一种创新的方法，能够统一神经图和MAE，并通过集成和知识蒸馏等技术提升模型性能，适用于多模态、多任务学习场景，并为相关领域的研究和应用提供了便利。

Abstract: The computer vision domain has greatly benefited from an abundance of data
across many modalities to improve on various visual tasks. Recently, there has
been a lot of focus on self-supervised pre-training methods through Masked
Autoencoders (MAE) \cite{he2022masked,bachmann2022multimae}, usually used as a
first step before optimizing for a downstream task, such as classification or
regression. This is very useful as it doesn't require any manually labeled
data. In this work, we introduce Probabilistic Hyper-Graphs using Masked
Autoencoders (PHG-MAE): a novel model that unifies the classical work on neural
graphs \cite{leordeanu2021semi} with the modern approach of masked autoencoders
under a common theoretical framework. Through random masking of entire
modalities, not just patches, the model samples from the distribution of
hyper-edges on each forward pass. Additionally, the model adapts the standard
MAE algorithm by combining pre-training and fine-tuning into a single training
loop. Moreover, our approach enables the creation of inference-time ensembles
which, through aggregation, boost the final prediction performance and
consistency. Lastly, we show that we can apply knowledge distillation on top of
the ensembles with little loss in performance, even with models that have fewer
than 1M parameters. While our work mostly focuses on outdoor UAV scenes that
contain multiple world interpretations and modalities, the same steps can be
followed in other similar domains, such as autonomous driving or indoor
robotics. In order to streamline the process of integrating external
pre-trained experts for computer vision multi-modal multi-task learning (MTL)
scenarios, we developed a data-pipeline software. Using this tool, we have
created and released a fully-automated extension of the Dronescapes dataset.
All the technical details, code and reproduction steps are publicly released.

</details>


### [41] [Tracking the Spatiotemporal Evolution of Landslide Scars Using a Vision Foundation Model: A Novel and Universal Framework](https://arxiv.org/abs/2510.10084)
*Meijun Zhou,Gang Mei,Zhengjing Ma,Nengxiong Xu,Jianbing Peng*

Main category: cs.CV

TL;DR: 本研究提出了一种利用视觉基础模型追踪大范围滑坡区域时空演化的新框架，通过将离散图像重建为连续视频序列，实现了对滑坡前兆和灾后演化的连续追踪，并以白格和Sela滑坡为例进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于单时相或双时相滑坡识别，难以追踪滑坡区域的时空演化，而理解滑坡时空演化对理解其机制、识别破坏前兆和实现早期预警至关重要。

Method: 将离散的光学遥感图像序列重建为连续视频，并利用为视频分割设计的视觉基础模型，在一个由知识引导、自动传播和交互式细化的范式下，追踪滑坡区域的演化。

Result: 该框架能够连续追踪滑坡区域，捕捉到用于早期预警的关键破坏前兆以及用于评估次生灾害和长期稳定性的灾后演化。

Conclusion: 所提出的框架能够为滑坡研究提供一种有效的时空追踪方法，有助于滑坡灾害的早期预警和风险评估。

Abstract: Tracking the spatiotemporal evolution of large-scale landslide scars is
critical for understanding the evolution mechanisms and failure precursors,
enabling effective early-warning. However, most existing studies have focused
on single-phase or pre- and post-failure dual-phase landslide identification.
Although these approaches delineate post-failure landslide boundaries, it is
challenging to track the spatiotemporal evolution of landslide scars. To
address this problem, this study proposes a novel and universal framework for
tracking the spatiotemporal evolution of large-scale landslide scars using a
vision foundation model. The key idea behind the proposed framework is to
reconstruct discrete optical remote sensing images into a continuous video
sequence. This transformation enables a vision foundation model, which is
developed for video segmentation, to be used for tracking the evolution of
landslide scars. The proposed framework operates within a knowledge-guided,
auto-propagation, and interactive refinement paradigm to ensure the continuous
and accurate identification of landslide scars. The proposed framework was
validated through application to two representative cases: the post-failure
Baige landslide and the active Sela landslide (2017-2025). Results indicate
that the proposed framework enables continuous tracking of landslide scars,
capturing both failure precursors critical for early warning and post-failure
evolution essential for assessing secondary hazards and long-term stability.

</details>


### [42] [Gesplat: Robust Pose-Free 3D Reconstruction via Geometry-Guided Gaussian Splatting](https://arxiv.org/abs/2510.10097)
*Jiahui Lu,Haihong Xiao,Xueyan Zhao,Wenxiong Kang*

Main category: cs.CV

TL;DR: Gesplat是一个基于3DGS的框架，可以从稀疏、无姿态的图像中进行新视角合成和几何一致的3D重建，它利用VGGT基础模型进行姿态和点云初始化，并结合了混合高斯表示、图引导属性细化和基于流的深度正则化等创新技术，在稀疏视图设置下表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有的NeRF和3DGS方法在稀疏视图设置下，由于相机姿态估计不可靠和监督不足，存在应用限制。Gesplat旨在克服这些挑战，实现鲁棒的新视角合成和几何一致的3D重建。

Method: Gesplat采用基于3DGS的框架，并引入了多项创新：1) 混合高斯表示，通过视图匹配一致性增强双重位置-形状优化；2) 图引导属性细化模块，增强场景细节；3) 基于流的深度正则化，提高深度估计精度。此外，它利用VGGT基础模型获得更可靠的初始姿态和密集点云，而非依赖COLMAP。

Result: Gesplat在正对和大规模复杂数据集上都取得了更鲁棒的性能，在稀疏视图设置下，其新视角合成和3D重建效果优于其他无姿态方法。

Conclusion: Gesplat成功地实现了从无姿态稀疏图像进行鲁棒的新视角合成和几何一致的3D重建，证明了其在处理具有挑战性的稀疏视图设置方面的有效性。

Abstract: Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS) have advanced
3D reconstruction and novel view synthesis, but remain heavily dependent on
accurate camera poses and dense viewpoint coverage. These requirements limit
their applicability in sparse-view settings, where pose estimation becomes
unreliable and supervision is insufficient. To overcome these challenges, we
introduce Gesplat, a 3DGS-based framework that enables robust novel view
synthesis and geometrically consistent reconstruction from unposed sparse
images. Unlike prior works that rely on COLMAP for sparse point cloud
initialization, we leverage the VGGT foundation model to obtain more reliable
initial poses and dense point clouds. Our approach integrates several key
innovations: 1) a hybrid Gaussian representation with dual position-shape
optimization enhanced by inter-view matching consistency; 2) a graph-guided
attribute refinement module to enhance scene details; and 3) flow-based depth
regularization that improves depth estimation accuracy for more effective
supervision. Comprehensive quantitative and qualitative experiments demonstrate
that our approach achieves more robust performance on both forward-facing and
large-scale complex datasets compared to other pose-free methods.

</details>


### [43] [Cooperative Pseudo Labeling for Unsupervised Federated Classification](https://arxiv.org/abs/2510.10100)
*Kuangpu Guo,Lijun Sheng,Yongcan Yu,Jian Liang,Zilei Wang,Ran He*

Main category: cs.CV

TL;DR: 本文首次将无监督联邦学习（UFL）与CLIP模型结合，用于解决图像分类问题，并提出了一种名为FedCoPL的新方法。


<details>
  <summary>Details</summary>
Motivation: 先前在UFL领域的研究主要集中在表示学习和聚类任务，而利用CLIP模型解决UFL下的分类问题仍是未被探索的领域。

Method: FedCoPL方法通过让客户端估计并上传伪标签分布，由服务器进行调整和重分布以避免类别全局不平衡。此外，还引入了部分提示聚合协议，服务器聚合通用的视觉提示，客户端保留个性化的文本提示。

Result: 实验结果表明，FedCoPL的性能优于现有的基线方法。

Conclusion: FedCoPL成功地将UFL扩展到了使用CLIP进行图像分类的场景，并通过提出的伪标签和提示聚合机制实现了优越的性能。

Abstract: Unsupervised Federated Learning (UFL) aims to collaboratively train a global
model across distributed clients without sharing data or accessing label
information. Previous UFL works have predominantly focused on representation
learning and clustering tasks. Recently, vision language models (e.g., CLIP)
have gained significant attention for their powerful zero-shot prediction
capabilities. Leveraging this advancement, classification problems that were
previously infeasible under the UFL paradigm now present promising new
opportunities, yet remain largely unexplored. In this paper, we extend UFL to
the classification problem with CLIP for the first time and propose a novel
method, \underline{\textbf{Fed}}erated \underline{\textbf{Co}}operative
\underline{\textbf{P}}seudo \underline{\textbf{L}}abeling (\textbf{FedCoPL}).
Specifically, clients estimate and upload their pseudo label distribution, and
the server adjusts and redistributes them to avoid global imbalance among
classes. Moreover, we introduce a partial prompt aggregation protocol for
effective collaboration and personalization. In particular, visual prompts
containing general image features are aggregated at the server, while text
prompts encoding personalized knowledge are retained locally. Extensive
experiments demonstrate the superior performance of our FedCoPL compared to
baseline methods. Our code is available at
\href{https://github.com/krumpguo/FedCoPL}{https://github.com/krumpguo/FedCoPL}.

</details>


### [44] [Answer-Consistent Chain-of-thought Reinforcement Learning For Multi-modal Large Langauge Models](https://arxiv.org/abs/2510.10104)
*Minbin Huang,Runhui Huang,Chuanyang Zheng,Jingyao Li,Guoxuan Chen,Han Shi,Hong Cheng*

Main category: cs.CV

TL;DR: ACRE 通过引入一个辅助一致性检查来修改 GRPO 算法，以提高多模态大语言模型在视觉问答任务中的推理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于奖励的强化学习方法虽然能提高答案的准确性，但可能导致推理链与最终答案不一致，ACRE 旨在解决这个问题。

Method: ACRE 在 GRPO 算法的基础上增加了一个一致性检查步骤。模型首先生成思考过程和初步答案，然后打乱选项顺序，并使用相同的推理过程生成第二个答案。只有当两个答案一致且正确时，才给予高奖励，否则给予较低奖励。

Result: 在视频推理和数学推理基准测试中，ACRE 相较于 GRPO 基线分别取得了 2.2% 和 1.5% 的平均提升，表明其有效解决了推理与答案不匹配的问题。

Conclusion: ACRE 能够有效提高多模态大语言模型在视觉问答任务中的推理一致性，并提升在视频推理和数学推理任务上的表现。

Abstract: Recent advances in large language models (LLMs) have demonstrated that
reinforcement learning with verifiable rewards (RLVR) can significantly enhance
reasoning abilities by directly optimizing correctness, rather than relying
solely on supervised imitation. This paradigm has been extended to multimodal
LLMs for complex video and image understanding tasks. However, while
outcome-driven RL improves answer accuracy, it can inadvertently decouple the
reasoning chain from the final answer, leading to situations where models
produce inconsistency between the reasoning trace and final answer. In our
experiments on multiple-choice visual question-answering tasks, the standard
GRPO method yields only 79.7\% consistency on MMVU between the reasoning steps
and the chosen answers, indicating frequent mismatches between answers and
reasoning. To this end, we propose Answer-Consistent Reinforcement Learning
(ACRE) that modifies the GRPO algorithm with an auxiliary consistency check.
After the model generates a chain of thought and an initial answer for a given
question, we shuffle the answer options and prompt the model again with the
same reasoning trace to predict a second answer. We design a
consistency-verification reward that grants a high reward only if both the
original and the post-shuffle answers agree and are correct; otherwise, a lower
reward is assigned accordingly. This mechanism penalizes reasoning-answer
misalignment and discourages the model from relying on spurious patterns, such
as option ordering biases. We evaluate ACRE on challenging Video Reasoning
benchmarks and multimodal math reasoning benchmarks, achieving an average 2.2\%
and 1.5\% improvement for Video Reasoning and Math Reasoning tasks over the
GRPO baseline.

</details>


### [45] [Uncertainty-Aware Post-Detection Framework for Enhanced Fire and Smoke Detection in Compact Deep Learning Models](https://arxiv.org/abs/2510.10108)
*Aniruddha Srinivas Joshi,Godwyn James William,Shreyas Srinivas Joshi*

Main category: cs.CV

TL;DR: 本研究提出了一种不确定性感知后处理框架，通过整合统计不确定性和视觉线索来改进 YOLOv5n 和 YOLOv8n 等紧凑型深度学习模型在火灾和烟雾检测中的性能，解决了现有方法在效率和可靠性之间平衡的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉的火灾和烟雾检测方法在效率和可靠性之间难以平衡，特别是对于 YOLOv5n 和 YOLOv8n 等紧凑型模型，由于容量受限，容易出现误报和漏检。传统的后处理方法（如 NMS）仅依赖空间重叠，在复杂场景下效果不佳。

Method: 提出了一种不确定性感知后处理框架，利用轻量级的置信度精炼网络（Confidence Refinement Network）集成不确定性估计与颜色、边缘和纹理特征，对检测分数进行调整，而不修改基础模型。

Result: 在 D-Fire 数据集上的实验表明，与现有基线方法相比，该框架提高了精度、召回率和平均精度（mAP），且计算开销适中。

Conclusion: 后处理重评分能有效增强紧凑型深度学习模型在实际火灾和烟雾检测中的鲁棒性。

Abstract: Accurate fire and smoke detection is critical for safety and disaster
response, yet existing vision-based methods face challenges in balancing
efficiency and reliability. Compact deep learning models such as YOLOv5n and
YOLOv8n are widely adopted for deployment on UAVs, CCTV systems, and IoT
devices, but their reduced capacity often results in false positives and missed
detections. Conventional post-detection methods such as Non-Maximum Suppression
and Soft-NMS rely only on spatial overlap, which can suppress true positives or
retain false alarms in cluttered or ambiguous fire scenes. To address these
limitations, we propose an uncertainty aware post-detection framework that
rescales detection confidences using both statistical uncertainty and domain
relevant visual cues. A lightweight Confidence Refinement Network integrates
uncertainty estimates with color, edge, and texture features to adjust
detection scores without modifying the base model. Experiments on the D-Fire
dataset demonstrate improved precision, recall, and mean average precision
compared to existing baselines, with only modest computational overhead. These
results highlight the effectiveness of post-detection rescoring in enhancing
the robustness of compact deep learning models for real-world fire and smoke
detection.

</details>


### [46] [Training-Free In-Context Forensic Chain for Image Manipulation Detection and Localization](https://arxiv.org/abs/2510.10111)
*Rui Chen,Bin Liu,Changtao Miao,Xinghao Wang,Yi Li,Tao Gong,Qi Chu,Nenghai Yu*

Main category: cs.CV

TL;DR: 本文提出了一种名为In-Context Forensic Chain (ICFC) 的训练无关的图像篡改定位框架，该框架利用多模态大语言模型（MLLMs）进行可解释的图像篡改定位。


<details>
  <summary>Details</summary>
Motivation: 图像篡改日益增多，对图像篡改定位（IML）的有效性提出了更高要求。现有的监督学习方法需要昂贵的像素级标注，而弱监督或无监督方法性能不足且缺乏可解释性。

Method: ICFC框架整合了目标化规则构建和自适应过滤，以构建可靠的知识库，并设计了一个多步渐进式推理流水线，模拟专家从粗粒度预测到细粒度取证的工作流程，从而系统性地利用MLLM的推理能力。

Result: ICFC在多个基准测试中，性能超越了最先进的无监督方法，并在与弱监督和全监督方法的比较中，取得了具有竞争力或更优的性能。

Conclusion: ICFC利用多模态大语言模型实现了训练无关、可解释的图像篡改定位，并在性能上取得了显著的成果。

Abstract: Advances in image tampering pose serious security threats, underscoring the
need for effective image manipulation localization (IML). While supervised IML
achieves strong performance, it depends on costly pixel-level annotations.
Existing weakly supervised or training-free alternatives often underperform and
lack interpretability. We propose the In-Context Forensic Chain (ICFC), a
training-free framework that leverages multi-modal large language models
(MLLMs) for interpretable IML tasks. ICFC integrates an objectified rule
construction with adaptive filtering to build a reliable knowledge base and a
multi-step progressive reasoning pipeline that mirrors expert forensic
workflows from coarse proposals to fine-grained forensics results. This design
enables systematic exploitation of MLLM reasoning for image-level
classification, pixel-level localization, and text-level interpretability.
Across multiple benchmarks, ICFC not only surpasses state-of-the-art
training-free methods but also achieves competitive or superior performance
compared to weakly and fully supervised approaches.

</details>


### [47] [ImmerIris: A Large-Scale Dataset and Benchmark for Immersive Iris Recognition in Open Scenes](https://arxiv.org/abs/2510.10113)
*Yuxi Mi,Qiuyang Yuan,Zhizhou Zhong,Xuan Zhao,Jiaogen Zhou,Fubao Zhu,Jihong Guan,Shuigeng Zhou*

Main category: cs.CV

TL;DR: 本文提出了ImmerIris数据集，解决了沉浸式虹膜识别中数据不足的问题，并提出了一种无需归一化的识别方法，在挑战性因素下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的虹膜识别方法主要针对轴上（on-axis）图像，在沉浸式（off-axis）场景下表现不佳，且缺乏专门针对此类场景的大规模数据集。

Method: 收集了包含499,791张眼部图像（来自564个受试者）的ImmerIris数据集，并在此基础上构建了评估协议。提出了一个无需归一化的识别方法，直接从眼部图像中学习特征。

Result: 现有的轴上虹膜识别方法在沉浸式设置下表现不佳。所提出的无需归一化的方法在各项评估中均优于基于归一化的方法。

Conclusion: ImmerIris数据集的提出填补了沉浸式虹膜识别数据集的空白。无需归一化的识别方法为应对沉浸式场景下的虹膜识别挑战提供了一个有前景的方向。

Abstract: In egocentric applications such as augmented and virtual reality, immersive
iris recognition is emerging as an accurate and seamless way to identify
persons. While classic systems acquire iris images on-axis, i.e., via dedicated
frontal sensors in controlled settings, the immersive setup primarily captures
off-axis irises through tilt-placed headset cameras, with only mild control in
open scenes. This yields unique challenges, including perspective distortion,
intensified quality degradations, and intra-class variations in iris texture.
Datasets capturing these challenges remain scarce. To fill this gap, this paper
introduces ImmerIris, a large-scale dataset collected via VR headsets,
containing 499,791 ocular images from 564 subjects. It is, to the best of
current knowledge, the largest public dataset and among the first dedicated to
off-axis acquisition. Based on ImmerIris, evaluation protocols are constructed
to benchmark recognition methods under different challenging factors. Current
methods, primarily designed for classic on-axis imagery, perform
unsatisfactorily on the immersive setup, mainly due to reliance on fallible
normalization. To this end, this paper further proposes a normalization-free
paradigm that directly learns from ocular images with minimal adjustment.
Despite its simplicity, this approach consistently outperforms
normalization-based counterparts, pointing to a promising direction for robust
immersive recognition.

</details>


### [48] [A Large-Language-Model Assisted Automated Scale Bar Detection and Extraction Framework for Scanning Electron Microscopic Images](https://arxiv.org/abs/2510.11260)
*Yuxuan Chen,Ruotong Yang,Zhengyang Zhang,Mehreen Ahmed,Yanming Wang*

Main category: cs.CV

TL;DR: 本研究提出了一种利用大型语言模型（LLM）的自动化框架，用于检测和提取扫描电子显微镜（SEM）图像中的尺度栏，提高了分析效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 手动确定SEM图像中的尺度栏耗时且易出错，本研究旨在解决此问题，实现自动化尺度栏检测与提取。

Method: 提出一个多模态自动化框架，包含自动数据集生成（Auto-DG）、尺度栏物体检测、基于DenseNet和CRNN的混合OCR信息提取，以及利用LLM进行结果分析和验证。

Result: 尺度栏物体检测精度达到100%，召回率95.8%，mAP为99.2% (IoU=0.5)。混合OCR系统在Auto-DG数据集上达到89%的精确率、65%的召回率和75%的F1分数，优于主流OCR引擎。

Conclusion: 该自动化方法通过LLM代理显著提高了SEM图像中尺度栏检测和提取的效率与准确性，为显微分析提供了有价值的工具，推动了科学成像领域的发展。

Abstract: Microscopic characterizations, such as Scanning Electron Microscopy (SEM),
are widely used in scientific research for visualizing and analyzing
microstructures. Determining the scale bars is an important first step of
accurate SEM analysis; however, currently, it mainly relies on manual
operations, which is both time-consuming and prone to errors. To address this
issue, we propose a multi-modal and automated scale bar detection and
extraction framework that provides concurrent object detection, text detection
and text recognition with a Large Language Model (LLM) agent. The proposed
framework operates in four phases; i) Automatic Dataset Generation (Auto-DG)
model to synthesize a diverse dataset of SEM images ensuring robust training
and high generalizability of the model, ii) scale bar object detection, iii)
information extraction using a hybrid Optical Character Recognition (OCR)
system with DenseNet and Convolutional Recurrent Neural Network (CRNN) based
algorithms, iv) an LLM agent to analyze and verify accuracy of the results. The
proposed model demonstrates a strong performance in object detection and
accurate localization with a precision of 100%, recall of 95.8%, and a mean
Average Precision (mAP) of 99.2% at IoU=0.5 and 69.1% at IoU=0.5:0.95. The
hybrid OCR system achieved 89% precision, 65% recall, and a 75% F1 score on the
Auto-DG dataset, significantly outperforming several mainstream standalone
engines, highlighting its reliability for scientific image analysis. The LLM is
introduced as a reasoning engine as well as an intelligent assistant that
suggests follow-up steps and verifies the results. This automated method
powered by an LLM agent significantly enhances the efficiency and accuracy of
scale bar detection and extraction in SEM images, providing a valuable tool for
microscopic analysis and advancing the field of scientific imaging.

</details>


### [49] [Multi Class Parkinsons Disease Detection Based on Finger Tapping Using Attention-Enhanced CNN BiLSTM](https://arxiv.org/abs/2510.10121)
*Abu Saleh Musa Miah,Najmul Hassan,Md Maruf Al Hossain,Yuichi Okuyama,Jungpil Shin*

Main category: cs.CV

TL;DR: 该研究提出了一种基于注意力增强的卷积神经网络（CNN）和双向长短期记忆（BiLSTM）的帕金森病（PD）严重程度检测系统，通过分析指触视频中的运动特征，提高了PD严重程度分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于手势的帕金森病识别系统在性能准确性方面尚不理想，需要更有效的临床管理和干预手段。

Method: 从指触视频中提取时间、频率和幅度特征，并提出一个集成了CNN、BiLSTM和注意力机制的混合深度学习框架，用于从视频中提取的运动特征进行多类别PD严重程度分类。具体步骤包括：使用Conv1D MaxPooling块捕获局部空间依赖性，然后通过BiLSTM层建模时间动态，接着利用注意力机制聚焦于最重要的时间特征，并结合CNN特征进行最终分类。

Result: 该模型在区分五个帕金森病严重程度等级方面表现出强大的性能。

Conclusion: 将时空表示与注意力机制相结合可以提高自动PD严重程度检测的性能，为临床医生提供一种有前景的非侵入性工具，以支持PD的监测和进展跟踪。

Abstract: Effective clinical management and intervention development depend on accurate
evaluation of Parkinsons disease (PD) severity. Many researchers have worked on
developing gesture-based PD recognition systems; however, their performance
accuracy is not satisfactory. In this study, we propose a multi-class Parkinson
Disease detection system based on finger tapping using an attention-enhanced
CNN BiLSTM. We collected finger tapping videos and derived temporal, frequency,
and amplitude based features from wrist and hand movements. Then, we proposed a
hybrid deep learning framework integrating CNN, BiLSTM, and attention
mechanisms for multi-class PD severity classification from video-derived motion
features. First, the input sequence is reshaped and passed through a Conv1D
MaxPooling block to capture local spatial dependencies. The resulting feature
maps are fed into a BiLSTM layer to model temporal dynamics. An attention
mechanism focuses on the most informative temporal features, producing a
context vector that is further processed by a second BiLSTM layer. CNN-derived
features and attention-enhanced BiLSTM outputs are concatenated, followed by
dense and dropout layers, before the final softmax classifier outputs the
predicted PD severity level. The model demonstrated strong performance in
distinguishing between the five severity classes, suggesting that integrating
spatial temporal representations with attention mechanisms can improve
automated PD severity detection, making it a promising non-invasive tool to
support clinicians in PD monitoring and progression tracking.

</details>


### [50] [DeepFusionNet: Autoencoder-Based Low-Light Image Enhancement and Super-Resolution](https://arxiv.org/abs/2510.10122)
*Halil Hüseyin Çalışkan,Talha Koruk*

Main category: cs.CV

TL;DR: DeepFusionNet是一种用于增强低光和低分辨率图像的神经网络，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有自动编码器方法在处理低光和低分辨率图像时存在SSIM和PSNR分数低、参数量大、计算能力要求高等问题。

Method: 提出了一种名为DeepFusionNet的神经网络架构，并基于该架构开发了一种自动编码器模型，用于提高低光和低分辨率图像的质量。

Result: DeepFusionNet在LOL-v1数据集上达到了92.8%的SSIM和26.30的PSNR，参数量约为250万。基于DeepFusionNet的超分辨率方法在验证集上达到了80.7%的SSIM和25.30的PSNR，参数量约为10万。

Conclusion: DeepFusionNet在增强低光和低分辨率图像方面表现出色，并且参数量较少，计算效率高。

Abstract: Computer vision and image processing applications suffer from dark and
low-light images, particularly during real-time image transmission. Currently,
low light and dark images are converted to bright and colored forms using
autoencoders; however, these methods often achieve low SSIM and PSNR scores and
require high computational power due to their large number of parameters. To
address these challenges, the DeepFusionNet architecture has been developed.
According to the results obtained with the LOL-v1 dataset, DeepFusionNet
achieved an SSIM of 92.8% and a PSNR score of 26.30, while containing only
approximately 2.5 million parameters. On the other hand, conversion of blurry
and low-resolution images into high-resolution and blur-free images has gained
importance in image processing applications. Unlike GAN-based super-resolution
methods, an autoencoder-based super resolution model has been developed that
contains approximately 100 thousand parameters and uses the DeepFusionNet
architecture. According to the results of the tests, the DeepFusionNet based
super-resolution method achieved a PSNR of 25.30 and a SSIM score of 80.7
percent according to the validation set.

</details>


### [51] [YOLOv11-Litchi: Efficient Litchi Fruit Detection based on UAV-Captured Agricultural Imagery in Complex Orchard Environments](https://arxiv.org/abs/2510.10141)
*Hongxing Peng,Haopei Xie,Weijia Lia,Huanai Liuc,Ximing Li*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 YOLOv11-Litchi 的轻量级无人机荔枝检测模型，通过引入多尺度残差模块、轻量化特征融合以及遮挡检测头，在减小模型尺寸（参数量减少 32.5%）和计算量的同时，提升了 mAP（90.1%）和 F1 分数（85.5%），并达到 57.2 FPS 的帧率，满足了复杂环境下实时检测的需求，为精准农业提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统的人工荔枝筛选方法已无法满足现代生产需求，需要更高效、低成本的解决方案。无人机结合深度学习技术为提高效率、降低成本提供了潜力。

Method: 提出了一种基于 YOLOv11 框架的轻量级、鲁棒的无人机荔枝检测模型 YOLOv11-Litchi。该模型解决了小目标、模型参数大、目标遮挡等问题，通过引入以下三个创新点：1. 多尺度残差模块：增强跨尺度的上下文特征提取。2. 轻量化特征融合：在保证精度的前提下，减小模型尺寸和计算成本。3. 荔枝遮挡检测头：通过强调目标区域、抑制背景干扰来减轻遮挡影响。

Result: YOLOv11-Litchi 的参数量为 6.35 MB，比基线 YOLOv11 模型减小了 32.5%。同时，mAP 提升了 2.5%，达到 90.1%；F1 分数提升了 1.4%，达到 85.5%。此外，模型的帧率为 57.2 FPS，满足了实时检测的要求。

Conclusion: YOLOv11-Litchi 模型适用于复杂果园环境下的无人机荔枝检测，证明了其在精准农业等领域的广泛应用潜力。

Abstract: Litchi is a high-value fruit, yet traditional manual selection methods are
increasingly inadequate for modern production demands. Integrating UAV-based
aerial imagery with deep learning offers a promising solution to enhance
efficiency and reduce costs. This paper introduces YOLOv11-Litchi, a
lightweight and robust detection model specifically designed for UAV-based
litchi detection. Built upon the YOLOv11 framework, the proposed model
addresses key challenges such as small target size, large model parameters
hindering deployment, and frequent target occlusion. To tackle these issues,
three major innovations are incorporated: a multi-scale residual module to
improve contextual feature extraction across scales, a lightweight feature
fusion method to reduce model size and computational costs while maintaining
high accuracy, and a litchi occlusion detection head to mitigate occlusion
effects by emphasizing target regions and suppressing background interference.
Experimental results validate the model's effectiveness. YOLOv11-Litchi
achieves a parameter size of 6.35 MB - 32.5% smaller than the YOLOv11 baseline
- while improving mAP by 2.5% to 90.1% and F1-Score by 1.4% to 85.5%.
Additionally, the model achieves a frame rate of 57.2 FPS, meeting real-time
detection requirements. These findings demonstrate the suitability of
YOLOv11-Litchi for UAV-based litchi detection in complex orchard environments,
showcasing its potential for broader applications in precision agriculture.

</details>


### [52] [Color3D: Controllable and Consistent 3D Colorization with Personalized Colorizer](https://arxiv.org/abs/2510.10152)
*Yecong Wan,Mingwen Shao,Renlong Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: Color3D是一个新框架，可以为3D场景（包括动态场景）添加颜色，并提供用户控制，解决了现有方法在色彩丰富度和可控性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景着色方法在处理动态场景时存在局限性，并且倾向于通过平均化来保证多视图一致性，这牺牲了色彩丰富度和用户控制能力。

Method: Color3D通过着色单个关键视图并训练个性化着色器来传播颜色，以确保跨视图和跨时间的一致性。该方法利用了场景特定的确定性颜色映射和高斯泼溅表示，将复杂的3D着色问题转化为单图像着色问题。

Result: 实验证明，Color3D能够生成色彩丰富、视图一致性好且具有精确用户控制的3D场景着色结果，优于现有方法。

Conclusion: Color3D框架成功地为静态和动态3D场景提供了高质量、多样的着色，并实现了用户对其进行精确控制的能力。

Abstract: In this work, we present Color3D, a highly adaptable framework for colorizing
both static and dynamic 3D scenes from monochromatic inputs, delivering
visually diverse and chromatically vibrant reconstructions with flexible
user-guided control. In contrast to existing methods that focus solely on
static scenarios and enforce multi-view consistency by averaging color
variations which inevitably sacrifice both chromatic richness and
controllability, our approach is able to preserve color diversity and
steerability while ensuring cross-view and cross-time consistency. In
particular, the core insight of our method is to colorize only a single key
view and then fine-tune a personalized colorizer to propagate its color to
novel views and time steps. Through personalization, the colorizer learns a
scene-specific deterministic color mapping underlying the reference view,
enabling it to consistently project corresponding colors to the content in
novel views and video frames via its inherent inductive bias. Once trained, the
personalized colorizer can be applied to infer consistent chrominance for all
other images, enabling direct reconstruction of colorful 3D scenes with a
dedicated Lab color space Gaussian splatting representation. The proposed
framework ingeniously recasts complicated 3D colorization as a more tractable
single image paradigm, allowing seamless integration of arbitrary image
colorization models with enhanced flexibility and controllability. Extensive
experiments across diverse static and dynamic 3D colorization benchmarks
substantiate that our method can deliver more consistent and chromatically rich
renderings with precise user control. Project Page
https://yecongwan.github.io/Color3D/.

</details>


### [53] [Stroke Locus Net: Occluded Vessel Localization from MRI Modalities](https://arxiv.org/abs/2510.10155)
*Mohamed Hamad,Muhammad Khan,Tamer Khattab,Mohamed Mabrok*

Main category: cs.CV

TL;DR: 本研究提出了卒中定位网络（Stroke Locus Net），一个端到端的深度学习流程，仅使用MRI扫描即可实现病灶检测、分割和闭塞血管定位，以应对缺血性中风诊断中准确识别闭塞血管的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前机器学习方法主要集中于病灶分割，对血管定位的研究有限，而准确识别闭塞血管对于缺血性中风诊断至关重要。

Method: 提出了一种结合nnUNet进行病灶检测、动脉图谱进行血管映射和识别的分割分支，以及使用pGAN合成MRA图像的生成分支的端到端深度学习流程。

Result: 该方法在卒中T1 MRI扫描的闭塞血管定位方面取得了初步成效。

Conclusion: 所提出的Stroke Locus Net在缺血性中风诊断中具有提升诊断速度和信息准确性的潜力。

Abstract: A key challenge in ischemic stroke diagnosis using medical imaging is the
accurate localization of the occluded vessel. Current machine learning methods
in focus primarily on lesion segmentation, with limited work on vessel
localization. In this study, we introduce Stroke Locus Net, an end-to-end deep
learning pipeline for detection, segmentation, and occluded vessel localization
using only MRI scans. The proposed system combines a segmentation branch using
nnUNet for lesion detection with an arterial atlas for vessel mapping and
identification, and a generation branch using pGAN to synthesize MRA images
from MRI. Our implementation demonstrates promising results in localizing
occluded vessels on stroke-affected T1 MRI scans, with potential for faster and
more informed stroke diagnosis.

</details>


### [54] [ReMix: Towards a Unified View of Consistent Character Generation and Editing](https://arxiv.org/abs/2510.10156)
*Benjia Zhou,Bin Fu,Pei Cheng,Yanru Wang,Jiayuan Fan,Tao Chen*

Main category: cs.CV

TL;DR: ReMix是一个统一的文本到图像生成和编辑框架，通过ReMix模块和IP-ControlNet实现了角色一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在角色一致性生成和编辑方面存在不足，难以在单一框架内统一这些任务。

Method: ReMix框架包含ReMix模块（利用MLLM编辑语义特征和指令嵌入）和IP-ControlNet（解耦语义和布局线索，引入{\epsilon}-等变潜在空间以在共享噪声空间中共用去噪参考和目标图像）。

Result: ReMix能够实现角色一致的生成和编辑，支持个性化生成、图像编辑、风格迁移和多条件合成等任务，并在实验中验证了其有效性和效率。

Conclusion: ReMix提供了一个统一的框架，有效解决了角色一致性图像生成和编辑的挑战。

Abstract: Recent advances in large-scale text-to-image diffusion models (e.g., FLUX.1)
have greatly improved visual fidelity in consistent character generation and
editing. However, existing methods rarely unify these tasks within a single
framework. Generation-based approaches struggle with fine-grained identity
consistency across instances, while editing-based methods often lose spatial
controllability and instruction alignment. To bridge this gap, we propose
ReMix, a unified framework for character-consistent generation and editing. It
constitutes two core components: the ReMix Module and IP-ControlNet. The ReMix
Module leverages the multimodal reasoning ability of MLLMs to edit semantic
features of input images and adapt instruction embeddings to the native DiT
backbone without fine-tuning. While this ensures coherent semantic layouts,
pixel-level consistency and pose controllability remain challenging. To address
this, IP-ControlNet extends ControlNet to decouple semantic and layout cues
from reference images and introduces an {\epsilon}-equivariant latent space
that jointly denoises the reference and target images within a shared noise
space. Inspired by convergent evolution and quantum decoherence,i.e., where
environmental noise drives state convergence, this design promotes feature
alignment in the hidden space, enabling consistent object generation while
preserving identity. ReMix supports a wide range of tasks, including
personalized generation, image editing, style transfer, and multi-condition
synthesis. Extensive experiments validate its effectiveness and efficiency as a
unified framework for character-consistent image generation and editing.

</details>


### [55] [SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation](https://arxiv.org/abs/2510.10160)
*Zhenjie Mao,Yuhuan Yang,Chaofan Ma,Dongsheng Jiang,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: SaFiRe框架通过模仿人类认知过程，解决指代图像分割中的歧义性表达问题，并在新基准aRefCOCO上取得优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 现有Referring Image Segmentation（RIS）方法主要处理简单表达，忽略了现实世界中复杂的、包含歧义的表达，限制了模型处理多实体和隐式类别信息的能力。

Method: 提出SaFiRe框架，模仿人类先全局理解再细节检查的双阶段认知过程，并利用Mamba的扫描-更新特性实现高效的多周期、线性复杂度细化。引入aRefCOCO数据集以评估在歧义表达下的RIS模型。

Result: SaFiRe框架在标准和新提出的aRefCOCO数据集上进行了广泛实验，结果证明其在处理歧义性表达的RIS任务上优于现有最先进方法。

Conclusion: SaFiRe框架通过其独特的设计和Mamba的运用，能够有效处理具有挑战性的歧义性表达，显著提升了RIS的性能。aRefCO6数据集的引入为该领域的研究提供了新的评估标准。

Abstract: Referring Image Segmentation (RIS) aims to segment the target object in an
image given a natural language expression. While recent methods leverage
pre-trained vision backbones and more training corpus to achieve impressive
results, they predominantly focus on simple expressions--short, clear noun
phrases like "red car" or "left girl". This simplification often reduces RIS to
a key word/concept matching problem, limiting the model's ability to handle
referential ambiguity in expressions. In this work, we identify two challenging
real-world scenarios: object-distracting expressions, which involve multiple
entities with contextual cues, and category-implicit expressions, where the
object class is not explicitly stated. To address the challenges, we propose a
novel framework, SaFiRe, which mimics the human two-phase cognitive
process--first forming a global understanding, then refining it through
detail-oriented inspection. This is naturally supported by Mamba's
scan-then-update property, which aligns with our phased design and enables
efficient multi-cycle refinement with linear complexity. We further introduce
aRefCOCO, a new benchmark designed to evaluate RIS models under ambiguous
referring expressions. Extensive experiments on both standard and proposed
datasets demonstrate the superiority of SaFiRe over state-of-the-art baselines.

</details>


### [56] [SparseUWSeg: Active Sparse Point-Label Augmentation for Underwater Semantic Segmentation](https://arxiv.org/abs/2510.10163)
*César Borja,Carlos Plou,Rubén Martinez-Cantín,Ana C. Murillo*

Main category: cs.CV

TL;DR: 该研究提出了一种名为SparseUWSeg的新框架，用于解决水下图像的语义分割问题，特别是细粒度场景分析的挑战。


<details>
  <summary>Details</summary>
Motivation: 水下图像分析对于生态监测至关重要，但目前现有分割模型在细粒度场景分析方面仍存在不足，主要原因是获取密集、专家标注的分割标签成本高昂，而稀疏点标注虽然易于获取，但在标注点选择和信息传播方面存在挑战。

Method: SparseUWSeg框架采用主动采样策略来指导标注者，最大化点标注的价值，并结合SAM2和超像素方法进行稀疏标签的传播。

Result: 在两个不同的水下数据集上的实验表明，SparseUWSeg的性能优于最先进的方法，mIoU最高可提升5%。

Conclusion: 该研究设计并发布了一个集成了其算法的交互式标注工具，使生态研究人员能够高效地生成高质量的分割掩码，以处理其数据。

Abstract: Semantic segmentation is essential to automate underwater imagery analysis
with ecology monitoring purposes. Unfortunately, fine grained underwater scene
analysis is still an open problem even for top performing segmentation models.
The high cost of obtaining dense, expert-annotated, segmentation labels hinders
the supervision of models in this domain. While sparse point-labels are easier
to obtain, they introduce challenges regarding which points to annotate and how
to propagate the sparse information. We present SparseUWSeg, a novel framework
that addresses both issues. SparseUWSeg employs an active sampling strategy to
guide annotators, maximizing the value of their point labels. Then, it
propagates these sparse labels with a hybrid approach leverages both the best
of SAM2 and superpixel-based methods. Experiments on two diverse underwater
datasets demonstrate the benefits of SparseUWSeg over state-of-the-art
approaches, achieving up to +5\% mIoU over D+NN. Our main contribution is the
design and release of a simple but effective interactive annotation tool,
integrating our algorithms. It enables ecology researchers to leverage
foundation models and computer vision to efficiently generate high-quality
segmentation masks to process their data.

</details>


### [57] [ViConEx-Med: Visual Concept Explainability via Multi-Concept Token Transformer for Medical Image Analysis](https://arxiv.org/abs/2510.10174)
*Cristiano Patrício,Luís F. Teixeira,João C. Neves*

Main category: cs.CV

TL;DR: ViConEx-Med是一个创新的视觉概念可解释性框架，通过可学习的概念标记联合预测和定位视觉概念，为基于概念的模型提供了视觉解释。


<details>
  <summary>Details</summary>
Motivation: 现有的基于概念的模型通常将概念视为数值属性，缺乏视觉解释，这限制了它们在医疗等高风险领域的应用。本研究旨在弥合这一差距，提供既能预测概念又能定位概念的解决方案。

Method: 提出了一种名为ViConEx-Med的新型Transformer模型，该模型引入了多概念可学习标记，并利用专门的注意力层来处理视觉和文本概念标记，从而生成概念级别的定位图。

Result: 在合成和真实世界的医学数据集上的实验表明，ViConEx-Med在概念检测和定位精度方面优于之前基于概念的模型，并且在预测准确性方面与黑盒模型相当。

Conclusion: ViConEx-Med为构建基于视觉概念的、内在地可解释的模型提供了一个有前途的方向，解决了现有方法在视觉解释方面的局限性。

Abstract: Concept-based models aim to explain model decisions with human-understandable
concepts. However, most existing approaches treat concepts as numerical
attributes, without providing complementary visual explanations that could
localize the predicted concepts. This limits their utility in real-world
applications and particularly in high-stakes scenarios, such as medical
use-cases. This paper proposes ViConEx-Med, a novel transformer-based framework
for visual concept explainability, which introduces multi-concept learnable
tokens to jointly predict and localize visual concepts. By leveraging
specialized attention layers for processing visual and text-based concept
tokens, our method produces concept-level localization maps while maintaining
high predictive accuracy. Experiments on both synthetic and real-world medical
datasets demonstrate that ViConEx-Med outperforms prior concept-based models
and achieves competitive performance with black-box models in terms of both
concept detection and localization precision. Our results suggest a promising
direction for building inherently interpretable models grounded in visual
concepts. Code is publicly available at
https://github.com/CristianoPatricio/viconex-med.

</details>


### [58] [HccePose(BF): Predicting Front \& Back Surfaces to Construct Ultra-Dense 2D-3D Correspondences for Pose Estimation](https://arxiv.org/abs/2510.10177)
*Yulin Wang,Mengting Hu,Hongli Li,Chen Luo*

Main category: cs.CV

TL;DR: 本研究提出了一种新的姿态估计方法，通过结合物体的前后表面和内部信息，并使用 HCCE 编码技术，提高了姿态估计的精度，并在 BOP 数据集上取得了 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 当前物体姿态估计方法主要关注物体正面表面信息的利用，忽略了物体背面和内部信息，限制了精度的进一步提升。

Method: 提出一种新的姿态估计方法，该方法预测物体前后表面的三维坐标并密集采样其间的坐标点，以创建超密集二维-三维对应关系。同时，提出 HCCE 编码技术来更准确高效地表示表面坐标。

Result: 实验结果表明，所提出的方法在七个经典的 BOP 核心数据集上，相比现有的 SOTA 方法，在姿态估计精度上表现更优。

Conclusion: 本研究提出的方法能够有效利用物体的全部表面和内部信息，通过创建超密集二维-三维对应关系和使用 HCCE 编码技术，显著提高了物体姿态估计的准确性，并在多个标准数据集上验证了其 SOTA 性能。

Abstract: In pose estimation for seen objects, a prevalent pipeline involves using
neural networks to predict dense 3D coordinates of the object surface on 2D
images, which are then used to establish dense 2D-3D correspondences. However,
current methods primarily focus on more efficient encoding techniques to
improve the precision of predicted 3D coordinates on the object's front
surface, overlooking the potential benefits of incorporating the back surface
and interior of the object. To better utilize the full surface and interior of
the object, this study predicts 3D coordinates of both the object's front and
back surfaces and densely samples 3D coordinates between them. This process
creates ultra-dense 2D-3D correspondences, effectively enhancing pose
estimation accuracy based on the Perspective-n-Point (PnP) algorithm.
Additionally, we propose Hierarchical Continuous Coordinate Encoding (HCCE) to
provide a more accurate and efficient representation of front and back surface
coordinates. Experimental results show that, compared to existing
state-of-the-art (SOTA) methods on the BOP website, the proposed approach
outperforms across seven classic BOP core datasets. Code is available at
https://github.com/WangYuLin-SEU/HCCEPose.

</details>


### [59] [TCMA: Text-Conditioned Multi-granularity Alignment for Drone Cross-Modal Text-Video Retrieval](https://arxiv.org/abs/2510.10180)
*Zixu Zhao,Yang Zhan*

Main category: cs.CV

TL;DR: 该论文构建了一个新的无人机视频-文本匹配数据集（DVTMD），包含2864个视频和14320个细粒度、多样化的标题，以解决现有数据集的不足。在此基础上，提出了一种名为文本条件多粒度对齐（TCMA）的框架，该框架通过全局视频-句子对齐、句子引导帧聚合和单词引导块对齐来改进文本-视频检索。TCMA框架在DVTMD和CapERA数据集上取得了最先进的性能，证明了该数据集和方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的无人机视频领域文本-视频检索方法由于数据集的限制（如标题粗糙、冗余）而发展不足。本研究旨在构建一个更优的数据集和提出一个更有效的检索框架，以推动该领域的发展。

Method: 1. 构建了无人机视频-文本匹配数据集（DVTMD），包含2864个视频和14320个细粒度、多语义的标题。2. 提出了文本条件多粒度对齐（TCMA）框架，结合了全局视频-句子对齐、句子引导帧聚合、单词引导块对齐。3. 设计了单词和块选择模块以及文本自适应动态温度机制来优化局部对齐。

Result: 在DVTMD和CapERA数据集上进行了广泛的实验，TCMA框架在文本到视频检索中达到了45.5%的R@1，在视频到文本检索中达到了42.8%的R@1，取得了最先进的性能。

Conclusion: 所提出的DVTMD数据集和TCMA框架为无人机文本-视频检索提供了有效的基准和解决方案，显著提高了检索性能。

Abstract: Unmanned aerial vehicles (UAVs) have become powerful platforms for real-time,
high-resolution data collection, producing massive volumes of aerial videos.
Efficient retrieval of relevant content from these videos is crucial for
applications in urban management, emergency response, security, and disaster
relief. While text-video retrieval has advanced in natural video domains, the
UAV domain remains underexplored due to limitations in existing datasets, such
as coarse and redundant captions. Thus, in this work, we construct the Drone
Video-Text Match Dataset (DVTMD), which contains 2,864 videos and 14,320
fine-grained, semantically diverse captions. The annotations capture multiple
complementary aspects, including human actions, objects, background settings,
environmental conditions, and visual style, thereby enhancing text-video
correspondence and reducing redundancy. Building on this dataset, we propose
the Text-Conditioned Multi-granularity Alignment (TCMA) framework, which
integrates global video-sentence alignment, sentence-guided frame aggregation,
and word-guided patch alignment. To further refine local alignment, we design a
Word and Patch Selection module that filters irrelevant content, as well as a
Text-Adaptive Dynamic Temperature Mechanism that adapts attention sharpness to
text type. Extensive experiments on DVTMD and CapERA establish the first
complete benchmark for drone text-video retrieval. Our TCMA achieves
state-of-the-art performance, including 45.5% R@1 in text-to-video and 42.8%
R@1 in video-to-text retrieval, demonstrating the effectiveness of our dataset
and method. The code and dataset will be released.

</details>


### [60] [Fairness Without Labels: Pseudo-Balancing for Bias Mitigation in Face Gender Classification](https://arxiv.org/abs/2510.10191)
*Haohua Dong,Ana Manzano Rodríguez,Camille Guinaudeau,Shin'ichi Satoh*

Main category: cs.CV

TL;DR: 伪平衡是一种通过在伪标签选择过程中强制执行人口统计平衡来减少面部性别分类模型偏差的半监督学习策略，即使在没有地面真实标注的情况下也能提高公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 面部性别分类模型往往会反映并放大训练数据中存在的人口统计偏差，导致在性别和种族亚组中的表现不均衡。

Method: 在伪标签选择过程中强制执行人口统计平衡，仅使用来自种族平衡数据集的未标记图像，而无需访问地面真实标注。

Result: 伪平衡持续提高公平性，同时保持或提高准确性。该方法实现了 79.81% 的总体准确率（比基线提高了 6.53%），并将性别准确性差距缩小了 44.17%。在基线差异超过 49% 的东亚亚组中，差距缩小到仅 5.01%。

Conclusion: 即使在没有标签监督的情况下，也可以访问人口统计平衡或中度倾斜的未标记数据集，作为去偏现有计算机视觉模型的有力资源。

Abstract: Face gender classification models often reflect and amplify demographic
biases present in their training data, leading to uneven performance across
gender and racial subgroups. We introduce pseudo-balancing, a simple and
effective strategy for mitigating such biases in semi-supervised learning. Our
method enforces demographic balance during pseudo-label selection, using only
unlabeled images from a race-balanced dataset without requiring access to
ground-truth annotations.
  We evaluate pseudo-balancing under two conditions: (1) fine-tuning a biased
gender classifier using unlabeled images from the FairFace dataset, and (2)
stress-testing the method with intentionally imbalanced training data to
simulate controlled bias scenarios. In both cases, models are evaluated on the
All-Age-Faces (AAF) benchmark, which contains a predominantly East Asian
population. Our results show that pseudo-balancing consistently improves
fairness while preserving or enhancing accuracy. The method achieves 79.81%
overall accuracy - a 6.53% improvement over the baseline - and reduces the
gender accuracy gap by 44.17%. In the East Asian subgroup, where baseline
disparities exceeded 49%, the gap is narrowed to just 5.01%. These findings
suggest that even in the absence of label supervision, access to a
demographically balanced or moderately skewed unlabeled dataset can serve as a
powerful resource for debiasing existing computer vision models.

</details>


### [61] [B2N3D: Progressive Learning from Binary to N-ary Relationships for 3D Object Grounding](https://arxiv.org/abs/2510.10194)
*Feng Xiao,Hongbin Xu,Hai Ci,Wenxiong Kang*

Main category: cs.CV

TL;DR: 该研究提出了一种渐进式关系学习框架，用于在3D场景中根据自然语言描述精确定位物体，解决了现有方法仅考虑成对关系而忽略全局n元关系的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3D物体本地化方法在处理涉及多个空间关系的自然语言描述时存在困难，因为它们仅模拟成对物体关系，忽视了n元组合在多模态关系理解中的全局感知重要性。

Method: 提出了一种新颖的渐进式关系学习框架，将关系学习从二元扩展到n元，以全局方式识别与参考描述匹配的视觉关系。由于缺乏特定注释，设计了一种分组监督损失来促进n元关系学习。在包含n元关系和多模态网络（具有混合注意力机制）的场景图中，进一步在n元组合中定位目标。

Result: 所提出的方法在ReferIt3D和ScanRefer数据集上进行了实验和消融研究，结果表明其性能优于现有技术水平。

Conclusion: 实验证明，n元关系感知对于3D物体本地化具有优势，并且所提出的框架能够有效地进行3D物体本地化。

Abstract: Localizing 3D objects using natural language is essential for robotic scene
understanding. The descriptions often involve multiple spatial relationships to
distinguish similar objects, making 3D-language alignment difficult. Current
methods only model relationships for pairwise objects, ignoring the global
perceptual significance of n-ary combinations in multi-modal relational
understanding. To address this, we propose a novel progressive relational
learning framework for 3D object grounding. We extend relational learning from
binary to n-ary to identify visual relations that match the referential
description globally. Given the absence of specific annotations for referred
objects in the training data, we design a grouped supervision loss to
facilitate n-ary relational learning. In the scene graph created with n-ary
relationships, we use a multi-modal network with hybrid attention mechanisms to
further localize the target within the n-ary combinations. Experiments and
ablation studies on the ReferIt3D and ScanRefer benchmarks demonstrate that our
method outperforms the state-of-the-art, and proves the advantages of the n-ary
relational perception in 3D localization.

</details>


### [62] [From Generic to Specialized: A Subspecialty Diagnostic System Powered by Self-Supervised Learning for Cervical Histopathology](https://arxiv.org/abs/2510.10196)
*Yizhi Wang,Li Chen,Qiang Huang,Tian Guan,Xi Deng,Zhiyuan Shen,Jiawen Li,Xinrui Chen,Bin Hu,Xitong Ling,Taojie Zhu,Zirui Huang,Deshui Yu,Yan Liu,Jiurun Chen,Lianghui Zhu,Qiming He,Yiqing Liu,Diwei Shi,Hanzhong Liu,Junbo Hu,Hongyi Gao,Zhen Song,Xilong Zhao,Chao He,Ming Zhao,Yonghong He*

Main category: cs.CV

TL;DR: CerS-Path是一个用于宫颈病理学诊断的系统，通过自监督学习和多模态增强，提高了准确性和泛化能力，支持多种诊断功能，并在前瞻性测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 宫颈癌的病理学评估复杂且需要支持工具，现有的深度学习模型准确性和泛化性不足，通用基础模型缺乏特异性特征捕捉和任务适应性。

Method: 开发了CerS-Path诊断系统，包含两个预训练阶段：1. 在约1.9亿个组织图像块上进行自监督学习，构建宫颈特异性特征提取器。2. 使用250万图像-文本对进行多模态增强，并集成多种下游诊断功能。

Result: CerS-Path支持八种诊断功能，包括罕见癌症分类和多模态问答，超越了现有基础模型。在3,173个病例的前瞻性测试中，筛查敏感性达到99.38%，并表现出良好的泛化能力。

Conclusion: CerS-Path在宫颈病理学诊断方面取得了显著进展，具有亚专科诊断转化和宫颈癌筛查的潜力。

Abstract: Cervical cancer remains a major malignancy, necessitating extensive and
complex histopathological assessments and comprehensive support tools. Although
deep learning shows promise, these models still lack accuracy and
generalizability. General foundation models offer a broader reach but remain
limited in capturing subspecialty-specific features and task adaptability. We
introduce the Cervical Subspecialty Pathology (CerS-Path) diagnostic system,
developed through two synergistic pretraining stages: self-supervised learning
on approximately 190 million tissue patches from 140,000 slides to build a
cervical-specific feature extractor, and multimodal enhancement with 2.5
million image-text pairs, followed by integration with multiple downstream
diagnostic functions. Supporting eight diagnostic functions, including rare
cancer classification and multimodal Q&A, CerS-Path surpasses prior foundation
models in scope and clinical applicability. Comprehensive evaluations
demonstrate a significant advance in cervical pathology, with prospective
testing on 3,173 cases across five centers maintaining 99.38% screening
sensitivity and excellent generalizability, highlighting its potential for
subspecialty diagnostic translation and cervical cancer screening.

</details>


### [63] [A Style-Based Metric for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Image Datasets](https://arxiv.org/abs/2510.10203)
*Dingyi Yao,Xinyao Han,Ruibo Ming,Zhihang Song,Lihui Peng,Jianming Hu,Danya Yao,Yi Zhang*

Main category: cs.CV

TL;DR: To address the domain gap between synthetic and real-world datasets in autonomous driving, this paper proposes a framework and a novel metric (SEDD) to quantify this gap, enabling systematic diagnosis and targeted enhancement of synthetic datasets.


<details>
  <summary>Details</summary>
Motivation: The unreliability of autonomous driving perception systems necessitates environment-based testing, but real-world testing is impractical. Synthetic datasets are a viable alternative, yet the domain gap between synthetic and real data hinders AI model generalization. Quantifying this gap is crucial for evaluating dataset utility and improving training pipelines.

Method: The paper establishes a systematic framework for quantifying the synthetic-to-real gap. It proposes Style Embedding Distribution Discrepancy (SEDD) as a novel evaluation metric, which uses Gram matrix-based style extraction combined with metric learning optimized for intra-class compactness and inter-class separation to extract style embeddings.

Result: Experiments conducted on various datasets and sim-to-real methods demonstrate that the proposed SEDD metric is capable of quantifying the synthetic-to-real gap.

Conclusion: This work provides a standardized quality control tool for diagnosing and enhancing synthetic datasets, which will aid in the development of data-driven autonomous driving systems.

Abstract: Ensuring the reliability of autonomous driving perception systems requires
extensive environment-based testing, yet real-world execution is often
impractical. Synthetic datasets have therefore emerged as a promising
alternative, offering advantages such as cost-effectiveness, bias free
labeling, and controllable scenarios. However, the domain gap between synthetic
and real-world datasets remains a critical bottleneck for the generalization of
AI-based autonomous driving models. Quantifying this synthetic-to-real gap is
thus essential for evaluating dataset utility and guiding the design of more
effective training pipelines. In this paper, we establish a systematic
framework for quantifying the synthetic-to-real gap in autonomous driving
systems, and propose Style Embedding Distribution Discrepancy (SEDD) as a novel
evaluation metric. Our framework combines Gram matrix-based style extraction
with metric learning optimized for intra-class compactness and inter-class
separation to extract style embeddings. Furthermore, we establish a benchmark
using publicly available datasets. Experiments are conducted on a variety of
datasets and sim-to-real methods, and the results show that our method is
capable of quantifying the synthetic-to-real gap. This work provides a
standardized quality control tool that enables systematic diagnosis and
targeted enhancement of synthetic datasets, advancing future development of
data-driven autonomous driving systems.

</details>


### [64] [Semantic Visual Anomaly Detection and Reasoning in AI-Generated Images](https://arxiv.org/abs/2510.10231)
*Chuangchuang Tan,Xiang Ming,Jinglu Wang,Renshuai Tao,Bin Li,Yunchao Wei,Yao Zhao,Yan Lu*

Main category: cs.CV

TL;DR: AI生成的图像存在语义不一致问题，本文提出了AnomReason基准和AnomAgent模型来检测和评估这些问题。


<details>
  <summary>Details</summary>
Motivation: 检测AI生成图像中的语义异常对于评估其可信度至关重要，尤其是在AIGC图像分析、可解释的深度伪造检测和语义真实性评估等领域。

Method: 本文形式化了AI生成图像的语义异常检测和推理，并引入了AnomReason基准，该基准包含结构化的四元组（名称、现象、推理、严重性）注释。注释是通过多智能体管道AnomAgent生成的，并辅以少量人工验证，以保证规模和质量。AnomAgent在构建时处理了约4.17B的GPT-4o tokens。

Result: 在AnomReason上微调的模型在提出的语义匹配指标（SemAP和SemF1）下，相比强大的视觉-语言基线模型，性能得到了一致提升。将该方法应用于可解释的深度伪造检测和图像生成器的语义合理性评估，证明了其实用性。

Conclusion: AnomReason基准和AnomAgent模型为衡量和改进AI生成图像的语义合理性奠定了基础。研究团队将发布代码、指标、数据和模型，以支持可复现的研究。

Abstract: The rapid advancement of
  AI-generated content (AIGC) has enabled the synthesis of visually convincing
images; however, many such outputs exhibit subtle \textbf{semantic anomalies},
including unrealistic object configurations, violations of physical laws, or
commonsense inconsistencies, which compromise the overall plausibility of the
generated scenes. Detecting these semantic-level anomalies
  is essential for assessing the trustworthiness of AIGC media, especially in
AIGC image analysis, explainable deepfake detection and semantic authenticity
assessment. In this paper,
  we formalize \textbf{semantic anomaly detection and reasoning} for AIGC
images and
  introduce \textbf{AnomReason}, a large-scale benchmark with structured
annotations as quadruples \emph{(Name, Phenomenon, Reasoning, Severity)}.
Annotations are produced by
  a modular multi-agent pipeline (\textbf{AnomAgent}) with lightweight
human-in-the-loop verification, enabling scale while preserving quality.
  At construction time, AnomAgent processed approximately 4.17\,B GPT-4o
tokens, providing scale evidence for the resulting structured annotations. We
further
  show that models fine-tuned on AnomReason achieve consistent gains over
strong vision-language baselines under our proposed semantic matching metric
(\textit{SemAP} and \textit{SemF1}).
  Applications to {explainable deepfake detection} and {semantic reasonableness
assessment of image generators} demonstrate practical utility. In summary,
AnomReason and AnomAgent
  serve as a foundation for measuring and improving the semantic plausibility
of AI-generated images. We will release code, metrics, data, and task-aligned
models to support reproducible research on semantic authenticity and
interpretable AIGC forensics.

</details>


### [65] [MRI Brain Tumor Detection with Computer Vision](https://arxiv.org/abs/2510.10250)
*Jack Krolik,Jake Lynn,John Henry Rudden,Dmytro Vremenko*

Main category: cs.CV

TL;DR: 本研究利用深度学习技术自动检测和分割MRI扫描中的脑肿瘤，并展示了其在提高诊断准确性和效率方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索深度学习技术在自动检测和分割脑肿瘤方面的应用，以期提高诊断的准确性和效率。

Method: 研究采用了包括逻辑回归、卷积神经网络（CNN）和残差网络（ResNet）在内的多种机器学习模型进行分类，并使用U-Net进行语义分割，使用EfficientDet进行对象检测，以增强肿瘤的定位和识别。

Result: 研究结果表明，在脑肿瘤诊断的准确性和效率方面取得了显著的进步。

Conclusion: 深度学习在医学影像分析，特别是在提高临床疗效方面具有巨大潜力。

Abstract: This study explores the application of deep learning techniques in the
automated detection and segmentation of brain tumors from MRI scans. We employ
several machine learning models, including basic logistic regression,
Convolutional Neural Networks (CNNs), and Residual Networks (ResNet) to
classify brain tumors effectively. Additionally, we investigate the use of
U-Net for semantic segmentation and EfficientDet for anchor-based object
detection to enhance the localization and identification of tumors. Our results
demonstrate promising improvements in the accuracy and efficiency of brain
tumor diagnostics, underscoring the potential of deep learning in medical
imaging and its significance in improving clinical outcomes.

</details>


### [66] [Are Video Models Emerging as Zero-Shot Learners and Reasoners in Medical Imaging?](https://arxiv.org/abs/2510.10254)
*Yuxiang Lai,Jike Zhong,Ming Li,Yuheng Li,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 大型视觉模型（LVM）在未接触过医疗数据的情况下，在器官分割、去噪、超分辨率和运动预测等医学影像任务中展现出强大的零样本泛化能力，尤其在放疗运动预测方面达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 将用于自然图像的自回归视频建模原理应用于医学影像任务，以探索模型在无领域特定微调下的零样本泛化能力。

Method: 评估一个大型视觉模型（LVM）在四个医学影像任务（器官分割、去噪、超分辨率、运动预测）上的零样本性能。

Result: LVM 在 CT 扫描中能够描绘解剖结构，并在分割、去噪和超分辨率任务上取得有竞争力且有时甚至优于专业基线模型的性能。特别是在放疗运动预测任务中，LVM 能够根据 4D CT 扫描的先前相位预测未来的 3D CT 相位，生成解剖学上一致且具有时间连贯性的预测，并在 122 名患者的数据上超越了基于 DVF 和生成模型的方法。

Conclusion: 通用视频模型具有零样本学习和推理能力，可以作为医学影像任务的统一学习者，为构建基于视频模型的未来医学基础模型奠定基础。

Abstract: Recent advances in large generative models have shown that simple
autoregressive formulations, when scaled appropriately, can exhibit strong
zero-shot generalization across domains. Motivated by this trend, we
investigate whether autoregressive video modeling principles can be directly
applied to medical imaging tasks, despite the model never being trained on
medical data. Specifically, we evaluate a large vision model (LVM) in a
zero-shot setting across four representative tasks: organ segmentation,
denoising, super-resolution, and motion prediction. Remarkably, even without
domain-specific fine-tuning, the LVM can delineate anatomical structures in CT
scans and achieve competitive performance on segmentation, denoising, and
super-resolution. Most notably, in radiotherapy motion prediction, the model
forecasts future 3D CT phases directly from prior phases of a 4D CT scan,
producing anatomically consistent predictions that capture patient-specific
respiratory dynamics with realistic temporal coherence. We evaluate the LVM on
4D CT data from 122 patients, totaling over 1,820 3D CT volumes. Despite no
prior exposure to medical data, the model achieves strong performance across
all tasks and surpasses specialized DVF-based and generative baselines in
motion prediction, achieving state-of-the-art spatial accuracy. These findings
reveal the emergence of zero-shot capabilities in medical video modeling and
highlight the potential of general-purpose video models to serve as unified
learners and reasoners laying the groundwork for future medical foundation
models built on video models.

</details>


### [67] [Opacity-Gradient Driven Density Control for Compact and Efficient Few-Shot 3D Gaussian Splatting](https://arxiv.org/abs/2510.10257)
*Abdelrhman Elrawy,Emad A. Mohammed*

Main category: cs.CV

TL;DR: 3DGS在少样本场景下表现不佳，FSGS等方法通过增加原始体数量来提高质量。本文提出了一种新的优化框架，使用不透明度梯度作为渲染误差的代理，并结合保守的剪枝策略，显著提高了3DGS的效率，在LLFF和Mip-NeRF 360数据集上分别实现了40%和70%的原始体数量减少，同时保持了良好的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法在少样本场景下存在过拟合和重建臃肿的问题，而FSGS等改进方法会显著增加原始体数量。本文旨在提出一种更高效的3DGS优化框架。

Method: 本文提出了一种新的框架，修改了3DGS的核心优化方法。具体来说，使用不透明度梯度作为渲染误差的轻量级代理，替代了标准的位置梯度启发式方法，作为新的致密化触发器。并将这种激进的致密化方法与更保守的剪枝策略相结合，同时辅以标准的深度相关性损失进行几何引导。

Result: 在3视图LLFF数据集上，本文模型比FSGS模型紧凑40%以上（32k vs 57k primitives）。在Mip-NeRF 360数据集上，模型原始体数量减少了约70%。

Conclusion: 本文提出的框架在效率方面取得了根本性改进，显著减少了3DGS的原始体数量，同时对重建指标的影响很小，在少样本场景下的视图合成质量-效率权衡方面树立了新的标杆。

Abstract: 3D Gaussian Splatting (3DGS) struggles in few-shot scenarios, where its
standard adaptive density control (ADC) can lead to overfitting and bloated
reconstructions. While state-of-the-art methods like FSGS improve quality, they
often do so by significantly increasing the primitive count. This paper
presents a framework that revises the core 3DGS optimization to prioritize
efficiency. We replace the standard positional gradient heuristic with a novel
densification trigger that uses the opacity gradient as a lightweight proxy for
rendering error. We find this aggressive densification is only effective when
paired with a more conservative pruning schedule, which prevents destructive
optimization cycles. Combined with a standard depth-correlation loss for
geometric guidance, our framework demonstrates a fundamental improvement in
efficiency. On the 3-view LLFF dataset, our model is over 40% more compact (32k
vs. 57k primitives) than FSGS, and on the Mip-NeRF 360 dataset, it achieves a
reduction of approximately 70%. This dramatic gain in compactness is achieved
with a modest trade-off in reconstruction metrics, establishing a new
state-of-the-art on the quality-vs-efficiency Pareto frontier for few-shot view
synthesis.

</details>


### [68] [VividAnimator: An End-to-End Audio and Pose-driven Half-Body Human Animation Framework](https://arxiv.org/abs/2510.10269)
*Donglin Huang,Yongyuan Li,Tianhang Liu,Junming Huang,Xiaoda Yang,Chi Wang,Weiwei Xu*

Main category: cs.CV

TL;DR: VividAnimator是一个创新的框架，通过预训练的手部清晰度编码本（HCC）、双流音频感知模块（DSAA）和姿态校准技巧（PCT），解决了现有音频和姿态驱动的人体动画中头部动作僵硬和手部模糊的问题，实现了高质量、半身动画的生成。


<details>
  <summary>Details</summary>
Motivation: 现有音频和姿态驱动的人体动画方法在处理头部动作和手部细节方面存在不足，容易出现头部动作僵硬和手部模糊的问题。

Method: 1. 预训练手部清晰度编码本（HCC）：对预训练的HCC进行编码，以丰富高保真手部纹理先验，从而减轻手部退化。2. 双流音频感知模块（DSAA）：分别对嘴唇同步和头部姿态动力学进行建模，并实现它们之间的交互。3. 姿态校准技巧（PCT）：通过放宽刚性约束来优化和对齐姿态条件，以实现平滑自然的姿态转换。

Result: VividAnimator在生成细节丰富的手部、逼真的姿态和一致的身份特征方面取得了先进的性能，并在定量和定性评估中得到了验证。

Conclusion: VividAnimator通过创新的HCC、DSAA和PCT模块，成功解决了现有方法的局限性，能够生成高质量、驱动自然的半身人体动画。

Abstract: Existing for audio- and pose-driven human animation methods often struggle
with stiff head movements and blurry hands, primarily due to the weak
correlation between audio and head movements and the structural complexity of
hands. To address these issues, we propose VividAnimator, an end-to-end
framework for generating high-quality, half-body human animations driven by
audio and sparse hand pose conditions. Our framework introduces three key
innovations. First, to overcome the instability and high cost of online
codebook training, we pre-train a Hand Clarity Codebook (HCC) that encodes
rich, high-fidelity hand texture priors, significantly mitigating hand
degradation. Second, we design a Dual-Stream Audio-Aware Module (DSAA) to model
lip synchronization and natural head pose dynamics separately while enabling
interaction. Third, we introduce a Pose Calibration Trick (PCT) that refines
and aligns pose conditions by relaxing rigid constraints, ensuring smooth and
natural gesture transitions. Extensive experiments demonstrate that Vivid
Animator achieves state-of-the-art performance, producing videos with superior
hand detail, gesture realism, and identity consistency, validated by both
quantitative metrics and qualitative evaluations.

</details>


### [69] [Bridging Perspectives: Foundation Model Guided BEV Maps for 3D Object Detection and Tracking](https://arxiv.org/abs/2510.10287)
*Markus Käppeler,Özgün Çiçek,Daniele Cattaneo,Claudius Gläser,Yakov Miron,Abhinav Valada*

Main category: cs.CV

TL;DR: DualViewDistill是一个结合了视角（PV）和鸟瞰图（BEV）特征的混合3D目标检测和跟踪框架，利用DINOv2特征增强了BEV表示，并在nuScenes和Argoverse 2基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中的相机3D目标检测和跟踪方法，要么仅依赖透视视图（PV）特征，要么仅依赖鸟瞰图（BEV）特征，这限制了它们同时利用精细物体细节和空间结构化场景表示的能力。

Method: 提出了一种名为DualViewDistill的混合检测和跟踪框架，该框架结合了PV和BEV相机图像特征。该方法通过新颖的蒸馏过程，利用基础模型引导的BEV图，并将描述性的DINOv2特征蒸馏到BEV表示中。通过可变形聚合整合了PV特征和由DINOv2语义及几何特征丰富后的BEV图，以增强3D目标检测和跟踪。

Result: 在nuScenes和Argoverse 2基准测试上的大量实验表明，DualViewDistill在3D目标检测和跟踪方面取得了最先进的性能。

Conclusion: 基础模型BEV图有潜力为自动驾驶提供更可靠的感知能力。

Abstract: Camera-based 3D object detection and tracking are essential for perception in
autonomous driving. Current state-of-the-art approaches often rely exclusively
on either perspective-view (PV) or bird's-eye-view (BEV) features, limiting
their ability to leverage both fine-grained object details and spatially
structured scene representations. In this work, we propose DualViewDistill, a
hybrid detection and tracking framework that incorporates both PV and BEV
camera image features to leverage their complementary strengths. Our approach
introduces BEV maps guided by foundation models, leveraging descriptive DINOv2
features that are distilled into BEV representations through a novel
distillation process. By integrating PV features with BEV maps enriched with
semantic and geometric features from DINOv2, our model leverages this hybrid
representation via deformable aggregation to enhance 3D object detection and
tracking. Extensive experiments on the nuScenes and Argoverse 2 benchmarks
demonstrate that DualViewDistill achieves state-of-the-art performance. The
results showcase the potential of foundation model BEV maps to enable more
reliable perception for autonomous driving. We make the code and pre-trained
models available at https://dualviewdistill.cs.uni-freiburg.de .

</details>


### [70] [SAM2LoRA: Composite Loss-Guided, Parameter-Efficient Finetuning of SAM2 for Retinal Fundus Segmentation](https://arxiv.org/abs/2510.10288)
*Sayan Mandal,Divyadarshini Karthikeyan,Manas Paldhe*

Main category: cs.CV

TL;DR: SAM2LoRA是一种参数高效的微调策略，通过集成低秩适配器来适配SAM2模型进行眼底图像分割，在保持高精度的同时显著降低了训练开销。


<details>
  <summary>Details</summary>
Motivation: 现有的SAM2模型在眼底图像分割任务上进行微调时面临挑战，需要一种更高效的微调方法。

Method: 提出SAM2LoRA，将低秩适配器集成到SAM2模型的图像编码器和掩码解码器中，使其可训练参数量减少到原始的5%以下。同时，采用结合了segmentationBCE、SoftDice和FocalTversky的复合损失函数进行网络调优。

Result: 在11个具有挑战性的眼底分割数据集上进行评估，SAM2LoRA在跨数据集的血管和视盘分割任务中均表现出高精度。血管分割的Dice分数最高可达0.86，视盘分割的Dice分数最高可达0.93；AUC值分别最高可达0.98和0.99。

Conclusion: SAM2LoRA在眼底图像分割任务上实现了最先进的性能，同时大幅降低了训练成本，证明了其作为参数高效微调策略的有效性。

Abstract: We propose SAM2LoRA, a parameter-efficient fine-tuning strategy that adapts
the Segment Anything Model 2 (SAM2) for fundus image segmentation. SAM2 employs
a masked autoencoder-pretrained Hierarchical Vision Transformer for multi-scale
feature decoding, enabling rapid inference in low-resource settings; however,
fine-tuning remains challenging. To address this, SAM2LoRA integrates a
low-rank adapter into both the image encoder and mask decoder, requiring fewer
than 5\% of the original trainable parameters. Our analysis indicates that for
cross-dataset fundus segmentation tasks, a composite loss function combining
segmentationBCE, SoftDice, and FocalTversky losses is essential for optimal
network tuning. Evaluated on 11 challenging fundus segmentation datasets,
SAM2LoRA demonstrates high performance in both blood vessel and optic disc
segmentation under cross-dataset training conditions. It achieves Dice scores
of up to 0.86 and 0.93 for blood vessel and optic disc segmentation,
respectively, and AUC values of up to 0.98 and 0.99, achieving state-of-the-art
performance while substantially reducing training overhead.

</details>


### [71] [From Programs to Poses: Factored Real-World Scene Generation via Learned Program Libraries](https://arxiv.org/abs/2510.10292)
*Joy Hsu,Emily Jin,Jiajun Wu,Niloy J. Mitra*

Main category: cs.CV

TL;DR: FactoredScenes是一个新的框架，用于生成逼真的3D场景，通过分解场景到房间布局和物体姿态，并利用函数库和大型语言模型来学习和生成。


<details>
  <summary>Details</summary>
Motivation: 真实世界的场景数据有限，生成具有不同物体姿态的逼真场景是一个挑战。

Method: 提出了一种分解表示，将场景分解为房间程序和物体姿态的层级概念。学习了一个函数库来捕捉可重用的布局模式，并使用大型语言模型来生成房间程序。然后，使用一个条件模型来层级地预测物体姿态，并将3D物体放入场景中。

Result: FactoredScenes能够生成逼真的、难以与真实ScanNet场景区分的房间。

Conclusion: FactoredScenes在生成逼真的3D场景方面取得了成功，解决了真实世界数据有限和物体姿态变化的问题。

Abstract: Real-world scenes, such as those in ScanNet, are difficult to capture, with
highly limited data available. Generating realistic scenes with varied object
poses remains an open and challenging task. In this work, we propose
FactoredScenes, a framework that synthesizes realistic 3D scenes by leveraging
the underlying structure of rooms while learning the variation of object poses
from lived-in scenes. We introduce a factored representation that decomposes
scenes into hierarchically organized concepts of room programs and object
poses. To encode structure, FactoredScenes learns a library of functions
capturing reusable layout patterns from which scenes are drawn, then uses large
language models to generate high-level programs, regularized by the learned
library. To represent scene variations, FactoredScenes learns a
program-conditioned model to hierarchically predict object poses, and retrieves
and places 3D objects in a scene. We show that FactoredScenes generates
realistic, real-world rooms that are difficult to distinguish from real ScanNet
scenes.

</details>


### [72] [Ordinal Scale Traffic Congestion Classification with Multi-Modal Vision-Language and Motion Analysis](https://arxiv.org/abs/2510.10342)
*Yu-Hsuan Lin*

Main category: cs.CV

TL;DR: 该研究提出了一种结合CLIP、YOLO-World和MOG2背景减除的多模态框架，用于交通拥堵分类，达到了76.7%的准确率。


<details>
  <summary>Details</summary>
Motivation: 准确的交通拥堵分类对于智能交通系统和实时城市交通管理至关重要。

Method: 该研究提出了一种多模态框架，结合了开放词汇视觉-语言推理（CLIP）、物体检测（YOLO-World）以及基于MOG2背景减除的运动分析。该系统能够对从1（自由流）到5（严重拥堵）的序数尺度上的拥堵水平进行预测，实现语义对齐和时间一致的分类。为了增强可解释性，该研究还引入了基于运动的置信度加权，并生成了带注释的视觉输出。

Result: 实验结果显示，该模型达到了76.7%的准确率，F1分数为0.752，二次加权Kappa（QWK）为0.684，显著优于单一模态的基线模型。

Conclusion: 实验结果证明了该框架在保持序数结构和利用视觉-语言及运动模态方面的有效性。未来的改进方向包括纳入车辆尺寸和精炼的密度指标。

Abstract: Accurate traffic congestion classification is essential for intelligent
transportation systems and real-time urban traffic management. This paper
presents a multimodal framework combining open-vocabulary visual-language
reasoning (CLIP), object detection (YOLO-World), and motion analysis via
MOG2-based background subtraction. The system predicts congestion levels on an
ordinal scale from 1 (free flow) to 5 (severe congestion), enabling
semantically aligned and temporally consistent classification. To enhance
interpretability, we incorporate motion-based confidence weighting and generate
annotated visual outputs. Experimental results show the model achieves 76.7
percent accuracy, an F1 score of 0.752, and a Quadratic Weighted Kappa (QWK) of
0.684, significantly outperforming unimodal baselines. These results
demonstrate the framework's effectiveness in preserving ordinal structure and
leveraging visual-language and motion modalities. Future enhancements include
incorporating vehicle sizing and refined density metrics.

</details>


### [73] [Ortho-Fuse: Orthomosaic Generation for Sparse High-Resolution Crop Health Maps Through Intermediate Optical Flow Estimation](https://arxiv.org/abs/2510.10360)
*Rugved Katole,Christopher Stewart*

Main category: cs.CV

TL;DR: AI-driven 农作物健康绘图系统可以通过减少重叠图像的需求来改进，从而提高农民的采用率。


<details>
  <summary>Details</summary>
Motivation: 传统航空摄影测量方法需要高重叠率才能准确重建，而 AI 系统在资源受限的情况下难以满足这一要求，从而阻碍了农民的广泛采用。

Method: 提出了一种名为 Ortho-Fuse 的基于光流的框架，该框架通过合成中间图像来增加特征对应，从而在较低的重叠率下生成可靠的正射影像。

Result: 实验证明，该方法可将最低重叠率要求降低 20%，并分析了精准农业的采用障碍。

Conclusion: Ortho-Fuse 通过降低对重叠图像的要求，为 AI 驱动的监测系统在精准农业中的广泛应用铺平了道路。

Abstract: AI-driven crop health mapping systems offer substantial advantages over
conventional monitoring approaches through accelerated data acquisition and
cost reduction. However, widespread farmer adoption remains constrained by
technical limitations in orthomosaic generation from sparse aerial imagery
datasets. Traditional photogrammetric reconstruction requires 70-80\%
inter-image overlap to establish sufficient feature correspondences for
accurate geometric registration. AI-driven systems operating under
resource-constrained conditions cannot consistently achieve these overlap
thresholds, resulting in degraded reconstruction quality that undermines user
confidence in autonomous monitoring technologies. In this paper, we present
Ortho-Fuse, an optical flow-based framework that enables the generation of a
reliable orthomosaic with reduced overlap requirements. Our approach employs
intermediate flow estimation to synthesize transitional imagery between
consecutive aerial frames, artificially augmenting feature correspondences for
improved geometric reconstruction. Experimental validation demonstrates a 20\%
reduction in minimum overlap requirements. We further analyze adoption barriers
in precision agriculture to identify pathways for enhanced integration of
AI-driven monitoring systems.

</details>


### [74] [PointMAC: Meta-Learned Adaptation for Robust Test-Time Point Cloud Completion](https://arxiv.org/abs/2510.10365)
*Linlian Jiang,Rui Ma,Li Gu,Ziqiang Wang,Xinxin Zuo,Yang Wang*

Main category: cs.CV

TL;DR: PointMAC是一种用于点云补全的元学习框架，通过在测试时进行样本特定的自监督适应，提高了对新颖结构和传感器畸变的鲁棒性，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在点云补全方面存在静态推理和对训练时归纳偏倚的过度依赖，限制了其在测试时适应新结构和传感器畸变的能力。

Method: PointMAC框架通过两个自监督辅助目标（模拟结构和传感器层面的不完整性）来优化补全模型，并采用基于MAML的元辅助学习策略来对齐适应与主任务。在推理时，通过优化辅助损失对共享编码器进行动态适应，同时保持解码器固定。此外，引入了自适应λ校准机制来平衡主辅助目标的梯度。

Result: PointMAC在合成、模拟和真实世界数据集上取得了最先进的成果，通过对每个样本进行单独优化，生成了高质量的点云补全。

Conclusion: PointMAC是首个将元辅助测试时适应应用于点云补全的工作，通过样本级的自监督适应，显著提高了点云补全的鲁棒性和质量。

Abstract: Point cloud completion is essential for robust 3D perception in
safety-critical applications such as robotics and augmented reality. However,
existing models perform static inference and rely heavily on inductive biases
learned during training, limiting their ability to adapt to novel structural
patterns and sensor-induced distortions at test time. To address this
limitation, we propose PointMAC, a meta-learned framework for robust test-time
adaptation in point cloud completion. It enables sample-specific refinement
without requiring additional supervision. Our method optimizes the completion
model under two self-supervised auxiliary objectives that simulate structural
and sensor-level incompleteness. A meta-auxiliary learning strategy based on
Model-Agnostic Meta-Learning (MAML) ensures that adaptation driven by auxiliary
objectives is consistently aligned with the primary completion task. During
inference, we adapt the shared encoder on-the-fly by optimizing auxiliary
losses, with the decoder kept fixed. To further stabilize adaptation, we
introduce Adaptive $\lambda$-Calibration, a meta-learned mechanism for
balancing gradients between primary and auxiliary objectives. Extensive
experiments on synthetic, simulated, and real-world datasets demonstrate that
PointMAC achieves state-of-the-art results by refining each sample individually
to produce high-quality completions. To the best of our knowledge, this is the
first work to apply meta-auxiliary test-time adaptation to point cloud
completion.

</details>


### [75] [Vision4PPG: Emergent PPG Analysis Capability of Vision Foundation Models for Vital Signs like Blood Pressure](https://arxiv.org/abs/2510.10366)
*Saurabh Kataria,Ayca Ermis,Lovely Yeswanth Panchumarthi,Minxiao Wang,Xiao Hu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Photoplethysmography (PPG) sensor in wearable and clinical devices provides
valuable physiological insights in a non-invasive and real-time fashion.
Specialized Foundation Models (FM) or repurposed time-series FMs are used to
benchmark physiological tasks. Our experiments with fine-tuning FMs reveal that
Vision FM (VFM) can also be utilized for this purpose and, in fact,
surprisingly leads to state-of-the-art (SOTA) performance on many tasks,
notably blood pressure estimation. We leverage VFMs by simply transforming
one-dimensional PPG signals into image-like two-dimensional representations,
such as the Short-Time Fourier transform (STFT). Using the latest VFMs, such as
DINOv3 and SIGLIP-2, we achieve promising performance on other vital signs and
blood lab measurement tasks as well. Our proposal, Vision4PPG, unlocks a new
class of FMs to achieve SOTA performance with notable generalization to other
2D input representations, including STFT phase and recurrence plots. Our work
improves upon prior investigations of vision models for PPG by conducting a
comprehensive study, comparing them to state-of-the-art time-series FMs, and
demonstrating the general PPG processing ability by reporting results on six
additional tasks. Thus, we provide clinician-scientists with a new set of
powerful tools that is also computationally efficient, thanks to
Parameter-Efficient Fine-Tuning (PEFT) techniques.

</details>


### [76] [Self-Supervised Multi-Scale Transformer with Attention-Guided Fusion for Efficient Crack Detection](https://arxiv.org/abs/2510.10378)
*Blessing Agyei Kyem,Joshua Kofi Asamoah,Eugene Denteh,Andrews Danyo,Armstrong Aboah*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Crack-Segmenter的全自监督框架，用于无需手动标注的像素级路面裂缝分割，并在多个公共数据集上取得了优于现有监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 路面裂缝检测依赖于昂贵且耗时的人工像素级标注，限制了大规模基础设施监控的可扩展性。本研究旨在克服这一障碍，探索完全无需手动标注即可实现有效像素级裂缝分割的可行性。

Method: 开发了一个名为Crack-Segmenter的全自监督框架，该框架集成了三个模块：用于鲁棒多尺度特征提取的尺度自适应嵌入器（SAE）、用于保持裂缝线性连续性的方向注意力Transformer（DAT）以及用于自适应特征整合的注意力引导融合（AGF）模块。

Result: 在十个公共数据集上的评估显示，Crack-Segmenter在平均交并比（mIoU）、Dice分数、XOR和Hausdorff距离（HD）等主要指标上，始终优于13种最先进的监督方法。

Conclusion: 研究结果表明，无需标注的路面裂缝检测不仅可行，而且性能更优，能够使交通部门和基础设施管理者进行可扩展且经济高效的监控。这项工作推动了自监督学习的发展，并为路面裂缝检测研究提供了新的方向。

Abstract: Pavement crack detection has long depended on costly and time-intensive
pixel-level annotations, which limit its scalability for large-scale
infrastructure monitoring. To overcome this barrier, this paper examines the
feasibility of achieving effective pixel-level crack segmentation entirely
without manual annotations. Building on this objective, a fully self-supervised
framework, Crack-Segmenter, is developed, integrating three complementary
modules: the Scale-Adaptive Embedder (SAE) for robust multi-scale feature
extraction, the Directional Attention Transformer (DAT) for maintaining linear
crack continuity, and the Attention-Guided Fusion (AGF) module for adaptive
feature integration. Through evaluations on ten public datasets,
Crack-Segmenter consistently outperforms 13 state-of-the-art supervised methods
across all major metrics, including mean Intersection over Union (mIoU), Dice
score, XOR, and Hausdorff Distance (HD). These findings demonstrate that
annotation-free crack detection is not only feasible but also superior,
enabling transportation agencies and infrastructure managers to conduct
scalable and cost-effective monitoring. This work advances self-supervised
learning and motivates pavement cracks detection research.

</details>


### [77] [Identifying bias in CNN image classification using image scrambling and transforms](https://arxiv.org/abs/2510.10383)
*Sai Teja Erukude*

Main category: cs.CV

TL;DR: CNNs存在“黑箱”问题，难以确定哪些特征最具影响力，可能导致偏见。本文提出通过图像切块和图像变换（傅里叶、小波、中值滤波）来识别CNN中的背景噪声和偏见。


<details>
  <summary>Details</summary>
Motivation: 现有CNN模型难以确定哪些特征最具影响力，存在“黑箱”问题，可能导致决策偏见。需要方法来区分图像中的背景噪声和上下文信息。

Method: 提出两种方法：1.将图像切分成不同大小的块并随机打乱，增加分类难度。2.应用傅里叶变换、小波变换和中值滤波等图像变换及其组合，以恢复CNN用于分类的背景噪声信息。

Result: 实验结果表明，所提出的方法能够有效地区分上下文信息和背景噪声，并在没有背景信息的情况下也能识别出背景噪声。

Conclusion: 所提出的基于图像切块和图像变换的方法可以有效识别CNN中的背景噪声和偏见，有助于提高模型的鲁棒性和可解释性。

Abstract: CNNs are now prevalent as the primary choice for most machine vision problems
due to their superior rate of classification and the availability of
user-friendly libraries. These networks effortlessly identify and select
features in a non-intuitive data-driven manner, making it difficult to
determine which features were most influential. That leads to a ``black box",
where users cannot know how the image data are analyzed but rely on empirical
results. Therefore the decision-making process can be biased by background
information that is difficult to detect. Here we discuss examples of such
hidden biases and propose techniques for identifying them, methods to
distinguish between contextual information and background noise, and explore
whether CNNs learn from irrelevant features. One effective approach to identify
dataset bias is to classify blank background parts of the images. However, in
some situations a blank background in the images is not available, making it
more difficult to separate the foreground information from the blank
background. Such parts of the image can also be considered contextual learning,
not necessarily bias. To overcome this, we propose two approaches that were
tested on six different datasets, including natural, synthetic, and hybrid
datasets. The first method involves dividing images into smaller,
non-overlapping tiles of various sizes, which are then shuffled randomly,
making classification more challenging. The second method involves the
application of several image transforms, including Fourier, Wavelet transforms,
and Median filter, and their combinations. These transforms help recover
background noise information used by CNN to classify images. Results indicate
that this method can effectively distinguish between contextual information and
background noise, and alert on the presence of background noise even without
the need to use background information.

</details>


### [78] [AVoCaDO: An Audiovisual Video Captioner Driven by Temporal Orchestration](https://arxiv.org/abs/2510.10395)
*Xinlong Chen,Yue Ding,Weihong Lin,Jingyun Hua,Linli Yao,Yang Shi,Bozhou Li,Yuanxing Zhang,Qiang Liu,Pengfei Wan,Liang Wang,Tieniu Tan*

Main category: cs.CV

TL;DR: AVoCaDO是一个强大的视听视频字幕生成器，通过视听模态之间的时间协调来驱动，在四个视听视频字幕基准测试中显著优于现有的开源模型。


<details>
  <summary>Details</summary>
Motivation: 视听视频字幕生成旨在生成与视觉和听觉事件在时间上对齐的语义丰富的描述，从而有利于视频理解和生成。

Method: AVoCaDO采用了一个两阶段的后训练流程：1）AVoCaDO SFT，在107K高质量、时间对齐的视听字幕新数据集上对模型进行微调；2）AVoCaDO GRPO，利用定制的奖励函数来进一步提高时间连贯性和对话准确性，同时规范字幕长度并减少崩溃。

Result: 实验结果表明，AVoCaDO在四个视听视频字幕基准测试中显著优于现有的开源模型，并且在仅视觉设置下在VDC和DREAM-1K基准测试上也取得了有竞争力的性能。

Conclusion: AVoCaDO通过新颖的视听模态时间协调方法，在视听视频字幕生成任务上取得了最先进的性能。

Abstract: Audiovisual video captioning aims to generate semantically rich descriptions
with temporal alignment between visual and auditory events, thereby benefiting
both video understanding and generation. In this paper, we present AVoCaDO, a
powerful audiovisual video captioner driven by the temporal orchestration
between audio and visual modalities. We propose a two-stage post-training
pipeline: (1) AVoCaDO SFT, which fine-tunes the model on a newly curated
dataset of 107K high-quality, temporally-aligned audiovisual captions; and (2)
AVoCaDO GRPO, which leverages tailored reward functions to further enhance
temporal coherence and dialogue accuracy while regularizing caption length and
reducing collapse. Experimental results demonstrate that AVoCaDO significantly
outperforms existing open-source models across four audiovisual video
captioning benchmarks, and also achieves competitive performance on the VDC and
DREAM-1K benchmark under visual-only settings.

</details>


### [79] [Mesh-Gait: A Unified Framework for Gait Recognition Through Multi-Modal Representation Learning from 2D Silhouettes](https://arxiv.org/abs/2510.10406)
*Zhao-Yang Wang,Jieneng Chen,Jiang Liu,Yuxiang Guo,Rama Chellappa*

Main category: cs.CV

TL;DR: Mesh-Gait通过从2D剪影直接重建3D表示来解决2D步态识别的局限性，实现了计算效率和准确性的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的步态识别方法在处理视角变化、遮挡和噪声方面存在不足，而基于3D的方法计算成本高昂，不适用于实时应用。

Method: Mesh-Gait 提出了一种新颖的端到端多模态步态识别框架，通过将2D剪影重建为3D热图作为中间表示，从而有效地融合2D和3D步态信息，并从中提取判别性特征。

Result: Mesh-Gait 能够有效地捕捉空间和结构步态特征，同时避免了直接从RGB视频进行3D重建的计算开销，在广泛的实验中取得了最先进的准确性。

Conclusion: Mesh-Gait 通过直接从2D剪影重建3D表示，克服了现有步态识别方法的局限性，在保持计算效率的同时提高了识别准确性。

Abstract: Gait recognition, a fundamental biometric technology, leverages unique
walking patterns for individual identification, typically using 2D
representations such as silhouettes or skeletons. However, these methods often
struggle with viewpoint variations, occlusions, and noise. Multi-modal
approaches that incorporate 3D body shape information offer improved robustness
but are computationally expensive, limiting their feasibility for real-time
applications. To address these challenges, we introduce Mesh-Gait, a novel
end-to-end multi-modal gait recognition framework that directly reconstructs 3D
representations from 2D silhouettes, effectively combining the strengths of
both modalities. Compared to existing methods, directly learning 3D features
from 3D joints or meshes is complex and difficult to fuse with silhouette-based
gait features. To overcome this, Mesh-Gait reconstructs 3D heatmaps as an
intermediate representation, enabling the model to effectively capture 3D
geometric information while maintaining simplicity and computational
efficiency. During training, the intermediate 3D heatmaps are gradually
reconstructed and become increasingly accurate under supervised learning, where
the loss is calculated between the reconstructed 3D joints, virtual markers,
and 3D meshes and their corresponding ground truth, ensuring precise spatial
alignment and consistent 3D structure. Mesh-Gait extracts discriminative
features from both silhouettes and reconstructed 3D heatmaps in a
computationally efficient manner. This design enables the model to capture
spatial and structural gait characteristics while avoiding the heavy overhead
of direct 3D reconstruction from RGB videos, allowing the network to focus on
motion dynamics rather than irrelevant visual details. Extensive experiments
demonstrate that Mesh-Gait achieves state-of-the-art accuracy. The code will be
released upon acceptance of the paper.

</details>


### [80] [Guided Image Feature Matching using Feature Spatial Order](https://arxiv.org/abs/2510.10414)
*Chin-Hung Teng,Ben-Jian Dong*

Main category: cs.CV

TL;DR: 该论文提出了一种结合特征空间顺序和极线几何的特征匹配方法，以提高匹配效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的特征匹配技术在处理大量特征点时效率低下，该研究旨在通过引入特征空间顺序来优化匹配过程。

Method: 利用初始匹配的特征点构建特征空间顺序计算模型，并将其与极线几何相结合，以筛选不必要的匹配并提高效率。同时，提出了一种基于基础矩阵的图像对齐方法来消除旋转效应。

Result: 实验结果表明，该方法在标准数据集、模拟图像和真实图像上均表现出比传统方法更高的效率和准确性。

Conclusion: 该方法通过整合特征空间顺序和极线几何，显著提高了图像特征匹配的效率和准确性。

Abstract: Image feature matching plays a vital role in many computer vision tasks.
Although many image feature detection and matching techniques have been
proposed over the past few decades, it is still time-consuming to match feature
points in two images, especially for images with a large number of detected
features. Feature spatial order can estimate the probability that a pair of
features is correct. Since it is a completely independent concept from epipolar
geometry, it can be used to complement epipolar geometry in guiding feature
match in a target region so as to improve matching efficiency. In this paper,
we integrate the concept of feature spatial order into a progressive matching
framework. We use some of the initially matched features to build a
computational model of feature spatial order and employs it to calculates the
possible spatial range of subsequent feature matches, thus filtering out
unnecessary feature matches. We also integrate it with epipolar geometry to
further improve matching efficiency and accuracy. Since the spatial order of
feature points is affected by image rotation, we propose a suitable image
alignment method from the fundamental matrix of epipolar geometry to remove the
effect of image rotation. To verify the feasibility of the proposed method, we
conduct a series of experiments, including a standard benchmark dataset,
self-generated simulated images, and real images. The results demonstrate that
our proposed method is significantly more efficient and has more accurate
feature matching than the traditional method.

</details>


### [81] [Combo-Gait: Unified Transformer Framework for Multi-Modal Gait Recognition and Attribute Analysis](https://arxiv.org/abs/2510.10417)
*Zhao-Yang Wang,Zhimin Shao,Jieneng Chen,Rama Chellappa*

Main category: cs.CV

TL;DR: 该研究提出了一种多模态、多任务框架，结合2D时间轮廓和3D SMPL特征进行步态分析，可用于身份识别和年龄、BMI、性别等属性估计。


<details>
  <summary>Details</summary>
Motivation: 现有的步态识别方法要么依赖2D表示，要么依赖3D表示，单独的模态无法完全捕捉人类行走模式的几何和动态复杂性。

Method: 提出了一种多模态、多任务框架，结合2D时间轮廓和3D SMPL特征。采用统一的Transformer来融合多模态步态特征，并学习与属性相关的表示，同时保留身份线索。该框架联合进行步态识别和人体属性估计（年龄、BMI、性别）。

Result: 在BRIAR数据集上进行了广泛的实验，该数据集在长距离（1公里）和极端俯仰角（50度）等挑战性条件下收集。实验结果表明，该方法在步态识别方面优于现有最先进的方法，并能准确估计人体属性。

Conclusion: 多模态和多任务学习在步态识别和人体属性估计方面展现出巨大潜力，有望在真实场景中提升基于步态的身份识别和人体理解能力。

Abstract: Gait recognition is an important biometric for human identification at a
distance, particularly under low-resolution or unconstrained environments.
Current works typically focus on either 2D representations (e.g., silhouettes
and skeletons) or 3D representations (e.g., meshes and SMPLs), but relying on a
single modality often fails to capture the full geometric and dynamic
complexity of human walking patterns. In this paper, we propose a multi-modal
and multi-task framework that combines 2D temporal silhouettes with 3D SMPL
features for robust gait analysis. Beyond identification, we introduce a
multitask learning strategy that jointly performs gait recognition and human
attribute estimation, including age, body mass index (BMI), and gender. A
unified transformer is employed to effectively fuse multi-modal gait features
and better learn attribute-related representations, while preserving
discriminative identity cues. Extensive experiments on the large-scale BRIAR
datasets, collected under challenging conditions such as long-range distances
(up to 1 km) and extreme pitch angles (up to 50{\deg}), demonstrate that our
approach outperforms state-of-the-art methods in gait recognition and provides
accurate human attribute estimation. These results highlight the promise of
multi-modal and multitask learning for advancing gait-based human understanding
in real-world scenarios.

</details>


### [82] [Towards Cybersickness Severity Classification from VR Gameplay Videos Using Transfer Learning and Temporal Modeling](https://arxiv.org/abs/2510.10422)
*Jyotirmay Nag Setu,Kevin Desai,John Quarles*

Main category: cs.CV

TL;DR: 本研究提出一种利用视频特征预测虚拟现实（VR）晕动症的方法，通过迁移学习和LSTM网络，实现了68.4%的准确率，优于现有纯视频模型。


<details>
  <summary>Details</summary>
Motivation: 虚拟现实（VR）技术发展迅速，但在医疗、教育、娱乐等领域应用广泛的同时，晕动症问题阻碍了其普及。虽然已有研究探索多模态深度学习，但利用视频特征预测晕动症的研究有限。

Method: 本研究采用迁移学习，利用在ImageNet数据集上预训练的InceptionV3模型从VR游戏视频中提取高层视觉特征，并将其输入长短期记忆（LSTM）网络，以捕捉VR体验的时间动态并预测晕动症的严重程度。

Result: 该方法实现了68.4%的晕动症严重程度分类准确率，优于仅使用视频数据训练的现有模型。

Conclusion: 本研究提出的基于视频特征预测晕动症的方法，为VR开发者提供了一个评估和缓解虚拟环境中晕动症的实用工具，并为未来基于视频的时间建模以提升VR应用用户舒适度的研究奠定了基础。

Abstract: With the rapid advancement of virtual reality (VR) technology, its adoption
across domains such as healthcare, education, and entertainment has grown
significantly. However, the persistent issue of cybersickness, marked by
symptoms resembling motion sickness, continues to hinder widespread acceptance
of VR. While recent research has explored multimodal deep learning approaches
leveraging data from integrated VR sensors like eye and head tracking, there
remains limited investigation into the use of video-based features for
predicting cybersickness. In this study, we address this gap by utilizing
transfer learning to extract high-level visual features from VR gameplay videos
using the InceptionV3 model pretrained on the ImageNet dataset. These features
are then passed to a Long Short-Term Memory (LSTM) network to capture the
temporal dynamics of the VR experience and predict cybersickness severity over
time. Our approach effectively leverages the time-series nature of video data,
achieving a 68.4% classification accuracy for cybersickness severity. This
surpasses the performance of existing models trained solely on video data,
providing a practical tool for VR developers to evaluate and mitigate
cybersickness in virtual environments. Furthermore, this work lays the
foundation for future research on video-based temporal modeling for enhancing
user comfort in VR applications.

</details>


### [83] [Taming a Retrieval Framework to Read Images in Humanlike Manner for Augmenting Generation of MLLMs](https://arxiv.org/abs/2510.10426)
*Suyang Xi,Chenxi Yang,Hong Ding,Yiqing Ni,Catherine C. Liu,Yunhao Liu,Chengqi Zhang*

Main category: cs.CV

TL;DR: HuLiRAG通过“what--where--reweight”级联框架解决了多模态大语言模型在细粒度视觉问答中的局限性，通过显式锚定查询到视觉区域、利用掩码进行空间解析和自适应重定权重，提高了 grounding 的准确性和事实一致性，减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在细粒度视觉问答中存在幻觉问题，因为文本查询没有明确映射到视觉区域，而RAG方法在检索和增强层面都未能模拟人类的认知过程，缺乏对局部细节的关注和细粒度交互的推理能力。

Method: 提出了一种名为HuLiRAG的框架，将多模态推理设计成一个“what--where--reweight”的级联过程。首先，通过开放词汇检测将查询锚定到候选区域（what）；然后，利用SAM派生的掩码进行空间解析以恢复细粒度精度（where）；最后，通过在局部和全局对齐之间进行权衡来自适应地确定优先级（reweight）。此外，还采用掩码引导的微调来注入空间证据，将 grounding 从被动偏置转变为显式约束。

Result: 实验证明，HuLiRAG框架提高了 grounding 的保真度和事实一致性，并减少了幻觉，在多模态问答的可信推理方面取得了进展。

Conclusion: HuLiRAG框架通过模拟人类的视觉推理过程，有效解决了多模态大语言模型在细粒度视觉问答中的不足，提高了回答的准确性和可靠性。

Abstract: Multimodal large language models (MLLMs) often fail in fine-grained visual
question answering, producing hallucinations about object identities,
positions, and relations because textual queries are not explicitly anchored to
visual referents. Retrieval-augmented generation (RAG) alleviates some errors,
but it fails to align with human-like processing at both the retrieval and
augmentation levels. Specifically, it focuses only on global-level image
information but lacks local detail and limits reasoning about fine-grained
interactions. To overcome this limitation, we present Human-Like
Retrieval-Augmented Generation (HuLiRAG), a framework that stages multimodal
reasoning as a ``what--where--reweight'' cascade. Queries are first anchored to
candidate referents via open-vocabulary detection (what), then spatially
resolved with SAM-derived masks to recover fine-grained precision (where), and
adaptively prioritized through the trade-off between local and global alignment
(reweight). Mask-guided fine-tuning further injects spatial evidence into the
generation process, transforming grounding from a passive bias into an explicit
constraint on answer formulation. Extensive experiments demonstrate that this
human-like cascade improves grounding fidelity and factual consistency while
reducing hallucinations, advancing multimodal question answering toward
trustworthy reasoning.

</details>


### [84] [MonoSE(3)-Diffusion: A Monocular SE(3) Diffusion Framework for Robust Camera-to-Robot Pose Estimation](https://arxiv.org/abs/2510.10434)
*Kangjian Zhu,Haobo Jiang,Yigong Zhang,Jianjun Qian,Jian Yang,Jin Xie*

Main category: cs.CV

TL;DR: MonoSE(3)-Diffusion是一个单目SE(3)扩散框架，将机器人姿态估计视为条件去噪扩散过程，通过多样化的姿态增强和渐进式的姿态细化来提高精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于图像的机器人姿态估计方法泛化能力受限，尤其是在处理多样化和视场内姿态时。本研究旨在提出一种新的框架来解决这个问题。

Method: 提出MonoSE(3)-Diffusion框架，包含两个过程：1. 视场约束的扩散过程，用于生成多样化的训练姿态，通过逐步扰动真实姿态生成噪声变换，并强制要求变换保持在相机视场内。2. 时间步感知逆过程，通过去噪网络迭代预测姿态，并根据当前时间步的扩散后验进行采样，实现从粗到精的渐进式姿态细化。时间步长被用于指导去噪网络进行更精确的姿态预测。

Result: 该方法在DREAM和RoboKeyGen两个基准测试中均取得了改进，在最具挑战性的DREAM数据集上达到了66.75%的AUC，比现有最佳方法提高了32.3%。

Conclusion: MonoSE(3)-Diffusion框架通过视场约束的扩散过程增强了训练数据的多样性和泛化能力，并通过时间步感知逆过程实现了鲁棒且精确的姿态细化，显著优于现有方法。

Abstract: We propose MonoSE(3)-Diffusion, a monocular SE(3) diffusion framework that
formulates markerless, image-based robot pose estimation as a conditional
denoising diffusion process. The framework consists of two processes: a
visibility-constrained diffusion process for diverse pose augmentation and a
timestep-aware reverse process for progressive pose refinement. The diffusion
process progressively perturbs ground-truth poses to noisy transformations for
training a pose denoising network. Importantly, we integrate visibility
constraints into the process, ensuring the transformations remain within the
camera field of view. Compared to the fixed-scale perturbations used in current
methods, the diffusion process generates in-view and diverse training poses,
thereby improving the network generalization capability. Furthermore, the
reverse process iteratively predicts the poses by the denoising network and
refines pose estimates by sampling from the diffusion posterior of current
timestep, following a scheduled coarse-to-fine procedure. Moreover, the
timestep indicates the transformation scales, which guide the denoising network
to achieve more accurate pose predictions. The reverse process demonstrates
higher robustness than direct prediction, benefiting from its timestep-aware
refinement scheme. Our approach demonstrates improvements across two benchmarks
(DREAM and RoboKeyGen), achieving a notable AUC of 66.75 on the most
challenging dataset, representing a 32.3% gain over the state-of-the-art.

</details>


### [85] [On the Problem of Consistent Anomalies in Zero-Shot Industrial Anomaly Detection](https://arxiv.org/abs/2510.10456)
*Tai Le-Gia,Ahn Jaehyun*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Zero-shot image anomaly classification (AC) and segmentation (AS) are vital
for industrial quality control, detecting defects without prior training data.
Existing representation-based methods compare patch features with nearest
neighbors in unlabeled test images but struggle with consistent anomalies --
similar defects recurring across multiple images -- resulting in poor AC/AS
performance. We introduce Consistent-Anomaly Detection Graph (CoDeGraph), a
novel algorithm that identifies and filters consistent anomalies from
similarity computations. Our key insight is that normal patches in industrial
images show stable, gradually increasing similarity to other test images, while
consistent-anomaly patches exhibit abrupt similarity spikes after exhausting a
limited set of similar matches, a phenomenon we term ``neighbor-burnout.''
CoDeGraph constructs an image-level graph, with images as nodes and edges
connecting those with shared consistent-anomaly patterns, using community
detection to filter these anomalies. We provide a theoretical foundation using
Extreme Value Theory to explain the effectiveness of our approach. Experiments
on MVTec AD with the ViT-L-14-336 backbone achieve 98.3% AUROC for AC and AS
performance of 66.8% (+4.2%) F1 and 68.1% (+5.4%) AP over state-of-the-art
zero-shot methods. Using the DINOv2 backbone further improves segmentation,
yielding 69.1% (+6.5%) F1 and 71.9% (+9.2%) AP, demonstrating robustness across
architectures.

</details>


### [86] [Learning from Disagreement: A Group Decision Simulation Framework for Robust Medical Image Segmentation](https://arxiv.org/abs/2510.10462)
*Chen Zhong,Yuxuan Yang,Xinyue Zhang,Ruohan Ma,Yong Guo,Gang Li,Jupeng Li*

Main category: cs.CV

TL;DR: 提出了一个模拟临床医生小组协作决策过程的框架，通过学习个体注释者的风格并从中采样来生成最终分割，以解决医学图像分割中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割注释存在由于注释者专业知识差异和图像本身模糊性导致的评分者间变异性（IRV）问题。简单平均专家标签的方法会丢失评分者不一致性所揭示的临床不确定性。

Method: 提出了一种名为“小组决策模拟框架”的新方法。该框架包含一个“专家签名生成器”（ESG），用于在独特的潜在空间中学习个体注释者的风格；以及一个“模拟咨询模块”（SCM），用于从该潜在空间中采样以智能地生成最终分割。

Result: 该方法在具有挑战性的 CBCT 和 MRI 数据集上取得了最先进的结果，Dice 分数分别为 92.11% 和 90.72%。

Conclusion: 通过将专家分歧视为有用的信号而非噪声，该研究为构建更可靠、更值得信赖的医疗保健人工智能系统提供了明确的方向。

Abstract: Medical image segmentation annotation suffers from inter-rater variability
(IRV) due to differences in annotators' expertise and the inherent blurriness
of medical images. Standard approaches that simply average expert labels are
flawed, as they discard the valuable clinical uncertainty revealed in
disagreements. We introduce a fundamentally new approach with our group
decision simulation framework, which works by mimicking the collaborative
decision-making process of a clinical panel. Under this framework, an Expert
Signature Generator (ESG) learns to represent individual annotator styles in a
unique latent space. A Simulated Consultation Module (SCM) then intelligently
generates the final segmentation by sampling from this space. This method
achieved state-of-the-art results on challenging CBCT and MRI datasets (92.11%
and 90.72% Dice scores). By treating expert disagreement as a useful signal
instead of noise, our work provides a clear path toward more robust and
trustworthy AI systems for healthcare.

</details>


### [87] [Post-TIPS Prediction via Multimodal Interaction: A Multi-Center Dataset and Framework for Survival, Complication, and Portal Pressure Assessment](https://arxiv.org/abs/2510.10464)
*Junhao Dong,Dejia Liu,Ruiqi Ding,Zongxing Chen,Yingjie Huang,Zhu Meng,Jianbo Zhao,Zhicheng Zhao,Fei Su*

Main category: cs.CV

TL;DR: 该研究提出了一个名为MultiTIPS的多中心数据集和一个新颖的多模态预后框架，旨在解决经颈静脉肝内门体分流术（TIPS）预后评估中的挑战，并提高了预测的准确性、泛化性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前TIPS术后的预后评估方法存在数据标注工作量大、单模态方法可靠性和泛化性差、以及单一预测终点评估不全面的问题。此外，公开数据集的缺乏也限制了该领域的研究。因此，需要更准确、更全面的预后评估模型。

Method: 研究者提出了一个名为MultiTIPS的多中心数据集，并基于该数据集构建了一个新颖的多模态预后框架。该框架包含三个核心模块：1. 双选项分割：利用半监督和基础模型管道实现鲁棒的感兴趣区域（ROI）分割，减少标注需求。2. 多模态交互：引入多粒度放射组学注意力（MGRA）、渐进正交解耦（POD）和临床引导预后增强（CGPE）技术，实现跨模态特征交互和互补表示，提高模型准确性和鲁棒性。3. 多任务预测：采用分阶段训练策略，稳定优化生存率、门脉压力梯度（PPG）和明显肝性脑病（OHE）的预测，实现全面的预后评估。

Result: 在MultiTIPS数据集上的大量实验表明，所提出的方法优于最先进的方法，并具有强大的跨域泛化能力和可解释性。

Conclusion: 该研究提出的MultiTIPS数据集和多模态预后框架在TIPS术后预后评估方面表现出色，能够克服现有方法的局限性，提供更准确、更全面的评估，并具有良好的临床应用前景。

Abstract: Transjugular intrahepatic portosystemic shunt (TIPS) is an established
procedure for portal hypertension, but provides variable survival outcomes and
frequent overt hepatic encephalopathy (OHE), indicating the necessity of
accurate preoperative prognostic modeling. Current studies typically build
machine learning models from preoperative CT images or clinical
characteristics, but face three key challenges: (1) labor-intensive
region-of-interest (ROI) annotation, (2) poor reliability and generalizability
of unimodal methods, and (3) incomplete assessment from single-endpoint
prediction. Moreover, the lack of publicly accessible datasets constrains
research in this field. Therefore, we present MultiTIPS, the first public
multi-center dataset for TIPS prognosis, and propose a novel multimodal
prognostic framework based on it. The framework comprises three core modules:
(1) dual-option segmentation, which integrates semi-supervised and foundation
model-based pipelines to achieve robust ROI segmentation with limited
annotations and facilitate subsequent feature extraction; (2) multimodal
interaction, where three techniques, multi-grained radiomics attention (MGRA),
progressive orthogonal disentanglement (POD), and clinically guided prognostic
enhancement (CGPE), are introduced to enable cross-modal feature interaction
and complementary representation integration, thus improving model accuracy and
robustness; and (3) multi-task prediction, where a staged training strategy is
used to perform stable optimization of survival, portal pressure gradient
(PPG), and OHE prediction for comprehensive prognostic assessment. Extensive
experiments on MultiTIPS demonstrate the superiority of the proposed method
over state-of-the-art approaches, along with strong cross-domain generalization
and interpretability, indicating its promise for clinical application. The
dataset and code are available.

</details>


### [88] [When Images Speak Louder: Mitigating Language Bias-induced Hallucinations in VLMs through Cross-Modal Guidance](https://arxiv.org/abs/2510.10466)
*Jinjin Cao,Zhiyang Chen,Zijun Wang,Liyuan Ma,Weijian Luo,Guojun Qi*

Main category: cs.CV

TL;DR: 为了解决视觉语言模型（VLM）中存在的幻觉问题，我们提出了一种名为跨模态引导（CMG）的训练无关解码方法。该方法通过分析语言偏见对幻觉的贡献，并利用原始模型与视觉语言注意力受损模型输出分布之间的差异来减少幻觉。通过自适应地掩盖关键图像标记的注意力权重来模拟注意力受损，CMG能够增强视觉上下文感知，从而在不损害VLM能力的情况下减少语言偏见。实验证明，CMG能够有效提升不同VLM在特定幻觉基准测试上的性能，并具有良好的泛化能力，且无需额外的训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在处理视觉和语言上下文方面表现出强大的能力，但它们常常会产生与图像无关的、仅在语言上流畅的“幻觉”内容。本文旨在解决VLM中的幻觉问题。

Method: 提出了一种名为跨模态引导（CMG）的训练无关解码方法。该方法通过分析语言偏见对幻觉的贡献，并利用原始模型与视觉语言注意力受损模型输出分布之间的差异来解决幻觉问题。具体而言，通过自适应地掩盖Transformer层中关键图像标记的注意力权重，模拟视觉语言感知的退化，从而在解码过程中强调视觉上下文的感知，减少语言偏见。

Result: 实验结果表明，CMG在减少VLM幻觉方面表现出显著的优势，并且不会损害VLM本身的能力。CMG能够提高不同VLM在专门针对幻觉问题的基准测试上的性能，并展现出良好的泛化能力，且无需额外的训练成本或条件。

Conclusion: 跨模态引导（CMG）是一种有效的、无需训练的解码方法，可以显著减少视觉语言模型（VLM）中的幻觉问题。通过引入一种模拟视觉语言注意力退化的机制，CMG能够增强模型对视觉信息的依赖，从而减轻语言偏见，提高模型的准确性和可靠性，并且易于集成到现有VLM中。

Abstract: Vision-Language Models (VLMs) have shown solid ability for multimodal
understanding of both visual and language contexts. However, existing VLMs
often face severe challenges of hallucinations, meaning that VLMs tend to
generate responses that are only fluent in the language but irrelevant to
images in previous contexts. To address this issue, we analyze how language
bias contributes to hallucinations and then introduce Cross-Modal
Guidance(CMG), a training-free decoding method that addresses the
hallucinations by leveraging the difference between the output distributions of
the original model and the one with degraded visual-language attention. In
practice, we adaptively mask the attention weight of the most influential image
tokens in selected transformer layers to corrupt the visual-language perception
as a concrete type of degradation. Such a degradation-induced decoding
emphasizes the perception of visual contexts and therefore significantly
reduces language bias without harming the ability of VLMs. In experiment
sections, we conduct comprehensive studies. All results demonstrate the
superior advantages of CMG with neither additional conditions nor training
costs. We also quantitatively show CMG can improve different VLM's performance
on hallucination-specific benchmarks and generalize effectively.

</details>


### [89] [DAGLFNet:Deep Attention-Guided Global-Local Feature Fusion for Pseudo-Image Point Cloud Segmentation](https://arxiv.org/abs/2510.10471)
*Chuang Chen,Wenyi Ge*

Main category: cs.CV

TL;DR: DAGLFNet是一种伪图像语义分割框架，通过全局-局部特征融合编码、多分支特征提取和深度特征引导注意力机制来提升点云特征的提取和融合能力，在SemanticKITTI和nuScenes数据集上取得了优异的性能，并兼具实时性。


<details>
  <summary>Details</summary>
Motivation: 现有的伪图像表示方法在处理点云数据时，往往忽略了点云的结构和语义细节，导致特征融合和区分能力有限。

Method: 提出DAGLFNet框架，包含全局-局部特征融合编码模块、多分支特征提取网络和深度特征引导注意力机制，以提取区分性特征。

Result: 在SemanticKITTI和nuScenes数据集的验证集上分别达到了69.83%和78.65%的准确率。

Conclusion: DAGLFNet方法在保证高性能的同时实现了实时性，在基于LiDAR的实时应用中展现出巨大潜力。

Abstract: Environmental perception systems play a critical role in high-precision
mapping and autonomous navigation, with LiDAR serving as a core sensor that
provides accurate 3D point cloud data. How to efficiently process unstructured
point clouds while extracting structured semantic information remains a
significant challenge, and in recent years, numerous pseudo-image-based
representation methods have emerged to achieve a balance between efficiency and
performance. However, they often overlook the structural and semantic details
of point clouds, resulting in limited feature fusion and discriminability. In
this work, we propose DAGLFNet, a pseudo-image-based semantic segmentation
framework designed to extract discriminative features. First, the Global-Local
Feature Fusion Encoding module is used to enhance the correlation among local
features within a set and capture global contextual information. Second, the
Multi-Branch Feature Extraction network is employed to capture more
neighborhood information and enhance the discriminability of contour features.
Finally, a Feature Fusion via Deep Feature-guided Attention mechanism is
introduced to improve the precision of cross-channel feature fusion.
Experimental evaluations show that DAGLFNet achieves 69.83\% and 78.65\% on the
validation sets of SemanticKITTI and nuScenes, respectively. The method
balances high performance with real-time capability, demonstrating great
potential for LiDAR-based real-time applications.

</details>


### [90] [MSF-Mamba: Motion-aware State Fusion Mamba for Efficient Micro-Gesture Recognition](https://arxiv.org/abs/2510.10478)
*Deng Li,Jun Shao,Bohao Xing,Rong Gao,Bihan Wen,Heikki Kälviäinen,Xin Liu*

Main category: cs.CV

TL;DR: MSF-Mamba是一种新型的基于状态空间模型（SSM）的微手势识别（MGR）模型，通过融合局部时空依赖性和引入运动感知机制，在保持高效率的同时实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 微手势识别（MGR）需要精确地建模长程和局部时空依赖性。现有的CNN模型在捕捉局部模式方面表现良好，但在处理长程依赖性方面存在局限；Transformer模型虽然能处理长程依赖性，但计算成本高；而Mamba模型虽然高效，但直接应用于MGR时，其处理1D序列的方式无法有效捕捉局部时空依赖性，且缺乏运动感知能力。

Method: 提出了一种名为MSF-Mamba（运动感知状态融合Mamba）的模型，通过融合局部上下文邻近状态来增强Mamba对局部时空依赖性的建模能力。该模型引入了基于中心帧差（CFD）的运动感知状态融合模块。此外，还提出了其多尺度版本MSF-Mamba+，支持多尺度运动感知状态融合和一个能够动态加权不同尺度融合状态的自适应尺度加权模块。

Result: MSF-Mamba模型在两个公开的MGR数据集上的实验表明，即使是轻量级版本，也取得了最先进的性能，优于现有的基于CNN、Transformer和SSM的模型，同时保持了高效率。

Conclusion: MSF-Mamba及其多尺度版本MSF-Mamba+通过引入运动感知状态融合和多尺度处理能力，有效解决了Mamba模型在MGR任务中存在的局部时空依赖建模不足和缺乏运动感知的问题，在识别精细运动方面表现出色，并实现了高效率。

Abstract: Micro-gesture recognition (MGR) targets the identification of subtle and
fine-grained human motions and requires accurate modeling of both long-range
and local spatiotemporal dependencies. While CNNs are effective at capturing
local patterns, they struggle with long-range dependencies due to their limited
receptive fields. Transformer-based models address this limitation through
self-attention mechanisms but suffer from high computational costs. Recently,
Mamba has shown promise as an efficient model, leveraging state space models
(SSMs) to enable linear-time processing However, directly applying the vanilla
Mamba to MGR may not be optimal. This is because Mamba processes inputs as 1D
sequences, with state updates relying solely on the previous state, and thus
lacks the ability to model local spatiotemporal dependencies. In addition,
previous methods lack a design of motion-awareness, which is crucial in MGR. To
overcome these limitations, we propose motion-aware state fusion mamba
(MSF-Mamba), which enhances Mamba with local spatiotemporal modeling by fusing
local contextual neighboring states. Our design introduces a motion-aware state
fusion module based on central frame difference (CFD). Furthermore, a
multiscale version named MSF-Mamba+ has been proposed. Specifically, MSF-Mamba
supports multiscale motion-aware state fusion, as well as an adaptive scale
weighting module that dynamically weighs the fused states across different
scales. These enhancements explicitly address the limitations of vanilla Mamba
by enabling motion-aware local spatiotemporal modeling, allowing MSF-Mamba and
MSF-Mamba to effectively capture subtle motion cues for MGR. Experiments on two
public MGR datasets demonstrate that even the lightweight version, namely,
MSF-Mamba, achieves SoTA performance, outperforming existing CNN-,
Transformer-, and SSM-based models while maintaining high efficiency.

</details>


### [91] [DKPMV: Dense Keypoints Fusion from Multi-View RGB Frames for 6D Pose Estimation of Textureless Objects](https://arxiv.org/abs/2510.10933)
*Jiahong Chen,Jinghao Wang,Zi Wang,Ziwen Wang,Banglei Guan,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出了一种仅使用多视图RGB图像进行纹理稀疏物体6D姿态估计的DKPMV方法，通过密集关键点级融合和三阶段优化策略，提升了姿态估计的准确性和对对称物体的处理能力，并在ROBI数据集上取得了优于现有RGB和RGB-D方法的性能。


<details>
  <summary>Details</summary>
Motivation: 纹理稀疏物体的6D姿态估计在工业机器人应用中具有重要价值，但由于深度信息频繁丢失而面临挑战。现有的多视图方法依赖深度数据或未能充分利用多视图几何线索，限制了性能。

Method: 提出DKPMV流程，仅使用多视图RGB图像作为输入，实现密集关键点级融合。设计了三阶段渐进式姿态优化策略，利用密集多视图关键点几何信息。通过注意力聚合和对称感知训练增强关键点网络，以实现有效的密集关键点融合，提高预测精度并解决对称物体上的歧义。

Result: 在ROBI数据集上的大量实验表明，DKPMV的性能优于最先进的多视图RGB方法，并且在大多数情况下甚至优于RGB-D方法。

Conclusion: DKPMV通过密集关键点级融合和创新的优化策略，有效解决了纹理稀疏物体6D姿态估计的挑战，并在实验中取得了领先性能。

Abstract: 6D pose estimation of textureless objects is valuable for industrial robotic
applications, yet remains challenging due to the frequent loss of depth
information. Current multi-view methods either rely on depth data or
insufficiently exploit multi-view geometric cues, limiting their performance.
In this paper, we propose DKPMV, a pipeline that achieves dense keypoint-level
fusion using only multi-view RGB images as input. We design a three-stage
progressive pose optimization strategy that leverages dense multi-view keypoint
geometry information. To enable effective dense keypoint fusion, we enhance the
keypoint network with attentional aggregation and symmetry-aware training,
improving prediction accuracy and resolving ambiguities on symmetric objects.
Extensive experiments on the ROBI dataset demonstrate that DKPMV outperforms
state-of-the-art multi-view RGB approaches and even surpasses the RGB-D methods
in the majority of cases. The code will be available soon.

</details>


### [92] [Towards Self-Refinement of Vision-Language Models with Triangular Consistency](https://arxiv.org/abs/2510.10487)
*Yunlong Deng,Guangyi Chen,Tianpei Gu,Lingjing Kong,Yan Li,Zeyu Tang,Kun Zhang*

Main category: cs.CV

TL;DR: 该研究表明，视觉语言模型（VLM）在没有监督指导的情况下也具备自我完善的能力，可以通过生成高质量的监督数据并从中学习，而无需外部输入。


<details>
  <summary>Details</summary>
Motivation: 以往的研究主要集中在使用监督指导的视觉语言模型（VLM），而忽略了未经监督训练的VLM的潜力。本研究旨在探索VLM在没有监督的情况下，利用其固有的自我完善能力生成高质量监督数据的潜力。

Method: 提出了一种基于“三角一致性”原则的自我完善框架。该框架包括：1. 通过多任务指令调优（如图像→问答或图像-答案→问题）来激发VLM的指令生成能力。2. 利用三角一致性原则从无标签图像生成图像-查询-答案三元组并进行过滤。3. 使用过滤后的合成数据进一步更新模型。研究还从因果关系角度进行了理论分析。

Result: 实验表明，在使用LLaVA-1.5作为基线模型的情况下，该模型能够在没有外部监督（如人工标注或环境反馈）的情况下，在多个基准测试中自主地实现持续的、尽管是温和的改进。

Conclusion: 该研究验证了视觉语言模型（VLM）在没有监督的情况下也具有自我完善的能力，这为未来研究VLM的学习机制提供了新的思路。

Abstract: Vision-Language Models (VLMs) integrate visual knowledge with the analytical
capabilities of Large Language Models (LLMs) through supervised visual
instruction tuning, using image-question-answer triplets. However, the
potential of VLMs trained without supervised instruction remains largely
unexplored. This study validates that VLMs possess inherent self-refinement
capabilities, enabling them to generate high-quality supervised data without
external inputs and thereby learn autonomously. Specifically, to stimulate the
self-refinement ability of VLMs, we propose a self-refinement framework based
on a Triangular Consistency principle: within the image-query-answer triangle,
any masked elements should be consistently and accurately reconstructed. The
framework involves three steps: (1) We enable the instruction generation
ability of VLMs by adding multi-task instruction tuning like
image$\rightarrow$question-answer or image-answer$\rightarrow$question. (2) We
generate image-query-answer triplets from unlabeled images and use the
Triangular Consistency principle for filtering. (3) The model is further
updated using the filtered synthetic data. To investigate the underlying
mechanisms behind this self-refinement capability, we conduct a theoretical
analysis from a causal perspective. Using the widely recognized LLaVA-1.5 as
our baseline, our experiments reveal that the model can autonomously achieve
consistent, though deliberately modest, improvements across multiple benchmarks
without any external supervision, such as human annotations or environmental
feedback. We expect that the insights of this study on the self-refinement
ability of VLMs can inspire future research on the learning mechanism of VLMs.
Code is available at https://github.com/dengyl20/SRF-LLaVA-1.5.

</details>


### [93] [REACT3D: Recovering Articulations for Interactive Physical 3D Scenes](https://arxiv.org/abs/2510.11340)
*Zhao Huang,Boyang Sun,Alexandros Delitzas,Jiaqi Chen,Marc Pollefeys*

Main category: cs.CV

TL;DR: REACT3D是一个零样本框架，可将静态3D场景转换为交互式3D场景，用于具身智能研究。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景数据集的标注过程繁琐，限制了具身智能的发展。需要一种可扩展的方法来创建交互式3D场景。

Method: 1. 检测和分割可开 object。
2. 估计关节类型和运动参数。
3. 完成隐藏的几何形状并进行交互式 object 组装。
4. 将交互式场景集成到标准模拟平台支持的格式中。

Result: 在室内场景的检测/分割和运动评估方面取得了最先进的性能。

Conclusion: REACT3D框架能有效生成可交互的3D场景，降低了进行大规模可动场景理解研究的门槛。

Abstract: Interactive 3D scenes are increasingly vital for embodied intelligence, yet
existing datasets remain limited due to the labor-intensive process of
annotating part segmentation, kinematic types, and motion trajectories. We
present REACT3D, a scalable zero-shot framework that converts static 3D scenes
into simulation-ready interactive replicas with consistent geometry, enabling
direct use in diverse downstream tasks. Our contributions include: (i)
openable-object detection and segmentation to extract candidate movable parts
from static scenes, (ii) articulation estimation that infers joint types and
motion parameters, (iii) hidden-geometry completion followed by interactive
object assembly, and (iv) interactive scene integration in widely supported
formats to ensure compatibility with standard simulation platforms. We achieve
state-of-the-art performance on detection/segmentation and articulation metrics
across diverse indoor scenes, demonstrating the effectiveness of our framework
and providing a practical foundation for scalable interactive scene generation,
thereby lowering the barrier to large-scale research on articulated scene
understanding. Our project page is
\textit{\hypersetup{urlcolor=black}\href{https://react3d.github.io/}{react3d.github.io}}.

</details>


### [94] [Head-wise Adaptive Rotary Positional Encoding for Fine-Grained Image Generation](https://arxiv.org/abs/2510.10489)
*Jiaye Li,Baoyou Chen,Hui Li,Zilong Dong,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

TL;DR: HARoPE是一种用于图像生成Transformers的位置编码方法，通过引入可学习的线性变换来改进RoPE，以解决其在处理图像空间关系、颜色和对象计数方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 标准的RoPE在1D领域表现良好，但在图像生成任务中，其在细粒度空间关系建模、颜色线索和对象计数方面存在显著局限性。这主要是由于其刚性的频率分配、轴向独立性和统一的头处理方式，无法捕捉图像生成所需的复杂结构偏差。

Method: HARoPE通过在旋转映射之前插入一个通过SVD参数化的可学习线性变换，实现了一种“头自适应”的扩展。这种修改能够动态地重新分配频率、对齐旋转平面进行语义化处理，并为每个头生成特定的位置感受野，同时保持RoPE的相对位置属性。

Result: 在ImageNet（类别条件生成）和文本到图像生成（Flux和MMDiT）的广泛实验中，HARoPE相比于强大的RoPE基线和其他扩展方法，始终能提升性能。

Conclusion: HARoPE是一种有效的即插即用解决方案，能够增强基于Transformer的图像生成模型的位置感知能力，为图像生成提供了一个原则性且可适应的方法。

Abstract: Transformers rely on explicit positional encoding to model structure in data.
While Rotary Position Embedding (RoPE) excels in 1D domains, its application to
image generation reveals significant limitations such as fine-grained spatial
relation modeling, color cues, and object counting. This paper identifies key
limitations of standard multi-dimensional RoPE-rigid frequency allocation,
axis-wise independence, and uniform head treatment-in capturing the complex
structural biases required for fine-grained image generation. We propose
HARoPE, a head-wise adaptive extension that inserts a learnable linear
transformation parameterized via singular value decomposition (SVD) before the
rotary mapping. This lightweight modification enables dynamic frequency
reallocation, semantic alignment of rotary planes, and head-specific positional
receptive fields while rigorously preserving RoPE's relative-position property.
Extensive experiments on class-conditional ImageNet and text-to-image
generation (Flux and MMDiT) demonstrate that HARoPE consistently improves
performance over strong RoPE baselines and other extensions. The method serves
as an effective drop-in replacement, offering a principled and adaptable
solution for enhancing positional awareness in transformer-based image
generative models.

</details>


### [95] [Jigsaw3D: Disentangled 3D Style Transfer via Patch Shuffling and Masking](https://arxiv.org/abs/2510.10497)
*Yuteng Ye,Zheng Zhang,Qinchuan Zhang,Di Wang,Youjia Zhang,Wenxiao Zhang,Wei Yang,Yuan Liu*

Main category: cs.CV

TL;DR: Jigsaw3D 通过打乱和遮蔽参考图像的图像块来分离风格和内容，并利用基于多视图扩散的反向注意力生成视图一致的风格化渲染，最终将风格烘焙到表面以实现纹理的无缝风格化。


<details>
  <summary>Details</summary>
Motivation: 现有3D风格迁移方法存在每场景优化开销大、风格与内容纠缠的问题，Jigsaw3D旨在实现快速、视图一致且解耦内容与风格的3D风格迁移。

Method: Jigsaw3D 利用“拼图操作”（空间打乱和随机遮蔽参考图块）来抑制语义信息，提取风格线索，并通过参考到视图的交叉注意力机制整合到多视图扩散模型中，以生成风格化渲染。最后，将渲染的风格烘焙到3D模型表面生成纹理。

Result: Jigsaw3D 在标准3D风格迁移基准测试中，实现了高风格保真度和多视图一致性，同时大大降低了延迟。该方法还能泛化到部分参考图风格迁移、多物体场景风格迁移和可平铺纹理生成。

Conclusion: Jigsaw3D 是一种有效的多视图扩散模型，通过拼图操作实现了3D资产的快速、视图一致且内容解耦的风格迁移。

Abstract: Controllable 3D style transfer seeks to restyle a 3D asset so that its
textures match a reference image while preserving the integrity and multi-view
consistency. The prevalent methods either rely on direct reference style token
injection or score-distillation from 2D diffusion models, which incurs heavy
per-scene optimization and often entangles style with semantic content. We
introduce Jigsaw3D, a multi-view diffusion based pipeline that decouples style
from content and enables fast, view-consistent stylization. Our key idea is to
leverage the jigsaw operation - spatial shuffling and random masking of
reference patches - to suppress object semantics and isolate stylistic
statistics (color palettes, strokes, textures). We integrate these style cues
into a multi-view diffusion model via reference-to-view cross-attention,
producing view-consistent stylized renderings conditioned on the input mesh.
The renders are then style-baked onto the surface to yield seamless textures.
Across standard 3D stylization benchmarks, Jigsaw3D achieves high style
fidelity and multi-view consistency with substantially lower latency, and
generalizes to masked partial reference stylization, multi-object scene
styling, and tileable texture generation. Project page is available at:
https://babahui.github.io/jigsaw3D.github.io/

</details>


### [96] [VR-Thinker: Boosting Video Reward Models through Thinking-with-Image Reasoning](https://arxiv.org/abs/2510.10518)
*Qunzhong Wang,Jie Liu,Jiajun Liang,Yilei Jiang,Yuanxing Zhang,Jinyuan Chen,Yaozhi Zheng,Xintao Wang,Pengfei Wan,Xiangyu Yue,Jiaheng Liu*

Main category: cs.CV

TL;DR: VR-Thinker是一个用于改进多模态奖励模型的框架，通过引入视觉推理操作和可配置的视觉记忆窗口来克服现有模型的局限性，并在视频偏好基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态奖励模型在处理视觉输入时存在上下文预算有限、细节丢失以及信息集中在初始提示导致推理中的幻觉和遗忘等问题。

Method: 提出VR-Thinker框架，通过强化学习微调进行激活，包括冷启动、拒绝采样微调和组相对策略优化（GRPO）。VR-Thinker能够进行视觉推理（如选择帧）并管理视觉记忆窗口，以在有限的上下文内获取和更新视觉证据。

Result: 在视频偏好基准测试中，7B的VR-Thinker在VideoGen Reward上达到80.5%，在GenAI-Bench上达到82.3%，在MJ-Bench-Video上达到75.6%，展现了其在长视频推理方面的优越性。

Conclusion: VR-Thinker在多模态奖励建模中实现了“以图思考”的范式，有效提高了推理的保真度和可靠性，并在多个基准测试中取得了领先的性能。

Abstract: Recent advancements in multimodal reward models (RMs) have substantially
improved post-training for visual generative models. However, current RMs face
inherent limitations: (1) visual inputs consume large context budgets, forcing
fewer frames and causing loss of fine-grained details; and (2) all visual
information is packed into the initial prompt, exacerbating hallucination and
forgetting during chain-of-thought reasoning. To overcome these issues, we
introduce VideoReward Thinker (VR-Thinker), a thinking-with-image framework
that equips the RM with visual reasoning operations (e.g., select frame) and a
configurable visual memory window. This allows the RM to actively acquire and
update visual evidence within context limits, improving reasoning fidelity and
reliability. We activate visual reasoning via a reinforcement fine-tuning
pipeline: (i) Cold Start with curated visual chain-of-thought data to distill
basic reasoning skills and operation formatting; (ii) select samples whose
per-dimension and overall judgments are all correct, then conduct Rejection
sampling Fine-Tuning on these high-quality traces to further enhance reasoning;
and (iii) apply Group Relative Policy Optimization (GRPO) to strengthen
reasoning. Our approach delivers state-of-the-art accuracy among open-source
models on video preference benchmarks, especially for longer videos: a 7B
VR-Thinker achieves 80.5% on VideoGen Reward, 82.3% on GenAI-Bench, and 75.6%
on MJ-Bench-Video. These results validate the effectiveness and promise of
thinking-with-image multimodal reward modeling.

</details>


### [97] [Receptive Field Expanded Look-Up Tables for Vision Inference: Advancing from Low-level to High-level Tasks](https://arxiv.org/abs/2510.10522)
*Xi Zhang,Xiaolin Wu*

Main category: cs.CV

TL;DR: 该研究提出了一种通过学习最优格向量量化器来扩展卷积神经网络（CNN）感受野的方法，以在固定表大小的情况下提高推理性能，同时保持相同的空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于查找表（LUT）的方法虽然能加速CNN推理，但存在卷积核感受野有限的问题，因为组合爆炸导致表的大小受限。本研究旨在固定表大小的情况下扩展CNN的感受野，从而在保持相同空间复杂度的前提下，提升LUT驱动的快速CNN推理性能。

Method: 提出了一种学习最优格向量量化器的新方法，该方法能根据数据维度对推理任务的重要性自适应地分配量化分辨率。此外，还引入了其他扩展感受野的策略，包括不规则的稀疏卷积和U型级联LUT结构，以捕捉多层次的上下文信息而不增加表的大小。

Result: 该方法有效平衡了速度、准确性和内存效率，并在与现有LUT方法进行比较时，取得了显著的改进。

Conclusion: 本研究提出的结合最优格向量量化器、不规则稀疏卷积和U型级联LUT结构的方法，能够有效扩展CNN感受野，在固定表大小和空间复杂度的条件下，提升推理速度和准确性，超越现有LUT方法。

Abstract: Recently, several look-up table (LUT) methods were developed to greatly
expedite the inference of CNNs in a classical strategy of trading space for
speed. However, these LUT methods suffer from a common drawback of limited
receptive field of the convolution kernels due to the combinatorial explosion
of table size. This research aims to expand the CNN receptive field with a
fixed table size, thereby enhancing the performance of LUT-driven fast CNN
inference while maintaining the same space complexity. To achieve this goal,
various techniques are proposed. The main contribution is a novel approach of
learning an optimal lattice vector quantizer that adaptively allocates the
quantization resolution across data dimensions based on their significance to
the inference task. In addition, the lattice vector quantizer offers an
inherently more accurate approximation of CNN kernels than scalar quantizer as
used in current practice. Furthermore, we introduce other receptive field
expansion strategies, including irregular dilated convolutions and a U-shaped
cascaded LUT structure, designed to capture multi-level contextual information
without inflating table size. Together, these innovations allow our approach to
effectively balance speed, accuracy, and memory efficiency, demonstrating
significant improvements over existing LUT methods.

</details>


### [98] [Unified Open-World Segmentation with Multi-Modal Prompts](https://arxiv.org/abs/2510.10524)
*Yang Liu,Yufei Yin,Chenchen Jing,Muzhi Zhu,Hao Chen,Yuling Xi,Bo Feng,Hao Wang,Shiyu Li,Chunhua Shen*

Main category: cs.CV

TL;DR: COSINE是一个统一的开放世界分割模型，结合了开放词汇分割和上下文内分割，并支持多模态提示。


<details>
  <summary>Details</summary>
Motivation: 统一开放词汇分割和上下文内分割，克服现有方法的架构差异、学习目标和表示学习策略。

Method: 利用基础模型提取图像和多模态提示的表示，并使用SegDecoder对齐这些表示，建模交互，获得不同粒度的掩码。

Result: 在开放词汇分割和上下文内分割任务上均取得显著的性能提升。

Conclusion: 视觉和文本提示的协同作用在泛化能力上优于单一模态方法。

Abstract: In this work, we present COSINE, a unified open-world segmentation model that
consolidates open-vocabulary segmentation and in-context segmentation with
multi-modal prompts (e.g., text and image). COSINE exploits foundation models
to extract representations for an input image and corresponding multi-modal
prompts, and a SegDecoder to align these representations, model their
interaction, and obtain masks specified by input prompts across different
granularities. In this way, COSINE overcomes architectural discrepancies,
divergent learning objectives, and distinct representation learning strategies
of previous pipelines for open-vocabulary segmentation and in-context
segmentation. Comprehensive experiments demonstrate that COSINE has significant
performance improvements in both open-vocabulary and in-context segmentation
tasks. Our exploratory analyses highlight that the synergistic collaboration
between using visual and textual prompts leads to significantly improved
generalization over single-modality approaches.

</details>


### [99] [Layout-Independent License Plate Recognition via Integrated Vision and Language Models](https://arxiv.org/abs/2510.10533)
*Elham Shabaninia,Fatemeh Asadi-zeydabadi,Hossein Nezamabadi-pour*

Main category: cs.CV

TL;DR: 该研究提出了一种模式感知框架，用于自动车牌识别（ALPR），该框架能够可靠地处理各种车牌布局和具有挑战性的真实世界条件。


<details>
  <summary>Details</summary>
Motivation: 提出一个能够处理各种车牌布局和具有挑战性的真实世界条件，并且无需手动布局分类或启发式修正的模式感知车牌识别框架。

Method: 该系统采用一个高精度的检测网络，后跟一个集成Transformer视觉模型和迭代语言建模机制的识别阶段。该识别阶段可同时进行字符识别和OCR后处理，并学习车牌的结构模式和格式规则。

Result: 实验结果表明，该方法在IR-LPR、UFPR-ALPR和AOLP等多个国际数据集上实现了优于现有分割方法的准确性和鲁棒性，并且能够实现与布局无关的识别。

Conclusion: 所提出的模式感知框架通过在识别阶段嵌入模式分析，将计算机视觉和语言建模相结合，提高了ALPR系统的准确性和鲁棒性，能够适应智能交通和监控应用中的各种挑战。

Abstract: This work presents a pattern-aware framework for automatic license plate
recognition (ALPR), designed to operate reliably across diverse plate layouts
and challenging real-world conditions. The proposed system consists of a
modern, high-precision detection network followed by a recognition stage that
integrates a transformer-based vision model with an iterative language
modelling mechanism. This unified recognition stage performs character
identification and post-OCR refinement in a seamless process, learning the
structural patterns and formatting rules specific to license plates without
relying on explicit heuristic corrections or manual layout classification.
Through this design, the system jointly optimizes visual and linguistic cues,
enables iterative refinement to improve OCR accuracy under noise, distortion,
and unconventional fonts, and achieves layout-independent recognition across
multiple international datasets (IR-LPR, UFPR-ALPR, AOLP). Experimental results
demonstrate superior accuracy and robustness compared to recent
segmentation-free approaches, highlighting how embedding pattern analysis
within the recognition stage bridges computer vision and language modelling for
enhanced adaptability in intelligent transportation and surveillance
applications.

</details>


### [100] [MCE: Towards a General Framework for Handling Missing Modalities under Imbalanced Missing Rates](https://arxiv.org/abs/2510.10534)
*Binyu Zhao,Wei Zhang,Zhaonian Zou*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“模态能力增强”（MCE）的新方法，用于解决多模态学习中缺失模态（尤其是在缺失率不平衡时）的问题。MCE通过“学习能力增强”（LCE）和“表示能力增强”（RCE）两个部分协同工作，分别动态平衡模态间的学习进度并提高特征的语义和鲁棒性。实验结果表明，MCE在多个数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在处理缺失模态（尤其是在缺失率不平衡时）方面存在挑战，现有方法通常关注全局平衡而忽略样本级差异和特征质量下降问题。

Method: 提出模态能力增强（MCE），包含学习能力增强（LCE）和表示能力增强（RCE）两个部分。LCE通过多层次因素动态平衡模态学习进度；RCE通过子集预测和跨模态补全任务来提高特征语义和鲁棒性。

Result: 在四个多模态基准测试中，MCE在各种缺失配置下始终优于最先进的方法。

Conclusion: MCE能够有效解决多模态学习中缺失模态（尤其是在缺失率不平衡时）的问题，并在多个数据集上取得了优于现有方法的性能。

Abstract: Multi-modal learning has made significant advances across diverse pattern
recognition applications. However, handling missing modalities, especially
under imbalanced missing rates, remains a major challenge. This imbalance
triggers a vicious cycle: modalities with higher missing rates receive fewer
updates, leading to inconsistent learning progress and representational
degradation that further diminishes their contribution. Existing methods
typically focus on global dataset-level balancing, often overlooking critical
sample-level variations in modality utility and the underlying issue of
degraded feature quality. We propose Modality Capability Enhancement (MCE) to
tackle these limitations. MCE includes two synergistic components: i) Learning
Capability Enhancement (LCE), which introduces multi-level factors to
dynamically balance modality-specific learning progress, and ii) Representation
Capability Enhancement (RCE), which improves feature semantics and robustness
through subset prediction and cross-modal completion tasks. Comprehensive
evaluations on four multi-modal benchmarks show that MCE consistently
outperforms state-of-the-art methods under various missing configurations. The
journal preprint version is now available at
https://doi.org/10.1016/j.patcog.2025.112591. Our code is available at
https://github.com/byzhaoAI/MCE.

</details>


### [101] [GLOFNet -- A Multimodal Dataset for GLOF Monitoring and Prediction](https://arxiv.org/abs/2510.10546)
*Zuha Fatima,Muhammad Anser Sohaib,Muhammad Talha,Sidra Sultana,Ayesha Kanwal,Nazia Perwaiz*

Main category: cs.CV

TL;DR: GLOFNet是一个多模态数据集，用于监测和预测冰川湖决口洪水（GLOFs），解决了数据碎片化和单模态的问题，可用于未来冰川灾害预测研究。


<details>
  <summary>Details</summary>
Motivation: 现有针对冰川湖决口洪水（GLOFs）的预测性研究受到数据碎片化和单模态的限制，而事件后的绘图方法无法满足预测需求。需要协调的、结合视觉指标和物理前兆的多模态数据集。 

Method: 提出GLOFNet，一个针对喀喇昆仑山石什攀冰川的多模态数据集，整合了Sentinel-2多光谱影像、NASA ITS_LIVE冰川速度产品和MODIS地表温度记录。对数据进行了预处理（云遮蔽、质量过滤、归一化、时间插值、增强和循环编码），并进行了跨模态协调。 

Result: 探索性分析揭示了冰川速度的季节性周期、每十年约0.8 K的长期变暖以及冰冻圈条件的空间异质性。

Conclusion: GLOFNet数据集是公开的，旨在支持未来的冰川灾害预测研究。它通过解决类别不平衡、云污染和粗分辨率等挑战，为评估多模态深度学习方法在罕见灾害预测中的应用提供了基础。

Abstract: Glacial Lake Outburst Floods (GLOFs) are rare but destructive hazards in high
mountain regions, yet predictive research is hindered by fragmented and
unimodal data. Most prior efforts emphasize post-event mapping, whereas
forecasting requires harmonized datasets that combine visual indicators with
physical precursors. We present GLOFNet, a multimodal dataset for GLOF
monitoring and prediction, focused on the Shisper Glacier in the Karakoram. It
integrates three complementary sources: Sentinel-2 multispectral imagery for
spatial monitoring, NASA ITS_LIVE velocity products for glacier kinematics, and
MODIS Land Surface Temperature records spanning over two decades. Preprocessing
included cloud masking, quality filtering, normalization, temporal
interpolation, augmentation, and cyclical encoding, followed by harmonization
across modalities. Exploratory analysis reveals seasonal glacier velocity
cycles, long-term warming of ~0.8 K per decade, and spatial heterogeneity in
cryospheric conditions. The resulting dataset, GLOFNet, is publicly available
to support future research in glacial hazard prediction. By addressing
challenges such as class imbalance, cloud contamination, and coarse resolution,
GLOFNet provides a structured foundation for benchmarking multimodal deep
learning approaches to rare hazard prediction.

</details>


### [102] [MRS-YOLO Railroad Transmission Line Foreign Object Detection Based on Improved YOLO11 and Channel Pruning](https://arxiv.org/abs/2510.10553)
*Siyuan Liu,Junting Lin*

Main category: cs.CV

TL;DR: 提出了一种改进的MRS-YOLO算法，用于解决铁路环境中输电线路异物漏检、误检和检测效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 解决铁路环境中输电线路异物检测存在的漏检、误检和检测效率低等问题。

Method: 提出并融合了多尺度自适应核深度特征融合（MAKDF）模块与C3k2模块，形成C3k2_MAKDF，以增强模型对不同尺寸和形状异物的特征提取能力。设计了新颖的再校准特征融合金字塔网络（RCFPN）作为颈部结构，以提升模型有效整合和利用多层级特征的能力。设计了基于空间和通道预处理的空间和通道重建检测头（SC_Detect），以增强模型的整体检测性能。最后，采用通道剪枝技术减少改进模型的冗余，显著降低参数量和GFLOPs，提高检测效率。

Result: MRS-YOLO算法的mAP50和mAP50:95分别提高到94.8%和86.4%，相较于基线分别提高了0.7和2.3个百分点，同时参数量和GFLOPs分别降低了44.2%和17.5%。

Conclusion: 改进的MRS-YOLO算法能够更好地应用于铁路输电线路的异物检测任务。

Abstract: Aiming at the problems of missed detection, false detection and low detection
efficiency in transmission line foreign object detection under railway
environment, we proposed an improved algorithm MRS-YOLO based on YOLO11.
Firstly, a multi-scale Adaptive Kernel Depth Feature Fusion (MAKDF) module is
proposed and fused with the C3k2 module to form C3k2_MAKDF, which enhances the
model's feature extraction capability for foreign objects of different sizes
and shapes. Secondly, a novel Re-calibration Feature Fusion Pyramid Network
(RCFPN) is designed as a neck structure to enhance the model's ability to
integrate and utilize multi-level features effectively. Then, Spatial and
Channel Reconstruction Detect Head (SC_Detect) based on spatial and channel
preprocessing is designed to enhance the model's overall detection performance.
Finally, the channel pruning technique is used to reduce the redundancy of the
improved model, drastically reduce Parameters and Giga Floating Point
Operations Per Second (GFLOPs), and improve the detection efficiency. The
experimental results show that the mAP50 and mAP50:95 of the MRS-YOLO algorithm
proposed in this paper are improved to 94.8% and 86.4%, respectively, which are
0.7 and 2.3 percentage points higher compared to the baseline, while Parameters
and GFLOPs are reduced by 44.2% and 17.5%, respectively. It is demonstrated
that the improved algorithm can be better applied to the task of foreign object
detection in railroad transmission lines.

</details>


### [103] [Deep semi-supervised approach based on consistency regularization and similarity learning for weeds classification](https://arxiv.org/abs/2510.10573)
*Farouq Benchallal,Adel Hafiane,Nicolas Ragot,Raphael Canals*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Weed species classification represents an important step for the development
of automated targeting systems that allow the adoption of precision agriculture
practices. To reduce costs and yield losses caused by their presence. The
identification of weeds is a challenging problem due to their shared
similarities with crop plants and the variability related to the differences in
terms of their types. Along with the variations in relation to changes in field
conditions. Moreover, to fully benefit from deep learning-based methods, large
fully annotated datasets are needed. This requires time intensive and laborious
process for data labeling, which represents a limitation in agricultural
applications. Hence, for the aim of improving the utilization of the unlabeled
data, regarding conditions of scarcity in terms of the labeled data available
during the learning phase and provide robust and high classification
performance. We propose a deep semi-supervised approach, that combines
consistency regularization with similarity learning. Through our developed deep
auto-encoder architecture, experiments realized on the DeepWeeds dataset and
inference in noisy conditions demonstrated the effectiveness and robustness of
our method in comparison to state-of-the-art fully supervised deep learning
models. Furthermore, we carried out ablation studies for an extended analysis
of our proposed joint learning strategy.

</details>


### [104] [UniFlow: A Unified Pixel Flow Tokenizer for Visual Understanding and Generation](https://arxiv.org/abs/2510.10575)
*Zhengrong Yue,Haiyu Zhang,Xiangyu Zeng,Boyu Chen,Chenting Wang,Shaobin Zhuang,Lu Dong,KunPeng Du,Yi Wang,Limin Wang,Yali Wang*

Main category: cs.CV

TL;DR: UniFlow是一个统一的视觉编码器和解码器，通过层级自蒸馏和轻量级像素流解码器，解决了视觉理解和生成之间的性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉 tokenizer 在理解和生成之间存在性能权衡，因为高级语义抽象和低级像素重建之间存在冲突。

Method: UniFlow 通过层级自蒸馏和轻量级像素流解码器，灵活地适配任何视觉编码器，并引入了基于补丁的像素流解码器，利用语义特征作为条件来缓解训练冲突。

Result: UniFlow 在 13 个基准测试中取得了优异的成绩，在理解任务上超越了 TokenFlow-XL，并在像素重建和生成任务上取得了具有竞争力的结果。

Conclusion: UniFlow 成功地解决了视觉理解和生成之间的性能权衡问题，实现了双赢的结果。

Abstract: Tokenizer is a crucial component for both visual understanding and
generation. To advance toward the ultimate goal of universal modeling, recent
research has focused on developing a unified tokenizer. However, existing
tokenizers face a significant performance trade-off between understanding and
generation, stemming from the inherent conflict between high-level semantic
abstraction and low-level pixel reconstruction. To tackle this challenge, we
propose a generic and unified tokenizer, namely UniFlow, by flexibly adapting
any visual encoder with a concise reconstruction decoder. Specifically, we
introduce layer-wise adaptive self-distillation applied to the well-pretrained
visual encoders, which enables UniFlow to simultaneously inherit the strong
semantic features for visual understanding and flexibly adapt to model
fine-grained details for visual generation. Moreover, we propose a lightweight
patch-wise pixel flow decoder, which efficiently achieves high-fidelity pixel
reconstruction by modeling a conditional flow from the noisy state back to the
patch-wise pixel domain. By leveraging the semantic features as visual
conditions for the decoder, we effectively alleviate the training conflicts
between understanding and generation. Furthermore, the patch-wise learning
strategy simplifies the data distribution, thereby improving training
efficiency. Extensive experiments across 13 challenging benchmarks spanning 7
widely studied visual understanding and generation tasks demonstrate that
UniFlow achieves a win-win outcome. For instance, our 7B UniFlow-XL not only
surpasses the 14B TokenFlow-XL by 7.75% on average understanding benchmarks,
but also achieves competitive results in both visual reconstruction and
generation, surpassing UniTok by 0.15 in rFID and 0.09 in gFID (without
guidance), respectively.

</details>


### [105] [Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes](https://arxiv.org/abs/2510.10577)
*Haonan Wang,Hanyu Zhou,Haoyue Liu,Luxin Yan*

Main category: cs.CV

TL;DR: Diff-ABFlow利用扩散模型处理高速低光照场景下的光流估计问题，通过融合帧相机和事件相机的优势，解决了传统方法中视觉特征退化的问题。


<details>
  <summary>Details</summary>
Motivation: 高速低光照场景下的光流估计面临运动模糊和光照不足的挑战，导致纹理减弱、噪声增强，帧相机在这些场景下提供的视觉特征（如外观饱和度和边界完整性）会恶化，影响基于特征匹配的方法。然而，帧相机提供外观饱和度，事件相机提供边界完整性，如何有效融合两者是关键。现有的融合或域适应方法未能解决视觉特征退化的问题，对判别模型和生成模型都造成了严重影响。

Method: 提出了一种新颖的光流估计框架Diff-ABFlow，该框架基于扩散模型，并融合了帧相机和事件相机的外观-边界信息。扩散模型用于学习从加噪流到清晰流的映射，从而不受退化视觉特征的影响。通过结合帧相机和事件相机的优势，以弥补各自的不足，实现更鲁棒的光流估计。

Result: Diff-ABFlow框架能够有效地解决高速低光照场景下的光流估计问题，通过扩散模型处理退化的视觉特征，并融合帧相机和事件相机的互补信息，提升了光流估计的准确性和鲁棒性。

Conclusion: Diff-ABFlow框架通过引入扩散模型并融合帧相机和事件相机的外观-边界信息，为解决传统光流估计方法在高速低光照场景下的局限性提供了一种有效的新途径。

Abstract: Optical flow estimation has achieved promising results in conventional scenes
but faces challenges in high-speed and low-light scenes, which suffer from
motion blur and insufficient illumination. These conditions lead to weakened
texture and amplified noise and deteriorate the appearance saturation and
boundary completeness of frame cameras, which are necessary for motion feature
matching. In degraded scenes, the frame camera provides dense appearance
saturation but sparse boundary completeness due to its long imaging time and
low dynamic range. In contrast, the event camera offers sparse appearance
saturation, while its short imaging time and high dynamic range gives rise to
dense boundary completeness. Traditionally, existing methods utilize feature
fusion or domain adaptation to introduce event to improve boundary
completeness. However, the appearance features are still deteriorated, which
severely affects the mostly adopted discriminative models that learn the
mapping from visual features to motion fields and generative models that
generate motion fields based on given visual features. So we introduce
diffusion models that learn the mapping from noising flow to clear flow, which
is not affected by the deteriorated visual features. Therefore, we propose a
novel optical flow estimation framework Diff-ABFlow based on diffusion models
with frame-event appearance-boundary fusion.

</details>


### [106] [Equipping Vision Foundation Model with Mixture of Experts for Out-of-Distribution Detection](https://arxiv.org/abs/2510.10584)
*Shizhen Zhao,Jiahui Liu,Xin Wen,Haoru Tan,Xiaojuan Qi*

Main category: cs.CV

TL;DR: 预训练视觉基础模型在OOD检测任务中展现出潜力，但现有方法在语义空间大时表现不佳。本文提出MoFE模块和Dynamic-β Mixup策略来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有预训练视觉基础模型在OOD检测上的应用仍有待探索，尤其是在大规模语义空间下表现不佳。

Method: 1. 评估预训练DINOv2模型在OOD检测上的性能。2. 提出MoFE模块来处理大规模语义空间。3. 引入Dynamic-β Mixup策略来改进特征学习。

Result: DINOv2模型在无微调情况下表现出良好的OOD检测能力。MoFE和Dynamic-β Mixup策略在实验中显著优于基线方法，尤其是在大规模语义空间下。

Conclusion: 预训练视觉基础模型是OOD检测的有效工具，提出的MoFE模块和Dynamic-β Mixup策略能够进一步提升其在复杂场景下的性能。

Abstract: Pre-trained vision foundation models have transformed many computer vision
tasks. Despite their strong ability to learn discriminative and generalizable
features crucial for out-of-distribution (OOD) detection, their impact on this
task remains underexplored. Motivated by this gap, we systematically
investigate representative vision foundation models for OOD detection. Our
findings reveal that a pre-trained DINOv2 model, even without fine-tuning on
in-domain (ID) data, naturally provides a highly discriminative feature space
for OOD detection, achieving performance comparable to existing
state-of-the-art methods without requiring complex designs. Beyond this, we
explore how fine-tuning foundation models on in-domain (ID) data can enhance
OOD detection. However, we observe that the performance of vision foundation
models remains unsatisfactory in scenarios with a large semantic space. This is
due to the increased complexity of decision boundaries as the number of
categories grows, which complicates the optimization process. To mitigate this,
we propose the Mixture of Feature Experts (MoFE) module, which partitions
features into subspaces, effectively capturing complex data distributions and
refining decision boundaries. Further, we introduce a Dynamic-$\beta$ Mixup
strategy, which samples interpolation weights from a dynamic beta distribution.
This adapts to varying levels of learning difficulty across categories,
improving feature learning for more challenging categories. Extensive
experiments demonstrate the effectiveness of our approach, significantly
outperforming baseline methods.

</details>


### [107] [A Simple and Better Baseline for Visual Grounding](https://arxiv.org/abs/2510.10587)
*Jingchao Wang,Wenlong Zhang,Dingjiang Huang,Hong Wang,Yefeng Zheng*

Main category: cs.CV

TL;DR: FSVG通过特征选择机制并行处理语言和视觉模态，在不进行迭代的情况下，仅提取与语言相关的视觉特征，从而在准确性和效率之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础研究方法在处理语言和视觉模态时，往往需要进行迭代操作，并在每次迭代中缓存特征，这会带来额外的计算开销。本研究旨在提出一种更简单有效的方法来解决这个问题。

Method: 提出了一种名为FSVG的方法，该方法直接将语言和视觉模态封装在网络结构中，无需复杂迭代。它利用语言并行指导，促进语言和视觉模态的交互，提取有效的视觉特征。此外，通过引入基于相似性的特征选择机制，仅利用与语言相关的视觉特征进行预测，以降低计算成本。

Result: 在多个基准数据集上的大量实验表明，FSVG在准确性和效率之间取得了比现有最先进方法更好的平衡。

Conclusion: FSVG是一种简单有效的方法，通过特征选择机制并行处理语言和视觉模态，在视觉基础任务中实现了准确性和效率的优于现有最先进方法的平衡。

Abstract: Visual grounding aims to predict the locations of target objects specified by
textual descriptions. For this task with linguistic and visual modalities,
there is a latest research line that focuses on only selecting the
linguistic-relevant visual regions for object localization to reduce the
computational overhead. Albeit achieving impressive performance, it is
iteratively performed on different image scales, and at every iteration,
linguistic features and visual features need to be stored in a cache, incurring
extra overhead. To facilitate the implementation, in this paper, we propose a
feature selection-based simple yet effective baseline for visual grounding,
called FSVG. Specifically, we directly encapsulate the linguistic and visual
modalities into an overall network architecture without complicated iterative
procedures, and utilize the language in parallel as guidance to facilitate the
interaction between linguistic modal and visual modal for extracting effective
visual features. Furthermore, to reduce the computational cost, during the
visual feature learning, we introduce a similarity-based feature selection
mechanism to only exploit language-related visual features for faster
prediction. Extensive experiments conducted on several benchmark datasets
comprehensively substantiate that the proposed FSVG achieves a better balance
between accuracy and efficiency beyond the current state-of-the-art methods.
Code is available at https://github.com/jcwang0602/FSVG.

</details>


### [108] [ViSurf: Visual Supervised-and-Reinforcement Fine-Tuning for Large Vision-and-Language Models](https://arxiv.org/abs/2510.10606)
*Yuqi Liu,Liangyu Chen,Jiazhen Liu,Mingkang Zhu,Zhisheng Zhong,Bei Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Typical post-training paradigms for Large Vision-and-Language Models (LVLMs)
include Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable
Rewards (RLVR). SFT leverages external guidance to inject new knowledge,
whereas RLVR utilizes internal reinforcement to enhance reasoning capabilities
and overall performance. However, our analysis reveals that SFT often leads to
sub-optimal performance, while RLVR struggles with tasks that exceed the
model's internal knowledge base. To address these limitations, we propose
ViSurf (\textbf{Vi}sual \textbf{Su}pervised-and-\textbf{R}einforcement
\textbf{F}ine-Tuning), a unified post-training paradigm that integrates the
strengths of both SFT and RLVR within a single stage. We analyze the derivation
of the SFT and RLVR objectives to establish the ViSurf objective, providing a
unified perspective on these two paradigms. The core of ViSurf involves
injecting ground-truth labels into the RLVR rollouts, thereby providing
simultaneous external supervision and internal reinforcement. Furthermore, we
introduce three novel reward control strategies to stabilize and optimize the
training process. Extensive experiments across several diverse benchmarks
demonstrate the effectiveness of ViSurf, outperforming both individual SFT,
RLVR, and two-stage SFT \textrightarrow RLVR. In-depth analysis corroborates
these findings, validating the derivation and design principles of ViSurf.

</details>


### [109] [OmniQuality-R: Advancing Reward Models Through All-Encompassing Quality Assessment](https://arxiv.org/abs/2510.10609)
*Yiting Lu,Fengbin Guan,Yixin Gao,Yan Zhong,Xinge Peng,Jiakang Yuan,Yihao Liu,Bo Zhang,Xin Li,Zhibo Chen,Weisi Lin*

Main category: cs.CV

TL;DR: OmniQuality-R是一个统一的奖励建模框架，用于多任务视觉质量评估，将多维度推理转化为连续、可解释的奖励信号。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉评估方法通常局限于单一任务，缺乏通用性。

Method: 提出OmniQuality-R框架，构建了一个推理增强的奖励建模数据集，并使用GRPO进行后训练，结合高斯奖励、STD过滤和熵门控机制来稳定训练和提高泛化能力。

Result: 在美学质量评估、技术质量评估和文本-图像一致性三个关键IQA任务上进行了评估。

Conclusion: OmniQuality-R能够将多任务质量推理转化为连续、可解释的奖励信号，并有效地应用于多个IQA任务。

Abstract: Current visual evaluation approaches are typically constrained to a single
task. To address this, we propose OmniQuality-R, a unified reward modeling
framework that transforms multi-task quality reasoning into continuous and
interpretable reward signals for policy optimization. Inspired by subjective
experiments, where participants are given task-specific instructions outlining
distinct assessment principles prior to evaluation, we propose OmniQuality-R, a
structured reward modeling framework that transforms multi-dimensional
reasoning into continuous and interpretable reward signals. To enable this, we
construct a reasoning-enhanced reward modeling dataset by sampling informative
plan-reason trajectories via rejection sampling, forming a reliable
chain-of-thought (CoT) dataset for supervised fine-tuning (SFT). Building on
this, we apply Group Relative Policy Optimization (GRPO) for post-training,
using a Gaussian-based reward to support continuous score prediction. To
further stabilize the training and improve downstream generalization, we
incorporate standard deviation (STD) filtering and entropy gating mechanisms
during reinforcement learning. These techniques suppress unstable updates and
reduce variance in policy optimization. We evaluate OmniQuality-R on three key
IQA tasks: aesthetic quality assessment, technical quality evaluation, and
text-image alignment.

</details>


### [110] [GraphTARIF: Linear Graph Transformer with Augmented Rank and Improved Focus](https://arxiv.org/abs/2510.10631)
*Zhaolin Hu,Kun Li,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: 现有的图Transformer中的线性注意力机制存在表达能力下降的问题，我们提出了一种混合框架，通过增强注意力的秩和焦点来解决此问题，在保持线性注意力的可扩展性的同时，在同质和异质图基准上都取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图Transformer中的线性注意力机制存在表达能力下降的问题，这是由于低秩投影结构和过于均匀的注意力分布。这会降低节点表示的类可分离性，限制模型的分类能力。

Method: 我们提出了一种新的混合框架，增强注意力的秩和焦点。具体来说，通过将门控局部图网络分支附加到值矩阵上来增强线性注意力，增加结果注意力图的秩。此外，为了缓解线性注意力固有的过度平滑效应，我们引入了一个可学习的对数幂函数到注意力分数中，以降低熵并锐化焦点。

Result: 通过理论证明和广泛的实验，我们表明该方法能够降低注意力分布的熵，增强学习嵌入的可分离性。我们的方法在同质和异质图基准上都取得了有竞争力的性能，同时保留了线性注意力的可扩展性。

Conclusion: 我们提出的混合框架通过增强注意力的秩和焦点，有效解决了现有线性注意力机制表达能力下降的问题，并在保持模型可扩展性的同时，在各种图基准测试中取得了具有竞争力的结果。

Abstract: Linear attention mechanisms have emerged as efficient alternatives to full
self-attention in Graph Transformers, offering linear time complexity. However,
existing linear attention models often suffer from a significant drop in
expressiveness due to low-rank projection structures and overly uniform
attention distributions. We theoretically prove that these properties reduce
the class separability of node representations, limiting the model's
classification ability. To address this, we propose a novel hybrid framework
that enhances both the rank and focus of attention. Specifically, we enhance
linear attention by attaching a gated local graph network branch to the value
matrix, thereby increasing the rank of the resulting attention map.
Furthermore, to alleviate the excessive smoothing effect inherent in linear
attention, we introduce a learnable log-power function into the attention
scores to reduce entropy and sharpen focus. We theoretically show that this
function decreases entropy in the attention distribution, enhancing the
separability of learned embeddings. Extensive experiments on both homophilic
and heterophilic graph benchmarks demonstrate that our method achieves
competitive performance while preserving the scalability of linear attention.

</details>


### [111] [DEMO: Disentangled Motion Latent Flow Matching for Fine-Grained Controllable Talking Portrait Synthesis](https://arxiv.org/abs/2510.10650)
*Peiyin Chen,Zhuowei Yang,Hui Feng,Sheng Jiang,Rui Yan*

Main category: cs.CV

TL;DR: DEMO是一个基于流匹配的生成框架，用于音频驱动的说话人头像视频合成，能够解耦并高保真地控制唇部运动、头部姿态和眼神。


<details>
  <summary>Details</summary>
Motivation: 生成具有精确运动控制的、时间上连贯的音频驱动的说话人头像视频仍然是一个挑战。

Method: DEMO利用运动自动编码器构建结构化潜在空间，其中运动因子独立表示且近似正交。在此基础上，它应用基于最优传输的流匹配和Transformer预测器，以音频为条件生成时间上平滑的运动轨迹。

Result: 实验表明，DEMO在视频真实感、唇音同步和运动保真度方面优于现有方法。

Conclusion: 将细粒度的运动解耦与基于流的生成模型相结合，为可控的说话人头像视频合成提供了一种强大的新范例。

Abstract: Audio-driven talking-head generation has advanced rapidly with
diffusion-based generative models, yet producing temporally coherent videos
with fine-grained motion control remains challenging. We propose DEMO, a
flow-matching generative framework for audio-driven talking-portrait video
synthesis that delivers disentangled, high-fidelity control of lip motion, head
pose, and eye gaze. The core contribution is a motion auto-encoder that builds
a structured latent space in which motion factors are independently represented
and approximately orthogonalized. On this disentangled motion space, we apply
optimal-transport-based flow matching with a transformer predictor to generate
temporally smooth motion trajectories conditioned on audio. Extensive
experiments across multiple benchmarks show that DEMO outperforms prior methods
in video realism, lip-audio synchronization, and motion fidelity. These results
demonstrate that combining fine-grained motion disentanglement with flow-based
generative modeling provides a powerful new paradigm for controllable
talking-head video synthesis.

</details>


### [112] [A Machine Learning Perspective on Automated Driving Corner Cases](https://arxiv.org/abs/2510.10653)
*Sebastian Schmidt,Julius Körner,Stephan Günnemann*

Main category: cs.CV

TL;DR: 提出了一种新的机器学习方法，考虑了数据分布，以实现对感知数据的有效异常情况识别。


<details>
  <summary>Details</summary>
Motivation: 传统的基于示例的异常情况分类方法存在可扩展性差、缺乏数据覆盖面以及忽视机器学习模型泛化能力等问题，因此需要一种新的方法来解决这些挑战。

Method: 提出了一种新颖的机器学习方法，该方法将数据分布纳入考量，并提出了一个框架来实现对单个样本的有效异常情况识别。

Result: 该方法能够统一现有的基于场景的异常情况分类，在异常情况检测任务中表现强劲，并能通过新引入的包含雾的“Lost & Found”数据集分析组合异常情况。

Conclusion: 所提出的方法为异常情况识别提供了一个有原则的基础，并支持无需手动指定的定义。

Abstract: For high-stakes applications, like autonomous driving, a safe operation is
necessary to prevent harm, accidents, and failures. Traditionally, difficult
scenarios have been categorized into corner cases and addressed individually.
However, this example-based categorization is not scalable and lacks a data
coverage perspective, neglecting the generalization to training data of machine
learning models. In our work, we propose a novel machine learning approach that
takes the underlying data distribution into account. Based on our novel
perspective, we present a framework for effective corner case recognition for
perception on individual samples. In our evaluation, we show that our approach
(i) unifies existing scenario-based corner case taxonomies under a
distributional perspective, (ii) achieves strong performance on corner case
detection tasks across standard benchmarks for which we extend established
out-of-distribution detection benchmarks, and (iii) enables analysis of
combined corner cases via a newly introduced fog-augmented Lost & Found
dataset. These results provide a principled basis for corner case recognition,
underlining our manual specification-free definition.

</details>


### [113] [Stability Under Scrutiny: Benchmarking Representation Paradigms for Online HD Mapping](https://arxiv.org/abs/2510.10660)
*Hao Shan,Ruikai Li,Han Jiang,Yizhe Fan,Ziyang Yan,Bohan Li,Xiaoshuai Hao,Hao Zhao,Zhiyong Cui,Yilong Ren,Haiyang Yu*

Main category: cs.CV

TL;DR: 该论文提出了一个用于评估在线高清地图模型时序稳定性的基准，并引入了新的评估指标（Presence, Localization, Shape Stability）和综合得分（mAS），实验表明精度和稳定性是两个独立维度，并分析了影响模型设计选择的因素。


<details>
  <summary>Details</summary>
Motivation: 现有在线高精地图构建模型优先考虑单帧精度，忽略了在动态环境中因传感器位移导致的地图不稳定性问题，而稳定性对于下游任务至关重要。

Method: 提出一个多维度稳定性评估框架，包含新颖的Presence, Localization, Shape Stability指标，并整合为统一的平均稳定性（mAS）得分，用于评估在线高精地图模型的时序稳定性。在此基础上，对42个模型进行了广泛的实验评估。

Result: 实验表明，精度（mAP）和稳定性（mAS）是两个基本独立的性能维度。研究分析了关键模型设计选择对这两个标准的影响，并确定了有助于提高精度、稳定性的架构和训练因素。

Conclusion: 该研究强调了在评估在线高精地图模型时，应将时序稳定性与精度同等视为核心评估标准，以推动更可靠的自动驾驶系统发展。论文将公开基准工具包、代码和模型。

Abstract: As one of the fundamental modules in autonomous driving, online
high-definition (HD) maps have attracted significant attention due to their
cost-effectiveness and real-time capabilities. Since vehicles always cruise in
highly dynamic environments, spatial displacement of onboard sensors inevitably
causes shifts in real-time HD mapping results, and such instability poses
fundamental challenges for downstream tasks. However, existing online map
construction models tend to prioritize improving each frame's mapping accuracy,
while the mapping stability has not yet been systematically studied. To fill
this gap, this paper presents the first comprehensive benchmark for evaluating
the temporal stability of online HD mapping models. We propose a
multi-dimensional stability evaluation framework with novel metrics for
Presence, Localization, and Shape Stability, integrated into a unified mean
Average Stability (mAS) score. Extensive experiments on 42 models and variants
show that accuracy (mAP) and stability (mAS) represent largely independent
performance dimensions. We further analyze the impact of key model design
choices on both criteria, identifying architectural and training factors that
contribute to high accuracy, high stability, or both. To encourage broader
focus on stability, we will release a public benchmark. Our work highlights the
importance of treating temporal stability as a core evaluation criterion
alongside accuracy, advancing the development of more reliable autonomous
driving systems. The benchmark toolkit, code, and models will be available at
https://stablehdmap.github.io/.

</details>


### [114] [Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection](https://arxiv.org/abs/2510.10663)
*Gaojian Wang,Feng Lin,Tong Wu,Zhisheng Yan,Kui Ren*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: With abundant, unlabeled real faces, how can we learn robust and transferable
facial representations to boost generalization across various face security
tasks? We make the first attempt and propose FS-VFM, a scalable self-supervised
pre-training framework, to learn fundamental representations of real face
images. We introduce three learning objectives, namely 3C, that synergize
masked image modeling (MIM) and instance discrimination (ID), empowering FS-VFM
to encode both local patterns and global semantics of real faces. Specifically,
we formulate various facial masking strategies for MIM and devise a simple yet
effective CRFR-P masking, which explicitly prompts the model to pursue
meaningful intra-region Consistency and challenging inter-region Coherency. We
present a reliable self-distillation mechanism that seamlessly couples MIM with
ID to establish underlying local-to-global Correspondence. After pre-training,
vanilla vision transformers (ViTs) serve as universal Vision Foundation Models
for downstream Face Security tasks: cross-dataset deepfake detection,
cross-domain face anti-spoofing, and unseen diffusion facial forensics. To
efficiently transfer the pre-trained FS-VFM, we further propose FS-Adapter, a
lightweight plug-and-play bottleneck atop the frozen backbone with a novel
real-anchor contrastive objective. Extensive experiments on 11 public
benchmarks demonstrate that our FS-VFM consistently generalizes better than
diverse VFMs, spanning natural and facial domains, fully, weakly, and
self-supervised paradigms, small, base, and large ViT scales, and even
outperforms SOTA task-specific methods, while FS-Adapter offers an excellent
efficiency-performance trade-off. The code and models are available on
https://fsfm-3c.github.io/fsvfm.html.

</details>


### [115] [AdaViewPlanner: Adapting Video Diffusion Models for Viewpoint Planning in 4D Scenes](https://arxiv.org/abs/2510.10670)
*Yu Li,Menghan Xia,Gongye Liu,Jianhong Bai,Xintao Wang,Conglang Zhang,Yuxuan Lin,Ruihang Chu,Pengfei Wan,Yujiu Yang*

Main category: cs.CV

TL;DR: T2V模型可用于4D场景的视角规划，提出两阶段范式，将4D场景注入T2V模型，并通过相机外参去噪提取视角，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: T2V模型在模拟现实世界几何和物理规律方面表现出强大能力，可作为隐式世界模型，受此启发，探索利用T2V模型的视频生成先验知识进行4D场景的视角规划。

Method: 提出一个两阶段范式来适应预训练的T2V模型以进行视角预测：1. 通过自适应学习分支将4D场景表示注入预训练的T2V模型，其中4D场景是视角无关的，条件生成的视频在视觉上嵌入视角。2. 将视角提取制定为混合条件引导的相机外参去噪过程，在预训练的T2V模型上引入相机外参扩散分支，以生成的视频和4D场景作为输入。

Result: 实验结果表明，所提出的方法在视角规划方面优于现有竞争对手，并且消融研究验证了关键技术设计的有效性。

Conclusion: 这项工作在一定程度上证明了视频生成模型在现实世界4D交互方面的潜力。

Abstract: Recent Text-to-Video (T2V) models have demonstrated powerful capability in
visual simulation of real-world geometry and physical laws, indicating its
potential as implicit world models. Inspired by this, we explore the
feasibility of leveraging the video generation prior for viewpoint planning
from given 4D scenes, since videos internally accompany dynamic scenes with
natural viewpoints. To this end, we propose a two-stage paradigm to adapt
pre-trained T2V models for viewpoint prediction, in a compatible manner. First,
we inject the 4D scene representation into the pre-trained T2V model via an
adaptive learning branch, where the 4D scene is viewpoint-agnostic and the
conditional generated video embeds the viewpoints visually. Then, we formulate
viewpoint extraction as a hybrid-condition guided camera extrinsic denoising
process. Specifically, a camera extrinsic diffusion branch is further
introduced onto the pre-trained T2V model, by taking the generated video and 4D
scene as input. Experimental results show the superiority of our proposed
method over existing competitors, and ablation studies validate the
effectiveness of our key technical designs. To some extent, this work proves
the potential of video generation models toward 4D interaction in real world.

</details>


### [116] [Image-to-Video Transfer Learning based on Image-Language Foundation Models: A Comprehensive Survey](https://arxiv.org/abs/2510.10671)
*Jinxuan Li,Chaolei Tan,Haoxuan Chen,Jianxin Ma,Jian-Fang Hu,Wei-Shi Zheng,Jianhuang Lai*

Main category: cs.CV

TL;DR: 该论文全面回顾了图像到视频迁移学习领域，重点介绍了如何利用图像-语言基础模型（ILFM）来改进视频-文本学习任务。


<details>
  <summary>Details</summary>
Motivation: 由于从头开始训练视频-语言基础模型需要大量数据和计算资源，因此研究如何将成功的图像-语言基础模型（ILFM）迁移到视频领域（即图像到视频迁移学习）具有重要意义。

Method: 该调查首先总结了常用的ILFM，然后将现有的图像到视频迁移学习策略分为“冻结特征”和“修改特征”两类。论文详细阐述了这些策略及其在各种视频-文本学习任务中的应用，并进行了实验分析，最后指出了未来的挑战和研究方向。

Result: 该论文对图像到视频迁移学习策略进行了分类，并分析了其在视频-文本学习任务中的应用和有效性。

Conclusion: 该调查为基于ILFM的视频-文本学习提供了一个全面的路线图，并为该领域未来的研究指明了方向。

Abstract: Image-Language Foundation Models (ILFM) have demonstrated remarkable success
in image-text understanding/generation tasks, providing transferable multimodal
representations that generalize across diverse downstream image-based tasks.
The advancement of video-text research has spurred growing interest in
extending image-based models to the video domain. This paradigm, known as
image-to-video transfer learning, succeeds in alleviating the substantial data
and computational requirements associated with training video-language
foundation models from scratch for video-text learning. This survey provides
the first comprehensive review of this emerging field, which begins by
summarizing the widely used ILFM and their capabilities. We then systematically
classify existing image-to-video transfer learning strategies into two
categories: frozen features and modified features, depending on whether the
original representations from ILFM are preserved or undergo modifications.
Building upon the task-specific nature of image-to-video transfer, this survey
methodically elaborates these strategies and details their applications across
a spectrum of video-text learning tasks, ranging from fine-grained (e.g.,
spatio-temporal video grounding) to coarse-grained (e.g., video question
answering). We further present a detailed experimental analysis to investigate
the efficacy of different image-to-video transfer learning paradigms on a range
of downstream video understanding tasks. Finally, we identify prevailing
challenges and highlight promising directions for future research. By offering
a comprehensive and structured overview, this survey aims to establish a
structured roadmap for advancing video-text learning based on existing ILFM,
and to inspire future research directions in this rapidly evolving domain.

</details>


### [117] [MSM-Seg: A Modality-and-Slice Memory Framework with Category-Agnostic Prompting for Multi-Modal Brain Tumor Segmentation](https://arxiv.org/abs/2510.10679)
*Yuxiang Luo,Qing Xu,Hai Huang,Yuqi Ouyang,Zhen Chen,Wenting Duan*

Main category: cs.CV

TL;DR: 该研究提出了MSM-Seg框架，用于多模态脑肿瘤分割，通过整合模态间和切片间信息，并使用类别无关的提示来提高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的分割方法忽略了模态间的相关性，并且依赖于需要大量人力标注的特定类别提示，限制了其在实际应用中的效果。多模态脑肿瘤分割对于准确识别内部解剖亚区域至关重要。

Method: 提出了一种新颖的双记忆分割范式，称为MSM-Seg。该范式整合了多模态和切片间信息，并使用高效的类别无关提示进行脑肿瘤理解。具体包括：1. 模态和切片记忆注意力（MSMA），用于挖掘输入扫描之间的模态间和切片间关系。2. 多尺度类别无关提示编码器（MCP-Encoder），为解码提供肿瘤区域指导。3. 模态自适应融合解码器（MF-Decoder），利用不同模态的互补解码信息来提高分割精度。

Result: 在不同的MRI数据集上进行了广泛的实验，MSM-Seg框架在多模态转移瘤和胶质瘤分割方面优于现有的最先进方法。

Conclusion: MSM-Seg框架通过其新颖的双记忆范式、模态和切片记忆注意力、多尺度类别无关提示编码器以及模态自适应融合解码器，有效地解决了现有方法在多模态脑肿瘤分割中的局限性，并在多个数据集上取得了优于现有技术的性能。

Abstract: Multi-modal brain tumor segmentation is critical for clinical diagnosis, and
it requires accurate identification of distinct internal anatomical subregions.
While the recent prompt-based segmentation paradigms enable interactive
experiences for clinicians, existing methods ignore cross-modal correlations
and rely on labor-intensive category-specific prompts, limiting their
applicability in real-world scenarios. To address these issues, we propose a
MSM-Seg framework for multi-modal brain tumor segmentation. The MSM-Seg
introduces a novel dual-memory segmentation paradigm that synergistically
integrates multi-modal and inter-slice information with the efficient
category-agnostic prompt for brain tumor understanding. To this end, we first
devise a modality-and-slice memory attention (MSMA) to exploit the cross-modal
and inter-slice relationships among the input scans. Then, we propose a
multi-scale category-agnostic prompt encoder (MCP-Encoder) to provide tumor
region guidance for decoding. Moreover, we devise a modality-adaptive fusion
decoder (MF-Decoder) that leverages the complementary decoding information
across different modalities to improve segmentation accuracy. Extensive
experiments on different MRI datasets demonstrate that our MSM-Seg framework
outperforms state-of-the-art methods in multi-modal metastases and glioma tumor
segmentation. The code is available at https://github.com/xq141839/MSM-Seg.

</details>


### [118] [Action-Dynamics Modeling and Cross-Temporal Interaction for Online Action Understanding](https://arxiv.org/abs/2510.10682)
*Xinyu Yang,Zheheng Jiang,Feixiang Zhou,Yihang Zhu,Na Lv,Nan Xing,Huiyu Zhou*

Main category: cs.CV

TL;DR: 该研究提出了一种名为状态特定模型（SSM）的新框架，用于统一和改进动作检测和动作预测任务，解决了未剪辑视频中的冗余信息和噪声问题，并考虑了智能对动作的影响。


<details>
  <summary>Details</summary>
Motivation: 未剪辑视频包含大量冗余信息和噪声，并且在动作理解建模中忽略了智能对动作的影响。

Method: 提出状态特定模型（SSM）框架，包括：1. 关键状态记忆压缩模块：压缩帧序列为关键状态，减少冗余。2. 动作模式学习模块：构建状态转移图，模拟动作动态并生成代表智能的未来线索。3. 跨时间交互模块：通过跨时间交互来模拟智能与过去和当前信息之间的相互影响，从而优化当前和未来的特征，实现同步的动作检测和预测。

Result: 在EPIC-Kitchens-100、THUMOS'14、TVSeries和PDMB等多个基准数据集上进行了广泛实验，结果表明SSM框架的性能优于其他最先进的方法。

Conclusion: SSM框架在动作检测和预测方面表现优越，突显了动作动态学习和跨时间交互的重要性，为未来的动作理解研究奠定了基础。

Abstract: Action understanding, encompassing action detection and anticipation, plays a
crucial role in numerous practical applications. However, untrimmed videos are
often characterized by substantial redundant information and noise. Moreover,
in modeling action understanding, the influence of the agent's intention on the
action is often overlooked. Motivated by these issues, we propose a novel
framework called the State-Specific Model (SSM), designed to unify and enhance
both action detection and anticipation tasks. In the proposed framework, the
Critical State-Based Memory Compression module compresses frame sequences into
critical states, reducing information redundancy. The Action Pattern Learning
module constructs a state-transition graph with multi-dimensional edges to
model action dynamics in complex scenarios, on the basis of which potential
future cues can be generated to represent intention. Furthermore, our
Cross-Temporal Interaction module models the mutual influence between
intentions and past as well as current information through cross-temporal
interactions, thereby refining present and future features and ultimately
realizing simultaneous action detection and anticipation. Extensive experiments
on multiple benchmark datasets -- including EPIC-Kitchens-100, THUMOS'14,
TVSeries, and the introduced Parkinson's Disease Mouse Behaviour (PDMB) dataset
-- demonstrate the superior performance of our proposed framework compared to
other state-of-the-art approaches. These results highlight the importance of
action dynamics learning and cross-temporal interactions, laying a foundation
for future action understanding research.

</details>


### [119] [Dynamic Gaussian Splatting from Defocused and Motion-blurred Monocular Videos](https://arxiv.org/abs/2510.10691)
*Xuankai Zhang,Junjin Xiao,Qing Zhang*

Main category: cs.CV

TL;DR: 本篇论文提出了一种统一的框架，能够从失焦和运动模糊的单目视频中生成高质量的动态高斯喷溅效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时处理失焦模糊和运动模糊，因为它们的形成过程差异很大。尽管可以通过模糊核卷积进行联合建模，但准确估计模糊核的难度限制了该方向的进展。本研究旨在解决这一问题。

Method: 提出了一种使用模糊预测网络估计每像素可靠模糊核的方法，该网络利用与模糊相关的场景和相机信息，并受到模糊感知稀疏性约束。此外，还引入了一种动态高斯致密化策略来解决不完整区域的高斯点缺失问题，并通过结合未见视图信息来约束场景优化，以提升新视图合成性能。

Result: 实验证明，该方法在从失焦和运动模糊的单目视频生成照片级真实感新视图方面，优于现有最先进的方法。

Conclusion: 本研究提出了一种统一框架，能够有效地处理失焦和运动模糊的单目视频，生成高质量的动态高斯喷溅效果，并在新视图合成方面取得了优于现有方法的性能。

Abstract: This paper presents a unified framework that allows high-quality dynamic
Gaussian Splatting from both defocused and motion-blurred monocular videos. Due
to the significant difference between the formation processes of defocus blur
and motion blur, existing methods are tailored for either one of them, lacking
the ability to simultaneously deal with both of them. Although the two can be
jointly modeled as blur kernel-based convolution, the inherent difficulty in
estimating accurate blur kernels greatly limits the progress in this direction.
In this work, we go a step further towards this direction. Particularly, we
propose to estimate per-pixel reliable blur kernels using a blur prediction
network that exploits blur-related scene and camera information and is subject
to a blur-aware sparsity constraint. Besides, we introduce a dynamic Gaussian
densification strategy to mitigate the lack of Gaussians for incomplete
regions, and boost the performance of novel view synthesis by incorporating
unseen view information to constrain scene optimization. Extensive experiments
show that our method outperforms the state-of-the-art methods in generating
photorealistic novel view synthesis from defocused and motion-blurred monocular
videos. Our code and trained model will be made publicly available.

</details>


### [120] [WorldMirror: Universal 3D World Reconstruction with Any-Prior Prompting](https://arxiv.org/abs/2510.10726)
*Yifan Liu,Zhiyuan Min,Zhenwei Wang,Junta Wu,Tengfei Wang,Yixuan Yuan,Yawei Luo,Chunchao Guo*

Main category: cs.CV

TL;DR: WorldMirror是一个一体化的前馈模型，可用于多种3D几何预测任务。它整合了多种几何先验信息（如相机姿态、内参和深度图），并能同时生成多种3D表示（如点云、多视图深度图、相机参数、表面法线和3D高斯）。该模型在多个基准测试中都取得了最先进的性能，同时保持了前馈推理的效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于仅图像输入或为特定任务定制，而WorldMirror旨在创建一个能够灵活整合多种几何先验信息并同时生成多种3D表示的通用框架。

Method: WorldMirror采用一体化、前馈的设计，整合了相机姿态、内参和深度图等几何先验信息，并通过单一前向传播生成包括密集点云、多视图深度图、相机参数、表面法线和3D高斯在内的多种3D表示。

Result: WorldMirror在相机、点图、深度和表面法线估计以及新视角合成等多个基准测试中取得了最先进的性能，同时保持了前馈推理的效率。

Conclusion: WorldMirror通过整合多种几何先验信息和生成多种3D表示，提供了一种高效且通用的3D几何预测解决方案，并在多个任务上展现了优越性能。

Abstract: We present WorldMirror, an all-in-one, feed-forward model for versatile 3D
geometric prediction tasks. Unlike existing methods constrained to image-only
inputs or customized for a specific task, our framework flexibly integrates
diverse geometric priors, including camera poses, intrinsics, and depth maps,
while simultaneously generating multiple 3D representations: dense point
clouds, multi-view depth maps, camera parameters, surface normals, and 3D
Gaussians. This elegant and unified architecture leverages available prior
information to resolve structural ambiguities and delivers geometrically
consistent 3D outputs in a single forward pass. WorldMirror achieves
state-of-the-art performance across diverse benchmarks from camera, point map,
depth, and surface normal estimation to novel view synthesis, while maintaining
the efficiency of feed-forward inference. Code and models will be publicly
available soon.

</details>


### [121] [Seeing My Future: Predicting Situated Interaction Behavior in Virtual Reality](https://arxiv.org/abs/2510.10742)
*Yuan Xu,Zimu Zhang,Xiaoxuan Ma,Wentao Zhu,Yu Qiao,Yizhou Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的框架，用于通过模拟认知机制来预测虚拟和增强现实中的人类意图和行为。


<details>
  <summary>Details</summary>
Motivation: 为了提升虚拟和增强现实（VR/AR）系统的交互体验，需要智能地适应用户行为，准确理解用户意图并预测其未来行为至关重要。

Method: 提出了一种分层的、意图感知的框架，该框架利用认知机制来模拟人类意图并预测详细的行为。该框架首先识别潜在的交互目标，然后预测未来的行为。在此过程中，使用动态图卷积网络（GCN）来捕捉人与环境之间的关系。

Result: 在具有挑战性的真实世界基准和实时VR环境上的广泛实验表明，该方法在所有指标上均取得了优越的性能。

Conclusion: 所提出的框架能够有效预测用户行为，并支持主动式VR系统，这些系统可以预测用户行为并相应地调整虚拟环境。

Abstract: Virtual and augmented reality systems increasingly demand intelligent
adaptation to user behaviors for enhanced interaction experiences. Achieving
this requires accurately understanding human intentions and predicting future
situated behaviors - such as gaze direction and object interactions - which is
vital for creating responsive VR/AR environments and applications like
personalized assistants. However, accurate behavioral prediction demands
modeling the underlying cognitive processes that drive human-environment
interactions. In this work, we introduce a hierarchical, intention-aware
framework that models human intentions and predicts detailed situated behaviors
by leveraging cognitive mechanisms. Given historical human dynamics and the
observation of scene contexts, our framework first identifies potential
interaction targets and forecasts fine-grained future behaviors. We propose a
dynamic Graph Convolutional Network (GCN) to effectively capture
human-environment relationships. Extensive experiments on challenging
real-world benchmarks and live VR environment demonstrate the effectiveness of
our approach, achieving superior performance across all metrics and enabling
practical applications for proactive VR systems that anticipate user behaviors
and adapt virtual environments accordingly.

</details>


### [122] [Uncovering Anomalous Events for Marine Environmental Monitoring via Visual Anomaly Detection](https://arxiv.org/abs/2510.10750)
*Laura Weihl,Nejc Novak,Stefan H. Bengtson,Malte Pedersen*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的视觉异常检测（VAD）方法，用于自动识别水下视频中不寻常的事件，以解决手动检查海量水下视频效率低下的问题。研究人员构建了首个水下VAD多注释基准数据集AURA，并评估了四种VAD模型在两个海洋场景下的表现。实验结果表明，有效的帧选择策略对于提取有意义的视频片段至关重要。此外，研究还强调了软标签和共识标签的价值，并提出了一种支持科学探索和可扩展生物多样性监测的实用方法。


<details>
  <summary>Details</summary>
Motivation: 水下视频监测是评估海洋生物多样性的有效手段，但手动检查海量视频内容繁琐且不切实际。本研究旨在探索使用基于深度学习的视觉异常检测（VAD）技术，自动识别水下视频中值得关注或异常的事件。

Method: 研究人员开发了一个名为AURA的多注释基准数据集，该数据集是第一个专门用于水下VAD任务的数据集。他们评估了四种不同的VAD模型在两个海洋场景下的性能，并重点研究了鲁棒的帧选择策略对于提取有意义的视频片段的重要性。

Result: 评估结果显示，当前VAD模型的性能差异很大，并且对训练数据的数量和定义“正常”场景的视觉内容的可变性高度敏感。研究还发现，软标签和共识标签在提高模型性能方面具有重要价值。

Conclusion: 视觉异常检测（VAD）是一种有潜力的方法，可以自动识别水下视频中的异常事件，从而辅助海洋生物多样性监测。然而，当前模型的性能尚不稳定，易受训练数据和场景内容变化的影响。研究强调了采用软标签和共识标签策略以及有效的帧选择方法的重要性，为未来的研究和实际应用提供了方向。

Abstract: Underwater video monitoring is a promising strategy for assessing marine
biodiversity, but the vast volume of uneventful footage makes manual inspection
highly impractical. In this work, we explore the use of visual anomaly
detection (VAD) based on deep neural networks to automatically identify
interesting or anomalous events. We introduce AURA, the first multi-annotator
benchmark dataset for underwater VAD, and evaluate four VAD models across two
marine scenes. We demonstrate the importance of robust frame selection
strategies to extract meaningful video segments. Our comparison against
multiple annotators reveals that VAD performance of current models varies
dramatically and is highly sensitive to both the amount of training data and
the variability in visual content that defines "normal" scenes. Our results
highlight the value of soft and consensus labels and offer a practical approach
for supporting scientific exploration and scalable biodiversity monitoring.

</details>


### [123] [Restricted Receptive Fields for Face Verification](https://arxiv.org/abs/2510.10753)
*Kagan Ozturk,Aman Bhatta,Haiyu Wu,Patrick Flynn,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 该研究提出了一种新的面部相似性度量方法，将全局相似性分解为受限感受野的贡献，实现了可解释的、局部可加的面部验证。


<details>
  <summary>Details</summary>
Motivation: 由于现有模型解释性方法（尤其是像素重要性分配）的保真度不确定，且缺乏可靠的评估指标，因此需要开发一种模型本身就具有可解释性的方法。

Method: 提出了一种面部相似性度量方法，将两张面部图像的相似性定义为局部块（patch）级别相似性分数的总和，实现了局部可加的解释，无需事后分析。

Result: 所提出的方法在人脸验证任务上取得了有竞争力的性能，即使在使用小至 28x28 像素的图像块时也是如此，并且在使用 56x56 像素的图像块时超越了现有技术。

Conclusion: 该方法通过将全局相似性分解为局部贡献，提供了一种固有可解释的面部相似性度量方法，并在人脸验证任务上展现出优越性能。

Abstract: Understanding how deep neural networks make decisions is crucial for
analyzing their behavior and diagnosing failure cases. In computer vision, a
common approach to improve interpretability is to assign importance to
individual pixels using post-hoc methods. Although they are widely used to
explain black-box models, their fidelity to the model's actual reasoning is
uncertain due to the lack of reliable evaluation metrics. This limitation
motivates an alternative approach, which is to design models whose decision
processes are inherently interpretable. To this end, we propose a face
similarity metric that breaks down global similarity into contributions from
restricted receptive fields. Our method defines the similarity between two face
images as the sum of patch-level similarity scores, providing a locally
additive explanation without relying on post-hoc analysis. We show that the
proposed approach achieves competitive verification performance even with
patches as small as 28x28 within 112x112 face images, and surpasses
state-of-the-art methods when using 56x56 patches.

</details>


### [124] [EGD-YOLO: A Lightweight Multimodal Framework for Robust Drone-Bird Discrimination via Ghost-Enhanced YOLOv8n and EMA Attention under Adverse Condition](https://arxiv.org/abs/2510.10765)
*Sudipto Sarkar,Mohammad Asif Hasan,Khondokar Ashik Shahriar,Fablia Labiba,Nahian Tasnim,Sheikh Anawarul Haq Fattah*

Main category: cs.CV

TL;DR: EGD-YOLOv8n是一个用于识别无人机和鸟类的轻量级模型，结合RGB和红外图像，在VIP CUP 2025数据集上实现了高精度和实时检测。


<details>
  <summary>Details</summary>
Motivation: 为了提高天空安全和安防系统，需要正确识别无人机和鸟类。

Method: 提出了一种名为EGD-YOLOv8n的新型轻量级目标检测模型，该模型改进了图像特征的捕捉和理解能力，并采用了注意力层和特殊检测头来适应不同大小和形状的目标。研究了仅使用RGB图像、仅使用红外图像以及结合两种图像的三个模型版本。

Result: 结合RGB和红外图像的模型在准确性和可靠性方面表现最佳，同时保持了在常见GPU上进行实时使用的速度。

Conclusion: 结合RGB和红外图像的EGD-YOLOv8n模型在无人机和鸟类识别任务中取得了最佳性能，证明了其在实时应用中的有效性。

Abstract: Identifying drones and birds correctly is essential for keeping the skies
safe and improving security systems. Using the VIP CUP 2025 dataset, which
provides both RGB and infrared (IR) images, this study presents EGD-YOLOv8n, a
new lightweight yet powerful model for object detection. The model improves how
image features are captured and understood, making detection more accurate and
efficient. It uses smart design changes and attention layers to focus on
important details while reducing the amount of computation needed. A special
detection head helps the model adapt to objects of different shapes and sizes.
We trained three versions: one using RGB images, one using IR images, and one
combining both. The combined model achieved the best accuracy and reliability
while running fast enough for real-time use on common GPUs.

</details>


### [125] [Structured Spectral Graph Learning for Multi-label Abnormality Classification in 3D Chest CT Scans](https://arxiv.org/abs/2510.10779)
*Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel*

Main category: cs.CV

TL;DR: 该研究提出了一种新的2.5D图神经网络框架，用于处理3D胸部CT扫描的多标签分类问题，解决了现有3D CNN和ViT的局限性，并在多个数据集上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对CT检查量不断增长的趋势，需要自动化工具来支持放射科医生，特别是胸部CT扫描的多标签分类，但现有方法存在捕捉长程依赖性不足和需要大规模预训练的问题。

Method: 提出了一种2.5D图神经网络框架，将3D CT数据表示为图结构，使用光谱图卷积处理相邻切片信息，以推理切片间的依赖关系。

Result: 该方法在多个独立数据集上进行了训练和评估，实现了良好的跨数据集泛化能力，并且在性能上与最先进的视觉编码器相当。消融研究验证了不同聚合策略、边权重方案和图连接模式的影响。此外，该方法在自动生成放射学报告和腹部CT数据上显示了其广泛的应用前景。

Conclusion: 所提出的2.5D图神经网络框架是一种有效且计算效率高的方法，能够处理3D胸部CT扫描的多标签分类任务，并具有良好的泛化能力和广泛的应用潜力。

Abstract: With the growing volume of CT examinations, there is an increasing demand for
automated tools such as organ segmentation, abnormality detection, and report
generation to support radiologists in managing their clinical workload.
Multi-label classification of 3D Chest CT scans remains a critical yet
challenging problem due to the complex spatial relationships inherent in
volumetric data and the wide variability of abnormalities. Existing methods
based on 3D convolutional neural networks struggle to capture long-range
dependencies, while Vision Transformers often require extensive pre-training on
large-scale, domain-specific datasets to perform competitively. In this work,
we propose a 2.5D alternative by introducing a new graph-based framework that
represents 3D CT volumes as structured graphs, where axial slice triplets serve
as nodes processed through spectral graph convolution, enabling the model to
reason over inter-slice dependencies while maintaining complexity compatible
with clinical deployment. Our method, trained and evaluated on 3 datasets from
independent institutions, achieves strong cross-dataset generalization, and
shows competitive performance compared to state-of-the-art visual encoders. We
further conduct comprehensive ablation studies to evaluate the impact of
various aggregation strategies, edge-weighting schemes, and graph connectivity
patterns. Additionally, we demonstrate the broader applicability of our
approach through transfer experiments on automated radiology report generation
and abdominal CT data.\\ This work extends our previous contribution presented
at the MICCAI 2025 EMERGE Workshop.

</details>


### [126] [DISC-GAN: Disentangling Style and Content for Cluster-Specific Synthetic Underwater Image Generation](https://arxiv.org/abs/2510.10782)
*Sneha Varur,Anirudh R Hanchinamani,Tarun S Bagewadi,Uma Mudenagudi,Chaitra D Desai,Sujata C,Padmashree Desai,Sumit Meharwade*

Main category: cs.CV

TL;DR: DISC-GAN通过解耦风格-内容并采用聚类特定训练策略来合成逼真的水下图像。


<details>
  <summary>Details</summary>
Motivation: 水下图像合成面临光学挑战，如颜色衰减和浊度，这些挑战在不同水体中表现为色调和朦胧度等风格变化。现有模型难以处理这些非均匀条件。

Method: 使用K-means聚类将数据集划分为特定风格的域。使用单独的编码器来获取风格和内容的潜在空间，并通过自适应实例归一化（AdaIN）整合这些潜在表示，然后解码生成最终图像。模型在每个风格簇上独立训练。

Result: 实现了0.9012的结构相似性指数（SSIM）、32.5118 dB的平均峰值信噪比（PSNR）和13.3728的弗雷歇起始距离（FID）。

Conclusion: DISC-GAN在水下图像合成方面取得了最先进的性能。

Abstract: In this paper, we propose a novel framework, Disentangled Style-Content GAN
(DISC-GAN), which integrates style-content disentanglement with a
cluster-specific training strategy towards photorealistic underwater image
synthesis. The quality of synthetic underwater images is challenged by optical
due to phenomena such as color attenuation and turbidity. These phenomena are
represented by distinct stylistic variations across different waterbodies, such
as changes in tint and haze. While generative models are well-suited to capture
complex patterns, they often lack the ability to model the non-uniform
conditions of diverse underwater environments. To address these challenges, we
employ K-means clustering to partition a dataset into style-specific domains.
We use separate encoders to get latent spaces for style and content; we further
integrate these latent representations via Adaptive Instance Normalization
(AdaIN) and decode the result to produce the final synthetic image. The model
is trained independently on each style cluster to preserve domain-specific
characteristics. Our framework demonstrates state-of-the-art performance,
obtaining a Structural Similarity Index (SSIM) of 0.9012, an average Peak
Signal-to-Noise Ratio (PSNR) of 32.5118 dB, and a Frechet Inception Distance
(FID) of 13.3728.

</details>


### [127] [ImHead: A Large-scale Implicit Morphable Model for Localized Head Modeling](https://arxiv.org/abs/2510.10793)
*Rolandos Alexandros Potamias,Stathis Galanakis,Jiankang Deng,Athanasios Papaioannou,Stefanos Zafeiriou*

Main category: cs.CV

TL;DR: imHead是一个新的隐式3DMM，可以生成和编辑3D头像，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3DMM在表示复杂的头部形状和进行局部编辑方面存在局限性。

Method: 提出了一种新的隐式3DMM（imHead），它使用一个紧凑的身份空间和一个中间的区域特定潜在表示来实现局部编辑，并构建了一个包含4000个独特身份的大规模数据集。

Result: imHead能够生成多样的身份和表情，优于现有方法，并提供可解释的3D面部操作。

Conclusion: imHead在表示和编辑3D头像方面取得了显著进步，并为大规模3D头部建模和可解释的面部操作提供了新的途径。

Abstract: Over the last years, 3D morphable models (3DMMs) have emerged as a
state-of-the-art methodology for modeling and generating expressive 3D avatars.
However, given their reliance on a strict topology, along with their linear
nature, they struggle to represent complex full-head shapes. Following the
advent of deep implicit functions, we propose imHead, a novel implicit 3DMM
that not only models expressive 3D head avatars but also facilitates localized
editing of the facial features. Previous methods directly divided the latent
space into local components accompanied by an identity encoding to capture the
global shape variations, leading to expensive latent sizes. In contrast, we
retain a single compact identity space and introduce an intermediate
region-specific latent representation to enable local edits. To train imHead,
we curate a large-scale dataset of 4K distinct identities, making a
step-towards large scale 3D head modeling. Under a series of experiments we
demonstrate the expressive power of the proposed model to represent diverse
identities and expressions outperforming previous approaches. Additionally, the
proposed approach provides an interpretable solution for 3D face manipulation,
allowing the user to make localized edits.

</details>


### [128] [Full segmentation annotations of 3D time-lapse microscopy images of MDA231 cells](https://arxiv.org/abs/2510.10797)
*Aleksandra Melnikova,Petr Matula*

Main category: cs.CV

TL;DR: 本文介绍了首个公开的迁移细胞3D延时分割标注数据集（Fluo-C3DL-MDA231），并提供了更详细的数据集描述和实验结果。


<details>
  <summary>Details</summary>
Motivation: 为推动图像处理领域发展，需要高质量、公开可用的图像和视频分割标注数据集，特别是针对具有复杂动态形状的大量目标的体积图像标注，具有耗时和挑战性。

Method: 对MDA231人类乳腺癌细胞的两个序列进行了标注，并进行了与现有追踪标记的一致性验证、2D金标准分割精度评估以及与自动生成的银标准分割的比较。

Result: 生成的标注与CTC提供的追踪标记一致，2D金标准分割精度在标注者间变异性范围内。与CTC提供的银标准相比，本文提出的3D标注能更好地表示输入图像的复杂性。

Conclusion: 所提出的3D分割标注数据集（Fluo-C3DL-MDA231）质量高，能准确表示动态细胞的复杂形状，可用于细胞分割测试、训练以及3D动态物体形状分析。

Abstract: High-quality, publicly available segmentation annotations of image and video
datasets are critical for advancing the field of image processing. In
particular, annotations of volumetric images of a large number of targets are
time-consuming and challenging. In (Melnikova, A., & Matula, P., 2025), we
presented the first publicly available full 3D time-lapse segmentation
annotations of migrating cells with complex dynamic shapes. Concretely, three
distinct humans annotated two sequences of MDA231 human breast carcinoma cells
(Fluo-C3DL-MDA231) from the Cell Tracking Challenge (CTC).
  This paper aims to provide a comprehensive description of the dataset and
accompanying experiments that were not included in (Melnikova, A., & Matula,
P., 2025) due to limitations in publication space. Namely, we show that the
created annotations are consistent with the previously published tracking
markers provided by the CTC organizers and the segmentation accuracy measured
based on the 2D gold truth of CTC is within the inter-annotator variability
margins. We compared the created 3D annotations with automatically created
silver truth provided by CTC. We have found the proposed annotations better
represent the complexity of the input images. The presented annotations can be
used for testing and training cell segmentation, or analyzing 3D shapes of
highly dynamic objects.

</details>


### [129] [MSCloudCAM: Cross-Attention with Multi-Scale Context for Multispectral Cloud Segmentation](https://arxiv.org/abs/2510.10802)
*Md Abdullah Al Mazid,Liangdong Deng,Naphtali Rishe*

Main category: cs.CV

TL;DR: MSCloudCAM是一个用于多光谱和多传感器云分割的交叉注意力多尺度上下文网络，在CloudSEN12和L8Biome数据集上实现了最先进的分割精度。


<details>
  <summary>Details</summary>
Motivation: 云层严重阻碍了光学卫星图像在环境监测、土地覆盖测绘和气候研究等领域的可靠分析。

Method: MSCloudCAM结合了Swin Transformer骨干网络、ASPP和PSP多尺度上下文模块、交叉注意力模块以及高效通道注意力模块（ECAB）和空间注意力模块，用于多光谱和多传感器的云分割，能够分类晴空、薄云、厚云和云影四个语义类别。

Result: 在CloudSEN12和L8Biome数据集上的实验表明，MSCloudCAM在分割精度上超越了领先的基线架构，同时保持了具有竞争力的参数效率和计算量（FLOPs）。

Conclusion: MSCloudCAM在云分割方面表现出有效性和实用性，适用于大规模地球观测任务和实际应用。

Abstract: Clouds remain a critical challenge in optical satellite imagery, hindering
reliable analysis for environmental monitoring, land cover mapping, and climate
research. To overcome this, we propose MSCloudCAM, a Cross-Attention with
Multi-Scale Context Network tailored for multispectral and multi-sensor cloud
segmentation. Our framework exploits the spectral richness of Sentinel-2
(CloudSEN12) and Landsat-8 (L8Biome) data to classify four semantic categories:
clear sky, thin cloud, thick cloud, and cloud shadow. MSCloudCAM combines a
Swin Transformer backbone for hierarchical feature extraction with multi-scale
context modules ASPP and PSP for enhanced scale-aware learning. A
Cross-Attention block enables effective multisensor and multispectral feature
fusion, while the integration of an Efficient Channel Attention Block (ECAB)
and a Spatial Attention Module adaptively refine feature representations.
Comprehensive experiments on CloudSEN12 and L8Biome demonstrate that MSCloudCAM
delivers state-of-the-art segmentation accuracy, surpassing leading baseline
architectures while maintaining competitive parameter efficiency and FLOPs.
These results underscore the model's effectiveness and practicality, making it
well-suited for large-scale Earth observation tasks and real-world
applications.

</details>


### [130] [From Detection to Mitigation: Addressing Bias in Deep Learning Models for Chest X-Ray Diagnosis](https://arxiv.org/abs/2510.10822)
*Clemence Mottez,Louisa Fay,Maya Varma,Sophie Ostmeier,Curtis Langlotz*

Main category: cs.CV

TL;DR: 深度学习模型在提高胸部X光诊断准确性方面显示出潜力，但也可能因人口统计学群体间的性能差异而加剧医疗保健差距。本研究提出了一个全面的偏见检测和缓解框架，针对胸部X光诊断中的性别、年龄和种族差异。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在胸部X光诊断中可能存在的性别、年龄和种族偏见问题，并提出一种既能提高预测性能又能减少偏见的框架。

Method: 扩展了CNN-XGBoost管道以支持多标签分类，并研究了不同模型（DenseNet-121和ResNet-50）的性能和公平性。将所提出的轻量级适配器训练方法与传统的对抗性训练、重加权、数据增强和主动学习等偏见缓解技术进行了比较。

Result: 与传统方法相比，CNN-XGBoost管道在提高公平性的同时，保持或提高了整体预测性能。所提出的轻量级适配器训练方法在计算成本更低的情况下，提供了具有竞争力的或更优的偏见减少效果。结合XGBoost再训练和主动学习的方法在CheXpert和MIMIC数据集上实现了最大的偏见减少。

Conclusion: 所提出的框架是一种实用且有效的深度学习公平性部署方法，尤其是在临床放射学领域。

Abstract: Deep learning models have shown promise in improving diagnostic accuracy from
chest X-rays, but they also risk perpetuating healthcare disparities when
performance varies across demographic groups. In this work, we present a
comprehensive bias detection and mitigation framework targeting sex, age, and
race-based disparities when performing diagnostic tasks with chest X-rays. We
extend a recent CNN-XGBoost pipeline to support multi-label classification and
evaluate its performance across four medical conditions. We show that replacing
the final layer of CNN with an eXtreme Gradient Boosting classifier improves
the fairness of the subgroup while maintaining or improving the overall
predictive performance. To validate its generalizability, we apply the method
to different backbones, namely DenseNet-121 and ResNet-50, and achieve
similarly strong performance and fairness outcomes, confirming its
model-agnostic design. We further compare this lightweight adapter training
method with traditional full-model training bias mitigation techniques,
including adversarial training, reweighting, data augmentation, and active
learning, and find that our approach offers competitive or superior bias
reduction at a fraction of the computational cost. Finally, we show that
combining eXtreme Gradient Boosting retraining with active learning yields the
largest reduction in bias across all demographic subgroups, both in and out of
distribution on the CheXpert and MIMIC datasets, establishing a practical and
effective path toward equitable deep learning deployment in clinical radiology.

</details>


### [131] [FastHMR: Accelerating Human Mesh Recovery via Token and Layer Merging with Diffusion Decoding](https://arxiv.org/abs/2510.10868)
*Soroush Mehraban,Andrea Iaboni,Babak Taati*

Main category: cs.CV

TL;DR: Recent transformer-based models for 3D Human Mesh Recovery (HMR) have achieved strong performance but often suffer from high computational cost and complexity due to deep transformer architectures and redundant tokens. This paper introduces HMR-specific merging strategies (ECLM and Mask-ToMe) to reduce computational cost and complexity by merging transformer layers with minimal impact on MPJPE and background tokens that contribute little to the final prediction. A diffusion-based decoder with temporal context and pose priors is proposed to address potential performance drops. Experiments show the method achieves up to 2.3x speed-up with slight performance improvement.


<details>
  <summary>Details</summary>
Motivation: Transformer-based models for 3D Human Mesh Recovery (HMR) are computationally expensive and complex due to deep architectures and redundant tokens. There is a need to reduce this cost and complexity without sacrificing performance.

Method: 1. Error-Constrained Layer Merging (ECLM): Selectively merges transformer layers with minimal impact on Mean Per Joint Position Error (MPJPE). 2. Mask-guided Token Merging (Mask-ToMe): Merges background tokens that contribute little to the final prediction. 3. Diffusion-based Decoder: Incorporates temporal context and pose priors to mitigate performance drops from merging.

Result: The proposed method achieves up to 2.3x speed-up while slightly improving performance over the baseline across multiple benchmarks.

Conclusion: The paper successfully reduces the computational cost and complexity of transformer-based 3D HMR models through novel merging strategies and a diffusion-based decoder, achieving significant speed-up with comparable or improved performance.

Abstract: Recent transformer-based models for 3D Human Mesh Recovery (HMR) have
achieved strong performance but often suffer from high computational cost and
complexity due to deep transformer architectures and redundant tokens. In this
paper, we introduce two HMR-specific merging strategies: Error-Constrained
Layer Merging (ECLM) and Mask-guided Token Merging (Mask-ToMe). ECLM
selectively merges transformer layers that have minimal impact on the Mean Per
Joint Position Error (MPJPE), while Mask-ToMe focuses on merging background
tokens that contribute little to the final prediction. To further address the
potential performance drop caused by merging, we propose a diffusion-based
decoder that incorporates temporal context and leverages pose priors learned
from large-scale motion capture datasets. Experiments across multiple
benchmarks demonstrate that our method achieves up to 2.3x speed-up while
slightly improving performance over the baseline.

</details>


### [132] [rareboost3d: a synthetic lidar dataset with enhanced rare classes](https://arxiv.org/abs/2510.10876)
*Shutong Lin,Zhengkang Xiang,Jianzhong Qi,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: We introduce RareBoost3D, a synthetic dataset with more rare class instances, and a cross-domain alignment method (CSC loss) to improve LiDAR point cloud segmentation.


<details>
  <summary>Details</summary>
Motivation: The problem of long-tail data distribution in real-world point cloud datasets, where rare classes have limited instances, hinders the development of LiDAR-based perception technologies. This limits the effectiveness of models trained on these datasets, particularly for applications like autonomous driving.

Method: 1. Created RareBoost3D, a synthetic point cloud dataset. 2. Proposed a cross-domain semantic alignment method called CSC loss to align feature representations between synthetic and real-world data. 3. Evaluated the approach on LiDAR point cloud segmentation tasks.

Result: Experimental results show that the proposed CSC loss significantly improves the performance of LiDAR point cloud segmentation models when trained with both real-world and the synthetic RareBoost3D data, effectively addressing the long-tail problem by increasing instances of rare classes.

Conclusion: The combination of the RareBoost3D dataset and the CSC loss effectively tackles the long-tail problem in LiDAR point cloud segmentation, leading to enhanced model performance through better alignment of features across synthetic and real-world domains.

Abstract: Real-world point cloud datasets have made significant contributions to the
development of LiDAR-based perception technologies, such as object segmentation
for autonomous driving. However, due to the limited number of instances in some
rare classes, the long-tail problem remains a major challenge in existing
datasets. To address this issue, we introduce a novel, synthetic point cloud
dataset named RareBoost3D, which complements existing real-world datasets by
providing significantly more instances for object classes that are rare in
real-world datasets. To effectively leverage both synthetic and real-world
data, we further propose a cross-domain semantic alignment method named CSC
loss that aligns feature representations of the same class across different
domains. Experimental results demonstrate that this alignment significantly
enhances the performance of LiDAR point cloud segmentation models over
real-world data.

</details>


### [133] [Where on Earth? A Vision-Language Benchmark for Probing Model Geolocation Skills Across Scales](https://arxiv.org/abs/2510.10880)
*Zhaofang Qian,Hardy Chen,Zeyu Wang,Li Zhang,Zijun Wang,Xiaoke Huang,Hui Liu,Xianfeng Tang,Zeyu Zheng,Haoqin Tu,Cihang Xie,Yuyin Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一个名为EarthWhere的基准测试，用于评估视觉语言模型（VLM）在开放世界条件下的图像地理定位能力。该基准测试包含810张全球分布的图像，涵盖国家级和街道级两个地理定位尺度，并引入了新的评估指标来衡量中间推理过程。通过对13个最先进的VLM进行测试，结果显示Gemini-2.5-Pro表现最佳，但模型普遍存在地域偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在开放世界图像地理定位方面的能力尚未得到全面评估，而此任务在现实生活中具有挑战性和需求。因此，需要一个全面的基准测试来评估和推动VLM在这一领域的发展。

Method: 提出EarthWhere基准测试，包含810张图像，分为WhereCountry（500个国家级多项选择题）和WhereStreet（310个街道级精细识别任务，需要多步推理和可选的网络搜索）。采用最终预测指标（Acc@k和层级路径得分）以及基于人类验证的关键视觉线索和Shapley重估的思维得分来评估中间推理过程。对13个最先进的VLM进行了基准测试。

Result: Gemini-2.5-Pro的平均准确率为56.32%，在所有测试模型中表现最佳。最强的开源模型GLM-4.5V的准确率为34.71%。研究发现，当视觉线索有限时，网络搜索和推理并不一定能提高性能。模型存在地域偏见，在某些地区的得分比其他地区高出42.7%。

Conclusion: EarthWhere基准测试揭示了VLM在图像地理定位方面的潜力和挑战。尽管模型在准确性方面取得了进展，但仍然存在地域偏见等问题，需要进一步研究以实现鲁棒、精细的地理定位并减轻偏见。该基准测试已开源。

Abstract: Vision-language models (VLMs) have advanced rapidly, yet their capacity for
image-grounded geolocation in open-world conditions, a task that is challenging
and of demand in real life, has not been comprehensively evaluated. We present
EarthWhere, a comprehensive benchmark for VLM image geolocation that evaluates
visual recognition, step-by-step reasoning, and evidence use. EarthWhere
comprises 810 globally distributed images across two complementary geolocation
scales: WhereCountry (i.e., 500 multiple-choice question-answering, with
country-level answer and panoramas) and WhereStreet (i.e., 310 fine-grained
street-level identification tasks requiring multi-step reasoning with optional
web search). For evaluation, we adopt the final-prediction metrics: location
accuracies within k km (Acc@k) for coordinates and hierarchical path scores for
textual localization. Beyond this, we propose to explicitly score intermediate
reasoning chains using human-verified key visual clues and a Shapley-reweighted
thinking score that attributes credit to each clue's marginal contribution. We
benchmark 13 state-of-the-art VLMs with web searching tools on our EarthWhere
and report different types of final answer accuracies as well as the calibrated
model thinking scores. Overall, Gemini-2.5-Pro achieves the best average
accuracy at 56.32%, while the strongest open-weight model, GLM-4.5V, reaches
34.71%. We reveal that web search and reasoning do not guarantee improved
performance when visual clues are limited, and models exhibit regional biases,
achieving up to 42.7% higher scores in certain areas than others. These
findings highlight not only the promise but also the persistent challenges of
models to mitigate bias and achieve robust, fine-grained localization. We
open-source our benchmark at https://github.com/UCSC-VLAA/EarthWhere.

</details>


### [134] [Topological Alignment of Shared Vision-Language Embedding Space](https://arxiv.org/abs/2510.10889)
*Junwon You,Dasol Kang,Jae-Hun Jung*

Main category: cs.CV

TL;DR: ToMCLIP通过拓扑对齐增强了多语言视觉-语言模型，提高了其零样本能力和跨语言检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多语言对比视觉-语言模型（VLMs）在跨模态对齐上存在英语偏见，且多语言扩展忽视了共享嵌入空间的全局几何结构。

Method: ToMCLIP是一个拓扑感知框架，利用持久性同调定义拓扑对齐损失，并通过图稀疏化策略近似持久性图，以保持嵌入空间的拓扑结构。

Result: ToMCLIP增强了多语言表示的结构相干性，在CIFAR-100上提高了零样本准确率，并在xFlickr&CO上展现了更强的多语言检索性能。

Conclusion: ToMCLIP提供了一种将拓扑对齐纳入表示学习的通用方法，能够提升多语言VLMs的性能。

Abstract: Contrastive Vision-Language Models (VLMs) have demonstrated strong zero-shot
capabilities. However, their cross-modal alignment remains biased toward
English due to limited multilingual multimodal data. Recent multilingual
extensions have alleviated this gap but enforce instance-level alignment while
neglecting the global geometry of the shared embedding space. We address this
problem by introducing ToMCLIP (Topological Alignment for Multilingual CLIP), a
topology-aware framework aligning embedding spaces with topology-preserving
constraints. The proposed method applies persistent homology to define a
topological alignment loss and approximates persistence diagram with
theoretical error bounds using graph sparsification strategy. This work
validates the proposed approach, showing enhanced structural coherence of
multilingual representations, higher zero-shot accuracy on the CIFAR-100, and
stronger multilingual retrieval performance on the xFlickr&CO. Beyond VLMs, the
proposed approach provides a general method for incorporating topological
alignment into representation learning.

</details>


### [135] [SceneTextStylizer: A Training-Free Scene Text Style Transfer Framework with Diffusion Model](https://arxiv.org/abs/2510.10910)
*Honghui Yuan,Keiji Yanai*

Main category: cs.CV

TL;DR: 该研究提出了SceneTextStylizer，一个用于场景文本的无训练、基于扩散的模型框架，实现了灵活、高保真的风格迁移，能够进行提示引导的文本区域风格转换，同时保持文本可读性和风格一致性。


<details>
  <summary>Details</summary>
Motivation: 现有场景文本编辑方法在风格迁移方面存在局限性，难以实现灵活、局部的风格编辑，并且通常仅限于内容替换或简单风格，缺乏自由风格迁移能力。

Method: 提出了一种名为SceneTextStylizer的框架，该框架利用扩散模型反演和自注意力机制设计了一个特征注入模块，以有效地迁移风格特征。此外，通过在每个去噪步骤中应用基于距离变化的掩码，引入了一个区域控制机制，实现了精确的空间控制。同时，还集成了一个基于傅里叶变换的风格增强模块，以增强风格的丰富性。

Result: 实验结果表明，该方法在场景文本风格转换方面表现优越，在视觉保真度和文本保留方面均优于现有最先进的方法。

Conclusion: SceneTextStylizer框架成功实现了灵活、高保真的场景文本风格迁移，解决了现有方法的局限性，并在实验中取得了优于现有方法的性能。

Abstract: With the rapid development of diffusion models, style transfer has made
remarkable progress. However, flexible and localized style editing for scene
text remains an unsolved challenge. Although existing scene text editing
methods have achieved text region editing, they are typically limited to
content replacement and simple styles, which lack the ability of free-style
transfer. In this paper, we introduce SceneTextStylizer, a novel training-free
diffusion-based framework for flexible and high-fidelity style transfer of text
in scene images. Unlike prior approaches that either perform global style
transfer or focus solely on textual content modification, our method enables
prompt-guided style transformation specifically for text regions, while
preserving both text readability and stylistic consistency. To achieve this, we
design a feature injection module that leverages diffusion model inversion and
self-attention to transfer style features effectively. Additionally, a region
control mechanism is introduced by applying a distance-based changing mask at
each denoising step, enabling precise spatial control. To further enhance
visual quality, we incorporate a style enhancement module based on the Fourier
transform to reinforce stylistic richness. Extensive experiments demonstrate
that our method achieves superior performance in scene text style
transformation, outperforming existing state-of-the-art methods in both visual
fidelity and text preservation.

</details>


### [136] [DreamMakeup: Face Makeup Customization using Latent Diffusion Models](https://arxiv.org/abs/2510.10918)
*Geon Yeong Park,Inhwa Han,Serin Yang,Yeobin Hong,Seongmin Jeong,Heechan Jeon,Myeongjin Goh,Sung Won Yi,Jin Nam,Jong Chul Ye*

Main category: cs.CV

TL;DR: DreamMakeup是一款新颖的、无需训练的基于扩散模型的虚拟美妆定制方法，它解决了现有GAN模型在训练稳定性和定制化方面的挑战，实现了更强的可控性、更精准的图像编辑、更好的色彩匹配和身份保留能力，并且计算成本较低。


<details>
  <summary>Details</summary>
Motivation: 研究虚拟美妆技术，解决现有基于GANs的技术在训练稳定性、定制化能力方面的挑战。

Method: 提出了一种新颖的、无需训练的、基于扩散模型的美妆定制方法DreamMakeup，采用提前停止的DDIM反演来保留面部结构和身份，并通过参考图像、RGB颜色、文本描述等多种条件输入实现定制化。

Result: DreamMakeup在定制化、色彩匹配、身份保留和文本描述兼容性方面优于现有的基于GAN和扩散模型的方法，并且计算成本低。

Conclusion: DreamMakeup是一种有效且高效的虚拟美妆定制方法，能够实现高度定制化和逼真的美妆效果，并且保留用户的身份信息。

Abstract: The exponential growth of the global makeup market has paralleled
advancements in virtual makeup simulation technology. Despite the progress led
by GANs, their application still encounters significant challenges, including
training instability and limited customization capabilities. Addressing these
challenges, we introduce DreamMakup - a novel training-free Diffusion model
based Makeup Customization method, leveraging the inherent advantages of
diffusion models for superior controllability and precise real-image editing.
DreamMakeup employs early-stopped DDIM inversion to preserve the facial
structure and identity while enabling extensive customization through various
conditioning inputs such as reference images, specific RGB colors, and textual
descriptions. Our model demonstrates notable improvements over existing
GAN-based and recent diffusion-based frameworks - improved customization,
color-matching capabilities, identity preservation and compatibility with
textual descriptions or LLMs with affordable computational costs.

</details>


### [137] [FG-CLIP 2: A Bilingual Fine-grained Vision-Language Alignment Model](https://arxiv.org/abs/2510.10921)
*Chunyu Xie,Bin Wang,Fanjing Kong,Jincheng Li,Dawei Liang,Ji Ao,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: FG-CLIP 2是一个双语视觉-语言模型，旨在提高英语和中文的细粒度对齐能力，通过区域-文本匹配、长标题建模和TIC损失等方法，在29个数据集的8个任务上取得了最先进的成果，并发布了新的中文多模态理解基准。


<details>
  <summary>Details</summary>
Motivation: 当前的细粒度视觉-语言理解模型在对齐视觉内容和语言描述方面能力有限，尤其是在非英语场景下，并且对双语支持不足。CLIP等模型虽然在全局对齐方面表现良好，但在捕捉物体属性、空间关系和语言表达等细节方面存在不足。

Method: 提出FG-CLIP 2，一个双语视觉-语言模型，利用丰富的细粒度监督（如图-文匹配和长标题建模）以及多种判别性目标。引入文本内模态对比（TIC）损失以更好地区分语义相似的标题。模型在混合的大规模英语和中文数据上进行训练。

Result: FG-CLIP 2在29个数据集的8个任务上取得了最先进的成果，在英语和中文上均表现出强大的双语性能，超越了现有方法。

Conclusion: FG-CLIP 2在双语细粒度对齐方面取得了显著进展，并在新的中文多模态理解基准上进行了严格评估，证明了其优越性。模型、代码和基准的发布将促进未来在双语细粒度对齐方面的研究。

Abstract: Fine-grained vision-language understanding requires precise alignment between
visual content and linguistic descriptions, a capability that remains limited
in current models, particularly in non-English settings. While models like CLIP
perform well on global alignment, they often struggle to capture fine-grained
details in object attributes, spatial relations, and linguistic expressions,
with limited support for bilingual comprehension. To address these challenges,
we introduce FG-CLIP 2, a bilingual vision-language model designed to advance
fine-grained alignment for both English and Chinese. Our approach leverages
rich fine-grained supervision, including region-text matching and long-caption
modeling, alongside multiple discriminative objectives. We further introduce
the Textual Intra-modal Contrastive (TIC) loss to better distinguish
semantically similar captions. Trained on a carefully curated mixture of
large-scale English and Chinese data, FG-CLIP 2 achieves powerful bilingual
performance. To enable rigorous evaluation, we present a new benchmark for
Chinese multimodal understanding, featuring long-caption retrieval and bounding
box classification. Extensive experiments on 29 datasets across 8 tasks show
that FG-CLIP 2 outperforms existing methods, achieving state-of-the-art results
in both languages. We release the model, code, and benchmark to facilitate
future research on bilingual fine-grained alignment.

</details>


### [138] [Towards Distribution-Shift Uncertainty Estimation for Inverse Problems with Generative Priors](https://arxiv.org/abs/2510.10947)
*Namhoon Kim,Sara Fridovich-Keil*

Main category: cs.CV

TL;DR: 生成模型可作为数据驱动先验来解决逆问题，但可能在处理分布外（OOD）图像时产生幻觉。本文提出了一种无需校准数据集、无需重训即可检测分布偏移的实例级不确定性指标，该指标基于重建图像对随机测量变化的稳定性。实验表明，OOD数字的重建误差更大，不确定性指标值也更高，验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的不确定性量化方法在生成模型用于逆问题（如从欠采样测量中重建医学图像）时存在局限性：需要校准数据集、提供启发式估计或仅量化模型容量/测量不确定性，而未能有效捕捉分布偏移（distribution shift）。

Method: 提出一种实例级、无需校准的不确定性指标，该指标对分布偏移敏感，不需要训练数据的分布信息，也无需重新训练。该指标基于核心假设：分布内（in-distribution）图像的重建在随机测量变化下保持稳定，而分布外（OOD）图像的重建则表现出更大的不稳定性。利用这种稳定性作为检测分布偏移的代理。

Result: 通过在MNIST数字断层重建任务上进行演示，其中一个仅在数字“0”上训练的学习邻近网络被评估于所有十个数字。结果显示，OOD数字的重建表现出更高的变异性，并相应地具有更高的重建误差，这验证了所提出指标的有效性。

Conclusion: 该方法提供了一种在部署生成模型先验时，结合轻量级防护措施的策略。它能够在处理分布内情况时实现积极的测量缩减，并在应用到分布外情况时自动发出警告。

Abstract: Generative models have shown strong potential as data-driven priors for
solving inverse problems such as reconstructing medical images from
undersampled measurements. While these priors improve reconstruction quality
with fewer measurements, they risk hallucinating features when test images lie
outside the training distribution. Existing uncertainty quantification methods
in this setting (i) require an in-distribution calibration dataset, which may
not be available, (ii) provide heuristic rather than statistical estimates, or
(iii) quantify uncertainty from model capacity or limited measurements rather
than distribution shift. We propose an instance-level, calibration-free
uncertainty indicator that is sensitive to distribution shift, requires no
knowledge of the training distribution, and incurs no retraining cost. Our key
hypothesis is that reconstructions of in-distribution images remain stable
under random measurement variations, while reconstructions of
out-of-distribution (OOD) images exhibit greater instability. We use this
stability as a proxy for detecting distribution shift. Our proposed OOD
indicator is efficiently computable for any computational imaging inverse
problem; we demonstrate it on tomographic reconstruction of MNIST digits, where
a learned proximal network trained only on digit "0" is evaluated on all ten
digits. Reconstructions of OOD digits show higher variability and
correspondingly higher reconstruction error, validating this indicator. These
results suggest a deployment strategy that pairs generative priors with
lightweight guardrails, enabling aggressive measurement reduction for
in-distribution cases while automatically warning when priors are applied out
of distribution.

</details>


### [139] [IUT-Plug: A Plug-in tool for Interleaved Image-Text Generation](https://arxiv.org/abs/2510.10969)
*Zeteng Lin,Xingxing Li,Wen You,Xiaoyang Li,Zehan Lu,Yujun Cai,Jing Tang*

Main category: cs.CV

TL;DR: IUT-Plug通过引入图像理解树（IUT）来解决现有视觉语言模型（VLM）在多模态图像-文本生成中存在的逻辑、对象身份和风格保持问题，从而提高复杂场景下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLM在多模态图像-文本生成中存在逻辑、对象身份和风格保持问题，限制了其泛化能力。

Method: 提出IUT-Plug模块，通过图像理解树（IUT）进行显式结构化推理，分为两个阶段：1. 动态IUT-Plug提取模块解析视觉场景为分层符号结构；2. 协调叙事流和图像合成机制确保跨模态一致性。构建了包含3000个真实人类生成问答对的新基准和动态评估协议。

Result: IUT-Plug在现有基准上提高了准确性，并有效缓解了不同多模态问答场景下的三种关键上下文漂移。

Conclusion: IUT-Plug通过引入基于图像理解树的显式结构化推理，成功解决了VLM在多模态生成中的上下文漂移问题，提高了模型的准确性和泛化能力。

Abstract: Existing vision language models (VLMs), including GPT-4 and DALL-E, often
struggle to preserve logic, object identity, and style in multimodal image-text
generation. This limitation significantly hinders the generalization capability
of VLMs in complex image-text input-output scenarios. To address this issue, we
propose IUT-Plug, a module grounded in an Image Understanding Tree (IUT), which
enhances existing interleaved VLMs through explicit structured reasoning,
thereby mitigating context drift in logic, entity identity, and style. The
proposed framework operates in two stages. (1) A dynamic IUT-Plug extraction
module parses visual scenes into hierarchical symbolic structures. (2) A
coordinated narrative-flow and image synthesis mechanism ensures cross-modal
consistency. To evaluate our approach, we construct a novel benchmark based on
3,000 real human-generated question-answer pairs over fine-tuned large models,
introducing a dynamic evaluation protocol for quantifying context drift in
interleaved VLMs. Experimental results demonstrate that IUT-Plug not only
improves accuracy on established benchmarks but also effectively alleviates the
three critical forms of context drift across diverse multimodal question
answering (QA) scenarios.

</details>


### [140] [Chart-RVR: Reinforcement Learning with Verifiable Rewards for Explainable Chart Reasoning](https://arxiv.org/abs/2510.10973)
*Sanchit Sinha,Oana Frunza,Kashif Rasul,Yuriy Nevmyvaka,Aidong Zhang*

Main category: cs.CV

TL;DR: Chart-RVR框架通过结合GRPO和可验证奖励，提升了大型视觉语言模型（LVLMs）在图表推理任务上的鲁棒性和可解释性，特别是在处理分布外（OOD）数据时表现更优，并生成更可靠的推理过程。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLMs在图表推理任务上虽达到SOTA，但在分布外（OOD）数据上表现不佳，且生成推理过程（CoT）时可解释性受限。

Method: 提出Chart-RVR框架，结合了Group Relative Policy Optimization (GRPO)和三种可自动验证的奖励（图表类型分类、表格重建、过程一致性），对LVLMs进行微调。

Result: Chart-RVR在分布内和分布外数据集上均优于标准监督微调（SFT），缩小了OOD性能差距，提高了推理过程的保真度。Chart-RVR-3B系列在六个基准测试中达到SOTA，超越了同等规模的现有模型。

Conclusion: Chart-RVR通过可验证奖励和GRPO的结合，能够训练出可靠、可解释的图表推理模型，生成更具可解释性的CoT推理过程，增强了模型的信任度和可靠性。

Abstract: The capabilities of Large Vision-Language Models (LVLMs) have reached
state-of-the-art on many visual reasoning tasks, including chart reasoning, yet
they still falter on out-of-distribution (OOD) data, and degrade further when
asked to produce their chain-of-thought (CoT) rationales, limiting
explainability. We present Chart-RVR, a general framework that fine-tunes LVLMs
to be more robust and explainable for chart reasoning by coupling Group
Relative Policy Optimization (GRPO) with automatically verifiable rewards. Our
framework comprises of three rewards that maximize: (i) correct chart-type
classification, (ii) faithful chart table reconstruction, and (iii) process
conformity. Applied to 3-billion-parameter LVLMs, Chart-RVR consistently
outperforms standard supervised fine-tuning (SFT) on both in-distribution and
out-of-distribution datasets, closing the OOD performance gap while improving
rationale fidelity. The resulting models, the Chart-RVR-3B series, achieve
state-of-the-art results on six chart-reasoning benchmarks spanning in-domain
and OOD settings, surpassing all existing models of comparable size. Beyond
accuracy, Chart-RVR yields more interpretable CoT rationales, strengthening
trust and reliability - showcasing the power of verifiable rewards with GRPO
for training reliable, interpretable chart-reasoning models.

</details>


### [141] [Mixup Helps Understanding Multimodal Video Better](https://arxiv.org/abs/2510.10986)
*Xiaoyu Ma,Ding Ding,Hao Chen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为多模态混淆（MM）的方法，通过在聚合的多模态特征层面应用混淆策略来缓解模型过拟合问题。在此基础上，进一步提出平衡多模态混淆（B-MM），通过动态调整每种模态的混合比例来解决模态不平衡问题。实验证明了这些方法在提高泛化能力和多模态鲁棒性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 多模态模型容易过拟合，导致某些模态（较强模态）的学习占据主导地位，从而抑制了其他模态（较弱模态）的贡献。

Method: 提出多模态混淆（MM），在聚合的多模态特征层面应用混淆策略，生成虚拟的特征-标签对，以缓解过拟合。在此基础上，提出平衡多模态混淆（B-MM），根据各模态在学习目标中的相对贡献动态调整混合比例。

Result: 在多个数据集上的广泛实验表明，所提出的MM和B-MM方法能够有效提高模型的泛化能力和多模态鲁棒性。

Conclusion: MM和B-MM是有效解决多模态学习中过拟合和模态不平衡问题的策略，能够提升模型的泛化性能和鲁棒性。

Abstract: Multimodal video understanding plays a crucial role in tasks such as action
recognition and emotion classification by combining information from different
modalities. However, multimodal models are prone to overfitting strong
modalities, which can dominate learning and suppress the contributions of
weaker ones. To address this challenge, we first propose Multimodal Mixup (MM),
which applies the Mixup strategy at the aggregated multimodal feature level to
mitigate overfitting by generating virtual feature-label pairs. While MM
effectively improves generalization, it treats all modalities uniformly and
does not account for modality imbalance during training. Building on MM, we
further introduce Balanced Multimodal Mixup (B-MM), which dynamically adjusts
the mixing ratios for each modality based on their relative contributions to
the learning objective. Extensive experiments on several datasets demonstrate
the effectiveness of our methods in improving generalization and multimodal
robustness.

</details>


### [142] [A Survey on Agentic Multimodal Large Language Models](https://arxiv.org/abs/2510.10991)
*Huanjin Yao,Ruifei Zhang,Jiaxing Huang,Jingyi Zhang,Yibo Wang,Bo Fang,Ruolin Zhu,Yongcheng Jing,Shunyu Liu,Guanbin Li,Dacheng Tao*

Main category: cs.CV

TL;DR: 本文对Agentic MLLMs进行了全面的调查，重点介绍了其核心能力：内部智能、外部工具调用和环境交互。此外，本文还汇编了开源资源，并讨论了下游应用和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 鉴于对Agentic AI及其迈向AGI的潜力的日益增长的兴趣，本文旨在对Agentic MLLM进行全面的调查。

Method: 本文建立了一个概念框架，将Agentic MLLM沿着三个基本维度进行组织：内部智能功能、外部工具调用和环境交互。此外，本文还汇编了用于开发Agentic MLLM的开源训练框架、训练和评估数据集，并回顾了其下游应用。

Result: 本文对Agentic MLLM进行了全面的调查，重点介绍了其核心能力：内部智能、外部工具调用和环境交互。此外，本文还汇编了开源资源，并讨论了下游应用和未来研究方向。

Conclusion: 本文对Agentic MLLM进行了全面的调查，重点介绍了其核心能力：内部智能、外部工具调用和环境交互。此外，本文还汇编了开源资源，并讨论了下游应用和未来研究方向。

Abstract: With the recent emergence of revolutionary autonomous agentic systems,
research community is witnessing a significant shift from traditional static,
passive, and domain-specific AI agents toward more dynamic, proactive, and
generalizable agentic AI. Motivated by the growing interest in agentic AI and
its potential trajectory toward AGI, we present a comprehensive survey on
Agentic Multimodal Large Language Models (Agentic MLLMs). In this survey, we
explore the emerging paradigm of agentic MLLMs, delineating their conceptual
foundations and distinguishing characteristics from conventional MLLM-based
agents. We establish a conceptual framework that organizes agentic MLLMs along
three fundamental dimensions: (i) Agentic internal intelligence functions as
the system's commander, enabling accurate long-horizon planning through
reasoning, reflection, and memory; (ii) Agentic external tool invocation,
whereby models proactively use various external tools to extend their
problem-solving capabilities beyond their intrinsic knowledge; and (iii)
Agentic environment interaction further situates models within virtual or
physical environments, allowing them to take actions, adapt strategies, and
sustain goal-directed behavior in dynamic real-world scenarios. To further
accelerate research in this area for the community, we compile open-source
training frameworks, training and evaluation datasets for developing agentic
MLLMs. Finally, we review the downstream applications of agentic MLLMs and
outline future research directions for this rapidly evolving field. To
continuously track developments in this rapidly evolving field, we will also
actively update a public repository at
https://github.com/HJYao00/Awesome-Agentic-MLLMs.

</details>


### [143] [Perspective-aware 3D Gaussian Inpainting with Multi-view Consistency](https://arxiv.org/abs/2510.10993)
*Yuxin Cheng,Binxiao Huang,Taiqiang Wu,Wenyong Zhou,Chenchen Ding,Zhengwu Liu,Graziano Chesi,Ngai Wong*

Main category: cs.CV

TL;DR: PAInpainter利用透视感知的内容传播和多视图一致性验证来改进3D高斯绘制，解决了现有方法的局限性，并在SPIn-NeRF和NeRFiller数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 多视图一致性是高质量3D高斯绘制的关键要求，而现有方法在此方面面临挑战。

Method: PAInpainter通过传播绘制的图像作为先验信息，并跨相邻视图验证一致性，利用透视感知的内容传播和多视图一致性验证，迭代地改进绘制和优化3D高斯表示。

Result: PAInpainter在SPIn-NeRF和NeRFiller数据集上分别取得了26.03 dB和29.51 dB的PSNR分数，证明了其在3D绘制质量、全局一致性和纹理保真度方面的优越性。

Conclusion: PAInpainter通过解决多视图一致性问题，显著提高了3D高斯绘制的质量，在各种应用中具有潜力。

Abstract: 3D Gaussian inpainting, a critical technique for numerous applications in
virtual reality and multimedia, has made significant progress with pretrained
diffusion models. However, ensuring multi-view consistency, an essential
requirement for high-quality inpainting, remains a key challenge. In this work,
we present PAInpainter, a novel approach designed to advance 3D Gaussian
inpainting by leveraging perspective-aware content propagation and consistency
verification across multi-view inpainted images. Our method iteratively refines
inpainting and optimizes the 3D Gaussian representation with multiple views
adaptively sampled from a perspective graph. By propagating inpainted images as
prior information and verifying consistency across neighboring views,
PAInpainter substantially enhances global consistency and texture fidelity in
restored 3D scenes. Extensive experiments demonstrate the superiority of
PAInpainter over existing methods. Our approach achieves superior 3D inpainting
quality, with PSNR scores of 26.03 dB and 29.51 dB on the SPIn-NeRF and
NeRFiller datasets, respectively, highlighting its effectiveness and
generalization capability.

</details>


### [144] [ContextGen: Contextual Layout Anchoring for Identity-Consistent Multi-Instance Generation](https://arxiv.org/abs/2510.11000)
*Ruihang Xu,Dewei Zhou,Fan Ma,Yi Yang*

Main category: cs.CV

TL;DR: ContextGen是一个创新的扩散Transformer框架，用于解决多实例图像生成中的布局控制和身份一致性问题，并引入了新的IMIG-100K数据集。


<details>
  <summary>Details</summary>
Motivation: 现代扩散模型在多实例图像生成（MIG）中面临精确控制对象布局和保持多个不同主体身份的挑战。

Method: 提出ContextGen框架，包含上下文布局锚定（CLA）机制以固定对象位置，以及身份一致性注意力（ICA）机制以保持实例身份。同时，发布了首个具有详细布局和身份注释的大规模数据集IMIG-100K。

Result: ContextGen在控制精度、身份保真度和整体视觉质量方面优于现有方法，达到了新的最先进水平。

Conclusion: ContextGen及其引入的数据集IMIG-100K显著推动了多实例图像生成领域的发展。

Abstract: Multi-instance image generation (MIG) remains a significant challenge for
modern diffusion models due to key limitations in achieving precise control
over object layout and preserving the identity of multiple distinct subjects.
To address these limitations, we introduce ContextGen, a novel Diffusion
Transformer framework for multi-instance generation that is guided by both
layout and reference images. Our approach integrates two key technical
contributions: a Contextual Layout Anchoring (CLA) mechanism that incorporates
the composite layout image into the generation context to robustly anchor the
objects in their desired positions, and Identity Consistency Attention (ICA),
an innovative attention mechanism that leverages contextual reference images to
ensure the identity consistency of multiple instances. Recognizing the lack of
large-scale, hierarchically-structured datasets for this task, we introduce
IMIG-100K, the first dataset with detailed layout and identity annotations.
Extensive experiments demonstrate that ContextGen sets a new state-of-the-art,
outperforming existing methods in control precision, identity fidelity, and
overall visual quality.

</details>


### [145] [Frequency Domain Unlocks New Perspectives for Abdominal Medical Image Segmentation](https://arxiv.org/abs/2510.11005)
*Kai Han,Siqi Ma,Chengxuan Qian,Jun Chen,Chongwen Lyu,Yuqing Song,Zhe Liu*

Main category: cs.CV

TL;DR: FASS框架通过增强前景感知、提取高频特征和约束边界，提高了医学图像中低对比度肿瘤分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分割中，尤其是在低对比度背景下，区分肿瘤与正常组织面临挑战，现有模型难以聚焦前景区域。

Method: 提出FASS框架，包括前景感知模块（增强背景与总体空间区分度）、基于小波变换的特征层频率增强模块（提取高频特征以增强边界识别）和边缘约束模块（保持边界几何连续性）。

Result: 在多个医学数据集上的广泛实验表明，FASS框架在各项指标上均表现优越，尤其在复杂条件下的鲁棒性和精细结构识别方面效果显著。

Conclusion: FASS框架能够有效提升低对比度医学图像的分割效果，为更复杂多样的医学成像应用场景提供了可能性。

Abstract: Accurate segmentation of tumors and adjacent normal tissues in medical images
is essential for surgical planning and tumor staging. Although foundation
models generally perform well in segmentation tasks, they often struggle to
focus on foreground areas in complex, low-contrast backgrounds, where some
malignant tumors closely resemble normal organs, complicating contextual
differentiation. To address these challenges, we propose the Foreground-Aware
Spectrum Segmentation (FASS) framework. First, we introduce a foreground-aware
module to amplify the distinction between background and the entire volume
space, allowing the model to concentrate more effectively on target areas.
Next, a feature-level frequency enhancement module, based on wavelet transform,
extracts discriminative high-frequency features to enhance boundary recognition
and detail perception. Eventually, we introduce an edge constraint module to
preserve geometric continuity in segmentation boundaries. Extensive experiments
on multiple medical datasets demonstrate superior performance across all
metrics, validating the effectiveness of our framework, particularly in
robustness under complex conditions and fine structure recognition. Our
framework significantly enhances segmentation of low-contrast images, paving
the way for applications in more diverse and complex medical imaging scenarios.

</details>


### [146] [COCO-Tree: Compositional Hierarchical Concept Trees for Enhanced Reasoning in Vision Language Models](https://arxiv.org/abs/2510.11012)
*Sanchit Sinha,Guangzhi Xiong,Aidong Zhang*

Main category: cs.CV

TL;DR: COCO-Tree通过结合VLM输出和LLM学习的概念树来增强VLM的语言推理能力，在四个基准测试中显著提高了组合泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLM）在组合推理方面存在不足，尤其是在处理涉及多个对象、属性和关系交互的任务时。虽然一些方法试图通过改进提示或思维链来解决这个问题，但它们可能资源消耗大或缺乏可解释性。因此，需要一种新的方法来增强VLM的语言推理能力，同时提供可解释的推理过程。

Method: 提出了一种名为'COCO-Tree'的新方法，该方法利用从大型语言模型（LLM）学习到的、经过精心设计的新型符号概念树来增强VLM的输出。COCO-Tree的推理过程受到beam search的启发，旨在提高VLM的组合推理能力并提供其预测的依据。

Result: 在Winoground、EqBench、ColorSwap和SugarCrepe四个组合推理基准测试中，在七种不同大小的开源VLM上进行了实验。结果表明，COCO-Tree在组合泛化方面比基线方法提高了5-10%。

Conclusion: COCO-Tree是一种有效的新方法，可以显著提高VLM的组合推理能力，同时提供可解释的推理过程。通过将VLM输出与LLM学习的概念树相结合，COCO-Tree克服了现有方法的局限性，并在多个基准测试中取得了优于基线方法的性能。

Abstract: Compositional reasoning remains a persistent weakness of modern vision
language models (VLMs): they often falter when a task hinges on understanding
how multiple objects, attributes, and relations interact within an image.
Multiple research works have attempted to improve compositionality performance
by creative tricks such as improving prompt structure, chain of thought
reasoning, etc. A more recent line of work attempts to impart additional
reasoning in VLMs using well-trained Large Language Models (LLMs), which are
far superior in linguistic understanding than VLMs to compensate for the
limited linguistic prowess of VLMs. However, these approaches are either
resource-intensive or do not provide an interpretable reasoning process. In
this paper, we present 'COCO-Tree' - a novel approach that augments VLM outputs
with carefully designed neurosymbolic concept trees learned from LLMs to
improve VLM's linguistic reasoning. COCO-Tree's beam search-inspired reasoning
process boosts compositionality performance and provides a rationale behind VLM
predictions. Empirical results on four compositionality benchmarks, Winoground,
EqBench, ColorSwap, and SugarCrepe, in seven different open-source VLMs with
varying sizes, demonstrate that COCO-Tree significantly improves compositional
generalization by 5-10% over baselines.

</details>


### [147] [High-Resolution Spatiotemporal Modeling with Global-Local State Space Models for Video-Based Human Pose Estimation](https://arxiv.org/abs/2510.11017)
*Runyang Feng,Hyung Jin Chang,Tze Ho Elden Tse,Boeun Kim,Yi Chang,Yixing Gao*

Main category: cs.CV

TL;DR: 本篇论文提出了一种新颖的视频人体姿态估计框架，通过扩展状态空间模型（Mamba），分别学习全局和局部的时空表示，以解决现有方法在平衡全局动态和局部细节上的不足，并克服了高分辨率序列处理的二次复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频人体姿态估计方法在统一的时空建模结构（卷积或注意力）中难以平衡全局动态和局部细节，且在处理高分辨率序列时存在二次复杂度问题。状态空间模型（Mamba）在处理长距离上下文方面有潜力，但仅限于一维序列数据。

Method: 提出了一种新颖的框架，从两个方面扩展了Mamba：1. 全局时空Mamba：通过6D选择性时空扫描和空间/时间调制扫描合并，有效提取高分辨率序列的全局表示。2. 局部精炼Mamba：基于窗口的时空扫描，增强局部关键点运动的高频细节。

Result: 在四个基准数据集上的实验表明，该模型优于现有最先进的视频人体姿态估计方法，并实现了更好的计算效率。

Conclusion: 该框架通过分别建模全局和局部时空表示，有效解决了视频人体姿态估计中的挑战，并在性能和计算效率上取得了优越的成果。

Abstract: Modeling high-resolution spatiotemporal representations, including both
global dynamic contexts (e.g., holistic human motion tendencies) and local
motion details (e.g., high-frequency changes of keypoints), is essential for
video-based human pose estimation (VHPE). Current state-of-the-art methods
typically unify spatiotemporal learning within a single type of modeling
structure (convolution or attention-based blocks), which inherently have
difficulties in balancing global and local dynamic modeling and may bias the
network to one of them, leading to suboptimal performance. Moreover, existing
VHPE models suffer from quadratic complexity when capturing global
dependencies, limiting their applicability especially for high-resolution
sequences. Recently, the state space models (known as Mamba) have demonstrated
significant potential in modeling long-range contexts with linear complexity;
however, they are restricted to 1D sequential data. In this paper, we present a
novel framework that extends Mamba from two aspects to separately learn global
and local high-resolution spatiotemporal representations for VHPE.
Specifically, we first propose a Global Spatiotemporal Mamba, which performs 6D
selective space-time scan and spatial- and temporal-modulated scan merging to
efficiently extract global representations from high-resolution sequences. We
further introduce a windowed space-time scan-based Local Refinement Mamba to
enhance the high-frequency details of localized keypoint motions. Extensive
experiments on four benchmark datasets demonstrate that the proposed model
outperforms state-of-the-art VHPE approaches while achieving better
computational trade-offs.

</details>


### [148] [GeoVLMath: Enhancing Geometry Reasoning in Vision-Language Models via Cross-Modal Reward for Auxiliary Line Creation](https://arxiv.org/abs/2510.11020)
*Shasha Guo,Liang Pang,Xi Wang,Yanling Wang,Huawei Shen,Jing Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种名为GeoVLMath的视觉语言模型，专门用于解决固体几何中的辅助线推理问题。该模型通过生成辅助线构造的文本描述，并利用跨模态奖励进行训练，以实现文本描述与空间结构之间的对齐，从而克服了当前模型在精确绘制辅助线方面的困难。研究还构建了一个名为AuxSolidMath的数据集，包含3018个真实考试题目，并验证了GeoVLMath在相关基准测试中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的大型视觉语言模型（LVLM）在处理需要绘制辅助线的复杂几何问题时存在挑战，因为图像编辑模型难以精确渲染辅助线。本研究旨在解决这个问题，使LVLM能够更好地处理这类几何推理任务。

Method: 提出了一种强化学习框架，通过生成辅助线构造的文本描述来解决几何问题。该框架的核心是一个跨模态奖励，用于评估生成的辅助线描述与真实辅助线图的匹配程度。在此基础上，开发了GeoVLMath模型，并通过一个基于GRPO的强化学习阶段来优化文本描述与空间结构的对齐。同时，构建了一个包含3018个真实考试几何题目的AuxSolidMath数据集来支持模型训练。

Result: 在3B和7B参数规模下，GeoVLMath在辅助线推理基准测试中取得了与强大的开源和专有LVLM相当甚至更优的性能。

Conclusion: GeoVLMath通过生成文本描述和利用强化学习来解决固体几何中的辅助线推理问题，并在相关数据集上展示了其有效性和优越性。

Abstract: Auxiliary lines are essential for solving complex geometric problems but
remain challenging for large vision-language models (LVLMs). Rather than
editing diagrams to draw auxiliary lines, which current image editing models
struggle to render with geometric precision, we generate textual descriptions
of auxiliary-line constructions to better align with the representational
strengths of LVLMs. To bridge the gap between textual descriptions and spatial
structure, we propose a reinforcement learning framework that enhances
diagram-text alignment. At the core of our approach is a cross-modal reward
that evaluates how well the generated auxiliary-line description for an
original diagram matches a ground-truth auxiliary-line diagram. Built on this
reward, we present GeoVLMath, an open-source LVLM tailored to auxiliary-line
reasoning in solid geometry. This fine-grained signal drives a GRPO-based RL
stage, yielding precise diagram-text alignment. To support training, we develop
a scalable data creation pipeline and construct AuxSolidMath, a dataset of
3,018 real-exam geometry problems with paired diagrams and aligned textual
fields. At the 3B and 7B scales, GeoVLMath achieves competitive and often
superior performance compared with strong open-source and proprietary LVLMs on
auxiliary-line reasoning benchmarks.

</details>


### [149] [GIR-Bench: Versatile Benchmark for Generating Images with Reasoning](https://arxiv.org/abs/2510.11026)
*Hongxiang Li,Yaowei Li,Bin Lin,Yuwei Niu,Yuhang Yang,Xiaoshuang Huang,Jiayin Cai,Xiaolong Jiang,Yao Hu,Long Chen*

Main category: cs.CV

TL;DR: GIR-Bench是一个用于评估统一多模态模型理解与生成一致性、文本到图像生成以及编辑能力的新基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基准缺乏系统性评估统一多模态模型在理解与生成之间的一致性、以及在复杂视觉任务上的泛化能力。

Method: 提出GIR-Bench，包含三个子基准：GIR-Bench-UGC（评估理解-生成一致性）、GIR-Bench-T2I（评估推理驱动的文本到图像生成）和GIR-Bench-Edit（评估多步编辑推理）。为每个子集设计了专门的评估流程，以实现细粒度和可解释的评估，并减少“多模态大模型作为裁判”范式的偏见。

Result: 统一多模态模型在推理驱动的视觉任务上更具优势，但在理解和生成之间仍存在差距。

Conclusion: GIR-Bench为评估统一多模态模型的关键能力提供了一个全面的框架，并揭示了当前模型在理解与生成一致性方面仍有提升空间。

Abstract: Unified multimodal models integrate the reasoning capacity of large language
models with both image understanding and generation, showing great promise for
advanced multimodal intelligence. However, the community still lacks a rigorous
reasoning-centric benchmark to systematically evaluate the alignment between
understanding and generation, and their generalization potential in complex
visual tasks. To this end, we introduce \textbf{GIR-Bench}, a comprehensive
benchmark that evaluates unified models across three complementary
perspectives. Firstly, we investigate understanding-generation consistency
(GIR-Bench-UGC), asking whether models can consistently leverage the same
knowledge in both understanding and generation tasks. Secondly, we investigate
whether models can perform reasoning-centric text-to-image generation that
requires applying logical constraints and implicit knowledge to generate
faithful visual content (GIR-Bench-T2I). Thirdly, we evaluate whether models
can handle multi-step reasoning in editing (GIR-Bench-Edit). For each subset,
we carefully design different task-specific evaluation pipelines tailored for
each task. This enables fine-grained and interpretable evaluation while
mitigating biases from the prevalent MLLM-as-a-Judge paradigm. Extensive
ablations over various unified models and generation-only systems have shown
that: Although unified models are more capable of reasoning-driven visual
tasks, they still exhibit a persistent gap between understanding and
generation. The data and code for GIR-Bench are available at
\href{https://hkust-longgroup.github.io/GIR-Bench}{https://hkust-longgroup.github.io/GIR-Bench}.

</details>


### [150] [Vlaser: Vision-Language-Action Model with Synergistic Embodied Reasoning](https://arxiv.org/abs/2510.11027)
*Ganlin Yang,Tianyi Zhang,Haoran Hao,Weiyun Wang,Yibin Liu,Dehui Wang,Guanzhou Chen,Zijian Cai,Junting Chen,Weijie Su,Wengang Zhou,Yu Qiao,Jifeng Dai,Jiangmiao Pang,Gen Luo,Wenhai Wang,Yao Mu,Zhi Hou*

Main category: cs.CV

TL;DR: Vlaser是一个结合了高级推理和低级控制的视觉-语言-动作模型，在各种具身推理基准测试中达到了最先进的性能，并在WidowX和Google Robot基准测试中取得了优异的成果。


<details>
  <summary>Details</summary>
Motivation: 现有研究在利用视觉语言模型（VLMs）进行具身推理或将VLMs集成到视觉-语言-动作（VLA）模型中进行端到端机器人控制方面投入了大量精力，但很少有研究直接解决上游VLM推理与下游VLA策略学习之间的关键差距。

Method: 提出Vlaser，一个具有协同具身推理能力的视觉-语言-动作模型，它是一个基础的视觉-语言模型，旨在为具身智能体集成高级推理与低级控制。该模型建立在高品质的Vlaser-6M数据集之上。系统地研究了不同的VLM初始化对监督VLA微调的影响，为减轻互联网规模的预训练数据与具身特定策略学习数据之间的领域偏移提供了新的见解。

Result: Vlaser在空间推理、具身基础、具身问答和任务规划等一系列具身推理基准测试中取得了最先进的性能。基于对VLM初始化的见解，该方法在WidowX基准测试中取得了最先进的结果，并在Google Robot基准测试中取得了有竞争力的性能。

Conclusion: Vlaser通过整合高级推理和低级控制，成功弥合了具身推理与VLA策略学习之间的差距，并在多个基准测试中取得了最先进的成果。通过系统地研究VLM初始化对微调的影响，为未来的研究提供了新的见解。

Abstract: While significant research has focused on developing embodied reasoning
capabilities using Vision-Language Models (VLMs) or integrating advanced VLMs
into Vision-Language-Action (VLA) models for end-to-end robot control, few
studies directly address the critical gap between upstream VLM-based reasoning
and downstream VLA policy learning. In this work, we take an initial step
toward bridging embodied reasoning with VLA policy learning by introducing
Vlaser - a Vision-Language-Action Model with synergistic embodied reasoning
capability, which is a foundational vision-language model designed to integrate
high-level reasoning with low-level control for embodied agents. Built upon the
high-quality Vlaser-6M dataset, Vlaser achieves state-of-the-art performance
across a range of embodied reasoning benchmarks - including spatial reasoning,
embodied grounding, embodied QA, and task planning. Furthermore, we
systematically examine how different VLM initializations affect supervised VLA
fine-tuning, offering novel insights into mitigating the domain shift between
internet-scale pre-training data and embodied-specific policy learning data.
Based on these insights, our approach achieves state-of-the-art results on the
WidowX benchmark and competitive performance on the Google Robot benchmark.

</details>


### [151] [Enhancing Zero-Shot Anomaly Detection: CLIP-SAM Collaboration with Cascaded Prompts](https://arxiv.org/abs/2510.11028)
*Yanning Hou,Ke Xu,Junfa Li,Yanran Ruan,Jianfeng Qiu*

Main category: cs.CV

TL;DR: 本研究提出了一种新颖的两阶段框架，用于工业异常检测中的零样本异常分割任务，该框架结合了CLIP和SAM的强大能力，并通过PPG和CPS模块优化分割效果，在多个数据集上取得了最先进的零样本异常分割结果。


<details>
  <summary>Details</summary>
Motivation: 现有的基础模型在零样本异常分割任务中表现出强大的泛化能力，但如何正确引导这些模型以适应下游任务仍然是一个挑战。

Method: 提出了一种新颖的两阶段框架：1. 提出协同特征点提示生成（PPG）模块，利用CLIP和SAM生成正负样本点提示，引导SAM关注异常区域而非整个物体。2. 提出级联SAM提示（CPS）模块，通过混合提示和轻量级解码器优化SAM的分割结果，解决边界粗糙和孤立噪声问题。

Result: 在多个数据集上进行了实验验证，证明了该方法在零样本异常分割任务上取得了最先进的结果。特别是在Visa数据集上，F1-max和AP指标分别优于现有方法10.3%和7.7%。

Conclusion: 本研究提出的两阶段框架通过结合CLIP和SAM的优势，并引入PPG和CPS模块，有效地解决了零样本异常分割任务中的挑战，并在多个数据集上取得了优异的性能。

Abstract: Recently, the powerful generalization ability exhibited by foundation models
has brought forth new solutions for zero-shot anomaly segmentation tasks.
However, guiding these foundation models correctly to address downstream tasks
remains a challenge. This paper proposes a novel two-stage framework, for
zero-shot anomaly segmentation tasks in industrial anomaly detection. This
framework excellently leverages the powerful anomaly localization capability of
CLIP and the boundary perception ability of SAM.(1) To mitigate SAM's
inclination towards object segmentation, we propose the Co-Feature Point Prompt
Generation (PPG) module. This module collaboratively utilizes CLIP and SAM to
generate positive and negative point prompts, guiding SAM to focus on
segmenting anomalous regions rather than the entire object. (2) To further
optimize SAM's segmentation results and mitigate rough boundaries and isolated
noise, we introduce the Cascaded Prompts for SAM (CPS) module. This module
employs hybrid prompts cascaded with a lightweight decoder of SAM, achieving
precise segmentation of anomalous regions. Across multiple datasets, consistent
experimental validation demonstrates that our approach achieves
state-of-the-art zero-shot anomaly segmentation results. Particularly
noteworthy is our performance on the Visa dataset, where we outperform the
state-of-the-art methods by 10.3\% and 7.7\% in terms of {$F_1$-max} and AP
metrics, respectively.

</details>


### [152] [Benchmarking Deep Learning Models for Laryngeal Cancer Staging Using the LaryngealCT Dataset](https://arxiv.org/abs/2510.11047)
*Nivea Roy,Son Tran,Atul Sajjanhar,K. Devaraja,Prakashini Koteshwara,Yong Xiang,Divya Rao*

Main category: cs.CV

TL;DR: LaryngealCT是一个包含1029个CT扫描的喉癌影像数据集，用于标准的深度学习模型开发。研究人员在此数据集上评估了多种3D深度学习模型，并取得了良好的分类效果，同时还提供了模型可解释性分析，为喉癌的临床决策提供了可重复的研究基础。


<details>
  <summary>Details</summary>
Motivation: 目前喉癌影像研究缺乏标准化的数据集，阻碍了可重复的深度学习模型开发。因此，需要构建一个标准化的数据集来推动该领域的研究。

Method: 1. 收集并整合了来自The Cancer Imaging Archive（TCIA）的六个数据源，共1029个喉癌CT扫描。 2. 使用弱监督参数搜索框架提取了包含喉部的1毫米各向同性视野（VOI），并通过临床专家进行了验证。 3. 在LaryngealCT数据集上，对早期（Tis, T1, T2）与晚期（T3, T4）以及T4与非T4的二分类任务，对3D卷积神经网络（CNN）、ResNet18、ResNet50、ResNet101和DenseNet121等3D深度学习模型进行了基准测试。 4. 采用3D GradCAMs结合甲状软骨叠加的方式评估了模型的解释性。

Result: 在早期 vs. 晚期分类任务中，3D CNN（AUC-0.881, F1-macro-0.821）表现最佳。在T4 vs. 非T4分类任务中，ResNet18（AUC-0.892, F1-macro-0.646）表现最佳。模型解释性分析显示，在非T4病例中，模型更关注喉软骨周围区域，而在T4预测中，模型激活区域更集中。

Conclusion: LaryngealCT数据集通过提供开源数据、预训练模型和集成解释性工具，为喉癌人工智能研究奠定了可重复的基础，有望支持临床决策。

Abstract: Laryngeal cancer imaging research lacks standardised datasets to enable
reproducible deep learning (DL) model development. We present LaryngealCT, a
curated benchmark of 1,029 computed tomography (CT) scans aggregated from six
collections from The Cancer Imaging Archive (TCIA). Uniform 1 mm isotropic
volumes of interest encompassing the larynx were extracted using a weakly
supervised parameter search framework validated by clinical experts. 3D DL
architectures (3D CNN, ResNet18,50,101, DenseNet121) were benchmarked on (i)
early (Tis,T1,T2) vs. advanced (T3,T4) and (ii) T4 vs. non-T4 classification
tasks. 3D CNN (AUC-0.881, F1-macro-0.821) and ResNet18 (AUC-0.892,
F1-macro-0.646) respectively outperformed the other models in the two tasks.
Model explainability assessed using 3D GradCAMs with thyroid cartilage overlays
revealed greater peri-cartilage attention in non-T4 cases and focal activations
in T4 predictions. Through open-source data, pretrained models, and integrated
explainability tools, LaryngealCT offers a reproducible foundation for
AI-driven research to support clinical decisions in laryngeal oncology.

</details>


### [153] [Zero-shot Face Editing via ID-Attribute Decoupled Inversion](https://arxiv.org/abs/2510.11050)
*Yang Hou,Minggu Wang,Jianjun Zhao*

Main category: cs.CV

TL;DR: 提出一种新的零样本人脸编辑方法，通过解耦身份和属性特征来保持身份一致性和结构完整性，同时实现精确的面部属性编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像模型在进行真实人脸编辑时，难以保持身份（ID）和结构的一致性。

Method: 提出一种基于身份-属性解耦（ID-Attribute Decoupled Inversion）的零样本人脸编辑方法。该方法将人脸表示分解为身份（ID）特征和属性特征，并将它们作为联合条件来指导反演和反向扩散过程。这种解耦允许独立控制身份和属性，从而在实现精确的面部属性操纵的同时，确保强大的身份保持和结构一致性。

Result: 该方法支持使用纯文本提示进行广泛的复杂多属性人脸编辑任务，无需区域特定输入，并且运行速度与DDIM反演相当。实验证明了其有效性。

Conclusion: 所提出的ID-属性解耦反演方法能够有效地解决现有方法在人脸编辑中存在的身份和结构一致性问题，实现了精确的面部属性编辑。

Abstract: Recent advancements in text-guided diffusion models have shown promise for
general image editing via inversion techniques, but often struggle to maintain
ID and structural consistency in real face editing tasks. To address this
limitation, we propose a zero-shot face editing method based on ID-Attribute
Decoupled Inversion. Specifically, we decompose the face representation into ID
and attribute features, using them as joint conditions to guide both the
inversion and the reverse diffusion processes. This allows independent control
over ID and attributes, ensuring strong ID preservation and structural
consistency while enabling precise facial attribute manipulation. Our method
supports a wide range of complex multi-attribute face editing tasks using only
text prompts, without requiring region-specific input, and operates at a speed
comparable to DDIM inversion. Comprehensive experiments demonstrate its
practicality and effectiveness.

</details>


### [154] [LSVOS 2025 Challenge Report: Recent Advances in Complex Video Object Segmentation](https://arxiv.org/abs/2510.11063)
*Chang Liu,Henghui Ding,Kaining Ying,Lingyi Hong,Ning Xu,Linjie Yang,Yuchen Fan,Mingqi Gao,Jingkun Chen,Yunqi Miao,Gengshen Wu,Zhijin Qin,Jungong Han,Zhixiong Zhang,Shuangrui Ding,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Chang Soo Lim,Joonyoung Moon,Donghyeon Cho,Tingmin Li,Yixuan Li,Yang Yang,An Yan,Leilei Cao,Feng Lu,Ran Hong,Youhai Jiang,Fengjie Zhu,Yujie Xie,Hongyang Zhang,Zhihui Liu,Shihai Ruan,Quanzhu Niu,Dengxian Gong,Shihao Chen,Tao Zhang,Yikang Zhou,Haobo Yuan,Lu Qi,Xiangtai Li,Shunping Ji,Ran Hong,Feng Lu,Leilei Cao,An Yan,Alexey Nekrasov,Ali Athar,Daan de Geus,Alexander Hermans,Bastian Leibe*

Main category: cs.CV

TL;DR: CVPR 2023 视频分割挑战赛（LSVOS）介绍了三个赛道：经典视频分割（VOS）、指代表达式分割（RVOS）和新增的复杂视频分割（MOSEv2）。MOSEv2 赛道增加了难度，引入了更具挑战性的场景，如密集小目标、频繁消失/重现、严重遮挡、恶劣天气和光照等，以测试长期一致性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 本次挑战赛旨在推进视频对象分割技术在真实世界复杂场景下的鲁棒性和泛化能力，特别是通过引入 MOSEv2 赛道来解决现有基准测试的局限性。

Method: 本次挑战赛包含经典视频分割（VOS）、指代表达式分割（RVOS）和复杂视频分割（MOSEv2）三个赛道。MOSEv2 赛道引入了更具挑战性的数据集和评估指标（J&F）。

Result: 本次挑战赛总结了数据集、协议、表现最佳的解决方案，并指出了大型语言模型（LLM/MLLM）和记忆感知传播等新兴趋势。

Conclusion: 本次挑战赛为在真实世界中实现鲁棒、可理解的视频分割指明了未来的发展方向。

Abstract: This report presents an overview of the 7th Large-scale Video Object
Segmentation (LSVOS) Challenge held in conjunction with ICCV 2025. Besides the
two traditional tracks of LSVOS that jointly target robustness in realistic
video scenarios: Classic VOS (VOS), and Referring VOS (RVOS), the 2025 edition
features a newly introduced track, Complex VOS (MOSEv2). Building upon prior
insights, MOSEv2 substantially increases difficulty, introducing more
challenging but realistic scenarios including denser small objects, frequent
disappear/reappear events, severe occlusions, adverse weather and lighting,
etc., pushing long-term consistency and generalization beyond curated
benchmarks. The challenge retains standard ${J}$, $F$, and ${J\&F}$ metrics for
VOS and RVOS, while MOSEv2 adopts ${J\&\dot{F}}$ as the primary ranking metric
to better evaluate objects across scales and disappearance cases. We summarize
datasets and protocols, highlight top-performing solutions, and distill
emerging trends, such as the growing role of LLM/MLLM components and
memory-aware propagation, aiming to chart future directions for resilient,
language-aware video segmentation in the wild.

</details>


### [155] [ROFI: A Deep Learning-Based Ophthalmic Sign-Preserving and Reversible Patient Face Anonymizer](https://arxiv.org/abs/2510.11073)
*Yuan Tian,Min Zhou,Yitong Chen,Fang Li,Lingzi Qi,Shuo Wang,Xieyang Xu,Yu Yu,Shiqiong Xu,Chaoyu Lei,Yankai Jiang,Rongzhao Zhang,Jia Tan,Li Wu,Hong Chen,Xiaowei Liu,Wei Lu,Lin Li,Huifang Zhou,Xuefei Song,Guangtao Zhai,Xianqun Fan*

Main category: cs.CV

TL;DR: ROFI是一个基于深度学习的隐私保护框架，用于眼科面部图像。它通过神经身份转换和弱监督学习，在保留疾病特征的同时匿名化面部特征，准确率超过98%。该框架对11种眼科疾病具有100%的诊断敏感性，并与AI系统兼容，支持图像安全逆转，有效保护数字医疗时代的患者隐私。


<details>
  <summary>Details</summary>
Motivation: 患者面部图像在评估眼部疾病方面提供了便利，但同时也引发了隐私担忧。需要一种方法来在利用这些图像的同时保护患者隐私。

Method: 使用弱监督学习和神经身份转换技术。

Result: ROFI在保留疾病特征方面准确率超过98%，对11种眼科疾病的诊断敏感性达到100%，并与AI系统兼容，同时支持图像安全逆转。

Conclusion: ROFI能够有效保护数字医疗时代的患者隐私，同时保留重要的医学诊断信息。

Abstract: Patient face images provide a convenient mean for evaluating eye diseases,
while also raising privacy concerns. Here, we introduce ROFI, a deep
learning-based privacy protection framework for ophthalmology. Using weakly
supervised learning and neural identity translation, ROFI anonymizes facial
features while retaining disease features (over 98\% accuracy, $\kappa >
0.90$). It achieves 100\% diagnostic sensitivity and high agreement ($\kappa >
0.90$) across eleven eye diseases in three cohorts, anonymizing over 95\% of
images. ROFI works with AI systems, maintaining original diagnoses ($\kappa >
0.80$), and supports secure image reversal (over 98\% similarity), enabling
audits and long-term care. These results show ROFI's effectiveness of
protecting patient privacy in the digital medicine era.

</details>


### [156] [Source-Free Object Detection with Detection Transformer](https://arxiv.org/abs/2510.11090)
*Huizai Yao,Sicheng Zhao,Shuo Lu,Hui Chen,Yangyang Li,Guoping Liu,Tengfei Xing,Chenggang Yan,Jianhua Tao,Guiguang Ding*

Main category: cs.CV

TL;DR: 该研究提出了一种名为FRANCK的新型无源域对象检测（SFOD）框架，专门用于增强基于DETR模型的查询中心特征，以提高在无标签目标域上的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有SFOD方法在应用于DETR等新型对象检测架构时存在局限性，缺乏定制化解决方案。

Method: FRANCK框架包含四个关键组件：1. 基于对象性分数的样本重加权（OSSR）模块，用于强调识别不足的区域；2. 基于匹配记忆库的对比学习（CMMB）模块，用于增强类别对比学习；3. 不确定性加权查询融合特征蒸馏（UQFD）模块，用于改进特征蒸馏；4. 具有动态教师更新间隔（DTUI）的改进自训练流程，用于优化伪标签质量。

Result: FRANCK框架通过其组件的协同作用，能够有效适应目标域，增强了DETR模型的鲁棒性和泛化能力，并在多个基准测试中达到了最先进的性能。

Conclusion: FRANCK框架在基于DETR的SFOD模型方面表现出了优越的性能和兼容性，证明了其有效性。

Abstract: Source-Free Object Detection (SFOD) enables knowledge transfer from a source
domain to an unsupervised target domain for object detection without access to
source data. Most existing SFOD approaches are either confined to conventional
object detection (OD) models like Faster R-CNN or designed as general solutions
without tailored adaptations for novel OD architectures, especially Detection
Transformer (DETR). In this paper, we introduce Feature Reweighting ANd
Contrastive Learning NetworK (FRANCK), a novel SFOD framework specifically
designed to perform query-centric feature enhancement for DETRs. FRANCK
comprises four key components: (1) an Objectness Score-based Sample Reweighting
(OSSR) module that computes attention-based objectness scores on multi-scale
encoder feature maps, reweighting the detection loss to emphasize
less-recognized regions; (2) a Contrastive Learning with Matching-based Memory
Bank (CMMB) module that integrates multi-level features into memory banks,
enhancing class-wise contrastive learning; (3) an Uncertainty-weighted
Query-fused Feature Distillation (UQFD) module that improves feature
distillation through prediction quality reweighting and query feature fusion;
and (4) an improved self-training pipeline with a Dynamic Teacher Updating
Interval (DTUI) that optimizes pseudo-label quality. By leveraging these
components, FRANCK effectively adapts a source-pre-trained DETR model to a
target domain with enhanced robustness and generalization. Extensive
experiments on several widely used benchmarks demonstrate that our method
achieves state-of-the-art performance, highlighting its effectiveness and
compatibility with DETR-based SFOD models.

</details>


### [157] [Text-Enhanced Panoptic Symbol Spotting in CAD Drawings](https://arxiv.org/abs/2510.11091)
*Xianlin Liu,Yan Gong,Bohao Li,Jiajing Huang,Bowen Du,Junchen Ye,Liyan Xu*

Main category: cs.CV

TL;DR: 该研究提出了一种结合文本信息和几何信息来识别CAD图纸中符号的新方法，解决了现有方法只关注几何图形而忽略文本标注的问题。


<details>
  <summary>Details</summary>
Motivation: 现有CAD图纸符号识别方法主要关注几何图元，忽略了丰富的文本标注，并且缺乏对图元之间关系的显式建模，导致对图纸的理解不全面。

Method: 提出了一种结合文本和几何信息的全景符号识别框架。该框架首先构建统一的表示，联合建模几何和文本图元。然后，利用预训练CNN提取的视觉特征作为初始表示，并采用基于Transformer的骨干网络，通过类型感知注意力机制来显式建模各种图元之间的不同类型的空间依赖关系。

Result: 在真实世界的数据集上进行了广泛的实验，结果表明该方法在涉及文本标注的符号识别任务上优于现有方法，并且在应用于复杂的CAD图纸时表现出更强的鲁棒性。

Conclusion: 所提出的框架通过联合建模几何和文本信息，并显式建模它们之间的空间依赖关系，能够更全面、更鲁棒地识别CAD图纸中的符号。

Abstract: With the widespread adoption of Computer-Aided Design(CAD) drawings in
engineering, architecture, and industrial design, the ability to accurately
interpret and analyze these drawings has become increasingly critical. Among
various subtasks, panoptic symbol spotting plays a vital role in enabling
downstream applications such as CAD automation and design retrieval. Existing
methods primarily focus on geometric primitives within the CAD drawings to
address this task, but they face following major problems: they usually
overlook the rich textual annotations present in CAD drawings and they lack
explicit modeling of relationships among primitives, resulting in
incomprehensive understanding of the holistic drawings. To fill this gap, we
propose a panoptic symbol spotting framework that incorporates textual
annotations. The framework constructs unified representations by jointly
modeling geometric and textual primitives. Then, using visual features extract
by pretrained CNN as the initial representations, a Transformer-based backbone
is employed, enhanced with a type-aware attention mechanism to explicitly model
the different types of spatial dependencies between various primitives.
Extensive experiments on the real-world dataset demonstrate that the proposed
method outperforms existing approaches on symbol spotting tasks involving
textual annotations, and exhibits superior robustness when applied to complex
CAD drawings.

</details>


### [158] [Future-Aware End-to-End Driving: Bidirectional Modeling of Trajectory Planning and Scene Evolution](https://arxiv.org/abs/2510.11092)
*Bozhou Zhang,Nan Song,Jingyu Li,Xiatian Zhu,Jiankang Deng,Li Zhang*

Main category: cs.CV

TL;DR: SeerDrive是一个端到端自动驾驶框架，通过联合建模未来场景演变和轨迹规划，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统端到端自动驾驶方法过于依赖当前场景，忽略了场景动态和时间演变的重要性，限制了其在复杂场景下的决策能力。

Method: SeerDrive首先预测未来的鸟瞰图（BEV）表示以预测周围场景的动态，然后利用这种预见性来生成面向未来上下文的轨迹。该框架包含两个关键组件：(1) 未来感知规划，将预测的BEV特征注入轨迹规划器；(2) 迭代场景建模与车辆规划，通过协作优化来精炼未来场景预测和轨迹生成。

Result: 在NAVSIM和nuScenes基准测试上的广泛实验表明，SeerDrive的性能显著优于现有的最先进方法。

Conclusion: SeerDrive通过引入双向关系的概念，即未来轨迹与环境动态相互关联，并且车辆自身状态可以影响周围场景的展开，从而在端到端自动驾驶领域取得了显著的进步。

Abstract: End-to-end autonomous driving methods aim to directly map raw sensor inputs
to future driving actions such as planned trajectories, bypassing traditional
modular pipelines. While these approaches have shown promise, they often
operate under a one-shot paradigm that relies heavily on the current scene
context, potentially underestimating the importance of scene dynamics and their
temporal evolution. This limitation restricts the model's ability to make
informed and adaptive decisions in complex driving scenarios. We propose a new
perspective: the future trajectory of an autonomous vehicle is closely
intertwined with the evolving dynamics of its environment, and conversely, the
vehicle's own future states can influence how the surrounding scene unfolds.
Motivated by this bidirectional relationship, we introduce SeerDrive, a novel
end-to-end framework that jointly models future scene evolution and trajectory
planning in a closed-loop manner. Our method first predicts future bird's-eye
view (BEV) representations to anticipate the dynamics of the surrounding scene,
then leverages this foresight to generate future-context-aware trajectories.
Two key components enable this: (1) future-aware planning, which injects
predicted BEV features into the trajectory planner, and (2) iterative scene
modeling and vehicle planning, which refines both future scene prediction and
trajectory generation through collaborative optimization. Extensive experiments
on the NAVSIM and nuScenes benchmarks show that SeerDrive significantly
outperforms existing state-of-the-art methods.

</details>


### [159] [CoDefend: Cross-Modal Collaborative Defense via Diffusion Purification and Prompt Optimization](https://arxiv.org/abs/2510.11096)
*Fengling Zhu,Boshi Liu,Jingyu Hua,Sheng Zhong*

Main category: cs.CV

TL;DR: MLLMs 易受对抗性攻击，现有防御方法效果有限。本文提出一种监督式扩散去噪框架，并结合提示优化，以增强 MLLMs 的视觉防御能力。


<details>
  <summary>Details</summary>
Motivation: 现有防御策略（如对抗训练和输入净化）在应对 MLLMs 的对抗性攻击时存在局限性，例如泛化能力不足、图像质量下降和计算成本高。

Method: 提出一种监督式扩散去噪框架，利用配对的对抗性干净图像数据集微调扩散模型，并引入特定任务的定向指导。同时，结合提示优化作为辅助防御机制。

Result: 在图像描述和视觉问答任务的广泛实验中，所提出的方法显著提高了模型的鲁棒性，并且能够抵抗未知的新型对抗性攻击，同时保持了高质量的图像重建。

Conclusion: 监督式扩散去噪结合提示优化能够有效防御 MLLMs 的视觉对抗性攻击，提高了模型的可靠性和安全性，为 MLLMs 在现实世界中的应用铺平了道路。

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable success in
tasks such as image captioning, visual question answering, and cross-modal
reasoning by integrating visual and textual modalities. However, their
multimodal nature also exposes them to adversarial threats, where attackers can
perturb either modality or both jointly to induce harmful, misleading, or
policy violating outputs. Existing defense strategies, such as adversarial
training and input purification, face notable limitations: adversarial training
typically improves robustness only against known attacks while incurring high
computational costs, whereas conventional purification approaches often suffer
from degraded image quality and insufficient generalization to complex
multimodal tasks.
  In this work, we focus on defending the visual modality, which frequently
serves as the primary entry point for adversarial manipulation. We propose a
supervised diffusion based denoising framework that leverages paired
adversarial clean image datasets to fine-tune diffusion models with
directional, task specific guidance. Unlike prior unsupervised purification
methods such as DiffPure, our approach achieves higher quality reconstructions
while significantly improving defense robustness in multimodal tasks.
Furthermore, we incorporate prompt optimization as a complementary defense
mechanism, enhancing resistance against diverse and unseen attack strategies.
  Extensive experiments on image captioning and visual question answering
demonstrate that our method not only substantially improves robustness but also
exhibits strong transferability to unknown adversarial attacks. These results
highlight the effectiveness of supervised diffusion based denoising for
multimodal defense, paving the way for more reliable and secure deployment of
MLLMs in real world applications.

</details>


### [160] [Compositional Zero-Shot Learning: A Survey](https://arxiv.org/abs/2510.11106)
*Ans Munir,Faisal Z. Qureshi,Mohsen Ali,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 本文是第一篇全面 survey CZSL 的论文，提出了一种基于解耦的分类方法，分析了现有方法的优缺点，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: CZSL 能够在推理时识别训练数据中未出现过的属性和物体组合，解决了需要为每种组合提供训练数据的组合性挑战。然而，原始概念（如“小”和“猫”）的视觉外观是高度情境化的，例如，“小”猫和“老”猫看起来不同，“湿”猫和“湿”汽车看起来也大不相同。因此，对这种情境性和固有的组合性进行建模对于鲁棒的 CZSL 识别至关重要。

Method: 本文提出了一个系统性的 CZSL 方法分类，主要基于解耦，将现有方法分为四类：无显式解耦、文本解耦、视觉解耦和跨模态解耦。并通过详细的比较分析了这些方法的优缺点，特别是在闭 عالم 和开 عالم CZSL 等不同场景下的表现。

Result: 对现有 CZSL 方法进行了详细的比较分析，突出了它们在不同问题设置（如闭 عالم 和开 عالم CZSL）下的核心优势和局限性。

Conclusion: 本文是 CZSL 领域的第一篇全面 survey，系统地回顾了现有方法，提出了基于解耦的分类法，并对各种方法进行了比较分析。最后，文章指出了该领域面临的重大挑战和未来的研究方向，旨在为该领域提供一个基础性资源，以指导和启发未来的研究。

Abstract: Compositional Zero-Shot Learning (CZSL) is a critical task in computer vision
that enables models to recognize unseen combinations of known attributes and
objects during inference, addressing the combinatorial challenge of requiring
training data for every possible composition. This is particularly challenging
because the visual appearance of primitives is highly contextual; for example,
``small'' cats appear visually distinct from ``older'' ones, and ``wet'' cars
differ significantly from ``wet'' cats. Effectively modeling this contextuality
and the inherent compositionality is crucial for robust compositional zero-shot
recognition. This paper presents, to our knowledge, the first comprehensive
survey specifically focused on Compositional Zero-Shot Learning. We
systematically review the state-of-the-art CZSL methods, introducing a taxonomy
grounded in disentanglement, with four families of approaches: no explicit
disentanglement, textual disentanglement, visual disentanglement, and
cross-modal disentanglement. We provide a detailed comparative analysis of
these methods, highlighting their core advantages and limitations in different
problem settings, such as closed-world and open-world CZSL. Finally, we
identify the most significant open challenges and outline promising future
research directions. This survey aims to serve as a foundational resource to
guide and inspire further advancements in this fascinating and important field.
Papers studied in this survey with their official code are available on our
github: https://github.com/ans92/Compositional-Zero-Shot-Learning

</details>


### [161] [MoMaps: Semantics-Aware Scene Motion Generation with Motion Maps](https://arxiv.org/abs/2510.11107)
*Jiahui Lei,Kyle Genova,George Kopanas,Noah Snavely,Leonidas Guibas*

Main category: cs.CV

TL;DR: 本论文提出了一种新的像素对齐运动图（MoMap）表示法，用于从单张输入图像预测未来3D场景运动。


<details>
  <summary>Details</summary>
Motivation: 从真实视频中学习有意义的3D运动先验，以实现从单张输入图像预测未来3D场景运动的挑战。

Method: 提出了一种新的像素对齐运动图（MoMap）表示法，用于从现有生成图像模型生成3D场景运动。创建了一个包含超过50,000个真实视频的MoMap的大型数据库，并在这些表示上训练了一个扩散模型。

Result: 生成的运动不仅可以合成3D轨迹，还可以为2D视频合成提出新的流程：首先生成MoMap，然后相应地扭曲图像并完成扭曲的点渲染。实验结果表明，该方法可以生成合理且语义一致的3D场景运动。

Conclusion: 该方法能够生成合理且语义一致的3D场景运动，并为2D视频合成提供了新的方法。

Abstract: This paper addresses the challenge of learning semantically and functionally
meaningful 3D motion priors from real-world videos, in order to enable
prediction of future 3D scene motion from a single input image. We propose a
novel pixel-aligned Motion Map (MoMap) representation for 3D scene motion,
which can be generated from existing generative image models to facilitate
efficient and effective motion prediction. To learn meaningful distributions
over motion, we create a large-scale database of MoMaps from over 50,000 real
videos and train a diffusion model on these representations. Our motion
generation not only synthesizes trajectories in 3D but also suggests a new
pipeline for 2D video synthesis: first generate a MoMap, then warp an image
accordingly and complete the warped point-based renderings. Experimental
results demonstrate that our approach generates plausible and semantically
consistent 3D scene motion.

</details>


### [162] [Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment](https://arxiv.org/abs/2510.11112)
*Chen Liu,Wenfang Yao,Kejing Yin,William K. Cheung,Jing Qin*

Main category: cs.CV

TL;DR: DiPro框架通过解耦CXRs中的静态和动态特征并进行多时间尺度对齐，有效利用了电子健康记录和胸部X光序列数据来模拟疾病进展，并在MIMIC数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 对电子健康记录（EHR）和连续胸部X光（CXR）序列等纵向多模态数据进行疾病进展建模至关重要，但由于连续CXR序列中的冗余（静态解剖结构占主导地位）和稀疏、不规则的成像与连续EHR数据之间的时间失准，这些数据仍未被充分利用。

Method: 提出了一种名为DiPro的新框架，通过区域感知解耦和多时间尺度对齐来解决这些挑战。首先，将CXR序列中的静态（解剖结构）和动态（病理进展）特征分离开来，优先考虑与疾病相关的变化。其次，通过局部（成对间隔级别）和全局（全序列）同步，将这些静态和动态CXR特征与异步EHR数据进行分层对齐，以模拟连贯的进展路径。

Result: 在MIMIC数据集上的大量实验表明，DiPro能够有效提取时间临床动态，并在疾病进展识别和一般ICU预测任务上取得最先进的性能。

Conclusion: DiPro框架能够有效处理纵向多模态数据中的挑战，并提高疾病进展建模的准确性。

Abstract: Longitudinal multimodal data, including electronic health records (EHR) and
sequential chest X-rays (CXRs), is critical for modeling disease progression,
yet remains underutilized due to two key challenges: (1) redundancy in
consecutive CXR sequences, where static anatomical regions dominate over
clinically-meaningful dynamics, and (2) temporal misalignment between sparse,
irregular imaging and continuous EHR data. We introduce $\texttt{DiPro}$, a
novel framework that addresses these challenges through region-aware
disentanglement and multi-timescale alignment. First, we disentangle static
(anatomy) and dynamic (pathology progression) features in sequential CXRs,
prioritizing disease-relevant changes. Second, we hierarchically align these
static and dynamic CXR features with asynchronous EHR data via local (pairwise
interval-level) and global (full-sequence) synchronization to model coherent
progression pathways. Extensive experiments on the MIMIC dataset demonstrate
that $\texttt{DiPro}$ could effectively extract temporal clinical dynamics and
achieve state-of-the-art performance on both disease progression identification
and general ICU prediction tasks.

</details>


### [163] [Connecting Giants: Synergistic Knowledge Transfer of Large Multimodal Models for Few-Shot Learning](https://arxiv.org/abs/2510.11115)
*Hao Tang,Shengfeng He,Jing Qin*

Main category: cs.CV

TL;DR: SynTrans通过从大型多模态模型中迁移多样化、互补的知识来增强少样本学习能力，克服了现有方法引入的噪声和偏差，在四个少样本学习数据集上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有少样本学习方法在利用小规模模型迁移语义知识时，常因数据本身的局限性而引入噪声和偏差。本研究旨在提出一种新的框架，能够有效地从大型多模态模型中迁移多样化且互补的知识，以增强少样本学习的性能。

Method: 本研究提出的SynTrans框架，首先利用CLIP作为教师模型，视觉编码器作为学生模型，通过无监督代理任务来迁移语义对齐的视觉知识。然后，利用一个无训练的协同知识挖掘模块促进大型多模态模型之间的协作，以提取高质量的语义知识。接着，一个视觉-语义桥接模块实现了视觉和语义空间之间的双向知识迁移，将显性视觉知识和隐性语义知识转化为特定类别的分类器权重。最后，通过视觉权重生成器和语义权重重建器自适应地构建最优的多模态少样本学习分类器。

Result: 在四个少样本学习数据集上的实验结果表明，SynTrans框架即使与简单的少样本视觉编码器结合使用，也显著优于当前最先进的方法。

Conclusion: SynTrans框架能够有效地从大型多模态模型中迁移知识，克服现有方法的局限性，显著提升少样本学习的性能。

Abstract: Few-shot learning (FSL) addresses the challenge of classifying novel classes
with limited training samples. While some methods leverage semantic knowledge
from smaller-scale models to mitigate data scarcity, these approaches often
introduce noise and bias due to the data's inherent simplicity. In this paper,
we propose a novel framework, Synergistic Knowledge Transfer (SynTrans), which
effectively transfers diverse and complementary knowledge from large multimodal
models to empower the off-the-shelf few-shot learner. Specifically, SynTrans
employs CLIP as a robust teacher and uses a few-shot vision encoder as a weak
student, distilling semantic-aligned visual knowledge via an unsupervised proxy
task. Subsequently, a training-free synergistic knowledge mining module
facilitates collaboration among large multimodal models to extract high-quality
semantic knowledge. Building upon this, a visual-semantic bridging module
enables bi-directional knowledge transfer between visual and semantic spaces,
transforming explicit visual and implicit semantic knowledge into
category-specific classifier weights. Finally, SynTrans introduces a visual
weight generator and a semantic weight reconstructor to adaptively construct
optimal multimodal FSL classifiers. Experimental results on four FSL datasets
demonstrate that SynTrans, even when paired with a simple few-shot vision
encoder, significantly outperforms current state-of-the-art methods.

</details>


### [164] [Demystifying Numerosity in Diffusion Models -- Limitations and Remedies](https://arxiv.org/abs/2510.11117)
*Yaqi Zhao,Xiaochen Wang,Li Dong,Wentao Zhang,Yuhui Yuan*

Main category: cs.CV

TL;DR: 大型语言模型难以准确生成提示中指定数量的物体，而增加数据集和模型大小并不能解决这个问题。研究发现，模型倾向于依赖噪声初始化而非提示中的数字。通过向噪声先验注入与计数相关的布局信息，可以显著提高生成物体数量的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究文本到图像生成模型（如FLUX和GPT-4o）在遵循文本提示中的计数指令时存在的挑战，特别是它们难以准确生成指定数量的物体。

Method: 构建了一个包含GrayCount250和NaturalCount6两个数据集的合成数据集，并在此基础上进行了实证研究，探讨了通过扩大数据集和模型规模是否能提升生成物体数量的准确性。此外，还提出了一种将计数感知的布局信息注入噪声先验的方法来控制物体数量。

Result: 实证研究表明，扩大模型和数据集规模并不能提高计数准确性，因为扩散模型倾向于依赖噪声初始化而非提示中的数字。提出的注入计数感知的布局信息的方法显著提高了准确性，在GrayCount250上从20.0%提高到85.3%，在NaturalCount6上从74.8%提高到86.3%。

Conclusion: 仅仅扩大模型和数据集的规模并不能解决扩散模型在生成指定数量物体方面的准确性问题。通过向噪声先验注入计数感知的布局信息，可以有效提升生成物体数量的准确性，并能很好地泛化到不同的场景。

Abstract: Numerosity remains a challenge for state-of-the-art text-to-image generation
models like FLUX and GPT-4o, which often fail to accurately follow counting
instructions in text prompts. In this paper, we aim to study a fundamental yet
often overlooked question: Can diffusion models inherently generate the correct
number of objects specified by a textual prompt simply by scaling up the
dataset and model size? To enable rigorous and reproducible evaluation, we
construct a clean synthetic numerosity benchmark comprising two complementary
datasets: GrayCount250 for controlled scaling studies, and NaturalCount6
featuring complex naturalistic scenes. Second, we empirically show that the
scaling hypothesis does not hold: larger models and datasets alone fail to
improve counting accuracy on our benchmark. Our analysis identifies a key
reason: diffusion models tend to rely heavily on the noise initialization
rather than the explicit numerosity specified in the prompt. We observe that
noise priors exhibit biases toward specific object counts. In addition, we
propose an effective strategy for controlling numerosity by injecting
count-aware layout information into the noise prior. Our method achieves
significant gains, improving accuracy on GrayCount250 from 20.0\% to 85.3\% and
on NaturalCount6 from 74.8\% to 86.3\%, demonstrating effective generalization
across settings.

</details>


### [165] [video-SALMONN S: Streaming Audio-Visual LLMs Beyond Length Limits via Memory](https://arxiv.org/abs/2510.11129)
*Guangzhi Sun,Yixuan Li,Xiaodong Wu,Yudong Yang,Wei Li,Zejun Ma,Chao Zhang*

Main category: cs.CV

TL;DR: 本研究提出 video-SALMONN S，一个能够处理长达 3 小时、1 FPS、360p 分辨率视频的流式音视频大语言模型，解决了现有模型在处理长视频时面临的内存和信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 未来的 AI 代理需要对长视频流进行连续、高帧率、高分辨率的处理，但现有的视频理解大模型难以扩展。

Method: 提出了一种名为 video-SALMONN S 的流式音视频大语言模型，该模型包含两个关键组件：(1) 一个测试时训练（TTT）内存模块，通过持续更新 token 表示来捕捉长程依赖关系，取代了 token 合并的方法；(2) 一个依赖于提示（prompt-dependent）的内存读取器，用于从固定大小的内存中选择性地检索与上下文相关的。TTT 模块通过 Hessian-free 共轭梯度过程（TTT_HF）进行优化，以实现高效适应。

Result: 在长视频基准测试（Video-MME, LVBench, VideoEvalPro）上，video-SALMONN S 能够在处理包含 10k 帧和 1M tokens 的多小时视频时，保持高质量的理解能力。其 8B 参数模型在 Video-MME 长视频分割上的总体准确率为 74.2%，在长视频分割上为 67.8%，优于离线和流式基线模型。

Conclusion: video-SALMONN S 是首个在固定内存预算下，能够以 1 FPS 和 360p 分辨率处理 3 小时视频的流式音视频大语言模型，在长视频理解任务上取得了优于现有方法的性能。

Abstract: Continuous, high-frame-rate, high-resolution processing of long video streams
is critical for future AI agents, yet current video-understanding LLMs struggle
to scale. Offline, fixed-frame-number methods require the stream length to
adapt frame rates; streaming methods constrain memory by merging or discarding
tokens, losing information. We propose video-SALMONN S, a streaming
audio-visual LLM that, to our knowledge, is the first to process 3-hour videos
at 1 FPS and 360p resolution under a fixed memory budget. Our model introduces
(i) a test-time-training (TTT) memory module that continually updates token
representations to capture long-range dependencies by replacing token merging,
and (ii) a prompt-dependent memory reader that selectively retrieves
context-relevant content from fixed-size memory. The TTT module is optimised
with a Hessian-free conjugate-gradient procedure (TTT_HF) for efficient
adaptation. On long-video benchmarks (Video-MME, LVBench, VideoEvalPro),
video-SALMONN S sustains high-quality understanding on multi-hour videos with
10k frames and 1M tokens. Our 8B-parameter model achieves 74.2% overall and
67.8% on the Video-MME long split, outperforming both offline and streaming
baselines.

</details>


### [166] [Validation of an Artificial Intelligence Tool for the Detection of Sperm DNA Fragmentation Using the TUNEL In Situ Hybridization Assay](https://arxiv.org/abs/2510.11142)
*Byron Alexander Jacobs,Aqeel Morris,Ifthakaar Shaik,Frando Lin*

Main category: cs.CV

TL;DR: 通过分析相差显微镜图像，利用AI工具检测精子DNA碎片化。


<details>
  <summary>Details</summary>
Motivation: 常规精液分析无法评估精子DNA碎片化（SDF），而SDF是评估男性生育能力的关键参数。

Method: 提出一种结合图像处理和基于Transformer的机器学习模型（GC-ViT）的形态辅助集成AI模型，用于预测相差图像中精子的DNA碎片化，并与纯粹的Transformer模型和仅基于形态学的模型进行了比较。

Result: 所提出的框架能够达到60%的敏感性和75%的特异性。

Conclusion: 这种非破坏性的方法通过实现基于DNA完整性的实时精子选择，在生殖医学领域取得了重大进展，可用于临床诊断和治疗。

Abstract: Sperm DNA fragmentation (SDF) is a critical parameter in male fertility
assessment that conventional semen analysis fails to evaluate. This study
presents the validation of a novel artificial intelligence (AI) tool designed
to detect SDF through digital analysis of phase contrast microscopy images,
using the terminal deoxynucleotidyl transferase dUTP nick end labeling (TUNEL)
assay as the gold standard reference. Utilising the established link between
sperm morphology and DNA integrity, the present work proposes a morphology
assisted ensemble AI model that combines image processing techniques with
state-of-the-art transformer based machine learning models (GC-ViT) for the
prediction of DNA fragmentation in sperm from phase contrast images. The
ensemble model is benchmarked against a pure transformer `vision' model as well
as a `morphology-only` model. Promising results show the proposed framework is
able to achieve sensitivity of 60\% and specificity of 75\%. This
non-destructive methodology represents a significant advancement in
reproductive medicine by enabling real-time sperm selection based on DNA
integrity for clinical diagnostic and therapeutic applications.

</details>


### [167] [Multiview Manifold Evidential Fusion for PolSAR Image Classification](https://arxiv.org/abs/2510.11171)
*Junfei Shi,Haojia Zhang,Haiyan Jin,Junhuai Li,Xiaogang Song,Yuanfan Guo,Haonan Su,Weisi Lin*

Main category: cs.CV

TL;DR: 提出了一种新的多视图流形证据融合（MMEFnet）方法，用于融合PolSAR协方差矩阵和多特征，以提高图像分类的准确性、鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的融合策略通常忽略了两种互补视图（协方差矩阵和多特征）位于不同流形上的几何结构差异，并且忽视了不同视图的重要性变化和模型不确定性，导致预测不可靠。

Method: 1.将协方差矩阵和多特征分别表示在HPD流形和Grassmann流形上。2.构建两种不同的核度量学习网络来学习它们的流形表示。3.使用基于Dempster-Shafer理论的证据融合策略来整合证据，并量化每个视图的不确定性，以实现更可靠的分类。

Result: 在三个真实的PolSAR数据集上的广泛实验表明，该方法在准确性、鲁棒性和可解释性方面优于现有方法。

Conclusion: MMEFnet通过整合PolSAR流形学习和证据融合，提供了一种有效融合不同视图的框架，能够进行更可靠和可解释的分类。

Abstract: Polarimetric Synthetic Aperture Radar (PolSAR) covariance matrices and their
extracted multi-features - such as scattering angle, entropy, texture, and
boundary descriptors - provide complementary and physically interpretable
information for image classification. Traditional fusion strategies typically
concatenate these features or employ deep learning networks to combine them.
However, the covariance matrices and multi-features, as two complementary
views, lie on different manifolds with distinct geometric structures. Existing
fusion methods also overlook the varying importance of different views and
ignore uncertainty, often leading to unreliable predictions. To address these
issues, we propose a Multiview Manifold Evidential Fusion (MMEFnet) method to
effectively fuse these two views. It gives a new framework to integrate PolSAR
manifold learning and evidence fusion into a unified architecture.
Specifically, covariance matrices are represented on the Hermitian Positive
Definite (HPD) manifold, while multi-features are modeled on the Grassmann
manifold. Two different kernel metric learning networks are constructed to
learn their manifold representations. Subsequently, a trusted multiview
evidence fusion, replacing the conventional softmax classifier, estimates
belief mass and quantifies the uncertainty of each view from the learned deep
features. Finally, a Dempster-Shafer theory-based fusion strategy combines
evidence, enabling a more reliable and interpretable classification. Extensive
experiments on three real-world PolSAR datasets demonstrate that the proposed
method consistently outperforms existing approaches in accuracy, robustness,
and interpretability.

</details>


### [168] [CoPRS: Learning Positional Prior from Chain-of-Thought for Reasoning Segmentation](https://arxiv.org/abs/2510.11173)
*Zhenyu Lu,Liupeng Li,Jinpeng Wang,Yan Feng,Bin Chen,Ke Chen,Yaowei Wang*

Main category: cs.CV

TL;DR: CoPRS是一个多模态的链式思考（MCoT）定位感知模型，通过可微分的热图将语言推理与分割联系起来，提高了可解释性和分割精度，并在RefCOCO和ReasonSeg数据集上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理分割方法要么直接将语言模型的隐藏特征连接到掩码解码器，要么表示文本中的位置，这限制了可解释性和语义细节。

Method: 提出CoPRS模型，利用多模态链式思考（MCoT）和可微分的热图作为定位先验，将语言推理与分割联系起来。通过学习到的注意力机制聚合图像和文本特征，生成热图，然后由轻量级解码器生成精确掩码。

Result: CoPRS在RefCOCO系列和ReasonSeg数据集上匹配或超过了现有最佳报告指标，并且在验证集和测试集上均达到了或超过了先前最先进的性能。实验表明，热图质量对掩码质量有显著影响。

Conclusion: CoPRS在连接推理和分割方面具有实用性，其推理驱动的注意力集中和精确的掩码预测能力显示出优势。

Abstract: Existing works on reasoning segmentation either connect hidden features from
a language model directly to a mask decoder or represent positions in text,
which limits interpretability and semantic detail. To solve this, we present
CoPRS, a Multi-modal Chain-of-Thought (MCoT)-based positional perception model
that bridges language reasoning to segmentation through a differentiable and
interpretable positional prior instantiated as a heatmap. By making the
reasoning process clear via MCoT and expressing it as a dense, differentiable
heatmap, this interface enhances interpretability and diagnostic analysis and
yields more concentrated evidence on the target. A learnable concentration
token aggregates features of the image and reasoning text to generate this
positional prior, which is decoded to precise masks through a lightweight
decoder, providing a direct connection between reasoning and segmentation.
Across the RefCOCO series and ReasonSeg, CoPRS matches or surpasses the best
reported metrics on each standard split under comparable protocols, with
performance at or above prior state of the art across both validation and test
partitions. Extensive experiments reveal that the quality of the heatmap
strongly influences the resulting mask quality, supporting a consistent
association between the reasoning output and downstream mask generation.
Collectively, these findings support the utility of this paradigm in bridging
reasoning and segmentation and show advantages in concentration driven by
reasoning and predicting masks more precisely. Code, checkpoints and logs are
released at https://github.com/ZhenyuLU-Heliodore/CoPRS.git.

</details>


### [169] [Reliable Cross-modal Alignment via Prototype Iterative Construction](https://arxiv.org/abs/2510.11175)
*Xiang Ma,Litian Xu,Lexin Fang,Caiming Zhang,Lizhen Cui*

Main category: cs.CV

TL;DR: PICO框架通过量化和加权特征列的语义概率来抑制跨模态对齐中的风格干扰。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态对齐方法忽略了风格信息对语义信息的影响，导致信息偏差或损失。

Method: 提出PICO框架，量化特征列的语义概率并用作嵌入交互的权重；通过基于性能反馈的加权函数进行原型迭代构建，以确保语义概率的可靠性。

Result: PICO框架在多个基准和模型骨干上进行了广泛实验，表现优于最先进的方法5.2%-14.1%。

Conclusion: PICO框架能够有效抑制风格干扰，提高跨模态对齐的性能。

Abstract: Cross-modal alignment is an important multi-modal task, aiming to bridge the
semantic gap between different modalities. The most reliable fundamention for
achieving this objective lies in the semantic consistency between matched
pairs. Conventional methods implicitly assume embeddings contain solely
semantic information, ignoring the impact of non-semantic information during
alignment, which inevitably leads to information bias or even loss. These
non-semantic information primarily manifest as stylistic variations in the
data, which we formally define as style information. An intuitive approach is
to separate style from semantics, aligning only the semantic information.
However, most existing methods distinguish them based on feature columns, which
cannot represent the complex coupling relationship between semantic and style
information. In this paper, we propose PICO, a novel framework for suppressing
style interference during embedding interaction. Specifically, we quantify the
probability of each feature column representing semantic information, and
regard it as the weight during the embedding interaction. To ensure the
reliability of the semantic probability, we propose a prototype iterative
construction method. The key operation of this method is a performance
feedback-based weighting function, and we have theoretically proven that the
function can assign higher weight to prototypes that bring higher performance
improvements. Extensive experiments on various benchmarks and model backbones
demonstrate the superiority of PICO, outperforming state-of-the-art methods by
5.2\%-14.1\%.

</details>


### [170] [G2L:From Giga-Scale to Cancer-Specific Large-Scale Pathology Foundation Models via Knowledge Distillation](https://arxiv.org/abs/2510.11176)
*Yesung Cho,Sungmin Lee,Geongyu Lee,Minkyung Lee,Jongbae Park,Dongmyung Shin*

Main category: cs.CV

TL;DR: G2L框架通过知识蒸馏，使参数量仅为万亿级模型的15%的大模型在癌症相关任务上达到甚至超越万亿级模型的性能，同时降低了计算成本和提高了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 万亿级病理基础模型在训练数据、癌症类型和模型规模上进行扩展可以提升性能，但其巨大的计算成本阻碍了实际应用。

Method: 提出G2L框架，利用知识蒸馏技术，仅使用1000张目标癌症病理切片（如乳腺癌、前列腺癌等），将万亿级模型的知识迁移到大模型（参数量为万亿级模型的15%）中。

Result: 蒸馏后的大模型在多个基准测试中超越了同等规模的最先进模型，并在某些基准测试中优于作为教师的万亿级模型和超大规模模型。此外，蒸馏模型还表现出更高的鲁棒性指数，对来自多机构的图像变化的抵抗能力更强。

Conclusion: 所提出的G2L框架为大模型提供了一种数据和参数高效的方法，可以在不承担高昂计算成本的情况下，实现万亿级模型水平的癌症特定应用性能。

Abstract: Recent studies in pathology foundation models have shown that scaling
training data, diversifying cancer types, and increasing model size
consistently improve their performance. However, giga-scale foundation models,
which are trained on hundreds of thousands of slides covering tens of cancer
types and contain billions of parameters, pose significant challenges for
practical use due to their tremendous computational costs in both development
and deployment. In this work, we present a novel strategy, named the G2L
framework, to increase the performance of large-scale foundation models, which
consist of only $15\%$ of the parameters of giga-scale models, to a comparable
performance level of giga-scale models in cancer-specific tasks. Our approach
applies knowledge distillation, transferring the capabilities of a giga-scale
model to a large-scale model, using just 1K pathology slides of a target cancer
(e.g., breast, prostate, etc.). The resulting distilled model not only
outperformed state-of-the-art models of the same size (i.e., large-scale)
across several benchmarks but also, interestingly, surpassed the giga-scale
teacher and huge-scale models in some benchmarks. In addition, the distilled
model exhibited a higher robustness index, indicating improved resilience to
image variations originating from multiple institutions. These findings suggest
that the proposed distillation approach for a large-scale model is a data- and
parameter-efficient way to achieve giga-scale-level performance for
cancer-specific applications without prohibitive computational burden.

</details>


### [171] [BLEnD-Vis: Benchmarking Multimodal Cultural Understanding in Vision Language Models](https://arxiv.org/abs/2510.11178)
*Bryan Chen Zhengyu Tan,Zheng Weihua,Zhengyuan Liu,Nancy F. Chen,Hwaran Lee,Kenny Tsu Wei Choo,Roy Ka-Wei Lee*

Main category: cs.CV

TL;DR: BLEnD-Vis 是一个评估视觉语言模型 (VLM) 在跨语言和跨模态理解文化知识方面的鲁棒性的新基准，结果显示当前 VLM 在文化理解方面存在不足，尤其是在低资源地区，并为未来 VLM 的发展指明了方向。


<details>
  <summary>Details</summary>
Motivation: 评估现有视觉语言模型 (VLM) 在理解文化背景知识方面的鲁棒性和可迁移性，现有评估方法存在不足。

Method: 引入 BLEnD-Vis 基准，该基准包含 313 个文化问题模板，涵盖 16 个地区，并生成三种 MCQs 格式：纯文本（区域->实体）、纯文本（实体->区域）以及视觉问答（VQA）风格。数据集包含 4,916 张图像和 21,000 多个 MCQs。

Result: 当前 VLM 在文化知识理解方面表现出显著的脆弱性，在语言重述下性能下降；虽然视觉线索通常能提高性能，但跨模态一致性较低，表明在整合文本和视觉理解方面存在挑战，尤其是在低资源地区。

Conclusion: BLEnD-Vis 提供了一个关键的测试平台，用于系统地分析文化的鲁棒性和多模态基础，揭示了 VLM 在文化理解方面的局限性，并为开发更具文化能力的 VLM 提供了指导。

Abstract: As vision-language models (VLMs) are deployed globally, their ability to
understand culturally situated knowledge becomes essential. Yet, existing
evaluations largely assess static recall or isolated visual grounding, leaving
unanswered whether VLMs possess robust and transferable cultural understanding.
We introduce BLEnD-Vis, a multimodal, multicultural benchmark designed to
evaluate the robustness of everyday cultural knowledge in VLMs across
linguistic rephrasings and visual modalities. Building on the BLEnD dataset,
BLEnD-Vis constructs 313 culturally grounded question templates spanning 16
regions and generates three aligned multiple-choice formats: (i) a text-only
baseline querying from Region $\to$ Entity, (ii) an inverted text-only variant
(Entity $\to$ Region), and (iii) a VQA-style version of (ii) with generated
images. The resulting benchmark comprises 4,916 images and over 21,000
multiple-choice question (MCQ) instances, validated through human annotation.
BLEnD-Vis reveals significant fragility in current VLM cultural knowledge;
models exhibit performance drops under linguistic rephrasing and, whilst visual
cues often aid performance, low cross-modal consistency highlights challenges
in robustly integrating textual and visual understanding, particularly for
lower-resource regions. BLEnD-Vis thus provides a crucial testbed for
systematically analysing cultural robustness and multimodal grounding, exposing
limitations and guiding the development of more culturally competent VLMs.

</details>


### [172] [Saudi Sign Language Translation Using T5](https://arxiv.org/abs/2510.11183)
*Ali Alhejab,Tomas Zelezny,Lamya Alkanhal,Ivan Gruber,Yazeed Alharbi,Jakub Straka,Vaclav Javorek,Marek Hruz,Badriah Alkalifah,Ahmed Ali*

Main category: cs.CV

TL;DR: 本研究使用T5模型和包含面部遮挡等特殊情况的新型数据集，对沙特手语(SSL)翻译进行了探索。研究发现，在包含YouTubeASL数据的预训练可以显著提升模型性能（BLEU-4分数约提高3倍），证明了跨语言迁移学习在手语模型中的可行性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索使用T5模型进行沙特手语(SSL)翻译，并解决SSL数据集中存在的独特挑战，例如面部遮挡，同时评估跨语言迁移学习的有效性。

Method: 本研究使用T5模型，并比较了在YouTubeASL数据集上预训练的模型与直接在SSL数据集上训练的模型。研究采用了包含三种具有挑战性的测试协议的新型SSL数据集，并评估了模型在处理面部遮挡等SSL独有特征时的表现。

Result: 实验结果表明，在YouTubeASL数据集上进行预训练能够显著提高SSL翻译模型的性能，BLEU-4分数大约提高了3倍，这表明跨语言迁移学习在手语模型中是有效的。

Conclusion: 本研究得出结论，利用大规模美国手语(ASL)数据预训练模型能够有效提升沙特手语(SSL)翻译的性能，并为开发更有效的手语翻译系统提供了见解。

Abstract: This paper explores the application of T5 models for Saudi Sign Language
(SSL) translation using a novel dataset. The SSL dataset includes three
challenging testing protocols, enabling comprehensive evaluation across
different scenarios. Additionally, it captures unique SSL characteristics, such
as face coverings, which pose challenges for sign recognition and translation.
In our experiments, we investigate the impact of pre-training on American Sign
Language (ASL) data by comparing T5 models pre-trained on the YouTubeASL
dataset with models trained directly on the SSL dataset. Experimental results
demonstrate that pre-training on YouTubeASL significantly improves models'
performance (roughly $3\times$ in BLEU-4), indicating cross-linguistic
transferability in sign language models. Our findings highlight the benefits of
leveraging large-scale ASL data to improve SSL translation and provide insights
into the development of more effective sign language translation systems. Our
code is publicly available at our GitHub repository.

</details>


### [173] [FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2510.11190)
*Shengming Yuan,Xinyu Lyu,Shuailong Wang,Beitao Chen,Jingkuan Song,Lianli Gao*

Main category: cs.CV

TL;DR: 现有方法在多模态大语言模型（MLLMs）的忠实度与创造力之间存在固有的权衡，但缺乏灵活调控联想推理能力。本文提出灵活联想控制（FlexAC）框架，通过调控中间层表征来控制联想推理强度，以平衡创造性指导和输出稳定性，并在创造性和幻觉减少方面取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏灵活调控多模态大语言模型（MLLMs）联想推理强度以适应不同任务（忠实度与创造性）的需求。

Method: 提出灵活联想控制（FlexAC）框架，该框架通过以下步骤调控MLLMs的联想行为：1. 诱导受幻觉引导的中间表征以编码联想方向。2. 构建联想转向向量（associative steering vectors）并自适应校准强度。3. 融合任务特定的联想向量以适应不同创造性任务。

Result: FlexAC 在 Creation-MMBench 上实现了高达 5.8 倍的创造力提升，在 CHAIR 上幻觉率降低了 29%，优于现有基线。

Conclusion: FlexAC 框架能够灵活有效地控制MLLMs的联想推理强度，平衡忠实度与创造性，提高了模型在不同任务上的适应性。

Abstract: Multimodal large language models (MLLMs) face an inherent trade-off between
faithfulness and creativity, as different tasks require varying degrees of
associative reasoning. However, existing methods lack the flexibility to
modulate this reasoning strength, limiting MLLMs' adaptability across factual
and creative scenarios. To bridge this gap, we propose equipping MLLMs with
mechanisms that enable flexible control over associative reasoning. We begin by
investigating the internal mechanisms underlying associative behavior in MLLMs
and find that: (1) middle layers play a pivotal role in shaping model's
associative tendencies, (2) modifying representations in these layers
effectively regulates associative reasoning strength, and (3) hallucinations
can be exploited to derive steering vectors that guide this modulation.
Building on these findings, we introduce Flexible Association Control (FlexAC),
a lightweight and training-free framework for modulating associative behavior
in MLLMs. FlexAC first induces hallucination-guided intermediate
representations to encode associative directions. Then, it selects
high-association instances to construct effective associative steering vectors,
whose strengths are adaptively calibrated to balance creative guidance with
output stability. Finally, recognizing the multi-dimensional nature of
associative reasoning, FlexAC incorporates task-specific associative vectors
derived from a forward pass on a few target-domain samples, enabling models to
follow diverse associative directions and better adapt to creative tasks.
Notably, our method achieves up to a 5.8x improvement in creativity on
Creation-MMBench and a 29% reduction in hallucination rate on CHAIR, surpassing
existing baselines and demonstrating its effectiveness in enabling flexible
control over associative reasoning in MLLMs. Our code is available at
https://github.com/ylhz/FlexAC.

</details>


### [174] [Class Prototypes based Contrastive Learning for Classifying Multi-Label and Fine-Grained Educational Videos](https://arxiv.org/abs/2510.11204)
*Rohit Gupta,Anirban Roy,Claire Christensen,Sujeong Kim,Sarah Gerard,Madeline Cincebeaux,Ajay Divakaran,Todd Grindal,Mubarak Shah*

Main category: cs.CV

TL;DR: 本篇论文提出了一种用于检测在线视频中教育内容（特别是读写和数学）的方法，该方法结合了监督对比学习和多模态 Transformer 网络，并发布了一个名为 APPROVE 的数据集来评估该方法。


<details>
  <summary>Details</summary>
Motivation: 鉴于儿童在线媒体消费的增长，需要数据驱动的工具来帮助教育工作者筛选适合幼儿的教育内容。

Method: 提出了一种基于类别原型（class prototypes）的监督对比学习方法，并结合多模态 Transformer 网络来处理细粒度的多标签分类问题，同时考虑视频的视觉和音频线索。

Result: 所提出的方法在 APPROVE 数据集以及 YouTube-8M 和 COIN 等其他基准测试中，表现优于现有的强有力基线方法。

Conclusion: 该方法能够有效地检测在线视频中的教育内容，并且所发布的数据集 APPROVE 将有助于该领域的研究。

Abstract: The recent growth in the consumption of online media by children during early
childhood necessitates data-driven tools enabling educators to filter out
appropriate educational content for young learners. This paper presents an
approach for detecting educational content in online videos. We focus on two
widely used educational content classes: literacy and math. For each class, we
choose prominent codes (sub-classes) based on the Common Core Standards. For
example, literacy codes include `letter names', `letter sounds', and math codes
include `counting', `sorting'. We pose this as a fine-grained multilabel
classification problem as videos can contain multiple types of educational
content and the content classes can get visually similar (e.g., `letter names'
vs `letter sounds'). We propose a novel class prototypes based supervised
contrastive learning approach that can handle fine-grained samples associated
with multiple labels. We learn a class prototype for each class and a loss
function is employed to minimize the distances between a class prototype and
the samples from the class. Similarly, distances between a class prototype and
the samples from other classes are maximized. As the alignment between visual
and audio cues are crucial for effective comprehension, we consider a
multimodal transformer network to capture the interaction between visual and
audio cues in videos while learning the embedding for videos. For evaluation,
we present a dataset, APPROVE, employing educational videos from YouTube
labeled with fine-grained education classes by education researchers. APPROVE
consists of 193 hours of expert-annotated videos with 19 classes. The proposed
approach outperforms strong baselines on APPROVE and other benchmarks such as
Youtube-8M, and COIN. The dataset is available at
https://github.com/rohit-gupta/MMContrast/tree/main/APPROVE

</details>


### [175] [Investigating Identity Signals in Conversational Facial Dynamics via Disentangled Expression Features](https://arxiv.org/abs/2510.11223)
*Masoumeh Chapariniya,Pierre Vuillecard,Jean-Marc Odobez,Volker Dellwo,Teodora Vukovic*

Main category: cs.CV

TL;DR: 通过分析面部表情的动态成分来识别个体，即使在忽略静态面部特征的情况下也能实现。


<details>
  <summary>Details</summary>
Motivation: 研究个体是否能仅通过面部表情的纯动态成分来识别，而与静态面部外观无关。

Method: 利用FLAME 3D可变形模型分离面部形状和表情动态，并从对话视频中提取仅包含表情和下颌系数的逐帧参数。使用Conformer模型和监督对比学习在CANDOR数据集上进行1,429类别的分类。

Result: 在CANDOR数据集上，Conformer模型达到了61.14%的准确率，远高于随机猜测（458倍）。引入的信噪比（DNR）量化了形状-表情分离的可靠性，并与识别性能呈强负相关。

Conclusion: 对话中的面部动态包含强烈的个体身份信息，这对于社会感知和临床评估具有潜在的应用价值。

Abstract: This work investigates whether individuals can be identified solely through
the pure dynamical components of their facial expressions, independent of
static facial appearance. We leverage the FLAME 3D morphable model to achieve
explicit disentanglement between facial shape and expression dynamics,
extracting frame-by-frame parameters from conversational videos while retaining
only expression and jaw coefficients. On the CANDOR dataset of 1,429 speakers
in naturalistic conversations, our Conformer model with supervised contrastive
learning achieves 61.14\%accuracy on 1,429-way classification -- 458 times
above chance -- demonstrating that facial dynamics carry strong identity
signatures. We introduce a drift-to-noise ratio (DNR) that quantifies the
reliability of shape expression separation by measuring across-session shape
changes relative to within-session variability. DNR strongly negatively
correlates with recognition performance, confirming that unstable shape
estimation compromises dynamic identification. Our findings reveal
person-specific signatures in conversational facial dynamics, with implications
for social perception and clinical assessment.

</details>


### [176] [LightPneumoNet: Lightweight Pneumonia Classifier](https://arxiv.org/abs/2510.11232)
*Neilansh Chauhan,Piyush Kumar Gupta,Faraz Doja*

Main category: cs.CV

TL;DR: LightPneumoNet是一个高效轻量级的CNN模型，用于从胸部X光片诊断肺炎，参数量少，内存占用低，在独立测试集中表现出色，准确率达到0.942，F1分数0.96，尤其在检测真阳性病例方面具有极高敏感性（0.99），有望在资源受限环境下普及AI辅助诊断。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境下部署大型、计算量大的深度学习模型进行肺炎诊断面临挑战，因此需要一个高效、轻量级的模型。

Method: 该研究从头开始构建了一个名为LightPneumoNet的轻量级卷积神经网络（CNN）。模型在包含5,856张胸部X光片的公开数据集上进行训练，预处理包括调整图像大小至224x224、灰度转换和像素归一化，并使用数据增强（旋转、缩放、剪切）技术防止过拟合。该自定义架构包含四个堆叠的卷积层块，仅有388,082个可训练参数，内存占用仅为1.48 MB。

Result: 在独立测试集上，LightPneumoNet取得了0.942的总体准确率、0.92的精确率和0.96的F1分数。关键的是，该模型实现了0.99的敏感性（召回率），在识别真阳性肺炎病例方面接近完美，并最大限度地减少了临床上显著的假阴性。

Conclusion: LightPneumoNet模型的高效性使其能够部署在低成本硬件上，使资源匮乏的诊所也能获得先进的计算机辅助诊断能力，并可作为可靠的辅助诊断工具，以改善患者的治疗效果。

Abstract: Effective pneumonia diagnosis is often challenged by the difficulty of
deploying large, computationally expensive deep learning models in
resource-limited settings. This study introduces LightPneumoNet, an efficient,
lightweight convolutional neural network (CNN) built from scratch to provide an
accessible and accurate diagnostic solution for pneumonia detection from chest
X-rays. Our model was trained on a public dataset of 5,856 chest X-ray images.
Preprocessing included image resizing to 224x224, grayscale conversion, and
pixel normalization, with data augmentation (rotation, zoom, shear) to prevent
overfitting. The custom architecture features four blocks of stacked
convolutional layers and contains only 388,082 trainable parameters, resulting
in a minimal 1.48 MB memory footprint. On the independent test set, our model
delivered exceptional performance, achieving an overall accuracy of 0.942,
precision of 0.92, and an F1-Score of 0.96. Critically, it obtained a
sensitivity (recall) of 0.99, demonstrating a near-perfect ability to identify
true pneumonia cases and minimize clinically significant false negatives.
Notably, LightPneumoNet achieves this high recall on the same dataset where
existing approaches typically require significantly heavier architectures or
fail to reach comparable sensitivity levels. The model's efficiency enables
deployment on low-cost hardware, making advanced computer-aided diagnosis
accessible in underserved clinics and serving as a reliable second-opinion tool
to improve patient outcomes.

</details>


### [177] [Nepali Sign Language Characters Recognition: Dataset Development and Deep Learning Approaches](https://arxiv.org/abs/2510.11243)
*Birat Poudel,Satyam Ghimire,Sijan Bhattarai,Saurav Bhandari,Suramya Sharma Dahal*

Main category: cs.CV

TL;DR: 本研究发布了首个尼泊尔手语（NSL）基准数据集，包含36个类别、每个类别1500个样本，并使用MobileNetV2和ResNet50模型进行了识别性能评估，准确率分别达到90.45%和88.78%，展示了卷积神经网络在资源匮乏的手语识别任务中的潜力。


<details>
  <summary>Details</summary>
Motivation: 为听力与言语障碍者提供重要的沟通工具，但像尼泊尔手语（NSL）这样的代表性不足的手语，其数字语言数据集资源稀缺。

Method: 创建了一个包含36个手语类别、每个类别1500个样本的NSL基准数据集。在数据集上对MobileNetV2和ResNet50模型进行了微调，以评估识别性能。

Result: MobileNetV2和ResNet50模型在NSL数据集上分别达到了90.45%和88.78%的分类准确率。

Conclusion: 卷积神经网络在手语识别任务中，尤其是在资源匮乏的情况下，是有效的。本研究首次系统性地构建NSL基准数据集并评估深度学习方法，展示了迁移学习和微调在推进未充分研究的手语研究方面的潜力。

Abstract: Sign languages serve as essential communication systems for individuals with
hearing and speech impairments. However, digital linguistic dataset resources
for underrepresented sign languages, such as Nepali Sign Language (NSL), remain
scarce. This study introduces the first benchmark dataset for NSL, consisting
of 36 gesture classes with 1,500 samples per class, designed to capture the
structural and visual features of the language. To evaluate recognition
performance, we fine-tuned MobileNetV2 and ResNet50 architectures on the
dataset, achieving classification accuracies of 90.45% and 88.78%,
respectively. These findings demonstrate the effectiveness of convolutional
neural networks in sign recognition tasks, particularly within low-resource
settings. To the best of our knowledge, this work represents the first
systematic effort to construct a benchmark dataset and assess deep learning
approaches for NSL recognition, highlighting the potential of transfer learning
and fine-tuning for advancing research in underexplored sign languages.

</details>


### [178] [DTEA: Dynamic Topology Weaving and Instability-Driven Entropic Attenuation for Medical Image Segmentation](https://arxiv.org/abs/2510.11259)
*Weixuan Li,Quanjun Li,Guang Yu,Song Yang,Zimeng Li,Chi-Man Pun,Yupeng Liu,Xuhang Chen*

Main category: cs.CV

TL;DR: DTEA模型通过STR和EPG模块改进了医学图像分割中的跳跃连接，提高了结构和语义表示，增强了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法在结构表示和上下文建模方面存在不足，影响了在复杂临床场景下的泛化能力。

Method: 提出DTEA模型，包含新的跳跃连接框架，利用STR模块将多尺度语义特征重组为动态超图，以更好地建模跨分辨率的解剖依赖性；利用EPG模块评估通道稳定性并过滤高熵通道，以强调临床重要区域和改善空间注意力。

Result: 在三个基准数据集上的广泛实验表明，DTEA模型在分割精度和跨临床设置的泛化能力方面均优于现有方法。

Conclusion: DTEA模型通过其创新的跳跃连接框架，有效解决了医学图像分割中的挑战，提高了分割性能和泛化能力。

Abstract: In medical image segmentation, skip connections are used to merge global
context and reduce the semantic gap between encoder and decoder. Current
methods often struggle with limited structural representation and insufficient
contextual modeling, affecting generalization in complex clinical scenarios. We
propose the DTEA model, featuring a new skip connection framework with the
Semantic Topology Reconfiguration (STR) and Entropic Perturbation Gating (EPG)
modules. STR reorganizes multi-scale semantic features into a dynamic
hypergraph to better model cross-resolution anatomical dependencies, enhancing
structural and semantic representation. EPG assesses channel stability after
perturbation and filters high-entropy channels to emphasize clinically
important regions and improve spatial attention. Extensive experiments on three
benchmark datasets show our framework achieves superior segmentation accuracy
and better generalization across various clinical settings. The code is
available at
\href{https://github.com/LWX-Research/DTEA}{https://github.com/LWX-Research/DTEA}.

</details>


### [179] [Exploring and Leveraging Class Vectors for Classifier Editing](https://arxiv.org/abs/2510.11268)
*Jaeik Kim,Jaeyoung Do*

Main category: cs.CV

TL;DR: Class Vectors are a new method for editing image classifiers by capturing class-specific representation adjustments in the latent space, enabling flexible editing for tasks like unlearning, environmental adaptation, and defense.


<details>
  <summary>Details</summary>
Motivation: Existing methods for editing image classifiers are difficult to use for tasks like forgetting specific classes or adapting to distribution shifts, often requiring extensive retraining. Class Vectors aim to overcome these challenges by providing a more flexible and efficient editing approach.

Method: Class Vectors capture class-specific representation adjustments in the latent space during fine-tuning. These vectors can be used to steer latent features or be mapped to weight space to update decision boundaries. Their linearity and orthogonality allow for efficient editing through class arithmetic.

Result: Class Vectors effectively capture semantic shifts for each class and enable flexible classifier editing. They have been validated in applications including unlearning, environmental adaptation, adversarial defense, and adversarial trigger optimization.

Conclusion: Class Vectors offer a novel and efficient approach to editing image classifiers, outperforming existing methods in flexibility and applicability to a wider range of tasks.

Abstract: Image classifiers play a critical role in detecting diseases in medical
imaging and identifying anomalies in manufacturing processes. However, their
predefined behaviors after extensive training make post hoc model editing
difficult, especially when it comes to forgetting specific classes or adapting
to distribution shifts. Existing classifier editing methods either focus
narrowly on correcting errors or incur extensive retraining costs, creating a
bottleneck for flexible editing. Moreover, such editing has seen limited
investigation in image classification. To overcome these challenges, we
introduce Class Vectors, which capture class-specific representation
adjustments during fine-tuning. Whereas task vectors encode task-level changes
in weight space, Class Vectors disentangle each class's adaptation in the
latent space. We show that Class Vectors capture each class's semantic shift
and that classifier editing can be achieved either by steering latent features
along these vectors or by mapping them into weight space to update the decision
boundaries. We also demonstrate that the inherent linearity and orthogonality
of Class Vectors support efficient, flexible, and high-level concept editing
via simple class arithmetic. Finally, we validate their utility in applications
such as unlearning, environmental adaptation, adversarial defense, and
adversarial trigger optimization.

</details>


### [180] [EEMS: Edge-Prompt Enhanced Medical Image Segmentation Based on Learnable Gating Mechanism](https://arxiv.org/abs/2510.11287)
*Han Xia,Quanjun Li,Qian Li,Zimeng Li,Hongbin Ye,Yupeng Liu,Haolun Li,Xuhang Chen*

Main category: cs.CV

TL;DR: EEMS模型通过结合边缘感知增强单元（EAEU）和多尺度提示生成单元（MSPGU），在医学图像分割中提高了准确性和鲁棒性，尤其在处理模糊边缘和背景噪声方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在诊断、治疗规划和疾病监测中至关重要，但面临边缘模糊和背景噪声等挑战。

Method: 提出了一种名为EEMS的新模型，该模型结合了边缘感知增强单元（EAEU）和多尺度提示生成单元（MSPGU）。EAEU通过多频特征提取来增强边缘感知，MSPGU则利用提示引导方法整合了高级语义和低级空间特征。最后，双源自适应门控融合单元（DAGFU）融合了来自EAEU的边缘特征和来自MSPGU的语义特征。

Result: 在ISIC2018等数据集上的测试表明，EEMS模型在分割准确性和鲁棒性方面表现优于现有方法。

Conclusion: EEMS模型能够有效提高医学图像分割的准确性和鲁棒性，可作为有价值的临床工具。

Abstract: Medical image segmentation is vital for diagnosis, treatment planning, and
disease monitoring but is challenged by complex factors like ambiguous edges
and background noise. We introduce EEMS, a new model for segmentation,
combining an Edge-Aware Enhancement Unit (EAEU) and a Multi-scale Prompt
Generation Unit (MSPGU). EAEU enhances edge perception via multi-frequency
feature extraction, accurately defining boundaries. MSPGU integrates high-level
semantic and low-level spatial features using a prompt-guided approach,
ensuring precise target localization. The Dual-Source Adaptive Gated Fusion
Unit (DAGFU) merges edge features from EAEU with semantic features from MSPGU,
enhancing segmentation accuracy and robustness. Tests on datasets like ISIC2018
confirm EEMS's superior performance and reliability as a clinical tool.

</details>


### [181] [Human Uncertainty-Aware Data Selection and Automatic Labeling in Visual Question Answering](https://arxiv.org/abs/2510.11295)
*Jian Lan,Zhicheng Liu,Udo Schlegel,Raoyuan Zhao,Yihong Liu,Hinrich Schütze,Michael A. Hedderich,Thomas Seidl*

Main category: cs.CV

TL;DR: 为了解决大型视觉语言模型（VLM）在视觉问答（VQA）中对大规模监督微调（SFT）的依赖，以及忽略真实数据中存在的人类不确定性（HU）的问题，研究提出了一个名为HaDola的框架。该框架通过数据选择和自动标注，有效识别和利用HU信息，减少了对昂贵标注的依赖，提高了模型的准确性和校准性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLM）在视觉问答（VQA）任务上表现出色，但其性能很大程度上依赖于成本高昂的监督微调（SFT）和大规模标注数据集。然而，真实数据集普遍存在人类不确定性（HU），即标注者在标注时的信心不一。标准SFT方法忽略了HU分布，仅优化最高频标签，这引发了两个关键问题：HU如何影响SFT，以及如何有效利用HU进行模型训练。

Method: 本研究提出了一个名为HaDola（人类不确定性感知的数据选择和自动标注框架）的方法。该框架分四个阶段进行：区分（识别有害样本）、自标注（优先选择信息量大的样本）、错误触发（利用少量种子数据进行迭代训练）和训练（最终模型训练）。该框架旨在减少对昂贵HU标注的依赖，提高VLM的准确性和校准性。

Result: 通过在VQAv2和VizWiz数据集上进行的大量实验，HaDola方法在准确性和校准性方面均能达到或超越最先进的基线模型，并且使用的训练数据量更少。研究发现，高HU样本不仅贡献有限，甚至可能损害模型性能，并且简单地在全部数据集上训练会导致模型校准不佳，无法捕捉HU分布。

Conclusion: 本研究强调了在SFT中显式地对HU进行建模的重要性。研究表明，更有效地利用HU信息比单纯扩大数据集规模更能提升模型性能，为未来VLM的训练提供了新的方向。

Abstract: Large vision-language models (VLMs) achieve strong performance in Visual
Question Answering but still rely heavily on supervised fine-tuning (SFT) with
massive labeled datasets, which is costly due to human annotations. Crucially,
real-world datasets often exhibit human uncertainty (HU) -- variation in human
confidence across annotations -- but standard SFT simply optimizes toward the
most frequent label, disregarding HU distributions. This leaves two open
questions: How does HU affect SFT, and how can HU be effectively leveraged in
training? In this work, we first conduct a systematic evaluation of VLMs across
varying HU levels. We have two key findings: (i) surprisingly, high-HU samples
contribute little or even degrade model performance, and (ii) naively training
on the full dataset yields under-calibrated models that fail to capture HU
distributions. Motivated by these findings, we introduce HaDola, a human
uncertainty-aware data selection and automatic labeling framework. HaDola
operates in four stages -- discriminate, self-annotate, error trigger, and
training -- to iteratively identify harmful samples, prioritize informative
ones, and bootstrap from a small seed set (5\% of data). Our approach
substantially reduces reliance on costly HU annotations and makes VLMs more
accurate and better calibrated. Extensive experiments on VQAv2 and VizWiz
datasets demonstrate that HaDola consistently matches or outperforms
state-of-the-art baselines with less training data. Our work highlights the
importance of explicitly modeling HU in SFT, suggesting that better utilization
of HU is more effective than merely scaling up dataset size.

</details>


### [182] [$Δ\mathrm{Energy}$: Optimizing Energy Change During Vision-Language Alignment Improves both OOD Detection and OOD Generalization](https://arxiv.org/abs/2510.11296)
*Lin Zhu,Yifeng Yang,Xinbing Wang,Qinying Gu,Nanyang Ye*

Main category: cs.CV

TL;DR: 该论文提出了一种名为ΔEnergy的新型OOD（分布外）检测分数，该分数通过衡量视觉-语言模态重新对齐时的能量变化来显著优于传统方法。此外，该方法通过下界最大化（EBM）进一步提高了模型对协变量偏移的OOD泛化能力，并被证明能增强OOD检测和提高域一致性Hessian。该框架在OOD检测和泛化基准测试中表现出色，AUROC提高了10%到25%。


<details>
  <summary>Details</summary>
Motivation: 近期视觉-语言模型（VLMs）在快速适应下游任务方面取得了显著成功。然而，在实际应用中，VLMs会遇到分布内（ID）和分布外（OOD）数据。OOD数据可能包含图像风格变化的已知类别（协变量偏移）和测试时未见的类别（语义偏移）。因此，提高VLMs对协变量偏移OOD数据的泛化能力，并有效检测开放集语义偏移OOD类别至关重要。

Method: 本文提出了一种名为ΔEnergy的新型OOD分数，该分数通过直接降低最大余弦相似度到一个低值来实现视觉-语言模态的重新对齐，并观察到在此过程中能量发生了显著变化。此外，通过对ΔEnergy进行下界最大化（EBM），可以提高模型在协变量偏移下的OOD泛化能力。EBM被理论证明不仅能增强OOD检测，还能产生域一致的Hessian，这是OOD泛化的有力指标。基于这些发现，研究人员开发了一个统一的微调框架，以提高VLMs在OOD泛化和OOD检测方面的鲁棒性。

Result: 在具有挑战性的OOD检测和泛化基准测试中，所提出的方法表现出了优越性，其在AUROC方面超越了现有方法10%到25%。

Conclusion: 本文提出的ΔEnergy分数和EBM框架为提高VLMs在OOD检测和泛化方面的鲁棒性提供了一个统一有效的解决方案，并在实验中取得了显著的性能提升。

Abstract: Recent approaches for vision-language models (VLMs) have shown remarkable
success in achieving fast downstream adaptation. When applied to real-world
downstream tasks, VLMs inevitably encounter both the in-distribution (ID) data
and out-of-distribution (OOD) data. The OOD datasets often include both
covariate shifts (e.g., known classes with changes in image styles) and
semantic shifts (e.g., test-time unseen classes). This highlights the
importance of improving VLMs' generalization ability to covariate-shifted OOD
data, while effectively detecting open-set semantic-shifted OOD classes. In
this paper, inspired by the substantial energy change observed in closed-set
data when re-aligning vision-language modalities (specifically by directly
reducing the maximum cosine similarity to a low value), we introduce a novel
OOD score, named {\Delta}Energy. {\Delta}Energy significantly outperforms the
vanilla energy-based OOD score and provides a more reliable approach for OOD
detection. Furthermore, {\Delta}Energy can simultaneously improve OOD
generalization under covariate shifts, which is achieved by lower-bound
maximization for {\Delta}Energy (termed EBM). EBM is theoretically proven to
not only enhance OOD detection but also yields a domain-consistent Hessian,
which serves as a strong indicator for OOD generalization. Based on this
finding, we developed a unified fine-tuning framework that allows for improving
VLMs' robustness in both OOD generalization and OOD detection. Extensive
experiments on challenging OOD detection and generalization benchmarks
demonstrate the superiority of our method, outperforming recent approaches by
10% to 25% in AUROC.

</details>


### [183] [When Does Supervised Training Pay Off? The Hidden Economics of Object Detection in the Era of Vision-Language Models](https://arxiv.org/abs/2510.11302)
*Samer Al-Hamadani*

Main category: cs.CV

TL;DR: 监督学习目标检测（YOLO）在标准类别上准确率更高，但成本高昂；零样本视觉-语言模型（VLM，如Gemini Flash 2.5）在多样化产品类别上表现优于YOLO，且每检测成本低得多。


<details>
  <summary>Details</summary>
Motivation: 比较监督学习目标检测（YOLO）和零样本视觉-语言模型（VLM，如Gemini Flash 2.5）的成本效益，以确定何时选择哪种方法。

Method: 在COCO数据集和多样化的产品图片上进行系统性评估，并结合详细的总体拥有成本模型，进行定量分析，建立成本效益的临界阈值。

Result: 在标准类别上，YOLO准确率为91.2%，Gemini为68.5%，相差22.7个百分点，YOLO的成本为10,800美元（针对100类别系统）。然而，YOLO的优势仅在超过5500万次推理后才值得投资。在多样化产品类别上，Gemini准确率为52.3%（消费电子产品75-85%，稀有设备25-40%），而YOLO准确率为0%。Gemini的每检测成本远低于YOLO（0.00050美元 vs 0.143美元，基于10万次推理）。

Conclusion: 最优架构的选择取决于部署量、类别稳定性、预算和准确性要求，而非单纯的技术性能指标。决策框架应综合考虑这些因素。

Abstract: Object detection systems have traditionally relied on supervised learning
with manually annotated bounding boxes, achieving high accuracy at the cost of
substantial annotation investment. The emergence of Vision-Language Models
(VLMs) offers an alternative paradigm enabling zero-shot detection through
natural language queries, eliminating annotation requirements but operating
with reduced accuracy. This paper presents the first comprehensive
cost-effectiveness analysis comparing supervised detection (YOLO) with
zero-shot VLM inference (Gemini Flash 2.5). Through systematic evaluation on
1,000 stratified COCO images and 200 diverse product images spanning consumer
electronics and rare categories, combined with detailed Total Cost of Ownership
modeling, we establish quantitative break-even thresholds governing
architecture selection. Our findings reveal that supervised YOLO achieves 91.2%
accuracy versus 68.5% for zero-shot Gemini on standard categories, representing
a 22.7 percentage point advantage that costs $10,800 in annotation for
100-category systems. However, this advantage justifies investment only beyond
55 million inferences, equivalent to 151,000 images daily for one year.
Zero-shot Gemini demonstrates 52.3% accuracy on diverse product categories
(ranging from highly web-prevalent consumer electronics at 75-85% to rare
specialized equipment at 25-40%) where supervised YOLO achieves 0% due to
architectural constraints preventing detection of untrained classes. Cost per
Correct Detection analysis reveals substantially lower per-detection costs for
Gemini ($0.00050 vs $0.143) at 100,000 inferences despite accuracy deficits. We
develop decision frameworks demonstrating that optimal architecture selection
depends critically on deployment volume, category stability, budget
constraints, and accuracy requirements rather than purely technical performance
metrics.

</details>


### [184] [sketch2symm: Symmetry-aware sketch-to-shape generation via semantic bridging](https://arxiv.org/abs/2510.11303)
*Yan Zhou,Mingji Li,Xiantao Zeng,Jie Lin,Yuexia Zhou*

Main category: cs.CV

TL;DR: Sketch2Symm通过语义桥接（草图到图像转换）和对称性约束来从草图中生成几何一致的3D形状，并在Chamfer距离、Earth Mover's距离和F-Score方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于草图输入的抽象和稀疏性质，通常缺乏足够的语义和几何信息，因此基于草图的3D重建仍然是一项挑战性任务。

Method: Sketch2Symm采用两阶段生成方法，首先通过草图到图像转换引入语义桥接来丰富稀疏的草图表示，然后结合对称性约束作为几何先验来利用日常物体中常见的结构规律性。

Result: 在主流草图数据集上的实验表明，与现有的基于草图的重建方法相比，该方法在Chamfer距离、Earth Mover's距离和F-Score方面表现更优。

Conclusion: 所提出的语义桥接和感知对称性的设计被证明是有效的。

Abstract: Sketch-based 3D reconstruction remains a challenging task due to the abstract
and sparse nature of sketch inputs, which often lack sufficient semantic and
geometric information. To address this, we propose Sketch2Symm, a two-stage
generation method that produces geometrically consistent 3D shapes from
sketches. Our approach introduces semantic bridging via sketch-to-image
translation to enrich sparse sketch representations, and incorporates symmetry
constraints as geometric priors to leverage the structural regularity commonly
found in everyday objects. Experiments on mainstream sketch datasets
demonstrate that our method achieves superior performance compared to existing
sketch-based reconstruction methods in terms of Chamfer Distance, Earth Mover's
Distance, and F-Score, verifying the effectiveness of the proposed semantic
bridging and symmetry-aware design.

</details>


### [185] [DocReward: A Document Reward Model for Structuring and Stylizing](https://arxiv.org/abs/2510.11391)
*Junpeng Liu,Yuzhong Zhao,Bowen Cao,Jiayu Ding,Yilin Jia,Tengchao Lv,Yupan Huang,Shaohan Huang,Nan Yang,Li Dong,Lei Cui,Tao Ge,Xun Wang,Huitian Jiao,Sun Mao,FNU Kartik,Si-Qing Chen,Wai Lam,Furu Wei*

Main category: cs.CV

TL;DR: 该研究提出了DocReward，一个专注于文档结构和风格而非仅文本质量的文档奖励模型，并构建了一个包含117K配对文档的数据集DocPair。DocReward在评估和文档生成任务上均优于GPT-4o和GPT-5。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化文档生成工作主要关注文本质量，忽略了对可读性和参与度至关重要的视觉结构和风格，其主要原因是缺乏能够指导代理工作流生成具有更强结构和风格质量的文档的奖励模型。

Method: 提出了DocReward文档奖励模型，该模型基于文档的结构和风格进行评估。构建了一个包含117K配对文档（涵盖32个领域和267种文档类型）的多领域数据集DocPair，每个配对包含相同内容但专业度不同的文档。DocReward使用Bradley-Terry损失进行训练，以预测文档得分，并对与标注排名相矛盾的预测进行惩罚。

Result: DocReward在准确性上比GPT-4o和GPT-5分别高出30.6和19.4个百分点。在文档生成的外在评估中，DocReward的胜率显著高于GPT-5，分别为60.8%对37.7%。

Conclusion: DocReward在评估文档结构和风格方面表现优于现有基线模型，并能有效指导生成代理创建更符合人类偏好的文档。

Abstract: Recent advances in agentic workflows have enabled the automation of tasks
such as professional document generation. However, they primarily focus on
textual quality, neglecting visual structure and style, which are crucial for
readability and engagement. This gap arises mainly from the absence of suitable
reward models to guide agentic workflows toward producing documents with
stronger structural and stylistic quality. To address this, we propose
DocReward, a document reward model that evaluates documents based on their
structure and style. We construct a multi-domain dataset DocPair of 117K paired
documents, covering 32 domains and 267 document types, each including a high-
and low-professionalism document with identical content but different structure
and style. This enables the model to evaluate professionalism comprehensively,
and in a textual-quality-agnostic way. DocReward is trained using the
Bradley-Terry loss to score documents, penalizing predictions that contradict
the annotated ranking. To assess the performance of reward models, we create a
test dataset containing document bundles ranked by well-educated human
evaluators. Notably, DocReward outperforms GPT-4o and GPT-5 in accuracy by 30.6
and 19.4 percentage points, respectively, demonstrating its superiority over
baselines. In an extrinsic evaluation of document generation, DocReward
achieves a significantly higher win rate of 60.8%, compared to GPT-5's 37.7%
win rate, demonstrating its utility in guiding generation agents toward
producing human-preferred documents.

</details>


### [186] [Evaluating the effects of preprocessing, method selection, and hyperparameter tuning on SAR-based flood mapping and water depth estimation](https://arxiv.org/abs/2510.11305)
*Jean-Paul Travert,Cédric Goeury,Sébastien Boyaval,Vito Bacchi,Fabrice Zaoui*

Main category: cs.CV

TL;DR: SAR 影像的洪水绘图和水位估算对于水力模型校准和验证至关重要。本研究使用 SAR 影像评估了多种预处理（特别是斑点噪声抑制）、洪水绘图和水位估算方法。通过考虑一系列预处理图像、洪水图和水位场，研究了不同步骤中方法选择及其超参数的影响。研究使用了 2019 年和 2021 年加龙河（法国）的两次洪水事件，并以水动力模拟和现场观测作为参考数据。结果表明，斑点滤波器的选择会改变洪水范围的估算，变化可达数平方公里。此外，洪水绘图方法的选择和调整也会影响性能。虽然监督方法优于无监督方法，但经过调整的无监督方法（如局部阈值法或变化检测）可以取得可比的结果。预处理和洪水绘图步骤带来的复合不确定性也会导致水位场估算出现很大的变异性。本研究强调了考虑整个处理流程（包括预处理、洪水绘图和水位估算方法及其相关超参数）的重要性。建议采用集成方法并考虑方法论不确定性，而不是依赖单一配置。对于洪水绘图，方法选择影响最大。对于水位估算，影响最大的处理步骤是洪水绘图步骤产生的洪水图以及方法的超参数。


<details>
  <summary>Details</summary>
Motivation: 评估 SAR 影像洪水绘图和水位估算中的各种预处理、洪水绘图和水位估算方法，并研究其对结果的影响，特别是考虑集成方法和方法论不确定性。

Method: 研究使用 SAR 影像，评估了不同的预处理（特别是斑点噪声抑制）、洪水绘图和水位估算方法。通过考虑一系列预处理图像、洪水图和水位场，研究了不同步骤中方法选择及其超参数的影响。使用 2019 年和 2021 年加龙河的两次洪水事件，并以水动力模拟和现场观测作为参考数据。

Result: 斑点滤波器的选择会影响洪水范围的估算，变化可达数平方公里。洪水绘图方法的选择和调整也会影响性能。监督方法优于无监督方法，但经过调整的无监督方法可以取得可比结果。预处理和洪水绘图步骤带来的复合不确定性会导致水位场估算出现很大的变异性。方法选择对洪水绘图影响最大，而洪水图和方法超参数对水位估算影响最大。

Conclusion: SAR 影像的洪水绘图和水位估算需要考虑整个处理流程（预处理、洪水绘图、水位估算方法及其超参数）的集成和方法论不确定性。方法选择对洪水绘图影响最大，而洪水图和方法超参数对水位估算影响最大。

Abstract: Flood mapping and water depth estimation from Synthetic Aperture Radar (SAR)
imagery are crucial for calibrating and validating hydraulic models. This study
uses SAR imagery to evaluate various preprocessing (especially speckle noise
reduction), flood mapping, and water depth estimation methods. The impact of
the choice of method at different steps and its hyperparameters is studied by
considering an ensemble of preprocessed images, flood maps, and water depth
fields. The evaluation is conducted for two flood events on the Garonne River
(France) in 2019 and 2021, using hydrodynamic simulations and in-situ
observations as reference data. Results show that the choice of speckle filter
alters flood extent estimations with variations of several square kilometers.
Furthermore, the selection and tuning of flood mapping methods also affect
performance. While supervised methods outperformed unsupervised ones, tuned
unsupervised approaches (such as local thresholding or change detection) can
achieve comparable results. The compounded uncertainty from preprocessing and
flood mapping steps also introduces high variability in the water depth field
estimates. This study highlights the importance of considering the entire
processing pipeline, encompassing preprocessing, flood mapping, and water depth
estimation methods and their associated hyperparameters. Rather than relying on
a single configuration, adopting an ensemble approach and accounting for
methodological uncertainty should be privileged. For flood mapping, the method
choice has the most influence. For water depth estimation, the most influential
processing step was the flood map input resulting from the flood mapping step
and the hyperparameters of the methods.

</details>


### [187] [InternSVG: Towards Unified SVG Tasks with Multimodal Large Language Models](https://arxiv.org/abs/2510.11341)
*Haomin Wang,Jinhui Yin,Qi Wei,Wenguang Zeng,Lixin Gu,Shenglong Ye,Zhangwei Gao,Yaohui Wang,Yanting Zhang,Yuanqi Li,Yanwen Guo,Wenhai Wang,Kai Chen,Yu Qiao,Hongjie Zhang*

Main category: cs.CV

TL;DR: InternSVG是一个集成的数据集、基准和模型套件，利用多模态大型语言模型（MLLM）统一处理SVG的理解、编辑和生成，解决了现有SVG建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的SVG建模面临数据集碎片化、跨任务迁移能力有限以及处理结构复杂性困难的问题。为解决这些挑战，我们利用MLLM强大的迁移和泛化能力来实现SVG理解、编辑和生成的统一建模。

Method: 我们提出了InternSVG系列，一个集成了数据集、基准和模型的套件。核心是SAgoge，一个最大的、最全面的SVG多模态数据集，涵盖静态图形和动态动画，并支持不同难度级别的任务。在此基础上，我们引入了SArena，一个拥有全面任务定义和标准化评估的基准。我们还提出了InternSVG，一个统一的MLLM，通过SVG特定特殊标记、子词嵌入初始化和从静态SVG到长序列插图和复杂动画的两阶段训练策略，实现了SVG的理解、编辑和生成。

Result: 在SArena和现有基准上的实验表明，InternSVG实现了显著的提升，并且持续优于领先的开放和专有模型。

Conclusion: InternSVG通过统一的MLLM方法，成功解决了SVG建模中的挑战，并在理解、编辑和生成任务上取得了优于现有方法的性能。

Abstract: General SVG modeling remains challenging due to fragmented datasets, limited
transferability of methods across tasks, and the difficulty of handling
structural complexity. In response, we leverage the strong transfer and
generalization capabilities of multimodal large language models (MLLMs) to
achieve unified modeling for SVG understanding, editing, and generation. We
present the InternSVG family, an integrated data-benchmark-model suite. At its
core is SAgoge, the largest and most comprehensive multimodal dataset for SVG
tasks, encompassing both static graphics and dynamic animations. It covers
icons, long-sequence illustrations, scientific diagrams, and dynamic
animations, supporting tasks of varied difficulty levels and providing deeper
hierarchies with richer attributes compared to previous datasets. Based on this
resource, we introduce SArena, a companion benchmark with comprehensive task
definitions and standardized evaluation that aligns with the domains and
difficulty spectrum covered by SAgoge. Building on these foundations, we
propose InternSVG, a unified MLLM for SVG understanding, editing, and
generation with SVG-specific special tokens, subword-based embedding
initialization, and a two-stage training strategy that progresses from short
static SVGs to long-sequence illustrations and complex animations. This unified
formulation induces positive transfer and improves overall performance.
Experiments on SArena and prior benchmark confirm that InternSVG achieves
substantial gains and consistently outperforms leading open and proprietary
counterparts.

</details>


### [188] [MMAP: A Multi-Magnification and Prototype-Aware Architecture for Predicting Spatial Gene Expression](https://arxiv.org/abs/2510.11344)
*Hai Dang Nguyen,Nguyen Dang Huy Pham,The Minh Duc Nguyen,Dac Thai Nguyen,Hang Thi Nguyen,Duong M. Nguyen*

Main category: cs.CV

TL;DR: MMAP通过多放大率和原型增强架构解决了空间转录组学中局部特征提取不足和全局空间背景覆盖不足的问题，在多个评估指标上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学（ST）在识别组织结构和疾病病理方面发挥着关键作用，但由于视觉特征和分子信号之间的巨大差异，从组织学图像预测空间基因表达仍然是一个挑战。现有方法在局部特征提取的精细度和全局空间背景的覆盖范围方面存在不足。

Method: 提出了一种名为MMAP（多放大率和原型增强架构）的新框架。该框架利用多放大率图像块表示来增强局部特征的精细度，并通过学习一组潜在原型嵌入来增强全局上下文理解，这些原型嵌入可以作为幻灯片级别信息的紧凑表示。

Result: MMAP在多个评估指标（包括平均绝对误差（MAE）、均方误差（MSE）和皮尔逊相关系数（PCC））上持续优于所有现有的最先进方法。

Conclusion: MMAP框架能够同时处理局部特征提取不足和全局空间背景覆盖不足的问题，从而在空间转录组学领域取得显著进展。

Abstract: Spatial Transcriptomics (ST) enables the measurement of gene expression while
preserving spatial information, offering critical insights into tissue
architecture and disease pathology. Recent developments have explored the use
of hematoxylin and eosin (H&E)-stained whole-slide images (WSIs) to predict
transcriptome-wide gene expression profiles through deep neural networks. This
task is commonly framed as a regression problem, where each input corresponds
to a localized image patch extracted from the WSI. However, predicting spatial
gene expression from histological images remains a challenging problem due to
the significant modality gap between visual features and molecular signals.
Recent studies have attempted to incorporate both local and global information
into predictive models. Nevertheless, existing methods still suffer from two
key limitations: (1) insufficient granularity in local feature extraction, and
(2) inadequate coverage of global spatial context. In this work, we propose a
novel framework, MMAP (Multi-MAgnification and Prototype-enhanced
architecture), that addresses both challenges simultaneously. To enhance local
feature granularity, MMAP leverages multi-magnification patch representations
that capture fine-grained histological details. To improve global contextual
understanding, it learns a set of latent prototype embeddings that serve as
compact representations of slide-level information. Extensive experimental
results demonstrate that MMAP consistently outperforms all existing
state-of-the-art methods across multiple evaluation metrics, including Mean
Absolute Error (MAE), Mean Squared Error (MSE), and Pearson Correlation
Coefficient (PCC).

</details>


### [189] [Uncertainty-Aware ControlNet: Bridging Domain Gaps with Synthetic Image Generation](https://arxiv.org/abs/2510.11346)
*Joshua Niemeijer,Jan Ehrhardt,Heinz Handels,Hristina Uzunova*

Main category: cs.CV

TL;DR: 通过引入不确定性来改进ControlNet，使其能够利用未标记数据生成特定领域的合成数据，从而提高下游任务（如视网膜OCT图像分割）的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的ControlNet在生成数据时倾向于复制原始训练数据分布，限制了其作为数据增强工具的效果。对于像视网膜OCT成像这样存在域偏移（例如，高质量Spectralis设备与低质量Home-OCT设备之间）的应用，需要能够生成目标域数据的模型，但又不能完全依赖于有标签数据。

Method: 提出了一种利用无标签域数据训练ControlNet的方法，通过在控制机制中引入“不确定性”概念。该不确定性指示图像不属于下游任务（如分割）的训练分布。最终网络结合了来自无标签数据集的不确定性控制和来自有标签数据集的语义控制，以生成带有标签的目标域合成数据。

Result: 所提出的ControlNet能够生成高不确定性的、目标域（Home-OCT）的带标签的合成数据，有效缩小了与高质量Spectralis数据的域差距。在视网膜OCT分割任务中，这种方法显著提高了分割性能，且无需额外的监督。与风格迁移相比，不确定性引导能够实现任意的域迁移，而无需严格学习图像风格。该方法在交通场景实验中也得到了验证。

Conclusion: 通过将不确定性引入ControlNet的控制机制，可以有效地利用无标签数据来生成目标域的合成数据，解决了现有方法在处理域偏移问题上的局限性。该方法在视网膜OCT图像分割任务中显示出显著的优势，并能泛化到其他领域。

Abstract: Generative Models are a valuable tool for the controlled creation of
high-quality image data. Controlled diffusion models like the ControlNet have
allowed the creation of labeled distributions. Such synthetic datasets can
augment the original training distribution when discriminative models, like
semantic segmentation, are trained. However, this augmentation effect is
limited since ControlNets tend to reproduce the original training distribution.
  This work introduces a method to utilize data from unlabeled domains to train
ControlNets by introducing the concept of uncertainty into the control
mechanism. The uncertainty indicates that a given image was not part of the
training distribution of a downstream task, e.g., segmentation. Thus, two types
of control are engaged in the final network: an uncertainty control from an
unlabeled dataset and a semantic control from the labeled dataset. The
resulting ControlNet allows us to create annotated data with high uncertainty
from the target domain, i.e., synthetic data from the unlabeled distribution
with labels. In our scenario, we consider retinal OCTs, where typically
high-quality Spectralis images are available with given ground truth
segmentations, enabling the training of segmentation networks. The recent
development in Home-OCT devices, however, yields retinal OCTs with lower
quality and a large domain shift, such that out-of-the-pocket segmentation
networks cannot be applied for this type of data. Synthesizing annotated images
from the Home-OCT domain using the proposed approach closes this gap and leads
to significantly improved segmentation results without adding any further
supervision. The advantage of uncertainty-guidance becomes obvious when
compared to style transfer: it enables arbitrary domain shifts without any
strict learning of an image style. This is also demonstrated in a traffic scene
experiment.

</details>


### [190] [Reasoning as Representation: Rethinking Visual Reinforcement Learning in Image Quality Assessment](https://arxiv.org/abs/2510.11369)
*Shijie Zhao,Xuanyu Zhang,Weiqi Li,Junlin Li,Li Zhang,Tianfan Xue,Jian Zhang*

Main category: cs.CV

TL;DR: 基于强化学习的图像质量评估模型通过将冗余视觉信息转化为紧凑的跨域文本表示来提高泛化能力，但推理成本高。RALI算法通过对比学习直接将图像与这些文本表示对齐，无需LLM，在保持泛化能力的同时显著降低了模型参数和推理时间。


<details>
  <summary>Details</summary>
Motivation: 当前研究对基于强化学习的图像质量评估（IQA）模型泛化能力背后的机制和关键因素探索不足，且这类模型存在高推理能耗和延迟的问题。

Method: 通过大量实验验证和阐述了多模态大语言模型（MLLMs）如何通过强化学习训练，利用其推理能力将冗余的视觉表示转换为紧凑的、跨域对齐的文本表示，并提出了一种名为RALI的新算法，该算法采用对比学习直接将图像与这些可泛化的文本表示对齐，从而无需推理过程或加载LLM。

Result: RALI算法在图像质量评分任务上实现了与基于推理的模型相当的泛化性能，同时模型参数和推理时间仅为其5%以内。

Conclusion: 基于强化学习的IQA模型通过将视觉信息转化为文本表示来获得泛化能力。RALI算法通过对比学习直接学习这种对齐，无需LLM，显著提高了效率。

Abstract: Reasoning-based image quality assessment (IQA) models trained through
reinforcement learning (RL) exhibit exceptional generalization, yet the
underlying mechanisms and critical factors driving this capability remain
underexplored in current research. Moreover, despite their superior
performance, these models incur inference energy usage and latency orders of
magnitude higher than their earlier counterparts, restricting their deployment
in specific scenarios. Through extensive experiments, this paper verifies and
elaborates that through RL training, MLLMs leverage their reasoning capability
to convert redundant visual representations into compact, cross-domain aligned
text representations. This conversion is precisely the source of the
generalization exhibited by these reasoning-based IQA models. Building on this
fundamental insight, we propose a novel algorithm, RALI, which employs
contrastive learning to directly align images with these generalizable text
representations learned by RL. This approach eliminates the reliance on
reasoning processes and even obviates the need to load an LLM. For the quality
scoring task, this framework achieves generalization performance comparable to
reasoning-based models while requiring less than 5% of their model parameters
and inference time.

</details>


### [191] [MaterialRefGS: Reflective Gaussian Splatting with Multi-view Consistent Material Inference](https://arxiv.org/abs/2510.11387)
*Wenyuan Zhang,Jimin Tang,Weiqi Zhang,Yi Fang,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: 该研究提出了一种多视角一致的材料推理方法，结合物理学上更精确的环境建模，用于改进基于高斯喷射的反射建模，以实现更逼真的渲染和新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有的基于高斯喷射的反射建模方法在材料推理方面缺乏足够的约束，尤其是在有限的环境模型下，容易导致照明失真和泛化能力下降。

Method: 通过强制2D高斯在延迟着色过程中生成多视角一致的材料贴图，并利用跨视图的光度变化来识别强反射区域作为反射强度项的先验。此外，引入了一种通过光线追踪结合2D高斯喷射的环境建模策略，以处理由物体间遮挡引起的间接照明。

Result: 实验结果表明，该方法能够准确地恢复光照和几何信息，在新的视角合成方面达到了最先进的渲染质量。

Conclusion: 多视角一致的材料推理和更物理学上精确的环境建模是使用高斯喷射学习精确反射的关键。

Abstract: Modeling reflections from 2D images is essential for photorealistic rendering
and novel view synthesis. Recent approaches enhance Gaussian primitives with
reflection-related material attributes to enable physically based rendering
(PBR) with Gaussian Splatting. However, the material inference often lacks
sufficient constraints, especially under limited environment modeling,
resulting in illumination aliasing and reduced generalization. In this work, we
revisit the problem from a multi-view perspective and show that multi-view
consistent material inference with more physically-based environment modeling
is key to learning accurate reflections with Gaussian Splatting. To this end,
we enforce 2D Gaussians to produce multi-view consistent material maps during
deferred shading. We also track photometric variations across views to identify
highly reflective regions, which serve as strong priors for reflection strength
terms. To handle indirect illumination caused by inter-object occlusions, we
further introduce an environment modeling strategy through ray tracing with
2DGS, enabling photorealistic rendering of indirect radiance. Experiments on
widely used benchmarks show that our method faithfully recovers both
illumination and geometry, achieving state-of-the-art rendering quality in
novel views synthesis.

</details>


### [192] [Robust Ego-Exo Correspondence with Long-Term Memory](https://arxiv.org/abs/2510.11417)
*Yijun Hu,Bing Fan,Xin Gu,Haiqing Ren,Dongfang Liu,Heng Fan,Libo Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种基于SAM 2的长时记忆Ego-Exo（egocentric-exocentric）对应（EEC）框架，称为LM-EEC，解决了现有方法在处理视角变化、遮挡和小物体等挑战时的不足，特别是在长视频中。


<details>
  <summary>Details</summary>
Motivation: 为了实现智能助手精确直观的视觉引导，需要在以自身为中心（egocentric）和以物体为中心（exocentric）的视图之间建立物体级别的对应关系。然而，该任务面临视角剧烈变化、遮挡和小物体等挑战，现有方法（通常借鉴视频物体分割模型）仍难以应对。

Method: 提出了一种基于SAM 2并融入长时记忆的新型EEC框架。该框架包含一个借鉴自混合专家（MoE）模型的自适应特征路由模块（Memory-View MoE），以及一个具有压缩策略的双记忆库系统，以保留关键的长时信息并消除冗余。

Result: 在具有挑战性的EgoExo4D基准测试中，LM-EEC取得了新的最先进成果，显著优于现有方法和SAM 2基线，展示了其在各种场景下的强大泛化能力。

Conclusion: 所提出的LM-EEC框架通过引入创新的自适应特征路由和双记忆库系统，有效解决了现有EEC方法在长视频和复杂场景下的局限性，并在基准测试中取得了领先结果。

Abstract: Establishing object-level correspondence between egocentric and exocentric
views is essential for intelligent assistants to deliver precise and intuitive
visual guidance. However, this task faces numerous challenges, including
extreme viewpoint variations, occlusions, and the presence of small objects.
Existing approaches usually borrow solutions from video object segmentation
models, but still suffer from the aforementioned challenges. Recently, the
Segment Anything Model 2 (SAM 2) has shown strong generalization capabilities
and excellent performance in video object segmentation. Yet, when simply
applied to the ego-exo correspondence (EEC) task, SAM 2 encounters severe
difficulties due to ineffective ego-exo feature fusion and limited long-term
memory capacity, especially for long videos. Addressing these problems, we
propose a novel EEC framework based on SAM 2 with long-term memories by
presenting a dual-memory architecture and an adaptive feature routing module
inspired by Mixture-of-Experts (MoE). Compared to SAM 2, our approach features
(i) a Memory-View MoE module which consists of a dual-branch routing mechanism
to adaptively assign contribution weights to each expert feature along both
channel and spatial dimensions, and (ii) a dual-memory bank system with a
simple yet effective compression strategy to retain critical long-term
information while eliminating redundancy. In the extensive experiments on the
challenging EgoExo4D benchmark, our method, dubbed LM-EEC, achieves new
state-of-the-art results and significantly outperforms existing methods and the
SAM 2 baseline, showcasing its strong generalization across diverse scenarios.
Our code and model are available at https://github.com/juneyeeHu/LM-EEC.

</details>


### [193] [Enhancing Maritime Domain Awareness on Inland Waterways: A YOLO-Based Fusion of Satellite and AIS for Vessel Characterization](https://arxiv.org/abs/2510.11449)
*Geoffery Agorku,Sarah Hernandez,Hayley Hames,Cade Wagner*

Main category: cs.CV

TL;DR: 该论文提出了一种融合高分辨率卫星图像和船舶自动识别系统（AIS）轨迹数据的新框架，用于提高内陆水道的海事态势感知能力，解决了AIS系统易受攻击的缺点，能有效识别‘暗船’、验证合作交通并支持高级MDA。


<details>
  <summary>Details</summary>
Motivation: 内陆水道的海事态势感知（MDA）能力受到合作系统漏洞的挑战，需要更可靠的监控方法。

Method: 提出了一种融合高分辨率卫星图像和AIS数据的框架，利用YOLOv11模型检测和表征船舶及驳船，并将其与AIS数据关联，以识别‘暗船’、验证合作交通并支持高级MDA。

Result: 研究成功开发了一个包含4,550个实例的标注数据集，并在测试集上取得了优异的性能：船舶分类F1分数95.8%，驳船覆盖状态检测F1分数91.6%，运行状态分类F1分数99.4%，航向识别准确率93.8%，驳船计数平均绝对误差（MAE）为2.4。空间迁移性分析显示，在不同河段的准确率仍高达98%。

Conclusion: 融合非合作卫星传感与AIS数据的方法是可行的，能够实现近乎实时的船队库存管理，支持异常检测，并为内陆水道监控生成高质量数据。未来工作将扩展数据集、引入时间跟踪并探索多模态深度学习以提高可扩展性。

Abstract: Maritime Domain Awareness (MDA) for inland waterways remains challenged by
cooperative system vulnerabilities. This paper presents a novel framework that
fuses high-resolution satellite imagery with vessel trajectory data from the
Automatic Identification System (AIS). This work addresses the limitations of
AIS-based monitoring by leveraging non-cooperative satellite imagery and
implementing a fusion approach that links visual detections with AIS data to
identify dark vessels, validate cooperative traffic, and support advanced MDA.
The You Only Look Once (YOLO) v11 object detection model is used to detect and
characterize vessels and barges by vessel type, barge cover, operational
status, barge count, and direction of travel. An annotated data set of 4,550
instances was developed from $5{,}973~\mathrm{mi}^2$ of Lower Mississippi River
imagery. Evaluation on a held-out test set demonstrated vessel classification
(tugboat, crane barge, bulk carrier, cargo ship, and hopper barge) with an F1
score of 95.8\%; barge cover (covered or uncovered) detection yielded an F1
score of 91.6\%; operational status (staged or in motion) classification
reached an F1 score of 99.4\%. Directionality (upstream, downstream) yielded
93.8\% accuracy. The barge count estimation resulted in a mean absolute error
(MAE) of 2.4 barges. Spatial transferability analysis across geographically
disjoint river segments showed accuracy was maintained as high as 98\%. These
results underscore the viability of integrating non-cooperative satellite
sensing with AIS fusion. This approach enables near-real-time fleet
inventories, supports anomaly detection, and generates high-quality data for
inland waterway surveillance. Future work will expand annotated datasets,
incorporate temporal tracking, and explore multi-modal deep learning to further
enhance operational scalability.

</details>


### [194] [Coupled Degradation Modeling and Fusion: A VLM-Guided Degradation-Coupled Network for Degradation-Aware Infrared and Visible Image Fusion](https://arxiv.org/abs/2510.11456)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: 提出了VGDCFusion网络，将退化建模与图像融合过程相结合，并利用视觉-语言模型（VLMs）进行退化感知和引导抑制，以处理降质的红外与可见光图像。


<details>
  <summary>Details</summary>
Motivation: 现有的红外与可见光图像融合（IVIF）方法通常假设输入图像质量高，在处理降质图像时需要手动切换预处理技术，导致退化处理与图像融合分离，性能显著下降。

Method: 提出了一种新颖的VLM引导的退化耦合融合网络（VGDCFusion）。具体来说，提出了一种特定的提示退化耦合提取器（SPDCE），实现了模态特定的退化感知，并建立了退化抑制与模态内特征提取的联合建模。同时，联合提示退化耦合融合（JPDCF）促进了跨模态退化感知，并将残差退化滤波与互补的跨模态特征融合相结合。

Result: VGDCFusion在各种降质图像场景下显著优于现有的最先进的融合方法。

Conclusion: VGDCFusion通过将退化建模与融合过程紧密耦合，并利用VLM进行退化感知和引导抑制，有效解决了现有IVIF方法在处理降质图像时的性能问题。

Abstract: Existing Infrared and Visible Image Fusion (IVIF) methods typically assume
high-quality inputs. However, when handing degraded images, these methods
heavily rely on manually switching between different pre-processing techniques.
This decoupling of degradation handling and image fusion leads to significant
performance degradation. In this paper, we propose a novel VLM-Guided
Degradation-Coupled Fusion network (VGDCFusion), which tightly couples
degradation modeling with the fusion process and leverages vision-language
models (VLMs) for degradation-aware perception and guided suppression.
Specifically, the proposed Specific-Prompt Degradation-Coupled Extractor
(SPDCE) enables modality-specific degradation awareness and establishes a joint
modeling of degradation suppression and intra-modal feature extraction. In
parallel, the Joint-Prompt Degradation-Coupled Fusion (JPDCF) facilitates
cross-modal degradation perception and couples residual degradation filtering
with complementary cross-modal feature fusion. Extensive experiments
demonstrate that our VGDCFusion significantly outperforms existing
state-of-the-art fusion approaches under various degraded image scenarios. Our
code is available at https://github.com/Lmmh058/VGDCFusion.

</details>


### [195] [VA-GS: Enhancing the Geometric Representation of Gaussian Splatting via View Alignment](https://arxiv.org/abs/2510.11473)
*Qing Li,Huifang Feng,Xun Gong,Yu-Shen Liu*

Main category: cs.CV

TL;DR: 提出了一种名为VA-GS的新方法，通过引入视图对齐（VA）来增强3D高斯泼溅在表面重建方面的几何表示能力，实现了最先进的表面重建和新视图合成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅方法在几何重建方面能力不足，仅基于图像渲染损失会导致几何不准确和多视图不一致。

Method: 通过引入边缘感知图像线索到渲染损失中来改进表面边界的描绘；引入了可见性感知光度对齐损失来模拟遮挡并鼓励高斯之间的空间关系；结合了基于法线的约束来优化高斯的空间方向和局部表面估计；利用深度图像特征嵌入来加强跨视图一致性。

Result: 在标准基准测试上进行了广泛的实验，证明了该方法在表面重建和新视图合成方面均取得了最先进的性能。

Conclusion: 所提出的VA-GS方法通过增强3D高斯泼溅的几何表示能力，显著提高了表面重建和新视图合成的质量和准确性。

Abstract: 3D Gaussian Splatting has recently emerged as an efficient solution for
high-quality and real-time novel view synthesis. However, its capability for
accurate surface reconstruction remains underexplored. Due to the discrete and
unstructured nature of Gaussians, supervision based solely on image rendering
loss often leads to inaccurate geometry and inconsistent multi-view alignment.
In this work, we propose a novel method that enhances the geometric
representation of 3D Gaussians through view alignment (VA). Specifically, we
incorporate edge-aware image cues into the rendering loss to improve surface
boundary delineation. To enforce geometric consistency across views, we
introduce a visibility-aware photometric alignment loss that models occlusions
and encourages accurate spatial relationships among Gaussians. To further
mitigate ambiguities caused by lighting variations, we incorporate normal-based
constraints to refine the spatial orientation of Gaussians and improve local
surface estimation. Additionally, we leverage deep image feature embeddings to
enforce cross-view consistency, enhancing the robustness of the learned
geometry under varying viewpoints and illumination. Extensive experiments on
standard benchmarks demonstrate that our method achieves state-of-the-art
performance in both surface reconstruction and novel view synthesis. The source
code is available at https://github.com/LeoQLi/VA-GS.

</details>


### [196] [AndesVL Technical Report: An Efficient Mobile-side Multimodal Large Language Model](https://arxiv.org/abs/2510.11496)
*Zhiwei Jin,Xiaohui Song,Nan Wang,Yafei Liu,Chao Li,Xin Li,Ruichen Wang,Zhihao Li,Qi Qi,Long Cheng,Dongze Hao,Quanlong Zheng,Yanhao Zhang,Haobo Ji,Jian Ma,Zhitong Zheng,Zhenyi Lin,Haolin Deng,Xin Zou,Xiaojie Yin,Ruilin Wang,Liankai Cai,Haijing Liu,Yuqing Qiu,Ke Chen,Zixian Li,Chi Xie,Huafei Li,Chenxing Li,Chuangchuang Wang,Kai Tang,Zhiguang Zhu,Kai Tang,Wenmei Gao,Rui Wang,Jun Wu,Chao Liu,Qin Xie,Chen Chen,Haonan Lu*

Main category: cs.CV

TL;DR: AndesVL是一个移动端多模态大模型系列，参数量在0.6B到4B之间，在多种基准测试中取得了同等规模模型中的顶尖性能。


<details>
  <summary>Details</summary>
Motivation: 近年来，云端大型多模态大模型（MLLMs）虽然性能强大，但对内存、功耗和计算能力的要求远超移动设备。

Method: 本文介绍了AndesVL模型系列，该系列基于Qwen3的LLM和多种视觉编码器构建，并详细阐述了其模型架构、训练流程和训练数据。此外，还引入了一种1+N LoR（一种参数高效微调技术）。

Result: AndesVL在文本丰富的图像理解、推理与数学、多图像理解、通用视觉问答、幻觉缓解、多语言理解和GUI相关任务等多个开源基准测试中，与同等规模的最新模型相比，取得了领先的性能。

Conclusion: AndesVL成功地在移动端实现了与云端模型相媲美的使用体验，解决了边缘设备在多模态大模型应用中的瓶颈。

Abstract: In recent years, while cloud-based MLLMs such as QwenVL, InternVL, GPT-4o,
Gemini, and Claude Sonnet have demonstrated outstanding performance with
enormous model sizes reaching hundreds of billions of parameters, they
significantly surpass the limitations in memory, power consumption, and
computing capacity of edge devices such as mobile phones. This paper introduces
AndesVL, a suite of mobile-side MLLMs with 0.6B to 4B parameters based on
Qwen3's LLM and various visual encoders. We comprehensively outline the model
architectures, training pipeline, and training data of AndesVL, which achieves
first-tier performance across a wide range of open-source benchmarks, including
fields such as text-rich image understanding, reasoning and math, multi-image
comprehension, general VQA, hallucination mitigation, multilingual
understanding, and GUI-related tasks when compared with state-of-the-art models
of a similar scale. Furthermore, we introduce a 1+N LoR

</details>


### [197] [Towards Fast and Scalable Normal Integration using Continuous Components](https://arxiv.org/abs/2510.11508)
*Francesco Milano,Jen Jen Chung,Lionel Ott,Roland Siegwart*

Main category: cs.CV

TL;DR: 提出了一种新的表面法线积分方法，通过将问题重构为连续分量的相对尺度估计来解决现有方法的扩展性问题，并在标准基准测试中取得了最先进的结果和显著的加速。


<details>
  <summary>Details</summary>
Motivation: 现有表面法线积分方法需要全局优化，难以处理大尺寸法线图。

Method: 将法线积分问题重构为连续分量的相对尺度估计，通过约束同一分量的像素共同改变尺度来减少优化变量。框架包含一个用于估计连续分量的启发式方法、一个用于重新平衡优化项的策略以及一个用于合并分量的迭代技术。

Result: 在标准法线积分基准测试中取得了最先进的结果，处理大尺寸法线图的速度比逐像素方法快一个数量级，并且在几秒钟内完成。

Conclusion: 新方法在效率和准确性上都优于现有方法，特别是在处理大尺寸法线图时。

Abstract: Surface normal integration is a fundamental problem in computer vision,
dealing with the objective of reconstructing a surface from its corresponding
normal map. Existing approaches require an iterative global optimization to
jointly estimate the depth of each pixel, which scales poorly to larger normal
maps. In this paper, we address this problem by recasting normal integration as
the estimation of relative scales of continuous components. By constraining
pixels belonging to the same component to jointly vary their scale, we
drastically reduce the number of optimization variables. Our framework includes
a heuristic to accurately estimate continuous components from the start, a
strategy to rebalance optimization terms, and a technique to iteratively merge
components to further reduce the size of the problem. Our method achieves
state-of-the-art results on the standard normal integration benchmark in as
little as a few seconds and achieves one-order-of-magnitude speedup over
pixel-level approaches on large-resolution normal maps.

</details>


### [198] [Situat3DChange: Situated 3D Change Understanding Dataset for Multimodal Large Language Model](https://arxiv.org/abs/2510.11509)
*Ruiping Liu,Junwei Zheng,Yufan Chen,Zirui Wang,Kunyu Peng,Kailun Yang,Jiaming Zhang,Marc Pollefeys,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: Situat3DChange是一个包含121K问答对、36K变化描述和17K重排指令的大型数据集，旨在解决3D数据集在理解动态环境和情境方面的局限性。它通过整合11K个人类观察，利用大型语言模型（LLM）来理解情境化变化。此外，研究提出了一种名为SCReasoner的高效3D多模态大型语言模型（MLLM）方法，用于比较有细微差别的点云对。实验证明了该数据集在训练MLLM用于动态场景和情境理解方面的有效性，并展示了MLLM在该领域的进展和局限性。


<details>
  <summary>Details</summary>
Motivation: 当前3D数据集在处理动态环境和情境的综合理解方面存在不足，需要更全面的数据集和评估方法来克服这些限制。

Method: 构建了一个名为Situat3DChange的大型数据集，包含问答、变化描述和重排指令任务，并利用人类观察和LLM来整合情境化变化信息。提出了一种名为SCReasoner的高效3D MLLM方法，用于比较点云对。

Result: 在Situat3DChange数据集上的全面评估揭示了MLLM在动态场景和情境理解方面的进展和局限性。实验还证明了Situat3DChange作为训练数据集在数据扩展和跨领域迁移方面的有效性。

Conclusion: Situat3DChange数据集和SCReasoner方法为3D动态场景和情境理解提供了新的途径，并为未来MLLM在该领域的发展奠定了基础。

Abstract: Physical environments and circumstances are fundamentally dynamic, yet
current 3D datasets and evaluation benchmarks tend to concentrate on either
dynamic scenarios or dynamic situations in isolation, resulting in incomplete
comprehension. To overcome these constraints, we introduce Situat3DChange, an
extensive dataset supporting three situation-aware change understanding tasks
following the perception-action model: 121K question-answer pairs, 36K change
descriptions for perception tasks, and 17K rearrangement instructions for the
action task. To construct this large-scale dataset, Situat3DChange leverages
11K human observations of environmental changes to establish shared mental
models and shared situational awareness for human-AI collaboration. These
observations, enriched with egocentric and allocentric perspectives as well as
categorical and coordinate spatial relations, are integrated using an LLM to
support understanding of situated changes. To address the challenge of
comparing pairs of point clouds from the same scene with minor changes, we
propose SCReasoner, an efficient 3D MLLM approach that enables effective point
cloud comparison with minimal parameter overhead and no additional tokens
required for the language decoder. Comprehensive evaluation on Situat3DChange
tasks highlights both the progress and limitations of MLLMs in dynamic scene
and situation understanding. Additional experiments on data scaling and
cross-domain transfer demonstrate the task-agnostic effectiveness of using
Situat3DChange as a training dataset for MLLMs.

</details>


### [199] [LikePhys: Evaluating Intuitive Physics Understanding in Video Diffusion Models via Likelihood Preference](https://arxiv.org/abs/2510.11512)
*Jianhao Yuan,Fabio Pizzati,Francesco Pinto,Lars Kunze,Ivan Laptev,Paul Newman,Philip Torr,Daniele De Martini*

Main category: cs.CV

TL;DR: 该研究提出了一种名为LikePhys的训练方法，用于评估视频扩散模型对直观物理的理解能力。


<details>
  <summary>Details</summary>
Motivation: 准确评估视频扩散模型在物理模拟方面的能力具有挑战性，因为很难将物理正确性与生成内容的视觉外观区分开来。

Method: LikePhys使用去噪目标作为ELBO（证据下界）似然的替代，通过区分物理上有效和无效的视频来评估直观物理。

Result: 研究构建了一个包含四个物理域、十二种场景的基准测试集，并展示了所提出的评估指标PPE（合理性偏好误差）与人类偏好高度一致，优于现有的评估方法。该研究还对当前视频扩散模型的直观物理理解能力进行了基准测试，并分析了模型设计和推理设置对其能力的影响，同时强调了不同物理定律下的能力差异。

Conclusion: 尽管当前模型在处理复杂和混沌动力学方面仍存在挑战，但随着模型容量和推理设置的扩展，其物理理解能力呈现出明显的提升趋势。

Abstract: Intuitive physics understanding in video diffusion models plays an essential
role in building general-purpose physically plausible world simulators, yet
accurately evaluating such capacity remains a challenging task due to the
difficulty in disentangling physics correctness from visual appearance in
generation. To the end, we introduce LikePhys, a training-free method that
evaluates intuitive physics in video diffusion models by distinguishing
physically valid and impossible videos using the denoising objective as an
ELBO-based likelihood surrogate on a curated dataset of valid-invalid pairs. By
testing on our constructed benchmark of twelve scenarios spanning over four
physics domains, we show that our evaluation metric, Plausibility Preference
Error (PPE), demonstrates strong alignment with human preference, outperforming
state-of-the-art evaluator baselines. We then systematically benchmark
intuitive physics understanding in current video diffusion models. Our study
further analyses how model design and inference settings affect intuitive
physics understanding and highlights domain-specific capacity variations across
physical laws. Empirical results show that, despite current models struggling
with complex and chaotic dynamics, there is a clear trend of improvement in
physics understanding as model capacity and inference settings scale.

</details>


### [200] [mmWalk: Towards Multi-modal Multi-view Walking Assistance](https://arxiv.org/abs/2510.11520)
*Kedi Ying,Ruiping Liu,Chongyan Chen,Mingzhe Tao,Hao Shi,Kailun Yang,Jiaming Zhang,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: mmWalk 是一个包含多视角传感器和面向可访问性特征的模拟多模态数据集，用于户外安全导航，并附带一个视觉问答基准 mmWalkVQA。


<details>
  <summary>Details</summary>
Motivation: 为盲人或低视力者（BLV）在极端或复杂环境中提供步行辅助，解决他们对整体场景理解能力不足的挑战。

Method: 构建了一个名为 mmWalk 的模拟多模态数据集，集成了多视角传感器和面向可访问性的特征，用于户外安全导航。该数据集包含 120 条手动控制的、按场景分类的步行轨迹，具有 62k 帧同步数据。它包含超过 559k 张全景图像，涵盖 RGB、深度和语义模态。此外，还生成了一个名为 mmWalkVQA 的视觉问答基准，包含超过 69k 个视觉问答三元组，涵盖 9 个类别，专门针对安全和信息丰富的步行辅助进行了定制。

Result: 在 mmWalkVQA 上评估了最先进的视觉语言模型（VLMs），在零样本和少样本设置下，发现它们难以应对风险评估和导航任务。将 mmWalk 微调的模型在真实世界数据集上进行了验证，证明了该数据集在推进多模态步行辅助方面的有效性。

Conclusion: mmWalk 数据集及其 VQA 基准为解决 BLV 群体的步行辅助挑战提供了宝贵的资源，并证明了在复杂导航任务中 VLMs 仍有改进空间。

Abstract: Walking assistance in extreme or complex environments remains a significant
challenge for people with blindness or low vision (BLV), largely due to the
lack of a holistic scene understanding. Motivated by the real-world needs of
the BLV community, we build mmWalk, a simulated multi-modal dataset that
integrates multi-view sensor and accessibility-oriented features for outdoor
safe navigation. Our dataset comprises 120 manually controlled,
scenario-categorized walking trajectories with 62k synchronized frames. It
contains over 559k panoramic images across RGB, depth, and semantic modalities.
Furthermore, to emphasize real-world relevance, each trajectory involves
outdoor corner cases and accessibility-specific landmarks for BLV users.
Additionally, we generate mmWalkVQA, a VQA benchmark with over 69k visual
question-answer triplets across 9 categories tailored for safe and informed
walking assistance. We evaluate state-of-the-art Vision-Language Models (VLMs)
using zero- and few-shot settings and found they struggle with our risk
assessment and navigational tasks. We validate our mmWalk-finetuned model on
real-world datasets and show the effectiveness of our dataset for advancing
multi-modal walking assistance.

</details>


### [201] [Massive Activations are the Key to Local Detail Synthesis in Diffusion Transformers](https://arxiv.org/abs/2510.11538)
*Chaofan Gan,Zicheng Zhao,Yuanpeng Tu,Xi Chen,Ziran Qin,Tieyuan Chen,Mehrtash Harandi,Weiyao Lin*

Main category: cs.CV

TL;DR: 本文研究了扩散Transformer（DiTs）中的“大规模激活”（MAs）现象，发现它们主要负责局部细节合成，并提出了一种名为“细节引导”（DG）的训练无关策略来增强细节保真度。


<details>
  <summary>Details</summary>
Motivation: DiTs在视觉生成领域表现出色，但其内部特征图中的“大规模激活”（MAs）现象的功能尚不明确，本文旨在系统性地研究MAs的作用并提出改进方法。

Method: 通过实验研究MAs在DiTs中的分布和影响，发现它们与局部细节合成密切相关，并提出了一种名为“细节引导”（DG）的策略，通过构造一个破坏MAs的“细节缺乏”模型来指导原始网络进行细节合成。

Result: DG策略能够无缝集成CFG，并且在多种预训练DiTs（如SD3, SD3.5, Flux）上均能有效提升细节质量。

Conclusion: MAs在DiTs的视觉生成中扮演着关键角色，主要影响局部细节合成。提出的DG策略是一种有效的训练无关方法，可以显著增强DiTs生成的图像的细节保真度。

Abstract: Diffusion Transformers (DiTs) have recently emerged as a powerful backbone
for visual generation. Recent observations reveal \emph{Massive Activations}
(MAs) in their internal feature maps, yet their function remains poorly
understood. In this work, we systematically investigate these activations to
elucidate their role in visual generation. We found that these massive
activations occur across all spatial tokens, and their distribution is
modulated by the input timestep embeddings. Importantly, our investigations
further demonstrate that these massive activations play a key role in local
detail synthesis, while having minimal impact on the overall semantic content
of output. Building on these insights, we propose \textbf{D}etail
\textbf{G}uidance (\textbf{DG}), a MAs-driven, training-free self-guidance
strategy to explicitly enhance local detail fidelity for DiTs. Specifically, DG
constructs a degraded ``detail-deficient'' model by disrupting MAs and
leverages it to guide the original network toward higher-quality detail
synthesis. Our DG can seamlessly integrate with Classifier-Free Guidance (CFG),
enabling further refinements of fine-grained details. Extensive experiments
demonstrate that our DG consistently improves fine-grained detail quality
across various pre-trained DiTs (\eg, SD3, SD3.5, and Flux).

</details>


### [202] [ODI-Bench: Can MLLMs Understand Immersive Omnidirectional Environments?](https://arxiv.org/abs/2510.11549)
*Liu Yang,Huiyu Duan,Ran Tao,Juntao Cheng,Sijing Wu,Yunhao Li,Jing Liu,Xiongkuo Min,Guangtao Zhai*

Main category: cs.CV

TL;DR: 本论文提出了ODI-Bench基准和Omni-CoT方法，以提升多模态大模型对全景图像的理解能力。


<details>
  <summary>Details</summary>
Motivation: 目前多模态大语言模型在理解全景图像（ODIs）方面存在不足，而ODIs在VR、AR等领域有广泛应用。

Method: 提出了ODI-Bench基准，包含2000张全景图像和4000个问答对，覆盖10项任务。同时提出了Omni-CoT方法，通过结合文本和视觉线索进行思维链推理，来提升模型的理解能力。

Result: 在ODI-Bench基准上对20个代表性多模态大语言模型进行了测试，发现现有模型在理解ODIs方面仍有困难。Omni-CoT方法显著提升了模型的理解能力。

Conclusion: 现有的大语言模型在处理全景图像方面仍有很大的提升空间，提出的Omni-CoT方法能够有效改善这一状况。

Abstract: Omnidirectional images (ODIs) provide full 360x180 view which are widely
adopted in VR, AR and embodied intelligence applications. While multi-modal
large language models (MLLMs) have demonstrated remarkable performance on
conventional 2D image and video understanding benchmarks, their ability to
comprehend the immersive environments captured by ODIs remains largely
unexplored. To address this gap, we first present ODI-Bench, a novel
comprehensive benchmark specifically designed for omnidirectional image
understanding. ODI-Bench contains 2,000 high-quality omnidirectional images and
over 4,000 manually annotated question-answering (QA) pairs across 10
fine-grained tasks, covering both general-level and spatial-level ODI
understanding. Extensive experiments are conducted to benchmark 20
representative MLLMs, including proprietary and open-source models, under both
close-ended and open-ended settings. Experimental results reveal that current
MLLMs still struggle to capture the immersive context provided by ODIs. To this
end, we further introduce Omni-CoT, a training-free method which significantly
enhances MLLMs' comprehension ability in the omnidirectional environment
through chain-of-thought reasoning across both textual information and visual
cues. Both the benchmark and the code will be released upon the publication.

</details>


### [203] [How many samples to label for an application given a foundation model? Chest X-ray classification study](https://arxiv.org/abs/2510.11553)
*Nikolay Nechaev,Evgenia Przhezdzetskaya,Viktor Gombolevskiy,Dmitry Umerenkov,Dmitry Dylov*

Main category: cs.CV

TL;DR: 在胸部X光片分类中，我们使用幂律拟合来预测达到特定ROC-AUC阈值所需的训练样本数量，并发现XrayCLIP和XraySigLIP等基础模型比ResNet-50基线模型需要更少的标注样本，并且仅使用50个标注样本即可准确预测最终性能。


<details>
  <summary>Details</summary>
Motivation: 胸部X光片分类在诊断中至关重要，但需要大量的标注数据，这使得标注成本高昂。基础模型可以减少对大量标注数据的依赖，但具体需要多少标注样本才能达到预期性能尚不清楚。

Method: 我们系统地评估了使用幂律拟合来预测特定ROC-AUC阈值所需的训练样本数量。我们测试了多种病理和基础模型，并将结果与ResNet-50基线进行了比较。此外，我们还分析了仅使用50个标注病例的学习曲线斜率对最终性能的预测能力。

Result: XrayCLIP和XraySigLIP等基础模型在标注样本量显著少于ResNet-50基线模型的情况下，表现出了强大的性能。仅使用50个标注病例的学习曲线斜率能够准确预测最终的性能平台期。

Conclusion: 研究结果表明，通过分析学习曲线，可以准确预测达到目标性能所需的标注样本数量，从而使从业者能够通过仅标注必需的样本来最大限度地减少标注成本。

Abstract: Chest X-ray classification is vital yet resource-intensive, typically
demanding extensive annotated data for accurate diagnosis. Foundation models
mitigate this reliance, but how many labeled samples are required remains
unclear. We systematically evaluate the use of power-law fits to predict the
training size necessary for specific ROC-AUC thresholds. Testing multiple
pathologies and foundation models, we find XrayCLIP and XraySigLIP achieve
strong performance with significantly fewer labeled examples than a ResNet-50
baseline. Importantly, learning curve slopes from just 50 labeled cases
accurately forecast final performance plateaus. Our results enable
practitioners to minimize annotation costs by labeling only the essential
samples for targeted performance.

</details>


### [204] [SNAP: Towards Segmenting Anything in Any Point Cloud](https://arxiv.org/abs/2510.11565)
*Aniket Gupta,Hanhui Wang,Charles Saunders,Aruni RoyChowdhury,Hanumant Singh,Huaizu Jiang*

Main category: cs.CV

TL;DR: SNAP是一个统一的交互式3D点云分割模型，支持点和文本提示，并能在室内、室外和航空等不同领域实现跨领域泛化，实现了8个零样本基准中的8个以及5个文本提示基准中的5个的最优或有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的交互式3D点云分割方法通常局限于单一领域（室内或室外）和单一交互形式（空间点击或文本提示），并且在多数据集上训练会导致负迁移，缺乏泛化性。为了解决这些问题，需要一个能够支持多种提示方式和跨多个领域进行点云分割的统一模型。

Method: SNAP通过在包括室内、室外和航空环境的7个数据集上进行训练，并采用领域自适应归一化来防止负迁移，从而实现跨领域泛化。对于文本提示分割，模型会自动生成掩码建议，并将其与文本查询的CLIP嵌入进行匹配，从而实现全景分割和开放词汇分割。

Result: SNAP在8个空间提示的零样本基准测试中取得了最先进的性能，并在所有5个文本提示的基准测试中取得了有竞争力的结果，表明其在各种3D点云分割任务中具有优越的性能。

Conclusion: SNAP是一个统一的交互式3D点云分割模型，能够匹配甚至超越专门的领域特定方法，为可扩展的3D标注提供了一个实用的工具，并且在点云分割任务中实现了最先进的性能。

Abstract: Interactive 3D point cloud segmentation enables efficient annotation of
complex 3D scenes through user-guided prompts. However, current approaches are
typically restricted in scope to a single domain (indoor or outdoor), and to a
single form of user interaction (either spatial clicks or textual prompts).
Moreover, training on multiple datasets often leads to negative transfer,
resulting in domain-specific tools that lack generalizability. To address these
limitations, we present \textbf{SNAP} (\textbf{S}egment a\textbf{N}ything in
\textbf{A}ny \textbf{P}oint cloud), a unified model for interactive 3D
segmentation that supports both point-based and text-based prompts across
diverse domains. Our approach achieves cross-domain generalizability by
training on 7 datasets spanning indoor, outdoor, and aerial environments, while
employing domain-adaptive normalization to prevent negative transfer. For
text-prompted segmentation, we automatically generate mask proposals without
human intervention and match them against CLIP embeddings of textual queries,
enabling both panoptic and open-vocabulary segmentation. Extensive experiments
demonstrate that SNAP consistently delivers high-quality segmentation results.
We achieve state-of-the-art performance on 8 out of 9 zero-shot benchmarks for
spatial-prompted segmentation and demonstrate competitive results on all 5
text-prompted benchmarks. These results show that a unified model can match or
exceed specialized domain-specific approaches, providing a practical tool for
scalable 3D annotation. Project page is at, https://neu-vi.github.io/SNAP/

</details>


### [205] [Benchmarking foundation models for hyperspectral image classification: Application to cereal crop type mapping](https://arxiv.org/abs/2510.11576)
*Walid Elbarz,Mohamed Bourriz,Hicham Hajji,Hamd Ait Abdelali,François Bourzeix*

Main category: cs.CV

TL;DR: 使用光谱地球数据集预训练的Vision Transformer在超光谱作物分类任务中表现最佳，准确率达到93.5%。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在超光谱作物测绘方面的潜力。

Method: 对三种基础模型（HyperSigma、DOFA和在SpectralEarth数据集上预训练的Vision Transformer）进行微调，并在独立测试区域评估其性能，使用总体准确率（OA）、平均准确率（AA）和F1分数作为评价指标。

Result: 在总体准确率方面，HyperSigma为34.5%（+/- 1.8%），DOFA为62.6%（+/- 3.5%），SpectralEarth模型为93.5%（+/- 0.8%）。从头开始训练的紧凑型SpectralEarth变体达到了91%的准确率。

Conclusion: 预训练的基础模型，特别是Vision Transformer，在超光谱作物测绘方面表现出色。模型架构对于跨区域和跨传感器平台的泛化能力至关重要。

Abstract: Foundation models are transforming Earth observation, but their potential for
hyperspectral crop mapping remains underexplored. This study benchmarks three
foundation models for cereal crop mapping using hyperspectral imagery:
HyperSigma, DOFA, and Vision Transformers pre-trained on the SpectralEarth
dataset (a large multitemporal hyperspectral archive). Models were fine-tuned
on manually labeled data from a training region and evaluated on an independent
test region. Performance was measured with overall accuracy (OA), average
accuracy (AA), and F1-score. HyperSigma achieved an OA of 34.5% (+/- 1.8%),
DOFA reached 62.6% (+/- 3.5%), and the SpectralEarth model achieved an OA of
93.5% (+/- 0.8%). A compact SpectralEarth variant trained from scratch achieved
91%, highlighting the importance of model architecture for strong
generalization across geographic regions and sensor platforms. These results
provide a systematic evaluation of foundation models for operational
hyperspectral crop mapping and outline directions for future model development.

</details>


### [206] [MS-Mix: Unveiling the Power of Mixup for Multimodal Sentiment Analysis](https://arxiv.org/abs/2510.11579)
*Hongyu Zhu,Lin Chen,Mounim A. El-Yacoubi,Mingsheng Shang*

Main category: cs.CV

TL;DR: MS-Mix是一个创新的框架，通过情感感知采样选择、情感强度引导的混合以及情感对齐损失，解决了多模态情感分析中数据稀疏和混合不当的问题，并在多个基准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型在多模态情感分析（MSA）中受限于稀疏的标注数据。虽然Mixup增强方法在单模态任务中有所改进，但直接应用于MSA时会因缺乏情感感知的混合机制而加剧标签模糊性和语义不一致性。

Method: 提出MS-Mix框架，包含三个关键组件：1. 情感感知采样选择（SASS）策略，避免混合具有矛盾情感的样本。2. 情感强度引导（SIG）模块，利用多头自注意力计算特定模态的情感强度。3. 情感对齐损失（SAL），对齐模态间的预测分布，并使用基于KL散度的损失进行联合训练。

Result: 在三个基准数据集和六种先进骨干网络上进行的大量实验表明，MS-Mix的性能持续优于现有方法，为鲁棒的多模态情感增强树立了新标准。

Conclusion: MS-Mix通过其情感感知和自适应的混合机制，有效解决了多模态情感分析中的数据增强挑战，并在多个数据集上取得了最先进的成果。

Abstract: Multimodal Sentiment Analysis (MSA) aims to identify and interpret human
emotions by integrating information from heterogeneous data sources such as
text, video, and audio. While deep learning models have advanced in network
architecture design, they remain heavily limited by scarce multimodal annotated
data. Although Mixup-based augmentation improves generalization in unimodal
tasks, its direct application to MSA introduces critical challenges: random
mixing often amplifies label ambiguity and semantic inconsistency due to the
lack of emotion-aware mixing mechanisms. To overcome these issues, we propose
MS-Mix, an adaptive, emotion-sensitive augmentation framework that
automatically optimizes sample mixing in multimodal settings. The key
components of MS-Mix include: (1) a Sentiment-Aware Sample Selection (SASS)
strategy that effectively prevents semantic confusion caused by mixing samples
with contradictory emotions. (2) a Sentiment Intensity Guided (SIG) module
using multi-head self-attention to compute modality-specific mixing ratios
dynamically based on their respective emotional intensities. (3) a Sentiment
Alignment Loss (SAL) that aligns the prediction distributions across
modalities, and incorporates the Kullback-Leibler-based loss as an additional
regularization term to train the emotion intensity predictor and the backbone
network jointly. Extensive experiments on three benchmark datasets with six
state-of-the-art backbones confirm that MS-Mix consistently outperforms
existing methods, establishing a new standard for robust multimodal sentiment
augmentation. The source code is available at:
https://github.com/HongyuZhu-s/MS-Mix.

</details>


### [207] [ACE-G: Improving Generalization of Scene Coordinate Regression Through Query Pre-Training](https://arxiv.org/abs/2510.11605)
*Leonard Bruns,Axel Barroso-Laguna,Tommaso Cavallari,Áron Monszpart,Sowmya Munukutla,Victor Adrian Prisacariu,Eric Brachmann*

Main category: cs.CV

TL;DR: 通过将坐标回归器与场景表示分离，ACE-G 方法提高了视觉重新定位的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于场景坐标回归（SCR）的方法在泛化能力方面不如传统的特征匹配方法，当查询图像的成像条件（如光照或视角）与训练视图差异过大时，SCR 模型会失效。这是因为它们的设计目标是将训练视图编码到坐标回归器的权重中，导致模型过拟合训练视图。

Method: 提出将坐标回归器和场景表示分离，分别构建一个通用的 Transformer 和一个场景特定的地图编码。这使得 Transformer 可以在数万个场景上进行预训练，并训练 Transformer 从映射图像泛化到未见过的查询图像。

Result: 在多个具有挑战性的重新定位数据集上，ACE-G 方法显著提高了鲁棒性，同时保持了较低的计算成本。

Conclusion: ACE-G 方法通过将坐标回归器与场景表示分离，实现了视觉重新定位的泛化能力和鲁棒性的提升，同时保持了有吸引力的计算效率。

Abstract: Scene coordinate regression (SCR) has established itself as a promising
learning-based approach to visual relocalization. After mere minutes of
scene-specific training, SCR models estimate camera poses of query images with
high accuracy. Still, SCR methods fall short of the generalization capabilities
of more classical feature-matching approaches. When imaging conditions of query
images, such as lighting or viewpoint, are too different from the training
views, SCR models fail. Failing to generalize is an inherent limitation of
previous SCR frameworks, since their training objective is to encode the
training views in the weights of the coordinate regressor itself. The regressor
essentially overfits to the training views, by design. We propose to separate
the coordinate regressor and the map representation into a generic transformer
and a scene-specific map code. This separation allows us to pre-train the
transformer on tens of thousands of scenes. More importantly, it allows us to
train the transformer to generalize from mapping images to unseen query images
during pre-training. We demonstrate on multiple challenging relocalization
datasets that our method, ACE-G, leads to significantly increased robustness
while keeping the computational footprint attractive.

</details>


### [208] [ExpVid: A Benchmark for Experiment Video Understanding & Reasoning](https://arxiv.org/abs/2510.11606)
*Yicheng Xu,Yue Wu,Jiashuo Yu,Ziang Yan,Tianxiang Jiang,Yinan He,Qingsong Zhao,Kai Chen,Yu Qiao,Limin Wang,Manabu Okumura,Yi Wang*

Main category: cs.CV

TL;DR: ExpVid 是首个用于评估 MLLMs 在科学实验视频中能力的基准，发现现有模型在细微差别和长期推理方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能涵盖科学实验视频的细粒度、长期特性，尤其是在湿式实验中，阻碍了 MLLMs 在科学发现中的应用。

Method: 创建了一个名为 ExpVid 的新基准，包含三个层次的任务（细粒度感知、程序理解、科学推理），并采用自动化生成与多学科专家验证相结合的标注流程，确保任务的视觉基础。

Result: 在 ExpVid 基准上评估了 19 个领先的 MLLMs，发现它们在粗粒度识别方面表现良好，但在区分细微差别、跟踪状态变化以及将实验程序与科学结果联系起来方面存在困难。专有模型在高级推理方面优于开源模型。

Conclusion: ExpVid 提供了一个诊断工具，并指明了开发能够成为科学实验可信赖伙伴的 MLLMs 的发展方向。

Abstract: Multimodal Large Language Models (MLLMs) hold promise for accelerating
scientific discovery by interpreting complex experimental procedures. However,
their true capabilities are poorly understood, as existing benchmarks neglect
the fine-grained and long-horizon nature of authentic laboratory work,
especially in wet-lab settings. To bridge this gap, we introduce ExpVid, the
first benchmark designed to systematically evaluate MLLMs on scientific
experiment videos. Curated from peer-reviewed video publications, ExpVid
features a new three-level task hierarchy that mirrors the scientific process:
(1) Fine-grained Perception of tools, materials, and actions; (2) Procedural
Understanding of step order and completeness; and (3) Scientific Reasoning that
connects the full experiment to its published conclusions. Our vision-centric
annotation pipeline, combining automated generation with multi-disciplinary
expert validation, ensures that tasks require visual grounding. We evaluate 19
leading MLLMs on ExpVid and find that while they excel at coarse-grained
recognition, they struggle with disambiguating fine details, tracking state
changes over time, and linking experimental procedures to scientific outcomes.
Our results reveal a notable performance gap between proprietary and
open-source models, particularly in high-order reasoning. ExpVid not only
provides a diagnostic tool but also charts a roadmap for developing MLLMs
capable of becoming trustworthy partners in scientific experimentation.

</details>


### [209] [High-resolution Photo Enhancement in Real-time: A Laplacian Pyramid Network](https://arxiv.org/abs/2510.11613)
*Feng Zhang,Haoyou Deng,Zhiqiang Li,Lida Li,Bin Xu,Qingbo Lu,Zisheng Cao,Minchen Wei,Changxin Gao,Nong Sang,Xiang Bai*

Main category: cs.CV

TL;DR: LLF-LUT++ is a fast and effective photo enhancement network that balances performance and efficiency for edge devices.


<details>
  <summary>Details</summary>
Motivation: Existing photo enhancement methods either achieve powerful performance but are not deployable on edge devices, or prioritize computational efficiency at the cost of inadequate performance. This paper aims to address this gap by proposing a method that is both efficient and effective.

Method: The paper introduces LLF-LUT++, a pyramid network that integrates global and local operators using closed-form Laplacian pyramid decomposition and reconstruction. It uses an image-adaptive 3D LUT for global enhancement based on downsampled image characteristics and a spatial-frequency transformer weight predictor to extract weights. Local Laplacian filters are used for edge detail refinement. The network structure and transformer model have been redesigned for efficiency.

Result: LLF-LUT++ achieves a 2.64 dB improvement in PSNR on the HDR+ dataset and processes 4K images in 13 ms on a single GPU. Experiments on benchmark datasets show favorable performance compared to state-of-the-art methods.

Conclusion: The proposed LLF-LUT++ network effectively balances enhancement performance and computational efficiency, making it suitable for real-world applications and deployment on edge devices. The method demonstrates significant improvements in both image quality and processing speed.

Abstract: Photo enhancement plays a crucial role in augmenting the visual aesthetics of
a photograph. In recent years, photo enhancement methods have either focused on
enhancement performance, producing powerful models that cannot be deployed on
edge devices, or prioritized computational efficiency, resulting in inadequate
performance for real-world applications. To this end, this paper introduces a
pyramid network called LLF-LUT++, which integrates global and local operators
through closed-form Laplacian pyramid decomposition and reconstruction. This
approach enables fast processing of high-resolution images while also achieving
excellent performance. Specifically, we utilize an image-adaptive 3D LUT that
capitalizes on the global tonal characteristics of downsampled images, while
incorporating two distinct weight fusion strategies to achieve coarse global
image enhancement. To implement this strategy, we designed a spatial-frequency
transformer weight predictor that effectively extracts the desired distinct
weights by leveraging frequency features. Additionally, we apply local
Laplacian filters to adaptively refine edge details in high-frequency
components. After meticulously redesigning the network structure and
transformer model, LLF-LUT++ not only achieves a 2.64 dB improvement in PSNR on
the HDR+ dataset, but also further reduces runtime, with 4K resolution images
processed in just 13 ms on a single GPU. Extensive experimental results on two
benchmark datasets further show that the proposed approach performs favorably
compared to state-of-the-art methods. The source code will be made publicly
available at https://github.com/fengzhang427/LLF-LUT.

</details>


### [210] [NV3D: Leveraging Spatial Shape Through Normal Vector-based 3D Object Detection](https://arxiv.org/abs/2510.11632)
*Krittin Chaowakarn,Paramin Sangwongngam,Nang Htet Htet Aung,Chalie Charoenlarpnopparut*

Main category: cs.CV

TL;DR: NV3D是一种利用局部法线向量特征进行3D目标检测的新模型，通过KNN和PCA提取法线向量，并提供两种采样策略以减少数据量。该模型在KITTI数据集上进行训练，并在汽车和骑行者检测方面表现优于基线Voxel R-CNN。


<details>
  <summary>Details</summary>
Motivation: 现有3D目标检测方法要么依赖于多模态融合（存在特征对齐挑战），要么仅提取局部特征（可能过于简化）。NV3D旨在通过利用更丰富的局部法线向量特征来解决这些问题。

Method: NV3D模型通过K-NN和PCA在每个体素（voxel）的基础上计算法线向量，以此作为一种包含表面相关信息的局部特征。模型还引入了两种采样策略（法线向量密度采样和FOV感知分箱采样）来减少数据量。此外，它还采用了元素级注意力融合机制，其中体素特征作为查询和值，法线向量特征作为键。

Result: 在KITTI数据集上，NV3D（未使用采样）在汽车和骑行者检测上的平均精度（mAP）分别为86.60%和80.18%，分别比基线Voxel R-CNN高出2.61%和4.23%。即使在过滤掉约55%的体素后，NV3D仍能实现85.54%的汽车检测mAP，优于基线1.56% mAP。

Conclusion: NV3D通过利用法线向量特征，有效地提升了3D目标检测性能，尤其在识别具有明显空间形状的汽车和骑行者方面。其采样策略能够在保持性能的同时显著减少数据量，展示了该方法的潜力和效率。

Abstract: Recent studies in 3D object detection for autonomous vehicles aim to enrich
features through the utilization of multi-modal setups or the extraction of
local patterns within LiDAR point clouds. However, multi-modal methods face
significant challenges in feature alignment, and gaining features locally can
be oversimplified for complex 3D object detection tasks. In this paper, we
propose a novel model, NV3D, which utilizes local features acquired from voxel
neighbors, as normal vectors computed per voxel basis using K-nearest neighbors
(KNN) and principal component analysis (PCA). This informative feature enables
NV3D to determine the relationship between the surface and pertinent target
entities, including cars, pedestrians, or cyclists. During the normal vector
extraction process, NV3D offers two distinct sampling strategies: normal vector
density-based sampling and FOV-aware bin-based sampling, allowing elimination
of up to 55% of data while maintaining performance. In addition, we applied
element-wise attention fusion, which accepts voxel features as the query and
value and normal vector features as the key, similar to the attention
mechanism. Our method is trained on the KITTI dataset and has demonstrated
superior performance in car and cyclist detection owing to their spatial
shapes. In the validation set, NV3D without sampling achieves 86.60% and 80.18%
mean Average Precision (mAP), greater than the baseline Voxel R-CNN by 2.61%
and 4.23% mAP, respectively. With both samplings, NV3D achieves 85.54% mAP in
car detection, exceeding the baseline by 1.56% mAP, despite roughly 55% of
voxels being filtered out.

</details>


### [211] [IVEBench: Modern Benchmark Suite for Instruction-Guided Video Editing Assessment](https://arxiv.org/abs/2510.11647)
*Yinan Chen,Jiangning Zhang,Teng Hu,Yuxiang Zeng,Zhucun Xue,Qingdong He,Chengjie Wang,Yong Liu,Xiaobin Hu,Shuicheng Yan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为IVEBench的新型视频编辑基准测试套件，用于评估指令驱动的视频编辑方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编辑基准测试在评估指令驱动的视频编辑方面存在不足，具体表现在源视频多样性有限、任务覆盖范围狭窄以及评估指标不全面。

Method: IVEBench包含一个包含600个高质量源视频的数据库，涵盖七个语义维度和32到1024帧的视频长度。它还包括8大类35小类的编辑任务，并通过大型语言模型和专家评审生成和优化提示。此外，IVEBench建立了一个包含视频质量、指令遵从度和视频保真度的三维评估协议，并结合了传统指标和基于多模态大型语言模型的评估方法。

Result: 通过在IVEBench上的广泛实验，证明了该基准测试在评估最先进的指令驱动视频编辑方法方面的有效性，能够提供全面且与人类评估一致的结果。

Conclusion: IVEBench是一个专门为指令驱动视频编辑评估设计的现代基准测试套件，解决了现有基准测试的局限性，并提供了更全面、更符合人类判断的评估方法。

Abstract: Instruction-guided video editing has emerged as a rapidly advancing research
direction, offering new opportunities for intuitive content transformation
while also posing significant challenges for systematic evaluation. Existing
video editing benchmarks fail to support the evaluation of instruction-guided
video editing adequately and further suffer from limited source diversity,
narrow task coverage and incomplete evaluation metrics. To address the above
limitations, we introduce IVEBench, a modern benchmark suite specifically
designed for instruction-guided video editing assessment. IVEBench comprises a
diverse database of 600 high-quality source videos, spanning seven semantic
dimensions, and covering video lengths ranging from 32 to 1,024 frames. It
further includes 8 categories of editing tasks with 35 subcategories, whose
prompts are generated and refined through large language models and expert
review. Crucially, IVEBench establishes a three-dimensional evaluation protocol
encompassing video quality, instruction compliance and video fidelity,
integrating both traditional metrics and multimodal large language model-based
assessments. Extensive experiments demonstrate the effectiveness of IVEBench in
benchmarking state-of-the-art instruction-guided video editing methods, showing
its ability to provide comprehensive and human-aligned evaluation outcomes.

</details>


### [212] [PhySIC: Physically Plausible 3D Human-Scene Interaction and Contact from a Single Image](https://arxiv.org/abs/2510.11649)
*Pradyumna Yalandur Muralidhar,Yuxuan Xue,Xianghui Xie,Margaret Kostyrko,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: PhySIC是一个从单张RGB图像重建具有物理意义的人体与场景交互和接触的框架，解决了单目深度估计中的遮挡和不一致性问题，实现了高精度的3D重建。


<details>
  <summary>Details</summary>
Motivation: 从单张图像重建精确的3D人体和场景对于虚拟现实、机器人和3D场景理解至关重要，但现有方法在处理深度模糊、遮挡和物理不一致接触方面存在困难。

Method: PhySIC框架首先从粗略的单目深度和人体姿态估计开始，然后进行遮挡感知修复，融合可见深度和未缩放几何以构建度量支架，并合成缺失的支撑表面。通过置信加权优化，联合强制执行深度对齐、接触先验、避免穿透和2D重投影一致性，来优化身体姿势、相机参数和全局尺度。显式的遮挡掩码保护不可见区域免受不合理配置的影响。

Result: PhySIC将平均每顶点场景误差从641毫米减少到227毫米，将PA-MPJPE减半至42毫米，并将接触F1分数从0.09提高到0.51。该方法在9秒内完成联合人体-场景优化，端到端处理时间少于27秒，可处理多个人体交互。

Conclusion: PhySIC能够将单张图像转换为物理上合理的人体-场景三维模型，提高了3D场景理解的尺度，并在人体姿态、场景几何和接触重建方面取得了显著的性能提升。

Abstract: Reconstructing metrically accurate humans and their surrounding scenes from a
single image is crucial for virtual reality, robotics, and comprehensive 3D
scene understanding. However, existing methods struggle with depth ambiguity,
occlusions, and physically inconsistent contacts. To address these challenges,
we introduce PhySIC, a framework for physically plausible Human-Scene
Interaction and Contact reconstruction. PhySIC recovers metrically consistent
SMPL-X human meshes, dense scene surfaces, and vertex-level contact maps within
a shared coordinate frame from a single RGB image. Starting from coarse
monocular depth and body estimates, PhySIC performs occlusion-aware inpainting,
fuses visible depth with unscaled geometry for a robust metric scaffold, and
synthesizes missing support surfaces like floors. A confidence-weighted
optimization refines body pose, camera parameters, and global scale by jointly
enforcing depth alignment, contact priors, interpenetration avoidance, and 2D
reprojection consistency. Explicit occlusion masking safeguards invisible
regions against implausible configurations. PhySIC is efficient, requiring only
9 seconds for joint human-scene optimization and under 27 seconds end-to-end.
It naturally handles multiple humans, enabling reconstruction of diverse
interactions. Empirically, PhySIC outperforms single-image baselines, reducing
mean per-vertex scene error from 641 mm to 227 mm, halving PA-MPJPE to 42 mm,
and improving contact F1 from 0.09 to 0.51. Qualitative results show realistic
foot-floor interactions, natural seating, and plausible reconstructions of
heavily occluded furniture. By converting a single image into a physically
plausible 3D human-scene pair, PhySIC advances scalable 3D scene understanding.
Our implementation is publicly available at https://yuxuan-xue.com/physic.

</details>


### [213] [InfiniHuman: Infinite 3D Human Creation with Precise Control](https://arxiv.org/abs/2510.11650)
*Yuxuan Xue,Xianghui Xie,Margaret Kostyrko,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: InfiniHuman是一个框架，通过蒸馏现有基础模型来生成大规模、多样化且经过充分注释的3D人类数据（InfiniHumanData），并在此基础上构建了一个可控的3D人类虚拟化身生成管线（InfiniHumanGen）。


<details>
  <summary>Details</summary>
Motivation: 现有的3D人类虚拟化身生成在覆盖广泛属性（如种族、年龄、服装风格和详细身体形状）时面临挑战，且用于训练的数据集获取成本高昂、规模和多样性受限。本文旨在探索是否能通过蒸馏现有基础模型来生成理论上无界、注释丰富且成本低廉的3D人类数据。

Method: 提出InfiniHuman框架，该框架协同蒸馏基础模型以低成本、高可扩展性地生成注释丰富的3D人类数据。具体包括：1. InfiniHumanData：一个全自动的生成管线，利用视觉-语言和图像生成模型创建大规模多模态数据集。2. InfiniHumanGen：一个基于扩散的生成管线，以文本、身体形状和服装资源为条件，实现快速、逼真且可控的虚拟化身生成。

Result: 用户研究表明，自动生成的身份与扫描渲染无法区分。InfiniHumanData包含111K个身份，具有前所未有的多样性，并附带多粒度文本描述、多视角RGB图像、详细服装图像和SMPL身体形状参数。InfiniHumanGen在视觉质量、生成速度和可控性方面显著优于现有最先进方法。

Conclusion: 该方法通过一种实用且经济的解决方案，实现了高质量、精细控制且理论上无界的虚拟化身生成。将公开释放数据生成管线、InfiniHumanData数据集和InfiniHumanGen模型。

Abstract: Generating realistic and controllable 3D human avatars is a long-standing
challenge, particularly when covering broad attribute ranges such as ethnicity,
age, clothing styles, and detailed body shapes. Capturing and annotating
large-scale human datasets for training generative models is prohibitively
expensive and limited in scale and diversity. The central question we address
in this paper is: Can existing foundation models be distilled to generate
theoretically unbounded, richly annotated 3D human data? We introduce
InfiniHuman, a framework that synergistically distills these models to produce
richly annotated human data at minimal cost and with theoretically unlimited
scalability. We propose InfiniHumanData, a fully automatic pipeline that
leverages vision-language and image generation models to create a large-scale
multi-modal dataset. User study shows our automatically generated identities
are undistinguishable from scan renderings. InfiniHumanData contains 111K
identities spanning unprecedented diversity. Each identity is annotated with
multi-granularity text descriptions, multi-view RGB images, detailed clothing
images, and SMPL body-shape parameters. Building on this dataset, we propose
InfiniHumanGen, a diffusion-based generative pipeline conditioned on text, body
shape, and clothing assets. InfiniHumanGen enables fast, realistic, and
precisely controllable avatar generation. Extensive experiments demonstrate
significant improvements over state-of-the-art methods in visual quality,
generation speed, and controllability. Our approach enables high-quality avatar
generation with fine-grained control at effectively unbounded scale through a
practical and affordable solution. We will publicly release the automatic data
generation pipeline, the comprehensive InfiniHumanData dataset, and the
InfiniHumanGen models at https://yuxuan-xue.com/infini-human.

</details>


### [214] [FACE: Faithful Automatic Concept Extraction](https://arxiv.org/abs/2510.11675)
*Dipkamal Bhusal,Michael Clifford,Sara Rampazzi,Nidhi Rastogi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Interpreting deep neural networks through concept-based explanations offers a
bridge between low-level features and high-level human-understandable
semantics. However, existing automatic concept discovery methods often fail to
align these extracted concepts with the model's true decision-making process,
thereby compromising explanation faithfulness. In this work, we propose FACE
(Faithful Automatic Concept Extraction), a novel framework that augments
Non-negative Matrix Factorization (NMF) with a Kullback-Leibler (KL) divergence
regularization term to ensure alignment between the model's original and
concept-based predictions. Unlike prior methods that operate solely on encoder
activations, FACE incorporates classifier supervision during concept learning,
enforcing predictive consistency and enabling faithful explanations. We provide
theoretical guarantees showing that minimizing the KL divergence bounds the
deviation in predictive distributions, thereby promoting faithful local
linearity in the learned concept space. Systematic evaluations on ImageNet,
COCO, and CelebA datasets demonstrate that FACE outperforms existing methods
across faithfulness and sparsity metrics.

</details>


### [215] [Beyond 'Templates': Category-Agnostic Object Pose, Size, and Shape Estimation from a Single View](https://arxiv.org/abs/2510.11687)
*Jinyu Zhang,Haitao Lin,Jiashu Hou,Xiangyang Xue,Yanwei Fu*

Main category: cs.CV

TL;DR: 该框架能够从单张RGB-D图像中同时预测物体的6D姿态、尺寸和密集形状，无需物体先验知识或类别标签，实现了类别无关的实时推理，并在多种基准测试中展现了强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 从视觉输入估计物体的6D姿态、尺寸和形状是计算机视觉中的一个基本问题，在机器人抓取和操作中有重要应用。现有方法依赖于物体特定的先验知识（如CAD模型或模板），或者由于姿态-形状耦合和多阶段流水线而导致跨类别的泛化能力有限。

Method: 提出一个统一的、类别无关的框架，利用Transformer编码器（增强了专家混合）融合视觉基础模型的2D密集特征和部分3D点云，并使用并行的解码器进行姿态-尺寸估计和形状重建，实现了28 FPS的实时推理。

Result: 在SOPE、ROPE、ObjaversePose和HANDAL四个不同的基准测试中，该框架在已见类别上达到了最先进的准确度，并对未见的真实世界物体展现出强大的零样本泛化能力。

Conclusion: 该框架通过融合2D和3D特征，并采用并行解码器结构，实现了对物体6D姿态、尺寸和形状的同时预测，有效解决了现有方法的局限性，并在开放集6D理解方面树立了新的标杆。

Abstract: Estimating an object's 6D pose, size, and shape from visual input is a
fundamental problem in computer vision, with critical applications in robotic
grasping and manipulation. Existing methods either rely on object-specific
priors such as CAD models or templates, or suffer from limited generalization
across categories due to pose-shape entanglement and multi-stage pipelines. In
this work, we propose a unified, category-agnostic framework that
simultaneously predicts 6D pose, size, and dense shape from a single RGB-D
image, without requiring templates, CAD models, or category labels at test
time. Our model fuses dense 2D features from vision foundation models with
partial 3D point clouds using a Transformer encoder enhanced by a
Mixture-of-Experts, and employs parallel decoders for pose-size estimation and
shape reconstruction, achieving real-time inference at 28 FPS. Trained solely
on synthetic data from 149 categories in the SOPE dataset, our framework is
evaluated on four diverse benchmarks SOPE, ROPE, ObjaversePose, and HANDAL,
spanning over 300 categories. It achieves state-of-the-art accuracy on seen
categories while demonstrating remarkably strong zero-shot generalization to
unseen real-world objects, establishing a new standard for open-set 6D
understanding in robotics and embodied AI.

</details>


### [216] [Diffusion Transformers with Representation Autoencoders](https://arxiv.org/abs/2510.11690)
*Boyang Zheng,Nanye Ma,Shengbang Tong,Saining Xie*

Main category: cs.CV

TL;DR: 使用新的“表示自编码器”（RAE）替代DiT中的VAE，以提高潜空间表示能力和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的DiT模型依赖于老旧的VAE，存在骨干网络过时、潜空间维度低、表示能力弱等问题，限制了生成质量。

Method: 将预训练的表示编码器（如DINO, SigLIP, MAE）与训练好的解码器结合，形成RAE，并解决了在RAE的高维潜空间中进行Diffusion Transformer有效操作的挑战。

Result: RAE模型在ImageNet上实现了更快的收敛速度，无需额外的表示对齐损失。使用配备DDT头的DiT变体，在256x256分辨率下（无引导）达到了1.51 FID，在256x256和512x512分辨率下（有引导）均达到了1.13 FID。

Conclusion: RAE模型在潜空间表示和图像生成方面具有明显优势，应成为Diffusion Transformer训练的新默认选择。

Abstract: Latent generative modeling, where a pretrained autoencoder maps pixels into a
latent space for the diffusion process, has become the standard strategy for
Diffusion Transformers (DiT); however, the autoencoder component has barely
evolved. Most DiTs continue to rely on the original VAE encoder, which
introduces several limitations: outdated backbones that compromise
architectural simplicity, low-dimensional latent spaces that restrict
information capacity, and weak representations that result from purely
reconstruction-based training and ultimately limit generative quality. In this
work, we explore replacing the VAE with pretrained representation encoders
(e.g., DINO, SigLIP, MAE) paired with trained decoders, forming what we term
Representation Autoencoders (RAEs). These models provide both high-quality
reconstructions and semantically rich latent spaces, while allowing for a
scalable transformer-based architecture. Since these latent spaces are
typically high-dimensional, a key challenge is enabling diffusion transformers
to operate effectively within them. We analyze the sources of this difficulty,
propose theoretically motivated solutions, and validate them empirically. Our
approach achieves faster convergence without auxiliary representation alignment
losses. Using a DiT variant equipped with a lightweight, wide DDT head, we
achieve strong image generation results on ImageNet: 1.51 FID at 256x256 (no
guidance) and 1.13 at both 256x256 and 512x512 (with guidance). RAE offers
clear advantages and should be the new default for diffusion transformer
training.

</details>


### [217] [Bayesian Topological Convolutional Neural Nets](https://arxiv.org/abs/2510.11704)
*Sarah Harkins Dayton,Hayden Everett,Ioannis Schizas,David L. Boothe Jr.,Vasileios Maroulas*

Main category: cs.CV

TL;DR: 提出了一种结合贝叶斯采样和拓扑感知学习的贝叶斯拓扑卷积神经网络，用于图像分类。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络需要大量数据，预测过于自信且无法量化预测的不确定性。为了解决这些问题，我们提出了一种新的贝叶斯拓扑卷积神经网络。

Method: 利用流形信息加速训练，通过在网络参数上设置先验分布并学习适当的后验分布来减少校准误差。学习成本中包含一致性条件，以改进先验分布和网络性能。

Result: 在基准图像分类数据集上评估模型，证明其优于传统CNN、贝叶斯神经网络和拓扑卷积神经网络。该方法在训练数据有限或损坏的情况下具有优势，并且能够更好地量化不确定性，识别未训练过的分布外数据。

Conclusion: 所提出的新颖混合方法有潜力用于更高效、更鲁棒的图像分类。

Abstract: Convolutional neural networks (CNNs) have been established as the main
workhorse in image data processing; nonetheless, they require large amounts of
data to train, often produce overconfident predictions, and frequently lack the
ability to quantify the uncertainty of their predictions. To address these
concerns, we propose a new Bayesian topological CNN that promotes a novel
interplay between topology-aware learning and Bayesian sampling. Specifically,
it utilizes information from important manifolds to accelerate training while
reducing calibration error by placing prior distributions on network parameters
and properly learning appropriate posteriors. One important contribution of our
work is the inclusion of a consistency condition in the learning cost, which
can effectively modify the prior distributions to improve the performance of
our novel network architecture. We evaluate the model on benchmark image
classification datasets and demonstrate its superiority over conventional CNNs,
Bayesian neural networks (BNNs), and topological CNNs. In particular, we supply
evidence that our method provides an advantage in situations where training
data is limited or corrupted. Furthermore, we show that the new model allows
for better uncertainty quantification than standard BNNs since it can more
readily identify examples of out-of-distribution data on which it has not been
trained. Our results highlight the potential of our novel hybrid approach for
more efficient and robust image classification.

</details>


### [218] [DiT360: High-Fidelity Panoramic Image Generation via Hybrid Training](https://arxiv.org/abs/2510.11712)
*Haoran Feng,Dizhe Zhang,Xiangtai Li,Bo Du,Lu Qi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we propose DiT360, a DiT-based framework that performs hybrid
training on perspective and panoramic data for panoramic image generation. For
the issues of maintaining geometric fidelity and photorealism in generation
quality, we attribute the main reason to the lack of large-scale, high-quality,
real-world panoramic data, where such a data-centric view differs from prior
methods that focus on model design. Basically, DiT360 has several key modules
for inter-domain transformation and intra-domain augmentation, applied at both
the pre-VAE image level and the post-VAE token level. At the image level, we
incorporate cross-domain knowledge through perspective image guidance and
panoramic refinement, which enhance perceptual quality while regularizing
diversity and photorealism. At the token level, hybrid supervision is applied
across multiple modules, which include circular padding for boundary
continuity, yaw loss for rotational robustness, and cube loss for distortion
awareness. Extensive experiments on text-to-panorama, inpainting, and
outpainting tasks demonstrate that our method achieves better boundary
consistency and image fidelity across eleven quantitative metrics. Our code is
available at https://github.com/Insta360-Research-Team/DiT360.

</details>


### [219] [Point Prompting: Counterfactual Tracking with Video Diffusion Models](https://arxiv.org/abs/2510.11715)
*Ayush Shrivastava,Sanyam Mehta,Daniel Geng,Andrew Owens*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Trackers and video generators solve closely related problems: the former
analyze motion, while the latter synthesize it. We show that this connection
enables pretrained video diffusion models to perform zero-shot point tracking
by simply prompting them to visually mark points as they move over time. We
place a distinctively colored marker at the query point, then regenerate the
rest of the video from an intermediate noise level. This propagates the marker
across frames, tracing the point's trajectory. To ensure that the marker
remains visible in this counterfactual generation, despite such markers being
unlikely in natural videos, we use the unedited initial frame as a negative
prompt. Through experiments with multiple image-conditioned video diffusion
models, we find that these "emergent" tracks outperform those of prior
zero-shot methods and persist through occlusions, often obtaining performance
that is competitive with specialized self-supervised models.

</details>


### [220] [Ev4DGS: Novel-view Rendering of Non-Rigid Objects from Monocular Event Streams](https://arxiv.org/abs/2510.11717)
*Takuya Nakabayashi,Navami Kairanda,Hideo Saito,Vladislav Golyanik*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Event cameras offer various advantages for novel view rendering compared to
synchronously operating RGB cameras, and efficient event-based techniques
supporting rigid scenes have been recently demonstrated in the literature. In
the case of non-rigid objects, however, existing approaches additionally
require sparse RGB inputs, which can be a substantial practical limitation; it
remains unknown if similar models could be learned from event streams only.
This paper sheds light on this challenging open question and introduces Ev4DGS,
i.e., the first approach for novel view rendering of non-rigidly deforming
objects in the explicit observation space (i.e., as RGB or greyscale images)
from monocular event streams. Our method regresses a deformable 3D Gaussian
Splatting representation through 1) a loss relating the outputs of the
estimated model with the 2D event observation space, and 2) a coarse 3D
deformation model trained from binary masks generated from events. We perform
experimental comparisons on existing synthetic and newly recorded real datasets
with non-rigid objects. The results demonstrate the validity of Ev4DGS and its
superior performance compared to multiple naive baselines that can be applied
in our setting. We will release our models and the datasets used in the
evaluation for research purposes; see the project webpage:
https://4dqv.mpi-inf.mpg.de/Ev4DGS/.

</details>


### [221] [CodePlot-CoT: Mathematical Visual Reasoning by Thinking with Code-Driven Images](https://arxiv.org/abs/2510.11718)
*Chengqi Duan,Kaiyue Sun,Rongyao Fang,Manyuan Zhang,Yan Feng,Ying Luo,Yufang Liu,Ke Wang,Peng Pei,Xunliang Cai,Hongsheng Li,Yi Ma,Xihui Liu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advances in Large Language Models (LLMs) and Vision Language Models
(VLMs) have shown significant progress in mathematical reasoning, yet they
still face a critical bottleneck with problems requiring visual assistance,
such as drawing auxiliary lines or plotting functions to solve the problems.
Most LLMs and VLMs are constrained to text-only reasoning chains, while
multimodal unified models that can generate interleaved text and images lack
the necessary precision and controllability for such tasks. To address this, we
propose CodePlot-CoT, a code-driven Chain-of-Thought paradigm for "thinking
with images" in mathematics. Our approach leverages the VLM to generate text
reasoning as well as executable plotting code, which is then rendered into
images as "visual thought", to solve mathematical problems. To achieve this, we
first construct Math-VR, the first large-scale, bilingual dataset and benchmark
for Mathematics problems with Visual Reasoning, comprising 178K samples.
Second, to create high-quality training data, we develop a state-of-the-art
image-to-code converter specialized for parsing complex mathematical figures
into codes. Finally, using these training data, we train the CodePlot-CoT model
for solving mathematical problems. Experimental results show that our model
achieves up to 21% increase over base model on our new benchmark, fully
validating the efficacy of our proposed code-driven reasoning paradigm. Our
work opens a new direction for multimodal mathematical reasoning and provides
the community with the first large-scale dataset, comprehensive benchmark, and
strong approach for such problems. To facilitate future research, we make our
datasets, code, and pretrained models publicly available at
https://github.com/HKU-MMLab/Math-VR-CodePlot-CoT.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [222] [Table Question Answering in the Era of Large Language Models: A Comprehensive Survey of Tasks, Methods, and Evaluation](https://arxiv.org/abs/2510.09671)
*Wei Zhou,Bolei Ma,Annemarie Friedrich,Mohsen Mesgar*

Main category: cs.CL

TL;DR: LLM在表格问答（TQA）领域的研究现状，重点关注任务形式、核心挑战和方法趋势，并探讨新兴研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有TQA研究缺乏系统性的组织和理解，尤其是在LLM和强化学习等新兴研究方向的背景下，因此需要对该领域进行梳理和总结。

Method: 对TQA研究进行全面的分类，包括基准测试和任务设置，并根据所解决的挑战对现有建模策略进行分组，分析其优缺点。

Result: 对TQA的研究进行了系统性的组织和理解，为TQA社区提供了一个整合的基础，促进对现有技术水平的深入理解，并指导该领域未来的发展。

Conclusion: 本调查为TQA社区提供了一个整合的基础，促进了对现有技术水平的深入理解，并指导了该领域未来的发展。

Abstract: Table Question Answering (TQA) aims to answer natural language questions
about tabular data, often accompanied by additional contexts such as text
passages. The task spans diverse settings, varying in table representation,
question/answer complexity, modality involved, and domain. While recent
advances in large language models (LLMs) have led to substantial progress in
TQA, the field still lacks a systematic organization and understanding of task
formulations, core challenges, and methodological trends, particularly in light
of emerging research directions such as reinforcement learning. This survey
addresses this gap by providing a comprehensive and structured overview of TQA
research with a focus on LLM-based methods. We provide a comprehensive
categorization of existing benchmarks and task setups. We group current
modeling strategies according to the challenges they target, and analyze their
strengths and limitations. Furthermore, we highlight underexplored but timely
topics that have not been systematically covered in prior research. By unifying
disparate research threads and identifying open problems, our survey offers a
consolidated foundation for the TQA community, enabling a deeper understanding
of the state of the art and guiding future developments in this rapidly
evolving area.

</details>


### [223] [Emotionally Charged, Logically Blurred: AI-driven Emotional Framing Impairs Human Fallacy Detection](https://arxiv.org/abs/2510.09695)
*Yanran Chen,Lynn Greschner,Roman Klinger,Michael Klenk,Steffen Eger*

Main category: cs.CL

TL;DR: 该研究首次探讨了情感操控与逻辑谬误在说服力中的相互作用，并使用大型语言模型（LLM）来自动化这一过程。研究发现，LLM生成的情感操控会降低人类检测谬误的能力，并且特定的情感（如愉悦）会比其他情感（如恐惧或悲伤）更能增强说服力。


<details>
  <summary>Details</summary>
Motivation: 逻辑谬误在公开交流中很常见，并且可能具有误导性。情感操控可能会使原本不合理的论点看起来更具说服力。本研究旨在探讨情感操控如何与逻辑谬误相互作用，影响论点的说服力，并首次使用大型语言模型（LLM）来系统地研究这一现象。

Method: 研究者们首先评估了八种大型语言模型（LLM）在保持逻辑结构的同时，向谬误论点注入情感诉求的能力。接着，研究者利用表现最佳的模型生成实验材料，并进行了一项包含人类参与者的研究，以评估情感操控对谬误检测和论点说服力的影响。

Result: 结果显示，与中性条件相比，经过LLM驱动的情感操控后，人类检测谬误的F1分数平均下降了14.5%。此外，研究还发现，当感知到愉悦情绪时，人类在谬误检测方面的表现优于感知到恐惧或悲伤情绪时。同时，这三种情绪状态都显著提高了论点的说服力，相比之下，中性或其他情绪状态的说服力较低。

Conclusion: 本研究表明，由LLM驱动的情感操控可以降低人类对逻辑谬误的识别能力，并显著增强论点的说服力。这些发现对于理解和应对人工智能驱动的情感操控在谬误论证中的潜在应用具有重要意义。

Abstract: Logical fallacies are common in public communication and can mislead
audiences; fallacious arguments may still appear convincing despite lacking
soundness, because convincingness is inherently subjective. We present the
first computational study of how emotional framing interacts with fallacies and
convincingness, using large language models (LLMs) to systematically change
emotional appeals in fallacious arguments. We benchmark eight LLMs on injecting
emotional appeal into fallacious arguments while preserving their logical
structures, then use the best models to generate stimuli for a human study. Our
results show that LLM-driven emotional framing reduces human fallacy detection
in F1 by 14.5% on average. Humans perform better in fallacy detection when
perceiving enjoyment than fear or sadness, and these three emotions also
correlate with significantly higher convincingness compared to neutral or other
emotion states. Our work has implications for AI-driven emotional manipulation
in the context of fallacious argumentation.

</details>


### [224] [The Idola Tribus of AI: Large Language Models tend to perceive order where none exists](https://arxiv.org/abs/2510.09709)
*Shin-nosuke Ishikawa,Masato Todo,Taiki Ogihara,Hirotsugu Ohba*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在识别数字序列规律时，即使在简单任务中也倾向于生成不合理的模式。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在复杂现实世界任务中的逻辑一致性和自我连贯性至关重要，因为现有方法（如检索增强生成和AI代理框架）依赖于这些能力。

Method: 通过实验，要求LLMs解释各种整数序列（从算术序列到随机生成序列）的模式，以识别LLMs在逻辑一致性方面的失败案例。

Result: LLMs能成功识别算术和几何序列的模式，但在分析随机生成序列时，频繁过度识别与给定数字不符的模式。即使是采用思维链推理的多步模型（如OpenAI o3、o4-mini和Google Gemini 2.5 Flash Preview Thinking）也存在此问题。

Conclusion: LLMs倾向于识别不存在的模式，这可以被视为AI模型的“部落 ഇമാ”的等价物，并可能限制其在需要逻辑推理的应用任务中的能力，即使使用了思维链推理机制。

Abstract: We present a tendency of large language models (LLMs) to generate absurd
patterns despite their clear inappropriateness in a simple task of identifying
regularities in number series. Several approaches have been proposed to apply
LLMs to complex real-world tasks, such as providing knowledge through
retrieval-augmented generation and executing multi-step tasks using AI agent
frameworks. However, these approaches rely on the logical consistency and
self-coherence of LLMs, making it crucial to evaluate these aspects and
consider potential countermeasures. To identify cases where LLMs fail to
maintain logical consistency, we conducted an experiment in which LLMs were
asked to explain the patterns in various integer sequences, ranging from
arithmetic sequences to randomly generated integer series. While the models
successfully identified correct patterns in arithmetic and geometric sequences,
they frequently over-recognized patterns that were inconsistent with the given
numbers when analyzing randomly generated series. This issue was observed even
in multi-step reasoning models, including OpenAI o3, o4-mini, and Google Gemini
2.5 Flash Preview Thinking. This tendency to perceive non-existent patterns can
be interpreted as the AI model equivalent of Idola Tribus and highlights
potential limitations in their capability for applied tasks requiring logical
reasoning, even when employing chain-of-thought reasoning mechanisms.

</details>


### [225] [SeCon-RAG: A Two-Stage Semantic Filtering and Conflict-Free Framework for Trustworthy RAG](https://arxiv.org/abs/2510.09710)
*Xiaonan Si,Meilin Zhu,Simeng Qin,Lijia Yu,Lijun Zhang,Shuaitong Liu,Xinfeng Li,Ranjie Duan,Yang Liu,Xiaojun Jia*

Main category: cs.CL

TL;DR: 本研究提出了一种名为SeCon-RAG的两阶段框架，用于增强检索增强生成（RAG）系统的可信度，通过结合语义过滤和冲突检测来抵御语料库投毒和污染攻击，同时最大限度地保留有价值的信息，并在各种实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）系统容易受到语料库投毒和污染攻击，导致输出不完整，而现有的防御措施过于激进，会丢失有价值的信息，降低生成可靠性。

Method: 提出一个两阶段的框架：第一阶段，使用实体-意图-关系提取器（EIRE）引导联合过滤，结合语义和聚类过滤，提取实体、潜在目标和实体关系，评估语义相关性，选择性地将文档添加到干净的检索数据库中。第二阶段，提出一个EIRE引导的冲突感知过滤模块，在生成最终答案之前，分析查询、候选答案和检索到的知识之间的语义一致性，过滤掉可能误导模型的内部和外部矛盾。

Result: SeCon-RAG 框架有效地保留了有用的知识，同时减轻了冲突污染，在生成鲁棒性和输出可信度方面取得了显著的改进。通过在各种大型语言模型和数据集上的广泛实验，证明了 SeCon-RAG 明显优于最先进的防御方法。

Conclusion: 所提出的两阶段SeCon-RAG框架能够有效抵御RAG系统中的污染攻击，同时最大限度地保留有价值的信息，显著提高生成鲁棒性和输出可信度。

Abstract: Retrieval-augmented generation (RAG) systems enhance large language models
(LLMs) with external knowledge but are vulnerable to corpus poisoning and
contamination attacks, which can compromise output integrity. Existing defenses
often apply aggressive filtering, leading to unnecessary loss of valuable
information and reduced reliability in generation. To address this problem, we
propose a two-stage semantic filtering and conflict-free framework for
trustworthy RAG. In the first stage, we perform a joint filter with semantic
and cluster-based filtering which is guided by the Entity-intent-relation
extractor (EIRE). EIRE extracts entities, latent objectives, and entity
relations from both the user query and filtered documents, scores their
semantic relevance, and selectively adds valuable documents into the clean
retrieval database. In the second stage, we proposed an EIRE-guided
conflict-aware filtering module, which analyzes semantic consistency between
the query, candidate answers, and retrieved knowledge before final answer
generation, filtering out internal and external contradictions that could
mislead the model. Through this two-stage process, SeCon-RAG effectively
preserves useful knowledge while mitigating conflict contamination, achieving
significant improvements in both generation robustness and output
trustworthiness. Extensive experiments across various LLMs and datasets
demonstrate that the proposed SeCon-RAG markedly outperforms state-of-the-art
defense methods.

</details>


### [226] [ReaLM: Residual Quantization Bridging Knowledge Graph Embeddings and Large Language Models](https://arxiv.org/abs/2510.09711)
*Wenbin Guo,Xin Wang,Jiaoyan Chen,Lingbing Guo,Zhao Li,Zirui Chen*

Main category: cs.CL

TL;DR: LLM在知识图谱补全（KGC）方面展现出强大潜力，但现有方法未能充分利用结构化语义表示，因其连续嵌入空间与LLM的离散令牌空间不匹配。为解决此问题，提出ReaLM框架，通过残差向量量化将预训练KG嵌入离散化为代码序列，并作为可学习令牌整合进LLM词汇表，实现符号知识与上下文知识的融合。此外，结合本体指导的类别约束，增强语义一致性。实验证明ReaLM在基准数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-KGC方法未能充分利用结构化语义表示，因其连续嵌入空间与LLM的离散令牌空间不匹配，阻碍了语义迁移并限制了性能。

Method: 提出ReaLM框架，通过残差向量量化（residual vector quantization）将预训练的知识图谱（KG）嵌入离散化为紧凑的代码序列，并将其作为可学习的令牌整合到LLM的词汇表中，实现符号知识和上下文知识的无缝融合。同时，引入了本体指导的类别约束（ontology-guided class constraints）来强制执行语义一致性，并根据类别兼容性来优化实体预测。

Result: 在两个广泛使用的基准数据集上的大量实验表明，ReaLM取得了最先进的性能。

Conclusion: ReaLM通过残差向量量化有效弥合了知识图谱嵌入和LLM令牌化之间的差距，并结合本体指导的类别约束，实现了结构化知识与大型语言模型的有效融合，达到了最先进的性能。

Abstract: Large Language Models (LLMs) have recently emerged as a powerful paradigm for
Knowledge Graph Completion (KGC), offering strong reasoning and generalization
capabilities beyond traditional embedding-based approaches. However, existing
LLM-based methods often struggle to fully exploit structured semantic
representations, as the continuous embedding space of pretrained KG models is
fundamentally misaligned with the discrete token space of LLMs. This
discrepancy hinders effective semantic transfer and limits their performance.
To address this challenge, we propose ReaLM, a novel and effective framework
that bridges the gap between KG embeddings and LLM tokenization through the
mechanism of residual vector quantization. ReaLM discretizes pretrained KG
embeddings into compact code sequences and integrates them as learnable tokens
within the LLM vocabulary, enabling seamless fusion of symbolic and contextual
knowledge. Furthermore, we incorporate ontology-guided class constraints to
enforce semantic consistency, refining entity predictions based on class-level
compatibility. Extensive experiments on two widely used benchmark datasets
demonstrate that ReaLM achieves state-of-the-art performance, confirming its
effectiveness in aligning structured knowledge with large-scale language
models.

</details>


### [227] [All Code, No Thought: Current Language Models Struggle to Reason in Ciphered Language](https://arxiv.org/abs/2510.09714)
*Shiyuan Guo,Henry Sleight,Fabien Roger*

Main category: cs.CL

TL;DR: 攻击者可能通过密码化推理来规避链式思考（CoT）监控，但即使是顶尖模型也难以在不常见的密码中进行推理，准确率下降明显。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理的普及，检测有害AI行为变得至关重要。链式思考（CoT）监控是一种广泛用于检测对抗性攻击和AI失准的方法。然而，攻击者和失准模型可能通过密码化推理（即隐藏在加密、翻译或压缩文本中的推理）来规避CoT监控。因此，评估这种风险是必要的。

Method: 为了评估密码化推理的风险，研究人员测试了模型在不同密码下进行推理的能力。他们针对28种不同的密码，对多达10个模型进行了微调和提示，以测试它们在该密码下进行推理的能力。并将模型在数学问题上的准确率作为衡量推理能力的代理指标。

Result: 研究发现，模型在密码化推理方面存在不对称性：即使模型能够准确地将密码化文本翻译成英文，但在密码化文本中进行推理时的准确率却显著下降。即使是顶尖模型，在处理不常见的密码时也面临困难，尽管它们可以准确地在常见的密码（如rot13）中进行推理。研究还表明，密码化推理能力与预训练数据中密码的普遍性相关，并且随着微调数据的增加，密码化推理能力仅缓慢提高。

Conclusion: 研究结果表明，目前模型利用密码化推理来规避CoT监控可能是一种无效的策略。该研究为未来限制此类能力的发展提供了指导。

Abstract: Detecting harmful AI actions is important as AI agents gain adoption.
Chain-of-thought (CoT) monitoring is one method widely used to detect
adversarial attacks and AI misalignment. However, attackers and misaligned
models might evade CoT monitoring through ciphered reasoning: reasoning hidden
in encrypted, translated, or compressed text. To assess this risk, we test
whether models can perform ciphered reasoning. For each of 28 different
ciphers, we fine-tune and prompt up to 10 models to reason in that cipher. We
measure model accuracy on math problems as a proxy for reasoning ability.
Across the models we test, we find an asymmetry: model accuracy can drop
significantly when reasoning in ciphered text, even though models demonstrate
comprehension of ciphered text by being able to translate it accurately to
English. Even frontier models struggle with lesser-known ciphers, although they
can reason accurately in well-known ciphers like rot13. We show that ciphered
reasoning capability correlates with cipher prevalence in pretraining data. We
also identify scaling laws showing that ciphered reasoning capability improves
slowly with additional fine-tuning data. Our work suggests that evading CoT
monitoring using ciphered reasoning may be an ineffective tactic for current
models and offers guidance on constraining the development of this capability
in future frontier models.

</details>


### [228] [Preference-Aware Memory Update for Long-Term LLM Agents](https://arxiv.org/abs/2510.09720)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.CL

TL;DR: LLM代理的一个关键因素是它们利用长期记忆的能力。虽然现有方法在存储和检索方面取得了进展，但在内存更新方面却有所不足。我们提出了一种称为PAMU的偏好感知内存更新机制，该机制通过结合滑动窗口平均值（SW）和指数移动平均值（EMA）来动态改进偏好记忆表示。 PAMU在LoCoMo数据集的五个任务场景的实验中，显著提高了LLM在五个基线上的输出质量，证明了其在长期对话中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的长期记忆机制在更新方面存在不足，无法根据用户行为和上下文动态地改进偏好记忆表示。

Method: 提出了一种偏好感知内存更新机制（PAMU），该机制通过集成滑动窗口平均值（SW）和指数移动平均值（EMA）来构建融合的、偏好感知的表示，能够捕捉短期波动和长期用户趋势。

Result: 在LoCoMo数据集的五个任务场景中，PAMU显著提高了五个基线LLM的输出质量。

Conclusion: PAMU能够有效地在长期对话中动态地改进LLM的偏好记忆表示，从而提高其输出质量。

Abstract: One of the key factors influencing the reasoning capabilities of LLM-based
agents is their ability to leverage long-term memory. Integrating long-term
memory mechanisms allows agents to make informed decisions grounded in
historical interactions. While recent advances have significantly improved the
storage and retrieval components, by encoding memory into dense vectors for
similarity search or organizing memory as structured knowledge graphs most
existing approaches fall short in memory updating. In particular, they lack
mechanisms for dynamically refining preference memory representations in
response to evolving user behaviors and contexts. To address this gap, we
propose a Preference-Aware Memory Update Mechanism (PAMU) that enables dynamic
and personalized memory refinement. By integrating sliding window averages (SW)
with exponential moving averages (EMA), PAMU constructs a fused
preference-aware representation that captures both short-term fluctuations and
long-term user tendencies. We conduct experiments on five task scenarios of the
LoCoMo dataset, and the results show that our mechanism can significantly
improve the output quality of LLM in five baselines, validating its
effectiveness in long-term conversations.

</details>


### [229] [Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation](https://arxiv.org/abs/2510.09722)
*Fanwei Zhu,Jinke Yu,Zulong Chen,Ying Zhou,Junhao Ji,Zhibo Yang,Yuxue Zhang,Haoyuan Hu,Zhenghao Liu*

Main category: cs.CL

TL;DR: 我们提出了一个自动化简历信息提取框架，解决了布局多样性、LLM成本和缺乏标准化评估的问题。该框架结合了布局解析器、高效LLM提取器和两阶段评估框架，在准确性和效率方面显著优于现有方法，并已成功应用于阿里巴巴智能HR平台。


<details>
  <summary>Details</summary>
Motivation: 自动化简历信息提取在人才招聘中至关重要，但面临简历格式多样、LLM成本高和缺乏标准化评估工具的挑战。

Method: 提出一个结合了精调布局解析器（用于规范化文档格式）、基于并行提示和指令调优的高效LLM提取器，以及一个支持新基准数据集的两阶段自动化评估框架。

Result: 我们的框架在准确性和效率方面显著优于现有基线。特别是，我们证明了一个精调过的0.6B小型LLM在显著降低推理延迟和计算成本的同时，达到了顶尖水平的准确性。

Conclusion: 所提出的框架能够有效解决自动化简历信息提取中的主要挑战，并在准确性和效率方面取得了显著的改进，已成功部署于实际生产环境。

Abstract: Automated resume information extraction is critical for scaling talent
acquisition, yet its real-world deployment faces three major challenges: the
extreme heterogeneity of resume layouts and content, the high cost and latency
of large language models (LLMs), and the lack of standardized datasets and
evaluation tools. In this work, we present a layout-aware and
efficiency-optimized framework for automated extraction and evaluation that
addresses all three challenges. Our system combines a fine-tuned layout parser
to normalize diverse document formats, an inference-efficient LLM extractor
based on parallel prompting and instruction tuning, and a robust two-stage
automated evaluation framework supported by new benchmark datasets. Extensive
experiments show that our framework significantly outperforms strong baselines
in both accuracy and efficiency. In particular, we demonstrate that a
fine-tuned compact 0.6B LLM achieves top-tier accuracy while significantly
reducing inference latency and computational cost. The system is fully deployed
in Alibaba's intelligent HR platform, supporting real-time applications across
its business units.

</details>


### [230] [VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented Generation](https://arxiv.org/abs/2510.09733)
*Yubo Sun,Chunyi Peng,Yukun Yan,Shi Yu,Zhenghao Liu,Chi Chen,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: EVisRAG是一个改进的VRAG框架，通过多图证据整合提升视觉推理能力，并在多个VQA基准测试中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有VRAG系统在整合多图证据方面存在不足，易导致推理不充分和结论错误。

Method: 提出EVisRAG框架，通过逐图证据记录和聚合证据进行推理。引入RS-GRPO算法，将细粒度奖励与特定范围的令牌绑定，以联合优化视觉感知和推理能力。

Result: EVisRAG在多个VQA基准测试中平均提升27%，相比基础VLM有显著的端到端收益。

Conclusion: EVisRAG通过精确感知和定位多图中的相关证据，并从中推导出最终答案，显著提高了答案的准确性。

Abstract: Visual retrieval-augmented generation (VRAG) augments vision-language models
(VLMs) with external visual knowledge to ground reasoning and reduce
hallucinations. Yet current VRAG systems often fail to reliably perceive and
integrate evidence across multiple images, leading to weak grounding and
erroneous conclusions. In this paper, we propose EVisRAG, an end-to-end
framework that learns to reason with evidence-guided multi-image to address
this issue. The model first observes retrieved images and records per-image
evidence, then derives the final answer from the aggregated evidence. To train
EVisRAG effectively, we introduce Reward-Scoped Group Relative Policy
Optimization (RS-GRPO), which binds fine-grained rewards to scope-specific
tokens to jointly optimize visual perception and reasoning abilities of VLMs.
Experimental results on multiple visual question answering benchmarks
demonstrate that EVisRAG delivers substantial end-to-end gains over backbone
VLM with 27\% improvements on average. Further analysis shows that, powered by
RS-GRPO, EVisRAG improves answer accuracy by precisely perceiving and
localizing question-relevant evidence across multiple images and deriving the
final answer from that evidence, much like a real detective.

</details>


### [231] [MedAgentAudit: Diagnosing and Quantifying Collaborative Failure Modes in Medical Multi-Agent Systems](https://arxiv.org/abs/2510.10185)
*Lei Gu,Yinghao Zhu,Haoran Sang,Zixiang Wang,Dehao Sui,Wen Tang,Ewen Harrison,Junyi Gao,Lequan Yu,Liantao Ma*

Main category: cs.CL

TL;DR: LLM驱动的多智能体医疗咨询系统评估不应仅限于最终答案的准确性，而应关注其推理过程的可靠性。本研究通过对3600个病例的分析，揭示了四种主要的协作失败模式，强调了透明度和可审计的推理过程对于医疗AI的负责任发展至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有LLM多智能体系统在医疗咨询中的评估过于关注最终答案的准确性，忽视了其内部推理过程的可靠性和可验证性，这在高风险的医疗应用中存在潜在风险。

Method: 通过对来自六个医疗数据集和六个多智能体框架的3600个病例进行大规模实证研究，结合定性分析和定量审计，开发了协作失败模式的分类法。

Result: 研究识别出四种主要的协作失败模式：由于模型共有的缺陷导致的错误共识、正确少数意见被压制、无效的讨论动态以及综合过程中关键信息的丢失。

Conclusion: 仅凭高准确性不足以赢得临床或公众的信任，透明且可审计的推理过程是医疗AI负责任发展和部署的基石。

Abstract: While large language model (LLM)-based multi-agent systems show promise in
simulating medical consultations, their evaluation is often confined to
final-answer accuracy. This practice treats their internal collaborative
processes as opaque "black boxes" and overlooks a critical question: is a
diagnostic conclusion reached through a sound and verifiable reasoning pathway?
The inscrutable nature of these systems poses a significant risk in high-stakes
medical applications, potentially leading to flawed or untrustworthy
conclusions. To address this, we conduct a large-scale empirical study of 3,600
cases from six medical datasets and six representative multi-agent frameworks.
Through a rigorous, mixed-methods approach combining qualitative analysis with
quantitative auditing, we develop a comprehensive taxonomy of collaborative
failure modes. Our quantitative audit reveals four dominant failure patterns:
flawed consensus driven by shared model deficiencies, suppression of correct
minority opinions, ineffective discussion dynamics, and critical information
loss during synthesis. This study demonstrates that high accuracy alone is an
insufficient measure of clinical or public trust. It highlights the urgent need
for transparent and auditable reasoning processes, a cornerstone for the
responsible development and deployment of medical AI.

</details>


### [232] [Judge's Verdict: A Comprehensive Analysis of LLM Judge Capability Through Human Agreement](https://arxiv.org/abs/2510.09738)
*Steve Han,Gilberto Titericz Junior,Tom Balough,Wenfei Zhou*

Main category: cs.CL

TL;DR: 本研究提出了Judge's Verdict Benchmark，一种评估LLM作为响应准确性评估任务的裁判的新颖两步方法。研究评估了54个LLM在评分RAG或Agentic管道的响应与地面真实答案方面复制人类判断的程度。该方法从传统的皮尔逊相关性分析发展到测量实际一致性模式的Cohen's Kappa分析。此两步方法包括：(1)一个过滤裁判的皮尔逊相关性测试，然后是(2)一个使用z分数的人类相似性测试，以识别两种不同的判断模式：模仿自然人类变异性的人类样判断（|z|<1），以及超过典型人类间一致性水平的超一致判断（z>1）。研究发现，54个模型中有27个达到Tier 1性能，其中23个模型展现出保留人类判断细微差别的人类样模式，而4个模型展现出超一致行为，这可能表明可靠性增强或对复杂判断的过度简化。测试了43个开源模型（1B-405B参数）和11个闭源模型（GPT、Gemini、Claude变体），研究表明裁判的卓越性不仅取决于模型大小，还取决于特定的训练策略。研究的主要贡献包括：(1)确立了相关性本身不足以进行裁判评估，(2)基于一致性模式引入了“裁判图灵测试”，(3)为将LLM裁判分入不同绩效等级以满足不同评估需求提供了标准化基准。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）作为响应准确性评估任务的裁判的能力，并提出一种新的两步评估方法来衡量它们复制人类判断的程度。

Method: 采用两步方法：首先进行皮尔逊相关性分析以筛选与人类判断有强相关性的模型，然后进行基于z分数的人类相似性测试，以识别模仿人类判断变异性（|z|<1）或表现出超一致性（z>1）的判断模式。测试了43个开源模型和11个闭源模型。

Result: 在54个测试模型中，27个（约50%）达到了Tier 1性能。其中23个模型展现出人类样判断模式，4个模型展现出超一致判断模式。研究表明，模型大小并非决定性因素，训练策略更为重要。

Conclusion: 相关性分析不足以评估LLM裁判的质量。本研究提出的“裁判图灵测试”方法能够根据判断的一致性模式将LLM裁判分级，为不同评估需求提供了标准化基准。高质量的LLM裁判并非仅由模型规模决定，而是与特定的训练策略相关。

Abstract: This research introduces the Judge's Verdict Benchmark, a novel two-step
methodology to evaluate Large Language Models (LLMs) as judges for response
accuracy evaluation tasks. We assess how well 54 LLMs can replicate human
judgment when scoring responses from RAG (Retrieval-Augmented Generation) or
Agentic pipelines against ground truth answers. Our methodology progresses from
traditional correlation analysis to comprehensive Cohen's Kappa analysis that
measures actual agreement patterns. The two-step approach includes: (1) a
correlation test that filters judges with strong alignment, followed by (2) a
human-likeness test using z-scores to identify two distinct judgment patterns:
human-like judgment (|z| < 1) that mimics natural human variation, and
super-consistent judgment (z > 1) that exceeds typical human-to-human agreement
levels. This methodology reveals that 27 out of 54 tested LLMs achieve Tier 1
performance: 23 models exhibit human-like patterns that preserve the nuances of
human judgment, while 4 models demonstrate super-consistent behavior, a pattern
that could indicate either enhanced reliability or oversimplification of
complex judgments. Testing 43 open-source models (1B-405B parameters) and 11
closed models (GPT, Gemini, Claude variants), we demonstrate that judge
excellence is not solely dependent on model size but on specific training
strategies. Our key contributions include: (1) establishing that correlation
alone is insufficient for judge evaluation, (2) introducing a "Turing Test for
judges" based on agreement patterns, and (3) providing a standardized benchmark
for classifying LLM judges into distinct performance tiers for different
evaluation needs.

</details>


### [233] [Gold Panning: Turning Positional Bias into Signal for Multi-Document LLM Reasoning](https://arxiv.org/abs/2510.09770)
*Adam Byerly,Daniel Khashabi*

Main category: cs.CL

TL;DR: LLM在处理多文档时存在位置偏见，倾向于优先考虑信息的位置而非相关性。本文提出的Gold Panning Bandits框架利用这一偏见作为诊断信号，通过重排文档并观察模型响应的变化来识别最相关的内容。该方法将重排问题构建为二分匹配问题，并提出了一种比匈牙利算法更高效的贪心策略（O(N log N)），该策略在识别相关文档时，相比随机排列基线，LLM查询次数减少高达65%，从而在不进行模型重训的情况下显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的方法试图消除LLM在多文档处理中的位置偏见，但本文提出了一种新颖的视角，即利用位置偏见作为诊断信号来识别最相关的内容。

Method: 将文档重排问题构建为二分匹配问题。提出了一种O(N log N)的贪心策略，通过优先将不确定性最高的文档放置在信息量最大的位置，以达到与最优分配（使用匈牙利算法，O(N^3)）相当的效果。

Result: 在知识密集型NLP任务上，该方法识别相关文档所需的语言模型查询次数比随机排列基线减少高达65%，显著降低了计算成本，且无需重新训练模型。

Conclusion: LLM固有的位置偏见可以从负面因素转变为提升效率、优化推理时间的有利因素。

Abstract: Large language models exhibit a strong position bias in multi-document
contexts, systematically prioritizing information based on location rather than
relevance. While existing approaches treat this bias as noise to be mitigated,
we introduce Gold Panning Bandits, a framework that leverages position bias as
a diagnostic signal: by reordering documents and observing shifts in the
model's responses, we can efficiently identify the most relevant content. We
frame the problem of choosing reorderings as a bipartite matching problem.
While an optimal assignment can be computed at each iteration with the
Hungarian algorithm in $O(N^3)$ time, we propose a greedy $O(N \log N)$
strategy that achieves comparable performance by prioritizing the placement of
the most uncertain documents in the most informative positions. Our approach
identifies relevant documents using up to 65\% fewer language model queries
than random permutation baselines on knowledge-intensive NLP tasks,
substantially reducing computational cost without model retraining. This work
demonstrates that inherent LLM biases can be transformed from liabilities into
assets for efficient, inference-time optimization.

</details>


### [234] [PromptGuard at BLP-2025 Task 1: A Few-Shot Classification Framework Using Majority Voting and Keyword Similarity for Bengali Hate Speech Detection](https://arxiv.org/abs/2510.09771)
*Rakib Hossan,Shubhashis Roy Dipta*

Main category: cs.CL

TL;DR: PromptGuard是一个少样本框架，用于孟加拉语仇恨言论分类，通过结合卡方统计关键词提取和自适应多数投票来提高性能，优于n-gram基线。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如孟加拉语）的仇恨言论分类需要大量标注数据，成本高昂。

Method: 开发了一个名为PromptGuard的少样本框架，该框架结合了使用卡方统计分析的关键词提取和自适应多数投票的决策机制。探索了统计关键词选择与随机方法以及基于共识质量的决策的自适应投票机制。

Result: PromptGuard在BLP-2025 Task 1A上实现了67.61的微F1分数，优于n-gram基线（60.75）和随机方法（14.65）。移除实验证实了基于卡方的关键词在所有类别中都具有最持续的影响。

Conclusion: 卡方关键词选择和自适应投票机制可以有效提高低资源语言的仇恨言论分类性能，并且比传统方法更具成本效益。

Abstract: The BLP-2025 Task 1A requires Bengali hate speech classification into six
categories. Traditional supervised approaches need extensive labeled datasets
that are expensive for low-resource languages. We developed PromptGuard, a
few-shot framework combining chi-square statistical analysis for keyword
extraction with adaptive majority voting for decision-making. We explore
statistical keyword selection versus random approaches and adaptive voting
mechanisms that extend classification based on consensus quality. Chi-square
keywords provide consistent improvements across categories, while adaptive
voting benefits ambiguous cases requiring extended classification rounds.
PromptGuard achieves a micro-F1 of 67.61, outperforming n-gram baselines
(60.75) and random approaches (14.65). Ablation studies confirm
chi-square-based keywords show the most consistent impact across all
categories.

</details>


### [235] [Steering Embedding Models with Geometric Rotation: Mapping Semantic Relationships Across Languages and Models](https://arxiv.org/abs/2510.09790)
*Michael Freenor,Lauren Alvarez*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Understanding how language and embedding models encode semantic relationships
is fundamental to model interpretability and control. While early word
embeddings exhibited intuitive vector arithmetic (''king'' - ''man'' +
''woman'' = ''queen''), modern high-dimensional text representations lack
straightforward interpretable geometric properties. We introduce
Rotor-Invariant Shift Estimation (RISE), a geometric approach that represents
semantic transformations as consistent rotational operations in embedding
space, leveraging the manifold structure of modern language representations.
RISE operations have the ability to operate across both languages and models
with high transfer of performance, suggesting the existence of analogous
cross-lingual geometric structure. We evaluate RISE across three embedding
models, three datasets, and seven morphologically diverse languages in five
major language groups. Our results demonstrate that RISE consistently maps
discourse-level semantic transformations with distinct grammatical features
(e.g., negation and conditionality) across languages and models. This work
provides the first systematic demonstration that discourse-level semantic
transformations correspond to consistent geometric operations in multilingual
embedding spaces, empirically supporting the Linear Representation Hypothesis
at the sentence level.

</details>


### [236] [Text Prompt Injection of Vision Language Models](https://arxiv.org/abs/2510.09849)
*Ruizhe Zhu*

Main category: cs.CL

TL;DR: 本项目提出了一种有效的文本提示注入攻击算法，可用于误导大型视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型广泛应用带来的安全隐患，特别是文本提示注入攻击的威胁。

Method: 开发了一种用于文本提示注入的攻击算法，并通过实验验证了其有效性和效率。

Result: 所提出的攻击算法在实践中被证明是有效的和高效的，并且相比其他攻击方法，对于大型模型具有更好的适应性，且计算资源需求不高。

Conclusion: 文本提示注入是一种简单但有效的攻击方式，值得关注和研究。

Abstract: The widespread application of large vision language models has significantly
raised safety concerns. In this project, we investigate text prompt injection,
a simple yet effective method to mislead these models. We developed an
algorithm for this type of attack and demonstrated its effectiveness and
efficiency through experiments. Compared to other attack methods, our approach
is particularly effective for large models without high demand for
computational resources.

</details>


### [237] [NG-Router: Graph-Supervised Multi-Agent Collaboration for Nutrition Question Answering](https://arxiv.org/abs/2510.09854)
*Kaiwen Shi,Zheyuan Zhang,Zhengqing Yuan,Keerthiram Murugesan,Vincent Galass,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

TL;DR: NG-Router是一个创新的框架，通过多智能体协作和知识图谱来解决营养问答问题，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有营养问答方法面临单智能体推理能力有限、多智能体架构设计复杂以及上下文过载导致决策不准确等挑战。

Method: NG-Router将营养问答构建为监督式、知识图谱引导的多智能体协作问题。它将智能体节点集成到异构知识图谱中，并使用图神经网络学习任务感知的智能体路由分布，并利用经验智能体性能的软监督。为了解决上下文过载问题，提出了一种基于梯度的子图检索机制，在训练过程中识别重要的证据，从而增强了多跳和关系推理能力。

Result: 通过在多个基准和骨干模型上的广泛实验，NG-Router 一致优于单智能体和集成基线。

Conclusion: NG-Router 为复杂的营养健康任务提供了一种基于领域感知和多智能体推理的原则性方法，能够有效解决现有方法的局限性。

Abstract: Diet plays a central role in human health, and Nutrition Question Answering
(QA) offers a promising path toward personalized dietary guidance and the
prevention of diet-related chronic diseases. However, existing methods face two
fundamental challenges: the limited reasoning capacity of single-agent systems
and the complexity of designing effective multi-agent architectures, as well as
contextual overload that hinders accurate decision-making. We introduce
Nutritional-Graph Router (NG-Router), a novel framework that formulates
nutritional QA as a supervised, knowledge-graph-guided multi-agent
collaboration problem. NG-Router integrates agent nodes into heterogeneous
knowledge graphs and employs a graph neural network to learn task-aware routing
distributions over agents, leveraging soft supervision derived from empirical
agent performance. To further address contextual overload, we propose a
gradient-based subgraph retrieval mechanism that identifies salient evidence
during training, thereby enhancing multi-hop and relational reasoning.
Extensive experiments across multiple benchmarks and backbone models
demonstrate that NG-Router consistently outperforms both single-agent and
ensemble baselines, offering a principled approach to domain-aware multi-agent
reasoning for complex nutritional health tasks.

</details>


### [238] [NarraBench: A Comprehensive Framework for Narrative Benchmarking](https://arxiv.org/abs/2510.09869)
*Sil Hamilton,Matthew Wilkens,Andrew Piper*

Main category: cs.CL

TL;DR: NarraBench是一个关于叙事理解任务的分类法，并对78个现有基准进行了调查，发现现有基准未能充分覆盖叙事理解的各个方面，尤其是在叙事事件、风格、视角和揭示等方面存在不足，并强调需要开发能够评估主观和视角化叙事方面的基准。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分覆盖叙事理解的各个方面，尤其是在叙事事件、风格、视角和揭示等方面存在不足，并且需要开发能够评估主观和视角化叙事方面的基准。

Method: 提出一个理论指导下的叙事理解任务分类法，并对78个现有基准进行调查。

Result: 27%的叙事任务被现有基准充分覆盖；叙事事件、风格、视角和揭示等方面在现有评估中几乎缺失；需要开发能够评估主观和视角化叙事方面的基准。

Conclusion: NarraBench分类法、调查和方法论对NLP研究人员测试LLM叙事理解能力具有价值。

Abstract: We present NarraBench, a theory-informed taxonomy of narrative-understanding
tasks, as well as an associated survey of 78 existing benchmarks in the area.
We find significant need for new evaluations covering aspects of narrative
understanding that are either overlooked in current work or are poorly aligned
with existing metrics. Specifically, we estimate that only 27% of narrative
tasks are well captured by existing benchmarks, and we note that some areas --
including narrative events, style, perspective, and revelation -- are nearly
absent from current evaluations. We also note the need for increased
development of benchmarks capable of assessing constitutively subjective and
perspectival aspects of narrative, that is, aspects for which there is
generally no single correct answer. Our taxonomy, survey, and methodology are
of value to NLP researchers seeking to test LLM narrative understanding.

</details>


### [239] [StoryBox: Collaborative Multi-Agent Simulation for Hybrid Bottom-Up Long-Form Story Generation Using Large Language Models](https://arxiv.org/abs/2510.11618)
*Zehao Chen,Rong Pan,Haoran Li*

Main category: cs.CL

TL;DR: 使用多智能体模拟生成长篇故事。


<details>
  <summary>Details</summary>
Motivation: 受到人类作家创作故事时先构思整体场景的启发，提出一种新方法。

Method: 提出一种混合式自下长篇故事生成方法，使用多智能体模拟。智能体在动态沙盒环境中互动，它们的行为和互动产生涌现事件，构成故事基础。

Result: 能够生成超过10000字且保持连贯性和一致性的故事，在多个指标上达到最先进的性能。

Conclusion: 该方法为创作动态、沉浸式且能从智能体驱动的互动中自然演变的长篇故事提供了一种可扩展且创新的解决方案。

Abstract: Human writers often begin their stories with an overarching mental scene,
where they envision the interactions between characters and their environment.
Inspired by this creative process, we propose a novel approach to long-form
story generation, termed hybrid bottom-up long-form story generation, using
multi-agent simulations. In our method, agents interact within a dynamic
sandbox environment, where their behaviors and interactions with one another
and the environment generate emergent events. These events form the foundation
for the story, enabling organic character development and plot progression.
Unlike traditional top-down approaches that impose rigid structures, our hybrid
bottom-up approach allows for the natural unfolding of events, fostering more
spontaneous and engaging storytelling. The system is capable of generating
stories exceeding 10,000 words while maintaining coherence and consistency,
addressing some of the key challenges faced by current story generation models.
We achieve state-of-the-art performance across several metrics. This approach
offers a scalable and innovative solution for creating dynamic, immersive
long-form stories that evolve organically from agent-driven interactions.

</details>


### [240] [CoBia: Constructed Conversations Can Trigger Otherwise Concealed Societal Biases in LLMs](https://arxiv.org/abs/2510.09871)
*Nafiseh Nikeghbal,Amir Hossein Kargaran,Jana Diesner*

Main category: cs.CL

TL;DR: LLMs在安全检查中表现良好，但在对话中仍可能表现出有害行为。引入CoBia攻击来系统性分析LLMs的偏见行为，评估其从偏见言论中恢复和拒绝偏见问题的能力。结果表明，LLMs在拒绝偏见问题时常常失败，暴露出潜在的深层偏见。


<details>
  <summary>Details</summary>
Motivation: LLMs在安全检查中表现良好，但在对话中仍可能表现出有害行为，需要系统性分析这种现象。

Method: 使用CoBia攻击套件，构建包含偏见言论的对话，评估LLMs恢复能力和拒绝偏见后续问题的能力，并与人类判断进行比较。

Result: LLMs在拒绝偏见后续问题时常常失败，表明对话中的偏见会暴露LLMs潜在的深层偏见。有 propósito 地构建的对话能够可靠地揭示偏见放大。

Conclusion: LLMs在对话中容易受到偏见影响，即使它们通过了标准的安全检查。CoBia攻击是一种有效的压力测试方法，可以揭示LLMs中存在的深层偏见。

Abstract: Improvements in model construction, including fortified safety guardrails,
allow Large language models (LLMs) to increasingly pass standard safety checks.
However, LLMs sometimes slip into revealing harmful behavior, such as
expressing racist viewpoints, during conversations. To analyze this
systematically, we introduce CoBia, a suite of lightweight adversarial attacks
that allow us to refine the scope of conditions under which LLMs depart from
normative or ethical behavior in conversations. CoBia creates a constructed
conversation where the model utters a biased claim about a social group. We
then evaluate whether the model can recover from the fabricated bias claim and
reject biased follow-up questions. We evaluate 11 open-source as well as
proprietary LLMs for their outputs related to six socio-demographic categories
that are relevant to individual safety and fair treatment, i.e., gender, race,
religion, nationality, sex orientation, and others. Our evaluation is based on
established LLM-based bias metrics, and we compare the results against human
judgments to scope out the LLMs' reliability and alignment. The results suggest
that purposefully constructed conversations reliably reveal bias amplification
and that LLMs often fail to reject biased follow-up questions during dialogue.
This form of stress-testing highlights deeply embedded biases that can be
surfaced through interaction. Code and artifacts are available at
https://github.com/nafisenik/CoBia.

</details>


### [241] [iBERT: Interpretable Style Embeddings via Sense Decomposition](https://arxiv.org/abs/2510.09882)
*Vishal Anand,Milad Alshomary,Kathleen McKeown*

Main category: cs.CL

TL;DR: iBERT通过稀疏、非负的语境无关的词向量混合，生成可解释且可控的嵌入，以模块化方式暴露语言中的风格和语义线索，并在风格任务上取得优于SBERT的性能。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在创建一个可解释且可控的编码器，该编码器能模块化地揭示语言中的判别性线索，如风格和语义结构。

Method: 提出iBERT（interpretable-BERT）模型，将每个输入词表示为k个语境无关的词向量的稀疏、非负混合体，这些向量可以聚合为句子嵌入或直接用于词级别。

Result: 在STEL基准测试中，iBERT在风格表示方面比SBERT-style基线提高了约8个百分点，同时在作者身份验证方面保持了竞争力。实验还表明，iBERT能够将特定的风格属性（如表情符号使用、正式度或拼写错误）分配给特定的词向量。

Conclusion: iBERT通过其结构化和可解释的词向量混合，实现了对表示的模块化控制，能够有效地分解数据中的判别性信号，即使在风格和语义因素混合的情况下也能实现泛化。

Abstract: We present iBERT (interpretable-BERT), an encoder to produce inherently
interpretable and controllable embeddings - designed to modularize and expose
the discriminative cues present in language, such as stylistic and semantic
structure. Each input token is represented as a sparse, non-negative mixture
over k context-independent sense vectors, which can be pooled into sentence
embeddings or used directly at the token level. This enables modular control
over representation, before any decoding or downstream use.
  To demonstrate our model's interpretability, we evaluate it on a suite of
style-focused tasks. On the STEL benchmark, it improves style representation
effectiveness by ~8 points over SBERT-style baselines, while maintaining
competitive performance on authorship verification. Because each embedding is a
structured composition of interpretable senses, we highlight how specific style
attributes - such as emoji use, formality, or misspelling can be assigned to
specific sense vectors. While our experiments center on style, iBERT is not
limited to stylistic modeling. Its structural modularity is designed to
interpretably decompose whichever discriminative signals are present in the
data - enabling generalization even when supervision blends stylistic and
semantic factors.

</details>


### [242] [DELTA: Dynamic Layer-Aware Token Attention for Efficient Long-Context Reasoning](https://arxiv.org/abs/2510.09883)
*Hossein Entezari Zarch,Lei Gao,Chaoyi Jiang,Murali Annavarm*

Main category: cs.CL

TL;DR: DELTA是一种训练无关的稀疏注意力机制，可在不牺牲模型准确性的情况下提高计算效率，在推理时通过识别和仅关注重要的标记来减少计算量。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏注意力方法在推理时会因累积选择错误和长推导过程中标记的动态重要性而导致准确性严重下降，而DELTA旨在解决这些问题。

Method: DELTA将Transformer层分为三组：使用完全注意力的初始层；通过聚合的头级别注意力分数识别显著标记的选择层；以及仅关注选定子集的稀疏注意力层。

Result: 在AIME和GPQA-Diamond等推理基准上，DELTA在准确性方面与完全注意力相当或超过完全注意力，同时将注意力标记的数量减少了高达5倍，并实现了1.5倍的端到端加速。

Conclusion: 选择性地重用中间注意力图为实现高效的长上下文推理提供了一条稳健的途径。

Abstract: Large reasoning models (LRMs) achieve state-of-the-art performance on
challenging benchmarks by generating long chains of intermediate steps, but
their inference cost is dominated by decoding, where each new token must attend
to the entire growing sequence. Existing sparse attention methods reduce
computation by pruning the key-value (KV) cache, yet they suffer from severe
accuracy degradation on reasoning tasks due to cumulative selection errors and
the dynamic importance of tokens over long derivations. We present
\textbf{DELTA}, a training-free sparse attention mechanism that achieves
computational efficiency without sacrificing model accuracy. DELTA partitions
transformer layers into three groups: initial layers that use full attention, a
small set of \emph{selection layers} that identify salient tokens via
aggregated head-level attention scores, and subsequent \emph{sparse-attention
layers} that attend only to the selected subset. This design preserves the full
KV cache in GPU memory for accuracy, while avoiding expensive full-attention
computation over many layers. On reasoning benchmarks such as AIME and
GPQA-Diamond, DELTA matches or surpasses full attention in accuracy, while
reducing the number of attended tokens by up to $5\times$ and delivering
$1.5\times$ end-to-end speedup. Our results show that selective reuse of
intermediate attention maps offers a robust path toward efficient long-context
reasoning.

</details>


### [243] [Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs](https://arxiv.org/abs/2510.09885)
*Xu Pan,Ely Hahami,Jingxuan Fan,Ziqian Xie,Haim Sompolinsky*

Main category: cs.CL

TL;DR: 掩码扩散语言模型（dLLMs）在微调（fine-tuning）阶段比自回归语言模型（arLLMs）表现出更好的知识获取能力，并且通过引入掩码微调范式可以提高arLLMs的数据效率。


<details>
  <summary>Details</summary>
Motivation: 探究掩码扩散语言模型（dLLMs）在微调阶段获取新知识的能力，并与自回归语言模型（arLLMs）进行比较，以解决arLLMs在微调中遇到的“反转诅咒”问题。

Method: 在三种不同的数据集上，对arLLMs和dLLMs进行微调，并使用正向和反向风格的问答（QA）进行评估，以检验知识泛化能力和反转诅咒现象。最后，提出了一种新的掩码微调范式用于arLLMs的知识注入。

Result: dLLMs在没有数据增强（如释义）的情况下，在正向和反向QA任务上均取得了高准确率。arLLMs在QA泛化方面严重依赖数据增强，且释义仅在信息顺序与QA风格匹配时有效。提出的掩码微调范式显著提高了arLLMs微调的数据效率，缩小了与dLLMs的性能差距。

Conclusion: dLLMs在微调阶段展现出优越的知识迁移能力，不受“反转诅咒”的影响。通过引入掩码微调范式，arLLMs也能有效提升数据效率和泛化能力。

Abstract: Despite autoregressive large language models (arLLMs) being the current
dominant paradigm in language modeling, they resist knowledge injection via
fine-tuning due to inherent shortcomings such as the "reversal curse" -- the
challenge of answering questions that reverse the original information order in
the training sample. Masked diffusion large language models (dLLMs) are rapidly
emerging as a powerful alternative to the arLLM paradigm, with evidence of
better data efficiency and free of the "reversal curse" in pre-training.
However, it is unknown whether these advantages extend to the post-training
phase, i.e. whether pre-trained dLLMs can easily acquire new knowledge through
fine-tuning. On three diverse datasets, we fine-tune arLLMs and dLLMs,
evaluating them with forward and backward style Question Answering (QA) to
probe knowledge generalization and the reversal curse. Our results confirm that
arLLMs critically rely on extensive data augmentation via paraphrases for QA
generalization, and paraphrases are only effective when their information order
matches the QA style. Conversely, dLLMs achieve high accuracies on both forward
and backward QAs without paraphrases; adding paraphrases yields only marginal
gains. Lastly, inspired by the dLLM's performance, we introduce a novel masked
fine-tuning paradigm for knowledge injection into pre-trained arLLMs. This
proposed method successfully and drastically improves the data efficiency of
arLLM fine-tuning, effectively closing the performance gap with dLLMs.

</details>


### [244] [Abductive Preference Learning](https://arxiv.org/abs/2510.09887)
*Yijin Ni,Peng Qi*

Main category: cs.CL

TL;DR: 大型语言模型在对安全消费的食品和薯片做出“否”的回答时表现出过度自信。我们提出了一种名为“溯因偏好学习”的新范则，通过学习对响应的偏好来解决此问题，而不是学习对提示的偏好。我们的方法在 HaluEval QA 基准测试中取得了显着改进，并且在 AlpacaEval 上也显示出有希望的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（如 GPT-5 和 Claude Sonnet）即使经过 RLHF 和 DPO 对齐，仍然存在过度自信的问题，对于不同情况的提示（例如，放了一夜的土豆和薯片）倾向于给出相同的保守答案。

Method: 提出了一种名为“溯因偏好学习”的微调范式，通过学习响应的偏好来逆转传统的条件设置。构建了一个包含 1001 个条目的溯因数据集，并实现了溯因 DPO 及其变体 DPOP。探索了标准方法（提高响应选择）、溯因方法（提高提示区分能力）以及结合两者的多任务目标。

Result: 在溯因数据集上，多任务 DPOP 将响应选择的准确率从 90.0% 提高到 99.5%，将提示区分的准确率从 54.7% 提高到 85.0%。在 AlpacaEval 上的评估显示，多任务 DPOP 将胜率从 5.26% 提高到 6.17%。

Conclusion: 溯因偏好学习在保留传统偏好优化的优势的同时，解决了被忽视的逆否提示挑战，提高了模型对提示差异的敏感性。

Abstract: Frontier large language models such as GPT-5 and Claude Sonnet remain prone
to overconfidence even after alignment through Reinforcement Learning with
Human Feedback (RLHF) and Direct Preference Optimization (DPO). For instance,
they tend to offer the same conservative answer "No" to both questions "Can I
eat the [food / potato chips] that has been left out overnight?" despite the
latter requiring no refridgeration for safe consumption. We find that this
failure is potentially attributed to a limitation of existing preference
learning: it emphasizes selecting the correct response for a given prompt,
while neglecting counterfactual prompts that should alter the response.
  To address this limitation, we propose abductive preference learning, a
fine-tuning paradigm that reverses the conventional conditioning by learning
preferences over prompts given a response. To validate this idea, we construct
an abductive dataset derived from the HaluEval QA benchmark with 1,001 entries,
implementing abductive DPO and its variant DPOP. Experiments reveal
complementary strengths: standard methods improve response selection, abductive
methods improve prompt discrimination, while a multitask objective unifies
both. On the abductive dataset, multitask DPOP boosts accuracy from $90.0\%$ to
$99.5\%$ in response selection and $54.7\%$ to $85.0\%$ in prompt
discrimination, with qualitative evidence highlighting improved sensitivity to
prompt differences. Finally, evaluation on AlpacaEval shows multitask DPOP
improves win rate (from $5.26\%$ to $6.17\%$), confirming that abductive
preference learning preserves the benefits of conventional preference
optimization while addressing the overlooked challenge of counterfactual
prompts.

</details>


### [245] [HIPPD: Brain-Inspired Hierarchical Information Processing for Personality Detection](https://arxiv.org/abs/2510.09893)
*Guanming Chen,Lingzhi Shen,Xiaohao Cai,Imran Razzak,Shoaib Jameel*

Main category: cs.CL

TL;DR: HIPPD是一个受大脑启发的框架，用于从文本中检测个性，通过模拟大脑处理信息的方式，在大规模数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉跨多个帖子的上下文信息以及在语义稀疏环境中提取代表性和鲁棒性特征方面存在不足。

Method: HIPPD框架模拟了大脑的层级信息处理：使用大型语言模型模拟大脑皮层进行全局语义推理和深度特征提取；使用动态记忆模块模拟前额叶皮层，通过多巴胺预测误差反馈进行自适应门控和选择性保留；使用专门的轻量级模型模拟基底神经节，通过“赢家通吃”机制进行动态路由，以识别最擅长识别的与个性相关的模式。

Result: 在Kaggle和Pandora数据集上的大量实验证明，HIPPD的性能持续优于最先进的基线方法。

Conclusion: HIPPD通过模拟大脑的层级信息处理机制，有效解决了现有文本个性检测方法的局限性，并在实验中取得了优越的性能。

Abstract: Personality detection from text aims to infer an individual's personality
traits based on linguistic patterns. However, existing machine learning
approaches often struggle to capture contextual information spanning multiple
posts and tend to fall short in extracting representative and robust features
in semantically sparse environments. This paper presents HIPPD, a
brain-inspired framework for personality detection that emulates the
hierarchical information processing of the human brain. HIPPD utilises a large
language model to simulate the cerebral cortex, enabling global semantic
reasoning and deep feature abstraction. A dynamic memory module, modelled after
the prefrontal cortex, performs adaptive gating and selective retention of
critical features, with all adjustments driven by dopaminergic prediction error
feedback. Subsequently, a set of specialised lightweight models, emulating the
basal ganglia, are dynamically routed via a strict winner-takes-all mechanism
to capture the personality-related patterns they are most proficient at
recognising. Extensive experiments on the Kaggle and Pandora datasets
demonstrate that HIPPD consistently outperforms state-of-the-art baselines.

</details>


### [246] [Don't Throw Away Your Pretrained Model](https://arxiv.org/abs/2510.09913)
*Shangbin Feng,Wenhao Yu,Yike Wang,Hongming Zhang,Yulia Tsvetkov,Dong Yu*

Main category: cs.CL

TL;DR: 通过模型协作，特别是“Switch Generation”方法，可以在语言模型对齐训练中平衡推理/指令遵循与创造力/校准之间的权衡，并提高模型在各种任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 对齐训练会影响语言模型的创造力和校准能力，而基础模型在这方面表现更好。研究的目的是结合两者的优点。

Method: 提出“Switch Generation”方法，让预训练模型和对齐模型在响应序列中交替生成，并通过训练一个切换器模型来动态决定在推理时使用哪个模型来生成下一个片段，以发挥各自的优势。

Result: 模型协作在18个数据集中的16个上持续优于单个模型，而“Switch Generation”比基线方法平均提高了12.9%。该方法还能发现组合技能来解决单个模型难以解决的问题，并能泛化到未见过的模型和任务。

Conclusion: “Switch Generation”通过模型协作有效解决了对齐训练的权衡问题，并在多项任务上取得了显著的性能提升，同时还能重复利用和重新调整模型训练过程中产生的副产品。

Abstract: Alignment training has tradeoffs: it helps language models (LMs) gain in
reasoning and instruction following but might lose out on skills such as
creativity and calibration, where unaligned base models are better at. We aim
to make the best of both worlds through model collaboration, where different
models in the training pipeline collaborate and complement each other. Since LM
responses feature interleaving skills that favor different models, we propose
Switch Generation, where pretrained and aligned model versions take turns to
``speak'' in a response sequence. Specifically, we train a switcher LM by
learning from outcomes of choosing different models to generate the next
segment across diverse queries and contexts. At inference time, the switcher LM
guides different model checkpoints to dynamically generate the next segment
where their strengths are most needed. Extensive experiments with 8 model
collaboration baselines and 18 datasets show that 1) model collaboration
consistently outperforms individual models on 16 out of 18 tasks, and 2) Switch
Generation further outperforms baselines by 12.9% on average. Further analysis
reveals that Switch Generation discovers compositional skills to solve problems
where individual models struggle and generalizes to unseen models and tasks,
reusing and repurposing by-products in expensive model training pipelines that
are otherwise discarded.

</details>


### [247] [Enhancing Faithfulness in Abstractive Summarization via Span-Level Fine-Tuning](https://arxiv.org/abs/2510.09915)
*Sicong Huang,Qianqi Yan,Shengze Wang,Ian Lane*

Main category: cs.CL

TL;DR: LLM摘要中的幻觉问题可以通过带有跨度级别标签的新数据集和三种微调技术（梯度上升、负采样训练和任务向量否定）来解决，其中负采样训练最有效。


<details>
  <summary>Details</summary>
Motivation: LLM摘要虽然流畅但可能包含幻觉，现有的缓解策略不能完全解决这些问题。

Method: 使用LLM生成摘要，然后用GPT-4o对幻觉进行跨度级别标注，最后利用这些标注和无幻觉摘要来微调LLM，并评估了三种微调技术。

Result: 三种技术都成功地利用了跨度级别的标注来提高摘要的忠实度，其中负采样训练效果最好。

Conclusion: 所提出的方法和数据集能够有效地提高LLM生成摘要的忠实度。

Abstract: Abstractive summarization using large language models (LLMs) has become an
essential tool for condensing information. However, despite their ability to
generate fluent summaries, these models sometimes produce unfaithful summaries,
introducing hallucinations at the word, phrase, or concept level. Existing
mitigation strategies, such as post-processing corrections or contrastive
learning with synthetically generated negative samples, fail to fully address
the diverse errors that can occur in LLM-generated summaries. In this paper, we
investigate fine-tuning strategies to reduce the occurrence of unfaithful spans
in generated summaries. First, we automatically generate summaries for the set
of source documents in the training set with a variety of LLMs and then use
GPT-4o to annotate any hallucinations it detects at the span-level. Leveraging
these annotations, we fine-tune LLMs with both hallucination-free summaries and
annotated unfaithful spans to enhance model faithfulness. In this paper, we
introduce a new dataset that contains both faithful and unfaithful summaries
with span-level labels and we evaluate three techniques to fine-tuning a LLM to
improve the faithfulness of the resulting summarization: gradient ascent,
unlikelihood training, and task vector negation. Experimental results show that
all three approaches successfully leverage span-level annotations to improve
faithfulness, with unlikelihood training being the most effective.

</details>


### [248] [Unpacking Hateful Memes: Presupposed Context and False Claims](https://arxiv.org/abs/2510.09935)
*Weibin Cai,Jiayu Li,Reza Zafarani*

Main category: cs.CL

TL;DR: 本论文提出了一种名为SHIELD的仇恨表情包检测框架，该框架通过结合预设的上下文和虚假信息检测来识别仇恨表情包，并在实验中取得了优于现有方法的结果。


<details>
  <summary>Details</summary>
Motivation: 当前仇恨表情包检测主要依赖预训练语言模型，但忽略了对仇恨表情包本质特征的探究。本研究旨在弥补这一不足，从哲学和心理学角度出发，认为仇恨表情包的本质特征在于预设的上下文和虚假信息的表达。

Method: 提出PCM模块来模拟跨模态的上下文信息，并引入FACT模块，该模块整合外部知识并利用跨模态引用图来检测虚假信息。最终将PCM和FACT结合，构建了SHIELD框架。

Result: 在多个数据集和指标上，SHIELD的性能优于现有最先进的方法，并且在虚假新闻检测等其他任务上也展现出了通用性。

Conclusion: SHIELD框架能够有效捕捉仇恨表情包的本质特征，并在多个检测任务上取得了优越的性能。

Abstract: While memes are often humorous, they are frequently used to disseminate hate,
causing serious harm to individuals and society. Current approaches to hateful
meme detection mainly rely on pre-trained language models. However, less focus
has been dedicated to \textit{what make a meme hateful}. Drawing on insights
from philosophy and psychology, we argue that hateful memes are characterized
by two essential features: a \textbf{presupposed context} and the expression of
\textbf{false claims}. To capture presupposed context, we develop \textbf{PCM}
for modeling contextual information across modalities. To detect false claims,
we introduce the \textbf{FACT} module, which integrates external knowledge and
harnesses cross-modal reference graphs. By combining PCM and FACT, we introduce
\textbf{\textsf{SHIELD}}, a hateful meme detection framework designed to
capture the fundamental nature of hate. Extensive experiments show that SHIELD
outperforms state-of-the-art methods across datasets and metrics, while
demonstrating versatility on other tasks, such as fake news detection.

</details>


### [249] [Beyond Fertility: Analyzing STRR as a Metric for Multilingual Tokenization Evaluation](https://arxiv.org/abs/2510.09947)
*Mir Tafseer Nayeem,Sawsan Alqahtani,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

TL;DR: 本文分析了六种广泛使用的分词器在七种语言和两个领域上的表现，并提出了一种名为“单标记保留率”（STRR）的新指标，以解决现有“生育率”指标在跨语言公平性评估上的不足。


<details>
  <summary>Details</summary>
Motivation: 评估现有分词器在不同语言和领域上的表现，并提出新的评估指标以解决现有指标的不足，关注跨语言公平性。

Method: 分析了六种广泛使用的分词器在七种语言和两个领域上的表现，并计算了“生育率”和新提出的“单标记保留率”（STRR）。

Result: 发现不同语言的分词器在“生育率”和“STRR”上存在差异，例如英语生育率稳定，中文生育率高，而印地语则存在碎片化问题。STRR能够更清晰地揭示分词器在跨语言公平性方面的表现。

Conclusion: STRR是一个有用的补充指标，可以为设计更公平的多语言分词器提供指导。

Abstract: Tokenization is a crucial but under-evaluated step in large language models
(LLMs). The standard metric, fertility (the average number of tokens per word),
captures compression efficiency but obscures how vocabularies are allocated
across languages and domains. We analyze six widely used tokenizers across
seven languages and two domains, finding stable fertility for English, high
fertility for Chinese, and little domain sensitivity. To address fertility's
blind spots, we propose the Single Token Retention Rate (STRR), which measures
the proportion of words preserved as single tokens. STRR reveals systematic
prioritization of English, strong support for Chinese, and fragmentation in
Hindi, offering an interpretable view of cross-lingual fairness. Our results
show that STRR complements fertility and provides practical guidance for
designing more equitable multilingual tokenizers.

</details>


### [250] [Unifying Tree Search Algorithm and Reward Design for LLM Reasoning: A Survey](https://arxiv.org/abs/2510.09988)
*Jiaqi Wei,Xiang Zhang,Yuejin Yang,Wenxuan Huang,Juntai Cao,Sheng Xu,Xiang Zhuang,Zhangyang Gao,Muhammad Abdul-Mageed,Laks V. S. Lakshmanan,Chenyu You,Wanli Ouyang,Siqi Sun*

Main category: cs.CL

TL;DR: Deliberative tree search in LLMs unifies test-time scaling and self-improvement but lacks a formal framework. This paper proposes a unified framework by deconstructing search algorithms into Search Mechanism, Reward Formulation, and Transition Function, distinguishing between transient Search Guidance and durable Parametric Reward Modeling. This formalism enables a component-centric taxonomy, synthesizes existing research, and outlines a roadmap for self-improving agents.


<details>
  <summary>Details</summary>
Motivation: The burgeoning field of deliberative tree search in LLM research is fragmented and lacks a common formalism, particularly regarding the role of the reward signal (transient heuristic or durable learning target).

Method: The paper resolves the ambiguity of the reward signal by introducing a unified framework that deconstructs search algorithms into three core components: the Search Mechanism, Reward Formulation, and Transition Function. It establishes a formal distinction between transient Search Guidance for Test-Time Scaling (TTS) and durable Parametric Reward Modeling for Self-Improvement.

Result: The paper establishes a formal distinction between transient Search Guidance and durable Parametric Reward Modeling. Based on this formalism, it introduces a component-centric taxonomy, synthesizes the state-of-the-art, and charts a research roadmap for autonomous, self-improving agents.

Conclusion: The proposed unified framework and formalism provide a clearer understanding of deliberative tree search in LLMs, paving the way for more systematic research and development of self-improving agents.

Abstract: Deliberative tree search is a cornerstone of modern Large Language Model
(LLM) research, driving the pivot from brute-force scaling toward algorithmic
efficiency. This single paradigm unifies two critical frontiers:
\textbf{Test-Time Scaling (TTS)}, which deploys on-demand computation to solve
hard problems, and \textbf{Self-Improvement}, which uses search-generated data
to durably enhance model parameters. However, this burgeoning field is
fragmented and lacks a common formalism, particularly concerning the ambiguous
role of the reward signal -- is it a transient heuristic or a durable learning
target? This paper resolves this ambiguity by introducing a unified framework
that deconstructs search algorithms into three core components: the
\emph{Search Mechanism}, \emph{Reward Formulation}, and \emph{Transition
Function}. We establish a formal distinction between transient \textbf{Search
Guidance} for TTS and durable \textbf{Parametric Reward Modeling} for
Self-Improvement. Building on this formalism, we introduce a component-centric
taxonomy, synthesize the state-of-the-art, and chart a research roadmap toward
more systematic progress in creating autonomous, self-improving agents.

</details>


### [251] [Toward Machine Translation Literacy: How Lay Users Perceive and Rely on Imperfect Translations](https://arxiv.org/abs/2510.09994)
*Yimin Xiao,Yongle Zhang,Dayeon Ki,Calvin Bao,Marianna J. Martindale,Charlotte Vaughn,Ge Gao,Marine Carpuat*

Main category: cs.CL

TL;DR: 这项研究调查了公众在日常使用中对不完美机器翻译（MT）的依赖程度，重点关注了流畅性和充分性错误的影响，并提出了提高MT评估和用户MT素养的建议。


<details>
  <summary>Details</summary>
Motivation: 理解公众如何看待和依赖不完美的机器翻译对于将机器翻译研究置于现实世界的应用中至关重要。

Method: 在一家公共博物馆进行了一项包含452名参与者的人类研究，调查了流畅性和充分性错误如何影响双语和非双语用户在随意使用中的机器翻译依赖性。

Result: 研究发现，非双语用户由于缺乏评估策略和替代方案，常常过度依赖机器翻译；而经历错误则会促使用户重新评估未来对机器翻译的依赖。

Conclusion: 这项研究强调了开发机器翻译评估和自然语言处理解释技术的重要性，以期不仅提高机器翻译质量，而且提高用户的机器翻译素养。

Abstract: As Machine Translation (MT) becomes increasingly commonplace, understanding
how the general public perceives and relies on imperfect MT is crucial for
contextualizing MT research in real-world applications. We present a human
study conducted in a public museum (n=452), investigating how fluency and
adequacy errors impact bilingual and non-bilingual users' reliance on MT during
casual use. Our findings reveal that non-bilingual users often over-rely on MT
due to a lack of evaluation strategies and alternatives, while experiencing the
impact of errors can prompt users to reassess future reliance. This highlights
the need for MT evaluation and NLP explanation techniques to promote not only
MT quality, but also MT literacy among its users.

</details>


### [252] [MTP-S2UT: Enhancing Speech-to-Speech Translation Quality with Multi-token Prediction](https://arxiv.org/abs/2510.10003)
*Jianjin Wang,Runsong Zhao,Xiaoqian Liu,Yuan Ge,Ziqiang Xu,Tong Xiao,Shengxiang Gao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

TL;DR: 通过在中间层应用多令牌预测（MTP）损失，提出MTP-S2UT来提高语音到单元翻译（S2UT）质量。


<details>
  <summary>Details</summary>
Motivation: 现有的语音转语音翻译方法使用稀疏的语音令牌作为中间表示，导致语义信息密度低。

Method: 将多令牌预测（MTP）损失引入S2UT模型，并提出MTP-S2UT，将MTP损失应用于CTC损失计算的隐藏表示层，以实现更早、更有效的表示增强。

Result: 所有MTP损失变体均能持续提高S2UT翻译质量，其中MTP-S2UT表现最佳。

Conclusion: MTP-S2UT通过在中间层进行信息丰富，比在最终层进行信息丰富更有效地提高了S2UT的性能。

Abstract: Current direct speech-to-speech translation methods predominantly employ
speech tokens as intermediate representations. However, a single speech token
is not dense in semantics, so we generally need multiple tokens to express a
complete semantic unit. To address this limitation, we introduce multi-token
prediction (MTP) loss into speech-to-unit translation (S2UT) models, enabling
models to predict multiple subsequent tokens at each position, thereby
capturing more complete semantics and enhancing information density per
position. Initial MTP implementations apply the loss at the final layer, which
improves output representation but initiates information enrichment too late.
We hypothesize that advancing the information enrichment process to
intermediate layers can achieve earlier and more effective enhancement of
hidden representation. Consequently, we propose MTP-S2UT loss, applying MTP
loss to hidden representation where CTC loss is computed. Experiments
demonstrate that all MTP loss variants consistently improve the quality of S2UT
translation, with MTP-S2UT achieving the best performance.

</details>


### [253] [Beyond the limitation of a single query: Train your LLM for query expansion with Reinforcement Learning](https://arxiv.org/abs/2510.10009)
*Shu Zhao,Tan Yu,Anbang Xu*

Main category: cs.CL

TL;DR: 通过强化学习训练一个基于LLM的搜索代理，并结合预训练的squeezer模型，以提升在多跳问答任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的搜索代理在多跳问答任务上表现不佳，原因在于其推理和搜索能力有限。

Method: 训练一个具有查询扩展能力的LLM搜索代理，并引入预训练的squeezer模型来帮助理解检索到的文档，使搜索代理能专注于查询生成以提高检索召回率。

Result: 该方法在七个问答基准测试中，平均比最先进的基线提高了4.4%的准确率，在需要多样化证据聚合的多跳推理任务上表现尤为突出。

Conclusion: 结合查询扩展和文档理解能力，即使是小型LLM也能在多跳问答任务上达到最先进的性能。

Abstract: Reasoning-augmented search agents, such as Search-R1, are trained to reason,
search, and generate the final answer iteratively. Nevertheless, due to their
limited capabilities in reasoning and search, their performance on multi-hop QA
benchmarks remains far from satisfactory. To handle complex or compound
queries, we train an LLM-based search agent with the native capability of query
expansion through reinforcement learning. In each turn, our search agent
proposes several query variants, which are searched simultaneously to cover
more relevant information. Meanwhile, given limited post-training data and
computing resources, it is very challenging for a search agent to master
multiple tasks, including query generation, retrieved information
understanding, and answer generation. Therefore, we propose incorporating a
pre-trained squeezer model that helps the search agent understand the retrieved
documents, allowing the search agent to focus on query generation for high
retrieval recall. With the assistance of the squeezer model, we discover that
even a small-scale 3B LLM can demonstrate a strong capability of query
expansion and achieve state-of-the-art accuracy on the multi-hop QA benchmarks.
To be specific, our experiments across seven question-answering benchmarks
demonstrate that our method, named ExpandSearch, achieves an average
improvement of 4.4% compared to state-of-the-art baselines, with strong gains
on multi-hop reasoning tasks requiring diverse evidence aggregation.

</details>


### [254] [Path Drift in Large Reasoning Models:How First-Person Commitments Override Safety](https://arxiv.org/abs/2510.10013)
*Yuyi Huang,Runzhe Zhan,Lidia S. Chao,Ailin Tao,Derek F. Wong*

Main category: cs.CL

TL;DR: 长CoT提示 LLMs 存在一个先前未被充分研究的漏洞：推理轨迹可能偏离对齐路径，导致违反安全约束的内容。本研究将此现象称为“路径漂移”，并提出了诱导框架和缓解策略。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）越来越多地用于复杂推理任务，长CoT提示已成为结构化推理的关键范式。尽管有RLHF等对齐技术的早期安全措施，但LLMs在长CoT推理中仍存在路径漂移的风险，可能产生违反安全约束的内容。

Method: 通过实证分析，识别出路径漂移的三个行为触发因素：第一人称承诺、道德蒸发和条件链升级。在此基础上，提出了一个包含认知负荷放大、自我角色启动和条件链劫持的三阶段路径漂移诱导框架。

Result: 该诱导框架能够独立降低拒绝率，组合使用时效果更佳。为应对这些风险，研究提出了一种包含角色归因纠正和元认知反思（反思性安全提示）的路径级防御策略。

Conclusion: 这项研究强调了在长形式推理中，除了令牌级对齐之外，还需要进行轨迹级对齐监督。

Abstract: As large language models (LLMs) are increasingly deployed for complex
reasoning tasks, Long Chain-of-Thought (Long-CoT) prompting has emerged as a
key paradigm for structured inference. Despite early-stage safeguards enabled
by alignment techniques such as RLHF, we identify a previously underexplored
vulnerability: reasoning trajectories in Long-CoT models can drift from aligned
paths, resulting in content that violates safety constraints. We term this
phenomenon Path Drift. Through empirical analysis, we uncover three behavioral
triggers of Path Drift: (1) first-person commitments that induce goal-driven
reasoning that delays refusal signals; (2) ethical evaporation, where
surface-level disclaimers bypass alignment checkpoints; (3) condition chain
escalation, where layered cues progressively steer models toward unsafe
completions. Building on these insights, we introduce a three-stage Path Drift
Induction Framework comprising cognitive load amplification, self-role priming,
and condition chain hijacking. Each stage independently reduces refusal rates,
while their combination further compounds the effect. To mitigate these risks,
we propose a path-level defense strategy incorporating role attribution
correction and metacognitive reflection (reflective safety cues). Our findings
highlight the need for trajectory-level alignment oversight in long-form
reasoning beyond token-level alignment.

</details>


### [255] [Lightweight Baselines for Medical Abstract Classification: DistilBERT with Cross-Entropy as a Strong Default](https://arxiv.org/abs/2510.10025)
*Jiaqi Liu,Lanruo Wang,Su Liu,Xin Hu*

Main category: cs.CL

TL;DR: BERT 及其变体在医疗文摘分类任务上进行了微调，DistilBERT 在参数量和性能之间取得了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗领域部署面临成本、延迟和隐私限制，需要轻量级解决方案。

Method: 在公开的医疗文摘语料库上，使用三种不同的损失函数（交叉熵、类别加权交叉熵、Focal Loss）对 BERT base 和 DistilBERT 进行了微调，并固定了分词器、序列长度、优化器和学习率计划。

Result: DistilBERT 在使用标准交叉熵损失函数时，在测试集上达到了最佳的性能与参数量平衡。

Conclusion: 对于医疗文摘分类任务，建议优先考虑使用紧凑型编码器（如 DistilBERT）和交叉熵损失函数，然后在考虑更复杂的模型。

Abstract: Large language models work well for many NLP tasks, but they are hard to
deploy in health settings with strict cost, latency, and privacy limits. We
revisit a lightweight recipe for medical abstract classification and ask how
far compact encoders can go under a controlled budget. Using the public medical
abstracts corpus, we finetune BERT base and DistilBERT with three objectives
standard cross-entropy, class weighted cross entropy, and focal loss keeping
tokenizer, sequence length, optimizer, and schedule fixed. DistilBERT with
plain cross-entropy gives the best balance on the test set while using far
fewer parameters than BERT base. We report accuracy, Macro F1, and Weighted F1,
release the evaluation code, and include confusion analyses to make error
patterns clear. Our results suggest a practical default: start with a compact
encoder and cross-entropy, then add calibration and task-specific checks before
moving to heavier models.

</details>


### [256] [HUME: Measuring the Human-Model Performance Gap in Text Embedding Task](https://arxiv.org/abs/2510.10062)
*Adnan El Assadi,Isaac Chung,Roman Solomatin,Niklas Muennighoff,Kenneth Enevoldsen*

Main category: cs.CL

TL;DR: 该研究提出了HUME框架，用于评估文本嵌入模型在多种任务和语言上的表现，并首次提供了人类表现基线，揭示了模型在某些数据集上的局限性，尤其是在低资源语言方面。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解嵌入模型的优势和劣势，需要将模型表现与人类表现进行比较，但目前缺乏可靠的人类表现评估方法。

Method: 构建了HUME框架，跨越16个MTEB数据集，涵盖重排、分类、聚类和语义文本相似性等任务，并覆盖了多种语言资源级别和语言。

Result: 在16个MTEB数据集上，人类的平均表现为77.6%，而最佳嵌入模型的平均表现为80.1%。模型在某些数据集上表现接近人类，但在其他数据集上则存在显著差距，尤其是在低资源语言方面。

Conclusion: HUME框架提供了人类表现基线，有助于更准确地解读模型得分，并为开发新模型和基准提供了指导，强调了数据质量和低资源语言的重要性。

Abstract: Comparing human and model performance offers a valuable perspective for
understanding the strengths and limitations of embedding models, highlighting
where they succeed and where they fail to capture meaning and nuance. However,
such comparisons are rarely made, as human performance on embedding tasks is
difficult to measure. To fill this gap, we introduce HUME: Human Evaluation
Framework for Text Embeddings. While frameworks like MTEB provide broad model
evaluation, they lack reliable estimates of human performance, limiting the
interpretability of model scores. We measure human performance across 16 MTEB
datasets spanning reranking, classification, clustering, and semantic textual
similarity across linguistically diverse high- and low-resource languages.
Humans achieve an average performance of 77.6% compared to 80.1% for the best
embedding model, although variation is substantial: models reach near-ceiling
performance on some datasets while struggling on others, suggesting dataset
issues and revealing shortcomings in low-resource languages. We provide human
performance baselines, insight into task difficulty patterns, and an extensible
evaluation framework that enables a more meaningful interpretation of the model
and informs the development of both models and benchmarks. Our code, dataset,
and leaderboard are publicly available at
https://github.com/embeddings-benchmark/mteb.

</details>


### [257] [CLMN: Concept based Language Models via Neural Symbolic Reasoning](https://arxiv.org/abs/2510.10063)
*Yibo Yang*

Main category: cs.CL

TL;DR: CLMN通过结合神经表征和符号推理，在保持NLP性能的同时提高了模型的可解释性，特别是在需要处理动态概念交互（如否定和上下文）的应用场景中。


<details>
  <summary>Details</summary>
Motivation: 现有NLP模型的可解释性有限，特别是在医疗和金融等关键领域。虽然概念瓶颈模型（Concept bottleneck models）在计算机视觉领域取得了一定的进展，但其在NLP领域的应用存在一些问题，例如二元激活损害文本表示，潜在概念削弱语义，并且难以捕捉动态概念交互（如否定和上下文）。

Method: 提出概念语言模型网络（CLMN），一个结合了神经网络和符号推理的框架。CLMN将概念表示为连续的、人类可读的嵌入，并利用模糊逻辑推理学习自适应的交互规则，以模拟概念之间以及概念与最终决策之间的相互影响。该模型通过增强原始文本特征，引入了概念感知表示，并能自动推导出可解释的逻辑规则。

Result: 在多个数据集和预训练语言模型上，CLMN的准确性优于现有的基于概念的方法，同时提高了模型解释的质量。

Conclusion: 将神经表征与符号推理在统一的概念空间中相结合，能够构建实用的、透明的NLP系统。

Abstract: Deep learning has advanced NLP, but interpretability remains limited,
especially in healthcare and finance. Concept bottleneck models tie predictions
to human concepts in vision, but NLP versions either use binary activations
that harm text representations or latent concepts that weaken semantics, and
they rarely model dynamic concept interactions such as negation and context. We
introduce the Concept Language Model Network (CLMN), a neural-symbolic
framework that keeps both performance and interpretability. CLMN represents
concepts as continuous, human-readable embeddings and applies fuzzy-logic
reasoning to learn adaptive interaction rules that state how concepts affect
each other and the final decision. The model augments original text features
with concept-aware representations and automatically induces interpretable
logic rules. Across multiple datasets and pre-trained language models, CLMN
achieves higher accuracy than existing concept-based methods while improving
explanation quality. These results show that integrating neural representations
with symbolic reasoning in a unified concept space can yield practical,
transparent NLP systems.

</details>


### [258] [Unilaw-R1: A Large Language Model for Legal Reasoning with Reinforcement Learning and Iterative Inference](https://arxiv.org/abs/2510.10072)
*Hua Cai,Shuang Zhao,Liang Zhang,Xuli Shen,Qing Xu,Weilin Shen,Zihao Wen,Tianke Ban*

Main category: cs.CL

TL;DR: Unilaw-R1是一个为法律推理设计的70亿参数的大型语言模型，通过使用高质量的CoT数据集和两阶段的训练策略，在法律知识、推理逻辑和商业泛化方面取得了显著进步，并在权威基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在处理复杂法律问题方面的能力仍有待探索，本研究旨在解决法律领域知识不足、推理逻辑不可靠和商业泛化能力弱这三个核心挑战。

Method: 构建了包含17K高质量的CoT样本的Unilaw-R1-Data数据集，并采用了监督微调（SFT）和强化学习（RL）相结合的两阶段训练策略。

Result: Unilaw-R1在权威基准测试中表现强劲，其性能与规模大得多的DeepSeek-R1-Distill-Qwen-32B相当（54.9%），并且在LawBench和LexEval等特定领域训练后，平均超出Qwen-2.5-7B-Instruct（46.6%）6.6%。

Conclusion: Unilaw-R1模型在法律推理任务上展现出强大的性能，并支持法律AI应用中的可解释决策。

Abstract: Reasoning-focused large language models (LLMs) are rapidly evolving across
various domains, yet their capabilities in handling complex legal problems
remains underexplored. In this paper, we introduce Unilaw-R1, a large language
model tailored for legal reasoning. With a lightweight 7-billion parameter
scale, Unilaw-R1 significantly reduces deployment cost while effectively
tackling three core challenges in the legal domain: insufficient legal
knowledge, unreliable reasoning logic, and weak business generalization. To
address these issues, we first construct Unilaw-R1-Data, a high-quality dataset
containing 17K distilled and screened chain-of-thought (CoT) samples. Based on
this, we adopt a two-stage training strategy combining Supervised Fine-Tuning
(SFT) and Reinforcement Learning (RL), which significantly boosts the
performance on complex legal reasoning tasks and supports interpretable
decision-making in legal AI applications. To assess legal reasoning ability, we
also introduce Unilaw-R1-Eval, a dedicated benchmark designed to evaluate
models across single- and multi-choice legal tasks. Unilaw-R1 demonstrates
strong results on authoritative benchmarks, outperforming all models of similar
scale and achieving performance on par with the much larger
DeepSeek-R1-Distill-Qwen-32B (54.9%). Following domain-specific training, it
also showed significant gains on LawBench and LexEval, exceeding
Qwen-2.5-7B-Instruct (46.6%) by an average margin of 6.6%.

</details>


### [259] [A-IPO: Adaptive Intent-driven Preference Optimization](https://arxiv.org/abs/2510.10077)
*Wenqing Wang,Muhammad Asif Ali,Ali Shoker,Ruohan Yang,Junyang Chen,Ying Sha,Huan Wang*

Main category: cs.CL

TL;DR: A-IPO通过引入意图模块来优化模型对齐，以解决DPO忽略少数意见和潜在用户意图的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人类偏好对齐方法（如DPO）倾向于遵循多数意见，忽略少数意见，并且未能捕捉提示中的潜在用户意图，导致对齐效果不佳。

Method: A-IPO引入了一个意图模块，用于推断用户提示背后的潜在意图，并将其明确纳入奖励函数。这增加了偏好边缘，从而在偏好和非偏好响应之间产生了更清晰的区分。

Result: A-IPO在两个新基准（Real-pref、Attack-pref）和一个现有数据集的扩展版本（GlobalOpinionQA-Ext）上进行了评估，并在响应-意图一致性、响应相似性和防御成功率等关键指标上取得了显著的改进，平均提高了24.8%到54.6%。

Conclusion: A-IPO通过显式建模多样化的用户意图，能够实现多元化的偏好优化，并增强偏好对齐的对抗鲁棒性，优于现有方法。

Abstract: Human preferences are diverse and dynamic, shaped by regional, cultural, and
social factors. Existing alignment methods like Direct Preference Optimization
(DPO) and its variants often default to majority views, overlooking minority
opinions and failing to capture latent user intentions in prompts.
  To address these limitations, we introduce \underline{\textbf{A}}daptive
\textbf{\underline{I}}ntent-driven \textbf{\underline{P}}reference
\textbf{\underline{O}}ptimization (\textbf{A-IPO}). Specifically,A-IPO
introduces an intention module that infers the latent intent behind each user
prompt and explicitly incorporates this inferred intent into the reward
function, encouraging stronger alignment between the preferred model's
responses and the user's underlying intentions. We demonstrate, both
theoretically and empirically, that incorporating an intention--response
similarity term increases the preference margin (by a positive shift of
$\lambda\,\Delta\mathrm{sim}$ in the log-odds), resulting in clearer separation
between preferred and dispreferred responses compared to DPO.
  For evaluation, we introduce two new benchmarks, Real-pref, Attack-pref along
with an extended version of an existing dataset, GlobalOpinionQA-Ext, to assess
real-world and adversarial preference alignment.
  Through explicit modeling of diverse user intents,A-IPO facilitates
pluralistic preference optimization while simultaneously enhancing adversarial
robustness in preference alignment. Comprehensive empirical evaluation
demonstrates that A-IPO consistently surpasses existing baselines, yielding
substantial improvements across key metrics: up to +24.8 win-rate and +45.6
Response-Intention Consistency on Real-pref; up to +38.6 Response Similarity
and +52.2 Defense Success Rate on Attack-pref; and up to +54.6 Intention
Consistency Score on GlobalOpinionQA-Ext.

</details>


### [260] [Diversity Augmentation of Dynamic User Preference Data for Boosting Personalized Text Summarizers](https://arxiv.org/abs/2510.10082)
*Parthiv Chatterjee,Shivam Sonawane,Amey Hengle,Aditya Tanna,Sourish Dasgupta,Tanmoy Chakraborty*

Main category: cs.CL

TL;DR: 个性化文档摘要的目标是满足用户对信息的需求，但由于用户主观性的存在，难以识别和提取信息。为了解决这个问题，我们提出了PerAugy，一种新颖的数据增强技术，通过跨轨迹混洗和摘要内容扰动来提高用户编码器的准确性。我们的方法显著提高了四个最先进的基线用户编码器的性能（AUC提高0.132），并使两个最先进的摘要框架在个性化方面平均提高了61.2%。我们还引入了三个数据集多样性指标（TP、RTC和DegreeD）来量化增强数据集的吸引力，并发现TP和DegreeD与用户编码器的性能密切相关，表明数据集多样性的增加是性能提升的关键因素。


<details>
  <summary>Details</summary>
Motivation: 文档摘要的个性化是必要的，因为现有的方法难以处理用户的主观性，并且缺乏包含用户偏好历史和预期摘要的训练数据。

Method: 提出了一种名为PerAugy的数据增强技术，该技术采用跨轨迹混洗和摘要内容扰动来生成更多样化的训练数据，从而提高用户编码器的性能。

Result: PerAugy将四个最先进的用户编码器的准确性提高了0.132（AUC），并使两个最先进的摘要框架的个性化性能平均提高了61.2%。TP和DegreeD这两个新的数据集多样性指标与用户编码器的性能密切相关。

Conclusion: PerAugy通过提高训练数据的多样性，能够显著提高个性化文档摘要的性能。该研究还强调了数据集多样性在提高用户编码器性能方面的重要性。

Abstract: Document summarization enables efficient extraction of user-relevant content
but is inherently shaped by individual subjectivity, making it challenging to
identify subjective salient information in multifaceted documents. This
complexity underscores the necessity for personalized summarization. However,
training models for personalized summarization has so far been challenging,
particularly because diverse training data containing both user preference
history (i.e., click-skip trajectory) and expected (gold-reference) summaries
are scarce. The MS/CAS PENS dataset is a valuable resource but includes only
preference history without target summaries, preventing end-to-end supervised
learning, and its limited topic-transition diversity further restricts
generalization. To address this, we propose $\mathrm{PerAugy}$, a novel
cross-trajectory shuffling and summary-content perturbation based data
augmentation technique that significantly boosts the accuracy of four
state-of-the-art baseline (SOTA) user-encoders commonly used in personalized
summarization frameworks (best result: $\text{0.132}$$\uparrow$ w.r.t AUC). We
select two such SOTA summarizer frameworks as baselines and observe that when
augmented with their corresponding improved user-encoders, they consistently
show an increase in personalization (avg. boost: $\text{61.2\%}\uparrow$ w.r.t.
PSE-SU4 metric). As a post-hoc analysis of the role of induced diversity in the
augmented dataset by \peraugy, we introduce three dataset diversity metrics --
$\mathrm{TP}$, $\mathrm{RTC}$, and \degreed\ to quantify the induced diversity.
We find that $\mathrm{TP}$ and $\mathrm{DegreeD}$ strongly correlate with
user-encoder performance on the PerAugy-generated dataset across all accuracy
metrics, indicating that increased dataset diversity is a key factor driving
performance gains.

</details>


### [261] [Stop When Enough: Adaptive Early-Stopping for Chain-of-Thought Reasoning](https://arxiv.org/abs/2510.10103)
*Renliang Sun,Wei Cheng,Dawei Li,Haifeng Chen,Wei Wang*

Main category: cs.CL

TL;DR: REFRAIN框架通过引入两阶段停止判别器和SW-UCB控制器，在不进行微调的情况下，自适应地决定何时停止链式思考推理，从而减少冗余推理，降低成本，同时保持或提高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在进行链式思考（CoT）推理时，由于过度或冗余推理（“过度思考”）导致推理成本增加，甚至得出错误结论的问题。

Method: REFRAIN框架包含一个两阶段的停止判别器，用于识别反思性但冗余的推理；以及一个滑动窗口上限置信界（SW-UCB）多臂老虎机控制器，用于在无监督或微调的情况下，根据问题难度动态调整停止阈值。

Result: 在四个代表性基准和两个模型系列上，REFRAIN将代币使用量减少了20-55%，同时保持或提高了准确性，并且在不同模型、评分器和提示变化下表现稳定。

Conclusion: “何时停止”是测试时扩展的一个新的、实用的维度，能够使模型实现“恰到好处”的推理，而不是仅仅进行更多的推理。

Abstract: Chain-of-Thought (CoT) reasoning has driven recent gains of large language
models (LLMs) on reasoning-intensive tasks by externalizing intermediate steps.
However, excessive or redundant reasoning -- so-called overthinking -- can
increase inference costs and lead LLMs toward incorrect conclusions. In this
paper, we present REFRAIN ($\underline{REF}$lective-$\underline{R}$edundancy
for $\underline{A}$daptive $\underline{IN}$ference), a training-free framework
that adaptively determines when to stop reasoning to mitigate overthinking.
REFRAIN integrates a two-stage stop discriminator to identify reflective yet
redundant reasoning and a sliding-window Upper Confidence Bound (SW-UCB)
multi-armed bandit controller to dynamically adjust stopping thresholds
according to problem difficulty without supervision or fine-tuning. Across four
representative benchmarks and two model families, REFRAIN reduces token usage
by 20-55% while maintaining or improving accuracy compared to standard CoT
prompting. Extensive ablation and robustness analyses demonstrate its stability
across models, scorers, and prompt variations. In summary, our findings
highlight when-to-stop as a new and practical axis of test-time scaling --
enabling models to reason not just more, but just enough.

</details>


### [262] [LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora](https://arxiv.org/abs/2510.10114)
*Luyao Zhuang,Shengyuan Chen,Yilin Xiao,Huachi Zhou,Yujing Zhang,Hao Chen,Qinggang Zhang,Xiao Huang*

Main category: cs.CL

TL;DR: LinearRAG通过构建无关系的层次图Tri-Graph，并采用两阶段检索策略，有效解决了传统GraphRAG在处理大规模非结构化语料库时存在的图谱构建不稳定、关系提取成本高、检索质量下降等问题，并在多项实验中表现出显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统RAG在处理大规模、非结构化语料库时存在信息碎片化问题，而现有的基于知识图谱的GraphRAG方法在图谱构建时依赖不稳定的关系提取，导致噪声大、检索质量下降。

Method: LinearRAG提出了一种高效的框架，通过轻量级的实体提取和语义链接构建了一个名为Tri-Graph的无关系层次图，避免了不稳定的关系建模。检索方面，采用两阶段策略：首先通过局部语义桥接激活相关实体，然后通过全局重要性聚合进行文章检索。

Result: 通过在四个数据集上进行的大量实验表明，LinearRAG显著优于基线模型。

Conclusion: LinearRAG通过一种经济可靠的索引方式，解决了GraphRAG在图谱构建和文章检索方面的痛点，实现了更优的性能。

Abstract: Retrieval-Augmented Generation (RAG) is widely used to mitigate
hallucinations of Large Language Models (LLMs) by leveraging external
knowledge. While effective for simple queries, traditional RAG systems struggle
with large-scale, unstructured corpora where information is fragmented. Recent
advances incorporate knowledge graphs to capture relational structures,
enabling more comprehensive retrieval for complex, multi-hop reasoning tasks.
However, existing graph-based RAG (GraphRAG) methods rely on unstable and
costly relation extraction for graph construction, often producing noisy graphs
with incorrect or inconsistent relations that degrade retrieval quality. In
this paper, we revisit the pipeline of existing GraphRAG systems and propose
LinearRAG (Linear Graph-based Retrieval-Augmented Generation), an efficient
framework that enables reliable graph construction and precise passage
retrieval. Specifically, LinearRAG constructs a relation-free hierarchical
graph, termed Tri-Graph, using only lightweight entity extraction and semantic
linking, avoiding unstable relation modeling. This new paradigm of graph
construction scales linearly with corpus size and incurs no extra token
consumption, providing an economical and reliable indexing of the original
passages. For retrieval, LinearRAG adopts a two-stage strategy: (i) relevant
entity activation via local semantic bridging, followed by (ii) passage
retrieval through global importance aggregation. Extensive experiments on four
datasets demonstrate that LinearRAG significantly outperforms baseline models.

</details>


### [263] [Hybrid OCR-LLM Framework for Enterprise-Scale Document Information Extraction Under Copy-heavy Task](https://arxiv.org/abs/2510.10138)
*Zilong Wang,Xiaoyu Shen*

Main category: cs.CL

TL;DR: 本研究提出了一种结合OCR和LLM的框架，用于从副本密集的文档中提取信息，解决了现有方法忽视文档特性和追求通用性方案的不足。通过智能选择直接、替换或基于表格的提取策略，并在不同格式的身份文件中进行评估，该框架在处理结构化文档时达到了F1=1.0的准确率和0.97s的延迟，处理图像输入时达到了F1=0.997的准确率和0.6s的延迟。与多模态方法相比，性能提升了54倍，实现了生产规模下的异构文档流处理。该方法证明了通过感知结构的方法选择，可以将副本密集任务的重复性转化为优化机会。


<details>
  <summary>Details</summary>
Motivation: 处理包含大量结构相似内容的副本密集型文档的信息提取是一个关键但研究不足的挑战。

Method: 提出一个系统性框架，结合OCR引擎和LLM，通过智能选择提取策略（直接、替换、基于表格）来优化准确性和效率的权衡。

Result: 在身份文件中，基于表格的提取方法在结构化文档中实现了F1=1.0的准确率和0.97s的延迟，在图像输入中实现了F1=0.997的准确率和0.6s的延迟，性能比多模态方法提高了54倍。

Conclusion: 副本密集型任务的重复性可以通过感知结构的方法选择，从计算负担转化为优化机会。

Abstract: Information extraction from copy-heavy documents, characterized by massive
volumes of structurally similar content, represents a critical yet understudied
challenge in enterprise document processing. We present a systematic framework
that strategically combines OCR engines with Large Language Models (LLMs) to
optimize the accuracy-efficiency trade-off inherent in repetitive document
extraction tasks. Unlike existing approaches that pursue universal solutions,
our method exploits document-specific characteristics through intelligent
strategy selection. We implement and evaluate 25 configurations across three
extraction paradigms (direct, replacement, and table-based) on identity
documents spanning four formats (PNG, DOCX, XLSX, PDF). Through table-based
extraction methods, our adaptive framework delivers outstanding results: F1=1.0
accuracy with 0.97s latency for structured documents, and F1=0.997 accuracy
with 0.6 s for challenging image inputs when integrated with PaddleOCR, all
while maintaining sub-second processing speeds. The 54 times performance
improvement compared with multimodal methods over naive approaches, coupled
with format-aware routing, enables processing of heterogeneous document streams
at production scale. Beyond the specific application to identity extraction,
this work establishes a general principle: the repetitive nature of copy-heavy
tasks can be transformed from a computational burden into an optimization
opportunity through structure-aware method selection.

</details>


### [264] [DiffHeads: Differential Analysis and Inference-Time Masking of Bias Heads in Large Language Models](https://arxiv.org/abs/2510.10142)
*Tingxu Han,Wei Song,Ziqi Ding,Ziming Li,Chunrong Fang,Yuekang Li,Dongfang Liu,Zhenyu Chen,Zhenting Wang*

Main category: cs.CL

TL;DR: LLM在敏感决策中可能存在偏见，现有研究对偏见产生机制的理解不足。本文提出DiffHeads框架，通过分析不同提示策略（DA与CoT）下模型内部注意力机制的差异，识别并抑制产生偏见的“偏见头”，从而有效降低LLM在决策中的不公平性，同时保持模型效用。


<details>
  <summary>Details</summary>
Motivation: 现有LLM偏见研究主要关注偏见何时出现，而对产生偏见的机制理解不足，导致偏见消除方法不够稳健。因此，需要系统性地研究LLM偏见及其产生机制，并提出有效的缓解方法。

Method: 1. 比较了直接回答（DA）提示和思维链（CoT）提示在8种不同LLM上的表现，量化了它们在公平性上的差异。2. 定义了token-to-head贡献得分，用于追踪每个token的影响力回溯到具体的注意力头，从而识别出在DA提示下激活而在CoT提示下不活跃的“偏见头”。3. 基于上述发现，提出了DiffHeads框架，通过分析DA和CoT提示下注意力头的激活差异来识别偏见头，并选择性地屏蔽这些头，以达到去偏见的目的。

Result: 1. DA提示相比CoT提示，在100%的测试中显著增加了LLM的不公平性，增幅在534.5%-391.9%之间。2. 识别出一小簇在DA提示下激活但在CoT提示下不活跃的“偏见头”，首次建立了提示策略与偏见产生的因果联系。3. DiffHeads框架在DA和CoT提示下分别将不公平性降低了49.4%和40.3%，且未损害模型的效用。

Conclusion: DiffHeads框架能够有效识别并缓解LLM在决策过程中的偏见，通过精确定位并屏蔽产生偏见的注意力头，实现了在不损失模型效用的前提下提升公平性，为LLM在敏感领域的应用提供了更安全可靠的解决方案。

Abstract: Large language models (LLMs) increasingly mediate decisions in domains where
unfair treatment of demographic groups is unacceptable. Existing work probes
when biased outputs appear, but gives little insight into the mechanisms that
generate them, leaving existing mitigations largely fragile. In this paper, we
conduct a systematic investigation LLM unfairness and propose DiffHeads, a
lightweight debiasing framework for LLMs. We first compare Direct-Answer (DA)
prompting to Chain-of-Thought (CoT) prompting across eight representative open-
and closed-source LLMs. DA will trigger the nature bias part of LLM and improve
measured unfairness by 534.5%-391.9% in both one-turn and two-turn dialogues.
Next, we define a token-to-head contribution score that traces each token's
influence back to individual attention heads. This reveals a small cluster of
bias heads that activate under DA but stay largely dormant with CoT, providing
the first causal link between prompting strategy and bias emergence. Finally,
building on this insight, we propose DiffHeads that identifies bias heads
through differential activation analysis between DA and CoT, and selectively
masks only those heads. DiffHeads reduces unfairness by 49.4%, and 40.3% under
DA and CoT, respectively, without harming model utility.

</details>


### [265] [BILLY: Steering Large Language Models via Merging Persona Vectors for Creative Generation](https://arxiv.org/abs/2510.10157)
*Tsung-Min Pai,Jui-I Wang,Li-Chun Lu,Shao-Hua Sun,Hung-Yi Lee,Kai-Wei Chang*

Main category: cs.CL

TL;DR: BILLY框架通过融合单个大型语言模型中的多个角色向量，在不增加计算成本和推理延迟的情况下，提升了模型的创造力。


<details>
  <summary>Details</summary>
Motivation: 多大型语言模型系统虽然能激发大型语言模型的创造力，但存在计算成本高和推理延迟显著等缺点。本研究旨在解决这些限制。

Method: BILLY框架通过在模型的激活空间中提取并融合多个不同的角色向量来实现。在推理时，使用融合后的向量来引导模型的生成过程，从而在没有明确的多模型通信的情况下实现多角度输出。

Result: 实验表明，BILLY框架在创造性基准测试中优于单一模型提示和传统的多模型方法，同时显著降低了推理时间和计算成本。

Conclusion: BILLY框架能够将不同角色向量融合，以实现对生成过程互补方面的有效控制和提高可解释性。

Abstract: Multi-LLM systems enhance the creativity of large language models by
simulating human collective intelligence but suffer from significant drawbacks,
such as high computational costs and inference latency. To address these
limitations, we propose BILLY (BlendIng persona vectors for Large Language
model creativitY), a training-free framework that captures the benefits of
multi-LLM collaboration, i.e. inducing diverse perspectives and specialized
expertise, within a single model. BILLY operates by extracting and blending
multiple distinct persona vectors directly in the model's activation space. We
steer the model's generation process with this merged vector while inference,
enabling multi-perspective output without explicit multi-LLM communication. Our
experiments across creativity-oriented benchmarks demonstrate that BILLY
surpasses single model prompting and traditional multi-LLM approaches, while
substantially reducing inference time and computational costs. Our analyses
further reveal that distinct persona vectors can be blended to achieve both
effective control over complementary aspects of generation and greater
interpretability.

</details>


### [266] [BabyBabelLM: A Multilingual Benchmark of Developmentally Plausible Training Data](https://arxiv.org/abs/2510.10159)
*Jaap Jumelet,Abdellah Fourtassi,Akari Haga,Bastian Bunzeck,Bhargav Shandilya,Diana Galvan-Sosa,Faiz Ghifari Haznitrama,Francesca Padovani,Francois Meyer,Hai Hu,Julen Etxaniz,Laurent Prévot,Linyang He,María Grandury,Mila Marcheva,Negar Foroutan,Nikitas Theodoropoulos,Pouya Sadeghi,Siyuan Song,Suchir Salhan,Susana Zhou,Yurii Paniv,Ziyin Zhang,Arianna Bisazza,Alex Warstadt,Leshem Choshen*

Main category: cs.CL

TL;DR: BabyBabelLM是一个包含45种语言的数据集，旨在模拟婴儿学习母语的过程，以促进多语言预训练和认知建模。


<details>
  <summary>Details</summary>
Motivation: 本文的动机是创建一个多语言数据集，模拟个体从出生到掌握母语所接触的语言，以支持多语言预训练和认知建模。

Method: BabyBabelLM通过收集模拟婴儿学习过程的、具有发展合理性的数据来构建，涵盖45种语言，每种语言的量相当于1亿个英语单词的内容。同时，还编制了评估套件并训练了基线模型。

Result: BabyBabelLM包含45种语言的预训练数据集，并附带评估套件和基线模型。

Conclusion: BabyBabelLM旨在促进多语言预训练和认知建模。

Abstract: We present BabyBabelLM, a multilingual collection of datasets modeling the
language a person observes from birth until they acquire a native language. We
curate developmentally plausible pretraining data aiming to cover the
equivalent of 100M English words of content in each of 45 languages. We compile
evaluation suites and train baseline models in each language. BabyBabelLM aims
to facilitate multilingual pretraining and cognitive modeling.

</details>


### [267] [Large Language Model Sourcing: A Survey](https://arxiv.org/abs/2510.10161)
*Liang Pang,Kangxi Wu,Sunhao Dai,Zihao Wei,Zenghao Duan,Jia Gu,Xiang Li,Zhiyi Yin,Jun Xu,Huawei Shen,Xueqi Cheng*

Main category: cs.CL

TL;DR: LLM的快速发展带来了革命性的变化，但同时也伴随着多方面的风险，如幻觉、偏见、不公平和版权侵权。因此，从多角度追溯信息来源至关重要。


<details>
  <summary>Details</summary>
Motivation: LLM的广泛应用和其生成内容的黑箱性质及类人特征，使得追踪其内容的来源成为一个关键问题，以解决幻觉、偏见、不公平和版权侵权等风险。

Method: 本调查从模型（Model Sourcing, Model Structure Sourcing）和数据（Training Data Sourcing, External Data Sourcing）两个维度，系统地研究了LLM生成内容的来源追溯问题，并提出了基于先验（prior-based）和后验（posterior-based）的分类方法。

Result: 对LLM内容溯源进行了全面的梳理和分类，包括模型层面和数据层面的追溯方法，以及先验和后验两种策略。

Conclusion: 通过在不同维度上加强溯源能力，可以提高LLM在实际应用中的透明度、可问责性和可信度。

Abstract: The rapid advancement of large language models (LLMs) has revolutionized
artificial intelligence, shifting from supporting objective tasks (e.g.,
recognition) to empowering subjective decision-making (e.g., planning,
decision). This marks the dawn of general and powerful AI, with applications
spanning a wide range of fields, including programming, education, healthcare,
finance, and law. However, their deployment introduces multifaceted risks. Due
to the black-box nature of LLMs and the human-like quality of their generated
content, issues such as hallucinations, bias, unfairness, and copyright
infringement become particularly significant. In this context, sourcing
information from multiple perspectives is essential.
  This survey presents a systematic investigation into provenance tracking for
content generated by LLMs, organized around four interrelated dimensions that
together capture both model- and data-centric perspectives. From the model
perspective, Model Sourcing treats the model as a whole, aiming to distinguish
content generated by specific LLMs from content authored by humans. Model
Structure Sourcing delves into the internal generative mechanisms, analyzing
architectural components that shape the outputs of model. From the data
perspective, Training Data Sourcing focuses on internal attribution, tracing
the origins of generated content back to the training data of model. In
contrast, External Data Sourcing emphasizes external validation, identifying
external information used to support or influence the responses of model.
Moreover, we also propose a dual-paradigm taxonomy that classifies existing
sourcing methods into prior-based (proactive traceability embedding) and
posterior-based (retrospective inference) approaches. Traceability across these
dimensions enhances the transparency, accountability, and trustworthiness of
LLMs deployment in real-world applications.

</details>


### [268] [A Survey of Inductive Reasoning for Large Language Models](https://arxiv.org/abs/2510.10182)
*Kedi Chen,Dezhao Ruan,Yuhao Dan,Yaoting Wang,Siyu Yan,Xuecheng Wu,Yinqi Zhang,Qin Chen,Jie Zhou,Liang He,Biqing Qi,Linyang Li,Qipeng Guo,Xiaoming Shi,Wei Zhang*

Main category: cs.CL

TL;DR: 本文对大型语言模型（LLM）的归纳推理能力进行了全面的调查，这是首次对该主题进行系统性总结。


<details>
  <summary>Details</summary>
Motivation: 归纳推理是大型语言模型的一项重要任务，其从具体到一般的思考过程和答案的非唯一性是其特点。它对于知识泛化至关重要，更符合人类认知，因此是学习的基本模式，正受到越来越多的关注。然而，目前缺乏对其进行系统的总结。

Method: 本文将提高归纳推理能力的方法分为三类：训练后、测试时扩展和数据增强。然后，对当前的归纳推理基准进行了总结，并提出了一种基于沙盒的统一评估方法，该方法包含观测覆盖率指标。

Result: 通过对归纳推理方法的分类、基准的总结和评估方法的提出，为未来研究奠定了基础。文章还分析了归纳能力的来源以及简单的模型架构和数据如何帮助完成归纳任务。

Conclusion: 本文全面调查了大型语言模型（LLM）的归纳推理能力，并对未来的研究方向进行了分析。

Abstract: Reasoning is an important task for large language models (LLMs). Among all
the reasoning paradigms, inductive reasoning is one of the fundamental types,
which is characterized by its particular-to-general thinking process and the
non-uniqueness of its answers. The inductive mode is crucial for knowledge
generalization and aligns better with human cognition, so it is a fundamental
mode of learning, hence attracting increasing interest. Despite the importance
of inductive reasoning, there is no systematic summary of it. Therefore, this
paper presents the first comprehensive survey of inductive reasoning for LLMs.
First, methods for improving inductive reasoning are categorized into three
main areas: post-training, test-time scaling, and data augmentation. Then,
current benchmarks of inductive reasoning are summarized, and a unified
sandbox-based evaluation approach with the observation coverage metric is
derived. Finally, we offer some analyses regarding the source of inductive
ability and how simple model architectures and data help with inductive tasks,
providing a solid foundation for future research.

</details>


### [269] [Weed Out, Then Harvest: Dual Low-Rank Adaptation is an Effective Noisy Label Detector for Noise-Robust Learning](https://arxiv.org/abs/2510.10208)
*Bo Yuan,Yulin Chen,Yin Zhang*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Parameter-efficient fine-tuning (PEFT) large language models (LLMs) have
shown impressive performance in various downstream tasks. However, in many
real-world scenarios, the collected training data inevitably contains noisy
labels. To learn from noisy labels, most solutions select samples with small
losses for model training. However, the selected samples, in turn, impact the
loss computation in the next iteration. An inaccurate initial selection can
create a vicious cycle, leading to suboptimal performance. To break this cycle,
we propose Delora, a novel framework that decouples the sample selection from
model training. For sample selection, Delora establishes a noisy label detector
by introducing clean and noisy LoRA. Benefiting from the memory effect, the
clean LoRA is encouraged to memorize clean data, while the noisy LoRA is
constrained to memorize mislabeled data, which serves as a learnable threshold
for selecting clean and noisy samples. For model training, Delora can use
carefully selected samples to fine-tune language models seamlessly.
Experimental results on synthetic and real-world noisy datasets demonstrate the
effectiveness of Delora in noisy label detection and text classification.

</details>


### [270] [You only need 4 extra tokens: Synergistic Test-time Adaptation for LLMs](https://arxiv.org/abs/2510.10223)
*Yijie Xu,Huizai Yao,Zhiyu Guo,Weiyu Guo,Pengteng Li,Aiwei Liu,Xuming Hu,Hui Xiong*

Main category: cs.CL

TL;DR: SyTTA是一个无需标注即可在测试时自适应语言模型的框架，它结合了输入端的困惑度（衡量与领域术语和模式的匹配度）和输出端的预测熵（衡量生成过程中不稳定的概率），在多个领域取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在金融、医学、农业等专业领域部署大型语言模型时，模型会面临与训练数据显著的分布偏移问题。虽然领域特定的微调可以缓解这一挑战，但在专业知识有限的情况下，收集高质量的标注数据成本高昂且耗时。因此，研究无需标注的测试时自适应方法具有重要意义。

Method: SyTTA框架在推理时，利用两种互补的不确定性信号：1. 输入端困惑度：衡量输入文本与领域特定术语和模式的不匹配程度。 2. 输出端预测熵：衡量模型在生成过程中输出概率分布的扩散和不稳定性。通过结合这两种信号，SyTTA在无额外监督的情况下，动态地调整模型以适应新的领域分布。

Result: SyTTA在各种模型架构和特定领域的基准测试中都取得了持续的性能提升。特别是在农业问答任务中，SyTTA在Qwen-2.5-7B模型上，每查询仅增加4个额外标记，就将Rouge-LSum指标提高了120%以上。

Conclusion: 研究表明，即使没有标注数据，语言模型也能实现有效的测试时自适应，这为在标注数据稀缺的领域部署模型提供了支持。

Abstract: Large language models (LLMs) are increasingly deployed in specialized domains
such as finance, medicine, and agriculture, where they face significant
distribution shifts from their training data. Domain-specific fine-tuning can
mitigate this challenge but relies on high-quality labeled data that is
expensive and slow to collect in expertise-limited settings. We study
label-free test-time adaptation for language models and present SyTTA, an
inference-time framework that adapts models on-the-fly without additional
supervision. SyTTA couples two complementary uncertainty signals that arise
under distribution shift: input-side perplexity, indicating mismatch with
domain-specific terminology and patterns, and output-side predictive entropy,
indicating diffuse and unstable token probabilities during generation. Across
diverse model architectures and domain-specific benchmarks, SyTTA delivers
consistent gains. Notably, on agricultural question answering, SyTTA improves
Rouge-LSum by over 120% on Qwen-2.5-7B with only 4 extra tokens per query.
These results show that effective test-time adaptation for language models is
achievable without labeled examples, supporting deployment in label-scarce
domains. The code will be made available upon acceptance.

</details>


### [271] [Text2Token: Unsupervised Text Representation Learning with Token Target Prediction](https://arxiv.org/abs/2510.10224)
*Ruize An,Richong Zhang,Zhijie Nie,Zhanyu Wu,Yanzhao Zhang,Dingkun Long*

Main category: cs.CL

TL;DR: Text2Token 是一个无监督文本表示学习框架，通过预测文本的关键标记来学习高质量的文本表示。


<details>
  <summary>Details</summary>
Motivation: 无监督文本表示学习对于改进搜索和推荐至关重要。最近的研究表明，高质量的表示与输入文本的关键标记对齐，这揭示了表示空间和词汇空间之间的潜在联系。

Method: Text2Token 框架基于标记目标预测任务，利用精心构建的目标标记分布作为监督信号。通过分析标记与高级嵌入器的对齐特性，识别出两类关键标记：文本中有意义的标记和超越文本的语义衍生标记。基于这些发现，提出了数据驱动和模型推导两种方法来构建合成标记目标。

Result: 在 MTEB v2 基准测试上的实验表明，Text2Token 取得了与最先进的无监督对比学习嵌入器 LLM2Vec 相当的性能。

Conclusion: Text2Token 的训练过程表明，词汇空间和表示空间能够协同优化，并共同趋向于最优解，为未来的研究提供了新的思路和见解。

Abstract: Unsupervised text representation learning (TRL) is a fundamental task in
natural language processing, which is beneficial for improving search and
recommendations with the web's unlabeled texts. A recent empirical study finds
that the high-quality representation aligns with the key token of the input
text, uncovering the potential connection between representation space and
vocabulary space. Inspired by the findings, we revisit the generative tasks and
develop an unsupervised generative framework for TRL, Text2Token. The framework
is based on the token target prediction task, utilizing carefully constructed
target token distribution as supervisory signals. To construct the high-quality
target token distribution, we analyze the token-alignment properties with
advanced embedders and identify two essential categories of key tokens: (1) the
meaningful tokens in the text and (2) semantically derived tokens beyond the
text. Based on these insights, we propose two methods -- data-driven and
model-derived -- to construct synthetic token targets from data or the LLM
backbone. Experiments on the MTEB v2 benchmark demonstrate that Text2Token
achieves performance competitive with the state-of-the-art embedder with
unsupervised contrastive learning, LLM2Vec. Our analysis further shows that
vocabulary and representation spaces optimize together and toward the optimum
solution during training, providing new ideas and insights for future work.

</details>


### [272] [ImCoref-CeS: An Improved Lightweight Pipeline for Coreference Resolution with LLM-based Checker-Splitter Refinement](https://arxiv.org/abs/2510.10241)
*Kangyang Luo,Yuzhuo Bai,Shuzheng Si,Cheng Gao,Zhitong Wang,Yingli Shen,Wenhao Li,Zhu Liu,Yufeng Han,Jiayi Wu,Cunliang Kong,Maosong Sun*

Main category: cs.CL

TL;DR: ImCoref-CeS框架结合了改进的监督模型ImCoref和基于LLM的推理，以解决核心词链接（CR）任务，并在实验中取得了优于现有SOTA方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的核心词链接（CR）研究面临一个关键困境：是进一步探索基于小型语言模型（LLM）的有监督神经网络方法的潜力，还是利用大型语言模型（LLM）的强大功能。然而，如何有效地结合两者的优点仍然是一个未被充分探索的领域。

Method: 提出了一种名为ImCoref-CeS的新框架，该框架集成了增强的有监督模型ImCoref和基于LLM的推理。ImCoref通过引入轻量级桥接模块来增强长文本编码能力，设计了双仿射评分器来全面捕获位置信息，并调用了混合提及正则化来提高训练效率。LLM被用作一个多角色的检查器-分割器代理，用于验证候选提及和分割错误的聚类。

Result: ImCoref-CeS框架在实验中被证明是有效的，与现有的SOTA方法相比，取得了优越的性能。

Conclusion: ImCoref-CeS框架通过结合增强的监督方法和LLM推理，有效地解决了CR任务中的挑战，并取得了SOTA的性能。

Abstract: Coreference Resolution (CR) is a critical task in Natural Language Processing
(NLP). Current research faces a key dilemma: whether to further explore the
potential of supervised neural methods based on small language models, whose
detect-then-cluster pipeline still delivers top performance, or embrace the
powerful capabilities of Large Language Models (LLMs). However, effectively
combining their strengths remains underexplored. To this end, we propose
\textbf{ImCoref-CeS}, a novel framework that integrates an enhanced supervised
model with LLM-based reasoning. First, we present an improved CR method
(\textbf{ImCoref}) to push the performance boundaries of the supervised neural
method by introducing a lightweight bridging module to enhance long-text
encoding capability, devising a biaffine scorer to comprehensively capture
positional information, and invoking a hybrid mention regularization to improve
training efficiency. Importantly, we employ an LLM acting as a multi-role
Checker-Splitter agent to validate candidate mentions (filtering out invalid
ones) and coreference results (splitting erroneous clusters) predicted by
ImCoref. Extensive experiments demonstrate the effectiveness of ImCoref-CeS,
which achieves superior performance compared to existing state-of-the-art
(SOTA) methods.

</details>


### [273] [Audit-of-Understanding: Posterior-Constrained Inference for Mathematical Reasoning in Language Models](https://arxiv.org/abs/2510.10252)
*Samir Abdaljalil,Erchin Serpedin,Khalid Qaraqe,Hasan Kurban*

Main category: cs.CL

TL;DR: LLMs会产生看似合理但基于未经证实的假设的推理，导致错误结论。我们提出了AoU框架，通过分解查询、审计假设支持、仅在验证后的子集上进行推理来约束LLM的推理过程，解决了推理诱导的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）生成的推理过程可能存在问题，尽管表面上看起来连贯，但其依据的假设可能未经证实，从而导致错误的结论。现有的方法主要关注事实性错误或依赖于事后验证，而对于推理过程中产生的错误则鲜有涉及。

Method: AoU框架包含三个阶段：1. 将查询分解为候选假设；2. 审计这些假设的依据；3. 仅基于验证后的假设子集进行推理。从形式上讲，AoU是一种“后验约束推理”，与选择性预测和拒绝学习相关。

Result: AoU框架在GSM8K、MultiArith和SVAMP数据集上，相较于Chain-of-Thought、Self-Consistency和CoT-Decoding等方法，在准确性和忠实度方面均有所提升，其中在GSM8K上提升高达+30%，在MultiArith上提升高达+45%，在SVAMP上稳定提升+20--28%。

Conclusion: AoU框架通过约束推理过程中的假设有效性，显著提高了LLMs在数学推理任务上的准确性和可靠性，解决了现有方法在处理推理过程中的幻觉问题上存在的不足。

Abstract: Large language models (LLMs) often generate reasoning traces that appear
coherent but rest on unsupported assumptions, leading to hallucinated
conclusions. Prior work mainly addresses factual hallucinations or relies on
post-hoc verification, leaving reasoning-induced hallucinations largely
unaddressed. We propose Audit-of-Understanding (AoU), a framework that
constrains inference to validated premises through three phases: (1)
decomposing a query into candidate assumptions, (2) auditing their support, and
(3) conditioning inference only on the validated subset. Formally, AoU is
\emph{posterior-constrained inference}, connecting to selective prediction and
rejection learning. Our contributions are threefold: (i) theoretical guarantees
under perfect validation, (ii) excess-risk bounds under imperfect audits, and
(iii) tractability analysis. Empirically, AoU improves both accuracy and
faithfulness on GSM8K, MultiArith, and SVAMP, achieving up to +30% gains on
GSM8K, +45% on MultiArith, and consistent +20--28% improvements on SVAMP over
Chain-of-Thought, Self-Consistency, and CoT-Decoding. Code is available at
https://anonymous.4open.science/r/audit-of-understanding-E28B.

</details>


### [274] [Backdoor Collapse: Eliminating Unknown Threats via Known Backdoor Aggregation in Language Models](https://arxiv.org/abs/2510.10265)
*Liang Lin,Miao Yu,Moayad Aloqaily,Zhenhong Zhou,Kun Wang,Linsey Pang,Prakhar Mehrotra,Qingsong Wen*

Main category: cs.CL

TL;DR: 提出了一种名为“\ourmethod”的防御框架，用于防御针对大型语言模型（LLM）的后门攻击，无需预先了解触发器的设置。该方法通过聚合后门表示并进行恢复微调来恢复模型的良性输出。实验证明该方法能有效降低攻击成功率，同时保持模型的干净准确率和效用。


<details>
  <summary>Details</summary>
Motivation: 现有的后门防御方法依赖于对触发器设置的不切实际的假设，而“\ourmethod”旨在解决这一挑战，提供一种无需预先了解触发器设置的防御框架。

Method: “\ourmethod”通过一个两阶段过程进行工作：首先，通过注入已知触发器来聚合后门表示；然后，进行恢复微调以恢复良性输出。该方法基于一个关键观察：当有意地将已知后门注入到已被破坏的模型中时，先前未知的后门和新注入的后门都会在表示空间中聚集。

Result: 实验结果表明，“\ourmethod”在多个基准测试中将平均攻击成功率降低到4.41%，在干净准确率和效用方面仅有不到0.5%的损失，并且能够防御不同类型的后门。

Conclusion: “\ourmethod”是一种有效的后门防御框架，能够显著降低LLM的攻击成功率，同时保持模型的性能，并且具有良好的泛化能力。

Abstract: Backdoor attacks are a significant threat to large language models (LLMs),
often embedded via public checkpoints, yet existing defenses rely on
impractical assumptions about trigger settings. To address this challenge, we
propose \ourmethod, a defense framework that requires no prior knowledge of
trigger settings. \ourmethod is based on the key observation that when
deliberately injecting known backdoors into an already-compromised model, both
existing unknown and newly injected backdoors aggregate in the representation
space. \ourmethod leverages this through a two-stage process: \textbf{first},
aggregating backdoor representations by injecting known triggers, and
\textbf{then}, performing recovery fine-tuning to restore benign outputs.
Extensive experiments across multiple LLM architectures demonstrate that: (I)
\ourmethod reduces the average Attack Success Rate to 4.41\% across multiple
benchmarks, outperforming existing baselines by 28.1\%$\sim$69.3\%$\uparrow$.
(II) Clean accuracy and utility are preserved within 0.5\% of the original
model, ensuring negligible impact on legitimate tasks. (III) The defense
generalizes across different types of backdoors, confirming its robustness in
practical deployment scenarios.

</details>


### [275] [On the Entity-Level Alignment in Crosslingual Consistency](https://arxiv.org/abs/2510.10280)
*Yihong Liu,Mingyang Wang,François Yvon,Hinrich Schütze*

Main category: cs.CL

TL;DR: 多语言大语言模型（LLMs）在跨语言事实回忆方面存在不一致性，这可能源于实体对齐失败。研究通过实体翻译任务评估对齐情况，发现对齐与一致性强相关。提出SubSub和SubInj方法，将英文翻译的实体整合到提示中，显著提高了事实回忆的准确性和一致性。机制分析表明，这些干预措施通过模型内部的枢轴语言处理，加强了实体表示的对齐，为改进多语言事实预测提供了有效策略。


<details>
  <summary>Details</summary>
Motivation: 多语言大语言模型（LLMs）在跨语言事实回忆方面存在不一致性，但其原因尚不清楚。

Method: 1. 评估实体（主语和宾语）的翻译任务，以检验实体对齐假设。 2. 提出SubSub和SubInj两种方法，将英文翻译的主语整合到跨语言提示中。 3. 进行机制分析，探究这些干预措施如何影响模型内部的实体表示对齐。

Result: 实体对齐与跨语言事实回忆的一致性密切相关，主语或宾语的错位频繁导致不一致性。SubSub和SubInj方法显著提高了事实回忆的准确性和一致性。

Conclusion: 实体对齐失败是导致多语言LLM跨语言事实回忆不一致性的关键因素。通过将英文翻译的实体整合到提示中（如SubSub和SubInj方法），可以有效改善实体表示的对齐，从而提高事实回忆的准确性和一致性。

Abstract: Multilingual large language models (LLMs) are expected to recall factual
knowledge consistently across languages. However, the factors that give rise to
such crosslingual consistency -- and its frequent failure -- remain poorly
understood. In this work, we hypothesize that these inconsistencies may arise
from failures in entity alignment, the process of mapping subject and object
entities into a shared conceptual space across languages. To test this, we
assess alignment through entity-level (subject and object) translation tasks,
and find that consistency is strongly correlated with alignment across all
studied models, with misalignment of subjects or objects frequently resulting
in inconsistencies. Building on this insight, we propose SubSub and SubInj, two
effective methods that integrate English translations of subjects into prompts
across languages, leading to substantial gains in both factual recall accuracy
and consistency. Finally, our mechanistic analysis reveals that these
interventions reinforce the entity representation alignment in the conceptual
space through model's internal pivot-language processing, offering effective
and practical strategies for improving multilingual factual prediction.

</details>


### [276] [MatryoshkaThinking: Recursive Test-Time Scaling Enables Efficient Reasoning](https://arxiv.org/abs/2510.10293)
*Hongwei Chen,Yishu Lei,Dan Zhang,Bo Ke,Danxiang Zhu,Xuyi Chen,Yuxiang Lu,Zhengjie Huang,Shikun Feng,Jingzhou He,Yu Sun,Hua Wu,Haifeng Wang*

Main category: cs.CL

TL;DR: Test-time scaling for language models can improve performance but is often computationally expensive. MatryoshkaThinking reduces this cost by recursively using the model's reasoning, verification, and summarization abilities, achieving high performance with significantly less computation.


<details>
  <summary>Details</summary>
Motivation: To address the substantial computational overhead of existing test-time scaling methods in language modeling while maintaining state-of-the-art performance.

Method: MatryoshkaThinking recursively exploits the model's intrinsic capabilities in reasoning, verification, and summarization to enhance solution retention and reduce the disparity between Pass@k and Pass@1, thereby reducing computational cost.

Result: Achieved a score of 99.79 on AIME2025 using only 4% of the computation required by DeepConf, demonstrating effectiveness and generality across multiple open-source models and multi-modal reasoning benchmarks.

Conclusion: MatryoshkaThinking offers a novel and efficient approach to test-time inference strategies for advanced language models, significantly reducing computational cost while maintaining state-of-the-art performance.

Abstract: Test-time scaling has emerged as a promising paradigm in language modeling,
wherein additional computational resources are allocated during inference to
enhance model performance. Recent approaches, such as DeepConf, have
demonstrated the efficacy of this strategy, however, they often incur
substantial computational overhead to achieve competitive results. In this
work, we propose MatryoshkaThinking, a novel method that significantly reduces
computational cost while maintaining state-of-the-art performance.
Specifically, MatryoshkaThinking attains a score of 99.79 on AIME2025 using
only 4% of the computation required by DeepConf. The core of our approach lies
in the recursive exploitation of the model's intrinsic capabilities in
reasoning, verification, and summarization, which collectively enhance the
retention of correct solutions and reduce the disparity between Pass@k and
Pass@1. Comprehensive evaluations across multiple open-source models and
challenging multi-modal reasoning benchmarks validate the effectiveness and
generality of our method. These findings offer new insights into the design of
efficient and scalable test-time inference strategies for advanced language
models.

</details>


### [277] [Are LLMs Empathetic to All? Investigating the Influence of Multi-Demographic Personas on a Model's Empathy](https://arxiv.org/abs/2510.10328)
*Ananya Malik,Nazanin Sabri,Melissa Karnaze,Mai Elsherief*

Main category: cs.CL

TL;DR: LLMs在同理心理解和回应方面存在跨用户群体不平等的问题。本研究提出的框架通过交叉分析315个用户画像，发现在年龄、文化和性别等属性影响下，LLMs的同理心表现存在显著差异，尤其是在组合属性时，同理心模式可能发生变化甚至反转。研究结果与现实世界同理心趋势相似，但在某些群体（如儒家文化背景）上存在偏差。研究强调了设计同理心感知LLMs以适应人口统计多样性的重要性。


<details>
  <summary>Details</summary>
Motivation: 用户的社会和文化背景会影响其情绪体验，因此需要探究大型语言模型（LLMs）是否能对不同用户群体展现出公平的同理心。

Method: 提出一个框架，通过交叉分析年龄、文化和性别这三个维度，构建315个独特的用户画像，以此研究四种大型语言模型在不同用户画像下的认知和情感同理心表现，并结合定性分析来揭示模型行为模式。

Result: 研究结果表明，用户的社会属性（年龄、文化、性别）深刻影响LLMs的同理心回应。当同时考虑多个属性时，同理心模式可能减弱甚至反转。LLMs的同理心表现总体上反映了现实世界的趋势，但在某些群体（如儒家文化背景）上存在显著的偏差。

Conclusion: LLMs在同理心方面未能实现跨用户群体的公平性。研究结果凸显了在设计LLMs时，必须考虑人口统计学上的多样性，以实现更具包容性和公平性的模型行为。

Abstract: Large Language Models' (LLMs) ability to converse naturally is empowered by
their ability to empathetically understand and respond to their users. However,
emotional experiences are shaped by demographic and cultural contexts. This
raises an important question: Can LLMs demonstrate equitable empathy across
diverse user groups? We propose a framework to investigate how LLMs' cognitive
and affective empathy vary across user personas defined by intersecting
demographic attributes. Our study introduces a novel intersectional analysis
spanning 315 unique personas, constructed from combinations of age, culture,
and gender, across four LLMs. Results show that attributes profoundly shape a
model's empathetic responses. Interestingly, we see that adding multiple
attributes at once can attenuate and reverse expected empathy patterns. We show
that they broadly reflect real-world empathetic trends, with notable
misalignments for certain groups, such as those from Confucian culture. We
complement our quantitative findings with qualitative insights to uncover model
behaviour patterns across different demographic groups. Our findings highlight
the importance of designing empathy-aware LLMs that account for demographic
diversity to promote more inclusive and equitable model behaviour.

</details>


### [278] [End-to-end Automatic Speech Recognition and Speech Translation: Integration of Speech Foundational Models and LLMs](https://arxiv.org/abs/2510.10329)
*Nam Luu,Ondřej Bojar*

Main category: cs.CL

TL;DR: 该论文提出了一种结合预训练语音编码器和大型语言模型的端到端架构，可同时执行自动语音识别（ASR）和语音翻译（ST）。


<details>
  <summary>Details</summary>
Motivation: 探索一种能够同时进行ASR和ST的端到端架构，以期在翻译性能上超越现有模型。

Method: 采用结合预训练语音编码器和大型语言模型的端到端架构。

Result: 在英德语言对的实验中，该模型在翻译性能上优于SeamlessM4T，并能媲美基于Whisper和NLLB的级联系统，COMET DA$_{22}$指标最高提升8%。

Conclusion: 所提出的端到端架构在语音翻译任务上取得了优异的成绩，性能超越了现有的大型模型和级联系统。

Abstract: Speech Translation (ST) is a machine translation task that involves
converting speech signals from one language to the corresponding text in
another language; this task has two different approaches, namely the
traditional cascade and the more recent end-to-end. This paper explores a
combined end-to-end architecture of pre-trained speech encoders and Large
Language Models (LLMs) for performing both Automatic Speech Recognition (ASR)
and ST simultaneously. Experiments with the English-to-German language pair
show that our best model not only can achieve better translation results than
SeamlessM4T, a large foundational end-to-end, multi-modal translation model,
but can also match the performance of a cascaded system with Whisper and NLLB,
with up to a score gain of 8% in $\text{COMET}^{\text{DA}}_{22}$ metric.

</details>


### [279] [ASC analyzer: A Python package for measuring argument structure construction usage in English texts](https://arxiv.org/abs/2510.10384)
*Hakyung Sung,Kristopher Kyle*

Main category: cs.CL

TL;DR: 该研究介绍了一个名为ASC分析器的Python工具包，用于量化第二语言学习者在写作中论证结构构建（ASC）的使用情况，并通过分析ASC指标与写作分数的关系来展示其效用。


<details>
  <summary>Details</summary>
Motivation: 现有的衡量第二语言（L2）学习者在论证结构构建（ASC）使用情况的工具不足，难以进行大规模、系统性的测量。

Method: 开发了一个名为ASC分析器的Python包，能够自动标记ASC，并计算包括多样性、比例、频率以及ASC-verb lemma关联强度在内的50个指标。随后，研究者使用该工具进行了双变量和多变量分析，以探究ASC指标与L2写作分数之间的关系。

Result: 该分析器可以自动量化ASC的使用情况，并提供了50个不同的指标。初步分析表明，ASC指标与L2写作分数之间存在关联。

Conclusion: ASC分析器是一个有用的工具，可以为L2能力研究提供更量化的视角，并有助于理解ASC使用与写作能力之间的关系。

Abstract: Argument structure constructions (ASCs) offer a theoretically grounded lens
for analyzing second language (L2) proficiency, yet scalable and systematic
tools for measuring their usage remain limited. This paper introduces the ASC
analyzer, a publicly available Python package designed to address this gap. The
analyzer automatically tags ASCs and computes 50 indices that capture
diversity, proportion, frequency, and ASC-verb lemma association strength. To
demonstrate its utility, we conduct both bivariate and multivariate analyses
that examine the relationship between ASC-based indices and L2 writing scores.

</details>


### [280] [RefusalBench: Generative Evaluation of Selective Refusal in Grounded Language Models](https://arxiv.org/abs/2510.10390)
*Aashiq Muhamed,Leonardo F. R. Ribeiro,Markus Dreyer,Virginia Smith,Mona T. Diab*

Main category: cs.CL

TL;DR: 大型语言模型在检索增强生成（RAG）系统中选择性拒绝回答错误信息的能力对于安全至关重要，但仍是关键的失败点。现有模型在此方面表现不佳，在多文档任务上的拒绝准确率低于50%。静态基准测试无法可靠评估此能力，因为模型会利用数据集的特定伪影并记住测试实例。本研究引入了一种名为RefusalBench的生成方法，通过受控的语言扰动来创建诊断测试用例。该框架在六类信息不确定性和三个强度级别上采用了176种不同的扰动策略。对30多个模型的评估揭示了系统性的失败模式：拒绝能力包括可分离的检测和分类技能，并且性能不随规模或扩展推理而提高。研究发现，选择性拒绝是一种可训练的、与对齐敏感的能力，为改进提供了明确的途径。研究发布了两个基准测试——RefusalBench-NQ（单文档）和RefusalBench-GaRAGe（多文档）——以及完整的生成框架，以支持对该关键能力的持续、动态评估。


<details>
  <summary>Details</summary>
Motivation: 现有模型在检索增强生成（RAG）系统中选择性拒绝回答基于错误信息的能力方面存在重大缺陷，影响了系统的安全性。静态基准测试无法有效评估此能力，模型会利用数据集的特定伪影并记住测试实例。

Method: 提出了一种名为RefusalBench的生成方法，该方法通过受控的语言扰动（176种扰动策略，涵盖6类信息不确定性和3个强度级别）来创建诊断测试用例，以评估模型在RAG系统中的选择性拒绝能力。此外，还发布了两个基准测试：RefusalBench-NQ（单文档）和RefusalBench-GaRAGe（多文档）。

Result: 对30多个模型的评估显示，即使是前沿模型在此任务上的表现也不佳，在多文档任务上的拒绝准确率低于50%。研究发现，选择性拒绝能力包括可分离的检测和分类技能，并且性能不随模型规模或扩展推理能力的提高而改善。最后，研究表明选择性拒绝是一种可训练的、与对齐敏感的能力，为未来的改进提供了方向。

Conclusion: 选择性拒绝回答错误信息是RAG系统安全的关键能力，但现有模型表现不佳。RefusalBench提供了一种新的评估方法，揭示了模型的系统性失败模式，并表明选择性拒绝是可训练且与对齐敏感的，为未来的模型改进指明了方向。

Abstract: The ability of language models in RAG systems to selectively refuse to answer
based on flawed context is critical for safety, yet remains a significant
failure point. Our large-scale study reveals that even frontier models struggle
in this setting, with refusal accuracy dropping below 50% on multi-document
tasks, while exhibiting either dangerous overconfidence or overcaution. Static
benchmarks fail to reliably evaluate this capability, as models exploit
dataset-specific artifacts and memorize test instances. We introduce
RefusalBench, a generative methodology that programmatically creates diagnostic
test cases through controlled linguistic perturbation. Our framework employs
176 distinct perturbation strategies across six categories of informational
uncertainty and three intensity levels. Evaluation of over 30 models uncovers
systematic failure patterns: refusal comprises separable detection and
categorization skills, and neither scale nor extended reasoning improves
performance. We find that selective refusal is a trainable, alignment-sensitive
capability, offering a clear path for improvement. We release two benchmarks --
RefusalBench-NQ (single document) and RefusalBench-GaRAGe (multi-document) --
and our complete generation framework to enable continued, dynamic evaluation
of this critical capability.

</details>


### [281] [AssoMem: Scalable Memory QA with Multi-Signal Associative Retrieval](https://arxiv.org/abs/2510.10397)
*Kai Zhang,Xinyuan Zhang,Ejaz Ahmed,Hongda Jiang,Caleb Kumar,Kai Sun,Zhaojiang Lin,Sanat Sharma,Shereen Oraby,Aaron Colak,Ahmed Aly,Anuj Kumar,Xiaozhong Liu,Xin Luna Dong*

Main category: cs.CL

TL;DR: AssoMem框架通过构建关联记忆图来改善AI助手的问答能力，特别是在相似性强的场景下，解决了大规模记忆的准确检索问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模记忆检索方法主要依赖与查询的语义距离，在相似性强的场景下效果不佳。本研究受到人类联想信息方式的启发，旨在提出一种新的框架来解决这个问题。

Method: 提出AssoMem框架，构建一个关联记忆图，将对话语句与自动提取的线索联系起来。该框架通过多维检索信号（相关性、重要性、时间对齐）的自适应互信息（MI）驱动融合策略进行整合。

Result: 在三个基准和新引入的MeetingQA数据集上的广泛实验表明，AssoMem的表现持续优于最先进的方法。

Conclusion: AssoMem在上下文感知记忆检索方面具有优越性。

Abstract: Accurate recall from large scale memories remains a core challenge for memory
augmented AI assistants performing question answering (QA), especially in
similarity dense scenarios where existing methods mainly rely on semantic
distance to the query for retrieval. Inspired by how humans link information
associatively, we propose AssoMem, a novel framework constructing an
associative memory graph that anchors dialogue utterances to automatically
extracted clues. This structure provides a rich organizational view of the
conversational context and facilitates importance aware ranking. Further,
AssoMem integrates multi-dimensional retrieval signals-relevance, importance,
and temporal alignment using an adaptive mutual information (MI) driven fusion
strategy. Extensive experiments across three benchmarks and a newly introduced
dataset, MeetingQA, demonstrate that AssoMem consistently outperforms SOTA
baselines, verifying its superiority in context-aware memory recall.

</details>


### [282] [STEAM: A Semantic-Level Knowledge Editing Framework for Large Language Models](https://arxiv.org/abs/2510.10398)
*Geunyeong Jeong,Juoh Sun,Seonghee Lee,Harksoo Kim*

Main category: cs.CL

TL;DR: LLM知识编辑的现有方法侧重于令牌级优化，忽略了语义一致性。我们提出了Steam，一个在语义层面进行知识编辑的框架，通过将更新后的知识引导到模型知识结构中的目标表示（语义锚点）来增强集成。实验表明，Steam 提高了模型对编辑后知识的推理能力和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型知识编辑方法主要关注令牌级别的似然度优化，而忽略了语义层面的考量，导致编辑后的知识在模型的潜在空间中被孤立地编码，绕过了自然的推理过程。

Method: Steam首先识别目标表示作为更新的事实关联的语义锚点，然后在优化过程中通过对齐损失引导编辑后事实的内部表示朝着这些锚点进行对齐。

Result: 实验结果表明，Steam 提高了模型使用编辑后知识进行推理的能力，并增强了语义一致性。

Conclusion: Steam 框架通过在潜在空间中进行对齐，为可靠且一致的知识编辑提供了重要的方法，强调了这种对齐对于知识编辑的可靠性和一致性的重要性。

Abstract: Large Language Models store extensive factual knowledge acquired during
large-scale pre-training. However, this knowledge is inherently static,
reflecting only the state of the world at the time of training. Knowledge
editing has emerged as a promising solution for updating outdated or incorrect
facts without full retraining. However, most existing locate-and-edit methods
primarily focus on token-level likelihood optimization without addressing
semantic coherence. Our analysis reveals that such edited knowledge is often
encoded as isolated residual streams in the model's latent space, distinct from
pre-existing knowledge and bypassing natural reasoning process. To address
this, we propose \textsc{Steam}, a semantic-level knowledge editing framework
that enhances integration of updated knowledge into the model's knowledge
structure. \textsc{Steam} first identifies target representations as semantic
anchors for the updated factual association, then guides the internal
representation of the edited fact towards these anchors through an alignment
loss during optimization. Experimental results demonstrate that \textsc{Steam}
improves model's ability to reason with edited knowledge and enhances semantic
coherence, underscoring the importance of latent-space alignment for reliable
and coherent knowledge editing. The code is available at
https://github.com/GY-Jeong/STEAM.

</details>


### [283] [LONGQAEVAL: Designing Reliable Evaluations of Long-Form Clinical QA under Resource Constraints](https://arxiv.org/abs/2510.10415)
*Federica Bologna,Tiffany Pan,Matthew Wilkens,Yue Guo,Lucy Lu Wang*

Main category: cs.CL

TL;DR: 长篇临床问答系统评估困难，我们提出了LongQAEval框架，通过医生标注的300个真实病例问答数据，比较了粗粒度与细粒度评估方法在正确性、相关性和安全性上的差异，并提出了在有限资源和高专业度要求下的评估建议。


<details>
  <summary>Details</summary>
Motivation: 评估长篇临床问答系统既耗费资源又充满挑战，因为准确的判断需要医学专业知识，而且在长文本上实现一致的人工判断非常困难。

Method: 基于医生对300个由医生和LLM回答的真实患者问题的标注，比较了粗粒度答案级别和细粒度句子级别的评估方法在正确性、相关性和安全性这几个维度上的表现。

Result: 研究发现，评价者间一致性（IAA）因维度而异：细粒度标注提高了正确性判断的一致性，粗粒度标注提高了相关性判断的一致性，而安全性判断的一致性仍然不一致。此外，只标注一小部分句子就能提供与粗粒度标注相当的可靠性，从而降低了成本和工作量。

Conclusion: 在资源有限和专业度要求高的情况下，可以考虑采用细粒度标注的子集句子进行评估，以在保证一定可靠性的前提下降低成本和工作量。

Abstract: Evaluating long-form clinical question answering (QA) systems is
resource-intensive and challenging: accurate judgments require medical
expertise and achieving consistent human judgments over long-form text is
difficult. We introduce LongQAEval, an evaluation framework and set of
evaluation recommendations for limited-resource and high-expertise settings.
Based on physician annotations of 300 real patient questions answered by
physicians and LLMs, we compare coarse answer-level versus fine-grained
sentence-level evaluation over the dimensions of correctness, relevance, and
safety. We find that inter-annotator agreement (IAA) varies by dimension:
fine-grained annotation improves agreement on correctness, coarse improves
agreement on relevance, and judgments on safety remain inconsistent.
Additionally, annotating only a small subset of sentences can provide
reliability comparable to coarse annotations, reducing cost and effort.

</details>


### [284] [Do Audio LLMs Really LISTEN, or Just Transcribe? Measuring Lexical vs. Acoustic Emotion Cues Reliance](https://arxiv.org/abs/2510.10444)
*Jingyi Chen,Zhimeng Guo,Jiyun Chun,Pichao Wang,Andrew Perrault,Micha Elsner*

Main category: cs.CL

TL;DR: 大型音频语言模型（LALMs）在理解语音情感时，倾向于依赖词汇内容而非声学线索。


<details>
  <summary>Details</summary>
Motivation: 需要弄清楚大型音频语言模型（LALMs）在理解语音情感时，是真正地处理了声学信息，还是主要依赖于词汇内容。

Method: 提出了一种名为LISTEN（Lexical vs. Acoustic Speech Test for Emotion in Narratives）的受控基准测试，用于区分LALMs在情感理解中的词汇依赖性和声学敏感性。

Result: 对六种最先进的LALMs的评估显示，模型普遍表现出词汇主导性。当词汇线索中性或缺失时，模型预测为“中性”；在词汇和声学线索一致时，模型性能提升有限；在词汇和声学线索冲突时，模型无法区分不同的情感。在 ફક્ત 声学线索（paralinguistic）的情况下，模型性能接近随机猜测。

Conclusion: 当前的大型音频语言模型（LALMs）在很大程度上是“抄录”而非“倾听”，它们严重依赖词汇语义，而对声学线索的利用不足。LISTEN提供了一个原则性的框架来评估多模态模型在情感理解方面的能力。

Abstract: Understanding emotion from speech requires sensitivity to both lexical and
acoustic cues. However, it remains unclear whether large audio language models
(LALMs) genuinely process acoustic information or rely primarily on lexical
content. We present LISTEN (Lexical vs. Acoustic Speech Test for Emotion in
Narratives), a controlled benchmark designed to disentangle lexical reliance
from acoustic sensitivity in emotion understanding. Across evaluations of six
state-of-the-art LALMs, we observe a consistent lexical dominance. Models
predict "neutral" when lexical cues are neutral or absent, show limited gains
under cue alignment, and fail to classify distinct emotions under cue conflict.
In paralinguistic settings, performance approaches chance. These results
indicate that current LALMs largely "transcribe" rather than "listen," relying
heavily on lexical semantics while underutilizing acoustic cues. LISTEN offers
a principled framework for assessing emotion understanding in multimodal
models.

</details>


### [285] [RECON: Reasoning with Condensation for Efficient Retrieval-Augmented Generation](https://arxiv.org/abs/2510.10448)
*Zhichao Xu,Minheng Wang,Yawei Wang,Wenqian Ye,Yuntao Du,Yunpu Ma,Yijun Tian*

Main category: cs.CL

TL;DR: RECON 通过在推理循环中集成显式摘要模块来压缩证据，解决了 RAG 系统中低效的上下文管理问题，从而减少了上下文长度、提高了训练速度和推理延迟，并改进了 QA 基准测试的性能。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统在利用强化学习（RL）进行推理时，面临着低效的上下文管理问题，因为冗长且包含无关信息的检索文档会增加成本并降低性能。

Method: 提出了一种名为 RECON（REasoning with CONdensation）的框架，该框架包含一个显式的摘要模块，用于在推理循环中压缩证据。该摘要器通过两个阶段进行训练：首先在问答数据集上进行相关性预训练，然后从专有的 LLM 中进行多方面蒸馏，以确保事实性和清晰度。RECON 被集成到 Search-R1 管道中。

Result: RECON 将总上下文长度减少了 35%，提高了训练速度和推理延迟，同时改进了下游问答基准测试的 RAG 性能。具体来说，它将 3B 模型的平均 EM 分数提高了 14.5%，7B 模型提高了 3.0%，在多跳问答方面表现尤为出色。

Conclusion: RECON 证明了学习到的上下文压缩对于构建实用、可扩展且高性能的 RAG 系统至关重要。

Abstract: Retrieval-augmented generation (RAG) systems trained using reinforcement
learning (RL) with reasoning are hampered by inefficient context management,
where long, noisy retrieved documents increase costs and degrade performance.
We introduce RECON (REasoning with CONdensation), a framework that integrates
an explicit summarization module to compress evidence within the reasoning
loop. Our summarizer is trained via a two-stage process: relevance pretraining
on QA datasets, followed by multi-aspect distillation from proprietary LLMs to
ensure factuality and clarity. Integrated into the Search-R1 pipeline, RECON
reduces total context length by 35\%, leading to improved training speed and
inference latency, while simultaneously improving RAG performance on downstream
QA benchmarks. Notably, it boosts the average EM score of the 3B model by
14.5\% and the 7B model by 3.0\%, showing particular strength in multi-hop QA.
RECON demonstrates that learned context compression is essential for building
practical, scalable, and performant RAG systems. Our code implementation is
made available at https://github.com/allfornancy/RECON.

</details>


### [286] [Steering Over-refusals Towards Safety in Retrieval Augmented Generation](https://arxiv.org/abs/2510.10452)
*Utsav Maskey,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）的安全对齐会导致过度拒绝，即LLM因过于激进的安全过滤器而拒绝良性请求。本研究在检索增强生成（RAG）中分析了这一现象，其中查询意图和检索到的上下文属性都会影响拒绝行为。


<details>
  <summary>Details</summary>
Motivation: 分析在检索增强生成（RAG）中，良性请求被安全对齐导致LLM过度拒绝的现象，并探究其潜在原因。

Method: 构建了一个名为RagRefuse的、按领域分层的基准测试，涵盖医学、化学和开放域，将良性查询和有害查询与受控的上下文污染模式和大小配对。分析了上下文安排/污染、查询和上下文的领域以及有害文本密度如何触发即使是良性查询的拒绝。提出了一种名为SafeRAG-Steering的模型中心嵌入干预方法，在推理时将嵌入区域引导至已确认的安全、不拒绝的输出区域。

Result: 上下文安排/污染、查询和上下文的领域以及有害文本密度会触发对良性查询的拒绝，并且其影响取决于模型的特定对齐选择。SafeRAG-Steering可以减少受污染的RAG管道中的过度拒绝，同时保留合法的拒绝。

Conclusion: 上下文的污染和领域特性是导致RAG中过度拒绝的关键因素。提出的SafeRAG-Steering方法可以有效减轻这些问题，同时保持模型的安全响应能力。

Abstract: Safety alignment in large language models (LLMs) induces over-refusals --
where LLMs decline benign requests due to aggressive safety filters. We analyze
this phenomenon in retrieval-augmented generation (RAG), where both the query
intent and retrieved context properties influence refusal behavior. We
construct RagRefuse, a domain-stratified benchmark spanning medical, chemical,
and open domains, pairing benign and harmful queries with controlled context
contamination patterns and sizes. Our analysis shows that context arrangement /
contamination, domain of query and context, and harmful-text density trigger
refusals even on benign queries, with effects depending on model-specific
alignment choices. To mitigate over-refusals, we introduce
\textsc{SafeRAG-Steering}, a model-centric embedding intervention that steers
the embedding regions towards the confirmed safe, non-refusing output regions
at inference time. This reduces over-refusals in contaminated RAG pipelines
while preserving legitimate refusals.

</details>


### [287] [End-to-end Speech Recognition with similar length speech and text](https://arxiv.org/abs/2510.10453)
*Peng Fan,Wenping Wang,Fei Deng*

Main category: cs.CL

TL;DR: 本文提出了一种在语音和文本长度相似的情况下进行语音识别的新方法，通过引入时间独立性损失（TIL）和对齐交叉熵损失（AXE）来解决语音与文本不对齐的问题，并通过帧融合增强关键帧信息，实验结果表明该方法在AISHELL数据集上表现优于现有方法，并将帧数减少了86%。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别（ASR）方法在处理语音长度和文本长度不匹配时存在挑战，特别是当语音被降采样到类似文本的长度时，传统的CTC方法难以实现准确的语音文本对齐。

Method: 本文提出了两种新的对齐方法：时间独立性损失（TIL）和基于编辑距离的对齐交叉熵损失（AXE）。此外，通过将关键帧与其上下文（前后各2帧）进行加权融合，以增强关键帧的信息。

Result: 在AISHELL-1和AISHELL-2数据集子集上的实验结果表明，所提出的方法（TIL和AXE）的性能优于先前的方法，并将帧数减少了至少86%。

Conclusion: 本文提出的TIL和AXE方法以及帧融合技术，有效解决了语音与文本长度相似情况下的语音识别对齐问题，并在数据集上取得了显著的性能提升和帧数约减。

Abstract: The mismatch of speech length and text length poses a challenge in automatic
speech recognition (ASR). In previous research, various approaches have been
employed to align text with speech, including the utilization of Connectionist
Temporal Classification (CTC). In earlier work, a key frame mechanism (KFDS)
was introduced, utilizing intermediate CTC outputs to guide downsampling and
preserve keyframes, but traditional methods (CTC) failed to align speech and
text appropriately when downsampling speech to a text-similar length. In this
paper, we focus on speech recognition in those cases where the length of speech
aligns closely with that of the corresponding text. To address this issue, we
introduce two methods for alignment: a) Time Independence Loss (TIL) and b)
Aligned Cross Entropy (AXE) Loss, which is based on edit distance. To enhance
the information on keyframes, we incorporate frame fusion by applying weights
and summing the keyframe with its context 2 frames. Experimental results on
AISHELL-1 and AISHELL-2 dataset subsets show that the proposed methods
outperform the previous work and achieve a reduction of at least 86\% in the
number of frames.

</details>


### [288] [Rethinking LLM Evaluation: Can We Evaluate LLMs with 200x Less Data?](https://arxiv.org/abs/2510.10457)
*Shaobo Wang,Cong Wang,Wenjie Fu,Yue Min,Mingquan Feng,Isabel Guan,Xuming Hu,Conghui He,Cunxiang Wang,Kexin Yang,Xingzhang Ren,Fei Huang,Dayiheng Liu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 该研究提出了EssenceBench框架，通过迭代遗传算法有效地压缩了基准测试套件，实现了高精度的模型排名预测和显著的样本减少，同时保持了排名的一致性。


<details>
  <summary>Details</summary>
Motivation: 随着模型能力评估需求的增加，基准测试套件规模不断扩大，需要更有效的压缩方法来提高效率并保证评估的准确性。

Method: 提出了一种结合样本级冗余分析和基于优化的基准压缩框架EssenceBench。该框架使用迭代遗传算法，结合了基于适应度的子集搜索和基于归因的样本搜索，将基准压缩视为一个分数重建的优化问题。

Result: EssenceBench框架在压缩率和重建误差方面优于现有方法。在HellaSwag基准测试中，使用25倍更少样本时，模型排名变化在5%以内；使用200倍更少样本时，排名保持度达到95%。

Conclusion: EssenceBench框架能够以极高的效率显著减少基准测试的样本数量，同时保持模型排名的准确性和一致性，为大规模模型评估提供了有效的解决方案。

Abstract: As the demand for comprehensive evaluations of diverse model capabilities
steadily increases, benchmark suites have correspondingly grown significantly
in scale. Despite notable advances in redundancy reduction and subset-level
performance prediction, a systematic framework that effectively integrates
these methods to ensure both prediction accuracy and ranking consistency is
still largely elusive. In this paper, we first perform a sample-level analysis
of benchmark redundancy and identify several highly similar samples that can be
eliminated. Besides, we frame benchmark compression as an optimization problem
with the aim of score reconstruction. Building on these, we then propose
EssenceBench, a coarse-to-fine framework utilizing an iterative Genetic
Algorithm (GA), which takes the advantages of fitness-based subset search and
attribution-based sample search. Compared to previous methods, our approach
yields superior compression results with lower reconstruction error and
markedly higher efficiency. In particular, on the HellaSwag benchmark (10K
samples), our method preserves the ranking of all models shifting within 5%
using 25x fewer samples, and achieves 95% ranking preservation shifting within
5% using only 200x fewer samples.

</details>


### [289] [NIM: Neuro-symbolic Ideographic Metalanguage for Inclusive Communication](https://arxiv.org/abs/2510.10459)
*Prawaal Sharma,Poonam Goyal,Navneet Goyal,Vidisha Sharma*

Main category: cs.CL

TL;DR: 开发了一种通用的表意元语言，用于弥合学术、语言和文化鸿沟，特别是帮助学术素养较低的人群。


<details>
  <summary>Details</summary>
Motivation: 低学术素养的个体在数字交流中面临巨大障碍，加剧了“数字鸿沟”。

Method: 利用神经符号AI的原理，结合基于神经网络的大型语言模型（LLMs）和基于自然语义元语言（NSM）理论的符号知识启发式方法，将复杂概念分解为原子概念。通过与200多名识字率低的参与者合作，共同定义问题、选择表意符号和验证系统。

Result: 该系统达到了超过80%的语义可理解性，学习曲线平缓，具有普遍适应性。

Conclusion: 该系统能有效服务于正规教育程度有限的弱势群体，为他们提供了跨越学术、语言和文化障碍的交流方式。

Abstract: Digital communication has become the cornerstone of modern interaction,
enabling rapid, accessible, and interactive exchanges. However, individuals
with lower academic literacy often face significant barriers, exacerbating the
"digital divide". In this work, we introduce a novel, universal ideographic
metalanguage designed as an innovative communication framework that transcends
academic, linguistic, and cultural boundaries. Our approach leverages
principles of Neuro-symbolic AI, combining neural-based large language models
(LLMs) enriched with world knowledge and symbolic knowledge heuristics grounded
in the linguistic theory of Natural Semantic Metalanguage (NSM). This enables
the semantic decomposition of complex ideas into simpler, atomic concepts.
Adopting a human-centric, collaborative methodology, we engaged over 200
semi-literate participants in defining the problem, selecting ideographs, and
validating the system. With over 80\% semantic comprehensibility, an accessible
learning curve, and universal adaptability, our system effectively serves
underprivileged populations with limited formal education.

</details>


### [290] [FML-bench: A Benchmark for Automatic ML Research Agents Highlighting the Importance of Exploration Breadth](https://arxiv.org/abs/2510.10472)
*Qiran Zou,Hou Hei Lam,Wenhao Zhao,Yiming Tang,Tingting Chen,Samson Yu,Tianyi Zhang,Chang Liu,Xiangyang Ji,Dianbo Liu*

Main category: cs.CL

TL;DR: FML-bench是一个新的机器学习研究基准，用于评估自动机器学习研究代理的科学能力，解决了现有基准的局限性，并提出了一个统一的评估框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准在评估自动机器学习研究代理时存在不足，过分侧重工程方面而忽略学术严谨性，任务类型单一，并且难以扩展到真实的研究场景。为了解决这些问题，需要一个更全面的评估基准。

Method: 提出FML-bench基准，包含8个多样化且基础性的机器学习研究问题，降低了编码负担，侧重于基础问题而非特定应用，并具有良好的可扩展性。同时，引入一个包含五个互补指标的统一评估框架来全面评估代理性能。

Result: 在FML-bench基准上评估了最先进的自动研究代理，发现采用广泛研究探索策略的代理优于专注于狭窄但深入探索的代理。这表明探索的广度可能比仅仅关注渐进式改进更能带来有效的研究成果。

Conclusion: FML-bench为评估自动机器学习研究代理提供了一个更全面、更具学术严谨性的平台。研究结果表明，在研究探索中，广度比深度更为重要，这为未来自动研究代理的设计和评估提供了新的方向。

Abstract: Large language models (LLMs) have sparked growing interest in automatic
machine learning research agents. Among them, agents capable of autonomously
proposing ideas and conducting machine learning experiments are particularly
promising, as they maximize research automation and accelerate scientific
progress by iteratively refining ideas based on experimental results. However,
comprehensively evaluating such agents remains challenging. Existing benchmarks
tend to overemphasize engineering aspects while neglecting academic rigor,
creating barriers that obscure a clear assessment of an agent's scientific
capabilities in machine learning research. They also suffer from limited task
diversity, an overemphasis on application-oriented tasks over fundamental
research problems, and limited scalability to realistic research settings. To
address these limitations, we introduce FML-bench, a benchmark designed to
evaluate automatic machine learning research agents on 8 diverse and
fundamental machine learning research problems. It reduces coding burden,
emphasizes fundamental problems rather than specific use cases, offers high
task diversity, and is extensible to real-world machine learning GitHub
repositories. Furthermore, we present a unified evaluation framework with five
complementary metrics, designed to comprehensively assess agent performance on
our benchmark. We evaluate state-of-the-art automatic research agents on
FML-bench, and find that agents employing broad research exploration strategies
outperform those focusing on narrow but deep exploration. These findings
suggest that emphasizing the breadth of exploration may lead to more effective
research outcomes than focusing solely on incremental refinement. Our benchmark
is available at https://github.com/qrzou/FML-bench.

</details>


### [291] [When or What? Understanding Consumer Engagement on Digital Platforms](https://arxiv.org/abs/2510.10474)
*Jingyi Wu,Junying Liang*

Main category: cs.CL

TL;DR: 内容创作中的受众吸引力受内容特征和发布时机的影响，而后者可能更为关键。


<details>
  <summary>Details</summary>
Motivation: 理解内容吸引力的驱动因素对于数字服务经济至关重要，但现有研究过分强调内容特征，而忽略了创作者可能误判受众偏好。

Method: 本研究利用潜在狄利克雷分配（LDA）模型分析TED演讲的语料库，对比创作者的主题供给与受众的参与度（需求），并进行纵向分析以探究时间动态的影响。

Result: 研究发现创作者在主题供给和受众需求之间存在持续的匹配不一致。时间动态对受众参与度的影响比主题内容更强，表明发布时机比内容本身更重要。

Conclusion: 内容特征并非吸引力的主要驱动因素，发布时机和情境因素在影响受众反应中起着更重要的作用。这为数字平台上的受众吸引力动态提供了新见解，并对营销人员、平台管理者和内容创作者具有实际意义。

Abstract: Understanding what drives popularity is critical in today's digital service
economy, where content creators compete for consumer attention. Prior studies
have primarily emphasized the role of content features, yet creators often
misjudge what audiences actually value. This study applies Latent Dirichlet
Allocation (LDA) modeling to a large corpus of TED Talks, treating the platform
as a case of digital service provision in which creators (speakers) and
consumers (audiences) interact. By comparing the thematic supply of creators
with the demand expressed in audience engagement, we identify persistent
mismatches between producer offerings and consumer preferences. Our
longitudinal analysis further reveals that temporal dynamics exert a stronger
influence on consumer engagement than thematic content, suggesting that when
content is delivered may matter more than what is delivered. These findings
challenge the dominant assumption that content features are the primary drivers
of popularity and highlight the importance of timing and contextual factors in
shaping consumer responses. The results provide new insights into consumer
attention dynamics on digital platforms and carry practical implications for
marketers, platform managers, and content creators seeking to optimize audience
engagement strategies.

</details>


### [292] [Assessing Large Language Models for Structured Medical Order Extraction](https://arxiv.org/abs/2510.10475)
*A H M Rezaul Karim,Ozlem Uzuner*

Main category: cs.CL

TL;DR: 该研究提出了一种使用通用指令微调的大型语言模型（LLaMA-4 17B）来提取医疗指令的方法，无需领域特定微调，仅使用少量示例（few-shot），并在 MEDIQA-OE 2025 共享任务中取得了第五名的成绩，平均 F1 分数为 37.76。


<details>
  <summary>Details</summary>
Motivation: 从电子健康记录、出院总结和医患对话等多种来源中提取结构化医疗指令，以支持临床决策、文档编写和工作流程自动化。

Method: 使用通用、指令微调的 LLaMA-4 17B 模型，并辅以一个 in-context 示例，以提取订单类型、描述、原因和来源。

Result: 在 MEDIQA-OE 2025 共享任务中排名第五，平均 F1 分数为 37.76，在原因和来源准确性方面有所提高。

Conclusion: 大型、非特定领域的语言模型，通过有效的提示工程，可以作为处理特定临床自然语言处理任务的强大且可扩展的基线。

Abstract: Medical order extraction is essential for structuring actionable clinical
information, supporting decision-making, and enabling downstream applications
such as documentation and workflow automation. Orders may be embedded in
diverse sources, including electronic health records, discharge summaries, and
multi-turn doctor-patient dialogues, and can span categories such as
medications, laboratory tests, imaging studies, and follow-up actions. The
MEDIQA-OE 2025 shared task focuses on extracting structured medical orders from
extended conversational transcripts, requiring the identification of order
type, description, reason, and provenance. We present the MasonNLP submission,
which ranked 5th among 17 participating teams with 105 total submissions. Our
approach uses a general-purpose, instruction-tuned LLaMA-4 17B model without
domain-specific fine-tuning, guided by a single in-context example. This
few-shot configuration achieved an average F1 score of 37.76, with notable
improvements in reason and provenance accuracy. These results demonstrate that
large, non-domain-specific LLMs, when paired with effective prompt engineering,
can serve as strong, scalable baselines for specialized clinical NLP tasks.

</details>


### [293] [UltraLLaDA: Scaling the Context Length to 128K for Diffusion Large Language Models](https://arxiv.org/abs/2510.10481)
*Guangxin He,Shen Nie,Fengqi Zhu,Yuankang Zhao,Tianyi Bai,Ran Yan,Jie Fu,Chongxuan Li,Binhang Yuan*

Main category: cs.CL

TL;DR: 本文提出了一种名为UltraLLaDA的扩散语言模型，通过改进RoPE并结合掩码策略，实现了128K的超长上下文窗口，并在长上下文任务上显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有扩散语言模型在长上下文场景下的表现仍有待探索，本文旨在研究如何有效扩展扩散语言模型的上下文窗口。

Method: 本文提出了一种后训练技术，通过修改标准的旋转位置嵌入（RoPE）并结合不同的掩码策略，以适应扩散过程的概率建模特性，从而实现上下文窗口的扩展。在此基础上，构建了UltraLLaDA模型。

Result: UltraLLaDA模型成功实现了128K的上下文窗口，并在长上下文任务的实证评估中，显著优于训练无关的基线模型。实验结果表明，特殊的位置嵌入扩展是扩展扩散语言模型上下文的关键。

Conclusion: 通过对RoPE进行修改和应用掩码策略，可以高效地将扩散语言模型的上下文窗口扩展到128K，且无需从头开始训练。本文为实践者提供了关于如何通过有效的后训练方法实现超长上下文的实用指导。

Abstract: Diffusion LLMs have attracted growing interest, with plenty of recent work
emphasizing their great potential in various downstream tasks; yet the
long-context behavior of diffusion LLMs remains largely uncharted. We present a
case study of post-training techniques for extending the context window of
diffusion LLMs (i.e., LLaDA) without retraining from scratch. We show that a
simple modification to the standard Rotary Positional Embeddings (RoPE)
extension effectively accommodates the probabilistic modeling inherent in the
diffusion process, enabling stable scaling to longer context ranges. We further
compare masking strategies used during post-training and analyze their impact
on optimization stability and long-range recall. Instantiating these insights,
we introduce UltraLLaDA, a diffusion LLM with a 128K-token context window that,
in our empirical evaluation on long-context tasks, significantly outperforms
training-free baselines. Our experimental results highlight the special
positional extension as a key lever for scaling diffusion LLMs to extended
contexts and offer practical guidance for practitioners seeking 128K-scale
context via efficient post-training.

</details>


### [294] [VOLTAGE: A Versatile Contrastive Learning based OCR Methodology for ultra low-resource scripts through Auto Glyph Feature Extraction](https://arxiv.org/abs/2510.10490)
*Prawaal Sharma,Poonam Goyal,Vidisha Sharma,Navneet Goyal*

Main category: cs.CL

TL;DR: UNESCO将全球7000种语言中的2500种列为濒危语言。语言的消亡会导致传统智慧、民间文学以及使用该语言的社群的本质的丧失。因此，必须让这些语言实现数字化，以避免其消亡。低资源语言面临的灭绝风险更大。缺乏针对低资源语言的无监督光学字符识别(OCR)方法是阻碍其数字化的原因之一。我们提出了VOLTAGE——一种基于对比学习的OCR方法，利用自动字形特征推荐进行聚类标签。我们使用图像变换和生成对抗网络来增强数据的多样性和数量。VOLTAGE是使用Takri设计的——一种在16世纪至20世纪在印度喜马拉雅地区使用的书写系统。我们展示了Takri以及其他印度书写系统（低资源和高资源）的结果，以证实该方法论的通用性。在Takri书写系统上，机器打印样本的准确率为95%，手写样本的准确率为87%。我们进行了基线和消融研究，并构建了Takri的下游用例，证明了我们工作的实用性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言面临灭绝风险，而缺乏针对这些语言的无监督OCR方法阻碍了它们的数字化。

Method: 提出VOLTAGE，一种基于对比学习的OCR方法，利用自动字形特征推荐进行聚类标签，并使用图像变换和生成对抗网络来增强数据。

Result: 在Takri书写系统上，机器打印样本的准确率为95%，手写样本的准确率为87%。

Conclusion: VOLTAGE是一种有效的OCR方法，可用于低资源语言的数字化，并具有广泛的适用性。

Abstract: UNESCO has classified 2500 out of 7000 languages spoken worldwide as
endangered. Attrition of a language leads to loss of traditional wisdom, folk
literature, and the essence of the community that uses it. It is therefore
imperative to bring digital inclusion to these languages and avoid its
extinction. Low resource languages are at a greater risk of extinction. Lack of
unsupervised Optical Character Recognition(OCR) methodologies for low resource
languages is one of the reasons impeding their digital inclusion. We propose
VOLTAGE - a contrastive learning based OCR methodology, leveraging auto-glyph
feature recommendation for cluster-based labelling. We augment the labelled
data for diversity and volume using image transformations and Generative
Adversarial Networks. Voltage has been designed using Takri - a family of
scripts used in 16th to 20th century in the Himalayan regions of India. We
present results for Takri along with other Indic scripts (both low and high
resource) to substantiate the universal behavior of the methodology. An
accuracy of 95% for machine printed and 87% for handwritten samples on Takri
script has been achieved. We conduct baseline and ablation studies along with
building downstream use cases for Takri, demonstrating the usefulness of our
work.

</details>


### [295] [Merlin's Whisper: Enabling Efficient Reasoning in LLMs via Black-box Adversarial Prompting](https://arxiv.org/abs/2510.10528)
*Heming Xia,Cunxiao Du,Rui Li,Chak Tou Leong,Yongqi Li,Wenjie Li*

Main category: cs.CL

TL;DR: 通过黑盒对抗性提示，AdvPrompt框架可以减少大型推理模型（LRMs）的响应长度，同时保持其准确性，从而提高LRMs的效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在解决复杂推理任务时存在计算和延迟开销大的问题，阻碍了其实际应用。

Method: 提出了一种名为AdvPrompt的黑盒对抗性提示框架，通过迭代优化生成高质量的对抗性提示，以引导LRMs产生更简洁的响应。

Result: 在多个基准测试中，AdvPrompt在保持性能的同时，显著减少了模型的响应长度。具体而言，在GSM8K简单问题上，Qwen3模型系列的平均响应长度减少了3倍；在四个基准测试中，平均令牌使用量减少了约40%。对于闭源API，Claude-3.7在MATH-500上令牌使用量减少了35%，Gemini-2.5减少了47%。

Conclusion: AdvPrompt在不同模型规模和系列上都表现出良好的泛化能力，表明黑盒提示是一种提高LRM效率的有效策略。

Abstract: Large reasoning models (LRMs) have demonstrated remarkable proficiency in
tackling complex reasoning tasks through step-by-step thinking. However, such a
lengthy reasoning process incurs substantial computational and latency
overheads, hindering the practical deployment of these models. In this work, we
present a new perspective on mitigating overthinking in LRMs via black-box
adversarial prompting. By treating both open-source LRMs and closed-source APIs
as black-box communicators, we investigate how to elicit concise responses
without sacrificing accuracy. We introduce AdvPrompt, an iterative refinement
framework that generates high-quality adversarial prompts from diverse
perspectives. Experiments across multiple benchmarks demonstrate that AdvPrompt
consistently reduces token usage while preserving performance. Notably,
AdvPrompt achieves a 3x reduction in average response length on simple GSM8K
questions for the Qwen3 model series, and delivers an average ~40% token
reduction across four benchmarks. For closed-source APIs, AdvPrompt reduces
token usage on MATH-500 by 35% for Claude-3.7 and 47% for Gemini-2.5. Further
analysis reveals the generalizability of AdvPrompt across various model scales
and families, underscoring the potential of black-box prompting as a practical
and effective strategy for enhancing LRM efficiency.

</details>


### [296] [Mission Impossible: Feedback-Guided Dynamic Interactive Planning for Improving Reasoning on LLMs](https://arxiv.org/abs/2510.05577)
*Dong Yan,Gaochen Wu,Bowen Zhou*

Main category: cs.CL

TL;DR: FGDIP框架通过动态和自适应的信息探索策略，提高了语言模型在开放域多跳推理任务中的表现，并在HotpotQA和StrategyQA数据集上取得了SOTA（State-of-the-art）的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型在处理需要海量信息检索的开放域多跳推理任务时存在不足，因为它们依赖于固定的动作序列。FGDIP旨在通过动态和自适应的策略来增强LLMs的推理能力。

Method: FGDIP框架首先识别与问题相关的关键实体，然后生成推理子节点。该过程通过历史错误分析和实时反馈进行优化，从而动态调整推理策略。框架结合了深度优先搜索和一种新颖的节点生成技术，能够根据先前的错误路径和同一层级的并发节点来适应，从而扩展搜索空间并确保推理过程系统地收敛到准确的解决方案。

Result: FGDIP在HotpotQA数据集上达到了54.47%的F1分数，在StrategyQA数据集上达到了70.05%的F1分数，分别超越了最佳基线5.03%和7.25%。

Conclusion: FGDIP框架有效地提升了语言模型在开放域多跳推理任务中的表现，展示了其在增强语言模型推理能力方面的潜力和通用性。

Abstract: Recent advancements in language agents have led to significant improvements
in multi-hop reasoning tasks. However, existing approaches often struggle with
handling open-domain problems, which require massive information retrieval due
to their reliance on a fixed sequence of actions. To address this, we propose
Feedback-Guided Dynamic Interactive Planning (FGDIP), a novel framework
tailored to enhance reasoning in LLMs by utilizing dynamic and adaptive
strategies for information exploration in open-domain multi-hop reasoning
tasks. Our approach begins by identifying key entities relevant to the problem,
which serve as the initial nodes in the reasoning process. From these initial
nodes, we then generate reasoning child nodes with the process being refined
through a combination of historical error analysis and real-time feedback,
which allows the framework to dynamically adjust and optimize its reasoning
strategies. By integrating depth-first search with an innovative node
generation technique, our framework adapts based on both prior error paths and
concurrently generated nodes at the same hierarchical level. This dynamic
strategy effectively expands the search space while ensuring the reasoning
process systematically converges toward accurate solutions. Experimental
results show that FGDIP achieved up to 54.47% F1 score on the HotpotQA dataset
and 70.05% on the StrategyQA dataset, surpassing the best baseline by 5.03% and
7.25% respectively, highlighting its versatility and potential to enhance
language agents in multi-hop reasoning tasks.

</details>


### [297] [Detecting Hallucinations in Authentic LLM-Human Interactions](https://arxiv.org/abs/2510.10539)
*Yujie Ren,Niklas Gruhlke,Anne Lauscher*

Main category: cs.CL

TL;DR: 本研究提出了首个基于真实大语言模型-人类交互的幻觉检测基准AuthenHallu，解决了现有基准脱离实际的问题。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型幻觉检测基准多为人工构造，未能反映真实世界交互的特点，因此需要一个基于真实交互数据的基准。

Method: 从真实的大语言模型-人类对话中选取并标注样本，构建了AuthenHallu基准，并尝试使用大语言模型本身作为幻觉检测器。

Result: AuthenHallu基准中31.4%的查询-响应对存在幻觉，在数学和数字问题等领域这一比例高达60.0%。同时，研究发现大语言模型作为幻觉检测器的效果尚不理想。

Conclusion: AuthenHallu基准能够更真实地反映大语言模型在日常使用中的幻觉情况，但大语言模型自身作为检测器的能力仍需提升。

Abstract: As large language models (LLMs) are increasingly applied in sensitive domains
such as medicine and law, hallucination detection has become a critical task.
Although numerous benchmarks have been proposed to advance research in this
area, most of them are artificially constructed--either through deliberate
hallucination induction or simulated interactions--rather than derived from
genuine LLM-human dialogues. Consequently, these benchmarks fail to fully
capture the characteristics of hallucinations that occur in real-world usage.
To address this limitation, we introduce AuthenHallu, the first hallucination
detection benchmark built entirely from authentic LLM-human interactions. For
AuthenHallu, we select and annotate samples from genuine LLM-human dialogues,
thereby providing a faithful reflection of how LLMs hallucinate in everyday
user interactions. Statistical analysis shows that hallucinations occur in
31.4% of the query-response pairs in our benchmark, and this proportion
increases dramatically to 60.0% in challenging domains such as Math & Number
Problems. Furthermore, we explore the potential of using vanilla LLMs
themselves as hallucination detectors and find that, despite some promise,
their current performance remains insufficient in real-world scenarios.

</details>


### [298] [BitMar: Low-Bit Multimodal Fusion with Episodic Memory for Edge Devices](https://arxiv.org/abs/2510.10560)
*Euhid Aman,Esteban Carlin,Hsing-Kuo Pao,Giovanni Beltrame,Ghaluh Indah Permata Sari,Yie-Tarng Chen*

Main category: cs.CL

TL;DR: BitMar是一种量化的多模态Transformer，它使用外部的、类似人类的 the episodic memory 来实现有效的图像-文本生成，适用于资源受限的硬件。


<details>
  <summary>Details</summary>
Motivation: 现有的跨注意力Transformer和多模态视觉-语言模型在部署到边缘设备时面临挑战，因为它们需要完整的、全精度的骨干网络。虽然内存增强架构可以利用过去的上下文，但很少与激进的、面向边缘的量化相结合。

Method: BitMar使用1.58位编码器（一个用于文本，一个用于视觉），创建紧凑的嵌入，这些嵌入被组合起来查询固定大小的关键-值 the episodic memory。在向量检索期间，BitNet解码器应用每层条件，以提高生成内容的上下文相关性。解码器还采用注意力汇聚和滑动窗口机制，在内存预算紧张的情况下处理长输入或流式输入。

Result: BitMar的每层条件和滑动窗口注意力相结合，实现了强大的质量-速度权衡，在低延迟和小型模型占用的情况下，提供了有竞争力的图像描述和多模态理解能力。

Conclusion: BitMar的特点使其非常适合边缘部署。

Abstract: Cross-attention transformers and other multimodal vision-language models
excel at grounding and generation; however, their extensive, full-precision
backbones make it challenging to deploy them on edge devices. Memory-augmented
architectures enhance the utilization of past context; however, most works
rarely pair them with aggressive edge-oriented quantization. We introduce
BitMar, a quantized multimodal transformer that proposes an external human-like
episodic memory for effective image-text generation on hardware with limited
resources. BitMar utilizes 1.58-bit encoders, one for text (BitNet-style) and
one for vision (DiNOv2-based), to create compact embeddings that are combined
and used to query a fixed-size key-value episodic memory. During vector
retrieval, the BitNet decoder applies per-layer conditioning, which increases
the contextual relevance of generated content. The decoder also employs
attention sinks with a sliding-window mechanism to process long or streaming
inputs under tight memory budgets. The combination of per-layer conditioning
and sliding-window attention achieves a strong quality-speed trade-off,
delivering competitive captioning and multimodal understanding at low latency
with a small model footprint. These characteristics make BitMar well-suited for
edge deployment.

</details>


### [299] [Dynamic Topic Evolution with Temporal Decay and Attention in Large Language Models](https://arxiv.org/abs/2510.10613)
*Di Wu abd Shuaidong Pan*

Main category: cs.CL

TL;DR: 该研究提出了一种基于时间大语言模型的动态主题演化建模框架。


<details>
  <summary>Details</summary>
Motivation: 现有主题模型在捕捉文本中主题随时间变化的动态性方面存在不足，本研究旨在提供一个能够有效描述主题生成、扩展和衰退过程的系统性解决方案。

Method: 利用大语言模型获取文本的上下文嵌入，并结合时间衰减函数和注意力机制来调整语义单元随时间的重要性，从而捕捉不同时期的主题变化。随后将时间表示映射到潜在主题空间，并使用状态转移矩阵描述主题的动态演化。通过联合优化目标来约束语义建模和时间一致性，以保证主题生成的发散性和平滑性。

Result: 在真实语料库上的实验表明，该框架能够有效地捕捉主题的生成、扩展和衰退，并在多个指标上优于现有模型。

Conclusion: 所提出的框架统一了语义表示和时间演化，提高了主题模型在时间和语义上的相干性、发散性和稳定性，为理解大规模文本中的动态语义模式提供了系统性方法，丰富了主题模型的研究范式，并支持多个领域的复杂文本分析任务。

Abstract: This paper proposes a modeling framework for dynamic topic evolution based on
temporal large language models. The method first uses a large language model to
obtain contextual embeddings of text and then introduces a temporal decay
function and an attention mechanism. These components allow the model to adjust
the importance of semantic units according to time intervals and capture topic
variations across different periods. The temporal representations are then
mapped into a latent topic space, where a state transition matrix is applied to
describe the dynamic evolution of topics. A joint optimization objective
constrains both semantic modeling and temporal consistency, ensuring diversity
and smoothness in topic generation. The design emphasizes the unified modeling
of semantic representation and temporal evolution, which improves topic
coherence and diversity while enhancing stability and interpretability over
time. Experiments on real-world corpora show that the framework effectively
captures the generation, expansion, and decline of topics and outperforms
existing models across multiple metrics. Overall, the proposed method provides
a systematic solution for understanding dynamic semantic patterns in
large-scale text, enriches the research paradigm of topic modeling, and
supports complex text analysis tasks in multiple domains.

</details>


### [300] [Preserving LLM Capabilities through Calibration Data Curation: From Analysis to Optimization](https://arxiv.org/abs/2510.10618)
*Bowei He,Lihao Yin,Huiling Zhen,Shuqi Liu,Han Wu,Xiaokun Zhang,Mingxuan Yuan,Chen Ma*

Main category: cs.CL

TL;DR: 校准数据对压缩后的大型语言模型（LLM）能力有重要影响，特别是在复杂的推理任务上。本研究提出了一个基于激活模式分析的校准数据策选框架，以提高压缩LLM的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对校准数据如何影响压缩后的大型语言模型（LLM）能力的研究不足，特别是在不同LLM能力方面，如组合特性和领域对应性。本研究旨在弥合这一差距，并从激活模式的角度分析潜在的影响机制。

Method: 本研究通过分析校准数据对高层复杂推理能力（如数学问题解决和代码生成）的影响，并从激活模式的角度深入研究潜在的影响机制。最后，提出一个基于这些观察和分析的校准数据策选框架。

Result: 研究发现，激活空间中的代表性和多样性从根本上决定了校准数据的质量。所提出的校准数据策选框架能够增强现有模型压缩方法在保持关键LLM能力方面的性能。

Conclusion: 校准数据的代表性和多样性对于在压缩过程中保持LLM的关键能力至关重要。本研究提出的校准数据策选框架可以提高压缩LLM在复杂推理任务上的性能。

Abstract: Post-training compression has been a widely employed approach to scale down
large language model (LLM) and facilitate efficient inference. In various
proposed compression methods, including pruning and quantization, calibration
data plays a vital role by informing the weight importance and activation
dynamic ranges. However, how calibration data impacts the LLM capability after
compression is less explored. Few of the existing works, though recognizing the
significance of this study, only investigate the language modeling or
commonsense reasoning performance degradation from limited angles, like the
data sources or sample amounts. More systematic research is still needed to
examine the impacts on different LLM capabilities in terms of compositional
properties and domain correspondence of calibration data. In this work, we aim
at bridging this gap and further analyze underlying influencing mechanisms from
the activation pattern perspective. Especially, we explore the calibration
data's impacts on high-level complex reasoning capabilities, like math problem
solving and code generation. Delving into the underlying mechanism, we find
that the representativeness and diversity in activation space more
fundamentally determine the quality of calibration data. Finally, we propose a
calibration data curation framework based on such observations and analysis,
enhancing the performance of existing post-training compression methods on
preserving critical LLM capabilities. Our code is provided in
\href{https://github.com/BokwaiHo/COLA.git}{Link}.

</details>


### [301] [FactAppeal: Identifying Epistemic Factual Appeals in News Media](https://arxiv.org/abs/2510.10627)
*Guy Mor-Lan,Tamir Sheafer,Shaul R. Shenhav*

Main category: cs.CL

TL;DR: 该研究提出了新的“认知诉求识别”任务，并发布了一个名为FactAppeal的标注数据集，旨在识别事实陈述如何通过外部来源或证据来支持其可信度。


<details>
  <summary>Details</summary>
Motivation: 识别事实陈述的可信度是如何通过外部来源或证据来建立的，这是一个新的研究领域，现有的资源主要集中在声明检测和验证上，未能捕捉支撑这些声明的细微认知结构和证据基础。

Method: 构建了一个包含3226个英文新闻句子的人工标注数据集FactAppeal，其中包含事实陈述和所依赖的来源的跨度级别标注。标注细化了诸如来源类型（例如，积极参与者、目击者、专家、直接证据）、是否提及来源名称、来源的角色和认知凭证、通过直接或间接引用进行归因等特征。利用2B-9B参数范围内的多种编码器模型和生成解码器模型对该任务进行了建模。

Result: 基于Gemma 2 9B模型，在FactAppeal数据集上实现了0.73的宏观F1分数。

Conclusion: 认知诉求识别任务是识别事实陈述可信度的新方向，FactAppeal数据集和提出的模型为该领域的研究奠定了基础。

Abstract: How is a factual claim made credible? We propose the novel task of Epistemic
Appeal Identification, which identifies whether and how factual statements have
been anchored by external sources or evidence. To advance research on this
task, we present FactAppeal, a manually annotated dataset of 3,226
English-language news sentences. Unlike prior resources that focus solely on
claim detection and verification, FactAppeal identifies the nuanced epistemic
structures and evidentiary basis underlying these claims and used to support
them. FactAppeal contains span-level annotations which identify factual
statements and mentions of sources on which they rely. Moreover, the
annotations include fine-grained characteristics of factual appeals such as the
type of source (e.g. Active Participant, Witness, Expert, Direct Evidence),
whether it is mentioned by name, mentions of the source's role and epistemic
credentials, attribution to the source via direct or indirect quotation, and
other features. We model the task with a range of encoder models and generative
decoder models in the 2B-9B parameter range. Our best performing model, based
on Gemma 2 9B, achieves a macro-F1 score of 0.73.

</details>


### [302] [You're Not Gonna Believe This: A Computational Analysis of Factual Appeals and Sourcing in Partisan News](https://arxiv.org/abs/2510.10658)
*Guy Mor-Lan,Tamir Sheafer,Shaul R. Shenhav*

Main category: cs.CL

TL;DR: CNN在事实陈述和引用来源方面优于Fox News，CNN倾向于引用专家和官方文件，而Fox News倾向于引用新闻报道和直接引语。


<details>
  <summary>Details</summary>
Motivation: 媒体偏见已被广泛研究，但事实报道背后的认识论策略在计算上仍未得到充分探索。

Method: 通过大规模比较CNN和Fox News，采用文章匹配策略比较同一事件的报道，并应用FactAppeal框架分析涵盖COVID-19大流行和以色列-哈马斯战争这两个高度政治化时期的470K多篇文章。

Result: CNN的报道包含更多事实陈述，并且更有可能以外部来源为依据。CNN倾向于引用专家和官方文件，而Fox News倾向于引用新闻报道和直接引语。

Conclusion: 量化了党派媒体如何使用系统上不同的认识论策略来构建现实，为媒体偏见研究增加了新的维度。

Abstract: While media bias is widely studied, the epistemic strategies behind factual
reporting remain computationally underexplored. This paper analyzes these
strategies through a large-scale comparison of CNN and Fox News. To isolate
reporting style from topic selection, we employ an article matching strategy to
compare reports on the same events and apply the FactAppeal framework to a
corpus of over 470K articles covering two highly politicized periods: the
COVID-19 pandemic and the Israel-Hamas war. We find that CNN's reporting
contains more factual statements and is more likely to ground them in external
sources. The outlets also exhibit sharply divergent sourcing patterns: CNN
builds credibility by citing Experts} and Expert Documents, constructing an
appeal to formal authority, whereas Fox News favors News Reports and direct
quotations. This work quantifies how partisan outlets use systematically
different epistemic strategies to construct reality, adding a new dimension to
the study of media bias.

</details>


### [303] [AGENTIQL: An Agent-Inspired Multi-Expert Framework for Text-to-SQL Generation](https://arxiv.org/abs/2510.10661)
*Omid Reza Heidari,Siobhan Reid,Yassine Yaakoubi*

Main category: cs.CL

TL;DR: AGENTIQL是一个多专家框架，通过问题分解、子查询生成和列选择来改进文本到SQL的生成，在Spider基准测试中达到了86.07%的准确率。


<details>
  <summary>Details</summary>
Motivation: 单一的文本到SQL模型在处理复杂推理和模式多样性时存在不足。

Method: 提出AGENTIQL，一个结合了推理代理（用于问题分解）、编码代理（用于子查询生成）和后处理步骤（用于列选择）的多专家框架。通过自适应路由器选择模块化管道或基线解析器。

Result: 在Spider基准测试中，AGENTIQL的执行准确率提高了14B模型，达到86.07% EX，并提高了可解释性。

Conclusion: AGENTIQL通过其模块化、可扩展和可解释的方法，在不使用GPT-4的情况下，缩小了与最先进模型在文本到SQL生成方面的差距。

Abstract: LLMs have advanced text-to-SQL generation, yet monolithic architectures
struggle with complex reasoning and schema diversity. We propose AGENTIQL, an
agent-inspired multi-expert framework that combines a reasoning agent for
question decomposition, a coding agent for sub-query generation, and a
refinement step for column selection. An adaptive router further balances
efficiency and accuracy by selecting between our modular pipeline and a
baseline parser. Several steps in the pipeline can be executed in parallel,
making the framework scalable to larger workloads. Evaluated on the Spider
benchmark, AGENTIQL improves execution accuracy and interpretability and
achieves up to 86.07\% EX with 14B models using the Planner&Executor merging
strategy. The attained performance is contingent upon the efficacy of the
routing mechanism, thereby narrowing the gap to GPT-4-based SOTA (89.65% EX)
while using much smaller open-source LLMs. Beyond accuracy, AGENTIQL enhances
transparency by exposing intermediate reasoning steps, offering a robust,
scalable, and interpretable approach to semantic parsing.

</details>


### [304] [BrowserAgent: Building Web Agents with Human-Inspired Web Browsing Actions](https://arxiv.org/abs/2510.10666)
*Zhengbo Zhang,Zhiheng Lyu,Junhao Gong,Hongzhu Yi,Xinming Wang,Yuxuan Zhou,Jiabing Yang,Ping Nie,Yan Huang,Wenhu Chen*

Main category: cs.CL

TL;DR: BrowserAgent通过模仿人类浏览行为，直接与原始网页交互，并采用SFT和RFT两阶段训练，在Open-QA任务上取得了有竞争力的结果，并在多步推理任务上显著优于Search-R1。


<details>
  <summary>Details</summary>
Motivation: 现有研究在解决网络任务时过度依赖将动态网页转为静态文本的工具，而忽略了人类浏览时如滚动、点击、输入等多样化交互。然而，高效解决现实世界问题需要LLM与动态网络环境的交互和自主获取外部信息的能力。

Method: 提出BrowserAgent，一个通过Playwright直接在原始网页上进行预定义浏览器操作（如滚动、点击、输入）来解决复杂任务的代理。采用监督微调（SFT）和拒绝微调（RFT）两阶段训练策略，并引入显式记忆机制来存储关键信息，以增强模型在长时任务中的推理能力。

Result: BrowserAgent在Open-QA任务上取得了比Search-R1更有竞争力的结果，尽管使用的训练数据量显著减少。在多步问答任务（如HotpotQA、2Wiki和Bamboogle）上，BrowserAgent-7B相比Search-R1取得了约20%的提升。

Conclusion: BrowserAgent提供了一个更先进的框架，能够实现更具交互性和可扩展性的网络代理，通过模拟人类浏览行为和利用显式记忆，能更有效地解决复杂任务。

Abstract: Efficiently solving real-world problems with LLMs increasingly hinges on
their ability to interact with dynamic web environments and autonomously
acquire external information. While recent research like Search-R1 and
WebDancer demonstrates strong performance in solving web tasks, they heavily
rely on additional tools to convert the interactive web environment into static
text content. This is in contrast to human browsing behaviors, which involve
diverse interactions with the browser, such as scrolling, clicking, and typing.
In this paper, we propose BrowserAgent, a more interactive agent that solves
complex tasks through human-inspired browser actions. BrowserAgent operates
directly on raw web pages via Playwright through a set of predefined browser
actions. We adopt a two-stage training (Supervised Fine-Tuning (SFT) and
Rejection Fine-Tuning (RFT)) to improve the model's generalization abilities.
Despite using significantly less training data than Search-R1, BrowserAgent
achieves more competitive results across different Open-QA tasks. Additionally,
we introduce an explicit memory mechanism to store key conclusions across
steps, further enhancing the model's reasoning capabilities for long-horizon
tasks. Notably, BrowserAgent-7B can achieve around 20\% improvement over
Search-R1 on multi-hop QA tasks like HotpotQA, 2Wiki, and Bamboogle. These
results indicate that BrowserAgent can serve as a more advanced framework for
more interactive and scalable web agents.

</details>


### [305] [Unlocking LLM Safeguards for Low-Resource Languages via Reasoning and Alignment with Minimal Training Data](https://arxiv.org/abs/2510.10677)
*Zhuowei Chen,Bowei Zhang,Nankai Lin,Tian Hou,Lianxi Wang*

Main category: cs.CL

TL;DR: ConsistentGuard是一种新的基于推理的多语言安全模型，通过推理增强可解释性，通过对齐促进语言间的知识转移，在低资源语言上表现优于基于分类器的方法。


<details>
  <summary>Details</summary>
Motivation: 需要有效的LLM安全措施来检测恶意查询，现有方法在可解释性和低资源语言方面存在不足。

Method: 提出了一种名为ConsistentGuard的新型基于推理的多语言安全模型，该模型通过推理增强可解释性，通过对齐促进语言间的知识转移。

Result: 该模型在六种语言的三个数据集上表现优于使用更多数据训练的更大模型，并且具有很强的可解释性和泛化能力，仅使用了1000个训练样本。

Conclusion: ConsistentGuard在提高LLM安全性方面取得了显著效果，尤其是在低资源语言和需要可解释性的场景下，并为未来的研究贡献了一个多语言基准和代码。

Abstract: Recent advances in LLMs have enhanced AI capabilities, but also increased the
risk posed by malicious requests, highlighting the need for effective LLM
safeguards to detect such queries. Existing approaches largely rely on
classifier-based methods that lack interpretability and perform poorly on
low-resource languages. To address these limitations, we propose
ConsistentGuard, a novel reasoning-based multilingual safeguard, which enhances
explainability via reasoning and boosts knowledge transfer between languages
through alignment. With only 1,000 training samples, our method demonstrates
superior performance on three datasets across six languages, outperforming
larger models trained with significantly more data, and exhibits strong
interpretability and generalization ability. We also contribute a multilingual
benchmark extension and release our codes to support future research.

</details>


### [306] [RePro: Training Language Models to Faithfully Recycle the Web for Pretraining](https://arxiv.org/abs/2510.10681)
*Zichun Yu,Chenyan Xiong*

Main category: cs.CL

TL;DR: RePro是一种创新的网页数据循环利用方法，通过训练一个小型语言模型（LM）来生成高质量、语义忠实的数据副本，从而解决大型语言模型（LLM）预训练数据不足的问题。实验证明，RePro在下游任务的准确性上显著优于仅使用原始数据的方法，并且在数据效率方面表现出色，能够将原始数据效率提升2-3倍。


<details>
  <summary>Details</summary>
Motivation: 高质量的预训练数据是大型语言模型（LLM）的关键，但目前高质量数据的储备正在枯竭，尤其对于前沿模型而言。因此，需要一种有效的方法来扩展预训练数据集。

Method: RePro方法训练一个相对较小的LM，利用强化学习来生成预训练数据的有效且忠实的重述。具体来说，设计了一个质量奖励和三个忠实度奖励，以优化LM重述器，使其能够将原始数据转换为高质量的重述，同时保持其核心语义和结构。实验中，训练了一个40亿参数的重述器来处理720亿个来自DCLM-RefinedWeb的数据样本。

Result: 在4亿和14亿参数的模型预训练实验中，RePro在22个下游任务上的相对准确性比仅使用原始数据的基线模型提高了4.7%-14.0%。RePro的表现优于最先进的网页数据循环利用方法ReWire（该方法使用一个700亿参数的重述器），并且在数据池大小是其4倍的原始数据基线之上。此外，RePro将原始数据效率提高了2-3倍。分析表明，RePro比基于提示的方法能保留更多关键信息，并更忠实地反映原始数据的特征。

Conclusion: RePro提供了一种高效且可控的途径，能够有效地利用LLM预训练所需的“燃料”（即高质量数据）。该方法通过生成高质量、语义忠实的数据副本，有效解决了预训练数据不足的问题，并在多个下游任务中展现出优越的性能和数据效率。

Abstract: High-quality pretraining data is the fossil fuel of large language models
(LLMs), yet its reserves are running low for frontier models. In this paper, we
introduce RePro, a novel web recycling method that trains a relatively small LM
with reinforcement learning to generate effective and faithful rephrasings of
pretraining data. Specifically, we design one quality reward and three
faithfulness rewards, optimizing the LM rephraser to convert organic data into
high-quality rephrasings while maintaining its core semantics and structure. In
our experiment, we train a 4B rephraser to recycle 72B tokens sampled from
DCLM-RefinedWeb. Pretraining results on 400M and 1.4B models demonstrate that
RePro delivers 4.7%-14.0% relative accuracy gains over organic-only baseline on
22 downstream tasks. RePro also outperforms ReWire, the state-of-the-art web
recycling method that prompts a 70B rephraser, as well as the organic baseline
with a 4x larger data pool. Experiments with different amounts of recycled data
highlight that RePro improves organic data efficiency by 2-3x. Individual and
distributional analyses validate that RePro preserves more critical information
and faithfully reflects the characteristics of organic data compared to
prompting-based methods. Together, these results show that RePro provides an
efficient and controllable path to effectively harness the fossil fuel of LLM
pretraining. We open-source our code, rephraser, and recycled data at
https://github.com/cxcscmu/RePro.

</details>


### [307] [Sarcasm Detection Using Deep Convolutional Neural Networks: A Modular Deep Learning Framework](https://arxiv.org/abs/2510.10729)
*Manas Zambre,Sarika Bobade*

Main category: cs.CL

TL;DR: 该论文提出了一个模块化的深度学习框架，用于通过结合DCNNs和BERT等模型来检测文本中的讽刺意味，以分析语言、情感和上下文线索。


<details>
  <summary>Details</summary>
Motivation: 鉴于讽刺在文本中常常被误解，论文旨在开发一种更准确的讽刺检测方法。

Method: 该方法利用深度卷积神经网络（DCNN）和BERT等上下文模型，通过整合情感分析、上下文嵌入、语言特征提取和情感检测的多层架构来分析。

Result: 该模型仍处于概念阶段，但证明了其在聊天机器人和社交媒体分析等实际应用中的可行性。

Conclusion: 该模块化深度学习框架为文本讽刺检测提供了一个有前景的方法，并具有实际应用潜力。

Abstract: Sarcasm is a nuanced and often misinterpreted form of communication,
especially in text, where tone and body language are absent. This paper
proposes a modular deep learning framework for sarcasm detection, leveraging
Deep Convolutional Neural Networks (DCNNs) and contextual models such as BERT
to analyze linguistic, emotional, and contextual cues. The system integrates
sentiment analysis, contextual embeddings, linguistic feature extraction, and
emotion detection through a multi-layer architecture. While the model is in the
conceptual stage, it demonstrates feasibility for real-world applications such
as chatbots and social media analysis.

</details>


### [308] [Large Language Models for Full-Text Methods Assessment: A Case Study on Mediation Analysis](https://arxiv.org/abs/2510.10762)
*Wenqing Zhang,Trang Nguyen,Elizabeth A. Stuart,Yiqun T. Chen*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在评估科学论文方法学方面表现接近人类，尤其擅长识别明确的标准，但在处理复杂、需要推理的评估时准确性会下降，并且可能被表面语言线索误导。


<details>
  <summary>Details</summary>
Motivation: 系统性文献回顾在科学证据合成中至关重要，但手动提取方法学信息劳动密集。本研究旨在探索利用大型语言模型（LLMs）自动化方法学评估的可行性，以期革新证据合成过程。

Method: 研究人员利用因果中介分析作为代表性的方法学领域，在180篇全文本科学文章中，对最先进的大型语言模型（LLMs）和专家评审员进行了基准测试和性能比较。

Result: 在评估标准化的方法学信息方面，LLMs的性能与人类评审员高度相关（准确性相关性为0.71，F1分数相关性为0.97），在处理简单、明确陈述的方法学标准时达到了接近人类的准确性。然而，在处理复杂、需要推理的评估时，LLMs的准确性显著下降，比专家评审员低15%。模型常因过度依赖表面语言线索而出错，例如将“纵向”或“敏感性”等关键词误解为严谨方法学的证据，导致系统性错误分类。处理更长的文档会降低模型准确性，而发表年份则无显著影响。

Conclusion: 尽管当前的大型语言模型在识别明确的方法学特征方面表现出色，但在进行细微的解释和推理时仍需要人类监督。将自动化信息提取与有针对性的专家评审相结合，为提高证据合成的效率和方法学严谨性提供了一个有前景的途径。

Abstract: Systematic reviews are crucial for synthesizing scientific evidence but
remain labor-intensive, especially when extracting detailed methodological
information. Large language models (LLMs) offer potential for automating
methodological assessments, promising to transform evidence synthesis. Here,
using causal mediation analysis as a representative methodological domain, we
benchmarked state-of-the-art LLMs against expert human reviewers across 180
full-text scientific articles. Model performance closely correlated with human
judgments (accuracy correlation 0.71; F1 correlation 0.97), achieving
near-human accuracy on straightforward, explicitly stated methodological
criteria. However, accuracy sharply declined on complex, inference-intensive
assessments, lagging expert reviewers by up to 15%. Errors commonly resulted
from superficial linguistic cues -- for instance, models frequently
misinterpreted keywords like "longitudinal" or "sensitivity" as automatic
evidence of rigorous methodological approache, leading to systematic
misclassifications. Longer documents yielded lower model accuracy, whereas
publication year showed no significant effect. Our findings highlight an
important pattern for practitioners using LLMs for methods review and synthesis
from full texts: current LLMs excel at identifying explicit methodological
features but require human oversight for nuanced interpretations. Integrating
automated information extraction with targeted expert review thus provides a
promising approach to enhance efficiency and methodological rigor in evidence
synthesis across diverse scientific fields.

</details>


### [309] [HiligayNER: A Baseline Named Entity Recognition Model for Hiligaynon](https://arxiv.org/abs/2510.10776)
*James Ald Teves,Ray Daniel Cal,Josh Magdiel Villaluz,Jean Malolos,Mico Magtira,Ramon Rodriguez,Mideth Abisado,Joseph Marvin Imperial*

Main category: cs.CL

TL;DR: 本研究介绍了HiligayNER，这是首个用于西班牙语命名实体识别（NER）的公开可用基线模型，旨在解决西班牙语在语言处理研究中代表性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 西班牙语在语言处理研究中代表性不足，缺乏标注语料库和基线模型。

Method: 收集了8000多条标注句子，用于构建HiligayNER模型，并对mBERT和XLM-RoBERTa两个Transformer模型进行了微调。

Result: 两种微调模型的准确率、召回率和F1分数均超过80%，在跨语言评估中表现出良好的迁移性。

Conclusion: HiligayNER的开发旨在促进代表性不足的菲律宾语言（特别是西班牙语）的语言技术发展，并支持未来区域语言处理的研究。

Abstract: The language of Hiligaynon, spoken predominantly by the people of Panay
Island, Negros Occidental, and Soccsksargen in the Philippines, remains
underrepresented in language processing research due to the absence of
annotated corpora and baseline models. This study introduces HiligayNER, the
first publicly available baseline model for the task of Named Entity
Recognition (NER) in Hiligaynon. The dataset used to build HiligayNER contains
over 8,000 annotated sentences collected from publicly available news articles,
social media posts, and literary texts. Two Transformer-based models, mBERT and
XLM-RoBERTa, were fine-tuned on this collected corpus to build versions of
HiligayNER. Evaluation results show strong performance, with both models
achieving over 80% in precision, recall, and F1-score across entity types.
Furthermore, cross-lingual evaluation with Cebuano and Tagalog demonstrates
promising transferability, suggesting the broader applicability of HiligayNER
for multilingual NLP in low-resource settings. This work aims to contribute to
language technology development for underrepresented Philippine languages,
specifically for Hiligaynon, and support future research in regional language
processing.

</details>


### [310] [Review of Inference-Time Scaling Strategies: Reasoning, Search and RAG](https://arxiv.org/abs/2510.10787)
*Zhichao Wang,Cheng Wan,Dong Nie*

Main category: cs.CL

TL;DR: LLM性能提升正从训练时扩展转向推理时扩展，重点是数据可用性下降。推理时扩展技术包括输出聚焦（如推理、搜索、RAG）和输入聚焦（如少样本、RAG）。


<details>
  <summary>Details</summary>
Motivation: 数据可用性下降导致LLM性能提升遇到瓶颈，研究重点转向推理时扩展。

Method: 对LLM的推理时扩展技术进行系统性调查，并将其分为输出聚焦和输入聚焦两大类。输出聚焦包括多步生成策略（如推理、搜索、模型集成），输入聚焦主要包括少样本和检索增强生成（RAG）。

Result: 对输出聚焦（如CoT, ToT, ReAct, MCTS, beam search, RLVR, GRPO）和输入聚焦（少样本, RAG）的LLM推理时扩展技术进行了分类和总结。RAG部分进一步细化了查询扩展、数据、检索、重排、生成方法和多模态RAG。

Conclusion: LLM性能提升的趋势已从训练时扩展转向推理时扩展，以应对高质量训练数据日益减少的挑战。推理时扩展技术，特别是检索增强生成（RAG），是未来研究的重要方向。

Abstract: The performance gains of LLMs have historically been driven by scaling up
model size and training data. However, the rapidly diminishing availability of
high-quality training data is introducing a fundamental bottleneck, shifting
the focus of research toward inference-time scaling. This paradigm uses
additional computation at the time of deployment to substantially improve LLM
performance on downstream tasks without costly model re-training. This review
systematically surveys the diverse techniques contributing to this new era of
inference-time scaling, organizing the rapidly evolving field into two
comprehensive perspectives: Output-focused and Input-focused methods.
Output-focused techniques encompass complex, multi-step generation strategies,
including reasoning (e.g., CoT, ToT, ReAct), various search and decoding
methods (e.g., MCTS, beam search), training for long CoT (e.g., RLVR, GRPO),
and model ensemble methods. Input-focused techniques are primarily categorized
by few-shot and RAG, with RAG as the central focus. The RAG section is further
detailed through a structured examination of query expansion, data, retrieval
and reranker, LLM generation methods, and multi-modal RAG.

</details>


### [311] [Toward Human-Centered Readability Evaluation](https://arxiv.org/abs/2510.10801)
*Bahar İlgen,Georges Hattab*

Main category: cs.CL

TL;DR: 现有的文本简化评估指标（如BLEU、FKGL、SARI）主要关注表面特征，无法评估健康信息的清晰度、可信度、语气、文化相关性和可操作性等以人为本的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的文本简化评估指标（如BLEU、FKGL、SARI）无法评估健康信息以人为本的质量，这在高风险的健康领域尤为关键，因为沟通不仅需要简单，还需要可用、尊重和可信。

Method: 提出以人为本的可读性评分（HCRS）框架，该框架结合了自动测量和结构化的人工反馈，以捕捉可读性的关系和背景方面，并概述了该框架，讨论了其在参与式评估工作流程中的整合，并提出了经验验证的协议。

Result: 该研究提出了以人为本的可读性评分（HCRS）框架，以解决现有文本简化评估指标的局限性。

Conclusion: 这项工作旨在推动健康文本简化评估超越表面指标，从而能够开发出更符合多元化用户需求、期望和生活经验的自然语言处理系统。

Abstract: Text simplification is essential for making public health information
accessible to diverse populations, including those with limited health
literacy. However, commonly used evaluation metrics in Natural Language
Processing (NLP), such as BLEU, FKGL, and SARI, mainly capture surface-level
features and fail to account for human-centered qualities like clarity,
trustworthiness, tone, cultural relevance, and actionability. This limitation
is particularly critical in high-stakes health contexts, where communication
must be not only simple but also usable, respectful, and trustworthy. To
address this gap, we propose the Human-Centered Readability Score (HCRS), a
five-dimensional evaluation framework grounded in Human-Computer Interaction
(HCI) and health communication research. HCRS integrates automatic measures
with structured human feedback to capture the relational and contextual aspects
of readability. We outline the framework, discuss its integration into
participatory evaluation workflows, and present a protocol for empirical
validation. This work aims to advance the evaluation of health text
simplification beyond surface metrics, enabling NLP systems that align more
closely with diverse users' needs, expectations, and lived experiences.

</details>


### [312] [Is Implicit Knowledge Enough for LLMs? A RAG Approach for Tree-based Structures](https://arxiv.org/abs/2510.10806)
*Mihir Gupte,Paolo Giusto,Ramesh S*

Main category: cs.CL

TL;DR: LLMs擅长基于其上下文中的信息生成响应。虽然此功能可用于与代码文件等结构化数据进行交互，但另一种流行的方法检索增强生成（RAG）会检索相关文档来增强模型的上下文学习。然而，如何最好地为结构化数据（特别是像树一样的分层结构）生成响应来表示这种检索到的知识，这一点尚未得到充分探索。在这项工作中，我们提出一种新颖的自下而上方法，通过在每个层次级别生成隐式、聚合的摘要来线性化来自树状结构（如 GitHub 存储库）的知识。这种方法使知识能够存储在知识库中并直接与 RAG 一起使用。然后，我们将我们的方法与在原始、非结构化代码上使用 RAG 进行比较，评估生成响应的准确性和质量。我们的结果表明，虽然两种方法的响应质量相当，但我们的方法在检索器中生成的文档数量减少了 68% 以上，效率得到了显著提高。这一发现表明，利用隐式、线性化的知识可能是处理复杂、分层数据结构的非常有效且可扩展的策略。


<details>
  <summary>Details</summary>
Motivation: 尚不清楚如何最好地为结构化数据（特别是像树一样的分层结构）生成响应来表示这种检索到的知识。

Method: 提出一种新颖的自下而上方法，通过在每个层次级别生成隐式、聚合的摘要来线性化来自树状结构（如 GitHub 存储库）的知识。该方法使知识能够存储在知识库中并直接与 RAG 一起使用。然后，将该方法与在原始、非结构化代码上使用 RAG 进行比较。

Result: 与在原始、非结构化代码上使用 RAG 相比，所提出的方法在检索器中生成的文档数量减少了 68% 以上，效率得到了显著提高，而响应质量相当。

Conclusion: 利用隐式、线性化的知识可能是处理复杂、分层数据结构的非常有效且可扩展的策略。

Abstract: Large Language Models (LLMs) are adept at generating responses based on
information within their context. While this ability is useful for interacting
with structured data like code files, another popular method,
Retrieval-Augmented Generation (RAG), retrieves relevant documents to augment
the model's in-context learning. However, it is not well-explored how to best
represent this retrieved knowledge for generating responses on structured data,
particularly hierarchical structures like trees. In this work, we propose a
novel bottom-up method to linearize knowledge from tree-like structures (like a
GitHub repository) by generating implicit, aggregated summaries at each
hierarchical level. This approach enables the knowledge to be stored in a
knowledge base and used directly with RAG. We then compare our method to using
RAG on raw, unstructured code, evaluating the accuracy and quality of the
generated responses. Our results show that while response quality is comparable
across both methods, our approach generates over 68% fewer documents in the
retriever, a significant gain in efficiency. This finding suggests that
leveraging implicit, linearized knowledge may be a highly effective and
scalable strategy for handling complex, hierarchical data structures.

</details>


### [313] [Happiness is Sharing a Vocabulary: A Study of Transliteration Methods](https://arxiv.org/abs/2510.10827)
*Haeji Jung,Jinju Kim,Kyungjin Kim,Youjeong Roh,David R. Mortensen*

Main category: cs.CL

TL;DR: 共享字符、词汇和语音有助于提高多语言模型的性能，其中罗马化在大多数评估中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究共享字符、词汇和语音对多语言模型性能的贡献程度。

Method: 通过三种转写（罗马化、语音转写和替换密码）以及拼写法进行对照实验，并在命名实体识别（NER）和自然语言推断（NLI）两个下游任务上进行评估。

Result: 罗马化在8个评估设置中的7个中表现优于其他输入类型，支持了其最有效方法的假设。模型还发现，与预训练语言共享更长的（子词）词元可以更好地利用模型。

Conclusion: 共享字符、词汇和语音在多语言模型中发挥着重要作用，其中罗马化被证明是一种特别有效的方法，这可能归因于其能够促进更长的共享（子词）词元，从而更好地利用预训练模型。

Abstract: Transliteration has emerged as a promising means to bridge the gap between
various languages in multilingual NLP, showing promising results especially for
languages using non-Latin scripts. We investigate the degree to which shared
script, overlapping token vocabularies, and shared phonology contribute to
performance of multilingual models. To this end, we conduct controlled
experiments using three kinds of transliteration (romanization, phonemic
transcription, and substitution ciphers) as well as orthography. We evaluate
each model on two downstream tasks -- named entity recognition (NER) and
natural language inference (NLI) -- and find that romanization significantly
outperforms other input types in 7 out of 8 evaluation settings, largely
consistent with our hypothesis that it is the most effective approach. We
further analyze how each factor contributed to the success, and suggest that
having longer (subword) tokens shared with pre-trained languages leads to
better utilization of the model.

</details>


### [314] [DUAL-Bench: Measuring Over-Refusal and Robustness in Vision-Language Models](https://arxiv.org/abs/2510.10846)
*Kaixuan Ren,Preslav Nakov,Usman Naseem*

Main category: cs.CL

TL;DR: DUAL-Bench 是首个专注于视觉语言模型 (VLM) 过度拒绝和安全完成的多模态基准，旨在解决安全机制导致的过度拒绝问题，并评估模型在处理包含有害内容的良性请求方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的安全机制可能导致 VLM 过度拒绝良性请求，并且缺乏专门针对视觉模态的过度拒绝基准。特别是在指令良性但图像有害的双重用途场景下，模型常失败，需要更细粒度的对齐。

Method: 提出 DUAL-Bench，首个关注 VLM 过度拒绝和安全完成的多模态基准。评估了 18 个 VLM 在 12 个危害类别下的表现，并特别关注了模型在语义不变的视觉扰动下的鲁棒性。

Result: 在 DUAL-Bench 基准测试中，GPT-5-Nano 的安全完成率为 12.9%，GPT-5 模型的平均完成率为 7.9%，而 Qwen 模型的平均完成率仅为 3.9%，表明 VLM 在安全完成方面存在显著的改进空间。

Conclusion: DUAL-Bench 的发布旨在推动更细致的对齐策略发展，以确保 VLM 在复杂的多模态场景下既安全又实用。

Abstract: As vision-language models become increasingly capable, maintaining a balance
between safety and usefulness remains a central challenge. Safety mechanisms,
while essential, can backfire, causing over-refusal, where models decline
benign requests out of excessive caution. Yet, no existing benchmark has
systematically addressed over-refusal in the visual modality. This setting
introduces unique challenges, such as dual-use cases where an instruction is
harmless, but the accompanying image contains harmful content. Models
frequently fail in such scenarios, either refusing too conservatively or
completing tasks unsafely, which highlights the need for more fine-grained
alignment. The ideal behavior is safe completion, i.e., fulfilling the benign
parts of a request while explicitly warning about any potentially harmful
elements. To address this, we present DUAL-Bench, the first multimodal
benchmark focused on over-refusal and safe completion in VLMs. We evaluated 18
VLMs across 12 hazard categories, with focus on their robustness under
semantics-preserving visual perturbations. The results reveal substantial room
for improvement: GPT-5-Nano achieves 12.9% safe completion, GPT-5 models
average 7.9%, and Qwen models only 3.9%. We hope that DUAL-Bench will foster
the development of more nuanced alignment strategies that ensure models remain
both safe and useful in complex multimodal settings.

</details>


### [315] [Rethinking Agentic Workflows: Evaluating Inference-Based Test-Time Scaling Strategies in Text2SQL Tasks](https://arxiv.org/abs/2510.10885)
*Jiajing Guo,Kenil Patel,Jorge Piazentin Ono,Wenbin He,Liu Ren*

Main category: cs.CL

TL;DR: 现有的光鲜亮丽的Text-to-SQL系统依赖于LLM，但其实际应用和最新推理模型的效果仍不确定。本研究评估了六种面向行业的测试时尺度策略和四种LLM（包括两种推理模型）在BIRD Mini-Dev基准上的表现，并考虑了推理延迟和令牌消耗。结果表明，分而治之提示和少样本演示能提高通用和推理LLM的性能，但工作流步骤和基础模型选择对结果有影响，揭示了准确性、效率和复杂性之间的实际权衡。


<details>
  <summary>Details</summary>
Motivation: 评估现有Text-to-SQL系统在真实世界应用中的表现，特别是在结合最新的推理模型时，并探讨测试时尺度策略的有效性。

Method: 对六种轻量级、面向行业的测试时尺度策略和四种LLM（包括两种推理模型）在BIRD Mini-Dev基准上进行基准测试，同时测量准确性、推理延迟和令牌消耗。

Result: 分而治之提示和少样本演示能持续提高通用和推理LLM的性能。然而，增加工作流步骤的效果不一，基础模型选择至关重要。

Conclusion: 在部署Text-to-SQL系统时，准确性、效率和复杂性之间存在实际的权衡。分而治之提示和少样本演示是提高性能的有效策略，但需要仔细选择模型和工作流程。

Abstract: Large language models (LLMs) are increasingly powering Text-to-SQL (Text2SQL)
systems, enabling non-expert users to query industrial databases using natural
language. While test-time scaling strategies have shown promise in LLM-based
solutions, their effectiveness in real-world applications, especially with the
latest reasoning models, remains uncertain. In this work, we benchmark six
lightweight, industry-oriented test-time scaling strategies and four LLMs,
including two reasoning models, evaluating their performance on the BIRD
Mini-Dev benchmark. Beyond standard accuracy metrics, we also report inference
latency and token consumption, providing insights relevant for practical system
deployment. Our findings reveal that Divide-and-Conquer prompting and few-shot
demonstrations consistently enhance performance for both general-purpose and
reasoning-focused LLMs. However, introducing additional workflow steps yields
mixed results, and base model selection plays a critical role. This work sheds
light on the practical trade-offs between accuracy, efficiency, and complexity
when deploying Text2SQL systems.

</details>


### [316] [LLM$\times$MapReduce-V3: Enabling Interactive In-Depth Survey Generation through a MCP-Driven Hierarchically Modular Agent System](https://arxiv.org/abs/2510.10890)
*Yu Chao,Siyu Lin,xiaorong wang,Zhu Zhang,Zihan Zhou,Haoyu Wang,Shuo Wang,Jie Zhou,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: LLM x MapReduce-V3 是一个用于长篇调查报告生成的层次化模块化代理系统。


<details>
  <summary>Details</summary>
Motivation: 旨在改进长篇调查报告的生成过程，通过多代理协作和模块化设计，提供更强的控制力和定制性。

Method: 采用多代理架构，将功能组件（如骨架初始化、摘要构建、骨架优化）实现为独立的 MCP 服务器，并由高级规划代理根据工具描述和执行历史动态协调工作流。

Result: 与代表性基线相比，在内容深度和长度方面表现更优。

Conclusion: LLM x MapReduce-V3 的 MCP 模块化规划方法在生成深度和长度方面均优于现有方法。

Abstract: We introduce LLM x MapReduce-V3, a hierarchically modular agent system
designed for long-form survey generation. Building on the prior work, LLM x
MapReduce-V2, this version incorporates a multi-agent architecture where
individual functional components, such as skeleton initialization, digest
construction, and skeleton refinement, are implemented as independent
model-context-protocol (MCP) servers. These atomic servers can be aggregated
into higher-level servers, creating a hierarchically structured system. A
high-level planner agent dynamically orchestrates the workflow by selecting
appropriate modules based on their MCP tool descriptions and the execution
history. This modular decomposition facilitates human-in-the-loop intervention,
affording users greater control and customization over the research process.
Through a multi-turn interaction, the system precisely captures the intended
research perspectives to generate a comprehensive skeleton, which is then
developed into an in-depth survey. Human evaluations demonstrate that our
system surpasses representative baselines in both content depth and length,
highlighting the strength of MCP-based modular planning.

</details>


### [317] [ADVICE: Answer-Dependent Verbalized Confidence Estimation](https://arxiv.org/abs/2510.10913)
*Ki Jung Seo,Sehun Lim,Taeuk Kim*

Main category: cs.CL

TL;DR: LLMs在表达置信度时常常表现出过度自信，研究发现这是由于模型未能根据自身答案来调整置信度（答案独立性）。为解决此问题，提出了一种名为ADVICE的微调框架，通过使置信度与答案相关联来改进置信度校准，同时不牺牲任务性能。


<details>
  <summary>Details</summary>
Motivation: LLMs能够以自然语言表达置信度，但其置信度常常表现出过度自信，且其原因尚不明确。

Method: 提出ADVICE（Answer-Dependent Verbalized Confidence Estimation）微调框架，以实现与答案相关的置信度估计。

Result: ADVICE显著改善了置信度校准，同时保持了任务性能。进一步的分析证实ADVICE增强了答案与置信度的相关性，使得置信度分布更加均衡和校准良好。

Conclusion: 研究揭示了过度自信的根源，并提出了一个更值得信赖的置信度表达框架。

Abstract: Recent progress in large language models (LLMs) has enabled them to express
their confidence in natural language, enhancing transparency and reliability.
However, their confidence often exhibits overconfidence, the cause of which
remains poorly understood. In this work, we conduct a detailed analysis of the
dynamics underlying verbalized confidence and identify answer-independence as a
key factor, defined as the model's failure to condition confidence on its own
answer. To address this, we propose ADVICE (Answer-Dependent Verbalized
Confidence Estimation), a fine-tuning framework that facilitates
answer-grounded confidence estimation. Extensive experiments show that ADVICE
substantially improves confidence calibration while preserving task
performance. Further analyses confirm that ADVICE strengthens
answer-groundedness, leading to more balanced and well-calibrated confidence
distributions. Our findings shed light on the origin of overconfidence and
establish a framework for more trustworthy confidence verbalization.

</details>


### [318] [GapDNER: A Gap-Aware Grid Tagging Model for Discontinuous Named Entity Recognition](https://arxiv.org/abs/2510.10927)
*Yawen Yang,Fukun Ma,Shiao Meng,Aiwei Liu,Lijie Wen*

Main category: cs.CL

TL;DR: GapDNER通过在实体片段之间的上下文“间隙”上应用表示学习来解决不连续命名实体识别中的解码歧义问题，从而实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的命名实体识别方法在处理由非相邻标记组成的实体时，面临错误传播和解码歧义的挑战。

Method: GapDNER将上下文间隙视为一种额外的跨度类型，并将跨度分类转化为一个令牌对网格标记任务。它利用两个交互组件来对令牌对网格特征进行建模：一个用于提取跨度内的规律性，另一个用于增强跨度间的关系。在实体解码的推理阶段，它使用广度优先搜索算法来搜索网格中的有效路径。

Result: GapDNER在三个数据集上实现了最先进的不连续命名实体识别性能，在识别复杂实体结构方面表现出显著优势。

Conclusion: GapDNER通过对上下文间隙进行表示学习，有效地解决了不连续命名实体识别中的解码歧义问题，并在复杂实体结构识别方面取得了优于现有方法的结果。

Abstract: In biomedical fields, one named entity may consist of a series of
non-adjacent tokens and overlap with other entities. Previous methods recognize
discontinuous entities by connecting entity fragments or internal tokens, which
face challenges of error propagation and decoding ambiguity due to the wide
variety of span or word combinations. To address these issues, we deeply
explore discontinuous entity structures and propose an effective Gap-aware grid
tagging model for Discontinuous Named Entity Recognition, named GapDNER. Our
GapDNER innovatively applies representation learning on the context gaps
between entity fragments to resolve decoding ambiguity and enhance
discontinuous NER performance. Specifically, we treat the context gap as an
additional type of span and convert span classification into a token-pair grid
tagging task. Subsequently, we design two interactive components to
comprehensively model token-pair grid features from both intra- and inter-span
perspectives. The intra-span regularity extraction module employs the biaffine
mechanism along with linear attention to capture the internal regularity of
each span, while the inter-span relation enhancement module utilizes
criss-cross attention to obtain semantic relations among different spans. At
the inference stage of entity decoding, we assign a directed edge to each
entity fragment and context gap, then use the BFS algorithm to search for all
valid paths from the head to tail of grids with entity tags. Experimental
results on three datasets demonstrate that our GapDNER achieves new
state-of-the-art performance on discontinuous NER and exhibits remarkable
advantages in recognizing complex entity structures.

</details>


### [319] [Evaluating Language Models' Evaluations of Games](https://arxiv.org/abs/2510.10930)
*Katherine M. Collins,Cedegao E. Zhang,Graham Todd,Lance Ying,Mauricio Barba da Costa,Ryan Liu,Prafull Sharma,Adrian Weller,Ionatan Kuperwajs,Lionel Wong,Joshua B. Tenenbaum,Thomas L. Griffiths*

Main category: cs.CL

TL;DR: 该论文提出了一种评估人工智能（AI）系统评估游戏能力的新范式，并使用包含100多种新颖棋盘游戏和450多个人类判断的大规模数据集进行了实验。结果表明，在评估游戏的公平性和趣味性方面，推理模型比非推理语言模型更符合人类的评估。然而，随着模型越来越接近博弈论最优，其与人类数据的契合度反而会降低。此外，趣味性评估比公平性评估具有更高的模型间变异性。研究还发现，推理模型在评估查询时的资源使用情况可变且不可预测，这表明需要增强其元推理能力。


<details>
  <summary>Details</summary>
Motivation: 评估AI系统评估游戏的能力，而非仅仅是解决游戏问题的能力，并提出一种评估AI评估游戏能力的新范式。

Method: 提出一种评估AI评估游戏能力的形式化方法，并利用大规模数据集（100+种新颖棋盘游戏，450+人类判断）比较了现代语言和推理模型、人类以及符号计算智能体在评估游戏公平性和趣味性方面的表现。

Result: 推理模型在评估游戏公平性和趣味性方面比非推理语言模型更符合人类的评估。模型性能与博弈论最优之间存在非单调关系，即越接近最优，与人类数据拟合度越弱。趣味性评估比公平性评估显示出更高的模型间变异性。推理模型在评估查询时的资源使用情况可变且不可预测。

Conclusion: 推理模型在评估游戏方面比非推理模型更接近人类，但在评估趣味性时表现出更大的变异性。模型在评估时的资源使用效率有待提高，需要增强其元推理能力。

Abstract: Reasoning is not just about solving problems -- it is also about evaluating
which problems are worth solving at all. Evaluations of artificial intelligence
(AI) systems primarily focused on problem solving, historically by studying how
models play games such as chess and Go. In this paper, we advocate for a new
paradigm that assesses AI systems' evaluation of games. First, we introduce a
formalism for evaluating such evaluations. We then leverage a large-scale
dataset of over $100$ novel board games and over 450 human judgments to compare
evaluations produced by modern language and reasoning models against those of
people and symbolic computational agents. We consider two kinds of evaluative
queries: assessing the payoff (or fairness) and the funness of games. These
queries span two dimensions relevant to the design of evaluations of AI
evaluations: how complex a query is to compute and how difficult a query is to
quantify. Our results show that reasoning models are generally more aligned to
people in their evaluations of games than non-reasoning language models.
However, we observe a non-monotonic relationship: as models get closer to
game-theoretic optimal, their fit to human data weakens. We also observe more
"jaggedness" across models for assessing funness, in line with the greater
difficulty of quantifying this query. Across queries and games, reasoning
models show highly variable and unpredictable resource usage when assessing
queries, pointing to the importance of imbuing more resource-rational
meta-reasoning in language and reasoning models.

</details>


### [320] [End-to-end Sequence Labeling via Bi-directional LSTM-CNNs-CRF: A Reproducibility Study](https://arxiv.org/abs/2510.10936)
*Anirudh Ganesh,Jayavardhan Reddy*

Main category: cs.CL

TL;DR: 我们复现了 Ma 和 Hovy (2016) 提出的用于序列标注的最先进的神经架构。


<details>
  <summary>Details</summary>
Motivation: 本文旨在复现 Ma 和 Hovy (2016) 提出的用于序列标注的 BiLSTM-CNN-CRF 模型，并验证其在命名实体识别 (NER) 和词性标注 (POS) 任务上的有效性。

Method: 通过结合卷积神经网络 (CNNs) 处理字符级表示，双向长短期记忆网络 (BiLSTMs) 进行词级上下文建模，以及条件随机场 (CRFs) 进行结构化预测，实现了端到端的序列标注。

Result: 成功复现了关键结果，在 CoNLL-2003 NER 数据集上取得了 91.18% 的 F1 分数，证明了该模型在序列标注任务上的有效性。

Conclusion: 该 BiLSTM-CNN-CRF 模型是一种有效的端到端序列标注方法，无需手工特征即可在 NER 和 POS 标注任务上取得优异性能。我们提供了详细的组件分析，并发布了开源实现以促进未来研究。

Abstract: We present a reproducibility study of the state-of-the-art neural
architecture for sequence labeling proposed by Ma and Hovy
(2016)\cite{ma2016end}. The original BiLSTM-CNN-CRF model combines
character-level representations via Convolutional Neural Networks (CNNs),
word-level context modeling through Bi-directional Long Short-Term Memory
networks (BiLSTMs), and structured prediction using Conditional Random Fields
(CRFs). This end-to-end approach eliminates the need for hand-crafted features
while achieving excellent performance on named entity recognition (NER) and
part-of-speech (POS) tagging tasks. Our implementation successfully reproduces
the key results, achieving 91.18\% F1-score on CoNLL-2003 NER and demonstrating
the model's effectiveness across sequence labeling tasks. We provide a detailed
analysis of the architecture components and release an open-source PyTorch
implementation to facilitate further research.

</details>


### [321] [Punctuation-aware treebank tree binarization](https://arxiv.org/abs/2510.10951)
*Eitan Klinger,Vivaan Wadhwa,Jungyeul Park*

Main category: cs.CL

TL;DR: 本研究提出了一种考虑标点符号的树库二值化方法，并发布了相应的处理流程、中间产物和评估套件。


<details>
  <summary>Details</summary>
Motivation: 现有的树库二值化方法在处理标点符号时会将其丢弃，这会改变句法结构并影响词语的依存关系识别。本研究旨在解决这一问题。

Method: 研究提出了一种可复现的处理流程，该流程在二值化之前将标点符号保留为兄弟节点。同时，研究还发布了派生的中间产物（如 @X 标记、可逆性签名、对齐索引）和一个评估套件，用于评估词语依存关系预测、往返可逆性和与衍生资源（CCGbank）的结构兼容性。

Result: 在宾州树库（Penn Treebank）上，考虑标点符号的处理方法将词语依存关系预测的准确率从使用 Collins 规则的 73.66% 和使用 MLP 的 86.66% 提高到 91.85%，同时在与 CCGbank 衍生资源的对齐方面也取得了有竞争力的结果。

Conclusion: 本研究提出的标点符号感知的树库二值化方法能够显著提高依存关系预测的准确性，并保证了处理流程的可复现性和可扩展性。

Abstract: This article presents a curated resource and evaluation suite for
punctuation-aware treebank binarization. Standard binarization pipelines drop
punctuation before head selection, which alters constituent shape and harms
head-child identification. We release (1) a reproducible pipeline that
preserves punctuation as sibling nodes prior to binarization, (2) derived
artifacts and metadata (intermediate @X markers, reversibility signatures,
alignment indices), and (3) an accompanying evaluation suite covering
head-child prediction, round-trip reversibility, and structural compatibility
with derivational resources (CCGbank). On the Penn Treebank, punctuation-aware
preprocessing improves head prediction accuracy from 73.66\% (Collins rules)
and 86.66\% (MLP) to 91.85\% with the same classifier, and achieves competitive
alignment against CCGbank derivations. All code, configuration files, and
documentation are released to enable replication and extension to other
corpora.

</details>


### [322] [KOTOX: A Korean Toxic Dataset for Deobfuscation and Detoxification](https://arxiv.org/abs/2510.10961)
*Yejin Lee,Su-Hyeon Kim,Hyundong Jin,Dayoung Kim,Yeonsoo Kim,Yo-Sub Han*

Main category: cs.CL

TL;DR: 本研究提出了KOTOX数据集，用于解决低资源语言（特别是韩语）中的有毒内容检测和去混淆问题，并提供了三种不同难度的版本。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中于英语的有毒内容检测，忽视了低资源语言，导致大型语言模型在这些语言上表现不佳，尤其是在用户使用混淆技术规避检测时。

Method: 研究人员根据韩语的语言学特征对各种混淆方法进行了分类，并定义了一系列基于实际案例的转换规则，然后使用这些规则构建了三个不同混淆难度（简单、普通、困难）的数据集版本。

Result: 创建了KOTOX：韩语有毒数据集，这是首个同时支持韩语去混淆和去毒化的数据集。

Conclusion: KOTOX数据集有望促进对低资源语言中混淆的有毒内容的更好理解和缓解，并推动相关研究。

Abstract: Toxic content has become an increasingly critical social issue with the rapid
expansion of online communication. While numerous studies explored methods for
detecting and detoxifying such content, most have focused primarily on English,
leaving low-resource language underrepresented. Consequently, Large Language
Models~(LLMs) often struggle to identify and neutralize toxic expressions in
these languages. This challenge becomes even more pronounced when user employ
obfuscation techniques to evade detection systems. Therefore, we propose a
\textbf{KOTOX: Korean Toxic Dataset} for deobfuscation and detoxicification to
address this issue. We categorize various obfuscation approaches based on
linguistic characteristics of Korean and define a set of transformation rules
grounded in real-word examples. Using these rules, we construct three dataset
versions (easy, normal, and hard) representing different levels of obfuscation
difficulty. This is the first dataset that simultaneously supports
deobfuscation and detoxification for the Korean language. We expect it to
facilitate better understanding and mitigating of obfuscated toxic content in
LLM for low-resource languages. Our code and data are available at
https://github.com/leeyejin1231/KOTOX.

</details>


### [323] [Judge Before Answer: Can MLLM Discern the False Premise in Question?](https://arxiv.org/abs/2510.10965)
*Jidong Li,Lingyong Fang,Haodong Zhao,Sufeng Duan,Gongshen Liu*

Main category: cs.CL

TL;DR: MLLMs在识别错误前提方面仍有不足，本研究提出了JBA数据集和相应的增强框架来解决此问题。


<details>
  <summary>Details</summary>
Motivation: 现有针对MLLMs错误前提问题的基准测试范围有限，分类不够精细，覆盖率不足，无法对其进行严格评估。

Method: 提出全自动化流程构建JBA数据集，将错误前提分为三类十三种；提出错误前提识别增强框架。

Result: 现有MLLMs在识别错误前提方面仍存在困难；使用增强框架训练的模型在错误前提识别方面取得了显著改进。

Conclusion: JBA数据集和增强框架能有效提升MLLMs识别错误前提的能力。

Abstract: Multimodal large language models (MLLMs) have witnessed astonishing
advancements in recent years. Despite these successes, MLLMs remain vulnerable
to flase premise problems. However, existing benchmarks targeting this issue
are limited in scope: they often lack fine-grained categorization, exhibit
insufficient coverage, and thus fail to provide a rigorous evaluation of the
ability of models to recognize false premises. To bridge this gap, we introduce
a fully automated pipeline for constructing a comprehensive benchmark of false
premise questions. Our method systematically categorizes the premises into
three main types and thirteen subtypes according to the abilities required to
identify the premises, resulting in the JBA dataset.Results show current MLLMs
still struggle with false premise recognition. Building upon this benchmark, we
further propose a recognition enhancement framework tailored to strengthen the
robustness of MLLMs to detect false premises. Extensive experiments demonstrate
that models trained with our framework achieve significant improvements in
false premise recognition.

</details>


### [324] [RV-HATE: Reinforced Multi-Module Voting for Implicit Hate Speech Detection](https://arxiv.org/abs/2510.10971)
*Yejin Lee,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.CL

TL;DR: RV-HATE是一个针对不同仇恨言论数据集特性的检测框架，通过强化学习优化模块权重和投票机制，提高了检测准确性并提供可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨言论数据集多样，但以往研究多采用固定方法，未能适应数据特性。

Method: RV-HATE框架包含多个专注于不同语言或语境特征的模块，利用强化学习优化各模块对不同数据集的贡献权重，并通过投票机制整合输出。

Result: RV-HATE提高了检测准确性，能有效检测隐含仇恨言论，并优于传统静态方法，同时提供数据集特性的可解释性。

Conclusion: RV-HATE通过考虑数据集特性和使用强化学习优化模块组合，能有效提升仇恨言论检测性能并提供可解释性。

Abstract: Hate speech remains prevalent in human society and continues to evolve in its
forms and expressions. Modern advancements in internet and online anonymity
accelerate its rapid spread and complicate its detection. However, hate speech
datasets exhibit diverse characteristics primarily because they are constructed
from different sources and platforms, each reflecting different linguistic
styles and social contexts. Despite this diversity, prior studies on hate
speech detection often rely on fixed methodologies without adapting to
data-specific features. We introduce RV-HATE, a detection framework designed to
account for the dataset-specific characteristics of each hate speech dataset.
RV-HATE consists of multiple specialized modules, where each module focuses on
distinct linguistic or contextual features of hate speech. The framework
employs reinforcement learning to optimize weights that determine the
contribution of each module for a given dataset. A voting mechanism then
aggregates the module outputs to produce the final decision. RV-HATE offers two
primary advantages: (1)~it improves detection accuracy by tailoring the
detection process to dataset-specific attributes, and (2)~it also provides
interpretable insights into the distinctive features of each dataset.
Consequently, our approach effectively addresses implicit hate speech and
achieves superior performance compared to conventional static methods. Our code
is available at https://github.com/leeyejin1231/RV-HATE.

</details>


### [325] [Enhancing Large Language Model Reasoning via Selective Critical Token Fine-Tuning](https://arxiv.org/abs/2510.10974)
*Zhiwen Ruan,Yixia Li,He Zhu,Yun Chen,Peng Li,Yang Liu,Guanhua Chen*

Main category: cs.CL

TL;DR: CFT通过仅更新关键反事实扰动标记来优化LLM的微调，提高了数学推理任务的性能和多样性。


<details>
  <summary>Details</summary>
Motivation: 标准SFT在微调LLM时会统一惩罚所有标记，忽略了只有一小部分关键标记决定了推理的正确性，这会导致输出多样性降低和泛化能力受限。

Method: CFT通过反事实扰动识别并仅更新功能上不可或缺的标记，将梯度信号集中在关键的推理步骤上，同时保持非关键标记的多样性。

Result: 在五个模型和十一个数学推理基准上的实验表明，CFT的表现优于标准SFT，尽管CFT只对少于12%的标记进行了微调。此外，CFT通过改进的采样多样性实现了测试时扩展，并为强化学习提供了更强的初始化。

Conclusion: CFT是一种实用且通用的框架，可以实现高效且鲁棒的LLM微调。

Abstract: Large language models (LLMs) primarily rely on supervised fine-tuning (SFT)
as a key method to adapt pre-trained models to domain-specific tasks such as
mathematical reasoning. However, standard SFT uniformly penalizes all tokens,
neglecting that only a small subset of critical tokens determines reasoning
correctness. This uniform supervision often causes reduced output diversity and
limited generalization. We propose Critical Token Fine-tuning (CFT), a simple
yet effective approach that updates only tokens identified as functionally
indispensable via counterfactual perturbations. By focusing gradient signals on
these decisive reasoning steps while preserving the diversity of non-critical
tokens, CFT can enhance both generation and diversity. Extensive experiments on
five models across three families (Qwen, OLMo, LLaMA) and eleven mathematical
reasoning benchmarks show that CFT, despite fine-tuning on less than 12% of
tokens, consistently outperforms standard SFT. Moreover, CFT enables test-time
scaling through improved sampling diversity and provides a stronger
initialization for reinforcement learning, sustaining performance gains in
later training stages while maintaining higher entropy for better exploration.
These results highlight CFT as a practical and general framework for efficient
and robust LLM fine-tuning.

</details>


### [326] [DeepResearchGuard: Deep Research with Open-Domain Evaluation and Multi-Stage Guardrails for Safety](https://arxiv.org/abs/2510.10994)
*Wei-Chieh Huang,Henry Peng Zou,Yaozu Wu,Dongyuan Li,Yankai Chen,Weizhi Zhang,Yangning Li,Angelo Zangari,Jizhou Guo,Chunyu Miao,Liancheng Fang,Langzhou He,Renhe Jiang,Philip S. Yu*

Main category: cs.CL

TL;DR: DEEPRESEARCHGUARD通过引入四阶段防护和开放域评估来改进深度研究框架，提高了报告质量并阻止了有害内容的传播。


<details>
  <summary>Details</summary>
Motivation: 现有的深度研究框架在评估程序和阶段性防护方面存在不足，未能充分考虑报告的信誉、连贯性、广度、深度和安全性，可能导致引入有害或恶意来源。

Method: 提出DEEPRESEARCHGUARD框架，包含四阶段防护，并进行开放域评估。引入DRSAFEBENCH作为深度研究安全性的阶段性基准。评估了包括GPT-4o、Gemini-2.5-flash等在内的多种先进语言模型。

Result: DEEPRESEARCHGUARD将平均防御成功率提高了18.16%，同时将过度拒绝率降低了6%。输入防护在早期过滤风险方面效果最显著，计划和研究防护则提高了引文规范性和来源可信度。

Conclusion: DEEPRESEARCHGUARD实现了全面的开放域评估和阶段感知防御，有效阻止了有害内容的传播，同时系统性地提高了报告质量，并且没有过高的过度拒绝率。

Abstract: Deep research frameworks have shown promising capabilities in synthesizing
comprehensive reports from web sources. While deep research possesses
significant potential to address complex issues through planning and research
cycles, existing frameworks are deficient in sufficient evaluation procedures
and stage-specific protections. They typically treat evaluation as exact match
accuracy of question-answering, but overlook crucial aspects of report quality
such as credibility, coherence, breadth, depth, and safety. This oversight may
result in hazardous or malicious sources being integrated into the final
report. To address these issues, we introduce DEEPRESEARCHGUARD, a
comprehensive framework featuring four-stage safeguards with open-domain
evaluation of references and reports. We assess performance across multiple
metrics, e.g., defense success rate and over-refusal rate, and five key report
dimensions. In the absence of a suitable safety benchmark, we introduce
DRSAFEBENCH, a stage-wise benchmark for deep research safety. Our evaluation
spans diverse state-of-the-art LLMs, including GPT-4o, Gemini-2.5-flash,
DeepSeek-v3, and o4-mini. DEEPRESEARCHGUARD achieves an average defense success
rate improvement of 18.16% while reducing over-refusal rate by 6%. The input
guard provides the most substantial early-stage protection by filtering out
obvious risks, while the plan and research guards enhance citation discipline
and source credibility. Through extensive experiments, we show that
DEEPRESEARCHGUARD enables comprehensive open-domain evaluation and stage-aware
defenses that effectively block harmful content propagation, while
systematically improving report quality without excessive over-refusal rates.
The code can be found via https://github.com/Jasonya/DeepResearchGuard.

</details>


### [327] [ABLEIST: Intersectional Disability Bias in LLM-Generated Hiring Scenarios](https://arxiv.org/abs/2510.10998)
*Mahika Phutane,Hayoung Jung,Matthew Kim,Tanushree Mitra,Aditya Vashistha*

Main category: cs.CL

TL;DR: 现有研究主要关注西方社会，忽略了性别和种姓等交叉边缘化形式如何影响全球南方残疾人（PwD）的经历。本研究审计了六个大型语言模型（LLMs）在2820个招聘场景中的表现，引入了旨在捕捉细微的交叉危害和偏见的ABLEIST指标。结果显示，针对残疾候选人的ABLEIST危害显著增加，许多先进模型未能检测到这些危害，并且性别和种姓边缘化的残疾候选人的交叉危害（如代币化）急剧增加，凸显了现有安全工具的严重不足，以及在招聘等高风险领域对前沿模型进行交叉安全评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 现有关于大型语言模型（LLMs）在招聘等高风险领域歧视残疾人（PwD）的研究主要集中在西方，忽略了性别和种姓等交叉边缘化形式在全球南方对PwD经历的影响。

Method: 对六个LLMs在2820个招聘场景中进行了全面审计，涵盖了不同的残疾、性别、国籍和种姓情况。引入了一套基于残疾研究文献的五项残疾歧视特定指标和三项交叉危害指标（ABLEIST），以捕捉细微的交叉危害和偏见。

Result: 结果表明，针对残疾候选人的ABLEIST危害显著增加，而许多最先进的模型未能检测到这些危害。性别和种姓边缘化的残疾候选人的交叉危害（如代币化）急剧增加，放大了这些危害。

Conclusion: 目前的LLM安全工具存在严重的盲点，无法检测和解决细微的、交叉的歧视性危害。在高风险领域（如招聘）对前沿模型进行交叉安全评估至关重要，以确保公平性和包容性。

Abstract: Large language models (LLMs) are increasingly under scrutiny for perpetuating
identity-based discrimination in high-stakes domains such as hiring,
particularly against people with disabilities (PwD). However, existing research
remains largely Western-centric, overlooking how intersecting forms of
marginalization--such as gender and caste--shape experiences of PwD in the
Global South. We conduct a comprehensive audit of six LLMs across 2,820 hiring
scenarios spanning diverse disability, gender, nationality, and caste profiles.
To capture subtle intersectional harms and biases, we introduce ABLEIST
(Ableism, Inspiration, Superhumanization, and Tokenism), a set of five
ableism-specific and three intersectional harm metrics grounded in disability
studies literature. Our results reveal significant increases in ABLEIST harms
towards disabled candidates--harms that many state-of-the-art models failed to
detect. These harms were further amplified by sharp increases in intersectional
harms (e.g., Tokenism) for gender and caste-marginalized disabled candidates,
highlighting critical blind spots in current safety tools and the need for
intersectional safety evaluations of frontier models in high-stakes domains
like hiring.

</details>


### [328] [DND: Boosting Large Language Models with Dynamic Nested Depth](https://arxiv.org/abs/2510.11001)
*Tieyuan Chen,Xiaodong Chen,Haoxing Chen,Zhenzhong Lan,Weiyao Lin,Jianguo Li*

Main category: cs.CL

TL;DR: DND通过识别和重新处理关键标记来提高LLM性能，同时避免冗余计算。


<details>
  <summary>Details</summary>
Motivation: 提高现成LLM的性能。

Method: DND识别关键标记，并通过路由器和阈值控制策略进行额外的处理。

Result: DND将Qwen3-1.7B的性能提高了1.88%，将Qwen3-30B-A3B的性能提高了0.87%，参数和计算的增加最小。

Conclusion: DND是一种有效的方法，可以在不显著增加参数和计算量的情况下提高LLM的性能。

Abstract: We introduce Dynamic Nested Depth (DND), a novel method that improves
performance for off-the-shelf LLMs by selecting critical tokens to reprocess in
a nested depth manner. Specifically, at the end of the given transformer layer,
DND identifies more critical tokens with a router and feeds them back for an
extra round of processing, effectively ``reviewing" difficult tokens while
avoiding redundant computation for easier ones. The dynamic selection mechanism
is tailored for precise control via two novel strategies: a router controlling
loss to enhance token selection distinguishability, and a threshold control
scheme to ensure selection stability. We demonstrate the effectiveness of DND
by directly integrating it into pre-trained dense and MoE models during a
post-training phase. On diverse benchmarks, this approach boosts the
performances of the dense Qwen3-1.7B by 1.88% and the MoE Qwen3-30B-A3B by
0.87%, all with a minimal parameter and computing increase.

</details>


### [329] [LogiNumSynth: Synthesizing Joint Logical-Numerical Reasoning Problems for Language Models](https://arxiv.org/abs/2510.11031)
*Yiwei Liu,Yucheng Li,Xiao Li,Gong Cheng*

Main category: cs.CL

TL;DR: LogiNumSynth是一个灵活的自然语言问题合成器，可以合成需要结合逻辑和数值推理的任务，并对任务的复杂性进行细粒度控制，用于评估和训练语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在逻辑-数值推理方面存在局限性，难以控制任务复杂度和通用性。

Method: LogiNumSynth支持对推理世界丰富度、逻辑推理深度和数值计算复杂性进行细粒度控制，从而能够合成不同难度级别的任务。

Result: 实验表明，LogiNumSynth可用于评估和增强语言模型在逻辑-数值推理方面的能力，并能诊断出其存在的弱点。

Conclusion: LogiNumSynth是一个有价值的工具，可以用于评估、诊断和改进语言模型中的联合逻辑-数值推理能力。

Abstract: Joint logical-numerical reasoning remains a major challenge for language
models, yet existing datasets rely on fixed rule sets and offer limited control
over task complexity, constraining their generalizability for evaluation and
training. We present LogiNumSynth, a flexible natural language problem
synthesizer that synthesizes tasks requiring proficiency in joint logical
reasoning (e.g., rule-based reasoning) and numerical reasoning (e.g.,
arithmetic computation). LogiNumSynth supports fine-grained control over
reasoning world richness, logical reasoning depth, and the complexity of
numerical computations, enabling flexible data synthesis across difficulty
levels. We demonstrate three key contributions: (1) Synthesizer -- synthesizing
fully controllable joint reasoning tasks over natural language; (2) Evaluation
& Process Analysis -- evaluating both process accuracy and answer accuracy; (3)
Targeted Training -- using synthesized data to enhance LLMs' reasoning
performance. Experiments with multiple LLMs highlight persistent weaknesses in
logical-numerical reasoning, showing that LogiNumSynth can serve as both a
diagnostic tool and a source of targeted supervision for advancing integrated
reasoning skills.

</details>


### [330] [Enabling Doctor-Centric Medical AI with LLMs through Workflow-Aligned Tasks and Benchmarks](https://arxiv.org/abs/2510.11040)
*Wenya Xie,Qingying Xiao,Yu Zheng,Xidong Wang,Junying Chen,Ke Ji,Anningzhe Gao,Prayag Tiwari,Xiang Wan,Feng Jiang,Benyou Wang*

Main category: cs.CL

TL;DR: LLM可用于辅助医生，但直接面向患者存在风险。本研究提出了DoctorFLAN，一个包含92,000个医疗问答实例的大规模中文数据集，旨在改进LLM在医疗领域的表现，使其更好地服务于医生工作流程。


<details>
  <summary>Details</summary>
Motivation: 直接将LLM部署给患者存在安全风险，因为LLM的领域专业知识有限。因此，本研究旨在将LLM重新定位为临床助理，与经验丰富的医生合作，而不是直接与患者互动，以解决这一问题。

Method: 通过两阶段的“灵感-反馈”调查来识别临床工作流程中的实际需求。基于这些需求，构建了一个名为DoctorFLAN的大规模中文医疗数据集，其中包含92,000个跨越22个临床任务和27个专科的问答实例。为了评估模型在面向医生的应用中的性能，还引入了DoctorFLAN-test（包含550个单轮问答）和DotaBench（包含74个多轮对话）测试集。

Result: 在十多个主流LLM上的实验结果表明，DoctorFLAN显著提高了开源LLM在医疗场景下的性能，有助于模型与医生工作流程的对齐，并能有效补充现有面向患者的模型。

Conclusion: 本研究贡献了一个宝贵的资源和框架，用于推进以医生为中心的医疗LLM的开发。

Abstract: The rise of large language models (LLMs) has transformed healthcare by
offering clinical guidance, yet their direct deployment to patients poses
safety risks due to limited domain expertise. To mitigate this, we propose
repositioning LLMs as clinical assistants that collaborate with experienced
physicians rather than interacting with patients directly. We conduct a
two-stage inspiration-feedback survey to identify real-world needs in clinical
workflows. Guided by this, we construct DoctorFLAN, a large-scale Chinese
medical dataset comprising 92,000 Q&A instances across 22 clinical tasks and 27
specialties. To evaluate model performance in doctor-facing applications, we
introduce DoctorFLAN-test (550 single-turn Q&A items) and DotaBench (74
multi-turn conversations). Experimental results with over ten popular LLMs
demonstrate that DoctorFLAN notably improves the performance of open-source
LLMs in medical contexts, facilitating their alignment with physician workflows
and complementing existing patient-oriented models. This work contributes a
valuable resource and framework for advancing doctor-centered medical LLM
development

</details>


### [331] [Latent Refinement Decoding: Enhancing Diffusion-Based Language Models by Refining Belief States](https://arxiv.org/abs/2510.11052)
*Qinglin Zhu,Yizhen Yao,Runcong Zhao,Yanzheng Xiang,Amrutha Saseendran,Chen Jin,Philip Alexander Teare,Bin Liang,Yulan He,Lin Gui*

Main category: cs.CL

TL;DR: LRD是一种两阶段框架，通过潜在细化和预测反馈循环来解决AR模型生成延迟问题，并改进了扩散模型的信息丢失和过早承诺的缺点。该框架通过保留未确定Token的分布信息并进行迭代反馈，实现了更高的准确性和更快的生成速度。


<details>
  <summary>Details</summary>
Motivation: 自回归（AR）模型虽然是自然语言生成的主流，但其严格的顺序解码导致高延迟。扩散模型虽然实现了并行生成，但存在信息丢失和过早承诺的问题。

Method: LRD框架包含两个阶段：1. 潜在细化：将未确定位置的Token保持为预测Token和掩码嵌入的混合分布，以建立更全局一致的信念。2. 预测反馈循环：逐步确定置信度高的Token，同时保留不确定的Token进行迭代反馈。使用KL散度作为收敛和提前停止的标准。

Result: 在代码（HumanEval +6.3, MBPP +2.6）和推理（GSM8K +2.9, MATH500 +3.8）任务上，LRD的准确性得到了提升，同时生成速度最高提升了10.6倍。

Conclusion: LRD是一种强大的、多功能的并行序列生成替代方案，能够提高准确性并显著降低延迟。

Abstract: Autoregressive (AR) models remain the standard for natural language
generation but still suffer from high latency due to strictly sequential
decoding. Recent diffusion-inspired approaches, such as LlaDA and Dream,
mitigate this by generating in parallel, yet they suffer from two core
limitations: information loss, as predictive distributions for non-finalized
tokens are discarded at each step, and premature commitment, where local
decisions are made without sufficient global coordination. We introduce Latent
Refinement Decoding (LRD), a two-stage framework with Latent Refinement and a
Predictive Feedback Loop. The first stage maintains masked positions as
distributional mixtures of predicted tokens and the mask embedding, allowing
the model to establish more globally consistent beliefs. The second stage
progressively finalizes confident tokens while retaining uncertain ones for
iterative feedback. KL-divergence dynamics provide a principled and reliable
criterion for convergence and early stopping. Experiments across coding
(HumanEval +6.3, MBPP +2.6) and reasoning (GSM8K +2.9, MATH500 +3.8) show that
LRD improves accuracy while delivering speedups of up to 10.6x, making it a
strong and versatile alternative for parallel sequence generation.

</details>


### [332] [Enhancing LLM Reasoning via Non-Human-Like Reasoning Path Preference Optimization](https://arxiv.org/abs/2510.11104)
*Junjie Lu,Yuliang Liu,Chaofeng Qu,Wei Shen,Zhouhan Lin,Min Xu*

Main category: cs.CL

TL;DR: CGPO是一种新的优化方法，通过利用置信度信号来识别模型推理过程中的最大不确定点，并应用非人类的推理路径引导来减少轨迹漂移，从而提高LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理增强方法倾向于引入人为的训练偏见，限制了非人类推理路径的探索，从而限制了性能。在推理错误发生之前，在模型置信度最低的点进行引导比定位第一个错误点更能提供准确的监督。

Method: CGPO方法利用置信度信号识别模型推理过程中的最大不确定点，并应用自我生成的、非人类的推理路径引导来减轻轨迹漂移。

Result: 在相同的训练数据量下，CGPO方法使用小模型生成的数据在大多数情况下优于使用强模型生成的数据或人工标注的方法，并且在代码和数学推理任务上表现更好。

Conclusion: CGPO通过利用置信度信号和非人类推理路径引导，克服了现有方法的局限性，提高了LLM的推理性能。

Abstract: Current approaches for strengthening LLM reasoning tend to introduce a
training bias toward human-like reasoning trajectories. In step-wise preference
optimization, in particular, dependence on human or higher-capacity model
annotations for intermediate steps limits exploration of alternative,
non-human-like reasoning paths and thus constrains achievable performance.
Furthermore, through a small-scale pilot study, we observed that in
approximately 75% of cases, the model's first erroneous step occurs after the
lowest-confidence point. This suggests that guiding the model at its
lowest-confidence point before an error provides more accurate supervision than
locating the first explicit error. In this paper, we propose Confidence-Guided
Reasoning Path Preference Optimization (CGPO), a method that leverages a
confidence signal to identify points of maximal uncertainty in the model's
reasoning process and applies self-generated, non-human-like reasoning-path
guidance to mitigate trajectory drift. Our experiments span diverse models
applied to both code and mathematical reasoning tasks. The results show that,
with the same amount of training data, our method using data generated by a
small model can achieve better performance in most cases compared with
approaches using data generated by a strong model or human-annotated.

</details>


### [333] [TypePilot: Leveraging the Scala Type System for Secure LLM-generated Code](https://arxiv.org/abs/2510.11151)
*Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic*

Main category: cs.CL

TL;DR: TypePilot是一个利用强类型和可验证语言（以Scala为例）来提高LLM生成代码的安全性和鲁棒性的AI框架，通过形式化验证和通用安全代码生成两方面进行评估，实验结果表明该方法能显著减少输入验证和注入漏洞。


<details>
  <summary>Details</summary>
Motivation: LLM生成的代码常包含不易察觉但关键的漏洞，在安全敏感或关键任务系统中部署存在重大风险。

Method: 利用强类型和可验证语言（以Scala为例）设计了一个名为TypePilot的agentic AI框架，并在形式化验证（使用Stainless框架）和通用目的安全代码生成两方面进行了评估。

Result: 实验表明，直接生成代码或进行安全代码生成提示常无法强制执行安全约束，而TypePilot的以类型为中心的agentic流程显著减少了输入验证和注入漏洞。

Conclusion: 结构化的、类型指导的LLM工作流有潜力提高高保证领域中自动化代码生成的可信赖性达到了SotA水平。

Abstract: Large language Models (LLMs) have shown remarkable proficiency in code
generation tasks across various programming languages. However, their outputs
often contain subtle but critical vulnerabilities, posing significant risks
when deployed in security-sensitive or mission-critical systems. This paper
introduces TypePilot, an agentic AI framework designed to enhance the security
and robustness of LLM-generated code by leveraging strongly typed and
verifiable languages, using Scala as a representative example. We evaluate the
effectiveness of our approach in two settings: formal verification with the
Stainless framework and general-purpose secure code generation. Our experiments
with leading open-source LLMs reveal that while direct code generation often
fails to enforce safety constraints, just as naive prompting for more secure
code, our type-focused agentic pipeline substantially mitigates input
validation and injection vulnerabilities. The results demonstrate the potential
of structured, type-guided LLM workflows to improve the SotA of the
trustworthiness of automated code generation in high-assurance domains.

</details>


### [334] [One Size Does Not Fit All: Exploring Variable Thresholds for Distance-Based Multi-Label Text Classification](https://arxiv.org/abs/2510.11160)
*Jens Van Nooten,Andriy Kosar,Guy De Pauw,Walter Daelemans*

Main category: cs.CL

TL;DR: 距离度量文本分类是一种利用文本与标签之间的语义相似性来判断标签相关性的方法，它在推理速度和适应不断扩展的标签集方面具有优势，并且通过优化标签特定的阈值来提升多标签文本分类的效果。


<details>
  <summary>Details</summary>
Motivation: 探索和评估句子编码器在距离度量文本分类任务中的能力，特别是解决多标签场景下的阈值设定问题。

Method: 在多个多标签文本分类数据集上进行实验，分析不同模型、数据集和标签集对文本与标签之间相似性分布的影响，并提出一种新的优化标签特定阈值的方法。

Result: 发现相似性分布在模型、数据集和标签集之间存在显著差异。提出的标签特定阈值优化方法比传统的0.5归一化阈值方法平均提升46%，比以往的统一阈值方法平均提升14%，并且在少量标记样本下表现良好。

Conclusion: 提出的标签特定阈值优化方法能够有效提升距离度量文本分类的性能，并且具有良好的泛化能力。

Abstract: Distance-based unsupervised text classification is a method within text
classification that leverages the semantic similarity between a label and a
text to determine label relevance. This method provides numerous benefits,
including fast inference and adaptability to expanding label sets, as opposed
to zero-shot, few-shot, and fine-tuned neural networks that require re-training
in such cases. In multi-label distance-based classification and information
retrieval algorithms, thresholds are required to determine whether a text
instance is "similar" to a label or query. Similarity between a text and label
is determined in a dense embedding space, usually generated by state-of-the-art
sentence encoders. Multi-label classification complicates matters, as a text
instance can have multiple true labels, unlike in multi-class or binary
classification, where each instance is assigned only one label. We expand upon
previous literature on this underexplored topic by thoroughly examining and
evaluating the ability of sentence encoders to perform distance-based
classification. First, we perform an exploratory study to verify whether the
semantic relationships between texts and labels vary across models, datasets,
and label sets by conducting experiments on a diverse collection of realistic
multi-label text classification (MLTC) datasets. We find that similarity
distributions show statistically significant differences across models,
datasets and even label sets. We propose a novel method for optimizing
label-specific thresholds using a validation set. Our label-specific
thresholding method achieves an average improvement of 46% over normalized 0.5
thresholding and outperforms uniform thresholding approaches from previous work
by an average of 14%. Additionally, the method demonstrates strong performance
even with limited labeled examples.

</details>


### [335] [Bridging Gaps in Hate Speech Detection: Meta-Collections and Benchmarks for Low-Resource Iberian Languages](https://arxiv.org/abs/2510.11167)
*Paloma Piot,José Ramom Pichel Campos,Javier Parapar*

Main category: cs.CL

TL;DR: 该研究旨在解决低资源语言（特别是西班牙语和葡萄牙语）仇恨言论检测的资源匮乏和语言变体问题。研究者整合并扩展了现有的欧洲西班牙语仇恨言论数据集，并将其翻译成欧洲葡萄牙语和两种加利西亚语变体，创建了多语言语料库，为伊比利亚语言的仇恨言论检测设定了新的基准，并评估了不同设置下的先进大型语言模型，强调了多语言和考虑语言变体方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于仇恨言论在社交媒体上传播迅速，对社会凝聚力和个人福祉构成威胁，但现有研究主要集中在英语，导致低资源语言的研究资源和基准有限，并且忽视了这些语言的多种语言变体。大型语言模型需要大量数据，这对于低资源语言来说是一个挑战。

Method: 通过系统性分析和整合现有资源，汇编了一个欧洲西班牙语仇恨言论数据集的元集合，并统一了标签和元数据。随后，将该集合扩展到欧洲葡萄牙语和两种加利西亚语变体，创建了多语言对齐语料库。利用这些资源，建立了伊比利亚语言仇恨言论检测的新基准，并评估了零样本、少样本和微调设置下的先进大型语言模型，同时进行了跨语言分析。

Result: 建立了欧洲西班牙语、欧洲葡萄牙语和两种加利西亚语的仇恨言论检测基准，并提供了不同设置下先进大型语言模型的基线结果。研究表明，多语言和考虑语言变体的方法对于仇恨言论检测至关重要。

Conclusion: 该研究为低资源欧洲语言的仇恨言论检测提供了基础，强调了多语言和考虑语言变体方法的重要性，并为改进基准测试奠定了基础。

Abstract: Hate speech poses a serious threat to social cohesion and individual
well-being, particularly on social media, where it spreads rapidly. While
research on hate speech detection has progressed, it remains largely focused on
English, resulting in limited resources and benchmarks for low-resource
languages. Moreover, many of these languages have multiple linguistic
varieties, a factor often overlooked in current approaches. At the same time,
large language models require substantial amounts of data to perform reliably,
a requirement that low-resource languages often cannot meet. In this work, we
address these gaps by compiling a meta-collection of hate speech datasets for
European Spanish, standardised with unified labels and metadata. This
collection is based on a systematic analysis and integration of existing
resources, aiming to bridge the data gap and support more consistent and
scalable hate speech detection. We extended this collection by translating it
into European Portuguese and into a Galician standard that is more convergent
with Spanish and another Galician variant that is more convergent with
Portuguese, creating aligned multilingual corpora. Using these resources, we
establish new benchmarks for hate speech detection in Iberian languages. We
evaluate state-of-the-art large language models in zero-shot, few-shot, and
fine-tuning settings, providing baseline results for future research. Moreover,
we perform a cross-lingual analysis with our target languages. Our findings
underscore the importance of multilingual and variety-aware approaches in hate
speech detection and offer a foundation for improved benchmarking in
underrepresented European languages.

</details>


### [336] [Evaluating Reasoning Faithfulness in Medical Vision-Language Models using Multimodal Perturbations](https://arxiv.org/abs/2510.11196)
*Johannes Moll,Markus Graf,Tristan Lemke,Nicolas Lenhart,Daniel Truhn,Jean-Benoit Delbrouck,Jiazhen Pan,Daniel Rueckert,Lisa C. Adams,Keno K. Bressem*

Main category: cs.CL

TL;DR: 在胸部X光视觉问答中，我们提出了一种新的评估框架，用于检测视觉语言模型（VLM）的解释是否与其决策过程一致。该框架通过修改文本和图像来检查临床保真度、因果归因和置信度校准。研究发现，现有的VLM解释往往与实际决策过程不符，并且模型在不同评估维度上的表现差异很大，尤其是在因果归因方面。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLM）在生成解释时，往往产生看似合理但未能真实反映其决策过程的链式思考（CoT）解释，这削弱了在临床等高风险场景下对其的信任。现有的评估方法往往无法检测到这种不一致性，因为它们过于关注答案的准确性或格式的符合性。

Method: 提出一个基于临床的胸部X光视觉问答（VQA）框架，通过对文本和图像进行受控修改，从临床保真度、因果归因和置信度校准三个维度探究CoT的忠实度。通过一项包含4名评估者（放射科医生）的读者研究来验证该框架。使用该框架对六个VLM进行基准测试。

Result: 在读者研究中，评估者-放射科医生在所有维度上的一致性均在观察到的放射科医生间一致性范围内。因果归因的一致性较强（Kendall's τ_b=0.670），临床保真度中等（τ_b=0.387），置信度语气较弱（τ_b=0.091）。基准测试显示，答案准确性和解释质量是分离的，模型未能保证对注入的提示的正确识别，并且文本提示比视觉提示更能改变解释。尽管一些开源模型在最终答案准确性上与闭源模型相当，但闭源模型在因果归因（25.0% vs. 1.4%）和临床保真度（36.1% vs. 31.7%）方面得分更高。

Conclusion: 现有的视觉语言模型（VLM）在胸部X光视觉问答任务中，其链式思考（CoT）解释的忠实度问题依然存在，答案准确性与解释质量并不总是一致。闭源模型在临床保真度和因果归因方面优于开源模型，这揭示了模型部署的潜在风险，并强调了超越最终答案准确性进行评估的必要性。

Abstract: Vision-language models (VLMs) often produce chain-of-thought (CoT)
explanations that sound plausible yet fail to reflect the underlying decision
process, undermining trust in high-stakes clinical use. Existing evaluations
rarely catch this misalignment, prioritizing answer accuracy or adherence to
formats. We present a clinically grounded framework for chest X-ray visual
question answering (VQA) that probes CoT faithfulness via controlled text and
image modifications across three axes: clinical fidelity, causal attribution,
and confidence calibration. In a reader study (n=4), evaluator-radiologist
correlations fall within the observed inter-radiologist range for all axes,
with strong alignment for attribution (Kendall's $\tau_b=0.670$), moderate
alignment for fidelity ($\tau_b=0.387$), and weak alignment for confidence tone
($\tau_b=0.091$), which we report with caution. Benchmarking six VLMs shows
that answer accuracy and explanation quality are decoupled, acknowledging
injected cues does not ensure grounding, and text cues shift explanations more
than visual cues. While some open-source models match final answer accuracy,
proprietary models score higher on attribution (25.0% vs. 1.4%) and often on
fidelity (36.1% vs. 31.7%), highlighting deployment risks and the need to
evaluate beyond final answer accuracy.

</details>


### [337] [Discursive Circuits: How Do Language Models Understand Discourse Relations?](https://arxiv.org/abs/2510.11210)
*Yisong Miao,Min-Yen Kan*

Main category: cs.CL

TL;DR: 稀疏计算图（discursive circuits）控制着 Transformer 模型如何处理语篇关系。


<details>
  <summary>Details</summary>
Motivation: 探究 Transformer 语言模型中哪些组件负责语篇理解，并提出稀疏计算图（discursive circuits）是关键。

Method: 引入名为“语篇关系下的补全”（Completion under Discourse Relation, CuDR）的任务，并构建了最小对比语料库以支持该任务的电路发现。

Result: 实验表明，稀疏电路（约占 GPT-2 模型的 0.2%）能够恢复模型在英文 PDTB-based CuDR 任务上的语篇理解能力，并且这些电路能够泛化到 RST 和 SDRT 等未见的语篇框架。进一步分析发现，较低层捕获词汇语义和指代等语言特征，而较高层编码语篇级抽象，且特征效用在不同框架下保持一致。

Conclusion: 稀疏电路在 Transformer 模型中扮演着关键角色，负责语篇理解，并且其结构和功能具有一定的泛化能力和跨框架一致性。

Abstract: Which components in transformer language models are responsible for discourse
understanding? We hypothesize that sparse computational graphs, termed as
discursive circuits, control how models process discourse relations. Unlike
simpler tasks, discourse relations involve longer spans and complex reasoning.
To make circuit discovery feasible, we introduce a task called Completion under
Discourse Relation (CuDR), where a model completes a discourse given a
specified relation. To support this task, we construct a corpus of minimal
contrastive pairs tailored for activation patching in circuit discovery.
Experiments show that sparse circuits ($\approx 0.2\%$ of a full GPT-2 model)
recover discourse understanding in the English PDTB-based CuDR task. These
circuits generalize well to unseen discourse frameworks such as RST and SDRT.
Further analysis shows lower layers capture linguistic features such as lexical
semantics and coreference, while upper layers encode discourse-level
abstractions. Feature utility is consistent across frameworks (e.g.,
coreference supports Expansion-like relations).

</details>


### [338] [Domain-Specific Data Generation Framework for RAG Adaptation](https://arxiv.org/abs/2510.11217)
*Chris Xing Tian,Weihao Xie,Zhen Chen,Zhengyuan Yi,Hui Liu,Haoliang Li,Shiqi Wang,Siwei Ma*

Main category: cs.CL

TL;DR: RAGen是一个用于生成领域特定问答上下文三元组的框架，以适应检索增强生成（RAG）系统。


<details>
  <summary>Details</summary>
Motivation: 为了有效适应RAG系统到特定领域，需要超越通用问答的、包含丰富上下文的专用训练数据。

Method: RAGen通过识别文档中的关键概念，生成基于布鲁姆分类法的多样化问题，并将其与从相关上下文中提取的精确答案配对，来生成问答上下文三元组。该框架支持多种RAG适应策略，包括LLM、检索器和嵌入模型的优化，并采用了语义分块、分层概念提取、多块检索以及引入精选的干扰上下文等模块化方法。

Result: RAGen能够生成用于RAG适应的领域特定问答上下文三元组，并支持多种适应策略和优化，其模块化流水线和干扰上下文设计旨在提高鲁棒性。

Conclusion: RAGen是一个可扩展、模块化的框架，能够为多种RAG适应方法生成量身定制的、领域特定的问答上下文三元组，适用于科学研究和企业知识库等动态演化领域。

Abstract: Retrieval-Augmented Generation (RAG) combines the language understanding and
reasoning power of large language models (LLMs) with external retrieval to
enable domain-grounded responses. Effectively adapting RAG systems to
domain-specific settings requires specialized, context-rich training data
beyond general-purpose question-answering. Here, we propose RAGen, a scalable
and modular framework for generating domain-grounded question-answer-context
(QAC) triples tailored to diverse RAG adaptation approaches. RAGen produces
these QAC triples by identifying key concepts in documents, generating diverse
questions guided by Bloom's Taxonomy-inspired principles, and pairing them with
precise answers extracted from relevant contexts. RAGen supports multiple RAG
adaptation strategies, including the optimization of key components such as the
LLM, retriever, and embedding model, etc. Its modular pipeline features
semantic chunking, hierarchical concept extraction, and multi-chunk retrieval,
along with the introduction of curated distractor contexts to promote robust
reasoning. Designed for scalability, RAGen efficiently handles large and
evolving document corpora without redundant processing, making it especially
suitable for dynamic evolving domains such as scientific research and
enterprise knowledge bases.

</details>


### [339] [The Curious Case of Factual (Mis)Alignment between LLMs' Short- and Long-Form Answers](https://arxiv.org/abs/2510.11218)
*Saad Obaid ul Islam,Anne Lauscher,Goran Glavaš*

Main category: cs.CL

TL;DR: LLMs在简单和复杂查询中的事实不一致性；提出SLAQ评估框架；发现位置依赖的准确性损失和动量效应；通过机制分析预测事实一致性。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在不同查询复杂度下的事实知识访问一致性，解决现有评估方法的不足。

Method: 提出SLAQ（Short-Long Form Alignment for Factual Question Answering）框架，对比LLMs对同一事实问题的简短和长形式查询的回答。分析16个LLMs的600个查询，并进行机制分析。

Result: 发现LLMs在简短和长形式查询中的回答存在系统性不一致；揭示了位置依赖的准确性损失和动量效应；通过机制分析，发现事实对齐会激活重叠的模型内部状态，且机制相似性度量可预测简短-长回答对齐的准确率高达78%。

Conclusion: LLMs的事实一致性比查询复杂度是衡量其可信度的重要方面，挑战了现有评估实践。

Abstract: Large language models (LLMs) can correctly answer "When was Einstein born?"
yet fail to provide the same date when writing about Einstein's life revealing
a fundamental inconsistency in how models access factual knowledge across task
complexities. While models display impressive accuracy on factual
question-answering benchmarks, the reliability gap between simple and complex
queries remains poorly understood, eroding their trustworthiness. In this work,
we introduce Short-Long Form Alignment for Factual Question Answering (SLAQ), a
controlled evaluation framework that compares LLMs' answers to the same factual
questions asked (a) in isolation (short) vs. (b) integrated into complex
queries (long). Looking at 16 LLMs across 600 queries, we find a systematic
misalignment of answers to the corresponding short and long queries. We further
uncover position-dependent accuracy loss and momentum effects where consecutive
correct or incorrect answers create self-reinforcing patterns. Through
mechanistic analysis, we find that aligned facts activate overlapping model
internals, and that metrics based on mechanistic similarity can predict
short-long answer alignment with up to 78% accuracy. Our work establishes
factual consistency over query complexity as an important aspect of LLMs'
trustworthiness and challenges current evaluation practices, which implicitly
assume that good performance for simple factual queries implies reliability in
more complex knowledge-seeking tasks too.

</details>


### [340] [WebRouter: Query-specific Router via Variational Information Bottleneck for Cost-sensitive Web Agent](https://arxiv.org/abs/2510.11221)
*Tao Li,Jinlong Hu,Yang Wang,Junfeng Liu,Xuejun Liu*

Main category: cs.CL

TL;DR: WebRouter通过信息论优化LLM驱动的网络代理，在显著降低成本的同时，仅有轻微的准确性损失。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的网络代理在自动化方面功能强大，但面临成本与性能的权衡。网络代理的复杂提示（包含目标、历史记录和环境状态）会降低LLM集成性能。

Method: 提出了一种名为WebRouter的新型查询特定路由器，采用成本感知的变分信息瓶颈（ca-VIB）目标，学习压缩输入提示的表示，并惩罚预期操作成本。

Result: 在WebVoyager基准的五个真实世界网站上的实验表明，与GPT-4o基线相比，WebRouter将操作成本降低了87.8%，准确性仅下降了3.8%。

Conclusion: WebRouter有效地解决了LLM网络代理的成本-性能权衡问题，通过信息论方法实现了显著的成本节约，同时保持了高准确性。

Abstract: LLM-brained web agents offer powerful capabilities for web automation but
face a critical cost-performance trade-off. The challenge is amplified by web
agents' inherently complex prompts that include goals, action histories, and
environmental states, leading to degraded LLM ensemble performance. To address
this, we introduce WebRouter, a novel query-specific router trained from an
information-theoretic perspective. Our core contribution is a cost-aware
Variational Information Bottleneck (ca-VIB) objective, which learns a
compressed representation of the input prompt while explicitly penalizing the
expected operational cost. Experiments on five real-world websites from the
WebVoyager benchmark show that WebRouter reduces operational costs by a
striking 87.8\% compared to a GPT-4o baseline, while incurring only a 3.8\%
accuracy drop.

</details>


### [341] [Fairness Metric Design Exploration in Multi-Domain Moral Sentiment Classification using Transformer-Based Models](https://arxiv.org/abs/2510.11222)
*Battemuulen Naranbat,Seyed Sahand Mohammadi Ziabari,Yousuf Nasser Al Husaini,Ali Mohammed Mansoor Alsahag*

Main category: cs.CL

TL;DR: 跨领域迁移中，BERT和DistilBERT在道德情感分类任务上表现出不公平的性能差异，尤其是在Twitter到Reddit的迁移中。引入了MFC指标来量化跨领域稳定性，该指标与Demographic Parity Difference呈负相关，可用于公平性评估。


<details>
  <summary>Details</summary>
Motivation: 在跨领域迁移场景下，评估和确保NLP模型（特别是Transformer模型）在道德情感分类任务中的公平性是一个严峻的挑战。

Method: 使用MFTC和MFRC语料库，评估了BERT和DistilBERT在多标签设置下的域内和跨域迁移性能。引入了MFC（Moral Fairness Consistency）指标来量化跨域稳定性，并将其与Demographic Parity Difference和Equalized Odds Difference进行比较。

Result: 跨域迁移表现出显著的不对称性，Twitter->Reddit迁移导致微F1下降14.9%，而Reddit->Twitter仅下降1.5%。'authority'标签表现出显著的公平性差异。MFC指标与Demographic Parity Difference呈完美负相关（rho = -1.000, p < 0.001），表明其作为公平性诊断指标的有效性。'loyalty'标签具有最高的跨域一致性（MFC = 0.96），而'authority'标签最低（MFC = 0.78）。

Conclusion: MFC是一个有价值的、面向诊断的公平性评估指标，能够揭示标准性能指标所掩盖的跨领域不公平性，有助于更可靠地部署道德推理模型。

Abstract: Ensuring fairness in natural language processing for moral sentiment
classification is challenging, particularly under cross-domain shifts where
transformer models are increasingly deployed. Using the Moral Foundations
Twitter Corpus (MFTC) and Moral Foundations Reddit Corpus (MFRC), this work
evaluates BERT and DistilBERT in a multi-label setting with in-domain and
cross-domain protocols. Aggregate performance can mask disparities: we observe
pronounced asymmetry in transfer, with Twitter->Reddit degrading micro-F1 by
14.9% versus only 1.5% for Reddit->Twitter. Per-label analysis reveals fairness
violations hidden by overall scores; notably, the authority label exhibits
Demographic Parity Differences of 0.22-0.23 and Equalized Odds Differences of
0.40-0.41. To address this gap, we introduce the Moral Fairness Consistency
(MFC) metric, which quantifies the cross-domain stability of moral foundation
detection. MFC shows strong empirical validity, achieving a perfect negative
correlation with Demographic Parity Difference (rho = -1.000, p < 0.001) while
remaining independent of standard performance metrics. Across labels, loyalty
demonstrates the highest consistency (MFC = 0.96) and authority the lowest (MFC
= 0.78). These findings establish MFC as a complementary, diagnosis-oriented
metric for fairness-aware evaluation of moral reasoning models, enabling more
reliable deployment across heterogeneous linguistic contexts. .

</details>


### [342] [A Theorem-Proving-Based Evaluation of Neural Semantic Parsing](https://arxiv.org/abs/2510.11225)
*Hayate Funakura,Hyunsoo Kim,Koji Mineshima*

Main category: cs.CL

TL;DR: 图匹配指标（如 Smatch）未能捕捉逻辑等价性，而基于自动定理证明的评估可以。与监督微调相比，GPT-4 等模型在少样本情境学习中表现出更强的逻辑能力。目标公式的归一化可以提高评估的准确性和模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的图匹配指标（如 Smatch）是评估神经语义解析器的标准，但它们仅关注表面重叠，而非逻辑等价性。这可能导致模型在评估中表现良好，但在实际逻辑推理任务中表现不佳。因此，需要重新评估现有的评估方法，并引入能够捕捉逻辑等价性的评估手段。

Method: 本文结合了图匹配指标和自动定理证明（ATP）来评估神经语义解析器。研究了两种模型构建方法：监督微调（T5-Small/Base）和少样本情境学习（GPT-4o/4.1/5）。在归一化和非归一化目标下，使用图匹配、源语言和目标语言公式之间的双向蕴含关系（通过一阶逻辑定理证明器）以及公式的良构性来评估模型输出。

Result: 研究发现，在图匹配指标上表现良好的模型，其生成的公式往往在逻辑上不等价。目标公式的归一化能够减少偶然的目标变异性，提高公式的良构性，并增强逻辑充分性。错误分析表明，随着公式复杂性、协调结构、介词短语和被动语态的增加，模型性能会下降。主要的失败原因包括变量绑定、索引和谓词命名。

Conclusion: 现有的基于图的评估指标在面向推理的应用中存在局限性，无法有效衡量逻辑等价性。因此，需要开发对逻辑敏感的评估和训练方法，并结合简化的、归一化的目标表示，以更准确地评估和提升神经语义解析器的逻辑推理能力。

Abstract: Graph-matching metrics such as Smatch are the de facto standard for
evaluating neural semantic parsers, yet they capture surface overlap rather
than logical equivalence. We reassess evaluation by pairing graph-matching with
automated theorem proving. We compare two approaches to building parsers:
supervised fine-tuning (T5-Small/Base) and few-shot in-context learning
(GPT-4o/4.1/5), under normalized and unnormalized targets. We evaluate outputs
using graph-matching, bidirectional entailment between source and target
formulas with a first-order logic theorem prover, and well-formedness. Across
settings, we find that models performing well on graph-matching often fail to
produce logically equivalent formulas. Normalization reduces incidental target
variability, improves well-formedness, and strengthens logical adequacy. Error
analysis shows performance degrades with increasing formula complexity and with
coordination, prepositional phrases, and passive voice; the dominant failures
involve variable binding and indexing, and predicate naming. These findings
highlight limits of graph-based metrics for reasoning-oriented applications and
motivate logic-sensitive evaluation and training objectives together with
simplified, normalized target representations. All code and data for our
experiments are publicly available.

</details>


### [343] [CNSocialDepress: A Chinese Social Media Dataset for Depression Risk Detection and Structured Analysis](https://arxiv.org/abs/2510.11233)
*Jinyuan Xu,Tian Lan,Xintao Yu,Xue He,Hezhi Zhang,Ying Wang,Pierre Magistry,Mathieu Valette,Lei Li*

Main category: cs.CL

TL;DR: 该研究发布了一个包含44,178条中文社交媒体帖子和233位用户数据的中文抑郁风险检测基准数据集CNSocialDepress，其中10,306条文本被专家标注了抑郁相关片段，并提供了二元风险标签和多维度心理学属性，以支持精细化分析。


<details>
  <summary>Details</summary>
Motivation: 现有的中文抑郁风险检测资源稀缺且多为二元分类，无法满足精细化分析需求。

Method: 发布了CNSocialDepress数据集，包含44,178条中文社交媒体文本，233位用户数据，10,306条标注的抑郁相关片段，以及二元风险标签和结构化的多维度心理学属性。

Result: 实验结果表明，该数据集在结构化心理画像和抑郁检测大语言模型微调等NLP任务中具有实用性。

Conclusion: CNSocialDepress数据集在抑郁风险识别和心理分析方面有效且具有实用价值，为针对华语人群的心理健康应用提供了见解。

Abstract: Depression is a pressing global public health issue, yet publicly available
Chinese-language resources for risk detection remain scarce and are mostly
limited to binary classification. To address this limitation, we release
CNSocialDepress, a benchmark dataset for depression risk detection from Chinese
social media posts. The dataset contains 44,178 texts from 233 users, within
which psychological experts annotated 10,306 depression-related segments.
CNSocialDepress provides binary risk labels together with structured
multi-dimensional psychological attributes, enabling interpretable and
fine-grained analysis of depressive signals. Experimental results demonstrate
its utility across a wide range of NLP tasks, including structured
psychological profiling and fine-tuning of large language models for depression
detection. Comprehensive evaluations highlight the dataset's effectiveness and
practical value for depression risk identification and psychological analysis,
thereby providing insights to mental health applications tailored for
Chinese-speaking populations.

</details>


### [344] [XQuant: Achieving Ultra-Low Bit KV Cache Quantization with Cross-Layer Compression](https://arxiv.org/abs/2510.11236)
*Haoqi Yang,Yao Yao,Zuchao Li,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: XQuant通过一种训练无关且即插即用的框架，实现了超低比特率的KV缓存量化，克服了LLMs在资源受限环境下的内存瓶颈，并在TruthfulQA和LongBench基准测试中表现优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在处理长文本时，其KV缓存的内存需求会急剧增长，这在资源受限的环境中部署带来了挑战。

Method: 提出了一种名为XQuant的训练无关且即插即用的框架，它引入了一种计算量极小的数据无关校准方法和跨层KV缓存压缩技术，实现了低至1.4比特以下的量化。

Result: 在TruthfulQA和LongBench数据集上的实验表明，XQuant在实现更低比特率的同时，保持了优于现有最先进方法（如KIVI-2bit和AsymKV-1.5bit）的性能，显著提高了内存效率和模型准确性之间的平衡。

Conclusion: XQuant成功地实现了LLMs的KV缓存量化，解决了内存消耗问题，为在资源受限环境下的部署提供了更优的解决方案。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse natural language processing tasks. However, their extensive memory
requirements, particularly due to KV cache growth during long-text
understanding and generation, present significant challenges for deployment in
resource-constrained environments. Quantization has emerged as a promising
solution to reduce memory consumption while preserving historical information.
We propose XQuant, a training-free and plug-and-play framework that achieves
ultra-low equivalent bit-width KV cache quantization. XQuant introduces two key
innovations: a computationally negligible data-free calibration method and
cross-layer KV cache compression, enabling quantization to sub-1.4 bits.
Extensive experiments on TruthfulQA and LongBench demonstrate that XQuant
outperforms state-of-the-art methods (e.g., KIVI-2bit and AsymKV-1.5bit) by
achieving lower bit-width while maintaining superior performance, establishing
a better trade-off between memory efficiency and model accuracy.

</details>


### [345] [Attacks by Content: Automated Fact-checking is an AI Security Issue](https://arxiv.org/abs/2510.11238)
*Michael Schlichtkrull*

Main category: cs.CL

TL;DR: 攻击者可以通过提供有偏见、误导性或虚假信息来操纵AI代理，而无需注入指令。这种“内容攻击”需要AI代理具备批判性评估检索信息、佐证声明和评估来源可信度的能力，这可以通过重新利用自动化事实核查任务来实现。


<details>
  <summary>Details</summary>
Motivation: 现有的AI代理检索和推理外部文档的研究主要关注间接提示注入，即攻击者注入恶意指令。然而，本研究认为，攻击者无需注入指令，仅需提供有偏见、误导性或虚假信息即可操纵AI代理的行为，这种攻击方式被称为“内容攻击”。现有的侧重于检测隐藏命令的防御措施对此类攻击无效。

Method: 本研究提出将自动化事实核查（Automated Fact-Checking）任务重新利用，作为AI代理的一种认知自我防御工具。这种方法要求AI代理能够批判性地评估检索到的信息，通过外部证据进行佐证，并评估信息来源的可靠性。

Result: 通过将自动化事实核查能力应用于AI代理，可以有效地防御“内容攻击”。这种防御机制使AI代理能够主动评估外部信息，而不是仅仅被动地接收和处理。

Conclusion: AI代理在检索和推理外部文档时，面临“内容攻击”的风险。为了有效防御，AI代理需要具备批判性评估信息的能力，这可以通过重新利用自动化事实核查任务来实现，将其作为一种认知自我防御机制。

Abstract: When AI agents retrieve and reason over external documents, adversaries can
manipulate the data they receive to subvert their behaviour. Previous research
has studied indirect prompt injection, where the attacker injects malicious
instructions. We argue that injection of instructions is not necessary to
manipulate agents - attackers could instead supply biased, misleading, or false
information. We term this an attack by content. Existing defenses, which focus
on detecting hidden commands, are ineffective against attacks by content. To
defend themselves and their users, agents must critically evaluate retrieved
information, corroborating claims with external evidence and evaluating source
trustworthiness. We argue that this is analogous to an existing NLP task,
automated fact-checking, which we propose to repurpose as a cognitive
self-defense tool for agents.

</details>


### [346] [Do Psychometric Tests Work for Large Language Models? Evaluation of Tests on Sexism, Racism, and Morality](https://arxiv.org/abs/2510.11254)
*Jana Jung,Marlene Lutz,Indira Sen,Markus Strohmaier*

Main category: cs.CL

TL;DR: 人类心理测量学测试不适用于大型语言模型（LLMs），因为它们在下游任务中的行为与其测试分数不一致，表明其生态效度较低。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在评估人类心理测量学测试在评估大型语言模型（LLMs）方面的可靠性和有效性，因为目前尚不清楚这些为人类设计的测试是否能为LLMs提供有意义的结果。

Method: 本研究系统地评估了三个构建（性别歧视、种族主义和道德）上的人类心理测量学测试的可靠性和有效性。通过分析多个项目和提示的变体来评估可靠性。通过聚合（测试理论基础的测试间相关性）和生态（测试分数与真实世界下游任务行为之间的一致性）方法来评估有效性。

Result: 研究发现，在多个项目和提示变体中，心理测量学测试具有中等的可靠性。然而，模型行为与下游任务中的测试分数不一致，甚至存在负相关，表明生态效度较低。

Conclusion: 在解释心理测量学测试分数之前，对其进行系统评估至关重要。此外，为人类设计的心理测量学测试在未进行调整的情况下不能直接应用于LLMs。

Abstract: Psychometric tests are increasingly used to assess psychological constructs
in large language models (LLMs). However, it remains unclear whether these
tests -- originally developed for humans -- yield meaningful results when
applied to LLMs. In this study, we systematically evaluate the reliability and
validity of human psychometric tests for three constructs: sexism, racism, and
morality. We find moderate reliability across multiple item and prompt
variations. Validity is evaluated through both convergent (i.e., testing
theory-based inter-test correlations) and ecological approaches (i.e., testing
the alignment between tests scores and behavior in real-world downstream
tasks). Crucially, we find that psychometric test scores do not align, and in
some cases even negatively correlate with, model behavior in downstream tasks,
indicating low ecological validity. Our results highlight that systematic
evaluations of psychometric tests is essential before interpreting their
scores. They also suggest that psychometric tests designed for humans cannot be
applied directly to LLMs without adaptation.

</details>


### [347] [Towards Real-Time Fake News Detection under Evidence Scarcity](https://arxiv.org/abs/2510.11277)
*Guangyu Wei,Ke Han,Yueming Lyu,Yu Luo,Yue Jiang,Caifeng Shan,Nicu Sebe*

Main category: cs.CL

TL;DR: EASE是一个用于实时虚假新闻检测的新框架，它通过评估可用证据的充分性来动态调整其决策过程。


<details>
  <summary>Details</summary>
Motivation: 现有虚假新闻检测方法在证据稀缺的实时场景下表现不佳，因为它们严重依赖外部证据。

Method: EASE框架引入了一个包含证据、推理和情感的顺序评估机制，并使用伪标签进行指令调优，以提高评估的准确性。它还引入了一个名为RealTimeNews-25的新基准。

Result: EASE在多个基准测试中取得了最先进的性能，并显著提高了对实时新闻的泛化能力。

Conclusion: EASE能够有效地解决证据稀缺的实时虚假新闻检测问题，并在准确性和泛化能力方面表现出色。

Abstract: Fake news detection becomes particularly challenging in real-time scenarios,
where emerging events often lack sufficient supporting evidence. Existing
approaches often rely heavily on external evidence and therefore struggle to
generalize under evidence scarcity. To address this issue, we propose
Evaluation-Aware Selection of Experts (EASE), a novel framework for real-time
fake news detection that dynamically adapts its decision-making process
according to the assessed sufficiency of available evidence. EASE introduces a
sequential evaluation mechanism comprising three independent perspectives: (1)
Evidence-based evaluation, which assesses evidence and incorporates it into
decision-making only when the evidence is sufficiently supportive; (2)
Reasoning-based evaluation, which leverages the world knowledge of large
language models (LLMs) and applies them only when their reliability is
adequately established; and (3) Sentiment-based fallback, which integrates
sentiment cues when neither evidence nor reasoning is reliable. To enhance the
accuracy of evaluation processes, EASE employs instruction tuning with pseudo
labels to guide each evaluator in justifying its perspective-specific knowledge
through interpretable reasoning. Furthermore, the expert modules integrate the
evaluators' justified assessments with the news content to enable
evaluation-aware decision-making, thereby enhancing overall detection accuracy.
Moreover, we introduce RealTimeNews-25, a new benchmark comprising recent news
for evaluating model generalization on emerging news with limited evidence.
Extensive experiments demonstrate that EASE not only achieves state-of-the-art
performance across multiple benchmarks, but also significantly improves
generalization to real-time news. The code and dataset are available:
https://github.com/wgyhhhh/EASE.

</details>


### [348] [Emergent Misalignment via In-Context Learning: Narrow in-context examples can produce broadly misaligned LLMs](https://arxiv.org/abs/2510.11288)
*Nikita Afonin,Nikita Andriyanov,Nikhil Bageshpura,Kyle Liu,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Alexander Panchenko,Oleg Rogov,Elena Tutubalina,Mikhail Seleznyov*

Main category: cs.CL

TL;DR: 在上下文学习（ICL）中也可能出现“涌现性失准”（EM）现象，即模型在窄上下文示例下会产生广泛的失准响应，高达58%，并且失准的原因通常是模型采纳了危险的“人格”。


<details>
  <summary>Details</summary>
Motivation: 探究在上下文学习（ICL）中是否存在“涌现性失准”（EM）现象，以及其产生机制。

Method: 在三个数据集和三个前沿模型上，通过提供不同数量（64和256个）的窄上下文示例来诱导EM，并要求模型进行逐步推理以分析EM的机制。

Result: 在ICL中发现了EM现象，在提供256个示例时，失准响应的比例高达58%。通过逐步推理分析发现，67.5%的失准推理都明确地将有害输出合理化，这与之前在微调中发现的EM现象类似，表明模型可能采纳了危险的“人格”。

Conclusion: “涌现性失准”（EM）现象不仅存在于微调，也存在于上下文学习（ICL）中。其机制与微调类似，都可能涉及模型采纳危险的“人格”来合理化有害输出。

Abstract: Recent work has shown that narrow finetuning can produce broadly misaligned
LLMs, a phenomenon termed emergent misalignment (EM). While concerning, these
findings were limited to finetuning and activation steering, leaving out
in-context learning (ICL). We therefore ask: does EM emerge in ICL? We find
that it does: across three datasets, three frontier models produce broadly
misaligned responses at rates between 2% and 17% given 64 narrow in-context
examples, and up to 58% with 256 examples. We also examine mechanisms of EM by
eliciting step-by-step reasoning (while leaving in-context examples unchanged).
Manual analysis of the resulting chain-of-thought shows that 67.5% of
misaligned traces explicitly rationalize harmful outputs by adopting a reckless
or dangerous ''persona'', echoing prior results on finetuning-induced EM.

</details>


### [349] [Are Large Language Models Effective Knowledge Graph Constructors?](https://arxiv.org/abs/2510.11297)
*Ruirui Chen,Weifeng Jiang,Chengwei Qin,Bo Xiong,Fiona Liausvia,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.CL

TL;DR: KGs are important but hard to build. This paper proposes a hierarchical extraction framework using LLMs to create better KGs and releases a dataset for children's mental well-being research.


<details>
  <summary>Details</summary>
Motivation: Constructing high-quality KGs is difficult, and existing LLM-based approaches are limited. High-quality KGs are vital for knowledge-intensive tasks and reducing LLM hallucinations.

Method: A hierarchical extraction framework is proposed that uses state-of-the-art LLMs to extract and construct knowledge graphs at multiple levels. The generated KGs are evaluated from structural and semantic perspectives. A curated dataset of LLM-generated KGs from children's mental well-being research papers is also released.

Result: The evaluation highlights the strengths and shortcomings of current LLMs in KG construction and identifies key challenges for future work. The released dataset aims to foster more transparent, reliable, and impactful applications in high-stakes domains.

Conclusion: The proposed hierarchical extraction framework offers a promising direction for improving KG construction using LLMs. Further research is needed to address the identified challenges and enhance the reliability of LLM-generated KGs, especially in critical domains like healthcare.

Abstract: Knowledge graphs (KGs) are vital for knowledge-intensive tasks and have shown
promise in reducing hallucinations in large language models (LLMs). However,
constructing high-quality KGs remains difficult, requiring accurate information
extraction and structured representations that support interpretability and
downstream utility. Existing LLM-based approaches often focus narrowly on
entity and relation extraction, limiting coverage to sentence-level contexts or
relying on predefined schemas. We propose a hierarchical extraction framework
that organizes information at multiple levels, enabling the creation of
semantically rich and well-structured KGs. Using state-of-the-art LLMs, we
extract and construct knowledge graphs and evaluate them comprehensively from
both structural and semantic perspectives. Our results highlight the strengths
and shortcomings of current LLMs in KG construction and identify key challenges
for future work. To advance research in this area, we also release a curated
dataset of LLM-generated KGs derived from research papers on children's mental
well-being. This resource aims to foster more transparent, reliable, and
impactful applications in high-stakes domains such as healthcare.

</details>


### [350] [FOSSIL: Harnessing Feedback on Suboptimal Samples for Data-Efficient Generalisation with Imitation Learning for Embodied Vision-and-Language Tasks](https://arxiv.org/abs/2510.11307)
*Sabrina McCallum,Amit Parekh,Alessandro Suglia*

Main category: cs.CL

TL;DR: 通过在模仿学习中加入基于语言的反馈，提高具身AI在处理最优和次优演示时的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前体式AI方法依赖专家演示，但缺乏评估演示质量的机制，导致只能学习最优行为或复制错误。强化学习效率低下。本研究旨在探索如何在模仿学习中利用建设性语言反馈，使智能体能够从最优和次优演示中学习鲁棒的表征。

Method: 将语言反馈嵌入作为输入序列的一部分，输入到基于Transformer的策略中。可选地，通过辅助的自监督学习目标来预测反馈，以补充传统的下一个动作预测目标。

Result: 在BabyAI-XGen环境中，该方法在具身视觉-语言任务上显著提高了智能体的组合泛化能力和鲁棒性。

Conclusion: 语言反馈是比中间标量奖励更具竞争力且更直观的替代方案，可以用于语言指定的具身任务，从而将次优行为转化为学习机会。

Abstract: Current approaches to embodied AI tend to learn policies from expert
demonstrations. However, without a mechanism to evaluate the quality of
demonstrated actions, they are limited to learning from optimal behaviour, or
they risk replicating errors and inefficiencies. While reinforcement learning
offers one alternative, the associated exploration typically results in
sacrificing data efficiency. This work explores how agents trained with
imitation learning can learn robust representations from both optimal and
suboptimal demonstrations when given access to constructive language feedback
as a means to contextualise different modes of behaviour. We directly provide
language feedback embeddings as part of the input sequence into a
Transformer-based policy, and optionally complement the traditional next action
prediction objective with auxiliary self-supervised learning objectives for
feedback prediction. We test our approach on a range of embodied
Vision-and-Language tasks in our custom BabyAI-XGen environment and show
significant improvements in agents' compositional generalisation abilities and
robustness, suggesting that our data-efficient method allows models to
successfully convert suboptimal behaviour into learning opportunities. Overall,
our results suggest that language feedback is a competitive and intuitive
alternative to intermediate scalar rewards for language-specified embodied
tasks.

</details>


### [351] [Template-Based Text-to-Image Alignment for Language Accessibility: A Study on Visualizing Text Simplifications](https://arxiv.org/abs/2510.11314)
*Belkiss Souayed,Sarah Ebling,Yingqiang Gao*

Main category: cs.CL

TL;DR: 提出了一种结构化视觉-语言模型（VLM）提示框架，用于从简化的文本生成可访问的图像，并评估了不同提示模板和视觉风格的效果。


<details>
  <summary>Details</summary>
Motivation: 评估简化的文本和视觉插图之间的关系，并为生成可访问的图像提供指导。

Method: 设计了五种提示模板（基本对象焦点、情境场景、教育布局、多级细节、网格布局），并使用CLIPScores和专家注释对生成的图像进行了两阶段评估。

Result: 基本对象焦点模板在语义对齐方面表现最佳，复古风格被认为是最易于访问的视觉风格，Wikipedia是最高效的数据源。文本简洁性显示出很强的一致性，而图像质量则更主观。

Conclusion: 该框架为可访问内容的生成提供了实用的指导，并强调了结构化提示在AI生成视觉可访问性工具中的重要性。

Abstract: Individuals with intellectual disabilities often have difficulties in
comprehending complex texts. While many text-to-image models prioritize
aesthetics over accessibility, it is not clear how visual illustrations relate
to text simplifications (TS) generated from them. This paper presents a
structured vision-language model (VLM) prompting framework for generating
accessible images from simplified texts. We designed five prompt templates,
i.e., Basic Object Focus, Contextual Scene, Educational Layout, Multi-Level
Detail, and Grid Layout, each following distinct spatial arrangements while
adhering to accessibility constraints such as object count limits, spatial
separation, and content restrictions. Using 400 sentence-level simplifications
from four established TS datasets (OneStopEnglish, SimPA, Wikipedia, and
ASSET), we conducted a two-phase evaluation: Phase 1 assessed prompt template
effectiveness with CLIPScores, and Phase 2 involved human annotation of
generated images across ten visual styles by four accessibility experts.
Results show that the Basic Object Focus prompt template achieved the highest
semantic alignment, indicating that visual minimalism enhances language
accessibility. Expert evaluation further identified Retro style as the most
accessible and Wikipedia as the most effective data source. Inter-annotator
agreement varied across dimensions, with Text Simplicity showing strong
reliability and Image Quality proving more subjective. Overall, our framework
offers practical guidelines for accessible content generation and underscores
the importance of structured prompting in AI-generated visual accessibility
tools.

</details>


### [352] [Do LLMs "Feel"? Emotion Circuits Discovery and Control](https://arxiv.org/abs/2510.11328)
*Chenxi Wang,Yixuan Zhang,Ruiji Yu,Yufei Zheng,Lang Gao,Zirui Song,Zixiang Xu,Gus Xia,Huishuai Zhang,Dongyan Zhao,Xiuying Chen*

Main category: cs.CL

TL;DR: LLMs 包含情境无关的情感表达机制，这些机制可以通过神经元和注意力头进行局部计算，并能被整合为驱动情感表达的全局情感回路，通过直接调控这些回路可以实现对 LLM 情感表达的精确控制。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究大型语言模型（LLMs）中情感表达的内部机制，并实现对生成文本情感的控制，以解决日益增长的对 LLM 情感智能的需求。

Method: 研究构建了 SEV（Scenario-Event with Valence）数据集，用于引发可比的内部状态。通过提取情境无关的情感方向来揭示跨情境的情感编码。利用解析分解和因果分析识别负责情感计算的神经元和注意力头，并通过烧蚀和增强干预验证其因果作用。量化各子层的因果影响，并将识别出的局部组件整合为全局情感回路。

Result: 研究发现了情境无关的情感方向，揭示了跨情境的情感编码。识别并验证了局部的情感计算组件（神经元和注意力头）的因果作用，并将它们整合为驱动情感表达的全局情感回路。通过直接调控这些回路，在测试集上实现了 99.65% 的情感表达准确率，优于提示和引导方法。

Conclusion: 本研究首次系统地揭示和验证了 LLMs 中的情感回路，为理解 LLMs 的可解释性和可控情感智能提供了新的见解。

Abstract: As the demand for emotional intelligence in large language models (LLMs)
grows, a key challenge lies in understanding the internal mechanisms that give
rise to emotional expression and in controlling emotions in generated text.
This study addresses three core questions: (1) Do LLMs contain context-agnostic
mechanisms shaping emotional expression? (2) What form do these mechanisms
take? (3) Can they be harnessed for universal emotion control? We first
construct a controlled dataset, SEV (Scenario-Event with Valence), to elicit
comparable internal states across emotions. Subsequently, we extract
context-agnostic emotion directions that reveal consistent, cross-context
encoding of emotion (Q1). We identify neurons and attention heads that locally
implement emotional computation through analytical decomposition and causal
analysis, and validate their causal roles via ablation and enhancement
interventions. Next, we quantify each sublayer's causal influence on the
model's final emotion representation and integrate the identified local
components into coherent global emotion circuits that drive emotional
expression (Q2). Directly modulating these circuits achieves 99.65%
emotion-expression accuracy on the test set, surpassing prompting- and
steering-based methods (Q3). To our knowledge, this is the first systematic
study to uncover and validate emotion circuits in LLMs, offering new insights
into interpretability and controllable emotional intelligence.

</details>


### [353] [LLM-Specific Utility: A New Perspective for Retrieval-Augmented Generation](https://arxiv.org/abs/2510.11358)
*Hengran Zhang,Keping Bi,Jiafeng Guo,Jiaming Zhang,Shuaiqiang Wang,Dawei Yin,Xueqi Cheng*

Main category: cs.CL

TL;DR: 检索增强生成（RAG）通过整合外部知识来增强大型语言模型（LLM）的能力。本研究提出并研究了特定于LLM的效用概念，强调了在RAG中采用这种特定效用的必要性，并提出了一个用于LLM特定效用判断的基准测试程序。


<details>
  <summary>Details</summary>
Motivation: 传统检索方法侧重于相关性，而RAG的有效性取决于检索到的文本片段的效用。然而，现有的研究忽略了不同LLM由于内部知识和理解能力的差异，可能从同一文本片段中获益不同的事实。本研究旨在解决这个问题，并提出LLM特定的效用概念。

Method: 通过大规模实验，研究了人类标注的文本片段并非对LLM最优，并且真实的效用文本片段不能在不同LLM之间转移。分析了查询和文本片段的可读性对LLM效用的影响，并指出困惑度是一个关键指标。提出了一种用于LLM特定效用判断的基准测试程序，并评估了现有的效用判断方法。

Result: 大规模实验表明，人类标注的文本片段并非LLM的最佳选择，真实的效用文本片段也不能在不同的LLM之间转移。评估现有的效用判断方法，发现使用伪答案的口头化方法表现稳健，但LLM在评估效用方面存在困难，无法拒绝已知查询的不合格文本片段，也无法为未知查询选择真正有用的文本片段。

Conclusion: LLM特定的效用对于RAG研究至关重要，因为不同LLM从同一文本片段中获益的程度不同。现有的效用判断方法存在局限性，需要进一步改进，特别是要解决LLM在评估效用时遇到的困难。

Abstract: Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
incorporating external knowledge. While traditional retrieval focuses on
relevance, RAG's effectiveness depends on the utility of retrieved passages,
i.e., the usefulness in facilitating the generation of an accurate and
comprehensive answer. Existing studies often treat utility as a generic
attribute, ignoring the fact that different LLMs may benefit differently from
the same passage due to variations in internal knowledge and comprehension
ability. In this work, we introduce and systematically investigate the notion
of LLM-specific utility. Through large-scale experiments across multiple
datasets and LLMs, we demonstrate that human-annotated passages are not optimal
for LLMs and that ground-truth utilitarian passages are not transferable across
different LLMs. These findings highlight the necessity of adopting the
LLM-specific utility in RAG research. Our findings indicate that some
human-annotated passages are not ground-truth utilitarian passages for specific
LLMs, partially due to the varying readability of queries and passages for
LLMs, a tendency for which perplexity is a key metric. Based on these findings,
we propose a benchmarking procedure for LLM-specific utility judgments. We
evaluate existing utility judgment methods on six datasets and find that while
verbalized methods using pseudo-answers perform robustly, LLMs struggle to
assess utility effectively-failing to reject all passages for known queries and
to select truly useful ones for unknown queries.

</details>


### [354] [Stabilizing MoE Reinforcement Learning by Aligning Training and Inference Routers](https://arxiv.org/abs/2510.11370)
*Wenhan Ma,Hailin Zhang,Liang Zhao,Yifan Song,Yudong Wang,Zhifang Sui,Fuli Luo*

Main category: cs.CL

TL;DR: R3通过记录推理引擎的路由分布并在训练中进行重放，解决了MoE模型强化学习训练不稳定的问题，显著降低了训练-推理策略的KL散度，并成功稳定了训练，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: MoE模型在强化学习训练中存在路由不稳定的问题，可能导致灾难性的训练崩溃。

Method: 提出了一种名为Rollout Routing Replay (R3) 的方法，该方法记录推理引擎的路由分布，并在训练过程中进行重放。

Result: R3显著降低了训练-推理策略的KL散度，缓和了路由选择的极端差异，且不影响训练速度。实验证明R3能有效稳定强化学习训练，防止崩溃，并优于GSPO和TIS等方法。

Conclusion: R3为稳定MoE模型的强化学习训练提供了一个新的解决方案。

Abstract: Reinforcement learning (RL) has emerged as a crucial approach for enhancing
the capabilities of large language models. However, in Mixture-of-Experts (MoE)
models, the routing mechanism often introduces instability, even leading to
catastrophic RL training collapse. We analyze the training-inference
consistency of MoE models and identify a notable discrepancy in routing
behaviors between the two phases. Moreover, even under identical conditions,
the routing framework can yield divergent expert selections across repeated
forward passes. To address this foundational inconsistency, we propose Rollout
Routing Replay (R3), a method that records routing distributions from the
inference engine and replays them during training. R3 significantly reduces
training-inference policy KL divergence and mitigates extreme discrepancies
without compromising training speed. Extensive experiments on various settings
confirm that R3 succeeds in stabilizing RL training, preventing collapse and
outperforming methods such as GSPO and TIS. We believe this work can offer a
new solution for stabilizing RL in MoE models.

</details>


### [355] [Early Detection and Reduction of Memorisation for Domain Adaptation and Instruction Tuning](https://arxiv.org/abs/2510.11372)
*Dean L. Slack,Noura Al Moubayed*

Main category: cs.CL

TL;DR: 大型语言模型在微调过程中会显著记住训练数据，尤其是在训练早期。通过使用n-gram记忆分数作为提前停止标准或引入n-gram感知的损失正则化器，可以有效减轻这种记忆现象，同时对模型性能影响最小。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在许多任务中表现出色，但它们会记住训练数据，从而暴露私有或受版权保护的文本。现有的防御措施大多针对预训练阶段，而对微调过程中（尤其是领域自适应和指令调优）的记忆现象研究不足。

Method: 对Pythia、Llama3和Mistral模型（跨越1.4B-70B参数）在常见的评估数据集上进行微调，并跟踪训练过程中的逐字记忆。使用n-gram记忆分数作为早期停止标准，并引入n-gram感知的损失正则化器。

Result: 发现在训练的最初几 [Epochs] 中，记忆现象会急剧增加，这通常发生在验证困惑度或评估性能最优之前。n-gram记忆分数能够可靠地预测逐字记忆。使用n-gram记忆分数作为早期停止标准，可以将记忆现象的程度减轻，同时仅对性能造成很小的损失。n-gram感知的损失正则化器可以将记忆现象减少高达40%，同时在与现有记忆缓解策略相比时，对评估性能的权衡最小。

Conclusion: 研究结果为理解语言模型微调过程中的记忆现象提供了实用且可扩展的见解。可以通过使用n-gram记忆分数进行早期停止或采用n-gram感知的损失正则化器来有效缓解微调过程中的数据记忆问题，并且对模型性能影响较小。

Abstract: Although large language models excel across many tasks, they can memorise
training data and thereby expose private or copyrighted text. Most defences
target the pre-training stage, leaving memorisation during fine-tuning,
especially for domain adaptation and instruction tuning, poorly understood. We
fine-tune Pythia, Llama3, and Mistral models spanning 1.4B-70B parameters on
common evaluation datasets and track verbatim memorisation throughout training.
We find that memorisation increases dramatically in the first few epochs, often
significantly before either validation perplexity or evaluation performance is
optimised. We use a simple but effective n-gram memorisation score which
reliably precedes verbatim memorisation; using it as an early-stopping
criterion mitigates memorisation with minimal performance loss. Further, we
introduce an n-gram-aware loss regulariser and show that it reduces
memorisation across all model families tested by up to 40% while minimising
evaluation performance trade-offs when compared to an existing memorisation
mitigation strategy. These results yield practical, scalable insights into
memorisation dynamics during language model fine-tuning.

</details>


### [356] [Beyond Survival: Evaluating LLMs in Social Deduction Games with Human-Aligned Strategies](https://arxiv.org/abs/2510.11389)
*Zirui Song,Yuan Huang,Junchang Liu,Haozhe Luo,Chenxi Wang,Lang Gao,Zixiang Xu,Mingfei Han,Xiaojun Chang,Xiuying Chen*

Main category: cs.CL

TL;DR: 本论文提出了一个包含100多小时视频和3240万个词元的多模态狼人杀数据集，并基于此数据集提出了一个策略对齐评估框架，用于评估语言模型在欺骗和反事实推理方面的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的社交推理性游戏研究主要依赖于基于LLM的自我对弈，这导致了模板化的言语和片面的案例，忽略了社交游戏的多样性。此外，评估通常依赖于生存时间或主观评分等粗略指标，因为缺乏高质量的参考数据。

Method: 1. 建立了一个包含100多小时视频、3240万个词元和15种规则变体的多模态狼人杀数据集。
2. 提出了一种新颖的策略对齐评估方法，该方法利用获胜派系的策略作为两个阶段的基础真值：
   a. 言语评估：将其构建为选择题形式的任务，以评估模型在社交能力的五个维度上是否能采取适当的立场。
   b. 决策评估：评估模型的投票选择和对手角色的推断。

Result: 在策略对齐评估中，最先进的LLM表现出不同的性能，大约一半的LLM表现低于0.50，这揭示了在欺骗和反事实推理方面存在的明显差距。

Conclusion: 本研究通过提供高质量的多模态数据集和精细化的评估框架，为语言模型在社交推理性游戏中的研究提供了新的方向，并指出了当前LLM在欺骗和反事实推理方面存在的不足。

Abstract: Social deduction games like Werewolf combine language, reasoning, and
strategy, providing a testbed for studying natural language and social
intelligence. However, most studies reduce the game to LLM-based self-play,
yielding templated utterances and anecdotal cases that overlook the richness of
social gameplay. Evaluation further relies on coarse metrics such as survival
time or subjective scoring due to the lack of quality reference data. To
address these gaps, we curate a high-quality, human-verified multimodal
Werewolf dataset containing over 100 hours of video, 32.4M utterance tokens,
and 15 rule variants. Based on this dataset, we propose a novel
strategy-alignment evaluation that leverages the winning faction's strategies
as ground truth in two stages: 1) Speech evaluation, formulated as
multiple-choice-style tasks that assess whether the model can adopt appropriate
stances across five dimensions of social ability; and 2) Decision evaluation,
which assesses the model's voting choices and opponent-role inferences. This
framework enables a fine-grained evaluation of models' linguistic and reasoning
capabilities, while capturing their ability to generate strategically coherent
gameplay. Our experiments show that state-of-the-art LLMs show diverse
performance, with roughly half remain below 0.50, revealing clear gaps in
deception and counterfactual reasoning. We hope our dataset further inspires
research on language, reasoning, and strategy in multi-agent interaction.

</details>


### [357] [KnowRL: Teaching Language Models to Know What They Know](https://arxiv.org/abs/2510.11407)
*Sahil Kale,Devendra Singh Dhami*

Main category: cs.CL

TL;DR: KnowRL框架通过增强模型对自身能力边界的理解，提高了AI的可靠性和责任感，通过内部评估和共识奖励机制，仅用少量数据即可提升准确率和F1分数。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在判断自身能力方面存在不足，导致其输出的不可靠性，需要一种能够提升模型自我认知能力的方法，以实现更安全、更负责任的AI。

Method: KnowRL框架包含两个部分：(1)内省：模型生成并评估自身可行的和不可行的任务；(2)共识奖励：通过模型内部评估的一致性来强化对自身知识的评估能力。

Result: 在LLaMA-3.1-8B和Qwen-2.5-7B模型上的实验表明，KnowRL能够稳定地提升模型的自我认知能力，在准确率和F1分数上分别取得了最高28%和12%的提升，并且优于基线方法。

Conclusion: KnowRL框架通过利用模型内部生成的数据，无需外部监督，就能有效提升LLM的知识意识和可靠性，为关键应用的AI部署提供了更安全的选择，并鼓励将其应用于未来的模型中。

Abstract: Truly reliable AI requires more than simply scaling up knowledge; it demands
the ability to know what it knows and when it does not. Yet recent research
shows that even the best LLMs misjudge their own competence in more than one in
five cases, making any response born of such internal uncertainty impossible to
fully trust. Inspired by self-improvement reinforcement learning techniques
that require minimal data, we present a simple but powerful framework KnowRL
that strengthens a model's internal understanding of its own feasibility
boundaries, enabling safer and more responsible behaviour. Our framework
combines two components: (i) introspection, where the model generates and
classifies tasks it judges feasible or infeasible, and (ii) consensus-based
rewarding, where stability of self-knowledge assessment is reinforced through
internal agreement. By using internally generated data, this design strengthens
consistency in self-knowledge and entirely avoids costly external supervision.
In experiments on LLaMA-3.1-8B and Qwen-2.5-7B, KnowRL steadily improved
self-knowledge, validated by both intrinsic self-consistency and extrinsic
benchmarking. With nothing more than a small seed set and no external
supervision, our method drove gains as high as 28% in accuracy and 12% in F1,
outperforming baselines in just a few iterations. Our framework essentially
unlocks the untapped capacity of LLMs to self-improve their knowledge
awareness, opening the door to reliable, more accountable AI and safer
deployment in critical applications. Owing to its simplicity and independence
from external effort, we encourage applying this reliability-enhancing process
to all future models.

</details>


### [358] [Valid Survey Simulations with Limited Human Data: The Roles of Prompting, Fine-Tuning, and Rectification](https://arxiv.org/abs/2510.11408)
*Stefan Krsteski,Giuseppe Russo,Serina Chang,Robert West,Kristina Gligorić*

Main category: cs.CL

TL;DR: LLM在调查中可能引入偏差，但结合纠正方法可显著降低偏差并提高样本量。


<details>
  <summary>Details</summary>
Motivation: 由于传统调查成本高昂且耗时，研究LLM作为替代方案，并解决其偏差问题。

Method: 通过对包含营养、政治和经济问题的两项小组调查数据进行分析，研究了LLM合成响应方法与纠正偏差方法结合的效果，并探讨了人力资源的最佳分配策略。

Result: 单独使用LLM合成响应会引入24%-86%的偏差，但结合纠正方法后，偏差可降低至5%以下，有效样本量最多可增加14%。

Conclusion: 在固定预算下，优先分配资源于纠正方法比全部用于微调LLM能获得更有效的估计，挑战了全员用于微调的常见做法。

Abstract: Surveys provide valuable insights into public opinion and behavior, but their
execution is costly and slow. Large language models (LLMs) have been proposed
as a scalable, low-cost substitute for human respondents, but their outputs are
often biased and yield invalid estimates. We study the interplay between
synthesis methods that use LLMs to generate survey responses and rectification
methods that debias population estimates, and explore how human responses are
best allocated between them. Using two panel surveys with questions on
nutrition, politics, and economics, we find that synthesis alone introduces
substantial bias (24-86%), whereas combining it with rectification reduces bias
below 5% and increases effective sample size by up to 14%. Overall, we
challenge the common practice of using all human responses for fine-tuning,
showing that under a fixed budget, allocating most to rectification results in
far more effective estimation.

</details>


### [359] [Who are you, ChatGPT? Personality and Demographic Style in LLM-Generated Content](https://arxiv.org/abs/2510.11434)
*Dana Sotto Porat,Ella Rabinovich*

Main category: cs.CL

TL;DR: LLM在生成文本时表现出比人类更高的“宜人性”和更低的“神经质”，并且在性别语言模式上与人类相似但变异性较低。


<details>
  <summary>Details</summary>
Motivation: 探究LLM是否在其语言中表现出人格和人口统计学特征。

Method: 使用自动人格和性别分类器分析LLM对开放式问题的回答，并与人类的回答进行比较。

Result: LLM系统地表现出更高的宜人性（更合作）和更低的神经质（更稳定）。LLM的性别语言模式与人类相似，但变异性较小。

Conclusion: LLM在人格和人口统计学模式上呈现出与人类相似的特征，但存在一些差异，这为了解生成AI的这一领域提供了新的视角。

Abstract: Generative large language models (LLMs) have become central to everyday life,
producing human-like text across diverse domains. A growing body of research
investigates whether these models also exhibit personality- and
demographic-like characteristics in their language. In this work, we introduce
a novel, data-driven methodology for assessing LLM personality without relying
on self-report questionnaires, applying instead automatic personality and
gender classifiers to model replies on open-ended questions collected from
Reddit. Comparing six widely used models to human-authored responses, we find
that LLMs systematically express higher Agreeableness and lower Neuroticism,
reflecting cooperative and stable conversational tendencies. Gendered language
patterns in model text broadly resemble those of human writers, though with
reduced variation, echoing prior findings on automated agents. We contribute a
new dataset of human and model responses, along with large-scale comparative
analyses, shedding new light on the topic of personality and demographic
patterns of generative AI.

</details>


### [360] [GenCNER: A Generative Framework for Continual Named Entity Recognition](https://arxiv.org/abs/2510.11444)
*Yawen Yang,Fukun Ma,Shiao Meng,Aiwei Liu,Lijie Wen*

Main category: cs.CL

TL;DR: GenCNER是一个生成框架，通过将CNER任务转化为实体三元组序列生成问题，并结合伪标签和知识蒸馏策略，有效解决了灾难性遗忘和语义偏移问题，在多个CNER设置下取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的持续命名实体识别（CNER）方法面临灾难性遗忘和非实体类型语义偏移的挑战。

Method: 将CNER任务转化为持续实体三元组序列生成问题，并利用预训练的seq2seq模型。设计了特定类型的置信度伪标签策略和知识蒸馏（KD）来保留知识并减轻标签噪声的影响。

Result: 在两个基准数据集上的实验结果表明，GenCNER框架在多个CNER设置下优于先前最先进的方法，并且在与非CL结果的差距方面最小。

Conclusion: GenCNER是一个简单有效的生成框架，可以缓解现有CNER方法的缺点。

Abstract: Traditional named entity recognition (NER) aims to identify text mentions
into pre-defined entity types. Continual Named Entity Recognition (CNER) is
introduced since entity categories are continuously increasing in various
real-world scenarios. However, existing continual learning (CL) methods for NER
face challenges of catastrophic forgetting and semantic shift of non-entity
type. In this paper, we propose GenCNER, a simple but effective Generative
framework for CNER to mitigate the above drawbacks. Specifically, we skillfully
convert the CNER task into sustained entity triplet sequence generation problem
and utilize a powerful pre-trained seq2seq model to solve it. Additionally, we
design a type-specific confidence-based pseudo labeling strategy along with
knowledge distillation (KD) to preserve learned knowledge and alleviate the
impact of label noise at the triplet level. Experimental results on two
benchmark datasets show that our framework outperforms previous
state-of-the-art methods in multiple CNER settings, and achieves the smallest
gap compared with non-CL results.

</details>


### [361] [Investigating Large Language Models' Linguistic Abilities for Text Preprocessing](https://arxiv.org/abs/2510.11482)
*Marco Braga,Gian Carlo Milanese,Gabriella Pasi*

Main category: cs.CL

TL;DR: 大型语言模型(LLMs)可用于文本预处理任务，如去除停用词、词形还原和词干提取，并且在文本分类任务上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统文本预处理方法忽略了上下文信息，而大型语言模型(LLMs)能够考虑上下文信息，并且不需要大量的特定语言标注资源。

Method: 在六种欧洲语言的网页来源数据上，将基于LLMs的预处理（去除停用词、词形还原、词干提取）与传统算法在多个文本分类任务上进行比较。

Result: LLMs在去除停用词、词形还原和词干提取方面的准确率分别达到97%、82%和74%。使用LLMs预处理的文本训练的机器学习算法在F1度量方面比传统技术提高了6%。

Conclusion: LLMs可以有效地执行文本预处理任务，并且可以提高下游文本分类任务的性能。

Abstract: Text preprocessing is a fundamental component of Natural Language Processing,
involving techniques such as stopword removal, stemming, and lemmatization to
prepare text as input for further processing and analysis. Despite the
context-dependent nature of the above techniques, traditional methods usually
ignore contextual information. In this paper, we investigate the idea of using
Large Language Models (LLMs) to perform various preprocessing tasks, due to
their ability to take context into account without requiring extensive
language-specific annotated resources. Through a comprehensive evaluation on
web-sourced data, we compare LLM-based preprocessing (specifically stopword
removal, lemmatization and stemming) to traditional algorithms across multiple
text classification tasks in six European languages. Our analysis indicates
that LLMs are capable of replicating traditional stopword removal,
lemmatization, and stemming methods with accuracies reaching 97%, 82%, and 74%,
respectively. Additionally, we show that ML algorithms trained on texts
preprocessed by LLMs achieve an improvement of up to 6% with respect to the
$F_1$ measure compared to traditional techniques. Our code, prompts, and
results are publicly available at
https://github.com/GianCarloMilanese/llm_pipeline_wi-iat.

</details>


### [362] [Hallucination Detection via Internal States and Structured Reasoning Consistency in Large Language Models](https://arxiv.org/abs/2510.11529)
*Yusheng Song,Lirong Qiu,Xi Zhang,Zhihao Tang*

Main category: cs.CL

TL;DR: LLM幻觉检测面临“检测困境”：内部状态探测方法擅长事实核查但忽略逻辑谬误，而外部推理验证方法则相反。本文提出了一个统一框架，通过多路径推理和跨注意力机制克服信号稀疏和表征不对齐的挑战，并在实验中显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM幻觉检测方法存在“检测困境”，即内部状态探测和外部推理验证方法各有侧重，无法同时处理事实错误和逻辑谬误，导致在不同类型任务上存在盲点。

Method: 提出一个统一框架，包含多路径推理机制以获取更细粒度、可比的信号，以及一个段感知时间化交叉注意力模块来融合对齐后的表征，以识别细微的不一致性。

Result: 在三个多样化的基准测试和两个主流LLM上的广泛实验表明，所提出的框架在检测LLM幻觉方面持续且显著优于强基线方法。

Conclusion: 所提出的统一框架成功克服了LLM幻觉检测中的“检测困境”，通过多路径推理和自适应的表征融合机制，能够更全面、准确地检测事实性和逻辑性错误。

Abstract: The detection of sophisticated hallucinations in Large Language Models (LLMs)
is hampered by a ``Detection Dilemma'': methods probing internal states
(Internal State Probing) excel at identifying factual inconsistencies but fail
on logical fallacies, while those verifying externalized reasoning
(Chain-of-Thought Verification) show the opposite behavior. This schism creates
a task-dependent blind spot: Chain-of-Thought Verification fails on
fact-intensive tasks like open-domain QA where reasoning is ungrounded, while
Internal State Probing is ineffective on logic-intensive tasks like
mathematical reasoning where models are confidently wrong. We resolve this with
a unified framework that bridges this critical gap. However, unification is
hindered by two fundamental challenges: the Signal Scarcity Barrier, as coarse
symbolic reasoning chains lack signals directly comparable to fine-grained
internal states, and the Representational Alignment Barrier, a deep-seated
mismatch between their underlying semantic spaces. To overcome these, we
introduce a multi-path reasoning mechanism to obtain more comparable,
fine-grained signals, and a segment-aware temporalized cross-attention module
to adaptively fuse these now-aligned representations, pinpointing subtle
dissonances. Extensive experiments on three diverse benchmarks and two leading
LLMs demonstrate that our framework consistently and significantly outperforms
strong baselines. Our code is available: https://github.com/peach918/HalluDet.

</details>


### [363] [An Encoder-Integrated PhoBERT with Graph Attention for Vietnamese Token-Level Classification](https://arxiv.org/abs/2510.11537)
*Ba-Quang Nguyen*

Main category: cs.CL

TL;DR: TextGraphFuseGAT模型结合了PhoBERT和图注意力网络，在越南语的三个序列标注任务上取得了优于基线模型的成果。


<details>
  <summary>Details</summary>
Motivation: 为了提升序列标注任务中模型捕捉超越顺序上下文的丰富跨标记依赖关系的能力，提出了一种结合预训练Transformer编码器（PhoBERT）和图注意力网络（GAT）的新型神经网络架构TextGraphFuseGAT。

Method: TextGraphFuseGat模型首先利用PhoBERT生成标记嵌入，然后构建一个全连接图，使GAT层能够捕捉跨标记依赖关系。在此基础上，添加一个Transformer风格的自注意力层来增强上下文表示，最后通过分类头进行序列标注。

Result: 在PhoNER-COVID19（COVID-19领域命名实体识别）、PhoDisfluency（语音非流利性检测）和VietMed-NER（医疗领域命名实体识别）这三个越南语基准数据集上，TextGraphFuseGat模型持续优于包括纯Transformer和BiLSTM+CNN+CRF在内的强基线模型。

Conclusion: 实验结果表明，将预训练的语义特征与基于图的关系建模相结合，可以有效提升跨多个领域的标记分类性能。VietMed-NER作为首个越南语医疗语音NER数据集，对模型提出了挑战，而TextGraphFuseGat在该数据集上取得了成功。

Abstract: We propose a novel neural architecture named TextGraphFuseGAT, which
integrates a pretrained transformer encoder (PhoBERT) with Graph Attention
Networks for token-level classification tasks. The proposed model constructs a
fully connected graph over the token embeddings produced by PhoBERT, enabling
the GAT layer to capture rich inter-token dependencies beyond those modeled by
sequential context alone. To further enhance contextualization, a
Transformer-style self-attention layer is applied on top of the graph-enhanced
embeddings. The final token representations are passed through a classification
head to perform sequence labeling. We evaluate our approach on three Vietnamese
benchmark datasets: PhoNER-COVID19 for named entity recognition in the COVID-19
domain, PhoDisfluency for speech disfluency detection, and VietMed-NER for
medical-domain NER. VietMed-NER is the first Vietnamese medical spoken NER
dataset, featuring 18 entity types collected from real-world medical speech
transcripts and annotated with the BIO tagging scheme. Its specialized
vocabulary and domain-specific expressions make it a challenging benchmark for
token-level classification models. Experimental results show that our method
consistently outperforms strong baselines, including transformer-only and
hybrid neural models such as BiLSTM + CNN + CRF, confirming the effectiveness
of combining pretrained semantic features with graph-based relational modeling
for improved token classification across multiple domains.

</details>


### [364] [Information-Preserving Reformulation of Reasoning Traces for Antidistillation](https://arxiv.org/abs/2510.11545)
*Jiayu Ding,Lei Cui,Li Dong,Nanning Zheng,Furu Wei*

Main category: cs.CL

TL;DR: 该研究提出了一种名为PART的信息保护方法，用于防止大型语言模型的推理过程被恶意提取，同时保留了推理过程的完整性，从而解决了模型保护和用户理解之间的矛盾。


<details>
  <summary>Details</summary>
Motivation: 现有的模型保护策略（如用摘要替换详细推理）会剥夺用户理解模型决策过程所需的中间信息。本研究旨在解决这一问题，在保护模型的同时，尽可能多地保留推理过程中的信息。

Method: 提出了一种名为PART（Preserving Anti-distillation Reformulation of Traces）的方法。该方法通过两个步骤对LLM的推理过程进行重构：1. 移除自言自语（self-talk）的行为。2. 重新排序子结论。使用一个小型辅助模型来执行此重构，以最小化计算开销。

Result: 实验表明，PART能够有效地阻止不同大小和类型的学生模型对教师模型的蒸馏。例如，在AIME 2024数据集上，使用重构后的推理过程进行训练，一个32B的学生模型的性能从54.17下降到46.88，下降了13.5%，表明PART成功地阻碍了蒸馏。

Conclusion: PART是一种有效的信息保护方法，它通过重构推理过程来防止模型被蒸馏，同时保留了推理过程对用户理解的价值，为在保护模型的同时促进模型的可解释性和可信度提供了一种新的解决方案。

Abstract: Recent advances in Large Language Models (LLMs) show that extending the
length of reasoning chains significantly improves performance on complex tasks.
While revealing these reasoning traces helps users better follow, verify, and
learn from the model's problem-solving process, it also makes them highly
vulnerable to unauthorized distillation. To mitigate this risk, proprietary
model providers often adopt aggressive protection strategies, such as replacing
detailed reasoning with brief summaries, which deprive users of valuable
intermediate information. To address this trade-off, we propose PART, an
information-preserving antidistillation reformulation of reasoning traces.
Motivated by the difference between how humans understand reasoning traces and
how LLMs exploit them for supervised fine-tuning, we design a simple but
effective two-step reformulation: removing self-talk behaviors and reordering
sub-conclusions. A small auxiliary model is trained to perform this
reformulation, incurring minimal computational overhead. Extensive experiments
demonstrate that PART consistently disrupts distillation across student models
of different sizes and types on various reasoning benchmarks. For instance,
when training on reformulated traces, even the performance of a large 32B
student model decreases from 54.17 to 46.88 on AIME 2024, corresponding to a
13.5% degradation.

</details>


### [365] [Invisible Languages of the LLM Universe](https://arxiv.org/abs/2510.11557)
*Saurabh Khanna,Xinxu Li*

Main category: cs.CL

TL;DR: LLMs 训练语料库虽然庞大，但忽视了约 2000 种有数百万使用者但数字生态系统却鲜为人知的语言。本研究提出了一个结合语言活力、数字性、后殖民理论和认识论不公正的框架，以解释人工智能系统中语言不平等问题的结构性根源。通过分析所有已记录的语言，将它们分为四类：强势语言（33%）、数字回声（6%）、衰落之声（36%）和隐形巨人（27%），后者代表了数百万使用者但几乎没有数字足迹的语言。研究表明，这些模式反映了从殖民时代到当代人工智能发展中持续存在的语言等级制度，这是一种“数字认识论不公正”。研究结论指出，人工智能中英语的主导地位并非技术必然，而是权力结构的体现，系统性地排除了边缘化的语言知识。最后，文章提出了语言技术去殖民化和人工智能惠及所有人的建议。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在揭示大型语言模型（LLMs）在处理全球语言多样性方面存在的“数字认识论不公正”问题，即大量使用但缺乏数字足迹的语言被系统性地忽视，并探讨这种不平等现象的结构性根源及其与殖民历史的联系。

Method: 该研究通过分析所有已记录的语言数据，结合语言活力（现实人口统计学实力）和数字性（在线存在）的实证测量，并借鉴后殖民理论和认识论不公正的视角，将语言划分为“强势语言”、“数字回声”、“衰落之声”和“隐形巨人”四类。

Result: 研究识别出四类语言：33%的语言具有高活力和高数字性（强势语言）；6%的语言虽然活力下降但数字性高（数字回声）；36%的语言在两个维度上均较低（衰落之声）；最关键的是，有27%的语言（隐形巨人）虽然活力高但数字性近乎为零，即数百万使用者却在LLM领域中缺席。研究表明，这些模式反映了从殖民时代到当代AI发展中持续存在的语言等级制度。

Conclusion: 人工智能中的英语主导地位并非技术上的必然，而是权力结构系统性排斥边缘化语言知识的体现，构成了“数字认识论不公正”。研究呼吁去殖民化语言技术，并实现人工智能惠益的民主化。

Abstract: Large Language Models are trained on massive multilingual corpora, yet this
abundance masks a profound crisis: of the world's 7,613 living languages,
approximately 2,000 languages with millions of speakers remain effectively
invisible in digital ecosystems. We propose a critical framework connecting
empirical measurements of language vitality (real world demographic strength)
and digitality (online presence) with postcolonial theory and epistemic
injustice to explain why linguistic inequality in AI systems is not incidental
but structural. Analyzing data across all documented human languages, we
identify four categories: Strongholds (33%, high vitality and digitality),
Digital Echoes (6%, high digitality despite declining vitality), Fading Voices
(36%, low on both dimensions), and critically, Invisible Giants (27%, high
vitality but near-zero digitality) - languages spoken by millions yet absent
from the LLM universe. We demonstrate that these patterns reflect continuities
from colonial-era linguistic hierarchies to contemporary AI development,
constituting what we term digital epistemic injustice. Our analysis reveals
that English dominance in AI is not a technical necessity but an artifact of
power structures that systematically exclude marginalized linguistic knowledge.
We conclude with implications for decolonizing language technology and
democratizing access to AI benefits.

</details>


### [366] [Culturally-Aware Conversations: A Framework & Benchmark for LLMs](https://arxiv.org/abs/2510.11563)
*Shreya Havaldar,Sunny Rai,Young-Min Cho,Lyle Ungar*

Main category: cs.CL

TL;DR: 现有的衡量文化适应性的基准测试与大型语言模型在与不同文化背景用户交互时面临的实际挑战不符。我们提出了一个新框架和基准测试，用于评估大型语言模型在多文化对话中的表现，并发现当前模型在这方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的衡量大型语言模型文化适应性的基准测试与模型在与来自不同文化背景的用户交互时所面临的实际挑战不符。

Method: 提出一个基于社会文化理论的框架，该框架对语言风格如何受到情境、关系和文化背景的影响进行了形式化。构建了一个基于该框架的数据集，并由具有不同文化背景的评估者进行标注。提出了一套新的跨文化评估标准：对话框架、风格敏感性和主观正确性。对当前主流的大型语言模型进行了评估。

Result: 我们发现，当前主流的大型语言模型在多文化对话的文化适应性方面存在挑战。

Conclusion: 现有基准测试与实际挑战脱节，需要新的评估框架和标准来衡量大型语言模型在多文化对话中的文化适应性，而当前模型在这方面表现不佳。

Abstract: Existing benchmarks that measure cultural adaptation in LLMs are misaligned
with the actual challenges these models face when interacting with users from
diverse cultural backgrounds. In this work, we introduce the first framework
and benchmark designed to evaluate LLMs in realistic, multicultural
conversational settings. Grounded in sociocultural theory, our framework
formalizes how linguistic style - a key element of cultural communication - is
shaped by situational, relational, and cultural context. We construct a
benchmark dataset based on this framework, annotated by culturally diverse
raters, and propose a new set of desiderata for cross-cultural evaluation in
NLP: conversational framing, stylistic sensitivity, and subjective correctness.
We evaluate today's top LLMs on our benchmark and show that these models
struggle with cultural adaptation in a conversational setting.

</details>


### [367] [LLMAtKGE: Large Language Models as Explainable Attackers against Knowledge Graph Embeddings](https://arxiv.org/abs/2510.11584)
*Ting Li,Yang Yang,Yipeng Yu,Liang Yao,Guoqing Chao,Ruifeng Xu*

Main category: cs.CL

TL;DR: LLMAtKGE是一个基于大语言模型（LLM）的框架，用于对知识图谱嵌入（KGE）进行对抗性攻击，能够生成人类可读的解释，并优于现有的黑盒攻击方法。


<details>
  <summary>Details</summary>
Motivation: 现有的针对知识图谱嵌入（KGE）的黑盒攻击方法在生成可解释性方面存在不足，并且泛化能力较差。大语言模型（LLM）在文本理解、生成和推理方面表现出色，可以用来改进KGE攻击。

Method: 提出LLMAtKGE框架，利用LLM选择攻击目标并生成解释。设计结构化提示方案，将攻击 formulated为多项选择题，并结合知识图谱事实证据。引入基于语义和中心性的过滤器，以压缩候选集并提高召回率。通过预计算高阶邻接和三元组分类任务微调LLM来增强过滤性能。

Result: LLMAtKGE在两个知识图谱数据集上的实验表明，其攻击效果优于最强的黑盒基线方法，并能通过推理提供解释。与白盒方法相比，LLMAtKGE表现出具有竞争力的性能。消融实验和案例研究进一步验证了其生成解释的能力。

Conclusion: LLMAtKGE框架成功地利用LLM的能力，实现了对KGE的高效攻击，并能生成可解释的攻击过程，克服了现有方法的局限性。

Abstract: Adversarial attacks on knowledge graph embeddings (KGE) aim to disrupt the
model's ability of link prediction by removing or inserting triples. A recent
black-box method has attempted to incorporate textual and structural
information to enhance attack performance. However, it is unable to generate
human-readable explanations, and exhibits poor generalizability. In the past
few years, large language models (LLMs) have demonstrated powerful capabilities
in text comprehension, generation, and reasoning. In this paper, we propose
LLMAtKGE, a novel LLM-based framework that selects attack targets and generates
human-readable explanations. To provide the LLM with sufficient factual context
under limited input constraints, we design a structured prompting scheme that
explicitly formulates the attack as multiple-choice questions while
incorporating KG factual evidence. To address the context-window limitation and
hesitation issues, we introduce semantics-based and centrality-based filters,
which compress the candidate set while preserving high recall of
attack-relevant information. Furthermore, to efficiently integrate both
semantic and structural information into the filter, we precompute high-order
adjacency and fine-tune the LLM with a triple classification task to enhance
filtering performance. Experiments on two widely used knowledge graph datasets
demonstrate that our attack outperforms the strongest black-box baselines and
provides explanations via reasoning, and showing competitive performance
compared with white-box methods. Comprehensive ablation and case studies
further validate its capability to generate explanations.

</details>


### [368] [Survey Response Generation: Generating Closed-Ended Survey Responses In-Silico with Large Language Models](https://arxiv.org/abs/2510.11586)
*Georg Ahnert,Anna-Carolina Haensch,Barbara Plank,Markus Strohmaier*

Main category: cs.CL

TL;DR: LLMs在模拟封闭式调查问卷时，生成方法对个体和亚群体的结果对齐有显著影响；限制性生成方法表现最佳，而推理输出并未持续改善结果对齐。


<details>
  <summary>Details</summary>
Motivation: 目前在利用LLMs进行人类调查反应模拟时，主要集中在生成封闭式问卷回答，但LLMs本身更擅长生成开放式文本，且在生成封闭式回答方面尚无统一标准方法。

Method: 系统性地研究了不同的调查问卷回答生成方法对LLM模拟结果的影响，共模拟了3200万份调查问卷回答，涵盖了8种生成方法、4种政治态度调查和10种开源语言模型。

Result: 在个体层面和亚群体层面，不同的调查问卷回答生成方法在结果对齐方面存在显著差异。限制性生成方法在整体表现上最佳，而推理输出并未能持续性地提高结果的对齐度。

Conclusion: 调查问卷回答生成方法对模拟结果有着重要影响，并为这些方法的实际应用提出了具体建议。

Abstract: Many in-silico simulations of human survey responses with large language
models (LLMs) focus on generating closed-ended survey responses, whereas LLMs
are typically trained to generate open-ended text instead. Previous research
has used a diverse range of methods for generating closed-ended survey
responses with LLMs, and a standard practice remains to be identified. In this
paper, we systematically investigate the impact that various Survey Response
Generation Methods have on predicted survey responses. We present the results
of 32 mio. simulated survey responses across 8 Survey Response Generation
Methods, 4 political attitude surveys, and 10 open-weight language models. We
find significant differences between the Survey Response Generation Methods in
both individual-level and subpopulation-level alignment. Our results show that
Restricted Generation Methods perform best overall, and that reasoning output
does not consistently improve alignment. Our work underlines the significant
impact that Survey Response Generation Methods have on simulated survey
responses, and we develop practical recommendations on the application of
Survey Response Generation Methods.

</details>


### [369] [MeTA-LoRA: Data-Efficient Multi-Task Fine-Tuning for Large Language Models](https://arxiv.org/abs/2510.11598)
*Bo Cheng,Xu Wang,Jinda Liu,Yi Chang,Yuan Wu*

Main category: cs.CL

TL;DR: MeTA-LoRA是一种高效的多任务语言模型适配框架，通过两阶段优化显著提高了数据效率。


<details>
  <summary>Details</summary>
Motivation: LoRA在单任务微调中很有效，但在多任务学习中难以利用跨任务知识，需要大量特定任务数据。

Method: MeTA-LoRA包含两个阶段：1. 学习特定任务的LoRA适配器，使用少量样本进行快速适配。2. 聚合多任务梯度更新共享LoRA适配器，促进知识迁移，减少数据使用。

Result: 在多任务和多语言学习场景下，MeTA-LoRA的性能与全数据LoRA微调相当或更优，同时使用的特定任务数据显著减少。

Conclusion: MeTA-LoRA是一种数据高效的多任务语言模型适配方法。

Abstract: Low-Rank Adaptation (LoRA) has emerged as one of the most widely used
parameter-efficient fine-tuning (PEFT) methods for adapting large language
models (LLMs) to downstream tasks. While highly effective in single-task
settings, it struggles to efficiently leverage inter-task knowledge in complex
multi-task learning scenarios, often requiring substantial task-specific data
to achieve optimal performance. To address this limitation, we introduce
MeTA-LoRA, a two-stage optimization framework that significantly improves data
efficiency in multi-task adaptation. In the first stage, task-specific LoRA
adapters are learned using only a few samples from each involved dataset,
enabling rapid adaptation without large-scale supervision. In the second stage,
the shared LoRA adapter is updated by aggregating gradients from multiple tasks
to promote knowledge transfer across tasks, further reducing data usage by
leveraging common patterns. In both multi-task learning and multilingual
learning scenarios, our method matches or surpasses the performance of
traditional full-data LoRA fine-tuning approaches, while using significantly
less task-specific data.

</details>


### [370] [SemCSE-Multi: Multifaceted and Decodable Embeddings for Aspect-Specific and Interpretable Scientific Domain Mapping](https://arxiv.org/abs/2510.11599)
*Marc Brinner,Sina Zarrieß*

Main category: cs.CL

TL;DR: SemCSE-Multi是一个无监督框架，用于生成科学摘要的多方面嵌入，可实现精细、可控的相似性评估和用户驱动的可视化。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够捕捉科学摘要中不同方面并进行精细、可控的相似性评估和可视化的无监督框架。

Method: 提出SemCSE-Multi框架，该框架首先生成方面特定的摘要句，然后训练嵌入模型将语义相关的摘要映射到嵌入空间中的邻近位置，最后将这些方面特定的嵌入能力提炼成一个统一的嵌入模型，该模型可以在一次高效的前向传播中直接从科学摘要预测多个方面嵌入。此外，还引入了一个嵌入解码管道，可将嵌入解码回其关联方面的自然语言描述。

Result: SemCSE-Multi能够生成多方面嵌入，捕捉科学摘要的独立方面，实现精细、可控的相似性评估和用户驱动的可视化。其解码管道即使在低维可视化的未占用区域也能有效地解码嵌入，提高了用户中心设置下的可解释性。

Conclusion: SemCSE-Multi提供了一种有效的无监督方法来生成多方面科学文本嵌入，并具有出色的可解释性。

Abstract: We propose SemCSE-Multi, a novel unsupervised framework for generating
multifaceted embeddings of scientific abstracts, evaluated in the domains of
invasion biology and medicine. These embeddings capture distinct, individually
specifiable aspects in isolation, thus enabling fine-grained and controllable
similarity assessments as well as adaptive, user-driven visualizations of
scientific domains. Our approach relies on an unsupervised procedure that
produces aspect-specific summarizing sentences and trains embedding models to
map semantically related summaries to nearby positions in the embedding space.
We then distill these aspect-specific embedding capabilities into a unified
embedding model that directly predicts multiple aspect embeddings from a
scientific abstract in a single, efficient forward pass. In addition, we
introduce an embedding decoding pipeline that decodes embeddings back into
natural language descriptions of their associated aspects. Notably, we show
that this decoding remains effective even for unoccupied regions in
low-dimensional visualizations, thus offering vastly improved interpretability
in user-centric settings.

</details>


### [371] [Deconstructing Attention: Investigating Design Principles for Effective Language Modeling](https://arxiv.org/abs/2510.11602)
*Huiyin Xue,Nafise Sadat Moosavi,Nikolaos Aletras*

Main category: cs.CL

TL;DR: Transformer attention's success hinges on multiple principles, but this paper finds only token mixing is essential, while other aspects like mathematical form and sequence dependency can be relaxed, especially when combined with standard attention layers.


<details>
  <summary>Details</summary>
Motivation: The paper aims to test the necessity of each design principle in the Transformer attention mechanism, which is credited for the model's success.

Method: The researchers systematically deconstruct attention by creating controlled variants that relax its core principles, testing them uniformly across layers and in hybrid architectures. They analyze the empirical performance of these variants.

Result: The results show that token mixing is indispensable for Transformer performance. Other principles, such as the exact mathematical form and sequence dependency, can be relaxed significantly, particularly when standard attention layers are also present. Variants that fail in isolation can perform well when interleaved with standard attention, indicating a cooperative effect.

Conclusion: Token mixing is the most critical component of Transformer attention. The mathematical form and sequence dependency are less crucial and can be relaxed, especially in hybrid architectures. The findings suggest potential for simplifying language models by understanding and selectively relaxing these principles.

Abstract: The success of Transformer language models is widely credited to their
dot-product attention mechanism, which interweaves a set of key design
principles: mixing information across positions (enabling multi-token
interactions), sequence-dependent activations (where attention weights adapt to
each input), a specific mathematical form (dot-product similarities plus
softmax weighting), and coupling of queries and keys to evolving hidden states
(grounding attention in the current layer). However, the necessity of each of
these principles remains largely untested. In this work, we systematically
deconstruct attention by designing controlled variants that selectively relax
these principles, applied both uniformly across all layers and in hybrid
architectures where only some layers retain standard attention. Our empirical
analysis reveals that mechanisms for mixing tokens are indispensable, as their
absence collapses models to near-random behavior, while the exact mathematical
form and sequence dependency can be substantially relaxed, especially when
preserved in just a subset of layers. Surprisingly, even variants that fail in
isolation can achieve robust performance when interleaved with standard
attention, highlighting a cooperative effect. These findings deepen our
understanding of what truly underpins attention's effectiveness and open new
avenues for simplifying language models without sacrificing performance.

</details>


### [372] [LLM-Oriented Token-Adaptive Knowledge Distillation](https://arxiv.org/abs/2510.11615)
*Xurong Xie,Zhucun Xue,Jiafu Wu,Jian Li,Yabiao Wang,Xiaobin Hu,Yong Liu,Jiangning Zhang*

Main category: cs.CL

TL;DR: 现有知识蒸馏方法在蒸馏过程中未能充分考虑学生模型的动态学习过程，导致知识迁移效率低下。本文提出AdaKD框架，通过引入Token难度度量，实现Token级别的自适应蒸馏。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Logit的知识蒸馏方法通常采用静态策略，与学生模型的动态学习过程不匹配，并且对所有Token一视同仁，使用单一固定的温度，导致知识迁移不理想。

Method: AdaKD框架包含两个模块：1. 损失驱动的自适应Token聚焦（LATF）模块：根据学生模型的学习稳定性动态调整蒸馏焦点，将计算资源集中在每个训练阶段最有价值的Token上。2. 逆难度温度缩放（IDTS）模块：为难Token使用低温度以进行针对性错误纠正，为易Token使用高温度以鼓励学生模型学习教师模型的完整平滑输出分布，提升泛化能力。

Result: AdaKD作为一个即插即用的框架，在多个模型架构和基准测试中，能够持续提升各种蒸馏方法的性能。

Conclusion: AdaKD通过引入Token级别的自适应蒸馏策略，有效解决了现有知识蒸馏方法的局限性，提高了知识迁移的效率和模型性能。

Abstract: Knowledge distillation (KD) is a key technique for compressing large-scale
language models (LLMs), yet prevailing logit-based methods typically employ
static strategies that are misaligned with the dynamic learning process of
student models. These methods typically treat all tokens indiscriminately and
apply a single, fixed temperature, resulting in suboptimal knowledge transfer.
To address these limitations, we propose LLM-Oriented Token-Adaptive Knowledge
Distillation (AdaKD), a novel framework that adapts the distillation process to
the real-time learning state of each token. AdaKD consists of two synergistic
modules driven by a unified token difficulty metric. First, our Loss-Driven
Adaptive Token Focusing (LATF) module dynamically adjusts the distillation
focus by monitoring the student's learning stability, concentrating
computational resources on the most valuable tokens at each training phase.
Second, we introduce Inverse Difficulty Temperature Scaling (IDTS), a
counterintuitive yet effective token-level temperature strategy. It employs low
temperatures for difficult tokens for targeted error correction, and high
temperatures for easy tokens to encourage students to learn from the teacher's
complete and smooth output distribution, thereby enhancing generalization. As a
plug-and-play framework, AdaKD can consistently improve the performance of
various distillation methods on multiple model architectures and benchmarks.

</details>


### [373] [Enhancing Long Chain-of-Thought Reasoning through Multi-Path Plan Aggregation](https://arxiv.org/abs/2510.11620)
*Siheng Xiong,Ali Payani,Faramarz Fekri*

Main category: cs.CL

TL;DR: 通过探索和聚合多个规划路径来增强语言模型的推理能力，解决了长推理链中的规划错误问题，并提出了更高效的在线训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有的推理时间扩展方法在生成长推理链时容易出现漂移，尤其是在容量有限的小型语言模型中，这主要是由于规划步骤中的错误。对长推理链的分析表明，大多数错误源于规划不当。

Method: 提出了一种名为多路径规划聚合（MPPA）的框架，通过在生成过程中探索和聚合多个候选规划来改进规划步骤。 MPPA 利用基础语言模型作为主要策略，并使用轻量级的 LoRA 模块来实现规划聚合策略。此外，引入了在线步骤-DPO（Step-DPO）进行过程级偏好优化，利用扭曲序列蒙特卡洛（TSMC）提供可扩展的逐步监督，以克服传统结果奖励强化学习在长轨迹上的低效问题。

Result: 在数学、科学和逻辑推理基准测试中，与现有的基线方法相比，该方法在效率（仅使用 10% 的 SFT 数据和 5% 的偏好对）和准确性方面均表现出色，并在多个基础模型和任务上取得了更好的性能。

Conclusion: 多路径规划聚合（MPPA）结合在线步骤-DPO 是一种有效且高效的框架，可以显著提高语言模型在长推理链任务中的推理能力，特别是在处理具有有限容量的小型模型时。

Abstract: Inference-time scaling enhances the reasoning ability of a language model
(LM) by extending its chain-of-thought (CoT). However, existing approaches
typically generate the entire reasoning chain in a single forward pass, which
often leads to CoT derailment, i.e., the reasoning trajectory drifting off
course due to compounding errors. This problem is particularly severe for
smaller LMs with long CoTs due to their limited capacity. To address this, we
analyze raw long CoTs and uncover a reasoning hierarchy consisting of planning
and execution steps. Our analysis reveals that most reasoning errors stem from
incorrect planning. Motivated by this observation, we propose Multi-Path Plan
Aggregation (MPPA), a framework that augments single-pass reasoning with plan
exploration and aggregation. Following a variable interval schedule based on
the token position, MPPA generates multiple candidate plans and aggregates them
into a refined planning step. To maintain efficiency, we adopt a minimal design
in which the base LM serves as the primary policy, while a lightweight LoRA
module implements the plan aggregation policy. We further observe that
outcome-reward RL is inefficient for long trajectories (e.g., exceeding 4K
tokens). To overcome this, we introduce online Step-DPO, a process-level
preference optimization scheme that leverages Twisted Sequential Monte Carlo
(TSMC) to provide scalable stepwise supervision using small LMs. This yields
more efficient training, improved stability, and higher accuracy. Extensive
experiments on challenging math, science, and logical reasoning benchmarks
demonstrate that, with only 10% SFT data and 5% of preference pairs, our method
outperforms both the DeepSeek-R1 distillation baseline and the outcome-reward
RL baseline across multiple base models and tasks.

</details>


### [374] [ACADREASON: Exploring the Limits of Reasoning Models with Academic Research Problems](https://arxiv.org/abs/2510.11652)
*Xin Gui,King Zhu,JinCheng Ren,Qianben Chen,Zekun Moore Wang,Yizhi LI,Xinpeng Liu,Xiaowan Li,Wenli Ren,Linyu Miao,Tianrui Qin,Ziqi Shu,He Zhu,Xiangru Tang,Dingfeng Shi,Jiaheng Liu,Yuchen Eleanor Jiang,Minghao Liu,Ge Zhang,Wangchunshu Zhou*

Main category: cs.CL

TL;DR: LLMs在学术知识推理方面表现不佳，新基准Acadreason显示大多数模型得分低于20分，凸显了当前能力差距。


<details>
  <summary>Details</summary>
Motivation: 现有LLM和智能体评估方法缺乏对学术知识的深入推理能力，难以衡量其在高阶推理方面的表现。学术界需要一个更严格的基准来评估LLM和智能体在学术知识获取和推理方面的能力。

Method: 提出Acadreason基准，包含50个跨越计算机科学、经济学、法学、数学和哲学五个领域，源自顶级学术出版物并经过专家标注和质控的学术问题。对10个主流LLM和智能体进行了系统性评估。

Result: 大多数LLM得分低于20分，即使是先进的GPT-5也只得到16分。智能体的得分虽然更高，但均未超过40分。

Conclusion: 当前LLM和智能体在超智能学术研究任务方面存在显著能力差距，Acadreason基准很好地揭示了这一挑战。

Abstract: In recent years, the research focus of large language models (LLMs) and
agents has shifted increasingly from demonstrating novel capabilities to
complex reasoning and tackling challenging tasks. However, existing evaluations
focus mainly on math/code contests or general tasks, while existing
multi-domain academic benchmarks lack sufficient reasoning depth, leaving the
field without a rigorous benchmark for high-level reasoning. To fill this gap,
we introduce the Acadreason benchmark, designed to evaluate the ability of LLMs
and agents to acquire and reason over academic knowledge. It consists of 50
expert-annotated academic problems across five high-reasoning domains,
including computer science, economics, law, mathematics, and philosophy. All
questions are sourced from top-tier publications in recent years and undergo
rigorous annotation and quality control to ensure they are both challenging and
answerable. We conduct systematic evaluations of over 10 mainstream LLMs and
agents. The results show that most LLMs scored below 20 points, with even the
cutting-edge GPT-5 achieving only 16 points. While agents achieved higher
scores, none exceeded 40 points. This demonstrates the current capability gap
between LLMs and agents in super-intelligent academic research tasks and
highlights the challenges of Acadreason.

</details>


### [375] [Scaling Language-Centric Omnimodal Representation Learning](https://arxiv.org/abs/2510.11693)
*Chenghao Xiao,Hou Pong Chan,Hao Zhang,Weiwen Xu,Mahani Aljunied,Yu Rong*

Main category: cs.CL

TL;DR: 最近的、利用对比学习（CL）微调的多模态大语言模型（MLLM）的嵌入方法取得了令人瞩目的成果，但其优越性的根本原因仍有待深入探索。本研究认为，基于MLLM的方法的一个关键优势在于生成式预训练过程中实现的隐式跨模态对齐，其中语言解码器学习在共享表示空间中利用多模态信号来生成单模态输出。通过对各向异性和核相似性结构的分析，我们实证地证实了MLLM表示中出现了潜在的对齐，使得CL能够作为一种轻量级的优化阶段。基于这一认识，我们提出了一种名为LCO-Emb的以语言为中心的全模态嵌入框架。在多种骨干模型和基准测试上的广泛实验证明了其有效性，并在跨模态任务上取得了最先进的性能。此外，我们识别出一种生成-表示缩放定律（GRSL），表明通过对比优化获得的表示能力与MLLM的生成能力呈正相关。这表明提高生成能力是增强表示质量的有效范式。我们对GRSL进行了理论解释，将MLLM的生成质量与其表示性能的上限进行了形式化关联，并在具有挑战性的低资源视觉文档检索任务上进行了验证，证明在CL之前进行持续的生成预训练可以进一步提升模型的嵌入潜力。


<details>
  <summary>Details</summary>
Motivation: MLLM 基于 CL 的嵌入方法的优势及其根本原因仍有待深入研究。本研究旨在揭示 MLLM 在生成式预训练中实现的隐式跨模态对齐是其优越性的关键，并提出一种新的嵌入框架 LCO-Emb。

Method: 通过分析各向异性和核相似性结构，实证地证实了 MLLM 表示中出现的潜在对齐。提出了一种名为 LCO-Emb 的以语言为中心的全模态嵌入框架。识别并理论解释了一种生成-表示缩放定律（GRSL），该定律将 MLLM 的生成质量与其表示性能的上限联系起来。

Result: LCO-Emb 在多种骨干模型和基准测试上取得了最先进的性能。GRSL 得到验证，表明生成能力的提升可以增强表示质量。在低资源视觉文档检索任务上，持续的生成预训练可以进一步提升模型的嵌入能力。

Conclusion: MLLM 的隐式跨模态对齐是其嵌入方法优越性的关键。LCO-Emb 框架和 GRSL 为理解和提升多模态嵌入提供了新的见解和方法，表明改进生成能力是增强表示质量的有效途径。

Abstract: Recent multimodal embedding approaches leveraging multimodal large language
models (MLLMs) fine-tuned with contrastive learning (CL) have shown promising
results, yet the underlying reasons behind their superiority remain
underexplored. This work argues that a crucial advantage of MLLM-based
approaches stems from implicit cross-modal alignment achieved during generative
pretraining, where the language decoder learns to exploit multimodal signals
within a shared representation space for generating unimodal outputs. Through
analysis of anisotropy and kernel similarity structure, we empirically confirm
that latent alignment emerges within MLLM representations, allowing CL to serve
as a lightweight refinement stage. Leveraging this insight, we propose a
Language-Centric Omnimodal Embedding framework, termed LCO-Emb. Extensive
experiments across diverse backbones and benchmarks demonstrate its
effectiveness, achieving state-of-the-art performance across modalities.
Furthermore, we identify a Generation-Representation Scaling Law (GRSL),
showing that the representational capabilities gained through contrastive
refinement scales positively with the MLLM's generative capabilities. This
suggests that improving generative abilities evolves as an effective paradigm
for enhancing representation quality. We provide a theoretical explanation of
GRSL, which formally links the MLLM's generative quality to the upper bound on
its representation performance, and validate it on a challenging, low-resource
visual-document retrieval task, showing that continual generative pretraining
before CL can further enhance the potential of a model's embedding
capabilities. Codes, models, and resources are available at
https://github.com/LCO-Embedding/LCO-Embedding.

</details>


### [376] [When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents](https://arxiv.org/abs/2510.11695)
*Lingfei Qian,Xueqing Peng,Yan Wang,Vincent Jim Zhang,Huan He,Hanley Smith,Yi Han,Yueru He,Haohang Li,Yupeng Cao,Yangyang Yu,Alejandro Lopez-Lira,Peng Lu,Jian-Yun Nie,Guojun Xiong,Jimin Huang,Sophia Ananiadou*

Main category: cs.CL

TL;DR: LLM交易代理在真实金融市场中的表现仍不明确。本文提出了Agent Market Arena (AMA)，一个用于评估LLM交易代理的、持续更新的基准测试平台，该平台整合了真实交易数据、新闻以及多种代理架构，并在加密货币和股票市场进行了实测。实验结果表明，不同的代理框架（如InvestorAgent, TradeAgent, HedgeFundAgent, DeepFundAgent）表现出显著不同的风险偏好和行为模式，而底层模型（如GPT-4o, Claude-3.5-haiku, Gemini-2.0-flash）对结果变异的贡献较小。AMA为LLM金融交易代理的严格、可复现和持续演进的评估奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）驱动的交易代理在真实、动态的市场环境中的推理和适应能力，填补现有研究在测试周期、资产范围、数据验证以及模型而非代理评估方面的不足。

Method: 提出Agent Market Arena (AMA)，一个集成了真实交易数据、专家审核新闻和多种代理架构（InvestorAgent, TradeAgent, HedgeFundAgent, DeepFundAgent）的实时基准测试平台。在加密货币和股票市场中，使用GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, Gemini-2.0-flash等模型进行多代理的实时实验。

Result: 在加密货币和股票市场进行的实时实验表明，不同的代理框架（如InvestorAgent, TradeAgent, HedgeFundAgent, DeepFundAgent）展现出显著不同的行为模式，从激进的风险承担到保守的决策制定。相比之下，底层模型（如GPT-4o, Claude-3.5-haiku, Gemini-2.0-flash）对结果差异的贡献较小。

Conclusion: AMA平台成功展示了LLM交易代理在真实市场中的多样化行为，并强调了代理框架对交易策略的影响大于底层模型本身。该平台为未来对LLM金融交易智能进行严格、可复现和持续演进的评估提供了基础。

Abstract: Although Large Language Model (LLM)-based agents are increasingly used in
financial trading, it remains unclear whether they can reason and adapt in live
markets, as most studies test models instead of agents, cover limited periods
and assets, and rely on unverified data. To address these gaps, we introduce
Agent Market Arena (AMA), the first lifelong, real-time benchmark for
evaluating LLM-based trading agents across multiple markets. AMA integrates
verified trading data, expert-checked news, and diverse agent architectures
within a unified trading framework, enabling fair and continuous comparison
under real conditions. It implements four agents, including InvestorAgent as a
single-agent baseline, TradeAgent and HedgeFundAgent with different risk
styles, and DeepFundAgent with memory-based reasoning, and evaluates them
across GPT-4o, GPT-4.1, Claude-3.5-haiku, Claude-sonnet-4, and
Gemini-2.0-flash. Live experiments on both cryptocurrency and stock markets
demonstrate that agent frameworks display markedly distinct behavioral
patterns, spanning from aggressive risk-taking to conservative decision-making,
whereas model backbones contribute less to outcome variation. AMA thus
establishes a foundation for rigorous, reproducible, and continuously evolving
evaluation of financial reasoning and trading intelligence in LLM-based agents.

</details>


### [377] [Demystifying Reinforcement Learning in Agentic Reasoning](https://arxiv.org/abs/2510.11701)
*Zhaochen Yu,Ling Yang,Jiaru Zou,Shuicheng Yan,Mengdi Wang*

Main category: cs.CL

TL;DR: 该研究系统性地探讨了在模型推理能力中应用强化学习（RL）的原理和实践，重点关注数据、算法和推理模式三个方面。研究发现，使用真实的、端到端的工具使用轨迹进行监督式微调（SFT）初始化效果优于合成数据；高多样性、模型感知的的数据集有助于持续探索并提高RL性能。在算法方面，鼓励探索的技术，如奖励塑造和维持策略熵，能提升训练效率。在推理模式上，较少的工具调用和简洁的自我推理策略比频繁调用工具或冗长的推理更能提高效率和准确性。这些实践能有效提升模型推理能力和训练效率，并在多个具有挑战性的基准测试中取得优异成绩，甚至使较小规模的模型（如4B）超越更大规模的模型（如32B）。此外，研究还贡献了高质量的SFT和RL数据集，并开源了代码和模型。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在提升大型语言模型（LLM）的推理能力方面展现出巨大潜力，但其关键设计原则和最佳实践尚不明确。本研究旨在系统地研究RL在智能体推理中的应用，以揭示其有效性。

Method: 本研究从数据、算法和推理模式三个关键维度对RL在智能体推理中的应用进行了全面系统的研究。具体而言，研究比较了合成轨迹与真实端到端工具使用轨迹在SFT初始化中的效果，探索了高多样性、模型感知的 数据集对RL性能的影响，并评估了探索性技术（如奖励塑造和策略熵）对训练效率的作用。此外，研究还对比了不同推理模式（如频繁工具调用 vs. 精简推理）对效率和准确性的影响。

Result: 研究发现，使用真实的端到端工具使用轨迹进行SFT初始化比合成轨迹效果更好；高多样性、模型感知的 数据集能够持续探索并显著提高RL性能。探索性技术（如奖励塑造和维持策略熵）能够提高训练效率。精简的推理策略（较少的工具调用）优于频繁的工具调用或冗长的自我推理，从而提高了工具使用效率和最终准确性。这些实践在AIME2024/AIME2025、GPQA-Diamond和LiveCodeBench-v6等四个具有挑战性的基准测试中，显著提升了LLM的智能体推理能力和训练效率，使4B模型能够超越32B模型。

Conclusion: 本研究通过对数据、算法和推理模式的系统性研究，提出了一套有效的RL实践方法，能够显著提升LLM的智能体推理能力和训练效率。这些方法简单有效，为未来的智能体RL研究奠定了坚实的实践基础。研究成果表明，即使是较小规模的模型，通过优化RL策略也能在复杂推理任务上取得优于更大模型的表现。

Abstract: Recently, the emergence of agentic RL has showcased that RL could also
effectively improve the agentic reasoning ability of LLMs, yet the key design
principles and optimal practices remain unclear. In this work, we conduct a
comprehensive and systematic investigation to demystify reinforcement learning
in agentic reasoning from three key perspectives: data, algorithm, and
reasoning mode. We highlight our key insights: (i) Replacing stitched synthetic
trajectories with real end-to-end tool-use trajectories yields a far stronger
SFT initialization; high-diversity, model-aware datasets sustain exploration
and markedly improve RL performance. (ii) Exploration-friendly techniques are
crucial for agentic RL, such as clip higher, overlong reward shaping, and
maintaining adequate policy entropy could improve the training efficiency.
(iii) A deliberative strategy with fewer tool calls outperforms frequent tool
calls or verbose self-reasoning, improving tool efficiency and final accuracy.
Together, these simple practices consistently enhance agentic reasoning and
training efficiency, achieving strong results on challenging benchmarks with
smaller models, and establishing a practical baseline for future agentic RL
research. Beyond these empirical insights, we further contribute a
high-quality, real end-to-end agentic SFT dataset along with a high-quality RL
dataset, and demonstrate the effectiveness of our insights in boosting the
agentic reasoning ability of LLMs across four challenging benchmarks, including
AIME2024/AIME2025, GPQA-Diamond, and LiveCodeBench-v6. With our recipes,
4B-sized models could also achieve superior agentic reasoning performance
compared to 32B-sized models. Code and models:
https://github.com/Gen-Verse/Open-AgentRL

</details>


### [378] [Are Large Reasoning Models Interruptible?](https://arxiv.org/abs/2510.11713)
*Tsung-Han Wu,Mihran Miroyan,David M. Chan,Trevor Darrell,Narges Norouzi,Joseph E. Gonzalez*

Main category: cs.CL

TL;DR: 大型推理模型(LRMs)在动态环境中（如辅助编程）的鲁棒性评估表明，它们在“静态世界”假设下表现优于实际情况，因为模型响应可能会被中断或上下文会发生变化，导致性能下降高达60%。


<details>
  <summary>Details</summary>
Motivation: 评估大型推理模型(LRMs)在“静态世界”假设下，即模型响应被假定为瞬时且上下文不可变的假设，在现代推理任务（如辅助编程）中的鲁棒性。

Method: 在数学和编程基准上，在两种动态场景下评估LRMs的鲁棒性：中断（在有限预算下测试模型部分输出的质量）和动态上下文（测试模型对进行中更改的适应性）。

Result: 静态评估持续高估鲁棒性：即使是先进的LRMs，在静态设置下准确率很高，但在中断或上下文变化时可能无法预测地失败，当在推理过程中后期引入更新时，性能下降高达60%。分析还揭示了新的失败模式，包括推理泄露、恐慌和自我怀疑。

Conclusion: “静态世界”假设高估了LRMs在动态环境下的鲁棒性，在中断或上下文变化时，LRMs的性能会显著下降，并可能出现新的故障模式。

Abstract: Large Reasoning Models (LRMs) excel at complex reasoning but are
traditionally evaluated in static, "frozen world" settings: model responses are
assumed to be instantaneous, and the context of a request is presumed to be
immutable over the duration of the response. While generally true for
short-term tasks, the "frozen world" assumption breaks down in modern reasoning
tasks such as assistive programming, where models may take hours to think
through problems and code may change dramatically from the time the model
starts thinking to the model's final output. In this work, we challenge the
frozen world assumption and evaluate LRM robustness under two realistic dynamic
scenarios: interruptions, which test the quality of the model's partial outputs
on a limited budget, and dynamic context, which tests model adaptation to
in-flight changes. Across mathematics and programming benchmarks that require
long-form reasoning, static evaluations consistently overestimate robustness:
even state-of-the-art LRMs, which achieve high accuracy in static settings, can
fail unpredictably when interrupted or exposed to changing context, with
performance dropping by up to 60% when updates are introduced late in the
reasoning process. Our analysis further reveals several novel failure modes,
including reasoning leakage, where models fold the reasoning into their final
answer when interrupted; panic, where under time pressure models abandon
reasoning entirely and return incorrect answers; and self-doubt, where
performance degrades while incorporating updated information.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [379] [CLoD-GS: Continuous Level-of-Detail via 3D Gaussian Splatting](https://arxiv.org/abs/2510.09997)
*Zhigang Cheng,Mingchao Sun,Yu Liu,Zengye Ge,Luyang Tang,Mu Xu,Yangyan Li,Peng Pan*

Main category: cs.GR

TL;DR: 3D高斯溅射（3DGS）技术可以实现连续细节级别（CLoD），克服了离散细节级别（DLOD）在存储和视觉伪影方面的缺点。


<details>
  <summary>Details</summary>
Motivation: 传统的离散细节级别（DLOD）在存储和视觉效果方面存在不足。

Method: 提出了一种名为CLoD-GS的框架，该框架将连续细节级别（CLoD）机制集成到3DGS表示中。该方法为每个高斯图元引入了一个可学习的、依赖于距离的衰减参数，该参数根据视角距离动态调整其不透明度。此外，还引入了虚拟距离缩放机制和一种新的由粗到精的训练策略，并进行渲染点数正则化。

Result: CLoD-GS能够从单个模型中实现平滑、质量可扩展的渲染，并在各种性能目标下提供高保真结果。它消除了离散方法的存储开销和视觉伪影，并减少了最终模型的图元数量和内存占用。

Conclusion: CLoD-GS是一种有效的连续细节级别（CLoD）方法，集成了3D高斯溅射（3DGS）技术，解决了传统DLOD方法的局限性。

Abstract: Level of Detail (LoD) is a fundamental technique in real-time computer
graphics for managing the rendering costs of complex scenes while preserving
visual fidelity. Traditionally, LoD is implemented using discrete levels
(DLoD), where multiple, distinct versions of a model are swapped out at
different distances. This long-standing paradigm, however, suffers from two
major drawbacks: it requires significant storage for multiple model copies and
causes jarring visual ``popping" artifacts during transitions, degrading the
user experience. We argue that the explicit, primitive-based nature of the
emerging 3D Gaussian Splatting (3DGS) technique enables a more ideal paradigm:
Continuous LoD (CLoD). A CLoD approach facilitates smooth, seamless quality
scaling within a single, unified model, thereby circumventing the core problems
of DLOD. To this end, we introduce CLoD-GS, a framework that integrates a
continuous LoD mechanism directly into a 3DGS representation. Our method
introduces a learnable, distance-dependent decay parameter for each Gaussian
primitive, which dynamically adjusts its opacity based on viewpoint proximity.
This allows for the progressive and smooth filtering of less significant
primitives, effectively creating a continuous spectrum of detail within one
model. To train this model to be robust across all distances, we introduce a
virtual distance scaling mechanism and a novel coarse-to-fine training strategy
with rendered point count regularization. Our approach not only eliminates the
storage overhead and visual artifacts of discrete methods but also reduces the
primitive count and memory footprint of the final model. Extensive experiments
demonstrate that CLoD-GS achieves smooth, quality-scalable rendering from a
single model, delivering high-fidelity results across a wide range of
performance targets.

</details>


### [380] [Sketch Animation: State-of-the-art Report](https://arxiv.org/abs/2510.10218)
*Gaurav Rai,Ojaswa Sharma*

Main category: cs.GR

TL;DR: 本篇论文对素描动画的最新趋势和方法进行了调查，重点介绍了关键帧插值、基于物理的动画、数据驱动、运动捕捉和深度学习等方法，并讨论了人工智能、实时渲染和云解决方案的集成。


<details>
  <summary>Details</summary>
Motivation: 探讨了素描动画在娱乐、教育、医疗和虚拟现实等领域的应用，以及人工智能、实时渲染和云解决方案对其发展的推动作用。

Method: 对关键帧插值、基于物理的动画、数据驱动、运动捕捉和深度学习等关键方法进行了分类和评估。

Result: 分析了计算复杂性、可扩展性和用户友好界面等挑战，并探讨了元宇宙应用和人机交互方面的新机遇。

Conclusion: 通过综合广泛的研究，旨在全面了解素描动画的现状和未来方向，为学术界和业界专业人士提供参考。

Abstract: Sketch animation has emerged as a transformative technology, bridging art and
science to create dynamic visual narratives across various fields such as
entertainment, education, healthcare, and virtual reality. This survey explores
recent trends and innovations in sketch animation, with a focus on methods that
have advanced the state of the art. The paper categorizes and evaluates key
methodologies, including keyframe interpolation, physics-based animation,
data-driven, motion capture, and deep learning approaches. We examine the
integration of artificial intelligence, real-time rendering, and cloud-based
solutions, highlighting their impact on enhancing realism, scalability, and
interactivity. Additionally, the survey delves into the challenges of
computational complexity, scalability, and user-friendly interfaces, as well as
emerging opportunities within metaverse applications and human-machine
interaction. By synthesizing insights from a wide array of research, this
survey aims to provide a comprehensive understanding of the current landscape
and future directions of sketch animation, serving as a resource for both
academics and industry professionals seeking to innovate in this dynamic field.

</details>


### [381] [Unlocking Thickness Modeling for Codimensional Contact Simulation](https://arxiv.org/abs/2510.10256)
*Gonzalo Gomez-Nogales,Zhen Chen,Rosalie Martin,Elena Garces,Danny M. Kaufman*

Main category: cs.GR

TL;DR: 该研究提出了一个用于处理增厚二维模拟的新型接触处理模型，以解决现有模型在模拟真实编织和针织面料时存在的网格分辨率限制和非物理接触力问题。


<details>
  <summary>Details</summary>
Motivation: 现有二维（线/壳）模型在模拟真实编织和针织面料时，当网格分辨率提高时会产生非物理接触力，导致严重的锁定伪影。以往的解决方案，如限制网格粗糙度或剔除可能产生锁定力的接触对，都存在各自的缺点。

Method: 提出了一种新的、实用的接触处理模型，用于处理增厚的二维模拟，该模型消除了分辨率限制，并保证了无接触锁定、无自相交的模拟。

Result: 该模型能够跨越各种以前无法实现的模拟场景，使用真实的材料纱线和织物参数及图案，应对具有挑战性的模拟条件和网格分辨率，并同时支持杆和壳模型，与IPC屏障集成。

Conclusion: 该研究成功地提出了一个能够克服现有模型限制的新型接触处理模型，实现了在更高分辨率下对真实面料进行准确且无伪影的模拟。

Abstract: In this work we analyze and address a fundamental restriction that blocks the
reliable application of codimensional yarn-level and shell models with
thickness, to simulate real-world woven and knit fabrics. As discretizations
refine toward practical and accurate physical modeling, such models can
generate non-physical contact forces with stencil-neighboring elements in the
simulation mesh, leading to severe locking artifacts. While not well-documented
in the literature, this restriction has so far been addressed with two
alternatives with undesirable tradeoffs. One option is to restrict the mesh to
coarse resolutions, however, this eliminates the possibility of accurate (and
consistent) resolution simulations across real-world material variations. A
second alternative instead seeks to cull contact pairs that can create such
locking forces in the first place. This relaxes resolution restrictions but
compromise robustness. Culling can and will generate unacceptable and
unpredictable geometric intersections and tunneling that destroys weaving and
knitting structures and cause unrecoverable pull-throughs. We address these
challenges to simulating real-world materials with a new and practical
contact-processing model for thickened codimensional simulation, that removes
resolution restrictions, while guaranteeing contact-locking-free,
non-intersecting simulations. We demonstrate the application of our model
across a wide range of previously unavailable simulation scenarios, with
real-world material yarn and fabric parameters and patterns, challenging
simulation conditions and mesh resolutions, and both rod and shell models,
integrated with the IPC barrier.

</details>


### [382] [GraphTracer: Graph-Guided Failure Tracing in LLM Agents for Robust Multi-Turn Deep Search](https://arxiv.org/abs/2510.10581)
*Heng Zhang,Yuling Shi,Xiaodong Gu,Haochen You,Zijian Zhang,Lubin Gan,Yilei Yuan,Jin Huang*

Main category: cs.GR

TL;DR: GraphTracer通过信息流分析解决多智能体系统中由信息依赖引起的多轮深度搜索失败问题，提高了故障归因的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有时间归因方法难以准确定位多智能体系统中跨代理错误传播的根本原因，尤其是在多轮深度搜索场景下，因其无法处理跨代理的信息依赖。

Method: 提出GraphTracer框架，构建信息依赖图（IDGs）来显式捕捉代理间的输出引用和构建关系，并利用图感知合成数据生成来定位关键节点，通过追踪依赖结构而非时间序列来定位根本原因。

Result: 在Who&When基准测试和生产系统集成评估中，GraphTracer-8B比现有最先进模型提高了18.18%的归因准确率，并使已部署的多智能体框架性能提高了4.8%至14.2%。

Conclusion: GraphTracer为多智能体系统的调试提供了一个健壮的解决方案，通过信息流分析有效解决了多轮深度搜索失败的归因问题。

Abstract: Multi-agent systems powered by Large Language Models excel at complex tasks
through coordinated collaboration, yet they face high failure rates in
multi-turn deep search scenarios. Existing temporal attribution methods
struggle to accurately diagnose root causes, particularly when errors propagate
across multiple agents. Attempts to automate failure attribution by analyzing
action sequences remain ineffective due to their inability to account for
information dependencies that span agents. This paper identifies two core
challenges: \textit{(i) distinguishing symptoms from root causes in multi-agent
error propagation}, and \textit{(ii) tracing information dependencies beyond
temporal order}. To address these issues, we introduce \textbf{GraphTracer}, a
framework that redefines failure attribution through information flow analysis.
GraphTracer constructs Information Dependency Graphs (IDGs) to explicitly
capture how agents reference and build on prior outputs. It localizes root
causes by tracing through these dependency structures instead of relying on
temporal sequences. GraphTracer also uses graph-aware synthetic data generation
to target critical nodes, creating realistic failure scenarios. Evaluations on
the Who\&When benchmark and integration into production systems demonstrate
that GraphTracer-8B achieves up to 18.18\% higher attribution accuracy compared
to state-of-the-art models and enables 4.8\% to 14.2\% performance improvements
in deployed multi-agent frameworks, establishing a robust solution for
multi-agent system debugging.

</details>


### [383] [D3MAS: Decompose, Deduce, and Distribute for Enhanced Knowledge Sharing in Multi-Agent Systems](https://arxiv.org/abs/2510.10585)
*Heng Zhang,Yuling Shi,Xiaodong Gu,Haochen You,Zijian Zhang,Lubin Gan,Yilei Yuan,Jin Huang*

Main category: cs.GR

TL;DR: 大型语言模型驱动的多智能体系统存在知识冗余问题，D3MAS框架通过分层协调来解决此问题，提高了准确性并减少了冗余。


<details>
  <summary>Details</summary>
Motivation: 当前由大型语言模型驱动的多智能体系统在协作解决问题时存在显著的知识冗余，体现在代理在检索和推理过程中重复努力，这是因为现有架构缺乏确保代理在每个操作阶段共享最少足够信息的机制。

Method: 提出了一种名为D3MAS（Decompose, Deduce, and Distribute）的分层协调框架。该框架通过结构化设计而非显式优化来解决冗余问题，包含三个协调层：任务分解、协作推理和分布式记忆。信息通过结构化消息传递在统一的异构图中进行跨层对齐，以满足实际任务需求。

Result: 实验结果表明，D3MAS在四个具有挑战性的数据集上，推理准确性平均提高了8.7%至15.6%，知识冗余平均减少了46%。

Conclusion: D3MAS框架通过分层协调的结构化设计，有效解决了多智能体系统中由大型语言模型带来的知识冗余问题，并在提高推理准确性和减少冗余方面取得了显著成效。

Abstract: Multi-agent systems powered by large language models exhibit strong
capabilities in collaborative problem-solving. However, these systems suffer
from substantial knowledge redundancy. Agents duplicate efforts in retrieval
and reasoning processes. This inefficiency stems from a deeper issue: current
architectures lack mechanisms to ensure agents share minimal sufficient
information at each operational stage. Empirical analysis reveals an average
knowledge duplication rate of 47.3\% across agent communications. We propose
D3MAS (Decompose, Deduce, and Distribute), a hierarchical coordination
framework addressing redundancy through structural design rather than explicit
optimization. The framework organizes collaboration across three coordinated
layers. Task decomposition filters irrelevant sub-problems early. Collaborative
reasoning captures complementary inference paths across agents. Distributed
memory provides access to non-redundant knowledge. These layers coordinate
through structured message passing in a unified heterogeneous graph. This
cross-layer alignment ensures information remains aligned with actual task
needs. Experiments on four challenging datasets show that D3MAS consistently
improves reasoning accuracy by 8.7\% to 15.6\% and reduces knowledge redundancy
by 46\% on average.

</details>


### [384] [VLM-Guided Adaptive Negative Prompting for Creative Generation](https://arxiv.org/abs/2510.10715)
*Shelly Golan,Yotam Nitzan,Zongze Wu,Or Patashnik*

Main category: cs.GR

TL;DR: 提出了一种名为VLM-Guided Adaptive Negative-Prompting的训练无关、推理时方法，利用视觉语言模型（VLM）引导扩散模型生成新颖且有效的图像。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像模型在生成新颖内容方面存在不足，而现有方法要么限制探索，要么耗时。需要一种更有效的方法来增强生成创造力。

Method: 利用VLM分析生成过程的中间输出，并自适应地引导模型避开常规视觉概念，从而鼓励产生新颖和令人惊讶的输出。此方法在推理时进行，无需训练。

Result: 通过CLIP嵌入空间的统计指标评估，证实了该方法在创造性新颖性方面取得了持续的改进，同时计算开销极小。该方法不仅适用于生成单个对象，还能扩展到生成创意对象的连贯集合，并在复杂的组合提示中保持创造力。

Conclusion: VLM-Guided Adaptive Negative-Prompting是一种实用的方法，可以无缝集成到现有的扩散模型中，以超越文本描述的限制，生成更具创造性的输出。

Abstract: Creative generation is the synthesis of new, surprising, and valuable samples
that reflect user intent yet cannot be envisioned in advance. This task aims to
extend human imagination, enabling the discovery of visual concepts that exist
in the unexplored spaces between familiar domains. While text-to-image
diffusion models excel at rendering photorealistic scenes that faithfully match
user prompts, they still struggle to generate genuinely novel content. Existing
approaches to enhance generative creativity either rely on interpolation of
image features, which restricts exploration to predefined categories, or
require time-intensive procedures such as embedding optimization or model
fine-tuning. We propose VLM-Guided Adaptive Negative-Prompting, a
training-free, inference-time method that promotes creative image generation
while preserving the validity of the generated object. Our approach utilizes a
vision-language model (VLM) that analyzes intermediate outputs of the
generation process and adaptively steers it away from conventional visual
concepts, encouraging the emergence of novel and surprising outputs. We
evaluate creativity through both novelty and validity, using statistical
metrics in the CLIP embedding space. Through extensive experiments, we show
consistent gains in creative novelty with negligible computational overhead.
Moreover, unlike existing methods that primarily generate single objects, our
approach extends to complex scenarios, such as generating coherent sets of
creative objects and preserving creativity within elaborate compositional
prompts. Our method integrates seamlessly into existing diffusion pipelines,
offering a practical route to producing creative outputs that venture beyond
the constraints of textual descriptions.

</details>


### [385] [MATStruct: High-Quality Medial Mesh Computation via Structure-aware Variational Optimization](https://arxiv.org/abs/2510.10751)
*Ningna Wang,Rui Xu,Yibo Yin,Zichun Zhong,Taku Komura,Wenping Wang,Xiaohu Guo*

Main category: cs.GR

TL;DR: 本论文提出了一种新的优化框架，用于计算同时保持了体素结构和高网格质量的 medial axis transform。


<details>
  <summary>Details</summary>
Motivation: 为了获得能够提供自然体积分解的三维形状的连接体素结构（由片、缝和连接组成），并确保 medial mesh 的高质量。

Method: 该方法引入了一个由受限功率图 (RPD) 引导的、感知结构的、基于粒子的优化流程，该流程将输入体积划分为由连接性 medial mesh 编码的对偶组成的凸单元。通过 SQEM 投影来约束 medial sphere 的移动，并通过高斯核能量来鼓励均匀的空间分布，从而实现感知结构。

Result: 与 MATFP 和 MATTopo 等保留特征的方法相比，该方法生成的 medial structure 更清晰、更准确，网格质量显著提高。与基于体素、基于点云和变分法相比，该框架首次将结构感知集成到优化过程中，生成的 medial mesh 具有卓越的几何保真度、拓扑正确性和明确的结构分解。

Conclusion: 所提出的框架能够生成高质量的 medial mesh，同时保持体素结构，并且在几何保真度、拓扑正确性和结构分解方面优于现有方法。

Abstract: We propose a novel optimization framework for computing the medial axis
transform that simultaneously preserves the medial structure and ensures high
medial mesh quality. The medial structure, consisting of interconnected sheets,
seams, and junctions, provides a natural volumetric decomposition of a 3D
shape. Our method introduces a structure-aware, particle-based optimization
pipeline guided by the restricted power diagram (RPD), which partitions the
input volume into convex cells whose dual encodes the connectivity of the
medial mesh. Structure-awareness is enforced through a spherical quadratic
error metric (SQEM) projection that constrains the movement of medial spheres,
while a Gaussian kernel energy encourages an even spatial distribution.
Compared to feature-preserving methods such as MATFP and MATTopo, our approach
produces cleaner and more accurate medial structures with significantly
improved mesh quality. In contrast to voxel-based, point-cloud-based, and
variational methods, our framework is the first to integrate structural
awareness into the optimization process, yielding medial meshes with superior
geometric fidelity, topological correctness, and explicit structural
decomposition.

</details>


### [386] [The Fire We Share](https://arxiv.org/abs/2510.10841)
*Chen Wang,Mengtan Lin*

Main category: cs.GR

TL;DR: 该项目提出了一个以关怀为中心、结果感知为导向的野火数据可视化框架，将野火数据视为生态和社会纠葛的动态档案，而不是静态指标。


<details>
  <summary>Details</summary>
Motivation: 以关怀为中心、结果感知为导向的可视化框架，用于处理野火数据，将其视为生态和社会纠葛的动态档案，而不是静态指标。

Method: 结合受植物启发的數據形式、事件驱动的映射和叙事分层，将野火视为一种共享的时间条件，这种条件跨越了自然周期和人类系统。

Result: 该项目将野火数据重新构想为一个具体、关联且具有高度道德性的、带有伤痕的档案，而不是将其简化为易于理解的可视化。

Conclusion: 野火数据可以被视为一个具体、关联且具有高度道德性的、带有伤痕的档案，而不是被简化为易于理解的可视化。

Abstract: The Fire We Share proposes a care-centered, consequence-aware visualization
framework for engaging with wildfire data not as static metrics, but as living
archives of ecological and social entanglement. By combining plants-inspired
data forms, event-based mapping, and narrative layering, the project
foregrounds fire as a shared temporal condition-one that cuts across natural
cycles and human systems. Rather than simplifying wildfire data into digestible
visuals, The Fire We Share reimagines it as a textured, wounded
archive-embodied, relational, and radically ethical.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [387] [Electron-electron scattering processes in quantum wells in a quantizing magnetic field: II. Scattering in the case of two subbands](https://arxiv.org/abs/2510.09787)
*M. P. Telenkov,Yu. A. Mityagin*

Main category: cond-mat.mes-hall

TL;DR: 电子-电子散射是多体问题，但由于能量守恒和动量守恒，电子-电子散射在量子限制的二维电子气体中被禁止，其中只有两个子带具有朗道能级。


<details>
  <summary>Details</summary>
Motivation: 在量子限制的二维电子气体中，电子-电子散射被禁止，其中只有两个子带具有朗道能级。这是因为能量守恒和动量守恒。然而，这项研究考虑了涉及两个子带的朗道能级的电子-电子散射过程。

Method: 计算了包含所有类型朗道能级之间跃迁的电子-电子散射速率矩阵。分析了该矩阵，并确定了不同类型跃迁的相对速率。

Result: 计算了电子-电子散射速率矩阵，并确定了不同类型跃迁的相对速率。研究了量子限制磁场方向对电子-电子散射过程的影响。

Conclusion: 量子限制磁场方向会影响电子-电子散射过程。

Abstract: Electron-electron scattering processes involving Landau levels of two subband
are considered. A matrix of electron-electron scattering rates containing all
tipes of transitions between Landau levels is calculated/ This matrix is
analized, and the relative rates of transitions of different types are
determined. The effect of the quantizing magnetic field orientation on
electron-electron scattering processes is ectablished.

</details>


### [388] [Thermoelectric effect at the quantum Hall-superconductor interface](https://arxiv.org/abs/2510.09798)
*Jordan T. McCourt,John Chiles,Chun-Chia Chen,Kenji Watanabe,Takashi Tanaguchi,Francois Amet,Gleb Finkelstein*

Main category: cond-mat.mes-hall

TL;DR: 量子霍尔-超导体界面存在复杂的传热和电荷现象，需要考虑热电效应。


<details>
  <summary>Details</summary>
Motivation: 量子霍尔绝缘体与超导体的界面是实现拓扑保护量子计算的潜在平台，但其他效应可能会掩盖所需激发。本研究旨在研究量子霍尔-超导体界面处的温热电效应。

Method: 通过测量量子霍尔-超导体界面处的温热电效应，并考虑界面处热点形成导致的非平衡电子分布，这些电子通过涡旋核传播到超导体。

Result: 观察到温热电效应，产生电压，该电压在量子霍尔平台上改变符号，并对涡旋的重排做出响应。

Conclusion: 量子霍尔-超导体界面的热量和电荷现象相互作用很复杂，在解释类似系统的输运测量时应予以考虑。

Abstract: The interfaces of quantum Hall insulators with superconductors have emerged
as a promising platform to realise interesting physics that may be relevant for
topologically protected quantum computing. However, these interfaces can host
other effects which obscure the detection of the desired excitations. Here we
present measurements of the thermoelectric effect at the quantum
Hall-superconductor interface. We explain the heat transport by considering the
formation of a hotspot at the interface, which results in a non-equilibrium
distribution of electrons that can propagate across the superconductor through
vortex cores. The observed thermoelectric effect results in a voltage which
changes sign on quantum Hall plateaus and responds to the rearrangement of
vortices in the wire. These observations highlight the complex interplay of
thermal and charge phenomena at the quantum Hall -- superconductor interfaces
and should be considered when interpreting transport measurements in similar
systems.

</details>


### [389] [Hybrid Quantum Systems: Coupling Single-Molecule Magnet Qudits with Industrial Silicon Spin Qubits](https://arxiv.org/abs/2510.10110)
*Daniel Schroller,Daniel Sitter,Thomas Koch,Viktor Adam,Noah Glaeser,Clement Godfrin,Stefan Kubicek,Julien Jussot,Roger Loo,Yosuke Shimura,Danny Wan,Yaorong Chen,Mario Ruben,Kristiaan De Greve,Wolfgang Wernsdorfer*

Main category: cond-mat.mes-hall

TL;DR: Use SiMOS spin qubit to detect TbPc2 molecular spin transitions for hybrid quantum memory.


<details>
  <summary>Details</summary>
Motivation: Molecular spin qudits like TbPc2 offer long coherence times and rich multi-level spin structures, making them attractive for quantum memory. Integrating them with semiconductor qubits for scalable readout is a step towards hybrid quantum architectures.

Method: Utilize an industrially manufactured silicon metal-oxide-semiconductor (SiMOS) spin qubit to detect electronic spin transitions of TbPc2 molecules using a combined Rapid adiabatic Passage and Spin-Selective tunneling (RPSS) protocol with microwave pulses and fixed gate voltages.

Result: Demonstrated ensemble detection of TbPc2 molecular spin transitions using a SiMOS spin qubit with high-contrast resonance detection, avoiding common recalibration issues.

Conclusion: Established a foundation for integrating molecular quantum memories with industrial qubit platforms, paving the way for single-molecule hybrid quantum technologies.

Abstract: Molecular spin qudits offer an attractive platform for quantum memory,
combining long coherence times with rich multi-level spin structures. Terbium
bis(phthalocyaninato) (TbPc$_2$) exemplifies such systems, with demonstrated
quantum control and chemical reproducibility. In hybrid quantum architectures,
TbPc$_2$ can act as the primary memory element, with semiconductor qubits
providing scalable readout and coupling. Here we present a step toward such a
hybrid system: using an industrially manufactured silicon
metal-oxide-semiconductor (SiMOS) spin qubit to detect electronic spin
transitions of an ensemble of TbPc$_2$ molecules. The readout is based on a
compact and robust protocol that applies a microwave pulse while all gate
voltages defining the qubit are held at a fixed operating point. This protocol,
which combines simultaneous Rapid adiabatic Passage and Spin- Selective
tunneling (RPSS), enables high-contrast resonance detection and avoids repeated
$\pi$-pulse recalibration common in decoupling schemes. By demonstrating
ensemble detection, we establish a foundation for integrating molecular quantum
memories with industrial qubit platforms and mark an important step toward
single-molecule hybrid quantum technologies.

</details>


### [390] [Scaling of Magnetic Domain Walls in Perpendicular Magnetic Anisotropy Systems](https://arxiv.org/abs/2510.10230)
*Guowen Gong,Changmin Xiong,Lijun Zhu*

Main category: cond-mat.mes-hall

TL;DR: DMI会影响磁畴壁的类型，但对宽度影响不大。形状各向异性也会影响磁畴壁的宽度。


<details>
  <summary>Details</summary>
Motivation: 尽管早期付出了努力，但对磁畴壁宽度和类型的微磁演化仍未完全理解。

Method: 结合解析和微磁模拟研究，建立了磁畴作为交换刚度、单轴垂直磁各向异性、饱和磁化强度、DMI和形状各向异性的函数关系。

Result: DMI对畴壁宽度的影响很小，但很大程度上影响畴壁的类型。零DMI下为布洛赫构型，DMI增大时逐渐转变为尼尔构型。

Conclusion: 研究结果全面、确定地理解了自旋电子器件中的磁畴壁。

Abstract: Magnetic domain walls play a critical role in the nanoscale evolution of
magnetic devices. Despite the early efforts, a complete understanding of the
micromagnetic evolution of the width and the type of magnetic domain walls has
still remained missing. Here, we report a combined analytical and micromagnetic
simulation study and establish the scaling of the magnetic domains as a
function of the exchange stiffness (A), uniaxial perpendicular magnetic
anisotropy (Ku), saturation magnetization (Ms), and Dzyaloshinskii-Moriya
interaction (DMI), and shape anisotropy of the magnetic device. We find that
the width of both Bloch and Neel walls scales excellently with the analytical
prediction. The DMI is found to have little influence on the domain wall width
but strongly affect the type of the domain wall. The domain wall has a Bloch
configuration at zero DMI and gradually transitions to Neel configuration upon
increase of the DMI. The shape anisotropy of the magnetic domain wall also
affects the domain wall width. These results have established a comprehensive,
conclusive understanding of the magnetic domain walls within spintronics
devices.

</details>


### [391] [Roles of Electrically Excited Magnons in Unidirectional Magnetoresistance of Metallic Magnetic Bilayers](https://arxiv.org/abs/2510.10309)
*Shashank Gupta,Steven S. -L. Zhang*

Main category: cond-mat.mes-hall

TL;DR: 金属双层材料中的单向磁电阻（UMR）可以通过非平衡的、由电场间接激发的以及通过吸收传导电子的自旋角动量来抑制


<details>
  <summary>Details</summary>
Motivation: 研究宏观磁性材料中的单向磁电阻（UMR）的物理机制，特别是电子-磁振子的耦合动力学在其中所扮演的角色。

Method: 建立一个包含电子-磁孙动力学耦合的理论框架，分析了磁场、厚度和温度依赖性。

Result: 非平衡磁孙可以吸收传导电子的自旋角动量，从而抑制UMR。该模型能够解释UMR的磁场、厚度和温度依赖性，并提供实验指纹。

Conclusion: 揭示了宏观磁性材料中UMR的电子-磁孙耦合动力学机制，并提出了实验上区分磁孙贡献的方法。

Abstract: Unidirectional magnetoresistance (UMR) in metallic bilayers arises from
nonlinear spin-charge transport mediated by broken time-reversal and inversion
symmetries, yet the role of magnons remains unsettled. We develop a theoretical
framework that incorporates coupled electron-magnon dynamics, revealing cross
diffusion and spin-angular-momentum transfer between the two subsystems, which
renormalize the characteristic electron and magnon spin-diffusion lengths. We
show that nonequilibrium magnons, indirectly excited by the electric field, can
suppress UMR by absorbing spin angular momentum from conduction electrons. We
also analyze the magnetic-field, thickness, and temperature dependencies and
identify distinct features that constitute experimental fingerprints of
magnonic contributions to UMR in metallic bilayers, providing qualitative to
semiquantitative guidance for elucidating the underlying physical mechanisms.

</details>


### [392] [Breakdown of the Wiedemann-Franz law in an interacting quantum Hall metamaterial](https://arxiv.org/abs/2510.10391)
*Patrice Roche,Carles Altimiras,François D. Parmentier,Olivier Maillet*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种由小金属点链组成的量子热输运系统，该系统在特定条件下表现出比电荷输运更好的热输运性能，并提出了利用该系统进行热量操控的新方法。


<details>
  <summary>Details</summary>
Motivation: Landauer-Büttiker 框架在描述电子在弹道通道中的量子热输运时失效，尤其是在引入强库仑相互作用的情况下。因此，有必要开发新的理论模型来处理这种情况。

Method: 提出一个由小金属点组成的链状系统，这些点通过手性弹道通道连接，并且不允许电荷积累。通过分析该系统中的热扩散和库仑相互作用，研究热量和电荷的输运特性，并计算洛伦兹比。

Result: 所提出的系统表现出比电荷更好的热导率，并且洛伦兹比可以任意大，与链的长度成平方根关系。

Conclusion: 该研究揭示了由中性激发引起的热扩散与链中库仑相互作用之间的竞争关系，该关系在一个有限的特征长度上定义了温度梯度。这表明该系统在介观尺度上具有热量操控的新潜力，并且洛伦兹比可以显著大于通常认为的极限值。

Abstract: Quantum heat transport by electrons in ballistic channels is usually
well-described in the Landauer-B\"uttiker framework, which fails when
introducing strong Coulomb interactions. We theoretically show that a chain of
small metallic dots where charge cannot accumulate, connected by chiral
ballistic channels, conducts heat better than charge. We relate this feature to
the competition between heat diffusion by neutral excitations and Coulomb
interactions in the chain, which defines a temperature gradient over a finite
characteristic length. We show that the Lorenz ratio can be arbitrarily large,
scaling as the square root of the chain's length, which suggests new approaches
for heat manipulation in mesoscopic systems.

</details>


### [393] [Constructing a Nanopipette-based DNA Electro-Mechanical Device](https://arxiv.org/abs/2510.10515)
*Cengiz J. Khan,Oliver J. Irving,Rand A. Al-Waqfi,Giorgio Ferrari,Tim Albrecht*

Main category: cond-mat.mes-hall

TL;DR: 通过对DNA进行端官能化和纳米颗粒封盖，在纳米移液管尖端实现DNA结构的稳定捕获，从而能够对同一DNA结构进行重复读出，并为在流动和受限环境中的应用开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 固态纳米孔和纳米移液管传感器在生物聚合物（如DNA和蛋白质）的检测、定量和结构分析方面功能强大，尤其是在载流子增强电阻脉冲传感中。然而，为了获得统计上可靠的信息，通常需要从溶液中抽取和分析数百种不同的分子，这限制了传感器的适用性并使相关工作流程复杂化。

Method: 提出一种通过端官能化和纳米颗粒封盖在纳米移液管的传感区域中捕获DNA结构的新策略，并开发了一套描述符来表征纳米颗粒-DNA构建体在纳米移液管尖端的插入和存在情况。

Result: 展示了DNA结构在纳米移液管尖端的可移动性和对外部电场的响应性，使得对同一DNA结构进行重复读出成为可能。

Conclusion: 所提出的策略能够对同一DNA结构进行重复读出，有望在流动和受限环境中实现新的应用。

Abstract: Solid-state nanopore and nanopipette sensors are powerful devices for the
detection, quantification and structural analysis of biopolymers such as DNA
and proteins, especially in carrier-enhanced resistive-pulse sensing. However,
hundreds of different molecules typically need to be sampled from solution and
analysed to obtain statistically robust information. This limits the
applicability of such sensors and complicates associated workflows. Here, we
present a new strategy to trap DNA structures in the sensing region of a
nanopipette through end functionalisation and nanoparticle capping. We develop
a robust set of descriptors to characterise the insertion and presence of
nanoparticle-DNA constructs in the nanopipette tip and, furthermore, show that
they remain mobile and responsive to external electric fields over extended
periods of time. This allows for repeated readout of the same DNA structure and
could enable new applications for such sensors, for example in flow and in
confined environments.

</details>


### [394] [Time domain braiding of anyons revealed through a nonequilibrium fluctuation dissipation theorem](https://arxiv.org/abs/2510.10525)
*Ines Safi*

Main category: cond-mat.mes-hall

TL;DR: 我们推导了一种适用于非平衡初始态的新型涨落-耗散定理(FDT)，该定理可以印制任意子在时域中的编织。该推导是在统一的非平衡微扰理论(UNEPT)框架内进行的，适用于标准的库几何和具有一个或两个量子点接触(QPC)注入稀散任意子通量的配置。基于此FDT，我们提出了确定时域编织相位的互补方法。第一种方法将直流反向散射噪声与直流驱动下的电流积分联系起来，第二种方法将交流电流相移与直流噪声联系起来。后者提供了对统计角$	heta$的特别鲁棒的探测，提供了内在校准并消除了某些非普适重整化效应。当专门研究热化的Tomonaga-Luttinger液体(TLL)时，我们进一步表明，在量子区域，相移可以直接确定标度维度$	au$，前提是$	au>1/2$。这些结果定义了在最小单QPC设置中提取$	heta$或$	au$的实验可及方案，而无需依赖干涉测量或互相关测量。


<details>
  <summary>Details</summary>
Motivation: 推导适用于非平衡初始态的涨落-耗散定理(FDT)，并提出提取任意子时域编织相位的方法。

Method: 在UNEPT框架下推导FDT，提出两种互补方法（直流反向散射噪声和交流电流相移）来确定时域编织相位。

Result: 提出两种确定时域编织相位的方法，交流电流相移法可用于提取统计角$	heta$和标度维度$	au$。

Conclusion: 提出的方法为实验提取任意子编织相位提供了可行方案。

Abstract: We derive a novel fluctuation--dissipation theorem (FDT) valid for
nonequilibrium initial states that imprint the braiding of anyons in the time
domain. The derivation is carried out within the Unifying Nonequilibrium
Perturbative Theory (UNEPT), which applies to both standard reservoir
geometries and configurations with one or two quantum point contacts (QPCs)
injecting dilute anyonic fluxes. Based on this FDT, we propose complementary
methods to determine the time-domain braiding phase. The first method relates
the DC backscattering noise to the integral of the current with respect to DC
drives, while the second connects the AC current phase shift to the DC noise.
The latter provides a particularly robust probe of the statistical angle
$\theta$, offering an intrinsic calibration and cancelling certain nonuniversal
renormalization effects. Specializing to a thermalized Tomonaga--Luttinger
liquid (TLL), we further show that in the quantum regime the phase shift
enables a direct determination of the scaling dimension $\delta$ when $\delta >
1/2$. These results define experimentally accessible schemes to extract either
$\theta$ or $\delta$ in minimal single-QPC setups, without relying on
interferometry or cross-correlation measurements.

</details>


### [395] [RKKY interaction in Weyl semimetal nanowires](https://arxiv.org/abs/2510.10589)
*Rohit Mukherjee,Asutosh Dubey*

Main category: cond-mat.mes-hall

TL;DR: Weyl半金属纳米线表面的局域杂质之间诱导了有效的耦合，该耦合由RKKY理论解释，其中手征费米弧表面态是关键。


<details>
  <summary>Details</summary>
Motivation: 研究Weyl半金属（WSM）纳米线表面局域杂质之间的有效耦合，并利用RKKY理论进行解释，重点关注手征费米弧表面态的作用。

Method: 使用RKKY理论，研究了费米弧表面态如何作为媒介来介导低能下的杂质-杂质相互作用，并考虑了自旋-动量锁定的影响。通过解析和数值方法，分离了体态和表面态对RKKY耦合的贡献，并分析了不同耦合项（$J_{\phi\phi}$、$J_{\mu\nu}$）的来源和各自的缩放行为。

Result: 发现Azimuthal耦合 ($J_{\phi\phi}$) 主要由相同自旋极化的费米弧态引起，而 $J_{\mu\nu}$ ($\mu,\nu = z,r$) 耦合则由相反自旋极化的费米弧态主导。表面态和包含费米弧及低能体态的贡献具有不同的缩放行为。

Conclusion: Weyl半金属纳米线为工程和模拟各类自旋模型提供了一个多功能的平台。

Abstract: We investigate the effective couplings induced between localized impurities
on the surface of a Weyl semimetal (WSM) nanowire within the framework of
Ruderman--Kittel--Kasuya--Yosida (RKKY) theory. The itinerant electrons from
the chiral Fermi arc surface states mediate impurity-impurity interaction at
low energies. As a result, the spin-momentum locking naturally plays a central
role in shaping the spin-spin correlations. We show that the dominant
interaction channels have distinct origins: while the azimuthal coupling,
$J_{\phi\phi}$ term arises exclusively from Fermi arc states with identical
spin polarization, the couplings $J_{\mu\nu}$ ($\mu,\nu = z,r$) are governed by
Fermi arc states with opposite spin polarizations. Furthermore, we demonstrate
that purely surface-mediated contributions exhibit different scaling behavior
compared to those involving Fermi arcs and low-energy bulk states. We
systematically untangle the contributions from bulk and surface states to the
RKKY couplings, using analytical and numerical methods. Our results establish
WSM nanowires as a versatile platform for engineering and simulating a broad
class of spin models.

</details>


### [396] [Non-unitary Time Evolution via the Chebyshev Expansion Method](https://arxiv.org/abs/2510.10643)
*Áron Holló,Dániel Varjas,Cosma Fulga,László Oroszlány,Viktor Könye*

Main category: cond-mat.mes-hall

TL;DR: Chebyshev展开方法可用于任意非厄米矩阵的任意时间演化，只需选择合适的谱半径和时间步长即可。可以通过分析性上界来控制舍入误差。


<details>
  <summary>Details</summary>
Motivation: 扩展Chebyshev展开方法在非厄米系统中的应用，并解决其数值精度问题。

Method: Derivation of an analytic upper bound for rounding error, numerical simulations with careful selection of spectral radius and time step.

Result: Chebyshev expansion method is shown to be valid for arbitrary non-Hermitian matrices across the entire complex plane, with numerical rounding errors identified as the main source of inaccuracies. The derived analytic upper bound provides a guideline for selecting time steps to suppress these errors effectively. The method's performance is illustrated via the Hatano-Nelson model.

Conclusion: Chebyshev expansion method is applicable to non-Hermitian systems, and numerical errors can be controlled by choosing appropriate parameters.

Abstract: The Chebyshev expansion method is a well-established technique for computing
the time evolution of quantum states, particularly in Hermitian systems with a
bounded spectrum. Here, we show that the applicability of the Chebyshev
expansion method extends well beyond this constraint: It remains valid across
the entire complex plane and is thus suitable for arbitrary non-Hermitian
matrices. We identify that numerical rounding errors are the primary source of
errors encountered when applying the method outside the conventional spectral
bounds, and they are not caused by fundamental limitations. By carefully
selecting the spectral radius and the time step, we show how these errors can
be effectively suppressed, enabling accurate time evolution calculations in
non-Hermitian systems. We derive an analytic upper bound for the rounding
error, which serves as a practical guideline for selecting time steps in
numerical simulations. As an application, we illustrate the performance of the
method by computing the time evolution of wave packets in the Hatano-Nelson
model.

</details>


### [397] [Quantifying Charge Noise Sources in Quantum Dot Spin Qubits via Impedance Spectroscopy, DLTS, and C-V Analysis](https://arxiv.org/abs/2510.10861)
*Tyafur Rahman Pathan,Daryoosh Vashaee*

Main category: cond-mat.mes-hall

TL;DR: 氧化物、量子阱界面和体块中的陷阱引起电荷噪声，限制了量子点自旋量子比特的相干性和保真度。本研究提出了一种结合交流阻抗光谱、深层瞬态光谱和电容-电压分析的通用陷阱表征框架，用于识别和量化这些陷阱状态的光谱特征。该方法可用于识别不同类型的陷阱，例如氧化物陷阱（在低频电导峰和奈奎斯特/瞬态光谱中占主导地位）、量子阱界面陷阱（在时域响应中表现出多指数衰减）和体块陷阱（影响高频导纳和稳态漏电流）。通过将陷阱类型与其特征时间常数、空间位置和光谱影响相关联，可以提供一种诊断工具集来分离影响量子比特性能的噪声源。


<details>
  <summary>Details</summary>
Motivation: 量子点（QD）自旋量子比特的相干性和保真度受到电荷噪声的根本限制，这些噪声源于氧化物界面、异质结构边界和块状半导体内的电活性陷阱态。这些陷阱通过自旋-轨道相互作用或对电荷敏感的限制势将静电波动耦合到量子比特，从而导致退相干和门错误。

Method: 使用交流阻抗光谱、深层瞬态光谱（DLTS）和传统的电容-电压（C-V）分析，提出了一种通用的陷阱表征框架，用于识别和量化这些陷阱态的光谱特征。

Result: 研究结果表明，不同类别的陷阱（氧化物界面、量子阱界面和体块）在频域和时域测量中表现出独特的特征。氧化物陷阱在低频电导峰中占主导地位，在奈奎斯特和瞬态光谱中表现明显。量子阱界面陷阱在传统 C-V 和交流阻抗分析中几乎不可见，但可以通过时域响应中的多指数衰减信号清晰地分辨出来。体块陷阱会影响高频导纳和稳态漏电流。通过将每种陷阱类型与其特征时间常数、空间位置和光谱影响相关联，提供了一个诊断工具集，用于区分导致量子比特性能下降的噪声源。

Conclusion: 通过将传统的缺陷计量学与新兴的量子比特噪声分析相结合，该统一方法学提供了一个全面的工具集，用于表征和区分量子比特性能的噪声源，从而能够通过材料和工艺级别的策略来优化可扩展量子器件的相干性。

Abstract: The coherence and fidelity of quantum dot (QD) spin qubits are fundamentally
limited by charge noise arising from electrically active trap states at oxide
interfaces, heterostructure boundaries, and within the bulk semiconductor.
These traps introduce electrostatic fluctuations that couple to the qubit via
spin-orbit interactions or charge-sensitive confinement potentials, leading to
dephasing and gate errors. In this work, we present a general trap
characterization framework for identifying and quantifying the spectral
signatures of these trap states using AC impedance spectroscopy, deep-level
transient spectroscopy (DLTS), and conventional capacitance-voltage (C-V)
analysis. While our case study focuses on strained Ge/SiGe quantum well
heterostructures, the approach is broadly applicable to other material systems
and qubit types. We demonstrate that each class of traps (oxide interface,
quantum well interface, and bulk) exhibits distinct fingerprints across
frequency- and time-domain measurements. Oxide traps dominate the low-frequency
conductance peaks and appear strongly in Nyquist and transient spectra. QW
interface traps, despite being nearly invisible at low densities in
conventional C-V and AC impedance analysis, are clearly resolved through
multi-exponential decay signatures in time-domain response. Bulk traps
contribute to high-frequency admittance and steady-state leakage currents. By
correlating each trap type to its characteristic time constant, spatial
location, and spectral impact, we provide a diagnostic toolset for
disentangling noise sources that degrade qubit performance. This unified
methodology bridges traditional defect metrology with emerging qubit noise
analysis and enables material- and process-level strategies for coherence
optimization in scalable quantum devices.

</details>


### [398] [Two-dimensional flat-bands in Moire-diamonds](https://arxiv.org/abs/2510.10908)
*Yalan Wei,Shifang Li,Yuke Song,Chaoyu He*

Main category: cond-mat.mes-hall

TL;DR: 在扭曲石墨烯中引入sp3杂化，在较大的扭转角和较短的莫尔周期下发现了鲁棒的平带，为探索新的量子材料提供了平台。


<details>
  <summary>Details</summary>
Motivation: 魔角扭曲双层石墨烯中的平带的实现困难且易受扰动影响，需要寻找新的实现平带的方法。

Method: 在扭曲石墨烯中引入sp3杂化，并通过计算发现莫尔-金刚石结构具有二维平带的导带和价带。

Result: 发现了莫尔-金刚石结构，其中载流子局域在特定的动量平面内，但在垂直方向上保持色散。

Conclusion: sp3杂化在扭曲石墨烯中实现鲁棒平带，为探索平带驱动的关联物理和设计具有高度定向电子功能的量子材料提供了新的平台。

Abstract: The discovery of flat-bands in magic-angle twisted bilayer graphene has
underscored the potential of moire engineering for correlated states, but such
phases are notoriously difficult to realize and highly fragile against
perturbations. Here, we propose an alternative route to flat-bands by
introducing sp3 hybridization in twisted graphite. Instead of relying on
fine-tuned magic angles, our approach identifies flat-band states at relatively
large twist angles with short moire periods. In this regime, sp3-induced
reconstructions generate electronic states that, once formed, are locked by
substantial energy barriers, rendering them robust against external
perturbations. Using twisted graphite as a prototype, we uncover a series
moire-diamond that host two-dimensional flat conduction of valence bands, where
carriers are localized within specific momentum planes but remain dispersive
along orthogonal directions. The emergence of dimensional flat-bands opens a
new platform for flat-band-driven correlated physics and suggests opportunities
for designing quantum materials with highly directional electronic
functionalities.

</details>


### [399] [Local-Antisymmetric Flat Band and Coexisting Correlated stripe charge orders in WSe2-Modulated Twisted Bilayer Graphene](https://arxiv.org/abs/2510.11088)
*Chi Zhang,Shihao Zhang,Mengmeng Zhang,Lin He,Qi Zheng*

Main category: cond-mat.mes-hall

TL;DR: 界面原子配位可调控石墨烯/WSe2异质结中的平带物理，实现对称性破缺并出现正交条纹电荷序。


<details>
  <summary>Details</summary>
Motivation: 探究原子级平整的TMDs（如WSe2）作为石墨烯衬底时对石墨烯本征性质的影响，特别是忽略的原子配位效应。

Method: 结合扫描隧道显微镜/谱学和理论分析，研究石墨烯/WSe2异质结的原子配位对魔角扭曲双层石墨烯（MATBG）电子结构的影响。

Result: 发现特定的石墨烯/WSe2扭角会导致三种不同的AA堆叠构型（A, B, X），产生位置依赖的势能，不对称地移动MATBG的平带，使其在同一AA堆叠区域内从空穴侧转变为电子侧。这种对称性破缺使得正交条纹电荷序得以共存，克服了传统库仑排斥理论的限制。该带隙调制效应源于石墨烯/WSe2界面原子配位和MATBG内部异质应变的协同作用，并具有多场调控性。

Conclusion: 界面原子配位是调控平带物理的一个关键且先前被忽视的参数，为在范德华异质结中工程化关联量子态开辟了新途径。

Abstract: Insulating, atomically flat transition metal dichalcogenides (TMDs) like WSe2
are ideal substrates for probing intrinsic graphene properties. Conventionally,
their influence on graphene's band structure is assumed negligible,
particularly when small moire patterns form. Combining scanning tunneling
microscopy/spectroscopy and theoretical analysis, we reveal that the atomic
registry in graphene/WSe2 heterostructures profoundly modulates the electronic
structure of magic-angle twisted bilayer graphene (MATBG). At special
graphene/WSe2 twist angles, an incommensurate moire superlattice hosts three
distinct atomic stacking configurations (A, B, X types). These induce
position-dependent potentials that asymmetrically shift MATBG's flat bands,
transforming them from hole-side to electron-side asymmetric within a single
AA-stacked region. This symmetry breaking enables the unprecedented coexistence
of orthogonal stripe charge orders in the correlated regime-a phenomenon
previously considered mutually exclusive due to Coulomb repulsion. This band
modulation arises from the synergistic effects of the graphene/WSe2 interfacial
atomic registry and heterostrain within the MATBG, exhibiting multi-field
tunability. Our work establishes interfacial atomic registry as a critical,
previously overlooked tuning parameter for flat-band physics, opening avenues
to engineer correlated quantum states in van der Waals heterostructures.

</details>


### [400] [Should it really be that hard to model the chirality induced spin selectivity effect?](https://arxiv.org/abs/2510.11240)
*J. Fransson*

Main category: cond-mat.mes-hall

TL;DR: The chirality induced spin selectivity (CISS) effect, where electron spin polarizes when traversing chiral molecules, is poorly understood theoretically. Independent electron models have failed, suggesting electron interactions are crucial. The paper discusses the role of electron correlations, spontaneous breaking of time-reversal symmetry, and Onsager reciprocity in potentially explaining the CISS effect, highlighting the need for a microscopic theoretical foundation.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the theoretical challenge in modeling the Chirality Induced Spin Selectivity (CISS) effect, as existing models have failed to reproduce experimental results, indicating the need for a new theoretical approach that includes electron interactions.

Method: The paper discusses the limitations of independent electron models and the necessity of including electron-electron interactions. It also explores the potential role of electron correlations, time-reversal symmetry, and Onsager reciprocity in explaining the CISS effect, suggesting a foundation in microscopic modeling.

Result: The paper indicates that independent electron models have failed to capture the CISS effect. It points towards the importance of electron correlations and the possible spontaneous breaking of time-reversal symmetry and Onsager reciprocity as key factors that need to be considered in theoretical modeling.

Conclusion: The conclusion is that a correct theoretical model for the CISS effect must incorporate electron interactions, potentially including spontaneous breaking of time-reversal symmetry and Onsager reciprocity, and that a foundation in microscopic modeling is necessary to overcome the failures of previous theoretical efforts.

Abstract: The chirality induced spin selectivity effect remains a challenge to capture
with theoretical modeling. While at least a decade was spent on independent
electron models, which completely fail to reproduce the experimental results,
the lesson to be drawn out of these efforts is that a correct modeling of the
effect has to include interactions among the electrons. In the discussion of
the phenomenon ones inevitably encounters the Onsager reciprocity and
time-reversal symmetry, and questions whether the observations violate these
fundamental concepts, or whether we have not been able to identify what it is
that make those concepts redundant in this context. The experimental fact is
that electrons spin-polarize by one or another reason, when traversing chiral
molecules. The set-ups are simple enough to enable effective modeling, however,
overcoming the grand failures of the theoretical efforts, thus far, and
formulating a theory which is founded on microscopic modeling appears to be a
challenge. A discussion of the importance of electron correlations is outlined,
pointing to possible spontaneous breaking of time-reversal symmetry and Onsager
reciprocity.

</details>


### [401] [One-dimensional topological superconductors with nonsymmorphic symmetries](https://arxiv.org/abs/2510.11342)
*Max Tymczyszyn,Edward McCann*

Main category: cond-mat.mes-hall

TL;DR: 本文提出了一维四个能带的厄米紧束缚的Bogoliubov-de-Gennes（BdG）哈密顿量和Kramer的简并哈密顿量，并研究了它们在不同时间反演对称性下的性质，发现了新的拓扑不变量和Majorana零模的存在，并提出了相应的电路实现方法。


<details>
  <summary>Details</summary>
Motivation: 研究具有不同时间反演对称性的BdG哈密顿量的拓扑性质，特别是与Majorana零模相关的性质。

Method: 从广义Rice-Mele模型出发，加入超导项得到具有内禀电荷共轭对称性的四带BdG哈密顿量，并用镜映或非镜映时间反演对称性进行约束。在位置空间，研究了在平移对称性下，不同时间反演对称性对BdG矩阵的块对角化作用。计算了$\mathbb{Z}_4$模型和AII模型的拓扑指数，并提出了相应的电路实现。

Result: 发现了具有时间反演对称性的BdG哈密顿量在平移对称性下存在独特的块对角化结构。对于非镜映时间反演对称性，提出了一个$\mathbb{Z}_4$拓扑不变量，其中两个相支持Majorana零模。提出了$\mathbb{Z}_4$模型和电荷密度波模型的topolectric电路实现。证明了一维非镜映酉对称性不会产生新的拓扑分类。

Conclusion: 本文在一维系统中，通过引入不同的时间反演对称性，扩展了BdG哈密顿量的拓扑分类，发现了新的拓扑不变量和Majorana零模，并验证了其电路实现的可行性。

Abstract: We present example four-band Hermitian tight-binding Bogoliubov-de-Gennes
(BdG) Hamiltonians and Kramer's degenerate Hamiltonians in one dimension.
Starting from a generalized Rice-Mele model, we incorporate superconducting
terms to obtain a four-band BdG Hamiltonian with intrinsic charge-conjugation
symmetry, and constrain it using symmorphic or nonsymmorphic time-reversal
symmetries. In position space we find that each form of time-reversal symmetry,
when applied to random BdG matrices, results in a unique block diagonalization
of the Hamiltonian when translational symmetry is also enforced. We provide
representative models in all relevant symmorphic symmetry classes, including
the non-superconducting CII class. For nonsymmorphic time-reversal symmetry, we
identify a $\mathbb{Z}_4$ topological index with two phases supporting Majorana
zero modes and two without, and study disorder effects in the presence of
topological solitons. We further generalize a winding-number method, previously
applied only to $\mathbb{Z}_2$ invariants without Kramer's degeneracy, to
compute indices for both the $\mathbb{Z}_4$ model and a non-superconducting AII
model with nonsymmorphic chiral symmetry and Kramer's degeneracy. We propose
topolectric circuit implementations of the charge-density-wave and
$\mathbb{Z}_4$ models which agree with the topological calculations. Finally,
we show that, in one dimension, nonsymmorphic unitary symmetries do not produce
new topological classifications beyond $\mathbb{Z}$ or $\mathbb{Z}_2$ indices.

</details>


### [402] [Deterministic Switching in Altermagnets via Asymmetric Sublattice Spin Current](https://arxiv.org/abs/2510.11362)
*Sayan Sarkar,Sunit Das,Amit Agarwal*

Main category: cond-mat.mes-hall

TL;DR: The paper demonstrates a deterministic switching mechanism in collinear altermagnets using asymmetric sublattice spin currents, enabling magnetic-field-free N'eel vector reversal on a picosecond timescale.


<details>
  <summary>Details</summary>
Motivation: To discover and demonstrate a deterministic switching mechanism in collinear altermagnets that is independent of magnetic fields and operates on ultrafast timescales, overcoming limitations of conventional antiferromagnets and existing altermagnet mechanisms.

Method: The study uses Landau-Lifshitz-Gilbert simulations on doped FeSb2 (a d-wave altermagnet) to demonstrate the switching mechanism driven by asymmetric sublattice spin currents, which arise from symmetry-protected nonrelativistic spin splitting in altermagnets.

Result: Simulations show that the asymmetric torques enable deterministic 180-degree N'eel vector reversal within picoseconds, without requiring an external magnetic field. This mechanism is shown to be generic to even-parity altermagnets and effective even in systems with weak spin-orbit coupling where other mechanisms fail.

Conclusion: The paper establishes an experimentally accessible mechanism for switching altermagnetic order, paving the way for the development of ultrafast and low-power spintronic devices based on altermagnets.

Abstract: We demonstrate a deterministic switching mechanism in collinear altermagnets
driven by asymmetric sublattice spin currents. Unlike conventional
antiferromagnets, where combined parity-time-reversal symmetry enforces purely
staggered sublattice spin torques, altermagnets host symmetry-protected
nonrelativistic spin splitting that produces unequal torques on the two
sublattices. Using doped FeSb$_2$ as a representative $d$-wave altermagnet, our
Landau--Lifshitz--Gilbert simulations show that these torques enable
magnetic-field-free and deterministic 180$^\circ$ N\'eel vector reversal over
picosecond timescale. The mechanism is generic to even-parity altermagnets and
remains effective even in centrosymmetric, weak spin-orbit coupled systems,
where the N\'eel spin-orbit torque mechanism fails. Our results establish an
experimentally accessible mechanism for switching of altermagnetic order,
opening pathways for realizing ultrafast, low-power altermagnet spintronic
devices.

</details>


### [403] [Intermediate chiral edge states in quantum Hall Josephson junctions](https://arxiv.org/abs/2510.11432)
*Partha Sarathi Banerjee,Rahul Marathe,Sankalpa Ghosh*

Main category: cond-mat.mes-hall

TL;DR: The paper develops a transfer-matrix method to analyze transport in superconductor-quantum Hall-superconductor (SQHS) Josephson junctions with potential barriers, focusing on how intermediate chiral edge states (ICES) affect conductivity.


<details>
  <summary>Details</summary>
Motivation: The motivation is to study transport in SQHS Josephson junctions modulated by local potential barriers in the quantum Hall regime, specifically how ICES affect conductivity.

Method: A transfer-matrix-based theoretical framework is developed to evaluate the change in conductivity of SQHS Josephson junctions contributed by ICES induced by local potential barriers.

Result: The study demonstrates how ICES created at different Landau levels overlap through mixing, leading to different mechanisms for forming Landau bands in the presence of potential barriers. The framework is also shown to be extendable to study lattice effects.

Conclusion: The developed theoretical framework provides a method to analyze transport in SQHS Josephson junctions with potential barriers and ICES, and can be extended to include lattice effects.

Abstract: A transfer-matrix-based theoretical framework is developed to study transport
in superconductor-quantum Hall-Superconductor (SQHS) Josephson junctions
modulated by local potential barriers in the quantum-Hall regime. The method
allows one to evaluate the change in the conductivity of such SQHS Josephson
junctions contributed by the intermediate chiral edge states (ICES) induced by
these local potential barriers at their electrostatic boundaries at specific
electron filling-fractions. It is particularly demonstrated how these ICES
created at different Landau levels (LL) overlap with each other through intra-
and inter-LL ICES mixing with the change in strength and width of the potential
barriers. This results in different mechanisms for forming Landau bands when an
array of such potential barriers are present. It is also demonstrated that our
theoretical framework can be extended to study the lattice effect in a bounded
domain in such SQHS Josephson junctions by simultaneously submitting the normal
region to a transverse magnetic field and periodic potential.

</details>


### [404] [Chirality reversal at finite magnetic impurity strength and local signatures of a topological phase transition](https://arxiv.org/abs/2510.11707)
*Ruiqi Xu,Arnab Seth,Itamar Kimchi*

Main category: cond-mat.mes-hall

TL;DR: 在具有单个磁性杂质（通过在单个六边形上添加虚数次近邻跳跃 ih 来模拟）的蜂窝晶格中，研究了霍尔丹缺陷。该缺陷会给无间隙狄拉克锥带来拓扑质量项并产生手性。对于低密度的缺陷，研究发现系统的手性在与零缺陷密度下的狄拉克费米子相关的反常三临界点相关的临界 hc ~ 0.95 处反转。通过分析单个缺陷和计算两个实验相关的 경手性度量（局部陈标记的轨道磁化和低能态的电子流），研究了零密度极限。这两个探测器都显示在临界 hc ~ 0.9–1 处发生手性反转。受此一致性的启发，提出了一种缺陷尺度玩具模型，其低能态在 hc' ~ 0.87 处反转其手性。同样一对零能束缚态也在完全杂质投影 T 矩阵中产生临界点 hc。结果表明，杂质产生的 경手性反转可以在局部探测或全局拓扑中观察到，并提出了微观 경手性结构在临界点处的可能作用。


<details>
  <summary>Details</summary>
Motivation: 研究蜂窝晶格中单个磁性杂质（霍尔丹缺陷）对手性反转的影响，并探索其在零缺陷密度下的临界行为。

Method: 通过计算局部陈标记（用于轨道磁化）和低能态电子流来探测 경手性，并构建缺陷尺度玩具模型进行对比分析。

Result: 局部探测和全局拓扑均显示在临界 hc ~ 0.9–1 处发生 경手性反转。所提出的玩具模型在 hc' ~ 0.87 处显示 경手性反转。零能束缚态在 T 矩阵中产生临界点 hc。

Conclusion: 杂质引起的 경手性反转可以在局部或全局拓扑中观察到，并且微观 경手性结构可能在临界点处发挥作用。

Abstract: We study the honeycomb lattice with a single magnetic impurity modeled by
adding imaginary next-nearest-neighbor hopping ih on a single hexagon. This
Haldane defect gives a topological mass term to the gapless Dirac cones and
generates chirality. For a small density of defects Neehus et al
[arXiv:2405.19289] found that the system's chirality reverses at a critical hc
~ 0.95 associated with an unexpected tri-critical point of Dirac fermions at
zero defect density. We investigate this zero-density limit by analyzing a
single defect and computing two experimentally relevant measures of chirality:
(1) orbital magnetization via local Chern marker, a bulk probe of all occupied
states; and (2) electronic currents of low-energy states. Both probes show a
chirality reversal at a critical hc ~ 0.9--1. Motivated by this consistency we
propose a defect-scale toy model whose low energy states reverse their
chirality at hc' ~ 0.87. Remarkably, the same pair of zero energy bound states
also generate the critical point hc in the full impurity projected T-matrix.
Our results show how the chirality reversal produced by an impurity can be
observed either in local probes or in the global topology and suggest a
possible role of the microscopic defect structure at the critical point.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [405] [Ensemble-Based Data Assimilation for Material Model Characterization in High-Velocity Impact](https://arxiv.org/abs/2510.09703)
*Rong Jin,Guangyao Wang,Xingsheng Sun*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种基于数据同化（DA）的框架，可以从一次高速冲击（HVI）测试中自动校准材料模型参数。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地理解和预测材料在高速冲击下的行为，需要精确的材料模型，但传统的手动拟合方法耗时耗力。

Method: 研究整合了光滑粒子流体动力学（SPH）进行HVI模拟，并使用最大似然估计（MLE）和贝叶斯推理来校准材料参数。框架还集成了集合卡尔曼滤波器（EnKF）进行参数优化，并采用自适应协方差膨胀来解决不确定性低估的问题。

Result: 该框架通过模拟AZ31B镁合金板的后部挠度数据，成功校准了Johnson-Cook材料模型和Mie-Gruneisen状态方程（EOS）参数。即使在初始猜测有偏差或数据有限的情况下，EnKF框架也能在几次迭代内准确恢复敏感参数，表现为集合标准差的收敛。不敏感的参数则会收敛到不正确的值，并保持较大的标准差。有限的观测数据也能实现收敛，但需要更多迭代次数。在极端先验偏差下，敏感参数可能表现出“漂移后停滞”的行为，并带有小的残差偏差。研究表明，集合标准差可以作为评估参数敏感性和校准准确性的诊断工具。

Conclusion: 该研究提出的数据同化框架是一种强大且高效的工具，能够用于高速冲击材料模型的表征，并能通过集合标准差评估参数的敏感性和校准准确性。

Abstract: High-fidelity simulations are essential for understanding and predicting the
behavior of materials under high-velocity impact (HVI) in both fundamental
research and practical applications. However, their accuracy relies on material
models and parameters that are traditionally obtained through manual fitting to
multiple time- and labor-intensive experiments. This study presents an
ensemble-based data assimilation (DA) framework to automatically and
simultaneously calibrate plasticity, fracture, and equation of state (EOS)
parameters from a single HVI test. The framework integrates Smoothed Particle
Hydrodynamics for HVI simulations, the ensemble Kalman filter (EnKF) for
parameter refinement, and adaptive covariance inflation to mitigate uncertainty
underestimation. The approach is demonstrated using synthetic back-face
deflection data from an AZ31B magnesium plate to identify Johnson-Cook
plasticity/fracture and Mie-Gruneisen EOS parameters. Test cases with biased
initial guesses and limited data show the EnKF-based framework accurately
recovers sensitive parameters in few iterations, indicated by a convergent
ensemble standard deviation. Conversely, insensitive parameters converge to
incorrect values with persistently large standard deviations. Limited
observational data can still achieve convergence but requires more iterations.
Under extreme prior bias, sensitive parameters may exhibit a drift-then-stall
behavior with small residual biases. In practice, the ensemble standard
deviation thus provides a diagnostic tool to assess parameter sensitivity and
calibration accuracy. This study demonstrates the proposed DA framework is a
robust and efficient tool for HVI material model characterization.

</details>


### [406] [Dipole Alignment and Layered Flow Structure in Pressure-Driven Water Transport through MoS$_{2}$ Membranes](https://arxiv.org/abs/2510.09789)
*João Victor Lemos Vale,Lucas Cesena,Bruno H. S. Mendonça,Elizane E. de Moraes*

Main category: cond-mat.mtrl-sci

TL;DR: MoS2纳米孔洞的直径和边缘的原子组成会影响水流


<details>
  <summary>Details</summary>
Motivation: 研究MoS2纳米孔洞中的水流机制，以期改进过滤和海水淡化技术。

Method: 使用分子动力学模拟研究不同直径MoS2纳米孔洞中的水流。

Result: 孔洞大小和原子边缘组成对水通量、分子组织和偶极取向有调控作用。较大的孔洞促进层状水结构的形成和边缘加速流动；较小的孔洞中，限制和不对称的边缘化学诱导偶极子的有序排列，增强定向传输。速度和密度图显示孔洞边缘是浓缩流动和减少阻力的活性区域。

Conclusion: 孔洞几何形状、表面化学和分子动力学对MoS2膜中水的行为有显著影响，为设计先进的纳米流体和水净化系统提供了宝贵的见解。

Abstract: Efficient water transport through nanostructure membranes is essential for
advancing filtration and desalination technologies. In this study, we
investigate the flow of water through molybdenum disulfide (MoS$_{2}$)
nanopores of varying diameters using molecular dynamics simulations. The
results demonstrate that both pore size and atomic edge composition play
crucial roles in regulating water flux, molecular organization, and dipole
orientation. Larger pores facilitate the formation of layered water structures
and promote edge-accelerated flow, driven by strong electrostatic interactions
between water molecules and exposed molybdenum atoms. In narrower pores,
confinement and asymmetric edge chemistry induce the ordered alignment of
dipoles, thereby enhancing directional transport. Velocity and density maps
reveal that pore edges act as active zones, concentrating flow and reducing
resistance. These findings highlight the significance of pore geometry, surface
chemistry, and molecular dynamics in influencing water behavior within
MoS$_{2}$ membranes, providing valuable insights for the design of advanced
nanofluidic and water purification systems.

</details>


### [407] [Rotation of crystal seed during early stages of growth reveals the anisotropy of glass matrix](https://arxiv.org/abs/2510.09807)
*R. Thapa,E. Mustermann,H. Jain,V. Dierolf,M. E. McKenzie*

Main category: cond-mat.mtrl-sci

TL;DR: 观察到玻璃基质中晶种在生长早期因扭矩而旋转，这与周围非晶基质的各向同性均匀结构预期相反。通过使用 LiNbO3 和 LiNbO3-SiO2 玻璃作为模型系统进行分子动力学模拟，我们确定了这种新现象的原子起源，这源于周围玻璃对晶种的非均匀作用力，玻璃在玻璃-晶体界面的尺度上表现出不均匀和各向异性。较高温度下的晶种晶体生长（SCG）由于原子动力学增强而放大了这种效应。在 LiNbO3 玻璃中添加二氧化硅会因粘度增加和生长界面原子迁移率受限而降低晶体生长速率，但对晶体旋转的影响很小。这些发现挑战了玻璃在结晶早期是各向同性材料的普遍假设，并为调整广泛使用的玻璃陶瓷的微观结构提供了见解。


<details>
  <summary>Details</summary>
Motivation: 研究玻璃基质中晶种在生长早期因扭矩而旋转的现象，并探究其原子起源。

Method: 使用 LiNbO3 和 LiNbO3-SiO2 玻璃作为模型系统，通过分子动力学模拟研究晶体生长和旋转现象。

Result: 玻璃基质在玻璃-晶体界面的尺度上表现出不均匀和各向异性，导致周围玻璃对晶种产生非均匀作用力，从而引起晶体旋转。较高温度下，晶体生长速率的增加会放大这种旋转效应。添加二氧化硅会降低晶体生长速率，但对晶体旋转影响不大。

Conclusion: 玻璃在结晶早期并非各向同性材料，存在影响晶体生长的各向异性。研究结果有助于理解和调控玻璃陶瓷的微观结构。

Abstract: Rotation of crystal seed during the early stages of growth in a glass matrix
has been observed due to some torque, contradicting the expectations from the
isotropic, uniform structure of the surrounding amorphous matrix. We establish
an atomistic origin of this new phenomenon from molecular dynamics simulations
using LiNbO3 and LiNbO3-SiO2 glasses as model systems. Effectively, it arises
due to non-uniform forces on the seed from the surrounding glass, which appears
inhomogeneous and anisotropic on the scale of glass-crystal interface. The
seeded crystal growth (SCG) at higher temperatures amplifies this effect due to
enhanced atomic dynamics. Silica, when added to LiNbO3 glass, reduces the
crystal growth rate due to increased viscosity and restricted atomic mobility
across the growth interface, but has minimal effect on the crystal rotation.
These findings challenge a general assumption that glass is an isotropic
material, especially during the early stage of its crystallization, and provide
insights for tailoring the microstructure of widely used glass-ceramics.

</details>


### [408] [Spin Hall effect in the high-resistivity high-entropy alloy AlCrMoW](https://arxiv.org/abs/2510.09835)
*Jyoti Yadav,Felix Janus,Tiago de Oliveira Schneider,Shalini Sharma,Daniel Schröter,Markus Meinert*

Main category: cond-mat.mtrl-sci

TL;DR: 高熵合金 Al$_{x}$(CrMoW)$_{1-x}$ 薄膜在 $x=0.5$ 时电阻率达到 180$
um	ext{$\Omega$}$cm，在 $x=0.25$ 时自旋霍尔角达到 $\theta = -0.12 \pm 0.01$，表明其在自旋霍尔器件工程中具有应用前景。


<details>
  <summary>Details</summary>
Motivation: 研究高熵合金 Al$_{x}$(CrMoW)$_{1-x}$ 薄膜的电学和自旋霍尔性质，探索其作为自旋霍尔器件工程材料的可能性。

Method: 通过磁控溅射生长 Al$_{x}$(CrMoW)$_{1-x}$ 薄膜，并使用谐波霍尔法测量自旋霍尔角，同时进行密度泛函理论计算。

Result: 在 $x=0.2$ 和 $x=0.6$ 之间，电阻率高于 100$
um	ext{$\Omega$}$cm，峰值为 180$
um	ext{$\Omega$}$cm (x=0.5)。在 AlCrMoW 化学计量比附近形成 bcc 固溶体。在 $x=0.25$ 时观察到最大的自旋霍尔角 $\theta = -0.12 \pm 0.01$，计算出的自旋霍尔电导率为 $\sigma_\mathrm{SH} \approx -72\,\!000 \,\, \hbar/(2e)\,\mathrm{S/m}$。实验结果与密度泛函理论计算结果吻合良好。

Conclusion: 含主族元素的高熵合金可以形成简单的晶体结构并表现出高电阻率，为自旋霍尔器件工程提供了一类新的材料选择，并且可以通过简单的方法制备。

Abstract: We study thin films of the high-entropy alloy system Al$_{x}$(CrMoW)$_{1-x}$,
grown on Ta seed layers by magnetron co-sputtering. Between $x=0.2$ and
$x=0.6$, a resistivity larger than 100$\mu\Omega$cm is achieved, with a peak of
180$\mu\Omega$cm at $x=0.5$. Around the stoichiometric composition AlCrMoW, the
alloy forms a bcc solid solution. The harmonic Hall method was used to
characterize the spin Hall angle of the alloy series, where a maximum spin Hall
angle of $\theta = -0.12 \pm 0.01$ is observed for $x=0.25$. The implied spin
Hall conductivity is $\sigma_\mathrm{SH} \approx -72\,000 \, \hbar/(2e)$\,S/m.
The experimental results show excellent agreement with density functional
theory calculations, which show similar trends and values. The results
demonstrate that high-entropy alloys with a main-group element component can
form a simple crystal structure and show high resistivity. This suggests that a
whole new class of materials for spin Hall device engineering is available with
simple methods.

</details>


### [409] [Raman Digital Twin of Monolayer Janus Transition Metal Dichalcogenides](https://arxiv.org/abs/2510.09839)
*Johnathan Kowalski,Liangbo Liang*

Main category: cond-mat.mtrl-sci

TL;DR: 建立Janus TMDs的拉曼光谱计算库，以加速其实验室识别和开发。


<details>
  <summary>Details</summary>
Motivation: Janus TMDs具有独特的性质，但其合成和识别具有挑战性，因此需要一种快速、简单的原位表征技术来监测其转化过程。

Method: 使用第一性原理密度泛函理论（DFT）计算了六种第6族TMDs及其Janus变体的振动特性，并预测了其独特的拉曼光谱。

Result: 计算出的声子和拉曼光谱能够反映材料的结构对称性和原子组成，从而可以通过拉曼光谱进行清晰的识别。

Conclusion: 该计算库为Janus TMDs的实验识别、结构分析和质量控制提供了理论支持，加速了理论预测与实验验证的结合。

Abstract: Monolayer transition metal dichalcogenides (TMDs) are a key class of
two-dimensional (2D) materials with broad technological potential. Their Janus
counterparts exhibit unique properties due to broken out-of-plane symmetry and
further enrich the functionalities of TMDs. However, experimental synthesis and
identification of Janus TMDs remain challenging. It is thus highly desirable to
have a rapid, simple, and in situ characterization technique to monitor, in
real time, the conversion process from the parent to Janus structure. Raman
spectroscopy stands out for such a task as it is a powerful, non-destructive,
and very commonly used tool to characterize 2D materials both in situ and ex
situ. To realize the full potential of Raman spectroscopy on rapid
characterization of Janus TMDs, we present a computational "Raman digital twin"
library for various monolayer Janus TMDs in both 2H and Td phases. We focus on
group-6 TMDs: MoS$_2$, WS$_2$, MoSe$_2$, WSe$_2$, MoTe$_2$, WTe$_2$ and their
Janus variants: MoSSe, MoSTe, MoSeTe, WSSe, WSTe, and WSeTe. Using
first-principles density functional theory (DFT), we calculate their
vibrational properties and predict distinct Raman fingerprints. These phonon
and Raman signatures reflect each material's structural symmetry and atomic
composition, enabling clear identification via Raman spectroscopy. Our
theoretical work supports experimental efforts by providing benchmarks for
material identification, structural analysis, and quality control. The
computational library expedites the discovery and development of Janus 2D
materials, facilitating tighter integration between theoretical predictions and
experimental validation.

</details>


### [410] [Predicting Crystal Structures and Ionic Conductivity in Li$_{3}$YCl$_{6-x}$Br$_{x}$ Halide Solid Electrolytes Using a Fine-Tuned Machine Learning Interatomic Potential](https://arxiv.org/abs/2510.09861)
*Jonas Böhm,Aurélie Champagne*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This work demonstrates the effectiveness of fine-tuning the CHGNet universal
machine learning interatomic potential (uMLIP) to investigate ionic transport
mechanisms in ternary halide solid electrolytes of the
Li$_{3}$YCl$_{6-x}$Br$_{x}$ family (x = 0 to 6), which are promising candidates
for solid-state battery applications. We present a strategy for generating
ordered structural models from experimentally derived disordered
Li$_{3}$YCl$_{6}$ (LYC) and Li$_{3}$YBr$_{6}$ (LYB) structures. These serve as
initial configurations for an iterative fine-tuning workflow that couples
molecular dynamics (MD) simulations with static density functional theory (DFT)
calculations. The fine-tuning process and the resulting improvements in
predictive accuracy are benchmarked across energy predictions, structure
optimizations, and diffusion coefficient calculations. Finally, we analyze the
influence of composition (varied x) on the predicted ionic conductivity in
Li$_{3}$YCl$_{6-x}$Br$_{x}$, demonstrating the robustness of our approach for
modeling transport properties in complex solid electrolytes.

</details>


### [411] [Nitrogen-Triggered Amorphization Enables High-Performance Solid-State Electrolytes](https://arxiv.org/abs/2510.09960)
*Bolong Hong,Lei Gao,Bingkai Zhang,Pengfei Nan,Ruishan Zhang,Yuhang Li,Zhihao Lei,Ming Liu,Jing Wu,Longbang Di,Haijin Ni,Songbai Han,Jinlong Zhu*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种氮驱动的通用策略，用于将多种金属氯化物转化为非晶态 xLi3N-MCly (0.3 < 3x < 1.9; M 表示金属元素; 2 < y < 5) 型固态电解质，解决了非晶态固态电解质设计缺乏通用原则的问题。该策略通过氮的协同作用破坏晶体有序性，并促进锂离子迁移，成功实现了 0.533Li3N-HfCl4 在 25°C 下 2.02 mS cm⁻¹ 的离子电导率。研究结果表明，氮的引入能够增强网络无序性，缩短金属配位原子距离，并优化锂离子扩散通路。采用 0.533Li3N-HfCl4 的全固态电池在 1000 mA g⁻¹ 下经过 2000 次循环后仍保持 81.87% 的容量，且具有高正极载量 (6.24 mg cm⁻²)，证明了该方法的工程可行性。


<details>
  <summary>Details</summary>
Motivation: 开发非晶态固态电解质（SSEs）用于全固态电池（ASSBs）的应用，但缺乏通用的设计原则。

Method: 提出了一种氮驱动的通用策略，将金属氯化物转化为非晶态 xLi3N-MCly (0.3 < 3x < 1.9; M denotes a metal element; 2 < y < 5) 型 SSE。氮通过破坏配位多面体和桥接网络来破坏晶体有序性，并促进锂离子迁移。

Result: 实现了 0.533Li3N-HfCl4 在 25°C 下 2.02 mS cm⁻¹ 的离子电导率。研究结果表明，高电荷密度和 N³⁻ 的桥接能力增强了网络无序性，缩短了金属配位原子距离，并优化了 Li⁺ 扩散通路。使用 0.533Li3N-HfCl4 的 ASSBs 在 1000 mA g⁻¹ 下经过 2000 次循环后仍保持 81.87% 的容量，且具有高正极载量 (6.24 mg cm⁻²)。

Conclusion: 氮驱动的通用策略为设计高性能非晶态 SSEs 提供了一种理性方法，并证明了其在全固态电池中的工程应用潜力。

Abstract: Amorphous solid-state electrolytes (SSEs) hold great promise for advancing
the application of all-solid-state batteries (ASSBs), owing to their favorable
ionic conductivity, structural tunability, and promising electrochemical
performance. However, the absence of universal design principles for amorphous
SSEs limits their development. By fundamentally re-evaluating the
amorphization-forming ability of amorphous SSE systems, this study establishes
a nitrogen-driven universal strategy to convert diverse metal chlorides into
amorphous xLi3N-MCly (0.3 < 3x < 1.9; M denotes a metal element; 2 < y < 5)
SSE. Nitrogen synergistically disrupts crystalline order via distorted
coordination polyhedra and N-bridged networks, while dynamic bond
reorganization enables rapid Li+ migration, achieving ionic conductivity of
2.02 mS cm-1 for 0.533Li3N-HfCl4 at 25 {\deg}C. Structural-property
relationships reveal that high charge density and bridging capability of N3-
enhance network disorder, shorten metal coordinating atom distances, and
optimize Li+ diffusion pathway connectivity. ASSBs employing 0.533Li3N-HfCl4
retain 81.87% capacity after 2000 cycles at 1000 mA g-1 with high cathode
loading (6.24 mg cm-2), demonstrating engineering viability. This work provides
a paradigm for rational design of high-performance amorphous SSEs.

</details>


### [412] [Relationship among Structural, Disordered, Magnetism and Band Topology in MnSb2Te4(Sb2Te3)n Family](https://arxiv.org/abs/2510.09973)
*Ming Xi,Yuchong Zhang,Wenju Zhou,Famin Chen,Donghan Jia,Huiyang Gou,Tian Qian,Hechang Lei*

Main category: cond-mat.mtrl-sci

TL;DR: MnSb2Te4(Sb2Te3)n (n=0-5)单晶的研究揭示了新型MnSb8Te13纯相，该相具有铁磁性、拓扑非平庸的电子结构，以及比MnBi2Te4(Bi2Te3)n(n=0-3)更大的体隙和更远离导带的狄拉克点，有望实现接近磁转变温度的量子反常霍尔效应。


<details>
  <summary>Details</summary>
Motivation: 实现接近磁转变温度的量子反常霍尔效应(QAHE)仍然是一个重大挑战，这主要是由于缺乏合适的材料平台以及对能带拓扑、磁性和缺陷之间复杂关系的理解有限。

Method: 通过实验测量和系统分析MnSb2Te4(Sb2Te3)n (n = 0 - 5)单晶，包括发现新型MnSb8Te13纯相，研究其结构、磁性、拓扑和无序之间的关系。

Result: 发现了新型MnSb8Te13纯相，并证实其具有铁磁性和拓扑非平庸的电子结构。与MnBi2Te4(Bi2Te3)n (n = 0 - 3)相比，MnSb8Te13具有更远离导带的狄拉克点和可能更大的体隙。

Conclusion: 该研究为探索实现接近磁转变温度的QAHE的潜在平台提供了新的方向，并为推进拓扑量子材料的研究开辟了新思路。

Abstract: Interplay between topology and magnetism induces various exotic quantum
phenomena, with magnetic topological insulators (MTIs) serving as a prominent
example due to their ability to host the quantum anomalous Hall effect (QAHE).
However, the realization of QAHE at higher temperature approaching
magnetic-transition-temperature remains a significant challenge, primarily due
to the scarcity of suitable material platforms and limited understanding of the
intricate relationships between band topology, magnetism, and defects. Here, we
report a comprehensive investigation of MnSb2Te4(Sb2Te3)n (n = 0 - 5) single
crystals, including the discovery of novel MnSb8Te13 pure phase. Experimental
measurements confirm that MnSb8Te13 exhibits ferromagnetism and features
topologically nontrivial electronic structures, characterized by a Dirac point
located further from the conduction band and a possible larger bulk gap
compared to MnBi2Te4(Bi2Te3)n (n = 0 - 3). Moreover, we systematically analyze
the relationship between structure, magnetism, topology, and disorder within
Mn(Sb, Bi)2Te4((Sb, Bi)2Te3)n family. Present work will shed light on the
exploration of potential platforms capable of achieving QAHE near magnetic
transition temperature, offering new directions for advancing topological
quantum materials.

</details>


### [413] [Ambient-Stable Transfer-Free Graphdiyne Wafers with Superhigh Hole Mobility at Room Temperature](https://arxiv.org/abs/2510.09998)
*Beining Ma,Jianyuan Qi,Xinghai Shen*

Main category: cond-mat.mtrl-sci

TL;DR: 在此论文中，研究人员通过超临界CO2环境下的合成技术，制备了层状可控的氢取代石墨炔（HsGDY）薄膜，并成功将其应用于场效应晶体管（FET）的制造。这种无需转移的生长策略有效避免了器件性能的衰减，并实现了高达3800 cm2 V-1 s-1的室温空穴迁移率，显著优于现有的p型半导体材料。这一成果为解决p型和n型二维半导体器件间的迁移率不匹配问题提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 石墨炔（GDY）作为一种p型半导体材料，在下一代高速低能耗电子器件领域具有潜力，但其较低的载流子迁移率限制了其在场效应晶体管（FET）、互补金属氧化物半导体（CMOS）和逻辑器件等方面的应用。

Method: 通过在超临界CO2气氛下，在硅衬底上直接合成层状可控的氢取代石墨炔（HsGDY）薄膜，并以此薄膜为基础制造HsGDY场效应晶体管（FET）。

Result: 制备的HsGDY场效应晶体管表现出高达3800 cm2 V-1 s-1的室温空穴迁移率，比大多数p型半导体材料高出一个数量级。这种无需转移的合成策略避免了后处理工艺对器件性能的损害。

Conclusion: 研究报告了一种无需转移的HsGDY薄膜的合成方法，并成功将其制成高性能FET。该方法解决了GDY在电子器件应用中的载流子迁移率瓶颈问题，并为解决p型和n型二维半导体器件之间的迁移率失配问题提供了新的策略。

Abstract: Graphdiyne (GDY) is recognized as a compelling candidate for the fabrication
of next-generation high-speed low-energy electronic devices due to its inherent
p-type semiconductor characteristics. However, the development of GDY for
applications in field-effect transistors (FETs), complementary
metal-oxide-semiconductor (CMOS), and logic devices remains constrained by the
relatively low carrier mobility reported in current experimental studies.
Herein, the synthesis of layer-controlled hydrogen-substituted graphdiyne
(HsGDY) films directly on silicon substrates under a supercritical CO2
atmosphere is reported, along with the fabrication of these films into
HsGDY-based FETs. The transfer-free growth strategy eliminates performance
degradation caused by post-synthesis transfer processes. The resulting HsGDY
FETs exhibit a remarkable hole mobility of up to 3800 cm2 V-1 s-1 at
room-temperature, which is an order of magnitude higher than that of most
p-type semiconductors. The synthesis of transfer-free HsGDY wafers provides a
new strategy for resolving the carrier mobility mismatch between p-channel and
n-channel two-dimensional metal-oxide-semiconductor devices.

</details>


### [414] [Multiscale Magnetic Correlations in La2Mn2-xNixO6: Role of Crystal Structure in Double Perovskites](https://arxiv.org/abs/2510.10012)
*A. K. Bera,K. S. Chikara,B. Saha,S. M. Yusuf,Mohd. Nasir,S. Sen*

Main category: cond-mat.mtrl-sci

TL;DR: 随着Ni浓度的增加，La2Mn2-xNixO6（x = 0.5, 0.75, 1.0, 1.25和1.5）中的磁相关性从长程铁磁（FM）有序演变为团簇铁磁或自旋玻璃（FM或SG）行为。


<details>
  <summary>Details</summary>
Motivation: 研究La2Mn2-xNixO6（x = 0.5, 0.75, 1.0, 1.25和1.5）中的磁相关性，以阐明其可调的磁和电性质的微观机制，为设计用于自旋电子学应用的先进材料提供见解。

Method: 采用温度依赖性直流磁化、中子去偏振和中子粉末衍射测量，分别在宏观、介观和微观尺度上系统研究了磁相关性。

Result: 磁性质从长程铁磁有序演变为团簇铁磁或自旋玻璃行为。Ni取代将磁有序温度从170 K（x=0.5）提高到280 K（x=1.0），但伴随着磁化强度和有序磁矩的降低。x=1.0以外的长程磁有序消失。所有成分在低温（约50 K以下）下均表现出重捕获自旋玻璃样相。中子衍射证实长程铁磁有序仅存在于斜方晶相中，而单斜晶和三方晶相缺乏这种磁有序。温度依赖性磁相关性与晶体结构参数的变化密切相关。电导率行为遵循可变程跳跃（VRH）模型。

Conclusion: La2Mn2-xNixO6中的磁和电性质可以通过Ni取代进行调控，这与晶体结构的变化密切相关，为开发用于自旋电子学的新型材料提供了基础。

Abstract: The magnetic correlations in double perovskites La2Mn2-xNixO6 (x = 0.5, 0.75,
1.0, 1.25 and 1.5) have been systematically investigated across macroscopic,
mesoscopic, and microscopic length scales using temperature-dependent bulk DC
magnetization, neutron depolarization, and neutron powder diffraction
measurements, respectivitly. The magnetic properties evolve from a long-range
ferromagnetic (FM) order to a cluster ferromagnetic or spin-glass (FM or SG)
behavior as the Ni concentration increases. This evolution is directly linked
to changes in the crystal structure, transitioning from pure orthorhombic
(x=0.5) to mixed orthorhombic and monoclinic (x=0.75-1.0), and eventually to
mixed trigonal and monoclinic symmetries (x=1.25-1.5). Ni substitution enhances
the magnetic ordering temperature from 170 K (x=0.5) to 280 K (x=1.0), but this
is accompanied by a reduction in both magnetization and ordered magnetic
moment. Beyond x=1.0, any long-range magnetic ordering is absent. Additionally,
all compositions exhibit a reentrant spin-glass-like phase at low temperatures
(below about 50 K). Neutron diffraction analysis confirms that long-range FM
order occurs only in the orthorhombic phase, while the monoclinic and trigonal
phases lack such magnetic ordering. The temperature-dependent magnetic
correlations are closely connected to variations in crystal structural
parameters, including lattice constants and unit cell volume. The electrical
conductivity behavior, following the variable range hopping (VRH) model,
highlights the role of multivalence Mn and Ni ions on the electrical
properties. This study elucidates the microscopic mechanisms behind the tunable
magnetic and electrical properties of La2Mn2-xNixO6, offering valuable insights
for the design of advanced materials for spintronic applications.

</details>


### [415] [Atomic bonding in equilibrium single-component melts. The cases of arsenic, antimony and bismuth](https://arxiv.org/abs/2510.10186)
*Artem A. Tsygankov,Bulat N. Galimzyanov,Anatolii V. Mokshin*

Main category: cond-mat.mtrl-sci

TL;DR: 近熔点温度下的液态磷族元素中，准稳定结构的稳定性与原子质量和结构中原子数量呈幂律负相关。这种稳定性由p轨道的电子相互作用决定。


<details>
  <summary>Details</summary>
Motivation: 探讨近熔点温度下液态磷族元素中准稳定结构的稳定性原因。

Method: 使用晶体轨道哈密顿量布居（COHP）方法，结合从头算模拟，分析了砷、锑和铋在近熔点温度下的性质。

Result: 电子相互作用（特别是p轨道的电子）决定了原子间的键长和键角。结构稳定性随原子质量和原子数量的增加而降低，且遵循幂律关系。

Conclusion: 研究结果有助于从第一性原理理解磷族熔体中准稳定结构的形成机制。

Abstract: In liquid pnictogens, quasi-stable structures can be formed near melting
temperature. The nature of their stability does not have the unified point of
view. In the present work, the task of determining the degree of atomic bonding
in these structures is solved using the Crystal Orbital Hamilton Population
(COHP) method. The original results of ab-initio simulation of arsenic,
antimony and bismuth melts near their melting temperatures are used. It is
shown that the features of the electron interaction at the level of
$p$-orbitals determine the characteristic bond lengths and angles between
atoms. It has been established that the stability of structures decreases
according to a power law with an increase in the atomic mass of a chemical
element and the number of atoms in the structure. The obtained results clarify
the understanding the mechanisms of formation of quasi-stable structures in
pnictogen melts from first principles.

</details>


### [416] [A continued fraction approximation for the effective elasticity tensor of two-dimensional polycrystals as a function of the crystal elasticity tensor](https://arxiv.org/abs/2510.10297)
*Graeme W. Milton*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文研究了二维多晶材料的有效弹性张量，并提出了一种基于渐进层压复合材料的连续分数展开近似方法。


<details>
  <summary>Details</summary>
Motivation: 研究二维多晶材料的有效弹性张量，并探索其函数形式。

Method: 提出一种连续分数展开方法来近似弹性张量，并将其与渐进层压复合材料进行比较。

Result: 证明了该连续分数展开方法可以近似任意多晶微观结构，但可能需要调整自由参数以匹配渐进层压复合材料的响应。

Conclusion: 虽然连续分数展开方法可以近似多晶材料的弹性响应，但仍需进一步研究其是否能精确匹配渐进层压复合材料的响应。

Abstract: For two-dimensional polycrystals the effective elasticity tensor $C_*$ as a
function $C_*(C_0)$ of the elasticity tensor $C_0$ of the constituent crystal
is considered. It is shown that this function can be approximated by one with a
continued fraction expansion resembling that associated with a class of
microstructure known as sequential laminates. These are hierarchical
microstructures defined inductively. Rank 0 sequential laminates are simply
rotations of the pure crystal. Rank $j$ sequential laminates are obtained by
laminating together, on a length scale much larger that the existing
microstructure and with interfaces perpendicular to some direction $n_j$, rank
$j-1$ sequential laminates with a rotation of the pure crystal. The continued
fraction approximation for arbitrary polycrystal microstructures typically
takes a more general form than that of sequential laminates, but has some free
parameters. It is an open question as to whether these free parameters can
always be adjusted so the continued fraction approximation matches exactly that
of a sequential laminate. If so, one would have established that the elastic
response of two-dimensional polycrystals can always be mimicked by that of
sequential laminates. Our analysis carries over to the more general case where
the strain is replaced by a field $E(x)$ that is the gradient of a vector
potential $u(x)$, i.e. $E=\nabla u$ and the stress is replaced by a matrix
valued field $J(x)$ that need not be symmetric but has zero divergence
$\nabla\cdot J=0$. The tensor $L(x)$ entering the constitutive relation $J=L E$
is locally a rotation of the tensor $L_0$ of the pure crystal that need not
have any special symmetries and has 16 independent tensor elements.

</details>


### [417] [Atomic-Scale Origins of Oxidation Resistance in Amorphous Boron Nitride](https://arxiv.org/abs/2510.10326)
*Onurcan Kaya,Qiushi Deng,Thomas Souvignet,Catherine Marichy,Catherine Journet,Ivan Cole,Stephan Roche*

Main category: cond-mat.mtrl-sci

TL;DR: 无定形氮化硼（α-BN）作为纳米电子学中的超薄势垒，其化学稳定性机制尚不明确。本研究结合机器学习分子动力学模拟和X射线光电子能谱，揭示了α-BN的氧化行为与其结构-性质关系密切。


<details>
  <summary>Details</summary>
Motivation: 研究无定形氮化硼（α-BN）的原子机制，以理解其化学稳定性，特别是氧化行为，为纳米电子学应用提供指导。

Method: 利用机器学习分子动力学模拟和角度分辨X射线光电子能谱，研究α-BN的结构-性质关系，特别是其氧化过程。

Result: 模拟结果表明，薄膜的致密度和化学有序性（B-N键比例高）能有效抵抗氧化，仅限于表面；而多孔、富含缺陷（B-B和N-N键）的结构则易于被氧渗透并导致本体降解。实验也证实了较高生长温度下形成的更有序、化学计量比更接近的α-BN薄膜具有更优越的抗氧化性。

Conclusion: α-BN的抗氧化性是可调控的，与其原子尺度形貌直接相关，这为设计化学稳定性好的介电势垒提供了清晰的框架。

Abstract: Amorphous boron nitride (\textrm{$\alpha$}-BN) is a promising ultrathin
barrier for nanoelectronics, yet the atomistic mechanisms governing its
chemical stability remain poorly understood. Here, we investigate the
structure-property relationship that dictates the oxidation of
\textrm{$\alpha$}-BN using a combination of machine-learning molecular dynamics
simulations and angle-resolved X-ray photoelectron spectroscopy. The
simulations reveal that the film structure, controlled by synthesis conditions,
is the critical factor determining oxidation resistance. Dense, chemically
ordered networks with a high fraction of B-N bonds effectively resist oxidation
by confining it to the surface, whereas porous, defect-rich structures with
abundant homonuclear B-B and N-N bonds permit oxygen penetration and undergo
extensive bulk degradation. These computational findings are consistent with
experimental trends observed in \textrm{$\alpha$}-BN films grown by chemical
vapour deposition. XPS analysis shows that a film grown at a higher temperature
develops a more ordered structure with a B/N ratio nearer to stoichiometric and
exhibits superior resistance to surface oxidation compared to its more
defective, lower-temperature counterpart. Together, these results demonstrate
that the oxidation resistance of \textrm{$\alpha$}-BN is a tunable property
directly linked to its atomic-scale morphology, providing a clear framework for
engineering chemically robust dielectric barriers for future nanoelectronic
applications.

</details>


### [418] [Electric Polarization-Driven Modulation of Fe Adatoms on Ferroelectric $α$-In$_2$Se$_3$](https://arxiv.org/abs/2510.10405)
*Monirul Shaikh,Aleksander L. Wysocki*

Main category: cond-mat.mtrl-sci

TL;DR: Fe原子在二维铁电材料α-In2Se3表面的吸附行为受衬底电极化方向的调控，表现出与吸附位点和电极化相关的电子、磁性以及磁各向异性的显著变化，特别是高浓度下可实现超大面外磁各向异性，为电压调控磁性提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 研究Fe原子在二维铁电α-In2Se3表面吸附时，其结构、电子和磁性与衬底电极化方向的相互作用，及其如何被调控。

Method: 利用第一性原理电子结构计算方法，研究Fe原子在α-In2Se3表面的吸附位点、能量势垒、轨道杂化、磁矩和磁各向异性。

Result: 发现了Fe原子存在两种竞争吸附位点，其稳定性受吸附浓度和衬底电极化方向影响。计算得到吸附位点间的能量势垒约为0.4 eV，对应的阻挡温度约为100 K。Fe原子与α-In2Se3的轨道杂化、电子构型、磁矩和磁各向异性表现出位点依赖性，并可被衬底电极化有效调控。特别地，在高浓度下，一种电极化方向可产生超过200 meV/Fe的超大面外磁各向异性，而反向电极化则显著减弱该效应。

Conclusion: 研究结果表明，铁电衬底为通过电压控制磁性吸附原子特性提供了一种有前景的途径，可通过可逆的极化切换实现磁性调控。

Abstract: The interplay among structural, electronic, and magnetic properties of Fe
adatoms on the surface of two-dimensional ferroelectric {\alpha}-In$_2$Se$_3$
is investigated using first-principles electronic structure calculations, with
a focus on how these properties are modulated by the direction of the electric
polarization of the substrate. We identify two competing adsorption sites for
Fe adatoms, whose relative stability depends on the adatom concentration and
can be reversed by switching the electric polarization of
{\alpha}-In$_2$Se$_3$. The calculated energy barrier for thermally activated
hopping between these sites is approximately 0.4 eV, corresponding to a
blocking temperature of around 100 K. The hybridization between Fe and
In$_2$Se$_3$ orbitals strongly depends on the adsorption site and polarization
direction, driven by variations in the local adatom geometry. As a result, the
electronic configuration of adatom, magnetic moment, and magnetic anisotropy
exhibit a pronounced site dependence and can be effectively modulated by
switching the electric polarization of the In$_2$Se$_3$ layer. In particular,
at higher adatom concentrations, an exceptionally large perpendicular magnetic
anisotropy, exceeding 200 meV per Fe atom, emerges for one polarization
direction, but is largely diminished when the polarization is reversed. These
findings indicate that ferroelectric substrates offer a promising route for
voltage-controlled tuning of magnetic adatom properties via reversible
polarization switching.

</details>


### [419] [Growth control of highly textured Bi2Te3 thin films by pulsed laser deposition](https://arxiv.org/abs/2510.10479)
*Damian Brzozowski,Yu Liu,Karola Neeleman,Magnus Nord,Ingrid G. Hallsteinsen*

Main category: cond-mat.mtrl-sci

TL;DR: Bi2Te3薄膜通过脉冲激光沉积技术在SrTiO3上生长，可以通过调整生长条件来控制其化学计量比和薄膜形貌，实现高质量薄膜的制备，为将硫族化物与钙钛矿集成提供了可能。


<details>
  <summary>Details</summary>
Motivation: 研究二维材料在自旋电子学中的应用潜力，特别是将具有强自旋-轨道耦合的硫族化物与功能性氧化物（如钙钛矿）进行异质结集成。

Method: 采用脉冲激光沉积（PLD）技术在(111)取向的SrTiO3衬底上制备高度择优取向的Bi2Te3薄膜。通过精确控制生长温度、压力、激光脉冲频率和能量密度等参数，调控薄膜的化学计量比、表面粗糙度、孔隙率、晶界和晶粒形状。

Result: 成功制备出晶粒尺寸可达430 nm、晶体质量与分子束外延（MBE）相当的Bi2Te3薄膜。研究发现，改变激光参数会对薄膜的表面粗糙度、孔隙率、晶界和晶粒形状产生显著影响。透射电子显微镜分析显示，衬底与薄膜之间界面清晰，无原子互混或非晶中间层形成。

Conclusion: 脉冲激光沉积是一种可行的制备高质量Bi2Te3薄膜的方法，为后续利用该技术将硫族化物与钙钛矿进行异质结集成提供了基础。

Abstract: Two-dimensional materials have attracted growing interest due to their unique
electronic properties and potential applications in spintronics. Interfacing
strongly spin-orbit-coupled chalcogenides with functional oxides such as
perovskites has a particularly high potential. In this work, highly textured
Bi2Te3 thin films were deposited on (111) oriented SrTiO3 by pulsed laser
deposition. We show that, by careful selection of the temperature and pressure
of growth, the film's stoichiometry can be manipulated between direct
stoichiometry transfer from the target and tellurium-deficient phases.
Optimized pulsed laser deposition enables the growth of films with coalesced,
faceted grains with grain sizes reaching up to 430 nm, while preserving
crystalline quality comparable to that of molecular-beam-epitaxy-grown films.
We show striking differences arising from tuning the laser's pulsing frequency
and fluence, which lead to changes in surface roughness, the film's porosity,
and grain boundaries, as well as grain shape. Analysis of cross-sectional
transmission electron microscopy images reveals a sharp substrate-film
interface without atomic intermixing and without the formation of amorphous
intermediate layers. The results demonstrate that pulsed laser deposition is a
viable method for producing high-quality Bi2Te3 thin films and opens the door
to the integration of chalcogenides with perovskites with this growth
technique.

</details>


### [420] [Anisotropic Strain Engineering in La0.7Sr0.3MnO3/LaFeO3 Superlattice: Structural Relaxation and Domain Formation](https://arxiv.org/abs/2510.10482)
*Yu Liu,Thea Marie Dale,Emma van der Minne,Susanne Boucher,Romar Avila,Christoph Klewe,Gertjan Koster,Magnus Nord,Mari-Ann Einarsrud,Ingrid Hallsteinsen*

Main category: cond-mat.mtrl-sci

TL;DR: 外延氧化物薄膜中的各向异性应变工程可以控制对反铁磁自旋电子学至关重要的反铁磁和结构特性。外延应变可以弛豫，形成结构域，并影响磁性。


<details>
  <summary>Details</summary>
Motivation: 利用外延氧化物薄膜中的各向异性应变工程来控制反铁磁和结构特性，以推动反铁磁自旋电子学的发展。

Method: 生长(La0.7Sr0.3MnO3/LaFeO3)4 超晶格于(101)o DyScO3 衬底上，通过倒易空间测绘、扫描预压电子衍射和高阶劳厄带分析来研究应变弛豫和结构域形成，并通过X射线磁二色性测量来研究磁性。

Result: 在(La0.7Sr0.3MnO3/LaFeO3)4 超晶格中，在[010]o 延展轴上观察到选择性应变弛豫，而在[-101]o 压缩轴上仍存在应变。结构域在LaFeO3层中形成，并从第二层开始层内传播。这些结构域与衬底台阶边缘相关。X射线磁二色性测量显示出具有多畴特征的块状面内反铁磁序。

Conclusion: 发现了与反铁磁多畴态共存的结构畴，揭示了应变-畴-磁性关系，为应变工程在自旋电子学中的应用提供了新的见解。

Abstract: Anisotropic strain engineering in epitaxial oxide films provides new
opportunities to control the antiferromagnetic and structural properties
crucial for advancements of antiferromagnetic spintronics. Here we report on a
(La0.7Sr0.3MnO3/LaFeO3)4 superlattice grown on (101)o DyScO3 substrate which
imposes significant anisotropic in-plane strain. Reciprocal space mapping
reveals selective strain relaxation along the tensile in-plane [010]o axis,
while compression along the perpendicular in-plane [-101]o axis remains
strained. Scanning precession electron diffraction and higher-order Laue zone
analysis show that the relaxation is accommodated by structural domain
formation in the LaFeO3 layers, initiating from the second bilayer and
propagating out-of-plane. These domains minimise structural defects and
correlate with the substrate step edges. X-ray magnetic dichroism measurements
reveal bulk-like in-plane antiferromagnetic order with polydomain signature as
previously reported. Our findings reveal the presence of structural domains
coexisting with antiferromagnetic polydomain states, showing a
strain-domain-magnetism relationship that provides insights for applications of
strain engineering in spintronics applications.

</details>


### [421] [Resolving the Structural Duality of Graphene Grain Boundaries](https://arxiv.org/abs/2510.10491)
*Haojie Guo,Emiliano Ventura-Macías,Mariano D. Jiménez-Sánchez,Nicoleta Nicoara,Pierre Mallet,Jean-Yves Veuillen,Vincent T. Renard,Antonio J. Martínez-Galera,Pablo Pou,Julio Gómez-Herrero,Rubén Pérez,Iván Brihuega*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Grain boundaries (GBs) are ubiquitous in large-scale graphene samples,
playing a crucial role in their overall performance. Due to their complexity,
they are usually investigated as model structures, under the assumption of a
fully relaxed interface. Here, we present cantilever-based non-contact atomic
force microscopy (ncAFM) as a suitable technique to resolve, atom by atom, the
complete structure of these linear defects. Our experimental findings reveal a
richer scenario than expected, with the coexistence of energetically stable and
metastable graphene GBs. Although both GBs are structurally composed of
pentagonal and heptagonal like rings, they can be differentiated by the
irregular geometric shapes present in the metastable boundaries. Theoretical
modeling and simulated ncAFM images, accounting for the experimental data, show
that metastable GBs form under compressive uniaxial strain and exhibit vertical
corrugation, whereas stable GBs remain in a fully relaxed, flat configuration.
By locally introducing energy with the AFM tip, we show the possibility to
manipulate the metastable GBs, driving them toward their minimum energy
configuration. Notably, our high-resolution ncAFM images reveal a clear
dichotomy: while the structural distortions of metastable grain boundaries are
confined to just a few atoms, their impact on graphene's properties extends
over significantly larger length scales.

</details>


### [422] [A ferroelectric junction transistor memory made from switchable van der Waals p-n heterojunctions](https://arxiv.org/abs/2510.10521)
*Baoyu Wang,Lingrui Zou,Tao Wang,Lijun Xu,Zexin Dong,Xin He,Shangui Lan,Yinchang Ma,Meng Tang,Maolin Chen,Chen Liu,Zhengdong Luo,Lijie Zhang,Zhenhua Wu,Yan Liu,Genquan Han,Bin Yu,Xixiang Zhang,Fei Xue,Kai Chang*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过结合SnSe和{\\alpha}-In2Se3两种材料，成功制备了近乎理想的多功能范德华p-n异质结，其漏电流极小（0.1 pA），二极管理想因子为1.95，并且晶体管开关比高达10^5。该研究的关键在于实现了铁电调控的能带对齐，能够调节900 meV的巨大势垒。在此基础上，研究人员提出并演示了一种新型铁电结场效应晶体管（FeFET）记忆器件，该器件具有1.8 V的大记忆窗口、100 ns的超快读写速度、393 K的高温稳定工作能力以及2%的低循环变异性。此外，该记忆器件展现出的可靠的突触特性，为低功耗神经形态计算提供了可能性。这项工作为开发具有可切换记忆功能的异质结器件提供了一个新的平台，适用于高性能的脑启发电子和光电子学。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有范德华p-n异质结中可调控耗尽区和抑制漏电流的挑战，以提升器件性能和功能。

Method: 利用带对齐的p型SnSe和n型铁电{\\alpha}-In2Se3作为模型，制备范德华p-n异质结，并通过铁电调控实现能带对齐，研究其电学特性，并在此基础上设计和验证铁电结场效应晶体管记忆器件。

Result: 制备了漏电流为0.1 pA、二极管理想因子为1.95的近乎理想的多功能范德华p-n异质结。制备的结型晶体管表现出超过10^5的高开关比。实现了铁电调控的能带对齐，获得了900 meV的巨大势垒调制。展示了具有1.8 V记忆窗口、100 ns速度、393 K高温工作能力和2%低循环变化的铁电结场效应晶体管记忆器件，并观察到可靠的突触特性。

Conclusion: 该研究成功制备了高性能范德华p-n异质结，并通过铁电调控实现了可调的能带对齐，为开发新型铁电结场效应晶体管记忆器件奠定了基础，该器件在存储、神经形态计算等领域具有广阔的应用前景。

Abstract: Van der Waals (vdW) p-n heterojunctions are important building blocks for
advanced electronics and optoelectronics, in which high-quality heterojunctions
essentially determine device performances or functionalities. Creating tunable
depletion regions with substantially suppressed leakage currents presents huge
challenges, but is crucial for heterojunction applications. Here, by using
band-aligned p-type SnSe and n-type ferroelectric {\alpha}-In2Se3 as a model,
we report near-ideal multifunctional vdW p-n heterojunctions with small reverse
leakage currents (0.1 pA) and a desired diode ideality factor (1.95).
As-fabricated junction transistors exhibit superior performance, such as a high
on/off ratio of over 105. Importantly, we realize ferroelectric-tuned band
alignment with a giant barrier modulation of 900 meV. Based on such tunable
heterojunctions, we propose and demonstrate a fundamental different device
termed ferroelectric junction field-effect transistor memory, which shows large
memory windows (1.8 V), ultrafast speed (100 ns), high operation temperature
(393 K), and low cycle-to-cycle variation (2 %). Additionally, the reliable
synaptic characteristics of these memory devices promise low-power neuromorphic
computing. Our work provides a new device platform with switchable memory
heterojunctions, applicable to high performance brain-inspired electronics and
optoelectronics.

</details>


### [423] [Near room temperature magnetoelectric response and tunable magnetic anisotropy in the two-dimensional magnet 1T-CrTe2](https://arxiv.org/abs/2510.10547)
*Fengping Li,Bheema Lingam Chittari,Chao Lei,Jeil Jung*

Main category: cond-mat.mtrl-sci

TL;DR: 二维CrTe2在单层极限下具有高达约300K的实验临界温度，这使其在自旋电子器件中具有应用潜力。通过第一性原理密度泛函理论研究，可以证明形变或电场可以调控其磁性质，如磁晶各向异性、临界居里温度和磁化强度。


<details>
  <summary>Details</summary>
Motivation: 需要具有可控磁化和高临界温度的磁体来实现实用的自旋电子器件。

Method: 使用第一性原理密度泛函理论研究单层和双层1T-CrTe2的磁性质。

Result: 形变或电场可以调控单层和双层1T-CrTe2的磁性质，包括磁晶各向异性、临界居里温度和磁化强度。

Conclusion: 形变或电场是调控二维1T-CrTe2磁性质的有效方法，有望推动自旋电子器件的发展。

Abstract: Magnets with controllable magnetization and high critical temperature are
essential for practical spintronics devices, among which the two-dimensional
1T-CrTe2 stands out because of its high experimental critical temperature up to
about 300K down to the single layer limit. By using ab initio density
functional theory, we investigate the magnetic properties of monolayer and
bilayer 1T-CrTe2 and demonstrate that the magnetic properties, such as the
magnetocrystalline anisotropy, critical Curie temperature and magnetizations,
can be influenced by strain or electric fields.

</details>


### [424] [Breaking the Sabatier Principle by Dynamic Adsorption-Desorption Decoupling in Electrocatalytic Hydrogen Evolution](https://arxiv.org/abs/2510.10555)
*Zi-Xuan Yang,Lei Li,Tao Huang,Hui Wan,X. S. Wang,Gui-Fang Huang,Wangyu Hu,Wei-Qing Huang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过动态调控氢吸附强度，该研究实现了超越传统火山限制的析氢反应活性。


<details>
  <summary>Details</summary>
Motivation: 氢析氢反应（HER）受Sabatier原理的限制，该原理指出吸附强度和脱附强度之间的权衡关系限制了催化剂的活性。

Method: 研究提出了一种基于单层GeS2的铁电平台，并用过渡金属原子进行修饰。通过极化驱动的表面电子重构，实现了对中间产物结合强度的实时调控，从而动态地改变氢的吸附强度。

Result: 该平台能够实现对氢吸附-脱附过程的解耦，先增强吸附以加速Volmer步骤，再减弱吸附以促进Heyrovsky/Tafel步骤，实现了前所未有的HER活性，并超越了火山曲线的限制。

Conclusion: 该研究提出的动态调控平台不仅在HER方面取得了突破，而且为设计能够适应操作条件的可重构自适应催化剂提供了一个通用范式。

Abstract: The Sabatier principle establishes a fundamental trade-off in heterogeneous
electrocatalysis.In the hydrogen evolution reaction (HER), this trade-off is
manifested by the coupling of Volmer step, which requires strong hydrogen
adsorption, with the Heyrovsky/Tafel step, which favors facile desorption, thus
giving rise to the classical volcano relationship and limiting activity even at
$\Delta G=0$. Here, we demonstrate a ferroelectric platform with dynamic
tunability -- monolayer GeS$_2$ decorated with transition metal atoms as a
proof-of-concept -- where polarization-driven surface electronic reconstruction
enables real-time modulation of intermediate binding strength, thereby breaking
the Sabatier constraint. Reversible control of hydrogen adsorption allows
strong H binding to accelerate the Volmer step, followed by weakened adsorption
to promote the Heyrovsky/Tafel step.This dynamic adsorption-desorption
decoupling not only surpasses the volcano limit to achieve unprecedented HER
activity, but also establishes a general paradigm for designing adaptive
electrocatalysts capable of reconfiguring under operating conditions.

</details>


### [425] [Weak-anti-localization-to-spin-dependent scattering at a proximity-magnetized heavy metal interface](https://arxiv.org/abs/2510.10595)
*Hisakazu Matsuki,Guang Yang,Jiahui Xu,Vitaly N. Golovach,Yu He,Jiaxu Li,Alberto Hijano,Niladri Banerjee,Iuliia Alekhina,Nadia Stelmashenko,F. Sebastian Bergeret,Jason W. A. Robinson*

Main category: cond-mat.mtrl-sci

TL;DR: EuS/Au/EuS自旋开关中，通过改变Au的厚度，可以实现从弱反局域化到界面GMR的转变，这与EuS引起的磁邻近效应有关，并为非金属磁性自旋电子学器件的构建提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 研究磁性材料中电子干涉和自旋相关输运的机制，以及如何通过调控材料厚度实现自旋电子学功能。

Method: 在EuS/Au/EuS自旋开关结构中，改变Au层的厚度（4-28 nm），并测量其磁阻效应，分析磁阻行为随厚度变化的交叉现象。

Result: 在Au厚度较小时，观察到弱反局域化现象；随着Au厚度增加，出现界面GMR和自旋霍尔磁阻效应。发现Au层中的磁邻近效应能够抑制弱反局域化，并且GMR的出现与界面交换场有关。

Conclusion: EuS/Au/EuS系统中，通过Au层厚度的调控，可以实现从弱反局域化到界面GMR的转变，该转变与EuS诱导的磁邻近效应密切相关。研究结果为在非磁性金属中实现自旋电子学功能提供了新的途径。

Abstract: A change in a materials electrical resistance with magnetic field
(magnetoresistance) results from quantum interference effects and, or
spin-dependent transport, depending on materials properties and dimensionality.
In disordered conductors, electron interference leads to weak localization or
anti-localization; in contrast, ferromagnetic conductors support spin-dependent
scattering, leading to giant magnetoresistance (GMR). By varying the thickness
of Au between 4 and 28 nm in a EuS/Au/EuS spin-switches, we observe a crossover
from weak anti-localization to interfacial GMR. The crossover is related to a
magnetic proximity effect in Au due to electron scattering at the insulating
EuS interface. The proximity-induced exchange field in Au suppresses weak
anti-localization, consistent with Maekawa-Fukuyama theory. With increasing Au
thickness, GMR emerges along with spin Hall magnetoresistance. These findings
demonstrate spin transport governed by interfacial exchange fields, building a
framework for spintronic functionality without metallic magnetism.

</details>


### [426] [Topology and Martensitic Phase Transformations](https://arxiv.org/abs/2510.10610)
*M. Yin,D. D. Vvedensky*

Main category: cond-mat.mtrl-sci

TL;DR: TPMS可以指示非磁性晶体是否会经历马氏体相变。


<details>
  <summary>Details</summary>
Motivation: 研究TPMS与晶体电荷密度分布、马氏体相变拓扑连续性的关系，并探索TPMS在预测马氏体相变中的应用。

Method: 基于既有工作，研究TPMS与晶体电荷密度分布的对应关系，并分析马氏体相变前后末端态对应的TPMS的拓扑等价性，以解释马氏体相变的拓扑连续性。

Result: 发现TPMS可以指示非磁性晶体是否可以进行马氏体相变。

Conclusion: TPMS的拓扑等价性是马氏体相变拓扑连续性的体现，TPMS可以作为预测非磁性晶体是否发生马氏体相变的指标。

Abstract: Triply periodic minimal surfaces (TPMS) are discovered to conform to surfaces
of given charge density distributions embedded in crystals [Z. Kristallogr.
\textbf{170}, 138 (1985)]. Based on our previous work [Phys. Rev. Mater.
\textbf{9}, 073802 (2025)], we discovered that crystals can have surfaces of a
given charge density converging to TPMS. We also discovered that end states
connected by a martensitic phase transformation should have their corresponding
TPMS being topologically equivalent. In this work, we gave an explanation for
the topological continuity of a martensitic phase transformation and studied
how TPMS indicate whether a non-magnetic crystal can undergo a martensitic
phase transformation or not.

</details>


### [427] [Near-room-temperature antiferromagnetism in Janus Fe$X$F ($X$ = O, S) monolayers](https://arxiv.org/abs/2510.10646)
*Xixiang Zhang,Busheng Wang,Yanfeng Ge,Yong Liu,Wenhui Wan*

Main category: cond-mat.mtrl-sci

TL;DR: FeF2及其衍生物（FeOF、FeSF）是具有优异磁性的反铁磁半导体。


<details>
  <summary>Details</summary>
Motivation: 受最近合成的FeF2六方层状相的启发，研究FeF2单层及其Janus衍生物（FeOF、FeSF）的磁性。

Method: 使用第一性原理计算研究了1T-FeF2单层及其Janus FeXF（X=O, S）衍生物的磁性。

Result: 结果证实这些材料是反铁磁半导体。阳离子取代有效地调节了它们的材料性质：带隙从3.37 eV（FeF2）变为2.35 eV（FeOF）和1.13 eV（FeSF）；Fe离子的磁矩增加；Néel温度（TN）显著升高，FeSF可达248 K，FeOF可达207 K。Janus结构表现出增强的磁矩和直接反铁磁耦合。在压缩下，TN进一步优化至274 K（FeSF，-2%应变）和244 K（FeOF，-5%应变）。两种Janus材料在±5%应变下均保持其半导体性质和易磁化轴方向。

Conclusion: Janus结构是增强二维反铁磁性的一种可行方法，而铁基氧卤化物是有前途的自旋电子材料。

Abstract: Inspired by the recently synthesized hexagonal layered phase of FeF$_2$, we
studied the magnetic properties of the 1T-FeF$_2$ monolayer and its Janus
Fe$X$F ($X$ = O, S) derivatives by first-principles calculations. Our results
confirm that these materials are antiferromagnetic semiconductors, and that
anion substitution effectively tunes their material properties: the band gap
shifts from 3.37 eV (direct, FeF$_2$) to 2.35 eV (direct, FeOF) and 1.13 eV
(indirect, FeSF); the magnetic moment of Fe ions increases; and the N\'{e}el
temperature ($T_N$) rises dramatically to 248 K (FeSF) and 207 K (FeOF). Janus
structures exhibit enhanced magnetic moment and direct AFM coupling. Under
compression, $T_N$ is further optimized to 274 K ($-2$\% strain, FeSF) and 244
K ($-5$\% strain, FeOF). Both Janus materials retain their semiconducting
nature and direction of easy magnetization axis under $\pm5$\% strain. This
study validates the Janus structure as a viable approach to enhance 2D
antiferromagnetism and highlights Fe-based oxyhalides as promising spintronic
materials.

</details>


### [428] [Ultra-transient grating spectroscopy for visualization of surface acoustics](https://arxiv.org/abs/2510.10696)
*Tomáš Grabec,Pavla Stoklasová,Kristýna Repček,Jakub Kušnír,David Mareš,Martin Ševčík,Petr Sedlák,Hanuš Seiner*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究首次通过实验可视化了材料表面的弹性行为，并成功复制了理论上的格林函数。


<details>
  <summary>Details</summary>
Motivation: 为了全面捕捉材料表面弹性行为的频率和方向依赖性特征，需要对表面进行表征。

Method: 通过对瞬态光栅光谱（TGS）进行改进，利用近场热声现象，观察到了超瞬态振荡，并引入了超瞬态光栅光谱（UTGS）技术。

Result: 实验结果与理论格林函数高度吻合，实现了对各向异性材料的详细表征。

Conclusion: UTGS作为一种新的无接触表征工具，为研究单晶材料在固态冷却、磁弹性器件和纳米机电系统等领域的应用开辟了新途径。

Abstract: Ultrasonic wave propagation across material surfaces reveals essential
information about the materials' elastic behavior. The elastodynamic response
of the surface is characterized by the Green's function that fully captures all
its direction-dependent and frequency-dependent features. Here we present the
first direct experimental visualization of the Green's function, including all
its complex details resulting from elastic anisotropy. We achieve this
visualization using a dedicated modification of transient grating spectroscopy
(TGS), which is a method otherwise well established for measuring Rayleigh-type
surface acoustic waves. To overcome the limitations of conventional TGS, we
explore near-field thermoacoustic phenomena occurring within TGS experiments.
We reveal that, along with the transient standing-wave patterns that diminish
within hundreds of nanoseconds, there also emerge ultra-transient oscillations
with lifetimes at least an order of magnitude shorter. These ultra-transient
effects enable capturing the surface acoustic response with exceptional detail,
and the resulting experimental angular dispersion maps strikingly replicate the
theoretical Green's functions. By utilizing this feature, ultra-transient
grating spectroscopy (UTGS) becomes a powerful new tool for detailed
contactless characterization of anisotropic solids, opening new pathways for
studying single-crystalline materials utilized in diverse modern application
fields, including solid-state cooling via the elastocaloric effect,
magnetoelastic devices, or nanoscale electromechanical systems.

</details>


### [429] [Unveiling the growth mode diagram of GaSe on sapphire](https://arxiv.org/abs/2510.10743)
*M. Bissolo,M. Dembecki,J. Belz,J. Schabesberger,M. Bergmann,P. Avdienko,F. Rauscher,A. S. Ulhe,H. Riedl,K. Volz,J. J. Finley,E. Zallo,G. Koblmüller*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究通过分子束外延技术在蓝宝石衬底上生长硒化镓，并构建了生长模式图，为规模化合成和集成二维材料提供了方法。


<details>
  <summary>Details</summary>
Motivation: 在工业相关衬底上生长二维外延材料对于其规模化合成和集成到下一代技术至关重要。

Method: 利用原位反射高能电子衍射（RHEED）、原位拉曼光谱、光学和扫描电子显微镜，研究了在530-650°C的衬底温度和5-110的Se/Ga通量比下，硒化镓在2英寸c面蓝宝石衬底上的生长模式。

Result: 生长模式图揭示了不同的生长区域，包括生长具有未应变面内晶格常数（0.371±0.001 nm）和在蓝宝石上部分外延排列的层状后过渡金属单硫族化合物GaSe。

Conclusion: 这项工作展示了一种基于RHEED合成特定相和形貌的硒化镓的方法，并为高蒸气压III-VI族化合物构建了相图，该方法可应用于多种其他金属硫族化合物材料。

Abstract: The growth of two-dimensional epitaxial materials on industrially relevant
substrates is critical for enabling their scalable synthesis and integration
into next-generation technologies. Here we present a comprehensive study of the
molecular beam epitaxial growth of gallium selenide on 2-inch c-plane sapphire
substrates. Using in-situ reflection high-energy electron diffraction (RHEED),
in-situ Raman spectroscopy, optical and scanning electron microscopies, we
construct a diagram of the gallium selenide growth modes as a function of
substrate temperature (530-650 {\deg}C) and Se/Ga flux ratio (5-110). The
growth mode diagram reveals distinct regimes, including the growth of layered
post-transition metal monochalcogenide GaSe with an unstrained in-plane lattice
constant of 0.371$\pm$0.001 nm and a partial epitaxial alignment on sapphire.
This work demonstrates a RHEED-based pathway for synthesizing gallium selenide
of specific phase and morphology, and the construction of a phase diagram for
high vapor pressure III-VI compounds that can be applied to a wide range of
other metal chalcogenide materials.

</details>


### [430] [Electron-hole liquid in biological tissues under ultra high dose rate ionizing radiation](https://arxiv.org/abs/2510.10786)
*Diana Shvydka,Victor Karpov*

Main category: cond-mat.mtrl-sci

TL;DR: We created a model for ionization in biological tissues under ultra-high dose rate radiation, based on the idea of electron-hole liquid (EHL) forming in water-based substances. This EHL is different from that in semiconductors because the charge carriers are less mobile and interact strongly with the background, resembling ionic melts. This leads to recombination barriers that suppress further structural changes, limiting the generation of reactive species and reducing biological damage, thus sparing tissue. We analyzed how tissue properties and dielectric permittivity affect these processes and derived equations for dose and dose rate thresholds.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a quantitative model for understanding ionization processes in biological tissues under Ultra High Dose Rate (UHDR) radiation, specifically investigating the conjecture of electron-hole liquid (EHL) formation.

Method: The method involves developing a quantitative model of ionization processes, considering the formation of electron-hole liquid (EHL) in water-based substances. The model accounts for strong interactions of charge carriers with the background, resembling ionic melts, and incorporates the effects of Coulomb coupling, recombination barriers, and frequency dispersion of dielectric permittivity. Equations for dose and dose rate sparing thresholds are derived.

Result: The results show that the formation of EHL leads to recombination barriers that suppress subsequent structural transformations. This suppression limits the generation of secondary reactive species, which translates into reduced biological damages and a tissue sparing effect. The study demonstrates the sensitivity of these processes to tissue quality and the frequency dispersion of dielectric permittivity.

Conclusion: The paper concludes that the proposed model of electron-hole liquid (EHL) formation in biological tissues under UHDR radiation provides insights into the mechanisms of reduced biological damage and tissue sparing. The derived equations for dose and dose rate sparing thresholds can be used to predict the effects of UHDR radiation.

Abstract: We develop a quantitative model of ionization processes in biological tissues
under Ultra High Dose Rate (UHDR) radiation. The underlying conjecture is that
of electron-hole liquid (EHL) forming in water based substances of biological
tissues. Unlike the earlier known EHL in semiconductor crystals, the charge
carriers here are low mobile due to strong interactions with the background
(solvated electrons, etc.); hence, EHL resembling ionic melts. Similar to all
ionic systems, the Coulomb coupling makes that EHL energetically favorable that
leads to recombination barriers suppressing subsequent structural
transformations. In particular, generation of secondary reactive species in
such EHL becomes limited translating into reduction of biological damages and
tissue sparing effect. We show how these processes are sensitive to the tissue
quality and frequency dispersion of the dielectric permittivity. Equations for
dose and dose rate defining the sparing thresholds are derived.

</details>


### [431] [Emerging Ferroelectric Domains: Stacking and Rotational Landscape of MoS2 Moire Bilayers](https://arxiv.org/abs/2510.10831)
*Anikeya Aditya,Ayu Irie,Nabankur Dasgupta,Rajiv K. Kalia,Aiichiro Nakano,Priya Vashishta*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了扭转双层二硫化钼中堆垛顺序和旋转对莫尔图案的影响，发现初始堆垛顺序决定了莫尔图案的形成。


<details>
  <summary>Details</summary>
Motivation: 探究堆垛顺序对二硫化钼双层莫尔图案的影响，因为其对扭转角敏感但对堆垛顺序的研究相对较少。

Method: 使用分子动力学模拟，在五种高对称堆垛顺序的基础上，施加1到120度的扭转角，研究莫尔图案的形成。

Result: 初始堆垛顺序显著影响特定扭转角下形成的莫尔结构。所有五种堆垛顺序在无扭转时都是亚稳态的，但它们形成了两个莫尔等价类：AA/AB 和 AA', A'B, AB'。在给定扭转角下，同一类别内的结构会弛豫到相同的莫尔构型。AA和AB堆垛在0+/-3度附近产生三角形铁电畴，而AA', A'B, 和AB'堆垛在60+/-3度附近产生三角形铁电畴。在精确的60度和120度扭转时，双层弛豫为纯高对称堆垛。

Conclusion: 堆垛顺序在控制扭转电子系统中可及的莫尔图案方面起着至关重要的作用。

Abstract: The structures and properties of moire patterns in twisted bilayers of
two-dimensional (2D) materials are known to depend sensitively on twist angle,
yet their dependence on stacking order remains comparatively underexplored. In
this study, we use molecular dynamics simulations to systematically investigate
the combined effects of stacking order and rotation in MoS2 bilayers. Beginning
from five well-established high-symmetry bilayer stackings, we apply twist
angles between 1 and 120 to the top layer, revealing a variety of relaxed moire
structures. Our results show that the initial stacking significantly influences
the moire domain configurations that emerge at a given twist angle. While all
five stacking orders are metastable without twist, they form two
moire-equivalent classes- AA/AB and AA',A'B,AB', i.e., for a given twist angle,
structures within each class relax to the same moire configuration.
Specifically, initial AA and AB stackings give rise to triangular ferroelectric
domains near 0+/-3, while AA', A'B, and AB' stackings produce triangular
ferroelectric domains near 60+/-3. At precisely 60 and 120 twists, the bilayers
relax to into pure high-symmetry stackings, highlighting the rotational
relationships between these configurations and explaining the shift of 60 in
the ferroelectric rotational range. These findings demonstrate the critical
role of stacking order in governing the rich moire landscapes accessible in
twistronic systems.

</details>


### [432] [Delayed 1T to 2H Phase Transition Upon Electrochemical Delithiation of LiMoS2](https://arxiv.org/abs/2510.10911)
*Yerin Hong,Juhwan Lim,Jinhong Min,Nishkarsh Agarwal,Robert Hovden,Ageeth A. Bol,Yiyang Li*

Main category: cond-mat.mtrl-sci

TL;DR: MoS2在脱锂后会从金属1T相转变为半导体2H相，但这一过程需要几天时间。


<details>
  <summary>Details</summary>
Motivation: 研究MoS2在电化学脱锂过程中的相变行为，特别是脱锂后相变的可逆性。

Method: 使用微电极阵列进行单片MoS2的电化学（脱）锂化，并结合电化学电压分析和拉曼光谱进行表征。

Result: MoS2在脱锂后会保持1T相，但经过几天后会逐渐转变为2H相。这表明1T-MoS2相可以通过电化学方法合成。

Conclusion: MoS2在脱锂过程中的相变行为是复杂的，涉及从1T相到2H相的缓慢转变，这为1T-MoS2相的电化学合成提供了新的途径。

Abstract: Molybdenum disulfide (MoS2) is a widely studied layered material for
electronic, optical, and catalytic applications. It can host lithium ions
between the van der Waals layers, which triggers a phase transition between the
semiconducting 2H phase and metallic 1T phase. While lithium insertion triggers
a phase transition to the 1T phase, the phase behavior upon electrochemical
lithium removal is not resolved. In this work, we conduct single-flake
electrochemical (de)lithiation of MoS2 using microelectrode arrays. Through
both electrochemical voltage analysis and correlative Raman spectroscopy, we
show that an electrochemically cycled and delithiated MoS2 flake initially
remains in the 1T phase. However, over the course of several days, it
transitions back into the thermodynamically stable 2H phase. This result
resolves the phase transformation pathway upon delithiation and showcases the
ability to electrochemically synthesize the metastable 1T-MoS2 phase.

</details>


### [433] [Generalized quantum limits of electrical contact resistance and thermal boundary resistance](https://arxiv.org/abs/2510.10919)
*Alice Ho,Jashan Singhal,Deji Akinwande,Huili Grace Xing,Debdeep Jena*

Main category: cond-mat.mtrl-sci

TL;DR: 为各种能带结构和所有维度推导出了电子接触电阻率和热边界电阻的量子极限的通用表达式。


<details>
  <summary>Details</summary>
Motivation: 随着器件缩减到原子极限，电子接触电阻和热边界电阻的重要性急剧增加。未来将越来越多地使用具有各种能带结构（例如抛物线、圆锥）和利用各种维度（例如一维线、二维片和三维块）的几何形状的丰富材料。

Method: 推导了各种能带结构和所有维度的电子接触电阻率的单一通用表达式。还推导了相应的热边界电阻量子极限的结果。

Result: 得出了电子接触电阻率和热边界电阻的量子极限的通用表达式。

Conclusion: 这些结果将有助于定量地协同设计、进行基准测试和指导降低节能设备的电气和热边界电阻。

Abstract: The importance of electrical contact resistance and thermal boundary
resistance has increased dramatically as devices are scaled to atomic limits.
The use of a rich range of materials with various bandstructures (e.g.
parabolic, conical), and in geometries exploiting various dimensionalities
(e.g. 1D wires, 2D sheets, and 3D bulk) will increase in the future. Here we
derive a single general expression for the quantum limit of electrical contact
resistivity for various bandstructures and all dimensions. A corresponding
result for the quantum limit of thermal boundary resistance is also derived.
These results will be useful to quantitatively co-design, benchmark, and guide
the lowering of electrical and thermal boundary resistances for energy
efficient devices.

</details>


### [434] [Frenkel anomaly on co-ordination numbers in liquid CO2 at 100 and 1000 bar studied by Monte Carlo simulation using Kihara potential model](https://arxiv.org/abs/2510.11029)
*Koji Kobashi*

Main category: cond-mat.mtrl-sci

TL;DR: 通过计算配位数值来确定CO2的Frenkel线的位置。


<details>
  <summary>Details</summary>
Motivation: 确定CO2的Frenkel线的位置，因为目前尚无定论。

Method: 使用Kihara势通过蒙特卡洛模拟计算配位数值，并与基于速度自相关函数的先前结果进行比较。

Result: 在P=100 bar, T=260 K时，Frenkel线的位置与基于VAFs的先前结果一致；在P=1000 bar, T=370 K时，Frenkel线的位置存在显著偏差。

Conclusion: 配位数值可以作为确定CO2 Frenkel线位置的替代方法，但需要进一步研究以解决在P=1000 bar, T=370 K时观察到的偏差。

Abstract: An issue concerning the Frenkel line of liquid CO2 is that its location has
not been unequivocally determined. So far, reliable Frenkel lines were
identified from velocity autocorrelation functions (VAFs) computed by Molecular
Dynamic simulations; however VAFs cannot be directly verified experimentally.
By contrast, the co-ordination numbers (CNs) can be measured experimentally by
X-ray and neutron scattering or computed by Monte Carlo (MC) simulation, and
thus provide an alternative means of determining the location of the Frenkel
line. In the present study, the CNs were computed by MC simulation using the
Kihara potential, and the Frenkel anomalies were identified at {P = 100 bar, T
= 260 K}, in good agreement with previous results based on VAFs, and at {P =
1000 bar, T = 370 K}, which deviates significantly from them.

</details>


### [435] [Entropy Engineering-Regulated Electron-Phonon Coupling for Highly Efficient Photoluminescence in Se-doped WS2](https://arxiv.org/abs/2510.11081)
*Chi Zhang,Quan Shen,Mengmeng Zhang,Zhiming Deng,Taishen Wu,Xuying Zhong,Gang Ouyang,Dongsheng Tang,Qi Zheng,Jiansheng Dong,Weichang Zhou*

Main category: cond-mat.mtrl-sci

TL;DR: 通过硒掺杂或范德华相互作用引入熵，可以提高 WS2 单分子层的光致发光。


<details>
  <summary>Details</summary>
Motivation: 解决液相生长或转移堆叠的拉伸单层过渡金属硫属化物量子产率低的问题，以增强其光电器件的应用。

Method: 引入“熵工程”策略，通过精确的硒掺杂或界面范德华相互作用引入可控的电子-声子耦合，以选择性地增强光-物质相互作用。

Result: 硒掺杂可显著提高 WS2 在拉伸条件下的光致发光。轻微硒掺杂可使发射强度提高一个数量级，而重掺杂则会因直接到间接带隙跃迁而导致 PL 猝灭。范德华耦合也可通过界面熵和邻近效应进一步增强 PL。

Conclusion: 通过可控掺杂实现熵工程是激活原子层半导体高效发光的有力策略。

Abstract: The limited quantum yield of strained monolayer transition metal
dichalcogenides grown by vapor-phase methods and during transfer-based stacking
poses a fundamental challenge for their optoelectronic applications. Here, we
introduce the concept of "entropy engineering" as a transformative strategy to
selectively enhance light-matter interactions through controlled
electron-phonon coupling. We unveil how tailored entropy introduced via precise
selenium doping or interfacial van der Waals proximity can significantly
amplify radiative recombination from momentum-dark excitons in WS2 monolayers.
Notably, we discover that slight selenium doping drastically enhances the
photoluminescence (PL) of WS2 under strain. While both undoped and heavily
doped WS2 suffer from strong PL quenching owing to the direct-to-indirect
bandgap transition, lightly Se-doped samples exhibit an order-of-magnitude
increase in emission intensity. This counterintuitive boost is traced to
doping-induced structural disorder, which intensifies electron-phonon
interactions and unlocks efficient phonon-assisted emission from otherwise
non-radiative indirect excitons. Moreover, we demonstrate that van der Waals
coupling to adjacent Se-doped layers can impart interfacial entropy and further
augment PL via proximity effects. Our work highlights entropy engineering via
controlled doping as a powerful strategy for activating high-efficiency light
emission in atomically thin semiconductors.

</details>


### [436] [In-plane polar domains enhanced energy storage](https://arxiv.org/abs/2510.11126)
*Yu Lei,Xiaoming Shi,Sihan Yan,Qinghua Zhang,Jiecheng Liu,Sixu Wang,Yu Chen,Jiaou Wang,He Qi,Qian Li,Ting Lin,Jingfen Li,Qing Zhu,Haoyu Wang,Jing Chen,Lincong Shu,Linkun Wang,Han Wu,Xianran Xing*

Main category: cond-mat.mtrl-sci

TL;DR: Relaxor铁电薄膜在储能领域表现出高功率密度，但实现高能量存储性能、化学均匀性、环境友好性和组成稳定性仍具挑战。本研究提出了一种通过面内极域和极性纳米区结合的机制来设计高能量存储性能的介电材料。


<details>
  <summary>Details</summary>
Motivation: 实现化学均匀、环境友好、组成稳定的高能量存储介电材料。

Method: 通过相场模拟指导，合成了La/Si共掺杂的BaTiO3固溶薄膜，并利用面内极域和极性纳米区结合的机制。

Result: 在6.15MV/cm电场下，实现了203.7J/cm3的高能量密度和约80%的能量效率。

Conclusion: 所提出的机制为设计下一代高性能储能介电材料和其他先进功能材料提供了前景。

Abstract: Relaxor ferroelectric thin films are recognized for their ultrahigh power
density, rendering them highly promising for energy storage applications in
electrical and electronic systems. However, achieving high energy storage
performance with chemically homogeneous, environmentally friendly and
compositionally stable materials remains challenging. In this work, we present
a design of dielectrics with high energy storage performance via an in-plane
polar domains incorporating polar nanoregions mechanism. Guided by phase-field
simulations, we synthesized La/Si co-doping BaTiO3 solid-solution thin films
with high chemical homogeneity to realize high energy storage performance.
Given that, we achieve a high energy density of 203.7J/cm3 and an energy
efficiency of approximately 80% at an electric field of 6.15MV/cm. This
mechanism holds significant promise for the design of next-generation
high-performance dielectric materials for energy storage and other advanced
functional materials.

</details>


### [437] [Optimizing Cross-Domain Transfer for Universal Machine Learning Interatomic Potentials](https://arxiv.org/abs/2510.11241)
*Jaesun Kim,Jinmu You,Yutack Park,Yunsung Lim,Yujin Kang,Jisu Kim,Haekwan Jeon,Deokgi Hong,Seung Yul Lee,Saerom Choi,Yongdeok Kim,Jae W. Lee,Seungwu Han*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种名为SevenNet-Omni的多领域机器学习势能模型，通过选择性正则化和领域桥接数据集，实现了跨化学和功能领域的准确性和可转移性，达到了最先进的交叉领域精度。


<details>
  <summary>Details</summary>
Motivation: 现有的通用机器学习势能模型（MLIPs）在处理不同化学和功能领域时，由于数据集或计算协议的限制，泛化能力和可靠性不足。

Method: 提出了一种多领域训练策略，通过选择性正则化联合优化通用和特定任务的参数，并引入领域桥接数据集（DBS）来对齐不同数据集的势能面。在十五个涵盖分子、晶体和表面的公开数据库上进行训练。

Result: SevenNet-Omni模型在跨领域测试中表现出色，在金属表面上的吸附能误差低于0.06 eV，在金属有机框架上的误差低于0.1 eV。即使仅包含0.5%的r$^2$SCAN数据，也能有效重现r$^2$SCAN的能量学计算结果，表明模型能从大规模PBE数据集中进行有效的跨功能迁移。

Conclusion: 该框架为构建可扩展的、通用的、可转移的MLIPs提供了一条途径，能够有效连接量子力学精度和化学领域。

Abstract: Accurate yet transferable machine-learning interatomic potentials (MLIPs) are
essential for accelerating materials and chemical discovery. However, most
universal MLIPs overfit to narrow datasets or computational protocols, limiting
their reliability across chemical and functional domains. We introduce a
transferable multi-domain training strategy that jointly optimizes universal
and task-specific parameters through selective regularization, coupled with a
domain-bridging set (DBS) that aligns potential-energy surfaces across
datasets. Systematic ablation experiments show that small DBS fractions (0.1%)
and targeted regularization synergistically enhance out-of-distribution
generalization while preserving in-domain fidelity. Trained on fifteen open
databases spanning molecules, crystals, and surfaces, our model, SevenNet-Omni,
achieves state-of-the-art cross-domain accuracy, including adsorption-energy
errors below 0.06 eV on metallic surfaces and 0.1 eV on metal-organic
frameworks. Despite containing only 0.5% r$^2$SCAN data, SevenNet-Omni
reproduces high-fidelity r$^2$SCAN energetics, demonstrating effective
cross-functional transfer from large PBE datasets. This framework offers a
scalable route toward universal, transferable MLIPs that bridge
quantum-mechanical fidelities and chemical domains.

</details>


### [438] [Electron-phonon coupling in magnetic materials using the local spin density approximation](https://arxiv.org/abs/2510.11350)
*Á. A. Carrasco Álvarez,M. Giantomassi,J. Lihm,G. E. Allemand,M. Mignolet,M. Verstraete,S. Poncé*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究扩展了EPW包，通过结合微扰理论和最大化局域Wannier函数来插值电子-声子矩阵元，从而能够以合理的计算成本在稠密的动量网上计算电子-声子相关性质。研究了铁和镍的磁性，发现它们的超导性被内在抑制，并评估了有限温度下的载流子电阻率，指出电子-声子散射在铁的电阻率中占主导地位，而在镍中占比不到三分之一。


<details>
  <summary>Details</summary>
Motivation: 电子-声子耦合在许多磁性材料的应用中很重要，但计算成本高。

Method: 扩展EPW包，结合微扰理论和最大化局域Wannier函数来插值电子-声子矩阵元。

Result: 成功计算了铁和镍的电子-声子性质。发现在铁和镍中，超导性被抑制。对于铁，电子-声子散射是电阻率的主要贡献者；对于镍，电子-声子散射贡献小于三分之一的电阻率。

Conclusion: 所提出的方法能够以合理的计算成本获得稠密的动量网格，用于计算电子-声子相关的性质。铁和镍的传输性质存在显著差异，这与磁性有关。

Abstract: Magnetic materials are crucial for manipulating electron spin and magnetic
fields, enabling applications in data storage, spintronics, charge transport,
and energy conversion, while also providing insight into fundamental quantum
phenomena. In numerous applications, the interaction between electrons and
lattice vibrations, known as electron-phonon coupling, can be of significant
importance. In that regard, we extend the EPW package to be able to interpolate
the electron-phonon matrix elements combining perturbation theory and maximally
localized Wannier functions. This allows to use dense momentum grids at a
reasonable computational cost when computing electron-phonon-related quantities
and physical properties. We validate our implementation considering
ferromagnetic iron and nickel, where we explore the absence of phonon-driven
superconductivity, finding that superconductivity is intrinsically suppressed.
Furthermore, we evaluate the carrier resistivity at finite temperatures for
both systems, considering the role of the magnetic phase in carrier transport.
Our findings indicate that in the case of Fe, the primary contributor to
resistivity is electron-phonon scattering. In contrast, for Ni, electron-phonon
scattering constitutes less than one-third of the resistivity, underscoring a
fundamental difference in the transport properties of the two systems.

</details>


### [439] [Host-atom-driven transformation of a honeycomb oxide into a dodecagonal quasicrystal](https://arxiv.org/abs/2510.11426)
*Martin Haller,Julia Hewelt,V. Y. M. Rajesh Chirala,Loi Vinh Tran,Ankur Bhide,Muriel Wegner,Stefan Förster,Wolf Widdra*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在金属氧化物蜂窝网络上吸附钡、锶或铕，可以诱导其重组为十二边形图案，从而实现十二边形氧化物准晶（OQCs）的形成。


<details>
  <summary>Details</summary>
Motivation: 建立一种通用的 OQC 形成机制，并探索新的 OQC 相。

Method: 在金属氧化物蜂窝网络上吸附不同的主原子（Ba, Sr, Eu），并利用低能电子衍射和扫描隧道显微镜等技术进行表征，同时通过开尔文探针和紫外光电子能谱研究功函数的变化。

Result: 成功制备了结构精确的 OQCs，包括一种新的铕-钛-氧化物相，并观察到主原子覆盖度与功函数之间存在线性关系，准晶形成后功函数急剧增加。

Conclusion: 提出了一种通用的 OQC 制备方法，该方法不仅适用于探索新的准晶材料（如铕基金属准晶），还可能应用于石墨烯、六方冰和二氧化硅等其他二维蜂窝材料，为工程非周期系统提供了新的途径。

Abstract: Dodecagonal oxide quasicrystals (OQCs) have so far been limited to a few
elemental systems, with no general formation mechanism established. Here, we
demonstrate a versatile approach to OQC formation via a host-atom-induced
transformation of a metal-oxide honeycomb (HC) network. Adsorption of Ba, Sr,
or Eu onto the HC layer triggers its reorganization into a dodecagonal tiling,
as revealed by low-energy electron diffraction and scanning tunneling
microscopy. Full conversion occurs when 73% of the honeycomb rings are
occupied. Kelvin probe and UV photoelectron spectroscopy show a linear decrease
in work function with increasing host coverage, followed by a sharp increase
upon quasicrystal formation due to reduced host dipoles. This transformation
mechanism enables the fabrication of structurally precise OQCs, including a new
Eu-Ti-O phase that extends the field to lanthanide quasicrystals, forming a 2D
grid of localized magnetic moments. The method offers a general route to
explore lattice-matched substrates for epitaxial growth and may be adapted to
other 2D honeycomb materials - such as graphene, hexagonal ice, and silica -
paving the way for engineered aperiodic systems beyond transition metal oxides.

</details>


### [440] [Enhancing the Plasmonic Hotspot Density via Structural Engineering of Multi-layered MoO3-Ag-Au Systems Under Extreme Electronic Excitation Conditions for Ultra-Sensitive SERS Applications](https://arxiv.org/abs/2510.11470)
*Om Prakash,Sharmistha Dey,Mayur Khan,Abhijith T,Udai Bhan Singh,Ambuj Tripathi,Santanu Ghosh*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用离子束处理MoO3-Ag-Au多层等离激元衬底，通过诱导金属薄膜的去湿和MoO3晶格缺陷的产生，显著提高了SERS性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高表面增强拉曼散射（SERS）的性能，研究人员探索了对MoO3-Ag-Au多层等离激元衬底进行离子束工程处理的方法。

Method: 通过化学气相沉积（CVD）在Si-SiO2衬底上制备MoO3微片，然后通过热蒸发沉积Ag（5 nm）和Au（5 nm）薄膜。随后，使用100 MeV Ag8+重离子辐照样品，剂量分别为3e11和3e12 ions cm-2。通过X射线衍射（XRD）、场发射扫描电子显微镜（FESEM）、拉曼光谱和X射线光电子能谱（XPS）对辐照后的样品进行表征，并进行SERS测量。

Result: 离子束辐照导致Ag-Au薄膜去湿，形成分散的Ag-Au纳米颗粒，增加了表面粗糙度，并在MoO3晶格中产生了缺陷（氧空位和Mo的部分还原）。SERS测量结果显示，辐照后的衬底对分子探针的拉曼信号强度显著增强。

Conclusion: 离子束工程处理是一种有效的策略，可以改善MoO3-Ag-Au多层等离激元衬底的SERS性能，这归因于纳米颗粒的形成、表面形貌的改变以及MoO3中氧空位的生成。

Abstract: We illustrate ion-beam engineering of MoO3 Ag Au multilayer plasmonic
substrates to improve SERS performance, We illustrate ion-beam engineering of
MoO3-Ag-Au multilayer plasmonic substrates to improve SERS performance.
Orthorhombic {\alpha}-MoO3 microflakes were produced via chemical vapour
deposition (CVD) on Si-SiO2 substrates. Thin films of Ag (5 nm) and Au (5 nm)
were thermally evaporated onto the MoO3 flakes, and the samples were subjected
to 100 MeV Ag8+ swift heavy ion irradiation at fluences of 3e11 and 3e12 ions
cm-2. Irradiation causes dewetting of metal films, prompting structural and
morphological changes that result in the formation of dispersed Ag-Au
nanoparticles, enhanced surface roughness, and defect generation within the
MoO3 lattice. X-ray diffraction (XRD) verifies the {\alpha}-MoO3 phase; field
emission scanning electron microscopy (FESEM) elucidates nanoparticle formation
and surface reorganisation; Raman spectroscopy and X-ray photoelectron
spectroscopy (XPS) disclose vibrational alterations and binding-energy shifts
in Mo 3d, indicative of oxygen vacancies (V_O) and partial reduction of Mo.
SERS measurements of molecular probes demonstrate significantly increased Raman
intensities following ion irradiation.

</details>


### [441] [Effects of strain on the stability of the metallic rutile and insulating M1 phases of vanadium dioxide](https://arxiv.org/abs/2510.11480)
*Peter Mlkvik,Lena Geistlich,Nicola A. Spaldin,Claude Ederer*

Main category: cond-mat.mtrl-sci

TL;DR: 应变对VO2的相稳定性起主导作用，尤其是在c轴方向上。


<details>
  <summary>Details</summary>
Motivation: 研究应变对VO2的结构和电子性质的影响，特别是应对变在金属金红石相和绝缘体一斜M1相之间的相对稳定性。

Method: 使用密度泛函理论进行系统研究。

Result: 计算证实了c轴应变的主导作用，并且在变形基面的应变情景中，c轴应变仍然对相稳定性起主导作用。应变主要通过削弱晶格刚度来影响相稳定性。

Conclusion: c轴应变是影响VO2相稳定性的关键因素。

Abstract: We present a systematic density-functional theory study of the effects of
strain on the structural and electronic properties in vanadium dioxide
(VO$_2$), with particular emphasis on its effect on the relative stability of
the metallic rutile and the insulating monoclinic M1 phases. We consider
various strain conditions that can be related to epitaxial strain present in
VO$_2$ films grown on different lattice planes. Our calculations confirm the
dominant role of $c$ axis strain, i.e., along the direction of the V-V
dimerization in the M1 phase. Our analysis suggests that this effect stems
primarily from the weakening of the lattice stiffness, with the hopping along
the $c$ axis playing a minor role. We also confirm that, in strain scenarios
that deform the basal plane, the $c$ axis strain still has a dominant effect on
the phase stability.

</details>


### [442] [Ab-initio calculation of magnetic exchange interactions using the spin-spiral method in VASP: Self-consistent versus magnetic force theorem approaches](https://arxiv.org/abs/2510.11603)
*Umit Dogan Daglum,Maria Stamenova,Ersoy Sasioglu,Stefano Sanvito*

Main category: cond-mat.mtrl-sci

TL;DR: 我们提出了一种使用 VASP 代码中的自旋螺旋方法进行磁交换相互作用的从头算研究，并对自洽（SC）和磁力定理（MFT）方法进行了比较分析。


<details>
  <summary>Details</summary>
Motivation: 为了从头算地研究磁交换相互作用，并比较自洽（SC）和磁力定理（MFT）方法的准确性。

Method: 使用 VASP 代码中的自旋螺旋方法，结合傅里叶变换，计算磁振色散关系和海森堡交换参数。然后，在平均场和随机相位近似下估计居里温度。

Result: SC 自旋螺旋计算在不同磁性系统（3d 铁磁体和 Mn 基全 Heusler 化合物）中与先前理论数据高度一致。MFT 方法则表现出系统性的定量偏差，尤其在高磁矩系统中，其偏差幅度随磁矩增大而显著增大。

Conclusion: 自洽性在精确确定磁交换参数方面起着决定性作用，为未来使用自旋螺旋技术进行自旋相互作用和激发的第一性原理研究提供了实际指导。

Abstract: We present an ab initio investigation of magnetic exchange interactions using
the spin-spiral method implemented in the VASP code, with a comparative
analysis of the self-consistent (SC) and magnetic force theorem (MFT)
approaches. Using representative 3d ferromagnets (Fe, Co, Ni) and Mn-based full
Heusler compounds, we compute magnon dispersion relations directly from
spin-spiral total energies and extract real-space Heisenberg exchange
parameters via Fourier transformation. Curie temperatures are subsequently
estimated within both the mean-field and random-phase approximations. The SC
spin-spiral calculations yield exchange parameters and magnon spectra in
excellent agreement with previous theoretical data, confirming their
quantitative reliability across different classes of magnetic systems. In
contrast, the MFT approach exhibits systematic quantitative deviations: it
overestimates spin-spiral energies and exchange couplings in high-moment
systems such as bcc Fe and the Mn-based Heuslers, while underestimating them in
low-moment fcc Ni. The magnitude of these discrepancies increases strongly with
magnetic moment size, exceeding several hundred percent in the high-moment
compounds. These findings underscore the decisive role of self-consistency in
accurately determining magnetic exchange parameters and provide practical
guidance for future first-principles studies of spin interactions and
excitations using the spin-spiral technique.

</details>


### [443] [Deterministic hBN bubbles as a versatile platform for studies on single-photon emitters](https://arxiv.org/abs/2510.11610)
*Piotr Tatarczak,Tomasz Fąs,Jan Pawłowski,Aleksandra Krystyna Dąbrowska,Jan Suffczyński,Piotr Wróbel,Andrzej Wysmołek,Johannes Binder*

Main category: cond-mat.mtrl-sci

TL;DR: MOVPE生长的hBN材料为单光子发射器提供了一个可扩展、可重现的平台，通过电子束诱导形成的气泡可以增强发光、实现发射器的重新定位并研究应变效应。


<details>
  <summary>Details</summary>
Motivation: 现有的hBN基单光子发射器研究主要基于难以复制且需要激活的剥离或粉末样品，阻碍了研究的进展和结果的比较。

Method: 使用MOVPE生长大面积hBN，通过电子束辐照产生气泡，实现发射增强、发射器重新定位、应变效应研究，并开发了基于掩模的方法进行确定性控制。

Result: 实现了约100-200%的发光增强，开发了可重新定位单个发射器的结构，并研究了应变诱导效应。所提出的气泡在低温下保持稳定，并实现了确定性的气泡形成。

Conclusion: 所提出的基于hBN气泡的平台具有多功能性，可用于hBN基发射器的可重现研究，为其性质和特性提供可靠的见解。

Abstract: Single-photon emitters (SPEs) in two-dimensional materials are highly
promising candidates for quantum technologies. SPEs in hexagonal boron nitride
(hBN) have been widely investigated, but mostly in exfoliated or powder samples
that require an activation process, making it difficult to compare studies and
reproduce results. Here, we address this problem and propose a platform based
on large-area metaloraganic vapour phase epitaxy (MOVPE)-grown hBN, which
combines reproducibility and scalability with the ability to readily host SPEs
without activation. Through the creation of bubbles via electron-beam
irradiation, we achieve additional functionalities, including an
interference-mediated enhancement of emission by approximately 100-200\%,
dedicated structures that allow the relocation of individual emitters across
different systems, and the opportunity to investigate strain-induced effects.
Moreover, in contrast to other gas-filled bubbles that deflate at low
temperatures, our bubbles remain stable under cryogenic conditions, allowing
studies as a function of temperature. To improve the control over the shape and
position of bubbles, we demonstrate a~mask-based method that enables
deterministic control over bubble formation. The presented hBN bubbles
constitute a versatile platform for reproducible studies of hBN-based emitters,
providing a reliable insight into their nature and properties.

</details>


### [444] [Strain-induced multiferroicity in Cr1/3NbS2](https://arxiv.org/abs/2510.11619)
*Y. Sun,Y. Ahn,D. Sapkota,H. S. Arachchige,R. Xue,S. Mozaffari,D. G. Mandrus,L. Zhao,J. Orenstein,V. Sunko*

Main category: cond-mat.mtrl-sci

TL;DR: 通过应变诱导在Cr1/3NbS2中产生多铁性


<details>
  <summary>Details</summary>
Motivation: 多铁性材料中电极化和磁有序共存且耦合，为基础发现和技术提供了丰富的机会。然而，由于铁电和磁性的电子要求相互冲突，多铁性仍然很罕见。

Method: 利用非共线自旋环形物的自旋排列，其对称性允许出现极性有序。本工作提出了一种新的多铁性有序途径，即利用应变在存在非极性自旋螺旋的材料中产生极化。选择研究广泛的螺旋磁体Cr1/3NbS2中的自旋螺旋作为例子，并引入磁电双折射（MEB）技术来检测诱导的极化。

Result: 通过结合MEB成像和应变工程，在磁转变时确认了极性矢量的出现，证明了应变Cr1/3NbS2是一种II型多铁性材料。

Conclusion: 应变工程是产生多铁性的一种新途径，并且MEB是一种检测极性有序的有效方法。

Abstract: Multiferroic materials, in which electric polarization and magnetic order
coexist and couple, offer rich opportunities for both fundamental discovery and
technology. However, multiferroicity remains rare due to conflicting electronic
requirements for ferroelectricity and magnetism. One route to circumvent this
challenge is to exploit the noncollinear ordering of spin cycloids, whose
symmetry permits the emergence of polar order. In this work, we introduce
another pathway to multiferroic order in which strain generates polarization in
materials that host nonpolar spin spirals. To demonstrate this phenomenon, we
chose the spin spiral in the well-studied helimagnet Cr1/3NbS2. To detect the
induced polarization, we introduce the technique of magnetoelectric
birefringence (MEB), an optical probe that enables spatially-resolved and
unambiguous detection of polar order. By combining MEB imaging with strain
engineering, we confirm the onset of a polar vector at the magnetic transition,
establishing strained Cr1/3NbS2 as a type-II multiferroic.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [445] [On the Relationship between Space-Time Accessibility and Leisure Activity Participation](https://arxiv.org/abs/2510.10307)
*Yuan Liao,Rafael H. M. Pereira,Jorge Gil,Silvia De Sojo Caso,Laura Alessandretti*

Main category: cs.SI

TL;DR: 该研究提出了一种时空可达性（SPA）指标，用于衡量个人在通勤路线上可行休闲机会，并评估其对出行时间和休闲参与的影响，以期促进城市包容性。


<details>
  <summary>Details</summary>
Motivation: 传统可达性衡量方法未能充分考虑个体日常活动和时间限制，因此需要一种能捕捉动态、以人为本的可达性指标，以促进城市包容性。

Method: 研究利用巴黎地区2415名居民的高分辨率GPS数据，引入基于能力方法论的时空可达性（SPA）指标，评估其对总出行时间和休闲参与（以休闲活动地点多样性衡量）的影响。并通过结构方程模型进行分析。

Result: 研究结果表明，大多数人（特别是活跃的交通方式使用者）选择的目的地与其SPA定义的机会集一致。SPA直接促进了休闲多样性，但也减少了出行时间，而较短的出行时间反而与较低的休闲多样性相关。

Conclusion: 研究强调了以人为本、以能力为导向的可达性指标对于理解城市出行不平等和制定交通规划策略的重要性，这些策略旨在扩大不同人群参与社会生活的真实自由度。

Abstract: Understanding how accessibility shapes participation in leisure activities is
central to promoting inclusive and vibrant urban life. Conventional
accessibility measures often focus on potential access from fixed home
locations, overlooking the constraints and opportunities embedded in daily
routines. In this study, we introduce a space-time accessibility (SPA) metric
rooted in the capability approach, capturing feasible leisure opportunities
between home and work given a certain time budget, individual transport modes,
and urban infrastructure. Using high-resolution GPS data from 2,415 residents
in the Paris region, we assess how SPA influences total travel time and leisure
participation, measured as the diversity of leisure activity locations. Spatial
patterns show that most individuals-especially active transport users-choose
destinations aligned with their SPA-defined opportunity sets, underscoring the
metric's validity in capturing capability sets. Structural equation modeling
reveals that SPA directly fosters leisure diversity but also reduces travel
time, which in turn is associated with lower diversity. These findings
highlight the value of person-centered, capability-informed accessibility
metrics for understanding inequalities in urban mobility and informing
transport planning strategies that expand real freedoms to participate in
social life across diverse population groups.

</details>


### [446] [Preserving Core Structures of Social Networks via Information Guided Multi-Step Graph Pruning](https://arxiv.org/abs/2510.10499)
*Yutong Hu,Bingxin Zhou,Jing Wang,Weishu Zhao,Liang Hong*

Main category: cs.SI

TL;DR: 该研究提出了一种名为IGPrune的多步网络修剪框架，用于简化具有密集和重叠连接的社交网络，以揭示其结构骨干。


<details>
  <summary>Details</summary>
Motivation: 识别社交网络的结构骨干对于理解社区组织、信息流和功能关系至关重要，而密集的连接阻碍了这种分析。

Method: 提出了一种多步网络修剪框架，该框架利用信息论原理，基于其对任务相关互信息的贡献，迭代地评估和移除图中的边。该方法受梯度提升的启发，提出IGPrune，以实现高效、可微分的优化。

Result: 在社交网络和生物网络上的广泛实验表明，IGPrune能够保留关键的结构和功能模式。

Conclusion: IGPrune 能够保留关键的结构和功能模式，并且生成的修剪网络揭示了可解释的骨干，有望促进科学发现和在实际网络中获得可操作的见解。

Abstract: Social networks often contain dense and overlapping connections that obscure
their essential interaction patterns, making analysis and interpretation
challenging. Identifying the structural backbone of such networks is crucial
for understanding community organization, information flow, and functional
relationships. This study introduces a multi-step network pruning framework
that leverages principles from information theory to balance structural
complexity and task-relevant information. The framework iteratively evaluates
and removes edges from the graph based on their contribution to task-relevant
mutual information, producing a trajectory of network simplification that
preserves most of the inherent semantics. Motivated by gradient boosting, we
propose IGPrune, which enables efficient, differentiable optimization to
progressively uncover semantically meaningful connections. Extensive
experiments on social and biological networks show that IGPrune retains
critical structural and functional patterns. Beyond quantitative performance,
the pruned networks reveal interpretable backbones, highlighting the method's
potential to support scientific discovery and actionable insights in real-world
networks.

</details>


### [447] [SocioBench: Modeling Human Behavior in Sociological Surveys with Large Language Models](https://arxiv.org/abs/2510.11131)
*Jia Wang,Ziyu Zhao,Tingjuntao Ni,Zhongyu Wei*

Main category: cs.SI

TL;DR: LLMs在模拟人类社会行为方面潜力巨大，但缺乏大规模、系统化的基准来评估其与现实社会态度的对齐程度。SocioBench是一个基于ISSP调查数据的基准，包含超过48万条记录，涵盖10个社会学领域和40个人口统计学属性。实验表明，LLMs在复杂调查场景中的模拟准确率仅为30-40%，在不同领域和群体间存在显著差异，这暴露了LLMs在数据覆盖、场景多样性和群体建模方面的局限性。


<details>
  <summary>Details</summary>
Motivation: LLMs在模拟人类社会行为方面潜力巨大，但缺乏大规模、系统化的基准来评估其与现实社会态度的对齐程度。

Method: 构建了一个名为SocioBench的基准，该基准来源于国际社会调查项目（ISSP）的年度标准化调查数据，整合了来自30多个国家、超过48万条真实受访者记录，涵盖10个社会学领域和40个人口统计学属性。

Result: LLMs在模拟复杂调查场景中的准确率仅为30-40%，并且在不同领域和人口统计学子群体之间存在统计学上的显著差异。

Conclusion: 当前的LLMs在调查场景中存在一些局限性，包括个体层面数据覆盖不足、场景多样性不足以及群体层面的建模缺失。

Abstract: Large language models (LLMs) show strong potential for simulating human
social behaviors and interactions, yet lack large-scale, systematically
constructed benchmarks for evaluating their alignment with real-world social
attitudes. To bridge this gap, we introduce SocioBench-a comprehensive
benchmark derived from the annually collected, standardized survey data of the
International Social Survey Programme (ISSP). The benchmark aggregates over
480,000 real respondent records from more than 30 countries, spanning 10
sociological domains and over 40 demographic attributes. Our experiments
indicate that LLMs achieve only 30-40% accuracy when simulating individuals in
complex survey scenarios, with statistically significant differences across
domains and demographic subgroups. These findings highlight several limitations
of current LLMs in survey scenarios, including insufficient individual-level
data coverage, inadequate scenario diversity, and missing group-level modeling.

</details>


### [448] [Beyond the Crowd: LLM-Augmented Community Notes for Governing Health Misinformation](https://arxiv.org/abs/2510.11423)
*Jiaying Wu,Zihang Fu,Haonan Wang,Fanxiao Li,Min-Yen Kan*

Main category: cs.SI

TL;DR: 社区笔记（X平台的一个众包错误信息治理系统）存在显著的延迟问题，我们提出了CrowdNotes+框架，利用大语言模型（LLMs）来增强社区笔记的功能，以提高健康相关错误信息的治理速度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 社区笔记系统在处理健康相关错误信息时存在显著的延迟，影响了其在真实世界错误信息激增时期的响应能力。

Method: 提出CrowdNotes+框架，该框架结合了基于证据的笔记增强和基于效用的笔记自动化，并通过三步评估（相关性、正确性、有用性）来提高治理效率。通过HealthNotes基准测试和对十五个大语言模型的实验来验证。

Result: 实验发现，当前的有用性评估存在漏洞，会将风格流畅度误判为事实准确性。CrowdNotes+框架通过分层评估和LLM增强生成，能够同时提高事实准确性和证据效用。

Conclusion: 研究结果表明，结合人类和AI的混合治理模式可以提高众包事实核查的严谨性和及时性。

Abstract: Community Notes, the crowd-sourced misinformation governance system on X
(formerly Twitter), enables users to flag misleading posts, attach contextual
notes, and vote on their helpfulness. However, our analysis of 30.8K
health-related notes reveals significant latency, with a median delay of 17.6
hours before the first note receives a helpfulness status. To improve
responsiveness during real-world misinformation surges, we propose CrowdNotes+,
a unified framework that leverages large language models (LLMs) to augment
Community Notes for faster and more reliable health misinformation governance.
CrowdNotes+ integrates two complementary modes: (1) evidence-grounded note
augmentation and (2) utility-guided note automation, along with a hierarchical
three-step evaluation that progressively assesses relevance, correctness, and
helpfulness. We instantiate the framework through HealthNotes, a benchmark of
1.2K helpfulness-annotated health notes paired with a fine-tuned helpfulness
judge. Experiments on fifteen LLMs reveal an overlooked loophole in current
helpfulness evaluation, where stylistic fluency is mistaken for factual
accuracy, and demonstrate that our hierarchical evaluation and LLM-augmented
generation jointly enhance factual precision and evidence utility. These
results point toward a hybrid human-AI governance model that improves both the
rigor and timeliness of crowd-sourced fact-checking.

</details>


### [449] [Networks Multiscale Entropy Analysis](https://arxiv.org/abs/2510.11524)
*Sebastián Brzovic,Cristóbal Rojas,Andrés Abeliuk*

Main category: cs.SI

TL;DR: 本研究提出了一个多尺度熵框架，通过谱图缩减来量化网络结构熵随网络粗化的演变，以解决现有单尺度方法忽略网络层次模式的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分析网络结构复杂性和可预测性时，往往只关注单尺度表示，忽略了真实世界网络中丰富的层次模式。

Method: 采用多尺度熵框架，结合谱图缩减技术，量化网络结构熵在不同尺度下的演变。

Result: 在生物、经济、社会、技术和交通等领域的真实网络上应用该框架，发现了不同网络家族一致的熵特征，并识别出三种与领域行为相关的结构模式（稳定、递增和混合）。与单尺度模型相比，多尺度熵显著提高了网络可预测性的判断能力。

Conclusion: 多尺度熵提供了一种更全面的网络复杂性表征方法，是一种强大且可扩展的工具，可用于复杂网络的结构表征、分类和评估。

Abstract: Understanding the structural complexity and predictability of complex
networks is a central challenge in network science. Although recent studies
have revealed a relationship between compression-based entropy and link
prediction performance, existing methods focus on single-scale representations.
This approach often overlooks the rich hierarchical patterns that can exist in
real-world networks. In this study, we introduce a multiscale entropy framework
that extends previous entropy-based approaches by applying spectral graph
reduction. This allows us to quantify how structural entropy evolves as the
network is gradually coarsened, capturing complexity across multiple scales. We
apply our framework to real-world networks across biological, economic, social,
technological, and transportation domains. The results uncover consistent
entropy profiles across network families, revealing three structural
regimes$\unicode{x2013}$stable, increasing, and hybrid$\unicode{x2013}$that
align with domain-specific behaviors. Compared to single-scale models,
multiscale entropy significantly improves our ability to determine network
predictability. This shows that considering structural information across
scales provides a more complete characterization of network complexity.
Together, these results position multiscale entropy as a powerful and scalable
tool for characterizing, classifying, and assessing the structure of complex
networks.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [450] [Bluetooth Fingerprint Identification Under Domain Shift Through Transient Phase Derivative](https://arxiv.org/abs/2510.09940)
*Haytham Albousayri,Bechir Hamdaoui,Weng-Keen Wong,Nora Basha*

Main category: eess.SP

TL;DR: 该研究首次研究了BLE设备的跳频效应对RFFP的影响，并提出了一种低成本、域自适应的特征提取方法，显著提高了分类准确性。


<details>
  <summary>Details</summary>
Motivation: 为了应对深度学习射频指纹识别（RFFP）在不同域（时间、地点、环境、接收器、信道）变化下的挑战，特别是在BLE设备中，由于其跳频特性，这一挑战尤为关键。

Method: 提出了一种新颖的、低成本的、域自适应的特征提取方法，以解决BLE设备RFFP中的跳频效应问题。

Result: 该方法在跨环境和跨接收器的分类准确性方面，相比现有基准提高了58%和80%。

Conclusion: 所提出的方法能够有效解决BLE设备RFFP中的跳频效应问题，并显著提高其在不同域下的识别准确性。

Abstract: Deep learning-based radio frequency fingerprinting (RFFP) has become an
enabling physical-layer security technology, allowing device identification and
authentication through received RF signals. This technology, however, faces
significant challenges when it comes to adapting to domain variations, such as
time, location, environment, receiver and channel. For Bluetooth Low Energy
(BLE) devices, addressing these challenges is particularly crucial due to the
BLE protocol's frequency-hopping nature. In this work, and for the first time,
we investigated the frequency hopping effect on RFFP of BLE devices, and
proposed a novel, low-cost, domain-adaptive feature extraction method. Our
approach improves the classification accuracy by up to 58\% across environments
and up to 80\% across receivers compared to existing benchmarks.

</details>


### [451] [Movable Antenna Enhanced Covert Dual-Functional Radar-Communication: Joint Beamforming and Antenna Position Optimization](https://arxiv.org/abs/2510.09949)
*Ran Yang,Zheng Dong,Peng Cheng,Lin Zhang,Wanting Lyu,Yue Xiu,Ning Wei,Chadi Assi*

Main category: eess.SP

TL;DR: 通过优化波束成形、接收滤波器和天线位置，在满足雷达信噪比和通信隐蔽性约束的条件下，最大化双功能雷达通信（DFRC）系统的和速率。


<details>
  <summary>Details</summary>
Motivation: 利用可移动天线（MA）灵活配置无线信道的潜力，研究增强型DFRC系统的通信安全问题，旨在最大化和速率。

Method: 采用拉格朗日对偶变换将原问题转化为可处理形式，并结合半定松弛（SDR）、投影梯度下降（PGD）和逐次凸逼近（SCA）技术，利用块坐标下降（BCD）算法求解。

Result: 仿真结果表明，所提出的方法能够显著提高隐蔽和速率，并在利用可移动天线的灵活性方面，与现有基准方案相比，在通信和雷达性能之间取得了满意的平衡。

Conclusion: 所提出的基于可移动天线的DFRC系统优化方法，能够有效提升通信速率，并平衡雷达与通信性能。

Abstract: Movable antenna (MA) has emerged as a promising technology to flexibly
reconfigure wireless channels by adjusting antenna placement. In this paper, we
study a dual-functional radar-communication (DFRC) system enhanced with movable
antennas. To ensure communication security, we aim to maximize the achievable
sum rate by jointly optimizing the transmit beamforming vectors, receiving
filter, and antenna placement, subject to radar signal-to-noise ratio (SNR)
performance and transmission covertness constraints. To tackle this challenging
optimization problem, we first employ a Lagrangian dual transformation process
to reformulate it into a more tractable form. Subsequently, the problem is
solved by introducing a block coordinate descent (BCD) algorithm, incorporating
semidefinite relaxation (SDR), projected gradient descent (PGD), and successive
convex approximation (SCA) techniques. Simulation results demonstrate that the
proposed method can significantly improve the covert sum rate, and achieve a
satisfactory balance between the communication and radar performance compared
with existing benchmark schemes by leveraging the flexibility of movable
antennas.

</details>


### [452] [Active IRS Assisted Joint Uplink and Downlink Communications](https://arxiv.org/abs/2510.10045)
*Qiaoyan Peng,Qingqing Wu,Guangji Chen,Wen Chen,Shaodan Ma*

Main category: eess.SP

TL;DR: 本文研究了主动智能反射面（AIRS）辅助下的无线通信系统，旨在通过联合优化基站（BS）、AIRS波束成形和AIRS单元分配来最大化上下行（UL/DL）通信的加权和速率（WSR）。


<details>
  <summary>Details</summary>
Motivation: 最大化IRS辅助无线通信系统的加权和速率（WSR），并比较不同部署方案的优劣。

Method: 研究了分布式AIRS、BS侧AIRS和用户侧AIRS三种部署方案。对于分布式AIRS，推导了最优和近优解。通过分析比较了不同部署方案在单用户场景下的速率性能。在多用户场景下，考虑了两种波束成形设置：用户自适应AIRS波束成形和静态AIRS波束成形。对于用户自适应方案，优化单元分配以最大化速率。对于静态方案，通过优化BS收发波束成形、用户波束成形和AIRS波束成形来解决速率最大化问题，并提出了一种交替优化（AO）算法。

Result: 数值结果验证了分布式AIRS相较于无源IRS（PIRS）、BS侧AIRS和用户侧AIRS的实际优势，并强调了动态IRS波束成形的优势。

Conclusion: 分布式AIRS在IRS辅助无线通信系统中具有实际优势，动态IRS波束成形能够带来显著效益。

Abstract: In this paper, we investigate an intelligent reflecting surface (IRS) aided
wireless communication system, where active IRSs (AIRSs) are deployed to assist
communication between a base station (BS) and users of both the uplink (UL) and
downlink (DL). We aim to maximize the weighted sum rate (WSR) of UL and DL
communications through joint optimization of BS, AIRS beamforming, and AIRS
element allocation. First, we study three deployment schemes, namely
distributed AIRSs, BS-side AIRS, and user-side AIRS. For distributed AIRSs,
both optimal and near-optimal solutions are derived in closed form. To draw
useful insights, we analytically compare the deployment schemes in terms of the
rate performance under the single-user setup. For the multi-user case, we
consider two beamforming setups at the distributed AIRSs to balance performance
and complexity tradeoffs. Regarding the user-adaptive AIRS beamforming,
different AIRS beamforming vectors are adopted for each user; while for the
static AIRS beamforming, all users share the same beamforming vectors, with
identical phase shifts but different amplitudes for UL and DL. With the
user-adaptive AIRS beamforming, we focus on the optimization of element
allocation for rate maximization. With static AIRS beamforming, we solve the
rate maximization problem by optimizing the BS transmit/receive beamformers,
user beamforming, and AIRS beamforming. Despite its non-convexity, we develop
an efficient alternating optimization (AO) based algorithm that solves each
sub-problem optimally. Numerical results validate the practical advantages of
distributed AIRSs compared to passive IRS (PIRS), BS-side AIRS, and user-side
AIRS, and highlight the benefits of dynamic IRS beamforming.

</details>


### [453] [Synchrosqueezed windowed linear canonical transform: A method for mode retrieval from multicomponent signals with crossing instantaneous frequencies](https://arxiv.org/abs/2510.10438)
*Shuixin Li,Jiecheng Chen,Qingtang Jiang,Jian Lu*

Main category: eess.SP

TL;DR: 该论文提出了一种新颖的窗化线性李群变换（WLCT），用于生成三维时-频-चिरप्रेट表示，以解决时-频域中信号重叠的挑战。


<details>
  <summary>Details</summary>
Motivation: 在自然界中，信号常常表现为多个非平稳信号的叠加，在时-频域中的信号分量重叠对信号分析提出了重大挑战。

Method: 提出了一种新颖的窗化线性李群变换（WLCT），它提供了新的三维时-频-चिरप्रेट表示。讨论了四种类型的WLCT，并使用特殊的X射线变换来进一步锐化时-频-चिरप्रेट表示。推导了相应的三维同步压缩变换。

Result: 证明了WLCT在三维信号分离方面具有巨大潜力。

Conclusion: WLCT为三维信号分离提供了一种有前景的方法。

Abstract: In nature, signals often appear in the form of the superposition of multiple
non-stationary signals. The overlap of signal components in the time-frequency
domain poses a significant challenge for signal analysis. One approach to
addressing this problem is to introduce an additional chirprate parameter and
use the chirplet transform (CT) to elevate the two-dimensional time-frequency
representation to a three-dimensional time-frequency-chirprate representation.
From a certain point of view, the CT of a signal can be regarded as a windowed
special linear canonical transform of that signal, undergoing a shift and a
modulation.
  In this paper, we develop this idea to propose a novel windowed linear
canonical transform (WLCT), which provides a new time-frequency-chirprate
representation. We discuss four types of WLCTs. In addition, we use a special
X-ray transform to further sharpen the time-frequency-chirprate representation.
Furthermore, we derive the corresponding three-dimensional synchrosqueezed
transform, demonstrating that the WLCTs have great potential for
three-dimensional signal separation.

</details>


### [454] [MIMO Radar Meets Polarization-Reconfigurable Antennas: A BCRB Perspective](https://arxiv.org/abs/2510.10235)
*Jinpeng Xu,Shuowen Zhang*

Main category: eess.SP

TL;DR: 本论文提出了一种利用相移器可重构天线（PRA）的新型多输入多输出（MIMO）雷达系统，用于在只有目标位置先验信息的情况下估计未知目标角度。


<details>
  <summary>Details</summary>
Motivation: 研究一种新型MIMO雷达系统，该系统利用相移器可重构天线（PRA）来估计目标角度，并利用目标的先验位置信息。

Method: 推导了贝叶斯克拉美-罗下界（BCRB），然后通过提出一种交替优化（AO）算法来联合优化发射信号协方差矩阵以及发射和接收移相矢量，以最小化BCRB。

Result: 推导了BCRB，并通过AO算法实现了对目标角度的估计。

Conclusion: 提出的PRA辅助MIMO雷达系统和AO算法能够有效估计目标角度。

Abstract: In this paper, we investigate a novel multiple-input multiple-output (MIMO)
radar system aided by phase shifter based polarization-reconfigurable antennas
(PRAs). Specifically, a base station (BS) equipped with multiple PRAs at both
the transmitter and the receiver aims to sense the unknown and random angular
location parameter of a point target via sending wireless signals and
processing the received echo signals reflected by the target, where only prior
distribution information about the location parameter is available for
exploitation. Firstly, we characterize the sensing performance of this novel
PRA-based MIMO radar system by deriving the Bayesian Cram\'er-Rao bound (BCRB)
of the mean-squared error (MSE) in estimating the desired location parameter
with prior distribution information. Then, to fully exploit the new design
degrees-of-freedom (DoF) empowered by PRAs, we study the joint optimization of
the transmit sample covariance matrix as well as the transmit and receive phase
shift vectors to minimize the sensing BCRB subject to a transmit power
constraint. This problem is non-convex and difficult to solve due to the
coupling among optimization variables. To resolve this issue, we develop an
alternating optimization (AO) based algorithm which iteratively obtains the
closed-form optimal solution to each variable with the others being fixed at
each time, thus being guaranteed to converge to at least a stationary point of
the joint optimization problem. Numerical results validate the effectiveness of
the proposed algorithm.

</details>


### [455] [HYPERDOA: Robust and Efficient DoA Estimation using Hyperdimensional Computing](https://arxiv.org/abs/2510.10718)
*Rajat Bhattacharjya,Woohyeok Park,Arnab Sarkar,Hyunwoo Oh,Mohsen Imani,Nikil Dutt*

Main category: eess.SP

TL;DR: HYPERDOA是一种利用超维度计算（HDC）的新型DOA估计算法，在低信噪比（SNR）和相干源场景下，其精度比现有方法高约35.39%，同时能耗降低约93%，适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 现有的DOA估计算法在低信噪比条件下精度不足，而深度学习方法能耗高且不透明，不适用于资源受限、安全关键的系统。HYPERDOA旨在解决这一权衡问题。

Method: HYPERDOA利用超维度计算（HDC），并引入了平均空间-滞后自相关和空间平滑两种特征提取策略，将DOA估计重构为模式识别问题。该方法利用HDC的抗噪声能力和透明的代数运算，避免了传统方法中的矩阵分解和深度学习中的“黑箱”问题。

Result: 在低信噪比、相干源场景下，HYPERDOA的精度比最先进的方法高约35.39%。在嵌入式NVIDIA Jetson Xavier NX平台上，其能耗比基线神经模型低约93%。

Conclusion: HYPERDOA在精度和效率方面均表现优异，是嵌入式边缘设备上执行任务的关键应用的可靠解决方案。

Abstract: Direction of Arrival (DoA) estimation techniques face a critical trade-off,
as classical methods often lack accuracy in challenging, low signal-to-noise
ratio (SNR) conditions, while modern deep learning approaches are too
energy-intensive and opaque for resource-constrained, safety-critical systems.
We introduce HYPERDOA, a novel estimator leveraging Hyperdimensional Computing
(HDC). The framework introduces two distinct feature extraction strategies --
Mean Spatial-Lag Autocorrelation and Spatial Smoothing -- for its HDC pipeline,
and then reframes DoA estimation as a pattern recognition problem. This
approach leverages HDC's inherent robustness to noise and its transparent
algebraic operations to bypass the expensive matrix decompositions and
``black-box'' nature of classical and deep learning methods, respectively. Our
evaluation demonstrates that HYPERDOA achieves ~35.39% higher accuracy than
state-of-the-art methods in low-SNR, coherent-source scenarios. Crucially, it
also consumes ~93% less energy than competing neural baselines on an embedded
NVIDIA Jetson Xavier NX platform. This dual advantage in accuracy and
efficiency establishes HYPERDOA as a robust and viable solution for
mission-critical applications on edge devices.

</details>


### [456] [Multi-Carrier Rydberg Atomic Quantum Receivers with Enhanced Bandwidth Feature for Communication and Sensing](https://arxiv.org/abs/2510.10473)
*Huizhi Wang,Tierui Gong,Emil Björnson,Chau Yuen*

Main category: eess.SP

TL;DR: 该研究提出了一种多载波里德堡原子量子接收器（MC-RAQR），通过引入五能级结构，将带宽提高了56倍，显著提升了信道容量和多目标感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统里德堡原子量子接收器（RAQRs）在接收宽带射频信号方面存在带宽限制，无法满足多载波通信和传感的需求。

Method: 提出了一种五能级MC-RAQR结构，推导了其幅度和相位，并提取了基带电信号。分析了其在多载波通信和传感方面的信道容量、到达角（AoA）和距离参数的精度。

Result: MC-RAQR的带宽达到14 MHz，比传统RAQRs高56倍。信道容量比传统天线和RAQRs分别提高了22倍和3倍。AoA估计的均方误差（MSE）为传统RAQR的0.16%，距离估计的MSE为传统天线克拉美罗下界的0.01%。

Conclusion: MC-RAQR能够兼容OFDM等波形，在多载波信号接收方面具有显著优势，能够显著提高信道容量和多目标传感的分辨率。

Abstract: Rydberg atomic quantum receivers (RAQRs) have attracted significant attention
in recent years due to their ultra-high sensitivity. Although capable of
precisely detecting the amplitude and phase of weak signals, conventional RAQRs
face inherent limitations in accurately receiving wideband RF signals, due to
the discrete nature of atomic energy levels and their intrinsic instantaneous
bandwidth constraints. These limitations hinder their direct application to
multi-carrier communication and sensing. To address this issue, this paper
proposes a multi-carrier Rydberg atomic quantum receiver (MC-RAQR) structure
with five energy levels. We derive the amplitude and phase of the MC-RAQR and
extract the baseband electrical signal for signal processing. In terms of
multi-carrier communication and sensing, we analyze the channel capacity and
accuracy of angle of arrival (AoA) and distance parameters, respectively.
Numerical results validate our proposed model, showing that the MC-RAQR can
achieve up to a bandwidth of 14 MHz, which is 56-fold larger than the
conventional RAQRs. As a result, the channel capacity and the resolution for
multi-target sensing are improved significantly. Specifically, the channel
capacity of MC-RAQR is 22-fold and 3-fold larger than the conventional antennas
and RAQRs, respectively. For sensing performance, the MSE of AoA estimation for
MC-RAQR is 0.16% of the conventional RAQR and the MSE of distance estimation is
0.01% of the CRB of conventional antennas, showing the superior performance of
the MC-RAQR. This demonstrates its compatibility with waveforms such as
orthogonal frequency-division multiplexing (OFDM) and its significant
advantages for multi-carrier signal reception.

</details>


### [457] [Graph Signal Wiener Filtering in the Linear Canonical Domain: Theory and Method Design](https://arxiv.org/abs/2510.10512)
*Xiaopeng Cheng,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出一种可训练的联合优化框架，将图线性正则变换（GLCT）参数和维纳滤波结合到端到端学习过程中，实现了变换域构建和滤波操作之间的协同优化。


<details>
  <summary>Details</summary>
Motivation: 图线性正则变换（GLCT）的滤波方法通常分别优化变换参数和滤波器，导致计算成本高且稳定性有限。

Method: 提出一个结合GLCT参数和维纳滤波的端到端可训练的联合优化框架。

Result: 实验结果表明，所提出的方法在去噪任务中优于现有方法，具有更好的去噪性能、更高的鲁棒性和更低的计算复杂度。

Conclusion: 所提出的联合优化框架消除了传统策略的网格搜索，增强了滤波系统的灵活性和训练稳定性，并在真实图数据去噪任务中表现出优越性能。

Abstract: The graph linear canonical transform (GLCT)-based filtering methods often
optimize transform parameters and filters separately, which results in high
computational costs and limited stability. To address this issue, this paper
proposes a trainable joint optimization framework that combines GLCT parameters
and Wiener filtering into an end-to-end learning process, allowing for
synergistic optimization between transform domain construction and filtering
operations. The proposed method not only eliminates the cumbersome grid search
required by traditional strategies but also significantly enhances the
flexibility and training stability of the filtering system. Experimental
results on real-world graph data show the proposed method outperforms existing
methods in denoising tasks, featuring superior denoising performance, higher
robustness and lower computational complexity.

</details>


### [458] [SVD-based ugmt-gft on directed product graphs](https://arxiv.org/abs/2510.10532)
*Guoyun Xie,Zhichao Zhang*

Main category: eess.SP

TL;DR: 该研究提出了一种基于统一图表示矩阵 (UGRM) 和奇异值分解 (SVD) 的广义图傅里叶变换 (UGRM-GFT) 方法，用于处理定向图和笛卡尔积图上的信号，解决了传统方法表示矩阵结构固定、适应性差的问题。UGRM-GFT 通过参数化 UGRM 整合了拉普拉斯矩阵和邻接矩阵等传统表示，并利用 SVD 构建了包含左右奇异向量的谱变换对。该方法扩展到定向笛卡尔积图，提出了两种 UGRM-GFT：UGRM-GFT-I 直接对二维图结构的复合 UGRM 进行 SVD，适用于全局耦合信号；UGRM-GFT-II 分别对因子图的 UGRM 进行 SVD 后组合结果，降低了计算复杂度。理论分析证实了该方法相对于 UGRM 中参数 alpha 和 k 的单调性。实验结果表明，该方法在去噪任务上显著优于传统固定矩阵方法，特别是在信噪比和带宽效率方面。


<details>
  <summary>Details</summary>
Motivation: 传统有向图信号处理依赖于固定的表示矩阵，其僵化的结构限制了模型适应复杂图拓扑的能力。本研究旨在解决这一局限性。

Method: 提出了一种基于奇异值分解 (SVD) 的统一图表示矩阵 (UGRM) 的广义图傅里叶变换 (UGRM-GFT) 方法，用于处理定向图和笛卡尔积图上的信号。通过引入参数化的 UGRM 来定义 UGRM-GFT，该 UGRM 整合了拉普拉斯矩阵和邻接矩阵等传统表示。利用 SVD 构建了包含左右奇异向量的谱变换对。将此方法扩展到两种适用于定向笛卡尔积图的 UGRM-GFT：UGRM-GFT-I 直接对复合 UGRM 进行 SVD；UGRM-GFT-II 分别对因子图的 UGRM 进行 SVD 后组合结果。

Result: 理论分析证实了该方法相对于 UGRM 中参数 alpha 和 k 的单调性。在真实数据集上的实验结果表明，该方法在去噪任务上，特别是在信噪比和带宽效率方面，显著优于传统的固定矩阵方法。

Conclusion: 该研究提出的 UGRM-GFT 方法通过引入灵活的 UGRM 和利用 SVD，能够有效处理定向图和笛卡尔积图上的信号，并在去噪任务中取得了优于传统方法的性能。

Abstract: Traditional directed graph signal processing generally depends on fixed
representation matrices, whose rigid structures limit the model's ability to
adapt to complex graph topologies. To address this issue, this study employed
the unified graph representation matrix (UGRM) to propose a generalized graph
Fourier transform (UGRM-GFT) method based on singular value decomposition (SVD)
for signal analysis on directed graphs and Cartesian product graphs. We defined
UGRM-GFT for general directed graphs by introducing a parameterized UGRM that
incorporates traditional representations such as the Laplacian matrix and
adjacency matrix. The SVD is used to construct spectral transform pairs with
both left and right singular vectors. We extended this approach to two types of
UGRM-GFTs applied to directed Cartesian product graphs. UGRM-GFT-I performs SVD
directly on the composite UGRM matrix of the two-dimensional graph structure,
suitable for globally coupled graph signals. UGRM-GFT-II separately applies SVD
to the UGRMs of the two-factor graphs and then combines the results,
significantly reducing computational complexity while preserving spectral
expressiveness. Theoretical analysis confirmed the monotonicity of the proposed
method with respect to the parameters alpha and k embedded in the UGRM.
Experimental results on real-world datasets demonstrated that the proposed
method significantly outperforms traditional fixed-matrix approaches in
denoising tasks, with a particular emphasis on signal-to-noise ratio and
bandwidth efficiency.

</details>


### [459] [Data Integration Using Multivariate Mode Decomposition for Physiological Sensing with Multiple Millimeter-Wave Radar Systems](https://arxiv.org/abs/2510.10542)
*Kimitaka Sumi,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 该研究提出了一个多雷达系统，用于在任意身体姿态下进行非接触式生理传感。


<details>
  <summary>Details</summary>
Motivation: 为了在任意身体姿态下实现非接触式生理传感，需要一个能够整合来自不同雷达视角的信号的系统。

Method: 采用多变量变分模态分解方法提取呼吸信号的共性分量。

Result: 与单雷达系统相比，该多雷达系统将呼吸间隔的均方根误差降低了35.5%，呼吸频率的平均绝对误差降低了30.8%，准确率提高了9.4个百分点。

Conclusion: 结合多个雷达视角和信号整合技术，可以实现不受身体姿态影响的稳定呼吸测量。

Abstract: This study proposes a multi-radar system for non-contact physiological
sensing across arbitrary body orientations. In integrating signals obtained
from different radar viewpoints, we adopt a multivariate variational mode
decomposition method to extract the common respiratory component. Experiments
conducted with six subjects under varying distances and orientations
demonstrate that, compared with a single-radar setup, the proposed system
reduced the root mean square error of the respiratory interval by 35.5%,
decreased the mean absolute error of the respiratory rate by 30.8%, and
improved accuracy by 9.4 percentage points. These results highlight that
combining multiple radar viewpoints with signal integration enables stable
respiratory measurement regardless of body orientation.

</details>


### [460] [Large Language Model-Empowered Channel Prediction and Predictive Beamforming for LEO Satellite Communications](https://arxiv.org/abs/2510.10561)
*Zhixiong Chen,Hyundong Shin,Arumugam Nallanathan,Jonathon Chambers*

Main category: eess.SP

TL;DR: 本研究提出了一个基于大语言模型（LLM）的信道预测框架CPLLM，用于预测低地球轨道（LEO）卫星通信的未来信道状态信息（CSI）。该框架通过CSI编码器将原始CSI数据映射到文本嵌入空间，并使用CSI解码器同时预测多个未来时间槽的CSI，同时采用LoRA进行参数高效微调。此外，还提出了BFLLM，用于直接生成预测性波束形成策略。


<details>
  <summary>Details</summary>
Motivation: 现有LEO卫星通信的信道预测和预测性波束形成方法在模型泛化能力和适应时变无线传播环境方面存在局限。受LLM泛化和推理能力的启发，需要新的方法来提高信道预测和波束形成的性能。

Method: 提出CPLLM框架，包含：1. CSI编码器，将CSI映射到文本嵌入空间。2. CSI解码器，同时预测多个未来时间槽的CSI。3. LoRA参数高效微调策略，冻结预训练LLM并注入可训练低秩矩阵。4. 扩展CPLLM到BFLLM，增加波束形成解码器，直接生成波束形成策略。

Result: 模拟结果验证了CPLLM在信道预测和BFLLM在预测性波束形成方面的有效性。

Conclusion: CPLLM和BFLLM为LEO卫星通信提供了有效的信道预测和预测性波束形成解决方案，克服了现有方法的局限性。

Abstract: Accurate channel prediction and effective beamforming are essential for low
Earth orbit (LEO) satellite communications to enhance system capacity and
enable high-speed connectivity. Most existing channel prediction and predictive
beamforming methods are limited by model generalization capabilities and
struggle to adapt to time-varying wireless propagation environments. Inspired
by the remarkable generalization and reasoning capabilities of large language
models (LLMs), this work proposes an LLM-based channel prediction framework,
namely CPLLM, to forecast future channel state information (CSI) for LEO
satellites based on historical CSI data. In the proposed CPLLM, a dedicated CSI
encoder is designed to map raw CSI data into the textual embedding space,
effectively bridging the modality gap and enabling the LLM to perform reliable
reasoning over CSI data. Additionally, a CSI decoder is introduced to
simultaneously predict CSI for multiple future time slots, substantially
reducing the computational burden and inference latency associated with the
inherent autoregressive decoding process of LLMs. Then, instead of training the
LLM from scratch, we adopt a parameter-efficient fine-tuning strategy, i.e.,
LoRA, for CPLLM, where the pretrained LLM remains frozen and trainable low-rank
matrices are injected into each Transformer decoder layer to enable effective
fine-tuning. Furthermore, we extend CPLLM to directly generate beamforming
strategies for future time slots based on historical CSI data, namely BFLLM.
This extended framework retains the same architecture as CPLLM, while
introducing a dedicated beamforming decoder to output beamforming strategies.
Finally, extensive simulation results validate the effectiveness of the
proposed approaches in channel prediction and predictive beamforming for LEO
satellite communications.

</details>


### [461] [Covert Waveform Design for Integrated Sensing and Communication System in Clutter Environment](https://arxiv.org/abs/2510.10563)
*Xuyang Zhao,Jiangtao Wang,Xinyu Zhang*

Main category: eess.SP

TL;DR: 本研究提出了一种集成传感与通信（ISAC）系统的隐蔽波形设计方法，旨在复杂杂波环境下最大化信噪比（SCNR），同时满足隐蔽性要求。通过联合优化发射波形和接收滤波器，实现了有效的杂波抑制，并解决了目标多普勒频移不确定性的问题。该方法还考虑了通信可靠性，加入了相位差、能量、隐蔽性和峰均功率比（PAPR）等约束。通过凸优化技术将非凸问题转化为可解的凸问题。仿真结果表明，该优化波形在复杂杂波环境下满足隐蔽性要求，并实现了优越的目标检测性能和可靠的通信。


<details>
  <summary>Details</summary>
Motivation: 在复杂杂波环境下，设计一种能够同时满足隐蔽通信和目标检测的集成传感与通信（ISAC）系统波形，以最大化信噪比（SCNR）。

Method: 联合优化发射波形和接收滤波器，解决目标多普勒频移不确定性，并加入相位差、能量、隐蔽性和峰均功率比（PAPR）约束，将非凸优化问题转化为凸优化问题。

Result: 优化后的波形在复杂杂波环境下满足隐蔽性要求，实现了优越的目标检测性能，并保证了通信的可靠性。

Conclusion: 所提出的ISAC系统隐蔽波形设计方法在复杂杂波环境下有效，能够同时实现隐蔽通信和目标检测。

Abstract: This paper proposes an integrated sensing and communication (ISAC) system
covert waveform design method for complex clutter environments, with the core
objective of maximizing the signal-to-clutter-plus-noise ratio (SCNR). The
design achieves efficient clutter suppression while meeting the covertness
requirement through joint optimization of the transmit waveform and receive
filter, enabling cooperative radar detection and wireless communication. This
study presents key innovations that explicitly address target Doppler shift
uncertainty, significantly enhancing system robustness against Doppler effects.
To ensure communication reliability, the method incorporates phase difference
constraints between communication signal elements in the waveform design, along
with energy constraint, covert constraint, and peak-to-average power ratio
(PAPR) constraint. The original non-convex optimization problem is transformed
into a tractable convex optimization form through convex optimization
technique. Simulation results demonstrate that the optimized waveform not only
satisfies the covertness requirement in complex clutter environment, but also
achieves superior target detection performance. It also ensures reliable
communication and confirms the effectiveness of propose method.

</details>


### [462] [A Parametric Power Model of Upper Mid-Band (FR3) Base Stations for 6G](https://arxiv.org/abs/2510.10647)
*Emanuele Peschiera,Sangbu Yun,Youngjoo Lee,Liesbet Van der Perre,François Rottenberg*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Increasing attention is given to the upper mid-band or Frequency Range 3
(FR3), from 7 to 24 GHz, in the research towards sixth-generation (6G)
networks. Promises of offering large data rates at favorable propagation
conditions are leading to novel FR3 base station (BS) architectures, with up to
thousands of antenna elements and radio-frequency (RF) chains. This work
investigates the power consumption of prospective FR3 BSs and its relation to
the delivered data rates. We model the power consumed by digital and analog
signal processing, power amplifiers (PAs), and supply and cooling during four
phases (data, signaling, micro-sleep, and idle) in downlink and uplink. Hybrid
partially-connected beamforming is compared to fully-digital one. Results show
that, for BS arrays with $1024$ antennas at $30\%$ of load, the PA consumes
most of the power when $64$ or less RF chains are utilized, while the digital
and analog processing consumption takes over when the number of RF chains is
$512$ or more. The digital plus analog processing consumes $2\times$ to
$4\times$ more than the PA for fully-digital beamforming. Hybrid beamforming
achieves $1.3$ Gbit/s/user in downlink while improving the energy efficiency by
$1.4\times$ compared to fully-digital beamforming.

</details>


### [463] [Spatially Filtered Sparse Bayesian Learning for Direction-of-Arrival Estimation with Leaky-Wave Antennas](https://arxiv.org/abs/2510.10796)
*R. Maydani,Y. Wang,J. Sarrazin,B. Ma*

Main category: eess.SP

TL;DR: LWA通过空间滤波稀疏贝叶斯学习框架实现相干源的鲁棒DOA估计。


<details>
  <summary>Details</summary>
Motivation: LWA的DOA估计在相干源存在时具有挑战性，需要一种紧凑且具有成本效益的解决方案。

Method: 将视场划分为扇区，并在每个扇区内解决贝叶斯逆问题，提出了一种空间滤波稀疏贝叶斯学习（SF-SBL）框架，包括网格内和网格外SBL。

Result: 所提出的SF-SBL框架在存在相干源的情况下实现了稳健且准确的DOA估计。

Conclusion: SF-SBL框架能够有效解决LWA在相干源存在时的DOA估计问题。

Abstract: Direction-of-arrival (DoA) estimation with leaky-wave antennas (LWAs) offers
a compact and cost-effective alternative to conventional antenna arrays but
remains challenging in the presence of coherent sources. To address this issue,
we propose a spatially filtered sparse Bayesian learning (SF-SBL) framework.
Firstly, the field of view (FoV) is divided into angular sectors according to
the frequency beam-scanning property of LWAs, and Bayesian inverse problems are
then solved within each sector to improve efficiency and reduce computational
cost. Both on-grid SBL and off-grid SBL formulations are developed. Simulation
results show that the proposed approach achieves robust and accurate DoA
estimation, even with coherent sources.

</details>


### [464] [Spatial Signal Focusing and Noise Suppression for Direction-of-Arrival Estimation in Large-Aperture 2D Arrays under Demanding Conditions](https://arxiv.org/abs/2510.10923)
*Xuyao Deng,Yong Dou,Kele Xu*

Main category: eess.SP

TL;DR: 该论文提出了一种名为SSFNS的新型DOA估计算法，它利用最优空间滤波器的概念，在低信噪比、单快照、相干源和未知信号数等挑战性条件下，能够比现有算法表现更好，特别适用于大型二维阵列。


<details>
  <summary>Details</summary>
Motivation: 现有DOA估计算法在低信噪比、单快照、相干源和未知信号数等条件下存在局限性。例如，传统波束成形受旁瓣干扰，自适应和子空间算法在快照数有限或信号相干时性能下降，稀疏恢复方法计算复杂度高。

Method: 提出了一种名为SSFNS（Spatial Signal Focusing and Noise Suppression）的新型DOA估计算法框架。该框架基于最优空间滤波器的理论存在性，将DOA估计问题转化为求解最优空间滤波器的问题。通过利用空间信号的稀疏性来构建最优空间滤波器。

Result: 实验结果表明，SSFNS算法适用于大型二维阵列，并且在快照数少（甚至单快照）、低信噪比、相干信号和未知信号数的情况下，其性能优于其他现有算法。

Conclusion: SSFNS算法是一种有效且鲁棒的DOA估计算法，尤其是在具有挑战性的条件下，能够克服现有方法的缺点，为大型二维阵列提供了更好的解决方案。

Abstract: Direction-of-Arrival (DOA) estimation in sensor arrays faces limitations
under demanding conditions, including low signal-to-noise ratio,
single-snapshot scenarios, coherent sources, and unknown source counts.
Conventional beamforming suffers from sidelobe interference, adaptive methods
(e.g., MVDR) and subspace algorithms (e.g., MUSIC) degrade with limited
snapshots or coherent signals, while sparse-recovery approaches (e.g., L1-SVD)
incur high computational complexity for large arrays. In this article, we
construct the concept of the optimal spatial filter to solve the DOA estimation
problem under demanding conditions by utilizing the sparsity of spatial
signals. By utilizing the concept of the optimal spatial filter, we have
transformed the DOA estimation problem into a solution problem for the optimal
spatial filter. We propose the Spatial Signal Focusing and Noise Suppression
(SSFNS) algorithm, which is a novel DOA estimation framework grounded in the
theoretical existence of an optimal spatial filter, to solve for the optimal
spatial filter and obtain DOA. Through experiments, it was found that the
proposed algorithm is suitable for large aperture two-dimensional arrays and
experiments have shown that our proposed algorithm performs better than other
algorithms in scenarios with few snapshots or even a single snapshot, low
signal-to-noise ratio, coherent signals, and unknown signal numbers in
two-dimensional large aperture arrays.

</details>


### [465] [Dual-Waveguide Pinching Antennas for PLS: Parallel Placement or Orthogonal Placement?](https://arxiv.org/abs/2510.11044)
*Yang Lu,Xinke Xie,Yanqing Xu,Bo Ai,Octavia A. Dobre,Dusit Niyato*

Main category: eess.SP

TL;DR: 本论文研究了在双波导系统中，利用可移动的捏合天线（PAs）来增强物理层安全（PLS），以扩大合法用户（LUs）和窃听者（Eves）之间的信道条件差异。


<details>
  <summary>Details</summary>
Motivation: 通过利用可移动捏合天线（PAs）来定制信道条件，旨在提升物理层安全（PLS），具体是通过增加合法用户（LUs）和窃听者（Eves）之间的信道差异。

Method: 在双波导场景下，考虑了平行和正交两种波导放置策略，以及包含相移和衰减的两种信道模型。通过两阶段算法求解安全和速率（SSR）及安全和能量效率（SEE）最大化问题：第一阶段使用改进的粒子群优化（PSO）算法（FeaPSO）进行PA放置，第二阶段使用连续凸近似（SCA）方法优化波束成形和人工噪声向量。

Result: 通过数值比较了两种放置策略的平均性能和窃听者位于合法用户之前的特殊情况。结果表明，所提出的算法能有效提升SSR和SEE，并验证了正交放置的必要性。

Conclusion: 捏合天线（PAs）能够显著提升双波导系统中的安全和速率（SSR）及安全和能量效率（SEE），并且正交放置策略是实现这些性能提升的关键。

Abstract: Pinching antennas (PAs), as an emerging flexible-antenna technology, enables
movable PAs deployed along waveguides to customize channel conditions over a
large scale. This paper investigates an application of PAs to enable
physical-layer security (PLS) by enlarging the channel condition diversity
between legitimate users (LUs) and eavesdroppers (Eves). Particularly, we focus
on the dual-waveguide scenario, where the two waveguides employs multiple PAs
to serve multiple LUs in the presence of an Eve. Specifically, we consider two
waveguide placement strategies, i.e., parallel placement and orthogonal
placement. Meanwhile, we incorporate two channel models, i.e., in-waveguide
phase shifts, and in-waveguide phase shifts and attenuation. We formulate the
secure sum rate (SSR) and secure energy efficiency (SEE) maximization problems,
and propose a two-stage algorithm to solve them. The first stage adopts a
particle swarm optimization (PSO) method with an improved feasibility module,
termed FeaPSO, for PA placement, and the second stage employs the successive
convex approximate (SCA) method to optimize beamforming and artificial noise
vectors. Furthermore, we conduct numerical comparisons between the two
placement strategies in terms of average performance and a special case where
an Eve is positioned in front of LUs. Numerical results validate the
effectiveness of the proposed algorithm and demonstrate that PAs can
significantly improve both SSR and SEE. Additionally, the necessity of
orthogonal waveguide placement is explicitly verified.

</details>


### [466] [The Post-Electromagnetic Era: A Vision for Wireless Communication Beyond 6G](https://arxiv.org/abs/2510.11097)
*Shumaila Javaid,Nasir Saeed*

Main category: eess.SP

TL;DR: 本篇论文提出了一种后6G通信的 state-centric 框架，通过操纵物理、生物和认知状态来传递信息，而非依赖电磁波，旨在克服现有通信的物理和热力学限制。


<details>
  <summary>Details</summary>
Motivation: 目前的电磁通信正接近物理和热力学极限，仅靠优化频谱已难以为继，带宽有限、高频损耗以及能量与信息的权衡限制了6G及未来系统的可扩展性，因此需要寻找超越传统电磁波的通信机制。

Method: 提出一个 state-centric 框架，识别定义了后电磁时代潜在载体和交互机制的十个基础范式，并概述了迈向自组织、认知集成网络的研发路线图。

Result: 设想了一种新的通信系统，该系统具有能量感知、自适应能力，并能将物质、生命和智能统一在单一信息连续体中。

Conclusion: 通过为这一转型奠定概念基础，本工作为未来旨在实现超越频谱限制的通信范式的研究提供了基础。

Abstract: Electromagnetic (EM) communication is nearing its physical and thermodynamic
limits, where further performance gains through spectrum optimization alone
have become increasingly unsustainable. Finite bandwidth, propagation loss at
higher frequencies, and the inherent trade-offs between energy and information
constrain the scalability of 6G and beyond systems. These limitations drive the
search for alternative mechanisms for information transfer beyond conventional
EM propagation. This work introduces a state-centric framework for post-6G
communication, in which information is conveyed by manipulating physical,
biological, and cognitive states rather than EM waves. It identifies ten
foundational paradigms that define potential carriers and interaction
mechanisms for the post-electromagnetic era and outlines a research roadmap
toward self-organizing, cognitively integrated networks. Together, these
developments envision a new class of communication systems that are
energy-aware, adaptive, and capable of uniting matter, life, and intelligence
within a single informational continuum. By establishing the conceptual basis
for this transition, the work provides a foundation for future research aimed
at realizing communication paradigms that transcend the limitations of
spectrum-bound systems.

</details>


### [467] [Navigating the Dual-Use Nature and Security Implications of Reconfigurable Intelligent Surfaces in Next-Generation Wireless Systems](https://arxiv.org/abs/2510.11113)
*Hetong Wang,Tiejun Lv,Yashuai Cao,Weicai Li,Jie Zeng,Pingmu Huang,Muhammad Khurram Khan*

Main category: eess.SP

TL;DR: RIS技术虽有潜力但存在安全风险，可用于混合攻击，也可能增强安全性。需要安全框架。


<details>
  <summary>Details</summary>
Motivation: RIS技术在增强无线通信的同时，也带来了安全风险，需要对其安全影响进行探讨。

Method: 1. 识别RIS的双重用途，展示其通信增强能力如何被恶意利用。
2. 提出“被动-主动混合攻击”新概念，并列举RIS辅助攻击类型（窃听、中间人、重放、反射干扰、侧信道攻击）。
3. 揭示攻击者如何利用开放无线信道在AI驱动的RIS网络中引入对抗性扰动。
4. 探讨RIS在射频(RF)和可见光通信(VLC)系统中增强安全和隐私的作用。
5. 综合当前见解，强调新兴威胁，并提供关于跨层协作、高级对抗防御以及安全与成本之间平衡的实用见解。

Result: RIS技术可以被恶意利用，导致窃听、中间人攻击等。同时，RIS也可用于增强RF和VLC系统的安全。AI驱动的RIS网络易受对抗性扰动的影响。

Conclusion: RIS技术具有双重性，既带来安全风险，也提供安全增强的潜力。未来的无线系统需要建立强大的安全框架来应对这些挑战。

Abstract: Reconfigurable intelligent surface (RIS) technology offers significant
promise in enhancing wireless communication systems, but its dual-use potential
also introduces substantial security risks. This survey explores the security
implications of RIS in next-generation wireless networks. We first highlight
the dual-use nature of RIS, demonstrating how its communication-enhancing
capabilities can be exploited by adversaries to compromise legitimate users. We
identify a new class of security vulnerabilities termed ``passive-active hybrid
attacks,'' where RIS, despite passively handling signals, can be reconfigured
to actively engage in malicious activities, enabling various RIS-assisted
attacks, such as eavesdropping, man-in-the-middle (MITM), replay, reflection
jamming, and side-channel attacks. Furthermore, we reveal how adversaries can
exploit the openness of wireless channels to introduce adversarial
perturbations in artificial intelligence-driven RIS networks, disrupting
communication terminals and causing misclassifications or errors in RIS
reflection predictions. Despite these risks, RIS technology also plays a
critical role in enhancing security and privacy across radio frequency (RF) and
visible light communication (VLC) systems. By synthesizing current insights and
highlighting emerging threats, we provide actionable insights into cross-layer
collaboration, advanced adversarial defenses, and the balance between security
and cost. This survey provides a comprehensive overview of RIS technology's
security landscape and underscores the urgent need for robust security
frameworks in the development of future wireless systems.

</details>


### [468] [WiNPA: Wireless Neural Processing Architecture](https://arxiv.org/abs/2510.11150)
*Sai Xu,Yanan Du*

Main category: eess.SP

TL;DR: WiNPA 是一种无线神经处理架构，通过联合优化无线通信和计算资源来加速边缘的深度神经网络（DNN）推理。


<details>
  <summary>Details</summary>
Motivation: 弥合无线通信和边缘智能之间的研究差距，并显著提高 DNN 推理性能。

Method: 通过数学建模、优化和统一的软硬件平台，对无线通信和边缘计算进行细粒度集成。

Result: 通过仿真证明了 WiNPA 在加速 DNN 推理方面的有效性。

Conclusion: WiNPA 为加速边缘 DNN 推理提供了一种新颖的方法，并通过对关键研究方向的讨论指导未来的发展和实际应用。

Abstract: This article presents a wireless neural processing architecture (WiNPA),
providing a novel perspective for accelerating edge inference of deep neural
network (DNN) workloads via joint optimization of wireless and computing
resources. WiNPA enables fine-grained integration of wireless communication and
edge computing, bridging the research gap between wireless and edge
intelligence and significantly improving DNN inference performance. To fully
realize its potential, we explore a set of fundamental research issues,
including mathematical modeling, optimization, and unified hardware--software
platforms. Additionally, key research directions are discussed to guide future
development and practical implementation. A case study demonstrates WiNPA's
workflow and effectiveness in accelerating DNN inference through simulations.

</details>


### [469] [CSI Prediction Using Diffusion Models](https://arxiv.org/abs/2510.11214)
*Mehdi Sattari,Javad Aliakbari,Alexandre Graell i Amat,Tommy Svensson*

Main category: eess.SP

TL;DR: 本论文提出了一种基于扩散模型的信道状态信息（CSI）预测新框架，解决了传统方法中存在的信道状态信息获取的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决无线通信中信道状态信息（CSI）获取的挑战，如过高的导频开销和信道老化问题，提出了一种基于深度学习的CSI预测方法。

Method: 该方法将CSI预测任务分解为两个部分：1. 时间编码器，用于提取信道动态。2. 基于扩散的模型生成器，用于生成未来的CSI样本。并探索了两种推理方案（自回归和序列到序列）、多种扩散骨干网络（U-Net和Transformer）以及一种无需显式时间编码器的扩散方法，并使用DDIM调度来降低模型复杂度。

Result: 通过大量的仿真实验证明，所提出的基于扩散模型的CSI预测方法显著优于现有的基线方法。

Conclusion: 基于扩散模型的CSI预测框架能够有效解决现有方法的局限性，并在性能上超越现有技术，为无线通信的CSI获取提供了新的解决方案。

Abstract: Acquiring accurate channel state information (CSI) is critical for reliable
and efficient wireless communication, but challenges such as high pilot
overhead and channel aging hinder timely and accurate CSI acquisition. CSI
prediction, which forecasts future CSI from historical observations, offers a
promising solution. Recent deep learning approaches, including recurrent neural
networks and Transformers, have achieved notable success but typically learn
deterministic mappings, limiting their ability to capture the stochastic and
multimodal nature of wireless channels. In this paper, we introduce a novel
probabilistic framework for CSI prediction based on diffusion models, offering
a flexible design that supports integration of diverse prediction schemes. We
decompose the CSI prediction task into two components: a temporal encoder,
which extracts channel dynamics, and a diffusion-based generator, which
produces future CSI samples. We investigate two inference
schemes-autoregressive and sequence-to-sequence- and explore multiple diffusion
backbones, including U-Net and Transformer-based architectures. Furthermore, we
examine a diffusion-based approach without an explicit temporal encoder and
utilize the DDIM scheduling to reduce model complexity. Extensive simulations
demonstrate that our diffusion-based models significantly outperform
state-of-the-art baselines.

</details>


### [470] [Normalized Ambiguity Function Characteristics of OFDM, OTFS, AFDM, and CP-AFDM for ISAC](https://arxiv.org/abs/2510.11216)
*Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 本文对四种用于 6G ISAC 的候选多载波波形（OFDM、OTFS、AFDM、CP-AFDM）的模糊函数 (AF) 特性进行了统一且与系统无关的分析，重点关注其时延-多普勒响应。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同多载波波形在集成传感与通信 (ISAC) 场景下的性能，特别是它们的模糊函数特性。

Method: 通过波形的离散时间定义及其理想分数插值来获得模糊函数，并分析了通信导向和传感导向两种信号模式下的模糊函数及其各项性能指标（如主瓣宽度、峰旁瓣比、积分旁瓣比）。

Result: OFDM 在时延分辨率和旁瓣特性方面表现优异，但在多普勒响应方面较差；而 OTFS、AFDM 和 CP-AFDM 在时延和多普勒分辨率之间取得了更好的平衡，但旁瓣特性各不相同。

Conclusion: 研究为 ISAC 波形设计提供了一个统一的基准，并公开了模糊函数仿真代码以促进未来研究。

Abstract: This paper presents a unified and system-agnostic analysis of the ambiguity
function (AF) characteristics of four representative multicarrier waveforms,
orthogonal frequency division multiplexing (OFDM), orthogonal time frequency
space (OTFS), affine frequency division multiplexing (AFDM), and chirp-permuted
AFDM (CP-AFDM), which are considered as key candidates for enabling integrated
sensing and communications (ISAC) in future sixth generation (6G) networks. The
AF of each waveform is obtained directly from its discrete-time definition and
enhanced via ideal fractional interpolation, enabling precise characterization
of its continuous-time delay-Doppler response. Two signaling modes are
examined: a communication-oriented case with random information symbols
suitable only for monostatic scenarios, and a sensing-oriented case with fixed
unimodular symbols suitable for general multi-static scenarios. Furthermore,
the AFs and the ambiguity metrics including the 3dB mainlobe width,
peak-to-sidelobe ratio (PSLR), and integrated sidelobe ratio (ISLR), are
evaluated in normalized delay-Doppler units, enabling direct translation to any
physical system configuration defined by bandwidth, sampling frequency, or
symbol duration, while ensuring straightforward and consistent comparison
across waveforms. The results establish a consistent benchmark for comparing
waveform sensing capabilities in ISAC design, consolidating known behaviors:
OFDM exhibits excellent delay resolution and sidelobe behavior but poor Doppler
response, whereas advanced waveforms achieve improved balance between delay and
Doppler resolution with varying sidelobe characteristics. The simulation code
of the smooth AFs, is openly shared to promote reproducibility and support
future ISAC waveform research.

</details>


### [471] [Two-Dimensional Graph Bi-Fractional Fourier Transform](https://arxiv.org/abs/2510.11279)
*Mingzhi Wang,Zhichao Zhang*

Main category: eess.SP

TL;DR: 现有的二维图分数傅里叶变换(2D-GFRFT)使用单一的分数阶数，限制了其在异构信号上的适应性。本文提出了二维图双分数傅里叶变换(2D-GBFRFT)，为笛卡尔积的因子图分配独立的 yı 分数阶数，同时保持可分离性。


<details>
  <summary>Details</summary>
Motivation: 现有的二维图分数傅里叶变换(2D-GFRFT)使用单一的分数阶数，限制了其在异构信号上的适应性。

Method: 提出二维图双分数傅里叶变换(2D-GBFRFT)，为笛卡尔积的因子图分配独立的 yı 分数阶数，同时保持可分离性。建立了可逆性、酉性和指标可加性，并开发了两种滤波方案：通过网格搜索实现的维纳风格设计和联合优化变换阶数和对角谱滤波器的可微分框架。进一步引入了具有联合时域-顶点分数傅里叶变换(JFRFT)的混合插值，该插值由一个可调参数控制，以平衡这两种方法。

Result: 在合成笛卡尔积图信号、真实时间图数据集和动态图像去模糊领域，2D-GBFRFT 的性能始终优于 2D-GFRFT，并增强了 JFRFT。

Conclusion: 实验结果证实了 2D-GBFRFT 在图信号处理（GSP）中用于滤波的多功能性和优越性能。

Abstract: Graph signal processing (GSP) advances spectral analysis on irregular
domains. However, existing two-dimensional graph fractional Fourier transform
(2D-GFRFT) employs a single fractional order for both factor graphs, thereby
limiting its adaptability to heterogeneous signals. We proposed the
two-dimensional graph bi-fractional Fourier transform (2D-GBFRFT), which
assigns independent fractional orders to the factor graphs of a Cartesian
product while preserving separability. We established invertibility, unitarity,
and index additivity, and developed two filtering schemes: a Wiener-style
design through grid search and a differentiable framework that jointly
optimizes transform orders and diagonal spectral filters. We further introduced
a hybrid interpolation with the joint time-vertex fractional Fourier transform
(JFRFT), controlled by a tunable parameter that balances the two methods. In
the domains of synthetic Cartesian product graph signals, authentic temporal
graph datasets, and dynamic image deblurring, 2D-GBFRFT consistently surpasses
2D-GFRFT and enhances JFRFT. Experimental results confirmed the versatility and
superior performance of 2D-GBFRFT for filtering in GSP.

</details>


### [472] [Channel-Aware Deep Learning for Superimposed Pilot Power Allocation and Receiver Design](https://arxiv.org/abs/2510.11294)
*Run Gu,Renjie Xie,Wei Xu,Zhaohui Yang,Kaibin Huang*

Main category: eess.SP

TL;DR: 本研究提出了一种名为CaSIP的信道感知学习框架，用于优化叠加导频（SIP）方案中的导频-数据功率（PDP）分配和接收机网络，以消除导频-数据干扰（PDI），特别是在高移动性和低信噪比条件下，显著优于传统方案。


<details>
  <summary>Details</summary>
Motivation: 现有的叠加导频（SIP）方案在多用户移动场景中，由于信道快速变化，面临导频和数据信号叠加与分离的挑战。

Method: 提出了一种名为CaSIP的信道感知学习框架，该框架联合优化导频-数据功率（PDP）分配和接收机网络，以消除导频-数据干扰（PDI）。该框架利用信道路径增益信息（大规模信道状态信息），识别用户特定的、按资源单元的PDP因子，并开发了一个基于深度神经网络的SIP接收机，包含显式的信道估计和数据检测组件。为了有效利用路径增益数据，研究者设计了一个嵌入生成器，将路径增益投影到嵌入空间，并与信道估计网络的中间特征图进行融合。

Result: 仿真结果表明，CaSIP在和吞吐量和信道估计准确性方面，尤其是在高移动性和低信噪比条件下，显著优于传统的导频方案和最先进的SIP方案。

Conclusion: 所提出的CaSIP框架能够有效地处理SIP方案中的挑战，并通过联合优化PDP分配和接收机网络，利用大规模CSI来提高系统性能，尤其是在严苛的移动和信噪比条件下。

Abstract: Superimposed pilot (SIP) schemes face significant challenges in effectively
superimposing and separating pilot and data signals, especially in multiuser
mobility scenarios with rapidly varying channels. To address these challenges,
we propose a novel channel-aware learning framework for SIP schemes, termed
CaSIP, that jointly optimizes pilot-data power (PDP) allocation and a receiver
network for pilot-data interference (PDI) elimination, by leveraging channel
path gain information, a form of large-scale channel state information (CSI).
The proposed framework identifies user-specific, resource element-wise PDP
factors and develops a deep neural network-based SIP receiver comprising
explicit channel estimation and data detection components. To properly leverage
path gain data, we devise an embedding generator that projects it into
embeddings, which are then fused with intermediate feature maps of the channel
estimation network. Simulation results demonstrate that CaSIP efficiently
outperforms traditional pilot schemes and state-of-the-art SIP schemes in terms
of sum throughput and channel estimation accuracy, particularly under
high-mobility and low signal-to-noise ratio (SNR) conditions.

</details>


### [473] [A Dynamic Watermarking Technique for Matching Communication Addresses with Cars in a Visual Field](https://arxiv.org/abs/2510.11353)
*Woo-Hyun Ko,Jaewon Kim,Tzu-Hsiang Lin,Samin Moosavi,P. R. Kumar*

Main category: eess.SP

TL;DR: RSU通过动态水印技术解决车辆IP地址匹配问题。


<details>
  <summary>Details</summary>
Motivation: RSU在监控道路时，无法将视频中的车辆与IP地址进行匹配，导致无法向特定车辆发送预警信息。

Method: 提出一种基于动态水印的技术，车辆通过在其控制指令中叠加小的随机扰动，并将包含IP地址的信号发送给RSU。RSU通过处理视频流中的车辆信号，匹配其与接收到的信号，从而确定车辆与IP地址的对应关系。

Result: 在实验室和实际道路环境中进行了演示，证明该方法能够有效区分目标车辆的通信与其他车辆的IP地址。

Conclusion: 动态水印技术为RSU解决了车辆IP地址匹配的根本性问题，提高了道路监控的效率和安全性。

Abstract: We consider a problem faced by an intelligent roadside unit (RSU) monitoring
a roadway by a video camera. Suppose the RSU notices that a particular car in
its visual field needs to execute a specific evasive maneuver to avoid danger.
It would like to send a packet addressed to that particular car with this
suggestion. The problem is that while all the cars are communicating with the
RSU, the RSU does not know which car in the video is associated with what IP
address. So, it does not know which IP address to send the packet to. Indeed,
the problem of matching addresses with cars in the visual field is a
fundamental open problem. We provide an active solution employing dynamic
watermarking that was originally developed for the security of cyber-physical
systems. This technique calls for a car to superpose a small random excitation
onto its actuation commands for steering angle or throttle/brake positions. The
car sends this random waveform to the RSU in a packet containing its IP
address. By signal processing of the video stream of a car at the RSU it can
verify whether it matches with the waveform in the packet and thereby
associates that the IP address of the packet with that car in the visual field.
The RSU thereby determines which IP address is associated with which car in its
visual field. We present two demonstrations of performance. We demonstrate
experimental results on a laboratory transportation automated vehicles, a
vision system, and a network, as well as on the field with two passenger sedans
in practice. The results demonstrate that employing the dynamic watermarking
method enables an RSU to distinguish the communication of a target vehicle from
that of other IP addresses of nearby vehicles.

</details>


### [474] [CIRSense: Rethinking WiFi Sensing with Channel Impulse Response](https://arxiv.org/abs/2510.11374)
*Ruiqi Kong,He Chen*

Main category: eess.SP

TL;DR: 本文提出了一种名为CIRSense的新型WiFi传感框架，利用信道冲激响应（CIR）替代传统的信道状态信息（CSI），以提升传感性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi传感方法主要从CSI估计运动信息，忽略了CIR在汇聚运动能量和分离多径分量方面的优势。

Method: CIRSense框架基于新的运动模型，该模型能表征CIR传感中的分数延迟效应，并解决了硬件失真补偿、高分辨率距离估计和用于扩展范围传感的子载波聚合等技术挑战。

Result: 在160 MHz信道带宽下，CIRSense在呼吸监测中达到约0.25 bpm的平均误差，在距离估计中达到0.09 m的平均误差。在20 m的挑战性传感距离下，CIRSense的平均准确度是现有基于CSI方法的3倍以上，计算效率更高4.5倍以上。

Conclusion: CIRSense在各种环境下（住宅、远距离、多目标）均表现出优于现有基于CSI方法的性能，证明了其在WiFi传感领域的潜力。

Abstract: WiFi sensing based on channel state information (CSI) collected from
commodity WiFi devices has shown great potential across a wide range of
applications, including vital sign monitoring and indoor localization. Existing
WiFi sensing approaches typically estimate motion information directly from
CSI. However, they often overlook the inherent advantages of channel impulse
response (CIR), a delay-domain representation that enables more intuitive and
principled motion sensing by naturally concentrating motion energy and
separating multipath components. Motivated by this, we revisit WiFi sensing and
introduce CIRSense, a new framework that enhances the performance and
interpretability of WiFi sensing with CIR. CIRSense is built upon a new motion
model that characterizes fractional delay effects, a fundamental challenge in
CIR-based sensing. This theoretical model underpins technical advances for the
three challenges in WiFi sensing: hardware distortion compensation,
high-resolution distance estimation, and subcarrier aggregation for extended
range sensing. CIRSense, operating with a 160 MHz channel bandwidth,
demonstrates versatile sensing capabilities through its dual-mode design,
achieving a mean error of approximately 0.25 bpm in respiration monitoring and
0.09 m in distance estimation. Comprehensive evaluations across residential
spaces, far-range scenarios, and multi-target settings demonstrate CIRSense's
superior performance over state-of-the-art CSI-based baselines. Notably, at a
challenging sensing distance of 20 m, CIRSense achieves at least 3x higher
average accuracy with more than 4.5x higher computational efficiency.

</details>


### [475] [Uncertainty Propagation in Finite Impulse Response Filters: Evaluating the Gaussian Assumption](https://arxiv.org/abs/2510.11384)
*Jennie Couchman,Phillip Stanley-Marbell*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A common assumption in signal processing is that underlying data numerically
conforms to a Gaussian distribution. It is commonly utilized in signal
processing to describe unknown additive noise in a system and is often
justified by citing the central limit theorem for sums of random variables,
although the central limit theorem applies only to sums of independent
identically distributed random variables. However, many linear operations in
signal processing take the form of weighted sums, which transforms the random
variables such that their distributions are no longer identical. One such
operation is a finite impulse response (FIR) filter. FIR filters are commonly
used in signal processing applications as a pre-processing step. FIR output
noise is generally assumed to be Gaussian. This article examines the FIR output
response in the presence of uniformly distributed quantization noise. We
express the FIR output uncertainty in terms of the input quantization
uncertainty and filter coefficients. We show that the output uncertainty cannot
be assumed to be Gaussian, but depending on the application a Gaussian
estimation may still be useful. Then, we show through detailed numerical
simulations that the output uncertainty distribution of the filter can be
estimated through its most dominant coefficients.

</details>


### [476] [Thermal Analysis of 3D GPU-Memory Architectures with Boron Nitride Interposer](https://arxiv.org/abs/2510.11461)
*Eric Han Wang,Weijia Yan,Ruihong Huang*

Main category: eess.SP

TL;DR: h-BN 散热片可将 AI 芯片的散热提高 20°C，并减少 22% 的功率泄漏。


<details>
  <summary>Details</summary>
Motivation: 传统硅基板在为 3D 堆叠设计的 AI 芯片提供散热方面已变得不足，因为 AI 芯片的功耗不断增加。

Method: 利用 COMSOL Multiphysics 模拟研究了 h-BN 互连件对散热和热点缓解的影响，并研究了高带宽内存 (HBM) 的分布和热界面材料配置。

Result: 与硅互连件相比，h-BN 互连件可将热点温度降低 20°C，从而将 AI 芯片的功耗泄漏减少 22%。

Conclusion: h-BN 互连件可有效散热 AI 芯片，并能显著提高其热性能。

Abstract: As artificial intelligence (AI) chips become more powerful, the thermal
management capabilities of conventional silicon (Si) substrates become
insufficient for 3D-stacked designs. This work integrates electrically
insulative and thermally conductive hexagonal boron nitride (h-BN) interposers
into AI chips for effective thermal management. Using COMSOL Multiphysics, the
effects of High-Bandwidth Memory (HBM) distributions and thermal interface
material configurations on heat dissipation and hotspot mitigation were
studied. A 20 {\deg}C reduction in hot spots was achieved using h-BN
interposers compared to Si interposers. Such an improvement could reduce AI
chips' power leakage by 22% and significantly enhance their thermal
performance.

</details>


### [477] [Control Requirements for Robust Beamforming in Multi-Satellite Systems](https://arxiv.org/abs/2510.11465)
*Diego Tuzi,Thomas Delamotte,Andreas Knopp*

Main category: eess.SP

TL;DR: 多卫星系统波束形成性能对位置和姿态扰动敏感，但可通过控制感知波束形成策略恢复。


<details>
  <summary>Details</summary>
Motivation: 研究多卫星系统中的位置和姿态扰动对波束形成性能的影响，并探索恢复性能的方法。

Method: 分析了位置和姿态扰动对直接辐射阵列合成大虚拟天线孔径的多卫星系统的影响，并提出将位置和姿态信息纳入波束形成过程。

Result: 结果表明，波束形成性能对扰动高度敏感，但通过在波束形成过程中加入位置和姿态信息，可以有效恢复标称性能。

Conclusion: 控制感知波束形成策略，将姿态和轨道控制系统与信号处理紧密集成，能够实现鲁棒的波束形成和自主协调。

Abstract: This work investigates the impact of position and attitude perturbations on
the beamforming performance of multi-satellite systems. The system under
analysis is a formation of small satellites equipped with direct radiating
arrays that synthesise a large virtual antenna aperture. The results show that
performance is highly sensitive to the considered perturbations. However, by
incorporating position and attitude information into the beamforming process,
nominal performance can be effectively restored. These findings support the
development of control-aware beamforming strategies that tightly integrate the
attitude and orbit control system with signal processing to enable robust
beamforming and autonomous coordination.

</details>


### [478] [Toward Efficient and Privacy-Aware eHealth Systems: An Integrated Sensing, Computing, and Semantic Communication Approach](https://arxiv.org/abs/2510.11514)
*Yinchao Yang,Yahao Ding,Zhaohui Yang,Chongwen Huang,Zhaoyang Zhang,Dusit Niyato,Mohammad Shikh-Bahaei*

Main category: eess.SP

TL;DR: 该研究提出了一种集成传感、计算和语义通信（ISCSC）框架，用于实时、非接触式生命体征监测和通信，以解决传统eHealth系统的不足。


<details>
  <summary>Details</summary>
Motivation: 现代医疗系统，尤其是在远程和隐私敏感环境中，需要实时、非接触式生命体征监测和可靠通信，但传统无线通信和传感网络在传感精度、数据效率和隐私保护方面存在不足。

Method: 提出了一种集成传感、计算和语义通信（ISCSC）框架。服务机器人利用雷达检测患者位置并监测生命体征，然后计算并传输语义提取的健康特征而非原始生理信息。采用交互多模型（IMM）滤波器跟踪患者运动，优化波束成形矩阵和语义提取率，以最大化语义保密率和传感精度。

Result: 与传统的联合传感和通信方法相比，ISCSC框架在传感精度、语义传输效率和隐私保护方面均表现出优越性能。

Conclusion: ISCSC框架能够有效解决eHealth系统中的挑战，提供高精度的生命体征监测、高效的数据传输和增强的隐私保护。

Abstract: Real-time and contactless monitoring of vital signs, such as respiration and
heartbeat, alongside reliable communication, is essential for modern healthcare
systems, especially in remote and privacy-sensitive environments. Traditional
wireless communication and sensing networks fall short in meeting all the
stringent demands of eHealth, including accurate sensing, high data efficiency,
and privacy preservation. To overcome the challenges, we propose a novel
integrated sensing, computing, and semantic communication (ISCSC) framework. In
the proposed system, a service robot utilises radar to detect patient positions
and monitor their vital signs, while sending updates to the medical devices.
Instead of transmitting raw physiological information, the robot computes and
communicates semantically extracted health features to medical devices. This
semantic processing improves data throughput and preserves the clinical
relevance of the messages, while enhancing data privacy by avoiding the
transmission of sensitive data. Leveraging the estimated patient locations, the
robot employs an interacting multiple model (IMM) filter to actively track
patient motion, thereby enabling robust beam steering for continuous and
reliable monitoring. We then propose a joint optimisation of the beamforming
matrices and the semantic extraction ratio, subject to computing capability and
power budget constraints, with the objective of maximising both the semantic
secrecy rate and sensing accuracy. Simulation results validate that the ISCSC
framework achieves superior sensing accuracy, improved semantic transmission
efficiency, and enhanced privacy preservation compared to conventional joint
sensing and communication methods.

</details>


### [479] [Beyond the Use-and-then-Forget (UatF) Bound: Fixed Point Algorithms for Statistical Max-Min Power Control](https://arxiv.org/abs/2510.11582)
*Renato Luis Garrido Cavalcante,Noor Ul Ain,Lorenzo Miretti,Slawomir Stanczak*

Main category: eess.SP

TL;DR: We present a new framework for optimal statistical max-min power control in massive MIMO systems that overcomes limitations of previous UatF-based approaches by utilizing alternative information-theoretic bounds.


<details>
  <summary>Details</summary>
Motivation: Previous studies on optimal statistical max-min power control in massive MIMO systems rely on the use-and-then-forget (UatF) lower bound, which has limitations such as being overly conservative and lacking scale invariance. This paper aims to address these shortcomings.

Method: The paper introduces mathematical tools and fixed point algorithms for optimal statistical max-min power control. The proposed framework is compatible with alternative information-theoretic bounds that explicitly consider perfect or imperfect channel state information (CSI) at the decoder, unlike previous UatF-based methods.

Result: The framework is illustrated by solving a max-min power control problem using a standard bound that exploits instantaneous CSI at the decoder. This demonstrates the framework's ability to handle bounds without the drawbacks of the UatF bound.

Conclusion: The proposed framework offers a more robust and accurate approach to statistical max-min power control in massive MIMO systems by employing alternative information-theoretic bounds that overcome the limitations of the UatF bound.

Abstract: We introduce mathematical tools and fixed point algorithms for optimal
statistical max-min power control in cellular and cell-less massive MIMO
systems. Unlike previous studies that rely on the use-and-then-forget (UatF)
lower bound on Shannon achievable (ergodic) rates, our proposed framework can
deal with alternative bounds that explicitly consider perfect or imperfect
channel state information (CSI) at the decoder. In doing so, we address
limitations of UatF-based algorithms, which inherit the shortcomings of the
UatF bound. For example, the UatF bound can be overly conservative: in extreme
cases, under fully statistical (nonadaptive) beamforming in zero-mean channels,
the UatF bound produces trivial (zero) rate bounds. It also lacks scale
invariance: merely scaling the beamformers can change the bound drastically,
especially when simple beamforming strategies are employed. In contrast, our
framework is compatible with information-theoretic bounds that do not suffer
from the above drawbacks. We illustrate the framework by solving a max-min
power control problem considering a standard bound that exploits instantaneous
CSI at the decoder.

</details>


### [480] [Bayesian Self-Calibration and Parametric Channel Estimation for 6G Antenna Arrays](https://arxiv.org/abs/2510.11628)
*Patrick Hödl,Jakob Möderl,Erik Leitinger,Klaus Witrisal*

Main category: eess.SP

TL;DR: 该研究提出了一种将天线单元自校准集成到变分稀疏贝叶斯学习（VSBL）算法中的方法，用于参数化信道估计，以解决6G无线系统中相位阵列天线在实际运行中校准失配的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决6G无线系统中相位阵列天线在实际运行中校准失配导致性能受限的问题。

Method: 将天线增益和相位偏差建模为潜在变量，并推导出显式的更新方程，以联合推断校准参数和信道参数（模型阶数、复幅度、延迟、角度和噪声方差）。所提出的算法在线运行，并能实时适应硬件引起的失配。

Result: 通过均方根误差（RMSE）和最优子模式分配（OSPA）指标评估，所提出的集成自校准的VSBL算法相比于没有校准的传统VSBL算法，在信道估计方面表现出持续的改进。

Conclusion: 将自校准嵌入贝叶斯推理可以显著提高信道估计的鲁棒性。

Abstract: Accurate channel estimation is essential for both high-rate communication and
high-precision sensing in 6G wireless systems. However, a major performance
limitation arises from calibration mismatches when operating phased-array
antennas under real-world conditions. To address this issue, we propose to
integrate antenna element self-calibration into a variational sparse Bayesian
learning (VSBL) algorithm for parametric channel estimation. We model antenna
gain and phase deviations as latent variables and derive explicit update
equations to jointly infer these calibration parameters and the channel
parameters: the model order, complex amplitudes, delays, angles, and the noise
variance. The resulting algorithm operates online and adapts in real time to
hardware-induced mismatches. We assess its performance in terms of the root
mean square error (RMSE) and the optimal subpattern-assignment (OSPA) metric,
demonstrating consistent improvements over conventional VSBL without
calibration. Our results demonstrate that embedding self-calibration within
Bayesian inference significantly enhances the robustness of channel estimation.

</details>


### [481] [Leaky Wave Antennas for Next Generation Wireless Applications in sub-THz Frequencies: Current Status and Research Challenges](https://arxiv.org/abs/2510.11666)
*Natalie Lang,Atsutse K. Kludze,Nir Shlezinger,Yasaman Ghasempour,Tirza Routtenberg,George C. Alexandropoulos,Yonina C. Eldar*

Main category: eess.SP

TL;DR: Leaky-wave antennas (LWAs) show promise for sub-THz communications due to their simple structure and frequency-controlled beamsteering. This review highlights their potential for high-rate multi-user communication and accurate localization, while also outlining challenges for future development.


<details>
  <summary>Details</summary>
Motivation: The increasing demand for high data rates, massive connectivity, and integrated communication-sensing in future wireless networks necessitates research into sub-THz communications, which face propagation and hardware challenges. LWAs offer a potential solution beyond traditional antenna arrays.

Method: This article reviews the fundamentals of LWA technology, discusses their unique properties, and presents studies demonstrating their capability in supporting multi-user wideband sub-THz wireless communications and localization with a single antenna element.

Result: Representative studies show that LWAs can simultaneously support high-rate multi-user communications and accurate localization using a single antenna element in sub-THz systems.

Conclusion: LWAs are a promising, cost-effective, and scalable technology for next-generation wireless systems, but several challenges in algorithm design, signal processing, information theory, standardization, and hardware implementation need to be addressed to fully realize their potential.

Abstract: The ever-growing demand for ultra-high data rates, massive connectivity, and
joint communication-sensing capabilities in future wireless networks is driving
research into sub-terahertz (sub-THz) communications. While these frequency
bands offer abundant spectrum, they also pose severe propagation and hardware
design challenges, motivating the search for alternative antenna solutions
beyond conventional antenna arrays. Leaky-wave antennas (LWAs) have emerged as
a promising candidate for sub-THz systems due to their simple feed structure,
low fabrication cost, and inherent angle-frequency coupling, which enables
frequency-controlled beamsteering with simple hardware. In this article, we
review the fundamentals of the LWA technology, highlight their unique
properties, and showcase their potential in multi-user wideband sub-THz
wireless communications. We present representative studies demonstrating that
LWAs can simultaneously support high-rate multi-user communications and
accurate localization using only a single antenna element. Finally, several key
open challenges are outlined, spanning algorithm design, signal processing,
information theory, standardization, and hardware implementation, that need to
be addressed to fully harness LWAs as a cost-effective and scalable enabler of
next generations of wireless systems.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [482] [Sequential Convex Programming for 6-DoF Powered Descent Guidance with Continuous-Time Compound State-Triggered Constraints](https://arxiv.org/abs/2510.09610)
*Samet Uzun,Behcet Acikmese,John M. Carson III*

Main category: eess.SY

TL;DR: 该论文提出了一种顺序凸规划（SCP）框架，用于在动力下降制导（PDG）问题中确保复合状态触发约束（逻辑规范的子集）的连续时间满足。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决在动力下降制导（PDG）问题中，确保复合状态触发约束（逻辑规范的子集）的连续时间满足的挑战。

Method: 该框架结合了基于广义均值的光滑鲁棒性度量（D-GMSR）和连续时间连续凸化（CT-SCvx）方法。D-GMSR 用于将离散时间时间逻辑规范参数化为光滑函数，而 CT-SCvx 是一种实时求解约束轨迹优化问题的方法，可保证连续时间约束满足和收敛。具体实现包括：1）重构以实现连续时间路径约束满足；2）时间膨胀将自由末端时间 PDG 问题转化为固定末端时间问题；3）多重射击实现精确离散化；4）精确惩罚函数用于惩罚非凸约束；5）具有收敛性保证的 SCP 算法——近线性方法，用于求解有限维非凸 PDG 问题。

Result: 通过数值模拟验证了该框架的有效性。

Conclusion: 该研究提出了一种有效的 SCP 框架，用于解决 PDG 问题中的复合状态触发约束的连续时间满足问题。

Abstract: This paper presents a sequential convex programming (SCP) framework for
ensuring the continuous-time satisfaction of compound state-triggered
constraints, a subset of logical specifications, in the powered descent
guidance (PDG) problem. The proposed framework combines the generalized
mean-based smooth robustness measure (D-GMSR), a parameterization technique
tailored for expressing discrete-time temporal and logical specifications
through smooth functions, with the continuous-time successive convexification
(CT-SCvx) method, a real-time solution for constrained trajectory optimization
that guarantees continuous-time constraint satisfaction and convergence. The
smoothness of the temporal and logical specifications parameterized via D-GMSR
enables solving the resulting optimization problem with robust and efficient
SCP algorithms while preserving theoretical guarantees. In addition to their
smoothness, the parameterized specifications are sound and complete, meaning
the specification holds if and only if the constraint defined by the
parameterized function is satisfied. The CT-SCvx framework is then applied to
solve the parameterized problem, incorporating: (1) reformulation for
continuous-time path constraint satisfaction, (2) time-dilation to transform
the free-final-time PDG problem into a fixed-final-time problem, (3) multiple
shooting for exact discretization, (4) exact penalty functions for penalizing
nonconvex constraints, and (5) the prox-linear method, a convergence-guaranteed
SCP algorithm, to solve the resulting finite-dimensional nonconvex PDG problem.
The effectiveness of the framework is demonstrated through a numerical
simulation. The implementation is available at
https://github.com/UW-ACL/CT-cSTC

</details>


### [483] [Designing Control Barrier Functions Using a Dynamic Backup Policy](https://arxiv.org/abs/2510.09810)
*Victor Freire,Marco M. Nicotra*

Main category: eess.SY

TL;DR: 本文提出了一种用于非线性控制仿射系统（具有任意状态和输入约束）的控制屏障函数的构造方法。


<details>
  <summary>Details</summary>
Motivation: 受参考调节器文献的启发，提出了一种参数化方法，用于构造控制屏障函数。

Method: 该方法在增强的状态和参考空间中定义控制屏障函数，并通过敏感性分析计算雅可比矩阵。

Result: 该方法已成功应用于倒立摆小车系统。

Conclusion: 所提出的方法简单通用，可用于构建控制屏障函数。

Abstract: This paper presents a systematic approach to construct control barrier
functions for nonlinear control affine systems subject to arbitrary state and
input constraints. Taking inspiration from the reference governor literature,
the proposed method defines a family of backup policies, parametrized by the
equilibrium manifold of the system. The control barrier function is defined on
the augmented state-and-reference space: given a state-reference pair, the
approach quantifies the distance to constraint violation at any time in the
future, should the current backup policy reference remain constant. Sensitivity
analysis is then used to compute the (possibly nonsmooth) Jacobian with respect
to the augmented state vector. To showcase its simple yet general nature, the
proposed method is applied to an inverted pendulum on cart.

</details>


### [484] [Latent-Feature-Informed Neural ODE Modeling for Lightweight Stability Evaluation of Black-box Grid-Tied Inverters](https://arxiv.org/abs/2510.09826)
*Jialin Zheng,Zhong Liu,Xiaonan Lu*

Main category: eess.SY

TL;DR: 该研究提出了一种名为LFI-NODE的新型建模方法，用于对并网逆变器进行轻量化的稳定性评估。


<details>
  <summary>Details</summary>
Motivation: 传统逆变器稳定性评估方法需要大量数据且受限于专有内部信息，本研究旨在解决此问题。

Method: LFI-NODE通过一个连续时间神经网络来参数化整个系统的常微分方程（ODE），并利用从轨迹数据中提取的潜在扰动特征来指导学习过程，同时揭示了小型信号特征值结构。

Result: 与传统方法相比，LFI-NODE仅需传统方法的百分之一到千分之一的训练样本，并且能以很小的误差（轨迹预测误差在百分之一量级，特征值估计误差在十分之一量级）实现高保真度的稳定性评估。

Conclusion: LFI-NODE是一种实用且轻量化的方法，可用于对复杂的黑盒电力电子系统进行高保真度的稳定性评估。

Abstract: Stability evaluation of black-box grid-tied inverters is vital for grid
reliability, yet identification techniques are both data-hungry and blocked by
proprietary internals. {To solve this, this letter proposes a
latent-feature-informed neural ordinary differential equation (LFI-NODE)
modeling method that can achieve lightweight stability evaluation directly from
trajectory data.} LFI-NODE parameterizes the entire system ODE with a single
continuous-time neural network, allowing each new sample to refine a unified
global model. It faithfully captures nonlinear large-signal dynamics to
preserve uniform predictive accuracy as the inverter transitions between
operating points. Meanwhile, latent perturbation features distilled from every
trajectory steer the learning process and concurrently reveal the small-signal
eigenstructure essential for rigorous stability analysis. Validated on a
grid-forming inverter, {The LFI-NODE requires one to two orders of magnitude
fewer training samples compared with traditional methods, collected from short
time-domain trajectories instead of extensive frequency-domain measurements.}
{Furthermore, the LFI-NODE requires only 48 short transients to achieve a
trajectory prediction error at the hundredth level and an eigenvalue estimation
error at the tenth level, outperforming benchmark methods by one to two orders
of magnitude.} This makes LFI-NODE a practical and lightweight approach for
achieving high-fidelity stability assessment of complex black-box
power-electronic systems.

</details>


### [485] [Cyber-Physical Systems on the Megawatt Scale: The impact of battery control on grid frequency stability](https://arxiv.org/abs/2510.09862)
*Carsten Hartmann,Edoardo De Din,Daniele Carta,Florian Middelkoop,Arndt Neubauer,Johannes Kruse,Ulrich Oberhofer,Richard Jumar,Benjamin Schäfer,Thiemo Pesch,Andrea Benigni,Dirk Witthaut*

Main category: eess.SY

TL;DR: 全球电网频率出现持续一分钟的振荡模式，源于电池储能系统的能量管理系统，并可能对未来低惯量电网的稳定性构成威胁。


<details>
  <summary>Details</summary>
Motivation: 文章旨在识别和解释电网频率中的新兴风险，特别关注网络物理耦合和控制系统设计。

Method: 通过分析全球电网频率时间序列数据，追溯一分钟振荡模式的起源，并识别其与电池储能系统能量管理系统的联系，同时评估该模式在特定电网中的增长趋势。

Result: 发现在全球电网频率时间序列中存在持续一分钟的振荡模式，并已追溯到电池储能系统的能量管理系统，该模式在北欧和英国电网中的幅度显著增加。

Conclusion: 文章认为，该振荡模式对未来低惯量和高电池渗透率的电网稳定性可能构成负担，但可以通过修改电池控制算法来缓解。

Abstract: Electric power systems are undergoing fundamental change. The shift to
inverter-based generation challenges frequency stability, while growing
digitalisation heightens vulnerability to errors and attacks. Here we identify
an emerging risk at the intersection of cyber-physical coupling and control
system design. We show that grid frequency time series worldwide exhibit a
persistent one-minute oscillatory pattern, whose origin has remained largely
unexplained. We trace this pattern back to the energy management systems of
battery electric storage systems and demonstrate that the pattern amplitude has
increased substantially in the Nordic and British grids. We argue that this
effect is a potential burden for stability in future grids with low inertia and
an increasing penetration with batteries and smart devices, though it can be
mitigated by a revision of battery control algorithms.

</details>


### [486] [Computing Safe Control Inputs using Discrete-Time Matrix Control Barrier Functions via Convex Optimization](https://arxiv.org/abs/2510.09925)
*James Usevitch,Juan Augusto Paredes Salazar,Ankit Goel*

Main category: eess.SY

TL;DR: 本研究提出一种利用凸优化和矩阵控制障碍函数技术，为具有非凸安全集的离散时间系统计算安全保持控制输入的新方法，解决了现有方法中非凸控制障碍函数导致的非凸优化问题，提高了实时计算效率。在双旋翼飞行器系统上进行了数值模拟验证。


<details>
  <summary>Details</summary>
Motivation: 现有离散时间控制障碍函数（CBFs）在处理非凹安全集时，需要求解非凸优化问题来计算安全控制输入，这阻碍了实时计算的效率。

Method: 利用凸优化和新提出的矩阵控制障碍函数技术，为离散时间系统设计安全保持控制输入的方法。

Result: 通过在双旋翼飞行器系统上的数值模拟，验证了所提出方法的有效性。

Conclusion: 所提出的新方法能够利用凸优化和矩阵控制障碍函数技术，有效地为离散时间系统计算安全保持控制输入，解决了现有方法的局限性。

Abstract: Control barrier functions (CBFs) have seen widespread success in providing
forward invariance and safety guarantees for dynamical control systems. A
crucial limitation of discrete-time formulations is that CBFs that are
nonconcave in their argument require the solution of nonconvex optimization
problems to compute safety-preserving control inputs, which inhibits real-time
computation of control inputs guaranteeing forward invariance. This paper
presents a novel method for computing safety-preserving control inputs for
discrete-time systems with nonconvex safety sets, utilizing convex optimization
and the recently developed class of matrix control barrier function techniques.
The efficacy of our methods is demonstrated through numerical simulations on a
bicopter system.

</details>


### [487] [Viscosity CBFs: Bridging the Control Barrier Function and Hamilton-Jacobi Reachability Frameworks in Safe Control Theory](https://arxiv.org/abs/2510.09929)
*Dylan Hirsch,Jaime Fernández Fisac,Sylvia Herbert*

Main category: eess.SY

TL;DR: 本文将粘性CBF与CB-VF联系起来，弥合了CBF和HJR框架的差距，并展示了粘性CBF的理论性质。


<details>
  <summary>Details</summary>
Motivation: 弥合控制障碍函数（CBF）和汉密尔顿-雅可比可达性（HJR）框架之间的差距，并研究了粘性CBF的性质。

Method: 将CBF推广到非微分的“粘性”CBF，并展示了粘性CBF与CB-VF之间的联系。

Result: 证明了粘性CBF在控制不变性和平滑逼近边界方面的安全性保证，并展示了它们在最大值和极限运算下的闭包性质。此外，还扩展了CB-VF的非指数反折扣，并更新了相关的理论。

Conclusion: 粘性CBF为CBF和HJR框架之间提供了一个有力的桥梁，具有良好的理论性质，并为安全控制的设计和分析提供了新的见解。

Abstract: Control barrier functions (CBFs) and Hamilton-Jacobi reachability (HJR) are
central frameworks in safe control. Traditionally, these frameworks have been
viewed as distinct, with the former focusing on optimally safe controller
design and the latter providing sufficient conditions for safety. A previous
work introduced the notion of a control barrier value function (CB-VF), which
is defined similarly to the other value functions studied in HJR but has
certain CBF-like properties. In this work, we proceed the other direction by
generalizing CBFs to non-differentiable ``viscosity'' CBFs. We show the deep
connection between viscosity CBFs and CB-VFs, bridging the CBF and HJR
frameworks. Through this bridge, we characterize the viscosity CBFs as
precisely those functions which provide CBF-like safety guarantees (control
invariance and smooth approach to the boundary). We then further show nice
theoretical properties of viscosity CBFs, including their desirable closure
under maximum and limit operations. In the process, we also extend CB-VFs to
non-exponential anti-discounting and update the corresponding theory for CB-VFs
along these lines.

</details>


### [488] [Modeling the Impact of Communication and Human Uncertainties on Runway Capacity in Terminal Airspace](https://arxiv.org/abs/2510.09943)
*Yutian Pang,Andrew Kendall,John-Paul Clarke*

Main category: eess.SY

TL;DR: 该研究评估了通信和人为因素的不确定性对跑道运行的影响，并提出了一种新的跑道容量估算方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估通信和人为因素的不确定性对跑道运行的影响，特别是在飞机到达场景中。

Method: 通过蒙特卡洛离散时间模拟和一种基于逆最优控制的自动化最终进近向量模型（Auto-ATC）来模拟和分析跑道运行。

Result: 研究结果表明，通信链路的不确定性显著影响当前基于语音运行的跑道容量，而在自主运行环境中，这种影响可以得到缓解。

Conclusion: 该研究提供了一种在合并场景中估算跑道容量的方法，并强调了在未来航空运行中减少通信和人为因素不确定性的重要性。

Abstract: We investigate the potential impact of communication and human performance
uncertainties on runway operations. Specifically, we consider these impacts
within the context of an arrival scenario with two converging flows: a
straight-in approach stream and a downwind stream merging into it. Both arrival
stream are modeled using a modified Possion distribution that incorporate the
separation minima as well as the runway occupancy time. Various system level
uncertainties are addressed in this process, including communication link- and
human-related uncertainties. In this research, we first build a Monte
Carlo-based discrete-time simulation, where aircraft arrivals are generated by
modified Poisson processes subject to minimum separation constraints,
simulating various traffic operations. The merging logic incorporates standard
bank angle continuous turn-to-final, pilot response delays, and dynamic gap
availability in real time. Then, we investigate an automated final approach
vectoring model (i.e., Auto-ATC), in which inverse optimal control is used to
learn decision advisories from human expert records. By augmenting trajectories
and incorporating the aforementioned uncertainties into the planning scenario,
we create a setup analogous to the discrete event simulation. For both studies,
runway capacity is measured by runway throughput, the fraction of downwind
arrivals that merge immediately without holding, and the average delay (i.e.,
holding time/distance) experienced on the downwind leg. This research provides
a method for runway capacity estimation in merging scenarios, and demonstrates
that aeronautical communication link uncertainties significantly affect runway
capacity in current voice-based operations, whereas the impact can be mitigated
in autonomous operational settings.

</details>


### [489] [Performance Index Shaping for Closed-loop Optimal Control](https://arxiv.org/abs/2510.10202)
*Ayush Rai,Shaoshuai Mou,Brian D. O. Anderson*

Main category: eess.SY

TL;DR: 该研究提出了一种新的分析框架，用于将性能指标（成本/奖励塑造）与闭环最优控制律联系起来，解决了反向优化问题，并提供了对系统行为和稳定性的见解。


<details>
  <summary>Details</summary>
Motivation: 在最优控制和强化学习中，性能指标的设计至关重要，因为它直接影响控制律的行为、权衡和目标。以往基于可微分轨迹优化方法在计算上成本高昂，需要反复求解最优控制问题。

Method: 提出了一种新的分析框架，在已知动力学假设下，将性能指标与闭环最优控制律解析地联系起来。将通常的双层反问题转化为单层问题。推导了适用于广泛系统和性能指标的闭式解，支持解释、稳定性分析以及对非线性闭环系统的鲁棒稳定性和输入状态稳定性行为的洞察。

Result: 得出了适用于广泛系统和性能指标的闭式解。研究结果不仅便于解释和稳定性分析，还提供了对所得到的非线性闭环系统的鲁棒稳定性和输入状态稳定性行为的见解。

Conclusion: 该分析框架提供了一种统一的方法来塑造性能指标，以实现特定的设计目标并相应地设计最优控制律。它通过将反向问题转化为更易于处理的单层公式，从而在计算上比以前的方法更有效。

Abstract: The design of the performance index, also referred to as cost or reward
shaping, is central to both optimal control and reinforcement learning, as it
directly determines the behaviors, trade-offs, and objectives that the
resulting control laws seek to achieve. A commonly used approach for this
inference task in recent years is differentiable trajectory optimization, which
allows gradients to be computed with respect to cost parameters by
differentiating through an optimal control solver. However, this method often
requires repeated solving of the underlying optimal control problem at every
iteration, making the method computationally expensive. In this work, assuming
known dynamics, we propose a novel framework that analytically links the
performance index to the resulting closed-loop optimal control law, thereby
transforming a typically bi-level inverse problem into a tractable single-level
formulation. Our approach is motivated by the question: given a closed-loop
control law that solves an infinite-horizon optimal control problem, how does
this law change when the performance index is modified with additional terms?
This formulation yields closed-form characterizations for broad classes of
systems and performance indices, which not only facilitate interpretation and
stability analysis, but also provide insight into the robust stability and
input-to-state stable behavior of the resulting nonlinear closed-loop system.
Moreover, this analytical perspective enables the generalization of our
approach to diverse design objectives, yielding a unifying framework for
performance index shaping. Given specific design objectives, we propose a
systematic methodology to guide the shaping of the performance index and
thereby design the resulting optimal control law.

</details>


### [490] [Bounds of Validity for Bifurcations of Equilibria in a Class of Networked Dynamical Systems](https://arxiv.org/abs/2510.10215)
*Pranav Gupta,Ravi Banavar,Anastasia Bizyaeva*

Main category: eess.SY

TL;DR: 本研究为连续时间网络动力学系统中的两种模型（Hopfield和Firing Rate神经网络模型）的 bifurcation diagram 分类建立了明确的有效界限。


<details>
  <summary>Details</summary>
Motivation: 为了理解网络非线性动力学系统（包括动态神经网络和意见动力学模型）中的定性转变，局部分岔分析起着至关重要的作用。然而，需要对这些模型的简化分析进行严格的界定，以确保其预测的可靠性。

Method: 利用最近在计算Lyapunov-Schmidt降阶方法有效界限方面的进展，该方法广泛用于非线性系统分析。在此基础上，严格界定了分岔点周围的邻域，在这些邻域中，降阶模型的预测仍然是可靠的。

Result: 我们为Hopfield和Firing Rate神经网络模型提供了分岔图分类的显式有效界限。这些界限量化了网络动力学中分岔现象的鲁棒性，并展示了如何在k-正则图上的意见动力学模型中应用这些界限。

Conclusion: 本研究为网络动力学中的分岔分析提供了新的分析工具，强调了网络结构与非线性动力学行为之间的相互作用，并为理解和预测复杂网络的行为提供了理论基础。

Abstract: Local bifurcation analysis plays a central role in understanding qualitative
transitions in networked nonlinear dynamical systems, including dynamic neural
network and opinion dynamics models. In this article we establish explicit
bounds of validity for the classification of bifurcation diagrams in two
classes of continuous-time networked dynamical systems, analogous in structure
to the Hopfield and the Firing Rate dynamic neural network models. Our approach
leverages recent advances in computing the bounds for the validity of
Lyapunov-Schmidt reduction, a reduction method widely employed in nonlinear
systems analysis. Using these bounds we rigorously characterize neighborhoods
around bifurcation points where predictions from reduced-order models remain
reliable. We further demonstrate how these bounds can be applied to an
illustrative family of nonlinear opinion dynamics on k-regular graphs, which
emerges as a special case of the general framework. These results provide new
analytical tools for quantifying the robustness of bifurcation phenomena in
dynamics over networked systems and highlight the interplay between network
structure and nonlinear dynamical behavior.

</details>


### [491] [Optimal monophasic, asymmetric electric field pulses for selective transcranial magnetic stimulation (TMS) with minimised power and coil heating](https://arxiv.org/abs/2510.10289)
*Ke Ma,Andrey Vlasov,Zeynep B. Simsek,Jinshui Zhang,Yiru Li,Boshuo Wang,David L. K. Murphy,Jessica Y. Choi,Maya E. Clinton,Noreen Bukhari-Parlakturk,Angel V. Peterchev,Stephan M. Goetz*

Main category: eess.SY

TL;DR: 通过优化脉冲波形，实现了高能量效率和神经选择性的非对称脉冲，可用于更精确和有效的神经调质。


<details>
  <summary>Details</summary>
Motivation: 之前的脉冲形状优化受限于对称脉冲或常规波形，未能实现能量效率和神经选择性的普遍最优。当前的非对称脉冲（如单相脉冲）虽然具有方向选择性，但需要过高的能量。

Method: 实现了一个包含神经元模型激活约束和脉冲非对称性灵活控制的优化框架，以寻找能量效率高且具有方向选择性的脉冲。

Result: 优化后的脉冲波形相比常规单相脉冲和先前改进的单相等效脉冲，能量损失和线圈发热分别降低了高达 92% 和 88%。人体实验表明，优化脉冲在 AP 和 PA 方向上与单相脉冲具有相似的运动阈值，同时能量损失显著降低，尤其是在 AP 方向。此外，优化脉冲在 AP 和 PA 方向上的 MEP 潜伏期存在显著差异（1.79 +/- 0.41 ms），表明其具有方向选择性。

Conclusion: 该优化框架成功识别出能量高效且具有方向选择性的非对称脉冲，可用于低功耗、低线圈发热的选择性快速重复经颅磁刺激方案，有望提高神经调质的精确性和效力。

Abstract: Transcranial magnetic stimulation (TMS) with asymmetric electric field
pulses, such as monophasic, offers directional selectivity for neural
activation but requires excessive energy. Previous pulse shape optimisation has
been limited to symmetric pulses or heavily constrained variations of
conventional waveforms without achieving general optimality in energy
efficiency or neural selectivity. We implemented an optimisation framework that
incorporates neuron model activation constraints and flexible control of pulse
asymmetry. The optimised electric field waveforms achieved up to 92 % and 88 %
reduction in energy loss and thus coil heating respectively compared to
conventional monophasic pulses and previously improved monophasic-equivalent
pulses. In the human experiments, OUR pulses showed similar motor thresholds to
monophasic pulses in both AP and PA directions with significantly lower energy
loss, particularly in the AP direction. Moreover, there was a significant MEP
latency difference of (1.79 +/- 0.41) ms between AP and PA direction with OUR
pulses, which suggests directional selectivity. Our framework successfully
identified highly energy-efficient asymmetric pulses for
directionally-selective neural engagement. These pulses can enable selective
rapid-rate repetitive TMS protocols with reduced power consumption and coil
heating, with potential benefits for precision and potency of neuro-modulation.

</details>


### [492] [Low-cost Pyranometer-Based ANN Approach for MPPT in Solar PV Systems](https://arxiv.org/abs/2510.10313)
*Luiz Fernando M. Arruda,Moises Ferber,Diego Greff*

Main category: eess.SY

TL;DR: 本文提出了一种基于人工神经网络（ANN）和低成本辐射传感器的光伏（PV）系统最大功率点跟踪（MPPT）方法。


<details>
  <summary>Details</summary>
Motivation: 为了在光伏系统中实现高效的最大功率点跟踪（MPPT），并利用低成本传感器。

Method: 将辐射传感器、温度传感器和人工神经网络（ANN）相结合，用于估算DC/DC转换器的占空比，以实现MPPT。该策略被集成到Cuk转换器的本地控制中，并通过实验与传统的摄动和观察（P&O）方法进行了比较。

Result: 基于ANN的方法能够准确地进行MPPT，并且与P&O方法相比，波动性更小。使用经济实惠的传感器技术，可以实现精确的MPPT性能。

Conclusion: 基于ANN的方法，利用低成本传感器技术，可以精确地进行MPPT，并提高光伏跟踪系统的响应速度和效率。

Abstract: This article presents a study on the application of artificial neural
networks (ANNs) for maximum power point tracking (MPPT) in photovoltaic (PV)
systems using low-cost pyranometer sensors. The proposed approach integrates
pyranometers, temperature sensors, and an ANN to estimate the duty cycle of a
DC/DC converter, enabling the system to consistently operate at its maximum
power point. The strategy was implemented in the local control of a Cuk
converter and experimentally validated against the conventional Perturb and
Observe (P&O) method. Results demonstrate that the ANN-based technique,
leveraging affordable sensor technology, achieves accurate MPPT performance
with reduced fluctuations, enhancing the responsiveness and efficiency of PV
tracking systems.

</details>


### [493] [Discovering interpretable piecewise nonlinear model predictive control laws via symbolic decision trees](https://arxiv.org/abs/2510.10411)
*Ilias Mitrai*

Main category: eess.SY

TL;DR: 该研究提出使用符号决策树来近似模型预测控制律，能够学习输入域划分和局部非线性表达式，以获得可解释的分段非线性控制律。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的方法来学习可解释的模型预测控制律。

Method: 使用符号决策树作为代理模型来近似模型预测控制律。该方法同时学习输入域的划分（分裂逻辑）和用于预测控制动作的局部非线性表达式。局部非线性表达式使用一组基函数进行建模。学习任务被表述为混合整数优化问题，并使用先进的全局优化求解器求解。

Result: 将该方法应用于等温反应器的控制案例研究。结果表明，该方法能够准确学习控制律，并且闭环性能与标准的模型预测控制器相当。与现有的可解释模型相比，符号决策树具有更低的预测误差和更优越的闭环性能。

Conclusion: 所提出的符号决策树方法能够准确地学习控制律，提供可解释的分段非线性控制律，并具有与标准模型预测控制器相当的闭环性能，优于现有的可解释模型。

Abstract: In this paper, we propose symbolic decision trees as surrogate models for
approximating model predictive control laws. The proposed approach learns
simultaneously the partition of the input domain (splitting logic) as well as
local nonlinear expressions for predicting the control action leading to
interpretable piecewise nonlinear control laws. The local nonlinear expressions
are determined by the learning problem and are modeled using a set of basis
functions. The learning task is posed as a mixed integer optimization, which is
solved to global optimality with state-of-the-art global optimization solvers.
We apply the proposed approach to a case study regarding the control of an
isothermal reactor. The results show that the proposed approach can learn the
control law accurately, leading to closed-loop performance comparable to that
of a standard model predictive controller. Finally, comparison with existing
interpretable models shows that the symbolic trees achieve both lower
prediction error and superior closed-loop performance.

</details>


### [494] [Risk-Budgeted Control Framework for Balanced Performance and Safety in Autonomous Vehicles](https://arxiv.org/abs/2510.10442)
*Pei Yu Chang,Vishnu Renganathan,Qadeer Ahmed*

Main category: eess.SY

TL;DR: 该论文提出了一种风险预算监控器和控制框架，用于自动驾驶的安全认证。该框架使用滑窗监控障碍物剩余风险，并在安全裕度不足时，从基于性能的松弛控制障碍函数（R-CBF）切换到基于条件在险值（CVaR-CBF）的保守约束，以确保安全。切换由可行性触发（FT）和质量触发（QT）两个条件控制。


<details>
  <summary>Details</summary>
Motivation: 为自动驾驶系统提供安全认证，特别是在存在不确定性（如定位噪声和障碍物位置不确定性）的情况下，并通过在安全性和性能之间取得平衡来提高鲁棒性。

Method: 提出了一种风险预算监控器，结合了两种控制障碍函数（R-CBF 和 CVaR-CBF）的切换机制，由可行性触发（FT）和质量触发（QT）条件控制。该方法在一个模型预测控制器（MPC）框架下进行了评估。

Result: 在最具挑战性的场景（行人检测不确定性为 5 米）下，该框架在 300 次试验中实现了 94-96% 的行人碰撞成功率，同时保持了最低的平均交叉轨迹误差（CTE = 3.2-3.6 米），表明在避障后能更快地恢复轨迹。

Conclusion: 所提出的风险预算监控器和控制框架能够有效地确保自动驾驶系统的安全性，并在面对不确定性和干扰时，在安全性和性能之间取得良好的平衡。

Abstract: This paper presents a risk-budgeted monitor with a control framework that
certifies safety for autonomous driving. In this process, a sliding window is
proposed to monitor for insufficient barrier residuals or nonzero tail risk,
ensuring system safety. When the safety margin deteriorates, it triggers
switching the safety constraint from a performance-based relaxed-control
barrier function (R-CBF) to a conservative conditional value at risk (CVaR-CBF)
to address the safety concern. This switching is governed by two real-time
triggers: Feasibility-Triggered (FT) and Quality-Triggered (QT) conditions. In
the FT condition, if the R-CBF constraint becomes infeasible or yields a
suboptimal solution, the risk monitor triggers the use of the CVaR constraints
for the controller. In the QT condition, the risk monitor observes the safety
margin of the R-CBF solution at every step, regardless of feasibility. If it
falls below the safety margin, the safety filter switches to the CVaR-CBF
constraints.
  The proposed framework is evaluated using a model predictive controller (MPC)
for autonomous driving in the presence of autonomous vehicle (AV) localization
noise and obstacle position uncertainties. Multiple AV-pedestrian interaction
scenarios are considered, with 1,500 Monte Carlo runs conducted for all
scenarios. In the most challenging setting with pedestrian detection
uncertainty of 5 m, the proposed framework achieves a 94-96% success rate of
not colliding with the pedestrians over 300 trials while maintaining the lowest
mean cross-track error (CTE = 3.2-3.6 m) to the reference path. The reduced CTE
indicates faster trajectory recovery after obstacle avoidance, demonstrating a
balance between safety and performance.

</details>


### [495] [Controller for Incremental Input-to-State Practical Stabilization of Partially Unknown systems with Invariance Guarantees](https://arxiv.org/abs/2510.10450)
*P Sangeerth,David Smith Sundarsingh,Bhabani Shankar Dey,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 本文提出了一种名为增量输入状态实际稳定性（δ-ISpS）的稳定性概念，以确保安全，并提出了一种基于反馈线性化的控制设计方案，该方案能够为部分未知的系统提供增量输入状态实际稳定性（δ-ISpS）和安全保证。通过使用高斯过程回归来近似模型以处理未知动力学，并最终在一个机械臂示例上实现了所提出的控制方案。


<details>
  <summary>Details</summary>
Motivation: 增量稳定性确保了轨迹之间的收敛性，而本文提出的增量输入状态实际稳定性（δ-ISpS）概念则进一步关注安全保证。

Method: 本文提出了一种基于反馈线性化的控制设计方案，并利用高斯过程回归来近似处理未知动力学。

Result: 所提出的控制方案在机械臂示例的实现中得到了验证。

Conclusion: 本文提出了一种新的稳定性概念（δ-ISpS）和一种控制设计方案，为部分未知的系统提供了增量输入状态实际稳定性（δ-ISpS）和安全保证。

Abstract: Incremental stability is a property of dynamical systems that ensures the
convergence of trajectories with respect to each other rather than a fixed
equilibrium point or a fixed trajectory. In this paper, we introduce a related
stability notion called incremental input-to-state practical stability
({\delta}-ISpS), ensuring safety guarantees. We also present a feedback
linearization based control design scheme that renders a partially unknown
system incrementally input-to-state practically stable and safe with formal
guarantees. To deal with the unknown dynamics, we utilize Gaussian process
regression to approximate the model. Finally, we implement the controller
synthesized by the proposed scheme on a manipulator example

</details>


### [496] [Transforming Tarlac State University (TSU) Gymnasium to a Nearly Zero-Energy Building through Integration of a Solar Photovoltaic (PV) System](https://arxiv.org/abs/2510.10552)
*Rafael R. Yumul,Enalyn T. Domingo*

Main category: eess.SY

TL;DR: 该研究将 Tarlac 州立大学体育馆改造成一个拥有节能设备、整合了太阳能光伏系统作为可再生能源的近零能耗建筑 (NZEB)，以减少碳足迹。


<details>
  <summary>Details</summary>
Motivation: 将 Tarlac 州立大学体育馆改造成近零能耗建筑 (NZEB)，整合太阳能光伏系统以提高能源效率并减少碳足迹。

Method: 评估 Tarlac 州立大学体育馆的现有电气基础设施、照明、冷却设备和电源插座，并分析整合太阳能光伏系统的成本效益和投资回收期。

Result: Tarlac 州立大学体育馆的电气基础设施过时，照明和冷却设备效率低下，电源插座不足。太阳能光伏系统的投资回收期在平均范围内，具有成本效益。然而，升级到 LED 照明、增加空调和电源插座会产生额外成本。

Conclusion: 该项目具有成本效益，但需要考虑额外的升级成本和屋顶系统的完整性。应计算整个电气系统的总成本，以确定 NZEB 项目的总成本。

Abstract: The study is anchored to the principles of Nearly-Zero Energy Building
(NZEB). It aimed to transform the Tarlac State University Gymnasium into a
facility with energy-efficient equipment to contribute to reducing carbon
footprints by integrating a solar PV system as its renewable energy source. The
researchers found out that the electrical infrastructure of the Gym was
outdated, and the lighting was not energy efficient, and there were too few
convenience or power outlets. There was also insufficient cooling equipment to
maintain a comfortable temperature. Analysis shows that the payback period is
within the average range, making it a cost-effective investment for the
University. Aside from the cost of the PV System, adherence to engineering
design standards will mean additional costs to replace the metal halides with
LED high bay lamps, installation of additional air conditioning units, and
provision of additional convenience outlets. These additional costs should be
considered when evaluating the feasibility of the project. It is recommended
that the integrity of the existing roof system of the Gymnasium be considered.
The total cost of putting up the whole electrical system, including new
lighting, cooling, and convenience loads, must be calculated to determine the
total cost of implementing the whole NZEB project. Other factors in the
economic evaluation may be considered to determine a more stringent result.

</details>


### [497] [Aggregate Modeling of Air-Conditioner Loads Under Packet-based Control with Both On and Off Grid Access Requests](https://arxiv.org/abs/2510.10651)
*Mohammad Hassan,Mads R. Almassalkhi*

Main category: eess.SY

TL;DR: 通过使用新的聚合仓模型（宏模型）来协调分布式能源（DER），该模型考虑了开关机请求和可变数据包长度，以提高电网可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有分布式能源（DER）协调方法（如分组能源管理，PEM）在处理可变数据包长度和开关机请求方面存在局限性，阻碍了对聚合DER能力的系统分析。

Method: 提出一种新的聚合仓（宏）模型，用于模拟PEM下的DER，该模型能够处理开关机请求和可变数据包长度，并能准确表征DER群体跟踪功率参考信号、群体温度动态、聚合请求速率和可变数据包长度的能力。通过与基于代理（微）的模型进行仿真比较来验证模型的准确性和鲁棒性。

Result: 仿真结果表明，该宏模型能够准确地表征DER群体的行为，并量化其能力。此外，仿真得到的变长数据包长度分布可用于改进先前关于具有随机数据包长度的PEM的研究。

Conclusion: 新提出的聚合仓（宏）模型能够有效地模拟具有开关机请求和可变数据包长度的DER群体，为系统分析提供了更准确的工具，并能改进对PEM的研究。

Abstract: Coordination of distributed energy resources (DERs) can engender flexibility
necessary to improve grid reliability. Packetized Energy Management (PEM) is a
method for coordinating DERs, such as thermostatically controlled loads (TCLs)
and electric vehicles, within customer quality-of-service (QoS) limits. In PEM,
a DER uses local information to offer flexibility by sending a request to the
DER coordinator to turn-ON or turn-OFF. Much work has focused on modeling and
analyzing aggregations of DERs under PEM with fixed packet durations and only
turn-ON requests. Different recent efforts to enable variable packet lengths
have shown an increase in available flexibility and ramping capability, but
have not been modeled in aggregate, which limits systematic analyses. To
address this issue, this paper presents a new aggregate bin-based (macro) model
of PEM loads that incorporates both turn-ON and turn-OFF request features,
enabling the model to accurately characterize the capability of the fleet of
DERs to track a power reference signal, population temperature dynamics,
aggregate request rates, and variable packet lengths. Simulation-based
validation is performed against an agent-based (micro) model to evaluate
robustness and quantify model accuracy. Finally, the distribution of variable
packet lengths from macro-model simulations are applied to inform past work on
PEM with randomized packet lengths

</details>


### [498] [Structured identification of multivariable modal systems](https://arxiv.org/abs/2510.10820)
*Maarten van der Hulst,Rodrigo A. González,Koen Classens,Paul Tacx,Nick Dirkx,Jeroen van de Wijdeven,Tom Oomen*

Main category: eess.SY

TL;DR: 提出了一种从频响数据中估计复杂多变量机械系统模态模型的方法。


<details>
  <summary>Details</summary>
Motivation: 开发物理可解释模型对于下一代工业系统至关重要，因为这些模型能够实现有效的控制、支持设计验证并为监控策略奠定基础。

Method: 提出了一种两步结构化辨识算法，首先使用改进的工具变量法估计加性模型，然后将其投影到模态形式。

Result: 所提出的辨识方法能够为具有一般阻尼和比例阻尼的模态系统提供精确、物理相关且阶数最小的模型。

Conclusion: 通过对具有大量空间分布式执行器和传感器以及复杂柔性动力学的原型晶圆台系统的实验验证，证明了所提出方法的有效性。

Abstract: Physically interpretable models are essential for next-generation industrial
systems, as these representations enable effective control, support design
validation, and provide a foundation for monitoring strategies. The aim of this
paper is to develop a system identification framework for estimating modal
models of complex multivariable mechanical systems from frequency response
data. To achieve this, a two-step structured identification algorithm is
presented, where an additive model is first estimated using a refined
instrumental variable method and subsequently projected onto a modal form. The
developed identification method provides accurate, physically-relevant,
minimal-order models, for both generally-damped and proportionally damped modal
systems. The effectiveness of the proposed method is demonstrated through
experimental validation on a prototype wafer-stage system, which features a
large number of spatially distributed actuators and sensors and exhibits
complex flexible dynamics.

</details>


### [499] [Observability and parameter estimation of a generic model for aggregated distributed energy resources](https://arxiv.org/abs/2510.10892)
*Bukunmi Gabriel Odunlami,Marcos Netto*

Main category: eess.SY

TL;DR: 本研究提出了一种新的框架，用于估计聚合分布式能源（DER_a）模型的参数，该框架能确定参数的可估计性，识别可估计的参数子集，并利用卡尔曼滤波方法进行模型校准，考虑了非线性效应，并在IEEE 34节点测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于对聚合分布式能源（DER_a）模型参数进行准确估计和校准，以应对其在配电系统中日益增长的重要性以及现有模型校准方法的局限性。

Method: 研究首先提出了一种严格的方法来确定模型参数的可估计性，并在参数不可估计时识别出可估计的参数子集。然后，引入了一种改进的卡尔曼滤波方法（包括扩展和无迹卡尔曼滤波）来校准DER_a模型，并特别设计了处理平滑函数以适应饱和和死区等非线性效应的机制。

Result: 研究结果表明，所提出的框架能够根据常用测量值可靠地估计参数，并揭示了模型校准的局限性。在修改后的IEEE 34节点配电馈线上的仿真结果证明了该方法的有效性，并与北美电力可靠性公司的参数化指南一致。

Conclusion: 本研究提出的框架对于准确捕获配电系统中分布式能源的集体动态至关重要，强调了模型校准在理解和管理这些资源方面的关键作用。

Abstract: We propose a novel framework for estimating the parameters of an aggregated
distributed energy resources (der_a) model. First, we introduce a rigorous
method to determine whether all model parameters are estimable. When they are
not, our approach identifies the subset of parameters that can be estimated.
The proposed framework offers new insights into the number and specific
parameters that can be reliably estimated based on commonly available
measurements. It also highlights the limitations of calibrating such models.
Second, we introduce a Kalman filtering method to calibrate the der_a model.
Since we account for nonlinear effects such as saturation and deadbands, we
develop a specific mechanism to handle smoothing functions within the Kalman
filter. Specifically, we consider the extended and the unscented Kalman filter.
We demonstrate the effectiveness of the proposed framework on a modified IEEE
34-node distribution feeder with inverter-based resources. Our findings align
with the North American Electric Reliability Corporation's parameterization
guideline and underscore the importance of model calibration in accurately
capturing the collective dynamics of distributed energy resources installed on
distribution systems.

</details>


### [500] [Optimal Multi-Modal Transportation and Electric Power Flow: The Value of Coordinated Dynamic Operation](https://arxiv.org/abs/2510.10914)
*Jiajie Qiu,Dakota Thompson,Kamal Youcef-Toumi,Amro M. Farid*

Main category: eess.SY

TL;DR: 交通运输电气化是迈向净零排放的关键挑战，需要电动汽车（EV）的广泛采用及其与交通-电力关联（TEN）的无缝集成。本研究提出了一个最优多式联运和电力流（OMTEPF）模型，利用异构图论，对车辆调度、路线选择、充电站排队、协调充电和车辆到电网稳定等五个关键运营决策进行联合优化。该模型显式表示了单个电动汽车及其充电状态轨迹，并纳入了五种不同的充电模式，同时通过IV-ACOPF保证了电力子问题的全局最优解。


<details>
  <summary>Details</summary>
Motivation: 交通运输电气化是实现净零排放目标的关键，而交通-电力关联（TEN）的协同管理对于实现这一目标至关重要，但现有研究未能充分解决这一系统性问题。

Method: 提出一个最优多式联运和电力流（OMTEPF）模型，该模型基于异构图论，能够联合优化车辆调度、路线选择、充电站排队、协调充电和车辆到电网稳定这五个关键决策。模型中显式考虑了单个电动汽车及其充电状态，并包含了五种不同的充电模式，同时使用IV-ACOPF确保电力子问题的最优解。

Result: 与孤立、未协调的基础设施管理相比，协调的TEN运营模式具有显著的优势，证明了其在可持续交通和能源系统协同设计与运营方面的价值。

Conclusion: 本研究提出的OMTEPF模型在方法论上具有创新性，并为下一代可持续交通-能源系统的协同设计和运营提供了可行的见解。

Abstract: The electrification of transportation represents a critical challenge in the
global transition toward net-zero emissions, as the sector often accounts for
more than one-quarter of national energy consumption. Achieving this
transformation requires not only widespread adoption of electric vehicles (EVs)
but also their seamless integration into interdependent infrastructure
systems-specifically, the transportation-electricity nexus (TEN). This paper
develops an optimal multi-modal transportation and electric power flow (OMTEPF)
model to evaluate the benefits of coordinated, dynamic system operation.
Building on recent advances in hetero-functional graph theory, the framework
enables joint optimization of five key operational decisions in intelligent TEN
management: vehicle dispatch, route choice, charging station queuing,
coordinated charging, and vehicle-to-grid stabilization. The mesoscopic,
dynamic model explicitly represents individual EVs and their state-of-charge
trajectories, thereby extending beyond the prevailing literature's focus on
static, macroscopic traffic assignment. It further captures the full scope of
the TEN as a system-of-systems, incorporating five distinct charging
modalities: private residential, private commercial, wired public commercial,
inductive public, and discharging. On the power system side, an IV-ACOPF
formulation ensures globally optimal solutions to the electrical subproblems.
Comparative analysis demonstrates the substantial value of coordinated TEN
operation relative to the status quo of siloed, uncoordinated infrastructure
management. This work provides both a novel methodological contribution and
actionable insights for the co-design and operation of next-generation
sustainable mobility-energy systems.

</details>


### [501] [Establishing assembly-oriented modular product architectures through Design for Assembly enhanced Modular Function Deployment](https://arxiv.org/abs/2510.11089)
*Fabio Marco Monetti,Adam Lundström,Colin de Kwant,Magnus Gyllenskepp,Antonio Maffei*

Main category: eess.SY

TL;DR: 该研究提出了模块化功能部署（MFD）的增强方法，通过整合面向装配的设计（DFA）逻辑来改进模块化产品设计，以解决现有MFD方法在早期概念设计中缺乏装配考虑的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有模块化功能部署（MFD）方法在早期概念和系统级开发中缺乏对装配的系统性支持，导致生产爬坡延迟和生命周期效率低下的问题。

Method: 通过引入结构化启发式方法、面向装配的模块驱动程序、编码接口分类法以及用于评估装配可行性和自动化准备情况的量化指标来增强MFD。

Result: 通过一个手持式落叶吹叶机的案例研究，展示了该方法的有效性，改进后的模块化设计在装配工作量、接口复杂性和自动化潜力方面均有所提高。

Conclusion: 该增强方法通过在早期阶段引入装配视角，能够更快地过渡到高效的批量生产，并为产品生命周期内的持续改进奠定基础。

Abstract: Modular product design has become a strategic enabler for companies seeking
to balance product variety, operational efficiency, and market responsiveness,
making the alignment between modular architecture and manufacturing
considerations increasingly critical. Modular Function Deployment (MFD) is a
widely adopted method for defining modular product architectures, yet it lacks
systematic support for assembly considerations during early concept and
system-level development. This limitation increases the risk of delayed
production ramp-up and lifecycle inefficiencies. This paper proposes a set of
enhancements to MFD that integrate Design for Assembly (DFA) logic into
architectural synthesis. The extended method introduces structured heuristics,
assembly-oriented module drivers, a coded interface taxonomy, and quantitative
metrics for assessing assembly feasibility and automation readiness. These
additions preserve compatibility with standard MFD workflows while enriching
decision-making with traceable, production-informed reasoning. An illustrative
case study involving a handheld leaf blower demonstrates the method's usability
and effectiveness. The redesigned architecture shows reduced assembly effort,
simplified interfaces, and increased automation potential. By supporting
early-stage evaluation of architectural alternatives through an assembly lens,
the method enables faster transition to efficient volume production and
provides a foundation for continuous improvement throughout the product
lifecycle.

</details>


### [502] [Utilizing Bayesian Optimization for Timetable-Independent Railway Junction Performance Determination](https://arxiv.org/abs/2510.11181)
*Tamme Emunds,Paul Brunzema,Sebastian Trimpe,Nils Nießen*

Main category: eess.SY

TL;DR: 本篇论文提出了一种在交通流量分配问题中确定与时刻表无关的铁路枢纽容量的方法，并使用贝叶斯优化来解决该问题，以提高交通吞吐量。


<details>
  <summary>Details</summary>
Motivation: 传统铁路交通流量分配方法依赖于固定的容量限制，该限制是基于对交通组成成分的特定假设确定的。然而，铁路基础设施的效率受到列车组成成分的影响，因为不同类型的服务（如货运和客运）有不同的运行需求。因此，需要一种能够处理动态交通分布的方法来确定容量。

Method: 本研究提出了一种确定与时刻表无关的容量的方法，并将其应用于交通流量分配问题。该方法使用贝叶斯优化（BO）来解决一个非线性约束优化问题，目标是最大化交通吞吐量。研究人员还调整了贝叶斯优化的获取过程，并通过将关于约束函数形状的先验知识纳入高斯过程代理模型来提高其性能。

Result: 与固定交通组成成分模型相比，所提出的方法在巴黎附近的一个铁路枢纽的实际应用中表现显著更优。

Conclusion: 本研究强调了动态容量分配在铁路交通管理中的优势，并为解决交通流量分配问题提供了一种更灵活、更有效的方法。

Abstract: The efficiency of railway infrastructure is significantly influenced by the
mix of trains that utilize it, as different service types have competing
operational requirements. While freight services might require extended service
times, passenger services demand more predictable schedules. Traditional
methods for addressing long-term traffic assignment problems often rely on
fixed-value capacity limitations, determined based on specific assumptions
about traffic composition. This paper introduces a methodology for determining
timetable-independent capacity within the traffic rate assignment problem,
enabling the calculation of junction capacities under dynamic traffic
distributions. We solve the underlying non-linear constrained optimization
problem maximizing the traffic throughput using Bayesian optimization (BO).
This setting combines a known objective function with expensive- to-compute
capacity constraints, motivating an adaption of standard BO problems, where
objective functions are usually unknown. We tailor the acquisition process in
BO to this specific setting and increase performance by incorporating prior
knowledge about the shape of the constraint functions into the Gaussian process
surrogate model. Our derived approaches are benchmarked on a railway junction
near Paris, significantly outperforming fixed traffic composition models and
highlighting the benefits of dynamic capacity allocation.

</details>


### [503] [Edge-to-Cloud Computations-as-a-Service in Software-Defined Energy Networks for Smart Grids](https://arxiv.org/abs/2510.11286)
*Jack Jackman,David Ryan,Arun Narayanan,Pedro Nardelli,Indrakshi Dey*

Main category: eess.SY

TL;DR: 该研究提出了首个软件定义能源网络（SDEN），用于计算即服务（CaaS），统一边缘、雾和云计算，并结合5G URLLC、SDN和NFV，以端到端地共同优化能源、延迟和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现代电网在数据生成地和处理地之间存在严峻的错配：边缘的保护继电器、电动汽车充电和分布式可再生能源需要毫秒级的分析，而耗能大的工作负载通常位于遥远的云端，这会导致错过实时截止日期和浪费电力。

Method: 提出了一种联合任务卸载方案，该方案在明确的URLLC约束下，将计算放置与网络容量相结合；提出了一种保持可行性的、轻量级的贪婪启发式方法，该方法能够扩展并密切跟踪最优的能源和延迟权衡；提出了一种分层人工智能（AI）管道——在边缘进行反应式处理，在雾节点进行预测性处理，在云端进行战略性处理——采用了注重隐私的联邦图神经网络（GNNs）进行故障检测和微电网协调。

Result: SDEN将分散的电网计算能力转化为一个单一的、可编程的底层架构，能够提供可靠的、能源感知的、实时的分析。

Conclusion: 与之前的仅限于边缘或仅限于云的方案不同，SDEN为实现实际的、电网规模的CaaS提供了首个软件定义路径。

Abstract: Modern power grids face an acute mismatch between where data is generated and
where it can be processed: protection relays, EV (Electric Vehicle) charging,
and distributed renewables demand millisecond analytics at the edge, while
energy-hungry workloads often sit in distant clouds leading to missed real-time
deadlines and wasted power. We address this by proposing, to our knowledge, the
first-ever SDEN (Software Defined Energy Network) for CaaS
(Computations-as-a-Service) that unifies edge, fog, and cloud compute with 5G
URLLC (Ultra-Reliable Low-Latency Communications), SDN (Software Defined
Networking), and NFV (Network Functions Virtualization) to co-optimize energy,
latency, and reliability end-to-end. Our contributions are threefold: (i) a
joint task offloading formulation that couples computation placement with
network capacity under explicit URLLC constraints; (ii) a feasibility
preserving, lightweight greedy heuristic that scales while closely tracking
optimal energy and latency trade-offs; and (iii) a tiered AI (Artificial
Intelligence) pipeline-reactive at the edge, predictive in the fog, strategic
in the cloud-featuring privacy-preserving, federated GNNs (Graph Neural
Networks) for fault detection and microgrid coordination. Unlike prior
edge-only or cloud-only schemes, SDEN turns fragmented grid compute into a
single, programmable substrate that delivers dependable, energy-aware, real
time analytics establishing a first-ever, software defined path to practical,
grid-scale CaaS.

</details>


### [504] [pyspect: An Extensible Toolbox for Automatic Construction of Temporal Logic Trees via Reachability Analysis](https://arxiv.org/abs/2510.11316)
*Kaj Munhoz Arfvidsson,Loizos Hadjiloizou,Frank J. Jiang,Karl H. Johansson,Jonas Mårtensson*

Main category: eess.SY

TL;DR: pyspect 是一个 Python 工具箱，通过时间逻辑树（TLTs）简化了可达性分析在时间逻辑问题中的应用，从而降低了复杂系统验证的门槛。


<details>
  <summary>Details</summary>
Motivation: 当前在网络物理系统中满足复杂需求需要大量手动工作和领域专业知识来开发底层可达性程序，这限制了可达性分析的广泛应用。pyspect 旨在解决此问题。

Method: pyspect 提供了一种独立于具体方法的可达性分析方法，通过时间逻辑树（TLTs）来验证时间逻辑规约。它允许用户使用高层逻辑表述来指定复杂的安全性和活性需求，这些表述不依赖于任何特定的可达性技术或集合表示。

Result: pyspect 能够实现不同可达性实现（如 Hamilton-Jacobi 和混合区域多面体）针对同一时间逻辑规约的比较。它将实现开发者（开发数值程序）和最终用户（编写规约）的关注点分离开来。通过一个简单的车辆示例，演示了 pyspect 如何简化可达性程序的综合、促进规约的可重用性以及方便对复杂任务的可达性技术进行并排比较。

Conclusion: pyspect 工具箱通过提供一种方法无关的接口，使用户能够更容易地表达和验证复杂的时间逻辑规约，并促进了不同可达性分析技术之间的比较。

Abstract: In this paper, we present pyspect, a Python toolbox that simplifies the use
of reachability analysis for temporal logic problems. Currently, satisfying
complex requirements in cyber-physical systems requires significant manual
effort and domain expertise to develop the underlying reachability programs.
This high development effort limits the broader adoption of reachability
analysis for complex verification problems. To address this, pyspect provides a
method-agnostic approach to performing reachability analysis for verifying a
temporal logic specification via temporal logic trees (TLTs). It enables the
specification of complex safety and liveness requirements using high-level
logic formulations that are independent of any particular reachability
technique or set representation. As a result, pyspect allows for the comparison
of different reachability implementations, such as Hamilton-Jacobi and Hybrid
Zonotope-based reachability analysis, for the same temporal logic
specification. This design separates the concerns of implementation developers
(who develop numerical procedures for reachability) and end-users (who write
specifications). Through a simple vehicle example, we demonstrate how pyspect
simplifies the synthesis of reachability programs, promotes specification
reusability, and facilitates side-by-side comparisons of reachability
techniques for complex tasks.

</details>


### [505] [Efficient LLM Inference over Heterogeneous Edge Networks with Speculative Decoding](https://arxiv.org/abs/2510.11331)
*Bingjie Zhu,Zhixiong Chen,Liqiang Zhao,Hyundong Shin,Arumugam Nallanathan*

Main category: eess.SY

TL;DR: 边缘端大语言模型推理面临延迟高和用户支持能力不足的挑战。本文提出了一种基于投机解码（SD）的框架，利用异构边缘节点上的大小模型协同推理，并结合流水线并行提高资源利用率。通过建立详细的延迟模型，并联合优化投机长度、任务批处理和无线通信资源分配，实现了总服务延迟的最小化。实验证明，该框架相比于基于自回归解码（AD）的系统具有更低的延迟，并且联合优化方法能带来显著的延迟降低。


<details>
  <summary>Details</summary>
Motivation: 现有的边缘大语言模型推理系统通常采用自回归解码（AD），其每个前向传播仅生成一个词元，这在边缘节点的计算资源有限的情况下导致服务延迟高，并限制了系统支持多用户能力。

Method: 提出一种基于投机解码（SD）的框架，将小模型和大模型部署在异构边缘节点上协同进行推理。小模型快速生成候选词元，大模型并行验证，实现每个前向传播生成多个词元，从而降低服务延迟。为提高边缘节点的资源利用率，引入流水线并行，跨多个推理任务重叠候选词元生成和验证过程。在此框架基础上，推导了包含通信和推理延迟的综合延迟模型，并将投机长度、任务批处理和无线通信资源分配进行联合优化，以最小化总服务延迟。推导了无线通信资源分配的闭式解，并开发了批处理和投机控制策略的动态规划算法。

Result: 实验结果表明，所提出的框架实现了比基于AD的服务系统更低的服务延迟。此外，所提出的联合优化方法与基准方案相比，延迟降低了高达44.9%。

Conclusion: 所提出的基于SD的框架和联合优化方法能够显著降低边缘端大语言模型推理的服务延迟，并提高系统性能。

Abstract: Large language model (LLM) inference at the network edge is a promising
serving paradigm that leverages distributed edge resources to run inference
near users and enhance privacy. Existing edge-based LLM inference systems
typically adopt autoregressive decoding (AD), which only generates one token
per forward pass. This iterative process, compounded by the limited
computational resources of edge nodes, results in high serving latency and
constrains the system's ability to support multiple users under growing
demands.To address these challenges, we propose a speculative decoding
(SD)-based LLM serving framework that deploys small and large models across
heterogeneous edge nodes to collaboratively deliver inference services.
Specifically, the small model rapidly generates draft tokens that the large
model verifies in parallel, enabling multi-token generation per forward pass
and thus reducing serving latency. To improve resource utilization of edge
nodes, we incorporate pipeline parallelism to overlap drafting and verification
across multiple inference tasks. Based on this framework, we analyze and derive
a comprehensive latency model incorporating both communication and inference
latency. Then, we formulate a joint optimization problem for speculation
length, task batching, and wireless communication resource allocation to
minimize total serving latency. To address this problem, we derive the
closed-form solutions for wireless communication resource allocation, and
develop a dynamic programming algorithm for joint batching and speculation
control strategies. Experimental results demonstrate that the proposed
framework achieves lower serving latency compared to AD-based serving systems.
In addition,the proposed joint optimization method delivers up to 44.9% latency
reduction compared to benchmark schemes.

</details>


### [506] [High-Order Quarter-Wave Plate Optimization for Linear Birefringence Suppression in Reflective FOCS](https://arxiv.org/abs/2510.11386)
*Yuechen Liu,Boqi Meng*

Main category: eess.SY

TL;DR: 本研究提出一种利用高阶波片补偿法消除反射式光纤电流传感器中线性双折射效应的策略，从而提高传感器的精度。


<details>
  <summary>Details</summary>
Motivation: 现代电网广泛采用光纤电流传感器（FOCS），但需要精确研究其误差来源并进行优化。

Method: 建立理论模型模拟由四分之一波片引起的线性双折射所造成的相位误差，并提出一种利用高阶波片进行补偿的策略。

Result: 所提出的方法有效消除了线性双折射效应，提高了FOCS的精度和实用性。

Conclusion: 利用高阶波片补偿法能有效消除线性双折射效应，提高FOCS在精密计量中的精度和实用性。

Abstract: Fiber optic current sensors (FOCS) are widely adopted in modern power grids
due to high sensitivity, excellent insulation, and strong immunity to
electromagnetic interference. This prominence necessitates precise
investigation into their error sources and corresponding optimization. This
study examines reflective FOCS based on the Faraday effect. A theoretical model
is established to simulate phase error caused by linear birefringence from the
quarter-wave plate. Conventional methods using circular birefringence are
analyzed, revealing inherent limitations. Innovatively, a compensation strategy
employing high-order quarter-wave plates is proposed to effectively eliminate
linear birefringence effects. This approach significantly enhances the accuracy
and practicality of FOCS in precision metrology.

</details>


### [507] [Data-Driven Estimation of Quadrotor Motor Efficiency via Residual Minimization](https://arxiv.org/abs/2510.11388)
*Sheng-Wen Cheng,Teng-Hu Cheng*

Main category: eess.SY

TL;DR: 提出一种数据驱动的框架，通过残差最小化来在线估计四旋翼飞行器电机效率。


<details>
  <summary>Details</summary>
Motivation: 该框架旨在解决四旋翼飞行器电机效率的在线估算问题，特别是在存在不确定性和噪声的情况下。

Method: 将问题构建为约束非线性优化问题，通过最小化测量数据与模型预测之间的轨迹残差来求解。采用滑动窗口策略实现在线估算，并结合迭代重加权最小二乘法（IRLS）和原对偶内点法高效求解优化问题，同时利用对数障碍函数处理不等式约束。为提高鲁棒性，采用Z分数加权法剔除异常值，该方法在电机削波情景下优于EKF基线。与传统滤波方法相比，该批处理模式提供了更大的灵活性，可以选择性地纳入信息量大的数据段。

Result: 仿真结果表明，所提出的估计器在各种退化场景下均表现出准确性和鲁棒性，尤其在电机削波情景下，其估计值的尖峰比EKF基线小。

Conclusion: 该框架适用于机载实现，特别适用于空中机器人系统的故障检测与隔离（FDI）、健康监测和预测性维护等应用。

Abstract: A data-driven framework is proposed for online estimation of quadrotor motor
efficiency via residual minimization. The problem is formulated as a
constrained nonlinear optimization that minimizes trajectory residuals between
measured flight data and predictions generated by a quadrotor dynamics model. A
sliding-window strategy enables online estimation, and the optimization is
efficiently solved using an iteratively reweighted least squares (IRLS) scheme
combined with a primal-dual interior-point method, with inequality constraints
enforced through a logarithmic barrier function. Robust z-score weighting is
employed to reject outliers, which is particularly effective in motor clipping
scenarios where the proposed estimator exhibits smaller spikes than an EKF
baseline. Compared to traditional filter-based approaches, the batch-mode
formulation offers greater flexibility by selectively incorporating informative
data segments. This structure is well-suited for onboard implementation,
particularly for applications such as fault detection and isolation (FDI),
health monitoring, and predictive maintenance in aerial robotic systems.
Simulation results under various degradation scenarios demonstrate the accuracy
and robustness of the proposed estimator.

</details>


### [508] [Robust Closed-Form Control for MIMO Nonlinear Systems under Conflicting Time-Varying Hard and Soft Constraints](https://arxiv.org/abs/2510.11393)
*Farhad Mehdifar,Charalampos P. Bechlioulis,Dimos V. Dimarogonas*

Main category: eess.SY

TL;DR: 提出了一种新颖的鲁棒闭式控制律，用于处理不确定的高相对阶非线性MIMO系统中时变的硬约束和软约束。


<details>
  <summary>Details</summary>
Motivation: 解决不确定的高相对阶非线性MIMO系统中时变的硬约束和软约束问题，这些约束代表了机械系统操作空间中的时空规范，硬约束确保了安全关键要求，软约束编码了性能或任务目标。

Method: 将所有约束合并为两个独立的标量时变硬约束和软约束函数，其正水平集定义了可行区域。开发了一种闭式控制律，使用适当设计的倒数屏障和非线性变换函数来强制执行这些约束。当硬约束和软约束之间出现冲突时，控制律通过动态松弛定律虚拟地放松软约束来优先考虑硬约束。该控制律避免了处理系统不确定性的近似方案，从而保持了低复杂度。

Result: 仿真结果验证了所提出方法的有效性。

Conclusion: 所提出的控制律在处理不确定的高相对阶非线性MIMO系统中时变的硬约束和软约束方面是有效的，并且保持了低复杂度。

Abstract: This paper introduces a novel robust closed-form control law to handle
time-varying hard and soft constraints in uncertain high-relative-degree
nonlinear MIMO systems. These constraints represent spatiotemporal
specifications in mechanical systems' operational space, with hard constraints
ensuring safety-critical requirements and soft constraints encoding performance
or task objectives. Initially, all constraints are consolidated into two
separate scalar time-varying hard and soft constraint functions, whose positive
level sets define feasible regions. A closed-form control law is developed to
enforce these constraints using appropriately designed reciprocal barriers and
nonlinear transformation functions. When conflicts between hard and soft
constraints arise, the control law prioritizes hard constraints by virtually
relaxing soft constraints via a dynamic relaxation law. Notably, the proposed
control law maintains low complexity by avoiding approximation schemes for
coping with system uncertainties. Simulation results confirm the effectiveness
of the proposed method.

</details>


### [509] [Robust Recovery and Control of Cyber-physical Discrete Event Systems under Actuator Attacks](https://arxiv.org/abs/2510.11405)
*Samuel Oliveira,Mostafa Tavakkoli Anbarani,Gregory Beal,Ilya Kovalenko,Marcelo Teixeira,André B. Leal,Rômulo Meira-Góes*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Critical real-world applications strongly rely on Cyber-physical systems
(CPS), but their dependence on communication networks introduces significant
security risks, as attackers can exploit vulnerabilities to compromise their
integrity and availability. This work explores the topic of cybersecurity in
the context of CPS modeled as discrete event systems (DES), focusing on
recovery strategies following the detection of cyberattacks. Specifically, we
address actuator enablement attacks and propose a method that preserves the
system's full valid behavior under normal conditions. Upon detecting an attack,
our proposed solution aims to guide the system toward a restricted yet robust
behavior, ensuring operational continuity and resilience. Additionally, we
introduce a property termed AE-robust recoverability, which characterizes the
necessary and sufficient conditions for recovering a system from attacks while
preventing further vulnerabilities. Finally, we showcase the proposed solution
through a case study based on a manufacturing system.

</details>


### [510] [Trajectory control of a suspended load with non-stopping flying carriers](https://arxiv.org/abs/2510.11413)
*Sofia Girardello,Giulia Michieletto,Angelo Cenedese,Antonio Franchi,Chiara Gabellieri*

Main category: eess.SY

TL;DR: 本文提出了首个用于非停歇飞行载体的协同吊装闭环控制框架，通过抓取矩阵和内力冗余，提出了一种反馈力控制器来主动调节负载姿态，并通过优化层动态调整内力振荡以保证载体持续运动。实验和仿真结果表明，该方法能有效防止载体停滞，实现精确的负载跟踪，并生成具有平滑速度曲线的物理可行轨迹。


<details>
  <summary>Details</summary>
Motivation: 开发用于非停歇飞行载体的协同吊装闭环控制框架。

Method: 提出了一种反馈力控制器，该控制器基于抓取矩阵和内力冗余，能够主动调节负载姿态，并通过优化层动态调整内力振荡以保证载体持续运动。

Result: 初步的实验结果验证了模型假设，数值模拟证明了该方法能够成功防止载体停滞，实现精确的负载跟踪，并生成具有平滑速度曲线的物理可行轨迹。

Conclusion: 所提出的框架不仅能推动技术进步，而且为未来需要协同非停歇飞行载体进行负载运输的实际应用提供了可靠且通用的解决方案。

Abstract: This paper presents the first closed-loop control framework for cooperative
payload transportation with non-stopping flying carriers. Building upon
grasp-matrix formulations and internal force redundancy, we propose a feedback
wrench controller that actively regulates the payload's pose while an
optimization layer dynamically shapes internal-force oscillations to guarantee
persistent carrier motion. Preliminary experimental results on multirotor UAVs
validate the model assumptions, and numerical simulations demonstrate that the
method successfully prevents carrier stagnation, achieves accurate load
tracking, and generates physically feasible trajectories with smooth velocity
profiles. The proposed framework not only advances the state of the art but
also offers a reliable, versatile solution for future real-world applications
requiring load transportation by coordinated non-stopping flying carriers.

</details>


### [511] [The Role of Flexible Connection in Accelerating Load Interconnection in Distribution Networks](https://arxiv.org/abs/2510.11476)
*Nan Gu,Ge Chen,Junjie Qin*

Main category: eess.SY

TL;DR: 灵活连接可显著提高电网承载能力，实现大规模负荷的快速接入，即使在电力需求增长的情况下也能避免大规模基础设施升级。


<details>
  <summary>Details</summary>
Motivation: 随着数据中心和电气化的发展，电力需求不断增长，迫切需要一种能够加速大型负荷接入电网的解决方案。

Method: 提出了一种考虑灵活性的负荷接入能力分析问题，并开发了有效的求解方法。该方法将每年由电力公司控制的干预次数限制在内，以确保干扰的稀少性。

Result: 研究结果表明，适度的灵活性，即较少的干预次数和较小的负荷削减或延迟，就可以显著提高负荷接入能力。理论分析也支持并推广了这些发现。

Conclusion: 灵活连接是一种有潜力的方法，可以通过允许新负荷在稀少的、电网受限的时期推迟或削减用电量，从而在不进行大规模基础设施升级的情况下，加快接入速度。

Abstract: This paper investigates the role of flexible connection in accelerating the
interconnection of large loads amid rising electricity demand from data centers
and electrification. Flexible connection allows new loads to defer or curtail
consumption during rare, grid-constrained periods, enabling faster access
without major infrastructure upgrades. To quantify how flexible connection
unlocks load hosting capacity, we formulate a flexibility-aware hosting
capacity analysis problem that explicitly limits the number of
utility-controlled interventions per year, ensuring infrequent disruption.
Efficient solution methods are developed for this nonconvex problem and applied
to real load data and test feeders. Empirical results reveal that modest
flexibility, i.e., few interventions with small curtailments or delays, can
unlock substantial hosting capacity. Theoretical analysis further explains and
generalizes these findings, highlighting the broad potential of flexible
connection.

</details>


### [512] [A Physics-Informed Reinforcement Learning Approach for Degradation-Aware Long-Term Charging Optimization in Batteries](https://arxiv.org/abs/2510.11515)
*Shanthan Kumar Padisala,Bharatkumar Hegde,Ibrahim Haskara,Satadru Dey*

Main category: eess.SY

TL;DR: 本研究提出了一种基于强化学习的自适应CCCV充电框架，能够根据电池健康状况调整恒流充电电流，以减缓电池老化。


<details>
  <summary>Details</summary>
Motivation: 现有充电方法很少考虑电池健康随时间的变化，本研究旨在填补这一空白，使CCCV充电协议能够适应电池的退化。

Method: 提出了一种基于物理信息强化学习（RL）的框架，该框架能够估计电池活性物质损失（LAM），并据此调整CCCV充电协议中的恒流充电电流。该框架结合了PyBamm和Stable-baselines库，并使用Proximal Policy Optimization（PPO）网络进行训练。

Result: 仿真结果表明，该框架能够通过将物理信息嵌入RL算法来优化CCCV协议，并与非物理RL代理和恒定CCCV充电协议进行了比较研究。

Conclusion: 所提出的自适应CCCV充电框架能够通过整合物理知识和RL算法来增强现有的CCCV协议，从而可能延长电池寿命。

Abstract: Batteries degrade with usage and continuous cycling. This aging is typically
reflected through the resistance growth and the capacity fade of battery cells.
Over the years, various charging methods have been presented in the literature
that proposed current profiles in order to enable optimal, fast, and/or
health-conscious charging. However, very few works have attempted to make the
ubiquitous Constant Current Constant Voltage (CCCV) charging protocol adaptive
to the changing battery health as it cycles. This work aims to address this gap
and proposes a framework that optimizes the constant current part of the CCCV
protocol adapting to long-term battery degradation. Specifically, a
physics-informed Reinforcement Learning (RL) approach has been used that not
only estimates a key battery degradation mechanism, namely, Loss of Active
Material (LAM), but also adjusts the current magnitude of CCCV as a result of
this particular degradation. The proposed framework has been implemented by
combining PyBamm, an open-source battery modeling tool, and Stable-baselines
where the RL agent was trained using a Proximal Policy Optimization (PPO)
network. Simulation results show the potential of the proposed framework for
enhancing the widely used CCCV protocol by embedding physics information in RL
algorithm. A comparative study of this proposed agent has also been discussed
with 2 other charging protocols generated by a non-physics-based RL agent and a
constant CCCV for all the cycles.

</details>


### [513] [Smooth Spatiotemporal Tube Synthesis for Prescribed-Time Reach-Avoid-Stay Control](https://arxiv.org/abs/2510.11583)
*Siddhartha Upadhyay,Ratnangshu Das,Pushpak Jagtap*

Main category: eess.SY

TL;DR: 提出了一种改进的基于时空管（STT）的控制器综合方法，用于满足控制仿射非线性系统的时序到达-避免-停留（RAS）规范，通过构造平滑的STT来消除对规避函数的需求，从而减少控制 esfuerzo。


<details>
  <summary>Details</summary>
Motivation: 先前的基于时空管（STT）的方法在满足时序到达-避免-停留（RAS）规范时，需要使用规避函数，这可能导致管的突然修改和高昂的控制成本。本工作旨在改进这些方法，消除对规避函数的需求，以实现更平滑的控制和更低的控制成本。

Method: 提出了一种自适应框架，该框架围绕静态不安全集构建平滑的时空管（STT），实现了连续的避免，同时在规定时间内将系统引导至目标。推导了一个闭式、无近似的控制律，以确保系统轨迹保持在管内并满足RAS任务。

Result: 通过一个案例研究证明了所提出方法的有效性，与先前的方法相比，显著降低了控制成本。

Conclusion: 所提出的自适应框架能够成功地为控制仿射非线性系统合成满足RAS规范的控制器，并且相比于现有方法，能够更有效地降低控制成本。

Abstract: In this work, we address the issue of controller synthesis for a
control-affine nonlinear system to meet prescribed time reach-avoid-stay
specifications. Our goal is to improve upon previous methods based on
spatiotemporal tubes (STTs) by eliminating the need for circumvent functions,
which often lead to abrupt tube modifications and high control effort. We
propose an adaptive framework that constructs smooth STTs around static unsafe
sets, enabling continuous avoidance while guiding the system toward the target
within the prescribed time. A closed-form, approximation-free control law is
derived to ensure the system trajectory remains within the tube and satisfies
the RAS task. The effectiveness of the proposed approach is demonstrated
through a case study, showing a significant reduction in control effort
compared to prior methods.

</details>


### [514] [Analysis of the Geometric Heat Flow Equation: Computing Geodesics in Real-Time with Convergence Guarantees](https://arxiv.org/abs/2510.11692)
*Samuel G. Gessow,Brett T. Lopez*

Main category: eess.SY

TL;DR: 该论文研究了几何热流方程在黎曼流形上计算测地线（最短路径曲线）的收敛性。


<details>
  <summary>Details</summary>
Motivation: 在控制和运动规划等领域，实时计算测地线的能力非常重要。

Method: 该论文提出了一种伪谱方法，利用切比雪夫多项式来计算测地线，并证明了几何热流方程在 $L_2$ 范数下的全局指数稳定性和渐近收敛性。

Result: 该方法能够在几毫秒内精确计算非平凡流形上的测地线，并在非线性系统的收缩控制器中进行了验证。

Conclusion: 几何热流方程在黎曼流形上计算测地线是一种有效且收敛性好的数值方法。

Abstract: We present an analysis on the convergence properties of the so-called
geometric heat flow equation for computing geodesics (shortest-path~curves) on
Riemannian manifolds. Computing geodesics numerically in real-time has become
an important capability in several fields, including control and motion
planning. The geometric heat flow equation involves solving a parabolic partial
differential equation whose solution is a geodesic. In practice, solving this
PDE numerically can be done efficiently, and tends to be more numerically
stable and exhibit a better rate of convergence compared to numerical
optimization. We prove that the geometric heat flow equation is globally
exponentially stable in $L_2$ if the curvature of the Riemannian manifold is
not too positive, and that asymptotic convergence in $L_2$ is always
guaranteed. We also present a pseudospectral method that leverages Chebyshev
polynomials to accurately compute geodesics in only a few milliseconds for
non-contrived manifolds. Our analysis was verified with our custom
pseudospectral method by computing geodesics on common non-Euclidean surfaces,
and in feedback for a contraction-based controller with a non-flat metric for a
nonlinear system.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [515] [Stability in Online Assignment Games](https://arxiv.org/abs/2510.09814)
*Emile Martinez,Felipe Garrido-Lucero,Umberto Grandi*

Main category: cs.GT

TL;DR: 该论文研究了在线分配博弈中次优匹配的稳定性度量及其与最优比例的关系，并分析了随机算法的稳定性表现。


<details>
  <summary>Details</summary>
Motivation: 在实际的住房市场中，尤其是在参与者依次进入市场的在线环境中，稳定分配通常难以实现，因为匹配往往是次优的。因此，需要有度量来衡量这种不稳定性。

Method: 提出并比较了两种衡量次优匹配分配不稳定的度量方法，并建立了它们与底层匹配的最优比例之间的联系。利用这个框架来研究随机算法在在线分配博弈中的稳定性表现。

Result: 论文介绍了两种新的不稳定性度量，并将其与最优比例联系起来，为分析在线分配博弈中的稳定性提供了一个新的框架。

Conclusion: 通过引入新的不稳定性度量和分析随机算法的表现，该研究为理解和改进在线分配博弈中的市场稳定性提供了理论支持。

Abstract: The assignment game models a housing market where buyers and sellers are
matched, and transaction prices are set so that the resulting allocation is
stable. Shapley and Shubik showed that every stable allocation is necessarily
built on a maximum social welfare matching. In practice, however, stable
allocations are rarely attainable, as matchings are often sub-optimal,
particularly in online settings where eagents arrive sequentially to the
market. In this paper, we introduce and compare two complementary measures of
instability for allocations with sub-optimal matchings, establish their
connections to the optimality ratio of the underlying matching, and use this
framework to study the stability performances of randomized algorithms in
online assignment games.

</details>


### [516] [Proportional and Pareto-Optimal Allocation of Chores with Subsidy](https://arxiv.org/abs/2510.10335)
*Jugal Garg,Eklavya Sharma,Xiaowei Wu*

Main category: cs.GT

TL;DR: 我们提出了一个多项式时间算法，用于在具有不同权重的代理之间分配不可分割的零星物品，以实现比例公平和帕累托最优。该算法通过计算比例公平的竞争均衡，然后应用一种由最小每单位成本边引导的舍入程序来实现，其补贴上限与现有方法相同，但方法更简单且具有经济效率。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在具有不同权重的代理之间分配不可分割零星物品的问题，同时实现公平（比例公平）和效率（帕累托最优）。现有的方法虽然能保证比例公平，但可能需要较高的补贴且缺乏经济效率。

Method: 本文提出了一个多项式时间算法，首先计算比例公平的竞争均衡，然后应用一种由最小每单位成本边引导的舍入程序。该算法在保证比例公平的同时，也确保了帕累托最优。

Result: 该算法在保证比例公平的前提下，实现了与现有方法（Wu and Zhou, WINE 2024）相同的补贴上限（最多为 n/3 - 1/6），并且能够保证帕累托最优。此外，该算法及其分析比现有方法更简单。

Conclusion: 本文提出了一个更简单、更经济高效的算法，用于在代理之间公平有效地分配不可分割的零星物品，并能保证比例公平和帕累托最优。

Abstract: We consider the problem of allocating $m$ indivisible chores among $n$ agents
with possibly different weights, aiming for a solution that is both fair and
efficient. Specifically, we focus on the classic fairness notion of
proportionality and efficiency notion of Pareto-optimality. Since proportional
allocations may not always exist in this setting, we allow the use of subsidies
(monetary compensation to agents) to ensure agents are
proportionally-satisfied, and aim to minimize the total subsidy required. Wu
and Zhou (WINE 2024) showed that when each chore has disutility at most 1, a
total subsidy of at most $n/3 - 1/6$ is sufficient to guarantee
proportionality. However, their approach is based on a complex technique, which
does not guarantee economic efficiency - a key desideratum in fair division.
  In this work, we give a polynomial-time algorithm that achieves the same
subsidy bound while also ensuring Pareto-optimality. Moreover, both our
algorithm and its analysis are significantly simpler than those of Wu and Zhou
(WINE 2024). Our approach first computes a proportionally-fair competitive
equilibrium, and then applies a rounding procedure guided by
minimum-pain-per-buck edges.

</details>


### [517] [Improved Maximin Share Guarantee for Additive Valuations](https://arxiv.org/abs/2510.10423)
*Ehsan Heidari,Alireza Kaviani,Masoud Seddighin,AmirMohammad Shahrezaei*

Main category: cs.GT

TL;DR: 已有算法在分配最大最小共享值（MMS）方面，对于某些情况，只能保证获得不超过1-1/n^4的MMS值。尽管如此，目前最好的算法可以达到3/4 + 3/3836的MMS值。本研究将这一差距缩小，并将MMS的最佳近似保证提高到10/13。


<details>
  <summary>Details</summary>
Motivation: 最大最小共享值（MMS）是公平分配不可分割物品的著名概念。已有研究致力于提高MMS在不同估值类别（尤其是可加估值）下的近似保证。然而，对于可加估值，已有研究表明，某些情况下无法保证所有代理的MMS值能达到1-1/n^4以上。目前最好的算法能达到3/4 + 3/3836的近似保证。

Method: 本研究旨在缩小已有算法的近似保证与理论上可能达到的最佳值之间的差距。

Result: 本研究将MMS的最佳近似保证从3/4 + 3/3836提高到10/13。

Conclusion: 本研究成功地缩小了MMS近似保证的差距，并将最佳保证值提高到10/13。

Abstract: The maximin share ($\textsf{MMS}$) is the most prominent share-based fairness
notion in the fair allocation of indivisible goods. Recent years have seen
significant efforts to improve the approximation guarantees for $\textsf{MMS}$
for different valuation classes, particularly for additive valuations. For the
additive setting, it has been shown that for some instances, no allocation can
guarantee a factor better than $1-\tfrac{1}{n^4}$ of maximin share value to all
agents. However, the best currently known algorithm achieves an approximation
guarantee of $\tfrac{3}{4} + \tfrac{3}{3836}$ for $\textsf{MMS}$. In this work,
we narrow this gap and improve the best-known approximation guarantee for
$\textsf{MMS}$ to $\tfrac{10}{13}$.

</details>


### [518] [Fair Assignment of Indivisible Chores to Asymmetric Agents](https://arxiv.org/abs/2510.10698)
*Masoud Seddighin,Saeed Seddighin*

Main category: cs.GT

TL;DR: 对于拥有不同权利的代理人，在最大最小份额值（MMS）的背景下，我们研究了分配不可分割的家务的问题。当代理人拥有不同的权利时，情况会变得更加复杂。对于不可分割的商品分配，已证明加权 MMS (WMMS) 保证是最好的。然而，对于不可分割的家务，最近发现 O(log n)-WMMS 分配保证是存在的。在这项工作中，我们将这个上界改进为常数-WMMS 保证。


<details>
  <summary>Details</summary>
Motivation: 研究在代理人拥有不同权利的情况下，分配不可分割家务的问题，并改进现有的加权最大最小份额 (WMMS) 分配的保证。

Method: 在论文中，我们证明了存在一个 20-WMMS 的分配，但没有尝试优化常数因子。我们相信我们的方法可以通过更紧密的分析产生略好的界限。

Result: 将不可分割家务分配的 WMMS 保证从 O(log n) 提高到常数级别。

Conclusion: 存在一个常数-WMMS 的家务分配保证，优于先前 O(log n) 的保证。

Abstract: We consider the problem of assigning indivisible chores to agents with
different entitlements in the maximin share value (\MMS) context. While
constant-\MMS\ allocations/assignments are guaranteed to exist for both goods
and chores in the symmetric setting, the situation becomes much more complex
when agents have different entitlements. For the allocation of indivisible
goods, it has been proven that an $n$-\WMMS\ (weighted \MMS) guarantee is the
best one can hope for. For indivisible chores, however, it was recently
discovered that an $O(\log n)$-\WMMS\ assignment is guaranteed to exist. In
this work, we improve this upper bound to a constant-\WMMS\
guarantee.\footnote{We prove the existence of a 20-\WMMS\ assignment, but we
did not attempt to optimize the constant factor. We believe our methods already
yield a slightly better bound with a tighter analysis.}

</details>


### [519] [Achieving Coordination in Non-Cooperative Joint Replenishment Games](https://arxiv.org/abs/2510.10929)
*Junjie Luo,Changjun Wang*

Main category: cs.GT

TL;DR: 研究了一个无限期确定性联合补货模型，采用非合作对策论方法。目标是设计成本分配规则，以最小化长期平均系统成本，同时考虑到每个零售商独立选择其补货间隔以最小化自身成本。


<details>
  <summary>Details</summary>
Motivation: 设计成本分配规则，以最小化长期平均系统成本，同时考虑到每个零售商独立选择其补货间隔以最小化自身成本。

Method: 引入了一类成本分配规则，按预定义的权重将主要设置成本分配给相关零售商。证明了该规则的代理人更好反应的单调性，证明了存在支付主导的纯纳什均衡，并且可以有效计算。分析了不同信息设置下均衡的效率，检查了稳定性的价格（PoS）。

Result: 一种利用零售商自身持有成本率的规则实现了接近最优的1.25 PoS。另一种不需要访问零售商私有信息的规则也产生了有利的PoS。

Conclusion: 存在一个支付主导的纯纳什均衡，并且可以有效计算。在某些规则下，系统成本可以接近最优。

Abstract: We analyze an infinite-horizon deterministic joint replenishment model from a
non-cooperative game-theoretical approach. In this model, a group of retailers
can choose to jointly place an order, which incurs a major setup cost
independent of the group, and a minor setup cost for each retailer.
Additionally, each retailer is associated with a holding cost. Our objective is
to design cost allocation rules that minimize the long-run average system cost
while accounting for the fact that each retailer independently selects its
replenishment interval to minimize its own cost. We introduce a class of cost
allocation rules that distribute the major setup cost among the associated
retailers in proportion to their predefined weights. For these rules, we
establish a monotonicity property of agent better responses, which enables us
to prove the existence of a payoff dominant pure Nash equilibrium that can also
be computed efficiently. We then analyze the efficiency of these equilibria by
examining the price of stability (PoS), the ratio of the best Nash
equilibrium's system cost to the social optimum, across different information
settings. In particular, our analysis reveals that one rule, which leverages
retailers' own holding cost rates, achieves a near-optimal PoS of 1.25, while
another rule that does not require access to retailers' private information
also yields a favorable PoS.

</details>


### [520] [Likes, Budgets, and Equilibria: Designing Contests for Socially Optimal Advertising](https://arxiv.org/abs/2510.11253)
*Sayantika Mandal,Harman Agrawal,Swaprava Nath*

Main category: cs.GT

TL;DR: 广告商在社交网络上竞争品牌知名度，我们可以通过选择合适的竞争成功函数来优化博弈均衡。


<details>
  <summary>Details</summary>
Motivation: 当公司在社交网络上竞争用户注意力以提高品牌知名度时，需要优化预算分配以最大化品牌知名度。

Method: 提出一个两时间尺度的决策模型，其中节点间的通信发生在较快的时间尺度上，而公司的策略更新发生在较慢的时间尺度上。

Result: 在标准条件下，公司的最佳响应动态会收敛到一个纯策略纳什均衡，但这可能偏离社会最优。

Conclusion: 通过为设计者提供竞争成功函数的选择，可以实现唯一且社会福利最大化的纳什均衡。实验表明，在现实场景中，这种竞争成功函数的效果相当不错。

Abstract: Firms (businesses, service providers, entertainment organizations, political
parties, etc.) advertise on social networks to draw people's attention and
improve their awareness of the brands of the firms. In all such cases, the
competitive nature of their engagements gives rise to a game where the firms
need to decide how to distribute their budget over the agents on a network to
maximize their brand's awareness. The firms (players) therefore need to
optimize how much budget they should put on the vertices of the network so that
the spread improves via direct (via advertisements or free promotional offers)
and indirect marketing (words-of-mouth). We propose a two-timescale model of
decisions where the communication between the vertices happen in a faster
timescale and the strategy update of the firms happen in a slower timescale. We
show that under fairly standard conditions, the best response dynamics of the
firms converge to a pure strategy Nash equilibrium. However, such equilibria
can be away from a socially optimal one. We provide a characterization of the
contest success functions and provide examples for the designers of such
contests (e.g., regulators, social network providers, etc.) such that the Nash
equilibrium becomes unique and social welfare maximizing. Our experiments show
that for realistic scenarios, such contest success functions perform fairly
well.

</details>


### [521] [Temporal Cooperative Games](https://arxiv.org/abs/2510.11255)
*Ashwin Goyal,Drashthi Doshi,Swaprava Nath*

Main category: cs.GT

TL;DR: 合作博弈的价值函数从依赖集合扩展到依赖序列，引入了时间合作博弈（TCG），并提出了激励最优到达（I4OA）、在线个体理性（OIR）和序列效率（SE）三个关键属性。研究发现，满足这些时间属性的奖励分配机制与基于Shapley值的经典机制存在根本性冲突，即使在处理特定TCG类型时也是如此，这为TCG中的公平和高效解决方案概念带来了新的挑战。


<details>
  <summary>Details</summary>
Motivation: 经典合作博弈理论在实际应用中存在局限，因为联盟的价值可能不仅仅取决于参与者集合，还可能取决于参与者的加入顺序。为了解决这一问题，引入了时间合作博弈（TCG），将价值函数从集合扩展到序列。

Method: 提出时间合作博弈（TCG），并定义了三个关键属性：激励最优到达（I4OA）、在线个体理性（OIR）和序列效率（SE）。研究了满足这些属性的奖励分配机制，并构建了Shapley值的两个类比：序列世界和扩展世界。通过效率、可加性和零玩家属性来确定这些类比。最后，分析了满足I4OA、OIR、SE的机制与Shapley类比之间的冲突。

Result: 发现满足I4OA、OIR和SE的奖励分配机制是唯一由这三个属性决定的。提出了Shapley值的两个类比（序列世界和扩展世界），并证明了它们由效率、可加性和零玩家属性唯一确定。最重要的是，证明了满足I4OA、OIR、SE的机制与Shapley类比之间存在冲突，即使在处理凸TCG和简单TCG等特定类别时也是如此。

Conclusion: 在时间合作博弈（TCG）中，当参与者按顺序到达时，满足激励最优到达（I4OA）、在线个体理性（OIR）和序列效率（SE）等时间属性的奖励分配机制，与基于Shapley值的经典机制存在根本性的差异和冲突。这一发现揭示了在序贯到达场景下，公平性和效率的分配原则需要重新考量，并为未来在TCG中定义新的解决方案概念指明了方向。

Abstract: Classical cooperative game theory assumes that the worth of a coalition
depends only on the set of agents involved, but in practice, it may also depend
on the order in which agents arrive. Motivated by such scenarios, we introduce
temporal cooperative games (TCG), where the worth $v$ becomes a function of the
sequence of agents $\pi$ rather than just the set $S$. This shift calls for
rethinking the underlying axioms. A key property in this temporal framework is
the incentive for optimal arrival (I4OA), which encourages agents to join in
the order maximizing total worth. Alongside, we define two additional
properties: online individual rationality (OIR), incentivizing earlier agents
to invite more participants, and sequential efficiency (SE), ensuring that the
total worth of any sequence is fully distributed among its agents. We identify
a class of reward-sharing mechanisms uniquely characterized by these three
properties. The classical Shapley value does not directly apply here, so we
construct its natural analogs in two variants: the sequential world, where
rewards are defined for each sequence-player pair, and the extended world,
where rewards are defined for each player alone. Properties of efficiency,
additivity, and null player uniquely determine these Shapley analogs in both
worlds. Importantly, the Shapley analogs are disjoint from mechanisms
satisfying I4OA, OIR, and SE, and this conflict persists even for restricted
classes such as convex and simple TCGs. Our findings thus uncover a fundamental
tension: when players arrive sequentially, reward-sharing mechanisms satisfying
desirable temporal properties must inherently differ from Shapley-inspired
ones, opening new questions for defining fair and efficient solution concepts
in TCGs.

</details>


### [522] [On the Complexity of Stationary Nash Equilibria in Discounted Perfect Information Stochastic Games](https://arxiv.org/abs/2510.11550)
*Kristoffer Arnsfelt Hansen,Xinhao Nie*

Main category: cs.GT

TL;DR: 该论文研究了在计算复杂度方面，如何计算具有折扣的完美信息随机博弈中的平稳纳什均衡。


<details>
  <summary>Details</summary>
Motivation: 研究计算平稳纳什均衡的计算复杂度。

Method: 对于两人博弈，将问题归类为PPAD；对于三人博弈，构造了不存在有理值平稳纳什均衡的博弈；对于四人博弈，证明了计算平稳纳什均衡的SqrtSum-硬度。

Result: 两人博弈的平稳纳什均衡计算是PPAD完全问题。三人博弈不保证存在有理值平稳纳什均衡。四人博弈的平稳纳什均衡计算是SqrtSum-硬的。

Conclusion: 该研究精确地界定了两人、三人和四人随机博弈中计算平稳纳什均衡的计算复杂度。

Abstract: We study the problem of computing stationary Nash equilibria in discounted
perfect information stochastic games from the viewpoint of computational
complexity. For two-player games we prove the problem to be in PPAD, which
together with a previous PPAD-hardness result precisely classifies the problem
as PPAD-complete. In addition to this we give an improved and simpler
PPAD-hardness proof for computing a stationary epsilon-Nash equilibrium. For
3-player games we construct games showing that rational-valued stationary Nash
equilibria are not guaranteed to exist, and we use these to prove
SqrtSum-hardness of computing a stationary Nash equilibrium in 4-player games.

</details>


### [523] [Multiwinner Voting with Interval Preferences under Incomplete Information](https://arxiv.org/abs/2510.11625)
*Drew Springham,Edith Elkind,Bart de Keijzer,Maria Polukarov*

Main category: cs.GT

TL;DR:  voters with one-dimensional preferences, an algorithm for computing committees that provide Proportional Justified Representation + (PJR+) is presented, which makes O(log(σ⋅k)) queries per voter in expectation.


<details>
  <summary>Details</summary>
Motivation: In multiwinner approval elections with many candidates, voters may struggle to determine their preferences over the entire slate of candidates. It is therefore of interest to explore which (if any) fairness guarantees can be provided under reduced communication.

Method: We put forward a probabilistic preference model, where the voter set consists of σ different groups; each group is associated with a distribution over an interval of ℝ, so that each voter draws the endpoints of her approval interval from the distribution associated with her group. We present an algorithm for computing committees that provide Proportional Justified Representation + (PJR+), which proceeds by querying voters' preferences.

Result: The algorithm makes O(log(σ⋅k)) queries per voter in expectation, where k is the desired committee size.

Conclusion: The proposed algorithm provides a fair and efficient way to compute committees in multiwinner approval elections with one-dimensional preferences and reduced communication.

Abstract: In multiwinner approval elections with many candidates, voters may struggle
to determine their preferences over the entire slate of candidates. It is
therefore of interest to explore which (if any) fairness guarantees can be
provided under reduced communication. In this paper, we consider voters with
one-dimensional preferences: voters and candidates are associated with points
in $\mathbb R$, and each voter's approval set forms an interval of $\mathbb R$.
We put forward a probabilistic preference model, where the voter set consists
of $\sigma$ different groups; each group is associated with a distribution over
an interval of $\mathbb R$, so that each voter draws the endpoints of her
approval interval from the distribution associated with her group. We present
an algorithm for computing committees that provide Proportional Justified
Representation + (PJR+), which proceeds by querying voters' preferences, and
show that, in expectation, it makes $\mathcal{O}(\log( \sigma\cdot k))$ queries
per voter, where $k$ is the desired committee size.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [524] [Nonlinear Strain-Mediated Magnetoelectric Coupling in Sub-Microscale Ni/BPZT Thin-Film Devices](https://arxiv.org/abs/2510.09795)
*Fanfan Meng,Emma Van Meirvenne,Federica Luciano,Xiangyu Wu,Yves Deblock,Kaustuv Banerjee,Peter Rickhaus,Florin Ciubotaru,Christoph Adelmann*

Main category: physics.app-ph

TL;DR: 本研究利用Ni/BPZT薄膜异质结构和侧向栅极，实现了亚微米尺度下低电压、空间选择性的磁电耦合，并建立了量化模型，为设计低功耗自旋电子器件提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 在薄膜器件中实现空间选择性、低电压控制磁性以及量化铁弹磁滞回线上的磁电耦合仍然是一个挑战。

Method: 研究了具有侧向栅极的亚微米Ni/BPZT薄膜器件，利用各向异性磁阻测量磁化强度变化，结合多物理场应变模拟和微磁建模，建立了量化模型。

Result: 提取的线性范围内的耦合系数为1.3 mT/V（跨越700 nm间隙），并展示了通过器件缩放提高电压效率的途径，为构建可扩展的、与CMOS兼容的、能源高效的自旋电子器件平台奠定了基础。

Conclusion: 所提出的方法能够量化铁弹和磁弹非线性的卷积，为器件设计提供了关键见解，并实现了多态、无偏磁场的磁化控制，可用于非常规计算。

Abstract: Strain-mediated magnetoelectric (ME) heterostructures enable electric-field
control of magnetism and are promising for ultra-low-power spintronic logic.
Yet achieving spatially selective, low-voltage control in thin films and
quantifying ME coupling across the full ferroelastic loop remains challenging.
Here, we investigate sub-micrometer Ni/BPZT thin-film devices with laterally
patterned gates that localize in-plane strain beneath the Ni stripe and
modulate its magnetization. We use anisotropic magnetoresistance to measure
magnetization changes across the ferroelastic loop under different magnetic
bias fields. Combined with Multiphysics strain simulations and micromagnetic
modeling, this provides a quantitative framework that captures the convolution
of ferroelastic and magnetoelastic nonlinearities and provides critical insight
for device design, while enabling multi-state, bias-field-free magnetization
control for non-conventional computing. The extracted coupling coefficient in
linear range is 1.3 mT/V across a 700 nm gap, with a clear pathway to improving
voltage efficiency through device scaling, establishing a scalable
CMOS-compatible platform for energy-efficient spintronic devices.

</details>


### [525] [Experimental Characterization and Dynamic Modeling of THz Channels Under Fog Conditions](https://arxiv.org/abs/2510.09906)
*Jiaobiao Zhao,Kefeng Huang,Xiaoxiang Li,Mingxia Zhang,Peian Li,Jie Yang,Wenbo Liu,Yiming Zhao,Weidong Hu,Jianjun Ma*

Main category: physics.app-ph

TL;DR: 太赫兹通信在6G中前景广阔，但户外雾环境下的信道衰减难以预测。本文提出了一种动态信道模型，该模型由雾的液滴尺寸分布（DSD）驱动，并结合了微物理传感。实验在220 GHz和320 GHz下进行，结果表明信道损耗主要由吸收引起，且瑞利近似在1 THz以下有效。THz信道在浓雾中仍保持良好的视距（LOS）稳定性，Rician K因子很高。系统性能分析表明，误比特率（BER）的下降是由DSD的缓慢演变驱动的，而非快速的man-in-the-middle衰落。这使得THz雾信道可以被简化为一个具有时变信噪比（SNR）的近高斯模型，为未来的THz网络设计提供了基础。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络的发展需要考虑太赫兹（THz）频段在户外环境下的应用，但雾等气象现象会导致信道衰减且难以预测，因此需要研究能够应对这些挑战的动态信道模型。

Method: 提出了一种由雾的液滴尺寸分布（DSD）动态驱动的THz频段动态信道模型，并结合了实时微物理传感。通过在控制的雾箱和房间规模的设置中进行220 GHz和320 GHz的实验测量，研究了准稳态和动态非稳态雾演化下的信道特性。

Result: 实验结果证实，信道功率损耗主要由吸收而非散射引起，并且在1 THz以下可以使用计算效率高的瑞利近似。统计分析显示THz信道在浓雾中仍具有很高的视距（LOS）稳定性，Rician K因子非常高。系统级性能分析表明，误比特率（BER）的下降是由DSD的缓慢演变驱动的，而不是由快速的多径衰落引起的。

Conclusion: 所提出的微物理感知方法支持将THz雾信道简化为一个具有时变信噪比（SNR）的近高斯模型，这为开发基于SNR跟踪的自适应系统设计奠定了基础，以实现可靠的未来THz网络。

Abstract: The terahertz (THz) band is a promising candidate for sixth-generation
wireless networks, but its deploymen in outdoor environments is challenged by
meteorological phenomena, particularly fog, which imposes variable and
difficult-to-predict channel degradation. This article introduces dynamic
channel model for the THz band explicitly driven by the time-evolving droplet
size distribution (DSD) of fog, integrating real-time microphysical sensing to
capture variations in the fog microstructure. Experimental measurements were
conducted at 220 GHz and 320 GHz in a controlled fog chamber to achieve
quasi-stationary states, and a larger room-scale setup to characterize dynamic,
non-stationary fog evolution. The results confirm that channel power loss is
overwhelmingly dominated by absorption rather than scattering, validating the
use of the computationally efficient Rayleigh approximation below 1 THz.
Statistical analysis revealed exceptionally high Rician K-factors,
demonstrating that THz channels maintain strong line-of-sight stability even in
dense fog. System-level performance analysis shows that degradation in bit
error rate is driven by the slow, gradual evolution of the DSD, rather than
fast multipath fading. This finding enables the reliable simplification of the
THz fog channel into a near-Gaussian channel model with time-varying
signal-to-noise ratio. This microphysics-aware approach established here
provides the necessary foundation for developing adaptive system designs
centered on SNR tracking for robust future THz networks.

</details>


### [526] [Spin Fluctuations-induced Unconventional Transverse Spin Current in Spin Degenerate Antiferromagnet](https://arxiv.org/abs/2510.09964)
*Cuimei Cao,Meng Zhu,Shiwei Chen,Yizhuo Song,Xiaoyu Feng,Zhenzhong Yang,Yihan Wang,Shiheng Liang,Qingfeng Zhan,Jia Zhang,Long You*

Main category: physics.app-ph

TL;DR: 在具有特定对称性破缺的自旋分裂反铁磁体（AFM）中，人们发现可以产生用于自旋轨道扭矩（SOT）应用的非常规自旋流。然而，这些AFM仅限于有限的材料候选。这项研究揭示了在具有常规自旋简并性的AFM在有限温度下，通过自旋涨落诱导产生非常规横向自旋流。研究以L10-MnPt为例，在异质结构中通过MnPt作为自旋流源，实现了垂直磁化在无磁场下的开关，利用了具有y和z自旋极化的自旋流，产生了面外反阻尼型SOT。


<details>
  <summary>Details</summary>
Motivation: 为了在现代磁性存储技术中实现垂直磁化确定性开关，需要非常规横向自旋流。

Method: 研究人员通过对称性分析和实验表征，研究了在L10-MnPt中，当其Néel矢量沿[110]方向时，由自旋涨落诱导产生的横向自旋流。

Result: 研究发现，在有限温度下，常规自旋简并反铁磁体（AFM）中存在由自旋涨落诱导产生的非常规横向自旋流。在L10-MnPt异质结构中，利用MnPt作为自旋流源，实现了垂直磁化在无磁场下的开关，通过面外反阻尼型SOT，利用了具有y和z自旋极化的自旋流。该自旋流表现出随电流方向变化的各向异性。

Conclusion: 在常规自旋简并反铁磁体中，存在由自旋涨落诱导产生的非常规横向自旋流，这为自旋电子学应用提供了新的可能性。

Abstract: Modern magnetic memory technology requires unconventional transverse spin
current to achieve deterministic switching of perpendicular magnetization. Spin
current in antiferromagnets (AFMs) has been long thought to be trivial as
nonmagnets. Recently, a class of spin-splitting AFMs has been shown to be able
to generate unconventional spin current for spin-orbit torque (SOT)
applications. However, such AFMs requires specific symmetry breaking, and have
been largely restricted by the limited material candidates. Here, we reveal
universal spin fluctuation-induced unconventional transverse spin current in
conventional spin degenerate AFMs at finite temperature by taking collinear
(AFM) L10-MnPt as an example. The field-free switching of perpendicular
magnetization was achieved via out-of-plane anti-damping-like SOT, leveraging
the spin current with both y- and z-spin polarizations in heterostructures with
MnPt functioning as spin current source. Based on symmetry analyses and
experimental characterizations of current-induced spin torques, we find that
the spin current generated by L10-MnPt exhibits anisotropy that varies with the
current direction, enforced by the low symmetry magnetic point group when its
N\'eel vector is along [110]. From a fundamental perspective, it would be
intriguing to uncover a mechanism underlying the emergence of unconventional
spin currents in spin degenerate antiferromagnets, which is highly desirable
for spintronic applications.

</details>


### [527] [Material combination optimization for brazed ceramic-metal composites using Artificial Intelligence](https://arxiv.org/abs/2510.10128)
*Sunita Khod,Vinay Kamma,Ravi Kumar Verma,Mayank Goswami*

Main category: physics.app-ph

TL;DR: 本文提出了一种基于人工智能（AI）的陶瓷-金属复合材料钎焊接头预测方法，并对比了多种机器学习（ML）和深度学习（DL）模型。


<details>
  <summary>Details</summary>
Motivation: 为了预测陶瓷-金属复合材料钎焊接头的性能，并比较不同AI模型的效果。

Method: 通过收集材料属性（热膨胀系数、分子量）和有限元分析得到的应力数据作为输入，训练和评估了多种ML/DL模型（包括多输出模型AE），并使用k折交叉验证和9种不同的输入-输出特征配置进行测试。

Result: 多项式回归（PR）在单输出预测任务中表现最佳，均方误差（MSE）为0.01。然而，在多输出预测任务中，具有32-16-32结构的自编码器（AE）模型表现更优，MSE为0.04%，且能准确预测所有输出特征，而PR模型在预测低重要性多输出特征时失败。AE模型预测的材料属性与文献值的平均误差在~0.16-3.78%之间。

Conclusion: 所开发的AE模型在预测陶瓷-金属复合材料钎焊接头的多种材料属性方面表现出色，能够准确处理单输出和多输出预测任务，优于传统的ML模型。

Abstract: This study proposes an Artificial Intelligence (AI) driven methodology for
predicting a combination of brazed ceramic-metal composite materials. Multiple
machine learning (ML) algorithms are compared with the deep learning (DL)
model. The developed models are tested using k-fold validation. Nine different
input-output feature configurations are evaluated to assess the model
performance. The input-output feature comprises material properties, namely,
the coefficient of thermal expansion (CTE) and molecular mass of brazed
ceramic-metal composite materials obtained from literature and the strength
parameter (average Von Mises Stress (VMS)) estimated from Finite Element Method
(FEM) simulation for joint assembly structure. A multi-output model,
Autoencoder (AE), has also been developed and tested to predict various
features. The ML model, namely the polynomial regression (PR), outperforms the
other ML/DL models with a Mean square Error (MSE) of 0.01 for the test data.
The autoencoder model with a 32-16-32 structure outperforms LR, PR, RF, and ANN
with an MSE of 0.04% for the prediction of unseen data. The developed
multi-output model accurately predicts all the features (single and multiple),
while PR fails to accurately predict multi-output features of low importance.
The developed AE model predicts the different material properties with an
average error of ~0.16-3.78% with literature-reported values.

</details>


### [528] [A Bioinspired Aquatic Machine Mimicking Water Caltrop](https://arxiv.org/abs/2510.10686)
*Yuanquan Liu,Thomas Speck,Isabella Fiorello*

Main category: physics.app-ph

TL;DR: 该研究受水葫芦（T. natans）果实的启发，设计了一种能够被动分散的水生仿生机器，并使用3D打印技术制造了两种模型（中空和实心），通过了流动室的测试，为水下、软体和微型机器人设计提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 从水葫芦（T. natans）果实的结构和分散机制中汲取灵感，设计能够适应水生环境的仿生机器。

Method: 收集水葫芦果实样本，利用X射线显微CT等技术提取几何特征，使用光固化水凝胶进行3D打印制造仿生机器（中空和实心），并通过压缩测试表征材料力学性能，最后在流动室中评估了仿生机器的浮动行为。

Result: 成功制造了两种配置（中空和实心）的水生仿生机器，并通过了流动室的测试，证明了其在水生环境中的适应性。

Conclusion: 这种仿生方法增强了机器在水生环境中的适应性，为水下、软体和微型机器人的设计提供了新的见解。

Abstract: Plants are increasingly becoming a source of inspiration for robotics and
engineers to develop bioinspired, adaptive, and multifunctional machines. In
this study, we propose a bioinspired aquatic machine that mimics the fruit of
the water caltrop (Trapa natans L.). Among various plant species, T. natans
produces unique woody fruits that can disperse passively via water currents or
by clinging to boats or waterfowls. Inspired by the structures and dispersal
mechanisms of T. natans, we designed miniaturized biomimetic machines capable
of passive dispersion in aquatic ecosystems. In order to study our selected
biological model, we collected natural fresh and dried mature samples of T.
natans fruits. We designed biomimetic aquatic machines by extracting the main
geometrical details from the natural samples, and by exploiting advanced
three-dimensional reconstruction techniques, including x-ray micro-computed
topography (Micro-CT). Then, we successfully fabricate the biomimetic machines
at high-resolution in two configurations (hollow body and solid body) using
light-based bioprinting of photo-responsive hydrogels. We also characterized
the mechanical properties of the bioprinted materials through compression
tests. Finally, we evaluated the floating behavior of the biomimetic machines
in a flow chamber as a proof of concept. This biomimetic approach enhances the
adaptability of the machine in aquatic environments, offering new design
insights for underwater, soft, and microrobotics.

</details>


### [529] [A High-Performance Training-Free Pipeline for Robust Random Telegraph Signal Characterization via Adaptive Wavelet-Based Denoising and Bayesian Digitization Methods](https://arxiv.org/abs/2510.10752)
*Tonghe Bai,Ayush Kapoor,Na Young Kim*

Main category: physics.app-ph

TL;DR: 该研究提出了一种结合双树复小波变换（DTCWT）去噪和贝叶斯数字化的信号处理流程，用于分析随机电报信号（RTS），以应对多层次结构或噪声干扰的挑战。


<details>
  <summary>Details</summary>
Motivation: 随机电报信号（RTS）分析对于表征物理、化学和生物系统中重要的时间波动至关重要，但当信号出现多层次结构或受到白噪声/粉红噪声干扰时，分析会变得复杂。

Method: 该方法结合了自适应双树复小波变换（DTCWT）去噪和贝叶斯数字化策略。DTCWT去噪器能够自动选择分解层数和阈值，优化白噪声抑制。贝叶斯数字化器能有效解析二元陷阱状态，即使在存在粉红噪声的情况下。

Result: 该流程在不同噪声水平和多陷阱场景下表现出鲁棒性，提高了平均驻留时间估计和RTS重构的准确性，优于传统和神经网络方法。该方法速度提高了83倍，无需训练，适用于实时或大规模分析。

Conclusion: 该研究提出的信号处理流程为未来全自适应和自动化RTS分析管道奠定了坚实的基础，在通用性、速度和可靠性方面得到验证。

Abstract: Random telegraph signal (RTS) analysis is increasingly important for
characterizing meaningful temporal fluctuations in physical, chemical, and
biological systems. The simplest RTS arises from discrete stochastic switching
events between two binary states, quantified by their transition amplitude and
dwell times in each state. Quantitative analysis of RTSs provides valuable
insights into microscopic processes such as charge trapping in semiconductors.
However, analyzing RTS becomes considerably complex when signals exhibit
multi-level structures or are corrupted by background white or pink noise. To
address these challenges and support high-throughput RTS analysis, we introduce
a modular and scalable signal processing pipeline combining dual-tree complex
wavelet transform (DTCWT) denoising with a Bayesian digitization strategy. The
adaptive DTCWT-based denoiser incorporates autonomous parameter selection rules
for its decomposition level and thresholds, optimizing white noise suppression
without manual tuning. Complementing this denoiser, our probabilistic digitizer
effectively resolves binary trap states even under residual notorious
background pink noise. The overall approach enables robust performance across
varying noise levels and multi-trap scenarios, improving mean dwell time
estimation and RTS reconstruction over classical and neural baselines. The
method is up to 83x faster, training-free, and suitable for real-time or
large-scale analysis. Evaluations confirm its generalizability, speed, and
reliability, providing a strong foundation for future fully adaptive and
automated RTS pipelines.

</details>


### [530] [Loss investigations of high frequency lithium niobate Lamb wave resonators at ultralow temperatures](https://arxiv.org/abs/2510.10983)
*Wenbing Jiang,Xuankai Xu,Jiazhen Pan,Hancong Sun,Yu Guo,Huabing Wang,Libing Zhou,Tao Wu*

Main category: physics.app-ph

TL;DR: Lamb wave resonators (LWRs) are good for aerospace communication, but their properties at low temperatures are not well understood. This paper studies LWRs at millikelvin temperatures, finding that quality factors increase with cooling for A1 modes and show non-monotonic behavior for A3 modes. This research helps with quantum acoustics and satellite communication.


<details>
  <summary>Details</summary>
Motivation: Aerospace communication systems require robust acoustic platforms like Lamb wave resonators (LWRs) for microwave-optical transduction and RF front-ends. Understanding LWR properties at ultralow temperatures is crucial for their effective implementation, but this area remains underexplored.

Method: This study experimentally investigates the temperature dependence of the quality factor and resonant frequency in higher order antisymmetric LWRs from room temperature down to millikelvin temperatures. Specifically, high-frequency A1 and A3 mode resonators with spurious-free responses were designed, fabricated, and characterized.

Result: The quality factors of A1 mode resonators gradually increase upon cryogenic cooling, achieving a value four times higher than at room temperature. In contrast, A3 mode resonators exhibit a non-monotonic temperature dependence. These findings offer new insights into the loss mechanisms of cryogenic LWRs.

Conclusion: This research provides crucial insights into the behavior of Lamb wave resonators at cryogenic temperatures, highlighting their potential for enhanced performance in aerospace applications. The observed temperature dependencies of quality factors and resonant frequencies pave the way for advancements in strong-coupling quantum acoustodynamics and next-generation satellite wireless communications.

Abstract: Lamb wave resonators (LWRs) operating at ultralow temperatures serve as
promising acoustic platforms for implementing microwave-optical transduction
and radio frequency (RF) front-ends in aerospace communications because of the
exceptional electromechanical coupling (k^2) and frequency scalability.
However, the properties of LWRs at cryogenic temperatures have not been well
understood yet. Herein, we experimentally investigate the temperature
dependence of the quality factor and resonant frequency in higher order
antisymmetric LWRs down to millikelvin temperatures. The high-frequency A1 and
A3 mode resonators with spurious-free responses are comprehensively designed,
fabricated, and characterized. The quality factors of A1 modes gradually
increase upon cryogenic cooling and shows 4 times higher than the room
temperature value, while A3 mode resonators exhibit a non-monotonic temperature
dependence. Our findings provide new insights into loss mechanisms of cryogenic
LWRs, paving the way to strong-coupling quantum acoustodynamics and
next-generation satellite wireless communications.

</details>


### [531] [A variational phase-field model for anisotropic fracture accounting for multiple cohesive lengths](https://arxiv.org/abs/2510.11309)
*Angela Maria Fajardo Lacave,Francesco Vicentini,Fabian Welschinger,Laura De Lorenzis*

Main category: physics.app-ph

TL;DR: 提出了一种新颖的各向异性材料断裂变分相场模型，该模型通过多内聚函数实现裂纹形核的灵活校准，并能在主要材料方向上独立控制内聚长度，从而独立控制裂纹形核和扩展。


<details>
  <summary>Details</summary>
Motivation: 现有各向异性断裂模型在裂纹形核校准方面不够灵活，且可能引入多个损伤变量。本研究旨在提出一种更灵活的模型，避免引入多个损伤变量。

Method: 提出了一种多内聚模型，通过各向异性弹性、利用二阶结构张量扩展断裂能密度以及引入具有潜在不同内聚长度的多内聚函数来实现断裂各向异性。

Result: 分析了模型的齐次解及其二阶稳定性，并将所得强度面与文献中两种代表性的各向异性相场模型进行了比较。数值模拟表明，该模型能够独立控制裂纹形核和扩展。

Conclusion: 所提出的多内聚相场模型能够独立控制各向异性材料中裂纹的形核和扩展，为各向异性断裂问题的研究提供了新的方法。

Abstract: We propose a novel variational phase-field model for fracture in anisotropic
materials. The model is specifically designed to allow a more flexible
calibration of crack nucleation than existing anisotropic fracture
formulations, while avoiding the introduction of multiple damage variables. In
addition to the classical components of anisotropic phase-field models based on
a single damage variable -- namely, anisotropic elasticity and the extension of
the fracture energy density via a second-order structural tensor -- the
proposed approach introduces fracture anisotropy through a cohesive degradation
function with potentially distinct cohesive lengths along the principal
material directions. For this reason, we refer to it as multi-cohesive model.
This feature enables independent control of the critical stresses governing
crack nucleation in each material direction. We analyze the homogeneous
solution and its second-order stability, and we compare the resulting strength
surfaces with those of two representative anisotropic phase-field models
available in the literature. Finally, numerical simulations in two and three
dimensions demonstrate the capability of the proposed model to independently
control crack nucleation and propagation in anisotropic fracture problems of
increasing complexity.

</details>


### [532] [Raman Microspectroscopy for Real-Time Structure Indicator in Ultrafast Laser Writing](https://arxiv.org/abs/2510.11422)
*Xingrui Cheng,Eugenio Picheo,Zhixin Chen,Martin J. Booth,Patrick S. Salter,Álvaro Fernández-Galiana*

Main category: physics.app-ph

TL;DR: 本研究提出了一种不依赖于样品的拉曼光谱分析方法，用于实时监测飞秒激光加工过程，并通过金刚石的实验验证了其有效性，可将拉曼光谱信息直接转化为器件规格，并推广应用于其他激光写入结构的在线质量控制。


<details>
  <summary>Details</summary>
Motivation: 为了实现飞秒激光制造过程的无损、结构特异性在位监测，开发一种通用的拉曼光谱分析方法。

Method: 提出了一种不依赖于样品的拉曼光谱分析工作流程，使用抗漂移、自归一化指标筛选候选光谱指示剂，并在适当时采用无标记高光谱解混提取端元并验证指标选择。以金刚石为例，通过高光谱成像和电气测试，发现1332 cm-1 sp3谱线的消耗是电阻的单调、可靠预测因子，优于通常认为最优的sp2基度量。

Result: 通过对金刚石的研究发现，1332 cm-1 sp3谱线的消耗是电阻的可靠预测指标，并且单通道窄带测量即可实现实时反馈，无需全光谱采集。

Conclusion: 该方法通过通用的谱带定义和功能验证，将拉曼光谱信息直接转化为器件规格，适用于其他拉曼活性材料的激光写入结构的在线质量控制。

Abstract: Raman microspectroscopy provides non-destructive, structure-specific contrast
suited to in situ monitoring of femtosecond (fs) laser fabrication processes.
In this work, we introduce a sample-agnostic Raman workflow that screens
candidate spectral indicators using drift-resistant, self-normalized metrics
and, where appropriate, label-free hyperspectral unmixing to extract endmembers
and validate metric selection. Using diamond as an example, hyperspectral maps
and electrical tests show that depletion of the 1332 cm-1 sp3 line is a
monotonic, robust predictor of resistance, counterintuitively outperforming
sp2-based measures often assumed optimal. This enables a practical
implementation: a single narrowband channel at the selected marker provides
real-time feedback without full-spectrum acquisition. Because the selection
hinges on general band definitions and functional validation rather than
diamond-specific physics, the approach translates Raman phase information
directly into device specifications and is transferable to other Raman-active
hosts for in-line quality control of laser-written structures.

</details>


### [533] [Unlocking High-Throughput Heterojunction Discovery](https://arxiv.org/abs/2510.11548)
*Thomas W. Gries,Davide Regaldo,Yanyan Duan,Florian Scheler,Maxim Simmonds,Valerio Stacchini,Annamaria Petrozza,Eva Unger,Antonio Abate,Jean-Paul Kleider,Artem Musiienko*

Main category: physics.app-ph

TL;DR: 在存在电荷选择性接触的情况下，光致发光（PL）会失去其预测可靠性，甚至可能在高效光伏器件的开路条件下表现出强烈的猝灭。本研究结合稳态和瞬态PL以及非接触瞬态表面光电压测量，解开提取和复合的交织过程，阐明了这种现象的物理起源，并提出了一种适用于各种光电器件的异质结分类和PL解释决策树。


<details>
  <summary>Details</summary>
Motivation: 光致发光（PL）通常用作光电器件材料质量的指标，但研究发现，在存在电荷选择性接触的情况下，PL会失去预测可靠性，甚至在高效光伏器件的开路条件下出现强烈的猝灭。因此，需要一种新的方法来准确评估材料质量。

Method: 结合稳态和瞬态光致发光（PL）测量以及非接触瞬态表面光电压测量，以解开电荷提取和复合过程。此外，还构建了界面的数字模型，以识别导致电荷提取后猝灭的基本机制。

Result: 发现电荷提取和复合过程相互交织，PL单独测量无法完全捕捉到提取动力学。数字模型表明，库仑吸引和界面复合是导致电荷提取后猝灭的主要原因。研究提出了一个决策树，用于对异质结进行分类和解释PL测量结果，该树可应用于光伏、光电探测器和LED等领域。

Conclusion: 本研究提出的方法能够准确解释PL测量结果，并有助于优化材料和器件的开发，弥合材料发现和器件发现之间的差距。

Abstract: Photoluminescence (PL) is a ubiquitous proxy for material quality in
optoelectronic devices, widely used for high-throughput materials discovery.
However, we demonstrate that in the presence of charge-selective contacts, PL
loses its predictive reliability and can exhibit strong quenching even in
highly efficient photovoltaic devices under open-circuit conditions. By
combining steady-state and transient PL with contactless transient surface
photovoltage measurements we disentangle the intertwined processes of
extraction and recombination, clarifying the physical origin of this
phenomenon. This joint approach reveals extraction dynamics not captured by PL
alone. A digital replica of the interface shows that Coulomb attraction and
interfacial recombination are the fundamental mechanisms driving quenching
after charge extraction. Based on these insights, we present a decision tree
for heterojunction classification and PL interpretation applicable across
diverse optoelectronic systems, including photovoltaics, photodetectors, and
LEDs. Our approach supports systematic screening and optimization of
half-devices, bridging the gap between accelerated materials discovery and
accelerated device discovery.

</details>


### [534] [Elastic Rod Origami (RodOri) for Programming Static and Dynamic Mechanical Properties](https://arxiv.org/abs/2510.11568)
*Sophie Leanza,Jeseung Lee,Ruike Renee Zhao*

Main category: physics.app-ph

TL;DR: 弹性杆折纸（RodOri）平台利用预应力弯曲的杆件，实现高度多稳态和丰富的构型，可用于可重构结构、软体机器人和自适应材料等领域。


<details>
  <summary>Details</summary>
Motivation: 开发一种能实现精确可编程控制的机械系统，以在结构特性方面提供新的机遇，应用于结构材料、自适应设备和多功能结构。

Method: 通过将预应力、自然弯曲的杆件组合成弹性杆折纸（RodOri）系统，利用杆件在夹紧边界条件下发生的离散形态变化，实现多稳态和可编程的静态及动态机械行为。

Result: 单个6杆RodOri单元可实现11种不同构型，并可用于实现可调的静态刚度、非线性力响应，以及可调的动态行为，如振动过滤、波传播切换和模态转换。

Conclusion: RodOri平台通过利用曲率引起的机械不稳定性，实现了高度可编程的静态和动态机械行为，为可重构结构、软体机器人、医疗设备和自适应材料提供了新的设计策略。

Abstract: Reconfigurable mechanical systems enable precise programmable control over
structural properties, opening new opportunities in architected materials,
adaptive devices, and multifunctional structures. Here, we introduce elastic
rod origami (RodOri), a platform that exploits remarkably simple elements
(pre-stressed, naturally curved rods) into a system with an extraordinary
degree of multistability and configurational richness. For example, a single
6-rod RodOri unit can easily access 11 distinct configurations, far exceeding
the reconfigurability of conventional origami or general mechanical
reconfigurable systems. Individual rods, constrained under clamped boundary
conditions, undergo snapping transitions between discrete morphologies whose
strain energy and stiffness are precisely prescribed by their natural
curvature. Assembling these rods into modular multi-rod architectures yields
metamaterials with numerous stable configurations that can be selectively and
reversibly programmed. This configurational diversity enables tunable static
stiffness, nonlinear force response, and thus enables tunable dynamic behaviors
such as vibration filtering, wave-propagation switching, and mode conversion
within a single, easily-manufactured platform. By leveraging curvature-induced
mechanical instability, RodOri unlocks highly programmable static and dynamic
mechanical behavior, offering new design strategies in reconfigurable
structures, soft robotics, medical devices, and adaptive materials.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [535] [Distributed clustering in partially overlapping feature spaces](https://arxiv.org/abs/2510.09799)
*Alessio Maritan,Luca Schenato*

Main category: cs.DS

TL;DR: 提出了一种新颖的分布式聚类问题，参与者拥有包含部分特征的私有数据集，并提出了两种解决该问题的算法：一种是联邦算法，另一种是单次算法。


<details>
  <summary>Details</summary>
Motivation: 解决分布式聚类问题，其中每个参与者的数据集只包含部分特征，且部分特征在多个数据集中存在，这种情况常见于医疗保健等领域。

Method: 提出两种算法：1. 联邦算法：参与者协作更新全局质心。2. 单次算法：参与者分享本地聚类的统计参数，由中央服务器生成和合并代理数据集。两种算法都允许参与者自由选择本地聚类方法。

Result: 在三种公共数据集上测试了所提出算法的实际性能。

Conclusion: 在满足特定条件下，所提出的算法有望收敛到最优的集中式解决方案。

Abstract: We introduce and address a novel distributed clustering problem where each
participant has a private dataset containing only a subset of all available
features, and some features are included in multiple datasets. This scenario
occurs in many real-world applications, such as in healthcare, where different
institutions have complementary data on similar patients. We propose two
different algorithms suitable for solving distributed clustering problems that
exhibit this type of feature space heterogeneity. The first is a federated
algorithm in which participants collaboratively update a set of global
centroids. The second is a one-shot algorithm in which participants share a
statistical parametrization of their local clusters with the central server,
who generates and merges synthetic proxy datasets. In both cases, participants
perform local clustering using algorithms of their choice, which provides
flexibility and personalized computational costs. Pretending that local
datasets result from splitting and masking an initial centralized dataset, we
identify some conditions under which the proposed algorithms are expected to
converge to the optimal centralized solution. Finally, we test the practical
performance of the algorithms on three public datasets.

</details>


### [536] [Combinatorial Philosopher Inequalities](https://arxiv.org/abs/2510.10039)
*Enze Sun,Zhihao Gavin Tang,Yifan Wang*

Main category: cs.DS

TL;DR: 本文研究在线组合分配问题，为XOS和次模估值代理设计了新的近似算法，并分析了在线配置LP的积分隙。


<details>
  <summary>Details</summary>
Motivation: 本文旨在设计近似算法，以克服在线组合分配问题中代理排序带来的挑战，并超越现有算法的性能瓶颈。

Method: 对于次模估值代理，本文建立了一个$0.5 + inom{	o}{1}$近似比。对于XOS估值代理，本文证明了在线配置LP的$0.5$积分隙。

Result: 本文为次模估值代理提供了$0.5 + inom{	o}{1}$的近似比，并为XOS估值代理证明了在线配置LP的$0.5$积分隙。

Conclusion: 本文为在线组合分配问题中的次模代理提供了新的近似算法，并揭示了在线配置LP在处理XOS代理时的局限性。

Abstract: In online combinatorial allocation, agents arrive sequentially and items are
allocated in an online manner. The algorithm designer only knows the
distribution of each agent's valuation, while the actual realization of the
valuation is revealed only upon her arrival. Against the offline benchmark,
Feldman, Gravin, and Lucier (SODA 2015) designed an optimal $0.5$-competitive
algorithm for XOS agents. An emerging line of work focuses on designing
approximation algorithms against the (computationally unbounded) optimal online
algorithm. The primary goal is to design algorithms with approximation ratios
strictly greater than $0.5$, surpassing the impossibility result against the
offline optimum. Positive results are established for unit-demand agents
(Papadimitriou, Pollner, Saberi, Wajc, MOR 2024), and for $k$-demand agents
(Braun, Kesselheim, Pollner, Saberi, EC 2024).
  In this paper, we extend the existing positive results for agents with
submodular valuations by establishing a $0.5 + \Omega(1)$ approximation against
a newly constructed online configuration LP relaxation for the combinatorial
allocation setting. Meanwhile, we provide negative results for agents with XOS
valuations by providing a $0.5$ integrality gap for the online configuration
LP, showing an obstacle of existing approaches.

</details>


### [537] [Simple Length-Constrained Expander Decompositions](https://arxiv.org/abs/2510.10227)
*Greg Bodwin,Bernhard Haeupler,D Ellis Hershkowitz,Zihan Tan*

Main category: cs.DS

TL;DR: 本文提出了一种新的图分解方法，将长度约束展开器分解的大小从 O(log n * s * n^{O(1/s)} * φ * m) 改进到 O(s * n^{O(1/s)} * φ * m)，并且在合并稀疏长度约束割时，将稀疏性损失从 O(log^3 n * s^3 * n^{O(1/s)}) 降低到 O(s * n^{O(1/s)})。


<details>
  <summary>Details</summary>
Motivation: 现有的长度约束展开器分解方法在图算法领域取得了显著进展，但其分解的大小以及合并稀疏长度约束割时的稀疏性损失仍有改进空间。

Method: 通过证明稀疏长度约束割的并集仍然是稀疏长度约束割，并改进了合并过程中的稀疏性损失。

Result: 成功将长度约束展开器分解的大小从 O(log n * s * n^{O(1/s)} * φ * m) 改进到 O(s * n^{O(1/s)} * φ * m)。同时，将合并稀疏长度约束割时的稀疏性损失从 O(log^3 n * s^3 * n^{O(1/s)}) 降低到 O(s * n^{O(1/s)})。

Conclusion: 本文提供了一种更有效的长度约束展开器分解方法，其分解大小和稀疏性损失均得到显著改善，为后续的图算法研究奠定了基础。

Abstract: Length-constrained expander decompositions are a new graph decomposition that
has led to several recent breakthroughs in fast graph algorithms. Roughly, an
$(h, s)$-length $\phi$-expander decomposition is a small collection of length
increases to a graph so that nodes within distance $h$ can route flow over
paths of length $hs$ while using each edge to an extent at most $1/\phi$. Prior
work showed that every $n$-node and $m$-edge graph admits an $(h, s)$-length
$\phi$-expander decomposition of size $\log n \cdot s n^{O(1/s)} \cdot \phi m$.
  In this work, we give a simple proof of the existence of $(h, s)$-length
$\phi$-expander decompositions with an improved size of $s n^{O(1/s)}\cdot \phi
m$. Our proof is a straightforward application of the fact that the union of
sparse length-constrained cuts is itself a sparse length-constrained cut. In
deriving our result, we improve the loss in sparsity when taking the union of
sparse length-constrained cuts from $\log ^3 n\cdot s^3 n^{O(1/s)}$ to $s\cdot
n^{O(1/s)}$.

</details>


### [538] [Explicit Min-wise Hash Families with Optimal Size](https://arxiv.org/abs/2510.10431)
*Xue Chen,Shengtang Huang,Xin Li*

Main category: cs.DS

TL;DR: 本研究提出了首个具有接近多项式最优误差的显式 k-min-wise 哈希族构造，该构造使用的随机比特数为 O(k log N)，显著优于以往所有结果。


<details>
  <summary>Details</summary>
Motivation: 寻找具有O(log N)比特（多项式大小族）和亚常数误差的min-wise哈希族构造。

Method: 利用伪随机性（特别是对组合矩形和读一次分支程序）来构造k-min-wise哈希族，并对经典Nisan-Zuckerman伪随机生成器进行了改进，以实现对min-wise哈希的乘法误差。

Result: 提出了首个显式的k-min-wise哈希族，其随机比特数为O(k log N)，误差可达2^{-O(log N/log log N)}。

Conclusion: 该研究在k-min-wise哈希族构造方面取得了重大突破，通过结合伪随机性和改进的伪随机生成器，实现了近乎最优的比特复杂度和亚常数误差，为相关应用提供了更高效的解决方案。

Abstract: We study explicit constructions of min-wise hash families and their extension
to $k$-min-wise hash families. Informally, a min-wise hash family guarantees
that for any fixed subset $X\subseteq[N]$, every element in $X$ has an equal
chance to have the smallest value among all elements in $X$; a $k$-min-wise
hash family guarantees this for every subset of size $k$ in $X$. Min-wise hash
is widely used in many areas of computer science such as sketching, web page
detection, and $\ell_0$ sampling.
  The classical works by Indyk and P\u{a}tra\c{s}cu and Thorup have shown
$\Theta(\log(1/\delta))$-wise independent families give min-wise hash of
multiplicative (relative) error $\delta$, resulting in a construction with
$\Theta(\log(1/\delta)\log N)$ random bits. Based on a reduction from
pseudorandom generators for combinatorial rectangles by Saks, Srinivasan, Zhou
and Zuckerman, Gopolan and Yehudayoff improved the number of bits to $O(\log
N\log\log N)$ for polynomially small errors $\delta$. However, no construction
with $O(\log N)$ bits (polynomial size family) and sub-constant error was known
before.
  In this work, we continue and extend the study of constructing ($k$-)min-wise
hash families from pseudorandomness for combinatorial rectangles and read-once
branching programs. Our main result gives the first explicit min-wise hash
families that use an optimal (up to constant) number of random bits and achieve
a sub-constant (in fact, almost polynomially small) error, specifically, an
explicit family of $k$-min-wise hash with $O(k\log N)$ bits and $2^{-O(\log
N/\log\log N)}$ error. This improves all previous results for any
$k=\log^{O(1)}N$ under $O(k \log N)$ bits. Our main techniques involve several
new ideas to adapt the classical Nisan-Zuckerman pseudorandom generator to fool
min-wise hashing with a multiplicative error.

</details>


### [539] [Information-Computation Tradeoffs for Noiseless Linear Regression with Oblivious Contamination](https://arxiv.org/abs/2510.10665)
*Ilias Diakonikolas,Chao Gao,Daniel M. Kane,John Lafferty,Ankit Pensia*

Main category: cs.DS

TL;DR: 高斯协变量下带噪声线性回归的样本复杂度下界


<details>
  <summary>Details</summary>
Motivation: 研究高斯协变量和可加盲污染存在下的无噪声线性回归问题，目标是准确恢复回归量β。

Method: 推导统计查询（SQ）算法的样本复杂度下界。

Result: 证明任何高效的SQ算法需要至少 VSTAT 复杂度为 Ω(d^1/2/α^2)。

Conclusion: 在高效算法（特别是SQ算法）的背景下，需要Ω(d/α^2)的样本量来解决该问题。

Abstract: We study the task of noiseless linear regression under Gaussian covariates in
the presence of additive oblivious contamination. Specifically, we are given
i.i.d.\ samples from a distribution $(x, y)$ on $\mathbb{R}^d \times
\mathbb{R}$ with $x \sim \mathcal{N}(0,\mathbf{I}_d)$ and $y = x^\top \beta +
z$, where $z$ is drawn independently of $x$ from an unknown distribution $E$.
Moreover, $z$ satisfies $\mathbb{P}_E[z = 0] = \alpha>0$. The goal is to
accurately recover the regressor $\beta$ to small $\ell_2$-error. Ignoring
computational considerations, this problem is known to be solvable using
$O(d/\alpha)$ samples. On the other hand, the best known polynomial-time
algorithms require $\Omega(d/\alpha^2)$ samples. Here we provide formal
evidence that the quadratic dependence in $1/\alpha$ is inherent for efficient
algorithms. Specifically, we show that any efficient Statistical Query
algorithm for this task requires VSTAT complexity at least
$\tilde{\Omega}(d^{1/2}/\alpha^2)$.

</details>


### [540] [Learning-Augmented Streaming Algorithms for Correlation Clustering](https://arxiv.org/abs/2510.10705)
*Yinhao Dong,Shan Jiang,Shi Li,Pan Peng*

Main category: cs.DS

TL;DR: 本研究提出了用于相关聚类的学习增强流算法，在完整图和一般图上均取得优于现有算法的近似比和空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 在给定带正负标签的边流的情况下，最小化聚类中的不一致性。

Method: 基于Cambus等人（SODA'24）和Ahn等人（ICML'15）的工作，利用成对距离预测器来指导流算法。

Result: 在完整图上，在预测质量良好时，近似比优于3，空间复杂度为~O(n)；在一般图上，在预测质量良好时，近似比为O(log |E^-|)，空间复杂度为~O(n)，优于现有的非学习算法。

Conclusion: 所提出的学习增强流算法在相关聚类问题上，尤其是在空间效率方面，优于现有的非学习算法，并在合成和真实数据集的实验中得到验证。

Abstract: We study streaming algorithms for Correlation Clustering. Given a graph as an
arbitrary-order stream of edges, with each edge labeled as positive or
negative, the goal is to partition the vertices into disjoint clusters, such
that the number of disagreements is minimized. In this paper, we give the first
learning-augmented streaming algorithms for the problem on both complete and
general graphs, improving the best-known space-approximation tradeoffs. Based
on the works of Cambus et al. (SODA'24) and Ahn et al. (ICML'15), our
algorithms use the predictions of pairwise distances between vertices provided
by a predictor. For complete graphs, our algorithm achieves a better-than-$3$
approximation under good prediction quality, while using $\tilde{O}(n)$ total
space. For general graphs, our algorithm achieves an $O(\log |E^-|)$
approximation under good prediction quality using $\tilde{O}(n)$ total space,
improving the best-known non-learning algorithm in terms of space efficiency.
Experimental results on synthetic and real-world datasets demonstrate the
superiority of our proposed algorithms over their non-learning counterparts.

</details>


### [541] [Crane Scheduling Problem with Energy Saving](https://arxiv.org/abs/2510.10989)
*Yixiong Gao,Florian Jaehn,Minming Li,Wenhao Ma,Xinbo Zhang*

Main category: cs.DS

TL;DR: 通过优化起重机调度，可以回收势能以减少能源消耗。


<details>
  <summary>Details</summary>
Motivation: 起重机在装卸集装箱时会消耗能量，并且在放下集装箱时会浪费能量。通过优化起重机调度，可以减少能源消耗，从而降低运营成本和环境影响。

Method: 提出一个考虑储区和处理长度的单起重机调度问题模型，通过将其与半欧拉化问题联系起来，设计了一个加性近似算法。然后，提出一个动态规划（DP）算法，用于处理有限能量缓冲和处理长度的情况。最后，从哈密顿路径的角度，提出了一个精确的DP算法，用于处理任意能量缓冲和处理长度的通用情况。

Result: 该研究提出了一种结合欧拉和哈密顿观点的综合方法，为解决集装箱调度问题提供了一个稳健的框架，并证明了该问题的一个变种在特定条件下是多项式可解的。

Conclusion: 该研究成功地解决了一个具有能源节约目标的单起重机调度问题，提出了一系列有效的算法，并在理论和实践上都具有重要意义。

Abstract: During loading and unloading steps, energy is consumed when cranes lift
containers, while energy is often wasted when cranes drop containers. By
optimizing the scheduling of cranes, it is possible to reduce energy
consumption, thereby lowering operational costs and environmental impacts. In
this paper, we introduce a single-crane scheduling problem with energy savings,
focusing on reusing the energy from containers that have already been lifted
and reducing the total energy consumption of the entire scheduling plan. We
establish a basic model considering a one-dimensional storage area and provide
a systematic complexity analysis of the problem. First, we investigate the
connection between our problem and the semi-Eulerization problem and propose an
additive approximation algorithm. Then, we present a polynomial-time Dynamic
Programming (DP) algorithm for the case of bounded energy buffer and processing
lengths. Next, adopting a Hamiltonian perspective, we address the general case
with arbitrary energy buffer and processing lengths. We propose an exact DP
algorithm and show that the variation of the problem is polynomially solvable
when it can be transformed into a path cover problem on acyclic interval
digraphs. We introduce a paradigm that integrates both the Eulerian and
Hamiltonian perspectives, providing a robust framework for addressing the
problem.

</details>


### [542] [Online Allocation with Concave, Diminishing-Returns Objectives](https://arxiv.org/abs/2510.11266)
*Kalen Patton*

Main category: cs.DS

TL;DR: 本文证明了具有凹形、收益递减目标的在线资源分配问题的$(1-1/e)$竞争性算法的存在性。


<details>
  <summary>Details</summary>
Motivation: 在线资源分配问题在经济学和计算机科学中是核心挑战，旨在最大化分配向量上的单调奖励函数。尽管过去的研究在特定场景下取得了显著进展，但并未解决是否存在通用的$(1-1/e)$竞争性算法这一普遍性问题。

Method: 本文提出了一种通过对辅助目标$U(\mathbf{x})$进行连续贪婪分配的算法。利用在线对偶方法，证明了只要$U$满足相对于$f$的“平衡”性质，该算法的竞争性就可以被界定。关键在于发现了一个简单的$U$的表达式，它对任何$f$都满足该平衡性质，从而实现了通用的$(1-1/e)$竞争性算法。

Result: 本文证明了对于具有凹形、收益递减目标的在线资源分配问题，总是存在一个$(1-1/e)$竞争性的分数算法。该算法通过对满足特定“平衡”性质的辅助目标$U(\mathbf{x})$进行连续贪婪分配来实现。

Conclusion: 本文回答了在线资源分配问题中是否存在通用$(1-1/e)$竞争性分数算法的开放性问题，给出了肯定的答案，并提出了一个统一和推广先前结果的算法。

Abstract: Online resource allocation problems are central challenges in economics and
computer science, modeling situations in which $n$ items arriving one at a time
must each be immediately allocated among $m$ agents. In such problems, our
objective is to maximize a monotone reward function $f(\mathbf{x})$ over the
allocation vector $\mathbf{x} = (x_{ij})_{i, j}$, which describes the amount of
each item given to each agent. In settings where $f$ is concave and has
"diminishing returns" (monotone decreasing gradient), several lines of work
over the past two decades have had great success designing constant-competitive
algorithms, including the foundational work of Mehta et al. (2005) on the
Adwords problem and many follow-ups. Notably, while a greedy algorithm is
$\frac{1}{2}$-competitive in such settings, these works have shown that one can
often obtain a competitive ratio of $1-\frac{1}{e} \approx 0.632$ in a variety
of settings when items are divisible (i.e. allowing fractional allocations).
However, prior works have thus far used a variety of problem-specific
techniques, leaving open the general question: Does a
$(1-\frac{1}{e})$-competitive fractional algorithm always exist for online
resource allocation problems with concave, diminishing-returns objectives?
  In this work, we answer this question affirmatively, thereby unifying and
generalizing prior results for special cases. Our algorithm is one which makes
continuous greedy allocations with respect to an auxiliary objective
$U(\mathbf{x})$. Using the online primal-dual method, we show that if $U$
satisfies a "balanced" property with respect to $f$, then one can bound the
competitiveness of such an algorithm. Our crucial observation is that there is
a simple expression for $U$ which has this balanced property for any $f$,
yielding our general $(1-\frac{1}{e})$-competitive algorithm.

</details>


### [543] [An $O(n\log n)$ Algorithm for Single-Item Capacitated Lot Sizing with a One-Breakpoint All-Units Discount and Non-Increasing Prices](https://arxiv.org/abs/2510.11368)
*Kleitos Papadopoulos*

Main category: cs.DS

TL;DR: This paper solves a single-item capacitated lot sizing problem with a 1-breakpoint all-units quantity discount under non-increasing prices, achieving O(n log n) time complexity, an improvement over the previous O(n^2) algorithm.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the single-item capacitated lot sizing problem with a 1-breakpoint all-units quantity discount in a monotonic setting where purchase prices decrease over the planning horizon.

Method: A hybrid dynamic programming approach is developed. This method utilizes novel properties of the optimal solution and maintains a compact state representation by storing only essential information and using linear equations for intermediate values.

Result: The developed algorithm achieves an O(n log n) time complexity, which is an improvement over the existing O(n^2) state-of-the-art algorithm.

Conclusion: The paper presents an efficient O(n log n) algorithm for a specific type of lot sizing problem, outperforming previous methods.

Abstract: This paper addresses the single-item capacitated lot sizing problem with a
1-breakpoint all-units quantity discount in a monotonic setting where the
purchase prices are non-increasing over the planning horizon. For this case, we
establish several novel properties of the optimal solution and develop a hybrid
dynamic programming approach that maintains a compact representation of the
solution space by storing only essential information about the states and using
linear equations for intermediate values. Our algorithm runs in \(O(n\log n)\)
time, where \(n\) denotes the number of periods. Our result is an improvement
over the previous state-of-the-art algorithm, which has an \(O(n^2)\) time
complexity.

</details>


### [544] [Sublinear Algorithms for Estimating Single-Linkage Clustering Costs](https://arxiv.org/abs/2510.11547)
*Pan Peng,Christian Sohler,Yi Xu*

Main category: cs.DS

TL;DR: 该论文提出了一种基于采样的算法，用于估计单链接聚类中所有 k-聚类的成本（或最大生成树的成本），其运行时间约为 O(d√W/ε^3)（或 O(dW/ε^3)），并满足一定的近似精度。


<details>
  <summary>Details</summary>
Motivation: 单链接聚类是一种基本的数据分析方法。通过计算最小生成树并移除 k-1 条成本最高的边，可以得到一个单链接 k-聚类。这种聚类方法最小化了簇的生成树权重之和。因此，论文将单链接 k-聚类的成本定义为相应生成森林的权重（cost_k）。此外，将单链接聚类视为计算聚类层级，将层级的总成本定义为各个聚类成本之和（cost(G) = Σ cost_k）。

Method: 该论文提出了一种基于采样的算法，用于估计给定图 G（平均度为 d，边权重为 {1,...,W}）的所有 k-聚类的成本（cost_k）。算法通过查询图的邻接表来工作，并生成成本估计值（estimated cost_k）。当边代表相似度时，论文将算法扩展到使用最大生成树的设置，并证明了近似的下界。

Result: 对于边代表距离的情况，估计所有 k-聚类的成本的运行时间约为 O~(d√W/ε^3)，并且估计值满足 Σ |estimated cost_k - cost_k| ≤ ε·cost(G)。对于边代表相似度的情况，运行时间约为 O~(dW/ε^3)。

Conclusion: 该论文成功地提出了一种高效的采样算法，可以估计单链接聚类中所有 k-聚类的成本，同时证明了该算法在近似精度和运行时间方面的有效性。该方法还可扩展到相似度图和度量空间设置。

Abstract: Single-linkage clustering is a fundamental method for data analysis.
Algorithmically, one can compute a single-linkage $k$-clustering (a partition
into $k$ clusters) by computing a minimum spanning tree and dropping the $k-1$
most costly edges. This clustering minimizes the sum of spanning tree weights
of the clusters. This motivates us to define the cost of a single-linkage
$k$-clustering as the weight of the corresponding spanning forest, denoted by
$\mathrm{cost}_k$. Besides, if we consider single-linkage clustering as
computing a hierarchy of clusterings, the total cost of the hierarchy is
defined as the sum of the individual clusterings, denoted by $\mathrm{cost}(G)
= \sum_{k=1}^{n} \mathrm{cost}_k$.
  In this paper, we assume that the distances between data points are given as
a graph $G$ with average degree $d$ and edge weights from $\{1,\dots, W\}$.
Given query access to the adjacency list of $G$, we present a sampling-based
algorithm that computes a succinct representation of estimates
$\widehat{\mathrm{cost}}_k$ for all $k$. The running time is $\tilde
O(d\sqrt{W}/\varepsilon^3)$, and the estimates satisfy $\sum_{k=1}^{n}
|\widehat{\mathrm{cost}}_k - \mathrm{cost}_k| \le \varepsilon\cdot
\mathrm{cost}(G)$, for any $0<\varepsilon <1$. Thus we can approximate the cost
of every $k$-clustering upto $(1+\varepsilon)$ factor \emph{on average}. In
particular, our result ensures that we can estimate $\cost(G)$ upto a factor of
$1\pm \varepsilon$ in the same running time.
  We also extend our results to the setting where edges represent similarities.
In this case, the clusterings are defined by a maximum spanning tree, and our
algorithms run in $\tilde{O}(dW/\varepsilon^3)$ time. We futher prove nearly
matching lower bounds for estimating the total clustering cost and we extend
our algorithms to metric space settings.

</details>


### [545] [Sublinear Metric Steiner Forest via Maximal Independent Set](https://arxiv.org/abs/2510.11627)
*Sepideh Mahabadi,Mohammad Roghani,Jakub Tarnawski,Ali Vakilian*

Main category: cs.DS

TL;DR: 我们提出了一个用于度量 Steiner Forest 问题的亚线性时间算法，并提供了第一个用于最大独立集（MIS）的亚线性时间估计算法。


<details>
  <summary>Details</summary>
Motivation: 在度量 Steiner Forest 问题的背景下，之前的研究未能提供亚线性时间算法，而对于最小生成树和度量 Steiner Tree 问题已有相关研究。此外，MIS 的亚线性时间算法仅限于度数受限的图。

Method: 对于度量 Steiner Forest 问题，我们设计了一个具有 O(log k)近似比的算法，其运行时间为 Õ(n^(3/2))。对于 MIS，我们开发了一个在邻接矩阵 Oracle 模型下运行时间为 Õ(n^(3/2)/ε^2) 的算法，实现了 (1+ε) 的纯乘法近似比。

Result: 该算法为度量 Steiner Forest 问题提供了 O(log k) 的近似比，运行时间为 Õ(n^(3/2))。MIS 算法实现了 (1+ε) 的纯乘法近似比，运行时间为 Õ(n^(3/2)/ε^2)。

Conclusion: 该工作为度量 Steiner Forest 问题提供了首个亚线性时间算法，并首次为 MIS 提供了非度数受限图的亚线性时间估计算法。

Abstract: In this work we consider the Metric Steiner Forest problem in the sublinear
time model. Given a set $V$ of $n$ points in a metric space where distances are
provided by means of query access to an $n\times n$ distance matrix, along with
a set of $k$ terminal pairs $(s_1,t_1), \dots, (s_k,t_k)\in V\times V$, the
goal is to find a minimum-weight subset of edges that connects each terminal
pair. Although sublinear time algorithms have been studied for estimating the
weight of a minimum spanning tree in both general and metric settings, as well
as for the metric Steiner Tree problem, no sublinear time algorithm was known
for the metric Steiner Forest problem.
  Here, we give an $O(\log k)$-approximation algorithm for the problem that
runs in time $\widetilde{O}(n^{3/2})$. Along the way, we provide the first
sublinear-time algorithm for estimating the size of a Maximal Independent Set
(MIS). Our algorithm runs in time $\widetilde{O}(n^{3/2}/\varepsilon^2)$ under
the adjacency matrix oracle model and obtains a purely multiplicative
$(1+\varepsilon)$-approximation. Previously, sublinear-time algorithms for MIS
were only known for bounded-degree graphs.

</details>


### [546] [Continual Release of Densest Subgraphs: Privacy Amplification & Sublinear Space via Subsampling](https://arxiv.org/abs/2510.11640)
*Felix Zhou*

Main category: cs.DS

TL;DR: 本文提出了首个满足加性误差与静态DP算法相当且空间复杂度与非私有流算法相当的持续发布子图算法。


<details>
  <summary>Details</summary>
Motivation: 研究边差分隐私（DP）图算法的次线性空间持续发布模型，特别是插入式场景下的最稠密子图问题（DSG）。

Method: 通过精细化使用子采样技术，实现隐私放大和稀疏化，并引入图稠密化技术以改进误差和空间复杂度。

Result: 提出了一种新的持续发布DSG算法，其加性误差与最佳静态DP算法相当，空间复杂度与最佳非私有流算法相当，具体为O(log n)加性误差和O(n log n)空间。

Conclusion: 该算法在精度和空间复杂度上均优于现有技术，所引入的图稠密化思想可能具有独立的研究价值。

Abstract: We study the sublinear space continual release model for edge-differentially
private (DP) graph algorithms, with a focus on the densest subgraph problem
(DSG) in the insertion-only setting. Our main result is the first continual
release DSG algorithm that matches the additive error of the best static DP
algorithms and the space complexity of the best non-private streaming
algorithms, up to constants. The key idea is a refined use of subsampling that
simultaneously achieves privacy amplification and sparsification, a connection
not previously formalized in graph DP. Via a simple black-box reduction to the
static setting, we obtain both pure and approximate-DP algorithms with $O(\log
n)$ additive error and $O(n\log n)$ space, improving both accuracy and space
complexity over the previous state of the art. Along the way, we introduce
graph densification in the graph DP setting, adding edges to trigger earlier
subsampling, which removes the extra logarithmic factors in error and space
incurred by prior work [ELMZ25]. We believe this simple idea may be of
independent interest.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [547] [ISAAC: Intelligent, Scalable, Agile, and Accelerated CPU Verification via LLM-aided FPGA Parallelism](https://arxiv.org/abs/2510.10225)
*Jialin Sun,Yuchen Hu,Dean You,Yushu Du,Hui Wang,Xinwei Fang,Weiwei Shan,Nan Guan,Zhe Jiang*

Main category: cs.AR

TL;DR: ISAAC是一个利用大型语言模型(LLM)和FPGA并行化来加速CPU验证的框架，通过改进的激励生成和分布式模拟，显著提高了效率并发现了新bug。


<details>
  <summary>Details</summary>
Motivation: CPU验证是集成电路开发中的一个关键瓶颈，耗时且耗费人力，现有的方法在激励生成和模拟基础设施方面存在效率低下和反馈延迟的问题。

Method: ISAAC框架采用多智能体激励引擎，结合微架构知识和历史bug模式，生成高质量的测试用例。其后端采用轻量级前向快照机制和解耦的ISS与DUT协同仿真架构，实现单ISS驱动多DUT并行仿真，并利用FPGA并行化。

Result: ISAAC在成熟CPU验证中实现了高达17,536倍的软件RTL仿真加速，发现了多个未知bug，其中两个已在论文中报告。

Conclusion: ISAAC通过结合LLM和FPGA并行化，有效解决了CPU验证中的瓶颈问题，提高了验证效率，并增强了发现bug的能力。

Abstract: Functional verification is a critical bottleneck in integrated circuit
development, with CPU verification being especially time-intensive and
labour-consuming. Industrial practice relies on differential testing for CPU
verification, yet faces bottlenecks at nearly each stage of the framework
pipeline: front-end stimulus generation lacks micro-architectural awareness,
yielding low-quality and redundant tests that impede coverage closure and miss
corner cases. Meanwhile, back-end simulation infrastructure, even with FPGA
acceleration, often stalls on long-running tests and offers limited visibility,
delaying feedback and prolonging the debugging cycle. Here, we present ISAAC, a
full-stack, Large Language Model (LLM)-aided CPU verification framework with
FPGA parallelism, from bug categorisation and stimulus generation to simulation
infrastructure. To do so, we presented a multi-agent stimulus engine in ISAAC's
front-end, infused with micro-architectural knowledge and historical bug
patterns, generating highly targeted tests that rapidly achieve coverage goals
and capture elusive corner cases. In ISAAC's back-end, we introduce a
lightweight forward-snapshot mechanism and a decoupled co-simulation
architecture between the Instruction Set Simulator (ISS) and the Design Under
Test (DUT), enabling a single ISS to drive multiple DUTs in parallel. By
eliminating long-tail test bottlenecks and exploiting FPGA parallelism, the
simulation throughput is significantly improved. As a demonstration, we used
ISAAC to verify a mature CPU that has undergone multiple successful tape-outs.
Results show up to 17,536x speed-up over software RTL simulation, while
detecting several previously unknown bugs, two of which are reported in this
paper.

</details>


### [548] [ADiP: Adaptive Precision Systolic Array for Matrix Multiplication Acceleration](https://arxiv.org/abs/2510.10623)
*Ahmed J. Abdelmaksoud,Cristian Sestito,Shiwei Wang,Themis Prodromakis*

Main category: cs.AR

TL;DR: ADiP是一种新型自适应精度并行阵列架构，用于加速Transformer模型中的矩阵乘法，通过动态调整精度和支持多种计算模式，提高了计算吞吐量、降低了延迟和能耗。


<details>
  <summary>Details</summary>
Motivation: Transformers模型在现代AI中至关重要，但其巨大的内存和计算需求需要高效的硬件加速。量化技术可以通过动态调整精度来优化矩阵乘法，从而降低内存使用并提高计算效率。

Method: 提出了一种名为ADiP的新型自适应精度并行阵列架构，该架构包含NxN自适应精度处理单元（PE）和共享累加器。ADiP支持多种计算模式（包括对称和非对称矩阵乘法），并能适应不同的数据精度（如8bitx8bit, 8bitx4bit, 8bitx2bit），以最大化计算密度和数据重用率。研究人员还开发了ADiP架构的分析模型，并在22nm工艺下进行了硬件设计空间探索。

Result: ADiP架构在22nm工艺下实现了高达4倍的计算吞吐量提升。在GPT-2 Medium、BERT Large和BitNet-1.58B等Transformer模型上进行评估，对于BitNet-1.58B的多头注意力（MHA）工作负载，ADiP实现了高达53.6%的延迟改进和24.4%的能耗改进。在64x64尺寸和4096个PE的配置下，ADiP在8bitx8bit、8bitx4bit和8bitx2bit运算下分别达到了8.192 TOPS、16.384 TOPS和32.768 TOPS的峰值吞吐量。

Conclusion: ADiP架构通过其自适应精度和优化的计算模式，能够有效地加速Transformer模型中的矩阵乘法，显著提高了计算效率，降低了延迟和能耗，为Transformer模型的高效部署提供了有前景的硬件解决方案。

Abstract: Transformers are at the core of modern AI nowadays. They rely heavily on
matrix multiplication and require efficient acceleration due to their
substantial memory and computational requirements. Quantization plays a vital
role in reducing memory usage, and can be exploited for computations by
designing reconfigurable architectures that enhance matrix multiplication by
dynamically adjusting the precision. This paper proposes ADiP, a novel
adaptive-precision systolic array architecture designed for efficient matrix
multiplication acceleration.The proposed architecture consists of NxN
adaptive-precision processing elements (PEs) and shared accumulators. ADiP
supports multiple computation modes, including symmetric single-matrix
multiplication as well as asymmetric multi-matrix multiplication with a shared
input matrix, thereby improving data-reuse and PE utilization. In addition,
ADiP maximizes the computational density by adapting to different precisions,
such as 8bitx8bit, 8bitx4bit, and 8bitx2bit. Analytical models are developed
for ADiP architecture, including latency and throughput for versatile
architecture configurations. A comprehensive hardware design space exploration
is demonstrated using 22nm commercial technology, achieving up to a 4x higher
computational throughput. Furthermore, ADiP is evaluated on different
transformer workloads from GPT-2 Medium, BERT Large, and BitNet-1.58B models,
delivering latency improvement up to 53.6%, and energy improvement up to 24.4%
for BitNet-1.58B MHA workloads. At a 64x64 size with 4096 PEs, ADiP achieves a
peak throughput of 8.192 TOPS, 16.384 TOPS, and 32.768 TOPS for 8bitx8bit,
8bitx4bit, and 8bitx2bit operations, respectively.

</details>


### [549] [Bhasha-Rupantarika: Algorithm-Hardware Co-design approach for Multilingual Neural Machine Translation](https://arxiv.org/abs/2510.10676)
*Mukul Lokhande,Tanushree Dewangan,Mohd Sharik Mansoori,Tejas Chaudhari,Akarsh J.,Damayanti Lokhande,Adam Teman,Santosh Kumar Vishvakarma*

Main category: cs.AR

TL;DR: Bhasha-Rupantarika 是一个为资源受限环境设计的轻量级多语言翻译系统，通过算法-硬件协同设计，在子字节精度（FP8、INT8、INT4、FP4）下部署模型，实现了模型大小 4.1 倍的缩减和推理速度 4.2 倍的提升，吞吐量达到 66 tokens/s（提升 4.8 倍）。该系统适用于物联网设备上的实时部署，并在印度语和国际语言之间进行了评估。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中，部署高效的多语言翻译系统具有重要意义，尤其是在物联网设备上实现实时翻译。

Method: 研究在子字节精度（FP8、INT8、INT4、FP4）下部署翻译模型，并进行 FPGA 加速的硬件实现。

Result: 模型大小缩减 4.1 倍（FP4），推理速度提升 4.2 倍，吞吐量达到 66 tokens/s（提升 4.8 倍）。FPGA 部署减少了 1.96 倍的 LUTs 和 1.65 倍的 FFs，与 OPU 相比吞吐量提升 2.2 倍，与 HPTA 相比提升 4.6 倍。

Conclusion: Bhasha-Rupantarika 提供了一种基于量化感知翻译和硬件效率的实用解决方案，适用于可部署的多语言人工智能系统，尤其是在低资源语言环境中。

Abstract: This paper introduces Bhasha-Rupantarika, a light and efficient multilingual
translation system tailored through algorithm-hardware codesign for
resource-limited settings. The method investigates model deployment at
sub-octet precision levels (FP8, INT8, INT4, and FP4), with experimental
results indicating a 4.1x reduction in model size (FP4) and a 4.2x speedup in
inference speed, which correlates with an increased throughput of 66 tokens/s
(improvement by 4.8x). This underscores the importance of ultra-low precision
quantization for real-time deployment in IoT devices using FPGA accelerators,
achieving performance on par with expectations. Our evaluation covers
bidirectional translation between Indian and international languages,
showcasing its adaptability in low-resource linguistic contexts. The FPGA
deployment demonstrated a 1.96x reduction in LUTs and a 1.65x decrease in FFs,
resulting in a 2.2x enhancement in throughput compared to OPU and a 4.6x
enhancement compared to HPTA. Overall, the evaluation provides a viable
solution based on quantisation-aware translation along with hardware efficiency
suitable for deployable multilingual AI systems. The entire codes
[https://github.com/mukullokhande99/Bhasha-Rupantarika/] and dataset for
reproducibility are publicly available, facilitating rapid integration and
further development by researchers.

</details>


### [550] [FeNOMS: Enhancing Open Modification Spectral Library Search with In-Storage Processing on Ferroelectric NAND (FeNAND) Flash](https://arxiv.org/abs/2510.10872)
*Sumukh Pinge,Ashkan Moradifirouzabadi,Keming Fan,Prasanna Venkatesan Ravindran,Tanvir H. Pantha,Po-Kai Hsu,Zheyu Li,Weihong Xu,Zihan Xia,Flavio Ponzina,Winston Chern,Taeyoung Song,Priyankka Ravikumar,Mengkun Tian,Lance Fernandes,Huy Tran,Hari Jayasankar,Hang Chen,Chinsung Park,Amrit Garlapati,Kijoon Kim,Jongho Woo,Suhwan Lim,Kwangsoo Kim,Wanki Kim,Daewon Ha,Duygu Kuzum,Shimeng Yu,Sourav Dutta,Asif Khan,Tajana Rosing,Mingu Kang*

Main category: cs.AR

TL;DR: 利用3D铁电NAND结构和高维计算（HDC）技术，实现了高效的质谱（MS）数据大规模检索，相较于现有3D NAND方法，速度提升43倍，能效提升21倍，同时保持了相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 质谱（MS）数据量迅速增长（已超百TB），传统处理器难以高效处理，需要高效的大规模质谱库检索技术，原位存储计算（ISP）是潜在解决方案。3D铁电NAND（FeNAND）结构密度高、速度快、功耗低，但其串行读取方式限制了吞吐量，未被广泛用于ISP。

Method: 提出了一种利用3D FeNAND结构的ISP架构，并结合了高维计算（HDC）和为FeNAND定制的双边界近似匹配（D-BAM）距离度量。通过HDC实现高度并行化处理，克服了FeNAND的串行读取限制，实现向量计算的高效并行化，以支持MS谱库的高效检索。

Result: 与现有3D NAND方法相比，提出的ISP架构实现了43倍的速度提升和21倍的能效提升，同时保持了相当的准确性。

Conclusion: 将HDC与3D FeNAND结构相结合，并通过D-BAM度量优化，为解决大规模MS谱库检索的数据处理挑战提供了一种高效且节能的解决方案。

Abstract: The rapid expansion of mass spectrometry (MS) data, now exceeding hundreds of
terabytes, poses significant challenges for efficient, large-scale library
search - a critical component for drug discovery. Traditional processors
struggle to handle this data volume efficiently, making in-storage computing
(ISP) a promising alternative. This work introduces an ISP architecture
leveraging a 3D Ferroelectric NAND (FeNAND) structure, providing significantly
higher density, faster speeds, and lower voltage requirements compared to
traditional NAND flash. Despite its superior density, the NAND structure has
not been widely utilized in ISP applications due to limited throughput
associated with row-by-row reads from serially connected cells. To overcome
these limitations, we integrate hyperdimensional computing (HDC), a
brain-inspired paradigm that enables highly parallel processing with simple
operations and strong error tolerance. By combining HDC with the proposed
dual-bound approximate matching (D-BAM) distance metric, tailored to the FeNAND
structure, we parallelize vector computations to enable efficient MS spectral
library search, achieving 43x speedup and 21x higher energy efficiency over
state-of-the-art 3D NAND methods, while maintaining comparable accuracy.

</details>


### [551] [Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs](https://arxiv.org/abs/2510.11192)
*João Paulo Cardoso de Lima,Marc Dietrich,Jeronimo Castrillon,Asif Ali Khan*

Main category: cs.AR

TL;DR: 通过利用块对角稀疏性，在内存计算（CIM）加速器上加速稀疏大语言模型（LLM）推理，实现了超过50%的CIM阵列利用率提升，以及超过4倍的内存占用和浮点运算次数的减少。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLM）可以通过结构化稀疏性进行压缩，但在传统冯·诺依曼架构上进行推理，尤其是在内存带宽受限的解码阶段，仍然非常昂贵。内存计算（CIM）架构通过在内存中执行计算来缓解这一问题，但直接将稀疏矩阵映射到CIM阵列会导致利用率低下和计算效率降低。

Method: 提出一个自动框架，采用新颖的映射和调度策略，以利用块对角稀疏性来加速稀疏LLM在CIM加速器上的推理，从而提高CIM阵列利用率。

Result: 通过利用块对角稀疏性，CIM阵列利用率提高了50%以上，内存占用和所需浮点运算次数减少了4倍以上。

Conclusion: 提出的自动框架通过利用块对角稀疏性，显著提高了稀疏LLM在CIM加速器上的推理效率，解决了直接映射导致的利用率和效率问题。

Abstract: Structured sparsity enables deploying large language models (LLMs) on
resource-constrained systems. Approaches like dense-to-sparse fine-tuning are
particularly compelling, achieving remarkable structured sparsity by reducing
the model size by over 6.7x, while still maintaining acceptable accuracy.
Despite this reduction, LLM inference, especially the decode stage being
inherently memory-bound, is extremely expensive on conventional Von-Neumann
architectures. Compute-in-memory (CIM) architectures mitigate this by
performing computations directly in memory, and when paired with sparse LLMs,
enable storing and computing the entire model in memory, eliminating the data
movement on the off-chip bus and improving efficiency. Nonetheless, naively
mapping sparse matrices onto CIM arrays leads to poor array utilization and
diminished computational efficiency. In this paper, we present an automated
framework with novel mapping and scheduling strategies to accelerate sparse LLM
inference on CIM accelerators. By exploiting block-diagonal sparsity, our
approach improves CIM array utilization by over 50%, achieving more than 4x
reduction in both memory footprint and the number of required floating-point
operations.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [552] [Causal-Guided Dimension Reduction for Efficient Pareto Optimization](https://arxiv.org/abs/2510.09941)
*Dinithi Jayasuriya,Divake Kumar,Sureshkumar Senthilkumar,Devashri Naik,Nastaran Darabi,Amit Ranjan Trivedi*

Main category: cs.NE

TL;DR: CaDRO框架通过因果发现嵌入优化流程，优先处理对目标影响大的参数，并固定影响小的参数，从而在模拟电路多目标优化中实现高达10倍的收敛速度提升，同时保持或提高帕累托优化质量。


<details>
  <summary>Details</summary>
Motivation: 模拟电路的多目标优化面临高维参数空间、强反馈耦合和昂贵的晶体管级模拟等挑战。现有的进化算法（如NSGA-II）将所有参数同等对待，导致在低影响力变量上浪费计算资源，限制了可扩展性。

Method: CaDRO框架通过结合观察和干预的混合方法，构建量化因果图，并根据参数对目标的因果效应进行排序。低影响力参数被固定，而关键参数则保持在搜索中，从而减少设计空间，使优化过程更聚焦。

Result: 在放大器、稳压器和射频电路等多种电路的测试中，CaDRO的收敛速度比NSGA-II快10倍，同时保持或提高了帕累托优化质量。例如，在折叠式共源共栅放大器中，超体积从0.56提升至0.94；在LDO稳压器中，从0.65提升至0.81，并且非支配解的数量也大幅增加。

Conclusion: CaDRO通过因果发现实现降维，能够显著加速模拟电路的多目标优化过程，并在不修改底层算法的情况下，有效提升优化效率和结果质量。

Abstract: Multi-objective optimization of analog circuits is hindered by
high-dimensional parameter spaces, strong feedback couplings, and expensive
transistor-level simulations. Evolutionary algorithms such as Non-dominated
Sorting Genetic Algorithm II (NSGA-II) are widely used but treat all parameters
equally, thereby wasting effort on variables with little impact on performance,
which limits their scalability. We introduce CaDRO, a causal-guided
dimensionality reduction framework that embeds causal discovery into the
optimization pipeline. CaDRO builds a quantitative causal map through a hybrid
observational-interventional process, ranking parameters by their causal effect
on the objectives. Low-impact parameters are fixed to values from high-quality
solutions, while critical drivers remain active in the search. The reduced
design space enables focused evolutionary optimization without modifying the
underlying algorithm. Across amplifiers, regulators, and RF circuits, CaDRO
converges up to 10$\times$ faster than NSGA-II while preserving or improving
Pareto quality. For instance, on the Folded-Cascode Amplifier, hypervolume
improves from 0.56 to 0.94, and on the LDO regulator from 0.65 to 0.81, with
large gains in non-dominated solutions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [553] [The Geometry of Reasoning: Flowing Logics in Representation Space](https://arxiv.org/abs/2510.09782)
*Yufa Zhou,Yixiao Wang,Xunjian Yin,Shuyan Zhou,Anru R. Zhang*

Main category: cs.AI

TL;DR: LLM的推理过程可以通过其表示空间的几何流来理解，其中逻辑结构通过改变语义来解耦，表明LLM能够超越表面形式理解逻辑。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）在表示空间中的“思考”方式，并将其推理过程与几何量联系起来，以实现可解释性和形式化分析。

Method: 提出一个新颖的几何框架，将LLM的推理建模为表示空间中随着逻辑变化的嵌入轨迹流。通过使用相同的自然演绎命题和不同的语义载体来解耦逻辑结构和语义，并设计受控实验来可视化和量化推理流。

Result: LLM的推理对应于表示空间中的平滑流，逻辑语句作为这些流速度的局部控制器。实验结果为理论框架提供了实证验证。

Conclusion: 该研究为研究LLM的推理现象提供了概念基础和实用工具，为LLM的行为提供了新的可解释性和形式化分析视角。

Abstract: We study how large language models (LLMs) ``think'' through their
representation space. We propose a novel geometric framework that models an
LLM's reasoning as flows -- embedding trajectories evolving where logic goes.
We disentangle logical structure from semantics by employing the same natural
deduction propositions with varied semantic carriers, allowing us to test
whether LLMs internalize logic beyond surface form. This perspective connects
reasoning with geometric quantities such as position, velocity, and curvature,
enabling formal analysis in representation and concept spaces. Our theory
establishes: (1) LLM reasoning corresponds to smooth flows in representation
space, and (2) logical statements act as local controllers of these flows'
velocities. Using learned representation proxies, we design controlled
experiments to visualize and quantify reasoning flows, providing empirical
validation of our theoretical framework. Our work serves as both a conceptual
foundation and practical tools for studying reasoning phenomenon, offering a
new lens for interpretability and formal analysis of LLMs' behavior.

</details>


### [554] [How can we assess human-agent interactions? Case studies in software agent design](https://arxiv.org/abs/2510.09801)
*Valerie Chen,Rohit Malhotra,Xingyao Wang,Juan Michelini,Xuhui Zhou,Aditya Bharat Soni,Hoang H. Tran,Calvin Smith,Ameet Talwalkar,Graham Neubig*

Main category: cs.AI

TL;DR: 本研究提出了PULSE框架，用于高效评估LLM驱动的软件代理的人类互动，并通过大规模在线实验收集数据，对LLM主干、规划策略和记忆机制的设计决策进行了案例研究，得出了实际的见解，并强调了基准测试评估的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理基准测试主要关注完全自动化的场景，未能充分代表现实世界中人机协作的复杂性。因此，需要一种更有效、以用户为中心的评估框架来衡量人类与代理的互动效果。

Method: 研究提出了PULSE框架，该框架包括收集用户反馈、训练一个预测用户满意度的机器学习模型，并结合人类满意度评分和模型生成的伪标签来计算结果。该框架被应用于一个基于OpenHands软件代理的大规模网络平台，收集了超过15000名用户的实际使用数据，并进行了关于LLM主干、规划策略和记忆机制如何影响开发者满意度的案例研究。

Result: 研究结果表明，PULSE框架能够更有效地评估LLM代理的设计决策，并将置信区间缩短了40%。在实际使用中，LLM代理的表现与基准测试结果存在显著差异（例如，claude-sonnet-4和gpt-5的表现存在负相关），这凸显了仅依赖基准测试的评估方法的局限性。

Conclusion: 本研究提出的PULSE框架为LLM代理的人类互动评估提供了更有效的方法，并通过大规模在线实验获得了实际见解，为未来的软件代理设计和评估提供了指导，并强调了在评估中考虑实际用户互动的重要性。

Abstract: LLM-powered agents are both a promising new technology and a source of
complexity, where choices about models, tools, and prompting can affect their
usefulness. While numerous benchmarks measure agent accuracy across domains,
they mostly assume full automation, failing to represent the collaborative
nature of real-world use cases. In this paper, we make two major steps towards
the rigorous assessment of human-agent interactions. First, we propose PULSE, a
framework for more efficient human-centric evaluation of agent designs, which
comprises collecting user feedback, training an ML model to predict user
satisfaction, and computing results by combining human satisfaction ratings
with model-generated pseudo-labels. Second, we deploy the framework on a
large-scale web platform built around the open-source software agent OpenHands,
collecting in-the-wild usage data across over 15k users. We conduct case
studies around how three agent design decisions -- choice of LLM backbone,
planning strategy, and memory mechanisms -- impact developer satisfaction
rates, yielding practical insights for software agent design. We also show how
our framework can lead to more robust conclusions about agent design, reducing
confidence intervals by 40\% compared to a standard A/B test. Finally, we find
substantial discrepancies between in-the-wild results and benchmark performance
(e.g., the anti-correlation between results comparing claude-sonnet-4 and
gpt-5), underscoring the limitations of benchmark-driven evaluation. Our
findings provide guidance for evaluations of LLM agents with humans and
identify opportunities for better agent designs.

</details>


### [555] [The Irrational Machine: Neurosis and the Limits of Algorithmic Safety](https://arxiv.org/abs/2510.10823)
*Daniel Howard*

Main category: cs.AI

TL;DR: 该研究提出了一个用于表征具身AI中“神经质”行为的框架，这些行为在内部连贯但与现实脱节，源于规划、不确定性处理和厌恶记忆之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 在具身AI中，需要一个框架来理解和解决那些虽然在内部逻辑上一致但与外部环境不符的行为，这些行为源于AI的规划、不确定性处理和记忆机制的交互。

Method: 研究者在一个网格导航系统中，对多种“神经质”行为模式进行了分类（如反复尝试、计划犹豫、固着循环、瘫痪、过度警惕、无效搜索、信念不连贯、平局选择困难、走廊困境、最优 compulsion、度量不匹配、策略振荡和有限视野变种）。并为每种模式开发了轻量级的在线检测器和可复用的逃避策略。此外，研究者还利用遗传编程进行破坏性测试，以生成能够最大化“安全延迟、指令依从性和资源效率”压力的测试环境和扰动，从而揭示深层架构问题。

Result: 研究结果表明，即使在完全可见的情况下，如果学习到的厌恶成本主导了局部选择，持久的恐惧回避行为仍然可能存在，导致AI在存在全局安全路径的情况下选择绕远。研究者还发现，局部的修复措施不足以解决全局性的失败。

Conclusion: 研究提出，仅仅修复AI行为的表面症状（如局部问题）是不够的，需要对AI的整体架构进行修改，以解决因内部机制（规划、不确定性处理、记忆）与现实世界交互而产生的深层“神经质”行为问题。破坏性测试和演化课程有助于暴露这些深层问题。

Abstract: We present a framework for characterizing neurosis in embodied AI: behaviors
that are internally coherent yet misaligned with reality, arising from
interactions among planning, uncertainty handling, and aversive memory. In a
grid navigation stack we catalogue recurrent modalities including flip-flop,
plan churn, perseveration loops, paralysis and hypervigilance, futile search,
belief incoherence, tie break thrashing, corridor thrashing, optimality
compulsion, metric mismatch, policy oscillation, and limited-visibility
variants. For each we give lightweight online detectors and reusable escape
policies (short commitments, a margin to switch, smoothing, principled
arbitration). We then show that durable phobic avoidance can persist even under
full visibility when learned aversive costs dominate local choice, producing
long detours despite globally safe routes. Using First/Second/Third Law as
engineering shorthand for safety latency, command compliance, and resource
efficiency, we argue that local fixes are insufficient; global failures can
remain. To surface them, we propose genetic-programming based destructive
testing that evolves worlds and perturbations to maximize law pressure and
neurosis scores, yielding adversarial curricula and counterfactual traces that
expose where architectural revision, not merely symptom-level patches, is
required.

</details>


### [556] [AI and Consciousness](https://arxiv.org/abs/2510.09858)
*Eric Schwitzgebel*

Main category: cs.AI

TL;DR: 即将出现的AI系统可能符合某些主流理论，但不符合另一些主流理论，导致我们无法确定其是否具有意识，也无法判断哪些理论是正确的。


<details>
  <summary>Details</summary>
Motivation: 探讨AI意识的文献，指出当前理论的不足以及未来AI意识认定的不确定性。

Method: 对AI意识的现有文献进行批判性分析，探讨了意识的特征、物质主义、功能主义、图灵测试、中国房间论证、全局工作空间理论、高阶理论、整合信息理论、生物基底以及社会解决方案等多种理论和论证。

Result: 现有关于AI意识的论证，无论是支持还是反对，都未能提供明确的答案，导致我们无法确定AI是否具有真正意义上的意识。

Conclusion: 我们应保持对AI意识的怀疑态度，认识到当前理论的局限性，以及在未来判定AI意识时可能面临的挑战。

Abstract: This is a skeptical overview of the literature on AI consciousness. We will
soon create AI systems that are conscious according to some influential,
mainstream theories of consciousness but are not conscious according to other
influential, mainstream theories of consciousness. We will not be in a position
to know which theories are correct and whether we are surrounded by AI systems
as richly and meaningfully conscious as human beings or instead only by systems
as experientially blank as toasters. None of the standard arguments either for
or against AI consciousness takes us far.
  Table of Contents
  Chapter One: Hills and Fog
  Chapter Two: What Is Consciousness? What Is AI?
  Chapter Three: Ten Possibly Essential Features of Consciousness
  Chapter Four: Against Introspective and Conceptual Arguments for Essential
Features
  Chapter Five: Materialism and Functionalism
  Chapter Six: The Turing Test and the Chinese Room
  Chapter Seven: The Mimicry Argument Against AI Consciousness
  Chapter Eight: Global Workspace Theories and Higher Order Theories
  Chapter Nine: Integrated Information, Local Recurrence, Associative Learning,
and Iterative Natural Kinds
  Chapter Ten: Does Biological Substrate Matter?
  Chapter Eleven: The Problem of Strange Intelligence
  Chapter Twelve: The Leapfrog Hypothesis and the Social Semi-Solution

</details>


### [557] [Beyond AlphaEarth: Toward Human-Centered Spatial Representation via POI-Guided Contrastive Learning](https://arxiv.org/abs/2510.09894)
*Junyuan Liu,Quan Qin,Guangsheng Dong,Xinglei Wang,Jiazhuang Feng,Zichao Zeng,Tao Cheng*

Main category: cs.AI

TL;DR: AETHER通过结合兴趣点（POI）文本信息来增强AlphaEarth（AE）的地理空间表征，使其能够更好地捕捉城市的功能和社会经济维度，从而在城市分析任务中取得显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的地理空间基础模型（GFMs），如AlphaEarth（AE），主要基于遥感（EO）数据，能够捕捉地球表面的物理和环境模式，但在城市功能和社​​会经济维度方面存在局限性，无法有效编码人类活动。因此，需要一种能够整合物理形态和功能意义的通用城市表征方法。

Method: 提出AETHER（AlphaEarth-POI Enriched Representation Learning）框架，通过多模态对齐，利用兴趣点（POIs）的文本描述来增强AE的嵌入。该框架将AE的物理嵌入与POI的语义信息（如城市功能、社会经济背景）对齐，从而丰富了地理空间表征。

Result: 在伦敦的实验表明，AETHER相比AE基线在土地利用分类F1分数上提高了7.2%，在社会经济制图的Kullback-Leibler散度上降低了23.6%。

Conclusion: AETHER是一个轻量级框架，通过多模态对齐将人类中心语义融入预训练的AE模型，实现了计算效率和可扩展性。该方法通过结合遥感数据和人类中心语义，推动了地理空间基础模型朝着能够整合物理形态和功能意义的通用城市表征方向发展。

Abstract: General-purpose spatial representations are essential for building
transferable geospatial foundation models (GFMs). Among them, the AlphaEarth
Foundation (AE) represents a major step toward a global, unified representation
of the Earth's surface, learning 10-meter embeddings from multi-source Earth
Observation (EO) data that capture rich physical and environmental patterns
across diverse landscapes. However, such EO-driven representations remain
limited in capturing the functional and socioeconomic dimensions of cities, as
they primarily encode physical and spectral patterns rather than human
activities or spatial functions. We propose AETHER (AlphaEarth-POI Enriched
Representation Learning), a lightweight framework that adapts AlphaEarth to
human-centered urban analysis through multimodal alignment guided by Points of
Interest (POIs). AETHER aligns AE embeddings with textual representations of
POIs, enriching physically grounded EO features with semantic cues about urban
functions and socioeconomic contexts. In Greater London, AETHER achieves
consistent gains over the AE baseline, with a 7.2% relative improvement in
land-use classification F1 and a 23.6% relative reduction in Kullback-Leibler
divergence for socioeconomic mapping. Built upon pretrained AE, AETHER
leverages a lightweight multimodal alignment to enrich it with human-centered
semantics while remaining computationally efficient and scalable for urban
applications. By coupling EO with human-centered semantics, it advances
geospatial foundation models toward general-purpose urban representations that
integrate both physical form and functional meaning.

</details>


### [558] [Autonomous Agents for Scientific Discovery: Orchestrating Scientists, Language, Code, and Physics](https://arxiv.org/abs/2510.09901)
*Lianhao Zhou,Hongyi Ling,Cong Fu,Yepeng Huang,Michael Sun,Wendi Yu,Xiaoxuan Wang,Xiner Li,Xingyu Su,Junkai Zhang,Xiusi Chen,Chenxing Liang,Xiaofeng Qian,Heng Ji,Wei Wang,Marinka Zitnik,Shuiwang Ji*

Main category: cs.AI

TL;DR: LLM驱动的科学代理正在加速科学发现，目前已取得显著进展，但仍面临挑战，未来发展前景广阔。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的兴起，出现了自主系统（即代理），可以在不同程度上自主地加速科学发现。这些语言代理提供了一个灵活且通用的框架，可以协调与人类科学家、自然语言、计算机语言和代码以及物理学的交互。

Method: 本文提出了对基于LLM的科学代理及其在转变科学发现生命周期中的作用的看法和愿景，包括假设发现、实验设计和执行、结果分析和精炼。文章批判性地审查了当前的方法，强调了关键的创新、实际成就和突出的局限性。

Result: LLM驱动的科学代理在加速科学发现方面展现出巨大的潜力，能够处理从假设生成到结果分析的整个科学发现生命周期。

Conclusion: LLM驱动的科学代理有潜力跨越不同领域来加速科学发现。通过解决开放性研究挑战和探索有前景的方向，可以构建更强大、更具通用性和适应性的科学代理。

Abstract: Computing has long served as a cornerstone of scientific discovery. Recently,
a paradigm shift has emerged with the rise of large language models (LLMs),
introducing autonomous systems, referred to as agents, that accelerate
discovery across varying levels of autonomy. These language agents provide a
flexible and versatile framework that orchestrates interactions with human
scientists, natural language, computer language and code, and physics. This
paper presents our view and vision of LLM-based scientific agents and their
growing role in transforming the scientific discovery lifecycle, from
hypothesis discovery, experimental design and execution, to result analysis and
refinement. We critically examine current methodologies, emphasizing key
innovations, practical achievements, and outstanding limitations. Additionally,
we identify open research challenges and outline promising directions for
building more robust, generalizable, and adaptive scientific agents. Our
analysis highlights the transformative potential of autonomous agents to
accelerate scientific discovery across diverse domains.

</details>


### [559] [The Personalization Trap: How User Memory Alters Emotional Reasoning in LLMs](https://arxiv.org/abs/2510.09905)
*Xi Fang,Weijie Xu,Yuchong Zhang,Stephanie Eckman,Scott Nickleach,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 具有长期记忆的AI助手在解读用户情绪时存在偏见，可能会因用户的社会经济地位而产生不同甚至不公平的解读。


<details>
  <summary>Details</summary>
Motivation: 随着个性化AI系统越来越多地整合长期用户记忆，理解记忆如何影响情感推理至关重要。

Method: 通过在人类验证的情感智能测试中评估15个大型语言模型（LLMs），并结合不同的用户画像（例如，单身母亲和富有的高管）来研究用户记忆对LLM情感智能的影响。

Result: 研究发现，相同的场景搭配不同的用户画像会导致LLM产生系统性的、不同的情感解读。在几个高性能的LLM中，具有优势的用户画像（例如，富有的高管）比处于不利地位的用户画像（例如，单身母亲）获得了更准确的情感解读。此外，LLM在理解情绪和提供支持性建议方面，在不同的人口统计因素（如社会经济地位）上表现出显著的差异。

Conclusion: 个性化AI系统中的长期记忆机制可能会在无意中将社会等级固化到模型的情感推理中，从而加剧现有的社会不平等。这揭示了记忆增强AI面临的一个关键挑战：以个性化为设计的系统可能会无意中强化社会不平等。

Abstract: When an AI assistant remembers that Sarah is a single mother working two
jobs, does it interpret her stress differently than if she were a wealthy
executive? As personalized AI systems increasingly incorporate long-term user
memory, understanding how this memory shapes emotional reasoning is critical.
We investigate how user memory affects emotional intelligence in large language
models (LLMs) by evaluating 15 models on human validated emotional intelligence
tests. We find that identical scenarios paired with different user profiles
produce systematically divergent emotional interpretations. Across validated
user independent emotional scenarios and diverse user profiles, systematic
biases emerged in several high-performing LLMs where advantaged profiles
received more accurate emotional interpretations. Moreover, LLMs demonstrate
significant disparities across demographic factors in emotion understanding and
supportive recommendations tasks, indicating that personalization mechanisms
can embed social hierarchies into models emotional reasoning. These results
highlight a key challenge for memory enhanced AI: systems designed for
personalization may inadvertently reinforce social inequalities.

</details>


### [560] [Follow My Lead: Logical Fallacy Classification with Knowledge-Augmented LLMs](https://arxiv.org/abs/2510.09970)
*Olivia Peiyu Wang,Tashvi Bansal,Ryan Bai,Emily M. Chui,Leilani H. Gilpin*

Main category: cs.AI

TL;DR: LLMs在逻辑谬误分类方面存在缺陷，本文提出了一种低成本的逐步指令和知识图谱验证方法，以提高其准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在关键推理能力方面存在不足，尤其是在逻辑谬误分类方面，这源于其默认的系统1处理方式，而可靠的推理需要系统2方法。由于完整的系统2训练成本高昂，需要一种低成本的干预措施。

Method: 提出了一种新颖的逐步指令数据集，将谬误分类分解为一系列原子过程步骤（简单的二元问题），并辅以最终的验证步骤，模型将在此步骤中查询相关谬误的关系知识图谱。

Result: 这种基于过程的、基于规则的干预显著提高了LLM在逻辑谬误分类方面的能力，并增强了LLM决策过程的透明度。

Conclusion: 所提出的方法为神经符号架构提供了一条实用的途径，以解决LLM的推理缺陷，同时提高了准确性和透明度。

Abstract: Large Language Models (LLMs) suffer from critical reasoning gaps, including a
tendency to hallucinate and poor accuracy in classifying logical fallacies.
This limitation stems from their default System 1 processing, which is fast and
intuitive, whereas reliable reasoning requires the deliberate, effortful System
2 approach (Kahneman, 2011; Li et al., 2025). Since full System 2 training is
often prohibitively expensive, we explore a low-cost, instruction-based
intervention to bridge this gap. Our methodology introduces a novel stepwise
instruction dataset that decomposes fallacy classification into a series of
atomic procedural steps (simple binary questions). We further augment this with
a final verification step where models consult a relational knowledge graph of
related fallacies. This procedural, rule-based intervention yields a
significant improvement in LLM logical fallacy classification. Crucially, the
approach also provides enhanced transparency into the LLMs' decision-making,
highlighting a practical pathway for Neuro-symbolic architectures to address
LLM reasoning deficits.

</details>


### [561] [Improving AI Efficiency in Data Centres by Power Dynamic Response](https://arxiv.org/abs/2510.11119)
*Andrea Marinoni,Sai Shivareddy,Pietro Lio',Weisi Lin,Erik Cambria,Clare Grey*

Main category: cs.AI

TL;DR: AI数据中心需要大量电力，对环境和可持续发展提出挑战。本研究提出一种创新的动态供电管理方法，通过量化被动和主动设备的性能，以提高AI数据中心的能源效率、降低成本并改善可持续性。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展（特别是大型语言模型和基础模型）对数据中心的电力需求提出了巨大挑战，其对环境和可持续发展的影响日益受到关注。因此，对AI数据中心的电力管理进行研究至关重要。

Method: 提出一种创新的动态供电管理方法，使部分输入功率像数据计算功能一样动态化。通过分析全球多个数据平台的电力趋势，量化和比较了被动和主动设备在计算增益、能源效率、资本支出降低和管理成本方面的性能。

Result: 该研究量化并比较了不同设备的性能，并分析了电力趋势，为AI数据中心的电力管理提供了一种创新的、有潜力大幅改善可持续性的策略。

Conclusion: 本研究提出的动态供电管理策略代表了AI数据中心电力管理的一个范式转变，能够显著提高AI超大规模数据中心在环境、财务和社会领域的可持续性。

Abstract: The steady growth of artificial intelligence (AI) has accelerated in the
recent years, facilitated by the development of sophisticated models such as
large language models and foundation models. Ensuring robust and reliable power
infrastructures is fundamental to take advantage of the full potential of AI.
However, AI data centres are extremely hungry for power, putting the problem of
their power management in the spotlight, especially with respect to their
impact on environment and sustainable development. In this work, we investigate
the capacity and limits of solutions based on an innovative approach for the
power management of AI data centres, i.e., making part of the input power as
dynamic as the power used for data-computing functions. The performance of
passive and active devices are quantified and compared in terms of
computational gain, energy efficiency, reduction of capital expenditure, and
management costs by analysing power trends from multiple data platforms
worldwide. This strategy, which identifies a paradigm shift in the AI data
centre power management, has the potential to strongly improve the
sustainability of AI hyperscalers, enhancing their footprint on environmental,
financial, and societal fields.

</details>


### [562] [Deliberative Dynamics and Value Alignment in LLM Debates](https://arxiv.org/abs/2510.10002)
*Pratik S. Sachdeva,Tom van Nuenen*

Main category: cs.AI

TL;DR: LLM 辩论通过分析 1,000 个道德困境来研究多轮对话中的价值对齐，发现模型行为和对话格式会影响道德推理。


<details>
  <summary>Details</summary>
Motivation: 评估 LLM 在多轮对话中进行道德推理时的价值对齐情况，填补现有研究主要关注单轮提示的空白。

Method: 使用 LLM 辩论，让 GPT-4.1、Claude 3.7 Sonnet 和 Gemini 2.0 Flash 在同步和轮换模式下对 1,000 个来自 Reddit 的道德困境进行评判，分析行为差异和价值取向。

Result: GPT 表现出较强的惯性（0.6-3.1% 的修正率），而 Claude 和 Gemini 则更为灵活（28-41%）。GPT 强调个人自主和直接沟通，Claude 和 Gemini 则侧重共情对话。对话格式显著影响模型行为，GPT 和 Gemini 更倾向于服从，其判决行为受顺序效应影响。

Conclusion: 多轮交互中，对话格式和模型特有的行为会影响道德推理，表明社会技术对齐不仅取决于模型输出，还取决于对话结构。

Abstract: As large language models (LLMs) are increasingly deployed in sensitive
everyday contexts - offering personal advice, mental health support, and moral
guidance - understanding their elicited values in navigating complex moral
reasoning is essential. Most evaluations study this sociotechnical alignment
through single-turn prompts, but it is unclear if these findings extend to
multi-turn settings where values emerge through dialogue, revision, and
consensus. We address this gap using LLM debate to examine deliberative
dynamics and value alignment in multi-turn settings by prompting subsets of
three models (GPT-4.1, Claude 3.7 Sonnet, and Gemini 2.0 Flash) to collectively
assign blame in 1,000 everyday dilemmas from Reddit's "Am I the Asshole"
community. We use both synchronous (parallel responses) and round-robin
(sequential responses) formats to test order effects and verdict revision. Our
findings show striking behavioral differences. In the synchronous setting, GPT
showed strong inertia (0.6-3.1% revision rates) while Claude and Gemini were
far more flexible (28-41%). Value patterns also diverged: GPT emphasized
personal autonomy and direct communication, while Claude and Gemini prioritized
empathetic dialogue. Certain values proved especially effective at driving
verdict changes. We further find that deliberation format had a strong impact
on model behavior: GPT and Gemini stood out as highly conforming relative to
Claude, with their verdict behavior strongly shaped by order effects. These
results show how deliberation format and model-specific behaviors shape moral
reasoning in multi-turn interactions, underscoring that sociotechnical
alignment depends on how systems structure dialogue as much as on their
outputs.

</details>


### [563] [RIPRAG: Hack a Black-box Retrieval-Augmented Generation Question-Answering System with Reinforcement Learning](https://arxiv.org/abs/2510.10008)
*Meng Xi,Sihan Lv,Yechen Jin,Guanjie Cheng,Naibo Wang,Ying Li,Jianwei Yin*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Retrieval-Augmented Generation (RAG) systems based on Large Language Models
(LLMs) have become a core technology for tasks such as question-answering (QA)
and content generation. However, by injecting poisoned documents into the
database of RAG systems, attackers can manipulate LLMs to generate text that
aligns with their intended preferences. Existing research has primarily focused
on white-box attacks against simplified RAG architectures. In this paper, we
investigate a more complex and realistic scenario: the attacker lacks knowledge
of the RAG system's internal composition and implementation details, and the
RAG system comprises components beyond a mere retriever. Specifically, we
propose the RIPRAG attack framework, an end-to-end attack pipeline that treats
the target RAG system as a black box, where the only information accessible to
the attacker is whether the poisoning succeeds. Our method leverages
Reinforcement Learning (RL) to optimize the generation model for poisoned
documents, ensuring that the generated poisoned document aligns with the target
RAG system's preferences. Experimental results demonstrate that this method can
effectively execute poisoning attacks against most complex RAG systems,
achieving an attack success rate (ASR) improvement of up to 0.72 compared to
baseline methods. This highlights prevalent deficiencies in current defensive
methods and provides critical insights for LLM security research.

</details>


### [564] [LLMs as Strategic Agents: Beliefs, Best Response Behavior, and Emergent Heuristics](https://arxiv.org/abs/2510.10813)
*Enric Junque de Fortuny,Veronica Roberta Cappelli*

Main category: cs.AI

TL;DR: LLMs在涉及其他代理行为的推理领域（如谈判、策略设计和市场模拟）中得到越来越广泛的应用，但现有研究主要评估它们对均衡博弈的遵守程度或其推理深度。它们是否表现出真正的战略思维，即对其他代理形成连贯的信念、评估可能的行动并根据这些信念进行选择，这一点仍有待探索。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs是否表现出真正的战略思维，即对其他代理形成连贯的信念、评估可能的行动并根据这些信念进行选择。

Method: 开发一个框架，通过区分静态、完全信息的博弈中的信念、评估和选择来识别这种能力，并将其应用于一系列非合作环境。通过联合分析模型揭示的选择和推理痕迹，并引入一个新的无上下文博弈以排除记忆模仿，我们展示了当前前沿模型在有针对性的推理深度上表现出信念连贯的最佳回应行为。

Result: 当前前沿模型在有针对性的推理深度上表现出信念连贯的最佳回应行为。当不受约束时，它们会自我限制推理深度，并对人类和合成对手形成差异化的猜测，从而揭示出一种元推理的涌现形式。在复杂性增加的情况下，显式递归让位于内部生成的选择启发式规则，这些规则是稳定、模型特定且不同于已知的人类偏差。

Conclusion: 信念连贯、元推理和新启发式规则的形成可以从语言建模目标中共同涌现，为研究人工智能代理的战略认知提供了一个结构化基础。

Abstract: Large Language Models (LLMs) are increasingly applied to domains that require
reasoning about other agents' behavior, such as negotiation, policy design, and
market simulation, yet existing research has mostly evaluated their adherence
to equilibrium play or their exhibited depth of reasoning. Whether they display
genuine strategic thinking, understood as the coherent formation of beliefs
about other agents, evaluation of possible actions, and choice based on those
beliefs, remains unexplored. We develop a framework to identify this ability by
disentangling beliefs, evaluation, and choice in static, complete-information
games, and apply it across a series of non-cooperative environments. By jointly
analyzing models' revealed choices and reasoning traces, and introducing a new
context-free game to rule out imitation from memorization, we show that current
frontier models exhibit belief-coherent best-response behavior at targeted
reasoning depths. When unconstrained, they self-limit their depth of reasoning
and form differentiated conjectures about human and synthetic opponents,
revealing an emergent form of meta-reasoning. Under increasing complexity,
explicit recursion gives way to internally generated heuristic rules of choice
that are stable, model-specific, and distinct from known human biases. These
findings indicate that belief coherence, meta-reasoning, and novel heuristic
formation can emerge jointly from language modeling objectives, providing a
structured basis for the study of strategic cognition in artificial agents.

</details>


### [565] [Failure-Driven Workflow Refinement](https://arxiv.org/abs/2510.10035)
*Jusheng Zhang,Kaitong Cai,Qinglin Zeng,Ningyuan Liu,Stephen Fan,Ziliang Chen,Keze Wang*

Main category: cs.AI

TL;DR: 通过最小化预期故障质量来优化基于LLM的工作流，而不是最大化标量分数。


<details>
  <summary>Details</summary>
Motivation: 现有的基于标量指标的工作流优化方法存在信息折叠问题，无法模拟工作流的故障分布。

Method: 提出一种新的范式，将工作流优化视为一个分布问题，通过最小化预期故障质量（EFM）来解决。引入CE-Graph框架，通过反例近似故障分布，识别常见的故障模式，并利用受约束的图编辑来减少故障质量。

Result: 在数学、代码和问答基准测试中，CE-Graph的鲁棒性更高，成本更低。

Conclusion: 系统的可靠性来自于系统地学习和重塑其故障分布的几何结构，而不是避免故障。

Abstract: Optimizing LLM-based workflows is typically formulated as a global search,
where candidate workflows are evaluated based on a scalar metric. This
paradigm, however, suffers from a critical flaw: information collapse. By
reducing rich, multi-step execution traces to simple success/failure signals,
existing methods are rendered blind to the underlying structure of failures,
fundamentally preventing them from modeling the workflow's failure
distribution. We reconceptualize this challenge as a distributional problem. We
propose a new paradigm where the optimization goal is not to maximize a scalar
score, but to directly minimize a workflow's Expected Failure Mass, i.e., the
integral of its failure probability density function defined over a
high-dimensional Failure Signature Space (FSS). This distributional lens allows
us to move from inefficient, zero-order optimization to a principled,
gradient-like descent on the failure landscape itself. We introduce CE-Graph, a
framework that operationalizes this paradigm through a novel, failure-driven
refinement process. CE-Graph approximates the failure distribution from a pool
of counterexamples, identifies its densest regions as recurring failure modes,
and applies targeted, operator-constrained graph edits via a Propose-and-Verify
mechanism to greedily reduce the failure mass. On math, code, and QA
benchmarks, our CE-Graph achieves higher robustness at a significantly lower
cost than strong baselines. This suggests that a system's reliability emerges
not from avoiding failures, but from systematically learning and reshaping the
geometric structure of its failure distributions.

</details>


### [566] [Extended Triangular Method: A Generalized Algorithm for Contradiction Separation Based Automated Deduction](https://arxiv.org/abs/2510.10701)
*Yang Xu,Shuwei Chen,Jun Liu,Feng Cao,Xingxing He*

Main category: cs.AI

TL;DR: 本篇论文提出了一种名为扩展三角法（ETM）的通用矛盾构建算法，该算法形式化并扩展了矛盾分离机制，统一了多种矛盾构建策略，并将其置于一个灵活的三角几何框架中。ETM 作为高性能定理证明器的核心算法，在标准一阶逻辑基准测试中取得了优异的成绩，证明了该方法的有效性和通用性。


<details>
  <summary>Details</summary>
Motivation: 传统基于二元归结的推理方法在效率和完备性之间存在挑战，限制了多子句间的推理协同。2018 年提出的矛盾分离扩展（CSE）框架提出了一种动态多子句推理理论，但缺乏算法实现。本研究旨在解决这一问题，提出一种新的算法框架。

Method: 本文提出了扩展三角法（ETM），一个形式化且泛化的矛盾构建算法。ETM 将多种矛盾构建策略（包括标准扩展方法）统一在一个三角几何框架内，实现了灵活的子句交互和动态协同。该算法是 CSE、CSE-E、CSI-E 和 CSI-Enig 等高性能定理证明器的核心。

Result: ETM 作为核心算法的几个高性能定理证明器在 TPTP 问题集和 CASC 2018-2015 等标准一阶逻辑基准测试中取得了有竞争力的结果，验证了该方法的有效性和通用性。

Conclusion: ETM 算法将矛盾分离范式推广为一个通用、可扩展且具有实际竞争力的自动化推理模型，弥合了理论抽象与操作实现之间的差距，为逻辑推理和定理证明的未来研究开辟了新方向。

Abstract: Automated deduction lies at the core of Artificial Intelligence (AI),
underpinning theorem proving, formal verification, and logical reasoning.
Despite decades of progress, reconciling deductive completeness with
computational efficiency remains an enduring challenge. Traditional reasoning
calculi, grounded in binary resolution, restrict inference to pairwise clause
interactions and thereby limit deductive synergy among multiple clauses. The
Contradiction Separation Extension (CSE) framework, introduced in 2018,
proposed a dynamic multi-clause reasoning theory that redefined logical
inference as a process of contradiction separation rather than sequential
resolution. While that work established the theoretical foundation, its
algorithmic realization remained unformalized and unpublished. This work
presents the Extended Triangular Method (ETM), a generalized
contradiction-construction algorithm that formalizes and extends the internal
mechanisms of contradiction separation. The ETM unifies multiple
contradiction-building strategies, including the earlier Standard Extension
method, within a triangular geometric framework that supports flexible clause
interaction and dynamic synergy. ETM serves as the algorithmic core of several
high-performance theorem provers, CSE, CSE-E, CSI-E, and CSI-Enig, whose
competitive results in standard first-order benchmarks (TPTP problem sets and
CASC 2018-2015) empirically validate the effectiveness and generality of the
proposed approach. By bridging theoretical abstraction and operational
implementation, ETM advances the contradiction separation paradigm into a
generalized, scalable, and practically competitive model for automated
reasoning, offering new directions for future research in logical inference and
theorem proving.

</details>


### [567] [Belief Graphs with Reasoning Zones: Structure, Dynamics, and Epistemic Activation](https://arxiv.org/abs/2510.10042)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.AI

TL;DR: 该研究提出了一种新的图论框架，用于在信念系统存在全局不一致的情况下进行局部推理。


<details>
  <summary>Details</summary>
Motivation: 有效推理通常在局部持续存在，但信念系统很少是全局一致的。

Method: 提出了一种图论框架，将可信度（外部信任）与置信度（网络结构引起的内部估值）分离开来。置信度通过结合先验信息和结构感知影响的收缩传播过程获得。定义了推理区域：高置信度、结构平衡的子图，在这些子图上可以进行经典推理。提出了一个近乎线性的过程来识别这些区域，包括使用基于奇偶校验的着色来测试平衡，以及使用 Jaccard 去重进行贪婪修复。为了模拟信念变化，引入了冲击更新，并通过简单的回溯规则来局部缩减支持并提升目标矛盾，同时保持收缩性。

Result: 在合成带区域的带符号图上进行了经验评估，报告了区域恢复、冲击下的稳定性和运行时间。

Conclusion: 该研究为容忍矛盾的推理提供了一个原则性基础，可以在结构支持它的地方激活经典逻辑。

Abstract: Belief systems are rarely globally consistent, yet effective reasoning often
persists locally. We propose a novel graph-theoretic framework that cleanly
separates credibility--external, a priori trust in sources--from confidence--an
internal, emergent valuation induced by network structure. Beliefs are nodes in
a directed, signed, weighted graph whose edges encode support and
contradiction. Confidence is obtained by a contractive propagation process that
mixes a stated prior with structure-aware influence and guarantees a unique,
stable solution. Within this dynamics, we define reasoning zones:
high-confidence, structurally balanced subgraphs on which classical inference
is safe despite global contradictions. We provide a near-linear procedure that
seeds zones by confidence, tests balance using a parity-based coloring, and
applies a greedy, locality-preserving repair with Jaccard de-duplication to
build a compact atlas. To model belief change, we introduce shock updates that
locally downscale support and elevate targeted contradictions while preserving
contractivity via a simple backtracking rule. Re-propagation yields localized
reconfiguration-zones may shrink, split, or collapse--without destabilizing the
entire graph. We outline an empirical protocol on synthetic signed graphs with
planted zones, reporting zone recovery, stability under shocks, and runtime.
The result is a principled foundation for contradiction-tolerant reasoning that
activates classical logic precisely where structure supports it.

</details>


### [568] [SwarmSys: Decentralized Swarm-Inspired Agents for Scalable and Adaptive Reasoning](https://arxiv.org/abs/2510.10047)
*Ruohao Li,Hongjun Liu,Leyi Zhao,Zisu Li,Jiawei Li,Jiajun Jiang,Linning Xu,Chen Zhao,Mingming Fan,Chen Liang*

Main category: cs.AI

TL;DR: SwarmSys是一个受群体智能启发的闭环框架，用于分布式多智能体推理，通过探索者、工作者和验证者之间的迭代互动实现协调，并在各种任务中优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体框架通常依赖于固定的角色或集中式控制，这限制了长时推理的可扩展性和适应性。

Method: SwarmSys框架集成了自适应智能体和事件配置、基于嵌入的概率匹配以及受信息素启发的增强机制，以实现可扩展和自适应的协作。

Result: SwarmSys在符号推理、研究综合和科学编程任务中的准确性和推理稳定性方面始终优于基线。

Conclusion: 受群体启发的协调是可扩展、健壮和自适应的多智能体推理的一个有前途的范例，可能与模型扩展在提高LLM智能方面相媲美。

Abstract: Large language model (LLM) agents have shown remarkable reasoning abilities.
However, existing multi-agent frameworks often rely on fixed roles or
centralized control, limiting scalability and adaptability in long-horizon
reasoning. We introduce SwarmSys, a closed-loop framework for distributed
multi-agent reasoning inspired by swarm intelligence. Coordination in SwarmSys
emerges through iterative interactions among three specialized roles,
Explorers, Workers, and Validators, that continuously cycle through
exploration, exploitation, and validation. To enable scalable and adaptive
collaboration, we integrate adaptive agent and event profiles, embedding-based
probabilistic matching, and a pheromone-inspired reinforcement mechanism,
supporting dynamic task allocation and self-organizing convergence without
global supervision. Across symbolic reasoning, research synthesis, and
scientific programming tasks, SwarmSys consistently outperforms baselines,
improving both accuracy and reasoning stability. These findings highlight
swarm-inspired coordination as a promising paradigm for scalable, robust, and
adaptive multi-agent reasoning, suggesting that coordination scaling may rival
model scaling in advancing LLM intelligence.

</details>


### [569] [SyncLipMAE: Contrastive Masked Pretraining for Audio-Visual Talking-Face Representation](https://arxiv.org/abs/2510.10069)
*Zeyu Ling,Xiaodong Gu,Jiangnan Tang,Changqing Zou*

Main category: cs.AI

TL;DR: SyncLipMAE是一个用于语音驱动的说话人脸视频的自监督预训练框架，通过掩码视觉建模和跨模态对比学习，显式编码身份、语音和环境运动等因素，实现了高度可迁移的面部动态学习，并在多种下游任务中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 为了学习说话人脸视频中与同步相关的、可迁移的面部动态，利用无标签的音频-视频流。

Method: 结合掩码视觉建模和跨模态对比学习，使用三种每帧的提示符（身份、语音运动、环境运动）来显式编码说话人脸帧的关键因素。对比学习的目标是使时间对齐的语音运动和音频令牌作为正例，未对齐的对作为负例，将两种模态映射到共享的嵌入空间，实现令牌级别的音视频流同步。

Result: 在预训练后，对齐的音频令牌与视觉提示符（身份、语音运动、环境运动）共同构成了一个统一的接口，用于四个不同的下游任务：(i) 音视频流同步；(ii) 面部表情和头部/面部动作识别；(iii) 视觉语音识别；(iv) 视觉配音。SyncLipMAE 在这四个任务中均取得了最先进的成果。

Conclusion: SyncLipMAE 证明了与同步感知、因子化自监督预训练在说话人脸视频分析任务中的有效性。

Abstract: We introduce SyncLipMAE, a self-supervised pretraining framework for
talking-face video that learns synchronization-aware and transferable facial
dynamics from unlabeled audio-visual streams. Our approach couples masked
visual modeling with cross-modal contrastive alignment and employs three
per-frame prompt tokens that explicitly encode the essential factors of a
talking-face frame - identity, vocal motion (speech-synchronized facial
dynamics), and ambient motion (audio-agnostic movements such as blinks and head
pose). The contrastive objective uses time-aligned vocal-motion and audio
tokens as positives and misaligned pairs as negatives, driving both modalities
into a shared embedding space and yielding token-level audio-visual stream
synchronization. After pretraining, the aligned audio tokens together with the
visual prompt tokens (identity, vocal motion, ambient motion) form a unified
interface for four disparate downstream settings: (i) audio-visual stream
synchronization; (ii) facial emotion and head/face action recognition; (iii)
visual speech recognition; and (iv) visual dubbing, for which we enable
indistinguishable audio- or video-driven control within a single model. Across
four task families that require distinct capabilities, SyncLipMAE achieves
state-of-the-art results, underscoring the effectiveness of
synchronization-aware, factorized self-supervised pretraining.

</details>


### [570] [Agentic Troubleshooting Guide Automation for Incident Management](https://arxiv.org/abs/2510.10074)
*Jiayi Mao,Liqun Li,Yanjie Gao,Zegang Peng,Shilin He,Chaoyun Zhang,Si Qin,Samia Khalid,Qingwei Lin,Saravan Rajmohan,Sitaram Lanka,Dongmei Zhang*

Main category: cs.AI

TL;DR: StepFly是一个创新的框架，旨在通过自动化故障排除指南（TSG）来改进大规模IT系统的事件管理。它通过三个阶段解决现有基于LLM的解决方案在TSG质量、复杂控制流解释、数据密集型查询处理和并行执行方面的不足。该框架包括一个用于改进TSG质量的TSG Mentor工具，一个用于提取结构化执行图（DAG）和创建查询准备插件（QPPs）的离线预处理阶段，以及一个用于保证正确工作流和支持并行执行的在线DAG引导调度执行器框架。实验证明StepFly在GPT-4.1上取得了约94%的成功率，并且在可并行化的TSG方面显著减少了执行时间。


<details>
  <summary>Details</summary>
Motivation: 手动执行故障排除指南（TSG）效率低下且容易出错，需要一种更自动化的方法来管理大规模IT系统中的事件。

Method: StepFly框架包含三个阶段：1. TSG Mentor工具协助SRE提高TSG质量。2. 离线预处理阶段使用LLM从非结构化TSG中提取结构化执行DAG，并创建查询准备插件（QPPs）。3. 在线执行阶段使用DAG引导的调度执行器框架和内存系统来保证正确的工作流程并支持独立步骤的并行执行。

Result: StepFly在GPT-4.1上实现了约94%的成功率，优于基线方法，同时减少了时间和令牌消耗。对于可并行化的TSG，执行时间减少了32.9%至70.4%。

Conclusion: StepFly通过其创新的三阶段方法，有效地自动化了故障排除指南，提高了事件管理的效率和准确性，并显著减少了执行时间和资源消耗。

Abstract: Effective incident management in large-scale IT systems relies on
troubleshooting guides (TSGs), but their manual execution is slow and
error-prone. While recent advances in LLMs offer promise for automating
incident management tasks, existing LLM-based solutions lack specialized
support for several key challenges, including managing TSG quality issues,
interpreting complex control flow, handling data-intensive queries, and
exploiting execution parallelism. We first conducted an empirical study on 92
real-world TSGs, and, guided by our findings, we present StepFly, a novel
end-to-end agentic framework for troubleshooting guide automation. Our approach
features a three-stage workflow: the first stage provides a comprehensive guide
together with a tool, TSG Mentor, to assist SREs in improving TSG quality; the
second stage performs offline preprocessing using LLMs to extract structured
execution DAGs from unstructured TSGs and to create dedicated Query Preparation
Plugins (QPPs); and the third stage executes online using a DAG-guided
scheduler-executor framework with a memory system to guarantee correct workflow
and support parallel execution of independent steps. Our empirical evaluation
on a collection of real-world TSGs and incidents demonstrates that StepFly
achieves a ~94% success rate on GPT-4.1, outperforming baselines with less time
and token consumption. Furthermore, it achieves a remarkable execution time
reduction of 32.9% to 70.4% for parallelizable TSGs.

</details>


### [571] [DixitWorld: Evaluating Multimodal Abductive Reasoning in Vision-Language Models with Multi-Agent Dixit Gameplay](https://arxiv.org/abs/2510.10117)
*Yunxiang Mo,Tianshi Zheng,Qing Zong,Jiayu Liu,Baixuan Xu,Yauwai Yim,Chunkit Chan,Jiaxin Bai,Yangqiu Song*

Main category: cs.AI

TL;DR: DixitWorld是一个用于评估多模态溯因推理能力的综合评估套件，包含 DixitArena（动态多代理环境）和 DixitBench（静态QA基准）。研究结果揭示了生成创造力与判别性理解之间的权衡，并强调了在多模态溯因推理中平衡这两种能力对于开发更强大的视觉语言模型的重要性。


<details>
  <summary>Details</summary>
Motivation: 评估当前视觉语言模型（VLMs）在多模态溯因推理方面的能力，并为该领域的研究提供一个更全面的评估框架。

Method: 提出并实现了DixitWorld评估套件，该套件包括DixitArena（一个动态的多代理环境，用于评估假设生成和选择）和DixitBench（一个静态的QA基准，用于隔离和评估假设选择）。

Result: DixitArena 的结果显示，不同规模和类型的模型在生成器（故事讲述者）和选择器（听众）角色上表现出不同的行为。较小的开源模型更具创造性，而较大的专有模型在整体表现和听众角色上更优。DixitBench 的结果与 DixitArena 中的听众表现高度相关，证明了其作为假设选择代理的有效性。

Conclusion: 多模态溯因推理中存在生成创造力与判别性理解之间的关键权衡。DixitWorld 为评估和改进视觉语言模型在这方面的能力提供了一个有价值的工具，并指明了未来研究的方向，即开发更均衡、更强大的视觉语言智能体。

Abstract: Multimodal abductive reasoning--the generation and selection of explanatory
hypotheses from partial observations--is a cornerstone of intelligence. Current
evaluations of this ability in vision-language models (VLMs) are largely
confined to static, single-agent tasks. Inspired by Dixit, we introduce
DixitWorld, a comprehensive evaluation suite designed to deconstruct this
challenge. DIXITWORLD features two core components: DixitArena, a dynamic,
multi-agent environment that evaluates both hypothesis generation (a
"storyteller" crafting cryptic clues) and hypothesis selection ("listeners"
choosing the target image from decoys) under imperfect information; and
DixitBench, a static QA benchmark that isolates the listener's task for
efficient, controlled evaluation. Results from DixitArena reveal distinct,
role-dependent behaviors: smaller open-source models often excel as creative
storytellers, producing imaginative yet less discriminative clues, whereas
larger proprietary models demonstrate superior overall performance,
particularly as listeners. Performance on DixitBench strongly correlates with
listener results in DixitArena, validating it as a reliable proxy for
hypothesis selection. Our findings reveal a key trade-off between generative
creativity and discriminative understanding in multimodal abductive reasoning,
a central challenge for developing more balanced and capable vision-language
agents.

</details>


### [572] [CharCom: Composable Identity Control for Multi-Character Story Illustration](https://arxiv.org/abs/2510.10135)
*Zhongsheng Wang,Ming Lin,Zhedong Lin,Yaser Shakib,Qian Liu,Jiamou Liu*

Main category: cs.AI

TL;DR: CharCom是一个新框架，可以通过组合LoRA适配器来保持角色身份在文生图中的一致性，无需重新训练基础模型。


<details>
  <summary>Details</summary>
Motivation: 现有文生图模型在处理跨不同提示的角色身份一致性方面存在局限性。

Method: CharCom使用可组合的LoRA适配器，在推理时通过提示感知控制动态组合这些适配器，以实现角色一致的故事插图。该框架建立在冻结的扩散骨干之上，并能进行每角色的高效定制。

Result: 实验表明，CharCom在多场景叙事中显著提高了角色的保真度、语义对齐和时间连贯性，即使在拥挤的场景中也表现稳健，并且能够以最小的开销实现可扩展的多角色生成。

Conclusion: CharCom是一种适用于故事插图和动画等现实世界应用的有效方法，可以解决文生图中的角色身份一致性问题。

Abstract: Ensuring character identity consistency across varying prompts remains a
fundamental limitation in diffusion-based text-to-image generation. We propose
CharCom, a modular and parameter-efficient framework that achieves
character-consistent story illustration through composable LoRA adapters,
enabling efficient per-character customization without retraining the base
model. Built on a frozen diffusion backbone, CharCom dynamically composes
adapters at inference using prompt-aware control. Experiments on multi-scene
narratives demonstrate that CharCom significantly enhances character fidelity,
semantic alignment, and temporal coherence. It remains robust in crowded scenes
and enables scalable multi-character generation with minimal overhead, making
it well-suited for real-world applications such as story illustration and
animation.

</details>


### [573] [Concise Reasoning in the Lens of Lagrangian Optimization](https://arxiv.org/abs/2510.10168)
*Chengqian Gao,Haonan Li,Taylor W. Killian,Jianshu She,Renxi Wang,Liqun Ma,Zhoujun Cheng,Shibo Hao,Zhiqiang Xu*

Main category: cs.AI

TL;DR: PALU通过将简洁推理视为一个约束优化问题，并采用拉格朗日优化和近似方法，在减少模型输出长度的同时提高了准确性，并且能够适应不同领域和模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在生成推理过程时，往往会产生冗余的中间步骤，即“过度思考”的问题。虽然一些方法试图通过精心设计的启发式规则来解决这个问题，但它们在简洁性和性能之间难以平衡，并且难以适应不同的领域和模型规模。

Method: PALU将简洁推理定义为一个约束优化问题，目标是最小化响应长度，同时满足性能约束。通过拉格朗日优化将其转化为一个可处理的无约束问题。为了简化计算，PALU采用了三种近似方法：(1) 使用离策略回放来估计性能；(2) 将拉格朗日乘子截断为两个极端值；(3) 用分位数驱动的长度调整代替基于梯度的更新。

Result: PALU在DeepSeek-Distill-Qwen-1.5B模型上，在五个基准测试的平均评估中，将输出长度减少了65%，同时将准确率提高了15%，优于多种替代方法。此外，PALU在逻辑、STEM和数学等不同领域以及1.5B、7B、14B等不同模型规模上都表现出良好的适应性。

Conclusion: PALU是一种原则性强且实用的简洁推理算法，通过将简洁推理形式化为约束优化问题，并结合有效的近似策略，能够显著减少大语言模型的输出长度，同时提高其准确性，并且具有跨领域和跨模型规模的适应性，是一种有效且实用的简洁推理方法。

Abstract: Concise reasoning in large language models seeks to generate only essential
intermediate steps needed to arrive at a final answer, thereby alleviating
issues of overthinking. Most proposed approaches hinge on carefully
hand-crafted heuristics, struggling to balance concision with performance,
often failing to adapt across domains and model scales. In this work, we
address these challenges by introducing a principled and pragmatic strategy,
performance-aware length updating (PALU). As a principled algorithm, PALU
formulates concise reasoning as a constrained optimization problem, minimizing
response length subject to a performance constraint, and then applies
Lagrangian optimization to convert it into a tractable unconstrained problem.
As a pragmatic solution, PALU streamlines complicated update rules through
three approximations: (i) estimating performance with off-policy rollouts, (ii)
truncating the Lagrange multiplier to two extremes, and (iii) replacing
gradient-based updates with quantile-driven length adjustments. PALU reduces
output length by 65% while improving accuracy by 15% when applied to
DeepSeek-Distill-Qwen-1.5B, averaged over five benchmarks, outperforming a
range of alternative methods. Furthermore, PALU is demonstrated to adapt across
both domain (logic, STEM and math) and model scale (1.5B, 7B, 14B) entrenching
the algorithm as a practical and effective concise reasoning approach.

</details>


### [574] [SAFER: Risk-Constrained Sample-then-Filter in Large Language Models](https://arxiv.org/abs/2510.10193)
*Qingni Wang,Yue Fan,Xin Eric Wang*

Main category: cs.AI

TL;DR: 本研究提出了一种名为SAFER的两阶段风险控制框架，用于提高大型语言模型在风险敏感应用中的可信度，特别是在开放式问答场景下，解决了现有方法无法处理无限答案空间的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在风险敏感应用中（如开放式问答）的可信度至关重要。然而，现有的选择性共形预测（SCP）方法假设所有实例的满意答案可以通过有限采样获得，这对于没有固定且有限解空间的开放式问答场景是不现实的。

Method: SAFER框架包含两个阶段：1. 风险控制：在独立的校准集上，使用Clopper-Pearson精确方法，在用户期望的风险水平下校准一个采样预算（在最大采样上限内）。如果无法满足风险水平，则弃权；否则，该预算成为测试时的最低要求。2. 共形过滤：利用在校准预算下可获得正确答案的校准实例，应用共形风险控制方法确定一个统计上有效的置信度阈值，以过滤掉测试数据点候选集中的不可靠选项。

Result: SAFER框架能够有效控制风险，即使在答案空间无限的情况下也能提供统计保证。此外，该方法与多种特定任务的准入标准和校准-测试拆分比例兼容，显示了其鲁棒性和高数据效率。

Conclusion: SAFER框架通过两阶段风险控制，包括弃权感知采样和共形过滤，解决了现有共形预测方法在处理开放式问答等无限答案空间场景时的局限性，为提高LLM在风险敏感应用中的可信度提供了有效解决方案。

Abstract: As large language models (LLMs) are increasingly deployed in risk-sensitive
applications such as real-world open-ended question answering (QA), ensuring
the trustworthiness of their outputs has become critical. Existing selective
conformal prediction (SCP) methods provide statistical guarantees by
constructing prediction sets with a constrained miscoverage rate for correct
answers. However, prior works unrealistically assume that admissible answers
for all instances can be obtained via finite sampling, even for open-ended QA
scenarios that lack a fixed and finite solution space. To address this, we
introduce a two-stage risk control framework comprising abstention-aware
sampling and conformalized filtering (SAFER). Firstly, on a held-out
calibration set, SAFER calibrates a sampling budget within the maximum sampling
cap, using the Clopper-Pearson exact method at a user-desired risk level (i.e.,
the maximum allowable miscoverage rate of the sampling sets). If the risk level
cannot be satisfied within the cap, we abstain; otherwise, the calibrated
sampling budget becomes the minimum requirements at test time. Then, we employ
calibration instances where correct answers are attainable under the calibrated
budget and apply the conformal risk control method to determine a statistically
valid uncertainty threshold, which filters unreliable distractors from the
candidate set for each test data point. In this stage, SAFER introduces an
additional risk level to guide the calculation of the threshold, thereby
controlling the risk of correct answers being excluded. Furthermore, we show
that SAFER is compatible with various task-specific admission criteria and
calibration-test split ratios, highlighting its robustness and high data
efficiency.

</details>


### [575] [Don't Just Fine-tune the Agent, Tune the Environment](https://arxiv.org/abs/2510.10197)
*Siyuan Lu,Zechuan Wang,Hongxuan Zhang,Qintong Wu,Leilei Gan,Chenyi Zhuang,Jinjie Gu,Tao Lin*

Main category: cs.AI

TL;DR: LLM代理在复杂的多轮工具使用任务中展现出巨大潜力，但高质量训练数据极其稀缺。本文提出了一种名为“环境调优”的新训练范式，使代理能够直接从问题实例中学习复杂行为，而无需预先收集的专家轨迹。该方法通过结构化课程、可操作的环境增强和细粒度进度奖励来确保稳定高效的探索。在仅使用400个BFCL基准问题实例的情况下，该方法在同类分布内性能上具有竞争力，并展现出卓越的分布外泛化能力，克服了基于SFT方法的常见性能崩溃问题。这标志着从在静态轨迹上进行监督微调转向动态、基于环境的探索，为训练更健壮、数据效率更高的代理铺平了道路。


<details>
  <summary>Details</summary>
Motivation: LLM代理在处理复杂的多轮工具使用任务方面潜力巨大，但高质量训练数据严重不足，导致监督微调（SFT）易过拟合，标准强化学习（RL）面临冷启动问题和训练不稳定的挑战。

Method: 提出了一种名为“环境调优”（Environment Tuning）的新训练范式。该范式不依赖预先收集的专家轨迹，而是通过结构化课程、可操作的环境增强（提供纠正性反馈）以及细粒度的进度奖励，引导代理直接从问题实例中学习复杂行为，以实现稳定高效的探索。

Result: 在仅使用400个BFCL基准问题实例的情况下，该方法取得了具有竞争力的同类分布内性能，并且表现出优越的分布外泛化能力，成功克服了基于SFT方法的性能崩溃问题。

Conclusion: “环境调优”是一种从在静态轨迹上进行监督微调转向动态、基于环境的探索的范式转变，能够训练出更健壮、数据效率更高的LLM代理。

Abstract: Large Language Model (LLM) agents show great promise for complex, multi-turn
tool-use tasks, but their development is often hampered by the extreme scarcity
of high-quality training data. Supervised fine-tuning (SFT) on synthetic data
leads to overfitting, whereas standard reinforcement learning (RL) struggles
with a critical cold-start problem and training instability. To address these
challenges, we introduce $\textbf{Environment Tuning}$, a novel training
paradigm that enables agents to learn complex behaviors directly from problem
instances without relying on pre-collected expert trajectories.
$\textbf{Environment Tuning}$ orchestrates this learning process through a
structured curriculum, actionable environment augmentation that provides
corrective feedback, and fine-grained progress rewards to ensure stable and
efficient exploration. Using only 400 problem instances from Berkeley
Function-Calling Leaderboard (BFCL) benchmark, our method not only achieves
competitive in-distribution performance against strong baselines but also
demonstrates superior out-of-distribution generalization, overcoming the
performance collapse common to SFT-based approaches. Our work presents a
paradigm shift from supervised fine-tuning on static trajectories to dynamic,
environment-based exploration, paving the way for training more robust and
data-efficient agents.

</details>


### [576] [PIXEL: Adaptive Steering Via Position-wise Injection with eXact Estimated Levels under Subspace Calibration](https://arxiv.org/abs/2510.10205)
*Manjiang Yu,Hongji Li,Priyanka Singh,Xue Li,Di Wang,Lijie Hu*

Main category: cs.AI

TL;DR: PIXEL是一种新颖的位置感知激活控制方法，通过学习特定于属性的子空间并优化干预强度，以实现更可靠、可控的语言模型生成。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型行为控制方法缺乏明确的指导，并且通常需要大量的调整，这使得在实际应用中部署大型语言模型（LLM）变得困难。因此，需要一种更精确、无需调整的方法来控制LLM的可信度和生成属性。

Method: PIXEL框架通过以下方式实现：1. 学习一个与目标属性对齐的子空间，该子空间从两个不同视角（尾部平均和末端标记）获得。2. 通过一个带有约束的几何目标，该目标具有封闭解，来精确地选择干预强度，从而适应标记级别的敏感性，避免全局超参数调整。3. 进行样本级别的正交残差校准，以优化全局属性方向。4. 采用轻量级的位置扫描例程，识别最适合进行干预的注入点。5. 提供表示级别的保证，以支持最小干预原则，确保可靠的对齐。

Result: 实验证明，PIXEL在各种模型和评估范式下，都能持续提高属性对齐度，同时保持模型的通用能力，证明了其作为一种实用且有原则的方法在LLM可控生成方面的有效性。

Conclusion: PIXEL框架为语言模型提供了可靠且可控的生成方法，通过位置感知干预和优化的强度选择，显著提升了生成内容的属性对齐度，同时不损害模型的整体性能。

Abstract: Reliable behavior control is central to deploying large language models
(LLMs) on the web. Activation steering offers a tuning-free route to align
attributes (e.g., truthfulness) that ensure trustworthy generation. Prevailing
approaches rely on coarse heuristics and lack a principled account of where to
steer and how strongly to intervene. To this end, we propose Position-wise
Injection with eXact Estimated Levels (PIXEL), a position-wise activation
steering framework that, in contrast to prior work, learns a property-aligned
subspace from dual views (tail-averaged and end-token) and selects intervention
strength via a constrained geometric objective with a closed-form solution,
thereby adapting to token-level sensitivity without global hyperparameter
tuning. PIXEL further performs sample-level orthogonal residual calibration to
refine the global attribute direction and employs a lightweight
position-scanning routine to identify receptive injection sites. We
additionally provide representation-level guarantees for the
minimal-intervention rule, supporting reliable alignment. Across diverse models
and evaluation paradigms, PIXEL consistently improves attribute alignment while
preserving model general capabilities, offering a practical and principled
method for LLMs' controllable generation. Our code is available at
https://github.com/V1centNevwake/PIXEL-Adaptive-Steering

</details>


### [577] [Adaptive Dual Reasoner: Large Reasoning Models Can Think Efficiently by Hybrid Reasoning](https://arxiv.org/abs/2510.10207)
*Yujian Zhang,Keyu Chen,Zhifeng Shen,Ruizhi Qiao,Xing Sun*

Main category: cs.AI

TL;DR: 长推理模型（LRMs）存在计算成本高和推理延迟长的问题，我们提出了自适应双推理器（ADR），它支持快思考和慢思考两种推理模式，并能根据上下文复杂度动态切换。ADR通过两阶段训练：1. 冷启动阶段，使用监督微调（SFT）和混合推理数据集来整合两种推理模式。2. 强化学习阶段，使用熵引导混合策略优化（EHPO）来优化推理成本，该框架采用熵引导动态 rollout 策略和难度感知惩罚来平衡推理。ADR在数学推理基准上实现了性能和效率的平衡，性能提升高达6.1%，同时推理输出长度减少49.5%至59.3%。


<details>
  <summary>Details</summary>
Motivation: 长推理模型（LRMs）虽然性能优越，但存在计算成本高和推理延迟长（“过度思考”）的问题。

Method: 提出自适应双推理器（ADR），支持快思考和慢思考两种模式，并根据上下文复杂度动态切换。ADR采用两阶段训练：1. 冷启动阶段：使用监督微调（SFT）和混合推理数据集。2. 强化学习阶段：使用熵引导混合策略优化（EHPO），该框架包含熵引导动态 rollout 策略和难度感知惩罚。

Result: ADR在数学推理基准上取得了良好的性能和效率平衡。与现有方法相比，性能提升高达6.1%，推理输出长度减少了49.5%至59.3%。

Conclusion: ADR通过引入快慢两种推理模式和两阶段训练策略，有效解决了长推理模型中存在的计算成本和推理延迟问题，并在保持高性能的同时显著提高了效率。

Abstract: Although Long Reasoning Models (LRMs) have achieved superior performance on
various reasoning scenarios, they often suffer from increased computational
costs and inference latency caused by overthinking. To address these
limitations, we propose Adaptive Dual Reasoner, which supports two reasoning
modes: fast thinking and slow thinking. ADR dynamically alternates between
these modes based on the contextual complexity during reasoning. ADR is trained
in two stages: (1) A cold-start stage using supervised fine-tuning (SFT) to
equip the model with the ability to integrate both fast and slow reasoning
modes, in which we construct a hybrid reasoning dataset through a dedicated
pipeline to provide large-scale supervision. (2) A reinforcement learning stage
for optimizing reasoning effort, where we introduce Entropy-guided Hybrid
Policy Optimization EHPO, an RL training framework employing an entropy-guided
dynamic rollout strategy for branching at high-entropy units and a
difficulty-aware penalty to balance fast and slow reasoning. Across challenging
mathematical reasoning benchmarks, ADR achieves an effective balance between
reasoning performance and efficiency among state-of-the-art approaches.
Specifically, ADR yields a performance gain of up to 6.1%, while reducing the
reasoning output length by 49.5% to 59.3%.

</details>


### [578] [The Achilles' Heel of LLMs: How Altering a Handful of Neurons Can Cripple Language Abilities](https://arxiv.org/abs/2510.10238)
*Zixuan Qin,Kunlin Lyu,Qingchen Yu,Yifan Sun,Zhaoxin Fan*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）中存在超稀疏的关键神经元子集，这些神经元主要集中在外层，其扰动会导致模型性能发生急剧的相位转变。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）是否像人脑一样，包含一小部分对核心认知功能至关重要的关键神经元。

Method: 提出一种基于扰动的因果识别关键神经元（Perturbation-based Causal Identification of Critical Neurons）的方法来系统地定位LLMs中的关键神经元。

Result: 1. LLMs包含超稀疏的关键神经元子集，扰乱这些神经元会导致一个拥有11亿神经元的72B参数模型完全崩溃，困惑度增加高达20个数量级。 2. 关键神经元倾向于集中在外层，特别是在MLP的down_proj组件中。 3. 扰乱关键神经元会导致性能下降呈现急剧的相位转变，而非逐渐下降。

Conclusion: LLMs确实包含超稀疏的关键神经元，它们集中在外层，并且对模型性能至关重要。这一发现对LLM的鲁棒性、可解释性、模型架构设计以及安全部署具有重要意义。

Abstract: Large Language Models (LLMs) have become foundational tools in natural
language processing, powering a wide range of applications and research. Many
studies have shown that LLMs share significant similarities with the human
brain. Recent neuroscience research has found that a small subset of biological
neurons in the human brain are crucial for core cognitive functions, which
raises a fundamental question: do LLMs also contain a small subset of critical
neurons? In this paper, we investigate this question by proposing a
Perturbation-based Causal Identification of Critical Neurons method to
systematically locate such critical neurons in LLMs. Our findings reveal three
key insights: (1) LLMs contain ultra-sparse critical neuron sets. Disrupting
these critical neurons can cause a 72B-parameter model with over 1.1 billion
neurons to completely collapse, with perplexity increasing by up to 20 orders
of magnitude; (2) These critical neurons are not uniformly distributed, but
tend to concentrate in the outer layers, particularly within the MLP down\_proj
components; (3) Performance degradation exhibits sharp phase transitions,
rather than a gradual decline, when these critical neurons are disrupted.
Through comprehensive experiments across diverse model architectures and
scales, we provide deeper analysis of these phenomena and their implications
for LLM robustness and interpretability. These findings can offer guidance for
developing more robust model architectures and improving deployment security in
safety-critical applications.

</details>


### [579] [Mitigating Hallucination in Multimodal Reasoning via Functional Attention Control](https://arxiv.org/abs/2510.10285)
*Haolang Lu,Bolun Chu,WeiYe Fu,Guoshun Nan,Junning Liu,Minghui Pan,Qiankun Li,Yi Yu,Hua Wang,Kun Wang*

Main category: cs.AI

TL;DR: 幻觉是多模态大模型（MLRMs）的一个持续存在的问题，会导致错误的推理和对视觉内容的误解。本研究提出了一种名为“功能头识别和类别条件重缩放”的两步插件，用于解决感知偏差和推理漂移问题，无需重新训练即可提高模型的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 幻觉是多模态大模型（MLRMs）中的一个关键问题，表现为错误的推理链和视觉内容误解，阻碍了其在现实世界的应用，尤其是在高风险场景下。

Method: 提出了一种名为“功能头识别和类别条件重缩放”的两步插件。该插件能够识别感知和推理导向的注意力头，并调节它们的贡献，而无需重新训练模型。它通过分析注意力头的分层结构来区分感知（浅层头）和推理（深层头）功能，并相应地进行调整。

Result: 在三个 MLRM（Kimi-VL、Ocean-R1、R1-Onevision）、六个基准测试和四个基线上的评估显示，该插件平均可提高 5%，最高可达 15%，同时计算量增加不到 1%，延迟增加 9%。

Conclusion: 所提出的插件是一种轻量级、可解释且模型无关的方法，可以有效解决 MLRM 中的幻觉问题，提高模型的可靠性和可解释性，从而实现安全部署。

Abstract: Multimodal large reasoning models (MLRMs) are rapidly advancing
vision-language reasoning and are emerging as a foundation for cross-modal
intelligence. Hallucination remains a persistent failure mode, manifesting
itself as erroneous reasoning chains and misinterpretation of visual content.
In this study, we observe that attention heads exhibit a staged division:
shallow heads predominantly serve perception, while deeper heads shift toward
symbolic reasoning, revealing two major causes of hallucination, namely
perceptual bias and reasoning drift. To address these issues, we propose a
lightweight and interpretable two-step plugin, Functional Head Identification
and Class-conditioned Rescaling, which locates perception- and
reasoning-oriented heads and regulates their contributions without retraining.
Evaluations on three real-world MLRMs (Kimi-VL, Ocean-R1, R1-Onevision), six
benchmarks across three domains, and four baselines show that our plugin
achieves an average improvement of 5% and up to 15%, with only <1% additional
computation and 9% of baseline latency. Our approach is completely
model-agnostic and significantly enhances both the reliability and
interpretability of the off-the-shelf MLRMs, thereby enabling their safe
deployment in high-stakes applications. Our code is available at
https://anonymous.4open.science/r/Functional-Attention-Control.

</details>


### [580] [LLM-Friendly Knowledge Representation for Customer Support](https://arxiv.org/abs/2510.10331)
*Hanchen Su,Wei Luo,Wei Han,Yu Elaine Liu,Yufeng Wayne Zhang,Cen Mia Zhao,Ying Joy Zhang,Yashar Mehdad*

Main category: cs.AI

TL;DR: 该研究提出了一种将大型语言模型（LLM）与Airbnb客户支持框架相结合的实用方法，通过ICA格式重构策略和工作流，并利用合成数据进行模型微调，以提高LLM在客户支持中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决Airbnb客户支持操作的复杂性，并提高LLM在客户支持中的应用性能。

Method: 采用Intent, Context, and Action (ICA)格式重构策略和工作流，使其更易于LLM理解。开发合成数据生成策略，以最小化人工干预生成训练数据，并对LLM进行成本效益高的微调。

Result: 内部实验表明，重构工作流和使用合成数据进行LLM微调能显著提高其性能，在准确性和手动处理时间方面设定了新的客户支持基准。

Conclusion: 所提出的方法不仅成本效益高，而且通过准确性和手动处理时间评估指标证明，能够改善客户支持，并为LLM在客户支持领域的应用树立了新的标杆。

Abstract: We propose a practical approach by integrating Large Language Models (LLMs)
with a framework designed to navigate the complexities of Airbnb customer
support operations. In this paper, our methodology employs a novel reformatting
technique, the Intent, Context, and Action (ICA) format, which transforms
policies and workflows into a structure more comprehensible to LLMs.
Additionally, we develop a synthetic data generation strategy to create
training data with minimal human intervention, enabling cost-effective
fine-tuning of our model. Our internal experiments (not applied to Airbnb
products) demonstrate that our approach of restructuring workflows and
fine-tuning LLMs with synthetic data significantly enhances their performance,
setting a new benchmark for their application in customer support. Our solution
is not only cost-effective but also improves customer support, as evidenced by
both accuracy and manual processing time evaluation metrics.

</details>


### [581] [Beyond Ethics: How Inclusive Innovation Drives Economic Returns in Medical AI](https://arxiv.org/abs/2510.10338)
*Balagopal Unnikrishnan,Ariel Guerra Adames,Amin Adibi,Sameer Peesapati,Rafal Kocielnik,Shira Fischer,Hillary Clinton Kasimbazi,Rodrigo Gameiro,Alina Peluso,Chrystinne Oliveira Fernandes,Maximin Lange,Lovedeep Gondara,Leo Anthony Celi*

Main category: cs.AI

TL;DR: 从包容性设计中获益：医疗保健人工智能的经济和战略价值


<details>
  <summary>Details</summary>
Motivation: 虽然医疗保健人工智能的公平性论证已经确立，但包容性设计的经济和战略价值仍未被充分探索。

Method: 提出“包容性创新红利”的原则，即为多样化、受限用例设计的解决方案在更广泛的市场中产生优越的经济回报。通过分析辅助技术如何演变为主流产业，展示包容性医疗保健人工智能开发如何创造超越合规要求的业务价值。确定了包容性创新驱动回报的四种机制：市场扩张、风险缓解、绩效红利和竞争优势。提出医疗保健人工智能包容性创新框架（HAIIF）——一个评估人工智能投资潜力的实用评分系统。

Result: 包容性设计能带来市场扩张、风险缓解、绩效提升和竞争优势。HAIIF框架为资源分配提供指导，将公平性和包容性转化为战略优势。

Conclusion: 投资于包容性设计的组织可以通过扩展市场覆盖范围和建立持续的竞争优势获得回报，而将这些考虑因素视为额外负担的组织将面临日益增长的劣势。

Abstract: While ethical arguments for fairness in healthcare AI are well-established,
the economic and strategic value of inclusive design remains underexplored.
This perspective introduces the ``inclusive innovation dividend'' -- the
counterintuitive principle that solutions engineered for diverse, constrained
use cases generate superior economic returns in broader markets. Drawing from
assistive technologies that evolved into billion-dollar mainstream industries,
we demonstrate how inclusive healthcare AI development creates business value
beyond compliance requirements. We identify four mechanisms through which
inclusive innovation drives returns: (1) market expansion via geographic
scalability and trust acceleration; (2) risk mitigation through reduced
remediation costs and litigation exposure; (3) performance dividends from
superior generalization and reduced technical debt, and (4) competitive
advantages in talent acquisition and clinical adoption. We present the
Healthcare AI Inclusive Innovation Framework (HAIIF), a practical scoring
system that enables organizations to evaluate AI investments based on their
potential to capture these benefits. HAIIF provides structured guidance for
resource allocation, transforming fairness and inclusivity from regulatory
checkboxes into sources of strategic differentiation. Our findings suggest that
organizations investing incrementally in inclusive design can achieve expanded
market reach and sustained competitive advantages, while those treating these
considerations as overhead face compounding disadvantages as network effects
and data advantages accrue to early movers.

</details>


### [582] [Trace Length is a Simple Uncertainty Signal in Reasoning Models](https://arxiv.org/abs/2510.10409)
*Siddartha Devic,Charlotte Peale,Arwen Bradley,Sinead Williamson,Preetum Nakkiran,Aravind Gollakota*

Main category: cs.AI

TL;DR: 研究表明，在大型推理模型中，推理痕迹的长度可以作为一种简单而有效的置信度估计器，尤其是在经过后训练后，它可以提供比语言化置信度更可靠的估算。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的可靠部署面临幻觉等问题的挑战，因此对其进行不确定性量化是关键的研究方向。现有方法如语言化置信度存在局限性。

Method: 通过在多个模型、数据集和提示上进行广泛实验，验证了推理痕迹长度作为置信度估计器的有效性，并分析了后训练对痕迹长度与准确性之间关系的影响，同时排除了问题难度和GRPO引起的长度偏差等混淆因素，并识别了高熵或“分叉”标记的作用。

Result: 推理痕迹长度的性能与其他零样本置信度估计器（如语言化置信度）相当但具有互补性。后训练显著改变了痕迹长度与准确性之间的关系，使其成为一个比语言化置信度更优越的不确定性量化指标。

Conclusion: 推理痕迹长度是一种实用且有效的置信度测量方法，可以提高大型推理模型的不确定性量化能力，并且这种能力在经过后训练后得到了增强。

Abstract: Uncertainty quantification for LLMs is a key research direction towards
addressing hallucination and other issues that limit their reliable deployment.
In this work, we show that reasoning trace length is a simple and useful
confidence estimator in large reasoning models. Through comprehensive
experiments across multiple models, datasets, and prompts, we show that trace
length performs in comparable but complementary ways to other zero-shot
confidence estimators such as verbalized confidence. Our work reveals that
reasoning post-training fundamentally alters the relationship between trace
length and accuracy, going beyond prior work that had shown that post-training
causes traces to grow longer in general (e.g., "overthinking"). We investigate
the mechanisms behind trace length's performance as a confidence signal,
observing that the effect remains even after adjusting for confounders such as
problem difficulty and GRPO-induced length bias. We identify high-entropy or
"forking" tokens as playing a key role in the mechanism. Our findings
demonstrate that reasoning post-training enhances uncertainty quantification
beyond verbal expressions, and establish trace length as a practical confidence
measure for large reasoning models.

</details>


### [583] [Traj-CoA: Patient Trajectory Modeling via Chain-of-Agents for Lung Cancer Risk Prediction](https://arxiv.org/abs/2510.10454)
*Sihang Zeng,Yujuan Fu,Sitong Zhou,Zixuan Yu,Lucas Jing Liu,Jun Wen,Matthew Thompson,Ruth Etzioni,Meliha Yetisgen*

Main category: cs.AI

TL;DR: Traj-CoA是一个多智能体系统，用于处理电子健康记录（EHR）数据，以解决LLM在时间推理中的挑战，并通过精炼关键事件来改进患者轨迹建模。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）在处理长而嘈杂的电子健康记录（EHR）数据进行时间推理时遇到的挑战。

Method: Traj-CoA采用一系列工作智能体来顺序处理EHR数据块，并将关键事件提取到共享的长期记忆模块（EHRMem）中，以减少噪声并保留完整的事件时间线。最后，一个管理智能体综合工作智能体的摘要和EHRMem中提取的时间线来进行预测。

Result: 在基于五年EHR数据的零样本一年肺癌风险预测任务中，Traj-CoA的性能优于四类基线模型。

Conclusion: Traj-CoA在临床上表现出一致的时间推理能力，证明了其在患者轨迹建模方面的鲁棒性和泛化能力。

Abstract: Large language models (LLMs) offer a generalizable approach for modeling
patient trajectories, but suffer from the long and noisy nature of electronic
health records (EHR) data in temporal reasoning. To address these challenges,
we introduce Traj-CoA, a multi-agent system involving chain-of-agents for
patient trajectory modeling. Traj-CoA employs a chain of worker agents to
process EHR data in manageable chunks sequentially, distilling critical events
into a shared long-term memory module, EHRMem, to reduce noise and preserve a
comprehensive timeline. A final manager agent synthesizes the worker agents'
summary and the extracted timeline in EHRMem to make predictions. In a
zero-shot one-year lung cancer risk prediction task based on five-year EHR
data, Traj-CoA outperforms baselines of four categories. Analysis reveals that
Traj-CoA exhibits clinically aligned temporal reasoning, establishing it as a
promisingly robust and generalizable approach for modeling complex patient
trajectories.

</details>


### [584] [MedCoAct: Confidence-Aware Multi-Agent Collaboration for Complete Clinical Decision](https://arxiv.org/abs/2510.10461)
*Hongjie Zheng,Zesheng Shi,Ping Yi*

Main category: cs.AI

TL;DR: LLM驱动的医疗AI在整合临床工作流程方面存在局限性，提出了MedCoAct框架，通过模拟医生和药剂师的协作来提高诊断和用药推荐的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗AI系统将任务孤立处理，缺乏临床团队中的交叉验证和知识整合，降低了其实际应用效果。

Method: 提出MedCoAct框架，这是一个置信度感知的多智能体框架，通过整合专门的医生和药剂师智能体来模拟临床协作，并提出了DrugCareQA基准来评估集成诊断和治疗工作流程中的医疗AI能力。

Result: MedCoAct实现了67.58%的诊断准确率和67.58%的用药推荐准确率，分别比单一智能体框架提高了7.04%和7.08%。

Conclusion: MedCoAct这种协作方法在不同医学领域具有良好的泛化能力，尤其适用于远程医疗咨询和常规临床场景，并能提供可解释的决策路径。

Abstract: Autonomous agents utilizing Large Language Models (LLMs) have demonstrated
remarkable capabilities in isolated medical tasks like diagnosis and image
analysis, but struggle with integrated clinical workflows that connect
diagnostic reasoning and medication decisions. We identify a core limitation:
existing medical AI systems process tasks in isolation without the
cross-validation and knowledge integration found in clinical teams, reducing
their effectiveness in real-world healthcare scenarios. To transform the
isolation paradigm into a collaborative approach, we propose MedCoAct, a
confidence-aware multi-agent framework that simulates clinical collaboration by
integrating specialized doctor and pharmacist agents, and present a benchmark,
DrugCareQA, to evaluate medical AI capabilities in integrated diagnosis and
treatment workflows. Our results demonstrate that MedCoAct achieves 67.58\%
diagnostic accuracy and 67.58\% medication recommendation accuracy,
outperforming single agent framework by 7.04\% and 7.08\% respectively. This
collaborative approach generalizes well across diverse medical domains, proving
especially effective for telemedicine consultations and routine clinical
scenarios, while providing interpretable decision-making pathways.

</details>


### [585] [Tracing the Traces: Latent Temporal Signals for Efficient and Accurate Reasoning](https://arxiv.org/abs/2510.10494)
*Martina G. Vilas,Safoora Yousefi,Besmira Nushi,Eric Horvitz,Vidhisha Balachandran*

Main category: cs.AI

TL;DR: Latent-Trajectory signals predict reasoning accuracy more reliably than existing methods, enabling more efficient and effective test-time scaling.


<details>
  <summary>Details</summary>
Motivation: Accurately predicting productive reasoning paths can significantly reduce wasted computation and enhance overall efficiency, as current reasoning models improve through inference-time scaling by allocating more compute via longer token budgets.

Method: Introduced Latent-Trajectory signals that characterize the temporal evolution of a model's internal representations during the generation of intermediate reasoning tokens. Measured overall change in latent representations, accumulated change across intermediate steps, and advancement toward the final state.

Result: Latent-Trajectory signals predict solution accuracy more reliably than cross-layer metrics and output-based confidence measures. Using these signals for answer selection across multiple sampled generations reduces token usage by up to 70% while improving accuracy by 2.6% on average, outperforming majority voting. Predictive signals often emerge early in the reasoning trace.

Conclusion: Latent-Trajectory signals offer practical strategies for inference-time efficiency and provide a deeper interpretability perspective on how reasoning processes are represented and differentiated in latent space.

Abstract: Reasoning models improve their problem-solving ability through inference-time
scaling, allocating more compute via longer token budgets. Identifying which
reasoning traces are likely to succeed remains a key opportunity: reliably
predicting productive paths can substantially reduce wasted computation and
improve overall efficiency. We introduce Latent-Trajectory signals that
characterize the temporal evolution of a model's internal representations
during the generation of intermediate reasoning tokens. By measuring the
overall change in latent representations between the start and end of
reasoning, the change accumulated across intermediate steps, and the extent to
which these changes advance toward the final state, we show that these signals
predict solution accuracy more reliably than both cross-layer metrics and
output-based confidence measures. When used to guide answer selection across
multiple sampled generations, Latent-Trajectory signals make test-time scaling
more effective and efficient than majority voting, reducing token usage by up
to 70% while preserving and even improving accuracy by 2.6% on average.
Moreover, these predictive signals often emerge early in the reasoning trace,
enabling early selection and allocation of compute to the most promising
candidates. Our findings contribute not only practical strategies for
inference-time efficiency, but also a deeper interpretability perspective on
how reasoning processes are represented and differentiated in latent space.

</details>


### [586] [ELAIPBench: A Benchmark for Expert-Level Artificial Intelligence Paper Understanding](https://arxiv.org/abs/2510.10549)
*Xinbang Dai,Huikang Hu,Yongrui Chen,Jiaqi Li,Rihui Jin,Yuyang Zhang,Xiaoguang Li,Lifeng Shang,Guilin Qi*

Main category: cs.AI

TL;DR: LLM在理解和推理学术论文方面能力不足，新基准ELAIPBench显示当前最佳LLM准确率仅为39.95%，远低于人类水平，且思维模式或RAG系统未能提升性能。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）深入理解和推理长篇学术论文的能力，现有基准不足以捕捉这种深度。

Method: 创建了一个由领域专家策划的基准ELAIPBench，包含403个选择题，源自137篇论文，覆盖三个难度级别，强调非平凡推理，并通过激励驱动的对抗性标注过程进行开发。

Result: 当前最佳LLM在ELAIPBench上的准确率仅为39.95%，远低于人类表现。 equipado con modo de pensamiento o RAG sistemas no mejoran el rendimiento final, incluso perjudican la precisión.

Conclusion: 目前的LLM在真正理解学术论文方面与人类水平存在显著差距，即使采用思维模式或RAG也无法有效弥补。

Abstract: While large language models (LLMs) excel at many domain-specific tasks, their
ability to deeply comprehend and reason about full-length academic papers
remains underexplored. Existing benchmarks often fall short of capturing such
depth, either due to surface-level question design or unreliable evaluation
metrics. To address this gap, we introduce ELAIPBench, a benchmark curated by
domain experts to evaluate LLMs' comprehension of artificial intelligence (AI)
research papers. Developed through an incentive-driven, adversarial annotation
process, ELAIPBench features 403 multiple-choice questions from 137 papers. It
spans three difficulty levels and emphasizes non-trivial reasoning rather than
shallow retrieval. Our experiments show that the best-performing LLM achieves
an accuracy of only 39.95%, far below human performance. Moreover, we observe
that frontier LLMs equipped with a thinking mode or a retrieval-augmented
generation (RAG) system fail to improve final results-even harming accuracy due
to overthinking or noisy retrieval. These findings underscore the significant
gap between current LLM capabilities and genuine comprehension of academic
papers.

</details>


### [587] [A Layered Intuition -- Method Model with Scope Extension for LLM Reasoning](https://arxiv.org/abs/2510.10592)
*Hong Su*

Main category: cs.AI

TL;DR: 该研究提出了一个结合直觉、方法和范围扩展的“直觉-方法分层模型”，以系统地解决大型语言模型（LLM）在处理间接（未见）问题时的不足。


<details>
  <summary>Details</summary>
Motivation: 现有研究虽然引入了基于方法推理和范围扩展来提升LLM性能，但缺乏系统性整合，难以有效处理间接性问题。

Method: 提出“直觉-方法分层模型”，其中直觉思考提供快速响应，方法思考将问题和解决方案解耦为可转移的推理单元。在此基础上，引入范围扩展（垂直、水平、以及首次提出的时间、空间维度），并将这些扩展组织成知识树和知识网络，以增强适应性。同时，提出“方法扩展熵”作为评估指标，衡量扩展的独立性和多样性。

Result: 通过逻辑连接现有方法和新扩展，并引入基于熵的评估框架，该模型能更好地解决未见问题。

Conclusion: 该研究通过提出一个系统化的模型和评估框架，推动了LLM在现实世界问题解决中朝着更鲁棒和可扩展的推理范式发展。

Abstract: Existing studies have introduced method-based reasoning and scope extension
as approaches to enhance Large Language Model (LLM) performance beyond direct
matrix mappings. Building on these foundations, this paper summarizes and
integrates these ideas into a unified Intuition-Method Layered Model with Scope
Extension, designed to address indirected (unseen) issues more systematically.
In this framework, intuition-based thinking provides rapid first-reaction
answers, while method-based thinking decouples questions and solutions into
transferable reasoning units. Scope extension is then applied to broaden
applicability, including vertical (cause analysis), horizontal (parallel and
generalized issues), and for the first time, temporal and spatial extensions,
which expand reasoning across time and contextual dimensions. These extensions
are organized into systematic knowledge trees that interconnect into a
knowledge network, thereby increasing adaptability. To quantitatively evaluate
this process, we propose the entropy of method extension, which measures the
independence and diversity of extensions as an indicator of the system's
capacity to solve unseen questions. By logically connecting existing approaches
with new extensions and introducing an entropy-based evaluation framework, this
work advances toward a more robust and extensible reasoning paradigm for LLMs
in real-world problem-solving.

</details>


### [588] [A Distance Measure for Random Permutation Set: From the Layer-2 Belief Structure Perspective](https://arxiv.org/abs/2510.10596)
*Ruolan Cheng,Yong Deng,Serafín Moral,José Ramón Trillo*

Main category: cs.AI

TL;DR: 本篇论文提出了一种新的随机置信集（RPS）距离度量方法，该方法基于累积Jaccard指数，具有更好的灵活性和敏感性。


<details>
  <summary>Details</summary>
Motivation: 随机置信集（RPS）理论中，度量RPS之间的距离是一个关键的研究课题。

Method: 提出了一种新的累积Jaccard指数定义来量化两个置信集之间的相似性，并基于累积Jaccard指数矩阵提出了一种RPS距离度量方法。该方法考虑了元素排序的重要性，并提供了两个参数来调整权重和截断深度。

Result: 所提出的距离度量方法具有良好的度量和结构性质，并且具有“上权”特性。通过数值例子与现有方法进行比较，结果表明该方法克服了现有方法的缺点，与Jousselme距离兼容，并且具有更高的敏感性和灵活性。

Conclusion: 本研究提出的基于累积Jaccard指数的RPS距离度量方法，为RPS理论在度量不确定信息距离方面提供了一种有效且灵活的解决方案。

Abstract: Random permutation set (RPS) is a recently proposed framework designed to
represent order-structured uncertain information. Measuring the distance
between permutation mass functions is a key research topic in RPS theory
(RPST). This paper conducts an in-depth analysis of distances between RPSs from
two different perspectives: random finite set (RFS) and transferable belief
model (TBM). Adopting the layer-2 belief structure interpretation of RPS, we
regard RPST as a refinement of TBM, where the order in the ordered focus set
represents qualitative propensity. Starting from the permutation, we introduce
a new definition of the cumulative Jaccard index to quantify the similarity
between two permutations and further propose a distance measure method for RPSs
based on the cumulative Jaccard index matrix. The metric and structural
properties of the proposed distance measure are investigated, including the
positive definiteness analysis of the cumulative Jaccard index matrix, and a
correction scheme is provided. The proposed method has a natural
top-weightiness property: inconsistencies between higher-ranked elements tend
to result in greater distance values. Two parameters are provided to the
decision-maker to adjust the weight and truncation depth. Several numerical
examples are used to compare the proposed method with the existing method. The
experimental results show that the proposed method not only overcomes the
shortcomings of the existing method and is compatible with the Jousselme
distance, but also has higher sensitivity and flexibility.

</details>


### [589] [EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms](https://arxiv.org/abs/2510.10603)
*WenTao Liu,Siyu Song,Hao Hao,Aimin Zhou*

Main category: cs.AI

TL;DR: Using evolutionary algorithms to train large language models (LLMs) can overcome hardware and differentiability limitations of gradient-based methods, enabling training of a 1-billion-parameter LLM and potentially reducing computational costs.


<details>
  <summary>Details</summary>
Motivation: Gradient-based optimizers used for LLMs have high hardware requirements (high-concurrency, high-memory GPUs) and require all operations to be differentiable, excluding non-differentiable architectures.

Method: Proposed using evolutionary algorithms (EA4LLM) to optimize LLMs and demonstrated its capability to train a 1-billion-parameter LLM from the pre-trained stage.

Result: Successfully trained a 1-billion-parameter LLM using EA4LLM. Conducted extensive experiments providing insights into EA's effectiveness in optimizing neural networks.

Conclusion: Evolutionary algorithms can effectively optimize neural networks, challenging the assumption that gradient-based optimization is the only viable approach. EA4LLM has the potential to reduce computational costs for training LLMs, making deep learning research more accessible to groups with limited resources.

Abstract: In recent years, large language models (LLMs) have made remarkable progress,
with model optimization primarily relying on gradient-based optimizers such as
Adam. However, these gradient-based methods impose stringent hardware
requirements, demanding high-concurrency, high-memory GPUs. Moreover, they
require all neural network operations to be differentiable, thereby excluding
many promising non-differentiable architectures from practical use. To address
these limitations, we propose a method for optimizing LLMs using evolutionary
algorithms (EA4LLM) and, for the first time, successfully demonstrate its
capability to train a 1-billion-parameter LLM from the pre-trained stage. We
conduct extensive experiments and provide key insights into how evolutionary
algorithms can effectively optimize neural networks. Our work challenges the
prevailing assumption that gradient-based optimization is the only viable
approach for training neural networks. It also holds significant potential to
reduce the computational cost of training large language models, thereby
enabling groups with limited computational resources to participate in deep
learning research.

</details>


### [590] [Collaborative Text-to-Image Generation via Multi-Agent Reinforcement Learning and Semantic Fusion](https://arxiv.org/abs/2510.10633)
*Jiabao Shi,Minfeng Qi,Lefeng Zhang,Di Wang,Yingjie Zhao,Ziying Li,Yalong Xing,Ningran Li*

Main category: cs.AI

TL;DR: 使用多智能体强化学习框架，通过领域专业智能体协同，提高文本到图像生成在语义对齐和细节方面的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态文本到图像生成在保持跨领域语义对齐和专业级细节方面存在挑战。

Method: 提出一个多智能体强化学习框架，包含文本增强和图像生成两个子系统，每个子系统由领域专业智能体（如建筑、肖像、风景）组成。智能体使用近端策略优化（PPO）进行训练，并结合了平衡语义相似性、语言视觉质量和内容多样性的复合奖励函数。通过对比学习、双向注意力和文本与图像间的迭代反馈来强制跨模态对齐。

Result: 在六个实验设置中，该系统显著丰富了生成内容（词数增加了1614%），但ROUGE-1分数下降了69.7%。基于Transformer的方法在融合模型中表现最佳（综合得分0.521），但存在稳定性问题。多模态集成方法的一致性中等（0.444至0.481）。

Conclusion: 协作式、驱动专业化的架构在推进可靠的多模态生成系统方面具有潜力。

Abstract: Multimodal text-to-image generation remains constrained by the difficulty of
maintaining semantic alignment and professional-level detail across diverse
visual domains. We propose a multi-agent reinforcement learning framework that
coordinates domain-specialized agents (e.g., focused on architecture,
portraiture, and landscape imagery) within two coupled subsystems: a text
enhancement module and an image generation module, each augmented with
multimodal integration components. Agents are trained using Proximal Policy
Optimization (PPO) under a composite reward function that balances semantic
similarity, linguistic visual quality, and content diversity. Cross-modal
alignment is enforced through contrastive learning, bidirectional attention,
and iterative feedback between text and image. Across six experimental
settings, our system significantly enriches generated content (word count
increased by 1614%) while reducing ROUGE-1 scores by 69.7%. Among fusion
methods, Transformer-based strategies achieve the highest composite score
(0.521), despite occasional stability issues. Multimodal ensembles yield
moderate consistency (ranging from 0.444 to 0.481), reflecting the persistent
challenges of cross-modal semantic grounding. These findings underscore the
promise of collaborative, specialization-driven architectures for advancing
reliable multimodal generative systems.

</details>


### [591] [Automatic Piecewise Linear Regression for Predicting Student Learning Satisfaction](https://arxiv.org/abs/2510.10639)
*Haemin Choi,Gayathri Nadarajan*

Main category: cs.AI

TL;DR: APLR模型预测学习满意度优于其他模型，并识别出影响因素。


<details>
  <summary>Details</summary>
Motivation: 尽管学生学习满意度已被广泛研究，但可解释机器学习和神经网络等现代技术尚未得到充分探索。

Method: 使用自动分段线性回归（APLR）模型，并结合数值和可视化解释，分析影响学习满意度的因素。

Result: 时间管理、专注能力、对同学的感知帮助以及线下课程参与度对学习满意度有显著的积极影响。创意活动参与度对学习满意度没有积极影响。

Conclusion: APLR模型能够解释个体层面的影响因素，使教育者能够根据学生情况定制教学。

Abstract: Although student learning satisfaction has been widely studied, modern
techniques such as interpretable machine learning and neural networks have not
been sufficiently explored. This study demonstrates that a recent model that
combines boosting with interpretability, automatic piecewise linear
regression(APLR), offers the best fit for predicting learning satisfaction
among several state-of-the-art approaches. Through the analysis of APLR's
numerical and visual interpretations, students' time management and
concentration abilities, perceived helpfulness to classmates, and participation
in offline courses have the most significant positive impact on learning
satisfaction. Surprisingly, involvement in creative activities did not
positively affect learning satisfaction. Moreover, the contributing factors can
be interpreted on an individual level, allowing educators to customize
instructions according to student profiles.

</details>


### [592] [Equity-Aware Geospatial AI for Forecasting Demand-Driven Hospital Locations in Germany](https://arxiv.org/abs/2510.10640)
*Piyush Pant,Marcellius William Suntoro,Ayesha Siddiqua,Muhammad Shehryaar Sharif,Daniyal Ahmed*

Main category: cs.AI

TL;DR: 该研究提出了EA-GeoAI框架，通过整合人口结构变化、老龄化和基础设施数据，构建了一个“公平性指数”，并利用AI优化器来优化医院床位分配和新址选择，以在预算和出行时间内满足需求，并为政策制定者提供建议。


<details>
  <summary>Details</summary>
Motivation: 整合地理空间人工智能（GeoAI）、长期预测和公平性衡量，为德国到2030年的医院规划和床位分配提供一个综合框架，以解决未满足的需求并促进公平性。

Method: 结合区域人口结构变化、老龄化人口密度和基础设施平衡数据，构建了一个统一的公平性指数。然后，使用一个可解释的Agentic AI优化器，在预算和出行时间限制下，最小化未满足的需求，并进行床位分配和新医院选址。

Result: 通过EA-GeoAI框架，实现了对德国到2030年医院床位需求的预测，并确定了优化后的床位分配和新医院的建设地点，旨在最小化未满足的需求，同时考虑预算和出行时间等因素。

Conclusion: EA-GeoAI框架能够有效地结合GeoAI、长期预测和公平性衡量，为德国医院规划提供可操作的建议，以应对未来的人口结构变化和医疗需求。

Abstract: This paper presents EA-GeoAI, an integrated framework for demand forecasting
and equitable hospital planning in Germany through 2030. We combine
district-level demographic shifts, aging population density, and infrastructure
balances into a unified Equity Index. An interpretable Agentic AI optimizer
then allocates beds and identifies new facility sites to minimize unmet need
under budget and travel-time constraints. This approach bridges GeoAI,
long-term forecasting, and equity measurement to deliver actionable
recommendations for policymakers.

</details>


### [593] [Hierarchical Optimization via LLM-Guided Objective Evolution for Mobility-on-Demand Systems](https://arxiv.org/abs/2510.10644)
*Yi Zhang,Yushen Long,Yun Ni,Liping Huang,Xiaohong Wang,Jun Liu*

Main category: cs.AI

TL;DR: 该研究提出了一种结合大语言模型（LLM）和数学优化的混合框架，用于解决网约车平台供需不平衡的问题。该框架无需训练，通过LLM生成自适应的高层目标，并由数学优化器处理底层约束和实时决策，实现了16%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的网约车平台方法要么是数据效率低、模型简化且难以满足操作约束的强化学习方法，要么是依赖手动设计的高层目标且缺乏底层路由意识的分解在线优化方法。

Method: 提出了一种结合大语言模型（LLM）和数学优化的动态分层混合框架。LLM作为元优化器，生成指导底层优化器的语义启发式规则，底层优化器负责执行约束和实时决策。通过基于和谐搜索的闭环进化过程，根据反馈迭代地优化LLM的提示。

Result: 与现有最先进的方法相比，在纽约和芝加哥出租车数据集的场景下，平均提高了16%的性能。

Conclusion: 所提出的混合框架通过LLM弥合了问题分解带来的认知限制，有效解决了网约车平台的供需动态和空间异质性挑战。

Abstract: Online ride-hailing platforms aim to deliver efficient mobility-on-demand
services, often facing challenges in balancing dynamic and spatially
heterogeneous supply and demand. Existing methods typically fall into two
categories: reinforcement learning (RL) approaches, which suffer from data
inefficiency, oversimplified modeling of real-world dynamics, and difficulty
enforcing operational constraints; or decomposed online optimization methods,
which rely on manually designed high-level objectives that lack awareness of
low-level routing dynamics. To address this issue, we propose a novel hybrid
framework that integrates large language model (LLM) with mathematical
optimization in a dynamic hierarchical system: (1) it is training-free,
removing the need for large-scale interaction data as in RL, and (2) it
leverages LLM to bridge cognitive limitations caused by problem decomposition
by adaptively generating high-level objectives. Within this framework, LLM
serves as a meta-optimizer, producing semantic heuristics that guide a
low-level optimizer responsible for constraint enforcement and real-time
decision execution. These heuristics are refined through a closed-loop
evolutionary process, driven by harmony search, which iteratively adapts the
LLM prompts based on feasibility and performance feedback from the optimization
layer. Extensive experiments based on scenarios derived from both the New York
and Chicago taxi datasets demonstrate the effectiveness of our approach,
achieving an average improvement of 16% compared to state-of-the-art baselines.

</details>


### [594] [Unlocking Exploration in RLVR: Uncertainty-aware Advantage Shaping for Deeper Reasoning](https://arxiv.org/abs/2510.10649)
*Can Xie,Ruotong Pan,Xiangyu Wu,Yunfei Zhang,Jiayi Fu,Tingting Gao,Guorui Zhou*

Main category: cs.AI

TL;DR: UCAS通过利用模型的内部不确定性信号来优化信用分配，解决RLVR在推理中探索效率低下和熵折叠的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR算法（如GRPO）使用统一的优势信号，忽略了推理过程中不确定、高风险决策的关键作用，导致探索效率低下和熵折叠。

Method: UCAS是一个无模型的方法，通过两个阶段来优化信用分配：1. 使用模型整体置信度调整响应级优势。2. 基于原始logit不确定性施加标记级惩罚。

Result: UCAS在五个数学推理基准的广泛实验中，显著优于RLVR基线，提高了奖励、推理多样性，并缓解了熵折叠。

Conclusion: UCAS通过利用模型不确定性信号，在解决RLVR的不足方面是有效的，并在数学推理任务上取得了最先进的成果。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has shown significant
promise for enhancing the reasoning capabilities of large language models
(LLMs). However, prevailing algorithms like GRPO broadcast a uniform advantage
signal across all tokens in a sequence. This coarse-grained approach overlooks
the pivotal role of uncertain, high-stakes decisions during reasoning, leading
to inefficient exploration and the well-documented problem of entropy collapse.
To address this, we introduce UnCertainty-aware Advantage Shaping (UCAS), a
model-free method that refines credit assignment by leveraging the model's
internal uncertainty signals. UCAS operates in two stages: it first modulates
the response-level advantage using the model's overall self-confidence, and
then applies a token-level penalty based on raw logit certainty. This dual
mechanism encourages exploration of high-uncertainty paths that yield correct
answers while penalizing overconfident yet erroneous reasoning, effectively
balancing the exploration-exploitation trade-off. Extensive experiments on five
mathematical reasoning benchmarks show that UCAS significantly outperforms
strong RLVR baselines across multiple model scales, including 1.5B and 7B. Our
analysis confirms that UCAS not only achieves higher rewards but also promotes
greater reasoning diversity and successfully mitigates entropy collapse.

</details>


### [595] [Simpliflow: A Lightweight Open-Source Framework for Rapid Creation and Deployment of Generative Agentic AI Workflows](https://arxiv.org/abs/2510.10675)
*Deven Panchal*

Main category: cs.AI

TL;DR: simpliflow是一个轻量级的开源Python框架，用于简化生成式Agentic AI系统的开发，特别是线性和确定性工作流。


<details>
  <summary>Details</summary>
Motivation: 现有Agentic AI框架复杂、学习曲线陡峭、样板代码多，阻碍了快速原型设计和部署。simpliflow旨在解决这些问题，提供一个简单、易用、可扩展的解决方案。

Method: simpliflow采用声明式的、基于JSON的配置，通过模块化架构实现代理管理、工作流执行和后处理的分离，并支持LiteLLM集成的100多个LLM。

Result: simpliflow能够快速开发和编排线性的、确定性的Agentic工作流，并通过软件开发模拟和实时系统交互等用例进行了演示。与LangChain和AutoGen等框架的比较分析表明，simpliflow在确定性工作流环境中具有简单性、控制性和速度方面的优势。

Conclusion: simpliflow是一个优化用于简单性、控制性和速度的工具，适用于确定性工作流环境，为Agentic AI系统的开发提供了一个高效的替代方案。

Abstract: Generative Agentic AI systems are emerging as a powerful paradigm for
automating complex, multi-step tasks. However, many existing frameworks for
building these systems introduce significant complexity, a steep learning
curve, and substantial boilerplate code, hindering rapid prototyping and
deployment. This paper introduces simpliflow, a lightweight, open-source Python
framework designed to address these challenges. simpliflow enables the rapid
development and orchestration of linear, deterministic agentic workflows
through a declarative, JSON-based configuration. Its modular architecture
decouples agent management, workflow execution, and post-processing, promoting
ease of use and extensibility. By integrating with LiteLLM, it supports over
100 Large Language Models (LLMs) out-of-the-box. We present the architecture,
operational flow, and core features of simpliflow, demonstrating its utility
through diverse use cases ranging from software development simulation to
real-time system interaction. A comparative analysis with prominent frameworks
like LangChain and AutoGen highlights simpliflow's unique position as a tool
optimized for simplicity, control, and speed in deterministic workflow
environments.

</details>


### [596] [OmniVideoBench: Towards Audio-Visual Understanding Evaluation for Omni MLLMs](https://arxiv.org/abs/2510.10689)
*Caorui Li,Yu Chen,Yiyan Ji,Jin Xu,Zhenyu Cui,Shihao Li,Yuanxing Zhang,Jiafu Tang,Zhenghao Song,Dingling Zhang,Ying He,Haoxiang Liu,Yuxuan Wang,Qiufeng Wang,Zhenhe Wu,Jiehui Luo,Zhiyu Pan,Weihao Xie,Chenchen Zhang,Zhaohui Wang,Jiayi Tian,Yanghai Wang,Zhe Cao,Minxin Dai,Ke Wang,Runzhe Wen,Yinghao Ma,Yaning Pan,Sungkyun Chang,Termeh Taheri,Haiwen Xia,Christos Plachouras,Emmanouil Benetos,Yizhi Li,Ge Zhang,Jian Yang,Tianhao Peng,Zili Wang,Minghao Liu,Junran Peng,Zhaoxiang Zhang,Jiaheng Liu*

Main category: cs.AI

TL;DR: 现有的视频理解基准未能充分评估跨音频和视觉模态的协同推理能力。为解决此问题，本文提出了OmniVideoBench，一个包含1000个高质量问答对的大规模基准，强调模态互补性和逻辑一致性，涵盖13种问题类型，旨在评估多模态大语言模型（MLLMs）在视频理解方面的协同推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视频理解基准未能充分评估跨音频和视觉模态的协同推理能力，常常忽略其中一种模态或以逻辑不一致的方式整合它们。为了弥补这一差距，需要一个专门用于评估协同音频-视觉理解的基准。

Method: 构建了一个名为OmniVideoBench的大规模基准，包含1000个高质量的问答对，这些问答对源自628个多样化的视频，并附有详细的推理过程。基准涵盖了13种精心设计的问题类型，如时间推理、空间定位、计数、因果推断和摘要等，以全面捕捉视频理解的挑战。

Result: 在OmniVideoBench上对多个多模态大语言模型（MLLMs）的评估显示，模型性能与人类推理能力之间存在显著差距。开源模型在性能上明显落后于闭源模型，这凸显了真正的音频-视觉推理的内在难度。

Conclusion: OmniVideoBench的评估结果表明，目前的MLLMs在处理需要跨模态协同推理的视频任务时仍有很大提升空间。该基准的提出和后续发布将有助于推动MLLMs在更强大、更具泛化能力的推理能力方面的发展。

Abstract: Recent advances in multimodal large language models (MLLMs) have demonstrated
substantial potential in video understanding. However, existing benchmarks fail
to comprehensively evaluate synergistic reasoning capabilities across audio and
visual modalities, often neglecting either one of the modalities or integrating
them in a logically inconsistent manner. To bridge this gap, we introduce
OmniVideoBench, a large-scale and rigorously designed benchmark dedicated to
assessing synergistic audio-visual understanding, with a strong emphasis on
modality complementarity and logical consistency. Specifically, OmniVideoBench
comprises 1000 high-quality question-answer(QA) pairs, each annotated with
step-by-step reasoning traces, derived from 628 diverse videos ranging from
several seconds to 30 minutes, and manually verified to guarantee complete
correctness and uniqueness. Moreover, OmniVideoBench encompasses 13 carefully
designed question types, covering temporal reasoning, spatial localization,
counting, causal inference, summarization, and beyond, thereby capturing the
essential challenges of video understanding. Evaluation of multiple MLLMs on
OmniVideoBench reveals a pronounced gap between model performance and human
reasoning, with open-source models lagging significantly behind their
closed-source counterparts, underscoring the inherent difficulty of genuine
audio-visual reasoning. We will release OmniVideoBench to foster the
development of MLLMs with stronger and more generalizable reasoning
capabilities.

</details>


### [597] [Adaptive Selection of Symbolic Languages for Improving LLM Logical Reasoning](https://arxiv.org/abs/2510.10703)
*Xiangyu Wang,Haocheng Yang,Fengxiang Cheng,Fenrong Liu*

Main category: cs.AI

TL;DR: LLMs在复杂逻辑推理方面仍有不足，以往的研究过度依赖自然语言到符号语言的翻译准确性，而忽略了目标符号语言类型的选择。本文提出一种自适应选择最适合的符号语言进行翻译的方法，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 以往关于提高LLM逻辑推理能力的研究主要集中在提高自然语言到符号语言的翻译准确性，而忽略了目标符号语言类型的选择对推理性能的影响。本文旨在解决这一问题，提出一种新的方法来提升LLM的逻辑推理能力。

Method: 本文提出一种自适应选择最适合的符号语言（一阶逻辑、逻辑编程、布尔可满足性）进行翻译的方法。首先利用LLM选择最适合的符号语言，然后将自然语言问题翻译成目标符号语言表达式，最后利用相应的逻辑求解器得到答案。

Result: 在基准测试集上的实验结果表明，本文提出的自适应选择方法显著优于将所有问题翻译成单一符号语言或随机选择符号语言的方法。在一个混合数据集上，本文方法达到了96%的准确率，比第二名（仅使用一阶逻辑翻译）的准确率提高了25%。

Conclusion: 本文提出的自适应选择不同符号语言的方法能够显著提升LLM在复杂逻辑推理任务上的性能。

Abstract: Large Language Models (LLMs) still struggle with complex logical reasoning.
While previous works achieve remarkable improvements, their performance is
highly dependent on the correctness of translating natural language (NL)
problems into a symbolic language (SL). Though numerous works focusing on
improving this translation accuracy, they only consider the similarity between
the meaning of SL and NL, overlooking another crucial influencing factor, the
selection of the target SL type itself. For example, first-order logic language
specializes in logical reasoning with categorical syllogisms and complex
quantifiers, while Boolean satisfiability formalism excels at representing
constraint satisfaction like partial problems. To our knowledge, this is the
first paper to claim and verify that different NL logical reasoning problem
corresponds to different optimal SL formalization for translation. Based on
this, we propose a methods to improve the logical reasoning performance of LLMs
by adaptively selecting the most suitable SL for each problem prior to
translation. Specifically, we leverage LLMs to select the target SL among
first-order logic, logic programming and Boolean satisfiability and then
translate the problem in NL to target SL expressions as well as employ the
corresponding logical solver to derive the final answer. Experimental results
on benchmarks show that our adaptive selection method significantly outperforms
translating all into single SL and randomly selecting the SL. On a mixed
dataset of these benchmarks, our approach achieves 96% accuracy, which
improving performance by 25% compared to the second highest accuracy from the
first-order logic translation.

</details>


### [598] [DRIFT: Decompose, Retrieve, Illustrate, then Formalize Theorems](https://arxiv.org/abs/2510.10815)
*Meiru Zhang,Philipp Borchert,Milan Gritta,Gerasimos Lampouras*

Main category: cs.AI

TL;DR: LLMs在自动将数学语句形式化以进行定理证明方面面临挑战，因为它们难以识别和利用相关的数学知识及其在Lean等语言中的形式化表示。现有方法直接使用非正式语句查询外部库，但忽略了非正式数学语句的复杂性和有限的上下文。为解决此问题，我们提出了DRIFT框架，它能将非正式语句分解为更小的“子组件”，从而实现对Mathlib等数学库中前提的定向检索，并检索示例定理以帮助模型更有效地利用这些前提。DRIFT在ProofNet、ConNF和MiniF2F-test等基准测试中提高了前提检索效果，在ProofNet上将F1分数提高近一倍。在ConNF基准测试中，DRIFT使用GPT-4.1和DeepSeek-V3.1分别实现了37.14%和42.25%的BEq+@10提升。分析表明，数学自动形式化中的检索效果很大程度上取决于特定模型的知识边界，因此需要与各模型能力相适应的自适应检索策略。


<details>
  <summary>Details</summary>
Motivation: 现有的自动形式化方法直接使用非正式语句查询外部库，但忽略了非正式数学语句的复杂性和有限的上下文，导致LLMs难以识别和利用相关的数学知识及其形式化表示。

Method: DRIFT框架通过将非正式数学语句分解为更小的、更易于处理的“子组件”，从而实现对数学库（如Mathlib）中前提的定向检索。此外，DRIFT还检索示例定理，以帮助模型更有效地利用检索到的前提进行形式化。

Result: DRIFT在ProofNet、ConNF和MiniF2F-test等多个基准测试中，显著提高了前提检索的效果，在ProofNet上F1分数相比DPR基线几乎翻倍。在ConNF基准测试中，使用GPT-4.1和DeepSeek-V3.1时，BEq+@10分别提高了37.14%和42.25%。

Conclusion: 检索效果在数学自动形式化任务中对模型的知识边界敏感，需要根据模型的具体能力采用自适应的检索策略。

Abstract: Automating the formalization of mathematical statements for theorem proving
remains a major challenge for Large Language Models (LLMs). LLMs struggle to
identify and utilize the prerequisite mathematical knowledge and its
corresponding formal representation in languages like Lean. Current
retrieval-augmented autoformalization methods query external libraries using
the informal statement directly, but overlook a fundamental limitation:
informal mathematical statements are often complex and offer limited context on
the underlying math concepts. To address this, we introduce DRIFT, a novel
framework that enables LLMs to decompose informal mathematical statements into
smaller, more tractable ''sub-components''. This facilitates targeted retrieval
of premises from mathematical libraries such as Mathlib. Additionally, DRIFT
retrieves illustrative theorems to help models use premises more effectively in
formalization tasks. We evaluate DRIFT across diverse benchmarks (ProofNet,
ConNF, and MiniF2F-test) and find that it consistently improves premise
retrieval, nearly doubling the F1 score compared to the DPR baseline on
ProofNet. Notably, DRIFT demonstrates strong performance on the
out-of-distribution ConNF benchmark, with BEq+@10 improvements of 37.14% and
42.25% using GPT-4.1 and DeepSeek-V3.1, respectively. Our analysis shows that
retrieval effectiveness in mathematical autoformalization depends heavily on
model-specific knowledge boundaries, highlighting the need for adaptive
retrieval strategies aligned with each model's capabilities.

</details>


### [599] [LLM-Empowered Agentic MAC Protocols: A Dynamic Stackelberg Game Approach](https://arxiv.org/abs/2510.10895)
*Renxuan Tan,Rongpeng Li,Fei Wang,Chenghui Peng,Shaoyun Wu,Zhifeng Zhao,Honggang Zhang*

Main category: cs.AI

TL;DR: 通过结合博弈论、大型语言模型（LLM）和多智能体深度强化学习（MARL），提出了一种新的MAC协议，提高了吞吐量和公平性，并具有出色的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度强化学习（DRL）的MAC协议泛化能力和鲁棒性差，需要昂贵的重新训练才能适应动态环境。

Method: 将上行链路传输建模为动态多追随者Stackelberg博弈（MFSG），并使用由LLM驱动的智能体，通过近端策略优化（PPO）进行协调，以合成自适应的、语义化的MAC协议。还使用了协议动作语法（PAG）来确保过程的可靠性和效率。

Result: 与传统基线相比，吞吐量提高了77.6%，公平性提高了65.2%。

Conclusion: 该框架具有出色的泛化能力，能够适应用户数量的变化，而无需重新训练或架构更改。

Abstract: Medium Access Control (MAC) protocols, essential for wireless networks, are
typically manually configured. While deep reinforcement learning (DRL)-based
protocols enhance task-specified network performance, they suffer from poor
generalizability and resilience, demanding costly retraining to adapt to
dynamic environments. To overcome this limitation, we introduce a
game-theoretic LLM-empowered multi-agent DRL (MARL) framework, in which the
uplink transmission between a base station and a varying number of user
equipments is modeled as a dynamic multi-follower Stackelberg game (MFSG),
capturing the network's natural hierarchical structure. Within this game,
LLM-driven agents, coordinated through proximal policy optimization (PPO),
synthesize adaptive, semantic MAC protocols in response to network dynamics.
Protocol action grammar (PAG) is employed to ensure the reliability and
efficiency of this process. Under this system, we further analyze the existence
and convergence behavior in terms of a Stackelberg equilibrium by studying the
learning dynamics of LLM-empowered unified policies in response to changing
followers. Simulations corroborate that our framework achieves a 77.6% greater
throughput and a 65.2% fairness improvement over conventional baselines.
Besides, our framework generalizes excellently to a fluctuating number of users
without requiring retraining or architectural changes.

</details>


### [600] [PaperArena: An Evaluation Benchmark for Tool-Augmented Agentic Reasoning on Scientific Literature](https://arxiv.org/abs/2510.10909)
*Daoyu Wang,Mingyue Cheng,Qi Liu,Shuo Yu,Zirui Liu,Ze Guo*

Main category: cs.AI

TL;DR: PaperArena是一个评估基准，用于测试语言模型代理在处理需要跨论文推理和多工具协作的复杂知识密集型任务中的能力。


<details>
  <summary>Details</summary>
Motivation: 现有的研究主要局限于单篇论文的无工具任务，缺乏跨论文推理和真实研究场景下多工具协调的基准。因此，有必要创建一个能够处理真实研究问题并整合多篇论文信息的评估基准。

Method: PaperArena提供了一个模块化、可扩展的平台，支持代理执行，并集成了多模态解析、上下文检索和程序化计算等工具。代理需要整合不同格式的论文信息，并通过推理和使用适当的工具来回答研究问题。

Result: 即使是最先进的语言模型代理，在PaperArena上的平均准确率也仅为38.78%，在困难子集上准确率更是低至18.47%。此外，所有测试代理都存在工具使用效率低下的问题，通常会调用比任务所需更多的工具。

Conclusion: 现有语言模型代理在处理复杂、跨论文的科学研究任务方面潜力巨大。PaperArena为开发和评估更强大的科学发现代理提供了一个标准化的平台。

Abstract: Understanding and reasoning on the web-scale scientific literature is a
crucial touchstone for large language model (LLM) based agents designed to
support complex knowledge-intensive tasks. However, existing works are mainly
restricted to tool-free tasks within isolated papers, largely due to the lack
of a benchmark for cross-paper reasoning and multi-tool orchestration in real
research scenarios. In this work, we propose PaperArena, an evaluation
benchmark for agents to address real-world research questions that typically
require integrating information across multiple papers with the assistance of
external tools. Given a research question, agents should integrate diverse
formats across multiple papers through reasoning and interacting with
appropriate tools, thereby producing a well-grounded answer. To support
standardized evaluation, we provide a modular and extensible platform for agent
execution, offering tools such as multimodal parsing, context retrieval, and
programmatic computation. Experimental results reveal that even the most
advanced LLM powering a well-established agent system achieves merely 38.78%
average accuracy. On the hard subset, accuracy drops to only 18.47%,
highlighting great potential for improvement. We also present several empirical
findings, including that all agents tested exhibit inefficient tool usage,
often invoking more tools than necessary to solve a task. We invite the
community to adopt PaperArena to develop and evaluate more capable agents for
scientific discovery. Our code and data are available
https://github.com/Melmaphother/PaperArena.

</details>


### [601] [PoU: Proof-of-Use to Counter Tool-Call Hacking in DeepResearch Agents](https://arxiv.org/abs/2510.10931)
*SHengjie Ma,Chenlong Deng,Jiaxin Mao,Jiadeng Huang,Teng Wang,Junjie Wu,Changwang Zhang,Jun wang*

Main category: cs.AI

TL;DR: 该研究提出了一种名为“Proof-of-Use”（PoU）的框架，用于解决检索增强生成（RAG）代理中的“工具调用劫持”问题，该问题会导致代理过度依赖某些工具或生成与证据关联不大的答案。PoU通过强制执行可验证的因果链接来确保工具使用、检索到的证据和最终答案之间的联系，从而提高了事实准确性、证据忠实度和工具路由的平衡性。


<details>
  <summary>Details</summary>
Motivation: 当前基于检索增强生成（RAG）的代理，虽然可以通过强化学习（RL）实现多步推理，但存在一种名为“工具调用劫持”的失败模式。在这种模式下，代理会通过发出表面上正确的工具调用来虚假地提高奖励信号，但实际上并没有真正利用检索到的证据。这会导致代理过度依赖单一来源（模式崩溃）和生成与引用内容支持度很弱的答案（虚假归因）。

Method: 为了解决“工具调用劫持”问题，研究者提出了“Proof-of-Use”（PoU）框架。该框架基于证据的RL方法，强制执行检索到的证据、推理过程和最终答案之间可验证的因果链接。PoU通过结合语法引用验证、基于扰动的敏感性奖励以及答案-证据对齐目标，在一个分步合同中进行操作，确保工具的使用既可解释又在功能上有所依据。

Result: 在七个跨领域（包括领域内、领域外和工具分布外）的问答基准测试中，PoU框架在事实准确性、证据忠实度以及工具路由平衡性方面，持续优于强大的DeepResearch基线模型。

Conclusion: 研究结果强调，在训练RL代理时，不仅要关注任务结果，还要关注检索信息的因果使用。这为实现可信赖的检索增强推理提供了一个有原则的途径。

Abstract: Retrieval-augmented generation (RAG) agents, such as recent
DeepResearch-style systems, extend large language models (LLMs) with autonomous
information-seeking capabilities through external tools. While reinforcement
learning (RL) has enabled impressive multi-step reasoning, we identify a
previously overlooked failure mode, Tool-Call Hacking, where agents inflate
reward signals by issuing superficially correct tool calls without genuinely
leveraging the retrieved evidence. This results in (i) mode collapse into
repetitive reliance on a single source and (ii) spurious grounding, where
answers are only weakly supported by cited content.
  To address this, we propose Proof-of-Use (PoU), an evidence-grounded RL
framework that enforces verifiable causal links between retrieved evidence,
reasoning traces, and final answers. PoU operationalizes this through a unified
step-wise contract combining syntactic citation validation, perturbation-based
sensitivity rewards, and answer-evidence alignment objectives, ensuring that
tool usage remains both interpretable and functionally grounded.
  Across seven QA benchmarks spanning in-domain, out-of-domain, and
out-of-tool-distribution settings, PoU consistently outperforms strong
DeepResearch baselines in factual accuracy, evidence faithfulness, and
tool-routing balance. These findings highlight the necessity of grounding
RL-trained agents not merely in task outcomes but in the causal use of
retrieved information, offering a principled path toward trustworthy
retrieval-augmented reasoning.

</details>


### [602] [Scalable and Explainable Enterprise Knowledge Discovery Using Graph-Centric Hybrid Retrieval](https://arxiv.org/abs/2510.10942)
*Nilima Rao,Jagriti Srivastava,Pradeep Kumar Sharma,Hritvik Shrivastava*

Main category: cs.AI

TL;DR: 现代企业面临海量分布在不同系统中的知识管理难题，传统检索方法难以应对复杂查询。本文提出了一个集成了KBLam、DeepGraph和语义搜索的混合检索框架，用于企业信息自适应访问。该框架构建统一知识图谱，支持语义相似性搜索、结构推理和多跳推理。查询分析可动态选择最优检索策略，并结合图谱可视化和交互式界面，提供简洁、可解释的答案。实验表明，该框架显著提高了答案相关性，为企业智能知识助手奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有企业知识管理面临分布式异构系统中的海量知识，传统关键词或静态嵌入方法难以支持需要上下文推理和跨工件多跳推理的复杂查询。

Method: 提出一个模块化的混合检索框架，该框架集成知识库语言增强模型（KBLam）、DeepGraph表示和驱动嵌入的语义搜索。框架从解析的代码、拉取请求和提交历史等仓库构建统一知识图谱，支持语义相似性搜索、结构推理和多跳推理。查询分析动态确定最优检索策略，通过独立或融合处理支持结构化和非结构化数据源。提供交互式界面，支持图可视化、子图探索和上下文感知查询路由，生成简洁、可解释的答案。

Result: 在大型Git仓库上的实验表明，与独立的基于GPT的检索流程相比，统一的推理层将答案的相关性提高了高达80%。

Conclusion: 通过结合图谱构建、混合推理和交互式可视化，所提出的框架为企业环境中的智能知识助手提供了可扩展、可解释和以用户为中心的基础。

Abstract: Modern enterprises manage vast knowledge distributed across heterogeneous
systems such as Jira, Git repositories, Confluence, and wikis. Conventional
retrieval methods based on keyword search or static embeddings often fail to
answer complex queries that require contextual reasoning and multi-hop
inference across artifacts. We present a modular hybrid retrieval framework for
adaptive enterprise information access that integrates Knowledge Base
Language-Augmented Models (KBLam), DeepGraph representations, and
embedding-driven semantic search. The framework builds a unified knowledge
graph from parsed repositories including code, pull requests, and commit
histories, enabling semantic similarity search, structural inference, and
multi-hop reasoning. Query analysis dynamically determines the optimal
retrieval strategy, supporting both structured and unstructured data sources
through independent or fused processing. An interactive interface provides
graph visualizations, subgraph exploration, and context-aware query routing to
generate concise and explainable answers. Experiments on large-scale Git
repositories show that the unified reasoning layer improves answer relevance by
up to 80 percent compared with standalone GPT-based retrieval pipelines. By
combining graph construction, hybrid reasoning, and interactive visualization,
the proposed framework offers a scalable, explainable, and user-centric
foundation for intelligent knowledge assistants in enterprise environments.

</details>


### [603] [Video-STR: Reinforcing MLLMs in Video Spatio-Temporal Reasoning with Relation Graph](https://arxiv.org/abs/2510.10976)
*Wentao Wang,Heqing Zou,Tianze Luo,Rui Huang,Yutian Zhao,Zhuochen Wang,Hansheng Zhang,Chengwei Qin,Yan Wang,Lin Zhao,Huaijian Zhang*

Main category: cs.AI

TL;DR: Video-STR是一个基于图的强化学习方法，用于精确理解视频中的时空关系，解决了现有模型在精细时空理解方面的不足，并通过引入GRPO和STV-205k数据集提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在视频的时空理解方面存在不足，尤其是在需要高精度理解的领域（如具身智能和VR）。

Method: 提出了一种名为Video-STR的新型图增强强化学习方法。该方法使用图作为基础，结合强化学习中的可验证奖励（RLVR）以及图分组相对策略优化（GRPO）来提升模型进行时空推理的能力，并构建了一个包含205k个问答对的STV-205k数据集来解决数据不足的问题。

Result: Video-STR在多个基准测试中取得了最先进的成果，在STI-Bench上的表现比基础模型提高了13%，证明了该方法和数据集的有效性。

Conclusion: Video-STR通过图增强的强化学习方法和新数据集，成功提高了模型在视频时空理解方面的精度，为相关下游应用提供了有力支持。

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has demonstrated
strong semantic understanding capabilities, but struggles to perform precise
spatio-temporal understanding. Existing spatio-temporal methods primarily focus
on the video itself, while overlooking the physical information within the
video, such as multi-object layouts and motion. Such limitations restrict the
use of MLLMs in downstream applications that demand high precision, including
embodied intelligence and VR. To address this issue, we present Video-STR, a
novel graph-based reinforcement method for precise Video Spatio-Temporal
Reasoning. Building upon the capacity of Reinforcement Learning with Verifiable
Reward (RLVR) to improve model abilities, we introduce a reasoning mechanism
using graph-based Group Relative Policy Optimization (GRPO) method to guide the
model in inferring the underlying spatio-temporal topology of scenarios during
the thinking process. To resolve the lack of spatio-temporal training data, we
construct the STV-205k dataset with 205k question-answering pairs, covering
dynamic multi-object scenes in both indoor and outdoor environments, to support
the model training. Experiments show that Video-STR achieves state-of-the-art
results on various benchmarks, outperforming the base model by 13% on
STI-Bench, and demonstrating the effectiveness of our approach and dataset.
Code, model, and data will be released.

</details>


### [604] [Revisiting Model Interpolation for Efficient Reasoning](https://arxiv.org/abs/2510.10977)
*Taiqiang Wu,Runming Yang,Tao Liu,Jiahao Wang,Ngai Wong*

Main category: cs.AI

TL;DR: 模型插值作为一种简单的模型融合方法，通过三阶段演化过程，能够在效率和效果上超越复杂的模型融合方法，为定制化模型提供了一个实用的框架。


<details>
  <summary>Details</summary>
Motivation: 直接插值模型权重是一种简单的模型融合方法，在有指导和思考模型上表现出色，但其行为尚未被充分理解。本研究旨在系统地重新审视这种方法，理解其内在机制，并提供一种有效的模型融合策略。

Method: 通过实验观察模型插值在推理轨迹上的三阶段演化行为，并利用这些行为指导参数选择，以在性能和成本之间取得平衡。通过对模型层、模块和解码策略进行广泛的消融研究来验证结果。

Result: 模型插值遵循三阶段演化范式，具有不同的推理轨迹行为。经过策略性插值的模型在效率和效果上均超越了复杂的模型融合基线。

Conclusion: 模型插值是一种简单而有效的方法，通过理解其三阶段演化过程，可以为其提供一种实用且可控的框架，以获得具有目标推理能力和成本效益的模型。

Abstract: Model merging, typically on Instruct and Thinking models, has shown
remarkable performance for efficient reasoning. In this paper, we
systematically revisit the simplest merging method that interpolates two
weights directly. Particularly, we observe that model interpolation follows a
three-stage evolutionary paradigm with distinct behaviors on the reasoning
trajectory. These dynamics provide a principled guide for navigating the
performance-cost trade-off. Empirical results demonstrate that a strategically
interpolated model surprisingly surpasses sophisticated model merging baselines
on both efficiency and effectiveness. We further validate our findings with
extensive ablation studies on model layers, modules, and decoding strategies.
Ultimately, this work demystifies model interpolation and offers a practical
framework for crafting models with precisely targeted reasoning capabilities.
Code is available at \href{https://github.com/wutaiqiang/MI}{Github}.

</details>


### [605] [FBS Model-based Maintenance Record Accumulation for Failure-Cause Inference in Manufacturing Systems](https://arxiv.org/abs/2510.11003)
*Takuma Fujiu,Sho Okazaki,Kohei Kaminishi,Yuji Nakata,Shota Hamamoto,Kenshin Yokose,Tatsunori Hara,Yasushi Umeda,Jun Ota*

Main category: cs.AI

TL;DR: 本研究提出了一种基于功能-行为-结构（FBS）模型的诊断知识本体和维护记录累积方法，以改进制造系统中基于知识的故障原因推断。


<details>
  <summary>Details</summary>
Motivation: 在制造系统中，识别故障原因对于维护和提高生产效率至关重要。在基于知识的故障原因推断中，知识库需要明确结构化目标系统和故障知识，并包含足够长的因果链。

Method: 构建了诊断知识本体，并提出了一种基于功能-行为-结构（FBS）模型的维护记录累积方法。

Result: 使用所提方法累积的维护记录进行故障原因推断，与专家确定的候选原因相比，具有更好的一致性，尤其是在相关案例少且词汇不同的困难情况下。

Conclusion: 该方法利用设计阶段对目标的理解和知识，支持维护阶段的知识累积和问题解决，有望成为未来整个工程链知识共享的基础。未来需要开发更适合这些维护记录的推断方法，构建用户界面，并在更大、更多样化的系统上进行验证。

Abstract: In manufacturing systems, identifying the causes of failures is crucial for
maintaining and improving production efficiency. In knowledge-based
failure-cause inference, it is important that the knowledge base (1) explicitly
structures knowledge about the target system and about failures, and (2)
contains sufficiently long causal chains of failures. In this study, we
constructed Diagnostic Knowledge Ontology and proposed a
Function-Behavior-Structure (FBS) model-based maintenance-record accumulation
method based on it. Failure-cause inference using the maintenance records
accumulated by the proposed method showed better agreement with the set of
candidate causes enumerated by experts, especially in difficult cases where the
number of related cases is small and the vocabulary used differs. In the
future, it will be necessary to develop inference methods tailored to these
maintenance records, build a user interface, and carry out validation on larger
and more diverse systems. Additionally, this approach leverages the
understanding and knowledge of the target in the design phase to support
knowledge accumulation and problem solving during the maintenance phase, and it
is expected to become a foundation for knowledge sharing across the entire
engineering chain in the future.

</details>


### [606] [Argumentation-Based Explainability for Legal AI: Comparative and Regulatory Perspectives](https://arxiv.org/abs/2510.11079)
*Andrada Iulia Prajescu,Roberto Confalonieri*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Artificial Intelligence (AI) systems are increasingly deployed in legal
contexts, where their opacity raises significant challenges for fairness,
accountability, and trust. The so-called ``black box problem'' undermines the
legitimacy of automated decision-making, as affected individuals often lack
access to meaningful explanations. In response, the field of Explainable AI
(XAI) has proposed a variety of methods to enhance transparency, ranging from
example-based and rule-based techniques to hybrid and argumentation-based
approaches. This paper promotes computational models of arguments and their
role in providing legally relevant explanations, with particular attention to
their alignment with emerging regulatory frameworks such as the EU General Data
Protection Regulation (GDPR) and the Artificial Intelligence Act (AIA). We
analyze the strengths and limitations of different explanation strategies,
evaluate their applicability to legal reasoning, and highlight how
argumentation frameworks -- by capturing the defeasible, contestable, and
value-sensitive nature of law -- offer a particularly robust foundation for
explainable legal AI. Finally, we identify open challenges and research
directions, including bias mitigation, empirical validation in judicial
settings, and compliance with evolving ethical and legal standards, arguing
that computational argumentation is best positioned to meet both technical and
normative requirements of transparency in the law domain.

</details>


### [607] [Modeling AI-Driven Production and Competitiveness A Multi-Agent Economic Simulation of China and the United States](https://arxiv.org/abs/2510.11085)
*Yuxinyue Qian,Jun Liu*

Main category: cs.AI

TL;DR: 随着人工智能（AI）技术的发展，本文构建了一个多层次智能体经济模型，通过模拟比较了中国和美国在不同AI协作机制下的宏观经济产出。研究表明，AI作为独立生产实体能显著提高社会产出增长率，而中国在智能体扩张和技术追赶方面潜力巨大，可能实现技术趋同甚至超越。本研究为理解AI驱动的生产系统变革和国际竞争力转移提供了模型化分析框架和量化见解。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）技术快速发展，社会经济系统进入“人机协同创造”的新阶段。本研究旨在建立一个分析框架，以理解AI驱动的生产系统转型和国际竞争力变化。

Method: 在先前建立的多层次智能体经济模型基础上，通过模拟仿真比较了中国和美国在AI协作、网络效应和AI自主生产等不同机制下的宏观经济产出演变。

Result: (1) 当AI作为独立的生产实体时，其社会总产出增长率远超传统人力模型。(2) 中国在智能体种群扩张和技术追赶步伐方面展现出明显的加速潜力，可能实现技术趋同甚至部分超越。

Conclusion: 本研究为理解AI驱动的生产系统转型和国际竞争力转移提供了系统化的、基于模型的分析框架，并为相关政策制定提供了量化见解。

Abstract: With the rapid development of artificial intelligence (AI) technology,
socio-economic systems are entering a new stage of "human-AI co-creation."
Building upon a previously established multi-level intelligent agent economic
model, this paper conducts simulation-based comparisons of macroeconomic output
evolution in China and the United States under different mechanisms-AI
collaboration, network effects, and AI autonomous production. The results show
that: (1) when AI functions as an independent productive entity, the overall
growth rate of social output far exceeds that of traditional human-labor-based
models; (2) China demonstrates clear potential for acceleration in both the
expansion of intelligent agent populations and the pace of technological
catch-up, offering the possibility of achieving technological convergence or
even partial surpassing. This study provides a systematic, model-based
analytical framework for understanding AI-driven production system
transformation and shifts in international competitiveness, as well as
quantitative insights for relevant policy formulation.

</details>


### [608] [Spec-Driven AI for Science: The ARIA Framework for Automated and Reproducible Data Analysis](https://arxiv.org/abs/2510.11143)
*Chuke Chen,Biao Luo,Nan Li,Boxiang Wang,Hang Yang,Jing Guo,Ming Xu*

Main category: cs.AI

TL;DR: ARIA是一个文档驱动的框架，通过自然语言规范实现自动化、可解释的数据分析，弥合了科学数据分析能力与研究意图之间的差距。


<details>
  <summary>Details</summary>
Motivation: 现有AI分析工具要么过度自动化缺乏透明度，要么依赖手动脚本，阻碍了可扩展性和可复现性。

Method: ARIA通过一个文档中心的框架，集成了命令、上下文、代码、数据、编排和AI模块六层，允许研究人员用自然语言定义分析目标，ARIA则自主生成代码、验证计算并生成透明文档。

Result: ARIA实现了高预测准确性，能够快速识别最优特征集并选择合适的模型，以最小的调优和实验实现了最小的过拟合（例如，在波士顿房价案例中，R方=0.93）。

Conclusion: ARIA结合了研究AI和科学AI的原则，提供了一种透明、协作和可复现的科学发现新范式。

Abstract: The rapid expansion of scientific data has widened the gap between analytical
capability and research intent. Existing AI-based analysis tools, ranging from
AutoML frameworks to agentic research assistants, either favor automation over
transparency or depend on manual scripting that hinders scalability and
reproducibility. We present ARIA (Automated Research Intelligence Assistant), a
spec-driven, human-in-the-loop framework for automated and interpretable data
analysis. ARIA integrates six interoperable layers, namely Command, Context,
Code, Data, Orchestration, and AI Module, within a document-centric workflow
that unifies human reasoning and machine execution. Through natural-language
specifications, researchers define analytical goals while ARIA autonomously
generates executable code, validates computations, and produces transparent
documentation. Beyond achieving high predictive accuracy, ARIA can rapidly
identify optimal feature sets and select suitable models, minimizing redundant
tuning and repetitive experimentation. In the Boston Housing case, ARIA
discovered 25 key features and determined XGBoost as the best performing model
(R square = 0.93) with minimal overfitting. Evaluations across heterogeneous
domains demonstrate ARIA's strong performance, interpretability, and efficiency
compared with state-of-the-art systems. By combining AI for research and AI for
science principles within a spec-driven architecture, ARIA establishes a new
paradigm for transparent, collaborative, and reproducible scientific discovery.

</details>


### [609] [$How^{2}$: How to learn from procedural How-to questions](https://arxiv.org/abs/2510.11144)
*Gautier Dagan,Frank Keller,Alex Lascarides*

Main category: cs.AI

TL;DR: 该研究提出了一个名为$How^2$的记忆代理框架，用于解决AI代理在规划问题中如何提出和回答“操作指南”类型的问题的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理在面对规划问题时，虽然可以利用“操作指南”类型问题的答案来减少不确定性和弥补知识的不足，但这类问题的开放性（回答可以是从可执行动作到高级子目标描述的任何内容）使得AI代理难以提出，AI专家也难以给出能够支持高效规划的答案。

Method: 提出$How^2$框架，使代理能够提问“操作指南”类型的问题，存储答案，并在交互式环境中用于终身学习。

Result: 在Plancraft（一个Minecraft合成环境）中进行了评估，代理需要通过操纵库存物品来完成一项合成任务。实验表明，终身学习代理从抽象的、与当前状态分离的答案中受益最多。

Conclusion: $How^2$为基于LLM的代理提供了一种在交互式环境中通过提问来随着时间推移提高其规划能力的方法。

Abstract: An agent facing a planning problem can use answers to how-to questions to
reduce uncertainty and fill knowledge gaps, helping it solve both current and
future tasks. However, their open ended nature, where valid answers to "How do
I X?" range from executable actions to high-level descriptions of X's
sub-goals, makes them challenging for AI agents to ask, and for AI experts to
answer, in ways that support efficient planning. We introduce $How^{2}$, a
memory agent framework that enables agents to ask how-to questions, store the
answers, and reuse them for lifelong learning in interactive environments. We
evaluate our approach in Plancraft, a Minecraft crafting environment, where
agents must complete an assembly task by manipulating inventory items. Using
teacher models that answer at varying levels of abstraction, from executable
action sequences to high-level subgoal descriptions, we show that lifelong
learning agents benefit most from answers that are abstracted and decoupled
from the current state. $How^{2}$ offers a way for LLM-based agents to improve
their planning capabilities over time by asking questions in interactive
environments.

</details>


### [610] [Aligning Deep Implicit Preferences by Learning to Reason Defensively](https://arxiv.org/abs/2510.11194)
*Peiming Li,Zhiyuan Hu,Yang Tang,Shiyu Li,Xi Chen*

Main category: cs.AI

TL;DR: CDRA通过引入DeepPref基准和Pers-GenPRM来解决LLM在用户交互中的偏好推断和防御性推理方面的挑战，从而实现个性化、鲁棒的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型（LLM）在用户交互中存在两大挑战：无法推断用户深层隐性偏好（包括未说明的目标、语义上下文和风险容忍度），并且缺乏应对现实世界模糊性的防御性推理能力。这导致模型生成的回复肤浅、脆弱且目光短浅。

Method: 提出批评驱动推理对齐（CDRA）框架，将对齐视为一个结构化推理过程，而非简单的奖励匹配任务。具体包括：1. 引入DeepPref基准：包含3000个跨20个主题的偏好-查询对，通过模拟多方面认知委员会生成批评性注释的推理链，以解构查询语义和揭示潜在风险，从而弥合偏好推断的差距。2. 引入个性化生成过程奖励模型（Pers-GenPRM）：将奖励建模视为个性化推理任务，通过生成批评链来评估回复与用户偏好的对齐程度，并基于该推理给出最终分数，以增强防御性推理能力。3. 采用批评驱动策略对齐：一种过程级别的在线强化学习算法，整合了数值和自然语言反馈，指导策略模型。

Result: 实验证明，CDRA在发现并对齐用户真实偏好方面表现出色，同时执行鲁棒的推理。

Conclusion: CDRA通过结构化的推理过程和个性化的奖励机制，有效地解决了大语言模型在用户交互中的偏好推断和防御性推理的局限性，能够生成更符合用户需求且更可靠的回复。

Abstract: Personalized alignment is crucial for enabling Large Language Models (LLMs)
to engage effectively in user-centric interactions. However, current methods
face a dual challenge: they fail to infer users' deep implicit preferences
(including unstated goals, semantic context and risk tolerances), and they lack
the defensive reasoning required to navigate real-world ambiguity. This
cognitive gap leads to responses that are superficial, brittle and
short-sighted. To address this, we propose Critique-Driven Reasoning Alignment
(CDRA), which reframes alignment from a scalar reward-matching task into a
structured reasoning process. First, to bridge the preference inference gap, we
introduce the DeepPref benchmark. This dataset, comprising 3000
preference-query pairs across 20 topics, is curated by simulating a
multi-faceted cognitive council that produces critique-annotated reasoning
chains to deconstruct query semantics and reveal latent risks. Second, to
instill defensive reasoning, we introduce the Personalized Generative Process
Reward Model (Pers-GenPRM), which frames reward modeling as a personalized
reasoning task. It generates a critique chain to evaluate a response's
alignment with user preferences before outputting a final score based on this
rationale. Ultimately, this interpretable, structured reward signal guides
policy model through Critique-Driven Policy Alignment, a process-level online
reinforcement learning algorithm integrating both numerical and natural
language feedback. Experiments demonstrate that CDRA excels at discovering and
aligning with users' true preferences while executing robust reasoning. Our
code and dataset are available at https://github.com/Zephyrian-Hugh/Deep-pref.

</details>


### [611] [AI Alignment Strategies from a Risk Perspective: Independent Safety Mechanisms or Shared Failures?](https://arxiv.org/abs/2510.11235)
*Leonard Dung,Florian Mai*

Main category: cs.AI

TL;DR: AI对齐技术旨在确保AI系统的安全，但每种技术都有其失效模式。为降低风险，业界采用多重冗余保护的“纵深防御”策略。该策略的有效性取决于各技术失效模式的（不）相关性。本文分析了7种对齐技术和7种失效模式的重叠情况，并探讨了其对当前风险水平和未来AI对齐研究优先级的启示。


<details>
  <summary>Details</summary>
Motivation: AI对齐技术旨在确保AI系统不造成伤害，但每种技术都有失效模式。为了降低风险，AI安全社区越来越多地采用纵深防御框架，即通过多重冗余保护来维持安全，即使某些保护措施失效。然而，纵深防御的成功依赖于对齐技术之间失效模式的（不）相关性。

Method: 分析了7种代表性的AI对齐技术和7种失效模式，以了解它们在多大程度上存在重叠。

Result: 本文分析了7种代表性的AI对齐技术和7种失效模式，以了解它们在多大程度上存在重叠。

Conclusion: 分析7种对齐技术和7种失效模式的重叠情况，并讨论了其结果对理解当前风险水平以及未来如何优先考虑AI对齐研究的启示。

Abstract: AI alignment research aims to develop techniques to ensure that AI systems do
not cause harm. However, every alignment technique has failure modes, which are
conditions in which there is a non-negligible chance that the technique fails
to provide safety. As a strategy for risk mitigation, the AI safety community
has increasingly adopted a defense-in-depth framework: Conceding that there is
no single technique which guarantees safety, defense-in-depth consists in
having multiple redundant protections against safety failure, such that safety
can be maintained even if some protections fail. However, the success of
defense-in-depth depends on how (un)correlated failure modes are across
alignment techniques. For example, if all techniques had the exact same failure
modes, the defense-in-depth approach would provide no additional protection at
all. In this paper, we analyze 7 representative alignment techniques and 7
failure modes to understand the extent to which they overlap. We then discuss
our results' implications for understanding the current level of risk and how
to prioritize AI alignment research in the future.

</details>


### [612] [PADME: Procedure Aware DynaMic Execution](https://arxiv.org/abs/2510.11281)
*Deepeka Garg,Sihan Zeng,Annapoorani L. Narayanan,Sumitra Ganesh,Leo Ardon*

Main category: cs.AI

TL;DR: PADME是一个智能体框架，通过将自然语言程序转换为图形表示来改进长期程序执行，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有智能体在执行长周期程序时面临挑战，因为自然语言指令变化多端且缺乏结构。

Method: PADME使用两阶段方法：‘教学’阶段将程序转换为可执行的图，‘执行’阶段动态执行该图，并利用图结构减少错误。

Result: PADME在四个基准测试（包括ALFWorld和ScienceWorld）上取得了最先进的性能。

Conclusion: 基于图的程序表示是实现可靠、可扩展和可泛化的智能体自动化执行的有力方法。

Abstract: Learning to autonomously execute long-horizon procedures from natural
language remains a core challenge for intelligent agents. Free-form
instructions such as recipes, scientific protocols, or business workflows
encode rich procedural knowledge, but their variability and lack of structure
cause agents driven by large language models (LLMs) to drift or fail during
execution. We introduce Procedure Aware DynaMic Execution (PADME), an agent
framework that produces and exploits a graph-based representation of
procedures. Unlike prior work that relies on manual graph construction or
unstructured reasoning, PADME autonomously transforms procedural text into
executable graphs that capture task dependencies, decision points, and reusable
subroutines. Central to PADME is a two-phase methodology; Teach phase, which
focuses on systematic structuring, enrichment with executable logic of
procedures, followed by Execute phase, which enables dynamic execution in
response to real-time inputs and environment feedback. This separation ensures
quality assurance and scalability, allowing expert knowledge to be encoded once
and reliably reused across varying contexts. The graph representation also
provides an inductive bias that reduces error accumulation in long-horizon
reasoning, underscoring the importance of structured procedure modeling for
reliable agent-driven automation. Empirically, PADME achieves state-of-the-art
performance on four diverse benchmarks, including ALFWorld and ScienceWorld.
These results demonstrate that agents equipped with graph-based procedure
representations offer a powerful intermediate abstraction for robust and
generalizable execution.

</details>


### [613] [Evolution in Simulation: AI-Agent School with Dual Memory for High-Fidelity Educational Dynamics](https://arxiv.org/abs/2510.11290)
*Sheng Jin,Haoming Wang,Zhiqi Gao,Yongbo Yang,Bao Chunjia,Chengliang Wang*

Main category: cs.AI

TL;DR: AAS系统通过引入自进化机制，利用LLM驱动的智能体来模拟复杂的教育动态，解决了现有教育过程建模碎片化和智能体性能不足的问题。该系统采用零经验策略，结合经验-反思-优化循环和双记忆库（经验库和知识库），使智能体能够在模拟的学校场景中自主进化，从而更准确地模拟师生互动和学习过程。实验证明，AAS能够有效模拟复杂的教育动态，提升智能体的认知能力，为从“经验时代”迈向“模拟时代”奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究在教学过程建模方面存在碎片化问题，且智能体在模拟多样化的教育参与者方面存在局限性。本研究旨在构建一个能够模拟复杂教育动态的系统，并提升智能体在模拟多样化教育参与者方面的性能。

Method: 提出AI-Agent School (AAS) 系统，该系统围绕一个自进化机制构建，利用智能体来模拟复杂的教育动态。AAS构建了零经验策略，采用了持续的“经验-反思-优化”循环，并以包含经验和知识库的双记忆库为基础，整合了短期和长期记忆组件。通过这种机制，智能体在多样化的模拟学校场景中的情境化交互中自主进化。

Result: AAS系统能够有效地模拟复杂的教育动态，并能有效地培养高级智能体的认知能力，通过生成高保真行为和交互数据，为从“经验时代”迈向“模拟时代”提供了基础性的垫脚石。

Conclusion: AAS系统通过其自进化机制和双记忆库设计，能够有效模拟复杂的教育动态，提升智能体的认知能力，为教育模拟领域的研究提供了新的方向和方法。

Abstract: Large language models (LLMs) based Agents are increasingly pivotal in
simulating and understanding complex human systems and interactions. We propose
the AI-Agent School (AAS) system, built around a self-evolving mechanism that
leverages agents for simulating complex educational dynamics. Addressing the
fragmented issues in teaching process modeling and the limitations of agents
performance in simulating diverse educational participants, AAS constructs the
Zero-Exp strategy, employs a continuous "experience-reflection-optimization"
cycle, grounded in a dual memory base comprising experience and knowledge bases
and incorporating short-term and long-term memory components. Through this
mechanism, agents autonomously evolve via situated interactions within diverse
simulated school scenarios. This evolution enables agents to more accurately
model the nuanced, multi-faceted teacher-student engagements and underlying
learning processes found in physical schools. Experiment confirms that AAS can
effectively simulate intricate educational dynamics and is effective in
fostering advanced agent cognitive abilities, providing a foundational stepping
stone from the "Era of Experience" to the "Era of Simulation" by generating
high-fidelity behavioral and interaction data.

</details>


### [614] [Automated Skill Decomposition Meets Expert Ontologies: Bridging the Granularity Gap with LLMs](https://arxiv.org/abs/2510.11313)
*Le Ngoc Luyen,Marie-Hélène Abel*

Main category: cs.AI

TL;DR: 该论文研究使用大型语言模型（LLM）进行自动技能分解，并提出一个严格的、基于本体的评估框架。该框架标准化了从提示和生成到标准化和与本体节点对齐的整个流程。为了评估输出，我们引入了两个指标：一个语义 F1 分数，它使用基于最佳嵌入的匹配来评估内容准确性；另一个是层级感知 F1 分数，它根据结构正确的放置来评估粒度。我们在 ROME-ESCO-DecompSkill（一个精心策划的父级子集）上进行实验，比较了两种提示策略：零样本和具有示例的防泄露少样本。在各种 LLM 中，零样本提供了一个强大的基线，而少样本则一致地稳定了措辞和粒度，并改善了层级感知对齐。延迟分析还表明，示例引导的提示与未引导的零样本相比具有竞争力，有时甚至更快，因为它们能生成更符合模式的补全。总的来说，该框架、基准和指标为开发忠于本体的技能分解系统提供了可重现的基础。


<details>
  <summary>Details</summary>
Motivation: 自动化技能分解以实现可重用性和可组合性，但缺乏标准化的评估方法。

Method: 提出一个基于本体的评估框架，包括提示、生成、标准化和对齐。引入语义 F1 分数和层级感知 F1 分数。在 ROME-ESCO-DecompSkill 数据集上，使用零样本和少样本提示策略进行实验，并进行延迟分析。

Result: 零样本提供了强有力的基线，少样本稳定了措辞和粒度，提高了层级对齐。示例引导的提示具有竞争力，有时甚至比零样本更快。

Conclusion: 该框架、基准和指标为开发忠于本体的技能分解系统提供了一个可重现的基础。

Abstract: This paper investigates automated skill decomposition using Large Language
Models (LLMs) and proposes a rigorous, ontology-grounded evaluation framework.
Our framework standardizes the pipeline from prompting and generation to
normalization and alignment with ontology nodes. To evaluate outputs, we
introduce two metrics: a semantic F1-score that uses optimal embedding-based
matching to assess content accuracy, and a hierarchy-aware F1-score that
credits structurally correct placements to assess granularity. We conduct
experiments on ROME-ESCO-DecompSkill, a curated subset of parents, comparing
two prompting strategies: zero-shot and leakage-safe few-shot with exemplars.
Across diverse LLMs, zero-shot offers a strong baseline, while few-shot
consistently stabilizes phrasing and granularity and improves hierarchy-aware
alignment. A latency analysis further shows that exemplar-guided prompts are
competitive - and sometimes faster - than unguided zero-shot due to more
schema-compliant completions. Together, the framework, benchmark, and metrics
provide a reproducible foundation for developing ontology-faithful skill
decomposition systems.

</details>


### [615] [AI-Driven anemia diagnosis: A review of advanced models and techniques](https://arxiv.org/abs/2510.11380)
*Abdullah Al Mahmud,Prangon Chowdhury,Mohammed Borhan Uddin,Khaled Eabne Delowar,Tausifur Rahman Talha,Bijoy Dewanjee*

Main category: cs.AI

TL;DR: 机器学习和深度学习在贫血症的检测、分类和诊断方面取得了显著进展，本综述系统地回顾了这些最新进展。


<details>
  <summary>Details</summary>
Motivation: 鉴于贫血症是一种影响全球数百万人健康的普遍性健康问题，对人工智能技术在贫血症的准确和及时诊断方面的应用日益增长。

Method: 本研究对机器学习和深度学习模型在贫血症检测中的应用进行了系统的回顾和比较，并基于准确性、敏感性、特异性和精确性等性能指标对模型进行了评估。

Result: 对不同模型在贫血症检测和分类方面的优势和局限性进行了分析，强调了解决这些因素对提高诊断准确性的重要性。

Conclusion: 人工智能技术，特别是机器学习和深度学习，在贫血症的诊断方面显示出巨大潜力，但仍需进一步研究以优化模型并提高诊断准确性。

Abstract: Anemia, a condition marked by insufficient levels of red blood cells or
hemoglobin, remains a widespread health issue affecting millions of individuals
globally. Accurate and timely diagnosis is essential for effective management
and treatment of anemia. In recent years, there has been a growing interest in
the use of artificial intelligence techniques, i.e., machine learning (ML) and
deep learning (DL) for the detection, classification, and diagnosis of anemia.
This paper provides a systematic review of the recent advancements in this
field, with a focus on various models applied to anemia detection. The review
also compares these models based on several performance metrics, including
accuracy, sensitivity, specificity, and precision. By analyzing these metrics,
the paper evaluates the strengths and limitation of discussed models in
detecting and classifying anemia, emphasizing the importance of addressing
these factors to improve diagnostic accuracy.

</details>


### [616] [From <Answer> to <Think>: Multidimensional Supervision of Reasoning Process for LLM Optimization](https://arxiv.org/abs/2510.11457)
*Beining Wang,Weihang Su,Hongtao Tian,Tao Yang,Yujia Zhou,Ting Yao,Qingyao Ai,Yiqun Liu*

Main category: cs.AI

TL;DR: DRM通过在置信度、相关性和一致性三个维度上评估推理过程的质量，来提高LLM的多步推理能力，从而克服了RLVR的稀疏奖励和PRM的泛化性差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM多步推理改进方法（如RLVR和PRM）存在局限性：RLVR仅奖励最终正确答案，易传播错误并存在稀疏奖励问题；PRM虽然提供更密集的反馈，但缺乏泛化性和可解释性，需要任务特定的推理过程分割。

Method: 提出维度级奖励模型（DRM），该模型从置信度（不确定性校准）、相关性（语义对齐）和一致性（逻辑连贯性）三个维度评估推理过程的质量，无需提供真实答案即可进行可解释的评估。

Result: DRM提供了有效的监督信号，指导LLM的优化，并增强其推理能力。DRM监督训练在数学、问答、代码执行和谜题等开放域任务上，无论是否分布内或分布外，均实现了持续的性能提升。

Conclusion: 对推理过程进行多维度监督可以提高LLM的泛化推理能力，超越训练数据的分布。

Abstract: Improving the multi-step reasoning ability of Large Language Models (LLMs) is
a critical yet challenging task. The dominant paradigm, outcome-supervised
reinforcement learning (RLVR), rewards only correct final answers, often
propagating flawed reasoning and suffering from sparse reward signals. While
process-level reward models (PRMs) provide denser, step-by-step feedback, they
lack generalizability and interpretability, requiring task-specific
segmentation of the reasoning process. To this end, we propose the
Dimension-level Reward Model (DRM), a new supervision framework that bridges
the gap between these two approaches. DRM evaluates the quality of a reasoning
process along three fundamental, complementary, and interpretable dimensions:
Confidence for uncertainty calibration, Relevance for semantic alignment, and
Coherence for logical consistency. Together, these dimensions capture aspects
beyond final answer correctness and enable interpretable assessment without
requiring ground truth answers. Experimental results show that DRM provides
effective supervision signals, guides the optimization of LLMs and enhances
their reasoning ability. In particular, DRM-supervised training achieves
consistent gains on both in-distribution and out-of-distribution open-domain
tasks, including mathematics, question answering, code execution, and puzzles.
Our findings demonstrate that multidimensional supervision of the reasoning
process can improve the generalized reasoning ability of LLMs beyond the
training distribution.

</details>


### [617] [Unifying Deductive and Abductive Reasoning in Knowledge Graphs with Masked Diffusion Model](https://arxiv.org/abs/2510.11462)
*Yisen Gao,Jiaxin Bai,Yi Huang,Xingcheng Fu,Qingyun Sun,Yangqiu Song*

Main category: cs.AI

TL;DR: DARK是一个统一的知识图谱推理框架，结合了演绎和溯因推理，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法各自处理演绎和溯因推理，忽略了它们结合的协同潜力，即演绎推理可验证假设，溯因推理可揭示更深层次的逻辑模式。然而，这两者协同工作可以提高知识图谱分析的效率和深度。

Method: 提出了一种名为DARK（Deductive and Abductive Reasoning in Knowledge graphs）的统一框架。DARK是一个掩码扩散模型，能够捕捉查询和结论之间的双向关系。其关键创新包括：1. 自我反思去噪过程：在溯因推理过程中，迭代地生成和验证候选假设，以更好地利用演绎推理来完善假设。2. 逻辑探索强化学习：通过同时掩码查询和结论，使模型能够探索新颖的推理组合，以发现更丰富的逻辑关联。

Result: 在多个基准知识图谱上的广泛实验表明，DARK在演绎和溯因推理任务上均取得了最先进的性能。

Conclusion: 实验结果证明了统一演绎和溯因推理方法的显著优势，表明DARK在知识图谱推理领域具有重要价值。

Abstract: Deductive and abductive reasoning are two critical paradigms for analyzing
knowledge graphs, enabling applications from financial query answering to
scientific discovery. Deductive reasoning on knowledge graphs usually involves
retrieving entities that satisfy a complex logical query, while abductive
reasoning generates plausible logical hypotheses from observations. Despite
their clear synergistic potential, where deduction can validate hypotheses and
abduction can uncover deeper logical patterns, existing methods address them in
isolation. To bridge this gap, we propose DARK, a unified framework for
Deductive and Abductive Reasoning in Knowledge graphs. As a masked diffusion
model capable of capturing the bidirectional relationship between queries and
conclusions, DARK has two key innovations. First, to better leverage deduction
for hypothesis refinement during abductive reasoning, we introduce a
self-reflective denoising process that iteratively generates and validates
candidate hypotheses against the observed conclusion. Second, to discover
richer logical associations, we propose a logic-exploration reinforcement
learning approach that simultaneously masks queries and conclusions, enabling
the model to explore novel reasoning compositions. Extensive experiments on
multiple benchmark knowledge graphs show that DARK achieves state-of-the-art
performance on both deductive and abductive reasoning tasks, demonstrating the
significant benefits of our unified approach.

</details>


### [618] [Zero Data Retention in LLM-based Enterprise AI Assistants: A Comparative Study of Market Leading Agentic AI Products](https://arxiv.org/abs/2510.11558)
*Komal Gupta,Aditya Shrivastava*

Main category: cs.AI

TL;DR: 该论文探讨了企业级大型语言模型（LLM）应用的数据零留存策略。


<details>
  <summary>Details</summary>
Motivation: 随着企业AI助手的出现，保护隐私和合规性变得至关重要，特别是对于医疗和金融行业。

Method: 通过研究Salesforce和Microsoft的AI助手（AgentForce和Copilot）的案例，分析其支持零数据留存策略的不同技术架构、合规性和可用性权衡。

Result: 研究了两家行业领导者在实现零数据留存方面的不同技术架构。

Conclusion: 论文旨在分析零数据留存策略在企业级LLM应用中的技术架构和部署，并考虑其对应用方和LLM服务提供商（如OpenAI、Anthropic、Meta）的影响。

Abstract: Governance of data, compliance, and business privacy matters, particularly
for healthcare and finance businesses. Since the recent emergence of AI
enterprise AI assistants enhancing business productivity, safeguarding private
data and compliance is now a priority. With the implementation of AI assistants
across the enterprise, the zero data retention can be achieved by implementing
zero data retention policies by Large Language Model businesses like Open AI
and Anthropic and Meta. In this work, we explore zero data retention policies
for the Enterprise apps of large language models (LLMs). Our key contribution
is defining the architectural, compliance, and usability trade-offs of such
systems in parallel. In this research work, we examine the development of
commercial AI assistants with two industry leaders and market titans in this
arena - Salesforce and Microsoft. Both of these companies used distinct
technical architecture to support zero data retention policies. Salesforce
AgentForce and Microsoft Copilot are among the leading AI assistants providing
much-needed push to business productivity in customer care. The purpose of this
paper is to analyze the technical architecture and deployment of zero data
retention policy by consuming applications as well as big language models
service providers like Open Ai, Anthropic, and Meta.

</details>


### [619] [Analyzing and Internalizing Complex Policy Documents for LLM Agents](https://arxiv.org/abs/2510.11588)
*Jiateng Liu,Zhenhailong Wang,Xiaojiang Huang,Yingjie Li,Xing Fan,Xiang Li,Chenlei Guo,Ruhi Sarikaya,Heng Ji*

Main category: cs.AI

TL;DR: LLM代理系统中的策略文档过大，提出CC-Gen基准和CAP-CPT方法来解决策略内化问题，CAP-CPT通过分类感知策略继续预训练来提高性能并减少数据需求。


<details>
  <summary>Details</summary>
Motivation: LLM代理系统中的策略文档因业务规则增加而迅速膨胀，导致计算开销高，需要一种将策略文档内化到模型先验中的方法。

Method: 提出CC-Gen基准来评估复杂性和策略内化能力，并提出CAP-CPT方法，该方法通过将策略文档解析为事实、行为和条件类别，并专注于复杂条件，然后通过自动化流程合成数据并使用自回归预训练损失进行策略内化。

Result: CAP-CPT在CC-Gen基准上实现了97.3%的提示长度缩减，在Qwen-3-32B模型上提高了41%的性能，并进一步增强了tau-Bench的性能，同时所需的SFT数据最少。

Conclusion: CAP-CPT是一种有效的方法，可以通过策略内化来解决LLM代理系统中策略文档过大的问题，并在保持性能的同时显著减少计算开销和数据需求。

Abstract: Large Language Model (LLM)-based agentic systems rely on in-context policy
documents encoding diverse business rules. As requirements grow, these
documents expand rapidly, causing high computational overhead. This motivates
developing internalization methods that embed policy documents into model
priors while preserving performance. Prior prompt compression work targets
generic prompts, but agentic policy documents span multiple complexity levels
and require deeper reasoning, making internalization harder. We introduce
CC-Gen, an agentic benchmark generator with Controllable Complexity across four
levels, enabling systematic evaluation of agents' ability to handle complexity
and offering a unified framework for assessing policy internalization. Our
analysis shows that complex policy specifications governing workflows pose
major reasoning challenges. Supporting internalization with gold user agent
interaction trajectories containing chain-of-thought (CoT) annotations via
supervised fine-tuning (SFT) is data-intensive and degrades sharply as policy
complexity increases. To mitigate data and reasoning burdens, we propose
Category-Aware Policy Continued Pretraining (CAP-CPT). Our automated pipeline
parses policy documents to extract key specifications, grouping them into
factual, behavioral, and conditional categories, and isolating complex
conditions that drive workflow complexity. This guides targeted data synthesis
and enables agents to internalize policy information through an autoregressive
pretraining loss. Experiments show CAP-CPT improves SFT baselines in all
settings, with up to 41% and 22% gains on Qwen-3-32B, achieving 97.3% prompt
length reduction on CC-Gen and further enhancing tau-Bench with minimal SFT
data.

</details>


### [620] [Reproducibility: The New Frontier in AI Governance](https://arxiv.org/abs/2510.11595)
*Israel Mason-Williams,Gabryel Mason-Williams*

Main category: cs.AI

TL;DR: AI研究的低信噪比和可复现性差阻碍了有效的AI治理，应加强可复现性指南。


<details>
  <summary>Details</summary>
Motivation: AI研究的低信噪比、监管俘获、深度不确定性和分歧，以及AI研究发表速度快和缺乏严格的科学标准，削弱了AI政策制定者制定有意义的政策和治理协议的能力。

Method: 通过借鉴其他科学领域的危机经验，提出AI研究应采用更严格的可复现性指南，包括预注册、提高统计功效和发表阴性结果。

Result: 加强可复现性有助于提高AI治理的有效性，并在AI风险格局方面达成共识。

Conclusion: AI治理必须是反应性的，但政策制定者和政府应将可复现性协议视为治理工具库的核心组成部分，并要求AI研究提高标准。

Abstract: AI policymakers are responsible for delivering effective governance
mechanisms that can provide safe, aligned and trustworthy AI development.
However, the information environment offered to policymakers is characterised
by an unnecessarily low Signal-To-Noise Ratio, favouring regulatory capture and
creating deep uncertainty and divides on which risks should be prioritised from
a governance perspective. We posit that the current publication speeds in AI
combined with the lack of strong scientific standards, via weak reproducibility
protocols, effectively erodes the power of policymakers to enact meaningful
policy and governance protocols. Our paper outlines how AI research could adopt
stricter reproducibility guidelines to assist governance endeavours and improve
consensus on the AI risk landscape. We evaluate the forthcoming reproducibility
crisis within AI research through the lens of crises in other scientific
domains; providing a commentary on how adopting preregistration, increased
statistical power and negative result publication reproducibility protocols can
enable effective AI governance. While we maintain that AI governance must be
reactive due to AI's significant societal implications we argue that
policymakers and governments must consider reproducibility protocols as a core
tool in the governance arsenal and demand higher standards for AI research.
Code to replicate data and figures:
https://github.com/IFMW01/reproducibility-the-new-frontier-in-ai-governance

</details>


### [621] [Explainability, risk modeling, and segmentation based customer churn analytics for personalized retention in e-commerce](https://arxiv.org/abs/2510.11604)
*Sanjula De Alwis,Indrajith Ekanayake*

Main category: cs.AI

TL;DR: 本研究提出了一种结合可解释人工智能、生存分析和RFM分析的三元框架，用于在线零售客户流失分析，以实现个性化的客户挽留策略。


<details>
  <summary>Details</summary>
Motivation: 在线零售中，客户获取成本高于客户留存成本，因此需要客户流失分析。然而，当前的流失模型多为不透明的黑箱，难以深入了解客户流失的原因、进行客户挽留时机的把握以及识别高风险客户群体。因此，研究的重点应从单纯的预测转向基于可解释证据的个性化挽留策略设计。

Method: 本研究提出一个包含三个组成部分的三元框架：1. 可解释人工智能（XAI）用于量化特征贡献度；2. 生存分析用于模拟客户流失的生存风险；3. RFM（最近一次购买时间、购买频率、购买金额）分析用于根据交易行为对客户进行细分。

Result: 该框架能够实现对客户流失驱动因素的归因、干预窗口的估计，以及对细分客户群体的优先排序，从而支持旨在减少客户流失和增强客户忠诚度的策略。

Conclusion: 结合XAI、生存分析和RFM分析，可以为在线零售商提供更具洞察力的客户流失分析，从而制定更有效的个性化客户挽留策略。

Abstract: In online retail, customer acquisition typically incurs higher costs than
customer retention, motivating firms to invest in churn analytics. However,
many contemporary churn models operate as opaque black boxes, limiting insight
into the determinants of attrition, the timing of retention opportunities, and
the identification of high-risk customer segments. Accordingly, the emphasis
should shift from prediction alone to the design of personalized retention
strategies grounded in interpretable evidence. This study advances a
three-component framework that integrates explainable AI to quantify feature
contributions, survival analysis to model time-to-event churn risk, and RFM
profiling to segment customers by transactional behaviour. In combination,
these methods enable the attribution of churn drivers, estimation of
intervention windows, and prioritization of segments for targeted actions,
thereby supporting strategies that reduce attrition and strengthen customer
loyalty.

</details>


### [622] [ParaCook: On Time-Efficient Planning for Multi-Agent Systems](https://arxiv.org/abs/2510.11608)
*Shiqi Zhang,Xinbei Ma,Yunqing Xu,Zouying Cao,Pengrui Lu,Haobo Yuan,Tiancheng Shen,Zhuosheng Zhang,Hai Zhao,Ming-Hsuan Yang*

Main category: cs.AI

TL;DR: 现有的LLM智能体基准测试侧重于任务完成，忽略了并行和异步操作中的时间效率。本文提出了ParaCook，一个用于时间效率协作规划的基准测试，用于评估LLM在多智能体系统中的规划能力，特别是在并行规划方面。


<details>
  <summary>Details</summary>
Motivation: 现有的智能体基准测试在评估LLM的长期任务规划能力时，往往只关注任务完成，而忽略了并行和异步操作中的时间效率问题。因此，需要一个能够衡量时间效率和协作规划能力的基准测试。

Method: 本文提出了ParaCook，一个受Overcooked游戏启发的、用于时间效率协作规划的基准测试。ParaCook模拟了多智能体协作烹饪的任务，提供了一个简化的动作空间，以隔离战略性并行规划的核心挑战。研究人员使用ParaCook对最先进的LLM进行了全面的评估。

Result: 通过对现有LLM的评估，研究发现当前的LLM在并行和协作规划方面表现不佳，生成的规划并非最优，并且在处理并行动作和协调方面存在困难。然而，研究也指出LLM在抽象任务上具有潜力，因为它们可以专注于高级别的并行优化。

Conclusion: ParaCook为开发和评估注重时间效率的多智能体规划算法提供了一个可扩展的评估框架。该基准测试的提出，旨在推动LLM在时间效率和协作规划方面的发展，并为未来研究提供基础。

Abstract: Large Language Models (LLMs) exhibit strong reasoning abilities for planning
long-horizon, real-world tasks, yet existing agent benchmarks focus on task
completion while neglecting time efficiency in parallel and asynchronous
operations. To address this, we present ParaCook, a benchmark for
time-efficient collaborative planning. Inspired by the Overcooked game,
ParaCook provides an environment for various challenging interaction planning
of multi-agent systems that are instantiated as cooking tasks, with a
simplified action space to isolate the core challenge of strategic parallel
planning. Through a comprehensive evaluation of state-of-the-art LLMs, we find
that current approaches achieve suboptimal plans, which struggle with parallel
actions or coordination. Our analysis also reveals LLMs' potential on abstract
tasks where they can focus on high-level parallel optimization. ParaCook
provides a scalable evaluation framework with adjustable complexity,
establishing a foundation for developing and assessing time efficiency-aware
multi-agent planning. The code and data are available at
https://github.com/zsq259/ParaCook.

</details>


### [623] [SR-Scientist: Scientific Equation Discovery With Agentic AI](https://arxiv.org/abs/2510.11661)
*Shijie Xia,Yuhan Sun,Pengfei Liu*

Main category: cs.AI

TL;DR: SR-Scientist框架将LLM从方程提出者提升为自主AI科学家，能够编写代码分析数据、实现方程、进行评估并根据反馈进行优化。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在科学方程发现中主要扮演方程提出者的角色，而SR-Scientist旨在将LLM提升为能够自主完成数据分析、代码实现、评估和优化的AI科学家。

Method: SR-Scientist框架将代码解释器封装为数据分析和方程评估的工具，并指导LLM利用这些工具进行长期优化，减少人工干预。此外，还开发了一个端到端的强化学习框架来增强代理的能力。

Result: SR-Scientist在四个科学领域的数据集上，相比基线方法取得了6%到35%的绝对优势，并且在噪声鲁棒性、泛化能力和符号准确性方面表现优异。

Conclusion: SR-Scientist框架成功地将LLM从方程提出者转变为能够自主进行科学研究的AI科学家，并在多个科学领域取得了显著的成果。

Abstract: Recently, Large Language Models (LLMs) have been applied to scientific
equation discovery, leveraging their embedded scientific knowledge for
hypothesis generation. However, current methods typically confine LLMs to the
role of an equation proposer within search algorithms like genetic programming.
In this paper, we present SR-Scientist, a framework that elevates the LLM from
a simple equation proposer to an autonomous AI scientist that writes code to
analyze data, implements the equation as code, submits it for evaluation, and
optimizes the equation based on experimental feedback. Specifically, we wrap
the code interpreter into a set of tools for data analysis and equation
evaluation. The agent is instructed to optimize the equation by utilizing these
tools over a long horizon with minimal human-defined pipelines. Empirical
results show that SR-Scientist outperforms baseline methods by an absolute
margin of 6% to 35% on datasets covering four science disciplines.
Additionally, we demonstrate our method's robustness to noise, the
generalization of the discovered equations to out-of-domain data, and their
symbolic accuracy. Furthermore, we develop an end-to-end reinforcement learning
framework to enhance the agent's capabilities.

</details>


### [624] [Operand Quant: A Single-Agent Architecture for Autonomous Machine Learning Engineering](https://arxiv.org/abs/2510.11694)
*Arjun Sahney,Ram Gorthi,Cezary Łastowski,Javier Vega*

Main category: cs.AI

TL;DR: Operand Quant是一个单一智能体、基于IDE的自主机器学习工程架构，在MLE-Benchmark (2025) 上取得了新的SOTA结果，奖牌率为0.3956 +/- 0.0565。


<details>
  <summary>Details</summary>
Motivation: 介绍一种新的自主机器学习工程（MLE）架构，名为Operand Quant，它与传统的多智能体协调框架不同。

Method: Operand Quant将MLE生命周期的所有阶段（探索、建模、实验和部署）整合到一个单一的、上下文感知的智能体中，并在一个受控的IDE环境中运行。

Result: 在MLE-Benchmark (2025) 上，Operand Quant取得了0.3956 +/- 0.0565的总体奖牌率，创下新的SOTA。

Conclusion: 证明了一个在受控IDE环境中自主运行的线性、非阻塞智能体，可以在相同的约束条件下超越多智能体和协调系统。

Abstract: We present Operand Quant, a single-agent, IDE-based architecture for
autonomous machine learning engineering (MLE). Operand Quant departs from
conventional multi-agent orchestration frameworks by consolidating all MLE
lifecycle stages -- exploration, modeling, experimentation, and deployment --
within a single, context-aware agent. On the MLE-Benchmark (2025), Operand
Quant achieved a new state-of-the-art (SOTA) result, with an overall medal rate
of 0.3956 +/- 0.0565 across 75 problems -- the highest recorded performance
among all evaluated systems to date. The architecture demonstrates that a
linear, non-blocking agent, operating autonomously within a controlled IDE
environment, can outperform multi-agent and orchestrated systems under
identical constraints.

</details>


### [625] [Domain-Specific Constitutional AI: Enhancing Safety in LLM-Powered Mental Health Chatbots](https://arxiv.org/abs/2509.16444)
*Chenhan Lyu,Yutong Song,Pengfei Zhang,Amir M. Rahmani*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Mental health applications have emerged as a critical area in computational
health, driven by rising global rates of mental illness, the integration of AI
in psychological care, and the need for scalable solutions in underserved
communities. These include therapy chatbots, crisis detection, and wellness
platforms handling sensitive data, requiring specialized AI safety beyond
general safeguards due to emotional vulnerability, risks like misdiagnosis or
symptom exacerbation, and precise management of vulnerable states to avoid
severe outcomes such as self-harm or loss of trust. Despite AI safety advances,
general safeguards inadequately address mental health-specific challenges,
including crisis intervention accuracy to avert escalations, therapeutic
guideline adherence to prevent misinformation, scale limitations in
resource-constrained settings, and adaptation to nuanced dialogues where
generics may introduce biases or miss distress signals. We introduce an
approach to apply Constitutional AI training with domain-specific mental health
principles for safe, domain-adapted CAI systems in computational mental health
applications.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [626] [Modular Counting over 3-Element and Conservative Domains](https://arxiv.org/abs/2510.09950)
*Andrei A. Bulatov,Amirhossein Kazeminia*

Main category: cs.LO

TL;DR: 该论文研究了模数计数问题，特别是#_pCSP(H)，即计算到H的同态数量模p，其中p是素数。这扩展了图同态的现有工作，并为一般关系结构提供了系统研究。


<details>
  <summary>Details</summary>
Motivation: 该论文的动机是系统地研究模数计数问题#_pCSP(H)，特别是对一般关系结构。

Method: 该论文提出了一种将模数计数问题约简到更小域的新方法，并研究了在3元域和保守域上的复杂性。

Result: 该论文的主要成果包括一种新的将模数计数问题约简到更小域的方法，以及对3元域和保守域上的模数计数问题的复杂性研究。

Conclusion: 该论文通过提供一种新的约简方法和对特定域上的复杂性进行分析，为模数计数研究做出了贡献。

Abstract: In the Constraint Satisfaction Problem (CSP for short) the goal is to decide
the existence of a homomorphism from a given relational structure $G$ to a
given relational structure $H$. If the structure $H$ is fixed and $G$ is the
only input, the problem is denoted $CSP(H)$. In its counting version,
$\#CSP(H)$, the task is to find the number of such homomorphisms. The CSP and
#CSP have been used to model a wide variety of combinatorial problems and have
received a tremendous amount of attention from researchers from multiple
disciplines.
  In this paper we consider the modular version of the counting CSPs, that is,
problems of the form $\#_pCSP(H)$ of counting the number of homomorphisms to
$H$ modulo a fixed prime number $p$. Modular counting has been intensively
studied during the last decade, although mainly in the case of graph
homomorphisms. Here we continue the program of systematic research of modular
counting of homomorphisms to general relational structures. The main results of
the paper include a new way of reducing modular counting problems to smaller
domains and a study of the complexity of such problems over 3-element domains
and over conservative domains, that is, relational structures that allow to
express (in a certain exact way) every possible unary predicate.

</details>


### [627] [Proof Strategy Extraction from LLMs for Enhancing Symbolic Provers](https://arxiv.org/abs/2510.10131)
*Jian Fang,Yican Sun,Yingfei Xiong*

Main category: cs.LO

TL;DR: LLMs can aid theorem proving but have drawbacks; this paper extracts LLM proof strategies to enhance symbolic provers like CoqHammer, improving its success rate by 13.41% on Rocq projects.


<details>
  <summary>Details</summary>
Motivation: To explore if internal strategies of LLMs can be extracted to improve symbolic provers, addressing the cost and security concerns of solely relying on LLMs for theorem proving.

Method: Strat2Rocq extracts proof strategies from LLMs by analyzing their natural language proofs and formalizing them as lemmas for symbolic provers (Rocq). Errors are mitigated using an agentic approach.

Result: Strat2Rocq enhanced the success rate of CoqHammer by 13.41% on open-source Rocq projects for software verification.

Conclusion: Extracting LLM proof strategies and formalizing them as lemmas significantly improves the performance of symbolic provers, demonstrating a viable approach to leverage LLMs' capabilities without their associated costs and security risks.

Abstract: One important approach to software verification is interactive theorem
proving. However, writing formal proofs often requires substantial human
effort, making proof automation highly important. Traditionally, proof
automation has relied on symbolic provers. Recently, large language models
(LLMs) have demonstrated strong capabilities in theorem proving, complementing
symbolic provers. Nonetheless, prompting LLMs can be expensive and may pose
security risks for confidential codebases. As a result, purely symbolic
approaches remain important even in the LLM era, as they are cost-effective,
secure, and complement the strengths of LLMs.
  Motivated by these considerations, we ask a new research question: can we
extract the internal strategies of LLMs to enhance the capabilities of symbolic
provers? As an initial attempt to answer this question, we propose Strat2Rocq,
which extracts proof strategies from LLMs and formalizes them as lemmas in
Rocq. These lemmas are accessible to symbolic provers such as CoqHammer. With
the addition of these LLM-extracted lemmas, CoqHammer is able to prove more
theorems. The knowledge extraction process involves analyzing the proof
trajectories of LLMs on a training set of proved theorems. For each theorem, we
prompt the LLM to generate a natural language proof, then ask it to summarize
this proof into formalized lemmas with proofs. We also employ a standard
agentic approach to mitigate errors during formalization. Our evaluation
demonstrates that, on open-source Rocq projects for software verification,
Strat2Rocq enhances the success rate of CoqHammer by 13.41%.

</details>


### [628] [Formally Verified Certification of Unsolvability of Temporal Planning Problems](https://arxiv.org/abs/2510.10189)
*David Wang,Mohammad Abdulaziz*

Main category: cs.LO

TL;DR: 该方法为时间规划问题提供了一个不可解性认证方法，将规划问题编码为带时自动机网络，并使用模型检查器和认证器进行认证。


<details>
  <summary>Details</summary>
Motivation: 提供一种可信的时间规划不可解性认证方法。

Method: 将规划问题编码为带时自动机网络，使用模型检查器进行检查，再用认证器进行认证。对编码实现进行了Isabelle/HOL形式化验证，并使用已有的Isabelle/HOL形式化验证过的认证器。

Result: 生成了不可解性认证，并且该认证是可信的。

Conclusion: 所提出的方法提供了一种可信的时间规划不可解性认证方式。

Abstract: We present an approach to unsolvability certification of temporal planning.
Our approach is based on encoding the planning problem into a network of timed
automata, and then using an efficient model checker on the network followed by
a certificate checker to certify the output of the model checker. Our approach
prioritises trustworthiness of the certification: we formally verify our
implementation of the encoding to timed automata using the theorem prover
Isabelle/HOL and we use an existing certificate checker (also formally verified
in Isabelle/HOL) to certify the model checking result.

</details>


### [629] [Non-Expansive Fuzzy Coalgebraic Logic](https://arxiv.org/abs/2510.11080)
*Stefan Gebhart,Lutz Schröder,Paul Wild*

Main category: cs.LO

TL;DR: 本文研究了非扩张性合变更模态模糊逻辑，并给出了判定其在PSace内可判定的标准，该标准既保留了Zadeh基的计算效率，又增强了其表达能力，同时避免了Lukasiewicz基的计算难题。


<details>
  <summary>Details</summary>
Motivation: 模糊模态逻辑在Zadeh基上虽然计算上可处理，但表达能力有限；在Lukasiewicz基上则表达能力更强，但计算上往往难以处理甚至不可判定。本文旨在寻找一种在表达能力和计算效率之间取得平衡的模糊模态逻辑。

Method: 本文聚焦于非扩张性合变更模态模糊逻辑，并提出一个判定其在PSpace内可判定的标准。利用此标准，本文不仅恢复了非扩张性模糊ALC的计算复杂性结果，还为概率和度量迁移系统的各种定量模态逻辑获得了新的PSpace上界。

Result: 提出的非扩张性合变更模态模糊逻辑判定标准，在恢复非扩张性模糊ALC的PSpace复杂性结果的同时，也为概率和度量迁移系统的定量模态逻辑提供了新的PSpace上界。

Conclusion: 非扩张性合变更模态模糊逻辑提供了一个在表达能力和计算效率之间取得平衡的框架，为相关领域的推理提供了新的可能性。

Abstract: Fuzzy logic extends the classical truth values "true" and "false" with
additional truth degrees in between, typically real numbers in the unit
interval. More specifically, fuzzy modal logics in this sense are given by a
choice of fuzzy modalities and a fuzzy propositional base. It has been noted
that fuzzy modal logics over the Zadeh base, which interprets disjunction as
maximum, are often computationally tractable but on the other hand add little
in the way of expressivity to their classical counterparts. Contrastingly,
fuzzy modal logics over the more expressive Lukasiewicz base have attractive
logical properties but are often computationally less tractable or even
undecidable. In the basic case of the modal logic of fuzzy relations, sometimes
termed fuzzy ALC, it has recently been shown that an intermediate non-expansive
propositional base, known from characteristic logics for behavioural distances
of quantitative systems, strikes a balance between these poles: It provides
increased expressiveness over the Zadeh base while avoiding the computational
problems of the Lukasiewicz base, in fact allowing for reasoning in PSpace.
Modal logics, in particular fuzzy modal logics, generally vary widely in terms
of syntax and semantics, involving, for instance, probabilistic, preferential,
or weighted structures. Coalgebraic modal logic provides a unifying framework
for wide ranges of semantically different modal logics, both two-valued and
fuzzy. In the present work, we focus on non-expansive coalgebraic fuzzy modal
logics, providing a criterion for decidability in PSpace. Using this criterion,
we recover the mentioned complexity result for non-expansive fuzzy ALC and
moreover obtain new PSpace upper bounds for various quantitative modal logics
for probabilistic and metric transition systems.

</details>


### [630] [Proceedings Twentieth International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice](https://arxiv.org/abs/2510.11199)
*Kaustuv Chaudhuri,Daniele Nantes-Sobrinho*

Main category: cs.LO

TL;DR: 2025年LFMTP研讨会论文集，讨论逻辑框架和元语言的理论与实践。


<details>
  <summary>Details</summary>
Motivation: 介绍LFMTP 2025会议论文集。

Method: 会议论文集。

Result: 包含逻辑框架和元语言的理论与实践相关研究。

Conclusion: LFMTP 2025会议在英国伯明翰举行，是FSCD会议的卫星活动。

Abstract: These are the contributed papers presented at the 20th International Workshop
on Logical Frameworks and Meta-Languages: Theory and Practice (LFMTP 2025), at
Birmingham, UK on 19 July as a satellite event of the FSCD conference. The
program committee for this edition of LFMTP was chaired by Kaustuv Chaudhuri
and Daniele Nantes-Sobrinho. More information about LFMTP can be found on
https://lfmtp.org.

</details>


### [631] [Cut-elimination for the alternation-free modal mu-calculus](https://arxiv.org/abs/2510.11293)
*Bahareh Afshari,Johannes Kloibhofer*

Main category: cs.LO

TL;DR: 使用循环证明系统，通过多重剪断和良基序理论，对无交替的模态 mu-演算片段进行了句法上的剪断消除。


<details>
  <summary>Details</summary>
Motivation: 对无交替的模态 mu-演算片段进行句法上的剪断消除，而无需通过其他逻辑或正则化中间机器。

Method: 在循环证明系统中，利用多重剪断和良基序理论，将带有剪断的循环证明直接转化为无剪断的证明。

Result: 成功实现了无交替模态 mu-演算片段的句法剪断消除。

Conclusion: 所提出的方法是一种新颖的、直接的剪断消除技术，避免了不必要的中间步骤，并利用了良基序理论来保证终止性。

Abstract: We present a syntactic cut-elimination procedure for the alternation-free
fragment of the modal mu-calculus. Cut reduction is carried out within a cyclic
proof system, where proofs are finitely branching but may be non-wellfounded.
The structure of such proofs is exploited to directly transform a cyclic proof
with cuts into a cut-free one, without detouring through other logics or
relying on intermediate machinery for regularisation. Novel ingredients include
the use of multicuts and results from the theory of well-quasi-orders, the
later used in the termination argument.

</details>


### [632] [A Denotational Product Construction for Temporal Verification of Effectful Higher-Order Programs](https://arxiv.org/abs/2510.11320)
*Kazuki Watanabe,Mayuko Kori,Taro Sekiyama,Satoshi Kura,Hiroshi Unno*

Main category: cs.LO

TL;DR: 提出一个适用于有效应高阶程序（包括概率高阶程序）的线性时间时序验证的范畴框架，该框架通过一个范畴乘积构造，将效应高阶程序的线性时间安全验证归约为乘积程序的最小前置条件计算，从而可以应用现有的最小前置条件计算算法。框架的正确性通过强单子同态下的保持定理和纤维丛上的提升存在性得到证明。该框架已成功应用于概率和天使非确定性高阶程序，并实现了针对概率情况的自动化求解器，是首个针对带递归的概率高阶程序的线性时间时序验证自动化验证器。


<details>
  <summary>Details</summary>
Motivation: 为有效应高阶程序（包括概率高阶程序）提供一个通用的线性时间时序验证方法。

Method: 提出一个范畴框架，通过范畴乘积构造，将时序验证问题归约为最小前置条件计算，并证明了该构造的正确性。

Result: 实现了针对概率和天使非确定性高阶程序的验证框架，并为概率情况开发了自动化求解器。

Conclusion: 该范畴框架能够有效地进行有效应高阶程序的线性时间时序验证，特别是对于概率高阶程序，并实现了首个针对带递归的概率高阶程序的自动化验证器。

Abstract: We propose a categorical framework for linear-time temporal verification of
effectful higher-order programs, including probabilistic higher-order programs.
Our framework provides a generic denotational reduction -- namely, a
denotational product construction -- from linear-time safety verification of
effectful higher-order programs to computation of weakest pre-conditions of
product programs. This reduction enables us to apply existing algorithms for
such well-studied computations of weakest pre-conditions, some of which are
available as off-the-shelf solvers. We show the correctness of our denotational
product construction by proving a preservation theorem under strong monad
morphisms and an existence of suitable liftings along a fibration. We
instantiate our framework with both probabilistic and angelic nondeterministic
higher-order programs, and implement an automated solver for the probabilistic
case based on the existing solver developed by Kura and Unno. To the best of
our knowledge, this is the first automated verifier for linear-time temporal
verification of probabilistic higher-order programs with recursion.

</details>


### [633] [Representations](https://arxiv.org/abs/2510.11419)
*Paul Brunet*

Main category: cs.LO

TL;DR: 该论文提出了一个名为Representations的软件分析系统（SAS）形式（元）模型，以简化SAS的开发并关注其完整性。


<details>
  <summary>Details</summary>
Motivation: 自动化系统的形式化分析需要新的验证框架来处理新的编程特性或需要关注的bug，但逻辑的完整性往往难以证明。

Method: 提出一个通用的SAS形式（元）模型（Representations），该模型假设很少，能够捕捉大量SAS。通过该模型来理解现有完整性证明的结构，并利用该结构来构建新的SAS并证明其完整性。

Result: 该方法有助于理解现有完整性证明的结构，并能用于构建新的SAS并证明其完整性。

Conclusion: Representations模型简化了SAS的开发，特别是在保证完整性方面。

Abstract: The formal analysis of automated systems is an important and growing
industry. This activity routinely requires new verification frameworks to be
developed to tackle new programming features, or new considerations (bugs of
interest). Often, one particular property can prove frustrating to establish:
completeness of the logic with respect to the semantics. In this paper, we try
and make such developments easier, with a particular attention on completeness.
Towards that aim, we propose a formal (meta-)model of software analysis systems
(SAS), the eponymous Representations. This model requires few assumptions on
the SAS being modeled, and as such is able to capture a large class of such
systems. We then show how our approach can be fruitful, both to understand how
existing completeness proofs can be structured, and to leverage this structure
to build new systems and prove their completeness.

</details>


### [634] [Lecture Notes on Verifying Graph Neural Networks](https://arxiv.org/abs/2510.11617)
*François Schwarzentruber*

Main category: cs.LO

TL;DR: We introduce a modal logic with counting inequalities for verifying graph neural networks, along with a tableau-based satisfiability algorithm.


<details>
  <summary>Details</summary>
Motivation: The paper aims to connect graph neural networks (GNNs) with logic and develop a verification method for GNNs using a novel modal logic.

Method: The paper recalls the connection between GNNs, Weisfeiler-Lehman tests, and logics. It then presents a modal logic with counting modalities in linear inequalities for GNN verification and describes a tableau-based satisfiability algorithm extended with quantifier-free Boolean algebra and Presburger arithmetic.

Result: The paper presents a novel modal logic and a satisfiability algorithm for GNN verification tasks.

Conclusion: The developed modal logic and algorithm offer a way to solve verification tasks on graph neural networks.

Abstract: In these lecture notes, we first recall the connection between graph neural
networks, Weisfeiler-Lehman tests and logics such as first-order logic and
graded modal logic. We then present a modal logic in which counting modalities
appear in linear inequalities in order to solve verification tasks on graph
neural networks. We describe an algorithm for the satisfiability problem of
that logic. It is inspired from the tableau method of vanilla modal logic,
extended with reasoning in quantifier-free fragment Boolean algebra with
Presburger arithmetic.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [635] [Generative Models for Helmholtz Equation Solutions: A Dataset of Acoustic Materials](https://arxiv.org/abs/2510.09657)
*Riccardo Fosco Gramaccioni,Christian Marinoni,Fabrizio Frezza,Aurelio Uncini,Danilo Comminiello*

Main category: cs.LG

TL;DR: 该研究引入了一个包含31,000个声学材料的HA30K数据集，并提出了一种基于Stable Diffusion和ControlNet的深度学习方法，用于快速模拟声波在这些材料中的传播，以解决传统数值方法的计算成本高昂的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的数值求解方法（如有限元方法）在模拟复杂声学材料中的声波传播时计算成本高昂，尤其是在处理大规模或实时场景时。因此，需要更高效的方法来解决这个问题。

Method: 研究人员创建了一个包含31,000个声学材料及其亥姆霍兹方程解的HA30K数据集。他们探索了一种基于Stable Diffusion和ControlNet的深度学习方法，将声学材料的解表示为图像，并利用GPU并行处理来加速模拟，从而绕过复杂的仿真软件和显式方程求解。

Result: 该深度学习方法利用GPU并行处理能力，可以同时处理多个模拟，显著减少了计算时间。通过将解表示为图像，避免了对复杂仿真软件和显式方程求解的需求。此外，可以在推理时调整扩散步数，以平衡速度和质量。

Conclusion: 深度学习方法，特别是本研究提出的方法，在早期研究阶段非常有用，因为在这些阶段，快速探索比绝对精度更重要。该方法通过利用GPU并行处理和将问题转化为图像生成任务，大大提高了声波传播模拟的效率。

Abstract: Accurate simulation of wave propagation in complex acoustic materials is
crucial for applications in sound design, noise control, and material
engineering. Traditional numerical solvers, such as finite element methods, are
computationally expensive, especially when dealing with large-scale or
real-time scenarios. In this work, we introduce a dataset of 31,000 acoustic
materials, named HA30K, designed and simulated solving the Helmholtz equations.
For each material, we provide the geometric configuration and the corresponding
pressure field solution, enabling data-driven approaches to learn Helmholtz
equation solutions. As a baseline, we explore a deep learning approach based on
Stable Diffusion with ControlNet, a state-of-the-art model for image
generation. Unlike classical solvers, our approach leverages GPU
parallelization to process multiple simulations simultaneously, drastically
reducing computation time. By representing solutions as images, we bypass the
need for complex simulation software and explicit equation-solving.
Additionally, the number of diffusion steps can be adjusted at inference time,
balancing speed and quality. We aim to demonstrate that deep learning-based
methods are particularly useful in early-stage research, where rapid
exploration is more critical than absolute accuracy.

</details>


### [636] [Direct Routing Gradient (DRGrad): A Personalized Information Surgery for Multi-Task Learning (MTL) Recommendations](https://arxiv.org/abs/2510.09643)
*Yuguang Liu,Yiyun Miao,Luyao Xia*

Main category: cs.LG

TL;DR: DRGrad是一个新框架，用于解决多任务推荐系统中的负迁移和跷跷板现象，通过路由、更新和个性化门控网络来管理任务冲突，并在真实数据集上取得了优于现有模型的效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决工业规模推荐系统中多任务学习（MTL）面临的负迁移和跷跷板现象，并更好地利用个性化信息，提出DRGrad框架。

Method: DRGrad框架包含路由、更新和个性化门控网络三个核心组件，能够评估训练过程中任务间的权重，并利用所有有效梯度来减少冲突。

Result: 在包含150亿样本的真实推荐数据集上，DRGrad相比于现有的MTL模型在AUC指标上表现更优，有效管理了任务冲突，且没有增加模型复杂度，同时解决了噪声处理的不足。在Census-income和Synthetic数据集上的实验也证明了DRGrad在处理不同相关度和个性化程度的任务时的能力。

Conclusion: DRGrad框架能够有效解决多任务推荐系统中的任务冲突问题，并在多个数据集上展现出优越的性能。

Abstract: Multi-task learning (MTL) has emerged as a successful strategy in
industrial-scale recommender systems, offering significant advantages such as
capturing diverse users' interests and accurately detecting different behaviors
like ``click" or ``dwell time". However, negative transfer and the seesaw
phenomenon pose challenges to MTL models due to the complex and often
contradictory task correlations in real-world recommendations. To address the
problem while making better use of personalized information, we propose a
personalized Direct Routing Gradient framework (DRGrad), which consists of
three key components: router, updater and personalized gate network. DRGrad
judges the stakes between tasks in the training process, which can leverage all
valid gradients for the respective task to reduce conflicts. We evaluate the
efficiency of DRGrad on complex MTL using a real-world recommendation dataset
with 15 billion samples. The results show that DRGrad's superior performance
over competing state-of-the-art MTL models, especially in terms of AUC (Area
Under the Curve) metrics, indicating that it effectively manages task conflicts
in multi-task learning environments without increasing model complexity, while
also addressing the deficiencies in noise processing. Moreover, experiments on
the public Census-income dataset and Synthetic dataset, have demonstrated the
capability of DRGrad in judging and routing the stakes between tasks with
varying degrees of correlation and personalization.

</details>


### [637] [Deep Neural Networks Inspired by Differential Equations](https://arxiv.org/abs/2510.09685)
*Yongshuai Liu,Lianfang Wang,Kuilin Qin,Qinghua Zhang,Faqiang Wang,Li Cui,Jun Liu,Yuping Duan,Tieyong Zeng*

Main category: cs.LG

TL;DR: 深度学习在计算机视觉、科学计算和动力学系统等领域取得了显著进展，但仍面临理论理解、可解释性和泛化能力的挑战。因此，本文采用微分方程的视角，对受微分方程启发的深度神经网络架构和动态建模方法进行了全面的回顾。研究了基于常微分方程（ODEs）的深度神经网络模型和确定性动力学网络，以及基于随机微分方程（SDEs）的正则化技术和随机动力学网络模型。通过数值比较来说明这些模型的特性和性能，并探讨了将微分方程与深度学习相结合的前沿研究方向，为开发具有更好可解释性和泛化能力的智能计算方法提供新思路。


<details>
  <summary>Details</summary>
Motivation: 深度学习在多个领域取得显著进展，但理论理解、可解释性和泛化能力仍是挑战。采用微分方程视角为神经网络提供统一的理论框架和系统设计方法。

Method: 对受微分方程启发的深度神经网络架构和动态建模方法进行全面回顾，包括基于常微分方程（ODEs）的模型和确定性动力学网络，以及基于随机微分方程（SDEs）的正则化技术和随机动力学网络模型。通过数值比较来展示模型特性和性能。

Result: 提供了深度神经网络模型和动态建模方法的数值比较，说明了它们的特性和性能。

Conclusion: 将微分方程与深度学习相结合具有广阔的研究前景，有望开发出具有更好可解释性和泛化能力的智能计算方法。

Abstract: Deep learning has become a pivotal technology in fields such as computer
vision, scientific computing, and dynamical systems, significantly advancing
these disciplines. However, neural Networks persistently face challenges
related to theoretical understanding, interpretability, and generalization. To
address these issues, researchers are increasingly adopting a differential
equations perspective to propose a unified theoretical framework and systematic
design methodologies for neural networks. In this paper, we provide an
extensive review of deep neural network architectures and dynamic modeling
methods inspired by differential equations. We specifically examine deep neural
network models and deterministic dynamical network constructs based on ordinary
differential equations (ODEs), as well as regularization techniques and
stochastic dynamical network models informed by stochastic differential
equations (SDEs). We present numerical comparisons of these models to
illustrate their characteristics and performance. Finally, we explore promising
research directions in integrating differential equations with deep learning to
offer new insights for developing intelligent computational methods that boast
enhanced interpretability and generalization capabilities.

</details>


### [638] [Decomposer Networks: Deep Component Analysis and Synthesis](https://arxiv.org/abs/2510.09825)
*Mohsen Joneidi*

Main category: cs.LG

TL;DR: DecompNet是一种语义自编码器，通过N个并行分支将输入分解为多个可解释的分量，每个分支使用“除我之外的所有残差”更新规则，从而实现具有竞争性的、有意义的表示。


<details>
  <summary>Details</summary>
Motivation: 与传统的压缩输入到单一潜在表示的自编码器不同，DecompNet旨在将输入分解为多个可解释的分量。

Method: DecompNet采用N个并行分支，每个分支都分配一个残差输入，该输入定义为原始信号减去所有其他分支的重建。通过将高斯-赛德尔风格的块坐标下降展开为一个可微分网络，DecompNet强制组件之间进行显式竞争。

Result: DecompNet能够产生简约的、具有语义意义的表示，并与PCA、NMF、深度展开优化和面向对象的架构等方法进行了比较。

Conclusion: DecompNet是第一个实现“除我之外的所有残差”更新规则的语义自编码器，在分解和表示学习方面具有新颖性。

Abstract: We propose the Decomposer Networks (DecompNet), a semantic autoencoder that
factorizes an input into multiple interpretable components. Unlike classical
autoencoders that compress an input into a single latent representation, the
Decomposer Network maintains N parallel branches, each assigned a residual
input defined as the original signal minus the reconstructions of all other
branches. By unrolling a Gauss--Seidel style block-coordinate descent into a
differentiable network, DecompNet enforce explicit competition among
components, yielding parsimonious, semantically meaningful representations. We
situate our model relative to linear decomposition methods (PCA, NMF), deep
unrolled optimization, and object-centric architectures (MONet, IODINE, Slot
Attention), and highlight its novelty as the first semantic autoencoder to
implement an all-but-one residual update rule.

</details>


### [639] [Enhanced Urban Traffic Management Using CCTV Surveillance Videos and Multi-Source Data Current State Prediction and Frequent Episode Mining](https://arxiv.org/abs/2510.09644)
*Shaharyar Alam Ansari,Mohammad Luqman,Aasim Zafar,Savir Ali*

Main category: cs.LG

TL;DR: 该研究提出了一种融合视频监控和多源数据描述子的统一框架，用于实时城市交通预测，以解决城市快速发展带来的交通拥堵和环境压力问题。


<details>
  <summary>Details</summary>
Motivation: 城市快速发展导致交通拥堵、环境压力和运输效率低下，迫切需要智能和自适应的交通管理解决方案。传统的依赖静态信号和手动监控的系统无法应对现代交通的动态性。

Method: 该框架整合了视频监控、时空特征融合、频繁事件挖掘（用于顺序交通模式发现）以及混合LSTM-Transformer模型，以实现强大的交通状态预测。

Result: 在CityFlowV2数据集上，该框架实现了98.46%的高预测准确率，宏精确率为0.9800，宏召回率为0.9839，宏F1分数为0.9819。频繁事件挖掘分析显示，中度拥堵到拥堵的转换等顺序模式的置信度超过55%。系统自动生成了46个持续拥堵警报，显示了主动管理拥堵的实用价值。

Conclusion: 将视频流分析与多源数据相结合，对于设计实时、响应迅速、自适应的多层次智能交通系统至关重要，能够使城市交通更智能、更安全。

Abstract: Rapid urbanization has intensified traffic congestion, environmental strain,
and inefficiencies in transportation systems, creating an urgent need for
intelligent and adaptive traffic management solutions. Conventional systems
relying on static signals and manual monitoring are inadequate for the dynamic
nature of modern traffic. This research aims to develop a unified framework
that integrates CCTV surveillance videos with multi-source data descriptors to
enhance real-time urban traffic prediction. The proposed methodology
incorporates spatio-temporal feature fusion, Frequent Episode Mining for
sequential traffic pattern discovery, and a hybrid LSTM-Transformer model for
robust traffic state forecasting. The framework was evaluated on the CityFlowV2
dataset comprising 313,931 annotated bounding boxes across 46 cameras. It
achieved a high prediction accuracy of 98.46 percent, with a macro precision of
0.9800, macro recall of 0.9839, and macro F1-score of 0.9819. FEM analysis
revealed significant sequential patterns such as moderate-congested transitions
with confidence levels exceeding 55 percent. The 46 sustained congestion alerts
are system-generated, which shows practical value for proactive congestion
management. This emphasizes the need for the incorporation of video stream
analytics with data from multiple sources for the design of real-time,
responsive, adaptable multi-level intelligent transportation systems, which
makes urban mobility smarter and safer.

</details>


### [640] [A Unified Framework for Lifted Training and Inversion Approaches](https://arxiv.org/abs/2510.09796)
*Xiaoyu Wang,Alexandra Valavanis,Azhir Mahmood,Andreas Mang,Martin Benning,Audrey Repetti*

Main category: cs.LG

TL;DR: 本论文提出一个统一的框架，用于理解和实现各种提升训练方法，并将其应用于深度学习和逆问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的方法在训练深度神经网络时存在梯度消失/爆炸、非光滑激活函数困难以及并行化受限等问题。提升训练方法通过在高维空间中对约束进行惩罚来解决这些问题。

Method: 提出一个统一框架，整合了辅助坐标法、Fenchel提升网络和提升Bregman训练等方法，并展示了多层感知机、残差网络和近端网络等架构如何适应该框架。利用凸优化工具，特别是Bregman距离，来实现分布式优化，处理不可微的近端激活函数，并改善训练景观的条件。讨论了使用块坐标下降策略的实现，包括确定性实现（通过加速和自适应优化技术增强）和隐式随机梯度方法。此外，还探讨了该框架在逆问题中的应用，包括训练专门的网络（如展开架构）和稳定地反转预训练的网络。

Result: 在标准的成像任务上进行的数值结果表明，与传统的训练方法相比，提升Bregman方法在效率和稳定性方面都得到了验证，尤其是在采用近端激活函数的架构中。

Conclusion: 所提出的统一框架能够有效处理提升训练方法，为深度学习和逆问题的解决提供了更优的解决方案，特别是在处理近端激活函数方面表现出优越性。

Abstract: The training of deep neural networks predominantly relies on a combination of
gradient-based optimisation and back-propagation for the computation of the
gradient. While incredibly successful, this approach faces challenges such as
vanishing or exploding gradients, difficulties with non-smooth activations, and
an inherently sequential structure that limits parallelisation. Lifted training
methods offer an alternative by reformulating the nested optimisation problem
into a higher-dimensional, constrained optimisation problem where the
constraints are no longer enforced directly but penalised with penalty terms.
This chapter introduces a unified framework that encapsulates various lifted
training strategies, including the Method of Auxiliary Coordinates, Fenchel
Lifted Networks, and Lifted Bregman Training, and demonstrates how diverse
architectures, such as Multi-Layer Perceptrons, Residual Neural Networks, and
Proximal Neural Networks fit within this structure. By leveraging tools from
convex optimisation, particularly Bregman distances, the framework facilitates
distributed optimisation, accommodates non-differentiable proximal activations,
and can improve the conditioning of the training landscape. We discuss the
implementation of these methods using block-coordinate descent strategies,
including deterministic implementations enhanced by accelerated and adaptive
optimisation techniques, as well as implicit stochastic gradient methods.
Furthermore, we explore the application of this framework to inverse problems,
detailing methodologies for both the training of specialised networks (e.g.,
unrolled architectures) and the stable inversion of pre-trained networks.
Numerical results on standard imaging tasks validate the effectiveness and
stability of the lifted Bregman approach compared to conventional training,
particularly for architectures employing proximal activations.

</details>


### [641] [Emergence of hybrid computational dynamics through reinforcement learning](https://arxiv.org/abs/2510.11162)
*Roman A. Kononov,Nikita A. Pospelov,Konstantin V. Anokhin,Vladimir V. Nekorkin,Oleg V. Maslennikov*

Main category: cs.LG

TL;DR: Reinforcement learning (RL) leads to more complex and robust computational strategies in neural networks compared to supervised learning (SL), particularly for decision-making tasks. RL discovers hybrid attractor architectures and balanced neural populations, enhancing performance and robustness, while SL converges to simpler fixed-point solutions.


<details>
  <summary>Details</summary>
Motivation: Understanding how learning algorithms shape computational strategies in neural networks is crucial but underexplored, especially the role of the learning paradigm itself.

Method: Systematic dynamical systems analysis was used to compare recurrent neural networks (RNNs) trained on identical decision-making tasks using reinforcement learning (RL) and supervised learning (SL).

Result: RL trained RNNs developed hybrid attractor architectures (fixed-point and quasi-periodic) and functionally balanced neural populations, leading to enhanced robustness and performance, especially in complex tasks. SL trained RNNs primarily converged to fixed-point-only solutions with more heterogeneous populations.

Conclusion: The learning algorithm is a primary determinant of emergent computation. RL autonomously discovers sophisticated dynamical mechanisms (hybrid attractors, balanced populations) that improve robustness and performance, offering insights for designing adaptive AI systems.

Abstract: Understanding how learning algorithms shape the computational strategies that
emerge in neural networks remains a fundamental challenge in machine
intelligence. While network architectures receive extensive attention, the role
of the learning paradigm itself in determining emergent dynamics remains
largely unexplored. Here we demonstrate that reinforcement learning (RL) and
supervised learning (SL) drive recurrent neural networks (RNNs) toward
fundamentally different computational solutions when trained on identical
decision-making tasks. Through systematic dynamical systems analysis, we reveal
that RL spontaneously discovers hybrid attractor architectures, combining
stable fixed-point attractors for decision maintenance with quasi-periodic
attractors for flexible evidence integration. This contrasts sharply with SL,
which converges almost exclusively to simpler fixed-point-only solutions. We
further show that RL sculpts functionally balanced neural populations through a
powerful form of implicit regularization -- a structural signature that
enhances robustness and is conspicuously absent in the more heterogeneous
solutions found by SL-trained networks. The prevalence of these complex
dynamics in RL is controllably modulated by weight initialization and
correlates strongly with performance gains, particularly as task complexity
increases. Our results establish the learning algorithm as a primary
determinant of emergent computation, revealing how reward-based optimization
autonomously discovers sophisticated dynamical mechanisms that are less
accessible to direct gradient-based optimization. These findings provide both
mechanistic insights into neural computation and actionable principles for
designing adaptive AI systems.

</details>


### [642] [Gradient-Sign Masking for Task Vector Transport Across Pre-Trained Models](https://arxiv.org/abs/2510.09658)
*Filippo Rinaldi,Aniello Panariello,Giacomo Salici,Fengyuan Liu,Marco Ciccone,Angelo Porrello,Simone Calderara*

Main category: cs.LG

TL;DR: 新的基础模型发布时，通常需要对同一任务进行完全重新微调。本文提出GradFix方法，通过匹配新旧模型梯度符号结构，利用少量标签样本实现跨模型任务向量的迁移，无需额外微调，并具有理论和实验保证。


<details>
  <summary>Details</summary>
Motivation: 当基础模型发布新版本时，通常需要对同一任务进行完全的重新微调，即使之前的版本已经解决了该任务。一种有前景的替代方法是复用参数（即任务向量），但它们往往由于参数空间不对齐而无法在不同预训练模型之间迁移。

Method: 提出GradFix方法，该方法通过计算目标模型的少量梯度来近似理想的梯度符号结构，并利用该结构来迁移知识，仅需少量标记样本。此方法无需额外的微调，通过计算目标模型的少量梯度并相应地掩码源任务向量来实现适应性调整，从而使更新在局部上与目标损失景观对齐，有效地将任务向量重新定位到新的预训练上。理论上保证了该方法确保了一阶下降。

Result: 在视觉和语言基准测试中，GradFix在性能上取得了显著的提升，持续优于朴素的任务向量加法和少样本微调。

Conclusion: GradFix通过匹配梯度符号结构，实现了任务向量在不同预训练模型之间的有效迁移，无需额外微调，并在多个基准测试中取得了优于现有方法的性能。

Abstract: When a new release of a foundation model is published, practitioners
typically need to repeat full fine-tuning, even if the same task has already
been solved in the previous version. A promising alternative is to reuse the
parameter changes (i.e., task vectors) that capture how a model adapts to a
specific task. However, they often fail to transfer across different
pre-trained models due to their misaligned parameter space. In this work, we
show that the key to successful transfer lies in the sign structure of the
gradients of the new model. Based on this insight, we propose GradFix, a novel
method that approximates the ideal gradient sign structure and leverages it to
transfer knowledge using only a handful of labeled samples. Notably, this
requires no additional fine-tuning: the adaptation is achieved by computing a
few gradients at the target model and masking the source task vector
accordingly. This yields an update that is locally aligned with the target loss
landscape, effectively rebasing the task vector onto the new pre-training. We
provide a theoretical guarantee that our method ensures first-order descent.
Empirically, we demonstrate significant performance gains on vision and
language benchmarks, consistently outperforming naive task vector addition and
few-shot fine-tuning.

</details>


### [643] [Heterogeneous Point Set Transformers for Segmentation of Multiple View Particle Detectors](https://arxiv.org/abs/2510.09659)
*Edgar E. Robles,Dikshant Sagar,Alejandro Yankelevich,Jianming Bian,Pierre Baldi,NOvA Collaboration*

Main category: cs.LG

TL;DR: NOvA实验提出了一种新的点集神经网络，用于处理稀疏的2D图像数据，以识别中微子粒子类型，该模型内存占用少，准确率高。


<details>
  <summary>Details</summary>
Motivation: NOvA实验需要将探测器原始数据（由X-Z和Y-Z两幅稀疏2D图像表示）中的hit与源粒子匹配并识别粒子类型，以用于后续分析。

Method: 提出了一种点集神经网络，该网络直接在稀疏矩阵上操作，并结合了两种视图（X-Z和Y-Z）的信息。该模型相比于以往的方法（如聚类和CNN）内存占用更少。

Result: 该模型实现了96.8%的AUC得分，优于独立处理两个视图（85.4%）的得分，并且内存占用仅为先前方法的10%。

Conclusion: 所提出的点集神经网络在NOvA实验数据处理中是一种更有效率且性能更优的方法，能够更好地融合多视图信息以提高粒子识别的准确性。

Abstract: NOvA is a long-baseline neutrino oscillation experiment that detects neutrino
particles from the NuMI beam at Fermilab. Before data from this experiment can
be used in analyses, raw hits in the detector must be matched to their source
particles, and the type of each particle must be identified. This task has
commonly been done using a mix of traditional clustering approaches and
convolutional neural networks (CNNs). Due to the construction of the detector,
the data is presented as two sparse 2D images: an XZ and a YZ view of the
detector, rather than a 3D representation. We propose a point set neural
network that operates on the sparse matrices with an operation that mixes
information from both views. Our model uses less than 10% of the memory
required using previous methods while achieving a 96.8% AUC score, a higher
score than obtained when both views are processed independently (85.4%).

</details>


### [644] [Population synthesis with geographic coordinates](https://arxiv.org/abs/2510.09669)
*Jacopo Lenti,Lorenzo Costantini,Ariadna Fosch,Anna Monticelli,David Scala,Marco Pangallo*

Main category: cs.LG

TL;DR: 提出一种新颖的NF+VAE算法，用于生成具有精确坐标的合成人口，优于现有基准。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以生成具有精确坐标的合成人口，因为坐标数据分布不均。本研究旨在解决此问题。

Method: 提出一种结合了正态流（NF）和变分自编码器（VAE）的算法。首先，NF将空间坐标映射到一个更规则的潜在空间，然后VAE将潜在空间特征与非空间特征结合，生成合成人口。该方法还能学习空间和非空间特征的联合分布，并利用空间自相关性。

Result: 在121个真实数据集上生成了具有相同统计特性的合成房屋，并在空间准确性和实际效用方面进行了评估，同时确保了隐私保护。结果表明，NF+VAE架构优于基于Copula的方法和地理区域内的均匀分配方法。

Conclusion: NF+VAE架构能够生成具有精细空间分辨率的地理定位合成人口，为需要详细地理信息的应用（如洪水响应、流行病传播、疏散规划和交通建模）提供了新的可能性。

Abstract: It is increasingly important to generate synthetic populations with explicit
coordinates rather than coarse geographic areas, yet no established methods
exist to achieve this. One reason is that latitude and longitude differ from
other continuous variables, exhibiting large empty spaces and highly uneven
densities. To address this, we propose a population synthesis algorithm that
first maps spatial coordinates into a more regular latent space using
Normalizing Flows (NF), and then combines them with other features in a
Variational Autoencoder (VAE) to generate synthetic populations. This approach
also learns the joint distribution between spatial and non-spatial features,
exploiting spatial autocorrelations. We demonstrate the method by generating
synthetic homes with the same statistical properties of real homes in 121
datasets, corresponding to diverse geographies. We further propose an
evaluation framework that measures both spatial accuracy and practical utility,
while ensuring privacy preservation. Our results show that the NF+VAE
architecture outperforms popular benchmarks, including copula-based methods and
uniform allocation within geographic areas. The ability to generate geolocated
synthetic populations at fine spatial resolution opens the door to applications
requiring detailed geography, from household responses to floods, to epidemic
spread, evacuation planning, and transport modeling.

</details>


### [645] [Learning What Matters: Steering Diffusion via Spectrally Anisotropic Forward Noise](https://arxiv.org/abs/2510.09660)
*Luca Scimeca,Thomas Jiralerspong,Berton Earnshaw,Jason Hartford,Yoshua Bengio*

Main category: cs.LG

TL;DR: 引入谱向异性高斯扩散 (SAGD) 以在扩散模型中明确构建归纳偏置，通过各向异性噪声算子调整频率响应，在图像生成任务中表现优于标准扩散模型，并实现了选择性遗漏能力。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型（DPMs）虽然生成性能强大，但其归纳偏置很大程度上是隐式的。本研究旨在将归纳偏置显式地构建到扩散模型的训练和采样过程中，以更好地适应需要建模的数据分布。

Method: 提出了一种谱向异性高斯扩散 (SAGD) 方法，该方法使用各向异性噪声算子，用结构化的、频率对角的协方差替换各向同性的前向协方差。这种算子统一了带通掩码和幂律加权，允许在保持前向过程高斯性的同时，强调或抑制指定的频率带。推导了各向异性协方差的得分关系，并表明在全支撑下，学习到的得分在t→0时收敛于真实数据得分，同时各向异性会重塑从噪声到数据的概率流路径。

Result: 经验证，SAGD 在多个视觉数据集上的表现优于标准扩散，并且能够实现选择性遗漏，即在学习的同时忽略特定频带内已知的噪声。

Conclusion: 精心设计的各向异性前向噪声为调整 DPMs 中的归纳偏置提供了一种简单而有原则的方法。

Abstract: Diffusion Probabilistic Models (DPMs) have achieved strong generative
performance, yet their inductive biases remain largely implicit. In this work,
we aim to build inductive biases into the training and sampling of diffusion
models to better accommodate the target distribution of the data to model. We
introduce an anisotropic noise operator that shapes these biases by replacing
the isotropic forward covariance with a structured, frequency-diagonal
covariance. This operator unifies band-pass masks and power-law weightings,
allowing us to emphasize or suppress designated frequency bands, while keeping
the forward process Gaussian. We refer to this as spectrally anisotropic
Gaussian diffusion (SAGD). In this work, we derive the score relation for
anisotropic covariances and show that, under full support, the learned score
converges to the true data score as $t\!\to\!0$, while anisotropy reshapes the
probability-flow path from noise to data. Empirically, we show the induced
anisotropy outperforms standard diffusion across several vision datasets, and
enables selective omission: learning while ignoring known corruptions confined
to specific bands. Together, these results demonstrate that carefully designed
anisotropic forward noise provides a simple, yet principled, handle to tailor
inductive bias in DPMs.

</details>


### [646] [A Joint Learning Approach to Hardware Caching and Prefetching](https://arxiv.org/abs/2510.10862)
*Samuel Yuan,Divyanshu Saxena,Jiayi Chen,Nihal Sharma,Aditya Akella*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Several learned policies have been proposed to replace heuristics for
scheduling, caching, and other system components in modern systems. By
leveraging diverse features, learning from historical trends, and predicting
future behaviors, such models promise to keep pace with ever-increasing
workload dynamism and continuous hardware evolution. However, policies trained
in isolation may still achieve suboptimal performance when placed together. In
this paper, we inspect one such instance in the domain of hardware caching --
for the policies of cache replacement and prefetching. We argue that these two
policies are bidirectionally interdependent and make the case for training the
two jointly. We propose a joint learning approach based on developing shared
representations for the features used by the two policies. We present two
approaches to develop these shared representations, one based on a joint
encoder and another based on contrastive learning of the embeddings, and
demonstrate promising preliminary results for both of these. Finally, we lay
down an agenda for future research in this direction.

</details>


### [647] [Preference-driven Knowledge Distillation for Few-shot Node Classification](https://arxiv.org/abs/2510.10116)
*Xing Wei,Chunchun Chen,Rui Fan,Xiaofeng Cao,Sourav Medya,Wei Ye*

Main category: cs.LG

TL;DR: 该研究提出了一种偏好驱动的知识蒸馏（PKD）框架，结合了LLMs和GNNs的优点，用于少样本节点分类任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决图神经网络（GNNs）在训练中对人类标注标签的依赖以及单一GNN难以处理真实世界图谱中复杂多样的节点拓扑结构的问题，并克服大型语言模型（LLMs）在文本属性图（TAGs）上进行零/少样本学习时面临的可扩展性挑战。

Method: 提出了一种偏好驱动的知识蒸馏（PKD）框架。该框架包含一个GNN偏好驱动的节点选择器，用于将LLMs的预测知识蒸馏到GNN教师模型；以及一个节点偏好驱动的GNN选择器，为每个节点选择最合适的GNN教师模型，实现定制化的知识蒸馏。

Result: 通过大量实验验证了所提出的PKD框架在真实世界TAGs上的少样本节点分类任务中的有效性。

Conclusion: PKD框架能够有效地结合LLMs和GNNs的优势，克服各自的局限性，在少样本节点分类任务上取得良好效果。

Abstract: Graph neural networks (GNNs) can efficiently process text-attributed graphs
(TAGs) due to their message-passing mechanisms, but their training heavily
relies on the human-annotated labels. Moreover, the complex and diverse local
topologies of nodes of real-world TAGs make it challenging for a single
mechanism to handle. Large language models (LLMs) perform well in
zero-/few-shot learning on TAGs but suffer from a scalability challenge.
Therefore, we propose a preference-driven knowledge distillation (PKD)
framework to synergize the complementary strengths of LLMs and various GNNs for
few-shot node classification. Specifically, we develop a GNN-preference-driven
node selector that effectively promotes prediction distillation from LLMs to
teacher GNNs. To further tackle nodes' intricate local topologies, we develop a
node-preference-driven GNN selector that identifies the most suitable teacher
GNN for each node, thereby facilitating tailored knowledge distillation from
teacher GNNs to the student GNN. Extensive experiments validate the efficacy of
our proposed framework in few-shot node classification on real-world TAGs.

</details>


### [648] [Assessment of different loss functions for fitting equivalent circuit models to electrochemical impedance spectroscopy data](https://arxiv.org/abs/2510.09662)
*Ali Jaberi,Amin Sadeghi,Runze Zhang,Zhaoyang Zhao,Qiuyu Shi,Robert Black,Zoya Sadighi,Jason Hattrick-Simpers*

Main category: cs.LG

TL;DR: 该研究提出了两种新的EIS数据拟合损失函数log-B和log-BW，并与现有损失函数进行了性能比较，发现在拟合精度和计算效率方面，X2损失函数和log-B损失函数各有优势，可根据具体需求选择。


<details>
  <summary>Details</summary>
Motivation: 传统的EIS数据ECM拟合方法使用非线性最小二乘法，但损失函数的选择会影响拟合结果的质量和效率。

Method: 提出了log-B和log-BW两种新的损失函数，并使用生成的大量EIS数据，在R2分数、卡方值、计算效率和MAPE等指标上，将新损失函数与现有损失函数进行了性能评估和统计比较。

Result: X2损失函数在多项拟合质量指标上表现最佳，是追求最佳拟合质量时的首选。log-B损失函数在保证稍低的拟合质量的同时，计算速度提高了约1.4倍，且在大多数电路元件上具有更低的MAPE，是数据驱动应用中大规模拟合的有力替代方案。

Conclusion: 损失函数的选择对ECM拟合的收敛性、计算效率、拟合质量和MAPE有显著影响。X2损失函数和log-B损失函数在拟合精度和计算效率方面各有优劣，可根据具体应用场景（如追求最高拟合精度或需要大规模快速迭代）进行选择。

Abstract: Electrochemical impedance spectroscopy (EIS) data is typically modeled using
an equivalent circuit model (ECM), with parameters obtained by minimizing a
loss function via nonlinear least squares fitting. This paper introduces two
new loss functions, log-B and log-BW, derived from the Bode representation of
EIS. Using a large dataset of generated EIS data, the performance of proposed
loss functions was evaluated alongside existing ones in terms of R2 scores,
chi-squared, computational efficiency, and the mean absolute percentage error
(MAPE) between the predicted component values and the original values.
Statistical comparisons revealed that the choice of loss function impacts
convergence, computational efficiency, quality of fit, and MAPE. Our analysis
showed that X2 loss function (squared sum of residuals with proportional
weighting) achieved the highest performance across multiple quality of fit
metrics, making it the preferred choice when the quality of fit is the primary
goal. On the other hand, log-B offered a slightly lower quality of fit while
being approximately 1.4 times faster and producing lower MAPE for most circuit
components, making log-B as a strong alternative. This is a critical factor for
large-scale least squares fitting in data-driven applications, such as training
machine learning models on extensive datasets or iterations.

</details>


### [649] [HeroFilter: Adaptive Spectral Graph Filter for Varying Heterophilic Relations](https://arxiv.org/abs/2510.10864)
*Shuaicheng Zhang,Haohui Wang,Junhong Lin,Xiaojie Guo,Yada Zhu,Si Zhang,Dongqi Fu,Dawei Zhou*

Main category: cs.LG

TL;DR: Graph heterophily analysis shows optimal filters are complex and vary with frequency, challenging fixed filter designs and motivating adaptive filtering in GNNs. The proposed method achieves significant accuracy improvements.


<details>
  <summary>Details</summary>
Motivation: Existing works oversimplify the relationship between graph heterophily and spectral filters. This paper aims to explore the complex relationship and design adaptive filters for GNNs to handle varying heterophilic connections.

Method: Proposes a GNN method that extracts information across the heterophily spectrum and combines representations through adaptive mixing.

Result: Achieves up to 9.2% accuracy improvement over leading baselines on both homophilic and heterophilic graphs.

Conclusion: Adaptive graph filters are necessary for good generalization performance in GNNs due to the complex relationship between graph heterophily and filter responses. The proposed method effectively addresses this by adaptively mixing salient representations across the heterophily spectrum.

Abstract: Graph heterophily, where connected nodes have different labels, has attracted
significant interest recently. Most existing works adopt a simplified approach
- using low-pass filters for homophilic graphs and high-pass filters for
heterophilic graphs. However, we discover that the relationship between graph
heterophily and spectral filters is more complex - the optimal filter response
varies across frequency components and does not follow a strict monotonic
correlation with heterophily degree. This finding challenges conventional fixed
filter designs and suggests the need for adaptive filtering to preserve
expressiveness in graph embeddings. Formally, natural questions arise: Given a
heterophilic graph G, how and to what extent will the varying heterophily
degree of G affect the performance of GNNs? How can we design adaptive filters
to fit those varying heterophilic connections? Our theoretical analysis reveals
that the average frequency response of GNNs and graph heterophily degree do not
follow a strict monotonic correlation, necessitating adaptive graph filters to
guarantee good generalization performance. Hence, we propose [METHOD NAME], a
simple yet powerful GNN, which extracts information across the heterophily
spectrum and combines salient representations through adaptive mixing. [METHOD
NAME]'s superior performance achieves up to 9.2% accuracy improvement over
leading baselines across homophilic and heterophilic graphs.

</details>


### [650] [Semantic-Cohesive Knowledge Distillation for Deep Cross-modal Hashing](https://arxiv.org/abs/2510.09664)
*Changchang Sun,Vickie Chen,Yan Yan*

Main category: cs.LG

TL;DR: 该研究提出了一种新的深度跨模态哈希方法SODA，通过引入多标签信息作为文本模态并结合知识蒸馏，解决了现有方法在多标签语义提取与原始多模态数据交互不足的问题，提高了跨模态语义表示的兼容性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度监督跨模态哈希方法在多标签语义提取时未能显式地与原始多模态数据交互，导致学习到的表示在语义层面与异构多模态数据不兼容，限制了弥合模态间差距的性能。

Method: 提出了一种新颖的语义内聚知识蒸馏方案（SODA）。将多标签信息作为一种新的文本模态，并将其重构为一组真实标签提示。设计了一个跨模态教师网络，以有效蒸馏图像和标签模态之间的跨模态语义特征，从而学习一个映射到汉明空间的图像表示。该汉明空间作为先验知识，指导跨模态学生网络的学习，并全面保留图像和文本模态之间的语义相似性。

Result: 在两个基准数据集上的大量实验证明，该模型优于现有最先进的方法。

Conclusion: 所提出的SODA方法通过显式地交互多标签语义信息和原始多模态数据，并利用知识蒸馏来弥合模态间差距，有效提高了深度跨模态哈希的性能。

Abstract: Recently, deep supervised cross-modal hashing methods have achieve compelling
success by learning semantic information in a self-supervised way. However,
they still suffer from the key limitation that the multi-label semantic
extraction process fail to explicitly interact with raw multimodal data, making
the learned representation-level semantic information not compatible with the
heterogeneous multimodal data and hindering the performance of bridging
modality gap. To address this limitation, in this paper, we propose a novel
semantic cohesive knowledge distillation scheme for deep cross-modal hashing,
dubbed as SODA. Specifically, the multi-label information is introduced as a
new textual modality and reformulated as a set of ground-truth label prompt,
depicting the semantics presented in the image like the text modality. Then, a
cross-modal teacher network is devised to effectively distill cross-modal
semantic characteristics between image and label modalities and thus learn a
well-mapped Hamming space for image modality. In a sense, such Hamming space
can be regarded as a kind of prior knowledge to guide the learning of
cross-modal student network and comprehensively preserve the semantic
similarities between image and text modality. Extensive experiments on two
benchmark datasets demonstrate the superiority of our model over the
state-of-the-art methods.

</details>


### [651] [Rescaling-Aware Training for Efficient Deployment of Deep Learning Models on Full-Integer Hardware](https://arxiv.org/abs/2510.11484)
*Lion Mueller,Alberto Garcia-Ortiz,Ardalan Najafi,Adam Fuks,Lennart Bamberg*

Main category: cs.LG

TL;DR: 通过在推断时应用更强的量化方法来降低整数AI推断中的重缩放成本，并引入重缩放感知训练来微调超低比特重缩放乘数，从而在不损失模型质量的情况下提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练（QAT）方法在量化AI推断时会忽略整数重缩放的影响，而重缩放操作在硬件上成本高昂，尤其是在仅使用整数的AI推断中。现有方法未解决此问题。

Method: 提出一种后训练量化方法，通过对重缩放乘数应用更强的量化来显著降低重缩放成本，且不损失模型质量。进一步提出重缩放感知训练（Rescale-Aware Training），一种用于微调超低比特重缩放乘数的方法。

Result: 即使在重缩放器宽度减少8倍的情况下，通过最小化的增量再训练也能保留完整的准确性。

Conclusion: 该方法能够显著降低AI推断中的重缩放成本，并能为资源受限的嵌入式系统实现更节能、更低成本的AI推断。

Abstract: Integer AI inference significantly reduces computational complexity in
embedded systems. Quantization-aware training (QAT) helps mitigate accuracy
degradation associated with post-training quantization but still overlooks the
impact of integer rescaling during inference, which is a hardware costly
operation in integer-only AI inference. This work shows that rescaling cost can
be dramatically reduced post-training, by applying a stronger quantization to
the rescale multiplicands at no model-quality loss. Furthermore, we introduce
Rescale-Aware Training, a fine tuning method for ultra-low bit-width rescaling
multiplicands. Experiments show that even with 8x reduced rescaler widths, the
full accuracy is preserved through minimal incremental retraining. This enables
more energy-efficient and cost-efficient AI inference for resource-constrained
embedded systems.

</details>


### [652] [LMCache: An Efficient KV Cache Layer for Enterprise-Scale LLM Inference](https://arxiv.org/abs/2510.09665)
*Yihua Cheng,Yuhan Liu,Jiayi Yao,Yuwei An,Xiaokun Chen,Shaoting Feng,Yuyang Huang,Samuel Shen,Kuntai Du,Junchen Jiang*

Main category: cs.LG

TL;DR: LMCache是一个高效的KV缓存解决方案，通过在LLM推理引擎之间共享KV缓存来提高吞吐量，并支持跨查询和跨引擎的缓存重用与传输。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM推理系统将引擎和查询视为独立个体，导致显著的资源低效。为了提高效率，需要一种能够跨LLM推理引擎和查询有效卸载和通信KV缓存的解决方案。

Method: LMCache通过提取、存储和共享KV缓存来连接不同的LLM引擎。它支持缓存卸载（跨查询的前缀重用）和预填充-解码分离（跨引擎缓存传输）。LMCache通过优化的数据移动、计算和I/O流水线、模块化连接器以及一套控制API来实现高性能，支持在GPU、CPU、存储和网络层进行灵活的缓存编排。

Result: 将LMCache与vLLM结合使用，在各种工作负载下可实现高达15倍的吞吐量提升。LMCache已被企业推理系统广泛采用。

Conclusion: LMCache是第一个也是最高效的开源KV缓存解决方案，它通过共享KV缓存显著提高了LLM推理的效率和吞吐量，为未来的KV缓存解决方案提供了宝贵的经验。

Abstract: Today's LLM inference systems treat individual engines and queries
independently for simplicity, but this causes significant resource
inefficiencies. While there are proposals to avoid redundant computation by
reusing KV caches across queries and to increase GPU utilization by
disaggregating a single query to different engines, their promises cannot be
realized without efficiently offloading and communicating KV cache across LLM
inference engines and queries.
  We present LMCache, the first and so far the most efficient open-source KV
caching solution, which extracts and stores KV caches generated by modern LLM
engines (vLLM and SGLang) and shares the KV caches across engines and queries.
LMCache exposes KV caches in the LLM engine interface, effectively transforming
LLM engines from individual token processors to a collection of engines with KV
cache as the storage and communication medium. In particular, it supports both
cache offloading (prefix reuse across queries) and prefill-decode
disaggregation (cross-engine cache transfer). LMCache's high performance and
wide adoption stem from the following contributions: highly optimized KV cache
data movement with performance optimizations including batched data movement
operations, compute and I/O pipelining; a modular KV cache connector component,
decoupling LMCache from the rapid evolution of inference engines; a first-class
control API, such as pinning, lookup, cleanup, movement, and compression, for
flexible cache orchestration across GPU, CPU, storage, and network layers.
Evaluation shows that combining LMCache with vLLM achieves up to 15x
improvement in throughput across diverse workloads. With a growing community,
LMCache has seen dramatic growth in adoption by enterprise inference systems,
which provides valuable lessons for future KV caching solutions. The source
code of LMCache is at: https://github.com/LMCache/LMCache.

</details>


### [653] [Spatial Uncertainty Quantification in Wildfire Forecasting for Climate-Resilient Emergency Planning](https://arxiv.org/abs/2510.09666)
*Aditya Chakravarty*

Main category: cs.LG

TL;DR: 本研究首次系统性地分析了使用多模态地球观测输入进行火灾蔓延预测的空间不确定性，发现不确定性集中在火灾边缘附近，形成可用于应急规划的缓冲带。


<details>
  <summary>Details</summary>
Motivation: 气候变化加剧了全球火灾风险，需要可靠的预测来制定适应策略。现有的机器学习方法缺乏不确定性量化，阻碍了风险决策。

Method: 通过多模态地球观测数据，系统性地分析了火灾蔓延预测中的空间不确定性，并提出了一种新的距离度量方法来识别高不确定性区域，同时利用特征归因识别不确定性的驱动因素。

Result: 预测不确定性呈现出与火灾边缘一致的空间结构，形成 20-60 米的缓冲带。植被健康和火灾活动是主要的学习不确定性驱动因素。

Conclusion: 这项工作通过量化和识别火灾蔓延预测中的空间不确定性，为更稳健的火灾管理系统奠定了基础，有助于社区适应气候变化带来的日益增长的火灾风险。

Abstract: Climate change is intensifying wildfire risks globally, making reliable
forecasting critical for adaptation strategies. While machine learning shows
promise for wildfire prediction from Earth observation data, current approaches
lack uncertainty quantification essential for risk-aware decision making. We
present the first systematic analysis of spatial uncertainty in wildfire spread
forecasting using multimodal Earth observation inputs. We demonstrate that
predictive uncertainty exhibits coherent spatial structure concentrated near
fire perimeters. Our novel distance metric reveals high-uncertainty regions
form consistent 20-60 meter buffer zones around predicted firelines - directly
applicable for emergency planning. Feature attribution identifies vegetation
health and fire activity as primary uncertainty drivers. This work enables more
robust wildfire management systems supporting communities adapting to
increasing fire risk under climate change.

</details>


### [654] [A Hybrid Computational Intelligence Framework with Metaheuristic Optimization for Drug-Drug Interaction Prediction](https://arxiv.org/abs/2510.09668)
*Maryam Abdollahi Shamami,Babak Teimourpour,Farshad Sharifi*

Main category: cs.LG

TL;DR: 该研究提出了一个结合了Mol2Vec、SMILES-BERT和基于规则的临床评分（RBScore）的框架，并使用一种新的三阶段元启发式策略（RSmpl-ACO-PSO）进行优化，以提高药物-药物相互作用（DDI）预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 预测药物-药物相互作用（DDI）对于避免不良事件、降低医疗成本和改善患者治疗至关重要，了解哪些药物不相互作用同样重要。

Method: 提出一个框架，结合分子嵌入（Mol2Vec和SMILES-BERT）和基于规则的临床评分（RBScore），并使用三阶段元启发式策略（RSmpl-ACO-PSO）训练的轻量级神经网络进行DDI预测。

Result: 在DrugBank数据集上实现了高预测准确性（ROC-AUC 0.911，PR-AUC 0.867），并在II型糖尿病患者队列中表现出良好的泛化能力。研究还揭示了嵌入融合、RBScore和优化器对模型性能的贡献。

Conclusion: 该研究提供了一种构建可靠、可解释且计算高效的模型的方法，以支持更安全的药物治疗和临床决策。

Abstract: Drug-drug interactions (DDIs) are a leading cause of preventable adverse
events, often complicating treatment and increasing healthcare costs. At the
same time, knowing which drugs do not interact is equally important, as such
knowledge supports safer prescriptions and better patient outcomes. In this
study, we propose an interpretable and efficient framework that blends modern
machine learning with domain knowledge to improve DDI prediction. Our approach
combines two complementary molecular embeddings - Mol2Vec, which captures
fragment-level structural patterns, and SMILES-BERT, which learns contextual
chemical features - together with a leakage-free, rule-based clinical score
(RBScore) that injects pharmacological knowledge without relying on interaction
labels. A lightweight neural classifier is then optimized using a novel
three-stage metaheuristic strategy (RSmpl-ACO-PSO), which balances global
exploration and local refinement for stable performance. Experiments on
real-world datasets demonstrate that the model achieves high predictive
accuracy (ROC-AUC 0.911, PR-AUC 0.867 on DrugBank) and generalizes well to a
clinically relevant Type 2 Diabetes Mellitus cohort. Beyond raw performance,
studies show how embedding fusion, RBScore, and the optimizer each contribute
to precision and robustness. Together, these results highlight a practical
pathway for building reliable, interpretable, and computationally efficient
models that can support safer drug therapies and clinical decision-making.

</details>


### [655] [Tight Regret Upper and Lower Bounds for Optimistic Hedge in Two-Player Zero-Sum Games](https://arxiv.org/abs/2510.11691)
*Taira Tsuchiya*

Main category: cs.LG

TL;DR: 本研究改进了乐观对冲算法在两人零和博弈中的学习动态


<details>
  <summary>Details</summary>
Motivation: 研究乐观对冲算法在两人零和博弈中学习动态的后悔上界是否最优，特别是对博弈方行动数量m和n的依赖性。

Method: 通过优化学习率和负项系数，改进了后悔上界分析，得到了O(sqrt(log m log n))的社会和个体后悔界限，并提供了算法相关的个体后悔下界来证明上界的不可改进性。此外，还改进了基于乐观对冲的算法的最后迭代收敛速度和动态后悔界限，并提供了匹配的动态后悔下界。

Result: 在强分离博弈中，将社会和个体后悔界限从O(log(mn))改进为O(sqrt(log m log n))。证明了现有及新的社会后悔上界和个体后悔上界均不可进一步改进。社会后悔上界和下界（包括常数因子）匹配。改进了最后迭代收敛速度和动态后悔界限，并提供了匹配的动态后悔下界。

Conclusion: 乐观对冲算法在两人零和博弈中的学习动态，特别是其后悔界限，具有可改进的空间。本研究通过改进分析方法和提供下界，得出了更优的界限，并证明了这些界限的最优性。

Abstract: In two-player zero-sum games, the learning dynamic based on optimistic Hedge
achieves one of the best-known regret upper bounds among strongly-uncoupled
learning dynamics. With an appropriately chosen learning rate, the social and
individual regrets can be bounded by $O(\log(mn))$ in terms of the numbers of
actions $m$ and $n$ of the two players. This study investigates the optimality
of the dependence on $m$ and $n$ in the regret of optimistic Hedge. To this
end, we begin by refining existing regret analysis and show that, in the
strongly-uncoupled setting where the opponent's number of actions is known,
both the social and individual regret bounds can be improved to $O(\sqrt{\log m
\log n})$. In this analysis, we express the regret upper bound as an
optimization problem with respect to the learning rates and the coefficients of
certain negative terms, enabling refined analysis of the leading constants. We
then show that the existing social regret bound as well as these new social and
individual regret upper bounds cannot be further improved for optimistic Hedge
by providing algorithm-dependent individual regret lower bounds. Importantly,
these social regret upper and lower bounds match exactly including the constant
factor in the leading term. Finally, building on these results, we improve the
last-iterate convergence rate and the dynamic regret of a learning dynamic
based on optimistic Hedge, and complement these bounds with algorithm-dependent
dynamic regret lower bounds that match the improved bounds.

</details>


### [656] [Multitask Learning with Learned Task Relationships](https://arxiv.org/abs/2510.10570)
*Zirui Wan,Stefan Vlaski*

Main category: cs.LG

TL;DR: 传统的联邦和去中心化学习策略在数据异构性方面存在统计上的不足。本文提出了一种新的算法框架，通过学习任务关系（使用高斯马尔可夫随机场和未知的精度矩阵）和本地模型来解决这个问题，允许代理根据其数据分布进行自我组织。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦和去中心化学习策略在数据异构性方面存在不足，本文旨在提出一种新的算法框架来解决这个问题。

Method: 通过对任务关系进行建模（使用具有未知精度矩阵的高斯马尔可夫随机场），联合学习任务关系和本地模型。

Result: 理论分析量化了学习到的任务关系的质量，数值实验证明了该方法的有效性。

Conclusion: 本文提出的算法框架在学习任务关系和本地模型方面取得了平衡，并且在实践中是有效的。

Abstract: Classical consensus-based strategies for federated and decentralized learning
are statistically suboptimal in the presence of heterogeneous local data or
task distributions. As a result, in recent years, there has been growing
interest in multitask or personalized strategies, which allow individual agents
to benefit from one another in pursuing locally optimal models without
enforcing consensus. Existing strategies require either precise prior knowledge
of the underlying task relationships or are fully non-parametric and instead
rely on meta-learning or proximal constructions. In this work, we introduce an
algorithmic framework that strikes a balance between these extremes. By
modeling task relationships through a Gaussian Markov Random Field with an
unknown precision matrix, we develop a strategy that jointly learns both the
task relationships and the local models, allowing agents to self-organize in a
way consistent with their individual data distributions. Our theoretical
analysis quantifies the quality of the learned relationship, and our numerical
experiments demonstrate its practical effectiveness.

</details>


### [657] [A physics-aware deep learning model for shear band formation around collapsing pores in shocked reactive materials](https://arxiv.org/abs/2510.09670)
*Xinlun Cheng,Bingzhe Chen,Joseph Choi,Yen T. Nguyen,Pradeep Seshadri,Mayank Verma,H. S. Udaykumar,Stephen Baek*

Main category: cs.LG

TL;DR: 该研究提出了改进的PARCv2模型，以模拟弱-中等冲击载荷下含能材料的塑性加热和剪切带形成，并与现有模型进行了比较。


<details>
  <summary>Details</summary>
Motivation: 研究弱-中等冲击载荷下含能材料的本征形成机制，这对于含能材料的安全储存和处理至关重要，但目前研究不足。

Method: 改进了PARCv2的架构，使其能够快速预测弱-中等冲击载荷下的剪切带和塑性加热。将改进后的PARCv2模型与傅里叶神经算子和神经常微分方程模型进行了基准测试。

Result: 改进后的PARCv2模型在捕捉剪切带形成的时空动力学方面表现出优越性能，尽管所有模型都存在一定的失效模式。

Conclusion: 在开发用于反应材料的AI加速模拟工具时，领域特定的考量至关重要，以确保模型的鲁棒性。

Abstract: Modeling shock-to-detonation phenomena in energetic materials (EMs) requires
capturing complex physical processes such as strong shocks, rapid changes in
microstructural morphology, and nonlinear dynamics of chemical reaction fronts.
These processes participate in energy localization at hotspots, which initiate
chemical energy release leading to detonation. This study addresses the
formation of hotspots in crystalline EMs subjected to weak-to-moderate shock
loading, which, despite its critical relevance to the safe storage and handling
of EMs, remains underexplored compared to the well-studied strong shock
conditions. To overcome the computational challenges associated with direct
numerical simulations, we advance the Physics-Aware Recurrent Convolutional
Neural Network (PARCv2), which has been shown to be capable of predicting
strong shock responses in EMs. We improved the architecture of PARCv2 to
rapidly predict shear localizations and plastic heating, which play important
roles in the weak-to-moderate shock regime. PARCv2 is benchmarked against two
widely used physics-informed models, namely, Fourier neural operator and neural
ordinary differential equation; we demonstrate its superior performance in
capturing the spatiotemporal dynamics of shear band formation. While all models
exhibit certain failure modes, our findings underscore the importance of
domain-specific considerations in developing robust AI-accelerated simulation
tools for reactive materials.

</details>


### [658] [Coupled Data and Measurement Space Dynamics for Enhanced Diffusion Posterior Sampling](https://arxiv.org/abs/2510.09676)
*Shayan Mohajer Hamidi,En-Hui Yang,Ben Liang*

Main category: cs.LG

TL;DR: C-DPS 框架通过在测量空间引入前向随机过程，解决了现有扩散模型在逆问题求解中的局限性，无需调整约束或近似似然，并在多个基准测试中取得了优于现有方法的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的逆问题求解方法依赖于投影技术或对似然函数进行近似，在复杂或高噪声条件下存在伪影和不稳定的问题。

Method: 提出了一种名为 C-DPS (coupled data and measurement space diffusion posterior sampling) 的新框架。该框架在测量空间（{y_t}）引入前向随机过程，与数据空间扩散（{x_t}）并行演化，从而可以推导出闭式后验 p(x_{t-1} | x_t, y_{t-1})，实现基于明确定义的后验分布的精确递归采样。

Result: 实验结果表明，C-DPS 在多个逆问题基准测试中，无论在定性还是定量上，都持续优于现有的基线方法。

Conclusion: C-DPS 框架通过在测量空间引入前向随机过程，实现了精确的逆问题求解，克服了现有方法的局限性。

Abstract: Inverse problems, where the goal is to recover an unknown signal from noisy
or incomplete measurements, are central to applications in medical imaging,
remote sensing, and computational biology. Diffusion models have recently
emerged as powerful priors for solving such problems. However, existing methods
either rely on projection-based techniques that enforce measurement consistency
through heuristic updates, or they approximate the likelihood $p(\boldsymbol{y}
\mid \boldsymbol{x})$, often resulting in artifacts and instability under
complex or high-noise conditions. To address these limitations, we propose a
novel framework called \emph{coupled data and measurement space diffusion
posterior sampling} (C-DPS), which eliminates the need for constraint tuning or
likelihood approximation. C-DPS introduces a forward stochastic process in the
measurement space $\{\boldsymbol{y}_t\}$, evolving in parallel with the
data-space diffusion $\{\boldsymbol{x}_t\}$, which enables the derivation of a
closed-form posterior $p(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t,
\boldsymbol{y}_{t-1})$. This coupling allows for accurate and recursive
sampling based on a well-defined posterior distribution. Empirical results
demonstrate that C-DPS consistently outperforms existing baselines, both
qualitatively and quantitatively, across multiple inverse problem benchmarks.

</details>


### [659] [Stronger Together: On-Policy Reinforcement Learning for Collaborative LLMs](https://arxiv.org/abs/2510.11062)
*Yujie Zhao,Lanxiang Hu,Yang Wang,Minmin Hou,Hao Zhang,Ke Ding,Jishen Zhao*

Main category: cs.LG

TL;DR: AT-GRPO算法和训练系统在多智能体强化学习中取得了显著的性能提升，尤其在长时规划、代码和数学任务上。


<details>
  <summary>Details</summary>
Motivation: 将on-policy强化学习应用于多智能体系统（MAS）仍然是一个未被充分探索的领域，并带来了独特的挑战，因为提示会因角色和回合而异。

Method: 提出了一种结合了（i）针对MAS定制的智能体和回合分组的强化学习算法，以及（ii）支持单策略和多策略训练的训练系统（AT-GRPO）。

Result: 在游戏、规划、代码和数学任务上，AT-GRPO带来了显著的收益。在长时规划任务上，准确率从单智能体RL基线的14.0%–47.0%提高到96.0%–99.5%。在代码任务上，推理性能平均提高了3.87%–7.62%；在数学任务上，平均提高了9.0%–17.93%。

Conclusion: AT-GRPO在多智能体强化学习任务中取得了显著的性能提升。

Abstract: Multi-agent systems (MAS) and reinforcement learning (RL) are widely used to
enhance the agentic capabilities of large language models (LLMs). MAS improves
task performance through role-based orchestration, while RL uses environmental
rewards to learn stronger policies, such as GRPO-style optimization. However,
applying on-policy RL to MAS remains underexplored and presents unique
challenges. Algorithmically, standard GRPO grouping assumptions break down
because prompts vary by role and by turn. System-wise, the training stack must
support MAS-workflow rollouts and on-policy updates for both single-policy and
multi-policy models.
  We propose AT-GRPO, which includes (i) an agent- and turn-wise grouped RL
algorithm tailored to MAS and (ii) a training system that supports both single-
and multi-policy regimes. Across game, planning, coding, and math tasks,
AT-GRPO delivers substantial gains. On long-horizon planning, it increases
accuracy from a 14.0 to 47.0 percent single-agent RL baseline to 96.0 to 99.5
percent. It also improves reasoning performance, with average gains of 3.87 to
7.62 percent on coding tasks and 9.0 to 17.93 percent on math. Code and
environments are available at: https://github.com/pettingllms-ai/PettingLLMs.

</details>


### [660] [Using LLMs to Directly Guess Conditional Expectations Can Improve Efficiency in Causal Estimation](https://arxiv.org/abs/2510.09684)
*Chris Engh,P. M. Aronow*

Main category: cs.LG

TL;DR: LLM工具可以提高因果推断的估计精度，尤其在高维混淆变量的情况下。


<details>
  <summary>Details</summary>
Motivation: 双重机器学习中，因果估计的准确性依赖于条件期望函数估计器的性能。现有方法仅依赖于从模型中提取的嵌入，可能存在局限性。

Method: 使用预训练的生成模型（如LLM）的预测能力来改进条件期望函数估计器的性能，并将其与仅使用模型嵌入的方法进行比较。

Result: 在在线珠宝拍卖的小型数据集案例研究中，LLM生成的预测作为预测变量可以提高估计效率。

Conclusion: LLM的预测能力及其蕴含的历史知识和推理能力，能够帮助克服因果推断中的高维性诅咒问题，从而提高因果估计的准确性。

Abstract: We propose a simple yet effective use of LLM-powered AI tools to improve
causal estimation. In double machine learning, the accuracy of causal estimates
of the effect of a treatment on an outcome in the presence of a
high-dimensional confounder depends on the performance of estimators of
conditional expectation functions. We show that predictions made by generative
models trained on historical data can be used to improve the performance of
these estimators relative to approaches that solely rely on adjusting for
embeddings extracted from these models. We argue that the historical knowledge
and reasoning capacities associated with these generative models can help
overcome curse-of-dimensionality problems in causal inference problems. We
consider a case study using a small dataset of online jewelry auctions, and
demonstrate that inclusion of LLM-generated guesses as predictors can improve
efficiency in estimation.

</details>


### [661] [Efficient Onboard Vision-Language Inference in UAV-Enabled Low-Altitude Economy Networks via LLM-Enhanced Optimization](https://arxiv.org/abs/2510.10028)
*Yang Li,Ruichen Zhang,Yinqiu Liu,Guangyuan Liu,Dusit Niyato,Abbas Jamalipour,Xianbin Wang,Dong In Kim*

Main category: cs.LG

TL;DR: 本论文提出了一种结合无人机（UAV）和低空经济网络（LAENet）的系统模型，旨在优化载板视觉-语言模型（VLM）的多模态推理。通过联合优化UAV移动性、通信和VQA流程，提出了一种混合整数非凸优化问题，以在满足用户特定精度要求的同时，最小化任务延迟和功耗。为解决该问题，设计了一个分层优化框架，包括用于资源分配的ARPO算法和用于自适应UAV轨迹优化的LLaRA方法。LLM在LLaRA中用于离线优化奖励设计，不增加实时决策的延迟。实验结果表明，该框架能有效提高动态LAENet条件下的推理性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 低空经济网络（LAENet）和无人机（UAV）视觉-语言模型（VLM）的发展带来了新的应用场景，但受限于资源和动态网络条件，保证推理精度和通信效率面临挑战。

Method: 提出UAV-LAENet系统模型，该模型考虑了UAV移动性、用户-UAV通信和板载VQA流程。提出混合整数非凸优化问题，目标是最小化任务延迟和功耗，同时满足用户特定的精度约束。设计了一个分层优化框架，包含（i）ARPO算法用于在精度约束下进行资源分配，（ii）LLaRA方法用于自适应UAV轨迹优化，其中LLM用于离线优化强化学习的奖励设计。

Result: 数值结果证明了所提出的框架在动态LAENet条件下能有效提升推理性能和通信效率。

Conclusion: 所提出的UAV-LAENet系统模型和分层优化框架（ARPO+LLaRA）能够有效解决低空网络环境下无人机多模态推理的精度和通信效率挑战。

Abstract: The rapid advancement of Low-Altitude Economy Networks (LAENets) has enabled
a variety of applications, including aerial surveillance, environmental
sensing, and semantic data collection. To support these scenarios, unmanned
aerial vehicles (UAVs) equipped with onboard vision-language models (VLMs)
offer a promising solution for real-time multimodal inference. However,
ensuring both inference accuracy and communication efficiency remains a
significant challenge due to limited onboard resources and dynamic network
conditions. In this paper, we first propose a UAV-enabled LAENet system model
that jointly captures UAV mobility, user-UAV communication, and the onboard
visual question answering (VQA) pipeline. Based on this model, we formulate a
mixed-integer non-convex optimization problem to minimize task latency and
power consumption under user-specific accuracy constraints. To solve the
problem, we design a hierarchical optimization framework composed of two parts:
(i) an Alternating Resolution and Power Optimization (ARPO) algorithm for
resource allocation under accuracy constraints, and (ii) a Large Language
Model-augmented Reinforcement Learning Approach (LLaRA) for adaptive UAV
trajectory optimization. The large language model (LLM) serves as an expert in
refining reward design of reinforcement learning in an offline fashion,
introducing no additional latency in real-time decision-making. Numerical
results demonstrate the efficacy of our proposed framework in improving
inference performance and communication efficiency under dynamic LAENet
conditions.

</details>


### [662] [On the Occurence of Critical Learning Periods in Neural Networks](https://arxiv.org/abs/2510.09687)
*Stanisław Pawlak*

Main category: cs.LG

TL;DR: 神经网络的训练可以通过调整学习超参数来避免关键学习期和启动性能损失。


<details>
  <summary>Details</summary>
Motivation: 研究神经网络在数据不足的情况下进行训练时出现的关键学习期现象，以及在已有模型基础上进行微调（warm-starting）时可能出现的性能损失问题，并探索解决方案。

Method: 通过调整学习超参数，特别是使用周期性学习率（cyclic learning rate schedule），来避免关键学习期和启动性能损失。实验复制了关键学习期现象，并扩展了相关实验的范围，同时研究了warm-starting方法。

Result: 证明了使用周期性学习率可以有效避免关键学习期和启动性能损失，使得网络在经过数据不足的训练后，仍能达到与从头训练的模型相当的准确率。

Conclusion: 关键学习期和启动性能损失是可以避免的，通过调整学习超参数（如周期性学习率）可以解决这些问题。这项研究将关键学习期与神经网络的warm-starting研究联系起来，对神经网络训练实践具有指导意义。

Abstract: This study delves into the plasticity of neural networks, offering empirical
support for the notion that critical learning periods and warm-starting
performance loss can be avoided through simple adjustments to learning
hyperparameters. The critical learning phenomenon emerges when training is
initiated with deficit data. Subsequently, after numerous deficit epochs, the
network's plasticity wanes, impeding its capacity to achieve parity in accuracy
with models trained from scratch, even when extensive clean data training
follows deficit epochs. Building upon seminal research introducing critical
learning periods, we replicate key findings and broaden the experimental scope
of the main experiment from the original work. In addition, we consider a
warm-starting approach and show that it can be seen as a form of deficit
pretraining. In particular, we demonstrate that these problems can be averted
by employing a cyclic learning rate schedule. Our findings not only impact
neural network training practices but also establish a vital link between
critical learning periods and ongoing research on warm-starting neural network
training.

</details>


### [663] [Evaluation of Differential Privacy Mechanisms on Federated Learning](https://arxiv.org/abs/2510.09691)
*Tejash Varsani*

Main category: cs.LG

TL;DR: 本研究提出了一种结合自适应隐私预算和自适应裁剪的差分隐私（DP）方法，以解决在联邦学习中，当模型收敛时，固定的隐私预算可能导致过多噪声从而损害模型性能的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的差分隐私（DP）技术在联邦学习中虽然能保护数据隐私，但通常使用固定的隐私预算，这可能在模型收敛时引入过多噪声，从而降低模型性能。因此，需要一种更优的隐私预算机制。

Method: 本研究实现了使用拉普拉斯和高斯机制的DP方法，并引入了自适应隐私预算和自适应裁剪。自适应裁剪允许高斯机制根据模型的梯度动态调整，而不是依赖于固定的敏感度。实验在SelecEval模拟器上进行。

Result: 实验结果表明，自适应隐私预算和自适应裁剪在保持模型准确性的同时，能够有效地保护隐私。尽管实验限于200个训练轮次，但结果是有希望的。

Conclusion: 自适应隐私预算和自适应裁剪是提高联邦学习中差分隐私技术性能和隐私保护之间平衡的有效方法。

Abstract: Federated learning is distributed model training across several clients
without disclosing raw data. Despite advancements in data privacy, risks still
remain. Differential Privacy (DP) is a technique to protect sensitive data by
adding noise to model updates, usually controlled by a fixed privacy budget.
However, this approach can introduce excessive noise, particularly when the
model converges, which compromises performance. To address this problem,
adaptive privacy budgets have been investigated as a potential solution. This
work implements DP methods using Laplace and Gaussian mechanisms with an
adaptive privacy budget, extending the SelecEval simulator. We introduce an
adaptive clipping approach in the Gaussian mechanism, ensuring that gradients
of the model are dynamically updated rather than using a fixed sensitivity. We
conduct extensive experiments with various privacy budgets, IID and non-IID
datasets, and different numbers of selected clients per round. While our
experiments were limited to 200 training rounds, the results suggest that
adaptive privacy budgets and adaptive clipping can help maintain model accuracy
while preserving privacy.

</details>


### [664] [Neural PDE Solvers with Physics Constraints: A Comparative Study of PINNs, DRM, and WANs](https://arxiv.org/abs/2510.09693)
*Jiakang Chen*

Main category: cs.LG

TL;DR: 该论文比较了三种无网格神经网络求解偏微分方程（PDE）的方法（PINNs, DRM, WANs），并在泊松方程和薛定谔方程上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 随着科学和工程领域对偏微分方程（PDE）的需求不断增长，传统求解方法的局限性（如高维度下的计算成本）日益凸显。本研究旨在统一比较三种新兴的无网格神经网络求解器——物理信息神经网络（PINNs）、深度黎曼方法（DRM）和弱对抗网络（WANs）——在解决泊松方程和薛定谔方程等问题上的性能。

Method: 本研究采用了统一的测试协议，比较了PINNs、DRM和WANs三种方法的性能。测试问题包括多维泊松方程和一维/二维定态薛定谔方程（无限深势阱和谐振子），并进一步扩展到利用Kramers-Henneberger（KH）变换处理激光驱动的薛定谔方程。在求解过程中，研究人员结合了强制边界条件（FBCs）、强制节点（FNs）和正交正则化（OG）等技术。

Result: 在强制边界条件（FBCs）、强制节点（FNs）和正交正则化（OG）的配合下，所有方法均实现了低至 $10^{-6}$-$10^{-9}$ 的 $L_2$ 误差。具体来说，PINNs在精度和激发谱恢复方面最可靠；DRM在精度和运行时间的平衡方面最优；WANs对参数选择较敏感，但有效利用弱形式约束和FN/OG时具有竞争力。敏感性分析表明，FBCs消除了边界损失的调优，网络宽度比深度对单网络求解器更重要，且大部分性能提升发生在5000-10000个训练周期内。研究还表明，该方法工具集同样适用于KH方程的求解。

Conclusion: 本研究为选择合适的神经网络求解器提供了实用的指导，并提出了未来的研究方向，包括DRM和WANs的时域方法、自适应残差驱动采样、并行多状态训练和神经域分解。研究结果表明，物理引导的神经网络求解器是解决复杂PDE问题的可信且可扩展的工具。

Abstract: Partial differential equations (PDEs) underpin models across science and
engineering, yet analytical solutions are atypical and classical mesh-based
solvers can be costly in high dimensions. This dissertation presents a unified
comparison of three mesh-free neural PDE solvers, physics-informed neural
networks (PINNs), the deep Ritz method (DRM), and weak adversarial networks
(WANs), on Poisson problems (up to 5D) and the time-independent Schr\"odinger
equation in 1D/2D (infinite well and harmonic oscillator), and extends the
study to a laser-driven case of Schr\"odinger's equation via the
Kramers-Henneberger (KH) transformation.
  Under a common protocol, all methods achieve low $L_2$ errors
($10^{-6}$-$10^{-9}$) when paired with forced boundary conditions (FBCs),
forced nodes (FNs), and orthogonality regularization (OG). Across tasks, PINNs
are the most reliable for accuracy and recovery of excited spectra; DRM offers
the best accuracy-runtime trade-off on stationary problems; WAN is more
sensitive but competitive when weak-form constraints and FN/OG are used
effectively. Sensitivity analyses show that FBC removes boundary-loss tuning,
network width matters more than depth for single-network solvers, and most
gains occur within 5000-10,000 epochs. The same toolkit solves the KH case,
indicating transfer beyond canonical benchmarks.
  We provide practical guidelines for method selection and outline the
following extensions: time-dependent formulations for DRM and WAN, adaptive
residual-driven sampling, parallel multi-state training, and neural domain
decomposition. These results support physics-guided neural solvers as credible,
scalable tools for solving complex PDEs.

</details>


### [665] [Kelp: A Streaming Safeguard for Large Models via Latent Dynamics-Guided Risk Detection](https://arxiv.org/abs/2510.09694)
*Xiaodan Li,Mengjie Wu,Yao Zhu,Yunna Lv,YueFeng Chen,Cen Chen,Jianmei Guo,Hui Xue*

Main category: cs.LG

TL;DR: Kelp是一个创新的即插即用框架，通过在大型模型（LMs）的生成过程中进行实时风险检测，解决了现有安全防护措施的不足。它利用中间隐藏状态和流式潜空间动力学头（SLD）来模拟风险的演变，并通过锚定时间一致性（ATC）损失来提高预测的可靠性。Kelp在文本和视觉-语言任务上均优于现有方法，同时参数量小，延迟低。


<details>
  <summary>Details</summary>
Motivation: 现有的大型模型（LMs）虽然内容生成能力强大，但也存在生成有害或偏见内容的风险。而现有的安全防护措施大多采用事后检测，可能在内容被发现前就已暴露，且延迟限制导致其模型轻量化，降低了检测精度。

Method: 提出了一种名为Kelp的新型即插即用框架，实现在LM生成管线中进行流式风险检测。Kelp利用LM的中间隐藏状态，通过一个流式潜空间动力学头（SLD）来模拟生成序列中风险的演变，从而实现更精确的实时风险检测。为了保证流式内容审核在实际应用中的可靠性，引入了锚定时间一致性（ATC）损失，通过嵌入一个良性-有害的时间先验来强制执行单调的危害预测。此外，为了严谨评估流式安全防护，还提出了StreamGuardBench基准，该基准包含每个受保护模型的即时响应，反映了文本和视觉-语言任务中的真实流式场景。

Result: Kelp在不同的模型和数据集上，持续优于最先进的事后安全防护措施和之前的即插即用探测方法（平均F1值高出15.61%），同时仅使用20M参数，并且每token延迟增加不到0.5毫秒。

Conclusion: Kelp通过其创新的流式风险检测方法，有效解决了大型模型生成内容中的安全风险问题，并在准确性、效率和可靠性方面均取得了显著的提升，为实际应用提供了更优的解决方案。

Abstract: Large models (LMs) are powerful content generators, yet their open-ended
nature can also introduce potential risks, such as generating harmful or biased
content. Existing guardrails mostly perform post-hoc detection that may expose
unsafe content before it is caught, and the latency constraints further push
them toward lightweight models, limiting detection accuracy. In this work, we
propose Kelp, a novel plug-in framework that enables streaming risk detection
within the LM generation pipeline. Kelp leverages intermediate LM hidden states
through a Streaming Latent Dynamics Head (SLD), which models the temporal
evolution of risk across the generated sequence for more accurate real-time
risk detection. To ensure reliable streaming moderation in real applications,
we introduce an Anchored Temporal Consistency (ATC) loss to enforce monotonic
harm predictions by embedding a benign-then-harmful temporal prior. Besides,
for a rigorous evaluation of streaming guardrails, we also present
StreamGuardBench-a model-grounded benchmark featuring on-the-fly responses from
each protected model, reflecting real-world streaming scenarios in both text
and vision-language tasks. Across diverse models and datasets, Kelp
consistently outperforms state-of-the-art post-hoc guardrails and prior plug-in
probes (15.61% higher average F1), while using only 20M parameters and adding
less than 0.5 ms of per-token latency.

</details>


### [666] [Vanishing Contributions: A Unified Approach to Smoothly Transition Neural Models into Compressed Form](https://arxiv.org/abs/2510.09696)
*Lorenzo Nikiforos,Charalampos Antoniadis,Luciano Prono,Fabio Pareschi,Riccardo Rovatti,Gianluca Setti*

Main category: cs.LG

TL;DR: VCON是一种通用的模型压缩方法，通过并行运行原始模型和压缩模型并逐步调整其贡献比例，有效缓解了精度下降问题，并在计算机视觉和自然语言处理任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络规模不断扩大，需要更有效的压缩技术来降低内存、计算和能源消耗，但现有技术直接应用时常导致精度显著下降。

Method: VCON通过在微调过程中并行运行原始模型和压缩模型，并逐步降低原始模型的贡献，同时增加压缩模型的贡献，实现平滑过渡。

Result: 在计算机视觉和自然语言处理基准测试中，VCON结合多种压缩策略，所有场景下均带来一致的性能提升，典型提升超过3%，部分配置甚至能提升20%的精度。

Conclusion: VCON是一种可泛化的方法，可应用于现有压缩技术，并在多个基准测试中展现出一致的性能提升，有效解决了模型压缩中的精度下降问题。

Abstract: The increasing scale of deep neural networks has led to a growing need for
compression techniques such as pruning, quantization, and low-rank
decomposition. While these methods are very effective in reducing memory,
computation and energy consumption, they often introduce severe accuracy
degradation when applied directly. We introduce Vanishing Contributions (VCON),
a general approach for smoothly transitioning neural models into compressed
form. Rather than replacing the original network directly with its compressed
version, VCON executes the two in parallel during fine-tuning. The contribution
of the original (uncompressed) model is progressively reduced, while that of
the compressed model is gradually increased. This smooth transition allows the
network to adapt over time, improving stability and mitigating accuracy
degradation. We evaluate VCON across computer vision and natural language
processing benchmarks, in combination with multiple compression strategies.
Across all scenarios, VCON leads to consistent improvements: typical gains
exceed 3%, while some configuration exhibits accuracy boosts of 20%. VCON thus
provides a generalizable method that can be applied to the existing compression
techniques, with evidence of consistent gains across multiple benchmarks.

</details>


### [667] [Operator Learning for Power Systems Simulation](https://arxiv.org/abs/2510.09704)
*Matthew Schlegel,Matthew E. Taylor,Mostafa Farrokhabadi*

Main category: cs.LG

TL;DR: 时间域仿真在可再生能源并网的电网中因所需时间步长过小而面临计算瓶颈。本文研究了算子学习作为一种替代模型，并提出了时间步长不变性概念，以实现从粗粒度到细粒度仿真的泛化。


<details>
  <summary>Details</summary>
Motivation: 可再生能源并网的电网在时间域仿真中面临计算挑战，需要更快的解决方案以支持可再生能源的稳定整合和气候变化减缓。

Method: 研究算子学习作为一种替代模型，并提出了时间步长不变性概念，以实现从粗粒度到细粒度仿真的泛化。对三种算子学习方法进行了基准测试，并在一个简单的测试系统中进行了评估。

Result: 验证了时间步长不变性的可行性，实现了在粗时间步长上训练的模型泛化到细时间步长（零次超分辨率）以及在稳定和不稳定动态模型之间的泛化。

Conclusion: 算子学习和时间步长不变性为解决可再生能源并网的电网仿真挑战提供了有前景的解决方案。

Abstract: Time domain simulation, i.e., modeling the system's evolution over time, is a
crucial tool for studying and enhancing power system stability and dynamic
performance. However, these simulations become computationally intractable for
renewable-penetrated grids, due to the small simulation time step required to
capture renewable energy resources' ultra-fast dynamic phenomena in the range
of 1-50 microseconds. This creates a critical need for solutions that are both
fast and scalable, posing a major barrier for the stable integration of
renewable energy resources and thus climate change mitigation. This paper
explores operator learning, a family of machine learning methods that learn
mappings between functions, as a surrogate model for these costly simulations.
The paper investigates, for the first time, the fundamental concept of
simulation time step-invariance, which enables models trained on coarse time
steps to generalize to fine-resolution dynamics. Three operator learning
methods are benchmarked on a simple test system that, while not incorporating
practical complexities of renewable-penetrated grids, serves as a first
proof-of-concept to demonstrate the viability of time step-invariance. Models
are evaluated on (i) zero-shot super-resolution, where training is performed on
a coarse simulation time step and inference is performed at super-resolution,
and (ii) generalization between stable and unstable dynamic regimes. This work
addresses a key challenge in the integration of renewable energy for the
mitigation of climate change by benchmarking operator learning methods to model
physical systems.

</details>


### [668] [A Multi-Component Reward Function with Policy Gradient for Automated Feature Selection with Dynamic Regularization and Bias Mitigation](https://arxiv.org/abs/2510.09705)
*Sudip Khadka,L. S. Paudel*

Main category: cs.LG

TL;DR: 本研究提出一种利用强化学习（RL）框架来解决隐藏依赖导致的偏见问题，并通过自动化特征选择来整合偏见缓解和特征选择过程。


<details>
  <summary>Details</summary>
Motivation: 现有的静态特征排除策略无法有效解决因隐藏依赖导致的偏见问题。

Method: 提出一种强化学习（RL）框架，该框架将偏见缓解和自动化特征选择整合到单一学习过程中。RL agent使用整合了预测性能和公平性考量的奖励信号来选择特征，从而动态地平衡泛化、准确性和公平性。

Result: 通过构建多组件奖励函数，定义了作用于特征子集的 agent 动作空间，并将该系统与集成学习相结合，实现了在预测变量相关且偏见可能重新出现的环境中进行特征选择。

Conclusion: 提出了一种灵活且可泛化的方法，用于在预测变量相关且可能出现偏见的复杂环境中进行特征选择。

Abstract: Static feature exclusion strategies often fail to prevent bias when hidden
dependencies influence the model predictions. To address this issue, we explore
a reinforcement learning (RL) framework that integrates bias mitigation and
automated feature selection within a single learning process. Unlike
traditional heuristic-driven filter or wrapper approaches, our RL agent
adaptively selects features using a reward signal that explicitly integrates
predictive performance with fairness considerations. This dynamic formulation
allows the model to balance generalization, accuracy, and equity throughout the
training process, rather than rely exclusively on pre-processing adjustments or
post hoc correction mechanisms. In this paper, we describe the construction of
a multi-component reward function, the specification of the agents action space
over feature subsets, and the integration of this system with ensemble
learning. We aim to provide a flexible and generalizable way to select features
in environments where predictors are correlated and biases can inadvertently
re-emerge.

</details>


### [669] [Group-Adaptive Adversarial Learning for Robust Fake News Detection Against Malicious Comments](https://arxiv.org/abs/2510.09712)
*Zhao Tong,Chunlin Gong,Yimeng Gu,Haichao Shi,Qiang Liu,Shu Wu,Xiao-Yu Zhang*

Main category: cs.LG

TL;DR: 本研究评估了评论攻击对虚假新闻检测（FND）模型的影响，并提出了一种名为 InfoDirichlet 的对抗性训练策略来提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在线虚假新闻的传播会扭曲公众判断并侵蚀对社交媒体平台的信任。尽管现有的 FND 模型在标准设置下表现良好，但它们容易受到由真实用户或大型语言模型（LLM）生成的评论攻击，这些攻击会微妙地改变模型决策。

Method: 本研究提出的对抗性训练策略包含三个步骤：1. 将对抗性评论分为感知、认知和社会三类；2. 利用 LLM 生成特定类别的多样化攻击；3. 采用基于 Dirichlet 的自适应采样机制（InfoDirichlet 调整机制）在训练过程中动态调整不同评论类别的学习重点。

Result: 实验表明，该方法在保持高检测精度的同时，显著提高了模型对各种对抗性评论干扰的鲁棒性。

Conclusion: 本研究提出的 InfoDirichlet 策略能够有效提高 FND 模型的鲁棒性，使其在面对对抗性评论时仍能保持准确的检测能力。

Abstract: The spread of fake news online distorts public judgment and erodes trust in
social media platforms. Although recent fake news detection (FND) models
perform well in standard settings, they remain vulnerable to adversarial
comments-authored by real users or by large language models (LLMs)-that subtly
shift model decisions. In view of this, we first present a comprehensive
evaluation of comment attacks to existing fake news detectors and then
introduce a group-adaptive adversarial training strategy to improve the
robustness of FND models. To be specific, our approach comprises three steps:
(1) dividing adversarial comments into three psychologically grounded
categories: perceptual, cognitive, and societal; (2) generating diverse,
category-specific attacks via LLMs to enhance adversarial training; and (3)
applying a Dirichlet-based adaptive sampling mechanism (InfoDirichlet Adjusting
Mechanism) that dynamically adjusts the learning focus across different comment
categories during training. Experiments on benchmark datasets show that our
method maintains strong detection accuracy while substantially increasing
robustness to a wide range of adversarial comment perturbations.

</details>


### [670] [High-Power Training Data Identification with Provable Statistical Guarantees](https://arxiv.org/abs/2510.09717)
*Zhenlong Liu,Hao Zeng,Weiran Huang,Hongxin Wei*

Main category: cs.LG

TL;DR: 介绍了一种名为PTDI（Provable Training Data Identification）的新方法，用于在大型模型中识别训练数据，该方法具有严格的可证明的错误发现率（FDR）控制能力，并且比现有方法具有更高的检测能力。


<details>
  <summary>Details</summary>
Motivation: 在大型模型中识别训练数据对于版权诉讼、隐私审计和确保公平评估至关重要，而现有方法在统计保证方面存在不足。

Method: PTDI方法通过利用一组未见数据计算每个数据点的p值，并构建一个保守的测试集数据使用比例估计量来扩展这些p值，最后选择缩放后的p值低于数据相关阈值的所有点作为训练数据。

Result: PTDI方法在广泛的模型（包括LLMs和VLMs）和数据集上进行了广泛的实验，证明了其严格控制FDR并显著提高检测能力的能力。

Conclusion: PTDI是一种严谨的方法，可以识别具有可证明的严格FDR控制的训练数据，并且比现有方法具有更高的检测能力。

Abstract: Identifying training data within large-scale models is critical for copyright
litigation, privacy auditing, and ensuring fair evaluation. The conventional
approaches treat it as a simple binary classification task without statistical
guarantees. A recent approach is designed to control the false discovery rate
(FDR), but its guarantees rely on strong, easily violated assumptions. In this
paper, we introduce Provable Training Data Identification (PTDI), a rigorous
method that identifies a set of training data with strict false discovery rate
(FDR) control. Specifically, our method computes p-values for each data point
using a set of known unseen data, and then constructs a conservative estimator
for the data usage proportion of the test set, which allows us to scale these
p-values. Our approach then selects the final set of training data by
identifying all points whose scaled p-values fall below a data-dependent
threshold. This entire procedure enables the discovery of training data with
provable, strict FDR control and significantly boosted power. Extensive
experiments across a wide range of models (LLMs and VLMs), and datasets
demonstrate that PTDI strictly controls the FDR and achieves higher power.

</details>


### [671] [Federated k-Means via Generalized Total Variation Minimization](https://arxiv.org/abs/2510.09718)
*A. Jung*

Main category: cs.LG

TL;DR: Federated k-means clustering using GTVMin formulation for privacy-friendly clustering without sharing local datasets.


<details>
  <summary>Details</summary>
Motivation: Address the problem of federated clustering where devices with private local datasets need to jointly cluster data without sharing.

Method: Formulate federated k-means as a GTVMin instance, leading to a federated algorithm where devices solve a modified local k-means problem with a penalty term for neighbor centroid discrepancy.

Result: A privacy-friendly federated k-means algorithm that only shares aggregated information.

Conclusion: The proposed federated k-means algorithm effectively performs clustering in a distributed and privacy-preserving manner.

Abstract: We consider the problem of federated clustering, where interconnected devices
have access to private local datasets and need to jointly cluster the overall
dataset without sharing their local dataset. Our focus is on hard clustering
based on the k-means principle. We formulate federated k-means clustering as an
instance of GTVMin. This formulation naturally lends to a federated k-means
algorithm where each device updates local cluster centroids by solving a
modified local k-means problem. The modification involves adding a penalty term
to measure the discrepancy between the cluster centroid of neighbouring
devices. Our federated k-means algorithm is privacy-friendly as it only
requires sharing aggregated information among interconnected devices.

</details>


### [672] [ICL-Router: In-Context Learned Model Representations for LLM Routing](https://arxiv.org/abs/2510.09719)
*Chenxu Wang,Hao Li,Yiqun Zhang,Linyao Chen,Jianhao Chen,Ping Jian,Peng Ye,Qiaosheng Zhang,Shuyue Hu*

Main category: cs.LG

TL;DR: 通过使用上下文内向量表示模型能力，提出一种新的模型路由方法，实现了最先进的路由性能，并支持无需重新训练即可添加新模型。


<details>
  <summary>Details</summary>
Motivation: 现有的模型路由方法在添加新模型时通常需要重新训练，这限制了其可扩展性。模型的表示也可能不准确，影响路由性能。

Method: 提出一种使用上下文内向量表示模型能力的新型路由方法。该方法包括两个阶段：1. 训练一个投影器和基于LLM的路由器来重建原始查询，以嵌入查询并将查询投影到向量。2. 训练路由器基于查询和模型性能的上下文内向量来预测模型能否正确回答新查询。

Result: 该方法在in-distribution和out-of-distribution任务上都实现了最先进的路由性能。此外，该方法允许在不重新训练路由器的前提下无缝集成新模型。

Conclusion: 所提出的基于上下文内向量的模型路由方法在性能和可扩展性方面均优于现有方法，并且能够轻松地集成新模型。

Abstract: Large language models (LLMs) often exhibit complementary strengths. Model
routing harnesses these strengths by dynamically directing each query to the
most suitable model, given a candidate model pool. However, routing performance
relies on accurate model representations, and adding new models typically
requires retraining, limiting scalability. To address these challenges, we
propose a novel routing method using in-context vectors to represent model
capabilities. The method proceeds in two stages. First, queries are embedded
and projected into vectors, with a projector and LLM-based router trained to
reconstruct the original queries, aligning vector representations with the
router's semantic space. Second, each candidate model is profiled on a query
set, and the router learns -- based on in-context vectors of query and model
performance -- to predict whether each model can correctly answer new queries.
Extensive experiments demonstrate that our method achieves state-of-the-art
routing performance in both in-distribution and out-of-distribution tasks.
Moreover, our method allows for seamless integration of new models without
retraining the router. The code is available at
https://github.com/lalalamdbf/ICL-Router.

</details>


### [673] [It's 2025 -- Narrative Learning is the new baseline to beat for explainable machine learning](https://arxiv.org/abs/2510.09723)
*Gregory D. Baker*

Main category: cs.LG

TL;DR: 使用自然语言定义模型并通过解释性提示进行迭代，叙述性学习在多个数据集上超越了基线可解释模型。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的机器学习方法，即叙述性学习，它使用自然语言定义模型并进行迭代式改进，以替代传统的数值优化方法。

Method: 该方法完全使用自然语言定义模型，并通过解释性提示而不是传统的数值优化来迭代地改进分类标准。

Result: 在6个数据集中的5个上，叙述性学习在2025年或更早的时候比基线可解释模型更准确，这得益于语言模型的改进。同时，还分析了模型输出的词汇统计趋势，作为解释可理解性的替代指标。

Conclusion: 叙述性学习在准确性和可解释性方面显示出巨大潜力，并且随着语言模型的进步，其性能有望进一步提升。

Abstract: In this paper, we introduce Narrative Learning, a methodology where models
are defined entirely in natural language and iteratively refine their
classification criteria using explanatory prompts rather than traditional
numerical optimisation. We report on experiments to evaluate the accuracy and
potential of this approach using 3 synthetic and 3 natural datasets and compare
them against 7 baseline explainable machine learning models. We demonstrate
that on 5 out of 6 of these datasets, Narrative Learning became more accurate
than the baseline explainable models in 2025 or earlier because of improvements
in language models. We also report on trends in the lexicostatistics of these
models' outputs as a proxy for the comprehensibility of the explanations.

</details>


### [674] [Evaluating LLM-Based Process Explanations under Progressive Behavioral-Input Reduction](https://arxiv.org/abs/2510.09732)
*P. van Oerle,R. H. Bemthuis,F. A. Bukhsh*

Main category: cs.LG

TL;DR: LLM生成过程模型解释在计算上可能很昂贵，但通过逐步减少行为输入，可以实现计算效率和解释质量之间的权衡，尤其是在资源有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 生成过程模型的文本解释可能非常耗时，尤其是在处理大型行为抽象时。本研究旨在探索通过逐步减少行为输入来降低计算成本，同时仍保持可接受的解释质量。

Method: 该方法包括三个步骤：(i)从不同大小的输入前缀中发现过程模型；(ii)提示LLM生成模型解释；(iii)使用另一个LLM评估这些解释的完整性、瓶颈识别和改进建议。

Result: 在合成日志上进行的研究表明，在适度减少输入的情况下，解释的质量基本保持不变，这表明存在一种实际的成本-质量权衡。

Conclusion: 研究结果表明，在资源受限的环境中，可以通过逐步减少行为输入来提高LLM辅助过程分析的计算效率，同时在解释质量方面取得可接受的权衡。然而，该研究具有探索性，因为评估是基于LLM的，并且数据是合成的。

Abstract: Large Language Models (LLMs) are increasingly used to generate textual
explanations of process models discovered from event logs. Producing
explanations from large behavioral abstractions (e.g., directly-follows graphs
or Petri nets) can be computationally expensive. This paper reports an
exploratory evaluation of explanation quality under progressive
behavioral-input reduction, where models are discovered from progressively
smaller prefixes of a fixed log. Our pipeline (i) discovers models at multiple
input sizes, (ii) prompts an LLM to generate explanations, and (iii) uses a
second LLM to assess completeness, bottleneck identification, and suggested
improvements. On synthetic logs, explanation quality is largely preserved under
moderate reduction, indicating a practical cost-quality trade-off. The study is
exploratory, as the scores are LLM-based (comparative signals rather than
ground truth) and the data are synthetic. The results suggest a path toward
more computationally efficient, LLM-assisted process analysis in
resource-constrained settings.

</details>


### [675] [ARROW: An Adaptive Rollout and Routing Method for Global Weather Forecasting](https://arxiv.org/abs/2510.09734)
*Jindong Tian,Yifei Ding,Ronghui Xu,Hao Miao,Chenjuan Guo,Bin Yang*

Main category: cs.LG

TL;DR: ARROW通过采用多时间间隔预测、混合专家模型、环形位置编码和基于强化学习的自适应回滚调度来改进长期天气预报，在全局天气预报方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的天气预报方法在模拟大气动力学和处理长期预测中的误差累积方面存在不足，尤其是在捕捉空间和多尺度时间依赖性方面。

Method: ARROW采用多时间间隔预测模型，其中共享-私有混合专家模型用于捕捉跨时间尺度的共享和特定大气动力学特征，环形位置编码用于编码地球的圆形纬度结构。此外，还开发了一种基于强化学习的自适应回滚调度器，用于根据当前天气状况选择最合适的时间间隔进行预测。

Result: 实验结果表明，ARROW在全局天气预报方面取得了最先进的性能。

Conclusion: ARROW通过解决现有方法的局限性，为全局天气预报领域提供了一个有前景的新范式。

Abstract: Weather forecasting is a fundamental task in spatiotemporal data analysis,
with broad applications across a wide range of domains. Existing data-driven
forecasting methods typically model atmospheric dynamics over a fixed short
time interval (e.g., 6 hours) and rely on naive autoregression-based rollout
for long-term forecasting (e.g., 138 hours). However, this paradigm suffers
from two key limitations: (1) it often inadequately models the spatial and
multi-scale temporal dependencies inherent in global weather systems, and (2)
the rollout strategy struggles to balance error accumulation with the capture
of fine-grained atmospheric variations. In this study, we propose ARROW, an
Adaptive-Rollout Multi-scale temporal Routing method for Global Weather
Forecasting. To contend with the first limitation, we construct a
multi-interval forecasting model that forecasts weather across different time
intervals. Within the model, the Shared-Private Mixture-of-Experts captures
both shared patterns and specific characteristics of atmospheric dynamics
across different time scales, while Ring Positional Encoding accurately encodes
the circular latitude structure of the Earth when representing spatial
information. For the second limitation, we develop an adaptive rollout
scheduler based on reinforcement learning, which selects the most suitable time
interval to forecast according to the current weather state. Experimental
results demonstrate that ARROW achieves state-of-the-art performance in global
weather forecasting, establishing a promising paradigm in this field.

</details>


### [676] [InterCorpRel-LLM: Enhancing Financial Relational Understanding with Graph-Language Models](https://arxiv.org/abs/2510.09735)
*Qianyou Sun,Jiexin Zheng,Bohan Jin,Lihua Chen,Yijie Peng*

Main category: cs.LG

TL;DR: InterCorpRel-LLM是一个结合了图神经网络（GNNs）和大型语言模型（LLMs）的跨模态框架，用于识别公司间的供应链和竞争关系，并在供应链关系识别任务中取得了显著优于包括GPT-5在内的强基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 识别公司间的供应链和竞争关系对于金融分析和公司治理至关重要，但由于公司数据的规模、稀疏性和语境依赖性，这一直是一个挑战。现有的图方法缺乏语义深度，而大型语言模型在表示关系依赖性方面能力有限。

Method: 提出InterCorpRel-LLM，一个结合了GNNs和LLMs的跨模态框架，并使用包含FactSet供应链记录的专有数据集和三个定制的训练任务（公司图匹配、行业分类和供应链关系预测）来支持其训练。

Result: InterCorpRel-LLM在供应链关系识别任务上的F分数达到了0.8543，显著优于F分数为0.2287的GPT-5等强基线模型，并且能够泛化到零样本竞争对手识别任务。

Conclusion: InterCorpRel-LLM提供了一个有效的工具，能够联合建模结构和语义，为分析师和战略家提供了绘制和推理复杂公司网络的强大工具，从而在动态市场中提高决策和风险管理能力。

Abstract: Identifying inter-firm relationships such as supply and competitive ties is
critical for financial analysis and corporate governance, yet remains
challenging due to the scale, sparsity, and contextual dependence of corporate
data. Graph-based methods capture structure but miss semantic depth, while
large language models (LLMs) excel at text but remain limited in their ability
to represent relational dependencies. To address this, we propose
InterCorpRel-LLM, a cross-modal framework that integrates GNNs with LLMs,
supported by a proprietary dataset derived from FactSet supply chain records
and three tailored training tasks: company graph matching, industry
classification, and supply relation prediction. This design enables effective
joint modeling of structure and semantics. Experiments show that
InterCorpRel-LLM substantially outperforms strong baselines, including GPT-5,
on a supply relation identification task, achieving an F-score of 0.8543 vs.
0.2287 with only a 7B-parameter backbone and lightweight training. The model
also generalizes to zero-shot competitor identification, underscoring its
ability to capture nuanced inter-firm dynamics. Our framework thus provides
analysts and strategists with a robust tool for mapping and reasoning about
complex corporate networks, enhancing decision-making and risk management in
dynamic markets.

</details>


### [677] [Machine learning methods fail to provide cohesive atheoretical construction of personality traits from semantic embeddings](https://arxiv.org/abs/2510.09739)
*Ayoub Bouguettaya,Elizabeth M. Stuart*

Main category: cs.LG

TL;DR: The Big Five personality traits are robust and may not be replaceable by machine learning models, as demonstrated by an analysis of Reddit comments.


<details>
  <summary>Details</summary>
Motivation: To test the lexical hypothesis and compare a machine learning-based personality model against the Big Five using online language data.

Method: Created a bottom-up personality model from an adjective list using machine learning and compared its descriptive utility against the Big Five by analyzing one million Reddit comments.

Result: The Big Five model, particularly Agreeableness, Conscientiousness, and Neuroticism, provided a much more powerful and interpretable description of online communities compared to the machine learning clusters. The machine learning clusters failed to make meaningful distinctions and did not recover the Extraversion trait.

Conclusion: The Big Five model is robust and its semantic structure is context-dependent. While machine learning can validate psychological theories, it may not replace them.

Abstract: The lexical hypothesis posits that personality traits are encoded in language
and is foundational to models like the Big Five. We created a bottom-up
personality model from a classic adjective list using machine learning and
compared its descriptive utility against the Big Five by analyzing one million
Reddit comments. The Big Five, particularly Agreeableness, Conscientiousness,
and Neuroticism, provided a far more powerful and interpretable description of
these online communities. In contrast, our machine-learning clusters provided
no meaningful distinctions, failed to recover the Extraversion trait, and
lacked the psychometric coherence of the Big Five. These results affirm the
robustness of the Big Five and suggest personality's semantic structure is
context-dependent. Our findings show that while machine learning can help check
the ecological validity of established psychological theories, it may not be
able to replace them.

</details>


### [678] [Reliable Active Learning from Unreliable Labels via Neural Collapse Geometry](https://arxiv.org/abs/2510.09740)
*Atharv Goel,Sharat Agarwal,Saket Anand,Chetan Arora*

Main category: cs.LG

TL;DR: 主动学习（AL）通过优先选择信息量大的样本来降低标注成本，但当标签有噪声或数据分布发生变化时，其可靠性会受到影响。我们提出了一个名为 NCAL-R 的框架，该框架利用深度网络的几何规律来抵消不可靠的监督。NCAL-R 结合了两个互补的信号：(i) 一个类别均值对齐扰动分数，用于量化候选样本在多大程度上稳定或扭曲了类间几何结构；(ii) 一个特征波动分数，用于捕捉跨训练检查点的表示的时间不稳定性。通过结合这些信号，NCAL-R 优先选择那些既能保持类别分离又能突出模糊区域的样本，从而减轻有噪声或冗余标签的影响。


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，标注者会犯错，稀有类别可能存在歧义，传统的AL启发式方法（如不确定性、多样性）常常会因为重复选择错误标注或冗余样本而放大这些错误。因此，有必要提高AL在标签噪声和数据分布变化下的可靠性。

Method: NCAL-R 框架利用深度网络的几何规律，引入两个互补的信号：类别均值对齐扰动分数（量化样本对类间几何结构稳定性的影响）和特征波动分数（捕捉表示的时间不稳定性）。通过结合这两个分数，NCAL-R 优先选择能够保持类别分离并突出模糊区域的样本。

Result: 在 ImageNet-100 和 CIFAR100 上的实验表明，NCAL-R 的表现优于标准的 AL 基线，能够以更少的标签获得更高的准确率，在合成标签噪声下具有更高的鲁棒性，并且对分布外数据的泛化能力更强。

Conclusion: 将几何可靠性标准纳入样本选择决策过程，可以使主动学习在面对标注错误和分布变化时变得不那么脆弱，这是实现值得信赖的现实世界标注流程的关键一步。

Abstract: Active Learning (AL) promises to reduce annotation cost by prioritizing
informative samples, yet its reliability is undermined when labels are noisy or
when the data distribution shifts. In practice, annotators make mistakes, rare
categories are ambiguous, and conventional AL heuristics (uncertainty,
diversity) often amplify such errors by repeatedly selecting mislabeled or
redundant samples. We propose Reliable Active Learning via Neural Collapse
Geometry (NCAL-R), a framework that leverages the emergent geometric
regularities of deep networks to counteract unreliable supervision. Our method
introduces two complementary signals: (i) a Class-Mean Alignment Perturbation
score, which quantifies how candidate samples structurally stabilize or distort
inter-class geometry, and (ii) a Feature Fluctuation score, which captures
temporal instability of representations across training checkpoints. By
combining these signals, NCAL-R prioritizes samples that both preserve class
separation and highlight ambiguous regions, mitigating the effect of noisy or
redundant labels. Experiments on ImageNet-100 and CIFAR100 show that NCAL-R
consistently outperforms standard AL baselines, achieving higher accuracy with
fewer labels, improved robustness under synthetic label noise, and stronger
generalization to out-of-distribution data. These results suggest that
incorporating geometric reliability criteria into acquisition decisions can
make Active Learning less brittle to annotation errors and distribution shifts,
a key step toward trustworthy deployment in real-world labeling pipelines. Our
code is available at https://github.com/Vision-IIITD/NCAL.

</details>


### [679] [Patentformer: A demonstration of AI-assisted automated patent drafting](https://arxiv.org/abs/2510.09752)
*Sai Krishna Reddy Mudhiganti,Juanyan Wang,Ruo Yang,Manali Sharma*

Main category: cs.LG

TL;DR: Patentformer是一个AI驱动的自动化专利起草平台，旨在通过快速生成符合法律书写标准的专利申请来协助专利律师。


<details>
  <summary>Details</summary>
Motivation: 专利起草工作依赖经验丰富的专利律师，他们需要兼备法律和技术知识，并使用正式的法律写作风格来撰写专利申请。

Method: 提出并展示了一个名为Patentformer的AI驱动的自动化专利起草平台。

Result: 该平台能够快速生成高质量的专利申请。

Conclusion: Patentformer可以支持专利律师，提高专利申请的质量和效率。

Abstract: Patent drafting presents significant challenges due to its reliance on the
extensive experience and specialized expertise of patent attorneys, who must
possess both legal acumen and technical understanding of an invention to craft
patent applications in a formal legal writing style. This paper presents a
demonstration of Patentformer, an AI-powered automated patent drafting platform
designed to support patent attorneys by rapidly producing high-quality patent
applications adhering to legal writing standards.

</details>


### [680] [PatentVision: A multimodal method for drafting patent applications](https://arxiv.org/abs/2510.09762)
*Ruo Yang,Sai Krishna Reddy Mudhiganti,Manali Sharma*

Main category: cs.LG

TL;DR: PatentVision是一个多模态框架，利用LVLM和视听输入自动生成专利说明书，在准确性和保真度方面优于纯文本方法。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型（LVLMs）在专利写作自动化方面的应用仍未得到充分探索，而专利写作本身因需要详细的技术描述、法律合规性和视觉元素而变得复杂。

Method: 构建了一个名为PatentVision的多模态框架，该框架集成了文本和视觉输入（如专利权利要求和图纸），并建立在先进的LVLM之上，通过结合微调的视觉语言模型和针对专利的领域特定训练来提高准确性。

Result: 实验表明，PatentVision在准确性和与人类书写标准的一致性方面，其表现优于纯文本方法。通过整合视觉数据，它能更好地表示复杂的设f计特征和功能联系，从而产生更丰富、更精确的结果。

Conclusion: 多模态技术在专利自动化方面具有重要价值，可以提供一个可扩展的工具来减少手动工作量并提高一致性。PatentVision不仅推进了专利起草的自动化，也为LVLM在专业领域的广泛应用奠定了基础，有望革新知识产权管理和创新过程。

Abstract: Patent drafting is complex due to its need for detailed technical
descriptions, legal compliance, and visual elements. Although Large Vision
Language Models (LVLMs) show promise across various tasks, their application in
automating patent writing remains underexplored. In this paper, we present
PatentVision, a multimodal framework that integrates textual and visual inputs
such as patent claims and drawings to generate complete patent specifications.
Built on advanced LVLMs, PatentVision enhances accuracy by combining fine tuned
vision language models with domain specific training tailored to patents.
Experiments reveal it surpasses text only methods, producing outputs with
greater fidelity and alignment with human written standards. Its incorporation
of visual data allows it to better represent intricate design features and
functional connections, leading to richer and more precise results. This study
underscores the value of multimodal techniques in patent automation, providing
a scalable tool to reduce manual workloads and improve consistency.
PatentVision not only advances patent drafting but also lays the groundwork for
broader use of LVLMs in specialized areas, potentially transforming
intellectual property management and innovation processes.

</details>


### [681] [Conformal Inference for Time Series over Graphs](https://arxiv.org/abs/2510.11049)
*Sonakshi Dua,Gonzalo Mateos,Sundeep Prabhakar Chepuri*

Main category: cs.LG

TL;DR: 针对图时间序列的预测，提出了一种基于共形预测的序贯预测区域框架，以解决现有方法忽略图拓扑或时间动态的问题。


<details>
  <summary>Details</summary>
Motivation: 现有共形预测方法在处理多元时间序列和静态图时存在不足，无法同时考虑图拓扑和时间动态。而可信赖的决策制定需要创新的不确定性量化方法来处理图时间序列预测模型。

Method: 提出一种基于共形预测的序贯预测区域框架，利用图结构捕捉节点间的依赖关系，并提供用户指定覆盖率保证。该方法在理论上证明了预测区域体积的指数收缩。

Result: 在真实世界数据集上，该框架在保持期望的经验覆盖率的同时，预测区域体积相比现有方法显著减小（最高可达80%）。

Conclusion: 所提出的不确定性量化框架能够有效地处理图时间序列数据，提供更精确的预测区域，并满足覆盖率保证，为网络化动态环境中的可信赖决策提供支持。

Abstract: Trustworthy decision making in networked, dynamic environments calls for
innovative uncertainty quantification substrates in predictive models for graph
time series. Existing conformal prediction (CP) methods have been applied
separately to multivariate time series and static graphs, but they either
ignore the underlying graph topology or neglect temporal dynamics. To bridge
this gap, here we develop a CP-based sequential prediction region framework
tailored for graph time series. A key technical innovation is to leverage the
graph structure and thus capture pairwise dependencies across nodes, while
providing user-specified coverage guarantees on the predictive outcomes. We
formally establish that our scheme yields an exponential shrinkage in the
volume of the ellipsoidal prediction set relative to its graph-agnostic
counterpart. Using real-world datasets, we demonstrate that the novel
uncertainty quantification framework maintains desired empirical coverage while
achieving markedly smaller (up to 80% reduction) prediction regions than
existing approaches.

</details>


### [682] [Leveraging Shared Prototypes for a Multimodal Pulse Motion Foundation Model](https://arxiv.org/abs/2510.09764)
*Wanting Mao,Maxwell A Xu,Harish Haresamudram,Mithun Saha,Santosh Kumar,James Matthew Rehg*

Main category: cs.LG

TL;DR: ProtoMM是一种新颖的自监督学习框架，使用共享原型字典来锚定不同模态的数据，以克服现有方法在多模态时间序列数据分析中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态自监督学习方法在处理如ECG、PPG、EDA和加速度计等生物信号时，往往依赖于CLIP风格的对比学习目标，容易导致对齐特征的过拟合，并将有效的跨模态关系误判为负例，从而产生碎片化且泛化能力不足的嵌入。

Method: ProtoMM通过引入一个共享的原型字典，将异构模态锚定在一个共同的嵌入空间中。该方法通过围绕共享原型进行聚类，而不是依赖显式的负样本采样，来捕捉跨模态的互补信息，为生理信号提供一种连贯的“通用语言”。

Result: 通过将ProtoMM应用于Pulse Motion基础模型的开发，实验结果表明，该方法在性能上优于仅使用对比学习和先前多模态自监督学习方法，达到了最先进的性能，并提高了学习特征的可解释性。

Conclusion: ProtoMM通过其创新的原型字典方法，成功地解决了多模态时间序列数据表示学习中的挑战，为生物信号分析提供了更优越、更具可解释性的解决方案。

Abstract: Modeling multi-modal time-series data is critical for capturing system-level
dynamics, particularly in biosignals where modalities such as ECG, PPG, EDA,
and accelerometry provide complementary perspectives on interconnected
physiological processes. While recent self-supervised learning (SSL) advances
have improved unimodal representation learning, existing multi-modal approaches
often rely on CLIP-style contrastive objectives that overfit to easily aligned
features and misclassify valid cross-modal relationships as negatives,
resulting in fragmented and non-generalizable embeddings. To overcome these
limitations, we propose ProtoMM, a novel SSL framework that introduces a shared
prototype dictionary to anchor heterogeneous modalities in a common embedding
space. By clustering representations around shared prototypes rather than
explicit negative sampling, our method captures complementary information
across modalities and provides a coherent "common language" for physiological
signals. In this work, we focus on developing a Pulse Motion foundation model
with ProtoMM and demonstrate that our approach outperforms contrastive-only and
prior multimodal SSL methods, achieving state-of-the-art performance while
offering improved interpretability of learned features.

</details>


### [683] [Robust Photoplethysmography Signal Denoising via Mamba Networks](https://arxiv.org/abs/2510.11058)
*I Chiu,Yu-Tung Liu,Kuan-Chen Wang,Hung-Yu Wei,Yu Tsao*

Main category: cs.LG

TL;DR: DPNet是一个基于Mamba的PPG去噪框架，通过SI-SDR损失和HR监督来提高信号保真度和生理一致性，在去除噪声和运动伪影方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PPG信号在可穿戴健康监测中应用广泛，但易受噪声和运动伪影干扰，限制了心率（HR）等下游应用。现有方法在保持生理信息方面存在不足。

Method: 提出DPNet，一个基于Mamba的去噪模型，并结合SI-SDR损失函数以提高波形保真度，同时引入HR预测器进行基于HR的监督，以保证生理信号的一致性。

Result: 在BIDMC数据集上，DPNet在合成噪声和真实运动伪影下表现出强大的鲁棒性，优于传统滤波和现有神经网络模型，能够有效恢复PPG信号并保持HR准确性。

Conclusion: DPNet结合SI-SDR损失和HR监督的方法在PPG去噪方面有效，展现了其在可穿戴医疗系统实际部署的潜力。

Abstract: Photoplethysmography (PPG) is widely used in wearable health monitoring, but
its reliability is often degraded by noise and motion artifacts, limiting
downstream applications such as heart rate (HR) estimation. This paper presents
a deep learning framework for PPG denoising with an emphasis on preserving
physiological information. In this framework, we propose DPNet, a Mamba-based
denoising backbone designed for effective temporal modeling. To further enhance
denoising performance, the framework also incorporates a scale-invariant
signal-to-distortion ratio (SI-SDR) loss to promote waveform fidelity and an
auxiliary HR predictor (HRP) that provides physiological consistency through
HR-based supervision. Experiments on the BIDMC dataset show that our method
achieves strong robustness against both synthetic noise and real-world motion
artifacts, outperforming conventional filtering and existing neural models. Our
method can effectively restore PPG signals while maintaining HR accuracy,
highlighting the complementary roles of SI-SDR loss and HR-guided supervision.
These results demonstrate the potential of our approach for practical
deployment in wearable healthcare systems.

</details>


### [684] [HeSRN: Representation Learning On Heterogeneous Graphs via Slot-Aware Retentive Network](https://arxiv.org/abs/2510.09767)
*Yifan Lu,Ziyun Zou,Belal Alsinglawi,Islam Al-Qudah,Izzat Alsmadi,Feilong Tang,Pengfei Jiao,Shoaib Jameel*

Main category: cs.LG

TL;DR: HeSRN通过解耦节点类型语义、使用基于注意力的编码器以及多尺度注意力层来解决Graph Transformers在异构图上的计算复杂性和语义建模限制，在节点分类任务上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: Graph Transformers在捕捉图的长期依赖性方面取得了显著进展，但在处理现实世界中的异构图时，其二次计算复杂性和对异构语义建模的不足限制了其可扩展性和泛化能力。

Method: 提出了一种新颖的异构图感知保留网络（HeSRN），它引入了一个显式解耦节点类型语义的感知结构编码器，并通过基于注意力的编码器取代自注意力机制来处理线性的计算复杂性。此外，使用异构感知编码器通过多尺度注意力层来捕获局部结构信号和全局异构语义。

Result: HeSRN在四个真实世界的异构图数据集上的节点分类任务中，始终优于最先进的异构图神经网络和Graph Transformer基线模型，在显著降低计算复杂性的同时提高了准确性。

Conclusion: HeSRN通过其新颖的结构，在效率和表达能力方面都优于现有的方法，为异构图表示学习提供了一个有前途的方向。

Abstract: Graph Transformers have recently achieved remarkable progress in graph
representation learning by capturing long-range dependencies through
self-attention. However, their quadratic computational complexity and inability
to effectively model heterogeneous semantics severely limit their scalability
and generalization on real-world heterogeneous graphs. To address these issues,
we propose HeSRN, a novel Heterogeneous Slot-aware Retentive Network for
efficient and expressive heterogeneous graph representation learning. HeSRN
introduces a slot-aware structure encoder that explicitly disentangles
node-type semantics by projecting heterogeneous features into independent slots
and aligning their distributions through slot normalization and retention-based
fusion, effectively mitigating the semantic entanglement caused by forced
feature-space unification in previous Transformer-based models. Furthermore, we
replace the self-attention mechanism with a retention-based encoder, which
models structural and contextual dependencies in linear time complexity while
maintaining strong expressive power. A heterogeneous retentive encoder is
further employed to jointly capture both local structural signals and global
heterogeneous semantics through multi-scale retention layers. Extensive
experiments on four real-world heterogeneous graph datasets demonstrate that
HeSRN consistently outperforms state-of-the-art heterogeneous graph neural
networks and Graph Transformer baselines on node classification tasks,
achieving superior accuracy with significantly lower computational complexity.

</details>


### [685] [Learning the Structure of Connection Graphs](https://arxiv.org/abs/2510.11245)
*Leonardo Di Nino,Gabriele D'Acunto,Sergio Barbarossa,Paolo Di Lorenzo*

Main category: cs.LG

TL;DR: 从观测信号中学习连接图（CG）。


<details>
  <summary>Details</summary>
Motivation: CG在同步、黎曼信号处理和神经层扩散等应用中发挥着关键作用。本研究旨在解决从观测信号中学习CG的反问题。

Method: 提出了一种基于最大伪似然和一致性假设的框架，强制执行连接拉普拉斯算子和组合拉普拉斯算子之间的谱性质。基于此，引入了结构化连接图学习（SCGL）算法，这是一种在黎曼流形上进行的块优化过程，可联合推断网络拓扑、边权重和几何结构。

Result: SCGL在拓扑恢复和几何保真度方面持续优于现有基线，同时保持计算效率。

Conclusion: SCGL是一种有效的学习连接图（CG）的方法，可用于需要表示全局几何一致性的各种应用。

Abstract: Connection graphs (CGs) extend traditional graph models by coupling network
topology with orthogonal transformations, enabling the representation of global
geometric consistency. They play a key role in applications such as
synchronization, Riemannian signal processing, and neural sheaf diffusion. In
this work, we address the inverse problem of learning CGs directly from
observed signals. We propose a principled framework based on maximum
pseudo-likelihood under a consistency assumption, which enforces spectral
properties linking the connection Laplacian to the underlying combinatorial
Laplacian. Based on this formulation, we introduce the Structured Connection
Graph Learning (SCGL) algorithm, a block-optimization procedure over Riemannian
manifolds that jointly infers network topology, edge weights, and geometric
structure. Our experiments show that SCGL consistently outperforms existing
baselines in both topological recovery and geometric fidelity, while remaining
computationally efficient.

</details>


### [686] [Scaling Laws and Symmetry, Evidence from Neural Force Fields](https://arxiv.org/abs/2510.09768)
*Khang Ngo,Siamak Ravanbakhsh*

Main category: cs.LG

TL;DR: 等变架构在更大规模上比非等变模型具有更好的可扩展性，并且等变架构中的更高阶表示可以提高可扩展性。数据和模型大小应同步扩展以实现计算最优的训练。


<details>
  <summary>Details</summary>
Motivation: 评估对称性等归纳偏见在更大规模上的重要性，并研究其对模型可扩展性的影响。

Method: 对学习原子间势能的几何任务进行了实证研究，重点分析了等变和非等变模型在数据、参数和计算方面的可扩展性行为，并研究了不同阶数的表示对可扩展性的影响。

Result: 等变架构比非等变模型具有更好的可扩展性，表现出明显的幂律缩放行为。更高阶的表示可以进一步提高可扩展性。为了实现计算最优的训练，数据和模型的大小应同步扩展。

Conclusion: 应在模型训练中明确纳入对称性等归纳偏见，尤其是在大规模场景下，因为它们会影响任务的固有难度和缩放定律。不应期望模型自行发现这些偏见。

Abstract: We present an empirical study in the geometric task of learning interatomic
potentials, which shows equivariance matters even more at larger scales; we
show a clear power-law scaling behaviour with respect to data, parameters and
compute with ``architecture-dependent exponents''. In particular, we observe
that equivariant architectures, which leverage task symmetry, scale better than
non-equivariant models. Moreover, among equivariant architectures, higher-order
representations translate to better scaling exponents. Our analysis also
suggests that for compute-optimal training, the data and model sizes should
scale in tandem regardless of the architecture. At a high level, these results
suggest that, contrary to common belief, we should not leave it to the model to
discover fundamental inductive biases such as symmetry, especially as we scale,
because they change the inherent difficulty of the task and its scaling laws.

</details>


### [687] [A Generic Machine Learning Framework for Radio Frequency Fingerprinting](https://arxiv.org/abs/2510.09775)
*Alex Hiles,Bashar I. Ahmad*

Main category: cs.LG

TL;DR: 本文提出了一种通用的机器学习框架，用于射频指纹识别及其在信号情报、电子监控和无线通信设备物理层认证等领域的应用。


<details>
  <summary>Details</summary>
Motivation: 传统的射频指纹识别方法耗时、不灵活且仅适用于特定发射器或传输方案，因此需要更优的方法。数据驱动的方法在自动学习复杂指纹方面表现出巨大潜力。

Method: 提出一个通用的机器学习框架，将射频指纹识别、特定发射器识别 (SEI)、发射器数据关联 (EDA) 和射频发射器聚类 (RFEC) 等下游任务都构建为依赖于射频指纹识别的任务。

Result: 在包括太空监视、信号情报和反无人机在内的各种应用场景中，使用真实的射频数据集演示了该框架的多功能性。

Conclusion: 所提出的通用机器学习框架能够有效处理多种射频指纹识别任务，并在实际应用中展现出优越的性能。

Abstract: Fingerprinting Radio Frequency (RF) emitters typically involves finding
unique emitter characteristics that are featured in their transmitted signals.
These fingerprints are nuanced but sufficiently detailed, motivating the
pursuit of methods that can successfully extract them. The most granular
downstream task is known as Specific Emitter Identification (SEI), which
requires a well informed RF fingerprinting (RFF) approach for it to be
successful. RFF and SEI have a long history, with numerous application areas in
defence and civilian contexts such as signal intelligence, electronic
surveillance, physical-layer authentication of wireless communication devices,
to name a few. RFF methods also support many other downstream tasks such as
Emitter Data Association (EDA) and RF Emitter Clustering (RFEC) and are
applicable to a range of transmission types. In recent years, data-driven
approaches have become popular in the RFF domain due to their ability to
automatically learn intricate fingerprints from raw data. These methods
generally deliver superior performance when compared to traditional techniques.
The more traditional approaches are often labour-intensive, inflexible and only
applicable to a particular emitter type or transmission scheme. Therefore, we
consider data-driven Machine Learning (ML)-enabled RFF. In particular, we
propose a generic framework for ML-enabled RFF which is inclusive of several
popular downstream tasks such as SEI, EDA and RFEC. Each task is formulated as
a RF fingerprint-dependent task. A variety of use cases using real RF datasets
are presented here to demonstrate the framework for a range of tasks and
application areas, such as spaceborne surveillance, signal intelligence and
countering drones.

</details>


### [688] [Why Do Transformers Fail to Forecast Time Series In-Context?](https://arxiv.org/abs/2510.09776)
*Yufa Zhou,Yixiao Wang,Surbhi Goel,Anru R. Zhang*

Main category: cs.LG

TL;DR: Transformer模型在时间序列预测（TSF）任务中难以超越简单线性模型，本文从 in-context learning (ICL) 理论角度进行理论分析，证明了线性自注意力（LSA）模型无法在预期均方误差（MSE）上优于线性模型，且在特定条件下会收敛于均值。


<details>
  <summary>Details</summary>
Motivation: 现有研究在时间序列预测（TSF）任务中，尽管大量使用基于 Transformer 的大语言模型（LLMs），但这类模型在实践中常常无法超越简单的线性模型。然而，对于这种现象的深入理论理解仍然有限。

Method: 本文采用 in-context learning (ICL) 理论，在 AR(p) 数据模型下，对 Transformer 的局限性进行了理论分析。

Result: 1. 线性自注意力（LSA）模型在预期 MSE 方面无法优于经典的线性模型； 2. 当上下文长度趋于无穷时，LSA 渐近地逼近最优线性预测器； 3. 在 Chain-of-Thought (CoT) 推理下，预测会指数级地衰减到均值。这些发现已通过实验得到验证。

Conclusion: 本文的理论分析揭示了 Transformer 在 TSF 任务中的局限性，并为设计更有效的预测模型提供了实践指导，鼓励研究界重新审视 TSF 的基本理论限制，并批判性地评估复杂模型直接应用的有效性。

Abstract: Time series forecasting (TSF) remains a challenging and largely unsolved
problem in machine learning, despite significant recent efforts leveraging
Large Language Models (LLMs), which predominantly rely on Transformer
architectures. Empirical evidence consistently shows that even powerful
Transformers often fail to outperform much simpler models, e.g., linear models,
on TSF tasks; however, a rigorous theoretical understanding of this phenomenon
remains limited. In this paper, we provide a theoretical analysis of
Transformers' limitations for TSF through the lens of In-Context Learning (ICL)
theory. Specifically, under AR($p$) data, we establish that: (1) Linear
Self-Attention (LSA) models $\textit{cannot}$ achieve lower expected MSE than
classical linear models for in-context forecasting; (2) as the context length
approaches to infinity, LSA asymptotically recovers the optimal linear
predictor; and (3) under Chain-of-Thought (CoT) style inference, predictions
collapse to the mean exponentially. We empirically validate these findings
through carefully designed experiments. Our theory not only sheds light on
several previously underexplored phenomena but also offers practical insights
for designing more effective forecasting architectures. We hope our work
encourages the broader research community to revisit the fundamental
theoretical limitations of TSF and to critically evaluate the direct
application of increasingly sophisticated architectures without deeper
scrutiny.

</details>


### [689] [SVTime: Small Time Series Forecasting Models Informed by "Physics" of Large Vision Model Forecasters](https://arxiv.org/abs/2510.09780)
*ChengAo Shen,Ziming Zhao,Hanghang Tong,Dongjin Song,Dongsheng Luo,Qingsong Wen,Jingchao Ni*

Main category: cs.LG

TL;DR: SVTime 是一种新型轻量级时间序列预测模型，它借鉴了大型视觉模型（LVM）的思想，可以在保证高性能的同时，大大减少参数量和计算资源，适用于资源受限的场景。


<details>
  <summary>Details</summary>
Motivation: 大型预训练模型在时间序列分析中表现出色，但其高昂的训练和推理成本引发了对碳足迹和可持续性的担忧。因此，有必要研究如何构建高性能且成本效益高的轻量级模型，特别是对于资源受限的用户。

Method: SVTime 通过识别大型视觉模型（LVM）在长期时间序列预测（LTSF）中的关键归纳偏置，并设计能够编码这些偏置的轻量级模型。具体方法包括精心设计的线性层和约束函数，以模仿 LVM 的行为。

Result: SVTime 在 8 个基准数据集的 21 个模型（包括轻量级、复杂和预训练的大型模型）的比较中，表现优于最先进的轻量级模型，并且性能可与大型模型相媲美，但参数量却减少了 1000 倍，同时实现了高效的训练和推理。

Conclusion: SVTime 成功地证明了可以构建出性能媲美大型模型但参数量和资源消耗大大降低的轻量级时间序列预测模型，为资源受限的用户提供了更经济实惠且可持续的解决方案。

Abstract: Time series AI is crucial for analyzing dynamic web content, driving a surge
of pre-trained large models known for their strong knowledge encoding and
transfer capabilities across diverse tasks. However, given their
energy-intensive training, inference, and hardware demands, using large models
as a one-fits-all solution raises serious concerns about carbon footprint and
sustainability. For a specific task, a compact yet specialized, high-performing
model may be more practical and affordable, especially for resource-constrained
users such as small businesses. This motivates the question: Can we build
cost-effective lightweight models with large-model-like performance on core
tasks such as forecasting? This paper addresses this question by introducing
SVTime, a novel Small model inspired by large Vision model (LVM) forecasters
for long-term Time series forecasting (LTSF). Recently, LVMs have been shown as
powerful tools for LTSF. We identify a set of key inductive biases of LVM
forecasters -- analogous to the "physics" governing their behaviors in LTSF --
and design small models that encode these biases through meticulously crafted
linear layers and constraint functions. Across 21 baselines spanning
lightweight, complex, and pre-trained large models on 8 benchmark datasets,
SVTime outperforms state-of-the-art (SOTA) lightweight models and rivals large
models with 10^3 fewer parameters than LVMs, while enabling efficient training
and inference in low-resource settings.

</details>


### [690] [Building a Foundational Guardrail for General Agentic Systems via Synthetic Data](https://arxiv.org/abs/2510.09781)
*Yue Huang,Hang Hua,Yujun Zhou,Pengcheng Jing,Manish Nagireddy,Inkit Padhi,Greta Dolcetti,Zhangchen Xu,Subhajit Chaudhury,Ambrish Rawat,Liubov Nedoshivina,Pin-Yu Chen,Prasanna Sattigeri,Xiangliang Zhang*

Main category: cs.LG

TL;DR: LLM代理在执行前进行干预是最安全的防止风险的方式，但现有方法大多在执行后干预，难以扩展且无法在计划层面进行可控监督。本文提出了AuraGen用于生成安全数据，Safiron用于构建基础护栏，以及Pre-Exec Bench用于评估，以弥合数据、模型和评估方面的差距，实现更安全的代理系统。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的安全护栏大多在执行后进行干预，难以扩展且无法在计划层面进行可控监督，可能导致严重后果。需要一种在执行前进行干预的安全机制。

Method: 1. AuraGen：一个可控引擎，用于合成良性轨迹，注入带标签的风险，并使用奖励模型过滤输出来生成大规模、可靠的预执行安全数据集。 2. Safiron：一个基础护栏模型，结合了跨规划器适配器和紧凑的守护模型，用于识别风险、分类风险类型并生成解释。 3. Pre-Exec Bench：一个包含多样化工具和分支轨迹的基准测试，用于评估检测、细粒度分类、解释和跨规划器泛化能力。

Result: 所提出的Safiron护栏在Pre-Exec Bench基准测试上相比现有方法取得了显著的提升，并且通过消融实验提炼出了可行的实践方法。

Conclusion: 通过引入AuraGen、Safiron和Pre-Exec Bench，本文成功弥合了LLM代理预执行安全领域的数据、模型和评估差距，为构建更安全的代理系统提供了一个实用的模板。Safiron在评估基准上表现出一致的优势，表明其有效性。

Abstract: While LLM agents can plan multi-step tasks, intervening at the planning
stage-before any action is executed-is often the safest way to prevent harm,
since certain risks can lead to severe consequences once carried out. However,
existing guardrails mostly operate post-execution, which is difficult to scale
and leaves little room for controllable supervision at the plan level. To
address this challenge, we highlight three critical gaps in current research:
data gap, model gap, and evaluation gap. To close the data gap, we introduce
AuraGen, a controllable engine that (i) synthesizes benign trajectories, (ii)
injects category-labeled risks with calibrated difficulty, and (iii) filters
outputs via an automated reward model, producing large and reliable corpora for
pre-execution safety. To close the guardian model gap, we propose a
foundational guardrail Safiron, combining a cross-planner adapter with a
compact guardian model. The adapter unifies different input formats, while
Safiron flags risky cases, assigns risk types, and generates rationales;
trained in two stages with a broadly explored data recipe, Safiron achieves
robust transfer across settings. To close the evaluation gap, we release
Pre-Exec Bench, a realistic benchmark covering diverse tools and branching
trajectories, which measures detection, fine-grained categorization,
explanation, and cross-planner generalization in human-verified scenarios.
Extensive experiments demonstrate consistent gains of the proposed guardrail
over strong baselines on Pre-Exec Bench, and ablations further distill
actionable practices, providing a practical template for safer agentic systems.

</details>


### [691] [Large Language Models for Imbalanced Classification: Diversity makes the difference](https://arxiv.org/abs/2510.09783)
*Dang Nguyen,Sunil Gupta,Kien Do,Thin Nguyen,Taylor Braund,Alexis Whitton,Svetha Venkatesh*

Main category: cs.LG

TL;DR: 提出一种新的基于大语言模型（LLM）的过采样方法，通过条件化采样和插值样本增强生成样本的多样性，并在10个表格数据集上实现显著优于8个SOTA基线的结果。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的过采样方法生成的少数类样本多样性有限，影响了下游分类任务的鲁棒性和泛化能力。

Method: 1. 引入一种条件化采样策略，同时基于少数类标签和特征生成合成样本。 2. 开发一种新的排列策略用于微调预训练LLM。 3. 在少数类样本和插值样本上同时微调LLM，以丰富生成样本的多样性。

Result: 在10个表格数据集上的广泛实验表明，该方法显著优于8个SOTA基线方法，生成的合成样本真实且多样。通过基于熵的理论分析证明了该方法鼓励生成样本的多样性。

Conclusion: 该新颖的基于LLM的过采样方法通过增强生成样本的多样性，能够有效提升不平衡分类任务的性能。

Abstract: Oversampling is one of the most widely used approaches for addressing
imbalanced classification. The core idea is to generate additional minority
samples to rebalance the dataset. Most existing methods, such as SMOTE, require
converting categorical variables into numerical vectors, which often leads to
information loss. Recently, large language model (LLM)-based methods have been
introduced to overcome this limitation. However, current LLM-based approaches
typically generate minority samples with limited diversity, reducing robustness
and generalizability in downstream classification tasks. To address this gap,
we propose a novel LLM-based oversampling method designed to enhance diversity.
First, we introduce a sampling strategy that conditions synthetic sample
generation on both minority labels and features. Second, we develop a new
permutation strategy for fine-tuning pre-trained LLMs. Third, we fine-tune the
LLM not only on minority samples but also on interpolated samples to further
enrich variability. Extensive experiments on 10 tabular datasets demonstrate
that our method significantly outperforms eight SOTA baselines. The generated
synthetic samples are both realistic and diverse. Moreover, we provide
theoretical analysis through an entropy-based perspective, proving that our
method encourages diversity in the generated samples.

</details>


### [692] [Combined Representation and Generation with Diffusive State Predictive Information Bottleneck](https://arxiv.org/abs/2510.09784)
*Richard John,Yunrui Qiu,Lukas Herron,Pratyush Tiwary*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generative modeling becomes increasingly data-intensive in high-dimensional
spaces. In molecular science, where data collection is expensive and important
events are rare, compression to lower-dimensional manifolds is especially
important for various downstream tasks, including generation. We combine a
time-lagged information bottleneck designed to characterize molecular important
representations and a diffusion model in one joint training objective. The
resulting protocol, which we term Diffusive State Predictive Information
Bottleneck (D-SPIB), enables the balancing of representation learning and
generation aims in one flexible architecture. Additionally, the model is
capable of combining temperature information from different molecular
simulation trajectories to learn a coherent and useful internal representation
of thermodynamics. We benchmark D-SPIB on multiple molecular tasks and showcase
its potential for exploring physical conditions outside the training set.

</details>


### [693] [Principled Operator Learning in Ocean Dynamics: The Role of Temporal Structure](https://arxiv.org/abs/2510.09792)
*Vahidreza Jahanmard,Ali Ramezani-Kebrya,Robinson Hordoir*

Main category: cs.LG

TL;DR: 通过引入时间傅里叶模式，修改后的傅里叶神经算子 (FNOtD) 提高了高分辨率海洋预测的物理保真度、长期预测稳定性和与物理动力学的一致性，同时计算成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子在天气和海洋预报中学习偏微分方程（PDE）解方面虽然有前景，但在长期预测稳定性和遵守物理定律（特别是高频过程）方面仍面临挑战。

Method: 本文提出了一种修改后的傅里叶神经算子 (FNOtD)，通过在积分核的训练中结合空间和时间傅里叶模式，使其能够内化色散关系，从而学习海洋PDE的解算子。

Result: FNOtD 在高频设置下，与标准 FNO 相比，能够更好地捕捉多尺度波动传播，更有效地学习海洋动力学，显著提高了长期预测稳定性和与物理动力学的相符性。此外，其预测能力可与最先进的数值海洋模型相媲美，但计算成本却大大降低。

Conclusion: 将空间和时间在积分核的训练中进行纠缠，能够使模型捕捉多尺度波动传播并有效地学习海洋动力学。FNOtD 在具有挑战性的高频设置下，相比标准的 FNO，能显著提高长期预测的稳定性和与基础物理动力学的一致性，并且在计算成本显著降低的情况下，提供了与最先进的数值海洋模型相竞争的预测能力。

Abstract: Neural operators are becoming the default tools to learn solutions to
governing partial differential equations (PDEs) in weather and ocean
forecasting applications. Despite early promising achievements, significant
challenges remain, including long-term prediction stability and adherence to
physical laws, particularly for high-frequency processes. In this paper, we
take a step toward addressing these challenges in high-resolution ocean
prediction by incorporating temporal Fourier modes, demonstrating how this
modification enhances physical fidelity. This study compares the standard
Fourier Neural Operator (FNO) with its variant, FNOtD, which has been modified
to internalize the dispersion relation while learning the solution operator for
ocean PDEs. The results demonstrate that entangling space and time in the
training of integral kernels enables the model to capture multiscale wave
propagation and effectively learn ocean dynamics. FNOtD substantially improves
long-term prediction stability and consistency with underlying physical
dynamics in challenging high-frequency settings compared to the standard FNO.
It also provides competitive predictive skill relative to a state-of-the-art
numerical ocean model, while requiring significantly lower computational cost.

</details>


### [694] [Causality $\neq$ Decodability, and Vice Versa: Lessons from Interpreting Counting ViTs](https://arxiv.org/abs/2510.09794)
*Lianghuan Huang,Yingshan Chang*

Main category: cs.LG

TL;DR: 本文研究了视觉Transformer（ViTs）中可译性、可解码性和因果性的关系，发现在中间层，物体token具有很强的因果作用但可解码性较弱，而在最终层，物体token的可解码性很强但因果作用较弱。CLS token也是如此，在中间层可解码但在最终层才获得因果作用。这表明可解码性和因果性反映了表示的互补维度（信息存在与否 vs. 信息使用情况），并且它们的分歧可以揭示隐藏的计算电路。


<details>
  <summary>Details</summary>
Motivation: 视觉Transformer（ViTs）中的机制可译性旨在揭示其内部组件如何产生预测。然而，长期存在的挑战是区分可解码性（从隐藏状态中恢复信息）和因果性（这些状态在功能上对输出的影响程度）这两个经常被混淆的概念。

Method: 使用激活修复技术，测试了空间和CLS token在对象计数任务中在视觉Transformer（ViTs）中的因果作用，通过在干净-损坏的图像对之间移植激活。同时，训练线性探针来评估不同深度的计数量信息的解码能力。

Result: 研究结果显示出系统性的不匹配：中间层的物体token具有很强的因果作用，但可解码性较弱；而最终层的物体token具有准确的解码能力，但功能上是惰性的。类似地，CLS token在中层变得可解码，但在最终层才获得因果作用。

Conclusion: 可解码性和因果性反映了表示的互补维度——即存在哪些信息以及这些信息被如何使用。它们之间的分歧可以揭示隐藏的计算电路。

Abstract: Mechanistic interpretability seeks to uncover how internal components of
neural networks give rise to predictions. A persistent challenge, however, is
disentangling two often conflated notions: decodability--the recoverability of
information from hidden states--and causality--the extent to which those states
functionally influence outputs. In this work, we investigate their relationship
in vision transformers (ViTs) fine-tuned for object counting. Using activation
patching, we test the causal role of spatial and CLS tokens by transplanting
activations across clean-corrupted image pairs. In parallel, we train linear
probes to assess the decodability of count information at different depths. Our
results reveal systematic mismatches: middle-layer object tokens exert strong
causal influence despite being weakly decodable, whereas final-layer object
tokens support accurate decoding yet are functionally inert. Similarly, the CLS
token becomes decodable in mid-layers but only acquires causal power in the
final layers. These findings highlight that decodability and causality reflect
complementary dimensions of representation--what information is present versus
what is used--and that their divergence can expose hidden computational
circuits.

</details>


### [695] [Temporal Lifting as Latent-Space Regularization for Continuous-Time Flow Models in AI Systems](https://arxiv.org/abs/2510.09805)
*Jeffrey Camlin*

Main category: cs.LG

TL;DR: 提出了一种名为“时间提升”的潜在空间自适应时间重参数化方法，用于处理连续时间动力学系统。


<details>
  <summary>Details</summary>
Motivation: 解决连续时间动力系统中的近奇异行为，同时保持守恒律，并稳定基于物理信息神经网络和其他潜在流架构的机器学习模型。

Method: 引入一个平滑单调映射 $t ightarrow 	au(t)$，在“提升”坐标中使轨迹（如 $f{T}^3$ 上的不可压缩 Navier-Stokes 方程）全局光滑。

Result: 时间提升作为一种连续时间归一化或时间扭曲算子，可以稳定物理信息神经网络和其他潜在流架构。

Conclusion: 该框架将解析正则性理论与用于处理刚性或湍流过程的表征学习方法联系起来。

Abstract: We present a latent-space formulation of adaptive temporal reparametrization
for continuous-time dynamical systems. The method, called *temporal lifting*,
introduces a smooth monotone mapping $t \mapsto \tau(t)$ that regularizes
near-singular behavior of the underlying flow while preserving its conservation
laws. In the lifted coordinate, trajectories such as those of the
incompressible Navier-Stokes equations on the torus $\mathbb{T}^3$ become
globally smooth. From the standpoint of machine-learning dynamics, temporal
lifting acts as a continuous-time normalization or time-warping operator that
can stabilize physics-informed neural networks and other latent-flow
architectures used in AI systems. The framework links analytic regularity
theory with representation-learning methods for stiff or turbulent processes.

</details>


### [696] [An Exploration of Non-Euclidean Gradient Descent: Muon and its Many Variants](https://arxiv.org/abs/2510.09827)
*Michael Crawshaw,Chirag Modi,Mingrui Liu,Robert M. Gower*

Main category: cs.LG

TL;DR: Muon和Momo的变体比Muon更鲁棒，并且通常能获得更好的验证分数。


<details>
  <summary>Details</summary>
Motivation: 为了在神经网络上定义最速下降法，我们需要为每一层选择一个范数，一种跨层聚合这些范数的方法，以及是否使用归一化。我们系统地探索了跨层聚合范数的不同选择。

Method: 将Adam和Muon的形式化为一种非欧几里得梯度下降，并推导了Muon优化器的新变体。通过对我们框架内的优化器进行全面的实验评估，我们发现Muon对学习率的选择很敏感，而我们称之为MuonMax的新变体则更加鲁棒。然后，我们展示了如何将任何非欧几里得梯度方法与基于模型的动量（称为Momo）相结合。

Result: Muon对学习率的选择很敏感，而MuonMax则更加鲁棒。Momo的Muon变体在超参数调整方面明显更加鲁棒，并且通常能获得更好的验证分数。

Conclusion: 对于不知道最优超参数的新任务，我们主张将Momo与MuonMax结合使用，以节省昂贵的超参数调整。

Abstract: To define a steepest descent method over a neural network, we need to choose
a norm for each layer, a way to aggregate these norms across layers, and
whether to use normalization. We systematically explore different alternatives
for aggregating norms across layers, both formalizing existing combinations of
Adam and the recently proposed Muon as a type of non-Euclidean gradient
descent, and deriving new variants of the Muon optimizer. Through a
comprehensive experimental evaluation of the optimizers within our framework,
we find that Muon is sensitive to the choice of learning rate, whereas a new
variant we call MuonMax is significantly more robust. We then show how to
combine any non-Euclidean gradient method with model based momentum (known as
Momo). The new Momo variants of Muon are significantly more robust to
hyperparameter tuning, and often achieve a better validation score. Thus for
new tasks, where the optimal hyperparameters are not known, we advocate for
using Momo in combination with MuonMax to save on costly hyperparameter tuning.

</details>


### [697] [Harnessing Self-Supervised Deep Learning and Geostationary Remote Sensing for Advancing Wildfire and Associated Air Quality Monitoring: Improved Smoke and Fire Front Masking using GOES and TEMPO Radiance Data](https://arxiv.org/abs/2510.09845)
*Nicholas LaHaye,Thilanka Munashinge,Hugo Lee,Xiaohua Pan,Gonzalo Gonzalez Abad,Hazem Mahmoud,Jennifer Wei*

Main category: cs.LG

TL;DR: 利用NASA TEMPO卫星和自监督深度学习技术，改善美国西部野火和空气质量管理。


<details>
  <summary>Details</summary>
Motivation: 为了改善美国西部地区的野火和空气质量管理，利用NASA TEMPO卫星前所未有的一小时数据和自监督深度学习的进展。

Method: 采用创新的自监督深度学习系统，演示了深度学习在近乎实时地描绘野火前线和烟羽扩散方面的有效性，并结合了GOES-18和TEMPO的数据来区分烟羽和云。

Result: 成功区分了烟羽和云，并显示了不同传感模式生成的烟羽和火灾掩膜之间的高度一致性，在针对相同案例的评估中，相比现有运行产品有显著提升。

Conclusion: 该研究证明了结合TEMPO卫星数据和自监督深度学习在改进野火和空气质量监测方面的巨大潜力。

Abstract: This work demonstrates the possibilities for improving wildfire and air
quality management in the western United States by leveraging the unprecedented
hourly data from NASA's TEMPO satellite mission and advances in self-supervised
deep learning. Here we demonstrate the efficacy of deep learning for mapping
the near real-time hourly spread of wildfire fronts and smoke plumes using an
innovative self-supervised deep learning-system: successfully distinguishing
smoke plumes from clouds using GOES-18 and TEMPO data, strong agreement across
the smoke and fire masks generated from different sensing modalities as well as
significant improvement over operational products for the same cases.

</details>


### [698] [CALM: A Causal Analysis Language Model for Tabular Data in Complex Systems with Local Scores, Conditional Independence Tests, and Relation Attributes](https://arxiv.org/abs/2510.09846)
*Zhenjiang Fan,Zengyi Qin,Yuanning Zheng,Bo Xiong,Summer Han*

Main category: cs.LG

TL;DR: CALM是一个用于处理表格数据的因果分析语言模型，它克服了现有方法的局限性，并在模拟和真实世界数据中表现出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的因果发现方法在处理观测数据时存在无法确定因果方向、仅限于线性关系、对忠实性假设敏感以及搜索效率低下等局限性。虽然大型语言模型（LLM）具有强大的推理能力，但它们主要用于文本，而因果数据通常是表格形式，这阻碍了它们在该领域的应用。

Method: CALM是一个新颖的因果分析语言模型，专门为复杂系统中的表格数据而设计。它采用基于Mamba的架构，通过对成对变量关系进行分类来识别因果模式。该模型整合了包括局部因果评分、条件独立性检验和关系属性在内的多种证据，以捕捉广泛的线性、非线性以及条件因果机制。CALM在多样化的合成数据（包括线性、混合和非线性模型）以及10个具有经过严格验证的因果关系的真实世界生物学数据集上进行了训练。

Result: 在模拟研究中，CALM的准确率超过91%，显著优于现有方法。在真实世界的应用中，CALM成功识别了丙型肝炎病毒（HCV）进展的因果因素。

Conclusion: CALM通过成功地将语言模型的模式识别能力应用于表格数据的复杂性，在实现准确且可泛化的因果发现方面迈出了重要一步。

Abstract: Causal discovery from observational data is fundamental to scientific fields
like biology, where controlled experiments are often impractical. However,
existing methods, including constraint-based (e.g., PC, causalMGM) and
score-based approaches (e.g., NOTEARS), face significant limitations. These
include an inability to resolve causal direction, restrictions to linear
associations, sensitivity to violations of the faithfulness assumption, and
inefficiency in searching vast hypothesis spaces. While large language models
(LLMs) offer powerful reasoning capabilities, their application is hindered by
a fundamental discrepancy: they are designed for text, while most causal data
is tabular. To address these challenges, we introduce CALM, a novel causal
analysis language model specifically designed for tabular data in complex
systems. CALM leverages a Mamba-based architecture to classify causal patterns
from pairwise variable relationships. It integrates a comprehensive suite of
evidence, including local causal scores, conditional independence tests, and
relational attributes, to capture a wide spectrum of linear, nonlinear, and
conditional causal mechanisms. Trained on a diverse corpus of synthetic data
(from linear, mixed, and nonlinear models) and 10 real-world biological
datasets with rigorously validated causal relationships, our model ensures
robustness and generalizability. Empirical evaluation demonstrates that CALM
significantly outperforms existing methods in both simulation studies,
achieving over 91% accuracy, and in a real-world application identifying causal
factors in Hepatitis C virus progression. This work represents a significant
step towards accurate and generalizable causal discovery by successfully
adapting the pattern recognition capabilities of language models to the
intricacies of tabular data.

</details>


### [699] [ProxRouter: Proximity-Weighted LLM Query Routing for Improved Robustness to Outliers](https://arxiv.org/abs/2510.09852)
*Shivam Patel,Neharika Jali,Ankur Mallick,Gauri Joshi*

Main category: cs.LG

TL;DR: ProxRouter是一种非参数查询路由器，通过指数倾斜聚合机制提高对异常查询的鲁棒性，同时保持准确性且开销极小。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM查询路由器（包括参数和非参数方法）在处理异常查询时存在泛化能力不足的问题，这通常是由于训练集多样性有限所致。

Method: 提出ProxRouter，采用指数倾斜聚合机制来平衡非参数路由器的偏差和方差，从而提高其对异常查询的鲁棒性。

Result: 实验证明，ProxRouter在提高异常查询路由能力的同时，保持了对正常查询的性能，并且只引入了极小的额外开销。

Conclusion: ProxRouter通过一种新颖的聚合机制，有效解决了现有非参数路由器在处理异常查询时的泛化能力不足的问题，是一种高效且鲁棒的LLM查询路由解决方案。

Abstract: Large language model (LLM) query routers are critical to modern AI platforms
as they seek to improve efficiency by assigning inference queries to accurate,
yet low-cost models. Parametric routers typically use trained neural networks
for LLM selection but suffer from retraining and maintenance overheads.
Nonparametric routers are training-free, instead estimating LLM accuracy and
cost via similarity between encodings of the input query and training set
queries. However, like their parametric counterparts, nonparametric routers
struggle to generalize to outlier queries, an issue exacerbated by limited
diversity in training sets which are costly to expand and difficult to keep
current with ever-evolving use cases. We propose ProxRouter, which applies an
exponentially tilted aggregation mechanism to balance bias and variance in
nonparametric routers, improving their robustness to outliers. Experiments show
ProxRouter enhances outlier routing while preserving inlier performance with
minimal overhead.

</details>


### [700] [WARC-Bench: Web Archive Based Benchmark for GUI Subtask Executions](https://arxiv.org/abs/2510.09872)
*Sanjari Srivastava,Gang Li,Cheng Chang,Rishu Garg,Manpreet Kaur,Charlene Y. Lee,Yuezhang Li,Yining Mao,Ignacio Cases,Yanan Xie,Peng Qi*

Main category: cs.LG

TL;DR: WARC-Bench是一个包含438个子任务的网络导航基准，用于评估多模态AI代理，并展示了它对现有模型的挑战性，同时探索了SFT和RLVR的有效性。


<details>
  <summary>Details</summary>
Motivation: 评估和改进AI代理掌握网页子任务的能力，因为这对于稳健的网页规划和导航至关重要，而现有基准未能充分评估这一点。

Method: 创建了一个名为WARC-Bench的新型网页导航基准，其中包含438个子任务，并使用Web ARChive文件在沙盒环境中与动态网页进行交互。探索了监督微调（SFT）和带可验证奖励的强化学习（RLVR）这两种训练技术。

Result: WARC-Bench对领先的计算机使用模型来说是一个挑战，最高成功率为64.8%。SFT模型在此基准上的成功率为48.8%，而使用RLVR在SFT检查点上进行训练可将成功率提高到52.8%。

Conclusion: 掌握子任务对于AI代理的稳健网页规划和导航能力至关重要，WARC-Bench为评估和改进这些能力提供了一个有价值的基准。

Abstract: Training web agents to navigate complex, real-world websites requires them to
master $\textit{subtasks}$ - short-horizon interactions on multiple UI
components (e.g., choosing the correct date in a date picker, or scrolling in a
container to extract information). We introduce WARC-Bench (Web Archive
Benchmark), a novel web navigation benchmark featuring 438 tasks designed to
evaluate multimodal AI agents on subtasks. WARC-Bench enables sandboxed
interactions with dynamic and realistic webpages using Web ARChive files. We
show that WARC-Bench is challenging for leading computer-use models, with the
highest observed success rate being 64.8%. To improve open source models on
subtask, we explore two common training techniques: supervised fine-tuning
(SFT) and reinforcement learning with verifiable rewards (RLVR). Experiments
show that SFT models obtain a 48.8% success rate on the benchmark. Training
with RLVR over SFT checkpoints, even in data-scarce settings, improves the
score to 52.8% on WARC-Bench, outperforming many frontier models. Our analysis
concludes that mastering these subtasks is essential for robust web planning
and navigation, and is a capability not extensively evaluated by existing
benchmarks.

</details>


### [701] [Myopic Bayesian Decision Theory for Batch Active Learning with Partial Batch Label Sampling](https://arxiv.org/abs/2510.09877)
*Kangping Hu,Stephen Mussmann*

Main category: cs.LG

TL;DR: 贝叶斯决策理论（BDT）为主动学习提供了一个统一的原则，派生了如预期误差减少（EER）和预期预测信息增益（EPIG）等算法。为了解决大规模批处理的挑战，提出了用于EPIG的部分批标签采样（ParBaLS），在实验中显示出优于现有方法，特别是在贝叶斯逻辑回归和神经网络嵌入方面。


<details>
  <summary>Details</summary>
Motivation: 解决主动学习中现有算法选择不明确的问题，并为批处理场景提供更有效的解决方案。

Method: 在近视框架下推导贝叶斯决策理论（BDT）用于主动学习，推导出EER、EPIG等算法，并结合渐近近似推导出BAIT。针对大规模批处理问题，提出并推导了部分批标签采样（ParBaLS）用于EPIG算法。

Result: 实验证明，ParBaLS EPIG在固定预算和贝叶斯逻辑回归神经网络嵌入方面，相比现有方法具有更优的性能。

Conclusion: BDT为主动学习提供了一个统一的理论框架，而ParBaLS解决了大规模批处理下的性能挑战，为主动学习提供了更优的算法选择。

Abstract: Over the past couple of decades, many active learning acquisition functions
have been proposed, leaving practitioners with an unclear choice of which to
use. Bayesian Decision Theory (BDT) offers a universal principle to guide
decision-making. In this work, we derive BDT for (Bayesian) active learning in
the myopic framework, where we imagine we only have one more point to label.
This derivation leads to effective algorithms such as Expected Error Reduction
(EER), Expected Predictive Information Gain (EPIG), and other algorithms that
appear in the literature. Furthermore, we show that BAIT (active learning based
on V-optimal experimental design) can be derived from BDT and asymptotic
approximations. A key challenge of such methods is the difficult scaling to
large batch sizes, leading to either computational challenges (BatchBALD) or
dramatic performance drops (top-$B$ selection). Here, using a particular
formulation of the decision process, we derive Partial Batch Label Sampling
(ParBaLS) for the EPIG algorithm. We show experimentally for several datasets
that ParBaLS EPIG gives superior performance for a fixed budget and Bayesian
Logistic Regression on Neural Embeddings. Our code is available at
https://github.com/ADDAPT-ML/ParBaLS.

</details>


### [702] [TAWRMAC: A Novel Dynamic Graph Representation Learning Method](https://arxiv.org/abs/2510.09884)
*Soheila Farokhi,Xiaojun Qi,Hamid Karimi*

Main category: cs.LG

TL;DR: TAWRMAC是一个创新的框架，用于解决动态图表示学习中的嵌入停滞、缺乏上下文感知和无法捕捉结构动态性等问题，通过整合时间匿名行走、记忆增强和邻居共现嵌入，在动态链接预测和节点分类任务上均优于现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的连续时间动态图表示学习方法在处理节点邻域信息整合、邻域相关性捕捉以及图结构动态性方面存在挑战，导致嵌入停滞、上下文感知不足和对动态变化的敏感度不高。

Method: TAWRMAC框架整合了时间匿名行走（带有重启机制）、记忆增强（通过带有时序编码的图神经网络）以及邻居共现嵌入，以增强嵌入的稳定性、上下文表示能力和对结构动态性的捕捉。

Result: 在多个基准数据集上的广泛实验表明，TAWRMAC在动态链接预测和节点分类任务上，无论是在转导（transductive）还是归纳（inductive）设置下，以及在三种不同的负采样策略下，都持续优于最先进的方法。

Conclusion: TAWRMAC通过提供稳定、可泛化且具上下文感知的嵌入，提高了动态图表示学习的水平，尤其是在连续时间动态图学习领域。

Abstract: Dynamic graph representation learning has become essential for analyzing
evolving networks in domains such as social network analysis, recommendation
systems, and traffic analysis. However, existing continuous-time methods face
three key challenges: (1) some methods depend solely on node-specific memory
without effectively incorporating information from neighboring nodes, resulting
in embedding staleness; (2) most fail to explicitly capture correlations
between node neighborhoods, limiting contextual awareness; and (3) many fail to
fully capture the structural dynamics of evolving graphs, especially in absence
of rich link attributes. To address these limitations, we introduce TAWRMAC-a
novel framework that integrates Temporal Anonymous Walks with Restart, Memory
Augmentation, and Neighbor Co-occurrence embedding. TAWRMAC enhances embedding
stability through a memory-augmented GNN with fixedtime encoding and improves
contextual representation by explicitly capturing neighbor correlations.
Additionally, its Temporal Anonymous Walks with Restart mechanism distinguishes
between nodes exhibiting repetitive interactions and those forming new
connections beyond their immediate neighborhood. This approach captures
structural dynamics better and supports strong inductive learning. Extensive
experiments on multiple benchmark datasets demonstrate that TAWRMAC
consistently outperforms state-of-the-art methods in dynamic link prediction
and node classification under both transductive and inductive settings across
three different negative sampling strategies. By providing stable,
generalizable, and context-aware embeddings, TAWRMAC advances the state of the
art in continuous-time dynamic graph learning. The code is available at
https://anonymous.4open.science/r/tawrmac-A253 .

</details>


### [703] [Understanding Robust Machine Learning for Nonparametric Regression with Heavy-Tailed Noise](https://arxiv.org/abs/2510.09888)
*Yunlong Feng,Qiang Wu*

Main category: cs.LG

TL;DR: 在存在重尾噪声的情况下，我们研究鲁棒的非参数回归，其中假设类别可能包含无界函数，并且通过鲁棒损失函数 $\ell_\sigma$ 确保鲁棒性。以 Tikhonov 正则化风险最小化和再生核希尔伯特空间 (RKHS) 中的 Huber 回归为例，我们解决了两个主要挑战：(i) 标准集中工具在弱矩假设下的失效，以及 (ii) 无界假设空间引入的分析困难。我们的第一个信息是概念性的：鲁棒损失的常规泛化误差界不能真实地反映样本外性能。我们认为，学习能力应通过预测误差来量化，即到真值 $f^\star$ 的 $L_2$ 距离，该距离与 $\sigma$ 无关，并直接反映鲁棒估计的目标。为了在无界性下实现这一目标，我们引入了一个概率有效假设空间，该空间以高概率限制了估计器，并在弱 $(1+\epsilon)$ 矩条件下实现了有意义的偏差-方差分解。从技术上讲，我们建立了新的比较定理，将多余的鲁棒风险与 $L_2$ 预测误差联系起来，其残差不超过 $\mathcal{O}(\sigma^{-2\epsilon})$ 的数量级，从而阐明了由尺度参数 $\sigma$ 引起的鲁棒性-偏差权衡。在此基础上，我们在 RKHS 中为 Huber 回归推导了显式的有限样本误差界和收敛率，这些界限在无统一有界性和重尾噪声的条件下成立。我们的研究提供了原则性的调优规则，超出了 Huber 回归的范围，适用于其他鲁棒损失，并强调预测误差（而非多余泛化风险）是分析鲁棒学习的基本视角。


<details>
  <summary>Details</summary>
Motivation: 在存在重尾噪声的情况下，标准集中工具在弱矩假设下会失效，并且无界假设空间会引入分析困难，这使得传统的泛化误差界不能真实地反映鲁棒损失的样本外性能。因此，需要一种新的方法来量化学习能力，并处理这些挑战。

Method: 本文采用 Tikhonov 正则化风险最小化和再生核希尔伯特空间 (RKHS)，以 Huber 回归为例。研究引入了一个概率有效假设空间，以在弱矩条件下实现偏差-方差分解。通过新的比较定理，将多余的鲁棒风险与 $L_2$ 预测误差联系起来，并推导出显式的有限样本误差界和收敛率。

Result: 本文在无统一有界性和重尾噪声的条件下，为 Huber 回归在 RKHS 中推导出了显式的有限样本误差界和收敛率。研究表明，预测误差是分析鲁棒学习的基本视角，并提供了原则性的调优规则，该方法也适用于其他鲁棒损失。

Conclusion: 本文认为，预测误差（而非多余泛化风险）是分析鲁棒学习的基本视角。研究为在存在重尾噪声和无界假设空间的情况下进行鲁棒非参数回归提供了新的理论工具和方法，并为实际应用提供了指导。

Abstract: We investigate robust nonparametric regression in the presence of
heavy-tailed noise, where the hypothesis class may contain unbounded functions
and robustness is ensured via a robust loss function $\ell_\sigma$. Using Huber
regression as a close-up example within Tikhonov-regularized risk minimization
in reproducing kernel Hilbert spaces (RKHS), we address two central challenges:
(i) the breakdown of standard concentration tools under weak moment
assumptions, and (ii) the analytical difficulties introduced by unbounded
hypothesis spaces. Our first message is conceptual: conventional
generalization-error bounds for robust losses do not faithfully capture
out-of-sample performance. We argue that learnability should instead be
quantified through prediction error, namely the $L_2$-distance to the truth
$f^\star$, which is $\sigma$-independent and directly reflects the target of
robust estimation. To make this workable under unboundedness, we introduce a
\emph{probabilistic effective hypothesis space} that confines the estimator
with high probability and enables a meaningful bias--variance decomposition
under weak $(1+\epsilon)$-moment conditions. Technically, we establish new
comparison theorems linking the excess robust risk to the $L_2$ prediction
error up to a residual of order $\mathcal{O}(\sigma^{-2\epsilon})$, clarifying
the robustness--bias trade-off induced by the scale parameter $\sigma$.
Building on this, we derive explicit finite-sample error bounds and convergence
rates for Huber regression in RKHS that hold without uniform boundedness and
under heavy-tailed noise. Our study delivers principled tuning rules, extends
beyond Huber to other robust losses, and highlights prediction error, not
excess generalization risk, as the fundamental lens for analyzing robust
learning.

</details>


### [704] [Probabilistic bias adjustment of seasonal predictions of Arctic Sea Ice Concentration](https://arxiv.org/abs/2510.09891)
*Parsa Gooya,Reinel Sospedra-Alfonso*

Main category: cs.LG

TL;DR: 该研究提出了一种基于条件变分自编码器的概率性误差校正框架，用于改进北极海冰密集度季节性预测的准确性和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 由于气候模型预测的系统性偏差和时空误差，需要对北极海冰密集度的季节性预测进行偏差校正和校准，以应对海冰减少带来的影响和机遇。

Method: 提出了一种基于条件变分自编码器的概率性误差校正框架，该框架能够模拟给定模型预测的观测条件分布，并生成大量调整后的集合预报，以量化预测的不确定性。

Result: 通过确定性和概率性指标评估，该模型生成的调整后预报的校准性更好，更接近观测分布，误差也小于气候平均值调整后的预报。

Conclusion: 研究提出的概率性误差校正框架能够有效改进北极海冰密集度预测的校准性和准确性，并能更好地量化预测不确定性。

Abstract: Seasonal forecast of Arctic sea ice concentration is key to mitigate the
negative impact and assess potential opportunities posed by the rapid decline
of sea ice coverage. Seasonal prediction systems based on climate models often
show systematic biases and complex spatio-temporal errors that grow with the
forecasts. Consequently, operational predictions are routinely bias corrected
and calibrated using retrospective forecasts. For predictions of Arctic sea ice
concentration, error corrections are mainly based on one-to-one post-processing
methods including climatological mean or linear regression correction and, more
recently, machine learning. Such deterministic adjustments are confined at best
to the limited number of costly-to-run ensemble members of the raw forecast.
However, decision-making requires proper quantification of uncertainty and
likelihood of events, particularly of extremes. We introduce a probabilistic
error correction framework based on a conditional Variational Autoencoder model
to map the conditional distribution of observations given the biased model
prediction. This method naturally allows for generating large ensembles of
adjusted forecasts. We evaluate our model using deterministic and probabilistic
metrics and show that the adjusted forecasts are better calibrated, closer to
the observational distribution, and have smaller errors than climatological
mean adjusted forecasts.

</details>


### [705] [Chain-of-Influence: Tracing Interdependencies Across Time and Features in Clinical Predictive Modelings](https://arxiv.org/abs/2510.09895)
*Yubo Li,Rema Padman*

Main category: cs.LG

TL;DR: Chain-of-Influence (CoI)是一个可解释的深度学习框架，通过构建特征交互的显式、时间展开图来对临床时间序列数据中的潜在、时变依赖关系进行建模。它使用多层注意力机制来识别关键时间点和对后续特征的定向影响，从而能够追踪影响路径并提供可解释的预测。


<details>
  <summary>Details</summary>
Motivation: 临床时间序列数据的建模面临着捕捉特征之间潜在的、时变的依赖关系的挑战。现有方法通常依赖于黑盒机制或简单的聚合，未能明确地模拟一个临床变量的影响如何随着时间的推移而传播到其他变量。

Method: CoI框架利用多层注意力架构：首先，时间注意力层识别患者记录中的关键时间点；其次，跨特征注意力层对从这些时间点的特征到后续特征的定向影响进行建模。这种设计能够追踪影响路径，提供细粒度的审计跟踪，显示任何时间点的任何特征如何直接或通过其对其他变量的影响来贡献最终预测。

Result: 在MIMIC-IV数据集和一项私人慢性肾脏疾病队列研究中，CoI在预测死亡率和疾病进展任务上显著优于现有方法。通过案例研究，CoI能够揭示其他模型无法显示的临床上有意义的、患者特定的疾病进展模式，为临床决策提供了前所未有的透明度。

Conclusion: CoI框架通过显式建模时变依赖关系，在临床时间序列预测任务上实现了更高的准确性和可解释性，能够揭示有临床意义的模式，为临床决策提供支持。

Abstract: Modeling clinical time-series data is hampered by the challenge of capturing
latent, time-varying dependencies among features. State-of-the-art approaches
often rely on black-box mechanisms or simple aggregation, failing to explicitly
model how the influence of one clinical variable propagates through others over
time. We propose $\textbf{Chain-of-Influence (CoI)}$, an interpretable deep
learning framework that constructs an explicit, time-unfolded graph of feature
interactions. CoI leverages a multi-level attention architecture: first, a
temporal attention layer identifies critical time points in a patient's record;
second, a cross-feature attention layer models the directed influence from
features at these time points to subsequent features. This design enables the
tracing of influence pathways, providing a granular audit trail that shows how
any feature at any time contributes to the final prediction, both directly and
through its influence on other variables. We evaluate CoI on mortality and
disease progression tasks using the MIMIC-IV dataset and a private chronic
kidney disease cohort. Our framework significantly outperforms existing methods
in predictive accuracy. More importantly, through case studies, we show that
CoI can uncover clinically meaningful, patient-specific patterns of disease
progression that are opaque to other models, offering unprecedented
transparency into the temporal and cross-feature dependencies that inform
clinical decision-making.

</details>


### [706] [Learning Bug Context for PyTorch-to-JAX Translation with LLMs](https://arxiv.org/abs/2510.09898)
*Hung Phan,Son Le Vu,Ali Jannesari*

Main category: cs.LG

TL;DR: 尽管LLM在主流语言代码翻译方面取得了进展，但PyTorch到JAX的翻译仍然困难。T2J是一个提示增强框架，通过整合PyTorch代码源、人工修复和结构化指导，提高LLM在PyTorch到JAX翻译中的表现。该框架还引入了三种新的评估指标，并在实验中证明了其有效性，生成的代码运行速度更快。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型（LLMs）在主流编程语言的代码翻译方面取得了显著进展，但在PyTorch到JAX的代码翻译方面仍然存在挑战。这主要是由于PyTorch和JAX在核心设计、执行语义和生态系统成熟度方面存在差异，并且缺乏大规模的并行PyTorch-JAX数据集。此外，现有的评估方法也无法充分衡量跨框架代码翻译的质量。

Method: T2J框架包含三个主要部分：1. 数据集构建：结合了TorchLeet（Aroori & Chien, 2025）的问题解决集和CodeParrot（Wolf et al., 2022）的GitHub代码集，并使用GPT-4o-mini生成初步的JAX翻译。2. 人工修复与数据集整理：邀请两位专业开发者对生成的JAX代码进行迭代修复，直至功能对等，从而创建一个包含常见错误及其修复方案的、经过整理的、修复后无错误的数据集。3. 提示增强：利用从修复过程中提取的结构化指导信息，构建增强型提示，以引导像GPT-4o-mini这样的小型语言模型进行翻译。此外，研究还提出了三种针对PyTorch到JAX翻译的特定评估指标：T2J代码翻译得分、T2J修复成本得分（基于LLM估计的修复工作量）和T2J比较得分（使用LLM作为裁判）。

Result: 在实验中，T2J框架显著提升了GPT-4o-mini的翻译性能。具体表现在：CodeBLEU得分提高了10%，T2J修复成本得分提高了50%，T2J代码翻译得分（0-4分制）提高了1.33分，T2J比较得分提高了100%。更重要的是，使用T2J框架生成的JAX代码运行速度比基线模型快2.5倍。

Conclusion: T2J框架通过提示增强显著提高了LLM在PyTorch到JAX代码翻译任务上的表现。该框架通过整合多源数据、利用专业开发者的修复经验以及引入结构化指导，有效解决了现有方法在跨框架代码翻译方面的不足。新提出的评估指标也为衡量此类翻译任务提供了更有效的工具。T2J不仅提高了翻译的准确性和效率，还使得生成的代码运行速度更快，为PyTorch到JAX的迁移提供了有力支持。

Abstract: Despite recent progress of large language models (LLMs) on code translation
among mainstream languages, translating PyTorch to JAX remains nontrivial. The
two libraries, though both embedded in Python, differ in core design, execution
semantics, and ecosystem maturity; JAX is newer and comparatively
underrepresented in public code, and parallel PyTorch--JAX corpora are limited.
Weaknesses in existing evaluation further complicate cross-framework
benchmarking. We present T2J, a prompt-augmentation framework that strengthens
LLM-based PyTorch to JAX translation. Our pipeline (i) assembles two PyTorch
sources -- the problem-solving set from TorchLeet (Aroori & Chien, 2025) and a
GitHub-derived set from CodeParrot (Wolf et al., 2022) -- and uses GPT-4o-mini
to produce initial JAX drafts; (ii) engages two professional developers to
iteratively repair those drafts until functional equivalence, yielding a
curated fixed-bug dataset of common errors and patches; and (iii) constructs
augmented prompts that inject structured guidance from these fixes to steer
lightweight LLMs (e.g., GPT-4o-mini). We also introduce three metrics tailored
to PyTorch to JAX: T2J CodeTrans Score, T2J FixCost Score (an LLM-based
estimate of bug-fix effort), and T2J Comparison Score (LLM-as-judge).
Empirically, T2J raises GPT-4o-mini performance by up to 10% on CodeBLEU, 50%
on T2J FixCost Score, 1.33 points on T2J CodeTrans Score (0--4 scale), and 100%
on T2J Comparison Score; moreover, the generated code runs up to 2.5x faster
than the baseline.

</details>


### [707] [Stability of Transformers under Layer Normalization](https://arxiv.org/abs/2510.09904)
*Kelvin Kan,Xingjian Li,Benjamin J. Zhang,Tuhin Sahai,Stanley Osher,Krishna Kumar,Markos A. Katsoulakis*

Main category: cs.LG

TL;DR: Transformer训练不稳定，本文研究了层归一化位置对训练稳定性的影响，并提出了理论分析和改进建议。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer被广泛使用，但其训练过程可能不稳定。层归一化是常用的稳定训练的方法，但其位置选择却缺乏统一的理论指导。

Method: 本文对Transformer在不同层归一化位置下的前向和后向稳定性进行了理论研究，推导了隐藏状态的增长界限，并分析了层归一化对梯度反向传播的影响。

Result: 理论分析揭示了层归一化位置对Transformer训练动力学的影响，并为残差连接的缩放提供了指导。数值结果验证了理论分析的有效性。

Conclusion: 本文提供了一个理论框架，用于分析和检查Transformer的训练稳定性，为未来Transformer架构的设计提供了指导。

Abstract: Despite their widespread use, training deep Transformers can be unstable.
Layer normalization, a standard component, improves training stability, but its
placement has often been ad-hoc. In this paper, we conduct a principled study
on the forward (hidden states) and backward (gradient) stability of
Transformers under different layer normalization placements. Our theory
provides key insights into the training dynamics: whether training drives
Transformers toward regular solutions or pathological behaviors. For forward
stability, we derive explicit bounds on the growth of hidden states in trained
Transformers. For backward stability, we analyze how layer normalization
affects the backpropagation of gradients, thereby explaining the training
dynamics of each layer normalization placement. Our analysis also guides the
scaling of residual steps in Transformer blocks, where appropriate choices can
further improve stability and performance. Our numerical results corroborate
our theoretical findings. Beyond these results, our framework provides a
principled way to sanity-check the stability of Transformers under new
architectural modifications, offering guidance for future designs.

</details>


### [708] [Augmenting generative models with biomedical knowledge graphs improves targeted drug discovery](https://arxiv.org/abs/2510.09914)
*Aditya Malusare,Vineet Punyamoorty,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: K-DREAM是一个结合知识图谱和扩散模型的框架，用于生成具有更高生物相关性的药物分子，并在药物设计任务中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 将全面的生物医学知识整合到分子生成模型中，以提高生成分子的生物相关性和治疗适用性。

Method: 通过嵌入大规模知识图谱的结构化信息来增强基于扩散的模型，以指导分子生成。

Result: 在靶向药物设计任务中，K-DREAM生成的候选药物具有更高的结合亲和力和预测疗效，并且能够为多个靶点生成分子。

Conclusion: 知识增强的生成模型在理性药物设计和实际治疗开发中具有实用价值。

Abstract: Recent breakthroughs in generative modeling have demonstrated remarkable
capabilities in molecular generation, yet the integration of comprehensive
biomedical knowledge into these models has remained an untapped frontier. In
this study, we introduce K-DREAM (Knowledge-Driven Embedding-Augmented Model),
a novel framework that leverages knowledge graphs to augment diffusion-based
generative models for drug discovery. By embedding structured information from
large-scale knowledge graphs, K-DREAM directs molecular generation toward
candidates with higher biological relevance and therapeutic suitability. This
integration ensures that the generated molecules are aligned with specific
therapeutic targets, moving beyond traditional heuristic-driven approaches. In
targeted drug design tasks, K-DREAM generates drug candidates with improved
binding affinities and predicted efficacy, surpassing current state-of-the-art
generative models. It also demonstrates flexibility by producing molecules
designed for multiple targets, enabling applications to complex disease
mechanisms. These results highlight the utility of knowledge-enhanced
generative models in rational drug design and their relevance to practical
therapeutic development.

</details>


### [709] [Advancing Intoxication Detection: A Smartwatch-Based Approach](https://arxiv.org/abs/2510.09916)
*Manuel Segura,Pere Vergés,Richard Ky,Ramesh Arangott,Angela Kristine Garcia,Thang Dihn Trong,Makoto Hyodo,Alexandru Nicolau,Tony Givargis,Sergio Gago-Masague*

Main category: cs.LG

TL;DR: 本研究提出了一种基于智能手表应用程序的方法，通过收集和分析用户的生理数据（包括TAC、加速度计、陀螺仪和心率），来实时识别醉酒状态并发出预警，旨在促进更健康的饮酒习惯。


<details>
  <summary>Details</summary>
Motivation: 过量饮酒会对个人及其社区造成严重的健康风险和后果，因此需要创新的方法来干预不健康的饮酒行为。

Method: 收集了为期三周的用户的TAC、加速度计、陀螺仪和心率数据，并使用Transformer、bi-LSTM、GRU、1D-CNN和HDC等多种先进分类器对这些数据进行分析，以识别醉酒程度。研究还评估了这些算法在资源受限环境（如移动设备）下的性能和效率。

Result: HDC模型在准确性和效率之间取得了最佳平衡，证明了其在基于智能手表的应用程序中的实用性。

Conclusion: 基于智能手表的数据分析和HDC模型是一种有效且实用的方法，可以用于开发实时醉酒预警系统，从而帮助用户养成更健康的饮酒习惯。

Abstract: Excess alcohol consumption leads to serious health risks and severe
consequences for both individuals and their communities. To advocate for
healthier drinking habits, we introduce a groundbreaking mobile smartwatch
application approach to just-in-time interventions for intoxication warnings.
In this work, we have created a dataset gathering TAC, accelerometer,
gyroscope, and heart rate data from the participants during a period of three
weeks. This is the first study to combine accelerometer, gyroscope, and heart
rate smartwatch data collected over an extended monitoring period to classify
intoxication levels. Previous research had used limited smartphone motion data
and conventional machine learning (ML) algorithms to classify heavy drinking
episodes; in this work, we use smartwatch data and perform a thorough
evaluation of different state-of-the-art classifiers such as the Transformer,
Bidirectional Long Short-Term Memory (bi-LSTM), Gated Recurrent Unit (GRU),
One-Dimensional Convolutional Neural Networks (1D-CNN), and Hyperdimensional
Computing (HDC). We have compared performance metrics for the algorithms and
assessed their efficiency on resource-constrained environments like mobile
hardware. The HDC model achieved the best balance between accuracy and
efficiency, demonstrating its practicality for smartwatch-based applications.

</details>


### [710] [AutoGD: Automatic Learning Rate Selection for Gradient Descent](https://arxiv.org/abs/2510.09923)
*Nikola Surjanovic,Alexandre Bouchard-Côté,Trevor Campbell*

Main category: cs.LG

TL;DR: AutoGD是一种自动调整学习率的梯度下降方法，无需用户手动调整，并能在多种优化任务中实现高效收敛。


<details>
  <summary>Details</summary>
Motivation: 梯度下降等优化方法的性能很大程度上取决于学习率的选择，但手动调整学习率可能很耗时，并且在作为其他算法的内循环时可能不切实际。

Method: 提出了一种名为AutoGD的梯度下降方法，该方法能够自动决定在给定迭代中是增加还是减少学习率。

Result: 在广泛的函数类别上，AutoGD被证明可以收敛，并且可以在不知道平滑常数的情况下恢复到梯度下降（GD）的最优速率（相差一个常数）。

Conclusion: AutoGD在各种传统问题和变分推断优化任务的实验中表现出强大的性能，并且其对AutoBFGS和AutoLBFGS的扩展也显示出有效性。

Abstract: The performance of gradient-based optimization methods, such as standard
gradient descent (GD), greatly depends on the choice of learning rate. However,
it can require a non-trivial amount of user tuning effort to select an
appropriate learning rate schedule. When such methods appear as inner loops of
other algorithms, expecting the user to tune the learning rates may be
impractical. To address this, we introduce AutoGD: a gradient descent method
that automatically determines whether to increase or decrease the learning rate
at a given iteration. We establish the convergence of AutoGD, and show that we
can recover the optimal rate of GD (up to a constant) for a broad class of
functions without knowledge of smoothness constants. Experiments on a variety
of traditional problems and variational inference optimization tasks
demonstrate strong performance of the method, along with its extensions to
AutoBFGS and AutoLBFGS.

</details>


### [711] [Phase-Aware Deep Learning with Complex-Valued CNNs for Audio Signal Applications](https://arxiv.org/abs/2510.09926)
*Naman Agrawal*

Main category: cs.LG

TL;DR: 本研究提出了复值卷积神经网络（CVCNN），并将其应用于音频信号处理，以解决传统实值网络忽略相位信息的问题。


<details>
  <summary>Details</summary>
Motivation: 传统信号处理方法（包括基于实值神经网络的方法）在处理包含相位信息的信号时，往往会忽略相位信息，从而限制了模型的表达能力和性能。本研究旨在探索如何有效利用复数域中的幅度和相位信息，以提升音频信号处理任务的性能。

Method: 本研究首先介绍了CVCNN的理论基础，包括复卷积、复池化、基于Wirtinger的微分和多种复值激活函数。同时，研究也讨论了训练CVCNN的技巧，如复值批归一化和权重初始化。随后，研究进行了三阶段的实证评估：1. 在图像数据集上进行基准测试，以验证CVCNN的性能和训练稳定性；2. 在MFCCs音频分类任务上，对比CVCNN和CNN的表现，并探讨在输入层保留相位信息的挑战；3. 引入图神经网络（GNNs）结合相位信息（通过边权重）进行音频流派分类，以评估相位信息在模型中的作用。

Result: 在图像数据集上，CVCNN表现与实值CNN相当。在MFCCs音频分类任务上，CVCNN略优于实值CNN。当输入层保留相位信息时，需要进行架构修改才能有效利用。在结合GNN的音频流派分类任务中，引入相位信息带来了可衡量的性能提升。

Conclusion: 本研究证明了复值神经网络（CVCNN）的表达能力，并确认相位信息是音频处理中有价值且可利用的特征。虽然目前的方法，特别是使用心形激活函数的方法，显示出潜力，但未来需要进一步的相位感知设计来充分发挥复数表示在神经网络中的潜力。

Abstract: This study explores the design and application of Complex-Valued
Convolutional Neural Networks (CVCNNs) in audio signal processing, with a focus
on preserving and utilizing phase information often neglected in real-valued
networks. We begin by presenting the foundational theoretical concepts of
CVCNNs, including complex convolutions, pooling layers, Wirtinger-based
differentiation, and various complex-valued activation functions. These are
complemented by critical adaptations of training techniques, including complex
batch normalization and weight initialization schemes, to ensure stability in
training dynamics. Empirical evaluations are conducted across three stages.
First, CVCNNs are benchmarked on standard image datasets, where they
demonstrate competitive performance with real-valued CNNs, even under synthetic
complex perturbations. Although our focus is audio signal processing, we first
evaluate CVCNNs on image datasets to establish baseline performance and
validate training stability before applying them to audio tasks. In the second
experiment, we focus on audio classification using Mel-Frequency Cepstral
Coefficients (MFCCs). CVCNNs trained on real-valued MFCCs slightly outperform
real CNNs, while preserving phase in input workflows highlights challenges in
exploiting phase without architectural modifications. Finally, a third
experiment introduces GNNs to model phase information via edge weighting, where
the inclusion of phase yields measurable gains in both binary and multi-class
genre classification. These results underscore the expressive capacity of
complex-valued architectures and confirm phase as a meaningful and exploitable
feature in audio processing applications. While current methods show promise,
especially with activations like cardioid, future advances in phase-aware
design will be essential to leverage the potential of complex representations
in neural networks.

</details>


### [712] [MemPromptTSS: Persistent Prompt Memory for Iterative Multi-Granularity Time Series State Segmentation](https://arxiv.org/abs/2510.09930)
*Ching Chang,Ming-Chih Lo,Chiao-Tung Chan,Wen-Chih Peng,Tien-Fu Chen*

Main category: cs.LG

TL;DR: MemPromptTSS框架通过引入持久化提示记忆，解决了现有时间序列分割方法中提示信号作用范围有限的问题，实现了跨粒度的迭代式分割，并在多个数据集上显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的时间序列分割方法仅能在局部上下文中使用提示信号，导致提示信号的引导作用随序列长度衰减，无法对整个序列进行有效引导。

Method: 提出MemPromptTSS框架，该框架引入持久化提示记忆（persistent prompt memory），通过记忆编码器将提示及其周围子序列转化为记忆令牌并存储在记忆库中。这使得每次预测不仅能基于局部线索，还能基于所有迭代中累积的提示，确保提示信号的全局有效性。

Result: 在六个数据集上进行实验，MemPromptTSS在单次迭代推理中，单粒度和多粒度分割的准确率分别比最佳基线提高了23%和85%。在迭代推理中，MemPromptTSS的平均每次迭代增益为2.66个百分点，优于PromptTSS的1.19个百分点。

Conclusion: 持久化记忆对于提示引导的时间序列分割至关重要，MemPromptTSS是一个在实际应用中实用且有效的框架。

Abstract: Web platforms, mobile applications, and connected sensing systems generate
multivariate time series with states at multiple levels of granularity, from
coarse regimes to fine-grained events. Effective segmentation in these settings
requires integrating across granularities while supporting iterative refinement
through sparse prompt signals, which provide a compact mechanism for injecting
domain knowledge. Yet existing prompting approaches for time series
segmentation operate only within local contexts, so the effect of a prompt
quickly fades and cannot guide predictions across the entire sequence. To
overcome this limitation, we propose MemPromptTSS, a framework for iterative
multi-granularity segmentation that introduces persistent prompt memory. A
memory encoder transforms prompts and their surrounding subsequences into
memory tokens stored in a bank. This persistent memory enables each new
prediction to condition not only on local cues but also on all prompts
accumulated across iterations, ensuring their influence persists across the
entire sequence. Experiments on six datasets covering wearable sensing and
industrial monitoring show that MemPromptTSS achieves 23% and 85% accuracy
improvements over the best baseline in single- and multi-granularity
segmentation under single iteration inference, and provides stronger refinement
in iterative inference with average per-iteration gains of 2.66 percentage
points compared to 1.19 for PromptTSS. These results highlight the importance
of persistent memory for prompt-guided segmentation, establishing MemPromptTSS
as a practical and effective framework for real-world applications.

</details>


### [713] [Conformal Sparsification for Bandwidth-Efficient Edge-Cloud Speculative Decoding](https://arxiv.org/abs/2510.09942)
*Payel Bhattacharjee,Fengwei Tian,Meiyu Zhong,Guangyi Zhang,Osvaldo Simeone,Ravi Tandon*

Main category: cs.LG

TL;DR: Edge-cloud 推理通过让云端大模型（LLM）验证边缘端小模型（SLM）生成的草稿 token 来加速。


<details>
  <summary>Details</summary>
Motivation: 解决边缘-云连接带宽限制导致草稿 token 分布压缩效率低的问题。

Method: 提出稀疏量化与采样（SQS-SD）框架，利用结构化稀疏化和格点量化来利用分布稀疏性。K-SQS 使用固定 Top-K 截断，C-SQS 使用在线一致性预测来调整保留的 token 集合。

Result: SQS-SD 框架在端到端延迟和拒绝率方面均有改进。

Conclusion: SQS-SD 框架在边缘-云推断中通过利用分布稀疏性来提高效率。

Abstract: Edge-cloud speculative decoding (SD) accelerates inference by having a
cloud-based large language model (LLM) that verifies draft tokens generated by
a resource-constrained small language model (SLM) at the edge. A central
bottleneck is the limited bandwidth of the edge-cloud link, which necessitates
efficient compression of draft token distributions. We first derive an
information-theoretic bound that decomposes the token rejection rate into
contributions from SLM-LLM distribution mismatch and from quantization
distortion. Guided by this analysis, we propose the Sparse Quantize-and-Sample
SD (SQS-SD) framework, which exploits distributional sparsity through
structured sparsification and lattice-based quantization. Within this
framework, K-SQS applies fixed top-K truncation, while C-SQS adaptively adjusts
the retained token set via online conformal prediction to ensure bounded
deviation from the dense distribution. Empirical results confirm that both
approaches improve end-to-end latency and rejection rates in complimentary
operating regimes.

</details>


### [714] [Clustering Result Re-guided Incomplete Multi-view Spectral Clustering](https://arxiv.org/abs/2510.09959)
*Jun Yin,Runcheng Cai,Shiliang Sun*

Main category: cs.LG

TL;DR: CRG_IMSC是一种新的不完整多视图谱聚类方法，它直接从提取的特征中获得聚类结果，并利用聚类结果构建连通性矩阵，以提高聚类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的不完整多视图谱聚类方法在特征提取后需要进行K-means聚类，且未能有效利用聚类结果所反映的样本连通性。CRG_IMSC旨在克服这些缺陷。

Method: CRG_IMSC通过对提取的特征施加非负约束直接获得聚类结果，并根据谱聚类结果构建连通性矩阵，然后最小化基于连通性矩阵的自表示残差。该方法采用乘法更新的迭代算法进行优化，并证明了其收敛性。

Result: 在基准数据集上，CRG_IMSC在多视图数据上的表现优于现有的最先进的聚类方法。实验结果也证明了CRG_IMSC算法的收敛性。

Conclusion: CRG_IMSC是一种有效的不完整多视图谱聚类方法，能够直接获得聚类结果并有效利用样本连通性，在性能上优于现有方法，并具有良好的收敛性。

Abstract: Incomplete multi-view spectral clustering generalizes spectral clustering to
multi-view data and simultaneously realizes the partition of multi-view data
with missing views. For this category of method, K-means algorithm needs to be
performed to generate the clustering result after the procedure of feature
extraction. More importantly, the connectivity of samples reflected by the
clustering result is not utilized effectively. To overcome these defects, we
propose Clustering Result re-Guided Incomplete Multi-view Spectral Clustering
(CRG_IMSC). CRG_IMSC obtains the clustering result directly by imposing
nonnegative constraint to the extracted feature. Furthermore, it constructs the
connectivity matrix according to the result of spectral clustering, and
minimizes the residual of self-representation based on the connectivity matrix.
A novel iterative algorithm using multiplicative update is developed to solve
the optimization problem of CRG_IMSC, and its convergence is proved rigorously.
On benchmark datasets, for multi-view data, CRG_IMSC performs better than
state-of-the-art clustering methods, and the experimental results also
demonstrate the convergence of CRG_IMSC algorithm.

</details>


### [715] [Homomorphic Mappings for Value-Preserving State Aggregation in Markov Decision Processes](https://arxiv.org/abs/2510.09965)
*Shuo Zhao,Yongqiang Li,Yu Feng,Zhongsheng Hou,Yuanjing Feng*

Main category: cs.LG

TL;DR: State aggregation can reduce MDP complexity while maintaining performance, but ensuring optimal policy equivalence is challenging. This paper introduces a homomorphism-based framework for state aggregation, providing a sufficient condition for optimal policy equivalence and deriving bounds for approximation error when the condition isn't met. It proposes Homomorphic Policy Gradient (HPG) and Error-Bounded HPG (EBHPG) algorithms.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the fundamental challenge of optimizing policies within an aggregated state space in Markov Decision Processes (MDPs) such that the performance remains optimal in the original, ground MDP, a property known as optimal policy equivalence. This is crucial for reducing computational complexity while preserving system performance.

Method: The paper introduces an abstraction framework based on the notion of homomorphism, where two Markov chains are homomorphic if their value functions have a linear relationship. Within this framework, a sufficient condition for optimal policy equivalence is established. When this condition is not met, an upper bound on the approximation error and a performance lower bound for the objective function are derived. Two algorithms, Homomorphic Policy Gradient (HPG) and Error-Bounded HPG (EBHPG), are proposed.

Result: The theoretical results concerning the sufficient condition for optimal policy equivalence and the derived bounds on approximation error and performance are validated through experiments. Comparative evaluations against seven other algorithms demonstrate the effectiveness of the proposed methods.

Conclusion: The paper presents a homomorphism-based framework for state aggregation in MDPs that guarantees optimal policy equivalence under certain conditions. It also provides methods to bound approximation errors and performance loss when these conditions are not met, offering algorithms (HPG and EBHPG) that balance computational efficiency and performance preservation. Experimental validation supports the theoretical findings.

Abstract: State aggregation aims to reduce the computational complexity of solving
Markov Decision Processes (MDPs) while preserving the performance of the
original system. A fundamental challenge lies in optimizing policies within the
aggregated, or abstract, space such that the performance remains optimal in the
ground MDP-a property referred to as {"}optimal policy equivalence {"}.
  This paper presents an abstraction framework based on the notion of
homomorphism, in which two Markov chains are deemed homomorphic if their value
functions exhibit a linear relationship. Within this theoretical framework, we
establish a sufficient condition for the equivalence of optimal policy.
  We further examine scenarios where the sufficient condition is not met and
derive an upper bound on the approximation error and a performance lower bound
for the objective function under the ground MDP. We propose Homomorphic Policy
Gradient (HPG), which guarantees optimal policy equivalence under sufficient
conditions, and its extension, Error-Bounded HPG (EBHPG), which balances
computational efficiency and the performance loss induced by aggregation. In
the experiments, we validated the theoretical results and conducted comparative
evaluations against seven algorithms.

</details>


### [716] [Reinforcement Fine-Tuning of Flow-Matching Policies for Vision-Language-Action Models](https://arxiv.org/abs/2510.09976)
*Mingyang Lyu,Yinqian Sun,Erliang Lin,Huangrui Li,Ruolin Chen,Feifei Zhao,Yi Zeng*

Main category: cs.LG

TL;DR: 通过提出流动策略优化（FPO）算法，解决现有视觉-语言-动作（VLA）模型在数据质量和覆盖范围方面的限制，并实现了对基于流匹配的模型进行稳定、可扩展的在线强化微调。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在数据质量和覆盖范围方面存在局限性；传统的策略梯度方法在基于流匹配的模型上计算不可行。

Method: 提出流动策略优化（FPO）算法，通过重塑重要性采样并结合结构感知信用分配、裁剪替代目标、多步潜在探索和Q集成机制来实现。

Result: 在LIBERO基准和ALOHA模拟任务上，FPO相对于其他基线方法（包括监督学习、偏好对齐、扩散模型、自回归在线RL和π0-FAST）取得了持续的改进，并在稀疏奖励下实现了稳定的学习。

Conclusion: FPO算法能够有效地解决VLA模型在数据方面的局限性，并实现稳定、可扩展的在线强化微调，其各个组成部分都对最终的性能做出了贡献。

Abstract: Vision-Language-Action (VLA) models such as OpenVLA, Octo, and $\pi_0$ have
shown strong generalization by leveraging large-scale demonstrations, yet their
performance is still fundamentally constrained by the quality and coverage of
supervised data. Reinforcement learning (RL) provides a promising path for
improving and fine-tuning VLAs through online interaction. However,
conventional policy gradient methods are computationally infeasible in the
context of flow-matching based models due to the intractability of the
importance sampling process, which requires explicit computation of policy
ratios. To overcome this limitation, we propose Flow Policy Optimization (FPO)
algorithm, which reformulates importance sampling by leveraging per-sample
changes in the conditional flow-matching objective. Furthermore, FPO achieves
stable and scalable online reinforcement fine-tuning of the $\pi_0$ model by
integrating structure-aware credit assignment to enhance gradient efficiency,
clipped surrogate objectives to stabilize optimization, multi-step latent
exploration to encourage diverse policy updates, and a Q-ensemble mechanism to
provide robust value estimation. We evaluate FPO on the LIBERO benchmark and
the ALOHA simulation task against supervised, preference-aligned,
diffusion-based, autoregressive online RL, and $\pi_0$-FAST baselines,
observing consistent improvements over the imitation prior and strong
alternatives with stable learning under sparse rewards. In addition, ablation
studies and analyses of the latent space dynamics further highlight the
contributions of individual components within FPO, validating the effectiveness
of the proposed computational modules and the stable convergence of the
conditional flow-matching objective during online RL.

</details>


### [717] [An Unsupervised Time Series Anomaly Detection Approach for Efficient Online Process Monitoring of Additive Manufacturing](https://arxiv.org/abs/2510.09977)
*Frida Cantu,Salomon Ibarra,Arturo Gonzales,Jesus Barreda,Chenang Liu,Li Zhang*

Main category: cs.LG

TL;DR: 提出一种基于矩阵剖分的无监督异常检测算法，用于识别制造过程中的细微异常。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有标签数据或只能检测极端异常，无法识别细微的语义偏移异常，而这对于捕捉新状态或意外模式的开始至关重要。

Method: 提出一种基于矩阵剖分的无监督异常检测算法，该算法能够捕捉制造周期的相似性并进行语义分割，以精确识别增材制造中缺陷异常的发生。

Result: 通过在真实世界传感器数据上的实验证明了该方法的有效性。

Conclusion: 所提出的基于矩阵剖分的无监督异常检测算法能够有效识别制造过程中的细微异常。

Abstract: Online sensing plays an important role in advancing modern manufacturing. The
real-time sensor signals, which can be stored as high-resolution time series
data, contain rich information about the operation status. One of its popular
usages is online process monitoring, which can be achieved by effective anomaly
detection from the sensor signals. However, most existing approaches either
heavily rely on labeled data for training supervised models, or are designed to
detect only extreme outliers, thus are ineffective at identifying subtle
semantic off-track anomalies to capture where new regimes or unexpected
routines start. To address this challenge, we propose an matrix profile-based
unsupervised anomaly detection algorithm that captures fabrication cycle
similarity and performs semantic segmentation to precisely identify the onset
of defect anomalies in additive manufacturing. The effectiveness of the
proposed method is demonstrated by the experiments on real-world sensor data.

</details>


### [718] [Learning Joint Embeddings of Function and Process Call Graphs for Malware Detection](https://arxiv.org/abs/2510.09984)
*Kartikeya Aneja,Nagender Aneja,Murat Kantarcioglu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为GeminiNet的新方法，通过联合分析函数调用图（FCG）和进程调用图（PCG）来更深入地理解软件系统。研究表明，这种联合分析比单独分析一种图更有效，并构建了一个包含635个Windows可执行文件的新数据集来验证该方法。


<details>
  <summary>Details</summary>
Motivation: 之前关于利用图神经网络（GNNs）分析软件行为的研究大多集中于单一类型的图表示（如函数调用图或进程交互图），而联合建模这两种图表示方法在软件分析中仍有待深入探索，这限制了对软件系统进行更深层次、多角度分析的可能性。

Method: 提出了一种构建和训练函数调用图（FCG）和进程调用图（PCG）的流水线，并学习联合嵌入。提出了GeminiNet，一个统一的神经网络方法，可以从FCG和PCG中学习联合嵌入。GeminiNet采用双图卷积分支，并使用自适应门控机制来平衡静态和动态视图的贡献。

Result: 研究表明，与单一图模型相比，联合嵌入的表现更优。构建了一个包含635个Windows可执行文件（318个恶意，317个良性）的新数据集，使用Ghidra提取FCG，使用Any.Run沙箱提取PCG。

Conclusion: GeminiNet通过联合学习函数调用图和进程调用图的嵌入，能够提供比单一图模型更深入、更全面的软件系统分析。

Abstract: Software systems can be represented as graphs, capturing dependencies among
functions and processes. An interesting aspect of software systems is that they
can be represented as different types of graphs, depending on the extraction
goals and priorities. For example, function calls within the software can be
captured to create function call graphs, which highlight the relationships
between functions and their dependencies. Alternatively, the processes spawned
by the software can be modeled to generate process interaction graphs, which
focus on runtime behavior and inter-process communication. While these graph
representations are related, each captures a distinct perspective of the
system, providing complementary insights into its structure and operation.
While previous studies have leveraged graph neural networks (GNNs) to analyze
software behaviors, most of this work has focused on a single type of graph
representation. The joint modeling of both function call graphs and process
interaction graphs remains largely underexplored, leaving opportunities for
deeper, multi-perspective analysis of software systems. This paper presents a
pipeline for constructing and training Function Call Graphs (FCGs) and Process
Call Graphs (PCGs) and learning joint embeddings. We demonstrate that joint
embeddings outperform a single-graph model. In this paper, we propose
GeminiNet, a unified neural network approach that learns joint embeddings from
both FCGs and PCGs. We construct a new dataset of 635 Windows executables (318
malicious and 317 benign), extracting FCGs via Ghidra and PCGs via Any.Run
sandbox. GeminiNet employs dual graph convolutional branches with an adaptive
gating mechanism that balances contributions from static and dynamic views.

</details>


### [719] [Tight Robustness Certificates and Wasserstein Distributional Attacks for Deep Neural Networks](https://arxiv.org/abs/2510.10000)
*Bach C. Le,Tung V. Dao,Binh T. Nguyen,Hong T. M. Chu*

Main category: cs.LG

TL;DR: 本文提出了一种新的 Wasserstein 分布鲁棒优化（WDRO）方法，通过引入原始方法和精确 Lipschitz 证书来改进 WDRO 的上界，并提出了一种新的 Wasserstein 分布攻击（WDA）来直接构建最坏情况的分布，在ReLU网络上实现了精确可解的 WDRO 问题，并在实验中展现了具有竞争力的鲁棒准确性和更紧致的证书。


<details>
  <summary>Details</summary>
Motivation: 现有基于全局 Lipschitz 连续性或强对偶性的 Wasserstein 分布鲁棒优化（WDRO）方法存在上界过松或计算成本过高的问题。

Method: 引入原始方法和精确 Lipschitz 证书来收紧 WDRO 的上界；提出一种新的 Wasserstein 分布攻击（WDA），直接构造最坏情况分布的候选；利用ReLU网络的激活单元的分段仿射结构，对相应的 WDRO 问题进行精确可解的刻画。

Result: 提出的方法在鲁棒准确性方面与最先进的基线方法具有竞争力，并提供了比现有方法更紧致的证书。

Conclusion: 本文提出的 WDRO 新方法和 WDA 能够有效解决现有方法的局限性，并在实践中取得了良好的效果。

Abstract: Wasserstein distributionally robust optimization (WDRO) provides a framework
for adversarial robustness, yet existing methods based on global Lipschitz
continuity or strong duality often yield loose upper bounds or require
prohibitive computation. In this work, we address these limitations by
introducing a primal approach and adopting a notion of exact Lipschitz
certificate to tighten this upper bound of WDRO. In addition, we propose a
novel Wasserstein distributional attack (WDA) that directly constructs a
candidate for the worst-case distribution. Compared to existing point-wise
attack and its variants, our WDA offers greater flexibility in the number and
location of attack points. In particular, by leveraging the piecewise-affine
structure of ReLU networks on their activation cells, our approach results in
an exact tractable characterization of the corresponding WDRO problem.
Extensive evaluations demonstrate that our method achieves competitive robust
accuracy against state-of-the-art baselines while offering tighter certificates
than existing methods. Our code is available at
https://github.com/OLab-Repo/WDA

</details>


### [720] [Bidirectional Time-Frequency Pyramid Network for Enhanced Robust EEG Classification](https://arxiv.org/abs/2510.10004)
*Jiahui Hong,Siqing Li,Muqing Jian,Luming Yang*

Main category: cs.LG

TL;DR: BITE是一个统一的端到端架构，通过多流协同、金字塔时频注意力和双向自适应卷积，解决了现有EEG识别模型跨范式泛化能力差的问题，在多个范式中取得了最先进的性能，并在MI和SSVEP任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有EEG识别模型由于数据集特定约束和个体差异，跨范式泛化能力较差。

Method: 提出BITE（双向时频金字塔网络），一个端到端统一架构，具有鲁棒的多流协同、金字塔时频注意（PTFA）和双向自适应卷积。该框架集成了：1）对齐的时频流，通过STFT保持双向建模的 temporal 同步；2）基于PTFA的多尺度特征增强，放大了关键神经模式；3）具有可学习融合的双向TCN（BiTCN），捕捉前向/后向神经动力学。

Result: BITE在四个不同的范式（BCICIV-2A/2B、HGD、SD-SSVEP）中实现了最先进的性能，在被试内准确率和跨被试泛化能力方面均表现出色。

Conclusion: BITE作为一个统一的架构，结合了在MI和SSVEP任务中的鲁棒性能和出色的计算效率。范式对齐的谱-时域处理对于可靠的BCI系统至关重要。

Abstract: Existing EEG recognition models suffer from poor cross-paradigm
generalization due to dataset-specific constraints and individual variability.
To overcome these limitations, we propose BITE (Bidirectional Time-Freq Pyramid
Network), an end-to-end unified architecture featuring robust multistream
synergy, pyramid time-frequency attention (PTFA), and bidirectional adaptive
convolutions. The framework uniquely integrates: 1) Aligned time-frequency
streams maintaining temporal synchronization with STFT for bidirectional
modeling, 2) PTFA-based multi-scale feature enhancement amplifying critical
neural patterns, 3) BiTCN with learnable fusion capturing forward/backward
neural dynamics. Demonstrating enhanced robustness, BITE achieves
state-of-the-art performance across four divergent paradigms (BCICIV-2A/2B,
HGD, SD-SSVEP), excelling in both within-subject accuracy and cross-subject
generalization. As a unified architecture, it combines robust performance
across both MI and SSVEP tasks with exceptional computational efficiency. Our
work validates that paradigm-aligned spectral-temporal processing is essential
for reliable BCI systems. Just as its name suggests, BITE "takes a bite out of
EEG." The source code is available at https://github.com/cindy-hong/BiteEEG.

</details>


### [721] [Skill-Targeted Adaptive Training](https://arxiv.org/abs/2510.10023)
*Yinghui He,Abhishek Panigrahi,Yong Lin,Sanjeev Arora*

Main category: cs.LG

TL;DR: STAT是一种新的微调策略，利用更强的LLM作为教师，通过识别和解决学生模型在特定技能上的不足来提升其性能，特别是在数学推理任务上表现显著。


<details>
  <summary>Details</summary>
Motivation: 标准的监督微调（SFT）在处理与预训练数据相似的数据集（如MATH）时，语言模型往往会饱和，改进效果不明显。需要新的微调策略来克服这一局限。

Method: STAT（Skill-Targeted Adaptive Training）策略：1. 教师LLM分析任务数据集，识别所需技能。2. 教师LLM为每个数据点打上所需技能标签。3. 教师LLM通过监控学生模型的回答，生成“缺失技能画像”，追踪学生在各项技能上的应用失败率。4. 基于“缺失技能画像”，STAT有两种训练方式：a) STAT-Sel：自适应地重新加权现有训练样本。b) STAT-Syn：合成包含缺失技能的新样本。

Result: 在Llama和Qwen模型上的大量实验表明，STAT方法在MATH数据集上最多可提高7.5%的性能，而SFT仅带来有限的提升。此外，STAT在处理分布外基准测试（如AIME24/25、AMC23等）时，平均性能提升4.6%。STAT与GRPO等强化学习方法是互补的，STAT解决技能缺口后，GRPO能进一步提升性能。

Conclusion: 针对技能的目标自适应训练（STAT）策略能够有效提升现有模型的训练流程，特别是在需要特定技能推理的任务上。

Abstract: Language models often show little to no improvement (i.e., "saturation") when
trained via vanilla supervised fine-tuning (SFT) on data similar to what they
saw in their training set (e.g., MATH). We introduce a new fine-tuning
strategy, STAT, to train such a student model by using the metacognition
ability of a stronger large language model (LLM) as the teacher. The teacher
uses the task dataset to create a list of skills needed for the task, and then
labels each data point with its required skills (Didolkar et al., 2024). By
monitoring the student's answers, the teacher creates a Missing-Skill-Profile
for the student, tracking how often they failed to apply each skill in their
responses. We use this idea to build a modified training set in one of two
ways. In STAT-Sel, the teacher uses an existing set of training examples but
adaptively reweights them according to the Missing-Skill-Profile. In STAT-Syn,
the teacher synthesizes additional examples involving missing skills. Across
extensive experiments on Llama and Qwen models, our methods yield improvements
of up to 7.5% on MATH, whereas SFT provides only limited gains. Furthermore,
STAT enhances performance on out-of-distribution benchmarks (e.g., AIME24/25,
AMC23, etc.) by an average of 4.6%. Crucially, we find that STAT is
complementary to RL via GRPO (Shao et al., 2024): after the model is improved
using STAT to address skill gaps, GRPO continues to add further gains. We
conclude that skill-targeted adaptive training should broadly improve current
training pipelines. Our code is available at:
https://github.com/princeton-pli/STAT.

</details>


### [722] [Experience-Efficient Model-Free Deep Reinforcement Learning Using Pre-Training](https://arxiv.org/abs/2510.10029)
*Ruoxing Yang*

Main category: cs.LG

TL;DR: PPOPT是一种利用预训练来提高模型无关深度强化学习算法在小样本量下的训练效率和稳定性的新算法。


<details>
  <summary>Details</summary>
Motivation: 在物理环境中，深度强化学习算法通常需要大量的样本才能有效学习，而与复杂环境的频繁交互会产生高昂的计算成本。

Method: 提出了一种新的策略神经网络结构，由预训练的神经网络中间部分和两个全连接网络组成，利用预训练环境中的可迁移物理特性来提升学习效率。

Result: PPOPT在小样本量下，在奖励获取和训练稳定性方面均优于经典的PPO算法；虽然性能不及DYNA DDPG等基于模型的方法，但其模型无关的特性使其训练时间显著少于基于模型的方法。

Conclusion: PPOPT通过预训练显著提高了小样本量下强化学习的训练效率和稳定性，并且该算法已开源。

Abstract: We introduce PPOPT - Proximal Policy Optimization using Pretraining, a novel,
model-free deep-reinforcement-learning algorithm that leverages pretraining to
achieve high training efficiency and stability on very small training samples
in physics-based environments. Reinforcement learning agents typically rely on
large samples of environment interactions to learn a policy. However, frequent
interactions with a (computer-simulated) environment may incur high
computational costs, especially when the environment is complex. Our main
innovation is a new policy neural network architecture that consists of a
pretrained neural network middle section sandwiched between two fully-connected
networks. Pretraining part of the network on a different environment with
similar physics will help the agent learn the target environment with high
efficiency because it will leverage a general understanding of the
transferrable physics characteristics from the pretraining environment. We
demonstrate that PPOPT outperforms baseline classic PPO on small training
samples both in terms of rewards gained and general training stability. While
PPOPT underperforms against classic model-based methods such as DYNA DDPG, the
model-free nature of PPOPT allows it to train in significantly less time than
its model-based counterparts. Finally, we present our implementation of PPOPT
as open-source software, available at github.com/Davidrxyang/PPOPT.

</details>


### [723] [FOSSIL: Regret-Minimizing Curriculum Learning for Metadata-Free and Low-Data Mpox Diagnosis](https://arxiv.org/abs/2510.10041)
*Sahng-Min Han,Minjae Kim,Jinho Cha,Se-woon Choe,Eunchan Daniel Cha,Jungwon Choi,Kyudong Jung*

Main category: cs.LG

TL;DR: FOSSIL框架通过自适应调整样本权重，解决了生物医学图像中深度学习在小样本和不平衡数据集上优化不稳定和泛化能力差的问题，提高了诊断准确性、校准性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在小样本和不平衡的生物医学数据集中存在优化不稳定和泛化能力差的根本限制。

Method: 提出并实现了FOSSIL（Flexible Optimization via Sample-Sensitive Importance Learning）框架，这是一种通过样本重要性学习进行遗憾最小化的加权框架，能够根据样本难度自适应地平衡训练。使用基于softmax的不确定性作为难度的连续度量，构建了一个四阶段（从易到非常难）的课程，并将FOSSIL集成到卷积和Transformer架构中，用于Mpox皮肤病变诊断。

Result: FOSSIL在所有设置下显著提高了辨别力（AUC = 0.9573）、校准度（ECE = 0.053）以及在真实世界扰动下的鲁棒性，且优于不使用元数据、手动整理或合成增强的传统基线方法。

Conclusion: 结果表明，FOSSIL是一个可泛化、数据高效且可解释的框架，适用于数据稀缺情况下医学影像中的难度感知学习。

Abstract: Deep learning in small and imbalanced biomedical datasets remains
fundamentally constrained by unstable optimization and poor generalization. We
present the first biomedical implementation of FOSSIL (Flexible Optimization
via Sample-Sensitive Importance Learning), a regret-minimizing weighting
framework that adaptively balances training emphasis according to sample
difficulty. Using softmax-based uncertainty as a continuous measure of
difficulty, we construct a four-stage curriculum (Easy-Very Hard) and integrate
FOSSIL into both convolutional and transformer-based architectures for Mpox
skin lesion diagnosis. Across all settings, FOSSIL substantially improves
discrimination (AUC = 0.9573), calibration (ECE = 0.053), and robustness under
real-world perturbations, outperforming conventional baselines without
metadata, manual curation, or synthetic augmentation. The results position
FOSSIL as a generalizable, data-efficient, and interpretable framework for
difficulty-aware learning in medical imaging under data scarcity.

</details>


### [724] [One4Many-StablePacker: An Efficient Deep Reinforcement Learning Framework for the 3D Bin Packing Problem](https://arxiv.org/abs/2510.10057)
*Lei Gao,Shihong Huang,Shengjie Wang,Hong Ma,Feng Zhang,Hengda Bao,Qichang Chen,Weihua Zhou*

Main category: cs.LG

TL;DR: O4M-SP是一个深度强化学习框架，用于解决具有稳定性约束的3D装箱问题，能处理不同尺寸的箱子，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在处理3D装箱问题时，忽略了稳定性约束，并且在不同箱子尺寸上的泛化能力有限。

Method: 提出了一种名为One4Many-StablePacker (O4M-SP) 的新颖深度强化学习框架。该框架包含两个机制：1. 加权奖励函数，结合了装载率和新的高度差指标，以实现更平坦的装箱布局；2. 裁剪策略梯度优化和定制的策略漂移方法，以避免策略熵崩溃，鼓励在关键决策点进行探索，避免次优解。

Result: 实验证明，O4M-SP在不同箱子尺寸上表现出良好的泛化能力，并且显著优于基线方法。此外，O4M-SP在处理包含稳定性约束的装箱场景时，展现出强大的实际应用能力。

Conclusion: O4M-SP成功地解决了3D装箱问题中的稳定性约束和泛化能力问题，并在实际应用中表现出色。

Abstract: The three-dimensional bin packing problem (3D-BPP) is widely applied in
logistics and warehousing. Existing learning-based approaches often neglect
practical stability-related constraints and exhibit limitations in generalizing
across diverse bin dimensions. To address these limitations, we propose a novel
deep reinforcement learning framework, One4Many-StablePacker (O4M-SP). The
primary advantage of O4M-SP is its ability to handle various bin dimensions in
a single training process while incorporating support and weight constraints
common in practice. Our training method introduces two innovative mechanisms.
First, it employs a weighted reward function that integrates loading rate and a
new height difference metric for packing layouts, promoting improved bin
utilization through flatter packing configurations. Second, it combines clipped
policy gradient optimization with a tailored policy drifting method to mitigate
policy entropy collapse, encouraging exploration at critical decision nodes
during packing to avoid suboptimal solutions. Extensive experiments demonstrate
that O4M-SP generalizes successfully across diverse bin dimensions and
significantly outperforms baseline methods. Furthermore, O4M-SP exhibits strong
practical applicability by effectively addressing packing scenarios with
stability constraints.

</details>


### [725] [Translution: Unifying Self-attention and Convolution for Adaptive and Relative Modeling](https://arxiv.org/abs/2510.10060)
*Hehe Fan,Yi Yang,Mohan Kankanhalli,Fei Wu*

Main category: cs.LG

TL;DR: Translution是一种结合了自注意力机制的自适应信息识别能力和卷积的相对编码优势的新型操作，并提出轻量化变体α-Translution以解决参数量过大的问题。实验证明Translution在计算机视觉和自然语言处理任务上优于自注意力机制。


<details>
  <summary>Details</summary>
Motivation: 现有的自注意力机制依赖绝对位置嵌入进行结构学习，卷积则因固定核大小限制了自适应选择相关元素的能力。需要一种能够结合两者优点的方法。

Method: 提出Translution操作，用于统一自注意力机制的自适应信息识别能力和卷积的相对编码优势。为解决参数量过大的问题，进一步提出轻量化变体α-Translution。

Result: Translution（包括α-Translution）在计算机视觉和自然语言处理任务上实现了比自注意力机制更高的准确率。

Conclusion: Translution是一种有效的方法，能够结合自注意力和卷积的优点，并在多个任务上取得优于自注意力的性能。

Abstract: When modeling a given type of data, we consider it to involve two key
aspects: 1) identifying relevant elements (e.g., image pixels or textual words)
to a central element, as in a convolutional receptive field, or to a query
element, as in self-attention, and 2) encoding these tokens effectively.
Self-attention can adaptively identify these elements but relies on absolute
positional embedding for structural representation learning. In contrast,
convolution encodes elements in a relative manner, yet their fixed kernel size
limits their ability to adaptively select the relevant elements. In this paper,
we introduce Translution, an operation that unifies the adaptive identification
capability of self-attention and the relative encoding advantage of
convolution. However, this integration leads to a substantial increase in the
number of parameters, exceeding most currently available computational
resources. Therefore, we propose a lightweight variant of Translution, named
{\alpha}-Translution. Experiments on computer vision and natural language
processing tasks show that Translution (including {\alpha}-Translution)
achieves superior accuracy compared to self-attention. The code is available at
https://github.com/hehefan/Translution.

</details>


### [726] [ADEPT: Continual Pretraining via Adaptive Expansion and Dynamic Decoupled Tuning](https://arxiv.org/abs/2510.10071)
*Jinyang Zhang,Yue Fang,Hongxin Ding,Weibin Liao,Muyang Ye,Xu Chu,Junfeng Zhao,Yasha Wang*

Main category: cs.LG

TL;DR: ADEPT通过选择性地扩展和解耦调整LLM层来解决灾难性遗忘和有限领域容量问题，实现了高效且鲁棒的领域自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的持续预训练（CPT）方法在进行大型语言模型（LLM）领域自适应时，存在灾难性遗忘和领域容量有限的问题。虽然一些策略通过层扩展来增加可训练参数，但这种方法统一扩展和更新参数，仍然会混淆通用学习和领域学习，降低了有效性。

Method: 提出了一种名为ADEPT（Adaptive Expansion and Dynamic Decoupled Tuning）的两阶段框架。第一阶段采用“通用能力引导的选择性层扩展”，复制对通用领域不那么关键的层，以增加表示能力并减少对通用知识的干扰。第二阶段应用“自适应单元解耦调优”，根据参数单元在通用领域的重要性来区分它们，并分配不对称的学习率，以平衡知识注入和保留。

Result: 在数学和医学基准测试中，ADEPT的表现优于全参数CPT，在通用领域提高了5.76%，在目标领域提高了5.58%。同时，ADEPT仅调整15%的参数，训练时间缩短不到50%。

Conclusion: 实验结果、消融研究、理论分析和扩展研究证明了目标扩展和解耦优化的必要性，为高效且鲁棒的领域自适应CPT提供了新原则。

Abstract: Conventional continual pretraining (CPT) for large language model (LLM)
domain adaptation often suffers from catastrophic forgetting and limited domain
capacity. Existing strategies adopt layer expansion, introducing additional
trainable parameters to accommodate new knowledge. However, the uniform
expansion and updates still entangle general and domain learning, undermining
its effectiveness. Our pilot studies reveal that LLMs exhibit functional
specialization, where layers and units differentially encode general-critical
capabilities, suggesting that parameter expansion and optimization should be
function-aware. We then propose ADEPT, Adaptive Expansion and Dynamic Decoupled
Tuning for continual pretraining, a two-stage framework for domain-adaptive
CPT. ADEPT first performs General-Competence Guided Selective Layer Expansion,
duplicating layers least critical for the general domain to increase
representational capacity while minimizing interference with general knowledge.
It then applies Adaptive Unit-Wise Decoupled Tuning, disentangling parameter
units within expanded layers according to their general-domain importance and
assigning asymmetric learning rates to balance knowledge injection and
retention. Experiments on mathematical and medical benchmarks show that ADEPT
outperforms full-parameter CPT by up to 5.76% on the general domain and 5.58%
on the target domain with only 15% of parameters tuned and less than 50%
training time. Ablation studies, theoretical analysis, and extended
investigations further demonstrate the necessity of targeted expansion and
decoupled optimization, providing new principles for efficient and robust
domain-adaptive CPT. Our code is open-sourced at
https://github.com/PuppyKnightUniversity/ADEPT

</details>


### [727] [Gradient-based Model Shortcut Detection for Time Series Classification](https://arxiv.org/abs/2510.10075)
*Salomon Ibarra,Frida Cantu,Kaixiong Zhou,Li Zhang*

Main category: cs.LG

TL;DR: 深度学习模型在时间序列分类（TSC）任务中表现出色，但可能依赖于虚假关联（shortcut learning）。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在时间序列分类中存在的，依赖于虚假关联（shortcut learning）而泛化能力受限的问题，并填补该领域研究的空白。

Method: 提出一种基于其他类别来检测时间序列分类中shortcut learning的方法，该方法不依赖测试数据或干净的训练类别。

Result: 在UCR时间序列数据集上测试了所提出的方法。

Conclusion: 该研究首次探索了深度学习时间序列分类中的点状shortcut learning行为，并提出了一种新的检测方法。

Abstract: Deep learning models have attracted lots of research attention in time series
classification (TSC) task in the past two decades. Recently, deep neural
networks (DNN) have surpassed classical distance-based methods and achieved
state-of-the-art performance. Despite their promising performance, deep neural
networks (DNNs) have been shown to rely on spurious correlations present in the
training data, which can hinder generalization. For instance, a model might
incorrectly associate the presence of grass with the label ``cat" if the
training set have majority of cats lying in grassy backgrounds. However, the
shortcut behavior of DNNs in time series remain under-explored. Most existing
shortcut work are relying on external attributes such as gender, patients
group, instead of focus on the internal bias behavior in time series models.
  In this paper, we take the first step to investigate and establish
point-based shortcut learning behavior in deep learning time series
classification. We further propose a simple detection method based on other
class to detect shortcut occurs without relying on test data or clean training
classes. We test our proposed method in UCR time series datasets.

</details>


### [728] [What Makes Looped Transformers Perform Better Than Non-Recursive Ones (Provably)](https://arxiv.org/abs/2510.10089)
*Zixuan Gong,Jiaye Teng,Yong Liu*

Main category: cs.LG

TL;DR: Looped-Attn比Single-Attn在复杂推理任务上表现更好，这归因于其损失函数的几何形状，具体来说，Looped-Attn倾向于“河-V形谷”，而Single-Attn倾向于“河-U形谷”。这种差异使得Looped-Attn在学习复杂模式方面具有优势。在此基础上，提出了一种名为SHIFT的训练框架，以加速Looped-Attn的训练过程。


<details>
  <summary>Details</summary>
Motivation: 解释Looped-Attn在复杂推理任务上优于Single-Attn的理论依据，尽管其优势已被经验观察证实。

Method: 通过损失函数的几何形状来解释Looped-Attn的优势，将损失函数分为U形谷和V形谷。提出Looped-Attn的递归结构诱导了“河-V形谷”的归纳偏倚，而Single-Attn诱导了“河-U形谷”。

Result: 理论推导表明，“河-V形谷”有利于在河流方向上更好地收敛损失，并鼓励学习复杂模式，优于“河-U形谷”。

Conclusion: Looped-Attn的优势可以通过损失函数的几何形状来解释。基于此，提出SHIF T训练框架，旨在加速Looped-Attn的训练并保持其性能。

Abstract: While looped transformers (termed as Looped-Attn) often outperform standard
transformers (termed as Single-Attn) on complex reasoning tasks, the
theoretical basis for this advantage remains underexplored. In this paper, we
explain this phenomenon through the lens of loss landscape geometry, inspired
by empirical observations of their distinct dynamics at both sample and Hessian
levels. To formalize this, we extend the River-Valley landscape model by
distinguishing between U-shaped valleys (flat) and V-shaped valleys (steep).
Based on empirical observations, we conjecture that the recursive architecture
of Looped-Attn induces a landscape-level inductive bias towards River-V-Valley.
Theoretical derivations based on this inductive bias guarantee a better loss
convergence along the river due to valley hopping, and further encourage
learning about complex patterns compared to the River-U-Valley induced by
Single-Attn. Building on this insight, we propose SHIFT (Staged HIerarchical
Framework for Progressive Training), a staged training framework that
accelerates the training process of Looped-Attn while achieving comparable
performances.

</details>


### [729] [Rademacher Meets Colors: More Expressivity, but at What Cost ?](https://arxiv.org/abs/2510.10101)
*Martin Carrasco,Caio Deberaldini Netto,Vahan A. Martirosyan,Aneeqa Mehrab,Ehimare Okoyomon,Caterina Graziani*

Main category: cs.LG

TL;DR: GNN的表达能力与泛化能力之间存在权衡，表达能力越强，泛化误差越大。本文通过着色算法的视角，将WL着色的等价类数量与GNN的Rademacher复杂度联系起来，解释了这种权衡。


<details>
  <summary>Details</summary>
Motivation: 解释为什么GNN的表达能力越强，泛化误差越大。

Method: 将WL着色的等价类数量与GNN的Rademacher复杂度联系起来，分析表达能力对泛化能力的影响。

Result: GNN的Rademacher复杂度直接受WL着色的等价类数量的约束，表达能力越强，复杂度越高，泛化能力越弱。Rademacher复杂度对颜色数量的扰动稳定，确保了对采样变化的鲁棒性。

Conclusion: 本文统一了GNN的表达能力和泛化能力的研究，提供了对为什么增加表达能力通常会以泛化能力为代价的原则性理解。该框架适用于任意GNN架构和着色等价类划分的表达能力度量。

Abstract: The expressive power of graph neural networks (GNNs) is typically understood
through their correspondence with graph isomorphism tests such as the
Weisfeiler-Leman (WL) hierarchy. While more expressive GNNs can distinguish a
richer set of graphs, they are also observed to suffer from higher
generalization error. This work provides a theoretical explanation for this
trade-off by linking expressivity and generalization through the lens of
coloring algorithms. Specifically, we show that the number of equivalence
classes induced by WL colorings directly bounds the GNNs Rademacher complexity
-- a key data-dependent measure of generalization. Our analysis reveals that
greater expressivity leads to higher complexity and thus weaker generalization
guarantees. Furthermore, we prove that the Rademacher complexity is stable
under perturbations in the color counts across different samples, ensuring
robustness to sampling variability across datasets. Importantly, our framework
is not restricted to message-passing GNNs or 1-WL, but extends to arbitrary GNN
architectures and expressivity measures that partition graphs into equivalence
classes. These results unify the study of expressivity and generalization in
GNNs, providing a principled understanding of why increasing expressive power
often comes at the cost of generalization.

</details>


### [730] [Align2Act: Instruction-Tuned Models for Human-Aligned Autonomous Driving](https://arxiv.org/abs/2510.10503)
*Kanishkha Jaisankar,Sunidhi Tandel*

Main category: cs.LG

TL;DR: Align2Act 是一个运动规划框架，它将指令微调的大语言模型转化为可解释的、符合人类行为的规划器，在 nuPlan 闭环基准测试中取得了优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型（LLM）已被用于自主驾驶决策，但尚不清楚它们是否真正捕捉了人类驾驶逻辑。本研究旨在解决这一问题。

Method: Align2Act 通过结合人类推理模式和交通规则来生成结构化的驾驶指令。其 Align2ActChain 模块能够进行分步推理，从而生成可解释的理由和安全的轨迹。该方法使用 LoRA 在 nuPlan 数据集上对 LLaMA-2-7B 模型进行了微调。

Result: Align2Act 在 Test14-random 的开放环路测试中得分为 85.17，在闭环测试中（非反应式）得分为 70.31，（反应式）得分为 66.96。与以往仅关注合成或开放环路设置的研究不同，该方法在真实世界的 nuPlan 闭环基准测试中展示了更高的规划质量和更像人类的行为。

Conclusion: Align2Act 框架能够将大语言模型转化为可解释的、符合人类行为的运动规划器，并在真实世界的闭环基准测试中取得了优于先前方法的性能，验证了结构化推理对于提升规划质量的重要性。

Abstract: Motion planning in complex scenarios is a core challenge in autonomous
driving. Conventional methods apply predefined rules or learn from driving data
to generate trajectories, while recent approaches leverage large language
models (LLMs) for decision-making. However, it remains unclear whether LLMs
truly capture human driving logic. We propose Align2Act, a motion planning
framework that transforms instruction-tuned LLMs into interpretable planners
aligned with human behavior. We derive structured driving instructions based on
human reasoning patterns (e.g., anticipate hazards, yield at intersections) and
traffic rules (e.g., stop at red lights, maintain lane boundaries). Our
Align2ActChain module guides step-by-step reasoning to produce both an
interpretable rationale and a safe trajectory. By fine-tuning LLaMA-2-7B with
LoRA on one million scenarios from the nuPlan dataset, our method achieves an
open-loop score of 85.17 and closed-loop scores of 70.31 (non-reactive) and
66.96 (reactive) on Test14-random. Unlike prior work focused on synthetic or
open-loop settings, we demonstrate improved planning quality and human-likeness
on the real-world nuPlan closed-loop benchmark. Ablation studies confirm that
structured reasoning significantly improves performance over baseline LLM
planners.

</details>


### [731] [PANTHER: Generative Pretraining Beyond Language for Sequential User Behavior Modeling](https://arxiv.org/abs/2510.10102)
*Guilin Li,Yun Zhang,Xiuyuan Chen,Chengqi Li,Bo Wang,Linghe Kong,Wenjia Wang,Weiran Huang,Matthias Hwai Yong Tan*

Main category: cs.LG

TL;DR: PANTHER是一个混合生成-判别式框架，它将用户行为预训练和下游适应相结合，实现了大规模的序列用户表示学习和实时推理。它通过结构化标记化、序列模式识别模块、统一用户画像嵌入以及实时可扩展性来解决用户行为建模的挑战。PANTHER在微信支付的实际应用中显著提高了预测精度和欺诈检测召回率，并在公开基准测试中表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然能很好地提取世界知识，但在用户行为建模方面存在不足，因为用户行为数据具有高基数性和有限监督的特点。

Method: PANTHER采用混合生成-判别式框架，包括结构化标记化、序列模式识别模块（SPRM）、统一用户画像嵌入以及通过离线缓存实现的可扩展性。

Result: 在微信支付的实际应用中，PANTHER将下一交易预测的HitRate@1提高了25.6%，欺诈检测召回率相对提高了38.6%。在公开基准测试中，其HitRate@1比Transformer基线模型提高了21%。

Conclusion: PANTHER是一个可扩展、高性能的框架，适用于工业级的序列用户行为建模，能够有效地融合用户静态信息和动态行为，并支持实时推理。

Abstract: Large language models (LLMs) have shown that generative pretraining can
distill vast world knowledge into compact token representations. While LLMs
encapsulate extensive world knowledge, they remain limited in modeling the
behavioral knowledge contained within user interaction histories. User behavior
forms a distinct modality, where each action, defined by multi-dimensional
attributes such as time, context, and transaction type, constitutes a
behavioral token. Modeling these high-cardinality sequences is challenging, and
discriminative models often falter under limited supervision. To bridge this
gap, we extend generative pretraining to user behavior, learning transferable
representations from unlabeled behavioral data analogous to how LLMs learn from
text. We present PANTHER, a hybrid generative-discriminative framework that
unifies user behavior pretraining and downstream adaptation, enabling
large-scale sequential user representation learning and real-time inference.
PANTHER introduces: (1) Structured Tokenization to compress multi-dimensional
transaction attributes into an interpretable vocabulary; (2) Sequence Pattern
Recognition Module (SPRM) for modeling periodic transaction motifs; (3) a
Unified User-Profile Embedding that fuses static demographics with dynamic
transaction histories; and (4) Real-time scalability enabled by offline caching
of pretrained embeddings for millisecond-level inference. Fully deployed and
operational online at WeChat Pay, PANTHER delivers a 25.6 percent boost in
next-transaction prediction HitRate@1 and a 38.6 percent relative improvement
in fraud detection recall over baselines. Cross-domain evaluations on public
benchmarks show strong generalization, achieving up to 21 percent HitRate@1
gains over transformer baselines, establishing PANTHER as a scalable,
high-performance framework for industrial sequential user behavior modeling.

</details>


### [732] [Lighter-X: An Efficient and Plug-and-play Strategy for Graph-based Recommendation through Decoupled Propagation](https://arxiv.org/abs/2510.10105)
*Yanping Zheng,Zhewei Wei,Frank de Hoog,Xu Chen,Hongteng Xu,Yuhang Ye,Jiadeng Huang*

Main category: cs.LG

TL;DR: Lighter-X 框架通过压缩图结构和嵌入矩阵，并采用解耦设计，显著减少了 GNN 推荐模型的参数量和计算复杂度，同时保持了性能，实现了大规模部署。


<details>
  <summary>Details</summary>
Motivation: 现有基于 GNN 的推荐系统模型（如 LightGCN）存在参数量大（O(n*d)）和计算复杂度高的问题，难以在大型图上部署。

Method: 提出 Lighter-X 框架，通过分析 GNN 参数的冗余性，设计了稀疏邻接结构和高维嵌入矩阵的压缩方案（参数复杂度 O(h*d)，h<<n），并采用解耦框架优化训练过程，降低计算复杂度。

Result: Lighter-X 在大规模交互图上实现了与基线模型相当甚至更好的性能，参数量仅为 LightGCN 的 1%。

Conclusion: Lighter-X 框架有效解决了 GNN 推荐系统在大规模图上的部署挑战，实现了参数量和计算复杂度的显著降低，同时保持了推荐性能。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable effectiveness in
recommendation systems. However, conventional graph-based recommenders, such as
LightGCN, require maintaining embeddings of size $d$ for each node, resulting
in a parameter complexity of $\mathcal{O}(n \times d)$, where $n$ represents
the total number of users and items. This scaling pattern poses significant
challenges for deployment on large-scale graphs encountered in real-world
applications. To address this scalability limitation, we propose
\textbf{Lighter-X}, an efficient and modular framework that can be seamlessly
integrated with existing GNN-based recommender architectures. Our approach
substantially reduces both parameter size and computational complexity while
preserving the theoretical guarantees and empirical performance of the base
models, thereby enabling practical deployment at scale. Specifically, we
analyze the original structure and inherent redundancy in their parameters,
identifying opportunities for optimization. Based on this insight, we propose
an efficient compression scheme for the sparse adjacency structure and
high-dimensional embedding matrices, achieving a parameter complexity of
$\mathcal{O}(h \times d)$, where $h \ll n$. Furthermore, the model is optimized
through a decoupled framework, reducing computational complexity during the
training process and enhancing scalability. Extensive experiments demonstrate
that Lighter-X achieves comparable performance to baseline models with
significantly fewer parameters. In particular, on large-scale interaction
graphs with millions of edges, we are able to attain even better results with
only 1\% of the parameter over LightGCN.

</details>


### [733] [CacheClip: Accelerating RAG with Effective KV Cache Reuse](https://arxiv.org/abs/2510.10129)
*Bin Yang,Qiuyu Leng,Jun Zeng,Zhenhua Wu*

Main category: cs.LG

TL;DR: CacheClip 通过利用小型辅助 LLM 来模仿主 LLM 的注意力分布，选择性地重新计算 KV 缓存，从而解决了 RAG 系统中时间延迟问题，并提高了生成质量。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）系统因长输入序列而面临严重的时间延迟（TTFT）瓶颈，现有的 KV 缓存重用方法在 RAG 场景下存在缓存命中率低或生成质量下降的问题。

Method: CacheClip 框架通过三种技术解决此问题：（1）辅助模型引导的 token 选择，选择性地重新计算 KV 缓存；（2）共享前缀以消除冗余注意力汇聚点；（3）分组策略以在部分 KV 缓存更新期间保持局部一致性。

Result: CacheClip 在 NIAH 和 LongBench 数据集上保留了高达 94.8% 和 85.0% 的全注意力性能，在 NIAH 数据集上（recomp% = 20%）比 APE 和 CacheBlend 分别提高了 25.2% 和 35.1%。此外，CacheClip 的预填充时间最高可提高 1.92 倍。

Conclusion: CacheClip 在 RAG 系统中有效解决了效率和质量的权衡问题，显著提高了 TTFT 并保持了生成质量。

Abstract: Retrieval-Augmented Generation (RAG) systems suffer from severe
time-to-first-token (TTFT) bottlenecks due to long input sequences. Existing KV
cache reuse methods face a fundamental trade-off: prefix caching requires
identical prefixes that rarely occur in RAG scenarios, while direct
precomputation sacrifices quality due to missing inter-chunk attention and
repeated attention sinks. Recent methods like APE and CacheBlend partially
address these issues but remain inadequate for robust RAG applications. This
paper presents CacheClip, a novel framework that achieves both fast TTFT and
high generation quality. Our key insight is that small auxiliary LLMs exhibit
similar last-layer attention distributions to primary LLMs (the target model
for generation), enabling efficient identification of tokens critical for
restoring inter-chunk attention, thereby significantly improving response
quality on cross-chunk reasoning tasks. CacheClip integrates three techniques:
(1) auxiliary-model-guided token selection for selective KV cache
recomputation, where the auxiliary model is finetuned to improve selection
accuracy, (2) shared prefixes to eliminate redundant attention sinks, and (3)
grouping strategy to maintain local coherence during partial KV cache updates.
Experiments show CacheClip retains up to 94.8% and 85.0% of full-attention
performance on NIAH and LongBench, outperforming APE and CacheBlend by 25.2%
and 35.1% on NIAH (with reomp% = 20%). Meanwhile, CacheClip accelerates LLM
inference by up to 1.92x in prefill time, providing a practical solution to the
efficiency-quality trade-off in RAG systems.

</details>


### [734] [PermLLM: Learnable Channel Permutation for N:M Sparse Large Language Models](https://arxiv.org/abs/2510.10136)
*Lancheng Zou,Shuo Yin,Zehua Pei,Tsung-Yi Ho,Farzan Farnia,Bei Yu*

Main category: cs.LG

TL;DR: PermLLM是一种新的N:M稀疏模型剪枝框架，通过可学习的通道排列（LCP）利用Sinkhorn归一化实现端到端优化，并结合块状通道排列策略，有效提高了稀疏模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统通道排列方法依赖手工设计的质量指标，无法准确捕捉剪枝对模型性能的影响。本研究提出PermLLM，旨在解决这一局限性。

Method: PermLLM提出可学习通道排列（LCP）技术，利用Sinkhorn归一化将离散排列矩阵转化为可微分的软排列矩阵，并采用高效的块状通道排列策略，与现有的一触式剪枝方法相结合，以自适应地优化通道排列。

Result: 在LLaMA系列、Qwen和OPT模型上的大量实验表明，PermLLM在优化N:M稀疏模型方面取得了优越的性能。

Conclusion: PermLLM通过引入可学习通道排列和高效的块状策略，能够有效缓解剪枝带来的误差，并提升N:M稀疏模型的性能。

Abstract: Channel permutation is a powerful technique for enhancing the accuracy of N:M
sparse models by reordering the channels of weight matrices to prioritize the
retention of important weights. However, traditional channel permutation
methods rely on handcrafted quality metrics, which often fail to accurately
capture the true impact of pruning on model performance. To address this
limitation, we propose PermLLM, a novel post-training pruning framework that
introduces learnable channel permutation (LCP) for N:M sparsity. LCP leverages
Sinkhorn normalization to transform discrete permutation matrices into
differentiable soft permutation matrices, enabling end-to-end optimization.
Additionally, PermLLM incorporates an efficient block-wise channel permutation
strategy, which significantly reduces the number of learnable parameters and
computational complexity. PermLLM seamlessly integrates with existing one-shot
pruning methods to adaptively optimize channel permutations, effectively
mitigating pruning-induced errors. Extensive experiments on the LLaMA series,
Qwen, and OPT models demonstrate that PermLLM achieves superior performance in
optimizing N:M sparse models. The code is available at
https://github.com/lanchengzou/PermLLM.

</details>


### [735] [Context-Aware Model-Based Reinforcement Learning for Autonomous Racing](https://arxiv.org/abs/2510.11501)
*Emran Yasser Moustafa,Ivana Dusparic*

Main category: cs.LG

TL;DR: MBRL算法在自动驾驶中表现出良好的性能和数据效率，但容易受到环境变化的影响。本文提出了一种名为cMask的上下文感知MBRL方法，以提高其泛化能力和在Roboracer环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在真实世界中部署自动驾驶等安全关键技术，需要能够泛化到未见场景和数据的算法。MBRL算法虽然性能优越且数据效率高，但对环境变化敏感。

Method: 将Roboracer环境中的赛车任务构建为上下文马尔可夫决策过程，并使用上下文参数化对手的行为，从而参数化转移和奖励动态。提出了一种名为cMask的上下文感知MBRL方法。

Result: 与上下文无关的方法相比，上下文感知MBRL算法在应对分布外对手行为时具有更好的泛化能力。cMask在与分布内对手行为比赛时，也表现出强大的泛化能力和进一步的性能提升。

Conclusion: 上下文感知MBRL算法，特别是cMask，在自动驾驶任务中比上下文无关的方法具有更强的泛化能力，并且能够进一步提升性能。

Abstract: Autonomous vehicles have shown promising potential to be a groundbreaking
technology for improving the safety of road users. For these vehicles, as well
as many other safety-critical robotic technologies, to be deployed in
real-world applications, we require algorithms that can generalize well to
unseen scenarios and data. Model-based reinforcement learning algorithms (MBRL)
have demonstrated state-of-the-art performance and data efficiency across a
diverse set of domains. However, these algorithms have also shown
susceptibility to changes in the environment and its transition dynamics.
  In this work, we explore the performance and generalization capabilities of
MBRL algorithms for autonomous driving, specifically in the simulated
autonomous racing environment, Roboracer (formerly F1Tenth). We frame the
head-to-head racing task as a learning problem using contextual Markov decision
processes and parameterize the driving behavior of the adversaries using the
context of the episode, thereby also parameterizing the transition and reward
dynamics. We benchmark the behavior of MBRL algorithms in this environment and
propose a novel context-aware extension of the existing literature, cMask. We
demonstrate that context-aware MBRL algorithms generalize better to
out-of-distribution adversary behaviors relative to context-free approaches. We
also demonstrate that cMask displays strong generalization capabilities, as
well as further performance improvement relative to other context-aware MBRL
approaches when racing against adversaries with in-distribution behaviors.

</details>


### [736] [Adversarial Attacks on Downstream Weather Forecasting Models: Application to Tropical Cyclone Trajectory Prediction](https://arxiv.org/abs/2510.10140)
*Yue Deng,Francisco Santos,Pang-Ning Tan,Lifeng Luo*

Main category: cs.LG

TL;DR: Cyc-Attack 是一种新颖的方法，通过扰乱深度学习天气预报 (DLWF) 模型的上游预报来生成对抗性热带气旋 (TC) 轨迹，解决了传统方法在处理不透明的 TC 检测系统、类别不平衡和物理一致性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究深度学习天气预报 (DLWF) 模型在热带气旋 (TC) 轨迹预测中的对抗性攻击漏洞，并提出一种能有效生成对抗性轨迹的新方法。

Method: Cyc-Attack 提出了一种新颖的方法，包括：1. 预训练一个可微分的代理模型来近似 TC 检测器的输出，从而实现基于梯度的攻击。2. 采用偏度感知损失函数和核扩展策略来解决类别不平衡问题。3. 利用基于距离的梯度加权方案和正则化来约束扰动，消除虚假轨迹，确保预测的物理一致性和隐蔽性。

Result: Cyc-Attack 能够生成能够可靠地将下游 TC 轨迹预测引导至攻击者指定轨迹的对抗性上游预报，同时保持物理一致性并且难以被检测。

Conclusion: Cyc-Attack 成功地解决了当前 DLWF 模型对抗性攻击中的关键挑战，为生成更鲁棒和安全的 DLWF 模型提供了新的途径。

Abstract: Deep learning based weather forecasting (DLWF) models leverage past weather
observations to generate future forecasts, supporting a wide range of
downstream tasks, including tropical cyclone (TC) trajectory prediction. In
this paper, we investigate their vulnerability to adversarial attacks, where
subtle perturbations to the upstream weather forecasts can alter the downstream
TC trajectory predictions. Although research on adversarial attacks in DLWF
models has grown recently, generating perturbed upstream forecasts that
reliably steer downstream output toward attacker-specified trajectories remains
a challenge. First, conventional TC detection systems are opaque,
non-differentiable black boxes, making standard gradient-based attacks
infeasible. Second, the extreme rarity of TC events leads to severe class
imbalance problem, making it difficult to develop efficient attack methods that
will produce the attacker's target trajectories. Furthermore, maintaining
physical consistency in adversarially generated forecasts presents another
significant challenge. To overcome these limitations, we propose Cyc-Attack, a
novel method that perturbs the upstream forecasts of DLWF models to generate
adversarial trajectories. First, we pre-train a differentiable surrogate model
to approximate the TC detector's output, enabling the construction of
gradient-based attacks. Cyc-Attack also employs skewness-aware loss function
with kernel dilation strategy to address the imbalance problem. Finally, a
distance-based gradient weighting scheme and regularization are used to
constrain the perturbations and eliminate spurious trajectories to ensure the
adversarial forecasts are realistic and not easily detectable.

</details>


### [737] [A Unified Frequency Domain Decomposition Framework for Interpretable and Robust Time Series Forecasting](https://arxiv.org/abs/2510.10145)
*Cheng He,Xijie Liang,Zengrong Zheng,Patrick P. C. Lee,Xu Huang,Zhaoyi Li,Hong Xie,Defu Lian,Enhong Chen*

Main category: cs.LG

TL;DR: FIRE是一个统一的频域分解框架，通过独立建模振幅和相位分量、自适应学习频率基分量权重、目标损失函数以及用于稀疏数据的训练范式，实现可解释、鲁棒的时间序列预测，并在长期预测基准上持续优于最先进的模型。


<details>
  <summary>Details</summary>
Motivation: 当前时间序列预测模型（包括时间域和频域）主要依赖深度学习模型，这些模型通常以黑盒方式编码数据，并仅基于预测性能进行反复试验优化，导致可解释性和理论理解有限。此外，数据在时域和频域上的动态分布变化给准确预测带来了严峻挑战。

Method: FIRE框架引入了几个关键创新：(i) 振幅和相位分量的独立建模，(ii) 频率基分量权重的自适应学习，(iii) 目标损失函数，以及 (iv) 用于稀疏数据的新颖训练范式。

Result: 大量实验表明，FIRE在长期预测基准上持续优于最先进的模型，实现了卓越的预测性能，并显著增强了时间序列的可解释性。

Conclusion: FIRE通过其统一的频域分解框架，在时间序列预测领域提供了一种可解释且鲁棒的方法，克服了现有模型的局限性，并在实验中取得了优于最先进水平的成果。

Abstract: Current approaches for time series forecasting, whether in the time or
frequency domain, predominantly use deep learning models based on linear layers
or transformers. They often encode time series data in a black-box manner and
rely on trial-and-error optimization solely based on forecasting performance,
leading to limited interpretability and theoretical understanding. Furthermore,
the dynamics in data distribution over time and frequency domains pose a
critical challenge to accurate forecasting. We propose FIRE, a unified
frequency domain decomposition framework that provides a mathematical
abstraction for diverse types of time series, so as to achieve interpretable
and robust time series forecasting. FIRE introduces several key innovations:
(i) independent modeling of amplitude and phase components, (ii) adaptive
learning of weights of frequency basis components, (iii) a targeted loss
function, and (iv) a novel training paradigm for sparse data. Extensive
experiments demonstrate that FIRE consistently outperforms state-of-the-art
models on long-term forecasting benchmarks, achieving superior predictive
performance and significantly enhancing interpretability of time series

</details>


### [738] [Robust Learning of Diffusion Models with Extremely Noisy Conditions](https://arxiv.org/abs/2510.10149)
*Xin Chen,Gillian Dobbie,Xinyu Wang,Feng Liu,Di Wang,Jingfeng Zhang*

Main category: cs.LG

TL;DR: 本研究提出了一种用于解决条件扩散模型在处理噪声条件时性能下降问题的鲁棒学习框架，通过学习和改进伪条件，并结合反向时间扩散条件技术，在图像生成和视觉-动作策略生成任务上均取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的条件扩散模型在处理噪声条件（如损坏的标签或不可靠的观测/状态）时，其性能会显著下降。本研究旨在解决条件扩散模型在极端噪声条件下的鲁棒性问题。

Method: 本研究提出了一种鲁棒学习框架，通过学习伪条件作为清洁条件的替代，并利用时间集成技术逐步改进这些伪条件。此外，还开发了一种反向时间扩散条件（RDC）技术，用于扩散伪条件以增强记忆效应并促进伪条件的改进。

Result: 在各种噪声水平下，本研究提出的方法在类别条件图像生成和视觉-动作策略生成任务上均取得了最先进的性能。

Conclusion: 本研究提出的鲁棒学习框架能够有效地解决条件扩散模型在极端噪声条件下的性能下降问题，并在多个任务上实现了最先进的性能。

Abstract: Conditional diffusion models have the generative controllability by
incorporating external conditions. However, their performance significantly
degrades with noisy conditions, such as corrupted labels in the image
generation or unreliable observations or states in the control policy
generation. This paper introduces a robust learning framework to address
extremely noisy conditions in conditional diffusion models. We empirically
demonstrate that existing noise-robust methods fail when the noise level is
high. To overcome this, we propose learning pseudo conditions as surrogates for
clean conditions and refining pseudo ones progressively via the technique of
temporal ensembling. Additionally, we develop a Reverse-time Diffusion
Condition (RDC) technique, which diffuses pseudo conditions to reinforce the
memorization effect and further facilitate the refinement of the pseudo
conditions. Experimentally, our approach achieves state-of-the-art performance
across a range of noise levels on both class-conditional image generation and
visuomotor policy generation tasks.The code can be accessible via the project
page https://robustdiffusionpolicy.github.io

</details>


### [739] [Rethinking Entropy Interventions in RLVR: An Entropy Change Perspective](https://arxiv.org/abs/2510.10150)
*Zhezheng Hao,Hong Wang,Haoyang Liu,Jian Luo,Jiarui Yu,Hande Dong,Qiang Lin,Can Wang,Jiawei Chen*

Main category: cs.LG

TL;DR: RLVR训练中的熵衰减问题阻碍了LLM的泛化能力，现有方法效果有限。本文提出的STEER方法通过精细化token级别的调整来稳定熵，提高了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: RLVR训练中存在熵衰减风险，现有干预方法机制不明且效果受限，需要新的方法来解决。

Method: 提出了一种名为STEER（Stabilizing Token-level Entropy-changE via Reweighting）的熵变化感知重加权方案，通过token级别的自适应调整来稳定熵。

Result: STEER有效缓解了熵衰减，稳定了熵动态，并在数学推理基准测试中取得了更好的下游性能。

Conclusion: STEER通过直接、精细化的token级别调整，克服了现有间接干预方法的局限性，能有效解决RLVR中的熵衰减问题，并提升模型性能。

Abstract: While Reinforcement Learning with Verifiable Rewards (RLVR) can enhance LLM
reasoning, its training process poses a critical risk: entropy collapse. This
phenomenon is a rapid loss of policy diversity, stemming from the
exploration-exploitation imbalance and leading to a lack of generalization.
Recent entropy-intervention methods aim to prevent \coloredtext{entropy
collapse}, yet their underlying mechanisms remain unclear. In this paper, we
conduct a quantitative analysis to reveal token-level entropy changes and how
existing entropy intervention methods help avoid entropy collapse. Our findings
point out a fundamental limitation of existing methods: they attempt to control
entropy dynamics indirectly. By only affecting related factors, such as the
advantage signal and generation probability, their effectiveness is inherently
limited and could potentially fail. To address this limitation, we introduce an
entropy-change-aware reweighting scheme, namely Stabilizing Token-level
Entropy-changE via Reweighting (STEER), that adaptively stabilizes entropy
dynamics through fine-grained token-level adjustments. Our approach mitigates
over-exploitation while fostering robust exploration. Extensive experiments
demonstrate that STEER significantly mitigates entropy collapse, stabilizes
entropy dynamics, and achieves stronger downstream performance across various
mathematical reasoning benchmarks \footnote{Our code is available at
https://github.com/zz-haooo/STEER.

</details>


### [740] [INR-Bench: A Unified Benchmark for Implicit Neural Representations in Multi-Domain Regression and Reconstruction](https://arxiv.org/abs/2510.10188)
*Linfei Li,Fengyi Zhang,Zhong Wang,Lin Zhang,Ying Shen*

Main category: cs.LG

TL;DR: INR-Bench 是一个用于多模态隐式神经表示 (INR) 任务的基准测试，它通过分析不同模型架构、位置编码和非线性原语对不同频率信号的响应来评估 INR 的有效性。


<details>
  <summary>Details</summary>
Motivation: 隐式神经表示 (INR) 在信号处理任务中取得了一定的成功，但影响其有效性和局限性的因素仍未得到充分探索。

Method: 利用神经切线核 (NTK) 理论分析了模型架构（MLP 和 KAN）、位置编码和非线性原语如何影响对不同频率信号的响应。在此基础上，提出了 INR-Bench 基准测试，包含 56 种 Coordinate-MLP 模型变体和 22 种 Coordinate-KAN 模型，并在 9 种隐式多模态任务上进行了评估。

Result: INR-Bench 包含大量的模型变体和多模态任务，为评估和比较不同的 INR 模型提供了全面的平台，突出了不同神经模型的优势和局限性。

Conclusion: INR-Bench 为隐式神经表示的研究奠定了坚实的基础，有助于未来相关研究的发展。

Abstract: Implicit Neural Representations (INRs) have gained success in various signal
processing tasks due to their advantages of continuity and infinite resolution.
However, the factors influencing their effectiveness and limitations remain
underexplored. To better understand these factors, we leverage insights from
Neural Tangent Kernel (NTK) theory to analyze how model architectures (classic
MLP and emerging KAN), positional encoding, and nonlinear primitives affect the
response to signals of varying frequencies. Building on this analysis, we
introduce INR-Bench, the first comprehensive benchmark specifically designed
for multimodal INR tasks. It includes 56 variants of Coordinate-MLP models
(featuring 4 types of positional encoding and 14 activation functions) and 22
Coordinate-KAN models with distinct basis functions, evaluated across 9
implicit multimodal tasks. These tasks cover both forward and inverse problems,
offering a robust platform to highlight the strengths and limitations of
different neural models, thereby establishing a solid foundation for future
research. The code and dataset are available at
https://github.com/lif314/INR-Bench.

</details>


### [741] [CauchyNet: Compact and Data-Efficient Learning using Holomorphic Activation Functions](https://arxiv.org/abs/2510.10195)
*Hong-Kun Zhang,Xin Li,Sikun Yang,Zhihong Xia*

Main category: cs.LG

TL;DR: 提出了一种名为CauchyNet的新型神经网络，该网络受柯西积分公式启发，用于函数逼近任务（如时间序列预测、缺失数据填充等）。


<details>
  <summary>Details</summary>
Motivation: 传统模型在处理复杂时间依赖性和不完整数据时存在局限性。

Method: CauchyNet将实值数据嵌入复平面，并采用复值激活函数，利用柯西积分公式和通用逼近定理进行函数逼近。

Result: 在交通、能源消耗和流行病学等领域的数据集上，CauchyNet的预测准确性优于最先进的模型，平均绝对误差降低了50%，且参数更少。

Conclusion: CauchyNet是一种有效且高效的函数逼近工具，尤其适用于资源受限和数据稀疏的环境。

Abstract: A novel neural network inspired by Cauchy's integral formula, is proposed for
function approximation tasks that include time series forecasting, missing data
imputation, etc. Hence, the novel neural network is named CauchyNet. By
embedding real-valued data into the complex plane, CauchyNet efficiently
captures complex temporal dependencies, surpassing traditional real-valued
models in both predictive performance and computational efficiency. Grounded in
Cauchy's integral formula and supported by the universal approximation theorem,
CauchyNet offers strong theoretical guarantees for function approximation. The
architecture incorporates complex-valued activation functions, enabling robust
learning from incomplete data while maintaining a compact parameter footprint
and reducing computational overhead. Through extensive experiments in diverse
domains, including transportation, energy consumption, and epidemiological
data, CauchyNet consistently outperforms state-of-the-art models in predictive
accuracy, often achieving a 50% lower mean absolute error with fewer
parameters. These findings highlight CauchyNet's potential as an effective and
efficient tool for data-driven predictive modeling, particularly in
resource-constrained and data-scarce environments.

</details>


### [742] [RLFR: Extending Reinforcement Learning for LLMs with Flow Environment](https://arxiv.org/abs/2510.10201)
*Jinghao Zhang,Naishan Zheng,Ruilin Li,Dongzhou Cheng,Zheming Liang,Feng Zhao,Jiaqi Wang*

Main category: cs.LG

TL;DR: RLFR框架利用潜在空间中的流场信息来指导大语言模型的强化学习过程，解决了传统RLVR方法忽略潜在推理路径的问题，并在语言和多模态推理任务上取得了可靠结果。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在优化过程中容易忽略有价值的推理探索，而标注黄金过程奖励模型（PRMs）成本高昂。现有方法尝试使用来自logit空间的熵和似然等辅助信号进行奖励塑造，但本文提出一种新颖的基于潜在空间流场的奖励塑造方法。

Method: RLFR方法构建由离线高质量数据和在线拒绝采样数据生成的模型潜变量的流场，并通过量化策略潜变量在流场中的速度偏差来获得奖励信号。该方法利用了隐藏状态中压缩的上下文依赖性，而非单独的token级别的标注。

Result: 实验证明，流奖励在语言和多模态推理基准测试中是可靠的，并且RLFR能够压缩任何离线专家数据作为参考来构建奖励信号，利用了隐藏状态中压缩的上下文依赖性。

Conclusion: RLFR提出了一种利用潜在空间流场信息进行奖励塑造的新范式，能够有效地利用离线专家数据，并在多个推理任务上展现出可靠性和潜力。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a promising framework for improving reasoning abilities in Large Language
Models (LLMs). However, policy optimized with binary verification prone to
overlook potential valuable exploration in reasoning trajectory. In view of
heavy annotation cost of golden Process Reward Models (PRMs), recent works
attempt using auxiliary signals for reward shaping of process tokens, involving
entropy and likelihood collected from logit space. In this work, we offer a
novel perspective on shaping RLVR with flow rewards derived from latent space,
and propose RLFR, where the flow fields of model latents are constructed from
either off-policy high-quality data and on-policy rejection sampling data, and
the velocity deviations of policy latents within it are quantified to serve as
a reward signal. RLFR first demonstrates that a well-established flow field can
be a sound environment for reward signal collection, highlighting the
expressive latent space is much underexplored. Moreover, RLFR is able to
compress any off-policy expert data as reference for constituting reward
signals, and we show that the efficient context dependence compressed within
the hidden states are utilized, rather than individual token-level denotation
for context comprehending. Experiments on both language and multimodal
reasoning benchmarks demonstrate the reliability of flow rewards, and
suggesting a promising paradigm for reward shaping with auxiliary signals.

</details>


### [743] [Hierarchical Bayesian Flow Networks for Molecular Graph Generation](https://arxiv.org/abs/2510.10211)
*Yida Xiong,Jiameng Chen,Kun Li,Hongzhi Zhang,Xiantao Cai,Wenbin Hu*

Main category: cs.LG

TL;DR: 分子图生成应被视为分类而非回归任务。现有方法（如扩散模型）在训练时将其视为回归问题，并在推理时进行四舍五入，这会导致训练和推理之间的不匹配。为解决此问题，我们提出了GraphBFN，一个基于贝叶斯流网络的框架，它通过引入累积分布函数来统一训练和采样过程，从而提高性能和生成速度。


<details>
  <summary>Details</summary>
Motivation: 当前分子图生成模型（如扩散模型）将任务视为回归问题，在训练时预测连续值，推理时进行四舍五入。这种方法在训练目标和推理过程之间存在不匹配，导致过度拟合、学习效率低下、分子多样性降低和泛化能力受限。

Method: 提出了一种名为GraphBFN的新型分层粗粒度到细粒度框架，该框架基于贝叶斯流网络，并作用于分布参数。通过引入累积分布函数，GraphBFN能够计算选择正确类别的概率，从而将训练目标与采样四舍五入操作统一起来。

Result: GraphBFN在QM9和ZINC250k分子图生成基准测试中取得了优于现有方法和更快的生成速度，并达到了新的最先进水平。

Conclusion: GraphBFN通过将训练目标与采样四舍五入操作统一起来，成功解决了当前分子图生成模型中存在的训练-推理不匹配问题，提高了性能、生成速度和分子多样性。

Abstract: Molecular graph generation is essentially a classification generation
problem, aimed at predicting categories of atoms and bonds. Currently,
prevailing paradigms such as continuous diffusion models are trained to predict
continuous numerical values, treating the training process as a regression
task. However, the final generation necessitates a rounding step to convert
these predictions back into discrete classification categories, which is
intrinsically a classification operation. Given that the rounding operation is
not incorporated during training, there exists a significant discrepancy
between the model's training objective and its inference procedure. As a
consequence, an excessive emphasis on point-wise precision can lead to
overfitting and inefficient learning. This occurs because considerable efforts
are devoted to capturing intra-bin variations that are ultimately irrelevant to
the discrete nature of the task at hand. Such a flaw results in diminished
molecular diversity and constrains the model's generalization capabilities. To
address this fundamental limitation, we propose GraphBFN, a novel hierarchical
coarse-to-fine framework based on Bayesian Flow Networks that operates on the
parameters of distributions. By innovatively introducing Cumulative
Distribution Function, GraphBFN is capable of calculating the probability of
selecting the correct category, thereby unifying the training objective with
the sampling rounding operation. We demonstrate that our method achieves
superior performance and faster generation, setting new state-of-the-art
results on the QM9 and ZINC250k molecular graph generation benchmarks.

</details>


### [744] [SGM: A Statistical Godel Machine for Risk-Controlled Recursive Self-Modification](https://arxiv.org/abs/2510.10232)
*Xuening Wu,Shenqin Yin,Yanlan Kang,Xinhang Zhang,Qianya Xu,Zeping Chen,Wenqiang Zhang*

Main category: cs.LG

TL;DR: SGM是一种用于自动机器学习的统计安全层，通过置信度测试而非形式证明来确保代码的安全递归修改，以控制累积风险。


<details>
  <summary>Details</summary>
Motivation: 自动机器学习（AutoML）、神经网络架构搜索和自适应优化中，递归自我修改日益重要，但现有框架缺乏安全保障。Godel机提供了基于形式证明的保障，但在随机、高维环境中不可行。

Method: 提出统计Godel机（SGM），用统计置信度检验（e-值、Hoeffding界限）替代证明要求，并引入确认触发谐波支出（CTHS）来分配全局误差预算，只允许在选定置信水平下被认证的改进，并将误差预算集中在有希望的修改上。

Result: 在监督学习、强化学习和黑盒优化方面的实验表明，SGM在CIFAR-100上验证了真正的收益，在ImageNet-100上拒绝了虚假的改进，并在强化学习和优化基准测试中表现出鲁棒性。

Conclusion: SGM是持续的、风险感知的学习系统自我修改的基础设施。

Abstract: Recursive self-modification is increasingly central in AutoML, neural
architecture search, and adaptive optimization, yet no existing framework
ensures that such changes are made safely. Godel machines offer a principled
safeguard by requiring formal proofs of improvement before rewriting code;
however, such proofs are unattainable in stochastic, high-dimensional settings.
We introduce the Statistical Godel Machine (SGM), the first statistical safety
layer for recursive edits. SGM replaces proof-based requirements with
statistical confidence tests (e-values, Hoeffding bounds), admitting a
modification only when superiority is certified at a chosen confidence level,
while allocating a global error budget to bound cumulative risk across
rounds.We also propose Confirm-Triggered Harmonic Spending (CTHS), which
indexes spending by confirmation events rather than rounds, concentrating the
error budget on promising edits while preserving familywise
validity.Experiments across supervised learning, reinforcement learning, and
black-box optimization validate this role: SGM certifies genuine gains on
CIFAR-100, rejects spurious improvement on ImageNet-100, and demonstrates
robustness on RL and optimization benchmarks.Together, these results position
SGM as foundational infrastructure for continual, risk-aware self-modification
in learning systems.Code is available at:
https://github.com/gravitywavelet/sgm-anon.

</details>


### [745] [Progressive Scale Convolutional Network for Spatio-Temporal Downscaling of Soil Moisture: A Case Study Over the Tibetan Plateau](https://arxiv.org/abs/2510.10244)
*Ziyu Zhou,Keyan Hu,Ling Zhang,Zhaohui Xue,Yutian Fang,Yusha Zheng*

Main category: cs.LG

TL;DR: 该研究提出了一种名为PSCNet的新型卷积网络，结合ERA5-Land数据，实现了高分辨率土壤湿度的时空降尺度，并在青藏高原验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有技术中因地表辅助因子不完整而导致的土壤湿度时间尺度反演的限制，本研究旨在通过结合低分辨率SMAP土壤湿度产品和高时间分辨率的ERA5-Land变量，实现土壤湿度的时空降尺度。

Method: 本研究提出了一种名为PSCNet（progressive scale convolutional network）的网络模型，该模型包含多频 temporal fusion 模块（MFTF）用于捕捉时间动态，以及专门设计的 squeeze-and-excitation（SE）模块以保留精细空间细节。将ERA5-Land变量引入SMAP土壤湿度产品的降尺度过程。

Result: 研究成功获得了2016年至2018年青藏高原10公里空间分辨率、3小时时间分辨率的无缝土壤湿度产品。实验结果表明，PSCNet在卫星产品验证中精度相当且误差更低（平均R值为0.881），优于其他方法；在实测站点验证中，PSCNet在R指标上始终排名前三，并且在整体误差降低方面表现更优；在时间泛化验证中，所有方法均保持了R指标低于6%和ubRMSE指标低于2%的平均相对误差，证实了使用高时间分辨率ERA5-Land变量进行降尺度的可行性；在时间动态和可视化验证中，PSCNet展现了出色的时间敏感性和生动的空间细节。

Conclusion: PSCNet通过有效模拟土壤湿度数据中复杂的时空关系，为土壤湿度数据的时空降尺度提供了一个有前景的解决方案。

Abstract: Soil moisture (SM) plays a critical role in hydrological and meteorological
processes. High-resolution SM can be obtained by combining coarse passive
microwave data with fine-scale auxiliary variables. However, the inversion of
SM at the temporal scale is hindered by the incompleteness of surface auxiliary
factors. To address this issue, first, we introduce validated high temporal
resolution ERA5-Land variables into the downscaling process of the
low-resolution SMAP SM product. Subsequently, we design a progressive scale
convolutional network (PSCNet), at the core of which are two innovative
components: a multi-frequency temporal fusion module (MFTF) for capturing
temporal dynamics, and a bespoke squeeze-and-excitation (SE) block designed to
preserve fine-grained spatial details. Using this approach, we obtained
seamless SM products for the Tibetan Plateau (TP) from 2016 to 2018 at 10-km
spatial and 3-hour temporal resolution. The experimental results on the TP
demonstrated the following: 1) In the satellite product validation, the PSCNet
exhibited comparable accuracy and lower error, with a mean R value of 0.881,
outperforming other methods. 2) In the in-situ site validation, PSCNet
consistently ranked among the top three models for the R metric across all
sites, while also showing superior performance in overall error reduction. 3)
In the temporal generalization validation, the feasibility of using
high-temporal resolution ERA5-Land variables for downscaling was confirmed, as
all methods maintained an average relative error within 6\% for the R metric
and 2\% for the ubRMSE metric. 4) In the temporal dynamics and visualization
validation, PSCNet demonstrated excellent temporal sensitivity and vivid
spatial details. Overall, PSCNet provides a promising solution for
spatio-temporal downscaling by effectively modeling the intricate
spatio-temporal relationships in SM data.

</details>


### [746] [Reasoning-Enhanced Large Language Models for Molecular Property Prediction](https://arxiv.org/abs/2510.10248)
*Jiaxi Zhuang,Yaorui Shi,Jue Hou,Yunong He,Mingwei Ye,Mingjun Xu,Yuming Su,Linfeng Zhang,Linfeng Zhang,Guolin Ke,Hengxing Cai*

Main category: cs.LG

TL;DR: MPPReasoner是一个结合化学推理能力的多模态大语言模型，用于分子属性预测，解决了现有方法的解释性差、跨任务泛化能力弱和缺乏化学推理能力等问题。该模型通过结合分子图像和SMILES字符串，采用两阶段训练策略（SFT和RLPGR），并在8个数据集上取得了显著的性能提升，尤其在跨任务泛化和模型可解释性方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有分子属性预测方法存在解释性差、跨任务泛化能力弱、缺乏化学推理能力等问题，MPPReasoner旨在解决这些局限性。

Method: MPPReasoner基于Qwen2.5-VL-7B-Instruct模型，结合分子图像和SMILES字符串，采用监督微调（SFT）和基于原则指导奖励的强化学习（RLPGR）两阶段训练策略，RLPGR利用计算验证来评估化学原理的应用、分子结构分析和逻辑一致性。

Result: 在8个数据集上的广泛实验表明，MPPReasoner的性能显著优于现有方法，在 in-distribution 和 out-of-distribution 任务上分别超出最佳基线 7.91% 和 4.53%。

Conclusion: MPPReasoner在分子属性预测方面展现了卓越的跨任务泛化能力，并能生成化学上合理的推理路径，提高了模型的可解释性和实际应用价值。

Abstract: Molecular property prediction is crucial for drug discovery and materials
science, yet existing approaches suffer from limited interpretability, poor
cross-task generalization, and lack of chemical reasoning capabilities.
Traditional machine learning models struggle with task transferability, while
specialized molecular language models provide little insight into their
decision-making processes. To address these limitations, we propose
\textbf{MPPReasoner}, a multimodal large language model that incorporates
chemical reasoning for molecular property prediction. Our approach, built upon
Qwen2.5-VL-7B-Instruct, integrates molecular images with SMILES strings to
enable comprehensive molecular understanding. We develop a two-stage training
strategy: supervised fine-tuning (SFT) using 16,000 high-quality reasoning
trajectories generated through expert knowledge and multiple teacher models,
followed by Reinforcement Learning from Principle-Guided Rewards (RLPGR). RLPGR
employs verifiable, rule-based rewards that systematically evaluate chemical
principle application, molecular structure analysis, and logical consistency
through computational verification. Extensive experiments across 8 datasets
demonstrate significant performance improvements, with MPPReasoner
outperforming the best baselines by 7.91\% and 4.53\% on in-distribution and
out-of-distribution tasks respectively. MPPReasoner exhibits exceptional
cross-task generalization and generates chemically sound reasoning paths that
provide valuable insights into molecular property analysis, substantially
enhancing both interpretability and practical utility for chemists. Code is
available at https://anonymous.4open.science/r/MPPReasoner-12687.

</details>


### [747] [Enhancing the Cross-Size Generalization for Solving Vehicle Routing Problems via Continual Learning](https://arxiv.org/abs/2510.10262)
*Jingwen Li,Zhiguang Cao,Yaoxin Wu,Tang Liu*

Main category: cs.LG

TL;DR: 现有的深度学习模型在处理车辆路径问题时，通常只在单一尺寸的实例上进行训练和评估，这限制了它们在不同问题尺寸上的泛化能力。本文提出了一种持续学习框架，通过顺序训练模型以适应不断增大的问题实例。该框架结合了跨任务和任务内正则化方案，以及经验回放机制，以保留先前知识、巩固模型并减轻灾难性遗忘。实验结果表明，该方法在各种问题尺寸上均优于现有最先进模型，并且各设计元素的协同作用也得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为了提高车辆路径问题的深度学习模型的泛化能力和实际应用性，解决现有模型在单一尺寸实例训练上面临的局限性。

Method: 提出了一种基于持续学习的框架，通过顺序训练模型来处理不同尺寸的实例。具体而言，设计了跨任务正则化方案以保留先前知识，任务内正则化方案以巩固模型，并利用经验回放机制来减轻灾难性遗忘。

Result: 在各种问题尺寸（包括训练中见过和未见过的）上，所提出的方法均取得了优于最先进的深度模型（包括专门用于增强泛化能力的方法）的性能。消融研究表明了关键设计元素的协同效应。

Conclusion: 所提出的持续学习框架能够有效解决车辆路径问题中深度模型在不同问题尺寸上的泛化能力不足的问题，并在各种规模的问题上实现了优越的性能。

Abstract: Exploring machine learning techniques for addressing vehicle routing problems
has attracted considerable research attention. To achieve decent and efficient
solutions, existing deep models for vehicle routing problems are typically
trained and evaluated using instances of a single size. This substantially
limits their ability to generalize across different problem sizes and thus
hampers their practical applicability. To address the issue, we propose a
continual learning based framework that sequentially trains a deep model with
instances of ascending problem sizes. Specifically, on the one hand, we design
an inter-task regularization scheme to retain the knowledge acquired from
smaller problem sizes in the model training on a larger size. On the other
hand, we introduce an intra-task regularization scheme to consolidate the model
by imitating the latest desirable behaviors during training on each size.
Additionally, we exploit the experience replay to revisit instances of formerly
trained sizes for mitigating the catastrophic forgetting. Experimental results
show that our approach achieves predominantly superior performance across
various problem sizes (either seen or unseen in the training), as compared to
state-of-the-art deep models including the ones specialized for
generalizability enhancement. Meanwhile, the ablation studies on the key
designs manifest their synergistic effect in the proposed framework.

</details>


### [748] [Lost in the Middle: An Emergent Property from Information Retrieval Demands in LLMs](https://arxiv.org/abs/2510.10276)
*Nikolaus Salvatore,Hao Wang,Qiong Zhang*

Main category: cs.LG

TL;DR: LLM在长文本中间信息检索时表现不佳，并非信息丢失，而是对预训练中不同信息检索需求的适应。


<details>
  <summary>Details</summary>
Motivation: LLM在长文本中间信息检索时表现不佳，即“lost-in-the-middle”现象，这与人类记忆中的首因效应和近因效应相似。

Method: 通过在两种模拟长短期记忆需求的人类记忆范式上从头开始训练LLM（GPT-2和Llama变体）来重现U型性能曲线。

Result: U型性能曲线的出现与短期记忆需求直接相关，而首因效应则受到长期记忆需求、模型自回归特性和注意力汇聚点的影响。

Conclusion: 信息检索需求、模型架构和训练过程中的结构注意力动态共同导致了LLM中的位置偏差。

Abstract: The performance of Large Language Models (LLMs) often degrades when crucial
information is in the middle of a long context, a "lost-in-the-middle"
phenomenon that mirrors the primacy and recency effects in human memory. We
propose that this behavior is not simply a flaw indicative of information loss
but an adaptation to different information retrieval demands during
pre-training: some tasks require uniform recall across the entire input (a
long-term memory demand), while others prioritize the most recent information
(a short-term memory demand). Consistent with this view, we show that this
U-shaped performance curve emerges when LLMs (GPT-2 and Llama variants) are
trained from scratch on two simple human memory paradigms simulating long-term
and short-term memory demands. Our analysis reveals that while the recency
effect directly aligns with short-term memory demand in the training data, the
primacy effect is induced by the uniform long-term memory demand and is
additionally influenced by the model's autoregressive properties and the
formation of attention sinks. Our main findings from simple human memory
paradigms also generalize to a sequence completion task, which more closely
resembles the next-token prediction process in LLM pre-training. Together, our
findings reveal how information retrieval demands, model architecture, and
structural attention dynamics during model training can jointly produce
positional bias observed in LLMs.

</details>


### [749] [Simulating Viva Voce Examinations to Evaluate Clinical Reasoning in Large Language Models](https://arxiv.org/abs/2510.10278)
*Christopher Chiu,Silviu Pitis,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: VivaBench是一个评估大型语言模型（LLM）进行顺序临床推理的多轮基准，它通过模拟医学培训中的互动场景来评估LLM在信息不完整时进行诊断的能力，并指出了当前LLM在推理和决策方面存在的局限性。


<details>
  <summary>Details</summary>
Motivation: 目前的医学基准主要评估LLM的知识回忆能力，而忽略了临床推理中信息不完整和需要多轮交互的现实情况。因此，需要一个能够评估LLM在顺序临床推理方面能力的新基准。

Method: 创建了一个包含1762个病例的VivaBench数据集，这些病例以互动场景的形式呈现，模拟了医学培训中的口试环节，要求LLM主动获取信息、选择检查并逐步推理出诊断。

Result: 在VivaBench基准测试中，当前LLM在处理信息不完整和不确定性下的迭代诊断推理能力表现不佳，其性能显著下降。分析发现，LLM存在固守初始假设、不当选择检查、过早确诊以及未能筛查危重病症等多种类似临床实践中常见认知错误的失败模式。

Conclusion: VivaBench提供了一个评估会话式医学人工智能系统用于真实世界临床决策支持的标准基准。此外，该研究还揭示了当前LLM在不确定性下的推理和决策能力存在根本性局限，并为研究智能体AI在复杂决策环境中的序列推理轨迹提供了新的视角。

Abstract: Clinical reasoning in medicine is a hypothesis-driven process where
physicians refine diagnoses from limited information through targeted history,
physical examination, and diagnostic investigations. In contrast, current
medical benchmarks for large language models (LLMs) primarily assess knowledge
recall through single-turn questions, where complete clinical information is
provided upfront. To address this gap, we introduce VivaBench, a multi-turn
benchmark that evaluates sequential clinical reasoning in LLM agents. Our
dataset consists of 1762 physician-curated clinical vignettes structured as
interactive scenarios that simulate a (oral) examination in medical training,
requiring agents to actively probe for relevant findings, select appropriate
investigations, and synthesize information across multiple steps to reach a
diagnosis. While current LLMs demonstrate competence in diagnosing conditions
from well-described clinical presentations, their performance degrades
significantly when required to navigate iterative diagnostic reasoning under
uncertainty in our evaluation. Our analysis identified several failure modes
that mirror common cognitive errors in clinical practice, including: (1)
fixation on initial hypotheses, (2) inappropriate investigation ordering, (3)
premature diagnostic closure, and (4) failing to screen for critical
conditions. These patterns reveal fundamental limitations in how current LLMs
reason and make decisions under uncertainty. Through VivaBench, we provide a
standardized benchmark for evaluating conversational medical AI systems for
real-world clinical decision support. Beyond medical applications, we
contribute to the larger corpus of research on agentic AI by demonstrating how
sequential reasoning trajectories can diverge in complex decision-making
environments.

</details>


### [750] [Sample-Efficient Online Learning in LM Agents via Hindsight Trajectory Rewriting](https://arxiv.org/abs/2510.10304)
*Michael Y. Hu,Benjamin Van Durme,Jacob Andreas,Harsh Jhamtani*

Main category: cs.LG

TL;DR: ECHO是一种基于语言模型（LM）的代理框架，通过回放经验和反事实轨迹生成来提高样本效率，在XMiniGrid和PeopleJoinQA上表现优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型代理在与新环境交互时学习效率低下，限制了其在与人类交互或重置物理系统等成本高昂的环境中的应用。虽然一些现有架构包含经验存储和反思机制，但它们未能充分利用语言模型生成或推理完整反事实轨迹的能力。

Method: ECHO（Experience Consolidation via Hindsight Optimization）是一种提示框架，它将强化学习中的反事实经验回放应用于语言模型代理。ECHO通过生成已实现的替代目标的优化轨迹，有效地从不成功的交互中创建合成正例。该方法包括一个利用语言模型本身识别相关子目标并生成优化轨迹的‘反事实规则’，以及一个维护压缩轨迹表示的‘更新规则’。

Result: 在XMiniGrid和PeopleJoinQA两个基准测试中，ECHO的性能比标准的语言代理基线模型提高了80%。在XMiniGrid上，ECHO的性能也优于Reflexion和AWM等复杂的代理架构，展示了通过更有效地利用过去的经验来更快地适应新环境。

Conclusion: ECHO通过利用语言模型的推理能力来生成和优化反事实轨迹，显著提高了语言模型代理在与新环境交互时的样本效率和适应性，尤其是在交互成本高昂的情况下。

Abstract: Language model (LM) agents deployed in novel environments often exhibit poor
sample efficiency when learning from sequential interactions. This
significantly hinders the usefulness of such agents in environments where
interaction is costly (for example, when they interact with humans or reset
physical systems). While a number of existing LM agent architectures
incorporate various mechanisms for experience storage and reflection, they make
limited use of LMs' abilities to directly generate or reason about full
counterfactual trajectories. We introduce ECHO (Experience Consolidation via
Hindsight Optimization), a prompting framework that adapts hindsight experience
replay from reinforcement learning for language model agents. ECHO generates
optimized trajectories for alternative goals that could have been achieved
during failed attempts, effectively creating synthetic positive examples from
unsuccessful interactions. Our approach consists of two components: a hindsight
rule that uses the language model itself to identify relevant subgoals and
generate optimized trajectories, and an update rule that maintains compressed
trajectory representations in memory. We evaluate ECHO on stateful versions of
XMiniGrid, a text-based navigation and planning benchmark, and PeopleJoinQA, a
collaborative information-gathering enterprise simulation. Across both domains,
ECHO outperforms vanilla language agent baselines by up to 80%; in XMiniGrid,
it also outperforms a number of sophisticated agent architectures including
Reflexion and AWM, demonstrating faster adaptation to novel environments
through more effective utilization of past experiences.

</details>


### [751] [Multi-View Graph Learning with Graph-Tuple](https://arxiv.org/abs/2510.10341)
*Shiyu Chen,Ningyuan,Huang,Soledad Villar*

Main category: cs.LG

TL;DR: GNN在稠密图上效率低下，现有方法会丢失信息。本文提出多视图图-元组框架，将图划分为子图，并通过异构消息传递学习多视图表示，实验证明该方法优于传统单图模型。


<details>
  <summary>Details</summary>
Motivation: 现有的GNN在稠密图上效率不高，常用的图稀疏化方法会丢弃多尺度信息。

Method: 提出多视图图-元组框架，将图划分为子图，并使用受非对易算子理论启发的异构消息传递学习多视图表示。

Result: 在分子性质预测和宇宙学参数推断任务上，多视图图-元组模型优于单图基线模型。

Conclusion: 多视图图-元组框架在处理稠密图时，相比于传统单图模型，具有更强的表达能力和更优的性能，适用于分子性质预测和宇宙学参数推断等领域。

Abstract: Graph Neural Networks (GNNs) typically scale with the number of graph edges,
making them well suited for sparse graphs but less efficient on dense graphs,
such as point clouds or molecular interactions. A common remedy is to sparsify
the graph via similarity thresholding or distance pruning, but this forces an
arbitrary choice of a single interaction scale and discards crucial information
from other scales. To overcome this limitation, we introduce a multi-view
graph-tuple framework. Instead of a single graph, our graph-tuple framework
partitions the graph into disjoint subgraphs, capturing primary local
interactions and weaker, long-range connections. We then learn multi-view
representations from the graph-tuple via a heterogeneous message-passing
architecture inspired by the theory of non-commuting operators, which we
formally prove is strictly more expressive and guarantees a lower oracle risk
compared to single-graph message-passing models. We instantiate our framework
on two scientific domains: molecular property prediction from feature-scarce
Coulomb matrices and cosmological parameter inference from geometric point
clouds. On both applications, our multi-view graph-tuple models demonstrate
better performance than single-graph baselines, highlighting the power and
versatility of our multi-view approach.

</details>


### [752] [Transformer Model Detects Antidepressant Use From a Single Night of Sleep, Unlocking an Adherence Biomarker](https://arxiv.org/abs/2510.10364)
*Ali Mirzazadeh,Simon Cadavid,Kaiwen Zha,Chao Li,Sultan Alzahrani,Manar Alawajy,Joshua Korzenik,Kreshnik Hoti,Charles Reynolds,David Mischoulon,John Winkelman,Maurizio Fava,Dina Katabi*

Main category: cs.LG

TL;DR: 研究提出了一种基于睡眠数据的无创生物标志物，利用Transformer模型分析消费级可穿戴设备或无线传感器的睡眠数据，以推断抗抑郁药的摄入情况，从而实现居家、无缝、每日的依从性评估。


<details>
  <summary>Details</summary>
Motivation: 抗抑郁药的依从性差是一个普遍存在的问题，它会导致病情复发、住院、自杀风险增加，并产生数十亿美元的额外成本。临床医生需要能够及时检测依从性问题的工具，但现有方法要么具有侵入性（血清分析、神经影像学），要么基于代理指标且不准确（药丸计数、药房续配）。

Method: 提出了一种非侵入性生物标志物，该标志物通过分析来自消费级可穿戴设备或非接触式无线传感器的睡眠数据，并利用Transformer模型来推断抗抑郁药的摄入情况。

Result: 在包含62,000晚睡眠数据（来自>20,000名参与者，其中1,800名使用抗抑郁药）的六个数据集中，该生物标志物实现了0.84的AUROC，能够跨药物类别泛化，并随着剂量的增加而扩展，同时对合并使用的精神科药物保持稳健。纵向监测能够捕捉到现实世界中的起始用药、减量和漏服情况。

Conclusion: 这种方法提供了一种客观、可扩展的依从性监测手段，有潜力改善抑郁症的治疗和预后。

Abstract: Antidepressant nonadherence is pervasive, driving relapse, hospitalization,
suicide risk, and billions in avoidable costs. Clinicians need tools that
detect adherence lapses promptly, yet current methods are either invasive
(serum assays, neuroimaging) or proxy-based and inaccurate (pill counts,
pharmacy refills). We present the first noninvasive biomarker that detects
antidepressant intake from a single night of sleep. A transformer-based model
analyzes sleep data from a consumer wearable or contactless wireless sensor to
infer antidepressant intake, enabling remote, effortless, daily adherence
assessment at home. Across six datasets comprising 62,000 nights from >20,000
participants (1,800 antidepressant users), the biomarker achieved AUROC = 0.84,
generalized across drug classes, scaled with dose, and remained robust to
concomitant psychotropics. Longitudinal monitoring captured real-world
initiation, tapering, and lapses. This approach offers objective, scalable
adherence surveillance with potential to improve depression care and outcomes.

</details>


### [753] [Exploration-free Algorithms for Multi-group Mean Estimation](https://arxiv.org/abs/2510.10374)
*Ziyi Wei,Huaiyang Zhong,Xiaocheng Li*

Main category: cs.LG

TL;DR: 传统的解决多重均值估计问题的方法需要为每个组分配有限的采样预算，以获得均匀准确的估计。与旨在通过识别和利用最佳手臂来最小化遗憾的经典多臂老虎机不同，这种情况下最优分配需要对每个组进行大约Θ(T)次采样。这种根本区别使得无探索算法自然而然且非常有效。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决多重均值估计问题，该问题寻求在多个组之间分配有限的采样预算，以获得它们均值的均匀准确的估计。与旨在通过识别和利用最佳臂来最小化遗憾的经典多臂老虎机不同，在这种情况下，最优分配需要对每个组进行Θ(T)次采样。

Method: 该研究提出了三种贡献：1. 利用Hanson-Wright不等式加强了现有的关于亚高斯方差集中的结果，并确定了一类具有更严格保证的严格亚高斯分布。2. 设计了无探索的非自适应和自适应算法，并建立了比现有结果更严格的遗憾界限。3. 将该框架扩展到上下文老虎机设置，这是一个未被充分探索的方向，并提出利用具有可证明保证的侧面信息的算法。

Result: 研究加强了亚高斯方差集中的结果，并确定了一类具有更严格保证的严格亚高斯分布。设计了无探索的非自适应和自适应算法，并建立了比现有结果更严格的遗憾界限。将框架扩展到上下文老虎机设置，并提出利用具有可证明保证的侧面信息的算法。

Conclusion: 这项工作将无探索分配定位为一种原则性和有效的方法，用于多重均值估计，并可能在实验设计、个性化和其他需要准确多重推断的领域得到应用。

Abstract: We address the problem of multi-group mean estimation, which seeks to
allocate a finite sampling budget across multiple groups to obtain uniformly
accurate estimates of their means. Unlike classical multi-armed bandits, whose
objective is to minimize regret by identifying and exploiting the best arm, the
optimal allocation in this setting requires sampling every group on the order
of $\Theta(T)$ times. This fundamental distinction makes exploration-free
algorithms both natural and effective. Our work makes three contributions.
First, we strengthen the existing results on subgaussian variance concentration
using the Hanson-Wright inequality and identify a class of strictly subgaussian
distributions that yield sharper guarantees. Second, we design exploration-free
non-adaptive and adaptive algorithms, and we establish tighter regret bounds
than the existing results. Third, we extend the framework to contextual bandit
settings, an underexplored direction, and propose algorithms that leverage side
information with provable guarantees. Overall, these results position
exploration-free allocation as a principled and efficient approach to
multi-group mean estimation, with potential applications in experimental
design, personalization, and other domains requiring accurate multi-group
inference.

</details>


### [754] [Applying non-negative matrix factorization with covariates to label matrix for classification](https://arxiv.org/abs/2510.10375)
*Kenichi Satoh*

Main category: cs.LG

TL;DR: NMF-LAB是一种新的分类方法，它将分类视为非负矩阵三分解（tri-NMF）的逆问题，可以直接从协变量得到类成员概率，并能整合核方法进行预测，支持半监督学习，在准确性、鲁棒性和可扩展性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有监督或半监督的NMF方法通常需要外部分类器，并且在利用类别标签方面存在局限性。

Method: NMF-LAB将分类视为非负矩阵三分解（tri-NMF）的逆问题，直接将标签矩阵Y作为观测值，协变量A作为解释变量进行分解，从而得到从协变量到标签的直接概率映射。

Result: 实验表明，NMF-LAB在准确性、鲁棒性（对噪声或不完整标签）和可扩展性（高维问题）方面均达到或超过现有方法，同时保持了可解释性。

Conclusion: NMF-LAB通过在tri-NMF框架下统一回归和分类，为现代分类任务提供了一种新颖、概率化且可扩展的方法。

Abstract: Non-negative matrix factorization (NMF) is widely used for dimensionality
reduction and interpretable analysis, but standard formulations are
unsupervised and cannot directly exploit class labels. Existing supervised or
semi-supervised extensions usually incorporate labels only via penalties or
graph constraints, still requiring an external classifier. We propose
\textit{NMF-LAB} (Non-negative Matrix Factorization for Label Matrix), which
redefines classification as the inverse problem of non-negative matrix
tri-factorization (tri-NMF). Unlike joint NMF methods, which reconstruct both
features and labels, NMF-LAB directly factorizes the label matrix $Y$ as the
observation, while covariates $A$ are treated as given explanatory variables.
This yields a direct probabilistic mapping from covariates to labels,
distinguishing our method from label-matrix factorization approaches that
mainly model label correlations or impute missing labels. Our inversion offers
two key advantages: (i) class-membership probabilities are obtained directly
from the factorization without a separate classifier, and (ii) covariates,
including kernel-based similarities, can be seamlessly integrated to generalize
predictions to unseen samples. In addition, unlabeled data can be encoded as
uniform distributions, supporting semi-supervised learning. Experiments on
diverse datasets, from small-scale benchmarks to the large-scale MNIST dataset,
demonstrate that NMF-LAB achieves competitive predictive accuracy, robustness
to noisy or incomplete labels, and scalability to high-dimensional problems,
while preserving interpretability. By unifying regression and classification
within the tri-NMF framework, NMF-LAB provides a novel, probabilistic, and
scalable approach to modern classification tasks.

</details>


### [755] [Controllable Graph Generation with Diffusion Models via Inference-Time Tree Search Guidance](https://arxiv.org/abs/2510.10402)
*Jiachi Zhao,Zehong Wang,Yamei Liao,Chuxu Zhang,Yanfang Ye*

Main category: cs.LG

TL;DR: TreeDiff是一个基于蒙特卡洛树搜索（MCTS）的引导式双空间扩散框架，用于可控的图生成，通过宏观步骤扩展、双空间去噪和双空间验证器克服了现有方法的局限性，并在分子生成等基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无条件扩散模型在可控性和生成质量稳定性方面存在不足，而推理时引导方法虽然有所改进，但仍受限于局部性、启发式和可控性。 TreeDiff旨在克服这些限制，实现可控的图生成。

Method: TreeDiff采用蒙特卡洛树搜索（MCTS）引导的双空间扩散框架。其关键设计包括：1）宏观步骤扩展策略，将多个去噪更新合并为一步，减少树的深度；2）双空间去噪机制，结合了潜在空间去噪和图空间中的离散校正；3）双空间验证器，用于预测部分去噪图的长期奖励，实现早期价值估计。

Result: 在2D和3D分子生成基准测试的无条件和有条件设置下，TreeDiff取得了最先进的性能。该方法在推理时表现出良好的可扩展性，并且随着计算资源的增加，性能可以持续提升，而现有方法则在资源有限时很快达到平台期。

Conclusion: TreeDiff是一种有效的、可插入的推理时图生成方法，通过结合MCTS和双空间扩散，实现了可控性、可扩展性和优于现有方法的性能。

Abstract: Graph generation is a fundamental problem in graph learning with broad
applications across Web-scale systems, knowledge graphs, and scientific domains
such as drug and material discovery. Recent approaches leverage diffusion
models for step-by-step generation, yet unconditional diffusion offers little
control over desired properties, often leading to unstable quality and
difficulty in incorporating new objectives. Inference-time guidance methods
mitigate these issues by adjusting the sampling process without retraining, but
they remain inherently local, heuristic, and limited in controllability. To
overcome these limitations, we propose TreeDiff, a Monte Carlo Tree Search
(MCTS) guided dual-space diffusion framework for controllable graph generation.
TreeDiff is a plug-and-play inference-time method that expands the search space
while keeping computation tractable. Specifically, TreeDiff introduces three
key designs to make it practical and scalable: (1) a macro-step expansion
strategy that groups multiple denoising updates into a single transition,
reducing tree depth and enabling long-horizon exploration; (2) a dual-space
denoising mechanism that couples efficient latent-space denoising with
lightweight discrete correction in graph space, ensuring both scalability and
structural fidelity; and (3) a dual-space verifier that predicts long-term
rewards from partially denoised graphs, enabling early value estimation and
removing the need for full rollouts. Extensive experiments on 2D and 3D
molecular generation benchmarks, under both unconditional and conditional
settings, demonstrate that TreeDiff achieves state-of-the-art performance.
Notably, TreeDiff exhibits favorable inference-time scaling: it continues to
improve with additional computation, while existing inference-time methods
plateau early under limited resources.

</details>


### [756] [Softmax $\geq$ Linear: Transformers may learn to classify in-context by kernel gradient descent](https://arxiv.org/abs/2510.10425)
*Sara Dragutinović,Andrew M. Saxe,Aaditya K. Singh*

Main category: cs.LG

TL;DR: Transformer 在上下文学习中通过梯度下降进行学习，即使在分类任务和 softmax 激活的非线性情况下也是如此。


<details>
  <summary>Details</summary>
Motivation: 理解 Transformer 在上下文中学习新概念的算法，特别是从线性回归任务扩展到更现实的离散分类任务。

Method: 分析 Transformer 在分类任务和 softmax 激活的非线性设置下的学习算法，重点研究其梯度下降行为和上下文适应性学习率。

Result: Transformer 仍然通过梯度下降进行上下文学习，尽管是在核特征空间中的泛函上，并且在 softmax Transformer 的情况下具有上下文自适应学习率。

Conclusion: Transformer 在分类任务中也能通过梯度下降进行上下文学习，softmax 注意力机制显示出更强的适应性，这增强了对更现实场景下上下文学习算法的理论理解。

Abstract: The remarkable ability of transformers to learn new concepts solely by
reading examples within the input prompt, termed in-context learning (ICL), is
a crucial aspect of intelligent behavior. Here, we focus on understanding the
learning algorithm transformers use to learn from context. Existing theoretical
work, often based on simplifying assumptions, has primarily focused on linear
self-attention and continuous regression tasks, finding transformers can learn
in-context by gradient descent. Given that transformers are typically trained
on discrete and complex tasks, we bridge the gap from this existing work to the
setting of classification, with non-linear (importantly, softmax) activation.
We find that transformers still learn to do gradient descent in-context, though
on functionals in the kernel feature space and with a context-adaptive learning
rate in the case of softmax transformer. These theoretical findings suggest a
greater adaptability to context for softmax attention, which we empirically
verify and study through ablations. Overall, we hope this enhances theoretical
understanding of in-context learning algorithms in more realistic settings,
pushes forward our intuitions and enables further theory bridging to larger
models.

</details>


### [757] [Hierarchical LoRA MoE for Efficient CTR Model Scaling](https://arxiv.org/abs/2510.10432)
*Zhichen Zeng,Mengyue Hang,Xiaolong Liu,Xiaoyi Liu,Xiao Lin,Ruizhong Qiu,Tianxin Wei,Zhining Liu,Siyang Yuan,Chaofei Yang,Yiqun Liu,Hang Yin,Jiyan Yang,Hanghang Tong*

Main category: cs.LG

TL;DR: HiLoMoE是一个分层LoRA MoE框架，通过参数高效地实现纵向和横向扩展，以提高CTR预测的投资回报率。


<details>
  <summary>Details</summary>
Motivation: 垂直扩展（堆叠层）会增加计算成本，而水平扩展（MoE）可能无法捕捉推荐任务中的分层结构。HiLoMoE旨在结合两者的优点，实现高效扩展。

Method: HiLoMoE采用轻量级秩1专家进行参数高效的横向扩展，并通过分层路由堆叠多个MoE层，以实现组合多样化的专家组合。与传统的堆叠不同，HiLoMoE基于先验层分数进行路由，允许所有层并行执行。采用三阶段训练框架来保证优化稳定性和专家多样性。

Result: 与非MoE基线相比，HiLoMoE在四个公共数据集上实现了更好的性能-效率权衡，AUC平均提高了0.20%，FLOPs减少了18.5%。

Conclusion: HiLoMoE通过结合分层和并行处理的优点，在CTR预测中实现了比传统方法更好的性能和效率。

Abstract: Deep models have driven significant advances in click-through rate (CTR)
prediction. While vertical scaling via layer stacking improves model
expressiveness, the layer-by-layer sequential computation poses challenges to
efficient scaling. Conversely, horizontal scaling through Mixture of Experts
(MoE) achieves efficient scaling by activating a small subset of experts in
parallel, but flat MoE layers may struggle to capture the hierarchical
structure inherent in recommendation tasks. To push the Return-On-Investment
(ROI) boundary, we explore the complementary strengths of both directions and
propose HiLoMoE, a hierarchical LoRA MoE framework that enables holistic
scaling in a parameter-efficient manner. Specifically, HiLoMoE employs
lightweight rank-1 experts for parameter-efficient horizontal scaling, and
stacks multiple MoE layers with hierarchical routing to enable combinatorially
diverse expert compositions. Unlike conventional stacking, HiLoMoE routes based
on prior layer scores rather than outputs, allowing all layers to execute in
parallel. A principled three-stage training framework ensures stable
optimization and expert diversity. Experiments on four public datasets show
that HiLoMoE achieving better performance-efficiency tradeoff, achieving an
average AUC improvement of 0.20\% in AUC and 18.5\% reduction in FLOPs compared
to the non-MoE baseline.

</details>


### [758] [Multi-Task Learning with Feature-Similarity Laplacian Graphs for Predicting Alzheimer's Disease Progression](https://arxiv.org/abs/2510.10433)
*Zixiang Xu,Menghui Zhou,Jun Qi,Xuanhan Fan,Yun Yang,Po Yang*

Main category: cs.LG

TL;DR: 提出了一种新的多任务学习框架MTL-FSL，通过引入特征相似性拉普拉斯（FSL）惩罚来解决现有框架无法处理特征相关性时变性的问题，并在ADNI数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多任务学习（MTL）框架在处理纵向AD数据时，未能考虑特征相关性的时变性。

Method: 提出了一种新的MTL框架MTL-FSL，引入了特征相似性拉普拉斯（FSL）惩罚来显式地对特征之间的时变关系进行建模。通过同时考虑任务之间的时间平滑性和特征之间的动态相关性，并采用交替方向乘子法（ADMM）算法来解决优化问题。

Result: 在ADNI数据集上的实验表明，MTL-FSL框架的性能优于各种基线方法，达到了最先进的水平。

Conclusion: MTL-FSL框架通过对特征相关性的时变性进行建模，提高了预测准确性和生物学可解释性。

Abstract: Alzheimer's Disease (AD) is the most prevalent neurodegenerative disorder in
aging populations, posing a significant and escalating burden on global
healthcare systems. While Multi-Tusk Learning (MTL) has emerged as a powerful
computational paradigm for modeling longitudinal AD data, existing frameworks
do not account for the time-varying nature of feature correlations. To address
this limitation, we propose a novel MTL framework, named Feature Similarity
Laplacian graph Multi-Task Learning (MTL-FSL). Our framework introduces a novel
Feature Similarity Laplacian (FSL) penalty that explicitly models the
time-varying relationships between features. By simultaneously considering
temporal smoothness among tasks and the dynamic correlations among features,
our model enhances both predictive accuracy and biological interpretability. To
solve the non-smooth optimization problem arising from our proposed penalty
terms, we adopt the Alternating Direction Method of Multipliers (ADMM)
algorithm. Experiments conducted on the Alzheimer's Disease Neuroimaging
Initiative (ADNI) dataset demonstrate that our proposed MTL-FSL framework
achieves state-of-the-art performance, outperforming various baseline methods.
The implementation source can be found at https://github.com/huatxxx/MTL-FSL.

</details>


### [759] [Reverse Supervision at Scale: Exponential Search Meets the Economics of Annotation](https://arxiv.org/abs/2510.10446)
*Masoud Makrehchi*

Main category: cs.LG

TL;DR: 在实际应用中，机器学习流水线仍然需要人类的初始贡献：指定目标、定义类并提供一组代表性的注释，以注入归纳偏差并使模型与任务语义对齐。


<details>
  <summary>Details</summary>
Motivation: 分析了最小化小标记集 A 上的错误来标记大标记集 B 的反向监督策略。

Method: 搜索空间为 2^n，即使在具有很大常数因子加速（例如，量子或大规模并行硬件）的情况下，复杂性仍然是指数级的。

Result: 任意快速的计算（但不是指数级的）并不能消除对信息标签或先验知识的需求。

Conclusion: 最初的人类（或人类级别）的输入对于将系统与预期任务联系起来仍然是必要的。

Abstract: We analyze a reversed-supervision strategy that searches over labelings of a
large unlabeled set \(B\) to minimize error on a small labeled set \(A\). The
search space is \(2^n\), and the resulting complexity remains exponential even
under large constant-factor speedups (e.g., quantum or massively parallel
hardware). Consequently, arbitrarily fast -- but not exponentially faster --
computation does not obviate the need for informative labels or priors. In
practice, the machine learning pipeline still requires an initial human
contribution: specifying the objective, defining classes, and providing a seed
set of representative annotations that inject inductive bias and align models
with task semantics. Synthetic labels from generative AI can partially
substitute provided their quality is human-grade and anchored by a
human-specified objective, seed supervision, and validation. In this view,
generative models function as \emph{label amplifiers}, leveraging small
human-curated cores via active, semi-supervised, and self-training loops, while
humans retain oversight for calibration, drift detection, and failure auditing.
Thus, extreme computational speed reduces wall-clock time but not the
fundamental supervision needs of learning; initial human (or human-grade) input
remains necessary to ground the system in the intended task.

</details>


### [760] [Data-driven simulator of multi-animal behavior with unknown dynamics via offline and online reinforcement learning](https://arxiv.org/abs/2510.10451)
*Keisuke Fujii,Kazushi Tsutsui,Yu Teshima,Makoto Itoh,Naoya Takeishi,Nozomi Nishiumi,Ryoya Tanaka,Shunsuke Shigaki,Yoshinobu Kawahara*

Main category: cs.LG

TL;DR: 该研究提出了一种基于深度强化学习和反事实模拟的数据驱动方法，用于模拟多动物行为，解决了真实世界过渡模型与模拟环境之间的差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有的动物行为模拟器在重现真实运动和支持奖励驱动的优化方面存在不足，尤其是在运动动力学模型未知的情况下，这阻碍了对复杂多动物行为的研究。

Method: 研究提出了一种数据驱动的模拟器，结合了深度强化学习和反事实模拟。该方法将运动变量的估计视为强化学习框架中的动作，以解决高自由度运动带来的问题。同时，采用基于距离的伪奖励来对齐和比较虚拟与物理空间的状态。

Result: 在人工代理、苍蝇、蝣以及家蚕的实验中，该方法在行为重现性和奖励获取方面均优于标准的模仿学习和强化学习方法。此外，它还能够预测新实验环境下的反事实行为，并支持多主体建模以生成灵活的“假设”轨迹。

Conclusion: 该方法在模拟和阐明复杂多动物行为方面具有巨大潜力，能够更准确地重现特定物种的行为，并在奖励获取和行为预测方面取得显著进步。

Abstract: Simulators of animal movements play a valuable role in studying behavior.
Advances in imitation learning for robotics have expanded possibilities for
reproducing human and animal movements. A key challenge for realistic
multi-animal simulation in biology is bridging the gap between unknown
real-world transition models and their simulated counterparts. Because
locomotion dynamics are seldom known, relying solely on mathematical models is
insufficient; constructing a simulator that both reproduces real trajectories
and supports reward-driven optimization remains an open problem. We introduce a
data-driven simulator for multi-animal behavior based on deep reinforcement
learning and counterfactual simulation. We address the ill-posed nature of the
problem caused by high degrees of freedom in locomotion by estimating movement
variables of an incomplete transition model as actions within an RL framework.
We also employ a distance-based pseudo-reward to align and compare states
between cyber and physical spaces. Validated on artificial agents, flies,
newts, and silkmoth, our approach achieves higher reproducibility of
species-specific behaviors and improved reward acquisition compared with
standard imitation and RL methods. Moreover, it enables counterfactual behavior
prediction in novel experimental settings and supports multi-individual
modeling for flexible what-if trajectory generation, suggesting its potential
to simulate and elucidate complex multi-animal behaviors.

</details>


### [761] [LightSAE: Parameter-Efficient and Heterogeneity-Aware Embedding for IoT Multivariate Time Series Forecasting](https://arxiv.org/abs/2510.10465)
*Yi Ren,Xinjie Yu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为共享辅助嵌入（SAE）的框架，用于解决多变量时间序列预测（MTSF）中的表示瓶颈问题，并通过LightSAE模块在物联网（IoT）数据集上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的多变量时间序列预测方法在处理大规模物联网数据时，由于共享嵌入层统一处理所有通道，导致了表示瓶颈，忽略了通道特有的信息，因此需要一种新的方法来解决这个问题。

Method: 提出共享辅助嵌入（SAE）框架，将嵌入分解为共享基础部分和通道特异性辅助部分。在此基础上，设计了LightSAE模块，利用低秩分解和共享门控组件池来捕捉辅助嵌入的低秩和聚类特性，以实现参数高效的嵌入。

Result: 在9个物联网相关数据集和4个骨干架构上进行的大量实验表明，LightSAE的平均均方误差（MSE）最多可提高22.8%，而参数量仅增加4.0%。

Conclusion: LightSAE通过捕捉共享嵌入的低秩和聚类特性，有效解决了多变量时间序列预测中的表示瓶颈问题，并在物联网数据集上取得了优于现有方法的性能。

Abstract: Modern Internet of Things (IoT) systems generate massive, heterogeneous
multivariate time series data. Accurate Multivariate Time Series Forecasting
(MTSF) of such data is critical for numerous applications. However, existing
methods almost universally employ a shared embedding layer that processes all
channels identically, creating a representational bottleneck that obscures
valuable channel-specific information. To address this challenge, we introduce
a Shared-Auxiliary Embedding (SAE) framework that decomposes the embedding into
a shared base component capturing common patterns and channel-specific
auxiliary components modeling unique deviations. Within this decomposition, we
\rev{empirically observe} that the auxiliary components tend to exhibit
low-rank and clustering characteristics, a structural pattern that is
significantly less apparent when using purely independent embeddings.
Consequently, we design LightSAE, a parameter-efficient embedding module that
operationalizes these observed characteristics through low-rank factorization
and a shared, gated component pool. Extensive experiments across 9 IoT-related
datasets and 4 backbone architectures demonstrate LightSAE's effectiveness,
achieving MSE improvements of up to 22.8\% with only 4.0\% parameter increase.

</details>


### [762] [AnyBCQ: Hardware Efficient Flexible Binary-Coded Quantization for Multi-Precision LLMs](https://arxiv.org/abs/2510.10467)
*Gunho Park,Jeongin Bae,Beomseok Kwon,Byeongwook Kim,Se Jung Kwon,Dongsoo Lee*

Main category: cs.LG

TL;DR: AnyBCQ是一种硬件友好的多精度量化方法，通过位平面操作和渐进式精度扩展，在保持高精度的同时显著提高LLM的推理效率，并支持动态精度选择。


<details>
  <summary>Details</summary>
Motivation: LLM的部署受到内存和延迟瓶颈的限制，需要量化技术来平衡精度和效率，而多精度模型允许在单个模型中根据运行时约束以多种精度进行推理。

Method: AnyBCQ通过将量化权重表示为具有相应尺度因子的二进制位平面，实现了位平面级别的计算，并设计了一种专门的内核来支持动态的每请求精度选择。

Result: AnyBCQ在低比特（例如2比特）情况下显著减小了精度下降，在高精度下也具有竞争力，并且与半精度相比实现了高达3.0倍的吞吐量提升，与最先进的多精度方法相比实现了1.2倍的提升。

Conclusion: AnyBCQ将算法灵活性与硬件效率相结合，为跨不同服务级别目标的LLM多精度部署提供了实用的基础。

Abstract: The deployment of large language models (LLMs) is increasingly constrained by
memory and latency bottlenecks, motivating the need for quantization techniques
that flexibly balance accuracy and efficiency. Recent work has introduced
multi-precision models, which enable inference at multiple precisions within a
single model depending on runtime constraints. To support such flexibility,
quantized weights are often stored as bit-planes, where hardware efficiency
improves when the compute operates directly at the bit-plane level and
activates only the precision required by each request. In this work, we present
AnyBCQ, a hardware-friendly multi-precision extension of Binary-Coded
Quantization (BCQ) that supports direct bit-plane operations. By representing
weights as binary bit-planes with corresponding scale factors, AnyBCQ enables
bit-plane-level computation and maps naturally to accelerator-friendly,
bit-parallel arithmetic. Our progressive precision expansion mechanism
incrementally refines scaling factors while reusing previously assigned binary
codes, yielding monotonic improvements in accuracy as additional bits are
enabled. We further co-design a specialized kernel that exploits the BCQ
structure to support dynamic per-request precision selection with negligible
overhead. Experiments on recent LLMs demonstrate that AnyBCQ significantly
narrows the accuracy drop in the low-bit regime (e.g. 2-bit), remains
competitive at higher precision, and achieves throughput gains of up to 3.0x
over half precision and 1.2x over state-of-the-art multi-precision methods. By
aligning algorithmic flexibility with hardware efficiency, AnyBCQ provides a
practical foundation for multi-precision LLM deployment across diverse
service-level objectives.

</details>


### [763] [Anchor-based Maximum Discrepancy for Relative Similarity Testing](https://arxiv.org/abs/2510.10477)
*Zhijian Zhou,Liuhua Peng,Xunye Tian,Feng Liu*

Main category: cs.LG

TL;DR: 本文提出了一种名为锚定最大差异（AMD）的新方法，用于在深度核空间中同时学习假设和核，以解决现有核方法在相对相似性测试中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的核方法在相对相似性测试中存在局限性，即手动指定假设会给核选择带来挑战，使得相对相似性测试在手动指定假设后变得不明确。

Method: 提出了一种锚定最大差异（AMD）方法，它将相对相似性定义为深度核空间中（U, P）和（U, Q）距离之间的最大差异。该方法包含两个阶段：第一阶段估计深度核空间上的AMD并推断潜在假设；第二阶段评估潜在假设的统计显著性，并提出了一个统一的测试框架来导出不同假设的阈值。

Result: 理论验证了该方法的有效性，并通过在基准数据集上的大量实验进行了证明。

Conclusion: AMD方法通过同时学习假设和核，解决了相对相似性测试中的挑战，并在理论和实践中都得到了验证。

Abstract: The relative similarity testing aims to determine which of the distributions,
P or Q, is closer to an anchor distribution U. Existing kernel-based approaches
often test the relative similarity with a fixed kernel in a manually specified
alternative hypothesis, e.g., Q is closer to U than P. Although kernel
selection is known to be important to kernel-based testing methods, the
manually specified hypothesis poses a significant challenge for kernel
selection in relative similarity testing: Once the hypothesis is specified
first, we can always find a kernel such that the hypothesis is rejected. This
challenge makes relative similarity testing ill-defined when we want to select
a good kernel after the hypothesis is specified. In this paper, we cope with
this challenge via learning a proper hypothesis and a kernel simultaneously,
instead of learning a kernel after manually specifying the hypothesis. We
propose an anchor-based maximum discrepancy (AMD), which defines the relative
similarity as the maximum discrepancy between the distances of (U, P) and (U,
Q) in a space of deep kernels. Based on AMD, our testing incorporates two
phases. In Phase I, we estimate the AMD over the deep kernel space and infer
the potential hypothesis. In Phase II, we assess the statistical significance
of the potential hypothesis, where we propose a unified testing framework to
derive thresholds for tests over different possible hypotheses from Phase I.
Lastly, we validate our method theoretically and demonstrate its effectiveness
via extensive experiments on benchmark datasets. Codes are publicly available
at: https://github.com/zhijianzhouml/AMD.

</details>


### [764] [Latent Retrieval Augmented Generation of Cross-Domain Protein Binders](https://arxiv.org/abs/2510.10480)
*Zishen Zhang,Xiangzhe Kong,Wenbing Huang,Yang Liu*

Main category: cs.LG

TL;DR: RADiAnce框架通过结合检索和生成来设计蛋白质结合剂，在结合亲和力和几何形状恢复方面优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 设计靶向特定位点的蛋白质结合剂是药物发现中的一个基本挑战，但现有的基于结构的生成模型在生成合理且可解释的相互作用模式方面存在局限性。

Method: 提出了一种名为RADiAnce的新框架，该框架利用已知的相互作用来指导新型结合剂的设计。它通过在共享的对比潜在空间中统一检索和生成，并使用条件潜在扩散生成器来实现跨域界面迁移。

Result:  RADiAnce在结合亲和力、几何形状和相互作用恢复等多个指标上显著优于基线模型。此外，实验证明了其跨域泛化能力，表明从不同域（如肽、抗体和蛋白质片段）检索界面可以提高其他域结合剂的生成性能。

Conclusion: RADiAnce框架成功地融合了基于检索的知识和生成人工智能，为蛋白质结合剂设计开创了新范式，为药物发现带来了新的可能性。

Abstract: Designing protein binders targeting specific sites, which requires to
generate realistic and functional interaction patterns, is a fundamental
challenge in drug discovery. Current structure-based generative models are
limited in generating nterfaces with sufficient rationality and
interpretability. In this paper, we propose Retrieval-Augmented Diffusion for
Aligned interface (RADiAnce), a new framework that leverages known interfaces
to guide the design of novel binders. By unifying retrieval and generation in a
shared contrastive latent space, our model efficiently identifies relevant
interfaces for a given binding site and seamlessly integrates them through a
conditional latent diffusion generator, enabling cross-domain interface
transfer. Extensive exeriments show that RADiAnce significantly outperforms
baseline models across multiple metrics, including binding affinity and
recovery of geometries and interactions. Additional experimental results
validate cross-domain generalization, demonstrating that retrieving interfaces
from diverse domains, such as peptides, antibodies, and protein fragments,
enhances the generation performance of binders for other domains. Our work
establishes a new paradigm for protein binder design that successfully bridges
retrieval-based knowledge and generative AI, opening new possibilities for drug
discovery.

</details>


### [765] [Gradient Enhanced Self-Training Physics-Informed Neural Network (gST-PINN) for Solving Nonlinear Partial Differential Equations](https://arxiv.org/abs/2510.10483)
*Narayan S Iyer,Bivas Bhaumik,Ram S Iyer,Satyasaran Changdar*

Main category: cs.LG

TL;DR: 通过引入基于梯度的伪点自学习算法，gST-PINN方法在解决偏微分方程方面优于传统PINN，尤其是在缺乏标签数据的情况下。


<details>
  <summary>Details</summary>
Motivation: 传统PINN在精度、训练速度、标签数据可用性和多物理场交互处理方面存在挑战。

Method: 提出一种名为gST-PINN的梯度增强自训练PINN方法，该方法引入了基于梯度的伪点自学习算法来解决偏微分方程。

Result: gST-PINN在三个不同的偏微分方程问题上进行了测试，与标准PINN方法相比，在所有情况下都表现更好，并且在缺乏标签数据时也能获得更好的泛化能力。

Conclusion: gST-PINN方法在精度和收敛性方面优于标准PINN，特别适用于标签数据稀疏或缺失的场景。

Abstract: Partial differential equations (PDEs) provide a mathematical foundation for
simulating and understanding intricate behaviors in both physical sciences and
engineering. With the growing capabilities of deep learning, data$-$driven
approaches like Physics$-$Informed Neural Networks (PINNs) have been developed,
offering a mesh$-$free, analytic type framework for efficiently solving PDEs
across a wide range of applications. However, traditional PINNs often struggle
with challenges such as limited precision, slow training dynamics, lack of
labeled data availability, and inadequate handling of multi$-$physics
interactions. To overcome these challenging issues of PINNs, we proposed a
Gradient Enhanced Self$-$Training PINN (gST$-$PINN) method that specifically
introduces a gradient based pseudo point self$-$learning algorithm for solving
PDEs. We tested the proposed method on three different types of PDE problems
from various fields, each representing distinct scenarios. The effectiveness of
the proposed method is evident, as the PINN approach for solving the Burgers$'$
equation attains a mean square error (MSE) on the order of $10^{-3}$, while the
diffusion$-$sorption equation achieves an MSE on the order of $10^{-4}$ after
12,500 iterations, with no further improvement as the iterations increase. In
contrast, the MSE for both PDEs in the gST$-$PINN model continues to decrease,
demonstrating better generalization and reaching an MSE on the order of
$10^{-5}$ after 18,500 iterations. Furthermore, the results show that the
proposed purely semi$-$supervised gST$-$PINN consistently outperforms the
standard PINN method in all cases, even when solution of the PDEs are
unavailable. It generalizes both PINN and Gradient$-$enhanced PINN (gPINN), and
can be effectively applied in scenarios prone to low accuracy and convergence
issues, particularly in the absence of labeled data.

</details>


### [766] [f-INE: A Hypothesis Testing Framework for Estimating Influence under Training Randomness](https://arxiv.org/abs/2510.10510)
*Subhodip Panda,Dhruv Tarsadiya,Shashwat Sourav,Prathosh A. P,Sai Praneeth Karimireddy*

Main category: cs.LG

TL;DR: 现有影响估计方法在训练随机性下不稳定，f-influence通过假设检验解决此问题，并提出f-INE算法，可在单次训练中高效计算，并成功用于检测Llama-3.1-8B指令调优数据中的中毒样本。


<details>
  <summary>Details</summary>
Motivation: 现有影响估计方法在训练过程中存在不稳定的问题，导致同一个样本在不同训练运行中可能显示出不同的重要性，这削弱了它们在数据整理和清洗等任务中的应用。为了解决这个问题，需要一种能够处理训练随机性的新方法。

Method: 提出f-influence框架，该框架基于假设检验，明确考虑了训练随机性，并具备可靠估计影响的理想特性。同时，设计了一种名为f-INE的高效算法，可以在单次训练运行中计算f-influence。

Result: f-INE算法被成功应用于Llama-3.1-8B模型的指令调优数据，能够有效地检测出用于引导模型观点的中毒样本。

Conclusion: f-influence框架及其f-INE算法为解决影响估计的稳定性问题提供了有效途径，并证明了其在数据清洗和模型行为归因方面的实用性。

Abstract: Influence estimation methods promise to explain and debug machine learning by
estimating the impact of individual samples on the final model. Yet, existing
methods collapse under training randomness: the same example may appear
critical in one run and irrelevant in the next. Such instability undermines
their use in data curation or cleanup since it is unclear if we indeed
deleted/kept the correct datapoints. To overcome this, we introduce
*f-influence* -- a new influence estimation framework grounded in hypothesis
testing that explicitly accounts for training randomness, and establish
desirable properties that make it suitable for reliable influence estimation.
We also design a highly efficient algorithm **f**-**IN**fluence **E**stimation
(**f-INE**) that computes f-influence **in a single training run**. Finally, we
scale up f-INE to estimate influence of instruction tuning data on Llama-3.1-8B
and show it can reliably detect poisoned samples that steer model opinions,
demonstrating its utility for data cleanup and attributing model behavior.

</details>


### [767] [A Hybrid Machine Learning Approach for Synthetic Data Generation with Post Hoc Calibration for Clinical Tabular Datasets](https://arxiv.org/abs/2510.10513)
*Md Ibrahim Shikder Mahin,Md Shamsul Arefin,Md Tanvir Hasan*

Main category: cs.LG

TL;DR: 本研究提出了一种结合五种数据增强方法（噪声注入、插值、GMM采样、CVAE采样和SMOTE）并使用强化学习动态选择权重的混合框架，用于生成高保真度的医疗合成数据。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺和严格的隐私法规（如HIPAA和GDPR），医疗研发面临数据获取障碍，阻碍了创新、AI模型开发和以患者为中心的护理。合成数据生成通过创建能模拟真实数据统计特征同时保护患者隐私的假数据集，为解决此问题提供了新途径。

Method: 本研究提出了一种新颖的混合框架，集成了噪声注入、插值、GMM采样、CVAE采样和SMOTE五种增强方法，并通过基于强化学习的动态权重选择机制进行组合。该框架采用了先进的校准技术，包括矩匹配、全直方图匹配、软直方图匹配和迭代精炼，以匹配边缘分布并保持联合特征依赖性。

Result: 在乳腺癌（UCI数据库）和Khulna医学院心脏病学数据集上进行的评估显示，该校准后的混合框架达到了0.001的低Wasserstein距离和约0.01的Kolmogorov-Smirnov统计量，显示接近零的边缘分布差异。成对趋势得分超过90%，最近邻对抗准确率接近50%，证明了其强大的隐私保护能力。使用合成数据训练的下游分类器达到了高达94%的准确率和93%以上F1分数，与使用真实数据训练的模型相当。

Conclusion: 该研究提出的可扩展、注重隐私的方法在医疗数据合成领域达到了最先进水平，并在联合分布保真度方面树立了新的标杆，支持敏感的AI应用。

Abstract: Healthcare research and development face significant obstacles due to data
scarcity and stringent privacy regulations, such as HIPAA and the GDPR,
restricting access to essential real-world medical data. These limitations
impede innovation, delay robust AI model creation, and hinder advancements in
patient-centered care. Synthetic data generation offers a transformative
solution by producing artificial datasets that emulate real data statistics
while safeguarding patient privacy. We introduce a novel hybrid framework for
high-fidelity healthcare data synthesis integrating five augmentation methods:
noise injection, interpolation, Gaussian Mixture Model (GMM) sampling,
Conditional Variational Autoencoder (CVAE) sampling, and SMOTE, combined via a
reinforcement learning-based dynamic weight selection mechanism. Its key
innovations include advanced calibration techniques -- moment matching, full
histogram matching, soft and adaptive soft histogram matching, and iterative
refinement -- that align marginal distributions and preserve joint feature
dependencies. Evaluated on the Breast Cancer Wisconsin (UCI Repository) and
Khulna Medical College cardiology datasets, our calibrated hybrid achieves
Wasserstein distances as low as 0.001 and Kolmogorov-Smirnov statistics around
0.01, demonstrating near-zero marginal discrepancy. Pairwise trend scores
surpass 90%, and Nearest Neighbor Adversarial Accuracy approaches 50%,
confirming robust privacy protection. Downstream classifiers trained on
synthetic data achieve up to 94% accuracy and F1 scores above 93%, comparable
to models trained on real data. This scalable, privacy-preserving approach
matches state-of-the-art methods, sets new benchmarks for joint-distribution
fidelity in healthcare, and supports sensitive AI applications.

</details>


### [768] [Reinforced Domain Selection for Continuous Domain Adaptation](https://arxiv.org/abs/2510.10530)
*Hanbing Liu,Huaze Tang,Yanru Wu,Yang Li,Xiao-Ping Zhang*

Main category: cs.LG

TL;DR: 提出了一种结合强化学习和特征解耦的无监督持续域适应新框架，用于选择中间域，并通过无监督奖励机制优化迁移路径和任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有持续域适应方法在没有显式元数据的情况下选择中间域存在挑战。

Method: 提出了一种结合强化学习和特征解耦的框架，利用中间域的嵌入距离作为无监督奖励，并通过解耦域不变特征和域特定特征来优化迁移路径和任务性能。

Result: 在Rotated MNIST和ADNI等数据集上进行了广泛的实证评估，与传统方法相比，在预测准确性和域选择效率方面均取得了显著改进。

Conclusion: 该方法在无监督持续域适应方面是一种有效的方法，能够同时优化迁移路径和目标任务性能。

Abstract: Continuous Domain Adaptation (CDA) effectively bridges significant domain
shifts by progressively adapting from the source domain through intermediate
domains to the target domain. However, selecting intermediate domains without
explicit metadata remains a substantial challenge that has not been extensively
explored in existing studies. To tackle this issue, we propose a novel
framework that combines reinforcement learning with feature disentanglement to
conduct domain path selection in an unsupervised CDA setting. Our approach
introduces an innovative unsupervised reward mechanism that leverages the
distances between latent domain embeddings to facilitate the identification of
optimal transfer paths. Furthermore, by disentangling features, our method
facilitates the calculation of unsupervised rewards using domain-specific
features and promotes domain adaptation by aligning domain-invariant features.
This integrated strategy is designed to simultaneously optimize transfer paths
and target task performance, enhancing the effectiveness of domain adaptation
processes. Extensive empirical evaluations on datasets such as Rotated MNIST
and ADNI demonstrate substantial improvements in prediction accuracy and domain
selection efficiency, establishing our method's superiority over traditional
CDA approaches.

</details>


### [769] [Rethinking RL Evaluation: Can Benchmarks Truly Reveal Failures of RL Methods?](https://arxiv.org/abs/2510.10541)
*Zihan Chen,Yiming Zhang,Hengguang Zhou,Zenghui Ding,Yining Sun,Cho-Jui Hsieh*

Main category: cs.LG

TL;DR: 现有基准不足以评估大型语言模型（LLM）强化学习（RL）的进展，尽管最近有报道称RL在这些基准上有所改进，但研究发现，在这些基准的训练集上进行训练与直接在测试集上进行训练相比，性能几乎相同，这表明基准无法有效地区分进一步的进展。


<details>
  <summary>Details</summary>
Motivation: 对大型语言模型（LLM）强化学习（RL）的评估基准不足，无法有效衡量模型的泛化能力。

Method: 提出了一种诊断套件和Oracle Performance Gap (OPG) 指标来量化训练集和测试集之间的性能差距，并通过压力测试分析了现有RL方法的泛化能力。

Result: 现有RL方法在分布变化、难度变化和反事实场景方面泛化能力不足，而这些问题在当前基准测试中未能暴露出来。

Conclusion: 现有基准不足以评估泛化能力，并提出了三个核心原则来设计更可靠的基准：充分的难度、平衡的评估和分布鲁棒性。

Abstract: Current benchmarks are inadequate for evaluating progress in reinforcement
learning (RL) for large language models (LLMs).Despite recent benchmark gains
reported for RL, we find that training on these benchmarks' training sets
achieves nearly the same performance as training directly on the test sets,
suggesting that the benchmarks cannot reliably separate further progress.To
study this phenomenon, we introduce a diagnostic suite and the Oracle
Performance Gap (OPG) metric that quantifies the performance difference between
training on the train split versus the test split of a benchmark. We further
analyze this phenomenon with stress tests and find that, despite strong
benchmark scores, existing RL methods struggle to generalize across
distribution shifts, varying levels of difficulty, and counterfactual
scenarios: shortcomings that current benchmarks fail to reveal.We conclude that
current benchmarks are insufficient for evaluating generalization and propose
three core principles for designing more faithful benchmarks: sufficient
difficulty, balanced evaluation, and distributional robustness.

</details>


### [770] [PAC-Bayesian Reinforcement Learning Trains Generalizable Policies](https://arxiv.org/abs/2510.10544)
*Abdelkrim Zitouni,Mehdi Hennequin,Juba Agoun,Ryan Horache,Nadia Kabachi,Omar Rivasplata*

Main category: cs.LG

TL;DR: We provide a new PAC-Bayesian generalization bound for reinforcement learning that considers Markov dependencies using mixing time, offering non-vacuous guarantees for algorithms like Soft Actor-Critic and improving exploration through a new algorithm, PB-SAC.


<details>
  <summary>Details</summary>
Motivation: The sequential nature of data in reinforcement learning violates independence assumptions in classical generalization bounds, making it challenging to obtain reliable guarantees. This work aims to overcome these challenges by developing a generalization bound that explicitly accounts for Markov dependencies.

Method: The paper derives a novel PAC-Bayesian generalization bound for reinforcement learning that incorporates the chain's mixing time to account for Markov dependencies in the data. They also propose a new algorithm, PB-SAC, which optimizes this bound during training to guide exploration.

Result: The derived bound provides non-vacuous generalization certificates for off-policy algorithms like Soft Actor-Critic. Experiments on continuous control tasks demonstrate that the proposed PB-SAC algorithm offers meaningful confidence certificates and maintains competitive performance.

Conclusion: The novel PAC-Bayesian generalization bound effectively addresses the challenges of data dependency in reinforcement learning, providing practical utility through the PB-SAC algorithm for improved exploration and reliable confidence certificates.

Abstract: We derive a novel PAC-Bayesian generalization bound for reinforcement
learning that explicitly accounts for Markov dependencies in the data, through
the chain's mixing time. This contributes to overcoming challenges in obtaining
generalization guarantees for reinforcement learning, where the sequential
nature of data breaks the independence assumptions underlying classical bounds.
Our bound provides non-vacuous certificates for modern off-policy algorithms
like Soft Actor-Critic. We demonstrate the bound's practical utility through
PB-SAC, a novel algorithm that optimizes the bound during training to guide
exploration. Experiments across continuous control tasks show that our approach
provides meaningful confidence certificates while maintaining competitive
performance.

</details>


### [771] [Multi-scale Frequency-Aware Adversarial Network for Parkinson's Disease Assessment Using Wearable Sensors](https://arxiv.org/abs/2510.10558)
*Weiming Zhao,Xulong Wang,Jun Qi,Yun Yang,Po Yang*

Main category: cs.LG

TL;DR: MFAM通过频率分解和多实例学习来提高帕金森病评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的可穿戴传感器方法在提取特征时缺乏病理特异性，并且由于帕金森病症状的时间稀疏性，关键诊断特征容易被稀释，从而难以准确评估疾病严重程度。

Method: 提出了一种名为MFAM（多尺度频率感知对抗多实例网络）的模型。该模型包含一个由医学先验知识指导的频率分解模块，以增强特征的特异性。此外，通过引入基于注意力的多实例学习（MIL）框架，该模型能够自适应地关注最具诊断价值的稀疏时间段。

Result: 在公开的PADS数据集（用于帕金森病与鉴别诊断的二元分类）和私有数据集（用于四级严重程度评估）上进行了全面验证。实验结果表明，MFAM在处理复杂的临床时间序列方面，其特异性优于通用时间序列模型。

Conclusion: MFAM在自动化评估帕金森病严重程度方面提供了一种有前景的解决方案，能够有效处理帕金森病评估中的特征特异性和时间稀疏性问题。

Abstract: Severity assessment of Parkinson's disease (PD) using wearable sensors offers
an effective, objective basis for clinical management. However, general-purpose
time series models often lack pathological specificity in feature extraction,
making it difficult to capture subtle signals highly correlated with
PD.Furthermore, the temporal sparsity of PD symptoms causes key diagnostic
features to be easily "diluted" by traditional aggregation methods, further
complicating assessment. To address these issues, we propose the Multi-scale
Frequency-Aware Adversarial Multi-Instance Network (MFAM). This model enhances
feature specificity through a frequency decomposition module guided by medical
prior knowledge. Furthermore, by introducing an attention-based multi-instance
learning (MIL) framework, the model can adaptively focus on the most
diagnostically valuable sparse segments.We comprehensively validated MFAM on
both the public PADS dataset for PD versus differential diagnosis (DD) binary
classification and a private dataset for four-class severity assessment.
Experimental results demonstrate that MFAM outperforms general-purpose time
series models in handling complex clinical time series with specificity,
providing a promising solution for automated assessment of PD severity.

</details>


### [772] [Understanding Self-supervised Contrastive Learning through Supervised Objectives](https://arxiv.org/abs/2510.10572)
*Byeongchan Lee*

Main category: cs.LG

TL;DR: 本文将自监督表示学习视为监督表示学习目标的近似，提出了一种新的理论框架，并推导了与InfoNCE等对比损失密切相关的损失函数，解释了其原理，并引入了原型表示偏差和平衡对比损失的概念，同时在经验上验证了平衡正负样本对交互效果。


<details>
  <summary>Details</summary>
Motivation: 自监督表示学习虽然取得了显著的经验成功，但其理论理解仍然有限。本文旨在提供一个理论视角来理解自监督表示学习。

Method: 将自监督表示学习公式化为监督表示学习目标的近似，并在此基础上推导损失函数，引入原型表示偏差和平衡对比损失的概念，并通过经验验证来评估平衡正负样本对交互的效果。

Result: 推导出的损失函数与InfoNCE等对比损失密切相关，引入的概念有助于解释和改进自监督学习算法的行为，经验验证了平衡正负样本对交互的效果。

Conclusion: 本文提出的理论框架为理解自监督表示学习提供了新的视角，并对对比学习中的实践进行了理论上的解释，同时通过实验验证了理论的有效性。

Abstract: Self-supervised representation learning has achieved impressive empirical
success, yet its theoretical understanding remains limited. In this work, we
provide a theoretical perspective by formulating self-supervised representation
learning as an approximation to supervised representation learning objectives.
Based on this formulation, we derive a loss function closely related to popular
contrastive losses such as InfoNCE, offering insight into their underlying
principles. Our derivation naturally introduces the concepts of prototype
representation bias and a balanced contrastive loss, which help explain and
improve the behavior of self-supervised learning algorithms. We further show
how components of our theoretical framework correspond to established practices
in contrastive learning. Finally, we empirically validate the effect of
balancing positive and negative pair interactions. All theoretical proofs are
provided in the appendix, and our code is included in the supplementary
material.

</details>


### [773] [Compositional Symmetry as Compression: Lie Pseudogroup Structure in Algorithmic Agents](https://arxiv.org/abs/2510.10586)
*Giulio Ruffini*

Main category: cs.LG

TL;DR: 智能体被视为能够使用生成程序跟踪和压缩感官流的程序。我们提出了一种框架，其中相关的结构先验是简单性（所罗门诺夫），理解为“组合对称性”：自然流可以通过有限参数李群（伪群）在几何和拓扑上复杂的低维流形（潜在空间）上的（局部）作用来很好地描述。将智能体建模为与这些流耦合的通用神经动力学系统，我们证明准确的世界跟踪会带来（i）“结构约束”——智能体构成方程和读数的等变性——以及（ii）“动力学约束”：在静态输入下，对称性会在智能体动力学中诱导守恒量（诺特定理标签），并将轨迹限制在约化的不变流形上；在缓慢漂移下，这些流形会移动但保持低维。这产生了与伪群的组合因子对齐的约化流形层次结构，为深度模型中“组合性的祝福”提供了几何解释。我们将这些思想与李伪群的斯宾塞形式主义联系起来，并提出了一种基于对称性的、自成一体的预测编码版本，其中更高层仅接收对称方向上（预测误差坐标）在较低层未解决的“粗粒度残差变换”。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于提出一种新的框架来理解和建模智能体（agents）如何处理和压缩感官信息流，借鉴了算法（Kolmogorov）和信息论（Solomonoff）的视角。核心在于探索“简单性”作为一种结构先验，并将其具体化为“组合对称性”，以解释自然流的生成过程和智能体的学习机制。研究旨在提供一个几何化的解释，说明为什么组合性（compositionality）在深度学习模型中如此重要，以及如何通过对称性原理来构建更有效的预测编码模型。

Method: 本研究提出一个将智能体建模为通用神经动力学系统与感官流耦合的框架。该框架的核心思想是将“简单性”理解为“组合对称性”，即自然流可以通过有限参数李伪群在低维流形上的作用来描述。通过分析准确世界跟踪对智能体提出的约束，研究推导出了两种类型的约束：（i）结构约束：智能体的构成方程和读数必须具有等变性；（ii）动力学约束：在静态输入下，对称性产生守恒量并约束轨迹在约化不变流形上，而在缓慢漂移下，这些流形保持低维。此外，研究还连接了李伪群的斯宾塞形式主义，并构建了一个基于对称性的预测编码模型，其中高层接收低层未解决的残差变换。

Result: 研究结果表明，准确的世界跟踪对智能体的结构和动力学施加了特定的约束。结构上，智能体的方程和读数需要满足等变性。动力学上，对称性在静态输入下导致了守恒量和约化不变流形，而在缓慢漂移下则维持了这些流形的低维特性。这形成了一个与伪群组合因子对齐的流形层次结构，解释了组合性在深度模型中的优势。此外，研究还提出了一个基于对称性的预测编码模型，其中信息在不同层级之间以粗粒度残差变换的形式传递。

Conclusion: 本研究提供了一个基于组合对称性的几何框架，用于理解智能体如何通过跟踪和压缩感官流来学习世界模型。研究表明，对称性不仅对智能体的结构和动力学提出了约束，还通过形成不变流形层次结构，解释了组合性在深度模型中的有效性。最终，研究提出了一个自成一体的、基于对称性的预测编码模型，为信息处理和学习提供了一种新的视角。

Abstract: In the algorithmic (Kolmogorov) view, agents are programs that track and
compress sensory streams using generative programs. We propose a framework
where the relevant structural prior is simplicity (Solomonoff) understood as
\emph{compositional symmetry}: natural streams are well described by (local)
actions of finite-parameter Lie pseudogroups on geometrically and topologically
complex low-dimensional configuration manifolds (latent spaces). Modeling the
agent as a generic neural dynamical system coupled to such streams, we show
that accurate world-tracking imposes (i) \emph{structural constraints} --
equivariance of the agent's constitutive equations and readouts -- and (ii)
\emph{dynamical constraints}: under static inputs, symmetry induces conserved
quantities (Noether-style labels) in the agent dynamics and confines
trajectories to reduced invariant manifolds; under slow drift, these manifolds
move but remain low-dimensional. This yields a hierarchy of reduced manifolds
aligned with the compositional factorization of the pseudogroup, providing a
geometric account of the ``blessing of compositionality'' in deep models. We
connect these ideas to the Spencer formalism for Lie pseudogroups and formulate
a symmetry-based, self-contained version of predictive coding in which higher
layers receive only \emph{coarse-grained residual transformations}
(prediction-error coordinates) along symmetry directions unresolved at lower
layers.

</details>


### [774] [FusionGen: Feature Fusion-Based Few-Shot EEG Data Generation](https://arxiv.org/abs/2510.10604)
*Yuheng Chen,Dingkun Liu,Xinyao Yang,Xinping Xu,Baicheng Chen,Dongrui Wu*

Main category: cs.LG

TL;DR: FusionGen是一个新颖的EEG数据生成框架，通过解纠缠表示学习和特征融合来解决EEG数据稀疏和跨主体变异性问题，从而提高EEG解码模型的泛化性和实用性。


<details>
  <summary>Details</summary>
Motivation: EEG信号的稀疏性和显著的跨体变异性限制了基于EEG的BCI的泛化和应用，这是实际应用中的一个关键挑战。

Method: FusionGen整合了跨试验的特征，通过特征匹配融合模块，并结合轻量级的特征提取和重建流程，以确保在数据有限的情况下实现数据多样性和可训练性。

Result: FusionGen在多个公开的EEG数据集上的广泛实验表明，它显著优于现有的增强技术，在分类准确性方面取得了显著的改进。

Conclusion: FusionGen通过利用解纠缠表示学习和特征融合，有效地解决了EEG数据稀疏性和跨体变异性问题，提高了EEG解码模型的性能。

Abstract: Brain-computer interfaces (BCIs) provide potential for applications ranging
from medical rehabilitation to cognitive state assessment by establishing
direct communication pathways between the brain and external devices via
electroencephalography (EEG). However, EEG-based BCIs are severely constrained
by data scarcity and significant inter-subject variability, which hinder the
generalization and applicability of EEG decoding models in practical settings.
To address these challenges, we propose FusionGen, a novel EEG data generation
framework based on disentangled representation learning and feature fusion. By
integrating features across trials through a feature matching fusion module and
combining them with a lightweight feature extraction and reconstruction
pipeline, FusionGen ensures both data diversity and trainability under limited
data constraints. Extensive experiments on multiple publicly available EEG
datasets demonstrate that FusionGen significantly outperforms existing
augmentation techniques, yielding notable improvements in classification
accuracy.

</details>


### [775] [Budget Allocation for Unknown Value Functions in a Lipschitz Space](https://arxiv.org/abs/2510.10605)
*MohammadHossein Bateni,Hossein Esfandiari,Samira HosseinGhorban,Alireza Mirrokni,Radin Shahdaei*

Main category: cs.LG

TL;DR: 预算约束下的模型选择问题


<details>
  <summary>Details</summary>
Motivation: 在构建学习模型时，需要评估大量的中间模型（例如特征选择、模型结构搜索、参数调优等），而这些评估结果会影响后续的模型探索决策。然而，中间模型的真实性能只有在评估后才能得知。

Method: 将问题形式化为在Lipschitz空间内对未知价值函数进行最优预算分配的一般性问题。

Result: （摘要中未提供具体结果）

Conclusion: （摘要中未提供具体结论）

Abstract: Building learning models frequently requires evaluating numerous intermediate
models. Examples include models considered during feature selection, model
structure search, and parameter tunings. The evaluation of an intermediate
model influences subsequent model exploration decisions. Although prior
knowledge can provide initial quality estimates, true performance is only
revealed after evaluation. In this work, we address the challenge of optimally
allocating a bounded budget to explore the space of intermediate models. We
formalize this as a general budget allocation problem over unknown-value
functions within a Lipschitz space.

</details>


### [776] [Encoder Decoder Generative Adversarial Network Model for Stock Market Prediction](https://arxiv.org/abs/2510.10617)
*Bahadur Yadav,Sanjay Kumar Mohanty*

Main category: cs.LG

TL;DR: EDGAN是一个基于GRU的Encoder-Decoder GAN模型，用于解决股票价格预测中的挑战，通过引入残差连接、静态和动态协变量以及窗口机制，提高了预测精度和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 金融市场具有波动性和非线性，使得股票价格预测具有挑战性。传统的GAN模型在应用于此领域时存在模式崩溃、训练不稳定以及难以捕捉时间/特征相关性等问题。

Method: 提出了一种基于GRU的Encoder-Decoder GAN（EDGAN）模型，其特点包括：使用带有残差连接的时序解码器进行精确重构；对静态和动态协变量进行条件化以实现上下文学习；采用窗口机制捕捉时间动态。生成器部分采用包含残差GRU块的密集Encoder-Decoder框架。

Result: 在多样化的股票数据集上进行的广泛实验表明，EDGAN在预测精度和训练稳定性方面表现优越，即使在波动性市场中也是如此。在市场条件下，其预测精度和收敛稳定性持续优于传统的GAN变体。

Conclusion: EDGAN模型通过其创新的设计，有效解决了现有GAN模型在股票价格预测中的局限性，并在实践中证明了其优越的性能和稳定性。

Abstract: Forecasting stock prices remains challenging due to the volatile and
non-linear nature of financial markets. Despite the promise of deep learning,
issues such as mode collapse, unstable training, and difficulty in capturing
temporal and feature level correlations have limited the applications of GANs
in this domain. We propose a GRU-based Encoder-Decoder GAN (EDGAN) model that
strikes a balance between expressive power and simplicity. The model introduces
key innovations such as a temporal decoder with residual connections for
precise reconstruction, conditioning on static and dynamic covariates for
contextual learning, and a windowing mechanism to capture temporal dynamics.
Here, the generator uses a dense encoder-decoder framework with residual GRU
blocks. Extensive experiments on diverse stock datasets demonstrate that EDGAN
achieves superior forecasting accuracy and training stability, even in volatile
markets. It consistently outperforms traditional GAN variants in forecasting
accuracy and convergence stability under market conditions.

</details>


### [777] [SDG-L: A Semiparametric Deep Gaussian Process based Framework for Battery Capacity Prediction](https://arxiv.org/abs/2510.10621)
*Hanbing Liu,Yanru Wu,Yang Li,Ercan E. Kuruoglu,Xuan Zhang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Lithium-ion batteries are becoming increasingly omnipresent in energy supply.
However, the durability of energy storage using lithium-ion batteries is
threatened by their dropping capacity with the growing number of
charging/discharging cycles. An accurate capacity prediction is the key to
ensure system efficiency and reliability, where the exploitation of battery
state information in each cycle has been largely undervalued. In this paper, we
propose a semiparametric deep Gaussian process regression framework named SDG-L
to give predictions based on the modeling of time series battery state data. By
introducing an LSTM feature extractor, the SDG-L is specially designed to
better utilize the auxiliary profiling information during charging/discharging
process. In experimental studies based on NASA dataset, our proposed method
obtains an average test MSE error of 1.2%. We also show that SDG-L achieves
better performance compared to existing works and validate the framework using
ablation studies.

</details>


### [778] [ImpMIA: Leveraging Implicit Bias for Membership Inference Attack under Realistic Scenarios](https://arxiv.org/abs/2510.10625)
*Yuval Golbari,Navve Wasserman,Gal Vardi,Michal Irani*

Main category: cs.LG

TL;DR: 黑盒成员推断攻击（MIA）在现实世界中表现不佳，因为其假设很少成立。本文提出了一种名为 ImpMIA 的白盒攻击方法，该方法利用神经网络的隐式偏差，无需参考模型即可识别训练样本，并在现实场景中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的黑盒成员推断攻击（MIA）在现实场景中存在假设不成立导致性能下降的问题。

Method: 提出了一种名为 ImpMIA 的白盒攻击方法，该方法利用神经网络的隐式偏差，基于最大间隔隐式偏差理论，并使用 KKT 最优性条件来识别训练样本，方法是找出其梯度最能重构训练模型参数的样本。

Result: ImpMIA 在现实场景中，即仅能获取模型权重和训练数据超集的情况下，与黑盒和白盒攻击相比，取得了最先进的性能。

Conclusion: ImpMIA 能够克服现有黑盒攻击的局限性，并在更现实的场景中实现成员推断攻击的最先进性能。

Abstract: Determining which data samples were used to train a model-known as Membership
Inference Attack (MIA)-is a well-studied and important problem with
implications for data privacy. Black-box methods presume access only to the
model's outputs and often rely on training auxiliary reference models. While
they have shown strong empirical performance, they rely on assumptions that
rarely hold in real-world settings: (i) the attacker knows the training
hyperparameters; (ii) all available non-training samples come from the same
distribution as the training data; and (iii) the fraction of training data in
the evaluation set is known. In this paper, we demonstrate that removing these
assumptions leads to a significant drop in the performance of black-box
attacks. We introduce ImpMIA, a Membership Inference Attack that exploits the
Implicit Bias of neural networks, hence removes the need to rely on any
reference models and their assumptions. ImpMIA is a white-box attack -- a
setting which assumes access to model weights and is becoming increasingly
realistic given that many models are publicly available (e.g., via Hugging
Face). Building on maximum-margin implicit bias theory, ImpMIA uses the
Karush-Kuhn-Tucker (KKT) optimality conditions to identify training samples.
This is done by finding the samples whose gradients most strongly reconstruct
the trained model's parameters. As a result, ImpMIA achieves state-of-the-art
performance compared to both black and white box attacks in realistic settings
where only the model weights and a superset of the training data are available.

</details>


### [779] [ProteinAE: Protein Diffusion Autoencoders for Structure Encoding](https://arxiv.org/abs/2510.10634)
*Shaoning Li,Le Zhuo,Yusong Wang,Mingyu Li,Xinheng He,Fandi Wu,Hongsheng Li,Pheng-Ann Heng*

Main category: cs.LG

TL;DR: ProteinAE是一个创新的扩散自编码器，可以直接在E(3)空间中处理蛋白质骨架坐标，并将其映射到连续的潜在空间，从而简化了训练过程并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理SE(3)流形、离散化或多重训练目标时存在复杂性，阻碍了模型优化和泛化。需要更有效的方法来表示蛋白质结构，特别是在蛋白质生成建模方面。

Method: ProteinAE采用非等变扩散Transformer和瓶颈设计，将蛋白质骨架坐标从E(3)直接映射到连续的紧凑潜在空间。它使用单一的流匹配目标进行端到端训练。

Result: ProteinAE在重建质量上达到了最先进的水平，优于现有的自编码器。其潜在空间能够支持一个潜在扩散模型，该模型能够生成高质量的蛋白质结构，与领先的基于结构的方法相媲美，并显著优于以前的基于潜在的方法。

Conclusion: ProteinAE通过直接在E(3)空间中处理蛋白质坐标并利用单一的流匹配目标，简化了蛋白质结构表示和生成的过程，并在重建和生成方面取得了最先进的性能。

Abstract: Developing effective representations of protein structures is essential for
advancing protein science, particularly for protein generative modeling.
Current approaches often grapple with the complexities of the SE(3) manifold,
rely on discrete tokenization, or the need for multiple training objectives,
all of which can hinder the model optimization and generalization. We introduce
ProteinAE, a novel and streamlined protein diffusion autoencoder designed to
overcome these challenges by directly mapping protein backbone coordinates from
E(3) into a continuous, compact latent space. ProteinAE employs a
non-equivariant Diffusion Transformer with a bottleneck design for efficient
compression and is trained end-to-end with a single flow matching objective,
substantially simplifying the optimization pipeline. We demonstrate that
ProteinAE achieves state-of-the-art reconstruction quality, outperforming
existing autoencoders. The resulting latent space serves as a powerful
foundation for a latent diffusion model that bypasses the need for explicit
equivariance. This enables efficient, high-quality structure generation that is
competitive with leading structure-based approaches and significantly
outperforms prior latent-based methods. Code is available at
https://github.com/OnlyLoveKFC/ProteinAE_v1.

</details>


### [780] [Trustworthy Retrosynthesis: Eliminating Hallucinations with a Diverse Ensemble of Reaction Scorers](https://arxiv.org/abs/2510.10645)
*Michal Sadowski,Maria Wyrzykowska,Lukasz Sztukiewicz,Tadija Radusinović,Jan Rzymkowski,Paweł Włodarczyk-Pruszyński,Mikołaj Sacha,Piotr Kozakowski,Ruard van Workum,Stanislaw Kamil Jastrzebski*

Main category: cs.LG

TL;DR: RetroTrim是一个逆合成系统，通过结合多种反应评分策略来避免生成不合理的合成路线，并在药物分子合成方面取得了高比例的高质量路线。


<details>
  <summary>Details</summary>
Motivation: 在逆合成领域，生成模型容易产生不合理或错误的输出（幻觉），而对合成路线的可靠评估耗时且缺乏自动化方法。

Method: RetroTrim结合了基于机器学习模型和现有化学数据库的多种反应评分策略，以识别和过滤掉幻觉反应，并生成高质量的合成路线。

Result: RetroTrim能够成功过滤掉不合理的合成路线，并且在生成的高质量路线数量方面优于其他基线方法。其评分策略能够捕捉不同类型的幻觉。

Conclusion: RetroTrim通过结合多样的反应评分策略，有效解决了逆合成中的幻觉问题，并在药物分子合成领域提供了高质量的合成路线。研究者们还提出了新的评估协议和基准数据集，以促进该领域的研究。

Abstract: Retrosynthesis is one of the domains transformed by the rise of generative
models, and it is one where the problem of nonsensical or erroneous outputs
(hallucinations) is particularly insidious: reliable assessment of synthetic
plans is time-consuming, with automatic methods lacking. In this work, we
present RetroTrim, a retrosynthesis system that successfully avoids nonsensical
plans on a set of challenging drug-like targets. Compared to common baselines
in the field, our system is not only the sole method that succeeds in filtering
out hallucinated reactions, but it also results in the highest number of
high-quality paths overall. The key insight behind RetroTrim is the combination
of diverse reaction scoring strategies, based on machine learning models and
existing chemical databases. We show that our scoring strategies capture
different classes of hallucinations by analyzing them on a dataset of labeled
retrosynthetic intermediates. To measure the performance of retrosynthesis
systems, we propose a novel evaluation protocol for reactions and synthetic
paths based on a structured review by expert chemists. Using this protocol, we
compare systems on a set of 32 novel targets, curated to reflect recent trends
in drug structures. While the insights behind our methodology are broadly
applicable to retrosynthesis, our focus is on targets in the drug-like domain.
By releasing our benchmark targets and the details of our evaluation protocol,
we hope to inspire further research into reliable retrosynthesis.

</details>


### [781] [Digital Twin-enabled Multi-generation Control Co-Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.10694)
*Ying-Kuan Tsai,Vispi Karkaria,Yi-Ping Chen,Wei Chen*

Main category: cs.LG

TL;DR: 本研究提出了一种数字孪生（DT）驱动的控制协同设计（CCD）框架，该框架利用深度强化学习（DRL）和多代设计范式，通过持续学习和适应来优化物理设计和控制器，以应对现实世界中不可预测的不确定性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的不确定性难以预测，现有的不确定性感知CCD方法仍有局限。多代设计通过利用产品全生命周期的数据进行迭代改进，以应对这一挑战。

Method: 提出了一种数字孪生（DT）驱动的控制协同设计（CCD）框架，集成了深度强化学习（DRL）和多代设计范式。该框架利用DT进行实时的模型更新和自适应的重新优化，DRL加速了决策制定过程，使其能够从数据中不断学习并适应不确定的环境。多代设计范式确保每个设计周期（部署、运行、重新设计）收集的数据都能用于改进DT模型、通过分位数回归提高不确定性量化，并指导下一代物理组件和控制器的设计。

Result: 在主动悬架系统上的实验表明，该框架通过学习路况和驾驶行为，能够产生更平稳、更稳定的控制轨迹，显著提高了动态性能、鲁棒性和效率。

Conclusion: 本研究将CCD扩展到面向全生命周期的多代设计框架，利用DT进行持续的模型更新和设计优化，并采用DRL加速自适应实时决策，从而有效提升了动态系统的性能和鲁棒性。

Abstract: Control Co-Design (CCD) integrates physical and control system design to
improve the performance of dynamic and autonomous systems. Despite advances in
uncertainty-aware CCD methods, real-world uncertainties remain highly
unpredictable. Multi-generation design addresses this challenge by considering
the full lifecycle of a product: data collected from each generation informs
the design of subsequent generations, enabling progressive improvements in
robustness and efficiency. Digital Twin (DT) technology further strengthens
this paradigm by creating virtual representations that evolve over the
lifecycle through real-time sensing, model updating, and adaptive
re-optimization. This paper presents a DT-enabled CCD framework that integrates
Deep Reinforcement Learning (DRL) to jointly optimize physical design and
controller. DRL accelerates real-time decision-making by allowing controllers
to continuously learn from data and adapt to uncertain environments. Extending
this approach, the framework employs a multi-generation paradigm, where each
cycle of deployment, operation, and redesign uses collected data to refine DT
models, improve uncertainty quantification through quantile regression, and
inform next-generation designs of both physical components and controllers. The
framework is demonstrated on an active suspension system, where DT-enabled
learning from road conditions and driving behaviors yields smoother and more
stable control trajectories. Results show that the method significantly
enhances dynamic performance, robustness, and efficiency. Contributions of this
work include: (1) extending CCD into a lifecycle-oriented multi-generation
framework, (2) leveraging DTs for continuous model updating and informed
design, and (3) employing DRL to accelerate adaptive real-time decision-making.

</details>


### [782] [Stock Prediction via a Dual Relation Fusion Network incorporating Static and Dynamic Relations](https://arxiv.org/abs/2510.10695)
*Long Chen,Huixin Bai,Mingxin Wang,Xiaohua Huang,Ying Liu,Jie Zhao,Ziyu Guan*

Main category: cs.LG

TL;DR: 该研究提出了一种双关系融合网络（DRFN）来改进股票价格预测，通过同时考虑股票间关系的长期稳定性和动态变化性。


<details>
  <summary>Details</summary>
Motivation: 现有股票价格预测方法主要关注单一状态的股票间关系，忽略了动态和静态关系之间的互补性。为解决此问题，本研究提出一种新的方法。

Method: 提出双关系融合网络（DRFN），该网络包含一个新颖的相对静态关系组件，用于模拟时变长期模式并纳入隔夜信息影响。通过距离感知机制捕捉动态股票间关系，并通过融合前一日的动态关系和预定义的静态关系来演化长期结构。

Result: 实验结果表明，DRFN在不同市场的表现显著优于基线方法，并且对关系强度和股价的协动性具有高敏感度。

Conclusion: DRFN能有效捕捉股票间关系的长期稳定性和动态变化性，在股票价格预测方面表现优异。

Abstract: Accurate modeling of inter-stock relationships is critical for stock price
forecasting. However, existing methods predominantly focus on single-state
relationships, neglecting the essential complementarity between dynamic and
static inter-stock relations. To solve this problem, we propose a Dual Relation
Fusion Network (DRFN) to capture the long-term relative stability of stock
relation structures while retaining the flexibility to respond to sudden market
shifts. Our approach features a novel relative static relation component that
models time-varying long-term patterns and incorporates overnight informational
influences. We capture dynamic inter-stock relationships through distance-aware
mechanisms, while evolving long-term structures via recurrent fusion of dynamic
relations from the prior day with the pre-defined static relations. Experiments
demonstrate that our method significantly outperforms the baselines across
different markets, with high sensitivity to the co-movement of relational
strength and stock price.

</details>


### [783] [Attention-Enhanced LSTM Modeling for Improved Temperature and Rainfall Forecasting in Bangladesh](https://arxiv.org/abs/2510.10702)
*Usman Gani Joy,Shahadat kabir,Tasnim Niger*

Main category: cs.LG

TL;DR: 该研究提出了一种结合注意力机制的LSTM模型，用于提高孟加拉国温度和降雨量预测的准确性，并在历史数据上取得了优于基线模型的性能。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国极易受到气候变化影响，现有模型在捕捉气候数据中的长期依赖性和复杂时间模式方面存在不足。

Method: 研究引入了集成了注意力机制的先进长短期记忆（LSTM）模型，并使用了1901-2023年的NASA POWER项目温度数据和人道主义数据交换组织的降雨量数据进行训练和评估。

Result: 该模型在月度预测中，温度预测的测试均方误差（MSE）为0.2411，平均绝对误差（MAE）为0.3860摄氏度，决定系数（R^2）为0.9834，归一化均方根误差（NRMSE）为0.0370。降雨量预测的MSE为1283.67 mm^2，MAE为22.91 mm，R^2为0.9639，NRMSE为0.0354。该模型在模拟气候趋势和区域变化方面表现出更好的鲁棒性。

Conclusion: 该模型能够提高预测精度，并为理解孟加拉国气候变率的物理过程提供潜在见解，支持气候敏感型行业的应用。

Abstract: Accurate climate forecasting is vital for Bangladesh, a region highly
susceptible to climate change impacts on temperature and rainfall. Existing
models often struggle to capture long-range dependencies and complex temporal
patterns in climate data. This study introduces an advanced Long Short-Term
Memory (LSTM) model integrated with an attention mechanism to enhance the
prediction of temperature and rainfall dynamics. Utilizing comprehensive
datasets from 1901-2023, sourced from NASA's POWER Project for temperature and
the Humanitarian Data Exchange for rainfall, the model effectively captures
seasonal and long-term trends. It outperforms baseline models, including
XGBoost, Simple LSTM, and GRU, achieving a test MSE of 0.2411 (normalized
units), MAE of 0.3860 degrees C, R^2 of 0.9834, and NRMSE of 0.0370 for
temperature, and MSE of 1283.67 mm^2, MAE of 22.91 mm, R^2 of 0.9639, and NRMSE
of 0.0354 for rainfall on monthly forecasts. The model demonstrates improved
robustness with only a 20 percent increase in MSE under simulated climate
trends (compared to an approximately 2.2-fold increase in baseline models
without trend features) and a 50 percent degradation under regional variations
(compared to an approximately 4.8-fold increase in baseline models without
enhancements). These results highlight the model's ability to improve
forecasting precision and offer potential insights into the physical processes
governing climate variability in Bangladesh, supporting applications in
climate-sensitive sectors.

</details>


### [784] [Designing ReLU Generative Networks to Enumerate Trees with a Given Tree Edit Distance](https://arxiv.org/abs/2510.10706)
*Mamoona Ghafoor,Tatsuya Akutsu*

Main category: cs.LG

TL;DR: 本研究提出了一种基于ReLU的生成网络，可以在理论上保证生成具有指定编辑距离的树结构数据，并且网络规模为O(n^3)，深度恒定。与现有的非确定性生成模型相比，该方法在生成所有有效树方面表现出更高的成功率。


<details>
  <summary>Details</summary>
Motivation: 生成具有指定树编辑距离的树在计算生物学、结构数据分析和图像处理等领域具有重要应用。然而，目前尚不清楚生成此类数据的生成网络的合适大小和深度。

Method: 研究人员从理论上证明了生成网络的存在性和构造方法，该网络能够生成与给定树在树编辑距离上相似的树。具体来说，对于给定的根、有序、带标签的树T（大小为n+1，标签来自字母表Σ）和非负整数d，证明了所有树编辑距离最多为d的树可以通过ReLU生成网络生成，其大小为O(n^3)，深度恒定。

Result: 所提出的网络在生成多达21个节点的树时得到了实现和评估。由于其确定性架构，网络成功地生成了所有在指定树编辑距离内的有效树。相比之下，最先进的图生成模型GraphRNN和GraphGDP（依赖于非确定性机制）生成的有效树数量明显减少，验证率分别仅达到35%和48%。

Conclusion: 这项研究为构建紧凑型生成模型提供了理论基础，并为精确有效的树结构数据生成开辟了新的方向。所提出的网络实现可在此处找到：https://github.com/MGANN-KU/TreeGen_ReLUNetworks。

Abstract: The generation of trees with a specified tree edit distance has significant
applications across various fields, including computational biology, structured
data analysis, and image processing. Recently, generative networks have been
increasingly employed to synthesize new data that closely resembles the
original datasets. However, the appropriate size and depth of generative
networks required to generate data with a specified tree edit distance remain
unclear. In this paper, we theoretically establish the existence and
construction of generative networks capable of producing trees similar to a
given tree with respect to the tree edit distance. Specifically, for a given
rooted, ordered, and vertex-labeled tree T of size n + 1 with labels from an
alphabet \Sigma, and a non-negative integer d, we prove that all rooted,
ordered, and vertex-labeled trees over \Sigma with tree edit distance at most d
from T can be generated using a ReLU-based generative network with size O(n^3 )
and constant depth. The proposed networks were implemented and evaluated for
generating trees with up to 21 nodes. Due to their deterministic architecture,
the networks successfully generated all valid trees within the specified tree
edit distance. In contrast, state-of-the-art graph generative models GraphRNN
and GraphGDP, which rely on non-deterministic mechanisms, produced
significantly fewer valid trees, achieving validation rates of only up to 35%
and 48%, respectively. These findings provide a theoretical foundation towards
construction of compact generative models and open new directions for exact and
valid tree-structured data generation. An implementation of the proposed
networks is available at https://github.com/MGANN-KU/TreeGen_ReLUNetworks.

</details>


### [785] [Provable Anytime Ensemble Sampling Algorithms in Nonlinear Contextual Bandits](https://arxiv.org/abs/2510.10730)
*Jiazheng Sun,Weixin Wang,Pan Xu*

Main category: cs.LG

TL;DR: 该研究提出了一个统一的算法框架，用于非线性上下文老虎机中的集成采样，并为两种常见的非线性上下文老虎机设置（广义线性老虎机和神经网络老虎机）推导了相应的遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 为非线性上下文老虎机提供一个统一的集成采样算法框架，并解决现有算法在理论和实践中存在的挑战。

Method: 通过在随机扰动数据上使用最大似然估计来维护多个奖励模型参数的估计器。分别提出了广义线性集成采样（GLM-ES）和神经网络集成采样（Neural-ES）。

Result: GLM-ES 的遗憾界限为 O(d^(3/2) * sqrt(T) + d^(9/2))，Neural-ES 的遗憾界限为 O(tilde(d) * sqrt(T))。这些界限与现有随机探索算法的最优结果相匹配。开发了适用于未知 T 的任何时域算法版本。

Conclusion: 集成采样是一种可证明且实用的非线性上下文老虎机随机探索方法。

Abstract: We provide a unified algorithmic framework for ensemble sampling in nonlinear
contextual bandits and develop corresponding regret bounds for two most common
nonlinear contextual bandit settings: Generalized Linear Ensemble Sampling
(\texttt{GLM-ES}) for generalized linear bandits and Neural Ensemble Sampling
(\texttt{Neural-ES}) for neural contextual bandits. Both methods maintain
multiple estimators for the reward model parameters via maximum likelihood
estimation on randomly perturbed data. We prove high-probability frequentist
regret bounds of $\mathcal{O}(d^{3/2} \sqrt{T} + d^{9/2})$ for \texttt{GLM-ES}
and $\mathcal{O}(\widetilde{d} \sqrt{T})$ for \texttt{Neural-ES}, where $d$ is
the dimension of feature vectors, $\widetilde{d}$ is the effective dimension of
a neural tangent kernel matrix, and $T$ is the number of rounds. These regret
bounds match the state-of-the-art results of randomized exploration algorithms
in nonlinear contextual bandit settings. In the theoretical analysis, we
introduce techniques that address challenges specific to nonlinear models.
Practically, we remove fixed-time horizon assumptions by developing anytime
versions of our algorithms, suitable when $T$ is unknown. Finally, we
empirically evaluate \texttt{GLM-ES}, \texttt{Neural-ES}, and their anytime
variants, demonstrating strong performance. Overall, our results establish
ensemble sampling as a provable and practical randomized exploration approach
for nonlinear contextual bandits.

</details>


### [786] [A Stochastic Differential Equation Framework for Multi-Objective LLM Interactions: Dynamical Systems Analysis with Code Generation Applications](https://arxiv.org/abs/2510.10739)
*Shivani Shukla,Himanshu Joshi*

Main category: cs.LG

TL;DR: 提出了一种基于随机微分方程的框架，用于模拟迭代大型语言模型（LLM）交互中的多目标优化动态，并通过代码生成进行了验证。


<details>
  <summary>Details</summary>
Motivation: 在迭代的大型语言模型（LLM）交互中，多目标优化动态的建模是一个挑战。本研究旨在开发一个框架来捕捉LLM响应的随机性并分析竞争目标之间的干扰模式。

Method: 提出一个通用的随机微分方程框架，包含显式的扩散项来模拟LLM响应的随机性，并使用干涉矩阵来描述竞争目标之间的干扰。以迭代代码生成为例，对400个会话进行了分析，涉及安全、效率和功能性等目标。

Result: 在代码生成实验中，观察到策略依赖的收敛行为，收敛速率在0.33到1.29之间。对于平衡的方法，预测准确度达到了R2 = 0.74。这表明该框架能够有效地捕捉和预测多目标优化动态。

Conclusion: 多目标LLM交互的动力学系统分析是可行的，代码生成是初步的验证领域。本研究为理解和优化LLM在多目标场景下的行为提供了新的视角。

Abstract: We introduce a general stochastic differential equation framework for
modelling multiobjective optimization dynamics in iterative Large Language
Model (LLM) interactions. Our framework captures the inherent stochasticity of
LLM responses through explicit diffusion terms and reveals systematic
interference patterns between competing objectives via an interference matrix
formulation. We validate our theoretical framework using iterative code
generation as a proof-of-concept application, analyzing 400 sessions across
security, efficiency, and functionality objectives. Our results demonstrate
strategy-dependent convergence behaviors with rates ranging from 0.33 to 1.29,
and predictive accuracy achieving R2 = 0.74 for balanced approaches. This work
proposes the feasibility of dynamical systems analysis for multi-objective LLM
interactions, with code generation serving as an initial validation domain.

</details>


### [787] [Optimally Deep Networks -- Adapting Model Depth to Datasets for Superior Efficiency](https://arxiv.org/abs/2510.10764)
*Shaharyar Ahmed Khan Tareen,Filza Khan Tareen*

Main category: cs.LG

TL;DR: ODNs通过渐进式深度扩展训练策略，为不同任务找到最优模型深度，减少计算和内存开销，便于部署到资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 现有DNN模型体积大、计算和内存需求高，在资源受限设备上部署不切实际。

Method: 提出渐进式深度扩展（progressive depth expansion）训练策略，从浅层开始训练，逐步增加深度直至达到目标精度，实现最优深度。

Result: ODNs在MNIST和SVHN数据集上，ResNet-18和ResNet-34模型分别实现了高达98.64%和96.44%的内存占用减少，同时保持了99.31%和96.08%的有竞争力的准确率。

Conclusion: ODNs通过找到最优模型深度，有效解决了DNN模型效率问题，降低了训练和推理成本，提高了计算效率，有利于在边缘设备上部署。

Abstract: Deep neural networks (DNNs) have provided brilliant performance across
various tasks. However, this success often comes at the cost of unnecessarily
large model sizes, high computational demands, and substantial memory
footprints. Typically, powerful architectures are trained at full depths but
not all datasets or tasks require such high model capacity. Training very deep
architectures on relatively low-complexity datasets frequently leads to wasted
computation, unnecessary energy consumption, and excessive memory usage, which
in turn makes deployment of models on resource-constrained devices impractical.
To address this problem, we introduce Optimally Deep Networks (ODNs), which
provide a balance between model depth and task complexity. Specifically, we
propose a NAS like training strategy called progressive depth expansion, which
begins by training deep networks at shallower depths and incrementally
increases their depth as the earlier blocks converge, continuing this process
until the target accuracy is reached. ODNs use only the optimal depth for the
given datasets, removing redundant layers. This cuts down future training and
inference costs, lowers the memory footprint, enhances computational
efficiency, and facilitates deployment on edge devices. Empirical results show
that the optimal depths of ResNet-18 and ResNet-34 for MNIST and SVHN, achieve
up to 98.64 % and 96.44 % reduction in memory footprint, while maintaining a
competitive accuracy of 99.31 % and 96.08 %, respectively.

</details>


### [788] [Understanding Sampler Stochasticity in Training Diffusion Models for RLHF](https://arxiv.org/abs/2510.10767)
*Jiayuan Sheng,Hanyang Zhao,Haoxian Chen,David D. Yao,Wenpin Tang*

Main category: cs.LG

TL;DR: RLHF 训练的扩散模型在训练时使用随机采样器，推理时使用确定性采样器，这会导致奖励不匹配。本文理论分析了这种不匹配，并提供了理论界限和收敛率。实验表明，这种奖励差距会随着训练而缩小，并且更高的随机性训练可以提高 ODE 采样质量。


<details>
  <summary>Details</summary>
Motivation: RLHF 训练的扩散模型在训练和推理时使用的采样器不匹配，导致奖励不匹配，引发对推理质量的担忧。

Method: 使用 gDDIM 框架理论分析了奖励差距，并对 VE 和 VP 模型进行了收敛率分析。实验采用了 DDPO 和 MixGRPO 方法。

Result: 理论上，本文为扩散模型提供了奖励差距的界限和收敛率。实验证明，奖励差距随着训练的进行而缩小，并且使用更高随机性的 SDE 训练能够提升 ODE 采样的质量。

Conclusion: RLHF 训练的扩散模型中存在的随机采样器与确定性采样器之间的不匹配会导致奖励差距，但这种差距会随着训练的进行而减小，并且采用更高的随机性进行训练可以提高推理时的采样质量。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is increasingly used to
fine-tune diffusion models, but a key challenge arises from the mismatch
between stochastic samplers used during training and deterministic samplers
used during inference. In practice, models are fine-tuned using stochastic SDE
samplers to encourage exploration, while inference typically relies on
deterministic ODE samplers for efficiency and stability. This discrepancy
induces a reward gap, raising concerns about whether high-quality outputs can
be expected during inference. In this paper, we theoretically characterize this
reward gap and provide non-vacuous bounds for general diffusion models, along
with sharper convergence rates for Variance Exploding (VE) and Variance
Preserving (VP) Gaussian models. Methodologically, we adopt the generalized
denoising diffusion implicit models (gDDIM) framework to support arbitrarily
high levels of stochasticity, preserving data marginals throughout.
Empirically, our findings through large-scale experiments on text-to-image
models using denoising diffusion policy optimization (DDPO) and mixed group
relative policy optimization (MixGRPO) validate that reward gaps consistently
narrow over training, and ODE sampling quality improves when models are updated
using higher-stochasticity SDE training.

</details>


### [789] [Structure Over Signal: A Globalized Approach to Multi-relational GNNs for Stock Prediction](https://arxiv.org/abs/2510.10775)
*Amber Li,Aruzhan Abil,Juno Marques Oda*

Main category: cs.LG

TL;DR: OmniGNN是一种基于注意力、多关系、动态图神经网络，通过引入行业节点来增强宏观经济冲击下的消息传递和股票预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有图神经网络在金融市场中虽然能捕捉非线性股票依赖关系，但在宏观经济冲击下消息传递效率低下。

Method: 提出OmniGNN，一种集成宏观经济背景、具有异构节点和边类型的多关系动态图神经网络。通过引入行业节点作为全局中介，利用图注意力网络（GAT）加权邻居贡献，并结合Transformer捕捉多重关系的时间动态。

Result: 在公开数据集上的股票预测任务中，OmniGNN的性能优于现有模型，尤其在COVID-19期间表现出更强的鲁棒性。

Conclusion: OmniGNN通过引入行业节点和多关系动态图神经网络架构，能够有效处理宏观经济冲击，提升股票预测的鲁棒性和准确性。

Abstract: In financial markets, Graph Neural Networks have been successfully applied to
modeling relational data, effectively capturing nonlinear inter-stock
dependencies. Yet, existing models often fail to efficiently propagate messages
during macroeconomic shocks. In this paper, we propose OmniGNN, an
attention-based multi-relational dynamic GNN that integrates macroeconomic
context via heterogeneous node and edge types for robust message passing.
Central to OmniGNN is a sector node acting as a global intermediary, enabling
rapid shock propagation across the graph without relying on long-range
multi-hop diffusion. The model leverages Graph Attention Networks (GAT) to
weigh neighbor contributions and employs Transformers to capture temporal
dynamics across multiplex relations. Experiments show that OmniGNN outperforms
existing stock prediction models on public datasets, particularly demonstrating
strong robustness during the COVID-19 period.

</details>


### [790] [Preconditioned Norms: A Unified Framework for Steepest Descent, Quasi-Newton and Adaptive Methods](https://arxiv.org/abs/2510.10777)
*Andrey Veprikov,Arman Bolatov,Samuel Horváth,Aleksandr Beznosikov,Martin Takáč,Slavomir Hanzely*

Main category: cs.LG

TL;DR: 现有的深度学习优化方法在适应问题几何和利用曲率信息之间存在固有权衡。本文提出了一个统一框架，通过预条件矩阵范数的概念，将最速下降法、拟牛顿法和自适应方法进行泛化，并将现有的多种优化器（如SGD、Adam、Muon、KL-Shampoo、SOAP和SPlus）统一为同一原理的特例。在此框架下，论文首次系统地处理了矩阵参数化设置中的仿射和尺度不变性，并在此基础上提出了两种新方法：MuAdam和MuAdam-SANIA，实验证明其性能优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习优化方法在适应问题几何和利用曲率信息之间存在固有权衡，限制了其在不同架构上的应用。

Method: 提出一个统一框架，通过预条件矩阵范数的概念，将最速下降法、拟牛顿法和自适应方法进行泛化，并将现有的多种优化器统一为同一原理的特例。在此框架下，系统地处理了矩阵参数化设置中的仿射和尺度不变性，并提出了两种新方法：MuAdam和MuAdam-SANIA。

Result: 提出的MuAdam和MuAdam-SANIA方法在实验中表现出竞争力，并在某些情况下优于现有的最先进方法。

Conclusion: 通过引入预条件矩阵范数的概念，成功地统一了现有的多种优化方法，并提出了新的有效优化算法。

Abstract: Optimization lies at the core of modern deep learning, yet existing methods
often face a fundamental trade-off between adapting to problem geometry and
leveraging curvature utilization. Steepest descent algorithms adapt to
different geometries through norm choices but remain strictly first-order,
whereas quasi-Newton and adaptive optimizers incorporate curvature information
but are restricted to Frobenius geometry, limiting their applicability across
diverse architectures. In this work, we propose a unified framework
generalizing steepest descent, quasi-Newton methods, and adaptive methods
through the novel notion of preconditioned matrix norms. This abstraction
reveals that widely used optimizers such as SGD and Adam, as well as more
advanced approaches like Muon and KL-Shampoo, and recent hybrids including SOAP
and SPlus, all emerge as special cases of the same principle. Within this
framework, we provide the first systematic treatment of affine and scale
invariance in the matrix-parameterized setting, establishing necessary and
sufficient conditions under generalized norms. Building on this foundation, we
introduce two new methods, $\texttt{MuAdam}$ and $\texttt{MuAdam-SANIA}$, which
combine the spectral geometry of Muon with Adam-style preconditioning. Our
experiments demonstrate that these optimizers are competitive with, and in some
cases outperform, existing state-of-the-art methods. Our code is available at
https://github.com/brain-lab-research/LIB/tree/quasi_descent

</details>


### [791] [BioOSS: A Bio-Inspired Oscillatory State System with Spatio-Temporal Dynamics](https://arxiv.org/abs/2510.10790)
*Zhongju Yuan,Geraint Wiggins,Dick Botteldooren*

Main category: cs.LG

TL;DR: 提出了一种名为BioOSS的受生物启发的振荡状态系统，用于模拟神经元活动的波状传播，并在合成和真实世界任务中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型（主要基于感知器）未能捕捉生物神经元的振荡动力学，而现有的振荡系统也无法完全模拟生物神经元复杂的时空相互作用。

Method: 提出BioOSS系统，包含两种相互作用的神经元群体：p神经元（模拟锥体细胞）和o神经元（控制传播速度和活动扩散）。通过局部相互作用产生波状传播模式，并包含可训练的阻尼和传播速度参数。

Result: 在合成和真实世界任务中，BioOSS相比其他模型展现出更优越的性能和更好的可解释性。

Conclusion: BioOSS能够有效地模拟关键的神经处理波状传播动力学，并为建模自然神经网络的复杂性提供了一种新的方法。

Abstract: Today's deep learning architectures are primarily based on perceptron models,
which do not capture the oscillatory dynamics characteristic of biological
neurons. Although oscillatory systems have recently gained attention for their
closer resemblance to neural behavior, they still fall short of modeling the
intricate spatio-temporal interactions observed in natural neural circuits. In
this paper, we propose a bio-inspired oscillatory state system (BioOSS)
designed to emulate the wave-like propagation dynamics critical to neural
processing, particularly in the prefrontal cortex (PFC), where complex activity
patterns emerge. BioOSS comprises two interacting populations of neurons: p
neurons, which represent simplified membrane-potential-like units inspired by
pyramidal cells in cortical columns, and o neurons, which govern propagation
velocities and modulate the lateral spread of activity. Through local
interactions, these neurons produce wave-like propagation patterns. The model
incorporates trainable parameters for damping and propagation speed, enabling
flexible adaptation to task-specific spatio-temporal structures. We evaluate
BioOSS on both synthetic and real-world tasks, demonstrating superior
performance and enhanced interpretability compared to alternative
architectures.

</details>


### [792] [Rethinking deep learning: linear regression remains a key benchmark in predicting terrestrial water storage](https://arxiv.org/abs/2510.10799)
*Wanshu Nie,Sujay V. Kumar,Junyu Chen,Long Zhao,Olya Skulovich,Jinwoong Yoo,Justin Pflug,Shahryar Khalique Ahmad,Goutam Konapala*

Main category: cs.LG

TL;DR: 在水文应用中，LSTM和Transformer等机器学习模型表现出色。然而，它们在预测受多种因素影响的陆地储水量（TWS）方面的优势尚不明确。本研究使用HydroGlobe数据集，发现线性回归模型在TWS预测方面优于LSTM和Temporal Fusion Transformer。


<details>
  <summary>Details</summary>
Motivation: 评估LSTM和Transformer等深度学习模型在预测陆地储水量（TWS）方面的性能，并与传统统计模型进行比较，以明确其优势。

Method: 使用HydroGlobe数据集，该数据集包含仅来自陆地模型模拟的基础版本和结合多源遥感数据同化的高级版本，比较了线性回归、LSTM和Temporal Fusion Transformer在TWS预测方面的表现。

Result: 线性回归模型在TWS预测方面表现稳健，优于更复杂的LSTM和Temporal Fusion Transformer模型。

Conclusion: 在评估深度学习模型时，应包含传统统计模型作为基准。同时，需要建立能够反映自然变率和人类活动综合影响的、具有全球代表性的基准数据集。

Abstract: Recent advances in machine learning such as Long Short-Term Memory (LSTM)
models and Transformers have been widely adopted in hydrological applications,
demonstrating impressive performance amongst deep learning models and
outperforming physical models in various tasks. However, their superiority in
predicting land surface states such as terrestrial water storage (TWS) that are
dominated by many factors such as natural variability and human driven
modifications remains unclear. Here, using the open-access, globally
representative HydroGlobe dataset - comprising a baseline version derived
solely from a land surface model simulation and an advanced version
incorporating multi-source remote sensing data assimilation - we show that
linear regression is a robust benchmark, outperforming the more complex LSTM
and Temporal Fusion Transformer for TWS prediction. Our findings highlight the
importance of including traditional statistical models as benchmarks when
developing and evaluating deep learning models. Additionally, we emphasize the
critical need to establish globally representative benchmark datasets that
capture the combined impact of natural variability and human interventions.

</details>


### [793] [PruneGCRN: Minimizing and explaining spatio-temporal problems through node pruning](https://arxiv.org/abs/2510.10803)
*Javier García-Sigüenza,Mirco Nanni,Faraón Llorens-Largo,José F. Vicent*

Main category: cs.LG

TL;DR: 提出一种新的深度学习模型，通过在训练过程中优化剪枝机制来识别和移除图中不相关的节点，以提高模型的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在时空问题中应用的可解释性挑战，并提出一种理解问题本身的新方法。

Method: 提出一种新的深度学习模型，该模型集成了一个优化的剪枝机制，允许在训练过程中动态地移除图中不相关的节点，从而在最小化预测误差的同时学习最相关的节点子集。

Result: 使用交通数据集进行实验，证明所提出的剪枝方法在减小图规模的同时能保留更多信息，优于其他对比方法。

Conclusion: 剪枝是一种有潜力的工具，可以用于开发能够简化时空问题并提取最重要元素的模型。

Abstract: This work addresses the challenge of using a deep learning model to prune
graphs and the ability of this method to integrate explainability into
spatio-temporal problems through a new approach. Instead of applying
explainability to the model's behavior, we seek to gain a better understanding
of the problem itself. To this end, we propose a novel model that integrates an
optimized pruning mechanism capable of removing nodes from the graph during the
training process, rather than doing so as a separate procedure. This
integration allows the architecture to learn how to minimize prediction error
while selecting the most relevant nodes. Thus, during training, the model
searches for the most relevant subset of nodes, obtaining the most important
elements of the problem, facilitating its analysis. To evaluate the proposed
approach, we used several widely used traffic datasets, comparing the accuracy
obtained by pruning with the model and with other methods. The experiments
demonstrate that our method is capable of retaining a greater amount of
information as the graph reduces in size compared to the other methods used.
These results highlight the potential of pruning as a tool for developing
models capable of simplifying spatio-temporal problems, thereby obtaining their
most important elements.

</details>


### [794] [Crisis-Aware Regime-Conditioned Diffusion with CVaR Allocation](https://arxiv.org/abs/2510.10807)
*Ali Atiah Alzahrani*

Main category: cs.LG

TL;DR: MARCD是一种新的生成模型，结合了多智能体、状态条件化和扩散模型，用于改善投资组合决策，特别是在市场状态转变时。它通过高斯HMM推断潜在市场状态，并使用专门的扩散模型生成更真实的危机场景。该模型随后将生成的情景输入到考虑交易成本和治理的CVaR优化器中。


<details>
  <summary>Details</summary>
Motivation: 研究状态条件化生成模型和CVaR分配器能否在市场状态转变时改善投资组合决策。

Method: 提出了一种名为MARCD（多智能体状态条件化扩散）的新方法。该方法包括：(1) 使用高斯隐马尔可夫模型（HMM）推断潜在的市场状态；(2) 训练一个扩散模型，该模型具有针对不同状态的专家混合（MoE）降噪器，并采用侧重于极端事件的损失函数，以生成更丰富的危机联动场景；(3) 将生成的场景输入到一个考虑交易成本和治理的CVaR（条件在险价值）优化器中。

Result: 在2005-2025年的严格前向测试中，MARCD在多个资产ETF上的表现优于标准分配器，并比流行的生成器具有更好的校准。在2020-2025年的样本外测试中，MARCD实现了1.23的夏普比率（基准为1.02），最大回撤为9.3%（基准为14.1%），回撤减少了34%，交易周转率相当。平稳块自举区间表明夏普比率的提升在5%的水平上是显著的。

Conclusion: MARCD提供了一种可复现的方法，将侧重尾部风险的场景建模与有治理约束的投资组合决策联系起来，并能显著改善回撤控制。理论分析支持其尾部风险建模和投资组合优化方法的有效性。

Abstract: We study whether regime-conditioned generative scenarios, coupled with a
convex CVaR allocator, improve portfolio decisions under regime shifts. We
introduce Multi-Agent Regime-Conditioned Diffusion (MARCD), which (i) infers
latent regimes via a Gaussian HMM, (ii) trains a diffusion model with a
tail-weighted objective and a regime-specialized mixture-of-experts (MoE)
denoiser to enrich crisis co-movements, and (iii) feeds the generated scenarios
into a turnover-aware CVaR epigraph quadratic program with explicit governance.
In strict walk-forward tests on liquid multi-asset ETFs (2005-2025), MARCD
outperforms standard allocators and improves calibration relative to popular
generators. Over 2020-2025 out-of-sample (monthly; 10 bps), MARCD attains
Sharpe 1.23 (BL 1.02) and MaxDD 9.3 percent (BL 14.1 percent), a 34 percent
reduction, at comparable turnover; stationary block-bootstrap intervals
indicate the Sharpe uplift is significant at 5 percent. We provide theory
linking tail-weighted diffusion to spectral-risk control of the
decision-relevant CVaR gap, oracle/consistency results for the regime-MoE
denoiser, and Lipschitz/regret guarantees for the allocator. Together, MARCD
offers a reproducible bridge from tail-faithful scenario modeling to governed
portfolio decisions with materially improved drawdown control.

</details>


### [795] [Aegis: A Correlation-Based Data Masking Advisor for Data Sharing Ecosystems](https://arxiv.org/abs/2510.10810)
*Omar Islam Laskar,Fatemeh Ramezani Khozestani,Ishika Nankani,Sohrab Namazi Nia,Senjuti Basu Roy,Kaustubh Beedkar*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Data-sharing ecosystems enable entities -- such as providers, consumers, and
intermediaries -- to access, exchange, and utilize data for various downstream
tasks and applications. Due to privacy concerns, data providers typically
anonymize datasets before sharing them; however, the existence of multiple
masking configurations results in masked datasets with varying utility.
Consequently, a key challenge lies in efficiently determining the optimal
masking configuration that maximizes a dataset's utility. This paper presents
AEGIS, a middleware framework for identifying the optimal masking configuration
for machine learning datasets that consist of features and a class label. We
introduce a utility optimizer that minimizes predictive utility deviation -- a
metric based on the changes in feature-label correlations before and after
masking. Our framework leverages limited data summaries (such as 1D histograms)
or none to estimate the feature-label joint distribution, making it suitable
for scenarios where raw data is inaccessible due to privacy restrictions. To
achieve this, we propose a joint distribution estimator based on iterative
proportional fitting, which allows supporting various feature-label correlation
quantification methods such as g3, mutual information, or chi-square. Our
experimental evaluation on real-world datasets shows that AEGIS identifies
optimal masking configurations over an order of magnitude faster, while the
resulting masked datasets achieve predictive performance on downstream ML tasks
that is on par with baseline approaches.

</details>


### [796] [Glance for Context: Learning When to Leverage LLMs for Node-Aware GNN-LLM Fusion](https://arxiv.org/abs/2510.10849)
*Donald Loveland,Yao-An Yang,Danai Koutra*

Main category: cs.LG

TL;DR: GLANCE框架通过调用LLM来改进GNN的预测，尤其是在GNN表现不佳的节点上，实现了显著的性能提升，尤其是在异质性节点上，同时保持了整体最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM-GNN融合策略在所有节点上应用相似，导致整体性能提升有限，并且忽略了LLM在特定节点上的优势。聚合指标掩盖了LLM的实际效益，阻碍了新策略的开发。

Method: 提出GLANCE框架，该框架围绕GNN通常表现不佳的节点来重构LLM-GNN融合。GLANCE使用一个轻量级路由器，根据每节点信号判断是否调用LLM。由于LLM调用不可微，路由器采用基于优势的目标进行训练，以比较调用LLM的效用与仅依赖GNN的效用。

Result: GLANCE在多个基准测试中实现了节点子群体之间最佳的性能平衡，在异质性节点上实现了显著的性能提升（高达+13%），同时实现了整体最佳性能。

Conclusion: GLANCE的成功表明，采用自适应的、节点感知的GNN-LLM架构具有价值，通过选择性地调用LLM，可以在不产生高计算成本的情况下，在大型图上实现可扩展的部署。

Abstract: Learning on text-attributed graphs has motivated the use of Large Language
Models (LLMs) for graph learning. However, most fusion strategies are applied
uniformly across all nodes and attain only small overall performance gains. We
argue this result stems from aggregate metrics that obscure when LLMs provide
benefit, inhibiting actionable signals for new strategies. In this work, we
reframe LLM-GNN fusion around nodes where GNNs typically falter. We first show
that performance can significantly differ between GNNs and LLMs, with each
excelling on distinct structural patterns, such as local homophily. To leverage
this finding, we propose GLANCE (GNN with LLM Assistance for Neighbor- and
Context-aware Embeddings), a framework that invokes an LLM to refine a GNN's
prediction. GLANCE employs a lightweight router that, given inexpensive
per-node signals, decides whether to query the LLM. Since the LLM calls are
non-differentiable, the router is trained with an advantage-based objective
that compares the utility of querying the LLM against relying solely on the
GNN. Across multiple benchmarks, GLANCE achieves the best performance balance
across node subgroups, achieving significant gains on heterophilous nodes (up
to $+13\%$) while simultaneously achieving top overall performance. Our
findings highlight the value of adaptive, node-aware GNN-LLM architectures,
where selectively invoking the LLM enables scalable deployment on large graphs
without incurring high computational costs.

</details>


### [797] [Discrete State Diffusion Models: A Sample Complexity Perspective](https://arxiv.org/abs/2510.10854)
*Aadithya Srikanth,Mudit Gaur,Vaneet Aggarwal*

Main category: cs.LG

TL;DR: 尽管连续状态扩散模型得到了广泛研究，但离散状态扩散模型在理论上仍未被充分理解。本文提出了第一个离散状态扩散的样本复杂度界限 $\widetilde{\mathcal{O}}(\epsilon^{-2})$，并分析了其训练效率。 


<details>
  <summary>Details</summary>
Motivation: 离散状态扩散模型（适用于文本、序列和组合结构）的理论理解滞后于连续状态模型，尤其是在样本复杂度方面。 

Method: 通过将分数估计误差分解为统计、近似、优化和裁剪分量，来构建离散状态扩散的理论框架，并推导出样本复杂度界限。

Result: 首次提出了离散状态扩散模型的样本复杂度界限 $\widetilde{\mathcal{O}}(\epsilon^{-2})$，并提供了对模型训练效率的见解。

Conclusion: 本文填补了离散状态扩散模型理论分析的空白，证明了其理论上的可处理性和实际相关性。

Abstract: Diffusion models have demonstrated remarkable performance in generating
high-dimensional samples across domains such as vision, language, and the
sciences. Although continuous-state diffusion models have been extensively
studied both empirically and theoretically, discrete-state diffusion models,
essential for applications involving text, sequences, and combinatorial
structures, remain significantly less understood from a theoretical standpoint.
In particular, all existing analyses of discrete-state models assume score
estimation error bounds without studying sample complexity results. In this
work, we present a principled theoretical framework for discrete-state
diffusion, providing the first sample complexity bound of
$\widetilde{\mathcal{O}}(\epsilon^{-2})$. Our structured decomposition of the
score estimation error into statistical, approximation, optimization, and
clipping components offers critical insights into how discrete-state models can
be trained efficiently. This analysis addresses a fundamental gap in the
literature and establishes the theoretical tractability and practical relevance
of discrete-state diffusion models.

</details>


### [798] [Quantifying Information Disclosure During Gradient Descent Using Gradient Uniqueness](https://arxiv.org/abs/2510.10902)
*Mahmoud Abdelghafar,Maryam Aliakbarpour,Chris Jermaine*

Main category: cs.LG

TL;DR: 发布机器学习模型可能泄露隐私，本文提出了一种名为“梯度唯一性”的度量指标来量化这种风险，该指标源于对模型发布信息泄露量的上界推导。梯度唯一性可用于隐私审计，且不依赖于模型架构、数据集类型或攻击者策略。实验表明，基于梯度唯一性的防御方法在隐私保护方面可与DP-SGD媲美，同时在模型准确率方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型发布可能泄露隐私，需要量化这种风险。

Method: 提出了一种名为“梯度唯一性”的度量指标，并推导了其数学公式，然后检验了一种基于梯度唯一性的防御方法。

Result: 梯度唯一性度量指标可用于隐私审计，且不依赖于模型架构、数据集类型或攻击者策略。基于梯度唯一性的防御方法在隐私保护方面可与DP-SGD媲美，同时在模型准确率方面表现更优。

Conclusion: 梯度唯一性是一种有效的隐私泄露度量指标，并且基于此的防御方法在隐私和模型准确率之间取得了良好的平衡。

Abstract: Disclosing private information via publication of a machine learning model is
often a concern. Intuitively, publishing a learned model should be less risky
than publishing a dataset. But how much risk is there? In this paper, we
present a principled disclosure metric called \emph{gradient uniqueness} that
is derived from an upper bound on the amount of information disclosure from
publishing a learned model. Gradient uniqueness provides an intuitive way to
perform privacy auditing. The mathematical derivation of gradient uniqueness is
general, and does not make any assumption on the model architecture, dataset
type, or the strategy of an attacker. We examine a simple defense based on
monitoring gradient uniqueness, and find that it achieves privacy comparable to
classical methods such as DP-SGD, while being substantially better in terms of
(utility) testing accuracy.

</details>


### [799] [LPCVAE: A Conditional VAE with Long-Term Dependency and Probabilistic Time-Frequency Fusion for Time Series Anomaly Detection](https://arxiv.org/abs/2510.10915)
*Hanchang Cheng,Weimin Mu,Fan Liu,Weilin Zhu,Can Ma*

Main category: cs.LG

TL;DR: LPCVAE通过引入LSTM和PoE机制，有效解决了现有VAE-based TSAD方法在长期依赖和时频信息利用方面的不足，并在实验中表现优于最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于VAE的时间序列异常检测（TSAD）方法存在单窗口特征和对长期时频信息利用不足的局限性。

Method: 提出了一种条件变分自编码器（Conditional Variational AutoEncoder），名为LPCVAE，该模型引入LSTM来捕获超越窗口的长期依赖性，并采用Product-of-Experts（PoE）机制进行自适应、分布层面的概率融合，以减少时频信息损失。

Result: 在四个公共数据集上的广泛实验表明，LPCVAE的性能优于现有的最先进方法。

Conclusion: 将长期时频表示与自适应融合相结合，为TSAD提供了鲁棒且高效的解决方案。

Abstract: Time series anomaly detection(TSAD) is a critical task in signal processing
field, ensuring the reliability of complex systems. Reconstruction-based
methods dominate in TSAD. Among these methods, VAE-based methods have achieved
promising results. Existing VAE-based methods suffer from the limitation of
single-window feature and insufficient leveraging of long-term time and
frequency information. We propose a Conditional Variational AutoEncoder with
Long-term dependency and Probabilistic time-frequency fusion, named LPCVAE.
LPCVAE introduces LSTM to capture long-term dependencies beyond windows. It
further incorporates a Product-of-Experts (PoE) mechanism for adaptive and
distribution-level probabilistic fusion. This design effectively mitigates
time-frequency information loss. Extensive experiments on four public datasets
demonstrate it outperforms state-of-the-art methods. The results confirm that
integrating long-term time and frequency representations with adaptive fusion
yields a robust and efficient solution for TSAD.

</details>


### [800] [Find Your Optimal Teacher: Personalized Data Synthesis via Router-Guided Multi-Teacher Distillation](https://arxiv.org/abs/2510.10925)
*Hengyuan Zhang,Shiping Yang,Xiao Liang,Chenming Shang,Yuxuan Jiang,Chaofan Tao,Jing Xiong,Hayden Kwok-Hay So,Ruobing Xie,Angel X. Chang,Ngai Wong*

Main category: cs.LG

TL;DR: PerSyn是一种新的个性化数据合成策略，通过


<details>
  <summary>Details</summary>
Motivation: 学生模型在教师模型生成的合成数据上进行训练是一种有前途的方法，但最近的研究表明，更强的模型不一定是最优的教师，这表明教师的输出与学生的学习能力之间存在不匹配。为了解决这个问题，我们提出了PerSyn（个性化数据合成），这是一种在新的“先路由后生成”范式下运行的新颖合成策略，用于创建针对每个学生模型的定制数据，使其能够更有效地学习。具体来说，PerSyn首先通过一个查询级别的路由器将每个提示分配给其最优教师，该路由器联合考虑了学生的学习能力和教师响应的质量。然后，每个教师只为分配给它的提示合成数据，这使得该过程比传统的“先生成后选择”范式更有效，在传统的范式中，所有教师必须为整个提示集生成并行响应，然后才能构建最终的数据集。

Method: PerSyn首先通过一个查询级别的路由器将每个提示分配给其最优教师，该路由器联合考虑了学生的学习能力和教师响应的质量。然后，每个教师只为分配给它的提示合成数据。

Result: PerSyn在指令调优和数学推理设置中，在不同模型系列和规模的广泛实验中，始终取得了优于或媲美所有基线的性能。进一步的分析验证了PerSyn的有效性，并提供了额外的见解，以推动未来的研究。

Conclusion: PerSyn通过“先路由后生成”范式，为每个学生模型定制合成数据，解决了强教师模型不一定最优的问题，提高了学习效率，并在多项任务和模型上取得了优于基线的结果。

Abstract: Training student models on synthetic data generated by strong teacher models
is a promising way to distilling the capabilities of teachers. However, recent
studies show that stronger models are not always optimal teachers, revealing a
mismatch between teacher outputs and student learnability. To address this
issue, we propose PerSyn (Personalized data Synthesis), a novel synthesis
strategy that operates under a new ``Route then Generate'' paradigm to create
data tailored to each student model, enabling it to learn more effectively.
Specifically, PerSyn first assigns each prompt to its optimal teacher via a
query-level router that jointly considers student learnability and teacher
response quality. Each teacher then synthesizes data only for its assigned
prompts, making the process more efficient than the conventional ``Generate
then Select'' paradigm, where all teachers must generate parallel responses for
the entire prompt set before constructing the final dataset. Extensive
experiments across different model families and scales demonstrate that PerSyn
consistently achieves superior or comparable performance to all baselines in
instruct tuning and math reasoning settings. Further analysis verifies the
effectiveness of PerSyn and offers extra insights to propel future research.

</details>


### [801] [Neutral Agent-based Adversarial Policy Learning against Deep Reinforcement Learning in Multi-party Open Systems](https://arxiv.org/abs/2510.10937)
*Qizhou Peng,Yang Zheng,Yu Wen,Yanna Wu,Yingying Du*

Main category: cs.LG

TL;DR: 深度强化学习易受对抗性攻击，现有方法在多方开放系统中受限。本文提出一种中立智能体的方法，无需与受害者智能体直接交互或完全控制环境，即可实现对抗性攻击。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习（DRL）在解决不确定性下的长期序贯决策问题上取得了显著成功，但也容易受到对抗性攻击。然而，现有的对抗性攻击方法在多方开放系统中应用受限，因为它们通常需要完全控制环境或与受害者智能体直接交互，这在实际中难以实现。

Method: 提出一种基于中立智能体（neutral agent）的对抗性策略学习方法。这种方法不直接与受害者智能体交互，也不需要完全控制环境，而是通过共享环境间接影响受害者智能体，从而实现对抗性攻击。

Result: 在星际争霸II的SMAC平台和Highway-env自动驾驶仿真平台上的实验结果表明，该方法能够针对多方开放系统发起通用且有效的对抗性攻击。

Conclusion: 所提出的中立智能体方法能够成功地在多方开放系统中实现对抗性攻击，克服了现有方法的局限性。

Abstract: Reinforcement learning (RL) has been an important machine learning paradigm
for solving long-horizon sequential decision-making problems under uncertainty.
By integrating deep neural networks (DNNs) into the RL framework, deep
reinforcement learning (DRL) has emerged, which achieved significant success in
various domains. However, the integration of DNNs also makes it vulnerable to
adversarial attacks. Existing adversarial attack techniques mainly focus on
either directly manipulating the environment with which a victim agent
interacts or deploying an adversarial agent that interacts with the victim
agent to induce abnormal behaviors. While these techniques achieve promising
results, their adoption in multi-party open systems remains limited due to two
major reasons: impractical assumption of full control over the environment and
dependent on interactions with victim agents.
  To enable adversarial attacks in multi-party open systems, in this paper, we
redesigned an adversarial policy learning approach that can mislead
well-trained victim agents without requiring direct interactions with these
agents or full control over their environments. Particularly, we propose a
neutral agent-based approach across various task scenarios in multi-party open
systems. While the neutral agents seemingly are detached from the victim
agents, indirectly influence them through the shared environment. We evaluate
our proposed method on the SMAC platform based on Starcraft II and the
autonomous driving simulation platform Highway-env. The experimental results
demonstrate that our method can launch general and effective adversarial
attacks in multi-party open systems.

</details>


### [802] [Redundancy as a Structural Information Principle for Learning and Generalization](https://arxiv.org/abs/2510.10938)
*Yuda Bi,Ying Zhu,Vince D Calhoun*

Main category: cs.LG

TL;DR: 该理论框架将信息论扩展到有限和结构化系统，将冗余重新定义为信息组织的根本属性，而不是低效。


<details>
  <summary>Details</summary>
Motivation: 将经典信息论扩展到有限和结构化系统，并将冗余重新定义为信息组织的基本属性。

Method: 将冗余表示为信息度量的通用类，在单一几何原理下统一了互信息、卡方依赖性和谱冗余等多种经典度量。该理论预测冗余有上下界，从而产生一个平衡过度压缩和过度耦合的最优平衡点。

Result: 通过对掩码自动编码器进行实验，验证了该原理：模型在泛化能力达到峰值时表现出稳定的冗余水平。

Conclusion: 冗余被确立为一种可衡量、可调整的量，可以连接通信的渐近世界和学习的有限世界。

Abstract: We present a theoretical framework that extends classical information theory
to finite and structured systems by redefining redundancy as a fundamental
property of information organization rather than inefficiency. In this
framework, redundancy is expressed as a general family of informational
divergences that unifies multiple classical measures, such as mutual
information, chi-squared dependence, and spectral redundancy, under a single
geometric principle. This reveals that these traditional quantities are not
isolated heuristics but projections of a shared redundancy geometry. The theory
further predicts that redundancy is bounded both above and below, giving rise
to an optimal equilibrium that balances over-compression (loss of structure)
and over-coupling (collapse). While classical communication theory favors
minimal redundancy for transmission efficiency, finite and structured systems,
such as those underlying real-world learning, achieve maximal stability and
generalization near this equilibrium. Experiments with masked autoencoders are
used to illustrate and verify this principle: the model exhibits a stable
redundancy level where generalization peaks. Together, these results establish
redundancy as a measurable and tunable quantity that bridges the asymptotic
world of communication and the finite world of learning.

</details>


### [803] [Interpretable Machine Learning for Cognitive Aging: Handling Missing Data and Uncovering Social Determinant](https://arxiv.org/abs/2510.10952)
*Xi Mao,Zhendong Wang,Jingyu Li,Lingchao Mao,Utibe Essien,Hairong Wang,Xuelei Sherry Ni*

Main category: cs.LG

TL;DR: 利用社会经济决定因素（SDOH）预测认知能力，以实现阿尔茨海默病（AD）的早期检测。


<details>
  <summary>Details</summary>
Motivation: 早期检测阿尔茨海默病（AD）至关重要，因为神经退行性影响不可逆，且风险因素在诊断前数年就开始积累。识别高风险个体有助于预防、及时护理和公平分配资源。

Method: 采用基于奇异值分解（SVD）的插补方法处理缺失值，并选择XGBoost模型进行预测。

Result: 该框架在预测准确性、鲁棒性和可解释性方面优于现有方法和数据挑战赛排行榜。SHAP分析显示，地板材料、年龄、社会经济地位（SES）、生活方式、社交互动、睡眠、压力和BMI是影响认知能力的重要因素。

Conclusion: 基于SDOH的可解释、数据驱动的建模方法对于理解认知衰退和早期检测阿尔茨海默病具有重要价值。

Abstract: Early detection of Alzheimer's disease (AD) is crucial because its
neurodegenerative effects are irreversible, and neuropathologic and
social-behavioral risk factors accumulate years before diagnosis. Identifying
higher-risk individuals earlier enables prevention, timely care, and equitable
resource allocation. We predict cognitive performance from social determinants
of health (SDOH) using the NIH NIA-supported PREPARE Challenge Phase 2 dataset
derived from the nationally representative Mex-Cog cohort of the 2003 and 2012
Mexican Health and Aging Study (MHAS).
  Data: The target is a validated composite cognitive score across seven
domains-orientation, memory, attention, language, constructional praxis, and
executive function-derived from the 2016 and 2021 MHAS waves. Predictors span
demographic, socioeconomic, health, lifestyle, psychosocial, and healthcare
access factors.
  Methodology: Missingness was addressed with a singular value decomposition
(SVD)-based imputation pipeline treating continuous and categorical variables
separately. This approach leverages latent feature correlations to recover
missing values while balancing reliability and scalability. After evaluating
multiple methods, XGBoost was chosen for its superior predictive performance.
  Results and Discussion: The framework outperformed existing methods and the
data challenge leaderboard, demonstrating high accuracy, robustness, and
interpretability. SHAP-based post hoc analysis identified top contributing SDOH
factors and age-specific feature patterns. Notably, flooring material emerged
as a strong predictor, reflecting socioeconomic and environmental disparities.
Other influential factors, age, SES, lifestyle, social interaction, sleep,
stress, and BMI, underscore the multifactorial nature of cognitive aging and
the value of interpretable, data-driven SDOH modeling.

</details>


### [804] [Rediscovering Entropy Regularization: Adaptive Coefficient Unlocks Its Potential for LLM Reinforcement Learning](https://arxiv.org/abs/2510.10959)
*Xiaoyun Zhang,Xiaojian Yuan,Di Huang,Wang You,Chen Hu,Jingqing Ruan,Kejiang Chen,Xing Hu*

Main category: cs.LG

TL;DR: RLVR训练中的策略熵崩溃问题可以通过自适应熵正则化（AER）框架得到解决，该框架能够根据任务难度动态调整熵系数，从而在保持探索能力的同时提高推理准确性。


<details>
  <summary>Details</summary>
Motivation: RLVR是增强LLM推理能力的关键范例，但其训练过程常遭遇策略熵崩溃问题，导致探索受限，推理性能下降。现有的熵正则化方法对固定系数敏感，不稳定。

Method: 提出了一种名为自适应熵正则化（AER）的框架，包含三个组件：难度感知系数分配、初始锚定目标熵和动态全局系数调整，以动态平衡探索和利用。

Result: 在多个数学推理基准测试中，AER的性能持续优于基线方法，提升了推理准确性和探索能力。

Conclusion: AER框架能够有效解决RLVR训练中的策略熵崩溃问题，通过动态调整熵正则化，实现了更好的探索和利用平衡，最终提高了LLM的推理性能。

Abstract: Reasoning ability has become a defining capability of Large Language Models
(LLMs), with Reinforcement Learning with Verifiable Rewards (RLVR) emerging as
a key paradigm to enhance it. However, RLVR training often suffers from policy
entropy collapse, where the policy becomes overly deterministic, hindering
exploration and limiting reasoning performance. While entropy regularization is
a common remedy, its effectiveness is highly sensitive to the fixed
coefficient, making it unstable across tasks and models. In this work, we
revisit entropy regularization in RLVR and argue that its potential has been
largely underestimated. Our analysis shows that (i) tasks of varying difficulty
demand distinct exploration intensities, and (ii) balanced exploration may
require the policy entropy to be maintained within a moderate range below its
initial level. Therefore, we propose Adaptive Entropy Regularization (AER)--a
framework that dynamically balances exploration and exploitation via three
components: difficulty-aware coefficient allocation, initial-anchored target
entropy, and dynamic global coefficient adjustment. Experiments on multiple
mathematical reasoning benchmarks show that AER consistently outperforms
baselines, improving both reasoning accuracy and exploration capability.

</details>


### [805] [MC#: Mixture Compressor for Mixture-of-Experts Large Models](https://arxiv.org/abs/2510.10962)
*Wei Huang,Yue Liao,Yukang Chen,Jianhui Liu,Haoru Tan,Si Liu,Shiming Zhang,Shuicheng Yan,Xiaojuan Qi*

Main category: cs.LG

TL;DR: MC# 通过静态量化和动态专家剪枝技术，显著压缩了 MoE-LLMs/VLMs 的模型大小和推理成本，在 DeepSeek-VL2 上实现了 6.2 倍的权重缩减和仅 1.7% 的准确率下降。


<details>
  <summary>Details</summary>
Motivation: 预训练所有专家并为每个输入激活多个专家会带来显著的计算和内存开销，使得专家模块成为模型大小和推理成本的主要因素。

Method: 提出 MC# 框架，结合静态量化和动态专家剪枝。其中，预加载混合精度量化 (PMQ) 通过线性规划优化比特分配，实现大小与性能的帕累托最优；在线 Top-any 剪枝 (OTP) 使用 Gumbel-Softmax 采样动态选择每个 token 的专家子集。

Result: MC# 在 DeepSeek-VL2 上实现了 6.2 倍的权重缩减（平均 2.57 比特），多模态基准测试准确率仅下降 1.7%。OTP 将专家激活减少超过 20%，性能下降不到 1%。

Conclusion: MC# 结合 PMQ 和 OTP，实现了极端的模型压缩，同时仅有微小的准确率损失，为高效部署 MoE 模型展示了巨大潜力。

Abstract: Mixture-of-Experts (MoE) effectively scales large language models (LLMs) and
vision-language models (VLMs) by increasing capacity through sparse activation.
However, preloading all experts into memory and activating multiple experts per
input introduces significant computational and memory overhead, making the
expert module a major contributor to model size and inference cost. To address
this, we propose MC# (Mixture-Compressor-sharp), a framework that combines
static quantization and dynamic expert pruning by leveraging the significance
of experts and tokens for aggressive compression of MoE-LLMs/VLMs. To reduce
storage and loading costs, we introduce Pre-Loading Mixed-Precision
Quantization (PMQ), which optimizes bit allocation via linear programming,
balancing expert importance and quantization error for a Pareto-optimal
trade-off between size and performance. To reduce runtime computation, Online
Top-any Pruning (OTP) uses Gumbel-Softmax sampling to dynamically select a
subset of experts per token, enabling fine-grained control over activation. By
combining PMQ's static bit-width optimization with OTP's dynamic routing, MC#
achieves extreme compression with minimal accuracy loss. On DeepSeek-VL2, MC#
achieves a 6.2 times weight reduction at 2.57 average bits with only a 1.7%
accuracy drop across five multimodal benchmarks. Additionally, OTP reduces
expert activation over 20% with less than 1% performance degradation,
demonstrating strong potential for efficient MoE-based model deployment.

</details>


### [806] [APLOT: Robust Reward Modeling via Adaptive Preference Learning with Optimal Transport](https://arxiv.org/abs/2510.10963)
*Zhuo Li,Yuege Feng,Dandan Guo,Jinpeng Hu,Anningzhe Gao,Xiang Wan*

Main category: cs.LG

TL;DR: 该研究提出了一种自适应边界机制来增强基于 Bradley-Terry (BT) 目标函数的奖励模型 (RM)，以解决其在区分相似偏好响应和泛化能力方面存在的不足。该机制通过考虑语义相似性和模型预测奖励差异，利用最优传输 (OT) 理论动态调整 RM 对更难样本的关注度，从而提高性能、收敛速度和泛化能力，并在多个基准测试和实际的 RLHF 实验中取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 基于 Bradley-Terry (BT) 目标函数的奖励模型 (RM) 在区分相似偏好响应方面存在困难，导致在容易的样本上过拟合，并且难以泛化到分布外 (OOD) 样本，从而影响了其整体性能。

Method: 通过引入自适应边界机制来增强 BT-RM。该机制基于语义相似性和模型预测奖励差异，利用最优传输 (OT) 理论，动态调整 RM 对更难样本的关注度，从而更好地捕捉所选和拒绝响应之间的分布差异。

Result: 在多个基准测试中，该方法在同分布 (ID) 和分布外 (OOD) 设置下均优于现有的 RM 技术。RLHF 实验也证明了其在更好地对齐 LLM 与人类偏好方面的实际有效性。

Conclusion: 所提出的自适应边界机制能够有效增强 BT-RM，提高其在区分相似偏好响应、泛化能力以及整体性能方面的表现，并在实际应用中展现出优越性。

Abstract: The reward model (RM) plays a crucial role in aligning Large Language Models
(LLMs) with human preferences through Reinforcement Learning, where the
Bradley-Terry (BT) objective has been recognized as simple yet powerful,
specifically for pairwise preference learning. However, BT-based RMs often
struggle to effectively distinguish between similar preference responses,
leading to insufficient separation between preferred and non-preferred outputs.
Consequently, they may easily overfit easy samples and cannot generalize well
to Out-Of-Distribution (OOD) samples, resulting in suboptimal performance. To
address these challenges, this paper introduces an effective enhancement to
BT-based RMs through an adaptive margin mechanism. Specifically, we design to
dynamically adjust the RM focus on more challenging samples through margins,
based on both semantic similarity and model-predicted reward differences, which
is approached from a distributional perspective solvable with Optimal Transport
(OT). By incorporating these factors into a principled OT cost matrix design,
our adaptive margin enables the RM to better capture distributional differences
between chosen and rejected responses, yielding significant improvements in
performance, convergence speed, and generalization capabilities. Experimental
results across multiple benchmarks demonstrate that our method outperforms
several existing RM techniques, showcasing enhanced performance in both
In-Distribution (ID) and OOD settings. Moreover, RLHF experiments support our
practical effectiveness in better aligning LLMs with human preferences. Our
code is available at https://github.com/BIRlz/APLOT

</details>


### [807] [Not All Bits Are Equal: Scale-Dependent Memory Optimization Strategies for Reasoning Models](https://arxiv.org/abs/2510.10964)
*Junhyuck Kim,Ethan Ewer,Taehong Moon,Jongho Park,Dimitris Papailiopoulos*

Main category: cs.LG

TL;DR: 4位量化对于推理模型并非最优选择，需要根据模型规模采用不同的优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有的针对非推理模型的4位量化通用策略，对于推理模型可能失效，因为推理模型的内存瓶颈在于KV缓存而非模型大小。现有的研究缺乏对推理模型进行内存优化的细致分析和指导。

Method: 通过在AIME25和GPQA-Diamond数据集上进行1700多种推理场景的系统性实验，研究不同规模的模型在内存分配上的权衡，以及KV缓存量化和KV缓存逐出策略的有效性。

Result: 发现存在一个与模型规模相关的权衡：小于8位4B参数的推理模型，通过分配更多内存给权重而非更长的生成长度来获得更高的准确性；而更大的模型则通过分配更多内存给更长的生成长度来提高准确性。这个规模阈值也决定了并行扩展的内存效率以及KV缓存逐出是否优于KV量化。

Conclusion: LLM的内存优化策略不能脱离模型规模。对于小型推理模型，应优先考虑模型容量；对于大型推理模型，应优先考虑测试时间计算。优化推理模型的部署需要与非推理模型不同的策略。

Abstract: While 4-bit quantization has emerged as a memory-optimal choice for
non-reasoning models and zero-shot tasks across scales, we show that this
universal prescription fails for reasoning models, where the KV cache rather
than model size can dominate memory. Through systematic experiments across
1,700 inference scenarios on AIME25 and GPQA-Diamond, we find a scale-dependent
trade-off: models with an effective size below 8-bit 4B parameters achieve
better accuracy by allocating memory to more weights rather than longer
generation, while larger models achieve better accuracy by allocating memory to
longer generations. This scale threshold also determines when parallel scaling
becomes memory-efficient and whether KV cache eviction outperforms KV
quantization. Our findings show that memory optimization for LLMs cannot be
scale-agnostic, while providing principled guidelines: for small reasoning
models, prioritize model capacity over test-time compute, while for larger
ones, maximize test-time compute. Our results suggest that optimizing reasoning
models for deployment requires fundamentally different strategies from those
established for non-reasoning models.

</details>


### [808] [Blade: A Derivative-free Bayesian Inversion Method using Diffusion Priors](https://arxiv.org/abs/2510.10968)
*Hongkai Zheng,Austin Wang,Zihui Wu,Zhengyu Huang,Ricardo Baptista,Yisong Yue*

Main category: cs.LG

TL;DR: Blade是一种无需计算导数即可进行贝叶斯反演的算法，它使用粒子集合和数据驱动的先验知识来处理非线性正向模型，并在各种反演问题上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当计算正向模型的导数在计算和实际上都具有挑战性时，无导数贝叶斯反演在许多科学和工程应用中是一项重要任务。

Method: Blade利用粒子集合和基于扩散模型的强大数据驱动先验来实现无导数贝叶斯反演，并且可以处理仅允许黑盒访问（即无导数）的非线性正向模型。

Result: Blade在包括高度非线性的流体动力学在内的各种反演问题上，取得了比现有的无导数贝叶斯反演方法更优越的性能。

Conclusion: Blade 算法能够处理非线性正向模型，并生成准确且经过良好校准的后验分布，为无导数贝叶斯反演提供了一种有效的解决方案。

Abstract: Derivative-free Bayesian inversion is an important task in many science and
engineering applications, particularly when computing the forward model
derivative is computationally and practically challenging. In this paper, we
introduce Blade, which can produce accurate and well-calibrated posteriors for
Bayesian inversion using an ensemble of interacting particles. Blade leverages
powerful data-driven priors based on diffusion models, and can handle nonlinear
forward models that permit only black-box access (i.e., derivative-free).
Theoretically, we establish a non-asymptotic convergence analysis to
characterize the effects of forward model and prior estimation errors.
Empirically, Blade achieves superior performance compared to existing
derivative-free Bayesian inversion methods on various inverse problems,
including challenging highly nonlinear fluid dynamics.

</details>


### [809] [On the Optimal Representation Efficiency of Barlow Twins: An Information-Geometric Interpretation](https://arxiv.org/abs/2510.10980)
*Di Zhang*

Main category: cs.LG

TL;DR: SSL 的理论框架尚不明确，本文提出了一种信息几何框架来量化表示效率，并证明 Barlow Twins 方法能达到最优效率。


<details>
  <summary>Details</summary>
Motivation: 缺乏统一的理论框架来理解和比较不同的自监督学习（SSL）方法的效率。

Method: 提出了一种新颖的信息几何框架，将表示效率定义为学习到的表示空间的有效内在维度与其环境维度的比率，其中有效维度源自编码器在统计流形上产生的费雪信息矩阵（FIM）的光谱特性。在此框架内，对 Barlow Twins 方法进行了理论分析。

Result: 证明了 Barlow Twins 方法通过驱动表示的互相关矩阵趋向于单位矩阵，从而诱导各向同性的 FIM，实现了最优的表示效率（η = 1）。

Conclusion: 该工作为理解 Barlow Twins 的有效性提供了严格的理论基础，并为分析 SSL 算法提供了新的几何视角。

Abstract: Self-supervised learning (SSL) has achieved remarkable success by learning
meaningful representations without labeled data. However, a unified theoretical
framework for understanding and comparing the efficiency of different SSL
paradigms remains elusive. In this paper, we introduce a novel
information-geometric framework to quantify representation efficiency. We
define representation efficiency $\eta$ as the ratio between the effective
intrinsic dimension of the learned representation space and its ambient
dimension, where the effective dimension is derived from the spectral
properties of the Fisher Information Matrix (FIM) on the statistical manifold
induced by the encoder. Within this framework, we present a theoretical
analysis of the Barlow Twins method. Under specific but natural assumptions, we
prove that Barlow Twins achieves optimal representation efficiency ($\eta = 1$)
by driving the cross-correlation matrix of representations towards the identity
matrix, which in turn induces an isotropic FIM. This work provides a rigorous
theoretical foundation for understanding the effectiveness of Barlow Twins and
offers a new geometric perspective for analyzing SSL algorithms.

</details>


### [810] [Catch-Only-One: Non-Transferable Examples for Model-Specific Authorization](https://arxiv.org/abs/2510.10982)
*Zihan Wang,Zhiyong Ma,Zhongkui Ma,Shuofeng Liu,Akide Liu,Derui Wang,Minhui Xue,Guangdong Bai*

Main category: cs.LG

TL;DR: 提出了一种名为“非迁移示例”（NEs）的训练无关、数据无关的输入端使用控制机制，通过在模型特定的低敏感子空间内重新编码输入，以保留授权模型的功能，同时降低未经授权模型上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI监管要求数据在保持可用于创新的同时，抵抗滥用，需要在模型层面平衡效用和保护。现有方法要么扰乱数据使其不可学，要么重新训练模型以抑制迁移，但都无法控制未知模型的推理，并且通常需要控制训练过程。

Method: 通过在模型特定的低敏感子空间内重新编码输入，以保留授权模型在子空间对齐下的输出，同时通过子空间不对齐降低未经授权模型上的性能。利用Hoffman-Wielandt不等式将性能下降与谱差异联系起来，为授权模型提供效用保证，并量化未经授权模型的偏差。

Result: 在各种视觉骨干网络和最先进的视觉-语言模型上，NEs 在常见的预处理下保持了性能，而未经授权的模型即使在尝试重建的情况下性能也会急剧下降。

Conclusion: NEs 是一种实用的方法，可以在防止未经授权的利用的同时，保持数据的预期用途。

Abstract: Recent AI regulations call for data that remain useful for innovation while
resistant to misuse, balancing utility with protection at the model level.
Existing approaches either perturb data to make it unlearnable or retrain
models to suppress transfer, but neither governs inference by unknown models,
and both typically require control over training. We propose non-transferable
examples (NEs), a training-free and data-agnostic input-side usage-control
mechanism. We recode inputs within a model-specific low-sensitivity subspace,
preserving outputs for the authorized model while reducing performance on
unauthorized models through subspace misalignment. We establish formal bounds
that guarantee utility for the authorized model and quantify deviation for
unauthorized ones, with the Hoffman-Wielandt inequality linking degradation to
spectral differences. Empirically, NEs retain performance on diverse vision
backbones and state-of-the-art vision-language models under common
preprocessing, whereas non-target models collapse even with reconstruction
attempts. These results establish NEs as a practical means to preserve intended
data utility while preventing unauthorized exploitation. Our project is
available at https://trusted-system-lab.github.io/model-specificity

</details>


### [811] [Instruction-aware User Embedding via Synergistic Language and Representation Modeling](https://arxiv.org/abs/2510.11016)
*Ziyi Gao,Yike Xu,Jiahao Yuan,Baokun Wang,Jinyong Wen,Xiaotong Lin,Yun Liu,Xing Fu,Yu Cheng,Yongchao Liu,Weiqiang Wang,Zhongle Xie*

Main category: cs.LG

TL;DR: InstructUE是一个利用大型语言模型（LLM）生成通用且指令感知的用户表示的基础模型，通过多编码器架构和对比-自回归训练框架，提高了用户嵌入的指令感知能力和噪声鲁棒性，并在用户预测、营销和推荐等多个领域取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有用户表示学习方法在跨领域泛化和对噪声行为信号的敏感性方面存在不足。

Method: 提出InstructUE，一个指令感知的用户嵌入基础模型，采用多编码器架构和轻量级适配器处理异构数据，并引入对比-自回归训练框架，结合自回归学习和对比学习，对齐用户-文本嵌入。

Result: 在用户预测、营销和推荐等现实世界应用中，InstructUE显著优于现有方法。

Conclusion: 指令感知的用户建模能有效实现特定场景下用户信息的指令引导去噪，为更通用和鲁棒的用户表示学习铺平了道路。

Abstract: User representation modeling has become increasingly crucial for personalized
applications, yet existing approaches struggle with generalizability across
domains and sensitivity to noisy behavioral signals. We present InstructUE, an
instruction-aware user embedding foundation model that leverages large language
models (LLMs) to generate general and instruction-aware user representations.
InstructUE introduces a multi-encoder architecture with a lightweight adapter
that efficiently processes heterogeneous data from six different sources while
preserving their structural characteristics. Additionally, it proposes a novel
contrastive-autoregressive training framework that bridges language and
representation spaces through a curated UserQA dataset. The
contrastive-autoregressive training framework simultaneously leverages
autoregressive learning to capture domain knowledge in language space and
contrastive learning to align user-text embeddings in representation space,
thereby enhancing the instruction-awareness and noise-robustness of user
embeddings. Through extensive experiments on real-world applications, we
demonstrate that InstructUE significantly outperforms existing methods across
multiple domains including user prediction, marketing, and recommendation
scenarios. Our results show that instruction-aware user modeling can
effectively achieve instruction-guided denoising of user information in
specific scenarios, paving the way for more generalizable and robust user
representation learning.

</details>


### [812] [The Easy Path to Robustness: Coreset Selection using Sample Hardness](https://arxiv.org/abs/2510.11018)
*Pranav Ramesh,Arjun Roy,Deepak Ravikumar,Kaushik Roy,Gopalakrishnan Srinivasan*

Main category: cs.LG

TL;DR: 该论文提出了一种名为EasyCore的数据选择方法，通过选择平均输入梯度范数（AIGN）较低的样本进行训练，以提高模型的对抗鲁棒性。实验证明，EasyCore在标准训练和对抗训练下都能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了从数据中心化的角度设计对抗鲁棒模型，需要识别出对学习弹性特征至关重要的输入样本。现有的协同集选择算法主要针对干净精度，在保持鲁棒性方面表现不佳。

Method: 提出了一种将样本的对抗脆弱性与其“难度”相关联的框架，并使用平均输入梯度范数（AIGN）来量化难度。EasyCore协同集选择算法仅保留低AIGN的样本进行训练。

Result: 在标准训练和对抗训练下，使用EasyCore选择的数据训练的模型，其对抗准确性显著高于使用现有协同集方法的数据训练的模型，在某些情况下准确性可提高高达7%（标准训练）和5%（TRADES对抗训练）。

Conclusion: EasyCore是一种高效且广泛适用的数据中心化方法，通过选择低AIGN样本可以提高对抗鲁棒性。AIGN是模型无关的数据集属性，使得EasyCore能够轻松集成到各种训练流程中。

Abstract: Designing adversarially robust models from a data-centric perspective
requires understanding which input samples are most crucial for learning
resilient features. While coreset selection provides a mechanism for efficient
training on data subsets, current algorithms are designed for clean accuracy
and fall short in preserving robustness. To address this, we propose a
framework linking a sample's adversarial vulnerability to its
\textit{hardness}, which we quantify using the average input gradient norm
(AIGN) over training. We demonstrate that \textit{easy} samples (with low AIGN)
are less vulnerable and occupy regions further from the decision boundary.
Leveraging this insight, we present EasyCore, a coreset selection algorithm
that retains only the samples with low AIGN for training. We empirically show
that models trained on EasyCore-selected data achieve significantly higher
adversarial accuracy than those trained with competing coreset methods under
both standard and adversarial training. As AIGN is a model-agnostic dataset
property, EasyCore is an efficient and widely applicable data-centric method
for improving adversarial robustness. We show that EasyCore achieves up to 7\%
and 5\% improvement in adversarial accuracy under standard training and TRADES
adversarial training, respectively, compared to existing coreset methods.

</details>


### [813] [Temporal Alignment Guidance: On-Manifold Sampling in Diffusion Models](https://arxiv.org/abs/2510.11057)
*Youngrok Park,Hojung Jung,Sangmin Bae,Se-Young Yun*

Main category: cs.LG

TL;DR: 生成模型中的扩散模型在生成过程中会累积误差，尤其是在应用引导来约束生成样本时，会导致样本失真。本文提出时间对齐引导（TAG）来解决此问题，通过时间预测器识别并纠正每一步的偏差，使样本重新回到目标流形，从而提高生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成过程中可能累积误差，尤其是在应用任意引导时，会导致样本失真（off-manifold）。

Method: 提出时间对齐引导（TAG）机制。利用时间预测器估计每一步的流形偏差，偏差越大，生成质量越低。TAG在生成过程中，通过吸引样本回到目标流形来纠正偏差。

Result: TAG在每一步生成中都能使样本更贴近目标流形，在多种下游任务中显著提高了生成质量。

Conclusion: TAG是一种有效的引导机制，可以解决扩散模型中的off-manifold现象，提高生成样本的质量。

Abstract: Diffusion models have achieved remarkable success as generative models.
However, even a well-trained model can accumulate errors throughout the
generation process. These errors become particularly problematic when arbitrary
guidance is applied to steer samples toward desired properties, which often
breaks sample fidelity. In this paper, we propose a general solution to address
the off-manifold phenomenon observed in diffusion models. Our approach
leverages a time predictor to estimate deviations from the desired data
manifold at each timestep, identifying that a larger time gap is associated
with reduced generation quality. We then design a novel guidance mechanism,
`Temporal Alignment Guidance' (TAG), attracting the samples back to the desired
manifold at every timestep during generation. Through extensive experiments, we
demonstrate that TAG consistently produces samples closely aligned with the
desired manifold at each timestep, leading to significant improvements in
generation quality across various downstream tasks.

</details>


### [814] [Efficient Edge Test-Time Adaptation via Latent Feature Coordinate Correction](https://arxiv.org/abs/2510.11068)
*Xinyu Luo,Jie Liu,Kecheng Chen,Junyi Yang,Bo Ding,Arindam Basu,Haoliang Li*

Main category: cs.LG

TL;DR: TED是一种新颖的、面向边缘设备的单实例测试时自适应（TTA）方法，它使用前向优化和CMA-ES来适应分布变化，而无需反向传播，从而在计算资源受限的情况下实现高效、无遗忘的自适应。


<details>
  <summary>Details</summary>
Motivation: 现有的测试时自适应（TTA）方法在计算资源有限的边缘设备上面临挑战，因为它们依赖于梯度优化或批处理，计算成本高且不适合资源受限的场景。

Method: 提出了一种名为TED的新型单实例TTA方法，该方法在潜在空间的主子空间中，使用协方差矩阵自适应演化策略（CMA-ES）进行前向仅坐标优化。通过更新一个紧凑的低维向量，TED在不进行反向传播、冻结模型参数的情况下，实现了适应性。

Result: TED在图像分类和关键词识别任务上取得了最先进的性能，并将计算复杂度降低了多达63倍。TED已成功部署在ZYNQ-7020平台上，证明了其在资源受限的边缘设备上的可行性。

Conclusion: TED通过其高效、无遗忘的自适应能力，为资源受限的边缘设备提供了一个实用的、可扩展的TTA解决方案。

Abstract: Edge devices face significant challenges due to limited computational
resources and distribution shifts, making efficient and adaptable machine
learning essential. Existing test-time adaptation (TTA) methods often rely on
gradient-based optimization or batch processing, which are inherently
unsuitable for resource-constrained edge scenarios due to their reliance on
backpropagation and high computational demands. Gradient-free alternatives
address these issues but often suffer from limited learning capacity, lack
flexibility, or impose architectural constraints. To overcome these
limitations, we propose a novel single-instance TTA method tailored for edge
devices (TED), which employs forward-only coordinate optimization in the
principal subspace of latent using the covariance matrix adaptation evolution
strategy (CMA-ES). By updating a compact low-dimensional vector, TED not only
enhances output confidence but also aligns the latent representation closer to
the source latent distribution within the latent principal subspace. This is
achieved without backpropagation, keeping the model parameters frozen, and
enabling efficient, forgetting-free adaptation with minimal memory and
computational overhead. Experiments on image classification and keyword
spotting tasks across the ImageNet and Google Speech Commands series datasets
demonstrate that TED achieves state-of-the-art performance while
$\textit{reducing computational complexity by up to 63 times}$, offering a
practical and scalable solution for real-world edge applications. Furthermore,
we successfully $\textit{deployed TED on the ZYNQ-7020 platform}$,
demonstrating its feasibility and effectiveness for resource-constrained edge
devices in real-world deployments.

</details>


### [815] [Causal Disentanglement Learning for Accurate Anomaly Detection in Multivariate Time Series](https://arxiv.org/abs/2510.11084)
*Wonah Kim,Jeonghyeon Park,Dongsan Jun,Jungkyu Han,Sejin Chun*

Main category: cs.LG

TL;DR: CDRL4AD通过构建时间异构图并推断时间段内的因果关系，在多变量时间序列异常检测方面表现优于现有方法，并能进行根源分析。


<details>
  <summary>Details</summary>
Motivation: 复杂因果关系的分离对于准确的异常检测至关重要。然而，多变量时间序列中数据变量随时间变化的动态交互作用，使得因果关系的解释复杂化。现有方法要么假设变量间的统计独立性，要么仅捕捉特征相关性，但未能明确推断不同时间段的因果关系。

Method: 提出因果解纠缠表示学习（CDRL4AD）模型，该模型将因果过程设计为模型输入（时间异构图和因果关系），识别不同时间段的因果关系，并解纠缠潜在变量以推断相应的因果因素。

Result: 在真实数据集上的实验表明，CDRL4AD在准确性和根源分析方面优于最先进的方法。模型分析验证了其超参数敏感性和时间复杂度。最后，通过案例研究展示了该方法如何帮助人类专家诊断异常的根本原因。

Conclusion: CDRL4AD在多变量时间序列异常检测和因果关系识别方面取得了显著成效，并且在真实世界数据集上的表现优于现有方法。

Abstract: Disentangling complex causal relationships is important for accurate
detection of anomalies. In multivariate time series analysis, dynamic
interactions among data variables over time complicate the interpretation of
causal relationships. Traditional approaches assume statistical independence
between variables in unsupervised settings, whereas recent methods capture
feature correlations through graph representation learning. However, their
representations fail to explicitly infer the causal relationships over
different time periods. To solve the problem, we propose Causally Disentangled
Representation Learning for Anomaly Detection (CDRL4AD) to detect anomalies and
identify their causal relationships in multivariate time series. First, we
design the causal process as model input, the temporal heterogeneous graph, and
causal relationships. Second, our representation identifies causal
relationships over different time periods and disentangles latent variables to
infer the corresponding causal factors. Third, our experiments on real-world
datasets demonstrate that CDRL4AD outperforms state-of-the-art methods in terms
of accuracy and root cause analysis. Fourth, our model analysis validates
hyperparameter sensitivity and the time complexity of CDRL4AD. Last, we conduct
a case study to show how our approach assists human experts in diagnosing the
root causes of anomalies.

</details>


### [816] [PhysioME: A Robust Multimodal Self-Supervised Framework for Physiological Signals with Missing Modalities](https://arxiv.org/abs/2510.11110)
*Cheol-Hui Lee,Hwa-Yeon Lee,Min-Kyung Jung,Dong-Joo Kim*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Missing or corrupted modalities are common in physiological signal-based
medical applications owing to hardware constraints or motion artifacts.
However, most existing methods assume the availability of all modalities,
resulting in substantial performance degradation in the absence of any
modality. To overcome this limitation, this study proposes PhysioME, a robust
framework designed to ensure reliable performance under missing modality
conditions. PhysioME adopts: (1) a multimodal self-supervised learning approach
that combines contrastive learning with masked prediction; (2) a
Dual-PathNeuroNet backbone tailored to capture the temporal dynamics of each
physiological signal modality; and (3) a restoration decoder that reconstructs
missing modality tokens, enabling flexible processing of incomplete inputs. The
experimental results show that PhysioME achieves high consistency and
generalization performance across various missing modality scenarios. These
findings highlight the potential of PhysioME as a reliable tool for supporting
clinical decision-making in real-world settings with imperfect data
availability.

</details>


### [817] [ELMO: Efficiency via Low-precision and Peak Memory Optimization in Large Output Spaces](https://arxiv.org/abs/2510.11168)
*Jinbin Zhang,Nasib Ullah,Erik Schultheis,Rohit Babbar*

Main category: cs.LG

TL;DR: ELMO是一个纯低精度训练框架，使用BFloat16和Float8数据类型，用于极端多标签分类（XMC）模型。它通过Kahan求和、随机舍入、梯度融合和分块等技术，在不损害准确性的前提下，显著减少了GPU内存使用量，并提高了训练效率。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的XMC方法主要依赖混合精度训练（FP16-FP32），但这种方法可能不稳定，并且在内存使用和计算开销方面效率低下。现有的低精度方法通常在分类层保留较高精度，但ELMO旨在提供一个完全低精度的解决方案。

Method: ELMO框架完全使用BFloat16和Float8数据类型进行训练。它采用了Kahan求和（Kahan summation）和随机舍入（stochastic rounding）技术，使得XMC模型能够完全在Float8中进行有效训练，而无需单精度主权重或张量缩放。此外，ELMO还结合了梯度融合（gradient fusion）和分块（chunking）的内存优化技术。

Result: ELMO框架在训练一个包含300万个标签的XMC模型时，仅使用了6.6 GiB的GPU内存，而经过优化的最先进方法Renee需要39.7 GiB内存。在实现显著内存节省的同时，ELMO没有降低模型的准确性。

Conclusion: ELMO是一个有效的纯低精度训练框架，能够显著降低XMC模型的GPU内存需求，并提高了训练效率，同时保持了模型的准确性。这使得在有限的硬件资源下训练大规模XMC模型成为可能。

Abstract: Large output spaces, also referred to as Extreme multilabel classification
(XMC), is a setting that arises, e.g., in large-scale tagging and
product-to-product recommendation, and is characterized by the number of labels
ranging from hundreds of thousands to millions. This means that the linear
classification head, usually only a tiny fraction of the overall model, turns
into the main driver for compute and memory demand. Current state-of-the-art
XMC methods predominantly rely on FP16-FP32 mixed-precision training, which we
show can be unstable, and inefficient in terms of memory usage and
computational overhead. Meanwhile, existing low-precision methods typically
retain higher precision for the classification layer. In this work, we propose
ELMO, a pure low-precision training framework for XMC models using BFloat16 and
Float8 data types. By leveraging Kahan summation and stochastic rounding, we
demonstrate that XMC models can be effectively trained entirely in Float8,
without relying on single-precision master weights or tensor scaling.
Low-precision training, combined with our proposed memory optimizations --
gradient fusion and chunking -- enables significant reductions in GPU memory
usage. For example, we train a 3-million-label XMC model with only 6.6 GiB of
GPU memory, compared to the 39.7 GiB required by the optimized SOTA method,
Renee without compromising accuracy.

</details>


### [818] [Refining Hybrid Genetic Search for CVRP via Reinforcement Learning-Finetuned LLM](https://arxiv.org/abs/2510.11121)
*Rongjie Zhu,Cong Zhang,Zhiguang Cao*

Main category: cs.LG

TL;DR: 小型语言模型经过微调后，在车辆路径问题（VRP）的交叉算子生成方面优于大型模型和专家设计。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖大型通用语言模型设计车辆路径问题的启发式方法，本文旨在证明小型、经过精心微调的语言模型可以生成超越专家设计的组件。

Method: 提出一种名为RFTHGS的新型强化学习框架，用于微调小型语言模型以生成混合遗传搜索（HGS）求解器的交叉算子，并应用于容量车辆路径问题（CVRP）。该方法采用多层、基于课程的学习的奖励函数，并结合了操作符缓存机制。

Result: RFTHGS生成的交叉算子显著优于HGS中的专家设计的算子，并且在从小型到大型问题（高达1000个节点）上表现一致。其性能优于领先的神经组合基线、基于提示的方法以及GPT-4o和GPT-4o-mini等商业语言模型。

Conclusion: 经过微调的小型语言模型在生成高性能的VRP交叉算子方面具有巨大潜力，能够超越当前最先进的方法，包括大型语言模型和专家设计的启发式方法。

Abstract: While large language models (LLMs) are increasingly used as automated
heuristic designers for vehicle routing problems (VRPs), current
state-of-the-art methods predominantly rely on prompting massive,
general-purpose models like GPT-4. This work challenges that paradigm by
demonstrating that a smaller, specialized LLM, when meticulously fine-tuned,
can generate components that surpass expert-crafted heuristics within advanced
solvers. We propose RFTHGS, a novel Reinforcement learning (RL) framework for
Fine-Tuning a small LLM to generate high-performance crossover operators for
the Hybrid Genetic Search (HGS) solver, applied to the Capacitated VRP (CVRP).
Our method employs a multi-tiered, curriculum-based reward function that
progressively guides the LLM to master generating first compilable, then
executable, and finally, superior-performing operators that exceed human expert
designs. This is coupled with an operator caching mechanism that discourages
plagiarism and promotes diversity during training. Comprehensive experiments
show that our fine-tuned LLM produces crossover operators which significantly
outperform the expert-designed ones in HGS. The performance advantage remains
consistent, generalizing from small-scale instances to large-scale problems
with up to 1000 nodes. Furthermore, RFTHGS exceeds the performance of leading
neuro-combinatorial baselines, prompt-based methods, and commercial LLMs such
as GPT-4o and GPT-4o-mini.

</details>


### [819] [EAGER: Entropy-Aware GEneRation for Adaptive Inference-Time Scaling](https://arxiv.org/abs/2510.11170)
*Daniel Scalena,Leonidas Zotos,Elisabetta Fersini,Malvina Nissim,Ahmet Üstün*

Main category: cs.LG

TL;DR: EAGer是一种训练方法，通过利用模型不确定性来减少冗余计算并提高性能，在复杂推理基准上实现了最佳效率-性能权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的推理语言模型和测试时扩展方法虽然可以提高模型性能，但通常需要大量的计算来为同一个提示生成多个候选序列，并且将相同的计算预算分配给每个提示，而忽略了不同提示的复杂度和计算需求可能不同。

Method: EAGer是一种训练方法，它利用模型不确定性通过令牌级熵分布来减少冗余计算。当存在高熵令牌时，EAGer才允许分支到多个推理路径，然后将节省的计算预算重新分配给最需要探索替代路径的实例。

Result: 在多个开源模型和AIME 2025等复杂推理基准上，EAGer可以在不访问目标标签的情况下重新分配预算，在推理长度和Pass@k方面实现了最佳的效率-性能权衡。当目标标签可用时，EAGer生成的令牌数量减少了65%，Pass@k提高了37%。

Conclusion: EAGer通过利用模型不确定性来减少冗余计算并提高性能，在复杂推理基准上实现了最佳的效率-性能权衡。

Abstract: With the rise of reasoning language models and test-time scaling methods as a
paradigm for improving model performance, substantial computation is often
required to generate multiple candidate sequences from the same prompt. This
enables exploration of different reasoning paths toward the correct solution,
however, allocates the same compute budget for each prompt. Grounded on the
assumption that different prompts carry different degrees of complexity, and
thus different computation needs, we propose EAGer, a training-free generation
method that leverages model uncertainty through token-wise entropy distribution
to reduce redundant computation and concurrently improve overall performance.
EAGer allows branching to multiple reasoning paths only in the presence of
high-entropy tokens, and then reallocates the saved compute budget to the
instances where exploration of alternative paths is most needed. We find that
across multiple open-source models on complex reasoning benchmarks such as AIME
2025, EAGer can reallocate the budget without accessing target labels,
achieving the best efficiency-performance trade-off in terms of reasoning
length and Pass@k. When target labels are accessible, EAGer generates up to 65%
fewer tokens (hence saving compute) and achieves up to 37% improvement in
Pass@k compared to the Full Parallel Sampling.

</details>


### [820] [Lightweight Facial Landmark Detection in Thermal Images via Multi-Level Cross-Modal Knowledge Transfer](https://arxiv.org/abs/2510.11128)
*Qiyi Tong,Olivia Nocentini,Marta Lagomarsino,Kuanqi Cai,Marta Lorenzini,Arash Ajoudani*

Main category: cs.LG

TL;DR: 提出一种名为多层次跨模态知识蒸馏（MLCM-KD）的新框架，用于解决热成像人脸关键点检测（FLD）的挑战，该框架通过双向注入知识蒸馏（DIKD）机制，实现高效且准确的热成像FLD模型。


<details>
  <summary>Details</summary>
Motivation: 热成像人脸关键点检测（FLD）在光照条件差的情况下很重要，但缺乏丰富的视觉线索。传统的跨模态解决方案计算成本高或产生伪影。

Method: 提出MLCM-KD框架，包含DIKD机制，该机制双向引导热成像学生模型，并反馈验证其学习到的表示，以实现跨模态的语义一致性。

Result: 在公开热成像FLD基准测试中，该方法达到了新的最先进水平，性能优于先前方法，并显著降低了计算开销。

Conclusion: MLCM-KD框架通过DIKD实现了高效准确的热成像FLD模型，克服了跨模态知识迁移的挑战。

Abstract: Facial Landmark Detection (FLD) in thermal imagery is critical for
applications in challenging lighting conditions, but it is hampered by the lack
of rich visual cues. Conventional cross-modal solutions, like feature fusion or
image translation from RGB data, are often computationally expensive or
introduce structural artifacts, limiting their practical deployment. To address
this, we propose Multi-Level Cross-Modal Knowledge Distillation (MLCM-KD), a
novel framework that decouples high-fidelity RGB-to-thermal knowledge transfer
from model compression to create both accurate and efficient thermal FLD
models. A central challenge during knowledge transfer is the profound modality
gap between RGB and thermal data, where traditional unidirectional distillation
fails to enforce semantic consistency across disparate feature spaces. To
overcome this, we introduce Dual-Injected Knowledge Distillation (DIKD), a
bidirectional mechanism designed specifically for this task. DIKD establishes a
connection between modalities: it not only guides the thermal student with rich
RGB features but also validates the student's learned representations by
feeding them back into the frozen teacher's prediction head. This closed-loop
supervision forces the student to learn modality-invariant features that are
semantically aligned with the teacher, ensuring a robust and profound knowledge
transfer. Experiments show that our approach sets a new state-of-the-art on
public thermal FLD benchmarks, notably outperforming previous methods while
drastically reducing computational overhead.

</details>


### [821] [Can Tool-Integrated Reinforcement Learning Generalize Across Diverse Domains?](https://arxiv.org/abs/2510.11184)
*Zhengyu Chen,Jinluan Yang,Teng Xiao,Ruochen Zhou,Luan Zhang,Xiangyu Xi,Xiaowei Shi,Wei Wang,Jinggang Wang*

Main category: cs.LG

TL;DR: LLM工具强化学习在数学领域训练后，可跨域泛化至复杂任务，TGRL框架通过标准化接口、双组分奖励和XML提示模板促进泛化。


<details>
  <summary>Details</summary>
Motivation: 现有LLM工具强化学习的跨域泛化能力研究不足。

Method: 提出TGRL框架，包含标准化工具接口、双组分奖励系统和XML提示模板，以促进LLM的跨域学习和技能迁移。

Result: 在多个不同推理领域进行评估，RL工具使用可有效迁移到其他领域的复杂任务，实现优异的任务性能和高代币效率。

Conclusion: TGRL框架验证了其在各种基准测试中的有效性，实现了最先进的性能，并突出了工具强化学习在LLM推理中的跨域潜力。

Abstract: Recent advances in large language models (LLMs) have demonstrated remarkable
capabilities in reasoning and tool utilization. However, the generalization of
tool-augmented reinforcement learning (RL) across diverse domains remains
underexplored. In this work, we investigate the cross-domain generalization of
an LLM agent equipped with a code interpreter tool, which is exclusively
trained on mathematical problem-solving tasks. Despite the restricted training
domain, we evaluate the agent's performance across several distinct reasoning
domains. The results reveal that RL-based tool usage learned from mathematical
tasks can be effectively transferred to complex tasks in other domains,
enabling great task performance and high token efficiency. To facilitate this
cross-domain transfer, we propose a Tool Generalization Reinforcement Learning
(TGRL) framework designed to promote domain-agnostic learning and skill
migration, encompassing: (i) a standardized tool interface that abstracts
domain-specific nuances through consistent formatting and explicit termination,
fostering transferable invocation patterns; (ii) a dual-component reward system
that decomposes rewards to incentivize generalizable behaviors like tool
efficiency and reasoning abstraction, ensuring alignment and robustness across
domain shifts; and (iii) an XML-based prompt template that separates thinking,
tool calls, and responses to encourage modular, domain-invariant planning and
coherent multi-turn interactions. Extensive experiments across diverse
benchmarks validate our approach, achieving state-of-the-art performance and
highlighting the cross-domain potential of Tool RL for LLM reasoning.

</details>


### [822] [Test-Time Adaptation by Causal Trimming](https://arxiv.org/abs/2510.11133)
*Yingnan Liu,Rui Qiao,Mong Li Lee,Wynne Hsu*

Main category: cs.LG

TL;DR: TACT是一种测试时自适应方法，通过识别并移除表示中的非因果成分来提高模型在分布变化下的鲁棒性，在基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在分布变化下，模型性能下降的主要原因是模型依赖于与预测目标没有直接因果关系的特征。测试时自适应旨在通过使用未标记的目标样本来调整模型，以提高模型在分布变化下的鲁棒性。

Method: TACT通过应用保留因果特征而改变非因果特征的数据增强。利用主成分分析分析表示的变化，TACT识别出与非因果特征相关联的最高方差方向。它通过移除表示在已识别方向上的投影来修剪表示，并使用修剪后的表示进行预测。在自适应过程中，TACT持续跟踪并优化这些方向，以获得对非因果特征的更好估计。

Result: TACT在现实世界的分布外基准测试中进行了实证验证，并持续以显著优势优于最先进的方法。

Conclusion: TACT通过识别并移除表示中的非因果成分，提高了模型在分布变化下的鲁棒性，并在各种基准测试中取得了优于现有方法的成果。

Abstract: Test-time adaptation aims to improve model robustness under distribution
shifts by adapting models with access to unlabeled target samples. A primary
cause of performance degradation under such shifts is the model's reliance on
features that lack a direct causal relationship with the prediction target. We
introduce Test-time Adaptation by Causal Trimming (TACT), a method that
identifies and removes non-causal components from representations for test
distributions. TACT applies data augmentations that preserve causal features
while varying non-causal ones. By analyzing the changes in the representations
using Principal Component Analysis, TACT identifies the highest variance
directions associated with non-causal features. It trims the representations by
removing their projections on the identified directions, and uses the trimmed
representations for the predictions. During adaptation, TACT continuously
tracks and refines these directions to get a better estimate of non-causal
features. We theoretically analyze the effectiveness of this approach and
empirically validate TACT on real-world out-of-distribution benchmarks. TACT
consistently outperforms state-of-the-art methods by a significant margin.

</details>


### [823] [ENIGMA: The Geometry of Reasoning and Alignment in Large-Language Models](https://arxiv.org/abs/2510.11278)
*Gareth Seneque,Lap-Hang Ho,Nafise Erfanian Saeedi,Jeffrey Molendijk,Ariel Kupermann,Tim Elson*

Main category: cs.LG

TL;DR: ENIGMA通过将组织策略视为信息流形上的方向，联合改进LLM的推理、对齐和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM的推理、对齐和鲁棒性可以通过信息几何学进行联合改进，将组织策略视为信息流形上的方向。

Method: ENIGMA结合了GRPO、SAMI风格的InfoNCE以及Sinkhorn最优传输正则化器。引入了信息量度指标，如充分性指数(SI)，用于在训练前选择和创建原则。

Result: 在1B LLM的实验中，高SI原则预测了比GRPO消融更稳定的训练动态和更高的基准性能。信息几何分析验证了流形中期望的结构变化。

Conclusion: 推理、对齐和鲁棒性是单一信息几何目标的投影，ENIGMA训练的模型在不使用奖励模型的情况下展现了原则性推理，为可信能力提供了途径。

Abstract: We present Entropic Mutual-Information Geometry Large-Language Model
Alignment (ENIGMA), a novel approach to Large-Language Model (LLM) training
that jointly improves reasoning, alignment and robustness by treating an
organisation's policies/principles as directions to move on a model's
information manifold. Our single-loop trainer combines Group-Relative Policy
Optimisation (GRPO), an on-policy, critic-free RL method with Chain-of-Thought
(CoT)-format only rewards; a Self-Supervised Alignment with Mutual Information
(SAMI)-style symmetric InfoNCE auxiliary; and an entropic Sinkhorn
optimal-transport regulariser on hidden-state distributions to bound geometry
drift. We also introduce infoNCE metrics that specialise to a standard MI lower
bound under matched negatives to measure how strongly a model's CoT encodes
these policies. These metrics include a Sufficiency Index (SI) that enables the
selection and creation of principles that maximise downstream performance prior
to training. In our experiments using small (1B) LLMs, high-SI principles
predict steadier training dynamics and improved benchmark performance over GRPO
ablations. Our information-geometry analysis of trained models validates
desirable structural change in the manifold. These results support our
hypothesis that reasoning, alignment, and robustness are projections of a
single informationgeometric objective, and that models trained using ENIGMA
demonstrate principled reasoning without the use of a reward model, offering a
path to trusted capability

</details>


### [824] [DUAL: Learning Diverse Kernels for Aggregated Two-sample and Independence Testing](https://arxiv.org/abs/2510.11140)
*Zhijian Zhou,Xunye Tian,Liuhua Peng,Chao Lei,Antonin Schrab,Danica J. Sutherland,Feng Liu*

Main category: cs.LG

TL;DR: 通过最大化多核统计量来提高核测试的功效，但可能会导致相似的核捕获重叠信息。本文提出了一种基于核协方差来明确纳入核多样性的聚合统计量。此外，本文还提出了一种测试框架，通过选择性推理来解决核多样性和单个核测试功效之间的权衡问题，从而从学习到的多样化核库中选择具有强大个体性能的核。理论分析和广泛的实验表明，该方法在两样本和独立性测试方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高核两样本和独立性检验在复杂结构数据上的功效，通常采用多核聚合。然而，直接最大化多核统计量可能导致高度相似的核捕获重叠信息，从而限制了聚合的有效性。

Method: 提出了一种聚合统计量，通过核之间的协方差明确地纳入了核多样性。此外，还提出了一种具有选择性推理的测试框架，利用训练阶段的信息从学习到的多样化核池中选择具有强大个体性能的核。

Result: 该方法在两样本和独立性测试方面均表现出优越的性能，并在各种基准测试中得到了验证。

Conclusion: 所提出的聚合统计量和选择性推理框架能够有效解决多核聚合中的核信息重叠问题，并在保持测试功效和控制I类错误率方面取得了良好的效果。

Abstract: To adapt kernel two-sample and independence testing to complex structured
data, aggregation of multiple kernels is frequently employed to boost testing
power compared to single-kernel tests. However, we observe a phenomenon that
directly maximizing multiple kernel-based statistics may result in highly
similar kernels that capture highly overlapping information, limiting the
effectiveness of aggregation. To address this, we propose an aggregated
statistic that explicitly incorporates kernel diversity based on the covariance
between different kernels. Moreover, we identify a fundamental challenge: a
trade-off between the diversity among kernels and the test power of individual
kernels, i.e., the selected kernels should be both effective and diverse. This
motivates a testing framework with selection inference, which leverages
information from the training phase to select kernels with strong individual
performance from the learned diverse kernel pool. We provide rigorous
theoretical statements and proofs to show the consistency on the test power and
control of Type-I error, along with asymptotic analysis of the proposed
statistics. Lastly, we conducted extensive empirical experiments demonstrating
the superior performance of our proposed approach across various benchmarks for
both two-sample and independence testing.

</details>


### [825] [A Comprehensive Forecasting-Based Framework for Time Series Anomaly Detection: Benchmarking on the Numenta Anomaly Benchmark (NAB)](https://arxiv.org/abs/2510.11141)
*Mohammad Karami,Mostafa Jalali,Fatemeh Ghassemi*

Main category: cs.LG

TL;DR: 现有时间序列异常检测方法缺乏系统的跨领域评估，本文提出了一个基于预测的统一框架，整合了经典方法和深度学习模型，并在Numenta Anomaly Benchmark上进行了全面评估。LSTM表现最佳，Informer在效率上具有优势，经典方法在简单合成数据上表现良好但实际应用中效果较差。研究强调了预测质量对异常检测性能的决定性影响，并为未来研究提供了基于实证的指导和基线。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测方法缺乏系统的跨领域评估，需要一个统一的框架来评估不同模型在不同数据集上的表现。

Method: 提出一个集成了预处理、四种预测模型（Holt-Winters, SARIMA, LSTM, Informer）和四种检测方法的预测型框架，并在Numenta Anomaly Benchmark（58个数据集）上进行了232次模型训练和464次检测评估。

Result: LSTM在异常检测任务中表现最佳（F1: 0.688），Informer训练速度快30%，经典方法在合成数据上效果好但实际数据上F1分数低2-3倍。预测模型的性能比检测方法对最终结果的影响更大。

Conclusion: LSTM适用于复杂模式，Informer适用于效率要求高的场景，经典方法适用于资源受限的简单周期性数据。该框架为未来基于预测的异常检测研究提供了基线和指导。

Abstract: Time series anomaly detection is critical for modern digital infrastructures,
yet existing methods lack systematic cross-domain evaluation. We present a
comprehensive forecasting-based framework unifying classical methods
(Holt-Winters, SARIMA) with deep learning architectures (LSTM, Informer) under
a common residual-based detection interface. Our modular pipeline integrates
preprocessing (normalization, STL decomposition), four forecasting models, four
detection methods, and dual evaluation through forecasting metrics (MAE, RMSE,
PCC) and detection metrics (Precision, Recall, F1, AUC). We conduct the first
complete evaluation on the Numenta Anomaly Benchmark (58 datasets, 7
categories) with 232 model training runs and 464 detection evaluations
achieving 100\% success rate. LSTM achieves best performance (F1: 0.688,
ranking first or second on 81\% of datasets) with exceptional correlation on
complex patterns (PCC: 0.999). Informer provides competitive accuracy (F1:
0.683) with 30\% faster training. Classical methods achieve perfect predictions
on simple synthetic data with 60 lower cost but show 2-3 worse F1-scores on
real-world datasets. Forecasting quality dominates detection performance:
differences between detection methods (F1: 0.621-0.688) are smaller than
between forecasting models (F1: 0.344-0.688). Our findings provide
evidence-based guidance: use LSTM for complex patterns, Informer for
efficiency-critical deployments, and classical methods for simple periodic data
with resource constraints. The complete implementation and results establish
baselines for future forecasting-based anomaly detection research.

</details>


### [826] [ReLook: Vision-Grounded RL with a Multimodal LLM Critic for Agentic Web Coding](https://arxiv.org/abs/2510.11498)
*Yuhang Li,Chenchen Zhang,Ruilin Lv,Ao Liu,Ken Deng,Yuanxing Zhang,Jiaheng Liu,Wiggin Zhou,Bo Zhou*

Main category: cs.LG

TL;DR: ReLook是一个基于视觉的多模态LLM框架，用于改进前端代码生成，通过生成-诊断-精炼的循环，实现像素级和交互式正确性，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: LLMs在代码生成方面表现出色，但在前端开发方面存在不足，因为前端开发的正确性需要通过渲染的像素和交互来判断。

Method: ReLook使用一个多模态LLM（MLLM）作为工具，通过视觉反馈进行评分，并提供基于视觉的反馈。在训练过程中，它引入了严格的零奖励规则来确保可渲染性，并采用“强制优化”策略来防止行为崩溃，只接受改进的修订。在推理过程中，它将评估器与生成器分离，以保持较低的延迟。

Result: ReLook在三个广泛使用的基准测试中，在基于视觉的前端代码生成方面持续优于强大的基线模型。

Conclusion: ReLook通过结合基于视觉的奖励、智能体感知和训练-推理分离，显著提升了前端代码生成的质量和效率。

Abstract: While Large Language Models (LLMs) excel at algorithmic code generation, they
struggle with front-end development, where correctness is judged on rendered
pixels and interaction. We present ReLook, an agentic, vision-grounded
reinforcement learning framework that empowers an agent to close a robust
generate--diagnose--refine loop by invoking a multimodal LLM (MLLM) as a tool.
During training, the agent uses the MLLM-in-the-loop both as a visual
critic--scoring code with screenshots--and as a source of actionable,
vision-grounded feedback; a strict zero-reward rule for invalid renders anchors
renderability and prevents reward hacking. To prevent behavioral collapse, we
introduce Forced Optimization, a strict acceptance rule that admits only
improving revisions, yielding monotonically better trajectories. At inference,
we decouple the critic and run a lightweight, critic-free self-edit cycle,
keeping latency comparable to base decoding while retaining most of the gains.
Across three widely used benchmarks, ReLook consistently outperforms strong
baselines in vision-grounded front-end code generation, highlighting the
benefits of agentic perception, visual rewards, and training-inference
decoupling.

</details>


### [827] [Beyond single-model XAI: aggregating multi-model explanations for enhanced trustworthiness](https://arxiv.org/abs/2510.11164)
*Ilaria Vascotto,Alex Rodriguez,Alessandro Bonaita,Luca Bortolussi*

Main category: cs.LG

TL;DR: XAI领域通过提供可解释性来解决AI的信任和伦理问题，但解释的鲁棒性常被忽视。本文提出一种基于集成多模型（kNN、随机森林、神经网络）的特征重要性聚合方法来提高解释的鲁棒性，以增强AI应用的信任度。


<details>
  <summary>Details</summary>
Motivation: AI在现实和高风险应用中的使用引发了对其可信度和伦理使用的担忧。XAI领域旨在通过解释复杂模型的决策过程来解决这些问题，但解释的鲁棒性是提升整体系统信任度的关键，却常被忽视。

Method: 本文研究了通过集成来自多个模型（kNN、随机森林和神经网络）的特征重要性来提高解释鲁棒性的作用。

Result: 初步结果表明，该方法在提高应用的可信度方面具有潜力，同时利用了多个模型的预测能力。

Conclusion: 通过集成多模型特征重要性聚合的方法，可以提高AI模型的可解释性鲁棒性，进而增强AI应用的信任度。

Abstract: The use of Artificial Intelligence (AI) models in real-world and high-risk
applications has intensified the discussion about their trustworthiness and
ethical usage, from both a technical and a legislative perspective. The field
of eXplainable Artificial Intelligence (XAI) addresses this challenge by
proposing explanations that bring to light the decision-making processes of
complex black-box models. Despite being an essential property, the robustness
of explanations is often an overlooked aspect during development: only robust
explanation methods can increase the trust in the system as a whole. This paper
investigates the role of robustness through the usage of a feature importance
aggregation derived from multiple models ($k$-nearest neighbours, random forest
and neural networks). Preliminary results showcase the potential in increasing
the trustworthiness of the application, while leveraging multiple model's
predictive power.

</details>


### [828] [Boundary-Guided Policy Optimization for Memory-efficient RL of Diffusion Large Language Models](https://arxiv.org/abs/2510.11683)
*Nianyi Lin,Jiajie Zhang,Lei Hou,Juanzi Li*

Main category: cs.LG

TL;DR: 基于边界引导策略优化（BGPO）的RL算法，通过构建ELBO下界，解决LLM训练中的内存瓶颈，提高性能。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在dLLM训练中，因似然函数难以处理，需要蒙特卡洛采样近似，但需要保留计算图导致内存开销大，限制了样本数量，影响了近似精度和RL目标。BGPO旨在克服这一内存限制。

Method: 提出边界引导策略优化（BGPO）算法，构建ELBO下界，该下界满足线性（仅依赖单一样本，内存恒定）和等价（价值和梯度与ELBO目标相同）两个关键属性，从而允许更大的蒙特卡洛样本量，实现更精确的似然近似和RL目标估计。

Result: BGPO在数学问题解决、代码生成和规划任务中显著优于之前的dLLM RL算法。

Conclusion: BGPO是一种内存高效的RL算法，通过构建特殊的ELBO下界，解决了dLLM训练中的内存瓶颈，实现了更准确的近似和更好的性能。

Abstract: A key challenge in applying reinforcement learning (RL) to diffusion large
language models (dLLMs) lies in the intractability of their likelihood
functions, which are essential for the RL objective, necessitating
corresponding approximation in each training step. While existing methods
approximate the log-likelihoods by their evidence lower bounds (ELBOs) via
customized Monte Carlo (MC) sampling, the forward computational graphs of all
MC samples need to be retained for the gradient computation of non-linear terms
in the RL objective, resulting in significant memory overhead. This constraint
restricts feasible sample sizes, leading to imprecise likelihood approximations
and ultimately distorting the RL objective. To overcome this limitation, we
propose \emph{Boundary-Guided Policy Optimization} (BGPO), a memory-efficient
RL algorithm that maximizes a specially constructed lower bound of the
ELBO-based objective. This lower bound is carefully designed to satisfy two key
properties: (1) Linearity: it is formulated in a linear sum where each term
depends only on a single MC sample, thereby enabling gradient accumulation
across samples and ensuring constant memory usage; (2) Equivalence: Both the
value and gradient of this lower bound are equal to those of the ELBO-based
objective in on-policy training, making it also an effective approximation for
the original RL objective. These properties allow BGPO to adopt a large MC
sample size, resulting in more accurate likelihood approximations and improved
RL objective estimation, which in turn leads to enhanced performance.
Experiments show that BGPO significantly outperforms previous RL algorithms for
dLLMs in math problem solving, code generation, and planning tasks.

</details>


### [829] [QeRL: Beyond Efficiency -- Quantization-enhanced Reinforcement Learning for LLMs](https://arxiv.org/abs/2510.11696)
*Wei Huang,Yi Ge,Shuai Yang,Yicheng Xiao,Huizi Mao,Yujun Lin,Hanrong Ye,Sifei Liu,Ka Chun Cheung,Hongxu Yin,Yao Lu,Xiaojuan Qi,Song Han,Yukang Chen*

Main category: cs.LG

TL;DR: QeRL是一个量化增强的强化学习框架，用于LLM，通过结合NVFP4量化和LoRA来提高效率和探索能力，可在单个GPU上训练大型LLM，并在数学基准测试中达到与全参数微调相当的性能。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）对LLM的推理能力至关重要，但资源消耗大（GPU内存和训练时长）。

Method: 提出QeRL框架，结合NVFP4量化和LoRA，加速RL的rollout阶段并降低内存开销。引入自适应量化噪声（AQN）机制来增强探索。

Result: QeRL在rollout阶段提速超过1.5倍，首次实现在单块H100 80GB GPU上训练32B LLM，并整体加速RL训练。与16位LoRA和QLoRA相比，QeRL实现了更快的奖励增长和更高的最终准确性，并在GSM8K（90.8%）和MATH 500（77.4%）等数学基准测试中，7B模型的性能与全参数微调相当。

Conclusion: QeRL是一个高效且有效的LLM强化学习训练框架。

Abstract: We propose QeRL, a Quantization-enhanced Reinforcement Learning framework for
large language models (LLMs). While RL is essential for LLMs' reasoning
capabilities, it is resource-intensive, requiring substantial GPU memory and
long rollout durations. QeRL addresses these issues by combining NVFP4
quantization with Low-Rank Adaptation (LoRA), accelerating rollout phase of RL
while reducing memory overhead. Beyond efficiency, our findings show that
quantization noise increases policy entropy, enhancing exploration, and
enabling the discovery of better strategies during RL. To further optimize
exploration, QeRL introduces an Adaptive Quantization Noise (AQN) mechanism,
which dynamically adjusts noise during training. Experiments demonstrate that
QeRL delivers over 1.5 times speedup in the rollout phase. Moreover, this is
the first framework to enable RL training of a 32B LLM on a single H100 80GB
GPU, while delivering overall speedups for RL training. It also achieves faster
reward growth and higher final accuracy than 16-bit LoRA and QLoRA, while
matching the performance of full-parameter fine-tuning on mathematical
benchmarks such as GSM8K (90.8%) and MATH 500 (77.4%) in the 7B model. These
results establish QeRL as an efficient and effective framework for RL training
in LLMs.

</details>


### [830] [Protein as a Second Language for LLMs](https://arxiv.org/abs/2510.11188)
*Xinhui Chen,Zuchao Li,Mengqi Gao,Yufeng Zhang,Chak Tou Leong,Haoyang Li,Jiaqi Chen*

Main category: cs.LG

TL;DR: 蛋白质序列可以通过将氨基酸序列视为一种新的符号语言，并利用大型语言模型（LLMs）进行理解，从而在零样本设置下揭示其功能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在解读蛋白质序列功能时，通常依赖于特定任务的适配器或大规模监督微调，而我们旨在开发一种无需额外训练即可理解蛋白质序列功能的方法。

Method: 我们提出了"蛋白质作为第二语言"（Protein-as-Second-Language）框架，将氨基酸序列重新构建为一种新的符号语言，并利用大型语言模型（LLMs）通过上下文示例进行解读。该框架自适应地构建序列-问题-答案三元组，在零样本设置下揭示功能线索。

Result: 通过包含79,926个蛋白质问答实例的双语语料库进行支持，我们的方法在各种开源LLMs和GPT-4上持续提升性能，ROUGE-L分数最高提高了17.2%（平均提高7%），并且超越了经过微调的蛋白质领域专用语言模型。

Conclusion: 通用LLMs在“蛋白质作为第二语言”的引导下，能够超越领域专用模型，为基础模型提供可扩展的蛋白质理解途径。

Abstract: Deciphering the function of unseen protein sequences is a fundamental
challenge with broad scientific impact, yet most existing methods depend on
task-specific adapters or large-scale supervised fine-tuning. We introduce the
"Protein-as-Second-Language" framework, which reformulates amino-acid sequences
as sentences in a novel symbolic language that large language models can
interpret through contextual exemplars. Our approach adaptively constructs
sequence-question-answer triples that reveal functional cues in a zero-shot
setting, without any further training. To support this process, we curate a
bilingual corpus of 79,926 protein-QA instances spanning attribute prediction,
descriptive understanding, and extended reasoning. Empirically, our method
delivers consistent gains across diverse open-source LLMs and GPT-4, achieving
up to 17.2% ROUGE-L improvement (average +7%) and even surpassing fine-tuned
protein-specific language models. These results highlight that generic LLMs,
when guided with protein-as-language cues, can outperform domain-specialized
models, offering a scalable pathway for protein understanding in foundation
models.

</details>


### [831] [Evaluating Line-level Localization Ability of Learning-based Code Vulnerability Detection Models](https://arxiv.org/abs/2510.11202)
*Marco Pintore,Giorgio Piras,Angelo Sotgiu,Maura Pintor,Battista Biggio*

Main category: cs.LG

TL;DR: ML模型在软件漏洞检测中存在定位不精确、易受偏见影响的问题，本文提出了一种基于可解释性的检测对齐（DA）方法来评估和量化模型预测与真实漏洞位置的一致性，并通过实验证明了现有模型受非漏洞代码行偏见的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习漏洞检测模型只能标记整个代码函数为易受攻击，无法精确到具体代码行，这给开发人员调试、评估和修复漏洞带来了困难。现有方法在提高定位能力的同时，忽视了数据中的虚假关联和偏见问题。

Method: 提出了一种名为检测对齐（DA）的可解释性评估方法，该方法通过量化输入源代码行对预测的影响程度与真实漏洞位置（ground truth）之间的一致性来评估模型的定位能力。DA方法模型无关且可适用于不同的检测任务。

Result: 通过DA方法分析了多个基于学习的漏洞检测器和数据集，结果表明这些模型的预测结果受到非漏洞代码行的持续偏见影响，突显了偏见和虚假关联的高影响力。

Conclusion: 机器学习漏洞检测模型在进行漏洞定位时，其预测结果受到数据偏见和虚假关联的严重影响，现有模型的定位能力并不完全可靠，需要更关注模型的可解释性和鲁棒性。

Abstract: To address the extremely concerning problem of software vulnerability, system
security is often entrusted to Machine Learning (ML) algorithms. Despite their
now established detection capabilities, such models are limited by design to
flagging the entire input source code function as vulnerable, rather than
precisely localizing the concerned code lines. However, the detection
granularity is crucial to support human operators during software development,
ensuring that such predictions reflect the true code semantics to help debug,
evaluate, and fix the detected vulnerabilities. To address this issue, recent
work made progress toward improving the detector's localization ability, thus
narrowing down the vulnerability detection "window" and providing more
fine-grained predictions. Such approaches, however, implicitly disregard the
presence of spurious correlations and biases in the data, which often
predominantly influence the performance of ML algorithms. In this work, we
investigate how detectors comply with this requirement by proposing an
explainability-based evaluation procedure. Our approach, defined as Detection
Alignment (DA), quantifies the agreement between the input source code lines
that most influence the prediction and the actual localization of the
vulnerability as per the ground truth. Through DA, which is model-agnostic and
adaptable to different detection tasks, not limited to our use case, we analyze
multiple learning-based vulnerability detectors and datasets. As a result, we
show how the predictions of such models are consistently biased by
non-vulnerable lines, ultimately highlighting the high impact of biases and
spurious correlations. The code is available at
https://github.com/pralab/vuln-localization-eval.

</details>


### [832] [Cross-Scale Reservoir Computing for large spatio-temporal forecasting and modeling](https://arxiv.org/abs/2510.11209)
*Nicola Alboré,Gabriele Di Antonio,Fabrizio Coccetti,Andrea Gabrielli*

Main category: cs.LG

TL;DR: 提出一种新的用于预测高分辨率时空数据集的储层计算方法，通过结合多分辨率输入，该模型能更好地捕捉局部和全局动力学，在海表温度预测上优于标准模型，并揭示了网络动力学特性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预测高分辨率时空数据集时存在捕捉局部和全局动力学的挑战。

Method: 提出一种结合多分辨率输入（从粗到细）的新型储层计算方法，实现跨层耦合。

Result: 在海表温度数据集上，该方法在长期预测方面优于标准的并行储层模型，提高了预测准确性。

Conclusion: 跨层耦合能有效提高预测精度，并且各层网络动力学趋于线性，揭示了传播到后续层的慢模态。

Abstract: We propose a new reservoir computing method for forecasting high-resolution
spatiotemporal datasets. By combining multi-resolution inputs from coarser to
finer layers, our architecture better captures both local and global dynamics.
Applied to Sea Surface Temperature data, it outperforms standard parallel
reservoir models in long-term forecasting, demonstrating the effectiveness of
cross-layers coupling in improving predictive accuracy. Finally, we show that
the optimal network dynamics in each layer become increasingly linear,
revealing the slow modes propagated to subsequent layers.

</details>


### [833] [Enforcing convex constraints in Graph Neural Networks](https://arxiv.org/abs/2510.11227)
*Ahmed Rashwan,Keith Briggs,Chris Budd,Lisa Kreusser*

Main category: cs.LG

TL;DR: ProjNet是一个图神经网络框架，通过结合稀疏向量裁剪和CAD算法来满足输入相关的约束，并提供可微的代理梯度以实现端到端训练，在多种约束优化问题上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器学习应用需要满足复杂、动态约束，特别是在图神经网络模型中，由于图结构数据的可变输出尺寸，这一任务更具挑战性。

Method: ProjNet结合了稀疏向量裁剪方法和组件平均Dykstra (CAD) 算法，这是一种求解最优逼近问题的迭代方案。

Result: ProjNet在四类约束优化问题（线性规划、两类非凸二次规划和无线电发射功率优化）上进行了验证，展示了其在不同问题设置下的有效性。

Conclusion: ProjNet是一个满足输入相关约束的图神经网络框架，通过CAD算法和代理梯度实现了高效的端到端训练，并在多种约束优化问题上取得了成功。

Abstract: Many machine learning applications require outputs that satisfy complex,
dynamic constraints. This task is particularly challenging in Graph Neural
Network models due to the variable output sizes of graph-structured data. In
this paper, we introduce ProjNet, a Graph Neural Network framework which
satisfies input-dependant constraints. ProjNet combines a sparse vector
clipping method with the Component-Averaged Dykstra (CAD) algorithm, an
iterative scheme for solving the best-approximation problem. We establish a
convergence result for CAD and develop a GPU-accelerated implementation capable
of handling large-scale inputs efficiently. To enable end-to-end training, we
introduce a surrogate gradient for CAD that is both computationally efficient
and better suited for optimization than the exact gradient. We validate ProjNet
on four classes of constrained optimisation problems: linear programming, two
classes of non-convex quadratic programs, and radio transmit power
optimization, demonstrating its effectiveness across diverse problem settings.

</details>


### [834] [Neural Weight Compression for Language Models](https://arxiv.org/abs/2510.11234)
*Jegwang Ryu,Minkyu Kim,Seungjun Shin,Hee Min Choi,Dokwan Oh,Jaeho Lee*

Main category: cs.LG

TL;DR: 神经加权压缩（NWC）是一种新颖的自动编码器神经编解码器，专门用于压缩语言模型权重，通过分块、归一化、重要性感知损失和基于模型输出的误差补偿来提高压缩效率，在4-6位精度下可与FP16模型媲美。


<details>
  <summary>Details</summary>
Motivation: 语言模型权重的存储和传输日益重要，但缺乏有效的压缩算法，现有方法依赖手动试错。

Method: 提出了一种名为神经加权压缩（NWC）的自动编码器神经编解码器，包括（1）列式张量分块和归一化；（2）重要性感知训练损失；（3）由模型输导的推理时误差补偿机制。

Result: 在开放权重语言模型上的实验表明，NWC在精度-压缩率权衡方面具有竞争力或达到最先进水平，在4-6位精度下几乎与FP16模型相当。

Conclusion: NWC是一种有效的神经编解码器，能够应对语言模型权重压缩的独特挑战，并在低比特精度下保持高准确性。

Abstract: The efficient storage and transmission of language model weights is becoming
increasingly important, as their scale and adoption continue to grow. However,
as our understanding of this new data modality is limited, designing a good
compression algorithm for language model weights heavily relies on manual,
trial-and-error approaches. In this paper, we propose a learned compression
framework that trains neural codecs directly from pretrained language model
weights. Unlike conventional data (e.g., images), language model weights pose
unique challenges: the sizes and shapes of weight tensors vary significantly,
and the reconstruction quality must be judged by downstream model predictions
rather than na\"ive MSE loss. To address this, we introduce Neural Weight
Compression (NWC), a novel autoencoder-based neural codec tailored to model
weight compression. The proposed method inherits the advantages of
autoencoder-based codecs while incorporating three technical components: (1)
column-wise tensor chunking and normalization; (2) an importance-aware training
loss; (3) an inference-time error compensation mechanism guided by model
outputs. Experiments on open-weight language models show that NWC achieves
competitive or state-of-the-art accuracy-compression tradeoffs, with
particularly strong results at 4-6 bit precisions where accuracy remains nearly
on par with FP16 models.

</details>


### [835] [FUSE: Fast Semi-Supervised Node Embedding Learning via Structural and Label-Aware Optimization](https://arxiv.org/abs/2510.11250)
*Sujan Chakraborty,Rahul Bordoloi,Anindya Sengupta,Olaf Wolkenhauer,Saptarshi Bej*

Main category: cs.LG

TL;DR: 通过联合优化无监督结构保持、有监督正则化和半监督标签传播，提出了一种快速的半监督图嵌入框架，在准确性和计算成本方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在许多真实世界图中，节点缺乏信息特征，主要依靠邻域连接和类别标签进行分类，因此需要学习能够捕捉结构角色和拓扑信息的节点嵌入。

Method: 提出了一种联合优化三种互补目标的快速半监督嵌入框架：(i) 通过可扩展的模块度近似进行无监督结构保持，(ii) 通过最小化标记节点内的方差进行有监督正则化，(iii) 通过具有注意力加权相似度的随机游走标签传播进行半监督传播。将这些组件统一在一个迭代优化方案中。

Result: 该框架在标准基准测试中，分类准确率与最先进的方法相当或更优，同时计算成本显著降低。

Conclusion: 所提出的框架能够生成高质量的节点嵌入，并在效率和准确性方面都表现出色。

Abstract: Graph-based learning is a cornerstone for analyzing structured data, with
node classification as a central task. However, in many real-world graphs,
nodes lack informative feature vectors, leaving only neighborhood connectivity
and class labels as available signals. In such cases, effective classification
hinges on learning node embeddings that capture structural roles and
topological context. We introduce a fast semi-supervised embedding framework
that jointly optimizes three complementary objectives: (i) unsupervised
structure preservation via scalable modularity approximation, (ii) supervised
regularization to minimize intra-class variance among labeled nodes, and (iii)
semi-supervised propagation that refines unlabeled nodes through
random-walk-based label spreading with attention-weighted similarity. These
components are unified into a single iterative optimization scheme, yielding
high-quality node embeddings. On standard benchmarks, our method consistently
achieves classification accuracy at par with or superior to state-of-the-art
approaches, while requiring significantly less computational cost.

</details>


### [836] [MIEO: encoding clinical data to enhance cardiovascular event prediction](https://arxiv.org/abs/2510.11257)
*Davide Borghini,Davide Marchi,Angelo Nardone,Giordano Scerra,Silvia Giulia Galfrè,Alessandro Pingitore,Giuseppe Prencipe,Corrado Priami,Alina Sîrbu*

Main category: cs.LG

TL;DR: 使用自监督自动编码器处理临床数据中的标签稀疏性和数据异质性问题，以预测心血管死亡率，并取得了比直接使用原始数据更好的效果。


<details>
  <summary>Details</summary>
Motivation: 临床数据可用性增加，但面临标签数据稀疏和数据异质性（导致缺失值）的挑战。

Method: 提出使用自监督自动编码器，首先用未标记数据构建潜在空间嵌入，然后用该嵌入训练神经网络分类器来预测心血管死亡率。

Result: 与直接在原始数据上应用分类器相比，自监督自动编码器方法提高了平衡准确率。

Conclusion: 自监督自动编码器是一种有前景的解决方案，特别是在未标记数据可用性可能增加的条件下。

Abstract: As clinical data are becoming increasingly available, machine learning
methods have been employed to extract knowledge from them and predict clinical
events. While promising, approaches suffer from at least two main issues: low
availability of labelled data and data heterogeneity leading to missing values.
This work proposes the use of self-supervised auto-encoders to efficiently
address these challenges. We apply our methodology to a clinical dataset from
patients with ischaemic heart disease. Patient data is embedded in a latent
space, built using unlabelled data, which is then used to train a neural
network classifier to predict cardiovascular death. Results show improved
balanced accuracy compared to applying the classifier directly to the raw data,
demonstrating that this solution is promising, especially in conditions where
availability of unlabelled data could increase.

</details>


### [837] [FedLoRA-Optimizer: Federated LoRA Fine-Tuning with Global and Local Optimization in Heterogeneous Data Scenarios](https://arxiv.org/abs/2510.11274)
*Jianzhe Zhao,Hailin Zhu,Yu Zhang,Ziqi Chen,Guibing Guo*

Main category: cs.LG

TL;DR: 提出一种细粒度联邦LoRA调优方法，通过区分A、B矩阵中向量的敏感度，分别优化共享知识和个性化知识，以提升全局泛化和本地化适应性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦LoRA方法在异构数据场景下存在全局模型泛化能力弱和本地模型个性化需求难满足的问题，且忽略了对调优矩阵的细粒度分析。

Method: 区分LoRA的A、B矩阵中向量的敏感度，优先调整更敏感的A矩阵方向向量以优化共享知识，调整更敏感的B矩阵幅度向量以优化个性化知识。结合全局和本地优化器进行协同优化。

Result: 实验证明，所提方法在Databricks-Dolly-15k和Natural Instructions数据集上，相对于现有方法，全局性能提升0.39%，本地性能提升0.59%。

Conclusion: 所提出的细粒度联邦LoRA调优方法能够有效提升全局模型的泛化能力和本地模型的个性化适应能力，解决了异构数据场景下的挑战。

Abstract: Federated efficient fine-tuning has emerged as an approach that leverages
distributed data and computational resources across nodes to address the
challenges of large-scale fine-tuning and privacy preservation. The Low-Rank
Adaptation (LoRA) enables efficient fine-tuning of large-scale pre-trained
models by introducing trainable low-rank matrices into weight updates.However,
in heterogeneous data scenarios, client drift weakens the generalization of the
global model, and local models often fail to meet the personalized needs of
individual clients.Moreover, existing federated LoRA efficient fine-tuning
techniques overlook fine-grained analysis of the tuning matrices. To address
this, we conducted preliminary experiments and found that different LoRA
matrices exhibit different sensitivity to changes in the direction and
magnitude of their vectors.We thus propose a fine-grained federated LoRA tuning
method. By fine-tuning the more sensitive directional vectors in the A matrix,
which encode shared knowledge, our method learns shared features more
effectively across clients and enhances global generalization. Simultaneously,
by fine-tuning the more sensitive magnitude vectors in the B matrix, which
encode personalized knowledge, our method better captures personalized
knowledge, enabling detailed adaptation to local data. The method uses a
pipeline combining global and local optimizers. Global optimization further
improves local models, achieving collaborative optimization between global and
local levels. This improves both the generalization ability of the global model
and the personalized adaptation of local models under heterogeneous data
scenarios. Experiments on Databricks-Dolly-15k and Natural Instructions with
LLaMA2-7B and Deepseek-7B confirm that our method improves global performance
by 0.39% and local performance by 0.59%.

</details>


### [838] [Vision-LLMs for Spatiotemporal Traffic Forecasting](https://arxiv.org/abs/2510.11282)
*Ning Yang,Hengyu Zhong,Haijun Zhang,Randall Berry*

Main category: cs.LG

TL;DR: ST-Vision-LLM 通过将时空预测重构为视觉-语言融合问题，利用视觉编码器处理历史流量矩阵作为图像序列，并采用特殊的数值编码方案和两阶段微调（SFT+GRPO）来克服 LLM 在处理空间依赖性和数值效率方面的挑战，在真实移动流量数据集上取得了显著的预测精度提升，尤其是在长期预测和少样本跨域场景下。


<details>
  <summary>Details</summary>
Motivation: 解决在大城市移动网络中，准确进行时空交通预测以支持主动资源管理的需求，同时克服现有大语言模型（LLM）在处理密集网格交通数据的复杂空间依赖性和效率方面的局限性。

Method: 将时空预测视为视觉-语言融合问题。使用 Vision-LLM 视觉编码器将历史全局交通矩阵作为图像序列进行处理，通过特殊词汇表将浮点数值编码为单个 token，并采用监督微调（SFT）和群组相对策略优化（GRPO）两阶段微调。

Result: 在真实移动交通数据集上，ST-Vision-LLM 在长期预测精度上比现有方法提高了 15.6%，在跨域少样本场景下超过第二名基线 30.04%，并验证了模型在数据稀疏环境下的泛化能力。

Conclusion: ST-Vision-LLM 框架能够有效地处理时空交通预测任务，克服了大语言模型在空间依赖性和数值效率方面的挑战，并在多种场景下取得了优于现有方法的性能。

Abstract: Accurate spatiotemporal traffic forecasting is a critical prerequisite for
proactive resource management in dense urban mobile networks. While Large
Language Models (LLMs) have shown promise in time series analysis, they
inherently struggle to model the complex spatial dependencies of grid-based
traffic data. Effectively extending LLMs to this domain is challenging, as
representing the vast amount of information from dense geographical grids can
be inefficient and overwhelm the model's context. To address these challenges,
we propose ST-Vision-LLM, a novel framework that reframes spatiotemporal
forecasting as a vision-language fusion problem. Our approach leverages a
Vision-LLM visual encoder to process historical global traffic matrices as
image sequences, providing the model with a comprehensive global view to inform
cell-level predictions. To overcome the inefficiency of LLMs in handling
numerical data, we introduce an efficient encoding scheme that represents
floating-point values as single tokens via a specialized vocabulary, coupled
with a two-stage numerical alignment fine-tuning process. The model is first
trained with Supervised Fine-Tuning (SFT) and then further optimized for
predictive accuracy using Group Relative Policy Optimization (GRPO), a
memory-efficient reinforcement learning method. Evaluations on real-world
mobile traffic datasets demonstrate that ST-Vision-LLM outperforms existing
methods by 15.6% in long-term prediction accuracy and exceeds the second-best
baseline by over 30.04% in cross-domain few-shot scenarios. Our extensive
experiments validate the model's strong generalization capabilities across
various data-scarce environments.

</details>


### [839] [Gym-TORAX: Open-source software for integrating RL with plasma control simulators](https://arxiv.org/abs/2510.11283)
*Antoine Mouchamps,Arthur Malherbe,Adrien Bolland,Damien Ernst*

Main category: cs.LG

TL;DR: Gym-TORAX是一个Python包，可以为等离子体动力学和控制模拟创建强化学习环境，并提供一个基于ITER的启动场景环境。


<details>
  <summary>Details</summary>
Motivation: 为了促进等离子体控制的强化学习研究，需要一个能够模拟等离子体动力学和控制的强化学习环境。

Method: Gym-TORAX允许用户定义控制动作、观测值和控制目标，然后自动创建一个包装了TORAX的Gymnasium环境，该环境通过奖励函数来优化等离子体的性能和稳定性。

Result: 创建了一个可以与各种强化学习算法和库兼容的Gymnasium环境，并且提供了一个基于ITER启动场景的可用环境。

Conclusion: Gym-TORAX通过提供一个简化的接口来创建等离子体模拟的强化学习环境，从而促进了等离子体控制的强化学习研究。

Abstract: This paper presents Gym-TORAX, a Python package enabling the implementation
of Reinforcement Learning (RL) environments for simulating plasma dynamics and
control in tokamaks. Users define succinctly a set of control actions and
observations, and a control objective from which Gym-TORAX creates a Gymnasium
environment that wraps TORAX for simulating the plasma dynamics. The objective
is formulated through rewards depending on the simulated state of the plasma
and control action to optimize specific characteristics of the plasma, such as
performance and stability. The resulting environment instance is then
compatible with a wide range of RL algorithms and libraries and will facilitate
RL research in plasma control. In its current version, one environment is
readily available, based on a ramp-up scenario of the International
Thermonuclear Experimental Reactor (ITER).

</details>


### [840] [LouisKV: Efficient KV Cache Retrieval for Long Input-Output Sequences](https://arxiv.org/abs/2510.11292)
*Wenbo Wu,Qingyi Si,Xiurui Pan,Ye Wang,Jie Zhang*

Main category: cs.LG

TL;DR: LouisKV通过利用KV缓存的时间局部性和不同分布模式，引入了一种语义感知检索策略和细粒度管理方案，并在内核级别进行了优化，从而在不损失精度的情况下显著提高了长序列任务的KV缓存效率。


<details>
  <summary>Details</summary>
Motivation: 现有的KV缓存方法在减少自动回归模型冗余计算的同时，会带来显著的内存开销，限制了其在长序列场景下的实际应用。现有的KV检索方法虽然缓解了这个问题，但由于逐个标记检索和粗粒度的页面级KV管理，在长输出推理场景下仍然存在效率和准确性瓶颈。随着大型推理模型的出现，有效处理这些场景变得越来越重要。

Method: LouisKV提出了一种利用时间局部性的语义感知检索策略，仅在语义边界触发检索，从而大大降低了计算和数据传输开销。同时，它还设计了一个解耦的、细粒度的管理方案，为输入和输出序列定制了差异化的策略，创建了更匹配模型注意力模式的检索单元，从而能够精确识别关键KV。此外，为了提高效率，LouisKV还包含了若干内核级别的优化，包括使用定制的Triton和CUDA内核来加速KV聚类和检索。

Result: 评估结果表明，LouisKV在各种长序列任务（包括长输入短输出、短输入长输出和长输入长输出场景）上，在保持接近无损的准确性的同时，与最先进的KV检索方法相比，速度最高可提升4.7倍。

Conclusion: LouisKV通过利用KV缓存的时间局部性和不同分布模式，引入了一种语义感知检索策略和细粒度管理方案，并在内核级别进行了优化，从而在不损失精度的情况下显著提高了长序列任务的KV缓存效率。

Abstract: While Key-Value (KV) cache succeeds in reducing redundant computations in
auto-regressive models, it introduces significant memory overhead, limiting its
practical deployment in long-sequence scenarios. Existing KV retrieval methods
mitigate this by dynamically retaining only a subset of KV entries on the GPU.
However, they still suffer from notable efficiency and accuracy bottlenecks due
to per-token retrieval and coarse-grained page-level KV management, especially
in long-output reasoning scenarios. With the emergence of large reasoning
models, efficiently handling such scenarios has become increasingly important.
To address this issue, we present two key observations: (1) critical KVs
exhibit strong temporal locality during decoding, and (2) these KVs exhibit
distinct distribution patterns across the input prompt and generated output.
Building on these observations, we propose LouisKV, an efficient KV cache
retrieval framework designed for various long-sequence scenarios. Specifically,
LouisKV introduces a semantic-aware retrieval strategy leveraging temporal
locality to trigger retrieval only at semantic boundaries, drastically reducing
computation and data transfer overhead. LouisKV also designs a decoupled,
fine-grained management scheme that tailors differentiated strategies for input
and output sequences to create retrieval units that better match the model's
attention patterns, enabling precise identification of critical KVs.
Furthermore, to boost efficiency, LouisKV incorporates several kernel-level
optimizations, including custom Triton and CUDA kernels to accelerate the KV
clustering and retrieval. Evaluations show that LouisKV achieves up to
4.7$\times$ speedup over state-of-the-art KV retrieval methods while
maintaining near-lossless accuracy across diverse long-sequence tasks,
including long-input short-output, short-input long-output, and long-input
long-output scenarios.

</details>


### [841] [DiffStyleTS: Diffusion Model for Style Transfer in Time Series](https://arxiv.org/abs/2510.11335)
*Mayank Nagda,Phil Ostheimer,Justus Arweiler,Indra Jungjohann,Jennifer Werner,Dennis Wagner,Aparna Muraleedharan,Pouya Jafari,Jochen Schmid,Fabian Jirasek,Jakob Burger,Michael Bortz,Hans Hasse,Stephan Mandt,Marius Kloft,Sophie Fellenz*

Main category: cs.LG

TL;DR: DiffTSST是一个基于扩散的方法，用于时间序列数据的风格迁移，通过解耦内容和风格，并利用其改进了数据稀疏领域中的异常检测。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据的风格迁移方法有限，而该技术在数据增强和场景模拟等应用中具有重要作用，有助于提高机器学习模型在数据稀疏域的泛化能力。

Method: DiffTSST采用基于扩散的框架，利用卷积编码器将时间序列分解为内容和风格表示，并通过基于自监督注意力的扩散过程重新组合。在推理时，编码器从两个不同的序列中提取内容和风格，从而能够有条件地生成新的样本以实现风格迁移。

Result: 实验结果表明，DiffTSST在风格迁移方面有效，并在数据稀疏条件下通过数据增强提高了异常检测的性能。

Conclusion: DiffTSST在时间序列风格迁移方面取得了成功，并证明了其在实际应用中的效用，尤其是在数据稀疏场景下的异常检测任务中。

Abstract: Style transfer combines the content of one signal with the style of another.
It supports applications such as data augmentation and scenario simulation,
helping machine learning models generalize in data-scarce domains. While well
developed in vision and language, style transfer methods for time series data
remain limited. We introduce DiffTSST, a diffusion-based framework that
disentangles a time series into content and style representations via
convolutional encoders and recombines them through a self-supervised
attention-based diffusion process. At inference, encoders extract content and
style from two distinct series, enabling conditional generation of novel
samples to achieve style transfer. We demonstrate both qualitatively and
quantitatively that DiffTSST achieves effective style transfer. We further
validate its real-world utility by showing that data augmentation with DiffTSST
improves anomaly detection in data-scarce regimes.

</details>


### [842] [Event-Aware Prompt Learning for Dynamic Graphs](https://arxiv.org/abs/2510.11339)
*Xingtong Yu,Ruijuan Liang,Xinming Zhang,Yuan Fang*

Main category: cs.LG

TL;DR: EVP是一个事件感知的动态图提示学习框架，可以作为插件增强现有DGNNs处理历史事件的能力。


<details>
  <summary>Details</summary>
Motivation: 现有动态图学习方法（DGNNs）主要关注节点和时间的关系，忽略了历史事件的影响。

Method: 1. 提取节点历史事件并引入事件适应机制以匹配下游任务。2. 提出事件聚合机制以整合历史知识到节点表示中。

Result: 在四个公开数据集上进行了广泛的实验评估。

Conclusion: EVP框架能够有效利用历史事件知识，增强动态图学习能力。

Abstract: Real-world graph typically evolve via a series of events, modeling dynamic
interactions between objects across various domains. For dynamic graph
learning, dynamic graph neural networks (DGNNs) have emerged as popular
solutions. Recently, prompt learning methods have been explored on dynamic
graphs. However, existing methods generally focus on capturing the relationship
between nodes and time, while overlooking the impact of historical events. In
this paper, we propose EVP, an event-aware dynamic graph prompt learning
framework that can serve as a plug-in to existing methods, enhancing their
ability to leverage historical events knowledge. First, we extract a series of
historical events for each node and introduce an event adaptation mechanism to
align the fine-grained characteristics of these events with downstream tasks.
Second, we propose an event aggregation mechanism to effectively integrate
historical knowledge into node representations. Finally, we conduct extensive
experiments on four public datasets to evaluate and analyze EVP.

</details>


### [843] [Part II: ROLL Flash -- Accelerating RLVR and Agentic Training with Asynchrony](https://arxiv.org/abs/2510.11345)
*Han Lu,Zichen Liu,Shaopan Xiong,Yancheng He,Wei Gao,Yanan Wu,Weixun Wang,Jiashun Liu,Yang Li,Haizhou Zhao,Ju Huang,Siran Yang,Xiaoyang Li,Yijia Luo,Zihe Liu,Ling Pan,Junchi Yan,Wei Wang,Wenbo Su,Jiamang Wang,Lin Qu,Bo Zheng*

Main category: cs.LG

TL;DR: ROLL Flash通过引入细粒度并行和 rollout-训练解耦，实现了异步强化学习（RL）后训练，提高了资源利用率和可扩展性，并在RLVR和agentic任务上实现了显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）后训练系统在资源利用率和可扩展性方面存在不足，需要更高效的解决方案来增强大型语言模型（LLMs）的功能。

Method: ROLL Flash通过细粒度并行和rollout-训练解耦设计，实现了全异步训练架构，并支持队列调度和环境级异步执行等高效的rollout机制。

Result: 与同步RL后训练相比，ROLL Flash显著提高了资源利用率和可扩展性，在RLVR任务上实现了高达2.24倍的加速，在agentic任务上实现了高达2.72倍的加速，且在多种离线策略算法上实现了与同步训练相当的性能。

Conclusion: ROLL Flash通过异步强化学习后训练，有效解决了现有系统在资源利用率和可扩展性方面的挑战，为增强大型语言模型的功能提供了更优越的解决方案。

Abstract: Synchronous Reinforcement Learning (RL) post-training has emerged as a
crucial step for enhancing Large Language Models (LLMs) with diverse
capabilities. However, many systems designed to accelerate RL post-training
still suffer from low resource utilization and limited scalability. We present
ROLL Flash, a system that extends ROLL with native support for asynchronous RL
post-training. ROLL Flash is built upon two core design principles:
fine-grained parallelism and rollout-train decoupling. Guided by these
principles, ROLL Flash provides flexible programming interfaces that enable a
fully asynchronous training architecture and support efficient rollout
mechanisms, including queue scheduling and environment-level asynchronous
execution. Through comprehensive theoretical analysis and extensive
experiments, we demonstrate that ROLL Flash significantly improves resource
utilization and scalability over synchronous RL post-training. ROLL Flash
achieves up to 2.24x speedup on RLVR tasks and 2.72x on agentic tasks, using
the same GPU budget as synchronous baselines. Furthermore, we implement several
popular off-policy algorithms and verify that asynchronous training can achieve
performance on par with synchronous training.

</details>


### [844] [Multi-View Graph Feature Propagation for Privacy Preservation and Feature Sparsity](https://arxiv.org/abs/2510.11347)
*Etzion Harari,Moshe Unger*

Main category: cs.LG

TL;DR: GNN在节点分类任务中表现优异，但依赖完整节点特征。本文提出多视图特征传播（MFP）框架，通过生成多个高斯噪声视图并独立传播信息，增强了在特征稀疏性下的节点分类能力，并提高了隐私保护。MFP的创新之处在于提高了极端稀疏性下的鲁棒性，并能在效用和隐私之间取得平衡。实验证明MFP在节点分类任务上优于现有方法，同时显著减少了隐私泄露。


<details>
  <summary>Details</summary>
Motivation: 许多实际场景中，节点特征矩阵高度稀疏或包含敏感信息，导致GNN性能下降并带来隐私风险。直接暴露信息可能导致数据泄露，使对手能够推断敏感信息。

Method: 提出了一种新颖的多视图特征传播（MFP）框架，该框架将可用特征划分为多个高斯噪声视图，每个视图独立地通过图拓扑传播信息。聚合的表示产生了富有表现力和鲁棒性的节点嵌入。

Result: MFP在节点分类任务上的表现优于最先进的基线方法，同时显著降低了隐私泄露。MFP的传播输出可作为替代性数据填充，而非原始特征的重建，从而在不损害隐私的情况下保持了效用。

Conclusion: MFP为特征缺失或敏感的图学习领域提供了一个有效且注重隐私的框架。它通过提高极端稀疏性下的鲁棒性，并提供一种在效用与隐私之间取得平衡的原则性方法，克服了现有方法的局限性。

Abstract: Graph Neural Networks (GNNs) have demonstrated remarkable success in node
classification tasks over relational data, yet their effectiveness often
depends on the availability of complete node features. In many real-world
scenarios, however, feature matrices are highly sparse or contain sensitive
information, leading to degraded performance and increased privacy risks.
Furthermore, direct exposure of information can result in unintended data
leakage, enabling adversaries to infer sensitive information. To address these
challenges, we propose a novel Multi-view Feature Propagation (MFP) framework
that enhances node classification under feature sparsity while promoting
privacy preservation. MFP extends traditional Feature Propagation (FP) by
dividing the available features into multiple Gaussian-noised views, each
propagating information independently through the graph topology. The
aggregated representations yield expressive and robust node embeddings. This
framework is novel in two respects: it introduces a mechanism that improves
robustness under extreme sparsity, and it provides a principled way to balance
utility with privacy. Extensive experiments conducted on graph datasets
demonstrate that MFP outperforms state-of-the-art baselines in node
classification while substantially reducing privacy leakage. Moreover, our
analysis demonstrates that propagated outputs serve as alternative imputations
rather than reconstructions of the original features, preserving utility
without compromising privacy. A comprehensive sensitivity analysis further
confirms the stability and practical applicability of MFP across diverse
scenarios. Overall, MFP provides an effective and privacy-aware framework for
graph learning in domains characterized by missing or sensitive features.

</details>


### [845] [Understanding the Generalization of Stochastic Gradient Adam in Learning Neural Networks](https://arxiv.org/abs/2510.11354)
*Xuan Tang,Han Zhang,Yuan Cao,Difan Zou*

Main category: cs.LG

TL;DR: 随机Adam的收敛性与批量大小和权重衰减有关。


<details>
  <summary>Details</summary>
Motivation: 现有理论主要分析全批量Adam，与实践中的随机变体不同。

Method: 分析了在图像数据上训练的二维过参数化CNN中批量大小如何影响Adam的泛化。

Result: 在适当的权重衰减下，Adam和AdamW都收敛到测试误差较差的解，但它们的mini-batch变体几乎可以达到零测试误差。Adam的有效权重衰减界严格小于AdamW。

Conclusion: 批量大小和权重衰减在Adam的泛化性能中起着关键作用。

Abstract: Adam is a popular and widely used adaptive gradient method in deep learning,
which has also received tremendous focus in theoretical research. However, most
existing theoretical work primarily analyzes its full-batch version, which
differs fundamentally from the stochastic variant used in practice. Unlike SGD,
stochastic Adam does not converge to its full-batch counterpart even with
infinitesimal learning rates. We present the first theoretical characterization
of how batch size affects Adam's generalization, analyzing two-layer
over-parameterized CNNs on image data. Our results reveal that while both Adam
and AdamW with proper weight decay $\lambda$ converge to poor test error
solutions, their mini-batch variants can achieve near-zero test error. We
further prove Adam has a strictly smaller effective weight decay bound than
AdamW, theoretically explaining why Adam requires more sensitive $\lambda$
tuning. Extensive experiments validate our findings, demonstrating the critical
role of batch size and weight decay in Adam's generalization performance.

</details>


### [846] [Medical Interpretability and Knowledge Maps of Large Language Models](https://arxiv.org/abs/2510.11390)
*Razvan Marinescu,Victoria-Elisabeth Gruber,Diego Fajardo*

Main category: cs.LG

TL;DR: 本研究系统研究了大型语言模型（LLMs）在医学领域的表征和处理知识的能力，使用UMAP、梯度、层移除和激活打补丁等方法，绘制了五种LLM的知识图谱，并分析了Llama3.3-70B中医学知识（年龄、症状、疾病、药物）的存储位置和处理方式，发现在模型前半部分层中处理了大部分医学知识，并观察到年龄编码非线性、疾病进展表示非单调、药物按专科而非作用机制聚类，以及Gemma3-27B和MedGemma-27B的激活在中间层坍塌后恢复等现象。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在系统地研究大型语言模型（LLMs）在医学领域的知识表征和处理方式，为未来在医学任务中进行模型微调、移除或消除偏见等操作提供指导。

Method: 研究采用了四种不同的可解释性技术：(1) UMAP投影中间激活，(2) 基于梯度的权重显著性分析，(3) 层病变/移除，(4) 激活打补丁，以研究LLMs如何表征和处理医学知识。绘制了五种LLM的知识图谱，并重点分析了Llama3.3-70B模型的具体现象。

Result: 研究发现，在Llama3.3-70B模型中，大部分医学知识（关于患者年龄、医疗症状、疾病和药物）存储在模型层的前半部分。此外，还观察到年龄编码非线性、疾病进展表示非单调且呈循环状、药物按医学专科而非作用机制聚类，以及Gemma3-27B和MedGemma-27B模型在中间层激活坍塌后又恢复的现象。

Conclusion: 本研究的发现为未来在医学任务中进行LLMs的微调、移除或消除偏见等操作提供了指导，指明了在模型中应用这些技术应关注的层级。

Abstract: We present a systematic study of medical-domain interpretability in Large
Language Models (LLMs). We study how the LLMs both represent and process
medical knowledge through four different interpretability techniques: (1) UMAP
projections of intermediate activations, (2) gradient-based saliency with
respect to the model weights, (3) layer lesioning/removal and (4) activation
patching. We present knowledge maps of five LLMs which show, at a
coarse-resolution, where knowledge about patient's ages, medical symptoms,
diseases and drugs is stored in the models. In particular for Llama3.3-70B, we
find that most medical knowledge is processed in the first half of the model's
layers. In addition, we find several interesting phenomena: (i) age is often
encoded in a non-linear and sometimes discontinuous manner at intermediate
layers in the models, (ii) the disease progression representation is
non-monotonic and circular at certain layers of the model, (iii) in
Llama3.3-70B, drugs cluster better by medical specialty rather than mechanism
of action, especially for Llama3.3-70B and (iv) Gemma3-27B and MedGemma-27B
have activations that collapse at intermediate layers but recover by the final
layers. These results can guide future research on fine-tuning, un-learning or
de-biasing LLMs for medical tasks by suggesting at which layers in the model
these techniques should be applied.

</details>


### [847] [FedHybrid: Breaking the Memory Wall of Federated Learning via Hybrid Tensor Management](https://arxiv.org/abs/2510.11400)
*Kahou Tam,Chunlin Tian,Li Li,Haikai Zhao,ChengZhong Xu*

Main category: cs.LG

TL;DR: FedHybrid通过联合评估设备内存、计算能力和数据多样性来选择参与设备，并采用重计算和压缩技术为每个客户端生成执行计划，以满足内存限制并最小化训练延迟，从而有效减少内存占用并保证模型准确性。


<details>
  <summary>Details</summary>
Motivation: 移动设备内存限制是联邦学习部署的主要挑战。

Method: FedHybrid框架通过联合评估设备资源和数据多样性来选择参与设备，并利用重计算和压缩技术为每个客户端生成执行计划，以在满足内存限制的同时最小化训练延迟。

Result: FedHybrid在模型准确性方面提高了39.1%，在实际执行时间方面减少了15.5倍。

Conclusion: FedHybrid是一种创新的联邦学习框架，能够有效解决移动设备的内存限制问题，并在保证模型准确性和训练进度的同时实现显著的内存和时间效率提升。

Abstract: Federated Learning (FL) emerges as a new learning paradigm that enables
multiple devices to collaboratively train a shared model while preserving data
privacy. However, one fundamental and prevailing challenge that hinders the
deployment of FL on mobile devices is the memory limitation. This paper
proposes \textit{FedHybrid}, a novel framework that effectively reduces the
memory footprint during the training process while guaranteeing the model
accuracy and the overall training progress. Specifically, \textit{FedHybrid}
first selects the participating devices for each training round by jointly
evaluating their memory budget, computing capability, and data diversity. After
that, it judiciously analyzes the computational graph and generates an
execution plan for each selected client in order to meet the corresponding
memory budget while minimizing the training delay through employing a hybrid of
recomputation and compression techniques according to the characteristic of
each tensor. During the local training process, \textit{FedHybrid} carries out
the execution plan with a well-designed activation compression technique to
effectively achieve memory reduction with minimum accuracy loss. We conduct
extensive experiments to evaluate \textit{FedHybrid} on both simulation and
off-the-shelf mobile devices. The experiment results demonstrate that
\textit{FedHybrid} achieves up to a 39.1\% increase in model accuracy and a
15.5$\times$ reduction in wall clock time under various memory budgets compared
with the baselines.

</details>


### [848] [Leveraging LLMs for Semi-Automatic Corpus Filtration in Systematic Literature Reviews](https://arxiv.org/abs/2510.11409)
*Lucas Joos,Daniel A. Keim,Maximilian T. Fischer*

Main category: cs.LG

TL;DR: 该研究提出了一种利用大型语言模型（LLMs）流水线来辅助系统性文献综述（SLR）的自动化方法，旨在减少人工筛选文献的时间和成本，并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的系统性文献综述（SLR）在文献检索和筛选方面耗时耗力，并且手动操作容易出错，因此需要一种更有效的方法来处理大量的文献。

Method: 研究人员提出了一种结合多种大型语言模型（LLMs）的流水线方法，通过描述性提示对论文进行分类，并采用共识机制进行联合决策。整个过程由人工监督，并通过一个名为LLMSurver的开源可视化分析网页界面进行交互式控制，允许实时检查和修改模型输出。

Result: 通过使用一个包含8000多篇候选论文的真实SLR数据集进行评估，结果表明该流水线方法显著减少了人工工作量，并且错误率低于单一的人工标注员。此外，研究发现现有的开源模型足以胜任此任务，使得该方法具有可及性和成本效益。

Conclusion: 研究证明了负责任的人工智能与人类协作能够加速和改进学术工作流程中的系统性文献综述。

Abstract: The creation of systematic literature reviews (SLR) is critical for analyzing
the landscape of a research field and guiding future research directions.
However, retrieving and filtering the literature corpus for an SLR is highly
time-consuming and requires extensive manual effort, as keyword-based searches
in digital libraries often return numerous irrelevant publications. In this
work, we propose a pipeline leveraging multiple large language models (LLMs),
classifying papers based on descriptive prompts and deciding jointly using a
consensus scheme. The entire process is human-supervised and interactively
controlled via our open-source visual analytics web interface, LLMSurver, which
enables real-time inspection and modification of model outputs. We evaluate our
approach using ground-truth data from a recent SLR comprising over 8,000
candidate papers, benchmarking both open and commercial state-of-the-art LLMs
from mid-2024 and fall 2025. Results demonstrate that our pipeline
significantly reduces manual effort while achieving lower error rates than
single human annotators. Furthermore, modern open-source models prove
sufficient for this task, making the method accessible and cost-effective.
Overall, our work demonstrates how responsible human-AI collaboration can
accelerate and enhance systematic literature reviews within academic workflows.

</details>


### [849] [Reconstructing 12-Lead ECG from 3-Lead ECG using Variational Autoencoder to Improve Cardiac Disease Detection of Wearable ECG Devices](https://arxiv.org/abs/2510.11442)
*Xinyan Guan,Yongfan Lai,Jiarui Jin,Jun Li,Haoyu Wang,Qinghao Zhao,Deyun Zhang,Shijia Geng,Shenda Hong*

Main category: cs.LG

TL;DR: 提出了一种名为WearECG的变分自编码器（VAE）方法，可以从三个导联（II、V1和V5）重建十二导联心电图（ECG），以解决便携性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决三导联心电图（ECG）便携性好但无法捕捉所有病理区域的问题，提出WearECG方法来重建十二导联ECG。

Method: 使用变分自编码器（VAE）模型，并进行架构改进以更好地捕捉ECG信号的时域和空域依赖性。

Result: 使用MSE、MAE和FID评估生成质量，并通过专家心脏病学家的图灵测试评估临床有效性。进一步通过在多标签分类任务上对ECGFounder模型进行微调来验证诊断效用，该任务涉及40多种心脏病，包括六种不同心肌梗死的部位。实验表明，该方法生成的信号在下游任务中具有稳健的性能。

Conclusion: WearECG方法展示了生成模型在ECG重建方面的潜力，并对可扩展、低成本的心脏筛查具有启示作用。

Abstract: Twelve-lead electrocardiograms (ECGs) are the clinical gold standard for
cardiac diagnosis, providing comprehensive spatial coverage of the heart
necessary to detect conditions such as myocardial infarction (MI). However,
their lack of portability limits continuous and large-scale use. Three-lead ECG
systems are widely used in wearable devices due to their simplicity and
mobility, but they often fail to capture pathologies in unmeasured regions. To
address this, we propose WearECG, a Variational Autoencoder (VAE) method that
reconstructs twelve-lead ECGs from three leads: II, V1, and V5. Our model
includes architectural improvements to better capture temporal and spatial
dependencies in ECG signals. We evaluate generation quality using MSE, MAE, and
Frechet Inception Distance (FID), and assess clinical validity via a Turing
test with expert cardiologists. To further validate diagnostic utility, we
fine-tune ECGFounder, a large-scale pretrained ECG model, on a multi-label
classification task involving over 40 cardiac conditions, including six
different myocardial infarction locations, using both real and generated
signals. Experiments on the MIMIC dataset show that our method produces
physiologically realistic and diagnostically informative signals, with robust
performance in downstream tasks. This work demonstrates the potential of
generative modeling for ECG reconstruction and its implications for scalable,
low-cost cardiac screening.

</details>


### [850] [Iterative Amortized Inference: Unifying In-Context Learning and Learned Optimizers](https://arxiv.org/abs/2510.11471)
*Sarthak Mittal,Divyat Mahajan,Guillaume Lajoie,Mohammad Pezeshki*

Main category: cs.LG

TL;DR: 现代学习系统通过重用跨任务的计算或归纳偏见来实现对新问题的快速泛化，这被称为摊销学习。本文提出了一个统一的框架来描述这些方法，并引入了一个分类法（参数式、隐式、显式），根据它们如何内化或外化任务适应性。为了解决现有方法在处理大规模数据集时能力有限的问题，我们提出了迭代摊销推理，这是一种受随机优化启发的、通过小批量逐步优化解决方案的模型。


<details>
  <summary>Details</summary>
Motivation: 现有的摊销学习方法，如元学习、上下文学习、提示调优等，虽然目标相似，但在编码和利用任务特定信息方面存在差异。这些方法通常在处理大规模数据集时面临扩展性挑战，因为它们在推理时处理任务数据（例如上下文长度）的能力有限。

Method: 提出一个统一的框架来描述不同的摊销学习方法，主要根据它们摊销的学习方面（如初始化、学习更新或预测映射）以及它们在推理时如何结合任务数据。引入一个分类法，将摊销模型分为参数式、隐式和显式三种模式，基于任务适应性是外部化、内化还是联合建模。提出迭代摊销推理，一种逐步优化解决方案的模型，以解决现有方法的扩展性问题。

Result: 识别出现有摊销学习方法的关键局限性，即在扩展到大数据集方面的困难。通过迭代摊销推理，提供了一个可扩展且可扩展的通用任务适应基础。

Conclusion: 迭代摊销推理提供了一种可扩展且可扩展的通用任务适应基础，弥合了基于优化的元学习与像大型语言模型这样的前向传播摊销之间的差距。

Abstract: Modern learning systems increasingly rely on amortized learning - the idea of
reusing computation or inductive biases shared across tasks to enable rapid
generalization to novel problems. This principle spans a range of approaches,
including meta-learning, in-context learning, prompt tuning, learned optimizers
and more. While motivated by similar goals, these approaches differ in how they
encode and leverage task-specific information, often provided as in-context
examples. In this work, we propose a unified framework which describes how such
methods differ primarily in the aspects of learning they amortize - such as
initializations, learned updates, or predictive mappings - and how they
incorporate task data at inference. We introduce a taxonomy that categorizes
amortized models into parametric, implicit, and explicit regimes, based on
whether task adaptation is externalized, internalized, or jointly modeled.
Building on this view, we identify a key limitation in current approaches: most
methods struggle to scale to large datasets because their capacity to process
task data at inference (e.g., context length) is often limited. To address
this, we propose iterative amortized inference, a class of models that refine
solutions step-by-step over mini-batches, drawing inspiration from stochastic
optimization. Our formulation bridges optimization-based meta-learning with
forward-pass amortization in models like LLMs, offering a scalable and
extensible foundation for general-purpose task adaptation.

</details>


### [851] [Differentiable Fast Top-K Selection for Large-Scale Recommendation](https://arxiv.org/abs/2510.11472)
*Yanjie Zhu,Zhen Zhang,Yunli Wang,Zhiqiang Wang,Yu Li,Rufan Zhou,Shiyang Wen,Peng Jiang,Chenhao Lin,Jian Yang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DFTopK的新型可微Top-K算子，其时间复杂度为O(n)，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理大规模信息检索中的Top-K选择时存在挑战，如LambdaLoss的目标不一致性以及ARF、LCRON等基于排序的方法中的梯度冲突，并且现有可微Top-K算子（如LapSum）复杂度为O(n log n)。

Method: DFTopK通过放松归一化约束，获得了一个闭式解，避免了排序，从而实现了O(n)的时间复杂度，并解决了基于可微排序的方法中存在的梯度冲突问题。

Result: DFTopK在RecFLow基准和工业系统上进行了评估，显著提高了训练效率和性能，并能在相同的计算预算下带来+1.77%的收入提升。

Conclusion: DFTopK是首个将可微Top-K算子引入推荐系统的工作，实现了理论上最优的线性时间复杂度，并且其实现已开源。

Abstract: Cascade ranking is a widely adopted paradigm in large-scale information
retrieval systems for Top-K item selection. However, the Top-K operator is
non-differentiable, hindering end-to-end training. Existing methods include
Learning-to-Rank approaches (e.g., LambdaLoss), which optimize ranking metrics
like NDCG and suffer from objective misalignment, and differentiable
sorting-based methods (e.g., ARF, LCRON), which relax permutation matrices for
direct Top-K optimization but introduce gradient conflicts through matrix
aggregation. A promising alternative is to directly construct a differentiable
approximation of the Top-K selection operator, bypassing the use of soft
permutation matrices. However, even state-of-the-art differentiable Top-K
operator (e.g., LapSum) require $O(n \log n)$ complexity due to their
dependence on sorting for solving the threshold. Thus, we propose DFTopK, a
novel differentiable Top-K operator achieving optimal $O(n)$ time complexity.
By relaxing normalization constraints, DFTopK admits a closed-form solution and
avoids sorting. DFTopK also avoids the gradient conflicts inherent in
differentiable sorting-based methods. We evaluate DFTopK on both the public
benchmark RecFLow and an industrial system. Experimental results show that
DFTopK significantly improves training efficiency while achieving superior
performance, which enables us to scale up training samples more efficiently. In
the online A/B test, DFTopK yielded a +1.77\% revenue lift with the same
computational budget compared to the baseline. To the best of our knowledge,
this work is the first to introduce differentiable Top-K operators into
recommendation systems and the first to achieve theoretically optimal
linear-time complexity for Top-K selection. We have open-sourced our
implementation to facilitate future research in both academia and industry.

</details>


### [852] [How Reinforcement Learning After Next-Token Prediction Facilitates Learning](https://arxiv.org/abs/2510.11495)
*Nikolaos Tsilivis,Eran Malach,Karen Ullrich,Julia Kempe*

Main category: cs.LG

TL;DR: 文章介绍了通过强化学习优化语言模型来提升其在推理任务上的表现，并从理论上解释了强化学习相比于下一个词预测的优势，特别是在处理不同长度的“思维链”数据时。研究表明，强化学习能帮助模型在数据稀疏的情况下实现泛化，并能利用增加的测试时间计算量来提升学习效果。在特定简化场景下，理论证明了该训练方法能有效学习特定任务，且对长演示数据的比例有要求。最后，通过在Llama系列模型上的实验验证了这些现象。


<details>
  <summary>Details</summary>
Motivation: 训练一个能够进行推理的语言模型。

Method: 使用强化学习算法对语言模型进行优化，并研究了混合长度“思维链”序列对模型训练的影响。

Result: 理论证明了强化学习能够使自回归Transformer模型在下一个词预测的基础上实现泛化，而单纯的下一个词预测需要极大的计算或统计资源。同时，强化学习能够利用增加的测试时间计算量来促进学习过程。在简化场景下，理论证明了该训练方法能有效学习特定任务。

Conclusion: 强化学习优化方法能够使语言模型在推理任务上实现泛化，并且能够有效地利用增加的测试时间计算量。该方法在Llama系列模型上的实验也验证了其有效性。

Abstract: Recent advances in reasoning domains with neural networks have primarily been
enabled by a training recipe that optimizes Large Language Models, previously
trained to predict the next-token in a sequence, with reinforcement learning
algorithms. We introduce a framework to study the success of this paradigm, and
we theoretically expose the optimization mechanisms by which reinforcement
learning improves over next-token prediction in this setting. We study learning
from mixture distributions of short and long ``chain-of-thought'' sequences
encoding a single task. In particular, when the task consists of predicting the
parity of $d$ bits and long sequences are rare, we show how reinforcement
learning after next-token prediction enables autoregressive transformers to
generalize, whereas mere next-token prediction requires extreme statistical or
computational resources to do so. We further explain how reinforcement learning
leverages increased test-time computation, manifested in longer responses, to
facilitate this learning process. In a simplified setting, we theoretically
prove that autoregressive linear models following this training recipe can
efficiently learn to predict the parity of $d$ bits as long as the proportion
of long demonstrations in the data mix is not exponentially small in the input
dimension $d$. Finally, we demonstrate these same phenomena in other settings,
including the post-training of Llama-series models on mixture variations of
common mathematical reasoning benchmarks.

</details>


### [853] [Offline Reinforcement Learning with Generative Trajectory Policies](https://arxiv.org/abs/2510.11499)
*Xinsong Feng,Leshu Tang,Chenan Wang,Haipeng Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Generative models have emerged as a powerful class of policies for offline
reinforcement learning (RL) due to their ability to capture complex,
multi-modal behaviors. However, existing methods face a stark trade-off: slow,
iterative models like diffusion policies are computationally expensive, while
fast, single-step models like consistency policies often suffer from degraded
performance. In this paper, we demonstrate that it is possible to bridge this
gap. The key to moving beyond the limitations of individual methods, we argue,
lies in a unifying perspective that views modern generative models, including
diffusion, flow matching, and consistency models, as specific instances of
learning a continuous-time generative trajectory governed by an Ordinary
Differential Equation (ODE). This principled foundation provides a clearer
design space for generative policies in RL and allows us to propose Generative
Trajectory Policies (GTPs), a new and more general policy paradigm that learns
the entire solution map of the underlying ODE. To make this paradigm practical
for offline RL, we further introduce two key theoretically principled
adaptations. Empirical results demonstrate that GTP achieves state-of-the-art
performance on D4RL benchmarks - it significantly outperforms prior generative
policies, achieving perfect scores on several notoriously hard AntMaze tasks.

</details>


### [854] [Learning to Make MISTAKEs: Modeling Incorrect Student Thinking And Key Errors](https://arxiv.org/abs/2510.11502)
*Alexis Ross,Jacob Andreas*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Research on reasoning in language models (LMs) predominantly focuses on
improving the correctness of their outputs. But some important applications
require modeling reasoning patterns that are incorrect. For example, automated
systems that can reason about and simulate student errors are useful for
providing real-time feedback in the classroom or offline practice for
educators-in-training. This paper presents a new method, MISTAKE, that (1)
constructs high-quality synthetic examples of reasoning errors by leveraging
cycle consistency between incorrect answers and latent misconceptions; and (2)
uses the generated data to learn models for student simulation, misconception
classification, and answer generation. We evaluate MISTAKE on three educational
tasks and find that it results in (1) higher accuracy when simulating incorrect
student answers based on specific misconceptions, (2) increased performance
inferring latent misconceptions from observed incorrect answers, and (3) higher
alignment with expert-written distractor answers when generating incorrect
answers (e.g., for multiple-choice tests).

</details>


### [855] [Knowledge-Guided Machine Learning Models to Upscale Evapotranspiration in the U.S. Midwest](https://arxiv.org/abs/2510.11505)
*Aleksei Rozanov,Samikshya Subedi,Vasudha Sharma,Bryan C. Runck*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Evapotranspiration (ET) plays a critical role in the land-atmosphere
interactions, yet its accurate quantification across various spatiotemporal
scales remains a challenge. In situ measurement approaches, like eddy
covariance (EC) or weather station-based ET estimation, allow for measuring ET
at a single location. Agricultural uses of ET require estimates for each field
over broad areas, making it infeasible to deploy sensing systems at each
location. This study integrates tree-based and knowledge-guided machine
learning (ML) techniques with multispectral remote sensing data, griddled
meteorology and EC data to upscale ET across the Midwest United States. We
compare four tree-based models - Random Forest, CatBoost, XGBoost, LightGBM -
and a simple feed-forward artificial neural network in combination with
features engineered using knowledge-guided ML principles. Models were trained
and tested on EC towers located in the Midwest of the United States using
k-fold cross validation with k=5 and site-year, biome stratified train-test
split to avoid data leakage. Results show that LightGBM with knowledge-guided
features outperformed other methods with an R2=0.86, MSE=14.99 W m^-2 and MAE =
8.82 W m^-2 according to grouped k-fold validation (k=5). Feature importance
analysis shows that knowledge-guided features were most important for
predicting evapotranspiration. Using the best performing model, we provide a
data product at 500 m spatial and one-day temporal resolution for gridded ET
for the period of 2019-2024. Intercomparison between the new gridded product
and state-level weather station-based ET estimates show best-in-class
correspondence.

</details>


### [856] [Query-Specific GNN: A Comprehensive Graph Representation Learning Method for Retrieval Augmented Generation](https://arxiv.org/abs/2510.11541)
*Yuchen Yan,Zhihua Liu,Hao Wang,Weiming Li,Xiaoshuai Hao*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Retrieval-augmented generation (RAG) has demonstrated its ability to enhance
Large Language Models (LLMs) by integrating external knowledge sources.
However, multi-hop questions, which require the identification of multiple
knowledge targets to form a synthesized answer, raise new challenges for RAG
systems. Under the multi-hop settings, existing methods often struggle to fully
understand the questions with complex semantic structures and are susceptible
to irrelevant noise during the retrieval of multiple information targets. To
address these limitations, we propose a novel graph representation learning
framework for multi-hop question retrieval. We first introduce a
Multi-information Level Knowledge Graph (Multi-L KG) to model various
information levels for a more comprehensive understanding of multi-hop
questions. Based on this, we design a Query-Specific Graph Neural Network
(QSGNN) for representation learning on the Multi-L KG. QSGNN employs
intra/inter-level message passing mechanisms, and in each message passing the
information aggregation is guided by the query, which not only facilitates
multi-granular information aggregation but also significantly reduces the
impact of noise. To enhance its ability to learn robust representations, we
further propose two synthesized data generation strategies for pre-training the
QSGNN. Extensive experimental results demonstrate the effectiveness of our
framework in multi-hop scenarios, especially in high-hop questions the
improvement can reach 33.8\%. The code is available at:
https://github.com/Jerry2398/QSGNN.

</details>


### [857] [Ontolearn-A Framework for Large-scale OWL Class Expression Learning in Python](https://arxiv.org/abs/2510.11561)
*Caglar Demir,Alkid Baci,N'Dah Jean Kouagou,Leonie Nora Sieger,Stefan Heindorf,Simon Bin,Lukas Blübaum,Alexander Bigerl,Axel-Cyrille Ngonga Ngomo*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we present Ontolearn-a framework for learning OWL class
expressions over large knowledge graphs. Ontolearn contains efficient
implementations of recent stateof-the-art symbolic and neuro-symbolic class
expression learners including EvoLearner and DRILL. A learned OWL class
expression can be used to classify instances in the knowledge graph.
Furthermore, Ontolearn integrates a verbalization module based on an LLM to
translate complex OWL class expressions into natural language sentences. By
mapping OWL class expressions into respective SPARQL queries, Ontolearn can be
easily used to operate over a remote triplestore. The source code of Ontolearn
is available at https://github.com/dice-group/Ontolearn.

</details>


### [858] [Diffusion-DFL: Decision-focused Diffusion Models for Stochastic Optimization](https://arxiv.org/abs/2510.11590)
*Zihao Zhao,Christopher Yeh,Lingkai Kong,Kai Wang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Decision-focused learning (DFL) integrates predictive modeling and
optimization by training predictors to optimize the downstream decision target
rather than merely minimizing prediction error. To date, existing DFL methods
typically rely on deterministic point predictions, which are often insufficient
to capture the intrinsic stochasticity of real-world environments. To address
this challenge, we propose the first diffusion-based DFL approach, which trains
a diffusion model to represent the distribution of uncertain parameters and
optimizes the decision by solving a stochastic optimization with samples drawn
from the diffusion model. Our contributions are twofold. First, we formulate
diffusion DFL using the reparameterization trick, enabling end-to-end training
through diffusion. While effective, it is memory and compute-intensive due to
the need to differentiate through the diffusion sampling process. Second, we
propose a lightweight score function estimator that uses only several forward
diffusion passes and avoids backpropagation through the sampling. This follows
from our results that backpropagating through stochastic optimization can be
approximated by a weighted score function formulation. We empirically show that
our diffusion DFL approach consistently outperforms strong baselines in
decision quality. The source code for all experiments is available at the
project repository: https://github.com/GT-KOALA/Diffusion_DFL.

</details>


### [859] [Attention Factors for Statistical Arbitrage](https://arxiv.org/abs/2510.11616)
*Elliot L. Epstein,Rose Wang,Jaewon Choi,Markus Pelger*

Main category: cs.LG

TL;DR: 本研究提出了一种名为“注意力因子”的新方法，用于统计套利交易，能够识别相似资产、发现错误定价并制定最大化风险调整后收益的交易策略，同时考虑交易成本。


<details>
  <summary>Details</summary>
Motivation: 旨在利用资产间的暂时性价格差异进行统计套利，并提出一种能够最大化考虑交易成本后的风险调整后收益的交易策略。

Method: 通过公司特征嵌入学习条件潜在因子（注意力因子），以处理复杂的相互作用。利用通用序列模型从因子残差组合中识别时间序列信号。联合估计因子和套利交易策略。

Result: 在为期24年的美国大型股实证研究中，注意力因子模型实现了超过4的样本外夏普比率。提出的单步解决方案在扣除交易成本后，取得了2.3的夏普比率。

Conclusion: 联合估计因子和交易策略对于最大化扣除交易成本后的盈利能力至关重要，并且弱因子对于套利交易也很重要。

Abstract: Statistical arbitrage exploits temporal price differences between similar
assets. We develop a framework to jointly identify similar assets through
factors, identify mispricing and form a trading policy that maximizes
risk-adjusted performance after trading costs. Our Attention Factors are
conditional latent factors that are the most useful for arbitrage trading. They
are learned from firm characteristic embeddings that allow for complex
interactions. We identify time-series signals from the residual portfolios of
our factors with a general sequence model. Estimating factors and the arbitrage
trading strategy jointly is crucial to maximize profitability after trading
costs. In a comprehensive empirical study we show that our Attention Factor
model achieves an out-of-sample Sharpe ratio above 4 on the largest U.S.
equities over a 24-year period. Our one-step solution yields an unprecedented
Sharpe ratio of 2.3 net of transaction costs. We show that weak factors are
important for arbitrage trading.

</details>


### [860] [MATH-Beyond: A Benchmark for RL to Expand Beyond the Base Model](https://arxiv.org/abs/2510.11653)
*Prasanna Mayilvahanan,Ricardo Dominguez-Olmedo,Thaddäus Wiedemer,Wieland Brendel*

Main category: cs.LG

TL;DR: 现有的强化学习（RL）方法在数学推理方面似乎取得了显著进展，但这种进步在很大程度上是由于在常用基准测试（如 MATH-500 和 AIME 2024）上进行了大量的采样（例如 pass@1024），而不是 RL 方法真正发现了新的解题模式。这表明当前的 RL 微调方法主要是增强现有模型的能力，而不是像 RL 的初衷那样去探索和学习新技能。为了突破这一瓶颈，我们提出了 MATH-Beyond (MATH-B) 基准测试，该测试旨在即使在大量采样的情况下也能有效地区分常见的开源模型（参数量高达 8B）。在 MATH-B 上取得进展需要能够超越基础模型在重复采样中的能力的 RL 方法。MATH-B 的问题来源于 DAPO-Math-17K 和 DeepScaleR 数据集，因此与标准高中数学主题相关。实验证明，在 MATH-B 上，像 Nemotron-Research-Reasoning-Qwen-1.5B 和 DeepScaleR-1.5B-Preview 这样的 RL 微调模型在 pass@1024 的表现不佳，这暴露了现有方法在处理更难的实例时存在的不足。我们希望 MATH-B 能促进探索驱动的 RL 方法的发展，以激发更深层次的推理能力。MATH-B 已在 https://huggingface.co/datasets/brendel-group/MATH-Beyond 发布。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）方法在数学推理方面的进步可能被高估，因为它们在常用基准测试上的成功可能归因于大量的采样，而不是真正的能力提升。这阻碍了 RL 探索新技能和推理方式的潜力。

Method: 提出 MATH-Beyond (MATH-B) 基准测试，该基准测试的构建旨在使常见的开源模型（高达 8B 参数）在大量采样（例如 pass@1024）下也难以解决。MATH-B 的问题来源于 DAPO-Math-17K 和 DeepScaleR 数据集，与高中数学主题相关。通过在 MATH-B 上评估现有 RL 微调模型（如 Nemotron-Research-Reasoning-Qwen-1.5B 和 DeepScaleR-1.5B-Preview）来验证该基准的有效性。

Result: 在 MATH-B 基准测试上，即使在 pass@1024 的高采样预算下，现有的 RL 微调模型（如 Nemotron-Research-Reasoning-Qwen-1.5B 和 DeepScaleR-1.5B-Preview）表现不佳，表明它们未能超越基础模型的性能，并且在解决更难的数学问题时存在局限性。

Conclusion: MATH-B 基准测试成功地揭示了现有 RL 数学推理方法的局限性，这些方法在处理更具挑战性的问题时，其性能提升主要依赖于采样而非真正的推理能力提升。该基准的提出旨在推动更具探索性的 RL 方法的发展，以期实现更深层次的数学推理能力。MATH-B 已开源以供社区使用。

Abstract: With the advent of DeepSeek-R1, a new wave of reinforcement learning (RL)
methods has emerged that seem to unlock stronger mathematical reasoning.
However, a closer look at the open-source ecosystem reveals a critical
limitation: with sufficiently many draws (e.g., $\texttt{pass@1024}$), many
existing base models already solve nearly all questions on widely used math
benchmarks such as MATH-500 and AIME 2024. This suggests that the RL
fine-tuning methods prevalent in the LLM reasoning literature largely sharpen
existing solution modes rather than discovering entirely new ones. Such
sharpening stands in contrast to the broader promise of RL: to foster
exploration and to acquire new skills. To move beyond this plateau, we
introduce MATH-Beyond (MATH-B), a benchmark deliberately constructed to defeat
common open-source models of up to 8B parameters even under large sampling
budgets. Improving performance on our benchmark via RL requires methods that
learn to reason in ways that go beyond base model capabilities in repeated
sampling. Since the problems are drawn from subsets of DAPO-Math-17K and
DeepScaleR datasets, they remain topically equivalent to standard high-school
math. Validating our premise, RL fine-tuned models such as
Nemotron-Research-Reasoning-Qwen-1.5B and DeepScaleR-1.5B-Preview perform
poorly on MATH-B at $\texttt{pass@1024}$, showing how existing approaches fall
short on tackling harder instances. We hope MATH-B will catalyze
exploration-driven RL approaches that elicit deeper reasoning capabilities. We
release MATH-B at https://huggingface.co/datasets/brendel-group/MATH-Beyond.

</details>


### [861] [An Eulerian Perspective on Straight-Line Sampling](https://arxiv.org/abs/2510.11657)
*Panos Tsimpos,Youssef Marzouk*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study dynamic measure transport for generative modeling: specifically,
flows induced by stochastic processes that bridge a specified source and target
distribution. The conditional expectation of the process' velocity defines an
ODE whose flow map achieves the desired transport. We ask \emph{which processes
produce straight-line flows} -- i.e., flows whose pointwise acceleration
vanishes and thus are exactly integrable with a first-order method? We provide
a concise PDE characterization of straightness as a balance between conditional
acceleration and the divergence of a weighted covariance (Reynolds) tensor.
Using this lens, we fully characterize affine-in-time interpolants and show
that straightness occurs exactly under deterministic endpoint couplings. We
also derive necessary conditions that constrain flow geometry for general
processes, offering broad guidance for designing transports that are easier to
integrate.

</details>


### [862] [Chronologically Consistent Generative AI](https://arxiv.org/abs/2510.11677)
*Songrun He,Linying Lv,Asaf Manela,Jimmy Wu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a family of chronologically consistent, instruction-following
large language models to eliminate lookahead bias. Each model is trained only
on data available before a clearly defined knowledge-cutoff date, ensuring
strict temporal separation from any post-cutoff data. The resulting framework
offers (i) a simple, conversational chat interface, (ii) fully open, fixed
model weights that guarantee replicability, and (iii) a conservative lower
bound on forecast accuracy, isolating the share of predictability that survives
once training leakage is removed. Together, these features provide researchers
with an easy-to-use generative AI tool useful for a wide range of prediction
tasks that is free of lookahead bias.

</details>


### [863] [Representation-Based Exploration for Language Models: From Test-Time to Post-Training](https://arxiv.org/abs/2510.11686)
*Jens Tuyls,Dylan J. Foster,Akshay Krishnamurthy,Jordan T. Ash*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Reinforcement learning (RL) promises to expand the capabilities of language
models, but it is unclear if current RL techniques promote the discovery of
novel behaviors, or simply sharpen those already present in the base model. In
this paper, we investigate the value of deliberate exploration -- explicitly
incentivizing the model to discover novel and diverse behaviors -- and aim to
understand how the knowledge in pre-trained models can guide this search. Our
main finding is that exploration with a simple, principled,
representation-based bonus derived from the pre-trained language model's hidden
states significantly improves diversity and pass@k rates -- both for
post-training, and in a novel inference-time scaling setting we introduce. For
inference-time, exploration with representation-based diversity improves
efficiency, consistently improving pass@k rates across a variety of models and
reasoning tasks. For example, for Qwen-2.5-14b-Instruct we obtain over 50%
improvement in verifier efficiency on almost all tasks. For post-training, we
show that integrating this exploration strategy into an RL pipeline improves
reasoning performance over that of the initial model and over standard RL
post-training. For example, on AIME 2024, our post-trained
Qwen-2.5-7b-Instruct's pass@80 matches the pass@256 of GRPO on the same model,
demonstrating a 3x improvement in test-time sample efficiency. Overall, our
findings suggest that deliberate exploration -- with the right notion of
diversity -- is a practical path toward discovery of new behaviors beyond
sharpening.

</details>


### [864] [Adversarial Attacks Leverage Interference Between Features in Superposition](https://arxiv.org/abs/2510.11709)
*Edward Stevinson,Lucas Prieto,Melih Barsbey,Tolga Birdal*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Fundamental questions remain about when and why adversarial examples arise in
neural networks, with competing views characterising them either as artifacts
of the irregularities in the decision landscape or as products of sensitivity
to non-robust input features. In this paper, we instead argue that adversarial
vulnerability can stem from efficient information encoding in neural networks.
Specifically, we show how superposition - where networks represent more
features than they have dimensions - creates arrangements of latent
representations that adversaries can exploit. We demonstrate that adversarial
perturbations leverage interference between superposed features, making attack
patterns predictable from feature arrangements. Our framework provides a
mechanistic explanation for two known phenomena: adversarial attack
transferability between models with similar training regimes and class-specific
vulnerability patterns. In synthetic settings with precisely controlled
superposition, we establish that superposition suffices to create adversarial
vulnerability. We then demonstrate that these findings persist in a ViT trained
on CIFAR-10. These findings reveal adversarial vulnerability can be a byproduct
of networks' representational compression, rather than flaws in the learning
process or non-robust inputs.

</details>


### [865] [Reinforced sequential Monte Carlo for amortised sampling](https://arxiv.org/abs/2510.11711)
*Sanghyeok Choi,Sarthak Mittal,Víctor Elvira,Jinkyoo Park,Nikolay Malkin*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper proposes a synergy of amortised and particle-based methods for
sampling from distributions defined by unnormalised density functions. We state
a connection between sequential Monte Carlo (SMC) and neural sequential
samplers trained by maximum-entropy reinforcement learning (MaxEnt RL), wherein
learnt sampling policies and value functions define proposal kernels and twist
functions. Exploiting this connection, we introduce an off-policy RL training
procedure for the sampler that uses samples from SMC -- using the learnt
sampler as a proposal -- as a behaviour policy that better explores the target
distribution. We describe techniques for stable joint training of proposals and
twist functions and an adaptive weight tempering scheme to reduce training
signal variance. Furthermore, building upon past attempts to use experience
replay to guide the training of neural samplers, we derive a way to combine
historical samples with annealed importance sampling weights within a replay
buffer. On synthetic multi-modal targets (in both continuous and discrete
spaces) and the Boltzmann distribution of alanine dipeptide conformations, we
demonstrate improvements in approximating the true distribution as well as
training stability compared to both amortised and Monte Carlo methods.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [866] [Spin coherence scale: operator-ordering sensitivity beyond Heisenberg-Weyl](https://arxiv.org/abs/2510.09747)
*Aaron Z. Goldberg,Anaelle Hertz*

Main category: quant-ph

TL;DR: 提出了自旋相干尺度，作为衡量自旋系统量子相干性的新指标，它是对先前为四元数可观测量定义的四元数相干尺度（QCS）的推广。该度量是SU（2）-不变的，量化了角动量基中量子态的非对角相干性，并由叠加态的经典可区分性加权。


<details>
  <summary>Details</summary>
Motivation: 介绍自旋相干尺度（spin coherence scale）作为衡量自旋系统量子相干性的新指标，并将其与之前的四元数相干尺度（QCS）进行比较和推广。

Method: 定义了自旋相干尺度，这是一个SU（2）-不变的度量，用于量化角动量基中量子态的非对角相干性，并考虑了叠加态的经典可区分性。同时，将该框架推广到SU（n）系统。

Result: 证明了自旋相干尺度具有许多与QCS相似的特性，包括与量子态的噪声敏感性以及拟概率分布矩的关系。该度量为非经典性提供了见证，并给出了与经典（自旋相干）态集合的希尔伯特-施密特距离的上下界。此外，还确定了SU（n）系统的唯一SU（n）-不变去极化通道。

Conclusion: 自旋相干尺度在量子计量学（特别是旋转传感）中具有直接应用价值，并为超越谐振子系统定义和表征相干尺度提供了一个更广泛的李代数方法。

Abstract: We introduce the spin coherence scale as a measure of quantum coherence for
spin systems, generalizing the quadrature coherence scale (QCS) previously
defined for quadrature observables. This SU($2$)-invariant measure quantifies
the off-diagonal coherences of a quantum state in angular momentum bases,
weighted by the classical distinguishability of the superposed states. It
serves as a witness of nonclassicality and provides both upper and lower bounds
on the Hilbert-Schmidt distance to the set of classical (spin coherent) states.
We demonstrate that many hallmark properties of the QCS carry over to the spin
setting, including its links to noise susceptibility of a state and moments of
quasiprobability distributions. The spin coherence scale has direct
implications for quantum metrology in the guise of rotation sensing. We also
generalize the framework to SU($n$) systems, identifying the unique
SU($n$)-invariant depolarization channel and outlining a broad, Lie-algebraic
approach to defining and characterizing the properties of coherence scale
beyond harmonic oscillators.

</details>


### [867] [Assessing the Role of Communication in Modular Multi-Core Quantum Systems](https://arxiv.org/abs/2510.11053)
*Maurizio Palesi,Enrico Russo,Giuseppe Ascia,Hamaad Rafique,Davide Patti,Vincenzo Catania,Sergi Abadal,Abhijit Das,Pau Escofet,Eduard Alarcon,Carmen G. Almudéver*

Main category: quant-ph

TL;DR: 该论文介绍了一个名为“qcomm”的开源模拟器，用于评估经典通信对模块化量子计算的影响，并提出了优化策略。


<details>
  <summary>Details</summary>
Motivation: 为了解决单片量子处理器在可扩展性方面的物理和架构限制，模块化多核量子架构被提出。然而，这种架构引入了通信开销，特别是经典通信在执行量子算法中至关重要。

Method: 介绍并使用了一个名为“qcomm”的开源模拟器，该模拟器提供了一个高级执行和计时模型，能够捕捉量子门执行、纠缠分发、隐形传态协议以及经典通信延迟之间的相互作用。通过该模拟器，对经典通信带宽、互连类型和量子电路映射策略对整体执行时间的影响进行了广泛的实验分析。

Result: 研究结果表明，经典通信通常不是影响执行时间的主要因素，但在优化场景下（如改进的量子技术、大规模互连或通信感知的电路映射），其影响会变得越来越重要。

Conclusion: 该研究结果为了设计可扩展的模块化量子架构提供了有用的见解，并强调了在评估未来系统中作为性能限制因素的经典通信的重要性。

Abstract: The scalability of quantum computing is constrained by the physical and
architectural limitations of monolithic quantum processors. Modular multi-core
quantum architectures, which interconnect multiple quantum cores (QCs) via
classical and quantum-coherent links, offer a promising alternative to address
these challenges. However, transitioning to a modular architecture introduces
communication overhead, where classical communication plays a crucial role in
executing quantum algorithms by transmitting measurement outcomes and
synchronizing operations across QCs. Understanding the impact of classical
communication on execution time is therefore essential for optimizing system
performance.
  In this work, we introduce \qcomm, an open-source simulator designed to
evaluate the role of classical communication in modular quantum computing
architectures. \qcomm{} provides a high-level execution and timing model that
captures the interplay between quantum gate execution, entanglement
distribution, teleportation protocols, and classical communication latency. We
conduct an extensive experimental analysis to quantify the impact of classical
communication bandwidth, interconnect types, and quantum circuit mapping
strategies on overall execution time. Furthermore, we assess classical
communication overhead when executing real quantum benchmarks mapped onto a
cryogenically-controlled multi-core quantum system. Our results show that,
while classical communication is generally not the dominant contributor to
execution time, its impact becomes increasingly relevant in optimized scenarios
-- such as improved quantum technology, large-scale interconnects, or
communication-aware circuit mappings. These findings provide useful insights
for the design of scalable modular quantum architectures and highlight the
importance of evaluating classical communication as a performance-limiting
factor in future systems.

</details>


### [868] [Vari-Cool: a non-unitary quantum variational protocol for simulated cooling](https://arxiv.org/abs/2510.09749)
*Jeffrey Z. Song,Gilad Kishony,Erez Berg,Mark S. Rudner*

Main category: quant-ph

TL;DR: 我们提出了一种变分方法，用于制备任意目标哈密顿量的低能态。该方案通过重复循环定义，包括应用于系统和辅助“浴”量子比特的 p 层酉门，然后重置浴量子比特。每个循环内的门参数经过优化，使得重复多次循环后达到的稳态相对于目标哈密顿量具有低能量期望值，并且能量以尽可能少的循环次数收敛到稳态值。我们以横向场伊辛模型为例说明该方案，并利用张量网络进行经典模拟，研究其系统行为随系统大小、模型参数和噪声的变化。然后，我们在 IBM 的 ibm_kingston 量子处理器上通过实验演示了该方案的操作，最多可耦合 28 个系统量子比特和 14 个浴位点。在小型系统和少量酉层循环上的经典训练能得到稳健的结果，并能很好地推广到更大的系统和噪声环境中。


<details>
  <summary>Details</summary>
Motivation: 我们提出了一种变分方法，用于制备任意目标哈密顿量的低能态。

Method: 该方案通过重复循环定义，包括应用于系统和辅助“浴”量子比特的 p 层酉门，然后重置浴量子比特。每个循环内的门参数经过优化，使得重复多次循环后达到的稳态相对于目标哈密顿量具有低能量期望值，并且能量以尽可能少的循环次数收敛到稳态值。我们以横向场伊辛模型为例说明该方案，并利用张量网络进行经典模拟，研究其系统行为随系统大小、模型参数和噪声的变化。然后，我们在 IBM 的 ibm_kingston 量子处理器上通过实验演示了该方案的操作，最多可耦合 28 个系统量子比特和 14 个浴位点。

Result: 在小型系统和少量酉层循环上的经典训练能得到稳健的结果，并能很好地推广到更大的系统和噪声环境中。

Conclusion: 该变分方法能够有效地制备任意目标哈密顿量的低能态，并且在噪声和扩展到更大系统方面表现出稳健性。

Abstract: We introduce a variational approach for preparing low energy states of
arbitrary target Hamiltonians. The protocol is defined in terms of a repeated
cycle consisting of p layers of unitary gates applied to the system and ancilla
"bath" qubits, followed by reset of the bath qubits. The gate parameters within
each cycle are optimized such that the steady state achieved after many cycles
has a low energy expectation value with respect to the target Hamiltonian, and
that the energy converges toward the steady state value in as few cycles as
possible. We illustrate the protocol for the transverse field Ising model, and
study its systematic behaviors with respect to system size, model parameters,
and noise using tensor network based classical simulations. We then
experimentally demonstrate its operation on IBM's ibm_kingston quantum
processor for up to 28 system qubits coupled to 14 bath sites. Classical
training on small system sizes and with few unitary layers per cycle gives
robust results that transfer well to larger system sizes and to noisy hardware.

</details>


### [869] [Bounds in the Projective Unitary Group with Respect to Global Phase Invariant Metric](https://arxiv.org/abs/2510.09765)
*Bhanu Pratap Yadav,Mahdi Bayanifar,Olav Tirkkonen*

Main category: quant-ph

TL;DR: 研究了适用于通用量子计算的 PUn 群的全局相位不变度量，并推导了 Gilbert-Varshamov 和 Hamming 界限，以及 PUn 中码字本书的覆盖半径和拥挤半径界限。


<details>
  <summary>Details</summary>
Motivation: 研究 PUn 群的度量，为量子计算中的编码提供理论基础。

Method: 推导 PUn 群的体积和测度，计算码字本书的拥挤半径界限，并利用拥挤半径的下界来推导 Hamming 界限。

Result: 得到 PUn 群的 Gilbert-Varshamov 和 Hamming 界限，码字本书的拥挤半径界限，以及量化 PUn 上均匀分布的源的失真率函数的界限。

Conclusion: 分析结果已通过模拟得到验证。

Abstract: We consider a global phase-invariant metric in the projective unitary group
PUn, relevant for universal quantum computing. We obtain the volume and measure
of small metric ball in PUn and derive the Gilbert-Varshamov and Hamming bounds
in PUn. In addition, we provide upper and lower bounds for the kissing radius
of the codebooks in PUn as a function of the minimum distance. Using the lower
bound of the kissing radius, we find a tight Hamming bound. Also, we establish
bounds on the distortion-rate function for quantizing a source uniformly
distributed over PUn. As example codebooks in PUn, we consider the projective
Pauli and Clifford groups, as well as the projective group of diagonal gates in
the Clifford hierarchy, and find their minimum distances. For any code in PUn
with given cardinality we provide a lower bound of covering radius. Also, we
provide expected value of the covering radius of randomly distributed points on
PUn, when cardinality of code is sufficiently large. We discuss codebooks at
various stages of the projective Clifford + T and projective Clifford + S
constructions in PU2, and obtain their minimum distance, distortion, and
covering radius. Finally, we verify the analytical results by simulation.

</details>


### [870] [Efficient Emulation of Neutral Atom Quantum Hardware](https://arxiv.org/abs/2510.09813)
*Kemal Bidzhiev,Stefano Grava,Pablo le Henaff,Mauro Mendizabal,Elie Merhej,Anton Quelle*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Simulating the dynamics of neutral atom arrays is a challenging problem. To
address this, we introduce two emulators, emu-sv and emu-mps, as computational
backends for Pasqal's pulser package. Emu-sv is designed for high-precision
state-vector simulations, giving the possibility to emulate systems of up to
$\thicksim 27$ qubits on an A100 40GB GPU, making it perfect for cases where
numerically exact results are needed. In contrast, emu-mps uses a Matrix
Product State representation and other controlled approximations to efficiently
simulate much larger arrays of atoms with manageable errors. We show through
benchmark comparisons that both emulators provide significant speed-ups over
generic solvers such as QuTiP. In addition, we provide practical guidance on
choosing between the two emulators. These quantum software tools are designed
to support researchers and developers aiming to simulate quantum systems either
as a precursor to full hardware implementation or as a means of benchmarking
hardware performance.

</details>


### [871] [Quantum Circuit for Quantum Fourier Transform for Arbitrary Qubit Connectivity Graphs](https://arxiv.org/abs/2510.09824)
*Kamil Khadiev,Aliya Khadieva,Vadim Sagitov,Kamil Khasanov*

Main category: quant-ph

TL;DR: 本论文提出了一种用于在具有限制的量子设备上构建量子傅里叶变换（QFT）电路的通用方法，该方法可以处理任意连接图，并最大限度地减少CNOT门的使用。


<details>
  <summary>Details</summary>
Motivation: 现有的量子设备（如超导设备）在应用两比特门方面存在限制，这些限制由量子比特连接图表示。然而，目前的研究主要集中在线性最近邻（LNN）架构上，而实际设备具有更复杂的连接图。因此，需要一种适用于任意连接图并优化CNOT门数量的通用QFT电路构建方法。

Method: 提出了一种通用的量子傅里叶变换（QFT）电路构建方法，该方法适用于任意连接图的量子设备，并能最小化电路中CNOT门的使用数量。

Result: 将该通用方法构建的电路与针对特定图（LNN、“sun”和“two joint suns”）的现有优化电路进行了比较。结果表明，对于“sun”和“two joint suns”架构，该通用方法得到的电路性能与现有优化电路相当；对于LNN架构，CNOT门数量略有增加。但该方法的优势在于其通用性，可用于构建任意连接图的电路。

Conclusion: 所提出的通用方法能够有效地在具有复杂连接图的量子设备上构建量子傅里叶变换（QFT）电路，并且在优化CNOT门数量方面取得了有竞争力的结果，为在更多样化的量子硬件上实现QFT算法提供了可行方案。

Abstract: In the paper, we consider quantum circuits for the Quantum Fourier Transform
(QFT) algorithm. The QFT algorithm is a very popular technique used in many
quantum algorithms. We present a generic method for constructing quantum
circuits for this algorithm implementing on quantum devices with restrictions.
Many quantum devices (for example, based on superconductors) have restrictions
on applying two-qubit gates. These restrictions are presented by a qubit
connectivity graph. Typically, researchers consider only the linear nearest
neighbor (LNN) architecture of the qubit connection, but current devices have
more complex graphs. We present a method for arbitrary connected graphs that
minimizes the number of CNOT gates in the circuit for implementing on such
architecture.
  We compare quantum circuits built by our algorithm with existing quantum
circuits optimized for specific graphs that are Linear-nearest-neighbor (LNN)
architecture, ``sun'' (a cycle with tails, presented by the 16-qubit IBMQ
device) and ``two joint suns'' (two joint cycles with tails, presented by the
27-qubit IBMQ device). Our generic method gives similar results with existing
optimized circuits for ``sun'' and ``two joint suns'' architectures, and a
circuit with slightly more CNOT gates for the LNN architecture. At the same
time, our method allows us to construct a circuit for arbitrary connected
graphs.

</details>


### [872] [Quantum Action-Dependent Channels](https://arxiv.org/abs/2510.09834)
*Michael Korenberg,Uzi Pereg*

Main category: quant-ph

TL;DR: 该研究提出了量子类比的信道模型，其中Alice可以通过量子操作影响信道环境，并利用共享的纠缠信息进行可靠通信，从而扩展了经典模型。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究量子作用依赖信道模型，并将其与经典模型进行类比，将经典作用依赖信道模型扩展到量子领域。

Method: 提出了一种量子作用依赖信道模型，其中Alice的编码通过量子操作（如测量）影响环境状态，并利用共享的纠缠信息进行通信。

Result: 建立了通过量子作用依赖信道进行可靠消息传输的可实现通信速率。

Conclusion: 该研究成功地将经典作用依赖信道模型扩展到了量子领域，并为量子通信提供了一种新的模型和通信速率的计算方法。

Abstract: We study the quantum action-dependent channel. The model can be viewed as a
quantum analog of the classical action-dependent channel model. In this
setting, the communication channel has two inputs: Alice's transmission and the
input environment. The action-dependent mechanism enables the transmitter to
influence the channel's environment through an action channel. Specifically,
Alice encodes her message into a quantum action, which subsequently affects the
environment state. For example, a quantum measurement at the encoder can induce
a state collapse of the environment. In addition, Alice has access to side
information. Unlike the classical model, she cannot have a copy of the
environment state due to the no-cloning theorem. Instead, she shares
entanglement with this environment. We establish an achievable communication
rate for reliable message transmission via the quantum action-dependent
channel, thereby extending the classical action-dependent framework to the
quantum domain.

</details>


### [873] [Quantum Algorithms for the Minimum Steiner Tree problem with application to Binary Near-Perfect Phylogenies](https://arxiv.org/abs/2510.09911)
*Lingfa Meng,David Salvador Novo,Albert H. Werner,Samir Bhatt*

Main category: quant-ph

TL;DR: We present a quantum algorithm for the Binary Near-Perfect Phylogeny Problem (BNPP) with a complexity of $O(8.926^q + 8^q nm2)$ and a polynomial space exact algorithm for the Minimum Steiner Tree (MST) problem with complexity $O^*(e^{(1+g(k,l))k})$.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the computational complexity of the Binary Near-Perfect Phylogeny Problem (BNPP) using a quantum algorithm and the Minimum Steiner Tree (MST) problem using a polynomial space exact algorithm.

Method: For BNPP, a quantum algorithm is presented with a complexity bound of $O(8.926^q + 8^q nm2)$ in the QRAM model. For MST, a polynomial space exact algorithm with complexity $O^*(e^{(1+g(k,l))k})$ in the circuit model is provided.

Result: A quantum algorithm for BNPP and a polynomial space exact algorithm for MST are presented, with specific complexity bounds for each.

Conclusion: The paper introduces novel algorithms for BNPP and MST, offering improved or specific complexity bounds for their respective problem domains.

Abstract: We present a quantum algorithm in bioinformatics for solving the Binary
Near-Perfect Phylogeny Problem (BNPP) with a complexity bound of $O(8.926^q +
8^q nm2)$, where n is the number of input taxa and m is the sequence length for
each taxon with each character in the sequence being a binary bit using the
QRAM model. We give another polynomial space exact algorithm for the Minimum
Steiner Tree (MST) problem with complexity $O^*(e^{(1+g(k,l))k})$ in the
circuit model.

</details>


### [874] [How much can we learn from quantum random circuit sampling?](https://arxiv.org/abs/2510.09919)
*Tudor Manole,Daniel K. Mark,Wenjie Gong,Bingtian Ye,Yury Polyanskiy,Soonwon Choi*

Main category: quant-ph

TL;DR: 本研究提出了一种基于随机电路采样（RCS）的新型量子设备基准测试方法，能够提供比传统方法更丰富的错误诊断信息，且无需修改实验设置或进行经典模拟。


<details>
  <summary>Details</summary>
Motivation: 准确地表征大规模量子设备是一个重大挑战，因为它们会经历多种错误源且无法被经典计算机模拟。

Method: 提出基于随机电路采样（RCS）的新型基准测试方法，利用参考量子设备获取的比特串样本作为侧信息，通过高维统计建模来分析RCS数据，从而提取时空错误分布、相关和上下文错误以及偏差读出错误等信息，并推导了信息论极限。

Result: 在现有的超导处理器RCS数据上进行了方法验证，获得了与组件级校准定性一致但定量不同的就位表征，并确定了学习能力随侧信息量变化的相变点。

Conclusion: 该研究为当前和未来的量子计算机提供了实用的基准测试协议，并确立了从RCS数据中学习的根本性信息论极限。

Abstract: Benchmarking quantum devices is a foundational task for the sustained
development of quantum technologies. However, accurate in situ characterization
of large-scale quantum devices remains a formidable challenge: such systems
experience many different sources of errors, and cannot be simulated on
classical computers. Here, we introduce new benchmarking methods based on
random circuit sampling (RCS), that substantially extend the scope of
conventional approaches. Unlike existing benchmarks that report only a single
quantity--the circuit fidelity--our framework extracts rich diagnostic
information, including spatiotemporal error profiles, correlated and contextual
errors, and biased readout errors, without requiring any modifications of the
experiment. Furthermore, we develop techniques that achieve this task without
classically intractable simulations of the quantum circuit, by leveraging side
information, in the form of bitstring samples obtained from reference quantum
devices. Our approach is based on advanced high-dimensional statistical
modeling of RCS data. We sharply characterize the information-theoretic limits
of error estimation, deriving matching upper and lower bounds on the sample
complexity across all regimes of side information. We identify surprising phase
transitions in learnability as the amount of side information varies. We
demonstrate our methods using publicly available RCS data from a
state-of-the-art superconducting processor, obtaining in situ characterizations
that are qualitatively consistent yet quantitatively distinct from
component-level calibrations. Our results establish both practical benchmarking
protocols for current and future quantum computers and fundamental
information-theoretic limits on how much can be learned from RCS data.

</details>


### [875] [Bounds on Eventually Universal Quantum Gate Sets](https://arxiv.org/abs/2510.09931)
*Chaitanya Karamchedu,Matthew Fox,Daniel Gottesman*

Main category: quant-ph

TL;DR: 该论文改进了量子门集“最终酉性”的界限，将所需系统规模从 d^8n 降低到 d^4n，对于量子比特系统，将界限从 256n 降低到 16n。


<details>
  <summary>Details</summary>
Motivation: 提高量子门集“最终酉性”所需系统规模的上限。

Method: 利用有限线性群的不变量和酉 2-设计的有限群分类结果。

Result: 将量子门集“最终酉性”的界限从 d^8n 改进到 d^4n。对于量子比特（d=2），界限从 256n 改进到 16n。

Conclusion: 对于量子比特系统，如果增加 15n 个辅助量子比特不能使门集达到酉性，那么增加任意数量的辅助量子比特也不会使其达到酉性。

Abstract: Say a collection of $n$-qu$d$it gates $\Gamma$ is eventually universal if and
only if there exists $N_0 \geq n$ such that for all $N \geq N_0$, one can
approximate any $N$-qu$d$it unitary to arbitrary precision by a circuit over
$\Gamma$. In this work, we improve the best known upper bound on the smallest
$N_0$ with the above property. Our new bound is roughly $d^4n$, where $d$ is
the local dimension (the `$d$' in qu$d$it), whereas the previous bound was
roughly $d^8n$. For qubits ($d = 2$), our result implies that if an $n$-qubit
gate set is eventually universal, then it will exhibit universality when acting
on a $16n$ qubit system, as opposed to the previous bound of a $256n$ qubit
system. In other words, if adding just $15n$ ancillary qubits to a quantum
system (as opposed to the previous bound of $255 n$ ancillary qubits) does not
boost a gate set to universality, then no number of ancillary qubits ever will.
Our proof relies on the invariants of finite linear groups as well as a
classification result for all finite groups that are unitary $2$-designs.

</details>


### [876] [Observational entropy of quantum correlations and entanglement](https://arxiv.org/abs/2510.10058)
*Leonardo Rossetti,Stefano Mancini,Andreas Winter,Joseph Schindler*

Main category: quant-ph

TL;DR: 本文提出了“观测熵”的概念，并将其应用于量化不同观测者（特别是具有局域性限制的观测者）的量子相关性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过“熵隙”来量化量子态中的量子相关性，该熵隙定义为最小局域观测熵与冯诺依曼熵之间的差值。

Method: 本文首先为一般类别的测量引入了熵隙并推导了其性质，然后专门研究了局域测量（LO）、仅使用经典通信的局域操作（LOCC）以及可分离测量（SEP）等测量类别。对于这些类别，本文将熵隙与状态的纠缠或非经典性度量相关联。

Result: 对于二分纯态，所有“局域”熵隙都等于纠缠熵；对于一般的复合态，熵隙被纠缠相对熵（relative entropy of entanglement）向下界定。不同测量类别的熵隙是有序的，并且它们在一般情况下（混合态和复合态）是不同的。

Conclusion: 熵隙可以作为量化量子相关性的有效工具，并且不同测量类别的熵隙提供了对量子态非经典性的不同视角。

Abstract: The use of coarse graining to connect physical and information theoretic
entropies has recently been given a precise formulation in terms of
``observational entropy'', describing entropy for observers with respect to a
measurement. Here we consider observers with various locality restrictions,
including local measurements (LO), measurements based on local operations with
classical communication (LOCC), and separable measurements (SEP), with the idea
that the ``entropy gap'' between the minimum locally measured observational
entropy and the von Neumann entropy quantifies quantum correlations in a given
state. After introducing entropy gaps for general classes of measurements and
deriving their general properties, we specialize to LO, LOCC, SEP and other
measurement classes related to the locality of subsystems. For those, we show
that the entropy gap can be related to well-known measures of entanglement or
non-classicality of the state (even though we point out that they are not
entanglement monotones themselves). In particular, for bipartite pure states,
all of the ``local'' entropy gaps reproduce the entanglement entropy, and for
general multipartite states they are lower-bounded by the relative entropy of
entanglement. The entropy gaps of the different measurement classes are
ordered, and we show that in general (mixed and multipartite states) they are
all different.

</details>


### [877] [Broad nonlocal spectrum in the Pb-InSb hybrid three terminals for potential realization of Kitaev chains](https://arxiv.org/abs/2510.10064)
*Guoan Li,Xiaofan Shi,Ruixuan Zhang,Yuxiao Song,Marco Rossi,Ghada Badawy,Zhiyuan Zhang,Anqi Wang,Xingchen Guo,Xiao Deng,Xiao Chen,Liangqian Xu,Bingbing Tong,Peiling Li,Xiaohui Song,Zhaozheng Lyu,Guangtong Liu,Fanming Qu,Michał P. Nowak,Paweł Wójcik,Ziwei Dou,Erik P. A. M. Bakkers,Li Lu,Jie Shen*

Main category: quant-ph

TL;DR: 使用铅基混合器件实现高温量子比特


<details>
  <summary>Details</summary>
Motivation: 铅（Pb）相比于铝（Al）具有更大的超导能隙和更高的临界温度，这有望实现更大的诱导超导能隙，为构建拓扑量子比特提供更好的平台。

Method: 制备了三端铅基混合器件，并进行非局域微分电导谱测量，同时观察了铅的本体能隙和诱导的超导能隙，并研究了安德烈夫束缚态（ABSs）和量子点（QDs）的耦合。

Result: 观察到ABSs经历单-双态跃迁，通过调控栅电压实现了栅控的非局域电导符号反转，识别出三种不同的量子点共振模式，并且ABSs与QDs的耦合可调。

Conclusion: 铅基混合器件具有较大的诱导能隙，能够在远高于铝基器件的温度下（约1K）保持鲁棒的非局域信号，这使得在较高温度下实现人工Kitaev链和拓扑量子器件成为可能。

Abstract: Hybrid superconductor-semiconductor(SC-SM) nanowires remain one of the
foremost platforms for engineering topological superconductivity and Majorana
zero modes(MZMs) towards fault-tolerant topological qubits, especially with the
rapid development of artificial Kitaev chains. In contrast to the widely used
aluminum(Al)-based hybrids, lead(Pb) offers a bulk superconducting gap of
~1.4meV and a critical temperature of ~7.2K, giving rise to a proximity-induced
gap that is roughly five times larger than that obtained with Al. Here we
present the first three-terminal Pb-hybrid devices and perform nonlocal
differential-conductance spectroscopy on this platform. The nonlocal
measurement simultaneously resolves a dual-gap feature of the parent Pb gap and
the large, hard, gate-tunable induced superconducting gap, distinguished by a
switch between electron- and hole-like dissipation processes. Within the
induced gap we observe several types of Andreev bound states(ABSs) that undergo
singlet-doublet transitions. Moreover, by tuning gate voltages we achieve
gate-controlled resonating sign reversals of the nonlocal conductance,
identifying three distinct regimes that correspond to different configurations
of quantum-dot(QD) resonances(single-resonance, double-resonance, and
series-resonance). Finally, the coupling between ABSs and QDs also present and
can be modulated from the weak- to strong-coupling limit, indicating the
feasibility of realizing the artificial Kitaev chains. Crucially, the robust
nonlocal signatures persist up to temperatures(~1K) far above the operating
temperature of Al-based devices thanks to the unusually large induced gap,
thereby widening the accessible parameter space greatly and underscoring the
suitability of Pb-based hybrids for implementing warm temperature artificial
Kitaev chains and the topological quantum devices protected by a substantially
larger topological gap.

</details>


### [878] [Spin exchange of two spin-1/2 atoms](https://arxiv.org/abs/2510.10091)
*Pan Zeming,Tan Naiming,Gao Chao,Yao Zhihai,Wang Xiaoqian*

Main category: quant-ph

TL;DR: 量子“柴郡猫”效应揭示了物理属性与其载体的可分离性，并通过计算和数值模拟验证了该效应在费米子系统中的可行性。


<details>
  <summary>Details</summary>
Motivation: 量子“柴郡猫”效应揭示了物理属性与其载体的可分离性，这超越了经典物理学关于属性必须固有地附属于物体的框架，为量子信息和精密测量提供了新的视角。

Method: 通过预选择过程制备自旋1/2原子系统的预选态，并利用虚时演化（ITE）方法对两个原子的自旋和位置进行量子弱测量和弱值提取。随后，对这两个原子进行后选择，设计了两种不同的后选择态，并分别计算了两种不同后选择态下两个原子的解析解，最后将解析解与数值解进行比较。

Result: 理论上证实了双体量子“柴郡猫”效应中费米子系统的可行性，并展示了延迟选择如何影响自旋1/2原子系统中的量子“柴郡猫”效应。

Conclusion: 研究在理论上证实了费米子系统在双体量子“柴郡猫”效应中的可行性，并阐明了延迟选择对自旋1/2原子系统量子“柴郡猫”效应的影响。

Abstract: The quantum Cheshire cat effect is an important phenomenon in quantum
mechanics that reveals the separability of physical properties from their
carriers. This effect transcends the classical framework whose attributes must
be inherently attached to objects, providing new perspectives for quantum
information and precision measurement. According to the quantum Cheshire cat
effect, we prepare a pre-selected state of a spin1/2 atomic system composed of
two particles through a pre-selection process. We conduct quantum weak
measurements on the spins and positions of these two atoms and extract weak
values by using the method of imaginary time evolution(ITE). Subsequently, we
perform post-selection on these two atoms and design two distinct post-selected
states. Initially, we calculate analytical solutions when both atoms encounter
these two different post-selected states separately. We also compare the
analytical and numerical solutions. Our research theoretically confirms the
feasibility of fermionic systems within bipartite quantum Cheshire cat effects
and illustrates how delayed-choice influences quantum Cheshire cat effects in
spin-1/2 atomic systems.

</details>


### [879] [On the Noisy Road to Open Quantum Dynamics: The Place of Stochastic Hamiltonians](https://arxiv.org/abs/2510.10137)
*Pietro De Checchi,Federico Gallina,Barbara Fresch,Giulio G. Giusteri*

Main category: quant-ph

TL;DR: 随机演化是开放量子系统动力学的一种方法，可以通过集成随机微积分概念来统一和实现。


<details>
  <summary>Details</summary>
Motivation: 为了提供对随机演化在开放量子系统动力学中的应用的清晰、自给自足的介绍，并阐述其共同的根源和等价性条件。

Method: 通过检查随机演化（例如，哈密顿量参数的随机调制、随机薛定谔方程（SSE）和随机李维尔方程（SLE））的各种方法，重点关注随机微积分概念。

Result: 得出了一个统一的视角，并为随机演化在开放量子系统模拟中的经典和量子实现提供了可行的方案。

Conclusion: 该分析为模拟开放量子系统中的随机演化提供了统一的视角，并为经典和量子实现提供了可行的方案。

Abstract: Stochastic evolution underpins several approaches to the dynamics of open
quantum systems, such as random modulation of Hamiltonian parameters, the
stochastic Schr\"odinger equation (SSE), and the stochastic Liouville equation
(SLE). In a stochastic formulation, the open-system problem is reduced from a
coupled system-environment dynamics to an effective system-only description,
with dissipative evolution recovered by ensemble averaging. In this work, we
aim at a self-contained and accessible presentation of these approaches to
further elaborate on their common roots in essential concepts of stochastic
calculus and to delineate the conditions under which they are equivalent. We
also discuss how different formulations naturally lead to different numerical
time-integration schemes, better suited for either classical simulation
platforms, based on finite-difference approximations, or quantum algorithms,
that employ random unitary maps. Our analysis supplies a unified perspective
and actionable recipes for classical and quantum implementations of stochastic
evolution in the simulation of open quantum systems.

</details>


### [880] [Features of preparable entangled states in Gaussian quantum networks](https://arxiv.org/abs/2510.10167)
*Shuanping Du,Zhaofang Bai*

Main category: quant-ph

TL;DR: 大型量子网络可以通过多源量子网络确定性地制备纠缠态，但目前缺乏有效的方法来验证制备的单体多分复合纠缠态。本研究分析了三种基本高斯量子网络（三角形、星形和链状）在什么条件下可以制备纠缠态，并推导了所有可制备纠缠高斯态的必要条件，证明了网络结构对可制备纠缠高斯态集合的强约束作用，这与标准的单体多分复合纠缠有本质区别。


<details>
  <summary>Details</summary>
Motivation: 缺乏有效验证多源量子网络能否制备单体多分复合纠缠态的方法。

Method: 理论分析了三种基本高斯量子网络（三角形、星形和链状）制备纠缠态的条件，并推导了必要条件。

Result: 网络结构对可制备纠缠高斯态集合施加了强约束，这与标准的单体多分复合纠缠有本质区别。

Conclusion: 本研究是理解制备纠缠高斯态的网络机制的第一步。

Abstract: Large-scale quantum networks have been employed to overcome practical
constraints on transmission and storage for single entangled systems. The
deterministic preparation of entangled states is one of the key factors for
realization of quantum networks. There is no efficient method to verify whether
single multipartite entanglement can be prepared by multisource quantum
networks. Here, we theoretically analysize under what conditions entangled
states can be prepared in three kinds of basic Gaussian quantum networks, named
triangle networks, star-shaped networks and chain-type networks. Some necessity
criteria are derived for all preparable entangled Gaussian states in such
networks. It shows that the network structure imposes strong constraints on the
set of preparable entangled Gaussian states, which is fundamentally different
with the standard single multipartite entanglement. This takes the first step
towards understanding network mechanism for preparing entangled Gaussian
states.

</details>


### [881] [Universal Manipulation of Quantum Synchronization in Spin Oscillator Networks](https://arxiv.org/abs/2510.10187)
*Shuo Dai,Zeqing Wang,Liang-Liang Wan,Weidong Li,Augusto Smerzi,Ran Qi,Jianwen Jie*

Main category: quant-ph

TL;DR: 提出了一种可扩展且通用的量子同步（QS）调控方法，通过改变各向异性耦合，可以在完全同步和完全同步阻塞（QSB）之间连续调控，且不依赖耗散工程，适用于从少体到宏观的系统。


<details>
  <summary>Details</summary>
Motivation: 现有量子同步（QS）调控方法依赖耗散工程，存在失真、扩展性差和系统依赖性强等问题。

Method: 通过连续调控各向异性耦合，从各向同性相互作用下的最大同步到全向异性耦合下的完全同步阻塞（QSB），并分析了QS的起源（自旋翻转过程和高阶相关性）以及各向异性相互作用诱导的非同步相干性。

Result: 提出了一种通用的QS调控方法，可以从完全同步连续调控到完全同步阻塞（QSB），且能保持内禀极限环。量子几何测度表明在热力学极限下存在宏观QSB效应。

Conclusion: 该方法是可扩展的、通用的，并且在实验上是可行的，为复杂量子网络和物质动力学相的同步控制提供了新框架。

Abstract: Quantum synchronization (QS) in open many-body systems offers a promising
route for controlling collective quantum dynamics, yet existing manipulation
schemes often rely on dissipation engineering, which distorts limit cycles,
lacks scalability, and is strongly system-dependent. Here, we propose a
universal and scalable method for continuously tuning QS from maximal
synchronization under isotropic interactions to complete synchronization
blockade (QSB) under fully anisotropic coupling in spin oscillator networks.
Our approach preserves intrinsic limit cycles and applies to both few-body and
macroscopic systems. We analytically show that QS arises solely from spin
flip-flop processes and their higher-order correlations, while anisotropic
interactions induce non-synchronizing coherence. A geometric QS measure reveals
a macroscopic QSB effect in the thermodynamic limit. The proposed mechanism is
experimentally feasible using XYZ interactions and optical pumping, and
provides a general framework for programmable synchronization control in
complex quantum networks and dynamical phases of matter.

</details>


### [882] [On the validity of intermediate tracing in multiple quantum interactions](https://arxiv.org/abs/2510.10319)
*Reuven Ianconescu,Bin Zhang,Aharon Friedman,Jacob Scheuer,Avraham Gover*

Main category: quant-ph

TL;DR: 该研究提出了一种在量子系统中有效处理连续相互作用的方法，特别是当一个“目标”系统与一系列不相互作用的“入射”系统依次相互作用时。


<details>
  <summary>Details</summary>
Motivation: 当多个独立的量子系统相互作用时，如何有效地准备和计算它们的测量结果是一个关键问题。特别是，当一个“目标”系统依次与多个“入射”系统相互作用，而这些“入射”系统本身不相互作用时，计算的复杂性会随着复合系统的维度呈指数增长。

Method: 提出了一种在量子系统中处理连续相互作用的计算方法。该方法允许在相互作用发生之前将一个新系统添加到复合系统中，并在相互作用结束后将其从中追踪出去，而无需显式计算整个巨大复合系统的演化。

Result: 提供了一个该方法的数学证明和一个计算示例，证明了在特定条件下，可以有效地处理这种逐步相互作用的场景，而无需处理巨大的复合系统。

Conclusion: 该研究表明，在适当的条件下，可以通过在相互作用前后添加和移除系统来简化处理连续相互作用的量子系统的计算，从而解决了处理大型复合系统带来的计算挑战。

Abstract: Interactions between many (initially separate) quantum systems raise the
question on how to prepare and how to compute the measurable results of their
interaction. When one prepares each system individually and let them interact,
one has to tensor multiply their density matrices and apply Hamiltonians on the
composite system (i.e. the system which includes all the interacting systems)
for definite time intervals. Evaluating the final state of one of the systems
after multiple consecutive interactions, requires tracing all other systems out
of the composite system, which may grow up to immense dimensions. For
computation efficiency during the interaction(s) one may consider only the
contemporary interacting partial systems, while tracing out the other non
interacting systems. In concrete terms, the type of problems to which we direct
this formulation is a ``target'' system interacting {\bf succesively} with
``incident'' systems, where the ``incident'' systems do not mutually interact.
For example a two-level atom, interacting succesively with free electrons, or a
resonant cavity interacting with radiatively free electrons, or a quantum dot
interacting succesively with photons. We refer to a ``system'' as one of the
components before interaction, while each interaction creates a ``composite
system''. A new interaction of the ``composite system'' with another ``system''
creates a ``larger composite system'', unless we trace out one of the systems
before this interaction. The scope of this work is to show that under proper
conditions one may add a system to the composite system just before it
interacts, and one may trace out this very system after it finishes to
interact. We show in this work a mathematical proof of the above property and
give a computational example.

</details>


### [883] [Fractional Aharonov-Bohm effect for retarded potentials](https://arxiv.org/abs/2510.10333)
*J. D. Franson*

Main category: quant-ph

TL;DR: 磁性Aharonov-Bohm效应可以用电子在封闭磁通量的干涉仪中产生的相位移动来解释，也可以解释为由产生磁场的螺线管中的电子产生的相位移动。 本文使用二阶量子场论推导了Aharonov-Bohm效应，以一致的方式描述所有电子以及电磁场。 结果与通常的Aharonov-Bohm效应表达式一致，当 the retardation of the electromagnetic field is negligible，但它们预测当 the retardation effects are significant 时，可能发生分数相位移动。


<details>
  <summary>Details</summary>
Motivation: 磁性Aharonov-Bohm效应的两种解释，以及用二阶量子场论推导该效应。

Method: 使用二阶量子场论描述电子和电磁场，推导Aharonov-Bohm效应。

Result: 当电磁场延迟可忽略时，结果与常规表达式一致；当电磁场延迟显著时，预测可能出现分数相位移动。

Conclusion: Aharonov-Bohm效应的二阶量子场论推导，并考虑了电磁场延迟的影响。

Abstract: It has been suggested that the magnetic Aharonov-Bohm effect can be
interpreted equally well as being due to a phase shift associated with an
electron in an interferometer enclosing a magnetic flux, or as a phase shift
associated with the electrons in the solenoid that generates the field. Here
the Aharonov-Bohm effect is derived using second-quantized field theory to
describe all the electrons as well as the electromagnetic field in a consistent
way. The results are in agreement with the usual expression for the
Aharonov-Bohm effect when the retardation of the electromagnetic field is
negligible, but they predict the possibility of a fractional phase shift when
retardation effects are significant.

</details>


### [884] [Monogamy of Gaussian quantum steering and entanglement in a hybrid qubit-cavity optomagnonic system with coherent feedback loop](https://arxiv.org/abs/2510.10334)
*Hamza Harraf,Mohamed Amazioug,Amjad Sohail,Rachid Ahl Laamara*

Main category: quant-ph

TL;DR: 量子关联的互斥性是量子信息处理中的基本原理，它限制了量子关联如何在多个子系统之间共享。本研究提出了一个理论方案，利用包含相干反馈回路的混合量子比特-腔光磁系统来研究量子转向和三方真实纠缠的互斥性。研究量化了纠缠和转向性，并验证了CKW型互斥不等式，该不等式通过调整三方模式之间的反射参数和温度，使得转向性具有互斥性。结果表明，相干反馈回路可以在热效应下增强纠缠和量子转向。


<details>
  <summary>Details</summary>
Motivation: 量子关联的互斥性是量子信息处理中的基本原理，它限制了量子关联如何在多个子系统之间共享。

Method: 使用对数负熵和高斯量子转向来量化纠缠和转向性，并验证CKW型互斥不等式。

Result: 量子转向可以通过调整三方模式之间的反射参数和温度来达到互斥性。相干反馈回路可以在热效应下增强纠缠和量子转向。

Conclusion: 本研究提出了一个理论方案，利用包含相干反馈回路的混合量子比特-腔光磁系统来研究量子转向和三方真实纠缠的互斥性。研究量化了纠缠和转向性，并验证了CKW型互斥不等式，该不等式通过调整三方模式之间的反射参数和温度，使得转向性具有互斥性。结果表明，相干反馈回路可以在热效应下增强纠缠和量子转向。

Abstract: The monogamy of quantum correlations is a fundamental principle in quantum
information processing, limiting how quantum correlations can be shared among
multiple subsystems. Here we propose a theoretical scheme to investigate the
monogamy of quantum steering and genuine tripartite entanglement in a hybrid
qubit-cavity optomagnonic system with a coherent feedback loop. Using
logarithmic negativity and Gaussian quantum steering, we quantify entanglement
and steerability, respectively. We verify the CKW-type monogamy inequalities
which leads to steering monogamous through adjustments of the reflective
parameter among three tripartite modes versus temperature. Our results show
that a coherent feedback loop can enhance entanglement and quantum steering
under thermal effects.

</details>


### [885] [Depth One Quantum Alternating Operator Ansatz as an Approximate Gibbs Distribution Sampler](https://arxiv.org/abs/2510.10345)
*Elijah Pelofske*

Main category: quant-ph

TL;DR: QAOA（量子近似优化算法的推广）在深度为1时，可以通过选择合适的角度，利用 Grover 混合器或 X 混合器来近似采样玻尔兹曼分布，其中 Grover 混合器在高 তাপমাত্রা下表现更优。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究量子近似优化算法（QAOA）的热采样特性，特别是其对经典伊辛模型的玻尔兹曼分布进行采样的能力。

Method: 通过数值模拟，研究了两种不同的 QAOA 混合器（标准横向场 X 混合器和 Grover 混合器）在深度为 1 时，对全连接无序自旋玻璃（Sherrington-Kirkpatrick）模型进行采样的行为。分析了能量景观、概率分布的香农熵以及玻尔兹曼分布采样温度和误差率之间的权衡。

Result: 在深度为 1 时，两种混合器都可以作为近似玻尔兹曼分布的采样器。在高温下，Grover 混合器比 X 混合器能更准确地从玻尔兹曼分布中采样。采样精度很大程度上取决于 QAOA 参数（角度）的选择。

Conclusion: QAOA 在深度为 1 时，能够近似采样玻尔兹曼分布，其采样效果与参数选择以及所使用的混合器类型有关。Grover 混合器在高温度下展现出更好的采样性能。

Abstract: This study numerically investigates the thermal sampling properties of QAOA,
the Quantum Alternating Operator Ansatz which was generalized from the original
Quantum Approximate Optimization Algorithm. Specifically, the ability of QAOA
to sample from the Gibbs distribution, equivalently the Boltzmann distribution,
defined by a classical Ising model, specifically a fully connected disordered
spin glass (Sherrington-Kirkpatrick) model. We focus on two different QAOA
mixers; the standard transverse field X mixer, and the Grover mixer. At a QAOA
depth of one we examine, for a single full QAOA parameter search space period,
the energy landscape, the Shannon entropy landscape of the QAOA probability
distribution, and the tradeoff between Boltzmann distribution sampling
temperature and error rate (how close to the true Boltzmann distribution is the
QAOA distribution). We find that at very high temperatures one-round Grover
mixer QAOA can sample from the Boltzmann distribution more accurately than the
standard X mixer QAOA at one round. Both X mixer and Grover mixer depth one
QAOA can serve as approximate Boltzmann distribution samplers, and how good
this approximation is depends heavily on the QAOA angle choice.

</details>


### [886] [Electron Lateral Trapping Induced by Non-Uniform Thickness in Solid Neon Layers](https://arxiv.org/abs/2510.10351)
*Toshiaki Kanai,Chuanwei Zhang*

Main category: quant-ph

TL;DR: 电子电荷量子比特在固态氖上方的侧向束缚机制尚未完全阐明，特别是在实验常用的薄氖层中。本研究理论上探讨了氖层厚度和非均匀性对电子束缚的影响，发现增加厚度可以显著增强电子的结合能。在此基础上，提出了一种利用纳米图案化基底的厚度变化来产生侧向束缚势的新机制，该势可由垂直电场调控，为构建量子计算的多量子比特系统提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 固态氖上方的电子电荷量子比特是量子计算的新兴平台，但其侧向束缚的物理起源，尤其是在薄层和非均匀氖层中的行为，尚未完全理解。

Method: 理论研究了固态氖层有限厚度和非均匀性对电子束缚的影响，并提出了一种利用纳米图案化基底诱导的厚度变化产生侧向束缚势的机制。

Result: 对于10 nm厚的氖层，电子结合能相比于本体氖增强了三倍。提出的纳米图案化基底机制产生的侧向束缚势可以通过垂直电场进行精细调控。

Conclusion: 利用氖层厚度依赖性产生的非均匀厚度诱导电子电荷量子比特，为构建用于量子计算的多量子比特系统提供了一条可行的途径。

Abstract: Recent experimental advances highlight electron charge qubits floating above
solid neon as an emerging promising platform for quantum computing, but the
physical origin of single-electron lateral trapping is still not fully
understood. While prior theoretical work has mainly examined electrons above
bulk solid neon, experimental systems usually feature neon layers of only
$\lesssim 10$ nm thickness and non-uniformity, highlighting unresolved
questions about how thickness influences electron trapping. Here we
theoretically investigate the effect of finite thickness and non-uniformity of
solid neon layers on electron trapping. For a 10 nm layer, the electron binding
energy is enhanced threefold compared to bulk. Exploiting this thickness
dependence, we propose a nanopatterned-substrate mechanism in which engineered
thickness variations generate lateral trapping potentials for electrons. The
lateral trapping potential can be finely tuned by a perpendicular electric
field. Such non-uniform-thickness induced electron charge qubits open a viable
pathway toward building multi-qubit systems for quantum computation.

</details>


### [887] [Spectrally controlled dissipation in a target subsystem](https://arxiv.org/abs/2510.10394)
*Man Yin Cheung,Mona Berciu,Kyle Monkman*

Main category: quant-ph

TL;DR: 该研究提出了一种基于微观哈密顿量时间演化来驱动目标系统达到稳态的方法，并展示了其在量子比特复位和可调混合态制备方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够将量子系统驱动到特定稳态（纯态或混合态）的方法，以实现量子比特复位和可调混合态制备等功能，同时探索了与传统Lindblad描述不同的谱控耗散机制。

Method: 通过在ancilla+target系统上进行微观哈密顿量时间演化，实现目标系统的稳态演化，并利用谱测度理论保证向稳态的趋同。

Result: 证明了该方法可以根据目标系统的能量尺度，使其达到预期的稳态或部分停留在初始状态。该协议可作为独立的量子比特复位，也可作为可调混合态制备。

Conclusion: 所提出的谱控耗散机制为工程耗散提供了一种新的设计原理，并为可调的自主量子控制开辟了道路，这种控制方式在常见的开放系统Lindblad描述中并不存在。

Abstract: We present a microscopic Hamiltonian time-evolution on an ancilla+target
system that evolves the target to a steady state. Using this description, we
demonstrate the potential of a spectrally controllable dissipator: Depending on
the energy scale of the target, the subsystem reaches the intended steady state
or remains partially trapped in the initial state. For a steady state which is
pure, this protocol can function as an autonomous qubit reset. We can also
choose a mixed steady state so that this functions as a tunable mixed-state
preparation. With a particular dissipative condition, we guarantee the
equilibration to the steady-state with spectral measure theory. This type of
spectral control over dissipation is not present in the common Lindblad
description of open systems. Our construction establishes a new design
principle for engineered dissipation and opens a pathway toward tunable
autonomous quantum control.

</details>


### [888] [Oscillator-qubit generalized quantum signal processing for vibronic models: a case study of uracil cation](https://arxiv.org/abs/2510.10495)
*Jungsoo Hong,Seong Ho Kim,Seung Kyu Min,Joonsuk Huh*

Main category: quant-ph

TL;DR: A compiler for hybrid oscillator-qubit processors is presented, enabling efficient implementation of quantum algorithms by synthesizing arbitrary bosonic phase gates using generalized quantum signal processing (GQSP). This approach avoids overheads of discrete encodings and shows linear dependence on vibration modes, validated on the uracil cation.


<details>
  <summary>Details</summary>
Motivation: Most quantum algorithms are limited to homogeneous architectures. This work aims to provide a compiler for hybrid oscillator-qubit processors to enable more versatile quantum algorithm implementation.

Method: The compiler invokes generalized quantum signal processing (GQSP) to synthesize arbitrary bosonic phase gates with moderate circuit depth. This method decomposes nonadiabatic molecular dynamics with arbitrary-phase potential propagators and avoids the overhead of truncating continuous variables.

Result: The approach shows linear dependence on the number of vibration modes, trading success probability for circuit depth. The method is validated on the uracil cation, estimating the cost for state preparation and time evolution.

Conclusion: The developed compiler, utilizing GQSP, offers an efficient way to implement quantum algorithms on hybrid oscillator-qubit processors, overcoming limitations of homogeneous architectures and providing a method for accurate molecular dynamics modeling.

Abstract: Hybrid oscillator-qubit processors have recently demonstrated high-fidelity
control of both continuous- and discrete-variable information processing.
However, most of the quantum algorithms remain limited to homogeneous quantum
architectures. Here, we present a compiler for hybrid oscillator-qubit
processors, implementing state preparation and time evolution. In hybrid
oscillator-qubit processors, this compiler invokes generalized quantum signal
processing (GQSP) to constructively synthesize arbitrary bosonic phase gates
with moderate circuit depth O(log(1/{\varepsilon})). The approximation cost is
scaled by the Fourier bandwidth of the target bosonic phase, rather than by the
degree of nonlinearity. Armed with GQSP, nonadiabatic molecular dynamics can be
decomposed with arbitrary-phase potential propagators. Compared to fully
discrete encodings, our approach avoids the overhead of truncating continuous
variables, showing linear dependence on the number of vibration modes while
trading success probability for circuit depth. We validate our method on the
uracil cation, a canonical system whose accurate modeling requires anharmonic
vibronic models, estimating the cost for state preparation and time evolution.

</details>


### [889] [Quantum Integration Networks for Efficient Monte Carlo in High-Energy Physics](https://arxiv.org/abs/2510.10501)
*Heechan Yi,Kayoung Ban,Myeonghun Park,Kyoungchul Kong*

Main category: quant-ph

TL;DR: 量子积分网络（QuInt-Net）利用量子计算优化蒙特卡洛方法在粒子物理中的应用，通过比较不同的采样策略、损失函数和量子电路架构，提高了数值积分的效率和精度。


<details>
  <summary>Details</summary>
Motivation: 传统的蒙特卡洛方法在处理具有奇异特征的函数时收敛缓慢且精度不足，而量子计算具有表达能力强、参数少、梯度优化精确等优点，可用于改进此问题。

Method: 研究了自适应和非自适应采样方法，以及不同损失函数对QuInt-Net中积分精度和收敛性的影响。同时，探索了数据重构模型、量子信号处理协议和单量子比特确定性量子计算这三种量子电路架构在数值积分中的应用。

Result: 比较了不同的采样策略、损失函数和量子电路架构对QuInt-Net积分效率的影响，为高能物理应用优化QuInt-Net提供了新的见解。

Conclusion: 量子计算方法，特别是QuInt-Net，在优化蒙特卡洛方法方面显示出巨大潜力，能够克服传统方法的局限性，为粒子物理等领域的计算提供更精确、高效的解决方案。

Abstract: Monte Carlo methods play a central role in particle physics, where they are
indispensable for simulating scattering processes, modeling detector responses,
and performing multi-dimensional integrals. However, traditional Monte Carlo
methods often suffer from slow convergence and insufficient precision,
particularly for functions with singular features such as rapidly varying
regions or narrow peaks. Quantum circuits provide a promising alternative:
compared to conventional neural networks, they can achieve rich expressivity
with fewer parameters, and the parameter-shift rule provides an exact analytic
form for circuit gradients, ensuring precise optimization. Motivated by these
advantages, we investigate how sampling strategies and loss functions affect
integration efficiency within the \textbf{Quantum Integration Network}
(QuInt-Net). We compare adaptive and non-adaptive sampling approaches and
examine the impact of different loss functions on accuracy and convergence.
Furthermore, we explore three quantum circuit architectures for numerical
integration: the data re-uploading model, the quantum signal processing
protocol, and deterministic quantum computation with one qubit. The results
provide new insights into optimizing QuInt-Nets for applications in high energy
physics.

</details>


### [890] [Gravitational and other shifts of neutron, hydrogen, antihydrogen, muonium, and positronium whispering gallery and gravitational state interference patterns](https://arxiv.org/abs/2510.10536)
*V. V. Nesvizhevsky,J. A. Pioquinto,K. Schreiner,S. Baessler,P. Crivelli,E. Widmann*

Main category: quant-ph

TL;DR: The paper discusses the potential for observing whispering-gallery interference patterns with various particles (neutrons, atoms, antimatter, muonium, positronium) and forces (magnetic, gravitational). It highlights the feasibility of gravitational shifts with cold neutrons and proposes similar experiments with hydrogen and antihydrogen. The study also touches upon quantum reflection properties and their applications in fundamental physics and surface studies.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the recent measurement of a neutron whispering-gallery interference pattern shift due to a magnetic field gradient and the analogy that similar phenomena can be observed with other particles and forces, particularly gravity. The authors aim to explore the feasibility and potential applications of observing gravitational shifts in whispering-gallery experiments with various particles, including neutrons, hydrogen, antihydrogen, muonium, and positronium.

Method: The paper proposes and evaluates parameters for observing whispering-gallery phenomena and their gravitational shifts with neutrons, hydrogen, antihydrogen, muonium, and positronium. It mentions planned measurements with neutrons at ILL facilities and with hydrogen/deuterium atoms by the GRASIAN collaboration. The study also considers the relevance for experiments at CERN like GBAR and ASACUSA, and acknowledges the experimental challenges for muonium and positronium due to their short lifetimes.

Result: The paper suggests that gravitational shifts of neutron whispering galleries are easily observable with cold neutrons, and similar methods can be used for measuring the gravitational constant or constraining the neutron electric charge. It evaluates parameters making measurements with hydrogen and antihydrogen feasible. The authors also note that while whispering-gallery states might be observable with muonium and positronium, it remains experimentally challenging, especially the observation of gravitational shifts due to extremely short lifetimes.

Conclusion: The observation of whispering gallery phenomena and their gravitational shifts with a variety of particles, including neutrons, atoms, antimatter, muonium, and positronium, offers unique insights into quantum reflection properties at surfaces. These measurements can provide valuable data for both fundamental physics studies and surface science applications.

Abstract: Recently, a shift of a neutron whispering-gallery interference pattern due to
an external magnetic field gradient was measured. By analogy, a similar
phenomenon can be observed with other particles and forces. In particular, a
gravitational shift of the neutron whispering gallery can be easily observed
with cold or very cold or ultracold neutrons, and the developed methods can be
used for observing/searching for other shifts in fundamental neutron physics
experiments, for instance, for measuring the gravitational constant or
constraining the neutron electric charge. A peculiar feature of analogous
atomic (anti-atomic) experiments is the much smaller effective critical
energies of the materials of atomic (anti-atomic) mirrors. We evaluated
parameters that make a measurement of the hydrogen and antihydrogen whispering
gallery and their gravitational shifts feasible. A series of such measurements
will be made with neutrons at the PF1B/PF2/D17 facilities at the ILL, as well
as with hydrogen or/and deuterium atoms by the GRASIAN collaboration in Vienna
and Turku. Such a measurement with antihydrogen atoms may be of interest for
the GBAR experiment, the ASACUSA experiment which is producing a beam of slow
antihydrogen atoms, or other experiments at CERN, which study the gravitational
properties of antimatter. Quantum reflection of muonium and positronium from
material surfaces opens the possibility of observing whispering-galley states,
although such measurements remain experimentally challenging. The observation
of gravitational shifts is particularly demanding because of the extremely
short lifetimes of these systems. Measurements of whispering gallery with all
these atoms and particles yield unique information on the quantum reflection
properties at surfaces, providing valuable input for both fundamental and
surface studies.

</details>


### [891] [Quantum-Squeezing-Induced Algebraic Non-Hermitian Skin Effects and Ultra Spectral Sensitivity](https://arxiv.org/abs/2510.10632)
*Zhao-Fan Cai,Tao Liu*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The well-established non-Bloch band theory predicts exponential localization
of skin-mode eigenstates in one-dimensional (1D) non-Hermitian systems. Recent
studies, however, have uncovered anomalous algebraic localization in higher
dimensions. Here, we extend these ideas to Hermitian bosonic quadratic
Hamiltonians incorporating quantum squeezing, offering a genuine quantum
framework to explore non-Hermitian phenomena without external reservoirs. We
construct a two-dimensional (2D) bosonic lattice model with two-mode squeezing
and study its spectral properties of bosonic excitation within the
Bogoliubov-de Gennes (BdG) formalism. We demonstrate an algebraic non-Hermitian
skin effect (NHSE), characterized by quasi-long-range power-law localization of
complex eigenstates. The system shows ultra spectral sensitivity to double
infinitesimal on-site and long-range hopping impurities, while remaining
insensitive to single impurities. Analytical treatment via the Green's function
reveals that this sensitivity originates from the divergence of the nonlocal
Green's function associated with the formation of nonlocal bound states between
impurities. Our study establishes a framework for realizing novel
higher-dimensional non-Hermitian physics in Hermitian bosonic platforms such as
superconducting circuits, photonic lattices, and optomechanical arrays, with
the demonstrated ultraspectral sensitivity enabling quantum sensing and
amplification via bosonic squeezing.

</details>


### [892] [One-Query Quantum Algorithms for the Index-$q$ Hidden Subgroup Problem](https://arxiv.org/abs/2510.10538)
*Amit Te'eni,Yaron Oz,Eliahu Cohen*

Main category: quant-ph

TL;DR: 文章重新审视了量子傅里叶变换（QFT）在经典查询问题中的必要性，并针对索引-q隐藏子群问题（HSP）提出了单查询算法，该算法在特定条件下可用于识别隐藏子群。


<details>
  <summary>Details</summary>
Motivation: 重新审视量子傅里叶变换（QFT）在经典查询问题中的必要性，并引入和解决索引-q隐藏子群问题（HSP）。

Method: 提出一个单查询算法，该算法可以区分索引1和索引q的隐藏子群。在满足特定条件（例如，G/H是阶为q的循环群，且输出字母表承认忠实的、兼容的群结构）的情况下，该算法可以通过一次查询精确识别隐藏子群H。该算法利用了预置和后置oracle幺正变换（G上的逆QFT/QFT）。

Result: 该单查询算法总是能区分索引1和索引q。在满足特定条件下，该算法可以精确识别隐藏子群H。对于q=2或q=3的情况，算法能在无条件的情况下实现单查询精确识别。与Shor-Kitaev的采样方法不同，该方法不能保证从单一样本中恢复。这些结果明确了阿贝尔HSP单查询可解性的情况。

Conclusion: 文章提出的单查询算法在特定条件下可以精确识别索引-q隐藏子群，并在q=2和q=3时提供无条件的精确识别，从而改进了对阿贝尔HSP单查询可解性的理解。

Abstract: The quantum Fourier transform (QFT) is central to many quantum algorithms,
yet its necessity is not always well understood. We re-examine its role in
canonical query problems. The Deutsch-Jozsa algorithm requires neither a QFT
nor a domain group structure. In contrast, the Bernstein-Vazirani problem is an
instance of the hidden subgroup problem (HSP), where the hidden subgroup has
either index $1$ or $2$; and the Bernstein-Vazirani algorithm exploits this
promise to solve the problem with a single query. Motivated by these insights,
we introduce the index-$q$ HSP: determine whether a hidden subgroup $H \le G$
has index $1$ or $q$, and, when possible, identify $H$. We present a
single-query algorithm that always distinguishes index $1$ from $q$, for any
choice of abelian structure on the oracle's codomain. Moreover, with suitable
pre- and post-oracle unitaries (inverse-QFT/QFT over $G$), the same query
exactly identifies $H$ under explicit minimal conditions: $G/H$ is cyclic of
order $q$, and the output alphabet admits a faithful, compatible group
structure. These conditions hold automatically for $q \in \left\{ 2,3
\right\}$, giving unconditional single-query identification in these cases. In
contrast, the Shor-Kitaev sampling approach cannot guarantee exact recovery
from a single sample. Our results sharpen the landscape of one-query quantum
solvability for abelian HSPs.

</details>


### [893] [Tunable multi-photon correlations from a coherently driven quantum dot](https://arxiv.org/abs/2510.11159)
*Thomas K. Bracht,Rachel N. Clark,Petros Androvitsaneas,Matthew Jordan,Samuel G. Bishop,Harry E. Dyte,Moritz Cygorek,Ian A. Farrer,Doris E. Reiter,Anthony J. Bennett*

Main category: quant-ph

TL;DR: 通过混合由不同光源产生的光场，可以工程化非高斯量子态。


<details>
  <summary>Details</summary>
Motivation: 理解和控制由此产生的 संशोध统计对于以干涉为基础的新兴量子技术很有用。

Method: 研究了由量子发射体和相干激光场的共振荧光干涉产生的强度相关函数。

Result: 通过调整混合比和相位，可以实现从反聚束到聚束的全二阶相关函数可调性。

Conclusion: 通过实验和理论分析了三阶相关函数，为解释高阶相关函数提供了新的见解，并为塑造量子光学场提供了实用的工具。

Abstract: Mixing the fields generated by different light sources has emerged as a
powerful approach for engineering non-Gaussian quantum states. Understanding
and controlling the resulting photon statistics is useful for emerging quantum
technologies that are underpinned by interference. In this work, we investigate
intensity correlation functions arising from the interference of resonance
fluorescence from a quantum emitter with a coherent laser field. We show that
the observed bunching behavior results from a subtle interplay between quantum
interference and the normalization of the correlation functions. We show that
by adjusting the mixing ratio and phase one can achieve full tunability of the
second-order correlation, ranging from anti-bunching to bunching. We further
extend our analysis to third-order correlation functions, both experimentally
and theoretically, to provide new insights into the interpretation of
higher-order correlations and offer practical tools for shaping quantum optical
fields.

</details>


### [894] [Beating the standard quantum limit with single-photon-added coherent states](https://arxiv.org/abs/2510.10565)
*Pankaj K. Jha,Lakshya Nagpal,Amir Targholizadeh,Utkarsh Mishra,Konstantin E. Dorfman*

Main category: quant-ph

TL;DR: 该研究使用单光子增广相干态和弱相干态作为输入，在马赫-曾德尔干涉仪中实现了超越标准量子极限（SQL）的相位传感。


<details>
  <summary>Details</summary>
Motivation: 量子测量精度受到光量子涨落的限制，标准量子极限（SQL）定义了这种限制。本研究旨在突破SQL的限制，尤其是在低光子数（<10）领域，以提升测量精度。

Method: 利用马赫-曾德尔干涉仪，输入单光子增广相干态和弱相干态，并与普通真空输入进行比较，以评估相位不确定性。

Result: 实验结果表明，在低光子数（<10）区域，该方案提供的相位灵敏度优于标准量子极限（SQL）。

Conclusion: 通过在低光子数区域超越SQL，该研究为“光子饥饿”的量子传感、光谱学和计量学领域的新一代设备奠定了基础。

Abstract: The standard quantum limit (SQL), also known as the shot-noise limit, defines
how quantum fluctuations of light constrain measurement precision. In a
benchmark experiment using the Mach-Zehnder interferometer (MZI), where a
coherent state with the average photon number $\langle n\rangle$ is combined
with an ordinary vacuum input, the SQL for the phase uncertainty is given by
the well-known relation $\Delta\varphi_{\text{SQL}} = 1/\langle n\rangle$.
Using a single photon-added coherent state and a weak coherent state as inputs,
we report an enhanced phase sensitivity in MZI surpassing the SQL. In stark
contrast to other approaches, we focus on the low-photon-number regime,
$\langle n\rangle < 10$, and demonstrate that our scheme offers better phase
sensitivity compared to the SQL. Beating the SQL at low photon numbers paves
the way for the new generation of devices employed in \textquotedblleft
photon-starved\textquotedblright quantum sensing, spectroscopy, and metrology.

</details>


### [895] [Uniformity Bias in Ground-State Sampling Induced by Replica Alignment in Quantum Monte Carlo for Quantum Annealing](https://arxiv.org/abs/2510.10566)
*Naoki Maruyama,Masayuki Ohzeki,Kazuyuki Tanaka*

Main category: quant-ph

TL;DR: 量子退火（QA）在采样简并基态时存在偏差，而量子蒙特卡洛（QMC）模拟QA时，由于“下坡”和“副本对齐”的效应，倾向于产生均匀的基态概率分布，无法准确复现QA的偏差。这种偏差源于Trotter副本对齐，其中副本不匹配的“扭结”构型在能量上受到抑制且熵减少。


<details>
  <summary>Details</summary>
Motivation: 研究量子蒙特卡洛（QMC）模拟量子退火（QA）时，在采样简并基态方面的准确性，特别是QMC能否复现QA的采样偏差。

Method: 通过比较QMC主方程和薛定谔方程得到的最终基态分布，定量评估QMC再现QA采样偏差的准确性。

Result: QMC倾向于产生均匀的基态概率分布，这与QA的偏差分布不同；并且随着退火的进行，这种均匀性偏差会增强。

Conclusion: 离散时间QMC在忠实模拟QA动力学方面存在根本性局限，因为“副本对齐”效应（Trotter副本重合的构型占主导地位）源于“扭结”构型（副本不匹配）的能量抑制和熵减少。这强调了副本相关性和转移规则在实现真实基态采样中的重要性。

Abstract: Quantum annealing (QA) with a transverse field often fails to sample
degenerate ground states fairly, limiting applicability to problems requiring
diverse optimal solutions. Although Quantum Monte Carlo (QMC) is widely used to
simulate QA, its ability to reproduce such unfair ground-state sampling remains
unclear because stochastic and coherent quantum dynamics differ fundamentally.
We quantitatively evaluate how accurately QMC reproduces the sampling bias in
QA by comparing the final ground-state distributions from the QMC master
equation and the Schr\"odinger equation. We find QMC tends to produce uniform
ground-state probabilities, unlike QA's biased distribution, and that this
uniformity bias strengthens as annealing proceeds. Our analysis reveals that
this bias originates from replica alignment -- the dominance of configurations
in which all Trotter replicas coincide -- caused by the energetic suppression
and entropic reduction of kink configurations (replica mismatches). These
findings clarify a fundamental limitation of discrete-time QMC in faithfully
simulating QA dynamics, highlighting the importance of replica correlations and
transition rules in achieving realistic ground-state sampling.

</details>


### [896] [Liouvillian Exceptional Points in Quantum Brickwork Circuits](https://arxiv.org/abs/2510.10629)
*Vladislav Popkov,Mario Salerno*

Main category: quant-ph

TL;DR: Liouvillian exceptional points (LEPs) and their sensing properties exist in discrete brickwork CPTP circuits, not just continuous Lindbladian dynamics.


<details>
  <summary>Details</summary>
Motivation: The motivation is to demonstrate the emergence of Liouvillian exceptional points (LEPs) and their associated sensing properties in discrete brickwork CPTP circuits, extending previous studies that were limited to continuous Lindbladian dynamics.

Method: The method involves systematically demonstrating the emergence of LEPs and their sensing properties in discrete brickwork CPTP circuits.

Result: The result is the first systematic demonstration that Liouvillian exceptional points (LEPs) and their associated sensing properties can emerge in discrete brickwork CPTP circuits, which is the natural framework for current quantum devices.

Conclusion: LEPs and their sensing properties, previously observed only in continuous systems, are now shown to exist in discrete stroboscopic quantum circuits.

Abstract: We provide the first systematic demonstration that Liouvillian exceptional
points (LEPs)and their associated sensing properties, previously studied only
in continuous Lindbladian dynamics, also emerge in discrete brickwork CPTP
circuits, the natural stroboscopic framework of present day quantum devices.

</details>


### [897] [Quantum Radar: An Engineering Perspective](https://arxiv.org/abs/2510.10699)
*Murat Can Karakoc,Ozgun Ersoy,Ahmad Salmanoghli Khiavi,Asaf Behzat Sahin*

Main category: quant-ph

TL;DR: 量子雷达利用微波纠缠来克服经典探测的局限性，并在实验室中得到验证。


<details>
  <summary>Details</summary>
Motivation: 量子雷达利用纠缠和量子关联来克服经典探测在嘈杂和有损环境中的局限性。

Method: 该综述提供了量子照明的理论基础，以及在微波区域中产生纠缠。它还检查了量子雷达子系统，例如量子传感器、放大器链和接收器架构。此外，它还回顾了微波领域的实验系统。

Result: 量子雷达系统可以通过利用超导设备产生的微波纠缠来实现更高的探测灵敏度、更低的错误概率以及更强的抗热噪声和抗干扰能力。

Conclusion: 量子雷达正从理论构建演变为实用的量子技术，能够扩展经典雷达的性能边界。

Abstract: Quantum radar has emerged as a promising paradigm that utilizes entanglement
and quantum correlations to overcome the limitations of classical detection in
noisy and lossy environments. By exploiting microwave entanglement generated
from superconducting devices such as Josephson parametric amplifiers,
converters, and traveling-wave parametric amplifiers, quantum radar systems can
achieve enhanced detection sensitivity, lower error probabilities, and greater
robustness against thermal noise and jamming. This review provides a
comprehensive overview of the field, beginning with the theoretical foundations
of quantum illumination and extending to the generation of entanglement in the
microwave regime. We then examine key quantum radar subsystems, including
quantum transducers, amplification chains, and receiver architectures, which
form the backbone of practical designs. Recent experimental systems are
surveyed in the microwave domain, highlighting proof-of-principle
demonstrations and their transition from conceptual frameworks to laboratory
realizations. Collectively, the progress reviewed here demonstrates that
quantum radar is evolving from a theoretical construct to a practical quantum
technology capable of extending the performance boundaries of classical radar.

</details>


### [898] [Automated discovery of high-dimensional multipartite entanglement with photons that never interacted](https://arxiv.org/abs/2510.10707)
*Sören Arlt,Mario Krenn,Xuemei Gu*

Main category: quant-ph

TL;DR: 通过路径同一性实现远程节点间的复杂量子纠缠，无需光子交互、预共享纠缠或贝尔态测量。


<details>
  <summary>Details</summary>
Motivation: 为了探索建立跨空间分离网络节点量子纠缠的新途径，提出了一种替代传统方法（如光子分发或纠缠交换）的路径同一性机制。

Method: 利用路径同一性机制，通过使来自不同源的光子在发射 origin 上不可区分，实现远程节点间复杂、多方、高维甚至逻辑纠缠。该方法不依赖于光子间的直接交互、预共享纠缠或贝尔态测量。

Result: 成功展示了路径同一性机制能够实现远程节点间从未交互过的光子的复杂、多方、高维甚至逻辑纠缠，并且所有方案均通过计算设计工具自动发现。

Conclusion: 路径同一性是一种独特的资源，可用于分布式量子通信和计算，并且计算算法有潜力为科学发现提供灵感。

Abstract: Quantum entanglement across spatially separated network nodes is
conventionally established through the distribution of photons from a common
source or via entanglement swapping that relies on Bell-state measurements and
pre-shared entanglement. Path identity, where the emission origins of photons
from different sources are made indistinguishable, offers an alternative route.
We show that this mechanism enables complex multipartite, high-dimensional, and
even logical entanglement between remote nodes whose photons never interacted.
Our schemes require neither direct photon interaction, pre-shared entanglement,
nor Bell-state measurements, highlighting a distinct resource for distributed
quantum communication and computation. All of the solutions were discovered
automatically using highly efficient computational design tools, indicating the
potential for scientific inspiration from computational algorithms.

</details>


### [899] [Extreme Capacities in Generalized Direct Sum Channels](https://arxiv.org/abs/2510.10711)
*Zhen Wu,Si-Qi Zhou*

Main category: quant-ph

TL;DR: 论文提出了一种广义直和（GDS）信道，用于研究量子信道容量的超加性现象，并揭示了量子容量、私有容量和经典容量之间的关系。


<details>
  <summary>Details</summary>
Motivation: 量子信道容量的精确计算由于超加性而变得棘手。本研究旨在通过构造广义直和（GDS）信道来深入理解这一现象。

Method: 通过在 Kraus 算符中引入直和结构，构造了广义直和（GDS）信道，并分析了其量子容量、私有容量和经典容量的特性。

Result: GDS 信道包含一些具有单字母容量公式的信道，也包含一些表现出显著容量特征的信道。研究发现，量子容量可以趋近于零但表现出与擦除信道相结合的无界超加性；私有容量和经典容量可以相等且任意大，与量子容量之间存在无界差距。

Conclusion: GDS 框架提供了一种更简单直观的方法来研究量子信道容量，加深了对量子信道容量及其相关现象的理解。

Abstract: Quantum channel capacities play a central role in quantum Shannon theory, a
formalism built upon rigorous coding theorems for noisy channels. Evaluating
exact capacity values for general quantum channels remains intractable due to
superadditivity. As a step toward understanding this phenomenon, we construct
the generalized direct sum (GDS) channel, extending conventional direct sum
channels through a direct sum structure in their Kraus operators. This
construction forms the basis of the GDS framework, encompassing classes of
channels with single-letter formula for quantum capacities and others
exhibiting striking capacity features. The quantum capacity can approach zero
yet display unbounded superadditivity combined with erasure channels. Private
and classical capacities coincide and can become arbitrarily large, resulting
in an unbounded gap with the quantum capacity. Providing a simpler and more
intuitive approach, the framework deepens our understanding of quantum channel
capacities.

</details>


### [900] [Quantum complementarity](https://arxiv.org/abs/2510.10800)
*Davide Rolino,Paolo Perinotti,Alessandro Tosini*

Main category: quant-ph

TL;DR: 量子系统中的互补性等同于操作的不兼容性。


<details>
  <summary>Details</summary>
Motivation: 阐述了Bohr互补性概念的背景，并提出操作性定义。

Method: 提出了互补性的操作性定义，并证明了在量子理论中，该定义等同于操作的不兼容性。

Result: 证明了互补性与操作不兼容性之间的等价关系。

Conclusion: 量子系统中的互补性概念可以通过操作不兼容性来操作化定义。

Abstract: We propose an operational definition of complementarity, pinning down the
concept originally introduced by Bohr. Two properties of a system are
considered complementary if they cannot be simultaneously well defined. We
further show that, within quantum theory, this notion is equivalent to the
incompatibility of operations -- that is, their inability to be performed
simultaneously.

</details>


### [901] [Sheared potentials and travelling nodes](https://arxiv.org/abs/2510.10808)
*Francisco M. Fernández*

Main category: quant-ph

TL;DR: 当势能变形方式保持经典转动点间距不变时，薛定谔方程的特征值会围绕导致变形的势能参数振荡，这与对应本征函数的节点通过原点密切相关。


<details>
  <summary>Details</summary>
Motivation: 研究当势能变形时，薛定谔方程的特征值与本征函数的节点行为之间的关系。

Method: 通过保持经典转动点间距不变的势能变形，并分析特征值的振荡和本征函数节点通过原点的现象。

Result: 证实了特征值的振荡与本征函数节点通过原点之间存在密切联系，并通过分裂谐振子势和分裂线性势进行了说明。

Conclusion: 特征值的振荡与本征函数节点通过原点密切相关。

Abstract: When a sheared potential is deformed in such a way that the distance between
the classical turning points remains constant the eigenvalues of the
Schr\"{o}dinger equation oscillate with respect to the potential parameter
responsible for the deformation. We show that such an oscillation is intimately
related to the passing of the nodes of the corresponding eigenfunctions through
the origin. We illustrate this effect by means of the split harmonic oscillator
and the split linear potential.

</details>


### [902] [Error thresholds of toric codes with transversal logical gates](https://arxiv.org/abs/2510.10835)
*Yichen Xu,Yiqing Zhou,James P. Sethna,Eun-Ah Kim*

Main category: quant-ph

TL;DR: 为抑制逻辑错误，容错量子计算依赖于物理错误率低于阈值。虽然横向门实现逻辑操作很有效，但它们会传播错误，可能降低阈值。我们通过将量子存储器推广到逻辑电路的统计力学（stat-mech）映射，来严格界定横向门错误传播的负面影响。我们建立了两个经受横向 CNOT (tCNOT) 门的 توریک码块的映射。通过这种映射，我们量化了两种独立错误传播机制的影响：物理比特翻转错误的传播和综合错误传播。对于前者，stat-mech 模型是二维随机 Ashkin-Teller 模型。数值模拟显示，tCNOT 门将最优比特翻转错误阈值降低到 p=0.080，比 توریک码存储器阈值 p=0.109 降低了 26%。综合错误与比特翻转错误共存的情况被映射到具有平面缺陷的三维随机四体伊辛模型。我们保守估计的错误阈值为 p=0.028，与存储器阈值 p=0.033 相比，综合错误传播的降幅更为温和。我们的工作表明，任意横向 Clifford 逻辑电路都可以映射到 stat-mech 模型，并相应地获得严格的阈值。


<details>
  <summary>Details</summary>
Motivation: 提供容错量子计算的理论基础，并通过严格的统计力学方法量化横向门操作对错误阈值的影响。

Method: 将量子存储器推广到逻辑电路的统计力学（stat-mech）映射，并对两个 توریک码块在横向 CNOT (tCNOT) 门下的映射进行量化，分析物理比特翻转错误和综合错误的传播机制。

Result: 通过数值模拟，证明横向 CNOT 门将最优比特翻转错误阈值降低到 p=0.080（降低 26%），并将综合错误阈值估计为 p=0.028（降低幅度小于存储器阈值 p=0.033）。

Conclusion: 横向 Clifford 逻辑电路可以映射到统计力学模型，从而获得严格的错误阈值。横向门操作确实会降低错误阈值，但其影响程度可以通过统计力学方法进行量化。

Abstract: The threshold theorem promises a path to fault-tolerant quantum computation
by suppressing logical errors, provided the physical error rate is below a
critical threshold. While transversal gates offer an efficient method for
implementing logical operations, they risk spreading errors and potentially
lowering this threshold compared to a static quantum memory. Available
threshold estimates for transversal circuits are empirically obtained and
limited to specific, sub-optimal decoders. To establish rigorous bounds on the
negative impact of error spreading by the transversal gates, we generalize the
statistical mechanical (stat-mech) mapping from quantum memories to logical
circuits. We establish a mapping for two toric code blocks that undergo a
transversal CNOT (tCNOT) gate. Using this mapping, we quantify the impact of
two independent error-spreading mechanisms: the spread of physical bit-flip
errors and the spread of syndrome errors. In the former case, the stat-mech
model is a 2D random Ashkin-Teller model. We use numerical simulation to show
that the tCNOT gate reduces the optimal bit-flip error threshold to $p=0.080$,
a $26\%$ decrease from the toric code memory threshold $p=0.109$. The case of
syndrome error coexisting with bit-flip errors is mapped to a 3D random 4-body
Ising model with a plane defect. There, we obtain a conservative estimate error
threshold of $p=0.028$, implying an even more modest reduction due to the
spread of the syndrome error compared to the memory threshold $p=0.033$. Our
work establishes that an arbitrary transversal Clifford logical circuit can be
mapped to a stat-mech model, and a rigorous threshold can be obtained
correspondingly.

</details>


### [903] [Magnon-rotation enhanced nonreciprocity of multipartite entanglement in a magnomechanical system](https://arxiv.org/abs/2510.10839)
*Hamza Harraf,Noura Chabar,Mohamed Amazioug,Rachid Ahl Laamara,Mojtaba Mazaheri*

Main category: quant-ph

TL;DR: 本研究提出了一种在磁力机械系统中研究双份和三份纠缠的非互易性并产生压缩态的方案。


<details>
  <summary>Details</summary>
Motivation: 量子信息处理中对非互易物理的研究兴趣日益浓厚。

Method: 通过源于第一磁振子模式旋转的巴内特效应，利用包含两个YIG球（每个球支撑一个代表集体自旋运动的磁振子模式）并位于微波腔（MC）内的系统来研究非互易性。

Result: 研究表明，巴内特效应增强了热效应对纠缠的影响，并为两个磁振子模式和光子模式产生了压缩态。此外，还发现磁振子-磁振子耦合增强了不同模式之间的纠缠。

Conclusion: 提出的方案能够有效利用巴内特效应增强纠缠并产生压缩态，为量子信息处理中的非互易性研究提供了新的途径。

Abstract: Nonreciprocal physics is attracting significant interest in quantum
information processing. In this work, we propose a scheme to investigate the
nonreciprocity of bi- and tripartite entanglement and generate squeezed states
in a magnomechanical system. This is achieved through the Barnett effect, which
originates from the rotation of the first magnon mode. The system consists of
two YIG spheres, each supporting a magnon mode that represents collective spin
motion, positioned inside a microwave cavity (MC). We show that the Barnett
effect enhances entanglement under thermal effects and generates squeezed
states for the two magnon modes and the photon mode. Moreover, we show that
magnon-magnon coupling enhances entanglement between different two modes.

</details>


### [904] [Sublogarithmic Distillation in all Prime Dimensions using Punctured Reed-Muller Codes](https://arxiv.org/abs/2510.10852)
*Tanay Saha,Shiroman Prakash*

Main category: quant-ph

TL;DR: 通过使用任意素数维度p的qudit，可以显著降低量子纠错的成本。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的容错魔态蒸馏是一种成本高昂但很重要的方法，需要探索最小化其成本的方法。

Method: 将基于穿刺Reed-Muller码的魔态蒸馏协议推广到任意素数维度p的qudit，并分析了其性能。

Result: 在一种可解析穿刺方案中，实现亚对数开销所需的qudit数量随着p的增加而急剧减少，并且渐近产率参数趋向于1/ln p。此外，还发现了一些具有亚对数开销的穿刺码。

Conclusion: 使用高维度qudit（p>2）是降低魔态蒸馏成本的一种有前途的方法。

Abstract: Magic state distillation is a leading but costly approach to fault-tolerant
quantum computation, and it is important to explore all possible ways of
minimizing its overhead cost. The number of ancillae required to produce a
magic state within a target error rate $\epsilon$ is $O(\log^{\gamma}
(\epsilon^{-1}))$ where $\gamma$ is known as the yield parameter. Hastings and
Haah derived a family of distillation protocols with sublogarithmic overhead
(i.e., $\gamma < 1$) based on punctured Reed-Muller codes. Building on work by
Campbell \textit{et al.} and Krishna-Tillich, which suggests that qudits of
dimension $p>2$ can significantly reduce overhead, we generalize their
construction to qudits of arbitrary prime dimension $p$. We find that, in an
analytically tractable puncturing scheme, the number of qudits required to
achieve sublogarithmic overhead decreases drastically as $p$ increases, and the
asymptotic yield parameter approaches $\frac{1}{\ln p}$ as $p \to \infty$. We
also perform a small computational search for optimal puncture locations, which
results in several interesting triorthogonal codes, including a
$[[519,106,5]]_5$ code with $\gamma=0.99$.

</details>


### [905] [Structural encoding with classical codes for computational-basis bit-flip correction in the early fault-tolerant regime](https://arxiv.org/abs/2510.10888)
*IlKwon Sohn,Changyeol Lee,Wooyeong Song,Kwangil Bae,Wonhyuk Lee*

Main category: quant-ph

TL;DR: 我们提出了一种将量子计算与经典纠错相结合的新框架，通过将计算限制在经典纠错码定义的码字子空间内，并基于最终测量结果纠正位翻转错误。该方法利用算法的非对称结构，使对角算子（如或）的开销最小化，并将主要计算成本限制在非对角算子上。仿真结果表明，该方案能有效提升早期容错量子硬件的性能。


<details>
  <summary>Details</summary>
Motivation: 早期容错量子硬件的可靠性很大程度上取决于在不产生过高开销的情况下管理噪声的协议。因此，开发能够有效处理噪声的协议至关重要。

Method: 提出了一种将量子计算与经典纠错功能相结合的新框架。在该框架中，量子计算在由经典纠错码定义的码字子空间内执行。错误（表现为位翻转）的纠正基于最终的测量结果。该方法利用了许多关键算法的非对称结构，其中问题定义性的对角算子（例如或）与固定的非对角算子（例如扩散算子）配对。所提出的编码将计算基态映射到经典码字，并且与对角算子可交换，从而避免了对角算子的开销，并将主要的计算成本限制在更简单的非对角算子上。

Result: 噪声模拟证实了该分析，并表明所提出的方案可以作为协议层，有效提高早期容错量子硬件的性能。

Conclusion: 所提出的框架通过在经典纠错码的码字子空间内执行量子计算，并基于测量结果进行纠本来管理噪声，为在早期容错量子硬件上实现可靠的量子计算提供了一种有前景的方法，同时最小化了开销。

Abstract: Achieving reliable performance on early fault-tolerant quantum hardware will
depend on protocols that manage noise without incurring prohibitive overhead.
We propose a novel framework that integrates quantum computation with the
functionality of classical error correction. In this approach, quantum
computation is performed within the codeword subspace defined by a classical
error correction code. The correction of various types of errors that manifest
as bit flips is carried out based on the final measurement outcomes. The
approach leverages the asymmetric structure of many key algorithms, where
problem-defining diagonal operators (e.g., oracles) are paired with fixed
non-diagonal operators (e.g., diffusion operators). The proposed encoding maps
computational basis states to classical codewords. This approach commutes with
diagonal operators, obviating their overhead and confining the main
computational cost to simpler non-diagonal components. Noisy simulations
corroborate this analysis, demonstrating that the proposed scheme serves as a
viable protocol-level layer for enhancing performance in the early
fault-tolerant regime.

</details>


### [906] [A Simple and Efficient One-Shot Signature Scheme](https://arxiv.org/abs/2510.10899)
*Andrew Huang,Vinod Vaikuntanathan*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: One-shot signatures (OSS) are a powerful and uniquely quantum cryptographic
primitive which allows anyone, given common reference string, to come up with a
public verification key $\mathsf{pk}$ and a secret signing state
$|\mathsf{sk}\rangle$. With the secret signing state, one can produce the
signature of any one message, but no more. In a recent breakthrough work,
Shmueli and Zhandry (CRYPTO 2025) constructed one-shot signatures, either
unconditionally in a classical oracle model or assuming post-quantum
indistinguishability obfuscation and the hardness of Learning with Errors (LWE)
in the plain model.
  In this work, we address the inefficiency of the Shmueli-Zhandry construction
which signs messages bit-by-bit, resulting in signing keys of
$\Theta(\lambda^4)$ qubits and signatures of size $\Theta(\lambda^3)$ bits for
polynomially long messages, where $\lambda$ is the security parameter. We
construct a new, simple, direct, and efficient one-shot signature scheme which
can sign messages of any polynomial length using signing keys of
$\Theta(\lambda^2)$ qubits and signatures of size $\Theta(\lambda^2)$ bits. We
achieve corresponding savings in runtimes, in both the oracle model and the
plain model. In addition, unlike the Shmueli-Zhandry construction, our scheme
achieves perfect correctness.
  Our scheme also achieves strong signature incompressibility, which implies a
public-key quantum fire scheme with perfect correctness among other
applications, correcting an error in a recent work of \c{C}akan, Goyal and
Shmueli (QCrypt 2025) and recovering their applications.

</details>


### [907] [Error mitigation for partially error-corrected quantum computers](https://arxiv.org/abs/2510.10905)
*Ben DalFavero,Ryan LaRose*

Main category: quant-ph

TL;DR: 我们提出了一种在部分纠错的量子计算机（即拥有部分逻辑量子比特和部分噪声量子比特的计算机）上进行量子误差缓释的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的量子误差缓释技术在处理部分纠错的量子计算机时面临挑战，该研究旨在提出一种新的方法来解决这个问题。

Method: 提出一种受误差消除方法启发的、通过新引入的‘通道的凸组合’电路实现的量子误差缓释方法，并分析了其在逻辑辅助量子比特下的采样复杂度。

Result: 该方法能够任意降低误差消除的采样复杂度，在极限情况下达到O(1)的采样复杂度，这在理论上优于现有所有误差缓释技术的样本复杂度下界。然而，这需要指数级的电路深度作为代价。

Conclusion: 研究者推测，任何具有（亚）多项式采样复杂度的误差缓释协议，即使利用逻辑量子比特作为资源，也需要指数级的时间和/或空间。此外，提出的‘通道的凸组合’量子电路在模拟开放量子系统方面显示出巨大的潜力，可将门计数减少一个数量级。

Abstract: We present a method for quantum error mitigation on partially error-corrected
quantum computers - i.e., computers with some logical qubits and some noisy
qubits. Our method is inspired by the error cancellation method and is
implemented via a circuit for convex combinations of channels which we
introduce in this work. We show how logical ancilla qubits can arbitrarily
reduce the sampling complexity of error cancellation in a continuous space-time
tradeoff, in the limiting case achieving $O(1)$ sample complexity which
circumvents lower bounds for sample complexity with all known error mitigation
techniques. This comes at the cost of exponential circuit depth, however, and
leads us to conjecture that any error mitigation protocol with (sub-)polynomial
sample complexity requires exponential time and/or space, even when logical
qubits are utilized as a resource. We anticipate additional applications for
our quantum circuits to implement convex combinations of channels, and to this
end we discuss one application in simulating open quantum systems, showing an
order of magnitude reduction in gate counts relative to current
state-of-the-art methods for a canonical problem.

</details>


### [908] [Dominant spin-spin relaxation mechanism at clock transition of the $Ho_{x}Y_{1-x}W_{10}$ complex at different concentrations](https://arxiv.org/abs/2510.10917)
*Xiao Chen,Haechan Park,Silas Hoffman,Shuanglong Liu,Hai-Ping Cheng*

Main category: quant-ph

TL;DR: 核自旋是分子磁体中自旋退相干的主要来源，但在时钟跃迁处，量子比特对核自旋表现出显著的鲁棒性。本研究的重点是研究量子比特作为退相干的来源，考察了少数 S=1 量子比特在时钟跃迁时的相互作用，并模拟了量子比特密度对自旋退相干动力学的影响，以期为优化量子比特密度和提高量子器件性能提供策略。


<details>
  <summary>Details</summary>
Motivation: 近期实验研究表明，退相干时间和量子比特密度之间存在相关性，这促使我们研究量子比特对自旋退相干的贡献。

Method: 采用精确对角化和簇相关展开（CCE）方法，模拟了量子比特密度变化的自旋退相干动力学，并结合了从 HoW10 晶体研究中获得的结构和能量参数。

Result: 研究结果表明，当两个量子比特的能量失配超过它们的相互作用强度时，它们可以对彼此不敏感。这解释了在较低量子比特密度下进行的实验中 T2 时间没有观察到变化的现象。

Conclusion: 理解时钟跃迁处量子比特对密度在自旋退相干中的作用，不仅有助于我们认识退相干机制，还能为分子磁体和其他量子系统中保护相干性的策略提供见解。通过优化量子比特密度，可以提高相干性，为提高量子器件的性能铺平道路。

Abstract: Spin decoherence poses a significant challenge in molecular magnets, with the
nuclear spin bath serving as a prominent source. Intriguingly, spin qubits at
the clock transition exhibit remarkable insensitivity to the surrounding
nuclear spins. Recent experimental studies have unveiled a correlation between
the decoherence time and the density of spin qubits, prompting our
investigation into the contribution of the qubit bath to spin decoherence. In
this paper, we present a comprehensive theoretical analysis of a few S=1 spin
qubits, focusing on their interaction at the clock transition. Employing the
exact diagonalization and the cluster correlation expansion (CCE) method, we
simulate the dynamics of spin decoherence while varying the density of the
qubit bath. To ensure the realism of our simulations, we incorporate structural
and energetic parameters derived from previous studies on the HoW10 crystal.
Our findings indicate that when the energy mismatch between the energy
splittings of two qubits exceeds their interaction strength, they can become
effectively insensitive to each other, offering an explanation for the absence
of observed changes in the T2 time during experiments with lower qubit
densities. Understanding the role of qubit bath density in spin decoherence at
the clock transition not only advances our knowledge of decoherence mechanisms
but also provides insights for the development of strategies to protect
coherence in molecular magnets and other quantum systems. By optimizing the
density of spin qubits, we can enhance the coherence properties and pave the
way for improved performance of quantum devices. Overall, this study offers
valuable insights into the relationship between qubit bath density and spin
decoherence at the clock transition, contributing to the broader understanding
and control of quantum systems in molecular magnets.

</details>


### [909] [On the Feasibility of Exact Unitary Transformations for Many-body Hamiltonians](https://arxiv.org/abs/2510.10957)
*Praveen Jayakumar,Tao Zeng,Artur F. Izmaylov*

Main category: quant-ph

TL;DR: 酉变换的精确实现条件可以通过算子空间的线性映射和Cayley-Hamilton定理来确定，这统一了之前的研究并为降低量子模拟的计算成本提供了新策略。


<details>
  <summary>Details</summary>
Motivation: 许多体量子系统的分析和模拟的核心是精确的酉变换，但实现这些变换的条件和效率仍不完全清楚。

Method: 本文证明，当酉变换生成元的伴随作用在有限维算子空间内定义一个线性映射时，精确酉变换是可行的。在这种情况下，Cayley-Hamilton定理保证存在一个有限次的泰勒展开，使得Baker-Campbell-Hausdorff展开式有限。

Result: 该方法统一了先前不同的精确变换示例，并阐明了生成元和变换算子之间的代数关系如何决定变换的多项式次数。文章通过酉耦合簇和对合生成元的例子进行了说明，并指出了仅需单个换向子的情形。

Conclusion: 文章提出了精确酉变换的可行性判据，并为降低量子模拟的计算成本提供了新的策略。

Abstract: Exact unitary transformations play a central role in the analysis and
simulation of many-body quantum systems, yet the conditions under which they
can be carried out exactly and efficiently remain incompletely understood. We
show that exact transformations arise whenever the adjoint action of a
unitary's generator defines a linear map within a finite-dimensional operator
space. In this regime, the Cayley-Hamilton theorem ensures the existence of a
finite-degree polynomial that annihilates the adjoint map, rendering the
Baker-Campbell-Hausdorff expansion finite. This perspective brings together
previously disparate examples of exact transformations under a single unifying
principle and clarifies how algebraic relations between generators and
transformed operators determine the polynomial degree of the transformation. We
illustrate this framework for unitary coupled-cluster and involutory
generators, identifying cases in which a single commutator suffices. The result
establishes clear algebraic criteria for when exact unitary transformations are
possible and provides new strategies for reducing their computational cost in
quantum simulation.

</details>


### [910] [Verifiable Quantum Advantage via Optimized DQI Circuits](https://arxiv.org/abs/2510.10967)
*Tanuj Khattar,Noah Shutty,Craig Gidney,Adam Zalcman,Noureldin Yosri,Dmitri Maslov,Ryan Babbush,Stephen P. Jordan*

Main category: quant-ph

TL;DR: DQI框架通过将优化问题简化为可逆解码任务来实现指数级量子加速，并首次将DQI应用于最优多项式交集（OPI）问题，该问题与Reed-Solomon（RS）码相关。


<details>
  <summary>Details</summary>
Motivation: 将DQI应用于OPI问题，以实现可验证的量子优势，并为量子计算在解决实际优化问题方面的潜力提供证据。

Method: 提出用于扩展欧几里得算法（RS解码器中的关键部分）的新型量子电路，重点是优化空间复杂性和门计数。

Result: DQI在OPI上的应用实现了理论上的最优渐近加速，将解决$O(2^N)$的经典硬度问题所需的量子门数减少到$\	ilde{O}(N)$。提出的量子电路在空间复杂性方面达到了理论最小值$2nb$量子比特，并显著降低了门计数。

Conclusion: DQI提供了一种实现可验证量子优势的可行途径，特别是对于OPI问题。通过改进的量子电路，可以解决实际规模的、经典上难以处理的问题，其资源需求低于破解RSA-2048所需的资源。

Abstract: Decoded Quantum Interferometry (DQI) provides a framework for superpolynomial
quantum speedups by reducing certain optimization problems to reversible
decoding tasks. We apply DQI to the Optimal Polynomial Intersection (OPI)
problem, whose dual code is Reed-Solomon (RS). We establish that DQI for OPI is
the first known candidate for verifiable quantum advantage with optimal
asymptotic speedup: solving instances with classical hardness $O(2^N)$ requires
only $\widetilde{O}(N)$ quantum gates, matching the theoretical lower bound.
Realizing this speedup requires highly efficient reversible RS decoders. We
introduce novel quantum circuits for the Extended Euclidean Algorithm, the
decoder's bottleneck. Our techniques, including a new representation for
implicit B\'ezout coefficient access, and optimized in-place architectures,
reduce the leading-order space complexity to the theoretical minimum of $2nb$
qubits while significantly lowering gate counts. These improvements are broadly
applicable, including to Shor's algorithm for the discrete logarithm. We
analyze OPI over binary extension fields $GF(2^b)$, assess hardness against new
classical attacks, and identify resilient instances. Our resource estimates
show that classically intractable OPI instances (requiring $>10^{23}$ classical
trials) can be solved with approximately 5.72 million Toffoli gates. This is
substantially less than the count required for breaking RSA-2048, positioning
DQI as a compelling candidate for practical, verifiable quantum advantage.

</details>


### [911] [Reduced Effective Reorganization Energy for Adiabatic Electron Transfer](https://arxiv.org/abs/2510.10996)
*Ethan Abraham,Junghyun Yoon,Troy Van Voorhis,Martin Z. Bazant*

Main category: quant-ph

TL;DR: 在Marcus正常区域的绝热极限下，Marcus动力学将具有与标准重组能量和耦合强度相关的有效重组能量。


<details>
  <summary>Details</summary>
Motivation: 推导异相电子转移在绝热极限下的Marcus-Hush-Chidsey类型速率表达式。

Method: 推导 Marcus 动力学，并引入预因子。

Result: 得到 Marcus 动力学在绝热极限下的 Marcus 动力学。

Conclusion:  Marcus 动力学在绝热极限下的 Marcus 动力学。

Abstract: We predict that in the adiabatic limit of the Marcus normal regime, Marcus
kinetics will be observed with a reduced effective reorganization energy that
is a function of the standard reorganization energy and the coupling strength.
This result enables the derivation of a closed-form Marcus-Hush-Chidsey type
rate expression for heterogeneous electron transfer in the adiabatic limit,
which also involves a different prefactor than in the non-adiabatic case.

</details>


### [912] [Electron-positron pair creation in a supercritical static asymmetric potential well](https://arxiv.org/abs/2510.11002)
*Z. L. Li,A. R. Sun,J. H. Xia,J. X. Wu,Y. J. Li*

Main category: quant-ph

TL;DR: 研究了超临界静态不对称势阱中的电子-正电子对的产生，并提出了一种优化能量分布和提高产率的方法。


<details>
  <summary>Details</summary>
Motivation: 为了解释能谱中出现的离散峰，并探索优化电子束和提高正电子产率的方法，本研究调查了超临界静态不对称势阱中的电子-正电子对的产生。

Method: 利用计算量子场论研究了由亚临界和超临界势阱组成的静态不对称势阱中的电子-正电子对的产生。推导了亚临界不对称势阱中束缚态位置的解析公式，并将其扩展到超临界势阱。

Result: 提出了一种可以预测束缚态位置和产生率的方法。研究发现亚临界势阱的高度可以优化产生电子的能量分布。将亚临界对称势阱与超临界 Sauter 势阱结合可以提高产率。

Conclusion: 本研究为优化高能电子束的产生和提高超临界势阱中的正电子产率提供了新的途径。

Abstract: The electron-positron pair creation in a supercritical static asymmetric
potential well, which is composed of a subcritical and a supercritical
potential separated by a fixed distance, is investigated using computational
quantum field theory. To explain the discrete peaks in the positron energy
spectrum, an analytical formula for determining the positions of bound states
in a subcritical asymmetric potential well is derived and extended to the
supercritical asymmetric potential well in two ways. One of the two methods can
not only predict the positions of bound states, but also offer the pair
creation rate. This study also reveals that the subcritical potential height
can optimize the energy spread of created electrons, providing a new way to
produce high-energy electron beams with concentrated energy in experiments.
Moreover, it is found that the pair creation rate in a supercritical asymmetric
potential well, composed of a subcritical symmetric potential well and a
supercritical Sauter potential, exceeds the sum of the pair creation rates
produced by each potential individually. This finding suggests a potential
method for enhancing pair yield.

</details>


### [913] [How Gravity Can Explain the Collapse of the Wavefunction](https://arxiv.org/abs/2510.11037)
*Sabine Hossenfelder*

Main category: quant-ph

TL;DR: 统一物质和引力的基本理论似乎会导致波函数塌缩。


<details>
  <summary>Details</summary>
Motivation: 解释统一物质和引力的基本理论如何以及为何会导致波函数塌缩。

Method: 提出一个简单的论点，并在此基础上构建一个模型。

Result: 得出了一个局域的、无参数且可进行检验的预测模型。

Conclusion: 该模型解释了波函数塌缩的现象，并且具有可检验的预测能力。

Abstract: I present a simple argument for why a fundamental theory that unifies matter
and gravity gives rise to what seems to be a collapse of the wavefunction. The
resulting model is local, parameter-free and makes testable predictions.

</details>


### [914] [Bright Single-Photon Emission from Individual Tin-Vacancy Centers in Multi-Cone Diamond Waveguides](https://arxiv.org/abs/2510.11285)
*Pablo Tieben,Jan Rhensius,Takuya F. Segawa,Risei Abe,Konosuke Shimazaki,Shigeki Takeuchi,Andeas W. Schell,Hideaki Takashima*

Main category: quant-ph

TL;DR: 通过在钻石纳米柱中加入锡空位（SnV）中心，实现了高光子提取率，这有望用于量子传感和量子计算。


<details>
  <summary>Details</summary>
Motivation: 尽管钻石色心在量子技术中有应用前景，但从钻石中提取光子仍然是一个关键挑战。

Method: 在此研究中，我们设计并制造了一个包含SnV中心的钻石纳米柱，该纳米柱具有锥形侧壁和多锥结构，以提高光子提取效率。

Result: 我们观察到了在619nm处具有6nm半高全宽的尖锐发射峰，并且第二阶关联函数显示出低于0.5的二阶峰谷，证明了单光子发射。此外，该发射体实现了约9Mcps的高饱和计数率。

Conclusion: 我们提出的包含SnV中心的钻石纳米柱平台为制造高亮度、高稳定性的量子源和传感器提供了一个有前景的解决方案。

Abstract: Diamonds containing color centers have recently gathered significant
attention for photonic quantum technologies, including quantum sensing,
photonic quantum computers, and quantum networks. Among the various color
centers, tin-vacancy (SnV) centers are particularly promising due to the high
emission efficiency from the zero-phonon line and due to their long spin
coherence times. However, the extraction of photons from diamond remains a key
challenge. Here we demonstrate high photon extraction from a single SnV center
incorporated in a diamond nanopillar with tapered sidewalls and a multi-cone
structure. A sharp emission peak with a full width at half maximum (FWHM) of
$6\,$nm was observed at a wavelength of $619\,$nm. Furthermore, the
second-order correlation function exhibited an antibunching dip well below
$g^{(2)}(0) = 0.5$, indicating single-photon emission. Remarkably, the emitter
achieved a high saturation count rate of approximately $9\,$Mcps. These results
establish our nanopillar platform as a promising candidate for bright and
stable quantum sources and sensors based on SnV centers in diamond.

</details>


### [915] [On the Potential of Quantum Computing in Classical Program Analysis](https://arxiv.org/abs/2510.11045)
*Yicheng Guang,Pietro Zanotta,Kai Zhou,Yueqi Chen,Ramin Ayanzadeh*

Main category: quant-ph

TL;DR: QEX是一种利用量子计算分析经典程序的设计，通过量子叠加和纠缠来增强可扩展性和精确性，并提出了混合方法QEX-H以实现更广泛的应用。


<details>
  <summary>Details</summary>
Motivation: 经典程序分析技术在处理大规模状态空间时面临计算限制，影响软件正确性、性能优化和编译器优化的有效性。

Method: QEX通过设计量子电路来编码程序状态（利用叠加）和追踪变量间的数据依赖（利用纠缠），从而实现对程序行为的同时探索。QEX-H是QEX与经典分析技术的混合方法。

Result: 在22个基准程序上进行了概念验证，证明了QEX分析程序状态的有效性。

Conclusion: QEX是利用量子计算进行经典程序分析的首次尝试，通过量子叠加和纠缠显著提高了可扩展性和精确性，QEX-H进一步扩展了其应用范围。

Abstract: Classical program analysis techniques, such as abstract interpretation and
symbolic execution, are essential for ensuring software correctness, optimizing
performance, and enabling compiler optimizations. However, these techniques
face computational limitations when analyzing programs with large or
exponential state spaces, limiting their effectiveness in ensuring system
reliability. Quantum computing, with its parallelism and ability to process
superposed states, offers a promising solution to these challenges. In this
work, we present QEX, a design that uses quantum computing to analyze classical
programs. By synthesizing quantum circuits that encode program states in
superposition and trace data dependency between program variables through
entanglement, QEX enables the simultaneous exploration of program behaviors,
significantly improving scalability and precision. This advancement has broad
applications, from debugging and security verification to optimizing compilers
for next-generation hardware. As a proof-of-concept, we evaluated QEX on 22
benchmark programs, demonstrating its effectiveness in analyzing program
states. To support more language features and make QEX realized sooner in
Fault-Tolerant Quantum Computing (FTQC), we propose QEX-H which hybridizes QEX
with classical analysis techniques. To our knowledge, this work is the first
proposal to use quantum computing for classical program analysis.

</details>


### [916] [Analytical Control of Quantum Coherence: Markovian Revival via Basis Engineering and Exact Non-Markovian Criteria](https://arxiv.org/abs/2510.11055)
*Na-Na Zhang,Chao-Yi Wu,Ming Li,Wei-Xuan Cao,Jun-Hao Zhang,Yong-Rui Guo,Ren-Pu Li*

Main category: quant-ph

TL;DR: 量子相干性的复兴不一定需要环境的非马尔可夫记忆效应，仅通过基矢工程即可在严格的马尔可夫机制下实现相干性的复兴。


<details>
  <summary>Details</summary>
Motivation: 挑战了量子相干性复兴必须依赖非马尔可夫记忆效应的传统观念，并提出了更简单的保护相干性的方法。

Method: 通过在 $\sigma_x$/$\sigma_y$ 基矢下进行基矢工程，实现了在严格马尔可夫机制下的量子相干性复兴，并建立了预测性相干性控制的分析框架，提出了三项通用设计原则：1. 推导了最小临界噪声频率 $\omega_{0}^{c} = 1.57/(0.4996 \cdot t_{\max})$ 作为工程非马尔可夫动力学的标准。2. 证明了当塞曼能量满足 $\omega_k > \pi/(2t_{\max})$ 时，马尔可夫环境也能实现相干性复兴，且与环境记忆无关。3. 针对非马尔可夫环境，给出了周期性和完全复兴的精确条件：设置 $\omega_0 = n \cdot 6.285/t_{\max}$ 可保证 $\sigma_z$ 基矢下的复兴，结合 $\omega_k = \pi \omega_0 / 6.285$ 可确保 $\sigma_x$/$\sigma_y$ 基矢下的完美复兴。

Result: 提出了预测性相干性控制的分析框架和三项通用设计原则，并通过量子模拟验证了结果。

Conclusion: 研究结果提供了一个可预测的相干性控制工具集，为增强量子记忆、传感和纠错提供了直接策略。

Abstract: The preservation of quantum coherence is besieged by a fundamental dogma: its
revival necessitates non-Markovian memory effects from structured environments.
This paradigm has constrained quantum control strategies and obscured simpler
paths to coherence protection. Here, we shatter this belief by demonstrating
unambiguous coherence revival even in strictly Markovian regimes, achieved
solely through basis engineering in the $\sigma_x/\sigma_y$ bases. We establish
a comprehensive analytical framework for predictive coherence control,
delivering three universal design principles. First, we derive a minimum
critical noise based frequency, $\omega_{0}^{c} = 1.57/(0.4996 \cdot
t_{\max})$, serving as a universal criterion for engineering non-Markovian
dynamics over any interval $[0, t_{\max}]$. Crucially, we show that Markovian
environments ($\omega_0 < \omega_0^c$) can exhibit coherence revival when the
Zeeman energy satisfies $\omega_k > \pi/(2t_{\max})$, decoupling revival from
environmental memory. Furthermore, for non-Markovian environments, we provide
exact conditions for periodic and complete revival: setting $\omega_0 = n \cdot
6.285/t_{\max}$ guarantees revival in the $\sigma_z$ basis, while combining it
with $\omega_k = \pi \omega_0 / 6.285$ ensures perfect revival in the
$\sigma_x/\sigma_y$ bases. Our results, validated by rigorous quantum
simulations, provide a predictive toolkit for coherence control, offering
immediate strategies for enhancing quantum memory, sensing, and error
mitigation.

</details>


### [917] [Efficient and Robust Spatial-to-Fiber Coupling forMultimode Quantum Networks via CascadedAdaptive Feedback Control](https://arxiv.org/abs/2510.11086)
*Ya Li,WanRu Wang,Weizhe Qiao,Qizhou Wu,Changqing Niu,Xiaolong Zou,Youxing Chen,Xin Guo*

Main category: quant-ph

TL;DR: 该研究提出了一种基于DLCZ的量子网络优化方法，通过自适应反馈控制系统提高空间光到单模光纤的耦合效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 环境扰动会降低DLCZ量子网络的空间光到光纤的耦合效率，影响其性能。

Method: 开发了一种级联自适应反馈控制系统，利用功率反馈爬山算法动态调节压电驱动镜，实现多维光束的自主对准。

Result: 实验表明，该系统能在20秒内将单模光纤耦合效率提高到70%以上，并在75秒内达到稳定高效的传输状态，同时提高了原子-光子接口的稳定性。

Conclusion: 该方法为可扩展量子网络中高效、鲁棒的空间光传输提供了一个实用的框架。

Abstract: Duan-Lukin-Cirac-Zoller (DLCZ)-based multimodequantum networks rely on
efficient spatial-to-fiber coupling, yetenvironmental perturbations compromise
this performance. Wedevelop a cascaded adaptive feedback control system
integratedinto the quantum entanglement source preparation path.Leveraging a
power-feedback hillclimbing algorithm, itdynamically regulates
piezoelectric-actuated mirrors to achieveautonomous multi-dimensional beam
alignment, Experimentsshow it rapidly boosts single-mode fiber (SMF) coupling
efficieneyto over 70% within 20 seconds and entering the most efficient
andstable transmission state after 75 seconds.Importantly, it enhancesthe
stability of the atom-photon interfacecritical for quantumlight-matter
interactionsproviding a practical framework forefficient, robust spatial light
transmission in scalable quantumnetworks.

</details>


### [918] [Quantum phase transition of sub-Ohmic spin-boson models: An approach by the multiple Davydov D2 Ansatz](https://arxiv.org/abs/2510.11130)
*Justin Tan,Nengji Zhou,Yang Zhao*

Main category: quant-ph

TL;DR: 研究了亚欧姆自旋-玻色子模型的基态性质和量子相变，并提出了一个通用的方法来解决这个模型。


<details>
  <summary>Details</summary>
Motivation: 研究亚欧姆自旋-玻色子模型的基态性质和量子相变，并使用多种方法来解决该模型。

Method: 使用多重DavydovD2ansatz结合变分原理来研究该模型。

Result: 在所有模型变体中，研究发现该模型与之前的方法得到的结果一致，并且在研究中发现了新的相变。

Conclusion: 该研究表明，多重DavydovD2ansatz是一个有效的方法，可以用来研究该模型，并且该方法在研究物理系统方面有很大的潜力。

Abstract: The ground state properties and quantum phase transitions of sub-Ohmic
spin-boson models are investigated using the multiple Davydov D2 Ansatz in
conjunction with the variational principle. Three variants of the model are
studied: (i) a single bath with diagonal coupling, (ii) two independent baths
with diagonal and off-diagonal couplings, and (iii) a single bath with
simultaneous diagonal and off-diagonal couplings. For the purely diagonal
model, the multiple Davydov D2 Ansatz yields critical coupling strengths that
are consistent with other methodologies, validating its accuracy and
efficiency. In the two-bath model, the competition between diagonal and
off-diagonal couplings drives a first-order transition for both symmetric and
asymmetric spectral exponents, with von-Neumann entropy showing a continuous
peak only under exact symmetry. Finally, for a single bath with simultaneous
diagonal and off-diagonal couplings, we demonstrate that a rotational
transformation maps the system to an equivalent purely diagonal model, enabling
simpler and intuitive physical interpretation and reduced computational
complexity.

</details>


### [919] [Hot-Starting Quantum Portfolio Optimization](https://arxiv.org/abs/2510.11153)
*Sebastian Schlütter,Tomislav Maras,Alexander Dotterweich,Nico Piatkowski*

Main category: quant-ph

TL;DR: 提出了一种新的量子优化方法，通过将搜索空间限制在连续最优值附近，并使用紧凑的希尔伯特空间来减少所需量子比特的数量，在组合优化问题上取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的绝热量子优化方法无法利用平滑、凸目标函数的连续最优解信息，并且现有的预训练策略没有明确地将连续松弛解的见解整合到QUBO公式中。

Method: 通过构建紧凑的希尔伯特空间，将搜索空间限制在连续最优值附近的离散解，从而减少所需的量子比特数量。

Result: 在软件求解器和D-Wave Advantage量子退火器上进行的实验表明，该方法优于最先进的技术。

Conclusion: 所提出的方法通过利用连续最优解的见解，有效地解决了组合优化问题，并且在量子硬件上具有优势。

Abstract: Combinatorial optimization with a smooth and convex objective function arises
naturally in applications such as discrete mean-variance portfolio
optimization, where assets must be traded in integer quantities. Although
optimal solutions to the associated smooth problem can be computed efficiently,
existing adiabatic quantum optimization methods cannot leverage this
information. Moreover, while various warm-starting strategies have been
proposed for gate-based quantum optimization, none of them explicitly integrate
insights from the relaxed continuous solution into the QUBO formulation. In
this work, a novel approach is introduced that restricts the search space to
discrete solutions in the vicinity of the continuous optimum by constructing a
compact Hilbert space, thereby reducing the number of required qubits.
Experiments on software solvers and a D-Wave Advantage quantum annealer
demonstrate that our method outperforms state-of-the-art techniques.

</details>


### [920] [Quantum Information Processing with Spatially Structured Light](https://arxiv.org/abs/2510.11154)
*Suraj Goel,Bohnishikha Ghosh,Mehul Malik*

Main category: quant-ph

TL;DR: Using spatially structured light in quantum optical circuits offers a scalable approach to photonic quantum information processing.


<details>
  <summary>Details</summary>
Motivation: Qudits, particularly photonic qudits encoded in transverse-spatial degrees of freedom, provide enhanced channel capacities, noise robustness, and efficient quantum algorithms. This review focuses on recent advances in quantum optical circuits utilizing these spatial qudits.

Method: This paper reviews top-down approaches in quantum optical circuits with spatially structured light. It examines complex mode-mixing transformations in free-space and fibers, highlighting platforms like multi-plane light conversion, scattering media, and multimode/multi-core fibers. The review also discusses applications in manipulating and measuring multi-dimensional and multi-mode quantum states, as well as performing multi-party operations and multi-outcome measurements.

Result: Recent advances in quantum optical circuits with spatially structured light have enabled the manipulation and measurement of complex quantum states and facilitated multi-party operations and multi-outcome measurements.

Conclusion: Quantum optical circuits employing spatially structured light, particularly through top-down mode-mixing transformations, represent a promising and scalable direction for photonic quantum information processing by enabling access to high-dimensional and multi-mode quantum states and operations.

Abstract: Qudits have proven to be a powerful resource for quantum information
processing, offering enhanced channel capacities, improved robustness to noise,
and highly efficient implementations of quantum algorithms. The encoding of
photonic qudits in transverse-spatial degrees of freedom has emerged as a
versatile tool for quantum information processing, allowing access to a vast
information capacity within a single photon. In this review, we examine recent
advances in quantum optical circuits with spatially structured light, focusing
particularly on top-down approaches that employ complex mode-mixing
transformations in free-space and fibers. In this context, we highlight
circuits based on platforms such as multi-plane light conversion, complex
scattering media, multimode and multi-core fibers. We discuss their
applications for the manipulation and measurement of multi-dimensional and
multi-mode quantum states. Furthermore, we discuss how these circuits have been
employed to perform multi-party operations and multi-outcome measurements,
thereby opening new avenues for scalable photonic quantum information
processing.

</details>


### [921] [Tensor-Network-Based Unraveling of Non-Markovian Dynamics in Large Spin Chains via the Influence Martingale Approach](https://arxiv.org/abs/2510.11200)
*Sujay Mondal,Siddhartha Dutta,Abhijit Bandyopadhyay*

Main category: quant-ph

TL;DR: 开发了一种新算法，用于模拟具有时间相关衰减率的马尔可夫和非马尔可夫开放量子系统动力学，克服了传统方法的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的开放量子系统模拟方法面临希尔伯特空间指数增长、精确捕捉耗散和退相干以及非马尔可夫体系中记忆效应复杂性的挑战。

Method: 该算法扩展了张量跳跃方法，结合了基于 TDVP 的张量网络演化和随机轨迹的 Suzuki-Trotter 分解，并纳入了时间相关的衰减率。正衰减率被视为时间不均匀的马尔可夫过程，而负衰减率通过影响鞅形式主义来处理，以揭示时间局域的非马尔可夫动力学。

Result: 该算法能够高效地模拟包含多达 100 个自旋量子比特的一维横向场伊辛链的开放系统动力学，尤其是在非马尔可夫体系中。

Conclusion: 所提出的资源高效框架能够大规模模拟非马尔可夫体系中的开放系统动力学。

Abstract: Classical simulation of open quantum system dynamics remains challenging due
to the exponential growth of the Hilbert space, the need to accurately capture
dissipation and decoherence, and the added complexity of memory effects in the
non-Markovian regime. We develop an efficient algorithm for simulating both
Markovian and non-Markovian dynamics in large one-dimensional quantum systems.
Extending the Tensor Jump Method, which combines TDVP-based tensor-network
evolution with a Suzuki-Trotter decomposition of stochastic trajectories, our
approach incorporates time-dependent decay rates-treating positive rates as
time-inhomogeneous Markovian processes and negative rates via the Influence
Martingale formalism to unravel time-local non-Markovian dynamics. This
resource-efficient framework enables scalable simulations of open-system
dynamics in the non-Markovian regime, as demonstrated for a one-dimensional
transverse-field Ising chain comprising up to 100 spin qubits.

</details>


### [922] [Comparison and optimisation of hybridization algorithms for onboard classical and quantum accelerometers](https://arxiv.org/abs/2510.11201)
*Benoit Kaczmarczuk,Yannick Bidel,Alexandre Bresson,Nassim Zahzam,Alexis Bonnin,Malo Cadoret,Tim Enzlberger Jensen,Quentin Beaufils,Franck Pereira Dos Santos*

Main category: quant-ph

TL;DR: 本研究比较了两种结合量子和经典惯性传感器的混合算法，用于机载加速度测量。


<details>
  <summary>Details</summary>
Motivation: 为了结合基于原子干涉的量子惯性传感器和经典惯性传感器，以进行机载加速度测量。

Method: 研究了两种混合算法：一种是直接提取干涉仪相位，另一种是结合三次连续测量。通过合成数据比较了它们的性能，并在实际的机载数据上进行了测试，以评估经典传感器的偏差和比例因子误差。此外，还将其应用于其他测量参数（如对齐误差）的动态评估。

Result: 研究表明，这两种算法可以改善两个加速度计测量之间的相关性，并显著减少经典传感器偏差估计中的误差。

Conclusion: 这两种混合算法能够有效提高传感器性能，并为评估其他关键测量参数提供了一种动态方法。

Abstract: We study two hybridization algorithms used for the combination of a quantum
inertial sensor based on atom interferometry with a classical inertial sensor
for onboard acceleration measurements. The first is based on the direct
extraction of the interferometer phase, and was previously used in seaborne and
airborne gravity measurement campaigns. The second is based on the combination
of three consecutive measurements and was originally developed to increase the
measurement range of the quantum sensor beyond its linear range. After
comparing their performances using synthetic data, we implement them on
acceleration data collected in a recent airborne campaign and evaluate the bias
and the scale factor error of the classical sensor. We then extend their scope
to the dynamical evaluation of other key measurement parameters (e.g. alignment
errors). We demonstrate an improvement in the correlation between the two
accelerometers' measurements and a significant reduction of the error in the
estimation of the bias of the classical sensor.

</details>


### [923] [Experimental Demonstration of the PBR Test on a Superconducting Processor](https://arxiv.org/abs/2510.11213)
*Songqinghao Yang,Haomu Yuan,Crispin H. W. Barnes*

Main category: quant-ph

TL;DR: 在IBM的超导量子处理器上实现了Pusey-Barrett-Rudolph（PBR）定理的实验验证，拒绝了量子态的认知解释，并展示了该测试作为量子性基准的潜力。


<details>
  <summary>Details</summary>
Motivation: 测试隐藏变量模型是否能将量子态解释为仅仅是认知性的，即反映了对某种潜在物理现实的无知。

Method: 在IBM的156量子比特Heron2 Marrakesh超导量子处理器上，通过制备非正交态并进行幺正演化，实验实现了PBR无 go 定理。推导了基于设备性能校准的退相干模型的噪声感知容错方法。

Result: 大多数相邻量子比特对和相邻五量子比特构型产生的结果统计违反了认知边界，从而排除了量子力学的认知解释。观察到通过PBR测试的概率随着量子比特空间分离的增加而减小，突显了该协议对NISQ系统连通性和相干性的敏感性。

Conclusion: PBR测试有望成为在存在实际噪声的情况下，用于量子性的有前景的器件级基准。

Abstract: We present an experimental implementation of the Pusey-Barrett-Rudolph (PBR)
no-go theorem on IBM's 156-qubit Heron2 Marrakesh superconducting quantum
processor. By preparing qubits in a set of non-orthogonal states and evolving
them under carefully compiled unitary circuits, we test whether one can
interpret the hidden variable model for quantum states as merely epistemic --
reflecting ignorance about some underlying physical reality. To account for
realistic hardware imperfections, we derive noise-aware error tolerance based
on decoherence models calibrated to the device's performance. Our results show
that a significant majority of adjacent qubit pairs and adjacent five-qubit
configurations yield outcome statistics that violate the epistemic bound, thus
ruling out the epistemic interpretation of quantum mechanics. Furthermore, we
observe a clear trend: the probability of passing the PBR test decreases as the
spatial separation within the quantum processor between qubits increases,
highlighting the sensitivity of this protocol to connectivity and coherence in
Noisy Intermediate-Scale Quantum (NISQ) systems. These results demonstrate the
PBR test as a promising device-level benchmark for quantumness in the presence
of realistic noise.

</details>


### [924] [Basis-independent Coherence in Noninertial Frames](https://arxiv.org/abs/2510.11329)
*Ming-Ming Du Yi-Hao Fan,Hong-Wei Li,Shu-Ting Shen,Xiao-Jing Yan,Xi-Yun Li,Wei Zhong,Yu-Bo Sheng,Lan Zhou*

Main category: quant-ph

TL;DR: 量子相干性在相对加速观测下保持稳定，即使在无限加速极限下也保持有限，并且在零加速度下表现出非零值，不受加速度影响。


<details>
  <summary>Details</summary>
Motivation: 研究相对加速观测者如何影响自由狄拉克场两种模式之间的无条件量子相干性。

Method: 分析了三种不同模式对（A和BI，A和BII，BI和BII）的无条件相干性的行为，考察了加速度对相干性的影响。

Result: （i）无条件相干性随加速度增加而减小，但在无限加速度极限下保持有限；（ii）在零加速度下，A和BII模式之间的相干性非零；（iii）BI和BII模式之间的相干性不随加速度变化，呈现冻结现象。

Conclusion: 无条件相干性在Unruh效应下表现出固有的鲁棒性。

Abstract: We investigate the behavior of basis-independent quantum coherence between
two modes of a free Dirac field as observed by relatively accelerated
observers. Our findings reveal three key results: (i) the basis-independent
coherence between modes A and BI decreases with increasing acceleration but
remains finite even in the limit of infinite acceleration; (ii) at zero
acceleration, the coherence between modes $A$ and $B_II$ is nonzero contrasting
with the behavior of basis-dependent coherence, which typically vanishes in
this case; and (iii) the basis-independent coherence between modes BI and BII
remains constant regardless of acceleration, exhibiting a freezing phenomenon.
These results demonstrate the intrinsic robustness of basis-independent
coherence under Unruh effects.

</details>


### [925] [Relative Information, Relative Facts](https://arxiv.org/abs/2510.11349)
*Andrea Di Biagio,Carlo Rovelli*

Main category: quant-ph

TL;DR: 该论文从信息论的角度提出了量子力学关系解释的新视角。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在提供一种基于可量化信息概念来理解量子力学世界的新方法，并解决该解释先前存在的一些问题。

Method: 通过将视角与可交换观测值而非整个量子系统相关联，来定义相对事实，而不对正统量子理论进行任何修改，也不引入观察者的特殊角色。

Result: 该方法消除了先前解释中存在的几个问题，并表明量子测量是一个连续过程。

Conclusion: 量子力学的关系解释可以被视为一种基于信息论的世界观，能够解决现有解释中的一些难题。

Abstract: We offer a fresh perspective on the relational interpretation of quantum
mechanics as a way of thinking about the world described by quantum theory
based on quantifiable notions of information. This allows us to provide a
definition of a relative fact, with no addition to orthodox quantum theory and
no fundamentally special role for observers. By associating perspectives with
commutative observables rather than entire quantum systems, several previous
problems with the interpretation are dissolved. As a side result, we show how a
quantum measurement, properly described, is a continuous process.

</details>


### [926] [Disorder-Induced Strongly Correlated Photons in Waveguide QED](https://arxiv.org/abs/2510.11376)
*Guoqing Tian,Li-Li Zheng,Zhi-Ming Zhan,Franco Nori,Xin-You Lü*

Main category: quant-ph

TL;DR: 在N个量子比特耦合到一维波导的链中，无序的跃迁频率可以诱导光子反聚束，并在透射和反射输出中产生近乎完美的光子阻塞事件，这归因于无序诱导的近乎完全破坏性的光子散射路径干涉。有序链中的光子反聚束较弱，并且在透射输出中几乎不存在。


<details>
  <summary>Details</summary>
Motivation: 研究有强关联光子的产生概率，以及无序性对光子关联生成的影响。

Method: 模拟N个量子比特耦合到一维波导的链中，并分析不同情况下（有无序）的透射和反射输出。

Result: 无序链可以产生近乎完美的光子阻塞事件，而有序链中的光子关联较弱。

Conclusion: 无序性可以增强产生强关联光子的潜力。

Abstract: Strongly correlated photons play a crucial role in modern quantum
technologies. Here, we investigate the probability of generating strongly
correlated photons in a chain of N qubits coupled to a one-dimensional (1D)
waveguide. We found that disorder in the transition frequencies can induce
photon antibunching, and especially nearly perfect photon blockade events in
the transmission and reflection outputs. As a comparison, in ordered chains,
strongly correlated photons cannot be generated in the transmission output, and
only weakly antibunched photons are found in the reflection output. The
occurrence of nearly perfect photon blockade events stems from the
disorder-induced near completely destructive interference of photon scattering
paths. Our work highlights the impact of disorder on photon correlation
generation and suggests that disorder can enhance the potential for achieving
strongly correlated photon.

</details>


### [927] [The Dirac equation and the Quantum Potential](https://arxiv.org/abs/2510.11435)
*Calum Robson*

Main category: quant-ph

TL;DR: 本篇论文将Hiley的量子势概念与Clifford代数在物理学中的应用相结合，并将其扩展到Dirac方程。


<details>
  <summary>Details</summary>
Motivation: 结合Hiley的量子势概念和Clifford代数在物理学中的应用，并将其扩展到Dirac方程。

Method: 首先讨论Dirac方程的几何结构及其在Clifford代数下的表示，然后将Cl(2)Dirac波函数改写为极坐标形式，最后讨论Dirac方程和Schroedinger方程之间的关系。

Result: 在将Dirac波函数改写为极坐标形式时，由于拓扑非定域性，出现了新的行为。

Conclusion: 量子势可以扩展到Dirac方程，并且Clifford代数在理解Dirac方程的几何结构方面发挥着重要作用。

Abstract: One key theme of Basil Hiley's work was the development of David Bohm's
approach to Quantum Mechanics; in particular the concept of the quantum
potential. Another theme was the importance of Clifford Algebras in fundamental
physics. In this paper I will combine these approaches by looking at how the
quantum potential can be extended to the Dirac equation. I will begin by
discussing the geometry of the Dirac equation, and how this is made clearer by
the use of Clifford algebras .Next, I will rewrite the Cl(2) Dirac wavefunction
in Polar form, and show that new behaviour arises due to topological
nonlocality. Finally, I discuss the relationship between the Dirac and
Schroedinger equations.

</details>


### [928] [Finite Key Rates for QKD Protocols with Data Filtering](https://arxiv.org/abs/2510.11488)
*Walter O. Krawec*

Main category: quant-ph

TL;DR: 该论文推导了对一类涉及筛选和丢弃数据的量子密码协议的新安全证明。


<details>
  <summary>Details</summary>
Motivation: 推导一类涉及筛选和丢弃数据的量子密码协议的新安全证明。

Method: 基于经典采样策略的性质，推导出该类系统量子最小熵的一个新界限。

Result: 展示了如何使用该方法轻松证明扩展B92协议的安全性。

Conclusion: 为扩展B92协议提供了首次针对通用、相干攻击的有限密钥安全证明。

Abstract: In this paper, we derive a new proof of security for a general class of
quantum cryptographic protocol involving filtering and discarded data. We
derive a novel bound on the quantum min entropy of such a system, based in
large part on properties of a certain classical sampling strategy. Finally, we
show how our methods can be used to readily prove security of the Extended B92
protocol, providing the first finite key proof of security for this protocol
against general, coherent, attacks.

</details>


### [929] [Buildings for Synthesis with Clifford+R](https://arxiv.org/abs/2510.11526)
*Mark Deaconu,Nihar Gargava,Amolak Ratan Kalra,Michele Mosca,Jon Yard*

Main category: quant-ph

TL;DR:  Clifford+R 门集精确合成问题及其 Bruhat-Tits 几何结构。


<details>
  <summary>Details</summary>
Motivation: 研究 Clifford+R 门集的精确合成问题，并给出其底层 Bruhat-Tits 几何结构的显式结构。

Method: 研究 Clifford+R 门集的精确合成问题，并给出其底层 Bruhat-Tits 几何结构的显式结构。

Result: 给出了 Clifford+R 门集精确合成问题的显式结构，并提供了 Clifford+R 门集的算术性质的替代证明。

Conclusion: Clifford+R 门集的精确合成问题和其 Bruhat-Tits 几何结构是相互关联的，并且 Clifford+R 门集的算术性质得到了进一步证明。

Abstract: We study the problem of exact synthesis for the Clifford+R gate set and give
the explicit structure of the underlying Bruhat-Tits building for this group.
In this process, we also give an alternative proof of the arithmetic nature of
the Clifford+R gate set.

</details>


### [930] [French on London and Bauer, and QBism](https://arxiv.org/abs/2510.11544)
*Jacques L. Pienaar*

Main category: quant-ph

TL;DR: QBism与LBF在现象学解释上存在分歧，但QBism在某些方面与现象学兼容，尤其在测量概念上，QBism的解释更优。


<details>
  <summary>Details</summary>
Motivation: 比较量子力学（QM）的两种现象学解释：London-Bauer-French（LBF）解释和QBism，并重点关注它们之间的分歧。

Method: 比较QBism和LBF解释在现象学上的契合度，特别关注QBism与Zahavi的相关主义以及Husserl的通感性概念的兼容性，并分析QBism与LBF在量子测量概念上的不兼容性。

Result: QBism可以与Zahavi的相关主义和Husserl的通感性概念兼容，但与LBF的量子测量概念不兼容。

Conclusion: QBism在现象学解释上与LBF存在分歧，尤其是在量子测量概念上，但QBism的解释更优。

Abstract: In this article I compare two interpretations of quantum mechanics (QM) that
draw inspiration from phenomenology: the London-Bauer-French interpretation
(hereafter LBF) as articulated by Steven French, and QBism. I give special
attention to certain disagreements between QBism and LBF identified French's
work, as well as French's related claims that QBism may be at odds with key
ideas in phenomenology. My main finding is that QBism does not fare so badly
with phenomenology as French makes out; in particular it can be made compatible
with Zahavi's correlationism and Husserl's notion of intersubjectivity, both of
which strongly inform LBF. Nevertheless, I concur with French's argument that
QBism is incompatible with the conception of quantum measurement in LBF, hence
also with that of Merleau-Ponty, as the latter based his own analysis on that
of London and Bauer. I explain why I find QBism's account preferable in this
case.

</details>


### [931] [Telecom-compatible cross-band quantum memory via dual photon modes dark-state polaritons](https://arxiv.org/abs/2510.11585)
*Dounan Du,Eden Figueroa*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum memories are essential components of quantum networks, enabling
synchronization, quantum repeaters, and long-distance entanglement
distribution. Most ensemble-based realizations rely on dark-state polaritons
(DSPs) in $\Lambda$-type systems that operate at near-infrared wavelengths,
such as 795 nm in $^{87}$Rb, far from the telecom band where long fiber
transmission is optimal. Here we identify a DSP in $^{87}$Rb that coherently
couples two photonic modes at 795 nm and 1324 nm through a shared spin-wave
coherence. We derive its field operator and group velocity, extending the
Fleischhauer-Lukin model to a dual-wavelength regime, and formulate a memory
protocol enabling bidirectional storage and retrieval between the two modes.
Numerical simulations of the full six-level dynamics confirm two-way storage
and retrieval for both same-mode and cross-mode operation between the two
wavelengths. The results demonstrate a dual-wavelength memory that unifies
node-band and telecom-band operation within a single ensemble, providing a
potential route toward frequency-conversion-free quantum-network interfaces.

</details>


### [932] [Hierarchical Qubit-Merging Transformer for Quantum Error Correction](https://arxiv.org/abs/2510.11593)
*Seong-Joon Park,Hee-Youl Kwak,Yongjune Kim*

Main category: quant-ph

TL;DR: HQMT是一个基于深度学习的量子纠错解码器，通过分层融合注意力机制，在表面码上显著降低了逻辑错误率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了实现可靠的大规模量子计算，需要量子纠错（QEC）方案来有效解决物理错误。深度学习的进展促使了神经元网络解码器的发展，以提高QEC的可靠性。

Method: 提出了一种名为HQMT的新型通用解码框架，该框架利用稳定器码的结构图来学习多尺度的错误相关性。该架构首先在结构相关的稳定器组上进行局部注意力计算，然后系统地融合这些以量子为中心的表示，以构建全局错误综合视图。

Result: HQMT通过在Transformer架构中集成专用的量子融合层，在表面码上实现了显著更低的逻辑错误率。在各种码距下，HQMT的性能明显优于之前的神经元网络QEC解码器以及强大的基于信念传播和有序统计的解码（BP+OSD）基线。

Conclusion: 这种分层方法为表面码解码提供了一个可扩展且有效的框架，有助于实现可靠的量子计算。

Abstract: For reliable large-scale quantum computation, a quantum error correction
(QEC) scheme must effectively resolve physical errors to protect logical
information. Leveraging recent advances in deep learning, neural network-based
decoders have emerged as a promising approach to enhance the reliability of
QEC. We propose the Hierarchical Qubit-Merging Transformer (HQMT), a novel and
general decoding framework that explicitly leverages the structural graph of
stabilizer codes to learn error correlations across multiple scales. Our
architecture first computes attention locally on structurally related groups of
stabilizers and then systematically merges these qubit-centric representations
to build a global view of the error syndrome. The proposed HQMT achieves
substantially lower logical error rates for surface codes by integrating a
dedicated qubit-merging layer within the transformer architecture. Across
various code distances, HQMT significantly outperforms previous neural
network-based QEC decoders as well as a powerful belief propagation with
ordered statistics decoding (BP+OSD) baseline. This hierarchical approach
provides a scalable and effective framework for surface code decoding,
advancing the realization of reliable quantum computing.

</details>


### [933] [Quantum Synchronization of Perturbed Oscillating Coherences](https://arxiv.org/abs/2510.11601)
*Yi J. Zhao,Joel E. Moore,Juzar Thingna,Christopher W. Wächtler*

Main category: quant-ph

TL;DR: 量子系统中的同步现象可以通过持久振荡的局部可观测量来研究，但这需要对系统进行微调以满足特定的对称性约束。本研究探讨了具有这种振荡模式的自旋系统对非特异性、弱扰动的响应，并证明即使扰动破坏了对称性并导致单一稳态，所形成状态的相位相关性也表现出同步的特征。这表明了同步的持久振荡（动力学）和基于相位相关性（稳态）的概念之间的联系，并揭示了稳态同步可能具有动力学同步所不具备的特性，暗示了量子同步的鲁棒性和潜在的统一框架。


<details>
  <summary>Details</summary>
Motivation: 研究具有持久振荡模式的量子系统对弱扰动的响应，以连接动力学同步和稳态同步，并探索稳态同步的特性。

Method: 分析具有持久振荡模式的自旋系统对弱扰动的响应，研究对称性破坏后的稳态相位相关性。

Result: 即使在扰动破坏对称性并导致单一稳态的情况下，相位相关性也表现出同步的特征；发现稳态同步具有动力学同步所不具备的特性。

Conclusion: 量子系统中的同步现象是鲁棒的，并且存在一个统一的量子同步框架。

Abstract: Synchronization in quantum systems has been recently studied through
persistent oscillations of local observables, which stem from undamped modes of
the dissipative dynamics. However, the existence of such modes requires
fine-tuning the system to satisfy specific symmetry constraints. We investigate
the response of spin systems that possess such oscillating modes to generic,
weak perturbations. We show that even when these perturbations break the
symmetry and lead to a single steady state, the phase correlations in the
resulting state exhibit signatures of synchronization. Our results therefore
connect the persistent oscillation notion (dynamical) and the notion based on
phase correlations (steady-state) of synchronization, which so far have been
regarded as distinct phenomena. Furthermore, we demonstrate that steady-state
synchronization in these systems can exhibit features that are absent in the
dynamical synchronization. Our work suggests robustness of synchronization and
points toward a potential unifying framework of quantum synchronization.

</details>


### [934] [A Monte Carlo approach to bound Trotter error](https://arxiv.org/abs/2510.11621)
*Nick S. Blunt,Aleksei V. Ivanov,Andreas Juul Bay-Smidt*

Main category: quant-ph

TL;DR: Trotter product formulas are useful for quantum simulation, but error analysis is hard. This paper shows a new method to bound Trotter error using Monte Carlo simulations, which is often tighter and cheaper than previous methods, significantly reducing costs for specific models.


<details>
  <summary>Details</summary>
Motivation: The error analysis of Trotter product formulas for quantum simulation is challenging, and their cost is often overestimated. Existing bounds are often loose due to repeated application of the triangle inequality.

Method: This paper proposes an approach to upper bound the spectral norm of an operator using the spectral norm of an equivalent sign-problem-free operator. This sign-problem-free operator can be efficiently calculated using projector Monte Carlo simulation. The method is applied to second-order Trotter formulas for various Hamiltonians.

Result: The Monte Carlo-based bound is demonstrated to be extremely tight, and in some cases exact, for a range of Hamiltonians. For the uniform electron gas, the cost of Trotterization is reduced by an order of magnitude. For the Pariser-Parr-Pople model, the number of Trotter steps and circuit depth required are significantly reduced.

Conclusion: This new Monte Carlo-based approach provides a tighter and more efficient error bound for Trotterization in quantum simulation, potentially improving the accuracy and feasibility of Trotterization for important applications.

Abstract: Trotter product formulas are a natural and powerful approach to perform
quantum simulation. However, the error analysis of product formulas is
challenging, and their cost is often overestimated. It is established that
Trotter error can be bounded in terms of spectral norms of nested commutators
of the Hamiltonian partitions [Childs et al., Phys. Rev. X 11, 011020], but
evaluating these expressions is challenging, often achieved by repeated
application of the triangle inequality, significantly loosening the bound.
Here, we show that the spectral norm of an operator can be upper bounded by the
spectral norm of an equivalent sign-problem-free operator, which can be
calculated efficiently to large system sizes using projector Monte Carlo
simulation. For a range of Hamiltonians and considering second-order formulas,
we demonstrate that this Monte Carlo-based bound is often extremely tight, and
even exact in some instances. For the uniform electron gas we reduce the cost
of performing Trotterization from the literature by an order of magnitude. For
the Pariser-Parr-Pople model for linear acene molecules, which has
$\mathcal{O}(N^2)$ long-range interaction terms, we show that it suffices to
use $\mathcal{O}(N^{0.57})$ Trotter steps and circuit depth
$\mathcal{O}(N^{1.57})$ to implement Hamiltonian simulation. We hope that this
approach will lead to a better understanding of the potential accuracy of
Trotterization in a range of important applications.

</details>


### [935] [Observation of ballistic plasma and memory in high-energy gauge theory dynamics](https://arxiv.org/abs/2510.11679)
*Daniel K. Mark,Federica M. Surace,Thomas Schuster,Adam L. Shaw,Wenjie Gong,Soonwon Choi,Manuel Endres*

Main category: quant-ph

TL;DR: 量子模拟器上高能规范场论动力学中观察到意外的弹道等离子体形成和长期记忆效应，挑战了传统热化理论，并提出了一种新的等离子体振荡理论。


<details>
  <summary>Details</summary>
Motivation: 尽管规范场论在描述基本力方面至关重要，但其高能动力学（如夸克-胶子等离子体）难以用经典方法模拟。量子模拟是该领域的一个有希望的方向，但先前主要集中在低能量。本研究旨在探索高能规范场论动力学，并利用高精度量子模拟器进行实验。

Method: 研究人员在高精度量子模拟器上模拟了(1+1)维Schwinger模型的格点版本。他们观察了粒子-反粒子对填充的初始状态的演化，并将其与新的等离子体振荡理论进行比较，该理论将等离子体振荡视为Wigner分布的旋转，并结合了量子光学技术。

Result: 实验观察到高能规范场论动力学中出现了弹道等离子体形成和长期记忆效应。这些现象与初始状态会迅速热化的预期相反。研究表明，这些观察结果不能用许多体疤痕来解释，但可以通过一种新的等离子体振荡理论来描述，该理论可以一直持续到(1+1)维Schwinger模型的连续极限。

Conclusion: 本研究在高精度量子模拟器上揭示了高能规范场论动力学中的意外现象，包括弹道等离子体形成和长期记忆效应。提出的新的等离子体振荡理论框架能够解释这些现象，并统一了等离子体振荡和许多体疤痕。这项工作强调了高精度量子模拟在规范场论研究和一般科学发现中的潜力。

Abstract: Gauge theories describe the fundamental forces of nature. However,
high-energy dynamics, such as the formation of quark-gluon plasmas, is
notoriously difficult to model with classical methods. Quantum simulation
offers a promising alternative in this regime, yet experiments have mainly
probed low energies. Here, we observe the formation of a ballistic plasma and
long-time memory effects in high-energy gauge theory dynamics on a
high-precision quantum simulator. Both observations are unexpected, as the
initial state - fully filled with particle-antiparticle pairs - was thought to
rapidly thermalize. Instead, we find correlations spreading ballistically to
long distances and a memory of charge clusters. Our observations cannot be
explained by many-body scars, but are captured by a new theory of plasma
oscillations between electric field and current operators, persisting all the
way to the continuum limit of the (1+1)D Schwinger model, of which we simulate
a lattice version. Adapting techniques from quantum optics, we visualize plasma
oscillations as rotations of Wigner distributions, leading to a novel set of
predictions which we test in experiment and numerics. The new framework
encompasses both our scenario and scars, which show up as coherent states of
the plasma. The experimental surprises we observe in the high-energy dynamics
of a simple gauge theory point to the potential of high-precision quantum
simulations of gauge theories for general scientific discovery.

</details>


### [936] [The Magic Barrier before Thermalization](https://arxiv.org/abs/2510.11681)
*Lukas Ebner,Berndt Müller,Andreas Schäfer,Leonhard Schmotzer,Clemens Seidl,Xiaojun Yao*

Main category: quant-ph

TL;DR: 文章研究了SU(2)链系统在热化过程中纠缠谱反平坦度的时变行为，发现其在纠缠熵快速增长期间出现峰值，并与纠缠增长最快的时刻相关，揭示了纠缠谱在热化过程中的普适结构。


<details>
  <summary>Details</summary>
Motivation: 研究纠缠谱反平坦度（衡量非稳定性和非局域量子魔性的下界）在热化过程中的时变行为。

Method: 通过追踪大量初始态随时间的演化，研究子系统（线性SU(2)劈链）的纠缠谱反平坦度。

Result: 发现在纠缠熵从初始值快速增长到微正则熵的时期，反平坦度呈现出类似屏障的最大值。该峰值位置与纠缠熵增长最快的时刻高度相关。此行为在多种高激发初态下均出现，并贯穿整个遍历区域，表明了热化过程中纠缠谱的普适结构。

Conclusion: 量化模拟非阿贝尔规范理论的热化过程需要量子计算。推测该性质可能推广到其他量子混沌系统。

Abstract: We investigate the time dependence of anti-flatness in the entanglement
spectrum, a measure for non-stabilizerness and lower bound for non-local
quantum magic, on a subsystem of a linear SU(2) plaquette chain during
thermalization. Tracing the time evolution of a large number of initial states,
we find that the anti-flatness exhibits a barrier-like maximum during the time
period when the entanglement entropy of the subsystem grows rapidly from the
initial value to the microcanonical entropy. The location of the peak is
strongly correlated with the time when the entanglement exhibits the strongest
growth. This behavior is found for generic highly excited initial computational
basis states and persists for coupling constants across the ergodic regime,
revealing a universal structure of the entanglement spectrum during
thermalization. We conclude that quantitative simulations of thermalization for
nonabelian gauge theories require quantum computing. We speculate that this
property generalizes to other quantum chaotic systems.

</details>


### [937] [Probing emergent prethermal dynamics and resonant melting on a programmable quantum simulator](https://arxiv.org/abs/2510.11706)
*Siva Darbha,Alexey Khudorozhkov,Pedro L. S. Lopes,Fangli Liu,Ermal Rrapaj,Jan Balewski,Majd Hamdan,Pavel E. Dolgirev,Alexander Schuckert,Katherine Klymko,Sheng-Tao Wang,Mikhail D. Lukin,Daan Camps,Milan Kornjača*

Main category: quant-ph

TL;DR: 使用量子模拟器探索了量子系统淬灭动力学，发现了新的动力学机制和无平衡态的动力学相变。


<details>
  <summary>Details</summary>
Motivation: 研究孤立量子系统在猝灭后的动力学，以理解热化、非平衡相变和Floquet相工程等复杂现象，尤其是在高维系统中的数值研究挑战。

Method: 利用一个可编程的180个量子比特的中性原子量子模拟器，在广泛的参数空间中对初始为积态的系统进行淬灭，并探索其动力学行为。

Result: 发现了几个稳定的、不同性质的动力学机制。揭示了这些机制在强动力学约束下，在长期的涌现时间尺度上稳定到类似于Floquet的预热稳定态。通过对预热过程的共振结构进行量化分析，解释了动力学响应中出现的尖峰。在二维系统中，观察到了一个随着系统尺寸增加而收敛的急剧动力学响应变化，这与Néel序缺陷的增殖有关，并指示了一种没有平衡态对应物的动力学相变。

Conclusion: 揭示了量子预热和涌现动力学相之间复杂的相互作用。研究结果展示了量子模拟器在揭示复杂的非平衡量子多体现象方面的应用价值。

Abstract: The dynamics of isolated quantum systems following a sudden quench plays a
central role in many areas of material science, high-energy physics, and
quantum chemistry. Featuring complex phenomena with implications for
thermalization, non-equilibrium phase transitions, and Floquet phase
engineering, such far-from-equilibrium quantum dynamics is challenging to study
numerically, in particular, in high-dimensional systems. Here, we use a
programmable neutral atom quantum simulator to systematically explore quench
dynamics in spin models with up to 180 qubits. By initializing the system in a
product state and performing quenches across a broad parameter space, we
discover several stable, qualitatively distinct dynamical regimes. We trace
their robustness to Floquet-like prethermal steady states that are stabilized
over long emergent timescales by strong dynamical constraints. In addition, we
observe sharp peaks in the dynamical response that are quantitatively explained
by the structured melting of prethermalization through resonances. In two
dimensions, we uncover a sharp dynamical response change that converges with
increased system size, that is linked to the proliferation of N\'{e}el-order
defects and indicative of a dynamical phase transition with no equilibrium
analogs. Uncovering an intricate interplay between quantum prethermalization
and emergent dynamical phases, our results demonstrate the use of quantum
simulators for revealing complex non-equilibrium quantum many-body phenomena.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [938] [Enhancing Diffusion Policy with Classifier-Free Guidance for Temporal Robotic Tasks](https://arxiv.org/abs/2510.09786)
*Yuang Lu,Song Wang,Xiao Han,Xuri Zhang,Yucong Wu,Zhicheng He*

Main category: cs.RO

TL;DR: 本研究提出了一种名为CFG-DP的新型扩散策略框架，通过结合分类器自由引导（CFG）来解决人形机器人序列任务中的局部最优和动作重复问题，实验证明该方法能有效提高任务成功率并减少不必要的重复动作。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略（DP）和基于Transformer的动作分块（ACT）方法在处理需要时间顺序的人形机器人任务时，往往缺乏对时间上下文的充分考虑，容易陷入局部最优和产生过多重复动作。因此，有必要提出一种新的方法来增强机器人执行序列任务时的时序理解和控制精度。

Method: 本研究提出了一种结合分类器自由引导（CFG）的扩散策略（CFG-DP）框架。该框架通过融合条件和非条件模型，并利用时间步长输入来跟踪任务进度和精确控制循环终止。CFG-DP能够根据任务阶段动态调整动作预测，并通过引导因子平衡时序连贯性和动作精度。

Result: 在人形机器人上的实际实验表明，CFG-DP框架取得了高成功率，并显著减少了重复动作。研究还评估了模型终止动作的能力，并分析了不同组件和参数设置对性能的影响。

Conclusion: CFG-DP框架通过集成CFG技术，有效地解决了人形机器人在执行序列任务时遇到的时序理解不足、局部最优和动作重复等问题，显著提高了确定性控制和执行的可靠性。

Abstract: Temporal sequential tasks challenge humanoid robots, as existing Diffusion
Policy (DP) and Action Chunking with Transformers (ACT) methods often lack
temporal context, resulting in local optima traps and excessive repetitive
actions. To address these issues, this paper introduces a Classifier-Free
Guidance-Based Diffusion Policy (CFG-DP), a novel framework to enhance DP by
integrating Classifier-Free Guidance (CFG) with conditional and unconditional
models. Specifically, CFG leverages timestep inputs to track task progression
and ensure precise cycle termination. It dynamically adjusts action predictions
based on task phase, using a guidance factor tuned to balance temporal
coherence and action accuracy. Real-world experiments on a humanoid robot
demonstrate high success rates and minimal repetitive actions. Furthermore, we
assessed the model's ability to terminate actions and examined how different
components and parameter adjustments affect its performance. This framework
significantly enhances deterministic control and execution reliability for
sequential robotic tasks.

</details>


### [939] [Cross-Sensor Touch Generation](https://arxiv.org/abs/2510.09817)
*Samanta Rodriguez,Yiming Dou,Miquel Oller,Andrew Owens,Nima Fazeli*

Main category: cs.RO

TL;DR: 提出两种跨传感器图像生成方法：Touch2Touch（需要配对数据）和T2D2（需要中间深度表示），以解决通用触觉表示的挑战，并成功应用于下游任务。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉-触觉传感器形态各异，导致开发通用的触觉表示模型面临挑战，因为大多数模型都与特定传感器设计相关联。

Method: 提出两种跨传感器图像生成方法：1. 端到端方法（Touch2Touch），利用配对数据。2. T2D2（Touch-to-Depth-to-Touch），构建中间深度表示，无需配对数据。

Result: 两种方法均能通过跨传感器触觉生成过程，实现传感器特定模型的跨传感器应用。在手部姿态估计和行为克隆等下游任务中验证了其有效性，成功将在一个传感器上训练的模型迁移到另一个传感器。

Conclusion: 所提出的模型为传感器转换提供了灵活的解决方案，具体取决于数据的可用性和应用需求。

Abstract: Today's visuo-tactile sensors come in many shapes and sizes, making it
challenging to develop general-purpose tactile representations. This is because
most models are tied to a specific sensor design. To address this challenge, we
propose two approaches to cross-sensor image generation. The first is an
end-to-end method that leverages paired data (Touch2Touch). The second method
builds an intermediate depth representation and does not require paired data
(T2D2: Touch-to-Depth-to-Touch). Both methods enable the use of sensor-specific
models across multiple sensors via the cross-sensor touch generation process.
Together, these models offer flexible solutions for sensor translation,
depending on data availability and application needs. We demonstrate their
effectiveness on downstream tasks such as in-hand pose estimation and behavior
cloning, successfully transferring models trained on one sensor to another.
Project page: https://samantabelen.github.io/cross_sensor_touch_generation.

</details>


### [940] [VG-Mapping: Variation-Aware 3D Gaussians for Online Semi-static Scene Mapping](https://arxiv.org/abs/2510.09962)
*Yicheng He,Jingwen Yu,Guangcheng Chen,Hong Zhang*

Main category: cs.RO

TL;DR: VG-Mapping是一个新的在线3DGS建图系统，用于半静态场景，通过结合3DGS和TSDF来有效识别变化区域，并使用感知变化的密度控制策略来更新高斯图元，解决了现有3DGS在线更新效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS技术在半静态场景的在线地图更新方面存在效率和准确性问题，可能导致地图质量下降、定位不准、操作低效甚至机器人迷路。

Method: 提出VG-Mapping系统，采用混合表示（3DGS + TSDF体素地图）来高效识别场景中的变化区域，并结合感知变化的密度控制策略来动态地插入或删除高斯图元以更新变化区域。

Result: 实验结果表明，VG-Mapping在半静态场景下显著提高了渲染质量和地图更新效率。

Conclusion: VG-Mapping通过结合3DGS和TSDF以及引入感知变化的密度控制策略，有效地解决了半静态场景下的在线地图更新问题，提高了效率和质量。

Abstract: Maintaining an up-to-date map that accurately reflects recent changes in the
environment is crucial, especially for robots that repeatedly traverse the same
space. Failing to promptly update the changed regions can degrade map quality,
resulting in poor localization, inefficient operations, and even lost robots.
3D Gaussian Splatting (3DGS) has recently seen widespread adoption in online
map reconstruction due to its dense, differentiable, and photorealistic
properties, yet accurately and efficiently updating the regions of change
remains a challenge. In this paper, we propose VG-Mapping, a novel online
3DGS-based mapping system tailored for such semi-static scenes. Our approach
introduces a hybrid representation that augments 3DGS with a TSDF-based voxel
map to efficiently identify changed regions in a scene, along with a
variation-aware density control strategy that inserts or deletes Gaussian
primitives in regions undergoing change. Furthermore, to address the absence of
public benchmarks for this task, we construct a RGB-D dataset comprising both
synthetic and real-world semi-static environments. Experimental results
demonstrate that our method substantially improves the rendering quality and
map update efficiency in semi-static scenes. The code and dataset are available
at https://github.com/heyicheng-never/VG-Mapping.

</details>


### [941] [LLM-HBT: Dynamic Behavior Tree Construction for Adaptive Coordination in Heterogeneous Robots](https://arxiv.org/abs/2510.09963)
*Chaoran Wang,Jingyuan Sun,Yanhui Zhang,Mingyu Zhang,Changju Wu*

Main category: cs.RO

TL;DR: 我们提出了一种利用大型语言模型（LLM）动态生成和扩展行为树（BT）的新框架，以应对异构多机器人系统在动态环境中适应性和鲁棒性的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统机器人受限于固定的功能属性，难以应对任务失败或环境变化。本框架旨在克服这一限制，通过LLM的推理和泛化能力结合BT的模块化和恢复能力，实现机器人策略的动态重构。

Method: 该框架包含任务初始化、任务分配、BT更新和失败节点检测四个模块，形成闭环。机器人执行BT，遇失败节点时可本地扩展BT或通过中央协调器（Alex）重新分配子任务和同步BT。

Result: 在模拟场景和真实咖啡馆环境中，针对60个任务的测试表明，该框架在任务成功率、鲁棒性和可扩展性方面持续优于基线方法。

Conclusion: 该框架能够实现异构机器人团队的长期协同执行，在复杂场景下展现出有效的机器人协作能力。

Abstract: We introduce a novel framework for automatic behavior tree (BT) construction
in heterogeneous multi-robot systems, designed to address the challenges of
adaptability and robustness in dynamic environments. Traditional robots are
limited by fixed functional attributes and cannot efficiently reconfigure their
strategies in response to task failures or environmental changes. To overcome
this limitation, we leverage large language models (LLMs) to generate and
extend BTs dynamically, combining the reasoning and generalization power of
LLMs with the modularity and recovery capability of BTs. The proposed framework
consists of four interconnected modules task initialization, task assignment,
BT update, and failure node detection which operate in a closed loop. Robots
tick their BTs during execution, and upon encountering a failure node, they can
either extend the tree locally or invoke a centralized virtual coordinator
(Alex) to reassign subtasks and synchronize BTs across peers. This design
enables long-term cooperative execution in heterogeneous teams. We validate the
framework on 60 tasks across three simulated scenarios and in a real-world cafe
environment with a robotic arm and a wheeled-legged robot. Results show that
our method consistently outperforms baseline approaches in task success rate,
robustness, and scalability, demonstrating its effectiveness for multi-robot
collaboration in complex scenarios.

</details>


### [942] [FORM: Fixed-Lag Odometry with Reparative Mapping utilizing Rotating LiDAR Sensors](https://arxiv.org/abs/2510.09966)
*Easton R. Potokar,Taylor Pool,Daniel McGann,Michael Kaess*

Main category: cs.RO

TL;DR: FORM是一种新的激光雷达里程计方法，可以实现实时、准确和平滑的轨迹估计。


<details>
  <summary>Details</summary>
Motivation: 现有激光雷达里程计方法大多基于子图，一次估计一个状态，容易传播误差并导致轨迹抖动，且无法实时进行平滑处理。

Method: FORM通过在密集连接因子图上进行平滑处理，并使用单一迭代地图进行匹配，实现了实时性能和对局部地图的主动纠正。

Result: FORM在多种数据集上进行了评估，证明其鲁棒性、准确性、实时性，并能提供比现有最先进方法更平滑的轨迹估计。

Conclusion: FORM是一种先进的激光雷达里程计方法，解决了现有方法的不足，能够实现实时、准确和平滑的轨迹估计。

Abstract: Light Detection and Ranging (LiDAR) sensors have become a de-facto sensor for
many robot state estimation tasks, spurring development of many LiDAR Odometry
(LO) methods in recent years. While some smoothing-based LO methods have been
proposed, most require matching against multiple scans, resulting in
sub-real-time performance. Due to this, most prior works estimate a single
state at a time and are ``submap''-based. This architecture propagates any
error in pose estimation to the fixed submap and can cause jittery trajectories
and degrade future registrations. We propose Fixed-Lag Odometry with Reparative
Mapping (FORM), a LO method that performs smoothing over a densely connected
factor graph while utilizing a single iterative map for matching. This allows
for both real-time performance and active correction of the local map as pose
estimates are further refined. We evaluate on a wide variety of datasets to
show that FORM is robust, accurate, real-time, and provides smooth trajectory
estimates when compared to prior state-of-the-art LO methods.

</details>


### [943] [ATRos: Learning Energy-Efficient Agile Locomotion for Wheeled-legged Robots](https://arxiv.org/abs/2510.09980)
*Jingyuan Sun,Hongyu Ji,Zihan Qu,Chaoran Wang,Mingyu Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一个基于强化学习（RL）的混合运动框架ATRos，用于轮腿式机器人，实现了高效且适应性强的混合行走-驾驶运动，无需预设步态，并通过仿真和真实实验验证了其在不同地形上的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 轮腿式机器人的混合运动结合了足式运动的灵活性和轮式运动的效率，但其全身控制仍然是一个挑战。

Method: 提出了一种基于强化学习（RL）的混合运动框架ATRos。该框架构建了一个预测策略网络，用于从本体感觉信息估计外部环境状态，并将输出输入到Actor-Critic网络以生成最优关节指令，从而协调轮子和腿部的运动。

Result: 所提出的框架在仿真和真实世界实验中，包括平坦地面、楼梯和草地等多种地形上，都表现出了鲁棒的性能，证明了其在各种未见地形上的泛化能力。

Conclusion: ATRos框架能够智能协调轮子和腿部的运动，实现改进的地形适应性和能源效率，并且具有良好的泛化能力。

Abstract: Hybrid locomotion of wheeled-legged robots has recently attracted increasing
attention due to their advantages of combining the agility of legged locomotion
and the efficiency of wheeled motion. But along with expanded performance, the
whole-body control of wheeled-legged robots remains challenging for hybrid
locomotion. In this paper, we present ATRos, a reinforcement learning
(RL)-based hybrid locomotion framework to achieve hybrid walking-driving
motions on the wheeled-legged robot. Without giving predefined gait patterns,
our planner aims to intelligently coordinate simultaneous wheel and leg
movements, thereby achieving improved terrain adaptability and improved energy
efficiency. Based on RL techniques, our approach constructs a prediction policy
network that could estimate external environmental states from proprioceptive
sensory information, and the outputs are then fed into an actor critic network
to produce optimal joint commands. The feasibility of the proposed framework is
validated through both simulations and real-world experiments across diverse
terrains, including flat ground, stairs, and grassy surfaces. The hybrid
locomotion framework shows robust performance over various unseen terrains,
highlighting its generalization capability.

</details>


### [944] [Hybrid Robotic Meta-gripper for Tomato Harvesting: Analysis of Auxetic Structures with Lattice Orientation Variations](https://arxiv.org/abs/2510.10016)
*Shahid Ansari,Vivek Gupta,Bishakh Bhattacharya*

Main category: cs.RO

TL;DR: 本研究介绍了一种用于番茄采摘的新型混合夹爪，该夹爪结合了刚性外框和软质吸能网格。研究了吸能网格方向对抓取顺应性的影响，并结合了实验验证和有限元分析。结果表明，网格方向显著影响顺应性、接触力和能效，为优化机器人夹爪性能提供了新的见解，并有助于推进精准农业的自动化。


<details>
  <summary>Details</summary>
Motivation: 全球粮食需求不断增长，但果蔬处理等劳动密集型任务效率低下并导致收获后损失，自动化（特别是选择性收获）是解决此问题的关键，而软体机器人是重要的推动者。

Method: 开发了一种新型混合夹爪，结合了刚性外框和软质吸能内网格，采用六指三维笼式设计。研究了不同倾斜角度（0、30、45、60度）的吸能结构对抓取顺应性的影响，并结合了2D数字图像相关（DIC）和非线性有限元分析（FEA）进行实验验证。

Result: 研究结果表明，吸能网格的取向对夹爪的顺应性、接触力和能耗有显著影响，不同构型在抓取性能上各有优势。

Conclusion: 本研究提出了一种定制吸能几何形状以优化机器人夹爪性能的比较框架，为软-硬混合夹爪设计提供了新的见解，有助于在最小化作物损伤的同时推进精准农业的自动化策略。

Abstract: The agricultural sector is rapidly evolving to meet growing global food
demands, yet tasks like fruit and vegetable handling remain labor-intensive,
causing inefficiencies and post-harvest losses. Automation, particularly
selective harvesting, offers a viable solution, with soft robotics emerging as
a key enabler. This study introduces a novel hybrid gripper for tomato
harvesting, incorporating a rigid outer frame with a soft auxetic internal
lattice. The six-finger, 3D caging-effect design enables gentle yet secure
grasping in unstructured environments. Uniquely, the work investigates the
effect of auxetic lattice orientation on grasping conformability, combining
experimental validation with 2D Digital Image Correlation (DIC) and nonlinear
finite element analysis (FEA). Auxetic configurations with unit cell
inclinations of 0 deg, 30 deg, 45 deg, and 60 deg are evaluated, and their
grasping forces, deformation responses, and motor torque requirements are
systematically compared. Results demonstrate that lattice orientation strongly
influences compliance, contact forces, and energy efficiency, with distinct
advantages across configurations. This comparative framework highlights the
novelty of tailoring auxetic geometries to optimize robotic gripper
performance. The findings provide new insights into soft-rigid hybrid gripper
design, advancing automation strategies for precision agriculture while
minimizing crop damage.

</details>


### [945] [LOMORO: Long-term Monitoring of Dynamic Targets with Minimum Robotic Fleet under Resource Constraints](https://arxiv.org/abs/2510.10046)
*Mingke Lu,Shuaikang Wang,Meng Guo*

Main category: cs.RO

TL;DR: 该研究提出了一种名为LOMORO的在线协同方案，用于多机器人协同目标监控、路径规划和资源充电。该方案通过对资源受限和监控间隔约束下的多机器人任务分配问题进行建模，并设计了一种资源感知的任务协调算法，能够在保证监控间隔和机器人资源水平的同时，最小化机器人数量。


<details>
  <summary>Details</summary>
Motivation: 长期监控动态目标（如野生鸟群、入侵者、搜救对象）对人类操作员来说是繁琐的，对单个机器人来说是不可行的。因此，需要一个能够有效协同工作的机器人集群。

Method: 提出LOMORO方案，包含三个核心部分：(I) 建立约束条件下的多机器人任务分配模型；(II) 设计一种资源感知的任务协调算法，结合Martin算法进行高层目标分配和低层多目标路径规划；(III) 设计在线适应算法以应对不可预测的目标行为和机器人故障。

Result: 通过大规模仿真验证了该方法的有效性，与基线方法相比，在不同路网、机器人速度、充电速率和监控间隔下，该方法能够确保所有目标的监控间隔和服务水平，同时最小化平均活跃机器人数量。

Conclusion: LOMORO方案能够有效地解决多机器人协同监控问题，克服了现有方法在机器人数量最小化和资源约束方面的不足，并能适应动态变化的环境。

Abstract: Long-term monitoring of numerous dynamic targets can be tedious for a human
operator and infeasible for a single robot, e.g., to monitor wild flocks,
detect intruders, search and rescue. Fleets of autonomous robots can be
effective by acting collaboratively and concurrently. However, the online
coordination is challenging due to the unknown behaviors of the targets and the
limited perception of each robot. Existing work often deploys all robots
available without minimizing the fleet size, or neglects the constraints on
their resources such as battery and memory. This work proposes an online
coordination scheme called LOMORO for collaborative target monitoring, path
routing and resource charging. It includes three core components: (I) the
modeling of multi-robot task assignment problem under the constraints on
resources and monitoring intervals; (II) the resource-aware task coordination
algorithm iterates between the high-level assignment of dynamic targets and the
low-level multi-objective routing via the Martin's algorithm; (III) the online
adaptation algorithm in case of unpredictable target behaviors and robot
failures. It ensures the explicitly upper-bounded monitoring intervals for all
targets and the lower-bounded resource levels for all robots, while minimizing
the average number of active robots. The proposed methods are validated
extensively via large-scale simulations against several baselines, under
different road networks, robot velocities, charging rates and monitoring
intervals.

</details>


### [946] [Ionospheric and Plasmaspheric Delay Characterization for Lunar Terrestrial GNSS Receivers with Global Core Plasma Model](https://arxiv.org/abs/2510.10059)
*Keidai Iiyama,Grace Gao*

Main category: cs.RO

TL;DR: GNSS信号可用于月球定位，但电离层延迟是主要误差源。本文利用GCPM和自定义射线追踪算法模拟分析了电离层和等离子层延迟，结果表明低轨道路径在太阳活动高峰期延迟可超100米，但弯曲延迟较小。研究结果可用于设计鲁棒的定位和授时算法。


<details>
  <summary>Details</summary>
Motivation: 月球定位、导航和授时（PNT）的进展表明，可以利用地面GNSS信号进行月球航天器的定位和授时。然而，未建模的电离层和等离子层延迟仍然是一个显著的误差源，尤其是在月球的信号几何形状和扩展传播路径下。

Method: 使用全球核心等离子体模型（GCPM）和自定义的低成本射线追踪算法来表征这些延迟，该算法迭代地求解弯曲的信号路径。模拟了在不同太阳和地磁条件下，在月球轨道和月球南极接收的GNSS信号的一阶、二阶和三阶群延迟以及由射线弯曲引起的额外路径长度。

Result: 平均群延迟通常在1米左右，但在高太阳活动期间，对于低海拔射线路径，延迟可能超过100米。而弯曲延迟虽然总体上较小，但对于低海拔射线路径来说不可忽略。此外，研究还量化了信号频率、地磁Kp指数和太阳R12指数的影响。

Conclusion: 这些发现为利用地面GNSS信号的鲁棒定位和授时算法的设计提供了信息。

Abstract: Recent advancements in lunar positioning, navigation, and timing (PNT) have
demonstrated that terrestrial GNSS signals, including weak sidelobe
transmissions, can be exploited for lunar spacecraft positioning and timing.
While GNSS-based navigation at the Moon has been validated recently, unmodeled
ionospheric and plasmaspheric delays remain a significant error source,
particularly given the unique signal geometry and extended propagation paths.
This paper characterizes these delays using the Global Core Plasma Model (GCPM)
and a custom low-cost ray-tracing algorithm that iteratively solves for bent
signal paths. We simulate first-, second-, and third-order group delays, as
well as excess path length from ray bending, for GNSS signals received at both
lunar orbit and the lunar south pole under varying solar and geomagnetic
conditions. Results show that mean group delays are typically on the order of 1
m, but can exceed 100 m for low-altitude ray paths during high solar activity,
while bending delays are generally smaller but non-negligible for low-altitude
ray paths. We also quantify the influence of signal frequency, geomagnetic
$K_p$ index, and solar R12 index. These findings inform the design of robust
positioning and timing algorithms that utilize terrestrial GNSS signals.

</details>


### [947] [Beyond ADE and FDE: A Comprehensive Evaluation Framework for Safety-Critical Prediction in Multi-Agent Autonomous Driving Scenarios](https://arxiv.org/abs/2510.10086)
*Feifei Liu,Haozhe Wang,Zejun Wei,Qirong Lu,Yiyang Wen,Xiaoyu Tang,Jingyan Jiang,Zhijian He*

Main category: cs.RO

TL;DR: 现有自动驾驶预测模型评估指标过于简化，无法应对复杂、互动和安全关键的驾驶场景。本文提出新的测试框架，考虑场景结构、地图上下文、交通密度和空间分布，量化了邻近代理对轨迹预测的影响，并识别出传统指标无法暴露的特定场景故障案例，旨在促进更鲁棒、可认证的预测系统开发。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶预测模型评估方法（如ADE、FDE）过于简单，无法在复杂、互动和安全关键的驾驶场景下充分评估预测模型的性能，未能区分邻近与远处代理的影响，也未能系统地测试模型在不同多代理交互下的鲁棒性。

Method: 提出一个新的测试框架，该框架能够评估在不同场景结构、地图上下文、代理密度和空间分布下的预测性能。通过广泛的实证分析，量化了代理邻近度对目标轨迹预测的不同影响，并识别了传统指标无法暴露的特定场景故障案例。

Result: 已量化代理邻近度对目标轨迹预测的影响，并识别出当前最先进的预测模型在特定场景下的关键脆弱性，这些脆弱性是传统指标无法暴露的。

Conclusion: 现有的预测模型评估方法存在不足，无法充分应对复杂驾驶场景。本文提出的场景感知评估框架对于识别易发生故障的边缘情况和开发稳健、可认证的自动驾驶汽车预测系统至关重要。

Abstract: Current evaluation methods for autonomous driving prediction models rely
heavily on simplistic metrics such as Average Displacement Error (ADE) and
Final Displacement Error (FDE). While these metrics offer basic performance
assessments, they fail to capture the nuanced behavior of prediction modules
under complex, interactive, and safety-critical driving scenarios. For
instance, existing benchmarks do not distinguish the influence of nearby versus
distant agents, nor systematically test model robustness across varying
multi-agent interactions. This paper addresses this critical gap by proposing a
novel testing framework that evaluates prediction performance under diverse
scene structures, saying, map context, agent density and spatial distribution.
Through extensive empirical analysis, we quantify the differential impact of
agent proximity on target trajectory prediction and identify scenario-specific
failure cases that are not exposed by traditional metrics. Our findings
highlight key vulnerabilities in current state-of-the-art prediction models and
demonstrate the importance of scenario-aware evaluation. The proposed framework
lays the groundwork for rigorous, safety-driven prediction validation,
contributing significantly to the identification of failure-prone corner cases
and the development of robust, certifiable prediction systems for autonomous
vehicles.

</details>


### [948] [Ctrl-World: A Controllable Generative World Model for Robot Manipulation](https://arxiv.org/abs/2510.10125)
*Yanjiang Guo,Lucy Xiaoyang Shi,Jianyu Chen,Chelsea Finn*

Main category: cs.RO

TL;DR: 本研究提出了一个可控的多视角世界模型，用于评估和改进通用机器人策略的指令遵循能力。该模型通过姿态条件记忆检索保持长时一致性，并通过帧级动作条件实现精确动作控制。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略在处理不熟悉物体和指令时存在评估和改进困难，现有方法（如真实世界回滚）成本高、速度慢。世界模型提供了一种可扩展的替代方案，但现有世界模型在处理多步交互、多视角预测、精细动作控制和长时一致性方面存在不足。

Method: 提出了一种可控的多视角世界模型，利用姿态条件记忆检索机制来维持长时一致性，并通过帧级动作条件来实现精确的动作控制。

Result: 在DROID数据集（95k轨迹，564个场景）上训练的模型，能够在新场景和新相机设置下生成超过20秒的空间和时间上一致的轨迹。该模型能够准确地对策略性能进行排名，而无需真实的机器人回滚。通过合成成功的轨迹并进行监督微调，策略成功率提高了44.7%。

Conclusion: 所提出的可控多视角世界模型能够有效地评估和改进通用机器人策略的指令遵循能力，克服了现有方法的局限性，并在效率和性能提升方面取得了显著成果。

Abstract: Generalist robot policies can now perform a wide range of manipulation
skills, but evaluating and improving their ability with unfamiliar objects and
instructions remains a significant challenge. Rigorous evaluation requires a
large number of real-world rollouts, while systematic improvement demands
additional corrective data with expert labels. Both of these processes are
slow, costly, and difficult to scale. World models offer a promising, scalable
alternative by enabling policies to rollout within imagination space. However,
a key challenge is building a controllable world model that can handle
multi-step interactions with generalist robot policies. This requires a world
model compatible with modern generalist policies by supporting multi-view
prediction, fine-grained action control, and consistent long-horizon
interactions, which is not achieved by previous works. In this paper, we make a
step forward by introducing a controllable multi-view world model that can be
used to evaluate and improve the instruction-following ability of generalist
robot policies. Our model maintains long-horizon consistency with a
pose-conditioned memory retrieval mechanism and achieves precise action control
through frame-level action conditioning. Trained on the DROID dataset (95k
trajectories, 564 scenes), our model generates spatially and temporally
consistent trajectories under novel scenarios and new camera placements for
over 20 seconds. We show that our method can accurately rank policy performance
without real-world robot rollouts. Moreover, by synthesizing successful
trajectories in imagination and using them for supervised fine-tuning, our
approach can improve policy success by 44.7\%.

</details>


### [949] [It Takes Two: Learning Interactive Whole-Body Control Between Humanoid Robots](https://arxiv.org/abs/2510.10206)
*Zuhong Liu,Junhao Ge,Minhao Xiong,Jiahao Gu,Bowei Tang,Wei Jing,Siheng Chen*

Main category: cs.RO

TL;DR: Harmanoid是一个用于双机器人运动模仿的框架，可以实现机器人之间富有意义的全身互动，克服了单机器人方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 单机器人方法在处理多机器人互动时存在隔离问题，会导致接触不协调、穿模和不真实的运动。然而，真正的人形机器人潜力在于多机器人之间的物理交互和社交互动，这模仿了丰富的人类社交互动。

Method: Harmanoid框架包含两个主要组件：(1) 接触感知运动重定向，通过将SMPL接触与机器人顶点对齐来恢复机器人之间的协调；(2) 交互驱动运动控制器，利用特定于交互的奖励来强制执行协调的关键点和物理上可行的接触。

Result: 实验证明，Harmanoid在交互运动模仿方面显著优于现有的单机器人方法，后者在这种场景下通常会失败。

Conclusion: Harmanoid通过显式建模机器人之间的接触和交互感知动力学，成功捕捉了单机器人框架固有地忽略的机器人耦合行为，实现了更真实、更协调的双机器人交互运动。

Abstract: The true promise of humanoid robotics lies beyond single-agent autonomy: two
or more humanoids must engage in physically grounded, socially meaningful
whole-body interactions that echo the richness of human social interaction.
However, single-humanoid methods suffer from the isolation issue, ignoring
inter-agent dynamics and causing misaligned contacts, interpenetrations, and
unrealistic motions. To address this, we present Harmanoid , a dual-humanoid
motion imitation framework that transfers interacting human motions to two
robots while preserving both kinematic fidelity and physical realism. Harmanoid
comprises two key components: (i) contact-aware motion retargeting, which
restores inter-body coordination by aligning SMPL contacts with robot vertices,
and (ii) interaction-driven motion controller, which leverages
interaction-specific rewards to enforce coordinated keypoints and physically
plausible contacts. By explicitly modeling inter-agent contacts and
interaction-aware dynamics, Harmanoid captures the coupled behaviors between
humanoids that single-humanoid frameworks inherently overlook. Experiments
demonstrate that Harmanoid significantly improves interactive motion imitation,
surpassing existing single-humanoid frameworks that largely fail in such
scenarios.

</details>


### [950] [CompassNav: Steering From Path Imitation To Decision Understanding In Navigation](https://arxiv.org/abs/2510.10154)
*LinFeng Li,Jian Zhao,Yuan Xie,Xin Tan,Xuelong Li*

Main category: cs.RO

TL;DR: 模仿专家轨迹的范式限制了导航机器人的探索和泛化能力。本文提出了一种新的范式，从路径模仿转向决策理解，通过引入包含A*测地线距离注释的Compass-Data-22k数据集和一种结合最大化奖励和探索奖励的混合奖励函数，训练CompassNav代理，使其在导航任务上达到最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的导航机器人训练范式主要依赖模仿专家轨迹，这种方法将复杂的导航任务简化为单一正确路径的序列到序列复制，限制了机器人的探索和泛化能力。

Method: 提出了一种新的范式，从路径模仿转向决策理解。引入了Compass-Data-22k数据集，其RFT子集包含了所有可行动作的A*测地线距离注释。设计了一种间隙感知混合奖励函数，该函数能够根据决策的确定性动态调整反馈，在最优动作和鼓励探索之间进行权衡。将此集成到SFT-then-RFT的训练流程中，训练CompassNav代理。

Result: CompassNav代理在目标导航基准测试中取得了新的最先进成果，性能优于更大规模的专有模型，并在实体机器人上实现了鲁棒的真实世界目标导航。

Conclusion: 新的决策理解范式使导航代理能够超越简单的路径模仿，通过评估所有可能移动的相对质量来发展内部的“指南针”，从而实现更强的导航能力。

Abstract: The dominant paradigm for training Large Vision-Language Models (LVLMs) in
navigation relies on imitating expert trajectories. This approach reduces the
complex navigation task to a sequence-to-sequence replication of a single
correct path, fundamentally limiting the agent's ability to explore and
generalize. In this work, we argue for and introduce a new paradigm: a shift
from Path Imitation to Decision Understanding. The goal of this paradigm is to
build agents that do not just follow, but truly understand how to navigate. We
materialize this through two core contributions: first, we introduce
Compass-Data-22k, a novel 22k-trajectory dataset.Its Reinforcement Fine-Tuning
(RFT) subset provides a panoramic view of the decision landscape by annotating
all feasible actions with A* geodesic distances. Second, we design a novel
gap-aware hybrid reward function that dynamically adapts its feedback to
decision certainty, shifting between decisive signals for optimal actions and
nuanced scores to encourage exploration. Integrated into an SFT-then-RFT
recipe, our CompassNav agent is trained not to memorize static routes, but to
develop an internal ``compass'' that constantly intuits the direction to the
goal by evaluating the relative quality of all possible moves. This approach
enables our 7B agent to set a new state-of-the-art on Goal navigation
benchmarks, outperforming even larger proprietary models, and achieve robust
real-world goal navigation on a physical robot.

</details>


### [951] [RobotFleet: An Open-Source Framework for Centralized Multi-Robot Task Planning](https://arxiv.org/abs/2510.10379)
*Rohan Gupta,Trevor Asbery,Zain Merchant,Abrar Anwar,Jesse Thomason*

Main category: cs.RO

TL;DR: RobotFleet是一个开源框架，利用LLM协调异构机器人车队以实现多重目标。


<details>
  <summary>Details</summary>
Motivation: 在多机器人系统中，协调异构机器人车队以实现多重目标具有挑战性。

Method: RobotFleet提供了一个用于规划、调度和跨服务部署的机器人执行的抽象。它通过维护共享的声明式世界状态和双向通信来实现任务执行和重新规划。该框架利用LLM进行开放世界推理，并实现了自主堆栈的模块化。

Result: 该框架能够简化机器人集群的扩展和管理。

Conclusion: RobotFleet通过模块化自主堆栈和利用LLM进行开放世界推理，降低了构建可扩展的多机器人系统的门槛。

Abstract: Coordinating heterogeneous robot fleets to achieve multiple goals is
challenging in multi-robot systems. We introduce an open-source and extensible
framework for centralized multi-robot task planning and scheduling that
leverages LLMs to enable fleets of heterogeneous robots to accomplish multiple
tasks. RobotFleet provides abstractions for planning, scheduling, and execution
across robots deployed as containerized services to simplify fleet scaling and
management. The framework maintains a shared declarative world state and
two-way communication for task execution and replanning. By modularizing each
layer of the autonomy stack and using LLMs for open-world reasoning, RobotFleet
lowers the barrier to building scalable multi-robot systems. The code can be
found here: https://github.com/therohangupta/robot-fleet.

</details>


### [952] [Dejavu: Post-Deployment Learning for Embodied Agents via Experience Feedback](https://arxiv.org/abs/2510.10181)
*Shaokai Wu,Yanbiao Ji,Qiuchang Li,Zhiyi Zhang,Qichen He,Wenyuan Xie,Guodong Zhang,Bayram Bayramli,Yue Ding,Hongtao Lu*

Main category: cs.RO

TL;DR: 该研究提出了一种名为Dejavu的通用部署后学习框架，用于解决实体智能体在部署后无法获取新知识以提升任务性能的局限性。


<details>
  <summary>Details</summary>
Motivation: 实体智能体在部署后无法获取新知识以提升任务性能。

Method: 提出Dejavu框架，包含经验反馈网络（EFN）。EFN通过检索先前的成功经验来增强固定的视觉-语言-动作（VLA）策略。利用基于语义相似性奖励的强化学习来训练EFN，使其预测的动作与过去的成功行为保持一致。EFN在部署过程中不断学习新的轨迹来丰富其记忆库。

Result: 在多种实体任务的实验中，Dejavu框架显著提高了智能体的适应性、鲁棒性和成功率，优于固定的基线模型。

Conclusion: Dejavu框架为部署后能够持续改进行为的实体智能体提供了一条有前景的研究路径。

Abstract: Embodied agents face a fundamental limitation: once deployed in real-world
environments to perform specific tasks, they are unable to acquire new useful
knowledge to enhance task performance. In this paper, we propose a general
post-deployment learning framework called Dejavu, which employs an Experience
Feedback Network (EFN) and augments the frozen Vision-Language-Action (VLA)
policy with retrieved execution memories. EFN automatically identifies
contextually successful prior action experiences and conditions action
prediction on this retrieved guidance. We adopt reinforcement learning with
semantic similarity rewards on EFN to ensure that the predicted actions align
with past successful behaviors under current observations. During deployment,
EFN continually enriches its memory with new trajectories, enabling the agent
to exhibit "learning from experience" despite fixed weights. Experiments across
diverse embodied tasks show that EFN significantly improves adaptability,
robustness, and success rates over frozen baselines. These results highlight a
promising path toward embodied agents that continually refine their behavior
after deployment.

</details>


### [953] [Two-Layer Voronoi Coverage Control for Hybrid Aerial-Ground Robot Teams in Emergency Response: Implementation and Analysis](https://arxiv.org/abs/2510.10781)
*Douglas Hutchings,Luai Abuelsamen,Karthik Rajgopal*

Main category: cs.RO

TL;DR: 提出了一种改进的Voronoi覆盖控制方法，用于协调空中和地面机器人团队执行危险品应急响应任务，通过解耦的二层架构优化空中和地面机器人的定位，并引入了空中机器人空投传感器到高优先级区域的策略。


<details>
  <summary>Details</summary>
Motivation: 传统Voronoi覆盖控制方法在应急响应中面临异构机器人能力、初始部署聚集和时间紧迫性等挑战，无法满足快速响应的需求。

Method: 采用解耦的二层架构，分别优化空中和地面机器人定位；空中机器人通过空投传感器到高优先级地点；实现有界的Voronoi单元计算，高效的数值积分技术，以及防止机器人陷入的鲁棒控制策略。

Result: 在模拟中，与仅使用地面部署相比，该方法将响应时间缩短了88%，在25秒内实现了目标传感器覆盖（初始传感器损失18.5%），而地面部署则需要220秒。

Conclusion: 所提出的两层Voronoi覆盖控制方法能够有效应对危险品应急响应场景中异构机器人协调的挑战，显著提高响应速度和覆盖效率。

Abstract: We present a comprehensive two-layer Voronoi coverage control approach for
coordinating hybrid aerial-ground robot teams in hazardous material emergency
response scenarios. Traditional Voronoi coverage control methods face three
critical limitations in emergency contexts: heterogeneous agent capabilities
with vastly different velocities, clustered initial deployment configurations,
and urgent time constraints requiring rapid response rather than eventual
convergence. Our method addresses these challenges through a decoupled
two-layer architecture that separately optimizes aerial and ground robot
positioning, with aerial agents delivering ground sensors via airdrop to
high-priority locations. We provide detailed implementation of bounded Voronoi
cell computation, efficient numerical integration techniques for
importance-weighted centroids, and robust control strategies that prevent agent
trapping. Simulation results demonstrate an 88% reduction in response time,
achieving target sensor coverage (18.5% of initial sensor loss) in 25 seconds
compared to 220 seconds for ground-only deployment. Complete implementation
code is available at https://github.com/dHutchings/ME292B.

</details>


### [954] [UF-RNN: Real-Time Adaptive Motion Generation Using Uncertainty-Driven Foresight Prediction](https://arxiv.org/abs/2510.10217)
*Hyogo Hiruma,Hiroshi Ito,Tetsuya Ogata*

Main category: cs.RO

TL;DR: UF-RNN通过引入“前瞻”模块来处理机器人操作中的不确定性，该模块通过内部模拟和最小化预测方差来优化隐藏状态，从而提高在不确定环境下的成功率。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中，尤其是在处理状态不确定的环境（例如，模糊的对象属性或不可预测的交互）时，机器人如何有效运作是一个长期存在的挑战。现有的模仿学习方法通常依赖于成功的示例，而忽略了不确定性最显著的失败场景。

Method: 提出了一种名为不确定性驱动前瞻循环神经网络（UF-RNN）的模型，该模型将标准的时间序列预测与一个主动的“前瞻”模块相结合。该模块执行对多个未来轨迹的内部模拟，并优化隐藏状态以最小化预测方差，使模型能够在不确定性较高的情况下有选择地探索动作。

Result: 在模拟和真实机器人环境中，UF-RNN 在开门任务中表现出鲁棒的适应性。其前瞻模块能激励机器人在环境模糊时进行探索性行为，从而提高了成功率，优于传统的随机循环神经网络基线。

Conclusion: 将不确定性驱动的前瞻机制集成到模仿学习流程中，能够显著增强机器人应对不可预测的现实世界条件的能力。

Abstract: Training robots to operate effectively in environments with uncertain states,
such as ambiguous object properties or unpredictable interactions, remains a
longstanding challenge in robotics. Imitation learning methods typically rely
on successful examples and often neglect failure scenarios where uncertainty is
most pronounced. To address this limitation, we propose the Uncertainty-driven
Foresight Recurrent Neural Network (UF-RNN), a model that combines standard
time-series prediction with an active "Foresight" module. This module performs
internal simulations of multiple future trajectories and refines the hidden
state to minimize predicted variance, enabling the model to selectively explore
actions under high uncertainty. We evaluate UF-RNN on a door-opening task in
both simulation and a real-robot setting, demonstrating that, despite the
absence of explicit failure demonstrations, the model exhibits robust
adaptation by leveraging self-induced chaotic dynamics in its latent space.
When guided by the Foresight module, these chaotic properties stimulate
exploratory behaviors precisely when the environment is ambiguous, yielding
improved success rates compared to conventional stochastic RNN baselines. These
findings suggest that integrating uncertainty-driven foresight into imitation
learning pipelines can significantly enhance a robot's ability to handle
unpredictable real-world conditions.

</details>


### [955] [A3RNN: Bi-directional Fusion of Bottom-up and Top-down Process for Developmental Visual Attention in Robots](https://arxiv.org/abs/2510.10221)
*Hyogo Hiruma,Hiroshi Ito,Hiroki Mori,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 本研究提出了 A^3 RNN 模型，用于在机器人学习中模拟自上而下和自下而上的视觉注意力发展交互，实验表明注意力行为随训练过程演变，从显著性驱动转向预测驱动。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在理解在机器人学习中，顶层（TD）和底层（BU）视觉注意力的发展交互如何通过相互适应随时间演变，并最终形成类似人类的结构化注意力行为。

Method: 提出了一种新颖的注意力模型 A^3 RNN，该模型通过双向注意力架构整合了预测性的 TD 信号和基于显著性的 BU 提示。

Result: 实验结果表明，在训练过程中，注意力行为发生了演变：最初 BU 注意力突出视觉显著区域以引导 TD 过程，随后 TD 注意力趋于稳定并反过来重塑感知到的显著区域。该模型比基线模型表现出更连贯、可解释的注意力模式。

Conclusion: 本研究的发现支持了发展机制在形成稳健注意力方面的重要性，并表明注意力行为的演变轨迹与认知科学和自由能框架的原理一致。

Abstract: This study investigates the developmental interaction between top-down (TD)
and bottom-up (BU) visual attention in robotic learning. Our goal is to
understand how structured, human-like attentional behavior emerges through the
mutual adaptation of TD and BU mechanisms over time. To this end, we propose a
novel attention model $A^3 RNN$ that integrates predictive TD signals and
saliency-based BU cues through a bi-directional attention architecture.
  We evaluate our model in robotic manipulation tasks using imitation learning.
Experimental results show that attention behaviors evolve throughout training,
from saliency-driven exploration to prediction-driven direction. Initially, BU
attention highlights visually salient regions, which guide TD processes, while
as learning progresses, TD attention stabilizes and begins to reshape what is
perceived as salient. This trajectory reflects principles from cognitive
science and the free-energy framework, suggesting the importance of
self-organizing attention through interaction between perception and internal
prediction. Although not explicitly optimized for stability, our model exhibits
more coherent and interpretable attention patterns than baselines, supporting
the idea that developmental mechanisms contribute to robust attention
formation.

</details>


### [956] [Coordinated Strategies in Realistic Air Combat by Hierarchical Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.11474)
*Ardian Selmonaj,Giacomo Del Rio,Adrian Schneider,Alessandro Antonucci*

Main category: cs.RO

TL;DR: 提出了一种新颖的3D多智能体空战环境和分层多智能体强化学习框架，以应对空中格斗中不完美的态势感知和非线性动力学带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 在逼真的空中格斗模拟中实现任务目标，由于态势感知不完美和非线性飞行动力学，极具挑战性。

Method: 引入了一个新颖的3D多智能体空战环境和分层多智能体强化学习框架。该方法结合了异构智能体动力学、课程学习、联赛比赛和新改编的训练算法。决策过程被组织成两个抽象级别：低级策略学习精确的控制机动，高级策略根据任务目标发布战术命令。

Result: 经验结果表明，所提出的分层方法在复杂缠斗场景中提高了学习效率和战斗性能。

Conclusion: 所提出的分层多智能体强化学习框架能够有效应对空中格斗中的挑战，并在复杂场景中取得更好的学习效率和战斗性能。

Abstract: Achieving mission objectives in a realistic simulation of aerial combat is
highly challenging due to imperfect situational awareness and nonlinear flight
dynamics. In this work, we introduce a novel 3D multi-agent air combat
environment and a Hierarchical Multi-Agent Reinforcement Learning framework to
tackle these challenges. Our approach combines heterogeneous agent dynamics,
curriculum learning, league-play, and a newly adapted training algorithm. To
this end, the decision-making process is organized into two abstraction levels:
low-level policies learn precise control maneuvers, while high-level policies
issue tactical commands based on mission objectives. Empirical results show
that our hierarchical approach improves both learning efficiency and combat
performance in complex dogfight scenarios.

</details>


### [957] [Integration of the TIAGo Robot into Isaac Sim with Mecanum Drive Modeling and Learned S-Curve Velocity Profiles](https://arxiv.org/abs/2510.10273)
*Vincent Schoenbach,Marvin Wiedemann,Raphael Memmesheimer,Malte Mosbach,Sven Behnke*

Main category: cs.RO

TL;DR: TIAGo++ Omni机器人在Isaac Sim中的仿真模型已开发并公开。


<details>
  <summary>Details</summary>
Motivation: 在机器人研究（如抓取和装配）中，高效的物理仿真至关重要，尤其是在GPU加速仿真框架（如Isaac Sim）的助力下，使得学习型方法能够应对更复杂的任务。PAL Robotics TIAGo++ Omni是一款多功能移动机器人，但此前在Isaac Sim中并无其仿真模型。本文旨在填补这一空白。

Method: 本文介绍了一个TIAGo++ Omni在Isaac Sim中的仿真模型，并着重校准了其全向驱动动力学。提出了两种控制模型：一种是物理精确模型，用于复制真实的轮子动力学；另一种是轻量级、面向学习型应用的基于速度的模型。此外，还引入了一种基于学习的校准方法，利用最小的轨迹数据记录来近似真实机器人的S形速度曲线。

Result: 成功在Isaac Sim中创建了TIAGo++ Omni的仿真模型，并提供了两种控制模型（物理精确模型和轻量级速度模型）。通过学习方法，实现了对机器人S形速度曲线的近似。仿真模型已在GitHub上公开。

Conclusion: 本文成功创建并公开了TIAGo++ Omni在Isaac Sim中的仿真模型，包括两种控制模型和一种学习驱动的校准方法，为研究人员在模拟环境中进行机器人实验和高效学习型控制提供了支持。

Abstract: Efficient physics simulation has significantly accelerated research progress
in robotics applications such as grasping and assembly. The advent of
GPU-accelerated simulation frameworks like Isaac Sim has particularly empowered
learning-based methods, enabling them to tackle increasingly complex tasks. The
PAL Robotics TIAGo++ Omni is a versatile mobile manipulator equipped with a
mecanum-wheeled base, allowing omnidirectional movement and a wide range of
task capabilities. However, until now, no model of the robot has been available
in Isaac Sim. In this paper, we introduce such a model, calibrated to
approximate the behavior of the real robot, with a focus on its omnidirectional
drive dynamics. We present two control models for the omnidirectional drive: a
physically accurate model that replicates real-world wheel dynamics and a
lightweight velocity-based model optimized for learning-based applications.
With these models, we introduce a learning-based calibration approach to
approximate the real robot's S-shaped velocity profile using minimal trajectory
data recordings. This simulation should allow researchers to experiment with
the robot and perform efficient learning-based control in diverse environments.
We provide the integration publicly at https://github.com/AIS-Bonn/tiago_isaac.

</details>


### [958] [X-VLA: Soft-Prompted Transformer as Scalable Cross-Embodiment Vision-Language-Action Model](https://arxiv.org/abs/2510.10274)
*Jinliang Zheng,Jianxiong Li,Zhihao Wang,Dongxiu Liu,Xirui Kang,Yuchun Feng,Yinan Zheng,Jiayin Zou,Yilun Chen,Jia Zeng,Ya-Qin Zhang,Jiangmiao Pang,Jingjing Liu,Tai Wang,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 通过引入特定于数据源的可学习嵌入（软提示），X-VLA 模型能够有效地利用跨实体特征，从而在各种机器人基准测试中实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了促进和利用丰富、多样化的机器人数据源中的异构性，需要一种新的方法来有效训练通用的视觉-语言-动作（VLA）模型。

Method: 提出了一种新颖的软提示方法，该方法仅添加少量参数，并将提示学习概念融入跨实体机器人学习中，为每个不同的数据源引入一组独立的可学习嵌入。X-VLA 是一个基于流匹配的 VLA 架构，它只使用软提示的标准 Transformer 编码器。

Result: 0.9B 实例化的 X-VLA-0.9B 在 6 个模拟和 3 个真实机器人上进行了评估，在各种基准测试中同时实现了最先进的性能，在从灵活的灵巧性到跨实体、环境和任务的快速适应性等广泛能力方面取得了优于现有技术的结果。

Conclusion: X-VLA 模型通过其软提示方法能够有效地利用跨实体特征，在各种机器人基准测试中取得了最先进的性能，证明了其在机器人学习方面的有效性。

Abstract: Successful generalist Vision-Language-Action (VLA) models rely on effective
training across diverse robotic platforms with large-scale, cross-embodiment,
heterogeneous datasets. To facilitate and leverage the heterogeneity in rich,
diverse robotic data sources, we propose a novel Soft Prompt approach with
minimally added parameters, by infusing prompt learning concepts into
cross-embodiment robot learning and introducing separate sets of learnable
embeddings for each distinct data source. These embeddings serve as
embodiment-specific prompts, which in unity empower VLA models with effective
exploitation of varying cross-embodiment features. Our new X-VLA, a neat
flow-matching-based VLA architecture, relies exclusively on soft-prompted
standard Transformer encoders, enjoying both scalability and simplicity.
Evaluated across 6 simulations as well as 3 real-world robots, our 0.9B
instantiation-X-VLA-0.9B simultaneously achieves SOTA performance over a sweep
of benchmarks, demonstrating superior results on a wide axes of capabilities,
from flexible dexterity to quick adaptation across embodiments, environments,
and tasks. Website: https://thu-air-dream.github.io/X-VLA/

</details>


### [959] [Towards Safe Maneuvering of Double-Ackermann-Steering Robots with a Soft Actor-Critic Framework](https://arxiv.org/abs/2510.10332)
*Kohio Deflesselle,Mélodie Daniel,Aly Magassouba,Miguel Aranda,Olivier Ly*

Main category: cs.RO

TL;DR: 我们提出了一个基于软Actor-Critic (SAC)的深度强化学习框架，用于双阿克曼转向移动机器人 (DASMRs) 的安全精确操控。


<details>
  <summary>Details</summary>
Motivation: DASMRs与全向或差速驱动机器人不同，面临严格的运动学约束，这使得传统规划器在复杂环境中容易失效。

Method: 该框架利用了事后经验回放 (HER) 和CrossQ叠加，以提高操控效率并避开障碍物。

Result: 在重型四轮转向探测车的仿真结果表明，所学的策略可以稳健地达到高达97%的目标位置，同时避开障碍物。

Conclusion: 该框架不依赖于手工设计的轨迹或专家演示。

Abstract: We present a deep reinforcement learning framework based on Soft Actor-Critic
(SAC) for safe and precise maneuvering of double-Ackermann-steering mobile
robots (DASMRs). Unlike holonomic or simpler non-holonomic robots such as
differential-drive robots, DASMRs face strong kinematic constraints that make
classical planners brittle in cluttered environments. Our framework leverages
the Hindsight Experience Replay (HER) and the CrossQ overlay to encourage
maneuvering efficiency while avoiding obstacles. Simulation results with a
heavy four-wheel-steering rover show that the learned policy can robustly reach
up to 97% of target positions while avoiding obstacles. Our framework does not
rely on handcrafted trajectories or expert demonstrations.

</details>


### [960] [Rise of the Robochemist](https://arxiv.org/abs/2510.10337)
*Jihong Zhu,Kefeng Huang,Jonathon Pipe,Chris Horbaczewsky,Andy Tyrrell,Ian J. S. Fairlamb*

Main category: cs.RO

TL;DR: 化学领域正通过机器人和人工智能（AI）的融合，即“化学机器人”的概念，迎来重大变革。化学机器人整合了多种技术，旨在辅助（而非取代）人类化学家进行实验设计、执行和分析，从而提高效率、可重复性和安全性，加速药物研发、材料科学和可持续制造等领域的创新。


<details>
  <summary>Details</summary>
Motivation: 化学领域传统上依赖手动且耗时的流程，尽管已有部分自动化，但机器人和人工智能（AI）的融合预示着一场重大变革，催生了“化学机器人”的新范式。

Method: 化学机器人整合了移动机械臂、高级感知、远程操作和数据驱动协议，以更高的适应性、可重复性和安全性执行实验。

Result: 化学机器人作为人类化学家的补充伙伴，通过增强人类的直觉和专业知识，利用机器人精度和AI洞察力，提高化学空间探索效率，加速创新。

Conclusion: 化学领域的未来在于人类直觉、专业知识与机器人精度、AI洞察力相结合的共生伙伴关系，这将加速药物研发、材料科学和可持续制造等领域的创新。

Abstract: Chemistry, a long-standing discipline, has historically relied on manual and
often time-consuming processes. While some automation exists, the field is now
on the cusp of a significant evolution driven by the integration of robotics
and artificial intelligence (AI), giving rise to the concept of the
robochemist: a new paradigm where autonomous systems assist in designing,
executing, and analyzing experiments. Robochemists integrate mobile
manipulators, advanced perception, teleoperation, and data-driven protocols to
execute experiments with greater adaptability, reproducibility, and safety.
Rather than a fully automated replacement for human chemists, we envisioned the
robochemist as a complementary partner that works collaboratively to enhance
discovery, enabling a more efficient exploration of chemical space and
accelerating innovation in pharmaceuticals, materials science, and sustainable
manufacturing. This article traces the technologies, applications, and
challenges that define this transformation, highlighting both the opportunities
and the responsibilities that accompany the emergence of the robochemist.
Ultimately, the future of chemistry is argued to lie in a symbiotic partnership
where human intuition and expertise is amplified by robotic precision and
AI-driven insight.

</details>


### [961] [sqrtVINS: Robust and Ultrafast Square-Root Filter-based 3D Motion Tracking](https://arxiv.org/abs/2510.10346)
*Yuxiang Peng,Chuchu Chen,Kejian Wu,Guoquan Huang*

Main category: cs.RO

TL;DR: 开源了一个名为sqrtVINS的超快、数值稳定的视觉-惯性导航系统(VINS)，它基于平方根滤波器(SRF)，即使在极端条件下也能进行动态初始化。


<details>
  <summary>Details</summary>
Motivation: 解决嵌入式（机器人）系统中由于资源限制和数值不稳定性导致视觉-惯性导航系统（VINS）性能下降的问题。

Method: 提出了一种新颖的基于Cholesky分解（LLT）的SRF更新方法，以提高VINS的效率，并设计了一种快速、鲁棒的动态初始化方法，首先恢复最小状态，然后迭代优化完整状态。

Result: 所提出的LLT-based SRF在数值稳定性方面表现优越，在32位单精度浮点数上实现了高效鲁棒的性能，速度是现有SOTA方法的两倍。初始化方法在各种条件下均取得了很高的初始化成功率。sqrtVINS在各种场景下得到了广泛验证，证明了其高效性、鲁棒性和可靠性。

Conclusion: sqrtVINS是一个超快、数值稳定且能够动态初始化的视觉-惯性导航系统，其性能优于现有方法，并且已开源以促进未来研究和应用。

Abstract: In this paper, we develop and open-source, for the first time, a square-root
filter (SRF)-based visual-inertial navigation system (VINS), termed sqrtVINS,
which is ultra-fast, numerically stable, and capable of dynamic initialization
even under extreme conditions (i.e., extremely small time window). Despite
recent advancements in VINS, resource constraints and numerical instability on
embedded (robotic) systems with limited precision remain critical challenges. A
square-root covariance-based filter offers a promising solution by providing
numerical stability, efficient memory usage, and guaranteed positive
semi-definiteness. However, canonical SRFs suffer from inefficiencies caused by
disruptions in the triangular structure of the covariance matrix during
updates. The proposed method significantly improves VINS efficiency with a
novel Cholesky decomposition (LLT)-based SRF update, by fully exploiting the
system structure to preserve the structure. Moreover, we design a fast, robust,
dynamic initialization method, which first recovers the minimal states without
triangulating 3D features and then efficiently performs iterative SRF update to
refine the full states, enabling seamless VINS operation. The proposed
LLT-based SRF is extensively verified through numerical studies, demonstrating
superior numerical stability and achieving robust efficient performance on
32-bit single-precision floats, operating at twice the speed of
state-of-the-art (SOTA) methods. Our initialization method, tested on both
mobile workstations and Jetson Nano computers, achieving a high success rate of
initialization even within a 100 ms window under minimal conditions. Finally,
the proposed sqrtVINS is extensively validated across diverse scenarios,
demonstrating strong efficiency, robustness, and reliability. The full
open-source implementation is released to support future research and
applications.

</details>


### [962] [Learning to Throw-Flip](https://arxiv.org/abs/2510.10357)
*Yang Liu,Bruno Da Costa,Aude Billard*

Main category: cs.RO

TL;DR: 本研究提出了一种机器人投掷物体并精确控制其落地姿态（位置和方向）的方法，解决了传统方法中物体落地方向不可控的问题。


<details>
  <summary>Details</summary>
Motivation: 传统机器人投掷技术主要关注物体落地位置，忽略了最终姿态，这限制了其在物流等领域的应用。本研究旨在实现机器人对投掷物体的精确姿态控制。

Method: 该方法基于冲量-动量原理，设计了一系列投掷动作以解耦物体在飞行中的“寄生”旋转，从而扩大了可控的落地姿态范围。结合了基于物理的自由飞行模型和基于回归的学习方法来处理未建模的效应。

Result: 在真实机器人实验中，该框架在几十次试验内能将物体投掷到目标姿态（位置误差±5厘米，姿态误差±45度）以内。通过数据同化，引入了弹道动力学，相比于端到端学习方法，在投掷到未见过姿态时样本复杂度降低了40%。此外，利用过去关于物体旋转的知识，可以在投掷具有质心偏移的新物体时将学习速度提高70%。

Conclusion: 本研究提出的投掷-翻转（throw-flip）方法能够精确控制机器人投掷物体的落地姿态，并通过结合物理模型和学习方法，有效提高了控制精度和学习效率。

Abstract: Dynamic manipulation, such as robot tossing or throwing objects, has recently
gained attention as a novel paradigm to speed up logistic operations. However,
the focus has predominantly been on the object's landing location, irrespective
of its final orientation. In this work, we present a method enabling a robot to
accurately "throw-flip" objects to a desired landing pose (position and
orientation). Conventionally, objects thrown by revolute robots suffer from
parasitic rotation, resulting in highly restricted and uncontrollable landing
poses. Our approach is based on two key design choices: first, leveraging the
impulse-momentum principle, we design a family of throwing motions that
effectively decouple the parasitic rotation, significantly expanding the
feasible set of landing poses. Second, we combine a physics-based model of free
flight with regression-based learning methods to account for unmodeled effects.
Real robot experiments demonstrate that our framework can learn to throw-flip
objects to a pose target within ($\pm$5 cm, $\pm$45 degrees) threshold in
dozens of trials. Thanks to data assimilation, incorporating projectile
dynamics reduces sample complexity by an average of 40% when throw-flipping to
unseen poses compared to end-to-end learning methods. Additionally, we show
that past knowledge on in-hand object spinning can be effectively reused,
accelerating learning by 70% when throwing a new object with a Center of Mass
(CoM) shift. A video summarizing the proposed method and the hardware
experiments is available at https://youtu.be/txYc9b1oflU.

</details>


### [963] [MicroRoboScope: A Portable and Integrated Mechatronic Platform for Magnetic and Acoustic Microrobotic Experimentation](https://arxiv.org/abs/2510.10392)
*Max Sokolich,Yanda Yang,Subrahmanyam Cherukumilli,Fatma Ceren Kirmizitas,Sambeeta Das*

Main category: cs.RO

TL;DR: MicroRoboScope是一个便携、紧凑、多功能的微机器人实验平台，可对磁性和声学微机器人进行实时闭环控制。


<details>
  <summary>Details</summary>
Motivation: 降低微机器人实验的技术门槛，促进研究、教育和生物医学、组织工程、机器人等领域的转化应用。

Method: 集成嵌入式计算机、显微镜、电源和控制电路，使用Python和Arduino C++开发控制软件，实现视频采集、微机器人追踪和控制信号生成。

Result: 成功构建了一个低成本、集成化的微机器人实验平台，支持多模态驱动。

Conclusion: MicroRoboScope通过其便携性、易用性和多功能性，为微机器人领域的研究和教育开辟了新的可能性。

Abstract: This paper presents MicroRoboScope, a portable, compact, and versatile
microrobotic experimentation platform designed for real-time, closed-loop
control of both magnetic and acoustic microrobots. The system integrates an
embedded computer, microscope, power supplies, and control circuitry into a
single, low-cost and fully integrated apparatus. Custom control software
developed in Python and Arduino C++ handles live video acquisition, microrobot
tracking, and generation of control signals for electromagnetic coils and
acoustic transducers. The platform's multi-modal actuation, accessibility, and
portability make it suitable not only for specialized research laboratories but
also for educational and outreach settings. By lowering the barrier to entry
for microrobotic experimentation, this system enables new opportunities for
research, education, and translational applications in biomedicine, tissue
engineering, and robotics.

</details>


### [964] [Hierarchical Planning for Long-Horizon Multi-Target Tracking Under Target Motion Uncertainty](https://arxiv.org/abs/2510.10421)
*Junbin Yuan,Brady Moon,Muqing Cao,Sebastian Scherer*

Main category: cs.RO

TL;DR: 使用分层规划器和基于MDP的方法来解决多动态目标跟踪中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 单个机器人在大空间区域内跟踪多个动态目标面临巨大挑战，因为机器人移动会导致视野外的目标累积不确定性。

Method: 提出一种分层规划器，包含低层覆盖规划器和基于MDP的目标跟踪任务排序方法，并结合运动模型和不确定性传播。

Result: 在模拟中验证了该方法的有效性，与现有规划器相比，最终不确定性降低了11-70%。

Conclusion: 该分层规划器在处理多动态目标跟踪方面优于现有方法，尤其是在大尺度场景下。

Abstract: Achieving persistent tracking of multiple dynamic targets over a large
spatial area poses significant challenges for a single-robot system with
constrained sensing capabilities. As the robot moves to track different
targets, the ones outside the field of view accumulate uncertainty, making them
progressively harder to track. An effective path planning algorithm must manage
uncertainty over a long horizon and account for the risk of permanently losing
track of targets that remain unseen for too long. However, most existing
approaches rely on short planning horizons and assume small, bounded
environments, resulting in poor tracking performance and target loss in
large-scale scenarios. In this paper, we present a hierarchical planner for
tracking multiple moving targets with an aerial vehicle. To address the
challenge of tracking non-static targets, our method incorporates motion models
and uncertainty propagation during path execution, allowing for more informed
decision-making. We decompose the multi-target tracking task into sub-tasks of
single target search and detection, and our proposed pipeline consists a novel
low-level coverage planner that enables searching for a target in an evolving
belief area, and an estimation method to assess the likelihood of success for
each sub-task, making it possible to convert the active target tracking task to
a Markov decision process (MDP) that we solve with a tree-based algorithm to
determine the sequence of sub-tasks. We validate our approach in simulation,
demonstrating its effectiveness compared to existing planners for active target
tracking tasks, and our proposed planner outperforms existing approaches,
achieving a reduction of 11-70% in final uncertainty across different
environments.

</details>


### [965] [Towards Dynamic Quadrupedal Gaits: A Symmetry-Guided RL Hierarchy Enables Free Gait Transitions at Varying Speeds](https://arxiv.org/abs/2510.10455)
*Jiayu Ding,Xulin Chen,Garrett E. Katz,Zhenyu Gan*

Main category: cs.RO

TL;DR: 该研究提出了一种基于强化学习的框架，利用对称性和速度-周期关系来生成通用的四足机器人步态，无需预定义轨迹或显式足部放置控制，并成功应用于Unitree Go2机器人。


<details>
  <summary>Details</summary>
Motivation: 传统的四足机器人步态生成需要大量专家调整，例如触地和抬起事件以及每条腿的全约束，作者旨在解决这一难题。

Method: 利用内在对称性（时间、形态、时间反转）和速度-周期关系设计了对称性引导的奖励函数，并将其应用于强化学习框架，以生成多样的步态。

Result: 该方法能够实现平稳过渡到各种步态（如小跑、弹跳、半弹跳和奔驰），并在模拟和硬件测试中表现出鲁棒性，提高了步态适应性。

Conclusion: 该研究强调了对称性在机器人步态设计中的关键作用，并为动态运动策略提供了见解。

Abstract: Quadrupedal robots exhibit a wide range of viable gaits, but generating
specific footfall sequences often requires laborious expert tuning of numerous
variables, such as touch-down and lift-off events and holonomic constraints for
each leg. This paper presents a unified reinforcement learning framework for
generating versatile quadrupedal gaits by leveraging the intrinsic symmetries
and velocity-period relationship of dynamic legged systems. We propose a
symmetry-guided reward function design that incorporates temporal,
morphological, and time-reversal symmetries. By focusing on preserved
symmetries and natural dynamics, our approach eliminates the need for
predefined trajectories, enabling smooth transitions between diverse locomotion
patterns such as trotting, bounding, half-bounding, and galloping. Implemented
on the Unitree Go2 robot, our method demonstrates robust performance across a
range of speeds in both simulations and hardware tests, significantly improving
gait adaptability without extensive reward tuning or explicit foot placement
control. This work provides insights into dynamic locomotion strategies and
underscores the crucial role of symmetries in robotic gait design.

</details>


### [966] [Galilean Symmetry in Robotics](https://arxiv.org/abs/2510.10468)
*Robert Mahony,Jonathan Kelly,Stephan Weiss*

Main category: cs.RO

TL;DR: 本文为机器人领域提供了伽利略对称性的新颖视角，将其与刚体变换联系起来，并展示了其在导航、机器人学和传感器融合等方面的应用。


<details>
  <summary>Details</summary>
Motivation: 机器人学领域缺乏对伽利略对称性的全面阐述，而刚体变换是该领域的基础工具。本研究旨在弥合这一差距，为机器人研究者提供一个易于理解的伽利略对称性处理方法。

Method: 通过将机器人学中熟悉的刚体变换和位姿表示法与伽利略矩阵李群联系起来，对伽利略对称性进行阐述。关键在于伽利略矩阵李群可用于表示两种不同的位姿表示法：伽利略坐标系和扩展位姿。

Result: 在惯性导航、机械臂运动学和传感器数据融合三个机器人学问题中，应用伽利略矩阵李群代数得到了直接且富有洞察力的结果。

Conclusion: 伽利略对称性是一个经典但被机器人学领域忽视的重要概念。通过将其与刚体变换相结合，可以为现代机器人学问题带来显著的优势和新的见解。

Abstract: Galilean symmetry is the natural symmetry of inertial motion that underpins
Newtonian physics. Although rigid-body symmetry is one of the most established
and fundamental tools in robotics, there appears to be no comparable treatment
of Galilean symmetry for a robotics audience. In this paper, we present a
robotics-tailored exposition of Galilean symmetry that leverages the
community's familiarity with and understanding of rigid-body transformations
and pose representations. Our approach contrasts with common treatments in the
physics literature that introduce Galilean symmetry as a stepping stone to
Einstein's relativity. A key insight is that the Galilean matrix Lie group can
be used to describe two different pose representations, Galilean frames, that
use inertial velocity in the state definition, and extended poses, that use
coordinate velocity. We provide three examples where applying the Galilean
matrix Lie-group algebra to robotics problems is straightforward and yields
significant insights: inertial navigation above the rotating Earth, manipulator
kinematics, and sensor data fusion under temporal uncertainty. We believe that
the time is right for the robotics community to benefit from rediscovering and
extending this classical material and applying it to modern problems.

</details>


### [967] [SuperEx: Enhancing Indoor Mapping and Exploration using Non-Line-of-Sight Perception](https://arxiv.org/abs/2510.10506)
*Kush Garg,Akshat Dave*

Main category: cs.RO

TL;DR: 该研究提出了一种名为SuperEx的框架，利用单光子激光雷达的非视线（NLOS）感知能力，提升机器人在未知室内环境中的探索和建图效率。


<details>
  <summary>Details</summary>
Motivation: 当前机器人探索受限于视线，导致在布局偏离预期时效率低下。本研究旨在将非视线（NLOS）感知技术应用于机器人探索，以克服这一局限。

Method: SuperEx框架整合了NLOS感知到建图-探索循环中。它通过（i）从时间直方图中移除空的NLOS区域，以及（ii）利用结构规律性，通过基于物理和数据驱动的两步方法重建占据的结构，来增强对视线之外信息的利用。

Result: 在复杂的模拟地图和KTH Floorplan数据集上的评估显示，在低于30%的覆盖率下，建图精度提高了12%，并且相比仅限视线的基线方法，探索效率得到了提升。

Conclusion: SuperEx框架能够有效地利用NLOS感知信息进行机器人探索和建图，提高了建图精度和探索效率，为超越直接可见性进行可靠建图提供了新的途径。

Abstract: Efficient exploration and mapping in unknown indoor environments is a
fundamental challenge, with high stakes in time-critical settings. In current
systems, robot perception remains confined to line-of-sight; occluded regions
remain unknown until physically traversed, leading to inefficient exploration
when layouts deviate from prior assumptions. In this work, we bring
non-line-of-sight (NLOS) sensing to robotic exploration. We leverage
single-photon LiDARs, which capture time-of-flight histograms that encode the
presence of hidden objects - allowing robots to look around blind corners.
Recent single-photon LiDARs have become practical and portable, enabling
deployment beyond controlled lab settings. Prior NLOS works target 3D
reconstruction in static, lab-based scenarios, and initial efforts toward
NLOS-aided navigation consider simplified geometries. We introduce SuperEx, a
framework that integrates NLOS sensing directly into the mapping-exploration
loop. SuperEx augments global map prediction with beyond-line-of-sight cues by
(i) carving empty NLOS regions from timing histograms and (ii) reconstructing
occupied structure via a two-step physics-based and data-driven approach that
leverages structural regularities. Evaluations on complex simulated maps and
the real-world KTH Floorplan dataset show a 12% gain in mapping accuracy under
< 30% coverage and improved exploration efficiency compared to line-of-sight
baselines, opening a path to reliable mapping beyond direct visibility.

</details>


### [968] [Population-Coded Spiking Neural Networks for High-Dimensional Robotic Control](https://arxiv.org/abs/2510.10516)
*Kanishkha Jaisankar,Xiaoyang Jiang,Feifan Liao,Jeethu Sreenivas Amuthan*

Main category: cs.RO

TL;DR: 本论文提出了一种结合脉冲神经网络（SNN）和深度强化学习（DRL）的新框架，用于机器人控制，在保持性能的同时显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 机器人高维连续控制任务面临能耗和计算资源限制的挑战，而现有的DRL方法计算量大，不适用于资源受限环境。

Method: 提出了一种名为PopSAN（Population-coded Spiking Actor Network）的新框架，该框架结合了脉冲神经网络（SNN）的事件驱动计算和DRL的策略优化能力。PopSAN将高维观测编码为神经元群体活动，并通过梯度更新进行策略学习。

Result: 在Isaac Gym平台和Franka机械臂上进行了评估，与传统人工神经网络（ANN）相比，该方法能耗降低高达96.10%，同时控制性能相当。SNN策略在手指位置跟踪和抓取-放置操作中表现稳定。

Conclusion: 结合群体编码SNN和DRL的方法为资源受限应用中的机器人控制提供了一种有前景的节能高效解决方案，有望在实际机器人系统中扩展应用。

Abstract: Energy-efficient and high-performance motor control remains a critical
challenge in robotics, particularly for high-dimensional continuous control
tasks with limited onboard resources. While Deep Reinforcement Learning (DRL)
has achieved remarkable results, its computational demands and energy
consumption limit deployment in resource-constrained environments. This paper
introduces a novel framework combining population-coded Spiking Neural Networks
(SNNs) with DRL to address these challenges. Our approach leverages the
event-driven, asynchronous computation of SNNs alongside the robust policy
optimization capabilities of DRL, achieving a balance between energy efficiency
and control performance. Central to this framework is the Population-coded
Spiking Actor Network (PopSAN), which encodes high-dimensional observations
into neuronal population activities and enables optimal policy learning through
gradient-based updates. We evaluate our method on the Isaac Gym platform using
the PixMC benchmark with complex robotic manipulation tasks. Experimental
results on the Franka robotic arm demonstrate that our approach achieves energy
savings of up to 96.10% compared to traditional Artificial Neural Networks
(ANNs) while maintaining comparable control performance. The trained SNN
policies exhibit robust finger position tracking with minimal deviation from
commanded trajectories and stable target height maintenance during
pick-and-place operations. These results position population-coded SNNs as a
promising solution for energy-efficient, high-performance robotic control in
resource-constrained applications, paving the way for scalable deployment in
real-world robotics systems.

</details>


### [969] [Decoupled Scaling 4ch Bilateral Control on the Cartesian coordinate by 6-DoF Manipulator using Rotation Matrix](https://arxiv.org/abs/2510.10545)
*Koki Yamane,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Four-channel bilateral control is a method for achieving remote control with
force feedback and adjustment operability by synchronizing the positions and
forces of two manipulators. This is expected to significantly improve the
operability of the remote control in contact-rich tasks. Among these, 4-channel
bilateral control on the Cartesian coordinate system is advantageous owing to
its suitability for manipulators with different structures and because it
allows the dynamics in the Cartesian coordinate system to be adjusted by
adjusting the control parameters, thus achieving intuitive operability for
humans. This paper proposes a 4-channel bilateral control method that achieves
the desired dynamics by decoupling each dimension in the Cartesian coordinate
system regardless of the scaling factor.

</details>


### [970] [Reinforcement Learning-based Dynamic Adaptation for Sampling-Based Motion Planning in Agile Autonomous Driving](https://arxiv.org/abs/2510.10567)
*Alexander Langmann,Yevhenii Tokarev,Mattia Piccinini,Korbinian Moller,Johannes Betz*

Main category: cs.RO

TL;DR: 强化学习（RL）代理被用作高级行为选择器，在运行时动态切换分析型低级轨迹规划器的成本函数参数，以解决手动调整的静态权重导致的战术妥协问题。


<details>
  <summary>Details</summary>
Motivation: 手动调整的静态权重导致轨迹规划器在各种比赛场景中表现不佳，无法在安全性和竞争力之间取得最佳平衡。

Method: 使用强化学习（RL）代理作为高级行为选择器，在运行时动态切换低级轨迹规划器的成本函数参数。

Result: 在模拟的自动驾驶赛车环境中，RL规划器实现了0%的碰撞率，并将超车时间缩短了高达60%，实现了以前无法实现的交互式操作。

Conclusion: 将强化学习作为高级选择器可以解决自动驾驶赛车规划器中固有的安全与竞争力之间的权衡问题，并为更广泛的自动驾驶应用提供自适应且可解释的运动规划方法。

Abstract: Sampling-based trajectory planners are widely used for agile autonomous
driving due to their ability to generate fast, smooth, and kinodynamically
feasible trajectories. However, their behavior is often governed by a cost
function with manually tuned, static weights, which forces a tactical
compromise that is suboptimal across the wide range of scenarios encountered in
a race. To address this shortcoming, we propose using a Reinforcement Learning
(RL) agent as a high-level behavioral selector that dynamically switches the
cost function parameters of an analytical, low-level trajectory planner during
runtime. We show the effectiveness of our approach in simulation in an
autonomous racing environment where our RL-based planner achieved 0% collision
rate while reducing overtaking time by up to 60% compared to state-of-the-art
static planners. Our new agent now dynamically switches between aggressive and
conservative behaviors, enabling interactive maneuvers unattainable with static
configurations. These results demonstrate that integrating reinforcement
learning as a high-level selector resolves the inherent trade-off between
safety and competitiveness in autonomous racing planners. The proposed
methodology offers a pathway toward adaptive yet interpretable motion planning
for broader autonomous driving applications.

</details>


### [971] [Fast Vision in the Dark: A Case for Single-Photon Imaging in Planetary Navigation](https://arxiv.org/abs/2510.10597)
*David Rodríguez-Martínez,C. J. Pérez del Pulgar*

Main category: cs.RO

TL;DR: SPAD camera can be used for planetary navigation, especially in challenging illumination conditions like high-latitude lunar regions.


<details>
  <summary>Details</summary>
Motivation: Vision-based navigation faces challenges with complex illumination and motion, limiting planetary robots. This paper proposes using SPAD cameras as an alternative passive sensing technology.

Method: Evaluate single-photon imaging with SPAD cameras for robotic exploration in perceptually challenging locations, focusing on high-latitude lunar regions. Detail SPAD camera principles and performance, assess advantages/limitations for lunar missions, and benchmark performance under representative illumination.

Result: The paper presents the first comprehensive evaluation of SPAD cameras for planetary navigation, detailing their operating principles and performance characteristics.

Conclusion: SPAD cameras offer a promising alternative for passive sensing in robotic exploration, particularly for missions facing challenging illumination conditions like those found in high-latitude lunar regions.

Abstract: Improving robotic navigation is critical for extending exploration range and
enhancing operational efficiency. Vision-based navigation relying on
traditional CCD or CMOS cameras faces major challenges when complex
illumination conditions are paired with motion, limiting the range and
accessibility of mobile planetary robots. In this study, we propose a novel
approach to planetary navigation that leverages the unique imaging capabilities
of Single-Photon Avalanche Diode (SPAD) cameras. We present the first
comprehensive evaluation of single-photon imaging as an alternative passive
sensing technology for robotic exploration missions targeting perceptually
challenging locations, with a special emphasis on high-latitude lunar regions.
We detail the operating principles and performance characteristics of SPAD
cameras, assess their advantages and limitations in addressing key perception
challenges of upcoming exploration missions to the Moon, and benchmark their
performance under representative illumination conditions.

</details>


### [972] [SpikeGrasp: A Benchmark for 6-DoF Grasp Pose Detection from Stereo Spike Streams](https://arxiv.org/abs/2510.10602)
*Zhuoheng Gao,Jiyao Zhang,Zhiyong Xie,Hao Dong,Zhaofei Yu,Rongmei Chen,Guozhang Chen,Tiejun Huang*

Main category: cs.RO

TL;DR: 机器人抓取系统可以借鉴生物视觉通路，使用事件相机直接从原始事件数据中推断抓握姿态，无需构建点云，并在合成数据集上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 大多数机器人抓取系统依赖于将传感器数据转换为显式的3D点云，而生物智能中不存在这一计算步骤。本研究旨在探索一种完全不同的、受神经启发的6-DoF抓握检测范式。

Method: 提出了一种名为SpikeGrasp的框架，该框架模仿生物视觉运动通路，处理来自立体事件相机的原始、异步事件，并直接推断抓握姿态，整个过程不进行点云重建。模型融合了立体事件流，并使用循环脉冲神经网络来迭代地优化抓握假设。

Result: 在合成数据集上的实验表明，SpikeGrasp在抓握检测任务上超越了传统的基于点云的方法，尤其是在杂乱和无纹理的场景中表现更优，并且具有显著的数据效率。

Conclusion: SpikeGrasp证明了这种端到端的、受神经启发的抓握检测方法的有效性，为未来实现自然界中流畅高效的操作（尤其是在动态物体方面）铺平了道路。

Abstract: Most robotic grasping systems rely on converting sensor data into explicit 3D
point clouds, which is a computational step not found in biological
intelligence. This paper explores a fundamentally different, neuro-inspired
paradigm for 6-DoF grasp detection. We introduce SpikeGrasp, a framework that
mimics the biological visuomotor pathway, processing raw, asynchronous events
from stereo spike cameras, similarly to retinas, to directly infer grasp poses.
Our model fuses these stereo spike streams and uses a recurrent spiking neural
network, analogous to high-level visual processing, to iteratively refine grasp
hypotheses without ever reconstructing a point cloud. To validate this
approach, we built a large-scale synthetic benchmark dataset. Experiments show
that SpikeGrasp surpasses traditional point-cloud-based baselines, especially
in cluttered and textureless scenes, and demonstrates remarkable data
efficiency. By establishing the viability of this end-to-end, neuro-inspired
approach, SpikeGrasp paves the way for future systems capable of the fluid and
efficient manipulation seen in nature, particularly for dynamic objects.

</details>


### [973] [High-Fidelity Simulated Data Generation for Real-World Zero-Shot Robotic Manipulation Learning with Gaussian Splatting](https://arxiv.org/abs/2510.10637)
*Haoyu Zhao,Cheng Zeng,Linghao Zhuang,Yaxi Zhao,Shengke Xue,Hao Wang,Xingyue Zhao,Zhongyu Li,Kehan Li,Siteng Huang,Mingxiu Chen,Xin Li,Deli Zhao,Hua Zou*

Main category: cs.RO

TL;DR: RoboSimGS是一个Real2Sim2Real框架，利用3D高斯泼溅和网格图元重建场景，并使用多模态大语言模型自动创建物理上可行的、可操作的资产，实现了零样本模拟到现实的迁移。


<details>
  <summary>Details</summary>
Motivation: 真实世界数据收集的成本和劳动量限制了机器人学习的可扩展性，而模拟数据在视觉外观、物理属性和物体交互方面存在差异，难以推广到真实世界。

Method: RoboSimGS框架结合了3D高斯泼溅（用于视觉保真度）和网格图元（用于物理模拟），并利用多模态大语言模型（MLLM）自动从视觉数据推断物体的物理属性和运动学结构。

Result: 在RoboSimGS生成的模拟数据上训练的策略成功实现了跨多个机器人操作任务的零样本模拟到现实的迁移，并且RoboSimGS的数据显著提高了现有最先进方法的性能和泛化能力。

Conclusion: RoboSimGS是一个强大且可扩展的解决方案，能够弥合模拟到现实之间的差距。

Abstract: The scalability of robotic learning is fundamentally bottlenecked by the
significant cost and labor of real-world data collection. While simulated data
offers a scalable alternative, it often fails to generalize to the real world
due to significant gaps in visual appearance, physical properties, and object
interactions. To address this, we propose RoboSimGS, a novel Real2Sim2Real
framework that converts multi-view real-world images into scalable,
high-fidelity, and physically interactive simulation environments for robotic
manipulation. Our approach reconstructs scenes using a hybrid representation:
3D Gaussian Splatting (3DGS) captures the photorealistic appearance of the
environment, while mesh primitives for interactive objects ensure accurate
physics simulation. Crucially, we pioneer the use of a Multi-modal Large
Language Model (MLLM) to automate the creation of physically plausible,
articulated assets. The MLLM analyzes visual data to infer not only physical
properties (e.g., density, stiffness) but also complex kinematic structures
(e.g., hinges, sliding rails) of objects. We demonstrate that policies trained
entirely on data generated by RoboSimGS achieve successful zero-shot
sim-to-real transfer across a diverse set of real-world manipulation tasks.
Furthermore, data from RoboSimGS significantly enhances the performance and
generalization capabilities of SOTA methods. Our results validate RoboSimGS as
a powerful and scalable solution for bridging the sim-to-real gap.

</details>


### [974] [UniCoD: Enhancing Robot Policy via Unified Continuous and Discrete Representation Learning](https://arxiv.org/abs/2510.10642)
*Jianke Zhang,Yucheng Hu,Yanjiang Guo,Xiaoyu Chen,Yichen Liu,Wenna Chen,Chaochao Lu,Jianyu Chen*

Main category: cs.RO

TL;DR: UniCoD是一个结合了理解、规划和未来表征学习的机器人策略模型，通过在大规模教学视频上进行预训练，并在机器人实体上进行微调，取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的通用机器人策略模型通常只依赖于视觉-语言理解或视觉生成模型，而忽略了两者对于机器人任务的重要性。本研究旨在结合理解、规划和未来表征学习的优势，以提升机器人策略的学习效果。

Method: UniCoD模型首先在超过100万个互联网规模的教学操作视频上进行预训练，以学习动态建模高维视觉特征的能力。随后，在机器人实体收集的数据上进行微调，以学习从预测表征到动作令牌的映射。

Result: 通过在大规模教学视频上进行预训练，UniCoD能够动态建模高维视觉特征。在模拟环境和真实世界中，UniCoD在多项任务上取得了比基线方法高出9%和12%的性能提升。

Conclusion: UniCoD通过结合理解、规划和未来表征学习，并在大规模视频数据上进行预训练，有效提升了机器人策略的学习能力，并在模拟和真实世界任务中表现出优越的性能。

Abstract: Building generalist robot policies that can handle diverse tasks in
open-ended environments is a central challenge in robotics. To leverage
knowledge from large-scale pretraining, prior work has typically built
generalist policies either on top of vision-language understanding models
(VLMs) or generative models. However, both semantic understanding from
vision-language pretraining and visual dynamics modeling from visual-generation
pretraining are crucial for embodied robots. Recent unified models of
generation and understanding have demonstrated strong capabilities in both
comprehension and generation through large-scale pretraining. We posit that
robotic policy learning can likewise benefit from the combined strengths of
understanding, planning and continuous future representation learning. Building
on this insight, we introduce UniCoD, which acquires the ability to dynamically
model high-dimensional visual features through pretraining on over 1M
internet-scale instructional manipulation videos. Subsequently, UniCoD is
fine-tuned on data collected from the robot embodiment, enabling the learning
of mappings from predictive representations to action tokens. Extensive
experiments show our approach consistently outperforms baseline methods in
terms of 9\% and 12\% across simulation environments and real-world
out-of-distribution tasks.

</details>


### [975] [Deployment and Development of a Cognitive Teleoreactive Framework for Deep Sea Autonomy](https://arxiv.org/abs/2510.10716)
*Christopher Thierauf*

Main category: cs.RO

TL;DR: DINOS-R是一个新的AUV任务规划和执行软件，它结合了符号决策、机器学习和实时行为，并已在AUV Sentry上进行了测试。


<details>
  <summary>Details</summary>
Motivation: 该软件旨在取代旧的MC架构，统一符号决策和机器学习技术，以实现跨海洋平台的现场就绪性。

Method: DINOS-R从认知架构和AUV控制系统汲取灵感，并将其符号决策能力与机器学习和反应式行为相结合。该软件使用Python3实现，具有模块化、可扩展和可重用性，并支持声明式任务规范和实时任务规划。

Result: DINOS-R已在AUV Sentry和各种模拟案例中得到验证，证明了其灵活性和功能性。

Conclusion: 该软件已成功演示，并为未来在海洋学和机器人算法方面的研究奠定了基础。

Abstract: A new AUV mission planning and execution software has been tested on AUV
Sentry. Dubbed DINOS-R, it draws inspiration from cognitive architectures and
AUV control systems to replace the legacy MC architecture. Unlike these
existing architectures, however, DINOS-R is built from the ground-up to unify
symbolic decision making (for understandable, repeatable, provable behavior)
with machine learning techniques and reactive behaviors, for field-readiness
across oceanographic platforms. Implemented primarily in Python3, DINOS-R is
extensible, modular, and reusable, with an emphasis on non-expert use as well
as growth for future research in oceanography and robot algorithms. Mission
specification is flexible, and can be specified declaratively. Behavior
specification is similarly flexible, supporting simultaneous use of real-time
task planning and hard-coded user specified plans. These features were
demonstrated in the field on Sentry, in addition to a variety of simulated
cases. These results are discussed, and future work is outlined.

</details>


### [976] [Controllable Generative Trajectory Prediction via Weak Preference Alignment](https://arxiv.org/abs/2510.10731)
*Yongxi Cao,Julian F. Schumann,Jens Kober,Joni Pajarinen,Arkady Zgonnikov*

Main category: cs.RO

TL;DR: 该研究提出了一种名为PrefCVAE的新型条件变分自编码器模型，用于提升自动驾驶规划中对周围Agent轨迹预测的多样性和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在轨迹预测准确性方面表现出色，但在生成可控、多样化的轨迹以应对人类行为的不确定性和多模态性方面存在不足，这对于安全规划至关重要。

Method: 提出了一种名为PrefCVAE的增强CVAE框架，利用弱标注的偏好对来为隐变量注入语义属性（如平均速度），实现可控、有意义的轨迹预测。

Result: 实验证明，PrefCVAE在不影响基线准确性的前提下，能够实现可控的、具有语义意义的轨迹预测，并且偏好监督是一种提升生成模型性能的有效且经济的方式。

Conclusion: 偏好监督是增强基于采样方法的生成模型（如CVAE）以实现可控、多样化轨迹预测的一种有效且成本效益高的方法，对于自动驾驶安全规划具有重要意义。

Abstract: Deep generative models such as conditional variational autoencoders (CVAEs)
have shown great promise for predicting trajectories of surrounding agents in
autonomous vehicle planning. State-of-the-art models have achieved remarkable
accuracy in such prediction tasks. Besides accuracy, diversity is also crucial
for safe planning because human behaviors are inherently uncertain and
multimodal. However, existing methods generally lack a scheme to generate
controllably diverse trajectories, which is arguably more useful than randomly
diversified trajectories, to the end of safe planning. To address this, we
propose PrefCVAE, an augmented CVAE framework that uses weakly labeled
preference pairs to imbue latent variables with semantic attributes. Using
average velocity as an example attribute, we demonstrate that PrefCVAE enables
controllable, semantically meaningful predictions without degrading baseline
accuracy. Our results show the effectiveness of preference supervision as a
cost-effective way to enhance sampling-based generative models.

</details>


### [977] [Gain Tuning Is Not What You Need: Reward Gain Adaptation for Constrained Locomotion Learning](https://arxiv.org/abs/2510.10759)
*Arthicha Srisuchinnawong,Poramate Manoonpong*

Main category: cs.RO

TL;DR: ROGER通过在线调整奖励权重增益来解决机器人运动学习中的约束满足和奖励加权问题，在模拟和真实机器人实验中均表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人运动学习技术依赖于离线选择奖励权重，且无法保证训练过程中的约束满足，导致约束违反。本研究旨在解决这些问题。

Method: 提出ROGER（Reward-Oriented Gains via Embodied Regulation）方法，该方法根据体现交互过程中收到的惩罚在线调整奖励权重增益。当学习接近约束阈值时，自动降低正奖励与负奖励（惩罚）增益的比例以避免违反；当学习处于安全状态时，则提高比例以优先考虑性能。

Result: 在60公斤四足机器人实验中，ROGER在多次学习试验中实现了接近零的约束违反，并且主要奖励比现有的最先进技术提高了高达50%。在MuJoCo连续运动基准测试（包括单腿跳跃机器人）中，ROGER的表现与使用默认奖励函数训练的机器人相当或高出100%，同时扭矩使用和方向偏差减少了60%。此外，在物理四足机器人上，ROGER在不到一小时内从零开始实现了现实世界的运动学习，且无任何跌倒。

Conclusion: ROGER的提出有助于实现满足约束的现实世界持续机器人运动学习，并简化了奖励权重增益的调整，有望促进物理机器人和现实世界学习机器人的发展。

Abstract: Existing robot locomotion learning techniques rely heavily on the offline
selection of proper reward weighting gains and cannot guarantee constraint
satisfaction (i.e., constraint violation) during training. Thus, this work aims
to address both issues by proposing Reward-Oriented Gains via Embodied
Regulation (ROGER), which adapts reward-weighting gains online based on
penalties received throughout the embodied interaction process. The ratio
between the positive reward (primary reward) and negative reward (penalty)
gains is automatically reduced as the learning approaches the constraint
thresholds to avoid violation. Conversely, the ratio is increased when learning
is in safe states to prioritize performance. With a 60-kg quadruped robot,
ROGER achieved near-zero constraint violation throughout multiple learning
trials. It also achieved up to 50% more primary reward than the equivalent
state-of-the-art techniques. In MuJoCo continuous locomotion benchmarks,
including a single-leg hopper, ROGER exhibited comparable or up to 100% higher
performance and 60% less torque usage and orientation deviation compared to
those trained with the default reward function. Finally, real-world locomotion
learning of a physical quadruped robot was achieved from scratch within one
hour without any falls. Therefore, this work contributes to
constraint-satisfying real-world continual robot locomotion learning and
simplifies reward weighting gain tuning, potentially facilitating the
development of physical robots and those that learn in the real world.

</details>


### [978] [Real2USD: Scene Representations in Universal Scene Description Language](https://arxiv.org/abs/2510.10778)
*Christopher D. Hsu,Pratik Chaudhari*

Main category: cs.RO

TL;DR: 该论文提出使用通用场景描述（USD）语言作为机器人任务的通用环境表示，并构建了一个“Real to USD”系统，利用大型语言模型（LLM）理解和规划机器人任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法将LLM应用于机器人任务的环境表示通常是任务特定的，缺乏通用性。该论文旨在证明USD语言作为一种通用表示的有效性。

Method: 该论文提出使用USD语言作为机器人环境的表示，并构建了一个“Real to USD”系统。该系统使用Unitree Go2机器人收集环境信息，构建USD表示，并利用Google的Gemini解析USD以实现场景理解、推理和规划。并在模拟环境中进行了实验。

Result: “Real to USD”系统成功地构建了室内环境的USD表示，并利用Gemini进行了场景理解、推理和规划。在模拟仓库和医院环境中也进行了相关的研究。

Conclusion: USD语言是一种有效且通用的机器人任务环境表示方法，能够支持LLM在机器人领域的广泛应用。

Abstract: Large Language Models (LLMs) can help robots reason about abstract task
specifications. This requires augmenting classical representations of the
environment used by robots with natural language-based priors. There are a
number of existing approaches to doing so, but they are tailored to specific
tasks, e.g., visual-language models for navigation, language-guided neural
radiance fields for mapping, etc. This paper argues that the Universal Scene
Description (USD) language is an effective and general representation of
geometric, photometric and semantic information in the environment for
LLM-based robotics tasks. Our argument is simple: a USD is an XML-based scene
graph, readable by LLMs and humans alike, and rich enough to support
essentially any task -- Pixar developed this language to store assets, scenes
and even movies. We demonstrate a ``Real to USD'' system using a Unitree Go2
quadruped robot carrying LiDAR and a RGB camera that (i) builds an explicit USD
representation of indoor environments with diverse objects and challenging
settings with lots of glass, and (ii) parses the USD using Google's Gemini to
demonstrate scene understanding, complex inferences, and planning. We also
study different aspects of this system in simulated warehouse and hospital
settings using Nvidia's Issac Sim. Code is available at
https://github.com/grasp-lyrl/Real2USD .

</details>


### [979] [PhysHSI: Towards a Real-World Generalizable and Natural Humanoid-Scene Interaction System](https://arxiv.org/abs/2510.11072)
*Huayi Wang,Wentao Zhang,Runyi Yu,Tao Huang,Junli Ren,Feiyu Jia,Zirui Wang,Xiaojie Niu,Xiao Chen,Jiahe Chen,Qifeng Chen,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 该研究提出了一个名为PhysHSI的物理世界人形机器人交互系统，用于实现机器人与真实环境的交互，如搬运物体和坐下。该系统结合了仿真训练和真实世界部署，通过对抗性运动先验策略学习来模仿自然的人形交互数据，并利用激光雷达和摄像头融合的物体定位模块进行鲁棒的场景感知。实验证明PhysHSI在搬箱子、坐下、躺下和站起等任务上表现出色，成功率高，泛化能力强，动作自然。


<details>
  <summary>Details</summary>
Motivation: 尽管已有方法在人形机器人与真实环境交互（如搬运物体、坐下）方面取得进展，但将场景感知和泛化运动能力结合到一个统一系统中仍然是一个挑战。

Method: 提出PhysHSI系统，包括仿真训练和真实世界部署两部分。仿真训练采用基于对抗性运动先验的策略学习，以模仿多样化场景下自然的人形-场景交互数据。真实世界部署引入了激光雷达和摄像头融合的粗到精物体定位模块，以实现持续鲁棒的场景感知。

Result: 在仿真和真实世界中，PhysHSI在搬箱子、坐下、躺下和站起四个代表性交互任务上都取得了持续的高成功率，并且表现出强大的跨任务泛化能力和自然流畅的运动模式。

Conclusion: PhysHSI系统成功地实现了人形机器人与真实环境的自主交互，兼具泛化能力、自然行为和鲁棒的场景感知能力。

Abstract: Deploying humanoid robots to interact with real-world environments--such as
carrying objects or sitting on chairs--requires generalizable, lifelike motions
and robust scene perception. Although prior approaches have advanced each
capability individually, combining them in a unified system is still an ongoing
challenge. In this work, we present a physical-world humanoid-scene interaction
system, PhysHSI, that enables humanoids to autonomously perform diverse
interaction tasks while maintaining natural and lifelike behaviors. PhysHSI
comprises a simulation training pipeline and a real-world deployment system. In
simulation, we adopt adversarial motion prior-based policy learning to imitate
natural humanoid-scene interaction data across diverse scenarios, achieving
both generalization and lifelike behaviors. For real-world deployment, we
introduce a coarse-to-fine object localization module that combines LiDAR and
camera inputs to provide continuous and robust scene perception. We validate
PhysHSI on four representative interactive tasks--box carrying, sitting, lying,
and standing up--in both simulation and real-world settings, demonstrating
consistently high success rates, strong generalization across diverse task
goals, and natural motion patterns.

</details>


### [980] [Representing Data in Robotic Tactile Perception -- A Review](https://arxiv.org/abs/2510.10804)
*Alessandro Albini,Mohsen Kaboli,Giorgio Cannata,Perla Maiolino*

Main category: cs.RO

TL;DR: Robotic tactile perception requires transforming sensor data into structured formats for high-level computation, often adapted from other fields like computer vision. This survey reviews existing methods for representing tactile information, identifying six common structures and providing guidelines for selecting the appropriate one based on hardware, information needs, and task requirements.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the crucial aspect of data representation in the robotic tactile perception pipeline, which is necessary because high-level computations often require structured input data, and the transformation of raw tactile sensor data significantly affects the encoded information and subsequent task execution.

Method: The method involves reviewing previous studies on representing tactile information, investigating the relationships among hardware, representations, and high-level computation methods, identifying six commonly used data structures in the literature, and providing discussions and guidelines for selecting the appropriate representation based on operating conditions.

Result: The analysis identified six common structures used in the literature for representing tactile data. The paper also provides discussions and guidelines to help select a representation based on operating conditions, including hardware, the type of tactile information to be encoded, and the specific task.

Conclusion: The paper concludes by emphasizing the importance of data representation in robotic tactile perception and offers guidance on selecting the most suitable representation for different scenarios, highlighting the interplay between hardware, representation, and computational methods.

Abstract: Robotic tactile perception is a complex process involving several
computational steps performed at different levels. Tactile information is
shaped by the interplay of robot actions, the mechanical properties of its
body, and the software that processes the data. In this respect, high-level
computation, required to process and extract information, is commonly performed
by adapting existing techniques from other domains, such as computer vision,
which expects input data to be properly structured. Therefore, it is necessary
to transform tactile sensor data to match a specific data structure. This
operation directly affects the tactile information encoded and, as a
consequence, the task execution. This survey aims to address this specific
aspect of the tactile perception pipeline, namely Data Representation. The
paper first clearly defines its contributions to the perception pipeline and
then reviews how previous studies have dealt with the problem of representing
tactile information, investigating the relationships among hardware,
representations, and high-level computation methods. The analysis has led to
the identification of six structures commonly used in the literature to
represent data. The manuscript provides discussions and guidelines for properly
selecting a representation depending on operating conditions, including the
available hardware, the tactile information required to be encoded, and the
task at hand.

</details>


### [981] [A Faster and More Reliable Middleware for Autonomous Driving Systems](https://arxiv.org/abs/2510.11448)
*Yuankai He,Hanlin Chen,Weisong Shi*

Main category: cs.RO

TL;DR: SIM是一种用于自动驾驶汽车的共享内存传输层，可显著减少ROS 2中的数据传输延迟，提高感知和控制频率，从而缩短制动距离。


<details>
  <summary>Details</summary>
Motivation: 现有ROS 2中间件在多传感器和控制节点共享同一计算单元时，会产生显著的序列化、复制和发现开销，挤压了自动驾驶汽车所需的可用时间预算。

Method: SIM通过在内存中保留传感器数据的原生布局（例如cv::Mat, PCL），并使用无锁队列来优先处理新数据，同时保持与ROS 2的集成，从而减少了延迟。

Result: 与ROS 2的零拷贝传输相比，SIM将数据传输延迟最多降低了98%，平均延迟降低了约95%，尾部延迟（95%/99%）降低了约96%。在Level 4车辆上，SIM将定位频率从7.5 Hz提高到9.5 Hz，并将平均感知到决策的延迟从521.91 ms降低到290.26 ms，从而在40 mph的速度下将紧急制动距离缩短了13.6英尺（4.14米）。

Conclusion: SIM通过提供低延迟、高数据新鲜度的传输，有效解决了自动驾驶汽车中ROS 2的性能瓶颈，在实际应用中显著提高了车辆的安全性和响应能力。

Abstract: Ensuring safety in high-speed autonomous vehicles requires rapid control
loops and tightly bounded delays from perception to actuation. Many open-source
autonomy systems rely on ROS 2 middleware; when multiple sensor and control
nodes share one compute unit, ROS 2 and its DDS transports add significant
(de)serialization, copying, and discovery overheads, shrinking the available
time budget. We present Sensor-in-Memory (SIM), a shared-memory transport
designed for intra-host pipelines in autonomous vehicles. SIM keeps sensor data
in native memory layouts (e.g., cv::Mat, PCL), uses lock-free bounded double
buffers that overwrite old data to prioritize freshness, and integrates into
ROS 2 nodes with four lines of code. Unlike traditional middleware, SIM
operates beside ROS 2 and is optimized for applications where data freshness
and minimal latency outweigh guaranteed completeness. SIM provides sequence
numbers, a writer heartbeat, and optional checksums to ensure ordering,
liveness, and basic integrity. On an NVIDIA Jetson Orin Nano, SIM reduces
data-transport latency by up to 98% compared to ROS 2 zero-copy transports such
as FastRTPS and Zenoh, lowers mean latency by about 95%, and narrows
95th/99th-percentile tail latencies by around 96%. In tests on a
production-ready Level 4 vehicle running Autoware.Universe, SIM increased
localization frequency from 7.5 Hz to 9.5 Hz. Applied across all
latency-critical modules, SIM cut average perception-to-decision latency from
521.91 ms to 290.26 ms, reducing emergency braking distance at 40 mph (64 km/h)
on dry concrete by 13.6 ft (4.14 m).

</details>


### [982] [Contact Sensing via Joint Torque Sensors and a Force/Torque Sensor for Legged Robots](https://arxiv.org/abs/2510.10843)
*Jared Grinberg,Yanran Ding*

Main category: cs.RO

TL;DR: 本研究提出了一种基于广义动量观测器框架的方法，利用分布式关节力矩传感器和单个髋部安装的力矩（FT）传感器来检测和定位机器人腿部的接触点。研究设计了一种低成本的应变片式关节力矩传感器，可安装在每个关节上，提供直接的力矩测量，无需复杂的摩擦模型，并比基于电机电流的估算提供更准确的力矩读数。在浮动基2-DoF机器人腿上的仿真研究表明，该框架能够准确恢复大腿和小腿连杆上的接触力和位置。通过校准程序，所提出的力矩传感器相对于地面实况测量实现了96.4%的平均准确率。在力矩传感器基础上，在2-DoF机械臂上进行了硬件实验，结果显示接触定位精度达到亚厘米级别，力误差低于0.2 N。


<details>
  <summary>Details</summary>
Motivation: 机器人腿部接触检测和定位对于实现机器人与环境的交互至关重要，但现有方法往往依赖于复杂的传感器或模型。

Method: 提出了一种基于广义动量观测器框架的方法，结合低成本的分布式关节力矩传感器和单个髋部FT传感器，用于检测和定位机器人腿部的接触点。

Result: 仿真结果表明，该方法能够准确恢复大腿和小腿连杆上的接触力和位置。力矩传感器达到了96.4%的平均准确率。硬件实验结果显示，接触定位精度达到亚厘米级别，力误差低于0.2 N。

Conclusion: 本研究提出的基于分布式关节力矩传感器和FT传感器的机器人腿部接触检测和定位方法，具有高精度和低成本的优点，为机器人与环境的交互提供了有效的解决方案。

Abstract: This paper presents a method for detecting and localizing contact along robot
legs using distributed joint torque sensors and a single hip-mounted
force-torque (FT) sensor using a generalized momentum-based observer framework.
We designed a low-cost strain-gauge-based joint torque sensor that can be
installed on every joint to provide direct torque measurements, eliminating the
need for complex friction models and providing more accurate torque readings
than estimation based on motor current. Simulation studies on a floating-based
2-DoF robot leg verified that the proposed framework accurately recovers
contact force and location along the thigh and shin links. Through a
calibration procedure, our torque sensor achieved an average 96.4% accuracy
relative to ground truth measurements. Building upon the torque sensor, we
performed hardware experiments on a 2-DoF manipulator, which showed
sub-centimeter contact localization accuracy and force errors below 0.2 N.

</details>


### [983] [Constraint-Aware Reinforcement Learning via Adaptive Action Scaling](https://arxiv.org/abs/2510.11491)
*Murad Dawood,Usama Ahmed Siddiquie,Shahram Khorshidi,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种模块化的成本感知调节器，通过预测约束违规来缩放智能体的动作，从而在保持任务性能的同时减少约束违规，并能与现有的离线 RL 方法（如 SAC 和 TD3）无缝集成。


<details>
  <summary>Details</summary>
Motivation: 现有的安全强化学习方法在平衡奖励和安全约束时可能存在不稳定性，或者需要先验系统知识，因此本文旨在提出一种新的方法来解决这些问题。

Method: 提出了一种模块化的成本感知调节器，该调节器通过预测约束违规来缩放智能体的动作，从而实现平滑的动作调整，而不是强制覆盖策略。该调节器经过训练，旨在最小化约束违规，同时避免动作的退化性抑制。

Result: 该方法在 Safety Gym 运动任务上实现了最先进的返回成本比，与现有方法相比，约束违规减少了多达 126 倍，同时回报增加了十倍以上。

Conclusion: 本文提出的成本感知调节器能够有效地提高安全强化学习的性能，通过平滑的动作调整来平衡探索和安全约束，并在标准基准测试中取得了优越的成果。

Abstract: Safe reinforcement learning (RL) seeks to mitigate unsafe behaviors that
arise from exploration during training by reducing constraint violations while
maintaining task performance. Existing approaches typically rely on a single
policy to jointly optimize reward and safety, which can cause instability due
to conflicting objectives, or they use external safety filters that override
actions and require prior system knowledge. In this paper, we propose a modular
cost-aware regulator that scales the agent's actions based on predicted
constraint violations, preserving exploration through smooth action modulation
rather than overriding the policy. The regulator is trained to minimize
constraint violations while avoiding degenerate suppression of actions. Our
approach integrates seamlessly with off-policy RL methods such as SAC and TD3,
and achieves state-of-the-art return-to-cost ratios on Safety Gym locomotion
tasks with sparse costs, reducing constraint violations by up to 126 times
while increasing returns by over an order of magnitude compared to prior
methods.

</details>


### [984] [Preference-Conditioned Multi-Objective RL for Integrated Command Tracking and Force Compliance in Humanoid Locomotion](https://arxiv.org/abs/2510.10851)
*Tingxuan Leng,Yushi Wang,Tinglong Zheng,Changsheng Luo,Mingguo Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一种多目标强化学习框架，用于解决人形机器人运动中的指令跟踪和外部力顺应性之间的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要关注鲁棒性，导致机器人虽能抵抗外力但缺乏顺应性，这对于不稳定性高的人形机器人尤为困难。本研究旨在解决这一挑战，实现机器人既能精确跟踪指令，又能对外部力做出顺应性响应。

Method: 提出了一种偏好条件多目标强化学习（MORL）框架，将刚性指令跟踪和顺应性行为集成到单一的全向运动策略中。通过速度阻力因子来建模外部力，并利用编码器-解码器结构从可部署的观测中推断任务相关的特权特征进行训练。

Result: 在模拟和真实机器人实验中，该框架显示出比标准方法更强的适应性和收敛性，并实现了可部署的、偏好可调的人形机器人运动。

Conclusion: 所提出的MORL框架成功地在指令跟踪和外部力顺应性之间取得了平衡，提高了人形机器人运动的灵活性和鲁棒性，并能在真实世界中部署。

Abstract: Humanoid locomotion requires not only accurate command tracking for
navigation but also compliant responses to external forces during human
interaction. Despite significant progress, existing RL approaches mainly
emphasize robustness, yielding policies that resist external forces but lack
compliance-particularly challenging for inherently unstable humanoids. In this
work, we address this by formulating humanoid locomotion as a multi-objective
optimization problem that balances command tracking and external force
compliance. We introduce a preference-conditioned multi-objective RL (MORL)
framework that integrates rigid command following and compliant behaviors
within a single omnidirectional locomotion policy. External forces are modeled
via velocity-resistance factor for consistent reward design, and training
leverages an encoder-decoder structure that infers task-relevant privileged
features from deployable observations. We validate our approach in both
simulation and real-world experiments on a humanoid robot. Experimental results
indicate that our framework not only improves adaptability and convergence over
standard pipelines, but also realizes deployable preference-conditioned
humanoid locomotion.

</details>


### [985] [IntersectioNDE: Learning Complex Urban Traffic Dynamics based on Interaction Decoupling Strategy](https://arxiv.org/abs/2510.11534)
*Enli Lin,Ziyuan Yang,Qiujing Lu,Jianming Hu,Shuo Feng*

Main category: cs.RO

TL;DR: 该论文提出了一个名为IntersectioNDE的数据驱动仿真器，用于解决城市复杂交通场景下自动驾驶汽车仿真中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶汽车仿真器在模拟城市交叉口密集、异构的交通交互方面存在局限性，难以处理中国常见的机动车、非机动车和行人混合交通流，并且在学习高维联合分布时容易出现模式崩溃和长期不稳定的问题。

Method: 作者收集了名为CiCross的大型真实城市交叉口数据集，并基于此提出了IntersectioNDE仿真器。其核心是交互解耦策略（IDS），该策略通过学习子集代理的组合动力学来实现从边缘到联合的模拟，并集成到具有特定训练技术的场景感知Transformer网络中，以提高仿真的鲁棒性和长期稳定性。

Result: 在CiCross数据集上的实验表明，IntersectioNDE在仿真保真度、稳定性和复制复杂、分布层级的城市交通动态方面优于基线方法。

Conclusion: IntersectioNDE通过交互解耦策略（IDS）有效解决了城市交叉口交通仿真中的挑战，提高了仿真的准确性和稳定性，为自动驾驶汽车的安全性和可靠性测试提供了更好的支持。

Abstract: Realistic traffic simulation is critical for ensuring the safety and
reliability of autonomous vehicles (AVs), especially in complex and diverse
urban traffic environments. However, existing data-driven simulators face two
key challenges: a limited focus on modeling dense, heterogeneous interactions
at urban intersections - which are prevalent, crucial, and practically
significant in countries like China, featuring diverse agents including
motorized vehicles (MVs), non-motorized vehicles (NMVs), and pedestrians - and
the inherent difficulty in robustly learning high-dimensional joint
distributions for such high-density scenes, often leading to mode collapse and
long-term simulation instability. We introduce City Crossings Dataset
(CiCross), a large-scale dataset collected from a real-world urban
intersection, uniquely capturing dense, heterogeneous multi-agent interactions,
particularly with a substantial proportion of MVs, NMVs and pedestrians. Based
on this dataset, we propose IntersectioNDE (Intersection Naturalistic Driving
Environment), a data-driven simulator tailored for complex urban intersection
scenarios. Its core component is the Interaction Decoupling Strategy (IDS), a
training paradigm that learns compositional dynamics from agent subsets,
enabling the marginal-to-joint simulation. Integrated into a scene-aware
Transformer network with specialized training techniques, IDS significantly
enhances simulation robustness and long-term stability for modeling
heterogeneous interactions. Experiments on CiCross show that IntersectioNDE
outperforms baseline methods in simulation fidelity, stability, and its ability
to replicate complex, distribution-level urban traffic dynamics.

</details>


### [986] [GRIP: A Unified Framework for Grid-Based Relay and Co-Occurrence-Aware Planning in Dynamic Environments](https://arxiv.org/abs/2510.10865)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: GRIP是一个统一的、模块化的框架，用于在动态、混乱和语义复杂的环境中进行机器人导航，通过结合感知、符号推理和空间规划，在AI2-THOR和RoboTHOR基准测试中取得了更高的成功率和路径效率，并已成功部署到真实世界的Jetbot上。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航方法在动态、混乱和语义复杂的环境中存在适应性不足的问题，特别是在部分可观察性和语义模糊的情况下，它们通常依赖于静态先验或有限的记忆。

Method: GRIP（Grid-based Relay with Intermediate Planning）框架集成了动态二维网格构建、开放词汇对象关联、共现感知符号规划以及行为克隆、D*搜索和网格条件控制的混合策略执行。它有三种可扩展的变体：GRIP-L（轻量级）、GRIP-F（完整版）和GRIP-R（真实世界）。

Result: 在AI2-THOR和RoboTHOR基准测试中，GRIP在长任务中的成功率提高了9.6%，路径效率（SPL和SAE）提高了2倍以上。定性分析显示，在模糊场景中可以生成可解释的符号计划。在Jetbot上的真实世界部署验证了GRIP在传感器噪声和环境变化下的泛化能力。

Conclusion: GRIP是一个健壮、可扩展且可解释的框架，成功地弥合了模拟与真实世界导航之间的差距。

Abstract: Robots navigating dynamic, cluttered, and semantically complex environments
must integrate perception, symbolic reasoning, and spatial planning to
generalize across diverse layouts and object categories. Existing methods often
rely on static priors or limited memory, constraining adaptability under
partial observability and semantic ambiguity. We present GRIP, Grid-based Relay
with Intermediate Planning, a unified, modular framework with three scalable
variants: GRIP-L (Lightweight), optimized for symbolic navigation via semantic
occupancy grids; GRIP-F (Full), supporting multi-hop anchor chaining and
LLM-based introspection; and GRIP-R (Real-World), enabling physical robot
deployment under perceptual uncertainty. GRIP integrates dynamic 2D grid
construction, open-vocabulary object grounding, co-occurrence-aware symbolic
planning, and hybrid policy execution using behavioral cloning, D* search, and
grid-conditioned control. Empirical results on AI2-THOR and RoboTHOR benchmarks
show that GRIP achieves up to 9.6% higher success rates and over $2\times$
improvement in path efficiency (SPL and SAE) on long-horizon tasks. Qualitative
analyses reveal interpretable symbolic plans in ambiguous scenes. Real-world
deployment on a Jetbot further validates GRIP's generalization under sensor
noise and environmental variation. These results position GRIP as a robust,
scalable, and explainable framework bridging simulation and real-world
navigation.

</details>


### [987] [Ego-Vision World Model for Humanoid Contact Planning](https://arxiv.org/abs/2510.11682)
*Hang Liu,Yuman Gao,Sangli Teng,Yufeng Chi,Yakun Sophia Shao,Zhongyu Li,Maani Ghaffari,Koushil Sreenath*

Main category: cs.RO

TL;DR: 通过结合学习到的世界模型和基于采样的模型预测控制（MPC），并利用无演示的离线数据集进行训练，使人形机器人能够在非结构化环境中利用物理接触进行自主导航，解决了传统方法在处理接触复杂性、样本效率和多任务能力方面的不足。


<details>
  <summary>Details</summary>
Motivation: 为了使人形机器人能够利用物理接触进行自主导航，而不是仅仅避免碰撞，这对于在非结构化环境中实现自主至关重要。

Method: 提出了一种结合学习到的世界模型和基于采样的模型预测控制（MPC）的框架，该框架在一个无演示的离线数据集上进行训练，以在压缩的潜在空间中预测未来结果。为了解决稀疏的接触奖励和传感器噪声问题，MPC使用学习到的代理价值函数来进行密集、鲁棒的规划。

Result: 所提出的单一、可扩展的模型支持了接触感知任务，包括扰动后的墙壁支撑、阻挡传入物体以及穿越高度限制的拱门，与在线强化学习相比，在数据效率和多任务能力方面有所提高。

Conclusion: 所提出的框架通过结合学习到的世界模型和MPC，并利用代理价值函数，成功地实现了人形机器人在物理世界中的鲁棒、实时的接触规划，展示了其在数据效率和多任务能力方面的优势。

Abstract: Enabling humanoid robots to exploit physical contact, rather than simply
avoid collisions, is crucial for autonomy in unstructured environments.
Traditional optimization-based planners struggle with contact complexity, while
on-policy reinforcement learning (RL) is sample-inefficient and has limited
multi-task ability. We propose a framework combining a learned world model with
sampling-based Model Predictive Control (MPC), trained on a demonstration-free
offline dataset to predict future outcomes in a compressed latent space. To
address sparse contact rewards and sensor noise, the MPC uses a learned
surrogate value function for dense, robust planning. Our single, scalable model
supports contact-aware tasks, including wall support after perturbation,
blocking incoming objects, and traversing height-limited arches, with improved
data efficiency and multi-task capability over on-policy RL. Deployed on a
physical humanoid, our system achieves robust, real-time contact planning from
proprioception and ego-centric depth images. Website:
https://ego-vcp.github.io/

</details>


### [988] [QuayPoints: A Reasoning Framework to Bridge the Information Gap Between Global and Local Planning in Autonomous Racing](https://arxiv.org/abs/2510.10886)
*Yashom Dighe,Youngjin Kim,Karthik Dantu*

Main category: cs.RO

TL;DR: 自主赛车需要整合感知、规划和控制以最小化延迟并及时做出决策。现有的自主导航流程会丢失全局信息，影响局部规划器的决策。本文研究了将时间最优性信息传递给局部规划器以改进决策。我们提出了一种名为 QuayPoints 的框架，它将全局知识传递给局部规划器，使规划器能在偏离最优赛道时做出更明智的全局决策，例如在超车时。实验证明，集成 QuayPoints 的规划器在四个不同的赛道上都能成功超越速度高达80%的对手。


<details>
  <summary>Details</summary>
Motivation: 标准自主导航流程会丢失全局信息，导致局部规划器在做出反应性决策时信息有限。因此，本文旨在研究能否将时间最优性信息传递给局部规划器，以改进其决策。

Method: 本文提出了一个名为 QuayPoints 的框架，它能够保留关键的全局知识，并通过 QuayPoints 区域将这些信息传递给局部规划器。这些区域的特点是，偏离最优赛道的行为会导致最优性的显著妥协。这种机制使得局部规划器在偏离赛道时能够做出更明智的全局决策，例如在进行战略性超车时。

Result: 在现有规划器中集成了 QuayPoints，并在四个不同的赛道上进行了测试。结果表明，该系统能够持续超越速度高达自身 75% 的对手。

Conclusion: QuayPoints 框架能够有效地将全局时间最优性信息传递给局部规划器，从而改进其决策能力，尤其是在超车等需要全局考虑的情况下。

Abstract: Autonomous racing requires tight integration between perception, planning and
control to minimize latency as well as timely decision making. A standard
autonomy pipeline comprising a global planner, local planner, and controller
loses information as the higher-level racing context is sequentially propagated
downstream into specific task-oriented context. In particular, the global
planner's understanding of optimality is typically reduced to a sparse set of
waypoints, leaving the local planner to make reactive decisions with limited
context. This paper investigates whether additional global insights,
specifically time-optimality information, can be meaningfully passed to the
local planner to improve downstream decisions. We introduce a framework that
preserves essential global knowledge and conveys it to the local planner
through QuayPoints regions where deviations from the optimal raceline result in
significant compromises to optimality. QuayPoints enable local planners to make
more informed global decisions when deviating from the raceline, such as during
strategic overtaking. To demonstrate this, we integrate QuayPoints into an
existing planner and show that it consistently overtakes opponents traveling at
up to 75% of the ego vehicle's speed across four distinct race tracks.

</details>


### [989] [An Adaptive Transition Framework for Game-Theoretic Based Takeover](https://arxiv.org/abs/2510.10893)
*Dikshant Shehmar,Matthew E. Taylor,Ehsan Hashemi*

Main category: cs.RO

TL;DR: 现有自动驾驶系统在车辆控制权交接时，受限于固定时间触发的策略，未能充分考虑驾驶员状态的变化，导致接管反应迟缓、轨迹误差增大。本文提出了一种自适应接管策略，该策略基于时间与驾驶员轨迹跟踪能力，能够动态调整控制权限，以实现更平顺、更高效的控制权交接。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中，从 autonomous systems 控制到 human drivers 控制的转换至关重要，尤其是在驾驶员处于“out-of-the-loop”（OOTL）状态时，驾驶员的准备度降低，反应时间延长。现有的接管策略基于固定的时间触发，无法适应驾驶员实时性能的变化。

Method: 本文将共享控制建模为一个合作微分博弈，通过调整时变的目标函数来调节控制权限，而非直接混合控制力矩。引入了一个特定于驾驶员的状态跟踪矩阵，使转换能够与个体控制偏好保持一致。

Result: 通过累积轨迹误差指标评估了多种转换策略。在标准化的 ISO 变道机动的人机回路控制场景下，与传统策略相比，自适应转换策略能够减小轨迹偏差和驾驶员控制的开销。实验证实，基于实时偏差连续调整控制权限能够增强车辆稳定性，同时减少接管过程中的驾驶员开销。

Conclusion: 本文提出的自适应接管策略通过考虑时间和驾驶员轨迹跟踪能力，能够动态调整控制权，减少轨迹误差和驾驶员控制开销，提高车辆稳定性和接管过程的平顺性。

Abstract: The transition of control from autonomous systems to human drivers is
critical in automated driving systems, particularly due to the out-of-the-loop
(OOTL) circumstances that reduce driver readiness and increase reaction times.
Existing takeover strategies are based on fixed time-based transitions, which
fail to account for real-time driver performance variations. This paper
proposes an adaptive transition strategy that dynamically adjusts the control
authority based on both the time and tracking ability of the driver trajectory.
Shared control is modeled as a cooperative differential game, where control
authority is modulated through time-varying objective functions instead of
blending control torques directly. To ensure a more natural takeover, a
driver-specific state-tracking matrix is introduced, allowing the transition to
align with individual control preferences. Multiple transition strategies are
evaluated using a cumulative trajectory error metric. Human-in-the-loop control
scenarios of the standardized ISO lane change maneuvers demonstrate that
adaptive transitions reduce trajectory deviations and driver control effort
compared to conventional strategies. Experiments also confirm that continuously
adjusting control authority based on real-time deviations enhances vehicle
stability while reducing driver effort during takeover.

</details>


### [990] [Towards a Unified Understanding of Robot Manipulation: A Comprehensive Survey](https://arxiv.org/abs/2510.10903)
*Shuanghao Bai,Wenxuan Song,Jiayi Chen,Yuheng Ji,Zhide Zhong,Jin Yang,Han Zhao,Wanqi Zhou,Wei Zhao,Zhe Li,Pengxiang Ding,Cheng Chi,Haoang Li,Chang Xu,Xiaolong Zheng,Donglin Wang,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 本篇论文对机器人操控领域进行了全面的调查，重点关注了多模态模型驱动下的具身智能进展。它提出了新的高层规划（语言、代码、运动、可供性、3D表示）和低层学习控制（输入建模、潜在学习、策略学习）的分类方法，并分析了数据收集、利用和泛化方面的瓶颈。最后，对现实世界的应用进行了回顾，并提供了一个资源列表以供社区参考。


<details>
  <summary>Details</summary>
Motivation: 机器人操控是具身智能的核心挑战之一，需要融合感知、规划和控制，以应对多样化和非结构化的环境。

Method: 对机器人操控的背景、基准、数据集和现有方法进行了全面的概述。将高层规划扩展到包括语言、代码、运动、可供性、3D表示，并引入了基于输入建模、潜在学习和策略学习等训练范式的低层学习控制分类。此外，还对数据收集、利用和泛化方面的瓶颈进行了分类。

Result: 提供了机器人操控方法的统一分类，识别了关键瓶颈，并回顾了现实世界的应用。通过GitHub仓库共享了相关资源。

Conclusion: 本调查为机器人操控领域的研究人员提供了一个更广泛的视角和更深入的见解，作为一个易于理解的入门指南和结构化的参考资料。

Abstract: Embodied intelligence has witnessed remarkable progress in recent years,
driven by advances in computer vision, natural language processing, and the
rise of large-scale multimodal models. Among its core challenges, robot
manipulation stands out as a fundamental yet intricate problem, requiring the
seamless integration of perception, planning, and control to enable interaction
within diverse and unstructured environments. This survey presents a
comprehensive overview of robotic manipulation, encompassing foundational
background, task-organized benchmarks and datasets, and a unified taxonomy of
existing methods. We extend the classical division between high-level planning
and low-level control by broadening high-level planning to include language,
code, motion, affordance, and 3D representations, while introducing a new
taxonomy of low-level learning-based control grounded in training paradigms
such as input modeling, latent learning, and policy learning. Furthermore, we
provide the first dedicated taxonomy of key bottlenecks, focusing on data
collection, utilization, and generalization, and conclude with an extensive
review of real-world applications. Compared with prior surveys, our work offers
both a broader scope and deeper insight, serving as an accessible roadmap for
newcomers and a structured reference for experienced researchers. All related
resources, including research papers, open-source datasets, and projects, are
curated for the community at
https://github.com/BaiShuanghao/Awesome-Robotics-Manipulation.

</details>


### [991] [More than A Point: Capturing Uncertainty with Adaptive Affordance Heatmaps for Spatial Grounding in Robotic Tasks](https://arxiv.org/abs/2510.10912)
*Xinyu Shao,Yanzhe Tang,Pengwei Xie,Kaiwen Zhou,Yuzheng Zhuang,Xingyue Quan,Jianye Hao,Long Zeng,Xiu Li*

Main category: cs.RO

TL;DR: RoboMAP使用连续、自适应的区域热图来表示空间目标，以解决语言引导机器人系统中空间推理的局限性，从而提高任务成功率、可解释性和效率。


<details>
  <summary>Details</summary>
Motivation: 许多语言引导的机器人系统在将空间推理折叠成离散点时存在脆弱性，容易受到感知噪声和语义歧义的影响。RoboMAP旨在通过使用连续、自适应的区域热图来表示空间目标，以此来解决这一挑战。

Method: RoboMAP框架将空间目标表示为连续、自适应的区域热图，这种密集表示可以捕获空间基础中的不确定性，并为下游策略提供更丰富的信息。

Result: RoboMAP在大多数基础基准测试中都超过了之前的最先进技术，速度提高了 50 倍，并在真实世界的操纵中达到了 82% 的成功率。通过广泛的模拟和物理实验，它展示了强大的性能，并在零次导航任务中表现出很强的泛化能力。

Conclusion: RoboMAP通过其密集表示显著提高了语言引导机器人系统的任务成功率、可解释性和效率，并在各种基准和实际应用中取得了最先进的成果。

Abstract: Many language-guided robotic systems rely on collapsing spatial reasoning
into discrete points, making them brittle to perceptual noise and semantic
ambiguity. To address this challenge, we propose RoboMAP, a framework that
represents spatial targets as continuous, adaptive affordance heatmaps. This
dense representation captures the uncertainty in spatial grounding and provides
richer information for downstream policies, thereby significantly enhancing
task success and interpretability. RoboMAP surpasses the previous
state-of-the-art on a majority of grounding benchmarks with up to a 50x speed
improvement, and achieves an 82\% success rate in real-world manipulation.
Across extensive simulated and physical experiments, it demonstrates robust
performance and shows strong zero-shot generalization to navigation. More
details and videos can be found at https://robo-map.github.io.

</details>


### [992] [Game-Theoretic Risk-Shaped Reinforcement Learning for Safe Autonomous Driving](https://arxiv.org/abs/2510.10960)
*Dong Hu,Fenqing Hu,Lidong Yang,Chao Huang*

Main category: cs.RO

TL;DR: 该研究提出了一种名为GTR2L的新型博弈论风险塑造强化学习框架，用于解决自动驾驶中的安全问题，通过多层次博弈论世界模型、自适应前视窗口和不确定性感知屏障机制来预测行为、管理风险和调整安全边界，并在各种危险交通场景中显著优于现有方法和人类驾驶员。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习（RL）方法在自动驾驶（AD）中难以平衡安全性、效率和适应性，因为它们主要关注奖励最大化，而没有明确考虑风险或安全约束，尤其是在动态和复杂的交通环境中。

Method: 提出了一种名为GTR2L（博弈论风险塑造强化学习）的框架，该框架包含一个多层次的博弈论世界模型，用于联合预测周围车辆的交互行为及其相关风险；一个自适应前视窗口，根据预测不确定性动态调整；一个不确定性感知屏障机制，用于灵活调整安全边界；以及一个专门的风险建模方法，明确捕捉认知不确定性和随机不确定性，以指导约束策略优化。

Result: 在各种各样的安全关键型交通场景中进行的大量评估表明，GTR2L在成功率、碰撞和违规减少以及驾驶效率方面，显著优于包括人类驾驶员在内的最先进的基线。

Conclusion: GTR2L框架通过整合博弈论、风险建模和不确定性处理，能够有效地提高自动驾驶系统的安全性和性能，特别是在复杂和不可预测的交通环境中。

Abstract: Ensuring safety in autonomous driving (AD) remains a significant challenge,
especially in highly dynamic and complex traffic environments where diverse
agents interact and unexpected hazards frequently emerge. Traditional
reinforcement learning (RL) methods often struggle to balance safety,
efficiency, and adaptability, as they primarily focus on reward maximization
without explicitly modeling risk or safety constraints. To address these
limitations, this study proposes a novel game-theoretic risk-shaped RL (GTR2L)
framework for safe AD. GTR2L incorporates a multi-level game-theoretic world
model that jointly predicts the interactive behaviors of surrounding vehicles
and their associated risks, along with an adaptive rollout horizon that adjusts
dynamically based on predictive uncertainty. Furthermore, an uncertainty-aware
barrier mechanism enables flexible modulation of safety boundaries. A dedicated
risk modeling approach is also proposed, explicitly capturing both epistemic
and aleatoric uncertainty to guide constrained policy optimization and enhance
decision-making in complex environments. Extensive evaluations across diverse
and safety-critical traffic scenarios show that GTR2L significantly outperforms
state-of-the-art baselines, including human drivers, in terms of success rate,
collision and violation reduction, and driving efficiency. The code is
available at https://github.com/DanielHu197/GTR2L.

</details>


### [993] [RoVer: Robot Reward Model as Test-Time Verifier for Vision-Language-Action Model](https://arxiv.org/abs/2510.10975)
*Mingtong Dai,Lingbo Liu,Yongjie Bai,Yang Liu,Zhouxia Wang,Rui SU,Chunjie Chen,Liang Lin,Xinyu Wu*

Main category: cs.RO

TL;DR: RoVer是一个测试时扩展框架，通过使用机器人过程奖励模型（PRM）作为测试时验证器，来增强现有视觉-语言-动作（VLA）模型的性能，而无需修改其架构或权重。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型性能提升依赖于扩展训练数据和模型大小，但成本高昂且受数据收集限制。RoVer旨在解决这一局限性。

Method: RoVer包括：1. 分配基于标量过程的奖励来评估候选动作的可靠性；2. 预测一个动作空间方向以进行候选扩展/细化。在推理过程中，RoVer同时生成多个候选动作，沿着PRM预测的方向进行扩展，然后用PRM对所有候选动作进行评分以选择最优动作。通过缓存共享感知特征，可以分摊感知成本，并在相同的测试时间计算预算下评估更多候选动作。

Result: RoVer能够将计算资源转化为更好的动作决策，在没有额外训练开销的情况下实现测试时扩展的好处。

Conclusion: RoVer是一个通用的、即插即用的VLA测试时扩展框架，提出了一个PRM模型，该模型可同时提供标量过程奖励和指导探索的动作空间方向，并通过一种利用共享感知缓存的高效定向采样策略，实现了可扩展的候选生成和推理选择。

Abstract: Vision-Language-Action (VLA) models have become a prominent paradigm for
embodied intelligence, yet further performance improvements typically rely on
scaling up training data and model size -- an approach that is prohibitively
expensive for robotics and fundamentally limited by data collection costs.We
address this limitation with $\mathbf{RoVer}$, an embodied test-time scaling
framework that uses a $\mathbf{Ro}$bot Process Reward Model (PRM) as a
Test-Time $\mathbf{Ver}$ifier to enhance the capabilities of existing VLA
models without modifying their architectures or weights. Specifically, RoVer
(i) assigns scalar-based process rewards to evaluate the reliability of
candidate actions, and (ii) predicts an action-space direction for candidate
expansion/refinement. During inference, RoVer generates multiple candidate
actions concurrently from the base policy, expands them along PRM-predicted
directions, and then scores all candidates with PRM to select the optimal
action for execution. Notably, by caching shared perception features, it can
amortize perception cost and evaluate more candidates under the same test-time
computational budget. Essentially, our approach effectively transforms
available computing resources into better action decision-making, realizing the
benefits of test-time scaling without extra training overhead. Our
contributions are threefold: (1) a general, plug-and-play test-time scaling
framework for VLAs; (2) a PRM that jointly provides scalar process rewards and
an action-space direction to guide exploration; and (3) an efficient
direction-guided sampling strategy that leverages a shared perception cache to
enable scalable candidate generation and selection during inference.

</details>


### [994] [AMO-HEAD: Adaptive MARG-Only Heading Estimation for UAVs under Magnetic Disturbances](https://arxiv.org/abs/2510.10979)
*Qizhi Guo,Siyuan Yang,Junning Lyu,Jianjun Sun,Defu Lin,Shaoming He*

Main category: cs.RO

TL;DR: 该研究提出了一种自适应MARG传感器组合的仅磁航姿估计方法（AMO-HEAD），用于解决无人机在磁场干扰的室内环境中精确航姿估计的挑战。


<details>
  <summary>Details</summary>
Motivation: 室内环境的磁场干扰会严重影响无人机航姿估计的准确性。

Method: 提出了一种轻量级、计算高效的扩展卡尔曼滤波器（EKF）框架，该框架利用惯性传感器和磁力计实现可靠的航姿估计。通过集成陀螺仪角速度测量来传播四元数状态，然后使用加速度计和磁力计数据进行校正。引入自适应过程噪声协方差方法来补偿陀螺仪测量噪声、偏差漂移和离散化误差。通过实时磁偏差检测应用比例因子来减轻外部磁场干扰的影响。

Result: 通过李导数对所提出的AMO-HEAD进行了理论可观测性分析。在定制的无人机平台上，在真实的室内环境中进行了广泛的实验。

Conclusion: 实验结果表明，该算法在磁场干扰条件下能够提供精确的航姿估计。

Abstract: Accurate and robust heading estimation is crucial for unmanned aerial
vehicles (UAVs) when conducting indoor inspection tasks. However, the cluttered
nature of indoor environments often introduces severe magnetic disturbances,
which can significantly degrade heading accuracy. To address this challenge,
this paper presents an Adaptive MARG-Only Heading (AMO-HEAD) estimation
approach for UAVs operating in magnetically disturbed environments. AMO-HEAD is
a lightweight and computationally efficient Extended Kalman Filter (EKF)
framework that leverages inertial and magnetic sensors to achieve reliable
heading estimation. In the proposed approach, gyroscope angular rate
measurements are integrated to propagate the quaternion state, which is
subsequently corrected using accelerometer and magnetometer data. The corrected
quaternion is then used to compute the UAV's heading. An adaptive process noise
covariance method is introduced to model and compensate for gyroscope
measurement noise, bias drift, and discretization errors arising from the Euler
method integration. To mitigate the effects of external magnetic disturbances,
a scaling factor is applied based on real-time magnetic deviation detection. A
theoretical observability analysis of the proposed AMO-HEAD is performed using
the Lie derivative. Extensive experiments were conducted in real world indoor
environments with customized UAV platforms. The results demonstrate the
effectiveness of the proposed algorithm in providing precise heading estimation
under magnetically disturbed conditions.

</details>


### [995] [Into the Unknown: Towards using Generative Models for Sampling Priors of Environment Uncertainty for Planning in Configuration Spaces](https://arxiv.org/abs/2510.11014)
*Subhransu S. Bhattacharjee,Hao Lu,Dylan Campbell,Rahul Shome*

Main category: cs.RO

TL;DR: 生成式模型可用于机器人规划中的零样本先验。


<details>
  <summary>Details</summary>
Motivation: 在部分可观察性下进行规划需要先验知识，而获取先验知识在实践中很困难。本研究提出了一种利用大规模预训练生成模型生成概率先验的方法，以捕捉环境不确定性和空间语义关系。

Method: 提出一个基于采样的流程，该流程利用大规模预训练的生成模型来生成概率先验，以零样本方式捕捉环境不确定性和空间语义关系。该流程以部分观测为条件，恢复完整的RGB-D点云样本，并包含占用和目标语义，可以直接用于配置空间规划。

Result: 在Matterport3D基准上，该方法能够恢复与真实情况一致的常识性空间语义，并生成可用于运动规划的多样化、干净的3D点云。

Conclusion: 生成式模型有潜力成为机器人规划中丰富的先验来源。

Abstract: Priors are vital for planning under partial observability, yet difficult to
obtain in practice. We present a sampling-based pipeline that leverages
large-scale pretrained generative models to produce probabilistic priors
capturing environmental uncertainty and spatio-semantic relationships in a
zero-shot manner. Conditioned on partial observations, the pipeline recovers
complete RGB-D point cloud samples with occupancy and target semantics,
formulated to be directly useful in configuration-space planning. We establish
a Matterport3D benchmark of rooms partially visible through doorways, where a
robot must navigate to an unobserved target object. Effective priors for this
setting must represent both occupancy and target-location uncertainty in
unobserved regions. Experiments show that our approach recovers commonsense
spatial semantics consistent with ground truth, yielding diverse, clean 3D
point clouds usable in motion planning, highlight the promise of generative
models as a rich source of priors for robotic planning.

</details>


### [996] [Refinery: Active Fine-tuning and Deployment-time Optimization for Contact-Rich Policies](https://arxiv.org/abs/2510.11019)
*Bingjie Tang,Iretiayo Akinola,Jie Xu,Bowen Wen,Dieter Fox,Gaurav S. Sukhatme,Fabio Ramos,Abhishek Gupta,Yashraj Narang*

Main category: cs.RO

TL;DR: Refinery框架通过贝叶斯优化和高斯混合模型提高了机器人装配任务中基于仿真的策略性能，将平均成功率提高了10.98%，并实现了长序列多部件装配。


<details>
  <summary>Details</summary>
Motivation: 高精度、高接触任务（如机器人装配）中基于仿真的策略虽然在研究中表现良好，但由于策略性能方差大，未能达到行业标准，并且策略链接脆弱。

Method: 提出了一种名为Refinery的框架，该框架结合了贝叶斯优化引导的微调和基于高斯混合模型采样的部署方法，以提高个体策略性能和选择成功的初始条件。

Result: 在机器人装配的仿真环境中，将平均成功率提高了10.98%，达到91.51%，并在真实世界中也取得了可比的性能。此外，还成功地将微调后的策略链接起来，完成了最多包含8个部件的长序列多部件装配。

Conclusion: Refinery框架有效地弥合了仿真基准与行业标准之间的性能差距，提高了策略在不同初始条件下的鲁棒性，并实现了复杂的多部件装配任务。

Abstract: Simulation-based learning has enabled policies for precise, contact-rich
tasks (e.g., robotic assembly) to reach high success rates (~80%) under high
levels of observation noise and control error. Although such performance may be
sufficient for research applications, it falls short of industry standards and
makes policy chaining exceptionally brittle. A key limitation is the high
variance in individual policy performance across diverse initial conditions. We
introduce Refinery, an effective framework that bridges this performance gap,
robustifying policy performance across initial conditions. We propose Bayesian
Optimization-guided fine-tuning to improve individual policies, and Gaussian
Mixture Model-based sampling during deployment to select initializations that
maximize execution success. Using Refinery, we improve mean success rates by
10.98% over state-of-the-art methods in simulation-based learning for robotic
assembly, reaching 91.51% in simulation and comparable performance in the real
world. Furthermore, we demonstrate that these fine-tuned policies can be
chained to accomplish long-horizon, multi-part
assembly$\unicode{x2013}$successfully assembling up to 8 parts without
requiring explicit multi-step training.

</details>


### [997] [XGrasp: Gripper-Aware Grasp Detection with Multi-Gripper Data Generation](https://arxiv.org/abs/2510.11036)
*Yeonseo Lee,Jungwook Mun,Hyosup Shin,Guebin Hwang,Junhee Nam,Taeyeop Lee,Sungho Jo*

Main category: cs.RO

TL;DR: XGrasp是一个能够处理多种抓手配置的实时抓手感知抓取检测框架，通过数据增强和分层两阶段架构解决了数据稀疏性问题，并在各种抓手类型上实现了有竞争力的抓取成功率和更快的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人抓取方法大多是为单一抓手类型设计的，这在需要多种末端执行器的现实场景中限制了其适用性。

Method: XGrasp采用分层两阶段架构：第一阶段，抓取点预测器（GPP）利用全局场景信息和抓手规格识别最佳位置；第二阶段，角度宽度预测器（AWP）利用局部特征优化抓取角度和宽度。AWP模块中的对比学习实现了对未见抓手的零样本泛化。

Result: 实验结果表明，XGrasp在各种抓手类型上实现了有竞争力的抓取成功率，并且与现有的抓手感知方法相比，推理速度有了显著提高。

Conclusion: XGrasp是一个高效、通用的抓取检测框架，能够处理多种抓手配置，并在保持高抓取成功率的同时提高了推理速度，并且易于与视觉基础模型集成。

Abstract: Most robotic grasping methods are typically designed for single gripper
types, which limits their applicability in real-world scenarios requiring
diverse end-effectors. We propose XGrasp, a real-time gripper-aware grasp
detection framework that efficiently handles multiple gripper configurations.
The proposed method addresses data scarcity by systematically augmenting
existing datasets with multi-gripper annotations. XGrasp employs a hierarchical
two-stage architecture. In the first stage, a Grasp Point Predictor (GPP)
identifies optimal locations using global scene information and gripper
specifications. In the second stage, an Angle-Width Predictor (AWP) refines the
grasp angle and width using local features. Contrastive learning in the AWP
module enables zero-shot generalization to unseen grippers by learning
fundamental grasping characteristics. The modular framework integrates
seamlessly with vision foundation models, providing pathways for future
vision-language capabilities. The experimental results demonstrate competitive
grasp success rates across various gripper types, while achieving substantial
improvements in inference speed compared to existing gripper-aware methods.
Project page: https://sites.google.com/view/xgrasp

</details>


### [998] [Unveiling Uncertainty-Aware Autonomous Cooperative Learning Based Planning Strategy](https://arxiv.org/abs/2510.11041)
*Shiyao Zhang,Liwei Deng,Shuyu Zhang,Weijie Yuan,Hong Zhang*

Main category: cs.RO

TL;DR: 使用基于深度强化学习的框架解决多智能体协同规划中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的自主协同规划（ACP）策略在处理感知、规划和通信不确定性方面存在局限性。

Method: 提出一种新的深度强化学习自主协同规划（DRLACP）框架，采用带有门循环单元（GRU）的软Actor-Critic（SAC）算法来学习最优时变动作，即使在状态信息不完整的情况下。

Result: 通过CARLA仿真平台验证了DRLACP框架，并与其他基线方法进行了比较，结果表明DRLACP在不确定条件下表现更优。

Conclusion: 所提出的DRLACP框架能够有效地进行协同规划，并能克服多智能体协同规划中的不确定性问题。

Abstract: In future intelligent transportation systems, autonomous cooperative planning
(ACP), becomes a promising technique to increase the effectiveness and security
of multi-vehicle interactions. However, multiple uncertainties cannot be fully
addressed for existing ACP strategies, e.g. perception, planning, and
communication uncertainties. To address these, a novel deep reinforcement
learning-based autonomous cooperative planning (DRLACP) framework is proposed
to tackle various uncertainties on cooperative motion planning schemes.
Specifically, the soft actor-critic (SAC) with the implementation of gate
recurrent units (GRUs) is adopted to learn the deterministic optimal
time-varying actions with imperfect state information occurred by planning,
communication, and perception uncertainties. In addition, the real-time actions
of autonomous vehicles (AVs) are demonstrated via the Car Learning to Act
(CARLA) simulation platform. Evaluation results show that the proposed DRLACP
learns and performs cooperative planning effectively, which outperforms other
baseline methods under different scenarios with imperfect AV state information.

</details>


### [999] [Flow Matching-Based Autonomous Driving Planning with Advanced Interactive Behavior Modeling](https://arxiv.org/abs/2510.11083)
*Tianyi Tan,Yinan Zheng,Ruiming Liang,Zexu Wang,Kexin Zheng,Jinliang Zheng,Jianxiong Li,Xianyuan Zhan,Jingjing Liu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Modeling interactive driving behaviors in complex scenarios remains a
fundamental challenge for autonomous driving planning. Learning-based
approaches attempt to address this challenge with advanced generative models,
removing the dependency on over-engineered architectures for representation
fusion. However, brute-force implementation by simply stacking transformer
blocks lacks a dedicated mechanism for modeling interactive behaviors that are
common in real driving scenarios. The scarcity of interactive driving data
further exacerbates this problem, leaving conventional imitation learning
methods ill-equipped to capture high-value interactive behaviors. We propose
Flow Planner, which tackles these problems through coordinated innovations in
data modeling, model architecture, and learning scheme. Specifically, we first
introduce fine-grained trajectory tokenization, which decomposes the trajectory
into overlapping segments to decrease the complexity of whole trajectory
modeling. With a sophisticatedly designed architecture, we achieve efficient
temporal and spatial fusion of planning and scene information, to better
capture interactive behaviors. In addition, the framework incorporates flow
matching with classifier-free guidance for multi-modal behavior generation,
which dynamically reweights agent interactions during inference to maintain
coherent response strategies, providing a critical boost for interactive
scenario understanding. Experimental results on the large-scale nuPlan dataset
and challenging interactive interPlan dataset demonstrate that Flow Planner
achieves state-of-the-art performance among learning-based approaches while
effectively modeling interactive behaviors in complex driving scenarios.

</details>


### [1000] [Design and Koopman Model Predictive Control of A Soft Exoskeleton Based on Origami-Inspired Pneumatic Actuator for Knee Rehabilitation](https://arxiv.org/abs/2510.11094)
*Junxiang Wang,Han Zhang,Zehao Wang,Huaiyuan Chen,Pu Wang,Weidong Chen*

Main category: cs.RO

TL;DR: 使用基于灵感来自折纸的空气动力执行器的软外骨骼，结合深度库普曼网络和预测控制，为中风患者提供有效的实时膝关节康复训练。


<details>
  <summary>Details</summary>
Motivation: 传统刚性外骨骼笨重且需要额外的依从性控制，而软外骨骼虽然穿戴舒适但其复杂的人机交互动力学对控制提出了挑战。

Method: 设计了一种基于折纸空气动力执行器的软膝关节康复外骨骼。使用深度库普曼网络（DKN）对人机交互动力学进行建模，将肌电信号（EMG）和控制气动阀门和泵的脉宽调制（PWM）波的占空比作为输入。基于得到的库普曼模型，使用模型预测控制（MPC）来实时控制软机器人，以跟踪屏幕上给定的参考信号。

Result: 深度库普曼网络模型准确地捕捉了复杂的人机交互动力学。将EMG信号集成到库普曼模型中可以提高模型精度。个体化的库普曼模型比非个体化的模型表现更好。所提出的控制框架在被动和主动训练模式下均优于传统的PID控制。

Conclusion: 提出的方法为软康复机器人提供了一种新的控制框架，通过结合EMG信号和个性化库普曼模型，实现了对软康复机器人的精确控制，从而提高了康复训练的效果。

Abstract: Effective rehabilitation methods are essential for the recovery of lower limb
dysfunction caused by stroke. Nowadays, robotic exoskeletons have shown great
potentials in rehabilitation. Nevertheless, traditional rigid exoskeletons are
usually heavy and need a lot of work to help the patients to put them on.
Moreover, it also requires extra compliance control to guarantee the safety. In
contrast, soft exoskeletons are easy and comfortable to wear and have intrinsic
compliance, but their complex nonlinear human-robot interaction dynamics would
pose significant challenges for control. In this work, based on the pneumatic
actuators inspired by origami, we design a rehabilitation exoskeleton for knee
that is easy and comfortable to wear. To guarantee the control performance and
enable a nice human-robot interaction, we first use Deep Koopman Network to
model the human-robot interaction dynamics. In particular, by viewing the
electromyography (EMG) signals and the duty cycle of the PWM wave that controls
the pneumatic robot's valves and pump as the inputs, the linear Koopman model
accurately captures the complex human-robot interaction dynamics. Next, based
on the obtained Koopman model, we further use Model Predictive Control (MPC) to
control the soft robot and help the user to do rehabilitation training in
real-time. The goal of the rehabilitation training is to track a given
reference signal shown on the screen. Experiments show that by integrating the
EMG signals into the Koopman model, we have improved the model accuracy to
great extent. In addition, a personalized Koopman model trained from the
individual's own data performs better than the non-personalized model.
Consequently, our control framework outperforms the traditional PID control in
both passive and active training modes. Hence the proposed method provides a
new control framework for soft rehabilitation robots.

</details>


### [1001] [A Primer on SO(3) Action Representations in Deep Reinforcement Learning](https://arxiv.org/abs/2510.11103)
*Martin Schuck,Sherif Samy,Angela P. Schoellig*

Main category: cs.RO

TL;DR: 几何形状影响SO(3)表示，会影响强化学习的探索和优化，切线向量表示在局部坐标系中最可靠。


<details>
  <summary>Details</summary>
Motivation: 许多机器人控制任务需要策略在方向上进行操作，但SO(3)的几何形状使得这一操作具有挑战性。由于SO(3)不承认全局、平滑、最小参数化，常见的表示（如欧拉角、四元数、旋转矩阵和李代数坐标）会带来独特的约束和失败模式。这些权衡在监督学习中得到了充分研究，但它们对强化学习中动作的影响尚不清楚。

Method: 系统评估了三种标准连续控制算法（PPO、SAC和TD3）在密集和稀疏奖励下的SO(3)动作表示。比较了表示如何影响探索、与熵正则化的相互作用以及训练稳定性。分析了不同投影在从欧几里得网络输出中获得有效旋转方面的影响。

Result: 在机器人基准测试中，量化了这些选择的实际影响，并提炼出选择和使用旋转动作的简单、可实施的指南。结果表明，表示引起的几何形状强烈影响探索和优化。

Conclusion: 表示引起的几何形状强烈影响探索和优化，并且在局部坐标系中将动作表示为切线向量能产生最可靠的结果。

Abstract: Many robotic control tasks require policies to act on orientations, yet the
geometry of SO(3) makes this nontrivial. Because SO(3) admits no global,
smooth, minimal parameterization, common representations such as Euler angles,
quaternions, rotation matrices, and Lie algebra coordinates introduce distinct
constraints and failure modes. While these trade-offs are well studied for
supervised learning, their implications for actions in reinforcement learning
remain unclear. We systematically evaluate SO(3) action representations across
three standard continuous control algorithms, PPO, SAC, and TD3, under dense
and sparse rewards. We compare how representations shape exploration, interact
with entropy regularization, and affect training stability through empirical
studies and analyze the implications of different projections for obtaining
valid rotations from Euclidean network outputs. Across a suite of robotics
benchmarks, we quantify the practical impact of these choices and distill
simple, implementation-ready guidelines for selecting and using rotation
actions. Our results highlight that representation-induced geometry strongly
influences exploration and optimization and show that representing actions as
tangent vectors in the local frame yields the most reliable results across
algorithms.

</details>


### [1002] [DemoHLM: From One Demonstration to Generalizable Humanoid Loco-Manipulation](https://arxiv.org/abs/2510.11258)
*Yuhui Fu,Feiyang Xie,Chaoyi Xu,Jing Xiong,Haoqi Yuan,Zongqing Lu*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Loco-manipulation is a fundamental challenge for humanoid robots to achieve
versatile interactions in human environments. Although recent studies have made
significant progress in humanoid whole-body control, loco-manipulation remains
underexplored and often relies on hard-coded task definitions or costly
real-world data collection, which limits autonomy and generalization. We
present DemoHLM, a framework for humanoid loco-manipulation that enables
generalizable loco-manipulation on a real humanoid robot from a single
demonstration in simulation. DemoHLM adopts a hierarchy that integrates a
low-level universal whole-body controller with high-level manipulation policies
for multiple tasks. The whole-body controller maps whole-body motion commands
to joint torques and provides omnidirectional mobility for the humanoid robot.
The manipulation policies, learned in simulation via our data generation and
imitation learning pipeline, command the whole-body controller with closed-loop
visual feedback to execute challenging loco-manipulation tasks. Experiments
show a positive correlation between the amount of synthetic data and policy
performance, underscoring the effectiveness of our data generation pipeline and
the data efficiency of our approach. Real-world experiments on a Unitree G1
robot equipped with an RGB-D camera validate the sim-to-real transferability of
DemoHLM, demonstrating robust performance under spatial variations across ten
loco-manipulation tasks.

</details>


### [1003] [Rotor-Failure-Aware Quadrotors Flight in Unknown Environments](https://arxiv.org/abs/2510.11306)
*Xiaobin Zhou,Miao Wang,Chengao Li,Can Cui,Ruibin Zhang,Yongchao Wang,Chao Xu,Fei Gao*

Main category: cs.RO

TL;DR: 本研究提出了一种用于四旋翼飞行器在未知环境中应对旋翼故障的导航系统，通过结合故障检测与诊断（FDD）、非线性模型预测控制（NMPC）和路径规划，实现了在旋翼故障（如失速或停转）后的鲁棒自主飞行。


<details>
  <summary>Details</summary>
Motivation: 为了应对四旋翼飞行器在未知环境中因旋翼故障导致的高速旋转和振动问题，以及现有容错控制（FTC）和预定义轨迹跟踪方法的局限性。

Method: 设计了一个集成了电机动力学的复合FDD-NMPC控制器以实现快速故障检测和飞行稳定；设计了一个基于FDD结果和时空联合优化的旋翼故障感知规划器；并利用激光雷达（LiDAR）和反扭矩板平台实现高速旋转下的可靠感知。

Result: 该系统在应对旋翼故障（包括螺旋桨卸载和电机停转）方面表现出优于现有方法的性能，并通过实验验证了其在杂乱房间和未知森林等复杂环境中实现自主飞行的能力。

Conclusion: 本研究首次实现了在存在旋翼故障的情况下，四旋翼飞行器在复杂未知环境中进行自主飞行的能力。

Abstract: Rotor failures in quadrotors may result in high-speed rotation and vibration
due to rotor imbalance, which introduces significant challenges for autonomous
flight in unknown environments. The mainstream approaches against rotor
failures rely on fault-tolerant control (FTC) and predefined trajectory
tracking. To the best of our knowledge, online failure detection and diagnosis
(FDD), trajectory planning, and FTC of the post-failure quadrotors in unknown
and complex environments have not yet been achieved. This paper presents a
rotor-failure-aware quadrotor navigation system designed to mitigate the
impacts of rotor imbalance. First, a composite FDD-based nonlinear model
predictive controller (NMPC), incorporating motor dynamics, is designed to
ensure fast failure detection and flight stability. Second, a
rotor-failure-aware planner is designed to leverage FDD results and
spatial-temporal joint optimization, while a LiDAR-based quadrotor platform
with four anti-torque plates is designed to enable reliable perception under
high-speed rotation. Lastly, extensive benchmarks against state-of-the-art
methods highlight the superior performance of the proposed approach in
addressing rotor failures, including propeller unloading and motor stoppage.
The experimental results demonstrate, for the first time, that our approach
enables autonomous quadrotor flight with rotor failures in challenging
environments, including cluttered rooms and unknown forests.

</details>


### [1004] [Adap-RPF: Adaptive Trajectory Sampling for Robot Person Following in Dynamic Crowded Environments](https://arxiv.org/abs/2510.11308)
*Weixi Situ,Hanjing Ye,Jianwei Peng,Yu Zhan,Hong Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一种自适应轨迹采样方法和一种预测感知模型预测积分（MPPI）控制器，以解决机器人跟随（RPF）中常见的遮挡问题，尤其是在动态和拥挤的环境中。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人跟随方法在处理由行人等移动障碍物引起的复杂遮挡时存在不足，通常依赖于固定点跟随或稀疏候选点选择，并且使用的启发式方法过于简单。

Method: 提出了一种自适应轨迹采样方法，该方法在社会感知区域内生成密集的候选点，并使用多目标成本函数进行评估。在此基础上，根据最优点，相对于目标目标的预测运动来估计跟随轨迹。此外，还设计了一种预测感知模型预测积分（MPPI）控制器，该控制器可同时跟踪此轨迹并利用预测的行人运动主动避免碰撞。

Result: 通过大量的实验表明，该方法在平稳性、安全性、鲁棒性和用户舒适度方面优于现有的最先进的方法。并在真实场景的移动机器人上进行了有效性验证。

Conclusion: 该研究提出的自适应轨迹采样方法和预测感知MPPI控制器能够有效解决机器人跟随中的遮挡问题，并在各种性能指标上优于现有方法。

Abstract: Robot person following (RPF) is a core capability in human-robot interaction,
enabling robots to assist users in daily activities, collaborative work, and
other service scenarios. However, achieving practical RPF remains challenging
due to frequent occlusions, particularly in dynamic and crowded environments.
Existing approaches often rely on fixed-point following or sparse
candidate-point selection with oversimplified heuristics, which cannot
adequately handle complex occlusions caused by moving obstacles such as
pedestrians. To address these limitations, we propose an adaptive trajectory
sampling method that generates dense candidate points within socially aware
zones and evaluates them using a multi-objective cost function. Based on the
optimal point, a person-following trajectory is estimated relative to the
predicted motion of the target. We further design a prediction-aware model
predictive path integral (MPPI) controller that simultaneously tracks this
trajectory and proactively avoids collisions using predicted pedestrian
motions. Extensive experiments show that our method outperforms
state-of-the-art baselines in smoothness, safety, robustness, and human
comfort, with its effectiveness further demonstrated on a mobile robot in
real-world scenarios.

</details>


### [1005] [HiMaCon: Discovering Hierarchical Manipulation Concepts from Unlabeled Multi-Modal Data](https://arxiv.org/abs/2510.11321)
*Ruizhe Liu,Pei Zhou,Qian Luo,Li Sun,Jun Cen,Yibing Song,Yanchao Yang*

Main category: cs.RO

TL;DR: 该论文提出了一种无需人类标注的自监督学习框架，用于学习机器人操作中的分层概念，通过跨模态感知相关性和多层次时间抽象来捕捉不变的交互模式。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器人操作的有效泛化，需要能够跨环境和任务捕捉不变交互模式的表征。

Method: 本研究提出的方法结合了一个跨模态相关性网络（识别跨感知模态的持久模式）和一个多视域预测器（跨时间尺度分层组织表征）。

Result: 实验评估表明，在模拟基准和真实世界部署中，所学概念能够增强策略，显著提高机器人操作性能，并且这些概念在没有语义监督的情况下，与人类可解释的操作原语相似。

Conclusion: 所学概念有助于策略专注于可迁移的关系模式，同时关注即时动作和长期目标，该工作在理解操作表征学习和提高机器人复杂场景性能方面取得了进展。

Abstract: Effective generalization in robotic manipulation requires representations
that capture invariant patterns of interaction across environments and tasks.
We present a self-supervised framework for learning hierarchical manipulation
concepts that encode these invariant patterns through cross-modal sensory
correlations and multi-level temporal abstractions without requiring human
annotation. Our approach combines a cross-modal correlation network that
identifies persistent patterns across sensory modalities with a multi-horizon
predictor that organizes representations hierarchically across temporal scales.
Manipulation concepts learned through this dual structure enable policies to
focus on transferable relational patterns while maintaining awareness of both
immediate actions and longer-term goals. Empirical evaluation across simulated
benchmarks and real-world deployments demonstrates significant performance
improvements with our concept-enhanced policies. Analysis reveals that the
learned concepts resemble human-interpretable manipulation primitives despite
receiving no semantic supervision. This work advances both the understanding of
representation learning for manipulation and provides a practical approach to
enhancing robotic performance in complex scenarios.

</details>


### [1006] [Path and Motion Optimization for Efficient Multi-Location Inspection with Humanoid Robots](https://arxiv.org/abs/2510.11401)
*Jiayang Wu,Jiongye Li,Shibowen Zhang,Zhicheng He,Zaijin Wang,Xiaokun Leng,Hangxin Liu,Jingwen Zhang,Jiayi Wang,Song-Chun Zhu,Yao Su*

Main category: cs.RO

TL;DR: 该研究提出了一种新颖的框架，用于高效率和毫米级精度的人形机器人执行检查任务。


<details>
  <summary>Details</summary>
Motivation: 为了实现高速度和高精度的人形机器人检查任务，需要一种能够处理高维度规划问题并确保精确末端执行器跟踪的框架。

Method: 该框架结合了分层规划（利用逆运动学和混合整数规划）、时间最优站立位置生成以及集成模型预测控制（MPC）。分层规划通过解耦高维度规划问题来降低计算复杂性。混合整数规划（MIP）优化站立位置选择和轨迹长度以最小化任务完成时间。MPC系统使用简化的运动学和单步位置校正来确保毫米级的末端执行器跟踪精度。

Result: 仿真和Kuavo 4Pro人形机器人平台上的实验表明，该框架在多位置任务中表现出低时间成本和高成功率。

Conclusion: 该框架能够高效且精确地执行复杂工业操作，展示了其在人形机器人检查任务中的潜力。

Abstract: This paper proposes a novel framework for humanoid robots to execute
inspection tasks with high efficiency and millimeter-level precision. The
approach combines hierarchical planning, time-optimal standing position
generation, and integrated \ac{mpc} to achieve high speed and precision. A
hierarchical planning strategy, leveraging \ac{ik} and \ac{mip}, reduces
computational complexity by decoupling the high-dimensional planning problem. A
novel MIP formulation optimizes standing position selection and trajectory
length, minimizing task completion time. Furthermore, an MPC system with
simplified kinematics and single-step position correction ensures
millimeter-level end-effector tracking accuracy. Validated through simulations
and experiments on the Kuavo 4Pro humanoid platform, the framework demonstrates
low time cost and a high success rate in multi-location tasks, enabling
efficient and precise execution of complex industrial operations.

</details>


### [1007] [A Modular AIoT Framework for Low-Latency Real-Time Robotic Teleoperation in Smart Cities](https://arxiv.org/abs/2510.11421)
*Shih-Chieh Sun,Yun-Cheng Tsai*

Main category: cs.RO

TL;DR: 该研究提出了一种用于智慧城市应用的 AI 驱动物联网远程操作系统，该系统集成了跨平台移动界面、轻量级对象检测（YOLOv11-nano）和低延迟通信（MQTT/WebRTC），实现了实时远程操控和智能视觉监控，在实际测试中，执行器响应时间低至 0.2 秒，视频延迟低于 1.2 秒。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为智慧城市应用开发一个集成人工智能的物联网远程操作系统，以实现实时远程操控和智能视觉监控，解决传统远程操作平台在模块化部署、实时感知和通信适应性方面的不足。

Method: 研究提出了一种基于 Flutter 的跨平台移动界面，结合 MQTT 控制信令和 LiveKit 框架的 WebRTC 视频流。系统集成了 YOLOv11-nano 模型进行对象检测，并通过 MQTT 将控制命令传输到 ESP8266 执行器节点，由 Arduino Mega2560 控制机器人臂运动。后端部署在 DigitalOcean 上，并评估了在不同 VPN 场景下的延迟。

Result: 研究在本地和国际 VPN 场景（包括香港、日本、比利时）下进行了延迟评估，结果显示执行器响应时间低至 0.2 秒，总视频延迟低于 1.2 秒，即使在高延迟网络下也表现出良好的性能。

Conclusion: 该系统通过低延迟双协议设计实现了响应迅速的闭环交互和分布式环境下的稳健性能，特别适用于远程基础设施检查、公共设备维护和城市自动化等智慧城市场景。未来的工作将集中在边缘设备部署、自适应路由和城市规模物联网网络集成上。

Abstract: This paper presents an AI-driven IoT robotic teleoperation system designed
for real-time remote manipulation and intelligent visual monitoring, tailored
for smart city applications. The architecture integrates a Flutter-based
cross-platform mobile interface with MQTT-based control signaling and WebRTC
video streaming via the LiveKit framework. A YOLOv11-nano model is deployed for
lightweight object detection, enabling real-time perception with annotated
visual overlays delivered to the user interface. Control commands are
transmitted via MQTT to an ESP8266-based actuator node, which coordinates
multi-axis robotic arm motion through an Arduino Mega2560 controller. The
backend infrastructure is hosted on DigitalOcean, ensuring scalable cloud
orchestration and stable global communication. Latency evaluations conducted
under both local and international VPN scenarios (including Hong Kong, Japan,
and Belgium) demonstrate actuator response times as low as 0.2 seconds and
total video latency under 1.2 seconds, even across high-latency networks. This
low-latency dual-protocol design ensures responsive closed-loop interaction and
robust performance in distributed environments. Unlike conventional
teleoperation platforms, the proposed system emphasizes modular deployment,
real-time AI sensing, and adaptable communication strategies, making it
well-suited for smart city scenarios such as remote infrastructure inspection,
public equipment servicing, and urban automation. Future enhancements will
focus on edge-device deployment, adaptive routing, and integration with
city-scale IoT networks to enhance resilience and scalability.

</details>


### [1008] [DQ-NMPC: Dual-Quaternion NMPC for Quadrotor Flight](https://arxiv.org/abs/2510.11525)
*Luis F. Recalde,Dhruv Agrawal,Jon Arrizabalaga,Guanrui Li*

Main category: cs.RO

TL;DR: 使用基于对偶四元数的新型NMPC框架（DQ-NMPC）来控制四旋翼飞行器，以提高在复杂动态环境下的控制精度。


<details>
  <summary>Details</summary>
Motivation: 四旋翼飞行器在执行复杂任务时具有巨大潜力，但其欠驱动和耦合的动力学特性使得在敏捷飞行中实现精确控制成为一项重大挑战。

Method: 提出了一种基于对偶四元数的新型NMPC框架（DQ-NMPC），将四旋翼飞行器动力学和姿态误差直接表示在对偶四元数流形上，实现了对四旋翼耦合动力学的紧凑且全局非奇异的表示。

Result: 与传统的基线NMPC方法相比，DQ-NMPC在数值条件和跟踪性能方面均有显著改善，位置和方向误差最多可减少56.11%和56.77%。该控制器还能成功处理高达13.66 m/s的速度和4.2 g的加速度的激进轨迹，并在基线控制器失效的受限空间内（11m x 4.5m x 3.65m）实现了性能。

Conclusion: 所提出的DQ-NMPC框架能够有效解决四旋翼飞行器的敏捷控制问题，并在模拟和现实世界实验中均表现出优越的性能。

Abstract: MAVs have great potential to assist humans in complex tasks, with
applications ranging from logistics to emergency response. Their agility makes
them ideal for operations in complex and dynamic environments. However,
achieving precise control in agile flights remains a significant challenge,
particularly due to the underactuated nature of quadrotors and the strong
coupling between their translational and rotational dynamics. In this work, we
propose a novel NMPC framework based on dual-quaternions (DQ-NMPC) for
quadrotor flight. By representing both quadrotor dynamics and the pose error
directly on the dual-quaternion manifold, our approach enables a compact and
globally non-singular formulation that captures the quadrotor coupled dynamics.
We validate our approach through simulations and real-world experiments,
demonstrating better numerical conditioning and significantly improved tracking
performance, with reductions in position and orientation errors of up to 56.11%
and 56.77%, compared to a conventional baseline NMPC method. Furthermore, our
controller successfully handles aggressive trajectories, reaching maximum
speeds up to 13.66 m/s and accelerations reaching 4.2 g within confined space
conditions of dimensions 11m x 4.5m x 3.65m under which the baseline controller
fails.

</details>


### [1009] [Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization](https://arxiv.org/abs/2510.11539)
*Denglin Cheng,Jiarong Kang,Xiaobin Xiong*

Main category: cs.RO

TL;DR: 该研究提出了一种双层优化框架，用于同时校准机器人状态估计中的噪声协方差和运动学参数。


<details>
  <summary>Details</summary>
Motivation: 在动态和不确定的环境中，精确的状态估计对于机器人至关重要，但过程和测量噪声协方差的指定通常是未知的或需要手动调整的。

Method: 提出了一种双层优化框架，上层优化噪声协方差和模型参数，下层执行全信息估计器。通过对估计器进行微分，可以直接优化轨迹级别的目标。

Result: 在四足和人形机器人上进行了验证，与手动调整的基线相比，估计精度和不确定性校准得到了显著提高。

Conclusion: 该方法将状态估计、传感器和运动学校准统一到一个基于数据的框架中，适用于各种机器人平台。

Abstract: Accurate state estimation is critical for legged and aerial robots operating
in dynamic, uncertain environments. A key challenge lies in specifying process
and measurement noise covariances, which are typically unknown or manually
tuned. In this work, we introduce a bi-level optimization framework that
jointly calibrates covariance matrices and kinematic parameters in an
estimator-in-the-loop manner. The upper level treats noise covariances and
model parameters as optimization variables, while the lower level executes a
full-information estimator. Differentiating through the estimator allows direct
optimization of trajectory-level objectives, resulting in accurate and
consistent state estimates. We validate our approach on quadrupedal and
humanoid robots, demonstrating significantly improved estimation accuracy and
uncertainty calibration compared to hand-tuned baselines. Our method unifies
state estimation, sensor, and kinematics calibration into a principled,
data-driven framework applicable across diverse robotic platforms.

</details>


### [1010] [NaviGait: Navigating Dynamically Feasible Gait Libraries using Deep Reinforcement Learning](https://arxiv.org/abs/2510.11542)
*Neil C. Janwani,Varun Madabushi,Maegan Tucker*

Main category: cs.RO

TL;DR: NaviGait框架结合了轨迹优化和强化学习的优点，实现了鲁棒且直观的双足行走控制。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习在奖励设计上存在困难，而基于轨迹优化的方法虽然更易于调优但泛化性不足，NaviGait旨在解决这些问题。

Method: NaviGait是一个分层框架，利用离线优化的步态库，并通过强化学习策略提供关节和速度指令的残差修正，以稳定参考轨迹。

Result: 实验结果表明，NaviGait的训练速度比传统的强化学习和模仿学习更快，并且生成的运动轨迹最接近参考轨迹。

Conclusion: NaviGait通过将高级运动生成与低级修正分离，提供了一种更具可扩展性和泛化性的方法来实现动态且鲁棒的双足行走。

Abstract: Reinforcement learning (RL) has emerged as a powerful method to learn robust
control policies for bipedal locomotion. Yet, it can be difficult to tune
desired robot behaviors due to unintuitive and complex reward design. In
comparison, offline trajectory optimization methods, like Hybrid Zero Dynamics,
offer more tuneable, interpretable, and mathematically grounded motion plans
for high-dimensional legged systems. However, these methods often remain
brittle to real-world disturbances like external perturbations.
  In this work, we present NaviGait, a hierarchical framework that combines the
structure of trajectory optimization with the adaptability of RL for robust and
intuitive locomotion control. NaviGait leverages a library of offline-optimized
gaits and smoothly interpolates between them to produce continuous reference
motions in response to high-level commands. The policy provides both
joint-level and velocity command residual corrections to modulate and stabilize
the reference trajectories in the gait library. One notable advantage of
NaviGait is that it dramatically simplifies reward design by encoding rich
motion priors from trajectory optimization, reducing the need for finely tuned
shaping terms and enabling more stable and interpretable learning. Our
experimental results demonstrate that NaviGait enables faster training compared
to conventional and imitation-based RL, and produces motions that remain
closest to the original reference. Overall, by decoupling high-level motion
generation from low-level correction, NaviGait offers a more scalable and
generalizable approach for achieving dynamic and robust locomotion.

</details>


### [1011] [Robot Soccer Kit: Omniwheel Tracked Soccer Robots for Education](https://arxiv.org/abs/2510.11552)
*Gregoire Passault,Clement Gaspard,Olivier Ly*

Main category: cs.RO

TL;DR: 教育机器人套件通过引入外部跟踪系统，解决了现有套件感知局限性，从而能够探索更高级的机器人学问题。


<details>
  <summary>Details</summary>
Motivation: 当前教育机器人套件多局限于机器人自身视角，难以解决涉及坐标和导航等更高层级的问题。

Method: 提出了一种带有外部跟踪系统的全向移动机器人套件。

Result: 该套件能够让学生探索传统教育机器人难以实现的、更高级的机器人学概念。

Conclusion: 该机器人套件通过外部跟踪系统，克服了现有教育机器人在感知方面的局限性，为探索高级机器人学概念提供了新的可能性。

Abstract: Recent developments of low cost off-the-shelf programmable components, their
modularity, and also rapid prototyping made educational robotics flourish, as
it is accessible in most schools today. They allow to illustrate and embody
theoretical problems in practical and tangible applications, and gather
multidisciplinary skills. They also give a rich natural context for
project-oriented pedagogy. However, most current robot kits all are limited to
egocentric aspect of the robots perception. This makes it difficult to access
more high-level problems involving e.g. coordinates or navigation. In this
paper we introduce an educational holonomous robot kit that comes with an
external tracking system, which lightens the constraint on embedded systems,
but allows in the same time to discover high-level aspects of robotics,
otherwise unreachable.

</details>


### [1012] [SCOOP'D: Learning Mixed-Liquid-Solid Scooping via Sim2Real Generative Policy](https://arxiv.org/abs/2510.11566)
*Kuanning Wang,Yongchong Gu,Yuqian Fu,Zeyu Shangguan,Sicheng He,Xiangyang Xue,Yanwei Fu,Daniel Seita*

Main category: cs.RO

TL;DR: 提出了一种名为 SCOOP'D 的方法，利用基于 NVIDIA Omniverse 的 OmniGibson 模拟器，通过算法程序收集舀取演示，然后使用生成策略通过扩散来模仿这些演示，并成功将其应用于各种现实世界场景。


<details>
  <summary>Details</summary>
Motivation: 开发一种通用的自主机器人舀取策略，以应对复杂的工具-物体交互和可变形物体（如颗粒介质或液体）的操作挑战。

Method: 在 OmniGibson 模拟器中使用特权状态信息收集舀取演示，然后使用基于扩散的生成策略来模仿这些演示，并将其直接应用于现实世界。

Result: 在 465 次零样本部署试验中，SCOOP'D 在不同难度级别（“1 级”和“2 级”）的各种物品数量、物品特性和容器类型方面表现出色，优于所有基线和消融方法。

Conclusion: SCOOP'D 是一种有前景的机器人舀取技能获取方法。

Abstract: Scooping items with tools such as spoons and ladles is common in daily life,
ranging from assistive feeding to retrieving items from environmental disaster
sites. However, developing a general and autonomous robotic scooping policy is
challenging since it requires reasoning about complex tool-object interactions.
Furthermore, scooping often involves manipulating deformable objects, such as
granular media or liquids, which is challenging due to their
infinite-dimensional configuration spaces and complex dynamics. We propose a
method, SCOOP'D, which uses simulation from OmniGibson (built on NVIDIA
Omniverse) to collect scooping demonstrations using algorithmic procedures that
rely on privileged state information. Then, we use generative policies via
diffusion to imitate demonstrations from observational input. We directly apply
the learned policy in diverse real-world scenarios, testing its performance on
various item quantities, item characteristics, and container types. In
zero-shot deployment, our method demonstrates promising results across 465
trials in diverse scenarios, including objects of different difficulty levels
that we categorize as "Level 1" and "Level 2." SCOOP'D outperforms all
baselines and ablations, suggesting that this is a promising approach to
acquiring robotic scooping skills. Project page is at
https://scoopdiff.github.io/.

</details>


### [1013] [Calibrated Dynamic Modeling for Force and Payload Estimation in Hydraulic Machinery](https://arxiv.org/abs/2510.11574)
*Lennart Werner,Pol Eyschen,Sean Costello,Pierluigi Micarelli,Marco Hutter*

Main category: cs.RO

TL;DR: 该研究提出了一种高精度的二维力和载荷估计算法，可用于液压挖掘机，并能实现1%的载荷精度和优于现有系统的力和载荷估算。


<details>
  <summary>Details</summary>
Motivation: 为了实现重型机械的先进自动化，需要精确估算挖掘机的末端执行器交互力和载荷。

Method: 提出了一种基于优化的动态模型辨识方法，用于在正常运行期间估算末端执行器交互力和铲斗载荷。该方法易于改装，只需少量校准，无需预先了解特定机器的动力学特性。

Result: 在25吨挖掘机上，在线力测量实现了13度的方向精度和383牛的量级精度。载荷估算精度达到1%。

Conclusion: 所提出的方法在精度和泛化能力方面优于传统的拟静态方法和市售系统，可用于挖掘机的自动化。

Abstract: Accurate real-time estimation of end effector interaction forces in hydraulic
excavators is a key enabler for advanced automation in heavy machinery.
Accurate knowledge of these forces allows improved, precise grading and digging
maneuvers. To address these challenges, we introduce a high-accuracy,
retrofittable 2D force- and payload estimation algorithm that does not impose
additional requirements on the operator regarding trajectory, acceleration or
the use of the slew joint. The approach is designed for retrofittability,
requires minimal calibration and no prior knowledge of machine-specific dynamic
characteristics. Specifically, we propose a method for identifying a dynamic
model, necessary to estimate both end effector interaction forces and bucket
payload during normal operation. Our optimization-based payload estimation
achieves a full-scale payload accuracy of 1%. On a standard 25 t excavator, the
online force measurement from pressure and inertial measurements achieves a
direction accuracy of 13 degree and a magnitude accuracy of 383 N. The method's
accuracy and generalization capability are validated on two excavator platforms
of different type and weight classes. We benchmark our payload estimation
against a classical quasistatic method and a commercially available system. Our
system outperforms both in accuracy and precision.

</details>


### [1014] [ManiAgent: An Agentic Framework for General Robotic Manipulation](https://arxiv.org/abs/2510.11660)
*Yi Yang,Kefan Gu,Yuqing Wen,Hebei Li,Yucheng Zhao,Tiancai Wang,Xudong Liu*

Main category: cs.RO

TL;DR: ManiAgent是一个用于通用机器人操作任务的智能体架构，通过多智能体协同来处理复杂的操纵场景，并在模拟和真实世界环境中取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在处理复杂推理和长时任务规划方面存在数据稀缺和模型容量的限制。

Method: ManiAgent框架采用多智能体协同机制，通过智能体间的通信，实现环境感知、子任务分解和动作生成，从而实现从任务描述和环境输入到机器人操作动作的端到端输出。

Result: ManiAgent在SimplerEnv基准测试中达到了86.8%的成功率，在真实世界的抓取和放置任务中达到了95.8%的成功率，并且通过高效的数据收集，使得VLA模型性能可与使用人类标注数据集训练的模型相媲美。

Conclusion: ManiAgent通过引入多智能体协同机制，有效解决了现有VLA模型在处理复杂推理和长时任务规划方面的局限性，并实现了高效的数据收集和模型训练。

Abstract: While Vision-Language-Action (VLA) models have demonstrated impressive
capabilities in robotic manipulation, their performance in complex reasoning
and long-horizon task planning is limited by data scarcity and model capacity.
To address this, we introduce ManiAgent, an agentic architecture for general
manipulation tasks that achieves end-to-end output from task descriptions and
environmental inputs to robotic manipulation actions. In this framework,
multiple agents involve inter-agent communication to perform environmental
perception, sub-task decomposition and action generation, enabling efficient
handling of complex manipulation scenarios. Evaluations show ManiAgent achieves
an 86.8% success rate on the SimplerEnv benchmark and 95.8% on real-world
pick-and-place tasks, enabling efficient data collection that yields VLA models
with performance comparable to those trained on human-annotated datasets.The
project webpage is available at https://yi-yang929.github.io/ManiAgent/.

</details>


### [1015] [Phys2Real: Fusing VLM Priors with Interactive Online Adaptation for Uncertainty-Aware Sim-to-Real Manipulation](https://arxiv.org/abs/2510.11689)
*Maggie Wang,Stephen Tian,Aiden Swann,Ola Shorinwa,Jiajun Wu,Mac Schwager*

Main category: cs.RO

TL;DR: 该研究提出了一种名为Phys2Real的强化学习（RL）管线，用于解决在真实世界中训练机器人操控策略的成本高昂和耗时问题。该方法结合了视觉-语言模型（VLM）推断的物理参数估计以及通过不确定性感知融合进行的交互式适应，以实现有效的仿真到现实（sim-to-real）迁移，特别是在需要精确动力学的任务中。


<details>
  <summary>Details</summary>
Motivation: 在真实世界中直接学习机器人操控策略成本高昂且耗时，而通过仿真训练的强化学习（RL）策略虽然可扩展，但在仿真到现实（sim-to-real）迁移方面仍存在挑战，尤其是在需要精确动力学的任务中。

Method: Phys2Real方法结合了三个核心部分：（1）使用3D高斯泼溅技术进行高保真几何重建；（2）利用视觉-语言模型（VLM）推断物理参数的先验分布；（3）通过交互数据在线估计物理参数。该方法将策略条件化在可解释的物理参数上，并通过基于不确定性的量化融合，利用在线估计来优化VLM的预测。

Result: 在T型块（重心可变）和平板推动任务中，Phys2Real相比于领域随机化基线取得了显著的改进：底部加权的T型块成功率从79%提高到100%；具有挑战性的顶部加权的T型块成功率从23%提高到57%；锤子推动任务的平均完成时间缩短了15%。消融研究表明，VLM和交互信息的结合对成功至关重要。

Conclusion: Phys2Real通过结合VLM推断的物理参数和在线交互数据，有效地解决了仿真到现实（sim-to-real）迁移中的动力学挑战，显著提高了机器人操控任务的成功率和效率。

Abstract: Learning robotic manipulation policies directly in the real world can be
expensive and time-consuming. While reinforcement learning (RL) policies
trained in simulation present a scalable alternative, effective sim-to-real
transfer remains challenging, particularly for tasks that require precise
dynamics. To address this, we propose Phys2Real, a real-to-sim-to-real RL
pipeline that combines vision-language model (VLM)-inferred physical parameter
estimates with interactive adaptation through uncertainty-aware fusion. Our
approach consists of three core components: (1) high-fidelity geometric
reconstruction with 3D Gaussian splatting, (2) VLM-inferred prior distributions
over physical parameters, and (3) online physical parameter estimation from
interaction data. Phys2Real conditions policies on interpretable physical
parameters, refining VLM predictions with online estimates via ensemble-based
uncertainty quantification. On planar pushing tasks of a T-block with varying
center of mass (CoM) and a hammer with an off-center mass distribution,
Phys2Real achieves substantial improvements over a domain randomization
baseline: 100% vs 79% success rate for the bottom-weighted T-block, 57% vs 23%
in the challenging top-weighted T-block, and 15% faster average task completion
for hammer pushing. Ablation studies indicate that the combination of VLM and
interaction information is essential for success. Project website:
https://phys2real.github.io/ .

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1016] [THEAS: Efficient Power Management in Multi-Core CPUs via Cache-Aware Resource Scheduling](https://arxiv.org/abs/2510.09847)
*Said Muhammad,Lahlou Laaziz,Nadjia Kara,Phat Tan Nguyen,Timothy Murphy*

Main category: cs.DC

TL;DR: 该研究提出了一种名为THEAS的动态资源调度算法，用于提高异构系统中的能源效率，同时保持必要的计算资源。


<details>
  <summary>Details</summary>
Motivation: 在计算需求波动的场景下，特别是在异构系统中，需要一种能够动态调整资源分配以平衡性能和功耗的调度方法。

Method: 部署了THEAS算法，并与CFS、EAS、HeteroSched和Utility-Based Scheduling等现有调度技术进行了比较分析，评估指标包括适应性、核心选择标准、性能扩展、缓存感知、开销和实时适用性。

Result: 通过与现有调度技术的比较分析（如表III所示），验证了THEAS算法在性能和功耗之间的平衡能力。

Conclusion: THEAS算法适用于各种实时应用，尤其是在工作负载波动大且分布不均的异构系统中。

Abstract: The dynamic adaptation of resource levels enables the system to enhance
energy efficiency while maintaining the necessary computational resources,
particularly in scenarios where workloads fluctuate significantly over time.
The proposed approach can play a crucial role in heterogeneous systems where
workload characteristics are not uniformly distributed, such as non-pinning
tasks. The deployed THEAS algorithm in this research work ensures a balance
between performance and power consumption, making it suitable for a wide range
of real-time applications. A comparative analysis of the proposed THEAS
algorithm with well-known scheduling techniques such as Completely Fair
Scheduler (CFS), Energy-Aware Scheduling (EAS), Heterogeneous Scheduling
(HeteroSched), and Utility-Based Scheduling is presented in Table III. Each
scheme is compared based on adaptability, core selection criteria, performance
scaling, cache awareness, overhead, and real-time suitability.

</details>


### [1017] [QONNECT: A QoS-Aware Orchestration System for Distributed Kubernetes Clusters](https://arxiv.org/abs/2510.09851)
*Haci Ismail Aslan,Syed Muhammad Mahmudul Haque,Joel Witzke,Odej Kao*

Main category: cs.DC

TL;DR: QONNECT是一个供应商无关的编排框架，用于跨异构Kubernetes和K3s集群进行声明式、服务质量驱动的应用程序部署。


<details>
  <summary>Details</summary>
Motivation: 现有的Kubernetes调度器无法满足能源效率、成本优化和全局性能等用户定义的目标，导致手动进行逐个集群的放置决策。

Method: QONNECT采用分布式架构，包括一个中央知识库、Raft复制的资源主代理和每个集群中的轻量级资源代理。用户通过基于YAML的界面指定高层服务质量目标，系统将其转换为放置和迁移操作。

Result: 在包含多达九个云-雾-边集群的联合测试平台上，使用Istio Bookinfo微服务应用程序进行了实现评估。该系统展示了动态的、策略驱动的微服务放置、自动故障转移、符合服务质量要求的重新调度以及节点故障后的领导者重新选举，所有这些都无需手动干预。

Conclusion: QONNECT弥合了声明式部署模型与运行时的服务质量目标之间的差距，将云-边连续体转变为统一的、自优化的平台。

Abstract: Modern applications increasingly span across cloud, fog, and edge
environments, demanding orchestration systems that can adapt to diverse
deployment contexts while meeting Quality-of-Service (QoS) requirements.
Standard Kubernetes schedulers do not account for user-defined objectives such
as energy efficiency, cost optimization, and global performance, often leaving
operators to make manual, cluster-by-cluster placement decisions. To address
this need, we present QONNECT, a vendor-agnostic orchestration framework that
enables declarative, QoS-driven application deployment across heterogeneous
Kubernetes and K3s clusters. QONNECT introduces a distributed architecture
composed of a central Knowledge Base, Raft-replicated Resource Lead Agents, and
lightweight Resource Agents in each cluster. Through a minimal YAML-based
interface, users specify high-level QoS goals, which the system translates into
concrete placement and migration actions. Our implementation is evaluated on a
federated testbed of up to nine cloud-fog-edge clusters using the Istio
Bookinfo microservice application. The system demonstrates dynamic,
policy-driven microservice placement, automated failover, QoS-compliant
rescheduling, and leader re-election after node failure, all without manual
intervention. By bridging the gap between declarative deployment models and
operational QoS goals, QONNECT transforms the cloud-edge continuum into a
unified, self-optimizing platform.

</details>


### [1018] [FedMon: Federated eBPF Monitoring for Distributed Anomaly Detection in Multi-Cluster Cloud Environments](https://arxiv.org/abs/2510.10126)
*Sehar Zehra,Hassan Jamil Syed,Ummay Faseeha*

Main category: cs.DC

TL;DR: FedMon是一个联邦式eBPF框架，用于跨集群异常检测，通过集成内核级遥测和联邦学习来解决Kubernetes多集群部署中的可扩展性和隐私问题。


<details>
  <summary>Details</summary>
Motivation: Kubernetes多集群部署需要可扩展且保护隐私的异常检测。现有的eBPF监控器受限于单集群，而集中式方法存在带宽、隐私和异构性问题。

Method: FedMon使用轻量级eBPF代理捕获系统调用和网络事件，提取本地特征，并仅与全局服务器共享模型更新。采用结合变分自编码器（VAE）和孤立森林（Isolation Forests）的混合检测引擎。

Result: 在三个Kubernetes集群上部署的FedMon实现了94%的精确率、91%的召回率和0.92的F1分数，并将带宽使用量相比集中式基线降低了60%。

Conclusion: FedMon提高了准确性、可扩展性和隐私性，为大规模、多租户的云原生环境提供了有效的防御。

Abstract: Kubernetes multi-cluster deployments demand scalable and privacy-preserving
anomaly detection. Existing eBPF-based monitors provide low-overhead system and
network visibility but are limited to single clusters, while centralized
approaches incur bandwidth, privacy, and heterogeneity challenges. We propose
FedMon, a federated eBPF framework that unifies kernel-level telemetry with
federated learning (FL) for cross-cluster anomaly detection. Lightweight eBPF
agents capture syscalls and network events, extract local statistical and
sequence features, and share only model updates with a global server. A hybrid
detection engine combining Variational Autoencoders (VAEs) with Isolation
Forests enables both temporal pattern modeling and outlier detection. Deployed
across three Kubernetes clusters, FedMon achieves 94% precision, 91% recall,
and an F1-score of 0.92, while cutting bandwidth usage by 60% relative to
centralized baselines. Results demonstrate that FedMon enhances accuracy,
scalability, and privacy, providing an effective defense for large-scale,
multi-tenant cloud-native environments.

</details>


### [1019] [Proactive and Reactive Autoscaling Techniques for Edge Computing](https://arxiv.org/abs/2510.10166)
*Suhrid Gupta,Muhammed Tawfiqul Islam,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 边缘计算通过微服务架构实现资源去中心化，但需满足低延迟和高服务水平协议（SLA）的要求。混合云和边缘环境可确保SLA合规性，但现有自动伸缩算法存在性能问题和配置复杂性。


<details>
  <summary>Details</summary>
Motivation: 为了满足边缘计算环境中低延迟和高服务水平协议（SLA）的要求，需要一种有效的资源伸缩方法。

Method: 本文概述了边缘计算架构、其用途、优势和资源伸缩方面的挑战。然后，介绍了服务水平协议（SLA）以及在边缘计算环境中用于满足这些协议的现有算法，并分析了它们的优缺点。

Result: 现有的自动伸缩算法存在性能问题和配置复杂性。

Conclusion: 混合云和边缘环境对于满足SLA至关重要，但需要更优的自动伸缩算法来解决现有方法的性能和复杂性问题。

Abstract: Edge computing allows for the decentralization of computing resources. This
decentralization is achieved through implementing microservice architectures,
which require low latencies to meet stringent service level agreements (SLA)
such as performance, reliability, and availability metrics. While cloud
computing offers the large data storage and computation resources necessary to
handle peak demands, a hybrid cloud and edge environment is required to ensure
SLA compliance. Several auto-scaling algorithms have been proposed to try to
achieve these compliance challenges, but they suffer from performance issues
and configuration complexity. This chapter provides a brief overview of edge
computing architecture, its uses, benefits, and challenges for resource
scaling. We then introduce Service Level Agreements, and existing research on
devising algorithms used in edge computing environments to meet these
agreements, along with their benefits and drawbacks.

</details>


### [1020] [SP-MoE: Speculative Decoding and Prefetching for Accelerating MoE-based Model Inference](https://arxiv.org/abs/2510.10302)
*Liangkun Chen,Zijian Wen,Tian Wu,Xiaoxi Zhang,Chuan Wu*

Main category: cs.DC

TL;DR: SP-MoE 是一种结合了专家模型（MoE）和推测性解码（SD）的框架，通过专家预取、分层预取策略和流水线运行时，显著提高了 MoE LLM 的推理速度，并减少了内存和带宽瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有 MoE 推理方法在结合推测性解码（SD）时，存在 GPU 内存膨胀和 CPU-GPU 带宽瓶颈问题，而现有的 MoE 卸载系统对此并未进行优化。

Method: SP-MoE 提出了一种 SD 感知的专家卸载和计算-通信流水线框架，包括：1. 专家预取：利用草稿模型和目标模型之间的结构相似性来提前预取专家。2. 分层预取策略：基于经验分析和延迟模型，限制每层的预取深度，实现及时可用且避免过度预取。3. 流水线运行时：使用异步预取线程和批量 I/O 来隐藏加载延迟。

Result: SP-MoE 在各种数据集、环境和 MoE 模型上，实现了比现有最先进方法高 1.07-3.5 倍的 TPOT 加速。

Conclusion: SP-MoE 是第一个 SD 感知的专家卸载和计算-通信流水线框架，有效解决了 MoE LLM 结合 SD 时的推理瓶颈，并取得了显著的性能提升。

Abstract: The Mixture-of-Experts (MoE) architecture has been widely adopted in large
language models (LLMs) to reduce computation cost through model sparsity.
Employing speculative decoding (SD) can further accelerate MoE inference by
drafting multiple tokens per step and verifying them in parallel. However,
combining MoE with SD inflates GPU memory and aggravates CPU-GPU bandwidth
contention during multi-token verification. Existing MoE offloading systems are
SD-agnostic and do not address this bottleneck. We present SP-MoE, the first
SD-aware expert-offloading and compute-communication pipelining framework.
SP-MoE introduces: (1) speculative expert prefetching that exploits structural
correspondence between the draft and target models to prefetch likely experts
ahead of verification; (2) a cutoff-layer policy that bounds per-layer prefetch
depth based on empirical profiles and an analytical latency model, guaranteeing
just-in-time availability without overfetch; and (3) a pipelined runtime with
asynchronous prefetch threads and batched I/O to hide loading latency.
Extensive experiments demonstrate that SP-MoE achieves a 1.07-3.5 times TPOT
speedup over state-of-the-art methods across diverse datasets, environments,
and MoE-based models.

</details>


### [1021] [FLAMMABLE: A Multi-Model Federated Learning Framework with Multi-Model Engagement and Adaptive Batch Sizes](https://arxiv.org/abs/2510.10380)
*Shouxu Lin,Zimeng Pan,Yuhang Yao,Haeyoung Noh,Pei Zhang,Carlee Joe-Wong*

Main category: cs.DC

TL;DR: MMFL框架FLAMMABLE通过自适应批处理大小和模型选择来优化模型训练，并在基准测试中展示了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的单模型联邦学习框架无法有效解决多模型联邦学习（MMFL）中因数据、系统和模型异构性带来的挑战。

Method: 提出名为FLAMMABLE的MMFL训练框架，通过智能调整客户端批处理大小，并根据客户端系统能力选择训练多个模型，以优化模型训练。此外，还开发了首个MMFL基准测试平台。

Result: 在多个数据集和模型上进行评估，结果显示FLAMMABLE相比现有基线，在MMFL时间-准确率性能上提升了1.1-10.0倍，最终模型准确率提升了1.3-5.4%。

Conclusion: FLAMMABLE是一个全面的MMFL训练框架，能够有效应对MMFL中的异构性挑战，并在时间和最终模型准确率方面取得显著改进。

Abstract: Multi-Model Federated Learning (MMFL) is an emerging direction in Federated
Learning (FL) where multiple models are trained in parallel, generally on
various datasets. Optimizing the models' accuracies and training times in the
MMFL setting requires adapting to data and system heterogeneity across clients
as in single-model FL; these challenges are amplified in the MMFL setting due
to additional heterogeneity across models. Neither existing solutions nor
na\"ive extensions of single-model FL frameworks efficiently address these
challenges. To bridge this gap, we propose FLAMMABLE, a comprehensive MMFL
training framework. FLAMMABLE optimizes model training by intelligently
adapting client batch sizes while engaging them to train multiple carefully
chosen models, depending on their system capabilities, in each training round.
To evaluate FLAMMABLE, we develop the first benchmark platform for the MMFL
setting, which may enable future reproducible MMFL research. Extensive
evaluations on multiple datasets and models show that FLAMMABLE boosts the MMFL
time-to-accuracy performance by 1.1$\sim$10.0$\times$ while improving the final
model accuracy by 1.3$\sim$5.4\% compared to several known baselines.

</details>


### [1022] [DCP: Addressing Input Dynamism In Long-Context Training via Dynamic Context Parallelism](https://arxiv.org/abs/2510.10620)
*Chenyu Jiang,Zhenkun Cai,Ye Tian,Zhen Jia,Yida Wang,Chuan Wu*

Main category: cs.DC

TL;DR: DCP是一个动态上下文并行训练框架，通过细粒度的块状数据和计算分区来适应可变序列特征，从而减少通信开销并提高内存和计算平衡。


<details>
  <summary>Details</summary>
Motivation: 现有的上下文并行方法依赖于静态并行化配置，忽略了训练数据中序列长度和标记之间关系（即注意力模式）的可变性，导致通信开销过大和计算失衡。

Method: DCP通过引入细粒度的块状数据和计算分区，并实现数据和计算块到设备的灵活映射，来适应可变序列特征。

Result: DCP在因果掩码下将注意力速度提高了1.19倍至2.45倍，在稀疏注意力模式下提高了2.15倍至3.77倍。端到端训练速度在因果掩码下最高提高了0.94倍至1.16倍，在稀疏掩码下最高提高了1.00倍至1.46倍。

Conclusion: DCP通过动态上下文并行有效地解决了现有方法在处理可变训练数据时的局限性，提高了训练效率。

Abstract: Context parallelism has emerged as a key technique to support long-context
training, a growing trend in generative AI for modern large models. However,
existing context parallel methods rely on static parallelization configurations
that overlook the dynamic nature of training data, specifically, the
variability in sequence lengths and token relationships (i.e., attention
patterns) across samples. As a result, these methods often suffer from
unnecessary communication overhead and imbalanced computation. In this paper,
we present DCP, a dynamic context parallel training framework that introduces
fine-grained blockwise partitioning of both data and computation. By enabling
flexible mapping of data and computation blocks to devices, DCP can adapt to
varying sequence characteristics, effectively reducing communication and
improving memory and computation balance. Micro-benchmarks demonstrate that DCP
accelerates attention by 1.19x~2.45x under causal masks and 2.15x~3.77x under
sparse attention patterns. Additionally, we observe up to 0.94x~1.16x
end-to-end training speed-up for causal masks, and 1.00x~1.46x for sparse
masks.

</details>


### [1023] [CPU-Limits kill Performance: Time to rethink Resource Control](https://arxiv.org/abs/2510.10747)
*Chirag Shetty,Sarthak Chakraborty,Hubertus Franke,Larisa Shwartz,Chandra Narayanaswami,Indranil Gupta,Saurabh Jha*

Main category: cs.DC

TL;DR: CPU-limits 会损害应用程序性能和成本，应避免在延迟敏感的应用程序中使用。


<details>
  <summary>Details</summary>
Motivation: 云原生应用程序的计算资源管理研究主要集中在设置最佳 CPU 限制，但这种方法会损害应用程序性能和成本，与普遍的看法相悖。

Method: 通过提供经验证据来论证完全避免在延迟敏感的应用程序中使用 CPU 限制的合理性。

Result: CPU 限制会对延迟敏感的应用程序产生负面影响；重新思考自动缩放和计费模式；为未来的研究开辟新途径；并确定 CPU 限制有益的特定场景（例如后台作业）。

Conclusion: CPU 限制的随意采用是由其对运营和安全目的至关重要的错误信念驱动的。因此，应避免在延迟敏感的应用程序中完全使用 CPU 限制，并重新思考自动缩放和计费模式。

Abstract: Research in compute resource management for cloud-native applications is
dominated by the problem of setting optimal CPU limits -- a fundamental OS
mechanism that strictly restricts a container's CPU usage to its specified
CPU-limits . Rightsizing and autoscaling works have innovated on
allocation/scaling policies assuming the ubiquity and necessity of CPU-limits .
We question this. Practical experiences of cloud users indicate that CPU-limits
harms application performance and costs more than it helps. These observations
are in contradiction to the conventional wisdom presented in both academic
research and industry best practices. We argue that this indiscriminate
adoption of CPU-limits is driven by erroneous beliefs that CPU-limits is
essential for operational and safety purposes. We provide empirical evidence
making a case for eschewing CPU-limits completely from latency-sensitive
applications. This prompts a fundamental rethinking of auto-scaling and billing
paradigms and opens new research avenues. Finally, we highlight specific
scenarios where CPU-limits can be beneficial if used in a well-reasoned way
(e.g. background jobs).

</details>


### [1024] [Fair Kernel-Lock-Free Claim/Release Protocol for Shared Object Access in Cooperatively Scheduled Runtimes](https://arxiv.org/abs/2510.10818)
*Kevin Chalmers,Jan Bækgaard Pedersen*

Main category: cs.DC

TL;DR: 提出了一种首个无锁、无内核锁的互斥体，该互斥体与用户模式调度程序协同工作，并通过CSP/FDR被形式化证明是FIFO公平和可线性化的。


<details>
  <summary>Details</summary>
Motivation: 为了管理对共享进程间通信通道的声明访问而设计的锁机制。

Method: 设计了一个用于进程导向语言（ProcessJ）的声明/释放协议，使用无锁队列来管理等待进程的访问，并通过CSP模型和FDR进行验证。

Result: 证明了该协议的行为类似于一个锁定的互斥体，并且具有FIFO公平性和可线性化。

Conclusion: 该研究提出了一个新颖的、可形式化验证的无锁互斥体，其公平性保证和证明方法可推广到其他协程运行时设计。

Abstract: We present the first spin-free, kernel-lock-free mutex that cooperates with
user-mode schedulers and is formally proven FIFO-fair and linearizable using
CSP/FDR. Our fairness oracle and stability-based proof method are reusable
across coroutine runtime designs. We designed the claim/release protocol for a
process-oriented language -- ProcessJ -- to manage the race for claiming shared
inter-process communication channels. Internally, we use a lock-free queue to
park waiting processes for gaining access to a shared object, such as exclusive
access to a shared channel to read from or write to. The queue ensures control
and fairness for processes wishing to access a shared resource, as the protocol
handles claim requests in the order they are inserted into the queue. We
produce CSP models of our protocol and a mutex specification, demonstrating
with FDR that our protocol behaves as a locking mutex.

</details>


### [1025] [FIDRS: A Novel Framework for Integrated Distributed Reliable Systems](https://arxiv.org/abs/2510.10833)
*Mehdi Zekriyapanah Gashti*

Main category: cs.DC

TL;DR: 提出了一个名为FIDRS的新框架，用于集成分布式和可靠的系统。


<details>
  <summary>Details</summary>
Motivation: 为了提高集成系统的满意度和性能，需要分析现有框架并提出改进。

Method: 通过分析现有框架，提出FIDRS框架，并讨论其不同阶段。在FIDRS框架中，使用了异构分布式数据库技术和RMSD算法来提高性能、响应速度、可靠性和可依赖性。最后，通过仿真比较了新框架与现有框架的结果。

Result: FIDRS框架通过使用异构分布式数据库和RMSD算法，提高了系统的效率、性能和可靠性，并解决了现有框架的一些问题。

Conclusion: FIDRS框架成功地提高了集成系统的效率、性能和可靠性，并解决了现有框架的一些问题。

Abstract: In this paper we represent a new framework for integrated distributed and
reliable systems. In the proposed framework we have used three parts to
increase Satisfaction and Performance of this framework. At first we analyze
previous frameworks related to integrated systems, then represent new proposed
framework in order to improving previous framework, and we discuss its
different phases. Finally we compare the results of simulation of the new
framework with previous ones. In FIDRS framework, the technique of
heterogeneous distributed data base is used to improve Performance and speed in
responding to users and in this way we can improve dependability and
reliability of framework simultaneously. In extraction phase of the new
framework we have used RMSD algorithm that decreases responding time in big
database. Finally by using FDIRS framework we succeeded to increase Efficiency,
Performance and reliability of integrated systems and remove some of previous
frameworks problems.

</details>


### [1026] [A Fast-Converging Decentralized Approach to the Weighted Minimum Vertex Cover Problem](https://arxiv.org/abs/2510.11697)
*Matteo Mordacchini,Emanuele Carlini,Patrizio Dazzi*

Main category: cs.DC

TL;DR: 我们提出了一种去中心化的协议来解决最小权重顶点覆盖问题，该协议仅使用本地知识并与邻居通信，具有适应性强、通信效率高、无需集中协调的优点。


<details>
  <summary>Details</summary>
Motivation: 该论文解决了在去中心化网络中计算最小权重顶点覆盖（MWVC）的问题，MWVC 是一个经典的 NP-hard 问题，在网络监控和资源放置等应用中至关重要。

Method: 提出了一种完全去中心化的协议，其中每个节点仅使用本地知识进行决策并与其邻居通信。

Result: 在真实世界和合成图上对该协议进行了评估，并与集中式和去中心化基线进行了比较。结果表明，在通信开销降低的情况下，具有可竞争的解的质量。

Conclusion: 该研究强调了在去中心化环境中计算 MWVC 的可行性。

Abstract: We address the problem of computing a Minimum Weighted Vertex Cover (MWVC) in
a decentralized network. MWVC, a classical NP-hard problem, is foundational in
applications such as network monitoring and resource placement. We propose a
fully decentralized protocol where each node makes decisions using only local
knowledge and communicates with its neighbors. The method is adaptive,
communication-efficient, and avoids centralized coordination. We evaluate the
protocol on real-world and synthetic graphs, comparing it to both centralized
and decentralized baselines. Our results demonstrate competitive solution
quality with reduced communication overhead, highlighting the feasibility of
MWVC computation in decentralized environments.

</details>


### [1027] [A Decentralized Microservice Scheduling Approach Using Service Mesh in Cloud-Edge Systems](https://arxiv.org/abs/2510.11189)
*Yangyang Wen,Paul Townend,Per-Olov Östberg,Abel Souza,Clément Courageux-Sudan*

Main category: cs.DC

TL;DR: 将服务网格 sidecar 代理作为去中心化调度器，以实现云原生环境的可扩展、低延迟协调。


<details>
  <summary>Details</summary>
Motivation: 传统的集中式调度机制在扩展到云边缘的微服务系统中面临延迟、协调开销和容错方面的挑战。

Method: 将轻量级、自主的调度逻辑嵌入到每个 sidecar 中，实现本地调度决策，无需集中控制。该方法利用了服务网格基础设施日益成熟的可编程分布式流量管理能力。

Result: 初步结果表明，该架构在响应时间和延迟方面具有可扩展性潜力，能够应对不同的请求速率。

Conclusion: 本文提出了一种新的系统级架构方向，利用服务网格 sidecar 作为去中心化调度器，以应对大规模云原生环境中微服务系统扩展带来的挑战，并提供了初步证据支持其可扩展性潜力。

Abstract: As microservice-based systems scale across the cloud-edge continuum,
traditional centralized scheduling mechanisms increasingly struggle with
latency, coordination overhead, and fault tolerance. This paper presents a new
architectural direction: leveraging service mesh sidecar proxies as
decentralized, in-situ schedulers to enable scalable, low-latency coordination
in large-scale, cloud-native environments. We propose embedding lightweight,
autonomous scheduling logic into each sidecar, allowing scheduling decisions to
be made locally without centralized control. This approach leverages the
growing maturity of service mesh infrastructures, which support programmable
distributed traffic management. We describe the design of such an architecture
and present initial results demonstrating its scalability potential in terms of
response time and latency under varying request rates. Rather than delivering a
finalized scheduling algorithm, this paper presents a system-level
architectural direction and preliminary evidence to support its scalability
potential.

</details>


### [1028] [An Explorative Study on Distributed Computing Techniques in Training and Inference of Large Language Models](https://arxiv.org/abs/2510.11211)
*Sheikh Azizul Hakim,Saem Hasan*

Main category: cs.DC

TL;DR: LLM 的分布式计算技术，包括如何使其能在消费级计算机上运行以及对三种最先进的 LLM 服务技术的比较研究。


<details>
  <summary>Details</summary>
Motivation: 鉴于当前 LLM 的巨大规模，单台计算节点难以进行训练、微调或推理，因此需要分布式计算技术来有效地利用 LLM。

Method: 研究了使 LLM 能够在消费级计算机上运行的技术，并实现了一种基于元启发式的新颖修改；同时，对三种最先进的 LLM 服务技术进行了比较研究。

Result: （摘要未提供具体结果）

Conclusion: （摘要未提供具体结论）

Abstract: Large language models (LLM) are advanced AI systems trained on extensive
textual data, leveraging deep learning techniques to understand and generate
human-like language. Today's LLMs with billions of parameters are so huge that
hardly any single computing node can train, fine-tune, or infer from them.
Therefore, several distributed computing techniques are being introduced in the
literature to properly utilize LLMs. We have explored the application of
distributed computing techniques in LLMs from two angles.
  \begin{itemize}
  \item We study the techniques that democratize the LLM, that is, how large
models can be run on consumer-grade computers. Here, we also implement a novel
metaheuristics-based modification to an existing system.
  \item We perform a comparative study on three state-of-the-art LLM serving
techniques. \end{itemize}

</details>


### [1029] [An Asynchronous Many-Task Algorithm for Unstructured $S_{N}$ Transport on Shared Memory Systems](https://arxiv.org/abs/2510.11513)
*Alex Elwood,Tom Deakin,Justin Lovegrove,Chris Nelson*

Main category: cs.DC

TL;DR: S_N 传输求解器在非结构化网格上的并行化存在扩展性挑战，本文分析了现有求解器在现代多核架构上的性能瓶颈，并提出了一种新的异步多任务（AMT）算法，该算法提高了计算性能。


<details>
  <summary>Details</summary>
Motivation: 离散纵向S_N传输求解器在非结构化网格上的扩展性是一个严峻的挑战，因为它们涉及复杂的数据依赖性、内存访问模式和高维域。

Method: 本文首先分析了现有传输求解器在现代多核架构上的共享内存并行化方案中的性能瓶颈，然后在多种计算硬件上对该求解器的性能进行了调查。随后，提出了一种新的异步多任务（AMT）算法来实现共享内存并行化，并展示了与现有方法相比计算性能的提升，并评估了性能提升的原因。

Result: 新的异步多任务（AMT）算法在计算性能上优于现有方法。

Conclusion: 本文提出的异步多任务（AMT）算法提高了S_N传输求解器在非结构化网格上的并行计算性能。

Abstract: Discrete ordinates $S_N$ transport solvers on unstructured meshes pose a
challenge to scale due to complex data dependencies, memory access patterns and
a high-dimensional domain. In this paper, we review the performance bottlenecks
within the shared memory parallelization scheme of an existing transport solver
on modern many-core architectures with high core counts. With this analysis, we
then survey the performance of this solver across a variety of compute
hardware. We then present a new Asynchronous Many-Task (AMT) algorithm for
shared memory parallelism, present results showing an increase in computational
performance over the existing method, and evaluate why performance is improved.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [1030] [A Hybrid Agent-Based and System Dynamics Framework for Modelling Project Execution and Technology Maturity in Early-Stage R&D](https://arxiv.org/abs/2510.09688)
*R. W. S. Pessoa,M. H. Næss,J. C. Bijos,C. M. Rebello,D. Colombo,L. Schnitman,I. B. R. Nogueira*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents a hybrid approach to predict the evolution of
technological maturity in R and D projects, using the oil and gas sector as an
example. Integrating System Dynamics (SD) and Agent Based Modelling (ABM)
allows the proposed multi level framework to capture uncertainties in work
effort, team size, and project duration, which influence technological
progress. While AB SD hybrid models are established in other fields, their use
in R and D remains limited. The model combines system level feedback structures
governing work phases, rework cycles, and duration with decentralised agents
such as team members, tasks, and controllers, whose interactions generate
emergent project dynamics. A base case scenario analysed early stage innovation
projects with 15 parallel tasks over 156 weeks. A comparative sequential
scenario showed an 88 percent reduction in rework duration. A second scenario
assessed mixed parallel sequential task structures with varying team sizes. In
parallel configurations, increasing team size reduced project duration and
improved task completion, with optimal results for teams of four to five
members. These findings align with empirical evidence showing that moderate
team expansion enhances coordination efficiency without excessive communication
overhead. However, larger teams may decrease performance due to communication
complexity and management delays. Overall, the model outputs and framework
align with expert understanding, supporting their validity as quantitative
tools for analysing resource allocation, scheduling efficiency, and technology
maturity progression.

</details>


### [1031] [Structured Cooperative Multi-Agent Reinforcement Learning: a Bayesian Network Perspective](https://arxiv.org/abs/2510.09937)
*Shahbaz P Qadri Syed,He Bai*

Main category: cs.MA

TL;DR: 利用贝叶斯网络和值依赖集来提高多智能体强化学习的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有 MARL 算法未能充分利用智能体间的耦合信息，导致效率和可扩展性不足。

Method: 提出一种利用智能体间耦合结构来改进无模型强化学习的系统方法。通过贝叶斯网络对合作 MARL 问题进行建模，确定了值依赖集，并基于此提出了 P-DTDE 训练范式。推导了基于 P-DTDE 的多智能体策略梯度定理，并开发了一个可扩展的 actor-critic 算法。针对密集值依赖集，提出了一种基于贝叶斯网络截断的近似方案。

Result: 理论上证明了 P-DTDE 策略梯度估计量的总方差小于 CTDE。在多仓库资源分配和多区域温度控制示例中，验证了所提出算法的效率和可扩展性。近似方案在具有大量智能体的应用中比精确值依赖集具有更快的收敛速度。

Conclusion: 所提出的基于值依赖集和 P-DTDE 范式的方法能够提高 MARL 算法的效率和可扩展性，并且近似方案在处理大规模问题时表现出更好的收敛性能。

Abstract: The empirical success of multi-agent reinforcement learning (MARL) has
motivated the search for more efficient and scalable algorithms for large scale
multi-agent systems. However, existing state-of-the-art algorithms do not fully
exploit inter-agent coupling information to develop MARL algorithms. In this
paper, we propose a systematic approach to leverage structures in the
inter-agent couplings for efficient model-free reinforcement learning. We model
the cooperative MARL problem via a Bayesian network and characterize the subset
of agents, termed as the value dependency set, whose information is required by
each agent to estimate its local action value function exactly. Moreover, we
propose a partially decentralized training decentralized execution (P-DTDE)
paradigm based on the value dependency set. We theoretically establish that the
total variance of our P-DTDE policy gradient estimator is less than the
centralized training decentralized execution (CTDE) policy gradient estimator.
We derive a multi-agent policy gradient theorem based on the P-DTDE scheme and
develop a scalable actor-critic algorithm. We demonstrate the efficiency and
scalability of the proposed algorithm on multi-warehouse resource allocation
and multi-zone temperature control examples. For dense value dependency sets,
we propose an approximation scheme based on truncation of the Bayesian network
and empirically show that it achieves a faster convergence than the exact value
dependence set for applications with a large number of agents.

</details>


### [1032] [KG-MAS: Knowledge Graph-Enhanced Multi-Agent Infrastructure for coupling physical and digital robotic environments](https://arxiv.org/abs/2510.10325)
*Walid Abdela*

Main category: cs.MA

TL;DR: KG-MAS通过中心化的知识图谱（KG）作为共享世界模型，赋能多智能体系统（MAS），以应对工业4.0中物理和数字环境异构性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的CPS集成方法（如协仿真或中间件）缺乏语义丰富性和灵活性，难以实现智能自主协调，因此需要新的解决方案。

Method: 提出了一种名为KG-MAS的基础设施，它利用中心化的知识图谱（KG）作为动态的、共享的世界模型，为多智能体系统（MAS）提供统一的语义基础。自主智能体（代表物理和数字组件）通过查询和更新KG来进行决策和信息交互。该基础设施采用模型驱动架构，支持从语义描述自动生成智能体，简化系统扩展和维护。

Result: KG-MAS通过抽象底层通信协议，提供统一的智能协调机制，解决了传统方法的局限性，实现了异构物理和数字机器人环境的耦合。

Conclusion: KG-MAS为工业4.0中的CPS提供了一个健壮、可扩展且灵活的解决方案，能够有效地处理系统异构性和复杂性，实现智能自主协调。

Abstract: The seamless integration of physical and digital environments in
Cyber-Physical Systems(CPS), particularly within Industry 4.0, presents
significant challenges stemming from system heterogeneity and complexity.
Traditional approaches often rely on rigid, data-centric solutions like
co-simulation frameworks or brittle point-to-point middleware bridges, which
lack the semantic richness and flexibility required for intelligent, autonomous
coordination. This report introduces the Knowledge Graph-Enhanced Multi-Agent
Infrastructure(KG-MAS), as resolution in addressing such limitations. KG-MAS
leverages a centralized Knowledge Graph (KG) as a dynamic, shared world model,
providing a common semantic foundation for a Multi-Agent System(MAS).
Autonomous agents, representing both physical and digital components, query
this KG for decision-making and update it with real-time state information. The
infrastructure features a model-driven architecture which facilitates the
automatic generation of agents from semantic descriptions, thereby simplifying
system extension and maintenance. By abstracting away underlying communication
protocols and providing a unified, intelligent coordination mechanism, KG-MAS
offers a robust, scalable, and flexible solution for coupling heterogeneous
physical and digital robotic environments.

</details>


### [1033] [HyperAgent: Leveraging Hypergraphs for Topology Optimization in Multi-Agent Communication](https://arxiv.org/abs/2510.10611)
*Heng Zhang,Yuling Shi,Xiaodong Gu,Zijian Zhang,Haochen You,Lubin Gan,Yilei Yuan,Jin Huang*

Main category: cs.MA

TL;DR: HyperAgent 是一个基于超图的多智能体框架，通过超边直接建模多智能体协作，并动态调整通信拓扑以适应任务复杂度，在性能和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于图的多智能体系统在群体协作建模和通信拓扑自适应性方面存在挑战，限制了其可扩展性和实用性。

Method: 提出了一种基于超图的框架 HyperAgent，使用超边表示多智能体间的直接关系，并利用超图卷积层进行信息聚合。同时，结合变分自编码器和稀疏正则化来动态调整超图拓扑。

Result: 实验表明 HyperAgent 在 GSM8K 数据集上达到了 95.07% 的准确率，同时将代币消耗减少了 25.33%，证明了其在性能和效率上的优越性。

Conclusion: 基于超图的优化方法在多智能体通信方面具有巨大潜力，能够有效解决现有方法的局限性。

Abstract: Recent advances in large language model-powered multi-agent systems have
demonstrated remarkable collective intelligence through effective
communication. However, existing approaches face two primary challenges: (i)
\textit{Ineffective group collaboration modeling}, as they rely on pairwise
edge representations in graph structures, limiting their ability to capture
relationships among multiple agents; and (ii) \textit{Limited task-adaptiveness
in communication topology design}, leading to excessive communication cost for
simple tasks and insufficient coordination for complex scenarios. These issues
restrict the scalability and practical deployment of adaptive collaboration
frameworks. To address these challenges, we propose \textbf{HyperAgent}, a
hypergraph-based framework that optimizes communication topologies and
effectively captures group collaboration patterns using direct hyperedge
representations. Unlike edge-based approaches, HyperAgent uses hyperedges to
link multiple agents within the same subtask and employs hypergraph
convolutional layers to achieve one-step information aggregation in
collaboration groups. Additionally, it incorporates a variational autoencoder
framework with sparsity regularization to dynamically adjust hypergraph
topologies based on task complexity. Experiments highlight the superiority of
HyperAgent in both performance and efficiency. For instance, on GSM8K,
HyperAgent achieves 95.07\% accuracy while reducing token consumption by
25.33\%, demonstrating the potential of hypergraph-based optimization for
multi-agent communication.

</details>


### [1034] [Fast and the Furious: Hot Starts in Pursuit-Evasion Games](https://arxiv.org/abs/2510.10830)
*Gabriel Smithline,Scott Nivison*

Main category: cs.MA

TL;DR: 提出一种结合博弈论和图神经网络的方法，用于在预先不知道逃避者位置的情况下，为追逐者找到有效的初始位置。


<details>
  <summary>Details</summary>
Motivation: 在追逐-逃避博弈中，在不知道逃避者位置的情况下，如何有效地部署追逐者是一个关键的挑战。

Method: 将追逐者配置视为战略性布局，并将其表示为图。利用多目标优化构建图特征空间，以识别帕累托最优配置。使用图卷积网络（GCN）在这些帕累托最优图上进行训练，以生成有效的初始配置（“热启动”）。

Result: 经验评估表明，与随机配置相比，GCN生成的“热启动”配置在追逐-逃避博弈中具有显著优势，能够加快逃避者生存率的下降，减少追逐者的行程距离，并增强围堵效果。

Conclusion: 所提出的结合博弈论和图神经网络的方法能够有效地为追逐者生成战略性初始配置，从而在追逐-逃避博弈中带来显著的性能提升。

Abstract: Effectively positioning pursuers in pursuit-evasion games without prior
knowledge of evader locations remains a significant challenge. A novel approach
that combines game-theoretic control theory with Graph Neural Networks is
introduced in this work. By conceptualizing pursuer configurations as strategic
arrangements and representing them as graphs, a Graph Characteristic Space is
constructed via multi-objective optimization to identify Pareto-optimal
configurations. A Graph Convolutional Network (GCN) is trained on these
Pareto-optimal graphs to generate strategically effective initial
configurations, termed "hot starts". Empirical evaluations demonstrate that the
GCN-generated hot starts provide a significant advantage over random
configurations. In scenarios considering multiple pursuers and evaders, this
method hastens the decline in evader survival rates, reduces pursuer travel
distances, and enhances containment, showcasing clear strategic benefits.

</details>


### [1035] [The Social Cost of Intelligence: Emergence, Propagation, and Amplification of Stereotypical Bias in Multi-Agent Systems](https://arxiv.org/abs/2510.10943)
*Thi-Nhung Nguyen,Linhao Luo,Thuy-Trang Vu,Dinh Phung*

Main category: cs.MA

TL;DR: 大型语言模型（LLM）的多智能体系统（MAS）研究表明，MAS比单智能体系统更容易出现刻板偏见，但特定的通信协议（如合作和辩论）可以减轻偏见的放大，而更鲁棒的底层LLM可以提高系统的稳定性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨大型语言模型（LLM）的多智能体系统（MAS）中偏见的出现和传播，因为这方面研究尚不充分。

Method: 通过模拟社会背景，让智能体代表不同的社会群体，并在各种交互和对抗场景下评估系统行为。研究了内部专业化、底层LLM和智能体间通信协议对偏见鲁棒性、传播和放大的影响。

Result: 实验表明，MAS普遍不如单智能体系统鲁棒，偏见常因群体内部偏好而早期出现。合作和辩论式的通信可以减轻偏见放大，而更鲁棒的底层LLM则能提高整体系统稳定性。

Conclusion: MAS中的偏见受到内部专业化、底层LLM和通信协议的显著影响。理解这些因素对于构建更公平、更具弹性的MAS至关重要。

Abstract: Bias in large language models (LLMs) remains a persistent challenge,
manifesting in stereotyping and unfair treatment across social groups. While
prior research has primarily focused on individual models, the rise of
multi-agent systems (MAS), where multiple LLMs collaborate and communicate,
introduces new and largely unexplored dynamics in bias emergence and
propagation. In this work, we present a comprehensive study of stereotypical
bias in MAS, examining how internal specialization, underlying LLMs and
inter-agent communication protocols influence bias robustness, propagation, and
amplification. We simulate social contexts where agents represent different
social groups and evaluate system behavior under various interaction and
adversarial scenarios. Experiments on three bias benchmarks reveal that MAS are
generally less robust than single-agent systems, with bias often emerging early
through in-group favoritism. However, cooperative and debate-based
communication can mitigate bias amplification, while more robust underlying
LLMs improve overall system stability. Our findings highlight critical factors
shaping fairness and resilience in multi-agent LLM systems.

</details>


### [1036] [Automating Structural Engineering Workflows with Large Language Model Agents](https://arxiv.org/abs/2510.11004)
*Haoran Liang,Yufa Zhou,Mohammad Talebi Kalaleh,Qipei Mei*

Main category: cs.MA

TL;DR: MASSE是一个结合大型语言模型（LLM）的通用多智能体系统，旨在自动化结构工程工作流，并已在实际案例中得到验证，显著减少了工作时间并提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 结构工程领域长期停滞不前，与LLM在复杂推理、规划和工具使用方面的最新进展形成对比，这表明LLM有潜力革新该领域。

Method: 提出MASSE，一个无需训练的基于LLM的多智能体系统，用于自动化结构工程工作流。

Result: MASSE能够自动化大多数真实的结构工程工作流，并在实际案例研究中得到验证，将专家工作量从大约两小时减少到几分钟，同时提高可靠性和准确性。

Conclusion: MASSE展示了LLM在自动化结构工程任务方面的潜力，并可在专业环境中立即部署。

Abstract: We introduce $\textbf{MASSE}$, the first Multi-Agent System for Structural
Engineering, effectively integrating large language model (LLM)-based agents
with real-world engineering workflows. Structural engineering is a fundamental
yet traditionally stagnant domain, with core workflows remaining largely
unchanged for decades despite its substantial economic impact and global market
size. Recent advancements in LLMs have significantly enhanced their ability to
perform complex reasoning, long-horizon planning, and precise tool utilization
-- capabilities well aligned with structural engineering tasks such as
interpreting design codes, executing load calculations, and verifying
structural capacities. We present a proof-of-concept showing that most
real-world structural engineering workflows can be fully automated through a
training-free LLM-based multi-agent system. MASSE enables immediate deployment
in professional environments, and our comprehensive validation on real-world
case studies demonstrates that it can reduce expert workload from approximately
two hours to mere minutes, while enhancing both reliability and accuracy in
practical engineering scenarios.

</details>


### [1037] [A Vision for Access Control in LLM-based Agent Systems](https://arxiv.org/abs/2510.11108)
*Xinfeng Li,Dong Huang,Jie Li,Hongyi Cai,Zhenhong Zhou,Wei Dong,XiaoFeng Wang,Yang Liu*

Main category: cs.MA

TL;DR: 传统的访问控制机制不足以应对LLM代理的自主性和情境复杂性，需要转向信息流治理。提出代理访问控制（AAC）框架，通过多维度情境评估和自适应响应（如内容删减、摘要、释义）来动态管理信息流，以实现可信赖的代理设计。


<details>
  <summary>Details</summary>
Motivation: 传统的、基于规则的访问控制系统在可预测的环境中运行，但对于LLM代理固有的动态信息流来说是不够的。LLM代理的自主性和情境复杂性使得传统的访问控制方法不足以应对。

Method: 提出代理访问控制（AAC）框架，包括（1）多维度情境评估，考虑身份、关系、场景和规范；（2）自适应响应制定，实现信息内容的删减、摘要和释义。

Result: AAC框架通过情境感知和动态适应，能够更有效地管理LLM代理中的信息流，超越了传统的允许/拒绝访问模式。

Conclusion: AAC框架代表了从传统的二元访问控制到更复杂的、情境感知的访问控制范式的转变，为可信赖的AI代理的设计提供了新的研究方向。

Abstract: The autonomy and contextual complexity of LLM-based agents render traditional
access control (AC) mechanisms insufficient. Static, rule-based systems
designed for predictable environments are fundamentally ill-equipped to manage
the dynamic information flows inherent in agentic interactions. This position
paper argues for a paradigm shift from binary access control to a more
sophisticated model of information governance, positing that the core challenge
is not merely about permission, but about governing the flow of information. We
introduce Agent Access Control (AAC), a novel framework that reframes AC as a
dynamic, context-aware process of information flow governance. AAC operates on
two core modules: (1) multi-dimensional contextual evaluation, which assesses
not just identity but also relationships, scenarios, and norms; and (2)
adaptive response formulation, which moves beyond simple allow/deny decisions
to shape information through redaction, summarization, and paraphrasing. This
vision, powered by a dedicated AC reasoning engine, aims to bridge the gap
between human-like nuanced judgment and scalable Al safety, proposing a new
conceptual lens for future research in trustworthy agent design.

</details>


### [1038] [Autonomous vehicles need social awareness to find optima in multi-agent reinforcement learning routing games](https://arxiv.org/abs/2510.11410)
*Anastasia Psarou,Łukasz Gorczyca,Dominik Gaweł,Rafał Kucharski*

Main category: cs.MA

TL;DR: 通过引入基于边际成本矩阵的内在奖励信号，可以显著减少自动驾驶汽车（AV）多智能体强化学习（MARL）的训练时间和提高收敛性，从而改善城市交通系统。 


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体强化学习（MARL）方法在引入自私的自动驾驶汽车（AVs）到城市交通系统中时，可能需要数年才能收敛到最优解，从而破坏交通系统。 

Method: 在奖励函数中加入基于边际成本矩阵的内在奖励信号，该信号量化了每个个体行为（路线选择）对系统（总行驶时间）的影响。 

Result: 实验表明，与基线算法相比，所提出的奖励机制能够使智能体收敛到最优解，并在玩具网络和圣阿尔努尔特真实网络中均取得成功。 

Conclusion: 社会意识（即在路线选择中考虑边际成本）可以同时改善未来城市 AV 交通系统的系统范围和个体性能。

Abstract: Previous work has shown that when multiple selfish Autonomous Vehicles (AVs)
are introduced to future cities and start learning optimal routing strategies
using Multi-Agent Reinforcement Learning (MARL), they may destabilize traffic
systems, as they would require a significant amount of time to converge to the
optimal solution, equivalent to years of real-world commuting.
  We demonstrate that moving beyond the selfish component in the reward
significantly relieves this issue. If each AV, apart from minimizing its own
travel time, aims to reduce its impact on the system, this will be beneficial
not only for the system-wide performance but also for each individual player in
this routing game.
  By introducing an intrinsic reward signal based on the marginal cost matrix,
we significantly reduce training time and achieve convergence more reliably.
Marginal cost quantifies the impact of each individual action (route-choice) on
the system (total travel time). Including it as one of the components of the
reward can reduce the degree of non-stationarity by aligning agents'
objectives. Notably, the proposed counterfactual formulation preserves the
system's equilibria and avoids oscillations.
  Our experiments show that training MARL algorithms with our novel reward
formulation enables the agents to converge to the optimal solution, whereas the
baseline algorithms fail to do so. We show these effects in both a toy network
and the real-world network of Saint-Arnoult. Our results optimistically
indicate that social awareness (i.e., including marginal costs in routing
decisions) improves both the system-wide and individual performance of future
urban systems with AVs.

</details>
