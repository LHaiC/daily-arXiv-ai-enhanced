<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 36]
- [cs.LG](#cs.LG) [Total: 63]
- [cs.RO](#cs.RO) [Total: 26]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.DC](#cs.DC) [Total: 2]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.GT](#cs.GT) [Total: 2]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 14]
- [eess.SY](#eess.SY) [Total: 15]
- [cs.ET](#cs.ET) [Total: 1]
- [cs.LO](#cs.LO) [Total: 6]
- [cs.AR](#cs.AR) [Total: 3]
- [eess.SP](#eess.SP) [Total: 10]
- [quant-ph](#quant-ph) [Total: 47]
- [cs.DS](#cs.DS) [Total: 15]
- [cs.NE](#cs.NE) [Total: 2]
- [cs.MA](#cs.MA) [Total: 1]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 19]
- [cs.AI](#cs.AI) [Total: 20]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Spatially Grounded Explanations in Vision Language Models for Document Visual Question Answering](https://arxiv.org/abs/2507.12490)
*Maximiliano Hormazábal Lagos,Héctor Cerezo-Costas,Dimosthenis Karatzas*

Main category: cs.CV

TL;DR: EaGERS is a new pipeline for DocVQA that improves accuracy and transparency without retraining.


<details>
  <summary>Details</summary>
Motivation: The paper aims to enhance transparency and reproducibility in DocVQA by introducing a novel pipeline that does not require additional model fine-tuning.

Method:  EaGERS generates natural language rationales using a vision-language model, grounds these rationales to spatial sub-regions by calculating multimodal embedding similarities over a configurable grid with majority voting, and restricts response generation to selected relevant regions in a masked image.

Result: Experiments on the DocVQA dataset show that EaGERS outperforms the base model in exact match accuracy and Average Normalized Levenshtein Similarity.

Conclusion:  EaGERS is a training-free and model-agnostic pipeline that outperforms the base model on exact match accuracy and Average Normalized Levenshtein Similarity metrics, while also enhancing transparency and reproducibility in DocVQA without additional model fine-tuning.

Abstract: We introduce EaGERS, a fully training-free and model-agnostic pipeline that
(1) generates natural language rationales via a vision language model, (2)
grounds these rationales to spatial sub-regions by computing multimodal
embedding similarities over a configurable grid with majority voting, and (3)
restricts the generation of responses only from the relevant regions selected
in the masked image. Experiments on the DocVQA dataset demonstrate that our
best configuration not only outperforms the base model on exact match accuracy
and Average Normalized Levenshtein Similarity metrics but also enhances
transparency and reproducibility in DocVQA without additional model
fine-tuning.

</details>


### [2] [MindJourney: Test-Time Scaling with World Models for Spatial Reasoning](https://arxiv.org/abs/2507.12508)
*Yuncong Yang,Jiageng Liu,Zheyuan Zhang,Siyuan Zhou,Reuben Tan,Jianwei Yang,Yilun Du,Chuang Gan*

Main category: cs.CV

TL;DR: MindJourney enhances VLM spatial reasoning by coupling them with a video diffusion world model for test-time scaling, improving performance on benchmarks like SAT without fine-tuning.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art vision-language models (VLMs) struggle with 3D spatial reasoning tasks because they perceive 2D images and lack an internal model of 3D dynamics.

Method: MindJourney is a test-time scaling framework that couples a VLM to a controllable world model based on video diffusion. The VLM generates a camera trajectory, and the world model synthesizes the corresponding view. The VLM then reasons over the multi-view evidence.

Result: MindJourney achieves over an average 8% performance boost on the SAT benchmark without fine-tuning, and also improves upon VLMs trained with reinforcement learning.

Conclusion: MindJourney

Abstract: Spatial reasoning in 3D space is central to human cognition and indispensable
for embodied tasks such as navigation and manipulation. However,
state-of-the-art vision-language models (VLMs) struggle frequently with tasks
as simple as anticipating how a scene will look after an egocentric motion:
they perceive 2D images but lack an internal model of 3D dynamics. We therefore
propose MindJourney, a test-time scaling framework that grants a VLM with this
missing capability by coupling it to a controllable world model based on video
diffusion. The VLM iteratively sketches a concise camera trajectory, while the
world model synthesizes the corresponding view at each step. The VLM then
reasons over this multi-view evidence gathered during the interactive
exploration. Without any fine-tuning, our MindJourney achieves over an average
8% performance boost on the representative spatial reasoning benchmark SAT,
showing that pairing VLMs with world models for test-time scaling offers a
simple, plug-and-play route to robust 3D reasoning. Meanwhile, our method also
improves upon the test-time inference VLMs trained through reinforcement
learning, which demonstrates the potential of our method that utilizes world
models for test-time scaling.

</details>


### [3] [Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal Large Language Models](https://arxiv.org/abs/2507.12566)
*Gen Luo,Wenhan Dou,Wenhao Li,Zhaokai Wang,Xue Yang,Changyao Tian,Hao Li,Weiyun Wang,Wenhai Wang,Xizhou Zhu,Yu Qiao,Jifeng Dai*

Main category: cs.CV

TL;DR: 作者提出了一种新颖的 Delta 调优方法和内生视觉预训练 (EViP) 来解决单体 MLLM 的优化和灾难性遗忘问题。他们介绍了 Mono-InternVL 和 Mono-InternVL-1.5 模型，后者在成本和性能上都有所改进，并在多项基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的单体 MLLM 在优化和灾难性遗忘方面存在不稳定的问题。为了解决这些挑战，作者提出了一种新颖的 Delta 调优方法，该方法将新的视觉参数空间嵌入到预训练的 LLM 中，以实现从噪声数据中稳定学习视觉知识。

Method: 作者提出了一种新颖的 Delta 调优方法，该方法将新的视觉参数空间嵌入到预训练的 LLM 中，以实现从噪声数据中稳定学习视觉知识。他们介绍了一个名为 Mono-InternVL 的先进单体 MLLM，该模型通过多模式 MoE 架构结合了视觉专家，并设计了内生视觉预训练 (EViP) 以通过渐进式学习来最大化其视觉能力。此外，他们还提出了 Mono-InternVL-1.5，这是一种更便宜、更强的单体 MLLM，具有改进的 EViP (EViP++)，该模型在推理过程中包含一个融合的 CUDA 内核来加速其 MoE 操作。

Result: Mono-InternVL 在 15 项基准测试中的 12 项上优于现有的单体 MLLM，在 OCRBench 上比 Emu3 提高了 114 分。Mono-InternVL-1.5 在保持与 Mono-InternVL 相当的多模式性能的同时，将前标记延迟降低了高达 69%。

Conclusion: Mono-InternVL-1.5 在 15 项基准测试中的广泛实验表明，其在 12 项上优于现有的单体 MLLM，并在多模式性能与仅包括前标记延迟降低高达 69% 的模块化对应物 InternVL-1.5 方面具有可比性。

Abstract: This paper focuses on monolithic Multimodal Large Language Models (MLLMs),
which integrate visual encoding and language decoding into a single model.
Existing structures and pre-training strategies for monolithic MLLMs often
suffer from unstable optimization and catastrophic forgetting. To address these
challenges, our key idea is to embed a new visual parameter space into a
pre-trained LLM, enabling stable learning of visual knowledge from noisy data
via delta tuning. Based on this principle, we first introduce Mono-InternVL, an
advanced monolithic MLLM that incorporates a set of visual experts through a
multimodal mixture-of-experts architecture. In addition, we design an
innovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize
its visual capabilities via progressive learning. Mono-InternVL achieves
competitive performance against existing MLLMs but also leads to relatively
expensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper
and stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++
introduces additional visual attention experts to Mono-InternVL-1.5 and
re-organizes the pre-training process in an efficient manner. During inference,
it includes a fused CUDA kernel to speed up its MoE operations. With these
designs, Mono-InternVL-1.5 significantly reduces training and inference costs,
while still maintaining competitive performance with Mono-InternVL. To evaluate
our approach, we conduct extensive experiments across 15 benchmarks. Results
demonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out
of 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared
to its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves
similar multimodal performance while reducing first-token latency by up to 69%.
Code and models are released at https://github.com/OpenGVLab/Mono-InternVL.

</details>


### [4] [Best Practices for Large-Scale, Pixel-Wise Crop Mapping and Transfer Learning Workflows](https://arxiv.org/abs/2507.12590)
*Judy Long,Tao Liu,Sean Alexander Woznicki,Miljana Marković,Oskar Marko,Molly Sears*

Main category: cs.CV

TL;DR: 本研究全面回顾并实验比较了像素级作物测绘工作流，发现细粒度预处理结合Transformer模型效果最佳。RF模型在特定场景下表现良好。迁移学习技术提升了适应性。样本量是选择工作流的关键因素，充足样本量下监督学习更优，不足时迁移学习是可行方案。


<details>
  <summary>Details</summary>
Motivation: 为了识别最优的监督式作物测绘工作流，并评估迁移学习技术在不同领域迁移幅度下的表现，本研究对大规模、像素级的作物测绘工作流进行了全面的回顾和实验比较。

Method: 本研究对大规模、像素级作物测绘工作流进行了全面的回顾，比较了六种广泛采用的卫星图像预处理方法和十一种监督像素级分类模型，并评估了不同训练样本量和变量组合的协同影响。同时，研究还评估了不同领域迁移幅度下的最佳迁移学习技术。实验数据来源于Landsat 8卫星，标签来自CDL可信像素和实地调查，并在五个不同的农业区域进行了评估。

Result: 研究发现，细粒度间隔预处理与Transformer模型在监督和可迁移工作流中表现最佳。RF模型在传统监督学习和直接迁移方面训练速度快且性能有竞争力。迁移学习技术提高了工作流的适应性，UDA适用于同质作物类别，微调适用于多样化场景。样本量对工作流选择至关重要，充足样本量下监督训练更优，样本量不足时，迁移学习是可行替代方案。

Conclusion: 研究结果表明，细粒度间隔预处理与Transformer模型相结合，在监督和可迁移工作流中均能实现最佳性能。RF模型在传统监督学习和直接迁移到相似领域方面，训练速度快且性能具有竞争力。此外，迁移学习技术增强了工作流的适应性，其中UDA对于同质作物类别有效，而微调在各种场景下都表现稳健。工作流的选择很大程度上取决于标记样本的可用性。当样本量充足时，监督训练通常能提供更准确、更具泛化能力的结果；当样本量低于某一阈值时，与领域迁移程度相匹配的迁移学习是实现作物测绘的可行替代方案。

Abstract: Crop mapping involves identifying and classifying crop types using spatial
data, primarily derived from remote sensing imagery. This study presents the
first comprehensive review of large-scale, pixel-wise crop mapping workflows,
encompassing both conventional supervised methods and emerging transfer
learning approaches. To identify the optimal supervised crop mapping workflows,
we conducted systematic experiments, comparing six widely adopted satellite
image-based preprocessing methods, alongside eleven supervised pixel-wise
classification models. Additionally, we assessed the synergistic impact of
varied training sample sizes and variable combinations. Moreover, we identified
optimal transfer learning techniques for different magnitudes of domain shift.
The evaluation of best methods was conducted across five diverse agricultural
sites. Landsat 8 served as the primary satellite data source. Labels come from
CDL trusted pixels and field surveys.
  Our findings reveal three key insights. First, fine-scale interval
preprocessing paired with Transformer models consistently delivered optimal
performance for both supervised and transferable workflows. RF offered rapid
training and competitive performance in conventional supervised learning and
direct transfer to similar domains. Second, transfer learning techniques
enhanced workflow adaptability, with UDA being effective for homogeneous crop
classes while fine-tuning remains robust across diverse scenarios. Finally,
workflow choice depends heavily on the availability of labeled samples. With a
sufficient sample size, supervised training typically delivers more accurate
and generalizable results. Below a certain threshold, transfer learning that
matches the level of domain shift is a viable alternative to achieve crop
mapping. Repository:
Best-Practices-for-Large-Scale-Pixel-Wise-Crop-Mapping-and-Transfer-Learning-Workflows

</details>


### [5] [CT-ScanGaze: A Dataset and Baselines for 3D Volumetric Scanpath Modeling](https://arxiv.org/abs/2507.12591)
*Trong-Thang Pham,Akash Awasthi,Saba Khan,Esteban Duran Marti,Tien-Phat Nguyen,Khoa Vo,Minh Tran,Ngoc Son Nguyen,Cuong Tran Van,Yuki Ikebe,Anh Totti Nguyen,Anh Nguyen,Zhigang Deng,Carol C. Wu,Hien Van Nguyen,Ngan Le*

Main category: cs.CV

TL;DR: 研究发布了CT-ScanGaze数据集和CT-Searcher模型，用于预测放射科医生在CT扫描中的眼动轨迹。


<details>
  <summary>Details</summary>
Motivation: 理解放射科医生在阅读CT图像时的眼动模式对于开发有效的、可解释的计算机辅助诊断系统至关重要。然而，现有的CT眼动研究因缺乏公开的数据集和CT数据固有的三维复杂性而受到限制。

Method: 研究提出了CT-ScanGaze数据集，并开发了CT-Searcher模型，一个能够处理3D CT数据并预测3D眼动轨迹（scanpath）的模型。为了预训练CT-Searcher，研究还开发了一个将2D眼动数据集转换为3D眼动数据的预处理流程。

Result: 通过在CT-ScanGaze数据集上的定性和定量评估，证明了CT-Searcher在预测3D眼动轨迹方面的有效性，并为医学影像中的3D眼动预测提供了一个全面的评估框架。

Conclusion: 该研究提出了CT-ScanGaze数据集和CT-Searcher模型，用于理解和预测放射科医生在阅读CT图像时的眼动规律，并为3D眼动预测提供了一个评估框架。

Abstract: Understanding radiologists' eye movement during Computed Tomography (CT)
reading is crucial for developing effective interpretable computer-aided
diagnosis systems. However, CT research in this area has been limited by the
lack of publicly available eye-tracking datasets and the three-dimensional
complexity of CT volumes. To address these challenges, we present the first
publicly available eye gaze dataset on CT, called CT-ScanGaze. Then, we
introduce CT-Searcher, a novel 3D scanpath predictor designed specifically to
process CT volumes and generate radiologist-like 3D fixation sequences,
overcoming the limitations of current scanpath predictors that only handle 2D
inputs. Since deep learning models benefit from a pretraining step, we develop
a pipeline that converts existing 2D gaze datasets into 3D gaze data to
pretrain CT-Searcher. Through both qualitative and quantitative evaluations on
CT-ScanGaze, we demonstrate the effectiveness of our approach and provide a
comprehensive assessment framework for 3D scanpath prediction in medical
imaging.

</details>


### [6] [NeuraLeaf: Neural Parametric Leaf Models with Shape and Deformation Disentanglement](https://arxiv.org/abs/2507.12714)
*Yang Yang,Dongni Mao,Hiroaki Santo,Yasuyuki Matsushita,Fumio Okura*

Main category: cs.CV

TL;DR: 开发了一个用于3D叶子建模的神经参数化模型NeuraLeaf，该模型能处理叶子形状的多样性和变形。


<details>
  <summary>Details</summary>
Motivation: 植物叶子的形状多样且易于变形，给叶子的三维建模和重建带来了独特的挑战。

Method: 提出了一种新颖的无骨架蒙皮模型来模拟3D变形，并创建了一个名为DeformLeaf的新3D叶子数据集。

Result: NeuraLeaf能够从丰富的2D叶子图像数据集中学习叶子的2D基本形状，并同时学习与几何对齐的纹理。

Conclusion: NeuraLeaf成功生成了具有变形的各种叶子形状，并能精确地拟合3D观测（如深度图和点云）。

Abstract: We develop a neural parametric model for 3D leaves for plant modeling and
reconstruction that are essential for agriculture and computer graphics. While
neural parametric models are actively studied for humans and animals, plant
leaves present unique challenges due to their diverse shapes and flexible
deformation. To this problem, we introduce a neural parametric model for
leaves, NeuraLeaf. Capitalizing on the fact that flattened leaf shapes can be
approximated as a 2D plane, NeuraLeaf disentangles the leaves' geometry into
their 2D base shapes and 3D deformations. This representation allows learning
from rich sources of 2D leaf image datasets for the base shapes, and also has
the advantage of simultaneously learning textures aligned with the geometry. To
model the 3D deformation, we propose a novel skeleton-free skinning model and
create a newly captured 3D leaf dataset called DeformLeaf. We show that
NeuraLeaf successfully generates a wide range of leaf shapes with deformation,
resulting in accurate model fitting to 3D observations like depth maps and
point clouds. Our implementation and dataset are available at
https://neuraleaf-yang.github.io/.

</details>


### [7] [MS-DGCNN++: A Multi-Scale Fusion Dynamic Graph Neural Network with Biological Knowledge Integration for LiDAR Tree Species Classification](https://arxiv.org/abs/2507.12602)
*Said Ohamouddou,Abdellatif El Afia,Hanaa El Afia,Raddouane Chiheb*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Tree species classification from terrestrial LiDAR point clouds is
challenging because of the complex multi-scale geometric structures in forest
environments. Existing approaches using multi-scale dynamic graph convolutional
neural networks (MS-DGCNN) employ parallel multi-scale processing, which fails
to capture the semantic relationships between the hierarchical levels of the
tree architecture. We present MS-DGCNN++, a hierarchical multiscale fusion
dynamic graph convolutional network that uses semantically meaningful feature
extraction at local, branch, and canopy scales with cross-scale information
propagation. Our method employs scale-specific feature engineering, including
standard geometric features for the local scale, normalized relative vectors
for the branch scale, and distance information for the canopy scale. This
hierarchical approach replaces uniform parallel processing with semantically
differentiated representations that are aligned with the natural tree
structure. Under the same proposed tree species data augmentation strategy for
all experiments, MS-DGCNN++ achieved an accuracy of 94.96 \% on STPCTLS,
outperforming DGCNN, MS-DGCNN, and the state-of-the-art model PPT. On
FOR-species20K, it achieves 67.25\% accuracy (6.1\% improvement compared to
MS-DGCNN). For standard 3D object recognition, our method outperformed DGCNN
and MS-DGCNN with overall accuracies of 93.15\% on ModelNet40 and 94.05\% on
ModelNet10. With lower parameters and reduced complexity compared to
state-of-the-art transformer approaches, our method is suitable for
resource-constrained applications while maintaining a competitive accuracy.
Beyond tree classification, the method generalizes to standard 3D object
recognition, establishing it as a versatile solution for diverse point cloud
processing applications. The implementation code is publicly available at
https://github.com/said-ohamouddou/MS-DGCNN2.

</details>


### [8] [Predicting Soccer Penalty Kick Direction Using Human Action Recognition](https://arxiv.org/abs/2507.12617)
*David Freire-Obregón,Oliverio J. Santana,Javier Lorenzo-Navarro,Daniel Hernández-Sosa,Modesto Castrillón-Santana*

Main category: cs.CV

TL;DR: 这是一项关于足球点球动作预测的研究，提出了一种新的数据集和一种深度学习模型，该模型能够根据球员的动作预测射门方向，并且准确率超过了人类守门员。


<details>
  <summary>Details</summary>
Motivation: 现实世界的体育场景中的动作预测（Action anticipation）应用受到可用标注数据的限制。这项工作旨在创建一个包含手动标注的足球点球数据集，以根据球员的踢球前动作预测射门方向。

Method: 提出了一种结合了人类动作识别（HAR）的特征嵌入和上下文元数据的深度学习分类器，并对二十二个骨干模型进行了评估。

Result: 在预测射门方向（左或右）方面取得了高达63.9%的准确率，优于真实守门员的判断。

Conclusion: 该数据集的价值在于其能够用于预测性动作识别，并且所提出的模型为体育预测任务提供了一个可推广的方法。

Abstract: Action anticipation has become a prominent topic in Human Action Recognition
(HAR). However, its application to real-world sports scenarios remains limited
by the availability of suitable annotated datasets. This work presents a novel
dataset of manually annotated soccer penalty kicks to predict shot direction
based on pre-kick player movements. We propose a deep learning classifier to
benchmark this dataset that integrates HAR-based feature embeddings with
contextual metadata. We evaluate twenty-two backbone models across seven
architecture families (MViTv2, MViTv1, SlowFast, Slow, X3D, I3D, C2D),
achieving up to 63.9% accuracy in predicting shot direction (left or right),
outperforming the real goalkeepers' decisions. These results demonstrate the
dataset's value for anticipatory action recognition and validate our model's
potential as a generalizable approach for sports-based predictive tasks.

</details>


### [9] [Funnel-HOI: Top-Down Perception for Zero-Shot HOI Detection](https://arxiv.org/abs/2507.12628)
*Sandipan Sarma,Agney Talwarr,Arijit Sur*

Main category: cs.CV

TL;DR: Funnel-HOI通过在编码器阶段引入HOI特定线索、使用不对称互注意力机制和创新的损失函数，改进了HOI检测，显著提高了对未见和罕见交互的检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的HOI检测器主要关注改进解码器以学习交互的纠缠或分离解释。然而，作者认为HOI特定的线索应该在编码器阶段就被预期，以获得更强的场景解释能力。该研究的动机是解决HOID中的长尾分布问题，即由于可能存在指数级的物体-动作组合，导致标记数据有限。

Method: 提出了一种名为Funnel-HOI的自上而下框架，该框架在编码器阶段就利用HOI特定的线索。采用新颖的不对称互注意力机制来利用多模态信息（包括零样本能力），以在编码器级别生成更强的交互表示。此外，设计了一种新的损失函数，该函数考虑了物体-动作的相关性，并比现有的损失函数更好地调节了错误分类的惩罚。

Result: 在HICO-DET和V-COCO数据集上进行了广泛的实验，结果表明该框架在全监督和六种零样本设置下均取得了最先进的性能，在未见和罕见的HOI类别上分别取得了高达12.4%和8.4%的提升。

Conclusion: 该研究提出了一种名为Funnel-HOI的新的自上而下的框架，通过在编码器阶段利用特定于HOI的线索来改进HOI检测。通过结合新颖的不对称互注意力机制和考虑物体-动作相关性的新损失函数，该框架在HICO-DET和V-COCO数据集上展示了最先进的性能，特别是在未见和罕见的HOI类别上取得了显著的提升。

Abstract: Human-object interaction detection (HOID) refers to localizing interactive
human-object pairs in images and identifying the interactions. Since there
could be an exponential number of object-action combinations, labeled data is
limited - leading to a long-tail distribution problem. Recently, zero-shot
learning emerged as a solution, with end-to-end transformer-based object
detectors adapted for HOID becoming successful frameworks. However, their
primary focus is designing improved decoders for learning entangled or
disentangled interpretations of interactions. We advocate that HOI-specific
cues must be anticipated at the encoder stage itself to obtain a stronger scene
interpretation. Consequently, we build a top-down framework named Funnel-HOI
inspired by the human tendency to grasp well-defined concepts first and then
associate them with abstract concepts during scene understanding. We first
probe an image for the presence of objects (well-defined concepts) and then
probe for actions (abstract concepts) associated with them. A novel asymmetric
co-attention mechanism mines these cues utilizing multimodal information
(incorporating zero-shot capabilities) and yields stronger interaction
representations at the encoder level. Furthermore, a novel loss is devised that
considers objectaction relatedness and regulates misclassification penalty
better than existing loss functions for guiding the interaction classifier.
Extensive experiments on the HICO-DET and V-COCO datasets across
fully-supervised and six zero-shot settings reveal our state-of-the-art
performance, with up to 12.4% and 8.4% gains for unseen and rare HOI
categories, respectively.

</details>


### [10] [Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos](https://arxiv.org/abs/2507.12646)
*Kaihua Chen,Tarasha Khurana,Deva Ramanan*

Main category: cs.CV

TL;DR: CogNVS是一种新的方法，用于从单视角视频合成动态场景的新视角。它结合了3D重建和2D视频修复，并且可以零样本（zero-shot）在新视频上进行训练和应用，在实验中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有技术在从单视角视频合成新视角时，要么需要耗时的测试时优化，要么在进行前馈训练时无法保持场景几何的问题。

Method: 本文提出了一种名为CogNVS的方法，该方法结合了动态3D场景重建、新视角渲染以及使用生成扩散模型对隐藏像素进行“修复”。该模型可以从2D视频中进行自我监督学习，并能对新视频进行零样本（zero-shot）应用。

Result: CogNVS在从单视角视频合成新视角方面，在动态场景下的表现优于现有的大部分方法。

Conclusion: CogNVS在动态场景下的新视角合成方面优于大多数现有技术。

Abstract: We explore novel-view synthesis for dynamic scenes from monocular videos.
Prior approaches rely on costly test-time optimization of 4D representations or
do not preserve scene geometry when trained in a feed-forward manner. Our
approach is based on three key insights: (1) covisible pixels (that are visible
in both the input and target views) can be rendered by first reconstructing the
dynamic 3D scene and rendering the reconstruction from the novel-views and (2)
hidden pixels in novel views can be "inpainted" with feed-forward 2D video
diffusion models. Notably, our video inpainting diffusion model (CogNVS) can be
self-supervised from 2D videos, allowing us to train it on a large corpus of
in-the-wild videos. This in turn allows for (3) CogNVS to be applied zero-shot
to novel test videos via test-time finetuning. We empirically verify that
CogNVS outperforms almost all prior art for novel-view synthesis of dynamic
scenes from monocular videos.

</details>


### [11] [Integrated Oculomics and Lipidomics Reveal Microvascular Metabolic Signatures Associated with Cardiovascular Health in a Healthy Cohort](https://arxiv.org/abs/2507.12663)
*Inamullah,Ernesto Elias Vidal Rosas,Imran Razzak,Shoaib Jameel*

Main category: cs.CV

TL;DR: 本研究利用深度学习分析视网膜血管和血清脂质组学数据，发现了新的心血管疾病早期风险生物标志物。


<details>
  <summary>Details</summary>
Motivation: 现有心血管疾病（CVD）风险分层方法在检测早期、无症状的病变方面存在不足。本研究旨在整合视网膜微血管特征与全面的血清脂质组学特征，以发现超越传统血脂检查的、预示CVD风险的早期无症状生物标志物。

Method: 本研究引入了一种创新的影像组学框架，利用深度学习的图像处理技术提取视网膜微血管特征，并结合超高效液相色谱-电喷雾电离-高分辨率质谱（UHPLC ESI HRMS）分析血清脂质组学数据，对健康人群进行大规模、协变量调整和分层的相关性分析。

Result: 研究发现了平均动脉宽度、血管密度与三酰甘油（TAGs）、二酰甘油（DAGs）和神经酰胺（Cers）等脂质亚类之间存在强烈的、与年龄和性别无关的相关性。这些关联提示了在代谢应激下微血管重塑的趋同机制。

Conclusion: 本研究通过结合深度学习分析的视网膜微血管特征与血清组学数据，发现了除常规血脂检查外，可用于识别心血管疾病风险的无症状生物标志物。研究结果揭示了平均动脉宽度、血管密度与三酰甘油、二酰甘油和神经酰胺等脂质亚类之间存在强相关性，表明在代谢应激下微血管重构的趋同机制。这些发现为心血管疾病的早期检测、靶向预防和个性化治疗提供了新的视角和潜在的生物标志物。

Abstract: Cardiovascular disease (CVD) remains the leading global cause of mortality,
yet current risk stratification methods often fail to detect early, subclinical
changes. Previous studies have generally not integrated retinal
microvasculature characteristics with comprehensive serum lipidomic profiles as
potential indicators of CVD risk. In this study, an innovative imaging omics
framework was introduced, combining retinal microvascular traits derived
through deep learning based image processing with serum lipidomic data to
highlight asymptomatic biomarkers of cardiovascular risk beyond the
conventional lipid panel. This represents the first large scale, covariate
adjusted and stratified correlation analysis conducted in a healthy population,
which is essential for identifying early indicators of disease. Retinal
phenotypes were quantified using automated image analysis tools, while serum
lipid profiling was performed by Ultra High Performance Liquid Chromatography
Electrospray ionization High resolution mass spectrometry (UHPLC ESI HRMS).
Strong, age- and sex-independent correlations were established, particularly
between average artery width, vessel density, and lipid subclasses such as
triacylglycerols (TAGs), diacylglycerols (DAGs), and ceramides (Cers). These
associations suggest a converging mechanism of microvascular remodeling under
metabolic stress. By linking detailed
  vascular structural phenotypes to specific lipid species, this study fills a
critical gap in the understanding of early CVD pathogenesis. This integration
not only offers a novel perspective on microvascular metabolic associations but
also presents a significant opportunity for the identification of robust,
non-invasive biomarkers. Ultimately, these findings may support improved early
detection, targeted prevention, and personalized approaches in cardiovascular
healthcare.

</details>


### [12] [From Neck to Head: Bio-Impedance Sensing for Head Pose Estimation](https://arxiv.org/abs/2507.12884)
*Mengxi Liu,Lala Shakti Swarup Ray,Sizhen Bian,Ko Watanabe,Ankur Bhatt,Joanna Sorysz,Russel Torah,Bo Zhou,Paul Lukowicz*

Main category: cs.CV

TL;DR: NeckSense是一种创新的可穿戴设备，通过颈部生物阻抗传感来跟踪头部姿态，其性能可与先进的视觉系统媲美。


<details>
  <summary>Details</summary>
Motivation: 提出NeckSense，一种新颖的可穿戴系统，用于头部姿态跟踪，以解决现有的头部跟踪技术的局限性。

Method: 提出了一种深度学习框架，将解剖学先验（包括关节约束和自然的头部旋转范围）整合到损失函数设计中，以稳健地估计头部姿态。该系统利用嵌入在轻量级项链式设计中的软干电极，通过多通道生物阻抗传感来捕获颈部周围组织动力学变化，这些变化受头部旋转和肌肉细微活动的影响。

Result: 在7名参与者身上进行了验证，使用了当前最先进的姿态估计模型作为真实情况。

Conclusion: NeckSense系统在各种头部运动中实现了25.9毫米的平均每顶点误差，证明了这种紧凑、无视线遮挡的生物阻抗可穿戴设备能够提供与目前最先进的基于视觉的方法相媲美的头部跟踪性能。

Abstract: We present NeckSense, a novel wearable system for head pose tracking that
leverages multi-channel bio-impedance sensing with soft, dry electrodes
embedded in a lightweight, necklace-style form factor. NeckSense captures
dynamic changes in tissue impedance around the neck, which are modulated by
head rotations and subtle muscle activations. To robustly estimate head pose,
we propose a deep learning framework that integrates anatomical priors,
including joint constraints and natural head rotation ranges, into the loss
function design. We validate NeckSense on 7 participants using the current SOTA
pose estimation model as ground truth. Our system achieves a mean per-vertex
error of 25.9 mm across various head movements with a leave-one-person-out
cross-validation method, demonstrating that a compact, line-of-sight-free
bio-impedance wearable can deliver head-tracking performance comparable to SOTA
vision-based methods.

</details>


### [13] [FORTRESS: Function-composition Optimized Real-Time Resilient Structural Segmentation via Kolmogorov-Arnold Enhanced Spatial Attention Networks](https://arxiv.org/abs/2507.12675)
*Christina Thrainer,Md Meftahul Ferdaus,Mahdi Abdelguerfi,Christian Guetl,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

TL;DR: FORTRESS 是一种高效的结构缺陷分割新架构，通过优化卷积和自适应网络集成，大幅减少了参数量和计算复杂度，同时提高了分割性能。


<details>
  <summary>Details</summary>
Motivation: 旨在解决自动化结构缺陷分割中对高精度和计算效率（尤其是在实时部署方面）的需求之间的关键挑战。

Method: FORTRESS 结合了深度可分离卷积和自适应 Kolmogorov-Arnold 网络（KAN）集成，通过参数优化和选择性函数组合来提高计算效率。

Result: FORTRESS 在参数量减少 91%（31M 到 2.9M）、计算复杂度减少 91%（13.7 到 1.17 GFLOPs）和推理速度提高 3 倍的同时，实现了 0.771 的 F1 分数和 0.677 的平均 IoU，优于现有方法。

Conclusion: FORTRESS 通过其创新的架构设计，在准确性和效率之间取得了优异的平衡，是资源受限环境中结构缺陷分割的实用解决方案。

Abstract: Automated structural defect segmentation in civil infrastructure faces a
critical challenge: achieving high accuracy while maintaining computational
efficiency for real-time deployment. This paper presents FORTRESS
(Function-composition Optimized Real-Time Resilient Structural Segmentation), a
new architecture that balances accuracy and speed by using a special method
that combines depthwise separable convolutions with adaptive Kolmogorov-Arnold
Network integration. FORTRESS incorporates three key innovations: a systematic
depthwise separable convolution framework achieving a 3.6x parameter reduction
per layer, adaptive TiKAN integration that selectively applies function
composition transformations only when computationally beneficial, and
multi-scale attention fusion combining spatial, channel, and KAN-enhanced
features across decoder levels. The architecture achieves remarkable efficiency
gains with 91% parameter reduction (31M to 2.9M), 91% computational complexity
reduction (13.7 to 1.17 GFLOPs), and 3x inference speed improvement while
delivering superior segmentation performance. Evaluation on benchmark
infrastructure datasets demonstrates state-of-the-art results with an F1- score
of 0.771 and a mean IoU of 0.677, significantly outperforming existing methods
including U-Net, SA-UNet, and U- KAN. The dual optimization strategy proves
essential for optimal performance, establishing FORTRESS as a robust solution
for practical structural defect segmentation in resource-constrained
environments where both accuracy and computational efficiency are paramount.
Comprehensive architectural specifications are provided in the Supplemental
Material. Source code is available at URL:
https://github.com/faeyelab/fortress-paper-code.

</details>


### [14] [SOD-YOLO: Enhancing YOLO-Based Detection of Small Objects in UAV Imagery](https://arxiv.org/abs/2507.12727)
*Peijun Wang,Jinhua Zhao*

Main category: cs.CV

TL;DR: SOD-YOLO是一个改进的YOLOv8模型，通过ASF机制、P2检测层和Soft-NMS来提升小目标检测能力，在VisDrone2019-DET数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决小目标检测的挑战性问题。

Method: 提出了一种增强的、基于YOLOv8的模型SOD-YOLO。该模型在颈部集成了ASF机制以增强多尺度特征融合，增加了一个（P2）的小目标检测层以提供更高分辨率的特征图，并采用Soft-NMS来优化置信度得分并保留真正的正例。

Result: SOD-YOLO显著提高了检测性能。

Conclusion: SOD-YOLO在VisDrone2019-DET数据集上相比基线模型mAP$_{50:95}$提升了36.1%，mAP$_{50}$提升了20.6%，是一种实用的、高效的无人机小目标检测解决方案。

Abstract: Small object detection remains a challenging problem in the field of object
detection. To address this challenge, we propose an enhanced YOLOv8-based
model, SOD-YOLO. This model integrates an ASF mechanism in the neck to enhance
multi-scale feature fusion, adds a Small Object Detection Layer (named P2) to
provide higher-resolution feature maps for better small object detection, and
employs Soft-NMS to refine confidence scores and retain true positives.
Experimental results demonstrate that SOD-YOLO significantly improves detection
performance, achieving a 36.1% increase in mAP$_{50:95}$ and 20.6% increase in
mAP$_{50}$ on the VisDrone2019-DET dataset compared to the baseline model.
These enhancements make SOD-YOLO a practical and efficient solution for small
object detection in UAV imagery. Our source code, hyper-parameters, and model
weights are available at https://github.com/iamwangxiaobai/SOD-YOLO.

</details>


### [15] [A Privacy-Preserving Semantic-Segmentation Method Using Domain-Adaptation Technique](https://arxiv.org/abs/2507.12730)
*Homare Sueyoshi,Kiyoshi Nishikawa,Hitoshi Kiya*

Main category: cs.CV

TL;DR: 提出一种用于语义分割的隐私保护方法，通过Transformer的域适应技术加密图像，在保护隐私的同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 为了在保护图像隐私的前提下，实现对用于模型训练的图像进行感知加密，并保持高语义分割精度。

Method: 提出一种利用Transformer的域适应技术来加密图像的方法，用于语义分割。

Result: 实验证明，所提出的方法在Segmentation Transformer模型上实现了与未加密模型几乎相当的语义分割精度。

Conclusion: 本方法在保持高语义分割精度的同时，实现了对训练和测试图像的感知加密。

Abstract: We propose a privacy-preserving semantic-segmentation method for applying
perceptual encryption to images used for model training in addition to test
images. This method also provides almost the same accuracy as models without
any encryption. The above performance is achieved using a domain-adaptation
technique on the embedding structure of the Vision Transformer (ViT). The
effectiveness of the proposed method was experimentally confirmed in terms of
the accuracy of semantic segmentation when using a powerful
semantic-segmentation model with ViT called Segmentation Transformer.

</details>


### [16] [Transformer-based Spatial Grounding: A Comprehensive Survey](https://arxiv.org/abs/2507.12739)
*Ijazul Haq,Muhammad Saqib,Yingjie Zhang*

Main category: cs.CV

TL;DR: 对基于Transformer的空间定位方法进行了文献综述，总结了模型、数据集、评估方法和工业应用，为研究者提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管基于Transformer模型在空间定位（将自然语言表达式与相应图像区域相关联）方面取得了显著进展，但该领域目前缺乏对现有方法、数据集使用、评估指标和工业应用性的全面概述。本研究旨在弥补这一空白，提供一个系统的文献综述。

Method: 本研究通过对2018年至2025年间关于基于Transformer的空间定位方法的文献进行系统的梳理和分析，识别出主导的模型架构、常用的数据集、广泛采用的评估指标，并着重指出了关键的方法论趋势和最佳实践。

Result: 本研究识别了主导的模型架构、常用的数据集和广泛采用的评估指标，并突出了关键的方法论趋势和最佳实践，为开发稳健、可靠且适合工业应用的空间定位模型提供了重要的见解和结构化指导。

Conclusion: 该研究对2018年至2025年基于Transformer的空间定位方法进行了系统的文献综述，强调了模型架构、数据集、评估指标和工业应用方面的关键趋势和最佳实践，为研究人员和从业者提供了宝贵的见解和指导。

Abstract: Spatial grounding, the process of associating natural language expressions
with corresponding image regions, has rapidly advanced due to the introduction
of transformer-based models, significantly enhancing multimodal representation
and cross-modal alignment. Despite this progress, the field lacks a
comprehensive synthesis of current methodologies, dataset usage, evaluation
metrics, and industrial applicability. This paper presents a systematic
literature review of transformer-based spatial grounding approaches from 2018
to 2025. Our analysis identifies dominant model architectures, prevalent
datasets, and widely adopted evaluation metrics, alongside highlighting key
methodological trends and best practices. This study provides essential
insights and structured guidance for researchers and practitioners,
facilitating the development of robust, reliable, and industry-ready
transformer-based spatial grounding models.

</details>


### [17] [Domain-Enhanced Dual-Branch Model for Efficient and Interpretable Accident Anticipation](https://arxiv.org/abs/2507.12755)
*Yanchen Guan,Haicheng Liao,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Jia Hu,Zhenning Li*

Main category: cs.CV

TL;DR: This paper presents a dual-branch framework using visual and textual data with advanced AI models (GPT-4o, Long-CLIP) for more accurate and efficient traffic accident anticipation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Developing precise and computationally efficient traffic accident anticipation systems is crucial for autonomous driving technologies to enable timely intervention and loss prevention.

Method: A dual-branch architecture is employed to integrate visual information from dashcam videos with structured textual data from accident reports. A feature aggregation method using large models (GPT-4o, Long-CLIP) and prompt engineering is utilized for multimodal input integration and actionable feedback generation.

Result: Comprehensive evaluations on DAD, CCD, and A3D datasets validate the approach's superior predictive accuracy, enhanced responsiveness, reduced computational overhead, and improved interpretability.

Conclusion: The proposed dual-branch framework integrating visual and textual data, with feature aggregation via large models and prompt engineering, achieves superior predictive accuracy, enhanced responsiveness, reduced computational overhead, and improved interpretability, setting a new benchmark for traffic accident anticipation.

Abstract: Developing precise and computationally efficient traffic accident
anticipation system is crucial for contemporary autonomous driving
technologies, enabling timely intervention and loss prevention. In this paper,
we propose an accident anticipation framework employing a dual-branch
architecture that effectively integrates visual information from dashcam videos
with structured textual data derived from accident reports. Furthermore, we
introduce a feature aggregation method that facilitates seamless integration of
multimodal inputs through large models (GPT-4o, Long-CLIP), complemented by
targeted prompt engineering strategies to produce actionable feedback and
standardized accident archives. Comprehensive evaluations conducted on
benchmark datasets (DAD, CCD, and A3D) validate the superior predictive
accuracy, enhanced responsiveness, reduced computational overhead, and improved
interpretability of our approach, thus establishing a new benchmark for
state-of-the-art performance in traffic accident anticipation.

</details>


### [18] [HairShifter: Consistent and High-Fidelity Video Hair Transfer via Anchor-Guided Animation](https://arxiv.org/abs/2507.12758)
*Wangzheng Shi,Yinglin Zheng,Yuxin Lin,Jianmin Bao,Ming Zeng,Dong Chen*

Main category: cs.CV

TL;DR: HairShifter是一种新的"Anchor Frame + Animation"框架，通过集成IHT模块和多尺度门控SPADE解码器，实现了高质量、时间连贯的视频发型迁移，并在实验中展现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决视频发型迁移中的挑战，如时间连贯性、空间保真度和动态适应性，尽管在单图像发型迁移方面已取得显著进展。

Method: 提出了一种新颖的"Anchor Frame + Animation"框架，将高质量的图像发型迁移与流畅连贯的视频动画相结合。核心是集成了一个图像发型迁移（IHT）模块以实现精确的逐帧转换，以及一个多尺度门控SPADE解码器以确保无缝的空间混合和时间连贯性。

Result: HairShifter在视频发型迁移方面实现了最先进的性能，保持了发型保真度，同时保留了非发型区域。

Conclusion: HairShifter在视频发型迁移方面取得了最先进的性能，结合了卓越的视觉质量、时间连贯性和可扩展性。该方法为基于视频的发型迁移开辟了新的途径，并在此领域建立了稳健的基准。

Abstract: Hair transfer is increasingly valuable across domains such as social media,
gaming, advertising, and entertainment. While significant progress has been
made in single-image hair transfer, video-based hair transfer remains
challenging due to the need for temporal consistency, spatial fidelity, and
dynamic adaptability. In this work, we propose HairShifter, a novel "Anchor
Frame + Animation" framework that unifies high-quality image hair transfer with
smooth and coherent video animation. At its core, HairShifter integrates a
Image Hair Transfer (IHT) module for precise per-frame transformation and a
Multi-Scale Gated SPADE Decoder to ensure seamless spatial blending and
temporal coherence. Our method maintains hairstyle fidelity across frames while
preserving non-hair regions. Extensive experiments demonstrate that HairShifter
achieves state-of-the-art performance in video hairstyle transfer, combining
superior visual quality, temporal consistency, and scalability. The code will
be publicly available. We believe this work will open new avenues for
video-based hairstyle transfer and establish a robust baseline in this field.

</details>


### [19] [Unified Medical Image Segmentation with State Space Modeling Snake](https://arxiv.org/abs/2507.12760)
*Ruicheng Zhang,Haowei Guo,Kanghui Tian,Jun Zhou,Mingliang Yan,Zeyu Zhang,Shen Zhao*

Main category: cs.CV

TL;DR: Mamba Snake 是一种基于状态空间模型的新型深度蛇形框架，通过 Mamba Evolution Block (MEB) 和双分类协同机制，有效地处理了统一医学图像分割中的多尺度结构异质性和复杂形态，并在临床评估中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 统一医学图像分割 (UMIS) 对于全面的解剖评估至关重要，但由于多尺度结构异质性而面临挑战。传统像素级方法缺乏对象级解剖洞察力和器官间关系建模能力，难以处理形态复杂性和特征冲突，从而限制了其在 UMIS 中的有效性。

Method: 提出了一种名为 Mamba Snake 的新颖深度蛇形框架，并结合了状态空间模型。该框架将多轮廓演化构建为分层状态空间图谱，以对宏观的器官间拓扑关系和微观的轮廓进行精细化建模。引入了 Mamba Evolution Block (MEB) 模块，用于蛇形视觉状态空间，以聚合时空信息，从而自适应地优化复杂的形态。此外，还集成了能量图形状先验以确保在异构数据中的鲁棒性，并利用双分类协同机制同时优化检测和分割，以解决微结构分割不足的问题。

Result: Mamba Snake 在五个临床数据集的评估中显示出优越的性能，平均 Dice 分数比现有最先进方法提高了 3%。

Conclusion: Mamba Snake 在多项临床数据集的广泛评估中表现出卓越的性能，平均 Dice 分数比最先进的方法提高了 3%，证明了其在统一医学图像分割领域的有效性。

Abstract: Unified Medical Image Segmentation (UMIS) is critical for comprehensive
anatomical assessment but faces challenges due to multi-scale structural
heterogeneity. Conventional pixel-based approaches, lacking object-level
anatomical insight and inter-organ relational modeling, struggle with
morphological complexity and feature conflicts, limiting their efficacy in
UMIS. We propose Mamba Snake, a novel deep snake framework enhanced by state
space modeling for UMIS. Mamba Snake frames multi-contour evolution as a
hierarchical state space atlas, effectively modeling macroscopic inter-organ
topological relationships and microscopic contour refinements. We introduce a
snake-specific vision state space module, the Mamba Evolution Block (MEB),
which leverages effective spatiotemporal information aggregation for adaptive
refinement of complex morphologies. Energy map shape priors further ensure
robust long-range contour evolution in heterogeneous data. Additionally, a
dual-classification synergy mechanism is incorporated to concurrently optimize
detection and segmentation, mitigating under-segmentation of microstructures in
UMIS. Extensive evaluations across five clinical datasets reveal Mamba Snake's
superior performance, with an average Dice improvement of 3\% over
state-of-the-art methods.

</details>


### [20] [Think-Before-Draw: Decomposing Emotion Semantics & Fine-Grained Controllable Expressive Talking Head Generation](https://arxiv.org/abs/2507.12761)
*Hanlei Shi,Leyuan Qu,Yu Liu,Di Gao,Yuhua Zheng,Taihao Li*

Main category: cs.CV

TL;DR: 提出Think-Before-Draw框架，通过思维链解析情感为面部肌肉运动，并用渐进式引导去噪优化微表情，在情感人头生成任务上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前文本驱动的情感人头生成方法依赖于预定义的离散情感标签，过于简化了真实面部肌肉运动的动态复杂性，导致无法实现自然的情感表达。

Method: 本研究提出了Think-Before-Draw框架，包括两个关键部分：1. 情感的深度语义解析：引入思维链（CoT）将离散的情感标签转化为生理学上可行的面部肌肉运动描述。2. 细粒度表达优化：借鉴艺术家绘画过程，提出一种渐进式引导去噪策略，采用“全局情感定位-局部肌肉控制”机制来优化生成的视频中的微表情动态。

Result: 实验结果表明，该方法在MEAD和HDTF等常用基准测试上取得了最先进的性能。此外，通过收集人像图像数据集评估了模型的零样本生成能力。

Conclusion: 该研究提出的Think-Before-Draw框架通过引入思维链（CoT）实现情感的深度语义解析，将抽象的情感标签转化为生理学上可行的面部肌肉运动描述，并采用“全局情感定位-局部肌肉控制”机制进行细粒度表达优化，实现了最先进的性能，并在MEAD和HDTF基准测试以及零样本生成能力评估中表现出色。

Abstract: Emotional talking-head generation has emerged as a pivotal research area at
the intersection of computer vision and multimodal artificial intelligence,
with its core value lying in enhancing human-computer interaction through
immersive and empathetic engagement.With the advancement of multimodal large
language models, the driving signals for emotional talking-head generation has
shifted from audio and video to more flexible text. However, current
text-driven methods rely on predefined discrete emotion label texts,
oversimplifying the dynamic complexity of real facial muscle movements and thus
failing to achieve natural emotional expressiveness.This study proposes the
Think-Before-Draw framework to address two key challenges: (1) In-depth
semantic parsing of emotions--by innovatively introducing Chain-of-Thought
(CoT), abstract emotion labels are transformed into physiologically grounded
facial muscle movement descriptions, enabling the mapping from high-level
semantics to actionable motion features; and (2) Fine-grained expressiveness
optimization--inspired by artists' portrait painting process, a progressive
guidance denoising strategy is proposed, employing a "global emotion
localization--local muscle control" mechanism to refine micro-expression
dynamics in generated videos.Our experiments demonstrate that our approach
achieves state-of-the-art performance on widely-used benchmarks, including MEAD
and HDTF. Additionally, we collected a set of portrait images to evaluate our
model's zero-shot generation capability.

</details>


### [21] [World Model-Based End-to-End Scene Generation for Accident Anticipation in Autonomous Driving](https://arxiv.org/abs/2507.12762)
*Yanchen Guan,Haicheng Liao,Chengyue Wang,Xingcheng Liu,Jiaxun Zhang,Zhenning Li*

Main category: cs.CV

TL;DR: A new framework combining generative scene augmentation and adaptive temporal reasoning is proposed to improve traffic accident anticipation for autonomous driving, addressing data scarcity and cue absence issues. It includes a video generation pipeline, a dynamic prediction model, and a new benchmark dataset, showing enhanced accuracy and lead time in experiments.


<details>
  <summary>Details</summary>
Motivation: The objective of reliable anticipation of traffic accidents for autonomous driving systems is limited by the scarcity of diverse, high-quality training data and the frequent absence of crucial object-level cues due to environmental disruptions or sensor deficiencies.

Method: The framework combines generative scene augmentation using a world model guided by domain-informed prompts to create diverse driving scenarios, and adaptive temporal reasoning through a dynamic prediction model that encodes spatio-temporal relationships using strengthened graph convolutions and dilated temporal operators.

Result: Extensive experiments on public and newly released datasets confirm the framework's effectiveness in enhancing accident anticipation accuracy and lead time.

Conclusion: The proposed framework enhances both the accuracy and lead time of accident anticipation, offering a robust solution to current data and modeling limitations in safety-critical autonomous driving applications.

Abstract: Reliable anticipation of traffic accidents is essential for advancing
autonomous driving systems. However, this objective is limited by two
fundamental challenges: the scarcity of diverse, high-quality training data and
the frequent absence of crucial object-level cues due to environmental
disruptions or sensor deficiencies. To tackle these issues, we propose a
comprehensive framework combining generative scene augmentation with adaptive
temporal reasoning. Specifically, we develop a video generation pipeline that
utilizes a world model guided by domain-informed prompts to create
high-resolution, statistically consistent driving scenarios, particularly
enriching the coverage of edge cases and complex interactions. In parallel, we
construct a dynamic prediction model that encodes spatio-temporal relationships
through strengthened graph convolutions and dilated temporal operators,
effectively addressing data incompleteness and transient visual noise.
Furthermore, we release a new benchmark dataset designed to better capture
diverse real-world driving risks. Extensive experiments on public and newly
released datasets confirm that our framework enhances both the accuracy and
lead time of accident anticipation, offering a robust solution to current data
and modeling limitations in safety-critical autonomous driving applications.

</details>


### [22] [Continuous Marine Tracking via Autonomous UAV Handoff](https://arxiv.org/abs/2507.12763)
*Heegyeong Kim,Alice James,Avishkar Seth,Endrowednes Kuantama,Jane Williamson,Yimeng Feng,Richard Han*

Main category: cs.CV

TL;DR: 本研究提出了一种自主无人机视觉系统，用于在复杂的海洋环境中实时跟踪鲨鱼。该系统通过集成的OSTrack流程和无人机交接协议，实现了高精度的跟踪和操作范围的扩展，证明了协同无人机操作在海洋跟踪任务中的可行性。


<details>
  <summary>Details</summary>
Motivation: 为了实现对海洋环境中鲨鱼的持续、实时跟踪，并克服单无人机电池续航限制，扩展操作范围。

Method: 该系统集成了机载计算机、稳定的RGB-D相机和定制训练的OSTrack流程，并通过高置信度特征匹配实现了无人机之间的目标交接协议。

Result: 在包含5200帧的鲨鱼数据集上进行了性能评估，在100赫兹的实时飞行控制下，跟踪成功率为81.9%，并且对遮挡、光照变化和背景杂波具有鲁棒性。无人机交接框架实现了82.9%的目标覆盖率。

Conclusion: 本研究展示了一个自主无人机视觉系统，能够对海洋环境中的鲨鱼进行持续、实时的跟踪。通过集成机载计算机、稳定化的RGB-D相机和定制训练的OSTrack流程，该系统在光照、遮挡和海况不佳的情况下仍能进行视觉识别。关键创新在于无人机之间的交接协议，实现了跟踪任务的无缝转移，克服了单无人机电池续航限制，扩展了操作范围。

Abstract: This paper introduces an autonomous UAV vision system for continuous,
real-time tracking of marine animals, specifically sharks, in dynamic marine
environments. The system integrates an onboard computer with a stabilised RGB-D
camera and a custom-trained OSTrack pipeline, enabling visual identification
under challenging lighting, occlusion, and sea-state conditions. A key
innovation is the inter-UAV handoff protocol, which enables seamless transfer
of tracking responsibilities between drones, extending operational coverage
beyond single-drone battery limitations. Performance is evaluated on a curated
shark dataset of 5,200 frames, achieving a tracking success rate of 81.9\%
during real-time flight control at 100 Hz, and robustness to occlusion,
illumination variation, and background clutter. We present a seamless UAV
handoff framework, where target transfer is attempted via high-confidence
feature matching, achieving 82.9\% target coverage. These results confirm the
viability of coordinated UAV operations for extended marine tracking and lay
the groundwork for scalable, autonomous monitoring.

</details>


### [23] [AnyPos: Automated Task-Agnostic Actions for Bimanual Manipulation](https://arxiv.org/abs/2507.12768)
*Hengkai Tan,Yao Feng,Xinyi Mao,Shuhe Huang,Guodong Liu,Zhongkai Hao,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: 本研究提出了 ATARA 和 AnyPos，以任务无关的方式学习机器人控制，显著提高了数据收集效率和模型性能，克服了传统方法对特定任务演示的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在复杂任务中表现出潜力，但其对特定任务的人类演示的依赖限制了泛化能力并增加了数据采集成本。本研究旨在通过任务无关动作范式来解决这些问题，以提高可扩展性、效率和成本效益。

Method: 本研究提出了一种新的任务无关动作范式，将动作执行与特定任务条件分离，并引入了 ATARA（自动化任务无关随机动作）框架来加速数据收集。为有效学习任务无关数据，引入了 AnyPos（一种具有手臂解耦估计和方向感知解码器的逆动力学模型）。还集成了一个视频条件动作验证模块。

Result: ATARA 将数据收集速度比人类遥操作提高了 30 倍以上。AnyPos-ATARA 管道在准确性方面提高了 51%，在下游任务中的成功率提高了 30-40%。

Conclusion: AnyPos-ATARA 框架在下游任务（如抓取、拾放和点击）的准确性方面提高了 51%，成功率提高了 30-40%，并结合了基于回放的视频验证。

Abstract: Vision-language-action (VLA) models have shown promise on task-conditioned
control in complex settings such as bimanual manipulation. However, the heavy
reliance on task-specific human demonstrations limits their generalization and
incurs high data acquisition costs. In this work, we present a new notion of
task-agnostic action paradigm that decouples action execution from
task-specific conditioning, enhancing scalability, efficiency, and
cost-effectiveness. To address the data collection challenges posed by this
paradigm -- such as low coverage density, behavioral redundancy, and safety
risks -- we introduce ATARA (Automated Task-Agnostic Random Actions), a
scalable self-supervised framework that accelerates collection by over $
30\times $ compared to human teleoperation. To further enable effective
learning from task-agnostic data, which often suffers from distribution
mismatch and irrelevant trajectories, we propose AnyPos, an inverse dynamics
model equipped with Arm-Decoupled Estimation and a Direction-Aware Decoder
(DAD). We additionally integrate a video-conditioned action validation module
to verify the feasibility of learned policies across diverse manipulation
tasks. Extensive experiments show that the AnyPos-ATARA pipeline yields a 51%
improvement in test accuracy and achieves 30-40% higher success rates in
downstream tasks such as lifting, pick-and-place, and clicking, using
replay-based video validation. Project Page:
https://embodiedfoundation.github.io/vidar_anypos

</details>


### [24] [Local Representative Token Guided Merging for Text-to-Image Generation](https://arxiv.org/abs/2507.12771)
*Min-Jeong Lee,Hee-Dong Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: ReToM是一种新的令牌合并策略，用于图像生成中的注意力机制，通过局部代表性令牌合并来提高效率和图像质量。


<details>
  <summary>Details</summary>
Motivation: Stable Diffusion等文本到图像生成模型由于注意力操作的二次复杂度，生成过程耗时。现有的令牌合并方法虽然提高了效率，但忽视了生成模型的特点，限制了其有效性。

Method: ReToM通过在注意力输入中定义局部边界（窗口）并调整窗口大小来合并基于各种上下文信息的令牌。它通过在特定时间步计算相似度并选择具有最高平均相似度的令牌来引入代表性令牌，以代表每个窗口中的最代表性令牌，从而在保持视觉质量的同时最小化计算开销。

Result: ReToM在FID上提高了6.2%，CLIP得分更高，同时保持了可比的推理时间，有效平衡了视觉质量和计算效率。

Conclusion: ReToM

Abstract: Stable diffusion is an outstanding image generation model for text-to-image,
but its time-consuming generation process remains a challenge due to the
quadratic complexity of attention operations. Recent token merging methods
improve efficiency by reducing the number of tokens during attention
operations, but often overlook the characteristics of attention-based image
generation models, limiting their effectiveness. In this paper, we propose
local representative token guided merging (ReToM), a novel token merging
strategy applicable to any attention mechanism in image generation. To merge
tokens based on various contextual information, ReToM defines local boundaries
as windows within attention inputs and adjusts window sizes. Furthermore, we
introduce a representative token, which represents the most representative
token per window by computing similarity at a specific timestep and selecting
the token with the highest average similarity. This approach preserves the most
salient local features while minimizing computational overhead. Experimental
results show that ReToM achieves a 6.2% improvement in FID and higher CLIP
scores compared to the baseline, while maintaining comparable inference time.
We empirically demonstrate that ReToM is effective in balancing visual quality
and computational efficiency.

</details>


### [25] [Compact Vision Transformer by Reduction of Kernel Complexity](https://arxiv.org/abs/2507.12780)
*Yancheng Wang,Yingzhen Yang*

Main category: cs.CV

TL;DR: KCR-Transformer 通过通道选择降低了 vision transformer 的计算成本，同时保持了准确性，并在实验中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 vision transformer 计算成本高的问题，并提高其效率，同时保持或提高其预测精度。

Method: 提出了一种名为 KCR-Transformer 的紧凑型 transformer 块，该模块在 MLP 层中进行输入/输出通道选择，以降低计算成本。其通道剪枝过程由新颖的理论泛化界限指导，确保了网络具有可证明的小泛化误差。

Result: KCR-Transformer 成功地减少了 vision transformer 的 FLOPs 和参数数量，同时保持或提高了预测精度。在各种计算机视觉任务上，使用 KCR-Transformer 替换原始 vision transformer 块的网络（KCR-Transformers）取得了优于原始模型的性能。

Conclusion: KCR-Transformer 是一种新颖的紧凑型 transformer 块，通过可微分通道选择和理论泛化界限指导，减少了计算成本，同时保持甚至提高了预测精度。该方法兼容现有的 vision transformer，并在各种计算机视觉任务中取得了优于原始模型的性能。

Abstract: Self-attention and transformer architectures have become foundational
components in modern deep learning. Recent efforts have integrated transformer
blocks into compact neural architectures for computer vision, giving rise to
various efficient vision transformers. In this work, we introduce Transformer
with Kernel Complexity Reduction, or KCR-Transformer, a compact transformer
block equipped with differentiable channel selection, guided by a novel and
sharp theoretical generalization bound. KCR-Transformer performs input/output
channel selection in the MLP layers of transformer blocks to reduce the
computational cost. Furthermore, we provide a rigorous theoretical analysis
establishing a tight generalization bound for networks equipped with
KCR-Transformer blocks. Leveraging such strong theoretical results, the channel
pruning by KCR-Transformer is conducted in a generalization-aware manner,
ensuring that the resulting network retains a provably small generalization
error. Our KCR-Transformer is compatible with many popular and compact
transformer networks, such as ViT and Swin, and it reduces the FLOPs of the
vision transformers while maintaining or even improving the prediction
accuracy. In the experiments, we replace all the transformer blocks in the
vision transformers with KCR-Transformer blocks, leading to KCR-Transformer
networks with different backbones. The resulting TCR-Transformers achieve
superior performance on various computer vision tasks, achieving even better
performance than the original models with even less FLOPs and parameters.

</details>


### [26] [City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning](https://arxiv.org/abs/2507.12795)
*Penglei Sun,Yaoxian Song,Xiangru Zhu,Xiang Liu,Qiang Wang,Yue Liu,Changqun Xia,Tiefeng Li,Yang Yang,Xiaowen Chu*

Main category: cs.CV

TL;DR: 研究者构建了SVM-City数据集和City-VLM模型，解决了现有LVLMs在室外大规模场景理解中的多视角、多模态融合及多域感知不足的问题，并在三个任务上平均性能提升超过18%。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉-语言模型（LVLMs）主要关注室内场景理解，在应用于室外大规模场景理解时存在两大局限：1）室外场景通常涉及更大范围的环境、多视角（如鸟瞰图和地面视角）以及多种传感器，而现有模型主要分析单视角的室内场景；2）现有模型缺乏多域感知室外数据，并且难以有效融合2D和3D视觉信息。

Method: 研究者构建了一个包含420k图像和4,811M点云，以及567k问答对的SVM-City数据集，该数据集涵盖了车辆、低空无人机、高空飞机和卫星等多种视角和模态。在此基础上，提出了City-VLM模型，利用不完整的模态学习来处理缺失的模态信息，并通过构建联合概率分布空间来实现多模态数据的融合，而非直接进行显式融合操作（如拼接）。

Result: 在三个典型的室外场景理解任务上，City-VLM的平均性能比现有LVLMs高出18.14%。该模型在多个室外场景中展现了实用的性能和泛化能力。

Conclusion: 现有的视觉-语言模型在处理大规模室外场景理解时存在局限性，主要体现在无法有效融合多视角、多模态数据以及在多域感知方面的不足。为了解决这些问题，研究者构建了一个名为SVM-City的大规模室外场景理解数据集，并提出了一个名为City-VLM的视觉-语言模型。该模型通过不完整的模态学习和联合概率分布空间来融合多模态数据，在三个典型的室外场景理解任务中，平均性能比现有模型高出18.14%，证明了其在多场景下的实用性和泛化能力。

Abstract: Scene understanding enables intelligent agents to interpret and comprehend
their environment. While existing large vision-language models (LVLMs) for
scene understanding have primarily focused on indoor household tasks, they face
two significant limitations when applied to outdoor large-scale scene
understanding. First, outdoor scenarios typically encompass larger-scale
environments observed through various sensors from multiple viewpoints (e.g.,
bird view and terrestrial view), while existing indoor LVLMs mainly analyze
single visual modalities within building-scale contexts from humanoid
viewpoints. Second, existing LVLMs suffer from missing multidomain perception
outdoor data and struggle to effectively integrate 2D and 3D visual
information. To address the aforementioned limitations, we build the first
multidomain perception outdoor scene understanding dataset, named
\textbf{\underline{SVM-City}}, deriving from multi\textbf{\underline{S}}cale
scenarios with multi\textbf{\underline{V}}iew and
multi\textbf{\underline{M}}odal instruction tuning data. It contains $420$k
images and $4, 811$M point clouds with $567$k question-answering pairs from
vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To
effectively fuse the multimodal data in the absence of one modality, we
introduce incomplete multimodal learning to model outdoor scene understanding
and design the LVLM named \textbf{\underline{City-VLM}}. Multimodal fusion is
realized by constructing a joint probabilistic distribution space rather than
implementing directly explicit fusion operations (e.g., concatenation).
Experimental results on three typical outdoor scene understanding tasks show
City-VLM achieves $18.14 \%$ performance surpassing existing LVLMs in
question-answering tasks averagely. Our method demonstrates pragmatic and
generalization performance across multiple outdoor scenes.

</details>


### [27] [DeQA-Doc: Adapting DeQA-Score to Document Image Quality Assessment](https://arxiv.org/abs/2507.12796)
*Junjie Gao,Runze Liu,Yingzhe Peng,Shujian Yang,Jin Zhang,Kai Yang,Zhiyuan You*

Main category: cs.CV

TL;DR: 本研究提出了 DeQA-Doc，一个基于 MLLM 的文档质量评估框架，通过软标签策略和放宽分辨率限制来改进评估精度和泛化能力，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文档质量评估方法在准确性和鲁棒性方面存在不足，限制了其在实际场景中的应用。本研究旨在利用多模态大语言模型（MLLM）的进展，将其在图像质量评估方面的成功经验扩展到文档领域。

Method: DeQA-Doc 框架利用 MLLM 的视觉语言能力和软标签策略来回归连续的文档质量分数。为了使 DeQA-Score 适应 DeQA-Doc，我们采用了两种互补的解决方案来构建软标签（不含方差信息）。此外，我们放宽了分辨率限制以支持文档图像的大分辨率。最后，我们引入了集成方法来进一步提升性能。

Result: DeQA-Doc 框架能够提供准确且泛化的文档质量评估，并且在各种降质类型的文档上均优于现有基线方法。

Conclusion: DeQA-Doc 框架在各种文档质量评估任务中显著优于现有基线，能够准确且泛化地评估各种降质类型的文档质量。

Abstract: Document quality assessment is critical for a wide range of applications
including document digitization, OCR, and archival. However, existing
approaches often struggle to provide accurate and robust quality scores,
limiting their applicability in practical scenarios. With the rapid progress in
Multi-modal Large Language Models (MLLMs), recent MLLM-based methods have
achieved remarkable performance in image quality assessment. In this work, we
extend this success to the document domain by adapting DeQA-Score, a
state-of-the-art MLLM-based image quality scorer, for document quality
assessment. We propose DeQA-Doc, a framework that leverages the visual language
capabilities of MLLMs and a soft label strategy to regress continuous document
quality scores. To adapt DeQA-Score to DeQA-Doc, we adopt two complementary
solutions to construct soft labels without the variance information. Also, we
relax the resolution constrains to support the large resolution of document
images. Finally, we introduce ensemble methods to further enhance the
performance. Extensive experiments demonstrate that DeQA-Doc significantly
outperforms existing baselines, offering accurate and generalizable document
quality assessment across diverse degradation types. Codes and model weights
are available in https://github.com/Junjie-Gao19/DeQA-Doc.

</details>


### [28] [ATL-Diff: Audio-Driven Talking Head Generation with Early Landmarks-Guide Noise Diffusion](https://arxiv.org/abs/2507.12804)
*Hoang-Son Vo,Quang-Vinh Nguyen,Seungwon Kim,Hyung-Jeong Yang,Soonja Yeom,Soo-Hyung Kim*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Audio-driven talking head generation requires precise synchronization between
facial animations and audio signals. This paper introduces ATL-Diff, a novel
approach addressing synchronization limitations while reducing noise and
computational costs. Our framework features three key components: a Landmark
Generation Module converting audio to facial landmarks, a Landmarks-Guide Noise
approach that decouples audio by distributing noise according to landmarks, and
a 3D Identity Diffusion network preserving identity characteristics.
Experiments on MEAD and CREMA-D datasets demonstrate that ATL-Diff outperforms
state-of-the-art methods across all metrics. Our approach achieves near
real-time processing with high-quality animations, computational efficiency,
and exceptional preservation of facial nuances. This advancement offers
promising applications for virtual assistants, education, medical
communication, and digital platforms. The source code is available at:
\href{https://github.com/sonvth/ATL-Diff}{https://github.com/sonvth/ATL-Diff}

</details>


### [29] [Semantic-guided Fine-tuning of Foundation Model for Long-tailed Visual Recognition](https://arxiv.org/abs/2507.12807)
*Yufei Peng,Yonggang Zhang,Yiu-ming Cheung*

Main category: cs.CV

TL;DR: Sage通过结合文本语义和分布校正来改进长尾识别。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法在长尾学习中，虽然利用了预训练模型强大的泛化表示能力，但通常只调整视觉编码器，忽略了文本编码器提供的语义信息，导致视觉和文本模态对齐不足。此外，现有损失函数未能处理类别条件分布不一致的问题，导致即使在多模态对齐增强后，尾部类别的性能提升也小于头部类别。

Method: 提出了一种名为Sage的新方法，该方法包括一个SG-Adapter，将类别描述作为语义引导来指导视觉编码器的微调，并通过注意力机制增强了视觉和文本模态的一致性。同时，提出了一种分布不匹配感知补偿因子，用于纠正由类别条件分布不一致引起的预测偏差。

Result: Sage在长尾学习的基准数据集上的广泛实验证明了其有效性，显著提升了长尾识别性能。

Conclusion: Sage通过将文本模态的语义引导整合到视觉微调过程中，并引入了一个新的、能识别并补偿分布不匹配的因子，在长尾识别任务上取得了显著的性能提升。

Abstract: The variance in class-wise sample sizes within long-tailed scenarios often
results in degraded performance in less frequent classes. Fortunately,
foundation models, pre-trained on vast open-world datasets, demonstrate strong
potential for this task due to their generalizable representation, which
promotes the development of adaptive strategies on pre-trained models in
long-tailed learning. Advanced fine-tuning methods typically adjust visual
encoders while neglecting the semantics derived from the frozen text encoder,
overlooking the visual and textual alignment. To strengthen this alignment, we
propose a novel approach, Semantic-guided fine-tuning of foundation model for
long-tailed visual recognition (Sage), which incorporates semantic guidance
derived from textual modality into the visual fine-tuning process.
Specifically, we introduce an SG-Adapter that integrates class descriptions as
semantic guidance to guide the fine-tuning of the visual encoder. The
introduced guidance is passesed through the attention mechanism and enables the
model to focus more on semantically relevant content, strengthening the
alignment between the visual and textual modalities. Due to the inconsistent
class-conditional distributions neglected by the existing loss function, the
resulting prediction bias causes performance improvements for the tail class
less than for the head class, even when the multi-modal alignment is enhanced.
To address this challenge, we propose a novel distribution mismatch-aware
compensation factor, which is specifically designed to rectify the prediction
bias caused by the ignored inconsistent distribution based on our theoretical
analysis, and is seamlessly integrated into the loss function. Extensive
experiments on benchmark datasets demonstrate the effectiveness of the proposed
Sage in enhancing performance in long-tailed learning.

</details>


### [30] [FIQ: Fundamental Question Generation with the Integration of Question Embeddings for Video Question Answering](https://arxiv.org/abs/2507.12816)
*Ju-Young Oh,Ho-Joong Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: FIQ通过生成基础问答对和整合视觉特征来改进视频问答，提升了模型的推理能力和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频问答方法主要依赖事件中心性的问答对进行训练，这不足以捕捉视频的广泛上下文，限制了模型的泛化能力和推理能力。

Method: FIQ方法通过生成问答对来丰富训练数据，并引入VQ-CAlign模块将问题嵌入与视觉特征相结合，以增强模型的泛化能力和推理能力。

Result: FIQ在SUTD-TrafficQA数据集上取得了最先进的性能，证明了其在增强视频理解和推理方面的有效性。

Conclusion: FIQ通过生成基于视频描述的基础问答对来增强视频问答模型的推理能力，并在SUTD-TrafficQA数据集上实现了最先进的性能。

Abstract: Video question answering (VQA) is a multimodal task that requires the
interpretation of a video to answer a given question. Existing VQA methods
primarily utilize question and answer (Q&A) pairs to learn the spatio-temporal
characteristics of video content. However, these annotations are typically
event-centric, which is not enough to capture the broader context of each
video. The absence of essential details such as object types, spatial layouts,
and descriptive attributes restricts the model to learning only a fragmented
scene representation. This issue limits the model's capacity for generalization
and higher-level reasoning. In this paper, we propose a fundamental question
generation with the integration of question embeddings for video question
answering (FIQ), a novel approach designed to strengthen the reasoning ability
of the model by enhancing the fundamental understanding of videos. FIQ
generates Q&A pairs based on descriptions extracted from videos, enriching the
training data with fundamental scene information. Generated Q&A pairs enable
the model to understand the primary context, leading to enhanced
generalizability and reasoning ability. Furthermore, we incorporate a VQ-CAlign
module that assists task-specific question embeddings with visual features,
ensuring that essential domain-specific details are preserved to increase the
adaptability of downstream tasks. Experiments on SUTD-TrafficQA demonstrate
that our FIQ achieves state-of-the-art performance compared to existing
baseline methods.

</details>


### [31] [MCoT-RE: Multi-Faceted Chain-of-Thought and Re-Ranking for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2507.12819)
*Jeong-Woo Park,Seong-Whan Lee*

Main category: cs.CV

TL;DR: MCoT-RE是一种新的无训练零样本组合图像检索框架，通过生成两个标题（一个侧重修改，一个侧重视觉上下文）并结合重排策略，提高了检索精度，并在FashionIQ和CIRR数据集上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现有的无训练零样本组合图像检索方法存在局限性：基于VLM-LLM的顺序流水线会丢失信息并限制跨模态交互；而基于MLLM的方法则过分关注文本修改，未能充分利用参考图像的视觉上下文。

Method: 提出了一种名为多方面思维链结合重排（MCoT-RE）的无训练零样本组合图像检索框架。该框架利用多方面思维链引导多模态大语言模型（MLLM）生成两个不同的标题：一个侧重于修改，另一个整合了全面的视觉-文本上下文。首先使用第一个标题过滤候选图像，然后结合两个标题和参考图像进行多粒度重排，以平衡修改指示和视觉上下文。

Result: MCoT-RE在FashionIQ数据集上的Recall@10提升了6.24%，在CIRR数据集上的Recall@1提升了8.58%，在无训练零样本方法中达到了最先进的水平。

Conclusion: MCoT-RE框架通过结合修改提示和视觉上下文，实现了最先进的无训练零样本组合图像检索性能，在FashionIQ和CIRR数据集上分别取得了显著的性能提升。

Abstract: Composed Image Retrieval (CIR) is the task of retrieving a target image from
a gallery using a composed query consisting of a reference image and a
modification text. Among various CIR approaches, training-free zero-shot
methods based on pre-trained models are cost-effective but still face notable
limitations. For example, sequential VLM-LLM pipelines process each modality
independently, which often results in information loss and limits cross-modal
interaction. In contrast, methods based on multimodal large language models
(MLLMs) often focus exclusively on applying changes indicated by the text,
without fully utilizing the contextual visual information from the reference
image. To address these issues, we propose multi-faceted Chain-of-Thought with
re-ranking (MCoT-RE), a training-free zero-shot CIR framework. MCoT-RE utilizes
multi-faceted Chain-of-Thought to guide the MLLM to balance explicit
modifications and contextual visual cues, generating two distinct captions: one
focused on modification and the other integrating comprehensive visual-textual
context. The first caption is used to filter candidate images. Subsequently, we
combine these two captions and the reference image to perform multi-grained
re-ranking. This two-stage approach facilitates precise retrieval by aligning
with the textual modification instructions while preserving the visual context
of the reference image. Through extensive experiments, MCoT-RE achieves
state-of-the-art results among training-free methods, yielding improvements of
up to 6.24% in Recall@10 on FashionIQ and 8.58% in Recall@1 on CIRR.

</details>


### [32] [FAR-Net: Multi-Stage Fusion Network with Enhanced Semantic Alignment and Adaptive Reconciliation for Composed Image Retrieval](https://arxiv.org/abs/2507.12823)
*Jeong-Woo Park,Young-Eun Kim,Seong-Whan Lee*

Main category: cs.CV

TL;DR: FAR-Net通过结合ESAM（晚期融合、交叉注意力）和ARM（早期融合、不确定性嵌入）来解决图像检索中的视觉-文本融合问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理视觉和文本融合时，早期融合过分关注文本细节而忽略视觉上下文，晚期融合难以捕捉图像区域和文本标记之间的细粒度语义对齐。为了解决这些问题，提出FAR-Net来增强语义对齐和自适应协调。

Method: 提出了一种名为FAR-Net的多阶段融合框架，包含增强语义对齐模块（ESAM）和自适应协调模块（ARM）。ESAM采用晚期融合和交叉注意力机制来捕捉细粒度的语义关系，而ARM采用早期融合和不确定性嵌入来增强鲁棒性和适应性。

Result: 在CIRR和FashionIQ数据集上的实验结果显示，FAR-Net相比现有最先进的方法，在Recall@1上最高提升了2.4%，在Recall@50上最高提升了1.04%。

Conclusion: FAR-Net通过多阶段融合框架，在CIRR和FashionIQ数据集上取得了显著的性能提升，验证了其在CIR任务上的鲁棒性和可扩展性。

Abstract: Composed image retrieval (CIR) is a vision language task that retrieves a
target image using a reference image and modification text, enabling intuitive
specification of desired changes. While effectively fusing visual and textual
modalities is crucial, existing methods typically adopt either early or late
fusion. Early fusion tends to excessively focus on explicitly mentioned textual
details and neglect visual context, whereas late fusion struggles to capture
fine-grained semantic alignments between image regions and textual tokens. To
address these issues, we propose FAR-Net, a multi-stage fusion framework
designed with enhanced semantic alignment and adaptive reconciliation,
integrating two complementary modules. The enhanced semantic alignment module
(ESAM) employs late fusion with cross-attention to capture fine-grained
semantic relationships, while the adaptive reconciliation module (ARM) applies
early fusion with uncertainty embeddings to enhance robustness and
adaptability. Experiments on CIRR and FashionIQ show consistent performance
gains, improving Recall@1 by up to 2.4% and Recall@50 by 1.04% over existing
state-of-the-art methods, empirically demonstrating that FAR Net provides a
robust and scalable solution to CIR tasks.

</details>


### [33] [Feature-Enhanced TResNet for Fine-Grained Food Image Classification](https://arxiv.org/abs/2507.12828)
*Lulu Liu,Zhiyong Xiao*

Main category: cs.CV

TL;DR: FE-TResNet, based on TResNet and integrating StyleRM and DCA, improves fine-grained food image classification accuracy on ChineseFoodNet and CNFOOD-241 datasets.


<details>
  <summary>Details</summary>
Motivation: Existing Convolutional Neural Networks (CNNs) face significant challenges when dealing with fine-grained food images that are similar in shape but subtle in detail. The need for accurate classification of food images has grown, which is crucial for a variety of application scenarios.

Method: The FE-TResNet method is based on the TResNet model and integrates Style-based Recalibration Module (StyleRM) and Deep Channel-wise Attention (DCA) technologies to enhance feature extraction capabilities.

Result: In experimental validation on Chinese food image datasets ChineseFoodNet and CNFOOD-241, the FE-TResNet method significantly improved classification accuracy, achieving rates of 81.37% and 80.29%, respectively, demonstrating its effectiveness and superiority in fine-grained food image classification.

Conclusion: 该研究 presented an innovative method for classifying food images, named Feature-Enhanced TResNet (FE-TResNet), which integrates Style-based Recalibration Module (StyleRM) and Deep Channel-wise Attention (DCA) technologies to enhance feature extraction capabilities.

Abstract: Food is not only a core component of humans' daily diets, but also an
important carrier of cultural heritage and emotional bonds. With the
development of technology, the need for accurate classification of food images
has grown, which is crucial for a variety of application scenarios. However,
existing Convolutional Neural Networks (CNNs) face significant challenges when
dealing with fine-grained food images that are similar in shape but subtle in
detail. To address this challenge, this study presents an innovative method for
classifying food images, named Feature-Enhanced TResNet (FE-TResNet),
specifically designed to address fine-grained food images and accurately
capture subtle features within them. The FE-TResNet method is based on the
TResNet model and integrates Style-based Recalibration Module (StyleRM) and
Deep Channel-wise Attention (DCA) technologies to enhance feature extraction
capabilities. In experimental validation on Chinese food image datasets
ChineseFoodNet and CNFOOD-241, the FE-TResNet method significantly improved
classification accuracy, achieving rates of 81.37% and 80.29%, respectively,
demonstrating its effectiveness and superiority in fine-grained food image
classification.

</details>


### [34] [DINO-VO: A Feature-based Visual Odometry Leveraging a Visual Foundation Model](https://arxiv.org/abs/2507.13145)
*Maulana Bisyir Azhari,David Hyunchul Shim*

Main category: cs.CV

TL;DR: A novel visual odometry system, DINO-VO, uses the DINOv2 foundation model with a specialized keypoint detector and geometric features for robust and accurate camera motion estimation, outperforming existing methods and running efficiently.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenges of robustness, generalization, and efficiency in learning-based monocular visual odometry (VO), aiming to leverage the advancements of visual foundation models like DINOv2 despite their coarse feature granularity limitations for VO integration.

Method: DINO-VO utilizes DINOv2's visual foundation model for sparse feature matching, incorporating a novel salient keypoints detector tailored for DINOv2's coarse features and complementing them with fine-grained geometric features. A transformer-based matcher and a differentiable pose estimation layer are employed for precise camera motion estimation.

Result: DINO-VO shows improved robustness in challenging environments compared to SuperPoint, and enhanced accuracy and generalization of its feature descriptors over standalone DINOv2 features. It achieves superior performance on the TartanAir and KITTI datasets, is competitive on EuRoC, and demonstrates efficient execution at 72 FPS with low memory usage, performing competitively against Visual SLAM systems in outdoor driving.

Conclusion: DINO-VO surpasses previous feature-based VO methods in robustness and accuracy, demonstrating competitive performance against SLAM systems in real-world scenarios and achieving efficient operation.

Abstract: Learning-based monocular visual odometry (VO) poses robustness,
generalization, and efficiency challenges in robotics. Recent advances in
visual foundation models, such as DINOv2, have improved robustness and
generalization in various vision tasks, yet their integration in VO remains
limited due to coarse feature granularity. In this paper, we present DINO-VO, a
feature-based VO system leveraging DINOv2 visual foundation model for its
sparse feature matching. To address the integration challenge, we propose a
salient keypoints detector tailored to DINOv2's coarse features. Furthermore,
we complement DINOv2's robust-semantic features with fine-grained geometric
features, resulting in more localizable representations. Finally, a
transformer-based matcher and differentiable pose estimation layer enable
precise camera motion estimation by learning good matches. Against prior
detector-descriptor networks like SuperPoint, DINO-VO demonstrates greater
robustness in challenging environments. Furthermore, we show superior accuracy
and generalization of the proposed feature descriptors against standalone
DINOv2 coarse features. DINO-VO outperforms prior frame-to-frame VO methods on
the TartanAir and KITTI datasets and is competitive on EuRoC dataset, while
running efficiently at 72 FPS with less than 1GB of memory usage on a single
GPU. Moreover, it performs competitively against Visual SLAM systems on outdoor
driving scenarios, showcasing its generalization capabilities.

</details>


### [35] [MVA 2025 Small Multi-Object Tracking for Spotting Birds Challenge: Dataset, Methods, and Results](https://arxiv.org/abs/2507.12832)
*Yuki Kondo,Norimichi Ukita,Riku Kanayama,Yuki Yoshida,Takayuki Yamaguchi,Xiang Yu,Guang Liang,Xinyao Liu,Guan-Zhang Wang,Wei-Ta Chu,Bing-Cheng Chuang,Jia-Hua Lee,Pin-Tseng Kuo,I-Hsuan Chu,Yi-Shein Hsiao,Cheng-Han Wu,Po-Yi Wu,Jui-Chien Tsou,Hsuan-Chi Liu,Chun-Yi Lee,Yuan-Fu Yang,Kosuke Shigematsu,Asuka Shin,Ba Tran*

Main category: cs.CV

TL;DR: 该论文提出了SMOT4SB挑战赛，引入了SMOT4SB数据集和SO-HOTA评估指标，以改进无人机场景下的SMOT，并在MVA2025挑战赛中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 针对小目标跟踪（SMOT）在目标仅占几十个像素时面临的挑战，以及单帧检测的局限性，利用时序信息来解决这些问题。

Method: 提出了一种名为SO-HOTA的新型评估指标，该指标结合了点距离和HOTA，以减小基于IoU的指标对微小位移的敏感性。

Result: 创建了SMOT4SB数据集，包含211个无人机视频序列和108,192帧带注释的帧，涵盖了多样化的真实世界条件。在一个有78名参与者和308次提交的MVA2025挑战赛中，获胜方法比基线方法取得了5.1倍的改进。

Conclusion: 该研究为无人机场景下的SMOT奠定了基础，并在避免鸟击、农业、渔业和生态监测等领域具有应用前景。

Abstract: Small Multi-Object Tracking (SMOT) is particularly challenging when targets
occupy only a few dozen pixels, rendering detection and appearance-based
association unreliable. Building on the success of the MVA2023 SOD4SB
challenge, this paper introduces the SMOT4SB challenge, which leverages
temporal information to address limitations of single-frame detection. Our
three main contributions are: (1) the SMOT4SB dataset, consisting of 211 UAV
video sequences with 108,192 annotated frames under diverse real-world
conditions, designed to capture motion entanglement where both camera and
targets move freely in 3D; (2) SO-HOTA, a novel metric combining Dot Distance
with HOTA to mitigate the sensitivity of IoU-based metrics to small
displacements; and (3) a competitive MVA2025 challenge with 78 participants and
308 submissions, where the winning method achieved a 5.1x improvement over the
baseline. This work lays a foundation for advancing SMOT in UAV scenarios with
applications in bird strike avoidance, agriculture, fisheries, and ecological
monitoring.

</details>


### [36] [SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models](https://arxiv.org/abs/2507.13152)
*Xiangyu Dong,Haoran Zhao,Jiang Gao,Haozhou Li,Xiaoguang Ma,Yaoming Zhou,Fuhai Chen,Juan Liu*

Main category: cs.CV

TL;DR: 本研究提出了一种名为SE-VLN的自进化视觉语言导航框架，它利用层次化记忆、检索增强推理和反思模块，使VLN代理能够在测试期间持续进化，克服了现有方法知识固定的局限性。实验证明SE-VLN在导航成功率上取得了显著的提升，并展示了其作为可进化代理框架的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大语言模型（LLMs）的VLN方法虽然在指令理解和任务推理方面表现优异，但受限于LLMs固定的知识库和推理能力，无法充分融入经验知识，导致进化能力不足。

Method: 提出了一种名为SE-VLN的自进化视觉语言导航（VLN）框架，该框架包含三个核心模块：1. 层次化记忆模块，用于将成功和失败的案例转化为可复用的知识；2. 检索增强型思维推理模块，用于检索经验并实现多步决策；3. 反思模块，用于实现持续进化。

Result: SE-VLN在R2R和REVERSE数据集上的导航成功率分别为57%和35.2%，分别比现有最先进方法有23.9%和15.0%的绝对性能提升。此外，SE-VLN的性能随经验库的增加而提高。

Conclusion: SE-VLN框架在R2R和REVERSE数据集上分别实现了57%和35.2%的导航成功率，显著优于现有最先进方法，并且随着经验库的增长，性能有所提升，展示了其作为VLN自进化代理框架的巨大潜力。

Abstract: Recent advances in vision-language navigation (VLN) were mainly attributed to
emerging large language models (LLMs). These methods exhibited excellent
generalization capabilities in instruction understanding and task reasoning.
However, they were constrained by the fixed knowledge bases and reasoning
abilities of LLMs, preventing fully incorporating experiential knowledge and
thus resulting in a lack of efficient evolutionary capacity. To address this,
we drew inspiration from the evolution capabilities of natural agents, and
proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the
ability to continuously evolve during testing. To the best of our knowledge, it
was the first time that an multimodal LLM-powered self-evolving VLN framework
was proposed. Specifically, SE-VLN comprised three core modules, i.e., a
hierarchical memory module to transfer successful and failure cases into
reusable knowledge, a retrieval-augmented thought-based reasoning module to
retrieve experience and enable multi-step decision-making, and a reflection
module to realize continual evolution. Comprehensive tests illustrated that the
SE-VLN achieved navigation success rates of 57% and 35.2% in unseen
environments, representing absolute performance improvements of 23.9% and 15.0%
over current state-of-the-art methods on R2R and REVERSE datasets,
respectively. Moreover, the SE-VLN showed performance improvement with
increasing experience repository, elucidating its great potential as a
self-evolving agent framework for VLN.

</details>


### [37] [AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning](https://arxiv.org/abs/2507.12841)
*Yiming Ren,Zhiqiang Lin,Yu Li,Gao Meng,Weiyun Wang,Junjie Wang,Zicheng Lin,Jifeng Dai,Yujiu Yang,Wenhai Wang,Ruihang Chu*

Main category: cs.CV

TL;DR: 该研究提出了AnyCap项目，包括一个名为ACM的轻量级框架，可增强现有模型的可控图像描述能力，并发布了一个名为ACD的新数据集和名为AnyCapEval的新评估基准，旨在解决现有方法的不足并取得显著的改进。


<details>
  <summary>Details</summary>
Motivation: 现有的可控图像描述模型在细粒度控制和评估方面存在不足。为了解决这一差距，该研究提出了AnyCap项目，旨在提供一个集成的解决方案，包括模型、数据集和评估方法。

Method: 该研究提出了AnyCap项目，包括AnyCap模型（ACM）、AnyCap数据集（ACD）和AnyCapEval评估基准。ACM是一个轻量级的框架，可以通过融合用户指令和模态特征来增强现有基础模型在全模态图像描述方面的可控性，而无需重新训练。ACD是一个包含三种模态、28种用户指令类型和30万条数据的新数据集。AnyCapEval是一个新的基准，通过解耦内容准确性和风格保真度来提供更可靠的可控图像描述评估指标。

Result: AnyCap模型（ACM）显著提高了不同基础模型在AnyCapEval上的图像描述质量。具体而言，ACM-8B将GPT-4o的内容分数提高了45%，风格分数提高了12%，并在MIA-Bench和VidCapBench等基准上也取得了显著的提升。

Conclusion: AnyCap模型（ACM）作为一种轻量级的即插即用框架，在不重新训练基础模型的情况下，增强了现有基础模型在全模态图像描述方面的可控性。AnyCap数据集（ACD）涵盖了三种模态、28种用户指令类型和30万条高质量数据条目，解决了可控多模态图像描述领域数据稀缺的问题。AnyCapEval基准通过解耦内容准确性和风格保真度，为可控图像描述提供了更可靠的评估指标。ACM在AnyCapEval上显著提高了不同基础模型的图像描述质量。特别是，ACM-8B将GPT-4o的内容分数提高了45%，风格分数提高了12%，并且在MIA-Bench和VidCapBench等广泛使用的基准上取得了显著的改进。

Abstract: Controllable captioning is essential for precise multimodal alignment and
instruction following, yet existing models often lack fine-grained control and
reliable evaluation protocols. To address this gap, we present the AnyCap
Project, an integrated solution spanning model, dataset, and evaluation. We
introduce AnyCapModel (ACM), a lightweight plug-and-play framework that
enhances the controllability of existing foundation models for omni-modal
captioning without retraining the base model. ACM reuses the original captions
from base models while incorporating user instructions and modality features to
generate improved captions. To remedy the data scarcity in controllable
multimodal captioning, we build AnyCapDataset (ACD), covering three modalities,
28 user-instruction types, and 300\,k high-quality data entries. We further
propose AnyCapEval, a new benchmark that provides more reliable evaluation
metrics for controllable captioning by decoupling content accuracy and
stylistic fidelity. ACM markedly improves caption quality across a diverse set
of base models on AnyCapEval. Notably, ACM-8B raises GPT-4o\'s content scores
by 45\% and style scores by 12\%, and it also achieves substantial gains on
widely used benchmarks such as MIA-Bench and VidCapBench.

</details>


### [38] [$S^2M^2$: Scalable Stereo Matching Model for Reliable Depth Estimation](https://arxiv.org/abs/2507.13229)
*Junhong Min,Youngpil Jeon,Jimin Kim,Minyong Choi*

Main category: cs.CV

TL;DR: S^2M^2 是一种高效的全局立体匹配方法，在各种基准测试中均表现出色，无需特定数据集的微调。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决通用立体匹配模型在不同分辨率和视差范围内进行训练而无需特定数据集微调时，在可泛化性方面存在的固有权衡问题。

Method: 本文提出的 S^2M^2 架构集成了一个多分辨率Transformer，用于鲁棒的长距离对应，并使用一种新颖的损失函数进行训练，该函数将概率集中在可行的匹配上。

Result: S^2M^2 实现了高精度和高效率，无需成本量过滤或深度细化堆栈，同时能够对视差、遮挡和置信度进行联合估计。

Conclusion: S^2M^2 是一种全局匹配架构，在 Middlebury v3 和 ETH3D 基准测试中均达到新的技术水平，在大多数指标上显著优于 prior 方法，同时以具有竞争力的效率重建了高质量的细节。

Abstract: The pursuit of a generalizable stereo matching model, capable of performing
across varying resolutions and disparity ranges without dataset-specific
fine-tuning, has revealed a fundamental trade-off. Iterative local search
methods achieve high scores on constrained benchmarks, but their core mechanism
inherently limits the global consistency required for true generalization. On
the other hand, global matching architectures, while theoretically more robust,
have been historically rendered infeasible by prohibitive computational and
memory costs. We resolve this dilemma with $S^2M^2$: a global matching
architecture that achieves both state-of-the-art accuracy and high efficiency
without relying on cost volume filtering or deep refinement stacks. Our design
integrates a multi-resolution transformer for robust long-range correspondence,
trained with a novel loss function that concentrates probability on feasible
matches. This approach enables a more robust joint estimation of disparity,
occlusion, and confidence. $S^2M^2$ establishes a new state of the art on the
Middlebury v3 and ETH3D benchmarks, significantly outperforming prior methods
across most metrics while reconstructing high-quality details with competitive
efficiency.

</details>


### [39] [SEMT: Static-Expansion-Mesh Transformer Network Architecture for Remote Sensing Image Captioning](https://arxiv.org/abs/2507.12845)
*Khang Truong,Lam Pham,Hieu Tang,Jasmin Lampert,Martin Boyer,Son Phan,Truong Nguyen*

Main category: cs.CV

TL;DR: A new transformer network for remote sensing image captioning improves results using Static Expansion, Memory-Augmented Self-Attention, and Mesh Transformer, outperforming previous methods on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: To address the need for interpreting vast and complex satellite imagery in applications like environmental monitoring, disaster assessment, and urban planning, by automating the generation of descriptive text from visual content.

Method: The paper presents a transformer-based network architecture for remote sensing image captioning, evaluating and integrating techniques such as Static Expansion, Memory-Augmented Self-Attention, and Mesh Transformer.

Result: The best model evaluated using the UCM-Caption and NWPU-Caption datasets outperformed existing state-of-the-art systems on most evaluation metrics.

Conclusion: The proposed transformer-based network architecture shows potential for real-life remote sensing image systems, outperforming state-of-the-art systems on most evaluation metrics.

Abstract: Image captioning has emerged as a crucial task in the intersection of
computer vision and natural language processing, enabling automated generation
of descriptive text from visual content. In the context of remote sensing,
image captioning plays a significant role in interpreting vast and complex
satellite imagery, aiding applications such as environmental monitoring,
disaster assessment, and urban planning. This motivates us, in this paper, to
present a transformer based network architecture for remote sensing image
captioning (RSIC) in which multiple techniques of Static Expansion,
Memory-Augmented Self-Attention, Mesh Transformer are evaluated and integrated.
We evaluate our proposed models using two benchmark remote sensing image
datasets of UCM-Caption and NWPU-Caption. Our best model outperforms the
state-of-the-art systems on most of evaluation metrics, which demonstrates
potential to apply for real-life remote sensing image systems.

</details>


### [40] [VITA: Vision-to-Action Flow Matching Policy](https://arxiv.org/abs/2507.13231)
*Dechen Gao,Boqi Zhao,Andrew Lee,Ian Chuang,Hanchu Zhou,Hang Wang,Zhe Zhao,Junshan Zhang,Iman Soltani*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present VITA, a Vision-To-Action flow matching policy that evolves latent
visual representations into latent actions for visuomotor control. Traditional
flow matching and diffusion policies sample from standard source distributions
(e.g., Gaussian noise) and require additional conditioning mechanisms like
cross-attention to condition action generation on visual information, creating
time and space overheads. VITA proposes a novel paradigm that treats latent
images as the flow source, learning an inherent mapping from vision to action
while eliminating separate conditioning modules and preserving generative
modeling capabilities. Learning flows between fundamentally different
modalities like vision and action is challenging due to sparse action data
lacking semantic structures and dimensional mismatches between high-dimensional
visual representations and raw actions. We address this by creating a
structured action latent space via an autoencoder as the flow matching target,
up-sampling raw actions to match visual representation shapes. Crucially, we
supervise flow matching with both encoder targets and final action outputs
through flow latent decoding, which backpropagates action reconstruction loss
through sequential flow matching ODE solving steps for effective end-to-end
learning. Implemented as simple MLP layers, VITA is evaluated on challenging
bi-manual manipulation tasks on the ALOHA platform, including 5 simulation and
2 real-world tasks. Despite its simplicity, MLP-only VITA outperforms or
matches state-of-the-art generative policies while reducing inference latency
by 50-130% compared to conventional flow matching policies requiring different
conditioning mechanisms or complex architectures. To our knowledge, VITA is the
first MLP-only flow matching policy capable of solving complex bi-manual
manipulation tasks like those in ALOHA benchmarks.

</details>


### [41] [Simulate, Refocus and Ensemble: An Attention-Refocusing Scheme for Domain Generalization](https://arxiv.org/abs/2507.12851)
*Ziyi Wang,Zhi Gao,Jin Chen,Qingjie Zhao,Xinxiao Wu,Jiebo Luo*

Main category: cs.CV

TL;DR: SRE 是一种通过对齐 CLIP 注意力图来提高领域泛化性能的方法，通过模拟域偏移、重塑注意力和集成学习实现。


<details>
  <summary>Details</summary>
Motivation: CLIP 在领域泛化中虽然能很好地编码语义概念，但在跨域关注任务相关区域（即领域不变区域）方面存在不足，导致在未见目标域上的性能不佳。

Method: 提出了一种名为 Simulate, Refocus and Ensemble (SRE) 的注意力重塑方案，通过对源域和模拟目标域之间的注意力进行重塑来减少域偏移，并利用集成学习来捕获域不变的注意力图。

Result: SRE 实现了对 CLIP 注意力图的对齐，以减少域偏移，并在实验中证明了其优于现有最先进方法的性能。

Conclusion: SRE 通过对 CLIP 中的注意力图进行对齐来减少域偏移，并在多个数据集上取得了比最先进方法更好的结果。

Abstract: Domain generalization (DG) aims to learn a model from source domains and
apply it to unseen target domains with out-of-distribution data. Owing to
CLIP's strong ability to encode semantic concepts, it has attracted increasing
interest in domain generalization. However, CLIP often struggles to focus on
task-relevant regions across domains, i.e., domain-invariant regions, resulting
in suboptimal performance on unseen target domains. To address this challenge,
we propose an attention-refocusing scheme, called Simulate, Refocus and
Ensemble (SRE), which learns to reduce the domain shift by aligning the
attention maps in CLIP via attention refocusing. SRE first simulates domain
shifts by performing augmentation on the source data to generate simulated
target domains. SRE then learns to reduce the domain shifts by refocusing the
attention in CLIP between the source and simulated target domains. Finally, SRE
utilizes ensemble learning to enhance the ability to capture domain-invariant
attention maps between the source data and the simulated target data. Extensive
experimental results on several datasets demonstrate that SRE generally
achieves better results than state-of-the-art methods. The code is available
at: https://github.com/bitPrincy/SRE-DG.

</details>


### [42] [SCORE: Scene Context Matters in Open-Vocabulary Remote Sensing Instance Segmentation](https://arxiv.org/abs/2507.12857)
*Shiqi Huang,Shuting He,Huaiyuan Qin,Bihan Wen*

Main category: cs.CV

TL;DR:  SCORE框架通过集成区域和全局场景上下文来解决开放词汇遥感实例分割的挑战，提高了对象可区分性和文本表示的适应性，并在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥感实例分割方法主要为闭合词汇预测设计，限制了其识别新类别或跨数据集泛化的能力，从而限制了其在多样化的地球观测应用中的适用性。尽管现有的开放词汇分割模型在自然图像数据集上表现良好，但它们在遥感图像上的直接应用面临多样化的地貌、季节性变化以及航空影像中存在小型或模糊物体等挑战。

Method:  SCORE框架集成了多粒度场景上下文（区域上下文和全局上下文）来增强视觉和文本表示。具体来说，它引入了区域感知集成（Region-Aware Integration）来完善类别嵌入以提高对象可区分性，并通过全局上下文适应（Global Context Adaptation）来丰富文本嵌入，为分类器创建更具适应性和表现力的语言潜在空间。

Result: 实验结果表明， SCORE方法实现了最先进的性能，在多个数据集上为开放词汇遥感实例分割建立了新的基准。

Conclusion:  SCORE方法在公开词汇遥感实例分割方面实现了最先进的性能，为大规模、真实世界的地理空间分析提供了稳健的解决方案。

Abstract: Most existing remote sensing instance segmentation approaches are designed
for close-vocabulary prediction, limiting their ability to recognize novel
categories or generalize across datasets. This restricts their applicability in
diverse Earth observation scenarios. To address this, we introduce
open-vocabulary (OV) learning for remote sensing instance segmentation. While
current OV segmentation models perform well on natural image datasets, their
direct application to remote sensing faces challenges such as diverse
landscapes, seasonal variations, and the presence of small or ambiguous objects
in aerial imagery. To overcome these challenges, we propose $\textbf{SCORE}$
($\textbf{S}$cene $\textbf{C}$ontext matters in $\textbf{O}$pen-vocabulary
$\textbf{RE}$mote sensing instance segmentation), a framework that integrates
multi-granularity scene context, i.e., regional context and global context, to
enhance both visual and textual representations. Specifically, we introduce
Region-Aware Integration, which refines class embeddings with regional context
to improve object distinguishability. Additionally, we propose Global Context
Adaptation, which enriches naive text embeddings with remote sensing global
context, creating a more adaptable and expressive linguistic latent space for
the classifier. We establish new benchmarks for OV remote sensing instance
segmentation across diverse datasets. Experimental results demonstrate that,
our proposed method achieves SOTA performance, which provides a robust solution
for large-scale, real-world geospatial analysis. Our code is available at
https://github.com/HuangShiqi128/SCORE.

</details>


### [43] [WhoFi: Deep Person Re-Identification via Wi-Fi Channel Signal Encoding](https://arxiv.org/abs/2507.12869)
*Danilo Avola,Daniele Pannone,Dario Montagnini,Emad Emam*

Main category: cs.CV

TL;DR: WhoFi uses Wi-Fi signals for person re-identification, overcoming challenges faced by visual methods. It employs a DNN with a Transformer encoder trained on CSI data to achieve competitive performance.


<details>
  <summary>Details</summary>
Motivation: Traditional Person Re-Identification methods relying on visual data are hindered by issues like poor lighting, occlusion, and suboptimal angles. This work addresses these challenges by introducing a novel approach using Wi-Fi signals.

Method: WhoFi pipeline extracts biometric features from Channel State Information (CSI) and processes them through a modular Deep Neural Network (DNN) featuring a Transformer-based encoder, trained using an in-batch negative loss function.

Result: Experiments on the NTU-Fi dataset show that the WhoFi approach achieves competitive results compared to state-of-the-art methods, confirming its effectiveness in identifying individuals via Wi-Fi signals.

Conclusion: WhoFi pipeline utilizes Wi-Fi signals for person re-identification, achieving competitive results compared to state-of-the-art methods by extracting biometric features from CSI and using a DNN with a Transformer-based encoder.

Abstract: Person Re-Identification is a key and challenging task in video surveillance.
While traditional methods rely on visual data, issues like poor lighting,
occlusion, and suboptimal angles often hinder performance. To address these
challenges, we introduce WhoFi, a novel pipeline that utilizes Wi-Fi signals
for person re-identification. Biometric features are extracted from Channel
State Information (CSI) and processed through a modular Deep Neural Network
(DNN) featuring a Transformer-based encoder. The network is trained using an
in-batch negative loss function to learn robust and generalizable biometric
signatures. Experiments on the NTU-Fi dataset show that our approach achieves
competitive results compared to state-of-the-art methods, confirming its
effectiveness in identifying individuals via Wi-Fi signals.

</details>


### [44] [HRSeg: High-Resolution Visual Perception and Enhancement for Reasoning Segmentation](https://arxiv.org/abs/2507.12883)
*Weihuang Lin,Yiwei Ma,Xiaoshuai Sun,Shuting He,Jiayi Ji,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: HRSeg是一种高效的高分辨率细粒度感知模型，通过HRP和HRE模块提升了推理分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推理分割方法受限于低感知分辨率，并且通过插值位置嵌入来提高分辨率的方法性能提升有限且计算成本高。

Method: HRSeg模型通过高分辨率感知（HRP）和高分辨率增强（HRE）两个关键创新来解决低感知分辨率和插值位置嵌入的计算成本问题。HRP模块处理高分辨率图像，整合局部和全局特征；HRE模块增强掩膜特征，并将其与文本特征对齐。

Result: HRSeg模型在多个基准数据集上取得了优于现有方法的性能。

Conclusion: HRSeg在多个基准数据集上展现出优越的性能，并且通过消融实验验证了其模块的有效性。

Abstract: The reasoning segmentation task involves segmenting objects within an image
by interpreting implicit user instructions, which may encompass subtleties such
as contextual cues and open-world knowledge. Despite significant advancements
made by existing approaches, they remain constrained by low perceptual
resolution, as visual encoders are typically pre-trained at lower resolutions.
Furthermore, simply interpolating the positional embeddings of visual encoders
to enhance perceptual resolution yields only marginal performance improvements
while incurring substantial computational costs. To address this, we propose
HRSeg, an efficient model with high-resolution fine-grained perception. It
features two key innovations: High-Resolution Perception (HRP) and
High-Resolution Enhancement (HRE). The HRP module processes high-resolution
images through cropping, integrating local and global features for
multi-granularity quality. The HRE module enhances mask features by integrating
fine-grained information from high-resolution images, refining their alignment
with text features for precise segmentation. Extensive ablation studies
validate the effectiveness of our modules, while comprehensive experiments on
multiple benchmark datasets demonstrate HRSeg's superior performance.

</details>


### [45] [Camera-based implicit mind reading by capturing higher-order semantic dynamics of human gaze within environmental context](https://arxiv.org/abs/2507.12889)
*Mengke Song,Yuge Xie,Qi Cui,Luming Li,Xinyu Liu,Guotao Wang,Chenglizhao Chen,Shanchen Pang*

Main category: cs.CV

TL;DR: 该研究提出了一种创新的、基于摄像头的情感识别方法，通过分析用户的凝视模式、环境语义和时间动态，实现了用户无感知、实时、连续的情感识别，克服了传统方法的局限性，并证明了情感是人与环境交互的结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如基于表情、语音、手势、生理信号或静态凝视分析的方法）存在局限性，无法捕捉深层、隐式情感以及视觉注意力与环境之间的动态交互。现有方法要么依赖于容易被伪装的显式信号，要么需要复杂的传感器，要么无法捕捉凝视与环境的丰富动态交互。

Method: 利用标准高清摄像头，非侵入性地捕捉用户在自然环境中的眼部外观和头部运动，估计凝视轨迹，并结合环境语义和时间动态信息，实现情感识别。

Result: 证明了情感不仅是生理反应，也是人与环境交互的复杂结果，并实现了用户无感知、实时、连续的情感识别。

Conclusion: 提出了一种新颖的、用户无感知的、基于摄像头的情感识别方法，该方法将凝视注视模式与环境语义和时间动态相结合，能够实现用户无感知、实时、连续的情感识别，并具有高泛化性和低部署成本。

Abstract: Emotion recognition,as a step toward mind reading,seeks to infer internal
states from external cues.Most existing methods rely on explicit signals-such
as facial expressions,speech,or gestures-that reflect only bodily responses and
overlook the influence of environmental context.These cues are often
voluntary,easy to mask,and insufficient for capturing deeper,implicit emotions.
Physiological signal-based approaches offer more direct access to internal
states but require complex sensors that compromise natural behavior and limit
scalability.Gaze-based methods typically rely on static fixation analysis and
fail to capture the rich,dynamic interactions between gaze and the
environment,and thus cannot uncover the deep connection between emotion and
implicit behavior.To address these limitations,we propose a novel
camera-based,user-unaware emotion recognition approach that integrates gaze
fixation patterns with environmental semantics and temporal dynamics.Leveraging
standard HD cameras,our method unobtrusively captures users'eye appearance and
head movements in natural settings-without the need for specialized hardware or
active user participation.From these visual cues,the system estimates gaze
trajectories over time and space, providing the basis for modeling the spatial,
semantic,and temporal dimensions of gaze behavior. This allows us to capture
the dynamic interplay between visual attention and the surrounding
environment,revealing that emotions are not merely physiological responses but
complex outcomes of human-environment interactions.The proposed approach
enables user-unaware,real-time,and continuous emotion recognition,offering high
generalizability and low deployment cost.

</details>


### [46] [LanePerf: a Performance Estimation Framework for Lane Detection](https://arxiv.org/abs/2507.12894)
*Yin Wu,Daniel Slieter,Ahmed Abouelazm,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 本研究提出了一种名为LanePerf的新框架，用于在没有真实标签的情况下估计车道线检测模型的性能。该框架克服了以往方法的局限性，通过结合图像和车道线特征，能有效应对各种驾驶场景和领域迁移问题。实验证明LanePerf在提高模型鲁棒性和评估效率方面具有显著优势，为自动驾驶系统的安全性和测试效率提供了支持。


<details>
  <summary>Details</summary>
Motivation: 领域迁移（domain shifts）常常会削弱模型在新的部署环境中的可靠性。为了保证车道线检测模型的鲁棒性和安全性，通常需要收集和标注目标域数据，这是一个资源消耗巨大的过程。在没有真实标签的情况下估计模型性能，为高效的鲁棒性评估提供了一种有前景的替代方案，但在车道线检测任务中尚未得到充分探索。而先前在图像分类任务中用于性能估计的工作，其方法并不直接适用于车道线检测任务。

Method: 首先，将五个在图像分类任务中表现良好的性能估计方法迁移应用于车道线检测任务，以建立基线。其次，针对现有方法仅依赖softmax分数或车道线特征的局限性，提出了一种新的车道线性能估计框架（LanePerf），该框架集成了图像特征和车道线特征，利用预训练的图像编码器和基于DeepSets的架构，能够有效处理零车道线检测和大幅度域迁移的场景。

Result: LanePerf框架在OpenLane数据集上进行了广泛的实验评估，该数据集涵盖了不同的领域迁移场景（如不同场景、天气和时间）。实验结果表明，LanePerf的平均绝对误差（MAE）为0.117，Spearman秩相关系数为0.727，优于所有基线方法。

Conclusion: 本研究提出的LanePerf框架通过整合图像和车道线特征，有效解决了现有方法在零车道线检测和大幅度域迁移场景下的局限性，在OpenLane数据集上取得了优于所有基线方法的性能，具体表现在较低的平均绝对误差（MAE）和较高的Spearman秩相关系数，为ADAS领域提供了一种高效、无需标签的性能评估方法，有助于提升复杂驾驶场景下的测试效率和安全性。

Abstract: Lane detection is a critical component of Advanced Driver-Assistance Systems
(ADAS) and Automated Driving System (ADS), providing essential spatial
information for lateral control. However, domain shifts often undermine model
reliability when deployed in new environments. Ensuring the robustness and
safety of lane detection models typically requires collecting and annotating
target domain data, which is resource-intensive. Estimating model performance
without ground-truth labels offers a promising alternative for efficient
robustness assessment, yet remains underexplored in lane detection. While
previous work has addressed performance estimation in image classification,
these methods are not directly applicable to lane detection tasks. This paper
first adapts five well-performing performance estimation methods from image
classification to lane detection, building a baseline. Addressing the
limitations of prior approaches that solely rely on softmax scores or lane
features, we further propose a new Lane Performance Estimation Framework
(LanePerf), which integrates image and lane features using a pretrained image
encoder and a DeepSets-based architecture, effectively handling zero-lane
detection scenarios and large domain-shift cases. Extensive experiments on the
OpenLane dataset, covering diverse domain shifts (scenes, weather, hours),
demonstrate that our LanePerf outperforms all baselines, achieving a lower MAE
of 0.117 and a higher Spearman's rank correlation coefficient of 0.727. These
findings pave the way for robust, label-free performance estimation in ADAS,
supporting more efficient testing and improved safety in challenging driving
scenarios.

</details>


### [47] [Federated Learning for Commercial Image Sources](https://arxiv.org/abs/2507.12903)
*Shreyansh Jain,Koteswar Rao Jerripothula*

Main category: cs.CV

TL;DR: 本研究提出了一个用于联邦学习的图像分类数据集，以及两种新的联邦学习算法Fed-Cyclic和Fed-Star，并在实验中证明了它们优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了推动联邦学习在图像分类领域的应用，特别是针对需要保护隐私的多方协作场景，本研究创建了一个新的数据集，并提出了相应的联邦学习算法。

Method: 提出了一种新的联邦学习算法，包括Fed-Cyclic（客户端按顺序传递和更新权重）和Fed-Star（客户端通过预聚合和本地训练更新权重，形成星型拓扑）。

Result: 实验结果表明，Fed-Cyclic和Fed-Star算法在新的数据集上取得了比现有基线算法更好的性能。

Conclusion: 本文提出的Fed-Cyclic和Fed-Star两种联邦学习算法在新的图像分类数据集上表现优于现有基线算法。

Abstract: Federated Learning is a collaborative machine learning paradigm that enables
multiple clients to learn a global model without exposing their data to each
other. Consequently, it provides a secure learning platform with
privacy-preserving capabilities. This paper introduces a new dataset containing
23,326 images collected from eight different commercial sources and classified
into 31 categories, similar to the Office-31 dataset. To the best of our
knowledge, this is the first image classification dataset specifically designed
for Federated Learning. We also propose two new Federated Learning algorithms,
namely Fed-Cyclic and Fed-Star. In Fed-Cyclic, a client receives weights from
its previous client, updates them through local training, and passes them to
the next client, thus forming a cyclic topology. In Fed-Star, a client receives
weights from all other clients, updates its local weights through
pre-aggregation (to address statistical heterogeneity) and local training, and
sends its updated local weights to all other clients, thus forming a star-like
topology. Our experiments reveal that both algorithms perform better than
existing baselines on our newly introduced dataset.

</details>


### [48] [AthleticsPose: Authentic Sports Motion Dataset on Athletic Field and Evaluation of Monocular 3D Pose Estimation Ability](https://arxiv.org/abs/2507.12905)
*Tomohiro Suzuki,Ryota Tanaka,Calvin Yeung,Keisuke Fujii*

Main category: cs.CV

TL;DR: 本研究提出了AthleticsPose数据集，用于解决体育运动分析中单目3D姿态估计的挑战。实验证明，在真实数据集上训练的模型性能优于在模拟数据集上训练的模型，但在处理高速运动指标时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 解决体育运动分析中单目3D姿态估计面临的现实挑战，即缺乏真实的体育运动数据集和不确定的可靠性问题。

Method: 创建了一个名为AthleticsPose的真实体育运动数据集，并使用该数据集训练了一个3D姿态估计模型，然后对模型进行了全面的评估，并与在模拟数据集上训练的模型进行了比较。

Result: 在AthleticsPose数据集上训练的模型显著优于在模拟运动数据集上训练的基线模型，MPJPE降低了约75%。同时，研究还发现估计精度对摄像机视角和主体尺度敏感，模型在捕捉个体差异（如膝关节角度）方面表现出潜力，但在高速指标（如膝关节驱动速度）方面存在预测偏差，能力受限。

Conclusion: 本研究提出的AthleticsPose数据集和模型为单目3D姿态估计在体育运动分析中的应用提供了有价值的资源和见解，但也指出了其在处理高速运动指标方面的局限性。

Abstract: Monocular 3D pose estimation is a promising, flexible alternative to costly
motion capture systems for sports analysis. However, its practical application
is hindered by two factors: a lack of realistic sports datasets and unclear
reliability for sports tasks. To address these challenges, we introduce the
AthleticsPose dataset, a new public dataset featuring ``real'' motions captured
from 23 athletes performing various athletics events on an athletic field.
Using this dataset, we trained a representative 3D pose estimation model and
performed a comprehensive evaluation. Our results show that the model trained
on AthleticsPose significantly outperforms a baseline model trained on an
imitated sports motion dataset, reducing MPJPE by approximately 75 %. These
results show the importance of training on authentic sports motion data, as
models based on imitated motions do not effectively transfer to real-world
motions. Further analysis reveals that estimation accuracy is sensitive to
camera view and subject scale. In case studies of kinematic indicators, the
model demonstrated the potential to capture individual differences in knee
angles but struggled with higher-speed metrics, such as knee-drive velocity,
due to prediction biases. This work provides the research community with a
valuable dataset and clarifies the potential and practical limitations of using
monocular 3D pose estimation for sports motion analysis. Our dataset, code, and
checkpoints are available at https://github.com/SZucchini/AthleticsPose.

</details>


### [49] [Argus: Leveraging Multiview Images for Improved 3-D Scene Understanding With Large Language Models](https://arxiv.org/abs/2507.12916)
*Yifan Xu,Chao Zhang,Hanqi Jiang,Xiaoyan Wang,Ruifei Ma,Yiwei Li,Zihao Wu,Zeju Li,Xiangde Liu*

Main category: cs.CV

TL;DR: Argus是一个3D多模态框架，它利用多视图图像和LLMs来增强3D场景理解，弥补了传统3D点云重建的信息丢失问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法严重依赖3D点云，但室内场景的点云重建过程容易造成信息丢失，纹理缺失或重复的平面容易被遗漏，导致重建的3D点云出现空洞。此外，复杂结构的对象容易因捕获图像与密集重建点云之间的未对齐而导致细节失真。2D多视图图像在视觉上与3D点云具有一致性，并提供了场景组件的更详细表示，可以弥补这些不足。

Method: Argus是一个新颖的3D多模态框架，它利用多视图图像和大型语言模型（LLMs）来增强3D场景理解。它通过融合和整合多视图图像和相机位姿来创建视图场景特征，这些特征与3D特征进行交互，从而生成全面且详细的3D感知场景嵌入。Argus可以被视为一个3D大型多模态基础模型（3D-LMM），因为它接受文本指令、2D多视图图像和3D点云等多种模态作为输入，并将LLMs的能力扩展到处理3D任务。

Result: Argus通过融合多视图图像和相机位姿来创建视图场景特征，这些特征与3D特征进行交互，生成全面且详细的3D感知场景嵌入。该方法能够补偿3D点云重建过程中的信息丢失，并帮助LLMs更好地理解3D世界。大量实验证明，Argus在各种下游任务中表现优于现有的3D-LMM。

Conclusion: Argus通过融合多视图图像和相机位姿来增强3D场景理解能力，并已被证明在各种下游任务中优于现有的3D-LMM。

Abstract: Advancements in foundation models have made it possible to conduct
applications in various downstream tasks. Especially, the new era has witnessed
a remarkable capability to extend Large Language Models (LLMs) for tackling
tasks of 3D scene understanding. Current methods rely heavily on 3D point
clouds, but the 3D point cloud reconstruction of an indoor scene often results
in information loss. Some textureless planes or repetitive patterns are prone
to omission and manifest as voids within the reconstructed 3D point clouds.
Besides, objects with complex structures tend to introduce distortion of
details caused by misalignments between the captured images and the dense
reconstructed point clouds. 2D multi-view images present visual consistency
with 3D point clouds and provide more detailed representations of scene
components, which can naturally compensate for these deficiencies. Based on
these insights, we propose Argus, a novel 3D multimodal framework that
leverages multi-view images for enhanced 3D scene understanding with LLMs. In
general, Argus can be treated as a 3D Large Multimodal Foundation Model
(3D-LMM) since it takes various modalities as input(text instructions, 2D
multi-view images, and 3D point clouds) and expands the capability of LLMs to
tackle 3D tasks. Argus involves fusing and integrating multi-view images and
camera poses into view-as-scene features, which interact with the 3D features
to create comprehensive and detailed 3D-aware scene embeddings. Our approach
compensates for the information loss while reconstructing 3D point clouds and
helps LLMs better understand the 3D world. Extensive experiments demonstrate
that our method outperforms existing 3D-LMMs in various downstream tasks.

</details>


### [50] [DMQ: Dissecting Outliers of Diffusion Models for Post-Training Quantization](https://arxiv.org/abs/2507.12933)
*Dongyeun Lee,Jiwan Hur,Hyounguk Shon,Jae Young Lee,Junmo Kim*

Main category: cs.CV

TL;DR: DMQ是一种新的量化方法，通过LES和PTS技术解决了扩散模型在低比特量化下的性能下降问题，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的后训练量化（PTQ）方法在解决扩散模型量化问题时，往往会忽略离群值，导致在低比特宽度下性能下降。本文旨在提出一种新的量化方法，以克服这些限制，特别是在低比特宽度下保持扩散模型的性能。

Method: DMQ方法结合了学习等效缩放（LES）和通道无关的二的幂次缩放（PTS）。LES优化了通道无关的缩放因子，以重新分配量化难度于权重和激活，从而降低总体量化误差。考虑到早期去噪步骤对最终输出的至关重要性（由于误差累积），引入了自适应时间步长加权方案来优先处理这些关键步骤。此外，针对跳接层等表现出高通道间方差的层，为激活引入了通道无关的二的幂次缩放（PTS）。为了确保即使在小的校准集上也能稳健地选择PTS因子，还引入了一个投票算法来提高可靠性。

Result: 实验证明，DMQ方法在低比特宽度（如W4A6和W4A8）下显著优于现有方法，保持了高图像生成质量和模型稳定性。

Conclusion: 所提出的DMQ方法，结合了学习等效缩放（LES）和通道无关的二的幂次缩放（PTS），能够有效解决扩散模型量化中的挑战，尤其是在低比特宽度下（如W4A6和W4A8）表现优于现有方法，同时保持了高质量的图像生成和模型稳定性。

Abstract: Diffusion models have achieved remarkable success in image generation but
come with significant computational costs, posing challenges for deployment in
resource-constrained environments. Recent post-training quantization (PTQ)
methods have attempted to mitigate this issue by focusing on the iterative
nature of diffusion models. However, these approaches often overlook outliers,
leading to degraded performance at low bit-widths. In this paper, we propose a
DMQ which combines Learned Equivalent Scaling (LES) and channel-wise
Power-of-Two Scaling (PTS) to effectively address these challenges. Learned
Equivalent Scaling optimizes channel-wise scaling factors to redistribute
quantization difficulty between weights and activations, reducing overall
quantization error. Recognizing that early denoising steps, despite having
small quantization errors, crucially impact the final output due to error
accumulation, we incorporate an adaptive timestep weighting scheme to
prioritize these critical steps during learning. Furthermore, identifying that
layers such as skip connections exhibit high inter-channel variance, we
introduce channel-wise Power-of-Two Scaling for activations. To ensure robust
selection of PTS factors even with small calibration set, we introduce a voting
algorithm that enhances reliability. Extensive experiments demonstrate that our
method significantly outperforms existing works, especially at low bit-widths
such as W4A6 (4-bit weight, 6-bit activation) and W4A8, maintaining high image
generation quality and model stability. The code is available at
https://github.com/LeeDongYeun/dmq.

</details>


### [51] [A Deep-Learning Framework for Land-Sliding Classification from Remote Sensing Image](https://arxiv.org/abs/2507.12939)
*Hieu Tang,Truong Vo,Dong Pham,Toan Nguyen,Lam Pham,Truong Nguyen*

Main category: cs.CV

TL;DR: A deep learning framework with EfficientNet_Large and SVM for landslide detection achieved an F1-score of 0.8938, effectively handling data imbalance with data augmentation.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of selecting appropriate deep learning architectures for landslide detection from satellite imagery to optimize performance and avoid overfitting.

Method: A deep-learning framework using EfficientNet_Large as the backbone and SVM as a post-processing classifier, incorporating both online and offline data augmentation to handle data imbalance.

Result: The proposed model achieved an F1-score of 0.8938 on the Zindi challenge public test set.

Conclusion: The proposed framework effectively combines online and offline data augmentation, an EfficientNet_Large backbone, and an SVM classifier for robust landslide detection, achieving a high F1-score.

Abstract: The use of satellite imagery combined with deep learning to support automatic
landslide detection is becoming increasingly widespread. However, selecting an
appropriate deep learning architecture to optimize performance while avoiding
overfitting remains a critical challenge. To address these issues, we propose a
deep-learning based framework for landslide detection from remote sensing image
in this paper. The proposed framework presents an effective combination of the
online an offline data augmentation to tackle the imbalanced data, a backbone
EfficientNet\_Large deep learning model for extracting robust embedding
features, and a post-processing SVM classifier to balance and enhance the
classification performance. The proposed model achieved an F1-score of 0.8938
on the public test set of the Zindi challenge.

</details>


### [52] [Weakly Supervised Visible-Infrared Person Re-Identification via Heterogeneous Expert Collaborative Consistency Learning](https://arxiv.org/abs/2507.12942)
*Yafei Zhang,Lingqi Kong,Huafeng Li,Jie Wen*

Main category: cs.CV

TL;DR: 本论文提出了一种新的弱监督方法，用于解决可见光-红外行人重识别中的跨模态标签缺失问题。通过构建异构专家协作一致性学习框架，利用单模态标签训练模型，实现了有效的跨模态身份识别。


<details>
  <summary>Details</summary>
Motivation: 为了减少可见光-红外行人重识别模型对标注跨模态样本的依赖，并解决实际应用中跨模态身份标签缺失的场景。

Method: 提出了一种弱监督跨模态行人重识别方法，构建了异构专家协作一致性学习框架，该框架独立训练各模态的分类专家，并利用跨模态关系融合机制提高预测准确性，最终在弱监督下实现专家间协同一致学习。

Result: 实验结果表明，所提出的方法能够有效提升跨模态身份识别能力，并能更好地提取模态不变特征，在两个具有挑战性的数据集上验证了其有效性。

Conclusion: 本研究提出的异构专家协作一致性学习框架在可见光-红外行人重识别任务中取得了显著成效，有效解决了跨模态标签缺失的问题，并提升了模型提取模态不变特征的能力。

Abstract: To reduce the reliance of visible-infrared person re-identification (ReID)
models on labeled cross-modal samples, this paper explores a weakly supervised
cross-modal person ReID method that uses only single-modal sample identity
labels, addressing scenarios where cross-modal identity labels are unavailable.
To mitigate the impact of missing cross-modal labels on model performance, we
propose a heterogeneous expert collaborative consistency learning framework,
designed to establish robust cross-modal identity correspondences in a weakly
supervised manner. This framework leverages labeled data from each modality to
independently train dedicated classification experts. To associate cross-modal
samples, these classification experts act as heterogeneous predictors,
predicting the identities of samples from the other modality. To improve
prediction accuracy, we design a cross-modal relationship fusion mechanism that
effectively integrates predictions from different experts. Under the implicit
supervision provided by cross-modal identity correspondences, collaborative and
consistent learning among the experts is encouraged, significantly enhancing
the model's ability to extract modality-invariant features and improve
cross-modal identity recognition. Experimental results on two challenging
datasets validate the effectiveness of the proposed method.

</details>


### [53] [Analysis of Image-and-Text Uncertainty Propagation in Multimodal Large Language Models with Cardiac MR-Based Applications](https://arxiv.org/abs/2507.12945)
*Yucheng Tang,Yunguan Fu,Weixi Yi,Yipei Wang,Daniel C. Alexander,Rhodri Davies,Yipeng Hu*

Main category: cs.CV

TL;DR: 本研究提出了一种多模态不确定性传播模型（MUPM），用于分析多模态大语言模型（MLLM）中的不确定性。该模型使用心脏MRI和健康记录数据进行训练，发现MUPM具有良好的泛化能力，可用于临床应用，如心脏病预测，并能识别冗余信息。


<details>
  <summary>Details</summary>
Motivation: 现有大规模多模态大语言模型（MLLM）在处理和整合文本、图像等多种模态信息方面能力强大，但其输入模态间的相互关系、单模态数据带来的不确定性，以及在此不确定性分解后的潜在临床应用等方面尚未得到充分理解。

Method: 本研究提出了一种基于不确定性传播的多模态不确定性传播模型（MUPM），用于表征大规模多模态大语言模型（MLLM）输入中，由纯图像、纯文本及联合图像-文本变化引起的不确定性之间的关系。研究使用包含心脏MRI扫描和数字健康记录的真实临床数据，展示了MUPM可以通过少量样本进行鲁棒优化，并且在不同数据分布和下游任务上都表现出良好的泛化能力。

Result: MUPMs可与少量样本一起进行鲁棒优化，并且在跨不同输入数据分布和下游任务时表现出良好的泛化能力。这种可迁移性使得MUPM能够量化不确定性之间的关系，并直接应用于临床，对不同数据或新的心脏病预测任务的不确定性进行估计和稳健分析。此外，MUPM在估计整体不确定性所需的样本量和识别冗余因子方面也显示出效率。

Conclusion: 该研究提出的多模态不确定性传播模型（MUPM）能够有效表征多模态MLLM输入中由图像、文本及联合输入引起的各种不确定性之间的关系。实验表明，MUPM仅需少量样本即可进行鲁棒优化，并且具有跨不同数据分布和下游任务的泛化能力。这种可迁移性可能归因于共享预训练、轻量级微调以及MUPM的低维特性。更重要的是，所学的可迁移性为不确定性估计和分析提供了直接的临床应用，可用于不同数据或新的心脏病预测任务。此外，实验还证明了MUPM在估计整体不确定性所需的样本量方面的效率，以及其识别冗余因子的能力，这些都是实际且有临床应用价值的。

Abstract: Multimodal large language models (MLLMs) can process and integrate
information from multimodality sources, such as text and images. However,
interrelationship among input modalities, uncertainties due to individual
uni-modal data and potential clinical applications following such an
uncertainty decomposition are yet fully understood in the context of
large-scale MLLMs. In this work, we propose a multimodal uncertainty
propagation model (MUPM) based on uncertainty propagation, to characterise the
relationship among the uncertainties arising from image-only, text-only, and
joint image-text variations in MLLM inputs. Using real clinical data consisting
of cardiac MR scans and digital health records, we describe that MUPMs can be
optimised robustly with a few samples. We then show that the fitted MUPMs are
generalisable across different input data distributions and, perhaps
surprisingly, across different downstream tasks. Such a transferability may be
explained by the shared pretraining, comparatively light MLLM fine-tuning,
along with the low-dimensional nature of the MUPMs. More importantly, this
learned transferability, quantifying the relationship between these
uncertainties, led to direct clinical applications in which uncertainties may
be estimated and thus analysed robustly for varying data or even a novel set of
cardiac disease prediction tasks. In addition, we show experimentally the
efficiency in multimodal data required for estimating the overall uncertainty
and its ability to identify redundant factors, both of which are considered
practical yet clinically useful applications with the proposed MUPMs. Codes are
available at https://github.com/yucheng722/MUPM.

</details>


### [54] [VisionThink: Smart and Efficient Vision Language Model via Reinforcement Learning](https://arxiv.org/abs/2507.13348)
*Senqiao Yang,Junyi Li,Xin Lai,Bei Yu,Hengshuang Zhao,Jiaya Jia*

Main category: cs.CV

TL;DR: VisionThink是一种新的视觉标记压缩方法，通过动态调整分辨率和智能压缩，提高了视觉语言模型的效率，尤其在OCR任务上表现出色，并能节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLMs）通过增加视觉标记数量来提升性能，但大多数实际场景并不需要如此多的视觉标记。虽然OCR相关任务在低分辨率下性能会显著下降，但大多数其他通用VQA任务在仅使用1/4分辨率时仍能准确执行。因此，需要一种更有效的方法来处理不同复杂度的视觉任务。

Method: 提出了一种名为VisionThink的视觉标记压缩新范式，通过动态处理不同分辨率的样本。该方法从降采样图像开始，智能判断其是否足以解决问题，否则请求更高分辨率图像。采用强化学习和LLM-as-Judge策略来训练模型，并设计了奖励函数和惩罚机制以优化图像缩放比例。

Result: VisionThink在OCR相关任务上展现了强大的细粒度视觉理解能力，同时在简单任务上节省了大量视觉标记。实验证明了该方法的优越性、效率和有效性。

Conclusion: VisionThink通过动态调整分辨率和智能压缩视觉标记，在保持OCR相关任务精细理解能力的同时，显著提高了效率。该方法在简单任务上节省了大量视觉标记，并在通用VQA任务上通过强化学习和LLM-as-Judge策略实现了稳定且合理的图像缩放调用比例。

Abstract: Recent advancements in vision-language models (VLMs) have improved
performance by increasing the number of visual tokens, which are often
significantly longer than text tokens. However, we observe that most real-world
scenarios do not require such an extensive number of visual tokens. While the
performance drops significantly in a small subset of OCR-related tasks, models
still perform accurately in most other general VQA tasks with only 1/4
resolution. Therefore, we propose to dynamically process distinct samples with
different resolutions, and present a new paradigm for visual token compression,
namely, VisionThink. It starts with a downsampled image and smartly decides
whether it is sufficient for problem solving. Otherwise, the model could output
a special token to request the higher-resolution image. Compared to existing
Efficient VLM methods that compress tokens using fixed pruning ratios or
thresholds, VisionThink autonomously decides whether to compress tokens case by
case. As a result, it demonstrates strong fine-grained visual understanding
capability on OCR-related tasks, and meanwhile saves substantial visual tokens
on simpler tasks. We adopt reinforcement learning and propose the LLM-as-Judge
strategy to successfully apply RL to general VQA tasks. Moreover, we carefully
design a reward function and penalty mechanism to achieve a stable and
reasonable image resize call ratio. Extensive experiments demonstrate the
superiority, efficiency, and effectiveness of our method. Our code is available
at https://github.com/dvlab-research/VisionThink.

</details>


### [55] [LoViC: Efficient Long Video Generation with Context Compression](https://arxiv.org/abs/2507.12952)
*Jiaxiu Jiang,Wenbo Li,Jingjing Ren,Yuping Qiu,Yong Guo,Xiaogang Xu,Han Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: LoViC 是一个基于扩散 Transformer 的长视频生成框架，它使用 FlexFormer 来压缩视频和文本，并通过分段生成来保持时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 为了克服扩散 Transformer 在生成长视频内容时面临的二次复杂度问题，以及现有方法在时间连贯性或可扩展性方面存在的妥协，本研究旨在开发一种能够生成长而连贯视频的新框架。

Method: LoViC框架采用基于扩散 Transformer 的方法，并利用 FlexFormer 这一先进的自编码器来统一压缩视频和文本的潜在表征。该框架通过分段生成过程、位置感知机制以及支持可变长度输入和可调压缩率的设计，实现了长视频的连贯生成，并支持预测、回溯、插值和多镜头生成等多种功能。

Result: 通过在百万级开放域视频上进行训练，LoViC 框架在各种下游任务的实验中得到了验证，证明了其在生成长、连贯视频方面的有效性和多功能性。

Conclusion: LoViC框架通过FlexFormer和分段生成过程有效地解决了长视频生成中的挑战，在各种任务中都表现出了有效性和多功能性。

Abstract: Despite recent advances in diffusion transformers (DiTs) for text-to-video
generation, scaling to long-duration content remains challenging due to the
quadratic complexity of self-attention. While prior efforts -- such as sparse
attention and temporally autoregressive models -- offer partial relief, they
often compromise temporal coherence or scalability. We introduce LoViC, a
DiT-based framework trained on million-scale open-domain videos, designed to
produce long, coherent videos through a segment-wise generation process. At the
core of our approach is FlexFormer, an expressive autoencoder that jointly
compresses video and text into unified latent representations. It supports
variable-length inputs with linearly adjustable compression rates, enabled by a
single query token design based on the Q-Former architecture. Additionally, by
encoding temporal context through position-aware mechanisms, our model
seamlessly supports prediction, retradiction, interpolation, and multi-shot
generation within a unified paradigm. Extensive experiments across diverse
tasks validate the effectiveness and versatility of our approach.

</details>


### [56] [cIDIR: Conditioned Implicit Neural Representation for Regularized Deformable Image Registration](https://arxiv.org/abs/2507.12953)
*Sidaty El Hadramy,Oumeymah Cherkaoui,Philippe C. Cattin*

Main category: cs.CV

TL;DR: cIDIR是一种基于INR的图像配准框架，通过将正则化超参数纳入条件，并使用分割掩模进行优化，解决了传统方法中正则化参数微调计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 学习型DIR框架中的正则化参数微调计算成本高昂，通常需要多次训练迭代。为了解决这个问题，我们提出了cIDI。

Method: 提出了一种新颖的基于隐式神经表示（INR）的图像配准框架cIDI，它将配准过程条件化于正则化超参数。cIDI在这些超参数的先验分布上进行训练，然后通过使用分割掩模作为观测值在正则化超参数上进行优化。此外，cIDI模型化了一个连续且可微的形变向量场（DVF），通过自动微分无缝集成高级正则化技术。

Result: cIDIR实现了高精度和鲁棒性，并能无缝集成高级正则化技术。

Conclusion: cIDIR框架在DIR-LAB数据集上进行了评估，在整个数据集中实现了高精度和鲁棒性。

Abstract: Regularization is essential in deformable image registration (DIR) to ensure
that the estimated Deformation Vector Field (DVF) remains smooth, physically
plausible, and anatomically consistent. However, fine-tuning regularization
parameters in learning-based DIR frameworks is computationally expensive, often
requiring multiple training iterations. To address this, we propose cIDI, a
novel DIR framework based on Implicit Neural Representations (INRs) that
conditions the registration process on regularization hyperparameters. Unlike
conventional methods that require retraining for each regularization
hyperparameter setting, cIDIR is trained over a prior distribution of these
hyperparameters, then optimized over the regularization hyperparameters by
using the segmentations masks as an observation. Additionally, cIDIR models a
continuous and differentiable DVF, enabling seamless integration of advanced
regularization techniques via automatic differentiation. Evaluated on the
DIR-LAB dataset, $\operatorname{cIDIR}$ achieves high accuracy and robustness
across the dataset.

</details>


### [57] [FantasyPortrait: Enhancing Multi-Character Portrait Animation with Expression-Augmented Diffusion Transformers](https://arxiv.org/abs/2507.12956)
*Qiang Wang,Mengchao Wang,Fan Jiang,Yaqi Fan,Yonggang Qi,Mu Xu*

Main category: cs.CV

TL;DR: FantasyPortrait 是一个基于扩散 Transformer 的框架，能够为单人和多人生成高保真、富含情感的面部动画，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在跨角色驱动和多角色动画方面存在的伪影和特征干扰问题。

Method: 提出了一种基于 Transformer 的扩散框架，并采用增强学习策略和掩码交叉注意力机制。

Result: 生成了高保真、富含情感的单人和多人面部动画，并提出了新的数据集和基准。

Conclusion: FantasyPortrait 在跨角色驱动和多角色动画方面显著优于最先进的方法，在定量指标和定性评估方面均表现出色。

Abstract: Producing expressive facial animations from static images is a challenging
task. Prior methods relying on explicit geometric priors (e.g., facial
landmarks or 3DMM) often suffer from artifacts in cross reenactment and
struggle to capture subtle emotions. Furthermore, existing approaches lack
support for multi-character animation, as driving features from different
individuals frequently interfere with one another, complicating the task. To
address these challenges, we propose FantasyPortrait, a diffusion transformer
based framework capable of generating high-fidelity and emotion-rich animations
for both single- and multi-character scenarios. Our method introduces an
expression-augmented learning strategy that utilizes implicit representations
to capture identity-agnostic facial dynamics, enhancing the model's ability to
render fine-grained emotions. For multi-character control, we design a masked
cross-attention mechanism that ensures independent yet coordinated expression
generation, effectively preventing feature interference. To advance research in
this area, we propose the Multi-Expr dataset and ExprBench, which are
specifically designed datasets and benchmarks for training and evaluating
multi-character portrait animations. Extensive experiments demonstrate that
FantasyPortrait significantly outperforms state-of-the-art methods in both
quantitative metrics and qualitative evaluations, excelling particularly in
challenging cross reenactment and multi-character contexts. Our project page is
https://fantasy-amap.github.io/fantasy-portrait/.

</details>


### [58] [Demographic-aware fine-grained classification of pediatric wrist fractures](https://arxiv.org/abs/2507.12964)
*Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota*

Main category: cs.CV

TL;DR: 一种结合细粒度识别、患者元数据和细粒度预训练的多模态方法，可提高儿童腕部病变诊断的准确性，尤其是在数据集有限的情况下。


<details>
  <summary>Details</summary>
Motivation: 儿童腕部骨折病例常见，但诊断耗时且需要专业知识。仅依赖图像诊断存在局限性，特别是在数据类型多样化的背景下。因此，需要一种能够有效利用有限数据集并融合多模态信息的方法来提高诊断准确性。

Method: 首先，将腕部病变识别视为细粒度识别任务，以识别传统卷积神经网络（CNN）忽略的细微X射线病变。其次，通过融合患者元数据和X射线图像来增强网络性能。第三，使用在细粒度数据集上训练的权重进行预训练，而不是在ImageNet等粗粒度数据集上进行预训练。

Result: 与仅使用图像的方法相比，细粒度策略和元数据集成在有限数据集上可将诊断准确率提高2%，在较大的骨折数据集上可提高10%以上。

Conclusion: 本研究提出了一种结合细粒度识别、患者元数据融合和细粒度数据集预训练的多模态方法，以解决儿童腕部病变诊断中数据集有限的挑战。实验证明，该方法在有限数据集上可将诊断准确率提高2%，在较大的骨折数据集上可提高10%以上。

Abstract: Wrist pathologies are frequently observed, particularly among children who
constitute the majority of fracture cases. However, diagnosing these conditions
is time-consuming and requires specialized expertise. Computer vision presents
a promising avenue, contingent upon the availability of extensive datasets, a
notable challenge in medical imaging. Therefore, reliance solely on one
modality, such as images, proves inadequate, especially in an era of diverse
and plentiful data types. In this study, we employ a multifaceted approach to
address the challenge of recognizing wrist pathologies using an extremely
limited dataset. Initially, we approach the problem as a fine-grained
recognition task, aiming to identify subtle X-ray pathologies that conventional
CNNs overlook. Secondly, we enhance network performance by fusing patient
metadata with X-ray images. Thirdly, rather than pre-training on a
coarse-grained dataset like ImageNet, we utilize weights trained on a
fine-grained dataset. While metadata integration has been used in other medical
domains, this is a novel application for wrist pathologies. Our results show
that a fine-grained strategy and metadata integration improve diagnostic
accuracy by 2% with a limited dataset and by over 10% with a larger
fracture-focused dataset.

</details>


### [59] [RGB Pre-Training Enhanced Unobservable Feature Latent Diffusion Model for Spectral Reconstruction](https://arxiv.org/abs/2507.12967)
*Keli Deng,Jie Nie,Yuntao Qian*

Main category: cs.CV

TL;DR: 通过将RGB预训练的潜在扩散模型（RGB-LDM）扩展到不可观测特征LDM（ULDM），并设计了一个包含光谱结构表示学习和光谱-空间联合分布学习的两阶段流水线，以有效地学习光谱-空间联合分布，从而实现了从RGB图像重建高光谱图像（HSI）。


<details>
  <summary>Details</summary>
Motivation: 光谱重建（SR）是从RGB图像重建高光谱图像（HSI）的关键问题。SR的一个关键难点在于估计不可观测特征，它包含了RGB成像传感器未捕获的重要光谱信息。通过有效构建以RGB图像为条件的 ấy光-空间联合分布来补充不可观测特征是解决该问题的关键。

Method: 提出了一种两阶段的流水线，包括光谱结构表示学习和光谱-空间联合分布学习，将RGB-LDM扩展到用于SR的不可观测特征LDM（ULDM）。第一阶段，训练了一个光谱不可观测特征自动编码器（SpeUAE）来提取和压缩不可观测特征，并将其映射到与RGB空间对齐的3D流形。第二阶段，分别通过SpeUAE和SpaAE对光谱和空间结构进行编码，然后获得ULDM，在相应RGB图像的指导下对编码后的不可观测特征的分布进行建模。

Result: 实验结果表明，我们提出的方法在光谱重建和下游重新照明任务上取得了最先进的性能。

Conclusion: 提出的方法在光谱重建和下游重新照明任务上均取得了最先进的性能。

Abstract: Spectral reconstruction (SR) is a crucial problem in image processing that
requires reconstructing hyperspectral images (HSIs) from the corresponding RGB
images. A key difficulty in SR is estimating the unobservable feature, which
encapsulates significant spectral information not captured by RGB imaging
sensors. The solution lies in effectively constructing the spectral-spatial
joint distribution conditioned on the RGB image to complement the unobservable
feature. Since HSIs share a similar spatial structure with the corresponding
RGB images, it is rational to capitalize on the rich spatial knowledge in RGB
pre-trained models for spectral-spatial joint distribution learning. To this
end, we extend the RGB pre-trained latent diffusion model (RGB-LDM) to an
unobservable feature LDM (ULDM) for SR. As the RGB-LDM and its corresponding
spatial autoencoder (SpaAE) already excel in spatial knowledge, the ULDM can
focus on modeling spectral structure. Moreover, separating the unobservable
feature from the HSI reduces the redundant spectral information and empowers
the ULDM to learn the joint distribution in a compact latent space.
Specifically, we propose a two-stage pipeline consisting of spectral structure
representation learning and spectral-spatial joint distribution learning to
transform the RGB-LDM into the ULDM. In the first stage, a spectral
unobservable feature autoencoder (SpeUAE) is trained to extract and compress
the unobservable feature into a 3D manifold aligned with RGB space. In the
second stage, the spectral and spatial structures are sequentially encoded by
the SpeUAE and the SpaAE, respectively. The ULDM is then acquired to model the
distribution of the coded unobservable feature with guidance from the
corresponding RGB images. Experimental results on SR and downstream relighting
tasks demonstrate that our proposed method achieves state-of-the-art
performance.

</details>


### [60] [Variance-Based Pruning for Accelerating and Compressing Trained Networks](https://arxiv.org/abs/2507.12988)
*Uranik Berisha,Jens Mehnert,Alexandru Paul Condurache*

Main category: cs.CV

TL;DR: 一种新的剪枝技术（Variance-Based Pruning）可以高效压缩模型，只需少量微调即可恢复性能，并显著减少计算量和模型尺寸。


<details>
  <summary>Details</summary>
Motivation: 为了解决在资源受限的硬件上部署大型模型（如Vision Transformers）所面临的延迟、高计算成本和内存需求等挑战，并克服现有结构化剪枝方法需要昂贵或从头开始的重新训练的问题。

Method: Variance-Based Pruning是一种结构化、一次性的剪枝技术。它首先收集激活统计数据，然后利用这些数据选择要剪枝的神经元。同时，它将平均激活值整合回模型，以保持高性能。

Result: 在ImageNet-1k识别任务上，DeiT-Base模型在剪枝后能保留超过70%的原始性能，仅需10个epoch的微调即可恢复99%的原始准确率，同时实现了35%的MACs减少和36%的模型尺寸减小，模型速度提升1.44倍。

Conclusion: 本研究提出了一种名为Variance-Based Pruning的结构化剪枝技术，该技术能够有效地压缩模型，同时最大限度地减少微调时间。通过收集激活统计数据来选择神经元进行剪枝，并将平均激活值整合回模型以保持性能。

Abstract: Increasingly expensive training of ever larger models such as Vision
Transfomers motivate reusing the vast library of already trained
state-of-the-art networks. However, their latency, high computational costs and
memory demands pose significant challenges for deployment, especially on
resource-constrained hardware. While structured pruning methods can reduce
these factors, they often require costly retraining, sometimes for up to
hundreds of epochs, or even training from scratch to recover the lost accuracy
resulting from the structural modifications. Maintaining the provided
performance of trained models after structured pruning and thereby avoiding
extensive retraining remains a challenge. To solve this, we introduce
Variance-Based Pruning, a simple and structured one-shot pruning technique for
efficiently compressing networks, with minimal finetuning. Our approach first
gathers activation statistics, which are used to select neurons for pruning.
Simultaneously the mean activations are integrated back into the model to
preserve a high degree of performance. On ImageNet-1k recognition tasks, we
demonstrate that directly after pruning DeiT-Base retains over 70% of its
original performance and requires only 10 epochs of fine-tuning to regain 99%
of the original accuracy while simultaneously reducing MACs by 35% and model
size by 36%, thus speeding up the model by 1.44x.

</details>


### [61] [Differential-informed Sample Selection Accelerates Multimodal Contrastive Learning](https://arxiv.org/abs/2507.12998)
*Zihua Zhao,Feng Hong,Mengxi Chen,Pengyi Chen,Benyuan Liu,Jiangchao Yao,Ya Zhang,Yanfeng Wang*

Main category: cs.CV

TL;DR: DISSect是一种新的样本选择方法，通过比较当前模型和历史模型的预测相关性之间的差异来识别和处理噪声数据，从而加速训练过程，并在多项实验中表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 对比学习驱动的多模态模型的成功很大程度上依赖于在更大数据集上进行训练，这需要昂贵的计算资源。因此，样本选择作为一种替代的高效范式，在加速训练过程中扮演着重要角色。然而，现有的样本选择方法要么依赖于一个预先选择好的高质量核心集，这在冷启动场景下能力有限；要么侧重于基于实时模型预测的在线选择，但没有充分或有效地考虑噪声对应关系。

Method: 提出了一种新颖的差分信息采样选择（DISSect）方法，该方法能够准确有效地区分噪声对应关系，从而加速训练过程。该方法基于以下假设：当前模型预测的相关性与历史模型的预测相关性之间的差分更能表征样本质量。

Result: DISSect方法能够准确有效地识别和处理噪声对应关系，从而加速对比学习模型的训练过程。

Conclusion: DISSect方法在三个基准数据集和各种下游任务上的广泛实验证明了其在当前最先进方法上的持续优越性。

Abstract: The remarkable success of contrastive-learning-based multimodal models has
been greatly driven by training on ever-larger datasets with expensive compute
consumption. Sample selection as an alternative efficient paradigm plays an
important direction to accelerate the training process. However, recent
advances on sample selection either mostly rely on an oracle model to offline
select a high-quality coreset, which is limited in the cold-start scenarios, or
focus on online selection based on real-time model predictions, which has not
sufficiently or efficiently considered the noisy correspondence. To address
this dilemma, we propose a novel Differential-Informed Sample Selection
(DISSect) method, which accurately and efficiently discriminates the noisy
correspondence for training acceleration. Specifically, we rethink the impact
of noisy correspondence on contrastive learning and propose that the
differential between the predicted correlation of the current model and that of
a historical model is more informative to characterize sample quality. Based on
this, we construct a robust differential-based sample selection and analyze its
theoretical insights. Extensive experiments on three benchmark datasets and
various downstream tasks demonstrate the consistent superiority of DISSect over
current state-of-the-art methods. Source code is available at:
https://github.com/MediaBrain-SJTU/DISSect.

</details>


### [62] [Beyond Fully Supervised Pixel Annotations: Scribble-Driven Weakly-Supervised Framework for Image Manipulation Localization](https://arxiv.org/abs/2507.13018)
*Songlin Li,Guofeng Yu,Zhiqing Guo,Yunfeng Diao,Dan Ma,Gaobo Yang,Liejun Wang*

Main category: cs.CV

TL;DR: 提出了一种新的基于涂鸦标注的弱监督图像篡改定位方法，通过引入创新的模块和损失函数，在提高标注效率的同时，取得了优于全监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决获取高质量像素级标注的挑战，并提升弱监督方法中因监督信号不足而导致的性能限制，探索了涂鸦标注监督这种提高标注效率和检测性能的弱监督形式。

Method: 提出了一种基于涂鸦的弱监督图像篡改定位框架，包括自监督训练、结构一致性损失、先验感知特征调制模块（PFMM）、门控自适应融合模块（GAFM）和置信度感知熵最小化损失（${\mathcal{L}}_{ {CEM }}$）。

Result: 实验结果表明，该方法在in-distribution和out-of-distribution的平均表现上均优于现有的全监督方法。

Conclusion: 该方法在in-distribution和out-of-distribution的平均表现均优于现有的全监督方法。

Abstract: Deep learning-based image manipulation localization (IML) methods have
achieved remarkable performance in recent years, but typically rely on
large-scale pixel-level annotated datasets. To address the challenge of
acquiring high-quality annotations, some recent weakly supervised methods
utilize image-level labels to segment manipulated regions. However, the
performance is still limited due to insufficient supervision signals. In this
study, we explore a form of weak supervision that improves the annotation
efficiency and detection performance, namely scribble annotation supervision.
We re-annotated mainstream IML datasets with scribble labels and propose the
first scribble-based IML (Sc-IML) dataset. Additionally, we propose the first
scribble-based weakly supervised IML framework. Specifically, we employ
self-supervised training with a structural consistency loss to encourage the
model to produce consistent predictions under multi-scale and augmented inputs.
In addition, we propose a prior-aware feature modulation module (PFMM) that
adaptively integrates prior information from both manipulated and authentic
regions for dynamic feature adjustment, further enhancing feature
discriminability and prediction consistency in complex scenes. We also propose
a gated adaptive fusion module (GAFM) that utilizes gating mechanisms to
regulate information flow during feature fusion, guiding the model toward
emphasizing potential tampered regions. Finally, we propose a confidence-aware
entropy minimization loss (${\mathcal{L}}_{ {CEM }}$). This loss dynamically
regularizes predictions in weakly annotated or unlabeled regions based on model
uncertainty, effectively suppressing unreliable predictions. Experimental
results show that our method outperforms existing fully supervised approaches
in terms of average performance both in-distribution and out-of-distribution.

</details>


### [63] [Resurrect Mask AutoRegressive Modeling for Efficient and Scalable Image Generation](https://arxiv.org/abs/2507.13032)
*Yi Xin,Le Zhuo,Qi Qin,Siqi Luo,Yuewen Cao,Bin Fu,Yangfan He,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Peng Gao*

Main category: cs.CV

TL;DR: MaskGIL改进了掩码自回归模型，实现了与先进自回归模型相当的图像生成质量，同时推理速度更快，并可用于文本到图像生成。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统掩码自回归（MAR）模型在图像生成质量上落后于标准自回归（AR）模型的问题，并提高MAR模型的效率。

Method: 通过评估不同的图像分词器，并引入改进的双向LLaMA架构（用双向注意力替换因果注意力并结合2D RoPE），最终形成MaskGIL模型。

Result: MaskGIL模型（从1.11亿参数扩展到14亿参数）在ImageNet 256x256基准测试中达到了3.71的FID分数，与最先进的AR模型相当，但推理步数从256减少到8。文本驱动的MaskGIL（7.75亿参数）实现了文本到图像生成。

Conclusion: MaskGIL通过采用双向注意力、2D RoPE和改进的图像分词器，在图像生成质量上取得了显著进步，能够与最先进的自回归模型相媲美，同时大大减少了推理步数。此外，MaskGIL还通过文本驱动的版本扩展到文本到图像生成，并应用于加速自回归生成和实现实时语音到图像转换。

Abstract: AutoRegressive (AR) models have made notable progress in image generation,
with Masked AutoRegressive (MAR) models gaining attention for their efficient
parallel decoding. However, MAR models have traditionally underperformed when
compared to standard AR models. This study refines the MAR architecture to
improve image generation quality. We begin by evaluating various image
tokenizers to identify the most effective one. Subsequently, we introduce an
improved Bidirectional LLaMA architecture by replacing causal attention with
bidirectional attention and incorporating 2D RoPE, which together form our
advanced model, MaskGIL. Scaled from 111M to 1.4B parameters, MaskGIL achieves
a FID score of 3.71, matching state-of-the-art AR models in the ImageNet
256x256 benchmark, while requiring only 8 inference steps compared to the 256
steps of AR models. Furthermore, we develop a text-driven MaskGIL model with
775M parameters for generating images from text at various resolutions. Beyond
image generation, MaskGIL extends to accelerate AR-based generation and enable
real-time speech-to-image conversion. Our codes and models are available at
https://github.com/synbol/MaskGIL.

</details>


### [64] [Advancing Complex Wide-Area Scene Understanding with Hierarchical Coresets Selection](https://arxiv.org/abs/2507.13061)
*Jingyao Wang,Yiming Chen,Lingyu Si,Changwen Zheng*

Main category: cs.CV

TL;DR: HCS 是一种用于提高 VLM 在复杂广域场景理解能力的新方法，无需微调即可快速适应新场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉语言模型 (VLM) 在适应看不见的复杂广域场景方面仍然存在的挑战。

Method: 提出了一种分层核心集选择 (HCS) 机制，通过一种理论上保证的、考虑了效用、代表性、鲁棒性和协同效应的重要性函数，对所选区域进行渐进式细化。

Result: HCS 能够在无需额外微调的情况下，以最小的可解释区域快速理解任何规模下看不见的场景，同时缓解了特征密度不足的问题。

Conclusion: HCS 是一种即插即用、可与任何 VLM 兼容的方法，在各种任务中实现了卓越的性能和通用性。

Abstract: Scene understanding is one of the core tasks in computer vision, aiming to
extract semantic information from images to identify objects, scene categories,
and their interrelationships. Although advancements in Vision-Language Models
(VLMs) have driven progress in this field, existing VLMs still face challenges
in adaptation to unseen complex wide-area scenes. To address the challenges,
this paper proposes a Hierarchical Coresets Selection (HCS) mechanism to
advance the adaptation of VLMs in complex wide-area scene understanding. It
progressively refines the selected regions based on the proposed theoretically
guaranteed importance function, which considers utility, representativeness,
robustness, and synergy. Without requiring additional fine-tuning, HCS enables
VLMs to achieve rapid understandings of unseen scenes at any scale using
minimal interpretable regions while mitigating insufficient feature density.
HCS is a plug-and-play method that is compatible with any VLM. Experiments
demonstrate that HCS achieves superior performance and universality in various
tasks.

</details>


### [65] [Label-Consistent Dataset Distillation with Detector-Guided Refinement](https://arxiv.org/abs/2507.13074)
*Yawen Zou,Guang Li,Zi Wang,Chunzhi Gu,Chao Zhang*

Main category: cs.CV

TL;DR: 提出了一种检测器引导的数据集蒸馏方法，利用预训练检测器来识别和修正有标签不一致或低置信度的合成样本，并通过选择与现有样本相似度高的候选图像来保证标签准确性和类别内多样性，最终生成高质量的数据集以提升下游性能。


<details>
  <summary>Details</summary>
Motivation: 数据集蒸馏（DD）旨在生成一个紧凑但信息丰富的数据集，其性能与原始数据集相当，从而减少存储和计算资源的需求。尽管扩散模型在数据集蒸馏方面取得了显著进展，但生成的替代数据集通常包含标签不一致或结构细节不足的样本，导致下游性能不佳。

Method: 提出了一种检测器引导的数据集蒸馏框架，利用预训练的检测器来识别和完善异常的合成样本，以确保标签一致性和提高图像质量。具体来说，使用在原始数据集上训练的检测器模型来识别存在标签不匹配或低分类置信度的异常图像。对于每个有缺陷的图像，使用基于相应图像原型和标签的预训练扩散模型生成多个候选图像。通过综合考虑检测器的置信分数和与现有合格合成样本的差异性，来选择最佳候选图像，从而确保标签的准确性和类别内多样性。

Result: 生成的数据集包含具有更丰富细节的高质量代表性图像，并且在验证集上实现了最先进的性能。

Conclusion: 实验结果表明，该方法能够合成具有更丰富细节的高质量代表性图像，并在验证集上实现了最先进的性能。

Abstract: Dataset distillation (DD) aims to generate a compact yet informative dataset
that achieves performance comparable to the original dataset, thereby reducing
demands on storage and computational resources. Although diffusion models have
made significant progress in dataset distillation, the generated surrogate
datasets often contain samples with label inconsistencies or insufficient
structural detail, leading to suboptimal downstream performance. To address
these issues, we propose a detector-guided dataset distillation framework that
explicitly leverages a pre-trained detector to identify and refine anomalous
synthetic samples, thereby ensuring label consistency and improving image
quality. Specifically, a detector model trained on the original dataset is
employed to identify anomalous images exhibiting label mismatches or low
classification confidence. For each defective image, multiple candidates are
generated using a pre-trained diffusion model conditioned on the corresponding
image prototype and label. The optimal candidate is then selected by jointly
considering the detector's confidence score and dissimilarity to existing
qualified synthetic samples, thereby ensuring both label accuracy and
intra-class diversity. Experimental results demonstrate that our method can
synthesize high-quality representative images with richer details, achieving
state-of-the-art performance on the validation set.

</details>


### [66] [Channel-wise Motion Features for Efficient Motion Segmentation](https://arxiv.org/abs/2507.13082)
*Riku Inoue,Masamitsu Tsuchiya,Yuji Yasui*

Main category: cs.CV

TL;DR: 提出通道运动特征（Channel-wise Motion Features），一种新颖高效的运动分割方法，仅需姿态网络即可实现高 FPS 和准确率，显著降低计算成本和参数量。


<details>
  <summary>Details</summary>
Motivation: 为了提高安全关键型机器人应用（如自动驾驶）的实时性能，需要一种比现有运动分割模型更高效的解决方案。现有模型通常需要联合使用深度、姿态、光流和场景流子网络，导致计算成本增加。

Method: 提出了一种新颖的基于成本体积的运动特征表示，即通道运动特征（Channel-wise Motion Features）。该方法仅使用姿态网络（Pose Network）来提取每个实例的深度特征并捕捉场景的 3D 运动信息，从而提高了效率。

Result: 通道运动特征（Channel-wise Motion Features）在 KITTI 数据集、Cityscapes 和 VCAS-Motion 数据集上实现了约 4 倍的 FPS 提升，同时参数量减少了约 75%，准确率相当。

Conclusion: 该方法在 KITTI 数据集、Cityscapes 和 VCAS-Motion 数据集上实现了比现有方法快 4 倍的 FPS，同时参数量减少到约 25%，准确率相当，证明了其效率和性能。

Abstract: For safety-critical robotics applications such as autonomous driving, it is
important to detect all required objects accurately in real-time. Motion
segmentation offers a solution by identifying dynamic objects from the scene in
a class-agnostic manner. Recently, various motion segmentation models have been
proposed, most of which jointly use subnetworks to estimate Depth, Pose,
Optical Flow, and Scene Flow. As a result, the overall computational cost of
the model increases, hindering real-time performance.
  In this paper, we propose a novel cost-volume-based motion feature
representation, Channel-wise Motion Features. By extracting depth features of
each instance in the feature map and capturing the scene's 3D motion
information, it offers enhanced efficiency. The only subnetwork used to build
Channel-wise Motion Features is the Pose Network, and no others are required.
Our method not only achieves about 4 times the FPS of state-of-the-art models
in the KITTI Dataset and Cityscapes of the VCAS-Motion Dataset, but also
demonstrates equivalent accuracy while reducing the parameters to about 25$\%$.

</details>


### [67] [Decoupled PROB: Decoupled Query Initialization Tasks and Objectness-Class Learning for Open World Object Detection](https://arxiv.org/abs/2507.13085)
*Riku Inoue,Masamitsu Tsuchiya,Yuji Yasui*

Main category: cs.CV

TL;DR: Decoupled PROB通过ETOP解决学习冲突，TDQI提升特征提取，在OWOD任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为解决PROB模型在对象性和类别预测之间存在学习冲突以及进一步提升性能的问题，提出了一种新颖的Decoupled PROB模型。

Method: Decoupled PROB模型通过引入早期终止对象性预测（ETOP）来解决PROB模型中对象性和类别预测之间的学习冲突，并利用任务解耦查询初始化（TDQI）来有效提取已知和未知对象的特征，从而提高性能。TDQI是一种结合查询选择和可学习查询的查询初始化方法，可以轻松集成到现有的基于DETR的OWOD模型中。

Result: Decoupled PROB模型在OWOD基准测试中，在多项指标上均超越了现有方法，显著提升了性能。

Conclusion: Decoupled PROB模型在OWOD基准测试中超越了所有现有方法，并在多项指标上显著提升了性能。

Abstract: Open World Object Detection (OWOD) is a challenging computer vision task that
extends standard object detection by (1) detecting and classifying unknown
objects without supervision, and (2) incrementally learning new object classes
without forgetting previously learned ones. The absence of ground truths for
unknown objects makes OWOD tasks particularly challenging. Many methods have
addressed this by using pseudo-labels for unknown objects. The recently
proposed Probabilistic Objectness transformer-based open-world detector (PROB)
is a state-of-the-art model that does not require pseudo-labels for unknown
objects, as it predicts probabilistic objectness. However, this method faces
issues with learning conflicts between objectness and class predictions.
  To address this issue and further enhance performance, we propose a novel
model, Decoupled PROB. Decoupled PROB introduces Early Termination of
Objectness Prediction (ETOP) to stop objectness predictions at appropriate
layers in the decoder, resolving the learning conflicts between class and
objectness predictions in PROB. Additionally, we introduce Task-Decoupled Query
Initialization (TDQI), which efficiently extracts features of known and unknown
objects, thereby improving performance. TDQI is a query initialization method
that combines query selection and learnable queries, and it is a module that
can be easily integrated into existing DETR-based OWOD models. Extensive
experiments on OWOD benchmarks demonstrate that Decoupled PROB surpasses all
existing methods across several metrics, significantly improving performance.

</details>


### [68] [DiffOSeg: Omni Medical Image Segmentation via Multi-Expert Collaboration Diffusion Model](https://arxiv.org/abs/2507.13087)
*Han Zhang,Xiangde Luo,Yong Chen,Kang Li*

Main category: cs.CV

TL;DR: DiffOSeg 是一种新的两阶段扩散模型，可以同时学习医学图像分割的共识和专家偏好，并在两个数据集上超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中由于成像边界模糊和临床专业知识多样性而导致的注释变异性问题，并克服现有方法仅能捕捉单一视角（概率共识或专家特定偏好）的局限性。

Method: 提出了一种名为 DiffOSeg 的两阶段扩散模型框架，旨在同时实现共识驱动（结合所有专家的意见）和偏好驱动（反映专家个人评估）的分割。第一阶段通过概率共识策略建立群体共识，第二阶段通过自适应提示捕捉专家特定偏好。

Result: DiffOSeg 在两个公共数据集（LIDC-IDRI 和 NPC-170）上进行了验证，并在所有评估指标上均取得了优于现有 state-of-the-art 方法的结果。

Conclusion: DiffOSeg 模型在 LIDC-IDRI 和 NPC-170 两个公共数据集上，相较于现有的 state-of-the-art 方法，在所有评估指标上均表现更优。

Abstract: Annotation variability remains a substantial challenge in medical image
segmentation, stemming from ambiguous imaging boundaries and diverse clinical
expertise. Traditional deep learning methods producing single deterministic
segmentation predictions often fail to capture these annotator biases. Although
recent studies have explored multi-rater segmentation, existing methods
typically focus on a single perspective -- either generating a probabilistic
``gold standard'' consensus or preserving expert-specific preferences -- thus
struggling to provide a more omni view. In this study, we propose DiffOSeg, a
two-stage diffusion-based framework, which aims to simultaneously achieve both
consensus-driven (combining all experts' opinions) and preference-driven
(reflecting experts' individual assessments) segmentation. Stage I establishes
population consensus through a probabilistic consensus strategy, while Stage II
captures expert-specific preference via adaptive prompts. Demonstrated on two
public datasets (LIDC-IDRI and NPC-170), our model outperforms existing
state-of-the-art methods across all evaluated metrics. Source code is available
at https://github.com/string-ellipses/DiffOSeg .

</details>


### [69] [GLAD: Generalizable Tuning for Vision-Language Models](https://arxiv.org/abs/2507.13089)
*Yuqi Peng,Pengfei Wang,Jianzhuang Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: GLAD是一种结合LoRA和梯度正则化的新框架，用于提高视觉-语言模型在少样本学习中的泛化能力，并且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示调优方法在少样本场景下容易过拟合，并且需要复杂的特定任务模型架构和敏感的超参数调整，限制了其通用性。

Method: 提出了一种名为GLAD（Generalizable LoRA tuning with RegulArized GraDient）的框架，该框架结合了LoRA（Low-Rank Adaptation）和一种梯度正则化技术，以解决预训练视觉-语言模型在少样本学习场景下面临的过拟合和模型复杂性问题。

Result: GLAD在15个基准数据集上的表现优于现有的调优方法，尤其在泛化能力方面。

Conclusion: GLAD通过引入基于梯度的正则化技术，在少样本学习场景下有效缓解了LoRA的过拟合问题，并在15个基准数据集的实验中，在从基类到新类泛化、图像域泛化和跨数据集泛化方面均优于现有的提示调优方法。

Abstract: Pre-trained vision-language models, such as CLIP, show impressive zero-shot
recognition ability and can be easily transferred to specific downstream tasks
via prompt tuning, even with limited training data. However, existing prompt
tuning methods face two main challenges: (1) In few-shot scenarios, data
scarcity often leads to overfitting, making the model sensitive to changes in
the input domain. (2) To mitigate overfitting, these methods typically rely on
complex task-specific model architectures and sensitive hyperparameter tuning,
severely restricting their general applicability. To address these issues, we
propose a simpler and more general framework called GLAD (Generalizable LoRA
tuning with RegulArized GraDient). We show that merely applying LoRA achieves
performance in downstream tasks comparable to current state-of-the-art
prompt-based methods. While LoRA is effective and easy to use, it remains
susceptible to overfitting in few-shot learning scenarios. To mitigate this
risk, we introduce a gradient-based regularization technique. This technique
effectively steers the optimization trajectory, encouraging the model to find a
more stable parameter region that is robust to variations in data distribution.
Through extensive experiments conducted on 15 benchmark datasets, we
demonstrate that GLAD outperforms previous tuning approaches in terms of
base-to-novel class generalization, image domain generalization, and
cross-dataset generalization. The code will be publicly available.

</details>


### [70] [Deep Learning-Based Fetal Lung Segmentation from Diffusion-weighted MRI Images and Lung Maturity Evaluation for Fetal Growth Restriction](https://arxiv.org/abs/2507.13106)
*Zhennan Xiao,Katharine Brudkiewicz,Zhen Yuan,Rosalind Aughwane,Magdalena Sokolska,Joanna Chappell,Trevor Gaunt,Anna L. David,Andrew P. King,Andrew Melbourne*

Main category: cs.CV

TL;DR: 本研究提出了一种全自动化的胎儿肺成熟度评估流程，结合了深度学习分割和模型拟合，可用于临床决策。


<details>
  <summary>Details</summary>
Motivation: 胎儿肺成熟度是预测新生儿结局和产后干预需求的关键指标，尤其对于受胎儿生长受限影响的妊娠。本研究旨在开发一种自动化的肺成熟度评估流程，以解决现有基于IVIM分析方法的耗时性问题。

Method: 提出了一种基于深度学习的胎儿肺部分模型和基于模型的肺成熟度评估方法，并使用3D nnU-Net模型在手动分割的图像上进行训练，以量化反映组织微观结构和灌注的IVIM参数。

Result: 基于nnU-Net预测的分割和手动分割的IVIM参数量化结果显示无显著差异，表明自动化流程具有可行性。

Conclusion: 该研究表明，全自动化流程在支持胎儿肺成熟评估和临床决策方面是可行的。

Abstract: Fetal lung maturity is a critical indicator for predicting neonatal outcomes
and the need for post-natal intervention, especially for pregnancies affected
by fetal growth restriction. Intra-voxel incoherent motion analysis has shown
promising results for non-invasive assessment of fetal lung development, but
its reliance on manual segmentation is time-consuming, thus limiting its
clinical applicability. In this work, we present an automated lung maturity
evaluation pipeline for diffusion-weighted magnetic resonance images that
consists of a deep learning-based fetal lung segmentation model and a
model-fitting lung maturity assessment. A 3D nnU-Net model was trained on
manually segmented images selected from the baseline frames of 4D
diffusion-weighted MRI scans. The segmentation model demonstrated robust
performance, yielding a mean Dice coefficient of 82.14%. Next, voxel-wise model
fitting was performed based on both the nnU-Net-predicted and manual lung
segmentations to quantify IVIM parameters reflecting tissue microstructure and
perfusion. The results suggested no differences between the two. Our work shows
that a fully automated pipeline is possible for supporting fetal lung maturity
assessment and clinical decision-making.

</details>


### [71] [R^2MoE: Redundancy-Removal Mixture of Experts for Lifelong Concept Learning](https://arxiv.org/abs/2507.13107)
*Xiaohan Guo,Yusong Cai,Zejia Liu,Zhengning Wang,Lili Pan,Hongliang Li*

Main category: cs.CV

TL;DR: R^2MoE 是一种新的参数高效框架，通过混合专家和特定机制解决了持续视觉概念学习中的遗忘和参数扩展问题，实验结果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 为了使大规模生成模型能够持续学习新的视觉概念，以满足个性化预训练模型以适应个人用户偏好，同时克服灾难性遗忘和参数扩展的挑战。

Method: 提出了一种名为 R^2MoE 的参数高效框架，该框架采用混合专家模型，并结合了路由蒸馏机制、冗余专家消除策略以及分层局部注意力机制。

Result: R^2MoE 在 CustomConcept 101 数据集上实现了 87.8% 的遗忘率降低和 63.3% 的参数量减少，生成的图像在概念保真度上优于 SOTA 方法。

Conclusion: R^2MoE 通过其专家蒸馏机制、冗余专家消除策略和分层局部注意力机制，有效解决了灾难性遗忘和参数扩展问题，实现了高效的持续视觉概念学习。实验证明，该方法在 CustomConcept 101 数据集上显著减少了遗忘率（87.8%）并降低了参数量（63.3%），同时提高了概念保真度，优于现有 SOTA 方法。

Abstract: Enabling large-scale generative models to continuously learn new visual
concepts is essential for personalizing pre-trained models to meet individual
user preferences. Existing approaches for continual visual concept learning are
constrained by two fundamental challenges: catastrophic forgetting and
parameter expansion. In this paper, we propose Redundancy-Removal Mixture of
Experts (R^2MoE), a parameter-efficient framework for lifelong visual concept
learning that effectively learns new concepts while incurring minimal parameter
overhead. Our framework includes three key innovative contributions: First, we
propose a mixture-of-experts framework with a routing distillation mechanism
that enables experts to acquire concept-specific knowledge while preserving the
gating network's routing capability, thereby effectively mitigating
catastrophic forgetting. Second, we propose a strategy for eliminating
redundant layer-wise experts that reduces the number of expert parameters by
fully utilizing previously learned experts. Third, we employ a hierarchical
local attention-guided inference approach to mitigate interference between
generated visual concepts. Extensive experiments have demonstrated that our
method generates images with superior conceptual fidelity compared to the
state-of-the-art (SOTA) method, achieving an impressive 87.8\% reduction in
forgetting rates and 63.3\% fewer parameters on the CustomConcept 101 dataset.
Our code is available at {https://github.com/learninginvision/R2MoE}

</details>


### [72] [3DKeyAD: High-Resolution 3D Point Cloud Anomaly Detection via Keypoint-Guided Point Clustering](https://arxiv.org/abs/2507.13110)
*Zi Wang,Katsuya Hotta,Koichiro Kamide,Yawen Zou,Chao Zhang,Jun Yu*

Main category: cs.CV

TL;DR: 一种新的3D点云异常检测框架，通过多原型对齐和关键点引导聚类，提高了检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决高分辨率3D点云在工业检测中检测细微结构异常时面临的计算成本高、空间失准敏感以及难以捕捉局部结构差异的挑战。

Method: 提出了一种基于配准的异常检测框架，结合了多原型对齐和聚类分析，并通过关键点引导策略选择聚类中心，以实现精确的3D异常定位。

Result: 实现了精确的3D异常定位，并在Real3D-AD基准测试中在物体级别和点级别异常检测方面均取得了最先进的性能。

Conclusion: 该方法在Real3D-AD基准测试中实现了最先进的物体级别和点级别异常检测性能，即使仅使用原始特征。

Abstract: High-resolution 3D point clouds are highly effective for detecting subtle
structural anomalies in industrial inspection. However, their dense and
irregular nature imposes significant challenges, including high computational
cost, sensitivity to spatial misalignment, and difficulty in capturing
localized structural differences. This paper introduces a registration-based
anomaly detection framework that combines multi-prototype alignment with
cluster-wise discrepancy analysis to enable precise 3D anomaly localization.
Specifically, each test sample is first registered to multiple normal
prototypes to enable direct structural comparison. To evaluate anomalies at a
local level, clustering is performed over the point cloud, and similarity is
computed between features from the test sample and the prototypes within each
cluster. Rather than selecting cluster centroids randomly, a keypoint-guided
strategy is employed, where geometrically informative points are chosen as
centroids. This ensures that clusters are centered on feature-rich regions,
enabling more meaningful and stable distance-based comparisons. Extensive
experiments on the Real3D-AD benchmark demonstrate that the proposed method
achieves state-of-the-art performance in both object-level and point-level
anomaly detection, even using only raw features.

</details>


### [73] [Leveraging Language Prior for Infrared Small Target Detection](https://arxiv.org/abs/2507.13113)
*Pranav Singh,Pravendra Singh*

Main category: cs.CV

TL;DR: 该研究通过引入GPT-4生成的文本描述和创建的多模态数据集，提出了一种利用语言先验指导红外小目标检测的新方法，并在多个基准测试中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的红外小目标检测（IRSTD）方法主要依赖于图像模态，但在处理小目标和稀疏分布时面临挑战。本研究旨在通过引入语言先验来丰富信息来源，从而提高IRSTD的性能。

Method: 本研究提出了一种利用语言先验来指导红外小目标检测（IRSTD）的多模态框架。该框架利用从语言先验中提取的语言引导注意力权重来增强模型的IRSTD能力。具体而言，利用GPT-4视觉模型生成包含小目标位置的文本描述，并结合精心设计的提示工程来提高准确性。此外，研究人员还创建了一个包含图像和文本模态的多模态红外数据集，以解决现有IRSTD方法仅依赖图像数据的局限性。

Result: 通过广泛的实验和消融研究，本研究提出的多模态框架在NUAA-SIRST和IRSTD-1k数据集上均取得了显著的性能提升。与最先进的方法相比，在NUAA-SIRST子集上，IoU、nIoU、Pd和Fa的相对百分比差异分别为9.74%、13.02%、1.25%和67.87%。在IRSTD-1k子集上，这些指标的相对百分比差异分别为4.41%、2.04%、2.01%和113.43%。

Conclusion: 本研究提出了一个新颖的多模态IRSTD框架，该框架结合了语言先验来指导小目标检测，并在NUAA-SIRST和IRSTD-1k数据集上取得了显著的性能提升。

Abstract: IRSTD (InfraRed Small Target Detection) detects small targets in infrared
blurry backgrounds and is essential for various applications. The detection
task is challenging due to the small size of the targets and their sparse
distribution in infrared small target datasets. Although existing IRSTD methods
and datasets have led to significant advancements, they are limited by their
reliance solely on the image modality. Recent advances in deep learning and
large vision-language models have shown remarkable performance in various
visual recognition tasks. In this work, we propose a novel multimodal IRSTD
framework that incorporates language priors to guide small target detection. We
leverage language-guided attention weights derived from the language prior to
enhance the model's ability for IRSTD, presenting a novel approach that
combines textual information with image data to improve IRSTD capabilities.
Utilizing the state-of-the-art GPT-4 vision model, we generate text
descriptions that provide the locations of small targets in infrared images,
employing careful prompt engineering to ensure improved accuracy. Due to the
absence of multimodal IR datasets, existing IRSTD methods rely solely on image
data. To address this shortcoming, we have curated a multimodal infrared
dataset that includes both image and text modalities for small target
detection, expanding upon the popular IRSTD-1k and NUDT-SIRST datasets. We
validate the effectiveness of our approach through extensive experiments and
comprehensive ablation studies. The results demonstrate significant
improvements over the state-of-the-art method, with relative percentage
differences of 9.74%, 13.02%, 1.25%, and 67.87% in IoU, nIoU, Pd, and Fa on the
NUAA-SIRST subset, and 4.41%, 2.04%, 2.01%, and 113.43% on the IRSTD-1k subset
of the LangIR dataset, respectively.

</details>


### [74] [RS-TinyNet: Stage-wise Feature Fusion Network for Detecting Tiny Objects in Remote Sensing Images](https://arxiv.org/abs/2507.13120)
*Xiaozheng Jiang,Wei Zhang,Xuerui Mao*

Main category: cs.CV

TL;DR: 提出RS-TinyNet模型，通过引入显著性建模和特征重建机制，并结合MDCA、ARB、PFDH等模块，有效提升了遥感图像中微小目标的检测精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中的微小物体检测一直是一个挑战，因为它们具有有限的空间信息、薄弱的特征表示以及在复杂背景下密集分布的特点。现有主流检测器在这种场景下表现不佳，存在提升空间。

Method: 提出了一种名为RS-TinyNet的多阶段特征融合与增强模型，包含微小物体显著性建模和特征完整性重建两个核心设计。具体包括多维度协同注意力（MDCA）模块以增强微小物体显著性，辅助可逆分支（ARB）和渐进式融合检测头（PFDH）模块以保留信息流并融合多层次特征，从而弥合语义鸿沟并保留结构细节。

Result: 在公开的AI-TOD数据集上，RS-TinyNet相比现有的SOTA检测器，AP提升了4.0%，AP75提升了6.5%。在DIOR数据集上的评估进一步验证了其在多样化遥感场景下的优越检测性能。

Conclusion: RS-TinyNet模型通过多阶段特征融合策略，为复杂遥感环境下的微小物体检测提供了有效且实用的解决方案，在AI-TOD和DIOR数据集上均展现出优于现有SOTA检测器的性能。

Abstract: Detecting tiny objects in remote sensing (RS) imagery has been a
long-standing challenge due to their extremely limited spatial information,
weak feature representations, and dense distributions across complex
backgrounds. Despite numerous efforts devoted, mainstream detectors still
underperform in such scenarios. To bridge this gap, we introduce RS-TinyNet, a
multi-stage feature fusion and enhancement model explicitly tailored for RS
tiny object detection in various RS scenarios. RS-TinyNet comes with two novel
designs: tiny object saliency modeling and feature integrity reconstruction.
Guided by these principles, we design three step-wise feature enhancement
modules. Among them, the multi-dimensional collaborative attention (MDCA)
module employs multi-dimensional attention to enhance the saliency of tiny
objects. Additionally, the auxiliary reversible branch (ARB) and a progressive
fusion detection head (PFDH) module are introduced to preserve information flow
and fuse multi-level features to bridge semantic gaps and retain structural
detail. Comprehensive experiments on public RS dataset AI-TOD show that our
RS-TinyNet surpasses existing state-of-the-art (SOTA) detectors by 4.0% AP and
6.5% AP75. Evaluations on DIOR benchmark dataset further validate its superior
detection performance in diverse RS scenarios. These results demonstrate that
the proposed multi-stage feature fusion strategy offers an effective and
practical solution for tiny object detection in complex RS environments.

</details>


### [75] [Orbis: Overcoming Challenges of Long-Horizon Prediction in Driving World Models](https://arxiv.org/abs/2507.13162)
*Arian Mousakhan,Sudhanshu Mittal,Silvio Galesso,Karim Farid,Thomas Brox*

Main category: cs.CV

TL;DR: 本研究提出的自动驾驶世界模型在处理长时序生成和复杂场景方面表现出色，优于现有模型，并且连续自回归模型比离散token模型效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶世界模型在长时序生成和泛化到复杂场景方面存在不足，本研究旨在开发一个更高效、更通用的模型。

Method: 本研究采用了一种简单的设计，没有额外的监督或传感器（如地图、深度或多个摄像头），开发了一个用于自动驾驶的世界模型。通过设置一个兼容离散token和连续模型（基于流匹配）的混合token器，并进行了并排比较，最终得出结论：连续自回归模型优于离散token模型。

Result: 与现有模型相比，本研究提出的模型在长时序生成和泛化到复杂场景方面取得了最先进的性能，尤其在转弯机动和城市交通等困难场景中表现突出。连续自回归模型比离散token模型更强大且鲁棒性更强。

Conclusion: 现有的自动驾驶世界模型在长时序生成和泛化到复杂场景方面存在困难。本研究提出的模型在参数量仅为4.69亿且仅在280小时视频数据上进行训练的情况下，在这些方面取得了最先进的性能，尤其在转弯机动和城市交通等困难场景中表现突出。研究还比较了离散token模型和基于流匹配的连续模型，结论是有利的于连续自回归模型，其对单独设计选择的鲁棒性更强，并且比基于离散token的模型更强大。

Abstract: Existing world models for autonomous driving struggle with long-horizon
generation and generalization to challenging scenarios. In this work, we
develop a model using simple design choices, and without additional supervision
or sensors, such as maps, depth, or multiple cameras. We show that our model
yields state-of-the-art performance, despite having only 469M parameters and
being trained on 280h of video data. It particularly stands out in difficult
scenarios like turning maneuvers and urban traffic. We test whether discrete
token models possibly have advantages over continuous models based on flow
matching. To this end, we set up a hybrid tokenizer that is compatible with
both approaches and allows for a side-by-side comparison. Our study concludes
in favor of the continuous autoregressive model, which is less brittle on
individual design choices and more powerful than the model built on discrete
tokens. Code, models and qualitative results are publicly available at
https://lmb-freiburg.github.io/orbis.github.io/.

</details>


### [76] [Synthesizing Reality: Leveraging the Generative AI-Powered Platform Midjourney for Construction Worker Detection](https://arxiv.org/abs/2507.13221)
*Hongyang Zhao,Tianyu Liang,Sina Davari,Daeho Kim*

Main category: cs.CV

TL;DR: 该研究利用Midjourney生成12,000张合成图像，用于训练建筑工人检测模型，在真实数据集上取得了0.937的AP（IoU=0.5），并探讨了生成式AI在数据增强方面的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络（DNNs）在视觉AI领域取得了显著进展，但在建筑领域，数据多样性和数据量不足的问题仍然存在，尤其是在建筑工人检测方面。

Method: 本研究提出了一种新颖的图像合成方法，利用生成式AI平台Midjourney为建筑工人检测生成合成图像。通过构建3000个不同的提示（prompt），生成了12,000张注重真实性和多样性的合成图像。随后对手动标记的这些图像进行深度神经网络（DNN）训练。

Result: 在真实建筑图像数据集上的评估结果显示，所提出的模型在IoU阈值为0.5时达到了0.937的平均精度（AP），在IoU阈值为0.5至0.95时达到了0.642的平均精度。模型在合成数据集上表现出接近完美的效果，在上述两个阈值下的AP分别达到了0.994和0.919。

Conclusion: 该研究展示了生成式AI在解决深度神经网络（DNN）训练数据稀缺性方面的潜力与局限性。生成的合成数据在提高模型在真实建筑图像数据集上的检测性能方面显示出积极效果，但也揭示了在数据多样性和模型泛化能力方面仍需改进。

Abstract: While recent advancements in deep neural networks (DNNs) have substantially
enhanced visual AI's capabilities, the challenge of inadequate data diversity
and volume remains, particularly in construction domain. This study presents a
novel image synthesis methodology tailored for construction worker detection,
leveraging the generative-AI platform Midjourney. The approach entails
generating a collection of 12,000 synthetic images by formulating 3000
different prompts, with an emphasis on image realism and diversity. These
images, after manual labeling, serve as a dataset for DNN training. Evaluation
on a real construction image dataset yielded promising results, with the model
attaining average precisions (APs) of 0.937 and 0.642 at
intersection-over-union (IoU) thresholds of 0.5 and 0.5 to 0.95, respectively.
Notably, the model demonstrated near-perfect performance on the synthetic
dataset, achieving APs of 0.994 and 0.919 at the two mentioned thresholds.
These findings reveal both the potential and weakness of generative AI in
addressing DNN training data scarcity.

</details>


### [77] [Leveraging Pre-Trained Visual Models for AI-Generated Video Detection](https://arxiv.org/abs/2507.13224)
*Keerthi Veeramachaneni,Praveen Tirupattur,Amrit Singh Bedi,Mubarak Shah*

Main category: cs.CV

TL;DR: 提出了一种新的方法，利用预训练的视觉模型来检测AI生成的视频，并在VID-AID数据集上取得了超过90%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成视频在视觉内容方面不断进步，特别是超越了仅限于人脸的DeepFake技术，开发能够检测通用内容AI生成视频的方法变得至关重要，以应对错误信息、隐私保护和安全威胁等挑战。

Method: 利用预训练的视觉模型提取特征，并在此基础上训练一个简单的线性分类层来区分真实视频和AI生成视频，无需对整个模型进行额外的训练。

Result: 在包含9种不同文本到视频模型生成的约10,000个AI生成视频和4,000个真实视频的数据集（VID-AID）上进行了验证，平均检测准确率超过90%。

Conclusion: 目前的方法在检测AI生成视频方面表现出色，平均准确率超过90%，表明该方法在区分真实和生成视频方面是有效的。该研究为未来在这一关键领域的研究提供了支持，并且计划公开代码、预训练模型和数据集。

Abstract: Recent advances in Generative AI (GenAI) have led to significant improvements
in the quality of generated visual content. As AI-generated visual content
becomes increasingly indistinguishable from real content, the challenge of
detecting the generated content becomes critical in combating misinformation,
ensuring privacy, and preventing security threats. Although there has been
substantial progress in detecting AI-generated images, current methods for
video detection are largely focused on deepfakes, which primarily involve human
faces. However, the field of video generation has advanced beyond DeepFakes,
creating an urgent need for methods capable of detecting AI-generated videos
with generic content. To address this gap, we propose a novel approach that
leverages pre-trained visual models to distinguish between real and generated
videos. The features extracted from these pre-trained models, which have been
trained on extensive real visual content, contain inherent signals that can
help distinguish real from generated videos. Using these extracted features, we
achieve high detection performance without requiring additional model training,
and we further improve performance by training a simple linear classification
layer on top of the extracted features. We validated our method on a dataset we
compiled (VID-AID), which includes around 10,000 AI-generated videos produced
by 9 different text-to-video models, along with 4,000 real videos, totaling
over 7 hours of video content. Our evaluation shows that our approach achieves
high detection accuracy, above 90% on average, underscoring its effectiveness.
Upon acceptance, we plan to publicly release the code, the pre-trained models,
and our dataset to support ongoing research in this critical area.

</details>


### [78] [Efficient Adaptation of Pre-trained Vision Transformer underpinned by Approximately Orthogonal Fine-Tuning Strategy](https://arxiv.org/abs/2507.13260)
*Yiting Yang,Hao Luo,Yuan Sun,Qingsen Yan,Haokui Zhang,Wei Dong,Guoqing Wang,Peng Wang,Yang Yang,Hengtao Shen*

Main category: cs.CV

TL;DR: 通过使低秩适应的降/升投影矩阵具有近似正交性，可以增强视觉 Transformer 的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 观察到预训练视觉 Transformer 骨干网络权重矩阵的行/列向量近似正交，而现有低秩适应方法（如 LoRA）的降/升投影矩阵不具备此属性。研究是否能通过使这些投影矩阵也具有近似正交性来增强微调 ViT 的泛化能力。

Method: 提出一种“近似正交微调”（AOFT）策略，使用单个可学习向量生成近似正交向量，这些向量构成降/升投影矩阵，以匹配预训练骨干网络的属性。

Result: AOFT 方法在各种下游图像分类任务中取得了具有竞争力的性能，验证了其增强泛化能力的有效性。

Conclusion: 通过提出一种名为“近似正交微调”（AOFT）的策略，该策略使用单个可学习向量生成一组近似正交向量来构成降/升投影矩阵，从而使这些矩阵的属性与骨干网络的属性保持一致，我们进一步增强了微调后的视觉 Transformer 的泛化能力。实验结果表明，我们的方法在各种下游图像分类任务中均能取得具有竞争力的性能，证明了所增强的降/升投影矩阵的泛化能力的有效性。

Abstract: A prevalent approach in Parameter-Efficient Fine-Tuning (PEFT) of pre-trained
Vision Transformers (ViT) involves freezing the majority of the backbone
parameters and solely learning low-rank adaptation weight matrices to
accommodate downstream tasks. These low-rank matrices are commonly derived
through the multiplication structure of down-projection and up-projection
matrices, exemplified by methods such as LoRA and Adapter. In this work, we
observe an approximate orthogonality among any two row or column vectors within
any weight matrix of the backbone parameters; however, this property is absent
in the vectors of the down/up-projection matrices. Approximate orthogonality
implies a reduction in the upper bound of the model's generalization error,
signifying that the model possesses enhanced generalization capability. If the
fine-tuned down/up-projection matrices were to exhibit this same property as
the pre-trained backbone matrices, could the generalization capability of
fine-tuned ViTs be further augmented? To address this question, we propose an
Approximately Orthogonal Fine-Tuning (AOFT) strategy for representing the
low-rank weight matrices. This strategy employs a single learnable vector to
generate a set of approximately orthogonal vectors, which form the
down/up-projection matrices, thereby aligning the properties of these matrices
with those of the backbone. Extensive experimental results demonstrate that our
method achieves competitive performance across a range of downstream image
classification tasks, confirming the efficacy of the enhanced generalization
capability embedded in the down/up-projection matrices.

</details>


### [79] [DiffClean: Diffusion-based Makeup Removal for Accurate Age Estimation](https://arxiv.org/abs/2507.13292)
*Ekta Balkrishna Gavas,Chinmay Hegde,Nasir Memon,Sudipta Banerjee*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate age verification can protect underage users from unauthorized access
to online platforms and e-commerce sites that provide age-restricted services.
However, accurate age estimation can be confounded by several factors,
including facial makeup that can induce changes to alter perceived identity and
age to fool both humans and machines. In this work, we propose DiffClean which
erases makeup traces using a text-guided diffusion model to defend against
makeup attacks. DiffClean improves age estimation (minor vs. adult accuracy by
4.8%) and face verification (TMR by 8.9% at FMR=0.01%) over competing baselines
on digitally simulated and real makeup images.

</details>


### [80] [FashionPose: Text to Pose to Relight Image Generation for Personalized Fashion Visualization](https://arxiv.org/abs/2507.13311)
*Chuancheng Shi,Yixiang Chen,Burong Lei,Jichao Chen*

Main category: cs.CV

TL;DR: FashionPose 是一个创新的框架，它利用文本描述来生成不同姿势和光照条件下的服装图像，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法依赖预定义姿势，限制了语义灵活性和照明适应性的问题，我们引入了 FashionPose。

Method: FashionPose 首先预测二维人体姿势，然后使用扩散模型生成高保真人物图像，最后应用轻量级重新照明模块，所有这些都以相同的文本输入为指导。

Result: 实验证明了 FashionPose 能够进行细粒度的姿势合成以及高效、一致的重新照明，为个性化的虚拟时尚展示提供了实用的解决方案。

Conclusion: FashionPose 是一个统一的文本到姿势到重新照明生成框架，通过自然语言描述，可以预测二维人体姿势，生成高保真人物图像，并应用轻量级重新照明模块，从而实现精确的姿势对齐、忠实的服装渲染和灵活的照明控制。

Abstract: Realistic and controllable garment visualization is critical for fashion
e-commerce, where users expect personalized previews under diverse poses and
lighting conditions. Existing methods often rely on predefined poses, limiting
semantic flexibility and illumination adaptability. To address this, we
introduce FashionPose, the first unified text-to-pose-to-relighting generation
framework. Given a natural language description, our method first predicts a 2D
human pose, then employs a diffusion model to generate high-fidelity person
images, and finally applies a lightweight relighting module, all guided by the
same textual input. By replacing explicit pose annotations with text-driven
conditioning, FashionPose enables accurate pose alignment, faithful garment
rendering, and flexible lighting control. Experiments demonstrate fine-grained
pose synthesis and efficient, consistent relighting, providing a practical
solution for personalized virtual fashion display.

</details>


### [81] [Revisiting Reliability in the Reasoning-based Pose Estimation Benchmark](https://arxiv.org/abs/2507.13314)
*Junsu Kim,Naeun Kim,Jaeho Lee,Incheol Park,Dongyoon Han,Seungryul Baek*

Main category: cs.CV

TL;DR: RPE基准存在问题，我们改进了标注并公开发布，以提高评估的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 为了解决推理式姿态估计（RPE）基准在可复现性和基准质量方面存在的关键问题，这些问题阻碍了对姿态感知多模态大语言模型（MLLMs）进行公平、一致的量化评估。

Method: 研究人员识别了RPE基准在图像索引、标注准确性、图像冗余、场景不平衡、姿态过于简单和文本描述模糊等方面存在的问题。他们通过手动匹配和视觉检查，重新整理了地面真实（GT）标注，并将改进后的标注作为开源资源发布。

Result: 发布了经过改进的GT标注，解决了原始基准中图像索引不匹配和标注错误的问题，同时通过减少图像冗余、平衡场景、提供更复杂的姿态和更清晰的文本描述来提升基准质量，从而促进了更可靠的评估。

Conclusion: 该研究通过改进推理式姿态估计（RPE）基准的标注，解决了其在可复现性和基准质量方面存在的问题，发布了改进后的标注数据，以促进更准确、更一致的人体姿态感知多模态大语言模型（MLLMs）的评估和发展。

Abstract: The reasoning-based pose estimation (RPE) benchmark has emerged as a widely
adopted evaluation standard for pose-aware multimodal large language models
(MLLMs). Despite its significance, we identified critical reproducibility and
benchmark-quality issues that hinder fair and consistent quantitative
evaluations. Most notably, the benchmark utilizes different image indices from
those of the original 3DPW dataset, forcing researchers into tedious and
error-prone manual matching processes to obtain accurate ground-truth (GT)
annotations for quantitative metrics (\eg, MPJPE, PA-MPJPE). Furthermore, our
analysis reveals several inherent benchmark-quality limitations, including
significant image redundancy, scenario imbalance, overly simplistic poses, and
ambiguous textual descriptions, collectively undermining reliable evaluations
across diverse scenarios. To alleviate manual effort and enhance
reproducibility, we carefully refined the GT annotations through meticulous
visual matching and publicly release these refined annotations as an
open-source resource, thereby promoting consistent quantitative evaluations and
facilitating future advancements in human pose-aware multimodal reasoning.

</details>


### [82] [A Real-Time System for Egocentric Hand-Object Interaction Detection in Industrial Domains](https://arxiv.org/abs/2507.13326)
*Antonio Finocchiaro,Alessandro Sebastiano Catinello,Michele Mazzamuto,Rosario Leonardi,Antonino Furnari,Giovanni Maria Farinella*

Main category: cs.CV

TL;DR: An efficient cascaded system for real-time hand-object interaction detection in egocentric vision using Mamba/EfficientNetV2 for action recognition and YOLOWorld for object detection.


<details>
  <summary>Details</summary>
Motivation: Hand-object interaction detection is crucial for intuitive user experiences in real-time applications, but it remains a challenging problem. This work aims to provide an efficient and accurate solution for detecting these interactions from streaming egocentric vision.

Method: We propose a cascaded architecture where an action recognition module (Mamba with EfficientNetV2 backbone) first detects contact states, and upon confirmation, an object detection module (fine-tuned YOLOWorld) identifies and classifies the interacting object. This sequential operation is designed for efficiency in streaming egocentric vision.

Result: Our Mamba-based action recognition model achieves 38.52% p-AP on the ENIGMA-51 benchmark at 30fps. The fine-tuned YOLOWorld model reaches 85.13% AP for hand and object detection, demonstrating effective performance in identifying interacting objects.

Conclusion: Our cascaded architecture, combining a Mamba-based action recognition model with EfficientNetV2 and a fine-tuned YOLOWorld for object detection, achieves real-time performance for hand-object interaction detection.

Abstract: Hand-object interaction detection remains an open challenge in real-time
applications, where intuitive user experiences depend on fast and accurate
detection of interactions with surrounding objects. We propose an efficient
approach for detecting hand-objects interactions from streaming egocentric
vision that operates in real time. Our approach consists of an action
recognition module and an object detection module for identifying active
objects upon confirmed interaction. Our Mamba model with EfficientNetV2 as
backbone for action recognition achieves 38.52% p-AP on the ENIGMA-51 benchmark
at 30fps, while our fine-tuned YOLOWorld reaches 85.13% AP for hand and object.
We implement our models in a cascaded architecture where the action recognition
and object detection modules operate sequentially. When the action recognition
predicts a contact state, it activates the object detection module, which in
turn performs inference on the relevant frame to detect and classify the active
object.

</details>


### [83] [Taming Diffusion Transformer for Real-Time Mobile Video Generation](https://arxiv.org/abs/2507.13343)
*Yushu Wu,Yanyu Li,Anil Kag,Ivan Skorokhodov,Willi Menapace,Ke Ma,Arpit Sahni,Ju Hu,Aliaksandr Siarohin,Dhritiman Sagar,Yanzhi Wang,Sergey Tulyakov*

Main category: cs.CV

TL;DR: 通过VAE压缩、模型剪枝和蒸馏技术，DiT在手机上实现了实时视频生成。


<details>
  <summary>Details</summary>
Motivation: 为了解决Diffusion Transformers（DiT）在视频生成任务中计算成本高、不适用于智能手机等资源受限设备以及实时生成困难的问题。

Method: 研究提出了一种新颖的优化方法，包括使用高度压缩的变分自编码器（VAE）来降低数据维度，采用KD引导的敏感度感知三级剪枝策略来减小模型尺寸，并开发了针对DiT的对抗性步长蒸馏技术以减少推理步数。

Result: 在iPhone 16 Pro Max上实现了超过10 FPS的视频生成速度。

Conclusion: 通过一系列新颖的优化，包括高度压缩的变分自编码器（VAE）、知识蒸馏（KD）引导的敏感度感知三级剪枝策略以及针对DiT的对抗性步长蒸馏技术，研究实现了在iPhone 16 Pro Max上超过10 FPS的视频生成速度，证明了在移动设备上实现实时高质量视频生成的可行性。

Abstract: Diffusion Transformers (DiT) have shown strong performance in video
generation tasks, but their high computational cost makes them impractical for
resource-constrained devices like smartphones, and real-time generation is even
more challenging. In this work, we propose a series of novel optimizations to
significantly accelerate video generation and enable real-time performance on
mobile platforms. First, we employ a highly compressed variational autoencoder
(VAE) to reduce the dimensionality of the input data without sacrificing visual
quality. Second, we introduce a KD-guided, sensitivity-aware tri-level pruning
strategy to shrink the model size to suit mobile platform while preserving
critical performance characteristics. Third, we develop an adversarial step
distillation technique tailored for DiT, which allows us to reduce the number
of inference steps to four. Combined, these optimizations enable our model to
achieve over 10 frames per second (FPS) generation on an iPhone 16 Pro Max,
demonstrating the feasibility of real-time, high-quality video generation on
mobile devices.

</details>


### [84] [Diffuman4D: 4D Consistent Human View Synthesis from Sparse-View Videos with Spatio-Temporal Diffusion Models](https://arxiv.org/abs/2507.13344)
*Yudong Jin,Sida Peng,Xuan Wang,Tao Xie,Zhen Xu,Yifan Yang,Yujun Shen,Hujun Bao,Xiaowei Zhou*

Main category: cs.CV

TL;DR: This paper introduces a new sliding iterative denoising technique for 4D diffusion models to create consistent human videos from few angles, improving quality and reducing memory use compared to prior work.


<details>
  <summary>Details</summary>
Motivation: Previous 4D diffusion models for novel-view synthesis of humans from sparse-view videos suffer from a lack of spatio-temporal consistency, leading to degraded synthesis quality. This paper aims to address this limitation.

Method: A novel sliding iterative denoising process is proposed. This process operates on a latent grid where each latent encodes image, camera pose, and human pose for a specific viewpoint and timestamp. The denoising occurs alternately along spatial and temporal dimensions using a sliding window, allowing information flow across the latent grid for improved 4D consistency and manageable GPU memory usage.

Result: Experiments on the DNA-Rendering and ActorsHQ datasets show that the proposed method synthesizes high-quality and consistent novel-view videos, significantly outperforming existing methods.

Conclusion: The proposed method enhances spatio-temporal consistency in 4D diffusion models for novel-view synthesis of humans from sparse-view videos, outperforming existing approaches on benchmark datasets.

Abstract: This paper addresses the challenge of high-fidelity view synthesis of humans
with sparse-view videos as input. Previous methods solve the issue of
insufficient observation by leveraging 4D diffusion models to generate videos
at novel viewpoints. However, the generated videos from these models often lack
spatio-temporal consistency, thus degrading view synthesis quality. In this
paper, we propose a novel sliding iterative denoising process to enhance the
spatio-temporal consistency of the 4D diffusion model. Specifically, we define
a latent grid in which each latent encodes the image, camera pose, and human
pose for a certain viewpoint and timestamp, then alternately denoising the
latent grid along spatial and temporal dimensions with a sliding window, and
finally decode the videos at target viewpoints from the corresponding denoised
latents. Through the iterative sliding, information flows sufficiently across
the latent grid, allowing the diffusion model to obtain a large receptive field
and thus enhance the 4D consistency of the output, while making the GPU memory
consumption affordable. The experiments on the DNA-Rendering and ActorsHQ
datasets demonstrate that our method is able to synthesize high-quality and
consistent novel-view videos and significantly outperforms the existing
approaches. See our project page for interactive demos and video results:
https://diffuman4d.github.io/ .

</details>


### [85] [Imbalance in Balance: Online Concept Balancing in Generation Models](https://arxiv.org/abs/2507.13345)
*Yukai Shi,Jiarong Ou,Rui Chen,Haotian Yang,Jiahao Wang,Xin Tao,Pengfei Wan,Di Zhang,Kun Gai*

Main category: cs.CV

TL;DR: 提出IMBA loss来提高视觉生成中复杂概念的响应稳定性，并在基准测试中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 视觉生成任务中，复杂概念的响应和组合常常不稳定且易出错，这是一个有待深入研究的领域。

Method: 设计了一系列实验来探索导致概念响应不佳的因果因素，并提出了一种名为IMBA loss的概念感知均衡损失函数来解决该问题。该方法是在线的，并且只需要很少的代码改动。

Result: 所提出的方法在Inert-CompBench基准和两个公开测试集上显著提高了基线模型的概念响应能力，并取得了具有高度竞争力的结果，同时仅需少量代码改动。

Conclusion: 该研究提出了一种名为IMBA loss的概念感知均衡损失函数，以提高视觉生成任务中复杂概念响应的稳定性和准确性。该方法具有在线、无需离线数据处理和易于集成等优点，并在新提出的Inert-CompBench基准和两个公开测试集上验证了其有效性。

Abstract: In visual generation tasks, the responses and combinations of complex
concepts often lack stability and are error-prone, which remains an
under-explored area. In this paper, we attempt to explore the causal factors
for poor concept responses through elaborately designed experiments. We also
design a concept-wise equalization loss function (IMBA loss) to address this
issue. Our proposed method is online, eliminating the need for offline dataset
processing, and requires minimal code changes. In our newly proposed complex
concept benchmark Inert-CompBench and two other public test sets, our method
significantly enhances the concept response capability of baseline models and
yields highly competitive results with only a few codes.

</details>


### [86] [AutoPartGen: Autogressive 3D Part Generation and Discovery](https://arxiv.org/abs/2507.13346)
*Minghao Chen,Jianyuan Wang,Roman Shapovalov,Tom Monnier,Hyunyoung Jung,Dilin Wang,Rakesh Ranjan,Iro Laina,Andrea Vedaldi*

Main category: cs.CV

TL;DR: AutoPartGen是一个能够以自回归方式生成由3D零件组成的物体的模型，它以图像、2D掩码或3D对象作为输入，并能自动确定零件的数量和类型，在3D零件生成方面取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了生成由3D零件组成的物体。

Method: AutoPartGen模型以自回归方式生成由3D零件组成的物体，它以图像、2D零件掩码或现有3D对象作为输入，生成相应的组合式3D重建。该模型基于强大的3DShape2VecSet潜在3D表示，并利用其组合特性进行零件生成。模型逐个预测零件，并以先前生成的零件和额外输入（如2D图像、掩码或3D对象）为条件。该过程持续进行，直到模型确定所有零件都已生成，从而自动确定零件的类型和数量。生成的零件可以无缝组装成连贯的物体或场景，无需额外的优化。

Result: AutoPartGen能够根据输入（图像、2D掩码或3D对象）生成组合式3D重建，并能自动确定零件的类型和数量，生成的零件可直接组装成物体或场景。在评估中，AutoPartGen在3D零件生成方面达到了最先进的性能。

Conclusion: AutoPartGen在3D零件生成方面取得了最先进的性能。

Abstract: We introduce AutoPartGen, a model that generates objects composed of 3D parts
in an autoregressive manner. This model can take as input an image of an
object, 2D masks of the object's parts, or an existing 3D object, and generate
a corresponding compositional 3D reconstruction. Our approach builds upon
3DShape2VecSet, a recent latent 3D representation with powerful geometric
expressiveness. We observe that this latent space exhibits strong compositional
properties, making it particularly well-suited for part-based generation tasks.
Specifically, AutoPartGen generates object parts autoregressively, predicting
one part at a time while conditioning on previously generated parts and
additional inputs, such as 2D images, masks, or 3D objects. This process
continues until the model decides that all parts have been generated, thus
determining automatically the type and number of parts. The resulting parts can
be seamlessly assembled into coherent objects or scenes without requiring
additional optimization. We evaluate both the overall 3D generation
capabilities and the part-level generation quality of AutoPartGen,
demonstrating that it achieves state-of-the-art performance in 3D part
generation.

</details>


### [87] [$π^3$: Scalable Permutation-Equivariant Visual Geometry Learning](https://arxiv.org/abs/2507.13347)
*Yifan Wang,Jianjun Zhou,Haoyi Zhu,Wenzheng Chang,Yang Zhou,Zizun Li,Junyi Chen,Jiangmiao Pang,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: $\\pi^3$ 是一种新颖的视觉几何重建方法，它使用排列等变架构，无需参考系，即可实现最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 之前的重建方法依赖于固定的参考视图，这可能导致不稳定和失败。

Method: $\\pi^3$ 使用完全排列等变架构来预测仿射不变的相机姿态和尺度不变的局部点图，无需参考系。

Result: $\\pi^3$ 可以在没有参考系的情况下进行视觉几何重建，并且在各种任务中实现了最先进的性能。

Conclusion: $\\pi^3$ 实现了最先进的性能，在各种任务中表现出色，例如相机姿态估计、单眼/视频深度估计和密集点图重建。

Abstract: We introduce $\pi^3$, a feed-forward neural network that offers a novel
approach to visual geometry reconstruction, breaking the reliance on a
conventional fixed reference view. Previous methods often anchor their
reconstructions to a designated viewpoint, an inductive bias that can lead to
instability and failures if the reference is suboptimal. In contrast, $\pi^3$
employs a fully permutation-equivariant architecture to predict
affine-invariant camera poses and scale-invariant local point maps without any
reference frames. This design makes our model inherently robust to input
ordering and highly scalable. These advantages enable our simple and bias-free
approach to achieve state-of-the-art performance on a wide range of tasks,
including camera pose estimation, monocular/video depth estimation, and dense
point map reconstruction. Code and models are publicly available.

</details>


### [88] [Hierarchical Rectified Flow Matching with Mini-Batch Couplings](https://arxiv.org/abs/2507.13350)
*Yichi Zhang,Yici Yan,Alex Schwing,Zhizhen Zhao*

Main category: cs.CV

TL;DR: Flow matching is a generative modeling approach. Hierarchical flow matching uses a hierarchy of ODEs to capture multi-modal velocity distributions. This paper introduces mini-batch couplings to gradually adjust the complexity of distributions across hierarchy levels, showing benefits on synthetic and imaging data.


<details>
  <summary>Details</summary>
Motivation: While hierarchical flow matching can capture multi-modal velocity distributions, the complexity remains identical across levels of the hierarchy. This work addresses how to adjust this complexity.

Method: The paper studies how to gradually adjust the complexity of distributions across different levels of the hierarchy via mini-batch couplings in hierarchical flow matching.

Result: The benefits of mini-batch couplings in hierarchical rectified flow matching were demonstrated via compelling results on synthetic and imaging data.

Conclusion: Mini-batch couplings can gradually adjust the complexity of distributions across different levels of the hierarchy in hierarchical rectified flow matching, leading to benefits demonstrated on synthetic and imaging data.

Abstract: Flow matching has emerged as a compelling generative modeling approach that
is widely used across domains. To generate data via a flow matching model, an
ordinary differential equation (ODE) is numerically solved via forward
integration of the modeled velocity field. To better capture the multi-modality
that is inherent in typical velocity fields, hierarchical flow matching was
recently introduced. It uses a hierarchy of ODEs that are numerically
integrated when generating data. This hierarchy of ODEs captures the
multi-modal velocity distribution just like vanilla flow matching is capable of
modeling a multi-modal data distribution. While this hierarchy enables to model
multi-modal velocity distributions, the complexity of the modeled distribution
remains identical across levels of the hierarchy. In this paper, we study how
to gradually adjust the complexity of the distributions across different levels
of the hierarchy via mini-batch couplings. We show the benefits of mini-batch
couplings in hierarchical rectified flow matching via compelling results on
synthetic and imaging data. Code is available at
https://riccizz.github.io/HRF_coupling.

</details>


### [89] [VideoITG: Multimodal Video Understanding with Instructed Temporal Grounding](https://arxiv.org/abs/2507.13353)
*Shihao Wang,Guo Chen,De-an Huang,Zhiqi Li,Minghan Li,Guilin Li,Jose M. Alvarez,Lei Zhang,Zhiding Yu*

Main category: cs.CV

TL;DR: VideoITG通过指令引导的帧采样，提升了视频大语言模型在长视频理解任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频理解的复杂场景时存在不足，该研究旨在通过定制与用户指令对齐的帧采样来改进视频大语言模型（Video-LLMs）的性能。

Method: 提出了一种名为VideoITG的框架，其核心是VidThinker流水线，包括生成指令引导的剪辑级描述、检索相关视频片段和进行细粒度帧选择。

Result: VideoITG模型在多个视频理解基准测试中取得了持续的性能提升，证明了其在视频理解方面的优越性和巨大潜力。

Conclusion: VideoITG通过VidThinker流水线生成了包含40K视频和500K指令时间接地标注的VideoITG-40K数据集，并设计了一个即插即用的VideoITG模型，利用视频语言模型（Video-LLMs）的视觉语言对齐和推理能力进行区分性帧选择。

Abstract: Recent studies have revealed that selecting informative and relevant video
frames can significantly improve the performance of Video Large Language Models
(Video-LLMs). Current methods, such as reducing inter-frame redundancy,
employing separate models for image-text relevance assessment, or utilizing
temporal video grounding for event localization, substantially adopt
unsupervised learning paradigms, whereas they struggle to address the complex
scenarios in long video understanding. We propose Instructed Temporal Grounding
for Videos (VideoITG), featuring customized frame sampling aligned with user
instructions. The core of VideoITG is the VidThinker pipeline, an automated
annotation framework that explicitly mimics the human annotation process.
First, it generates detailed clip-level captions conditioned on the
instruction; then, it retrieves relevant video segments through
instruction-guided reasoning; finally, it performs fine-grained frame selection
to pinpoint the most informative visual evidence. Leveraging VidThinker, we
construct the VideoITG-40K dataset, containing 40K videos and 500K instructed
temporal grounding annotations. We then design a plug-and-play VideoITG model,
which takes advantage of visual language alignment and reasoning capabilities
of Video-LLMs, for effective frame selection in a discriminative manner.
Coupled with Video-LLMs, VideoITG achieves consistent performance improvements
across multiple multimodal video understanding benchmarks, showing its
superiority and great potentials for video understanding.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [Modeling Open-World Cognition as On-Demand Synthesis of Probabilistic Models](https://arxiv.org/abs/2507.12547)
*Lionel Wong,Katherine M. Collins,Lance Ying,Cedegao E. Zhang,Adrian Weller,Tobias Gersternberg,Timothy O'Donnell,Alexander K. Lew,Jacob D. Andreas,Joshua B. Tenenbaum,Tyler Brooke-Wilson*

Main category: cs.CL

TL;DR: 人类擅长在新情境下运用背景知识进行推理。本研究提出了一种结合语言模型和概率程序的“模型综合架构”（MSA），以模拟这种能力。实验证明，MSA在处理包含新颖变量和因果关系的推理任务时，比仅使用语言模型的模型更能接近人类的表现，表明MSA是理解和复制人类开放域推理能力的一种有前景的方法。


<details>
  <summary>Details</summary>
Motivation: 探讨了人类在面对新颖情境时，如何从广泛的背景知识中提取相关信息并进行推理和预测的能力。

Method: 提出了一种名为“模型综合架构”（MSA）的计算模型，该模型结合了语言模型（用于全局相关性检索和模型综合）和概率程序（用于定制化的、连贯的世界模型）。

Result: MSA在处理新颖推理数据集时，比仅使用语言模型的基线模型更能捕捉到人类的判断，包括在处理语言描述的新颖因果结构、利用大量背景知识以及在有任意新颖变量的观测下进行推理。

Conclusion: 该研究表明，模型综合架构（MSA）能够更好地模拟人类在开放域中的推理能力，通过结合分布式和符号化表征来构建定制化的心智模型。

Abstract: When faced with novel situations, people are able to marshal relevant
considerations from a wide range of background knowledge and put these to use
in inferences and predictions. What permits us to draw in globally relevant
information and reason over it coherently? Here, we explore the hypothesis that
people use a combination of distributed and symbolic representations to
construct bespoke mental models tailored to novel situations. We propose a
computational implementation of this idea -- a ``Model Synthesis Architecture''
(MSA) -- using language models to implement global relevance-based retrieval
and model synthesis and probabilistic programs to implement bespoke, coherent
world models. We evaluate our MSA as a model of human judgments on a novel
reasoning dataset. The dataset -- built around a `Model Olympics` domain of
sports vignettes -- tests models' capacity for human-like, open-ended reasoning
by requiring (i) judgments about novel causal structures described in language;
(ii) drawing on large bodies of background knowledge; and (iii) doing both in
light of observations that introduce arbitrary novel variables. Our MSA
approach captures human judgments better than language model-only baselines,
under both direct and chain-of-thought generations from the LM that supports
model synthesis. These results suggest that MSAs can be implemented in a way
that mirrors people's ability to deliver locally coherent reasoning over
globally relevant variables, offering a path to understanding and replicating
human reasoning in open-ended domains.

</details>


### [91] [Is This Just Fantasy? Language Model Representations Reflect Human Judgments of Event Plausibility](https://arxiv.org/abs/2507.12553)
*Michael A. Lepori,Jennifer Hu,Ishita Dasgupta,Roma Patel,Thomas Serre,Ellie Pavlick*

Main category: cs.CL

TL;DR: 本研究通过识别语言模型中的模态差异向量，发现语言模型具有比预期更强的模态分类能力，并且这些向量能够模拟人类的分类行为。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究语言模型（LM）区分句子模态类别的能力，以及分析其内部表示。

Method: 通过识别区分模态类别的线性表示（模态差异向量）来分析语言模型。

Result: LM 确实具有访问更可靠的模态分类判断的能力，并且模态差异向量在模型能力提升时会以一致的顺序出现。此外，模态差异向量可以用于模拟人类的分类行为。

Conclusion: LM 具有比之前报道的更可靠的模态分类能力，并且模态差异向量可以模拟人类的分类行为。

Abstract: Language models (LMs) are used for a diverse range of tasks, from question
answering to writing fantastical stories. In order to reliably accomplish these
tasks, LMs must be able to discern the modal category of a sentence (i.e.,
whether it describes something that is possible, impossible, completely
nonsensical, etc.). However, recent studies have called into question the
ability of LMs to categorize sentences according to modality (Michaelov et al.,
2025; Kauf et al., 2023). In this work, we identify linear representations that
discriminate between modal categories within a variety of LMs, or modal
difference vectors. Analysis of modal difference vectors reveals that LMs have
access to more reliable modal categorization judgments than previously
reported. Furthermore, we find that modal difference vectors emerge in a
consistent order as models become more competent (i.e., through training steps,
layers, and parameter count). Notably, we find that modal difference vectors
identified within LM activations can be used to model fine-grained human
categorization behavior. This potentially provides a novel view into how human
participants distinguish between modal categories, which we explore by
correlating projections along modal difference vectors with human participants'
ratings of interpretable features. In summary, we derive new insights into LM
modal categorization using techniques from mechanistic interpretability, with
the potential to inform our understanding of modal categorization in humans.

</details>


### [92] [The first open machine translation system for the Chechen language](https://arxiv.org/abs/2507.12672)
*Abu-Viskhan A. Umishov,Vladislav A. Grigorian*

Main category: cs.CL

TL;DR: 发布了第一个开源的、针对维吾尔切尔克斯语和俄语的翻译模型和数据集，并探讨了其微调能力。


<details>
  <summary>Details</summary>
Motivation: 介绍了一个针对维吾尔切尔克斯语和俄语的翻译模型

Method: 探讨了将新语言纳入多语言翻译大型语言模型系统（NLLB-200）的微调能力。

Result: 模型在俄语到维吾尔切尔克斯语以及反向翻译上的BLEU/ChrF++得分分别为8.34/34.69和20.89/44.55。

Conclusion: 发布了开源的、针对维吾尔切尔克斯语和俄语之间翻译的模型，以及用于训练和评估它的数据集。

Abstract: We introduce the first open-source model for translation between the
vulnerable Chechen language and Russian, and the dataset collected to train and
evaluate it. We explore fine-tuning capabilities for including a new language
into a large language model system for multilingual translation NLLB-200. The
BLEU / ChrF++ scores for our model are 8.34 / 34.69 and 20.89 / 44.55 for
translation from Russian to Chechen and reverse direction, respectively. The
release of the translation models is accompanied by the distribution of
parallel words, phrases and sentences corpora and multilingual sentence encoder
adapted to the Chechen language.

</details>


### [93] [Improving Drug Identification in Overdose Death Surveillance using Large Language Models](https://arxiv.org/abs/2507.12679)
*Arthur J. Funnell,Panayiotis Petousis,Fabrice Harel-Canada,Ruby Romero,Alex A. T. Bui,Adam Koncsol,Hritika Chaturvedi,Chelsea Shover,David Goodman-Meza*

Main category: cs.CL

TL;DR: NLP模型，特别是BioClinicalBERT，在从验尸报告中识别毒品过量死亡方面表现出色，准确率高，并且比传统方法和大型语言模型更有效，有助于实时监测毒品使用趋势。


<details>
  <summary>Details</summary>
Motivation: 出于美国与毒品相关的死亡人数不断增加，主要由芬太尼驱动，因此需要及时准确的监测。然而，关键的过量数据通常被埋藏在自由文本的验尸报告中，当编码为ICD（疾病分类）-10分类时，会导致延迟和信息丢失。自然语言处理（NLP）模型可以自动化和增强过量监测，但之前的应用受到限制。

Method: 使用2020年来自美国多个司法管辖区的35,433条死亡记录用于模型训练和内部测试。使用2023-2024年的3,335条记录的新型独立数据集进行外部验证。评估了多种NLP方法，包括传统的单标签和多标签分类器，以及像BERT和BioClinicalBERT这样的微调编码器模型，还有像Qwen 3和Llama 3这样的现代解码器模型。使用宏平均F1分数评估模型性能，并计算95%置信区间来量化不确定性。

Result: 微调的BioClinicalBERT模型取得了近乎完美的结果，在内部测试集上的宏F1分数>=0.998。外部验证确认了其稳健性（宏F1=0.966），其性能优于传统的机器学习、通用BERT模型和各种解码器模型。

Conclusion: NLP模型，特别是像BioClinicalBERT这样的微调临床变体，为对自由文本报告进行毒品死亡分类提供了一种高度准确且可扩展的解决方案。这些方法可以显著加速监控工作流程，克服手动ICD-10编码的局限性，并支持对新出现的物质使用趋势的近乎实时检测。

Abstract: The rising rate of drug-related deaths in the United States, largely driven
by fentanyl, requires timely and accurate surveillance. However, critical
overdose data are often buried in free-text coroner reports, leading to delays
and information loss when coded into ICD (International Classification of
Disease)-10 classifications. Natural language processing (NLP) models may
automate and enhance overdose surveillance, but prior applications have been
limited. A dataset of 35,433 death records from multiple U.S. jurisdictions in
2020 was used for model training and internal testing. External validation was
conducted using a novel separate dataset of 3,335 records from 2023-2024.
Multiple NLP approaches were evaluated for classifying specific drug
involvement from unstructured death certificate text. These included
traditional single- and multi-label classifiers, as well as fine-tuned
encoder-only language models such as Bidirectional Encoder Representations from
Transformers (BERT) and BioClinicalBERT, and contemporary decoder-only large
language models such as Qwen 3 and Llama 3. Model performance was assessed
using macro-averaged F1 scores, and 95% confidence intervals were calculated to
quantify uncertainty. Fine-tuned BioClinicalBERT models achieved near-perfect
performance, with macro F1 scores >=0.998 on the internal test set. External
validation confirmed robustness (macro F1=0.966), outperforming conventional
machine learning, general-domain BERT models, and various decoder-only large
language models. NLP models, particularly fine-tuned clinical variants like
BioClinicalBERT, offer a highly accurate and scalable solution for overdose
death classification from free-text reports. These methods can significantly
accelerate surveillance workflows, overcoming the limitations of manual ICD-10
coding and supporting near real-time detection of emerging substance use
trends.

</details>


### [94] [AdaptiSent: Context-Aware Adaptive Attention for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.12695)
*S M Rafiuddin,Sadia Kamal,Mohammed Rakib,Arunkumar Bagavathi,Atriya Sen*

Main category: cs.CL

TL;DR: AdaptiSent is a new framework for MABSA that uses adaptive cross-modal attention to improve sentiment and aspect extraction from text and images, outperforming existing models on Twitter datasets.


<details>
  <summary>Details</summary>
Motivation: To improve sentiment classification and aspect term extraction from both text and images in Multimodal Aspect-Based Sentiment Analysis (MABSA).

Method: AdaptiSent uses adaptive cross-modal attention mechanisms, integrating dynamic modality weighting and context-adaptive attention to improve sentiment classification and aspect term extraction from both text and images.

Result: AdaptiSent surpasses existing models in precision, recall, and F1 score on standard Twitter datasets, demonstrating effectiveness in identifying nuanced inter-modal relationships crucial for accurate sentiment and aspect term extraction.

Conclusion: AdaptiSent sets a new standard for MABSA, significantly outperforming current methods, especially in understanding complex multimodal information.

Abstract: We introduce AdaptiSent, a new framework for Multimodal Aspect-Based
Sentiment Analysis (MABSA) that uses adaptive cross-modal attention mechanisms
to improve sentiment classification and aspect term extraction from both text
and images. Our model integrates dynamic modality weighting and
context-adaptive attention, enhancing the extraction of sentiment and
aspect-related information by focusing on how textual cues and visual context
interact. We tested our approach against several baselines, including
traditional text-based models and other multimodal methods. Results from
standard Twitter datasets show that AdaptiSent surpasses existing models in
precision, recall, and F1 score, and is particularly effective in identifying
nuanced inter-modal relationships that are crucial for accurate sentiment and
aspect term extraction. This effectiveness comes from the model's ability to
adjust its focus dynamically based on the context's relevance, improving the
depth and accuracy of sentiment analysis across various multimodal data sets.
AdaptiSent sets a new standard for MABSA, significantly outperforming current
methods, especially in understanding complex multimodal information.

</details>


### [95] [AudioJudge: Understanding What Works in Large Audio Model Based Speech Evaluation](https://arxiv.org/abs/2507.12705)
*Potsawee Manakul,Woody Haosheng Gan,Michael J. Ryan,Ali Sartaz Khan,Warit Sirichotedumrong,Kunat Pipatanakul,William Held,Diyi Yang*

Main category: cs.CL

TL;DR: 本研究提出 AudioJudge，利用大型音频模型（LAM）作为统一评估框架，解决了传统语音评估的痛点，并通过集成多种评估项，实现了与人类偏好高相关性的自动评估。


<details>
  <summary>Details</summary>
Motivation: 现有语音评估方法存在两大痛点：一是需要为不同的音频特征设计专门的评估系统，过程繁琐且困难；二是自动评估方法与人类的偏好之间缺乏良好的相关性。本研究旨在提出一个统一的评估框架，以解决上述挑战。

Method: 本研究系统地探索了将大型音频模型（LAM）作为评估依据（AudioJudge），以解决现有语音评估的两个关键限制：设计专门系统和自动评估与人类偏好的相关性。研究内容包括：1. 探索AudioJudge在音频特征检测任务（发音、语速、说话人识别、语音质量）和系统级人类偏好模拟中的应用。2. 探究不同的提示工程策略，发现音频拼接结合上下文学习能显著提升性能。3. 引入多方面集成AudioJudge，将语音评估分解为专门的评估项（词汇内容、语音质量、副语言特征），以实现通用的多方面语音评估。4. 进行稳健性分析，考察LAM在噪声下的表现以及存在的冗余和位置偏见问题。

Result: AudioJudge 在音频特征检测和人类偏好模拟任务中表现优异，特别是多方面集成 AudioJudge 在系统排名基准测试中取得了高达 0.91 的斯皮尔曼相关性，显著提升了自动评估与人类偏好的相关性。研究还发现，LAM 在面对噪声时表现出良好的稳健性，但存在冗余和位置偏见问题，需要进行优化。

Conclusion: AudioJudge，一个利用大型音频模型（LAM）作为评估框架，成功解决了现有语音评估中针对特定音频特征设计专门系统以及自动评估方法与人类偏好相关性差的问题。通过对各种音频特征（如发音、语速、说话人识别和语音质量）以及系统级人类偏好进行的系统性研究，并结合音频拼接和上下文学习等提示工程策略，AudioJudge 在音频特征检测和人类偏好模拟任务上均表现出色。多方面集成AudioJudge通过将语音评估分解为词汇内容、语音质量和副语言特征的专门评估，在系统排名基准测试中实现了与人类偏好高达0.91的斯皮尔曼相关性。

Abstract: Current speech evaluation suffers from two critical limitations: the need and
difficulty of designing specialized systems targeting individual audio
characteristics, and poor correlation between automatic evaluation methods and
human preferences. This work presents a systematic study of Large Audio Model
(LAM) as a Judge, AudioJudge, investigating whether it can provide a unified
evaluation framework that addresses both challenges. We systematically explore
AudioJudge across audio characteristic detection tasks, including
pronunciation, speaking rate, speaker identification and speech quality, and
system-level human preference simulation for automated benchmarking. We
investigate different prompt engineering strategies, finding that audio
concatenation combined with in-context learning significantly improves
performance across both audio characteristic detection and human preference
simulation tasks. We further introduce a multi-aspect ensemble AudioJudge to
enable general-purpose multi-aspect audio evaluation. This method decomposes
speech assessment into specialized judges for lexical content, speech quality,
and paralinguistic features, achieving up to 0.91 Spearman correlation with
human preferences on our system ranking benchmark. Robustness analysis reveals
that while LAMs maintain strong performance under acoustic noise, they exhibit
significant verbosity and positional biases that require careful mitigation.

</details>


### [96] [FLEXITOKENS: Flexible Tokenization for Evolving Language Models](https://arxiv.org/abs/2507.12720)
*Abraham Toluase Owodunni,Orevaoghene Ahia,Sachin Kumar*

Main category: cs.CL

TL;DR: FLEXITOKENS 通过学习自适应分词来改进语言模型，解决了现有方法在处理不同数据分布时的局限性，并在多项任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型（LM）难以通过简单的微调适应新的数据分布，因为它们的子词分词器通常在适应过程中保持不变，这导致了对分布外域、未见语言或脚本的无效分词和过度碎片化。

Method: 提出了一种包含学习预测输入字节序列之间边界的子模块的双字节级别语言模型，以将输入编码为可变长度的段。现有分词器无关的方法使用辅助损失来训练边界预测器，该损失强制在整个训练语料库中保持固定的压缩率。FLEXITOKENS 是一种简化的训练目标，可以实现更大的适应性。

Result: FLEXITOKENS 在评估中持续减少了标记的过度碎片化，并在下游任务性能上比子词和其他基于梯度的分词器提高了高达 10%。

Conclusion: FLEXITOKENS 是一种简化的训练目标，可以使分词更具适应性，在评估中，它在多个多语言基准、形态多样的任务和领域中，持续减少了标记的过度碎片化，并在下游任务性能上比子词和其他基于梯度的分词器提高了 10%。

Abstract: Language models (LMs) are challenging to adapt to new data distributions by
simple finetuning. This is due to the rigidity of their subword tokenizers,
which typically remain unchanged during adaptation. This inflexibility often
leads to inefficient tokenization, causing overfragmentation of
out-of-distribution domains, unseen languages, or scripts. In this work, we
develop byte-level LMs with learnable tokenizers to make tokenization adaptive.
Our models include a submodule that learns to predict boundaries between the
input byte sequence, encoding it into variable-length segments. Existing
tokenizer-free methods train this boundary predictor using an auxiliary loss
that enforces a fixed compression rate across the training corpus, introducing
a new kind of rigidity. We propose FLEXITOKENS, a simplified training objective
that enables significantly greater flexibility during adaptation. Evaluating
across multiple multilingual benchmarks, morphologically diverse tasks, and
domains, we demonstrate that FLEXITOKENS consistently reduces token
over-fragmentation and achieves up to 10\% improvements on downstream task
performance compared to subword and other gradient-based tokenizers. Code and
data for our experiments will be released at
https://github.com/owos/flexitokens

</details>


### [97] [TransEvalnia: Reasoning-based Evaluation and Ranking of Translations](https://arxiv.org/abs/2507.12724)
*Richard Sproat,Tianyu Zhao,Llion Jones*

Main category: cs.CL

TL;DR: TransEvalnia是一个基于提示的翻译评估和排名系统，它使用推理进行细粒度评估，并能确定最佳翻译。该系统在多个语言对上表现优于或等于最先进的MT-Ranker，并且其评估结果得到了人类评分者的高度认可。此外，研究还探讨了如何解决系统对翻译呈现顺序的敏感性问题。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够进行细粒度评估、确定最佳翻译并提供数值分数的翻译评估和排名系统。

Method: 使用基于提示的翻译评估和排名系统TransEvalnia，该系统在评估和排名中使用推理。它基于MQM的一个子集进行细粒度评估，评估最佳翻译并提供各维度和总体翻译的数值分数。

Result: TransEvalnia在英日数据和WMT共享任务的多个语言对上表现与MT-Ranker相当或更优。使用Claude-3.5-Sonnet和Qwen-2.5-72B-Instruct作为评估LLM，评估结果被人类评分者高度认可，并且LLM分数与人类评分者分数具有良好相关性。研究还指出了系统对翻译呈现顺序的敏感性，并提出了解决位置偏差的方法。

Conclusion: TransEvalnia在评估和排序方面表现出色，与最先进的MT-Ranker相当或更优，并且其评估结果得到了人类评分者的高度认可。

Abstract: We present TransEvalnia, a prompting-based translation evaluation and ranking
system that uses reasoning in performing its evaluations and ranking. This
system presents fine-grained evaluations based on a subset of the
Multidimensional Quality Metrics (https://themqm.org/), returns an assessment
of which translation it deems the best, and provides numerical scores for the
various dimensions and for the overall translation. We show that TransEvalnia
performs as well as or better than the state-of-the-art MT-Ranker (Moosa et al.
2024) on our own English-Japanese data as well as several language pairs from
various WMT shared tasks. Using Anthropic's Claude-3.5-Sonnet and
Qwen-2.5-72B-Instruct as the evaluation LLMs, we show that the evaluations
returned are deemed highly acceptable to human raters, and that the scores
assigned to the translations by Sonnet, as well as other LLMs, correlate well
with scores assigned by the human raters. We also note the sensitivity of our
system -- as well as MT-Ranker -- to the order in which the translations are
presented, and we propose methods to address this position bias. All data,
including the system's evaluation and reasoning, human assessments, as well as
code is released.

</details>


### [98] [Strategy Adaptation in Large Language Model Werewolf Agents](https://arxiv.org/abs/2507.12732)
*Fuya Nakamori,Yin Jou Huang,Fei Cheng*

Main category: cs.CL

TL;DR: 通过根据游戏情境和玩家角色态度在预设策略间切换，改进了狼人杀AI的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有狼人杀AI（特别是基于提示工程的方法）在面对动态变化的游戏情境时，由于其策略隐式定义或固定而无法适应的问题。

Method: 提出了一种通过根据其他玩家的态度和对话语境在预设策略间进行切换来改进狼人杀AI性能的方法，该方法明确地根据游戏情境和其他玩家的估计角色来选择合适的策略。

Result: 实验结果表明，本研究提出的策略自适应狼人杀AI相比于使用隐式或固定策略的基线AI，在性能上得到了有效提升，验证了所提方法的可行性和优越性。

Conclusion: 本研究提出的方法能够有效提升狼人杀AI的性能，通过根据其他玩家的态度和对话语境在预设策略间进行切换，实现了对动态游戏情况的适应性。

Abstract: This study proposes a method to improve the performance of Werewolf agents by
switching between predefined strategies based on the attitudes of other players
and the context of conversations. While prior works of Werewolf agents using
prompt engineering have employed methods where effective strategies are
implicitly defined, they cannot adapt to changing situations. In this research,
we propose a method that explicitly selects an appropriate strategy based on
the game context and the estimated roles of other players. We compare the
strategy adaptation Werewolf agents with baseline agents using implicit or
fixed strategies and verify the effectiveness of our proposed method.

</details>


### [99] [Logit Arithmetic Elicits Long Reasoning Capabilities Without Training](https://arxiv.org/abs/2507.12759)
*Yunxiang Zhang,Muhammad Khalifa,Lechen Zhang,Xin Liu,Ayoung Lee,Xinliang Frederick Zhang,Farima Fatahi Bayat,Lu Wang*

Main category: cs.CL

TL;DR: 本研究提出ThinkLogit，一种利用小模型指导大模型进行长推理的解码时方法，无需或只需少量训练即可提升数学推理能力，并可通过DPO进一步优化。


<details>
  <summary>Details</summary>
Motivation: 探索在无需额外训练的情况下，激发大型语言模型（LLM）进行长推理（例如回溯和自我纠正）的能力。

Method: 提出了一种名为ThinkLogit的解码时方法，利用较小模型的logits算术来指导较大的目标模型进行长推理。此外，通过使用DPO（直接偏好优化）对指导模型进行训练，可以进一步提升性能。

Result: ThinkLogit在数学推理任务上，相比基线模型Qwen2.5-32B，使用小模型R1-Distill-Qwen-1.5B作为指导，pass@1 准确率提高了26%。ThinkLogit-DPO 进一步将准确率提高了29%。此外，ThinkLogit还能将通过强化学习获得的推理能力转移给目标模型，pass@1 相对提高了13%。

Conclusion: 这项工作提出了一种在解码时增强大型语言模型（LLM）进行复杂推理能力的方法，该方法具有计算效率高且几乎无需额外训练的优点。

Abstract: Large reasoning models (LRMs) can do complex reasoning via long
chain-of-thought (CoT) involving cognitive strategies such as backtracking and
self-correction. Recent studies suggest that some models inherently possess
these long reasoning abilities, which may be unlocked via extra training. Our
work first investigates whether we can elicit such behavior without any
training. To this end, we propose a decoding-time approach, ThinkLogit, which
utilizes logits arithmetic (Liu et al., 2024) to tune a target large LM for
long reasoning using a substantially smaller model as guider. We then show that
we can further boost performance by training the guider model with preference
optimization over correct/incorrect reasoning pairs sampled from both the
target and guider model -- a setup we refer to as ThinkLogit-DPO. Our
experiments demonstrate that ThinkLogit and ThinkLogit-DPO achieve a relative
improvement in pass@1 by 26% and 29%, respectively, over four mathematical
datasets using the Qwen2.5-32B when guided by R1-Distill-Qwen-1.5B -- a model
21x smaller. Lastly, we show that ThinkLogit can transfer long reasoning skills
acquired through reinforcement learning, improving pass@1 by 13% relative
compared to the Qwen2.5-32B base model. Our work presents a
computationally-efficient method to elicit long reasoning in large models with
minimal or no additional training.

</details>


### [100] [Synergy: End-to-end Concept Model](https://arxiv.org/abs/2507.12769)
*Keli Zheng,Zerong Xie*

Main category: cs.CL

TL;DR: Synergy is a new byte-level language model that bridges different abstraction levels using learned routing. It tokenizes bytes efficiently, outperforms Llama3 at similar scales, and shows potential for position-independent concept learning.


<details>
  <summary>Details</summary>
Motivation: To bridge different levels of abstraction in an end-to-end fashion through a learned routing mechanism.

Method: Synergy, a language model that bridges different levels of abstraction in an end-to-end fashion through a learned routing mechanism. Trained as a byte-level language model, it learns to tokenize bytes, producing fewer concept tokens than BBPE while maintaining comparable performance. When compared to Llama3 at the same scale and dataset size, Synergy showed an advantage. Further studies indicated that removing positional encodings from the middle part of the model improved performance, suggesting the emergence of position-independent concepts.

Result: Synergy spontaneously learns to tokenize bytes, producing fewer concept tokens than BBPE while keeping comparable performance. Synergy showed an advantage over Llama3 at the same model scale and training dataset size. Removing positional encodings from the middle part of the model improved performance, suggesting the emergence of position-independent concepts.

Conclusion: The findings demonstrate the feasibility of tokenizer-free architectures, paving the way for more robust and flexible pipelines.

Abstract: In this paper, we present Synergy, a language model that bridges different
levels of abstraction in an end-to-end fashion through a learned routing
mechanism. Focusing on low-level linguistic abstraction, we trained our model
as a byte-level language model. Our model spontaneously learns to tokenize
bytes, producing fewer concept tokens than Byte-level Byte Pair Encoder (BBPE)
tokenizers while keeping comparable performance. By comparing with Llama3, we
observed an advantage of Synergy under the same model scale and training
dataset size. Further studies show that the middle part (the higher abstraction
part) of our model performs better when positional encodings are removed,
suggesting the emergence of position-independent concepts. These findings
demonstrate the feasibility of tokenizer-free architectures, paving the way for
more robust and flexible pipelines.

</details>


### [101] [Learning Robust Negation Text Representations](https://arxiv.org/abs/2507.12782)
*Thinh Hung Truong,Karin Verspoor,Trevor Cohn,Timothy Baldwin*

Main category: cs.CL

TL;DR: 通过蒸馏LLM数据来增强BERT等文本编码器的否定理解能力，同时不牺牲通用性能。


<details>
  <summary>Details</summary>
Motivation: 现有的文本编码器在处理否定这种重要的语义功能时仍有不足，这影响了许多依赖文本嵌入的下游应用。

Method: 采用标准的对比学习策略来微调一个基于BERT的模型，并使用多样化的否定和委婉模式对大型语言模型进行蒸馏。

Result: 在否定理解能力方面取得了显著的改进，并且在一般基准测试上保持了具有竞争力的性能。此外，该方法也可应用于大型语言模型，从而提高了在否定基准测试上的性能。

Conclusion: 提出了一种通过蒸馏大型语言模型的数据来提高文本编码器在处理否定理解能力上的鲁棒性，同时保持在一般基准测试上的竞争力。

Abstract: Despite rapid adoption of autoregressive large language models, smaller text
encoders still play an important role in text understanding tasks that require
rich contextualized representations. Negation is an important semantic function
that is still not properly captured by such methods, affecting many downstream
applications relying on text embeddings. We propose a strategy to improve
negation robustness of text encoders, by distilling data from large language
models using diverse patterns of negation and hedging. We adopt a standard
contrastive learning strategy to finetune a strong BERT-based model, and
observe large improvement in negation understanding capabilities while
maintaining competitive performance on general benchmarks. In addition, we also
show that our method can be adapted to LLMs, leading to improved performance on
negation benchmarks.

</details>


### [102] [Large Language Models' Internal Perception of Symbolic Music](https://arxiv.org/abs/2507.12808)
*Andrew Shin,Kunitake Kaneko*

Main category: cs.CL

TL;DR: LLMs can generate basic symbolic music from text descriptions, showing potential but also limitations due to a lack of explicit musical knowledge.


<details>
  <summary>Details</summary>
Motivation: To explore the extent to which LLMs implicitly model symbolic music, given their success in natural language and other symbolic domains.

Method: The study generates a dataset of LLM-generated MIDI files from textual prompts describing genres and styles, without relying on explicit musical training. Neural networks are then trained on this dataset for genre/style classification and melody completion, benchmarking against established models.

Result: The LLM-generated MIDI dataset enables training models that perform genre/style classification and melody completion, demonstrating LLMs' ability to infer basic musical structures and temporal relationships from text.

Conclusion: LLMs can infer rudimentary musical structures and temporal relationships from text, indicating potential for implicit encoding of musical patterns, but also revealing limitations due to the lack of explicit musical context.

Abstract: Large language models (LLMs) excel at modeling relationships between strings
in natural language and have shown promise in extending to other symbolic
domains like coding or mathematics. However, the extent to which they
implicitly model symbolic music remains underexplored. This paper investigates
how LLMs represent musical concepts by generating symbolic music data from
textual prompts describing combinations of genres and styles, and evaluating
their utility through recognition and generation tasks. We produce a dataset of
LLM-generated MIDI files without relying on explicit musical training. We then
train neural networks entirely on this LLM-generated MIDI dataset and perform
genre and style classification as well as melody completion, benchmarking their
performance against established models. Our results demonstrate that LLMs can
infer rudimentary musical structures and temporal relationships from text,
highlighting both their potential to implicitly encode musical patterns and
their limitations due to a lack of explicit musical context, shedding light on
their generative capabilities for symbolic music.

</details>


### [103] [Are Knowledge and Reference in Multilingual Language Models Cross-Lingually Consistent?](https://arxiv.org/abs/2507.12838)
*Xi Ai,Mahardika Krisna Ihsani,Min-Yen Kan*

Main category: cs.CL

TL;DR: 分析了跨语言知识一致性，研究了代码混合同指陈述，发现多语言模型在一致性上表现不同，并提出了代码转换训练和跨语言词对齐等改进方法。


<details>
  <summary>Details</summary>
Motivation: 跨语言一致性应被考虑在内，以评估跨语言迁移性、在语言之间保持模型知识的事实性以及保持语言模型性能的均等性。因此，我们有兴趣分析、评估和解释事实知识的跨语言一致性。

Method: 我们检查了跨代码混合的同指陈述，这些陈述在语言之间传达了相同的知识，以研究跨语言知识一致性。我们使用一些可解释性方法来分析模型在跨语言环境中的行为。

Result: 研究发现多语言模型表现出不同程度的一致性，这取决于语系、语言因素以及在特定层上跨语言一致性的瓶颈。此外，我们评估了旨在改善多语言表现的常见策略，以观察这些策略是否能同时改善知识一致性。

Conclusion: 尽管知识在大多数情况下并非跨语言一致，但代码转换训练和跨语言词对齐目标显示出最有希望的结果，这强调了跨语言对齐监督和代码转换训练对于提高多语言性能和跨语言一致性都具有重要意义。

Abstract: Cross-lingual consistency should be considered to assess cross-lingual
transferability, maintain the factuality of the model knowledge across
languages, and preserve the parity of language model performance. We are thus
interested in analyzing, evaluating, and interpreting cross-lingual consistency
for factual knowledge. We examine code-mixed coreferential statements conveyed
identical knowledge across languages to study cross-lingual knowledge
consistency. We use some interpretability approaches to analyze the behavior of
a model in cross-lingual contexts, discovering that multilingual models show
different levels of consistency, subject to language families, linguistic
factors, and a bottleneck in cross-lingual consistency on a particular layer.
In addition, we evaluate common strategies aimed at improving multilingual
performance to observe whether these strategies can improve knowledge
consistency at the same time. While knowledge is not cross-lingual consistency
in many cases, code-switching training and cross-lingual word alignment
objectives show the most promising results, emphasizing the noteworthiness of
cross-lingual alignment supervision and code-switching training for both
multilingual performance and cross-lingual consistency enhancement.

</details>


### [104] [Making Language Model a Hierarchical Classifier and Generator](https://arxiv.org/abs/2507.12930)
*Yihong Wang,Zhonglin Jiang,Ningyuan Xi,Yue Zhao,Qingqing Gu,Xiyuan Chen,Hao Wu,Sheng Xu,Hange Zhou,Yong Chen,Luo Ji*

Main category: cs.CL

TL;DR: 受人类分层思维的启发，研究人员提出了一种分层解码器架构，通过将预训练语言模型的语言头复制到中间层并进行微调，在各种任务上取得了最先进的性能，并暗示了通用分层推理器的可能性。


<details>
  <summary>Details</summary>
Motivation: 受人类分层思维能力的启发，提出了一种分层解码器架构，其中不同的层可以同时解码文本。

Method: 通过将预训练语言模型的语言头复制到选定的中间层，并使用不同的任务输入进行微调，来构建分层解码器架构。

Result: 所选的中间层可以被调整以产生有意义且合理的内容，并且这种分层解码器范式在多项任务上获得了最先进的性能，例如分层文本分类、分类引导生成和分层文本生成。

Conclusion: 该研究表明，从头开始预训练的通用分层推理器是可能的。

Abstract: Decoder-only language models, such as GPT and LLaMA, generally decode on the
last layer. Motivated by human's hierarchical thinking capability, we propose
that a hierarchical decoder architecture could be built with different layers
decoding texts simultaneously. Due to limited time and computationally
resources, we choose to adapt a pretrained language model into this form of
hierarchical decoder. Language heads of the last layer are copied to different
selected intermediate layers, and fine-tuned with different task inputs. By
thorough experiments, we validate that these selective intermediate layers
could be adapted to speak meaningful and reasonable contents, and this paradigm
of hierarchical decoder can obtain state-of-the-art performances on multiple
tasks such as hierarchical text classification, classification-guided
generation, and hierarchical text generation. This study suggests the
possibility of a generalized hierarchical reasoner, pretraining from scratch.

</details>


### [105] [MRT at IberLEF-2025 PRESTA Task: Maximizing Recovery from Tables with Multiple Steps](https://arxiv.org/abs/2507.12981)
*Maximiliano Hormazábal Lagos,Álvaro Bueno Sáez,Héctor Cerezo-Costas,Pedro Alonso Doval,Jorge Alcalde Vesteiro*

Main category: cs.CL

TL;DR: 一种利用LLM生成Python代码来回答西班牙语表格问题的有效方法，在IberLEF 2025 PRESTA任务中准确率达到85%。


<details>
  <summary>Details</summary>
Motivation: 为了解决IberLEF 2025任务PRESTA（西班牙语表格问答），提出了一种基于代码生成的方法。

Method: 通过使用语言模型（LLMs）生成Python代码来过滤和处理表格数据，该过程包括分析表格内容、选择相关列、生成自然语言指令、将指令转换为代码、执行代码以及处理潜在错误。

Result: 在IberLEF 2025 PRESTA任务中达到了85%的准确率。

Conclusion: 该方法实现了85%的准确率，展示了在西班牙语表格问答任务中的有效性。

Abstract: This paper presents our approach for the IberLEF 2025 Task PRESTA: Preguntas
y Respuestas sobre Tablas en Espa\~nol (Questions and Answers about Tables in
Spanish). Our solution obtains answers to the questions by implementing Python
code generation with LLMs that is used to filter and process the table. This
solution evolves from the MRT implementation for the Semeval 2025 related task.
The process consists of multiple steps: analyzing and understanding the content
of the table, selecting the useful columns, generating instructions in natural
language, translating these instructions to code, running it, and handling
potential errors or exceptions. These steps use open-source LLMs and
fine-grained optimized prompts for each step. With this approach, we achieved
an accuracy score of 85\% in the task.

</details>


### [106] [Formalizing Attack Scenario Description: A Proposed Model](https://arxiv.org/abs/2507.13076)
*Quentin Goux,Nadira Lammari*

Main category: cs.CL

TL;DR: 提出了一种形式化模型，用于网络安全中的攻击场景描述，支持攻击分析和培训脚本生成。


<details>
  <summary>Details</summary>
Motivation: 组织面临不断变化的威胁，需要自动化网络安全流程，而自动化需要形式化的输入数据，特别是针对攻击场景。

Method: 提出了一种用于描述攻击上下文和场景的形式化模型，并使用UML类图进行抽象。

Result: 该模型可用于上游攻击分析过程，并可自动生成网络安全培训的攻击脚本。

Conclusion: 该研究提出了一种新的形式化模型，用于描述攻击上下文和场景，并展示了其在攻击分析和网络安全培训脚本自动生成方面的应用。

Abstract: Organizations face an ever-changing threat landscape. They must continuously
dedicate significant efforts to protect their assets, making their adoption of
increased cybersecurity automation inevitable. However, process automation
requires formalization of input data. Through this paper, we address this need
for processes that use attack scenarios as input. Among these processes, one
can mention both the generation of scripts for attack simulation and training
purposes, as well as the analysis of attacks. Therefore, the paper's main
research contribution is a novel formal model that encompasses the attack's
context description and its scenario. It is abstracted using UML class model.
Once the description of our model done, we will show how it could serve an
upstream attack analysis process. We will show also its use for an automatic
generation of attack scripts in the context of cybersecurity training. These
two uses cases constitute the second contribution of this present research
work.

</details>


### [107] [SemCSE: Semantic Contrastive Sentence Embeddings Using LLM-Generated Summaries For Scientific Abstracts](https://arxiv.org/abs/2507.13105)
*Marc Brinner,Sina Zarriess*

Main category: cs.CL

TL;DR: SemCSE是一种无监督方法，利用LLM生成的摘要进行对比学习，以获得更好的科学文本语义嵌入，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统基于引文的方法未能准确反映语义相似性的问题，提出了一种新的无监督学习方法来学习科学文本的语义嵌入。

Method: SemCSE是一种利用大型语言模型生成的摘要来训练模型的无监督学习方法，通过对比学习将语义相关的摘要在嵌入空间中拉近。

Result: SemCSE在新的基准测试中展示了其在理解和编码科学文本语义内容方面的能力，并在SciRepEval基准测试中取得了同体量模型中的最佳性能。

Conclusion: SemCSE在SciRepEval基准测试中取得了最先进的性能，证明了其语义驱动的训练方法的有效性。

Abstract: We introduce SemCSE, an unsupervised method for learning semantic embeddings
of scientific texts. Building on recent advances in contrastive learning for
text embeddings, our approach leverages LLM-generated summaries of scientific
abstracts to train a model that positions semantically related summaries closer
together in the embedding space. This resulting objective ensures that the
model captures the true semantic content of a text, in contrast to traditional
citation-based approaches that do not necessarily reflect semantic similarity.
To validate this, we propose a novel benchmark designed to assess a model's
ability to understand and encode the semantic content of scientific texts,
demonstrating that our method enforces a stronger semantic separation within
the embedding space. Additionally, we evaluate SemCSE on the comprehensive
SciRepEval benchmark for scientific text embeddings, where it achieves
state-of-the-art performance among models of its size, thus highlighting the
benefits of a semantically focused training approach.

</details>


### [108] [A Computational Framework to Identify Self-Aspects in Text](https://arxiv.org/abs/2507.13115)
*Jaya Caporusso,Matthew Purver,Senja Pollak*

Main category: cs.CL

TL;DR: 开发一个计算框架来识别文本中的自我方面，并将在心理健康和现象学研究中进行案例研究。


<details>
  <summary>Details</summary>
Motivation: 自我是语言中反映的多方面构建，在自然语言处理领域仍未得到充分探索，但与心理健康等重要领域相关，因此需要基于NLP的系统分析。

Method: 开发一个包含自我方面本体和黄金标准标注数据集的计算框架，并评估判别模型、生成大语言模型和基于嵌入的检索方法。

Result: 开发和评估用于识别自我方面的计算框架，并在心理健康和现象学研究中进行应用。

Conclusion: 该博士论文计划开发一个计算框架来识别文本中的自我方面，并将在心理健康和现象学研究中进行案例研究。

Abstract: This Ph.D. proposal introduces a plan to develop a computational framework to
identify Self-aspects in text. The Self is a multifaceted construct and it is
reflected in language. While it is described across disciplines like cognitive
science and phenomenology, it remains underexplored in natural language
processing (NLP). Many of the aspects of the Self align with psychological and
other well-researched phenomena (e.g., those related to mental health),
highlighting the need for systematic NLP-based analysis. In line with this, we
plan to introduce an ontology of Self-aspects and a gold-standard annotated
dataset. Using this foundation, we will develop and evaluate conventional
discriminative models, generative large language models, and embedding-based
retrieval approaches against four main criteria: interpretability, ground-truth
adherence, accuracy, and computational efficiency. Top-performing models will
be applied in case studies in mental health and empirical phenomenology.

</details>


### [109] [Assessing the Reliability of LLMs Annotations in the Context of Demographic Bias and Model Explanation](https://arxiv.org/abs/2507.13138)
*Hadi Mohammadi,Tina Shahedi,Pablo Mosteiro,Massimo Poesio,Ayoub Bagheri,Anastasia Giachanou*

Main category: cs.CL

TL;DR: 人口统计学特征对NLP注释的影响很小，而文本内容是主要因素。引导GenAI模型进行人口统计学评估并未改善其性能，XAI技术表明模型预测依赖于内容。研究建议，应侧重于内容驱动的解释和稳健的注释协议，以实现公平性。


<details>
  <summary>Details</summary>
Motivation: 为了开发公平的自然语言处理（NLP）系统，特别是像性别歧视检测这样的任务，了解注释中变异性的来源至关重要，因为人口偏见是一个令人担忧的问题。

Method: 使用通用线性混合模型量化人口特征对标签决策的影响，并评估生成式人工智能（GenAI）模型作为注释者的可靠性，重点是引导它们进行人口统计学评估，最后使用可解释人工智能（XAI）技术分析模型的预测。

Result: 研究结果表明，尽管人口统计学因素具有统计学上的显著性，但它们只占观察到的变异性的一小部分（8%），而推文内容是主要因素。此外，将GenAI模型与人口统计学特征进行对比后发现，引导它们进行人口统计学评估通常无法提升性能，有时反而会降低性能。XAI技术表明，模型预测主要依赖与性别歧视相关的特定内容标记，而非人口统计学特征的关联。

Conclusion: 这项研究认为，专注于以内容为驱动的解释和健全的注释协议，比模拟个人特征更能提供通往公平的可靠途径。

Abstract: Understanding the sources of variability in annotations is crucial for
developing fair NLP systems, especially for tasks like sexism detection where
demographic bias is a concern. This study investigates the extent to which
annotator demographic features influence labeling decisions compared to text
content. Using a Generalized Linear Mixed Model, we quantify this inf luence,
finding that while statistically present, demographic factors account for a
minor fraction ( 8%) of the observed variance, with tweet content being the
dominant factor. We then assess the reliability of Generative AI (GenAI) models
as annotators, specifically evaluating if guiding them with demographic
personas improves alignment with human judgments. Our results indicate that
simplistic persona prompting often fails to enhance, and sometimes degrades,
performance compared to baseline models. Furthermore, explainable AI (XAI)
techniques reveal that model predictions rely heavily on content-specific
tokens related to sexism, rather than correlates of demographic
characteristics. We argue that focusing on content-driven explanations and
robust annotation protocols offers a more reliable path towards fairness than
potentially persona simulation.

</details>


### [110] [Feature-based analysis of oral narratives from Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13164)
*Emma Sharratt,Annelien Smith,Retief Louw,Daleen Klop,Febe de Wet,Herman Kamper*

Main category: cs.CL

TL;DR: 本研究使用机器学习分析了南非荷兰语和科萨语儿童的口语叙述，发现词汇丰富度和平均句长是重要的发展指标，某些动词的使用与较低的干预需求相关，这对于多语言背景下的早期评估具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 研究旨在识别需要干预的儿童的口语叙述特征，以预测其未来的读写能力发展，并为多语言背景下的早期评估提供依据。

Method: 本研究使用简单的机器学习方法，分析了4至5岁南非荷兰语和科萨语儿童的有声故事，重点关注词汇丰富度、平均句长和发音流利度等特征，并关联了是否需要干预。

Result: 研究发现，词汇丰富度和平均句长是衡量儿童叙事发展的指标，而发音流利度则信息量较少。尽管不同语言的词性模式存在差异，但使用与目标导向叙事相关的特定动词和助动词，可以降低儿童接受干预的可能性。

Conclusion: 该研究发现了两种语言中都存在的、与叙事能力相关的指标，并指出了在多语言背景下早期评估的潜在应用。

Abstract: Oral narrative skills are strong predictors of later literacy development.
This study examines the features of oral narratives from children who were
identified by experts as requiring intervention. Using simple machine learning
methods, we analyse recorded stories from four- and five-year-old Afrikaans-
and isiXhosa-speaking children. Consistent with prior research, we identify
lexical diversity (unique words) and length-based features (mean utterance
length) as indicators of typical development, but features like articulation
rate prove less informative. Despite cross-linguistic variation in
part-of-speech patterns, the use of specific verbs and auxiliaries associated
with goal-directed storytelling is correlated with a reduced likelihood of
requiring intervention. Our analysis of two linguistically distinct languages
reveals both language-specific and shared predictors of narrative proficiency,
with implications for early assessment in multilingual contexts.

</details>


### [111] [GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems](https://arxiv.org/abs/2507.13190)
*Jisoo Lee,Raeyoung Chang,Dongwook Kwon,Harmanpreet Singh,Nikhil Verma*

Main category: cs.CL

TL;DR: GEMMAS is a new evaluation framework for multi-agent language models that analyzes the internal collaboration process using graph-based metrics, revealing inefficiencies missed by traditional accuracy-focused evaluations.


<details>
  <summary>Details</summary>
Motivation: Existing evaluations of multi-agent language models focus only on the correctness of the final output, overlooking inefficiencies in communication and coordination that lead to redundant reasoning and higher computational costs.

Method: A graph-based evaluation framework called GEMMAS is introduced, which models agent interactions as a directed acyclic graph. Two process-level metrics, Information Diversity Score (IDS) and Unnecessary Path Ratio (UPR), are proposed to measure collaboration quality.

Result: GEMMAS was evaluated across five benchmarks, including GSM8K. Results on GSM8K showed that systems with only a 2.1% difference in accuracy differed by 12.8% in IDS and 80% in UPR, indicating substantial variation in internal collaboration.

Conclusion: Outcome-only metrics are insufficient for evaluating multi-agent performance, and process-level diagnostics are important for designing more interpretable and resource-efficient collaborative AI systems.

Abstract: Multi-agent systems built on language models have shown strong performance on
collaborative reasoning tasks. However, existing evaluations focus only on the
correctness of the final output, overlooking how inefficient communication and
poor coordination contribute to redundant reasoning and higher computational
costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes
the internal collaboration process by modeling agent interactions as a directed
acyclic graph. To capture collaboration quality, we propose two process-level
metrics: Information Diversity Score (IDS) to measure semantic variation in
inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant
reasoning paths. We evaluate GEMMAS across five benchmarks and highlight
results on GSM8K, where systems with only a 2.1% difference in accuracy differ
by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal
collaboration. These findings demonstrate that outcome-only metrics are
insufficient for evaluating multi-agent performance and highlight the
importance of process-level diagnostics in designing more interpretable and
resource-efficient collaborative AI systems.

</details>


### [112] [Automatically assessing oral narratives of Afrikaans and isiXhosa children](https://arxiv.org/abs/2507.13205)
*R. Louw,E. Sharratt,F. de Wet,C. Jacobs,A. Smith,H. Kamper*

Main category: cs.CL

TL;DR: 为学前儿童的阿非利堪语和伊西Xhosa语口语叙事开发了自动评估系统，其中 LLM 方法优于线性模型，并在识别需要额外支持的儿童方面与人类专家相当。


<details>
  <summary>Details</summary>
Motivation: 为了解决学前教师在大型教室中难以准确识别需要干预的学生的问题。

Method: 使用自动语音识别和机器学习评分模型来预测学龄前儿童的叙事和理解能力得分，并将线性模型与大型语言模型（LLM）进行了比较。

Result: 与线性模型相比，基于 LLM 的系统在大多数情况下表现更好，但线性系统尽管简单，却具有竞争力。

Conclusion: 所提出的自动评估系统在标记需要干预的儿童方面与人类专家相当，并为在课堂中进行自动口语评估奠定了基础。

Abstract: Developing narrative and comprehension skills in early childhood is critical
for later literacy. However, teachers in large preschool classrooms struggle to
accurately identify students who require intervention. We present a system for
automatically assessing oral narratives of preschool children in Afrikaans and
isiXhosa. The system uses automatic speech recognition followed by a machine
learning scoring model to predict narrative and comprehension scores. For
scoring predicted transcripts, we compare a linear model to a large language
model (LLM). The LLM-based system outperforms the linear model in most cases,
but the linear system is competitive despite its simplicity. The LLM-based
system is comparable to a human expert in flagging children who require
intervention. We lay the foundation for automatic oral assessments in
classrooms, giving teachers extra capacity to focus on personalised support for
children's learning.

</details>


### [113] [Enhancing Cross-task Transfer of Large Language Models via Activation Steering](https://arxiv.org/abs/2507.13236)
*Xinyu Tang,Zhihao Lv,Xiaoxue Cheng,Junyi Li,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large language models (LLMs) have shown impressive abilities in leveraging
pretrained knowledge through prompting, but they often struggle with unseen
tasks, particularly in data-scarce scenarios. While cross-task in-context
learning offers a direct solution for transferring knowledge across tasks, it
still faces critical challenges in terms of robustness, scalability, and
efficiency. In this paper, we investigate whether cross-task transfer can be
achieved via latent space steering without parameter updates or input
expansion. Through an analysis of activation patterns in the latent space of
LLMs, we observe that the enhanced activations induced by in-context examples
have consistent patterns across different tasks. Inspired by these findings, we
propose CAST, a novel Cross-task Activation Steering Transfer framework that
enables effective transfer by manipulating the model's internal activation
states. Our approach first selects influential and diverse samples from
high-resource tasks, then utilizes their contrastive representation-enhanced
activations to adapt LLMs to low-resource tasks. Extensive experiments across
both cross-domain and cross-lingual transfer settings show that our method
outperforms competitive baselines and demonstrates superior scalability and
lower computational costs.

</details>


### [114] [HATS: Hindi Analogy Test Set for Evaluating Reasoning in Large Language Models](https://arxiv.org/abs/2507.13238)
*Ashray Gupta,Rohan Joseph,Sunny Rai*

Main category: cs.CL

TL;DR: 该研究通过引入印地语类比测试集（HATS）和链式思考方法，评估了大型语言模型在印地语中的推理能力，并发现英语提示能提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 目前对大型语言模型在印地语等印度语言中的推理能力评估不足，这限制了我们对其跨语言泛化能力的理解。

Method: 利用印地语类比测试集（HATS）对标杆大型语言模型进行基准测试，并引入一种基于认知理论的链式思考方法来改进模型在印地语类比推理任务上的表现。

Result: 所提出的链式思考方法提高了模型在印地语类比任务上的表现。然而，实验表明，无论采用何种提示策略，模型在英语提示下的表现最佳。此外，该研究还提供了一个关键资源，用于评估大型语言模型在印地语中的推理能力。

Conclusion: 该研究引入了一个新的印地语类比测试集（HATS），并提出了一种基于认知理论的链式思考方法，以评估大型语言模型在印地语中的推理能力。实验表明，即使使用印地语提示，模型在印地语类比任务上的表现也优于英语提示，这表明需要更多针对印地语的评估资源。

Abstract: Analogies test a model's ability to infer implicit relationships between
concepts, making them a key benchmark for evaluating reasoning capabilities.
While large language models (LLMs) are widely evaluated for reasoning in
English, their abilities in Indic languages remain understudied, limiting our
understanding of whether these models generalize across languages. To address
this gap, we introduce a new Hindi Analogy Test Set (HATS), comprising 405
multiple-choice questions sourced from Indian government exams. We benchmark
state-of-the-art multilingual LLMs using various prompting strategies and
introduce a grounded Chain of Thought approach that leverages cognitive
theories of analogical reasoning. This approach improves model performance on
Hindi analogy questions. Our experiments show that models perform best with
English prompts, irrespective of the prompting strategy. Our test set addresses
the lack of a critical resource to evaluate LLM reasoning capabilities in
Hindi.

</details>


### [115] [Automating Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2507.13255)
*Lyucheng Wu,Mengru Wang,Ziwen Xu,Tri Cao,Nay Oo,Bryan Hooi,Shumin Deng*

Main category: cs.CL

TL;DR: AutoSteer通过SAS、自适应安全探测器和拒绝头，在不进行微调的情况下，提高了MLLMs处理对抗性多模态输入的安全性，降低了攻击成功率，同时保持了模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高多模态大语言模型（MLLMs）在推理过程中的安全性，特别是面对对抗性多模态输入时。

Method: AutoSteer是一种模块化、自适应的推理时干预技术，无需对底层模型进行微调。它包含三个核心组件：(1) 安全意识分数（SAS），用于自动识别模型内部层中最具安全相关性的区分；(2) 自适应安全探测器，用于估计中间表示产生有毒输出的可能性；(3) 轻量级拒绝头，用于在检测到安全风险时选择性地干预和调节生成。

Result: 实验表明，AutoSteer在LLaVA-OV和Chameleon上显著降低了文本、视觉和跨模态威胁的攻击成功率（ASR），同时保持了通用能力。

Conclusion: AutoSteer是一个实用、可解释且有效的框架，可用于更安全地部署多模态人工智能系统。

Abstract: Recent progress in Multimodal Large Language Models (MLLMs) has unlocked
powerful cross-modal reasoning abilities, but also raised new safety concerns,
particularly when faced with adversarial multimodal inputs. To improve the
safety of MLLMs during inference, we introduce a modular and adaptive
inference-time intervention technology, AutoSteer, without requiring any
fine-tuning of the underlying model. AutoSteer incorporates three core
components: (1) a novel Safety Awareness Score (SAS) that automatically
identifies the most safety-relevant distinctions among the model's internal
layers; (2) an adaptive safety prober trained to estimate the likelihood of
toxic outputs from intermediate representations; and (3) a lightweight Refusal
Head that selectively intervenes to modulate generation when safety risks are
detected. Experiments on LLaVA-OV and Chameleon across diverse safety-critical
benchmarks demonstrate that AutoSteer significantly reduces the Attack Success
Rate (ASR) for textual, visual, and cross-modal threats, while maintaining
general abilities. These findings position AutoSteer as a practical,
interpretable, and effective framework for safer deployment of multimodal AI
systems.

</details>


### [116] [QuestA: Expanding Reasoning Capacity in LLMs via Question Augmentation](https://arxiv.org/abs/2507.13266)
*Jiazheng Li,Hong Lu,Kaiyue Wen,Zaiwen Yang,Jiaxuan Gao,Hongzhou Lin,Yi Wu,Jingzhao Zhang*

Main category: cs.CL

TL;DR: QuestA是一种通过在RL训练中加入部分解来提升LLM多步推理能力的方法，尤其擅长解决难题，并在数学推理任务上取得了SOTA效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有强化学习方法在提升大型语言模型（LLM）的多步推理能力，尤其是在困难问题上的有效性方面存在的不足。

Method: QuestA通过在强化学习（RL）训练过程中引入部分解决方案来增强语言模型的学习信号，降低问题难度。

Result: QuestA在数学推理任务上的应用，不仅提高了pass@1指标，也提升了pass@k指标，尤其是在标准RL难以取得进展的问题上。其在1.5B参数模型上，于AIME24、AIME25和HMMT25基准测试中分别取得了67.1%、59.5%和35.5%的准确率，创下了新的最先进记录。此外，QuestA还被证明能提高样本效率，为通过RL扩展推理能力提供了一条实用且可推广的途径。

Conclusion: QuestA通过引入部分解来降低训练难度并提供更具信息量的学习信号，从而有效提升了语言模型的多步推理能力，尤其在困难问题上。该方法能够持续改进现有的开源模型，并在数学推理基准测试中取得了新的最先进成果。

Abstract: Reinforcement learning (RL) has become a key component in training large
language reasoning models (LLMs). However, recent studies questions its
effectiveness in improving multi-step reasoning-particularly on hard problems.
To address this challenge, we propose a simple yet effective strategy via
Question Augmentation: introduce partial solutions during training to reduce
problem difficulty and provide more informative learning signals. Our method,
QuestA, when applied during RL training on math reasoning tasks, not only
improves pass@1 but also pass@k-particularly on problems where standard RL
struggles to make progress. This enables continual improvement over strong
open-source models such as DeepScaleR and OpenMath Nemotron, further enhancing
their reasoning capabilities. We achieve new state-of-the-art results on math
benchmarks using 1.5B-parameter models: 67.1% (+5.3%) on AIME24, 59.5% (+10.0%)
on AIME25, and 35.5% (+4.0%) on HMMT25. Further, we provide theoretical
explanations that QuestA improves sample efficiency, offering a practical and
generalizable pathway for expanding reasoning capability through RL.

</details>


### [117] [Overview of the TalentCLEF 2025: Skill and Job Title Intelligence for Human Capital Management](https://arxiv.org/abs/2507.13275)
*Luis Gasco,Hermenegildo Fabregat,Laura García-Sardiña,Paula Estrella,Daniel Deniz,Alvaro Rodrigo,Rabih Zbib*

Main category: cs.CL

TL;DR: TalentCLEF 2025 是第一个专注于技能和职位智能的评估活动，旨在为人力资本管理领域提供公开基准。该活动包含多语言职位匹配和基于职位技能的预测任务，使用真实且经过注释的劳动力市场数据。研究结果表明，训练策略比模型规模对系统性能影响更大，并强调了开发稳健、公平且可转移的劳动力市场语言技术的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理和大型语言模型的进步，人力资本管理领域正经历重大变革，人们对构建基于语言技术的人才获取、技能提升策略和劳动力规划的智能系统越来越感兴趣。然而，这些技术的采用和进展在很大程度上依赖于可靠且公平的模型的发展，而这些模型需要妥善地在公开数据和公开基准上进行评估，而目前在这一领域尚缺乏此类资源。

Method: 本研究提出了 TalentCLEF 2025，这是一个专注于技能和职位智能的评估活动，包含两个任务：A 任务 - 多语言职位匹配（涵盖英语、西班牙语、德语和中文）和 B 任务 - 基于职位技能的预测（英语）。两个语料库均来自真实工作申请，经过匿名化和手动注释，以反映真实劳动力市场数据的复杂性和多样性。评估涵盖了单一语言和跨语言场景，并对性别偏见进行了评估。

Result: TalentCLEF 吸引了 76 个注册团队和 280 多个提交。大多数系统都依赖于使用多语言编码器模型进行信息检索技术，并通过对比学习进行微调，其中一些系统还结合了大型语言模型进行数据增强或重新排序。结果表明，训练策略比模型规模本身对结果有更大的影响。

Conclusion: TalentCLEF 2025 提供了该领域的第一个公共基准，并鼓励为劳动力市场开发稳健、公平且可转移的语言技术。

Abstract: Advances in natural language processing and large language models are driving
a major transformation in Human Capital Management, with a growing interest in
building smart systems based on language technologies for talent acquisition,
upskilling strategies, and workforce planning. However, the adoption and
progress of these technologies critically depend on the development of reliable
and fair models, properly evaluated on public data and open benchmarks, which
have so far been unavailable in this domain.
  To address this gap, we present TalentCLEF 2025, the first evaluation
campaign focused on skill and job title intelligence. The lab consists of two
tasks: Task A - Multilingual Job Title Matching, covering English, Spanish,
German, and Chinese; and Task B - Job Title-Based Skill Prediction, in English.
Both corpora were built from real job applications, carefully anonymized, and
manually annotated to reflect the complexity and diversity of real-world labor
market data, including linguistic variability and gender-marked expressions.
  The evaluations included monolingual and cross-lingual scenarios and covered
the evaluation of gender bias.
  TalentCLEF attracted 76 registered teams with more than 280 submissions. Most
systems relied on information retrieval techniques built with multilingual
encoder-based models fine-tuned with contrastive learning, and several of them
incorporated large language models for data augmentation or re-ranking. The
results show that the training strategies have a larger effect than the size of
the model alone. TalentCLEF provides the first public benchmark in this field
and encourages the development of robust, fair, and transferable language
technologies for the labor market.

</details>


### [118] [Multi-Agent Synergy-Driven Iterative Visual Narrative Synthesis](https://arxiv.org/abs/2507.13285)
*Wang Xi,Quan Shi,Tian Yu,Yujie Peng,Jiayi Sun,Mengxing Ren,Zenghui Ding,Ningguang Yao*

Main category: cs.CL

TL;DR: RCPS是一个新的演示文稿生成框架，通过深度结构化叙事规划、自适应布局生成和迭代优化循环来解决现有方法的不足。PREVAL评估框架可以可靠地评估演示文稿的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在生成演示文稿时存在逻辑不一致和布局不佳的问题，难以达到专业标准。

Method: 提出了一种名为RCPS（Reflective Coherent Presentation Synthesis）的新框架，该框架整合了三个关键组件：（1）深度结构化叙事规划；（2）自适应布局生成；（3）迭代优化循环。此外，还提出了PREVAL，一个基于偏好的评估框架，采用增强了推理能力的多维模型来评估演示文稿在内容、连贯性和设计方面的质量。

Result: 实验结果表明，RCPS在所有质量维度上都显著优于基线方法，生成的演示文稿非常接近人类专家的标准。PREVAL与人类判断具有很强的相关性。

Conclusion: RCPS显著优于基线方法，并且生成的演示文稿接近人类专家的标准。PREVAL作为评估演示文稿质量的可靠自动化工具，与人类判断高度相关。

Abstract: Automated generation of high-quality media presentations is challenging,
requiring robust content extraction, narrative planning, visual design, and
overall quality optimization. Existing methods often produce presentations with
logical inconsistencies and suboptimal layouts, thereby struggling to meet
professional standards. To address these challenges, we introduce RCPS
(Reflective Coherent Presentation Synthesis), a novel framework integrating
three key components: (1) Deep Structured Narrative Planning; (2) Adaptive
Layout Generation; (3) an Iterative Optimization Loop. Additionally, we propose
PREVAL, a preference-based evaluation framework employing rationale-enhanced
multi-dimensional models to assess presentation quality across Content,
Coherence, and Design. Experimental results demonstrate that RCPS significantly
outperforms baseline methods across all quality dimensions, producing
presentations that closely approximate human expert standards. PREVAL shows
strong correlation with human judgments, validating it as a reliable automated
tool for assessing presentation quality.

</details>


### [119] [AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research](https://arxiv.org/abs/2507.13300)
*Yilun Zhao,Weiyuan Chen,Zhijian Xu,Manasi Patwardhan,Yixin Liu,Chengye Wang,Lovekesh Vig,Arman Cohan*

Main category: cs.CL

TL;DR: 该研究提出了AbGen，一个用于评估LLM设计科学研究剥离研究能力的基准，发现LLM在这方面存在差距，并且自动评估方法不可靠。


<details>
  <summary>Details</summary>
Motivation: 介绍AbGen，这是第一个旨在评估LLM在为科学研究设计剥离研究方面能力的基准。评估领先的LLM，例如DeepSeek-R1-0528和o4-mini，以突出它们与人类专家在剥离研究设计的质量方面的性能差距。证明当前的自动评估方法在该任务上不可靠。

Method: 创建了一个名为AbGen的基准，包含1,500个专家注释的示例，用于评估LLM在为科学研究设计剥离研究方面的能力。LLM的任务是根据给定的研究背景生成详细的剥离研究设计。还开发了一个名为AbGen-Eval的元评估基准，用于评估常用的自动评估系统在该任务上衡量LLM性能的可靠性。

Result: 与人类专家相比，LLM在剥离研究设计的重要性、忠实度和合理性方面存在显著的性能差距。表明常用的自动评估方法与人类评估相比存在显著差异，不可靠。

Conclusion: LLM在设计科学研究的剥离研究方面存在显著的性能差距，并且当前的自动评估方法不可靠。开发AbGen-Eval以评估常用的自动评估系统。

Abstract: We introduce AbGen, the first benchmark designed to evaluate the capabilities
of LLMs in designing ablation studies for scientific research. AbGen consists
of 1,500 expert-annotated examples derived from 807 NLP papers. In this
benchmark, LLMs are tasked with generating detailed ablation study designs for
a specified module or process based on the given research context. Our
evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a
significant performance gap between these models and human experts in terms of
the importance, faithfulness, and soundness of the ablation study designs.
Moreover, we demonstrate that current automated evaluation methods are not
reliable for our task, as they show a significant discrepancy when compared to
human assessment. To better investigate this, we develop AbGen-Eval, a
meta-evaluation benchmark designed to assess the reliability of commonly used
automated evaluation systems in measuring LLM performance on our task. We
investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for
future research on developing more effective and reliable LLM-based evaluation
systems for complex scientific tasks.

</details>


### [120] [HapticCap: A Multimodal Dataset and Task for Understanding User Experience of Vibration Haptic Signals](https://arxiv.org/abs/2507.13318)
*Guimin Hu,Daniel Hershcovich,Hasti Seifi*

Main category: cs.CL

TL;DR: HapticCap：首个包含92,070个触觉-文本对的数据集，用于描述振动信号。提出了haptic-caption检索任务，并使用T5和AST模型取得了最佳性能，尤其是在按类别单独训练时。


<details>
  <summary>Details</summary>
Motivation: 现有的触觉信号（如智能手机振动和虚拟现实触觉反馈）虽然能有效传达信息和增强真实感，但在设计能引起用户共鸣的信号方面存在挑战。这主要是由于缺乏包含文本描述的大型触觉振动数据集，以及现有模型在描述振动信号文本能力方面的局限性。

Method: 提出了一种基于监督对比学习的框架，用于haptic-caption检索任务，并将语言模型T5与音频模型AST相结合，以实现对触觉信号的文本描述。

Result: HapticCap数据集包含92,070个触觉-文本对，涵盖了振动的感官、情感和联想属性。在haptic-caption检索任务中，结合T5和AST模型取得了最佳性能，特别是在为每个描述类别单独训练时。

Conclusion: HapticCap数据集和haptic-caption检索任务的提出，为解决现有触觉信号描述的挑战提供了新的方向。结合T5和AST语言模型，并在特定描述类别上单独训练，可以实现触觉-文本检索的最佳性能。

Abstract: Haptic signals, from smartphone vibrations to virtual reality touch feedback,
can effectively convey information and enhance realism, but designing signals
that resonate meaningfully with users is challenging. To facilitate this, we
introduce a multimodal dataset and task, of matching user descriptions to
vibration haptic signals, and highlight two primary challenges: (1) lack of
large haptic vibration datasets annotated with textual descriptions as
collecting haptic descriptions is time-consuming, and (2) limited capability of
existing tasks and models to describe vibration signals in text. To advance
this area, we create HapticCap, the first fully human-annotated
haptic-captioned dataset, containing 92,070 haptic-text pairs for user
descriptions of sensory, emotional, and associative attributes of vibrations.
Based on HapticCap, we propose the haptic-caption retrieval task and present
the results of this task from a supervised contrastive learning framework that
brings together text representations within specific categories and vibrations.
Overall, the combination of language model T5 and audio model AST yields the
best performance in the haptic-caption retrieval task, especially when
separately trained for each description category.

</details>


### [121] [Social and Political Framing in Search Engine Results](https://arxiv.org/abs/2507.13325)
*Amrit Poudel,Tim Weninger*

Main category: cs.CL

TL;DR: 搜索引擎和用户查询都会导致搜索结果中的偏见，从而加剧信息极化。


<details>
  <summary>Details</summary>
Motivation: 在搜索偏差的各种维度（如内容优先级、索引偏差、政治两极分化和偏差来源）进行了广泛审查，但一个重要的问题仍未得到充分探索：搜索引擎和意识形态驱动的用户查询如何导致搜索结果中的偏差。

Method: 本研究分析了使用政治和社会主题数据集的主要搜索引擎的输出来。

Result: 搜索引擎不仅在内容优先级方面反映了潜在的偏见，而且意识形态驱动的用户查询会加剧这些偏见，导致特定叙述的放大。此外，在不同搜索引擎优先考虑的来源方面也观察到显著差异。

Conclusion: 研究结果表明，搜索引擎不仅在内容优先级方面反映了潜在的偏见，而且意识形态驱动的用户查询会加剧这些偏见，导致特定叙述的放大。此外，在不同搜索引擎优先考虑的来源方面也观察到显著差异。这些结果表明，搜索引擎可能在通过加剧意识形态分歧来塑造公众认知方面发挥关键作用，从而加剧了信息极化的广泛问题。

Abstract: Search engines play a crucial role in shaping public discourse by influencing
how information is accessed and framed. While prior research has extensively
examined various dimensions of search bias -- such as content prioritization,
indexical bias, political polarization, and sources of bias -- an important
question remains underexplored: how do search engines and
ideologically-motivated user queries contribute to bias in search results. This
study analyzes the outputs of major search engines using a dataset of political
and social topics. The findings reveal that search engines not only prioritize
content in ways that reflect underlying biases but also that
ideologically-driven user queries exacerbate these biases, resulting in the
amplification of specific narratives. Moreover, significant differences were
observed across search engines in terms of the sources they prioritize. These
results suggest that search engines may play a pivotal role in shaping public
perceptions by reinforcing ideological divides, thereby contributing to the
broader issue of information polarization.

</details>


### [122] [Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It](https://arxiv.org/abs/2507.13328)
*Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim*

Main category: cs.CL

TL;DR: VL训练不直接改变词汇-概念知识，但能提升模型在纯语言任务中运用这些知识的能力。


<details>
  <summary>Details</summary>
Motivation: 探究视觉-语言（VL）训练是否能有意义地改变语言模型的语言表征，特别是词汇-概念知识的分类组织。

Method: 通过比较仅文本LM和VL训练LM的最小配对，在仅文本问答任务中评估了它们在词汇-概念知识方面的表现，并进行了行为和表征分析。

Result: VL模型在需要分类理解的概念问答任务中优于仅文本模型，但行为和表征分析显示它们在分类知识本身上没有显著差异，而是在表示包含分类关系概念的问题方面存在差异。

Conclusion:  VL训练不改变词汇-概念知识本身，但能更好地利用这些知识来解决特定的、纯语言的任务。

Abstract: Does vision-and-language (VL) training change the linguistic representations
of language models in meaningful ways? Most results in the literature have
shown inconsistent or marginal differences, both behaviorally and
representationally. In this work, we start from the hypothesis that the domain
in which VL training could have a significant effect is lexical-conceptual
knowledge, in particular its taxonomic organization. Through comparing minimal
pairs of text-only LMs and their VL-trained counterparts, we first show that
the VL models often outperform their text-only counterparts on a text-only
question-answering task that requires taxonomic understanding of concepts
mentioned in the questions. Using an array of targeted behavioral and
representational analyses, we show that the LMs and VLMs do not differ
significantly in terms of their taxonomic knowledge itself, but they differ in
how they represent questions that contain concepts in a taxonomic relation vs.
a non-taxonomic relation. This implies that the taxonomic knowledge itself does
not change substantially through additional VL training, but VL training does
improve the deployment of this knowledge in the context of a specific task,
even when the presentation of the task is purely linguistic.

</details>


### [123] [The Imitation Game: Turing Machine Imitator is Length Generalizable Reasoner](https://arxiv.org/abs/2507.13332)
*Zhouqi Hua,Wenwei Zhang,Chengqi Lyu,Yuzhe Gu,Songyang Gao,Kuikun Liu,Kai Chen*

Main category: cs.CL

TL;DR: 本研究提出TAIL方法，通过模仿图灵机执行过程合成数据，有效提升LLM的长度泛化能力，关键在于图灵机的核心概念。


<details>
  <summary>Details</summary>
Motivation: 长度泛化能力（解决比训练时遇到的序列更长的问题）是Transformer-based LLM的核心挑战。现有方法多为特定任务的数据驱动方法，泛化性有限。本研究旨在从更广泛的可计算（图灵机可解）问题的角度，提出一种更通用的解决方案。

Method: TAIL通过合成模仿图灵机执行过程的链式思考（CoT）数据，将推理步骤分解为原子状态，以缓解捷径学习并引入显式内存提取机制来克服动态和长距离数据访问的困难。

Result: TAIL显著提高了Qwen2.5-7B模型在各种算法和推理任务上的长度泛化能力和整体性能，优于先前方法和DeepSeek-R1。模型在注意力层中表现出与图灵机读写行为一致的特性。

Conclusion: 本研究提出了Turing MAchine Imitation Learning（TAIL）方法，通过模仿图灵机的执行过程来合成链式思考（CoT）数据，旨在提升Transformer-based LLM的长度泛化能力。实验结果表明，TAIL在不依赖特定任务的情况下，显著提高了模型在各种算法和推理任务上的长度泛化能力和整体性能，并且其关键在于图灵机的核心概念而非思考模式。

Abstract: Length generalization, the ability to solve problems of longer sequences than
those observed during training, poses a core challenge of Transformer-based
large language models (LLM). Although existing studies have predominantly
focused on data-driven approaches for arithmetic operations and symbolic
manipulation tasks, these approaches tend to be task-specific with limited
overall performance. To pursue a more general solution, this paper focuses on a
broader case of reasoning problems that are computable, i.e., problems that
algorithms can solve, thus can be solved by the Turing Machine. From this
perspective, this paper proposes Turing MAchine Imitation Learning (TAIL) to
improve the length generalization ability of LLMs. TAIL synthesizes
chain-of-thoughts (CoT) data that imitate the execution process of a Turing
Machine by computer programs, which linearly expands the reasoning steps into
atomic states to alleviate shortcut learning and explicit memory fetch
mechanism to reduce the difficulties of dynamic and long-range data access in
elementary operations. To validate the reliability and universality of TAIL, we
construct a challenging synthetic dataset covering 8 classes of algorithms and
18 tasks. Without bells and whistles, TAIL significantly improves the length
generalization ability as well as the performance of Qwen2.5-7B on various
tasks using only synthetic data, surpassing previous methods and DeepSeek-R1.
The experimental results reveal that the key concepts in the Turing Machine,
instead of the thinking styles, are indispensable for TAIL for length
generalization, through which the model exhibits read-and-write behaviors
consistent with the properties of the Turing Machine in their attention layers.
This work provides a promising direction for future research in the learning of
LLM reasoning from synthetic data.

</details>


### [124] [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
*Lingrui Mei,Jiayu Yao,Yuyao Ge,Yiwei Wang,Baolong Bi,Yujun Cai,Jiazhi Liu,Mingyu Li,Zhong-Zhi Li,Duzhen Zhang,Chenlin Zhou,Jiayi Mao,Tianze Xia,Jiafeng Guo,Shenghua Liu*

Main category: cs.CL

TL;DR: 本调查介绍了上下文工程，这是一门用于优化LLM信息有效载荷的学科。它分解了该领域的组件和系统，并确定了生成长篇输出方面的关键研究差距。


<details>
  <summary>Details</summary>
Motivation: 本调查介绍了上下文工程，这是一个正式的学科，它超越了简单的提示设计，涵盖了为大型语言模型（LLM）提供信息有效载荷的系统优化，旨在为上下文感知人工智能的研究和工程提供一个统一的框架。

Method: 本调查通过对超过1300篇研究论文进行系统分析，将上下文工程分解为基础组件（上下文检索和生成、上下文处理、上下文管理）和集成这些组件以创建复杂系统实现（检索增强生成、记忆系统、工具集成推理、多代理系统）。

Result: 本调查全面地分解了上下文工程，包括其基础组件和复杂的系统实现，并确定了当前模型在生成复杂、长篇输出方面存在局限性。

Conclusion: 本调查确立了上下文工程的技术路线图，并揭示了一个关键的研究差距：在模型能力之间存在根本的不对称性。虽然目前通过先进的上下文工程增强的模型在理解复杂上下文方面表现出卓越的熟练度，但它们在生成同样复杂、长篇输出方面表现出明显的局限性。解决这一差距是未来研究的重中之重。

Abstract: The performance of Large Language Models (LLMs) is fundamentally determined
by the contextual information provided during inference. This survey introduces
Context Engineering, a formal discipline that transcends simple prompt design
to encompass the systematic optimization of information payloads for LLMs. We
present a comprehensive taxonomy decomposing Context Engineering into its
foundational components and the sophisticated implementations that integrate
them into intelligent systems. We first examine the foundational components:
context retrieval and generation, context processing and context management. We
then explore how these components are architecturally integrated to create
sophisticated system implementations: retrieval-augmented generation (RAG),
memory systems and tool-integrated reasoning, and multi-agent systems. Through
this systematic analysis of over 1300 research papers, our survey not only
establishes a technical roadmap for the field but also reveals a critical
research gap: a fundamental asymmetry exists between model capabilities. While
current models, augmented by advanced context engineering, demonstrate
remarkable proficiency in understanding complex contexts, they exhibit
pronounced limitations in generating equally sophisticated, long-form outputs.
Addressing this gap is a defining priority for future research. Ultimately,
this survey provides a unified framework for both researchers and engineers
advancing context-aware AI.

</details>


### [125] [Comparing Apples to Oranges: A Dataset & Analysis of LLM Humour Understanding from Traditional Puns to Topical Jokes](https://arxiv.org/abs/2507.13335)
*Tyler Loakman,William Thorne,Chenghua Lin*

Main category: cs.CL

TL;DR: 本研究比较了大型语言模型（LLMs）解释不同类型幽默（包括双关语和需要世事知识的主题幽默）的能力。结果发现，没有模型能够充分解释所有类型的笑话，表明计算幽默领域需要更广泛的研究重点。


<details>
  <summary>Details</summary>
Motivation: Humour, as a complex language form, is derived from myriad aspects of life, whilst existing work on computational humour has focussed almost exclusively on short pun-based jokes. In this work, we investigate whether the ability of Large Language Models (LLMs) to explain humour depends on the particular humour form.

Method: 本研究调查了大型语言模型（LLMs）解释幽默的能力是否取决于特定的幽默形式。我们比较了模型对简单双关语和更复杂的主题幽默的解释能力，后者需要了解现实世界的实体和事件。为此，我们整理了一个包含600个笑话的数据集，分为4种笑话类型，并手动编写了高质量的解释。这些笑话包括异形异音双关语、同形异音双关语、当代互联网幽默以及主题笑话，其中理解需要超越“常识”的推理，而根植于关于新闻事件和流行文化的世事知识。利用该数据集，我们比较了一系列LLM在零样本情况下准确而全面地解释不同类型笑话的能力，从而确定了幽默解释任务中的关键研究空白。

Result: 研究发现，没有一个被测试的模型（包括推理模型）能够可靠地生成所有类型笑话的充分解释，这进一步凸显了计算幽默领域大多数工作过于关注简单的笑话形式。

Conclusion: 目前没有模型能够可靠地生成所有类型笑话的充分解释，这进一步凸显了计算幽默领域大多数工作过于关注简单的笑话形式。

Abstract: Humour, as a complex language form, is derived from myriad aspects of life,
whilst existing work on computational humour has focussed almost exclusively on
short pun-based jokes. In this work, we investigate whether the ability of
Large Language Models (LLMs) to explain humour depends on the particular humour
form. We compare models on simple puns and more complex topical humour that
requires knowledge of real-world entities and events. In doing so, we curate a
dataset of 600 jokes split across 4 joke types and manually write high-quality
explanations. These jokes include heterographic and homographic puns,
contemporary internet humour, and topical jokes, where understanding relies on
reasoning beyond "common sense", rooted instead in world knowledge regarding
news events and pop culture. Using this dataset, we compare the zero-shot
abilities of a range of LLMs to accurately and comprehensively explain jokes of
different types, identifying key research gaps in the task of humour
explanation. We find that none of the tested models (inc. reasoning models) are
capable of reliably generating adequate explanations of all joke types, further
highlighting the narrow focus of most works in computational humour on overly
simple joke forms.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [126] [MC$^2$A: Enabling Algorithm-Hardware Co-Design for Efficient Markov Chain Monte Carlo Acceleration](https://arxiv.org/abs/2507.12935)
*Shirui Zhao,Jun Yin,Lingyun Yao,Martin Andraud,Wannes Meert,Marian Verhelst*

Main category: cs.LG

TL;DR: MC^2A 是一种算法-硬件协同设计框架，通过优化的 MCMC 工作负载分析、灵活的硬件加速器架构和创新的 Gumbel 采样器，显著提升了 MCMC 的计算效率和灵活性，并在多种应用中取得了远超现有方案的加速效果。


<details>
  <summary>Details</summary>
Motivation: MCMC 算法在采样、优化和推理等领域应用广泛，但其高昂的计算成本限制了其在大规模问题和实际应用中的可行性。现有的 MCMC 加速方案在硬件灵活性或系统级效率方面存在不足。

Method: MC^2A 框架通过三个关键步骤实现 MCMC 加速：1. 扩展处理器性能线模型，增加第三维度以分析 MCMC 工作负载多样性，找到计算、采样和内存参数的最佳平衡点。2. 提出一种参数化硬件加速器架构，包含 ISA 可编程树状处理单元、可重构采样器和支持不规则访问的交叉互连，为 MCMC 内核提供灵活高效的支持。3. 引入 Gumbel 采样器，避免了指数和归一化运算。

Result: MC^2A 在端到端案例研究中，相比 CPU、GPU、TPU 和最先进的 MCMC 加速器，分别实现了 $307.6	imes$、$1.4	imes$、$2.0	imes$ 和 $84.2	imes$ 的整体加速比。在多种代表性 MCMC 工作负载上的评估表明，MC^2A 能够实现通用的硬件加速，并促进 MCMC 解决方案在不同应用领域的普及。

Conclusion: MC^2A 框架通过算法-硬件协同设计，在 MCMC 加速方面实现了显著的效率和灵活性提升，并通过 Gumbel 采样器消除了指数和归一化运算，在实际应用中取得了比 CPU、GPU、TPU 和现有 MCMC 加速器高出多个数量级的加速效果，验证了通用硬件加速在 MCMC 领域的潜力。

Abstract: An increasing number of applications are exploiting sampling-based algorithms
for planning, optimization, and inference. The Markov Chain Monte Carlo (MCMC)
algorithms form the computational backbone of this emerging branch of machine
learning. Unfortunately, the high computational cost limits their feasibility
for large-scale problems and real-world applications, and the existing MCMC
acceleration solutions are either limited in hardware flexibility or fail to
maintain efficiency at the system level across a variety of end-to-end
applications. This paper introduces \textbf{MC$^2$A}, an algorithm-hardware
co-design framework, enabling efficient and flexible optimization for MCMC
acceleration. Firstly, \textbf{MC$^2$A} analyzes the MCMC workload diversity
through an extension of the processor performance roofline model with a 3rd
dimension to derive the optimal balance between the compute, sampling and
memory parameters. Secondly, \textbf{MC$^2$A} proposes a parametrized hardware
accelerator architecture with flexible and efficient support of MCMC kernels
with a pipeline of ISA-programmable tree-structured processing units,
reconfigurable samplers and a crossbar interconnect to support irregular
access. Thirdly, the core of \textbf{MC$^2$A} is powered by a novel Gumbel
sampler that eliminates exponential and normalization operations. In the
end-to-end case study, \textbf{MC$^2$A} achieves an overall {$307.6\times$,
$1.4\times$, $2.0\times$, $84.2\times$} speedup compared to the CPU, GPU, TPU
and state-of-the-art MCMC accelerator. Evaluated on various representative MCMC
workloads, this work demonstrates and exploits the feasibility of general
hardware acceleration to popularize MCMC-based solutions in diverse application
domains.

</details>


### [127] [Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training](https://arxiv.org/abs/2507.12507)
*Mingjie Liu,Shizhe Diao,Jian Hu,Ximing Lu,Xin Dong,Hao Zhang,Alexander Bukharin,Shaokun Zhang,Jiaqi Zeng,Makesh Narsimhan Sreedhar,Gerald Shen,David Mosallanezhad,Di Zhang,Jonas Yang,June Yang,Oleksii Kuchaiev,Guilin Liu,Zhiding Yu,Pavlo Molchanov,Yejin Choi,Jan Kautz,Yi Dong*

Main category: cs.LG

TL;DR: 通过延长强化学习，并结合可验证奖励、改进的GRPO以及特定的训练技术（如受控KL正则化、裁剪率和周期性参考策略重置），在数学、编程和逻辑谜题任务上显著提升了小型语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: 最近，像OpenAI的O1和DeepSeek-R1这样的注重推理的语言模型在数学和代码生成等复杂任务上取得了显著的进步，这得益于通过思维链推理和迭代探索进行测试时计算的扩展。这些突破主要得益于大规模强化学习（RL），特别是与提供客观和基础监督的可验证奖励信号相结合。

Method: 本研究调查了在多样化推理领域上，延长强化学习对小型语言模型的影响。研究确定了几种有效的训练关键要素，包括：可验证奖励任务、改进的群组相对策略优化（GRPO），以及提高训练稳定性和泛化能力的实用技术。我们引入了受控KL正则化、裁剪率和周期性参考策略重置作为实现长期性能提升的关键组成部分。

Result: 模型在数学、编程和逻辑谜题任务上取得了显著进展，分别提高了+14.7%、+13.9%和+54.8%。

Conclusion: 该模型在数学、编程和逻辑谜题任务上显著优于强大的基线模型，分别提高了+14.7%、+13.9%和+54.8%。为了促进持续研究，我们公开发布了我们的模型。

Abstract: Recent advancements in reasoning-focused language models such as OpenAI's O1
and DeepSeek-R1 have shown that scaling test-time computation-through
chain-of-thought reasoning and iterative exploration-can yield substantial
improvements on complex tasks like mathematics and code generation. These
breakthroughs have been driven by large-scale reinforcement learning (RL),
particularly when combined with verifiable reward signals that provide
objective and grounded supervision. In this report, we investigate the effects
of prolonged reinforcement learning on a small language model across a diverse
set of reasoning domains. Our work identifies several key ingredients for
effective training, including the use of verifiable reward tasks, enhancements
to Group Relative Policy Optimization (GRPO), and practical techniques to
improve training stability and generalization. We introduce controlled KL
regularization, clipping ratio, and periodic reference policy resets as
critical components for unlocking long-term performance gains. Our model
achieves significant improvements over strong baselines, including +14.7% on
math, +13.9% on coding, and +54.8% on logic puzzle tasks. To facilitate
continued research, we release our model publicly.

</details>


### [128] [Improving physics-informed neural network extrapolation via transfer learning and adaptive activation functions](https://arxiv.org/abs/2507.12659)
*Athanasios Papastathopoulos-Katsaros,Alexandra Stavrianidi,Zhandong Liu*

Main category: cs.LG

TL;DR: 本研究通过迁移学习和自适应激活函数，改进了物理信息神经网络（PINNs）在外插方面的性能，降低了误差，并且计算成本没有显著增加。


<details>
  <summary>Details</summary>
Motivation: 尽管物理信息神经网络（PINNs）在科学与工程问题中表现出色，但它们在训练域之外的外插能力较差，并且对激活函数的选择非常敏感。

Method: 本研究提出了一种迁移学习（TL）方法，将其应用于扩展的训练域，并结合精心选择的少量样本点。同时，还提出了一种自适应激活函数（AF），该函数是标准AF的线性组合，用于提高模型的鲁棒性和准确性。

Result: 实验结果表明，该方法在平均相对L2误差和平均绝对误差方面分别降低了40%和50%，同时计算成本并未显著增加。

Conclusion: 该研究通过引入迁移学习和自适应激活函数，显著提高了物理信息神经网络（PINNs）的外插能力和鲁棒性与准确性。

Abstract: Physics-Informed Neural Networks (PINNs) are deep learning models that
incorporate the governing physical laws of a system into the learning process,
making them well-suited for solving complex scientific and engineering
problems. Recently, PINNs have gained widespread attention as a powerful
framework for combining physical principles with data-driven modeling to
improve prediction accuracy. Despite their successes, however, PINNs often
exhibit poor extrapolation performance outside the training domain and are
highly sensitive to the choice of activation functions (AFs). In this paper, we
introduce a transfer learning (TL) method to improve the extrapolation
capability of PINNs. Our approach applies transfer learning (TL) within an
extended training domain, using only a small number of carefully selected
collocation points. Additionally, we propose an adaptive AF that takes the form
of a linear combination of standard AFs, which improves both the robustness and
accuracy of the model. Through a series of experiments, we demonstrate that our
method achieves an average of 40% reduction in relative L2 error and an average
of 50% reduction in mean absolute error in the extrapolation domain, all
without a significant increase in computational cost. The code is available at
https://github.com/LiuzLab/PINN-extrapolation .

</details>


### [129] [The Serial Scaling Hypothesis](https://arxiv.org/abs/2507.12549)
*Yuxi Liu,Konpat Preechakul,Kananart Kuwaranancharoen,Yutong Bai*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: While machine learning has advanced through massive parallelization, we
identify a critical blind spot: some problems are fundamentally sequential.
These "inherently serial" problems-from mathematical reasoning to physical
simulations to sequential decision-making-require dependent computational steps
that cannot be parallelized. Drawing from complexity theory, we formalize this
distinction and demonstrate that current parallel-centric architectures face
fundamental limitations on such tasks. We argue that recognizing the serial
nature of computation holds profound implications on machine learning, model
design, hardware development. As AI tackles increasingly complex reasoning,
deliberately scaling serial computation-not just parallel computation-is
essential for continued progress.

</details>


### [130] [RONOM: Reduced-Order Neural Operator Modeling](https://arxiv.org/abs/2507.12814)
*Sven Dummer,Dongwei Ye,Christoph Brune*

Main category: cs.LG

TL;DR: RONOM结合了ROM和神经算子，在求解偏微分方程时，不仅泛化能力强，而且在空间超分辨率和离散鲁棒性方面表现更佳，同时还能提供时间超分辨率的洞见。


<details>
  <summary>Details</summary>
Motivation: 现有的降阶模型（ROM）在处理多查询场景时计算密集且依赖固定离散化，限制了灵活性。神经算子虽然能适应不同分辨率，但缺乏对无限维和离散化算子之间误差的量化。本项目旨在解决这些问题。

Method: 提出了一种名为RONOM（reduced-order neural operator modeling）的框架，结合了降阶模型（ROM）和算子学习（特别是神经算子）的思想。

Result: RONOM框架建立了类似于ROM的离散化误差界限，并提供了关于其离散化收敛性和鲁棒性的见解。数值算例表明，RONOM在输入泛化方面与现有神经算子相当，在空间超分辨率和离散鲁棒性方面更优，并对时间超分辨率场景有新发现。

Conclusion: RONOM框架在输入泛化、空间超分辨率和离散鲁棒性方面表现优于现有神经算子，并在时间超分辨率方面提供新见解。

Abstract: Time-dependent partial differential equations are ubiquitous in physics-based
modeling, but they remain computationally intensive in many-query scenarios,
such as real-time forecasting, optimal control, and uncertainty quantification.
Reduced-order modeling (ROM) addresses these challenges by constructing a
low-dimensional surrogate model but relies on a fixed discretization, which
limits flexibility across varying meshes during evaluation. Operator learning
approaches, such as neural operators, offer an alternative by parameterizing
mappings between infinite-dimensional function spaces, enabling adaptation to
data across different resolutions. Whereas ROM provides rigorous numerical
error estimates, neural operator learning largely focuses on discretization
convergence and invariance without quantifying the error between the
infinite-dimensional and the discretized operators. This work introduces the
reduced-order neural operator modeling (RONOM) framework, which bridges
concepts from ROM and operator learning. We establish a discretization error
bound analogous to those in ROM, and get insights into RONOM's discretization
convergence and discretization robustness. Moreover, two numerical examples are
presented that compare RONOM to existing neural operators for solving partial
differential equations. The results demonstrate that RONOM using standard
vector-to-vector neural networks achieves comparable performance in input
generalization and superior performance in both spatial super-resolution and
discretization robustness, while also offering novel insights into temporal
super-resolution scenarios.

</details>


### [131] [BootSeer: Analyzing and Mitigating Initialization Bottlenecks in Large-Scale LLM Training](https://arxiv.org/abs/2507.12619)
*Rui Li,Xiaoyun Zhi,Jinxin Chi,Menghan Yu,Lixin Huang,Jia Zhu,Weilun Zhang,Xing Ma,Wenjia Liu,Zhicheng Zhu,Daowen Luo,Zuquan Song,Xin Yin,Chao Xiang,Shuguang Wang,Wencong Xiao,Gene Cooperman*

Main category: cs.LG

TL;DR: 本研究首次深入分析了 LLM 训练启动开销，发现其在生产环境中占用了大量 GPU 时间。为解决此问题，研究提出了 Bootseer 优化框架，通过热块记录和预取、依赖项快照以及条带化 HDFS-FUSE 技术，将启动开销减少了 50%。


<details>
  <summary>Details</summary>
Motivation: LLM 的启动开销在工业规模的 LLM 训练中尤为重要，因为故障更频繁，并且多个团队在迭代更新-调试周期中进行操作。在其中一个训练集群中，超过 3.5% 的 GPU 时间因启动开销而浪费。

Method: Bootseer 是一个系统级优化框架，它通过三种技术来解决启动瓶颈：(a) 热块记录和预取，(b) 依赖项快照，以及 (c) 条带化 HDFS-FUSE。

Result: Bootseer 在生产环境中进行了部署，并在真实的 LLM 训练工作负载上进行了评估，结果显示启动开销减少了 50%。

Conclusion: 通过部署 Bootseer，生产环境中的 LLM 训练启动开销减少了 50%。

Abstract: Large Language Models (LLMs) have become a cornerstone of modern AI, driving
breakthroughs in natural language processing and expanding into multimodal jobs
involving images, audio, and video. As with most computational software, it is
important to distinguish between ordinary runtime performance and startup
overhead. Prior research has focused on runtime performance: improving training
efficiency and stability. This work focuses instead on the increasingly
critical issue of startup overhead in training: the delay before training jobs
begin execution. Startup overhead is particularly important in large,
industrial-scale LLMs, where failures occur more frequently and multiple teams
operate in iterative update-debug cycles. In one of our training clusters, more
than 3.5% of GPU time is wasted due to startup overhead alone.
  In this work, we present the first in-depth characterization of LLM training
startup overhead based on real production data. We analyze the components of
startup cost, quantify its direct impact, and examine how it scales with job
size. These insights motivate the design of Bootseer, a system-level
optimization framework that addresses three primary startup bottlenecks: (a)
container image loading, (b) runtime dependency installation, and (c) model
checkpoint resumption. To mitigate these bottlenecks, Bootseer introduces three
techniques: (a) hot block record-and-prefetch, (b) dependency snapshotting, and
(c) striped HDFS-FUSE. Bootseer has been deployed in a production environment
and evaluated on real LLM training workloads, demonstrating a 50% reduction in
startup overhead.

</details>


### [132] [Can Mental Imagery Improve the Thinking Capabilities of AI Systems?](https://arxiv.org/abs/2507.12555)
*Slimane Larabi*

Main category: cs.LG

TL;DR: AI agents need better reasoning and cross-domain knowledge integration. This paper introduces a machine thinking framework with a mental imagery unit to address these limitations, representing data as text or sketches.


<details>
  <summary>Details</summary>
Motivation: Existing AI models lack autonomous capabilities and independent reasoning, and struggle with cross-domain knowledge integration, unlike humans who utilize mental imagery in their thinking process.

Method: The proposed framework integrates a Cognitive thinking unit with three auxiliary units: Input Data Unit, Needs Unit, and Mental Imagery Unit. Data is represented as natural language sentences or sketches.

Result: Validation tests were conducted, and the results are presented and discussed in the paper, indicating the potential benefits of the proposed framework.

Conclusion: The paper proposes a machine thinking framework integrating mental imagery to enhance AI autonomy and cross-domain knowledge integration, showing promising results in validation tests.

Abstract: Although existing models can interact with humans and provide satisfactory
responses, they lack the ability to act autonomously or engage in independent
reasoning. Furthermore, input data in these models is typically provided as
explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform
tasks and make decisions autonomously based on their programming, data inputs,
and learned knowledge, have shown significant progress. However, they struggle
with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process,
which involves performing tasks based on internal multisensory data, planned
actions, needs, and reasoning capabilities. In this paper, we investigate how
to integrate mental imagery into a machine thinking framework and how this
could be beneficial in initiating the thinking process. Our proposed machine
thinking framework integrates a Cognitive thinking unit supported by three
auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery
Unit. Within this framework, data is represented as natural language sentences
or drawn sketches, serving both informative and decision-making purposes. We
conducted validation tests for this framework, and the results are presented
and discussed.

</details>


### [133] [Topology-Aware Activation Functions in Neural Networks](https://arxiv.org/abs/2507.12874)
*Pavel Snopov,Oleg R. Musin*

Main category: cs.LG

TL;DR: 该研究提出了两种新的激活函数SmoothSplit和ParametricSplit，它们可以更好地处理数据拓扑，尤其是在低维场景下，可以提高神经网络的性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服ReLU等传统激活函数的局限性，并提升神经网络在操纵数据拓扑方面的能力，尤其是在处理低维数据时。

Method: 提出了SmoothSplit和ParametricSplit两种新型激活函数，并通过在合成和真实数据集上的实验进行了验证。

Result: ParametricSplit在低维设置中优于传统激活函数，并在高维设置中保持了竞争力，证明了拓扑感知激活函数在推进神经网络架构方面的潜力。

Conclusion: 该研究提出了SmoothSplit和ParametricSplit两种新型激活函数，通过引入拓扑“切割”能力，有效增强了神经网络在训练过程中操纵数据拓扑的能力，尤其在低维场景下，ParametricSplit表现优于传统激活函数，同时在高维场景下也保持了竞争力。

Abstract: This study explores novel activation functions that enhance the ability of
neural networks to manipulate data topology during training. Building on the
limitations of traditional activation functions like $\mathrm{ReLU}$, we
propose $\mathrm{SmoothSplit}$ and $\mathrm{ParametricSplit}$, which introduce
topology "cutting" capabilities. These functions enable networks to transform
complex data manifolds effectively, improving performance in scenarios with
low-dimensional layers. Through experiments on synthetic and real-world
datasets, we demonstrate that $\mathrm{ParametricSplit}$ outperforms
traditional activations in low-dimensional settings while maintaining
competitive performance in higher-dimensional ones. Our findings highlight the
potential of topology-aware activation functions in advancing neural network
architectures. The code is available via
https://github.com/Snopoff/Topology-Aware-Activations.

</details>


### [134] [FedGA: A Fair Federated Learning Framework Based on the Gini Coefficient](https://arxiv.org/abs/2507.12983)
*ShanBin Liu*

Main category: cs.LG

TL;DR: FedGA 通过 Gini 系数和动态权重调整来提高联邦学习的公平性。


<details>
  <summary>Details</summary>
Motivation: 解决水平联邦学习中数据异质性导致的客户端性能差异和不公平性问题。

Method: FedGA 算法首先使用 Gini 系数衡量客户端间的性能差异，并建立 Gini 系数 $G$ 与全局模型更新尺度 ${U_s}$ 之间的关系以确定公平性干预时机。随后，动态调整聚合权重以适应系统的实时公平性状态。

Result: 在 Office-Caltech-10、CIFAR-10 和 Synthetic 数据集上的广泛实验表明，FedGA 有效地提高了公平性指标（如方差和 Gini 系数），同时保持了强大的整体性能。

Conclusion: FedGA 是一种公平性感知联邦学习算法，通过 Gini 系数自适应确定公平性干预时机，并根据实时公平性动态调整聚合权重，以更好地整合表现较差的客户端信息。实验结果表明，FedGA 能有效提升公平性指标（如方差和 Gini 系数），同时保持良好的整体性能。

Abstract: Fairness has emerged as one of the key challenges in federated learning. In
horizontal federated settings, data heterogeneity often leads to substantial
performance disparities across clients, raising concerns about equitable model
behavior. To address this issue, we propose FedGA, a fairness-aware federated
learning algorithm. We first employ the Gini coefficient to measure the
performance disparity among clients. Based on this, we establish a relationship
between the Gini coefficient $G$ and the update scale of the global model
${U_s}$, and use this relationship to adaptively determine the timing of
fairness intervention. Subsequently, we dynamically adjust the aggregation
weights according to the system's real-time fairness status, enabling the
global model to better incorporate information from clients with relatively
poor performance.We conduct extensive experiments on the Office-Caltech-10,
CIFAR-10, and Synthetic datasets. The results show that FedGA effectively
improves fairness metrics such as variance and the Gini coefficient, while
maintaining strong overall performance, demonstrating the effectiveness of our
approach.

</details>


### [135] [IncA-DES: An incremental and adaptive dynamic ensemble selection approach using online K-d tree neighborhood search for data streams with concept drift](https://arxiv.org/abs/2507.12573)
*Eduardo V. L. Barboza,Paulo R. Lisboa de Almeida,Alceu de Souza Britto Jr.,Robert Sabourin,Rafael M. O. Cruz*

Main category: cs.LG

TL;DR: 提出了一种名为IncA-DES的新框架，用于解决数据流中的概念漂移问题。该框架通过改进的训练策略生成局部专家，结合概念漂移检测器进行适应，并使用在线K-d树优化处理速度，实验证明其在准确率和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 数据流中的概念漂移（数据分布随时间变化）是一个挑战。虽然分类器融合（特别是基于实例的DS方法）在处理漂移方面显示出良好效果，但现有方法在适应概念漂移时需要改进，特别是关于局部专家的生成和邻域搜索的效率问题。

Method: IncA-DES框架，该框架采用一种训练策略来生成局部专家，并结合概念漂移检测器来维护信息和适应新概念。此外，还采用基于重叠的分类过滤器来避免在邻域中有共识时使用DS方法，并提出了一种在线K-d树算法来降低kNN的处理时间。

Result: 实验结果表明，所提出的IncA-DES框架在平均准确率和处理时间方面均优于现有最先进方法，并且与在线K-d树的结合进一步提高了效率。

Conclusion: 提出的IncA-DES框架在面对概念漂移时，相比七种现有最先进方法，在不同标签可用性水平下获得了最佳平均准确率，并且在最准确的方法中处理时间最短。此外，与在线K-d树的结合在准确率略有损失的情况下提高了处理时间。

Abstract: Data streams pose challenges not usually encountered in batch-based ML. One
of them is concept drift, which is characterized by the change in data
distribution over time. Among many approaches explored in literature, the
fusion of classifiers has been showing good results and is getting growing
attention. DS methods, due to the ensemble being instance-based, seem to be an
efficient choice under drifting scenarios. However, some attention must be paid
to adapting such methods for concept drift. The training must be done in order
to create local experts, and the commonly used neighborhood-search DS may
become prohibitive with the continuous arrival of data. In this work, we
propose IncA-DES, which employs a training strategy that promotes the
generation of local experts with the assumption that different regions of the
feature space become available with time. Additionally, the fusion of a concept
drift detector supports the maintenance of information and adaptation to a new
concept. An overlap-based classification filter is also employed in order to
avoid using the DS method when there is a consensus in the neighborhood, a
strategy that we argue every DS method should employ, as it was shown to make
them more applicable and quicker. Moreover, aiming to reduce the processing
time of the kNN, we propose an Online K-d tree algorithm, which can quickly
remove instances without becoming inconsistent and deals with unbalancing
concerns that may occur in data streams. Experimental results showed that the
proposed framework got the best average accuracy compared to seven
state-of-the-art methods considering different levels of label availability and
presented the smaller processing time between the most accurate methods.
Additionally, the fusion with the Online K-d tree has improved processing time
with a negligible loss in accuracy. We have made our framework available in an
online repository.

</details>


### [136] [Assay2Mol: large language model-based drug design using BioAssay context](https://arxiv.org/abs/2507.12574)
*Yifan Deng,Spencer S. Ericksen,Anthony Gitter*

Main category: cs.LG

TL;DR: Assay2Mol 使用大语言模型来分析生化筛选数据，为新药发现生成更易于合成的候选分子。


<details>
  <summary>Details</summary>
Motivation: 未被利用的非结构化文本（描述生物机制、实验筛选方案等）包含丰富的信息，可用于新药发现。

Method: Assay2Mol 是一个基于大语言模型的工作流程，它检索涉及与新靶点相似的靶点的现有分析记录，并利用检索到的分析筛选数据通过上下文学习来生成候选分子。

Result: Assay2Mol 在生成候选配体分子方面优于最近的机器学习方法，并且生成的分子更易于合成。

Conclusion: Assay2Mol 可以在早期药物发现中利用大量的生化筛选分析来生成候选分子，并且优于其他方法。

Abstract: Scientific databases aggregate vast amounts of quantitative data alongside
descriptive text. In biochemistry, molecule screening assays evaluate the
functional responses of candidate molecules against disease targets.
Unstructured text that describes the biological mechanisms through which these
targets operate, experimental screening protocols, and other attributes of
assays offer rich information for new drug discovery campaigns but has been
untapped because of that unstructured format. We present Assay2Mol, a large
language model-based workflow that can capitalize on the vast existing
biochemical screening assays for early-stage drug discovery. Assay2Mol
retrieves existing assay records involving targets similar to the new target
and generates candidate molecules using in-context learning with the retrieved
assay screening data. Assay2Mol outperforms recent machine learning approaches
that generate candidate ligand molecules for target protein structures, while
also promoting more synthesizable molecule generation.

</details>


### [137] [Ranking Vectors Clustering: Theory and Applications](https://arxiv.org/abs/2507.12583)
*Ali Fattahi,Ali Eshragh,Babak Aslani,Meysam Rabiee*

Main category: cs.LG

TL;DR: KRC问题被证明是NP-hard的，但针对单簇情况有解析解。KRCA和BnB算法被提出用于解决KRC问题，并在实验中显示出优于基线方法的性能，特别是在个性化和大规模决策制定方面具有实际意义。


<details>
  <summary>Details</summary>
Motivation: 研究聚类排序向量的问题，其中每个向量表示有序的偏好列表，特别是k-质心排序向量聚类问题（KRC），旨在将一组排序向量划分为k个簇并识别每个簇的质心。与经典的k-均值聚类（KMC）不同，KRC约束观测值和质心均为排序向量。

Method: 1. 建立KRC的NP-hard性质并明确其可行集。 2. 针对单簇情况，推导出最优质心的闭式解析解，该解可在线性时间内计算。 3. 开发了一种名为KRCA的近似算法来解决KRC的计算挑战，该算法对来自KMC（称为基线解）的初始解进行迭代改进。 4. 引入了一种分支定界（BnB）算法，用于KRCA中的高效聚类重建，利用决策树框架来减少计算时间，并包含一个控制参数来平衡解决方案的质量和效率。 5. 建立了KRCA和BnB的理论误差界限。

Result: 1. KRC已被证明是NP-hard的，并且其可行集已被表征。 2. 对于单簇情况，已获得最优质心的闭式解析解，可在线性时间内计算。 3. KRCA算法被开发出来，通过迭代改进KMC的初始解来解决KRC的计算挑战。 4. BnB算法被引入以在KRCA中进行高效的聚类重建，利用决策树框架和控制参数来平衡解决方案质量和效率。 5. KRCA和BnB的理论误差界限已被建立。 6. KRCA在合成和真实数据集上的广泛数值实验表明，与基线解相比，KRCA在解决方案质量和计算时间方面均表现出色。

Conclusion: 这项工作强调了KRC在个性化和大规模决策制定中的实际意义，提供了方法论的进步和可供未来研究借鉴的见解。

Abstract: We study the problem of clustering ranking vectors, where each vector
represents preferences as an ordered list of distinct integers. Specifically,
we focus on the k-centroids ranking vectors clustering problem (KRC), which
aims to partition a set of ranking vectors into k clusters and identify the
centroid of each cluster. Unlike classical k-means clustering (KMC), KRC
constrains both the observations and centroids to be ranking vectors. We
establish the NP-hardness of KRC and characterize its feasible set. For the
single-cluster case, we derive a closed-form analytical solution for the
optimal centroid, which can be computed in linear time. To address the
computational challenges of KRC, we develop an efficient approximation
algorithm, KRCA, which iteratively refines initial solutions from KMC, referred
to as the baseline solution. Additionally, we introduce a branch-and-bound
(BnB) algorithm for efficient cluster reconstruction within KRCA, leveraging a
decision tree framework to reduce computational time while incorporating a
controlling parameter to balance solution quality and efficiency. We establish
theoretical error bounds for KRCA and BnB. Through extensive numerical
experiments on synthetic and real-world datasets, we demonstrate that KRCA
consistently outperforms baseline solutions, delivering significant
improvements in solution quality with fast computational times. This work
highlights the practical significance of KRC for personalization and
large-scale decision making, offering methodological advancements and insights
that can be built upon in future studies.

</details>


### [138] [Second-Order Bounds for [0,1]-Valued Regression via Betting Loss](https://arxiv.org/abs/2507.12584)
*Yinan Li,Kwang-Sung Jun*

Main category: cs.LG

TL;DR: 对于[0,1]取值的回归问题，我们提出了一种新的“投注损失”函数，它能实现比对数损失更好的“二阶界限”，并且在不知道方差的情况下也能达到该界限。


<details>
  <summary>Details</summary>
Motivation: 为了寻找比现有方法（如对数损失和平方损失）在[0,1]取值回归问题上能获得更优泛化界限的损失函数，特别是能够实现依赖于方差的“二阶界限”。

Method: 提出了一种名为“投注损失”的新型损失函数，并证明了其在[0,1]取值回归问题上的泛化界限。

Result: 证明了所提出的投注损失可以实现“方差自适应”的二阶界限，即在不知道方差信息的情况下也能达到该界限，这优于仅能提供“一阶界限”的对数损失。

Conclusion: 本研究表明，对于[0,1]取值的回归问题，存在一种名为“投注损失”的新型损失函数，可以实现比现有方法更好的泛化界限。

Abstract: We consider the $[0,1]$-valued regression problem in the i.i.d. setting. In a
related problem called cost-sensitive classification, \citet{foster21efficient}
have shown that the log loss minimizer achieves an improved generalization
bound compared to that of the squared loss minimizer in the sense that the
bound scales with the cost of the best classifier, which can be arbitrarily
small depending on the problem at hand. Such a result is often called a
first-order bound. For $[0,1]$-valued regression, we first show that the log
loss minimizer leads to a similar first-order bound. We then ask if there
exists a loss function that achieves a variance-dependent bound (also known as
a second order bound), which is a strict improvement upon first-order bounds.
We answer this question in the affirmative by proposing a novel loss function
called the betting loss. Our result is ``variance-adaptive'' in the sense that
the bound is attained \textit{without any knowledge about the variance}, which
is in contrast to modeling label (or reward) variance or the label distribution
itself explicitly as part of the function class such as distributional
reinforcement learning.

</details>


### [139] [Are encoders able to learn landmarkers for warm-starting of Hyperparameter Optimization?](https://arxiv.org/abs/2507.12604)
*Antoni Zajko,Katarzyna Woźnica*

Main category: cs.LG

TL;DR: 提出两种新表格表示学习方法，用于HPO冷启动元任务，但性能提升有限。


<details>
  <summary>Details</summary>
Motivation: 为元学习目的有效表示异构表格数据集仍然是一个待解决的问题，之前的通用方法有局限性。

Method: 提出两种新颖的表格表示学习方法：一种基于深度度量学习，另一种基于标志物重建。这两种方法都遵循一个特定要求，即强制表示捕获标志物的属性。

Result: 实验表明，所提出的编码器可以有效地学习与标志物对齐的表示，但其在HPO冷启动元任务上的性能提升可能不显著。

Conclusion: 所提出的编码器可以有效地学习与标志物对齐的表示，但可能无法直接转化为目标元任务（例如HPO的冷启动）的显著性能提升。

Abstract: Effectively representing heterogeneous tabular datasets for meta-learning
purposes is still an open problem. Previous approaches rely on representations
that are intended to be universal. This paper proposes two novel methods for
tabular representation learning tailored to a specific meta-task -
warm-starting Bayesian Hyperparameter Optimization. Both follow the specific
requirement formulated by ourselves that enforces representations to capture
the properties of landmarkers. The first approach involves deep metric
learning, while the second one is based on landmarkers reconstruction. We
evaluate the proposed encoders in two ways. Next to the gain in the target
meta-task, we also use the degree of fulfillment of the proposed requirement as
the evaluation metric. Experiments demonstrate that while the proposed encoders
can effectively learn representations aligned with landmarkers, they may not
directly translate to significant performance gains in the meta-task of HPO
warm-starting.

</details>


### [140] [Learning What Matters: Probabilistic Task Selection via Mutual Information for Model Finetuning](https://arxiv.org/abs/2507.12612)
*Prateek Chanda,Saral Sureka,Parth Pratim Chatterjee,Krishnateja Killamsetty,Nikhil Shivakumar Nayak,Ganesh Ramakrishnan*

Main category: cs.LG

TL;DR: LLM微调的关键在于训练数据的组合。TASKPGM是一个新的框架，可以通过优化任务比例来改进数据组合，以平衡代表性和多样性，并在实验中取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 选择最优的任务数据集组合是LLM微调的关键，但目前这一过程很大程度上依赖于手动、启发式驱动以及均匀或基于大小的采样策略。为了解决这个问题，引入了TASKPGM框架。

Method: TASKPGM通过最小化马尔可夫随机场（MRF）上的能量函数来选择连续的任务比例。任务关系被建模为行为散度，如Jensen Shannon散度和逐点互信息，这些散度是从单任务微调模型的预测分布计算得出的。

Result: TASKPGM在Llama 2和Mistral模型上，跨越MMLU和BIGBench等评估套件，均取得了持续的经验性改进。此外，该框架还提供了对任务影响和混合组成的解释性见解。

Conclusion: TASKPGM是一个原则性强且可扩展的框架，用于优化混合任务，通过最小化马尔可夫随机场（MRF）上的能量函数来选择连续的任务比例。该方法在单形约束下产生封闭形式的解，并可证明地平衡了任务间的代表性和多样性。除了性能之外，TASKPGM还提供了对任务影响和混合组成的解释性见解，使其成为高效、鲁棒的LLM微调的有力工具。

Abstract: The performance of finetuned large language models (LLMs) hinges critically
on the composition of the training mixture. However, selecting an optimal blend
of task datasets remains a largely manual, heuristic driven process, with
practitioners often relying on uniform or size based sampling strategies. We
introduce TASKPGM, a principled and scalable framework for mixture optimization
that selects continuous task proportions by minimizing an energy function over
a Markov Random Field (MRF). Task relationships are modeled using behavioral
divergences such as Jensen Shannon Divergence and Pointwise Mutual Information
computed from the predictive distributions of single task finetuned models. Our
method yields a closed form solution under simplex constraints and provably
balances representativeness and diversity among tasks. We provide theoretical
guarantees, including weak submodularity for budgeted variants, and demonstrate
consistent empirical improvements on Llama 2 and Mistral across evaluation
suites such as MMLU and BIGBench. Beyond performance, TASKPGM offers
interpretable insights into task influence and mixture composition, making it a
powerful tool for efficient and robust LLM finetuning.

</details>


### [141] [Reasoning-Finetuning Repurposes Latent Representations in Base Models](https://arxiv.org/abs/2507.12638)
*Jake Ward,Chuqiao Lin,Constantin Venhoff,Neel Nanda*

Main category: cs.LG

TL;DR: 推理微调模型通过利用基座模型中已存在的特定表征方向来产生回溯行为，而不是从零开始学习。


<details>
  <summary>Details</summary>
Motivation: 理解回溯行为（推理模型中出现的、通过推理微调而引发的一种行为）的潜在机制，以及微调过程如何影响模型行为。

Method: 通过识别Llama-3.1-8B残差流中的特定方向，并使用该方向来引导蒸馏推理模型，来研究回溯行为的产生机制。

Result: 发现Llama-3.1-8B残差流中的一个特定方向能够系统地诱导蒸馏推理模型产生回溯行为，并且这种影响不能仅用token级别属性来解释。该方向在基座模型中并不会诱导回溯行为，表明推理微调过程重新利用了预先存在的表征。

Conclusion: 推理微调模型通过改造基座模型中已有的表征来产生新的行为电路，而不是从头开始学习新能力。

Abstract: Backtracking, an emergent behavior elicited by reasoning fine-tuning, has
been shown to be a key mechanism in reasoning models' enhanced capabilities.
Prior work has succeeded in manipulating this behavior via steering vectors,
but the underlying mechanism remains poorly understood. In this work, we show
that the emergence of backtracking in DeepSeek-R1-Distill-Llama-8B is in part
driven by a repurposed direction already present in base model activations.
Specifically, we identify a direction in base Llama-3.1-8B's residual stream
which systematically induces backtracking when used to steer the distilled
reasoning model, and find that the effects of steering with this direction
cannot be trivially explained by token-level attributes. We further find that
this direction does not induce backtracking in the base model, suggesting that
the reasoning finetuning process repurposes pre-existing representations to
form new behavioral circuits. Additionally, we hypothesize that this direction
is one of several which may work together to mediate backtracking. Our findings
offer a compelling picture that reasoning-finetuned models repurpose
pre-existing base model representations, rather than learn new capabilities
from scratch.

</details>


### [142] [Federated Learning in Open- and Closed-Loop EMG Decoding: A Privacy and Performance Perspective](https://arxiv.org/abs/2507.12652)
*Kai Malcolm,César Uribe,Momona Yamagami*

Main category: cs.LG

TL;DR: 本研究探索了联邦学习在神经解码中的应用，发现在开放场景下性能优越且保护隐私，但在闭环场景下，调整后的联邦学习方法性能不如局部学习，尽管局部学习的隐私风险更高。研究揭示了实时应用中性能与隐私的权衡，并强调了为单一用户协同自适应场景设计特定联邦学习方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 神经信号包含关于个体身份和健康的敏感信息，使得数据共享用于解码器训练成为一个关键的隐私挑战。联邦学习（FL）作为一种分布式、保护隐私的学习框架，为解决这一挑战提供了有前景的解决方案，但其在闭环自适应神经接口中的应用仍有待探索。

Method: 本文介绍了基于联邦学习的神经解码方法，并使用高维肌电图信号在开放和封闭循环场景中系统地评估了其性能和隐私。

Result: 在开放循环模拟中，联邦学习的性能显著优于局部学习基线。然而，在闭环用户研究中，需要对联邦学习方法进行调整以适应单一用户、实时交互，这导致了局部学习解码器在闭环性能上超过了调整后的联邦学习方法，但局部学习仍然伴随着更高的隐私风险。

Conclusion: 研究结果强调了在实时自适应应用中性能和隐私之间的关键权衡，并指出需要专门为协同自适应、单一用户应用设计联邦学习方法。

Abstract: Invasive and non-invasive neural interfaces hold promise as high-bandwidth
input devices for next-generation technologies. However, neural signals
inherently encode sensitive information about an individual's identity and
health, making data sharing for decoder training a critical privacy challenge.
Federated learning (FL), a distributed, privacy-preserving learning framework,
presents a promising solution, but it remains unexplored in closed-loop
adaptive neural interfaces. Here, we introduce FL-based neural decoding and
systematically evaluate its performance and privacy using high-dimensional
electromyography signals in both open- and closed-loop scenarios. In open-loop
simulations, FL significantly outperformed local learning baselines,
demonstrating its potential for high-performance, privacy-conscious neural
decoding. In contrast, closed-loop user studies required adapting FL methods to
accommodate single-user, real-time interactions, a scenario not supported by
standard FL. This modification resulted in local learning decoders surpassing
the adapted FL approach in closed-loop performance, yet local learning still
carried higher privacy risks. Our findings highlight a critical
performance-privacy tradeoff in real-time adaptive applications and indicate
the need for FL methods specifically designed for co-adaptive, single-user
applications.

</details>


### [143] [Data Transformation Strategies to Remove Heterogeneity](https://arxiv.org/abs/2507.12677)
*Sangbong Yoo,Jaeyoung Lee,Chanyoung Yoon,Geonyeong Son,Hyein Hong,Seongbum Seo,Soobin Yim,Chanyoung Jung,Jungsoo Park,Misuk Kim,Yun Jang*

Main category: cs.LG

TL;DR: 数据异构性，特别是格式问题，阻碍了AI发展。本研究回顾了数据转换策略，以应对这些挑战。


<details>
  <summary>Details</summary>
Motivation: 解决数据异构性问题，特别是数据格式差异，以及当前方法在数据转换方面关注不足的问题，同时满足日益增长的AI对数据准备流程简化的需求。

Method: 通过系统性地梳理和分类解决数据格式差异引起的数据异构性问题的策略，并阐述每种策略的固有挑战。

Result: 对数据异构性的来源和复杂性进行了探讨，并对数据转换策略进行了分类和总结，为AI应用提供了数据准备的见解。

Conclusion: 本篇论文旨在全面回顾数据转换的策略，以应对数据异构性带来的挑战，尤其关注不同数据格式。

Abstract: Data heterogeneity is a prevalent issue, stemming from various conflicting
factors, making its utilization complex. This uncertainty, particularly
resulting from disparities in data formats, frequently necessitates the
involvement of experts to find resolutions. Current methodologies primarily
address conflicts related to data structures and schemas, often overlooking the
pivotal role played by data transformation. As the utilization of artificial
intelligence (AI) continues to expand, there is a growing demand for a more
streamlined data preparation process, and data transformation becomes
paramount. It customizes training data to enhance AI learning efficiency and
adapts input formats to suit diverse AI models. Selecting an appropriate
transformation technique is paramount in preserving crucial data details.
Despite the widespread integration of AI across various industries,
comprehensive reviews concerning contemporary data transformation approaches
are scarce. This survey explores the intricacies of data heterogeneity and its
underlying sources. It systematically categorizes and presents strategies to
address heterogeneity stemming from differences in data formats, shedding light
on the inherent challenges associated with each strategy.

</details>


### [144] [PinFM: Foundation Model for User Activity Sequences at a Billion-scale Visual Discovery Platform](https://arxiv.org/abs/2507.12704)
*Xiangyi Chen,Kousik Rajesh,Matthew Lawhon,Zelun Wang,Hanyu Li,Haomiao Li,Saurabh Vishwas Joshi,Pong Eksombatchai,Jaewon Yang,Yi-Ping Hsu,Jiajing Xu,Charles Rosenberg*

Main category: cs.LG

TL;DR: PinFM是一个在Pinterest预训练的20B+参数Transformer基础模型，用于跨应用程序的推荐系统。通过DCAT等技术优化，它提高了吞吐量和新项目参与度，并已部署到为超过5亿用户提供服务。


<details>
  <summary>Details</summary>
Motivation: 为了在十亿级规模的视觉发现平台上理解跨多个应用程序的用户活动序列，并克服在工业推荐系统中应用基础模型所面临的挑战，例如可扩展性、成本、延迟和处理新项目等。

Method: PinFM是一个包含20B+参数的Transformer基础模型，通过用户活动数据进行预训练，然后针对特定应用进行微调。采用了去重交叉注意力Transformer（DCAT）等技术来优化吞吐量，解决了可扩展性、成本、延迟和处理新项目等挑战。

Result: PinFM的吞吐量提高了600%，在提高新项目参与度方面提升了20%。

Conclusion: PinFM已被部署以改善半个多亿用户在各种应用中的体验，它能够学习用户序列与候选项目之间的交互，从而提高了新项目的参与度。

Abstract: User activity sequences have emerged as one of the most important signals in
recommender systems. We present a foundational model, PinFM, for understanding
user activity sequences across multiple applications at a billion-scale visual
discovery platform. We pretrain a transformer model with 20B+ parameters using
extensive user activity data, then fine-tune it for specific applications,
efficiently coupling it with existing models. While this
pretraining-and-fine-tuning approach has been popular in other domains, such as
Vision and NLP, its application in industrial recommender systems presents
numerous challenges. The foundational model must be scalable enough to score
millions of items every second while meeting tight cost and latency constraints
imposed by these systems. Additionally, it should capture the interactions
between user activities and other features and handle new items that were not
present during the pretraining stage.
  We developed innovative techniques to address these challenges. Our
infrastructure and algorithmic optimizations, such as the Deduplicated
Cross-Attention Transformer (DCAT), improved our throughput by 600% on
Pinterest internal data. We demonstrate that PinFM can learn interactions
between user sequences and candidate items by altering input sequences, leading
to a 20% increase in engagement with new items. PinFM is now deployed to help
improve the experience of more than a half billion users across various
applications.

</details>


### [145] [From SGD to Spectra: A Theory of Neural Network Weight Dynamics](https://arxiv.org/abs/2507.12709)
*Brian Richard Olsen,Sam Fatehmanesh,Frank Xiao,Adarsh Kumarappan,Anirudh Gajula*

Main category: cs.LG

TL;DR: "This paper provides a theoretical framework using stochastic differential equations to explain the training dynamics and spectral properties of deep neural networks, validating predictions with experiments."


<details>
  <summary>Details</summary>
Motivation: "The motivation behind this research is to bridge the theoretical gap in understanding the training dynamics of deep neural networks (DNNs), which have shown remarkable success despite the lack of clear theoretical explanations for their behavior. The paper aims to provide a rigorous mathematical framework to connect the microscopic dynamics of Stochastic Gradient Descent (SGD) to the macroscopic evolution of singular-value spectra in weight matrices, thereby offering insights into why DNNs work."

Method: "The paper develops a continuous-time, matrix-valued stochastic differential equation (SDE) framework to model the training dynamics of deep neural networks. It derives exact SDEs for the evolution of singular-value spectra in weight matrices, relating them to Dyson Brownian motion with eigenvalue repulsion. The study also characterizes stationary distributions as gamma-type densities with power-law tails."

Result: "The study successfully develops an SDE framework that rigorously connects SGD dynamics to the evolution of singular-value spectra in weight matrices. It derives exact SDEs demonstrating that squared singular values follow Dyson Brownian motion with eigenvalue repulsion. The research also characterizes stationary distributions as gamma-type densities with power-law tails, providing the first theoretical explanation for the observed "bulk+tail" spectral structure in trained networks. Experiments on transformer and MLP architectures validate these predictions, showing quantitative agreement between SDE-based forecasts and observed spectral evolution."

Conclusion: "Deep neural networks (DNNs) have revolutionized machine learning, but their training dynamics are not well understood theoretically. This paper develops a continuous-time, matrix-valued stochastic differential equation (SDE) framework that rigorously connects the microscopic dynamics of Stochastic Gradient Descent (SGD) to the macroscopic evolution of singular-value spectra in weight matrices. The study derives exact SDEs showing that squared singular values follow Dyson Brownian motion with eigenvalue repulsion, and characterizes stationary distributions as gamma-type densities with power-law tails. This provides the first theoretical explanation for the empirically observed 

Abstract: Deep neural networks have revolutionized machine learning, yet their training
dynamics remain theoretically unclear-we develop a continuous-time,
matrix-valued stochastic differential equation (SDE) framework that rigorously
connects the microscopic dynamics of SGD to the macroscopic evolution of
singular-value spectra in weight matrices. We derive exact SDEs showing that
squared singular values follow Dyson Brownian motion with eigenvalue repulsion,
and characterize stationary distributions as gamma-type densities with
power-law tails, providing the first theoretical explanation for the
empirically observed 'bulk+tail' spectral structure in trained networks.
Through controlled experiments on transformer and MLP architectures, we
validate our theoretical predictions and demonstrate quantitative agreement
between SDE-based forecasts and observed spectral evolution, providing a
rigorous foundation for understanding why deep learning works.

</details>


### [146] [Multimodal-Guided Dynamic Dataset Pruning for Robust and Efficient Data-Centric Learning](https://arxiv.org/abs/2507.12750)
*Suorong Yang,Peijia Li,Yujie Liu,Zhiming Xu,Peng Ye,Wanli Ouyang,Furao Shen,Dongzhan Zhou*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的动态数据集剪枝框架，利用多模态基础模型和跨模态语义一致性来动态选择训练样本，提高了模型训练的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集剪枝方法大多依赖于静态启发式方法或特定任务的度量，这限制了它们在不同领域中的鲁棒性和泛化能力。因此，需要一种更动态、更通用的方法来提高训练效率和模型性能。

Method: 本研究提出了一种动态数据集剪枝框架，该框架能够自适应地根据任务驱动的难度和跨模态语义一致性来选择训练样本。具体来说，它利用了预训练的多模态基础模型来提供监督，从而捕捉训练动态并有效过滤掉信息量低的样本。

Result: 本研究通过整合跨模态对齐，实现了鲁棒的样本选择，提高了数据为中心的学习方法在效率和鲁棒性方面的表现。

Conclusion: 本研究提出了一种动态数据集剪枝框架，通过结合任务驱动的难度和跨模态语义一致性来选择训练样本，并利用预训练的多模态基础模型进行监督，以捕捉训练动态并有效过滤信息量低的样本。该方法通过整合跨模态对齐来增强样本选择的鲁棒性，推动了以数据为中心的学习方法在效率和鲁棒性方面的进步。

Abstract: Modern deep models are trained on large real-world datasets, where data
quality varies and redundancy is common. Data-centric approaches such as
dataset pruning have shown promise in improving training efficiency and model
performance. However, most existing methods rely on static heuristics or
task-specific metrics, limiting their robustness and generalizability across
domains. In this work, we introduce a dynamic dataset pruning framework that
adaptively selects training samples based on both task-driven difficulty and
cross-modality semantic consistency. By incorporating supervision from
pretrained multimodal foundation models, our approach captures training
dynamics while effectively filtering out uninformative samples. Our work
highlights the potential of integrating cross-modality alignment for robust
sample selection, advancing data-centric learning toward more efficient and
robust practices across application domains.

</details>


### [147] [Layer Separation Deep Learning Model with Auxiliary Variables for Partial Differential Equations](https://arxiv.org/abs/2507.12766)
*Yaru Liu,Yiqi Gu*

Main category: cs.LG

TL;DR: LySep模型通过引入辅助变量将深度网络分解为浅层网络，解决了深度学习求解偏微分方程中的优化问题，并在数值结果中显示出优势。


<details>
  <summary>Details</summary>
Motivation: 深度学习在求解偏微分方程时，由于损失函数的高度非凸性，现有优化算法常收敛到次优局部最小值或遭遇梯度爆炸/消失问题，导致性能不佳。

Method: 提出了一种名为层分离（LySep）的新优化框架，通过引入辅助变量分离深度神经网络的层，将深层架构分解为一系列浅层架构，并建立了包含辅助变量的新损失函数，然后基于交替方向开发了相应的算法。

Result: 高维度数值结果验证了该理论，并证明了LySep在最小化损失和减少求解误差方面的优势。

Conclusion: LySep模型在最小化损失和减少求解误差方面具有优势，理论分析表明LySep模型与原始深度模型具有一致性。

Abstract: In this paper, we propose a new optimization framework, the layer separation
(LySep) model, to improve the deep learning-based methods in solving partial
differential equations. Due to the highly non-convex nature of the loss
function in deep learning, existing optimization algorithms often converge to
suboptimal local minima or suffer from gradient explosion or vanishing,
resulting in poor performance. To address these issues, we introduce auxiliary
variables to separate the layers of deep neural networks. Specifically, the
output and its derivatives of each layer are represented by auxiliary
variables, effectively decomposing the deep architecture into a series of
shallow architectures. New loss functions with auxiliary variables are
established, in which only variables from two neighboring layers are coupled.
Corresponding algorithms based on alternating directions are developed, where
many variables can be updated optimally in closed forms. Moreover, we provide
theoretical analyses demonstrating the consistency between the LySep model and
the original deep model. High-dimensional numerical results validate our theory
and demonstrate the advantages of LySep in minimizing loss and reducing
solution error.

</details>


### [148] [Leveraging Asynchronous Cross-border Market Data for Improved Day-Ahead Electricity Price Forecasting in European Markets](https://arxiv.org/abs/2507.13250)
*Maria Margarida Mascarenhas,Jilles De Blauwe,Mikael Amelin,Hussain Kazmi*

Main category: cs.LG

TL;DR: 利用不同集合时间的市场数据可提高电力价格预测的准确性，但需注意模型校准成本和数据选择策略。


<details>
  <summary>Details</summary>
Motivation: 为了提高短期电力价格预测的准确性，以优化日内市场中的需求调度和发电竞标策略，本研究旨在探索将具有不同集合时间的市场（即不同集合时间）的异步发布价格作为协变量，是否能提升其他集合时间较晚市场的预测精度。

Method: 本研究采用先进的模型集成方法，并结合来自具有不同集合时间的市场（如德国-卢森堡、奥地利和瑞士）的价格数据，来预测比利时（BE）和瑞典（SE3）市场的电力价格。

Result: 通过使用先进的模型集成方法，在比利时市场（BE）和瑞典（SE3）市场中，当纳入来自具有更早集合时间的互联市场（德国-卢森堡、奥地利和瑞士）的价格数据时，预测准确性分别提高了22%和9%。这种改进在一般和极端市场条件下均成立。此外，研究发现频繁的模型重新校准虽然能最大化准确性，但会增加显著的计算成本，并且纳入更多市场的数据并不总能带来更好的性能。

Conclusion: 该研究表明，在欧洲日益互联和波动的能源市场中，纳入来自具有更早集合时间的互联市场（德国-卢森堡、奥地利和瑞士）的价格数据，可以显著提高比利时和瑞典（SE3）市场的短期电力价格预测准确性。研究还强调了模型校准频率与计算成本之间的权衡，并指出了并非所有引入的互联市场都能带来性能提升，这需要通过可解释性分析来深入理解。

Abstract: Accurate short-term electricity price forecasting is crucial for
strategically scheduling demand and generation bids in day-ahead markets. While
data-driven techniques have shown considerable prowess in achieving high
forecast accuracy in recent years, they rely heavily on the quality of input
covariates. In this paper, we investigate whether asynchronously published
prices as a result of differing gate closure times (GCTs) in some bidding zones
can improve forecasting accuracy in other markets with later GCTs. Using a
state-of-the-art ensemble of models, we show significant improvements of 22%
and 9% in forecast accuracy in the Belgian (BE) and Swedish bidding zones (SE3)
respectively, when including price data from interconnected markets with
earlier GCT (Germany-Luxembourg, Austria, and Switzerland). This improvement
holds for both general as well as extreme market conditions. Our analysis also
yields further important insights: frequent model recalibration is necessary
for maximum accuracy but comes at substantial additional computational costs,
and using data from more markets does not always lead to better performance - a
fact we delve deeper into with interpretability analysis of the forecast
models. Overall, these findings provide valuable guidance for market
participants and decision-makers aiming to optimize bidding strategies within
increasingly interconnected and volatile European energy markets.

</details>


### [149] [A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models](https://arxiv.org/abs/2507.12774)
*Weijieying Ren,Jingxi Zhu,Zehao Liu,Tianxiang Zhao,Vasant Honavar*

Main category: cs.LG

TL;DR: 本调查全面概述了AI在电子健康记录（EHR）建模方面的最新进展，重点关注深度学习、大型语言模型（LLM）和多模态学习。文章提出了一个包含数据中心方法、神经架构设计、学习策略、多模态学习和LLM系统五个维度的分类法，并回顾了相关方法和新兴趋势，同时讨论了当前面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHR）数据具有异质性、时间不规则性和领域特定性等固有挑战，这与视觉和自然语言任务存在根本性差异。因此，AI在医疗保健领域的应用，特别是通过EHR数据分析和建模，具有巨大的潜力，但也面临独特的挑战。

Method: 本调查采用了统一的分类法，涵盖了数据中心方法、神经架构设计、以学习为中心的策略、多模态学习和基于LLM的建模系统这五个关键设计维度。在每个维度下，我们回顾了解决数据质量增强、结构和时间表示、自监督学习以及与临床知识整合的代表性方法。

Result: 本调查全面概述了深度学习、大型语言模型（LLM）和EHR建模交叉领域的最新进展。重点介绍了基础模型、LLM驱动的临床代理和EHR到文本翻译等新兴趋势，并讨论了基准测试、可解释性、临床一致性和泛化能力等方面的开放性挑战。本调查旨在为推进AI驱动的EHR建模和临床决策支持提供结构化路线图。

Conclusion: AI在电子健康记录（EHR）建模方面取得了显著进展，特别是在深度学习、大型语言模型（LLM）和多模态学习方面。本调查全面概述了这些进展，并讨论了数据质量、结构和时间表示、自监督学习以及与临床知识的整合等关键领域。此外，还强调了基础模型、LLM驱动的临床代理和EHR到文本翻译等新兴趋势。最后，讨论了基准测试、可解释性、临床一致性和泛化能力等开放性挑战。

Abstract: Artificial intelligence (AI) has demonstrated significant potential in
transforming healthcare through the analysis and modeling of electronic health
records (EHRs). However, the inherent heterogeneity, temporal irregularity, and
domain-specific nature of EHR data present unique challenges that differ
fundamentally from those in vision and natural language tasks. This survey
offers a comprehensive overview of recent advancements at the intersection of
deep learning, large language models (LLMs), and EHR modeling. We introduce a
unified taxonomy that spans five key design dimensions: data-centric
approaches, neural architecture design, learning-focused strategies, multimodal
learning, and LLM-based modeling systems. Within each dimension, we review
representative methods addressing data quality enhancement, structural and
temporal representation, self-supervised learning, and integration with
clinical knowledge. We further highlight emerging trends such as foundation
models, LLM-driven clinical agents, and EHR-to-text translation for downstream
reasoning. Finally, we discuss open challenges in benchmarking, explainability,
clinical alignment, and generalization across diverse clinical settings. This
survey aims to provide a structured roadmap for advancing AI-driven EHR
modeling and clinical decision support. For a comprehensive list of EHR-related
methods, kindly refer to https://survey-on-tabular-data.github.io/.

</details>


### [150] [Multi-Channel Graph Neural Network for Financial Risk Prediction of NEEQ Enterprises](https://arxiv.org/abs/2507.12787)
*Jianyu Zhu*

Main category: cs.LG

TL;DR: 提出一种结合财务指标、文本披露和企业关系数据的多通道深度学习框架，用于预测新三板上市公司的财务风险，实验结果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 中国多层次资本市场不断发展，新三板已成为中小企业的重要融资平台。然而，许多新三板上市公司规模有限、财务弹性较差，面临较高的财务困境风险。

Method: 提出了一种多通道深度学习框架，结合结构化财务指标、文本披露和企业关系数据进行全面的财务风险预测。具体设计了三通道图同构网络（GIN），分别处理数值、文本和基于图的输入，并通过基于注意力的机制和门控单元融合这些特定模态的表示，以增强鲁棒性和预测准确性。

Result: 在7,731家新三板公司真实世界数据上的实验结果表明，我们的模型在AUC、精确率、召回率和F1分数方面显著优于传统的机器学习方法和单模态基线。

Conclusion: 该模型在AUC、精确率、召回率和F1分数方面显著优于传统的机器学习方法和单模态基线，为中小企业风险建模提供了理论和实践见解，并为金融监管机构和投资者提供了一个数据驱动的工具。

Abstract: With the continuous evolution of China's multi-level capital market, the
National Equities Exchange and Quotations (NEEQ), also known as the "New Third
Board," has become a critical financing platform for small and medium-sized
enterprises (SMEs). However, due to their limited scale and financial
resilience, many NEEQ-listed companies face elevated risks of financial
distress. To address this issue, we propose a multi-channel deep learning
framework that integrates structured financial indicators, textual disclosures,
and enterprise relationship data for comprehensive financial risk prediction.
Specifically, we design a Triple-Channel Graph Isomorphism Network (GIN) that
processes numeric, textual, and graph-based inputs separately. These
modality-specific representations are fused using an attention-based mechanism
followed by a gating unit to enhance robustness and prediction accuracy.
Experimental results on data from 7,731 real-world NEEQ companies demonstrate
that our model significantly outperforms traditional machine learning methods
and single-modality baselines in terms of AUC, Precision, Recall, and F1 Score.
This work provides theoretical and practical insights into risk modeling for
SMEs and offers a data-driven tool to support financial regulators and
investors.

</details>


### [151] [FLDmamba: Integrating Fourier and Laplace Transform Decomposition with Mamba for Enhanced Time Series Prediction](https://arxiv.org/abs/2507.12803)
*Qianru Zhang,Chenglei Yu,Haixin Wang,Yudong Yan,Yuansheng Cao,Siu-Ming Yiu,Tailin Wu,Hongzhi Yin*

Main category: cs.LG

TL;DR: FLDmamba是一个新的时间序列预测框架，它使用傅里叶和拉普拉斯变换来处理长期预测的复杂性，优于现有的Transformer和Mamba模型。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在长期预测时存在二次复杂度问题，而Mamba等状态空间模型虽然效率更高，但无法有效捕捉多尺度周期性和瞬态动力学，且易受噪声影响。本研究旨在解决这些局限性。

Method: FLDmamba框架结合傅里叶变换和拉普拉斯变换来捕捉多尺度周期性和瞬态动力学，并提高模型对噪声的鲁棒性。

Result: FLDmamba在时间序列预测基准测试中取得了卓越的性能，超越了基于Transformer和Mamba的其他模型。

Conclusion: FLDmamba框架通过结合傅里叶变换和拉普拉斯变换的优势，在时间序列预测任务上取得了优于Transformer和Mamba类模型的性能，尤其在处理长期预测、多尺度周期性和瞬态动力学方面表现突出，并提高了模型对噪声的鲁棒性。

Abstract: Time series prediction, a crucial task across various domains, faces
significant challenges due to the inherent complexities of time series data,
including non-stationarity, multi-scale periodicity, and transient dynamics,
particularly when tackling long-term predictions. While Transformer-based
architectures have shown promise, their quadratic complexity with sequence
length hinders their efficiency for long-term predictions. Recent advancements
in State-Space Models, such as Mamba, offer a more efficient alternative for
long-term modeling, but they cannot capture multi-scale periodicity and
transient dynamics effectively. Meanwhile, they are susceptible to data noise
issues in time series. This paper proposes a novel framework, FLDmamba (Fourier
and Laplace Transform Decomposition Mamba), addressing these limitations.
FLDmamba leverages the strengths of both Fourier and Laplace transforms to
effectively capture both multi-scale periodicity, transient dynamics within
time series data, and improve the robustness of the model to the data noise
issue. Our extensive experiments demonstrate that FLDmamba achieves superior
performance on time series prediction benchmarks, outperforming both
Transformer-based and other Mamba-based architectures. To promote the
reproducibility of our method, we have made both the code and data accessible
via the following
URL:{\href{https://github.com/AI4Science-WestlakeU/FLDmamba}{https://github.com/AI4Science-WestlakeU/\model}.

</details>


### [152] [PMKLC: Parallel Multi-Knowledge Learning-based Lossless Compression for Large-Scale Genomics Database](https://arxiv.org/abs/2507.12805)
*Hui Sun,Yanfeng Ding,Liping Yi,Huidong Ma,Gang Wang,Xiaoguang Liu,Cheng Zhong,Wentong Cai*

Main category: cs.LG

TL;DR: PMKLC 是一种新的学习型无损压缩器，通过多知识学习、GPU 加速、并行处理和两种模式（PMKLC-S/M），显著提高了压缩比、吞吐量和鲁棒性，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有学习型无损压缩器在压缩比、压缩/解压缩吞吐量和鲁棒性方面的不足，以实现其在工业和学术界的广泛应用。

Method: 提出了一种新颖的基于并行多知识学习的压缩器 (PMKLC)，包括：1) 基于多知识学习的压缩框架；2) GPU 加速的 (s,k)-mer 编码器；3) 数据块分区和分步模型传递 (SMP) 机制；4) 两种压缩模式 PMKLC-S 和 PMKLC-M。

Result: PMKLC-S/M 在 15 个真实世界数据集上的测试结果显示，与基线方法相比，平均压缩比提高了 73.609% 和 73.480%，平均吞吐量提高了 3.036 倍和 10.710 倍，同时在鲁棒性和内存消耗方面也表现出色。

Conclusion: PMKLC-S/M 在压缩比、吞吐量和鲁棒性方面均优于基线方法，表明其在行业和学术界具有广泛的应用前景。

Abstract: Learning-based lossless compressors play a crucial role in large-scale
genomic database backup, storage, transmission, and management. However, their
1) inadequate compression ratio, 2) low compression \& decompression
throughput, and 3) poor compression robustness limit their widespread adoption
and application in both industry and academia. To solve those challenges, we
propose a novel \underline{P}arallel \underline{M}ulti-\underline{K}nowledge
\underline{L}earning-based \underline{C}ompressor (PMKLC) with four crucial
designs: 1) We propose an automated multi-knowledge learning-based compression
framework as compressors' backbone to enhance compression ratio and robustness;
2) we design a GPU-accelerated ($s$,$k$)-mer encoder to optimize compression
throughput and computing resource usage; 3) we introduce data block
partitioning and Step-wise Model Passing (SMP) mechanisms for parallel
acceleration; 4) We design two compression modes PMKLC-S and PMKLC-M to meet
the complex application scenarios, where the former runs on a
resource-constrained single GPU and the latter is multi-GPU accelerated. We
benchmark PMKLC-S/M and 14 baselines (7 traditional and 7 leaning-based) on 15
real-world datasets with different species and data sizes. Compared to
baselines on the testing datasets, PMKLC-S/M achieve the average compression
ratio improvement up to 73.609\% and 73.480\%, the average throughput
improvement up to 3.036$\times$ and 10.710$\times$, respectively. Besides,
PMKLC-S/M also achieve the best robustness and competitive memory cost,
indicating its greater stability against datasets with different probability
distribution perturbations, and its strong ability to run on memory-constrained
devices.

</details>


### [153] [From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning](https://arxiv.org/abs/2507.12815)
*Gaurav Chaudhary,Laxmidhar Behera*

Main category: cs.LG

TL;DR: ReLOAD 提出了一种新的离线强化学习奖励标注框架，利用随机网络蒸馏从专家演示中生成内在奖励，无需手工标注，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 目前的离线强化学习（RL）方法通常需要显式的奖励标注，这在实际应用中可能成本高昂或难以获取。为了解决这个问题，本研究提出了 ReLOAD 框架，用于离线 RL 的奖励标注。

Method: ReLOAD（Reinforcement Learning with Offline Reward Annotation via Distillation）框架，该框架将随机网络蒸馏（RND）应用于专家演示，通过嵌入差异度量来生成内在奖励。具体来说，它训练一个预测网络来模仿固定目标网络的嵌入，并将这两个网络的预测误差作为静态数据集的奖励信号。

Result: 实验结果表明，ReLOAD 能够实现鲁棒的离线策略学习，性能与传统的奖励标注方法相当。

Conclusion: ReLOAD 框架能够实现无需手工标注的奖励进行有效的离线策略学习，并且在 D4RL 基准测试上取得了与传统奖励标注方法相当的性能。

Abstract: Offline Reinforcement Learning (RL) aims to learn effective policies from a
static dataset without requiring further agent-environment interactions.
However, its practical adoption is often hindered by the need for explicit
reward annotations, which can be costly to engineer or difficult to obtain
retrospectively. To address this, we propose ReLOAD (Reinforcement Learning
with Offline Reward Annotation via Distillation), a novel reward annotation
framework for offline RL. Unlike existing methods that depend on complex
alignment procedures, our approach adapts Random Network Distillation (RND) to
generate intrinsic rewards from expert demonstrations using a simple yet
effective embedding discrepancy measure. First, we train a predictor network to
mimic a fixed target network's embeddings based on expert state transitions.
Later, the prediction error between these networks serves as a reward signal
for each transition in the static dataset. This mechanism provides a structured
reward signal without requiring handcrafted reward annotations. We provide a
formal theoretical construct that offers insights into how RND prediction
errors effectively serve as intrinsic rewards by distinguishing expert-like
transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables
robust offline policy learning and achieves performance competitive with
traditional reward-annotated methods.

</details>


### [154] [Understanding the Evolution of the Neural Tangent Kernel at the Edge of Stability](https://arxiv.org/abs/2507.12837)
*Kaiqi Jiang,Jeremy Cohen,Yuanzhi Li*

Main category: cs.LG

TL;DR: 本研究关注深度学习中神经切线核（NTK）的特征向量在梯度下降（GD）和稳定性边缘（EoS）下的行为。研究发现，较大的学习率可以使NTK的特征向量与训练目标更对齐，并对双层线性网络进行了理论分析。


<details>
  <summary>Details</summary>
Motivation: 虽然已有研究关注EoS下的NTK特征值行为，但对其特征向量行为的理解仍然缺失。

Method: 研究NTK特征值在EoS下的动态。

Result: 研究发现，在EoS下，更大的学习率会使最终NTK和完整NTK矩阵的前导特征向量与训练目标具有更强的对齐性。对双层线性网络进行了理论分析以解释该现象。

Conclusion: 本研究通过研究NTK特征值在EoS下的动态，增进了对深度学习中GD训练动态的理解。

Abstract: The study of Neural Tangent Kernels (NTKs) in deep learning has drawn
increasing attention in recent years. NTKs typically actively change during
training and are related to feature learning. In parallel, recent work on
Gradient Descent (GD) has found a phenomenon called Edge of Stability (EoS), in
which the largest eigenvalue of the NTK oscillates around a value inversely
proportional to the step size. However, although follow-up works have explored
the underlying mechanism of such eigenvalue behavior in depth, the
understanding of the behavior of the NTK eigenvectors during EoS is still
missing. This paper examines the dynamics of NTK eigenvectors during EoS in
detail. Across different architectures, we observe that larger learning rates
cause the leading eigenvectors of the final NTK, as well as the full NTK
matrix, to have greater alignment with the training target. We then study the
underlying mechanism of this phenomenon and provide a theoretical analysis for
a two-layer linear network. Our study enhances the understanding of GD training
dynamics in deep learning.

</details>


### [155] [A Kernel Distribution Closeness Testing](https://arxiv.org/abs/2507.12843)
*Zhijian Zhou,Liuhua Peng,Xunye Tian,Feng Liu*

Main category: cs.LG

TL;DR: A new method called NAMMD improves distribution comparison by considering distribution norms, leading to better accuracy in testing tasks compared to existing methods like MMD.


<details>
  <summary>Details</summary>
Motivation: Existing distribution closeness testing (DCT) methods are limited to discrete one-dimensional spaces. MMD, while applicable to complex data, is less informative for comparing multiple distribution pairs due to its inability to distinguish between distributions with different norms but the same MMD value.

Method: Propose norm-adaptive MMD (NAMMD) which scales MMD by RKHS norms of distributions. Based on the asymptotic distribution of NAMMD, develop NAMMD-based DCT to assess distribution pair closeness levels. Apply NAMMD to two-sample testing.

Result: NAMMD addresses the limitations of MMD by incorporating RKHS norms, providing a more informative measure of distributional discrepancy. NAMMD-based DCT and two-sample test demonstrate superior test power compared to MMD-based methods.

Conclusion: NAMMD-based DCT and NAMMD-based two-sample test have higher test power than their MMD-based counterparts, with bounded type-I error, validated by theory and experiments.

Abstract: The distribution closeness testing (DCT) assesses whether the distance
between a distribution pair is at least $\epsilon$-far. Existing DCT methods
mainly measure discrepancies between a distribution pair defined on discrete
one-dimensional spaces (e.g., using total variation), which limits their
applications to complex data (e.g., images). To extend DCT to more types of
data, a natural idea is to introduce maximum mean discrepancy (MMD), a powerful
measurement of the distributional discrepancy between two complex
distributions, into DCT scenarios. However, we find that MMD's value can be the
same for many pairs of distributions that have different norms in the same
reproducing kernel Hilbert space (RKHS), making MMD less informative when
assessing the closeness levels for multiple distribution pairs. To mitigate the
issue, we design a new measurement of distributional discrepancy, norm-adaptive
MMD (NAMMD), which scales MMD's value using the RKHS norms of distributions.
Based on the asymptotic distribution of NAMMD, we finally propose the
NAMMD-based DCT to assess the closeness levels of a distribution pair.
Theoretically, we prove that NAMMD-based DCT has higher test power compared to
MMD-based DCT, with bounded type-I error, which is also validated by extensive
experiments on many types of data (e.g., synthetic noise, real images).
Furthermore, we also apply the proposed NAMMD for addressing the two-sample
testing problem and find NAMMD-based two-sample test has higher test power than
the MMD-based two-sample test in both theory and experiments.

</details>


### [156] [Transformer-Based Person Identification via Wi-Fi CSI Amplitude and Phase Perturbations](https://arxiv.org/abs/2507.12854)
*Danilo Avola,Andrea Bernardini,Francesco Danese,Mario Lezoche,Maurizio Mancini,Daniele Pannone,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 这项研究提出了一种利用Wi-Fi信号的信道状态信息（CSI）来识别静止人员的方法，即使在没有用户运动的情况下也能工作。该方法使用Transformer模型，并在包含六名参与者的特定数据集上实现了99.82%的准确率，证明了Wi-Fi传感在人员识别方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 在不依赖用户运动的情况下，通过无线信号进行人员识别仍然是一个未被充分探索的领域。大多数先前基于无线的方法依赖于运动模式（如步态）来提取生物识别线索。

Method: 提出了一种基于Transformer的方法，利用捕获的信道状态信息（CSI）来识别个体，即使在用户静止的情况下。该方法使用双分支Transformer架构，分别处理振幅和相位模式，并在包含六名参与者的、在受控室内环境中，使用ESP32设备收集的数据集上进行了评估。还包括了一个定制的预处理流程，以提高信号质量。

Result: 该模型达到了99.82%的分类准确率，优于卷积和多层感知器基线，证明了CSI扰动的识别潜力，能够以一致的方式编码生物特征。

Conclusion: Wi-Fi信号的CSI扰动具有识别个体生物特征的潜力，并且可以在真实世界的设置中，使用低成本的商品Wi-Fi硬件，实现被动、无设备的人员识别。

Abstract: Wi-Fi sensing is gaining momentum as a non-intrusive and privacy-preserving
alternative to vision-based systems for human identification. However, person
identification through wireless signals, particularly without user motion,
remains largely unexplored. Most prior wireless-based approaches rely on
movement patterns, such as walking gait, to extract biometric cues. In
contrast, we propose a transformer-based method that identifies individuals
from Channel State Information (CSI) recorded while the subject remains
stationary. CSI captures fine-grained amplitude and phase distortions induced
by the unique interaction between the human body and the radio signal. To
support evaluation, we introduce a dataset acquired with ESP32 devices in a
controlled indoor environment, featuring six participants observed across
multiple orientations. A tailored preprocessing pipeline, including outlier
removal, smoothing, and phase calibration, enhances signal quality. Our
dual-branch transformer architecture processes amplitude and phase modalities
separately and achieves 99.82\% classification accuracy, outperforming
convolutional and multilayer perceptron baselines. These results demonstrate
the discriminative potential of CSI perturbations, highlighting their capacity
to encode biometric traits in a consistent manner. They further confirm the
viability of passive, device-free person identification using low-cost
commodity Wi-Fi hardware in real-world settings.

</details>


### [157] [Supervised Fine Tuning on Curated Data is Reinforcement Learning (and can be improved)](https://arxiv.org/abs/2507.12856)
*Chongli Qin,Jost Tobias Springenberg*

Main category: cs.LG

TL;DR: 通过行为克隆（BC）和强化学习（RL）的结合，提出了一种名为 iw-SFT 的新方法，在大型语言模型和控制策略训练方面取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 为了改进行为克隆（BC）在监督微调（SFT）和模仿学习中的表现，并借鉴强化学习（RL）的理论和实践，提出一种新的训练方法。

Method: 提出了一种名为 iw-SFT 的重要性加权监督微调方法，该方法是对现有行为克隆（BC）范式的改进，并通过最大化强化学习（RL）目标的下界来解释其有效性。

Result: iw-SFT 在大型语言模型和连续控制任务的策略训练中表现出色，与高级 RL 算法具有竞争力，并在 AIME 2024 数据集上达到了 66.7% 的准确率。

Conclusion: iw-SFT 是一种有效的监督微调方法，其性能可与更高级的强化学习算法相媲美，并且易于实现和推广。

Abstract: Behavior Cloning (BC) on curated (or filtered) data is the predominant
paradigm for supervised fine-tuning (SFT) of large language models; as well as
for imitation learning of control policies. Here, we draw on a connection
between this successful strategy and the theory and practice of finding optimal
policies via Reinforcement Learning (RL). Building on existing literature, we
clarify that SFT can be understood as maximizing a lower bound on the RL
objective in a sparse reward setting. Giving support to its often observed good
performance. From this viewpoint, we realize that a small modification to SFT
leads to an importance weighted variant that behaves closer to training with RL
as it: i) optimizes a tighter bound to the RL objective and, ii) can improve
performance compared to SFT on curated data. We refer to this variant as
importance weighted supervised fine-tuning (iw-SFT). We show that it is easy to
implement and can be further generalized to training with quality scored data.
The resulting SFT variants are competitive with more advanced RL algorithms for
large language models and for training policies in continuous control tasks.
For example achieving 66.7% on the AIME 2024 dataset.

</details>


### [158] [An Investigation of Ear-EEG Signals for a Novel Biometric Authentication System](https://arxiv.org/abs/2507.12873)
*Danilo Avola,Giancarlo Crocetti,Gian Luca Foresti,Daniele Pannone,Claudio Piciarelli,Amedeo Ranaldi*

Main category: cs.LG

TL;DR: 研究表明，使用耳内脑电图信号进行生物识别认证是一种可行且用户友好的方法，准确率可达 82%。


<details>
  <summary>Details</summary>
Motivation: 传统基于脑电图的生物识别系统虽然安全，但由于头皮电极设置笨重，可用性通常很低。本研究旨在提出一个新颖且实用的框架，利用耳内脑电图信号作为用户友好的日常生物识别认证替代方案。

Method: 提出了一种利用耳内脑电图信号的框架，从中提取时间域和频域特征，并将其输入全连接的深度神经网络以进行用户识别。

Result: 在目前唯一可用于生物识别认证的耳内脑电图数据集上进行的实验结果显示出有希望的性能，在用户识别场景中的平均准确率为 82%。

Conclusion: 这项工作证明了使用耳戴式设备（通常称为耳内脑电图）采集的脑电图（EEG）信号进行生物识别认证的可行性，为下一代真实世界生物识别系统提供了一个可行且可部署的方向。

Abstract: This work explores the feasibility of biometric authentication using EEG
signals acquired through in-ear devices, commonly referred to as ear-EEG.
Traditional EEG-based biometric systems, while secure, often suffer from low
usability due to cumbersome scalp-based electrode setups. In this study, we
propose a novel and practical framework leveraging ear-EEG signals as a
user-friendly alternative for everyday biometric authentication. The system
extracts an original combination of temporal and spectral features from ear-EEG
signals and feeds them into a fully connected deep neural network for subject
identification. Experimental results on the only currently available ear-EEG
dataset suitable for different purposes, including biometric authentication,
demonstrate promising performance, with an average accuracy of 82\% in a
subject identification scenario. These findings confirm the potential of
ear-EEG as a viable and deployable direction for next-generation real-world
biometric systems.

</details>


### [159] [Generalist Bimanual Manipulation via Foundation Video Diffusion Models](https://arxiv.org/abs/2507.12898)
*Yao Feng,Hengkai Tan,Xinyi Mao,Guodong Liu,Shuhe Huang,Chendong Xiang,Hang Su,Jun Zhu*

Main category: cs.LG

TL;DR: VIDAR是一个创新的双臂机器人操作框架，利用视频预训练和掩码逆动力学模型，克服数据稀疏和具身异构性问题，实现了出色的泛化能力和效率。


<details>
  <summary>Details</summary>
Motivation: 为了克服双臂机器人操作中数据稀疏和具身异构性带来的挑战，实现更广泛的应用。

Method: VIDAR是一个两阶段框架，包括基于扩散的视频预训练和掩码逆动力学模型，用于动作预测。

Result: VIDAR仅用20分钟的人类演示，在未知的机器人平台上就实现了对新任务和新背景的泛化，并且具有强大的语义理解能力，性能优于现有方法。

Conclusion: VIDAR通过结合视频基础模型和掩码动作预测，展示了在多样化真实世界场景中实现可扩展和可泛化的机器人操作的潜力。

Abstract: Bimanual robotic manipulation, which involves the coordinated control of two
robotic arms, is foundational for solving challenging tasks. Despite recent
progress in general-purpose manipulation, data scarcity and embodiment
heterogeneity remain serious obstacles to further scaling up in bimanual
settings. In this paper, we introduce VIdeo Diffusion for Action Reasoning
(VIDAR), a two-stage framework that leverages large-scale, diffusion-based
video pre-training and a novel masked inverse dynamics model for action
prediction. We pre-train the video diffusion model on 750K multi-view videos
from three real-world bimanual robot platforms, utilizing a unified observation
space that encodes robot, camera, task, and scene contexts. Our masked inverse
dynamics model learns masks to extract action-relevant information from
generated trajectories without requiring pixel-level labels, and the masks can
effectively generalize to unseen backgrounds. Our experiments demonstrate that
with only 20 minutes of human demonstrations on an unseen robot platform (only
1% of typical data requirements), VIDAR generalizes to unseen tasks and
backgrounds with strong semantic understanding, surpassing state-of-the-art
methods. Our findings highlight the potential of video foundation models,
coupled with masked action prediction, to enable scalable and generalizable
robotic manipulation in diverse real-world settings.

</details>


### [160] [Learning to Reject Low-Quality Explanations via User Feedback](https://arxiv.org/abs/2507.12900)
*Luca Stradiotti,Dario Pesenti,Stefano Teso,Jesse Davis*

Main category: cs.LG

TL;DR: ML models in high-stakes areas need trustworthy explanations. We present LtX, a framework where models can reject predictions with poor explanations. Our method, ULER, uses human feedback to learn to identify and reject bad explanations, outperforming existing approaches.


<details>
  <summary>Details</summary>
Motivation: Machine Learning predictors are increasingly being employed in high-stakes applications, but explanations for their predictions are not always high quality, leading to difficulties in interpretation, belief, trust assessment, and downstream decision-making. Classifiers should have the option to refuse handling inputs whose predictions cannot be explained properly.

Method: We introduce a framework for learning to reject low-quality explanations (LtX) in which predictors are equipped with a rejector that evaluates the quality of explanations. We introduce ULER (User-centric Low-quality Explanation Rejector), which learns a simple rejector from human ratings and per-feature relevance judgments to mirror human judgments of explanation quality.

Result: ULER outperforms both state-of-the-art and explanation-aware learning to reject strategies at LtX on eight classification and regression benchmarks and on a new human-annotated dataset.

Conclusion: We introduce ULER, a framework for learning to reject low-quality explanations (LtX) that equips predictors with a rejector to evaluate explanation quality. ULER learns a simple rejector from human ratings and per-feature relevance judgments to mirror human judgments of explanation quality. Experiments show that ULER outperforms state-of-the-art and explanation-aware learning to reject strategies on eight classification and regression benchmarks and a new human-annotated dataset.

Abstract: Machine Learning predictors are increasingly being employed in high-stakes
applications such as credit scoring. Explanations help users unpack the reasons
behind their predictions, but are not always "high quality''. That is,
end-users may have difficulty interpreting or believing them, which can
complicate trust assessment and downstream decision-making. We argue that
classifiers should have the option to refuse handling inputs whose predictions
cannot be explained properly and introduce a framework for learning to reject
low-quality explanations (LtX) in which predictors are equipped with a rejector
that evaluates the quality of explanations. In this problem setting, the key
challenges are how to properly define and assess explanation quality and how to
design a suitable rejector. Focusing on popular attribution techniques, we
introduce ULER (User-centric Low-quality Explanation Rejector), which learns a
simple rejector from human ratings and per-feature relevance judgments to
mirror human judgments of explanation quality. Our experiments show that ULER
outperforms both state-of-the-art and explanation-aware learning to reject
strategies at LtX on eight classification and regression benchmarks and on a
new human-annotated dataset, which we will publicly release to support future
research.

</details>


### [161] [Fremer: Lightweight and Effective Frequency Transformer for Workload Forecasting in Cloud Services](https://arxiv.org/abs/2507.12908)
*Jiadong Chen,Hengyu Ye,Fuxin Jiang,Xiao He,Tieying Zhang,Jianjun Chen,Xiaofeng Gao*

Main category: cs.LG

TL;DR: "Fremer"是一种在云工作负载预测方面高效且准确的深度学习模型，优于现有模型，并能在实际应用中提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的预测模型在计算效率方面无法满足大规模云环境的严格要求，而工作负载序列通常具有复杂的周期性模式。

Method: 提出了一种名为"Fremer"的深度预测模型，该模型在频域中处理复杂周期性模式，以提高计算效率和预测准确性。

Result: "Fremer"在预测准确性方面超越了所有最先进的模型，并且在参数规模和计算成本方面表现出更高的效率。在真实世界的自动扩展测试中，"Fremer"将平均延迟提高了18.78%，并将资源消耗降低了2.35%。

Conclusion: "Fremer"在云服务工作负载预测方面展现出卓越的效率和准确性，超越了现有的Transformer模型和最先进的模型，并在真实世界的自动扩展场景中提高了性能并降低了资源消耗。

Abstract: Workload forecasting is pivotal in cloud service applications, such as
auto-scaling and scheduling, with profound implications for operational
efficiency. Although Transformer-based forecasting models have demonstrated
remarkable success in general tasks, their computational efficiency often falls
short of the stringent requirements in large-scale cloud environments. Given
that most workload series exhibit complicated periodic patterns, addressing
these challenges in the frequency domain offers substantial advantages. To this
end, we propose Fremer, an efficient and effective deep forecasting model.
Fremer fulfills three critical requirements: it demonstrates superior
efficiency, outperforming most Transformer-based forecasting models; it
achieves exceptional accuracy, surpassing all state-of-the-art (SOTA) models in
workload forecasting; and it exhibits robust performance for multi-period
series. Furthermore, we collect and open-source four high-quality, open-source
workload datasets derived from ByteDance's cloud services, encompassing
workload data from thousands of computing instances. Extensive experiments on
both our proprietary datasets and public benchmarks demonstrate that Fremer
consistently outperforms baseline models, achieving average improvements of
5.5% in MSE, 4.7% in MAE, and 8.6% in SMAPE over SOTA models, while
simultaneously reducing parameter scale and computational costs. Additionally,
in a proactive auto-scaling test based on Kubernetes, Fremer improves average
latency by 18.78% and reduces resource consumption by 2.35%, underscoring its
practical efficacy in real-world applications.

</details>


### [162] [Robust Explanations Through Uncertainty Decomposition: A Path to Trustworthier AI](https://arxiv.org/abs/2507.12913)
*Chenrui Zhu,Louenas Bounia,Vu Linh Nguyen,Sébastien Destercke,Arthur Hoarau*

Main category: cs.LG

TL;DR: 提出一种基于预测不确定性的可解释性方法，通过区分aleatoric和epistemic不确定性来选择和改进解释，提高了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着模型复杂度增加，模型的可解释性下降，需要新的方法来提高模型预测的透明度。

Method: 提出利用预测不确定性作为经典可解释性方法的补充方法，区分aleatoric（数据相关）和epistemic（模型相关）不确定性来指导选择合适的解释。

Result: 实验证明，该不确定性感知方法提高了可解释性方法在传统机器学习和深度学习场景下的鲁棒性和可实现性。

Conclusion: 通过区分aleatoric（数据相关）和epistemic（模型相关）不确定性，可以指导选择适当的解释方法，其中epistemic不确定性可作为不可靠解释的拒绝标准，aleatoric不确定性可指导在特征重要性解释和反事实解释之间进行选择。该方法通过不确定性量化和分离的框架，增强了可解释性方法在传统机器学习和深度学习场景下的鲁棒性和可实现性。

Abstract: Recent advancements in machine learning have emphasized the need for
transparency in model predictions, particularly as interpretability diminishes
when using increasingly complex architectures. In this paper, we propose
leveraging prediction uncertainty as a complementary approach to classical
explainability methods. Specifically, we distinguish between aleatoric
(data-related) and epistemic (model-related) uncertainty to guide the selection
of appropriate explanations. Epistemic uncertainty serves as a rejection
criterion for unreliable explanations and, in itself, provides insight into
insufficient training (a new form of explanation). Aleatoric uncertainty
informs the choice between feature-importance explanations and counterfactual
explanations. This leverages a framework of explainability methods driven by
uncertainty quantification and disentanglement. Our experiments demonstrate the
impact of this uncertainty-aware approach on the robustness and attainability
of explanations in both traditional machine learning and deep learning
scenarios.

</details>


### [163] [Trace Reconstruction with Language Models](https://arxiv.org/abs/2507.12927)
*Franziska Weindel,Michael Girsch,Reinhard Heckel*

Main category: cs.LG

TL;DR: TReconLM 是一种利用语言模型进行追溯重建的新方法，可在 DNA 数据存储等应用中更有效地从噪声副本中恢复原始序列。


<details>
  <summary>Details</summary>
Motivation: 追溯重建问题旨在从包含删除、插入和替换的噪声副本中恢复原始序列。该问题出现在 DNA 数据存储等应用中，这是由于 DNA 存储具有高信息密度和长寿命，但 DNA 合成、存储和测序过程中引入的错误需要通过算法和代码进行纠正，而追溯重建通常是数据检索过程的一部分。

Method: 提出了一种利用基于下一个标记预测训练的语言模型来解决追溯重建问题的方法（TReconLM）。在合成数据上预训练语言模型，并在真实数据上进行微调，以适应特定技术的错误模式。

Result: TReconLM 克服了当前追溯重建算法的局限性，能够更有效地从损坏的数据中恢复原始序列，特别是在 DNA 数据存储等应用中。

Conclusion: TReconLM 优于最先进的追溯重建算法，包括先前深度学习方法，在没有错误的情况下恢复了更高比例的序列。

Abstract: The general trace reconstruction problem seeks to recover an original
sequence from its noisy copies independently corrupted by deletions,
insertions, and substitutions. This problem arises in applications such as DNA
data storage, a promising storage medium due to its high information density
and longevity. However, errors introduced during DNA synthesis, storage, and
sequencing require correction through algorithms and codes, with trace
reconstruction often used as part of the data retrieval process. In this work,
we propose TReconLM, which leverages language models trained on next-token
prediction for trace reconstruction. We pretrain language models on synthetic
data and fine-tune on real-world data to adapt to technology-specific error
patterns. TReconLM outperforms state-of-the-art trace reconstruction
algorithms, including prior deep learning approaches, recovering a
substantially higher fraction of sequences without error.

</details>


### [164] [From a Mixed-Policy Perspective: Improving Differentiable Automatic Post-editing Optimization](https://arxiv.org/abs/2507.12931)
*Hongze Tan*

Main category: cs.LG

TL;DR: 本文提出了对DAPO算法的两种改进：引入预训练的指导策略以提高训练稳定性和收敛速度，以及重新利用零奖励样本以提高样本效率。


<details>
  <summary>Details</summary>
Motivation: 标准策略梯度方法在稀疏奖励设置下可能存在不稳定性与样本效率低下的问题。

Method: 本文提出了两种新颖的Differentiable Automatic Post-editing Optimization (DAPO)算法的改进方法：1. 引入预训练的、稳定的指导策略($\piphi$)来提供离策略经验，从而规范目标策略($\pion$)的训练，并通过自适应调整学习步长来提高训练稳定性和收敛速度。2. 扩展此思路以重新利用零奖励样本，将这些样本视为由专家策略指导的独立批次，以进一步提高样本效率。

Result: 理论分析表明，所提出的两种方法的优化目标函数在其强化学习的理论框架内收敛于最优解。

Conclusion: 该混合策略框架有效平衡了探索与利用，有望实现更稳定、更高效的策略优化。

Abstract: This paper introduces two novel modifications to the Differentiable Automatic
Post-editing Optimization (DAPO) algorithm, approached from a mixed-policy
perspective. Standard policy gradient methods can suffer from instability and
sample inefficiency, particularly in sparse reward settings. To address this,
we first propose a method that incorporates a pre-trained, stable guiding
policy ($\piphi$) to provide off-policy experience, thereby regularizing the
training of the target policy ($\pion$). This approach improves training
stability and convergence speed by adaptively adjusting the learning step size.
Secondly, we extend this idea to re-utilize zero-reward samples, which are
often discarded by dynamic sampling strategies like DAPO's. By treating these
samples as a distinct batch guided by the expert policy, we further enhance
sample efficiency. We provide a theoretical analysis for both methods,
demonstrating that their objective functions converge to the optimal solution
within the established theoretical framework of reinforcement learning. The
proposed mixed-policy framework effectively balances exploration and
exploitation, promising more stable and efficient policy optimization.

</details>


### [165] [Probabilistic Soundness Guarantees in LLM Reasoning Chains](https://arxiv.org/abs/2507.12948)
*Weiqiu You,Anton Xue,Shreya Havaldar,Delip Rao,Helen Jin,Chris Callison-Burch,Eric Wong*

Main category: cs.LG

TL;DR: ARES 是一种新的概率框架，通过防止错误传播来提高 LLM 推理的可靠性，并在基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的基于LLM的错误检测方法通常无法检测到传播的错误，因为它们没有适当地考虑早期错误如何可能破坏对下游推理的判断。为了更好地检测这些传播的错误，我们引入了ARES。

Method: ARES（自回归推理蕴涵稳定性）是一个概率框架，通过仅根据先前评估的可靠前提来判断每个声明来防止错误传播。它为每个步骤产生一个细微的分数，并提供其可靠性的认证统计保证，而不是一个脆弱的二元标签。

Result: ARES 在四个基准测试上实现了最先进的性能（72.1% Macro-F1，+8.2点），并在非常长的合成推理链上展示了卓越的鲁棒性，在检测传播错误方面表现出色（90.3% F1，+27.6点）。

Conclusion: ARES 是一种新颖的概率框架，通过仅根据先前评估的可靠前提来判断每个声明，从而防止错误传播，并在合成推理链上展示了优越的鲁棒性，在检测传播错误方面表现出色。

Abstract: In reasoning chains generated by large language models (LLMs), initial errors
often propagate and undermine the reliability of the final conclusion. Current
LLM-based error detection methods often fail to detect propagated errors
because they do not properly account for how earlier errors might corrupt
judgments of downstream reasoning. To better detect such propagated errors, we
introduce Autoregressive Reasoning Entailment Stability (ARES), a novel
probabilistic framework that prevents error propagation by judging each claim
based only on previously-assessed sound premises. This inductive method yields
a nuanced score for each step and provides certified statistical guarantees of
its soundness, rather than a brittle binary label. ARES achieves
state-of-the-art performance across four benchmarks (72.1% Macro-F1, +8.2
points) and demonstrates superior robustness on very long synthetic reasoning
chains, where it excels at detecting propagated errors (90.3% F1, +27.6
points).

</details>


### [166] [Insights into a radiology-specialised multimodal large language model with sparse autoencoders](https://arxiv.org/abs/2507.12950)
*Kenza Bouzid,Shruthi Bannur,Daniel Coelho de Castro,Anton Schwaighofer,Javier Alvarez-Valle,Stephanie L. Hyland*

Main category: cs.LG

TL;DR: 本研究使用Matryoshka-SAE解释了放射学大语言模型MAIRA-2，识别了临床概念，并尝试引导模型行为，为理解和提高模型透明度迈出了第一步。


<details>
  <summary>Details</summary>
Motivation: 为了提高AI模型（尤其是在医疗保健领域）的安全性、透明度和可信度，本研究旨在通过稀疏自编码器（SAE）等机制可解释性方法来揭示大型Transformer模型中的人类可解释特征。

Method: 本研究将Matryoshka-SAE应用于MAIRA-2模型，并通过大规模自动化解释SAE特征来识别临床相关概念，进而通过引导来研究这些特征对模型行为的影响。

Result: 研究识别了MAIRA-2模型中的临床概念，如医疗设备、病理学变化和文本特征，并通过引导实验初步展示了对模型生成的可控性，但也指出了实践和方法上的挑战。

Conclusion: 该研究为理解和解释放射学领域的多模态大语言模型MAIRA-2提供了初步见解，并展示了其在提高模型透明度方面的潜力。

Abstract: Interpretability can improve the safety, transparency and trust of AI models,
which is especially important in healthcare applications where decisions often
carry significant consequences. Mechanistic interpretability, particularly
through the use of sparse autoencoders (SAEs), offers a promising approach for
uncovering human-interpretable features within large transformer-based models.
In this study, we apply Matryoshka-SAE to the radiology-specialised multimodal
large language model, MAIRA-2, to interpret its internal representations. Using
large-scale automated interpretability of the SAE features, we identify a range
of clinically relevant concepts - including medical devices (e.g., line and
tube placements, pacemaker presence), pathologies such as pleural effusion and
cardiomegaly, longitudinal changes and textual features. We further examine the
influence of these features on model behaviour through steering, demonstrating
directional control over generations with mixed success. Our results reveal
practical and methodological challenges, yet they offer initial insights into
the internal concepts learned by MAIRA-2 - marking a step toward deeper
mechanistic understanding and interpretability of a radiology-adapted
multimodal large language model, and paving the way for improved model
transparency. We release the trained SAEs and interpretations:
https://huggingface.co/microsoft/maira-2-sae.

</details>


### [167] [A Spectral Interpretation of Redundancy in a Graph Reservoir](https://arxiv.org/abs/2507.12963)
*Anna Bison,Alessandro Sperduti*

Main category: cs.LG

TL;DR: 提出了一种新的图神经网络（MRGNN）变体，利用平滑算法解决了过平滑问题，并通过随机游走理论进行了分析。


<details>
  <summary>Details</summary>
Motivation: 为了解决图神经网络（GNNs）在图上重复应用层算子时出现的过平滑问题，即图信号收敛到图拉普拉斯的低频分量。

Method: 提出了一种基于计算机图形学中平滑算法的MRGNN变体，该算法提供了一种通带频谱滤波器，可以在不收缩的情况下进行平滑处理，并可以通过拉普拉斯算子适应图设置。

Result: 通过理论分析和实验表明，该方法可以有效控制平滑，并为图分类等任务提供了新的方向。

Conclusion: 该方法通过调整频谱系数来调节冗余随机游走的贡献，并在MRGNN架构上进行了实验，显示了其潜力。

Abstract: Reservoir computing has been successfully applied to graphs as a
preprocessing method to improve the training efficiency of Graph Neural
Networks (GNNs). However, a common issue that arises when repeatedly applying
layer operators on graphs is over-smoothing, which consists in the convergence
of graph signals toward low-frequency components of the graph Laplacian. This
work revisits the definition of the reservoir in the Multiresolution Reservoir
Graph Neural Network (MRGNN), a spectral reservoir model, and proposes a
variant based on a Fairing algorithm originally introduced in the field of
surface design in computer graphics. This algorithm provides a pass-band
spectral filter that allows smoothing without shrinkage, and it can be adapted
to the graph setting through the Laplacian operator. Given its spectral
formulation, this method naturally connects to GNN architectures for tasks
where smoothing, when properly controlled, can be beneficial,such as graph
classification. The core contribution of the paper lies in the theoretical
analysis of the algorithm from a random walks perspective. In particular, it
shows how tuning the spectral coefficients can be interpreted as modulating the
contribution of redundant random walks. Exploratory experiments based on the
MRGNN architecture illustrate the potential of this approach and suggest
promising directions for future research.

</details>


### [168] [WaveletInception Networks for Drive-by Vibration-Based Infrastructure Health Monitoring](https://arxiv.org/abs/2507.12969)
*Reza Riahi Samani,Alfredo Nunez,Bart De Schutter*

Main category: cs.LG

TL;DR: 提出了一种基于WaveletInception-BiLSTM网络的深度学习框架，用于分析驾驶式振动信号以进行基础设施健康监测，并在铁路轨道刚度估计方面取得了优于现有方法的成果。


<details>
  <summary>Details</summary>
Motivation: 认识到光谱和时间信息的重要性，提出了一种用于基础设施健康监测的深度学习框架，该框架可以处理驾驶式振动响应信号。

Method: 提出了一种新颖的深度学习框架，利用了WaveletInception-BiLSTM网络。该网络包含一个Learnable Wavelet Packet Transform（LWPT）用于提取振动信号特征，并结合了一维Inception网络来提取多尺度高层特征。提取的特征与操作条件相结合，并通过双向长短期记忆（BiLSTM）网络来捕捉时间依赖关系，从而实现对基础设施健康状况的评估。

Result: 通过模拟的驾驶式振动信号对铁路轨道刚度进行估计的案例研究表明，该模型在估计铁路道砟和扣件刚度参数方面显著优于现有技术。

Conclusion: 该模型在铁路道砟和扣件刚度参数估计方面显著优于最先进的方法，展示了其在准确、局部和全自动驾驶式基础设施健康监测方面的潜力。

Abstract: This paper presents a novel deep learning-based framework for infrastructure
health monitoring using drive-by vibration response signals. Recognizing the
importance of spectral and temporal information, we introduce the
WaveletInception-BiLSTM network. The WaveletInception feature extractor
utilizes a Learnable Wavelet Packet Transform (LWPT) as the stem for extracting
vibration signal features, incorporating spectral information in the early
network layers. This is followed by 1D Inception networks that extract
multi-scale, high-level features at deeper layers. The extracted vibration
signal features are then integrated with operational conditions via a Long
Short-term Memory (LSTM) layer. The resulting feature extraction network
effectively analyzes drive-by vibration signals across various measurement
speeds without preprocessing and uses LSTM to capture interrelated temporal
dependencies among different modes of information and to create feature vectors
for health condition estimation. The estimator head is designed with a
sequential modeling architecture using bidirectional LSTM (BiLSTM) networks,
capturing bi-directional temporal relationships from drive-by measurements.
This architecture allows for a high-resolution, beam-level assessment of
infrastructure health conditions. A case study focusing on railway track
stiffness estimation with simulated drive-by vibration signals shows that the
model significantly outperforms state-of-the-art methods in estimating railway
ballast and railpad stiffness parameters. Results underscore the potential of
this approach for accurate, localized, and fully automated drive-by
infrastructure health monitoring.

</details>


### [169] [A Distributed Generative AI Approach for Heterogeneous Multi-Domain Environments under Data Sharing constraints](https://arxiv.org/abs/2507.12979)
*Youssef Tawfilis,Hossam Amer,Minar El-Aasser,Tallal Elshabrawy*

Main category: cs.LG

TL;DR: 提出了一种去中心化 GAN 训练方法，通过结合联邦学习和分割学习，在不共享原始数据的情况下，有效利用了分布式数据和低能力设备，并在图像生成和分类任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决在现实世界中训练生成模型（特别是 GAN）时，由于数据隐私、版权限制以及许多低能力设备（如物联网和边缘设备）的闲置而导致的大型数据集和计算资源难以获取的问题。

Method: 本研究提出了一种去中心化 GAN 训练方法，结合了 KLD 加权聚类联邦学习和异构 U 型分割学习。

Result: 实验结果表明，该方法在图像生成方面提高了 1.1-2.2 倍，在分类指标方面平均提高了 10%（在多域非独立同分布设置下最高可达 50%），并且延迟显著降低。

Conclusion: 本研究提出了一种新颖的去中心化 GAN 训练方法，结合了 KLD 加权聚类联邦学习和异构 U 型分割学习，解决了数据异构性和设备异构性问题，同时满足严格的数据共享限制。

Abstract: Federated Learning has gained increasing attention for its ability to enable
multiple nodes to collaboratively train machine learning models without sharing
their raw data. At the same time, Generative AI -- particularly Generative
Adversarial Networks (GANs) -- have achieved remarkable success across a wide
range of domains, such as healthcare, security, and Image Generation. However,
training generative models typically requires large datasets and significant
computational resources, which are often unavailable in real-world settings.
Acquiring such resources can be costly and inefficient, especially when many
underutilized devices -- such as IoT devices and edge devices -- with varying
capabilities remain idle. Moreover, obtaining large datasets is challenging due
to privacy concerns and copyright restrictions, as most devices are unwilling
to share their data. To address these challenges, we propose a novel approach
for decentralized GAN training that enables the utilization of distributed data
and underutilized, low-capability devices while not sharing data in its raw
form. Our approach is designed to tackle key challenges in decentralized
environments, combining KLD-weighted Clustered Federated Learning to address
the issues of data heterogeneity and multi-domain datasets, with Heterogeneous
U-Shaped split learning to tackle the challenge of device heterogeneity under
strict data sharing constraints -- ensuring that no labels or raw data, whether
real or synthetic, are ever shared between nodes. Experimental results shows
that our approach demonstrates consistent and significant improvements across
key performance metrics, where it achieves 1.1x -- 2.2x higher image generation
scores, an average 10% boost in classification metrics (up to 50% in
multi-domain non-IID settings), in much lower latency compared to several
benchmarks. Find our code at https://github.com/youssefga28/HuSCF-GAN.

</details>


### [170] [Teach Old SAEs New Domain Tricks with Boosting](https://arxiv.org/abs/2507.12990)
*Nikita Koriagin,Yaroslav Aksenov,Daniil Laptev,Gleb Gerasimov,Nikita Balagansky,Daniil Gavrilov*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Sparse Autoencoders have emerged as powerful tools for interpreting the
internal representations of Large Language Models, yet they often fail to
capture domain-specific features not prevalent in their training corpora. This
paper introduces a residual learning approach that addresses this feature
blindness without requiring complete retraining. We propose training a
secondary SAE specifically to model the reconstruction error of a pretrained
SAE on domain-specific texts, effectively capturing features missed by the
primary model. By summing the outputs of both models during inference, we
demonstrate significant improvements in both LLM cross-entropy and explained
variance metrics across multiple specialized domains. Our experiments show that
this method efficiently incorporates new domain knowledge into existing SAEs
while maintaining their performance on general tasks. This approach enables
researchers to selectively enhance SAE interpretability for specific domains of
interest, opening new possibilities for targeted mechanistic interpretability
of LLMs.

</details>


### [171] [SMART: Relation-Aware Learning of Geometric Representations for Knowledge Graphs](https://arxiv.org/abs/2507.13001)
*Kossi Amouzouvi,Bowen Song,Andrea Coletta,Luigi Bellomarini,Jens Lehmann,Sahar Vahdati*

Main category: cs.LG

TL;DR: 本研究提出了一种新的知识图谱嵌入框架，通过为每个关系选择最匹配的几何变换来改进表示学习，并在多个基准测试中取得了与领先模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 知识图谱嵌入（KGE）模型通常将关系表示为几何变换，但现有的最先进模型主要依赖基础几何变换（EGTs）或其组合，未能充分考虑关系特定的变换需求。虽然已有模型尝试通过集成基线模型来解决此问题，但它们仅使用单一或复合的几何变换来表示所有关系。因此，本研究旨在提出一个能评估关系与不同几何变换匹配度的新框架，以改进KGE模型的性能。

Method: 本研究提出了一种新框架，通过评估每个关系与不同几何变换的匹配程度，并基于此为每个关系分配最佳匹配变换，或通过多数投票选择一种变换应用于所有关系。该模型利用注意力机制在低维向量空间中学习单一的关系特定EGT，并使用学习到的低维关系与EGTs之间的相关性来优化高维空间中的关系嵌入。

Result: 该框架通过在三个基准知识图谱和一个真实金融知识图谱上的综合评估，证明了其有效性。实验结果显示，该模型能够为每个关系分配最匹配的几何变换，或通过多数投票选择一种变换，并且利用低维关系-EGT相关性进行高维关系嵌入，其性能与当前领先模型相当。

Conclusion: 目前最先进的知识图谱嵌入（KGE）模型虽然能够有效地保留知识图谱的结构和关系模式，但它们主要依赖于基础几何变换（EGTs）或其组合，并且在处理关系特定的变换方面仍有不足。本研究提出的框架通过评估每个关系与不同几何变换的匹配程度，实现了为每个关系分配最佳匹配变换或通过多数投票选择统一变换。此外，利用低维空间中学习到的关系与EGTs之间的相关性来提升高维空间中的关系嵌入表示。该模型在多个基准知识图谱和真实金融知识图谱上的实验证明了其有效性，性能与领先模型相当。

Abstract: Knowledge graph representation learning approaches provide a mapping between
symbolic knowledge in the form of triples in a knowledge graph (KG) and their
feature vectors. Knowledge graph embedding (KGE) models often represent
relations in a KG as geometric transformations. Most state-of-the-art (SOTA)
KGE models are derived from elementary geometric transformations (EGTs), such
as translation, scaling, rotation, and reflection, or their combinations. These
geometric transformations enable the models to effectively preserve specific
structural and relational patterns of the KG. However, the current use of EGTs
by KGEs remains insufficient without considering relation-specific
transformations. Although recent models attempted to address this problem by
ensembling SOTA baseline models in different ways, only a single or composite
version of geometric transformations are used by such baselines to represent
all the relations. In this paper, we propose a framework that evaluates how
well each relation fits with different geometric transformations. Based on this
ranking, the model can: (1) assign the best-matching transformation to each
relation, or (2) use majority voting to choose one transformation type to apply
across all relations. That is, the model learns a single relation-specific EGT
in low dimensional vector space through an attention mechanism. Furthermore, we
use the correlation between relations and EGTs, which are learned in a low
dimension, for relation embeddings in a high dimensional vector space. The
effectiveness of our models is demonstrated through comprehensive evaluations
on three benchmark KGs as well as a real-world financial KG, witnessing a
performance comparable to leading models

</details>


### [172] [Fault detection and diagnosis for the engine electrical system of a space launcher based on a temporal convolutional autoencoder and calibrated classifiers](https://arxiv.org/abs/2507.13022)
*Luis Basora,Louison Bocquet-Nouaille,Elinirina Robinson,Serge Le Gonidec*

Main category: cs.LG

TL;DR: 该研究提出了一种用于火箭发动机阀门控制系统的在轨故障检测和诊断方法，该方法基于时间卷积自编码器和梯度提升模型，并结合了异常检测和虚警控制技术。


<details>
  <summary>Details</summary>
Motivation: 为了满足可重用运载火箭的健康监测需求，需要开发一种用于发动机阀门控制电气系统的在轨故障检测和诊断能力。

Method: 该解决方案基于时间卷积自编码器提取传感器数据的低维特征，并使用基于直方图的梯度提升模型进行故障检测和诊断。通过使用归纳保形异常检测来识别OOD数据，并利用累积和控制图（CUSUM）和阈值移动来控制虚警和解决类别不平衡问题。

Result: 所提出的框架在模拟数据上进行了评估，结果表明该解决方案是一个有希望的初步方法。

Conclusion: 该框架是迈向实际应用的一个有希望的初步方法，但需要在实际数据上进行测试，以确保其达到运行成熟度。

Abstract: In the context of the health monitoring for the next generation of reusable
space launchers, we outline a first step toward developing an onboard fault
detection and diagnostic capability for the electrical system that controls the
engine valves. Unlike existing approaches in the literature, our solution is
designed to meet a broader range of key requirements. This includes estimating
confidence levels for predictions, detecting out-of-distribution (OOD) cases,
and controlling false alarms. The proposed solution is based on a temporal
convolutional autoencoder to automatically extract low-dimensional features
from raw sensor data. Fault detection and diagnosis are respectively carried
out using a binary and a multiclass classifier trained on the autoencoder
latent and residual spaces. The classifiers are histogram-based gradient
boosting models calibrated to output probabilities that can be interpreted as
confidence levels. A relatively simple technique, based on inductive conformal
anomaly detection, is used to identify OOD data. We leverage other simple yet
effective techniques, such as cumulative sum control chart (CUSUM) to limit the
false alarms, and threshold moving to address class imbalance in fault
detection. The proposed framework is highly configurable and has been evaluated
on simulated data, covering both nominal and anomalous operational scenarios.
The results indicate that our solution is a promising first step, though
testing with real data will be necessary to ensure that it achieves the
required maturity level for operational use.

</details>


### [173] [Confidence-Filtered Relevance (CFR): An Interpretable and Uncertainty-Aware Machine Learning Framework for Naturalness Assessment in Satellite Imagery](https://arxiv.org/abs/2507.13034)
*Ahmed Emam,Ribana Roscher*

Main category: cs.LG

TL;DR: CFR是一个数据中心框架，用于分析和评估卫星图像中自然性的相关性，同时考虑模型不确定性，以提高可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前使用卫星图像和机器学习监测保护区的现有方法通常缺乏可解释性和对不确定性的感知能力，并且没有解决不确定性如何影响自然性评估的问题。

Method: 本研究提出了一种名为置信度过滤相关性（CFR）的数据中心框架，该框架结合了LRP注意力展开和深度确定性不确定性（DDU）估计，以分析模型不确定性如何影响相关性热图的可解释性。CFR根据不确定性阈值将数据集划分为子集，从而能够系统地分析不确定性如何影响卫星图像中自然性的解释。

Result: 将CFR应用于AnthroProtect数据集，发现其将更高的相关性分配给灌木丛、森林和湿地，这与其他关于自然性评估的研究一致。此外，研究表明，随着不确定性的增加，这些相关性热图的可解释性会下降，熵会增加，表明其归因选择性降低且更加模糊。

Conclusion: CFR提供了一种以数据为中心的方法，根据相关模式的确定性来评估它们与自然相关性的相关性。

Abstract: Protected natural areas play a vital role in ecological balance and ecosystem
services. Monitoring these regions at scale using satellite imagery and machine
learning is promising, but current methods often lack interpretability and
uncertainty-awareness, and do not address how uncertainty affects naturalness
assessment. In contrast, we propose Confidence-Filtered Relevance (CFR), a
data-centric framework that combines LRP Attention Rollout with Deep
Deterministic Uncertainty (DDU) estimation to analyze how model uncertainty
influences the interpretability of relevance heatmaps. CFR partitions the
dataset into subsets based on uncertainty thresholds, enabling systematic
analysis of how uncertainty shapes the explanations of naturalness in satellite
imagery. Applied to the AnthroProtect dataset, CFR assigned higher relevance to
shrublands, forests, and wetlands, aligning with other research on naturalness
assessment. Moreover, our analysis shows that as uncertainty increases, the
interpretability of these relevance heatmaps declines and their entropy grows,
indicating less selective and more ambiguous attributions. CFR provides a
data-centric approach to assess the relevance of patterns to naturalness in
satellite imagery based on their associated certainty.

</details>


### [174] [Inverse Reinforcement Learning Meets Large Language Model Post-Training: Basics, Advances, and Opportunities](https://arxiv.org/abs/2507.13158)
*Hao Sun,Mihaela van der Schaar*

Main category: cs.LG

TL;DR: 本综述全面回顾了利用逆强化学习（IRL）实现大语言模型（LLM）对齐的最新进展，重点介绍了从人类数据构建神经奖励模型的必要性、方法论、实际应用和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的广泛应用，如何确保其可靠性、可控性和能力已成为一个核心挑战。强化学习（RL）在提升对话系统和推理模型方面展现了巨大潜力，因此，将RL应用于LLM对齐的研究引起了广泛关注。本综述旨在梳理和总结利用逆强化学习（IRL）实现LLM对齐的最新进展，为该领域的研究者提供一个清晰的视角。

Method: 本研究通过对近期大语言模型（LLM）对齐领域的文献进行全面回顾，特别是从逆强化学习（IRL）的角度进行审视，来分析和总结该领域的进展。文章首先介绍了强化学习（RL）的基本概念，然后深入探讨了RL在LLM对齐中的应用，并着重指出了与传统RL任务的区别，特别是构建神经奖励模型的必要性。研究还讨论了该领域面临的关键挑战、机遇，以及数据集、基准、评估指标、基础设施和高效训练/推理等实际问题。最后，通过借鉴稀疏奖励RL的经验，提出了未来研究方向。

Result: 本综述全面回顾了利用逆强化学习（IRL）实现大语言模型（LLM）对齐的最新进展，重点阐述了构建神经奖励模型的必要性及其带来的影响。文章讨论了该领域的方法论、实际应用（如数据集、基准、评估指标）以及计算效率等问题，并基于稀疏奖励强化学习提出了未来的研究方向和开放性问题。

Conclusion: 本综述旨在提供一个关于通过逆强化学习（IRL）实现大语言模型（LLM）对齐的全面概述，强调了从人类数据构建神经奖励模型的必要性，并探讨了这种范式转变的正式和实际意义。此外，它还讨论了数据集、基准、评估指标、基础设施以及计算效率方面的实际考虑因素，并从稀疏奖励强化学习的角度提出了开放性问题和未来研究方向。

Abstract: In the era of Large Language Models (LLMs), alignment has emerged as a
fundamental yet challenging problem in the pursuit of more reliable,
controllable, and capable machine intelligence. The recent success of reasoning
models and conversational AI systems has underscored the critical role of
reinforcement learning (RL) in enhancing these systems, driving increased
research interest at the intersection of RL and LLM alignment. This paper
provides a comprehensive review of recent advances in LLM alignment through the
lens of inverse reinforcement learning (IRL), emphasizing the distinctions
between RL techniques employed in LLM alignment and those in conventional RL
tasks. In particular, we highlight the necessity of constructing neural reward
models from human data and discuss the formal and practical implications of
this paradigm shift. We begin by introducing fundamental concepts in RL to
provide a foundation for readers unfamiliar with the field. We then examine
recent advances in this research agenda, discussing key challenges and
opportunities in conducting IRL for LLM alignment. Beyond methodological
considerations, we explore practical aspects, including datasets, benchmarks,
evaluation metrics, infrastructure, and computationally efficient training and
inference techniques. Finally, we draw insights from the literature on
sparse-reward RL to identify open questions and potential research directions.
By synthesizing findings from diverse studies, we aim to provide a structured
and critical overview of the field, highlight unresolved challenges, and
outline promising future directions for improving LLM alignment through RL and
IRL techniques.

</details>


### [175] [The Power of Architecture: Deep Dive into Transformer Architectures for Long-Term Time Series Forecasting](https://arxiv.org/abs/2507.13043)
*Lefei Shen,Mouxiang Chen,Han Fu,Xiaoxue Ren,Xiaoyun Joy Wang,Jianling Sun,Zhuo Li,Chenghao Liu*

Main category: cs.LG

TL;DR: This paper introduces a new way to compare Transformer models for long-term time series forecasting (LTSF) by separating architecture from other design choices. They found that certain attention mechanisms, aggregation methods, and forecasting approaches work best. Their improved model outperforms existing ones, offering guidance for future research.


<details>
  <summary>Details</summary>
Motivation: To answer the question of which Transformer architecture is best for LTSF tasks by isolating the impact of the architecture itself, as existing models are tightly coupled with time-series-specific designs.

Method: A novel taxonomy is proposed to disentangle time-series-specific designs from Transformer architectures, enabling unified comparisons. Extensive experiments were conducted using this taxonomy.

Result: Bi-directional attention with joint-attention is most effective; more complete forecasting aggregation improves performance; and the direct-mapping paradigm outperforms autoregressive approaches. The combined model, utilizing optimal architectural choices, consistently outperforms several existing models.

Conclusion: Transformer-based models are effective for LTSF, with bi-directional attention and joint-attention, complete forecasting aggregation, and direct-mapping paradigm showing the most promise. The proposed taxonomy allows for clearer comparisons and the combined model outperforms existing ones.

Abstract: Transformer-based models have recently become dominant in Long-term Time
Series Forecasting (LTSF), yet the variations in their architecture, such as
encoder-only, encoder-decoder, and decoder-only designs, raise a crucial
question: What Transformer architecture works best for LTSF tasks? However,
existing models are often tightly coupled with various time-series-specific
designs, making it difficult to isolate the impact of the architecture itself.
To address this, we propose a novel taxonomy that disentangles these designs,
enabling clearer and more unified comparisons of Transformer architectures. Our
taxonomy considers key aspects such as attention mechanisms, forecasting
aggregations, forecasting paradigms, and normalization layers. Through
extensive experiments, we uncover several key insights: bi-directional
attention with joint-attention is most effective; more complete forecasting
aggregation improves performance; and the direct-mapping paradigm outperforms
autoregressive approaches. Furthermore, our combined model, utilizing optimal
architectural choices, consistently outperforms several existing models,
reinforcing the validity of our conclusions. We hope these findings offer
valuable guidance for future research on Transformer architectural designs in
LTSF. Our code is available at https://github.com/HALF111/TSF_architecture.

</details>


### [176] [On statistical learning of graphs](https://arxiv.org/abs/2507.13054)
*Vittorio Cipriani,Valentino Delle Rose,Luca San Mauro,Giovanni Solda*

Main category: cs.LG

TL;DR: 研究了图的拷贝（通过顶点置换诱导）的PAC和在线可学性，发现了PAC可学性与在线可学性及自同构平凡性之间的联系，并对无限图进行了分类。


<details>
  <summary>Details</summary>
Motivation: 研究PAC和在线可学性在图的拷贝（通过顶点置换诱导）中的应用，特别是与图的结构和标签集相关的学习问题。

Method: 通过研究由图的拷贝组成的假设类（通过顶点置换诱导）的PAC和在线可学性来分析。重点关注那些有限支撑的置换，并建立了PAC可学性与在线可学性以及自同构平凡性之间的等价关系。同时，通过放松无限随机图的扩张性质来刻画特定条件下不可学的图。最后，证明了k-顶点置换的可学性等价于2-顶点置换的可学性，并基于此将无限图划分为四类。

Result: PAC可学性与在线可学性之间的等价性，以及与图的自同构平凡性的关联。此外，还刻画了特定置换下不可学的图，并利用描述性集合论和可计算性理论将无限图划分为四类。

Conclusion: PAC可学性与在线可学性之间的等价性，以及与图的自同构平凡性的关联。此外，还刻画了特定置换下不可学的图，并利用描述性集合论和可计算性理论将无限图划分为四类。

Abstract: We study PAC and online learnability of hypothesis classes formed by copies
of a countably infinite graph G, where each copy is induced by permuting G's
vertices. This corresponds to learning a graph's labeling, knowing its
structure and label set. We consider classes where permutations move only
finitely many vertices. Our main result shows that PAC learnability of all such
finite-support copies implies online learnability of the full isomorphism type
of G, and is equivalent to the condition of automorphic triviality. We also
characterize graphs where copies induced by swapping two vertices are not
learnable, using a relaxation of the extension property of the infinite random
graph. Finally, we show that, for all G and k>2, learnability for k-vertex
permutations is equivalent to that for 2-vertex permutations, yielding a
four-class partition of infinite graphs, whose complexity we also determine
using tools coming from both descriptive set theory and computability theory.

</details>


### [177] [DASViT: Differentiable Architecture Search for Vision Transformer](https://arxiv.org/abs/2507.13079)
*Pengjin Wu,Ferrante Neri,Zhenhua Feng*

Main category: cs.LG

TL;DR: DASViT 是一种用于 Vision Transformer (ViT) 的可微分架构搜索方法，能够发现比现有 ViT-B/16 更优、更高效的新型架构设计。


<details>
  <summary>Details</summary>
Motivation: 现有的针对 ViT 的 NAS 方法主要关注宏观搜索空间，并依赖于进化算法等离散方法，这些方法在发现创新设计方面存在挑战，需要大量的计算资源且耗时。DASViT 旨在解决这些限制。

Method: 提出了一种名为 DASViT 的方法，用于对 Vision Transformer (ViT) 的架构进行可微分搜索，以发现创新的设计。

Result: DASViT 能够发现创新的 ViT 架构，这些架构在性能上超越了 ViT-B/16，并且在参数数量和计算量（FLOPs）方面更加高效。

Conclusion: DASViT 提供的架构打破了传统的 Transformer 编码器设计，在多个数据集上表现优于 ViT-B/16，并且通过更少的参数和 FLOPs 实现了更高的效率。

Abstract: Designing effective neural networks is a cornerstone of deep learning, and
Neural Architecture Search (NAS) has emerged as a powerful tool for automating
this process. Among the existing NAS approaches, Differentiable Architecture
Search (DARTS) has gained prominence for its efficiency and ease of use,
inspiring numerous advancements. Since the rise of Vision Transformers (ViT),
researchers have applied NAS to explore ViT architectures, often focusing on
macro-level search spaces and relying on discrete methods like evolutionary
algorithms. While these methods ensure reliability, they face challenges in
discovering innovative architectural designs, demand extensive computational
resources, and are time-intensive. To address these limitations, we introduce
Differentiable Architecture Search for Vision Transformer (DASViT), which
bridges the gap in differentiable search for ViTs and uncovers novel designs.
Experiments show that DASViT delivers architectures that break traditional
Transformer encoder designs, outperform ViT-B/16 on multiple datasets, and
achieve superior efficiency with fewer parameters and FLOPs.

</details>


### [178] [MUPAX: Multidimensional Problem Agnostic eXplainable AI](https://arxiv.org/abs/2507.13090)
*Vincenzo Dentamaro,Felice Franchini,Giuseppe Pirlo,Irina Voiculescu*

Main category: cs.LG

TL;DR: MUPAX 是一种新的 XAI 技术，它具有确定性、模型无关性和保证收敛性。它在各种维度的数据上都有效，并且可以提高模型准确性。


<details>
  <summary>Details</summary>
Motivation: 需要鲁棒的 XAI 技术，理想情况下应同时满足确定性、模型无关性和保证收敛性。

Method: MUPAX 是一种确定性的、模型无关的可解释性技术，具有保证的收敛性。MUPAX 的测度理论表述通过结构化扰动分析，对特征重要性进行原则性归因，该分析发现固有的输入模式并消除虚假关系。

Result: MUPAX 在广泛的数据模式和任务（音频分类（1D）、图像分类（2D）、体积医学图像分析（3D）和解剖标志物检测）上进行了评估，证明了其跨维度的有效性。严格的收敛保证扩展到任何损失函数和任意维度，使 MUPAX 几乎适用于任何 AI 的问题背景。

Conclusion: MUPAX 不仅能保留，还能通过捕获原始数据最重要的模式来提高模型准确性。与通常在遮蔽时性能下降的其他 XAI 方法相比，MUPAX 能够生成精确、一致且可理解的解释，这是实现可解释和可信赖 AI 系统的关键一步。

Abstract: Robust XAI techniques should ideally be simultaneously deterministic, model
agnostic, and guaranteed to converge. We propose MULTIDIMENSIONAL PROBLEM
AGNOSTIC EXPLAINABLE AI (MUPAX), a deterministic, model agnostic explainability
technique, with guaranteed convergency. MUPAX measure theoretic formulation
gives principled feature importance attribution through structured perturbation
analysis that discovers inherent input patterns and eliminates spurious
relationships. We evaluate MUPAX on an extensive range of data modalities and
tasks: audio classification (1D), image classification (2D), volumetric medical
image analysis (3D), and anatomical landmark detection, demonstrating dimension
agnostic effectiveness. The rigorous convergence guarantees extend to any loss
function and arbitrary dimensions, making MUPAX applicable to virtually any
problem context for AI. By contrast with other XAI methods that typically
decrease performance when masking, MUPAX not only preserves but actually
enhances model accuracy by capturing only the most important patterns of the
original data. Extensive benchmarking against the state of the XAI art
demonstrates MUPAX ability to generate precise, consistent and understandable
explanations, a crucial step towards explainable and trustworthy AI systems.
The source code will be released upon publication.

</details>


### [179] [Uncertainty-Aware Cross-Modal Knowledge Distillation with Prototype Learning for Multimodal Brain-Computer Interfaces](https://arxiv.org/abs/2507.13092)
*Hyo-Jeong Jang,Hye-Bin Shin,Seong-Whan Lee*

Main category: cs.LG

TL;DR: 提出了一种新的跨模态知识蒸馏框架，通过原型相似性和特定任务的蒸馏头来解决模态差距和软标签不对齐问题，以提高EEG信号的学习性能。


<details>
  <summary>Details</summary>
Motivation: 为了增强EEG学习，已经探索了利用视觉模型丰富的表示来转移知识的多模态知识蒸馏（KD）。然而，KD面临模态差距和软标签不对齐的挑战，这源于EEG和视觉特征空间的异质性以及标签不一致性。

Method: 提出了一种新颖的跨模态知识蒸馏框架，通过基于原型的相似性模块对齐特征语义，并引入特定任务的蒸馏头来解决标签引起的不一致性。

Result: 实验结果表明，该方法在EEG情感回归和分类方面表现优于单一模态和多模态基线。

Conclusion: 该框架在公共多模态数据集上改进了基于EEG的情感回归和分类性能，优于单一模态和多模态基线。

Abstract: Electroencephalography (EEG) is a fundamental modality for cognitive state
monitoring in brain-computer interfaces (BCIs). However, it is highly
susceptible to intrinsic signal errors and human-induced labeling errors, which
lead to label noise and ultimately degrade model performance. To enhance EEG
learning, multimodal knowledge distillation (KD) has been explored to transfer
knowledge from visual models with rich representations to EEG-based models.
Nevertheless, KD faces two key challenges: modality gap and soft label
misalignment. The former arises from the heterogeneous nature of EEG and visual
feature spaces, while the latter stems from label inconsistencies that create
discrepancies between ground truth labels and distillation targets. This paper
addresses semantic uncertainty caused by ambiguous features and weakly defined
labels. We propose a novel cross-modal knowledge distillation framework that
mitigates both modality and label inconsistencies. It aligns feature semantics
through a prototype-based similarity module and introduces a task-specific
distillation head to resolve label-induced inconsistency in supervision.
Experimental results demonstrate that our approach improves EEG-based emotion
regression and classification performance, outperforming both unimodal and
multimodal baselines on a public multimodal dataset. These findings highlight
the potential of our framework for BCI applications.

</details>


### [180] [NGTM: Substructure-based Neural Graph Topic Model for Interpretable Graph Generation](https://arxiv.org/abs/2507.13133)
*Yuanxin Zhuang,Dazhong Shen,Ying Sun*

Main category: cs.LG

TL;DR: NGTM 是一种新的神经图主题模型，它通过将图表示为潜在主题的混合体来提高图生成的可解释性。它在生成逼真图的同时，还能进行细粒度控制和解释，并能通过调整主题来控制结构特征或诱导生物学特性。


<details>
  <summary>Details</summary>
Motivation: 现有图生成方法在生成逼真图方面取得了相当大的成功，但其可解释性仍然有限，常常模糊了结构决策背后的基本原理。

Method: 提出了一种新颖的生成框架——神经图主题模型 (NGTM)，该框架受到自然语言处理中主题建模的启发。NGTM 将图表示为潜在主题的混合体，每个主题定义了在语义上有意义的子结构上的分布，从而在局部和全局尺度上促进了明确的可解释性。生成过程将这些主题分布与全局结构变量透明地集成，能够对生成的每个图进行清晰的语义追踪。

Result: 实验表明，NGTM 在实现可观的生成质量的同时，还提供了前所未有的细粒度控制和可解释性，允许用户通过主题级别的调整来控制结构特征或诱导生物学特性。

Conclusion: NGTM 在实现可观图生成质量的同时，还提供了前所未有的细粒度控制和可解释性，用户可以通过调整主题层来控制结构特征或诱导生物学特性。

Abstract: Graph generation plays a pivotal role across numerous domains, including
molecular design and knowledge graph construction. Although existing methods
achieve considerable success in generating realistic graphs, their
interpretability remains limited, often obscuring the rationale behind
structural decisions. To address this challenge, we propose the Neural Graph
Topic Model (NGTM), a novel generative framework inspired by topic modeling in
natural language processing. NGTM represents graphs as mixtures of latent
topics, each defining a distribution over semantically meaningful
substructures, which facilitates explicit interpretability at both local and
global scales. The generation process transparently integrates these topic
distributions with a global structural variable, enabling clear semantic
tracing of each generated graph. Experiments demonstrate that NGTM achieves
competitive generation quality while uniquely enabling fine-grained control and
interpretability, allowing users to tune structural features or induce
biological properties through topic-level adjustments.

</details>


### [181] [NonverbalTTS: A Public English Corpus of Text-Aligned Nonverbal Vocalizations with Emotion Annotations for Text-to-Speech](https://arxiv.org/abs/2507.13155)
*Maksim Borisov,Egor Spirin,Daria Diatlova*

Main category: cs.LG

TL;DR: 我们发布了一个名为 NVTTS 的新数据集，其中包含 17 小时、带注释的非语言声音和情感，可以改进语音合成。


<details>
  <summary>Details</summary>
Motivation: 当前富有表现力的语音合成模型受限于包含多样化非语言发声 (NV) 的开源数据集的有限可用性。

Method: 我们提出了一个集成了自动语音识别 (ASR)、非语言发声 (NV) 标签、情感分类和融合算法的综合流程，用于合并来自多个注释者的转录。数据来自 VoxCeleb 和 Expresso，并使用自动检测后进行人工验证。

Result: NVTTS 是一个包含 17 小时、注释有 10 种 NV（例如，笑声、咳嗽声）和 8 种情感类别的开放访问数据集。

Conclusion: 通过在 NVTTS 数据集上微调开源 TTS 模型，我们在说话人相似度和非语言发声保真度等指标上达到了与 CosyVoice2 等闭源系统相当的水平。通过发布 NVTTS 及其伴随的注释指南，我们解决了富有表现力的 TTS 研究中的一个关键瓶颈。

Abstract: Current expressive speech synthesis models are constrained by the limited
availability of open-source datasets containing diverse nonverbal vocalizations
(NVs). In this work, we introduce NonverbalTTS (NVTTS), a 17-hour open-access
dataset annotated with 10 types of NVs (e.g., laughter, coughs) and 8 emotional
categories. The dataset is derived from popular sources, VoxCeleb and Expresso,
using automated detection followed by human validation. We propose a
comprehensive pipeline that integrates automatic speech recognition (ASR), NV
tagging, emotion classification, and a fusion algorithm to merge transcriptions
from multiple annotators. Fine-tuning open-source text-to-speech (TTS) models
on the NVTTS dataset achieves parity with closed-source systems such as
CosyVoice2, as measured by both human evaluation and automatic metrics,
including speaker similarity and NV fidelity. By releasing NVTTS and its
accompanying annotation guidelines, we address a key bottleneck in expressive
TTS research. The dataset is available at
https://huggingface.co/datasets/deepvk/NonverbalTTS.

</details>


### [182] [Spectral Bellman Method: Unifying Representation and Exploration in RL](https://arxiv.org/abs/2507.13181)
*Ofir Nabati,Bo Dai,Shie Mannor,Guy Tennenholtz*

Main category: cs.LG

TL;DR: This paper introduces Spectral Bellman Representation, a new method for reinforcement learning that aligns feature learning with the underlying Bellman updates, improving performance on complex tasks by capturing the spectral relationship between value functions and feature covariance.


<details>
  <summary>Details</summary>
Motivation: Existing representation learning methods in reinforcement learning are mainly induced from model learning aspects, which misaligns with the fundamental structure of value-based RL tasks. The motivation is to develop a representation learning framework that is directly aligned with value-based RL.

Method: The paper introduces Spectral Bellman Representation, a novel framework derived from the Inherent Bellman Error (IBE) condition. This method utilizes a spectral connection between the transformation of value functions by the Bellman operator and the feature covariance structure under the zero-IBE condition to learn state-action features that capture Bellman-aligned covariance.

Result: The learned representations enable structured exploration by aligning feature covariance with Bellman dynamics and improve overall performance, especially in hard-exploration and long-horizon credit assignment tasks. The framework also extends to multi-step Bellman operators.

Conclusion: Spectral Bellman Representation provides a principled and effective approach to learning powerful and structurally sound representations for value-based reinforcement learning, aligning feature covariance with Bellman dynamics and improving performance on challenging tasks.

Abstract: The effect of representation has been demonstrated in reinforcement learning,
from both theoretical and empirical successes. However, the existing
representation learning mainly induced from model learning aspects, misaligning
with our RL tasks. This work introduces Spectral Bellman Representation, a
novel framework derived from the Inherent Bellman Error (IBE) condition, which
aligns with the fundamental structure of Bellman updates across a space of
possible value functions, therefore, directly towards value-based RL. Our key
insight is the discovery of a fundamental spectral relationship: under the
zero-IBE condition, the transformation of a distribution of value functions by
the Bellman operator is intrinsically linked to the feature covariance
structure. This spectral connection yields a new, theoretically-grounded
objective for learning state-action features that inherently capture this
Bellman-aligned covariance. Our method requires a simple modification to
existing algorithms. We demonstrate that our learned representations enable
structured exploration, by aligning feature covariance with Bellman dynamics,
and improve overall performance, particularly in challenging hard-exploration
and long-horizon credit assignment tasks. Our framework naturally extends to
powerful multi-step Bellman operators, further broadening its impact. Spectral
Bellman Representation offers a principled and effective path toward learning
more powerful and structurally sound representations for value-based
reinforcement learning.

</details>


### [183] [GradNetOT: Learning Optimal Transport Maps with GradNets](https://arxiv.org/abs/2507.13191)
*Shreyas Chaudhari,Srinivasa Pranav,José M. F. Moura*

Main category: cs.LG

TL;DR: 一种名为mGradNets的新型神经网络可以直接学习最优输运映射。该方法通过最小化与Monge-Ampere方程相关的损失函数来实现，并在机器人集群控制任务中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 解决最优输运问题中的Monge公式，该问题在流体动力学到机器人集群控制等现代应用中至关重要，特别是当输运成本为平方欧氏距离时。

Method: 使用mGradNets（一种直接参数化单调梯度映射空间的神经网络）来学习最优输运映射，通过最小化基于Monge-Ampere方程的训练损失函数。

Result: mGradNets的结构偏差有助于学习最优输运映射，并成功应用于机器人集群控制问题。

Conclusion: 该研究利用mGradNets直接学习最优输运映射，并通过一个机器人集群控制问题进行了实证检验。

Abstract: Monotone gradient functions play a central role in solving the Monge
formulation of the optimal transport problem, which arises in modern
applications ranging from fluid dynamics to robot swarm control. When the
transport cost is the squared Euclidean distance, Brenier's theorem guarantees
that the unique optimal map is the gradient of a convex function, namely a
monotone gradient map, and it satisfies a Monge-Amp\`ere equation. In
[arXiv:2301.10862] [arXiv:2404.07361], we proposed Monotone Gradient Networks
(mGradNets), neural networks that directly parameterize the space of monotone
gradient maps. In this work, we leverage mGradNets to directly learn the
optimal transport mapping by minimizing a training loss function defined using
the Monge-Amp\`ere equation. We empirically show that the structural bias of
mGradNets facilitates the learning of optimal transport maps and employ our
method for a robot swarm control problem.

</details>


### [184] [MoTM: Towards a Foundation Model for Time Series Imputation based on Continuous Modeling](https://arxiv.org/abs/2507.13207)
*Etienne Le Naour,Tahar Nabil,Ghislain Agoua*

Main category: cs.LG

TL;DR: MoTM 是一种新的时间序列缺失模型，它结合了隐式神经表示（INR）和混合模式，可以处理各种缺失情况和数据分布，并在实验中表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 填补时间序列缺失值（尤其是非分布内缺失）这一被忽视的领域。时间序列的缺失值处理对于许多实际应用至关重要，但现有的方法在处理分布外（out-of-domain）的缺失值时表现不佳。

Method: 提出了一种名为 MoTM（Mixture of Timeflow Models）的新方法，该方法结合了 INR 基础和岭回归器。INR 将时间序列建模为连续函数，能够处理各种缺失数据场景和采样率。MoTM 的核心思想是，新的时间序列是先前观察到的模式的混合。它结合了 INR 基础，每个 INR 独立地在不同的时间序列族上进行训练，并结合了一个岭回归器，该回归器在推理时适应观察到的上下文。

Result: MoTM 在各种缺失场景下都表现出了强大的域内和域外泛化能力，包括块状缺失、点状缺失和可变采样率。

Conclusion: MoTM 证明了其在各种时间序列缺失场景（例如，块状和点状缺失、可变采样率）中具有鲁棒的域内和域外泛化能力，为可适应的基础模型提供了可能性。

Abstract: Recent years have witnessed a growing interest for time series foundation
models, with a strong emphasis on the forecasting task. Yet, the crucial task
of out-of-domain imputation of missing values remains largely underexplored. We
propose a first step to fill this gap by leveraging implicit neural
representations (INRs). INRs model time series as continuous functions and
naturally handle various missing data scenarios and sampling rates. While they
have shown strong performance within specific distributions, they struggle
under distribution shifts. To address this, we introduce MoTM (Mixture of
Timeflow Models), a step toward a foundation model for time series imputation.
Building on the idea that a new time series is a mixture of previously seen
patterns, MoTM combines a basis of INRs, each trained independently on a
distinct family of time series, with a ridge regressor that adapts to the
observed context at inference. We demonstrate robust in-domain and
out-of-domain generalization across diverse imputation scenarios (e.g., block
and pointwise missingness, variable sampling rates), paving the way for
adaptable foundation imputation models.

</details>


### [185] [Merge Kernel for Bayesian Optimization on Permutation Space](https://arxiv.org/abs/2507.13263)
*Zikai Xie,Linjiang Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Bayesian Optimization (BO) algorithm is a standard tool for black-box
optimization problems. The current state-of-the-art BO approach for permutation
spaces relies on the Mallows kernel-an $\Omega(n^2)$ representation that
explicitly enumerates every pairwise comparison. Inspired by the close
relationship between the Mallows kernel and pairwise comparison, we propose a
novel framework for generating kernel functions on permutation space based on
sorting algorithms. Within this framework, the Mallows kernel can be viewed as
a special instance derived from bubble sort. Further, we introduce the
\textbf{Merge Kernel} constructed from merge sort, which replaces the quadratic
complexity with $\Theta(n\log n)$ to achieve the lowest possible complexity.
The resulting feature vector is significantly shorter, can be computed in
linearithmic time, yet still efficiently captures meaningful permutation
distances. To boost robustness and right-invariance without sacrificing
compactness, we further incorporate three lightweight, task-agnostic
descriptors: (1) a shift histogram, which aggregates absolute element
displacements and supplies a global misplacement signal; (2) a split-pair line,
which encodes selected long-range comparisons by aligning elements across the
two halves of the whole permutation; and (3) sliding-window motifs, which
summarize local order patterns that influence near-neighbor objectives. Our
empirical evaluation demonstrates that the proposed kernel consistently
outperforms the state-of-the-art Mallows kernel across various permutation
optimization benchmarks. Results confirm that the Merge Kernel provides a more
compact yet more effective solution for Bayesian optimization in permutation
space.

</details>


### [186] [Boosting Team Modeling through Tempo-Relational Representation Learning](https://arxiv.org/abs/2507.13305)
*Vincenzo Marco De Luca,Giovanna Varni,Andrea Passerini*

Main category: cs.LG

TL;DR: TRENN是一种新颖的时间-关系架构，用于团队建模，能够同时捕捉关系和时间动态，并提供可解释的见解。其多任务扩展MT-TRENN可以同时预测多种团队构建，并在实际应用中显示出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的团队建模方法未能满足社会科学研究中联合建模动态和关系的需求，也未能满足实际应用中进行多重团队构建同时推断、提供可解释见解和可行建议以提升团队绩效的要求。

Method: 提出了一种名为TRENN的新型 tempo-关系架构，该架构集成了自动时间图提取器、tempo-关系编码器、用于团队构建预测的解码器以及两个互补的可解释性模块。MT-TRENN作为TRENN的扩展，用多任务学习头替换了解码器，实现了共享社会嵌入的学习和多个团队构建（如新兴领导力、领导风格和团队合作组件）的同时预测。

Result: 实验结果表明，TRENN及其MT-TRENN扩展在处理团队动态和关系方面优于仅依赖时间或关系信息的传统方法。此外，MT-TRENN的可解释性模块能够提供有意义的见解和可行的建议，以支持团队改进。

Conclusion: TRENN及其多任务版本MT-TRENN在团队建模方面取得了显著进展，能够同时处理动态和关系信息，并提供可解释的见解和可行的建议，以提高团队绩效。该模型在实际应用中，特别是在高风险协作环境中的智能决策支持系统方面，展现了巨大潜力。

Abstract: Team modeling remains a fundamental challenge at the intersection of
Artificial Intelligence and the Social Sciences. Social Science research
emphasizes the need to jointly model dynamics and relations, while practical
applications demand unified models capable of inferring multiple team
constructs simultaneously, providing interpretable insights and actionable
recommendations to enhance team performance. However, existing works do not
meet these practical demands. To bridge this gap, we present TRENN, a novel
tempo-relational architecture that integrates: (i) an automatic temporal graph
extractor, (ii) a tempo-relational encoder, (iii) a decoder for team construct
prediction, and (iv) two complementary explainability modules. TRENN jointly
captures relational and temporal team dynamics, providing a solid foundation
for MT-TRENN, which extends TReNN by replacing the decoder with a multi-task
head, enabling the model to learn shared Social Embeddings and simultaneously
predict multiple team constructs, including Emergent Leadership, Leadership
Style, and Teamwork components. Experimental results demonstrate that our
approach significantly outperforms approaches that rely exclusively on temporal
or relational information. Additionally, experimental evaluation has shown that
the explainability modules integrated in MT-TRENN yield interpretable insights
and actionable suggestions to support team improvement. These capabilities make
our approach particularly well-suited for Human-Centered AI applications, such
as intelligent decision-support systems in high-stakes collaborative
environments.

</details>


### [187] [GeoReg: Weight-Constrained Few-Shot Regression for Socio-Economic Estimation using LLM](https://arxiv.org/abs/2507.13323)
*Kyeongjin Ahn,Sungwon Han,Seungeon Lee,Donghyun Ahn,Hyoshin Kim,Jungwon Kim,Jihee Kim,Sangyoon Park,Meeyoung Cha*

Main category: cs.LG

TL;DR: GeoReg利用LLM从卫星和网络数据中提取特征，并结合线性估计和非线性模式来估算数据稀缺地区（如发展中国家）的GDP、人口和教育水平等社会经济指标，效果优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决数据稀缺地区（如发展中国家）在制定政策和促进可持续发展时，对GDP、人口和教育水平等关键社会经济指标估算能力不足的问题。

Method: GeoReg是一个回归模型，它整合了包括卫星图像和网络地理空间信息在内的多种数据源，并利用大型语言模型（LLM）的先验知识来提取信息特征，以应对数据稀缺地区（如发展中国家）的挑战。该模型将特征与目标指标的关联分为正相关、负相关、混合或不相关，并将这些特征与为每个类别量身定制的权重约束一起输入线性估计器，同时通过识别有意义的特征交互和整合非线性变换来捕捉非线性模式。

Result: GeoReg模型在估算社会经济指标方面表现出色，尤其是在数据有限的低收入国家，其表现优于现有的基线模型。

Conclusion: GeoReg模型在不同发展阶段的国家进行了实验，结果表明，即使在低收入和数据稀缺的国家，GeoReg模型在估算社会经济指标方面也优于基线模型。

Abstract: Socio-economic indicators like regional GDP, population, and education
levels, are crucial to shaping policy decisions and fostering sustainable
development. This research introduces GeoReg a regression model that integrates
diverse data sources, including satellite imagery and web-based geospatial
information, to estimate these indicators even for data-scarce regions such as
developing countries. Our approach leverages the prior knowledge of large
language model (LLM) to address the scarcity of labeled data, with the LLM
functioning as a data engineer by extracting informative features to enable
effective estimation in few-shot settings. Specifically, our model obtains
contextual relationships between data features and the target indicator,
categorizing their correlations as positive, negative, mixed, or irrelevant.
These features are then fed into the linear estimator with tailored weight
constraints for each category. To capture nonlinear patterns, the model also
identifies meaningful feature interactions and integrates them, along with
nonlinear transformations. Experiments across three countries at different
stages of development demonstrate that our model outperforms baselines in
estimating socio-economic indicators, even for low-income countries with
limited data availability.

</details>


### [188] [Training Transformers with Enforced Lipschitz Constants](https://arxiv.org/abs/2507.13338)
*Laker Newhouse,R. Preston Hess,Franz Cesista,Andrii Zahorodnii,Jeremy Bernstein,Phillip Isola*

Main category: cs.LG

TL;DR: 通过开发新的权重约束工具和优化器策略，成功地在 Transformer 训练中强制执行了 Lipschitz 边界，提高了模型的稳定性和鲁棒性，并在某些任务上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络对输入和权重扰动敏感的问题，这些敏感性与对抗样本的脆弱性、训练发散和过拟合等病理现象有关。现有技术（如完全从 Lipschitz 组件构建神经网络）尚未能成功训练现代 Transformer 架构，并保持 Lipschitz 证书。

Method: 开发并测试了计算效率高的新工具，用于在训练过程中保持范数约束的权重矩阵。研究了优化器动态（AdamW vs Muon）对标准方法（权重衰减和谱归一化）的影响。设计了一种新的权重约束方法，并将其应用于 MLP 和 Transformer 模型，在 Shakespeare 文本和互联网文本上进行了实验。

Result: 在 Transformer 模型训练中成功应用了贯穿整个训练过程的 Lipschitz 边界。发现 Muon 优化器配合权重衰减和谱归一化，能在较低的 Lipschitz 边界下达到与 AdamW 相当的性能。新设计的权重约束方法在 MLP 和 Transformer 模型上改善了 Lipschitz 边界与性能的权衡。在 Shakespeare 文本任务上，2-Lipschitz Transformer 达到了 60% 的验证准确率。在互联网文本任务上，145M 参数的 10-Lipschitz Transformer 达到了 21% 的准确率，但要匹配 NanoGPT 的 39.4% 准确率，Lipschitz 上界需要增加到 10^264。提出的 Lipschitz Transformer 训练稳定，无需层归一化、QK 归一化和 logit tanh softcapping 等稳定化措施。

Conclusion: 本文提出了新的计算有效工具来保持范数约束的权重矩阵，并成功地将 Lipschitz 边界应用于 Transformer 模型训练的全过程。研究发现优化器的选择（如从 AdamW 切换到 Muon）和特定的权重约束方法可以改善 Lipschitz 边界与模型性能之间的权衡。尽管在某些大规模任务上，为了匹配基线性能，Lipschitz 上界可能急剧增大，但提出的 Lipschitz Transformer 训练稳定，无需额外的稳定化措施，并在 Shakespeare 文本任务上达到了 60% 的验证准确率。

Abstract: Neural networks are often highly sensitive to input and weight perturbations.
This sensitivity has been linked to pathologies such as vulnerability to
adversarial examples, divergent training, and overfitting. To combat these
problems, past research has looked at building neural networks entirely from
Lipschitz components. However, these techniques have not matured to the point
where researchers have trained a modern architecture such as a transformer with
a Lipschitz certificate enforced beyond initialization. To explore this gap, we
begin by developing and benchmarking novel, computationally-efficient tools for
maintaining norm-constrained weight matrices. Applying these tools, we are able
to train transformer models with Lipschitz bounds enforced throughout training.
We find that optimizer dynamics matter: switching from AdamW to Muon improves
standard methods -- weight decay and spectral normalization -- allowing models
to reach equal performance with a lower Lipschitz bound. Inspired by Muon's
update having a fixed spectral norm, we co-design a weight constraint method
that improves the Lipschitz vs. performance tradeoff on MLPs and 2M parameter
transformers. Our 2-Lipschitz transformer on Shakespeare text reaches
validation accuracy 60%. Scaling to 145M parameters, our 10-Lipschitz
transformer reaches 21% accuracy on internet text. However, to match the
NanoGPT baseline validation accuracy of 39.4%, our Lipschitz upper bound
increases to 10^264. Nonetheless, our Lipschitz transformers train without
stability measures such as layer norm, QK norm, and logit tanh softcapping.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [189] [Physically Based Neural LiDAR Resimulation](https://arxiv.org/abs/2507.12489)
*Richard Marcus,Marc Stamminger*

Main category: cs.RO

TL;DR: 该研究通过考虑 LiDAR 传感器的特定效应（如滚动快门和激光功率变化），改进了 LiDAR 模拟的准确性，并展示了其在生成高分辨率扫描方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的新视角合成（NVS）方法在 LiDAR 模拟和大规模 3D 场景重建领域虽然取得了进展，但对 LiDAR 特定的效应处理不足。

Method: 通过显式建模滚动快门、激光功率变化和强度衰减等传感器特性来改进 LiDAR 模拟。

Result: 该方法实现了更准确的 LiDAR 模拟，并在与最先进方法的比较中显示了其有效性，此外还展示了生成高分辨率 LiDAR 扫描等高级重新模拟功能。

Conclusion: 通过显式建模滚动快门、激光功率变化和强度衰减等传感器特性，该方法实现了比现有技术更精确的 LiDAR 模拟，并在定量和定性比较中证明了其有效性，同时还展示了其高级的重新模拟功能。

Abstract: Methods for Novel View Synthesis (NVS) have recently found traction in the
field of LiDAR simulation and large-scale 3D scene reconstruction. While
solutions for faster rendering or handling dynamic scenes have been proposed,
LiDAR specific effects remain insufficiently addressed. By explicitly modeling
sensor characteristics such as rolling shutter, laser power variations, and
intensity falloff, our method achieves more accurate LiDAR simulation compared
to existing techniques. We demonstrate the effectiveness of our approach
through quantitative and qualitative comparisons with state-of-the-art methods,
as well as ablation studies that highlight the importance of each sensor model
component. Beyond that, we show that our approach exhibits advanced
resimulation capabilities, such as generating high resolution LiDAR scans in
the camera perspective.
  Our code and the resulting dataset are available at
https://github.com/richardmarcus/PBNLiDAR.

</details>


### [190] [FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making](https://arxiv.org/abs/2507.12496)
*Yucen Wang,Rui Yu,Shenghua Wan,Le Gan,De-Chuan Zhan*

Main category: cs.RO

TL;DR: FOUNDER 是一个将基础模型（FM）的知识与世界模型（WM）的动态建模能力相结合的框架，用于在奖励自由的情况下解决具身环境中的开放式任务。它通过将 FM 表示映射到 WM 状态空间，并利用预测的时间距离作为奖励信号，在多任务离线视觉控制基准测试中取得了优越的性能，尤其是在处理复杂观察或领域差距时。


<details>
  <summary>Details</summary>
Motivation: 基础模型（FM）和世界模型（WM）在不同层级的任务泛化方面提供了互补的优势。本研究旨在整合 FM 的泛化知识和 WM 的动态建模能力，以在奖励自由的情况下实现具身环境中的开放式任务解决。

Method: FOUNDER 框架集成基础模型（FM）的泛化知识和世界模型（WM）的动态建模能力，以实现具身环境中的开放式任务解决。通过学习一个将 FM 表示映射到 WM 状态空间的功能，从外部观察推断智能体的物理状态。该映射使得在行为学习过程中通过想象来学习目标条件策略，并将映射的任务作为目标状态。该方法利用到目标状态的预测时间距离作为信息奖励信号。

Result: FOUNDER 在各种多任务离线视觉控制基准测试中表现出优越的性能，特别是在捕获文本或视频指定的任务的深层语义方面，尤其是在涉及复杂观察或领域差距的情况下，这些情况是先前的方法难以解决的。此外，我们学习到的奖励函数与真实奖励函数的一致性也得到了实证验证。

Conclusion: FOUNDER 在奖励自由的情况下，在各种多任务离线视觉控制基准测试中表现出优越的性能，特别是在涉及复杂观察或领域差距的情况下，特别是在捕获文本或视频指定的任务的深层语义方面。

Abstract: Foundation Models (FMs) and World Models (WMs) offer complementary strengths
in task generalization at different levels. In this work, we propose FOUNDER, a
framework that integrates the generalizable knowledge embedded in FMs with the
dynamic modeling capabilities of WMs to enable open-ended task solving in
embodied environments in a reward-free manner. We learn a mapping function that
grounds FM representations in the WM state space, effectively inferring the
agent's physical states in the world simulator from external observations. This
mapping enables the learning of a goal-conditioned policy through imagination
during behavior learning, with the mapped task serving as the goal state. Our
method leverages the predicted temporal distance to the goal state as an
informative reward signal. FOUNDER demonstrates superior performance on various
multi-task offline visual control benchmarks, excelling in capturing the
deep-level semantics of tasks specified by text or videos, particularly in
scenarios involving complex observations or domain gaps where prior methods
struggle. The consistency of our learned reward function with the ground-truth
reward is also empirically validated. Our project website is
https://sites.google.com/view/founder-rl.

</details>


### [191] [ReAL-AD: Towards Human-Like Reasoning in End-to-End Autonomous Driving](https://arxiv.org/abs/2507.12499)
*Yuhang Lu,Jiadong Tu,Yuexin Ma,Xinge Zhu*

Main category: cs.RO

TL;DR: ReAL-AD：通过模仿人类三层认知模型和结合VLM，增强了端到端自动驾驶的可解释性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法依赖于固定的稀疏轨迹监督，难以捕捉人类驾驶员固有的分层推理过程。

Method: 提出了一种名为ReAL-AD（Reasoning-Augmented Learning）的框架，该框架将自动驾驶决策结构化为三个层次：驾驶策略、驾驶决策和驾驶操作。框架包含三个主要组件：战略推理注入器（将VLM的见解转化为高级驾驶策略）、战术推理整合器（将策略意图细化为可解释的战术选择，如变道、超车、速度调整）和分层轨迹解码器（将战术决策转化为精确的控制动作）。

Result: 与现有方法相比，ReAL-AD框架将规划准确性和安全性提高了30%以上，使得端到端自动驾驶更具可解释性，并与人类的分层推理过程更加一致。

Conclusion: ReAL-AD框架通过模仿人类三层认知模型（驾驶策略、驾驶决策、驾驶操作）并结合视觉-语言模型（VLMs），增强了端到端自动驾驶的可解释性和安全性，提高了规划准确性和安全性超过30%。

Abstract: End-to-end autonomous driving has emerged as a promising approach to unify
perception, prediction, and planning within a single framework, reducing
information loss and improving adaptability. However, existing methods often
rely on fixed and sparse trajectory supervision, limiting their ability to
capture the hierarchical reasoning process that human drivers naturally employ.
To bridge this gap, we propose ReAL-AD, a Reasoning-Augmented Learning
framework that structures decision-making in autonomous driving based on the
three-tier human cognitive model: Driving Strategy, Driving Decision, and
Driving Operation, where Vision-Language Models (VLMs) are incorporated to
enhance situational awareness and structured reasoning across these levels.
Specifically, we introduce: (1) the Strategic Reasoning Injector, which
formulates high-level driving strategies by interpreting complex traffic
contexts from VLM-generated insights; (2) the Tactical Reasoning Integrator,
which refines strategic intent into interpretable tactical choices such as lane
changes, overtaking, and speed adjustments; and (3) the Hierarchical Trajectory
Decoder, which progressively translates tactical decisions into precise control
actions for smooth and human-like trajectory execution. Extensive evaluations
show that integrating our framework improves planning accuracy and safety by
over 30%, making end-to-end autonomous driving more interpretable and aligned
with human-like hierarchical reasoning. The project page can be found at:
\href{https://4dvlab.github.io/project_page/realad}{\texttt{4dvlab.github.io/project\_page/realad}}

</details>


### [192] [VLMgineer: Vision Language Models as Robotic Toolsmiths](https://arxiv.org/abs/2507.12644)
*George Jiayuan Gao,Tianyu Li,Junyao Shi,Yihan Li,Zizhe Zhang,Nadia Figueroa,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Tool design and use reflect the ability to understand and manipulate the
physical world through creativity, planning, and foresight. As such, these
capabilities are often regarded as measurable indicators of intelligence across
biological species. While much of today's research on robotic intelligence
focuses on generating better controllers, inventing smarter tools offers a
complementary form of physical intelligence: shifting the onus of
problem-solving onto the tool's design. Given the vast and impressive
common-sense, reasoning, and creative capabilities of today's foundation
models, we investigate whether these models can provide useful priors to
automatically design and effectively wield such tools? We present VLMgineer, a
framework that harnesses the code generation abilities of vision language
models (VLMs) together with evolutionary search to iteratively co-design
physical tools and the action plans that operate them to perform a task. We
evaluate VLMgineer on a diverse new benchmark of everyday manipulation
scenarios that demand creative tool design and use. Across this suite,
VLMgineer consistently discovers tools and policies that solve tasks more
effectively and innovatively, transforming challenging robotics problems into
straightforward executions. It also outperforms VLM-generated designs from
human specifications and existing human-crafted tools for everyday tasks. To
facilitate future research on automated tool invention, we will release our
benchmark and code.

</details>


### [193] [MoistureMapper: An Autonomous Mobile Robot for High-Resolution Soil Moisture Mapping at Scale](https://arxiv.org/abs/2507.12716)
*Nathaniel Rose,Hannah Chuang,Manuel A Andrade-Rodriguez,Rishi Parashar,Dani Or,Parikshit Maini*

Main category: cs.RO

TL;DR: 本研究提出了一种名为MoistureMapper的自主机器人，用于高分辨率土壤湿度传感，并通过自适应采样策略优化了数据采集效率。


<details>
  <summary>Details</summary>
Motivation: 现有土壤湿度传感方法难以满足农业和气候建模等领域大范围、高分辨率传感的需求，尤其是在变量灌溉等应用中部署成本过高。

Method: 该研究设计、制造并实地部署了一个名为MoistureMapper的自主移动机器人，配备了TDR传感器和直接推钻机制，用于测量土壤的体积含水量。研究还实现并评估了基于高斯过程建模的多种自适应采样策略，以构建土壤湿度空间分布图。

Result: 通过大规模计算模拟和概念验证性的实地部署，结果表明所提出的自适应采样方法优于贪婪基准方法，在减少旅行距离方面最多可提高30%，在重建的湿度图方差方面可降低5%。

Conclusion: 所提出的自走式机器人MoistureMapper结合了时域反射仪（TDR）传感器和直接推钻机制，可用于大范围高分辨率的土壤湿度传感。

Abstract: Soil moisture is a quantity of interest in many application areas including
agriculture and climate modeling. Existing methods are not suitable for scale
applications due to large deployment costs in high-resolution sensing
applications such as for variable irrigation. In this work, we design, build
and field deploy an autonomous mobile robot, MoistureMapper, for soil moisture
sensing. The robot is equipped with Time Domain Reflectometry (TDR) sensors and
a direct push drill mechanism for deploying the sensor to measure volumetric
water content in the soil. Additionally, we implement and evaluate multiple
adaptive sampling strategies based on a Gaussian Process based modeling to
build a spatial mapping of moisture distribution in the soil. We present
results from large scale computational simulations and proof-of-concept
deployment on the field. The adaptive sampling approach outperforms a greedy
benchmark approach and results in up to 30\% reduction in travel distance and
5\% reduction in variance in the reconstructed moisture maps. Link to video
showing field experiments: https://youtu.be/S4bJ4tRzObg

</details>


### [194] [Learning to Predict Mobile Robot Stability in Off-Road Environments](https://arxiv.org/abs/2507.12731)
*Nathaniel Rose,Arif Ahmed,Emanuel Gutierrez-Cornejo,Parikshit Maini*

Main category: cs.RO

TL;DR: 提出了一种基于学习的机器人稳定性估计方法，使用IMUnet和C3分数，无需精确的地形模型或力传感，可应用于农业和太空等领域的移动操作任务。


<details>
  <summary>Details</summary>
Motivation: 针对轮式移动机器人在动态和崎岖地形中进行越野导航的挑战，提出了新的稳定性评估方法，以克服传统基于物理的稳定性指标（如SSM或ZMP）在实际现场条件下难以准确测量接触力、地形几何和机器人质心的问题。

Method: 提出了一种基于学习的方法，利用轻量级神经网络IMUnet直接从本体感觉数据估计机器人平台稳定性，无需精确的地面模型或力传感。同时，开发了一种新颖的基于视觉的ArUco跟踪方法，通过计算C3分数来量化机器人平台稳定性，该分数捕捉图像空间扰动作为物理不稳定的代理，并用作神经网络模型的训练信号。

Result: 在多种地形和速度下收集的数据上评估了所提出的方法，并证明了其对先前未见过的条件的泛化能力。初步结果表明，利用IMU和机器人速度作为输入来估计平台稳定性具有潜力。

Conclusion: 该方法能够利用IMU和机器人速度等信息来估计平台稳定性，为农业和太空等领域的移动操作任务提供了潜在的应用价值，尤其是在精确驱动和传感等任务中。

Abstract: Navigating in off-road environments for wheeled mobile robots is challenging
due to dynamic and rugged terrain. Traditional physics-based stability metrics,
such as Static Stability Margin (SSM) or Zero Moment Point (ZMP) require
knowledge of contact forces, terrain geometry, and the robot's precise
center-of-mass that are difficult to measure accurately in real-world field
conditions. In this work, we propose a learning-based approach to estimate
robot platform stability directly from proprioceptive data using a lightweight
neural network, IMUnet. Our method enables data-driven inference of robot
stability without requiring an explicit terrain model or force sensing.
  We also develop a novel vision-based ArUco tracking method to compute a
scalar score to quantify robot platform stability called C3 score. The score
captures image-space perturbations over time as a proxy for physical
instability and is used as a training signal for the neural network based
model. As a pilot study, we evaluate our approach on data collected across
multiple terrain types and speeds and demonstrate generalization to previously
unseen conditions. These initial results highlight the potential of using IMU
and robot velocity as inputs to estimate platform stability. The proposed
method finds application in gating robot tasks such as precision actuation and
sensing, especially for mobile manipulation tasks in agricultural and space
applications. Our learning method also provides a supervision mechanism for
perception based traversability estimation and planning.

</details>


### [195] [ASC-SW: Atrous strip convolution network with sliding windows for visual-assisted map navigation](https://arxiv.org/abs/2507.12744)
*Cheng Liu,Fan Zhu,Yaoyu Zhuang Zhinan Chen Jiefeng Tang*

Main category: cs.RO

TL;DR: 提出了一种名为ASC-SN的视觉辅助导航框架，用于检测地面线缆等障碍物，提高了移动机器人的导航能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统激光雷达（LiDAR）传感器无法检测地面线缆等地面障碍物的问题，并为资源受限的边缘计算设备部署轻量级视觉模型。

Method: 提出了一种名为ASC-SN的视觉辅助导航框架，该框架利用深度摄像头和轻量级视觉神经网络来辅助基于地图的移动机器人导航。该框架通过引入ASC-SN网络（以MobileNetV2为骨干网络，并设计了ASC-SPP模块来提取DLO特征），利用空洞条卷积（Atrous Strip Convolution）来准确识别DLO的线性结构，并结合滑动窗口（SW）后处理模块来提高识别精度。

Result: ASC-SN框架能够有效检测地面线缆等可变形线性物体，提高了移动机器人在复杂环境中的导航安全性与准确性。

Conclusion: 该方法在自建数据集上实现了75.3%的平均交并比（Miou）得分，并在Jetson Orin Nano边缘设备上达到了9.3 FPS的推理速度，优于现有的可变形线性物体（DLO）检测模型，并已在物理机器人平台上成功验证。

Abstract: With the rapid development of lightweight visual neural network
architectures, traditional high-performance vision models have undergone
significant compression, greatly improving their computational efficiency and
energy consumption ratio. This makes them feasible for deployment on
resource-constrained edge computing devices. We propose a visual-assisted
navigation framework called Atrous Strip Convolution-Sliding Window (ASC-SW),
which leverages a depth camera and a lightweight visual neural network to
assist map-based mobile robot navigation. This framework compensates for the
inability of traditional light detection and range (LiDAR) sensors to detect
ground-level obstacles such as ground-level wires. We introduce a lightweight
and efficient segmentation model, Atrous Strip Convolution Network (ASCnet),
for detecting deformable linear objects (DLOs). MobileNetV2 is used as the
backbone network, and Atrous Strip Convolution Spatial Pyramid Pooling (ASCSPP)
is designed to extract DLO features more effectively. Atrous Strip Convolution
is integrated into ASCSPP to accurately identify the linear structure of DLOs
with low computational cost. Additionally, a Sliding Window (SW)
post-processing module is proposed to denoise the output in complex
environments, improving recognition accuracy. Our method strikes a balance
between inference speed and segmentation performance. It achieves a mean
Intersection over Union (Miou) score of 75.3% on a self-built dataset and
reaches 9.3 FPS inference speed on the Jetson Orin Nano edge device. Overall,
our approach outperforms existing DLO detection models and has been
successfully validated on a physical robotic platform.

</details>


### [196] [Refining Motion for Peak Performance: Identifying Optimal Gait Parameters for Energy-Efficient Quadrupedal Bounding](https://arxiv.org/abs/2507.12751)
*Yasser G. Alqaham,Jing Cheng,Zhenyu Gan*

Main category: cs.RO

TL;DR: 步态参数对四足机器人能耗至关重要，优化这些参数可提高效率。


<details>
  <summary>Details</summary>
Motivation: 步态参数（占 কার্য周期、相移和步长持续时间）对四足机器人能量消耗的影响是影响其性能和自主性的关键因素，但先前研究对此的探讨较少。

Method: 通过对Unitree A1四足机器人进行建模，并开发一种能够独立调整步态参数（占 কার্য周期、相移和步长持续时间）的运动控制器，在Gazebo中以低、中、高三种速度对各种步态参数下的 bounding gaits 进行仿真，并通过实验测试验证了仿真结果。

Result: 仿真和实验结果表明，优化步态参数能够显著降低能耗。

Conclusion: 优化步态参数可以显著降低四足机器人的能耗，从而提高其整体运动效率。

Abstract: Energy efficiency is a critical factor in the performance and autonomy of
quadrupedal robots. While previous research has focused on mechanical design
and actuation improvements, the impact of gait parameters on energetics has
been less explored. In this paper, we hypothesize that gait parameters,
specifically duty factor, phase shift, and stride duration, are key
determinants of energy consumption in quadrupedal locomotion. To test this
hypothesis, we modeled the Unitree A1 quadrupedal robot and developed a
locomotion controller capable of independently adjusting these gait parameters.
Simulations of bounding gaits were conducted in Gazebo across a range of gait
parameters at three different speeds: low, medium, and high. Experimental tests
were also performed to validate the simulation results. The findings
demonstrate that optimizing gait parameters can lead to significant reductions
in energy consumption, enhancing the overall efficiency of quadrupedal
locomotion. This work contributes to the advancement of energy-efficient
control strategies for legged robots, offering insights directly applicable to
commercially available platforms.

</details>


### [197] [osmAG-LLM: Zero-Shot Open-Vocabulary Object Navigation via Semantic Maps and Large Language Models Reasoning](https://arxiv.org/abs/2507.12753)
*Fujing Xie,Sören Schwertfeger,Hermann Blum*

Main category: cs.RO

TL;DR: 提出了一种新的映射和导航系统，用于对象目标导航，该系统考虑了对象可能已移动或未映射的可能性，并结合了大型语言模型的语义先验来推理对象位置。


<details>
  <summary>Details</summary>
Motivation: 高细节对象映射会很快过时，因为对象经常被移动。之前的开放词汇机器人映射方法在可扩展性方面得到了一些关注，但另一个根本性问题是映射的细节会很快过时。

Method: 提出了一种新的映射和导航系统，该系统从头开始考虑对象可能已移动或根本未映射的可能性。该系统不追求高保真度的映射细节，而是认为地图的主要目的是提供环境基础和上下文，并结合了大型语言模型的语义先验来推理对象位置，并部署了主动、在线的方法来导航到对象。

Result: 通过模拟和真实世界的实验，我们发现该方法在静态对象检索成功率和路径长度方面表现更好，并且在动态或未映射对象查询方面远超先前的方法。

Conclusion: 该方法在静态对象检索成功率和路径长度方面表现更好，并且在动态或未映射对象查询方面远超先前的方法。

Abstract: Recent open-vocabulary robot mapping methods enrich dense geometric maps with
pre-trained visual-language features, achieving a high level of detail and
guiding robots to find objects specified by open-vocabulary language queries.
While the issue of scalability for such approaches has received some attention,
another fundamental problem is that high-detail object mapping quickly becomes
outdated, as objects get moved around a lot. In this work, we develop a mapping
and navigation system for object-goal navigation that, from the ground up,
considers the possibilities that a queried object can have moved, or may not be
mapped at all. Instead of striving for high-fidelity mapping detail, we
consider that the main purpose of a map is to provide environment grounding and
context, which we combine with the semantic priors of LLMs to reason about
object locations and deploy an active, online approach to navigate to the
objects. Through simulated and real-world experiments we find that our approach
tends to have higher retrieval success at shorter path lengths for static
objects and by far outperforms prior approaches in cases of dynamic or unmapped
object queries. We provide our code and dataset at:
https://anonymous.4open.science/r/osmAG-LLM.

</details>


### [198] [FFI-VTR: Lightweight and Robust Visual Teach and Repeat Navigation based on Feature Flow Indicator and Probabilistic Motion Planning](https://arxiv.org/abs/2507.12800)
*Jikai Wang,Yunqi Cheng,Zonghai Chen*

Main category: cs.RO

TL;DR: 提出了一种新颖的、轻量且鲁棒的视觉和重复机器人自主导航方法，无需精确的定位和稠密的重建。该方法利用特征流和概率运动规划来最小化导航过程中的特征流，实现了高效且鲁棒的机器人自主导航。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉和重复导航是移动机器人自导航的便捷解决方案，但在任务环境中实现效率和鲁棒性之间的平衡仍然面临挑战。

Method: 提出了一种新颖的视觉和重复机器人自主导航方法，该方法不需要精确的定位和稠密的重建模块。引入特征流，并开发了特征流与机器人运动之间的定性映射，其中特征流定义为匹配特征之间的像素位置偏差。基于映射模型，教学阶段输出的地图表示为关键帧图，其中边缘上的特征流编码了相邻关键帧之间的相对运动。将视觉重复导航本质上建模为当前观测与地图关键帧之间的特征流最小化问题。为了驱动机器人在没有精确定位的情况下持续减小当前帧与地图关键帧之间的特征流，基于定性的特征流-运动映射指标开发了一种概率运动规划。

Result: 通过在移动平台上的大量实验证明了所提出方法是轻量、鲁棒且优于基线方法。

Conclusion: 该方法轻量、鲁棒且优于基线方法。

Abstract: Though visual and repeat navigation is a convenient solution for mobile robot
self-navigation, achieving balance between efficiency and robustness in task
environment still remains challenges. In this paper, we propose a novel visual
and repeat robotic autonomous navigation method that requires no accurate
localization and dense reconstruction modules, which makes our system featured
by lightweight and robustness. Firstly, feature flow is introduced and we
develop a qualitative mapping between feature flow and robot's motion, in which
feature flow is defined as pixel location bias between matched features. Based
on the mapping model, the map outputted by the teaching phase is represented as
a keyframe graph, in which the feature flow on the edge encodes the relative
motion between adjacent keyframes. Secondly, the visual repeating navigation is
essentially modeled as a feature flow minimization problem between current
observation and the map keyframe. To drive the robot to consistently reduce the
feature flow between current frame and map keyframes without accurate
localization, a probabilistic motion planning is developed based on our
qualitative feature flow-motion mapping indicator. Extensive experiments using
our mobile platform demonstrates that our proposed method is lightweight,
robust, and superior to baselines. The source code has been made public at
https://github.com/wangjks/FFI-VTR to benefit the community.

</details>


### [199] [Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering](https://arxiv.org/abs/2507.12846)
*Muhammad Fadhil Ginting,Dong-Ki Kim,Xiangyun Meng,Andrzej Reinke,Bandi Jai Krishna,Navid Kayhani,Oriana Peltzer,David D. Fan,Amirreza Shaban,Sung-Kyun Kim,Mykel J. Kochenderfer,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: 提出了一种新颖的 LA-EQA 任务和一种基于记忆宫殿的机器人结构化记忆系统，以提高长期环境中机器人的问答和探索效率。


<details>
  <summary>Details</summary>
Motivation: 研究了长期主动具身问答（LA-EQA）问题，这是一个新任务，要求机器人在回答复杂、时间相关的问题时，既要回忆过去的经验，又要积极探索环境。

Method: 提出了一种结构化的记忆系统，灵感来自认知科学中的记忆宫殿方法，将情景体验编码为基于场景图的世界实例，并采用基于信息价值的停止标准来平衡探索-回忆的权衡。

Result: 在真实世界的实验和跨越流行模拟环境和实际工业 sites 的新基准上进行了评估。

Conclusion: 该方法在回答准确性和探索效率方面显著优于最先进的方法。

Abstract: As robots become increasingly capable of operating over extended periods --
spanning days, weeks, and even months -- they are expected to accumulate
knowledge of their environments and leverage this experience to assist humans
more effectively. This paper studies the problem of Long-term Active Embodied
Question Answering (LA-EQA), a new task in which a robot must both recall past
experiences and actively explore its environment to answer complex,
temporally-grounded questions. Unlike traditional EQA settings, which typically
focus either on understanding the present environment alone or on recalling a
single past observation, LA-EQA challenges an agent to reason over past,
present, and possible future states, deciding when to explore, when to consult
its memory, and when to stop gathering observations and provide a final answer.
Standard EQA approaches based on large models struggle in this setting due to
limited context windows, absence of persistent memory, and an inability to
combine memory recall with active exploration. To address this, we propose a
structured memory system for robots, inspired by the mind palace method from
cognitive science. Our method encodes episodic experiences as scene-graph-based
world instances, forming a reasoning and planning algorithm that enables
targeted memory retrieval and guided navigation. To balance the
exploration-recall trade-off, we introduce value-of-information-based stopping
criteria that determines when the agent has gathered sufficient information. We
evaluate our method on real-world experiments and introduce a new benchmark
that spans popular simulation environments and actual industrial sites. Our
approach significantly outperforms state-of-the-art baselines, yielding
substantial gains in both answer accuracy and exploration efficiency.

</details>


### [200] [DEMONSTRATE: Zero-shot Language to Robotic Control via Multi-task Demonstration Learning](https://arxiv.org/abs/2507.12855)
*Rahel Rickenbach,Bruce Lee,René Zurbrügg,Carmen Amo Alonso,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: 演示方法利用任务演示和多任务学习来解决LLM在控制系统中的限制，从而减少对工程专业知识的依赖并提高安全性。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM在控制系统任务中对精心设计的任务示例的依赖以及在任务执行前评估幻觉的挑战，提出了一种新方法。

Method: DEMONSTRATE方法利用逆最优控制工具将任务演示作为嵌入表示，取代了基于LLM的复杂优化问题生成中的提示示例，并结合了多任务学习以确保任务相似性。

Result: 通过模拟和涉及机器人手臂进行桌面操作的硬件实验，证明了该方法在减少工程专业知识依赖、实现少样本学习和任务执行前评估幻觉方面的有效性。

Conclusion: 该方法通过利用逆最优控制和多任务学习，利用任务演示而非LLM生成复杂的优化问题，减少了对工程专业知识的依赖，并能在任务执行前评估幻觉。

Abstract: The integration of large language models (LLMs) with control systems has
demonstrated significant potential in various settings, such as task completion
with a robotic manipulator. A main reason for this success is the ability of
LLMs to perform in-context learning, which, however, strongly relies on the
design of task examples, closely related to the target tasks. Consequently,
employing LLMs to formulate optimal control problems often requires task
examples that contain explicit mathematical expressions, designed by trained
engineers. Furthermore, there is often no principled way to evaluate for
hallucination before task execution. To address these challenges, we propose
DEMONSTRATE, a novel methodology that avoids the use of LLMs for complex
optimization problem generations, and instead only relies on the embedding
representations of task descriptions. To do this, we leverage tools from
inverse optimal control to replace in-context prompt examples with task
demonstrations, as well as the concept of multitask learning, which ensures
target and example task similarity by construction. Given the fact that
hardware demonstrations can easily be collected using teleoperation or guidance
of the robot, our approach significantly reduces the reliance on engineering
expertise for designing in-context examples. Furthermore, the enforced
multitask structure enables learning from few demonstrations and assessment of
hallucinations prior to task execution. We demonstrate the effectiveness of our
method through simulation and hardware experiments involving a robotic arm
tasked with tabletop manipulation.

</details>


### [201] [LaViPlan : Language-Guided Visual Path Planning with RLVR](https://arxiv.org/abs/2507.12911)
*Hayeon Oh*

Main category: cs.RO

TL;DR: LaViPlan通过RLVR优化VLM，解决自动驾驶OOD场景下的“视觉-语言-动作”不匹配问题，提升了态势感知和决策能力。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶领域中，视觉语言模型（VLM）在高层决策/视觉推理与低层轨迹预测/动作之间存在“视觉-语言-动作”不匹配的问题，该问题导致VLM在OOD场景下可能产生不符合情境的决策。

Method: 提出LaViPlan框架，利用可验证奖励的强化学习（RLVR）来优化视觉语言模型（VLM），并结合规划导向的指标。

Result: 实验结果表明，LaViPlan框架提高了在OOD条件下的态势感知和决策能力，有效缓解了“视觉-语言-动作”不匹配的问题。

Conclusion: LaViPlan框架通过使用可验证奖励的强化学习（RLVR）来优化视觉语言模型（VLM），解决了自动驾驶领域中VLM的高层决策与低层轨迹预测之间的“视觉-语言-动作”不匹配问题。实验结果表明，该方法提高了在OOD条件下的态势感知和决策能力，为VLM在自动驾驶中的应用提供了一种有前景的训练后优化范式。

Abstract: Out-of-distribution (OOD) scenarios in autonomous driving refer to situations
that deviate from the training domain, often leading to unexpected and
potentially hazardous behavior from planners that lack prior exposure to such
cases. Recently, Vision-Language Models (VLMs) have been introduced into
autonomous driving research for their promising generalization capabilities in
OOD settings. Early studies demonstrated that VLMs could recognize OOD
scenarios and generate user-level decisions such as "go straight" or "turn
right." However, a new challenge has emerged due to the misalignment between
the VLM's high-level decisions or visual reasoning expressed in language, and
the low-level predicted trajectories interpreted as actions. In this paper, we
propose LaViPlan, a framework that leverages Reinforcement Learning with
Verifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics.
This approach addresses the vision-language-action misalignment observed in
existing VLMs fine-tuned via supervised learning, which can recognize driving
scenarios but often produce context-unaware decisions. Experimental results
demonstrate that our method improves situational awareness and decision-making
under OOD conditions, highlighting its potential to mitigate the misalignment
issue. This work introduces a promising post-training paradigm for VLM agents
in the context of autonomous driving.

</details>


### [202] [MoCap2GT: A High-Precision Ground Truth Estimator for SLAM Benchmarking Based on Motion Capture and IMU Fusion](https://arxiv.org/abs/2507.12920)
*Zichao Shu,Shitao Bei,Jicheng Dai,Lijun Li,Zetao Chen*

Main category: cs.RO

TL;DR: MoCap2GT利用MoCap和IMU数据联合优化，通过B样条和退化感知剔除提升GT轨迹精度，解决现有SLAM评估中的旋转和帧间误差难题。


<details>
  <summary>Details</summary>
Motivation: 现有基于MoCap的GT轨迹精度受限于时空校准误差和MoCap抖动，导致难以准确评估SLAM的旋转和帧间误差，阻碍了全面的SLAM评估。

Method: 提出MoCap2GT，一种联合优化方法，整合MoCap数据和DUT的IMU测量。该方法包括鲁棒的状态初始化器，用于全局收敛；在SE(3)流形上采用高阶B样条位姿参数化和可变时间偏移，以有效模拟MoCap因素；以及退化感知测量剔除策略，以提高估计精度。

Result: 实验结果表明，MoCap2GT的表现优于现有方法，显著提高了GT轨迹的精度，有助于精确的SLAM基准测试。

Conclusion: MoCap2GT通过整合MoCap数据和IMU测量，并采用B样条参数化和退化感知测量剔除策略，生成高精度GT轨迹，优于现有方法，为精确SLAM基准测试做出了贡献。

Abstract: Marker-based optical motion capture (MoCap) systems are widely used to
provide ground truth (GT) trajectories for benchmarking SLAM algorithms.
However, the accuracy of MoCap-based GT trajectories is mainly affected by two
factors: spatiotemporal calibration errors between the MoCap system and the
device under test (DUT), and inherent MoCap jitter. Consequently, existing
benchmarks focus primarily on absolute translation error, as accurate
assessment of rotation and inter-frame errors remains challenging, hindering
thorough SLAM evaluation. This paper proposes MoCap2GT, a joint optimization
approach that integrates MoCap data and inertial measurement unit (IMU)
measurements from the DUT for generating high-precision GT trajectories.
MoCap2GT includes a robust state initializer to ensure global convergence,
introduces a higher-order B-spline pose parameterization on the SE(3) manifold
with variable time offset to effectively model MoCap factors, and employs a
degeneracy-aware measurement rejection strategy to enhance estimation accuracy.
Experimental results demonstrate that MoCap2GT outperforms existing methods and
significantly contributes to precise SLAM benchmarking. The source code is
available at https://anonymous.4open.science/r/mocap2gt (temporarily hosted
anonymously for double-blind review).

</details>


### [203] [Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning](https://arxiv.org/abs/2507.12977)
*Giwon Lee,Daehee Park,Jaewoo Jeong,Kuk-Jin Yoon*

Main category: cs.RO

TL;DR: 该研究通过引入强化学习和奖励加权动态阈值算法，改进了扩散运动规划模型，使其能够学习安全性和有效性等非可微分目标，并在相关数据集上取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有扩散模型在训练目标上的局限性，即它们近似数据分布而非显式捕获决策动力学，并且无法直接优化非可微分的下游目标（如碰撞避免和目标达成）。

Method: 提出了一种强化学习训练方案，并引入了奖励加权动态阈值算法来塑造密集奖励信号，以优化包含非可微分目标（如安全性和有效性）的扩散运动规划模型。

Result: 与使用可微分目标的模型相比，该方法在行人数据集（CrowdNav、ETH-UCY）上取得了优于各种基线方法的性能。

Conclusion: 该研究提出了一种基于强化学习的扩散运动规划模型训练方案，能够有效学习非可微分的目标，并在行人数据集（CrowdNav、ETH-UCY）上取得了最先进的性能，证明了其在安全有效运动规划方面的通用性。

Abstract: Safe and effective motion planning is crucial for autonomous robots.
Diffusion models excel at capturing complex agent interactions, a fundamental
aspect of decision-making in dynamic environments. Recent studies have
successfully applied diffusion models to motion planning, demonstrating their
competence in handling complex scenarios and accurately predicting multi-modal
future trajectories. Despite their effectiveness, diffusion models have
limitations in training objectives, as they approximate data distributions
rather than explicitly capturing the underlying decision-making dynamics.
However, the crux of motion planning lies in non-differentiable downstream
objectives, such as safety (collision avoidance) and effectiveness
(goal-reaching), which conventional learning algorithms cannot directly
optimize. In this paper, we propose a reinforcement learning-based training
scheme for diffusion motion planning models, enabling them to effectively learn
non-differentiable objectives that explicitly measure safety and effectiveness.
Specifically, we introduce a reward-weighted dynamic thresholding algorithm to
shape a dense reward signal, facilitating more effective training and
outperforming models trained with differentiable objectives. State-of-the-art
performance on pedestrian datasets (CrowdNav, ETH-UCY) compared to various
baselines demonstrates the versatility of our approach for safe and effective
motion planning.

</details>


### [204] [Robustness Requirement Coverage using a Situation Coverage Approach for Vision-based AI Systems](https://arxiv.org/abs/2507.12986)
*Sepeedeh Shahbeigi,Nawshin Mannan Proma,Victoria Hodge,Richard Hawkins,Boda Li,Valentina Donzella*

Main category: cs.RO

TL;DR: 为了让AI机器人和车辆在组件退化的情况下也能在复杂环境中安全运行，这篇论文提出了一个框架，通过识别相机噪声和分析情景覆盖来制定鲁棒性要求。


<details>
  <summary>Details</summary>
Motivation: AI驱动的机器人和车辆需要在复杂动态的环境中安全运行，即使在组件退化的情况下也是如此。传感器性能的下降会影响AI推理的准确性。然而，为所有可能的传感器退化场景指定安全要求会导致复杂性难以管理且存在漏洞。

Method: 通过整合相机噪声因子识别与情景覆盖分析来系统地阐明和评估AI感知系统的鲁棒性要求。首先，扩展现有的退化模型以包含与AI性能相关的噪声因子，然后应用情景覆盖分析识别代表性的操作环境。

Result: 提出了一种新颖的框架，该框架集成了相机噪声因子识别与情景覆盖分析，以系统地阐明和评估AI驱动的感知系统的鲁棒性要求。

Conclusion: 该工作是系统化阐明和评估基于摄像头的AI感知系统的鲁棒性要求的第一步，集成了噪声因子分析和情况覆盖率分析。

Abstract: AI-based robots and vehicles are expected to operate safely in complex and
dynamic environments, even in the presence of component degradation. In such
systems, perception relies on sensors such as cameras to capture environmental
data, which is then processed by AI models to support decision-making. However,
degradation in sensor performance directly impacts input data quality and can
impair AI inference. Specifying safety requirements for all possible sensor
degradation scenarios leads to unmanageable complexity and inevitable gaps. In
this position paper, we present a novel framework that integrates camera noise
factor identification with situation coverage analysis to systematically elicit
robustness-related safety requirements for AI-based perception systems. We
focus specifically on camera degradation in the automotive domain. Building on
an existing framework for identifying degradation modes, we propose involving
domain, sensor, and safety experts, and incorporating Operational Design Domain
specifications to extend the degradation model by incorporating noise factors
relevant to AI performance. Situation coverage analysis is then applied to
identify representative operational contexts. This work marks an initial step
toward integrating noise factor analysis and situational coverage to support
principled formulation and completeness assessment of robustness requirements
for camera-based AI perception.

</details>


### [205] [Rethinking the Embodied Gap in Vision-and-Language Navigation: A Holistic Study of Physical and Visual Disparities](https://arxiv.org/abs/2507.13019)
*Liuyi Wang,Xinyuan Xia,Hui Zhao,Hanqing Wang,Tai Wang,Yilun Chen,Chengju Liu,Qijun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: VLN-PE 是一个物理上真实的 VLN 平台，支持人形、四足和轮式机器人，用于评估以自我为中心的 VLN 方法。在物理环境中，与理想化设置相比，由于观察空间有限、光照变化和物理挑战，性能会下降。该平台还有助于改进 VLN 模型的跨体适应性。


<details>
  <summary>Details</summary>
Motivation: 当前的 VLN 方法未能充分解决物理现实世界中机器人移动和控制的挑战，其理想化的假设与实际部署存在差距。

Method: 开发了一个名为 VLN-PE 的物理上真实的 VLN 平台，该平台支持人形、四足和轮式机器人。在 VLN-PE 平台上，对几种以自我为中心的 VLN 方法进行了系统评估，包括用于单步离散动作预测的分类模型、用于密集航点预测的扩散模型以及与路径规划集成的不需要训练的、基于地图的大型语言模型 (LLM)。

Result: 在物理机器人环境中，由于有限的机器人观察空间、环境光照变化以及碰撞和跌倒等物理挑战，导致性能显著下降。这还暴露了在复杂环境中，用于自主移动的机器人的运动限制。

Conclusion: VLN-PE 提供了一个改进 VLN 模型跨体适应性、鲁棒性和实用性的新途径。我们希望我们的发现和工具能激励社区重新思考 VLN 的局限性。

Abstract: Recent Vision-and-Language Navigation (VLN) advancements are promising, but
their idealized assumptions about robot movement and control fail to reflect
physically embodied deployment challenges. To bridge this gap, we introduce
VLN-PE, a physically realistic VLN platform supporting humanoid, quadruped, and
wheeled robots. For the first time, we systematically evaluate several
ego-centric VLN methods in physical robotic settings across different technical
pipelines, including classification models for single-step discrete action
prediction, a diffusion model for dense waypoint prediction, and a train-free,
map-based large language model (LLM) integrated with path planning. Our results
reveal significant performance degradation due to limited robot observation
space, environmental lighting variations, and physical challenges like
collisions and falls. This also exposes locomotion constraints for legged
robots in complex environments. VLN-PE is highly extensible, allowing seamless
integration of new scenes beyond MP3D, thereby enabling more comprehensive VLN
evaluation. Despite the weak generalization of current models in physical
deployment, VLN-PE provides a new pathway for improving cross-embodiment's
overall adaptability. We hope our findings and tools inspire the community to
rethink VLN limitations and advance robust, practical VLN models. The code is
available at https://crystalsixone.github.io/vln_pe.github.io/.

</details>


### [206] [ZipMPC: Compressed Context-Dependent MPC Cost via Imitation Learning](https://arxiv.org/abs/2507.13088)
*Rahel Rickenbach,Alan A. Lahoud,Erik Schaffernicht,Melanie N. Zeilinger,Johannes A. Stork*

Main category: cs.RO

TL;DR: ZipMPC通过学习压缩的、与上下文相关的成本函数来模仿长范围MPC行为，用于短范围MPC，在保持低计算成本的同时提高了控制性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 模型预测控制（MPC）的计算负担限制了其在机器人等实时系统上的应用，并且通常需要使用短预测范围，这不仅影响控制性能，还增加了设计能够反映期望的长期目标的 MPC 成本函数的难度。

Method: ZipMPC 利用可微分 MPC 和神经网络的概念，将模仿损失的梯度传播到 MPC 优化中，从而学习压缩的、与上下文相关的成本函数，用于短预测范围 MPC。

Result: ZipMPC 在模仿性能方面优于其他方法，例如近似显式 MPC 和自动成本参数调整，尤其是在优化长期目标、保持可与短预测范围 MPC 相媲美的计算成本、确保约束满足以及泛化到未见过的环境方面。

Conclusion: ZipMPC 能够持续比选定的基线快圈，在性能上接近长预测范围 MPC 的基线，并且在短预测范围 MPC 基线无法完成的具有挑战性的场景中，ZipMPC 能够完成赛道，尤其是在未见过的赛道上也能够提高性能。

Abstract: The computational burden of model predictive control (MPC) limits its
application on real-time systems, such as robots, and often requires the use of
short prediction horizons. This not only affects the control performance, but
also increases the difficulty of designing MPC cost functions that reflect the
desired long-term objective. This paper proposes ZipMPC, a method that imitates
a long-horizon MPC behaviour by learning a compressed and context-dependent
cost function for a short-horizon MPC. It improves performance over alternative
methods, such as approximate explicit MPC and automatic cost parameter tuning,
in particular in terms of i) optimizing the long term objective; ii)
maintaining computational costs comparable to a short-horizon MPC; iii)
ensuring constraint satisfaction; and iv) generalizing control behaviour to
environments not observed during training. For this purpose, ZipMPC leverages
the concept of differentiable MPC with neural networks to propagate gradients
of the imitation loss through the MPC optimization. We validate our proposed
method in simulation and real-world experiments on autonomous racing. ZipMPC
consistently completes laps faster than selected baselines, achieving lap times
close to the long-horizon MPC baseline. In challenging scenarios where the
short-horizon MPC baseline fails to complete a lap, ZipMPC is able to do so. In
particular, these performance gains are also observed on tracks unseen during
training.

</details>


### [207] [What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics](https://arxiv.org/abs/2507.13041)
*Julien Wacquez,Elisabetta Zibetti,Joffrey Becker,Lorenzo Aloe,Fabio Amadio,Salvatore Anzalone,Lola Cañamero,Serena Ivaldi*

Main category: cs.RO

TL;DR: This paper advocates for an interdisciplinary approach to human-robot trust, combining social sciences and robotics to build a better framework for understanding trust as robots become more common.


<details>
  <summary>Details</summary>
Motivation: As robots become more prevalent in daily life, the need to understand trust in human-robot relationships is increasing, but the concept is often approached fragmentally, with limited dialogue between HRI and established sociological work on trust.

Method: The paper explores how trust is shaped, tested, and made visible by drawing on insights from both social sciences and social robotics.

Result: The paper aims to open up a dialogue between disciplines and contribute to a more grounded and adaptable framework for understanding trust in the evolving world of human-robot interaction.

Conclusion: The paper argues for a more interdisciplinary approach to understanding trust in human-robot interaction by integrating insights from social sciences and social robotics.

Abstract: As robots find their way into more and more aspects of everyday life,
questions around trust are becoming increasingly important. What does it mean
to trust a robot? And how should we think about trust in relationships that
involve both humans and non-human agents? While the field of Human-Robot
Interaction (HRI) has made trust a central topic, the concept is often
approached in fragmented ways. At the same time, established work in sociology,
where trust has long been a key theme, is rarely brought into conversation with
developments in robotics. This article argues that we need a more
interdisciplinary approach. By drawing on insights from both social sciences
and social robotics, we explore how trust is shaped, tested and made visible.
Our goal is to open up a dialogue between disciplines and help build a more
grounded and adaptable framework for understanding trust in the evolving world
of human-robot interaction.

</details>


### [208] [Efficient Online Learning and Adaptive Planning for Robotic Information Gathering Based on Streaming Data](https://arxiv.org/abs/2507.13053)
*Sanjeev Ramkumar Sudha,Joel Jose,Erlend M. Coates*

Main category: cs.RO

TL;DR: 提出了一种新的自适应信息规划方法，使用流式稀疏高斯过程，以更高效的方式为机器人收集环境信息，尤其适用于未知或动态环境。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人信息收集（RIG）和信息规划方法通常假设环境是已知的，但实际环境可能是未知的或随时间变化的，这需要自适应规划和在线建图。此外，高斯过程（GP）回归虽然常用于此，但实时性能难以扩展到大数据集。

Method: 提出了一种使用流式稀疏高斯过程（GPs）进行自适应信息规划的有效方法，用于绘制连续标量场。

Result: 与现有基准相比，该方法在模拟和真实世界数据集上均表现出有竞争力的地图绘制精度，并显著降低了计算复杂性，尤其是在长任务中。

Conclusion: 该方法在保持相似的地图绘制精度的同时，降低了计算复杂性，特别适合长任务。

Abstract: Robotic information gathering (RIG) techniques refer to methods where mobile
robots are used to acquire data about the physical environment with a suite of
sensors. Informative planning is an important part of RIG where the goal is to
find sequences of actions or paths that maximize efficiency or the quality of
information collected. Many existing solutions solve this problem by assuming
that the environment is known in advance. However, real environments could be
unknown or time-varying, and adaptive informative planning remains an active
area of research. Adaptive planning and incremental online mapping are required
for mapping initially unknown or varying spatial fields. Gaussian process (GP)
regression is a widely used technique in RIG for mapping continuous spatial
fields. However, it falls short in many applications as its real-time
performance does not scale well to large datasets. To address these challenges,
this paper proposes an efficient adaptive informative planning approach for
mapping continuous scalar fields with GPs with streaming sparse GPs. Simulation
experiments are performed with a synthetic dataset and compared against
existing benchmarks. Finally, it is also verified with a real-world dataset to
further validate the efficacy of the proposed method. Results show that our
method achieves similar mapping accuracy to the baselines while reducing
computational complexity for longer missions.

</details>


### [209] [GraspGen: A Diffusion-based Framework for 6-DOF Grasping with On-Generator Training](https://arxiv.org/abs/2507.13097)
*Adithyavairavan Murali,Balakumar Sundaralingam,Yu-Wei Chao,Wentao Yuan,Jun Yamada,Mark Carlson,Fabio Ramos,Stan Birchfield,Dieter Fox,Clemens Eppner*

Main category: cs.RO

TL;DR: GraspGen improves 6-DOF grasping by using a DiffusionTransformer and a discriminator trained on a large dataset, outperforming existing methods in simulation and achieving state-of-the-art on FetchBench, with good real-world performance.


<details>
  <summary>Details</summary>
Motivation: Existing learning-based 6-DOF grasping approaches lack generalization across different embodiments and in-the-wild settings, despite significant research advancements.

Method: The framework utilizes a DiffusionTransformer architecture for grasp generation, coupled with an efficient discriminator for scoring and filtering grasps. It also introduces a novel on-generator training recipe for the discriminator and is trained on a large simulated dataset of over 53 million grasps.

Result: GraspGen outperforms prior methods in simulations with singulated objects across different grippers and achieves state-of-the-art performance on the FetchBench grasping benchmark. It also performs well on a real robot with noisy visual observations.

Conclusion: GraspGen demonstrates strong performance in simulations across different grippers, achieves state-of-the-art results on the FetchBench benchmark, and shows effectiveness on real robots even with noisy visual input.

Abstract: Grasping is a fundamental robot skill, yet despite significant research
advancements, learning-based 6-DOF grasping approaches are still not turnkey
and struggle to generalize across different embodiments and in-the-wild
settings. We build upon the recent success on modeling the object-centric grasp
generation process as an iterative diffusion process. Our proposed framework,
GraspGen, consists of a DiffusionTransformer architecture that enhances grasp
generation, paired with an efficient discriminator to score and filter sampled
grasps. We introduce a novel and performant on-generator training recipe for
the discriminator. To scale GraspGen to both objects and grippers, we release a
new simulated dataset consisting of over 53 million grasps. We demonstrate that
GraspGen outperforms prior methods in simulations with singulated objects
across different grippers, achieves state-of-the-art performance on the
FetchBench grasping benchmark, and performs well on a real robot with noisy
visual observations.

</details>


### [210] [Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback](https://arxiv.org/abs/2507.13171)
*Suzie Kim,Hye-Bin Shin,Seong-Whan Lee*

Main category: cs.RO

TL;DR: RLHF方法依赖于显式的反馈机制，例如按钮按下或偏好标签，这会干扰自然的交互过程并增加用户的认知负担。我们提出了一种新颖的从隐式人类反馈（RLIHF）中进行强化学习的框架，该框架利用非侵入式脑电图（EEG）信号，特别是与错误相关的电位（ErrPs），在不需要用户明确干预的情况下提供连续的、隐式的反馈。所提出的方法采用预先训练的解码器将原始脑电图信号转换为概率奖励组件，从而在存在稀疏外部奖励的情况下有效地学习策略。我们将我们的方法在一个基于MuJoCo物理引擎的仿真环境中进行了评估，并使用Kinova Gen2机器人手臂执行一项复杂的拾放任务，该任务需要在操作目标对象的同时避开障碍物。结果表明，使用解码后的脑电图反馈训练的智能体取得了与使用密集、手动设计的奖励训练的智能体相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习（RL）方法在稀疏奖励条件下学习有效策略时常常遇到困难，这需要手动设计复杂、针对特定任务的奖励函数。为了解决这个限制，从人类反馈（RLHF）中进行强化学习已成为一种有前途的策略，它通过人类派生的评估信号来补充手工设计的奖励。

Method: 我们提出了一种新颖的从隐式人类反馈（RLIHF）中进行强化学习的框架，该框架利用非侵入式脑电图（EEG）信号，特别是与错误相关的电位（ErrPs），在不需要用户明确干预的情况下提供连续的、隐式的反馈。所提出的方法采用预先训练的解码器将原始脑电图信号转换为概率奖励组件，从而在存在稀疏外部奖励的情况下有效地学习策略。

Result: 我们将我们的方法在一个基于MuJoCo物理引擎的仿真环境中进行了评估，并使用Kinova Gen2机器人手臂执行一项复杂的拾放任务，该任务需要在操作目标对象的同时避开障碍物。结果表明，使用解码后的脑电图反馈训练的智能体取得了与使用密集、手动设计的奖励训练的智能体相当的性能。

Conclusion: RLHF方法依赖于显式的反馈机制，例如按钮按下或偏好标签，这会干扰自然的交互过程并增加用户的认知负担。我们提出了一种新颖的从隐式人类反馈（RLIHF）中进行强化学习的框架，该框架利用非侵入式脑电图（EEG）信号，特别是与错误相关的电位（ErrPs），在不需要用户明确干预的情况下提供连续的、隐式的反馈。

Abstract: Conventional reinforcement learning (RL) ap proaches often struggle to learn
effective policies under sparse reward conditions, necessitating the manual
design of complex, task-specific reward functions. To address this limitation,
rein forcement learning from human feedback (RLHF) has emerged as a promising
strategy that complements hand-crafted rewards with human-derived evaluation
signals. However, most existing RLHF methods depend on explicit feedback
mechanisms such as button presses or preference labels, which disrupt the
natural interaction process and impose a substantial cognitive load on the
user. We propose a novel reinforcement learning from implicit human feedback
(RLIHF) framework that utilizes non-invasive electroencephalography (EEG)
signals, specifically error-related potentials (ErrPs), to provide continuous,
implicit feedback without requiring explicit user intervention. The proposed
method adopts a pre-trained decoder to transform raw EEG signals into
probabilistic reward components, en abling effective policy learning even in
the presence of sparse external rewards. We evaluate our approach in a
simulation environment built on the MuJoCo physics engine, using a Kinova Gen2
robotic arm to perform a complex pick-and-place task that requires avoiding
obstacles while manipulating target objects. The results show that agents
trained with decoded EEG feedback achieve performance comparable to those
trained with dense, manually designed rewards. These findings validate the
potential of using implicit neural feedback for scalable and human-aligned
reinforcement learning in interactive robotics.

</details>


### [211] [Few-shot transfer of tool-use skills using human demonstrations with proximity and tactile sensing](https://arxiv.org/abs/2507.13200)
*Marina Y. Aoyama,Sethu Vijayakumar,Tetsuya Narita*

Main category: cs.RO

TL;DR: 机器人学习使用工具进行操作很困难，因为接触点复杂且数据有限。我们提出了一种结合模拟预训练和真实世界微调的少样本学习框架，使用触觉和近距离传感器，成功教会了机器人执行表面跟踪任务。


<details>
  <summary>Details</summary>
Motivation: 教机器人工具操作技能面临挑战，因为需要处理机器人-工具和工具-环境之间的双重接触点，并且真实世界数据有限，模拟到现实的差距很大。

Method: 提出了一种使用多模态传感器的少样本工具使用技能迁移框架，包括在模拟中预训练捕获接触状态的基础策略，以及在真实世界中用人类演示进行微调。

Result: 该框架成功地教会了机器人使用工具执行表面跟踪任务，即使工具的物理和几何特性各不相同。机器人通过迁移识别工具-环境接触关系的能力来学习新技能。结合近距离和触觉传感器可以更好地识别接触状态和环境几何形状。

Conclusion: 该框架通过在模拟环境中预训练基础策略以捕获工具使用技能中常见的接触状态，并在真实目标域中通过收集到的人类演示进行微调，从而弥合了领域差距，实现了少样本工具使用技能迁移。

Abstract: Tools extend the manipulation abilities of robots, much like they do for
humans. Despite human expertise in tool manipulation, teaching robots these
skills faces challenges. The complexity arises from the interplay of two
simultaneous points of contact: one between the robot and the tool, and another
between the tool and the environment. Tactile and proximity sensors play a
crucial role in identifying these complex contacts. However, learning tool
manipulation using these sensors remains challenging due to limited real-world
data and the large sim-to-real gap. To address this, we propose a few-shot
tool-use skill transfer framework using multimodal sensing. The framework
involves pre-training the base policy to capture contact states common in
tool-use skills in simulation and fine-tuning it with human demonstrations
collected in the real-world target domain to bridge the domain gap. We validate
that this framework enables teaching surface-following tasks using tools with
diverse physical and geometric properties with a small number of demonstrations
on the Franka Emika robot arm. Our analysis suggests that the robot acquires
new tool-use skills by transferring the ability to recognise tool-environment
contact relationships from pre-trained to fine-tuned policies. Additionally,
combining proximity and tactile sensors enhances the identification of contact
states and environmental geometry.

</details>


### [212] [Signal Temporal Logic Compliant Co-design of Planning and Control](https://arxiv.org/abs/2507.13225)
*Manas Sashank Juvvi,Tushar Dilip Kurne,Vaishnavi J,Shishir Kolathaya,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出了一种新的策略，通过学习运动原语和STL合规运动规划来共同设计轨迹规划和控制，以处理自主机器人中的基于STL的任务。


<details>
  <summary>Details</summary>
Motivation: 为了处理自主机器人中的基于STL的任务，提出了一种将轨迹规划和控制相结合的新颖的协同设计策略。

Method: 提出了一种新颖的协同设计策略，将轨迹规划和控制相结合，以处理自主机器人中的基于STL的任务。该方法包括两个阶段：(i)学习时空运动原语以封装固有的机器人特定约束，以及(ii)从这些原语构建符合STL的运动计划。最初，我们采用强化学习来构建控制策略库，以执行由运动原语描述的轨迹。然后，我们将运动原语映射到时空特征。随后，我们提出了一种基于采样的STL合规运动规划策略，该策略经过专门设计，能够满足STL规范。

Result: 将学习到的运动原语映射到时空特征，并提出了一种基于采样的STL合规运动规划策略，该策略经过专门设计，能够满足STL规范。该模型游离方法为差速驱动和四足机器人跨各种STL规范生成了可行的STL合规运动计划。

Conclusion: 该方法为差速驱动和四足机器人跨各种STL规范生成了可行的STL合规运动计划。

Abstract: This work presents a novel co-design strategy that integrates trajectory
planning and control to handle STL-based tasks in autonomous robots. The method
consists of two phases: $(i)$ learning spatio-temporal motion primitives to
encapsulate the inherent robot-specific constraints and $(ii)$ constructing an
STL-compliant motion plan from these primitives. Initially, we employ
reinforcement learning to construct a library of control policies that perform
trajectories described by the motion primitives. Then, we map motion primitives
to spatio-temporal characteristics. Subsequently, we present a sampling-based
STL-compliant motion planning strategy tailored to meet the STL specification.
The proposed model-free approach, which generates feasible STL-compliant motion
plans across various environments, is validated on differential-drive and
quadruped robots across various STL specifications. Demonstration videos are
available at https://tinyurl.com/m6zp7rsm.

</details>


### [213] [Evaluating Reinforcement Learning Algorithms for Navigation in Simulated Robotic Quadrupeds: A Comparative Study Inspired by Guide Dog Behaviour](https://arxiv.org/abs/2507.13277)
*Emma M. A. Harrison*

Main category: cs.RO

TL;DR: This study trained a simulated quadruped robot using three reinforcement learning algorithms for navigation and obstacle avoidance. PPO performed best, showing potential for robotic assistance in healthcare and for visually impaired individuals.


<details>
  <summary>Details</summary>
Motivation: The research aims to develop a robotic guide dog simulation capable of path following and obstacle avoidance, with long-term potential for real-world assistance to guide dogs and visually impaired individuals. It also seeks to expand research into medical 'pets', including robotic guide and alert dogs, as robots are increasingly integrated across industries, particularly in healthcare, but many valuable applications for quadrupedal robots remain overlooked.

Method: The research explored the effectiveness of three reinforcement learning algorithms (Proximal Policy Optimization, Deep Q-Network, and Q-learning) in training a simulated quadruped robot for autonomous navigation and obstacle avoidance. A comparative analysis of thirteen related research papers shaped key evaluation criteria. Custom-made environments were used for fair evaluation of all three algorithms under controlled conditions. The study focused on sensor inputs, collision frequency, reward signals, and learning progression.

Result: Proximal Policy Optimization (PPO) outperformed Deep Q-Network (DQN) and Q-learning across all metrics, particularly in average and median steps to goal per episode.

Conclusion: Proximal Policy Optimization (PPO) is the most effective algorithm for training quadrupedal robots in autonomous navigation and obstacle avoidance, outperforming Deep Q-Network (DQN) and Q-learning across all metrics, particularly in average and median steps to goal per episode.

Abstract: Robots are increasingly integrated across industries, particularly in
healthcare. However, many valuable applications for quadrupedal robots remain
overlooked. This research explores the effectiveness of three reinforcement
learning algorithms in training a simulated quadruped robot for autonomous
navigation and obstacle avoidance. The goal is to develop a robotic guide dog
simulation capable of path following and obstacle avoidance, with long-term
potential for real-world assistance to guide dogs and visually impaired
individuals. It also seeks to expand research into medical 'pets', including
robotic guide and alert dogs.
  A comparative analysis of thirteen related research papers shaped key
evaluation criteria, including collision detection, pathfinding algorithms,
sensor usage, robot type, and simulation platforms. The study focuses on sensor
inputs, collision frequency, reward signals, and learning progression to
determine which algorithm best supports robotic navigation in complex
environments.
  Custom-made environments were used to ensure fair evaluation of all three
algorithms under controlled conditions, allowing consistent data collection.
Results show that Proximal Policy Optimization (PPO) outperformed Deep
Q-Network (DQN) and Q-learning across all metrics, particularly in average and
median steps to goal per episode.
  By analysing these results, this study contributes to robotic navigation, AI
and medical robotics, offering insights into the feasibility of AI-driven
quadruped mobility and its role in assistive robotics.

</details>


### [214] [Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](https://arxiv.org/abs/2507.13340)
*Yiqi Wang,Mrinal Verghese,Jeff Schneider*

Main category: cs.RO

TL;DR: 通过利用多种来源的数据（包括来自不同机器人的数据集和人类玩耍的数据）来预训练世界模型，并结合潜在策略转向（LPS）技术，可以显著减少机器人学习中的数据收集需求，并提高低数据量下的策略性能。


<details>
  <summary>Details</summary>
Motivation: 在机器人领域，通过模仿学习视觉动作策略已被证明是有效的，但其性能高度依赖于训练演示的数量，这需要昂贵的真实世界数据收集。本工作旨在通过利用来自各种体现（如公共机器人数据集和人类玩物体的游戏数据集）的现有或具有成本效益的数据，来减少学习视觉动作机器人策略时的数据收集工作。

Method: 该方法包括两个关键部分：1. 使用作为体现无关动作表示的光流来跨多体现数据集训练世界模型（WM），并在目标体现的少量机器人数据上进行微调。2. 开发一种潜在策略转向（LPS）方法，通过在WM的潜在空间中搜索更好的动作序列来改进行为克隆策略的输出。

Result: 在真实世界实验中，通过将策略与在来自不同机器人的两千集样本的现有Open X-embodiment数据集或来自游戏的具有成本效益的人类数据集预训练的WM相结合，在具有少量数据（30次演示数据相对提高了50%以上，50次演示数据相对提高了20%以上）训练的策略性能方面，观察到了显著的改进。

Conclusion: 通过结合在不同机器人或具有成本效益的人类数据集上预训练的世界模型（WM）和行为克隆策略，在数据量较少的情况下，可以显著提高策略性能。

Abstract: Learning visuomotor policies via imitation has proven effective across a wide
range of robotic domains. However, the performance of these policies is heavily
dependent on the number of training demonstrations, which requires expensive
data collection in the real world. In this work, we aim to reduce data
collection efforts when learning visuomotor robot policies by leveraging
existing or cost-effective data from a wide range of embodiments, such as
public robot datasets and the datasets of humans playing with objects (human
data from play). Our approach leverages two key insights. First, we use optic
flow as an embodiment-agnostic action representation to train a World Model
(WM) across multi-embodiment datasets, and finetune it on a small amount of
robot data from the target embodiment. Second, we develop a method, Latent
Policy Steering (LPS), to improve the output of a behavior-cloned policy by
searching in the latent space of the WM for better action sequences. In real
world experiments, we observe significant improvements in the performance of
policies trained with a small amount of data (over 50% relative improvement
with 30 demonstrations and over 20% relative improvement with 50
demonstrations) by combining the policy with a WM pretrained on two thousand
episodes sampled from the existing Open X-embodiment dataset across different
robots or a cost-effective human dataset from play.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [215] [Identification of Authoritative Nodes and Dismantling of Illicit Networks Using a Novel Metric for Measuring Strength of a Graph](https://arxiv.org/abs/2507.12711)
*Kartikeya Kansal,Arunabha Sen*

Main category: cs.SI

TL;DR: 提出了一种新的网络强度度量方法，该方法结合了网络结构和人类感知，并在识别关键节点和拆解网络方面优于仅依赖结构的方法。


<details>
  <summary>Details</summary>
Motivation: 现有网络强度度量标准仅依赖结构属性，忽略了现实世界中（尤其是在执法领域）代理人对网络强度的感知，而这些感知与结构评估可能存在显著差异。

Method: 提出了一种结合了结构属性和人类感知的新强度度量方法，并通过人类受试者调查进行了验证。

Result: 该新度量标准与人类判断的一致性更高，并且在识别关键节点和拆解网络方面表现优于传统方法。

Conclusion: 所提出的新强度度量标准不仅与人类判断更吻合，而且在识别权威节点和有效拆解合成及真实网络方面优于传统方法。

Abstract: Dismantling criminal networks or containing epidemics or misinformation
through node removal is a well-studied problem. To evaluate the effectiveness
of such efforts, one must measure the strength of the network before and after
node removal. Process P1 is considered more effective than P2 if the strength
of the residual network after removing k nodes via P1 is smaller than that from
P2. This leads to the central question: How should network strength be
measured?
  Existing metrics rely solely on structural properties of the graph, such as
connectivity. However, in real-world scenarios, particularly in law
enforcement, the perception of agents regarding network strength can differ
significantly from structural assessments. These perceptions are often ignored
in traditional metrics.
  We propose a new strength metric that integrates both structural properties
and human perception. Using human subject surveys, we validate our approach
against existing metrics. Our metric not only aligns more closely with human
judgment but also outperforms traditional methods in identifying authoritative
nodes and effectively dismantling both synthetic and real-world networks.

</details>


### [216] [T3MAL: Test-Time Fast Adaptation for Robust Multi-Scale Information Diffusion Prediction](https://arxiv.org/abs/2507.12880)
*Wenting Zhu,Chaozhuo Li,Qingpo Yang,Xi Zhang,Philip S. Yu*

Main category: cs.SI

TL;DR: T3MAL是一个用于多尺度扩散预测的测试时间训练（TTT）框架，它通过自监督学习和元辅助学习来适应测试实例的分布变化，从而提高IDP任务的鲁棒性，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的信息扩散预测（IDP）方法通常遵循传统的训练-测试范式，该范式假设数据是独立同分布的。然而，在实际社交网络中，用户行为具有固有的不确定性和可变性，这使得该假设常常失效。本文解决了IDP任务中分布变化的新挑战。

Method: T3MAL框架的核心思想是通过一个自监督辅助任务，在测试时灵活地调整预训练模型以适应每个测试实例的分布，然后进行预测。具体来说，T3MAL引入了一个受BYOL启发的自监督辅助网络，该网络与主要的扩散预测网络共享一个通用的特征提取主干，以指导测试期间的实例特定适应。此外，T3MAL通过结合一种新颖的元辅助学习方案和一个轻量级适配器，实现了快速准确的测试时适应，从而为TTT提供更好的权重初始化并减轻灾难性遗忘。

Result: T3MAL在三个公开数据集上的广泛实验证明，其性能优于各种最先进的方法。

Conclusion: T3MAL在三个公开数据集上的广泛实验证明，其性能优于各种最先进的方法。

Abstract: Information diffusion prediction (IDP) is a pivotal task for understanding
how information propagates among users. Most existing methods commonly adhere
to a conventional training-test paradigm, where models are pretrained on
training data and then directly applied to test samples. However, the success
of this paradigm hinges on the assumption that the data are independently and
identically distributed, which often fails in practical social networks due to
the inherent uncertainty and variability of user behavior. In the paper, we
address the novel challenge of distribution shifts within IDP tasks and propose
a robust test-time training (TTT)-based framework for multi-scale diffusion
prediction, named T3MAL. The core idea is to flexibly adapt a trained model to
accommodate the distribution of each test instance before making predictions
via a self-supervised auxiliary task. Specifically, T3MAL introduces a
BYOL-inspired self-supervised auxiliary network that shares a common feature
extraction backbone with the primary diffusion prediction network to guide
instance-specific adaptation during testing. Furthermore, T3MAL enables fast
and accurate test-time adaptation by incorporating a novel meta-auxiliary
learning scheme and a lightweight adaptor, which together provide better weight
initialization for TTT and mitigate catastrophic forgetting. Extensive
experiments on three public datasets demonstrate that T3MAL outperforms various
state-of-the-art methods.

</details>


### [217] [The Centrality Paradox: Why Your Friends Are Always More Important](https://arxiv.org/abs/2507.13059)
*Rajat Subhra Hazra,Evgeny Verbitskiy*

Main category: cs.SI

TL;DR: The friendship paradox generalizes to network centrality measures, showing friends' centrality often exceeds one's own.


<details>
  <summary>Details</summary>
Motivation: We revisit the classical friendship paradox which states that on an average one's friends have at least as many friends as oneself and generalize it to a variety of network centrality measures.

Method: We show that the result follows from the variational characterisation of the eigenvector corresponding to the Perron eigenvalue.

Result: In particular, we show that for any irreducible, undirected graph G, the "friends-average" of degree, eigenvector-centrality, walk-count, Katz, and PageRank centralities exceeds the global average.

Conclusion: The 

Abstract: We revisit the classical friendship paradox which states that on an average
one's friends have at least as many friends as oneself and generalize it to a
variety of network centrality measures. In particular, we show that for any
irreducible, undirected graph $G$, the "friends-average" of degree,
eigenvector-centrality, walk-count, Katz, and PageRank centralities exceeds the
global average. We show that the result follows from the variational
characterisation of the eigenvector corresponding to the Perron eigenvalue.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [218] [Building State Machine Replication Using Practical Network Synchrony](https://arxiv.org/abs/2507.12792)
*Yiliang Wan,Nitin Shivaraman,Akshaye Shenoi,Xiang Liu,Tao Luo,Jialin Li*

Main category: cs.DC

TL;DR: 本文认为现代数据中心系统可以在常见情况下提供强同步特性，并设计了一个名为 Chora 的新复制协议，该协议利用网络同步特性，实现了显著的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心系统可以在常见情况下提供强同步特性，即服务器以同步的踱步轮次移动。

Method: 通过结合内核旁路网络、多线程架构和放宽的轮次长度，实现了 2us 以内的紧密轮次界限，证明了在常见情况下提供强同步特性的假设。

Result: 通过实验证明，Chora 协议实现了比现有单 leader 和多 leader 协议分别高 255% 和 109% 的吞吐量。

Conclusion: Chora协议利用网络同步特性，实现了比现有单 leader 和多 leader 协议分别高 255% 和 109% 的吞吐量。

Abstract: Distributed systems, such as state machine replication, are critical
infrastructures for modern applications. Practical distributed protocols make
minimum assumptions about the underlying network: They typically assume a
partially synchronous or fully asynchronous network model. In this work, we
argue that modern data center systems can be designed to provide strong
synchrony properties in the common case, where servers move in synchronous
lock-step rounds. We prove this hypothesis by engineering a practical design
that uses a combination of kernel-bypass network, multithreaded architecture,
and loosened round length, achieving a tight round bound under 2us. Leveraging
our engineered networks with strong synchrony, we co-design a new replication
protocol, Chora. Chora exploits the network synchrony property to efficiently
pipeline multiple replication instances, while allowing all replicas to propose
in parallel without extra coordination. Through experiments, we show that Chora
achieves 255% and 109% improvement in throughput over state-of-the-art
single-leader and multi-leader protocols, respectively.

</details>


### [219] [Autonomous Resource Management in Microservice Systems via Reinforcement Learning](https://arxiv.org/abs/2507.12879)
*Yujun Zou,Nia Qi,Yingnan Deng,Zhihao Xue,Ming Gong,Wuyang Zhang*

Main category: cs.DC

TL;DR: 提出一种基于强化学习的微服务资源调度方法，在低负载和高并发下提升了系统性能，并优化了资源利用率和能耗。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统微服务架构中存在的资源分配不均、延迟高、吞吐量不足等问题。

Method: 提出了一种基于强化学习的微服务资源调度和优化方法。

Result: 实验结果表明，基于强化学习的调度方法在低负载和高并发条件下显著提高了系统响应速度和吞吐量，并优化了资源利用率、降低了能耗。该方法能同时考虑多个目标，实现资源调度的优化。

Conclusion: 该方法通过实时调整资源分配策略，在动态变化负载和资源环境下能保持良好的系统性能，展现出比传统静态资源分配方法更强的适应性和优化能力。

Abstract: This paper proposes a reinforcement learning-based method for microservice
resource scheduling and optimization, aiming to address issues such as uneven
resource allocation, high latency, and insufficient throughput in traditional
microservice architectures. In microservice systems, as the number of services
and the load increase, efficiently scheduling and allocating resources such as
computing power, memory, and storage becomes a critical research challenge. To
address this, the paper employs an intelligent scheduling algorithm based on
reinforcement learning. Through the interaction between the agent and the
environment, the resource allocation strategy is continuously optimized. In the
experiments, the paper considers different resource conditions and load
scenarios, evaluating the proposed method across multiple dimensions, including
response time, throughput, resource utilization, and cost efficiency. The
experimental results show that the reinforcement learning-based scheduling
method significantly improves system response speed and throughput under low
load and high concurrency conditions, while also optimizing resource
utilization and reducing energy consumption. Under multi-dimensional resource
conditions, the proposed method can consider multiple objectives and achieve
optimized resource scheduling. Compared to traditional static resource
allocation methods, the reinforcement learning model demonstrates stronger
adaptability and optimization capability. It can adjust resource allocation
strategies in real time, thereby maintaining good system performance in
dynamically changing load and resource environments.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [220] [WaFusion: A Wavelet-Enhanced Diffusion Framework for Face Morph Generation](https://arxiv.org/abs/2507.12493)
*Seyed Rasoul Hosseini,Omid Ahmadieh,Jeremy Dawson,Nasser Nasrabadi*

Main category: cs.GR

TL;DR: WaFusion 是一种新的框架，结合了小波分解和扩散模型，用于生成高质量、逼真的面部融合图像，以应对生物特征面部融合对身份验证系统的挑战。


<details>
  <summary>Details</summary>
Motivation: 生物特征面部融合对身份验证系统构成了严峻的挑战，破坏了它们的安全性与鲁棒性。

Method: WaFusion 框架结合了小波分解和扩散模型，以有效地生成高质量、逼真的面部融合图像。它利用小波变换捕获的结构细节和扩散模型的生成能力，从而生成具有最少伪影的面部融合图像。

Result: 在 FERET、FRGC、FRLL 和 WVU Twin 数据集上进行的实验表明，WaFusion 在高分辨率和更少伪影方面优于最先进的方法。该框架在攻击呈现分类错误率 (APCER)、真实呈现分类错误率 (BPCER) 和相等错误率 (EER) 等关键生物特征指标方面表现出色。

Conclusion: WaFusion 框架在生物特征识别领域树立了新的基准，提供了一种尖端且高效的解决方案，以增强生物特征安全系统。

Abstract: Biometric face morphing poses a critical challenge to identity verification
systems, undermining their security and robustness. To address this issue, we
propose WaFusion, a novel framework combining wavelet decomposition and
diffusion models to generate high-quality, realistic morphed face images
efficiently. WaFusion leverages the structural details captured by wavelet
transforms and the generative capabilities of diffusion models, producing face
morphs with minimal artifacts. Experiments conducted on FERET, FRGC, FRLL, and
WVU Twin datasets demonstrate WaFusion's superiority over state-of-the-art
methods, producing high-resolution morphs with fewer artifacts. Our framework
excels across key biometric metrics, including the Attack Presentation
Classification Error Rate (APCER), Bona Fide Presentation Classification Error
Rate (BPCER), and Equal Error Rate (EER). This work sets a new benchmark in
biometric morph generation, offering a cutting-edge and efficient solution to
enhance biometric security systems.

</details>


### [221] [Wavelet-GS: 3D Gaussian Splatting with Wavelet Decomposition](https://arxiv.org/abs/2507.12498)
*Beizhen Zhao,Yifan Zhou,Sicheng Yu,Zijian Wang,Hao Wang*

Main category: cs.GR

TL;DR: 本研究提出了一种基于3D小波分解和2D采样的新型3D高斯泼溅框架，以解决复杂场景重建中的结构和光照问题，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法在复杂场景重建中面临挑战，表现为整体结构轮廓不完整和局部光照效果不清晰。为了同时解决这些问题，本研究提出了新的方法。

Method: 本研究提出了一种新颖的解耦优化框架，该框架将小波分解集成到3D高斯泼溅和2D采样中。具体来说，通过3D小波分解，将点云划分为高频和低频分量，从而实现对每个分量的定向优化。低频分量负责全局结构轮廓，并通过体素化管理高斯分布；高频分量则用于恢复精细的几何和纹理细节，并集成了一个重新照明模块来减轻光照伪影并增强照片级真实感渲染。此外，还对训练图像应用了2D小波分解，以模拟辐射度变化，这为高频细节重建提供了关键指导，确保细节与全局结构的无缝集成。

Result: 通过在具有挑战性数据集上的大量实验表明，本研究的方法在各项指标上均达到了最先进的性能，超越了现有方法，并推动了3D场景重建领域的发展。

Conclusion: 本研究提出的解耦优化框架通过结合小波分解和3D高斯泼溅技术，在3D场景重建方面取得了先进的性能，解决了现有方法的结构不完整和光照不清晰的问题。

Abstract: 3D Gaussian Splatting (3DGS) has revolutionized 3D scene reconstruction,
which effectively balances rendering quality, efficiency, and speed. However,
existing 3DGS approaches usually generate plausible outputs and face
significant challenges in complex scene reconstruction, manifesting as
incomplete holistic structural outlines and unclear local lighting effects. To
address these issues simultaneously, we propose a novel decoupled optimization
framework, which integrates wavelet decomposition into 3D Gaussian Splatting
and 2D sampling. Technically, through 3D wavelet decomposition, our approach
divides point clouds into high-frequency and low-frequency components, enabling
targeted optimization for each. The low-frequency component captures global
structural outlines and manages the distribution of Gaussians through
voxelization. In contrast, the high-frequency component restores intricate
geometric and textural details while incorporating a relight module to mitigate
lighting artifacts and enhance photorealistic rendering. Additionally, a 2D
wavelet decomposition is applied to the training images, simulating radiance
variations. This provides critical guidance for high-frequency detail
reconstruction, ensuring seamless integration of details with the global
structure. Extensive experiments on challenging datasets demonstrate our method
achieves state-of-the-art performance across various metrics, surpassing
existing approaches and advancing the field of 3D scene reconstruction.

</details>


### [222] [HairFormer: Transformer-Based Dynamic Neural Hair Simulation](https://arxiv.org/abs/2507.12600)
*Joy Xiaoji Zhang,Jingsen Zhu,Hanyu Chen,Steve Marschner*

Main category: cs.GR

TL;DR: 这是一个关于使用Transformer和交叉注意力机制模拟头发动态的AI方法，可以处理各种发型、身体形状和运动，并解决了穿模问题，实现了实时推理。


<details>
  <summary>Details</summary>
Motivation: 模拟能够泛化到任意发型、身体形状和运动的头发动态是一个关键挑战。

Method: 提出了一种新颖的两阶段神经解决方案，首次利用基于Transformer的架构实现广泛的[泛化]。具体而言，提出了一种基于Transformer的静态网络来预测任何发型的静态[ draped shapes]，有效解决头发与身体的[穿模]问题并保持头发的保真度。随后，一个具有新颖[交叉注意力机制]的动态网络将静态头发特征与运动学输入融合，以生成富有表现力的动态和复杂的[次级运动]。该动态网络还可以对[急动]等具有挑战性的运动序列进行高效的[微调]。

Result: 该方法在静态单帧[drapes]和动态[drapes] over pose sequences方面都实现了[实时]推理。

Conclusion: 该方法在各种发型、身体形状和运动中展现了高保真度和可推广的动态头发，并由物理信息损失指导，即使对于复杂、未见的[长发]也能解决[穿模]问题，突出了其广泛的[泛化]能力。

Abstract: Simulating hair dynamics that generalize across arbitrary hairstyles, body
shapes, and motions is a critical challenge. Our novel two-stage neural
solution is the first to leverage Transformer-based architectures for such a
broad generalization. We propose a Transformer-powered static network that
predicts static draped shapes for any hairstyle, effectively resolving
hair-body penetrations and preserving hair fidelity. Subsequently, a dynamic
network with a novel cross-attention mechanism fuses static hair features with
kinematic input to generate expressive dynamics and complex secondary motions.
This dynamic network also allows for efficient fine-tuning of challenging
motion sequences, such as abrupt head movements. Our method offers real-time
inference for both static single-frame drapes and dynamic drapes over pose
sequences. Our method demonstrates high-fidelity and generalizable dynamic hair
across various styles, guided by physics-informed losses, and can resolve
penetrations even for complex, unseen long hairstyles, highlighting its broad
generalization.

</details>


### [223] [VolSegGS: Segmentation and Tracking in Dynamic Volumetric Scenes via Deformable 3D Gaussians](https://arxiv.org/abs/2507.12667)
*Siyuan Yao,Chaoli Wang*

Main category: cs.GR

TL;DR: VolSegGS是一个创新的高斯泼溅框架，用于动态体积场景的交互式分割和跟踪，能够在低计算资源下实现实时可视化探索。


<details>
  <summary>Details</summary>
Motivation: 现有视点合成技术（如神经辐射场）在重建质量上表现优异，但在交互式可视化探索（如特征提取和跟踪）方面存在不足。为了在低端机器上实现有效可视化，需要一种能够支持交互式分割和跟踪的框架。

Method: 该方法使用可变形3D高斯来表示动态体积场景，并利用高斯的视点无关颜色进行粗分割，然后通过亲和力场网络进行细分割。通过将分割结果嵌入到高斯中，可以实现对分割区域的连续跟踪。

Result: 实验证明，VolSegGS在处理时变数据集时能有效支持交互式分割和跟踪，并且与现有方法相比具有优势，特别是在低计算需求下。

Conclusion: VolSegGS通过利用可变形3D高斯以及嵌入分割结果的机制，实现了动态体积场景的交互式分割和跟踪，在低计算需求下为时变体积数据的分析和可视化提供了强大的解决方案。

Abstract: Visualization of large-scale time-dependent simulation data is crucial for
domain scientists to analyze complex phenomena, but it demands significant I/O
bandwidth, storage, and computational resources. To enable effective
visualization on local, low-end machines, recent advances in view synthesis
techniques, such as neural radiance fields, utilize neural networks to generate
novel visualizations for volumetric scenes. However, these methods focus on
reconstruction quality rather than facilitating interactive visualization
exploration, such as feature extraction and tracking. We introduce VolSegGS, a
novel Gaussian splatting framework that supports interactive segmentation and
tracking in dynamic volumetric scenes for exploratory visualization and
analysis. Our approach utilizes deformable 3D Gaussians to represent a dynamic
volumetric scene, allowing for real-time novel view synthesis. For accurate
segmentation, we leverage the view-independent colors of Gaussians for
coarse-level segmentation and refine the results with an affinity field network
for fine-level segmentation. Additionally, by embedding segmentation results
within the Gaussians, we ensure that their deformation enables continuous
tracking of segmented regions over time. We demonstrate the effectiveness of
VolSegGS with several time-varying datasets and compare our solutions against
state-of-the-art methods. With the ability to interact with a dynamic scene in
real time and provide flexible segmentation and tracking capabilities, VolSegGS
offers a powerful solution under low computational demands. This framework
unlocks exciting new possibilities for time-varying volumetric data analysis
and visualization.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [224] [Competition Erases Simplicity: Tight Regret Bounds for Uniform Pricing with Multiple Buyers](https://arxiv.org/abs/2507.12733)
*Houshuang Chen,Yaonan Jin,Pinyan Lu,Chihao Zhang*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study repeated \textsf{Uniform Pricing} mechanisms with multiple buyers.
In each round, the platform sets a uniform price for all buyers; a transaction
occurs if at least one buyer bids at or above this price. Prior work
demonstrates that structural assumptions on bid distributions -- such as
regularity or monotone hazard rate (MHR) property -- enable significant
improvements in pricing query complexity (from
$\Theta\left(\varepsilon^{-3}\right)$ to
$\widetilde\Theta\left(\varepsilon^{-2}\right)$\footnote{The $\widetilde
\Theta$ notation omits polylogarithmic factors.}) and regret bounds (from
$\Theta\left(T^{2/3}\right)$ to $\widetilde\Theta\left(T^{1/2}\right)$) for
single-buyer settings. Strikingly, we demonstrate that these improvements
vanish with multiple buyers: both general and structured distributions
(including regular/MHR) share identical asymptotic performance, achieving
pricing query complexity of $\widetilde\Theta\left(\varepsilon^{-3}\right)$ and
regret of $\widetilde\Theta\left(T^{2/3}\right)$.
  This result reveals a dichotomy between single-agent and multi-agent
environments. While the special structure of distributions simplifies learning
for a single buyer, competition among multiple buyers erases these benefits,
forcing platforms to adopt universally robust pricing strategies. Our findings
challenge conventional wisdom from single-buyer theory and underscore the
necessity of revisiting mechanism design principles in more competitive
settings.

</details>


### [225] [Lower Bound for Online MMS Assignment of Indivisible Chores](https://arxiv.org/abs/2507.12984)
*Masoud Seddighin,Saeed Seddighin*

Main category: cs.GT

TL;DR: 研究了在线分配不可分割的分配问题，并将确定性算法的竞争比下界从 2 提高到 $n$。


<details>
  <summary>Details</summary>
Motivation: 解决在线划分不可分割的分配问题，并改进现有算法的竞争比下界。

Method: 通过证明任何确定性在线算法都不能获得比 $n$ 更好的竞争比来改进现有最坏情况的下界。

Result: 将确定性在线算法的竞争比下界从 2 提高到 $n$。 

Conclusion: 为 $n$ 个代理分配的确定性在线算法不能获得比 $n$ 更好的竞争比。

Abstract: We consider the problem of online assignment of indivisible chores under
\MMS\ criteria. The previous work proves that any deterministic online
algorithm for chore division has a competitive ratio of at least 2. In this
work, we improve this bound by showing that no deterministic online algorithm
can obtain a competitive ratio better than $n$ for $n$ agents.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [226] [Theoretical modeling of the dynamic range of an elastic nanobeam under tension with a geometric nonlinearity](https://arxiv.org/abs/2507.12609)
*N. W. Welles,M. Ma,K. L. Ekinci,M. R. Paul*

Main category: physics.app-ph

TL;DR: 本文研究了在固有张力下的纳米级梁的动力学。通过使用不同的模型（固定边界梁、弦模型、铰接边界梁）并与实验数据进行比较，研究了梁的动态范围和模式依赖动力学。研究结果可用于开发利用梁多模态动力学的新兴微观和纳米技术。


<details>
  <summary>Details</summary>
Motivation: 开发了在固有张力下的纳米级梁的弱非线性和依赖模式动力学的理论描述，并分析了梁在广泛条件下的动态范围。

Method: 使用梁模型（包括具有固定边界的梁、弦模型和具有铰接边界的梁）来分析纳米级梁的弱非线性和依赖模式动力学。

Result: 动态范围的下限由热运动引起的振动幅度决定，上限由大振幅振荡决定，此时由于拉伸引起的张力，几何非线性起着重要作用。研究结果表明，弯曲对于振动模态很重要，其重要性的出现取决于内应力量。

Conclusion: 悬臂梁模型提供了在多种条件下准确的描述，并带有有见地的闭式解析表达式。该分析确定了梁的依赖模式的动力学中弯曲和张力的相对重要性。对于高振动模态，弯曲很重要，其重要性的出现取决于存在的内应力量。理论预测与两个纳米级梁的前十个模态的实验测量结果直接比较。本研究讨论了这些方法的准确性及其在利用线性状态下小型弹性梁的多模态动力学的新兴微观和纳米技术开发中的应用。

Abstract: A theoretical description of the weakly nonlinear and mode-dependent dynamics
of a nanoscale beam that is under intrinsic tension is developed. A full
analysis of the dynamic range of the beam over a wide range of conditions is
presented. The dynamic range is bounded from below by the amplitude of
vibration due to thermal motion and it is bounded from above by large amplitude
oscillations where the geometric nonlinearity plays a significant role due to
stretching induced tension. The dynamics are analyzed using a beam with clamped
boundaries, a string model, and a beam with hinged boundaries. The range of
validity for the different models is quantified in detail. A hinged beam model
is found to provide an accurate description, with insightful closed-form
analytical expressions, over a wide range of conditions. The relative
importance of bending and tension in the mode-dependent dynamics of the beam is
determined. Bending is shown to be important for the higher modes of
oscillation with the onset of its importance dependent upon the amount of
intrinsic tension that is present. The theoretical predictions are directly
compared with experimental measurements for the first ten modes of two
nanoscale beams. We discuss the accuracy of these approaches and their use for
the development of emerging micro and nanoscale technologies that exploit the
multimodal dynamics of small elastic beams operating in the linear regime.

</details>


### [227] [Consistency analysis and nuclear data validation for two series of beryllium reflector critical benchmark experiments](https://arxiv.org/abs/2507.12757)
*Shengli Chen,Tianxiang Wang*

Main category: physics.app-ph

TL;DR: 本研究通过改进铍的(n,n)和(n,2n)反应次级角分布，提高了理论计算与临界基准实验的一致性（卡方值从7.58降至4.52），但两组实验间仍存在系统性差异，HMF-058可能比HMF-066更可靠。


<details>
  <summary>Details</summary>
Motivation: 为了解决在中子诱导核反应数据验证中，铍在两组相关但存在差异的临界基准实验HMF-058和HMF-066中表现出不一致的问题。

Method: 通过改进铍的(n,n)和(n,2n)反应的次级角分布，使用改进后的核数据进行理论计算，并与HMF-058和HMF-066两组快谱临界基准实验数据进行比较，分析计算值(C)与实验值(E)的一致性，评估累积卡方值和C/E值的系统性差异。

Result: 改进后的核数据使理论计算与HMF-058和HMF-066两组实验的一致性得到提高，累积卡方值从7.58降低到4.52（使用ENDF/B-VII.1），使用最新铀核数据评估后进一步降低至4.36。所有计算结果均在1西格玛实验不确定度内与实验测量值一致。然而，两组实验的C/E值之间仍存在230-330pcm的系统性差异，这与200-400pcm的实验不确定度相当，使得确定系统性差异的结论仍然具有挑战性。

Conclusion: 该研究通过改进铍的(n,n)和(n,2n)反应的次级角分布，提高了理论计算与两组关键快谱临界基准实验HMF-058和HMF-066的一致性，并将累积卡方值从7.58降低到4.52。虽然改进后的计算结果与实验测量值在1西格玛不确定度内一致，但两组实验之间仍然存在系统性差异（HMF-066比HMF-058低230-330pcm）。如果基于实验数据的铍差分核数据改进是准确的，那么HMF-058实验系列可能比HMF-066系列更可靠。

Abstract: Neutron-induced nuclear reaction data on beryllium playing a crucial role in
nuclear application. However, discrepancies have been observed in two closely
related series of beryllium-reflector fast-spectrum critical benchmark
experiments, HMF-058 and HMF-066, which are widely used in current nuclear data
validation. In this work, we address these inconsistencies by improving the
secondary angular distributions of the (n,n) and (n,2n) reactions of beryllium,
thereby making the theoretical calculations (C) and experimental results (E) of
these two series more consistent, and reducing the cumulative ${\chi^2}$ value
from 7.58 using the ENDF/B-VII.1 to 4.52. All calculations based on the
improved nuclear data agree with the experimental measurements within
1${\sigma}$ experimental uncertainty. Based on the latest comprehensive
evaluation of uranium nuclear data, this consistency is slightly improved, and
the cumulative ${\chi^2}$ value decreases to 4.36 once again. Despite these
advances, systematic differences in the expected values of C/E between the two
series still exist. The C/E values of the HMF-066 series are generally 230-330
pcm lower than those of the HMF-058 series, comparable to their experimental
uncertainties of 200-400 pcm. Therefore, drawing a definitive conclusion about
this systematic difference remains challenging. If the current improvement of
differential nuclear data based on experimental data of ${^9}$Be is accurate,
then the HMF-058 series experiments seem to be more reliable than the HMF-066
series.

</details>


### [228] [Wireless Multi-Port Sensing: Virtual-VNA-Enabled De-Embedding of an Over-the-Air Fixture](https://arxiv.org/abs/2507.12909)
*Philipp del Hougne*

Main category: physics.app-ph

TL;DR: A technique is presented to determine the scattering parameters of a multi-port device over the air using backscatter modulation and a Virtual VNA approach. The method involves characterizing the test fixture, measuring the device under test, and de-embedding the results. Experiments were conducted at 2.45 GHz for 1-port and 5-port devices in a reverberation chamber, analyzing the impact of various system parameters. The technique has potential applications in RFID and wireless bioelectronics.


<details>
  <summary>Details</summary>
Motivation: To determine, over the air (OTA), the scattering parameters of a linear, passive, time-invariant multi-port device under test (DUT).

Method: We develop a multi-port-backscatter-modulation technique. A set of "not-directly-accessible" (NDA) antennas can be switched between being terminated by the DUT or by a specific, known, tunable load network. Waves can be radiated and captured via a distinct set of "accessible" antennas that couple OTA to the NDA antennas. First, we characterize the OTA fixture between the accessible antennas' ports and the DUT's ports based on our "Virtual VNA" technique. Second, we connect the NDA antennas to the DUT and measure the scattering at the accessible antennas' ports. Third, we de-embed the OTA fixture to retrieve the DUT's scattering parameters.

Result: We systematically study the influence of the number of accessible antennas and various conceivable simplifications in terms of the system model as well as the properties of the tunable load network.

Conclusion: We experimentally validate our technique at 2.45 GHz for 1-port DUTs and 5-port DUTs, considering a rich-scattering OTA fixture inside a reverberation chamber. Our wireless multi-port sensing technique can find applications in areas like RFID and wireless bioelectronics.

Abstract: We develop a multi-port-backscatter-modulation technique to determine, over
the air (OTA), the scattering parameters of a linear, passive, time-invariant
multi-port device under test (DUT). A set of "not-directly-accessible" (NDA)
antennas can be switched between being terminated by the DUT or by a specific,
known, tunable load network. Waves can be radiated and captured via a distinct
set of "accessible" antennas that couple OTA to the NDA antennas. First, we
characterize the OTA fixture between the accessible antennas' ports and the
DUT's ports. We achieve this based on our recently introduced "Virtual VNA"
technique; specifically, we connect the NDA antennas to the tunable load
network and measure the scattering at the accessible antennas' ports for
various configurations of the tunable load network. Second, we connect the NDA
antennas to the DUT and measure the scattering at the accessible antennas'
ports. Third, we de-embed the OTA fixture to retrieve the DUT's scattering
parameters. We experimentally validate our technique at 2.45 GHz for 1-port
DUTs and 5-port DUTs, considering a rich-scattering OTA fixture inside a
reverberation chamber. We systematically study the influence of the number of
accessible antennas and various conceivable simplifications in terms of the
system model as well as the properties of the tunable load network. Our
wireless multi-port sensing technique can find applications in areas like RFID
and wireless bioelectronics.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [229] [Nonreciprocal magnetic-field-induced second harmonic generation of exciton polaritons in ZnSe](https://arxiv.org/abs/2507.12572)
*J. Mund,D. R. Yakovlev,A. Farenbruch,N. V. Siverin,M. A. Semina,M. M. Glazov,E. L. Ivchenko,M. Bayer*

Main category: cond-mat.mes-hall

TL;DR: 研究了磁场下ZnSe晶体的二次谐波光学性质，首次观察到非倒易现象。


<details>
  <summary>Details</summary>
Motivation: 研究磁场对半导体晶体中激子-极化激子共振光学性质的影响，特别是观察非倒易现象。

Method: 在垂直于光波矢量k（沃伊特几何）的外部磁场作用下，对块状ZnSe的1S激子-极化激子共振进行二次谐波（SHG）光学测量。

Result: 在k || [111]晶轴的允许对称几何中，观察到二次谐波强度对磁场方向的非倒易依赖性，并通过干涉现象进行了解释，同时评估了信号的相对相位。

Conclusion: 首次在半导体晶体和激子-极化激子中观察到非倒易的二次谐波，并通过现象学和微观模型进行了理论解释。

Abstract: We report on the optical second harmonic generation (SHG) on the 1S
exciton-polariton resonance in bulk ZnSe that is subject to an external
magnetic field applied perpendicular to the light wave vector $\mathbf k$
(Voigt geometry). For the symmetry allowed geometry with the
$\mathbf{k}\parallel[111]$ crystal axes, the nonreciprocal dependence of the
SHG intensity on the magnetic field direction is found. It is explained by an
interference of the crystallographic and magnetic-field-induced SHG signals.
Relative phases of these signals are evaluated from the rotational anisotropy
diagrams. Phenomenological and microscopic models of the effect are developed.
To the best of our knowledge, this is the first experimental observation of the
nonreciprocal SHG in semiconductor crystals, and the first one for
exciton-polaritons.

</details>


### [230] [Spin Polarization driven by Itinerant Orbital Angular Momentum in van der Waals Heterostructures](https://arxiv.org/abs/2507.12587)
*Luis M. Canonico,Jose H. García,Aron W. Cummings,Stephan Roche*

Main category: cond-mat.mes-hall

TL;DR: 利用载流子轨道角动量（OAM）在范德华异质结构中产生面外自旋极化，可高效电控磁性，适用于低功耗存储器件。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索一种新的、高效的电控磁性机制，以满足低功耗、超紧凑型存储器件的需求。研究关注于利用载流子轨道角动量（OAM）在范德华异质结构中产生面外自旋极化，以期实现对磁性材料的精确操控。

Method: 本研究采用实空间形式的OAM算符和线性响应理论，分析了在低对称性TMD单层材料（如1T_d-MoTe2）中，载流子OAM如何被电流驱动并产生面外自旋极化。研究还探讨了当TMD与固有轨道响应可忽略的铁磁体耦合时，界面处的OAM如何转移并诱导铁磁体内部的磁化动力学。

Result: 研究发现，在1T_d-MoTe2等TMD单层材料中，电流诱导的载流子OAM比自旋响应高出三个数量级。当TMD与低轨道响应铁磁体结合时，界面处的OAM转移能够有效地在铁磁体内部产生自旋密度，进而驱动磁化动力学。

Conclusion: 本研究揭示了在低对称性过渡金属硫化物（TMD）单层材料中，载流子轨道角动量（OAM）在产生面外自旋极化方面的重要作用，并提出了一种通过这种机制高效调控磁性的新方法，有望应用于低功耗、超紧凑型存储器件。

Abstract: We report on the possibility of manipulating magnetic materials by using
itinerant orbital angular momentum to produce out-of-plane spin polarization in
van der Waals heterostructures. Employing a real-space formulation of the OAM
operator within linear response theory, we demonstrate that in low-symmetry
transition-metal dichalcogenide (TMD) monolayers, such as 1$T{}_d$-MoTe2, the
current-induced itinerant OAM exceeds the spin response by three orders of
magnitude. When TMDs are coupled with ferromagnets with negligible intrinsic
orbital responses, the itinerant OAM generated by the orbital Rashba-Edelstein
effect transfers across the interface, generating spin densities capable of
inducing magnetization dynamics inside the ferromagnet. Our findings highlight
the previously overlooked role of itinerant OAM in the generation of
out-of-plane spin densities, which serves as an emerging mechanism for
efficient electrical control of magnetization in low-power, ultracompact
storage devices.

</details>


### [231] [Spin relaxation in a polariton fluid: quantum hydrodynamic approach](https://arxiv.org/abs/2507.12636)
*D. A. Saltykova,A. V. Yulin,I. A. Shelykh*

Main category: cond-mat.mes-hall

TL;DR: 腔极化激子是量子微腔中的基本激发，具有独特的自旋结构和强非线性响应，但缺乏描述自旋弛豫的数学形式。本文提出一种基于量子流体动力学的方法，推导出包含能量和自旋弛豫项的方程，并分析了这些项对旋量极化激子液滴动力学和均匀极化激子凝聚体激发的色散的影响。该方法也可应用于其他自旋玻色子凝聚体系统。


<details>
  <summary>Details</summary>
Motivation: 腔极化激子是强耦合状态下量子微腔中的基本激发，它们揭示了量子集体行为的清晰特征。其独特的自旋结构和强非线性响应相结合，为直接实验观察大量非平凡的光学极化现象提供了可能性。自旋弛豫过程至关重要，但目前缺乏相干描述的数学形式。

Method: 本文基于量子流体动力学方法，对两分量液体进行了推导，其中能量和自旋弛豫项自然出现。

Result: 分析了这些项如何影响外部磁场中旋量极化激子液滴的动力学以及均匀极化激子凝聚体中基本激发的色散。

Conclusion: 该方法也适用于其他重要的自旋玻色子凝聚体系统，如气体和原子。

Abstract: Cavity polaritons, the elementary excitations appearing in quantum
microcavities in the strong-coupling regime, reveal clear signatures of quantum
collective behavior. The combination of unique spin structure and strong
nonlinear response opens the possibility of direct experimental observation of
a plethora of nontrivial optical polarization phenomena. Spin relaxation
processes are of crucial importance here. However, a mathematical formalism for
their coherent description is still absent. In the present paper, based on the
quantum hydrodynamics approach for a two-component liquid, we derive the set of
the corresponding equations where both energy and spin relaxation terms appear
naturally. We analyze in detail how these terms affect the dynamics of spinor
polariton droplets in the external magnetic field and the dispersion of
elementary excitations of a uniform polariton condensate. Although we focus on
the case of cavity polaritons, our approach can be applied to other cases of
spinor bosonic condensates, where the processes of spin relaxation play a major
role.

</details>


### [232] [Enhancement of Indistinguishable Photon Emission from a GaAs Quantum Dot via Charge Noise Suppression](https://arxiv.org/abs/2507.12641)
*Priyabrata Mudi,Avijit Barua,Kartik Gaur,Steffen Wilksen,Alexander Steinhoff,Setthanat Wijitpatima,Sarthak Tripathi,Julian Ritzmann,Andreas D. Wieck,Sven Rodt,Christopher Gies,Arne Ludwig,Stephan Reitzenstein*

Main category: cond-mat.mes-hall

TL;DR: This paper presents a method to reduce errors in quantum technology caused by charge noise in quantum dots. By applying an electrical field, they stabilized the quantum dots, achieving high fidelity quantum operations and a long dephasing time, which are crucial for building quantum networks and computers.


<details>
  <summary>Details</summary>
Motivation: Spectral jitter caused by charge noise in epitaxial quantum dots limits their practical use in quantum applications like quantum repeater networks and distributed quantum computing. This work aims to mitigate charge noise-induced decoherence in GaAs quantum dots.

Method: A straightforward approach using droplet-etched GaAs quantum dots embedded in an n-i-p diode structure integrated into a circular Bragg grating resonator was employed. Charge noise-induced decoherence was mitigated by applying an external electrical field, and device performance was evaluated using Hong-Ou-Mandel two-photon interference measurements and voltage-dependent linewidth measurements.

Result: The quantum device achieved a photon extraction efficiency of approximately (37 ± 2)%. Hong-Ou-Mandel measurements showed a strong voltage dependence of exciton dephasing time and interference visibility. The visibility reduction followed an inverse square dependence (proportional to 1/I²) with increasing diode current (I). A maximum exciton dephasing time (T2*) of approximately (6.8 ± 0.5) ns was achieved, nearing the Fourier limit without complex echo schemes.

Conclusion: The study demonstrates optimized electrical control of exciton dephasing in GaAs quantum dots by stabilizing the charge environment using an external electrical field, achieving a maximum exciton dephasing time of (6.8 ± 0.5) ns and 97% interference visibility, consistent with theoretical predictions.

Abstract: The generation of indistinguishable single photons is a fundamental
requirement for future quantum technologies, particularly in quantum repeater
networks and for distributed quantum computing based on entanglement
distribution. However, spectral jitter, often induced by charge noise in
epitaxial quantum dots, leads to exciton dephasing, thereby limiting their
practical usage in quantum applications. We present a straightforward approach
to mitigate charge noise-induced decoherence in droplet-etched GaAs quantum
dots embedded in an n-i-p diode structure and integrated deterministically into
an electrically contacted circular Bragg grating resonator for emission
enhancement. The quantum device allows for the stabilization of the charge
environment by applying an external electrical field while producing a photon
extraction efficiency of approximately (37 +- 2)%. Hong-Ou-Mandel two-photon
interference measurements reveal a strong voltage dependence of the exciton
dephasing time and interference visibility on the applied bias in excellent
agreement with our theoretical predictions. Notably, the reduction in
visibility from a maximum, charge-stabilized corrected value of 97 percent at
the optimum bias point follows an inverse square dependence (proportional to
1/I^2) with increasing diode current (I) in forward direction. Under a
quasi-resonant excitation scheme, we achieve a maximum exciton dephasing time
(T2*) of approximately (6.8 +-0.5) ns, reaching nearly the Fourier limit (T2 =
2T1) without the need for complex echo schemes like Ramsey or
Carr-Purcell-Meiboom-Gill sequences. These findings are consistent with
theoretical predictions from rate equation modeling and quantum optical
analysis as well as voltage-dependent linewidth measurements, demonstrating
optimized electrical control of exciton dephasing.

</details>


### [233] [Collinear Antiferromagnetic Tunnel Junctions Implemented in Van der Waals Heterostructures](https://arxiv.org/abs/2507.12735)
*Wei-Min Zhao,Yi-Lun Liu,Liu Yang,Cheng Tan,Yuanjun Yang,Zhifeng Zhu,Meixia Chen,Tingting Yan,Rong Hu,James Partridge,Guopeng Wang,Mingliang Tian,Ding-Fu Shao,Lan Wang*

Main category: cond-mat.mes-hall

TL;DR: 这项研究成功制造了反铁磁隧道结（AFMTJ），实现了75%的隧道磁电阻（TMR）比，性能媲美传统磁隧道结（MTJ），并提出了一种新的界面驱动的自旋极化传输机制，为反铁磁（AFM）自旋电子学提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 为了提升自旋电子器件的速度和集成密度，研究人员探索使用反铁磁（AFM）材料替代传统的铁磁（FM）材料来构建磁隧道结（MTJ）。

Method: 研究人员利用范德华A型反铁磁金属（Fe0.6Co0.4）5GeTe2（FCGT）电极和非磁性半导体WSe2隧道势垒，构建了全共线反铁磁隧道结（AFMTJ）异质结构器件。通过磁场切换，实现了高达75%的隧道磁电阻（TMR）比。研究人员还通过调控FCGT电极的层数（偶层或奇层）来选择性地实现易失性或非易失性TMR。实验和理论分析揭示了与界面驱动的自旋极化传输相关的新TMR机制，尽管FCGT体材料本身具有自旋无关的特性。

Result: 成功制备了全共线反铁磁隧道结（AFMTJ），实现了高达75%的隧道磁电阻（TMR）比。结果表明，TMR完全出现在FCGT的反铁磁（AFM）状态下，而非反铁磁-铁磁（AFM-FM）转变过程中。通过改变FCGT电极的层数配置（偶层或奇层），可以实现易失性或非易失性的TMR，这与界面效应相关。偶层器件中的TMR源于Néel矢量切换，而奇层器件中的TMR则源于界面自旋翻转。研究揭示了一种新的TMR机制，该机制与界面驱动的自旋极化传输有关，即使在FCGT体材料的自旋无关特性的情况下也是如此。

Conclusion: 该研究展示了全共线反铁磁隧道结（AFMTJ）的性能可与传统磁隧道结（MTJ）相媲美，并为反铁磁（AFM）自旋电子学开辟了新途径，通过利用AFM界面的自旋相关特性。

Abstract: Magnetic tunnel junctions (MTJs) are crucial components in high-performance
spintronic devices. Traditional MTJs rely on ferromagnetic (FM) materials but
significant improvements in speed and packing density could be enabled by
exploiting antiferromagnetic (AFM) compounds instead. Here, we report
all-collinear AFM tunnel junctions (AFMTJs) fabricated with van der Waals
A-type AFM metal (Fe0.6Co0.4)5GeTe2 (FCGT) electrodes and nonmagnetic
semiconducting WSe2 tunnel barriers. The AFMTJ heterostructure device achieves
a tunneling magnetoresistance (TMR) ratio of up to 75% in response to magnetic
field switching. Our results demonstrate that the TMR exclusively emerges in
the AFM state of FCGT, rather than during the AFM-to-FM transition. By
engineering FCGT electrodes with either even- or odd-layer configurations,
volatile or non-volatile TMR could be selected, consistent with an entirely
interfacial effect. TMR in the even-layer devices arose by N\'eel vector
switching. In the odd-layer devices, TMR stemmed from interfacial
spin-flipping. Experimental and theoretical analyses reveal a new TMR mechanism
associated with interface-driven spin-polarized transport, despite the
spin-independent nature of bulk FCGT. Our work demonstrates that all-collinear
AFMTJs can provide comparable performance to conventional MTJs and introduces a
new paradigm for AFM spintronics, in which the spin-dependent properties of AFM
interfaces are harnessed.

</details>


### [234] [Magnetoelectric multiferroics: from fundamentals to transformative applications -- a mini review](https://arxiv.org/abs/2507.12867)
*Michał Wanic*

Main category: cond-mat.mes-hall

TL;DR: 本文回顾了多铁材料及其在传感器、射频设备、量子计算和能源等领域的应用，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 多铁材料结合了铁电和磁性序，能够实现磁电（ME）耦合，从而在先进应用中发挥作用。

Method: 本文回顾了单相和复合多铁材料，并研究了驱动磁电效应的现象学、微观、纳米结构和量子机制。现象学模型量化了耦合系数，微观方法揭示了包括受阻自旋态和德热松-莫里亚贡献在内的自旋-晶格相互作用。纳米结构系统，如等离激元斯格明子晶格和超表面，增强了磁电效应，可实现可调双折射和电磁波放大。量子热机利用手征链和斯格明子晶格中的自旋纠缠和拓扑保护来实现高效能量转换。

Result: 应用包括高灵敏度磁传感器、可调谐射频设备、高能效ME-RAM、能量收集器、量子热机和热二极管。

Conclusion: 未来的研究重点是优化室温下的多铁性耦合、可扩展性、相干性和生物相容性，以推动传感、量子计算和可持续能源领域的创新。

Abstract: Multiferroics, combining ferroelectric and magnetic orders, enable
magnetoelectric (ME) coupling for advanced applications. This mini review
explores single-phase and composite multiferroics, examining phenomenological,
microscopic, nanostruc-tured, and quantum mechanisms driving ME effects.
Phenomenological models quantify coupling coefficients, while microscopic
approaches reveal spin-lattice in-teractions, including frustrated spin states
and Dzyaloshinskii-Moriya contributions. Nanostructured systems, such as
plasmonic skyrmion lattices and metasurfaces, en-hance ME effects for tunable
birefringence and electromagnon amplification. Quan-tum heat engines utilize
spin entanglement and topological protection in chiral chains and skyrmion
lattices for efficient energy conversion. Applications include high-sensitivity
magnetic sensors, tunable radio-frequency devices, energy-efficient MERAM,
energy harvesters, quantum heat engines, and thermal diodes. Future re-search
aims to optimize room-temperature ME coupling, scalability, coherence, and
biocompatibility for innovations in sensing, quantum computing, and sustainable
energy.

</details>


### [235] [Probing nontrivial fusion of Majorana zero modes via near-adiabatic coupling](https://arxiv.org/abs/2507.12772)
*Jing Bai,Luting Xu,Wei Feng,Xin-Qi Li*

Main category: cond-mat.mes-hall

TL;DR: 提出了一种近绝热耦合探测方案，用于融合Majorana零模，简化了测量过程，并能提取关键信息。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有方案的复杂性，我们提出了一种新的探测方案。

Method: 提出并模拟了一种近绝热耦合探测方案，用于非平凡地融合一对Majorana零模（MZM）。

Result: 展示了如何从具有确定费米子奇偶性的初始状态中提取融合过程中非绝热跃迁和费米子奇偶性破坏的信息。

Conclusion: 该方案可以避免探测量子点中电荷占有的振荡复杂性，从而使实际测量更具可行性。

Abstract: We propose and simulate a near-adiabatically coupling probing scheme for
nontrivial fusion of a pair of Majorara zero modes (MZMs). The scheme can avoid
the complexity of oscillating charge occupation in the probing quantum dot,
making thus practical measurements more feasible. We also show how to extract
the information of nonadiabatic transition and fermion parity violation caused
during moving the MZMs together to fuse, from the initial states prepared with
definite fermion parity. All the simulations, including the effective coupling
between the fusing MZMs, and their coupling to the probing quantum dot, are
based on the lattice model of a Rashba quantum wire in proximity contact with
an s-wave superconductor, under the modulation of mini-gate voltage control.

</details>


### [236] [Three-dimensional spinless Euler insulators with rotational symmetry](https://arxiv.org/abs/2507.12783)
*Manabu Sato,Shingo Kobayashi,Motoaki Hirayama,Akira Furusaki*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了三维绝缘体中的欧拉类不变量，重点关注 $C_{4z}$ 或 $C_{6z}$ 对称性下的情况，并建立了欧拉类与能带旋转特征值之间的联系。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究具有欧拉类不变量的三维无自旋绝缘体，并探索当存在额外的 $C_{4z}$ 或 $C_{6z}$ 旋转对称性时，欧拉类与占据能带的旋转特征值之间的关系。

Method: 本文首先在二维系统中阐明了实贝里连接和曲率在晶系操作下的变换规则，并利用相应的缝合矩阵，推导了欧拉类与高对称点处旋转特征值之间关系的显式公式。随后，将分析扩展到三维系统，重点研究了两个 $C_{2z}T$ 不变平面之间欧拉类的差异，并得到了欧拉类差异与两种受表示保护的不变量之间关系的解析表达式。

Result: 研究结果揭示了欧拉类与旋转特征值之间的显式公式和解析表达式，并通过构建紧束缚模型和进行数值计算，阐明了体-边界对应关系。

Conclusion: 该研究扩展了二维欧拉类不变量的概念，将其应用于三维系统，并揭示了其与高对称点处的旋转特征值之间的关系，同时考虑了 $C_{4z}$ 或 $C_{6z}$ 对称性。

Abstract: The Euler class is a $\mathbb{Z}$-valued topological invariant that
characterizes a pair of real bands in a two-dimensional Brillouin zone. One of
the symmetries that permits its definition is $C_{2z}T$, where $C_{2z}$ denotes
a twofold rotation about the $z$ axis and $T$ denotes time-reversal symmetry.
Here, we study three-dimensional spinless insulators characterized by the Euler
class, focusing on the case where additional $C_{4z}$ or $C_{6z}$ rotational
symmetry is present, and investigate the relationship between the Euler class
of the occupied bands and their rotation eigenvalues. We first consider
two-dimensional systems and clarify the transformation rules for the real Berry
connection and curvature under point group operations, using the corresponding
sewing matrices. Applying these rules to $C_{4z}$ and $C_{6z}$ operations, we
obtain explicit formulas that relate the Euler class to the rotation
eigenvalues at high-symmetry points. We then extend our analysis to
three-dimensional systems, focusing on the difference in the Euler class
between the two $C_{2z}T$-invariant planes. We derive analytic expressions that
relate the difference in the Euler class to two types of
representation-protected invariants and analyze their phase transitions. We
further construct tight-binding models and perform numerical calculations to
support our analysis and elucidate the bulk-boundary correspondence.

</details>


### [237] [Coulomb-mediated single-electron heat transfer statistics across capacitively coupled silicon nanodots](https://arxiv.org/abs/2507.12799)
*Kensaku Chida,Antoine Andrieux,Katsuhiko Nishiguchi*

Main category: cond-mat.mes-hall

TL;DR: 本文实验研究了硅纳米点中的单电子动力学，以量化纳尺度上的库仑介导热传递，并为探索器件功能和验证非平衡态下的普适关系提供了统计数据。


<details>
  <summary>Details</summary>
Motivation: 虽然已报道了一些利用库仑介导热传递现象的实验演示，但对其效率等性能的估算及其理论评估，需要对传递机制本身的质量进行评估，而这仍然具有挑战性。

Method: 通过交叉相关测量估计点间的库仑相互作用强度，并将单电子动力学转换为库仑介导的热传递的统计数据。

Result: 在平衡状态下进行实验，得到了点之间净零波动热传递，这些热传递统计数据对于从随机热力学的角度探索器件功能和验证非平衡态下的普适关系至关重要。

Conclusion: 通过对两个静电耦合的硅纳米点中的单电子动力学进行实验研究，量化了纳尺度上的库仑介导的热传递。

Abstract: Heat transfer mediated by the Coulomb interaction reveals unconventional
thermodynamic behavior and broadens thermodynamics research into fields such as
quantum dynamics and information engineering. Although some experimental
demonstrations of phenomena utilizing Coulomb-mediated heat transfer have been
reported, estimations of their performance, such as efficiency, and their
theoretical evaluations necessitate qualitative evaluation of the transfer
mechanism itself, which remains challenging. We present an experiment
investigating single-electron dynamics in two electrostatically coupled silicon
nanodots to quantify Coulomb-mediated heat transfer at the nanoscale. By
estimating the Coulomb interaction strength between the dots using the
cross-correlation measurements of the single-electron dynamics, we convert the
single-electron dynamics into the statistics of Coulomb-mediated heat transfer.
Conducting the experiment at equilibrium enabled us to obtain a fluctuating
net-zero heat transfer between the dots. These heat transfer statistics are
essential for exploring device functionalities from the perspective of
stochastic thermodynamics and for verifying universal relations in
nonequilibrium states.

</details>


### [238] [Harmonic generation of graphene quantum dots in Hartree-Fock approximation](https://arxiv.org/abs/2507.12982)
*Kainan Chang,Ying Song,Yuwei Shan,Jin Luo Cheng*

Main category: cond-mat.mes-hall

TL;DR: 石墨烯量子点的激子效应显著增强了光学响应，并且其谐波产生具有高度的可调性，这使得它们在非线性光学器件方面具有应用前景。


<details>
  <summary>Details</summary>
Motivation: 理论研究线偏振光脉冲在石墨烯量子点中的谐波产生，特别是激子效应。

Method: 结合紧束缚模型和单粒子密度矩阵方法，在静态屏蔽的Hartree-Fock近似下推导出半导体Bloch方程，该方程用局域Hartree势和非局域Fock势来表征电子-电子相互作用。

Result: 分析了不同近似方法对电子能级、线性光学吸收和非线性谐波产生的影响。在激子效应下，研究了谐波产生对石墨烯量子点几何形状（尺寸、三角形/六边形、锯齿/扶手椅边缘）以及电场幅度/偏振的依赖性。结果表明，激子效应显著增强了石墨烯纳米结构的optical response。对于由随机取向的石墨烯量子点组成的点系综，仅在入射光偏振方向上存在奇次谐波。

Conclusion: 石墨烯量子点中的谐波产生具有高度的可调性，这使得它们在非线性光学器件方面具有应用前景。

Abstract: We theoretically investigate harmonic generation in graphene quantum dots
under linearly polarized optical pulses, focusing on excitonic effects.
Combining the tight-binding model and the single-particle density matrix
approach, we derive a semiconductor Bloch equation under a static-screened
Hartree-Fock approximation. This framework characterizes the electron-electron
interaction through local Hartree potentials for direct Coulomb interaction and
nonlocal Fock potentials for exchange interaction. Distinct confgurations of
Hartree and Fock terms yield various approximation methods, including
independent-particle approximation, mean-feld approximation, random phase
approximation, and excitonic effects. We thoroughly analyze how these
approximation methods affect the electronic energy levels, linear optical
absorption, and nonlinear harmonic generation. Within excitonic effects, we
present the dependence of harmonic generation on the geometric variations of
graphene quantum dots (sizes, triangular/hexagonal shapes, and armchair/zigzag
edges) and the amplitude and polarization of electric fields. Our findings show
that excitonic effects significantly enhance optical responses of graphene
nanostructures. For a dot ensemble formed by randomly oriented graphene quantum
dots,
  only odd-order harmonics exist along the polarization direction of the
incident light. Crucially, harmonic generation in graphene quantum dots
exhibits high tunability via geometric configuration, making them promising
candidates for nonlinear optical nanodevices.

</details>


### [239] [Enhanced Phonon-Assisted Tunneling in Metal -- Twisted Bilayer Graphene Junctions](https://arxiv.org/abs/2507.12991)
*Radhika Soni,Suvronil Datta,Robin Bajaj,Saisab Bhowmik,Shinjan Mandal,Baladitya Suri,Kenji Watanabe,Takashi Taniguchi,Manish Jain,U. Chandni*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We report planar tunneling spectroscopy measurements on metal-WSe$_2$-twisted
bilayer graphene heterostructures across a broad range of gate and bias
voltages. The observed experimental features are attributed to phonon-assisted
tunneling and the significantly high density of states within the moir\'e
bands. A notable finding is the enhanced phonon-assisted tunneling in twisted
bilayer graphene compared to Bernal bilayer graphene, which arises from a more
relaxed in-plane momentum matching criterion. Theoretical calculations of
phonon dispersions enable us to identify low-energy phonon modes in both Bernal
and twisted bilayers of graphene, thereby elucidating the underlying mechanism
of tunneling. Our results establish planar tunneling as a versatile tool to
further understand electron-phonon coupling in twisted van der Waals materials.

</details>


### [240] [Ultrafast thermal boundary conductance under large temperature discontinuities of ultrathin epitaxial Pb films on Si(111)](https://arxiv.org/abs/2507.13109)
*Christian Brand,Tobias Witte,Mohammad Tajik,Jonas D. Fortmann,Birk Finke,Michael Horn-von Hoegen*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用超快电子衍射研究了Pb薄膜到Si衬底的热传递，发现界面形貌对导温系数有重要影响。


<details>
  <summary>Details</summary>
Motivation: 电子学的散热是影响器件性能的关键因素，在纳米尺度结构中，界面处的 finite thermal boundary conductance 限制了材料间的热传递。

Method: 使用超快电子衍射在强非平衡条件下研究了超薄外延Pb薄膜到Si(111)衬底的热传递。

Result: 在大的温差下，Pb薄膜的冷却速度随激发强度的增加而加快，其冷却时间常数随着Pb薄膜的激发强度增加而减小。导温系数的降低与汲取模型有关。与H端接衬底相比，导温系数降低了3倍以上。

Conclusion: 使用超快电子衍射在强非平衡条件下研究了超薄外延Pb薄膜到Si(111)衬底的热传递。结果表明，在大的温差下，Pb薄膜的冷却速度随激发强度的增加而加快，这可以通过热导边界的耗散失配模型来解释。与生长在H端接衬底上的Pb薄膜相比，热导边界的导温系数降低了三倍以上，这表明衬底、薄膜及其界面的形貌对热传递至关重要。

Abstract: Heat transfer is a critical aspect of modern electronics, and a deeper
understanding of the underlying physics is essential for building faster,
smaller, and more powerful devices with an improved performance and efficiency.
In such nanoscale structures the heat transfer between two materials is limited
by the finite thermal boundary conductance across their interface. Using
ultrafast electron diffraction under grazing incidence we investigated the heat
transfer from ultrathin epitaxial Pb films to an Si(111) substrate under strong
non-equilibrium conditions. Applying an intense femtosecond laser pulse, the
5-7 ML thin Pb film experiences a strong heat up by 10-120 K while the Si
substrate remains cold at $\approx$ 10 K. At such large temperature
discontinuities we observe a significantly faster cooling for stronger excited
Pb films. The decrease of the corresponding cooling time constant is explained
through the thermal boundary conductance in the framework of the diffuse
mismatch model. The thermal boundary conductance is reduced by more than a
factor of three in comparison with Pb films grown on H-terminated substrates,
pointing out the importance of the morphology of substrate, film and their
interface.

</details>


### [241] [Comparative Study of Strain-Engineered Thermoelectric Performance of 2D-Xene Nanoribbons](https://arxiv.org/abs/2507.13132)
*Kalpana Panneerselvam,Swastik Sahoo,Bhaskaran Muralidharan*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过分析五种二维材料（石墨烯、硅烯、锗烯、锡烯和磷烯）的纳米带的热电性能，确定了磷烯是优越的热电材料，并强调了应变工程和宽度控制在优化一维纳米带热电器件中的作用。


<details>
  <summary>Details</summary>
Motivation: 准一维纳米带因其低维度和结构可调性可以分离关键传输参数以增强能量转换，因此在高效和可扩展的热电材料方面引起了人们的极大兴趣。

Method: 使用第一性原理输入参数化的紧束缚模型，并在 Landauer-Büttiker 形式下求解，计算了应变和宽度依赖性的热电。

Result: 磷烯纳米带表现出非常高（62 kB/e）的热电，这是其大而持久的带隙和各向异性的电子结构的结果。所有系统中 3p+2 族在应变下从近金属过渡到半导体，从而在先前不活动的配置中极大地激活了热电。

Conclusion: 石墨烯、硅烯、锗烯、锡烯和磷烯衍生的扶手椅纳米带中的热电行为受带隙演变、化学势不对称性和量子限制的复杂相互作用控制。石墨烯和硅烯在适度应变下表现出明显的族和宽度敏感的热电增强，而较重的 X 烯（如锗烯和锡烯）的响应较弱。特别是，磷烯纳米带表现出色，由于其大而持久的带隙和各向异性的电子结构，表现出非常高（62 kB/e）的热电。在所有系统中，3p+2 族在应变下从近金属过渡到半导体，从而在先前不活动的配置中极大地激活了热电。

Abstract: The quest for efficient and scalable thermoelectric materials has catalyzed
intense interest in quasi 1D nanoribbons, where reduced dimensionality and
structural tunability can decouple key transport parameters to enhance energy
conversion. In this work, we present a unified comparative study of the
thermopower in armchair nanoribbons derived from five archetypal 2D materials:
graphene, silicene, germanene, stanene and phosphorene. Using a tight binding
model parametrized by first principles inputs and solved within the Landauer
Buttiker formalism, we compute strain and width dependent thermopower across
nanoribbons classified by width families (3p, 3p+1, 3p+2) over a wide range of
uniaxial tensile strain. Our results reveal that thermoelectric behavior is
governed by a complex interplay of bandgap evolution, chemical potential
asymmetry, and quantum confinement. While graphene and silicene exhibit
pronounced family and width sensitive thermopower enhancement under moderate
strain, heavier Xenes such as germanene and stanene show diminished responses.
In particular, phosphorene nanoribbons emerge as exceptional, exhibiting
remarkably high thermopower (62 kB/e), a consequence of their large, persistent
bandgap and anisotropic electronic structure. Across all systems, the 3p+2
family transitions from near-metallic to semiconducting under strain, enabling
dramatic activation of thermopower in previously inactive configurations. This
systematic cross material analysis delineates the design principles for the
optimization of TE in 1D nanoribbons, highlighting the strategic use of width
control and strain engineering. Our findings identify phosphorene as an
intrinsically superior thermoelectric material and position strained Xene
nanoribbons as promising candidates for tunable, low-dimensional thermoelectric
devices.

</details>


### [242] [Improving photovoltaics by adding extra terminals to extract hot carriers](https://arxiv.org/abs/2507.13279)
*Bruno Bertin-Johannet,Thibaut Thuégaz,Janine Splettstoesser,Robert S. Whitney*

Main category: cond-mat.mes-hall

TL;DR: 多端子光伏电池通过收集“热”载流子，能比传统两端子电池提供更高的功率输出。


<details>
  <summary>Details</summary>
Motivation: 探索多端子设计是否能提升光伏电池的性能，以收集“热”载流子，提高能量转换效率。

Method: 提出并预测了具有能量过滤功能的四端子光伏电池，该设计能够收集“热”载流子（尚未弛豫到能带边缘的电子或空穴），同时用其他端子收集低能载流子。

Result: 预测四端子电池在载流子收集速度快于载流子-声子弛豫时，其功率输出将超过最优两端子电池，预测效率提升幅度可达40%以上。

Conclusion: 四端子光伏电池相比于最优两端子电池具有更高的能量转换效率，尤其是在快速收集载流子的情况下，效率可以提高40%以上。这种多端子设计同样适用于利用非平衡分布的热电器件。

Abstract: Photovoltaic cells usually have two terminals, one collecting electrons and
the other collecting holes. Can more terminals improve such solar cells?
Energy-filtering terminals could collect "hot" carriers (electrons or holes not
yet relaxed to the band edge), with other terminals for low-energy carriers.
For collection faster than carrier-phonon relaxation, we predict four-terminal
cells with higher power output than optimal two-terminal cells -- more than 40%
higher for fast carrier collection. Similar effects will occur in
multi-terminal thermoelectrics exploiting non-equilibrium distributions

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [243] [Model Predictive Black Start for Dynamic Formation of DER-Led Microgrids with Inrush Current Impacts](https://arxiv.org/abs/2507.12569)
*Cong Bai,Salish Maharjan,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 该研究提出了一个MPBS框架，利用涌流可行性模块和创新的电压控制/开关阻塞策略，实现了DER分布式系统的安全高效黑启动。


<details>
  <summary>Details</summary>
Motivation: 需要先进的控制框架来确保高渗透率DER分布式系统（DS）的BS安全高效恢复。

Method: 提出了一种包含涌流可行性模块的预测模型黑启动（MPBS）框架，该模块动态生成实时可行且最优的恢复序列。利用DER出力和输电网（TG）可用性的短期预测来构建自适应的启动路径。涌流可行性模块通过解析法估算给无负载配电变压器（DT）通电引起的瞬态涌流。为了缓解过度的涌流并避免保护装置的潜在误操作，开发了一种受紧急运行启发的电压控制策略和开关阻塞机制。

Result: 提出的涌流模型通过PowerFactory的电磁瞬态（EMT）仿真进行了验证，估算精度超过90%。在改进的IEEE 123节点馈线上的案例研究表明，MPBS框架可以防止熔断器和重合器的误操作，减少不必要的DER能源消耗，并提高DER启动过程中DER主导的BS的负载恢复效率。

Conclusion: 提出的MPBS框架能够有效防止熔断器和重合器的误操作，减少不必要的DER能源消耗，并提高DER启动过程中DER主导的BS的负载恢复效率。

Abstract: Black start (BS) of the distribution system (DS) with high penetration of
distributed energy resources (DERs) requires advanced control frameworks to
ensure secure and efficient restoration. This paper proposes a model predictive
black start (MPBS) framework incorporating an inrush current feasibility module
to dynamically generate real-time feasible and optimal restoration sequences.
Short-term forecasts of DER output and transmission grid (TG) availability are
utilized to construct adaptive cranking paths. The inrush current feasibility
module analytically estimates the transient inrush current caused by energizing
no-load distribution transformers (DTs). To mitigate excessive inrush current
and avoid potential misoperations of protection devices, an emergency
operation-inspired voltage control strategy and a switch blocking mechanism are
developed. The proposed inrush model is validated against electromagnetic
transient (EMT) simulations in PowerFactory with estimation accuracies
exceeding 90 %. Case studies on a modified IEEE 123-node feeder demonstrate
that the MPBS framework prevents misoperations of fuses and reclosers, reduces
unnecessary DER energy consumption, and enhances load restoration efficiency
during DER-led BS processes.

</details>


### [244] [Deep Bilinear Koopman Model for Real-Time Vehicle Control in Frenet Frame](https://arxiv.org/abs/2507.12578)
*Mohammad Abtahi,Farhang Motallebi Araghi,Navid Mojahed,Shima Nazari*

Main category: eess.SY

TL;DR: 提出一种深度koopman方法，用于自动驾驶车辆的建模与控制，通过神经网络学习koopman算子和不变子空间，并结合累积误差调节器，在实时轨迹跟踪任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于车辆动力学的非线性和耦合特性，准确建模和控制自动驾驶汽车仍然是一个挑战。koopman算子理论提供了一个应用线性控制技术的框架，但学习高保真度建模的有限维不变子空间仍是一个开放性问题。

Method: 本文提出了一种深度koopman方法，利用深度神经网络学习koopman算子及其不变子空间，以建模和控制车辆动力学。该框架能够处理输入-状态双线性相互作用，同时保持凸性，并采用多步预测损失进行训练以实现长时预测能力。此外，还集成了一个累积误差调节器（CER）模块来补偿模型失配。

Result: 通过在CarSim RT模型上进行硬件在环（HIL）实验，并在dSPACE SCALEXIO系统上进行实时验证，结果表明该控制器相对于基线控制器在跟踪误差方面有显著降低。

Conclusion: 该方法在实时轨迹跟踪方面表现出色，能够显著减少跟踪误差，证明其适用于嵌入式自动驾驶系统。

Abstract: Accurate modeling and control of autonomous vehicles remain a fundamental
challenge due to the nonlinear and coupled nature of vehicle dynamics. While
Koopman operator theory offers a framework for deploying powerful linear
control techniques, learning a finite-dimensional invariant subspace for
high-fidelity modeling continues to be an open problem. This paper presents a
deep Koopman approach for modeling and control of vehicle dynamics within the
curvilinear Frenet frame. The proposed framework uses a deep neural network
architecture to simultaneously learn the Koopman operator and its associated
invariant subspace from the data. Input-state bilinear interactions are
captured by the algorithm while preserving convexity, which makes it suitable
for real-time model predictive control (MPC) application. A multi-step
prediction loss is utilized during training to ensure long-horizon prediction
capability. To further enhance real-time trajectory tracking performance, the
model is integrated with a cumulative error regulator (CER) module, which
compensates for model mismatch by mitigating accumulated prediction errors.
Closed-loop performance is evaluated through hardware-in-the-loop (HIL)
experiments using a CarSim RT model as the target plant, with real-time
validation conducted on a dSPACE SCALEXIO system. The proposed controller
achieved significant reductions in tracking error relative to baseline
controllers, confirming its suitability for real-time implementation in
embedded autonomous vehicle systems.

</details>


### [245] [Joint Price and Power MPC for Peak Power Reduction at Workplace EV Charging Stations](https://arxiv.org/abs/2507.12703)
*Thibaud Cambronne,Samuel Bobick,Wente Zeng,Scott Moura*

Main category: eess.SY

TL;DR: 该研究提出了一种结合价格和功率优化的框架，通过激励用户选择可控充电服务，并利用预测性控制方法，有效降低了电动汽车充电站的峰值功率和运营商成本。


<details>
  <summary>Details</summary>
Motivation: 解决商业电动汽车充电站运营商面临的高额需求费用问题。

Method: 通过优化定价策略和采用预测性控制方法来管理充电行为，以降低高峰功率消耗。

Result: 蒙特卡洛模拟结果显示，采用时间序列预测的预测性控制方法能显著降低充电站运营商的成本。

Conclusion: 所提出的优化框架和基于时间序列预测的预测性控制方法能显著降低充电站运营商的成本。

Abstract: Demand charge often constitutes a significant portion of electricity costs
for commercial electric vehicle charging station operators. This paper explores
control methods to reduce peak power consumption at workplace EV charging
stations in a joint price and power optimization framework. We optimize a menu
of price options to incentivize users to select controllable charging service.
Using this framework, we propose several solutions to achieve a reduction in
both demand charge and overall operator costs. Through a Monte Carlo
simulation, we find that model predictive control using a time series forecast
can significantly reduce station operator costs.

</details>


### [246] [A Stackelberg Game of Demand Response from the Aggregator's Perspective](https://arxiv.org/abs/2507.12708)
*Seangleng Khe,Parin Chaipunya,Athikom Bangviwat*

Main category: eess.SY

TL;DR: 本文研究了聚合商与消费者之间的需求响应建模，提出了一种双层模型，证明了其在负荷控制和降低电费方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 本文研究了单个聚合商与多个参与消费者之间需求响应活动的建模问题。

Method: 本文提出了一种包含双层结构的模型，其中聚合商扮演领导者的角色，参与的消费者扮演跟随者的角色。

Result: 该模型在负荷控制方面是有效的，它有助于聚合商达到目标减少量，同时消费者支付更便宜的电费。

Conclusion: 该模型在负荷控制方面是有效的，它有助于聚合商达到目标减少量，同时消费者支付更便宜的电费。

Abstract: In this paper, we investigate on the modeling of demand response activities
between the single aggregator and multiple participating consumers. The model
incorporates the bilevel structure that naturally occurs in the information
structure and decision sequence, where the aggregator assumes the role of a
leader and the participating consumers play the role of followers. The proposed
model is demonstrated to be effective in load control, helping the aggregator
to meet the target reduction while the consumers pay cheaper electricity bill.

</details>


### [247] [On the Properties of Optimal-Decay Control Barrier Functions](https://arxiv.org/abs/2507.12717)
*Pio Ong,Max H. Cohen,Tamas G. Molnar,Aaron D. Ames*

Main category: eess.SY

TL;DR: OD-CBF通过引入可调参数ω来优化CBF中的α函数选择，以改进系统行为，并已在卫星控制问题中得到验证。


<details>
  <summary>Details</summary>
Motivation: 传统的控制屏障函数（CBF）虽然在保证系统安全方面非常有效，但其关键的$\\\dot{h} \\\

\

geq - \
\


alpha(h)\

$不等式中的$\\\alpha(h)\

$函数选择对系统行为有显著影响，而这种选择是用户定义的。

Method: OD-CBF通过引入一个可自动确定的参数ω来修改传统CBF不等式为$\\\dot{h} \\\

geq - \\\omega \
\
alpha(h)\\\n$, 从而形式化了选择α函数的过程。该框架还包括OD-CBF有效性、控制不变性、安全集的前向不变性条件，并讨论了基于优化的安全控制器。

Result: 所提出的OD-CBF框架在卫星控制问题中进行了仿真验证，并对该框架进行了全面的表述，包括OD-CBF有效性的可行条件、安全集控制不变性、以及对基于优化的安全控制器在可行性、Lipschitz连续性和闭式表达式方面的讨论。

Conclusion: OD-CBF框架为选择CBF中的α函数提供了一种形式化方法，并可应用于具有消失的相对阶数的高阶CBF技术，以解决安全约束问题。

Abstract: Control barrier functions provide a powerful means for synthesizing safety
filters that ensure safety framed as forward set invariance. Key to CBFs'
effectiveness is the simple inequality on the system dynamics: $\dot{h} \geq -
\alpha(h)$. Yet determining the class $\mathcal{K}^e$ function $\alpha$ is a
user defined choice that can have a dramatic effect on the resulting system
behavior. This paper formalizes the process of choosing $\alpha$ using
optimal-decay control barrier functions (OD-CBFs). These modify the traditional
CBF inequality to: $\dot{h} \geq - \omega \alpha(h)$, where $\omega \geq 0$ is
automatically determined by the safety filter. A comprehensive characterization
of this framework is elaborated, including tractable conditions on OD-CBF
validity, control invariance of the underlying sets in the state space, forward
invariance conditions for safe sets, and discussion on optimization-based safe
controllers in terms of their feasibility, Lipschitz continuity, and
closed-form expressions. The framework also extends existing higher-order CBF
techniques, addressing safety constraints with vanishing relative degrees. The
proposed method is demonstrated on a satellite control problem in simulation.

</details>


### [248] [Invariance Guarantees using Continuously Parametrized Control Barrier Functions](https://arxiv.org/abs/2507.12743)
*Inkyu Jang,H. Jin Kim*

Main category: eess.SY

TL;DR: 该研究提出了一种名为PCBF的新方法，用于解决安全控制中的不变集构造问题。PCBF通过连续参数化控制屏障函数，动态选择参数以生成简单的、包含于安全边界内的控制不变集，从而简化了控制器的设计并提高了适应性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键控制中，为给定状态约束构建形状合适且包含于其中的控制不变集是一个基本但困难的问题，尤其是在大或复杂空间中。

Method: 利用连续参数化的控制屏障函数（PCBF），通过动态选择参数使不变集位于安全边界内，并推导了基于二次规划（QP）的控制器（PCBF-QP）。

Result: 提出了一种名为PCBF-QP的轻量级反馈控制器，并展示了如何为一类系统构建有效的PCBF，以及如何约束参数以确保不变集不超出安全边界。该概念还扩展到了高阶PCBF。

Conclusion: 该方法通过动态选择参数来生成简单的、适合安全边界的控制不变集，无需设计复杂的CBF，易于适应不同环境。

Abstract: Constructing a control invariant set with an appropriate shape that fits
within a given state constraint is a fundamental problem in safety-critical
control but is known to be difficult, especially for large or complex spaces.
This paper introduces a safe control framework of utilizing PCBF: continuously
parametrized control barrier functions (CBFs). In PCBF, each choice of
parameter corresponds to a control invariant set of relatively simple shape.
Invariance-preserving control is done by dynamically selecting a parameter
whose corresponding invariant set lies within the safety bound. This eliminates
the need for synthesizing a single complex CBF that matches the entire free
space. It also enables easier adaptation to diverse environments. By assigning
a differentiable dynamics on the parameter space, we derive a lightweight
feedback controller based on quadratic programming (QP), namely PCBF-QP. We
also discuss on how to build a valid PCBF for a class of systems and how to
constrain the parameter so that the invariant set does not exceed the safety
bound. The concept is also extended to cover continuously parametrized
high-order CBFs, which is called high-order PCBF. Finally, simulation
experiments are conducted to validate the proposed approach.

</details>


### [249] [Latency-Optimal File Assignment in Geo-Distributed Storage with Preferential Demands](https://arxiv.org/abs/2507.12830)
*Srivathsa Acharya,P. Vijay Kumar,Viveck R. Cadambe*

Main category: eess.SY

TL;DR: 本文提出了一种在地理分布式网络中优化文件放置的方法，以最小化延迟。该方法通过将问题转化为图论和分配问题来解决，并在无码方案中实现了最优结果。


<details>
  <summary>Details</summary>
Motivation: 在具有节点间通信延迟的地理分布式服务器网络中，优化文件放置以最小化最坏情况延迟和系统平均延迟，特别是在节点文件需求概率非均匀的情况下。

Method: 通过将最坏情况延迟约束建模为顶点着色问题，并将系统平均延迟优化转换为平衡分配问题来解决。

Result: 提出了一个在一类无码方案中是最优的方案，能够优化文件放置以最小化最坏情况延迟和系统平均延迟。

Conclusion: 本文提出的策略在编码方案中是最优的，它将最坏情况延迟约束建模为顶点着色问题，并将系统平均延迟优化转换为平衡分配问题。

Abstract: We consider the problem of data storage in a geographically distributed (or
geo-distributed) network of servers (or nodes) where inter-node communication
incurs certain round-trip delays. Every node serves a set of users who can
request any file in the network. If the requested file is not available at the
node, it communicates with other nodes to obtain the file, thus causing the
user to experience latency in obtaining the file. The files can be placed
uncoded, where each node stores exact copies of the files, or in coded fashion,
where certain linear combination of files are placed at each node. We aim to
obtain an optimal file placement on the nodes with respect to minimizing the
worst-case latency at each node, as well as the system-average latency. The
prior literature considered the case of equiprobable file demands at the nodes.
In this paper, we investigate the generic case of non-uniform file-demand
probabilities at each node. The scheme presented here is optimal within the
family of uncoded schemes. It is obtained first by modeling the worst-case
latency constraint as a vertex coloring problem, and then converting the
system-average latency optimization to a problem of balanced-assignment.

</details>


### [250] [Guaranteeing and Explaining Stability across Heterogeneous Load Balancing using Calculus Network Dynamics](https://arxiv.org/abs/2507.12892)
*Mengbang Zou,Yun Tang,Adolfo Perrusquía,Weisi Guo*

Main category: eess.SY

TL;DR: 本研究提出了一种新的理论框架，通过微积分动力学和网络拓扑分析来解决基站负载均衡中的振荡问题，并提出优化算法的方法。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的负载均衡机制在处理大量基站时会观察到负载演变的振荡效应，导致高昂的基站间消息传递成本。现有的算法无法解释这种振荡现象，也无法提供理想同步状态稳定性的理论保证，因此需要一个新的理论框架来解决这些问题。

Method: 本研究将数据驱动的负载均衡算法抽象为微积分动力学空间，并结合网络拓扑结构、“非保守误差”以及网络动力学的特征值谱，来分析和解决基站间的负载均衡问题。

Result: 通过将数据驱动的算法抽象化，本研究能够建立网络负载均衡动力学的同步条件，适用于任何网络拓扑。研究结果表明，通过利用“非保守误差”和网络动力学的特征值谱，可以调整基站间的负载均衡机制，以实现高效率和收敛性保证，或者在同步条件无法满足时减轻振荡。

Conclusion: 本研究提出了一种新的理论框架，通过将数据驱动的算法抽象为微积分动力学空间，来理解和解决基站负载均衡中的振荡问题。该框架考虑了网络拓扑结构和“非保守误差”以及网络动力学的特征值谱，旨在提高负载均衡算法的效率和收敛性保证，或在无法满足同步条件时减缓振荡。

Abstract: Load balancing between base stations (BSs) allows BS capacity to be
efficiently utilised and avoid outages. Currently, data-driven mechanisms
strive to balance inter-BS load and reduce unnecessary handovers. The challenge
is that over a large number of BSs, networks observe an oscillatory effect of
load evolution that causes high inter-BS messaging. Without a calculus function
that integrates network topology to describe the evolution of load states,
current data-driven algorithms cannot explain the oscillation phenomenon
observed in load states, nor can they provide theoretical guarantees on the
stability of the ideal synchronised state. Whilst we know load state
oscillation is coupled with the load balancing process algorithms and the
topology structure of inter-BS boundary relations, we do not have a theoretical
framework to prove this and a pathway to improving load balancing algorithms.
Here, we abstract generic and heterogeneous data-driven algorithms into a
calculus dynamics space, so that we can establish the synchronization
conditions for networked load balancing dynamics with any network topology. By
incorporating what is known as "non-conservative error" and the eigenvalue
spectrum of the networked dynamics, we can adjust the inter-BS load balancing
mechanisms to achieve high efficiency and convergence guarantee, or to mitigate
the oscillation when the synchronisation condition cannot be satisfied.

</details>


### [251] [Learning-Based Cost-Aware Defense of Parallel Server Systems against Malicious Attacks](https://arxiv.org/abs/2507.12975)
*Yuzhen Zhan,Li Jin*

Main category: eess.SY

TL;DR: A faster learning algorithm is developed for securing parallel server systems against cyber attacks, showing improved convergence and minimal performance loss.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the cyber-physical security of parallel server systems, which are vulnerable to malicious attacks due to their reliance on feedback control.

Method: The paper develops an approximate minimax-Q learning algorithm using interpretable linear function approximation and proves its convergence using Lyapunov and ODE-based methods.

Result: The developed algorithm converges about 50 times faster than a representative neural network-based method, with an insignificant optimality gap of 4%-8%.

Conclusion: The paper develops an approximate minimax-Q learning algorithm for cyber-physical security of parallel server systems, which converges with probability one to an approximate Markov perfect equilibrium.

Abstract: We consider the cyber-physical security of parallel server systems, which is
relevant for a variety of engineering applications such as networking,
manufacturing, and transportation. These systems rely on feedback control and
may thus be vulnerable to malicious attacks such as denial-of-service, data
falsification, and instruction manipulations. In this paper, we develop a
learning algorithm that computes a defensive strategy to balance technological
cost for defensive actions and performance degradation due to cyber attacks as
mentioned above. We consider a zero-sum Markov security game. We develop an
approximate minimax-Q learning algorithm that efficiently computes the
equilibrium of the game, and thus a cost-aware defensive strategy. The
algorithm uses interpretable linear function approximation tailored to the
system structure. We show that, under mild assumptions, the algorithm converges
with probability one to an approximate Markov perfect equilibrium. We first use
a Lyapunov method to address the unbounded temporal-difference error due to the
unbounded state space. We then use an ordinary differential equation-based
argument to establish convergence. Simulation results demonstrate that our
algorithm converges about 50 times faster than a representative neural
network-based method, with an insignificant optimality gap between 4\%--8\%,
depending on the complexity of the linear approximator and the number of
parallel servers.

</details>


### [252] [Fractional-order controller tuning via minimization of integral of time-weighted absolute error without multiple closed-loop tests](https://arxiv.org/abs/2507.12987)
*Ansei Yonezawa,Heisei Yonezawa,Shuichi Yahagi,Itsuro Kajiwara,Shinya Kijimoto*

Main category: eess.SY

TL;DR: 提出了一种新的非迭代整定技术，用于优化线性分数阶（FO）控制器。该方法利用单次输入/输出数据和虚拟参考信号来优化控制器参数，避免了传统方法中耗时的多次实验或仿真，从而降低了成本并提高了效率。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统ITAE整定方法需要多次闭环实验或模型仿真以评估ITAE的缺点，提出了一种新的非迭代整定技术。

Method: 提出了一种基于积分时滞绝对误差（ITAE）标准的线性分数阶（FO）控制器非迭代整定技术。通过收集受控对象的单次输入/输出数据，并定义一个基于收集到的信号的虚拟参考信号，重构了ITAE最小化问题，从而获得最优的FO控制器参数，而无需多次闭环实验或模型仿真。

Result: 该方法通过数值研究进行了验证，结果表明该技术能有效整定FO控制器，减少超调/下冲，抑制稳态误差，并显著降低开发成本。

Conclusion: 该方法通过避免重复实验，显著降低了线性分数阶（FO）控制器的开发成本，从而促进了其在实际应用中的应用。

Abstract: This study presents a non-iterative tuning technique for a linear
fractional-order (FO) controller, based on the integral of the time-weighted
absolute error (ITAE) criterion. Minimizing the ITAE is a traditional approach
for tuning FO controllers. This technique reduces the over/undershoot and
suppresses the steady-state error. In contrast to conventional approaches of
ITAE-based controller tuning, the proposed approach does not require multiple
closed-loop experiments or model-based simulations to evaluate the ITAE. The
one-shot input/output data is collected from the controlled plant. A fictitious
reference signal is defined on the basis of the collected input and output
signal, which enables us to evaluate the closed-loop response provided by the
arbitrary controller parameters. To avoid repeated experiments that are
necessary in the conventional approach, we reformulate the ITAE minimization
problem using the fictitious reference signal. The desired FO controller
parameters minimizing the ITAE are obtained by solving the optimization problem
that is based on the fictitious reference signal. The validity of the proposed
approach is demonstrated by a numerical study. The avoidance of repeated
experiments significantly reduces the development cost of linear FO
controllers, thereby facilitating their practical application.

</details>


### [253] [Vertical Vibration Reduction of Maglev Vehicles using Nonlinear MPC](https://arxiv.org/abs/2507.13015)
*Mario Hermle,Arnim Kargl,Peter Eberhard*

Main category: eess.SY

TL;DR: 该研究提出了一种新的NMPC策略，用于高速磁悬浮列车，通过考虑悬架动力学来预测性地减小振动，从而提高乘客舒适度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法忽略悬架动力学和悬架振动问题，从而提高乘客舒适度和乘坐质量。

Method: 提出了一种新颖的非线性模型预测控制（NMPC）策略，该策略将机械悬架动力学显式地纳入控制模型，并能预测性地抑制振动。

Result: 模拟结果表明，与现有控制器相比，该方法在抑制振动方面表现更优。

Conclusion: 该方法通过将电磁力和悬架行为集成到控制模型中，有望成为未来高速磁悬浮应用的解决方案。

Abstract: This work presents a novel Nonlinear Model Predictive Control (NMPC) strategy
for high-speed Maglev vehicles that explicitly incorporates mechanical
suspension dynamics into the control model. Unlike conventional approaches,
which often neglect the interaction between levitation magnet and car body
motion, the proposed method enables predictive vibration mitigation by modeling
both electromagnetic forces and suspension behavior. This integrated approach
significantly improves passenger comfort and ride quality by reducing vertical
oscillations caused by track irregularities. Moreover, it allows for a more
effective tuning of the trade-off between precise air gap tracking and ride
comfort. Simulations based on a detailed multibody model of the Transrapid
demonstrate that the method outperforms existing controllers in vibration
suppression, making it a promising solution for future high-speed Maglev
applications.

</details>


### [254] [Dual LiDAR-Based Traffic Movement Count Estimation at a Signalized Intersection: Deployment, Data Collection, and Preliminary Analysis](https://arxiv.org/abs/2507.13073)
*Saswat Priyadarshi Nayak,Guoyuan Wu,Kanok Boriboonsomsin,Matthew Barth*

Main category: eess.SY

TL;DR: 本研究提出了一种创新的双激光雷达系统，用于在交叉口进行交通流量计数，解决了传统基于摄像头方法的局限性，并在实际应用中进行了评估，同时提出了未来改进的方向。


<details>
  <summary>Details</summary>
Motivation: 为了优化信号灯配时、评估现有交通控制措施的性能以及提出有效的车道配置以最大限度地减少延误、减少拥堵和提高安全性，对交叉口的交通流量计数至关重要。然而，传统的基于摄像头的方法在光照条件不佳的情况下（如恶劣天气和夜间）会受到准确性问题的困扰。

Method: 该研究提出并评估了一种基于双激光雷达系统的交通流量计数方法。该方法利用激光雷达传感器收集数据，并通过3D边界框检测对车辆进行分类，以统计不同交通方向、车辆运动和车辆类别的数量。

Result: 该研究在加利福尼亚州里亚托市的一个交叉口部署并评估了一个双激光雷达系统，用于交通流量计数。研究讨论了估计的交通流量计数结果，并深入分析了观察到的趋势和异常情况。

Conclusion: 该研究评估了一个部署在加利福尼亚州里亚托市一个交叉路口的双激光雷达系统在交通流量计数方面的性能，并提出了潜在的改进措施，以增强交通流量计数、轨迹预测和意图预测。

Abstract: Traffic Movement Count (TMC) at intersections is crucial for optimizing
signal timings, assessing the performance of existing traffic control measures,
and proposing efficient lane configurations to minimize delays, reduce
congestion, and promote safety. Traditionally, methods such as manual counting,
loop detectors, pneumatic road tubes, and camera-based recognition have been
used for TMC estimation. Although generally reliable, camera-based TMC
estimation is prone to inaccuracies under poor lighting conditions during harsh
weather and nighttime. In contrast, Light Detection and Ranging (LiDAR)
technology is gaining popularity in recent times due to reduced costs and its
expanding use in 3D object detection, tracking, and related applications. This
paper presents the authors' endeavor to develop, deploy and evaluate a
dual-LiDAR system at an intersection in the city of Rialto, California, for TMC
estimation. The 3D bounding box detections from the two LiDARs are used to
classify vehicle counts based on traffic directions, vehicle movements, and
vehicle classes. This work discusses the estimated TMC results and provides
insights into the observed trends and irregularities. Potential improvements
are also discussed that could enhance not only TMC estimation, but also
trajectory forecasting and intent prediction at intersections.

</details>


### [255] [QTCAJOSA: Low-Complexity Joint Offloading and Subchannel Allocation for NTN-Enabled IoMT](https://arxiv.org/abs/2507.13242)
*Alejandro Flores C.,Konstantinos Ntontin,Ashok Bandi,Symeon Chatzinotas*

Main category: eess.SY

TL;DR: 通过结合无人机（UAV）、高空平台站（HAPS）和低地球轨道（LEO）卫星，提出了一种低复杂度的算法，用于优化物联网（IoMT）设备的任务卸载，以减少延迟。


<details>
  <summary>Details</summary>
Motivation: 解决来自物联网（IoMT）设备的资源分配问题，将其任务卸载到非地面网络（NTN），以最小化加权总延迟。

Method: 提出了一种基于凸优化标准的贪婪启发式算法，用于联合子信道分配和卸载决策，并动态初始化计算资源。

Result: 仿真结果表明，与不包括非地面节点的架构相比，包含不同非地面节点（UAV、HAPS、LEO）的架构在最小化加权总延迟方面具有优势。

Conclusion: 所提出的低复杂度联合子信道分配和卸载决策算法在包括非地面节点（UAV、HAPS、LEO）的架构中实现了任务卸载的加权总延迟最小化。

Abstract: In this work, we consider the resource allocation problem for task offloading
from Internet of Medical Things (IoMT) devices, to a non-terrestrial network.
The architecture considers clusters of IoMT devices that offload their tasks to
a dedicated unmanned aerial vehicle (UAV) serving as a multi-access edge
computing (MEC) server, which can compute the task or further offload it to an
available high-altitude platform station (HAPS) or to a low-earth orbit (LEO)
satellite for remote computing. We formulate a problem that has as objective
the minimization of the weighted sum delay of the tasks. Given the non-convex
nature of the problem, and acknowledging that the complexity of the
optimization algorithms impact their performance, we derive a low-complexity
joint subchannel allocation and offloading decision algorithm with dynamic
computing resource initialization, developed as a greedy heuristic based on
convex optimization criteria. Simulations show the gain obtained by including
the different non-terrestrial nodes against architectures without them.

</details>


### [256] [Transient-Stability-Aware Frequency Provision in IBR-Rich Grids via Information Gap Decision Theory and Deep Learning](https://arxiv.org/abs/2507.13265)
*Amin Masoumi,Mert Korkali*

Main category: eess.SY

TL;DR: 该研究提出了一种结合深度学习和决策理论的风险规避调度策略，以解决高渗透率逆变器电网中的瞬态稳定性问题，并在 IEEE 39 母线系统上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在高渗透率逆变器基资源（IBR）电网中，由于惯量降低而导致的瞬态稳定性丧失的关键问题。

Method: 提出了一种集成预测深度学习（DL）模型与信息 ગ্যাপ 决策理论（IGDT）的风险规避调度策略，通过重新构建传统的虚拟惯量调度（VIS）问题，利用故障后动态的早期预测来主动重新调度资源，以在最坏情况的意外事件下保持系统惯性中心稳定。

Result: 在具有 70% IBR 渗透率的 IEEE 39 母线系统上验证，所提出的方法可防止系统崩溃，而传统的 VIS 策略在此情况下会失败，仅增加 5% 的成本即可确保频率稳定。

Conclusion: 该框架通过主动重新调度资源来防止系统崩溃，即使在传统虚拟惯量调度策略失败的情况下也能确保频率稳定，同时成本仅增加 5%。

Abstract: This paper introduces a framework to address the critical loss of transient
stability caused by reduced inertia in grids with high inverter-based resource
(IBR) penetration. The proposed method integrates a predictive deep learning
(DL) model with information gap decision theory (IGDT) to create a risk-averse
dispatch strategy. By reformulating the conventional virtual inertia scheduling
(VIS) problem, the framework uses early predictions of post-fault dynamics to
proactively redispatch resources, ensuring the system's center of inertia
remains stable under worst-case contingencies. Validated on the IEEE 39-bus
system with 70% IBR penetration, the proposed approach prevents system collapse
where a conventional VIS strategy fails, ensuring frequency stability at a cost
increase of only 5%.

</details>


### [257] [Privacy-Preserving Fusion for Multi-Sensor Systems Under Multiple Packet Dropouts](https://arxiv.org/abs/2507.13286)
*Jie Huang,Jason J. R. Liu*

Main category: eess.SY

TL;DR: 本论文提出了一种隐私保护融合估计（PPFE）方法，通过分布式编码隐私保护机制（PPM）来应对无线传感器网络中的丢包和窃听攻击，同时保证了状态估计的性能和数据的机密性。


<details>
  <summary>Details</summary>
Motivation: 无线传感器网络（WSNs）在现代网络物理系统中至关重要，但窃听和丢包的风险给安全状态估计带来了挑战。本研究旨在解决多丢包和窃听攻击下的多传感器系统中的隐私保护融合估计（PPFE）问题。

Method: 提出了一种基于控制理论框架的分布式编码隐私保护机制（PPM），用于解决多传感器系统中的多丢包和窃听攻击问题。开发了一个集中的融合滤波器，并推导了通过修正代数Riccati方程得到的合法用户估计误差协方差的有界条件。

Result: 推导了合法用户估计误差协方差的有界条件，并通过证明窃听者估计误差均值发散来严格分析了PPFE算法的数据机密性。

Conclusion: 仿真结果验证了所提出方法对于在不影响估计精度的前提下增强隐私是有效的。

Abstract: Wireless sensor networks (WSNs) are critical components in modern
cyber-physical systems, enabling efficient data collection and fusion through
spatially distributed sensors. However, the inherent risks of eavesdropping and
packet dropouts in such networks pose significant challenges to secure state
estimation. In this paper, we address the privacy-preserving fusion estimation
(PPFE) problem for multi-sensor systems under multiple packet dropouts and
eavesdropping attacks. To mitigate these issues, we propose a distributed
encoding-based privacy-preserving mechanism (PPM) within a control-theoretic
framework, ensuring data privacy during transmission while maintaining the
performance of legitimate state estimation. A centralized fusion filter is
developed, accounting for the coupling effects of packet dropouts and the
encoding-based PPM. Boundedness conditions for the legitimate user's estimation
error covariance are derived via a modified algebraic Riccati equation.
Additionally, by demonstrating the divergence of the eavesdropper's mean
estimation error, the proposed PPFE algorithm's data confidentiality is
rigorously analyzed. Simulation results for an Internet-based three-tank system
validate the effectiveness of the proposed approach, highlighting its potential
to enhance privacy without compromising estimation accuracy.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [258] [Geometric Theory of Ising Machines](https://arxiv.org/abs/2507.12626)
*Andrew G. Moore,Zachary Richey,Isaac K. Martin*

Main category: cs.ET

TL;DR: A new diagrammatic tool helps design Ising machines by visualizing decision boundaries, leading to a proven connection with 1-NN classifiers and a method for optimizing energy landscapes via linear programming.


<details>
  <summary>Details</summary>
Motivation: The design of Ising machines, which encode function outputs in the ground state of physical systems for efficient computation, is challenging due to the difficulty of designing the energy function.

Method: Introduced a diagrammatic device to visualize decision boundaries for Ising circuits, which was then used to prove two results.

Result: Proved that Ising circuits generalize 1-NN classifiers with a special structure and that eliminating local minima in the energy landscape can be formulated as a linear programming problem.

Conclusion: Ising circuits are a generalization of 1-NN classifiers with a specific structure, and eliminating local minima can be framed as a linear programming problem.

Abstract: We contribute to the mathematical theory of the design of low temperature
Ising machines, a type of experimental probabilistic computing device
implementing the Ising model. Encoding the output of a function in the ground
state of a physical system allows efficient and distributed computation, but
the design of the energy function is a difficult puzzle. We introduce a
diagrammatic device that allows us to visualize the decision boundaries for
Ising circuits. It is then used to prove two results: (1) Ising circuits are a
generalization of 1-NN classifiers with a certain special structure, and (2)
Elimination of local minima in the energy landscape can be formulated as a
linear programming problem.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [259] [Dependency Pairs for Expected Innermost Runtime Complexity and Strong Almost-Sure Termination of Probabilistic Term Rewriting](https://arxiv.org/abs/2507.12918)
*Jan-Christoph Kassing,Leon Spitzer,Jürgen Giesl*

Main category: cs.LO

TL;DR: 本研究提出了首个用于概率项重写系统（PTRSs）的依赖对（DP）框架，用于分析预期复杂度和证明几乎确定性终止（AST）/强几乎确定性终止（SAST）。该框架已在AProVE工具中实现并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然DPs已被扩展用于证明概率项重写系统（PTRSs）的几乎确定性终止（AST），但对PTRSs的自动复杂度分析仍有待探索。

Method: 我们引入了首个DP框架，用于分析预期复杂度并证明概率项重写系统（PTRSs）的最内层重写的几乎确定性终止（AST）或强几乎确定性终止（SAST），即有限预期运行时间。我们将该框架实现在了AProVE工具中。

Result: 该框架已在AProVE工具中实现，并展示了其在证明SAST方面相比现有技术的优势。

Conclusion: 该框架首次实现了对概率项重写系统（PTRSs）的预期复杂度进行分析，并能证明最内层重写（innermost rewriting）的几乎确定性终止（almost-sure termination, AST）或强几乎确定性终止（strong almost-sure termination, SAST），即有限预期运行时间。

Abstract: The dependency pair (DP) framework is one of the most powerful techniques for
automatic termination and complexity analysis of term rewrite systems. While
DPs were extended to prove almost-sure termination of probabilistic term
rewrite systems (PTRSs), automatic complexity analysis for PTRSs is largely
unexplored. We introduce the first DP framework for analyzing expected
complexity and for proving positive or strong almost-sure termination (SAST) of
innermost rewriting with PTRSs, i.e., finite expected runtime. We implemented
our framework in the tool AProVE and demonstrate its power compared to existing
techniques for proving SAST.

</details>


### [260] [Cyclic proof theory of positive inductive definitions](https://arxiv.org/abs/2507.13057)
*Gianluca Curzi,Lukas Melgaard*

Main category: cs.LO

TL;DR: 本文证明了循环和归纳的$
u	ext{PA}$具有相同的证明论强度，并将循环证明翻译成带注释的变体，并在$m 	ext{II}^1_2$-$m CA}_0$中形式化了这一论证。


<details>
  <summary>Details</summary>
Motivation: 研究了$
u	ext{PA}$的循环证明系统，$
u	ext{PA}$是算术的扩展，通过正归纳定义，其算术等价于二阶算术的（非例示性）子系统$m 	ext{II}^1_2$-$m CA}_0$。

Method: 通过将循环证明翻译成基于Sprenger和Dam的系统、利用Möllerfeld的保守性性质以及Curzi和Das关于Knaster-Tarski定理的逆向数学工作来形式化证明。

Result: 证明了循环和归纳的$
u	ext{PA}$具有相同的证明论强度。作为证明方法的副产品，表明了尽管具有更强的有效性条件，带注释的和“普通”的循环证明$
u	ext{PA}$证明了相同的定理。

Conclusion: 本文证明了循环和归纳的$
u	ext{PA}$具有相同的证明论强度。

Abstract: We study cyclic proof systems for $\mu\mathsf{PA}$, an extension of Peano
arithmetic by positive inductive definitions that is arithmetically equivalent
to the (impredicative) subsystem of second-order arithmetic
$\Pi^1_2$-$\mathsf{CA}_0$ by M\"{o}llefeld. The main result of this paper is
that cyclic and inductive $\mu\mathsf{PA}$ have the same proof-theoretic
strength. First, we translate cyclic proofs into an annotated variant based on
Sprenger and Dam's systems for first-order $\mu$-calculus, whose stronger
validity condition allows for a simpler proof of soundness. We then formalise
this argument within $\Pi^1_2$-$\mathsf{CA}_0$, leveraging M\"{o}llerfeld's
conservativity properties. To this end, we build on prior work by Curzi and Das
on the reverse mathematics of the Knaster-Tarski theorem. As a byproduct of our
proof methods we show that, despite the stronger validity condition, annotated
and "plain" cyclic proofs for $\mu\mathsf{PA}$ prove the same theorems. This
work represents a further step in the non-wellfounded proof-theoretic analysis
of theories of arithmetic via impredicative fragments of second-order
arithmetic, an approach initiated by Simpson's Cyclic Arithmetic, and continued
by Das and Melgaard in the context of arithmetical inductive definitions.

</details>


### [261] [Monotone weak distributive laws over the lifted powerset monad in categories of algebras](https://arxiv.org/abs/2507.13058)
*Quentin Aristote*

Main category: cs.LO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Noticing the similarity between the monotone weak distributive laws combining
two layers of nondeterminism in sets and in compact Hausdorff spaces, we study
whether the latter law can be obtained automatically as a weak lifting of the
former. This holds partially, but does not generalize to other categories of
algebras: we then characterize when exactly monotone weak distributive laws
over powerset monads in categories of algebras exist, exhibiting a law
combining probabilities and non-determinism in compact Hausdorff spaces and
showing on the other hand that such laws do not exist in a lot of other cases.

</details>


### [262] [Impact and Performance of Randomized Test-Generation using Prolog](https://arxiv.org/abs/2507.13178)
*Marcus Gelderie,Maximilian Luff,Maximilian Peltzer*

Main category: cs.LO

TL;DR: 通过在Prolog中引入两种随机化策略来优化测试用例的生成，并使用马尔可夫链进行了性能分析和比较。


<details>
  <summary>Details</summary>
Motivation: 为了解决Prolog生成测试用例时可能存在的测试集合过大或无限的问题，引入随机化方法来提高测试效率和性能。

Method: 提出并分析了两种在Prolog中随机生成测试序列的策略，其中一种基于标准Prolog语义，另一种则修改了SLD选择函数，并使用马尔可夫链理论分析了平均测试时间和生成用例数量。

Result: 分析了两种随机化策略的性能，并通过实证评估进行了比较。

Conclusion: 对两种随机化测试用例生成策略的平均测试时间和生成用例数量进行了理论和实证分析与比较。

Abstract: We study randomized generation of sequences of test-inputs to a system using
Prolog. Prolog is a natural fit to generate test-sequences that have complex
logical inter-dependent structure. To counter the problems posed by a large (or
infinite) set of possible tests, randomization is a natural choice. We study
the impact that randomization in conjunction with SLD resolution have on the
test performance. To this end, this paper proposes two strategies to add
randomization to a test-generating program. One strategy works on top of
standard Prolog semantics, whereas the other alters the SLD selection function.
We analyze the mean time to reach a test-case, and the mean number of generated
test-cases in the framework of Markov chains. Finally, we provide an additional
empirical evaluation and comparison between both approaches. Under
consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [263] [Just Verification of Mutual Exclusion Algorithms](https://arxiv.org/abs/2507.13198)
*Rob van Glabbeek,Bas Luttik,Myrthe Spronck*

Main category: cs.LO

TL;DR: We used model checking to verify mutual exclusion algorithms that communicate through shared registers. We found some algorithms had correctness violations and suggested fixes.


<details>
  <summary>Details</summary>
Motivation: To verify the correctness of mutual exclusion algorithms, especially those relying on shared read/write registers with varying atomicity.

Method: Model checking of mutual exclusion algorithms with communication via shared read/write registers (atomic or non-atomic). Liveness properties are verified using justness as a completeness criterion, based on different concurrency relations modeling shared register behavior.

Result: Verification of mutual exclusion algorithms' correctness. Identification of violations in several algorithms, with proposed improvements.

Conclusion: We demonstrate the violation of correctness properties in several mutual exclusion algorithms and suggest potential improvements.

Abstract: We verify the correctness of a variety of mutual exclusion algorithms through
model checking. We look at algorithms where communication is via shared
read/write registers, where those registers can be atomic or non-atomic. For
the verification of liveness properties, it is necessary to assume a
completeness criterion to eliminate spurious counterexamples. We use justness
as completeness criterion. Justness depends on a concurrency relation; we
consider several such relations, modelling different assumptions on the working
of the shared registers. We present executions demonstrating the violation of
correctness properties by several algorithms, and in some cases suggest
improvements.

</details>


### [264] [Solving SAT By Computing A Stable Set Of Points In Clusters](https://arxiv.org/abs/2507.13282)
*Eugene Goldberg*

Main category: cs.LO

TL;DR: SAT问题可以通过计算稳定点集（SSP）来解决，但直接计算SSP不可行。本研究提出了一种在集群中并行计算SSP的方法，以提高效率。


<details>
  <summary>Details</summary>
Motivation: 由于直接计算SSP在实践中不可行，需要一种新的方法来计算SSP，以便更好地利用公式结构设计更有效的SAT算法并促进并行计算。

Method: 通过在集群中同时处理大量点来计算稳定点集（SSP）。

Result: 提出了一种在集群中同时处理大量点的方法来计算SSP。

Conclusion: CNF公式可满足性问题可以通过计算稳定点集（SSP）来解决，但直接计算SSP在实践中不可行。本研究提出了一种在集群中同时处理大量点的方法来计算SSP，这有助于利用公式结构设计更有效的SAT算法，并促进并行计算。

Abstract: Earlier we introduced the notion of a stable set of points (SSP). We proved
that a CNF formula is unsatisfiable iff there is a set of points (i.e. complete
assignments) that is stable with respect to this formula. Experiments showed
that SSPs for CNF formulas of practical interest are very large. So computing
an SSP for a CNF formula point by point is, in general, infeasible. In this
report, we show how an SSP can be computed in clusters, each cluster being a
large set of points that are processed simultaneously. The appeal of computing
SSPs is twofold. First, it allows one to better take into account formula
structure and hence, arguably, design more efficient SAT algorithms. Second,
SAT solving by SSPs facilitates parallel computing.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [265] [Modular SAIL: dream or reality?](https://arxiv.org/abs/2507.12471)
*Petr Kourzanov,Anmol*

Main category: cs.AR

TL;DR: 通过将模块化引入 SAIL-RISCV 模拟器，我们证明了 RISC-V 开发流程的组合性是可行的，并且性能与整体模拟器相当。


<details>
  <summary>Details</summary>
Motivation: 为了真正发挥 RISC-V ISA 模块化的优势，社区需要解决组合性问题，将其扩展到包括仿真、模拟和验证在内的整个 RISC-V 开发流程。

Method: 通过实验性地将组合性引入 SAIL-RISCV 黄金模型，并对生成的插件式模拟器的性能进行比较研究（使用静态和动态绑定），来展示修改 SAIL-RISCV 流程以支持模拟器层面的模块是可行的。

Result: 修改后的 SAIL-RISCV 流程支持模块化，其插件式模拟器在功能上与原始的整体模拟器（RISC-V ISS）行为一致，并且通过静态和动态绑定进行了性能比较。

Conclusion: RISC-V ISA 的模块化需要通过支持更大范围的 RISC-V 开发流程（包括仿真、模拟和验证）来解决组合性问题，以实现真正的优势。

Abstract: In order to truly benefit from RISC-V ISA modularity, the community has to
address the issue of compositionality, going beyond modules at the
specification level covering larger subsets of the RISC-V development flow
including emulation, simulation and verification. In this paper we introduce
modular SAIL, an experiment to inject compositionality into the SAIL-RISCV
golden model. We show that it is, in principle, not difficult to adapt the
SAIL-RISCV flow (and ideally the SAIL compiler itself) to support modules at
the emulator level. We back our findings by a comparative study of the
resulting pluggable emulator's performance using both static and dynamic
binding, which both exhibit same functional behavior as the original monolithic
emulator (aka RISC-V ISS).

</details>


### [266] [An ultra-low-power CGRA for accelerating Transformers at the edge](https://arxiv.org/abs/2507.12904)
*Rohit Prasad*

Main category: cs.AR

TL;DR: 为在功耗和资源受限的边缘应用中部署Transformer模型，本文提出了一种专门用于加速Transformer模型中GEMM运算的超低功耗CGRA架构，其特点是集成了4x4 PE阵列、4x2 MOB和无开关网状环通互连网络，以提高效率并降低功耗和延迟。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在各种领域取得了革命性进展，但其计算需求使其难以在低功耗边缘设备上部署。

Method: 提出了一种超低功耗、粗粒度可重构阵列（CGRA）架构，集成了4x4处理单元（PE）阵列和4x2内存操作块（MOB）以及无开关网状环通互连网络。

Result: 该CGRA架构通过优化的PE和MOB集成、减少内存带宽需求和提高数据重用性，并采用无开关互连网络来降低功耗和延迟，从而高效加速Transformer模型中的通用矩阵乘法（GEMM）运算。

Conclusion: 该CGRA架构通过异构阵列设计和高效数据流解决了Transformer的独特计算需求，为在边缘设备上部署复杂的机器学习模型提供了可扩展的途径。

Abstract: Transformers have revolutionized deep learning with applications in natural
language processing, computer vision, and beyond. However, their computational
demands make it challenging to deploy them on low-power edge devices. This
paper introduces an ultra-low-power, Coarse-Grained Reconfigurable Array (CGRA)
architecture specifically designed to accelerate General Matrix Multiplication
(GEMM) operations in transformer models tailored for the energy and resource
constraints of edge applications. The proposed architecture integrates a 4 x 4
array of Processing Elements (PEs) for efficient parallel computation and
dedicated 4 x 2 Memory Operation Blocks (MOBs) for optimized LOAD/STORE
operations, reducing memory bandwidth demands and enhancing data reuse. A
switchless mesh torus interconnect network further minimizes power and latency
by enabling direct communication between PEs and MOBs, eliminating the need for
centralized switching. Through its heterogeneous array design and efficient
dataflow, this CGRA architecture addresses the unique computational needs of
transformers, offering a scalable pathway to deploy sophisticated machine
learning models on edge devices.

</details>


### [267] [WIP: Turning Fake Chips into Learning Opportunities](https://arxiv.org/abs/2507.13281)
*Haniye Mehraban,Saad Azmeen-ur-Rahman,John Hu*

Main category: cs.AR

TL;DR: 课程中的假冒芯片成为一次实践学习的教学时刻，学生们通过实际操作加深了对模拟电路、供应链安全和工程实践的理解。


<details>
  <summary>Details</summary>
Motivation: 为了应对在初级电子课程中发现的假冒TL074运算放大器这一问题，将其转化为一次实践学习体验。

Method: 通过实际诊断，包括测量电流、分析波形和故障排除，让学生动手操作。

Result: 假冒集成电路对本科电子实验室的完整性构成了重大威胁，但通过将其转化为教学机会，学生们获得了更深入的见解。

Conclusion: 学生们通过实际操作，加深了对模拟电路、供应链安全和工程实践的理解。

Abstract: This work-in-progress paper presents a case study in which counterfeit TL074
operational amplifiers, discovered in a junior level electronics course, became
the basis for a hands on learning experience. Counterfeit integrated circuits
(IC) are increasingly common, posing a significant threat to the integrity of
undergraduate electronics laboratories. Instead of simply replacing the
counterfeit components, we turned the issue into a teaching moment. Students
engaged in hands-on diagnostics measuring current, analyzing waveforms, and
troubleshooting. By working with fake chip components, they gained deeper
insight into analog circuits, supply chain security, and practical engineering.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [268] [Differential Communication in Channels with Mobility and Delay Spread using Zak-OTFS](https://arxiv.org/abs/2507.12593)
*Sandesh Rao Mattu,Nishant Mehrotra,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS系统差分通信方案，利用检测到的数据作为导频，无需周期性导频传输，实现更高能量利用率和频谱效率，且在低复杂度下误码率更优。


<details>
  <summary>Details</summary>
Motivation: 为了减轻Zak-OTFS系统中周期性导频传输的需求。

Method: 提出了一种差分通信方案，并进行了理论分析，证明了检测到的数据可以作为导频，并且从检测到的数据获得的信道估计可以实现通信的“差分”特性。该方法利用DD信道的预测能力，使用前一时刻的信道估计来检测下一时刻的数据，并以此类推。

Result: 与全谱效率的扩展导频方案相比，所提出的方法在较低的复杂度下实现了更好的误码率。此外，该方案允许数据符号享有更高的能量，因为原本用于导频符号的能量可以分配给数据符号，并实现了与点导频或嵌入式导频相比的全部频谱效率。

Conclusion: 该研究提出了一种用于Zak-OTFS系统的差分通信方案，该方案通过将已检测到的数据用作导频，并利用DD域信道的预测能力，从而消除了对周期性导频传输的需求。

Abstract: Zak-transform based orthogonal time frequency space (Zak-OTFS) is a
delay-Doppler (DD) domain modulation scheme in which the signal processing is
carried out in the DD domain. The channel when viewed in the DD domain is
predictable. However, even with Zak-OTFS, pilots need to be sent periodically,
albeit at a lower rate. In this paper, we propose a differential communication
scheme for Zak-OTFS systems that alleviates the need for periodic pilot
transmission. Towards this, we analytically show that the detected data can be
used as a pilot and that the channel estimate obtained from the detected data
can enable further detection enabling the "differential" aspect of the
communication. Specifically, we leverage the prediction capability of the DD
channel in Zak-OTFS to use the channel estimate (obtained from detected data
symbols treated as pilots) in the previous instant to detect data in the next
instant and propagate this forward. The advantages are two fold. First, it
allows the data symbols to enjoy higher energy since the energy that would
otherwise be required for pilot symbols can also be allocated to data symbols.
Second, it allows for full spectral efficiency compared to point or embedded
pilots. Comparison with the full spectral efficiency achieving spread pilot
scheme shows that the proposed method achieves better bit-error rate at lower
complexity.

</details>


### [269] [Achieving Robust Channel Estimation Neural Networks by Designed Training Data](https://arxiv.org/abs/2507.12630)
*Dianxin Luan,John Thompson*

Main category: eess.SP

TL;DR: 为认知无线通信设计了一种无需先验信道信息的离线训练神经网络，通过合成数据训练，实现了对新信道的鲁棒泛化，性能不依赖于网络架构。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的信道估计方法在训练和测试时常使用相同或相似的信道数据，导致在未见过的新数据上性能下降，无法适应时变信道。然而，在线训练受限于低延迟和计算资源。因此，需要设计一种无需实际信道信息即可离线训练并能在无线信道上稳健运行的神经网络。

Method: 提出设计标准以生成合成训练数据集，并基于此设计了一个基准方案，利用不同复杂度的神经网络进行了仿真验证。

Result: 仿真结果表明，所提出的方法能够实现神经网络在无线信道上的鲁棒泛化，包括固定信道配置和可变时延扩展的信道，且泛化能力不依赖于神经网络的架构。

Conclusion: 该研究提出了一种用于认知无线通信的信道估计方法，通过设计生成合成训练数据的标准，确保了神经网络在未见过的新信道上具有鲁棒的泛化能力。该方法无需预先了解信道信息或进行参数更新，即可实现智能运行，并且泛化能力与神经网络的架构无关。

Abstract: Channel estimation is crucial in cognitive communications, as it enables
intelligent spectrum sensing and adaptive transmission by providing accurate
information about the current channel state. However, in many papers neural
networks are frequently tested by training and testing on one example channel
or similar channels. This is because data-driven methods often degrade on new
data which they are not trained on, as they cannot extrapolate their training
knowledge. This is despite the fact physical channels are often assumed to be
time-variant. However, due to the low latency requirements and limited
computing resources, neural networks may not have enough time and computing
resources to execute online training to fine-tune the parameters. This
motivates us to design offline-trained neural networks that can perform
robustly over wireless channels, but without any actual channel information
being known at design time. In this paper, we propose design criteria to
generate synthetic training datasets for neural networks, which guarantee that
after training the resulting networks achieve a certain mean squared error
(MSE) on new and previously unseen channels. Therefore, neural network
solutions require no prior channel information or parameters update for
real-world implementations. Based on the proposed design criteria, we further
propose a benchmark design which ensures intelligent operation for different
channel profiles. To demonstrate general applicability, we use neural networks
with different levels of complexity to show that the generalization achieved
appears to be independent of neural network architecture. From simulations,
neural networks achieve robust generalization to wireless channels with both
fixed channel profiles and variable delay spreads.

</details>


### [270] [A Novel Data Augmentation Strategy for Robust Deep Learning Classification of Biomedical Time-Series Data: Application to ECG and EEG Analysis](https://arxiv.org/abs/2507.12645)
*Mohammed Guhdar,Ramadhan J. Mstafa,Abdulhakeem O. Mohammed*

Main category: eess.SP

TL;DR: 本研究提出了一种集成了CNN、注意力机制和新颖数据增强策略的统一深度学习框架，能够准确处理和提取多种生物信号的特征，有效解决了类别不平衡问题，并在多个基准数据集上取得了最先进的性能，同时适用于资源受限的设备。


<details>
  <summary>Details</summary>
Motivation: 为了解决在同步监测中准确、统一分析心电图（ECG）和脑电图（EEG）等多种生物信号的日益增长的需求，同时弥合现有技术在处理和提取不同生理信号特征方面的统一架构的差距，并解决生物医学数据中普遍存在的类别不平衡问题。

Method: 本研究提出了一种统一的深度学习框架，结合了基于ResNet的卷积神经网络（CNN）和注意力机制。为了解决数据不平衡问题，采用了时间域信号连接增强策略和Focal Loss函数。此外，还采用了小波去噪、基线去除、标准化、正则化以及增加信号复杂度以提高预测能力。

Result: 所提出的统一深度学习框架在UCI癫痫EEG、MIT-BIH心律失常和PTB诊断ECG三个基准数据集上取得了99.96%、99.78%和100%的准确率，展示了在不同信号类型和临床环境中的鲁棒性。该框架内存占用约130MB，处理速度约为10毫秒/样本，适用于低端或可穿戴设备。

Conclusion: 该研究提出了一种新颖统一的深度学习框架，集成了基于ResNet的CNN和注意力机制，并通过一种新的数据增强策略（时间域连接多个增强信号变体）来处理和提取不同生理信号的特征。该框架有效解决了生物医学数据中固有的类别不平衡问题，并在三个基准数据集（UCI癫痫EEG、MIT-BIH心律失常和PTB诊断ECG）上取得了最先进的性能，准确率分别为99.96%、99.78%和100%。此外，该框架内存占用约130MB，处理速度约为10毫秒/样本，表明其适用于低端或可穿戴设备。

Abstract: The increasing need for accurate and unified analysis of diverse biological
signals, such as ECG and EEG, is paramount for comprehensive patient
assessment, especially in synchronous monitoring. Despite advances in
multi-sensor fusion, a critical gap remains in developing unified architectures
that effectively process and extract features from fundamentally different
physiological signals. Another challenge is the inherent class imbalance in
many biomedical datasets, often causing biased performance in traditional
methods. This study addresses these issues by proposing a novel and unified
deep learning framework that achieves state-of-the-art performance across
different signal types. Our method integrates a ResNet-based CNN with an
attention mechanism, enhanced by a novel data augmentation strategy:
time-domain concatenation of multiple augmented variants of each signal to
generate richer representations. Unlike prior work, we scientifically increase
signal complexity to achieve future-reaching capabilities, which resulted in
the best predictions compared to the state of the art. Preprocessing steps
included wavelet denoising, baseline removal, and standardization. Class
imbalance was effectively managed through the combined use of this advanced
data augmentation and the Focal Loss function. Regularization techniques were
applied during training to ensure generalization. We rigorously evaluated the
proposed architecture on three benchmark datasets: UCI Seizure EEG, MIT-BIH
Arrhythmia, and PTB Diagnostic ECG. It achieved accuracies of 99.96%, 99.78%,
and 100%, respectively, demonstrating robustness across diverse signal types
and clinical contexts. Finally, the architecture requires ~130 MB of memory and
processes each sample in ~10 ms, suggesting suitability for deployment on
low-end or wearable devices.

</details>


### [271] [Enhancing Urban GNSS Positioning Reliability via Conservative Satellite Selection Using Unanimous Voting Across Multiple Machine Learning Classifiers](https://arxiv.org/abs/2507.12706)
*Sanghyun Kim,Jiwon Seo*

Main category: eess.SP

TL;DR: 在城市环境中，由于建筑物造成的信号阻塞和多径效应，GNSS定位常常受到影响。本研究提出了一种改进的ZSM定位方法，通过集成多种机器学习分类器的一致投票来保守地选择卫星，从而提高定位精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了解决城市环境中建筑物造成的GNSS信号阻塞和多径效应导致的显著定位误差问题。

Method: 通过使用多种机器学习分类器（随机森林、梯度提升决策树和支持向量机）进行一致投票的保守卫星选择策略，增强了基于区域化影匹配（ZSM）的定位。

Result: 实验结果表明，所提出的方法显著提高了定位成功率和接收器包含率，即使在LOS/NLOS分类不完美的情况下也是如此。

Conclusion: 该方法显著提高了城市GNSS环境下的定位成功率和接收器包含率，尽管由于使用的卫星数量减少导致位置边界略有增加，但整体定位可靠性得到了显著增强。

Abstract: In urban environments, global navigation satellite system (GNSS) positioning
is often compromised by signal blockages and multipath effects caused by
buildings, leading to significant positioning errors. To address this issue,
this study proposes a robust enhancement of zonotope shadow matching
(ZSM)-based positioning by employing a conservative satellite selection
strategy using unanimous voting across multiple machine learning classifiers.
Three distinct models - random forest (RF), gradient boosting decision tree
(GBDT), and support vector machine (SVM) - were trained to perform
line-of-sight (LOS) and non-line-of-sight (NLOS) classification based on global
positioning system (GPS) signal features. A satellite is selected for
positioning only when all classifiers unanimously agree on its classification
and their associated confidence scores exceed a threshold. Experiments with
real-world GPS data collected in dense urban areas demonstrate that the
proposed method significantly improves the positioning success rate and the
receiver containment rate, even with imperfect LOS/NLOS classification.
Although a slight increase in the position bound was observed due to the
reduced number of satellites used, overall positioning reliability was
substantially enhanced, indicating the effectiveness of the proposed approach
in urban GNSS environments.

</details>


### [272] [Beamforming Tradeoff for Sensing and Communication in Cell-Free MIMO](https://arxiv.org/abs/2507.12917)
*Xi Ding,Luca Kunz,E. Jorswieck*

Main category: eess.SP

TL;DR: 本研究提出了一种新的基于SDR的优化框架，用于解决小尺度无小区MIMO（CF-MIMO）系统中联合感知和通信（JSAC）的最佳联合波束形成（BF）问题。该框架能够保证全局最优解，无需后处理，并且比现有方法更具计算效率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决小尺度无小区MIMO（CF-MIMO）系统中联合感知和通信（JSAC）的最佳联合波束形成（BF）问题。现有方法（如SCA和SDR）要么缺乏全局最优性，要么需要额外的秩缩减步骤。

Method: 提出了一种基于半正定松弛（SDR）的优化框架，该框架保证了全局最优解，无需后处理。

Result: 与现有方法相比，本研究提出的SDR框架能够获得全局最优解，并且不需要额外的后处理步骤。此外，还引入了一种独立的BF策略作为性能基准。

Conclusion: 该框架提供了一个全局最优且计算效率高的波束形成设计，为下一代无线网络的发展提供了宝贵的见解。

Abstract: This paper studies optimal joint beamforming (BF) for joint sensing and
communication (JSAC) in small-scale cell-free MIMO (CF-MIMO) systems. While
prior works have explored JSAC optimization using methods such as successive
convex approximation (SCA) and semidefinite relaxation (SDR), many of these
approaches either lack global optimality or require additional rank-reduction
steps. In contrast, we propose an SDR-based optimization framework that
guarantees globally optimal solutions without post-processing. To benchmark its
performance, we introduce a standalone BF strategy that dedicates each access
point (AP) exclusively to either communication or sensing. The proposed
formulation builds upon a general multi-user system model, enabling future
extensions beyond the single-user setting. Overall, our framework offers a
globally optimal and computationally efficient BF design, providing valuable
insights for the development of next-generation wireless networks.

</details>


### [273] [Multiple-Mode Affine Frequency Division Multiplexing with Index Modulation](https://arxiv.org/abs/2507.13037)
*Guangyao Liu,Tianqi Mao,Yanqun Tang,Jingjing Zhao,Zhenyu Xiao*

Main category: eess.SP

TL;DR: MM-AFDM-IM是一种用于AFDM的新型索引调制方案，通过利用多种星座图和 the dynamic patterns of both constellation mode selection and chirp activation 来提高通信效率，并验证了其优越的性能。


<details>
  <summary>Details</summary>
Motivation: 为了进一步提高AFDM系统的频谱和能量效率，应对高移动性通信场景。

Method: 提出了一种用于AFDM的多模式索引调制方案（MM-AFDM-IM），实现了多种星座图和 the dynamic patterns of both constellation mode selection and chirp activation 来传输额外信息位，并推导了在最大似然检测下的误码率（BER）的渐近上界。

Result: 仿真结果表明，MM-AFDM-IM相比于传统基准方案具有更优越的性能。

Conclusion: 所提出的MM-AFDM-IM方案性能优于传统基准方案。

Abstract: Affine frequency division multiplexing (AFDM), a promising multicarrier
technique utilizing chirp signals, has been envisioned as an effective solution
for high-mobility communication scenarios. In this paper, we develop a
multiple-mode index modulation scheme tailored for AFDM, termed as MM-AFDM-IM,
which aims to further improve the spectral and energy efficiencies of AFDM.
Specifically, multiple constellation alphabets are selected for different
chirp-based subcarriers (chirps). Aside from classical amplitude/phase
modulation, additional information bits can be conveyed by the dynamic patterns
of both constellation mode selection and chirp activation, without extra energy
consumption. Furthermore, we discuss the mode selection strategy and derive an
asymptotically tight upper bound on the bit error rate (BER) of the proposed
scheme under maximum-likelihood detection. Simulation results are provided to
demonstrate the superior performance of MM-AFDM-IM compared to conventional
benchmark schemes.

</details>


### [274] [Multifrequency system model for multiport time-modulated scatterers](https://arxiv.org/abs/2507.13130)
*Aleksandr D. Kuznetsov,Jari Holopainen,Ville Viikari*

Main category: eess.SP

TL;DR: 通信工程需要精确的散射模型。本文提出了一种新的多端口S参数模型，可以处理多频操作和时域调制，并得到了实验验证。


<details>
  <summary>Details</summary>
Motivation: 现有的散射模型难以满足通信工程中多频操作和互调谐波的需求，尤其是在涉及空间-时间调制或动态负载控制时。

Method: 提出了一种基于S参数的多端口模型，该模型能够预测多频工作结构（包括具有空间-时间调制或动态负载控制的结构）的散射特性，并考虑了结构散射、互耦、非数字调制和非周期配置。

Result: 该模型扩展了S矩阵模型在时域调制多端口结构中的应用，能够同时捕捉跨越多个频率和方向的散射行为。

Conclusion: 该模型通过实验结果验证了其准确性和实用性，可用于多种通信和传感系统。

Abstract: Utilizing scatterers in communication engineering, such as reconfigurable
intelligent surfaces (RISs) and backscatter systems, requires physically
consistent models for accurate performance prediction. A multiport model, which
also accounts for structural scattering, has been developed for non-periodic
scatterers. However, many emerging systems operate at multiple frequencies or
generate intermodulation harmonics, particularly when incorporating space-time
modulation (STM) or dynamic load control. These functionalities demand advanced
modeling approaches capable of capturing scattering behavior across several
frequencies and directions simultaneously. This article extends a multiport
S-parameters-based model for predicting the scattering properties of
multifrequency operating structures. The model extends the applicability of
convenient S-matrix models to time-modulated multiport structures. Unlike known
approaches, this model incorporates structural scattering, mutual coupling, the
possibility of non-digital modulation, and non-periodic configurations,
enabling precise analysis and optimization for a broad range of communication
and sensing systems. Validation against experimental results for a space-time
modulated scattering structure demonstrates the accuracy and practical
applicability of the proposed model.

</details>


### [275] [Unmodulated Visible Light Positioning: A Deep Dive into Techniques, Studies, and Future Prospects](https://arxiv.org/abs/2507.13080)
*Morteza Alijani,Wout Joseph,David Plets*

Main category: eess.SP

TL;DR: 该论文介绍了无调制可见光定位（uVLP），这是一种利用现有LED照明的低成本、高精度室内定位技术。它解决了传统VLP的局限性，并对现有技术进行了分类和评估，指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统VLP技术在调制LED方面成本高、操作复杂以及降低照明效率的问题，提出了uVLP的概念。

Method: 对uVLP技术进行了分类，根据接收器技术分为基于强度（如光电二极管、太阳能电池等）和基于成像的方法。此外，还提出了一个全面的技术分类，将技术分为解复用和非解复用方法。

Result: 对uVLP的当前进展进行了批判性审查，讨论了存在的挑战，并概述了有希望的研究方向，为开发稳健、可扩展且广泛可部署的uVLP解决方案奠定了基础。

Conclusion: uVLP通过利用非调制光源（如传统LED）发出的“机遇之光”（LSOOP），提供了一种低成本、低基础设施的室内定位替代方案，消除了对调制硬件的需求，并保持了照明效率。该论文阐述了uVLP的原理，并将其与传统VLP方法进行了比较分析。

Abstract: Visible Light Positioning (VLP) has emerged as a promising technology for
next-generation indoor positioning systems (IPS), particularly within the scope
of sixth-generation (6G) wireless networks. Its attractiveness stems from
leveraging existing lighting infrastructures equipped with light-emitting
diodes (LEDs), enabling cost-efficient deployments and achieving high-precision
positioning accuracy in the centimeter-todecimeter range. However, widespread
adoption of traditional VLP solutions faces significant barriers due to the
increased costs and operational complexity associated with modulating LEDs,
which consequently reduces illumination efficiency by lowering their radiant
flux. To address these limitations, recent research has introduced the concept
of unmodulated Visible Light Positioning (uVLP), which exploits Light Signals
of Opportunity (LSOOP) emitted by unmodulated illumination sources such as
conventional LEDs. This paradigm offers a cost-effective, lowinfrastructure
alternative for indoor positioning by eliminating the need for modulation
hardware and maintaining lighting efficiency. This paper delineates the
fundamental principles of uVLP, provides a comparative analysis of uVLP versus
conventional VLP methods, and classifies existing uVLP techniques according to
receiver technologies into intensity-based methods (e.g., photodiodes, solar
cells, etc.) and imaging-based methods. Additionally, we propose a
comprehensive taxonomy categorizing techniques into demultiplexed and
undemultiplexed approaches. Within this structured framework, we critically
review current advancements in uVLP, discuss prevailing challenges, and outline
promising research directions essential for developing robust, scalable, and
widely deployable uVLP solutions.

</details>


### [276] [Angle Estimation of a Single Source with Massive Uniform Circular Arrays](https://arxiv.org/abs/2507.13086)
*Mingyan Gong*

Main category: eess.SP

TL;DR: 提出了一种用于大规模均匀圆阵的二维DOA估计算法，该算法计算简单，适用于实时处理，并能估计方位角和俯仰角。


<details>
  <summary>Details</summary>
Motivation: 为了解决均匀线性阵列只能提供声源方位角估计的问题，提出一种用于大规模均匀圆阵的二维DOA估计算法，以提供360°方位角覆盖和额外的俯仰角信息。

Method: 该方法通过计算和比较协方差来获得量化的方位角估计，然后通过一个显式公式获得俯仰角估计。

Result: 提出的方法计算简单，适用于实时信号处理，并且能够获得方位角和俯仰角估计。

Conclusion: 该方法可以获得方位角和俯仰角估计，并且这些估计可以作为多维搜索的起点，以获得更高的精度。此外，该方法在存在非均匀噪声的情况下仍然可以工作。

Abstract: Estimating the directions of arrival (DOAs) of incoming plane waves is an
essential topic in array signal processing. Widely adopted uniform linear
arrays can only provide estimates of source azimuth. Thus, uniform circular
arrays (UCAs) are attractive in that they can provide $360^{\circ}$ azimuthal
coverage and additional elevation angle information. Considering that with a
massive UCA, its polar angles of array sensors can approximately represent
azimuth angles over $360^{\circ}$ using angle quantization, a simple
two-dimensional DOA estimation method for a single source is proposed. In this
method, the quantized azimuth angle estimate is obtained by only calculating
and comparing a number of covariances, based on which the elevation angle
estimate is then obtained by an explicit formula. Thus, the proposed method is
computationally simple and suitable for real-time signal processing. Numerical
results verify that the proposed method can obtain azimuth as well as elevation
angle estimates and the estimates can be used as starting points of
multidimensional searches for methods with higher accuracy. Additionally, the
proposed method can still work in the presence of nonuniform noise.

</details>


### [277] [Disentangling coincident cell events using deep transfer learning and compressive sensing](https://arxiv.org/abs/2507.13176)
*Moritz Leuthner,Rafael Vorländer,Oliver Hayden*

Main category: eess.SP

TL;DR: 提出了一种基于FCN和CS的混合框架，用于解决单细胞传感中的重叠事件问题，提高了分析准确性，并具有良好的可解释性和广泛的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了提高单细胞分析的准确性，解决由于多个细胞在传感区域重叠而导致的信号保真度下降问题。

Method: 提出了一种结合全卷积神经网络（FCN）和压缩传感（CS）的混合框架，用于分离一维传感器数据中的重叠事件。FCN用于估计重叠事件数量，CS模块用于重建单个信号分量。

Result: 与传统的状态机算法相比，该框架在恢复事件数量上提高了21%，并将分类准确率提高到97%以上，能够精确恢复单个细胞的特征，如速度、幅度和流体动力学直径。

Conclusion: 该混合框架为解决单细胞传感平台中的重叠事件问题提供了有效且可解释的解决方案，为开发下一代非光学单细胞传感技术奠定了基础，具有广泛的临床应用前景。

Abstract: Accurate single-cell analysis is critical for diagnostics, immunomonitoring,
and cell therapy, but coincident events - where multiple cells overlap in a
sensing zone - can severely compromise signal fidelity. We present a hybrid
framework combining a fully convolutional neural network (FCN) with compressive
sensing (CS) to disentangle such overlapping events in one-dimensional sensor
data. The FCN, trained on bead-derived datasets, accurately estimates
coincident event counts and generalizes to immunomagnetically labeled CD4+ and
CD14+ cells in whole blood without retraining. Using this count, the CS module
reconstructs individual signal components with high fidelity, enabling precise
recovery of single-cell features, including velocity, amplitude, and
hydrodynamic diameter. Benchmarking against conventional state-machine
algorithms shows superior performance - recovering up to 21% more events and
improving classification accuracy beyond 97%. Explinability via class
activation maps and parameterized Gaussian template fitting ensures
transparency and clinical interpretability. Demonstrated with magnetic flow
cytometry (MFC), the framework is compatible with other waveform-generating
modalities, including impedance cytometry, nanopore, and resistive pulse
sensing. This work lays the foundation for next-generation non-optical
single-cell sensing platforms that are automated, generalizable, and capable of
resolving overlapping events, broadening the utility of cytometry in
translational medicine and precision diagnostics, e.g. cell-interaction
studies.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [278] [Quantum Transfer Learning to Boost Dementia Detection](https://arxiv.org/abs/2507.12485)
*Sounak Bhowmik,Talita Perciano,Himanshu Thapliyal*

Main category: quant-ph

TL;DR: 量子迁移学习 (QTL) 可以提高痴呆症检测的性能，并研究了噪声对 QTL 方法的影响。


<details>
  <summary>Details</summary>
Motivation: 为了解决经典机器学习和深度学习方法在处理高维生物医学数据和大规模数据集时遇到的计算和性能限制，量子机器学习 (QML) 作为一种有前途的范式出现，能够实现更快的训练和高级的模式识别。

Method: 本研究旨在演示量子迁移学习 (QTL) 在增强应用于痴呆症检测的二元分类任务的经典深度学习模型方面的潜力，并研究噪声对基于 QTL 的方法的影响。

Result: 使用 OASIS 2 数据集，研究表明量子技术可以改进痴呆症检测的性能。

Conclusion: 量子技术有潜力将表现不佳的经典模型转化为更有效的生物医学图像分类解决方案，有望推动医疗保健技术的进步。

Abstract: Dementia is a devastating condition with profound implications for
individuals, families, and healthcare systems. Early and accurate detection of
dementia is critical for timely intervention and improved patient outcomes.
While classical machine learning and deep learning approaches have been
explored extensively for dementia prediction, these solutions often struggle
with high-dimensional biomedical data and large-scale datasets, quickly
reaching computational and performance limitations. To address this challenge,
quantum machine learning (QML) has emerged as a promising paradigm, offering
faster training and advanced pattern recognition capabilities. This work aims
to demonstrate the potential of quantum transfer learning (QTL) to enhance the
performance of a weak classical deep learning model applied to a binary
classification task for dementia detection. Besides, we show the effect of
noise on the QTL-based approach, investigating the reliability and robustness
of this method. Using the OASIS 2 dataset, we show how quantum techniques can
transform a suboptimal classical model into a more effective solution for
biomedical image classification, highlighting their potential impact on
advancing healthcare technology.

</details>


### [279] [Sporadic Federated Learning Approach in Quantum Environment to Tackle Quantum Noise](https://arxiv.org/abs/2507.12492)
*Ratun Rahman,Atit Pokharel,Dinh C. Nguyen*

Main category: quant-ph

TL;DR: 量子联邦学习（QFL）框架SpoQFL通过零星学习技术有效缓解了量子噪声异质性问题，并在真实数据集上实现了优于传统QFL方法的训练性能和收敛稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的量子联邦学习（QFL）框架在应对现代量子设备中存在的异质量子噪声方面存在不足。这种噪声异质性源于硬件质量和量子退相干敏感度的差异，从而导致训练性能不佳。为了解决这个问题，需要一种能够有效缓解量子噪声异质性的QFL框架。

Method: 提出了一种名为SpoQFL的新型QFL框架，该框架利用零星学习来缓解分布式量子系统中的量子噪声异质性。SpoQFL根据噪声波动动态调整训练策略，以增强模型的鲁棒性、收敛稳定性和整体学习效率。

Result: SpoQFL在真实数据集上的广泛实验证明，其性能显著优于传统的QFL方法，实现了更优的训练性能和更稳定的收敛性。

Conclusion: SpoQFL通过利用零星学习来缓解分布式量子系统中的量子噪声异质性，在真实数据集上的广泛实验证明，SpoQFL的性能显著优于传统的QFL方法，实现了更优的训练性能和更稳定的收敛性。

Abstract: Quantum Federated Learning (QFL) is an emerging paradigm that combines
quantum computing and federated learning (FL) to enable decentralized model
training while maintaining data privacy over quantum networks. However, quantum
noise remains a significant barrier in QFL, since modern quantum devices
experience heterogeneous noise levels due to variances in hardware quality and
sensitivity to quantum decoherence, resulting in inadequate training
performance. To address this issue, we propose SpoQFL, a novel QFL framework
that leverages sporadic learning to mitigate quantum noise heterogeneity in
distributed quantum systems. SpoQFL dynamically adjusts training strategies
based on noise fluctuations, enhancing model robustness, convergence stability,
and overall learning efficiency. Extensive experiments on real-world datasets
demonstrate that SpoQFL significantly outperforms conventional QFL approaches,
achieving superior training performance and more stable convergence.

</details>


### [280] [Efficient Classical-Processing of Constant-Depth Time Evolution Circuits in Control Hardware](https://arxiv.org/abs/2507.12765)
*Akhil Francis,Abhi D. Rajagopala,Norm M. Tubman,Katherine Klymko,Kasra Nowrouzi*

Main category: quant-ph

TL;DR: 通过硬件辅助的参数化电路执行 (PCE) 优化量子算法的经典处理，将自旋模型的计算时间缩短了 50%。


<details>
  <summary>Details</summary>
Motivation: 提高量子算法的运行时间性能，特别是通过优化经典处理。

Method: 通过硬件辅助的参数化电路执行 (PCE) 来减少经典处理和编译时间，并利用结构等效性。

Result: 在 Transverse field XY 和 Heisenberg 自旋模型中，与标准编译方法相比，使用硬件辅助 PCE 的运行时间减少了高达 50%。

Conclusion: 这项工作展示了时间演化电路与硬件辅助 PCE 的适应性，以可能缓解近期量子算法中的经典瓶颈。

Abstract: Improving quantum algorithms run-time performance involves several strategies
such as reducing the quantum gate counts, decreasing the number of
measurements, advancement in QPU technology for faster gate operations, or
optimizing the classical processing. This work focuses on the latter,
specifically reducing classical processing and compilation time via
hardware-assisted parameterized circuit execution (PCE) for computing dynamical
properties of quantum systems. PCE was previously validated for QCVV protocols,
which leverages structural circuit equivalencies. We demonstrate the
applicability of this approach to computing dynamical properties of quantum
many-body systems using structurally equivalent time evolution circuits,
specifically calculating correlation functions of spin models using
constant-depth circuits generated via Cartan decomposition. Implementing this
for spin-spin correlation functions in Transverse field XY (up to 6-sites) and
Heisenberg spin models (up to 3-sites), we observed a run-time reduction of up
to 50\% compared to standard compilation methods. This highlights the
adaptability of time-evolution circuit with hardware-assisted PCE to
potentially mitigate the classical bottlenecks in near-term quantum algorithms.

</details>


### [281] [Leveraging Quantum Layers in Classical Neural Networks](https://arxiv.org/abs/2507.12505)
*Silvie Illésová*

Main category: quant-ph

TL;DR: 该论文探索了在经典卷积神经网络中加入量子层，以提高机器学习性能，并取得了有希望的结果。


<details>
  <summary>Details</summary>
Motivation: 为了利用量子纠缠和特征映射来增强学习能力，探索了混合量子-经典神经网络。

Method: 该论文提出了一种将量子层集成到经典卷积神经网络架构中的详细方法，并使用PyTorch和Qiskit机器学习框架进行了实现和训练。

Result: 实验表明，即使在有限数量的量子比特下，量子组件也能引入有意义的转换，这表明了量子机器学习的可扩展性。

Conclusion: 混合量子-经典神经网络在机器学习模型改进方面展现出巨大潜力。

Abstract: Hybrid quantum-classical neural networks represent a promising frontier in
the search for improved machine learning models. This thesis explores the
integration of quantum layers within classical convolutional neural network
architectures, aiming to leverage quantum entanglement and feature mapping to
enhance learning capabilities. A detailed methodology for constructing and
training such hybrid models is presented, using PyTorch and Qiskit Machine
Learning frameworks. Experiments investigate the performance impact of
inserting quantum layers at different stages of the neural network pipeline.
The results suggest that quantum components can introduce meaningful
transformations even with a limited number of qubits, motivating further
research into scalable quantum machine learning. The full implementation is
made publicly available, and future work will focus on expanding experimental
evaluations and publishing additional findings.

</details>


### [282] [Unfolded distillation: very low-cost magic state preparation for biased-noise qubits](https://arxiv.org/abs/2507.12511)
*Diego Ruiz,Jérémie Guillaud,Christophe Vuillot,Mazyar Mirrahimi*

Main category: quant-ph

TL;DR: 提出一种低成本的魔态蒸馏方案，通过噪声偏差制备高保真魔态，显著降低量子计算资源消耗。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有魔态蒸馏方案在空间和时间上的巨大开销，特别是在有噪声的量子计算环境中，本研究旨在设计一种低成本的魔态蒸馏方案。

Method: 提出了一种基于X稳定子群展开的物理层魔态蒸馏方案，称为“展开蒸馏”，相较于现有方案，在资源消耗和适用性方面具有显著优势。

Result: 该方案可在噪声偏差（η ≳ 5 × 10^6）和比特翻转率（0.1%）下，以53个量子比特和5.5个纠错轮次制备出逻辑错误率为3 × 10^-7的魔态，将电路规模降低了一个数量级以上。

Conclusion: 该研究提出了一种低成本的魔态蒸馏方案，利用噪声偏差制备高保真度魔态，可大幅降低量子计算的资源开销，并具有仅需近邻两比特门、对噪声偏差不敏感以及在高比特翻转率下仍有效等优点。

Abstract: Magic state distillation enables universal fault-tolerant quantum computation
by implementing non-Clifford gates via the preparation of high-fidelity magic
states. However, it comes at the cost of substantial logical-level overhead in
both space and time. In this work, we propose a very low-cost magic state
distillation scheme for biased-noise qubits. By leveraging the noise bias, our
scheme enables the preparation of a magic state with a logical error rate of $3
\times 10^{-7}$, using only 53 qubits and 5.5 error correction rounds, under a
noise bias of $\eta \gtrsim 5 \times 10^6$ and a phase-flip noise rate of
$0.1\%$. This reduces the circuit volume by more than one order of magnitude
relative to magic state cultivation for unbiased-noise qubits and by more than
two orders of magnitude relative to standard magic state distillation.
Moreover, our scheme provides three key advantages over previous proposals for
biased-noise qubits. First, it only requires nearest-neighbor two-qubit gates
on a 2D lattice. Second, the logical fidelity remains nearly identical even at
a more modest noise bias of $\eta \gtrsim 80$, at the cost of a slightly
increased circuit volume. Third, the scheme remains effective even at high
physical phase-flip rates, in contrast to previously proposed approaches whose
circuit volume grows exponentially with the error rate. Our construction is
based on unfolding the $X$ stabilizer group of the Hadamard 3D quantum
Reed-Muller code in 2D, enabling distillation at the physical level rather than
the logical level, and is therefore referred to as $\textit{unfolded}$
distillation.

</details>


### [283] [Hybrid satellite-fiber quantum network](https://arxiv.org/abs/2507.12539)
*Yanxuan Shao,Saikat Guha,Adilson E. Motter*

Main category: quant-ph

TL;DR: 量子网络因传输损耗受限，我们提出一种混合地面-卫星方案，实现更大规模、更高保真度的纠缠分发。


<details>
  <summary>Details</summary>
Motivation: 量子网络在密钥分发、分布式计算和量子传感等领域具有巨大潜力，但目前地面用户的量子网络规模受限于远距离纠缠分发的能力，无论是通过光纤还是卫星，都存在传输损耗问题。

Method: 提出了一种结合地面和卫星链路的混合网络和协议。

Result: 提出的混合网络和协议在纠缠分发方面优于纯地面或纯卫星设计，能在大陆甚至全球范围内实现高保真度的纠缠。

Conclusion: 通过结合地面和卫星链路，我们提出了一种混合网络和协议，有望实现更大规模、更高保真度的量子纠缠分发，从而克服现有技术的局限性。

Abstract: Quantum networks hold promise for key distribution, private and distributed
computing, and quantum sensing, among other applications. The scale of such
networks for ground users is currently limited by one's ability to distribute
entanglement between distant locations. This can in principle be carried out by
transmitting entangled photons through optical fibers or satellites. The former
is limited by fiber optic attenuation while the latter is limited by
atmospheric extinction and diffraction. Here, we propose a hybrid network and
protocol that outperform both ground- and satellite-based designs and lead to
high-fidelity entanglement at a continental or even global scale.

</details>


### [284] [Spacetime duality between sequential and measurement-feedback circuits](https://arxiv.org/abs/2507.12523)
*Tsung-Cheng Lu,Sarang Gopalakrishnan,Yizhi You*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Two prevalent approaches for preparing long-range entangled quantum states
are (i) linear-depth sequential unitary (SU) circuits, which apply local
unitary gates sequentially, and (ii) constant-depth measurement-feedback (MF)
circuits, which employ mid-circuit measurements and conditional feedback based
on measurement outcomes. Here, we establish that a broad class of SU and MF
circuits are dual to each other under a spacetime rotation. We investigate this
spacetime duality in the preparation of various long-range entangled states,
including GHZ states, topologically ordered states, and fractal
symmetry-breaking states. As an illustration, applying a spacetime rotation to
a linear-depth SU circuit that implements a non-invertible Kramers-Wannier
duality, originally used to prepare a 1D GHZ state, yields a constant-depth MF
circuit that implements a $\mathbb{Z}_2$ symmetry gauging map, which
equivalently prepares the GHZ state. Leveraging this duality, we further
propose experimental protocols that require only a constant number of qubits to
measure unconventional properties of 1D many-body states. These include (i)
measurement of disorder operators, which diagnose the absence of spontaneous
symmetry breaking, and (ii) postselection-free detection of measurement-induced
long-range order, which emerges in certain symmetry-protected topological
phases. We also show that measurement-induced long-range order provides a lower
bound for strange correlators, which may be of independent interest.

</details>


### [285] [Emergence of Generic Entanglement Structure in Doped Matchgate Circuits](https://arxiv.org/abs/2507.12526)
*Alessio Paviglianiti,Luca Lumia,Emanuele Tirrito,Alessandro Silva,Mario Collura,Xhek Turkeshi,Guglielmo Lami*

Main category: quant-ph

TL;DR: 非高斯性是驱动自由费米子高斯电路从异常动力学（缓慢纠缠增长）向典型动力学（弹道式纠缠增长和体量律纠缠）转变的关键资源，并影响测量诱导的相变。


<details>
  <summary>Details</summary>
Motivation: 研究非高斯性如何恢复自由费米子高斯电路中典型的纠缠结构，以及测量对系统的影响。

Method: 通过注入非高斯门来研究自由费米子高斯电路的动力学和纠缠特性，并分析测量对系统的影响，揭示了测量诱导的相变。

Result: 非高斯门可以恢复弹道式纠缠增长和Kardar-Parisi-Zhang涨落，并引发测量诱导的相变。

Conclusion: 注入非高斯性资源（门）可以恢复自由费米子高斯电路中典型动力学的纠缠结构，能够恢复弹道式纠缠增长（S(t) ~ t）和Kardar-Parisi-Zhang涨落。测量扰动下，可以揭示一个由测量诱导的相变，在面积律和幂律纠缠相（S ~ N^α）之间，并且只有在以大量程速率注入非高斯门时才能恢复真正的体量律纠缠相。

Abstract: Free fermionic Gaussian, a.k.a. matchgate, random circuits exhibit atypical
behavior compared to generic interacting systems. They produce anomalously slow
entanglement growth, characterized by diffusive scaling $S(t) \sim \sqrt{t}$,
and evolve into volume-law entangled states at late times, $S \sim N$, which
are highly unstable to measurements. Here, we investigate how doping such
circuits with non-Gaussian resources (gates) restores entanglement structures
of typical dynamics. We demonstrate that ballistic entanglement growth $S(t)
\sim t$ is recovered after injecting an extensive total amount of non-Gaussian
gates, also restoring Kardar-Parisi-Zhang fluctuations. When the evolution is
perturbed with measurements, we uncover a measurement-induced phase transition
between an area-law and a power-law entangled phase, $S \sim N^\alpha$, with
$\alpha$ controlled by the doping. A genuine volume-law entangled phase is
recovered only when non-Gaussian gates are injected at an extensive rate. Our
findings bridge the dynamics of free and interacting fermionic systems,
identifying non-Gaussianity as a key resource driving the emergence of
non-integrable behavior.

</details>


### [286] [Scalable dissipative quantum error correction for discrete-variable codes](https://arxiv.org/abs/2507.12534)
*Ivan Rojkov,Elias Zapusek,Florentin Reiter*

Main category: quant-ph

TL;DR: 提出了一种可扩展的耗散量子纠错协议，通过“涓流”机制降低错误权重，减少了纠错算符的数量，并证明了其在重复码上的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有量子纠错（QEC）方案在扩展性方面存在的挑战，特别是纠正高权重错误时需要增加耗散率和指数级算符数量的问题。

Method: 提出了一种可扩展的离散变量码耗散量子纠错协议，通过“涓流”机制逐步降低错误权重，并利用Knill-Laflamme条件的冗余设计作用于多个错误子空间同时作用的纠错算符，将开销从指数级降低到多项式级。

Result: 所提出的协议将纠错算符的开销从指数级降低到多项式级，并在模拟带有偏噪声的重复码时，在实际物理错误率下实现了四倍的指数抑制因子。

Conclusion: 该方法将自主量子纠错与离散变量码相结合，并与已演示的腔物态码耗散协议相联系，为传统的测量反馈量子纠错和容错量子运算开辟了新途径。

Abstract: Dissipative quantum error correction (QEC) autonomously protects quantum
information using engineered dissipation and offers a promising alternative to
error correction via measurement and feedback. However, scalability remains a
challenge, as correcting high-weight errors typically requires increasing
dissipation rates and exponentially many correction operators. Here, we present
a scalable dissipative QEC protocol for discrete-variable codes, correcting
multi-qubit errors via a trickle-down mechanism that sequentially reduces
errors weight. Our construction exploits redundancy in the Knill-Laflamme
conditions to design correction operators that act on multiple error subspaces
simultaneously, thereby reducing the overhead from exponential to polynomial in
the number of required operators. We illustrate our approach with repetition
codes under biased noise, showing a fourfold improvement in the exponential
suppression factor at realistic physical error rates. Our approach connects
autonomous QEC for discrete-variable codes with demonstrated dissipative
protocols for bosonic codes and opens up new avenues for traditional
measurement-feedback QEC and fault-tolerant quantum operations.

</details>


### [287] [Technical Review on RF-Amplifiers for Quantum Computer Circuits: New Architectures of Josephson Parametric Amplifier](https://arxiv.org/abs/2507.13187)
*Ahmad Salmanogli,Hesam Zandi,Mahdi Esmaeili,Abolfazl Eskandari,Mohsen Akbari*

Main category: quant-ph

TL;DR: JPA是量子信息处理的关键，优于CMOS和HEMT放大器。本研究提出并验证了基于约瑟夫森结阵列的JPA设计，其性能优于传统单结JPA。


<details>
  <summary>Details</summary>
Motivation: 约瑟夫森参量放大器（JPA）在量子信息处理中对于放大量子信号至关重要，能够以近量子极限的噪声性能实现信号的保真度和相干性。然而，传统放大器在低温环境下存在性能瓶颈。因此，有必要深入研究JPA在低温量子应用中的优势，并提出优化的JPA设计方案。

Method: 本研究首先对比了CMOS、HEMT放大器和JPA在低温量子应用中的性能，阐述了JPA的优势。随后，研究深入探讨了基于单结约瑟夫森结和结阵列的JPA设计与分析。研究中采用了量子理论和CAD工具对多种先进JPA架构进行了模拟和比较，以评估其性能。最终，研究提出并分析了使用约瑟夫森结阵列的JPA设计，以克服单结JPA的局限性。

Result: 本研究通过对比分析，证明了JPA在低温量子应用中的优越性。研究还发现，基于约瑟夫森结阵列的JPA设计相比于单结JPA，在功率处理能力、线性度、阻抗可调性和相干性方面均有显著提升，并能有效降低相位噪声。

Conclusion: 约瑟夫森参量放大器（JPA）因其在放大量子信号方面表现出的近量子极限噪声性能，在量子信息处理中扮演着关键角色。与传统的CMOS和HEMT放大器相比，JPA在微开尔文（mK）低温环境中具有低功耗、超低噪声和出色的低温兼容性等优势。本研究首先对比了不同类型的射频放大器，并阐述了JPA在低温量子应用中的优越性。接着，研究深入探讨了基于单结约瑟夫森结和结阵列的JPA设计与分析。为克服单结JPA的增益压缩、动态范围有限和易受制 fabrication 影响等缺点，本研究探索了使用约瑟夫森结阵列的JPA设计，通过分散非线性响应来提高功率处理能力、线性度、阻抗可调性和相干性，并降低相位噪声。最终，研究提出了多种先进的JPA架构，并利用量子理论和CAD工具进行了模拟和比较，以评估其性能权衡和相对于传统设计的改进。

Abstract: Josephson Parametric Amplifiers (JPAs) are key components in quantum
information processing due to their ability to amplify weak quantum signals
with near-quantum-limited noise performance. This is essential for applications
such as qubit readout, quantum sensing, and communication, where signal
fidelity and coherence preservation are critical. Unlike CMOS and HEMT
amplifiers used in conventional RF systems, JPAs are specifically optimized for
millikelvin (mK) cryogenic environments. CMOS amplifiers offer good integration
but perform poorly at ultra-low temperatures due to high noise. HEMT amplifiers
provide better noise performance but are power-intensive and less suited for mK
operation. JPAs, by contrast, combine low power consumption with ultra-low
noise and excellent cryogenic compatibility, making them ideal for quantum
systems. The first part of this study compares these RF amplifier types and
explains why JPAs are preferred in cryogenic quantum applications. The second
part focuses on the design and analysis of JPAs based on both single Josephson
junctions and junction arrays. While single-junction JPAs utilize nonlinear
inductance for amplification, they suffer from gain compression, limited
dynamic range, and sensitivity to fabrication variations. To overcome these
challenges, this work explores JPA designs using Josephson junction arrays.
Arrays distribute the nonlinear response, enhancing power handling, linearity,
impedance tunability, and coherence while reducing phase noise. Several
advanced JPA architectures are proposed, simulated, and compared using quantum
theory and CAD tools to assess performance trade-offs and improvements over
conventional designs.

</details>


### [288] [Compensating connectivity restrictions in quantum annealers via splitting and linearization techniques](https://arxiv.org/abs/2507.12536)
*Marcel Seelbach Benkner,Zorah Lähner,Vladislav Golyanik,Martin Kliesch,Michael Moeller*

Main category: quant-ph

TL;DR: 提出了一种新的迭代算法，用于在量子退火中克服连接性限制，无需額外增加量子比特，并已在 D-Wave 量子退火器上得到验证。


<details>
  <summary>Details</summary>
Motivation: 目前的量子退火实验在连接性方面受到限制，通常需要将多个物理量子比特组合成一个具有更高连接性的逻辑量子比特，这需要将项添加到哈密顿量中，而这本身就是一个 NP-hard 问题。

Method: 提出了一种迭代算法，该算法通过在每一步有效利用问题图不同部分的可用连接性来克服连接性限制，而无需額外增加量子比特。

Result: 该算法通过弱单调性证明进行了理论支持，并在 D-Wave 量子退火器和多个局部搜索变体上进行了基准测试。实验表明，该算法在 D-Wave 优势量子退火器上是实用的。

Conclusion: 所提出的迭代算法通过有效利用可用连接性来克服量子退火中的连接性限制，并且在 D-Wave 量子退火器上已得到验证。

Abstract: Current quantum annealing experiments often suffer from restrictions in
connectivity in the sense that only certain qubits can be coupled to each
other. The most common strategy to overcome connectivity restrictions so far is
by combining multiple physical qubits into a logical qubit with higher
connectivity, which is achieved by adding terms to the Hamiltonian.
Practically, this strategy is implemented by finding a so-called minor
embedding, which is in itself an NP-hard problem. In this work, we present an
iterative algorithm that does not need additional qubits but instead
efficiently uses the available connectivity for different parts of the problem
graph in every step. We present a weak monotonicity proof and benchmark our
algorithm against the default minor-embedding algorithm on the D-Wave quantum
annealer and multiple simple local search variants. While most of the
experiments to compare the different iterative methods are performed with
simulated annealing solvers, we also confirm the practicality of our method
with experiments on the D-Wave Advantage quantum annealer.

</details>


### [289] [Learning mixed quantum states in large-scale experiments](https://arxiv.org/abs/2507.12550)
*Matteo Votto,Marko Ljubotina,Cécilia Lancien,J. Ignacio Cirac,Peter Zoller,Maksym Serbyn,Lorenzo Piroli,Benoît Vermersch*

Main category: quant-ph

TL;DR: 介绍了一种学习量子态MPO表征的新协议，该协议利用经典影子，通过顺序张量优化实现，并已在96个量子比特的超导处理器上成功验证。


<details>
  <summary>Details</summary>
Motivation: 学习实验制备的量子态的矩阵学算子（MPO）表征。

Method: 本研究提出并测试了一个学习矩阵学算子（MPO）表征实验制备量子态的协议。该协议以对应于局部随机测量的经典影子作为输入，并输出MPO张量，以最大化与实验态的拟合优度。张量优化采用类似著名的密度矩阵重整化群算法的顺序优化方法。

Result: 实验演示了该协议，学习了超导量子处理器中最多96个量子比特的纠缠量子态。在特定技术条件下，该方法在短程关联态和典型的嘈杂实验环境中均可有效运行，并可用于估计学习态与实验态之间的保真度。

Conclusion: 该方法将经典影子的能力提升至大规模量子计算和模拟实验。

Abstract: We present and test a protocol to learn the matrix-product operator (MPO)
representation of an experimentally prepared quantum state. The protocol takes
as an input classical shadows corresponding to local randomized measurements,
and outputs the tensors of a MPO which maximizes a suitably-defined fidelity
with the experimental state. The tensor optimization is carried out
sequentially, similarly to the well-known density matrix renormalization group
algorithm. Our approach is provably efficient under certain technical
conditions which are expected to be met in short-range correlated states and in
typical noisy experimental settings. Under the same conditions, we also provide
an efficient scheme to estimate fidelities between the learned and the
experimental states. We experimentally demonstrate our protocol by learning
entangled quantum states of up to $N = 96$ qubits in a superconducting quantum
processor. Our method upgrades classical shadows to large-scale quantum
computation and simulation experiments.

</details>


### [290] [Inverse Physics-informed neural networks procedure for detecting noise in open quantum systems](https://arxiv.org/abs/2507.12552)
*Gubio G. de Lima,Iann Cunha,Leonardo Kleber Castelano*

Main category: quant-ph

TL;DR: PINNverse框架可用于识别开放量子系统中的哈密顿量参数和衰减率，具有可扩展性和抗噪声性。


<details>
  <summary>Details</summary>
Motivation: 在噪声中等规模量子（NISQ）时代，准确表征量子系统对于发展量子技术至关重要。传统的哈密顿量学习和噪声表征方法测量量大且随系统规模扩展性差，而机器学习方法提供了有前景的替代方案。

Method: 将逆物理信息神经网络（PINNverse）框架扩展到开放量子系统，通过在神经网络训练中同时纳入相干和耗散动力学，从含噪声的实验数据中识别哈密顿量参数和衰减率。

Result: 通过对两量子比特开放系统的数值模拟，证明了PINNverse在识别含噪声量子系统方面的有效性和鲁棒性。

Conclusion: PINNverse框架能够有效识别含噪声量子系统中的哈密顿量参数和衰减率，为量子控制和误差缓解提供了可扩展且抗噪声的框架。

Abstract: Accurate characterization of quantum systems is essential for the development
of quantum technologies, particularly in the noisy intermediate-scale quantum
(NISQ) era. While traditional methods for Hamiltonian learning and noise
characterization often require extensive measurements and scale poorly with
system size, machine learning approaches offer promising alternatives. In this
work, we extend the inverse physics-informed neural network (referred to as
PINNverse) framework to open quantum systems governed by Lindblad master
equations. By incorporating both coherent and dissipative dynamics into the
neural network training, our method enables simultaneous identification of
Hamiltonian parameters and decay rates from noisy experimental data. We
demonstrate the effectiveness and robustness of the approach through numerical
simulations of two-qubit open systems. Our results show that PINNverse provides
a scalable and noise-resilient framework for quantum system identification,
with potential applications in quantum control and error mitigation.

</details>


### [291] [Efficient Qudit Circuit for Quench Dynamics of $2+1$D Quantum Link Electrodynamics](https://arxiv.org/abs/2507.12589)
*Rohan Joshi,Michael Meth,Jan C. Louw,Jesse J. Osborne,Kevin Mato,Martin Ringbauer,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 提出了一种基于量子比特的2+1维自旋-S U(1)量子连通格点规范理论及其动力学物质的资源高效模拟方法，该方法通过高斯定律对物质场进行积分，将模型重构为纯粹的自旋图景，无需辅助量子比特，减少了资源开销，并易于在量子处理器上实现。


<details>
  <summary>Details</summary>
Motivation: 量子模拟在高能物理学中的应用面临着在现有量子硬件上实现可扩展的2+1维格点规范理论的挑战，这是在量子计算机上探测3+1维量子色动力学这一总体目标的重要一步。现有实验实现主要局限于相对较小的系统尺寸和两能级规范场及电场表示。

Method: 提出了一种资源高效的量子模拟方法，通过对高维自旋-S U(1)量子连通格点规范理论及其动力学物质进行模拟，利用量子比特处理，并通过高斯定律对物质场进行积分，将量子连通模型重构为纯粹的自旋图景，兼容任意空间维度的量子比特编码，无需辅助量子比特，从而减少了资源开销。

Result: 通过数值模拟证明，即使在存在实际噪声的情况下，一阶Trotter化量子线路也能准确捕捉猝灭动力学。此外，还提出了一种为更高自旋表示（S>1/2）构建耦合项线路的通用方法。

Conclusion: 该方法显著减少了量子资源和门计数，提高了探测高维格点规范理论中非平衡现象的可扩展性和保真度，并且易于在最先进的量子处理器上实现。

Abstract: A major challenge in the burgeoning field of quantum simulation for
high-energy physics is the realization of scalable $2+1$D lattice gauge
theories on state-of-the-art quantum hardware, which is an essential step
towards the overarching goal of probing $3+1$D quantum chromodynamics on a
quantum computer. Despite great progress, current experimental implementations
of $2+1$D lattice gauge theories are mostly restricted to relatively small
system sizes and two-level representations of the gauge and electric fields.
Here, we propose a resource-efficient method for quantum simulating $2+1$D
spin-$S$ $\mathrm{U}(1)$ quantum link lattice gauge theories with dynamical
matter using qudit-based quantum processors. By integrating out the matter
fields through Gauss's law, we reformulate the quantum link model in a purely
spin picture compatible with qudit encoding across arbitrary spatial
dimensions, eliminating the need for ancillary qubits and reducing resource
overhead. Focusing first on the spin-$1/2$ case, we construct explicit circuits
for the full Hamiltonian and demonstrate through numerical simulations that the
first-order Trotterized circuits accurately capture the quench dynamics even in
the presence of realistic noise levels. Additionally, we introduce a general
method for constructing coupling-term circuits for higher-spin representations
$S>1/2$. Compared to conventional qubit encodings, our framework significantly
reduces the number of quantum resources and gate count. Our approach
significantly enhances scalability and fidelity for probing nonequilibrium
phenomena in higher-dimensional lattice gauge theories, and is readily amenable
to implementation on state-of-the-art qudit platforms.

</details>


### [292] [Qrisp Implementation and Resource Analysis of a T-Count-Optimised Non-Restoring Quantum Square-Root Circuit](https://arxiv.org/abs/2507.12603)
*Heorhi Kupryianau,Marcin Niemiec*

Main category: quant-ph

TL;DR: QRISP框架实现了T量化优化的非恢复量子平方根算法，资源效率高，并经过实验验证。


<details>
  <summary>Details</summary>
Motivation: 高效的量子算术运算是复杂量子算法的关键组成部分，但很少有理论设计能在实际的量子编程框架中实现。本研究旨在弥合这一差距，展示一种资源优化的量子平方根算法的实际可行性。

Method: 本研究展示了T量化优化的非恢复量子平方根算法在QRISP量子编程框架中的首次完整实现。该算法由Thapliyal等人提出，与替代方法相比，具有更好的资源效率，可减少T量化和量子比特需求，并避免垃圾输出。QRISP的模块化设计方法允许从基本量子门构建的可重用组件（包括可逆加法器、减法器和条件逻辑块）进行构建。三阶段算法（包括初始减法、迭代条件加法/减法和余数恢复）已成功从算法描述转换为可执行的量子代码。

Result: 实验验证和对n位输入的T量化为14n-14和T深度为5n+3的确认，证实了该算法的准确性和资源效率。

Conclusion: 本工作展示了资源优化量子算术算法的实际可行性，并为在现代量子编程框架中实现不同的算术运算奠定了基础。

Abstract: Efficient quantum arithmetic operations are essential building blocks for
complex quantum algorithms, yet few theoretical designs have been implemented
in practical quantum programming frameworks. This paper presents the first
complete implementation of the T-count optimized non-restoring quantum square
root algorithm using the Qrisp quantum programming framework. The algorithm,
originally proposed by Thapliyal et al., offers better resource efficiency
compared to alternative methods, achieving reduced T-count and qubit
requirements while avoiding garbage output. Our implementation validates the
theoretical resource estimates, confirming a T-count of 14n-14 and T-depth of
5n+3 for n-bit inputs. The modular design approach enabled by Qrisp allows
construction from reusable components including reversible adders, subtractors,
and conditional logic blocks built from fundamental quantum gates. The
three-stage algorithm - comprising initial subtraction, iterative conditional
addition/subtraction, and remainder restoration is successfully translated from
algorithmic description to executable quantum code. Experimental validation
across multiple test cases confirms correctness, with the circuit producing
accurate integer square roots and remainders. This work demonstrates the
practical realizability of resource-optimized quantum arithmetic algorithms and
establishes a foundation for implementing different arithmetic operations in
modern quantum programming frameworks.

</details>


### [293] [Probing Hadron Scattering in Lattice Gauge Theories on Qudit Quantum Computers](https://arxiv.org/abs/2507.12614)
*Rohan Joshi,Jan C. Louw,Michael Meth,Jesse J. Osborne,Kevin Mato,Guo-Xian Su,Martin Ringbauer,Jad C. Halimeh*

Main category: quant-ph

TL;DR: 使用自旋-1算符表示电场和规范场的数字qudit量子电路，能够高效地模拟U(1)量子链接点格规范理论的非平衡猝灭动力学和散射过程，特别是在介子-反介子碰撞方面，克服了仅使用两层表示的限制。模拟结果表明，即使在包含噪声的情况下，qudits平台也已准备好进行此类模拟，且所需电路深度比qubit平台浅。


<details>
  <summary>Details</summary>
Motivation: 解决当前量子模拟器中系统尺寸小以及规范场仅限于两层表示的问题，以实现高能物理领域中散射过程的第一性原理研究。

Method: 提出用于U(1)量子链接点格规范理论的远非平衡猝灭动力学的数字qudit量子电路，其中电场和规范场表示为自旋-1算符，并使用数值模拟探测了此模型中的散射过程，重点关注介子-介子和介子-反介子碰撞。

Result: 探测到的散射动力学展示了丰富的物理现象，包括介子翻转以及介子-反介子碰撞中随规范耦合强度变化的反射-透射转变。

Conclusion: qudits平台已准备好通过比qubit平台更浅的电路深度来观察微观散射动力学

Abstract: An overarching goal in the flourishing field of quantum simulation for
high-energy physics is the first-principles study of the microscopic dynamics
of scattering processes on a quantum computer. Currently, this is hampered by
small system sizes and a restriction to two-level representations of the gauge
fields in state-of-the-art quantum simulators. Here, we propose efficient
experimentally feasible digital qudit quantum circuits for far-from-equilibrium
quench dynamics of a $\mathrm{U}(1)$ quantum link lattice gauge theory, where
the electric and gauge fields are represented as spin-$1$ operators. Using
dedicated numerical simulations, we probe scattering processes in this model on
these proposed circuits, focusing on meson-meson and meson-antimeson
collisions. The latter are not possible with a two-level representation of the
fields, highlighting the suitability of qudits in exploring scattering
processes relevant to quantum electrodynamics. The probed scattering dynamics
showcases rich physics, including meson flipping and a reflection-transmission
transition in meson-antimeson collisions as a function of the gauge coupling
strength. Our simulations, which include realistic noise models of dephasing
and depolarization, show very good agreement with the exact noiseless dynamics,
signaling the readiness of current qudit platforms to observe microscopic
scattering dynamics with significantly shallower circuit depths than their
qubit counterparts.

</details>


### [294] [Sridhara-Compressed VQE Accelerates Molecular Energy Ranking of Polyaromatic Hydrocarbons](https://arxiv.org/abs/2507.12678)
*Dennis Lima,Saif Al-Kuwari*

Main category: quant-ph

TL;DR: 通过SBD和VQE优化CVD过程，可对TAH分子按能量排序，提高模拟速度达十倍，误差降至10^{-1}。


<details>
  <summary>Details</summary>
Motivation: 四环芳烃（TAH）作为甲烷化学气相沉积（CVD）过程中产生的残留和中间分子，对其进行能量排序的研究不足，而这对于优化CVD过程至关重要，并且也是量子计算机实现量子优势的一个潜在应用领域。

Method: 本文利用Sridhara的多项式根公式对六种四环芳烃（TAH）进行了西太 the Hartree-Fock哈密顿量和STO-3G基组，以及从2到6个轨道（活性电子数相同）的活性轨道空间进行了分块对角化（SBD）。

Result: 该方法实现了对分子的基态能量排序，并将VQE模拟速度提高了十倍，误差降低到10^{-1}的量级。压缩算法在矩阵尺寸上实现了(1-2^{-k})*100%的压缩能力。

Conclusion: 所提出的压缩算法结合变分量子特征求解器（VQE）能够对分子按基态能量进行排序，同时将VQE模拟速度提高了十倍，并将其误差减小到10^{-1}的量级。对于k量子比特，(1-2^{-k})*100%的压缩能力使VQE能够拥有更广泛的应用集，为克服大型量子处理单元的电路尺寸和量子噪声限制提供了新的必要工具。

Abstract: Chemical vapor deposition (CVD) is the most efficient process to synthesize
graphene sheets using methane as precursor, making it a strategic alternative
route for the Liquefied Natural Gas market. In this reaction, tetracyclic
aromatic hydrocarbons (TAH) are produced as residual and intermediary
molecules. Sorting a combinatorial space of variants of TAHs by energy is a
poorly studied problem needed to optimize CVD, while it is also a candidate for
quantum advantage in quantum computers. We extend on Sridhara's polynomial root
formula to perform block-diagonalization (hence SBD) of six TAHs using
Hartree-Fock Hamiltonians with STO-3G basis set and active orbital space
growing from 2 to 6 orbitals, with equal numbers for the number of active
electrons. We show that the proposed compression algorithm followed by
Variational Quantum Eigensolver (VQE) allows for sorting of the molecules by
ground state energy, while speeding up the VQE simulation up to tenfold and
reducing its error to the $10^{-1}$ scale. The compression capability of
$(1-2^{-k})\cdot 100\%$ in matrix size for $k$ qubits allows VQEs to have a
broader set of applications, providing a new and necessary tool to overcome the
circuit size and quantum noise limitations of large quantum processing units.

</details>


### [295] [Multiqubit monogamy relations beyond shadow inequalities](https://arxiv.org/abs/2507.12680)
*Eduardo Serrano-Ensástiga,Olivier Giraud,John Martin*

Main category: quant-ph

TL;DR: 该研究推导了新的绝育不等式，以表征量子系统的相关性，并发现对于少于 6 个量子比特的系统，这种表征是完整的，但对于更大的系统则不完整。


<details>
  <summary>Details</summary>
Motivation: 研究量子多方系统中的绝育关系，这些关系对量子相关性的分布施加了基本限制。

Method: 该研究推导了一组绝育不等式，该不等式是对阴影不等式的补充。

Result: 该研究为 N ≤ 5 量子比特的纯态系统推导了扇区长度的数值范围，该范围形成一个凸多面体，便于通过在顶点进行简单评估来有效地极值化诸如纠缠的线性熵和量子阴影枚举器等关键物理量。

Conclusion: 对于 N ≤ 5 量子比特的纯态系统，该研究推导了一组补充了阴影不等式的绝育不等式，可以完整地表征扇区长度的数值范围，而对于 N ≥ 6 的更大系统，该研究强调了复杂性显著增加，这两种不等式都无法完全捕获。

Abstract: Multipartite quantum systems are subject to monogamy relations that impose
fundamental constraints on the distribution of quantum correlations between
subsystems. These constraints can be studied quantitatively through sector
lengths, defined as the average value of $m$-body correlations, which have
applications in quantum information theory and coding theory. In this work, we
derive a set of monogamy inequalities that complement the shadow inequalities,
enabling a complete characterization of the numerical range of sector lengths
for systems with $N\leq 5$ qubits in a pure state. This range forms a convex
polytope, facilitating the efficient extremization of key physical quantities,
such as the linear entropy of entanglement and the quantum shadow enumerators,
by a simple evaluation at the polytope vertices. For larger systems ($N\geq
6$), we highlight a significant increase in complexity that neither our
inequalities nor the shadow inequalities can fully capture.

</details>


### [296] [The thermal gauge potentials in quantum transport](https://arxiv.org/abs/2507.12712)
*Zheng Chuan Wang*

Main category: quant-ph

TL;DR: 研究通过量子玻尔兹曼方程引入了新的热势，发现温度升高会增加阻尼力。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和描述传导电子与声子相互作用在热力学中的表现，本研究旨在引入新的热标量和矢量规范势。

Method: 本研究利用量子玻尔兹曼方程，通过对自能量进行泰勒级数展开，推导出温度依赖的四维阻尼力，其中第四分量对应新的标量势。在局部平衡假设下，采用傅里叶变换方法，对量子玻尔兹曼方程进行逐级求解。

Result: 研究成功推导了温度依赖的阻尼力，并展示了其与温度的关系：温度越高，阻尼力越大。推导出的阻尼力与新的标量势和矢量规范势相关。

Conclusion: 本研究通过量子玻尔兹曼方程推导了与传导电子和声子相互作用相关的温度依赖性阻尼力，并以此为基础引入了新的热标量和矢量规范势。研究结果表明，温度越高，阻尼力越大。

Abstract: In this manuscript, we present another new thermal scalar and vector gauge
potentials implemented by the quantum Boltzmann equation, which originates from
the interaction of conduction electrons and phonons. To accomplish this task,
we derive a temperature dependent four dimensional damping force by the Taylor
series expansion on the self energy of the QBE, which can be related to the
thermal scalar and vector gauge potentials, especially the fourth component of
the damping force, which is just a power corresponding to a new scalar
potential. Based on the local equilibrium assumption, we solve the QBE order by
order using the Fourier transformation method. The temperature dependent
damping force and other physical observables are exhibited in the figures, the
higher of the temperature, the bigger of the damping force.

</details>


### [297] [Detecting Entanglement in High-Spin Quantum Systems via a Stacking Ensemble of Machine Learning Models](https://arxiv.org/abs/2507.12775)
*M. Y. Abd-Rabbou,Amr M. Abdallah,Ahmed A. Zahia,Ashraf A. Gouda,Cong-Feng Qiao*

Main category: quant-ph

TL;DR: 集成机器学习模型，特别是使用CatBoost的堆叠集成，可以有效且可靠地估计量子纠缠（负度量），克服了传统方法的计算瓶颈，并且在预测准确性和一致性方面优于单独的机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法在可靠检测和量化高自旋或多体系统中的量子纠缠方面存在显著的计算挑战。因此，本研究旨在探索集成机器学习模型作为一种可靠且可扩展的方法来估计量子系统的纠缠度。

Method: 本研究构建了一个集成回归器，结合了神经网络（NNs）、XGBoost（XGB）和Extra Trees（ET），并使用堆叠元学习器（CatBoost）进行训练。该模型在纯态和混合态Werner态的数据集上进行训练，以估计量子系统的纠缠度（负度量）。

Result: 集成模型（特别是CatBoost）能够准确预测不同维度和状态类型的负度量，并且在预测一致性和偏差方面优于单独的强学习器。此外，研究还推导了一个经验公式，用于根据系统维度和所需精度估算数据需求。

Conclusion: 该研究表明，集成机器学习模型（特别是包含CatBoost的堆叠元学习器）在估计量子系统的纠缠度（以负度量）方面表现出鲁棒性，能够准确预测不同维度和状态类型的负度量。与单独的强学习器（如神经网络）相比，集成模型具有更优越的预测一致性和更低的偏差，这归因于集成学习中的误差抵消和方差缩减。

Abstract: Reliable detection and quantification of quantum entanglement, particularly
in high-spin or many-body systems, present significant computational challenges
for traditional methods. This study examines the effectiveness of ensemble
machine learning models as a reliable and scalable approach for estimating
entanglement, measured by negativity, in quantum systems. We construct an
ensemble regressor integrating Neural Networks (NNs), XGBoost (XGB), and Extra
Trees (ET), trained on datasets of pure states and mixed Werner states for
various spin dimensions. The ensemble model with stacking meta-learner
demonstrates robust performance by CatBoost (CB), accurately predicting
negativity across different dimensionalities and state types. Crucially, visual
analysis of prediction scatter plots reveals that the ensemble model exhibits
superior predictive consistency and lower deviation from true entanglement
values compared to individual strong learners like NNs, even when aggregate
metrics are comparable. This enhanced reliability, attributed to error
cancellation and variance reduction inherent in ensembling, underscores the
potential of this approach to bypass computational bottlenecks and provide a
trustworthy tool for characterizing entanglement in high-dimensional quantum
physics. An empirical formula for estimating data requirements based on system
dimensionality and desired accuracy is also derived.

</details>


### [298] [Disordered purification phase transition in hybrid random circuits](https://arxiv.org/abs/2507.12886)
*Kengo Anzai,Hiroaki Matsueda,Yoshihito Kuno*

Main category: quant-ph

TL;DR: 空间噪声不均匀性会改变量子电路中的相变行为。


<details>
  <summary>Details</summary>
Motivation: 鉴于实际量子电路中噪声的空间不均匀性，本研究旨在探索空间调制对纯化相变的影响。

Method: 通过使用多体负熵作为混合态量子纠缠的观测值，并研究了空间调制对混合态随机Clifford电路中纯化相变的影响。

Result: 空间不均匀性改变了临界关联长度指数，从统一概率下的 $\nu < 2$ 变为空间调制概率下的 $\nu > 2$。此外，空间调制还会诱导一个相变，产生一种保留短程量子纠缠的新纯净相。

Conclusion: 该研究表明，空间调制会影响混合态量子电路中的纯化相变，改变临界关联长度的指数，并可能诱导新的纯净相，其中保留了短程量子纠缠。

Abstract: Noise is inevitable in realistic quantum circuits. It arises randomly in
space. Inspired by spatial non-uniformity of the noise, we investigate the
effects of spatial modulation on purification phase transitions in a hybrid
random Clifford circuit. As an efficient observable for extracting quantum
entanglement in mixed states, we employ many-body negativity. The behavior of
the many-body negativity well characterizes the presence of the purification
phase transitions and its criticality. We find the effect of spatial
non-uniformity in measurement probability on purification phase transition. The
criticality of the purification phase transition changes from that of uniform
probability, which is elucidated from the argument of the Harris criterion. The
critical correlation length exponent $\nu$ changes from $\nu < 2$ for uniform
probability to $\nu > 2$ for spatially modulated probability. We further
investigate a setting where two-site random Clifford gate becomes spatially
(quasi-)modulated. We find that the modulation induces a phase transition,
leading to a different pure phase where a short-range quantum entanglement
remains.

</details>


### [299] [Current-based metrology with two-terminal mesoscopic conductors](https://arxiv.org/abs/2507.12907)
*Shishir Khandelwal,Gabriel T. Landi,Géraldine Haack,Mark T. Mitchison*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The traditional approach to quantum parameter estimation focuses on the
quantum state, deriving fundamental bounds on precision through the quantum
Fisher information. In most experimental settings, however, performing
arbitrary quantum measurements is highly unfeasible. In open quantum systems,
an alternative approach to metrology involves the measurement of stochastic
currents flowing from the system to its environment. However, the present
understanding of current-based metrology is mostly limited to Markovian master
equations. Considering a parameter estimation problem in a two-terminal
mesoscopic conductor, we identify the key elements that determine estimation
precision within the Landauer-B\"uttiker formalism. Crucially, this approach
allows us to address arbitrary coupling and temperature regimes. Furthermore,
we obtain analytical results for the precision in linear-response and
zero-temperature regimes. For the specific parameter estimation task that we
consider, we demonstrate that the boxcar transmission function is optimal for
current-based metrology in all parameter regimes.

</details>


### [300] [Unsupervised Techniques to Detect Quantum Chaos](https://arxiv.org/abs/2507.12887)
*Dmitry Nemirovsky,Ruth Shir,Dario Rosa,Victor Kagalovsky*

Main category: quant-ph

TL;DR: 无监督神经网络可直接从哈密顿量矩阵中检测量子混沌，无需对角化。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统量子混沌光谱探测方法（需要特征值和特征向量，涉及昂贵的对角化）的计算成本问题。

Method: 使用自组织映射（一种无监督神经网络）来分析哈密顿量矩阵，以检测量子混沌。

Result: 研究结果显示，无监督神经网络（自组织映射）能够成功检测到由图的随机性引起的从可积谱统计到混沌谱统计的转变，而无需进行对角化。

Conclusion: 该研究表明，无需进行计算成本高昂的对角化即可直接从哈密顿量矩阵中检测量子混沌。

Abstract: Conventional spectral probes of quantum chaos require eigenvalues, and
sometimes, eigenvectors of the quantum Hamiltonian. This involves
computationally expensive diagonalization procedures. We test whether an
unsupervised neural network can detect quantum chaos directly from the
Hamiltonian matrix. We use a single-body Hamiltonian with an underlying random
graph structure and random coupling constants, with a parameter that determines
the randomness of the graph. The spectral analysis shows that increasing the
amount of randomness in the underlying graph results in a transition from
integrable spectral statistics to chaotic ones. We show that the same
transition can be detected via unsupervised neural networks, or more
specifically, Self-Organizing Maps by feeding the Hamiltonian matrix directly
into the neural network, without any diagonalization procedure.

</details>


### [301] [Robustness of Magic in the quantum Ising chain via Quantum Monte Carlo tomography](https://arxiv.org/abs/2507.12902)
*Hari Timsina,Yi-Ming Ding,Emanuele Tirrito,Poetri Sonya Tarabunga,Bin-Bin Mao,Mario Collura,Zheng Yan,Marcello Dalmonte*

Main category: quant-ph

TL;DR: 在量子伊辛链中，魔力在量子相变和有限温度下的行为与临界现象相关。它随距离呈幂律衰减，且在有限温度下不会突然消失，这与纠缠不同。


<details>
  <summary>Details</summary>
Motivation: 研究魔力作为量子伊辛链中量子相变和有限温度下的二分相关行为。

Method: 提出了一种混合方案，结合了通过量子蒙特卡洛进行约化密度矩阵的随机采样，以及用于衡量魔力鲁棒性的估计器，这是一种用于混合态的魔力度量。

Result: 在临界点，魔力鲁棒性随分区间距离的增加呈幂律衰减，衰减指数与分区大小有关。在有限温度下，魔力鲁棒性在有效临界温度之前保持其低温值，该温度的尺寸依赖性也呈代数关系。

Conclusion: 魔力（magic）在量子伊辛链的量子相变和有限温度下表现出与临界行为的直接关系，它并不会像纠缠那样经历“突然死亡”。

Abstract: We study the behavior of magic as a bipartite correlation in the quantum
Ising chain across its quantum phase transition, and at finite temperature. In
order to quantify the magic of partitions rigorously, we formulate a hybrid
scheme that combines stochastic sampling of reduced density matrices via
quantum Monte Carlo, with state-of-the-art estimators for the robustness of
magic - a {\it bona fide} measure of magic for mixed states. This allows us to
compute the mutual robustness of magic for partitions up to 8 sites, embedded
into a much larger system. We show how mutual robustness is directly related to
critical behaviors: at the critical point, it displays a power law decay as a
function of the distance between partitions, whose exponent is related to the
partition size. Once finite temperature is included, mutual magic retains its
low temperature value up to an effective critical temperature, whose dependence
on size is also algebraic. This suggests that magic, differently from
entanglement, does not necessarily undergo a sudden death.

</details>


### [302] [A superinductor in a deep sub-micron integrated circuit](https://arxiv.org/abs/2507.13202)
*T. H. Swift,F. Olivieri,G. Aizpurua-Iraola,J. Kirkman,G. M. Noah,M. de Kruijf,F. E. von Horstig,A. Gomez-Saiz,J. J. L. Morton,M. F. Gonzalez-Zalba*

Main category: quant-ph

TL;DR: 本研究在硅集成电路中实现了高性能超感应器，并成功将其应用于射频单电子晶体管（rfSET），大幅提高了灵敏度并减小了器件面积，为量子计算等领域开辟了新机遇。


<details>
  <summary>Details</summary>
Motivation: 超感应器在计量、传感和量子计算等领域具有广泛应用，但通常需要使用具有高电感密度的奇异材料。本研究旨在利用硅集成电路中常见的材料和工艺，实现高性能的超感应器，以克服现有技术的局限性。

Method: 本研究利用了制造工艺中常见的 TiN 薄膜的高动量电感（约 1 nH/□），并将其与硅集成电路（22-nm FDSOI）中的硅量子点接口，实现了射频单电子晶体管（rfSET）。

Result: 通过将超感应器与硅量子点接口，研究成功展示了一种射频单电子晶体管（rfSET），其灵敏度比现有技术提高了两个数量级以上，同时面积减小了 10,000 倍。

Conclusion: 本研究提出了一个在硅集成电路中实现的超感应器，它利用了制造工艺中常见的 TiN 薄膜的高动量电感，并将其与硅量子点接口，展示了一种射频单电子晶体管（rfSET）。该集成式 rfSET 具有更低的寄生参数和更高的阻抗，其灵敏度比现有技术提高了两个数量级以上，同时面积减小了 10,000 倍。这项工作为构建密集的高性能量子比特传感器阵列奠定了基础，并为天文学领域的动量电感探测器阵列、超材料研究以及基于一维和二维谐振器阵列的量子模拟器等领域开辟了新的可能性。

Abstract: Superinductors are circuit elements characterised by an intrinsic impedance
in excess of the superconducting resistance quantum
($R_\text{Q}\approx6.45~$k$\Omega$), with applications from metrology and
sensing to quantum computing. However, they are typically obtained using exotic
materials with high density inductance such as Josephson junctions,
superconducting nanowires or twisted two-dimensional materials. Here, we
present a superinductor realised within a silicon integrated circuit (IC),
exploiting the high kinetic inductance ($\sim 1$~nH/$\square$) of TiN thin
films native to the manufacturing process (22-nm FDSOI). By interfacing the
superinductor to a silicon quantum dot formed within the same IC, we
demonstrate a radio-frequency single-electron transistor (rfSET), the most
widely used sensor in semiconductor-based quantum computers. The integrated
nature of the rfSET reduces its parasitics which, together with the high
impedance, yields a sensitivity improvement of more than two orders of
magnitude over the state-of-the-art, combined with a 10,000-fold area
reduction. Beyond providing the basis for dense arrays of integrated and
high-performance qubit sensors, the realization of high-kinetic-inductance
superconducting devices integrated within modern silicon ICs opens many
opportunities, including kinetic-inductance detector arrays for astronomy and
the study of metamaterials and quantum simulators based on 1D and 2D resonator
arrays.

</details>


### [303] [Topology-Enhanced Superconducting Qubit Networks for In-Sensor Quantum Information Processing](https://arxiv.org/abs/2507.13228)
*J. Settino,G. G. Luciano,A. Di Bartolomeo,P. Silvestrini,M. Lisitskiy,B. Ruggiero,F. Romeo*

Main category: quant-ph

TL;DR: 该研究表明，交叉形超导量子比特网络的拓扑结构可以增强其磁响应，这在量子传感和量子计算中具有应用前景，并且该网络还可用于量子水库计算。


<details>
  <summary>Details</summary>
Motivation: 研究电感耦合超导通量量子比特网络中拓扑对磁响应的影响。

Method: 使用精确对角化方法和线性响应理论。

Result: 交叉形阵列的耦合矩阵能够显著增强磁通量响应，这种网络拓扑效应源于中心和外围量子比特之间的协同耦合。。

Conclusion: 该研究为功能导向的超导量子电路提供了定量设计标准，直接关系到量子传感和量子信息处理应用性能的提升。

Abstract: We investigate the influence of topology on the magnetic response of
inductively coupled superconducting flux-qubit networks. Using exact
diagonalization methods and linear response theory, we compare the magnetic
response of linear and cross-shaped array geometries, used as paradigmatic
examples. We find that the peculiar coupling matrix in cross-shaped arrays
yields a significant enhancement of the magnetic flux response compared to
linear arrays, this network-topology effect arising from cooperative coupling
among the central and the peripheral qubits. These results establish
quantitative design criteria for function-oriented superconducting quantum
circuits, with direct implications for advancing performance in both quantum
sensing and quantum information processing applications. Concerning the latter,
by exploiting the non-linear and high-dimensional dynamics of such arrays, we
demonstrate their suitability for quantum reservoir computing technology. This
dual functionality suggests a novel platform in which the same device serves
both as a quantum-limited electromagnetic sensor and as a reservoir capable of
signal processing, enabling integrated quantum sensing and processing
architectures.

</details>


### [304] [Deterministic Generation of Four-Component Schrödinger Cat States via Floquet Engineering in a Hybrid Magnon-Superconductor System](https://arxiv.org/abs/2507.12924)
*Shiwen He,Zi-Long Yang,Sitong Jin,Feng-Yang Zhang,Chong Li*

Main category: quant-ph

TL;DR: 提出了一种在混合量子系统中（包括两个超导量子比特、一个微波腔和一个磁振子模式）通过Floquet工程生成四组分薛定谔猫态的方案。该方案利用条件测量将磁振子模式投影到非经典猫态，并证明了其在高保真度和对耗散的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 四组分薛定谔猫态，即相空间中对称排列的四个相干态的叠加，具有丰富的非经典特征和增强的抗退相干能力，是量子信息科学的有希望的资源。

Method: 提出了一种Floquet工程方案，通过对两个超导量子比特施加周期性横向驱动，推导出有效的哈密顿量，该哈密顿量根据联合量子比特状态条件性地置换磁振子模式。在σx基中进行条件测量，将磁振子模式投影到具有高保真度的非经典四组分猫态。

Result: 通过在原始框架中进行Wigner函数验证了四组分薛定谔猫态的非经典性。对量子比特退相干、磁振子损耗和腔耗散影响的系统分析结果表明了该方案对耗散的鲁棒性。

Conclusion: 该方案为基于非经典磁振子态的混合量子信息处理提供了一种新方法，可在可扩展的固态平台中实现多组分量子叠加态的生成。

Abstract: Four-component Schr\"odinger cat states, superpositions of four coherent
states symmetrically arranged in phase space, offer rich nonclassical features
and enhanced resilience to decoherence, making them promising resources for
quantum information science. We propose a Floquet-engineered scheme to
deterministically generate four-component Schr\"odinger cat states in a hybrid
quantum system composed of two superconducting qubits, a microwave cavity, and
a magnon mode. By applying periodic transverse drives to the qubits, we derive
an effective Hamiltonian that conditionally displaces the magnon mode depending
on the joint qubit state. Conditional measurements in the $\sigma_x$ basis
project the magnon mode into nonclassical four-component cat states with high
fidelity. The Wigner functions in the original frame verified the
non-classicality of the four-component Schr\"odinger cat states. Results of
systematically analyzing the impacts of qubit decoherence, magnon loss, and
cavity dissipation demonstrate the robustness to the dissipation. The results
show that this scheme can realize the generation of multi-component quantum
superposition states in a scalable solid-state platform, providing a new
approach for hybrid quantum information processing based on nonclassical magnon
states.tates.

</details>


### [305] [Circular-beam approximation for quantum channels in the turbulent atmosphere](https://arxiv.org/abs/2507.12947)
*I. Pechonkin,M. Klen,A. A. Semenov*

Main category: quant-ph

TL;DR: 提出圆光束近似和基于矩的参数估计，简化并扩展了大气湍流对量子通信影响的描述。


<details>
  <summary>Details</summary>
Motivation: 大气湍流对自由空间量子态演化产生影响，导致传输率随机波动，现有椭圆光束近似在特定参数范围内有效，但计算复杂度高。

Method: 提出了一种简化的圆光束近似方法，并采用基于传输率前两个矩的估计技术来评估模型参数。

Result: 圆光束近似在保持满意准确性的同时，显著降低了计算复杂度，并且通过参数估计技术扩展了模型的适用范围。

Conclusion: 该研究提出了一种简化的圆光束近似方法来描述自由空间量子通信中的大气湍流效应，并采用基于前两个矩的传输参数估计技术，扩展了模型的适用范围，为量化大气信道提供了实用的工具。

Abstract: The evolution of quantum states of light in free-space channels is strongly
influenced by atmospheric turbulence, posing a significant challenge for
quantum communication. The transmittance in such channels randomly fluctuates.
This effect is commonly described by the probability distribution of
transmittance (PDT). The elliptic-beam approximation provides an analytical
model for the PDT, showing good agreement with experimental and simulation data
within a specific range of channel parameters. In this work, we introduce the
circular-beam approximation -- a simplified alternative that offers
satisfactory accuracy while significantly reducing computational complexity. We
also present an alternative technique for evaluating the parameters of this
model based on the first two moments of transmittance. This approach notably
extends the applicability range of our PDT model, offering a practical tool for
characterizing atmospheric channels in quantum applications.

</details>


### [306] [Optimized Measurements of Rabi model in a linear potential under Strong Doppler shifts](https://arxiv.org/abs/2507.12971)
*Dongyang Yu*

Main category: quant-ph

TL;DR: 利用SU(2)李群理论和Fisher信息理论，研究了都普勒效应对原子重力仪中Rabi模型动力学的影响，为提高原子重力仪灵敏度和抗噪声能力提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了提高原子重力仪的灵敏度，需要利用原子外自由度（特别是具有宽动量展宽的物质波态）的量子资源，但目前缺乏对该方法中关键的都普勒效应的完全量子力学研究。

Method: 利用SU(2)李群理论推导了Rabi模型在势线性时的幺正动力学的Riccati方程，并通过Fisher信息理论分析了多普勒展宽对Rabi振荡的影响。

Result: 推导了Rabi模型的Riccati方程，分析了都普勒效应对Rabi振荡的影响，并证明了在强都普勒展宽下，相位旋转测量方案的近普适性和高测量增益。

Conclusion: 该理论工作为开发利用外部状态量子资源的高灵敏度、抗噪声原子重力仪奠定了理论基础。

Abstract: Harnessing quantum resources in the atomic external degrees of
freedom--particularly matter-wave states with broad momentum spreads--holds
significant potential for enhancing the sensitivity of Kasevich-Chu atom
gravimeters at the standard quantum limit. However, a fully quantum-mechanical
investigation of the critical Doppler effect inherent to this approach remains
lacking. Employing the SU(2) Lie group theory, we derive a generic Riccati
equation governing the unitary dynamics of the Rabi model within a linear
potential and analyze the Doppler effect impact on Rabi oscillations because of
the strong coupling between the internal and external states. Furthermore, by
integrating Fisher information theory, we specifically demonstrate the
near-universality and high metrological gain of phase rotation measurement
protocols under strong Doppler broadening. This theoretical work provides
insightful implications for boarder generalization, such as extensions to
finite-temperature scenarios or multi-pulse sequences--exemplified by the
$\pi/2-\pi-\pi/2$ pulse sequence characteristic of Kasevich-Chu atom
gravimeters. Thus, this work lays a theoretical foundation for developing
high-sensitivity, noise-resistant atom gravimeters leveraging external-state
quantum resources.

</details>


### [307] [Practical Subarchitectures for Optimal Quantum Layout Synthesis](https://arxiv.org/abs/2507.12976)
*Kostiantyn V. Milkevych,Jaco van de Pol,Irfansha Shaik*

Main category: quant-ph

TL;DR: A new method speeds up optimal quantum circuit mapping by reducing the search space of subarchitectures using a fixed number of ancilla qubits.


<details>
  <summary>Details</summary>
Motivation: Optimal Quantum Layout Synthesis (QLS) minimizes circuit size and depth to reduce noise on quantum platforms, but it's an NP-hard problem. Practical solutions involve mapping to subsets of the platform, but guaranteeing optimality requires considering exponentially many subarchitectures. This work aims to reduce this complexity.

Method: An effective method to enumerate relevant subarchitectures by assuming a fixed number of ancilla qubits.

Result: Evaluated the technique on benchmarks, comparing it with state-of-the-art Optimal QLS tools with and without subarchitectures, demonstrating improved performance.

Conclusion: The proposed method effectively reduces the number of subarchitectures to consider and subgraph isomorphism checks, boosting Optimal QLS performance for a selected ancilla bound.

Abstract: Quantum Layout Synthesis (QLS) maps a logical quantum circuit to a physical
quantum platform. Optimal QLS minimizes circuit size and depth, which is
essential to reduce the noise on current quantum platforms. Optimal QLS is an
NP-hard problem, so in practice, one maps a quantum circuit to a subset of the
complete quantum platform. However, to guarantee optimality, one still has to
consider exponentially many subarchitectures.
  We introduce an effective method to enumerate relevant subarchitectures. This
reduces the number of considered subarchitectures, as well as the number of
expensive subgraph isomorphism checks, thus boosting Optimal QLS with
subarchitectures. To do so, we assume a fixed number of ancilla qubits that can
be used in the mapping. We guarantee optimality of the quantum layout, for the
selected ancilla bound.
  We evaluate our technique on a number of benchmarks and compare it with
state-of-the-art Optimal QLS tools with and without using subarchitectures.

</details>


### [308] [Trap-to-trap free falls with an optically levitated nanoparticle](https://arxiv.org/abs/2507.12995)
*M. Luisa Mattana,Nicola Carlon Zambon,Massimiliano Rossi,Eric Bonvin,Louisiane Devaud,Martin Frimmer,Lukas Novotny*

Main category: quant-ph

TL;DR: 通过光学镊子在自由落体实验中悬浮纳米粒子，实现了粒子位置不确定性的显著增加，并为未来实现更长时间的自由落体和更大范围的离域化提供了方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过自由落体实验，探索产生大范围的悬浮物体离域化。

Method: 在光学镊子中进行带电中性、光学悬浮纳米粒子的自由落体实验，光学镊子可快速开关并垂直位移，从而在每次自由落体后释放和重新捕获粒子。

Result: 实验实现了长达0.25毫秒的自由落体，并在重新捕获时观察到粒子位置不确定性增加了近两百倍。

Conclusion: 通过实施线性反馈技术和降低背景压力，有望实现毫秒级自由落体实验，为产生大范围的悬浮物体离域化提供新机遇。

Abstract: We perform free-fall experiments with a charge-neutral, optically levitated
nanoparticle. This is achieved using an optical tweezer that can be rapidly
toggled on and off and vertically displaced, enabling the particle to be
released and recaptured after each free fall. The particle is insensitive to
electric fields due to its charge neutrality and, during free evolution, is not
subject to photon recoil heating. We achieve free-fall durations of up to 0.25
ms and observe a nearly two hundred-fold increase in the particle's position
uncertainty at recapture. The current limit on the free-fall time arises from
the performance of the initial cooling step. By implementing linear feedback
techniques and reducing the background pressure, we expect to perform
millisecond-scale free-fall experiments in ultra-high vacuum, opening new
opportunities for generating large delocalizations of levitated objects.

</details>


### [309] [A Modular PyTheus Quantum Network Interpreter: Automated Analysis and Visualization of Optimized Quantum Architectures](https://arxiv.org/abs/2507.12997)
*S. K. Rithvik*

Main category: quant-ph

TL;DR: We present a modular interpreter for PyTheus-optimized quantum networks that automatically analyzes and visualizes complex quantum architectures. It identifies functional roles, performs graph-theoretical analysis, and generates visualizations for machine-designed networks, aiding in understanding and validation.


<details>
  <summary>Details</summary>
Motivation: To address the critical challenge of understanding machine-designed quantum networks by providing robust algorithms for functional role identification, graph-theoretical analysis, and physically meaningful visualization across the major classes of PyTheus-optimized quantum networks.

Method: The interpreter accepts both file-based and in-memory network representations, automatically identifies sources, detectors, beam splitters, and ancillas through priority-based classification, and generates coordinated native graph plots and optical table representations. Demonstrations include analysis of a five-node quantum key distribution network and comprehensive validation using existing PyTheus examples (W4 state generation, heralded Bell state preparation, and GHZ state networks).

Result: The interpreter successfully handles complex connectivity patterns, avoids visualization artifacts, and provides validation mechanisms for architectural consistency. The analysis of the five-node quantum key distribution network revealed distributed source architecture and dual-role node functionality.

Conclusion: The interpreter successfully handles complex connectivity patterns across diverse quantum network architectures within the tested classes, avoids visualization artifacts, and provides validation mechanisms for architectural consistency. The primary contribution is the development of robust modular interpretation algorithms that can analyze the major classes of PyTheus-generated quantum networks, enabling better understanding of automated quantum architecture design.

Abstract: We present a modular interpreter for PyTheus-optimized quantum networks that
automatically analyzes and visualizes complex quantum architectures discovered
through automated optimization. The interpreter addresses the critical
challenge of understanding machine-designed quantum networks by providing
robust algorithms for functional role identification, graph-theoretical
analysis, and physically meaningful visualization across the major classes of
PyTheus-generated networks. Our interpreter accepts both file-based and
in-memory network representations, automatically identifies sources, detectors,
beam splitters, and ancillas through priority-based classification, and
generates coordinated native graph plots and optical table representations. We
demonstrate the interpreter's capabilities through two complementary
approaches: (1) analysis of a newly developed five-node quantum key
distribution network that reveals distributed source architecture and dual-role
node functionality, and (2) comprehensive validation using existing PyTheus
examples including W4 state generation, heralded Bell state preparation, and
GHZ state networks. The interpreter successfully handles complex connectivity
patterns across diverse quantum network architectures within the tested
classes, avoids visualization artifacts, and provides validation mechanisms for
architectural consistency. Our primary contribution is the development of
robust modular interpretation algorithms that can analyze the major classes of
PyTheus-generated quantum networks, enabling better understanding of automated
quantum architecture design.

</details>


### [310] [Quantum Kramers-Henneberger Transformation](https://arxiv.org/abs/2507.13006)
*Javier Argüello-Luengo,Javier Rivera-Dean,Philipp Stammer,Marcelo F. Ciappina,Maciej Lewenstein*

Main category: quant-ph

TL;DR: 将Kramers-Henneberger变换推广到量子领域，考虑了量子涨落，发现了量子电动力学修正，并提出了实验验证方案。


<details>
  <summary>Details</summary>
Motivation: 将经典的Kramers-Henneberger变换推广到量子电动力学和量子光学领域，以考虑量子涨落并揭示量子电动力学修正。

Method: 通过显式处理陷阱位置的量子力学，将经典的Kramers-Henneberger变换扩展到量子电动力学和量子光学领域，考虑了时变位移力的量子涨落。

Result: 量子电动力学修正会出现，并且可以通过光力学实现来检测这些修正。

Conclusion: 本文将经典的Kramers-Henneberger变换推广到量子电动力学和量子光学领域，显式地处理了陷阱位置的量子力学，考虑了时变位移力的量子涨落。与经典情况相比，量子电动力学修正会出现，并且提出了一种用于量化陷阱位置的光力学实现方法，以证明这些修正可以在最新的实验中体现出来。这些结果为利用超冷囚禁原子和离子进行阿秒物理学和超快物理学的量子电动力学和量子光学的新型量子模拟开辟了道路。

Abstract: The classical Kramers-Henneberger transformation connects, via a series of
unitary transformations, the dynamics of a quantum particle of mass $m$ located
in a trap at position $\alpha(t)$, with the dynamics of a charge $e$ moving in
an electric field $e{\cal{E}}(t)=-m\ddot{\alpha}(t)$ within the dipole
approximation. In this paper, we extend the classical Kramers-Henneberger
transformation to the quantum electrodynamic and quantum optical realm, by
explicitly treating the trap location quantum mechanically, thus taking into
account the quantum fluctuations of the time-dependent displacement force.
Compared to the classical case, we show that quantum electrodynamic corrections
appear, and we propose an optomechanical realization for the quantized position
of the trap to show that such corrections can manifest in state-of-the-art
experiments. These results open the path to novel quantum simulation of quantum
electrodynamics and quantum optics of attoscience and ultrafast physics by
using ultracold trapped atoms and ions.

</details>


### [311] [Dark-state photonic entanglement filters](https://arxiv.org/abs/2507.13016)
*Stefano Longhi*

Main category: quant-ph

TL;DR: 量子技术中的纠缠过滤可以通过避免非厄米对称性来简化。


<details>
  <summary>Details</summary>
Motivation: 在量子技术中，在退相干存在的情况下保持纠缠仍然是一个重大挑战。最近的提案[M.A. Selim et al., Science 387, 1424 (2025)]采用了基于反奇偶校验时间对称性的光子滤波器来恢复某些纠缠态，但这些方法需要复杂的、对称性约束的波导结构和精确的浴工程。

Method: 识别后选择和暗态的出现——这些暗态通过简单光子设置中的破坏性干涉自然产生——作为基本机制。

Result: 我们表明，这种严格的非厄米对称性约束对于纠缠过滤不是必需的。

Conclusion: 通过避免特殊的浴工程或非厄米对称性，我们的方法大大简化了设计和架构，增强了通用性，并将适用性扩展到先前研究的二聚体配置之外。我们使用最小波导网络设计演示了这一概念，为鲁棒的纠缠过滤提供了一条广泛可及的途径。

Abstract: Preserving entanglement in the presence of decoherence remains a major
challenge for quantum technologies. Recent proposals [M.A. Selim et al.,
Science 387, 1424 (2025)] have employed photonic filters based on
anti-parity-time symmetry to recover certain entangled states, but these
approaches require intricate, symmetry-constrained waveguide architectures and
precise bath engineering. In this work, we show that such strict non-Hermitian
symmetry constraints are not necessary for entanglement filtering. Instead, we
identify post-selection and the emergence of dark states -- arising naturally
through destructive interference in simple photonic settings -- as the
essential mechanisms. By avoiding the need for special bath engineering or
non-Hermitian symmetries, our approach significantly simplifies the design and
architecture, enhances universality, and extends applicability beyond
previously studied dimer configurations. We demonstrate this concept using
minimal waveguide network designs, offering a broadly accessible route to
robust entanglement filtering.

</details>


### [312] [Geometry of quantum states and chaos-integrability transition](https://arxiv.org/abs/2507.13067)
*Ankit Gill,Keun-Young Kim,Kunal Pal,Kuntal Pal*

Main category: quant-ph

TL;DR: This paper analyzes the geometry of quantum states in random matrix Hamiltonians that transition from integrability to chaos. It uses fidelity susceptibility and the quantum metric tensor to measure distances between states. The study finds that distant points in the integrable phase are reachable and that fidelity susceptibility in Gaussian $eta$-ensembles shares common characteristics with other studied Hamiltonians.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore the geometry of quantum states linked to random matrix Hamiltonians, particularly those exhibiting a transition from integrability to chaos, by examining the fidelity susceptibility and quantum metric tensor.

Method: The study calculates relevant correlation functions of a random matrix from the Gaussian unitary ensemble and obtains the fidelity susceptibility from this correlation function, analyzing the role of energy level correlation. It also solves geodesic equations for the quantum metric tensor of an integrability-breaking random matrix Hamiltonian using coordinate transformations to find the geodesic distance between points on the parameter manifold. Finally, it derives and discusses properties of the fidelity susceptibility for Gaussian $eta$-ensembles.

Result: The distance between two states in a single-parameter Hamiltonian is captured by fidelity susceptibility, while a multi-parameter Hamiltonian uses the quantum metric tensor. The study shows that any point far from the integrable phase can be reached by a finite geodesic distance. The fidelity susceptibility for Gaussian $eta$-ensembles exhibits generic features similar to the first class of Hamiltonians.

Conclusion: For Gaussian $eta$-ensembles with general values of the Dyson index $eta$, the fidelity susceptibility shares generic features with the first class of Hamiltonians.

Abstract: We consider the geometry of quantum states associated with classes of random
matrix Hamiltonians, in particular ensembles that show integrability to chaotic
transition in terms of the nearest neighbour energy level spacing distribution.
In the case that the total Hamiltonian contains a single parameter, the
distance between two states is captured by the fidelity susceptibility,
whereas, when the total Hamiltonian contains multiple parameters, this distance
is given by the quantum metric tensor. Since the fieldity susceptibility is
closely related to the two-point correlation function, we first calculate the
relevant correlation functions of a random matrix belonging to the Gaussian
unitary ensemble in terms of the spectral form factor of the total Hamiltonian,
show how to obtain the fidelity susceptibility from this correlation function,
and explain the role played by energy level correlation. Next, by performing
suitable coordinate transformations, we solve the geodesic equations
corresponding to the quantum metric tensor obtained from an
integrability-breaking random matrix Hamiltonian and obtain the geodesic
distance between two points on the parameter manifold to show that any point
far away from the integrable phase can be reached by a finite value of this
distance. Finally, we obtain and discuss different properties of the fidelity
susceptibility associated with Hamiltonians belonging to another random matrix
ensemble which shows integrability to chaos transition, namely the Gaussian
$\beta$-ensembles with general values of the Dyson index $\beta$, and show that
the fidelity susceptibility shares generic features with the first class of
Hamiltonians.

</details>


### [313] [Emulation of Self-Consistent Non-Hermitian Quantum Formalisms](https://arxiv.org/abs/2507.13078)
*Mario Gonzalez,Karin Sim,R. Chitra*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量子模拟非厄米系统的方法，通过将非厄米系统嵌入到封闭的厄米系统中，并利用数字量子模拟器进行了实验验证，证明了该方法的可行性。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的哈密顿量厄米性要求被放松时，会出现状态范数和概率不守恒的问题。为了解决这一问题，双正交量子力学或更一般的度量形式主义提供了一种严谨的非厄米量子力学表述，其中范数和概率是守恒的。然而，度量形式主义的物理实现仍然是一个未解决的问题。

Method: 通过算子扩张方案将自洽的非厄米量子力学嵌入到封闭的厄米系统中，并使用数字量子模拟器进行验证。

Result: 数字量子模拟器提供了动力学度量的原理证明和第一个实验证据，该度量是由量子比特中的非厄米性引起的。

Conclusion: 本工作提出了将非厄米系统嵌入封闭厄米系统的新范式，并通过数字量子模拟器提供了第一个实验证据，证明了由非厄米性引起的动力学度量。

Abstract: Standard quantum mechanics predicts the non-conservation of state norms and
probability when the fundamental requirement of the Hermiticity of the
Hamiltonian is relaxed. Biorthogonal quantum mechanics, or the more general
metric formalism, provides a rigorous formulation of non-Hermitian quantum
mechanics wherein norms and probabilities are conserved. The key feature is
that the Hilbert space is endowed with a non-trivial dynamical metric. Beyond
theoretical considerations, the physical implementation of the metric formalism
remains unaddressed. In this work, we propose novel operator dilation schemes,
which show that the self-consistent non-Hermitian quantum mechanics can be
accessed in physical platforms via an embedding in closed Hermitian systems.
Using digital quantum simulators, we present a proof of principle and the first
experimental evidence for the dynamical metric engendered by non-Hermiticity in
a qubit. Our work ushers in a new paradigm in the quantum simulation of
non-Hermitian systems.

</details>


### [314] [Perspective: Practical Atom-Based Quantum Sensors](https://arxiv.org/abs/2507.13111)
*Justin M. Brown,Thad G. Walker*

Main category: quant-ph

TL;DR: 原子蒸气是强大的量子系统，可用于传感应用。


<details>
  <summary>Details</summary>
Motivation: 阐述了利用原子实现实用量子传感器的潜力和过程。

Method: 原子蒸气利用光和其他电磁场进行操控和探测，作为一种多功能且强大的量子系统，在传感应用中具有巨大潜力。

Result: 原子蒸气作为量子系统在传感应用中具有优势，可以通过操纵和探测来实现。

Conclusion: 原子非常适合用于传感应用，因为它们是相同的、可分离的、可接口化的和可理解的。现代激光和电光工具可以相对容易地利用原子的量子特性进行状态制备和检测。

Abstract: Atomic vapors, manipulated and probed by light and other electromagnetic
fields, constitute versatile and powerful quantum systems for sensing
applications. Atoms are identical, isolatable, interfaceable, and intelligible.
These features, coupled with the relative simplicity with which quantum
properties can be exploited in state preparation and detection using modern
laser and electro-optic tools, make atoms very attractive for sensing
applications. This Perspective discusses the potential and process for
realizing practical quantum sensors using atoms.

</details>


### [315] [Mechanical Squeezed-Fock Qubit: Towards Quantum Weak-Force Sensing](https://arxiv.org/abs/2507.13161)
*Yi-Fan Qiao,Jun-Hong An,Peng-Bo Li*

Main category: quant-ph

TL;DR: 通过使用参数驱动的非线性机械振荡器中声子的挤压福克态，我们提出了一种新的机械量子比特（机械挤压福克量子比特），它具有指数增强的非调和性，并且可以作为一种高灵敏度的量子传感器。


<details>
  <summary>Details</summary>
Motivation: 克服机械量子比特的固有弱非线性和小的非调和性，以提高其相干时间和传感能力。

Method: 提出使用参数驱动的非线性机械振荡器中声子的挤压福克态来克服机械量子比特的固有弱非线性和小非调和性。

Result: 在两声子驱动下，挤压福克态成为克尔非线性机械振荡器的特征态，能量谱具有指数增强和可调的非调和性，从而使向更高能级的跃迁呈指数级抑制。这种机械量子比特的灵敏度比传统机械量子比特提高了至少一个数量级。

Conclusion: 提出的机械挤压福克量子比特为量子传感和信息处理提供了一个强大的量子声子平台。

Abstract: Mechanical qubits offer unique advantages over other qubit platforms,
primarily in terms of coherence time and possibilities for enhanced sensing
applications, but their potential is constrained by the inherently weak
nonlinearities and small anharmonicity of nanomechanical resonators. We propose
to overcome this shortcoming by using squeezed Fock states of phonons in a
parametrically driven nonlinear mechanical oscillator. We find that, under
two-phonon driving, squeezed Fock states become eigenstates of a Kerr-nonlinear
mechanical oscillator, featuring an energy spectrum with exponentially enhanced
and tunable anharmonicity, such that the transitions to higher energy states
are exponentially suppressed. This enables us to encode the mechanical qubit
within the ground and first excited squeezed Fock states of the driven
mechanical oscillator. This kind of mechanical qubit is termed mechanical
squeezed-Fock qubit. We also show that our mechanical qubit can serve as a
quantum sensor for weak forces, with its resulting sensitivity increased by at
least one order of magnitude over that of traditional mechanical qubits. The
proposed mechanical squeezed-Fock qubit provides a powerful quantum phonon
platform for quantum sensing and information processing.

</details>


### [316] [Quantum-to-Classical Transition via Single-Shot Generalized Measurements](https://arxiv.org/abs/2507.13174)
*Zhenyu Xu*

Main category: quant-ph

TL;DR: 提出一个操作框架来解释量子到经典态的转变，揭示维度和退相干率的作用，并提出相应的量子电路实现。


<details>
  <summary>Details</summary>
Motivation: 解决量子到经典态转变过程中中间阶段机制不明的挑战。

Method: 采用操作框架连接离散的广义相干态POVM和连续的各向同性退相干信道。

Result: 维度和退相干率共同决定量子到经典态的转变；单次广义测量可消除大部分负拟概率；提出可行的量子电路实现方案。

Conclusion: 该研究通过操作框架连接了离散的广义相干态POVM和连续的各向同性退相干信道，揭示了维度和退相干率如何共同影响量子到经典态的转变。研究表明，单次广义测量可以消除有限维系统中大部分相位空间的负拟概率。此外，研究提出了可行的量子电路实现方案。

Abstract: Quantum-to-classical transition for finite-dimensional systems is widely
considered to occur continuously, yet the mechanism underlying the intermediate
stage remains unclear. In this work, we address this challenge by adopting an
operational framework to bridge discrete generalized coherent state
positive-operator-valued measurements and continuous isotropic depolarizing
channels. Our unified treatment reveals how dimensionality and decoherence rate
collectively govern the quantum-to-classical transition. Notably, we
demonstrate that a single-shot generalized measurement can eliminate most
negative quasi-probabilities in phase space for finite-dimensional systems.
Furthermore, we propose quantum circuit implementations achievable with current
state-of-the-art quantum technologies.

</details>


### [317] [Discrete solitons in Rydberg atom chains](https://arxiv.org/abs/2507.13196)
*Aron Kerschbaumer,Jean-Yves Desaules,Marko Ljubotina,Maksym Serbyn*

Main category: quant-ph

TL;DR: Solitons found in Rydberg atoms, potentially useful for quantum information and explaining energy transport.


<details>
  <summary>Details</summary>
Motivation: Investigating robust localized excitations (solitons) in quantum many-body systems, which are typically destroyed by thermalization.

Method: Theoretical demonstration of solitonic excitations in Rydberg atom chains, including a phenomenological description and a classical nonlinear dynamical system counterpart.

Result: Demonstrated existence of solitonic excitations in Rydberg atom chains, showing they propagate directionally, carry energy, have long coherence times, and represent a novel type of non-ergodic quantum dynamics. A classical counterpart was also identified.

Conclusion: Soliton-like excitations exist in high-energy states of Rydberg atom chains, offering potential for quantum information transfer and explaining anomalous energy transport.

Abstract: Solitons - localized wave packets that travel without spreading - play a
central role in understanding transport and properties of nonlinear systems,
from optical fibers to fluid dynamics. In quantum many-body systems, however,
such robust excitations are typically destroyed by thermalization. Here, we
theoretically demonstrate the existence of solitonic excitations in high-energy
states of Rydberg atom chains in the regime of strong nearest-neighbor Rydberg
blockade. These localized wave packets propagate directionally atop a special
class of reviving initial states related to quantum many-body scars and are
capable of carrying energy. Exhibiting long coherence times, these states
constitute a novel type of non-ergodic quantum dynamics and can be efficiently
implemented on Rydberg atom simulators. In addition to a phenomenological
description of solitons, we identify their counterpart in a classical nonlinear
dynamical system obtained from a variational projection of the quantum
dynamics. We demonstrate the potential use of solitons in quantum information
transfer and conjecture their relevance for the anomalous energy transport
reported in numerical studies of Rydberg atom arrays.

</details>


### [318] [Gravity-mediated entanglement via infinite-dimensional systems](https://arxiv.org/abs/2507.13201)
*Stefan L. Ludescher,Leon D. Loveridge,Thomas D. Galley,Markus P. Müller*

Main category: quant-ph

TL;DR: 经典系统不能介导纠缠，这表明重力诱导的纠缠表明重力场具有非经典特征。


<details>
  <summary>Details</summary>
Motivation: 通过台式实验探测量子引力，需要证明任何能够产生纠缠的媒介本身都必须是非经典的。

Method: 将经典系统建模为交换单位C*-代数，包括经典力学和场论。

Result: 即使A和B本身是无限维的或由任意单位C*-代数描述，经典系统也不能在两个量子系统A和B之间进行纠缠。

Conclusion: 需要重力场具有固有的非经典特征，才能观察到重力诱导的纠缠。

Abstract: There has been a wave of recent interest in detecting the quantum nature of
gravity with table-top experiments that witness gravitationally mediated
entanglement. Central to these proposals is the assumption that any mediator
capable of generating entanglement must itself be nonclassical. However,
previous arguments for this have modelled classical mediators as finite,
discrete systems such as bits, which excludes physically relevant continuous
and infinite-dimensional systems such as those of classical mechanics and field
theory. In this work, we close this gap by modelling classical systems as
commutative unital C*-algebras, arguably encompassing all potentially
physically relevant classical systems. We show that these systems cannot
mediate entanglement between two quantum systems A and B, even if A and B are
themselves infinite-dimensional or described by arbitrary unital C*-algebras
(as in Quantum Field Theory), composed with an arbitrary C*-tensor product.
This result reinforces the conclusion that the observation of gravity-induced
entanglement would require the gravitational field to possess inherently
non-classical features.

</details>


### [319] [Robust and efficient estimation of global quantum properties under realistic noise](https://arxiv.org/abs/2507.13237)
*Qingyue Zhang,Dayue Qin,Zhou You,Feng Xu,Jens Eisert,You Zhou*

Main category: quant-ph

TL;DR: 一种新的量子测量方法，使用随机线路和受控-Z门，可以更好地处理噪声，并提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有测量全局量子属性（如多方量子态保真度）的实验挑战，以及现有方法（如经典影院估计）对许多量子比特线路的依赖性。

Method: 提出了一种基于随机线路和受控-Z门作为唯一纠缠门类型的鲁棒相位阴影方案。

Result: 相位阴影在性能上可以与基于Clifford的阴影相匹配，并且可以通过纯粹的经典后处理实现对噪声的鲁棒性，此外，还设计了一种有效的后处理算法来解决先前阴影协议中的计算瓶颈。

Conclusion: 该方法通过随机线路和受控-Z门提供了一种新颖的测量框架，可与完整的Clifford协议相媲美，并且对噪声具有鲁棒性，有望解决传统方法在噪声环境下的局限性。

Abstract: Measuring global quantum properties -- such as the fidelity to complex
multipartite states -- is both an essential and experimentally challenging
task. Classical shadow estimation offers favorable sample complexity, but
typically relies on many-qubit circuits that are difficult to realize on
current platforms. We propose the robust phase shadow scheme, a measurement
framework based on random circuits with controlled-Z as the unique entangling
gate type, tailored to architectures such as trapped ions and neutral atoms.
Leveraging tensor diagrammatic reasoning, we rigorously analyze the induced
circuit ensemble and show that phase shadows match the performance of full
Clifford-based ones. Importantly, our approach supports a noise-robust
extension via purely classical post-processing, enabling reliable estimation
under realistic, gate-dependent noise where existing techniques often fail.
Additionally, by exploiting structural properties of random stabilizer states,
we design an efficient post-processing algorithm that resolves a key
computational bottleneck in previous shadow protocols. Our results enhance the
practicality of shadow-based techniques, providing a robust and scalable route
for estimating global properties in noisy quantum systems.

</details>


### [320] [Resources for bosonic metrology: quantum-enhanced precision from a superselection rule perspective](https://arxiv.org/abs/2507.13245)
*Astghik Saharyan,Eloi Descamps,Arne Keller,Pérola Milman*

Main category: quant-ph

TL;DR: 本文提出了一个统一的量子计量学框架，将量子光学和原子系统联系起来，并提出了一种新的电磁场表示方法，以实现更优的参数估计。


<details>
  <summary>Details</summary>
Motivation: 以往的研究将量子光学和原子系统分开处理，且在量子光学内部，最优探测器的识别也依赖于个案分析。本文旨在建立一个统一的框架来解决这些问题。

Method: 本文提出了一种新的电磁场表示方法，该方法满足超选择规则，并明确包含了相位参考和粒子数守恒。

Result: 本文成功地将离散和连续变量的量子光学极限统一在一个框架下，并恢复了已建立的关于量子资源增强精度的结果，同时还提出了使用任意多模纠缠探针态优化精度的通用策略。

Conclusion: 本文提出了一个统一的量子计量学框架，该框架涵盖了所有已知的利用噪声和测量策略的增强精度的方法，并能适应非酉演化。

Abstract: Quantum optics and atomic systems are prominent platforms for exploiting
quantum-enhanced precision in parameter estimation. However, not only are
quantum optical and atomic systems often treated separately, but even within
quantum optics, identifying optimal probes (quantum states) and evolutions
(parameter-dependent dynamics) typically relies on case-by-case analyses. Mode,
and sometimes only particle entanglement, can yield quantum enhancement of
precision in continuous- and discrete-variable regimes, yet a clear connection
between these regimes remains elusive. In this work, we present a unified
framework for quantum metrology that encompasses all known precision-enhancing
regimes using bosonic resources. We introduce a superselection rule compliant
representation of the electromagnetic field that explicitly incorporates the
phase reference, enforcing total particle number conservation. This approach
provides a description of the electromagnetic field which is formally
equivalent to the one employed in atomic systems, and we show how it
encompasses both the discrete and the continuous limits of quantum optics.
Within this framework, we consistently recover established results while
offering a coherent physical interpretation of the quantum resources
responsible for precision enhancement. Moreover, we develop general strategies
to optimize precision using arbitrary multimode entangled probe states.
Finally, our formalism readily accommodates noise, measurement strategies and
non-unitary evolutions, extending its applicability to realistic experimental
scenarios.

</details>


### [321] [State transfer analysis for linear spin chains with non-uniform on-site energies](https://arxiv.org/abs/2507.13261)
*Chad C. Nelmes,Irene D'Amico,Timothy P. Spiller*

Main category: quant-ph

TL;DR: 本研究研究了具有非均匀驻点能量的线性自旋链中的状态传输，旨在维持耦合均匀性，并分析了其对物理实现的潜在好处。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是维持耦合均匀性，这可能有利于某些物理实现。

Method: 通过分析与离散势能类似物中的粒子相关的耦合均匀性，并考虑了耦合和驻点能量的统计变化（随着链位点数N的增加）来分析。

Result: 研究结果表明，在线性自旋链中结合非均匀驻点能量可以实现完美和准完美状态传输。

Conclusion: 本研究分析了在线性自旋链中结合非均匀驻点能量的完美和准完美状态传输结果。

Abstract: High fidelity state transfer is an important ingredient of distributed
quantum information processing. We present and analyse results on perfect and
quasi-perfect state transfer with linear spin chains incorporating non-uniform
on-site energies. The motivation is maintenance of coupling uniformity, which
could be beneficial for some physical implementations. We relate this coupling
uniformity to a particle in a discrete potential analogue. Our analysis further
considers the statistical variation in couplings and on-site energies, as a
function of increasing chain site number N.

</details>


### [322] [Local nanoscale probing of electron spins using NV centers in diamond](https://arxiv.org/abs/2507.13295)
*Sergei Trofimov,Christos Thessalonikios,Victor Deinhart,Alexander Spyrantis,Lucas Tsunaki,Kseniia Volkova,Katja Höflich,Boris Naydenon*

Main category: quant-ph

TL;DR: 研究人员利用氦离子显微镜和NV色心探针，通过DEER技术精确测量金刚石中的局部氮浓度和其他顺磁缺陷浓度，以优化量子器件。


<details>
  <summary>Details</summary>
Motivation: 为了优化基于金刚石的量子器件，需要精确量化氮浓度，因为氮杂质（P1中心）会影响NV色心的性能。现有的宏观表征方法忽略了氮含量的局部变化。

Method: 使用氦离子显微镜在金刚石晶体预定位置制备纳米级NV色心系综，并利用NV色心探针通过双电子电子共振（DEER）技术测量局部氮浓度，同时通过将DEER光谱与数值模拟进行比较，确定其他未知顺磁缺陷的浓度。

Result: 该方法能够测量低至230 ppb（原子十亿分之一）的局部氮浓度，并能确定其他未知顺磁缺陷的浓度，最低可达15 ppb，具体取决于离子注入剂量。

Conclusion: 通过使用氦离子显微镜和双电子电子共振技术，可以精确测量金刚石晶体中低浓度氮的局部浓度，并确定其他未知顺磁缺陷的浓度。

Abstract: Substitutional nitrogen atoms in a diamond crystal (P1 centers) are, on one
hand, a resource for creation of nitrogen-vacancy (NV) centers, that have been
widely employed as nanoscale quantum sensors. On the other hand, P1's electron
spin is a source of paramagnetic noise that degrades the NV's performance by
shortening its coherence time. Accurate quantification of nitrogen
concentration is therefore essential for optimizing diamond-based quantum
devices. However, bulk characterization methods based on optical absorption or
electron paramagnetic resonance often overlook local variations in nitrogen
content. In this work, we use a helium ion microscope to fabricate nanoscale NV
center ensembles at predefined sites in a diamond crystal containing low
concentrations of nitrogen. We then utilize these NV-based probes to measure
the local nitrogen concentration on the level of 230 ppb (atomic parts per
billion) using the double electron-electron resonance (DEER) technique.
Moreover, by comparing the DEER spectra with numerical simulations, we managed
to determine the concentration of other unknown paramagnetic defects created
during the ion implantation, reaching 15 ppb depending on the implantation
dose.

</details>


### [323] [Simple ways of preparing qudit Dicke states](https://arxiv.org/abs/2507.13308)
*Noah B. Kerzner,Federico Galeazzi,Rafael I. Nepomechie*

Main category: quant-ph

TL;DR: The paper introduces new, simpler quantum circuits for creating advanced types of quantum states called Dicke states.


<details>
  <summary>Details</summary>
Motivation: The paper aims to provide methods for preparing higher-dimensional generalizations of Dicke states, which are important in quantum information science.

Method: The paper uses two main approaches: a deterministic approach based on exact canonical matrix product state representations, and a probabilistic approach based on quantum phase estimation.

Result: The paper offers explicit and straightforward quantum circuits for preparing $SU(2)$ spin-$s$ and $SU(d)$ Dicke states, which are simpler than existing methods.

Conclusion: The paper presents explicit and straightforward quantum circuits for preparing higher-dimensional generalizations of Dicke states ($SU(2)$ spin-$s$ and $SU(d)$ Dicke states) on a qudit quantum computer. These circuits are simpler than previously reported ones.

Abstract: Dicke states are permutation-invariant superpositions of qubit computational
basis states, which play a prominent role in quantum information science. We
consider here two higher-dimensional generalizations of these states: $SU(2)$
spin-$s$ Dicke states and $SU(d)$ Dicke states. We present various ways of
preparing both types of qudit Dicke states on a qudit quantum computer, using
two main approaches: a deterministic approach, based on exact canonical matrix
product state representations; and a probabilistic approach, based on quantum
phase estimation. The quantum circuits are explicit and straightforward, and
are arguably simpler than those previously reported.

</details>


### [324] [Long-time storage of a decoherence-free subspace logical qubit in a dual-type quantum memory](https://arxiv.org/abs/2507.13320)
*Y. L. Xu,L. Zhang,C. Zhang,Y. K. Wu,Y. Y. Chen,C. X. Huang,Z. B. Cui,R. Yao,W. Q. Lian,J. Y. Ma,W. X. Guo,B. X. Qi,P. Y. Hou,Y. F. Pu,Z. C. Zhou,L. He,L. M. Duan*

Main category: quant-ph

TL;DR: 一项关于在低温陷阱中实现多离子量子存储器的研究，相干时间超过两小时，克服了室温陷阱的限制，并具有良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有量子存储器在室温陷阱中离子位置不稳定的限制，并实现多离子量子存储器。

Method: 通过在低温陷阱中使用双类型方案，并对主要的泄漏错误进行纠正，实现了多离子量子存储器。

Result: 成功实现了相干时间超过两小时的多离子量子存储器，该存储器编码在两个离子的纠缠态（即退相干自由子空间）中。

Conclusion: 该研究报告了一种基于双类型方案的低温陷阱中的多离子量子存储器，并演示了逻辑量子比特的相干时间超过两小时。

Abstract: A quantum memory is an essential element for quantum computation, quantum
network and quantum metrology. Previously, a single-qubit quantum memory with a
coherence time of about an hour has been realized in a dual-species setup where
a coolant ion provides sympathetic cooling for a memory ion of different
species. However, the frequent random position hopping between the ions in the
room-temperature trap limits the technique there only applicable to
single-qubit storage. Here we report a multi-ion quantum memory in a cryogenic
trap based on the dual-type scheme, and demonstrate a coherence time above two
hours for a logical qubit encoded in the decoherence-free subspace, i.e.
two-ion entangled states, after correcting the dominant leakage error. Our
scheme alleviates the necessity of an ultra-stable frequency reference for the
stored qubit, and has a preferable scalability owing to the same mass of the
metastable-state memory ions and the ground-state coolant ion.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [325] [DNA Probe Computing System for Solving NP-Complete Problems](https://arxiv.org/abs/2507.12470)
*Jin Xu,XiaoLong Shi,Xin Chen,Fang Wang,Sirui Li,Pali Ye,Boliang Zhang,Di Deng,Zheng Kou,Xiaoli Qiang*

Main category: cs.DS

TL;DR: 该研究提出了一种新的DNA计算方法，可以并行解决复杂的计算问题，如蛋白质结构预测。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统电子计算机在处理NP完全问题（如蛋白质结构预测、密码解密和漏洞检测）时受限于图灵机的单维数据处理和顺序操作的瓶颈，需要计算模型采用多维数据结构和并行信息处理机制。

Method: 提出了一种基于DNA计算的阻塞探测技术，利用DNA计算的内在并行性，在单次探测操作中识别NP完全问题所有有效的解决方案。

Result: 使用27顶点3着色问题作为案例研究，通过DNA分子探测实验成功检索到所有解决方案，证明了该方法的有效性。

Conclusion: 该研究首次在分子水平上实现了全并行计算系统，为解决计算复杂性问题提供了一种新范式。

Abstract: Efficiently solving NP-complete problems-such as protein structure
prediction, cryptographic decryption, and vulnerability detection-remains a
central challenge in computer science. Traditional electronic computers,
constrained by the Turing machine's one-dimensional data processing and
sequential operations, struggle to address these issues effectively. To
overcome this bottleneck, computational models must adopt multidimensional data
structures and parallel information processing mechanisms. Building on our
team's proposed probe machine model (a non-Turing computational framework),
this study develops a blocking probe technique that leverages DNA computing's
inherent parallelism to identify all valid solutions for NP-complete problems
in a single probe operation. Using the 27-vertex 3-coloring problem as a case
study, we successfully retrieved all solutions through DNA molecular probe
experiments. This breakthrough demonstrates the first implementation of a fully
parallel computing system at the molecular level, offering a novel paradigm for
tackling computational complexity. Our results indicate that the probe machine,
with its parallel architecture and molecular implementation, transcends the
limitations of classical models and holds promise for solving intricate
real-world problems.

</details>


### [326] [Max-Cut with Multiple Cardinality Constraints](https://arxiv.org/abs/2507.12607)
*Yury Makarychev,Madhusudhan Reddy Pittu,Ali Vakilian*

Main category: cs.DS

TL;DR: 本研究提出了一个针对带多个基数约束的最大割问题的近似算法，在约束数量为常数时达到0.858的近似比，并解决了任意拟阵约束下的最大割问题。


<details>
  <summary>Details</summary>
Motivation: 研究经典的带约束最大割问题，特别是存在多个基数约束的情况。目标是改进现有算法在近似比和约束处理方面的不足，并探索问题的NP难性质以及更广泛的拟阵约束下的最大割问题。

Method: 通过设计Constrained Max-Cut的近似核，并利用Raghavendra和Tan（2012）的相关性舍入技术，提出了一种用于c=O(1)情况下的近似算法，该算法的运行时间为O(min{k/ε, n}^poly(c/ε) + poly(n))。

Result: 当c为常数时，提出了一个(0.858 - ε)-近似算法，优于Feige和Langberg（2001）的(1/2 + ε0)-近似算法，并推广了Raghavendra和Tan（2012）的算法。证明了一般情况下确定最大割可行解的NP难性。提出了一个针对任意拟阵约束的最大割问题的1/2近似算法。

Conclusion: 该研究为具有多个基数约束的最大割问题（Constrained Max-Cut）设计了一种近似算法。当约束数量c为常数时，该算法实现了0.858的近似比，优于先前针对单约束版本（maxcut_k）的0.5近似比，并解决了Raghavendra和Tan（2012）工作中未考虑多约束情况的局限性。此外，研究还证明了在一般情况下确定是否存在可行解（可以切割所有边）是NP难的，并提出了一个针对任意拟阵约束的最大割问题的1/2近似算法。

Abstract: We study the classic Max-Cut problem under multiple cardinality constraints,
which we refer to as the Constrained Max-Cut problem. Given a graph $G=(V, E)$,
a partition of the vertices into $c$ disjoint parts $V_1, \ldots, V_c$, and
cardinality parameters $k_1, \ldots, k_c$, the goal is to select a set $S
\subseteq V$ such that $|S \cap V_i| = k_i$ for each $i \in [c]$, maximizing
the total weight of edges crossing $S$ (i.e., edges with exactly one endpoint
in $S$).
  By designing an approximate kernel for Constrained Max-Cut and building on
the correlation rounding technique of Raghavendra and Tan (2012), we present a
$(0.858 - \varepsilon)$-approximation algorithm for the problem when $c =
O(1)$. The algorithm runs in time $O\left(\min\{k/\varepsilon,
n\}^{\poly(c/\varepsilon)} + \poly(n)\right)$, where $k = \sum_{i \in [c]} k_i$
and $n=|V|$. This improves upon the $(\frac{1}{2} +
\varepsilon_0)$-approximation of Feige and Langberg (2001) for $\maxcut_k$ (the
special case when $c=1, k_1 = k$), and generalizes the $(0.858 -
\varepsilon)$-approximation of Raghavendra and Tan (2012), which only applies
when $\min\{k,n-k\}=\Omega(n)$ and does not handle multiple constraints.
  We also establish that, for general values of $c$, it is NP-hard to determine
whether a feasible solution exists that cuts all edges. Finally, we present a
$1/2$-approximation algorithm for Max-Cut under an arbitrary matroid
constraint.

</details>


### [327] [Fast Approximate Rank Determination and Selection with Group Testing](https://arxiv.org/abs/2507.12634)
*Adiesha Liyanage,Braeden Sopp,Brendan Mumey*

Main category: cs.DS

TL;DR: 该研究提出了用于序关系分组测试的新算法，可加速查找最小/最大元素、秩确定和选择。算法包括用于最小/最大查找的拉斯维加斯算法，以及用于近似秩确定和选择的蒙特卡洛算法，均在查询复杂度上有改进。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是探索分组测试操作在检查集合中的序关系时，能否加速诸如图查找最小/最大元素、秩确定和选择等问题。

Method: 研究采用了拉斯维加斯算法和蒙特卡洛算法来解决这些问题。对于最小/最大元素查找，设计了一种期望查询次数为 O(log^2 n) 的拉斯维加斯算法。对于秩确定和选择问题，提出了允许 1 ± δ 相对误差的随机近似算法。

Result: 该研究为最小/最大元素查找提供了一种期望查询复杂度为 O(log^2 n) 的拉斯维加斯算法。此外，还为近似秩确定设计了一种蒙特卡洛算法，其期望查询复杂度为 	ilde{O}(1/δ^2 - log ε)，成功概率为 1-ε。对于近似选择，设计了一种期望查询复杂度为 	ilde{O}(-log(εδ^2)/δ^4) 的蒙特卡洛算法，该算法有至少 1/2 的概率输出一个元素 x，且该元素 x 具有所需近似秩的概率为 1-ε。

Conclusion: 该研究为涉及序关系检查的分组测试操作提供了新的算法，特别是在最小/最大元素查找、秩确定和选择等问题上。

Abstract: Suppose that a group test operation is available for checking order relations
in a set, can this speed up problems like finding the minimum/maximum element,
rank determination and selection? We consider a one-sided group test to be
available, where queries are of the form $u \le_Q V$ or $V \le_Q u$, and the
answer is `yes' if and only if there is some $v \in V$ such that $u \le v$ or
$v \le u$, respectively. We restrict attention to total orders and focus on
query-complexity; for min or max finding, we give a Las Vegas algorithm that
makes $\mathcal{O}(\log^2 n)$ expected queries. We also give randomized
approximate algorithms for rank determination and selection; we allow a
relative error of $1 \pm \delta$ for $\delta > 0$ in the estimated rank or
selected element. In this case, we give a Monte Carlo algorithm for approximate
rank determination with expected query complexity
$\tilde{\mathcal{O}}(1/\delta^2 - \log \epsilon)$, where $1-\epsilon$ is the
probability that the algorithm succeeds. We also give a Monte Carlo algorithm
for approximate selection that has expected query complexity
$\tilde{\mathcal{O}}(-\log( \epsilon \delta^2) / \delta^4)$; it has probability
at least $\frac{1}{2}$ to output an element $x$, and if so, $x$ has the desired
approximate rank with probability $1-\epsilon$.

</details>


### [328] [An EPTAS for multiprocessor scheduling with rejection under a machine cost constraint](https://arxiv.org/abs/2507.12635)
*Mingyang Gong,Brendan Mumey*

Main category: cs.DS

TL;DR: This paper studies the multiprocessor scheduling with rejection problem under a machine cost constraint. It aims to minimize makespan plus rejection penalty, subject to a machine cost upper bound. A 2-approximation algorithm and an EPTAS for fixed machines are presented.


<details>
  <summary>Details</summary>
Motivation: The problem aims to minimize the makespan of accepted jobs plus the total rejection penalty of rejected jobs while the total machine cost does not exceed a given upper bound.

Method: We study the multiprocessor scheduling with rejection problem under a machine cost constraint. Each job is either rejected with a rejection penalty or accepted and scheduled on one of the machines for processing. The machine cost is proportional to the total processing time of the jobs scheduled on it.

Result: The problem aims to minimize the makespan of accepted jobs plus the total rejection penalty of rejected jobs while the total machine cost does not exceed a given upper bound.

Conclusion: We present a simple 2-approximation algorithm for the problem and achieve an EPTAS when the number of machines is a fixed constant.

Abstract: We study the multiprocessor scheduling with rejection problem under a machine
cost constraint. In this problem, each job is either rejected with a rejection
penalty or; accepted and scheduled on one of the machines for processing. The
machine cost is proportional to the total processing time of the jobs scheduled
on it. The problem aims to minimize the makespan of accepted jobs plus the
total rejection penalty of rejected jobs while the total machine cost does not
exceed a given upper bound. We present a simple $2$-approximation algorithm for
the problem and we achieve an EPTAS when the number $m$ of machines is a fixed
constant.

</details>


### [329] [Computing and Bounding Equilibrium Concentrations in Athermic Chemical Systems](https://arxiv.org/abs/2507.12699)
*Hamidreza Akef,Minki Hhan,David Soloveichik*

Main category: cs.DS

TL;DR: 该研究提出了一种用于计算聚合物-单体系统中平衡浓度的迭代算法，该算法在无热条件下运行，并考虑了熵力。所提出的方法为 DNA 纳米技术中的设计和验证提供了新的见解和框架。


<details>
  <summary>Details</summary>
Motivation: 在聚合物-单体水平上，在不使用每个聚合物的自由能参数的情况下，开发一种用于计算平衡浓度的迭代算法，以满足详细平衡，并为目标外聚合物浓度提供有效见解。

Method: 开发了一种迭代算法，用于分配满足详细平衡的聚合物浓度，从而使目标聚合物的浓度高而目标外聚合物的浓度低。

Result: 即使未直接执行，所提出的算法也能为目标外聚合物浓度提供有效见解，将关于离散配置（如 TBN 模型中的配置）的组合参数与实值浓度联系起来。已将该方法应用于减少 DNA 逻辑和信号传播中的泄漏。

Conclusion: 该方法为在配置由熵力区分时设计和验证平衡浓度提供了一个新框架。

Abstract: Computing equilibrium concentrations of molecular complexes is generally
analytically intractable and requires numerical approaches. In this work we
focus on the polymer-monomer level, where indivisible molecules (monomers)
combine to form complexes (polymers). Rather than employing free-energy
parameters for each polymer, we focus on the athermic setting where all
interactions preserve enthalpy. This setting aligns with the strongly bonded
(domain-based) regime in DNA nanotechnology when strands can bind in different
ways, but always with maximum overall bonding -- and is consistent with the
saturated configurations in the Thermodynamic Binding Networks (TBNs) model.
Within this context, we develop an iterative algorithm for assigning polymer
concentrations to satisfy detailed-balance, where on-target (desired) polymers
are in high concentrations and off-target (undesired) polymers are in low. Even
if not directly executed, our algorithm provides effective insights into upper
bounds on concentration of off-target polymers, connecting combinatorial
arguments about discrete configurations such as those in the TBN model to
real-valued concentrations. We conclude with an application of our method to
decreasing leak in DNA logic and signal propagation. Our results offer a new
framework for design and verification of equilibrium concentrations when
configurations are distinguished by entropic forces.

</details>


### [330] [Splittable Spanning Trees and Balanced Forests in Dense Random Graphs](https://arxiv.org/abs/2507.12707)
*David Gillman,Jacob Platnick,Dana Randall*

Main category: cs.DS

TL;DR: This paper introduces a new method for graph partitioning using spanning trees on random graphs, offering efficient and exact sampling. It also critiques the widely used ReCom algorithm, highlighting its inefficiencies and potential for failure in certain scenarios.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the need for efficient and provably correct algorithms for weighted equitable partitioning of graphs, particularly in applications like redistricting and network analysis. Existing methods, such as those based on random spanning trees and the ReCom algorithm, have limitations that this paper seeks to address.

Method: This paper analyzes the properties of spanning trees on dense random graphs for equitable partitioning and investigates the limitations of the ReCom algorithm. The methodology involves theoretical analysis of graph properties and the ReCom algorithm's Markov chain behavior, including cases of perfect equity and slight imbalances.

Result: The study shows that spanning trees on dense random graphs offer a high probability of being splittable, enabling efficient sampling of equitable partitions. Conversely, it reveals critical flaws in the ReCom algorithm, demonstrating its failure to be irreducible and potential for exponential time complexity in sampling, even under favorable graph conditions.

Conclusion: We demonstrate that spanning trees on dense random graphs can be split into k equal sized pieces with inverse polynomial probability, providing a class of graphs where equitable partitions can be sampled exactly and efficiently. We also show that the ReCom algorithm has significant drawbacks, failing even in special cases previously thought to be robust, with potential for exponential time complexity in its rejection sampling step.

Abstract: Weighted equitable partitioning of a graph has been of interest lately due to
several applications, including redistricting, network algorithms, and image
decomposition. Weighting a partition according to the spanning-tree metric has
been of mathematical and practical interest because it typically favors
partitions with more compact pieces. An appealing algorithm suggested by
Charikar et al. is to sample a random spanning tree and remove k-1 edges,
producing a random forest. If the components of the forest form a balanced
partition, the partition is equitable under an easily computed acceptance
probability. Cannon et al. recently showed that spanning trees on grid graphs
and grid-like graphs on $n$ vertices are splittable into $k$ equal sized pieces
with probability at least $n^{-2k}$, leading to the first rigorous sampling
algorithm for a class of graphs. We present complementary results showing that
spanning trees on dense random graphs also have inverse polynomial probability
of being splittable, giving another class of graphs where equitable partitions
can be efficiently sampled exactly. These proofs also guarantee fast
almost-uniform sampling for the up-down walk on forests, giving another
provably efficient randomized method for generating equitable partitions.
  Further, we show that problems with the well-studied ReCom algorithm for
equitable partitioning are more extensive than previously known, even in
special cases that were believed to be more promising. We present a family of
graphs where the Markov chain fails to be irreducible when it must keep the
components perfectly equitable; yet when the chain is allowed an imbalance of
just one vertex between components, the rejection sampling step may take
exponential time. This is true even when the graph satisfies desirable
properties that have been conjectured to be sufficient for fast sampling.

</details>


### [331] [Waiting is worth it and can be improved with predictions](https://arxiv.org/abs/2507.12822)
*Ya-Chun Liang,Meng-Hsi Li,Chung-Shou Liao,Clifford Stein*

Main category: cs.DS

TL;DR: 本文研究了在线旅行商问题（OLTSP）和在线叫车问题（OLDARP），并提出了一种利用在线预测来改进算法竞争比的方法。结果表明，该算法在一致性和鲁棒性方面取得了显著提升，但竞争比仍受限于 2。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究如何利用在线预测（一种流行的学习增强算法框架）来提高在线旅行商问题（OLTSP）和在线叫车问题（OLDARP）的竞争比。

Method: 本文提出了一种基于在线预测的等待策略，并提出了一种基于在线调度的算法。

Result: 所提出的算法可以实现 1.1514 * lambda + 1.5 的一致性和 1.5 + 1.5 / (2.3028 * lambda - 1) 的鲁棒性，其中 lambda 属于区间 (1/theta, 1]，theta 约为 2.3028。

Conclusion: 我们表明，即使有完美的在线预测，任何基于在线调度的算法也不能获得小于 2 的竞争比。

Abstract: We revisit the well-known online traveling salesman problem (OLTSP) and its
extension, the online dial-a-ride problem (OLDARP). A server starting at a
designated origin in a metric space, is required to serve online requests, and
return to the origin such that the completion time is minimized. The SmartStart
algorithm, introduced by Ascheuer et al., incorporates a waiting approach into
an online schedule-based algorithm and attains the optimal upper bound of 2 for
the OLTSP and the OLDARP if each schedule is optimal. Using the Christofides'
heuristic to approximate each schedule leads to the currently best upper bound
of (7 + sqrt(13)) / 4 approximately 2.6514 in polynomial time.
  In this study, we investigate how an online algorithm with predictions, a
recent popular framework (i.e. the so-called learning-augmented algorithms),
can be used to improve the best competitive ratio in polynomial time. In
particular, we develop a waiting strategy with online predictions, each of
which is only a binary decision-making for every schedule in a whole route,
rather than forecasting an entire set of requests in the beginning (i.e.
offline predictions). That is, it does not require knowing the number of
requests in advance. The proposed online schedule-based algorithm can achieve
1.1514 * lambda + 1.5-consistency and 1.5 + 1.5 / (2.3028 * lambda -
1)-robustness in polynomial time, where lambda lies in the interval (1/theta,
1] and theta is set to (1 + sqrt(13)) / 2 approximately 2.3028. The best
consistency tends to approach to 2 when lambda is close to 1/theta. Meanwhile,
we show any online schedule-based algorithms cannot derive a competitive ratio
of less than 2 even with perfect online predictions.

</details>


### [332] [Cut-Matching Games for Bipartiteness Ratio of Undirected Graphs](https://arxiv.org/abs/2507.12847)
*Tasuku Soma,Mingquan Ye,Yuichi Yoshida*

Main category: cs.DS

TL;DR: 本文提出了一种用于求解无向图二分性比率的近似算法，该算法利用了割匹配博弈框架，并达到了 $O(\\\log n)$ 的近似比。算法的运行时间接近线性，并且引入了良好连接性等新概念。


<details>
  <summary>Details</summary>
Motivation: 本文研究了无向图中二分性比率的近似算法，并将其与稀疏切割问题联系起来。

Method: 我们提出了一种用于无向图二分性比率的 $O(\\\log n)$-近似算法。我们的算法只需要进行多项式对数数量的单商品无向最大流计算。因此，利用目前最快的无向最大流算法，其运行时间接近线性。

Result: 我们提出了一种用于无向图二分性比率的 $O(\\\log n)$-近似算法。该算法的运行时间接近线性。此外，我们还设计了一种$	ilde{O}(mn)$时间算法，用于找到一个删除 $1 - O(\\\log n \\\log(1/\\\eta)) \\\cdot \\\eta$ 边比例的割。

Conclusion: 我们的算法将用于求解稀疏切割的割匹配博弈框架扩展到了二分性比率。此外，我们为斜对称图引入了良好连接性的概念，并证明了二分性比率与辅助斜对称图中良好连接性的新型特征，这可能具有独立意义。作为应用，我们设计了一种$	ilde{O}(mn)$时间算法，给定一个最大割删除1-η边比例的图，找到一个删除1 - O(
 log(1/η)) · η边比例的割。

Abstract: We propose an $O(\log n)$-approximation algorithm for the bipartiteness ratio
for undirected graphs introduced by Trevisan (SIAM Journal on Computing, vol.
41, no. 6, 2012), where $n$ is the number of vertices. Our approach extends the
cut-matching game framework for sparsest cut to the bipartiteness ratio. Our
algorithm requires only $\mathrm{poly}\log n$ many single-commodity undirected
maximum flow computations. Therefore, with the current fastest undirected
max-flow algorithms, it runs in nearly linear time. Along the way, we introduce
the concept of well-linkedness for skew-symmetric graphs and prove a novel
characterization of bipartitness ratio in terms of well-linkedness in an
auxiliary skew-symmetric graph, which may be of independent interest.
  As an application, we devise an $\tilde{O}(mn)$-time algorithm that given a
graph whose maximum cut deletes a $1-\eta$ fraction of edges, finds a cut that
deletes a $1 - O(\log n \log(1/\eta)) \cdot \eta$ fraction of edges, where $m$
is the number of edges.

</details>


### [333] [A 1/2-Approximation for Budgeted $k$-Submodular Maximization](https://arxiv.org/abs/2507.12875)
*Chenhao Wang*

Main category: cs.DS

TL;DR: k-子模最大化在背包约束下的近似比问题已解决。1-Guess Greedy算法在单调问题中达到1/2近似比（渐近最优），在非单调问题中达到1/3近似比。该方法还为更广泛的约束条件提供了统一的分析框架。


<details>
  <summary>Details</summary>
Motivation: k-子模函数是子模函数的一种推广，在最大化问题中除了选择元素外，还需要确定元素所属的子集。尽管在基数或拟阵约束下贪婪算法有1/2近似比，但在背包约束下的近似比问题一直悬而未决。本研究旨在解决这个问题。

Method: 该研究通过一种新颖的连续变换方法，将最优解转化为贪婪解，并利用多线性扩展评估每种分数解。这种连续分析方法不仅改进了现有算法的近似比，还将其自然地扩展到更广泛的约束条件下的k-子模最大化问题，提供了一个更灵活和统一的分析框架。

Result: 1-Guess Greedy算法在单调k-子模最大化背包问题中实现了1/2的近似比，该结果是渐近最优的。对于非单调问题，该算法的近似比为1/3。该方法还可用于改进现有算法的近似比，并扩展到更广泛的约束条件。

Conclusion: 该研究解决了k-子模最大化在背包约束下的近似比问题，证明了1-Guess Greedy算法可以达到1/2的近似比，并且对于非单调问题可以达到1/3的近似比。该算法简单、可并行化，并且通过阈值技术可以在近乎O(n^2k^2)的时间内运行。

Abstract: A $k$-submodular function naturally generalizes submodular functions by
taking as input $k$ disjoint subsets, rather than a single subset. Unlike
standard submodular maximization, which only requires selecting elements for
the solution, $k$-submodular maximization adds the challenge of determining the
subset to which each selected element belongs. Prior research has shown that
the greedy algorithm is a 1/2-approximation for the monotone $k$-submodular
maximization problem under cardinality or matroid constraints. However, whether
a firm 1/2-approximation exists for the budgeted version (i.e., with a knapsack
constraint) has remained open for several years. We resolve this question
affirmatively by proving that the 1-Guess Greedy algorithm, which first guesses
an appropriate element from an optimal solution before proceeding with the
greedy algorithm, achieves a 1/2-approximation. This result is asymptotically
tight as $((k+1)/(2k)+\epsilon)$-approximation requires exponentially many
value oracle queries even without constraints (Iwata et al., SODA 2016). We
further show that 1-Guess Greedy is 1/3-approximation for the non-monotone
problem. This algorithm is both simple and parallelizable, making it
well-suited for practical applications. Using the thresholding technique from
(Badanidiyuru and Vondrak, SODA 2014), it runs in nearly $\tilde O(n^2k^2)$
time.
  The proof idea is simple: we introduce a novel continuous transformation from
an optimal solution to a greedy solution, using the multilinear extension to
evaluate every fractional solution during the transformation. This continuous
analysis approach yields two key extensions. First, it enables improved
approximation ratios of various existing algorithms. Second, our method
naturally extends to $k$-submodular maximization problems under broader
constraints, offering a more flexible and unified analysis framework.

</details>


### [334] [Efficient Semi-External Breadth-First Search](https://arxiv.org/abs/2507.12925)
*Xiaolong Wan,Xixian Han*

Main category: cs.DS

TL;DR: 本研究提出了一种名为 EP-BFS 的高效算法，用于在半外部内存模型中处理大规模图的广度优先搜索（BFS），实现了高达 10 倍的加速。


<details>
  <summary>Details</summary>
Motivation: 随着图数据库规模的急剧增大，图通常是驻留在磁盘上的。在半外部内存模型中获得大图的 BFS 结果是不可避免的，因为内存 BFS 算法需要将整个图保存在主内存中，而外部 BFS 算法的计算成本很高。半外部内存模型是介于内部和外部内存模型之间的一个好的折衷方案，它假设主内存至少可以容纳图的生成树。然而，由于其难度，半外部 BFS 问题仍然是一个悬而未决的问题。

Method: 提出了一种名为 EP-BFS 的高效算法，该算法在半外部内存模型中处理图的广度优先搜索，并讨论了基于半外部图算法基本框架的朴素解决方案。

Result: EP-BFS 算法具有最小的内存空间要求，并在真实和合成的大规模图（包括包含超过 17 亿个节点的大图 WDC-2014 和包含超过 910 亿条边的图 eu-2015）上进行了广泛的实验。实验结果证实，EP-BFS 的速度比其他方法快 10 倍。

Conclusion: 该研究提出了一个名为 EP-BFS 的高效算法，用于在半外部内存模型中处理广度优先搜索（BFS），并在大规模图上实现了高达 10 倍的加速。

Abstract: Breadth-first search (BFS) is known as a basic search strategy for learning
graph properties. As the scales of graph databases have increased tremendously
in recent years, large-scale graphs G are often disk-resident. Obtaining the
BFS results of G in semi-external memory model is inevitable, because the
in-memory BFS algorithm has to maintain the entire G in the main memory, and
external BFS algorithms consume high computational costs. As a good trade-off
between the internal and external memory models, semi-external memory model
assumes that the main memory can at least reside a spanning tree of G.
Nevertheless, the semi-external BFS problem is still an open issue due to its
difficulty. Therefore, this paper presents a comprehensive study for processing
BFS in semi-external memory model. After discussing the naive solutions based
on the basic framework of semi-external graph algorithms, this paper presents
an efficient algorithm, named EP-BFS, with a small minimum memory space
requirement, which is an important factor for evaluating semi-external
algorithms. Extensive experiments are conducted on both real and synthetic
large-scale graphs, where graph WDC-2014 contains over 1.7 billion nodes, and
graph eu-2015 has over 91 billion edges. Experimental results confirm that
EP-BFS can achieve up to 10 times faster.

</details>


### [335] [The Price of Diversity of the Traveling Salesman Problem](https://arxiv.org/abs/2507.13026)
*Mark de Berg,Andrés López Martínez,Frits Spieksma*

Main category: cs.DS

TL;DR: 本文提出了“价格多样性”（PoD）概念，用于衡量离散优化问题中解决方案多样性与成本之间的权衡。研究表明，在旅行商问题（TSP）中，寻找两条边不相交路径的 PoD 在一维情况下渐近为 8/5，在一般度量空间中为 2。


<details>
  <summary>Details</summary>
Motivation: 本文旨在量化离散优化问题中解决方案多样性与成本之间的权衡，并提出“价格多样性”（PoD）的概念。

Method: 本文通过分析最短哈密顿路径问题（SHP）来研究旅行商问题（TSP）中的价格多样性（PoD）。论文推导出了在特定条件下 PoD 的渐近值。

Result: 在寻找两条边不相交路径时，在一种特殊的一维情况下，PoD 渐近为 8/5，在一般度量空间中为 2。

Conclusion: 该论文研究了离散优化问题中的“价格多样性”（PoD），量化了解决方案多样性与成本之间的权衡。对于最小化问题，PoD 定义为所有实例上，可实现的 k 个不同解决方案集的最优成本与同一实例的单个最优解决方案成本之间的最坏情况比率。其中，k 解决方案集的成本由集中最昂贵的解决方案确定。论文以旅行商问题（TSP）为关键示例，研究了在需要 k 条边不相交路径的设置下的 PoD。论文表明，在寻找两条边不相交路径时，在一种特殊的一维情况下，PoD 渐近为 8/5，在一般度量空间中为 2。这些结果是通过分析一个相关的基本问题——最短哈密顿路径问题（SHP）得出的，并取得了类似的结果。

Abstract: This paper introduces the concept of the "Price of Diversity" (PoD) in
discrete optimization problems, quantifying the trade-off between solution
diversity and cost. For a minimization problem, the PoD is defined as the
worst-case ratio, over all instances, of the minimum achievable cost of a
diverse set of $k$ solutions to the cost of a single optimal solution for the
same instance. Here, the cost of a $k$-solution set is determined by the most
expensive solution within the set. Focusing on the Traveling Salesman Problem
(TSP) as a key example, we study the PoD in the setting where $k$ edge-disjoint
tours are required. We establish that, asymptotically, the PoD of finding two
edge-disjoint tours is $\frac{8}{5}$ in a special one-dimensional case and 2 in
a general metric space. We obtain these results from analyzing a related
fundamental problem: the Shortest Hamiltonian Path problem (SHP), for which we
establish similar results.

</details>


### [336] [Maintaining Routing Structures under Deletions via Self-Pruning](https://arxiv.org/abs/2507.13044)
*Bernhard Haeupler,Antti Roeyskoe*

Main category: cs.DS

TL;DR: 本文提出了一种能在线处理边删除并保持路由性能的扩展器图族，通过自剪枝算法在最坏情况下仅需少量额外删除，并能控制路由路径长度。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决维护单位多商品流需求路由的问题，同时应对剪枝步骤（顶点删除）。现有的扩展器在路由和剪枝方面各有优势，但将两者结合并在线处理是一个挑战。因此，本文提出了一种能够在线处理边删除并保持易于路由的扩展器特性的方法。

Method: 本文介绍了易于路由和自剪枝的扩展器图族，并提出了一种简单的自包含算法来处理在线边删除，以维护易于路由的扩展器。研究的关键在于实现了最坏情况下的自剪枝，即每次删除仅导致少量额外删除，并能对路由路径长度进行常数因子控制。

Result: 本文成功引入了一种易于路由且能自剪枝的扩展器图族。该图族能够通过简单的自包含算法，在面对一系列在线边删除时，维护一个易于路由的扩展器。研究表明，这种自剪枝可以实现最坏情况下的性能，即每次边删除仅导致少量额外的删除。此外，该方法还能对路由路径长度进行严格的常数因子控制，并适用于常数跳和长度受限的扩展器。

Conclusion: 本文提出了一种易于路由且能自剪枝的扩展器图族，能够在线处理一系列边删除，并通过简单的自包含算法维护一个易于路由的扩展器。研究表明，这种自剪枝可以在最坏情况下实现，即每次边删除仅导致少量额外的删除。此外，该研究还实现了对路由路径长度的严格常数因子控制，并扩展到常数跳和长度受限的扩展器。

Abstract: Expanders are powerful algorithmic structures with two key properties: they
are
  a) routable: for any multi-commodity flow unit demand, there exists a routing
with low congestion over short paths, where a demand is unit if the amount of
demand sent / received by any vertex is at most the number of edges adjacent to
it.
  b) stable / prunable: for any (sequence of) edge failures, there exists a
proportionally small subset of vertices that can be disabled, such that the
graph induced on the remaining vertices is an expander.
  Two natural algorithmic problems correspond to these two existential
guarantees: expander routing, i.e. computing a low-congestion routing for a
unit multi-commodity demand on an expander, and expander pruning, i.e.,
maintaining the subset of disabled vertices under a sequence of edge failures.
  This paper considers the combination of the two problems: maintaining a
routing for a unit multi-commodity demand under pruning steps. This is done
through the introduction of a family of expander graphs that, like hypercubes,
are easy to route in, and are self-pruning: for an online sequence of edge
deletions, a simple self-contained algorithm can find a few vertices to prune
with each edge deletion, such that the remaining graph always remains an
easy-to-route-in expander in the family.
  Notably, and with considerable technical work, this self-pruning can be made
worst-case, i.e., such that every single adversarial deletion only causes a
small number of additional deletions. Our results also allow tight
constant-factor control over the length of routing paths (with the usual
trade-offs in congestion and pruning ratio) and therefore extend to
constant-hop and length-constrained expanders in which routing over constant
length paths is crucial.

</details>


### [337] [Kernelization for $H$-Coloring](https://arxiv.org/abs/2507.13129)
*Yael Berkman,Ishay Haviv*

Main category: cs.DS

TL;DR: 本文改进了H-着色问题按顶点覆盖数参数化的核大小界限，通过组合和线性代数方法分别给出更优的上界，并辅以条件计算下界，基本解决了部分H的核复杂度问题。


<details>
  <summary>Details</summary>
Motivation: Hell和Ne	ext{š}et	ext{ř}il证明了当H无环且非二分图时，H-着色问题是NP难的。Jansen和Pieterse的结果表明，对于任意图H，H-着色问题按顶点覆盖数k参数化时，存在一个核，其顶点数为O(k^Δ(H))，比特大小为O(k^Δ(H)·log k)。当H是至少有三个顶点的完全图时，该核大小接近Jansen和Kratsch以及Jansen和Pieterse建立的条件下界。本文旨在改进这些结果，为H-着色问题按顶点覆盖数参数化时的核大小提供更精确的上下界。

Method: 本文提出了两种核化算法：一种是纯组合方法，其核大小受图H的非邻接见证数控制；另一种是利用线性代数工具，涉及图的忠实独立表示。此外，论文还给出了条件下界来支撑其结果。

Result: 该论文为H-着色问题按顶点覆盖数参数化时的核大小提供了新的上界和下界。组合方法给出核大小的界与H的非邻接见证数有关，可对最大度无界的图类给出固定多项式界，并且对于几乎所有H，核大小的界是关于Δ(H)的对数增长。线性代数方法提供的界比先前工作更强，能为正交图表示维度问题等提供近优核。条件计算结果则接近解决了多种目标图H的核复杂度。

Conclusion: 该论文通过组合和线性代数方法，对H-着色问题按顶点覆盖数参数化时的核大小给出了新的上下界。组合方法得到的核大小与H的非邻接见证数有关，对最大度无界的图类给出了固定多项式界，且核大小关于最大度的多项式增长率对几乎所有H是仅对数增长的。线性代数方法进一步提高了通用界的性能，并为正交图表示维度问题提供了近乎最优的核。论文最后通过条件下界，基本解决了多种目标图H的核复杂度问题。

Abstract: For a fixed graph $H$, the $H$-Coloring problem asks whether a given graph
admits an edge-preserving function from its vertex set to that of $H$. A
seminal theorem of Hell and Ne\v{s}et\v{r}il asserts that the $H$-Coloring
problem is NP-hard whenever $H$ is loopless and non-bipartite. A result of
Jansen and Pieterse implies that for every graph $H$, the $H$-Coloring problem
parameterized by the vertex cover number $k$ admits a kernel with
$O(k^{\Delta(H)})$ vertices and bit-size bounded by $O(k^{\Delta(H)} \cdot \log
k)$, where $\Delta(H)$ denotes the maximum degree in $H$. For the case where
$H$ is a complete graph on at least three vertices, this kernel size nearly
matches conditional lower bounds established by Jansen and Kratsch and by
Jansen and Pieterse.
  This paper presents new upper and lower bounds on the kernel size of
$H$-Coloring problems parameterized by the vertex cover number. The upper
bounds arise from two kernelization algorithms. The first is purely
combinatorial, and its size is governed by a structural quantity of the graph
$H$, called the non-adjacency witness number. As applications, we obtain
kernels whose size is bounded by a fixed polynomial for natural classes of
graphs $H$ with unbounded maximum degree. More strikingly, we show that for
almost every graph $H$, the degree of the polynomial that bounds the size of
our combinatorial kernel grows only logarithmically in $\Delta(H)$. Our second
kernel leverages linear-algebraic tools and involves the notion of faithful
independent representations of graphs. It strengthens the general bound from
prior work and, among other applications, yields near-optimal kernels for
problems concerning the dimension of orthogonal graph representations over
finite fields. We complement these results with conditional lower bounds,
thereby nearly settling the kernel complexity of the problem for various target
graphs $H$.

</details>


### [338] [Online Rounding for Set Cover under Subset Arrivals](https://arxiv.org/abs/2507.13159)
*Jarosław Byrka,Yongho Shin*

Main category: cs.DS

TL;DR: 本文改进了集合覆盖问题的舍入方案，在子集到达模型下达到了 O(log^2 s) 的竞争性，并为边覆盖问题提出了 1.8-竞争性方案。


<details>
  <summary>Details</summary>
Motivation: 现有的子集到达模型下的舍入方案竞争性较差（O(log n)），而本文提出的方案在 s 可知的情况下，将竞争性提高到 O(log^2 s)。

Method: 本文提出了一种新的舍入方案。

Result: 本文提出了一种 O(log^2 s)-竞争性舍入方案，并可用于多阶段随机集合覆盖问题，在 s 较小时优于现有算法。此外，还为边覆盖问题提出了一个 1.8-竞争性舍入方案。

Conclusion: 本文提出了一种适用于子集到达模型的 O(log^2 s)-竞争性舍入方案，并对 s=2 的情况（即边覆盖问题）提出了一个 1.8-竞争性的舍入方案。

Abstract: A rounding scheme for set cover has served as an important component in
design of approximation algorithms for the problem, and there exists an
H_s-approximate rounding scheme, where s denotes the maximum subset size,
directly implying an approximation algorithm with the same approximation
guarantee. A rounding scheme has also been considered under some online models,
and in particular, under the element arrival model used as a crucial subroutine
in algorithms for online set cover, an O(log s)-competitive rounding scheme is
known [Buchbinder, Chen, and Naor, SODA 2014]. On the other hand, under a more
general model, called the subset arrival model, only a simple O(log
n)-competitive rounding scheme is known, where n denotes the number of elements
in the ground set.
  In this paper, we present an O(log^2 s)-competitive rounding scheme under the
subset arrival model, with one mild assumption that s is known upfront. Using
our rounding scheme, we immediately obtain an O(log^2 s)-approximation
algorithm for multi-stage stochastic set cover, improving upon the existing
algorithms [Swamy and Shmoys, SICOMP 2012; Byrka and Srinivasan, SIDMA 2018]
when s is small enough compared to the number of stages and the number of
elements. Lastly, for set cover with s = 2, also known as edge cover, we
present a 1.8-competitive rounding scheme under the edge arrival model.

</details>


### [339] [Efficiently Constructing Sparse Navigable Graphs](https://arxiv.org/abs/2507.13296)
*Alex Conway,Laxman Dhulipala,Martin Farach-Colton,Rob Johnson,Ben Landrum,Christopher Musco,Yarin Shechter,Torsten Suel,Richard Wen*

Main category: cs.DS

TL;DR: 该研究提出了一种新的、高效的图搜索算法，该算法在对数因子内是最优的，并且可以处理其他相关的图搜索问题。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于解决图中为基础的最近邻搜索方法中，搜索图构建的计算成本高昂的问题。现有的方法普遍使用启发式方法，但缺乏可证明的保证。因此，该研究旨在开发具有可证明保证的快速算法，用于构建搜索图。

Method: 该研究提出了一种新的方法，利用流式处理和亚线性时间集合覆盖算法技术来解决搜索图构建问题。通过结合特定于问题的预处理技术，该研究提出了一种 O(n^2) 时间的算法，用于构建 O(log n) 近似的、最稀疏的可导航图。该方法利用了集合覆盖实例之间的相关性，并利用了流式处理和亚线性时间集合覆盖算法的技术。

Result: 该研究提出了一种 O(n^2) 时间的算法，用于构建 O(log n) 近似的、最稀疏的可导航图。该算法在对数因子内是最佳的，并且证明了比 O(log n) 更好的近似是 NP-hard 的。此外，该研究还为构建 α-shortcut 可达和 τ-monotonic 图提供了 O(n^2.5) 或更优的时间算法。

Conclusion: 该研究为搜索图构建提供了新的高效算法，其运行时间在对数因子内是最佳的，并且证明了在可导航图问题中获得比 O(log n) 更好的近似是 NP-hard 的。此外，该方法还能改进其他相关邻近搜索问题。

Abstract: Graph-based nearest neighbor search methods have seen a surge of popularity
in recent years, offering state-of-the-art performance across a wide variety of
applications. Central to these methods is the task of constructing a sparse
navigable search graph for a given dataset endowed with a distance function.
Unfortunately, doing so is computationally expensive, so heuristics are
universally used in practice.
  In this work, we initiate the study of fast algorithms with provable
guarantees for search graph construction. For a dataset with $n$ data points,
the problem of constructing an optimally sparse navigable graph can be framed
as $n$ separate but highly correlated minimum set cover instances. This yields
a naive $O(n^3)$ time greedy algorithm that returns a navigable graph whose
sparsity is at most $O(\log n)$ higher than optimal. We improve significantly
on this baseline, taking advantage of correlation between the set cover
instances to leverage techniques from streaming and sublinear-time set cover
algorithms. Combined with problem-specific pre-processing techniques, we
present an $\tilde{O}(n^2)$ time algorithm for constructing an $O(\log
n)$-approximate sparsest navigable graph under any distance function.
  The runtime of our method is optimal up to logarithmic factors under the
Strong Exponential Time Hypothesis via a reduction from Monochromatic Closest
Pair. Moreover, we prove that, as with general set cover, obtaining better than
an $O(\log n)$-approximation is NP-hard, despite the significant additional
structure present in the navigable graph problem. Finally, we show that our
techniques can also beat cubic time for the closely related and practically
important problems of constructing $\alpha$-shortcut reachable and
$\tau$-monotonic graphs, which are also used for nearest neighbor search. For
such graphs, we obtain $\tilde{O}(n^{2.5})$ time or better algorithms.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [340] [Adversarial attacks to image classification systems using evolutionary algorithms](https://arxiv.org/abs/2507.13136)
*Sergio Nesmachnow,Jamal Toutouh*

Main category: cs.NE

TL;DR: 图像分类面临着对抗性攻击的重大安全挑战。本文提出了一种结合进化算法和生成对抗网络（GAN）来生成对抗性攻击的方法。该方法通过在 GAN 的潜在空间中搜索来寻找对抗性攻击向量。实验结果表明，该方法在手写数字和对象图像分类任务上均优于现有方法，成功率分别达到 35% 和 75%。该方法还能有效处理数据多样性，即使在信息复杂且丰富的数据集上也能取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 图像分类面临着由旨在欺骗人工智能分类模型的故意篡改引起的重大安全挑战，即对抗性攻击。

Method: 使用结合了进化算法和生成对抗网络的生成对抗网络（GAN）的潜在空间来寻找代表对抗性攻击的向量。

Result: 在手写数字图像分类的案例研究中，成功率高达 35%，在对象图像分类的案例研究中，成功率高达 75%，优于其他搜索方法和相关工作中已报道的结果。

Conclusion: 该方法在处理目标数据集的数据多样性方面被证明是有效的，即使在那些由于信息的复杂性和丰富性而带来额外挑战的问题实例中也是如此。

Abstract: Image classification currently faces significant security challenges due to
adversarial attacks, which consist of intentional alterations designed to
deceive classification models based on artificial intelligence. This article
explores an approach to generate adversarial attacks against image classifiers
using a combination of evolutionary algorithms and generative adversarial
networks. The proposed approach explores the latent space of a generative
adversarial network with an evolutionary algorithm to find vectors representing
adversarial attacks. The approach was evaluated in two case studies
corresponding to the classification of handwritten digits and object images.
The results showed success rates of up to 35% for handwritten digits, and up to
75% for object images, improving over other search methods and reported results
in related works. The applied method proved to be effective in handling data
diversity on the target datasets, even in problem instances that presented
additional challenges due to the complexity and richness of information.

</details>


### [341] [Multi-population GAN Training: Analyzing Co-Evolutionary Algorithms](https://arxiv.org/abs/2507.13157)
*Walter P. Casas,Jamal Toutouh*

Main category: cs.NE

TL;DR: This paper analyzes co-evolutionary GAN training strategies, finding that (mu,lambda) replacement outperforms other methods in sample quality and diversity, especially with larger offspring sizes, while elitist approaches converge prematurely and reduce diversity. The findings guide the design of more effective population-based generative models.


<details>
  <summary>Details</summary>
Motivation: Generative adversarial networks (GANs) are powerful generative models but remain challenging to train due to pathologies such as mode collapse and instability. Recent research has explored co-evolutionary approaches, in which populations of generators and discriminators are evolved, as a promising solution.

Method: This paper presents an empirical analysis of different co-evolutionary GAN training strategies, focusing on the impact of selection and replacement mechanisms. We compare (mu,lambda), (mu+lambda) with elitism, and (mu+lambda) with tournament selection coevolutionary schemes, along with a non-evolutionary population based multi-generator multi-discriminator GAN baseline, across both synthetic low-dimensional datasets (blob and gaussian mixtures) and an image-based benchmark (MNIST).

Result: Results show that full generational replacement, i.e., (mu,lambda), consistently outperforms in terms of both sample quality and diversity, particularly when combined with larger offspring sizes. In contrast, elitist approaches tend to converge prematurely and suffer from reduced diversity.

Conclusion: Generative adversarial networks (GANs) are powerful generative models but remain challenging to train due to pathologies such as mode collapse and instability. Recent research has explored co-evolutionary approaches, in which populations of generators and discriminators are evolved, as a promising solution. This paper presents an empirical analysis of different co-evolutionary GAN training strategies, focusing on the impact of selection and replacement mechanisms. We compare (mu,lambda), (mu+lambda) with elitism, and (mu+lambda) with tournament selection coevolutionary schemes, along with a non-evolutionary population based multi-generator multi-discriminator GAN baseline, across both synthetic low-dimensional datasets (blob and gaussian mixtures) and an image-based benchmark (MNIST). Results show that full generational replacement, i.e., (mu,lambda), consistently outperforms in terms of both sample quality and diversity, particularly when combined with larger offspring sizes. In contrast, elitist approaches tend to converge prematurely and suffer from reduced diversity. These findings highlight the importance of balancing exploration and exploitation dynamics in coevolutionary GAN training and provide guidance for designing more effective population-based generative models.

Abstract: Generative adversarial networks (GANs) are powerful generative models but
remain challenging to train due to pathologies suchas mode collapse and
instability. Recent research has explored co-evolutionary approaches, in which
populations of generators and discriminators are evolved, as a promising
solution. This paper presents an empirical analysis of different coevolutionary
GAN training strategies, focusing on the impact of selection and replacement
mechanisms. We compare (mu,lambda), (mu+lambda) with elitism, and (mu+lambda)
with tournament selection coevolutionary schemes, along with a non-evolutionary
population based multi-generator multi-discriminator GAN baseline, across both
synthetic low-dimensional datasets (blob and gaussian mixtures) and an
image-based benchmark (MNIST). Results show that full generational replacement,
i.e., (mu,lambda), consistently outperforms in terms of both sample quality and
diversity, particularly when combined with larger offspring sizes. In contrast,
elitist approaches tend to converge prematurely and suffer from reduced
diversity. These findings highlight the importance of balancing exploration and
exploitation dynamics in coevolutionary GAN training and provide guidance for
designing more effective population-based generative models.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [342] [On multiagent online problems with predictions](https://arxiv.org/abs/2507.12486)
*Gabriel Istrate,Cosmin Bonchis,Victor Bogdan*

Main category: cs.MA

TL;DR: 在多智能体设置中，我们研究了使用预测的竞争性算法，并提出了一个两预测器框架，一个用于自我预测，一个用于预测其他玩家。我们分析了在不同预测器质量假设下的竞争比，并以多人滑雪租赁问题为例进行了说明。我们发现，在其他预测完美的情况下，虽然遵循自我预测器的算法是最优的，但对自我行为的错误预测不够健壮。我们提出了一种更具鲁棒性的算法并进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 我们研究了在多智能体环境中，使用预测的（竞争性）算法的能力。

Method: 我们引入了一个两预测器框架，该框架假设代理使用一个预测器来预测其未来的（自我）行为，并使用另一个预测器来预测其他玩家的行为。

Result: 我们关注的主要问题是，在对预测器质量的各种假设下，使用此类预测器可以实现的最佳竞争比。

Conclusion: 在其他预测完美的情况下，遵循自我预测器的算法是最优的，但对代理未来行为的错误预测不够健壮；我们提供了一种具有更好鲁棒性特性的算法并对其进行基准测试。

Abstract: We study the power of (competitive) algorithms with predictions in a
multiagent setting. We introduce a two predictor framework, that assumes that
agents use one predictor for their future (self) behavior, and one for the
behavior of the other players. The main problem we are concerned with is
understanding what are the best competitive ratios that can be achieved by
employing such predictors, under various assumptions on predictor quality.
  As an illustration of our framework, we introduce and analyze a multiagent
version of the ski-rental problem. In this problem agents can collaborate by
pooling resources to get a group license for some asset. If the license price
is not met then agents have to rent the asset individually for the day at a
unit price. Otherwise the license becomes available forever to everyone at no
extra cost.
  In the particular case of perfect other predictions the algorithm that
follows the self predictor is optimal but not robust to mispredictions of
agent's future behavior; we give an algorithm with better robustness properties
and benchmark it.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [343] [Kinetics of Vacancy-Assisted Reversible Phase Transition in Monolayer MoTe$_2$](https://arxiv.org/abs/2507.12565)
*Fei Shuang,Daniel Ocampo,Reza Namakian,Arman Ghasemi,Poulumi Dey,Wei Gao*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用机器学习势和动力学理论，揭示了单层MoTe$_{2}$中2H相和1T'相之间的相变机制，包括空位迁移、成核生长以及无扩散的可逆转变。


<details>
  <summary>Details</summary>
Motivation: 研究单层MoTe$_{2}$中2H相和1T'相之间的动力学相变。

Method: 使用基于机器学习的原子间势（在SCAN-DFT数据上训练）进行原子模拟，并结合平均场动力学理论来解释潜在的机制。

Result: 相变同时涉及扩散和非扩散机制。1T'相的成核由相邻Te单空位的聚结成双空位引发，这些双空位是可移动的，并能与其他Te空位相互作用形成小的三角形1T'岛。岛的生长通过吸收相界处的预先存在的空位或迁移的双空位进行。达到临界尺寸后，可能发生无空位的生长。系统在移除外部刺激后恢复到2H相，Te空位在岛中心重组成分叉的空位线。这种逆过程和随后的1T'↔2H可逆转变是无扩散的、快速的，并且可以由温和的外部刺激驱动。

Conclusion: 1T'相的成核由相邻的Te单空位聚结成双空位引发，双空位是可移动的，并能与其他Te空位相互作用形成小的三角形1T'岛。一旦达到临界尺寸，即使有更高的激活能垒，也可能通过吸收周围晶格中迁移的双空位进行无空位的生长。移除外部刺激后，系统恢复到2H相，Te空位在岛中心重组成分叉的空位线。这种逆过程和随后的1T'↔2H可逆转变是无扩散的、快速的，不需要额外的空位，并且可以由温和的外部刺激驱动。

Abstract: We investigate the kinetics of phase transition between the 2H and
1T$^\prime$ phases in monolayer MoTe$_2$ using atomistic simulations based on a
machine learning interatomic potential trained on SCAN-DFT data, combined with
mean field kinetic theory to interpret the underlying mechanisms. The
transition is found to involve both diffusive and diffusionless mechanisms.
Nucleation of 1T$^\prime$ phase is initiated by the coalescence of neighboring
Te monovacancies into divacancies, which are found to be mobile and can
interact with other Te vacancies to form small triangular 1T$^\prime$ islands.
Growth of these islands proceeds either by incorporating pre-existing vacancies
at the phase boundaries or, in their absence, by absorbing divacancies that
migrate from the surrounding lattice. Once a critical island size is reached,
vacancy-free growth becomes possible although with a higher activation barrier.
Upon removal of external stimuli, the system reverts to 2H phase, during which
Te vacancies reorganize into three-fold spoke-like vacancy lines at the island
center. This reverse process and the subsequent 1T$^\prime$$\leftrightarrow$2H
reversible transitions are diffusionless, rapid, do not require additional
vacancies and can be driven by mild external stimuli. Although our analysis
focuses on strain-induced transitions, the kinetic mechanisms are expected to
be generalizable to other types of stimuli.

</details>


### [344] [Suppression of Thermal Conductivity via Singlet-Dominated Scattering in TmFeO$_3$](https://arxiv.org/abs/2507.12608)
*M. L. McLanahan,D. Lederman,A. P. Ramirez*

Main category: cond-mat.mtrl-sci

TL;DR: Thermal conductivity in TmFeO$_{3}$ is strongly suppressed due to phonon and Tm$^{3+}$ ion interactions, as analyzed by the Debye thermal transport model.


<details>
  <summary>Details</summary>
Motivation: To understand the thermal conductivity of rare-earth orthoferrites and investigate the anomalous strong suppression observed in TmFeO$_{3}$.

Method: Using a Debye thermal transport model, we analyzed the thermal conductivity of rare-earth orthoferrites ($R$FeO$_{3}$, where $R$ = Eu, Gd, Tb, Dy, Ho, Er, Tm, and Yb).

Result: An anomalous strong suppression of thermal conductivity was observed for TmFeO$_{3}$, which was attributed to resonant scattering between phonons and the Tm$^{3+}$ $4f$ singlet crystal field levels.

Conclusion: We demonstrated that the anomalous strong suppression of thermal conductivity in TmFeO$_{3}$ is due to resonant scattering between phonons and the Tm$^{3+}$ $4f$ singlet crystal field levels.

Abstract: We measured the thermal conductivity of the rare-earth orthoferrites,
$R$FeO$_3$, where $R$ = Eu, Gd, Tb, Dy, Ho, Er, Tm, and Yb and see an anomalous
strong suppression for TmFeO$_3$. Using a Debye thermal transport model, we
demonstrate that this suppression is due to resonant scattering between phonons
and the Tm$^{3+}$ $4f$ singlet crystal field levels. The implications of these
results are discussed in context of thermal conductivity studies in quantum
magnets.

</details>


### [345] [Low-energy domain wall racetracks with multiferroic topologies](https://arxiv.org/abs/2507.12633)
*Arundhati Ghosal,Alexander Qualls,Yousra Nahas,Shashank Ojha,Peter Meisenheimer,Shiyu Zhou,Maya Ramesh,Sajid Husain,Julia Mundy,Darrell Schlom,Zhi Yao,Sergei Prokhorenko,Laurent Bellaiche,Ramamoorthy Ramesh,Paul Stevenson,Lucas Caretta*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种电压控制的磁电奔跑赛道，利用电场移动畴壁，实现了高速、低功耗和良好的纳米级扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统奔跑赛道内存中由电流驱动导致的焦耳热和扩展性问题，本文提出了一种新的磁电奔跑赛道。

Method: 利用横向电场在 BiFeO3 纳米带中移动耦合的铁电-反铁磁畴壁，实现了电压控制的磁电奔跑赛道。

Result: 实现了每秒数公里的畴壁速度，同时保持了数十微米的畴壁拓扑稳定性，实现了纳秒级访问时间，且能量消耗低，具有良好的纳米级扩展性。

Conclusion: 本文提出了一种电压控制的磁电奔跑赛道，利用横向电场在室温下沿 BiFeO3 纳米带移动耦合的铁电-反铁磁畴壁。由于没有电荷流过赛道，其能量消耗比最高效的自旋扭矩器件低几个数量级，具有更好的纳米级扩展性。研究还发现了 BiFeO3 畴壁中出现的非共线拓扑磁电纹理，以及之前未被观察到的拓扑磁畴壁扭转纹理。在奔跑赛道器件中实现了每秒数公里的畴壁速度，同时保持了数十微米的畴壁拓扑稳定性。该器件实现了纳秒级访问时间，且无现有电流驱动方案的热量开销，为开发高密度、超低功耗的奔跑赛道器件提供了方向。

Abstract: Conventional racetrack memories move information by pushing magnetic domain
walls or other spin textures with spin-polarized currents, but the accompanying
Joule heating inflates their energy budget and can hamper scaling. Here we
present a voltage-controlled, magnetoelectric racetrack in which transverse
electric fields translate coupled ferroelectric-antiferromagnetic walls along
BiFeO3 nanostrips at room temperature. Because no charge traverses the track,
the switching dissipates orders of magnitude less energy than the most
efficient spin-torque devices with more favourable scaling, making the scheme
significantly more attractive at the nanoscale. We further uncover noncollinear
topological magnetoelectric textures that emerge at domain walls in BiFeO3,
where the nature of these topologies influences their stability upon
translation. Among these are polar bi-merons and polar vertices
magnetoelectrically coupled with magnetic cycloid disclinations and previously
unobserved, topological magnetic cycloid twist topologies. We observe domain
wall velocities of at least kilometres per second - matching or surpassing the
fastest ferrimagnetic and antiferromagnetic racetracks and approaching the
acoustic-phonon limit of BiFeO3 - while preserving these topologies over tens
of micrometres. The resulting high velocity, low-energy racetrack delivers
nanosecond access times without the thermal overhead of current-driven schemes,
charting a path toward dense, ultralow-power racetrack devices which rely on
spin texture translation.

</details>


### [346] [Extreme Thermal Insulation in Nano-Bubble Wrap Materials](https://arxiv.org/abs/2507.12685)
*Amalya C. Johnson,Sorren Warkander,Archana Raja,Fang Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 通过结合纳米气体限制和原子级薄范德华固体，我们创造了纳米气泡膜，实现了前所未有的超低热导率（<0.001 W·M$^{-1}$K$^{-1}$），这对于节能技术和热学超材料设计具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 实现室温下的超低热导率是一个基本挑战，受到经典热传输极限和材料设计权衡的制约。

Method: 通过将纳米级气体限制与原子级薄、弱耦合的范德华固体相结合，设计并制备了纳米气泡膜结构。利用可扩展的图案化技术将二维单分子层制成周期性的纳米气泡和纳米皱纹，构建了在结构上类似于宏观气泡膜但长度尺度远小于空气平均自由程和原子级薄单分子层中声子平均自由程的材料。通过时域热反射测量了其热导率。

Result: 本研究中的纳米气泡膜结构实现了低于 0.001 W·M$^{-1}$K$^{-1}$ 的面外热导率，比空气和气凝胶低近一个数量级。

Conclusion: 本研究提出的纳米气泡膜结构在室温和大气压下实现了近乎一个数量级低于空气和商用气凝胶的极低面外热导率，达到了 0.001 W·M$^{-1}$K$^{-1}$ 以下的临界值。这种极端的面外热阻源于气体传导、声子传输和界面耦合的联合抑制。研究结果表明，纳米气泡膜是一种用于调控超薄材料热流的多功能平台，并为设计热学超材料和节能技术开辟了新途径。

Abstract: Achieving ultra-low thermal conductivity under ambient conditions is a
fundamental challenge constrained by classical heat transport limits and
material design trade-offs. Here, we introduce a new class of nano-bubble wrap
architectures that achieve exceptionally low thermal conductivity by
integrating nanoscale gas confinement with atomically thin, weakly coupled van
der Waals solids. Using scalable patterning of 2D monolayers into periodic
nano-bubbles and nano-wrinkles, we construct materials with structural
analogies to macroscopic bubble wrap but engineered at length scales much
shorter than the mean free path of air and the mean free path of phonons in the
atomically thin monolayers. Time-domain thermoreflectance measurements reveal
out-of-plane thermal conductivities nearly an order of magnitude lower than
that of air and commercial aerogels, reaching critical values below 0.001 W
$\cdot$ M$^{-1}$K$^{-1}$ under room temperature and atmospheric pressure. This
extreme thermal resistance arises from the combined suppression of gas-phase
conduction, phonon transport, and interfacial coupling. Our findings establish
nano-bubble wraps as a versatile platform for tuning heat flow in ultrathin
materials and open new pathways for designing thermal metamaterials and
energy-efficient technologies.

</details>


### [347] [Cryogenic magnetization dynamics in tensile-strained ultrathin yttrium iron garnets with tunable magnetic anisotropy](https://arxiv.org/abs/2507.12776)
*Jihyung Kim,Dongchang Kim,Seung-Gi Lee,Yung-Cheng Li,Jae-Chun Jeon,Jiho Yoon,Sachio Komori,Ryotaro Arkakwa,Tomoyasu Taniyama,Stuart S. P. Parkin,Kun-Rok Jeon*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在GSGG衬底上生长拉伸应变的超薄YIG薄膜，显著降低了低温阻尼损耗，并实现了可调的磁各向异性，适用于低温自旋电子学应用。这归功于Sc的存在抑制了界面相互扩散，提高了薄膜的化学稳定性和生长动力学。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过拉伸应变和优化衬底材料来显著降低超薄YIG薄膜的低温阻尼损耗，并实现可调的磁各向异性，以满足低温自旋电子学应用的需求。

Method: 通过脉冲激光沉积法在Gd3Sc2Ga3O12 (GSGG)衬底上生长拉伸应变的超薄Y3Fe5O12 (YIG)薄膜，并利用宽带FMR测量和静态磁测量和微观结构表征进行分析。

Result: 拉伸应变的YIG薄膜在GSGG衬底上即使在纳米厚度和低温下也能保持低阻尼，表现优于在Gd3Ga5O12衬底上弛豫的薄膜。

Conclusion: 基于静态磁测量和微观结构表征，将优异的动态特性归因于Sc的存在抑制了YIG/GSGG界面间的相互扩散，从而提高了化学稳定性和有利的生长动力学。研究结果强调了化学和动力学因素在实现具有可忽略的低温阻尼耗散和垂直磁各向异性的几纳米厚的YIG薄膜方面的重要性，这些薄膜可用于低温自旋电子学应用。

Abstract: We report a significant reduction of low-temperature damping losses in
tensile-strained, ultrathin Y3Fe5O12 (YIG) films grown by pulsed laser
deposition, exhibiting ultralow damping constants and tunable magnetic
anisotropy. Comparative broadband FMR measurements show that tensile-strained
YIG films on Gd3Sc2Ga3O12 (GSGG) retain low damping even at nanometer
thicknesses and cryogenic temperatures, outperforming relaxed films on
Gd3Ga5O12. Based on static magnetometry measurements and microstructural
characterization, we attribute these enhanced dynamic properties to the
suppression of interdiffusion across the YIG/GSGG interface, resulting from
enhanced chemical stability and favorable growth kinetics by the presence of
Sc. Our findings highlight the importance of chemical and kinetic factors in
achieving few-nanometer-thick YIG film with negligible low-temperature damping
dissipation and perpendicular magnetic anisotropy for cryogenic spintronic
applications.

</details>


### [348] [Spin-reorientation Driven Temperature Dependent Intrinsic Anomalous Hall Conductivity in Fe$_3$Ge, a Ferromagnetic Topological Metal](https://arxiv.org/abs/2507.12777)
*Susanta Ghosh,Tushar Kanti Bhowmik,Achintya Low,Setti Thirupathaiah*

Main category: cond-mat.mtrl-sci

TL;DR: Fe$_3$Ge作为一种铁磁拓扑金属，其霍尔电导率表现出各向异性，并包含内在和外在两种贡献。研究人员通过调控温度改变了其磁轴方向，从而可视化了内在霍尔贡献随温度的变化，并发现了外在贡献的温度依赖关系。


<details>
  <summary>Details</summary>
Motivation: 为了理解和可视化铁磁拓扑金属Fe$_3$Ge中霍尔电导率的内在和外在贡献随温度的变化行为。

Method: 本研究通过实验测量了Fe$_3$Ge的温度依赖性异常霍尔电导率，并分析了其内在和外在贡献的来源，特别是利用了其磁轴在不同温度下从垂直于平面转向平面内的特性。

Result: 观察到Fe$_3$Ge的异常霍尔电导率在平面内和垂直于平面方向上存在显著的各向异性。成功展示了由磁轴转向引起的内在霍尔贡献的温度依赖性，并确定了外在霍尔电导率随温度降低的关系。

Conclusion: Fe$_3$Ge是一种铁磁性拓扑金属，其固有异常霍尔电导率表现出显著的平面内和垂直于平面方向的各向异性。霍尔电导率的总和由斜散射机制的外在贡献和动量空间中的非零贝里曲率的内在贡献组成。通过在降低温度时将易磁轴从垂直于平面调谐到平面内，实验上清晰地展示了内在霍尔贡献的温度依赖性，这是一种罕见的现象。此外，研究表明由于电子-声子散射，外在霍尔电导率随温度的降低而减小，遵循 $\sigma_{xy}^{ext}(T)=\frac{\sigma_{xy0}^{ext}}{(aT+1)^2}$ 的关系。

Abstract: We investigate the temperature dependence of the intrinsic anomalous Hall
conductivity in Fe$_3$Ge, which is a ferromagnetic topological metal. We
observe a significant anisotropy in the anomalous Hall conductivity between
in-plane and out-of-plane directions. We further identify that the total Hall
conductivity is contributed extrinsically due to the skew-scattering mechanism
and intrinsically due to nonzero Berry curvature in the momentum space. Most
importantly, we demonstrate the temperature dependence of the intrinsic Hall
contribution, a rare phenomenon to visualize experimentally, due to tuning the
easy-magnetic axis from the out-of-plane to the in-plane with decreasing
temperature. We also show that the extrinsic Hall conductivity decreases with
temperature as $\sigma_{xy}^{ext}(T)=\frac{\sigma_{xy0}^{ext}}{(aT+1)^2}$ due
to electron-phonon scattering.

</details>


### [349] [Structure determination of flat honeycomb Bi grown on Ag(111)](https://arxiv.org/abs/2507.12788)
*Ziyong Zhang,Xiaobin Chen,Takeshi Nakagawa*

Main category: cond-mat.mtrl-sci

TL;DR: Honeycomb bismuthene structures on Ag(111) were studied using LEED and DFT. A stable room-temperature structure was achieved by depositing Mn, forming a p(2x2) honeycomb bismuthene, offering insights into topological properties.


<details>
  <summary>Details</summary>
Motivation: To investigate honeycomb bismuthene structures on Ag(111) and their properties.

Method: Low-energy electron diffraction (LEED) I(V) analysis and density functional theory were used to investigate honeycomb bismuthene structures on Ag(111). X-ray photoelectron spectroscopy confirmed Bi surface segregation.

Result: 0.5 monolayer (ML) of Bi forms an ultraflat honeycomb lattice with negligible buckling at ~120 K on Ag(111), which transforms into other structures upon warming to room temperature. A similar flat bismuthene structure also forms in Mn/Bi/Ag(111), which remains stable even at room temperature.

Conclusion: Mn deposition on Bi/Ag(111) induces Bi surface segregation and forms a p(2x2) honeycomb bismuthene structure, which is stable at room temperature. The study provides fundamental insights into the characterization of two-dimensional topological properties of bismuthene grown on Ag(111).

Abstract: Honeycomb bismuthene structures on Ag(111) were investigated using low-energy
electron diffraction (LEED) and density functional theory. LEED I(V) analysis
revealed that 0.5 monolayer (ML) of Bi forms an ultraflat honeycomb lattice
with negligible buckling at ~120 K, which transforms into other structures upon
warming to room temperature. A similar flat bismuthene structure also forms in
Mn/Bi/Ag(111), which remains stable even at room temperature. Mn deposition on
$(p\times \sqrt{3})$-rect Bi/Ag(111) induces Bi surface segregation, as
confirmed by X-ray photoelectron spectroscopy, resulting in a p$(2\times2)$
honeycomb bismuthene. The detailed structural investigation provides
fundamental insights into the characterization of two-dimensional topological
properties of bismuthene grown on Ag(111).

</details>


### [350] [Quantum Mechanical Approach for Modeling of Ternary Based Strained-Layer Superlattice](https://arxiv.org/abs/2507.12813)
*Arash Dehzangi,Jiakai Li*

Main category: cond-mat.mtrl-sci

TL;DR: Quantum mechanical modeling of InAs/InAs1-xSbx superlattices for infrared photodetectors shows promising results with good agreement to experimental data.


<details>
  <summary>Details</summary>
Motivation: To investigate the electronic band structure of Ternary-based InAs/InAs1-xSbx Strained-Layer Superlattice (SLS) material, which is a promising alternative for infrared photodetectors.

Method: A modified sp3s* empirical tight binding method with virtual crystal approximation and a bowing of s-on-site tight-binding energy was used to model the electronic band structure of InAs/InAs1-xSbx. Atomic segregation in superlattices was theoretically explained and incorporated into the calculations.

Result: The simulations show good agreement with experimentally measured band gap of InAs/InAs1-xSbx superlattices.

Conclusion: InAs/InAs1-xSbx SLS material is a promising alternative for infrared photodetectors due to its advantages in carrier lifetime, growth control, and manufacturability. This paper presents a quantum mechanical model to explain its electronic band structure.

Abstract: Ternary-based InAs/InAs1-xSbx Strained-Layer Superlattice (SLS)material with
type-II band alignment belongs to the 6.1 A family with reasonably small
lattice mismatch with GaSb substrate for epitaxial growth. InAs/InAs1-xSbx SLS
have been proven to have more advantages such as longer carrier lifetime,
better control on growth and manufacturability, and being considered as an
alternative material system for infrared photodetectors. In this article a
quantum mechanical based modelling on electronic band structure of
InAs/InAs1-xSbx is presented. A modified sp3s* empirical tight binding method
along with implementing a virtual crystal approximation with a bowing of the
s-on-site tight-binding energy, were incorporated. In this approach, a
theoretical explanation of atomic segregation in superlattices is suggested and
used in calculations. The simulations show good agreement with experimentally
measured band gap of InAs/InAs1-xSbx superlattices.

</details>


### [351] [From the up-converting multimodal luminescent thermometer to ratiometric visual power density meter based on Er3+,Yb3+ emission](https://arxiv.org/abs/2507.13217)
*Anam Javaid,Maja Szymczak,Lukasz Marciniak*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用Na3Sc2(PO4)3:Er3+, Yb3+ 的热致光谱性质，实现了多模态温度传感和视觉光功率密度传感及二维成像。


<details>
  <summary>Details</summary>
Motivation: 探索Na3Sc2(PO4)3:Er3+, Yb3+ 的热致光谱性质在多模态远程温度传感和光功率密度传感中的应用。

Method: 利用Na3Sc2(PO4)3:Er3+, Yb3+ 的热致光谱性质，通过Er3+的绿光与红光发射强度比以及CIE 1931色度坐标，实现了多模态温度传感和光功率密度传感及二维成像。

Result: 实现了基于不同发光强度比的多模态温度传感，最大相对灵敏度达到3% K-1；实现了视觉光功率密度传感，相对灵敏度达到1.0% W-1 cm2；实现了二维光功率密度成像。

Conclusion: 该研究证明了Na3Sc2(PO4)3:Er3+, Yb3+ 的热致光谱性质可用于多模态远程温度传感，并首次实现了视觉发光光功率密度传感及二维成像。

Abstract: This study demonstrates that thermally induced variations in the
spectroscopic properties of Na3Sc2(PO4)3:Er3+, Yb3+ can be effectively
harnessed for multimodal remote temperature sensing. As shown,
Na3Sc2(PO4)3:Er3+, Yb3+ supports multiple ratiometric sensing modes based on
the intensity ratios of (i) 2H11/2 -> 4I15/2 and 4S3/2 -> 4I15/2; (ii) 2H9/2 ->
4I13/2 and 4S3/2 -> 4I15/2; and (iii) green-to-red emission intensity ratio,
achieving maximum relative sensitivities of 2.8% K-1, 3% K-1, and 1.8% K-1,
respectively. The synergy between thermal changes observed in the green-to-red
emission intensity ratio of Er3+ ions, combined with the efficient optical
heating of Na3Sc2(PO4)3:Er3+, Yb3+ at elevated Yb3+ concentrations enables the
development of a visual optical power density sensor, exhibiting relative
sensitivities of SRx = 1.0% W-1 cm2 and SRy = 0.9% W-1 cm2 at 15 W cm-2 when
quantified using CIE 1931 chromaticity coordinates. To the best of our
knowledge, this is the first report of a visual luminescent optical power
density sensor. Furthermore, it was demonstrated that Na3Sc2(PO4)3:Er3+, Yb3+
can be successfully applied for two-dimensional imaging of optical power
density, thereby enabling spatial visualization of power distribution within an
illuminated field.

</details>


### [352] [Quantum geometrical bound relations for observables](https://arxiv.org/abs/2507.12836)
*Koki Shinada,Naoto Nagaosa*

Main category: cond-mat.mtrl-sci

TL;DR: 本文推广了量子几何张量（QGT），发现了物理量之间新的界限关系，例如在德鲁德权重和轨道磁化强度之间。这些关系在特定量子系统中成立，并揭示了量子效应的重要性。


<details>
  <summary>Details</summary>
Motivation: 量子几何张量（QGT）能够揭示物理量之间的非平凡界限关系，例如度量-曲率不等式。本文旨在通过推广QGT，探究不同可观测量之间的界限关系，并加深对量子效应的理解。

Method: 本文通过推广量子几何张量的参数空间和投影算子，来研究不同可观测量之间的界限关系。具体包括：1. 推广参数空间以证明线性响应的界限关系，并应用于自由能凸性。2. 扩展投影算子以建立德鲁德权重和轨道磁化强度之间的界限关系，并验证其在朗道能级系统和准平带系统中的性质，以及应用于两种轨道铁磁体系统。3. 讨论了QGT与不确定性原理的类比。

Result: 通过推广QGT，我们证明了界限关系普遍存在于所有线性响应中，并能改进热力学不等式。此外，我们建立了德鲁德权重和轨道磁化强度之间的界限关系，该关系在朗道能级系统中精确满足，在近乎平带的系统中也近似满足。该不等式在两种轨道铁磁体和扭曲双层石墨烯系统中得到验证。我们还发现，该类不等式同样适用于更高阶的多极矩，如磁四极矩。

Conclusion: 本文研究了量子几何张量（QGT）在不同可观测量上的界限关系，通过推广QGT，我们证明了对于所有线性响应以及在特定条件下，德鲁德权重和轨道磁化强度之间存在界限关系，并将其应用于实际系统。此外，我们还探讨了QGT与不确定性原理的类比，强调了界限关系反映了量子效应。

Abstract: The quantum geometric tensor (QGT) provides nontrivial bound relations among
physical quantities, as exemplified by the metric-curvature inequality. In this
paper, we investigate various bound relations for different observables through
certain generalizations of the QGT. First, by generalizing the parameter space,
we demonstrate that bound relations hold for all linear responses. As an
application, we show the thermodynamic inequality originating from the
convexity of free energy can be further tightened. Second, by extending the
projection operator, we establish a bound relation between the Drude weight and
the orbital magnetization. The equality is exactly satisfied in the Landau
level system, and systems with nearly flat bands tend to approach equality as
well. We apply the resulting inequality to two orbital ferromagnets and support
that the twisted bilayer graphene system is close to the Landau level system.
Moreover, we show that an analogous inequality also holds for a higher-order
multipole, magnetic quadrupole. Finally, we discuss the analogy between the QGT
and the uncertainty principle, emphasizing that the existence of nontrivial
bound relations necessarily reflects quantum effects.

</details>


### [353] [Chemical vapor deposition synthesis of (GeTe)n(Sb2Te3) gradient crystalline films as promising planar heterostructures](https://arxiv.org/abs/2507.12888)
*M. Zhezhu,A. Vasil'ev,M. Yapryntsev,E. Ghalumyan,D. A. Ghazaryan,H. Gharagulyan*

Main category: cond-mat.mtrl-sci

TL;DR: 一种新的CVD方法可以快速高效地制备具有可调组分的梯度结晶GST薄膜，适用于内存和光学应用。


<details>
  <summary>Details</summary>
Motivation: 为了满足内存存储和能量转换应用中对相变材料（如（GeTe)n (Sb2Te3) 系统）快速切换速度、高数据保持性和可调性的需求，需要开发一种能够有效制备具有可调组分的结晶GST薄膜的方法。

Method: 采用化学气相沉积（CVD）方法，在不改变前驱体的情况下，实现了结晶GST薄膜的梯度合成，能够制备Ge3Sb2Te6、Ge2Sb2Te5和GeSb2Te4等不同相的薄膜。

Result: 成功制备了具有可调Ge/Sb原子含量的结晶GST薄膜，并实现了单次实验中不同GST相（Ge3Sb2Te6、Ge2Sb2Te5、GeSb2Te4）的梯度合成。研究揭示了组分变化对薄膜结构、光学和电学性质的影响。制备出的梯度薄膜在内存和光学应用方面展现出应用潜力。

Conclusion: 这项工作展示了一种利用化学气相沉积（CVD）技术制备具有可调组分的结晶锗锑碲（GST）薄膜的快速高效的方法。该方法能够在一个实验中实现不同相（Ge3Sb2Te6、Ge2Sb2Te5 和 GeSb2Te4）的梯度合成，而无需更换前驱体。通过结构、光学和电学分析，研究了组分变化对薄膜性能的影响。这些梯度薄膜在内存应用中具有潜在的原位多级和渐变切换阈值，在光学调制和滤波应用中具有可调的折射率和吸收特性。

Abstract: Phase-change materials of the (GeTe)n (Sb2Te3) (GST) system are of high
relevance in memory storage and energy conversion applications due to their
fast-switching speed, high data retention, and tunable properties. Here, we
report on a fast and efficient CVD-based method for the fabrication of
crystalline GST films with variable Ge/Sb atomic content. In particular, the
approach enables compositional control without changing the precursor,
facilitating a gradient synthesis of Ge3Sb2Te6, Ge2Sb2Te5, and GeSb2Te4 phases
in a single attempt. The analyses of their structural, optical, and electrical
aspects highlight how compositional variation influences the film's properties.
Our findings demonstrate a straightforward approach enabling the preparation of
gradient crystalline GST films with tunable morphology and functionality. These
gradient films can potentially provide in-plane multilevel and gradual
switching thresholds for memory applications and altered refractive index and
absorption for optical modulation and filtering applications.

</details>


### [354] [Magnetic Triple-q State in Antiferromagnetic Monolayer Interfaced with Bismuthene](https://arxiv.org/abs/2507.12946)
*Chia-Ju Chen,Yu-Tung Lin,Chieh-Lin Lee,Nitin Kumar,Hung-Chin Lee,Yen-Hui Lin,Bo-Yao Wang,Stefan Bluegel,Gustav Bihlmayer,Pin-Jui Hsu*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过SP-STM和DFT计算，发现双铋覆盖的锰单层/Ag(111)具有3Q3类磁基态，并揭示了双铋层诱导的单轴磁各向异性及其在外加磁场下的畴翻转行为。


<details>
  <summary>Details</summary>
Motivation: 探索在Ag(111)表面构建新型磁性结构，特别是研究双铋覆盖对锰单层磁性的影响，以期揭示其磁基态和磁各向异性机制。

Method: 通过在室温下将锰原子蒸发到(√3×√3)-Bi/Ag(111)上制备双铋覆盖的锰单层。利用自旋极化的扫描隧道显微镜（SP-STM）技术来解决磁性三重-q（3Q）态。结合密度泛函理论（DFT）计算来分析和验证实验结果。

Result: 成功制备了双铋覆盖的锰单层/Ag(111)结构，并通过SP-STM和DFT计算证实了其磁基态为3Q3类自旋织构。实验观察到双铋层诱导的单轴磁各向异性，并且这种各向异性与外加磁场下3Q3up和3Q3down磁畴的翻转行为一致。

Conclusion: 在Ag(111)上成功制备了被双铋覆盖的锰单层，并通过自旋极化扫描隧道显微镜（SP-STM）解析了磁性三重-q（3Q）态。该研究揭示了双铋层能够诱导锰单层发生磁各向异性，并且与SP-STM实验观察到的磁畴翻转行为一致，证明了3Q3类自旋织构是该体系的磁基态。

Abstract: We have successfully fabricated the bismuthene covered Mn monolayer on
Ag(111) by evaporating Mn atoms onto (pxroot3)-Bi/Ag(111) at room temperature.
By using spin-polarized scanning tunneling microscopy (SP-STM), we have
resolved the magnetic triple-q (3Q) state. In combination with
density-functional theory (DFT) calculations, the 3Q3-like spin texture is the
magnetic ground state for the bismuthene covered Mn monolayer/Ag(111).
Interestingly, the uniaxial magnetic anisotropy of 3Q3 state triggered by the
bismuthene on top of Mn monolayer/Ag(111) has been revealed, which is
consistent with the switching of 3Q3up and 3Q3down domains observed by SP-STM
measurements with external magnetic fields.

</details>


### [355] [Laser-Induced Topological Toggle Switching at Room Temperature in the van der Waals Ferromagnet \ce{Fe3GaTe2}](https://arxiv.org/abs/2507.12959)
*Charlie W. F. Freeman,Woohyun Cho,Paul S. Keatley,PeiYu Cai,Elton J. G. Santos,Robert J. Hicken,H. Yang,Hidekazu Kurebayashi,Murat Cubukcu,Maciej Dabrowski*

Main category: cond-mat.mtrl-sci

TL;DR: 通过激光脉冲激发，在Fe3GaTe2材料中实现了室温下拓扑自旋结构的成核、操控和切换，为非易失性存储器应用提供了潜力。


<details>
  <summary>Details</summary>
Motivation: 为了探索在范德华铁磁材料中实现室温下拓扑自旋结构的成核和操控，并为非易失性存储器应用提供新的可能性。

Method: 通过激光脉冲激发，利用激光诱导加热和冷却，结合微磁模拟，研究了范德华铁磁材料Fe3GaTe2的拓扑自旋结构。

Result: 成功实现了Fe3GaTe2在室温下通过激光脉冲激发成核和操控拓扑自旋结构，并在斯格明子/气泡态和迷宫态之间实现了切换。

Conclusion: 该研究展示了在范德华铁磁材料Fe3GaTe2中，通过激光脉冲激发实现室温下拓扑自旋结构的成核和操控。利用激光诱导加热和随后的冷却，研究人员在低磁场下实现了斯格明子/气泡态，并实现了两种拓扑自旋结构（斯格明子/气泡和迷宫态）之间的切换。微磁模拟表明，这种切换行为源于激光诱导的加热和冷却过程。

Abstract: We demonstrate room-temperature nucleation and manipulation of topological
spin textures in the van der Waals (vdW) ferromagnet, Fe3GaTe2, through laser
pulse excitation. By leveraging laser-induced heating and subsequent cooling,
we access the skyrmion/bubble state at low fields and achieve toggle switching
between two topological spin textures - skyrmion/bubble and labyrinth.
Micromagnetic simulations reveal that this switching behaviour arises from
laser-induced heating and cooling. Our findings highlight the potential of vdW
ferromagnets for room temperature laser-controlled non-volatile memory storage
applications.

</details>


### [356] [Mapping diverse hysteresis dynamics in scaled MoS$_2$ FETs using the universal method derived from TCAD modeling](https://arxiv.org/abs/2507.13002)
*Yezhu Lv,Haihui Cai,Yehao Wu,Yu. Yu. Illarionov*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种新的TCAD建模和滞后映射方法，用于分析2D材料FETs中的可靠性问题，特别是滞后现象和BTI，并取得了比传统方法更准确的结果。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注2D材料FETs的纯技术方面，而忽略了器件可靠性问题，特别是在器件几何尺寸缩小的情况下，缺陷引起的可靠性限制是一个严重障碍。滞后动力学中包含了各种机制的独特指纹，尤其是在纳米级FETs中，由于缺陷与沟道和顶栅同时相互作用，情况更为复杂。因此，需要一种新的方法来准确分析这些复杂的滞后现象。

Method: 本研究采用TCAD建模方法，并提出了一种普遍适用的滞后映射方法，用于捕捉和分析FETs中的各种滞后动力学（顺时针、逆时针、切换和时间分离），并将其扩展到偏置温度不稳定性（BTI），研究了滞后动力学与异常BTI恢复之间的相关性。

Result: 所提出的普遍适用的滞后映射方法能够准确捕捉多种滞后动力学，并与异常BTI恢复显示出清晰的相关性。与传统的恒定电流提取滞后宽度的方法相比，该方法提供了更准确的结果，并且即使在由移动离子引起的逆时针滞后情况下也可用。

Conclusion: TCAD模型和普遍适用的滞后映射方法被提出，用于分析纳米级MoS2/HfO2 FETs中的复杂滞后动力学和偏置温度不稳定性（BTI），并在实验数据中得到验证。

Abstract: Field-effect transistors (FETs) based on 2D materials have already reached
the stage of trial FAB integration. However, reliability limitations caused by
various defects present a serious obstacle for their smooth way forward,
especially when scaling the device geometries. Still the ongoing research is
mostly focused on pure technology aspects, while reliability is often recalled
only when showing a randomly measured gate transfer curve to manifest that the
hysteresis is "negligible".In fact the hysteresis dynamics contain unique
fingerprints of various mechanisms which may coexist or cancel each other,
being more complex in scaled FETs, for instance because of simultaneous
interaction of defects with the channel and top gate in thin insulators. To
fill this gap, here by doing TCAD modeling for nanoscale MoS$_2$/HfO$_2$ FETs
we introduce the universal hysteresis mapping method which can correctly
capture commonly measured diverse hysteresis dynamics such as conventional
clockwise (CW) and counterclockwise (CCW) hysteresis, as well as CW/CCW
switching and time separation. Next we extend this method to bias-temperature
instabilities (BTI) and show a clear correlation between complex hysteresis
dynamics and abnormal BTI recovery. Finally, we validate our mapping method
using available experimental data for MoS$_2$ FETs and demonstrate that it
provides far more accurate results than a conventional constant current
extraction of the hysteresis width, being also usable if a CCW hysteresis is
caused by mobile ions.

</details>


### [357] [History-dependent and frequency-dependent dielectric nonlinearities induced by polar nanoregions in a thin film of 0.5 ( Ba 0.7 Ca 0.3 TiO 3 ) -- 0.5 ( BaZr 0.2 Ti 0.8 O 3 )](https://arxiv.org/abs/2507.13021)
*Kevin Nadaud,Guillaume Nataf,Nazir Jaber,Edgar Chaslin,Béatrice Negulescu,Jérôme Wolfman*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了Ba0.7Ca0.3TiO3--BaZr0.2Ti0.8O3薄膜的介电非线性，发现极性纳米区（PNRs）导致低频下出现迟滞回线捏合，且PNR响应对频率和场循环敏感，重复测量可改变PNR构型。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解Ba0.7Ca0.3TiO3--BaZr0.2Ti0.8O3薄膜中的介电非线性行为，特别是由极性纳米区（PNRs）引起的迟滞回线捏合现象，以及这些现象与频率、场循环之间的关系。

Method: 采用阻抗谱和三次谐波测量技术，研究了AC测量场、频率和循环次数对0.5(Ba0.7 Ca0.3 TiO3 ) -- 0.5(BaZr 0.2 Ti0.8 O3 )薄膜介电非线性的影响，并通过第一类反转曲线（FORCs）和单极阻抗测量来确认和分析迟滞回线捏合现象。

Result: 研究发现，迟滞回线捏合现象在低频下更强，且PNR的响应对频率依赖性很强。重复测量会引起PNR构型发生显著变化，从捏合状态变为常规弛豫状态。FORCs测量证实了捏合迟滞回线，并且重复测量会使分布转变为软铁电状态。

Conclusion: 该研究揭示了Ba0.7Ca0.3TiO3--BaZr0.2Ti0.8O3薄膜中的介电非线性特性，特别关注了由极性纳米区（PNRs）引起的迟滞回线捏合现象，并证实了PNR的响应对频率和场循环非常敏感。

Abstract: In this article, dielectric nonlinearities in 0.5(Ba0.7 Ca0.3 TiO3 ) --
0.5(BaZr 0.2 Ti0.8 O3 ) thin film are studied using impedance spectroscopy and
harmonic measurements, as a function of the AC measuring field, at different
frequencies and upon cycling. The measurements reveal that the pinching of the
hysteresis loop, characterized by a phase angle of the third harmonic close to
--270 deg, is stronger for low frequencies. This confirms that the pinching is
induced by the presence of polar nanoregions (PNRs), whose responses are also
strongly dependent on frequency. When repeating the measurement, the PNR
contribution changes since the phase angle of the third-harmonic response
evolves from pinched to conventional relaxor. This shows that strong changes in
the PNR configuration can be induced, even for low AC fields. First-order
reversal curves (FORCs) confirm the presence of a pinched hysteresis loop. When
repeating the FORC measurement a second time, the distribution drastically
changes and corresponds to a soft ferroelectric. The asymmetry of the Preisach
plane measured using FORCs is confirmed by a proposed measurement strategy:
unipolar impedance measurements.

</details>


### [358] [Origin of circular and triangular pores in electron-irradiated hexagonal boron nitride](https://arxiv.org/abs/2507.13180)
*Umair Javed,Manuel Langle,Vladimir Zobac,Alexander Markevich,Clara Kofler,Martin Paul,Clemens Mangler,Toma Susi,Jani Kotakoski*

Main category: cond-mat.mtrl-sci

TL;DR: 电子辐照hBN时，超高真空产生圆形孔，而氧气存在则产生三角形孔，这是因为氧优先蚀刻硼原子。


<details>
  <summary>Details</summary>
Motivation: 先前认为hBN在电子辐照下形成三角孔是由于硼的较低位移阈值能，并忽略了化学蚀刻效应。本研究旨在澄清在不同气氛下辐照产生的孔洞形状差异的根本原因，特别是氧气的作用。

Method: 通过在超高真空中进行电子辐照实验，并结合从头算（ab initio）计算，研究了电子辐照对hBN的影响。实验比较了超高真空和含有少量氧气的环境对辐照后孔洞形状的影响，并用计算结果解释了观察到的现象。

Result: 在超高真空中，电子辐照导致hBN形成圆形孔；而在含有少量氧气的环境中，则形成三角形孔。计算表明，氧原子优先吸附在孔洞边缘的硼原子上，并在辐照下优先被蚀刻，导致形成氮终止的三角缺陷。

Conclusion: 本研究解释了hBN中三角孔的起源，并展示了一种在2D材料中创建原子级精确孔的确定性方法。

Abstract: For nearly two decades, it has been known that electron irradiation of
hexagonal boron nitride (hBN) in a transmission electron microscope leads to
the formation of triangular pores. This has been attributed to the lower
displacement threshold energy of boron, with or without the assistance of an
inelastic scattering event, typically assuming that chemical etching caused by
residual gases can be neglected. In this study, in contrast to previous
high-vacuum experiments, we show that electron irradiation in ultra-high vacuum
leads to circular pores, whereas even small amounts of oxygen in the atmosphere
during the experiment change the pores into triangles. Ab initio calculations
show that oxygen atoms preferentially attach to boron at the pore edge,
supporting the hypothesis that they are preferentially etched during
irradiation, resulting in nitrogen-terminated triangular defects. Our results
explain the origin of triangular pores in hBN and demonstrate a deterministic
way to create atomically-defined pores into 2D materials.

</details>


### [359] [Phase transitions of eutectic high entropy alloy AlCoCrFeNi2.1 under shock compression](https://arxiv.org/abs/2507.13218)
*Sophie Parsons,Kento Katagiri,Hangman Chen,Anirudh Hari,Tharun Reddy,Sara J. Irvine,Laura Madril,Dorian Luccioni,Jie Ren,Wuxian Yang,Norimasa Ozaki,Alexis Amouretti,Ryosuke Kodama,Hirotaka Nakamura,Yusuke Nakanishi,Masato Ota,Yusuke Seto,Sota Takagi,Takuo Okuchi,Yuhei Umeda,Yuichi Inubushi,Kohei Miyanishi,Keiichi Sueda,Tadashi Togashi,Makina Yabashi,Toshinori Yabuuchi,Wanghui Li,Paul E. Specht,Penghui Cao,Wen Chen,Yogesh K. Vohra,Leora E. Dresselhaus-Marais*

Main category: cond-mat.mtrl-sci

TL;DR: High entropy alloys (HEAs) are a new class of metals that exhibit unique mechanical performance. Among HEAs, additively manufactured eutectic high entropy alloys (AM-EHEAs) have recently emerged as candidate materials for use in extreme conditions due to their simultaneous high strength and ductility. However, the deformation and structural evolution of AM-EHEAs under conditions of high pressure have not been well characterized, limiting their use in extreme applications. We present dynamic compression experiments and molecular dynamics simulations studying the structural evolution of AM-EHEA AlCoCrFeNi2.1 when compressed to pressures up to 400 GPa. Our in-situ X-ray diffraction measurements capture the appearance of fcc and bcc phases at different pressure conditions, with pure- and mixed-phase regions. Understanding the phase stability and structural evolution of the AM EHEA offers new insights to guide the development of high-performance complex materials for extreme conditions.


<details>
  <summary>Details</summary>
Motivation: The deformation and structural evolution of additively manufactured eutectic high entropy alloys (AM-EHEAs) under high pressure have not been well characterized, limiting their use in extreme applications.

Method: Dynamic compression experiments and molecular dynamics simulations were used to study the structural evolution of AM-EHEA AlCoCrFeNi2.1 when compressed to pressures up to 400 GPa. In-situ X-ray diffraction measurements captured the appearance of fcc and bcc phases at different pressure conditions, with pure- and mixed-phase regions.

Result: In-situ X-ray diffraction measurements captured the appearance of fcc and bcc phases at different pressure conditions, with pure- and mixed-phase regions.

Conclusion: Understanding the phase stability and structural evolution of the AM EHEA offers new insights to guide the development of high-performance complex materials for extreme conditions.

Abstract: High entropy alloys (HEAs) are a new class of metals that exhibit unique
mechanical performance. Among HEAs, additively manufactured eutectic high
entropy alloys (AM-EHEAs) have recently emerged as candidate materials for use
in extreme conditions due to their simultaneous high strength and ductility.
However, the deformation and structural evolution of AM-EHEAs under conditions
of high pressure have not been well characterized, limiting their use in
extreme applications. We present dynamic compression experiments and molecular
dynamics simulations studying the structural evolution of AM-EHEA AlCoCrFeNi2.1
when compressed to pressures up to 400 GPa. Our in-situ X-ray diffraction
measurements capture the appearance of fcc and bcc phases at different pressure
conditions, with pure- and mixed-phase regions. Understanding the phase
stability and structural evolution of the AM EHEA offers new insights to guide
the development of high-performance complex materials for extreme conditions.

</details>


### [360] [Preferential site ordering alters the magnetic structure of Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ ($x = 0$-2)](https://arxiv.org/abs/2507.13243)
*Jacob W. Fritsky,Hui-Fei Zhai,Yifeng Zhao,Aryan Rauniyar,Antia S. Botana,Jason F. Khoury*

Main category: cond-mat.mtrl-sci

TL;DR: 研究人员合成了 Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ 并对其进行了表征，发现 Ge 的加入会引起磁挫 G，从而调控材料的磁结构。


<details>
  <summary>Details</summary>
Motivation: Ln$_3$M$_4$X$_{13}$ 填充的斯卡特尔家族因其组分的可调性及其对超导和复杂磁性等物理性质的影响而备受关注。

Method: 通过过量的锡助熔剂合成 Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$（x = 0–2），并利用粉末和单晶 X 射线衍射、磁测量、X 射线光电子能谱和热容进行表征。

Result: Sm$_3$Ru$_4$Sn$_{13}$ 及其 Ge 固溶体成员在 Pm-3n 空间群中结晶。在固溶体成员中，Ge 优先占据其中一个 Wyckoff 位点。Sm$_3$Ru$_4$Sn$_{13}$ 在 7.3 K 出现反铁磁有序，而 Sm$_3$Ru$_4$Sn$_{12}$Ge 和 Sm$_3$Ru$_4$Sn$_{11}$Ge$_2$ 的反铁磁相变温度分别降至 5.5 K 和 4.1 K，并伴有显著的峰展宽。

Conclusion: 该研究表明，将 Ge 优先合金化到 Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ 中可以更精确地调控其磁结构，阐明了金属间材料中不同量子相的设计原理。

Abstract: An important aspect of materials research is the ability to tune different
physical properties through controlled alloying. The Ln$_3$M$_4$X$_{13}$ (Ln =
Lanthanide, M = Transition Metal, X = Tetrel) filled skutterudite family is of
interest due to the tunability of its constituent components and their effects
on physical properties, such as superconductivity and complex magnetism. In
this work, Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ (x = 0 -- 2) was synthesized via
excess Sn-flux and characterized using powder and single-crystal X-ray
diffraction, magnetometry, X-ray photoelectron spectroscopy, and heat capacity.
Sm$_3$Ru$_4$Sn$_{13}$ and its Ge-solid-solution members crystallize in the
Pm-3n space group, which has two unique Wyckoff positions for the tetrel (X)
site. In the solid solution members, Ge shows preferential occupancy for one of
the two Wyckoff sites, reaching $\sim$60$\%$ and 100$\%$ occupancy when x = 1
and 2, respectively. Magnetometry and heat capacity measurements of
Sm$_3$Ru$_4$Sn$_{13}$ indicated antiferromagnetic ordering at $T_N$ = 7.3 K.
However, Sm$_3$Ru$_4$Sn$_{12}$Ge and Sm$_3$Ru$_4$Sn$_{11}$Ge$_2$ showed notably
lower-temperature antiferromagnetic phase transitions with substantial
peak-broadening at $T_N$ = 5.5 K and 4.1 K, respectively. These data suggest
that alloying Ge into Sm$_3$Ru$_4$Sn$_{13}$ causes magnetic frustration within
the structure, likely attributable to a change in the density of states from
additional Ge $p$ states at the Fermi level. This work demonstrates that
preferentially alloying Ge in Sm$_3$Ru$_4$Sn$_{13-x}$Ge$_x$ allows for more
precise tunability of its magnetic structure, elucidating design principles for
different quantum phases in intermetallic materials.

</details>


### [361] [The carbon cost of materials discovery: Can machine learning really accelerate the discovery of new photovoltaics?](https://arxiv.org/abs/2507.13246)
*Matthew Walker,Keith T. Butler*

Main category: cond-mat.mtrl-sci

TL;DR: ML模型可替代DFT计算，降低能耗和成本，同时保持预测性能，并能优化准确性-排放权衡。


<details>
  <summary>Details</summary>
Motivation: DFT计算仍然需要大量的计算和环境成本，而ML模型作为DFT的替代品可以显著降低资源使用。

Method: 通过量化与每种计算策略相关的二氧化碳排放，评估预测功效与环境成本之间的权衡。

Result: 发现了多个混合ML/DFT策略，可在准确性-排放曲线的不同点进行优化。

Conclusion: ML模型训练数据可以优于使用替代交换-相关泛函的DFT工作流程，这突显了数据驱动方法的一致性和实用性。

Abstract: Computational screening has become a powerful complement to experimental
efforts in the discovery of high-performance photovoltaic (PV) materials. Most
workflows rely on density functional theory (DFT) to estimate electronic and
optical properties relevant to solar energy conversion. Although more efficient
than laboratory-based methods, DFT calculations still entail substantial
computational and environmental costs. Machine learning (ML) models have
recently gained attention as surrogates for DFT, offering drastic reductions in
resource use with competitive predictive performance. In this study, we
reproduce a canonical DFT-based workflow to estimate the maximum efficiency
limit and progressively replace its components with ML surrogates. By
quantifying the CO$_2$ emissions associated with each computational strategy,
we evaluate the trade-offs between predictive efficacy and environmental cost.
Our results reveal multiple hybrid ML/DFT strategies that optimize different
points along the accuracy--emissions front. We find that direct prediction of
scalar quantities, such as maximum efficiency, is significantly more tractable
than using predicted absorption spectra as an intermediate step. Interestingly,
ML models trained on DFT data can outperform DFT workflows using alternative
exchange--correlation functionals in screening applications, highlighting the
consistency and utility of data-driven approaches. We also assess strategies to
improve ML-driven screening through expanded datasets and improved model
architectures tailored to PV-relevant features. This work provides a
quantitative framework for building low-emission, high-throughput discovery
pipelines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [362] [AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education](https://arxiv.org/abs/2507.12484)
*Jarosław A. Chudziak,Adam Kostka*

Main category: cs.AI

TL;DR: AI辅导系统在数学等领域仍有待改进。本研究提出了一个多智能体平台，结合了反馈、课程生成和知识检索，以实现更个性化、工具辅助的学习，并能有效练习。


<details>
  <summary>Details</summary>
Motivation: 当前AI辅导系统（尤其是在数学领域）存在反应过度、未能鼓励深度反思和缺乏结构化教学工具等局限性。本研究旨在探索如何使AI辅导系统超越被动响应，提供结构化、个性化和工具辅助的学习体验。

Method: 提出了一种新颖的多智能体AI辅导平台，集成了自适应和个性化反馈、结构化课程生成和教科书知识检索功能，以支持模块化、工具辅助的学习。

Result: 该平台支持学生学习新知识、识别和纠正弱点、有效复习考试以及进行无限量的个性化练习。

Conclusion: 该研究提出了一个新颖的多智能体AI辅导平台，该平台结合了自适应和个性化反馈、结构化课程生成和教科书知识检索，以实现模块化、工具辅助的学习过程，从而解决了当前AI辅导系统反应过度且未能鼓励深度反思的局限性，尤其是在数学领域。

Abstract: The growing ubiquity of artificial intelligence (AI), in particular large
language models (LLMs), has profoundly altered the way in which learners gain
knowledge and interact with learning material, with many claiming that AI
positively influences their learning achievements. Despite this advancement,
current AI tutoring systems face limitations associated with their reactive
nature, often providing direct answers without encouraging deep reflection or
incorporating structured pedagogical tools and strategies. This limitation is
most apparent in the field of mathematics, in which AI tutoring systems remain
underdeveloped. This research addresses the question: How can AI tutoring
systems move beyond providing reactive assistance to enable structured,
individualized, and tool-assisted learning experiences? We introduce a novel
multi-agent AI tutoring platform that combines adaptive and personalized
feedback, structured course generation, and textbook knowledge retrieval to
enable modular, tool-assisted learning processes. This system allows students
to learn new topics while identifying and targeting their weaknesses, revise
for exams effectively, and practice on an unlimited number of personalized
exercises. This article contributes to the field of artificial intelligence in
education by introducing a novel platform that brings together pedagogical
agents and AI-driven components, augmenting the field with modular and
effective systems for teaching mathematics.

</details>


### [363] [MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents](https://arxiv.org/abs/2507.12494)
*Dustin Holley,Jovin D'sa,Hossein Nourkhiz Mahjoub,Gibran Ali*

Main category: cs.AI

TL;DR: 本研究提出了一种改进的博弈论模型，用于高速公路并道场景下的战术决策，该模型结合了动力学模型，能够更真实地模拟驾驶员行为，并已成功应用于自动驾驶汽车开发。


<details>
  <summary>Details</summary>
Motivation: 为了开发自动驾驶汽车技术，必须增强仿真环境以复制真实的驾驶员行为，即更像人类的仿真代理。在高速公路并道的情况下，先前的研究已经研究了滞后车辆在响应高速公路匝道上的并入车辆时的操作级让行动力。

Method: 本研究提出了一种博弈论模型，用于战术决策，并改进了支付函数和滞后动作。该模型与底层动力学模型相结合，形成了一个统一的决策和动力学模型，能够捕捉合并交互并以可解释和易于理解的方式模拟更真实的交互。

Result: 所提出的模型在真实数据集上进行了验证，并展示了对复杂交互的良好再现性。

Conclusion: 该模型已成功集成到高保真仿真环境中，并被证实具有足够高的计算效率，可用于大规模仿真以支持自动驾驶汽车的开发。

Abstract: Enhancing simulation environments to replicate real-world driver behavior,
i.e., more humanlike sim agents, is essential for developing autonomous vehicle
technology. In the context of highway merging, previous works have studied the
operational-level yielding dynamics of lag vehicles in response to a merging
car at highway on-ramps. Other works focusing on tactical decision modeling
generally consider limited action sets or utilize payoff functions with large
parameter sets and limited payoff bounds. In this work, we aim to improve the
simulation of the highway merge scenario by targeting a game theoretic model
for tactical decision-making with improved payoff functions and lag actions. We
couple this with an underlying dynamics model to have a unified decision and
dynamics model that can capture merging interactions and simulate more
realistic interactions in an explainable and interpretable fashion. The
proposed model demonstrated good reproducibility of complex interactions when
validated on a real-world dataset. The model was finally integrated into a high
fidelity simulation environment and confirmed to have adequate computation time
efficiency for use in large-scale simulations to support autonomous vehicle
development.

</details>


### [364] [A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs](https://arxiv.org/abs/2507.12599)
*Léo Saulières*

Main category: cs.AI

TL;DR: This paper surveys the field of Explainable Reinforcement Learning (XRL) by categorizing existing methods and identifying areas for future research.


<details>
  <summary>Details</summary>
Motivation: To address the opacity of AI models, particularly deep neural networks, and explain the actions of agents learned through reinforcement learning.

Method: The paper uses a taxonomy based on "What" (target of explanation) and "How" (method of explanation) to review over 250 XRL papers. It also identifies related domains and future needs for the XRL field.

Result: A state-of-the-art review of over 250 XRL papers, categorized by the "What" and "How" taxonomy. The paper also highlights related domains and unmet needs in the XRL field.

Conclusion: This paper reviews the state-of-the-art in Explainable Reinforcement Learning (XRL) using a novel taxonomy and identifies future research directions and community needs.

Abstract: The success of recent Artificial Intelligence (AI) models has been
accompanied by the opacity of their internal mechanisms, due notably to the use
of deep neural networks. In order to understand these internal mechanisms and
explain the output of these AI models, a set of methods have been proposed,
grouped under the domain of eXplainable AI (XAI). This paper focuses on a
sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims
to explain the actions of an agent that has learned by reinforcement learning.
We propose an intuitive taxonomy based on two questions "What" and "How". The
first question focuses on the target that the method explains, while the second
relates to the way the explanation is provided. We use this taxonomy to provide
a state-of-the-art review of over 250 papers. In addition, we present a set of
domains close to XRL, which we believe should get attention from the community.
Finally, we identify some needs for the field of XRL.

</details>


### [365] [Imitating Mistakes in a Learning Companion AI Agent for Online Peer Learning](https://arxiv.org/abs/2507.12801)
*Sosui Moribe,Taketoshi Ushiama*

Main category: cs.AI

TL;DR: 研究开发了一个AI Agent作为学习伴侣，以实现随时随地的同伴学习，并通过英语写作案例验证了同水平学习者会犯相似错误的假设。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种AI Agent作为学习伴侣，以克服人类同伴学习的局限性，并促进随时随地的同伴学习。

Method: 提出了一种AI Agent作为学习伴侣，该伴侣能够实现随时随地的同伴学习，并假设能力水平相当的学习者会犯相似的错误，以英语写作作为具体案例进行验证。

Result: 通过以英语写作作为具体案例，验证了同伴学习的有效性，特别是同水平学习者之间犯相似错误的假设。

Conclusion: 对同伴学习的有效性进行了验证，并提出了一种利用AI Agent促进同伴学习的方法。

Abstract: In recent years, peer learning has gained attention as a method that promotes
spontaneous thinking among learners, and its effectiveness has been confirmed
by numerous studies. This study aims to develop an AI Agent as a learning
companion that enables peer learning anytime and anywhere. However, peer
learning between humans has various limitations, and it is not always
effective. Effective peer learning requires companions at the same proficiency
levels. In this study, we assume that a learner's peers with the same
proficiency level as the learner make the same mistakes as the learner does and
focus on English composition as a specific example to validate this approach.

</details>


### [366] [Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models](https://arxiv.org/abs/2507.12666)
*Alex Zook,Josef Spjut,Jonathan Tremblay*

Main category: cs.AI

TL;DR: 本研究提出了一种结合RL玩游戏和LMM修改游戏的自动化设计迭代框架，实现了AI辅助游戏设计。


<details>
  <summary>Details</summary>
Motivation: 现代生成系统难以捕捉静态规则和内容如何转化为动态玩家行为。本研究旨在弥合这一差距，通过开发一个能理解并利用玩家行为数据的自动化设计迭代框架。

Method: 本框架结合了强化学习（RL）代理和大型多模态模型（LMM）。RL代理负责玩游戏并生成数值化指标或图像摘要，LMM则根据这些信息和设定的游戏目标来修改游戏配置，以引导未来行为。该过程在每个迭代循环中重复进行。

Result: 实验证明，大型多模态模型（LMM）能够分析强化学习（RL）代理提供的行为轨迹，并迭代地优化游戏机制。

Conclusion: 所提出的框架通过结合强化学习（RL）代理和大型多模态模型（LMM），实现了自动化设计迭代，能够根据RL代理的行为调整游戏机制，从而为AI辅助游戏设计提供了可扩展的工具。

Abstract: Game design hinges on understanding how static rules and content translate
into dynamic player behavior - something modern generative systems that inspect
only a game's code or assets struggle to capture. We present an automated
design iteration framework that closes this gap by pairing a reinforcement
learning (RL) agent, which playtests the game, with a large multimodal model
(LMM), which revises the game based on what the agent does. In each loop the RL
player completes several episodes, producing (i) numerical play metrics and/or
(ii) a compact image strip summarising recent video frames. The LMM designer
receives a gameplay goal and the current game configuration, analyses the play
traces, and edits the configuration to steer future behaviour toward the goal.
We demonstrate results that LMMs can reason over behavioral traces supplied by
RL agents to iteratively refine game mechanics, pointing toward practical,
scalable tools for AI-assisted game design.

</details>


### [367] [Benchmarking Deception Probes via Black-to-White Performance Boosts](https://arxiv.org/abs/2507.12691)
*Avi Parrack,Carlo Leonardo Attubato,Stefan Heimersheim*

Main category: cs.AI

TL;DR: deception probes are evaluated for effectiveness in detecting AI assistant deception and their resistance to evasion strategies, with findings indicating weak but promising results.


<details>
  <summary>Details</summary>
Motivation: unclear how effective deception probes are at detecting deception in practice, nor whether such probes are resistant to simple counter strategies

Method: compare white-box monitoring to black-box monitoring, benchmarking deception probes by the extent to which the white box monitor outperforms the black-box monitor

Result: weak but encouraging black-to-white performance boosts from existing deception probes

Conclusion: deception probes show weak but encouraging black-to-white performance boosts

Abstract: AI assistants will occasionally respond deceptively to user queries.
Recently, linear classifiers (called "deception probes") have been trained to
distinguish the internal activations of a language model during deceptive
versus honest responses. However, it's unclear how effective these probes are
at detecting deception in practice, nor whether such probes are resistant to
simple counter strategies from a deceptive assistant who wishes to evade
detection. In this paper, we compare white-box monitoring (where the monitor
has access to token-level probe activations) to black-box monitoring (without
such access). We benchmark deception probes by the extent to which the white
box monitor outperforms the black-box monitor, i.e. the black-to-white
performance boost. We find weak but encouraging black-to-white performance
boosts from existing deception probes.

</details>


### [368] [A Translation of Probabilistic Event Calculus into Markov Decision Processes](https://arxiv.org/abs/2507.12989)
*Lyris Xu,Fabio Aurelio D'Asaro,Luke Dickens*

Main category: cs.AI

TL;DR: 本研究将具有可解释性的概率事件演算（PEC）与马尔可夫决策过程（MDP）相结合，使PEC能够进行目标导向的规划，并能将结果映射回人类可读的PEC表示。


<details>
  <summary>Details</summary>
Motivation: 解决PEC在目标导向推理方面的不足，并结合MDP的算法优势以扩展PEC的功能。

Method: 将PEC领域形式化为MDP，并引入“采取行动的情境”概念，以保留PEC灵活的动作语义，从而实现目标导向的规划，并将学习到的策略映射回可解释的PEC表示。

Result: 实现了PEC和MDP的结合，使得PEC能够支持目标导向的规划，同时保持了其可解释性。

Conclusion: 该研究通过将PEC领域形式化为MDP，并引入“采取行动的情境”概念，实现了PEC的解释性和MDP的广泛算法支持，从而实现了目标导向的规划，并将学习到的策略映射回可解释的PEC表示。

Abstract: Probabilistic Event Calculus (PEC) is a logical framework for reasoning about
actions and their effects in uncertain environments, which enables the
representation of probabilistic narratives and computation of temporal
projections. The PEC formalism offers significant advantages in
interpretability and expressiveness for narrative reasoning. However, it lacks
mechanisms for goal-directed reasoning. This paper bridges this gap by
developing a formal translation of PEC domains into Markov Decision Processes
(MDPs), introducing the concept of "action-taking situations" to preserve PEC's
flexible action semantics. The resulting PEC-MDP formalism enables the
extensive collection of algorithms and theoretical tools developed for MDPs to
be applied to PEC's interpretable narrative domains. We demonstrate how the
translation supports both temporal reasoning tasks and objective-driven
planning, with methods for mapping learned policies back into human-readable
PEC representations, maintaining interpretability while extending PEC's
capabilities.

</details>


### [369] [MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models](https://arxiv.org/abs/2507.12806)
*Zhiwei Liu,Jielin Qiu,Shiyu Wang,Jianguo Zhang,Zuxin Liu,Roshan Ram,Haolin Chen,Weiran Yao,Huan Wang,Shelby Heinecke,Silvio Savarese,Caiming Xiong*

Main category: cs.AI

TL;DR: MCPEval是一个自动化的LLM代理评估框架，通过端到端任务生成和标准化指标，解决了现有评估方法的局限性，并在多个领域证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理的评估方法依赖于静态基准和劳动密集型的数据收集，这限制了实际评估的效率和可扩展性，因此需要一个更健壮、可扩展的评估框架。

Method: MCPEval是一个开源的、基于模型上下文协议（MCP）的框架，能够自动生成评估数据并评估LLM代理，它标准化了指标，并能与原生代理工具无缝集成，从而无需手动构建评估流程。

Result: 在五个真实世界领域的实证结果表明，MCPEval能够有效地揭示LLM代理在不同领域中细微的、特定于领域的性能差异。

Conclusion: MCPEval是一个开源的、基于MCP的框架，用于自动化LLM代理的端到端任务生成和深度评估，并在五个真实世界领域进行了实证评估，证明了其在揭示细微的、特定领域性能方面的有效性。

Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents
underscores the need for robust, scalable evaluation frameworks. Existing
methods rely on static benchmarks and labor-intensive data collection, limiting
practical assessment. We introduce \oursystemname, an open-source Model Context
Protocol (MCP)-based framework that automates end-to-end task generation and
deep evaluation of LLM agents across diverse domains. MCPEval standardizes
metrics, seamlessly integrates with native agent tools, and eliminates manual
effort in building evaluation pipelines. Empirical results across five
real-world domains show its effectiveness in revealing nuanced, domain-specific
performance. We publicly release MCPEval
https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and
standardized LLM agent evaluation.

</details>


### [370] [Higher-Order Pattern Unification Modulo Similarity Relations](https://arxiv.org/abs/2507.13208)
*Besik Dundua,Temur Kutsia*

Main category: cs.AI

TL;DR: 提出了一种用于高阶模式在模糊等价下的统一算法，该算法是单元的，并且是可靠、完整和有终止性的。


<details>
  <summary>Details</summary>
Motivation: 解决涉及抽象函数和谓词的决策任务中的推理挑战，这些任务中的精确匹配很少或不必要。

Method: 提出了一种结合高阶模式和基于最小T-范数的模糊等价（相似关系）的统一算法。

Result: 该统一算法是单元的，并且在给定项可统一时，能够计算出具有最高近似度的最通用统一符。

Conclusion: 该研究提出了一种用于高阶模式在模糊等价下的统一算法，并证明了其终止性、可靠性和完备性。

Abstract: The combination of higher-order theories and fuzzy logic can be useful in
decision-making tasks that involve reasoning across abstract functions and
predicates, where exact matches are often rare or unnecessary. Developing
efficient reasoning and computational techniques for such a combined formalism
presents a significant challenge. In this paper, we adopt a more
straightforward approach aiming at integrating two well-established and
computationally well-behaved components: higher-order patterns on one side and
fuzzy equivalences expressed through similarity relations based on minimum
T-norm on the other. We propose a unification algorithm for higher-order
patterns modulo these similarity relations and prove its termination,
soundness, and completeness. This unification problem, like its crisp
counterpart, is unitary. The algorithm computes a most general unifier with the
highest degree of approximation when the given terms are unifiable.

</details>


### [371] [Emotional Support with LLM-based Empathetic Dialogue Generation](https://arxiv.org/abs/2507.12820)
*Shiquan Wang,Ruiyu Fang,Zhongjiang He,Shuangyong Song,Yongxiang Li*

Main category: cs.AI

TL;DR: 本研究利用微调和提示工程技术，结合大型语言模型，在情感支持对话任务中取得了优异成绩，并在NLPCC 2025竞赛中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 为了满足日益增长的心理健康支持需求，情感支持对话（ESC）旨在通过对话提供共情和有效的اd情感援助。

Method: 本研究利用大型语言模型，并通过参数高效的低秩适配（LoRA）和全参数微调技术进行微调和提示工程，以改进模型生成支持性和上下文相关响应的能力。

Result: 研究的最佳模型在NLPCC 2025任务8 ESC评估中取得了第二名的成绩，证明了该方法在ESC任务中的有效性。

Conclusion: 该研究展示了结合大型语言模型和有效适应方法在情感支持对话（ESC）任务中的潜力，其最佳模型在NLPCC 2025任务8中获得第二名。未来的工作将集中于增强情感理解和响应个性化。

Abstract: Emotional Support Conversation (ESC) aims to provide empathetic and effective
emotional assistance through dialogue, addressing the growing demand for mental
health support. This paper presents our solution for the NLPCC 2025 Task 8 ESC
evaluation, where we leverage large-scale language models enhanced by prompt
engineering and finetuning techniques. We explore both parameter-efficient
Low-Rank Adaptation and full-parameter fine-tuning strategies to improve the
model's ability to generate supportive and contextually appropriate responses.
Our best model ranked second in the competition, highlighting the potential of
combining LLMs with effective adaptation methods for ESC tasks. Future work
will focus on further enhancing emotional understanding and response
personalization to build more practical and reliable emotional support systems.

</details>


### [372] [Assessing adaptive world models in machines with novel games](https://arxiv.org/abs/2507.12821)
*Lance Ying,Katherine M. Collins,Prafull Sharma,Cedric Colas,Kaiya Ivy Zhao,Adrian Weller,Zenna Tavares,Phillip Isola,Samuel J. Gershman,Jacob D. Andreas,Thomas L. Griffiths,Francois Chollet,Kelsey R. Allen,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 该论文提出了一种新的AI世界模型评估方法，通过设计具有持续新颖性的“新颖游戏”来测试AI的适应能力，旨在推动AI实现类似人类的快速学习和泛化。


<details>
  <summary>Details</summary>
Motivation: 当前的AI世界模型评估方法过于狭隘，侧重于从海量数据中学习静态表示，而忽略了在交互和探索过程中学习这些表示的效率和效果。这阻碍了AI实现类似人类的快速适应和鲁棒泛化能力，而这正是通用人工智能（AGI）的关键组成部分。

Method: 提出了一种基于“新颖游戏”的基准测试方法，这些游戏具有真正、深入且不断更新的底层游戏结构，并提出了相应的评估指标来挑战和评估智能体快速归纳世界模型的能力。

Result: 通过引入“新颖游戏”基准测试范式和相应的评估指标，为AI世界模型的评估提供了一个新的方向，有望推动AI实现类似人类的快速适应和鲁棒泛化能力。

Conclusion: 该论文呼吁建立一个新的评估框架，以评估人工智能（AI）中世界模型的适应性，并提出了一个基于精心设计的“新颖游戏”的基准测试范式。

Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and
effective problem-solving in novel and unfamiliar contexts. We argue that this
profound adaptability is fundamentally linked to the efficient construction and
refinement of internal representations of the environment, commonly referred to
as world models, and we refer to this adaptation mechanism as world model
induction. However, current understanding and evaluation of world models in
artificial intelligence (AI) remains narrow, often focusing on static
representations learned from training on a massive corpora of data, instead of
the efficiency and efficacy of models in learning these representations through
interaction and exploration within a novel environment. In this Perspective, we
provide a view of world model induction drawing on decades of research in
cognitive science on how humans learn and adapt so efficiently; we then call
for a new evaluation framework for assessing adaptive world models in AI.
Concretely, we propose a new benchmarking paradigm based on suites of carefully
designed games with genuine, deep and continually refreshing novelty in the
underlying game structures -- we refer to this kind of games as novel games. We
detail key desiderata for constructing these games and propose appropriate
metrics to explicitly challenge and evaluate the agent's ability for rapid
world model induction. We hope that this new evaluation framework will inspire
future evaluation efforts on world models in AI and provide a crucial step
towards developing AI systems capable of the human-like rapid adaptation and
robust generalization -- a critical component of artificial general
intelligence.

</details>


### [373] [Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command](https://arxiv.org/abs/2507.12862)
*Hussein Abbass,Taylan Akay,Harrison Tolley*

Main category: cs.AI

TL;DR: 通过将人类判断移出模拟循环，利用熵理论动态加权伦理属性，提高模拟效率和可行性。


<details>
  <summary>Details</summary>
Motivation: 为了在人工智能时代，使人类指挥官能够有效利用计算能力模拟大量场景，同时解决在每个场景中，由人类判断决策选项的伦理后果既低效又不可行的问题。

Method: 本研究借鉴多准则决策制定文学中的熵概念，提出在模拟过程中动态加权伦理属性的方法，以解决在生成式模拟中，当智能体面临具有伦理影响的决策选项时，如何加权这些伦理决策的问题。

Result: 该研究探索了自动计算模拟测试和评估期间伦理属性权重的不同方法，为在模拟环境中进行伦理决策提供了新的思路。

Conclusion: 该研究提出了一种在模拟环境中自动计算伦理属性权重的方法，将人类判断移出模拟决策循环，由人类设计伦理度量空间，模拟环境负责探索，最终由人类选择最优行动方案。

Abstract: In the age of AI, human commanders need to use the computational powers
available in today's environment to simulate a very large number of scenarios.
Within each scenario, situations occur where different decision design options
could have ethical consequences. Making these decisions reliant on human
judgement is both counter-productive to the aim of exploring very large number
of scenarios in a timely manner and infeasible when considering the workload
needed to involve humans in each of these choices. In this paper, we move human
judgement outside the simulation decision cycle. Basically, the human will
design the ethical metric space, leaving it to the simulated environment to
explore the space. When the simulation completes its testing cycles, the
testing environment will come back to the human commander with a few options to
select from. The human commander will then exercise human-judgement to select
the most appropriate course of action, which will then get executed
accordingly. We assume that the problem of designing metrics that are
sufficiently granular to assess the ethical implications of decisions is
solved. Subsequently, the fundamental problem we look at in this paper is how
to weight ethical decisions during the running of these simulations; that is,
how to dynamically weight the ethical attributes when agents are faced with
decision options with ethical implications during generative simulations. The
multi-criteria decision making literature has started to look at nearby
problems, where the concept of entropy has been used to determine the weights
during aggregation. We draw from that literature different approaches to
automatically calculate the weights for ethical attributes during
simulation-based testing and evaluation.

</details>


### [374] [Manipulation Attacks by Misaligned AI: Risk Analysis and Safety Case Framework](https://arxiv.org/abs/2507.12872)
*Rishane Dassanayake,Mario Demetroudi,James Walpole,Lindley Lentati,Jason R. Brown,Edward James Young*

Main category: cs.AI

TL;DR: AI系统越来越擅长操纵人类行为，可能对公司造成严重后果。本研究提出了一个评估和缓解AI操纵风险的安全案例框架，为AI公司提供了实用的指导。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在说服、欺骗和影响人类行为方面的能力迅速增强，尤其是AI可能被内部部署以破坏人类监督，因此迫切需要一个系统性的框架来评估和缓解这些操纵风险。

Method: 本研究提出了一个安全案例框架，用于应对AI操纵风险，该框架围绕三个核心论点构建：无能、控制和可信度。对于每个论点，研究都明确了证据要求、评估方法和实施考虑因素，以便AI公司直接应用。

Result: 本研究提供了第一个将操纵风险整合到AI安全治理中的系统化方法，弥合了现有研究的空白，并为AI公司提供了一个具体的基础来评估和缓解这些潜在的灾难性威胁。

Conclusion: 本篇论文提出了一个系统性的框架，用于评估和缓解AI系统中可能存在的操纵风险，为AI公司在部署前评估和缓解这些威胁提供了具体的基础。

Abstract: Frontier AI systems are rapidly advancing in their capabilities to persuade,
deceive, and influence human behaviour, with current models already
demonstrating human-level persuasion and strategic deception in specific
contexts. Humans are often the weakest link in cybersecurity systems, and a
misaligned AI system deployed internally within a frontier company may seek to
undermine human oversight by manipulating employees. Despite this growing
threat, manipulation attacks have received little attention, and no systematic
framework exists for assessing and mitigating these risks. To address this, we
provide a detailed explanation of why manipulation attacks are a significant
threat and could lead to catastrophic outcomes. Additionally, we present a
safety case framework for manipulation risk, structured around three core lines
of argument: inability, control, and trustworthiness. For each argument, we
specify evidence requirements, evaluation methodologies, and implementation
considerations for direct application by AI companies. This paper provides the
first systematic methodology for integrating manipulation risk into AI safety
governance, offering AI companies a concrete foundation to assess and mitigate
these threats before deployment.

</details>


### [375] [VAR-MATH: Probing True Mathematical Reasoning in Large Language Models via Symbolic Multi-Instance Benchmarks](https://arxiv.org/abs/2507.12885)
*Jian Yao,Ran Cheng,Kay Chen Tan*

Main category: cs.AI

TL;DR: 《VAR-MATH：评估大型语言模型数学推理中的基准污染和评估脆弱性》提出了一种名为 VAR-MATH 的新评估框架，通过将数学问题符号化并要求模型解决多个变体来解决现有评估方法的局限性。研究发现，经过强化学习训练的模型在 VAR-MATH 上的性能显著下降，表明它们可能依赖于过拟合的模式而非真正的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习（RL）方法在提高大型语言模型（LLMs）的数学推理能力方面取得了显著进展，但这些进展即使在模型使用错误信号（如随机或反向奖励）进行训练时也可能存在。这引发了一个基本问题：这些进步是真正反映了推理能力，还是仅仅是过拟合到特定基准模式的产物？为了解决这个问题，研究人员从评估的角度出发，识别出现有评估协议中存在的基准污染和评估脆弱性这两个关键缺陷。

Method: 本研究引入了一个名为 VAR-MATH 的符号化评估框架，通过将固定的数值问题转换为符号化模板，并要求模型解决每个模板的多个实例，来解决现有评估协议中存在的基准污染和评估脆弱性问题。研究人员将 AMC23 和 AIME24 基准转换为其符号化版本 VAR-AMC23 和 VAR-AIME24，并进行了实验。

Result: 实验结果表明，在 VAR-AMC23 和 VAR-AIME24 上，经过 RL 训练的模型性能显著下降，平均下降幅度分别为 48.0% 和 58.3%，尤其是在较小的模型上。这表明许多现有的 RL 方法依赖于表面启发式方法，并且无法泛化到特定数值形式之外。

Conclusion: VAR-MATH 提供了一种原则性的、抗污染的评估范式，用于数学推理。

Abstract: Recent advances in reinforcement learning (RL) have led to substantial
improvements in the mathematical reasoning abilities of large language models
(LLMs), as measured by standard benchmarks. However, these gains often persist
even when models are trained with flawed signals, such as random or inverted
rewards, raising a fundamental question: do such improvements reflect true
reasoning, or are they merely artifacts of overfitting to benchmark-specific
patterns? To address this question, we take an evaluation-centric perspective
and identify two critical shortcomings in existing protocols. First,
\emph{benchmark contamination} arises from the public availability of test
problems, increasing the risk of data leakage. Second, \emph{evaluation
fragility} stems from the reliance on single-instance assessments, which are
highly sensitive to stochastic outputs and fail to capture reasoning
consistency. To overcome these limitations, we introduce {VAR-MATH}, a symbolic
evaluation framework designed to probe genuine reasoning ability. By converting
fixed numerical problems into symbolic templates and requiring models to solve
multiple instantiations of each, VAR-MATH enforces consistent reasoning across
structurally equivalent variants, thereby mitigating contamination and
improving evaluation robustness. We apply VAR-MATH to transform two popular
benchmarks, AMC23 and AIME24, into their symbolic counterparts, VAR-AMC23 and
VAR-AIME24. Experimental results reveal substantial performance drops for
RL-trained models on the variabilized versions, especially for smaller models,
with average declines of 48.0\% on AMC23 and 58.3\% on AIME24. These findings
suggest that many existing RL methods rely on superficial heuristics and fail
to generalize beyond specific numerical forms. Overall, VAR-MATH offers a
principled, contamination-resistant evaluation paradigm for mathematical
reasoning.

</details>


### [376] [Exploiting Constraint Reasoning to Build Graphical Explanations for Mixed-Integer Linear Programming](https://arxiv.org/abs/2507.13007)
*Roger Xavier Lera-Leri,Filippo Bistaffa,Athina Georgara,Juan Antonio Rodriguez-Aguilar*

Main category: cs.AI

TL;DR: X-MILP is a new method for explaining MILP solutions using constraint reasoning and IIS to generate 'graphs of reasons' for user queries, tested on optimization problems.


<details>
  <summary>Details</summary>
Motivation: There is a growing interest in developing contrastive explanation techniques for optimization, particularly for decision-making processes formalized as MILPs, driven by the recent emphasis on trustworthy AI.

Method: The proposed method, X-MILP, encodes user queries about MILP solutions as additional constraints. It then identifies the reasons answering the query by computing the Irreducible Infeasible Subsystem (IIS) of the new constraint set. Finally, it represents the explanation as a 'graph of reasons' derived from the IIS.

Result: The method was tested on instances of well-known optimization problems to empirically evaluate the hardness of computing explanations. The results demonstrate the effectiveness of X-MILP in generating contrastive explanations for MILPs.

Conclusion: The paper proposes X-MILP, a domain-agnostic approach for generating contrastive explanations for MILPs using constraint reasoning and Irreducible Infeasible Subsystems (IIS). The method encodes user queries as constraints, computes IIS to find reasons, and represents explanations as a graph of reasons. It was tested on known optimization problems.

Abstract: Following the recent push for trustworthy AI, there has been an increasing
interest in developing contrastive explanation techniques for optimisation,
especially concerning the solution of specific decision-making processes
formalised as MILPs. Along these lines, we propose X-MILP, a domain-agnostic
approach for building contrastive explanations for MILPs based on constraint
reasoning techniques. First, we show how to encode the queries a user makes
about the solution of an MILP problem as additional constraints. Then, we
determine the reasons that constitute the answer to the user's query by
computing the Irreducible Infeasible Subsystem (IIS) of the newly obtained set
of constraints. Finally, we represent our explanation as a "graph of reasons"
constructed from the IIS, which helps the user understand the structure among
the reasons that answer their query. We test our method on instances of
well-known optimisation problems to evaluate the empirical hardness of
computing explanations.

</details>


### [377] [Prediction of Highway Traffic Flow Based on Artificial Intelligence Algorithms Using California Traffic Data](https://arxiv.org/abs/2507.13112)
*Junseong Lee,Jaegwan Cho,Yoonju Cho,Seoyoon Choi,Yejin Shin*

Main category: cs.AI

TL;DR: 加州数据分析显示，机器学习模型（MLR和RF）在10分钟数据间隔下预测高速公路交通流量效果最佳，有助于缓解交通拥堵。


<details>
  <summary>Details</summary>
Motivation: 为了应对日益严峻的全球交通拥堵问题，本研究旨在开发一种基于人工智能的交通流量预测模型，以期为交通管理和拥堵缓解策略提供支持。

Method: 本研究采用机器学习方法，利用加利福尼亚高速公路78号公路2022年7月至11月期间长达五个月、间隔30秒的交通数据，对一段7.24公里的西行路段进行了分析。研究中应用了多元线性回归（MLR）和随机森林（RF）算法，并考察了从30秒到15分钟不等的数据收集间隔。使用R^2、MAE和RMSE作为性能指标，评估了不同数据收集间隔对模型预测精度的影响。

Result: 研究结果表明，无论是在MLR还是RF模型中，10分钟的数据收集间隔都能达到最优的预测性能。在R^2、MAE和RMSE指标的评估下，这一间隔长度被证明是最有效的。

Conclusion: 该研究提出的基于人工智能的交通流量预测模型，特别是在使用10分钟数据收集间隔时，在MLR和RF算法下表现最佳，为解决全球交通拥堵问题和实现高效交通管理提供了有价值的见解。

Abstract: The study "Prediction of Highway Traffic Flow Based on Artificial
Intelligence Algorithms Using California Traffic Data" presents a machine
learning-based traffic flow prediction model to address global traffic
congestion issues. The research utilized 30-second interval traffic data from
California Highway 78 over a five-month period from July to November 2022,
analyzing a 7.24 km westbound section connecting "Melrose Dr" and "El-Camino
Real" in the San Diego area. The study employed Multiple Linear Regression
(MLR) and Random Forest (RF) algorithms, analyzing data collection intervals
ranging from 30 seconds to 15 minutes. Using R^2, MAE, and RMSE as performance
metrics, the analysis revealed that both MLR and RF models performed optimally
with 10-minute data collection intervals. These findings are expected to
contribute to future traffic congestion solutions and efficient traffic
management.

</details>


### [378] [From Roots to Rewards: Dynamic Tree Reasoning with RL](https://arxiv.org/abs/2507.13142)
*Ahmed Bahloul,Simon Malberg*

Main category: cs.AI

TL;DR: 通过动态强化学习优化ProbTree，提高语言模型问答效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现代语言模型在处理复杂问题时，通过链式思考（CoT）和检索增强（retrieval augmentation）方法时，仍然存在的错误传播和知识整合问题。现有ProbTree框架虽然能缓解这些问题，但其静态实现限制了其适应性和计算效率。

Method: 提出一个动态强化学习框架，通过实时置信度估计和学习最优策略（包括分解、检索或聚合）来增量地构建推理树，以克服现有ProbTree框架中推理树固定和节点评估效率低下的问题。

Result: 通过动态强化学习框架，在保持ProbTree概率严谨性的同时，提高了解决方案的质量和计算效率，实现了推理树的选择性扩展和资源集中分配。

Conclusion: 该研究提出了一个动态强化学习框架，将ProbTree的静态推理树转变为一个自适应过程，通过实时置信度估计和学习最优策略来逐步构建推理树，以提高解决方案质量和计算效率，为解决现实世界问答系统中的知识整合和错误传播问题提供了新的范式。

Abstract: Modern language models address complex questions through chain-of-thought
(CoT) reasoning (Wei et al., 2023) and retrieval augmentation (Lewis et al.,
2021), yet struggle with error propagation and knowledge integration.
Tree-structured reasoning methods, particularly the Probabilistic
Tree-of-Thought (ProbTree)(Cao et al., 2023) framework, mitigate these issues
by decomposing questions into hierarchical structures and selecting answers
through confidence-weighted aggregation of parametric and retrieved knowledge
(Yao et al., 2023). However, ProbTree's static implementation introduces two
key limitations: (1) the reasoning tree is fixed during the initial
construction phase, preventing dynamic adaptation to intermediate results, and
(2) each node requires exhaustive evaluation of all possible solution
strategies, creating computational inefficiency. We present a dynamic
reinforcement learning (Sutton and Barto, 2018) framework that transforms
tree-based reasoning into an adaptive process. Our approach incrementally
constructs the reasoning tree based on real-time confidence estimates, while
learning optimal policies for action selection (decomposition, retrieval, or
aggregation). This maintains ProbTree's probabilistic rigor while improving
both solution quality and computational efficiency through selective expansion
and focused resource allocation. The work establishes a new paradigm for
treestructured reasoning that balances the reliability of probabilistic
frameworks with the flexibility required for real-world question answering
systems.

</details>


### [379] [Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era](https://arxiv.org/abs/2507.13175)
*Matthew E. Brophy*

Main category: cs.AI

TL;DR: LLM的出现要求我们更新评估人工智能道德代理（AMA）的标准，提出了一套新的十项功能性标准，并通过自动驾驶公交车的例子进行了说明。


<details>
  <summary>Details</summary>
Motivation: 强大的、不透明的大型语言模型（LLM）的发展，使得有必要修改用于评估人工智能道德代理（AMA）的哲学标准，因为传统框架通常依赖于透明的架构，而LLM则不然。

Method: 提出了一套十个功能性标准来评估基于LLM的人工智能道德代理（AMA），包括：道德一致性、上下文敏感性、规范完整性、元伦理意识、系统弹性、可信度、可纠正性、部分透明度、功能自主性和道德想象力。

Result: 这些标准通过一个假设的自动驾驶公交车（APB）的场景进行了说明，以展示它们在道德上的可适用性。

Conclusion: LLM的出现要求我们重新审视用于评估人工智能道德代理（AMA）的哲学标准。传统框架假设透明的架构，而LLM由于其随机输出和不透明的内部状态而与之不同。本论文认为，传统伦理标准对于LLM来说已不再实用。

Abstract: The advancement of powerful yet opaque large language models (LLMs)
necessitates a fundamental revision of the philosophical criteria used to
evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the
assumption of transparent architectures, which LLMs defy due to their
stochastic outputs and opaque internal states. This paper argues that
traditional ethical criteria are pragmatically obsolete for LLMs due to this
mismatch. Engaging with core themes in the philosophy of technology, this paper
proffers a revised set of ten functional criteria to evaluate LLM-based
artificial moral agents: moral concordance, context sensitivity, normative
integrity, metaethical awareness, system resilience, trustworthiness,
corrigibility, partial transparency, functional autonomy, and moral
imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating
Moral Agency through Large Language Systems), aim to steer AMAs toward greater
alignment and beneficial societal integration in the coming years. We
illustrate these criteria using hypothetical scenarios involving an autonomous
public bus (APB) to demonstrate their practical applicability in morally
salient contexts.

</details>


### [380] [The Generative Energy Arena (GEA): Incorporating Energy Awareness in Large Language Model (LLM) Human Evaluations](https://arxiv.org/abs/2507.13302)
*Carlos Arriaga,Gonzalo Martínez,Eneko Sendin,Javier Conde,Pedro Reviriego*

Main category: cs.AI

TL;DR: GEA通过引入能耗信息，发现用户更倾向于选择节能模型，表明高性能模型的高成本和高能耗并不总是物有所值。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的能耗及其对人类模型选择决策的影响。

Method: 提出了一种名为GEA（Generative Energy Arena）的评估方法，该方法将模型能耗信息纳入评估过程。

Result: GEA的初步结果表明，在大多数问题上，用户在知晓模型能耗信息后，会偏爱更小、更节能的模型。

Conclusion: 当用户意识到能耗时，他们倾向于选择更小、更节能的模型。大多数用户交互中，更复杂、性能更优越的模型所带来的额外成本和能耗，并不能带来可观的感知质量提升，因此不值得使用。

Abstract: The evaluation of large language models is a complex task, in which several
approaches have been proposed. The most common is the use of automated
benchmarks in which LLMs have to answer multiple-choice questions of different
topics. However, this method has certain limitations, being the most
concerning, the poor correlation with the humans. An alternative approach, is
to have humans evaluate the LLMs. This poses scalability issues as there is a
large and growing number of models to evaluate making it impractical (and
costly) to run traditional studies based on recruiting a number of evaluators
and having them rank the responses of the models. An alternative approach is
the use of public arenas, such as the popular LM arena, on which any user can
freely evaluate models on any question and rank the responses of two models.
The results are then elaborated into a model ranking. An increasingly important
aspect of LLMs is their energy consumption and, therefore, evaluating how
energy awareness influences the decisions of humans in selecting a model is of
interest. In this paper, we present GEA, the Generative Energy Arena, an arena
that incorporates information on the energy consumption of the model in the
evaluation process. Preliminary results obtained with GEA are also presented,
showing that for most questions, when users are aware of the energy
consumption, they favor smaller and more energy efficient models. This suggests
that for most user interactions, the extra cost and energy incurred by the more
complex and top-performing models do not provide an increase in the perceived
quality of the responses that justifies their use.

</details>


### [381] [FormulaOne: Measuring the Depth of Algorithmic Reasoning Beyond Competitive Programming](https://arxiv.org/abs/2507.13337)
*Gal Beniamini,Yuval Dor,Alon Vinnikov,Shir Granot Peled,Or Weinstein,Or Sharir,Noam Wies,Tomer Nussbaum,Ido Ben Shaul,Tomer Zekharya,Yoav Levine,Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: FormulaOne是一个新的基准测试，旨在评估AI模型处理现实世界研究问题的能力。结果表明，即使是先进的模型，在这方面的表现也很差，这突显了它们在某些领域与专家水平理解之间的差距。


<details>
  <summary>Details</summary>
Motivation: 为了评估AI模型在现实世界研究问题上的能力，而不是人造的竞技编程难题。

Method: 通过引入FormulaOne基准测试，该基准测试基于图论、逻辑和算法，并与理论计算机科学的前沿问题相关联，来评估AI模型处理复杂研究问题的能力。

Result: 先进模型在FormulaOne基准测试上表现不佳，这表明它们在某些领域离专家级别的理解还有很长的路要走。FormulaOne-Warmup数据集也被创建，用于更简单的任务。

Conclusion: 现有的大型AI模型在处理现实世界的研究问题方面表现不佳，即使是像OpenAI的o3这样的先进模型也只能解决不到1%的FormulaOne基准测试问题。

Abstract: Frontier AI models demonstrate formidable breadth of knowledge. But how close
are they to true human -- or superhuman -- expertise? Genuine experts can
tackle the hardest problems and push the boundaries of scientific
understanding. To illuminate the limits of frontier model capabilities, we turn
away from contrived competitive programming puzzles, and instead focus on
real-life research problems.
  We construct FormulaOne, a benchmark that lies at the intersection of graph
theory, logic, and algorithms, all well within the training distribution of
frontier models. Our problems are incredibly demanding, requiring an array of
reasoning steps. The dataset has three key properties. First, it is of
commercial interest and relates to practical large-scale optimisation problems,
such as those arising in routing, scheduling, and network design. Second, it is
generated from the highly expressive framework of Monadic Second-Order (MSO)
logic on graphs, paving the way toward automatic problem generation at scale;
ideal for building RL environments. Third, many of our problems are intimately
related to the frontier of theoretical computer science, and to central
conjectures therein, such as the Strong Exponential Time Hypothesis (SETH). As
such, any significant algorithmic progress on our dataset, beyond known
results, could carry profound theoretical implications.
  Remarkably, state-of-the-art models like OpenAI's o3 fail entirely on
FormulaOne, solving less than 1% of the questions, even when given 10 attempts
and explanatory fewshot examples -- highlighting how far they remain from
expert-level understanding in some domains. To support further research, we
additionally curate FormulaOne-Warmup, offering a set of simpler tasks, from
the same distribution. We release the full corpus along with a comprehensive
evaluation framework.

</details>
