<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.CL](#cs.CL) [Total: 46]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.LO](#cs.LO) [Total: 11]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.SI](#cs.SI) [Total: 1]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.LG](#cs.LG) [Total: 62]
- [cs.AI](#cs.AI) [Total: 25]
- [quant-ph](#quant-ph) [Total: 40]
- [eess.SY](#eess.SY) [Total: 9]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 9]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.MA](#cs.MA) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 15]
- [cs.GR](#cs.GR) [Total: 4]
- [eess.SP](#eess.SP) [Total: 8]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.ET](#cs.ET) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 本文提出了一种用于图谱系和分级图的代数类型理论，以支持分层模型架构的构建和操作，并成功应用于深度神经网络和多网格方法。


<details>
  <summary>Details</summary>
Motivation: 提供一种用于构建和操作多尺度、分层图结构的方法，适用于机器学习和计算科学中的模型架构定义，特别关注图谱系和分级图。

Method: 本文定义了结构化图“谱系”（按层级排序），其特性包括：1）图顶点和边的数量随层级呈指数增长；2）二分图连接谱系中的连续层级，并约束层级间的矩阵；3）利用谱系内的延长图谱，可以定义连续层级间图的派生距离度量；4）定义了一类“分级图”，并利用其推导出标准代数图运算和类型构造器（交叉积、盒积、不相交和、函数类型）的低成本“骨架”变体；5）这些骨架二元运算符具有与标准运算符相似但不完全相同的代数和范畴论性质；6）图谱系及其骨架乘积构造器可以逼近连续体极限对象。此外，还推导了分级图上的一个空间高效的一元运算符：加厚，用于创建多尺度图谱系；以及升级，用于创建搜索前沿图谱系（作为自适应网格的推广以及定义“骨架”函数）。

Result: 文章提出了一种代数类型理论，用于分级图和（分层）图谱系，并推导了相应的骨架算子和空间高效的一元算子（加厚和升级）。将此方法应用于深度神经网络和多网格数值方法，展示了其在定义分层模型架构和相关算法方面的潜力。

Conclusion: 该方法为“分级图”和（分层）图谱系创建了一种代数类型理论，有望用于定义分层模型架构（“分层架构”）以及在其上运行的局部采样、搜索或优化算法。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [2] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: 提出了一种名为QME的新型框架，通过专家混合（MoE）模型和伪质量损失，提升了整体生物识别的准确性，并在多个数据集上达到了最先进的水平。


<details>
  <summary>Details</summary>
Motivation: 为了克服单一生物识别模态系统的局限性，需要整合包括人脸、步态和身体在内的多种生物识别模态。然而，传统的基于评分融合（如加权平均相似度矩阵）的方法可能无法充分考虑各模态评分分布的差异，从而限制了最终性能的提升。

Method: 提出了一种名为QME（Quality-guided Mixture of score-fusion Experts）的新型框架，采用专家混合（MoE）模型进行可学习的评分融合。该框架还引入了伪质量损失来指导质量估计（通过特定模态的质量估计器QE），并使用了评分三元组损失来优化度量性能。

Result: 在多个整体生物识别数据集上进行的广泛实验证明了所提出方法的有效性，在各项指标上均取得了优于基线方法的最新成果。该方法在多模态和多模型场景下均表现出色，能够有效处理相似度评分域中的模型不对齐以及数据质量变化等问题。

Conclusion: 所提出的QME框架通过采用可学习的评分融合策略（MoE），并结合伪质量损失和评分三元组损失，在多项生物识别数据集上实现了最先进的整体生物识别结果，有效解决了模型在相似度评分域中的不对齐以及数据质量的可变性等关键挑战。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [3] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 动作识别模型在将动作概念迁移到新上下文时表现不佳，尤其是在细粒度、时间密集型任务中。模型架构、训练数据和上下文线索都会影响迁移能力。


<details>
  <summary>Details</summary>
Motivation: 为了探究动作识别模型是否能有效地将高层运动概念跨不同但相似分布的上下文进行迁移，例如识别“打人”这一未见过的“拳击”的变体。

Method: 提出一个包含三个数据集（Syn-TA、Kinetics400-TA 和 Something-Something-v2-TA）的运动迁移性框架，并在这些基准上评估了 13 种最先进的模型。

Result: 在识别新上下文中的高层动作时，模型性能显著下降。多模态模型在细粒度未知动作上比粗粒度动作更挣扎；无偏见的 Syn-TA 与真实世界数据集一样具有挑战性，模型在受控环境中的性能下降更明显；更大的模型在空间线索占主导时能提高迁移性，但在密集的时间推理上会遇到困难；依赖物体和背景线索会阻碍泛化。

Conclusion: 该研究建立了运动可迁移性评估的关键基准，并探讨了如何通过分离粗略和精细运动来提高模型在具有挑战性的数据集上的识别能力。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [4] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出一个包含 PromptEngineer 和 VisionReasoner 的框架，用于多图像推理，该框架无需训练即可泛化到多种任务，并在 MIRAGE 挑战赛中取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 解决跨不同数据集和任务格式的交错多模态推理的挑战。

Method: 提出一个用于多图像推理的协同式基于代理的框架，该框架使用一个名为 PromptEngineer 的语言代理来生成提示，以及一个名为 VisionReasoner 的大型视觉语言模型 (LVLM) 来进行推理。该框架是全自动、模块化且无需训练的，可以泛化到涉及一个或多个输入图像的分类、问答和自由形式生成任务。

Result: 在 2025 年 MIRAGE 挑战赛（A 赛道）的 18 个数据集上进行了评估，涵盖了文档问答、视觉比较、基于对话的理解和场景级推理等视觉推理任务。结果表明，Claude 3.7 在 TQA (99.13%)、DocVQA (96.87%) 和 MMCoQA (75.28 ROUGE-L) 等任务上取得了接近最优的性能。

Conclusion: LVLMs 在有信息量提示的指导下可以有效地推理多张图像。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [5] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: New dataset released for VR/headset tracking: Monado SLAM dataset captures challenging real-world scenarios like fast motion, occlusions, and bad lighting, which existing datasets miss. Promotes better VIO/SLAM development.


<details>
  <summary>Details</summary>
Motivation: Existing VIO/SLAM tracking systems struggle with challenging real-world scenarios common in head-mounted applications such as high-intensity motion, dynamic occlusions, long tracking sessions, low-textured areas, adverse lighting, and sensor saturation. Current datasets inadequately cover these issues.

Method: The paper introduces the Monado SLAM dataset, which consists of real-world sequences captured from multiple virtual reality headsets, specifically designed to encompass challenging scenarios often encountered in head-mounted use cases.

Result: The Monado SLAM dataset has been created and released to provide a more comprehensive resource for evaluating and improving VIO/SLAM systems in challenging head-mounted tracking environments.

Conclusion: The Monado SLAM dataset, comprising real-world sequences from various VR headsets and released under a CC BY 4.0 license, is presented to address the limitations of existing datasets in handling challenging head-mounted tracking scenarios and to promote further research and development in VIO/SLAM.

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [6] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 本研究提出了一种基于围眼区域和CNN的性别分类方法，能够有效克服化妆和伪装的影响，在两个数据集上均取得了优异的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决化妆和伪装影响性别分类准确性的问题，本研究专注于利用围眼区域进行性别分类。

Method: 提出了一种利用颜色图像和卷积神经网络（CNN）对围眼区域进行性别分类的模型，并使用CVBL和Female and Male两个数据集进行了验证。

Result: 所提出的CNN模型在CVBL数据集上实现了99%的准确率，在Female and Male数据集上使用较少可学习参数（7,235,089）达到了96%的准确率，并通过多种评估指标和与现有方法的比较证明了其有效性。

Conclusion: 所提出的基于围眼区域的性别分类模型能够达到很高的准确率，在CVBL数据集上达到99%，在Female and Male数据集上达到96%，表明其在安全和监控等领域的实际应用潜力。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [7] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: WCS 是一种新的视频生成评估指标，通过物体持久性、关系稳定性、因果遵从性和闪烁惩罚等子指标来衡量视频的时间和物理一致性，并与人类判断保持一致。


<details>
  <summary>Details</summary>
Motivation: WCS 的提出是为了解决现有视频评估指标的不足，这些指标往往只关注视觉保真度或提示匹配度，而忽略了视频生成模型在保持连贯“世界”随时间变化的能力。

Method: WCS 整合了四个可解释的子组件——物体持久性、关系稳定性、因果遵从性和闪烁惩罚——每个组件都测量视频中时间与物理一致性的不同方面。这些子指标通过学习到的加权公式组合，以产生与人类判断一致的单一一致性分数。论文详细介绍了 WCS 的动机、计算方法以及如何使用人类偏好数据训练组合权重。

Result: 通过在 VBench-2.0、EvalCrafter 和 LOVE 等基准测试上进行实验验证，WCS 被证明与人类评估具有相关性，并且优于现有的评估指标（如 FVD、CLIPScore、VBench、FVMD）。

Conclusion: WCS 是一个新颖的、统一的视频生成模型评估指标，它强调生成视频的内部世界一致性，并与人类判断保持一致。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [8] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: GeoExplorer是一种主动地理定位（AGL）代理，它使用好奇心驱动的探索来提高在未知环境和目标定位中的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前AGL方法依赖于基于距离的奖励，在面对难以估计的距离、未见过的目标和环境时，鲁棒性和泛化能力会下降。GeoExplorer旨在解决这个问题。

Method: GeoExplorer采用好奇心驱动的探索机制，通过内在奖励来指导代理人的探索过程，而不是依赖于基于距离的奖励。

Result: GeoExplorer在四个AGL基准测试中进行了广泛的实验，证明了其在各种设置下，尤其是在定位不熟悉的目标和环境方面的有效性和泛化能力。

Conclusion: GeoExplorer通过结合好奇心驱动的探索，在各种AGL基准测试中表现出更强的鲁棒性和泛化能力，特别是在定位不熟悉的目标和环境方面。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [9] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: LiDAR 传感器常因物体特性或环境因素产生稀疏或错误的点云。为解决此问题，本文提出了概率点云（PPC）表示，为每个点引入不确定性属性。基于 PPC 的 3D 检测方法在各种挑战性场景下均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的 3D 处理流程在构建点云时没有保留原始测量中的不确定性信息，导致在真实世界的场景中（如长距离或低反照率物体）可能出现稀疏或错误的点云，从而影响下游感知模型的准确性。

Method: 提出了一种名为概率点云（PPC）的新型 3D 表示，其中每个点都包含一个概率属性，以封装原始测量中的不确定性。还介绍了利用 PPC 进行稳健 3D 对象检测的推理方法，这些方法可以作为 3D 推理管道中的轻量级即插即用模块。

Result: 通过仿真和真实捕获表明，PPC 3D 推理方法在具有挑战性的室内和室外场景中，在检测小型、远处和低反照率物体以及强环境光方面，优于使用 LiDAR 或相机-LiDAR 融合模型的几种基线方法。

Conclusion: PPC 3D 推理方法在具有挑战性的室内和室外场景中，在检测小型、远处和低反照率物体以及强环境光方面，优于使用 LiDAR 或相机-LiDAR 融合模型的几种基线方法。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [10] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 现有的医疗视觉语言模型严重偏向文本，忽视图像信息。我们提出了一种名为SMS的方法来量化这种偏见，发现在MIMIC-CXR和FairVLMed数据集上，模型在处理医学影像和文本报告时，对文本的依赖性很高，图像信息常常被忽略。


<details>
  <summary>Details</summary>
Motivation: 解决了现有视觉语言模型（VLMs）在整合医学影像和临床报告时存在偏向单一模态（尤其是文本）的问题，忽视了关键的视觉线索。

Method: 提出了一种名为选择性模态转移（SMS）的基于扰动的方法，通过系统地交换具有相反标签的样本的图像或文本，来量化模型对每个模态的依赖性，并评估了六个开源VLM在两个医学成像数据集上的表现和校准。

Result: 研究表明，所评估的模型普遍存在对文本输入的明显依赖，即使在存在互补视觉信息的情况下也依然如此。通过基于注意力的定性分析也证实了图像内容常常被文本细节所掩盖。

Conclusion: 该研究揭示了多模态医疗模型在整合视觉和文本线索时存在严重依赖文本信息的偏见，并强调了设计和评估真正整合两种模态信号的模型的重要性。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [11] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: This paper proposes a new method for real personality recognition (RPR) by simulating internal cognition from expressive behaviors. It uses a 2D Graph Neural Network (2D-GNN) to infer personality traits from a novel graph representation of the simulated cognition. The method outperforms existing approaches.


<details>
  <summary>Details</summary>
Motivation: Existing RPR solutions infer personality impressions from external observations of expressive behaviors, which deviate from real personalities and lead to inferior performance. The paper is motivated by the association between real personality and internal cognition underlying expressive behaviors.

Method: A novel RPR approach is proposed that simulates personalized internal cognition from audio-visual behaviors. This cognition is encoded as a graph with node and edge features, and a 2D-GNN is used for personality recognition. An end-to-end strategy jointly trains the cognition simulation, graph construction, and personality recognition modules.

Result: The proposed method achieves superior recognition performance by inferring real personality traits.

Conclusion: The proposed approach simulates personalized internal cognition to infer real personality traits, outperforming existing methods.

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [12] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: SAM-PTx是一种通过文本提示（CLIP衍生的文本嵌入）来增强SAM分割能力的参数高效方法，实验证明其在COD10K、COCO和ADE20K数据集上优于纯空间提示方法。


<details>
  <summary>Details</summary>
Motivation: 为了探索基于文本的语义提示在SAM中的潜力，以补充传统的空间提示。

Method: 提出了一种名为Parallel-Text的轻量级适配器设计，通过修改Transformer块的MLP并行分支，将文本嵌入注入SAM的图像编码器，同时保持大部分原始架构冻结。

Result: 在COD10K数据集以及COCO和ADE20K的低数据子集上进行的监督实验和消融实验表明，通过输入固定的文本嵌入可以提高分割性能，并且这是首次在COD10K数据集上使用文本提示进行分割的研究。

Conclusion: SAM-PTx通过在SAM的图像编码器中注入由CLIP衍生的文本嵌入作为类别级语义指导，实现了参数高效的SAM适应，从而在空间提示基础上提高了分割性能，为SAM的有效适应提供了一条实用且可扩展的路径。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [13] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 研究表明，在Few-Shot图像分类中加入物体位置信息可提升性能，Segment Anything Model或无监督提取方法可实现此效果。


<details>
  <summary>Details</summary>
Motivation: Few-Shot图像分类任务在处理包含多个物体或复杂背景的图像时，由于图像歧义性，性能会显著下降。需要在Few-Shot图像分类中引入额外信息来克服这一挑战。

Method: 通过在Few-Shot图像分类任务中引入物体局部位置信息来增强分类性能，并探索了使用Segment Anything Model和无监督前景物体提取方法来实现此目标。

Result: 在Few-Shot图像分类任务中，加入物体局部位置信息能够显著提高分类准确率。使用Segment Anything Model或无监督前景物体提取方法可以在很大程度上实现这种性能提升。

Conclusion: 该研究表明，在图像中加入物体局部位置的额外信息可以显著提高Few-Shot图像分类的性能，并且可以使用Segment Anything Model或完全无监督的前景物体提取方法来实现这一改进。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [14] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 提出了一种名为MSF-UM的多尺度融合U型Mamba模型，用于深度图超分辨率。该模型结合了Mamba的状态空间建模和CNN的局部特征提取能力，并通过彩色图像进行引导，实现了参数量减少和精度提升，泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 传统的卷积神经网络在处理长距离依赖和全局上下文信息方面存在局限性。Transformer虽然能模拟全局依赖，但其计算复杂度和内存消耗是二次方的，限制了其在高分辨率深度图处理上的应用。因此，需要一种能有效处理长距离依赖并保持全局上下文信息，同时计算效率高的方法来提升深度图的空间分辨率。

Method: 提出了一种新颖的引导式深度图超分辨率框架——多尺度融合U型Mamba（MSF-UM）模型。该模型将Mamba的高效状态空间建模能力集成到受彩色图像引导的多尺度U型融合结构中。该结构结合了残差密集通道注意力块和Mamba状态空间模块，融合了卷积层的局部特征提取能力和状态空间模型处理长距离依赖的优势。同时，模型采用多尺度跨模态融合策略，利用彩色图像的高频纹理信息指导深度图的超分辨率过程。

Result: 与现有主流方法相比，MSF-UM模型显著减少了模型参数数量，同时实现了更高的重建精度。在多个公开数据集上的广泛实验证明了该模型的有效性，特别是在大规模深度图超分辨率任务中表现出优异的泛化能力。

Conclusion: 提出的MSF-UM模型在参数量显著减少的情况下，实现了比现有主流方法更好的重建精度，并且在多项公开数据集上进行了验证，尤其在大规模深度图超分辨率任务中展现了出色的泛化能力。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [15] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: PointGauss 是一种新的点云引导框架，可实现高斯图元表示中的实时多目标分割，并引入了新的 DesktopObjects-360 数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多目标分割方面存在初始化时间长和多视图一致性有限的问题，本研究旨在解决这些挑战。

Method: PointGauss 框架，采用基于点云的 3D 高斯图元解码器和 GPU 加速的 2D 掩码渲染系统，实现了实时多目标分割。

Result: PointGauss 在多视图 mIoU 方面取得了 1.89% 至 31.78% 的性能提升，同时保持了计算效率。

Conclusion: PointGauss 通过直接解析高斯图元实现了高效的 3D 分割，并在多视图一致性和计算效率方面取得了显著的改进。同时，提出的 DesktopObjects-360 数据集为 3D 分割研究提供了全面的基准。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [16] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 提出了一种新颖的框架，通过混合、推荐和剪枝视觉投影仪专家来改进持续学习中的视觉-语言模型，以更好地处理语言指令。


<details>
  <summary>Details</summary>
Motivation: 最近的方法通过更新视觉投影仪来为新任务转换视觉信息，连接了预训练的视觉编码器和大型语言模型。然而，这种调整可能导致模型优先考虑视觉输入而非语言指令，尤其是在处理具有重复类型文本指令的学习任务时。

Method: 提出了一种新颖的框架，该框架基于语言模型的指令来调整视觉信息的翻译。引入了视觉投影仪混合机制，其中每个投影仪作为基于给定指令上下文的专门视觉到语言翻译专家来适应新任务。提出了一种专家推荐策略，用于将专家用于与先前学习的任务相似的任务。此外，还引入了专家剪枝，以减轻先前任务中累积激活的专家的使用所带来的干扰。

Result: 与现有方法相比，本方法在遵循指令的响应生成方面表现更优。

Conclusion: 本方法在多种视觉-语言任务的广泛实验中，通过生成遵循指令的响应，其性能优于现有的持续学习方法。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [17] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文对多模态指代分割领域进行了全面的 survey，总结了其背景、方法、挑战和应用，并提供了性能比较。


<details>
  <summary>Details</summary>
Motivation: 多模态指代分割在需要根据用户指令进行准确物体感知的实际应用中至关重要，并且在过去十年中得到了显著关注。

Method: 本文 survey 了多模态指代分割领域，总结了统一的元架构，回顾了针对图像、视频和 3D 场景的代表性方法，并讨论了广义指代表达式（GREx）方法。

Result: 本文对多模态指代分割进行了全面的 survey，包括背景、数据集、统一元架构、代表性方法（图像、视频、3D 场景）、GREx 方法、相关任务和应用，并提供了广泛的性能比较。

Conclusion: 本文全面 survey 了多模态指代分割（multimodal referring segmentation）领域，涵盖了背景、常用数据集、统一的元架构、针对图像、视频和 3D 场景的代表性方法、广义指代表达式（GREx）方法以应对现实世界的复杂性，以及相关任务和实际应用。文章还提供了标准基准上的广泛性能比较，并附有持续更新的研究论文链接。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [18] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 本文提出了一个包含14种挑战性场景的新基准，用于评估语义对应在不利条件下的鲁棒性。结果显示，现有方法和微调大型模型都会降低鲁棒性，DINO优于Stable Diffusion，且需要针对性设计鲁棒性增强策略。


<details>
  <summary>Details</summary>
Motivation: 语义对应是计算机视觉中的一个基本挑战，它为3D重建、物体跟踪和图像编辑等任务奠定了基础。尽管现有方法在受控和高质量的条件下表现出色，但其在不利条件下的鲁棒性研究不足。

Method: 构建了一个新的基准数据集，包含14种不同的挑战性场景，如几何畸变、图像模糊、数字伪影和环境遮挡，并在此数据集上对现有的语义对应方法进行了广泛的评估，同时还评估了常见的鲁棒性增强策略。

Result: 现有语义对应方法在不利条件下性能均有显著下降；微调大型视觉模型会降低其相对鲁棒性；DINO模型比Stable Diffusion具有更好的相对鲁棒性，融合两者可提高绝对鲁棒性；通用数据增强对提升语义对应鲁棒性效果不佳。

Conclusion: 现有方法在不利条件下都会出现明显的性能下降，虽然大型视觉模型可以提高整体鲁棒性，但微调会降低相对鲁棒性。DINO模型在相对鲁棒性方面优于Stable Diffusion，并且它们的融合在绝对鲁棒性方面表现更好。通用的数据增强对于提高语义对应鲁棒性是无效的，需要进行针对特定任务的设计。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [19] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 提出了一种结合空间自注意力和LSTM以及梯度相似性比较的联邦学习框架，用于处理分散、多样化的面部数据以检测驾驶员嗜睡。该框架在联邦学习设置中达到了89.9%的准确率，优于现有方法，并强调了其在智能交通系统中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 驾驶员嗜睡是导致交通事故的主要原因之一，也是造成道路死亡的罪魁祸首。然而，准确检测嗜睡仍然是一项艰巨的任务，特别是在现实世界中，来自不同个体的面部数据是分散且高度多样化的。本研究旨在提出一个能够有效处理异构和分散数据的嗜睡检测新框架。

Method: 提出了一种新颖的框架，集成了空间自注意力（SSA）机制和长短期记忆（LSTM）网络，以提取关键面部特征并提高检测性能。为了支持联邦学习，采用了梯度相似性比较（GSC）来选择最相关的训练模型进行聚合，从而提高全局模型的准确性和鲁棒性，同时保护用户隐私。此外，还开发了一个自定义工具来自动处理视频数据，提取帧、检测和裁剪面部，并应用旋转、翻转、亮度调整和缩放等数据增强技术。

Result: 实验结果表明，该框架在联邦学习设置中实现了89.9%的检测准确率，在各种部署场景下均优于现有方法。

Conclusion: 该框架在联邦学习环境中实现了89.9%的检测准确率，在各种部署场景下均优于现有方法，证明了其处理现实世界数据变异性的有效性，并突显了其在智能交通系统中通过早期可靠的嗜睡检测来提高道路安全方面的潜力。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [20] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: TITAN-Guide 是一种创新的方法，通过优化扩散潜在变量来改进文本到视频（T2V）扩散模型的引导过程，解决了现有方法的内存和控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有的免训练引导框架要么内存需求大，要么控制不佳，这限制了它们在文本到视频（T2V）扩散模型等高计算量控制扩散模型中的应用。

Method: 提出了一种名为 TITAN-Guide 的新方法，该方法通过前向梯度下降和各种方向指令来优化扩散潜在变量，以实现无需训练的引导。

Result: TITAN-Guide 在内存管理和 T2V 性能方面均优于现有方法，能在各种扩散引导基准测试中有效运行。

Conclusion: TITAN-Guide 克服了内存空间问题，并在引导过程中提供了比现有方法更优的控制效果。通过优化扩散潜在变量而不进行反向传播，该方法显著提高了文本到视频（T2V）扩散模型的性能，同时降低了内存需求。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [21] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 提出了一种用于多视图场景下可控行人视频编辑的框架，通过视频修复和人体运动控制技术，解决了自动驾驶中行人检测模型鲁棒性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中的行人检测模型由于训练数据中危险行人场景表示不足，往往缺乏鲁棒性。

Method: 通过整合视频修复和人体运动控制技术，首先识别多摄像头视图中的感兴趣行人区域，以固定比例扩展检测边界框，并在保持跨视图空间关系的同时将这些区域调整大小并拼接成统一的画布。然后应用二元掩码来指定可编辑区域，并在该区域内通过姿态序列控制条件来指导行人编辑，从而实现灵活的编辑功能，包括行人插入、替换和删除。

Result: 实验证明，该框架能够实现高质量的行人编辑，具有很强的视觉真实感、时空连贯性和跨视图一致性。

Conclusion: 该框架实现了高质量的行人编辑，具有很强的视觉真实感、时空连贯性和跨视图一致性。该方法为多视图行人视频生成提供了一种强大而通用的解决方案，在自动驾驶的数据增强和场景模拟方面具有广泛的应用潜力。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [22] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: AniMer+通过结合创新的ViT-MoE架构和扩散模型生成的合成数据集，实现了对哺乳动物和鸟类的统一姿态和形状重建，并在各种基准测试中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 为了在基础模型时代实现对不同动态对象的统一理解，从而增强空间智能。准确估计跨不同物种的动物姿态和形状对于生物学研究中的定量分析至关重要。然而，由于先前方法的网络容量有限以及全面的多物种数据集稀缺，这方面的研究尚处于探索阶段。

Method: 提出了一种名为AniMer+的框架，它是AniMer的扩展版本。AniMer+采用了高容量、家族感知的Vision Transformer（ViT），并结合了Mixture-of-Experts（MoE）设计，将网络层划分为特定类群（哺乳动物和鸟类）的组件以及类群共享组件。为了解决3D训练数据不足的问题，特别是鸟类数据，引入了一个基于扩散模型的条件图像生成流程，生成了CtrlAni3D和CtrlAVES3D两个大规模合成数据集。该模型在包含41.3k哺乳动物和12.4k鸟类图像（真实和合成数据）的集合上进行训练。

Result: AniMer+在重构哺乳动物和鸟类方面展现了优越的性能，优于现有方法，并在Animal Kingdom等具有挑战性的数据集上进行了验证。合成数据集CtrlAni3D和CtrlAVES3D对于提高模型性能起到了关键作用，特别是CtrlAVES3D是首个大规模3D标注的鸟类数据集。

Conclusion: AniMer+在哺乳动物和鸟类（aves）的重建方面实现了统一的方法。通过结合高容量、家族感知的ViT和MoE设计，以及利用扩散模型生成的大规模合成数据集（CtrlAni3D和CtrlAVES3D），该方法在各种基准测试中表现出优于现有方法的性能，尤其是在具有挑战性的Animal Kingdom数据集上。消融研究证实了网络架构和合成数据集在提高真实应用性能方面的有效性。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [23] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 为CSP工厂的航空影像创建了一个名为AerialCSP的合成数据集，以减少数据标注成本并提高模型性能。该数据集可用于模型预训练，从而提高故障检测能力，特别是对罕见缺陷的检测。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模型在处理CSP工厂的航空影像时泛化能力不足，因为该场景包含高反射表面和特定领域元素，而这些在通用数据集不常见。收集和标注真实数据成本高昂且耗时。

Method: 提出了一种名为AerialCSP的新型方法，该方法创建一个虚拟数据集来模拟CSP工厂的航空影像，目的是在部署前对模型进行预训练，从而减少对广泛手动标注数据的需求。

Result: 创建了一个名为AerialCSP的高质量合成数据集，用于CSP工厂的航空检查，提供了用于对象检测和图像分割的标注数据。对多个模型在AerialCSP上进行了基准测试，并证明了在AerialCSP上的预训练能显著提高真实世界故障检测的性能，尤其对罕见和小缺陷的检测。

Conclusion: 通过在AerialCSP上进行预训练，可以显著提高在真实世界中对CSP工厂进行故障检测的性能，尤其对于罕见和微小的缺陷，同时减少了对大量手动标注数据的需求。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [24] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 为了解决自动驾驶数据集中检索罕见的VRU行为边缘案例的挑战，我们提出了一个结合SMPL运动序列和视频帧的多模态检索框架，并构建了一个包含自动标记的运动和场景上下文描述的WayMoCo数据集，该框架在检索准确率上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在安全关键场景中必须可靠运行，特别是那些涉及弱势道路使用者（VRU）不寻常或复杂行为的场景。然而，在大型数据集中检索这些罕见的、长尾分布的人类行为边缘案例具有挑战性。

Method: 提出了一种新颖的、与上下文相关的运动检索框架，该框架结合了基于SMPL（蒙皮多人线性模型）的运动序列和相应的视频帧，并将它们编码到一个共享的多模态嵌入空间中，该空间与自然语言对齐。

Result: 所提出的框架能够通过文本查询可扩展地检索人类行为及其上下文，并在WayMoCo数据集上实现了比最先进模型高出27.5%的准确率。

Conclusion: 该方法通过结合SMPL运动序列和视频帧，并将其编码到共享的、与自然语言对齐的多模态嵌入空间中，实现了可扩展的、通过文本查询检索人类行为及其上下文的功能。在WayMoCo数据集上，该方法在运动-上下文检索方面的准确率比现有最先进模型高出27.5%。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [25] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的两阶段事件相机增强方法，通过振幅-相位纠缠和动态对齐融合策略，有效解决了现有方法的局限性，并在实验中取得了优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 现有事件相机增强方法未能充分利用不同传感模式的优势，将帧和事件直接输入单个模型，限制了性能。因此，有必要分析每种传感模式的作用，并解耦增强流水线。

Method: 论文提出了一种事件相机增强流水线，将其解耦为两个阶段：可见性恢复和结构精炼。在可见性恢复阶段，设计了一种基于傅里叶空间的振幅-相位纠缠网络。在结构精炼阶段，提出了一种具有动态对齐的融合策略，以解决两种传感模式之间的时间分辨率差异造成的空间不匹配问题。此外，通过空间频率插值模拟负样本，开发了一种对比损失函数。

Result: 实验证明，所提出的方法在图像增强方面优于最先进的模型。

Conclusion: 该方法优于现有技术水平。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [26] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: DocTron-Formula 是一个基于通用视觉-语言模型的OCR框架，配合CSFormula数据集，解决了科学文献中数学公式识别的挑战，达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的光学字符识别（OCR）技术在处理数学公式时面临挑战，因为数学内容具有结构多样性、复杂性和真实世界的变异性。通用视觉-语言模型也难以应对这些挑战。

Method: 提出了一种名为 DocTron-Formula 的统一框架，该框架基于通用的视觉-语言模型，无需专门的架构。同时，引入了一个名为 CSFormula 的大规模、多领域、结构复杂的数据集，涵盖行、段落和页面级别的公式。

Result: DocTron-Formula 在各种风格、科学领域和复杂布局中取得了最先进的性能，其准确性和鲁棒性均优于专门的模型，为复杂科学文档的自动理解树立了新范例。

Conclusion: DocTron-Formula 是一个统一的框架，它建立在通用的视觉-语言模型之上，无需专门的架构。该方法通过简单的监督微调，在各种风格、科学领域和复杂布局中实现了最先进的性能，超越了专门的模型，并为复杂科学文档的自动理解树立了新范例。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [27] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: IGL-Nav improves 3D-aware image-goal navigation by incrementally updating scene representation with feed-forward monocular prediction and using 3D Gaussian localization for efficient and accurate goal localization, outperforming existing methods and handling challenging scenarios.


<details>
  <summary>Details</summary>
Motivation: Conventional methods for visual navigation with an image as goal either rely on end-to-end RL learning or modular-based policy with topological graph or BEV map as memory, which cannot fully model the geometric relationship between the explored 3D environment and the goal image. Direct leveraging of 3DGS for image localization during agent exploration process is prohibitively inefficient due to computational intensity of 3DGS optimization and the large search space of 6-DoF camera pose.

Method: IGL-Nav incrementally updates the scene representation as new images arrive with feed-forward monocular prediction. It coarsely localizes the goal by leveraging the geometric information for discrete space matching, and finally solves the fine target pose with optimization via differentiable rendering.

Result: The proposed IGL-Nav outperforms existing state-of-the-art methods by a large margin across diverse experimental configurations. It can also handle the more challenging free-view image-goal setting and be deployed on real-world robotic platform using a cellphone to capture goal image at arbitrary pose.

Conclusion: IGL-Nav outperformed existing state-of-the-art methods by a large margin across diverse experimental configurations, can handle the more challenging free-view image-goal setting, and be deployed on real-world robotic platform using a cellphone.

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


### [28] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: 通过使用文本到视频模型生成合成数据来增强视频异常检测的训练数据集，以解决现实世界数据稀缺和标注成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的异常事件的稀有性、不可预测性和高昂的标注成本限制了视频异常检测（VAD）数据集的扩展，进而影响了现有模型的性能和泛化能力。

Method: 提出了一种生成式视频增强的弱监督视频异常检测（GV-VAD）框架，该框架利用文本条件视频生成模型来生成语义可控、物理上合理的合成视频，以低成本增强训练数据，并采用合成样本损失缩放策略来控制生成样本的影响以进行有效训练。

Result: 通过实验证明，该框架在UCF-Crime数据集上的表现优于最先进的方法。

Conclusion: 该研究提出的GV-VAD框架在UCF-Crime数据集上超越了现有方法。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [29] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: Personalization guidance is a new method for text-to-image diffusion models that balances subject fidelity and text editability by using an unlearned weak model and dynamic weight interpolation, outperforming existing methods like CFG and AG.


<details>
  <summary>Details</summary>
Motivation: Fine-tuning pre-trained text-to-image diffusion models with few images introduces a trade-off between target distribution alignment (subject fidelity) and preserving the original model's broad knowledge (text editability). Existing methods like CFG and AG fail to effectively guide the output toward a well-balanced space.

Method: Personalization guidance, which leverages an unlearned weak model conditioned on a null text prompt and dynamically controls the extent of unlearning through weight interpolation between pre-trained and fine-tuned models during inference.

Result: Experimental results show that the proposed personalization guidance improves text alignment and target distribution fidelity, and integrates seamlessly with various fine-tuning strategies.

Conclusion: Personalization guidance effectively balances target distribution alignment and preservation of the original model's broad knowledge, improving text alignment and target distribution fidelity without additional computational overhead.

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [30] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 本研究提出了一种使用衍射光栅的相机光谱灵敏度校准方法，该方法实用且准确，仅需一个现成的衍射光栅片。


<details>
  <summary>Details</summary>
Motivation: 准确校准相机光谱灵敏度对于颜色校正、光照估计和材料分析等各种计算机视觉任务至关重要。

Method: 通过捕获直射光照及其通过光栅片的衍射图案的图像，以闭式解的形式估计相机光谱灵敏度和衍射光栅参数。

Result: 实验在合成和真实数据上进行，结果表明本方法优于传统的基于参考目标的传统方法，证明了其有效性和实用性。

Conclusion: 本研究提出了一种使用衍射光栅的相机光谱灵敏度校准的实用且准确的方法，该方法仅需一个未经校准的衍射光栅片，无需专业的窄带滤光器或已知光谱反射率的参考目标。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [31] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: 本文提出了一种新的多目标跟踪方法SG-LKF，通过考虑主车速度来提高跟踪稳定性和准确性，并在多项基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于检测的多目标跟踪方法忽略了主车速度变化引起的观测噪声和参考系变化，导致在高速动态场景下的跟踪稳定性和准确性下降。本文旨在解决这一问题，研究主车速度在多目标跟踪中的关键作用。

Method: 提出了一种由MotionScaleNet (MSNet)驱动的Speed-Guided Learnable Kalman Filter (SG-LKF)，MSNet能够自适应地预测SG-LKF的关键参数。此外，还引入了一种自监督轨迹一致性损失，并与语义和位置约束联合优化，以增强帧间关联和轨迹连续性。

Result: SG-LKF在KITTI 2D MOT上取得了79.59%的HOTA，在KITTI 3D MOT上取得了82.03%的HOTA，在nuScenes 3D MOT上比SimpleTrack的AMOTA高出2.2%。

Conclusion: SG-LKF在KITTI 2D MOT、KITTI 3D MOT和nuScenes 3D MOT上均取得了优于现有方法的性能，证明了其在多目标跟踪领域的有效性。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [32] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: CoST是一种高效的协作感知方法，通过统一的时空聚合来提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法将多智能体融合和多时间融合分开处理导致的效率和性能问题，并解决单智能体面临的遮挡和小感知范围等问题。

Method: 提出了一种将来自不同智能体（空间）和不同时间（时间）的观测聚合到统一的时空空间中的高效协作感知方法，称为CoST（Collaborative perception with Spatio-temporal Transformer）。

Result: CoST在效率和准确性方面均有所提高，减少了传输带宽，并能提高先前方法的准确性。

Conclusion: CoST通过将多智能体和多时间信息融合到统一的稀疏时空聚合中，提高了效率和准确性，并且可以兼容大多数先前的方法。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [33] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: 提出一种基于机器学习（LDA、SVM、KNN）的蜂蜜植物来源自动分类方法，通过类变换和特征提取优化，在HSI数据集上取得了95.13%（图像）和92.80%（实例）的准确率。


<details>
  <summary>Details</summary>
Motivation: 自动分类蜂蜜的植物来源，以提高分类效率和准确性。

Method: 该方法包括三个主要步骤：数据集准备（使用类变换最大化类间可分离性）、特征提取（使用线性判别分析LDA降维和提取相关特征）和分类（使用支持向量机SVM和K近邻KNN模型）。

Result: 在标准蜂蜜高光谱成像（HSI）数据集上，该系统实现了95.13%的基于高光谱图像的分类准确率和92.80%的基于高光谱实例的分类准确率，达到了最先进的水平。

Conclusion: 该研究提出了一种基于机器学习的自动分类蜂蜜植物来源的方法，并取得了先进的分类精度。

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [34] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: 提出了一种名为SparseRecon的新型神经隐式重建方法，通过结合特征一致性损失和不确定性引导的深度约束，解决了稀疏视图三维重建的挑战，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于泛化的方法在未见过的视图上泛化能力不足，而基于过拟合的方法的重建质量受限于有限的几何线索。为了解决这些问题，需要一种能够处理稀疏视图并提高重建质量的方法。

Method: 提出了一种新颖的神经隐式重建方法SparseRecon，结合了基于体积渲染的特征一致性和基于不确定性的深度约束。具体来说，通过引入跨视图的特征一致性损失来约束神经隐式场，以解决视图信息不足导致的歧义问题，并保证重建结果的完整性和光滑性。此外，采用不确定性引导的深度约束来补充特征一致性损失，特别是在遮挡和特征不明显的情况下，以恢复几何细节并提高重建质量。

Result: 实验结果表明，本方法在稀疏视图输入的条件下，尤其是在视图重叠较少的情况下，相比于现有最先进的方法，能够生成高质量的几何形状。

Conclusion: 本方法在稀疏视图输入下能够生成高质量的几何形状，尤其是在视图重叠较少的情况下，优于现有方法。

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [35] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: Representation Shift is a new method for token compression that works with FlashAttention and speeds up models.


<details>
  <summary>Details</summary>
Motivation: To reduce the computation cost of self-attention, prior works have proposed token compression techniques that drop redundant or less informative tokens. Meanwhile, fused attention kernels such as FlashAttention have been developed to alleviate memory overhead by avoiding attention map construction and its associated I/O to HBM. However, this makes it incompatible with most training-free token compression methods, which rely on attention maps to determine token importance.

Method: Representation Shift, a training-free, model-agnostic metric that measures the degree of change in each token's representation. This seamlessly integrates token compression with FlashAttention, without attention maps or retraining. Our method further generalizes beyond Transformers to CNNs and state space models.

Result: Representation Shift enables effective token compression compatible with FlashAttention, yielding significant speedups of up to 5.5% and 4.4% in video-text retrieval and video QA, respectively.

Conclusion: Representation Shift

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [36] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt是一种新的视频长时动作预测方法，通过结合前向和后向预测以及大型语言模型，提升了预测精度。


<details>
  <summary>Details</summary>
Motivation: 传统的视频长时动作预测方法由于其单向性，难以捕捉场景中语义上不同的子动作，限制了性能。

Method: 提出了一种名为BiAnt的方法，该方法结合了前向预测和后向预测，并利用大型语言模型来克服传统方法单向性的局限性。

Result: 在Ego4D数据集上的实验结果表明，BiAnt在编辑距离方面相比基线方法有所改进。

Conclusion: BiAnt通过结合前向预测和后向预测，并利用大型语言模型，在Ego4D数据集上显著提高了长时动作预测的性能，在编辑距离方面优于基线方法。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [37] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 为了解决海洋油气管道焊接缺陷检测的挑战，本研究提出了Adapt-WeldNet，一个能优化检测性能的自适应框架，并引入了DDIA，一个利用XAI和专家验证来增强模型可解释性和可信赖性的框架。


<details>
  <summary>Details</summary>
Motivation: 传统的无损检测方法难以检测海洋和陆地环境中管道系统的细微或内部焊接缺陷，而现有的基于神经网络的方法缺乏可解释性，引发了部署安全担忧。因此，需要开发一种能够提高检测性能和可解释性的自适应焊接缺陷检测框架。

Method: 本研究提出Adapt-WeldNet框架，通过系统评估不同的预训练模型、迁移学习策略和自适应优化器来寻找最优模型和超参数。同时，提出Defect Detection Interpretability Analysis (DDIA)框架，利用Grad-CAM和LIME等XAI技术，并结合ASNT NDE Level II专业人士的领域特定评估进行验证，引入Human-in-the-Loop (HITL)方法，旨在提升系统的透明度和可信赖AI原则。

Result: Adapt-WeldNet能够识别出性能最优的模型和超参数，从而优化缺陷检测能力。DDIA框架利用XAI技术和专家验证，增强了检测系统的透明度，确保了系统的可靠性、公平性和可问责性。

Conclusion: 该研究通过Adapt-WeldNet和DDIA框架，显著提高了焊接缺陷检测的性能和可解释性，增强了自动化决策的可靠性、公平性和可问责性，最终提升了海洋和陆地环境油气管道焊接检测系统的信任度、安全性和可靠性。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [38] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: MVHybrid 是一种结合了 SSM 和 ViT 的混合骨干架构，旨在通过改进形态模式捕捉能力，提升病理视觉基础模型在临床应用中的表现，特别是在基因表达预测方面。


<details>
  <summary>Details</summary>
Motivation: 为了克服空间转录组学成本高和技术复杂性的限制，并解决现有基于 ViT 的病理视觉基础模型（VFMs）在捕捉与分子表型相关的低频、细微形态模式方面表现不足的问题。

Method: 通过结合状态空间模型（SSMs）和 Vision Transformer（ViT），提出了一种名为 MVHybrid 的混合骨干架构。该模型在相同的结直肠癌数据集上使用 DINOv2 自监督学习方法进行预训练，并在随机分割和留一研究（LOSO）评估中进行了比较。

Result: 在 LOSO 评估中，MVHybrid 的相关性比表现最佳的 ViT 高出 57%，与随机分割相比，性能下降减少了 43%，在基因表达预测方面表现出优越的性能和鲁棒性。

Conclusion: MVHybrid 作为下一代病理视觉基础模型骨干，在基因表达预测、分类、图块检索和生存预测等下游任务中展现出与 ViT 相当或更优的性能，并具有更高的鲁棒性。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [39] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: Cued-Agent 是首个用于自动手语识别 (ACSR) 的协作多主体系统。它结合了手部和唇部识别、手语提示解码以及音素到单词的转换，并使用了包含 14 名用户的扩展数据集进行训练。实验证明，Cued-Agent 在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统自动手语识别方法在处理手部和唇部运动的时间不同步问题时，由于数据可用性有限，难以充分训练融合机制，导致性能不佳。多主体系统在处理此类复杂任务方面显示出潜力。

Method: 提出了一种名为 Cued-Agent 的协作多主体系统，集成了手部识别、唇部识别、手语提示解码和音素到单词的自我纠正转换四个子代理，以实现自动手语识别。

Result: Cued-Agent 在正常人和听障人士的场景中均优于现有技术。

Conclusion: Cued-Agent 在正常人和听障人士的场景中均优于现有技术。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [40] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: DAPT通过解耦视觉模态并进行对称的跨模态对齐，解决了提示调优中的信息不对称问题，并利用正则化增强了对目标区域的关注，从而提升了模型在各项视觉-语言任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的提示调优（PT）方法在视觉-语言模型中存在信息不对称问题，即视觉模态比面向对象的文本模态包含更多信息，这可能导致模型注意力偏差，仅关注背景区域。

Method: 提出了一种名为DAPT的提示调优框架，其核心思想是先解耦再对齐。具体来说，DAPT将视觉模态分解为前景和背景表示，并分别与文本模态（前景文本和手工设计的背景类）进行对齐。此外，还引入了视觉拉推正则化，以增强模型对感兴趣区域的关注。

Result: DAPT在少样本学习、基础到新颖泛化和数据高效学习等任务中均表现出优越的性能，并在多个基准测试中取得了领先结果。

Conclusion: DAPT通过解耦-对齐范式和视觉拉推正则化，有效解决了提示调优中的信息不对称问题，在少样本学习、基础到新颖泛化和数据高效学习方面取得了优于现有方法的性能。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [41] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出一种结合RGB外观特征和光流残差的伪造视频检测方法，以解决现有方法在捕捉AI生成视频细粒度时间不一致性方面存在的不足。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成视频具有高视觉保真度和连贯运动，导致现有伪造检测方法难以捕捉细粒度的时间不一致性。

Method: 提出一个利用时空一致性检测伪造视频的框架，结合RGB外观特征和光流残差。模型采用双分支架构，一个分支分析RGB帧以检测外观伪影，另一个分支处理光流残差以揭示由不完美时间合成引起的细微运动异常。

Result: 在文本到视频和图像到视频任务以及十个不同的生成模型上进行了广泛的实验，证明了该方法的鲁棒性和强大的泛化能力。

Conclusion: 该方法通过结合RGB外观特征和光流残差来利用时空一致性，有效检测各种伪造视频。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [42] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: iSafetyBench 是一个用于评估工业安全视频理解的新基准，现有模型表现不佳，需要更强大的安全模型。


<details>
  <summary>Details</summary>
Motivation: 目前的视觉-语言模型在工业高风险领域的应用仍有待探索，而识别常规操作和安全关键异常在工业环境中至关重要。因此，需要一个专门的基准来评估和改进模型在这些方面的能力。

Method: 提出 iSafetyBench，一个包含 1100 个真实工业场景视频片段的新型视频-语言基准，并标注了涵盖 98 种常规动作和 67 种危险动作的开放词汇、多标签动作标签。每个视频片段都配有单标签和多标签的单项选择题，用于在标准和安全关键情境下对视觉-语言模型进行细粒度评估。评估了八个最先进的视频-语言模型在零样本条件下的表现。

Result: 尽管评估的八个最先进的视觉-语言模型在现有视频基准上表现良好，但它们在 iSafetyBench 上表现不佳，尤其是在识别危险活动和处理多标签场景时，这表明在工业安全应用方面存在显著的性能差距。

Conclusion: 目前的视觉-语言模型在工业安全领域存在显著的性能差距，尤其是在识别危险活动和多标签场景方面，这凸显了开发更强大、更注重安全的模型以满足工业应用需求的必要性。iSafetyBench 是一个旨在推动该领域进步的开创性测试平台。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [43] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: Sari Sandbox is a realistic 3D retail simulation for training embodied agents, featuring interactive items and a dataset of human demonstrations for benchmarking against human performance.


<details>
  <summary>Details</summary>
Motivation: Addressing a gap in retail-specific sim environments for embodied agent training.

Method: The paper presents Sari Sandbox, a high-fidelity, photorealistic 3D retail store simulation for benchmarking embodied agents against human performance in shopping tasks. It features over 250 interactive grocery items across three store configurations, controlled via an API. It supports both virtual reality (VR) for human interaction and a vision language model (VLM)-powered embodied agent. The paper also introduces SariBench, a dataset of annotated human demonstrations across varied task difficulties.

Result: Sari Sandbox features over 250 interactive grocery items across three store configurations, controlled via an API. It supports both virtual reality (VR) for human interaction and a vision language model (VLM)-powered embodied agent. SariBench is a dataset of annotated human demonstrations across varied task difficulties.

Conclusion: The sandbox enables embodied agents to navigate, inspect, and manipulate retail items, providing baselines against human performance. The paper concludes with benchmarks, performance analysis, and recommendations for enhancing realism and scalability.

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [44] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: "介绍了一种新的视频恢复方法，通过DEI指数量化动态强度，并使用PMR框架分阶段恢复视频，能够有效处理高湍流和复杂动态场景。"


<details>
  <summary>Details</summary>
Motivation: "为了解决大气湍流引起的几何畸变和模糊问题，以及现有方法在恢复边缘细节和消除混合畸变方面的不足，特别是在强湍流和复杂动态条件下。"

Method: "提出了一种动态效率指数（DEI）来量化视频动态强度，并引入了一个物理模型驱动的多阶段视频恢复（PMR）框架，该框架包含三个阶段：倾斜校正、运动分割增强和去模糊。PMR采用轻量级骨干网络和分阶段联合训练，以确保效率和高质量恢复。"

Result: "实验结果表明，所提出的方法能够有效抑制运动拖尾伪影，恢复边缘细节，并具有强大的泛化能力，尤其是在高湍流和复杂动态的真实场景中。"

Conclusion: "该方法有效抑制了运动拖尾伪影，恢复了边缘细节，并表现出强大的泛化能力，特别是在高湍流和复杂动态的真实场景中。代码和数据集将公开提供。"

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [45] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: Sortblock通过智能缓存和跳过计算来加速DiT，速度加倍且质量损失小。


<details>
  <summary>Details</summary>
Motivation: 现有的无训练加速方法通常复用固定时间步或层的中间特征，忽略了跨去噪阶段和Transformer块的语义焦点演变，导致Diffusion Transformers（DiT）存在高推理延迟的问题，限制了其在实时场景的应用。

Method: Sortblock是一个无训练的推理加速框架，通过根据相邻时间步之间的相似性动态缓存块级特征。它通过对残差的演变进行排序，自适应地确定重计算比率，选择性地跳过冗余计算。此外，该框架还引入了一个轻量级的线性预测机制来减少跳过的块中累积的误差。

Result: 实验证明，Sortblock在各种任务和DiT架构上实现了超过2倍的推理加速，且输出质量仅有很小的下降。

Conclusion: Sortblock通过动态缓存块级特征并根据残差演变情况自适应地确定重计算比率，实现了超过2倍的推理加速，同时保持了生成质量，为加速扩散模型提供了一个有效且通用的解决方案。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [46] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: DC-AE 1.5 通过结构化潜在空间和增强扩散训练，提升了高分辨率扩散模型的性能和训练速度。


<details>
  <summary>Details</summary>
Motivation: 为了解决增加自编码器潜在通道数以提高重建质量但导致扩散模型收敛缓慢、生成质量下降的问题，以及现有方法在更高空间压缩比下性能受限的挑战。

Method: 本文提出了一种名为 DC-AE 1.5 的深度压缩自编码器新家族，并引入了两种创新技术：1. 结构化潜在空间：通过训练将潜在空间组织成特定结构，使前置通道捕获对象结构，后置通道捕获图像细节。2. 增强扩散训练：在对象潜在通道上增加额外的扩散训练目标，以加速收敛。

Result: DC-AE 1.5 实现了比 DC-AE 更快的收敛速度和更好的扩散模型扩展结果。在 ImageNet 512x512 数据集上，DC-AE-1.5-f64c128 的图像生成质量优于 DC-AE-f32c32，并且训练速度快 4 倍。

Conclusion: DC-AE 1.5 家族通过结构化潜在空间和增强扩散训练，实现了比 DC-AE 更快的收敛速度和更好的扩散模型性能，在 ImageNet 512x512 上，DC-AE-1.5-f64c128 的图像生成质量优于 DC-AE-f32c32，且速度快 4 倍。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [47] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: This paper improves video outpainting by using inpainting models and a new hierarchical discriminator with a specialized loss function, resulting in better quality than previous methods.


<details>
  <summary>Details</summary>
Motivation: Existing video outpainting methods, which focus on background generation, are ineffective and often produce blurry results when extended to outpainting tasks. This paper addresses the limitation of directly applying or fine-tuning inpainting models by incorporating object flow learning and reconstruction capabilities, and by introducing a discriminator capable of assessing perceptual quality.

Method: A hierarchical discriminator is introduced to address the lack of perceptual quality assessment in video outpainting fine-tuning. This discriminator differentiates adversarial training objectives into global and local goals. A specialized outpainting loss function is also developed, leveraging both local and global features from the discriminator.

Result: The proposed method, utilizing a hierarchical discriminator and specialized outpainting loss, enhances the generator's ability to produce visually appealing and globally coherent outpainted scenes. It outperforms state-of-the-art methods quantitatively and qualitatively.

Conclusion: Video outpainting is improved by using inpainting models with a focus on object flow and reconstruction. A hierarchical discriminator and specialized outpainting loss function enhance visual appeal and global coherence, outperforming existing methods.

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [48] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: UIS-Mamba 是首个基于 Mamba 的水下实例分割模型，通过动态树扫描（DTS）和隐藏状态削弱（HSW）模块解决了水下成像的挑战，在公开数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的固定块扫描机制在处理水下色彩失真和模糊实例边界等问题时，无法保持扫描实例的内部连续性，并且复杂水下背景的隐藏状态会抑制对实例的理解。因此，需要一种新的方法来解决这些挑战。

Method: 提出了一种基于 Mamba 的水下实例分割模型 UIS-Mamba，并设计了动态树扫描（DTS）和隐藏状态削弱（HSW）两个创新模块。DTS 模块通过允许块动态偏移和缩放来保持实例内部特征的连续性，并提供动态局部感受野。HSW 模块通过基于 Ncut 的隐藏状态削弱机制来抑制复杂背景的干扰，并将状态传播的信息流有效地集中到实例本身。

Result: UIS-Mamba 在 UIIS 和 USIS10K 数据集上取得了最先进的性能。

Conclusion: UIS-Mamba 在 UIIS 和 USIS10K 数据集上实现了最先进的性能，同时保持了较少的参数量和计算复杂度。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [49] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 为了解决现有方法在理解人机交互（HOI）方面的局限性，我们提出了一种结合物理先验知识和多区域修复技术的新方法，通过定制化去噪策略提升了物体补全的准确性和真实感，并在HOI场景中取得了优于现有方法的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如使用预训练的扩散模型）在动态场景中生成合理补全的能力有限，因为它们对人机交互（HOI）的理解有限。为了解决这个问题，我们开发了一种新方法。

Method: 本方法结合了物理先验知识（包括人体拓扑和接触信息）以及一种专门针对HOI的多区域修复技术。通过定义主要区域（遮挡物体最可能出现）和次要区域（遮挡不太可能出现），并结合定制化的去噪策略，在扩散模型中实现了跨区域的处理。

Result: 实验结果表明，我们提出的方法在HOI场景中的表现显著优于现有方法。此外，我们的流程在没有真实接触注释的情况下也表现出鲁棒性，这拓宽了其在3D重建和新视角/姿态合成等任务中的应用前景。

Conclusion: 通过结合物理先验知识和针对人机交互（HOI）的多区域修复技术，我们开发了一种新方法，该方法在HOI场景中显著优于现有方法，使机器感知更接近于对动态环境的类人理解。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [50] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: 为了解决管道结构分割（TSS）在跨域应用中因域偏移导致性能下降的问题，我们提出了TopoTTA。该框架通过TopoMDCs增强拓扑表示，并通过TopoHG策略和伪标签对齐提高拓扑连续性。实验证明TopoTTA能显著提升性能，平均clDice提升31.81%。


<details>
  <summary>Details</summary>
Motivation: 管道结构分割（TSS）在血流动力学分析和路径导航等领域至关重要。然而，域偏移是TSS面临的主要挑战，它会导致在未见过的目标域上的性能下降。与其它分割任务相比，TSS对域偏移更敏感，因为拓扑结构的变化会影响分割的完整性，而区分前景和背景的局部特征（如纹理和对比度）的变化会进一步破坏拓扑连续性。

Method: TopoTTA框架包含两个阶段：第一阶段使用提出的拓扑元差异卷积（TopoMDCs）来适应跨域拓扑差异，增强拓扑表示而不改变预训练参数；第二阶段通过新颖的拓扑困难样本生成（TopoHG）策略和在生成伪断裂区域的困难样本上进行伪标签预测对齐，来提高拓扑连续性。

Result: 在四个场景和十个数据集上的广泛实验表明，TopoTTA在处理拓扑分布偏移方面非常有效，clDice平均提升了31.81%。TopoTTA还可以作为即插即用TTA解决方案应用于基于CNN的TSS模型。

Conclusion: 该研究提出了首个专门用于管道结构分割（TSS）的测试时域自适应（TTA）框架——TopoTTA，以解决跨域迁移中存在的域偏移问题，特别是在拓扑结构和局部特征方面的影响。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [51] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: SDMatte是一个创新的交互式抠图模型，它利用扩散模型的强大能力，通过视觉提示驱动交互，并结合坐标嵌入和掩码自注意力机制，显著提高了在边缘区域细节提取方面的性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 最近的交互式抠图方法虽然在捕捉物体主要区域方面表现令人满意，但在提取边缘区域的细节方面存在不足。而经过海量图像-文本对训练的扩散模型在建模复杂数据分布、合成逼真纹理细节以及文本驱动交互方面表现出色，使其成为交互式抠图的一个有吸引力的解决方案。

Method: SDMatte模型，一种由扩散模型驱动的交互式抠图模型。该模型利用扩散模型的强大先验知识，将文本驱动的交互能力转化为视觉提示驱动的交互能力，并实现了以下创新：1. 整合了视觉提示的坐标嵌入和目标对象的透明度嵌入到U-Net中，提高了模型对空间位置和透明度信息的敏感度。2. 提出了一种掩码自注意力机制，使模型能够专注于由视觉提示指定的区域，从而获得更好的性能。

Result: 通过在多个数据集上进行的大量实验，证明了SDMatte方法的优越性能，验证了其在交互式抠图方面的有效性。

Conclusion: SDMatte在多个数据集上的广泛实验证明了其在交互式抠图方面的优越性能和有效性。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [52] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: AutoDebias框架通过利用视觉-语言模型和CLIP引导的训练，自动识别和减轻文本到图像模型中的社会偏见，即使是微妙和重叠的偏见也能有效处理，并且不会影响图像质量。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型经常会产生与社会偏见相关的刻板印象，即使在提示中没有提及这些属性。现有的偏见消除方法在处理微妙或重叠偏见方面存在局限性，因此需要一种能够自动识别和减轻这些偏见的新方法。

Method: AutoDebias框架利用视觉-语言模型检测偏见视觉模式，并通过生成包容性替代提示来构建公平性指南，以促进更公平的输出，同时通过CLIP引导的训练过程来保持原始模型的图像质量和多样性。

Result: AutoDebias在包含25个以上偏见场景的基准测试中表现出色，检测有害模式的准确率为91.6%，并将有偏见的输出从90%降低到可忽略的水平，同时保持了原始模型的视觉保真度。

Conclusion: AutoDebias框架能够自动识别和减轻文本到图像生成模型中的有害偏见，即使在存在微妙或重叠偏见的情况下也能有效处理，同时保持图像质量和多样性。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [53] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: CLIPTime 是一个结合图像和文本信息的多模态模型，用于预测真菌生长的阶段和时间，解决了现有模型在处理生物生长时间动态方面的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉-语言模型在捕捉生物生长的时间动态方面能力有限的问题，该研究旨在提升模型在处理时间序列生物学数据方面的能力。

Method: 提出了一种名为 CLIPTime 的多模态、多任务框架，该框架基于 CLIP 架构，能够从图像和文本输入预测真菌生长的发育阶段和相应的时间戳。CLIPTime 在训练和评估中采用了合成的真菌生长数据集，并进行分类和回归任务，同时提出了自定义的评估指标（如时间准确性和回归误差）来评估时间感知预测的精度。

Result: CLIPTime 在预测离散生长阶段和连续时间戳方面表现出色，实验结果表明该模型能有效模拟生物进程。

Conclusion: CLIPTime 框架能够有效地模拟生物生长过程，并产生可解释的、与时间相关的输出，展示了视觉-语言模型在实际生物监测应用中的潜力。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [54] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: 由于数据错位导致的病态问题，多光谱和高光谱图像融合（MHIF）任务很困难。我们提出了PIF-Net，一个结合了病态先验和可逆Mamba架构的框架，以提高图像质量。通过感知低秩适应模块，该模型能够动态校准特征并保持轻量化。实验证明PIF-Net优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多光谱和高光谱图像融合（MHIF）的目的是生成同时具有丰富的光谱信息和精细空间细节的高质量图像。然而，由于光谱和空间信息之间固有的权衡以及观测数据的有限性，这项任务本质上是病态的。以往的研究未能有效解决由数据错位引起的病态问题。

Method: 提出了一种名为PIF-Net的融合框架，该框架明确结合了病态先验来有效融合多光谱图像和高光谱图像。该方法基于可逆Mamba架构，并在特征变换和融合过程中保持信息一致性，确保了稳定的梯度流和过程可逆性。此外，引入了一种名为“感知低秩适应”的新型融合模块，该模块在保持模型轻量化的同时，动态校准了光谱和空间特征。

Result: PIF-Net在保持模型效率的同时，在图像恢复性能方面取得了显著的进步。

Conclusion: PIF-Net在多个基准数据集上的广泛实验表明，与当前最先进的方法相比，PIF-Net在保持模型效率的同时，在图像恢复性能方面取得了显著的进步。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [55] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: SeTe-VSR是一种新的视频超分辨率方法，通过在潜在扩散空间中结合语义和时间引导，解决了现有方法在保真对齐和时间一致性方面的挑战，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视频超分辨率模型在控制生成过程方面存在局限，难以在保持时间一致性的同时，实现与低分辨率输入的保真对齐。

Method: 提出了一种名为SeTe-VSR的新方法，该方法结合了语义和时间引导，在潜在扩散空间中进行视频超分辨率。通过整合高层语义信息以及空间和时间信息，实现了恢复细节与保持时间一致性之间的平衡。

Result: SeTe-VSR能够无缝地平衡恢复精细细节和保持时间连贯性，不仅保留了高真实度的视觉内容，还显著提高了保真度。

Conclusion: SeTe-VSR在细节恢复和感知质量方面优于现有方法，有效解决了复杂视频超分辨率任务中的挑战。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [56] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: HyPCV-Former是一种用于3D点云视频异常检测的双曲时空Transformer，通过在洛伦兹双曲空间中嵌入特征并使用HMHA机制来学习时空依赖性，从而克服了传统方法的局限性，并在多个数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的视频异常检测方法在RGB或深度域中利用欧几里得表示，但这些嵌入在捕获分层事件结构和时空连续性方面存在固有局限性。为了解决这些问题，提出了一种用于3D点云视频异常检测的双曲时空Transformer。

Method: HyPCV-Former是一种新颖的双曲时空Transformer，用于3D点云视频中的异常检测。该方法首先通过点云提取器从点云序列中提取每帧空间特征，然后将其嵌入到洛伦兹双曲空间中，以捕捉事件潜在的层次结构。通过引入双曲多头自注意力（HMHA）机制来模拟时间动态，该机制利用洛伦兹内积和曲率感知softmax在非欧几里得几何下学习时间依赖性。所有特征变换和异常评分均在完整的洛伦兹空间中进行。

Result: HyPCV-Former在TIMo数据集上提高了7%，在DAD数据集上提高了5.6%，在多个异常类别上实现了最先进的性能。

Conclusion: HyPCV-Former在多个异常类别上取得了最先进的性能，在TIMo数据集上提高了7%，在DAD数据集上比基准提高了5.6%。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [57] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 该研究提出了 EgoMask，首个用于 egocentric 视频细粒度时空定位的像素级基准，并创建了 EgoMask-Train 训练数据集。该研究分析了 egocentric 和 exocentric 视频的差异，并展示了其方法在提高 egocentric 视频理解方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 针对现有研究在 egocentric 视频设置方面探索不足的问题，以及 egocentric 视频在增强现实和机器人等应用中的日益增长的重要性，本文旨在解决 egocentric 视频和 exocentric 视频之间的差异，以及由此带来的挑战。

Method: 提出了一种名为 EgoMask 的像素级基准，用于 egocentric 视频中的细粒度时空定位。该基准是通过自动注释流程构建的，该流程对短、中、长期视频中的指称表达和对象掩码进行注释。此外，还创建了一个大规模的训练数据集 EgoMask-Train 以促进模型开发。

Result: 实验证明，最先进的时空定位模型在 EgoMask 基准上表现不佳，但在 EgoMask-Train 上进行微调可显著提高性能，同时保持在 exocentric 数据集上的性能。

Conclusion: 该研究为 egocentric 视频理解提供了基础资源和见解，推动了该领域的发展。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [58] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: LAMIC 是一个无需训练的多图像组合框架，通过创新的注意力机制实现了先进的布局控制和图像一致性。


<details>
  <summary>Details</summary>
Motivation: 在可控图像合成领域，从多个参考图像生成连贯、一致且具有空间布局意识的图像仍然是一个挑战。

Method: LAMIC 是一个基于 MMDiT 模型、无需训练的布局感知多图像组合框架，通过引入群组隔离注意力和区域调制注意力两种即插即用注意力机制，增强实体解耦并实现感知布局生成。

Result: LAMIC 在 ID-S、BG-S、IN-R 和 AVG 分数上始终优于现有的多参考基线，并在复杂的组合任务中取得了最佳的 DPG 分数，展示了其强大的零样本泛化能力。

Conclusion: LAMIC 提出了一种新的框架，用于在无需训练的情况下，将单参考扩散模型扩展到多参考图像组合场景，实现了最先进的性能，并在身份保持、背景保持、布局控制和提示遵循方面表现出色。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [59] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA 2.0 是一种用于高光谱医学成像的交互式分割框架，通过结合光谱和空间线索来提高分割精度和鲁棒性，并且在数据有限或有噪声的情况下表现更好。


<details>
  <summary>Details</summary>
Motivation: 为了在高光谱医学成像中实现更准确、更鲁棒的分割，并提高少样本和零样本性能，尤其是在临床成像中常见的具有挑战性的低数据和噪声场景中。

Method: SAMSA 2.0 是一个交互式分割框架，利用光谱角度提示将光谱相似性与空间线索相结合，以指导分割任何模型（SAM）。

Result: SAMSA 2.0 在不重新训练的情况下，实现了比仅 RGB 模型高出 3.8% 的 Dice 分数，比先前光谱融合方法高出 3.1% 的 Dice 分数，并展示了在具有挑战性的低数据和噪声场景中的强大泛化能力。

Conclusion: SAMSA 2.0 通过引入光谱角度提示，将光谱相似性与空间线索相结合，实现了对高光谱医学成像的交互式分割框架，在不重新训练的情况下，相比仅 RGB 模型和先前光谱融合方法，实现了更高的 Dice 分数，并增强了少样本和零样本性能。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [60] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: LesiOnTime是一种新的3D分割方法，通过整合纵向影像和BI-RADS评分，提高了乳腺小灶性病变的分割精度。


<details>
  <summary>Details</summary>
Motivation: 准确分割乳腺动态增强MRI（DCE-MRI）中的小灶性病变对于早期癌症检测至关重要，但现有深度学习方法主要关注大病变，忽略了纵向和临床信息。放射科医生在筛查中需要对比不同时间点的影像并参考BI-RADS评分来检测细微或新兴的病变。

Method: LesiOnTime是一种新颖的3D分割方法，其核心在于：1. 时间先验注意力（TPA）模块，用于动态整合前后扫描信息；2. BI-RADS一致性正则化（BCR）损失，用于对齐具有相似放射学评估的扫描的潜在空间，将领域知识嵌入训练过程。

Result: 在内部分多个时间点的DCE-MRI数据集上，LesiOnTime相比于最先进的单时间点和纵向方法，在Dice指标上提升了5%。消融研究表明，TPA和BCR模块均能带来性能增益。

Conclusion: LesiOnTime方法通过结合纵向影像和BI-RADS评分，能够有效提升小灶性病变的分割精度，为乳腺癌早期筛查提供了新的思路。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [61] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的无监督方法，利用先进的神经网络技术，无需预先标注即可高效、精确地标注遥感影像，为遥感图像分析提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 遥感影像的机器学习依赖于最新、准确的标签来进行模型训练和测试，但传统的标注方法耗时耗费人力，需要专家进行分析。

Method: 本研究定义了一个无监督流程，利用分割、卷积神经网络和图神经网络来寻找和标注Sentinel-2卫星图像中具有相似上下文和内容的地理区域。通过将图像分割成基于颜色和空间相似性的同类像素区域，并利用图神经网络聚合邻近区域信息，实现了更鲁棒的特征表示，该方法减少了标注工具中的异常值，允许用户进行细粒度标注，并在编码空间中形成旋转不变的图像级语义关系。

Result: 该方法通过编码更鲁棒的特征空间，实现了更精确的图像比较和标注，减少了异常值，支持细粒度标注，并建立了图像级的旋转不变语义关系。

Conclusion: 本研究提出的无监督方法利用分割、卷积神经网络和图神经网络来编码更鲁棒的特征空间，用于遥感图像的比较和标注，克服了以往依赖预先标注数据的限制。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [62] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: EPANet是一种高效的水下鱼类检测网络，通过特征融合和优化的瓶颈结构，在准确性和效率上均取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 解决当前水下鱼类检测（UFD）方法在低物体分辨率、显著的背景干扰和目标与周围环境之间高视觉相似性方面存在的挑战，并克服现有方法侧重于局部特征增强或复杂注意力机制导致模型复杂性增加和效率降低的局限性。

Method: EPANet包含两个关键部分：高效路径聚合特征金字塔网络（EPA-FPN）和多尺度多样化短路径瓶颈（MS-DDSP bottleneck）。EPA-FPN引入跨不同尺度的长程跳跃连接以增强语义-空间互补性，并采用跨层融合路径提高特征融合效率。MS-DDSP瓶颈通过引入更细粒度的特征划分和多样化的卷积操作来扩展传统的瓶颈结构，从而增强局部特征多样性和表示能力。

Result: EPANet在基准UFD数据集上的大量实验表明，其在检测准确性和推理速度方面均优于最先进的方法。

Conclusion: EPANet在准确性和效率方面优于现有方法，同时保持可比甚至更低的参数复杂性。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [63] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: A new framework simplifies video color grading using a diffusion model to create a LUT for matching reference looks, preserving details and speeding up the process, with added features for user customization via text prompts.


<details>
  <summary>Details</summary>
Motivation: Video color grading, used for artistic or storytelling purposes to establish a specific look or mood, is typically complex and requires specialized skills, limiting it to professional colorists. This paper aims to simplify and democratize the process.

Method: The paper proposes a reference-based video color grading framework that utilizes a diffusion model to explicitly generate a look-up table (LUT) for color attribute alignment between reference scenes and input video. The training objective enforces similarity in high-level features (look, mood, emotion) between the reference and input. A pipeline is also developed to incorporate user preferences via text prompts for low-level feature enhancement.

Result: Experimental results and extensive user studies demonstrate the effectiveness of the proposed approach for video color grading, highlighting its ability to maintain structural details and achieve fast inference.

Conclusion: The proposed reference-based video color grading framework effectively achieves desired artistic looks and moods by generating a LUT via a diffusion model, ensuring no loss of structural details and enabling fast inference. User studies confirm its effectiveness, and a pipeline for incorporating text prompts allows for low-level feature enhancement.

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [64] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 先进的VLM在医学图像相对位置判断方面表现不佳，即使有视觉提示也效果有限，主要依赖先验知识而非图像内容。我们提出了MIRP数据集来推动相关研究。


<details>
  <summary>Details</summary>
Motivation: 为了使视觉-语言模型（VLMs）在临床实践中得到应用，准确判断医学图像中解剖结构和异常的相对位置是基础前提，但目前该能力研究不足。

Method: 评估了GPT-4o、Llama3.2、Pixtral和JanusPro等先进VLM在医学图像上的相对位置判断能力。尝试使用字母数字或彩色标记等视觉提示来提高性能，但效果有限。

Result: 所有被评估的VLM在医学图像相对位置判断任务上均失败。视觉提示（如标记）只能提供适度改善，且在医学图像上的表现远不如在自然图像上。

Conclusion: 当前的视觉-语言模型（VLMs）在医学图像的相对位置判断任务上表现不佳，它们更多地依赖先验解剖知识而非图像内容，导致结论不准确。引入MIRP数据集以促进该领域的研究。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [65] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: DBLP 是一种高效的基于扩散的对抗性净化方法，通过噪声桥蒸馏和自适应语义增强，在保证高准确率和图像质量的同时，实现了接近实时的推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的对抗性净化方法通常需要密集的迭代去噪，严重限制了其实际应用。本研究旨在开发一种高效的基于扩散的净化方法。

Method: 提出了一种名为 DBLP（Diffusion Bridge Distillation for Purification）的新型高效的基于扩散的框架来进行对抗性净化。其核心是一种新的目标——噪声桥蒸馏，它在潜在一致性模型 (LCM) 中构建了对抗性噪声分布与干净数据分布之间的原则性对齐。为了进一步增强语义保真度，该方法引入了自适应语义增强，将多尺度金字塔边缘图作为条件输入来指导净化过程。

Result: DBLP 在多个数据集上的广泛实验表明，其在鲁棒精度、图像质量和推理时间方面均优于现有方法，实现了最先进的性能。

Conclusion: DBLP 实现了最先进的鲁棒精度、卓越的图像质量，并具有约 0.2 秒的推理时间，标志着其在实时对抗性净化方面迈出了重要一步。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [66] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: HiPrune 是一种新颖的视觉 token 剪枝框架，无需训练即可显著减少模型中的 token 数量，从而提高效率，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）将图像编码为长序列的视觉 token，导致过高的计算开销和有限的推理效率。先前的剪枝或合并 token 的方法通常依赖特殊 token 或需要针对特定任务进行训练，这限制了其跨架构的可扩展性。

Method: HiPrune 框架利用视觉编码器内的分层注意力结构。通过识别出中层关注对象中心区域，深层捕捉全局上下文特征，HiPrune 选取三种信息 token：(1) 在对象中心层具有高注意力的锚点 token，(2) 邻近锚点的缓冲区 token 以保持空间连续性，(3) 在深层具有强注意力的寄存器 token 以进行全局总结。该方法无需重新训练，可与任何基于 ViT 的 VLM 无缝集成。

Result: 在 LLaVA-1.5、LLaVA-NeXT 和 Qwen2.5-VL 上的大量实验表明，HiPrune 实现了最先进的剪枝性能，在仅使用 33.3% 的 token 时可保留高达 99.3% 的任务准确性，使用 11.1% 的 token 时可保持 99.5% 的准确性。同时，推理 FLOPs 和延迟降低了高达 9 倍。

Conclusion: HiPrune 是一种训练无关且与模型无关的 token 剪枝框架，利用视觉编码器内的分层注意力结构，能够在显著减少 token 数量的同时，保持高达 99.3% 的任务准确性，并大幅降低推理 FLOPs 和延迟（高达 9 倍），展示了跨模型和任务的强大泛化能力。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [67] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: Wukong是一种新的NSFW检测框架，它利用扩散模型的中间输出来实现高效准确的检测，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的NSFW内容检测方法（文本过滤器和图像过滤器）存在一些局限性：文本过滤器无法处理T2I模型特有的变异，并且容易受到对抗性攻击；图像过滤器计算成本高且会增加延迟。

Method: 提出了一种基于Transformer的NSFW检测框架Wukong，该框架利用早期去噪步骤的中间输出，并重新利用U-Net预训练的交叉注意力参数。Wukong在扩散过程中进行操作，能够在不等待完整图像生成的情况下实现早期检测。

Result: Wukong在新的包含提示、种子和图像特定NSFW标签的数据集以及两个公开基准上进行了评估，结果表明其性能优于文本安全防护，且效率远高于图像过滤器。

Conclusion: Wukong显著优于基于文本的安全防护，并且在准确性上与基于图像的安全防护相当，同时效率更高。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [68] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: FreeCP 是一种新的、无需训练的框架，可以提高开放词汇语义分割的性能，通过净化类别表示来解决类别冗余和歧义问题。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的 OVSS 方法在处理类别冗余和视觉-语言歧义方面存在不足，这可能导致次优的类别激活图和亲和力细化激活图。Motivated by these observations, we propose FreeCP, a novel training-free class purification framework designed to address these challenges.

Method: FreeCP 提出了一种新颖的、无需训练的类别净化框架，专注于净化语义类别和纠正由冗余和歧义引起 的错误，然后利用净化后的类别表示来生成最终的分割预测。

Result: 在八个基准上的大量实验表明，FreeCP 作为即插即用模块，可以显著提升与其他 OVSS 方法结合时的分割性能。

Conclusion: FreeCP 通过净化语义类别并纠正冗余和歧义造成的错误来解决 OVSS 中的挑战，并且可以作为即插即用模块与其他 OVSS 方法结合使用。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [69] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: PhysNAP是一种基于扩散模型的生成方法，用于生成与局部点云对齐且物理上可信的 artiküle objekter。


<details>
  <summary>Details</summary>
Motivation: 为了在生成可关节物体时提高其物理真实性并实现与局部点云的一致性，本研究提出了一种名为PhysNAP的新型扩散模型方法。

Method: PhysNAP提出了一种新颖的基于扩散模型的方法，使用符号距离函数（SDF）表示部件形状，并通过点云对齐损失、非穿透和可移动性约束来指导反向扩散过程，同时支持类别感知能力。

Result: 实验结果表明，PhysNAP能够生成物理上更具可信度的可关节物体，并与给定的局部点云保持良好的一致性，同时通过与基线模型的对比证明了其在约束一致性方面的优越性，并展示了生成能力与约束一致性之间的权衡。

Conclusion: PhysNAP通过引入点云对齐损失、非穿透和可移动性约束，以及类别感知能力，显著提高了可关节物体生成在物理真实性和点云对齐方面的表现，并在PartNet-Mobility数据集上进行了验证，相比基线模型具有明显优势。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [70] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 本研究提出了一种新的弱监督目标检测算法，仅需图像级标注，利用预训练模型的知识提取病毒颗粒的伪标签，该方法标注成本低且性能优越。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的目标检测方法依赖于大型数据集的标注边界框进行训练，但获取这些标注成本高昂且耗时，需要领域专家知识。为了解决这个挑战，提出一种仅依赖图像级标注的弱监督方法。

Method: 提出一种特定领域的弱监督目标检测算法，仅依赖图像级标注。利用预训练模型在图像中预测病毒存在与否的任务来提取伪标签，进而训练目标检测模型。采用带有收缩感受野的优化方法直接提取病毒颗粒，无需特定的网络结构。

Result: 提出的方法能够获得比其他现有弱标注方法，甚至在标注时间受限的情况下优于地面真实标签的伪标签。

Conclusion: 提出的伪标签更容易获得，并且在标注时间有限的情况下，其性能优于其他现有的弱标注方法，甚至优于地面真实标签。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [71] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: This paper introduces a Landmark Shift Attack that exploits face detectors by manipulating landmark coordinates, and provides solutions to prevent such attacks.


<details>
  <summary>Details</summary>
Motivation: Unconstrained face recognition systems face challenges due to varying conditions like inconsistent lighting and diverse face poses, requiring a Face Detection module for proper Face Alignment. This work investigates the effectiveness of Object Generation Attacks on Face Detection.

Method: The paper proposes a Landmark Shift Attack that backdoors the coordinate regression task performed by face detectors. It also offers mitigations against these vulnerabilities.

Result: The paper shows the effectiveness of Object Generation Attacks on Face Detection, particularly a Landmark Shift Attack, and presents mitigations.

Conclusion: The paper demonstrates the effectiveness of Face Generation Attacks on Face Detection, specifically a Landmark Shift Attack that targets the coordinate regression task. It also proposes mitigations against these vulnerabilities.

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [72] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: CoProU-VO是一种新的无监督视觉里程计方法，通过结合和传播跨帧不确定性来处理动态物体，显著提高了在KITTI和nuScenes数据集上的准确性，尤其在复杂场景下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 无监督视觉里程计（VO）在消除真实世界标签依赖的同时，易受动态物体影响而产生错误的位姿估计。现有方法在处理动态场景时存在不足，特别是未能有效利用连续帧间的时序信息来传播和组合不确定性，从而准确识别不可靠区域。

Method: 提出了一种名为CoProU-VO的新型端到端方法，该方法基于视觉Transformer骨干网络，能够同时学习深度、不确定性估计和相机位姿。其核心在于利用概率模型结合目标帧不确定性与投影参考帧不确定性，实现跨帧不确定性传播和组合，以过滤动态物体和遮挡。

Result: 在KITTI和nuScenes数据集上进行了实验，结果表明CoProU-VO相比于之前的无监督单目端到端两帧方法有了显著提升，并且在其他方法经常失效的高速公路等挑战性场景下也表现出强大的性能。消融研究也验证了跨帧不确定性传播的有效性。

Conclusion: CoProU-VO通过结合目标帧不确定性和投影参考帧不确定性，并利用概率模型在时间序列上进行传播和组合，解决了视觉里程计中动态物体和遮挡导致的位姿估计误差问题。实验证明该方法在KITTI和nuScenes数据集上表现优于现有无监督单目端到端方法，尤其在高速公路场景下效果显著，并且验证了跨帧不确定性传播的有效性。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [73] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 通过不确定性感知似然比估计，在区分已知和未知像素特征方面，优于现有方法，在真实驾驶场景中提高了语义分割的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的面向对象的语义分割模型在真实驾驶场景中，对于未知物体会产生错误的分类，而像素级的分布外检测方法在复杂场景下区分稀有物体和未知物体时存在困难。本研究旨在解决这些限制。

Method: 提出了一种不确定性感知似然比估计方法，该方法在似然比测试中使用证据分类器来区分已知和未知像素特征，并明确考虑了不确定性。

Result: 在五个标准基准数据集上的评估结果表明，该方法实现了最低的平均假阳性率（2.5%），同时保持了高平均精度（90.91%），并且计算开销可忽略不计。

Conclusion: 该方法通过在似然比测试中引入不确定性感知，能够更有效地利用离群值暴露，从而在区分已知和未知像素特征方面表现出色。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [74] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 由于现有夜间灯光遥感方法在时间覆盖和精度上存在局限，本研究提出了一个名为EVAL的新框架，通过分层融合解码器和双特征精炼器来重建夜间灯光数据，将中国的数据记录追溯至1986年，并在定量评估中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的夜间灯光（NTL）遥感方法在估计光照强度和结构细节方面存在不足，限制了长期的时序研究。

Method: 提出了一种新颖的、由两阶段组成的重建框架：构建和精炼。构建阶段采用分层融合解码器（HFD）来提高初始重建的保真度。精炼阶段采用双特征精炼器（DFR），利用高分辨率不透水地表面具来指导和增强细粒度结构细节。

Result: 开发了扩展的VIIRS类夜间灯光（EVAL）产品，将中国的数据记录向前追溯了26年，起始于1986年。定量评估显示，EVAL的R²从0.68提升至0.80，RMSE从1.27降低至0.99，显著优于现有方法。

Conclusion: EVAL产品在长时间序列分析方面表现出优越的性能，并为研究界提供了一个有价值的新资源。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [75] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: 该研究提出了一种名为 D3 的新方法，通过分析视频中的时态伪影来检测 AI 生成的视频，并在多个数据集上取得了优于现有方法的检测效果，同时保持了高效和鲁棒的特点。


<details>
  <summary>Details</summary>
Motivation: 为了应对 Sora 等视频生成技术带来的高保真 AI 生成视频的泛滥以及公众对合成内容传播的担忧，同时弥补现有检测方法在时态伪影探索方面的不足，本研究旨在开发一种新的检测方法。

Method: 本研究首先通过牛顿力学下的二阶动力学分析建立理论框架，然后提出用于时态伪影检测的二阶中心差分特征，并在此基础上开发了一种名为 D3 的无需训练的检测方法，该方法利用了二阶时间特征的差异。

Result: D3 在 Gen-Video、VideoPhy、EvalCrafter 和 VidProM 这 4 个公开数据集的 40 个子集上进行了验证，结果显示其平均准确率比先前最佳方法提高了 10.39%，并且在时间成本和后处理操作的额外实验中也证明了其卓越的计算效率和强大的鲁棒性能。

Conclusion: 该研究提出了一种名为 D3 的新颖的、无需训练的检测方法，该方法利用了二阶时间特征的差异，并在多个公开数据集上验证了其优越性，平均准确率比先前最佳方法提高了 10.39%，同时表现出出色的计算效率和鲁棒性。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [76] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: GeoMoE通过概率引导分解和MoE增强双路径校正器，有效地处理了复杂场景中的异构运动模式，在两视图几何估计中取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂真实场景中的异构运动模式时存在不足，这些场景具有极端视角、尺度变化和深度不连续性。这些方法未能明确考虑运动场的变异性，导致估计的运动场与其真实的结构和分布存在偏差。

Method: GeoMoE框架采用概率先验引导分解策略，利用内点概率信号将运动场分解为异构子场，以减少异常值偏差。此外，它还引入了MoE增强双路径校正器，通过空间上下文和通道语义路径增强每个子场，并将其路由到定制的专家进行针对性建模，从而解耦异构运动模式，抑制跨子场干扰和表示纠缠。

Result: GeoMoE在相对位姿和单应性估计方面取得了优于现有最先进方法的性能，并展示了良好的泛化能力。

Conclusion: GeoMoE通过其创新的方法在相对位姿和单应性估计方面超越了现有技术，并表现出强大的泛化能力。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [77] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: DPoser-X 是一种基于扩散的全身人类姿势先验模型，通过新颖的截断时间步长调度和掩码训练机制解决了数据稀缺和姿势复杂性的挑战，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于人体姿势的固有复杂性和高质量全身姿势数据集的稀缺性，构建通用且鲁棒的全身人类姿势先验仍然具有挑战性。

Method: 提出了一种名为 DPoser 的扩散模型作为人体姿势先验，并将其扩展为 DPoser-X，用于富有表现力的全身人类姿势建模。该方法将各种以姿势为中心的任务统一为逆问题，通过变分扩散采样来解决。

Result: DPoser-X 在身体、手部、面部和全身姿势建模的多个基准测试中表现出鲁棒性和多功能性，并在各种任务中持续优于最先进的替代方案。

Conclusion: DPoser-X 通过新颖的截断时间步长调度方法和掩码训练机制，在身体、手部、面部和全身姿势建模的多个基准测试中，始终优于最先进的替代方案，为全身人类姿势先验建模树立了新的标杆。

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [78] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 本研究提出使用条件扩散模型利用少量数据合成带属性标注的医学图像，以提高可解释AI模型在医学图像诊断中的性能和可信度。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学图像数据集缺乏属性标注的问题，本研究旨在通过合成数据来增强可解释模型在医学图像诊断中的应用。

Method: 本研究提出了一种通过生成模型合成带注释数据的方法，具体是增强了具有属性条件约束的扩散模型，并使用来自LIDC-IDRI数据集的20个带标签的肺结节样本进行训练。

Result: 与仅使用少量真实带属性标注数据集训练相比，将生成图像纳入可解释模型的训练中，将属性预测准确率提高了13.4%，目标预测准确率提高了1.8%。

Conclusion: 通过使用生成模型合成带注释的数据，可以克服数据集限制，从而提高可解释模型在医学图像分析中的应用性。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [79] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 该论文提出了首个补丁防御基准，通过大规模数据集和全面的分析，揭示了数据分布和自适应攻击对防御效果的关键影响，并为未来的研究提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有针对对象检测器的补丁攻击防御评估缺乏统一、全面的框架，导致评估结果不一致且不完整。

Method: 通过重新审视11种代表性防御方法，构建了一个包含2种攻击目标、13种补丁攻击、11种对象检测器和4种不同指标的补丁防御基准。该基准涉及94种补丁和94,000张图像，形成了大规模对抗性补丁数据集。

Result: 研究发现，防御自然补丁的难点在于数据分布而非高频率；在AP@0.5指标上，该数据集可将现有防御方法提升15.09%。此外，被攻击对象的平均精度与防御性能高度相关，而非补丁检测准确率；自适应攻击能有效绕过现有防御，而具有复杂/随机模型或通用补丁特性的防御方法相对更鲁棒。

Conclusion: 该研究提出的基准和分析为了评估和设计对抗性补丁攻击和防御提供了一个框架，并强调了理解数据分布和适应性攻击的重要性。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [80] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 图像去雾的挑战在于现实世界场景中雾的变化。本研究提出了一种即插即用的RGB-D融合模块，将预训练的深度特征集成到各种去雾架构中，有效解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的去雾方法在适应不同精度和效率要求的多样化场景方面存在局限性，因为它们的设计针对特定架构。本研究旨在探索预训练的深度表示在图像去雾中的泛化能力。

Method: 提出了一种即插即用的RGB-D融合模块，将预训练的深度表示（从数百万张多样化图像中学习）集成到各种去雾架构中。

Result: 经验分析表明，学习到的深度特征在不同雾度水平下保持了显著的一致性。RGB-D融合模块可以无缝集成到各种去雾架构中，并在多个基准测试中验证了其有效性和广泛的适用性。

Conclusion: 该方法通过RGB-D融合模块，将预训练的深度特征集成到各种去雾架构中，在多个基准测试中验证了其有效性和广泛的适用性。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [81] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 本研究填补了多图像大型语言模型幻觉研究的空白，提出了MIHBench基准和动态注意力平衡机制，有效解决了多图像场景下的幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单图像设置，对多图像场景下的幻觉问题关注不足。本研究旨在解决这一空白，首次对多图像大型语言模型中的幻觉进行系统性研究。

Method: 本研究提出了MIHBench基准，包含三个核心任务：多图像对象存在幻觉、多图像对象计数幻觉和对象身份一致性幻觉。此外，研究提出了一种动态注意力平衡机制，用于调整图像间的注意力分布。

Result: 研究发现，图像输入数量与幻觉发生几率之间存在递进关系；单图像幻觉倾向与多图像幻觉之间存在强相关性；相同对象图像比例以及负样本在图像序列中的位置会影响对象身份一致性幻觉的发生。所提出的动态注意力平衡机制能有效减少幻觉，增强语义整合和推理稳定性。

Conclusion: 本研究首次系统地研究了多图像大型语言模型中的幻觉问题，并提出了MIHBench基准来评估跨多个图像的对象幻觉。通过大量实验，我们识别了多图像幻觉的关键影响因素，并提出了一种动态注意力平衡机制，该机制有效减少了幻觉的发生，并增强了多图像场景下的语义整合和推理稳定性。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [82] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 该研究提出了一种基于面部运动模式的行为生物识别方法，用于验证虚拟化身用户的身份，并提供了一个新的数据集和轻量级的模型，证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决照片般逼真的虚拟头像在虚拟会议、游戏和社交平台中日益普遍，但同时也引入了冒充等严重安全风险的问题，本研究旨在探讨在化身媒介场景中进行生物识别验证的挑战。

Method: 提出了一种轻量级的、可解释的时空图卷积网络架构，并结合了时间注意力池化，仅使用面部地标来模拟动态面部姿态，以应对化身中的生物识别验证挑战。

Result: 实验结果表明，面部运动线索能够实现有意义的身份验证，AUC值接近80%。

Conclusion: 面部运动模式可以作为一种行为生物识别手段，在化身中具有有意义的身份验证能力，模型的AUC值接近80%。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [83] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: YOLO-Count是一个可微的开放词汇对象计数模型，可以精确控制文本到图像生成中的对象数量。它使用'基数图'作为新的回归目标，并通过表示对齐和混合监督方案进行训练。


<details>
  <summary>Details</summary>
Motivation: 为了解决通用的对象计数挑战，并实现对文本到图像生成进行精确的数量控制。

Method: 提出了一种名为'基数图'的新型回归目标，该目标考虑了对象大小和空间分布的变化。利用表示对齐和混合强弱监督方案，并构建了一个完全可微的架构，用于梯度优化。

Result: 在对象计数方面达到了最先进的准确性，并为文本到图像系统提供了稳健且有效的数量控制。

Conclusion: YOLO-Count在对象计数方面达到了最先进的准确性，并为文本到图像系统提供了强大而有效的数量控制。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [84] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 本研究提出了一种名为Dense Backbone的轻量级骨干网络，用于3D目标检测。与现有方法相比，该骨干网络可显著降低模型复杂度和计算成本，同时保持高检测精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于LiDAR的3D目标检测方法依赖于复杂骨干网络（如VGG或ResNet）的问题，本研究旨在设计一个轻量级的骨干网络，以提高处理速度并降低模型复杂度，同时保持高检测精度。

Method: 提出了一种名为Dense Backbone的轻量级骨干网络，并将其应用于PillarNet（DensePillarNet）以进行3D目标检测。该骨干网络结合了高处理速度、轻量化架构和强大的检测精度，并通过实验证明了其在降低计算成本方面的有效性。

Result: DensePillarNet在nuScenes测试集上实现了29%的模型参数减少和28%的延迟降低，而检测精度仅下降了2%。Dense Backbone的即插即用设计允许轻松集成到现有架构中，而无需修改其他网络组件。

Conclusion: 该研究提出了Dense Backbone，一种轻量级骨干网络，可与现有3D目标检测器（如PillarNet）结合使用，以降低计算成本并保持高检测精度。DensePillarNet在模型参数和延迟方面均有显著降低，仅对检测精度造成微小影响。该骨干网络的即插即用设计使其易于集成到现有架构中。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [85] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO是一个新的训练框架，通过最优传输学习几何感知特征，在多个数据集上取得了最先进的性能，并且速度更快。


<details>
  <summary>Details</summary>
Motivation: 现有自监督视觉基础模型虽然能捕捉语义对应，但缺乏对底层3D几何的感知。GECO旨在弥补这一差距，生成具有几何连贯性且能基于几何区分部分的语义特征。

Method: GECO使用基于最优传输的训练框架，实现了超越关键点的监督，即使在遮挡和非遮挡情况下也能进行训练。

Result: GECO在PFPascal、APK和CUB数据集上均达到了最先进的性能，分别将PCK提高了6.0%、6.2%和4.1%。此外，GECO的运行速度比现有方法快98.2%，达到了30帧/秒。研究还表明，PCK指标不足以完全评估几何质量，并提出了新的评估指标。

Conclusion: GECO通过引入基于最优传输的训练框架，解决了自监督视觉基础模型在3D几何感知方面的不足，能够生成语义上区分部分且几何上连贯的特征。该方法在PFPascal、APK和CUB数据集上均取得了最先进的性能，同时运行速度比现有方法快98.2%，并且证明了单独使用PCK指标不足以衡量几何质量，提出了新的评估指标和见解。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [86] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 为解决医学图像到图像翻译中处理分布外样本性能下降的问题，提出了一种名为Sample-Aware TTA的新框架，该框架通过动态调整翻译过程，根据测试样本的特征进行适应性修改，从而在保证分布内样本性能的同时提高了模型对分布外样本的处理能力，并在CT去噪和MRI翻译任务上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的图像到图像翻译技术在处理分布外样本时存在性能下降的问题，需要一种能够动态调整以适应不同测试样本特征的方法。

Method: 提出了一种新颖的测试时自适应（TTA）框架，该框架包含一个重建模块用于量化域偏移，以及一个动态自适应块，该模块选择性地修改预训练翻译模型的内部特征，以减轻偏移，同时不影响在不需要自适应的分布内样本上的性能。

Result: 在低剂量CT去噪和T1到T2 MRI翻译任务上，所提出的TTA框架相比于基线模型和先前TTA方法均取得了持续的改进。

Conclusion: 该研究提出了一种新颖的测试时自适应（TTA）框架，通过动态调整翻译过程来处理分布外样本，解决了现有图像到图像翻译方法在处理分布外样本时性能下降的问题。实验证明，该方法在低剂量CT去噪和T1到T2 MRI翻译任务上均优于基线模型和其他TTA方法，表明动态、样本特定的调整是提高模型在实际场景中鲁棒性的有效途径。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [87] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: SU-ESRGAN是首个为卫星图像设计的超分辨率框架，它通过结合ESRGAN、DeepLabv3分割损失和蒙特卡洛Dropout，提高了图像的语义一致性和像素级不确定性。该模型在航空影像上表现与基线ESRGAN相当，适用于无人机等场景，但跨域应用性能受数据领域差异影响。


<details>
  <summary>Details</summary>
Motivation: 现有的生成对抗网络（GANs）在图像超分辨率（SR）方面虽然能生成逼真的图像，但在语义一致性和像素级置信度方面存在不足，这限制了它们在遥感关键应用（如灾难响应、城市规划和农业）中的可信度。

Method: 提出了一种名为SU-ESRGAN（Semantic and Uncertainty-Aware ESRGAN）的超分辨率框架，它集成了ESRGAN、用于类别细节保留的DeepLabv3分割损失以及用于生成像素级不确定性图的蒙特卡洛 Dropout。

Result: SU-ESRGAN在航空影像上实现了与基线ESRGAN相当的超分辨率结果（PSNR、SSIM、LPIPS）。

Conclusion: SU-ESRGAN在卫星图像超分辨率方面取得了与基线ESRGAN相当的结果（PSNR、SSIM、LPIPS），但增加了语义一致性和像素级不确定性。该模型在无人机数据管道中具有应用价值，可用于板载或后处理超分辨率，以增强由于运动模糊、压缩和传感器限制而受损的图像。然而，在跨域应用中，模型性能会受到训练数据和目标数据之间成像特征差异的影响，这凸显了领域感知训练在超分辨率应用中的重要性。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [88] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: PILOT框架通过创新的提示学习和自适应策略，解决了零样本异常检测在领域迁移下的泛化能力问题，并在多项基准测试中取得优异成果。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法在领域迁移下表现不佳，因为它们的训练数据来源于有限的训练域，无法泛化到新的分布。PILOT旨在解决这一问题。

Method: PILOT框架采用双分支提示学习机制，动态整合可学习提示池和结构化语义属性，并结合无标签的测试时自适应策略，利用高置信度伪标签更新提示参数。

Result: PILOT在13个工业和医学基准测试中，在领域迁移下的异常检测和定位方面均达到了最先进的性能。

Conclusion: PILOT框架通过新颖的双分支提示学习机制和无标签的测试时自适应策略，成功克服了现有零样本异常检测方法在领域迁移下的局限性，并在13个工业和医学基准测试中取得了最先进的性能。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [89] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 这项研究分析了与公共安全相关的点云数据集的语义分割性能，发现较大的物体分割效果更好，而较小的、关键的物体则不然。研究强调了数据标准化和改进标记技术以提高公共安全应用中点云分析的准确性的重要性。


<details>
  <summary>Details</summary>
Motivation: 分析与公共安全应用相关的异构标记点云数据集的语义分割性能，重点关注来自激光雷达扫描的预事件规划系统，并研究统一不同 3D 数据时面临的挑战。

Method: 采用 KPConv 架构和分级模式，通过 IoU 指标评估与安全相关的特征的性能。

Result: 几何尺寸较大的对象（例如楼梯、窗户）的分割性能较高，而较小的、安全关键的特征识别率较低。类不平衡和较小物体的几何区分度有限会影响性能。

Conclusion: 可靠的点云语义分割在公共安全领域需要标准化的注释协议和改进的标记技术，以解决数据异构性和检测小型、安全关键元素的问题。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [90] [PhysicsEval: Inference-Time Techniques to Improve the Reasoning Proficiency of Large Language Models on Physics Problems](https://arxiv.org/abs/2508.00079)
*Oshayer Siddique,J. M Areeb Uzair Alam,Md Jobayer Rahman Rafy,Syed Rifat Raiyan,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

TL;DR: 本文评估了大型语言模型在物理问题解决方面的能力，通过引入多代理框架和新的评估基准PHYSICEVAL，显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 物理学是推动技术发展和理解宇宙基本原理的关键学科。为了推进自然语言推理在物理问题解决中的应用，本文旨在评估和改进大型语言模型在这一任务上的表现。

Method: 本文评估了前沿大型语言模型在解决数学和描述性物理问题上的性能，并采用了多种推理时技术和代理框架（如累积验证）来提升模型表现。研究进行了技术性能的比较分析。

Result: 研究发现，多代理框架显著提高了模型在初始表现不佳的物理问题上的性能。通过引入PHYSICEVAL基准，为未来评估和改进物理问题解决模型提供了资源。

Conclusion: 该研究评估了前沿大型语言模型在解决物理问题（包括数学和描述性问题）方面的性能，并探索了多种推理时技术和代理框架以提高其表现。研究表明，多代理框架在模型初始表现不佳的问题上能带来显著改进。此外，研究还引入了一个包含19,609个物理问题及其解决方案的新评估基准PHYSICEVAL。

Abstract: The discipline of physics stands as a cornerstone of human intellect, driving
the evolution of technology and deepening our understanding of the fundamental
principles of the cosmos. Contemporary literature includes some works centered
on the task of solving physics problems - a crucial domain of natural language
reasoning. In this paper, we evaluate the performance of frontier LLMs in
solving physics problems, both mathematical and descriptive. We also employ a
plethora of inference-time techniques and agentic frameworks to improve the
performance of the models. This includes the verification of proposed solutions
in a cumulative fashion by other, smaller LLM agents, and we perform a
comparative analysis of the performance that the techniques entail. There are
significant improvements when the multi-agent framework is applied to problems
that the models initially perform poorly on. Furthermore, we introduce a new
evaluation benchmark for physics problems, ${\rm P{\small HYSICS}E{\small
VAL}}$, consisting of 19,609 problems sourced from various physics textbooks
and their corresponding correct solutions scraped from physics forums and
educational websites. Our code and data are publicly available at
https://github.com/areebuzair/PhysicsEval.

</details>


### [91] [Do LLMs produce texts with "human-like" lexical diversity?](https://arxiv.org/abs/2508.00086)
*Kelly Kendro,Jeffrey Maloney,Scott Jarvis*

Main category: cs.CL

TL;DR: LLM文本的词汇多样性不如人类写作，新模型尤其如此。ChatGPT-4.5词汇多样性低，生成词数也少。人类作者的词汇多样性不受教育和语言背景影响。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量实证研究关注大型语言模型（LLM）生成文本的‘人类化’程度，但其具体表现仍不明确。本研究旨在从词汇多样性的角度深入探讨这一问题，以期为理解LLM的写作能力提供更精确的评估。

Method: 本研究通过测量六个词汇多样性维度（词量、丰富度、多样性-重复性、均匀度、差异度和离散度），比较了四种ChatGPT模型（-3.5、-4、-o4 mini和-4.5）与240名不同教育水平的以英语为母语（L1）和非母语（L2）的学习者所写文本的词汇多样性。采用了多元方差分析（MANOVAs）、单因素方差分析（ANOVAS）和支持向量机（SVM）等统计方法进行分析。

Result: 研究结果显示，所有ChatGPT模型生成的文本在所有测量的词汇多样性维度上均与人类写作存在显著差异。其中，ChatGPT-o4 mini和-4.5模型的差异最为明显。在模型内部，ChatGPT-4.5虽然生成的词语（tokens）数量较少，但其词汇多样性水平反而更高。然而，人类作者的词汇多样性在不同教育背景和语言能力分组之间没有显著差异。

Conclusion: LLM生成文本在词汇多样性方面与人类写作存在显著差异，较新模型（如ChatGPT-4.5）的词汇多样性更低，尽管其生成的词语数量也更少。研究结果表明，LLM文本在词汇多样性上并非真正‘人类化’，并且更新的模型反而表现出更低的人类化程度。这些发现对语言教学和相关应用具有重要启示。

Abstract: The degree to which LLMs produce writing that is truly human-like remains
unclear despite the extensive empirical attention that this question has
received. The present study addresses this question from the perspective of
lexical diversity. Specifically, the study investigates patterns of lexical
diversity in LLM-generated texts from four ChatGPT models (-3.5, -4, -o4 mini,
and -4.5) in comparison with texts written by L1 and L2 English participants (n
= 240) across four education levels. Six dimensions of lexical diversity were
measured in each text: volume, abundance, variety-repetition, evenness,
disparity, and dispersion. Results from one-way MANOVAs, one-way ANOVAS, and
Support Vector Machines revealed that the LLM-generated texts differed
significantly from human-written texts for each variable, with ChatGPT-o4 mini
and -4.5 differing the most. Within these two groups, ChatGPT-4.5 demonstrated
higher levels of lexical diversity despite producing fewer tokens. The human
writers' lexical diversity did not differ across subgroups (i.e., education,
language status). Altogether, the results indicate that LLMs do not produce
human-like texts in relation to lexical diversity, and the newer LLMs produce
less human-like texts than older models. We discuss the implications of these
results for language pedagogy and related applications.

</details>


### [92] [Semiotic Complexity and Its Epistemological Implications for Modeling Culture](https://arxiv.org/abs/2508.00095)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 计算人文领域需要加强方法理论化，将建模视为翻译过程，注意符号复杂性，避免将复杂数据视为简单数据，以提高清晰度和准确性。


<details>
  <summary>Details</summary>
Motivation: 计算人文领域需要更多的理论化方法，以实现认识论和解释的清晰度，从而促进该领域的成熟。

Method: 论文提出将计算人文领域的建模工作视为一种翻译工作，即从文化、语言领域到计算、数学领域，再反向翻译。论文强调了理论化在确保内部一致性、避免细微但后果严重的翻译错误以及促进解释透明度方面的重要性。

Result: 论文指出了理论化不足导致的主要问题，即在评估等建模实践中，将具有符号复杂性的数据视为简单数据，从而在认识论上造成了“翻译错误”。论文还提出了几项建议，帮助研究人员在工作中更好地解决这些认识论问题。

Conclusion: 本篇论文的结论是，应加强计算人文领域中方法的理论化，以提高认识论和解释的清晰度，从而推动该领域的成熟。我们提出将建模工作视为一种从文化、语言领域到计算、数学领域再返回的翻译工作。

Abstract: Greater theorizing of methods in the computational humanities is needed for
epistemological and interpretive clarity, and therefore the maturation of the
field. In this paper, we frame such modeling work as engaging in translation
work from a cultural, linguistic domain into a computational, mathematical
domain, and back again. Translators benefit from articulating the theory of
their translation process, and so do computational humanists in their work --
to ensure internal consistency, avoid subtle yet consequential translation
errors, and facilitate interpretive transparency. Our contribution in this
paper is to lay out a particularly consequential dimension of the lack of
theorizing and the sorts of translation errors that emerge in our modeling
practices as a result. Along these lines we introduce the idea of semiotic
complexity as the degree to which the meaning of some text may vary across
interpretive lenses, and make the case that dominant modeling practices --
especially around evaluation -- commit a translation error by treating
semiotically complex data as semiotically simple when it seems
epistemologically convenient by conferring superficial clarity. We then lay out
several recommendations for researchers to better account for these
epistemological issues in their own work.

</details>


### [93] [FACTORY: A Challenging Human-Verified Prompt Set for Long-Form Factuality](https://arxiv.org/abs/2508.00109)
*Mingda Chen,Yang Li,Xilun Chen,Adina Williams,Gargi Ghosh,Scott Yih*

Main category: cs.CL

TL;DR: FACTORY is a new, human-verified benchmark for evaluating factual accuracy in long responses. Existing benchmarks are flawed. FACTORY is harder, showing current models are only 60% accurate. Models need to improve on obscure facts.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for long-form factuality evaluation often lack human verification, leading to potential quality issues. This limitation is addressed by introducing FACTORY, a human-verified prompt set designed to be challenging, fact-seeking, answerable, and unambiguous.

Method: A model-in-the-loop approach was used to develop FACTORY, a large-scale, human-verified prompt set. Human evaluations were conducted on 6 state-of-the-art language models using FACTORY and existing datasets.

Result: FACTORY proves to be a challenging benchmark, revealing that approximately 40% of claims in SOTA model responses are not factual, a significant increase compared to the 10% observed on other datasets. This indicates a gap in models' ability to generate factually accurate long-form responses.

Conclusion: FACTORY is a reliable and challenging benchmark for evaluating the factuality of long-form responses, highlighting the need for models to reason across long-tailed facts. It demonstrates that current SOTA models struggle with factuality, with approximately 40% of claims being non-factual compared to 10% on other datasets.

Abstract: Long-form factuality evaluation assesses the ability of models to generate
accurate, comprehensive responses to short prompts. Existing benchmarks often
lack human verification, leading to potential quality issues. To address this
limitation, we introduce FACTORY, a large-scale, human-verified prompt set.
Developed using a model-in-the-loop approach and refined by humans, FACTORY
includes challenging prompts that are fact-seeking, answerable, and
unambiguous. We conduct human evaluations on 6 state-of-the-art language models
using FACTORY and existing datasets. Our results show that FACTORY is a
challenging benchmark: approximately 40% of the claims made in the responses of
SOTA models are not factual, compared to only 10% for other datasets. Our
analysis identifies the strengths of FACTORY over prior benchmarks, emphasizing
its reliability and the necessity for models to reason across long-tailed
facts.

</details>


### [94] [ReaGAN: Node-as-Agent-Reasoning Graph Agentic Network](https://arxiv.org/abs/2508.00429)
*Minghao Guo,Xi Zhu,Jingyuan Huang,Kai Mei,Yongfeng Zhang*

Main category: cs.CL

TL;DR: ReaGAN 是一个新颖的图学习框架，通过让每个节点充当具有自主决策能力的代理，并结合检索增强生成（RAG）来克服现有 GNN 的局限性，从而实现自适应的消息传播和全局关系建模。


<details>
  <summary>Details</summary>
Motivation: 现有的 GNNs 在处理节点信息不平衡（有些节点信息丰富，有些节点信息稀疏）以及仅利用局部结构相似性而忽略跨图的全局语义关系方面存在局限性，这限制了模型捕获遥远但相关信息的能力。

Method: 提出了一种名为 ReaGAN 的代理框架，该框架使每个节点都具有自主的、节点级别的决策能力。每个节点充当一个代理，根据其内部记忆独立规划其下一个动作，从而实现节点级别的规划和自适应的消息传播。此外，检索增强生成（RAG）允许节点访问语义上相关的内容并在图中构建全局关系。

Result: ReaGAN 实现了有竞争力的性能，尤其是在少样本的上下文设置中，并且无需对 LLM 主干进行微调。

Conclusion: ReaGAN 在没有微调的情况下，使用冻结的 LLM 主干，在少样本的上下文设置中取得了有竞争力的性能，展示了代理规划和局部-全局检索在图学习中的潜力。

Abstract: Graph Neural Networks (GNNs) have achieved remarkable success in graph-based
learning by propagating information among neighbor nodes via predefined
aggregation mechanisms. However, such fixed schemes often suffer from two key
limitations. First, they cannot handle the imbalance in node informativeness --
some nodes are rich in information, while others remain sparse. Second,
predefined message passing primarily leverages local structural similarity
while ignoring global semantic relationships across the graph, limiting the
model's ability to capture distant but relevant information. We propose
Retrieval-augmented Graph Agentic Network (ReaGAN), an agent-based framework
that empowers each node with autonomous, node-level decision-making. Each node
acts as an agent that independently plans its next action based on its internal
memory, enabling node-level planning and adaptive message propagation.
Additionally, retrieval-augmented generation (RAG) allows nodes to access
semantically relevant content and build global relationships in the graph.
ReaGAN achieves competitive performance under few-shot in-context settings
using a frozen LLM backbone without fine-tuning, showcasing the potential of
agentic planning and local-global retrieval in graph learning.

</details>


### [95] [Is neural semantic parsing good at ellipsis resolution, or isn't it?](https://arxiv.org/abs/2508.00121)
*Xiao Zhang,Johan bos*

Main category: cs.CL

TL;DR: Neural semantic parsers fail on verb phrase ellipsis, a context-sensitive linguistic phenomenon, despite good performance on standard tests. A custom dataset of 120 ellipsis cases was used to demonstrate this failure.


<details>
  <summary>Details</summary>
Motivation: To investigate the performance of neural semantic parsers on strongly context-sensitive phenomena, specifically English verb phrase ellipsis, where entire verb phrases can be abbreviated by auxiliary verbs.

Method: A challenge set of 120 ellipsis cases with their resolved meaning representations was created and used to test a battery of neural semantic parsers.

Result: Neural semantic parsers, despite performing well on standard test sets, failed to correctly parse instances with verb phrase ellipsis.

Conclusion: Despite strong performance on standard datasets, neural semantic parsers struggle with context-sensitive phenomena like verb phrase ellipsis, failing to correctly parse them even after data augmentation.

Abstract: Neural semantic parsers have shown good overall performance for a variety of
linguistic phenomena, reaching semantic matching scores of more than 90%. But
how do such parsers perform on strongly context-sensitive phenomena, where
large pieces of semantic information need to be duplicated to form a meaningful
semantic representation? A case in point is English verb phrase ellipsis, a
construct where entire verb phrases can be abbreviated by a single auxiliary
verb. Are the otherwise known as powerful semantic parsers able to deal with
ellipsis or aren't they? We constructed a corpus of 120 cases of ellipsis with
their fully resolved meaning representation and used this as a challenge set
for a large battery of neural semantic parsers. Although these parsers
performed very well on the standard test set, they failed in the instances with
ellipsis. Data augmentation

</details>


### [96] [Comparison of Large Language Models for Deployment Requirements](https://arxiv.org/abs/2508.00185)
*Alper Yaman,Jannik Schwab,Christof Nitsche,Abhirup Sinha,Marco Huber*

Main category: cs.CL

TL;DR: A list comparing LLMs (foundational and domain-specific) based on release year, licensing, and hardware requirements to help users choose the right model, available on GitLab.


<details>
  <summary>Details</summary>
Motivation: To help researchers and companies navigate the complex and rapidly evolving LLM landscape by facilitating LLM selection.

Method: Comparative analysis of foundational and domain-specific LLMs, focusing on features like release year, licensing, and hardware requirements. The list is maintained on GitLab for continuous updates.

Result: A continuously updated comparative list of LLMs published on GitLab, detailing features such as release year, licensing, and hardware requirements.

Conclusion: LLMs are revolutionizing text generation but face challenges like bias and hallucinations. Open-source models are rapidly increasing, complicating selection. This paper provides a comparative list of models to aid researchers and companies.

Abstract: Large Language Models (LLMs), such as Generative Pre-trained Transformers
(GPTs) are revolutionizing the generation of human-like text, producing
contextually relevant and syntactically correct content. Despite challenges
like biases and hallucinations, these Artificial Intelligence (AI) models excel
in tasks, such as content creation, translation, and code generation.
Fine-tuning and novel architectures, such as Mixture of Experts (MoE), address
these issues. Over the past two years, numerous open-source foundational and
fine-tuned models have been introduced, complicating the selection of the
optimal LLM for researchers and companies regarding licensing and hardware
requirements. To navigate the rapidly evolving LLM landscape and facilitate LLM
selection, we present a comparative list of foundational and domain-specific
models, focusing on features, such as release year, licensing, and hardware
requirements. This list is published on GitLab and will be continuously
updated.

</details>


### [97] [Tabular Data Understanding with LLMs: A Survey of Recent Advances and Challenges](https://arxiv.org/abs/2508.00217)
*Xiaofeng Wu,Alan Ritter,Wei Xu*

Main category: cs.CL

TL;DR: 该研究分析了大型语言模型在处理表格数据时面临的挑战，提出了表格表示分类和理解任务，并指出了模型在处理复杂、大规模表格以及跨不同格式泛化方面的不足，需要进一步研究。


<details>
  <summary>Details</summary>
Motivation: 鉴于表格在大型语言模型和多模态大型语言模型中的复杂性和多样性，需要提出专门的方法和任务来应对，但目前缺乏通用方法，因此有必要进行研究以应对这些挑战。

Method: 通过对表格输入表示进行分类和介绍表格理解任务来分析表格在大型语言模型和多模态大型语言模型中的应用和挑战。

Result: 研究强调了当前模型在表格理解方面存在的关键差距，包括检索任务的局限性、处理复杂表格结构和大规模数据的挑战以及模型泛化能力不足。

Conclusion: 该研究通过对表格输入表示进行分类并介绍表格理解任务，强调了当前模型在处理复杂表格结构、大规模表格、长上下文或多表格场景以及跨不同表格表示和格式的泛化能力方面存在的关键差距，指出了未来研究的方向。

Abstract: Tables have gained significant attention in large language models (LLMs) and
multimodal large language models (MLLMs) due to their complex and flexible
structure. Unlike linear text inputs, tables are two-dimensional, encompassing
formats that range from well-structured database tables to complex,
multi-layered spreadsheets, each with different purposes. This diversity in
format and purpose has led to the development of specialized methods and tasks,
instead of universal approaches, making navigation of table understanding tasks
challenging. To address these challenges, this paper introduces key concepts
through a taxonomy of tabular input representations and an introduction of
table understanding tasks. We highlight several critical gaps in the field that
indicate the need for further research: (1) the predominance of
retrieval-focused tasks that require minimal reasoning beyond mathematical and
logical operations; (2) significant challenges faced by models when processing
complex table structures, large-scale tables, length context, or multi-table
scenarios; and (3) the limited generalization of models across different
tabular representations and formats.

</details>


### [98] [Semantic Compression for Word and Sentence Embeddings using Discrete Wavelet Transform](https://arxiv.org/abs/2508.00220)
*Rana Aref Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: DWT可有效压缩NLP嵌入，降低维度同时保持或提高性能。


<details>
  <summary>Details</summary>
Motivation: 为了探索小波变换在自然语言处理（NLP）领域的应用潜力，特别是利用其分析嵌入表示和压缩嵌入的能力，同时保持其语义质量。

Method: 本文采用离散小波变换（DWT）对词嵌入和句子嵌入进行分析和压缩，并在语义相似性任务和下游任务上评估其有效性。

Result: DWT能够将嵌入的维度降低50-93%，同时在语义相似性任务上几乎不影响性能，并在大多数下游任务上取得更高的准确性。

Conclusion: 该研究表明，离散小波变换（DWT）在词嵌入和句子嵌入的应用能够有效降低嵌入的维度，同时在语义相似性任务中保持其性能，并在大多数下游任务中提高准确性，为在自然语言处理（NLP）应用中应用DWT提供了新的途径。

Abstract: Wavelet transforms, a powerful mathematical tool, have been widely used in
different domains, including Signal and Image processing, to unravel intricate
patterns, enhance data representation, and extract meaningful features from
data. Tangible results from their application suggest that Wavelet transforms
can be applied to NLP capturing a variety of linguistic and semantic
properties. In this paper, we empirically leverage the application of Discrete
Wavelet Transforms (DWT) to word and sentence embeddings. We aim to showcase
the capabilities of DWT in analyzing embedding representations at different
levels of resolution and compressing them while maintaining their overall
quality. We assess the effectiveness of DWT embeddings on semantic similarity
tasks to show how DWT can be used to consolidate important semantic information
in an embedding vector. We show the efficacy of the proposed paradigm using
different embedding models, including large language models, on downstream
tasks. Our results show that DWT can reduce the dimensionality of embeddings by
50-93% with almost no change in performance for semantic similarity tasks,
while achieving superior accuracy in most downstream tasks. Our findings pave
the way for applying DWT to improve NLP applications.

</details>


### [99] [Model Misalignment and Language Change: Traces of AI-Associated Language in Unscripted Spoken English](https://arxiv.org/abs/2508.00238)
*Bryce Anderson,Riley Galpin,Tom S. Juzek*

Main category: cs.CL

TL;DR: LLM可能正在改变我们说话和写作的方式。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLM）对科学和教育领域书面语词汇使用的影响，以及这种影响是否反映了人类语言系统本身的更广泛变化。

Method: 通过分析2022年前后从科学和技术播客中提取的2210万个单词的数据集，重点关注与LLM相关的常用词汇，并与基线同义词进行对比。

Result: 在2022年后，与LLM相关的词汇使用量出现了显著增加，而基线同义词没有显示出明显的变化趋势，这表明人类的用词选择可能正在向LLM的模式靠拢。

Conclusion: 该研究表明，在2022年后，人类在口语中使用的与LLM相关的词汇有所增加，这表明人类语言使用可能正在发生变化，但尚不清楚这种变化是自然的语言演变还是由AI驱动的。

Abstract: In recent years, written language, particularly in science and education, has
undergone remarkable shifts in word usage. These changes are widely attributed
to the growing influence of Large Language Models (LLMs), which frequently rely
on a distinct lexical style. Divergences between model output and target
audience norms can be viewed as a form of misalignment. While these shifts are
often linked to using Artificial Intelligence (AI) directly as a tool to
generate text, it remains unclear whether the changes reflect broader changes
in the human language system itself. To explore this question, we constructed a
dataset of 22.1 million words from unscripted spoken language drawn from
conversational science and technology podcasts. We analyzed lexical trends
before and after ChatGPT's release in 2022, focusing on commonly LLM-associated
words. Our results show a moderate yet significant increase in the usage of
these words post-2022, suggesting a convergence between human word choices and
LLM-associated patterns. In contrast, baseline synonym words exhibit no
significant directional shift. Given the short time frame and the number of
words affected, this may indicate the onset of a remarkable shift in language
use. Whether this represents natural language change or a novel shift driven by
AI exposure remains an open question. Similarly, although the shifts may stem
from broader adoption patterns, it may also be that upstream training
misalignments ultimately contribute to changes in human language use. These
findings parallel ethical concerns that misaligned models may shape social and
moral beliefs.

</details>


### [100] [Integrating clinical reasoning into large language model-based diagnosis through etiology-aware attention steering](https://arxiv.org/abs/2508.00285)
*Peixian Li,Yu Tian,Ruiqi Tu,Chengkai Wu,Jingjing Ren,Jingsong Li*

Main category: cs.CL

TL;DR: 本研究提出了一种病因感知注意力引导框架，通过整合结构化临床推理，显著提高了大语言模型在复杂临床场景下的诊断准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在医学文本理解和生成方面表现出色，但在复杂的临床场景中的诊断可靠性仍然有限，因此本研究旨在提高大语言模型在临床诊断中的准确性和临床推理能力。

Method: 本研究提出了一种病因感知注意力引导框架（Etiology-Aware Attention Steering Framework），包括构建临床推理脚手架（CRS）、开发病因感知头部识别算法，以及引入推理引导的参数高效微调（Reasoning-Guided Parameter-Efficient Fine-tuning），以整合结构化临床推理到大语言模型诊断中。

Result: 在一致性诊断队列中，本框架将平均诊断准确率提高了 15.65%，平均推理关注得分提高了 31.6%。在差异性诊断队列的外部验证进一步证实了其提高诊断准确性的有效性。通过推理注意力频率的进一步评估表明，在面对真实世界的复杂场景时，本模型表现出更高的可靠性。

Conclusion: 本研究提出了一种实用的方法来增强基于大语言模型的诊断能力，通过将模型注意力与结构化临床推理相结合，为构建可解释、可靠的 AI 诊断系统提供了新的方向。

Abstract: Objective: Large Language Models (LLMs) demonstrate significant capabilities
in medical text understanding and generation. However, their diagnostic
reliability in complex clinical scenarios remains limited. This study aims to
enhance LLMs' diagnostic accuracy and clinical reasoning ability. Method: We
propose an Etiology-Aware Attention Steering Framework to integrate structured
clinical reasoning into LLM-based diagnosis. Specifically, we first construct
Clinical Reasoning Scaffolding (CRS) based on authoritative clinical guidelines
for three representative acute abdominal emergencies: acute appendicitis, acute
pancreatitis, and acute cholecystitis. Next, we develop the Etiology-Aware Head
Identification algorithm to pinpoint attention heads crucial for the model's
etiology reasoning. To ensure reliable clinical reasoning alignment, we
introduce the Reasoning-Guided Parameter-Efficient Fine-tuning that embeds
etiological reasoning cues into input representations and steers the selected
Etiology-Aware Heads toward critical information through a Reasoning-Guided
Loss function. Result: On the Consistent Diagnosis Cohort, our framework
improves average diagnostic accuracy by 15.65% and boosts the average Reasoning
Focus Score by 31.6% over baselines. External validation on the Discrepant
Diagnosis Cohort further confirms its effectiveness in enhancing diagnostic
accuracy. Further assessments via Reasoning Attention Frequency indicate that
our models exhibit enhanced reliability when faced with real-world complex
scenarios. Conclusion: This study presents a practical and effective approach
to enhance clinical reasoning in LLM-based diagnosis. By aligning model
attention with structured CRS, the proposed framework offers a promising
paradigm for building more interpretable and reliable AI diagnostic systems in
complex clinical settings.

</details>


### [101] [Systematic Evaluation of Optimization Techniques for Long-Context Language Models](https://arxiv.org/abs/2508.00305)
*Ammar Ahmed,Sheng Di,Franck Cappello,Zirui Liu,Jingoo Han,Ali Anwar*

Main category: cs.CL

TL;DR: 本研究系统地测试了LLM的剪枝、量化和标记丢弃技术，发现在长上下文和更大的模型上，这些技术的组合使用可能适得其反，并提出结合系统分析和任务指标来优化LLM。


<details>
  <summary>Details</summary>
Motivation: LLMs在处理长上下文和资源需求方面存在挑战，而现有的优化技术（剪枝、量化、标记丢弃）在长上下文场景下的效果和系统评估研究不足。

Method: 系统地对LLM优化技术（如剪枝、量化和标记丢弃）进行基准测试，表征内存使用、延迟和吞吐量，并研究这些方法如何影响文本生成质量。首先分析了两种支持长上下文的LLM架构的单个优化方法，然后系统地评估这些技术的组合，最后在更大的700亿参数模型上研究了单个优化方法的可扩展性。

Result: LLM优化技术的组合使用可能对大模型产生负面影响，因为累积的近似误差会比小模型更严重。实验表明，仅依赖F1分数会掩盖这些问题，因为它隐藏了问答任务中的精确率-召回率权衡。通过整合系统级分析和任务特定洞察，为LLM从业者和研究人员提供了平衡效率、准确性和可扩展性的新见解。

Conclusion: LLM优化技术的组合使用可能对大模型产生负面影响，因为累积的近似误差会比小模型更严重。实验表明，仅依赖F1分数会掩盖这些问题，因为它隐藏了问答任务中的精确率-召回率权衡。本研究通过整合系统级分析和任务特定洞察，为LLM从业者和研究人员提供了在任务和硬件配置之间平衡效率、准确性和可扩展性的新见解。

Abstract: Large language models (LLMs) excel across diverse natural language processing
tasks but face resource demands and limited context windows. Although
techniques like pruning, quantization, and token dropping can mitigate these
issues, their efficacy in long-context scenarios and system evaluation remains
underexplored. This paper systematically benchmarks these optimizations,
characterizing memory usage, latency, and throughput, and studies how these
methods impact the quality of text generation. We first analyze individual
optimization methods for two LLM architectures supporting long context and then
systematically evaluate combinations of these techniques to assess how this
deeper analysis impacts performance metrics. We subsequently study the
scalability of individual optimization methods on a larger variant with 70
billion-parameter model. Our novel insights reveal that naive combination
inference optimization algorithms can adversely affect larger models due to
compounded approximation errors, as compared to their smaller counterparts.
Experiments show that relying solely on F1 obscures these effects by hiding
precision-recall trade-offs in question answering tasks. By integrating
system-level profiling with task-specific insights, this study helps LLM
practitioners and researchers explore and balance efficiency, accuracy, and
scalability across tasks and hardware configurations.

</details>


### [102] [Improving Multimodal Contrastive Learning of Sentence Embeddings with Object-Phrase Alignment](https://arxiv.org/abs/2508.00332)
*Kaiyan Zhao,Zhongtao Miao,Yoshimasa Tsuruoka*

Main category: cs.CL

TL;DR: MCSEO通过精确的对象-词语对齐来提高多模态句嵌入的质量，以解决图像-标题数据中的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态句嵌入模型在训练时通常会使用包含噪声（冗余或无关信息）的图像-标题对。MCSEO旨在缓解这个问题。

Method: MCSEO利用现有的分割和目标检测模型提取精确的对象-词语对，并优化对比学习目标以实现对象-词语对应。

Result: 在跨不同骨干模型的语义文本相似性（STS）任务上的实验结果表明，MCSEO持续优于强大的基线模型。

Conclusion: MCSEO通过引入细粒度的 图像-对象-词语 对齐，提高了多模态句嵌入的表示能力，并在语义文本相似性任务上取得了优于现有方法的性能。

Abstract: Multimodal sentence embedding models typically leverage image-caption pairs
in addition to textual data during training. However, such pairs often contain
noise, including redundant or irrelevant information on either the image or
caption side. To mitigate this issue, we propose MCSEO, a method that enhances
multimodal sentence embeddings by incorporating fine-grained object-phrase
alignment alongside traditional image-caption alignment. Specifically, MCSEO
utilizes existing segmentation and object detection models to extract accurate
object-phrase pairs, which are then used to optimize a contrastive learning
objective tailored to object-phrase correspondence. Experimental results on
semantic textual similarity (STS) tasks across different backbone models
demonstrate that MCSEO consistently outperforms strong baselines, highlighting
the significance of precise object-phrase alignment in multimodal
representation learning.

</details>


### [103] [PilotRL: Training Language Model Agents via Global Planning-Guided Progressive Reinforcement Learning](https://arxiv.org/abs/2508.00344)
*Keer Lu,Chong Chen,Bin Cui,Huang Leng,Wentao Zhang*

Main category: cs.CL

TL;DR: AdaPlan 和 PilotRL 框架通过全局规划和渐进式强化学习提升了 LLM 代理在复杂任务中的决策能力和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有 LLM 代理范式（如 ReAct）在处理需要长期战略规划的复杂任务时效果有限，且在规划者和执行者之间的协调以及依赖监督微调导致泛化能力受限等方面存在挑战。

Method: 提出了一种名为 AdaPlan 的自适应全局规划代理范式，以协同高级显式指导和执行来支持有效的长时决策。基于此范式，提出了 PilotRL，一个由渐进式强化学习驱动的全局规划指导的 LLM 代理训练框架，分阶段优化模型的规划遵循能力、规划生成质量以及规划与执行的协同。

Result: 实验表明，PilotRL 取得了最先进的性能，LLaMA3.1-8B-Instruct + PilotRL 在性能上超越了 GPT-4o 3.60%，并相比同等参数规模的 GPT-4o-mini 有了 55.78% 的显著提升。

Conclusion: AdaPlan 框架能够有效地利用全局规划来指导 LLM 代理进行长期决策，PilotRL 通过渐进式强化学习优化了规划和执行的协同，并在多项基准测试中取得了最先进的性能，超越了 GPT-4o 等模型。

Abstract: Large Language Models (LLMs) have shown remarkable advancements in tackling
agent-oriented tasks. Despite their potential, existing work faces challenges
when deploying LLMs in agent-based environments. The widely adopted agent
paradigm ReAct centers on integrating single-step reasoning with immediate
action execution, which limits its effectiveness in complex tasks requiring
long-term strategic planning. Furthermore, the coordination between the planner
and executor during problem-solving is also a critical factor to consider in
agent design. Additionally, current approaches predominantly rely on supervised
fine-tuning, which often leads models to memorize established task completion
trajectories, thereby restricting their generalization ability when confronted
with novel problem contexts. To address these challenges, we introduce an
adaptive global plan-based agent paradigm AdaPlan, aiming to synergize
high-level explicit guidance with execution to support effective long-horizon
decision-making. Based on the proposed paradigm, we further put forward
PilotRL, a global planning-guided training framework for LLM agents driven by
progressive reinforcement learning. We first develop the model's ability to
follow explicit guidance from global plans when addressing agent tasks.
Subsequently, based on this foundation, we focus on optimizing the quality of
generated plans. Finally, we conduct joint optimization of the model's planning
and execution coordination. Experiments indicate that PilotRL could achieve
state-of-the-art performances, with LLaMA3.1-8B-Instruct + PilotRL surpassing
closed-sourced GPT-4o by 3.60%, while showing a more substantial gain of 55.78%
comparing to GPT-4o-mini at a comparable parameter scale.

</details>


### [104] [Lucy: edgerunning agentic web search on mobile with machine generated task vectors](https://arxiv.org/abs/2508.00360)
*Alan Dao,Dinh Bach Vu,Alex Nguyen,Norapat Buppodom*

Main category: cs.CL

TL;DR: 研究人员提出了一种新范式，将小语言模型（SLM）的内部推理过程（<think>...</think>）视为动态任务向量机，并通过强化学习进行优化。他们训练了一个名为Lucy的17亿参数SLM，通过这种动态推理机制和多模态复杂性（MCP）集成，在SimpleQA基准测试上取得了78.3%的准确率，表现与大型模型相当。


<details>
  <summary>Details</summary>
Motivation: 由于容量受限，小语言模型（SLM）在知识密集型任务中表现不佳。虽然测试时计算可以提高性能，但大多数方法将推理视为固定的或启发式的。

Method: 将模型的内部推理过程（<think>...</think>）视为动态任务向量机，并使用强化学习从人类反馈（RLHF）来优化该过程，以训练一个代理网络搜索模型。

Result: 提出的方法使一个17亿参数的小型语言模型（Lucy）在SimpleQA基准测试上达到了78.3%的准确率，与DeepSeek-V3等大型模型相当。

Conclusion: 通过集成多模态复杂性（MCP）和动态任务向量，小语言模型（SLM）在知识密集型任务上取得了与大型模型相媲美的性能，证明了结构化、自构任务推理的重要性。

Abstract: Small language models (SLMs) are inherently limited in knowledge-intensive
tasks due to their constrained capacity. While test-time computation offers a
path to enhanced performance, most approaches treat reasoning as a fixed or
heuristic process. In this work, we propose a new paradigm: viewing the model's
internal reasoning, delimited by <think> and </think> tags, as a dynamic task
vector machine. Rather than treating the content inside these tags as a mere
trace of thought, we interpret the generation process itself as a mechanism
through which the model \textbf{constructs and refines its own task vectors} on
the fly. We developed a method to optimize this dynamic task vector machine
through RLVR and successfully trained an agentic web-search model. We present
Lucy, a 1.7B-parameter SLM that leverages this dynamic reasoning mechanism with
MCP integration to achieve 78.3% accuracy on the SimpleQA benchmark, performing
on par with much larger models such as DeepSeek-V3. This demonstrates that
small models can rival large ones when equipped with structured,
self-constructed task reasoning.

</details>


### [105] [EdgeInfinite-Instruct: Bridging SFT-Based Optimization and NPU-Level Efficiency for Edge Devices](https://arxiv.org/abs/2508.00370)
*Jiyu Chen,Poh Seng Lim,Shuang Peng,Daxiong Luo,JungHau Foo,Yap Deep,Timothy Lee Jun Jie,Kelvin Teh Kae Wen,Fan Yang,Danyu Feng,Hao-Yun Chen,Peng-Wen Chen,Fangyuan Li,Xiaoxin Chen,Wong Wai Mun*

Main category: cs.CL

TL;DR: EdgeInfinite-Instruct通过S-SFT、PTQ和固定形状计算图优化了LLMs在边缘设备的部署，解决了长序列任务的效率和性能问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决在资源受限的边缘设备上部署Transformer-based LLMs用于长序列任务的挑战，这些挑战源于自注意力机制的二次时间复杂度和日益增长的KV缓存需求，同时需要改进现有的KV缓存优化方法（它们可能无法减少首次令牌时间TTFT或会因令牌修剪而降低性能）和替代序列建模架构（它们通常需要完全重新训练且缺乏基础设施支持）。

Method: 提出了一种名为EdgeInfinite-Instruct的解决方案，该方案通过采用段监督微调（S-SFT）策略来优化长序列任务，并针对边缘NPU部署进行了优化，包括使用细粒度训练后量化（PTQ）和固定形状计算图。

Result: 实验表明，该方法在长上下文基准和真实世界的移动任务上，提高了领域特定性能，同时在NPU加速的边缘设备上保持了效率。

Conclusion: EdgeInfinite-Instruct通过结合S-SFT策略、PTQ和固定形状计算图，在保持效率的同时，提高了模型在NPU加速的边缘设备上处理长序列任务（如摘要和问答）的领域特定性能。

Abstract: Deploying Transformer-based large language models (LLMs) on
resource-constrained edge devices for long-sequence tasks remains challenging
due to the quadratic time complexity of self-attention and growing Key-Value
(KV) cache demands. While existing KV cache optimizations improve memory
efficiency, they often fail to reduce time to first token (TTFT) and may
degrade performance through token pruning. Alternative sequence modeling
architectures address some of these limitations, but typically require full
retraining and lack infrastructure support. EdgeInfinite offers an efficient
solution by fine-tuning only a small subset of parameters, maintaining quality
while reducing both computational and memory costs, including improved TTFT.
However, its instruction-following ability is limited, and it lacks
mobile-specific optimizations. To address these issues, we propose
EdgeInfinite-Instruct, which introduces a Segmented Supervised Fine-Tuning
(S-SFT) strategy tailored to long-sequence tasks such as summarization and
question answering. We further optimized EdgeInfinite-Instruct for efficient
deployment on edge NPUs by employing fine-grained post-training quantization
(PTQ) to reduce computational demands while maintaining accuracy, and by
implementing a fixed-shape computation graph that balances memory usage and
on-device efficiency through scenario-specific customization of input token and
cache sizes. Experiments on long-context benchmarks and real-world mobile tasks
show that our approach improves domain-specific performance while maintaining
efficiency on NPU-accelerated edge devices.

</details>


### [106] [Multi-Layer Attention is the Amplifier of Demonstration Effectiveness](https://arxiv.org/abs/2508.00385)
*Dingzirui Wang,Xuangliang Zhang,Keyan Xu,Qingfu Zhu,Wanxiang Che,Yang Deng*

Main category: cs.CL

TL;DR: 该研究分析了 in-context learning (ICL) 中示范无效的原因，提出了一种名为 GradS 的新方法，通过梯度流选择示范，并在实验中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注示范的有效性，而忽略了并非所有示范都有效这一事实。因此，需要研究示范无效的原因，并提出一种能选择有效示范的方法。

Method: 通过设置梯度流为零来分析示范无效的原因。提出了一种名为 GradS 的新方法，该方法利用梯度流来选择示范，并使用示范相对于给定用户查询的梯度流幅度作为标准。

Result: 梯度流分析和 GradS 在四个主流大型语言模型和五个主流数据集上进行了验证。实验结果证实了模型层数增加会放大示范有效性方面的差异，支持了推导。GradS 平均比最强的基线提高了 6.8%，证明了其有效性。

Conclusion: 梯度流和线性自注意力分析表明，当示范信息已被模型学习或与用户查询无关时，示范会失效。模型层数增加会放大示范有效性方面的差异，使得模型更关注有效的示范。提出的 GradS 方法利用梯度流来选择示范，并确保所选示范的有效性。

Abstract: Numerous studies have investigated the underlying mechanisms of in-context
learning (ICL) effectiveness to inspire the design of related methods. However,
existing work predominantly assumes the effectiveness of the demonstrations
provided within ICL, while many research indicates that not all demonstrations
are effective, failing to yielding any performance improvement during ICL.
Therefore, in this paper, we investigate the reasons behind demonstration
ineffectiveness. Our analysis is based on gradient flow and linear
self-attention models. By setting the gradient flow to zero, we deduce that a
demonstration becomes ineffective if its information has either been learned by
the model or is irrelevant to the user query. Furthermore, we demonstrate that
in multi-layer models, the disparity in effectiveness among demonstrations is
amplified with layer increasing, causing the model to focus more on effective
ones. Considering that current demonstration selection methods primarily focus
on the relevance to the user query while overlooking the information that the
model has already assimilated, we propose a novel method called GradS, which
leverages gradient flow for demonstration selection. We use the magnitude of
the gradient flow of the demonstration with respect to a given user query as
the criterion, thereby ensuring the effectiveness of the chosen ones. We
validate our derivation and GradS on four prominent LLMs across five mainstream
datasets. The experimental results confirm that the disparity in effectiveness
among demonstrations is magnified as the model layer increases, substantiating
our derivations. Moreover, GradS achieves a relative improvement of $6.8\%$ on
average over the strongest baselines, demonstrating its effectiveness.

</details>


### [107] [SA-GCS: Semantic-Aware Gaussian Curriculum Scheduling for UAV Vision-Language Navigation](https://arxiv.org/abs/2508.00390)
*Hengxing Cai,Jinhan Dong,Yijie Rao,Jingcheng Deng,Jingjun Tan,Qien Chen,Haidong Wang,Zhen Wang,Shiyu Huang,Agachai Sumalee,Renxin Zhong*

Main category: cs.CL

TL;DR: SA-GCS 通过将课程学习整合到强化学习中，解决了现有 RL 方法在数据利用、收敛速度和样本难度处理方面的不足，从而提高了无人机视觉语言导航的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）方法在利用训练数据、收敛速度和样本难度变化考虑不足方面存在效率低下、收敛缓慢和训练样本难度变化考虑不足的问题，这限制了性能的进一步提升。

Method: 提出了一种名为“语义感知高斯课程调度 (SA-GCS)”的新颖训练框架，该框架将课程学习（CL）系统地整合到强化学习（RL）中。SA-GCS 采用语义感知难度估计器（SA-DE）来量化训练样本的复杂性，并采用高斯课程调度器（GCS）来动态调整采样分布，从而实现从简单到复杂的任务的平滑进展。

Result: SA-GCS 显著提高了训练效率，加速了收敛，并增强了整体模型性能。

Conclusion: SA-GCS 在 CityNav 基准测试中持续优于强基线，在所有指标上均表现出色，实现了更快、更稳定的收敛，并在不同规模的模型上表现出良好的泛化能力，证明了其鲁棒性和可扩展性。

Abstract: Unmanned Aerial Vehicle (UAV) Vision-Language Navigation (VLN) aims to enable
agents to accurately localize targets and plan flight paths in complex
environments based on natural language instructions, with broad applications in
intelligent inspection, disaster rescue, and urban monitoring. Recent progress
in Vision-Language Models (VLMs) has provided strong semantic understanding for
this task, while reinforcement learning (RL) has emerged as a promising
post-training strategy to further improve generalization. However, existing RL
methods often suffer from inefficient use of training data, slow convergence,
and insufficient consideration of the difficulty variation among training
samples, which limits further performance improvement. To address these
challenges, we propose \textbf{Semantic-Aware Gaussian Curriculum Scheduling
(SA-GCS)}, a novel training framework that systematically integrates Curriculum
Learning (CL) into RL. SA-GCS employs a Semantic-Aware Difficulty Estimator
(SA-DE) to quantify the complexity of training samples and a Gaussian
Curriculum Scheduler (GCS) to dynamically adjust the sampling distribution,
enabling a smooth progression from easy to challenging tasks. This design
significantly improves training efficiency, accelerates convergence, and
enhances overall model performance. Extensive experiments on the CityNav
benchmark demonstrate that SA-GCS consistently outperforms strong baselines
across all metrics, achieves faster and more stable convergence, and
generalizes well across models of different scales, highlighting its robustness
and scalability. The implementation of our approach is publicly available.

</details>


### [108] [Combining Discrete Wavelet and Cosine Transforms for Efficient Sentence Embedding](https://arxiv.org/abs/2508.00420)
*Rana Salama,Abdou Youssef,Mona Diab*

Main category: cs.CL

TL;DR: Wavelets (DWT and DWT+DCT) are effective for NLP tasks, improving word embeddings and compressing sentences, with results comparable or better than existing methods.


<details>
  <summary>Details</summary>
Motivation: To explore the application of wavelets, a cutting-edge technology in various fields, to Natural Language Processing (NLP) tasks by capturing linguistic properties in word and sentence embeddings.

Method: Leveraging Discrete Wavelet Transforms (DWT) for word and sentence embeddings, and combining DWT with Discrete Cosine Transform (DCT) to create a non-parameterized sentence compression model.

Result: The proposed paradigm shows efficacy in downstream applications, yielding comparable or even superior results to original embeddings on certain tasks.

Conclusion: Wavelet transforms, particularly DWT, can effectively consolidate information in word embeddings, reduce dimensionality, and compress sentences into fixed-size vectors. Combining DWT with DCT yields a non-parameterized model that achieves comparable or superior results to original embeddings in downstream NLP tasks.

Abstract: Wavelets have emerged as a cutting edge technology in a number of fields.
Concrete results of their application in Image and Signal processing suggest
that wavelets can be effectively applied to Natural Language Processing (NLP)
tasks that capture a variety of linguistic properties. In this paper, we
leverage the power of applying Discrete Wavelet Transforms (DWT) to word and
sentence embeddings. We first evaluate, intrinsically and extrinsically, how
wavelets can effectively be used to consolidate important information in a word
vector while reducing its dimensionality. We further combine DWT with Discrete
Cosine Transform (DCT) to propose a non-parameterized model that compresses a
sentence with a dense amount of information in a fixed size vector based on
locally varying word features. We show the efficacy of the proposed paradigm on
downstream applications models yielding comparable and even superior (in some
tasks) results to original embeddings.

</details>


### [109] [Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges](https://arxiv.org/abs/2508.00454)
*Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding*

Main category: cs.CL

TL;DR: 提出了一种高效的多轮对话评估器，通过聚合多个LLM裁判的偏好知识到单个模型中，解决了现有评估方法的偏见和高计算成本问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有“LLM-as-a-judge”范式存在偏见问题，多裁判方法计算开销大。旨在提出一种高效的方法来解决这些问题。

Method: 提出了一种高效的多轮对话评估器，通过聚合多个LLM裁判的偏好知识到单个模型中。

Result: 在七个单评分和成对比较对话评估基准上进行了广泛的实验，结果表明该方法在各种场景下优于现有基线，展现了其效率和鲁棒性。

Conclusion: 所提出的多轮对话评估器通过聚合多个LLM裁判的偏好知识到单个模型中，有效保留了多裁判反馈的优势，同时大幅降低了评估成本，实现了快速灵活的对话质量评估。

Abstract: Evaluating the conversational abilities of large language models (LLMs)
remains a challenging task. Current mainstream approaches primarily rely on the
``LLM-as-a-judge" paradigm, where an LLM is prompted to serve as an evaluator
to assess dialogue quality. However, such methods often suffer from various
biases, which undermine the reliability and consistency of the evaluation
results. To mitigate these biases, recent methods employ multiple LLMs as
judges and aggregate their judgments to select the optimal assessment. Although
effective, this multi-judge approach incurs significant computational overhead
during inference. In this paper, we propose an efficient multi-turn dialogue
evaluator that captures the collective wisdom of multiple LLM judges by
aggregating their preference knowledge into a single model. Our approach
preserves the advantages of diverse multi-judge feedback while drastically
reducing the evaluation cost, enabling fast and flexible dialogue quality
assessment. Extensive experiments on seven single rating and pairwise
comparison dialogue evaluation benchmarks demonstrate that our method
outperforms existing baselines across diverse scenarios, showcasing its
efficiency and robustness.

</details>


### [110] [GETALP@AutoMin 2025: Leveraging RAG to Answer Questions based on Meeting Transcripts](https://arxiv.org/abs/2508.00476)
*Jeongwoo Kang,Markarit Vartampetian,Felix Herron,Yongxin Zhou,Diandra Fabre,Gabriela Gonzalez-Saez*

Main category: cs.CL

TL;DR: GETALP 使用结合了 RAG 和 AMR 的系统参加了会议记录问答任务，AMR 提高了约 35% 的问题回答质量，尤其在区分参与者的问题上效果更佳。


<details>
  <summary>Details</summary>
Motivation: 参加 SIGDial 2025 自动会议记录共享任务 B，旨在解决基于会议记录的问答问题。

Method: 该方法结合了检索增强生成（RAG）和抽象意义表示（AMR），并提出了三种组合这两种方法的系统。

Result: 实验结果表明，AMR 的引入能够提高约 35% 问题的回答质量，并在回答涉及区分不同参与者（例如，“谁”问题）的问题方面有显著改进。

Conclusion: GETALP 提交了基于检索增强生成（RAG）和抽象意义表示（AMR）的系统参加了 SIGDial 2025 自动会议记录共享任务 B（基于会议记录的问答）。

Abstract: This paper documents GETALP's submission to the Third Run of the Automatic
Minuting Shared Task at SIGDial 2025. We participated in Task B:
question-answering based on meeting transcripts. Our method is based on a
retrieval augmented generation (RAG) system and Abstract Meaning
Representations (AMR). We propose three systems combining these two approaches.
Our results show that incorporating AMR leads to high-quality responses for
approximately 35% of the questions and provides notable improvements in
answering questions that involve distinguishing between different participants
(e.g., who questions).

</details>


### [111] [The Missing Parts: Augmenting Fact Verification with Half-Truth Detection](https://arxiv.org/abs/2508.00489)
*Yixuan Tang,Jincheng Wang,Anthony K. H. Tung*

Main category: cs.CL

TL;DR: 该研究提出了 TRACER 框架来检测遗漏关键信息而产生的误导性声明（半真实性），并构建了一个新的基准 PolitiFact-Hidden。TRACER 通过对齐证据、推断意图和评估隐藏内容的影响来识别此类错误信息，并能有效提升现有事实核查系统的性能。


<details>
  <summary>Details</summary>
Motivation: 现有事实核查系统主要关注证据是否支持声明，而忽视了许多现实世界中的声明虽然在事实层面正确但可能因遗漏关键信息而产生误导。为了解决这一问题，引入了半真实性检测任务，并提出了一个名为 PolitiFact-Hidden 的新基准，包含 15k 个政治声明及其句子级证据对齐和推断的声明意图。

Method: 提出了一种名为 TRACER 的模块化重评估框架，该框架通过对证据进行对齐、推断隐含意图以及估计隐藏内容的因果影响来识别基于遗漏的错误信息。

Result: TRACER 框架可以整合到现有的事实核查流程中，并能在多个强基线上持续提高性能，特别是将 Half-True 分类的 F1 分数提高了 16 个点。

Conclusion: TRACER 框架能够识别基于遗漏的错误信息，并能整合到现有的事实核查流程中，在多个强基线上持续提高性能，特别是将 Half-True 分类的 F1 分数提高了 16 个点，凸显了在可信事实核查中对遗漏信息进行建模的重要性。

Abstract: Fact verification systems typically assess whether a claim is supported by
retrieved evidence, assuming that truthfulness depends solely on what is
stated. However, many real-world claims are half-truths, factually correct yet
misleading due to the omission of critical context. Existing models struggle
with such cases, as they are not designed to reason about what is left unsaid.
We introduce the task of half-truth detection, and propose PolitiFact-Hidden, a
new benchmark with 15k political claims annotated with sentence-level evidence
alignment and inferred claim intent. To address this challenge, we present
TRACER, a modular re-assessment framework that identifies omission-based
misinformation by aligning evidence, inferring implied intent, and estimating
the causal impact of hidden content. TRACER can be integrated into existing
fact-checking pipelines and consistently improves performance across multiple
strong baselines. Notably, it boosts Half-True classification F1 by up to 16
points, highlighting the importance of modeling omissions for trustworthy fact
verification.

</details>


### [112] [EFlat-LoRA: Efficiently Seeking Flat Minima for Better Generalization in Fine-Tuning Large Language Models and Beyond](https://arxiv.org/abs/2508.00522)
*Jiaxin Deng,Qingcheng Zhu,Junbiao Pang,Linlin Yang,Zhongqian Fu,Baochang Zhang*

Main category: cs.CL

TL;DR: Flat-LoRA和EFlat-LoRA通过寻找LoRA的平坦最小区域来提高模型泛化能力，实验证明其效果优于LoRA和全参数微调。


<details>
  <summary>Details</summary>
Motivation: 为了探索低秩适应（LoRA）的可表达能力和泛化能力之间的相关性，以及解决以往研究中缺乏寻找平坦最小区域的工具或理论方法的不足。

Method: 提出了Flat-LoRA和EFlat-LoRA来寻找LoRA的平坦最小区域，理论上证明了全参数空间的扰动可以转移到低秩子空间，从而避免了低秩子空间中多个扰动矩阵的潜在干扰。

Result: 实验证明，EFlat-LoRA在优化效率上与LoRA相当，同时在性能上也能达到相当甚至更好的水平。例如，在GLUE数据集上，EFlat-LoRA相比LoRA和全参数微调平均分别提高了1.0%和0.5%；在视觉语言模型方面，Qwen-VL-Chat在SQA和VizWiz数据集上的性能分别提高了1.5%和1.0%。

Conclusion: 该研究表明LoRA的泛化能力与sharpness密切相关，而这被之前的研究方法所忽略。

Abstract: Little research explores the correlation between the expressive ability and
generalization ability of the low-rank adaptation (LoRA). Sharpness-Aware
Minimization (SAM) improves model generalization for both Convolutional Neural
Networks (CNNs) and Transformers by encouraging convergence to locally flat
minima. However, the connection between sharpness and generalization has not
been fully explored for LoRA due to the lack of tools to either empirically
seek flat minima or develop theoretical methods. In this work, we propose
Flat-LoRA and its efficient version i.e., EFlat-LoRA, to seek flat minima for
LoRA. Concretely, we theoretically demonstrate that perturbations in the full
parameter space can be transferred to the low-rank subspace. This approach
eliminates the potential interference introduced by perturbations across
multiple matrices in the low-rank subspace. Our extensive experiments on large
language models and vision-language models demonstrate that EFlat-LoRA achieves
optimize efficiency comparable to that of LoRA while simultaneously attaining
comparable or even better performance. For example, on the GLUE dataset with
RoBERTa-large, EFlat-LoRA outperforms LoRA and full fine-tuning by 1.0% and
0.5% on average, respectively. On vision-language models e.g., Qwen-VL-Chat
shows performance improvements of 1.5% and 1.0% on SQA and VizWiz datasets,
respectively. These empirical results also verify that the generalization of
LoRA is closely related to sharpness, which is omitted by previous methods.

</details>


### [113] [The Prosody of Emojis](https://arxiv.org/abs/2508.00537)
*Giulio Zhou,Tsz Kin Lam,Alexandra Birch,Barry Haddow*

Main category: cs.CL

TL;DR: Emojis affect speech prosody; listeners can infer emojis from speech, and different emojis have distinct prosodic markers.


<details>
  <summary>Details</summary>
Motivation: This study examines how emojis influence prosodic realization in speech and how listeners interpret prosodic cues to recover emoji meanings, directly linking prosody and emoji.

Method: The study analyzed actual human speech data, collected through structured but open-ended production and perception tasks.

Result: Speakers adapt their prosody based on emoji cues, listeners can often identify the intended emoji from prosodic variation alone, and greater semantic differences between emojis correspond to increased prosodic divergence.

Conclusion: Emojis can act as meaningful carriers of prosodic intent, offering insight into their communicative role in digitally mediated contexts.

Abstract: Prosodic features such as pitch, timing, and intonation are central to spoken
communication, conveying emotion, intent, and discourse structure. In
text-based settings, where these cues are absent, emojis act as visual
surrogates that add affective and pragmatic nuance. This study examines how
emojis influence prosodic realisation in speech and how listeners interpret
prosodic cues to recover emoji meanings. Unlike previous work, we directly link
prosody and emoji by analysing actual human speech data, collected through
structured but open-ended production and perception tasks. This provides
empirical evidence of how emoji semantics shape spoken delivery and perception.
Results show that speakers adapt their prosody based on emoji cues, listeners
can often identify the intended emoji from prosodic variation alone, and
greater semantic differences between emojis correspond to increased prosodic
divergence. These findings suggest that emojis can act as meaningful carriers
of prosodic intent, offering insight into their communicative role in digitally
mediated contexts.

</details>


### [114] [PaPaformer: Language Model from Pre-trained Paraller Paths](https://arxiv.org/abs/2508.00544)
*Joonas Tapaninaho,Mourad Oussala*

Main category: cs.CL

TL;DR: PaPaformer是一种新的语言模型训练方法，可以在数小时内完成训练，并且性能更优。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型的训练需要大量的计算能力和时间，即使是小型模型也需要数天甚至多个GPU才能训练。本研究旨在探索在数小时内训练和评估语言模型的方法。

Method: 提出了一种名为PaPaformer的解码器-Transformer架构变体，其低维并行路径可以被单独训练，然后组合成一个更大的模型。

Result: PaPaformer可以减少总模型参数量和训练时间，同时提高性能。

Conclusion: PaPaformer架构通过使用低维并行路径，可以在数小时而非数天/数周内训练和评估基于Transformer的解码器模型，同时减少模型参数数量、训练时间和提高性能，并为定制化路径以满足特定任务需求提供了可能性。

Abstract: The training of modern large-language models requires an increasingly amount
of computation power and time. Even smaller variants, such as small-language
models (SLMs), take several days to train in the best-case scenarios, often
requiring multiple GPUs. This paper explores methods to train and evaluate
decoder-only transformer-based language models in hours instead of days/weeks.
We introduces \textit{PaPaformer}, a decoder-only transformer architecture
variant, whose lower-dimensional parallel paths are combined into larger model.
The paper shows that these lower-dimensional paths can be trained individually
with different types of training data and then combined into one larger model.
This method gives the option to reduce the total number of model parameters and
the training time with increasing performance. Moreover, the use of parallel
path structure opens interesting possibilities to customize paths to
accommodate specific task requirements.

</details>


### [115] [SynAdapt: Learning Adaptive Reasoning in Large Language Models via Synthetic Continuous Chain-of-Thought](https://arxiv.org/abs/2508.00574)
*Jianwei Wang,Ziming Wu,Fuming Lai,Shaobing Lian,Ziqian Zeng*

Main category: cs.CL

TL;DR: SynAdapt通过生成合成的CCoT和自适应地提示模型重新思考难问，提高了语言模型的推理效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有连续思维链（CCoT）方法在微调、对齐和目标一致性方面的不足，并提高语言模型在处理复杂推理任务时的效率。

Method: SynAdapt框架通过生成合成的连续思维链（CCoT）作为语言模型的对齐目标，并结合难度分类器来识别和重新思考难问，从而提高模型性能。

Result: SynAdapt通过生成合成CCoT和自适应地提示模型重新思考难问，显著提高了模型的准确性和效率，实现了最佳的准确性-效率权衡。

Conclusion: SynAdapt在不同难度级别的数据集上进行了广泛的实验，证明了其有效性，实现了最佳的准确性-效率权衡。

Abstract: While Chain-of-Thought (CoT) reasoning improves model performance, it incurs
significant time costs due to the generation of discrete CoT tokens (DCoT).
Continuous CoT (CCoT) offers a more efficient alternative, but existing CCoT
methods are hampered by indirect fine-tuning, limited alignment, or
inconsistent targets. To overcome these limitations, we propose
\textit{SynAdapt}, an innovative efficient reasoning framework. Specifically,
\textit{SynAdapt} generates the synthetic CCoT to serve as a precise and
effective alignment target for LLMs. This synthetic CCoT explicitly guides the
LLM to learn CCoT and derive accurate answers directly. Furthermore, relying
solely on CCoT is insufficient for solving hard questions. To address this,
\textit{SynAdapt} integrates a difficulty classifier that leverages both
question context and CCoT to identify hard questions. CCoT can effectively help
identify hard questions after some brief reasoning. We then adaptively prompt
the LLM to re-think these hard questions for improved performance. Extensive
experimental results across various benchmarks from different difficulty levels
strongly demonstrate the effectiveness of our method, achieving the best
accuracy-efficiency trade-off.

</details>


### [116] [NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts](https://arxiv.org/abs/2502.18148)
*Muhammad Farid Adilazuarda,Musa Izzanardi Wijanarko,Lucky Susanto,Khumaisa Nur'aini,Derry Wijaya,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 本研究提出了NusaAksara，一个包含印尼本土文字（包括低资源和非Unicode文字）的文本和图像基准，用于评估OCR、翻译等任务。结果显示现有NLP技术在处理这些文字时表现不佳。


<details>
  <summary>Details</summary>
Motivation: 大多数自然语言处理的进展都是使用罗马字母文本完成的，但印度尼西亚拥有丰富的语言和文字。

Method: 提出NusaAksara，一个包含印尼原始文字的公共基准，涵盖文本和图像模态，以及图像分割、OCR、音译、翻译和语言识别等任务。该数据由人类专家通过严格步骤构建，包含8种文字和7种语言，其中包括低资源语言和不受Unicode支持的楠榜语。

Result: NusaAksara 包含了8 种文字和 7 种语言，包括低资源语言和不受 Unicode 支持的楠榜语。测试结果表明，大多数自然语言处理技术（包括 LLMs、VLMs 和特定任务系统）在处理印度尼西亚本地文字方面表现不佳，准确率接近于零。

Conclusion: 大多数自然语言处理技术无法处理印尼的本地文字，许多技术的表现接近于零。

Abstract: Indonesia is rich in languages and scripts. However, most NLP progress has
been made using romanized text. In this paper, we present NusaAksara, a novel
public benchmark for Indonesian languages that includes their original scripts.
Our benchmark covers both text and image modalities and encompasses diverse
tasks such as image segmentation, OCR, transliteration, translation, and
language identification. Our data is constructed by human experts through
rigorous steps. NusaAksara covers 8 scripts across 7 languages, including
low-resource languages not commonly seen in NLP benchmarks. Although
unsupported by Unicode, the Lampung script is included in this dataset. We
benchmark our data across several models, from LLMs and VLMs such as GPT-4o,
Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and
show that most NLP technologies cannot handle Indonesia's local scripts, with
many achieving near-zero performance.

</details>


### [117] [A Context-Aware Dual-Metric Framework for Confidence Estimation in Large Language Models](https://arxiv.org/abs/2508.00600)
*Mingruo Yuan,Shuyi Zhang,Ben Kao*

Main category: cs.CL

TL;DR: CRUX框架通过考虑上下文信息来提高LLM的置信度估计，并通过两种新方法（上下文熵约减和统一一致性检验）来衡量不确定性和一致性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的置信度估计方法忽略了响应与上下文信息之间的相关性，这在有背景知识的场景下是评估输出质量的关键因素。为解决此问题，提出CRUX框架。

Method: 提出CRUX框架，整合了上下文忠实度和一致性，通过两种新颖的度量方法进行置信度估计：上下文熵约减（通过有无上下文的对比采样表示数据不确定性）和统一一致性检验（捕捉生成答案与有无上下文的全局一致性）。

Result: CRUX在CoQA、SQuAD、QuAC、BioASQ和EduQG数据集上的实验结果显示，其AUROC高于现有基线。

Conclusion: CRUX在三个基准数据集和两个特定领域的数据集上进行了实验，并取得了比现有基线更高的AUROC，证明了其有效性。

Abstract: Accurate confidence estimation is essential for trustworthy large language
models (LLMs) systems, as it empowers the user to determine when to trust
outputs and enables reliable deployment in safety-critical applications.
Current confidence estimation methods for LLMs neglect the relevance between
responses and contextual information, a crucial factor in output quality
evaluation, particularly in scenarios where background knowledge is provided.
To bridge this gap, we propose CRUX (Context-aware entropy Reduction and
Unified consistency eXamination), the first framework that integrates context
faithfulness and consistency for confidence estimation via two novel metrics.
First, contextual entropy reduction represents data uncertainty with the
information gain through contrastive sampling with and without context. Second,
unified consistency examination captures potential model uncertainty through
the global consistency of the generated answers with and without context.
Experiments across three benchmark datasets (CoQA, SQuAD, QuAC) and two
domain-specific datasets (BioASQ, EduQG) demonstrate CRUX's effectiveness,
achieving the highest AUROC than existing baselines.

</details>


### [118] [GHTM: A Graph based Hybrid Topic Modeling Approach in Low-Resource Bengali Language](https://arxiv.org/abs/2508.00605)
*Farhana Haque,Md. Abdur Rahman,Sumon Ahmed*

Main category: cs.CL

TL;DR: 提出了一种名为GHTM的新型图基混合主题模型，用于孟加拉语主题建模，并在主题一致性和多样性方面优于现有模型。此外，还发布了一个名为NCTBText的新孟加拉语数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管主题建模在英语中得到了广泛研究，但由于其形态复杂性、资源和倡议的缺乏，在孟加拉语中的研究仍然不足。

Method: 提出了一种基于图卷积网络（GCN）的新型图基混合主题模型（GHTM）。该模型将文档的输入向量表示为图中的节点，然后使用非负矩阵分解（NMF）来分解嵌入，以获得文本语料库的潜在主题的主题表示。

Result: GHTM模型在主题一致性和多样性方面优于LDA、LSA、NMF、BERTopic和Top2Vec等模型。

Conclusion: GHTM模型在主题一致性和多样性方面优于其他模型，并且引入了一个新的孟加拉语数据集NCTBText，以丰富孟加拉语语料库。

Abstract: Topic modeling is a Natural Language Processing (NLP) technique that is used
to identify latent themes and extract topics from text corpora by grouping
similar documents based on their most significant keywords. Although widely
researched in English, topic modeling remains understudied in Bengali due to
its morphological complexity, lack of adequate resources and initiatives. In
this contribution, a novel Graph Convolutional Network (GCN) based model called
GHTM (Graph-Based Hybrid Topic Model) is proposed. This model represents input
vectors of documents as nodes in the graph, which GCN uses to produce
semantically rich embeddings. The embeddings are then decomposed using
Non-negative Matrix Factorization (NMF) to get the topical representations of
the underlying themes of the text corpus. This study compares the proposed
model against a wide range of Bengali topic modeling techniques, from
traditional methods such as LDA, LSA, and NMF to contemporary frameworks such
as BERTopic and Top2Vec on three Bengali datasets. The experimental results
demonstrate the effectiveness of the proposed model by outperforming other
models in topic coherence and diversity. In addition, we introduce a novel
Bengali dataset called "NCTBText" sourced from Bengali textbook materials to
enrich and diversify the predominantly newspaper-centric Bengali corpora.

</details>


### [119] [Prompting Science Report 3: I'll pay you or I'll kill you -- but will you care?](https://arxiv.org/abs/2508.00614)
*Lennart Meincke,Ethan Mollick,Lilach Mollick,Dan Shapiro*

Main category: cs.CL

TL;DR: 简单提示（如给小费或威胁）对AI整体性能影响不大，但可能影响单题表现，不过难以预测。


<details>
  <summary>Details</summary>
Motivation: 本报告旨在帮助商业、教育和政策领导者理解AI的技术细节，通过对两种常见的提示工程策略（给予小费和威胁）进行实证测试，以验证其对AI模型性能的影响。

Method: 本研究通过严格测试，调查了两种常见的提示工程信念：a) 提出给予AI模型小费（tipping）和 b) 威胁AI模型（threatening）。研究评估了模型在GPQA和MMLU-Pro基准测试上的表现。

Result: 研究发现，威胁或给予模型小费通常对基准测试性能没有显著影响。虽然提示的变化可能显著影响模型在单个问题上的表现，但事先难以预料哪种提示方法会提高或损害LLM回答特定问题的能力。

Conclusion: 提示工程（prompting）的简单变化，尤其是在面对复杂问题时，可能不像之前假设的那样有效。然而，研究也指出，提示工程方法在单个问题上可能产生截然不同的结果。

Abstract: This is the third in a series of short reports that seek to help business,
education, and policy leaders understand the technical details of working with
AI through rigorous testing. In this report, we investigate two commonly held
prompting beliefs: a) offering to tip the AI model and b) threatening the AI
model. Tipping was a commonly shared tactic for improving AI performance and
threats have been endorsed by Google Founder Sergey Brin (All-In, May 2025,
8:20) who observed that 'models tend to do better if you threaten them,' a
claim we subject to empirical testing here. We evaluate model performance on
GPQA (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024).
  We demonstrate two things:
  - Threatening or tipping a model generally has no significant effect on
benchmark performance.
  - Prompt variations can significantly affect performance on a per-question
level. However, it is hard to know in advance whether a particular prompting
approach will help or harm the LLM's ability to answer any particular question.
  Taken together, this suggests that simple prompting variations might not be
as effective as previously assumed, especially for difficult problems. However,
as reported previously (Meincke et al. 2025a), prompting approaches can yield
significantly different results for individual questions.

</details>


### [120] [DACTYL: Diverse Adversarial Corpus of Texts Yielded from Large Language Models](https://arxiv.org/abs/2508.00619)
*Shantanu Thorat,Andrew Caines*

Main category: cs.CL

TL;DR: AI文本检测器在真实场景下表现不佳，本研究提出了DACTYL数据集，并对比了BCE和DXO两种训练方法。结果显示DXO方法在处理OOD数据和模型泛化能力上更优。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测器在实际应用中效果不佳，其鲁棒性有待提高。特别是对于少样本、单样本生成以及领域特定模型生成的文本，检测效果更差。

Method: 本研究提出了DACTYL数据集，专注于单样本/少样本生成文本和领域特定的持续预训练（CPT）语言模型。并对比了使用标准二元交叉熵（BCE）优化和深度X风险优化（DXO）两种方法训练的AI生成文本检测器。

Result: 在DACTYL测试集上，BCE训练的分类器性能略优于DXO。然而，在处理非分布外（OOD）文本时，DXO分类器表现更出色。在模拟的学生论文检测场景中，DXO分类器相比BCE分类器在低误报率下，宏F1分数高出50.56个百分点，表明DXO分类器泛化能力更强，不易过拟合。

Conclusion: 现有AI生成文本检测器在真实场景下表现不佳，可能对单样本/少样本生成文本和持续预训练模型生成的文本不够鲁棒。本研究通过引入DACTYL数据集，并对比了标准二元交叉熵（BCE）和深度X风险优化（DXO）两种训练方法，发现DXO训练的分类器在模型泛化能力上优于BCE，尤其在处理非分布外（OOD）数据时，能显著提高检测性能。

Abstract: Existing AIG (AI-generated) text detectors struggle in real-world settings
despite succeeding in internal testing, suggesting that they may not be robust
enough. We rigorously examine the machine-learning procedure to build these
detectors to address this. Most current AIG text detection datasets focus on
zero-shot generations, but little work has been done on few-shot or one-shot
generations, where LLMs are given human texts as an example. In response, we
introduce the Diverse Adversarial Corpus of Texts Yielded from Language models
(DACTYL), a challenging AIG text detection dataset focusing on
one-shot/few-shot generations. We also include texts from domain-specific
continued-pre-trained (CPT) language models, where we fully train all
parameters using a memory-efficient optimization approach. Many existing AIG
text detectors struggle significantly on our dataset, indicating a potential
vulnerability to one-shot/few-shot and CPT-generated texts. We also train our
own classifiers using two approaches: standard binary cross-entropy (BCE)
optimization and a more recent approach, deep X-risk optimization (DXO). While
BCE-trained classifiers marginally outperform DXO classifiers on the DACTYL
test set, the latter excels on out-of-distribution (OOD) texts. In our mock
deployment scenario in student essay detection with an OOD student essay
dataset, the best DXO classifier outscored the best BCE-trained classifier by
50.56 macro-F1 score points at the lowest false positive rates for both. Our
results indicate that DXO classifiers generalize better without overfitting to
the test set. Our experiments highlight several areas of improvement for AIG
text detectors.

</details>


### [121] [Medical Reasoning in the Era of LLMs: A Systematic Review of Enhancement Techniques and Applications](https://arxiv.org/abs/2508.00669)
*Wenxuan Wang,Zizhan Ma,Meidan Ding,Shiyi Zheng,Shengyuan Liu,Jie Liu,Jiaming Ji,Wenting Chen,Xiang Li,Linlin Shen,Yixuan Yuan*

Main category: cs.CL

TL;DR: 医学 LLM 推理能力有待提高，本文综述了训练和测试时增强技术，分析了其在不同模式和应用中的表现，并指出了忠实-合理性差距和多模态推理等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在医学领域的广泛应用，其在系统性、透明性和可验证性推理方面的能力成为临床实践的关键需求，但目前仍存在明显不足。因此，推动 LLM 从单一的答案生成转向专注于医学推理的研究变得至关重要。本研究旨在系统性地回顾这一新兴领域，为理解和发展更可靠的医学人工智能提供指导。

Method: 本篇论文是一项系统性综述，旨在梳理和分析医学领域用于增强大型语言模型（LLM）推理能力的技术。研究人员提出了一种推理增强技术的分类法，将其分为训练时策略（例如，监督微调、强化学习）和测试时机制（例如，提示工程、多智能体系统）。论文分析了这些技术在文本、图像、代码等不同数据模式以及诊断、教育、治疗规划等临床应用中的具体应用情况。同时，研究也回顾了评估基准的发展，从最初的准确性度量演变到对推理质量和视觉可解释性的高级评估。分析基于 2022 年至 2025 年间的 60 篇相关研究。

Result: 本篇论文通过对 60 篇相关研究的系统性回顾，提出了一个医学推理增强技术的分类法，并分析了这些技术在不同数据模式和临床应用中的运用情况。研究发现，评估基准已从基础的准确性指标发展到更复杂的推理质量和视觉可解释性评估。论文识别出忠实-合理性差距和原生多模态推理需求等关键挑战，并为未来医学人工智能的发展指明了方向。

Conclusion: 本篇论文识别出在医学领域，大型语言模型（LLM）在系统性、透明性和可验证性推理方面存在关键差距，这是临床实践的基石。为了弥补这一差距，研究人员正从单一步骤的答案生成转向专门为医学推理设计的 LLM。论文提出了一个推理增强技术的分类法，分为训练时策略（如监督微调、强化学习）和测试时机制（如提示工程、多智能体系统）。论文分析了这些技术在不同数据模式（文本、图像、代码）和关键临床应用（诊断、教育、治疗规划）中的应用。此外，论文还调查了评估基准的演变，从简单的准确性指标到对推理质量和视觉可解释性的复杂评估。基于对 2022-2025 年 60 项开创性研究的分析，论文最终指出了关键挑战，包括忠实-合理性差距和对原生多模态推理的需求，并概述了未来构建高效、稳健且具有社会技术责任的医学人工智能的发展方向。

Abstract: The proliferation of Large Language Models (LLMs) in medicine has enabled
impressive capabilities, yet a critical gap remains in their ability to perform
systematic, transparent, and verifiable reasoning, a cornerstone of clinical
practice. This has catalyzed a shift from single-step answer generation to the
development of LLMs explicitly designed for medical reasoning. This paper
provides the first systematic review of this emerging field. We propose a
taxonomy of reasoning enhancement techniques, categorized into training-time
strategies (e.g., supervised fine-tuning, reinforcement learning) and test-time
mechanisms (e.g., prompt engineering, multi-agent systems). We analyze how
these techniques are applied across different data modalities (text, image,
code) and in key clinical applications such as diagnosis, education, and
treatment planning. Furthermore, we survey the evolution of evaluation
benchmarks from simple accuracy metrics to sophisticated assessments of
reasoning quality and visual interpretability. Based on an analysis of 60
seminal studies from 2022-2025, we conclude by identifying critical challenges,
including the faithfulness-plausibility gap and the need for native multimodal
reasoning, and outlining future directions toward building efficient, robust,
and sociotechnically responsible medical AI.

</details>


### [122] [MELAC: Massive Evaluation of Large Language Models with Alignment of Culture in Persian Language](https://arxiv.org/abs/2508.00673)
*Farhan Farsi,Farnaz Aghababaloo,Shahriar Shariati Motlagh,Parsa Ghofrani,MohammadAli SadraeiJavaheri,Shayan Bali,Amirhossein Shabani,Farbod Bijary,Ghazal Zamaninejad,AmirMohammad Salehoof,Saeedeh Momtazi*

Main category: cs.CL

TL;DR: 本研究通过创建和使用新的评估数据集，填补了大型语言模型在波斯语和伊朗文化背景下评估的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM评估基准主要集中在英语和西方文化背景下，对于波斯语和伊朗文化等非西方背景的评估资源存在显著不足，因此需要为这些领域开发专门的评估工具。

Method: 本研究引入了19个新的评估数据集，涵盖了伊朗法律、波斯语语法、波斯语习语和大学入学考试等主题，并使用这些数据集对41个大型语言模型进行了基准测试。

Result: 通过在41个大型语言模型上进行测试，本研究为评估LLM在波斯语和伊朗文化背景下的表现提供了基准，并揭示了现有模型在该领域的优势和劣势。

Conclusion: LLMs在波斯语和伊朗文化背景下的评估能力存在显著差距，本研究通过引入19个新的评估数据集，并在41个大型语言模型上进行基准测试，旨在弥合这一差距。

Abstract: As large language models (LLMs) become increasingly embedded in our daily
lives, evaluating their quality and reliability across diverse contexts has
become essential. While comprehensive benchmarks exist for assessing LLM
performance in English, there remains a significant gap in evaluation resources
for other languages. Moreover, because most LLMs are trained primarily on data
rooted in European and American cultures, they often lack familiarity with
non-Western cultural contexts. To address this limitation, our study focuses on
the Persian language and Iranian culture. We introduce 19 new evaluation
datasets specifically designed to assess LLMs on topics such as Iranian law,
Persian grammar, Persian idioms, and university entrance exams. Using these
datasets, we benchmarked 41 prominent LLMs, aiming to bridge the existing
cultural and linguistic evaluation gap in the field.

</details>


### [123] [Team "better_call_claude": Style Change Detection using a Sequential Sentence Pair Classifier](https://arxiv.org/abs/2508.00675)
*Gleb Schmidt,Johannes Römisch,Mariia Halchynska,Svetlana Gorovaia,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: 通过序列句对分类器（SSPC）结合预训练语言模型（PLM）和双向LSTM（BiLSTM），在PAN 2025任务中实现了高精度的句级风格转变检测，尤其擅长处理短句。


<details>
  <summary>Details</summary>
Motivation: 解决计算作者身份分析中的风格转变检测问题，特别是在PAN 2025共享任务中以单个句子为单位进行最细粒度风格切换检测的挑战。

Method: 提出一种序列句对分类器（SSPC），利用预训练语言模型（PLM）获取句向量，并通过双向LSTM（BiLSTM）进行上下文建模，最后将相邻句子的BiLSTM向量拼接后输入多层感知机进行预测。

Result: 在EASY、MEDIUM和HARD数据集上分别取得了0.923、0.828和0.724的宏F1分数，有效解决了“风格浅层化”短句的问题。

Conclusion: 该模型在PAN-2025测试数据集上取得了显著的成果，在EASY、MEDIUM和HARD数据集上的宏F1分数分别为0.923、0.828和0.724，优于随机基线和claude-3.7-sonnet的零样本表现。

Abstract: Style change detection - identifying the points in a document where writing
style shifts - remains one of the most important and challenging problems in
computational authorship analysis. At PAN 2025, the shared task challenges
participants to detect style switches at the most fine-grained level:
individual sentences. The task spans three datasets, each designed with
controlled and increasing thematic variety within documents. We propose to
address this problem by modeling the content of each problem instance - that
is, a series of sentences - as a whole, using a Sequential Sentence Pair
Classifier (SSPC). The architecture leverages a pre-trained language model
(PLM) to obtain representations of individual sentences, which are then fed
into a bidirectional LSTM (BiLSTM) to contextualize them within the document.
The BiLSTM-produced vectors of adjacent sentences are concatenated and passed
to a multi-layer perceptron for prediction per adjacency. Building on the work
of previous PAN participants classical text segmentation, the approach is
relatively conservative and lightweight. Nevertheless, it proves effective in
leveraging contextual information and addressing what is arguably the most
challenging aspect of this year's shared task: the notorious problem of
"stylistically shallow", short sentences that are prevalent in the proposed
benchmark data. Evaluated on the official PAN-2025 test datasets, the model
achieves strong macro-F1 scores of 0.923, 0.828, and 0.724 on the EASY, MEDIUM,
and HARD data, respectively, outperforming not only the official random
baselines but also a much more challenging one: claude-3.7-sonnet's zero-shot
performance.

</details>


### [124] [Segment First, Retrieve Better: Realistic Legal Search via Rhetorical Role-Based Queries](https://arxiv.org/abs/2508.00679)
*Shubham Kumar Nigam,Tanmay Dubey,Noel Shallum,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: TraceRetriever improves legal precedent retrieval by using limited case information and a pipeline combining BM25, Vector DB, and Cross-Encoder models, outperforming traditional methods with partial case data.


<details>
  <summary>Details</summary>
Motivation: The growing complexity and volume of legal documents challenge traditional retrieval methods. TraceRetriever aims to mirror real-world legal search by operating with limited case information, extracting only rhetorically significant segments instead of requiring complete documents.

Method: The pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining initial results through Reciprocal Rank Fusion before final re-ranking. Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier trained on Indian judgments.

Result: Evaluated on IL-PCR and COLIEE 2025 datasets, TraceRetriever demonstrates its effectiveness in handling challenges posed by document volume and partial case knowledge.

Conclusion: TraceRetriever addresses the challenge of growing document volume in precedent retrieval, aligning with practical search constraints and providing a reliable and scalable foundation for legal research when only partial case knowledge is available.

Abstract: Legal precedent retrieval is a cornerstone of the common law system, governed
by the principle of stare decisis, which demands consistency in judicial
decisions. However, the growing complexity and volume of legal documents
challenge traditional retrieval methods. TraceRetriever mirrors real-world
legal search by operating with limited case information, extracting only
rhetorically significant segments instead of requiring complete documents. Our
pipeline integrates BM25, Vector Database, and Cross-Encoder models, combining
initial results through Reciprocal Rank Fusion before final re-ranking.
Rhetorical annotations are generated using a Hierarchical BiLSTM CRF classifier
trained on Indian judgments. Evaluated on IL-PCR and COLIEE 2025 datasets,
TraceRetriever addresses growing document volume challenges while aligning with
practical search constraints, reliable and scalable foundation for precedent
retrieval enhancing legal research when only partial case knowledge is
available.

</details>


### [125] [Better Call Claude: Can LLMs Detect Changes of Writing Style?](https://arxiv.org/abs/2508.00680)
*Johannes Römisch,Svetlana Gorovaia,Mariia Halchynska,Gleb Schmidt,Ivan P. Yamshchikov*

Main category: cs.CL

TL;DR: LLMs在句子级别的风格变化检测任务上表现出惊人的敏感性，为该领域设定了新的基准，并可能比预期更能捕捉纯粹的风格信号。


<details>
  <summary>Details</summary>
Motivation: 探索最先进的大型语言模型（LLMs）在 authorship analysis 领域中最具挑战性的任务之一：句子级别的风格变化检测上的零样本性能。

Method: 对四种最先进的大型语言模型（LLMs）在PAN 2024和2025“多作者写作风格分析”数据集上的零样本性能进行基准测试。

Result: 先进的生成模型对写作风格的变化很敏感，即使是在单个句子的粒度级别上。它们的准确性为该任务建立了一个具有挑战性的基准，优于PAN竞赛建议的基准。研究还表明，最新一代的LLMs可能比之前报告的更能对与内容无关的纯粹风格信号做出反应。

Conclusion: LLMs对句子级别的风格变化检测任务非常敏感，并且其准确性为该任务设定了具有挑战性的基准，优于PAN竞赛提出的基准。此外，研究表明LLMs可能比之前认为的更能对与内容无关的纯粹风格信号做出反应。

Abstract: This article explores the zero-shot performance of state-of-the-art large
language models (LLMs) on one of the most challenging tasks in authorship
analysis: sentence-level style change detection. Benchmarking four LLMs on the
official PAN~2024 and 2025 "Multi-Author Writing Style Analysis" datasets, we
present several observations. First, state-of-the-art generative models are
sensitive to variations in writing style - even at the granular level of
individual sentences. Second, their accuracy establishes a challenging baseline
for the task, outperforming suggested baselines of the PAN competition.
Finally, we explore the influence of semantics on model predictions and present
evidence suggesting that the latest generation of LLMs may be more sensitive to
content-independent and purely stylistic signals than previously reported.

</details>


### [126] [NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System](https://arxiv.org/abs/2508.00709)
*Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya*

Main category: cs.CL

TL;DR: 本研究提出NyayaRAG框架，通过结合案件事实、法律条文和先例判决，提升法律判决预测的准确性和解释质量，尤其在印度法律体系中。


<details>
  <summary>Details</summary>
Motivation: 之前的法律判决预测方法（LJP）主要依赖案件的内部内容，如事实、问题和推理，而忽视了普通法系中依赖法律条文和司法先例的核心要素。本研究旨在解决这一问题。

Method: 提出了一种名为NyayaRAG的检索增强生成（RAG）框架，该框架通过向模型提供事实案件描述、相关法律法规和语义检索的先例案例，来模拟真实的法庭场景。

Result: 所提出的NyayaRAG框架通过结合事实信息和法律知识，在预测法院判决和生成法律解释方面表现出色，并且在事实输入中增加结构化法律知识可以显著提高预测准确性和解释质量。

Conclusion: 通过在事实输入中增加结构化法律知识，可以显著提高预测准确性和解释质量。

Abstract: Legal Judgment Prediction (LJP) has emerged as a key area in AI for law,
aiming to automate judicial outcome forecasting and enhance interpretability in
legal reasoning. While previous approaches in the Indian context have relied on
internal case content such as facts, issues, and reasoning, they often overlook
a core element of common law systems, which is reliance on statutory provisions
and judicial precedents. In this work, we propose NyayaRAG, a
Retrieval-Augmented Generation (RAG) framework that simulates realistic
courtroom scenarios by providing models with factual case descriptions,
relevant legal statutes, and semantically retrieved prior cases. NyayaRAG
evaluates the effectiveness of these combined inputs in predicting court
decisions and generating legal explanations using a domain-specific pipeline
tailored to the Indian legal system. We assess performance across various input
configurations using both standard lexical and semantic metrics as well as
LLM-based evaluators such as G-Eval. Our results show that augmenting factual
inputs with structured legal knowledge significantly improves both predictive
accuracy and explanation quality.

</details>


### [127] [Dynamically Adaptive Reasoning via LLM-Guided MCTS for Efficient and Context-Aware KGQA](https://arxiv.org/abs/2508.00719)
*Yingxu Wang,Shiqi Fan,Mengzhu Wang,Siwei Liu*

Main category: cs.CL

TL;DR: DAMR是一种新颖的KGQA框架，通过结合MCTS和自适应路径评估，解决了现有方法的局限性，并在实验中取得了优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有KGQA方法要么受限于静态路径提取和缺乏上下文细化，要么因依赖固定评分函数和大量LLM调用而产生高计算成本和路径评估不准确的问题。

Method: DAMR框架整合了符号搜索和自适应路径评估，采用基于LLM的规划器指导的蒙特卡洛树搜索（MCTS）骨干，并引入了轻量级的Transformer评分器进行上下文感知可行性估计，同时还包含一个动态伪路径细化机制来解决监督稀疏性问题。

Result: DAMR框架能够进行高效且上下文感知的KGQA。

Conclusion: DAMR框架在多个KGQA基准测试中显著优于最先进的方法。

Abstract: Knowledge Graph Question Answering (KGQA) aims to interpret natural language
queries and perform structured reasoning over knowledge graphs by leveraging
their relational and semantic structures to retrieve accurate answers. Recent
KGQA methods primarily follow either retrieve-then-reason paradigm, relying on
GNNs or heuristic rules for static paths extraction, or dynamic path generation
strategies that use large language models (LLMs) with prompting to jointly
perform retrieval and reasoning. However, the former suffers from limited
adaptability due to static path extraction and lack of contextual refinement,
while the latter incurs high computational costs and struggles with accurate
path evaluation due to reliance on fixed scoring functions and extensive LLM
calls. To address these issues, this paper proposes Dynamically Adaptive
MCTS-based Reasoning (DAMR), a novel framework that integrates symbolic search
with adaptive path evaluation for efficient and context-aware KGQA. DAMR
employs a Monte Carlo Tree Search (MCTS) backbone guided by an LLM-based
planner, which selects top-$k$ relevant relations at each step to reduce search
space. To improve path evaluation accuracy, we introduce a lightweight
Transformer-based scorer that performs context-aware plausibility estimation by
jointly encoding the question and relation sequence through cross-attention,
enabling the model to capture fine-grained semantic shifts during multi-hop
reasoning. Furthermore, to alleviate the scarcity of high-quality supervision,
DAMR incorporates a dynamic pseudo-path refinement mechanism that periodically
generates training signals from partial paths explored during search, allowing
the scorer to continuously adapt to the evolving distribution of reasoning
trajectories. Extensive experiments on multiple KGQA benchmarks show that DAMR
significantly outperforms state-of-the-art methods.

</details>


### [128] [Out-of-Context Abduction: LLMs Make Inferences About Procedural Data Leveraging Declarative Facts in Earlier Training Data](https://arxiv.org/abs/2508.00741)
*Sohaib Imran,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

TL;DR: LLM可以根据聊天机器人的行为推断其身份，这对其情境感知和AI安全至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否能利用其训练数据中的信息进行推理，特别是“离境推断”能力，以评估其情境感知能力和AI安全。

Method: 通过训练LLM识别虚构聊天机器人的名字和行为描述，然后测试其在对话示例中推断身份的能力。

Result: GPT-4o在接受了虚构聊天机器人的名字和行为描述训练后，能够根据对话示例推断出至少一个聊天机器人的名字，并且能更好地模仿该聊天机器人的行为。

Conclusion: LLM在没有明确对话示例的情况下，可以根据行为推断出聊天机器人的身份。

Abstract: Large language models (LLMs) are trained on large corpora, yet it is unclear
whether they can reason about the information present within their training
data. We design experiments to study out-of-context abduction in LLMs, the
ability to infer the most plausible explanations for observations using
relevant facts present in training data. We train treatment LLMs on names and
behavior descriptions of fictitious chatbots, but not on examples of dialogue
with the chatbots. We find that OpenAI's GPT 4o LLM can correctly infer at
least one chatbot's name after observing example responses characteristic of
that chatbot. We also find that previously training GPT 4o on descriptions of a
chatbot's behavior allows it to display behaviors more characteristic of the
chatbot when iteratively trained to display such behaviors. Our results have
implications for situational awareness in LLMs and, therefore, for AI safety.

</details>


### [129] [Applying Psychometrics to Large Language Model Simulated Populations: Recreating the HEXACO Personality Inventory Experiment with Generative Agents](https://arxiv.org/abs/2508.00742)
*Sarah Mercer,Daniel P. Martin,Phil Swatton*

Main category: cs.CL

TL;DR: 本研究使用310个GPT-4代理进行人格测试，发现它们的人格结构与HEXACO框架部分一致，且在GPT-4模型内部表现一致，但不同模型间存在差异。这表明AI代理可用于社会科学研究，但需注意模型偏见。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型驱动的生成式AI在进行复杂的自然语言交互时能够展现出类似人类的特征，并且能够根据预定义的角色传记扮演不同的角色和个性，因此它们有潜力成为社会科学研究中替代人类参与者的经济有效方案。本研究旨在探讨这类基于人格特征的代理在代表人类群体方面的有效性。

Method: 本研究通过对310个由GPT-4驱动的代理进行HEXACO人格量表测试，并对代理的回答进行因子分析，将结果与Ashton, Lee, & Goldberg于2004年提出的原始研究进行比较，以此探索基于人格特征的代理在代表人类群体方面的有效性。

Result: 研究结果显示：1) 从代理的回答中可以恢复出一致且可靠的人格结构，并在一定程度上与HEXACO框架保持一致。2) 当结合经过充分筛选的代理群体时，从GPT-4中提取的人格维度具有一致性和可靠性。3) 跨模型分析揭示了人格画像存在差异，表明存在特定模型的偏见和局限性。

Conclusion: 本研究表明，基于GPT-4的生成式AI代理在模仿人类行为和进行人格测试方面表现出一定程度的有效性，可以作为社会科学研究的替代方案。然而，结果显示其人格结构与HEXACO框架仅部分一致，并且在不同模型之间存在差异，说明存在模型特定的偏见和局限性。研究为使用生成式AI进行社会科学研究提供了实践指导，强调了设计一致且具有代表性的人格代理的重要性。

Abstract: Generative agents powered by Large Language Models demonstrate human-like
characteristics through sophisticated natural language interactions. Their
ability to assume roles and personalities based on predefined character
biographies has positioned them as cost-effective substitutes for human
participants in social science research. This paper explores the validity of
such persona-based agents in representing human populations; we recreate the
HEXACO personality inventory experiment by surveying 310 GPT-4 powered agents,
conducting factor analysis on their responses, and comparing these results to
the original findings presented by Ashton, Lee, & Goldberg in 2004. Our results
found 1) a coherent and reliable personality structure was recoverable from the
agents' responses demonstrating partial alignment to the HEXACO framework. 2)
the derived personality dimensions were consistent and reliable within GPT-4,
when coupled with a sufficiently curated population, and 3) cross-model
analysis revealed variability in personality profiling, suggesting
model-specific biases and limitations. We discuss the practical considerations
and challenges encountered during the experiment. This study contributes to the
ongoing discourse on the potential benefits and limitations of using generative
agents in social science research and provides useful guidance on designing
consistent and representative agent personas to maximise coverage and
representation of human personality traits.

</details>


### [130] [Agentic large language models improve retrieval-based radiology question answering](https://arxiv.org/abs/2508.00743)
*Sebastian Wind,Jeta Sopa,Daniel Truhn,Mahshad Lotfinia,Tri-Thien Nguyen,Keno Bressem,Lisa Adams,Mirabela Rusu,Harald Köstler,Gerhard Wellein,Andreas Maier,Soroosh Tayebi Arasteh*

Main category: cs.CL

TL;DR: 一种新的 agentic RAG 框架通过智能问题分解和迭代信息检索，显著提高了放射学问答的准确性和可靠性，尤其对中型 AI 模型效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统的单步检索 RAG 系统在处理复杂的临床推理任务时能力有限，需要更优的框架来提高放射学问答的准确性。

Method: 提出了一种 agentic RAG 框架，使 LLM 能够自主分解放射学问题，从 Radiopaedia 迭代检索临床证据，并动态综合基于证据的回答。

Result: Agentic RAG 框架显著提高了平均诊断准确性（73% vs 64%），特别是在中等规模和小型模型中。该框架还减少了幻觉（平均 9.4%）并提高了事实依据（46% 的案例检索到相关上下文）。

Conclusion: Agentic RAG 框架通过使 LLM 自主分解问题、迭代检索证据和动态综合回答，显著提高了放射学问答的准确性和事实性，尤其是在中等规模的模型中。

Abstract: Clinical decision-making in radiology increasingly benefits from artificial
intelligence (AI), particularly through large language models (LLMs). However,
traditional retrieval-augmented generation (RAG) systems for radiology question
answering (QA) typically rely on single-step retrieval, limiting their ability
to handle complex clinical reasoning tasks. Here we propose an agentic RAG
framework enabling LLMs to autonomously decompose radiology questions,
iteratively retrieve targeted clinical evidence from Radiopaedia, and
dynamically synthesize evidence-based responses. We evaluated 24 LLMs spanning
diverse architectures, parameter scales (0.5B to >670B), and training paradigms
(general-purpose, reasoning-optimized, clinically fine-tuned), using 104
expert-curated radiology questions from previously established RSNA-RadioQA and
ExtendedQA datasets. Agentic retrieval significantly improved mean diagnostic
accuracy over zero-shot prompting (73% vs. 64%; P<0.001) and conventional
online RAG (73% vs. 68%; P<0.001). The greatest gains occurred in mid-sized
models (e.g., Mistral Large improved from 72% to 81%) and small-scale models
(e.g., Qwen 2.5-7B improved from 55% to 71%), while very large models (>200B
parameters) demonstrated minimal changes (<2% improvement). Additionally,
agentic retrieval reduced hallucinations (mean 9.4%) and retrieved clinically
relevant context in 46% of cases, substantially aiding factual grounding. Even
clinically fine-tuned models exhibited meaningful improvements (e.g.,
MedGemma-27B improved from 71% to 81%), indicating complementary roles of
retrieval and fine-tuning. These results highlight the potential of agentic
frameworks to enhance factuality and diagnostic accuracy in radiology QA,
particularly among mid-sized LLMs, warranting future studies to validate their
clinical utility.

</details>


### [131] [GLiDRE: Generalist Lightweight model for Document-level Relation Extraction](https://arxiv.org/abs/2508.00757)
*Robin Armingaud,Romaric Besançon*

Main category: cs.CL

TL;DR: GLiDRE是一个在文档级关系抽取任务上表现出色（尤其是在少样本场景下）的新模型，它借鉴了GLiNER的紧凑模型思想。


<details>
  <summary>Details</summary>
Motivation: 与GLiNER模型有相似的动机，即探索紧凑型模型在自然语言处理任务中的潜力。

Method: GLiDRE是一个用于文档级关系抽取的新模型，它借鉴了GLiNER的核心思想，并在Re-DocRED数据集上进行了基准测试。

Result: GLiDRE在Re-DocRED数据集的少样本设置中取得了最先进的性能。

Conclusion: GLiDRE在小样本场景下达到了最先进的性能，并且代码是公开的。

Abstract: Relation Extraction (RE) is a fundamental task in Natural Language
Processing, and its document-level variant poses significant challenges, due to
the need to model complex interactions between entities across sentences.
Current approaches, largely based on the ATLOP architecture, are commonly
evaluated on benchmarks like DocRED and Re-DocRED. However, their performance
in zero-shot or few-shot settings remains largely underexplored due to the
task's complexity. Recently, the GLiNER model has shown that a compact NER
model can outperform much larger Large Language Models. With a similar
motivation, we introduce GLiDRE, a new model for document-level relation
extraction that builds on the key ideas of GliNER. We benchmark GLiDRE against
state-of-the-art models across various data settings on the Re-DocRED dataset.
Our results demonstrate that GLiDRE achieves state-of-the-art performance in
few-shot scenarios. Our code is publicly available.

</details>


### [132] [MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese Hate Speech Detection under Cloaking Perturbations](https://arxiv.org/abs/2508.00760)
*Qiyao Xue,Yuchen Dou,Ryan Shi,Xiang Lorraine Li,Wei Gao*

Main category: cs.CL

TL;DR: MMBERT是一种新的多模态框架，通过整合文本、语音和视觉信息，并采用创新的训练方法，在中文仇恨言论检测方面取得了优于现有模型（包括LLM）的成果。


<details>
  <summary>Details</summary>
Motivation: 中文社交网络上的仇恨言论检测面临独特挑战，特别是由于广泛使用的旨在规避传统基于文本的检测系统的伪装技术。尽管大型语言模型（LLMs）最近提高了仇恨言论检测能力，但现有工作大多集中在英语数据集上，对中文多模态策略的关注有限。

Method: 提出了一种名为MMBERT的新型基于BERT的多模态框架，该框架通过混合专家（MoE）架构整合了文本、语音和视觉模态。为了解决将MoE直接集成到基于BERT的模型中的不稳定性问题，开发了一种渐进式三阶段训练范式。MMBERT包含特定模态的专家、共享的自注意力机制以及基于路由器的专家分配策略，以提高对对抗性干扰的鲁棒性。

Result: MMBERT在多个中文仇恨言论数据集上显著优于现有方法。

Conclusion: MMBERT模型在多个中文仇恨言论数据集上显著优于基于BERT的编码器模型、微调的LLM以及使用上下文学习方法的LLM。

Abstract: Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.

</details>


### [133] [ITUNLP at SemEval-2025 Task 8: Question-Answering over Tabular Data: A Zero-Shot Approach using LLM-Driven Code Generation](https://arxiv.org/abs/2508.00762)
*Atakan Site,Emre Hakan Erdemir,Gülşen Eryiğit*

Main category: cs.CL

TL;DR: 本文提出了一个基于LLM代码生成的零样本解决方案，用于表格数据问答任务，并在SemEval-2025 Task 8的两个子任务中取得了优异的成绩。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决SemEval-2025 Task 8：表格数据问答任务，该任务涉及在不同领域的表格数据集上进行问答，包括DataBench QA（Subtask I）和DataBench Lite QA（Subtask II）。

Method: 本文提出了一个基于LLM的代码生成框架，利用优化的提示策略生成可执行的Pandas代码，以解决表格数据问答问题。

Result: 实验表明，不同的LLM在Python代码生成方面表现出不同的有效性。此外，与替代方法相比，Python代码生成在表格问答方面取得了卓越的性能。

Conclusion: 虽然在零样本系统中的排名尚不确定，但该系统在Subtask I中排名第八，在Subtask II中排名第六，在开源模型类别中超过基线的30个系统中表现出色。

Abstract: This paper presents our system for SemEval-2025 Task 8: DataBench,
Question-Answering over Tabular Data. The primary objective of this task is to
perform question answering on given tabular datasets from diverse domains under
two subtasks: DataBench QA (Subtask I) and DataBench Lite QA (Subtask II). To
tackle both subtasks, we developed a zero-shot solution with a particular
emphasis on leveraging Large Language Model (LLM)-based code generation.
Specifically, we propose a Python code generation framework utilizing
state-of-the-art open-source LLMs to generate executable Pandas code via
optimized prompting strategies. Our experiments reveal that different LLMs
exhibit varying levels of effectiveness in Python code generation.
Additionally, results show that Python code generation achieves superior
performance in tabular question answering compared to alternative approaches.
Although our ranking among zero-shot systems is unknown at the time of this
paper's submission, our system achieved eighth place in Subtask I and sixth
place in Subtask~II among the 30 systems that outperformed the baseline in the
open-source models category.

</details>


### [134] [Do They Understand Them? An Updated Evaluation on Nonbinary Pronoun Handling in Large Language Models](https://arxiv.org/abs/2508.00788)
*Xushuo Tang,Yi Ding,Zhengyi Yang,Yin Chen,Yongrui Gu,Wenke Yang,Mingchen Ju,Xin Cao,Yongfei Liu,Wenjie Zhang*

Main category: cs.CL

TL;DR: MISGENDERED+ 基准测试显示，虽然 LLMs 在性别中立代词方面有所改进，但在新颖代词和反向推理方面仍存在不足。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在处理性别中立代词和新颖代词方面的能力，以解决负责任的人工智能问题。

Method: 通过引入扩展和更新的基准 MISGENDERED+ 来评估五个代表性 LLMs（GPT-4o、Claude 4、DeepSeek-V3、Qwen Turbo 和 Qwen2.5）在零样本、少样本和性别身份推理方面的代词保真度。

Result: 与之前的研究相比，在处理二元代词和性别中立代词方面有了显著的改进。然而，在新颖代词和反向推理任务上的准确性仍然不一致。

Conclusion: 尽管在处理二元代词和性别中立代词方面取得了显著进展，但在处理新颖代词和反向推理任务方面，大型语言模型（LLMs）在代词准确性方面仍然存在不足，这表明在处理涉及身份的推理方面仍存在挑战。

Abstract: Large language models (LLMs) are increasingly deployed in sensitive contexts
where fairness and inclusivity are critical. Pronoun usage, especially
concerning gender-neutral and neopronouns, remains a key challenge for
responsible AI. Prior work, such as the MISGENDERED benchmark, revealed
significant limitations in earlier LLMs' handling of inclusive pronouns, but
was constrained to outdated models and limited evaluations. In this study, we
introduce MISGENDERED+, an extended and updated benchmark for evaluating LLMs'
pronoun fidelity. We benchmark five representative LLMs, GPT-4o, Claude 4,
DeepSeek-V3, Qwen Turbo, and Qwen2.5, across zero-shot, few-shot, and gender
identity inference. Our results show notable improvements compared with
previous studies, especially in binary and gender-neutral pronoun accuracy.
However, accuracy on neopronouns and reverse inference tasks remains
inconsistent, underscoring persistent gaps in identity-sensitive reasoning. We
discuss implications, model-specific observations, and avenues for future
inclusive AI research.

</details>


### [135] [Beyond Fixed: Variable-Length Denoising for Diffusion Large Language Models](https://arxiv.org/abs/2508.00819)
*Jinsong Li,Xiaoyi Dong,Yuhang Zang,Yuhang Cao,Jiaqi Wang,Dahua Lin*

Main category: cs.CL

TL;DR: DAEDAL是一种新的方法，解决了DLLM中固定的生成长度问题，允许模型动态调整长度以适应任务，从而提高性能和效率。


<details>
  <summary>Details</summary>
Motivation: DLLM在实际应用中受到需要预定义生成长度的架构限制，这会导致性能与计算开销之间的权衡：长度不足会影响复杂任务的性能，而过长则会带来显著的计算开销，甚至可能导致性能下降。

Method: DAEDAL是一种新颖的、无需训练的去噪策略，它利用DLLM内部与给定任务最佳响应长度相关的潜在信号，实现了动态自适应长度扩展。该策略分两个阶段进行：1. 在去噪过程之前，从初始短长度开始，通过序列完成度量指导，迭代地将其扩展到粗略的、适合任务的长度。2. 在去噪过程中，通过识别和扩展不足的生成区域（通过插入掩码标记）来动态干预，确保最终输出充分展开。

Result: DAEDAL在DLLM上的广泛实验表明，它实现了与精心调整的固定长度基线相当甚至更优的性能，同时通过实现更高的有效标记比来提高计算效率。

Conclusion: DAEDAL通过解决静态长度限制，实现了与微调的固定长度基线相当甚至更优的性能，同时通过提高有效标记比来增强计算效率，解锁了DLLM的潜力，弥合了与自回归模型的关键差距，并为更高效、更强大的生成铺平了道路。

Abstract: Diffusion Large Language Models (DLLMs) are emerging as a powerful
alternative to the dominant Autoregressive Large Language Models, offering
efficient parallel generation and capable global context modeling. However, the
practical application of DLLMs is hindered by a critical architectural
constraint: the need for a statically predefined generation length. This static
length allocation leads to a problematic trade-off: insufficient lengths
cripple performance on complex tasks, while excessive lengths incur significant
computational overhead and sometimes result in performance degradation. While
the inference framework is rigid, we observe that the model itself possesses
internal signals that correlate with the optimal response length for a given
task. To bridge this gap, we leverage these latent signals and introduce
DAEDAL, a novel training-free denoising strategy that enables Dynamic Adaptive
Length Expansion for Diffusion Large Language Models. DAEDAL operates in two
phases: 1) Before the denoising process, DAEDAL starts from a short initial
length and iteratively expands it to a coarse task-appropriate length, guided
by a sequence completion metric. 2) During the denoising process, DAEDAL
dynamically intervenes by pinpointing and expanding insufficient generation
regions through mask token insertion, ensuring the final output is fully
developed. Extensive experiments on DLLMs demonstrate that DAEDAL achieves
performance comparable, and in some cases superior, to meticulously tuned
fixed-length baselines, while simultaneously enhancing computational efficiency
by achieving a higher effective token ratio. By resolving the static length
constraint, DAEDAL unlocks new potential for DLLMs, bridging a critical gap
with their Autoregressive counterparts and paving the way for more efficient
and capable generation.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [136] [E2ATST: A Temporal-Spatial Optimized Energy-Efficient Architecture for Training Spiking Transformer](https://arxiv.org/abs/2508.00475)
*Yunhao Ma,Yanyu Lin,Mingjing Li,Puli Quan,Chenlin Zhou,Wenyue Zhang,Zhiwei Zhong,Wanyi Jia,Xueke Zhu,Qingyan Meng,Huihui Zhou,Fengwei An*

Main category: cs.AR

TL;DR: Institutions involved: Pengcheng Laboratory, Southern University of Science and Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, University of Chinese Academy of Sciences.


<details>
  <summary>Details</summary>
Motivation: To identify the institutions involved in the research.

Method: Affiliation analysis

Result: The analysis identified the following affiliations: Pengcheng Laboratory, Southern University of Science and Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, and University of Chinese Academy of Sciences.

Conclusion: The affiliations are Pengcheng Laboratory, Southern University of Science and Technology, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, and University of Chinese Academy of Sciences.

Abstract: (1) Pengcheng Laboratory, (2) Southern University of Science and Technology,
(3) Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences,
(4) University of Chinese Academy of Sciences

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [137] [Integrated user scheduling and beam steering in over-the-air federated learning for mobile IoT](https://arxiv.org/abs/2508.00341)
*Shengheng Liu,Ningning Fu,Zhonghao Zhang,Yongming Huang,Tony Q. S. Quek*

Main category: cs.DC

TL;DR: 本文提出了一种结合㞔计算和优化的联邦学习框架，以提高效率和保护隐私。通过用户调度和波束转向技术，并开发了低复杂度算法，在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）的普及，用户隐私面临泄露风险。联邦学习（FL）作为一种分布式训练范式，为解决此挑战提供了可能，但其模型聚合效率和通信效率有待提高，特别是在大规模网络中用户选择和模型传输的优化问题。

Method: 本文提出了一种将㞔计算引入联邦学习（FL）的框架，以提高分布式本地模型的聚合效率。针对通信效率和推理准确性，设计了一种集成的用户调度和接收波束转向方法，并利用差值凸技术将非凸优化问题分解为两个子问题进行迭代求解。此外，为克服迭代法的计算瓶颈，还提出了一种低复杂度的用户调度策略。

Result: 所提出的集成方法和低复杂度用户调度策略在聚合误差和学习性能方面均优于现有方法，有效解决了联邦学习中的通信效率和隐私保护问题。

Conclusion: 本文提出了一种低复杂度的用户调度策略，通过分析无线信道特性直接确定用户子集，无需迭代。实验结果验证了该方法在聚合误差和学习性能方面优于现有方法。

Abstract: The rising popularity of Internet of things (IoT) has spurred technological
advancements in mobile internet and interconnected systems. While offering
flexible connectivity and intelligent applications across various domains, IoT
service providers must gather vast amounts of sensitive data from users, which
nonetheless concomitantly raises concerns about privacy breaches. Federated
learning (FL) has emerged as a promising decentralized training paradigm to
tackle this challenge. This work focuses on enhancing the aggregation
efficiency of distributed local models by introducing over-the-air computation
into the FL framework. Due to radio resource scarcity in large-scale networks,
only a subset of users can participate in each training round. This highlights
the need for effective user scheduling and model transmission strategies to
optimize communication efficiency and inference accuracy. To address this, we
propose an integrated approach to user scheduling and receive beam steering,
subject to constraints on the number of selected users and transmit power.
Leveraging the difference-of-convex technique, we decompose the primal
non-convex optimization problem into two sub-problems, yielding an iterative
solution. While effective, the computational load of the iterative method
hampers its practical implementation. To overcome this, we further propose a
low-complexity user scheduling policy based on characteristic analysis of the
wireless channel to directly determine the user subset without iteration.
Extensive experiments validate the superiority of the proposed method in terms
of aggregation error and learning performance over existing approaches.

</details>


### [138] [Tetris: Efficient Intra-Datacenter Calls Packing for Large Conferencing Services](https://arxiv.org/abs/2508.00426)
*Rohan Gandhi,Ankur Mallick,Ken Sueda,Rui Liang*

Main category: cs.DC

TL;DR: Tetris框架通过优化呼叫分配和迁移，显著减少了会议服务中MP服务器的过载情况，提高了性能并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 现有的会议服务（如Zoom、Teams）在跨媒体处理器（MP）服务器分配呼叫时，未能充分考虑CPU使用率的变异性（受参与者数量和媒体类型影响）以及呼叫到达的突发性，导致部分MP服务器过载（CPU利用率高），从而引起性能下降和/或托管成本升高。

Method: Tetris框架包含两个主要步骤：1. 利用历史数据优化初始呼叫分配；2. 使用线性优化周期性地迁移呼叫，以最小化热点MP的使用。

Result: 在基于真实数据（一个数据中心24小时内超过1000万次呼叫）的评估中，Tetris框架将热点MP上的参与者数量减少了至少2.5倍。

Conclusion: Tetris框架通过优化初始呼叫分配和周期性地迁移呼叫，能够显著减少热点MP的使用，从而提高会议服务的性能并降低托管成本。

Abstract: Conference services like Zoom, Microsoft Teams, and Google Meet facilitate
millions of daily calls, yet ensuring high performance at low costs remains a
significant challenge. This paper revisits the problem of packing calls across
Media Processor (MP) servers that host the calls within individual datacenters
(DCs). We show that the algorithm used in Teams -- a large scale conferencing
service as well as other state-of-art algorithms are prone to placing calls
resulting in some of the MPs becoming hot (high CPU utilization) that leads to
degraded performance and/or elevated hosting costs. The problem arises from
disregarding the variability in CPU usage among calls, influenced by
differences in participant numbers and media types (audio/video), compounded by
bursty call arrivals. To tackle this, we propose Tetris, a multi-step framework
which (a) optimizes initial call assignments by leveraging historical data and
(b) periodically migrates calls from hot MPs using linear optimization, aiming
to minimize hot MP usage. Evaluation based on a 24-hour trace of over 10
million calls in one DC shows that Tetris reduces participant numbers on hot
MPs by at least 2.5X.

</details>


### [139] [SwarnRaft: Leveraging Consensus for Robust Drone Swarm Coordination in GNSS-Degraded Environments](https://arxiv.org/abs/2508.00622)
*Kapel Dev,Yash Madhwal,Sofia Shevelo,Pavel Osinenko,Yury Yanovich*

Main category: cs.DC

TL;DR: 在 GNSS 信号丢失时，SwarnRaft 使用类似区块链的共识机制（Raft 算法）来帮助无人机群保持位置和航向的一致性，以确保协同和任务的成功。


<details>
  <summary>Details</summary>
Motivation: 无人机群在关键应用中越来越广泛，但其可靠性高度依赖 GNSS 信号，而 GNSS 信号在现实场景中易受干扰、环境因素或恶意攻击的影响，导致无人机迷失方向、碰撞风险和任务失败。

Method: 提出了一种名为 SwarnRaft 的、受区块链启发的定位和共识框架，利用 Raft 共识算法，使分布式无人机（节点）能够在 GNSS 信号丢失的情况下就位置和航向等状态更新达成一致。

Result: 所提出的 SwarnRaft 系统在模拟的无人机群中进行了原型验证，展示了在 GNSS 信号丢失的情况下，通过共识机制重建或验证故障节点位置的鲁棒性，并保持了无人机群的协同和容错能力，采用了一种轻量级、可扩展的通信模型。

Conclusion: 该研究为去中心化的无人机在不可预测环境中的运行提供了一个实用且安全的基础。

Abstract: Unmanned aerial vehicle (UAV) swarms are increasingly used in critical
applications such as aerial mapping, environmental monitoring, and autonomous
delivery. However, the reliability of these systems is highly dependent on
uninterrupted access to the Global Navigation Satellite Systems (GNSS) signals,
which can be disrupted in real-world scenarios due to interference,
environmental conditions, or adversarial attacks, causing disorientation,
collision risks, and mission failure. This paper proposes SwarnRaft, a
blockchain-inspired positioning and consensus framework for maintaining
coordination and data integrity in UAV swarms operating under GNSS-denied
conditions. SwarnRaft leverages the Raft consensus algorithm to enable
distributed drones (nodes) to agree on state updates such as location and
heading, even in the absence of GNSS signals for one or more nodes. In our
prototype, each node uses GNSS and local sensing, and communicates over WiFi in
a simulated swarm. Upon signal loss, consensus is used to reconstruct or verify
the position of the failed node based on its last known state and trajectory.
Our system demonstrates robustness in maintaining swarm coherence and fault
tolerance through a lightweight, scalable communication model. This work offers
a practical and secure foundation for decentralized drone operation in
unpredictable environments.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [140] [Building Bigraphs of the real world](https://arxiv.org/abs/2508.00003)
*Kang Rong Roy Ang*

Main category: cs.LO

TL;DR: 利用OpenStreetMap数据构建全球地理空间信息的数字孪生，并优化了相关工具的性能。


<details>
  <summary>Details</summary>
Motivation: 为了对全球的地理空间信息进行统一的、分层的组织，并实现对街道连接性的全面捕获，以构建世界的数字孪生。

Method: 该研究提出了一种利用OpenStreetMap数据构建世界bigraph（一种捕获完整街道连接性的数字孪生）的方法，该bigraph将全球建筑物、街道和行政区域组织成一个分层空间划分树。

Result: 实现了一个OCaml工具，可以为世界任何地区的bigraph提供构建，并对现有的开源bigraph构建工具进行了算法改进，实现了高达97倍的加速。

Conclusion: 该报告提出了一个形式化规范，利用来自OpenStreetMap的数据，将全球所有建筑物、街道和行政区域组织成一个分层空间划分树。该分层结构被编码为bigraph，作为世界的数字孪生，并捕获完整的街道连接性。

Abstract: This report proposes a formal specification for organising all buildings,
streets and administrative areas in the world into a hierarchical
space-partitioning tree using data from OpenStreetMap. This hierarchical
structure is encoded into a bigraph, serving as a digital twin of the world and
capturing complete street connectivity. It presents a tool implemented in OCaml
(source code at https://github.com/royangkr/bigraph-of-the-world ) that
constructs bigraphs for regions from any part of the world. In addition, it
contributes algorithmic improvements to open-source bigraph-building tools that
enable them to efficiently construct and transform extremely large bigraphs,
achieving up to a 97x speedup among other gains.

</details>


### [141] [Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation](https://arxiv.org/abs/2508.00017)
*Nikolai Sergeev*

Main category: cs.LO

TL;DR: GL 是一种新的确定性架构，可以将公理定义转化为可审计的证明图，并已成功用于自动重建基础算术定律的证明。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种自动形式化和探索数学推导的方法，并为与概率模型（如 LLM）的集成以及大规模并行实现奠定基础。

Method: GL 将定义编译为分布式逻辑块 (LB) 网格，通过消息交换进行推理，并生成具有完整溯源信息的新的事实，形成可重现、可审计的证明图。原型软件实现了对一阶皮亚诺算术的实例化，自动重建了加法和乘法的结合律、交换律以及分配律等基础算术定律的机器可检查证明，并生成了可导航的 HTML 证明图。

Result: 成功从皮亚诺公理出发，自动重建了加法和乘法的结合律、交换律以及分配律等基础算术定律的机器可检查证明，并生成了可导航的 HTML 证明图。

Conclusion: 本文提出了 Generative Logic (GL) 架构，该架构从用户提供的公理定义出发，通过系统地探索其推导邻域来生成证明。

Abstract: We present Generative Logic (GL), a deterministic architecture that begins
from user-supplied axiomatic definitions -- written in a minimalist
Mathematical Programming Language (MPL) -- and systematically explores their
deductive neighborhood. Definitions are compiled into a distributed grid of
simple Logic Blocks (LBs) that exchange messages; any time several expressions
unify under an inference rule, a new fact is emitted with full provenance to
its sources, yielding replayable, auditable proof graphs.
  A prototype software implementation instantiates the workflow on first-order
Peano arithmetic. Starting only from the Peano axioms, GL enumerates candidate
implications, applies normalization and type filters, and automatically
reconstructs machine-checkable proofs of foundational arithmetic laws including
associativity and commutativity of addition, associativity and commutativity of
multiplication, and distributivity. Generated proofs export to navigable HTML
so that every inference step can be inspected independently.
  We outline a hardware-software co-design path toward massively parallel
realizations and describe prospective integration with probabilistic models
(e.g., Large Language Models (LLMs)) for autoformalization and conjecture
seeding. The Python and MPL code to reproduce the Peano experiments, along with
the full HTML proof graphs, are available in the project's GitHub repository at
https://github.com/Generative-Logic/GL/tree/35a111ea9ba53afe051703d6050be0c3923e9724
and are permanently archived at https://doi.org/10.5281/zenodo.16408441. We
invite community feedback and collaboration.

</details>


### [142] [Reasoning under uncertainty in the game of Cops and Robbers](https://arxiv.org/abs/2508.00004)
*Dazhu Li,Sujata Ghosh,Fenrong Liu*

Main category: cs.LO

TL;DR: 本文提出了“警察与强盗认识逻辑”（ELCR）框架，用于分析信息不完备的警察与强盗博弈，实现了玩家互动和信息更新的自动化追踪，并研究了该框架的公理化和可判定性。


<details>
  <summary>Details</summary>
Motivation: 追捕-逃避环境中的计算查询，特别是警察与强盗博弈，因其与模态逻辑的类比而具有吸引力。

Method: 提出了一种新的形式化框架，即“警察与强盗认识逻辑”（ELCR），以精确化诸如玩家位置、观察能力和推理等核心概念。该框架引入了一个新的动态算子来定义信息更新机制，并从博弈和逻辑的角度将其与相关范式进行了比较。研究了ELCR的公理化和可判定性等各种性质。

Result: ELCR为追踪玩家互动和表征其在博弈中的信息更新提供了一种自动化方法。

Conclusion: 该研究首次从形式化角度探讨了考虑（部分）信息可用性的追捕-逃避游戏。

Abstract: The game of Cops and Robbers is an important model for studying computational
queries in pursuit-evasion environments, among others. As recent logical
explorations have shown, its structure exhibits appealing analogies with modal
logic. In this paper, we enrich the game with a setting in which players may
have imperfect information. We propose a new formal framework, Epistemic Logic
of Cops and Robbers (ELCR), to make the core notions of the game precise, for
instance, players' positions, observational power and inference. Applying ELCR
to analyze the game, we obtain an automated way to track interactions between
players and characterize their information updates during the game. The update
mechanism is defined by a novel dynamic operator, and we compare it with some
relevant paradigms from the game and logic perspectives. We study various
properties of ELCR including axiomatization and decidability. To our knowledge,
this is the first attempt to explore these games from a formal point of view
where (partial) information available to players is taken into account.

</details>


### [143] [Deciding the Value of Two-Clock Almost Non-Zeno Weighted Timed Games](https://arxiv.org/abs/2508.00014)
*Isa Vialard*

Main category: cs.LO

TL;DR: 本文证明了，在两时钟近似非Zeno加权时序博弈（WTGs）的情况下，价值问题是可判定的。这解决了该领域一个长期存在的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 在已解决一时钟和近期解决两时钟非负加权时序博弈（WTGs）的价值问题后，研究两时钟近似非Zeno WTGs的价值问题，填补了该领域的一个开放性问题。

Method: 通过研究两时钟近似非Zeno加权时序博弈的性质来证明其价值问题的可判定性。

Result: 证明了两时钟近似非Zeno加权时序博弈的价值问题是可判定的。

Conclusion: 本文证明了对于两时钟近似非Zeno加权时序博弈，价值问题是可判定的。

Abstract: The Value Problem for weighted timed games (wtgs) consists in determining,
given a two-player weighted timed game with a reachability objective and a
rational threshold, whether or not the value of the game exceeds the threshold.
When restrained to wtgs with non-negative weight, this problem is known to be
undecidable for weighted timed games with three or more clocks, and decidable
for one-clock wtgs. The Value Problem for two-clock non-negative wtgs, which
remained stubbornly open for a decade, was recently shown to be undecidable. In
this article, we show that the Value Problem is decidable when considering
two-clock almost non-Zeno wtgs.

</details>


### [144] [Ordinal Folding Index: A Computable Metric for Self-Referential Semantics](https://arxiv.org/abs/2508.00151)
*Faruk Alpay,Hamdi Al Alakkad*

Main category: cs.LO

TL;DR: 本文提出序数折叠指数 (OFI)，一种衡量自我指涉稳定性的新序数指标，它统一了逻辑、博弈论和理论强度，具有可计算性和多项式时间近似方案，并开启了跨领域研究的新方向。


<details>
  <summary>Details</summary>
Motivation: 本文提出了一种名为序数折叠指数 (OFI) 的新指标，旨在衡量陈述、协议或立场在趋于稳定之前所经历的自我指涉轮数。该指标旨在连接通常独立研究的领域，如不动点逻辑的闭包阶段、无限偶数游戏的获胜时间以及形式理论的序数进展。

Method: OFI 通过将“折叠回”深度转化为序数来衡量自我指涉的轮数。研究证明了 OFI 精炼了所有经典博弈论和逻辑度量，同时保持算法可枚举性，并在有限场上提供了多项式时间近似方案，并展示了该指标如何与相关评估博弈中最短获胜策略的长度精确匹配。

Result: OFI 精炼了所有经典的博弈论和逻辑度量，同时保持算法可枚举性。研究还提供了一个有限场上的多项式时间近似方案，并证明了该指标与相关评估博弈中最短获胜策略的长度精确匹配。

Conclusion: OFI 是一种新颖且完全可计算的指标，用于衡量陈述、协议或立场在趋于稳定之前必须经历多少轮自我指涉。通过将抽象的“折叠回”深度转化为单个序数，OFI 在通常孤立研究的领域之间建立了直接联系：不动点逻辑的闭包阶段、无限偶数游戏的获胜时间值以及校准形式理论强度的序数进展。

Abstract: The Ordinal Folding Index (OFI) is a new, fully computable yard-stick that
measures how many rounds of self-reference a statement, protocol or position
must unfold before its truth or outcome stabilises. By turning this abstract
'fold-back' depth into a single ordinal number, OFI forges a direct link
between areas that are usually studied in isolation: the closure stages of
fixed-point logics, the time-to-win values of infinite parity games, and the
ordinal progressions that calibrate the strength of formal theories. We prove
that OFI refines all classical game-theoretic and logical metrics while
remaining algorithmically enumerable, supply a polynomial-time approximation
scheme on finite arenas, and show how the index coincides exactly with the
length of the shortest winning strategy in the associated evaluation game.
Alongside the theory we outline five open problems from the completeness of the
computable-ordinal spectrum to the possibility of 'compressing' deep
self-reference that chart a research programme at the intersection of
computer-aided logic, algorithmic game theory and ordinal analysis. OFI thus
invites game theorists and logicians alike to view infinite play, transfinite
induction and reflective reasoning through a single, intuitive lens, opening
common ground for techniques.

</details>


### [145] [Extended Abstract: Partial-encapsulate and Its Support for Floating-point Operations in ACL2](https://arxiv.org/abs/2508.00015)
*Matt Kaufmann,J Strother Moore*

Main category: cs.LO

TL;DR: Partial-encapsulate is powerful for implementing floating-point operations in ACL2.


<details>
  <summary>Details</summary>
Motivation: To show the power of partial-encapsulate.

Method: Partial-encapsulate implementation.

Result: Demonstrated the implementation of floating-point operations in ACL2 using partial-encapsulate.

Conclusion: The power of partial-encapsulate is illustrated through its implementation of floating-point operations in ACL2.

Abstract: We illustrate the power of partial-encapsulate, showing how it is used in the
implementation of floating-point operations in ACL2.

</details>


### [146] [Alignment Monitoring](https://arxiv.org/abs/2508.00021)
*Thomas A. Henzinger,Konstantin Kueffner,Vasu Singh,I Sun*

Main category: cs.LO

TL;DR: 为了确保概率系统的形式化验证的准确性，我们提出了一种名为“对齐监控”的方法。该方法通过量化模型预测与系统实际行为的相似度来衡量模型与现实的一致性。我们开发了三种监控器（预期、差异和加权），并通过实验证明它们能够快速、高效地检测模型的不一致性。


<details>
  <summary>Details</summary>
Motivation: 为了解决概率系统形式化验证的假设——即系统模型与现实一致——可能不成立的问题，提出对齐监控来验证这一假设。

Method: 提出了一种名为“对齐监控”的方法，该方法通过量化模型预测与系统实际行为分布的相似性来衡量模型的准确性。具体来说，对齐监控器在运行时观察系统，利用当前状态和模型预测下一状态。在观察到下一个状态后，监控器会更新其判断，提供一个关于真实对齐分数的高概率区间估计。该方法借鉴了顺序预测的工具来构建监控器，并提供了三种监控器：一种用于测量预期对齐分数，一种用于比较两个模型（差异对齐监控器），以及一种允许任务特定对齐监控（加权对齐监控器）。

Result: 实验结果表明，所提出的对齐监控器速度快、内存效率高，并且能够早期检测到模型与系统实际行为之间不一致的情况。

Conclusion: 该方法通过实验在PRISM基准套件上进行了评估，结果表明该方法具有速度快、内存效率高和早期检测不对齐的优点。

Abstract: Formal verification provides assurances that a probabilistic system satisfies
its specification--conditioned on the system model being aligned with reality.
We propose alignment monitoring to watch that this assumption is justified. We
consider a probabilistic model well aligned if it accurately predicts the
behaviour of an uncertain system in advance. An alignment score measures this
by quantifying the similarity between the model's predicted and the system's
(unknown) actual distributions. An alignment monitor observes the system at
runtime; at each point in time it uses the current state and the model to
predict the next state. After the next state is observed, the monitor updates
the verdict, which is a high-probability interval estimate for the true
alignment score. We utilize tools from sequential forecasting to construct our
alignment monitors. Besides a monitor for measuring the expected alignment
score, we introduce a differential alignment monitor, designed for comparing
two models, and a weighted alignment monitor, which permits task-specific
alignment monitoring. We evaluate our monitors experimentally on the PRISM
benchmark suite. They are fast, memory-efficient, and detect misalignment
early.

</details>


### [147] [Loop Invariant Generation: A Hybrid Framework of Reasoning optimised LLMs and SMT Solvers](https://arxiv.org/abs/2508.00419)
*Varun Bharti,Shashwat Jha,Dhruv Kumar,Pankaj Jalote*

Main category: cs.LO

TL;DR: LLM与SMT求解器结合，在循环不变式合成方面表现出色，实现了100%的覆盖率。


<details>
  <summary>Details</summary>
Motivation: 研究现代推理优化的LLM在自动合成循环不变式方面的潜力，以克服现有符号和神经网络方法的局限性。

Method: 将OpenAI的O1、O1-mini和O3-mini集成到带有Z3 SMT求解器的生成-检查流水线中，并利用求解器的反例来指导不变式的迭代细化。

Result: 在包含133个任务的Code2Inv基准测试中，实现了100%的覆盖率（133/133），每次仅需1-2次模型建议和14-55秒的实际运行时间，优于之前最好的107/133。

Conclusion: 现代推理优化的LLM可以通过结合SMT求解器来更好地合成循环不变式，在Code2Inv基准测试中实现了100%的覆盖率，优于现有方法。

Abstract: Loop invariants are essential for proving the correctness of programs with
loops. Developing loop invariants is challenging, and fully automatic synthesis
cannot be guaranteed for arbitrary programs. Some approaches have been proposed
to synthesize loop invariants using symbolic techniques and more recently using
neural approaches. These approaches are able to correctly synthesize loop
invariants only for subsets of standard benchmarks. In this work, we
investigate whether modern, reasoning-optimized large language models can do
better. We integrate OpenAI's O1, O1-mini, and O3-mini into a tightly coupled
generate-and-check pipeline with the Z3 SMT solver, using solver
counterexamples to iteratively guide invariant refinement. We use Code2Inv
benchmark, which provides C programs along with their formal preconditions and
postconditions. On this benchmark of 133 tasks, our framework achieves 100%
coverage (133 out of 133), outperforming the previous best of 107 out of 133,
while requiring only 1-2 model proposals per instance and 14-55 seconds of
wall-clock time. These results demonstrate that LLMs possess latent logical
reasoning capabilities which can help automate loop invariant synthesis. While
our experiments target C-specific programs, this approach should be
generalizable to other imperative languages.

</details>


### [148] [Analysing Temporal Reasoning in Description Logics Using Formal Grammars](https://arxiv.org/abs/2508.00575)
*Camille Bourgaux,Anton Gnatenko,Michaël Thomazo*

Main category: cs.LO

TL;DR: $\	ext{TEL}^\bigcirc$与连缀文法相对应，导致其查询回答不可判定，但部分情况下的查询回答是可判定的。


<details>
  <summary>Details</summary>
Motivation: 填补关于$\	ext{TEL}^\bigcirc$查询回答可判定性的研究空白。

Method: 将$\	ext{TEL}^\bigcirc$（$\	ext{EL}$描述逻辑的带LTL算子$\igcirc^k$的时间延伸）的片段与特定类型形式文法（特别是连缀文法）建立对应关系。

Result: $\	ext{TEL}^\bigcirc$不具备模型的最终周期性，查询回答是不可判定的。部分$\	ext{TEL}^\bigcirc$的查询回答是可判定的。

Conclusion: 由于$\	ext{TEL}^\bigcirc$与特定类型的形式文法（特别是连缀文法）之间的联系，$\	ext{TEL}^\bigcirc$不具备模型的最终周期性，并且其查询回答是不可判定的。然而，这一联系也使得部分$\	ext{TEL}^\bigcirc$的查询回答可判定，并能够利用现有的连缀文法工具和算法。

Abstract: We establish a correspondence between (fragments of)
$\mathcal{TEL}^\bigcirc$, a temporal extension of the $\mathcal{EL}$
description logic with the LTL operator $\bigcirc^k$, and some specific kinds
of formal grammars, in particular, conjunctive grammars (context-free grammars
equipped with the operation of intersection). This connection implies that
$\mathcal{TEL}^\bigcirc$ does not possess the property of ultimate periodicity
of models, and further leads to undecidability of query answering in
$\mathcal{TEL}^\bigcirc$, closing a question left open since the introduction
of $\mathcal{TEL}^\bigcirc$. Moreover, it also allows to establish decidability
of query answering for some new interesting fragments of
$\mathcal{TEL}^\bigcirc$, and to reuse for this purpose existing tools and
algorithms for conjunctive grammars.

</details>


### [149] [Parameterized Infinite-State Reactive Synthesis](https://arxiv.org/abs/2508.00613)
*Benedikt Maderbacher,Roderick Bloem*

Main category: cs.LO

TL;DR: 提出一种通过反 وحد and 语法制导综合来综合参数化无限状态系统的方法，该方法可以处理参数化时序逻辑，并在实例和文献示例中得到评估。


<details>
  <summary>Details</summary>
Motivation: 提出一种方法来综合参数化的无限状态系统，以处理具有数据变量和环境属性参数的参数化时序逻辑。

Method: 通过包含四个主要步骤的循环来综合参数化的无限状态系统：1.为小的参数实例综合具体的系统。2.将具体的系统泛化为参数化程序。3.创建包含不变量和秩函数的证明候选。4.检查证明候选与程序的相容性。该方法结合了反 وحد and 语法制导综合来泛化程序和创建证明候选，以处理程序间的句法差异。

Result: 该方法能够成功综合参数化的无限状态系统，并通过反 وحد and 语法制导综合来泛化程序和创建证明候选。

Conclusion: 该方法可以综合参数化的无限状态系统，并能为不同的参数值进行实例化。它能够处理包含数据变量和环境属性编码参数变量的参数化时序逻辑。该方法在实际应用和文献示例中得到了评估。

Abstract: We propose a method to synthesize a parameterized infinite-state systems that
can be instantiated for different parameter values. The specification is given
in a parameterized temporal logic that allows for data variables as well as
parameter variables that encode properties of the environment. Our synthesis
method runs in a counterexample-guided loop consisting of four main steps:
First, we use existing techniques to synthesize concrete systems for some small
parameter instantiations. Second, we generalize the concrete systems into a
parameterized program. Third, we create a proof candidate consisting of an
invariant and a ranking function. Fourth, we check the proof candidate for
consistency with the program. If the proof succeeds, the parameterized program
is valid. Otherwise, we identify a parameter value for which the proof fails
and add a new concrete instance to step one. To generalize programs and create
proof candidates, we use a combination of anti-unification and syntax-guided
synthesis to express syntactic differences between programs as functions of the
parameters. We evaluate our approach on examples from the literature that have
been extended with parameters as well as new problems.

</details>


### [150] [Putting Perspective into OWL [sic]: Complexity-Neutral Standpoint Reasoning for Ontology Languages via Monodic S5 over Counting Two-Variable First-Order Logic (Extended Version with Appendix)](https://arxiv.org/abs/2508.00653)
*Lucía Gómez Álvarez,Sebastian Rudolph*

Main category: cs.LO

TL;DR: 本研究将单子立场引入C2逻辑，提出多项式时间翻译，保持NExpTime-complete复杂度，并对OWL 1/2等描述逻辑的扩展具有实际意义。研究还探讨了名词和单子立场对复杂度的影响。


<details>
  <summary>Details</summary>
Motivation: 为了在知识表示形式主义中整合多视角建模和推理，引入了立场的概念。单子立场扩展在提供高级建模功能（如刚性概念）的同时，保持了可接受的推理复杂度，因此具有重要的研究意义。本研究旨在将单子立场扩展到C2逻辑，并分析其推理复杂度。

Method: 本文的核心方法是提出一个多项式时间翻译，将扩展C2逻辑（包含单子立场）的公式转化为标准的、无立场的C2公式。这一翻译过程依赖于精细的模型理论论证。

Result: 在C2逻辑中引入单子立场后，其可满足性问题的复杂度仍保持为NExpTime-complete，与纯C2相同。这得益于所提出的多项式时间翻译。该结果也推进了对一阶模态逻辑的研究，因为它包含了单子S5在C2上的扩展。此外，研究还发现，在包含名词和单子立场的描述逻辑中，NExpTime-hardness是存在的，而放宽单子立场限制则会导致不可判定性。

Conclusion: 该研究成功将单子立场的概念引入了C2逻辑，并提供了一个多项式时间翻译，将扩展后的公式转化为标准的C2公式。这使得扩展后的形式化在保持与纯C2相同的NExpTime-complete可满足性问题复杂度的同时，也为更高级的描述逻辑（如OWL 1和OWL 2）的单子立场扩展提供了理论基础。研究还表明，在包含名词和单子立场的描述逻辑中，NExpTime-hardness是不可避免的，并且稍微放宽单子立场限制会导致不可判定性。

Abstract: Standpoint extensions of knowledge representation formalisms have been
recently introduced as a means to incorporate multi-perspective modelling and
reasoning through modal operators that attribute pieces of knowledge to
specific entities or agents. In these extensions, the integration between
conceptual modelling and perspective annotations can vary in strength, with
monodic standpoint extensions offering a well-balanced approach. They allow for
advanced modelling features, such as the expression of rigid concepts, while
maintaining desirable reasoning complexity.
  We consider the extension of C2--the counting two-variable fragment of
first-order logic--by monodic standpoints. At the heart of our work is a
polynomial-time translation of formulas in this extended formalism into
standard, standpoint-free C2, a result that relies on intricate model-theoretic
arguments. Thanks to this translation, the satisfiability problem remains at
the same complexity level: NExpTime-complete, as in plain C2. Since our
formalism subsumes monodic S5 over C2, this result also marks a substantial
advancement in the study of first-order modal logics.
  From a practical standpoint, this means that highly expressive description
logics such as SHOIQBs and SROIQBs--which underpin the widely adopted OWL 1 and
OWL 2 ontology languages standardised by the W3C--can be extended with monodic
standpoints without increasing the standard reasoning complexity.
  We further prove that NExpTime-hardness arises even in significantly less
expressive description logics, as long as they include both nominals and
monodic standpoints. Moreover, we show that if the monodicity restriction is
relaxed even slightly in the presence of inverse roles, functionality, and
nominals, the satisfiability problem becomes undecidable.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [151] [Computation of Approximately Stable Committees in Approval-based Elections](https://arxiv.org/abs/2508.00130)
*Drew Gao,Yihang Sun,Jan Vondrák*

Main category: cs.GT

TL;DR: Approval-based committee selection is studied with a focus on approximate stability. A $3.65$-approximately stable committee is proven to exist and be computable using Lindahl equilibria and strongly Rayleigh distributions.


<details>
  <summary>Details</summary>
Motivation: Study of approval-based committee selection, a model of significant interest in social choice theory.

Method: The approach is based on finding a Lindahl equilibrium and sampling from a strongly Rayleigh distribution associated with it.

Result: A $3.65$-approximately stable committee always exists and can be computed algorithmically.

Conclusion: A $3.65$-approximately stable committee always exists and can be computed algorithmically.

Abstract: Approval-based committee selection is a model of significant interest in
social choice theory. In this model, we have a set of voters $\mathcal{V}$, a
set of candidates $\mathcal{C}$, and each voter has a set $A_v \subset
\mathcal{C}$ of approved candidates. For any committee size $K$, the goal is to
choose $K$ candidates to represent the voters' preferences. We study a
criterion known as \emph{approximate stability}, where a committee is
$\lambda$-approximately-stable if there is no other committee $T$ preferred by
at least $\frac{\lambda|T|}{k} |\mathcal{V}| $ voters. We prove that a
$3.65$-approximately stable committee always exists and can be computed
algorithmically in this setting. Our approach is based on finding a Lindahl
equilibrium and sampling from a strongly Rayleigh distribution associated with
it.

</details>


### [152] [On the Equivalence of the Graph-Structural and Optimization-Based Characterizations of Popular Matchings](https://arxiv.org/abs/2508.00349)
*Yuga Kanaya,Kenjiro Takazawa*

Main category: cs.GT

TL;DR: 本文证明了 popular matching 的两种主要表征方法（图结构和基于优化）是等价的，并可以相互推导，为理解 popular matching 提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: Popular matching 是投票系统中 Condorcet winner 的模型。然而，直接判断一个 matching 的 popularity 需要指数时间。因此，需要更高效的表征方法。

Method: 本文研究了三种 popular matching 问题：单边有偏好、允许偏好有 ties、双边有偏好。主要贡献在于证明了图结构表征和基于优化的表征之间的直接联系，并证明了它们可以相互推导。

Result: 本文成功地将两种 popular matching 的表征方法（图结构和基于优化的方法）联系起来，并证明了它们可以相互推导，为理解 popular matching 提供了更全面的视角。

Conclusion: 本文证明了两种 popular matching 的表征方法（图结构和基于优化的方法）是等价的，并且可以相互推导。此外，研究还为图结构表征提供了一种新的解释，即与最大权重匹配问题的对偶最优解相关。

Abstract: Popular matchings provide a model of matching under preferences in which a
solution corresponds to a Condorcet winner in voting systems. In a bipartite
graph in which the vertices have preferences over their neighbours, a matching
is defined to be popular if it does not lose in a majority vote against any
matching. In this paper, we study the following three primary problems: only
the vertices on one side have preferences; a generalization of this problem
allowing ties in the preferences; and the vertices on both sides have
preferences. A principal issue in the algorithmic aspects of popular matchings
is how to determine the popularity of a matching, because it requires
exponential time if the definition is simply applied. In the literature, we
have the following two types of characterizations: a graph-structural
characterization; and an optimization-based characterization described by
maximum-weight matchings. The graph-structural characterizations are
specifically designed for each problem and provide a combinatorial structure of
the popular matchings. The optimization-based characterizations work in the
same manner for all problems, while they do not reveal the structure of the
popular matchings. A main contribution of this paper is to provide a direct
connection of the above two types of characterizations for all of the three
problems. Specifically, we prove that each characterization can be derived from
the other, without relying on the fact that they characterize popular
matchings. Our proofs offer a comprehensive understanding of the equivalence of
the two types of characterizations, and suggest a new interpretation of the
graph-structural characterization in terms of the dual optimal solution for the
maximum-weight matching problem.

</details>


### [153] [Justified Representation: From Hare to Droop](https://arxiv.org/abs/2508.00811)
*Matthew M. Casey,Edith Elkind*

Main category: cs.GT

TL;DR: 该研究扩展了多赢者投票中比例性公理的边界，通过使用德鲁普配额而非哈尔配额，并提供了相应的投票规则和理论证明，同时通过实验验证了新规则的有效性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于填补现有关于在多赢者投票（multiwinner voting）和认可投票（approval ballots）中使用德鲁普配额的理论空白，并扩展可满足比例性公理的边界。

Method: 该研究通过修改现有的投票规则和证明方法，来满足使用德鲁普配额定义的类JR公理。同时，研究还进行了实验研究，以评估这些公理在不同概率模型下的实际需求。

Result: 研究为每个标准的JR公理（JR, PJR, EJR, FPJR, FJR, PJR+ and EJR+）都确定了一个满足其德鲁普配额版本的投票规则。研究还通过实验证明，德鲁普配额的JR/EJR+公理比哈尔配额的JR/EJR+公理更难满足。

Conclusion: 该研究系统地研究了使用德鲁普配额（Droop quota）而非哈尔配额（Hare quota）定义的类JR（Justified Representation）公理，以及满足这些公理的投票规则。研究发现，使用德鲁普配额的公理更难满足，但通过修改现有规则或引入新规则，可以实现这些公理。此外，实验研究表明，在多种概率模型下，德鲁普配额的JR/EJR+公理比哈尔配额的JR/EJR+公理要求更高。

Abstract: The study of proportionality in multiwinner voting with approval ballots has
received much attention in recent years. Typically, proportionality is captured
by variants of the Justified Representation axiom, which say that cohesive
groups of at least $\ell\cdot\frac{n}{k}$ voters (where $n$ is the total number
of voters and $k$ is the desired number of winners) deserve $\ell$
representatives. The quantity $\frac{n}{k}$ is known as the Hare quota in the
social choice literature. Another -- more demanding -- choice of quota is the
Droop quota, defined as $\lfloor\frac{n}{k+1}\rfloor+1$. This quota is often
used in multiwinner voting with ranked ballots: in algorithms such as Single
Transferable Voting, and in proportionality axioms, such as Droop's
Proportionality Criterion. A few authors have considered it in the context of
approval ballots, but the existing analysis is far from comprehensive. The
contribution of our work is a systematic study of JR-style axioms (and voting
rules that satisfy them) defined using the Droop quota instead of the Hare
quota. For each of the standard JR axioms (namely, JR, PJR, EJR, FPJR, FJR,
PJR+ and EJR+), we identify a voting rule that satisfies the Droop version of
this axiom. In some cases, it suffices to consider known rules (modifying the
corresponding Hare proof, sometimes quite substantially), and in other cases it
is necessary to modify the rules from prior work. Each axiom is more difficult
to satisfy when defined using the Droop quota, so our results expand the
frontier of satisfiable proportionality axioms. We complement our theoretical
results with an experimental study, showing that for many probabilistic models
of voter approvals, Droop JR/EJR+ are considerably more demanding than standard
(Hare) JR/EJR+.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [154] [From Individuals to Crowds: Dual-Level Public Response Prediction in Social Media](https://arxiv.org/abs/2508.00497)
*Jinghui Zhang,Kaiyang Wan,Longwei Xu,Ao Li,Zongfang Liu,Xiuying Chen*

Main category: cs.SI

TL;DR: SocialAlign框架通过结合个性化的微观分析和宏观的情感趋势预测，能够更准确地预测公共反应。


<details>
  <summary>Details</summary>
Motivation: 公共反应预测对于理解个人或团体对特定事件、政策或社会现象的反应至关重要，这对于危机管理、政策制定和社会媒体分析具有很高的价值。然而，现有方法在微观层面缺乏个性化，生成的响应是通用的，忽略了个人用户偏好。此外，它们忽略了宏观层面的情感分布，只处理个体层面的情感，这限制了它们分析更广泛的社会趋势和群体情感动态的能力。

Method: SocialAlign在微观层面采用带有文章个性化分析-组合LoRA（PAC-LoRA）结构的SocialLLM，该结构部署了专门的专家模块，用于跨不同主题和用户配置文件进行内容分析和响应生成，从而能够生成具有相应情感的个性化评论。在宏观层面，它模拟群体情感分布，并将预测与从社交媒体数据中提取的现实世界情感趋势相结合。

Result: 实验结果表明，SocialAlign在准确性、可解释性和泛化能力方面优于其他基线模型。

Conclusion: SocialAlign是一个统一的框架，可以在微观和宏观层面预测社会背景下的现实世界反应。该框架在SentiWeibo和LaMP基准测试上的实验结果表明，SocialAlign在准确性、可解释性和泛化能力方面优于其他基线模型，有望在公共反应预测和计算社会科学领域激发进一步的研究。

Abstract: Public response prediction is critical for understanding how individuals or
groups might react to specific events, policies, or social phenomena, making it
highly valuable for crisis management, policy-making, and social media
analysis. However, existing works face notable limitations. First, they lack
micro-level personalization, producing generic responses that ignore individual
user preferences. Moreover, they overlook macro-level sentiment distribution
and only deal with individual-level sentiment, constraining them from analyzing
broader societal trends and group sentiment dynamics. To address these
challenges, we propose SocialAlign, a unified framework that predicts
real-world responses at both micro and macro levels in social contexts. At the
micro level, SocialAlign employs SocialLLM with an articulate Personalized
Analyze-Compose LoRA (PAC-LoRA) structure, which deploys specialized expert
modules for content analysis and response generation across diverse topics and
user profiles, enabling the generation of personalized comments with
corresponding sentiments. At the macro level, it models group sentiment
distributions and aligns predictions with real-world sentiment trends derived
from social media data. To evaluate SocialAlign in real-world scenarios, we
introduce SentiWeibo, a large-scale dataset curated from authentic social
interactions on the Weibo platform. Experimental results on our SentiWeibo and
related LaMP benchmark demonstrate that SocialAlign surpasses strong baselines,
showing improved accuracy, interpretability, and generalization in public
response prediction. We hope our work inspires further research in public
response prediction and computational social science:
https://github.com/Znull-1220/SocialAlign.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [155] [XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation](https://arxiv.org/abs/2508.00097)
*Zhigen Zhao,Liuchuan Yu,Ke Jing,Ning Yang*

Main category: cs.RO

TL;DR: XRoboToolkit是一个基于XR和OpenXR的机器人遥操作框架，解决了现有方法的局限性，提高了数据收集的效率和质量，并成功用于训练VLA模型。


<details>
  <summary>Details</summary>
Motivation: 当前机器人遥操作在数据收集方面存在可扩展性有限、设置复杂和数据质量不佳等问题，这阻碍了视觉-语言-动作（VLA）模型的快速发展，因此需要更高效、高质量的数据收集方法。

Method: 提出XRoboToolkit框架，该框架基于OpenXR标准，利用扩展现实技术进行机器人遥操作。系统包含低延迟立体视觉反馈、基于优化的逆运动学，并支持头部、控制器、手部及辅助运动追踪器等多种追踪模式。其模块化架构可轻松集成到机器人平台和模拟环境中。

Result: XRoboToolkit已被证明能有效支持机器人遥操作，并能生成高质量数据，用于训练出具有稳健自主性能的VLA模型。框架的模块化设计使其能够兼容多种机器人类型（精密操作器、移动机器人、灵巧手）和模拟环境。

Conclusion: XRoboToolkit是一个跨平台框架，使用扩展现实和OpenXR标准进行机器人遥操作，解决了当前遥操作方法的可扩展性、设置复杂性和数据质量问题。该框架支持多种追踪模式，并能与不同机器人平台和模拟环境集成。通过在精密操作任务中的应用和训练VLA模型，证明了其有效性和生成的高质量数据。未来可用于提升机器人遥操作和数据收集的效率与质量。

Abstract: The rapid advancement of Vision-Language-Action models has created an urgent
need for large-scale, high-quality robot demonstration datasets. Although
teleoperation is the predominant method for data collection, current approaches
suffer from limited scalability, complex setup procedures, and suboptimal data
quality. This paper presents XRoboToolkit, a cross-platform framework for
extended reality based robot teleoperation built on the OpenXR standard. The
system features low-latency stereoscopic visual feedback, optimization-based
inverse kinematics, and support for diverse tracking modalities including head,
controller, hand, and auxiliary motion trackers. XRoboToolkit's modular
architecture enables seamless integration across robotic platforms and
simulation environments, spanning precision manipulators, mobile robots, and
dexterous hands. We demonstrate the framework's effectiveness through precision
manipulation tasks and validate data quality by training VLA models that
exhibit robust autonomous performance.

</details>


### [156] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
*Noboru Myers,Obin Kwon,Sankalp Yamsani,Joohyung Kim*

Main category: cs.RO

TL;DR: CHILD系统实现了人形机器人的全身关节级遥操作，支持运动-操纵，并集成了力反馈，通过开源硬件设计提高了可及性。


<details>
  <summary>Details</summary>
Motivation: 现有遥操作研究很少支持人形机器人的全身关节级遥操作，限制了可完成任务的多样性。本研究旨在解决这一局限性。

Method: CHILD系统通过紧凑的可重构设计，允许操作员控制人形机器人的所有四肢，支持全身控制的直接关节映射和运动-操纵（loco-manipulation）。系统集成了自适应力反馈，以增强操作员体验并防止不安全的操作。

Result: 通过在人形机器人和多个双臂系统上进行运动-操纵和全身控制的示例，验证了CHILD系统的能力。

Conclusion: 该研究提出了一种名为CHILD（Controller for Humanoid Imitation and Live Demonstration）的紧凑型、可重构的遥操作系统，实现了对人形机器人的关节级控制，并开源了硬件设计，以提高可及性和可重复性。

Abstract: Recent advances in teleoperation have demonstrated robots performing complex
manipulation tasks. However, existing works rarely support whole-body
joint-level teleoperation for humanoid robots, limiting the diversity of tasks
that can be accomplished. This work presents Controller for Humanoid Imitation
and Live Demonstration (CHILD), a compact reconfigurable teleoperation system
that enables joint level control over humanoid robots. CHILD fits within a
standard baby carrier, allowing the operator control over all four limbs, and
supports both direct joint mapping for full-body control and loco-manipulation.
Adaptive force feedback is incorporated to enhance operator experience and
prevent unsafe joint movements. We validate the capabilities of this system by
conducting loco-manipulation and full-body control examples on a humanoid robot
and multiple dual-arm systems. Lastly, we open-source the design of the
hardware promoting accessibility and reproducibility. Additional details and
open-source information are available at our project website:
https://uiuckimlab.github.io/CHILD-pages.

</details>


### [157] [Topology-Inspired Morphological Descriptor for Soft Continuum Robots](https://arxiv.org/abs/2508.00258)
*Zhiwei Wu,Siyi Wei,Jiahao Luo,Jinhui Zhang*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper presents a topology-inspired morphological descriptor for soft
continuum robots by combining a pseudo-rigid-body (PRB) model with Morse theory
to achieve a quantitative characterization of robot morphologies. By counting
critical points of directional projections, the proposed descriptor enables a
discrete representation of multimodal configurations and facilitates
morphological classification. Furthermore, we apply the descriptor to
morphology control by formulating the target configuration as an optimization
problem to compute actuation parameters that generate equilibrium shapes with
desired topological features. The proposed framework provides a unified
methodology for quantitative morphology description, classification, and
control of soft continuum robots, with the potential to enhance their precision
and adaptability in medical applications such as minimally invasive surgery and
endovascular interventions.

</details>


### [158] [UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents](https://arxiv.org/abs/2508.00288)
*Jianqiang Xiao,Yuexuan Sun,Yixin Shao,Boxi Gan,Rongqiang Liu,Yanjing Wu,Weili Gua,Xiang Deng*

Main category: cs.RO

TL;DR: UAV-ON是一个大规模的无人机物体导航基准，用于开放世界环境，并引入了新的挑战，以推动可扩展的无人机自主性研究。


<details>
  <summary>Details</summary>
Motivation: 现有的研究大多遵循Vision-and-Language Navigation (VLN)范例，该范例严重依赖于语言指令，限制了其可扩展性和自主性。为了解决这一差距，我们引入了UAV-ON。

Method: 提出UAV-ON基准，这是一个用于开放世界环境中航空器的}(\textbf{ObjectNav})的大规模基准，其中{\textbf{航空器}}根据高级语义目标运行，而不依赖于VLN中的详细指导。UAV-ON包含14个高保真Unreal Engine环境，具有多样化的语义区域和复杂空间布局，涵盖城市、自然和混合用途环境。它定义了1270个带注释的目标对象，每个对象都具有实例级指令，该指令编码类别、物理足迹和视觉描述符，以实现基础推理。为了评估基准，我们实现了几个基线方法，包括航空目标导航代理(AOA)，这是一个将指令语义与以自我为中心的观测相结合的模块化策略，用于长视域、目标导向的探索。

Result: 实验结果表明，所有基线方法在此设置中都面临挑战，凸显了航空导航和语义目标基础的复合挑战。

Conclusion: UAV-ON旨在通过语义目标描述来推进复杂真实世界环境中可扩展的无人机自主性研究。

Abstract: Aerial navigation is a fundamental yet underexplored capability in embodied
intelligence, enabling agents to operate in large-scale, unstructured
environments where traditional navigation paradigms fall short. However, most
existing research follows the Vision-and-Language Navigation (VLN) paradigm,
which heavily depends on sequential linguistic instructions, limiting its
scalability and autonomy. To address this gap, we introduce UAV-ON, a benchmark
for large-scale Object Goal Navigation (ObjectNav) by aerial agents in
open-world environments, where agents operate based on high-level semantic
goals without relying on detailed instructional guidance as in VLN. UAV-ON
comprises 14 high-fidelity Unreal Engine environments with diverse semantic
regions and complex spatial layouts, covering urban, natural, and mixed-use
settings. It defines 1270 annotated target objects, each characterized by an
instance-level instruction that encodes category, physical footprint, and
visual descriptors, allowing grounded reasoning. These instructions serve as
semantic goals, introducing realistic ambiguity and complex reasoning
challenges for aerial agents. To evaluate the benchmark, we implement several
baseline methods, including Aerial ObjectNav Agent (AOA), a modular policy that
integrates instruction semantics with egocentric observations for long-horizon,
goal-directed exploration. Empirical results show that all baselines struggle
in this setting, highlighting the compounded challenges of aerial navigation
and semantic goal grounding. UAV-ON aims to advance research on scalable UAV
autonomy driven by semantic goal descriptions in complex real-world
environments.

</details>


### [159] [TopoDiffuser: A Diffusion-Based Multimodal Trajectory Prediction Model with Topometric Maps](https://arxiv.org/abs/2508.00303)
*Zehui Xu,Junhui Wang,Yongliang Shi,Chao Gao,Guyue Zhou*

Main category: cs.RO

TL;DR: TopoDiffuser is a new diffusion-based model for trajectory prediction that uses map information to generate accurate and road-compliant future motion forecasts, outperforming existing methods on the KITTI benchmark.


<details>
  <summary>Details</summary>
Motivation: The paper aims to generate accurate, diverse, and road-compliant future motion forecasts by incorporating topometric maps into a diffusion-based framework for multimodal trajectory prediction, enabling trajectory generation that naturally adheres to road geometry without relying on explicit constraints.

Method: TopoDiffuser utilizes a diffusion-based framework incorporating topometric maps into the denoising process of a conditional diffusion model. A multimodal conditioning encoder fuses LiDAR observations, historical motion, and route information into a unified bird's-eye-view (BEV) representation.

Result: The proposed approach enables trajectory generation that naturally adheres to road geometry without relying on explicit constraints. Extensive experiments on the KITTI benchmark demonstrate that TopoDiffuser outperforms state-of-the-art methods, while maintaining strong geometric consistency. Ablation studies validate the contribution of each input modality, denoising steps, and the number of trajectory samples.

Conclusion: TopoDiffuser outperforms state-of-the-art methods in trajectory prediction, maintaining strong geometric consistency and demonstrating the contribution of each input modality.

Abstract: This paper introduces TopoDiffuser, a diffusion-based framework for
multimodal trajectory prediction that incorporates topometric maps to generate
accurate, diverse, and road-compliant future motion forecasts. By embedding
structural cues from topometric maps into the denoising process of a
conditional diffusion model, the proposed approach enables trajectory
generation that naturally adheres to road geometry without relying on explicit
constraints. A multimodal conditioning encoder fuses LiDAR observations,
historical motion, and route information into a unified bird's-eye-view (BEV)
representation. Extensive experiments on the KITTI benchmark demonstrate that
TopoDiffuser outperforms state-of-the-art methods, while maintaining strong
geometric consistency. Ablation studies further validate the contribution of
each input modality, as well as the impact of denoising steps and the number of
trajectory samples. To support future research, we publicly release our code at
https://github.com/EI-Nav/TopoDiffuser.

</details>


### [160] [Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging](https://arxiv.org/abs/2508.00354)
*Tianshuang Qiu,Zehan Ma,Karim El-Refai,Hiya Shah,Chung Min Kim,Justin Kerr,Ken Goldberg*

Main category: cs.RO

TL;DR: Omni-Scan uses a two-handed robot and AI models to create full 360-degree 3D models of objects, which are accurate enough (83%) for inspecting defects in parts.


<details>
  <summary>Details</summary>
Motivation: Traditional 3D object scanning methods often rely on multi-camera arrays or laser scanners with restricted workspaces. This work introduces Omni-Scan to overcome these limitations by enabling the creation of high-quality 3D Gaussian Splat models using a more flexible bi-manual robot setup, suitable for a wider range of applications including detailed inspections.

Method: The Omni-Scan pipeline utilizes a bi-manual robot system where one gripper holds an object while a stationary camera captures its data. A second gripper then re-grasps the object to expose previously occluded surfaces. The process leverages DepthAnything, Segment Anything, and RAFT optical flow models to isolate objects, remove grippers and backgrounds, and modifies the 3DGS training pipeline to handle concatenated datasets with gripper occlusions, ultimately producing omnidirectional 3DGS models.

Result: The Omni-Scan pipeline successfully generates omnidirectional 3D Gaussian Splat models. When applied to part defect inspection on 12 different industrial and household objects, it achieved an average accuracy of 83% in identifying visual or geometric defects.

Conclusion: Omni-Scan pipeline combined with 3D Gaussian Splats (3DGS) achieves high-quality, omnidirectional 3D models using a bi-manual robot, enabling applications like part defect inspection with an average accuracy of 83% across various objects.

Abstract: 3D Gaussian Splats (3DGSs) are 3D object models derived from multi-view
images. Such "digital twins" are useful for simulations, virtual reality,
marketing, robot policy fine-tuning, and part inspection. 3D object scanning
usually requires multi-camera arrays, precise laser scanners, or robot
wrist-mounted cameras, which have restricted workspaces. We propose Omni-Scan,
a pipeline for producing high-quality 3D Gaussian Splat models using a
bi-manual robot that grasps an object with one gripper and rotates the object
with respect to a stationary camera. The object is then re-grasped by a second
gripper to expose surfaces that were occluded by the first gripper. We present
the Omni-Scan robot pipeline using DepthAny-thing, Segment Anything, as well as
RAFT optical flow models to identify and isolate objects held by a robot
gripper while removing the gripper and the background. We then modify the 3DGS
training pipeline to support concatenated datasets with gripper occlusion,
producing an omni-directional (360 degree view) model of the object. We apply
Omni-Scan to part defect inspection, finding that it can identify visual or
geometric defects in 12 different industrial and household objects with an
average accuracy of 83%. Interactive videos of Omni-Scan 3DGS models can be
found at https://berkeleyautomation.github.io/omni-scan/

</details>


### [161] [TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots](https://arxiv.org/abs/2508.00355)
*Zhenghan Chen,Haocheng Xu,Haodong Zhang,Liang Zhang,He Li,Dongqi Wang,Jiyu Yu,Yifei Yang,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: 通过时间优化策略（TOP）协调机器人上下半身运动，并解耦控制器，以实现精确、稳定且高效的站立操控。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以精确控制高维度的上半身关节，或在快速运动时难以同时保证鲁棒性和精确性。本研究旨在训练一个能够同时保证平衡、精确和时间效率的站立操控模型。

Method: 1.利用运动先验（motion prior）训练变分自编码器（VAE）以增强上下半身协调能力。 2.将全身控制分解为上半身的PD控制器（用于精确性）和下半身的强化学习（RL）控制器（用于鲁棒稳定性）。 3.训练TOP方法结合解耦控制器和VAE，以减轻快速上半身运动带来的平衡负担。

Result: 仿真和真实世界实验证明，该方法在站立操控任务中能够稳定且精确地执行任务，优于现有方法。

Conclusion: 该研究提出的时间优化策略（TOP）及其解耦控制器和VAE，能够有效提升人形机器人在站立操控任务中的平衡性、精确性和时间效率，特别是在处理快速上半身运动时表现优越。

Abstract: Humanoid robots have the potential capability to perform a diverse range of
manipulation tasks, but this is based on a robust and precise standing
controller. Existing methods are either ill-suited to precisely control
high-dimensional upper-body joints, or difficult to ensure both robustness and
accuracy, especially when upper-body motions are fast. This paper proposes a
novel time optimization policy (TOP), to train a standing manipulation control
model that ensures balance, precision, and time efficiency simultaneously, with
the idea of adjusting the time trajectory of upper-body motions but not only
strengthening the disturbance resistance of the lower-body. Our approach
consists of three parts. Firstly, we utilize motion prior to represent
upper-body motions to enhance the coordination ability between the upper and
lower-body by training a variational autoencoder (VAE). Then we decouple the
whole-body control into an upper-body PD controller for precision and a
lower-body RL controller to enhance robust stability. Finally, we train TOP
method in conjunction with the decoupled controller and VAE to reduce the
balance burden resulting from fast upper-body motions that would destabilize
the robot and exceed the capabilities of the lower-body RL policy. The
effectiveness of the proposed approach is evaluated via both simulation and
real world experiments, which demonstrate the superiority on standing
manipulation tasks stably and accurately. The project page can be found at
https://anonymous.4open.science/w/top-258F/.

</details>


### [162] [A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot](https://arxiv.org/abs/2508.00362)
*Zhenghan Chen,Haodong Zhang,Dongqi Wang,Jiyu Yu,Haocheng Xu,Yue Wang,Rong Xiong*

Main category: cs.RO

TL;DR: 该研究提出了一种用于人形机器人运动模仿的框架，通过接触感知运动重定向和非线性重心模型预测控制器，实现了在保持平衡的同时精确模仿人类运动。


<details>
  <summary>Details</summary>
Motivation: 为了让人形机器人的表现更像人类，需要通过运动模仿来实现更广泛、更复杂、更具表现力的运动。然而，由于人形机器人与人类在运动学和动力学上的显著差异，在保持平衡的同时精确模仿运动是一个重大挑战。

Method: 提出了一种新颖的全身体运动模仿框架，该框架采用接触感知全身体运动重定向来模仿人类运动并为参考轨迹提供初始值，并使用非线性重心模型预测控制器来确保运动的准确性，同时保持平衡并实时克服外部干扰。

Result: 在真实世界的人形机器人和仿真环境中，通过模仿各种人类运动的实验证明了该方法在精确性和适应性方面的能力。

Conclusion: 实验证明了该方法在精确性和适应性方面的能力，验证了该方法的有效性。

Abstract: Motion imitation is a pivotal and effective approach for humanoid robots to
achieve a more diverse range of complex and expressive movements, making their
performances more human-like. However, the significant differences in
kinematics and dynamics between humanoid robots and humans present a major
challenge in accurately imitating motion while maintaining balance. In this
paper, we propose a novel whole-body motion imitation framework for a full-size
humanoid robot. The proposed method employs contact-aware whole-body motion
retargeting to mimic human motion and provide initial values for reference
trajectories, and the non-linear centroidal model predictive controller ensures
the motion accuracy while maintaining balance and overcoming external
disturbances in real time. The assistance of the whole-body controller allows
for more precise torque control. Experiments have been conducted to imitate a
variety of human motions both in simulation and in a real-world humanoid robot.
These experiments demonstrate the capability of performing with accuracy and
adaptability, which validates the effectiveness of our approach.

</details>


### [163] [On Learning Closed-Loop Probabilistic Multi-Agent Simulator](https://arxiv.org/abs/2508.00384)
*Juanwu Lu,Rohit Gupta,Ahmadreza Moradipari,Kyungtae Han,Ruqi Zhang,Ziran Wang*

Main category: cs.RO

TL;DR: NIVA是一种新的多智能体交通模拟框架，用于自动驾驶汽车评估，它通过概率模型实现闭环仿真，并能控制意图和驾驶风格。


<details>
  <summary>Details</summary>
Motivation: 为了应对自动驾驶汽车（AV）部署快速迭代的需求，需要构建现实且可扩展的多智能体交通模拟器进行有效评估。

Method: 提出了一种基于分层贝叶斯模型的概率框架NIVA，通过自回归采样实现闭环、条件化仿真。

Result: NIVA统一了现有的序列到序列轨迹预测模型和新兴的基于贝叶斯推理的闭环仿真模型。

Conclusion: NIVA框架在Waymo开放运动数据集上实现了与现有方法相当的性能，同时提供了对意图和驾驶风格的细致控制。

Abstract: The rapid iteration of autonomous vehicle (AV) deployments leads to
increasing needs for building realistic and scalable multi-agent traffic
simulators for efficient evaluation. Recent advances in this area focus on
closed-loop simulators that enable generating diverse and interactive
scenarios. This paper introduces Neural Interactive Agents (NIVA), a
probabilistic framework for multi-agent simulation driven by a hierarchical
Bayesian model that enables closed-loop, observation-conditioned simulation
through autoregressive sampling from a latent, finite mixture of Gaussian
distributions. We demonstrate how NIVA unifies preexisting sequence-to-sequence
trajectory prediction models and emerging closed-loop simulation models trained
on Next-token Prediction (NTP) from a Bayesian inference perspective.
Experiments on the Waymo Open Motion Dataset demonstrate that NIVA attains
competitive performance compared to the existing method while providing
embellishing control over intentions and driving styles.

</details>


### [164] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
*Samratul Fuady,Danesh Tarapore,Mohammad D. Soorati*

Main category: cs.RO

TL;DR: 我们提出了一种名为子集式集体决策（SubCDM）的新方法，该方法允许机器人群体仅使用一部分机器人就能做出集体决策，从而节省了资源。


<details>
  <summary>Details</summary>
Motivation: 现有的策略要求所有机器人参与决策过程，这会消耗大量资源，并阻止群体将机器人分配给任何其他任务。

Method: 提出了一种名为子集式集体决策（SubCDM）的方法，该方法仅使用群体子集即可进行决策。子集的构建是动态和分散的，仅依赖于局部信息。

Result: 模拟结果表明，我们的方法实现了与使用整个群体相当的准确性，同时减少了执行集体决策所需的机器人数量。

Conclusion: SubCDM方法在实现与使用整个群体相当的准确性的同时，减少了执行集体决策所需的机器人数量，使其成为群体机器人中集体决策的一种资源高效的解决方案。

Abstract: Collective decision-making is a key function of autonomous robot swarms,
enabling them to reach a consensus on actions based on environmental features.
Existing strategies require the participation of all robots in the
decision-making process, which is resource-intensive and prevents the swarm
from allocating the robots to any other tasks. We propose Subset-Based
Collective Decision-Making (SubCDM), which enables decisions using only a swarm
subset. The construction of the subset is dynamic and decentralized, relying
solely on local information. Our method allows the swarm to adaptively
determine the size of the subset for accurate decision-making, depending on the
difficulty of reaching a consensus. Simulation results using one hundred robots
show that our approach achieves accuracy comparable to using the entire swarm
while reducing the number of robots required to perform collective
decision-making, making it a resource-efficient solution for collective
decision-making in swarm robotics.

</details>


### [165] [HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning](https://arxiv.org/abs/2508.00491)
*Carlo Alessi,Federico Vasile,Federico Ceola,Giulia Pasquale,Nicolò Boccardo,Lorenzo Natale*

Main category: cs.RO

TL;DR: 通过模仿学习方法（HannesImitationPolicy）和数据集（HannesImitationDataset）的结合，成功提升了假肢手在非结构化环境下的抓取能力，并且优于现有的视觉伺服控制方法。


<details>
  <summary>Details</summary>
Motivation: 为了增强假肢灵活性恢复能力，并使假肢能在非结构化场景下进行任务操作，弥合了模仿学习在假肢手控制领域的应用空白。

Method: 提出了一种名为HannesImitationPolicy的模仿学习方法，并构建了包含抓取演示的HannesImitationDataset数据集，利用该数据集训练了单一的扩散策略来预测抓取所需的腕部方向和手部闭合。

Result: HannesImitationPolicy成功实现了在非结构化环境下的物体抓取，并在多样化的物体和条件下进行了实验评估，证明了其有效性。

Conclusion: 该研究成功展示了HannesImitationPolicy在非结构化环境中进行物体抓取的能力，并且在抓取成功率方面优于基于分割的视觉伺服控制器。

Abstract: Recent advancements in control of prosthetic hands have focused on increasing
autonomy through the use of cameras and other sensory inputs. These systems aim
to reduce the cognitive load on the user by automatically controlling certain
degrees of freedom. In robotics, imitation learning has emerged as a promising
approach for learning grasping and complex manipulation tasks while simplifying
data collection. Its application to the control of prosthetic hands remains,
however, largely unexplored. Bridging this gap could enhance dexterity
restoration and enable prosthetic devices to operate in more unconstrained
scenarios, where tasks are learned from demonstrations rather than relying on
manually annotated sequences. To this end, we present HannesImitationPolicy, an
imitation learning-based method to control the Hannes prosthetic hand, enabling
object grasping in unstructured environments. Moreover, we introduce the
HannesImitationDataset comprising grasping demonstrations in table, shelf, and
human-to-prosthesis handover scenarios. We leverage such data to train a single
diffusion policy and deploy it on the prosthetic hand to predict the wrist
orientation and hand closure for grasping. Experimental evaluation demonstrates
successful grasps across diverse objects and conditions. Finally, we show that
the policy outperforms a segmentation-based visual servo controller in
unstructured scenarios. Additional material is provided on our project page:
https://hsp-iit.github.io/HannesImitation

</details>


### [166] [OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery](https://arxiv.org/abs/2508.00580)
*Raul Castilla-Arquillo,Carlos Perez-del-Pulgar,Levin Gerdes,Alfonso Garcia-Cerezo,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: 本研究提出了一种名为OmniUnet的AI模型，用于处理RGB、深度和热成像数据，以帮助机器人（如火星探测器）在类似火星的地形中更安全地导航。该模型在模拟火星环境中进行了测试，分割地形的准确率达到80.37%，并且运行速度足够快，可以直接在机器人上使用。研究人员还公开发布了模型和数据集，以供其他研究人员使用。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在非结构化环境中安全导航，这需要能够整合来自不同传感器（如RGB、深度和热成像）的互补信息的感知系统。然而，处理这些异构数据需要专门的机器学习算法。此外，识别哪些传感器模态对特定环境下的导航最有用也至关重要。特别是对于火星探索，热成像因其评估地形安全性的价值而被证明是有用的。

Method: 本研究提出了一种名为OmniUnet的Transformer神经网络架构，用于处理RGB、深度和热成像（RGB-D-T）数据，以实现语义分割。研究团队使用3D打印技术开发了一个定制的多模态传感器外壳，并将其安装在火星漫游车测试平台（MaRTA）上，在西班牙北部的Bardenas半干旱区收集了多模态数据集。该数据集包含了沙地、基岩和密实土壤等代表火星表面的地形类型。研究人员手动标注了部分数据集用于监督训练，并通过定量和定性评估了模型的性能。

Result: OmniUnet在Bardenas半干旱区收集的多模态数据集上进行了评估，在分割非结构化地形方面取得了80.37%的像素准确率。该模型在资源受限的Jetson Orin Nano上进行了推理测试，平均预测时间为673毫秒，证明了其适用于机器人部署。研究结果表明，OmniUnet能够有效处理多模态数据，并在复杂地形分割任务中表现出色。

Conclusion: 该研究提出了OmniUnet，一种基于Transformer的语义分割神经网络架构，能够处理RGB、深度和热成像（RGB-D-T）数据，并在非结构化地形的分割任务中取得了80.37%的像素准确率。该模型在资源受限的Jetson Orin Nano上实现了平均673毫秒的推理时间，证明了其在机器人部署上的可行性。此外，研究还公开了网络软件实现和标注数据集，以促进未来行星机器人多模态地形感知研究。

Abstract: Robot navigation in unstructured environments requires multimodal perception
systems that can support safe navigation. Multimodality enables the integration
of complementary information collected by different sensors. However, this
information must be processed by machine learning algorithms specifically
designed to leverage heterogeneous data. Furthermore, it is necessary to
identify which sensor modalities are most informative for navigation in the
target environment. In Martian exploration, thermal imagery has proven valuable
for assessing terrain safety due to differences in thermal behaviour between
soil types. This work presents OmniUnet, a transformer-based neural network
architecture for semantic segmentation using RGB, depth, and thermal (RGB-D-T)
imagery. A custom multimodal sensor housing was developed using 3D printing and
mounted on the Martian Rover Testbed for Autonomy (MaRTA) to collect a
multimodal dataset in the Bardenas semi-desert in northern Spain. This location
serves as a representative environment of the Martian surface, featuring
terrain types such as sand, bedrock, and compact soil. A subset of this dataset
was manually labeled to support supervised training of the network. The model
was evaluated both quantitatively and qualitatively, achieving a pixel accuracy
of 80.37% and demonstrating strong performance in segmenting complex
unstructured terrain. Inference tests yielded an average prediction time of 673
ms on a resource-constrained computer (Jetson Orin Nano), confirming its
suitability for on-robot deployment. The software implementation of the network
and the labeled dataset have been made publicly available to support future
research in multimodal terrain perception for planetary robotics.

</details>


### [167] [A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup](https://arxiv.org/abs/2508.00584)
*Konstantinos Plotas,Emmanouil Papadakis,Drosakis Drosakis,Panos Trahanias,Dimitrios Papageorgiou*

Main category: cs.RO

TL;DR: A new control scheme for robots working with humans to move objects uses a suction cup and special controls to make it easier and safer for the human, as shown in robot tests.


<details>
  <summary>Details</summary>
Motivation: To develop a control scheme for human-robot collaborative object transportation that enhances human controllability and reduces human effort, while ensuring the object remains securely held by the suction cup.

Method: Admittance control with a variable damping term and a barrier artificial potential for controlling a quadruped robot with a suction cup during human-robot collaborative object transportation.

Result: Experimental evaluations demonstrated the performance and passivity of the proposed control scheme.

Conclusion: The proposed control scheme, based on admittance control with variable damping and a barrier artificial potential, is proven to be passive and effective in experimental evaluations using the Unitree Go1 robot with a MIGHTY suction cup for human-robot collaborative object transportation.

Abstract: In this work, a control scheme for human-robot collaborative object
transportation is proposed, considering a quadruped robot equipped with the
MIGHTY suction cup that serves both as a gripper for holding the object and a
force/torque sensor. The proposed control scheme is based on the notion of
admittance control, and incorporates a variable damping term aiming towards
increasing the controllability of the human and, at the same time, decreasing
her/his effort. Furthermore, to ensure that the object is not detached from the
suction cup during the collaboration, an additional control signal is proposed,
which is based on a barrier artificial potential. The proposed control scheme
is proven to be passive and its performance is demonstrated through
experimental evaluations conducted using the Unitree Go1 robot equipped with
the MIGHTY suction cup.

</details>


### [168] [OpenScout v1.1 mobile robot: a case study on open hardware continuation](https://arxiv.org/abs/2508.00625)
*Bartosz Krawczyk,Ahmed Elbary,Robbie Cato,Jagdish Patil,Kaung Myat,Anyeh Ndi-Tah,Nivetha Sakthivel,Mark Crampton,Gautham Das,Charles Fox*

Main category: cs.RO

TL;DR: OpenScout v1.1是一个改进的开源移动机器人，具有更强的计算能力、ROS2接口和Gazebo仿真，为研究和工业提供了更好的平台。


<details>
  <summary>Details</summary>
Motivation: 发布OpenScout v1.1，旨在提供一个更强大、更便宜、更易于使用的开源移动机器人平台。

Method: 开源硬件案例研究

Result: OpenScout v1.1的发布，包括更强大的计算硬件、ROS2接口和Gazebo仿真，证明了其在研究和工业领域的潜力。

Conclusion: OpenScout v1.1的发布，包括更强大的计算硬件、ROS2接口和Gazebo仿真，是一个成功的开源硬件案例研究。

Abstract: OpenScout is an Open Source Hardware (OSH) mobile robot for research and
industry. It is extended to v1.1 which includes simplified, cheaper and more
powerful onboard compute hardware; a simulated ROS2 interface; and a Gazebo
simulation. Changes, their rationale, project methodology, and results are
reported as an OSH case study.

</details>


### [169] [Towards Data-Driven Adaptive Exoskeleton Assistance for Post-stroke Gait](https://arxiv.org/abs/2508.00691)
*Fabian C. Weigend,Dabin K. Choe,Santiago Canete,Conor J. Walsh*

Main category: cs.RO

TL;DR: 研究人员开发了一种基于深度学习（TCN）的方法，利用IMU数据从多任务学习中估计中风后患者的踝关节力矩，并成功演示了其在外骨骼控制中的实时应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管数据驱动的方法在为健康成人控制外骨骼方面显示出潜力，但由于人群异质性高、步态变异性大以及缺乏中风后步态数据集，将其应用于神经运动步态缺陷人群（如中风后偏瘫）具有挑战性。

Method: 本研究训练了一个多任务时间卷积网络（TCN），使用来自四名中风后参与者在跑步机上行走的数据，并使用来自六名健康参与者的数据对模型进行了预训练。

Result: 在对中风后参与者步态的踝关节力矩估计方面，TCN模型达到了0.74±0.13的R^2值。研究还成功实现了一个用于外骨骼控制的踝关节力矩估计方法的穿戴式原型，并与一名中风后参与者一起演示了实时传感、估计和驱动的可行性。

Conclusion: 该研究展示了端到端深度学习模型在从IMU数据估计行走时的踝关节力矩方面的潜力，为开发能够适应中风后步态的自适应假肢提供了初步证据。

Abstract: Recent work has shown that exoskeletons controlled through data-driven
methods can dynamically adapt assistance to various tasks for healthy young
adults. However, applying these methods to populations with neuromotor gait
deficits, such as post-stroke hemiparesis, is challenging. This is due not only
to high population heterogeneity and gait variability but also to a lack of
post-stroke gait datasets to train accurate models. Despite these challenges,
data-driven methods offer a promising avenue for control, potentially allowing
exoskeletons to function safely and effectively in unstructured community
settings. This work presents a first step towards enabling adaptive
plantarflexion and dorsiflexion assistance from data-driven torque estimation
during post-stroke walking. We trained a multi-task Temporal Convolutional
Network (TCN) using collected data from four post-stroke participants walking
on a treadmill ($R^2$ of $0.74 \pm 0.13$). The model uses data from three
inertial measurement units (IMU) and was pretrained on healthy walking data
from 6 participants. We implemented a wearable prototype for our ankle torque
estimation approach for exoskeleton control and demonstrated the viability of
real-time sensing, estimation, and actuation with one post-stroke participant.

</details>


### [170] [On-Device Diffusion Transformer Policy for Efficient Robot Manipulation](https://arxiv.org/abs/2508.00697)
*Yiming Wu,Huan Wang,Zhenghao Chen,Jianxin Pang,Dong Xu*

Main category: cs.RO

TL;DR: 提出LightDP框架，通过网络压缩和减少采样步骤，使扩散策略能够在计算能力有限的移动设备上高效运行，并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散策略在资源受限的移动平台上部署时面临的计算效率低下和内存占用大的问题。

Method: 通过网络压缩（包括统一的剪枝和再训练流程）和减少采样步骤（结合剪枝技术和一致性蒸馏）来加速扩散策略。

Result: LightDP在PushT、Robomimic、CALVIN和LIBERO等标准数据集上实现了实时动作预测，并且在实际操作中表现与最先进的扩散策略相当。

Conclusion: LightDP框架在资源受限的移动设备上实现了实时动作预测，并且性能与最先进的扩散策略相当，是在资源有限的环境中实际部署基于扩散的策略的重要一步。

Abstract: Diffusion Policies have significantly advanced robotic manipulation tasks via
imitation learning, but their application on resource-constrained mobile
platforms remains challenging due to computational inefficiency and extensive
memory footprint. In this paper, we propose LightDP, a novel framework
specifically designed to accelerate Diffusion Policies for real-time deployment
on mobile devices. LightDP addresses the computational bottleneck through two
core strategies: network compression of the denoising modules and reduction of
the required sampling steps. We first conduct an extensive computational
analysis on existing Diffusion Policy architectures, identifying the denoising
network as the primary contributor to latency. To overcome performance
degradation typically associated with conventional pruning methods, we
introduce a unified pruning and retraining pipeline, optimizing the model's
post-pruning recoverability explicitly. Furthermore, we combine pruning
techniques with consistency distillation to effectively reduce sampling steps
while maintaining action prediction accuracy. Experimental evaluations on the
standard datasets, \ie, PushT, Robomimic, CALVIN, and LIBERO, demonstrate that
LightDP achieves real-time action prediction on mobile devices with competitive
performance, marking an important step toward practical deployment of
diffusion-based policies in resource-limited environments. Extensive real-world
experiments also show the proposed LightDP can achieve performance comparable
to state-of-the-art Diffusion Policies.

</details>


### [171] [Video Generators are Robot Policies](https://arxiv.org/abs/2508.00795)
*Junbang Liang,Pavel Tokmakov,Ruoshi Liu,Sruthi Sudhakar,Paarth Shah,Rares Ambrus,Carl Vondrick*

Main category: cs.RO

TL;DR: Video Policy框架通过学习生成机器人行为视频，克服了现有视觉运动策略在泛化能力和数据依赖性方面的限制，实现了更高效、更具鲁棒性的机器人策略学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有抓取操作的视觉运动策略在感知或行为分布变化下泛化能力差以及性能受人类演示数据量限制的两个挑战。

Method: 提出了一种名为Video Policy的模块化框架，该框架结合了视频和动作生成，能够进行端到端训练。

Result: 学习生成机器人行为视频使得能够提取出具有最小演示数据的策略，鲁棒性和样本效率得到显著提高。该方法在模拟和现实世界中都表现出对未见过的物体、背景和任务的强大泛化能力。任务成功与生成的视频紧密相关，并且无动作视频数据对于泛化到新任务具有关键优势。与传统的行为克隆方法相比，该方法利用大规模视频生成模型取得了优越的性能。

Conclusion: 该方法通过学习生成机器人行为视频，能够以极少量的人类演示数据提取策略，显著提高鲁棒性和样本效率，并在模拟和现实世界中展现出对未见过的物体、背景和任务的强大泛化能力。

Abstract: Despite tremendous progress in dexterous manipulation, current visuomotor
policies remain fundamentally limited by two challenges: they struggle to
generalize under perceptual or behavioral distribution shifts, and their
performance is constrained by the size of human demonstration data. In this
paper, we use video generation as a proxy for robot policy learning to address
both limitations simultaneously. We propose Video Policy, a modular framework
that combines video and action generation that can be trained end-to-end. Our
results demonstrate that learning to generate videos of robot behavior allows
for the extraction of policies with minimal demonstration data, significantly
improving robustness and sample efficiency. Our method shows strong
generalization to unseen objects, backgrounds, and tasks, both in simulation
and the real world. We further highlight that task success is closely tied to
the generated video, with action-free video data providing critical benefits
for generalizing to novel tasks. By leveraging large-scale video generative
models, we achieve superior performance compared to traditional behavior
cloning, paving the way for more scalable and data-efficient robot policy
learning.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [172] [Learning Like Humans: Resource-Efficient Federated Fine-Tuning through Cognitive Developmental Stages](https://arxiv.org/abs/2508.00041)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.LG

TL;DR: DevFT 是一种受认知发展启发的资源高效的联邦微调方法，它通过分阶段优化具有不同参数容量的子模型来构建 LLM，从而实现更快的收敛速度、更低的通信开销和更高的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦微调资源密集且限制在边缘设备部署的问题，本文提出了一种名为 DevFT 的资源高效方法，该方法受到认知发展的启发，并逐步从一个紧凑的基础构建一个强大的 LLM。

Method: DevFT 将微调过程分解为不同的发展阶段，每个阶段都有不同的参数容量，并使用去冲突引导的层分组和基于差分的层融合来构建阶段特定的子模型。

Result: DevFT 实现了比最先进方法快 4.59 倍的收敛速度，通信开销减少了 10.67 倍，性能平均提高了 9.07%。

Conclusion: DevFT 在多个基准测试中显著优于最先进的方法，在保持与现有方法兼容性的同时，实现了高达 4.59 倍的收敛速度，通信开销减少了 10.67 倍，性能平均提高了 9.07%。

Abstract: Federated fine-tuning enables Large Language Models (LLMs) to adapt to
downstream tasks while preserving data privacy, but its resource-intensive
nature limits deployment on edge devices. In this paper, we introduce
Developmental Federated Tuning (DevFT), a resource-efficient approach inspired
by cognitive development that progressively builds a powerful LLM from a
compact foundation. DevFT decomposes the fine-tuning process into developmental
stages, each optimizing submodels with increasing parameter capacity. Knowledge
from earlier stages transfers to subsequent submodels, providing optimized
initialization parameters that prevent convergence to local minima and
accelerate training. This paradigm mirrors human learning, gradually
constructing comprehensive knowledge structure while refining existing skills.
To efficiently build stage-specific submodels, DevFT introduces
deconfliction-guided layer grouping and differential-based layer fusion to
distill essential information and construct representative layers. Evaluations
across multiple benchmarks demonstrate that DevFT significantly outperforms
state-of-the-art methods, achieving up to 4.59$\times$ faster convergence,
10.67$\times$ reduction in communication overhead, and 9.07% average
performance improvement, while maintaining compatibility with existing
approaches.

</details>


### [173] [Predicting Large-scale Urban Network Dynamics with Energy-informed Graph Neural Diffusion](https://arxiv.org/abs/2508.00037)
*Tong Nie,Jian Sun,Wei Ma*

Main category: cs.LG

TL;DR: ScaleSTF是一种高效、可扩展的Transformer模型，用于预测大规模城市系统的时空动态。


<details>
  <summary>Details</summary>
Motivation: 为了在工业和工程领域辅助决策，需要对城市系统中的复杂过程进行数据驱动的预测。现有模型（如图神经网络）在处理大规模网络时面临效率和效果之间的权衡，计算成本高昂，因此需要更有效、可扩展的模型。

Method: 提出了一种基于Transformer的、具有低维嵌入诱导注意力层的可解释神经扩散方案（ScaleSTF），该方案具有线性复杂度，灵感来源于物理定律，旨在解决现有模型（如图神经网络）在效率和效果之间的权衡问题。

Result: ScaleSTF模型在交通流量、太阳能发电和智能电表等大规模城市系统上展示了最先进的性能和显著的可扩展性。

Conclusion: 该研究提出了一种名为ScaleSTF的可扩展时空Transformer模型，该模型具有线性复杂度，并在交通流量、太阳能发电和智能电表等大规模城市系统上进行了验证，表现出最先进的性能和卓越的可扩展性。研究结果为预测大规模城市网络中的动态提供了一个新的视角。

Abstract: Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.

</details>


### [174] [Adacc: Adaptive Compression and Activation Checkpointing for LLM Memory Management](https://arxiv.org/abs/2508.00806)
*Ping Chen,Zhuohong Deng,Ping Li,Shuibing He,Hongzi Zhu,Yi Zheng,Zhefeng Wang,Baoxing Huai,Minyi Guo*

Main category: cs.LG

TL;DR: Adacc, a new memory management framework, reduces LLM training memory usage and speeds up training by up to 1.37x using adaptive compression and activation checkpointing.


<details>
  <summary>Details</summary>
Motivation: Recomputation in training large language models can introduce significant overhead (up to 30%) due to memory pressure. Adacc aims to reduce the GPU memory footprint to alleviate this.

Method: Adacc is a novel memory management framework that combines adaptive compression and activation checkpointing. It features layer-specific compression algorithms that handle outliers in LLM tensors, an optimal scheduling policy determined by MILP, and an adaptive policy evolution mechanism to adjust during training.

Result: Adacc accelerates LLM training by 1.01x to 1.37x and maintains comparable model accuracy.

Conclusion: Adacc can accelerate LLM training by 1.01x to 1.37x compared to state-of-the-art frameworks while maintaining comparable model accuracy to the Baseline.

Abstract: Training large language models often employs recomputation to alleviate
memory pressure, which can introduce up to 30% overhead in real-world
scenarios. In this paper, we propose Adacc, a novel memory management framework
that combines adaptive compression and activation checkpointing to reduce the
GPU memory footprint. It comprises three modules: (1) We design layer-specific
compression algorithms that account for outliers in LLM tensors, instead of
directly quantizing floats from FP16 to INT4, to ensure model accuracy. (2) We
propose an optimal scheduling policy that employs MILP to determine the best
memory optimization for each tensor. (3) To accommodate changes in training
tensors, we introduce an adaptive policy evolution mechanism that adjusts the
policy during training to enhance throughput. Experimental results show that
Adacc can accelerate the LLM training by 1.01x to 1.37x compared to
state-of-the-art frameworks, while maintaining comparable model accuracy to the
Baseline.

</details>


### [175] [Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade Crossings](https://arxiv.org/abs/2508.00039)
*Kaustav Chatterjee,Joshua Q. Li,Fatemeh Ansari,Masud Rana Munna,Kundan Parajulee,Jared Schwennesen*

Main category: cs.LG

TL;DR: 本研究提出了一种结合LSTM和Transformer的混合深度学习方法，用于精确测量公路铁路近地交叉口（HRGC）的剖面，以解决传统测量方法的不足，并提高铁路和公路交通安全。


<details>
  <summary>Details</summary>
Motivation: 高调的公路铁路近地交叉口（HRGC）由于潜在的挂车风险，对公路车辆构成了安全威胁。这些交叉口的出现通常是由于轨道维修活动或不符合设计规范。传统测量HRGC剖面的方法成本高、耗时长、会干扰交通，并存在安全隐患。因此，有必要开发更优越的测量方法。

Method: 研究采用了创新的建模方法和先进的、具有成本效益的技术来测量HRGC剖面。具体而言，利用了配备惯性测量单元（IMU）和全球定位系统（GPS）传感器的公路测试车辆所收集的仪器数据，以及通过工业标准的走走剖面仪获得的真实数据。在此基础上，开发了一个结合长短期记忆（LSTM）和Transformer架构的新型混合深度学习框架。对三种不同的深度学习模型（Transformer-LSTM sequential, LSTM-Transformer sequential, and LSTM-Transformer parallel）进行了评估，以确定最高效的架构。

Result: 研究评估了三种混合深度学习模型（Transformer-LSTM sequential, LSTM-Transformer sequential, and LSTM-Transformer parallel），其中LSTM-Transformer sequential和LSTM-Transformer parallel模型表现优于其他模型。这些模型已被用于生成2D/3D HRGC剖面，并证明了通过快速准确地评估HRGC的挂车易感性来提高公路和铁路安全性的巨大潜力。

Conclusion: 通过使用LSTM和Transformer的混合深度学习框架，可以快速准确地评估公路铁路近地交叉口（HRGC）的挂车易感性，从而提高公路和铁路的安全性。

Abstract: Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.

</details>


### [176] [Regime-Aware Conditional Neural Processes with Multi-Criteria Decision Support for Operational Electricity Price Forecasting](https://arxiv.org/abs/2508.00040)
*Abhinav Das,Stephan Schlüter*

Main category: cs.LG

TL;DR: "本文提出了一种结合贝叶斯状态检测和条件神经网络（R-NP）的电力价格预测模型，并在电池储能优化应用中进行了评估。结果显示，R-NP模型在多标准评估中表现最为均衡和优越。"


<details>
  <summary>Details</summary>
Motivation: "为了更准确地预测24小时电力价格，并评估预测模型在电池储能优化应用中的实际效用，本文整合了贝叶斯状态检测和条件神经网络。"

Method: "本文提出了一种名为R-NP的混合模型，该模型结合了贝叶斯状态检测和条件神经网络。具体地，使用解耦粘性狄利克雷过程隐马尔可夫模型（DS-HDP-HMM）对德国电力市场24小时的电力价格进行状态检测，识别出不同的状态。然后，为每个识别出的状态训练一个独立的条件神经网络（CNP），以学习从输入上下文到24小时电力价格轨迹的局部映射。最终的预测是通过对这些CNP输出进行状态加权混合得到的。"

Result: "通过将R-NP模型、深度神经网络（DNN）和Lasso估计自回归（LEAR）模型的预测结果整合到电池储能优化框架（包括价格套利、风险管理、电网服务和成本最小化）中进行评估，研究发现LEAR模型在绝对利润或成本方面通常表现最优，DNN模型在特定成本最小化场景下表现出色。然而，经过TOPSIS多标准评估后，R-NP模型在2021、2022和2023年被认为是整体表现最均衡、最受青睐的模型。"

Conclusion: "R-NP模型在2021年、2022年和2023年被确定为最均衡且最优选的模型，尽管在绝对利润和成本方面，LEAR模型有时表现更优，DNN模型在特定成本最小化场景下表现出色。"

Abstract: This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.

</details>


### [177] [Improved Robustness and Functional Localization in Topographic CNNs Through Weight Similarity](https://arxiv.org/abs/2508.00043)
*Nhut Truong,Uri Hasson*

Main category: cs.LG

TL;DR: WS约束比AS和非地形CNN在鲁棒性、输入敏感性和功能定位方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 检验不同的地形约束实现方式对神经网络学习表示的影响。

Method: 本文比较了两种空间约束下地形卷积神经网络的训练：权重相似性（WS）和激活相似性（AS）。

Result: 与AS和标准CNN相比，WS在鲁棒性（对噪声和权重扰动）、输入敏感性（更高的激活方差）和功能定位（激活相似的单元距离更近）方面具有优势。WS还影响了单元的方向调优、对称性敏感性和离心率分布。

Conclusion: WS约束在端到端训练中比AS或非地形CNN产生更鲁棒的表示。这些发现还表明，基于权重的空间约束可以塑造生物物理启发模型中的特征学习和功能组织。

Abstract: Topographic neural networks are computational models that can simulate the
spatial and functional organization of the brain. Topographic constraints in
neural networks can be implemented in multiple ways, with potentially different
impacts on the representations learned by the network. The impact of such
different implementations has not been systematically examined. To this end,
here we compare topographic convolutional neural networks trained with two
spatial constraints: Weight Similarity (WS), which pushes neighboring units to
develop similar incoming weights, and Activation Similarity (AS), which
enforces similarity in unit activations. We evaluate the resulting models on
classification accuracy, robustness to weight perturbations and input
degradation, and the spatial organization of learned representations. Compared
to both AS and standard CNNs, WS provided three main advantages: i) improved
robustness to noise, also showing higher accuracy under weight corruption; ii)
greater input sensitivity, reflected in higher activation variance; and iii)
stronger functional localization, with units showing similar activations
positioned at closer distances. In addition, WS produced differences in
orientation tuning, symmetry sensitivity, and eccentricity profiles of units,
indicating an influence of this spatial constraint on the representational
geometry of the network. Our findings suggest that during end-to-end training,
WS constraints produce more robust representations than AS or non-topographic
CNNs. These findings also suggest that weight-based spatial constraints can
shape feature learning and functional organization in biophysical inspired
models.

</details>


### [178] [Foundations of Interpretable Models](https://arxiv.org/abs/2508.00545)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Alberto Termine,Mateja Jamnik,Giuseppe Marra*

Main category: cs.LG

TL;DR: 现有可解释性定义不适用于指导模型设计。本文提出了一个更优的定义，并提供了设计蓝图和开源库。


<details>
  <summary>Details</summary>
Motivation: 现有可解释性定义缺乏可操作性，无法指导模型设计，导致可解释性研究存在根本性问题。

Method: 提出一个更具操作性的可解释性定义，并基于此提出通用可解释模型设计蓝图和开源库。

Result: 提出了一个可操作的、更具通用性的可解释性定义，并提供了可解释模型的设计蓝图和相应的开源库。

Conclusion: 现有可解释性定义无法指导可解释模型设计，使可解释性研究存在根本性问题。本文提出了一个更具操作性的可解释性定义，该定义具有通用性、简洁性，并涵盖了现有非正式概念。新定义直接揭示了设计可解释模型所需的根本属性、基础假设、原则、数据结构和架构特性。基于此，本文提出了一个通用的可解释模型设计蓝图，并发布了首个支持可解释数据结构和过程的开源库。

Abstract: We argue that existing definitions of interpretability are not actionable in
that they fail to inform users about general, sound, and robust interpretable
model design. This makes current interpretability research fundamentally
ill-posed. To address this issue, we propose a definition of interpretability
that is general, simple, and subsumes existing informal notions within the
interpretable AI community. We show that our definition is actionable, as it
directly reveals the foundational properties, underlying assumptions,
principles, data structures, and architectural features necessary for designing
interpretable models. Building on this, we propose a general blueprint for
designing interpretable models and introduce the first open-sourced library
with native support for interpretable data structures and processes.

</details>


### [179] [Benchmarking Partial Observability in Reinforcement Learning with a Suite of Memory-Improvable Domains](https://arxiv.org/abs/2508.00046)
*Ruo Yu Tao,Kaicheng Guo,Cameron Allen,George Konidaris*

Main category: cs.LG

TL;DR: 该研究提出了POBAX库，包含一系列用于评估强化学习在部分可观察性环境下的基准测试，旨在解决现有基准测试的局限性，并推动该领域的研究进展。


<details>
  <summary>Details</summary>
Motivation: 为了促进强化学习算法在部分可观察性环境下的发展，需要更全面的基准测试来评估算法的进展。现有基准测试仅限于简单的状态别名形式，无法充分反映现实世界中复杂的部分可观察性问题。

Method: 研究提出了关于如何评估部分可观察性强化学习的基准测试的原则，并引入了基于JAX的开源库POBAX。POBAX库中包含了多种部分可观察性环境，例如定位与建图、视觉控制和游戏等，并对这些环境进行了测试，证明了它们是“记忆可改进的”，需要难以学习的记忆功能。

Result: POBAX库包含了一系列具有挑战性的部分可观察性环境，这些环境被证明是“记忆可改进的”，即性能提升主要来源于算法处理部分可观察性的能力，而非其他因素。该库还提供了推荐的超参数和算法实现，以及高性能的JAX环境，支持GPU扩展。

Conclusion: 该研究提出了一个名为POBAX的开源库，包含了一系列用于评估和改进强化学习算法在部分可观察性环境下的基准测试。POBAX库提供了多种形式的部分可观察性环境，包括状态别名、视觉遮挡和未知的对手意图等，旨在推动强化学习算法在更广泛的实际应用中的发展。

Abstract: Mitigating partial observability is a necessary but challenging task for
general reinforcement learning algorithms. To improve an algorithm's ability to
mitigate partial observability, researchers need comprehensive benchmarks to
gauge progress. Most algorithms tackling partial observability are only
evaluated on benchmarks with simple forms of state aliasing, such as feature
masking and Gaussian noise. Such benchmarks do not represent the many forms of
partial observability seen in real domains, like visual occlusion or unknown
opponent intent. We argue that a partially observable benchmark should have two
key properties. The first is coverage in its forms of partial observability, to
ensure an algorithm's generalizability. The second is a large gap between the
performance of a agents with more or less state information, all other factors
roughly equal. This gap implies that an environment is memory improvable: where
performance gains in a domain are from an algorithm's ability to cope with
partial observability as opposed to other factors. We introduce best-practice
guidelines for empirically benchmarking reinforcement learning under partial
observability, as well as the open-source library POBAX: Partially Observable
Benchmarks in JAX. We characterize the types of partial observability present
in various environments and select representative environments for our
benchmark. These environments include localization and mapping, visual control,
games, and more. Additionally, we show that these tasks are all memory
improvable and require hard-to-learn memory functions, providing a concrete
signal for partial observability research. This framework includes recommended
hyperparameters as well as algorithm implementations for fast, out-of-the-box
evaluation, as well as highly performant environments implemented in JAX for
GPU-scalable experimentation.

</details>


### [180] [TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly Detection](https://arxiv.org/abs/2508.00047)
*Yuan-Cheng Yu,Yen-Chieh Ouyang,Chun-An Lin*

Main category: cs.LG

TL;DR: TriP-LLM 是一种新颖的无监督时间序列异常检测框架，利用大型语言模型处理时间序列数据。它在多个基准测试中均表现优于现有方法，并且内存效率更高。


<details>
  <summary>Details</summary>
Motivation: 传统统计方法难以处理物联网和智能制造中日益增长的高异质性和复杂时间序列数据。受大型语言模型在多模态任务中成功的启发，需要新的异常检测框架。

Method: 提出了一种名为 TriP-LLM 的三分支补丁大型语言模型框架，用于无监督时间序列异常检测。该框架通过“补丁”、“选择”和“全局”三个分支来整合局部和全局时间特征，将输入时间序列编码为补丁块标记，并由预训练的大型语言模型处理。一个轻量级的补丁块解码器用于重建输入，并从中导出异常分数。

Result: TriP-LLM 在多个公开基准数据集上进行评估，并与最近最先进的方法进行了公平比较。实验结果表明，TriP-LLM 在所有数据集上始终优于最先进的方法，展现出强大的检测能力。此外，通过广泛的消融研究，验证了大型语言模型对整体架构的显著贡献。与使用通道独立性（CI）补丁处理的基于 LLM 的方法相比，TriP-LLM 的内存消耗显著降低。

Conclusion: TriP-LLM 框架在时间序列异常检测方面表现出色，在所有数据集上均优于最先进的方法，并且内存消耗较低，适用于 GPU 内存受限的环境。

Abstract: Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git

</details>


### [181] [Evaluating COVID 19 Feature Contributions to Bitcoin Return Forecasting: Methodology Based on LightGBM and Genetic Optimization](https://arxiv.org/abs/2508.00078)
*Imen Mahmoud,Andrei Velichko*

Main category: cs.LG

TL;DR: 本研究提出了一种结合 LightGBM 和遗传算法的新方法，利用 COVID-19 数据预测比特币回报，发现疫情指标（尤其是疫苗接种率）能显著提升预测准确性，为投资者提供参考。


<details>
  <summary>Details</summary>
Motivation: 本研究的主要目的是预测比特币回报，更重要的是确定包含疫情相关的健康数据是否能显著提高预测的准确性。

Method: 本研究提出了一种新颖的方法论框架，该框架整合了 LightGBM 回归模型和遗传算法 (GA) 优化。研究人员构建了一个包含每日比特币回报和 COVID-19 指标（如疫苗接种率、住院人数、检测统计数据）的综合数据集。通过在 31 次独立运行中使用 GA 优化模型，并与未使用 COVID-19 特征的模型进行对比，以进行稳健的统计评估。研究采用了 R2、RMSE、MAE 等性能指标，并通过分布重叠和 Mann-Whitney U 检验进行统计比较。此外，还使用了排列特征重要性 (PFI) 分析来量化单个特征的贡献。

Result: 研究结果显示，COVID-19 指标显著提高了模型性能，尤其是在捕捉极端市场波动方面（R2 提高了 40%，RMSE 降低了 2%，均具有高度统计显著性）。在 COVID-19 指标中，疫苗接种指标，特别是已完全接种个体占总人口的 75% 百分位数，被证明是最重要的预测因子。

Conclusion: 本研究提出的结合 LightGBM 回归模型和遗传算法 (GA) 优化的新方法框架，能够系统地评估 COVID-19 相关指标对预测比特币回报的贡献。研究结果表明，COVID-19 指标的纳入显著提高了模型性能，尤其是在捕捉极端市场波动方面，R2 提高了 40%，RMSE 降低了 2%，并且这些改进在统计上具有显著性。其中，疫苗接种指标，特别是完全接种个体占总人口的 75% 的百分位数，成为主要的预测因子。该方法通过整合公共卫生信号，扩展了现有的金融分析工具，为投资者和政策制定者在系统性危机期间应对市场不确定性提供了更优的指标。

Abstract: This study proposes a novel methodological framework integrating a LightGBM
regression model and genetic algorithm (GA) optimization to systematically
evaluate the contribution of COVID-19-related indicators to Bitcoin return
prediction. The primary objective was not merely to forecast Bitcoin returns
but rather to determine whether including pandemic-related health data
significantly enhances prediction accuracy. A comprehensive dataset comprising
daily Bitcoin returns and COVID-19 metrics (vaccination rates,
hospitalizations, testing statistics) was constructed. Predictive models,
trained with and without COVID-19 features, were optimized using GA over 31
independent runs, allowing robust statistical assessment. Performance metrics
(R2, RMSE, MAE) were statistically compared through distribution overlaps and
Mann-Whitney U tests. Permutation Feature Importance (PFI) analysis quantified
individual feature contributions. Results indicate that COVID-19 indicators
significantly improved model performance, particularly in capturing extreme
market fluctuations (R2 increased by 40%, RMSE decreased by 2%, both highly
significant statistically). Among COVID-19 features, vaccination metrics,
especially the 75th percentile of fully vaccinated individuals, emerged as
dominant predictors. The proposed methodology extends existing financial
analytics tools by incorporating public health signals, providing investors and
policymakers with refined indicators to navigate market uncertainty during
systemic crises.

</details>


### [182] [Robust Classification under Noisy Labels: A Geometry-Aware Reliability Framework for Foundation Models](https://arxiv.org/abs/2508.00202)
*Ecem Bozkurt,Antonio Ortega*

Main category: cs.LG

TL;DR: 该研究提出一种基于非负核（NNK）的改进方法，通过结合几何信息来增强模型在带噪声数据上的鲁棒性，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是现有基于FM的kNN方法利用局部几何信息表现良好，但该研究认为可以通过引入几何信息来进一步提升性能，尤其是在FM需要用带噪声数据进行微调的场景下。

Method: 提出了一种两阶段框架，包括可靠性估计和可靠性加权推理。其中，推理过程利用非负核（NNK）进行邻域构建，并提出多种可靠性估计方法，以应对标签噪声增加时对距离和局部邻域的依赖性。

Result: 在CIFAR-10和DermaMNIST数据集上，所提出的方法在不同噪声水平下均能提升鲁棒性，并且优于标准的kNN方法和近期自适应邻域基线方法。

Conclusion: 该研究提出的基于几何信息的NNK方法在CIFAR-10和DermaMNIST数据集上，在各种噪声条件下均提高了鲁棒性，优于标准的kNN方法和近期自适应邻域基线方法。

Abstract: Foundation models (FMs) pretrained on large datasets have become fundamental
for various downstream machine learning tasks, in particular in scenarios where
obtaining perfectly labeled data is prohibitively expensive. In this paper, we
assume an FM has to be fine-tuned with noisy data and present a two-stage
framework to ensure robust classification in the presence of label noise
without model retraining. Recent work has shown that simple k-nearest neighbor
(kNN) approaches using an embedding derived from an FM can achieve good
performance even in the presence of severe label noise. Our work is motivated
by the fact that these methods make use of local geometry. In this paper,
following a similar two-stage procedure, reliability estimation followed by
reliability-weighted inference, we show that improved performance can be
achieved by introducing geometry information. For a given instance, our
proposed inference uses a local neighborhood of training data, obtained using
the non-negative kernel (NNK) neighborhood construction. We propose several
methods for reliability estimation that can rely less on distance and local
neighborhood as the label noise increases. Our evaluation on CIFAR-10 and
DermaMNIST shows that our methods improve robustness across various noise
conditions, surpassing standard K-NN approaches and recent
adaptive-neighborhood baselines.

</details>


### [183] [Stress-Aware Resilient Neural Training](https://arxiv.org/abs/2508.00098)
*Ashkan Shakarami,Yousef Yeganeh,Azade Farshad,Lorenzo Nicole,Stefano Ghidoni,Nassir Navab*

Main category: cs.LG

TL;DR: 通过引入“塑性变形优化器”，模型可以动态调整优化行为，以提高在不稳定训练环境下的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了提高深度神经网络在不稳定或动态变化环境下的训练鲁棒性，借鉴材料科学中的结构疲劳概念，提出了应激感知学习框架。

Method: 提出了一种名为“塑性变形优化器”的应激感知机制，通过在检测到训练损失和准确性停滞的内部应激信号时，向模型参数注入自适应噪声，使模型能够跳出尖锐的最小值，收敛到更平坦、更具泛化能力的损失区域。

Result: 实验结果表明，该方法能够提高模型的鲁棒性和泛化能力，且计算开销很小。

Conclusion: 该研究提出的应激感知学习框架在六种架构、四种优化器和七个视觉基准的实验中，证明了其具有鲁棒性和泛化能力，同时计算开销极小。

Abstract: This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.

</details>


### [184] [StackLiverNet: A Novel Stacked Ensemble Model for Accurate and Interpretable Liver Disease Detection](https://arxiv.org/abs/2508.00117)
*Md. Ehsanul Haque,S. M. Jahidul Islam,Shakil Mia,Rumana Sharmin,Ashikuzzaman,Md Samir Morshed,Md. Tahmidul Huque*

Main category: cs.LG

TL;DR: StackLiverNet是一种结合了数据预处理、特征选择和集成学习的可解释模型，用于肝脏疾病检测，准确率高，速度快，并能提供关键指标的诊断依据。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前肝脏疾病检测模型中存在的误分类错误率高、可解释性差、计算成本高以及缺乏良好预处理策略等问题。

Method: 提出了一种名为StackLiverNet的可解释堆叠集成模型，该模型结合了先进的数据预处理、特征选择技术、随机欠采样（处理类别不平衡）以及经过超参数优化的基分类器，并使用LightGBM作为元模型。

Result: StackLiverNet在测试中达到了99.89%的准确率、0.9974的Cohen Kappa和0.9993的AUC，仅有5个误分类。训练时间为4.2783秒，推理时间为0.1106秒。模型的可解释性分析揭示了高浓度的碱性磷酸酶和中等浓度的SGOT是肝脏疾病的重要指标。

Conclusion: StackLiverNet在肝脏疾病检测任务中表现出色，具有高准确率（99.89%）、高Cohen Kappa（0.9974）和高AUC（0.9993），并且训练和推理速度快，适合临床应用。通过LIME和SHAP等方法，模型能够提供可解释性，识别出碱性磷酸酶和SGOT等关键指标对肝脏疾病诊断的重要性。

Abstract: Liver diseases are a serious health concern in the world, which requires
precise and timely diagnosis to enhance the survival chances of patients. The
current literature implemented numerous machine learning and deep learning
models to classify liver diseases, but most of them had some issues like high
misclassification error, poor interpretability, prohibitive computational
expense, and lack of good preprocessing strategies. In order to address these
drawbacks, we introduced StackLiverNet in this study; an interpretable stacked
ensemble model tailored to the liver disease detection task. The framework uses
advanced data preprocessing and feature selection technique to increase model
robustness and predictive ability. Random undersampling is performed to deal
with class imbalance and make the training balanced. StackLiverNet is an
ensemble of several hyperparameter-optimized base classifiers, whose
complementary advantages are used through a LightGBM meta-model. The provided
model demonstrates excellent performance, with the testing accuracy of 99.89%,
Cohen Kappa of 0.9974, and AUC of 0.9993, having only 5 misclassifications, and
efficient training and inference speeds that are amenable to clinical practice
(training time 4.2783 seconds, inference time 0.1106 seconds). Besides, Local
Interpretable Model-Agnostic Explanations (LIME) are applied to generate
transparent explanations of individual predictions, revealing high
concentrations of Alkaline Phosphatase and moderate SGOT as important
observations of liver disease. Also, SHAP was used to rank features by their
global contribution to predictions, while the Morris method confirmed the most
influential features through sensitivity analysis.

</details>


### [185] [Structured Transformations for Stable and Interpretable Neural Computation](https://arxiv.org/abs/2508.00127)
*Saleh Nikooroo,Thomas Engel*

Main category: cs.LG

TL;DR: 通过将神经网络的层级变换分解为结构化线性算子和残差校正分量，可以提高模型的稳定性、可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前的神经网络尽管性能令人印象深刻，但常常缺乏促进稳定学习和可解释行为的结构化保障。

Method: 提出了一种层级变换的重构方法，将变换分解为结构化线性算子和残差校正分量，以实现更受约束的信号传播和改进的训练动态。

Result: 通过一系列合成和真实世界的实验，证明了采用结构化变换构建的模型在梯度条件、对扰动的敏感性以及层级稳健性方面有所提高，并且这些优势在不同模型规模和训练方案中都得以保持。

Conclusion: 本研究为一类更规整的神经架构奠定了基础，该架构优先考虑稳定性和透明度，并提供了新的工具来推理学习行为而不牺牲表达能力。

Abstract: Despite their impressive performance, contemporary neural networks often lack
structural safeguards that promote stable learning and interpretable behavior.
In this work, we introduce a reformulation of layer-level transformations that
departs from the standard unconstrained affine paradigm. Each transformation is
decomposed into a structured linear operator and a residual corrective
component, enabling more disciplined signal propagation and improved training
dynamics. Our formulation encourages internal consistency and supports stable
information flow across depth, while remaining fully compatible with standard
learning objectives and backpropagation. Through a series of synthetic and
real-world experiments, we demonstrate that models constructed with these
structured transformations exhibit improved gradient conditioning, reduced
sensitivity to perturbations, and layer-wise robustness. We further show that
these benefits persist across architectural scales and training regimes. This
study serves as a foundation for a more principled class of neural
architectures that prioritize stability and transparency-offering new tools for
reasoning about learning behavior without sacrificing expressive power.

</details>


### [186] [Wind Power Scenario Generation based on the Generalized Dynamic Factor Model and Generative Adversarial Network](https://arxiv.org/abs/2508.00692)
*Young-ho Cho,Hao Zhu,Duehee Lee,Ross Baldick*

Main category: cs.LG

TL;DR: 通过结合GDFM和GAN，提出了一种新的方法来合成风力发电场景，该方法考虑了时空特征，并在数值测试中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 为了进行资源充分性研究，需要合成多个分布式风电场的长期风力发电场景，并考虑其时空特征，如空间和时间相关性、波形、功率谱密度等。

Method: 提出了一种结合广义动态因子模型（GDFM）和生成对抗网络（GAN）的方法，其中GAN用于提供一个提取具有时间信息的动态因子的滤波器，然后将该滤波器应用于GDFM中，以同时表示空间和频率相关性以及合理的波形。

Result: 数值测试表明，所提出的GDFM和GAN的结合方法在合成风力发电场景方面优于现有方法，能够更好地实现实际风力发电的统计特性，相比于仅使用GDFM或GAN的方法。

Conclusion: 通过结合GDFM和GAN的优势，所提出的方法在合成风力发电场景方面表现出优于其他方法的性能，并且能够更好地实现实际风力发电的统计特性。

Abstract: For conducting resource adequacy studies, we synthesize multiple long-term
wind power scenarios of distributed wind farms simultaneously by using the
spatio-temporal features: spatial and temporal correlation, waveforms, marginal
and ramp rates distributions of waveform, power spectral densities, and
statistical characteristics. Generating the spatial correlation in scenarios
requires the design of common factors for neighboring wind farms and
antithetical factors for distant wind farms. The generalized dynamic factor
model (GDFM) can extract the common factors through cross spectral density
analysis, but it cannot closely imitate waveforms. The GAN can synthesize
plausible samples representing the temporal correlation by verifying samples
through a fake sample discriminator. To combine the advantages of GDFM and GAN,
we use the GAN to provide a filter that extracts dynamic factors with temporal
information from the observation data, and we then apply this filter in the
GDFM to represent both spatial and frequency correlations of plausible
waveforms. Numerical tests on the combination of GDFM and GAN have demonstrated
performance improvements over competing alternatives in synthesizing wind power
scenarios from Australia, better realizing plausible statistical
characteristics of actual wind power compared to alternatives such as the GDFM
with a filter synthesized from distributions of actual dynamic filters and the
GAN with direct synthesis without dynamic factors.

</details>


### [187] [ECG Latent Feature Extraction with Autoencoders for Downstream Prediction Tasks](https://arxiv.org/abs/2508.00131)
*Christopher Harvey,Sumaiya Shomaji,Zijun Yao,Amit Noheria*

Main category: cs.LG

TL;DR: 本研究提出VAE编码，用于简化ECG数据，提高深度学习模型在数据有限情况下的表现，并实现了优于现有方法的效率。


<details>
  <summary>Details</summary>
Motivation: ECG信号的复杂性和个体间变异性（通常是12导联、500 Hz采样率下的60,000维向量）在深度学习模型中应用时，尤其是在只有小型训练数据集可用时，带来了挑战。

Method: 本研究探索了从代表性心拍ECG生成特征的方法，重点关注主成分分析（PCA）和自动编码器以降低数据复杂度。研究引入了三种新颖的变分自动编码器（VAE）变体——随机自动编码器（SAE）、退火beta-VAE（A beta-VAE）和循环beta-VAE（C beta-VAE），并比较了它们在保持信号保真度和增强下游预测任务方面的有效性，使用了Light Gradient Boost Machine（LGBM）。

Result: A beta-VAE在信号重建方面表现优越，将平均绝对误差（MAE）降至15.7+/-3.2 muV，达到信号噪声的水平。此外，SAE编码与传统的ECG摘要特征相结合，提高了预测降低的左心室射血分数（LVEF）的能力，使用LGBM分类器在独立的测试集上达到了0.901的接收者操作特征曲线下面积（AUROC），这接近了最先进的CNN模型的0.909 AUROC，但计算资源需求显著减少。此外，ECG特征提取-LGBM流程在用较少数据训练时，避免了过拟合并保持了预测性能。

Conclusion: 本研究提出的VAE编码有效简化了ECG数据，并为在标记训练数据有限的情况下应用深度学习提供了实用的解决方案。

Abstract: The electrocardiogram (ECG) is an inexpensive and widely available tool for
cardiac assessment. Despite its standardized format and small file size, the
high complexity and inter-individual variability of ECG signals (typically a
60,000-size vector with 12 leads at 500 Hz) make it challenging to use in deep
learning models, especially when only small training datasets are available.
This study addresses these challenges by exploring feature generation methods
from representative beat ECGs, focusing on Principal Component Analysis (PCA)
and Autoencoders to reduce data complexity. We introduce three novel
Variational Autoencoder (VAE) variants-Stochastic Autoencoder (SAE), Annealed
beta-VAE (A beta-VAE), and Cyclical beta VAE (C beta-VAE)-and compare their
effectiveness in maintaining signal fidelity and enhancing downstream
prediction tasks using a Light Gradient Boost Machine (LGBM). The A beta-VAE
achieved superior signal reconstruction, reducing the mean absolute error (MAE)
to 15.7+/-3.2 muV, which is at the level of signal noise. Moreover, the SAE
encodings, when combined with traditional ECG summary features, improved the
prediction of reduced Left Ventricular Ejection Fraction (LVEF), achieving an
holdout test set area under the receiver operating characteristic curve (AUROC)
of 0.901 with a LGBM classifier. This performance nearly matches the 0.909
AUROC of state-of-the-art CNN model but requires significantly less
computational resources. Further, the ECG feature extraction-LGBM pipeline
avoids overfitting and retains predictive performance when trained with less
data. Our findings demonstrate that these VAE encodings are not only effective
in simplifying ECG data but also provide a practical solution for applying deep
learning in contexts with limited-scale labeled training data.

</details>


### [188] [INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling Network Prediction via Reinforcement Learning Boosted Graph Neural Networks](https://arxiv.org/abs/2508.00141)
*Mohit Gupta,Debjit Bhowmick,Rhys Newbury,Meead Saberi,Shirui Pan,Ben Beck*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.

</details>


### [189] [Watch the Weights: Unsupervised monitoring and control of fine-tuned LLMs](https://arxiv.org/abs/2508.00161)
*Ziqian Zhong,Aditi Raghunathan*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的基于权重而非激活的LLM可解释性方法，称为WeightWatch。该方法通过分析模型权重差异来识别和监控新行为，可有效检测后门攻击（100%攻击阻止率，<1.2%误报率）并审计模型（如揭示营销策略）。它还能用于模型“去学习”的监控和引导。与依赖特定训练数据的现有方法不同，WeightWatch不需要与未知训练数据分布相似的数据。实现代码已在GitHub上公开。


<details>
  <summary>Details</summary>
Motivation: 现有的可解释性方法（尤其是基于激活的方法）通常需要或假设与未知训练数据分布相似的数据，这在检测和防御由其定义为分布外的新型潜在威胁（如后门）时是一个重大限制。因此，需要一种能够处理与未知训练数据分布不相似的数据的可解释性方法。

Method: 本文提出了一种新的方法，通过解释权重而非激活来理解、监控和控制经过微调的大型语言模型（LLM）。该方法通过分析微调模型和基础模型之间权重差异的顶部奇异向量来识别新获得的行为，并通过监控沿这些方向的激活的余弦相似性来检测微调期间引入的显著行为。

Result: 该方法在后门检测方面表现出色，能阻止高达100%的攻击，误报率低于1.2%。在模型“去学习”方面，该方法能以高达95.42%的准确率检测关于已删除主题的推理，并能引导模型恢复“已去学习”的信息。此外，在模型审计方面，该方法成功揭示了商业指令微调模型（OLMo、Llama、Qwen）的模型特定微调重点，例如营销策略和Midjourney提示生成。

Conclusion: 该研究提出了一种基于权重的LLM可解释性方法，能够有效检测和防御新型后门攻击，并能监控和引导经过微调的模型。该方法通过分析微调模型与基础模型之间的权重差异的顶部奇异向量来识别新获得的行为，并利用激活的余弦相似性来检测微调引入的显著行为。在后门检测方面，该方法能阻止高达100%的攻击，误报率低于1.2%。在模型“去学习”方面，该方法能以高达95.42%的准确率检测关于已删除主题的推理，并能引导模型恢复“已去学习”的信息。此外，该方法还可用于部署前的模型审计，通过分析商业指令微调模型，揭示了模型特定的微调重点，如营销策略和Midjourney提示生成。

Abstract: The releases of powerful open-weight large language models (LLMs) are often
not accompanied by access to their full training data. Existing
interpretability methods, particularly those based on activations, often
require or assume distributionally similar data. This is a significant
limitation when detecting and defending against novel potential threats like
backdoors, which are by definition out-of-distribution.
  In this work, we introduce a new method for understanding, monitoring and
controlling fine-tuned LLMs that interprets weights, rather than activations,
thereby side stepping the need for data that is distributionally similar to the
unknown training data. We demonstrate that the top singular vectors of the
weight difference between a fine-tuned model and its base model correspond to
newly acquired behaviors. By monitoring the cosine similarity of activations
along these directions, we can detect salient behaviors introduced during
fine-tuning with high precision.
  For backdoored models that bypasses safety mechanisms when a secret trigger
is present, our method stops up to 100% of attacks with a false positive rate
below 1.2%. For models that have undergone unlearning, we detect inference on
erased topics with accuracy up to 95.42% and can even steer the model to
recover "unlearned" information. Besides monitoring, our method also shows
potential for pre-deployment model auditing: by analyzing commercial
instruction-tuned models (OLMo, Llama, Qwen), we are able to uncover
model-specific fine-tuning focus including marketing strategies and Midjourney
prompt generation.
  Our implementation can be found at https://github.com/fjzzq2002/WeightWatch.

</details>


### [190] [DiSC-Med: Diffusion-based Semantic Communications for Robust Medical Image Transmission](https://arxiv.org/abs/2508.00172)
*Fupei Guo,Hao Zheng,Xiang Zhang,Li Chen,Yue Wang,Songyang Zhang*

Main category: cs.LG

TL;DR: A new diffusion-based semantic communication framework (DiSC-Med) improves medical image transmission over noisy, low-bandwidth channels using enhanced compression and denoising, outperforming traditional methods.


<details>
  <summary>Details</summary>
Motivation: To enable timely and effective remote healthcare, efficient transmission of medical data through noisy channels with limited bandwidth is a critical challenge driven by advancements in AI and wireless communication.

Method: A novel diffusion-based semantic communication framework (DiSC-Med) is proposed, incorporating medical-enhanced compression and denoising blocks for bandwidth efficiency and robustness respectively. It differs from conventional pixel-wise frameworks by capturing key semantic information.

Result: Extensive experiments on real-world medical datasets validate the effectiveness of the DiSC-Med framework, showing its ability to achieve superior reconstruction performance with ultra-high bandwidth efficiency against noisy channels.

Conclusion: The proposed DiSC-Med framework demonstrates superior reconstruction performance and ultra-high bandwidth efficiency against noisy channels for medical image transmission, showcasing its potential for robust and efficient telehealth applications.

Abstract: The rapid development of artificial intelligence has driven smart health with
next-generation wireless communication technologies, stimulating exciting
applications in remote diagnosis and intervention. To enable a timely and
effective response for remote healthcare, efficient transmission of medical
data through noisy channels with limited bandwidth emerges as a critical
challenge. In this work, we propose a novel diffusion-based semantic
communication framework, namely DiSC-Med, for the medical image transmission,
where medical-enhanced compression and denoising blocks are developed for
bandwidth efficiency and robustness, respectively. Unlike conventional
pixel-wise communication framework, our proposed DiSC-Med is able to capture
the key semantic information and achieve superior reconstruction performance
with ultra-high bandwidth efficiency against noisy channels. Extensive
experiments on real-world medical datasets validate the effectiveness of our
framework, demonstrating its potential for robust and efficient telehealth
applications.

</details>


### [191] [RL as Regressor: A Reinforcement Learning Approach for Function Approximation](https://arxiv.org/abs/2508.00174)
*Yongchao Huang*

Main category: cs.LG

TL;DR: 将回归视为强化学习（RL）问题，并使用Actor-Critic智能体结合优先经验回放、增加网络容量和位置编码来解决回归问题，该方法提供了更大的灵活性。


<details>
  <summary>Details</summary>
Motivation: 标准回归技术受限于预定义、可微的损失函数（如均方误差），这些函数可能无法完全捕捉系统的期望行为，尤其是在处理非对称成本或复杂、不可微的目标时。

Method: 将回归视为强化学习（RL）问题，将模型的预测视为一个动作，并根据预测误差定义自定义奖励信号，以利用强大的RL算法进行函数逼近。通过一个学习带噪正弦波的渐进案例研究，展示了Actor-Critic智能体的发展，并结合了优先经验回放、增加网络容量和位置编码来增强智能体。 

Result: RL框架成功解决了回归问题，并提供了定义目标和指导学习过程的增强灵活性。

Conclusion: RL框架不仅成功解决了回归问题，还为定义目标和指导学习过程提供了增强的灵活性。

Abstract: Standard regression techniques, while powerful, are often constrained by
predefined, differentiable loss functions such as mean squared error. These
functions may not fully capture the desired behavior of a system, especially
when dealing with asymmetric costs or complex, non-differentiable objectives.
In this paper, we explore an alternative paradigm: framing regression as a
Reinforcement Learning (RL) problem. We demonstrate this by treating a model's
prediction as an action and defining a custom reward signal based on the
prediction error, and we can leverage powerful RL algorithms to perform
function approximation. Through a progressive case study of learning a noisy
sine wave, we illustrate the development of an Actor-Critic agent, iteratively
enhancing it with Prioritized Experience Replay, increased network capacity,
and positional encoding to enable a capable RL agent for this regression task.
Our results show that the RL framework not only successfully solves the
regression problem but also offers enhanced flexibility in defining objectives
and guiding the learning process.

</details>


### [192] [Learning Potential Energy Surfaces of Hydrogen Atom Transfer Reactions in Peptides](https://arxiv.org/abs/2508.00578)
*Marlen Neubert,Patrick Reiser,Frauke Gräter,Pascal Friederich*

Main category: cs.LG

TL;DR: 本文利用机器学习势能模拟生物分子中的氢原子转移反应，其中MACE模型表现最佳，为理解生物过程中的化学反应性提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 氢原子转移（HAT）反应在许多生物过程中至关重要，但其机理尚不完全清楚，并且在生物相关尺度上模拟HAT具有挑战性，因为需要量子化学精度。

Method: 本文系统地生成肽中的氢原子转移（HAT）构型，使用半经验方法和DFT构建大型数据集，并对三种图神经网络（SchNet、Allegro和MACE）学习HAT势能面的能力进行基准测试，以及间接预测反应势垒。

Result: MACE在能量、力和势垒预测方面始终优于其他模型，在预测分布外的DFT势垒方面，平均绝对误差为1.13 kcal/mol。该精度能够将机器学习势能集成到大规模胶原蛋白模拟中，通过预测的势垒计算反应速率，从而增进对肽中HAT和自由基迁移机理的理解。

Conclusion: 机器学习势能可以与过渡态搜索算法和主动学习相结合，以进一步改进方法，并能推广到其他生物分子系统，从而实现对复杂环境中化学反应性的量子精度模拟。

Abstract: Hydrogen atom transfer (HAT) reactions are essential in many biological
processes, such as radical migration in damaged proteins, but their mechanistic
pathways remain incompletely understood. Simulating HAT is challenging due to
the need for quantum chemical accuracy at biologically relevant scales; thus,
neither classical force fields nor DFT-based molecular dynamics are applicable.
Machine-learned potentials offer an alternative, able to learn potential energy
surfaces (PESs) with near-quantum accuracy. However, training these models to
generalize across diverse HAT configurations, especially at radical positions
in proteins, requires tailored data generation and careful model selection.
Here, we systematically generate HAT configurations in peptides to build large
datasets using semiempirical methods and DFT. We benchmark three graph neural
network architectures (SchNet, Allegro, and MACE) on their ability to learn HAT
PESs and indirectly predict reaction barriers from energy predictions. MACE
consistently outperforms the others in energy, force, and barrier prediction,
achieving a mean absolute error of 1.13 kcal/mol on out-of-distribution DFT
barrier predictions. This accuracy enables integration of ML potentials into
large-scale collagen simulations to compute reaction rates from predicted
barriers, advancing mechanistic understanding of HAT and radical migration in
peptides. We analyze scaling laws, model transferability, and cost-performance
trade-offs, and outline strategies for improvement by combining ML potentials
with transition state search algorithms and active learning. Our approach is
generalizable to other biomolecular systems, enabling quantum-accurate
simulations of chemical reactivity in complex environments.

</details>


### [193] [EMA Without the Lag: Bias-Corrected Iterate Averaging Schemes](https://arxiv.org/abs/2508.00180)
*Adam Block,Cyril Zhang*

Main category: cs.LG

TL;DR: BEMA 通过消除偏差来改进 EMA，从而在语言模型微调中实现更稳定、更高效的训练。


<details>
  <summary>Details</summary>
Motivation: 语言模型微调中的随机性（通常由小批量大小引起）会导致训练不稳定和生成质量的巨大波动。标准的 EMA 方法可以缓解这种不稳定性，但会引入偏差，从而在优化方面落后于标准训练。

Method: 提出了一种名为偏差修正指数移动平均（BEMA）的方法，该方法通过消除旧迭代引入的偏差来增强标准的 EMA，从而在不牺牲方差缩减效益的情况下加速优化。

Result: 通过在多种标准语言模型基准上的大量实验证明，BEMA 在收敛速度和最终性能方面均显著优于 EMA 和标准训练。

Conclusion: BEMA是一种简单实用的 EMA 增强方法，可保留方差缩减的优点，同时消除偏差，并在语言模型微调中显示出比 EMA 和标准训练明显提高收敛速度和最终性能。

Abstract: Stochasticity in language model fine-tuning, often caused by the small batch
sizes typically used in this regime, can destabilize training by introducing
large oscillations in generation quality. A popular approach to mitigating this
instability is to take an Exponential moving average (EMA) of weights
throughout training. While EMA reduces stochasticity, thereby smoothing
training, the introduction of bias from old iterates often creates a lag in
optimization relative to vanilla training. In this work, we propose the
Bias-Corrected Exponential Moving Average (BEMA), a simple and practical
augmentation of EMA that retains variance-reduction benefits while eliminating
bias. BEMA is motivated by a simple theoretical model wherein we demonstrate
provable acceleration of BEMA over both a standard EMA and vanilla training.
Through an extensive suite of experiments on Language Models, we show that BEMA
leads to significantly improved convergence rates and final performance over
both EMA and vanilla training in a variety of standard LM benchmarks, making
BEMA a practical and theoretically motivated intervention for more stable and
efficient fine-tuning.

</details>


### [194] [RecoMind: A Reinforcement Learning Framework for Optimizing In-Session User Satisfaction in Recommendation Systems](https://arxiv.org/abs/2508.00201)
*Mehdi Ben Ayed,Fei Feng,Jay Adams,Vishwakarma Singh,Kritarth Anand,Jiajing Xu*

Main category: cs.LG

TL;DR: RecoMind 是一个创新的框架，它利用模拟器和自定义探索策略，成功地将强化学习应用于大规模推荐系统，显著提高了用户参与度和会话深度，解决了传统监督学习方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的网络规模推荐系统通常使用优先考虑即时用户反馈的监督学习方法。尽管强化学习（RL）为优化诸如会话内参与度等长期目标提供了解决方案，但由于其极大的动作空间和工程复杂性，在网络规模上应用它具有挑战性。

Method: RecoMind是一个基于模拟器的强化学习框架，利用现有的推荐模型建立模拟环境并引导强化学习策略，以从一开始就优化即时用户互动。它还引入了一种自定义的探索策略，用于高效地探索包含数亿个项目的网络规模动作空间。

Result: 通过在视频流平台上进行的广泛的离线模拟和在线 A/B 测试评估，RecoMind 训练的 RL 策略在会话内用户满意度方面显著优于传统的监督学习推荐方法。在线 A/B 测试显示，RL 策略将观看超过 10 秒的视频次数增加了 15.81%，并将至少包含 10 次互动会话的深度提高了 4.71%。

Conclusion: RecoMind是一个系统化的、可扩展的方法，用于将强化学习嵌入到网络规模的推荐系统中，在优化基于会话的用户满意度方面显示出巨大潜力。

Abstract: Existing web-scale recommendation systems commonly use supervised learning
methods that prioritize immediate user feedback. Although reinforcement
learning (RL) offers a solution to optimize longer-term goals, such as
in-session engagement, applying it at web scale is challenging due to the
extremely large action space and engineering complexity. In this paper, we
introduce RecoMind, a simulator-based RL framework designed for the effective
optimization of session-based goals at web-scale. RecoMind leverages existing
recommendation models to establish a simulation environment and to bootstrap
the RL policy to optimize immediate user interactions from the outset. This
method integrates well with existing industry pipelines, simplifying the
training and deployment of RL policies. Additionally, RecoMind introduces a
custom exploration strategy to efficiently explore web-scale action spaces with
hundreds of millions of items. We evaluated RecoMind through extensive offline
simulations and online A/B testing on a video streaming platform. Both methods
showed that the RL policy trained using RecoMind significantly outperforms
traditional supervised learning recommendation approaches in in-session user
satisfaction. In online A/B tests, the RL policy increased videos watched for
more than 10 seconds by 15.81\% and improved session depth by 4.71\% for
sessions with at least 10 interactions. As a result, RecoMind presents a
systematic and scalable approach for embedding RL into web-scale recommendation
systems, showing great promise for optimizing session-based user satisfaction.

</details>


### [195] [Towards Higher Effective Rank in Parameter-efficient Fine-tuning using Khatri--Rao Product](https://arxiv.org/abs/2508.00230)
*Paul Albert,Frederic Z. Zhang,Hemanth Saratchandran,Anton van den Hengel,Ehsan Abbasnejad*

Main category: cs.LG

TL;DR: KRAdapter是一种新的PEFT方法，通过Khatri-Rao积克服了LoRA在处理高秩矩阵时的局限性，在多模态和大型语言模型上均表现出性能提升，同时保持了效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决LoRA在应用于多模态和大型语言模型时，与全秩替代方法相比的局限性，尤其是在处理具有相对平坦谱或高频分量的矩阵时。

Method: 通过使用具有可控谱特性的合成矩阵近似基准，对全秩和低秩PEFT方法进行量化比较，并引入了KRAdapter，一种利用Khatri-Rao积的新型PEFT算法。

Result: LoRA在近似具有相对平坦谱或高频分量的矩阵时存在困难，而KRAdapter在视觉语言模型和大型语言模型上均取得了性能提升，特别是在未见过的常识推理任务上。

Conclusion: KRAdapter通过利用Khatri-Rao积来产生权重更新，该更新在结构上倾向于产生具有高有效秩的矩阵乘积。在视觉语言模型（多达1B参数）和大型语言模型（多达8B参数）上，KRAdapter在处理未见过的常识推理任务时表现出性能提升，同时保持了LoRA的内存和计算效率。

Abstract: Parameter-efficient fine-tuning (PEFT) has become a standard approach for
adapting large pre-trained models. Amongst PEFT methods, low-rank adaptation
(LoRA) has achieved notable success. However, recent studies have highlighted
its limitations compared against full-rank alternatives, particularly when
applied to multimodal and large language models. In this work, we present a
quantitative comparison amongst full-rank and low-rank PEFT methods using a
synthetic matrix approximation benchmark with controlled spectral properties.
Our results confirm that LoRA struggles to approximate matrices with relatively
flat spectrums or high frequency components -- signs of high effective ranks.
To this end, we introduce KRAdapter, a novel PEFT algorithm that leverages the
Khatri-Rao product to produce weight updates, which, by construction, tends to
produce matrix product with a high effective rank. We demonstrate performance
gains with KRAdapter on vision-language models up to 1B parameters and on large
language models up to 8B parameters, particularly on unseen common-sense
reasoning tasks. In addition, KRAdapter maintains the memory and compute
efficiency of LoRA, making it a practical and robust alternative to fine-tune
billion-scale parameter models.

</details>


### [196] [Calibrated Language Models and How to Find Them with Label Smoothing](https://arxiv.org/abs/2508.00264)
*Jerry Huang,Peng Lu,Qiuhao Zeng*

Main category: cs.LG

TL;DR: 指令微调会损害LLM的置信度校准，标签平滑可缓解此问题，但对大型词汇量LLM效果有限，研究者提出了改进方案。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理（NLP）的进步，微调大型语言模型（LLM）使其成为更强大的交互式代理已成为可能。然而，指令微调对模型置信度校准的影响尚未得到充分研究，这对于保证模型输出的可靠性至关重要。

Method: 本研究通过分析开源LLM，研究了指令微调对其置信度校准的影响。研究人员尝试使用标签平滑作为一种正则化方法来解决过度自信问题，并从理论和实验上论证了其有效性，特别是在处理大型词汇量LLM（LV-LLM）时。

Result: 研究表明，指令微调会显著降低LLM的置信度校准。标签平滑可以作为一种有效的解决方案，但对于大型词汇量LLM（LV-LLM）而言，其效果会大打折扣，因为这些模型更容易出现过度自信。研究还提出了一种新的方法来优化标签平滑的内存占用。

Conclusion: 本研究发现，指令微调虽然提升了LLM的交互能力，但会严重降低其置信度校准。研究发现标签平滑可以缓解这一问题，但对于具有大型词汇量（LV-LLM）的LLM效果会减弱，其原因是模型容易过度自信，这与模型的隐藏层大小和词汇量大小有关。此外，研究还提出了一种优化的标签平滑损失计算方法，以减小内存占用。

Abstract: Recent advances in natural language processing (NLP) have opened up greater
opportunities to enable fine-tuned large language models (LLMs) to behave as
more powerful interactive agents through improved instruction-following
ability. However, understanding how this impacts confidence calibration for
reliable model output has not been researched in full. In this work, we examine
various open-sourced LLMs, identifying significant calibration degradation
after instruction tuning in each. Seeking a practical solution, we look towards
label smoothing, which has been shown as an effective method to regularize for
overconfident predictions but has yet to be widely adopted in the supervised
fine-tuning (SFT) of LLMs. We first provide insight as to why label smoothing
is sufficient to maintain calibration throughout the SFT process. However,
settings remain where the effectiveness of smoothing is severely diminished, in
particular the case of large vocabulary LLMs (LV-LLMs). We posit the cause to
stem from the ability to become over-confident, which has a direct relationship
with the hidden size and vocabulary size, and justify this theoretically and
experimentally. Finally, we address an outstanding issue regarding the memory
footprint of the cross-entropy loss computation in the label smoothed loss
setting, designing a customized kernel to dramatically reduce memory
consumption without sacrificing speed or performance in comparison to existing
solutions for non-smoothed losses.

</details>


### [197] [Learning to Optimize Feedback for One Million Students: Insights from Multi-Armed and Contextual Bandits in Large-Scale Online Tutoring](https://arxiv.org/abs/2508.00270)
*Robin Schmucker,Nimish Pachapurkar,Shanmuga Bala,Miral Shah,Tom Mitchell*

Main category: cs.LG

TL;DR: 一个在线辅导系统利用MAB和CB框架，通过分析百万学生数据，学习并优化反馈策略，以提高学生学习效果。虽然MAB策略效果显著，但CB策略的个性化改进有限。


<details>
  <summary>Details</summary>
Motivation: 为了提高在线辅导系统的有效性，特别是针对学生答错问题后提供的反馈，以优化学生学习。

Method: 提出了一种利用多臂老虎机（MAB）和离线策略评估来学习有效反馈的在线辅导系统。该系统使用一百万学生数据评估了43,000种辅助操作，并设计了一种算法来优化学生学习和练习会话表现。此外，还利用因果推断研究了个性化反馈（上下文老虎机 CB）与整体反馈（MAB）的对比。

Result: 与基线相比，MAB策略在166,000次练习会话中显著改善了学生成果。然而，尽管发现了一些辅助操作对某些问题存在异质性效应，但CB策略相比于MAB策略仅能带来边际改进，因为效果规模有限。

Conclusion: 多臂老虎机（MAB）策略在整体学生群体中优化反馈方面表现出色，而上下文老虎机（CB）策略在个性化反馈以提高结果方面，仅能带来边际改进，因为个体学生行为异质性的效果规模有限。

Abstract: We present an online tutoring system that learns to provide effective
feedback to students after they answer questions incorrectly. Using data from
one million students, the system learns which assistance action (e.g., one of
multiple hints) to provide for each question to optimize student learning.
Employing the multi-armed bandit (MAB) framework and offline policy evaluation,
we assess 43,000 assistance actions, and identify trade-offs between assistance
policies optimized for different student outcomes (e.g., response correctness,
session completion). We design an algorithm that for each question decides on a
suitable policy training objective to enhance students' immediate second
attempt success and overall practice session performance. We evaluate the
resulting MAB policies in 166,000 practice sessions, verifying significant
improvements in student outcomes. While MAB policies optimize feedback for the
overall student population, we further investigate whether contextual bandit
(CB) policies can enhance outcomes by personalizing feedback based on
individual student features (e.g., ability estimates, response times). Using
causal inference, we examine (i) how effects of assistance actions vary across
students and (ii) whether CB policies, which leverage such effect
heterogeneity, outperform MAB policies. While our analysis reveals that some
actions for some questions exhibit effect heterogeneity, effect sizes may often
be too small for CB policies to provide significant improvements beyond what
well-optimized MAB policies that deliver the same action to all students
already achieve. We discuss insights gained from deploying data-driven systems
at scale and implications for future refinements. Today, the teaching policies
optimized by our system support thousands of students daily.

</details>


### [198] [Toward using explainable data-driven surrogate models for treating performance-based seismic design as an inverse engineering problem](https://arxiv.org/abs/2508.00286)
*Mohsen Zaker Esteghamati*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.

</details>


### [199] [Invariant Graph Transformer for Out-of-Distribution Generalization](https://arxiv.org/abs/2508.00304)
*Tianyin Liao,Ziwei Zhang,Yufei Sun,Chunyu Hu,Jianxin Li*

Main category: cs.LG

TL;DR: GOODFormer通过结合熵引导子图分解、演化子图编码和不变性学习模块，解决了现有图 Transformer 在分布变化下的泛化能力不足的问题，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的图 Transformer（GTs）主要关注在相同分布的图数据上进行训练和测试，在分布变化的情况下泛化能力不足。图不变性学习旨在捕捉标签下具有分布变化泛化能力的图结构模式，是一个有潜力的解决方案，但如何基于图不变性学习原理设计注意力机制以及位置和结构编码（PSE）仍然是一个挑战。

Method: GOODFormer通过联合优化三个模块来学习通用的图表示：1. 熵引导不变子图分解器，用于分离不变和变化的子图，同时保持注意力函数的清晰度。2. 演化子图位置和结构编码器，用于有效且高效地捕获动态变化的子图的编码信息。3. 不变性学习模块，利用子图节点表示和编码来推导可泛化的图表示。

Result: GOODFormer能够学习可泛化到未见图的图表示。

Conclusion: GOODFormer在基准数据集上的广泛实验证明了该方法在分布变化下的优越性，优于最先进的基线。

Abstract: Graph Transformers (GTs) have demonstrated great effectiveness across various
graph analytical tasks. However, the existing GTs focus on training and testing
graph data originated from the same distribution, but fail to generalize under
distribution shifts. Graph invariant learning, aiming to capture generalizable
graph structural patterns with labels under distribution shifts, is potentially
a promising solution, but how to design attention mechanisms and positional and
structural encodings (PSEs) based on graph invariant learning principles
remains challenging. To solve these challenges, we introduce Graph
Out-Of-Distribution generalized Transformer (GOODFormer), aiming to learn
generalized graph representations by capturing invariant relationships between
predictive graph structures and labels through jointly optimizing three
modules. Specifically, we first develop a GT-based entropy-guided invariant
subgraph disentangler to separate invariant and variant subgraphs while
preserving the sharpness of the attention function. Next, we design an evolving
subgraph positional and structural encoder to effectively and efficiently
capture the encoding information of dynamically changing subgraphs during
training. Finally, we propose an invariant learning module utilizing subgraph
node representations and encodings to derive generalizable graph
representations that can to unseen graphs. We also provide theoretical
justifications for our method. Extensive experiments on benchmark datasets
demonstrate the superiority of our method over state-of-the-art baselines under
distribution shifts.

</details>


### [200] [PnP-DA: Towards Principled Plug-and-Play Integration of Variational Data Assimilation and Generative Models](https://arxiv.org/abs/2508.00325)
*Yongquan Qu,Matthieu Blanke,Sara Shamekh,Pierre Gentine*

Main category: cs.LG

TL;DR: PnP-DA是一种新的数据同化算法，通过结合梯度下降和生成模型，解决了地球系统模型中的误差问题，并在测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决地球系统模型在计算效率和误差最小化之间的挑战，以及传统数据同化方法在处理混沌动力学系统的非高斯误差统计时的局限性。

Method: PnP-DA算法，通过（1）基于梯度下降的分析更新（使用新观测值与背景场之间的马氏距离）和（2）通过条件Wasserstein耦合将预训练生成先验通过单次前向传播进行结合，从而放宽了对统计假设的限制，并利用了历史数据。

Result: 在标准的混沌测试案例中，PnP-DA算法在各种观测稀疏度和噪声水平下，持续降低了预测误差，并且优于经典的变分方法。

Conclusion: 提出了一种名为PnP-DA的即插即用算法，该算法通过结合梯度下降分析更新和预训练生成先验，能够有效减轻地球系统模型中的误差累积，尤其是在处理非高斯误差统计时，优于传统的变分方法。

Abstract: Earth system modeling presents a fundamental challenge in scientific
computing: capturing complex, multiscale nonlinear dynamics in computationally
efficient models while minimizing forecast errors caused by necessary
simplifications. Even the most powerful AI- or physics-based forecast system
suffer from gradual error accumulation. Data assimilation (DA) aims to mitigate
these errors by optimally blending (noisy) observations with prior model
forecasts, but conventional variational methods often assume Gaussian error
statistics that fail to capture the true, non-Gaussian behavior of chaotic
dynamical systems. We propose PnP-DA, a Plug-and-Play algorithm that alternates
(1) a lightweight, gradient-based analysis update (using a Mahalanobis-distance
misfit on new observations) with (2) a single forward pass through a pretrained
generative prior conditioned on the background forecast via a conditional
Wasserstein coupling. This strategy relaxes restrictive statistical assumptions
and leverages rich historical data without requiring an explicit regularization
functional, and it also avoids the need to backpropagate gradients through the
complex neural network that encodes the prior during assimilation cycles.
Experiments on standard chaotic testbeds demonstrate that this strategy
consistently reduces forecast errors across a range of observation sparsities
and noise levels, outperforming classical variational methods.

</details>


### [201] [Embryology of a Language Model](https://arxiv.org/abs/2508.00331)
*George Wang,Garrett Baker,Andrew Gordon,Daniel Murfet*

Main category: cs.LG

TL;DR: 本研究提出一种新方法，使用UMAP分析易感性矩阵，可视化语言模型训练过程中的结构发展，发现了新的神经网络结构。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解语言模型内部计算结构的开发，并充分发掘易感性分析在可视化网络组织方面的潜力。

Method: 提出了一种“胚胎学”方法，将UMAP应用于易感性矩阵，以可视化模型在训练过程中的结构发展。

Result: 可视化结果揭示了一个清晰的“身体计划”，展示了诸如“诱导电路”等已知特征的形成，并发现了一个先前未知的结构，即用于计算空间标记的“间隔鳍”。

Conclusion: 该研究表明，易感性分析不仅可以用于验证，还可以揭示新的机制，为研究复杂神经网络的发育原理提供了一个强大而全面的视角。

Abstract: Understanding how language models develop their internal computational
structure is a central problem in the science of deep learning. While
susceptibilities, drawn from statistical physics, offer a promising analytical
tool, their full potential for visualizing network organization remains
untapped. In this work, we introduce an embryological approach, applying UMAP
to the susceptibility matrix to visualize the model's structural development
over training. Our visualizations reveal the emergence of a clear ``body
plan,'' charting the formation of known features like the induction circuit and
discovering previously unknown structures, such as a ``spacing fin'' dedicated
to counting space tokens. This work demonstrates that susceptibility analysis
can move beyond validation to uncover novel mechanisms, providing a powerful,
holistic lens for studying the developmental principles of complex neural
networks.

</details>


### [202] [BOOD: Boundary-based Out-Of-Distribution Data Generation](https://arxiv.org/abs/2508.00350)
*Qilin Liao,Shuo Yang,Bo Zhao,Ping Luo,Hengshuang Zhao*

Main category: cs.LG

TL;DR: BOOD使用扩散模型在潜在空间中生成OOD特征，并生成异常图像，以提高OOD检测性能，克服了在ID数据边界之外提取特征的挑战。


<details>
  <summary>Details</summary>
Motivation: 从潜在空间中提取有效的特征以增强分布外（OOD）检测性能，尤其是在决策边界之外，这一直是一个挑战，因为难以识别类之间的决策边界。因此，需要一种新的方法来生成高质量的OOD特征。

Method: BOOD首先从ID数据集中学习文本条件潜在特征空间，选择最接近决策边界的ID特征，并通过扰动使其跨越决策边界形成OOD特征。然后，扩散模型将这些合成的OOD特征解码为像素空间中的图像。

Result: BOOD框架在CIFAR-100数据集上实现了29.64%的平均FPR95降低（从40.31%降至10.67%）和7.27%的平均AUROC提升（从90.15%提升至97.42%），显著优于现有技术。

Conclusion: BOOD通过在潜在空间中生成高质量的OOD特征并利用扩散模型生成人类可兼容的异常图像，为合成OOD特征提供了一种更具训练效率的策略，从而实现了ID和OOD数据之间更清晰的区分。实验结果表明，BOOD在CIFAR-100数据集上显著优于现有方法。

Abstract: Harnessing the power of diffusion models to synthesize auxiliary training
data based on latent space features has proven effective in enhancing
out-of-distribution (OOD) detection performance. However, extracting effective
features outside the in-distribution (ID) boundary in latent space remains
challenging due to the difficulty of identifying decision boundaries between
classes. This paper proposes a novel framework called Boundary-based
Out-Of-Distribution data generation (BOOD), which synthesizes high-quality OOD
features and generates human-compatible outlier images using diffusion models.
BOOD first learns a text-conditioned latent feature space from the ID dataset,
selects ID features closest to the decision boundary, and perturbs them to
cross the decision boundary to form OOD features. These synthetic OOD features
are then decoded into images in pixel space by a diffusion model. Compared to
previous works, BOOD provides a more training efficient strategy for
synthesizing informative OOD features, facilitating clearer distinctions
between ID and OOD data. Extensive experimental results on common benchmarks
demonstrate that BOOD surpasses the state-of-the-art method significantly,
achieving a 29.64% decrease in average FPR95 (40.31% vs. 10.67%) and a 7.27%
improvement in average AUROC (90.15% vs. 97.42%) on the CIFAR-100 dataset.

</details>


### [203] [Sheaf Graph Neural Networks via PAC-Bayes Spectral Optimization](https://arxiv.org/abs/2508.00357)
*Yoonhyuk Choi,Jiho Choi,Chong-Kwon Kim*

Main category: cs.LG

TL;DR: SGPC通过创新的theaf GNN架构，解决了异质图上的过平滑问题，并在性能和可扩展性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 图神经网络（GNNs）在异质图上存在过平滑问题，导致节点特征崩溃。现有的theaf神经网络虽然有所缓解，但依赖静态或参数化的theaf结构，限制了泛化和可扩展性。

Method: SGPC（Sheaf GNNs with PAC-Bayes Calibration）是一种新颖的统一架构，它结合了细胞- theaf消息传递与最优传输、方差缩减扩散和PAC-Bayes谱正则化等机制，用于处理异质图上的过平滑问题。

Result: SGPC在九个同质和异质基准测试中取得了优于最先进方法的结果，并提供了认证的置信区间，证明了其在鲁棒半监督节点分类方面的有效性。

Conclusion: SGPC通过结合细胞- theaf消息传递、基于最优传输的提升、方差缩减扩散和PAC-Bayes谱正则化，成功解决了GNN中的平滑问题，特别是在异质图上。该方法在理论上建立了性能界限，并通过端到端训练实现了线性计算复杂度。实验证明，SGPC在九个同质和异质基准测试中优于最先进的谱和theaf GNNs，并为未见节点提供了认证的置信区间。

Abstract: Over-smoothing in Graph Neural Networks (GNNs) causes collapse in distinct
node features, particularly on heterophilic graphs where adjacent nodes often
have dissimilar labels. Although sheaf neural networks partially mitigate this
problem, they typically rely on static or heavily parameterized sheaf
structures that hinder generalization and scalability. Existing sheaf-based
models either predefine restriction maps or introduce excessive complexity, yet
fail to provide rigorous stability guarantees. In this paper, we introduce a
novel scheme called SGPC (Sheaf GNNs with PAC-Bayes Calibration), a unified
architecture that combines cellular-sheaf message passing with several
mechanisms, including optimal transport-based lifting, variance-reduced
diffusion, and PAC-Bayes spectral regularization for robust semi-supervised
node classification. We establish performance bounds theoretically and
demonstrate that the resulting bound-aware objective can be achieved via
end-to-end training in linear computational complexity. Experiments on nine
homophilic and heterophilic benchmarks show that SGPC outperforms
state-of-the-art spectral and sheaf-based GNNs while providing certified
confidence intervals on unseen nodes.

</details>


### [204] [OID-PPO: Optimal Interior Design using Proximal Policy Optimization by Transforming Design Guidelines into Reward Functions](https://arxiv.org/abs/2508.00364)
*Chanyoung Yoon,Sangbong Yoo,Soobin Yim,Chansoo Kim,Yun Jang*

Main category: cs.LG

TL;DR: OID-PPO是一种新的强化学习框架，通过整合专家设计的指南，实现了更优、更高效的室内设计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有室内设计方法在处理非结构化空间布局、高计算需求和依赖专家知识方面存在挑战，基于优化或深度学习的方法计算成本高或受数据稀疏性限制，而强化学习方法则在家具放置的离散性和设计原则的整合方面存在不足。

Method: 提出了一种名为OID-PPO的新型强化学习框架，采用近端策略优化（PPO），该框架将专家定义的 funcional 和 visual 指南整合到结构化奖励函数中，并利用对角高斯策略实现连续灵活的家具布局，以应对部分可观测环境下的潜在环境动态。

Result: 实验结果表明，OID-PPO在各种房间形状和家具配置下，相比最先进的方法，在布局质量和计算效率方面均有显著提升。消融研究进一步证实了结构化指南整合的重要性，并揭示了各个设计约束的独特贡献。

Conclusion: OID-PPO框架在室内设计领域展现出显著优势，在布局质量和计算效率上均优于现有最先进方法，并且通过消融研究验证了结构化指南整合的影响以及各个设计约束的贡献。

Abstract: Designing residential interiors strongly impacts occupant satisfaction but
remains challenging due to unstructured spatial layouts, high computational
demands, and reliance on expert knowledge. Existing methods based on
optimization or deep learning are either computationally expensive or
constrained by data scarcity. Reinforcement learning (RL) approaches often
limit furniture placement to discrete positions and fail to incorporate design
principles adequately. We propose OID-PPO, a novel RL framework for Optimal
Interior Design using Proximal Policy Optimization, which integrates
expert-defined functional and visual guidelines into a structured reward
function. OID-PPO utilizes a diagonal Gaussian policy for continuous and
flexible furniture placement, effectively exploring latent environmental
dynamics under partial observability. Experiments conducted across diverse room
shapes and furniture configurations demonstrate that OID-PPO significantly
outperforms state-of-the-art methods in terms of layout quality and
computational efficiency. Ablation studies further demonstrate the impact of
structured guideline integration and reveal the distinct contributions of
individual design constraints.

</details>


### [205] [Dual Adaptivity: Universal Algorithms for Minimizing the Adaptive Regret of Convex Functions](https://arxiv.org/abs/2508.00392)
*Lijun Zhang,Wenhao Yang,Guanghui Wang,Wei Jiang,Zhi-Hua Zhou*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的元专家框架，用于开发可处理多种凸函数和环境类型的通用在线学习算法，以最小化自适应遗憾。该框架通过动态创建、聚合和利用睡眠专家来适应函数属性和环境变化，并已被证明在理论上是有效的，甚至可以扩展到复合优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有的在线学习算法在处理自适应遗憾时，往往缺乏通用性，只能处理特定类型的凸函数，并且需要预先知道参数，这限制了它们在实际场景中的应用。因此，本研究旨在解决这一局限性，开发能够自动适应函数属性和环境性质的通用算法。

Method: 本研究提出了一种元专家框架，通过动态创建和聚合多个专家，并结合睡眠专家技术来构建通用算法。专家可以通过增加数量或增强能力来实现通用性。该元专家框架旨在实现二阶界限，以适应未知的函数类型，并捕获环境的变化。

Result: 理论分析表明，所提出的算法能够同时最小化多种凸函数类型的自适应遗憾，并且允许函数类型在不同轮次之间切换。此外，该元专家框架已被成功扩展到在线复合优化问题，并开发了一个用于最小化复合函数自适应遗憾的通用算法。

Conclusion: 该研究提出了一个元专家框架，用于开发具有双重适应性的通用算法，能够处理多种凸函数类型（凸函数、指数凹函数或强凸函数）和环境类型（平稳或变化），从而最小化自适应遗憾。该框架通过动态创建和聚合多个专家来实现，并结合了睡眠专家技术以适应环境变化。理论分析表明，所提出的算法能够同时最小化多种凸函数类型的自适应遗憾，并且允许在不同轮次之间切换函数类型。此外，该框架被扩展到在线复合优化问题，并开发了一个用于最小化复合函数自适应遗憾的通用算法。

Abstract: To deal with changing environments, a new performance measure -- adaptive
regret, defined as the maximum static regret over any interval, was proposed in
online learning. Under the setting of online convex optimization, several
algorithms have been successfully developed to minimize the adaptive regret.
However, existing algorithms lack universality in the sense that they can only
handle one type of convex functions and need apriori knowledge of parameters,
which hinders their application in real-world scenarios. To address this
limitation, this paper investigates universal algorithms with dual adaptivity,
which automatically adapt to the property of functions (convex, exponentially
concave, or strongly convex), as well as the nature of environments (stationary
or changing). Specifically, we propose a meta-expert framework for dual
adaptive algorithms, where multiple experts are created dynamically and
aggregated by a meta-algorithm. The meta-algorithm is required to yield a
second-order bound, which can accommodate unknown function types. We further
incorporate the technique of sleeping experts to capture the changing
environments. For the construction of experts, we introduce two strategies
(increasing the number of experts or enhancing the capabilities of experts) to
achieve universality. Theoretical analysis shows that our algorithms are able
to minimize the adaptive regret for multiple types of convex functions
simultaneously, and also allow the type of functions to switch between rounds.
Moreover, we extend our meta-expert framework to online composite optimization,
and develop a universal algorithm for minimizing the adaptive regret of
composite functions.

</details>


### [206] [ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs](https://arxiv.org/abs/2508.00394)
*Antonis Klironomos,Baifan Zhou,Zhipeng Tan,Zhuoxun Zheng,Mohamed H. Gad-Elrab,Heiko Paulheim,Evgeny Kharlamov*

Main category: cs.LG

TL;DR: ExeKGLib是一个用户友好的Python库，利用知识图谱和图形界面，让非机器学习专家也能轻松构建、执行和复用机器学习流水线。


<details>
  <summary>Details</summary>
Motivation: 旨在解决领域专家（尤其是在科学和工程领域）在缺乏机器学习专业知识和培训的情况下，仍然迫切需要基于机器学习的分析工具的问题。

Method: ExeKGLib利用知识图谱来编码机器学习知识，并提供图形用户界面，让不具备机器学习专业知识的用户也能构建机器学习流水线。

Result: 展示了ExeKGLib的可用性和实用性，并通过实际用例进行了说明。

Conclusion: ExeKGLib是一个Python库，它通过利用知识图谱来简化机器学习流水线（ML pipelines）的构建过程，使得没有机器学习专业知识的用户也能轻松创建高质量的ML流水线。该库提高了ML工作流的透明度、可重用性和可执行性。

Abstract: Nowadays machine learning (ML) practitioners have access to numerous ML
libraries available online. Such libraries can be used to create ML pipelines
that consist of a series of steps where each step may invoke up to several ML
libraries that are used for various data-driven analytical tasks. Development
of high-quality ML pipelines is non-trivial; it requires training, ML
expertise, and careful development of each step. At the same time, domain
experts in science and engineering may not possess such ML expertise and
training while they are in pressing need of ML-based analytics. In this paper,
we present our ExeKGLib, a Python library enhanced with a graphical interface
layer that allows users with minimal ML knowledge to build ML pipelines. This
is achieved by relying on knowledge graphs that encode ML knowledge in simple
terms accessible to non-ML experts. ExeKGLib also allows improving the
transparency and reusability of the built ML workflows and ensures that they
are executable. We show the usability and usefulness of ExeKGLib by presenting
real use cases.

</details>


### [207] [Co-Reward: Self-supervised Reinforcement Learning for Large Language Model Reasoning via Contrastive Agreement](https://arxiv.org/abs/2508.00410)
*Zizhuo Zhang,Jianing Zhu,Xinmu Ge,Zihua Zhao,Zhanke Zhou,Xuan Li,Xiao Feng,Jiangchao Yao,Bo Han*

Main category: cs.LG

TL;DR: Co-Reward 是一种新的自监督强化学习框架，它利用对比协议和类比问题来生成奖励信号，解决了现有 RLVR 和自奖励方法的局限性，在 LLM 推理任务上取得了优于基线且可比 GT 标签的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决强化学习与可验证奖励（RLVR）在扩展方面对人类标注标签的依赖性问题，以及现有自奖励信号在处理 LLM 推理时遇到的不可避免的崩溃问题。

Method: Co-Reward 是一个新颖的强化学习框架，它利用对比协议来奖励语义类比问题。它通过为每个训练样本构建一个类似的问题，并对它们进行简单的轮滚投票来合成它们各自的代理标签。然后，通过交叉引用每个问题对的标签来构建奖励，以强制执行跨类比输入的内部推理一致性。

Result: Co-Reward 在 MATH500 上比 Llama-3.2-3B-Instruct 上的 GT 奖励提高了 +6.8%，在多个推理基准和 LLM 系列上取得了优于其他自奖励基线的性能。

Conclusion: Co-Reward 在多个推理基准和 LLM 系列上取得了优于其他自奖励基线、可与甚至超越地面真实（GT）标签奖励的性能，在 MATH500 上比 Llama-3.2-3B-Instruct 上的 GT 奖励提高了 +6.8%。

Abstract: Although reinforcement learning with verifiable rewards (RLVR) shows promise
in improving the reasoning ability of large language models (LLMs), the scaling
up dilemma remains due to the reliance on human annotated labels especially for
complex tasks. Recent alternatives that explore various self-reward signals
exhibit the eliciting potential of LLM reasoning, but suffer from the
non-negligible collapse issue. Inspired by the success of self-supervised
learning, we propose \textit{Co-Reward}, a novel RL framework that leverages
contrastive agreement across semantically analogical questions as a reward
basis. Specifically, we construct a similar question for each training sample
(without labels) and synthesize their individual surrogate labels through a
simple rollout voting, and then the reward is constructed by cross-referring
the labels of each question pair to enforce the internal reasoning consistency
across analogical inputs. Intuitively, such a self-supervised reward-shaping
mechanism increases the difficulty of learning collapse into a trivial
solution, and promotes stable reasoning elicitation and improvement through
expanding the input sample variants. Empirically, Co-Reward achieves superior
performance compared to other self-reward baselines on multiple reasoning
benchmarks and LLM series, and reaches or even surpasses ground-truth (GT)
labeled reward, with improvements of up to $+6.8\%$ on MATH500 over GT reward
on Llama-3.2-3B-Instruct. Our code is publicly available at
https://github.com/tmlr-group/Co-Reward.

</details>


### [208] [Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM Framework for Post-Loan Default Detection](https://arxiv.org/abs/2508.00415)
*Yue Yang,Yuxiang Lin,Ying Zhang,Zihan Su,Chang Chuan Goh,Tangtangfang Fang,Anthony Graham Bellotti,Boon Giin Lee*

Main category: cs.LG

TL;DR: ResE-BiLSTM模型在预测贷后违约方面表现优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 为了提高贷后违约预测的性能，这对于信用风险管理很重要。

Method: 使用ResE-BiLSTM模型，结合滑动窗口技术，并在Freddie Mac美国抵押贷款数据集的44个独立队列上进行评估。

Result: ResE-BiLSTM模型在准确率、精确率、召回率、F1分数和AUC等多个指标上均优于LSTM、BiLSTM、GRU、CNN和RNN等基线模型。

Conclusion: ResE-BiLSTM模型在预测贷后违约方面优于基线模型，具有实际应用价值。

Abstract: Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.

</details>


### [209] [A Conditional GAN for Tabular Data Generation with Probabilistic Sampling of Latent Subspaces](https://arxiv.org/abs/2508.00472)
*Leonidas Akritidis,Panayiotis Bozanis*

Main category: cs.LG

TL;DR: ctdGAN是一种用于解决表格数据集类别不平衡问题的条件GAN。它通过空间划分、概率采样和改进的损失函数，在保留原始数据分布的子空间内生成样本，并有效提高了生成样本的质量和分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有GAN模型在处理表格数据类别不平衡问题时，未能考虑输入样本的向量子空间，导致生成数据的位置任意，并且类别标签的处理方式与其他分类变量相同，降低了条件采样的有效性。

Method: ctdGAN首先执行空间划分步骤为输入样本分配聚类标签。随后，它利用这些标签通过一种新颖的概率采样策略和惩罚聚类及类别预测错误的新损失函数来合成样本。此外，还引入了一种简单的聚类内缩放技术，可以在不影响数据维度的情况下捕捉多个特征模式。

Result: ctdGAN能够生成高保真样本并提高分类准确性。

Conclusion: ctdGAN在14个不平衡数据集上的广泛评估证明了其在生成高保真样本和提高分类准确性方面的优越性。

Abstract: The tabular form constitutes the standard way of representing data in
relational database systems and spreadsheets. But, similarly to other forms,
tabular data suffers from class imbalance, a problem that causes serious
performance degradation in a wide variety of machine learning tasks. One of the
most effective solutions dictates the usage of Generative Adversarial Networks
(GANs) in order to synthesize artificial data instances for the
under-represented classes. Despite their good performance, none of the proposed
GAN models takes into account the vector subspaces of the input samples in the
real data space, leading to data generation in arbitrary locations. Moreover,
the class labels are treated in the same manner as the other categorical
variables during training, so conditional sampling by class is rendered less
effective. To overcome these problems, this study presents ctdGAN, a
conditional GAN for alleviating class imbalance in tabular datasets. Initially,
ctdGAN executes a space partitioning step to assign cluster labels to the input
samples. Subsequently, it utilizes these labels to synthesize samples via a
novel probabilistic sampling strategy and a new loss function that penalizes
both cluster and class mis-predictions. In this way, ctdGAN is trained to
generate samples in subspaces that resemble those of the original data
distribution. We also introduce several other improvements, including a simple,
yet effective cluster-wise scaling technique that captures multiple feature
modes without affecting data dimensionality. The exhaustive evaluation of
ctdGAN with 14 imbalanced datasets demonstrated its superiority in generating
high fidelity samples and improving classification accuracy.

</details>


### [210] [Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration for Text-Attributed Graph Anomaly Detection](https://arxiv.org/abs/2508.00507)
*Yiming Xu,Jiarun Chen,Zhen Peng,Zihan Chen,Qika Lin,Lan Ma,Bin Shi,Bo Dong*

Main category: cs.LG

TL;DR: CoLL框架通过多LLM协作和GNN融合，有效解决了文本属性图异常检测中忽视文本信息和高阶结构信息的问题，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法忽视了文本模态的价值，主要依赖于浅层嵌入技术，可能丢失与异常相关的语义上下文。LLM在语义理解方面具有优势，但直接应用于图异常检测时存在输入长度限制，难以编码高阶结构信息。

Method: CoLL框架结合了多LLM协作进行证据增强生成，并利用集成GNN和门控机制来融合文本特征和证据，同时保留高阶拓扑信息。

Result: CoLL框架在实验中表现出色，平均改进了13.37%的AP（准确率），证明了其在文本属性图异常检测方面的优越性。

Conclusion: CoLL框架的引入为图异常检测提供了新思路，通过结合LLM和GNN的优势，在处理文本属性图时取得了显著的性能提升。

Abstract: The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.

</details>


### [211] [Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and Uni-Modal Contrastive Learning](https://arxiv.org/abs/2508.00513)
*Yiming Xu,Xu Hua,Zhen Peng,Bin Shi,Jiarun Chen,Xingbo Fu,Song Wang,Bo Dong*

Main category: cs.LG

TL;DR: CMUCL是一种用于文本属性图异常检测的新型端到端范式，通过联合建模文本和图结构，并利用跨模态一致性来提高检测性能，同时发布了8个新数据集。


<details>
  <summary>Details</summary>
Motivation: 现有图异常检测方法在处理文本属性图（TAGs）时，通常将文本信息编码为特征，然后依赖图域内的自监督任务进行异常检测。然而，这种文本编码过程与图域的异常检测训练目标是分离的，导致提取的文本特征可能并非专注于与异常检测相关的信息，严重制约了检测能力。因此，如何无缝集成原始文本和图结构以释放跨媒体数据在TAG异常检测中的潜力是一个挑战。

Method: 提出了一种名为CMUCL的新型端到端范式，该范式能够同时对文本和图结构数据进行建模，并通过利用跨模态和单模态多尺度一致性来联合训练文本和图编码器，以发掘与异常检测相关的潜在信息。此外，设计了一种基于不一致性挖掘的异常评分估计器来获得节点特定的异常分数。

Result: CMUCL在文本属性图异常检测方面取得了显著进展，平均准确率（AP）比次优方法提高了11.13%。此外，发布了8个数据集以促进未来的研究。

Conclusion: CMUCL显著提高了文本属性图异常检测的性能，平均准确率（AP）提高了11.13%，克服了现有方法在文本特征提取和异常检测任务之间缺乏联合优化的问题。

Abstract: The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.

</details>


### [212] [Online Nonsubmodular Optimization with Delayed Feedback in the Bandit Setting](https://arxiv.org/abs/2508.00523)
*Sifan Yang,Yuanyu Wan,Lijun Zhang*

Main category: cs.LG

TL;DR: 本研究提出两种算法（DBGD-NF及其扩展）来优化带有延迟反馈的在线非次模问题。新算法相比现有方法，提供了更优的遗憾界，尤其是在延迟变化较大或特定条件下。实验证明了其在结构化稀疏学习中的优越性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在线非次模优化中延迟反馈的问题。现有的研究提出的遗憾界虽然依赖于最大延迟，但对不规则延迟敏感，并且将延迟和带宽反馈的影响耦合在一起。为了解决这些限制，本研究提出了两种新的算法，旨在提供更优的遗憾界。

Method: 本研究提出了两种算法来解决在线非次模优化中的延迟反馈问题。第一种算法DBGD-NF利用单点梯度估计器，并在每次迭代中使用所有可用的估计梯度来更新决策。第二种算法是DBGD-NF的扩展，采用阻塞更新机制来解耦延迟和带宽反馈的联合效应。

Result: DBGD-NF算法实现了$"O(nar{d}^{1/3}T^{2/3})"$的遗憾界，该界与平均延迟$"\bar{d}"$相关。扩展的DBGD-NF算法，采用阻塞更新机制，实现了$"O(n(T^{2/3} + "	ext{sqrt}(dT)))"$的遗憾界。当延迟$"d = "O(T^{1/3})"$时，该遗憾界与无延迟带宽设置下的$"O(nT^{2/3})"$界限相当。此外，在$"d = "o(ar{d}^{2/3}T^{1/3})"$的情况下，该算法比DBGD-NF更具优势。实验结果在结构化稀疏学习任务中验证了这些算法的优越性。

Conclusion: 该研究提出了两种新算法来应对在线非次模优化中的延迟反馈问题。第一种算法DBGD-NF使用单点梯度估计，并将所有可用梯度用于更新决策，实现了与平均延迟相关的$"O(nar{d}^{1/3}T^{2/3})"$的遗憾界。第二种算法扩展了DBGD-NF，引入了阻塞更新机制，将延迟和带宽反馈的影响解耦，达到了$"O(n(T^{2/3} + "	ext{sqrt}(dT)))"$的遗憾界。在延迟d等于$"O(T^{1/3})"$的情况下，该界限与无延迟带宽设置下的$"O(nT^{2/3})"$界限相当，并且在d等于$"o(ar{d}^{2/3}T^{1/3})"$时优于第一种算法。实验结果表明，所提出的方法在结构化稀疏学习方面表现更优。

Abstract: We investigate the online nonsubmodular optimization with delayed feedback in
the bandit setting, where the loss function is $\alpha$-weakly DR-submodular
and $\beta$-weakly DR-supermodular. Previous work has established an
$(\alpha,\beta)$-regret bound of $\mathcal{O}(nd^{1/3}T^{2/3})$, where $n$ is
the dimensionality and $d$ is the maximum delay. However, its regret bound
relies on the maximum delay and is thus sensitive to irregular delays.
Additionally, it couples the effects of delays and bandit feedback as its bound
is the product of the delay term and the $\mathcal{O}(nT^{2/3})$ regret bound
in the bandit setting without delayed feedback. In this paper, we develop two
algorithms to address these limitations, respectively. Firstly, we propose a
novel method, namely DBGD-NF, which employs the one-point gradient estimator
and utilizes all the available estimated gradients in each round to update the
decision. It achieves a better $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ regret
bound, which is relevant to the average delay $\bar{d} =
\frac{1}{T}\sum_{t=1}^T d_t\leq d$. Secondly, we extend DBGD-NF by employing a
blocking update mechanism to decouple the joint effect of the delays and bandit
feedback, which enjoys an $\mathcal{O}(n(T^{2/3} + \sqrt{dT}))$ regret bound.
When $d = \mathcal{O}(T^{1/3})$, our regret bound matches the
$\mathcal{O}(nT^{2/3})$ bound in the bandit setting without delayed feedback.
Compared to our first $\mathcal{O}(n\bar{d}^{1/3}T^{2/3})$ bound, it is more
advantageous when the maximum delay $d = o(\bar{d}^{2/3}T^{1/3})$. Finally, we
conduct experiments on structured sparse learning to demonstrate the
superiority of our methods.

</details>


### [213] [Phase-Locked SNR Band Selection for Weak Mineral Signal Detection in Hyperspectral Imagery](https://arxiv.org/abs/2508.00539)
*Judy X Yang*

Main category: cs.LG

TL;DR: 为解决高光谱成像中弱矿物信号被噪声和冗余波段掩盖的问题，提出一个两阶段集成框架。该框架首先通过信噪比（SNR）和相位锁定阈值技术去除冗余和背景噪声，并使用Savitzky-Golay滤波进行光谱平滑；然后利用KMeans聚类和NNLS解混提取端元光谱，并通过实验验证了该方法能提高混叠精度并增强弱矿物区域的检测能力。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像（HSI）虽然能提供详细的矿产信息，但弱矿物信号常被噪声和冗余波段掩盖，限制了检测性能。为解决此问题，提出此框架。

Method: 提出一个两阶段集成框架：第一阶段计算信噪比（SNR）并应用相位锁定阈值技术去除低SNR的波段，然后使用Savitzky-Golay滤波进行光谱平滑；第二阶段将处理后高光谱数据（HSI）重新引入模型，使用KMeans聚类提取12个端元光谱，并使用非负最小二乘法（NNLS）进行丰度反演。

Result: 通过信噪比（SNR）和相位锁定阈值技术有效去除冗余和背景噪声，并通过Savitzky-Golay滤波进行光谱平滑，保留了精细的光谱特征。随后，使用KMeans聚类和NNLS解混提取了12个端元光谱，并通过余弦相似度和RMSE与实验室光谱进行了量化比较。实验结果表明，该方法提高了混叠精度并增强了弱矿物区域的检测能力。

Conclusion: 该框架通过信噪比（SNR）和相位锁定阈值技术有效去除冗余和背景噪声，并通过Savitzky-Golay滤波进行光谱平滑，保留了精细的光谱特征。随后，使用KMeans聚类和NNLS解混提取了12个端元光谱，并通过余弦相似度和RMSE与实验室光谱进行了量化比较。实验结果表明，该方法提高了混叠精度并增强了弱矿物区域的检测能力。该两步策略为地质高光谱遥感应用中的光谱降维和混叠提供了实用且可复现的解决方案。

Abstract: Hyperspectral imaging offers detailed spectral information for mineral
mapping; however, weak mineral signatures are often masked by noisy and
redundant bands, limiting detection performance. To address this, we propose a
two-stage integrated framework for enhanced mineral detection in the Cuprite
mining district. In the first stage, we compute the signal-to-noise ratio (SNR)
for each spectral band and apply a phase-locked thresholding technique to
discard low-SNR bands, effectively removing redundancy and suppressing
background noise. Savitzky-Golay filtering is then employed for spectral
smoothing, serving a dual role first to stabilize trends during band selection,
and second to preserve fine-grained spectral features during preprocessing. In
the second stage, the refined HSI data is reintroduced into the model, where
KMeans clustering is used to extract 12 endmember spectra (W1 custom), followed
by non negative least squares (NNLS) for abundance unmixing. The resulting
endmembers are quantitatively compared with laboratory spectra (W1 raw) using
cosine similarity and RMSE metrics. Experimental results confirm that our
proposed pipeline improves unmixing accuracy and enhances the detection of weak
mineral zones. This two-pass strategy demonstrates a practical and reproducible
solution for spectral dimensionality reduction and unmixing in geological HSI
applications.

</details>


### [214] [The Role of Active Learning in Modern Machine Learning](https://arxiv.org/abs/2508.00586)
*Thorben Werner,Lars Schmidt-Thieme,Vijaya Krishna Yalavarthi*

Main category: cs.LG

TL;DR: 与数据增强（DA）和半监督学习（SSL）相比，主动学习（AL）在少样本场景下的效率最低。然而，当与DA和SSL结合使用时，AL仍然可以提高性能，因此应作为最终的性能优化步骤。


<details>
  <summary>Details</summary>
Motivation: 主动学习（AL）很少应用于其自身的科学文献之外的领域，原因在于其高计算成本以及在标记样本很少的情况下产生的相对较小的提升。

Method: 研究了数据增强（DA）、半监督学习（SSL）和主动学习（AL）这几种方法在少样本场景下的影响。

Result: AL是解决少样本问题的效率最低的方法，仅比随机抽样产生1-4%的提升，而DA和SSL方法与随机抽样结合使用可产生高达60%的提升。然而，当AL与强大的DA和SSL技术结合时，仍能提供改进。

Conclusion: 在应用了适当的数据增强（DA）和半监督学习（SSL）方法后，主动学习（AL）仍然可以提供改进，因此AL不应被视为解决缺失标签的方法，而应作为在数据上榨取最后一丝性能的最终构建块。

Abstract: Even though Active Learning (AL) is widely studied, it is rarely applied in
contexts outside its own scientific literature. We posit that the reason for
this is AL's high computational cost coupled with the comparatively small lifts
it is typically able to generate in scenarios with few labeled points. In this
work we study the impact of different methods to combat this low data scenario,
namely data augmentation (DA), semi-supervised learning (SSL) and AL. We find
that AL is by far the least efficient method of solving the low data problem,
generating a lift of only 1-4\% over random sampling, while DA and SSL methods
can generate up to 60\% lift in combination with random sampling. However, when
AL is combined with strong DA and SSL techniques, it surprisingly is still able
to provide improvements. Based on these results, we frame AL not as a method to
combat missing labels, but as the final building block to squeeze the last bits
of performance out of data after appropriate DA and SSL methods as been
applied.

</details>


### [215] [Similarity-Based Self-Construct Graph Model for Predicting Patient Criticalness Using Graph Neural Networks and EHR Data](https://arxiv.org/abs/2508.00615)
*Mukesh Kumar Sahu,Pinki Roy*

Main category: cs.LG

TL;DR: 我们提出了一个基于图的模型，可以通过分析电子健康记录来更准确地预测ICU患者的死亡风险。


<details>
  <summary>Details</summary>
Motivation: 为了在重症监护中进行早期干预，准确预测重症监护患者（例如ICU死亡风险）的关键性至关重要。然而，传统的模型通常将每个患者隔离处理，并且难以利用电子健康记录（EHR）中的关系结构。

Method: 提出了一种相似性图模型（SBSCGM）和混合图模型（HybridGraphMedGNN）来动态构建患者相似性图并预测患者死亡率和连续危重程度得分。

Result: 在 MIMIC-III 数据集上对 6000 例 ICU 住院病例进行的实验中，我们的模型取得了最先进的性能（AUC-ROC 0.94），优于基线分类器和单类型 GNN 模型。我们还证明了精确率/召回率的提高，并表明注意力机制为模型预测提供了可解释的见解。

Conclusion: 该模型为危重监护的风险预测提供了一个可扩展且可解释的解决方案，有潜力支持临床医生在实际ICU部署。

Abstract: Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.

</details>


### [216] [IAMAP: Unlocking Deep Learning in QGIS for non-coders and limited computing resources](https://arxiv.org/abs/2508.00627)
*Paul Tresson,Pierre Le Coz,Hadrien Tulet,Anthony Malkassian,Maxime Réjou Méchain*

Main category: cs.LG

TL;DR: IAMAP 是一个 QGIS 插件，让非 AI 专家也能轻松使用深度学习进行遥感图像分析，无需大量数据或强大计算能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习在遥感领域的应用受限于专家知识、大规模数据集和高计算资源的问题，IAMAP 插件被开发出来，旨在降低使用门槛，实现遥感图像分析的民主化。

Method: IAMAP 是一个用户友好的 QGIS 插件，它利用自监督学习策略和基础模型来提取遥感图像特征，并提供降维、聚类、特征相似图生成以及监督机器学习模型校准与验证等功能，用户无需 GPU 或大规模数据集即可使用。

Result: IAMAP 插件使用户能够提取深度学习特征、进行降维、聚类、生成特征相似图并校准监督机器学习模型，而无需 GPU 或大量标注数据，从而使非 AI 专家也能利用先进的深度学习技术。

Conclusion: IAMAP 插件通过利用自监督学习和基础模型，解决了遥感图像分析中对专业知识、大规模数据集和计算资源的需求，使得非 AI 专家也能使用先进的深度学习方法，促进了计算高效和节能的深度学习方法的普及。

Abstract: Remote sensing has entered a new era with the rapid development of artificial
intelligence approaches. However, the implementation of deep learning has
largely remained restricted to specialists and has been impractical because it
often requires (i) large reference datasets for model training and validation;
(ii) substantial computing resources; and (iii) strong coding skills. Here, we
introduce IAMAP, a user-friendly QGIS plugin that addresses these three
challenges in an easy yet flexible way. IAMAP builds on recent advancements in
self-supervised learning strategies, which now provide robust feature
extractors, often referred to as foundation models. These generalist models can
often be reliably used in few-shot or zero-shot scenarios (i.e., with little to
no fine-tuning). IAMAP's interface allows users to streamline several key steps
in remote sensing image analysis: (i) extracting image features using a wide
range of deep learning architectures; (ii) reducing dimensionality with
built-in algorithms; (iii) performing clustering on features or their reduced
representations; (iv) generating feature similarity maps; and (v) calibrating
and validating supervised machine learning models for prediction. By enabling
non-AI specialists to leverage the high-quality features provided by recent
deep learning approaches without requiring GPU capacity or extensive reference
datasets, IAMAP contributes to the democratization of computationally efficient
and energy-conscious deep learning methods.

</details>


### [217] [Separated-Variable Spectral Neural Networks: A Physics-Informed Learning Approach for High-Frequency PDEs](https://arxiv.org/abs/2508.00628)
*Xiong Xiong,Zhuo Zhang,Rongchun Hu,Chen Gao,Zichen Deng*

Main category: cs.LG

TL;DR: SV-SNN通过变量分离和自适应谱方法克服了PINNs的光谱偏差问题，在高频PDE求解方面取得了显著的精度和效率提升。


<details>
  <summary>Details</summary>
Motivation: 传统的物理信息神经网络（PINNs）在高频成分捕获方面存在光谱偏差问题，限制了其在求解高频振荡偏微分方程（PDEs）方面的能力。

Method: SV-SNN框架通过以下创新来解决高频成分捕获问题：1.将多元函数分解为单变量函数乘积，实现独立时空网络；2.引入具有可学习频率参数的自适应傅立叶谱特征以捕获高频；3.基于奇异值分解的理论框架量化谱偏差。

Result: 在热方程、亥姆霍兹方程、泊松方程和纳维-斯托克斯方程等基准问题上的评估表明，SV-SNN的准确性提高了1-3个数量级，同时参数数量减少了90%以上，训练时间减少了60%。

Conclusion: SV-SNN通过将变量分离与自适应谱方法相结合，有效解决了神经PDE求解中的谱偏差问题。

Abstract: Solving high-frequency oscillatory partial differential equations (PDEs) is a
critical challenge in scientific computing, with applications in fluid
mechanics, quantum mechanics, and electromagnetic wave propagation. Traditional
physics-informed neural networks (PINNs) suffer from spectral bias, limiting
their ability to capture high-frequency solution components. We introduce
Separated-Variable Spectral Neural Networks (SV-SNN), a novel framework that
addresses these limitations by integrating separation of variables with
adaptive spectral methods. Our approach features three key innovations: (1)
decomposition of multivariate functions into univariate function products,
enabling independent spatial and temporal networks; (2) adaptive Fourier
spectral features with learnable frequency parameters for high-frequency
capture; and (3) theoretical framework based on singular value decomposition to
quantify spectral bias. Comprehensive evaluation on benchmark problems
including Heat equation, Helmholtz equation, Poisson equations and
Navier-Stokes equations demonstrates that SV-SNN achieves 1-3 orders of
magnitude improvement in accuracy while reducing parameter count by over 90\%
and training time by 60\%. These results establish SV-SNN as an effective
solution to the spectral bias problem in neural PDE solving. The implementation
will be made publicly available upon acceptance at
https://github.com/xgxgnpu/SV-SNN.

</details>


### [218] [KFS: KAN based adaptive Frequency Selection learning architecture for long term time series forecasting](https://arxiv.org/abs/2508.00635)
*Changning Wu,Gao Wu,Rongyao Cai,Yong Liu,Kexin Zhang*

Main category: cs.LG

TL;DR: The paper introduces KFS, a KAN-based architecture for time series forecasting that addresses noise and representation issues by adaptively selecting dominant frequencies and aligning temporal features across scales, achieving state-of-the-art results.


<details>
  <summary>Details</summary>
Motivation: Real-world time series exhibit noise interference across different scales, and the heterogeneous information distribution among frequency components at varying scales leads to suboptimal multi-scale representation. This motivates the development of a new architecture to address these challenges.

Method: This paper proposes a KAN based adaptive Frequency Selection learning architecture (KFS) to address challenges in multi-scale decomposition architectures for time series forecasting. The framework includes a FreK module for dominant frequency selection based on energy distribution and KAN for sophisticated pattern representation. Timestamp embedding alignment synchronizes temporal representations across scales, and a feature mixing module fuses scale-specific patterns with aligned temporal features.

Result: The proposed KFS architecture, through its FreK module and KAN, effectively tackles prediction challenges arising from cross-scale noise interference and complex pattern modeling, leading to state-of-the-art performance.

Conclusion: KT achieves state-of-the-art performance as a simple yet effective architecture across multiple real-world time series datasets.

Abstract: Multi-scale decomposition architectures have emerged as predominant
methodologies in time series forecasting. However, real-world time series
exhibit noise interference across different scales, while heterogeneous
information distribution among frequency components at varying scales leads to
suboptimal multi-scale representation. Inspired by Kolmogorov-Arnold Networks
(KAN) and Parseval's theorem, we propose a KAN based adaptive Frequency
Selection learning architecture (KFS) to address these challenges. This
framework tackles prediction challenges stemming from cross-scale noise
interference and complex pattern modeling through its FreK module, which
performs energy-distribution-based dominant frequency selection in the spectral
domain. Simultaneously, KAN enables sophisticated pattern representation while
timestamp embedding alignment synchronizes temporal representations across
scales. The feature mixing module then fuses scale-specific patterns with
aligned temporal features. Extensive experiments across multiple real-world
time series datasets demonstrate that KT achieves state-of-the-art performance
as a simple yet effective architecture.

</details>


### [219] [Reinforcement Learning for Decision-Level Interception Prioritization in Drone Swarm Defense](https://arxiv.org/abs/2508.00641)
*Alessandro Palmas*

Main category: cs.LG

TL;DR: 强化学习在防御无人机群攻击方面表现出色，能优化拦截策略，降低损失。


<details>
  <summary>Details</summary>
Motivation: 低成本神风无人机群的威胁日益增长，对现代防御系统提出了快速、战略决策的严峻挑战，需要在多个拦截器和高价值目标区域之间进行优先排序。

Method: 本文提出了一种基于强化学习的方法，在一个高保真仿真环境中训练一个决策级别的强化学习智能体。该智能体在一个离散动作空间中操作，根据观察到的状态特征（如位置、类别和效应器状态）为每个效应器选择要交战的无人机。

Result: 在数百个模拟攻击场景中，基于强化学习的策略相比于手工规则基线，能够持续实现更低的平均损害和更高的防御效率，有效保护了关键区域。

Conclusion: 本研究展示了强化学习在应对低成本神风无人机群威胁方面的实际优势，通过高保真仿真环境训练的强化学习智能体能够有效协调多个拦截器，实现最优拦截优先级排序，从而显著降低平均损害并提高关键区域的防御效率。强化学习可作为防御架构中的战略层，增强韧性且不干扰现有控制系统。

Abstract: The growing threat of low-cost kamikaze drone swarms poses a critical
challenge to modern defense systems demanding rapid and strategic
decision-making to prioritize interceptions across multiple effectors and
high-value target zones. In this work, we present a case study demonstrating
the practical advantages of reinforcement learning in addressing this
challenge. We introduce a high-fidelity simulation environment that captures
realistic operational constraints, within which a decision-level reinforcement
learning agent learns to coordinate multiple effectors for optimal interception
prioritization. Operating in a discrete action space, the agent selects which
drone to engage per effector based on observed state features such as
positions, classes, and effector status. We evaluate the learned policy against
a handcrafted rule-based baseline across hundreds of simulated attack
scenarios. The reinforcement learning based policy consistently achieves lower
average damage and higher defensive efficiency in protecting critical zones.
This case study highlights the potential of reinforcement learning as a
strategic layer within defense architectures, enhancing resilience without
displacing existing control systems. All code and simulation assets are
publicly released for full reproducibility, and a video demonstration
illustrates the policy's qualitative behavior.

</details>


### [220] [Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators](https://arxiv.org/abs/2508.00643)
*Albert Matveev,Sanmitra Ghosh,Aamal Hussain,James-Michael Leahy,Michalis Michaelides*

Main category: cs.LG

TL;DR: DINOZAUR是一种新的神经算子，解决了FNO的可扩展性和不确定性量化问题，性能优越且资源消耗低。


<details>
  <summary>Details</summary>
Motivation: FNOs在可扩展性方面存在挑战（过度参数化），并且不能原生支持不确定性量化，而这是科学和工程应用中的关键要求。

Method: DINOZAUR用一种与维度无关的扩散乘数取代了FNO中的密集张量乘数，该乘数每个通道只有一个可学习的时间参数。通过定义时间参数的先验，将DINOZAUR作为贝叶斯神经算子。

Result: DINOZAUR在多个PDE基准测试中取得了具有竞争力或更优的性能，同时提供了高效的不确定性量化。

Conclusion: DINOZAUR是一种基于扩散的神经算子参数化方法，通过引入具有可学习时间参数的降维扩散乘数，显著减少了参数量和内存占用，同时保持了预测性能。该方法通过定义时间参数的先验，实现了贝叶斯神经算子，能够生成具有空间相关性的输出和校准的不确定性估计。在多个PDE基准测试中，DINOZAUR的性能具有竞争力甚至更优，并能提供高效的不确定性量化。

Abstract: Operator learning is a powerful paradigm for solving partial differential
equations, with Fourier Neural Operators serving as a widely adopted
foundation. However, FNOs face significant scalability challenges due to
overparameterization and offer no native uncertainty quantification -- a key
requirement for reliable scientific and engineering applications. Instead,
neural operators rely on post hoc UQ methods that ignore geometric inductive
biases. In this work, we introduce DINOZAUR: a diffusion-based neural operator
parametrization with uncertainty quantification. Inspired by the structure of
the heat kernel, DINOZAUR replaces the dense tensor multiplier in FNOs with a
dimensionality-independent diffusion multiplier that has a single learnable
time parameter per channel, drastically reducing parameter count and memory
footprint without compromising predictive performance. By defining priors over
those time parameters, we cast DINOZAUR as a Bayesian neural operator to yield
spatially correlated outputs and calibrated uncertainty estimates. Our method
achieves competitive or superior performance across several PDE benchmarks
while providing efficient uncertainty quantification.

</details>


### [221] [TrajSurv: Learning Continuous Latent Trajectories from Electronic Health Records for Trustworthy Survival Prediction](https://arxiv.org/abs/2508.00657)
*Sihang Zeng,Lucas Jing Liu,Jun Wen,Meliha Yetisgen,Ruth Etzioni,Gang Luo*

Main category: cs.LG

TL;DR: TrajSurv是一个利用神经控制微分方程和对比学习从纵向EHR数据中学习连续潜在轨迹的模型，用于提高生存预测的准确性和透明度。


<details>
  <summary>Details</summary>
Motivation: 为了解决从纵向电子健康记录（EHR）数据中准确模拟患者连续临床进展的挑战，以及透明地将该进展与生存结果联系起来的难题，提出了TrajSurv模型。

Method: TrajSurv模型，采用神经控制微分方程（NCDE）从不规则采样的数据中提取连续时间潜在状态，形成连续潜在轨迹。通过时间感知对比学习方法将潜在状态空间与患者状态空间对齐，确保潜在轨迹反映临床进展。为了透明地将临床进展与生存结果联系起来，TrajSurv采用两步分解和解释过程：首先，利用学习到的向量场解释临床特征的变化如何转化为潜在轨迹的演变；其次，对潜在轨迹进行聚类，以识别与不同生存结果相关的关键临床进展模式。

Result: TrajSurv在MIMIC-III和eICU两个真实世界医学数据集上进行了评估，结果显示其具有与现有深度学习方法相当的准确性，并且在透明度方面表现更优。

Conclusion: TrajSurv在MIMIC-III和eICU两个真实世界医学数据集上进行了评估，结果显示其具有与现有深度学习方法相当的准确性，并且在透明度方面表现更优。

Abstract: Trustworthy survival prediction is essential for clinical decision making.
Longitudinal electronic health records (EHRs) provide a uniquely powerful
opportunity for the prediction. However, it is challenging to accurately model
the continuous clinical progression of patients underlying the irregularly
sampled clinical features and to transparently link the progression to survival
outcomes. To address these challenges, we develop TrajSurv, a model that learns
continuous latent trajectories from longitudinal EHR data for trustworthy
survival prediction. TrajSurv employs a neural controlled differential equation
(NCDE) to extract continuous-time latent states from the irregularly sampled
data, forming continuous latent trajectories. To ensure the latent trajectories
reflect the clinical progression, TrajSurv aligns the latent state space with
patient state space through a time-aware contrastive learning approach. To
transparently link clinical progression to the survival outcome, TrajSurv uses
latent trajectories in a two-step divide-and-conquer interpretation process.
First, it explains how the changes in clinical features translate into the
latent trajectory's evolution using a learned vector field. Second, it clusters
these latent trajectories to identify key clinical progression patterns
associated with different survival outcomes. Evaluations on two real-world
medical datasets, MIMIC-III and eICU, show TrajSurv's competitive accuracy and
superior transparency over existing deep learning methods.

</details>


### [222] [DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic Prototypes](https://arxiv.org/abs/2508.00664)
*Jialun Zheng,Jie Liu,Jiannong Cao,Xiao Wang,Hanchen Yang,Yankai Chen,Philip S. Yu*

Main category: cs.LG

TL;DR: DP-DGAD是一种用于动态图异常检测的模型，通过动态原型捕捉演化的域特定和域不可知模式，并在跨领域数据上表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决现有通用图异常检测模型在动态图和新领域缺乏标签数据方面的挑战，同时捕捉演化中的域特定和域不可知异常模式。

Method: DP-DGAD模型，通过提取动态原型（演化的正常和异常模式表示）并存储在内存缓冲区中，然后使用异常评分器将输入数据与动态原型进行比较来标记异常。最后，采用基于置信度的伪标签进行自监督适应。

Result: DP-DGAD在十个跨不同领域的真实世界数据集上实现了最先进的性能。

Conclusion: DP-DGAD通过动态原型在跨10个真实世界数据集的实验中展现了最先进的性能，有效地捕捉了动态图中的演化中的域特定和域不可知异常模式。

Abstract: Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.

</details>


### [223] [Classification of Psychiatry Clinical Notes by Diagnosis: A Deep Learning and Machine Learning Approach](https://arxiv.org/abs/2508.00695)
*Sergio Rubio-Martín,María Teresa García-Ordás,Antonio Serrano-García,Clara Margarita Franch-Pato,Arturo Crespo-Álvaro,José Alberto Benítez-Andrades*

Main category: cs.LG

TL;DR: 本研究评估了人工智能模型在精神健康诊断中的应用，发现超参数调整比过采样技术更能提高模型准确性。决策树、极限梯度提升、DistilBERT 和 SciBERT 模型均达到 96% 的准确率。


<details>
  <summary>Details</summary>
Motivation: 临床笔记分类对于医疗保健至关重要，特别是对于焦虑和适应障碍等心理健康状况。本研究旨在比较各种人工智能模型在对临床笔记进行分类时的性能，并评估过采样策略和超参数调整对模型性能的影响。

Method: 本研究比较了传统机器学习模型（随机森林、支持向量机、K近邻、决策树和极限梯度提升）和深度学习模型（DistilBERT 和 SciBERT）在将临床笔记分类到焦虑和适应障碍诊断类别中的性能。此外，还实施了三种过采样策略（无过采样、随机过采样和合成少数过采样技术（SMOTE））来评估它们对模型性能的影响，并进行了超参数调整以优化模型准确性。

Result: 结果表明，过采样技术对模型性能的影响很小，只有 SMOTE 对 BERT 类模型有积极影响。然而，超参数优化显著提高了所有模型的准确性。决策树和极限梯度提升模型的准确性最高，达到 96%，DistilBERT 和 SciBERT 模型也达到了 96% 的准确性。

Conclusion: 超参数调整对于最大化模型性能至关重要，与数据平衡方法相比，它对模型性能的影响更大。

Abstract: The classification of clinical notes into specific diagnostic categories is
critical in healthcare, especially for mental health conditions like Anxiety
and Adjustment Disorder. In this study, we compare the performance of various
Artificial Intelligence models, including both traditional Machine Learning
approaches (Random Forest, Support Vector Machine, K-nearest neighbors,
Decision Tree, and eXtreme Gradient Boost) and Deep Learning models (DistilBERT
and SciBERT), to classify clinical notes into these two diagnoses.
Additionally, we implemented three oversampling strategies: No Oversampling,
Random Oversampling, and Synthetic Minority Oversampling Technique (SMOTE), to
assess their impact on model performance. Hyperparameter tuning was also
applied to optimize model accuracy. Our results indicate that oversampling
techniques had minimal impact on model performance overall. The only exception
was SMOTE, which showed a positive effect specifically with BERT-based models.
However, hyperparameter optimization significantly improved accuracy across the
models, enhancing their ability to generalize and perform on the dataset. The
Decision Tree and eXtreme Gradient Boost models achieved the highest accuracy
among machine learning approaches, both reaching 96%, while the DistilBERT and
SciBERT models also attained 96% accuracy in the deep learning category. These
findings underscore the importance of hyperparameter tuning in maximizing model
performance. This study contributes to the ongoing research on AI-assisted
diagnostic tools in mental health by providing insights into the efficacy of
different model architectures and data balancing methods.

</details>


### [224] [Learning Network Dismantling without Handcrafted Inputs](https://arxiv.org/abs/2508.00706)
*Haozhe Tian,Pietro Ferraro,Robert Shorten,Mahdi Jalili,Homayoun Hamedmoghadam*

Main category: cs.LG

TL;DR: MIND是一个新的图神经网络模型，它不需要手工特征，并且在网络拆卸任务上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决消息传递图神经网络在解决网络科学问题时需要手工特征输入的问题，这会增加计算成本并引入偏差。

Method: 提出了一种新的消息传递图神经网络框架，该框架利用注意力机制和消息传递剖析，并通过算法生成多样化的合成网络数据集来消除对手工特征的需求。

Result: 该模型在仅在合成网络上训练的情况下，能够很好地泛化到大规模的真实网络，并且在网络拆卸任务上取得了优于最先进方法的性能。

Conclusion: 该模型在网络拆卸方面表现优于最先进的方法，并且可以应用于其他复杂网络问题。

Abstract: The application of message-passing Graph Neural Networks has been a
breakthrough for important network science problems. However, the competitive
performance often relies on using handcrafted structural features as inputs,
which increases computational cost and introduces bias into the otherwise
purely data-driven network representations. Here, we eliminate the need for
handcrafted features by introducing an attention mechanism and utilizing
message-iteration profiles, in addition to an effective algorithmic approach to
generate a structurally diverse training set of small synthetic networks.
Thereby, we build an expressive message-passing framework and use it to
efficiently solve the NP-hard problem of Network Dismantling, virtually
equivalent to vital node identification, with significant real-world
applications. Trained solely on diversified synthetic networks, our proposed
model -- MIND: Message Iteration Network Dismantler -- generalizes to large,
unseen real networks with millions of nodes, outperforming state-of-the-art
network dismantling methods. Increased efficiency and generalizability of the
proposed model can be leveraged beyond dismantling in a range of complex
network problems.

</details>


### [225] [Efficient Solution and Learning of Robust Factored MDPs](https://arxiv.org/abs/2508.00707)
*Yannik Schnitzer,Alessandro Abate,David Parker*

Main category: cs.LG

TL;DR: 提出因子分解方法解决r-MDPs，提高样本效率和策略性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决从交互中学习r-MDPs需要大量样本的效率问题，并利用模型不确定性在系统组件间的独立性。

Method: 提出基于因子分解的状态空间表示方法来解决和学习鲁棒马尔可夫决策过程（r-MDPs），并将策略合成的优化问题重构为可行的线性规划问题。在此基础上，还提出了直接学习因子分解模型表示的方法。

Result: 实验结果表明，利用因子分解结构可以带来样本效率上的维度增益，生成更有效的鲁棒策略，并提供比最先进方法更严格的性能保证。

Conclusion: 本研究提出的基于因子分解的状态空间表示方法，利用了模型不确定性在系统组件间的独立性，可以显著提高样本效率，并生成比现有方法更有效的鲁棒策略，同时具有更严格的性能保证。

Abstract: Robust Markov decision processes (r-MDPs) extend MDPs by explicitly modelling
epistemic uncertainty about transition dynamics. Learning r-MDPs from
interactions with an unknown environment enables the synthesis of robust
policies with provable (PAC) guarantees on performance, but this can require a
large number of sample interactions. We propose novel methods for solving and
learning r-MDPs based on factored state-space representations that leverage the
independence between model uncertainty across system components. Although
policy synthesis for factored r-MDPs leads to hard, non-convex optimisation
problems, we show how to reformulate these into tractable linear programs.
Building on these, we also propose methods to learn factored model
representations directly. Our experimental results show that exploiting
factored structure can yield dimensional gains in sample efficiency, producing
more effective robust policies with tighter performance guarantees than
state-of-the-art methods.

</details>


### [226] [JSON-Bag: A generic game trajectory representation](https://arxiv.org/abs/2508.00712)
*Dien Nguyen,Diego Perez-Liebana,Simon Lucas*

Main category: cs.LG

TL;DR: JSON-Bag 使用分词和 JSD 来表示游戏轨迹，并在游戏分类任务中表现出色，优于手工特征，同时还能自动提取特征。


<details>
  <summary>Details</summary>
Motivation: 为了提供一种通用的方法来表示和分析游戏轨迹，并评估其在不同游戏和分类任务上的有效性。

Method: 提出了一种名为 JSON-Bag-of-Tokens (JSON-Bag) 的方法，通过对游戏轨迹的 JSON 描述进行分词来表示它们，并使用 Jensen-Shannon 距离 (JSD) 作为距离度量。结合原型最近邻搜索 (P-NNS) 来评估 JSON-Bag 与 JSD 在六种桌面游戏上的有效性，用于对游戏轨迹分类任务。

Result: JSON-Bag 在大多数任务中优于基线方法，并且在 N 样本分类任务中显示出样本效率。它还能通过随机森林自动提取特征，提高准确性。JSD 与 agent 策略之间的距离高度相关。

Conclusion: JSON-Bag 方法在大多数任务中优于手工特征基线，并且在 N 样本分类中表现出样本效率。此外，JSON-Bag 通过将 token 视为用于随机森林的单独特征，提高了在表现不佳的任务上的准确性。最后，JSON-Bag 产生的 agent 类别原型之间的 JSD 与 agent 策略之间的距离高度相关。

Abstract: We introduce JSON Bag-of-Tokens model (JSON-Bag) as a method to generically
represent game trajectories by tokenizing their JSON descriptions and apply
Jensen-Shannon distance (JSD) as distance metric for them. Using a
prototype-based nearest-neighbor search (P-NNS), we evaluate the validity of
JSON-Bag with JSD on six tabletop games -- \textit{7 Wonders},
\textit{Dominion}, \textit{Sea Salt and Paper}, \textit{Can't Stop},
\textit{Connect4}, \textit{Dots and boxes} -- each over three game trajectory
classification tasks: classifying the playing agents, game parameters, or game
seeds that were used to generate the trajectories.
  Our approach outperforms a baseline using hand-crafted features in the
majority of tasks. Evaluating on N-shot classification suggests using JSON-Bag
prototype to represent game trajectory classes is also sample efficient.
Additionally, we demonstrate JSON-Bag ability for automatic feature extraction
by treating tokens as individual features to be used in Random Forest to solve
the tasks above, which significantly improves accuracy on underperforming
tasks. Finally, we show that, across all six games, the JSD between JSON-Bag
prototypes of agent classes highly correlates with the distances between
agents' policies.

</details>


### [227] [Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation Learning](https://arxiv.org/abs/2508.00716)
*Yingxu Wang,Mengzhu Wang,Zhichao Huang,Suyu Liu*

Main category: cs.LG

TL;DR: NeGPR是一种新颖的框架，用于处理带噪声标签的图域自适应。它通过双分支预训练、嵌套伪标签细化和噪声感知正则化来提高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的图域自适应（GDA）方法大多依赖于干净的源标签假设，但在现实场景中，标签噪声普遍存在，严重影响了特征对齐和域迁移下的自适应性能。

Method: NeGPR首先通过在特征空间中强制执行邻域一致性来预训练语义和拓扑双分支，从而减少噪声监督的影响。然后，通过嵌套细化机制，一个分支选择高置信度目标样本来指导另一个分支的适应，实现渐进式跨域学习。最后，通过噪声感知正则化策略来减轻伪标签噪声的影响，并增强适应过程的鲁棒性。

Result: NeGPR框架在存在严重标签噪声的情况下，持续优于最先进的方法，在准确性方面提高了12.7%。

Conclusion: NeGPR框架在存在严重标签噪声的情况下，持续优于最先进的方法，在准确性方面提高了12.7%。

Abstract: Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.

</details>


### [228] [Democratizing Tabular Data Access with an Open$\unicode{x2013}$Source Synthetic$\unicode{x2013}$Data SDK](https://arxiv.org/abs/2508.00718)
*Ivona Krchova,Mariana Vargas Vieyra,Mario Scriminaci,Andrey Sidorenko*

Main category: cs.LG

TL;DR: MOSTLY AI SDK是一个开源的Python工具包，用于生成高质量的表格合成数据。它具有差分隐私、公平性感知和自动化质量保证功能，支持多种数据类型和复杂数据集，并且易于使用。该SDK已被广泛采用，以解决现实世界中的数据访问问题。


<details>
  <summary>Details</summary>
Motivation: 机器学习的发展离不开高质量的数据，但隐私、所有权和道德伦理问题限制了数据的可访问性。合成数据作为一种解决方案，可以在不泄露敏感信息的情况下实现数据的广泛安全使用。

Method: 本研究提出了MOSTLY AI合成数据软件开发工具包（SDK），一个开源工具包，专门用于合成高质量的表格数据。该SDK集成了差分隐私保证、公平性感知数据生成以及自动化的质量保证等功能，并通过Python接口提供。

Result: 该SDK利用TabularARGN自回归框架，支持多种数据类型以及复杂的多表和序列数据集，在速度和易用性方面取得了显著改进，并实现了具有竞争力的性能。

Conclusion: 该SDK通过集成差分隐私、公平性感知生成和自动化质量保证等功能，为合成高质量表格数据提供了灵活易用的解决方案，并已在云服务和本地部署中得到广泛应用，有效解决了现实世界中的数据瓶颈问题。

Abstract: Machine learning development critically depends on access to high-quality
data. However, increasing restrictions due to privacy, proprietary interests,
and ethical concerns have created significant barriers to data accessibility.
Synthetic data offers a viable solution by enabling safe, broad data usage
without compromising sensitive information. This paper presents the MOSTLY AI
Synthetic Data Software Development Kit (SDK), an open-source toolkit designed
specifically for synthesizing high-quality tabular data. The SDK integrates
robust features such as differential privacy guarantees, fairness-aware data
generation, and automated quality assurance into a flexible and accessible
Python interface. Leveraging the TabularARGN autoregressive framework, the SDK
supports diverse data types and complex multi-table and sequential datasets,
delivering competitive performance with notable improvements in speed and
usability. Currently deployed both as a cloud service and locally installable
software, the SDK has seen rapid adoption, highlighting its practicality in
addressing real-world data bottlenecks and promoting widespread data
democratization.

</details>


### [229] [Adaptive Machine Learning-Driven Multi-Fidelity Stratified Sampling for Failure Analysis of Nonlinear Stochastic Systems](https://arxiv.org/abs/2508.00734)
*Liuyun Xu,Seymour M. J. Spence*

Main category: cs.LG

TL;DR: 本研究提出了一种结合多精度分层采样和自适应机器学习元模型的新方法，用于高效估计稀有事件的失效概率，尤其适用于复杂的非线性有限元分析。该方法通过训练深度学习元模型作为低精度模型，并结合自适应训练策略，在保证精度的同时大幅减少了计算量，在实际工程案例中取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方差缩减技术在稀有事件分析中需要大量模型评估才能估计小失效概率的挑战，特别是在复杂、非线性的有限元建模环境和随机激励下，本研究旨在提出一种更有效的解决方案。

Method: 提出了一种多精度分层采样方案，该方案结合了自适应机器学习元模型，用于不确定性传播和失效概率估计。首先，利用分层采样生成的高精度数据集来训练基于深度学习的元模型，该模型充当具有成本效益且高度相关的低精度模型。然后，提出了一种自适应训练方案来平衡低精度模型的近似质量和计算需求。最后，通过将低精度输出与额外的高精度结果相结合，并利用全概率定理，使用多精度蒙特卡洛框架获得无偏的层相关失效概率估计。

Result: 通过将该方法应用于承受随机风激励的全尺寸高层钢结构建筑，证明了该方案可以准确估计非线性响应的超过概率曲线，并实现了显著的计算节约。

Conclusion: 该方法能够准确估计非线性响应的超过概率曲线，并与单精度方差缩减方法相比，显著节省了计算资源。

Abstract: Existing variance reduction techniques used in stochastic simulations for
rare event analysis still require a substantial number of model evaluations to
estimate small failure probabilities. In the context of complex, nonlinear
finite element modeling environments, this can become computationally
challenging-particularly for systems subjected to stochastic excitation. To
address this challenge, a multi-fidelity stratified sampling scheme with
adaptive machine learning metamodels is introduced for efficiently propagating
uncertainties and estimating small failure probabilities. In this approach, a
high-fidelity dataset generated through stratified sampling is used to train a
deep learning-based metamodel, which then serves as a cost-effective and highly
correlated low-fidelity model. An adaptive training scheme is proposed to
balance the trade-off between approximation quality and computational demand
associated with the development of the low-fidelity model. By integrating the
low-fidelity outputs with additional high-fidelity results, an unbiased
estimate of the strata-wise failure probabilities is obtained using a
multi-fidelity Monte Carlo framework. The overall probability of failure is
then computed using the total probability theorem. Application to a full-scale
high-rise steel building subjected to stochastic wind excitation demonstrates
that the proposed scheme can accurately estimate exceedance probability curves
for nonlinear responses of interest, while achieving significant computational
savings compared to single-fidelity variance reduction approaches.

</details>


### [230] [A Simple and Effective Method for Uncertainty Quantification and OOD Detection](https://arxiv.org/abs/2508.00754)
*Yaxin Ma,Benjamin Colburn,Jose C. Principe*

Main category: cs.LG

TL;DR: 提出了一种基于特征空间密度的有效方法，用于量化分布偏移和检测 OOD 数据。该方法利用信息势场来近似训练集的特征空间密度，并通过比较测试样本的特征空间表示来检测分布偏移。


<details>
  <summary>Details</summary>
Motivation: 为了解决贝叶斯神经网络和深度集成方法计算量大且需要大量存储的问题，提出利用单一确定性模型。

Method: 通过比较该密度与测试样本的特征空间表示，来判断是否发生了分布偏移。该方法利用从核密度估计中提取的信息势场来近似训练集的特征空间密度。

Result: 实验结果表明，与基线模型相比，该方法在 OOD 检测任务上表现更优。

Conclusion: 该方法在二维合成数据集（Two Moons 和 Three Spirals）以及 OOD 检测任务（CIFAR-10 vs. SVHN）上进行了实验，结果表明该方法优于基线模型。

Abstract: Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.

</details>


### [231] [Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in Tabular Data](https://arxiv.org/abs/2508.00758)
*Timur Sattarov,Marco Schreyer,Damian Borth*

Main category: cs.LG

TL;DR: DDAE improves tabular anomaly detection by combining diffusion noise scheduling and contrastive learning, outperforming existing methods, especially in semi-supervised scenarios. Optimal noise strategies are crucial for performance.


<details>
  <summary>Details</summary>
Motivation: Anomaly detection in tabular data is challenging due to complex feature interactions and scarce anomalous examples. Existing methods like denoising autoencoders and diffusion models have limitations in adapting to diverse data distributions and providing explicit reconstruction mappings.

Method: The proposed Diffusion-Scheduled Denoising Autoencoder (DDAE) framework integrates diffusion-based noise scheduling and contrastive learning into the encoding process.

Result: DDAE outperforms state-of-the-art autoencoder and diffusion models in semi-supervised settings (improving PR-AUC by up to 65% and ROC-AUC by 16%) and achieves competitive results in unsupervised settings (improving PR-AUC by 9% and ROC-AUC by 6%). Higher noise levels benefit unsupervised training, while lower noise with linear scheduling is optimal for semi-supervised settings.

Conclusion: Denoising autoencoders and diffusion models have limitations in tabular anomaly detection due to fixed noise and lack of explicit reconstruction mappings, respectively. DDAE integrates diffusion-based noise scheduling and contrastive learning to improve anomaly detection, outperforming existing methods in semi-supervised settings and achieving competitive results in unsupervised settings. The study highlights the importance of noise strategies for tabular anomaly detection.

Abstract: Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.

</details>


### [232] [Evaluating Angle and Amplitude Encoding Strategies for Variational Quantum Machine Learning: their impact on model's accuracy](https://arxiv.org/abs/2508.00768)
*Antonio Tudisco,Andrea Marchesin,Maurizio Zamboni,Mariagrazia Graziano,Giovanna Turvani*

Main category: cs.LG

TL;DR: 本研究分析了不同编码模型和旋转门对变分量子电路（VQC）分类性能的影响，发现旋转门的选择对模型性能有显著影响，并且嵌入是VQC模型的一个超参数。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习（QML）是量子计算和机器学习领域的一个交叉学科，旨在利用量子计算范式开发机器学习模型。变分量子电路（VQC）是QML中常用的模型，它结合了量子电路和经典优化。本研究旨在分析不同编码模型和旋转门对VQC分类性能的影响。

Method: 本研究分析了幅度编码和角度编码模型，并检查了旋转门类型对模型分类性能的影响。通过在Wine和Diabetes两个数据集上训练不同的模型并评估它们的性能来进行比较。

Result: 在相同的模型拓扑下，最佳模型和最差模型之间的准确率差异范围为10%至30%，最高可达41%。研究结果强调了编码中使用的旋转门的选择对模型分类性能的显著影响。

Conclusion: 研究结果证实了嵌入是变分量子计算（VQC）模型的一个超参数，并且旋转门的选择会显著影响模型的分类性能。

Abstract: Recent advancements in Quantum Computing and Machine Learning have increased
attention to Quantum Machine Learning (QML), which aims to develop machine
learning models by exploiting the quantum computing paradigm. One of the widely
used models in this area is the Variational Quantum Circuit (VQC), a hybrid
model where the quantum circuit handles data inference while classical
optimization adjusts the parameters of the circuit. The quantum circuit
consists of an encoding layer, which loads data into the circuit, and a
template circuit, known as the ansatz, responsible for processing the data.
This work involves performing an analysis by considering both Amplitude- and
Angle-encoding models, and examining how the type of rotational gate applied
affects the classification performance of the model. This comparison is carried
out by training the different models on two datasets, Wine and Diabetes, and
evaluating their performance. The study demonstrates that, under identical
model topologies, the difference in accuracy between the best and worst models
ranges from 10% to 30%, with differences reaching up to 41%. Moreover, the
results highlight how the choice of rotational gates used in encoding can
significantly impact the model's classification performance. The findings
confirm that the embedding represents a hyperparameter for VQC models.

</details>


### [233] [Explainable AI and Machine Learning for Exam-based Student Evaluation: Causal and Predictive Analysis of Socio-academic and Economic Factors](https://arxiv.org/abs/2508.00785)
*Bushra Akter,Md Biplob Hosen,Sabbir Ahmed,Mehrin Anannya,Md. Farhad Hossain*

Main category: cs.LG

TL;DR: 本研究通过分析影响学业成绩的多种因素，并利用机器学习模型进行预测和分类，最终开发了一个帮助学生提升学业成绩的网络应用。


<details>
  <summary>Details</summary>
Motivation: 为了优化学生的平均成绩（CGPA），本研究旨在探究影响学业成绩的社会、经济和学术等多变量因素，并开发有效的策略。

Method: 本研究首先通过文献综述确定影响学生学业成绩的关键因素，并构建了初始的因果图。随后，通过对1050名学生进行在线调查收集数据，并进行数据预处理。接着，利用因果分析验证变量间的关系，并采用岭回归模型进行学业成绩预测（平均绝对误差为0.12，均方误差为0.023），以及随机森林模型进行学业成绩分类（F1分数接近完美，准确率为98.68%）。最后，利用SHAP、LIME和Interpret等可解释人工智能技术增强模型的可解释性，并开发了一个网络应用。

Result: 研究识别出学习时数、奖学金、父母教育水平和以往学业成绩是影响CGPA的关键因素。岭回归模型在预测方面表现出色，随机森林模型在分类方面准确率高达98.68%。

Conclusion: 本研究提出了一个包含社会、经济和学术因素的综合模型，并通过网络应用为学生提供个性化指导，以优化其学业成绩。

Abstract: Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [234] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench基准存在依赖专家意见、易带入偏见以及在低收入国家适用性不足的问题。本文提出一种基于循证临床实践指南（CPG）的强化学习方法，以提高医学语言模型评估的可靠性、公平性和全球适用性。


<details>
  <summary>Details</summary>
Motivation: 现有评估AI医疗能力的基准（如HealthBench）依赖专家意见，可能包含区域偏见和个体差异，在低收入和中等收入国家尤其明显，且存在数据稀疏、基础设施不足和监管框架不完善等挑战。

Method: 提出了一种“证据稳健”的强化学习方法，通过将评分标准链接到指南，进行证据加权评分，并引入上下文覆盖逻辑，同时关注伦理问题和延迟结果反馈。

Result: 通过将奖励函数建立在经过严格审查的临床实践指南（CPG）之上，并在保留HealthBench的透明度和医生参与度的同时，旨在培养出不仅语言流畅，而且在临床上值得信赖、符合伦理且具有全球相关性的医学语言模型。

Conclusion: 通过将奖励函数锚定在版本控制的临床实践指南（CPG）上，并结合系统评价和GRADE证据评级，旨在创建更值得信赖、符合伦理且具有全球相关性的医学语言模型。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [235] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本研究将 HyperTWTL（一种用于机器人应用的形式化语言）应用于安全强化学习（SecRL），提出了一种学习安全感知最优策略的方法，并验证了其有效性和优越性。


<details>
  <summary>Details</summary>
Motivation: 尽管基于时间逻辑约束的安全强化学习（SRL）是一个不断发展的研究问题，但利用超属性探索安全感知强化学习（RL）的研究尚有空白。本研究旨在填补这一空白，将 HyperTWTL 应用于安全强化学习。

Method: 提出了一种使用动态玻尔兹曼 Softmax 强化学习（RL）的方法，该方法在满足 HyperTWTL 约束的同时，学习安全意识最优策略。该方法将智能体的动态表示为马尔可夫决策过程（MDP），并将不透明性/安全约束形式化为 HyperTWTL。

Result: 所提出的方法在 pick-up and delivery 机器人任务案例研究中被证明是有效的，并且具有良好的可扩展性。与两种基线强化学习算法相比，该方法表现出更优越的性能。

Conclusion: 本文提出的方法在 pick-up and delivery 机器人任务案例研究中被证明是有效的，并且具有良好的可扩展性，优于其他两种基线强化学习算法。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [236] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: AI在工业运营中落地困难，需要对象为中心的流程挖掘（OCPM）和流程智能（PI）来实现成功应用。


<details>
  <summary>Details</summary>
Motivation: 组织在工业环境中成功应用AI方面存在挑战，特别是在端到端运营流程方面。AI需要与流程数据相结合才能有效改进这些流程。

Method: 本文提出将AI应用于工业运营流程，重点介绍了生成式、预测式和规范式AI，并探讨了诊断和改进这些流程的挑战。文章指出，AI需要以对象为中心的流程挖掘（OCPM）为基础，并引入了流程智能（PI）的概念，即处理各种对象和事件类型的数据驱动技术，以实现组织环境中的AI应用。

Result: 通过结合OCPM和生成式、预测式及规范式AI，可以成功改进组织运营流程，实现流程智能（PI）。

Conclusion: AI需要以对象为中心的流程挖掘（OCPM）为基础，才能成功应用于工业领域的端到端运营流程。本文阐述了诊断和改进这些流程的挑战，并强调了OCPM与生成式、预测式和规范式AI相结合的机遇。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [237] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: A new method uses 'theory of mind' in active inference for better multi-agent cooperation without needing shared models or communication. Agents learn to understand others' beliefs from actions, improving task performance in simulations.


<details>
  <summary>Details</summary>
Motivation: To enable multi-agent cooperation by allowing agents to reason about others' beliefs and goals, without relying on task-specific shared generative models or explicit communication.

Method: This paper implements theory of mind (ToM) within active inference. It extends the inference tree-based planning algorithm to explore joint policy spaces through recursive reasoning. The ToM-equipped agent maintains distinct representations of its own and others' beliefs and goals.

Result: ToM-equipped agents demonstrated improved cooperation in collision avoidance and foraging simulations compared to non-ToM agents, by inferring others' beliefs from observable behavior.

Conclusion: ToM-equipped agents cooperate better than non-ToM counterparts by inferring others' beliefs solely from observable behavior, leading to collision avoidance and reduced redundant efforts. This work advances practical AI applications and provides computational insights into ToM.

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [238] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 该研究提出了三种检测秩反转的方法，以评估和比较多标准决策方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决多标准决策分析（MCDA）中的秩反转问题，该研究旨在提出一种衡量多标准决策方法在不同备选方案集上性能的机制。

Method: 提出了三种检测秩反转的方法，并实现了 Scikit-Criteria 库。

Result: 实现了三种秩反转检测方法，并讨论了在一般场景下实施这些检测的复杂性和设计考虑因素。

Conclusion: 该研究提出的秩反转检测方法有助于评估和比较多标准决策方法的性能，并为多标准决策方法的选择提供依据。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [239] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: This paper studies SHACL validation under updates, introducing a SHACL-based update language and reducing static validation to constraint satisfiability. It analyzes complexity and provides a prototype implementation.


<details>
  <summary>Details</summary>
Motivation: We study SHACL validation in RDF graphs under updates and present a SHACL-based update language that can capture intuitive and realistic modifications on RDF graphs.

Method: Using a regression technique that embeds the update actions into SHACL constraints.

Result: We analyze the computational complexity of the static validation problem for SHACL and some key fragments, and present a prototype implementation that performs static validation and other static analysis tasks on SHACL constraints and demonstrate its behavior through preliminary experiments.

Conclusion: We show that static validation under updates can be reduced to (un)satisfiability of constraints in (a minor extension of) SHACL.

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [240] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 本研究提出了一种名为AVR-Eval的新评估指标和AVR-Agent多智能体系统，用于改进AI生成交互式视听内容的质量。AVR-Agent在生成游戏和动画方面表现优于单次生成，但模型在利用自定义素材和AVR反馈方面仍有待提高，这表明AI内容创作与人类创作在利用资源方面存在差异。


<details>
  <summary>Details</summary>
Motivation: 目前AI在生成交互式视听内容方面面临挑战，缺乏自动评估指标且难以处理复杂内容。

Method: 我们提出了一种用于多媒体内容质量的相对评估指标AVR-Eval，它使用音频-视觉录制（AVRs）。一个全模态模型（处理文本、视频和音频）对两个内容的AVRs进行比较，并由一个文本模型审查评估结果以确定优劣。我们证明了AVR-Eval能够正确地识别出好的内容与损坏或不匹配的内容。我们构建了一个多智能体系统AVR-Agent，该系统从多媒体素材库（音频、图像、3D模型）生成JavaScript代码。该编码智能体选择相关素材，生成多个初始代码，使用AVR-Eval识别最佳版本，并通过全模态智能体的AVR反馈进行迭代改进。

Result: 我们在游戏和动画上运行了AVR-Eval实验（内容A相对于内容B的胜率）。我们发现，AVR-Agent生成的内容相对于单次生成的内容具有显著更高的胜率。然而，模型在有效利用自定义素材和AVR反馈方面存在困难，胜率没有提高。这揭示了一个关键差距：虽然人类受益于高质量的素材和视听反馈，但当前的编码模型似乎没有有效地利用这些资源，这突显了人类和机器内容创作方法之间的根本差异。

Conclusion: 虽然AI在生成文本、音频、图像和视频方面表现出色，但在创建交互式视听内容（如视频游戏）方面仍然存在挑战。当前的大型语言模型（LLMs）可以生成JavaScript游戏和动画，但缺乏自动评估指标，并且在通常需要数月的人工（多轮、多智能体）和艺术家制作的素材才能完成的复杂内容方面存在困难。为了解决这些问题，我们构建了一个新的评估指标和一个多智能体系统。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [241] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: AI的风险和偏见问题需要重构AI生产流程，以共同构建、多样性、公平性、包容性和多学科协作为中心，提出包含五个阶段的AI生命周期模型。


<details>
  <summary>Details</summary>
Motivation: AI算法可能对文化边缘化群体产生不成比例的影响，尽管已有各种缓解风险和偏见的努力，但仍需根本性的重构。

Method: 本文利用设计正义、扩展学习理论和参与式AI的实证研究，提出了一种包含共同构思、共同设计、共同实施、共同部署和共同维护的五个相互关联的阶段的AI生命周期模型。该模型基于四个跨学科研讨会，并以分布式权威和迭代知识交流为指导。

Result: 提出了一种新的AI生命周期模型，强调共同构建、多样性、公平性、包容性和多学科协作，以解决AI的风险和偏见问题。

Conclusion: 文章提出了一种包含共同构建、多样性、公平性、包容性和多学科协作的AI生命周期模型，以应对AI算法对文化边缘化群体的不利影响，并呼吁对AI生产流程进行根本性重构。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [242] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 人类评估者存在缺陷，但IRR指标在AI教育应用中仍用于验证数据。本文认为过度依赖IRR会阻碍进展，并提出五种互补的评估方法，如多标签标注、专家方法和闭环验证，以提高数据分类的有效性和教育影响力。


<details>
  <summary>Details</summary>
Motivation: 随着教育应用中AI对大量训练数据的需求激增，过度依赖人类评估者信度（IRR）作为标注质量的门槛，阻碍了在数据分类方面取得进展，这些分类在与改善学习相关方面是有效且具有预测性的。

Method: 本文提出了五种互补的评估方法，例如多标签标注方案、基于专家的方法和闭环验证。

Result: 本文认为，与单独的IRR方法相比，这些方法能更好地为训练数据以及后续能改善学生学习和提供更可操作见解的模型提供支持。文章还强调了外部有效性的重要性，例如，通过建立一个验证导师行为的程序，并证明其在许多类别的导师行为（例如提供提示）中都有效。

Conclusion: 研究者应当重新思考标注质量和真实性标准，优先考虑有效性和教育影响力，而非仅仅是共识。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [243] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: This paper proposes an objective function for AI agents that prioritizes human empowerment and power balance, aiming to enhance both safety and wellbeing. It uses a principled approach to design a metric that considers human rationality and diverse goals, deriving algorithms for its computation and demonstrating its potential benefits over direct utility-based objectives.


<details>
  <summary>Details</summary>
Motivation: Exploring the idea of promoting both safety and wellbeing by forcing AI agents explicitly to empower humans and to manage the power balance between humans and AI agents in a desirable way.

Method: Using a principled, partially axiomatic approach, design a parametrizable and decomposable objective function that represents an inequality- and risk-averse long-term aggregate of human power. Derive algorithms for computing this metric by backward induction or approximating it via a form of multi-agent reinforcement learning from a given world model.

Result: Exemplify the consequences of (softly) maximizing this metric in a variety of paradigmatic situations and describe what instrumental sub-goals it will likely imply.

Conclusion: Softly maximizing suitable aggregate metrics of human power might constitute a beneficial objective for agentic AI systems that is safer than direct utility-based objectives.

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [244] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS 通过结合内部思考和外部学习，利用多种重要性采样和基于探索的优势函数，提高了 LLM 的推理能力，克服了现有 RLVR 方法的局限性，并在多个推理任务上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 为了解决 RLVR 挣扎于基础 LLM 的固有能力边界、可能导致能力边界崩溃的问题，我们提出了 RL-PLUS。

Method: RL-PLUS 整合了两种核心组件：多种重要性采样，用于解决外部数据产生的分布不匹配问题；以及基于探索的优势函数，用于指导模型走向高价值、未探索的推理路径。

Result: RL-PLUS 在六个数学推理基准测试中取得了最先进的性能，并在六个分布外推理任务上表现出优越的性能，与现有的 RLVR 方法相比，平均相对提高了 21.1% 到 69.2%。Pass@k 曲线表明 RL-PLUS 有效解决了能力边界崩溃问题。

Conclusion: RL-PLUS 成功解决了能力边界崩溃问题，在六个数学推理基准测试中取得了最先进的性能，并在六个分布外推理任务上表现出优越的性能，与现有的 RLVR 方法相比，平均相对提高了 21.1% 到 69.2%。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [245] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent 是一种受“边做边学”启发的代理范例，它通过实践、自我反思、生成帮助请求以及自主构建工具和知识库来不断改进其推理和工具使用策略。该方法在知识发现任务中表现出色，无需重新训练模型即可实现自我进化。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种能够通过实践和持续自我改进来发展专业知识的代理范例，类似于“边做边学”的原理。

Method: MetaAgent 的方法包括一个由基本推理和适应性寻求帮助能力组成的最小工作流。当遇到知识差距时，它会生成自然语言帮助请求，并通过专门的工具路由器路由到最合适的外部工具。MetaAgent 通过自我反思和答案验证来不断提炼经验，并将其纳入未来任务的上下文中。此外，它通过组织工具使用历史来自主构建内部工具和持久的知识库，以增强信息检索和集成能力。这个过程被称为“元工具学习”，它在不改变模型参数或需要进一步进行后训练的情况下，逐步优化推理和工具使用策略。

Result: MetaAgent 在 GAIA、WebWalkerQA 和 BrowseCamp 等基准测试中表现出色，其性能优于基于工作流的方法，并能与端到端训练的代理相媲美甚至超越。

Conclusion: MetaAgent 在具有挑战性的知识发现基准（包括 GAIA、WebWalkerQA 和 BrowseCamp）上持续优于基于工作流的基线，并匹配或超过了端到端训练的代理，证明了自进化代理系统在鲁棒、通用的知识发现方面的前景。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [246] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: LLM 在任务生成方面未能模仿人类的心理驱动因素和行为模式，生成结果偏向抽象且缺乏社会性和身体活动。尽管 LLM 的任务更具新颖性和趣味性，但这暴露了其在具身化目标生成方面的局限性，强调了在设计智能体时融入内在动机和物理基础的重要性。


<details>
  <summary>Details</summary>
Motivation: 旨在探究由大型语言模型（LLM）驱动的生成式智能体在模拟人类由内在动机驱动的多样化任务生成行为时，是否遵循与人类相似的认知原理。

Method: 通过一项任务生成实验，将人类的反应与大型语言模型（LLM）代理（GPT-4o）的反应进行比较，以探究 LLM 在模拟人类多样化任务生成方面的认知原理。

Result: 研究发现，人类的任务生成受到个人价值观（如开放性）和认知风格等心理驱动因素的显著影响。即使将这些心理驱动因素明确提供给 LLM，其生成的任务也未能反映相应的行为模式，表现出社会性和身体活动的倾向较低，且更偏向于抽象主题。此外，LLM 生成的任务虽然被认为更有趣和新颖，但这表明其语言能力与生成类似人类的、具身化的目标的能力之间存在脱节。

Conclusion: LLM 的目标生成能力与人类相比存在显著差异，主要体现在缺乏与心理驱动因素和物理现实的联系。虽然 LLM 生成的任务可能更具趣味性和新颖性，但它们未能反映人类任务生成中常见的社会性和身体活动偏向。因此，为了实现更符合人类期望的智能体，有必要在设计中融入内在动机和物理基础。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [247] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: ReasonBench：首个专注于结构化图形推理任务的基准测试，包含1,613个真实智力测试问题，旨在评估和改进视觉语言模型（VLM）在复杂图形推理方面的能力。提出的DiaCoT和ReasonTune策略显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究对VLM在复杂图形推理和抽象问题解决方面的能力研究不足，且仅关注简单图形，需要新的基准来评估和改进VLM在该领域的表现。

Method: 提出ReasonBench基准测试，包含1,613个来自真实智力测试的问题，涵盖位置、属性、数量和多元素任务；提出DiaCoT（Diagrammatic Reasoning Chain）和ReasonTune两种优化策略。

Result: 在ReasonBench基准测试中，对11种主流VLM进行了基准测试，揭示了现有模型的局限性。DiaCoT和ReasonTune策略将VLM性能提高了33.5%。

Conclusion: 现有模型在复杂图形推理能力方面存在显著局限性，但提出的DiaCoT和ReasonTune策略能显著提升VLM性能33.5%。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [248] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: 本研究提出了一种名为 R1-Act 的新方法，旨在解决大型推理模型 (LRM) 的安全问题。研究发现 LRM 具备安全知识但无法有效激活。R1-Act 通过结构化推理过程来触发这些安全知识，从而提高了模型的安全性，同时保持了其推理能力。该方法训练高效，仅需少量数据和时间即可在不同规模的模型上取得良好效果。


<details>
  <summary>Details</summary>
Motivation: LRM 在复杂任务中表现出强大的能力，但它们经常会响应有害的用户指令，引发了重大的安全担忧。本研究旨在调查 LRM 安全风险的根本原因。

Method: R1-Act 是一种通过结构化推理过程显式触发安全知识的后训练方法。

Result: R1-Act 在多个 LRM 主干和规模上进行了广泛的实验，证明了其鲁棒性、可扩展性和实际效率。值得注意的是，仅需 1000 个训练样本和 90 分钟的训练时间（在单个 RTX A6000 GPU 上），即可实现强大的安全改进，同时保留推理性能，并且优于以往的对齐方法。

Conclusion: R1-Act 是一种简单高效的后训练方法，通过结构化推理过程显式触发安全知识，在提升安全性的同时保持了推理性能，优于以往的对齐方法。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [249] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI framework improves VLM reasoning by adding visual verification to the Chain-of-Thought process, grounding explanations in visual evidence and reducing hallucinations. It enhances performance without retraining and yields more factual explanations.


<details>
  <summary>Details</summary>
Motivation: Existing Chain-of-Thought (CoT) prompting in vision-language models (VLMs) often produces explanations that are fluent but lack grounding in visual content, leading to hallucinations. This is partly due to the absence of an explicit verification mechanism during multi-step reasoning. The motivation is to address this by introducing visual verification into the reasoning process.

Method: CoRGI (Chain of Reasoning with Grounded Insights) is a modular framework that introduces visual verification into the reasoning process of VLMs. It follows a three-stage pipeline: 1. Generate a textual reasoning chain. 2. Extract supporting visual evidence for each reasoning step using a dedicated module (VEVM). 3. Synthesize the textual rationale with visual evidence to generate a grounded, verified answer. The framework can be integrated with existing VLMs without end-to-end retraining.

Result: CoRGI improves reasoning performance on the VCR benchmark using two representative open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm the contribution of each step in the verification module, and human evaluations suggest that CoRGI leads to more factual and helpful explanations. The paper also examines alternative designs for the visual verification step and discusses potential limitations of post-hoc verification frameworks.

Conclusion: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in vision-language models (VLMs), but it often produces explanations that are linguistically fluent yet lack grounding in visual content. This paper addresses this issue by proposing CoRGI (Chain of Reasoning with Grounded Insights), a modular framework that introduces visual verification into the reasoning process. CoRGI integrates with existing VLMs without end-to-end retraining and has demonstrated improved reasoning performance on the VCR benchmark with open-source VLM backbones. Ablation studies and human evaluations confirm the effectiveness of CoRGI in generating more factual and helpful explanations by grounding intermediate reasoning steps in visual evidence, highlighting the importance of this approach for enhancing the robustness of multimodal reasoning.

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [250] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro 是一个开源免费的 AI 代理框架，它通过高质量数据和改进的测试策略，在 GAIA 基准测试中达到了最先进的性能，超越了之前的领先系统。


<details>
  <summary>Details</summary>
Motivation: 当前的 AI 代理系统要么是闭源的，要么严重依赖各种付费 API 和专有工具，这限制了研究社区的可访问性和可重复性。因此，有必要创建一个开源且免费的框架来普及先进 AI 代理的开发和评估。

Method: Cognitive Kernel-Pro 是一个完全开源且免费的模块化 AI 代理框架。研究人员系统地研究了针对代理基础模型的高质量训练数据的管理，重点关注跨越 Web、文件、代码和通用推理四个关键领域的查询、轨迹和可验证答案的构建。此外，还探索了用于代理测试时反思和投票的新颖策略，以提高代理的鲁棒性和性能。

Result: 在 GAIA 基准测试中，Cognitive Kernel-Pro 取得了最先进的成果，优于所有开源且免费的代理。具体来说，其 8B 参数开源模型在性能上超过了 WebDancer 和 WebSailor 等之前的领先系统，为可访问、高能力 AI 代理树立了新的性能标准。

Conclusion: Cognitive Kernel-Pro 是一个完全开源且免费的模块化 AI 代理框架，旨在促进先进 AI 代理的开发和评估。该框架在 GAIA 基准测试中取得了最先进的成果，其 8B 参数模型性能优于之前的领先系统，为可访问、高能力 AI 代理树立了新的性能标准。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [251] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: LLMs在代码方面很强，但在数学证明方面表现不佳。本文探讨了原因和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在代码等结构化推理任务中表现出色，但在数学领域，尤其是在形式化定理证明方面，进展却困难得多。这引发了关于LLMs的‘推理’方式、监督机制以及它们是否能内部追踪计算或演绎状态的关键问题。

Method: 本文梳理了LLMs在数学领域（包括非形式化问题解决和形式化定理证明）的最新进展，重点关注模型、基准测试，并探讨了形式化与非形式化数学作为训练域的权衡、证明生成比代码合成更脆弱的原因，以及LLMs是否真正模拟了逻辑状态的演变。

Result: 文章旨在识别当前LLMs在数学领域能力的边界，并探索扩展这些能力的途径，而非设定硬性界限。

Conclusion: LLMs在数学领域的应用仍面临挑战，尤其在形式化证明方面，其表现不如代码生成稳定。未来的研究需要深入理解LLMs的‘推理’机制，以及它们是否能真正理解和维护逻辑状态。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [252] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard通过概率可达性分析主动解决LLM代理的安全风险，通过学习DTMC预测风险并提前干预，在具身代理和自动驾驶场景中均表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的强制系统（如AgentSpec）主要关注反应式安全规则，并且在应对长期依赖性和分布变化方面存在不足。LLM代理的随机行为带来了难以预测的重大安全风险。

Method: Pro2Guard将代理行为抽象为符号状态，并从执行跟踪中学习离散时间马尔可夫链（DTMC）。在运行时，它通过估计到达不安全状态的概率来预测未来风险，并在预测风险超过用户定义的阈值时触发干预。

Result: 在具身代理任务中，Pro2Guard在使用低阈值时，可提前强制执行高达93.6%的不安全任务，并能通过可配置模式（如reflect）在保持高达80.4%的任务完成率的同时平衡安全与任务成功。在自动驾驶场景中，Pro2Guard实现了100%的交通法规和碰撞预测，可提前38.66秒预测风险。

Conclusion: Pro2Guard是一个主动运行时强制框架，通过概率可达性分析来解决LLM代理的随机行为带来的安全风险。它通过学习离散时间马尔可夫链（DTMC）来预测未来风险，并在超出用户定义的阈值时触发干预，从而在违规发生之前进行干预。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [253] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP是一种新的解释框架，用于理解多模态AI模型如何结合不同来源的信息。它能精确地解释模型为何做出特定预测，并揭示跨模型的通用信息整合模式，适用于各种模型。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态AI模型具有“黑箱”性质，难以解释其跨模态交互，这在高风险应用中阻碍了其部署。现有的解释方法（如注意力图和Grad-CAM）只能提供粗略的见解，无法精确量化模态间的协同效应，并且局限于需要访问内部权重的开源模型。

Method: 提出MultiSHAP框架，利用Shapley交互指数量化细粒度视觉和文本元素之间的成对交互作用，实现模型无关的解释，适用于开源和闭源模型。

Result: MultiSHAP能够精确量化模态间的协同和抑制效应，揭示实例级和数据集级的跨模态交互模式。实验证明该方法能忠实捕捉跨模态推理机制，并在实际案例中展现其应用潜力。

Conclusion: MultiSHAP是一个模型无关的解释框架，利用Shapley交互指数来归因多模态预测于细粒度的视觉和文本元素之间的成对交互，并且适用于开源和闭源模型。该方法提供了实例级解释（揭示特定输入的跨模态效应）和数据集级解释（揭示跨样本的通用交互模式）。实验和案例研究表明MultiSHAP能够准确捕捉跨模态推理机制，并具有实际应用价值，且该框架可扩展至多于两种模态。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [254] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 本研究提出了一种多阶段LLM框架，用于从电子病历中生成预咨询问卷，解决了直接LLM方法在信息完整性和逻辑顺序方面的不足。该框架通过提取事实、构建因果网络和综合疾病知识来生成定制问卷，并在真实数据和专家验证中显示出优越性能。


<details>
  <summary>Details</summary>
Motivation: 从复杂的、大量的电子病历（EMRs）中生成全面的预咨询问卷是一项艰巨的任务。直接的大型语言模型（LLM）方法在此任务中面临挑战，特别是在信息完整性、逻辑顺序和疾病级别综合方面。

Method: 提出了一种新颖的多阶段LLM驱动框架：第一阶段从EMR中提取原子断言（带有时效性的关键事实）；第二阶段通过聚类EMR语料库的代表性网络来构建个人因果网络并综合疾病知识；第三阶段基于这些结构化表示生成定制的个人和标准化的疾病特定问卷。

Result: 在真实世界的EMR数据集上进行评估，并由临床专家验证，我们提出的方法在信息覆盖、诊断相关性、可理解性和生成时间方面表现出优越的性能，突显了其在加强患者信息收集方面的实际潜力。

Conclusion: 该框架通过构建显式的临床知识克服了直接方法的局限性。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [255] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: MB-VLGC通过考虑频率依赖性来改进格兰是因果关系，在各种数据集上表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有的格兰是因果关系框架通常存在固定的滞后假设，这在复杂系统中往往不切实际。虽然最近的可变延迟格兰是因果关系（VLGC）解决了这个限制，但它未能考虑到因果相互作用不仅在时间延迟上，而且在频率带上也会变化。

Method: 提出了一种名为多频段可变延迟格兰是因果关系（MB-VLGC）的新型框架，该框架通过明确建模依赖于频率的因果延迟来泛化传统的VLGC，并提供了一个高效的推理流程。

Result: 该框架在合成和真实世界数据集的多个领域进行了广泛的实验，证明其性能显著优于现有方法，证实了其广泛的适用性。

Conclusion: MB-VLGC框架通过明确建模依赖于频率的因果延迟，对传统VLGC进行了泛化，并在合成和真实世界数据集的多个领域进行了广泛的实验，证明其性能显著优于现有方法，证实了其广泛的适用性。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [256] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: This paper introduces a new framework for AI in education that uses generative AI and personalization to make explanations understandable to different users, addressing the lack of transparency in current systems.


<details>
  <summary>Details</summary>
Motivation: Existing AI-driven adaptive learning systems often lack transparency, providing limited insight into decision-making processes. Current XAI techniques primarily focus on technical outputs and neglect user roles and comprehension.

Method: A hybrid framework that integrates traditional XAI techniques with generative AI models and user personalization to generate multimodal, personalized explanations tailored to user needs.

Result: The paper outlines the framework's design, discusses key XAI limitations in educational contexts, and identifies research directions concerning accuracy, fairness, and personalization.

Conclusion: The paper proposes a hybrid framework integrating traditional XAI techniques with generative AI and user personalization to create multimodal, personalized explanations for adaptive learning systems. It redefines explainability as a dynamic communication process tailored to user roles and learning goals, aiming to enhance transparency and support user-centered experiences.

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [257] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: AI推荐需要解释，但现有解释过于笼统。本研究提出一个视觉解释系统，能根据用户类型（专家/普通用户）和情境调整解释方式（视觉/数值），以提升用户理解和信任。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体平台的AI推荐缺乏可解释性，用户不理解推荐原因，导致推荐价值下降，用户体验受损。

Method: 提出一个视觉解释系统，该系统包含多种解释方法，并能根据用户需求和情境调整解释风格（视觉或数值）和粒度（专家或普通用户）。

Result: 该框架首次实现了在单个流程中同时适应解释风格（视觉 vs. 数值）和粒度（专家 vs. 普通用户）的调整。一项包含30名X用户的公开试点研究将验证该系统对决策和信任的影响。

Conclusion: 该研究提出了一个用户分层、情境感知的解释层，并辅以一个包含多种解释方法的视觉解释系统，旨在解决当前社交媒体平台中AI推荐缺乏用户理解的问题。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [258] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 提出使用大型预训练多模态模型的潜在代码进行虚假内容检测，在音频和图像上取得了优于或媲美现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对恶意用户利用合成媒体传播错误信息和深度伪造的威胁，需要开发稳健且稳定的虚假内容检测器，特别是面对日益增多的新型生成模型。

Method: 利用大型预训练多模态模型的潜在代码来提取区分真实与虚假信息的特征，并在此基础上训练线性分类器。

Result: 在音频和图像的虚假检测任务中，基于预训练模型潜在特征的线性分类器达到了最先进的性能，并且在计算效率、训练速度和少样本学习方面表现出色。

Conclusion: 该研究提出使用大型预训练多模态模型来检测生成内容，并在音频和图像方面取得了与现有方法相当或更优的性能。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [259] [Weak Values as Geometric Lenses: Deformations of Hilbert Space and the Emergence of superoscillations](https://arxiv.org/abs/2508.00023)
*Mirco A. Mannucci*

Main category: quant-ph

TL;DR: 量子力学中的弱测量和超振荡可以通过一种新的几何透镜来理解，这种透镜揭示了它们之间深刻的联系。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的弱测量形式主义揭示了测量理论、量子基础和信号处理之间深刻的联系。本研究旨在进一步探索这种联系，特别是弱测量与超振荡之间的关系。

Method: 提出了一种无指针的推导方法，将弱值解释为几何变形的比率，并将弱值解释为变形的半双线性形式与标准形式之间的比较。

Result: 推导了超振荡，并将其与弱值联系起来，表明它们是弱值潜在几何结构的必然结果。

Conclusion: 该研究将弱测量和超振荡统一为单一几何原理的两个方面，将弱值解释为几何变形的比率，量化可观测量的希尔伯特空间结构相对于标准内积的变换。

Abstract: The formalism of weak measurement in quantum mechanics has revealed profound
connections between measurement theory, quantum foundations, and signal
processing. In this paper, we develop a pointer-free derivation of
superoscillations, demonstrating that they are a natural and necessary
consequence of the geometric structure underlying weak values. We argue that
the weak value is best understood as a ratio of geometric deformation,
quantifying how an observable transforms the structure of Hilbert space
relative to a reference provided by the standard inner product. This
deformation acts as a conceptual lens, warping the local structure of quantum
states to produce oscillations far exceeding the global Fourier bandwidth. We
formalize this by interpreting the weak value as a comparison between a
deformed sesquilinear form and the standard one, and explore its deep
connections to generalized Rayleigh quotients and the projective geometry of
quantum states. This perspective unifies weak values and superoscillations as
two facets of a single underlying geometric principle.

</details>


### [260] [Are controlled unitaries helpful?](https://arxiv.org/abs/2508.00055)
*Ewin Tang,John Wright*

Main category: quant-ph

TL;DR: This paper shows that controlled unitaries (cU) are not more helpful than regular unitaries (U) for many quantum problems. The authors provide a method to "decontrol" circuits using cU into ones using only U, with minimal overhead. This is useful when global phase information of U is not important. They also generalize this result and provide an application in proving the existence of pseudorandom unitary ensembles.


<details>
  <summary>Details</summary>
Motivation: The authors aim to popularize a decontrolling result by generalizing it and investigating its implications, countering negative results in the literature that suggest decontrolling is not possible.

Method: Show how to "decontrol" a circuit that uses cU and cU^	op and outputs |	ext{psi}(U)angle into one that uses only U and U^	op and outputs |	ext{psi}(	ext{phi} U)angle for a uniformly random phase 	ext{phi}, with a small amount of time and space overhead.

Result: A decontrolled circuit suffices when one only cares about the output state up to a global phase on U. A simple proof for the existence of unitary ensembles which are pseudorandom under access to U, U^	op, cU, and cU^	op is also provided as an application.

Conclusion: Having access to cU does not help for a large class of quantum problems. cU is only helpful because it contains global phase information about U.

Abstract: Many quantum algorithms, to compute some property of a unitary $U$, require
access not just to $U$, but to $cU$, the unitary with a control qubit. We show
that having access to $cU$ does not help for a large class of quantum problems.
For a quantum circuit which uses $cU$ and $cU^\dagger$ and outputs
$|\psi(U)\rangle$, we show how to ``decontrol'' the circuit into one which uses
only $U$ and $U^\dagger$ and outputs $|\psi(\varphi U)\rangle$ for a uniformly
random phase $\varphi$, with a small amount of time and space overhead. When we
only care about the output state up to a global phase on $U$, then the
decontrolled circuit suffices. Stated differently, $cU$ is only helpful because
it contains global phase information about $U$.
  A version of our procedure is described in an appendix of Sheridan, Maslov,
and Mosca [SMM09]. Our goal with this work is to popularize this result by
generalizing it and investigating its implications, in order to counter
negative results in the literature which might lead one to believe that
decontrolling is not possible. As an application, we give a simple proof for
the existence of unitary ensembles which are pseudorandom under access to $U$,
$U^\dagger$, $cU$, and $cU^\dagger$.

</details>


### [261] [Embedding-Aware Quantum-Classical SVMs for Scalable Quantum Machine Learning](https://arxiv.org/abs/2508.00024)
*Sebastián Andrés Cajas Ordóñez,Luis Fernando Torres Torres,Mario Bifulco,Carlos Andrés Durán,Cristian Bosch,Ricardo Simón Carbajo*

Main category: quant-ph

TL;DR: Quantum Support Vector Machines improved with Vision Transformer embeddings, outperforming classical methods on MNIST datasets; embedding choice is key for quantum advantage.


<details>
  <summary>Details</summary>
Motivation: To address the scalability challenges of Quantum Support Vector Machines, particularly those arising from high-dimensional quantum states and hardware limitations.

Method: A quantum-classical pipeline combining class-balanced k-means distillation with pretrained Vision Transformer embeddings was proposed and evaluated using 16-qubit tensor network simulations.

Result: Vision Transformer embeddings led to accuracy improvements of up to 8.02% on Fashion-MNIST and 4.42% on MNIST compared to classical SVMs, whereas CNN features resulted in performance degradation. This provides evidence for the synergy between transformer attention and quantum feature spaces.

Conclusion: The study demonstrates that the choice of embedding is critical for achieving quantum kernel advantage in Quantum Support Vector Machines, with Vision Transformer embeddings showing significant improvements over classical methods and CNN features.

Abstract: Quantum Support Vector Machines face scalability challenges due to
high-dimensional quantum states and hardware limitations. We propose an
embedding-aware quantum-classical pipeline combining class-balanced k-means
distillation with pretrained Vision Transformer embeddings. Our key finding:
ViT embeddings uniquely enable quantum advantage, achieving up to 8.02%
accuracy improvements over classical SVMs on Fashion-MNIST and 4.42% on MNIST,
while CNN features show performance degradation. Using 16-qubit tensor network
simulation via cuTensorNet, we provide the first systematic evidence that
quantum kernel advantage depends critically on embedding choice, revealing
fundamental synergy between transformer attention and quantum feature spaces.
This provides a practical pathway for scalable quantum machine learning that
leverages modern neural architectures.

</details>


### [262] [Casimir force between two dielectric layers: Van Kampen approach](https://arxiv.org/abs/2508.00025)
*Michael Davidovich*

Main category: quant-ph

TL;DR: Vankampen 方法用于计算介电层 Casimir 力，考虑了洛伦兹模型和 Drude 模型，发现了力与厚度的复杂关系，并在任意层配置和有限温度下均适用。


<details>
  <summary>Details</summary>
Motivation: 研究 Vankampen 方法在计算 Casimir 力时的应用，特别是在考虑介电层和导电介质（如金属）的情况下，并探索其在不同厚度和温度下的行为。

Method: 使用 Van Kampen 方法计算两个介电层之间的 Casimir 力，并采用洛伦兹振子模型来描述介电常数。

Result: Casimir 力的强度与厚度之间存在复杂的依赖关系，在 10 纳米左右厚度时出现饱和。在低厚度情况下，力密度与厚度的平方成正比，但此时连续介质模型不再适用。

Conclusion: 该研究展示了 Van Kampen 方法在计算介电层之间的 Casimir 力方面的有效性，并揭示了其与洛伦兹模型和 Casimir 模型的对应关系，证明了其对任意层配置和有限温度的适用性。

Abstract: The Van Kampen method is used to calculate the Casimir force for two
dielectric layers. Several terms of Lorentz oscillators are used in the
permittivity model. A conductive dielectric (metal) with the Drude model is
considered as a special case. The dependence of strength on thickness has a
complex character with saturation at thicknesses of the order of 10 nm. At low
thickness, the force density is proportional to the square of the thickness,
but this is the case at low thicknesses, when the continuum model is no longer
applicable. The correspondence between the method of the Casimir model and the
Lorentz model is shown, as well as its applicability for an arbitrary
configuration of layers and for a finite temperature.

</details>


### [263] [Quantum Semi-Random Forests for Qubit-Efficient Recommender Systems](https://arxiv.org/abs/2508.00027)
*Azadeh Alavi,Fatemeh Kouchmeshki,Abdolrahman Alavi,Yongli Ren,Jiayang Niu*

Main category: quant-ph

TL;DR: 通过标签压缩、QAOA特征选择和量子半随机森林，在仅使用5个量子比特的情况下，实现了与全特征推荐系统相当的性能。


<details>
  <summary>Details</summary>
Motivation: 目前的量子推荐系统需要大量量子比特，远超NISQ设备的承受能力，并且容易出错。本研究旨在缩小这一差距，实现低量子比特数量下的高效推荐。

Method: 本文提出了一种三阶段混合机器学习算法：1.利用SVD和k-means学习字典压缩标签信息。2.使用QAOA优化在固定量子比特预算下的特征选择。3.构建基于量子半随机森林（QsRF）的推荐评分模型。

Result: 通过1000个原子的字典（保留97%以上方差）和深度为3的QAOA，从2020个QUBO问题中选择了5个原子。基于这5个原子训练的100棵树的QsRF模型，在ICM-150/500数据集上达到了与全特征基线相当的性能。

Conclusion: 量子推荐系统可以通过压缩标签、优化特征选择和使用量子半随机森林在有限的量子比特预算内实现与最先进方法相当的性能。

Abstract: Modern recommenders describe each item with hundreds of sparse semantic tags,
yet most quantum pipelines still map one qubit per tag, demanding well beyond
one hundred qubits, far out of reach for current noisy-intermediate-scale
quantum (NISQ) devices and prone to deep, error-amplifying circuits. We close
this gap with a three-stage hybrid machine learning algorithm that compresses
tag profiles, optimizes feature selection under a fixed qubit budget via QAOA,
and scores recommendations with a Quantum semi-Random Forest (QsRF) built on
just five qubits, while performing similarly to the state-of-the-art methods.
Leveraging SVD sketching and k-means, we learn a 1000-atom dictionary ($>$97 \%
variance), then solve a 2020 QUBO via depth-3 QAOA to select 5 atoms. A
100-tree QsRF trained on these codes matches full-feature baselines on
ICM-150/500.

</details>


### [264] [Hybrid Quantum Classical Surrogate for Real Time Inverse Finite Element Modeling in Digital Twins](https://arxiv.org/abs/2508.00029)
*Azadeh Alavi,Sanduni Jayasinghe,Mojtaba Mahmoodian,Sam Mazaheri,John Thangarajah,Sujeeva Setunge*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large-scale civil structures, such as bridges, pipelines, and offshore
platforms, are vital to modern infrastructure, where unexpected failures can
cause significant economic and safety repercussions. Although finite element
(FE) modeling is widely used for real-time structural health monitoring (SHM),
its high computational cost and the complexity of inverse FE analysis, where
low dimensional sensor data must map onto high-dimensional displacement or
stress fields pose ongoing challenges. Here, we propose a hybrid quantum
classical multilayer perceptron (QMLP) framework to tackle these issues and
facilitate swift updates to digital twins across a range of structural
applications.
  Our approach embeds sensor data using symmetric positive definite (SPD)
matrices and polynomial features, yielding a representation well suited to
quantum processing. A parameterized quantum circuit (PQC) transforms these
features, and the resultant quantum outputs feed into a classical neural
network for final inference. By fusing quantum capabilities with classical
modeling, the QMLP handles large scale inverse FE mapping while preserving
computational viability.
  Through extensive experiments on a bridge, we demonstrate that the QMLP
achieves a mean squared error (MSE) of 0.0000000000316, outperforming purely
classical baselines with a large margin. These findings confirm the potential
of quantum-enhanced methods for real time SHM, establishing a pathway toward
more efficient, scalable digital twins that can robustly monitor and diagnose
structural integrity in near real time.

</details>


### [265] [Dimension reduction with structure-aware quantum circuits for hybrid machine learning](https://arxiv.org/abs/2508.00048)
*Ammar Daskin*

Main category: quant-ph

TL;DR: 本文提出一种利用Schmidt分解和量子电路进行数据压缩和近似的方法。该方法通过量子电路实现数据的指数级压缩，有望减少大型模型的参数数量。实验结果表明该方法能有效压缩数据并提供k秩近似。


<details>
  <summary>Details</summary>
Motivation: Schmidt分解可以看作是向量形式的SVD。通过递归应用Schmidt分解和SVD到所有子系统，可以将向量写成二维向量张量积的线性组合。使用k个主要项可以得到向量的k秩近似，从而在去除噪声的同时保留向量最重要的部分。

Method: 通过递归应用Schmidt分解和SVD到所有子系统来分解向量。利用确定的k值设计的量子电路可以近似数据集的简化表示。将该电路ansatz与经典神经网络头结合构建混合机器学习模型。

Result: 实验结果证实了量子电路能够成功压缩数据，为经典处理组件提供有效的k秩近似。

Conclusion: 量子电路能够成功压缩数据，为经典处理组件提供有效的k秩近似。

Abstract: Schmidt decomposition of a vector can be understood as writing the singular
value decomposition (SVD) in vector form. A vector can be written as a linear
combination of tensor product of two dimensional vectors by recursively
applying Schmidt decompositions via SVD to all subsystems. Given a vector
expressed as a linear combination of tensor products, using only the $k$
principal terms yields a $k$-rank approximation of the vector. Therefore,
writing a vector in this reduced form allows to retain most important parts of
the vector while removing small noises from it, analogous to SVD-based
denoising.
  In this paper, we show that quantum circuits designed based on a value $k$
(determined from the tensor network decomposition of the mean vector of the
training sample) can approximate the reduced-form representations of entire
datasets. We then employ this circuit ansatz with a classical neural network
head to construct a hybrid machine learning model. Since the output of the
quantum circuit for an $2^n$ dimensional vector is an $n$ dimensional
probability vector, this provides an exponential compression of the input and
potentially can reduce the number of learnable parameters for training
large-scale models. We use datasets provided in the Python scikit-learn module
for the experiments. The results confirm the quantum circuit is able to
compress data successfully to provide effective $k$-rank approximations to the
classical processing component.

</details>


### [266] [Free Independence and Unitary Design from Random Matrix Product Unitaries](https://arxiv.org/abs/2508.00051)
*Neil Dowling,Jacopo De Nardis,Markus Heinrich,Xhek Turkeshi,Silvia Pappalardi*

Main category: quant-ph

TL;DR: 本研究证明了随机矩阵乘积酉（RMPU）系综在多项式维度下可以高效复现量子混沌系统中的高阶OTOCs，揭示了其酉设计性质，并阐明了自由度涌现的机制。但研究也指出，要完全描述所有可观测量，需要超越现有酉设计范畴的复杂性。


<details>
  <summary>Details</summary>
Motivation: 理解复杂量子系统如何模拟随机性是量子混沌、热化和信息理论的核心问题。本研究旨在连接“时间反演对称性破缺”和“近似酉设计”这两个研究方向，通过研究随机矩阵乘积酉（RMPU）系综，来理解自由度如何从其中涌现，并阐明其与量子混沌多体系统热化过程的关系。

Method: 本研究主要采用理论分析和计算方法，研究了随机矩阵乘积酉（RMPU）系综的性质。通过证明RMPU系综能够复现高阶OTOCs的Haar值，并分析其酉设计的性质，以及精确计算其二阶框架势，来探究自由度涌现的机制。同时，研究也探讨了复现特定可观测量所需的条件，如体定律算符纠缠。

Result: 本研究证明，在多项式键维度下，RMPU系综可以复现高阶OTOCs的Haar值，这与混沌多体系统中的热化过程一致。研究还发现，RMPU系综本身构成一个酉设计，但其酉设计性质并不能完全解释平均OTOCs的行为和自由度的涌现。通过精确计算二阶框架势，研究表明RMPU系综在平均意义下也能达到Haar值，即使存在多项式偏差。然而，要复现无迹局部可观测量，需要满足体定律算符纠缠，这超出了高效可复现的随机酉特征范畴。

Conclusion: 本研究通过研究随机矩阵乘积酉（RMPU）系综，在多项式键维度下，成功复现了高阶OTOCs的Haar值，并证明了其酉设计的性质。研究还表明，RMPU系综在二阶框架势精确计算上，也能在多项式偏差下收敛到Haar值。然而，为了复现无迹局部可观测量，RMPU系综需要满足体定律算符纠缠，这超出了随机酉特征的可复现范围。本研究强调了在算符动力学背景下，需要完善酉设计的概念，为实现真正的量子优势提供指导，并阐明混沌多体系统涌现复杂性的机制。

Abstract: Understanding how complex quantum systems emulate randomness is central to
quantum chaos, thermalization, and information theory. In one setting,
out-of-time-ordered correlators (OTOCs) have recently been shown to probe
asymptotic freeness between Heisenberg operators: the non-commutative
generalization of statistical independence. In a distinct research direction,
the concept of approximate unitary designs have led to efficient constructions
of unitaries that look random according to forward-in-time protocols. Bridging
these two concepts, in this work we study the emergence of freeness from a
random matrix product unitary (RMPU) ensemble. We prove that, with only
polynomial bond dimension, these unitaries reproduce Haar values of
higher-order OTOCs for local, finite-trace observables -- precisely the
observables that lead to thermal correlations in chaotic many-body systems
according to the eigenstate thermalization hypothesis. The RMPU ensemble
provably forms a unitary design, but, we argue, this does not account for
average OTOC behavior and therefore the emergence of freeness. We further
compute the ensemble's frame potential exactly to second order, showing
convergence to Haar values also with polynomial deviations, indicating that
freeness is also reached on-average for global observables. On the other hand,
to reproduce the Haar-like OTOC value for local, traceless observables, the
considered ensemble requires volume-law operator entanglement. Such
correlations therefore lie beyond the paradigm of random unitary features which
can be replicated efficiently. Our results highlight the need to refine
previous notions of unitary designs in the context of operator dynamics,
guiding us towards protocols for genuine quantum advantage while shedding light
on the emergent complexity of chaotic many-body systems.

</details>


### [267] [Learning shadows to predict quantum ground state correlations](https://arxiv.org/abs/2508.00052)
*Pierre-Gabriel Rozon,Kartiek Agarwal*

Main category: quant-ph

TL;DR: 提出了一种基于影子断层扫描的变分方法，用于计算量子自旋哈密顿量的基态相关性，该方法通过优化一组参数化快照来降低能量，并能产生比现有方法更完整的基态描述。


<details>
  <summary>Details</summary>
Motivation: 为了计算量子自旋哈密顿量的基态相关性，并借鉴影子断层扫描可以从一组快照中高效重构期望值的思想。

Method: 提出了一种受经典影子断层扫描启发的变分方案，该方案使用一组参数化的快照来表示目标哈密顿量的假定基态，并通过降低能量来优化它。此外，还采用了非负性等附加约束，以确保预测的相关性与底层希尔伯特空间兼容。

Result: 数值结果表明，所提出的变分方法是可行的，并且比现有方法能更全面地描述基态。

Conclusion: 该方法可并行化、可高效模拟，并能产生比约束密度矩阵更完整的基态描述。

Abstract: We introduce a variational scheme inspired by classical shadow tomography to
compute ground state correlations of quantum spin Hamiltonians. Shadow
tomography allows for efficient reconstruction of expectation values of
arbitrary observables from a bag of repeated, randomized measurements, called
snapshots, on copies of the state $\rho$. The prescription allows one to infer
expectation values of $M$ $k-$local observables to accuracy $\epsilon$ using
just $N \sim 3^k \text{log}M /\epsilon^2$ snapshots when measurements are
performed in locally random bases. Turning this around, a bag of snapshots can
be considered an efficient representation of the state $\rho$, particularly for
estimating low-weight observables, such as terms in a local Hamiltonian needed
to estimate the energy. Inspired by this, we consider a variational scheme
wherein a bag of $N$ parametrized snapshots is used to represent the putative
ground state of a desired local spin Hamiltonian and optimized to lower the
energy with respect to it. Additional constraints in the form of positivity of
reduced density matrices, motivated by work in quantum chemistry, are employed
to ensure compatibility of the predicted correlations with the underlying
Hilbert space. Unlike reduced density matrix approaches, learning the
underlying distribution of measurement outcomes allows one to further
correlations beyond those in the constrained density matrix. We show, with
numerical results, that the proposed variational method can be parallelized, is
efficiently simulable, and yields a more complete description of the ground
state.

</details>


### [268] [Effective 2D Envelope Function Theory for Silicon Quantum Dots](https://arxiv.org/abs/2508.00139)
*Christian W. Binder,Guido Burkard,Andrew J. Fisher*

Main category: quant-ph

TL;DR: "A new 2D theory for quantum dots accurately simplifies 3D systems, revealing valley physics and saving computation time, outperforming simpler methods, especially with rough interfaces."


<details>
  <summary>Details</summary>
Motivation: "The motivation is to develop a rigorous method to reduce the complexity of 3D quantum dot descriptions to a more computationally tractable 2D envelope function theory for electron spin qubits. This aims to improve simulation efficiency, particularly for multi-electron systems, and gain conceptual clarity on the role of valley physics in qubit operations."

Method: "A rigorous method is presented to reduce the 3D description of a quantum dot in silicon to an effective 2D envelope function theory. This is achieved by systematically integrating out the vertical dimension using a Born-Oppenheimer-inspired ansatz at the envelope-function level, deriving an effective in-plane potential. The method considers the lowest two eigenstates of the out-of-plane direction, leading to the emergence of the valley degree of freedom within a 2D formalism."

Result: "The method derives an effective in-plane potential that captures the essential electrostatics of the full 3D system. The reduction in dimensionality naturally incorporates the valley degree of freedom. Validation through comparisons with full 3D simulations shows accuracy and superiority over naive 2D slicing, especially with interface roughness. Significant computational savings are achieved."

Conclusion: "The presented rigorous 2D envelope function theory, derived from first principles, incorporates valley physics in a physically grounded manner, offering conceptual clarity on the role of valley states in qubit operation and measurement. It also provides substantial computational savings, making it well-suited for simulating two-electron systems and extracting parameters like exchange coupling."

Abstract: We present a rigorous method to reduce the three-dimensional (3D) description
of a quantum dot in silicon to an effective two-dimensional (2D) envelope
function theory for electron spin qubits. By systematically integrating out the
strongly confined vertical dimension using a Born-Oppenheimer-inspired ansatz
at the envelope-function level, we derive an effective in-plane potential that
faithfully captures the essential electrostatics of the full 3D system.
Considering the lowest two eigenstates of the out-of-plane direction, this
reduction leads to the natural and explicit emergence of the valley degree of
freedom within a 2D formalism, which is derived here from first principles. We
validate the accuracy of the method through comparisons with full 3D
simulations and demonstrate its superiority over naive 2D slicing, particularly
in the presence of interface roughness. Crucially, the reduction in
dimensionality leads to substantial computational savings, making our approach
particularly well suited for simulating two-electron systems, e.g., for the
extraction of parameters such as the exchange coupling. Beyond its practical
utility, the rigorous 2D envelope function theory that is introduced in this
study incorporates valley physics in a physically grounded manner, offering
conceptual clarity on the role of valley states in qubit operation and
measurement.

</details>


### [269] [Truncation uncertainties for accurate quantum simulations of lattice gauge theories](https://arxiv.org/abs/2508.00061)
*Anthony N. Ciavarella,Siddharth Hariprakash,Jad C. Halimeh,Christian W. Bauer*

Main category: quant-ph

TL;DR: 利用希尔伯特空间碎裂来估计量子计算机上格点规范场论的截断误差，精度显著提高。


<details>
  <summary>Details</summary>
Motivation: 格点规范场论在量子计算机上的编码需要在每个链路上对规范场进行希尔伯特空间离散化，这在Kogut-Susskind极限下会引入误差。

Method: 提出了一种利用希尔伯特空间碎裂来估计电基中的截断误差的算法。

Result: 与以前的误差估计相比，该方法在合理的参数选择下，误差估计精度提高了10^306数量级。

Conclusion: 该方法通过利用希尔伯特空间碎裂来估计电基中的截断误差，并已成功应用于薛定谔模型和纯U(1)格点规范场论。

Abstract: The encoding of lattice gauge theories onto quantum computers requires a
discretization of the gauge field's Hilbert space on each link, which presents
errors with respect to the Kogut--Susskind limit. In the electric basis,
Hilbert space fragmentation has recently been shown to limit the excitation of
large electric fields. Here, we leverage this to develop a formalism for
estimating the size of truncation errors in the electric basis. Generically,
the truncation error falls off as a factorial of the field truncation. Examples
of this formalism are applied to the Schwinger model and a pure U(1) lattice
gauge theory. For reasonable choices of parameters, we improve on previous
error estimates by a factor of 10^{306}.

</details>


### [270] [Replacement-Type Quantum Gates](https://arxiv.org/abs/2508.00437)
*Florian Ginzel,Javad Kazemi,Valentin Torggler,Wolfgang Lechner*

Main category: quant-ph

TL;DR: 提出了一种新的量子门类型——替换型量子门，它能近似保持量子比特的噪声偏差，为高级量子计算架构提供了基础。


<details>
  <summary>Details</summary>
Motivation: 为了提出一种能够近似保持量子比特固有噪声偏差的新型量子门，以支持具有纠错功能的高级量子计算机架构。

Method: 提出并实现了替换型量子门（replacement-type quantum gates），包括替换型X门和CNOT门。利用自旋量子比特和中性原子量子比特作为物理实现，并通过扩展希尔伯特空间（包含粒子位置）来近似保持量子比特的固有噪声偏差。

Result: 成功实现了替换型X门和CNOT门，并证明了它们能够近似保持量子比特的固有噪声偏差。这种特性对于设计具有纠错能力的高级量子计算机架构具有重要意义。

Conclusion: 该研究提出了替换型量子门，这种门通过引入输入、候选和输出量子比特，并利用候选量子比特的位移操作来实现目标输出态，最终用输出量子比特替代输入量子比特。研究展示了在自旋量子比特和中性原子量子比特上实现的替换型X门和CNOT门。利用包含粒子位置的扩展希尔伯特空间，这些门能够近似保持量子比特的固有噪声偏差，这为具有纠错功能的高级量子计算机架构提供了新的思路。

Abstract: We introduce the paradigm of replacement-type quantum gates. This type of
gate introduces input qubits, candidate qubits, and output qubits. The
candidate qubits are prepared such, that a displacement conditional on the
input qubit results in the targeted output state. Finally, the circuit
continues with the output qubits constructed from the candidate qubits instead
of the input qubits, thus the name "replacement-type gate". We present examples
of replacement-type $X$ and $\mathrm{CNOT}$ gates realized with spin qubits and
with neutral atom qubits. By making use of the extended Hilbert space,
including the position of the particles, these gates approximately preserve the
innate noise bias of the qubits. The gate preserves the noise-bias which
motivates advanced quantum computer architectures with error correction.

</details>


### [271] [Imaginary Time Spectral Transforms for Excited State Preparation](https://arxiv.org/abs/2508.00065)
*D. A. Millar,L. W. Anderson,E. Altamura,O. Wallis,M. E. Sahin,J. Crain,S. J. Thomson*

Main category: quant-ph

TL;DR: A new approach combining shift-invert and imaginary time evolution to find excited states of quantum systems, demonstrated on spin chains and applicable to quantum hardware.


<details>
  <summary>Details</summary>
Motivation: Unlike ground states, there are few systematic ways to construct excited states of generic quantum systems on either classical or quantum hardware.

Method: By combining the shift-invert mechanism with imaginary time evolution, we avoid explicit inversion of the Hamiltonian and construct excited eigenstates of large many-body quantum systems.

Result: We demonstrate the technique classically by applying it to large disordered spin chains.

Conclusion: We propose a hybrid scheme suitable for near-future quantum hardware based on our approach.

Abstract: Excited states of many-body quantum systems play a key role in a wide range
of physical and chemical phenomena. Unlike ground states, for which many
efficient variational techniques exist, there are few ways to systematically
construct excited states of generic quantum systems on either classical or
quantum hardware. To address this challenge, we introduce a general approach
that allows us to obtain arbitrary eigenstates of quantum systems at a given
energy. By combining the shift-invert mechanism with imaginary time evolution,
we are able to avoid explicit inversion of the Hamiltonian and construct
excited eigenstates of large many-body quantum systems. We demonstrate the
technique classically by applying it to large disordered spin chains. Based on
this approach, we propose a hybrid scheme suitable for near-future quantum
hardware.

</details>


### [272] [Coexistence of Entanglement-based Quantum Channels with DWDM Classical Channels over Hollow Core Fibre in a Four Node Quantum Communication Network](https://arxiv.org/abs/2508.00072)
*Marcus J Clark,Obada Alia,Sima Bahrani,Gregory T Jasion,Hesham Sakr,Periklis Petropoulos,Francesco Poletti,George T Kanellos,John Rarity,Reza Nejabati,Siddarth K Joshi,Rui Wang,Dimitra Simeonidou*

Main category: quant-ph

TL;DR: Quantum and classical communication successfully coexisted in a 4-user network over 11.5km fibre, achieving high-speed classical transmission and secure quantum key distribution with stable performance.


<details>
  <summary>Details</summary>
Motivation: To demonstrate the feasibility of integrating quantum communication channels with existing classical optical infrastructure within a multi-user network setting, overcoming challenges related to channel coexistence and performance.

Method: Experimental demonstration of coexistence of quantum and classical channels in a hollow core fibre quantum network, employing Bell state measurements for quantum key distribution and monitoring secret key rates over time.

Result: Achieved coexistence of three quantum channels and four classical channels (800Gbps) in the C-band over 11.5km fibre. Quantum key distribution achieved Bell state fidelity up to 90.0±0.8%, with secret key rates preserved over 55 hours.

Conclusion: The paper successfully demonstrates the coexistence of three entanglement-based quantum channels with carrier-grade classical optical channels in a four-user quantum network over 11.5km of hollow core fibre. It achieved 800Gbps for classical channels and high fidelity quantum key distribution (up to 90.0±0.8%) with preserved secret key rates over 55 hours.

Abstract: We experimentally demonstrate the coexistence of three entanglement-based
quantum channels with carrier-grade classical optical channels over $11.5$km
hollow core nested antiresonant nodeless fibre, in a four user quantum network.
A transmission of $800$Gbps is achieved with four classical channels
simultaneously with three quantum channels all operating in the C-band with a
separation of $1.2$nm, with aggregated coexistence power of $-3$dBm. We
established quantum key distribution in the four-node full-mesh quantum network
with Bell state fidelity of up to $90.0\pm0.8$%. The secret key rate for all
the links in the network are passively preserved over $55$hours of experimental
time.

</details>


### [273] [Efficient and simple Gibbs state preparation of the 2D toric code via duality to classical Ising chains](https://arxiv.org/abs/2508.00126)
*Pablo Páez-Velasco,Niclas Schilling,Samuel O. Scalet,Frank Verstraete,Ángela Capel*

Main category: quant-ph

TL;DR: 通过多深度对偶变换构建量子哈密顿量的吉布斯采样器，并证明了其对2D表面码和伊辛自旋链的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了构建各种量子哈密顿量的有效吉布斯采样器，因为它们在多深度上与经典哈密顿量对偶。

Method: 提出多深度对偶变换的概念，该变换通过多深度量子电路的共轭关系将两组算子代数联系起来。

Result: 证明了2D表面码在多深度上与两个分离的经典伊辛自旋链对偶，无论系统大小如何。

Conclusion: 多深度对偶变换被证明可以保持混合时间、谱隙和修正后的对数-Sobolev不等式等量

Abstract: We introduce the notion of polynomial-depth duality transformations, which
relates two sets of operator algebras through a conjugation by a poly-depth
quantum circuit, and make use of this to construct efficient Gibbs samplers for
a variety of interesting quantum Hamiltonians as they are poly-depth dual to
classical Hamiltonians. This is for example the case for the 2D toric code,
which is demonstrated to be poly-depth dual to two decoupled classical Ising
spin chains for any system size, and we give evidence that such dualities hold
for a wide class of stabilizer Hamiltonians. Additionally, we extend the above
notion of duality to Lindbladians in order to show that mixing times and other
quantities such as the spectral gap or the modified logarithmic Sobolev
inequality are preserved under duality.

</details>


### [274] [Breakdown of Fermi's Golden Rule in 1d systems at non-zero temperature](https://arxiv.org/abs/2508.00254)
*Thomas Young,Jerome LLoyd,Curt von Keyserlingk*

Main category: quant-ph

TL;DR: 对于一维费米子系统，弱相互作用下的准粒子寿命与其衰减率的关系尚不明确。本研究提出了一种结合数值模拟和图重求和的方法，预测衰减率会以 $\\\log$ 的方式增强，即 $\\\tau^{-1} \\sim \\Delta^{2} \\log \\Delta^{-2}$。


<details>
  <summary>Details</summary>
Motivation: 在相互作用量子系统中，单粒子格林函数预期会因相互作用诱导的准粒子退相干而在时间上衰减。对于弱相互作用强度（$\	riangle$）的极限，费米黄金定则（FGR）预测准粒子衰减率为 $\\"(\	riangle^{2})\\$。然而，对于一维费米子在 $T>0$ 的格点上，该计算结果发散，准粒子寿命与相互作用强度的关系仍然是一个悬而未决的问题。

Method: 结合了耗散辅助算符演化（DAOE）数值模拟和非微扰图重求和。

Result: 预测准粒子衰减率的对数增强：$\	au^{-1} \\sim \\Delta^{2} \\log \\Delta^{-2}$，并且认为该效应存在于多种弱相互作用的量子费米子和玻色子系统，甚至一些经典系统中。

Conclusion: 该研究提出了一个结合了耗散辅助算符演化（DAOE）数值模拟和非微扰图重求和的方法，预测了准粒子衰减率的对数增强，即 $	au^{-1} \sim \Delta^{2} \log \Delta^{-2}$。研究认为这种效应存在于多种弱相互作用的量子费米子和玻色子系统，甚至一些经典系统中，前提是其非相互作用极限下的准粒子具有通用的色散。

Abstract: In interacting quantum systems, the single-particle Green's function is
expected to decay in time due to the interaction induced decoherence of
quasiparticles. In the limit of weak interaction strengths ($\Delta$), a naive
application of Fermi's Golden Rule (FGR) predicts an $\mathcal{O}(\Delta^{2})$
quasiparticle decay rate. However, for 1d fermions on the lattice at $T>0$,
this calculation gives a divergent result and the scaling of the quasiparticle
lifetime with interaction strength remains an open question. In this work we
propose a solution to this question: combining numerical simulations using the
recently introduced dissipation-assisted operator evolution (DAOE) method, with
non-perturbative diagrammatic re-summations, we predict a logarithmic
enhancement of the quasiparticle decay rate $\tau^{-1} \sim \Delta^{2} \log
\Delta^{-2}$. We argue that this effect is present in a wide variety of
well-known weakly interacting quantum fermionic and bosonic systems, and even
in some classical systems, provided the non-interacting limit has
quasiparticles with a generic dispersion.

</details>


### [275] [Towards Efficient Verification of Computation in Quantum Devices](https://arxiv.org/abs/2508.00262)
*Keren Li,Peng Yan,Hanru Jiang,Nengkun Yu*

Main category: quant-ph

TL;DR: A new verification method for quantum computers significantly speeds up testing by using the device's structure, achieving double logarithmic scaling and validated on IBM's cloud service.


<details>
  <summary>Details</summary>
Motivation: Traditional verification methods like quantum process tomography are limited by exponential resource growth due to treating quantum devices as black boxes and ignoring their design structure. New testing methods are needed that consider the design structure for effective verification of quantum processors.

Method: The paper investigates the structure of computations on hardware, focusing on the layered interruptible quantum circuit model. It designs a scalable algorithm to verify this model comprehensively by reconstructing circuits within a time complexity of O(d^2 t log(n/δ)), with success probability at least 1-δ, where t is the maximum execution time per layer.

Result: The developed algorithm completely reconstructs quantum circuits within a time complexity of O(d^2 t log(n/δ)), achieving double logarithmic scaling in problem size. Experiments on IBM's quantum cloud service validated the algorithm's applicability in the noisy intermediate-scale quantum era.

Conclusion: The paper proposes a new verification method for quantum processors that leverages the design structure, specifically the layered interruptible quantum circuit model. This method offers a scalable algorithm with a time complexity of O(d^2 t log(n/δ)) for reconstructing unknown n-qubit, d-layer circuits, achieving double logarithmic scaling in problem size and significantly reducing verification execution time. The approach was validated through experiments on IBM's quantum cloud service.

Abstract: Designing quantum processors is a complex task that demands advanced
verification methods to ensure their correct functionality. However,
traditional methods of comprehensively verifying quantum devices, such as
quantum process tomography, face significant limitations because of the
exponential growth in computational resources. These limitations arise from
treating the system as a black box and ignoring its design structure.
Consequently, new testing methods must be developed considering the design
structure. In this paper, we investigate the structure of computations on the
hardware, focusing on the layered interruptible quantum circuit model and
designing a scalable algorithm to verify it comprehensively. Specifically, for
a given quantum hardware that claims to process an unknown $n$ qubit $d$ layer
circuit via a finite set of quantum gates, our method completely reconstructs
the circuits within a time complexity of $O(d^2 t \log (n/\delta))$,
guaranteeing success with a probability of at least $1-\delta$. Here, $t$
represents the maximum execution time for each circuit layer. Our approach
significantly reduces execution time for completely verifying computations in
quantum devices, achieving double logarithmic scaling in the problem size.
Furthermore, we validate our algorithm through experiments using IBM's quantum
cloud service, demonstrating its potential applicability in the noisy
intermediate-scale quantum era.

</details>


### [276] [Entangling Power and Its Deviation: A Quantitative Analysis on Input-State Dependence and Variability in Entanglement Generation](https://arxiv.org/abs/2508.00301)
*Kyoungho Cho,Jeongho Bang*

Main category: quant-ph

TL;DR: EPD作为纠缠能力的补充度量，揭示了纠缠能力与状态敏感性之间的权衡以及维度奇偶性对纠缠生成的影响。


<details>
  <summary>Details</summary>
Motivation: 现有的纠缠能力（EP）指标无法捕捉纠缠生成的输入状态依赖性，需要一个补充指标来全面表征纠缠行为。

Method: 提出纠缠能力偏差（EPD）作为衡量标准，并建立了一个通用的群论框架来推导EP和EPD的闭合表达式，将框架推广到任意维度二分希尔伯特空间的广义酉操作。

Result: 开发了EPD度量，揭示了纠缠能力与状态敏感性之间的基本权衡，并发现相同的EP可能对应不同的EPD，表明物理实现影响纠缠生成性质；发现维度奇偶性依赖的纠缠生成行为。

Conclusion: EPD与EP相辅相成，是量化量子操作纠缠能力的必要补充，揭示了增强纠缠能力与状态敏感性之间的固有权衡，并发现了维度奇偶性依赖的纠缠生成行为。

Abstract: Quantifying the entangling capability of quantum operations is a fundamental
task in quantum information science. Traditionally, this capability is measured
by the entangling power (EP), defined as the average entanglement generated
when a quantum operation acts uniformly on all possible product states.
However, EP alone cannot capture the intricate input-state-dependent nature of
entanglement generation. To address this, we define a complementary metric --
entangling power deviation (EPD) -- as the standard deviation of entanglement
generated over all product input states, thereby capturing the multifaceted
nature of entangling behavior. We develop a general group-theoretical framework
that yields closed-form expressions for both EP and EPD. Our analysis reveals a
fundamental and previously unexplored physics: enhancing entangling capability
inevitably increases sensitivity, or bias, toward specific input states. By
analyzing representative two-qubit gates, we show that the gates with identical
EP can exhibit markedly different EPD values, illustrating that the nature of
entanglement generation can significantly differ depending on physical
implementation. Extending our framework to a class of generalized
controlled-unitary operations acting on bipartite Hilbert spaces of arbitrary
dimensions, we (re)affirm the inherent trade-off between the entangling
strength and uniformity. Moreover, we uncover a subtle
dimension-parity-dependent behavior in entanglement generation, which EP alone
fails to detect. These findings highlight EPD as an indispensable diagnostic
tool -- one that, alongside EP, provides a deeper and more complete
characterization of the entangling structure.

</details>


### [277] [Enhancement of non-Markovianity due to environment-induced indirect interaction](https://arxiv.org/abs/2508.00320)
*Asif Zaman,Muhammad Faryad,Adam Zaman Chaudhry*

Main category: quant-ph

TL;DR: 多量子比特系统与共同环境相互作用时，可增强非马尔可夫效应，增加量子比特数量可进一步增强此效应，这在量子技术中有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 探究在多量子比特系统中，由于与共同环境的相互作用，非马尔可夫效应的增强机制及其与单量子比特系统的对比。

Method: 通过解析推导多量子比特系统的动力学演化，并对除一个量子比特外的所有量子比特进行偏迹，研究剩余单个量子比特的非马尔可夫动力学。

Result: 即使在弱耦合区，多量子比特系统也表现出显著的非马尔可夫动力学，且非马尔可夫性随量子比特数量的增加而增强。这与单量子比特系统在某些环境下的马尔可夫动力学行为形成对比。

Conclusion: 该研究表明，在多量子比特系统中，通过与共同环境的相互作用，可以显著增强非马尔可夫效应，甚至在弱耦合区也能观察到。研究结果为控制多量子比特退相干提供了新思路，并可能在量子技术中将非马尔可夫性作为一种资源加以利用。

Abstract: Non-Markovian effects are often significant when the system-environment
coupling is not weak. Indeed, we find the non-Markovianity to be negligible for
a single two-level system undergoing pure dephasing via interaction with a
harmonic oscillator environment. In this paper, we examine a natural extension,
namely a pure dephasing model where a collection of two-level systems interacts
with a common environment. We obtain analytically the dynamics of the
collection of the two-level systems, and then take a partial trace over all the
two-level systems except one. This remaining single two-level system is shown
to display markedly non-Markovian dynamics, even in the weak system-environment
coupling regime. This is due to the indirect interaction between two-level
systems induced by their interaction with the common environment. In fact, this
indirect interaction can not only increase the non-Markovianity by orders of
magnitude, but also display qualitatively different characteristics. For
instance, for a single two-level system undergoing pure dephasing, the dynamics
are Markovian for Ohmic and sub-Ohmic environments. This is markedly not the
case when we consider multiple two-level systems. We also show that the
non-Markovianity increases as we increase the number of two-level systems.
These findings provide insights into controlling decoherence in multi-qubit
quantum systems and have implications for quantum technologies where
non-Markovianity can be a resource rather than a limitation.

</details>


### [278] [Mixed State Entanglement Via the Cauchy-Schwarz Inequality](https://arxiv.org/abs/2508.00334)
*Nishaant Jacobus,Paul Brumer,Chern Chuang*

Main category: quant-ph

TL;DR: CSV条件是一种新的纠缠度量方法，它比现有的方法更易于应用，并且与系统的物理性质有更直接的联系。


<details>
  <summary>Details</summary>
Motivation: 现有的纠缠度量方法（如负熵）在开放量子系统和量子信息科学中难以应用或与物理性质联系起来。因此，需要一种新的、更易于应用且与物理性质联系更紧密的纠缠度量方法。

Method: CSV条件是一种新的纠缠度量方法，它基于密度算符的布居数和相干性，具有简单的数学依赖性。

Result: CSV条件在Jaynes-Cummings模型、量子Rabi模型和开放系统量子Rabi模型中的应用，揭示了其在理解和分析这些模型中的纠缠性质方面的有效性。

Conclusion: CSV条件是一种充分条件，用于判断混合态是否具有纠缠性，并且与系统的物理特性（如对称性）有更直接的联系。

Abstract: The entanglement properties of mixed states are of great importance in the
study of open quantum systems and quantum information science, but commonly
used entanglement measures, such as negativity, can be difficult to apply or
connect to physical properties of the system. We introduce the Cauchy-Schwarz
Violation (CSV) Condition, which has a simple dependence on the populations and
coherences of the density operator. A sufficient condition for entanglement, it
provides a more direct connection to the physical characteristics of the system
such as its symmetries. We illustrate the often surprising insights gained from
the CSV condition by applying it to the Jaynes-Cummings Model, the Quantum Rabi
Model, and an open-system Quantum Rabi Model.

</details>


### [279] [Truncating loopy tensor networks by zero-mode gauge fixing](https://arxiv.org/abs/2508.00338)
*Ihor Sokolov,Yintai Zhang,Jacek Dziarmaga*

Main category: quant-ph

TL;DR: 卷曲张量网络的压缩可以通过优化局部键和利用状态的度量张量的零模来改进，从而减少截断误差。


<details>
  <summary>Details</summary>
Motivation: 卷曲张量网络内部的关联性常常导致其压缩效率低下。该方法旨在通过利用局部键优化来更好地利用其对局部相关循环的洞察力来解决这个问题。

Method: 通过切割 the bond，定义一组状态，并利用这些状态的度量张量的零模来消除线性依赖性，从而实现对卷曲张量网络的压缩。

Result: 该方法在iPEPS和pMPS的示例中，提供了比标准初始化更好的初始截断误差。

Conclusion: 通过消除零模，该方法可以消除线性依赖性，从而在iPEPS和pMPS的初始截断误差方面优于标准初始化。

Abstract: Loopy tensor networks have internal correlations that often make their
compression inefficient. We show that even local bond optimization can make
better use of the insight it has locally into relevant loop correlations. By
cutting the bond, we define a set of states whose linear dependence can be used
to truncate the bond dimension. The linear dependence is eliminated with zero
modes of the states' metric tensor. The method is illustrated by a series of
examples for the infinite pair entangled projected state (iPEPS) and for the
periodic matrix product state (pMPS) that occurs in the tensor renormalization
group (TRG) step. In all examples, it provides better initial truncation errors
than standard initialization.

</details>


### [280] [Nonclassical microwave radiation from the parametric dynamical Casimir effect in the reversed-dissipation regime of circuit optomechanics](https://arxiv.org/abs/2508.00353)
*H. Solki,Ali Motazedifard,M. H. Naderi,A. Youssefi,R. Roknizadeh*

Main category: quant-ph

TL;DR: 该研究提出了一个在反耗散体制（RDR）下的光学机械系统（OMS），通过激光频率调制实现了参数动力学 Casimir 效应（parametrically-DCE），产生了具有非经典特征（如亚泊松统计）的 Casimir 光子，并展示了其在量子技术中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了在反耗散体制（RDR）下，利用光学机械系统（OMS）实现量子真空涨落的参数放大，并产生具有非经典特性的 Casimir 光子，以应用于量子信息处理、量子计算和微波量子传感。

Method: 提出一个实验上可行的光学机械系统（OMS），该系统采用色散驱动并在反耗散体制（RDR）下运行，其中机械阻尼率远超腔衰减率。通过对驱动激光频率进行相干、快时间调制，在长于机械退相干时间的相干时间尺度上，实现了机械模式的绝热消除，从而对腔内场的量子真空涨落产生强烈的参数放大，即参数动力学 Casimir 效应（parametrically-DCE），导致 Casimir 光子的产生。

Result: 在反耗散体制（RDR）下，系统哈密顿量（包括 DCE 项）被广义的光学机械 Kerr 型非线性内在地修改。这种非线性不仅在短时间尺度上使辐射的 Casimir 光子的平均数量饱和（即使在没有耗散的情况下），还引起了其动力学和量子特性的振荡行为。Kerr 非线性的存在使得产生的 DCE 光子表现出非经典特征，如低于泊松统计、负 Wigner 函数和象限压缩，这些都可以通过调整系统参数来控制。

Conclusion: 所提出的反耗散体制下的光学机械系统，利用激光频率的相干快时调制，能够产生具有非经典特性的 Casimir 光子，可用于量子信息处理、量子计算和微波量子传感。

Abstract: We propose an experimentally feasible optomechanical system (OMS) that is
dispersively driven and operates in the reversed dissipation regime (RDR),
where the mechanical damping rate far exceeds the cavity decay rate. We
demonstrate that coherent, fast-time modulation of the driving laser
frequency-on time scales longer than the mechanical decoherence time-allows for
adiabatic elimination of the mechanical mode, resulting in strong parametric
amplification of quantum vacuum fluctuations of the intracavity field. This
mechanism, known as the parametric dynamical Casimir effect (parametric-DCE),
leads to the generation of Casimir photons. In the dispersive RDR, we find that
the total system Hamiltonian-including the DCE term-is intrinsically modified
by a generalized optomechanical Kerr-type nonlinearity. This nonlinearity not
only saturates the mean number of radiated Casimir photons on short time
scales, even without dissipation, but also induces oscillatory behavior in
their dynamics and quantum characteristics. Remarkably, the presence of the
Kerr nonlinearity causes the generated DCE photons to exhibit nonclassical
features, including sub-Poissonian statistics, negative Wigner function and
quadrature squeezing which can be controlled by adjusting the system
parameters. The proposed nonclassical microwave radiation source possesses the
potential to be applied in quantum information processing, quantum computing as
well as microwave quantum sensing.

</details>


### [281] [Reducing Quantum Circuit Synthesis to #SAT](https://arxiv.org/abs/2508.00416)
*Dekel Zak,Jingyi Mei,Jean-Marie Lagniez,Alfons Laarman*

Main category: quant-ph

TL;DR: 将量子电路合成问题规约为最大模型计数问题，并使用改进的经典工具d4Max进行求解，结果显示经典工具在此问题上具有潜力。


<details>
  <summary>Details</summary>
Motivation: 探索使用模型计数（#SAT）方法解决量子电路分析中的核心问题，特别是量子电路合成问题。

Method: 通过将量子电路合成问题（包括精确和近似的深度最优合成）规约为最大模型计数问题（#SAT），并使用d4Max作为后端进行评估。

Result: 实验结果表明，现有的经典工具（特别是d4Max，已扩展支持复数和负数权重）在解决量子电路合成问题方面具有潜力。

Conclusion: 该研究首次表明，通用量子电路合成问题可以归约到最大模型计数问题，并为精确和近似深度最优量子电路合成到Clifford+T门集提供了#SAT编码。

Abstract: Quantum circuit synthesis is the task of decomposing a given quantum operator
into a sequence of elementary quantum gates. Since the finite target gate set
cannot exactly implement any given operator, approximation is often necessary.
Model counting, or #SAT, has recently been demonstrated as a promising new
approach for tackling core problems in quantum circuit analysis. In this work,
we show for the first time that the universal quantum circuit synthesis problem
can be reduced to maximum model counting. We formulate a #SAT encoding for
exact and approximate depth-optimal quantum circuit synthesis into the
Clifford+T gate set. We evaluate our method with an open-source implementation
that uses the maximum model counter d4Max as a backend. For this purpose, we
extended d4Max with support for complex and negative weights to represent
amplitudes. Experimental results show that existing classical tools have
potential for the quantum circuit synthesis problem.

</details>


### [282] [Quantum Key-Recovery Attacks on FBC Algorithm](https://arxiv.org/abs/2508.00448)
*Yan-Ying Zhu,Bin-Bin Cai,Fei Gao,Song Lin*

Main category: quant-ph

TL;DR: 本文研究了FBC算法在量子计算攻击下的安全性。在Q2模型中，实现了比量子暴力搜索更快的密钥恢复攻击。在Q1模型中，使用Grover算法实现了低数据攻击。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算技术的飞速发展，传统的对称密码算法面临着来自量子计算机的潜在威胁。理解并量化这种威胁对于设计和评估抵抗量子攻击的密码算法至关重要。本文旨在深入分析FBC算法在量子计算环境下的安全性，特别是针对其在两种主要量子攻击模型（Q1和Q2）下的脆弱性。

Method: 本文提出了一种基于量子算法的FBC密码分析方法。在Q2模型下，我们设计了针对FBC-F和FBC-KF结构的4轮量子区分器，并基于此进行了r(r>6)轮量子密钥恢复攻击，其查询复杂度为O(2^((2n(r-6)+3n)/2))。同时，我们还为FBC-FK结构设计了一个新的6轮量子区分器，并实现了r(r>6)轮量子密钥恢复攻击，复杂度为O(2^(n(r-6)))。在Q1模型下，我们利用Grover算法对中间状态进行搜索，实现了对FBC-KF/FK结构的低数据量子密钥恢复攻击，仅需常数对明文-密文即可在O(2^(n/2))时间内恢复密钥。

Result: 在Q2模型下，针对FBC-F和FBC-KF结构，本文成功实现了r(r>6)轮量子密钥恢复攻击，其查询复杂度为O(2^((2n(r-6)+3n)/2))，相比量子暴力搜索有2^(4.5n)倍的提升。对于FBC-FK结构，攻击复杂度为O(2^(n(r-6)))。在Q1模型下，本文实现了仅需常数对明文-密文的低数据量子密钥恢复攻击，时间复杂度为O(2^(n/2))。

Conclusion: 本文对FBC算法在量子计算背景下的对称密码分析进行了全面的研究。针对不同的量子攻击模型（Q1和Q2），我们设计了多轮量子区分器，并实现了高效的量子密钥恢复攻击。研究结果表明，在Q2模型下，我们的攻击在查询复杂度上相比量子暴力搜索有显著降低；在Q1模型下，我们提出的低数据攻击也展示了FBC算法在面对量子计算时的潜在弱点。

Abstract: With the advancement of quantum computing, symmetric cryptography faces new
challenges from quantum attacks. These attacks are typically classified into
two models: Q1 (classical queries) and Q2 (quantum superposition queries). In
this context, we present a comprehensive security analysis of the FBC algorithm
considering quantum adversaries with different query capabilities. In the Q2
model, we first design 4-round polynomial-time quantum distinguishers for FBC-F
and FBC-KF structures, and then perform $r(r>6)$-round quantum key-recovery
attacks. Our attacks require $O(2^{(2n(r-6)+3n)/2})$ quantum queries, reducing
the time complexity by a factor of $2^{4.5n}$ compared with quantum brute-force
search, where $n$ denotes the subkey length. Moreover, we give a new 6-round
polynomial-time quantum distinguisher for FBC-FK structure. Based on this, we
construct an $r(r>6)$-round quantum key-recovery attack with complexity
$O(2^{n(r-6)})$. Considering an adversary with classical queries and quantum
computing capabilities, we demonstrate low-data quantum key-recovery attacks on
FBC-KF/FK structures in the Q1 model. These attacks require only a constant
number of plaintext-ciphertext pairs, then use the Grover algorithm to search
the intermediate states, thereby recovering all keys in $O(2^{n/2})$ time.

</details>


### [283] [Inference of maximum parsimony phylogenetic trees with model-based classical and quantum methods](https://arxiv.org/abs/2508.00468)
*Jiawei Zhang,Yibo Chen,Yang Zhou,Jun-Han Huang*

Main category: quant-ph

TL;DR: 该研究通过设计新的优化模型，解决了最大简约性系统发育树重建的NP难问题。研究表明，其基于分支的模型在经典和量子计算上都表现出色，特别是在量子计算方面，为解决进化生物学中的难题提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 最大简约性系统发育树重建问题的NP难性是经典计算的瓶颈，促使人们探索量子计算等新兴范式。

Method: 设计了三个适用于经典和量子求解器的优化模型，直接搜索所有可能的树拓扑和祖先状态，其中基于分支的模型通过特定的变量定义，减少了变量和显式约束的数量。

Result: 在GAPDH基因数据集上，经典求解器获得了比启发式方法更好的解。量子模拟在小规模实例上以快速收敛成功找到精确的最优解。

Conclusion: 量子计算有潜力为进化生物学中棘手的推断问题提供新的解决方案，并在小规模实例上成功找到精确的最优解。

Abstract: The maximum parsimony phylogenetic tree reconstruction problem is NP-hard,
presenting a computational bottleneck for classical computing and motivating
the exploration of emerging paradigms like quantum computing. To this end, we
design three optimization models compatible with both classical and quantum
solvers. Our method directly searches the complete solution space of all
possible tree topologies and ancestral states, thereby avoiding the potential
biases associated with pre-constructing candidate internal nodes. Among these
models, the branch-based model drastically reduces the number of variables and
explicit constraints through a specific variable definition, providing a novel
modeling approach effective not only for phylogenetic tree building but also
for other tree problems. The correctness of this model is validated with a
classical solver, which obtains solutions that are generally better than those
from heuristics on the GAPDH gene dataset. Moreover, our quantum simulations
successfully find the exact optimal solutions for small-scale instances with
rapid convergence, highlighting the potential of quantum computing to offer a
new avenue for solving these intractable problems in evolutionary biology.

</details>


### [284] [Emergent Bifurcations in Quantum Circuit Stability from Hidden Parameter Statistics](https://arxiv.org/abs/2508.00484)
*Pilsung Kang*

Main category: quant-ph

TL;DR: 量子电路的压缩和稳定性是一个关键问题。本研究通过数值分析发现，电路的鲁棒性或脆弱性取决于其门旋转参数的统计特性，而非结构。脆弱电路具有“统计脆性”，并且存在“悖论重要性”现象，即小角度门更关键。这为设计更鲁棒的量子算法提供了新的思路。


<details>
  <summary>Details</summary>
Motivation: 为了解决量子电路压缩中的一个基础性挑战，即对控制电路稳定性的原理知之甚少。

Method: 通过对300个结构均匀的电路（横跨10、12和14个量子比特）进行大规模数值分析。

Result: 研究发现，尽管电路宏观均匀，但它们普遍分为鲁棒和脆弱的类别，其根源在于门旋转参数的统计特性，而非结构。脆弱电路表现出“统计脆性”特征，其参数变异性低，小角度门稀少。还揭示了“悖论重要性”机制，即小角度门对电路功能更为关键，这使得脆弱电路在压缩时更容易失败。

Conclusion: 本研究提出了一种新的量子算法工程框架，将重点从宏观结构转移到电路参数的微观统计特性，以设计更具弹性的量子算法。

Abstract: The compression of quantum circuits is a foundational challenge for near-term
quantum computing, yet the principles governing circuit stability remain poorly
understood. We investigate this problem through a large-scale numerical
analysis of 300 structurally-uniform circuits across 10, 12, and 14 qubits.
Despite their macroscopic uniformity, we find that each ensemble universally
bifurcates into distinct robust and fragile classes. We solve the puzzle of
this emergent bifurcation, demonstrating that its origin is not structural, but
is instead encoded in the statistical properties of the gate rotation
parameters. Fragile circuits consistently exhibit a universal signature of
``statistical brittleness,'' characterized by low parameter variability and a
scarcity of small-angle gates. We uncover the underlying physical mechanism for
this phenomenon: Paradoxical Importance where smaller-angle gates are
counter-intuitively more critical to the circuit's function, an effect most
pronounced in fragile circuits. This reliance on fine-tuning explains why
statistically brittle circuits are uniquely vulnerable to failure under
compression. These findings establish a new framework for engineering resilient
quantum algorithms, shifting the focus from macroscopic structure to the
microscopic statistical properties of a circuit's parameters.

</details>


### [285] [Q-Sylvan: A Parallel Decision Diagram Package for Quantum Computing](https://arxiv.org/abs/2508.00514)
*Sebastiaan Brand,Alfons Laarman*

Main category: quant-ph

TL;DR: Q-Sylvan工具通过并行DDs技术，提高了量子电路模拟和等价性检查的效率，实现了显著的并行加速。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算应用的临近，需要分析和验证量子算法的工具。决策图（DDs）在解决这类问题中表现出色，但其并行化存在困难，尤其是在量子特定DDs方面。

Method: 利用细粒度任务并行和无锁哈希表实现了并行边缘值决策图（DDs）。

Result: Q-Sylvan在单核性能上可与最先进的量子DD工具MQT DDSIM在大规模实例上相媲美，并且在64核上实现了高达18倍的并行加速。

Conclusion: 该研究提出了Q-Sylvan工具，实现了并行边缘值决策图（DDs），并成功应用于量子电路的模拟和等价性检查。

Abstract: As physical realizations of quantum computers move closer towards practical
applications, the need for tools to analyze and verify quantum algorithms
grows. Among the algorithms and data structures used to tackle such problems,
decision diagrams (DDs) have shown much success. However, an obstacle with DDs
is their efficient parallelization, and while parallel speedups have been
obtained for DDs used in classical applications, attempts to parallelize
operations for quantum-specific DDs have yielded only limited success. In this
work, we present an efficient implementation of parallel edge-valued DDs, which
makes use of fine-grained task parallelism and lock-free hash tables.
Additionally, we use these DDs to implement two use cases: simulation and
equivalence checking of quantum circuits. In our empirical evaluation we find
that our tool, Q-Sylvan, shows a single-core performance that is competitive
with the state-of-the-art quantum DD tool MQT DDSIM on large instances, and
moreover achieves parallel speedups of up to x18 on 64 cores.

</details>


### [286] [Quantum repeaters based on stationary and flying Gottesman-Kitaev-Preskill qudits](https://arxiv.org/abs/2508.00530)
*Stefan Häussler,Peter van Loock*

Main category: quant-ph

TL;DR: 结合GKP量子纠错的量子中继器在特定参数下表现更优。


<details>
  <summary>Details</summary>
Motivation: 探索一种结合量子纠错（QEC）的量子中继器方案，以克服现有方案的局限性。

Method: 探索了一种结合飞行（光）和固定（物质）量子比特的量子纠错（QEC）量子中继器方案，并使用GKP码来编码和保护量子比特。

Result: 发现存在一个中间参数范围，结合的量子中继器协议优于单独的单向或双向方案。

Conclusion: 该量子中继器方案结合了量子纠错（QEC）和GKP码，在特定参数范围内优于单一的单向或双向方案。

Abstract: There are various approaches to long-range quantum communication based on
conceptually different forms of quantum repeaters. Here we explore a quantum
repeater scheme that employs quantum error correction (QEC) both on the flying
(light) qubits and on the stationary (matter) qubits. The idea is to combine
the benefits of encoded one-way and two-way schemes where effective channel
transmission and loss scaling are enhanced by means of photon loss codes and
encoded quantum memories, respectively, while sacrificing some of their
advantages such as high clock rates, independent of classical communication
times (one-way), and potentially large segment lengths (two-way). More
specifically, we illustrate, propose, and analyze such a quantum repeater using
the bosonic Gottesman-Kitaev-Preskill (GKP) code which naturally enables
encoding and QEC of qudits, protecting them against transmission and memory
loss, the latter, for instance, occuring on collective spin modes of atomic
ensembles. While the encoded one-way and two-way schemes on their own either
require very high repeater link coupling efficiencies and GKP squeezing or
allow for experimentally more feasible, small values of these parameters,
respectively, we find that there are intermediate parameter regimes where the
combined repeater protocol is superior.

</details>


### [287] [Beyond asymptotic reasoning: a practical ground state projector based on the wall-Chebyshev expansion](https://arxiv.org/abs/2508.00533)
*Maria-Andreea Filip,Nathan Fitzpatrick*

Main category: quant-ph

TL;DR: 一种新的量子算法，通过Chebyshev级数逼近墙函数来制备基态，在精度和鲁棒性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 为解决化学问题中基态制备的挑战，引入一种新的量子算法。

Method: 提出一种基于Chebyshev级数逼近墙函数（wall function）的量子算法，用于基态制备。该投影算符可高效地实现为哈密顿量算符的乘积，并通过酉组合（linear combinations of unitaries）方法实现。

Result: 通过渐近缩放分析和数值基准测试，证明该算法具有竞争力，并在缺乏精确基态能量估计的情况下表现出优越的鲁棒性和收敛性。

Conclusion: 该方法在精度和鲁棒性方面与基于虚时演化和其他投影函数逼近的领先方法具有竞争力，在需要精确的基态能量估计的情况下，显示出优于其他方法的性能。

Abstract: We introduce a quantum algorithm for ground-state preparation based on a
Chebyshev series approximation to the wall function. This projector can be
efficiently implemented as a product of Hamiltonian operators, enabling a
straightforward realization via the linear combinations of unitaries method. We
analyze the asymptotic scaling and provide numerical benchmarks, demonstrating
that the wall-Chebyshev projector achieves competitive performance with leading
methods based on imaginary time evolution and alternative projector function
approximations. Notably, our approach exhibits superior robustness and
convergence in scenarios where accurate ground-state energy estimates are
unavailable, showing promise for realistic chemistry problems.

</details>


### [288] [Persistent Quantum Memory in Iterated Lifts](https://arxiv.org/abs/2508.00562)
*Hartosh Singh Bal*

Main category: quant-ph

TL;DR: HL’2 提升是一种在完美图上传输量子行走的方法，可以提高量子相干性。


<details>
  <summary>Details</summary>
Motivation: 为了量化这些效应，我们评估了量子资源理论中的标准相干性度量，包括逆参与比 (IPR)、纯度、相干性相对熵和对数相干数。

Method: 研究了在由对称提升 HL’2(G)（G 的二分双覆盖的线图）产生的完美图上的连续时间量子行走中的量子相干性。

Result: HL’2 提升会离域本征态，增加相干熵，并扩展量子态的基支撑。在小图和随机图上，HL’2 提升会产生具有长时相干性的完美图塔。

Conclusion: HL’2 是一种可扩展的、结构化的量子干涉组织机制，它引入了一种新的完美图家族，该家族能够在没有光谱调整或工程权重的情况下支持长时间量子相干。

Abstract: We study quantum coherence in continuous-time quantum walks on perfect graphs
generated by the symmetric lift ${\mathrm{HL}}'_2(G)$, a canonical, unweighted,
undirected construction defined as the line graph of a bipartite double cover
of $G$. This lift acts as both a coherence-preserving and coherence-inducing
transformation: it preserves and scales structured quantum interference in
highly symmetric base graphs, and induces sustained coherence in random or
weakly structured ones.
  In small graphs such as $K_4$, $K_5$, and the Petersen graph, where quantum
walks exhibit sharp revivals and high return probability, repeated
$\mathrm{HL}'_2$ lifting produces towers of perfect graphs with thousands to
tens of thousands of vertices that retain periodic or quasi-periodic coherence.
When applied to random regular or Erd\H{o}s--R\'enyi graphs with flat or
decaying return behavior, the lift introduces structured interference and
significant amplification of mean and peak return probabilities.
  To quantify these effects, we evaluate standard coherence metrics from
quantum resource theory, including inverse participation ratio (IPR), purity,
relative entropy of coherence, and the logarithmic coherence number. These
measures confirm that $\mathrm{HL}'_2$ lifting delocalizes eigenstates,
increases coherence entropy, and expands the basis support of quantum states.
These results demonstrate that $\mathrm{HL}'_2$ is a scalable and structurally
grounded mechanism for organizing quantum interference, and introduce a new
family of perfect graphs that support long-time quantum coherence without
spectral tuning or engineered weights.

</details>


### [289] [Swapped Entanglement in High-Dimensional Quantum Systems](https://arxiv.org/abs/2508.00634)
*S. M. Zangi,Chitra Shukla,Khalid Naseer,Saeed Haddadi*

Main category: quant-ph

TL;DR: Entanglement swapping extended to higher dimensions (qudits) improves entanglement distribution and has applications in quantum repeaters, even in noisy systems.


<details>
  <summary>Details</summary>
Motivation: To explore and enhance entanglement distribution in quantum information processing by extending entanglement swapping to higher-dimensional systems and analyzing its performance and applications.

Method: Extending entanglement swapping to higher-dimensional systems (qudits) and analyzing its dynamics using concurrence and negativity.

Result: Higher-dimensional systems show enhanced entanglement distribution capabilities. Applications in long-distance teleportation and quantum repeaters are discussed. The behavior of entanglement against fidelity in noisy systems with different dimensions is also analyzed.

Conclusion: Higher-dimensional systems enhance entanglement distribution compared to qubit-based protocols, with applications in long-distance teleportation and quantum repeaters. The paper also discusses entanglement swapping in noisy systems and its behavior against fidelity with different dimensions.

Abstract: Entanglement swapping is a fundamental protocol in quantum information
processing that enables the distribution of entanglement between distant
quantum systems. In this work, we first extend the concept of entanglement
swapping to higher-dimensional quantum systems, specifically qudits. We then
analyze the dynamics of entanglement swapping and quantify the average swapped
entanglement in terms of concurrence and negativity. Our results demonstrate
that higher-dimensional systems offer enhanced entanglement distribution
capabilities compared to qubit-based protocols. We also discuss the application
of entangled qudits in terms of long-distance teleportation that provides the
base for quantum repeaters. Furthermore, we discuss the entanglement swapping
for a real and noisy system. The behaviors of entanglement against fidelity
with different dimensions are also discussed.

</details>


### [290] [Uncertainty Relation for Pseudo-Hermitian Quantum Systems](https://arxiv.org/abs/2508.00648)
*Boubakeur Khantoul,Bilel Hamil,Amar Benchikha*

Main category: quant-ph

TL;DR: 伪hermitian量子力学中的不确定性关系与标准hermitian情况等价，非hermitian系统很重要。


<details>
  <summary>Details</summary>
Motivation: 研究伪hermitian量子力学，并将其不确定性关系与标准hermitian情况进行比较，以强调非hermitian系统在量子力学中的重要性。

Method: 研究了伪hermitian量子力学，其中哈密顿量满足修正的hermiticity条件，并推导了含线性势的时间相关薛定谔方程的解析解。

Result: 推导了伪hermitian量子力学中的不确定性关系，并证明了其与标准hermitian情况的等价性。此外，还得到了含线性势的时间相关薛定谔方程的解析解，并展示了位置和动量的不确定性关系保持为实数且大于1/2。

Conclusion: 伪hermitian量子力学中的不确定性关系与标准hermitian情况等价，并且位置和动量的不确定性关系保持为实数且大于1/2，这表明了非hermitian系统在量子力学中的重要性。

Abstract: This study investigates pseudo-Hermitian quantum mechanics, where the
Hamiltonian satisfies a modified Hermiticity condition. We extend the
uncertainty relation for such systems, demonstrating its equivalence to the
standard Hermitian case within a pseudo-Hermitian inner product. Analytical
solutions to the time-dependent Schr\"odinger equation with a linearly evolving
potential are derived. Furthermore, we show that the uncertainty relation for
position and momentum remains real and greater than 1/2, highlighting the
significance of non-Hermitian systems in quantum mechanics.

</details>


### [291] [Spontaneous emission as a bridge from Lindbladian to nonreciprocal reservoirs](https://arxiv.org/abs/2508.00689)
*C. J. Bolech,T. Giamarchi*

Main category: quant-ph

TL;DR: 本研究提出了一个超越 Lindbladian 形式的有效描述，以研究与光子损耗相关的非平衡量子系统，并讨论了其在冷原子气体实验中的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在研究一个非平衡量子系统，该系统通过受激和自发辐射光子耦合到一个反捕获态，从而实现粒子损失，并探讨其可观测的后果。

Method: 本研究通过考虑一个与两个储层相连接的状态，该状态还通过受激和自发辐射光子耦合到一个反捕获态，从而实现粒子损失。在重新审视自发辐射过程后，我们表明，对该系统的适当有效描述需要超越通常的 Lindbladian 形式，并包括一个非互易（“非厄米”）耦合到模拟未捕获态的储层。

Result: 本研究计算了储层和非互易耦合的存在所产生的可观测后果，例如通过观察损耗流中的量子芝诺效应。

Conclusion: 本研究表明，需要超越通常的 Lindbladian 形式，并包括一个非互易（“非厄米”）耦合到模拟未捕获态的储层，才能对所研究的系统进行有效的描述。本研究还讨论了研究结果与冷原子气体中可能进行的实验之间的联系。

Abstract: We study an out-of-equilibrium quantum system in which a state connecting two
reservoirs is also coupled by stimulated and spontaneous emission of photons to
an antitrapped state, thus implementing particle loss. After revisiting the
spontaneous emission process, we show that the proper effective description of
such a system requires one to go beyond the usual Lindbladian formalism and
includes a nonreciprocal (``non-Hermitian'') coupling to the reservoir modeling
the untrapped state. The presence of both, the reservoirs and the nonreciprocal
coupling, have observable consequences that we compute, for example, by looking
at the quantum Zeno effect in the loss current. We discuss the connection of
our findings to possible experiments in cold atomic gases.

</details>


### [292] [There is no ultrastrong coupling with photons](https://arxiv.org/abs/2508.00702)
*Diego Fernández de la Pradilla,Esteban Moreno,Johannes Feist*

Main category: quant-ph

TL;DR: 超强耦合不能通过光子实现，源于库仑相互作用，极化自能项无需考虑。


<details>
  <summary>Details</summary>
Motivation: 理论上，超强耦合的产生通常认为是发射器与结构所支持的传播光子模式的相互作用，但这种描述忽略了发射器和结构电荷间的库仑相互作用。

Method: 文章通过基于电磁约束的通用论证，并用一个分析模型阐释了该观点。

Result: 文章证明了发射器-光子耦合强度存在基本限制，因此超强耦合不能通过光子实现，而必须源于库仑相互作用。此外，文章还说明了极化自能项不包含在内。

Conclusion: 超强耦合不能通过光子实现，而必须源于电荷间的库仑相互作用。所谓极化自能项不需要被包含。

Abstract: Theoretical accounts of ultrastrongly coupled light-matter systems commonly
assume that it arises from the interaction of an emitter with propagating
photon modes supported by a structure, understanding photons as the excitations
of the transverse electromagnetic field. This description discards the Coulomb
interaction between the emitter and structure charges. Here, we show with a
general argument based on electromagnetic constraints that the emitter-photon
coupling strength is fundamentally limited. Accordingly, we conclude that the
ultrastrong coupling regime cannot be reached with photons. Instead, it must
originate from the Coulomb interactions between charges. A further corollary is
that the so-called polarization self-energy term does not need to be included.
We illustrate our claims by solving an analytical model of the paradigmatic
case of an emitter next to a metallic nanosphere. These findings shed light on
the fundamental processes underlying ultrastrong coupling, clarify the role of
the polarization self-energy term and compel a reevaluation of previous
literature.

</details>


### [293] [Magic States in the Asymmetric Quantum Rabi Model](https://arxiv.org/abs/2508.00765)
*A. Campos-Uscanga,E. Benítez Rodríguez,E. Piceno Martínez,M. A. Bastarrachea-Magnani*

Main category: quant-ph

TL;DR: 研究在量子光学模型中探索了魔力的存在性及其生成机制，为量子计算资源的研究提供了新的视角。


<details>
  <summary>Details</summary>
Motivation: 量子计算中的魔力（magic）作为一种资源，在qudit网络中得到了广泛研究，但其在连续变量和一般复合系统中的定义仍然是一个悬而未决的问题。本研究旨在解决这一问题，并探讨魔力在量子光学模型中的表现。

Method: 本研究采用理论分析方法，研究了非对称量子拉比模型中魔力的性质。

Result: 研究发现在非对称量子拉比模型中，魔力普遍存在于二嗪类约化系统中，并且光-物质相互作用在魔力生成中起着关键作用。此外，研究还观察到了相应的玻色子自由度中负Wigner函数的出现。

Conclusion: 这项研究探讨了在非对称量子拉比模型（一种来自量子光学中的范例模型）的二分系统中魔力（magic）的存在性。研究人员探索了在整个哈密顿量参数空间中，二嗪类约化系统中魔力的存在性，光-物质相互作用在魔力生成中的作用，以及在相应的玻色子自由度中负Wigner函数的表现。最后，研究人员讨论了在强耦合和超强耦合区域内，魔力态制备在量子信息系统背景下的结果。

Abstract: Magic or non-stabilizerness is a resource for quantum computing that has been
extensively studied in qudit networks. It describes the degree to which
Clifford gates cannot generate a given state, capturing the advantage of
quantum over classical computing. However, its definition in continuous
variables and general composite systems remains an open issue. We study magic
in a bipartite system, the Asymmetric Quantum Rabi model, a paradigmatic model
from quantum optics. We explore the presence of magic in the qubit-reduced
system throughout the Hamiltonian parameter space, the role of light-matter
interactions in its generation, and the manifestation of Wigner function
negativity in the corresponding bosonic degree of freedom. Finally, we discuss
our results for magic state preparation in the strong and ultra-strong coupling
regimes within the context of quantum informational systems.

</details>


### [294] [The Role of the Satellite in Quantum Information Networks](https://arxiv.org/abs/2508.00790)
*Luca Paccard,Valentin Leloup,Luca Lazzarini,Agathe Blaise,Mailys Guerault,Mickael Faugeron,Fabrice Arnal,Mathieu Bertrand,Raphael Aymeric,Michel Sotom,Stéphanie Molin,Patrick Gélard,Pierre Besancenot,Cyrille Laborde,Laurent de Forges de Parny,Mathias van den Bossche*

Main category: quant-ph

TL;DR: 量子信息网络（QIN）依赖于量子纠缠，但光纤距离有限。该论文提出了利用卫星实现全球连接，克服距离限制，并探讨了其动机、用例和用户，量化了卫星的必要性。


<details>
  <summary>Details</summary>
Motivation: 为了克服地面光纤链路在距离上的固有限制，并实现全球量子连接。

Method: 探讨了量子态传输和纠缠分发在量子信息网络中的应用，并量化了卫星的必要性。

Result: 阐述了利用卫星构建量子信息网络的动机，讨论了其用例，并提出了未来潜在用户，同时量化了卫星在量子信息网络中的必要通信距离。

Conclusion: 卫星在量子信息网络中具有不可或缺的作用，尤其是在长距离连接方面。

Abstract: Quantum Information Networks (QIN) attract increasing interest, as they will
enable interconnection of multiple quantum devices in a distributed
organization thus enhancing intrinsic computing, sensing, and security
capabilities. The core mechanism of a QIN is quantum state swapping, based on
teleportation, which consumes quantum entanglement, and which can be seen in
this context as a new kind of network resource. The satellite is expected to
play a central role for supporting global connectivity in such novel networks
in which ground fiber links have stringent restrictions in length due to the
absorption losses in optical fibers. There is indeed fundamental limits in the
maximal fiber links distance which may not be exceeded for any unitary links.
In this paper we clarify our motivations to develop such networks with
satellites, and we discuss their associated use cases based on entanglement
distribution, and we present the future potential users. We also assess
quantitatively the ranges for which the satellite becomes mandatory in quantum
information networks.

</details>


### [295] [Entanglement Management in Space-Based Quantum Information Networks](https://arxiv.org/abs/2508.00793)
*Luca Paccard,Agathe Blaise,Fabrice Arnal,Laurent de Forges de Parny*

Main category: quant-ph

TL;DR: Satellites are key to global Quantum Information Networks (QIN) due to their long-distance connectivity capabilities, despite facing integration and deployment challenges.


<details>
  <summary>Details</summary>
Motivation: The demand for global development of Quantum Information Networks (QIN) has become crucial due to the evolution of quantum computing, quantum sensing, and secure quantum communication protocols. Satellites are indispensable for enabling connectivity across vast distances, transcending terrestrial limitations.

Method: This article explores the integration of satellites into Quantum Information Networks (QIN) from their network architecture to the challenges they face.

Result: This article explores the various ways satellites can be involved in the deployment of QIN, covering their integration into the network architecture and the challenges they encounter.

Conclusion: Globally deploying Quantum Information Networks (QIN) is crucial with the evolution of quantum computing, quantum sensing, and secure quantum communication protocols. Satellites are essential for enabling long-distance connectivity and overcoming terrestrial limitations. This article explores the integration of satellites into QIN architecture and the associated challenges.

Abstract: With the evolution of quantum computing, quantum sensing and secure quantum
communication protocols, the demand for global development of Quantum
Information Networks (QIN) has become crucial. Satellites play an indispensable
role in enabling connectivity across vast distances, transcending terrestrial
limitations. In this article, we explore various ways in which satellites may
be involved in the deployment of these novel networks from their integration
into the network architecture to the challenges they face.

</details>


### [296] [Close encounters between periodic light and periodic arrays of quantum emitters](https://arxiv.org/abs/2508.00797)
*Frieder Lindel,Carlos J. Sánchez Martínez,Johannes Feist,Francisco J. García-Vidal*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量化方案，用于处理等离激元超表面的量子光-物质相互作用，实现了晶体极化子的形成，并展示了其在产生纠缠光子对方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有技术缺乏对等离激元超表面进行量化以及处理其中量子光-物质相互作用的一般性方法。

Method: 本研究基于宏观量子电动力学，构建了一种用于等离激元超表面共振的从头开始的少模量化方案。

Result: 实现了集体的量子发射器激子与超表面支持的光模式的强耦合，形成了晶体极化子，并展示了晶体极化子间的相互作用能够高效、定向地产生纠缠光子对。

Conclusion: 本研究提出了一种基于宏观量子电动力学、用于等离激元超表面共振的从头开始的少模量化方案，为强光-物质耦合提供了框架，实现了周期性量子发射器阵列表体激子与超表面支持的光模式的强耦合，形成了晶体极化子。

Abstract: Periodically structured surfaces (metasurfaces), i.e., periodic light, have
evolved as a powerful tool for manipulating electromagnetic fields both in
classical and quantum regimes. However, no general approach for quantizing the
electromagnetic fields and treating quantum light-matter interactions in such
structures exists. Here, we construct an ab initio few-mode quantization scheme
for metasurface resonances based on macroscopic quantum electrodynamics. We use
our approach to propose a framework for strong light-matter coupling in which
collective excitations of periodic arrays of quantum emitters are strongly
coupled to the light modes supported by the metasurface, leading to the
formation of crystal polaritons. As a proof-of-principle example of their
potential, we show that interactions between crystal polaritons can lead to an
efficient and directional generation of entangled photon pairs.

</details>


### [297] [Statistical Mechanics of Random Mixed State Ensembles with Fixed Energy](https://arxiv.org/abs/2508.00809)
*Harry J. D. Miller*

Main category: quant-ph

TL;DR: 研究将具有固定平均能量的随机状态纳入混合状态的概率分布框架，发现了无相互作用的相变等奇异特征。


<details>
  <summary>Details</summary>
Motivation: 扩展现有混合状态概率分布（如 Bures-Hall 和 Hilbert-Schmidt 测度）的框架，以包含具有固定平均能量的随机状态的性质。

Method: 通过考虑具有固定平均能量的随机状态的性质，导出集合平均密度矩阵，并将其性质与统计力学熵和温度联系起来。

Result: 导出了混合状态的微正则系综，并发现了无相互作用的相变和热力学极限下的有限相对能量涨落等奇异特征。

Conclusion: 该研究将混合状态的概率分布扩展到具有固定平均能量的随机状态，并将其与统计力学熵和温度联系起来。研究结果在简单的自旋系统中得到了说明，并发现了无相互作用的相变和热力学极限下的有限相对能量涨落等奇异特征。

Abstract: Mixed state ensembles such as the Bures-Hall and Hilbert-Schmidt measure are
probability distributions that characterise the statistical properties of
random density matrices and can be used to determine the typical features of
mixed quantum states. Here we extend this framework by considering the
properties of random states with fixed average energy, and the
ensemble-averaged density matrix is derived under this additional physical
constraint. This gives rise to a type of microcanonical ensemble for random
mixed states and we connect its properties to a statistical mechanical entropy
and temperature. Our results are illustrated using a variety of simple spin
systems, and we find that they can exhibit exotic features such as phase
transitions in the absence of interactions and finite relative energy
fluctuations in the thermodynamic limit.

</details>


### [298] [Entanglement swapping for partially entangled qudits and the role of quantum complementarity](https://arxiv.org/abs/2508.00813)
*Diego S. Starke,Marcos L. W. Basso,Lucas C. Céleri,Jonas Maziero*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We extend the entanglement swapping protocol (ESP) to partially entangled
qudit states and analyze the process within the framework of complete
complementarity relations (CCRs). Building on previous results for qubits, we
show that the average distributed entanglement between two parties via ESP is
bounded above by the initial entanglement of one of the input pairs, and also
by the product of the initial entanglements. Notably, we find that using
initial states with vanishing local quantum coherence is sufficient to capture
the essential features of the protocol, simplifying the analysis. By exploring
the cases of qubits and qutrits, we observe that the upper bound on the average
distributed entanglement -- expressed in terms of the product of the initial
entanglements -- can be improved, and we conjecture what this tighter bound
might be. Finally, we discuss the role of quantum complementarity in the ESP
and show how local predictability constrains the entanglement that can be
operationally distributed via ESP.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [299] [Data-Driven Motion Planning for Uncertain Nonlinear Systems](https://arxiv.org/abs/2508.00154)
*Babak Esmaeili,Hamidreza Modares,Stefano Di Cairano*

Main category: eess.SY

TL;DR: 该论文提出了一种数据驱动的运动规划框架，用于非线性系统，通过学习不变集来确保安全、动态可行的路径。


<details>
  <summary>Details</summary>
Motivation: 与依赖系统动力学模型的传统方法不同，该方法仅需要数据来计算安全区域和设计状态反馈控制器。

Method: 该框架围绕每个随机采样的航路点，通过解决数据驱动的线性矩阵不等式问题来学习多个椭圆不变集及其局部状态反馈增益。这些不变集由分段仿射控制器组合而成，并被多面体逼近。通过验证连续凸包多面体的交集并引入中间节点来实现安全转换。

Result: 所提出方法在复杂的非线性系统中实现了安全、动态可行的路径。

Conclusion: 该方法通过仿真得到验证，证明了在复杂的非线性系统中实现安全、动态可行的路径的有效性。

Abstract: This paper proposes a data-driven motion-planning framework for nonlinear
systems that constructs a sequence of overlapping invariant polytopes. Around
each randomly sampled waypoint, the algorithm identifies a convex admissible
region and solves data-driven linear-matrix-inequality problems to learn
several ellipsoidal invariant sets together with their local state-feedback
gains. The convex hull of these ellipsoids, still invariant under a
piece-wise-affine controller obtained by interpolating the gains, is then
approximated by a polytope. Safe transitions between nodes are ensured by
verifying the intersection of consecutive convex-hull polytopes and introducing
an intermediate node for a smooth transition. Control gains are interpolated in
real time via simplex-based interpolation, keeping the state inside the
invariant polytopes throughout the motion. Unlike traditional approaches that
rely on system dynamics models, our method requires only data to compute safe
regions and design state-feedback controllers. The approach is validated
through simulations, demonstrating the effectiveness of the proposed method in
achieving safe, dynamically feasible paths for complex nonlinear systems.

</details>


### [300] [Integrating Opinion Dynamics into Safety Control for Decentralized Airplane Encounter Resolution](https://arxiv.org/abs/2508.00156)
*Shuhao Qi,Zhiqi Tang,Zhiyong Sun,Sofie Haesaert*

Main category: eess.SY

TL;DR: 本研究提出将受生物启发的非线性意见动力学应用于飞机安全控制，以解决空中交通拥堵导致的阻塞问题，实现安全、高效、无阻塞的冲突解决。


<details>
  <summary>Details</summary>
Motivation: 当前的去中心化安全控制器虽然能防止碰撞，但可能导致飞机在某些情况下长时间阻塞，影响飞行效率。

Method: 通过集成受生物启发的非线性意见动力学到飞机安全控制框架来解决阻塞问题，以实现无需通信或预设规则的协作决策和快速、安全的协调。

Result: 仿真结果表明，该方法能提高飞行效率并保证安全性，为自主控制器设计提供了实用见解。

Conclusion: 本研究将受生物启发的非线性意见动力学集成到飞机安全控制框架中，以解决空中交通冲突的阻塞问题，确保了安全性和无阻塞的冲突解决。

Abstract: As the airspace becomes increasingly congested, decentralized conflict
resolution methods for airplane encounters have become essential. While
decentralized safety controllers can prevent dangerous midair collisions, they
do not always ensure prompt conflict resolution. As a result, airplane progress
may be blocked for extended periods in certain situations. To address this
blocking phenomenon, this paper proposes integrating bio-inspired nonlinear
opinion dynamics into the airplane safety control framework, thereby
guaranteeing both safety and blocking-free resolution. In particular, opinion
dynamics enable the safety controller to achieve collaborative decision-making
for blocking resolution and facilitate rapid, safe coordination without relying
on communication or preset rules. Extensive simulation results validate the
improved flight efficiency and safety guarantees. This study provides practical
insights into the design of autonomous controllers for airplanes.

</details>


### [301] [Adaptive Compensation of Nonlinear Friction in Mechanical Systems Without Velocity Measurement](https://arxiv.org/abs/2508.00175)
*Jose Guadalupe Romero,Romeo Ortega,Leyan Fang,Alexey Bobtsov*

Main category: eess.SY

TL;DR: This paper introduces a new controller that compensates for friction in mechanical systems without needing to measure velocity, using a special observer. It's the first of its kind to guarantee convergence and works even with complex friction models.


<details>
  <summary>Details</summary>
Motivation: Friction is a significant impediment to precise servo control in mechanical systems. Existing compensation schemes often require velocity measurements, which are difficult to obtain, and rely on mathematical models with unknown parameters. This work aims to overcome these limitations.

Method: The paper utilizes an immersion and invariance-based adaptive speed observer for friction compensation, avoiding the need for velocity measurements and relying on a static and Coulomb friction model.

Result: The paper presents a globally convergent tracking controller and simulation results demonstrating its effectiveness for systems with static and Coulomb friction, as well as the more advanced LuGre friction model.

Conclusion: The paper proposes a novel globally convergent tracking controller for mechanical systems with static and Coulomb friction, which does not require velocity measurements and uses an immersion and invariance-based adaptive speed observer for friction compensation. This is presented as the first globally convergent solution to this problem.

Abstract: Friction is an unavoidable phenomenon that exists in all mechanical systems
incorporating parts with relative motion. It is well-known that friction is a
serious impediment for precise servo control, hence the interest to devise a
procedure to compensate for it -- a subject that has been studied by many
researchers for many years. The vast majority of friction compensation schemes
reported in the literature rely on the availability of velocity measurements,
an information that is hard to obtain. A second limitation of the existing
procedures is that they rely on mathematical models of friction that contain
several unknown parameters, some of them entering nonlinearly in the dynamic
equations. In this paper we propose a globally convergent tracking controller
for a mechanical system perturbed by static and Coulomb friction, which is a
reliable mathematical model of the friction phenomenon, that does not rely one
measurement of velocity. The key component is an immersion and invariance-based
adaptive speed observer, used for the friction compensation. To the best of our
knowledge, this is the first globally convergent solution to this challenging
problem. We also present simulation results of the application of our observer
for systems affected by friction, which is described by the more advanced LuGre
model.

</details>


### [302] [Optimal Messaging Strategy for Incentivizing Agents in Dynamic Systems](https://arxiv.org/abs/2508.00188)
*Renyan Sun,Ashutosh Nayyar*

Main category: eess.SY

TL;DR: 设计师通过发送信息和采取行动来激励代理人，并最大化自身回报。研究提出了一种基于顺序理性的激励兼容性方法，并使用逆向归纳和线性规划来找到最优策略。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在有限时间、离散时间动态系统中，设计师如何通过选择性信息披露来激励代理人采取特定策略，同时最大化自身回报的问题。

Method: 提出了一种基于顺序理性的激励相容性概念，并设计了一个利用逆向归纳算法解决一系列线性规划问题的计算方法来寻找最优策略。

Result: 证明了在特定信息结构下，存在最优的设计者策略，并且该策略可以通过逆向归纳算法和线性规划得到。

Conclusion: 本论文提出了一种基于顺序理性的激励相容性概念，并展示了在特定信息结构下，设计者可以通过解决一系列线性规划问题来找到最优信息披露和行动策略，以最大化其总期望回报并激励代理人遵循特定策略。

Abstract: We consider a finite-horizon discrete-time dynamic system jointly controlled
by a designer and one or more agents, where the designer can influence the
agents' actions through selective information disclosure. At each time step,
the designer sends a message to the agent(s) from a prespecified message space.
The designer may also take an action that directly influences system dynamics
and rewards. Each agent uses its received message (and its own information) to
choose its action. We are interested in the setting where the designer would
like to incentivize each agent to play a specific strategy. We consider a
notion of incentive compatibility that is based on sequential rationality at
each realization of the common information between the designer and the
agent(s). Our objective is to find a messaging and action strategy for the
designer that maximizes its total expected reward while incentivizing each
agent to follow a prespecified strategy. Under certain assumptions on the
information structure of the problem, we show that an optimal designer strategy
can be computed using a backward inductive algorithm that solves a family of
linear programs.

</details>


### [303] [Neural Co-state Projection Regulator: A Model-free Paradigm for Real-time Optimal Control with Input Constraints](https://arxiv.org/abs/2508.00283)
*Lihan Lian,Uduak Inyang-Udoh*

Main category: eess.SY

TL;DR: NCPR是一种创新的基于学习的最优控制框架，它利用神经网络和PMP理论，在输入受限的情况下有效解决非线性控制问题，并显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于学习的最优控制方法（如强化学习）在样本效率、奖励设计敏感性、超参数敏感性以及泛化性（尤其是在输入约束下）方面的挑战，提出NCPR。

Method: NCPR框架使用神经网络（NN）通过自监督学习来预测投影共态的有限时间轨迹，然后仅提取预测的第一个元素来解决轻量级二次规划（QP）问题，从而在反馈控制设置中实时计算满足输入约束和一阶最优性条件的控制动作。

Result: 在模拟的机器人轨迹跟踪和摆动pendulum任务中，NCPR展示了优越的泛化能力（针对未知的系统状态和输入约束）和更高的采样效率。

Conclusion: 所提出的神经共态投影调节器（NCPR）是一种基于学习的无模型方法，能够解决具有输入约束的非线性控制仿射系统中的二次调节器问题，并且在泛化性和采样效率方面表现优于强化学习方法。

Abstract: Learning-based approaches, notably Reinforcement Learning (RL), have shown
promise for solving optimal control tasks without explicit system models.
However, these approaches are often sample-inefficient, sensitive to reward
design and hyperparameters, and prone to poor generalization, especially under
input constraints. To address these challenges, we introduce the neural
co-state projection regulator (NCPR), a model-free learning-based optimal
control framework that is grounded in Pontryagin's Minimum Principle (PMP) and
capable of solving quadratic regulator problems in nonlinear control-affine
systems with input constraints. In this framework, a neural network (NN) is
trained in a self-supervised setting to take the current state of the system as
input and predict a finite-horizon trajectory of projected co-states (i.e., the
co-state weighted by the system's input gain). Subsequently, only the first
element of the NN's prediction is extracted to solve a lightweight quadratic
program (QP). This workflow is executed in a feedback control setting, allowing
real-time computation of control actions that satisfy both input constraints
and first-order optimality conditions.
  We test the proposed learning-based model-free quadratic regulator on (1) a
unicycle model robot reference tracking problem and (2) a pendulum swing-up
task. For comparison, reinforcement learning is used on both tasks; and for
context, a model-based controller is used in the unicycle model example. Our
method demonstrates superior generalizability in terms of both unseen system
states and varying input constraints, and also shows improved sampling
efficiency.

</details>


### [304] [Low-dimensional observer design for stable linear systems by model reduction](https://arxiv.org/abs/2508.00609)
*M. F. Shakib,M. Khalil,R. Postoyan*

Main category: eess.SY

TL;DR: 本文提出了一种低维观察器设计，用于稳定LTI系统。该方法利用矩量匹配降阶技术，为特定输入实现精确状态重构，并保证通用输入的指数输入状态稳定性。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于稳定、单输入单输出、连续时间线性时不变（LTI）系统的低维观察器设计。

Method: 利用矩量匹配降阶技术，我们用降阶模型逼近系统。基于此降阶模型，我们设计了一个低维观察器来估计原系统的状态。

Result: 数值模拟证实了该方法对于基准降阶问题的有效性。

Conclusion: 该观察器为一类给定的、与观察器维度相关的输入建立了精确的渐近状态重构，并为通用输入建立了指数输入状态稳定性，确保了有界估计误差。

Abstract: This paper presents a low-dimensional observer design for stable,
single-input single-output, continuous-time linear time-invariant (LTI)
systems. Leveraging the model reduction by moment matching technique, we
approximate the system with a reduced-order model. Based on this reduced-order
model, we design a low-dimensional observer that estimates the states of the
original system. We show that this observer establishes exact asymptotic state
reconstruction for a given class of inputs tied to the observer's dimension.
Furthermore, we establish an exponential input-to-state stability property for
generic inputs, ensuring a bounded estimation error. Numerical simulations
confirm the effectiveness of the approach for a benchmark model reduction
problem.

</details>


### [305] [Cyber-Physical Co-Simulation of Load Frequency Control under Load-Altering Attacks](https://arxiv.org/abs/2508.00637)
*Michał Forystek,Andrew D. Syrmakesis,Alkistis Kontou,Panos Kotsampopoulos,Nikos D. Hatziargyriou,Charalambos Konstantinou*

Main category: eess.SY

TL;DR: 该研究提出了一个用于分析电网网络攻击的仿真环境。


<details>
  <summary>Details</summary>
Motivation: 将ICT设备集成到电网虽然带来好处，但也引入了新的网络威胁，特别是动态负荷改变攻击（DLAAs）对电网稳定构成了威胁。

Method: 提出一个开源的联合仿真环境，模拟电力系统和通信网络，并实现电网保护机制，以分析动态负荷改变攻击（DLAAs）对负荷频率控制（LFC）和低频负荷甩出（UFLS）的影响。

Result: 该仿真环境能够对DLAAs在LFC和UFLS场景下的影响进行全面的分析。

Conclusion: 该研究提出了一个开源的联合仿真环境，用于模拟电力系统及其通信网络，并实现了电网保护机制。

Abstract: Integrating Information and Communications Technology (ICT) devices into the
power grid brings many benefits. However, it also exposes the grid to new
potential cyber threats. Many control and protection mechanisms, such as Load
Frequency Control (LFC), responsible for maintaining nominal frequency during
load fluctuations and Under Frequency Load Shedding (UFLS) disconnecting
portion of the load during an emergency, are dependent on information exchange
through the communication network. The recently emerging Load Altering Attacks
(LAAs) utilize a botnet of high-wattage devices to introduce load fluctuation.
In their dynamic form (DLAAs), they manipulate the load in response to live
grid frequency measurements for increased efficiency, posing a notable threat
to grid stability. Recognizing the importance of communication networks in
power grid cyber security research, this paper presents an open-source
co-simulation environment that models the power grid with the corresponding
communication network, implementing grid protective mechanisms. This setup
allows the comprehensive analysis of the attacks in concrete LFC and UFLS
scenarios.

</details>


### [306] [Petri Net Modeling and Deadlock-Free Scheduling of Attachable Heterogeneous AGV Systems](https://arxiv.org/abs/2508.00724)
*Boyu Li,Zhengchen Li,Weimin Wu,Mengchu Zhou*

Main category: eess.SY

TL;DR: 开发了一种用于异构AGV（载波和穿梭车）的无死锁调度算法，该算法基于Petri网建模，并通过元启发式方法和自适应大邻域搜索进行优化，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了应对自动化和灵活性日益增长的需求，以及异构自动导引车（AGV）系统中存在的耦合和易死锁的调度问题，本研究旨在解决可附加异构AGV（包括载波和穿梭车）的调度问题。

Method: 提出了一种基于Petri网的调度模型，使用驱动触发解码方法，并结合了死锁检测与预防策略。开发了一种基于Petri网的元启发式算法，并将其集成到自适应大邻域搜索框架中，辅以加速方法以提高计算效率。

Result: 所提出的算法在模拟真实世界工业数据的数值实验中，被证明比工程实践中的调度策略、精确求解器和四种最先进的元启发式算法更有效。此外，还进行了敏感性分析以提供管理见解。

Conclusion: 本研究提出的基于Petri网的元启发式算法在调度问题上展现了有效性，并且能够确保无死锁的调度，在与工程实践、精确求解器和现有元启发式算法的比较中表现出优势，同时提供了管理学见解。

Abstract: The increasing demand for automation and flexibility drives the widespread
adoption of heterogeneous automated guided vehicles (AGVs). This work intends
to investigate a new scheduling problem in a material transportation system
consisting of attachable heterogeneous AGVs, namely carriers and shuttles. They
can flexibly attach to and detach from each other to cooperatively execute
complex transportation tasks. While such collaboration enhances operational
efficiency, the attachment-induced synchronization and interdependence render
the scheduling coupled and susceptible to deadlock. To tackle this challenge,
Petri nets are introduced to model AGV schedules, well describing the
concurrent and sequential task execution and carrier-shuttle synchronization.
Based on Petri net theory, a firing-driven decoding method is proposed, along
with deadlock detection and prevention strategies to ensure deadlock-free
schedules. Furthermore, a Petri net-based metaheuristic is developed in an
adaptive large neighborhood search framework and incorporates an effective
acceleration method to enhance computational efficiency. Finally, numerical
experiments using real-world industrial data validate the effectiveness of the
proposed algorithm against the scheduling policy applied in engineering
practice, an exact solver, and four state-of-the-art metaheuristics. A
sensitivity analysis is also conducted to provide managerial insights.

</details>


### [307] [Learning to optimize with guarantees: a complete characterization of linearly convergent algorithms](https://arxiv.org/abs/2508.00775)
*Andrea Martin,Ian R. Manchester,Luca Furieri*

Main category: eess.SY

TL;DR: 本文提出了一种方法，可以在保证算法最坏情况收敛性的同时，提高其在特定问题上的平均情况性能。该方法通过修改更新规则来实现，适用于梯度下降、Nesterov 加速方法和投影方法等多种算法，并在求解迭代次数受限的优化问题和 MPC 问题上得到了有效验证。


<details>
  <summary>Details</summary>
Motivation: 本文旨在解决在优化算法设计中，如何在保证最坏情况下的收敛性（在数学定义的有问题类别上具有可证明的最坏情况保证）的同时，提高其在实际应用中常见的问题实例上的平均情况性能。具体来说，研究人员希望增强一个给定的线性收敛算法，使其在特定目标问题（例如，针对特定动力系统的模型预测控制MPC的现成求解器）上的平均情况性能得到提升，同时保持其在整个问题类别上的最坏情况保证。

Method: 本文研究了一类非光滑复合优化问题的算法，并推导了保持线性收敛性质的更新规则修改方法。研究人员从一个基线线性收敛算法出发，得到了所有且仅有能够保持其收敛性质的更新规则修改方法。

Result: 本文成功地描述了一类非光滑复合优化问题的算法，并且推导出了所有能够保持线性收敛性质的更新规则修改方法。这些方法可以应用于梯度下降、Nesterov 加速方法和投影方法等多种算法。

Conclusion: 该研究推导了所有能维持收敛性质的更新规则的修改方法，并将该方法应用于梯度下降、Nesterov 加速方法和投影方法等算法，以增强它们在特定问题实例上的平均情况性能，同时保持其在整个问题类别上的最坏情况保证。在求解迭代次数受限的优化问题和 MPC 问题上展示了该方法的有效性。

Abstract: In high-stakes engineering applications, optimization algorithms must come
with provable worst-case guarantees over a mathematically defined class of
problems. Designing for the worst case, however, inevitably sacrifices
performance on the specific problem instances that often occur in practice. We
address the problem of augmenting a given linearly convergent algorithm to
improve its average-case performance on a restricted set of target problems -
for example, tailoring an off-the-shelf solver for model predictive control
(MPC) for an application to a specific dynamical system - while preserving its
worst-case guarantees across the entire problem class. Toward this goal, we
characterize the class of algorithms that achieve linear convergence for
classes of nonsmooth composite optimization problems. In particular, starting
from a baseline linearly convergent algorithm, we derive all - and only - the
modifications to its update rule that maintain its convergence properties. Our
results apply to augmenting legacy algorithms such as gradient descent for
nonconvex, gradient-dominated functions; Nesterov's accelerated method for
strongly convex functions; and projected methods for optimization over
polyhedral feasibility sets. We showcase effectiveness of the approach on
solving optimization problems with tight iteration budgets in application to
ill-conditioned systems of linear equations and MPC for linear systems.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [308] [Scalable, Wireless Determination of Electric Properties of Nanostructures via Electro-Rotation in Water Solution](https://arxiv.org/abs/2508.00227)
*Yun Huang,Kai Xu,Zexi Liang,Huaizhi Li,Wenjuan Zhu,Donglei Emma Fan*

Main category: physics.app-ph

TL;DR: 提出了一种快速、无线、平行表征纳米结构电导率的新方法，通过分析其在水中的电旋转行为，并与传统测量方法的结果进行了比较。


<details>
  <summary>Details</summary>
Motivation: 纳米技术在纳米粒子大规模制造方面取得了突破，但由于体积大和个体差异大，评估其电导率仍然具有挑战性。

Method: 利用基于Maxwell-Wagner和双电层极化的半定量模型，通过纳米结构在水中的电旋转行为，确定其电导率，数据与四探针测量结果吻合。

Result: 该方法能够表征包括绝缘体、半导体和导电金属氧化物在内的各种纳米结构，电导率跨越六个数量级。

Conclusion: 该方法为非破坏性、快速、简便的表征方法，有望推动纳米材料在电子、光学、传感、催化和机器人等领域的实际应用。

Abstract: Breakthroughs in nanotechnology have enabled the large-scale fabrication of
nanoparticles with varied compositions and structures. Yet, evaluating their
electrical conductivities remains challenging due to high volume and individual
variability. We report a rapid, wireless, and parallel method to characterize
longitudinal nanostructures, including insulators, semiconductors, and
conducting metal oxides by using MoO3, MoS2/MoO2, and MoS2 nanoribbons,
produced at different fabrication stages, as a model system. Leveraging our
semi-quantitative model based on Maxwell-Wagner and electrical double-layer
polarization, electric conductivities of various nanoparticles are determined
from their distinct electro-rotation behaviors in water, spanning six orders of
magnitude. The results agree well with standard four-probe measurements. These
findings highlight a non-destruction, rapid, simple characterization method
promising to bring nanomaterials closer to practical applications in
electronics, optics, sensing, catalysis, and robotics.

</details>


### [309] [A compact quasi-zero stiffness metamaterial based on monolithic shells for vibration isolation](https://arxiv.org/abs/2508.00310)
*Yong Zhang,Xianfeng Chen*

Main category: physics.app-ph

TL;DR: 本研究提出了一种新颖的、仅由单片壳体单元组成的设计，用于实现准零刚度（QZS）超材料，无需组合正负刚度部件。通过实验和数值模拟验证了该设计的有效性，并展示了其在低频振动隔离方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统QZS超材料需要组合两种组件的限制，提出了一种仅通过单片壳体单元的几何形状和非线性变形来实现QZS特性的新设计。

Method: 通过实验和数值方法研究了所提出的QZS超材料的静态和动态响应，并调整了几何参数以实现理想的零刚度行为。

Result: 实验证明了该超材料在低频振动隔离方面具有出色的性能，并且该设计理念可以扩展到构建具有多个零刚度特性的超材料。

Conclusion: 所提出的单片壳体单元的准零刚度（QZS）超材料设计提供了一种无需组合两个组件即可实现QZS特性的新颖方法，并且已通过实验和数值方法得到验证。

Abstract: Quasi-zero stiffness (QZS) metamaterials are highly effective in isolating
objects from low-frequency external vibrations, due to their high static
stiffness but low dynamic stiffness characteristics. Traditionally, QZS
metamaterials are designed by combining a negative-stiffness part with a
positive-stiffness counterpart. Here, we present a novel QZS metamaterial
design without relying on combining two components. The QZS characteristic is
achieved solely through monolithic shell elements' unique geometry and
nonlinear deformation. Using experimental and numerical approaches, we
investigate the static and dynamic responses of the proposed metamaterials as a
function of their geometric parameters. We then tune the structure's geometry
to achieve ideal zero-stiffness behaviors and experimentally demonstrate an
exceptional low-frequency vibration isolation mechanism. This concept can be
further utilized as a building block for constructing metamaterials with
multiple zero-stiffness features, enabling a broad range of applications.

</details>


### [310] [Spin light-emitting devices in a 2D magnet](https://arxiv.org/abs/2508.00572)
*Fanglu Qin,Haiyang Liu,Aosai Yang,Yilin Liu,Xuanji Wang,Yue Sun,Xinyi Zhou,Zdenek Sofer,Jiayuan Zhou,Xue Liu,Sheng Liu,Vanessa Li Zhang,Xiaoze Liu,Weibo Gao,Ting Yu*

Main category: physics.app-ph

TL;DR: 本研究成功研制出基于二维磁性半导体CrSBr的自旋LED原型，实现了由自旋翻转和自旋倾斜跃迁调制的电致发光，为二维光子-自旋电子器件的发展奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 二维磁性半导体材料为探索磁光和光子-自旋电子学应用提供了新的平台。尽管在自旋相关光电探测器和非易失性存储器领域已有广泛研究，但自旋调制的发光器件（自旋LED）的实现仍然是一个挑战。

Method: 通过集成二维半导体磁性材料CrSBr，构建了自旋LED原型，并在低温下对其进行了电致发光（EL）测试，研究了自旋翻转和自旋倾斜跃迁对其EL特性的影响。

Result: 成功实现了原型自旋LED，在低至双层CrSBr器件上观察到显著的电致发光。研究发现，自旋翻转和自旋倾斜跃迁能够分别引起EL特性的迟滞行为和连续调制，并揭示了磁序介导的激子跃迁与自旋电子传输的协同作用是实现这种调制的机制。

Conclusion: 本研究成功实现了集成二维半导体磁性材料CrSBr的自旋LED原型，并展示了其在低至双层器件上的电致发光特性。研究发现，自旋翻转和自旋倾斜跃迁能够直接调控该自旋LED的发光，其中自旋翻转实现了前所未有的电致发光迟滞行为，而自旋倾 দক্ষতার则实现了具有鲁棒抗异性的连续电致发光调制。

Abstract: Emerging two-dimensional (2D) magnetic semiconductors represent
transformative platforms to explore magneto-optics and opto-spintronic
applications. Though 2D opto-spintronics has attracted tremendous research
efforts in spin-dependent photodetectors and non-volatile memory components,
the realization of one core application - spin-modulated light-emitting device
(spin-LED) - remains elusive so far. Here we successfully realize prototype
spin-LED integrated with a 2D semiconducting magnet CrSBr, demonstrating
considerable electroluminescence (EL) down to bilayers. Intriguingly, the EL of
the spin-LED is discovered to be directly manipulated by spin-flip and
spin-canting transitions. Notably, spin-flip transitions enable unprecedented
hysteretic behaviors of EL characteristics, while spin-canting transitions
induce EL continuous modulation with robust anisotropy. This versatile
manipulation is originated from the synergy of magnetic-order mediated
excitonic transitions and spintronic transport. The prototype demonstration of
spin-LED establishes an indispensable scheme of opto-spintronic devices
leveraging 2D spin transitions and strong excitonic effects, presenting a
critical step towards integrated 2D opto-spintronics.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [311] [Explicit equivalence between the spectral localizer and local Chern and winding markers](https://arxiv.org/abs/2508.00214)
*Lucien Jezequel,Jens H. Bardarson,Adolfo G. Grushin*

Main category: cond-mat.mes-hall

TL;DR: 本文证明了谱局域化不变量和陈/绕组数不变量之间的等价性。


<details>
  <summary>Details</summary>
Motivation: 缺少平移对称性的无序、准晶或非晶拓扑系统，促使人们对拓扑不变量进行替代性的实空间定义，包括局域陈标记和谱局域化不变量。

Method: 通过利用谱局域化算子的Clifford代数，我们证明了陈和绕组标记作为展开的领先阶项出现。

Result: 陈和绕组标记作为展开的领先阶项出现，这是一种简单的、可供更广泛物理学受众使用的方法。

Conclusion: 本文从谱局域化算子的参数$
u$的幂次出发，明确展示了谱局域化不变量和陈/绕组数不变量之间的等价性。

Abstract: Topological band insulators are classified using momentum-space topological
invariants, such as Chern or winding numbers, when they feature translational
symmetry. The lack of translation symmetry in disordered, quasicrystalline, or
amorphous topological systems has motivated alternative, real-space definitions
of topological invariants, including the local Chern marker and the spectral
localizer invariant.
  However, the equivalence between these invariants is so far implicit. Here,
we explicitly demonstrate their equivalence from a systematic perturbative
expansion in powers of the spectral localizer's parameter $\kappa$. By
leveraging only the Clifford algebra of the spectral localizer, we prove that
Chern and winding markers emerge as leading-order terms in the expansion. It
bypasses abstract topological machinery, offering a simple approach accessible
to a broader physics audience.

</details>


### [312] [The Quadrupole Moment of Higher-Order Topological Insulator at Finite temperature](https://arxiv.org/abs/2508.00277)
*Yiting Deng,Yan He*

Main category: cond-mat.mes-hall

TL;DR: 研究发现，手征对称性保证了高温下高阶拓扑绝缘体的四极矩量子化。温度变化和无序性会引起拓扑相变，包括重入相变。


<details>
  <summary>Details</summary>
Motivation: 研究高温下高阶拓扑绝缘体的拓扑性质，并探索温度、各向异性胞内跳变和准无序跳变对拓扑相变的影响。

Method: 基于广义实空间四极矩，该研究将零温度下的基态期望推广至系综平均，用于分析高温下的高阶拓扑绝缘体。

Result: 1. 手征对称性保证有限温度下四极矩的量子化（0或1/2）。2. 有限温度可诱导从非平庸到平庸的拓扑相变。3. 各向异性胞内跳变可导致重入拓扑相变，与零温度下的结果形成对比。4. 准无序跳变可驱动平庸系统进入拓扑相，类似于拓扑安德森相变。

Conclusion: 该研究提出了一个基于广义实空间四极矩的新方法，用于研究高温下的高阶拓扑绝缘体。研究表明，手征对称性保证了即使在有限温度下，四极矩也只能取0和1/2两个值。研究还发现，有限温度可诱导从非平庸到平庸的拓扑相变，并且各向异性胞内跳变可导致系统出现与零温度相反的重入拓扑相变现象。此外，准无序跳变在足够强的无序强度下可驱动平庸系统进入拓扑相，这类似于拓扑安德森相变。该研究为研究高阶拓扑绝缘体在有限温度下的拓扑性质提供了实例。

Abstract: We study the higher-order topological insulators at finite temperature based
on a generalized real-space quadrupole moment, which extends the ground state
expectations to ensemble averages. Our study reveals that chiral symmetry alone
dictates that the quadrupole moment must be quantized to two values of $0$ and
$1/2$, even at finite temperature. It is found that finite temperature can
induce a topological phase transition from non-trivial to trivial. Furthermore,
we found that the anisotropic intra-cell hopping can lead to a reentrant
topological phase transition, in which the system becomes topological again
with rising temperature. This reentrant behavior is in stark contrast to the
results at zero temperature. We also investigate the effects of the
quasi-disorder hopping on the topology. It is found that the initially trivial
system can be driven into a topological phase with strong enough disorder
strength, which closely resembles the topological Anderson transition. Our work
provides an example for studying the finite temperature topology of
higher-order topological insulators.

</details>


### [313] [Self-strain suppression of the metal-to-insulator transition in phase-change oxide devices](https://arxiv.org/abs/2508.00347)
*Nicolò D'Anna,Nareg Ghazikhanian,Erik S. Lamb,Edoardo Zatterin,Mingze Wan,Ashley Thorshov,Ivan K. Schuller,Oleg Shpyrko*

Main category: cond-mat.mes-hall

TL;DR: V2O3微器件的X射线纳米衍射研究表明，镓离子辐照导致的应变会抑制其金属-绝缘体转变。该效应在纳米尺度上对于相变器件的相工程至关重要。


<details>
  <summary>Details</summary>
Motivation: 具有可通过外部刺激（如电场）控制的相变的量子材料，因其具有内在的记忆性，类似于神经突触，因此有望用于神经形态计算。特别是相变氧化物，可以控制金属-绝缘体转变。

Method: 通过X射线纳米衍射结构成像，对含有镓离子辐照区域的钒氧化物（V2O3）微器件进行了研究。辐照区域会降低金属-绝缘体转变的临界温度。

Result: 研究结果表明，原始材料与辐照材料之间的晶格失配引起的应变会导致金属-绝缘体转变的抑制。抑制作用发生在辐照区域内部或其边缘，具体取决于缺陷分布和区域大小。

Conclusion: 应变诱导的金属-绝缘体转变抑制现象可能延伸到其他相变氧化物，并且随着器件尺寸减小而变得更加重要，因为减小尺寸会限制应变在辐照区域内的消散。这些发现对于相变器件中的相工程具有重要意义，并强调了在纳米尺度上研究相变行为的必要性。

Abstract: Quantum materials exhibiting phase transitions which can be controlled
through external stimuli, such as electric fields, are promising for future
computing technologies beyond conventional semiconductor transistors. Devices
that take advantage of structural phase transitions have inherent built-in
memory, reminiscent of synapses and neurons, and are thus natural candidates
for neuromorphic computing. Of particular interest are phase-change oxides,
which allow for control over the metal-to-insulator transition. Here, we report
X-ray nano-diffraction structural imaging of micro-devices fabricated with the
archetypal phase-change material vanadium sesquioxide (V$_2$O$_3$). The devices
contain a Ga ion-irradiated region where the metal-to-insulator transition
critical temperature is lowered, a useful feature for controlling neuron-like
spiking behavior. Results show that strain, induced by crystal lattice mismatch
between the pristine and irradiated material, leads to a suppression of the
metal-to-insulator-transition. Suppression occurs within the irradiated region
or along its edges, depending on the defect-distribution and the size of the
region. The observed self-straining effect could extend to other phase-change
oxides and dominate as device dimensions are reduced and become too small to
dissipate strain within the irradiated region. The findings are important for
phase engineering in phase-change devices and highlight the necessity to study
phase transitions at the nanoscale.

</details>


### [314] [Precision high-speed quantum logic with holes on a natural silicon foundry platform](https://arxiv.org/abs/2508.00446)
*Isaac Vorreiter,Jonathan Y. Huang,Scott D. Liles,Joe Hillier,Ruoyu Li,Bart Raes,Stefan Kubicek,Julien Jussot,Sofie Beyne,Clement Godfrin,Sugandha Sharma,Danny Wan,Nard Dumoulin Stuyck,Will Gilbert,Chih Hwan Yang,Andrew S. Dzurak,Kristiaan De Greve,Alexander R. Hamilton*

Main category: cond-mat.mes-hall

TL;DR: 硅基穴自旋量子比特性能接近电子量子比特，创下自然硅中的新纪录，有望推动量子CMOS架构发展。


<details>
  <summary>Details</summary>
Motivation: 为了克服硅基穴自旋量子比特相比电子量子比特在抗无序性和复杂自旋物理方面存在的挑战，并利用其紧凑的全电学控制优势。

Method: 通过快速量子比特控制、交换脉冲和工业级制造技术，实现了高保真度的硅基穴自旋量子比特操作。

Result: 实现了高达99.8%的单量子比特门保真度和240的双量子比特门品质因数，表明物理保真度极限为99.7%。

Conclusion: 硅基穴自旋量子比特的性能已接近电子量子比特，在自然硅中达到了最高的单量子比特门保真度（99.8%）和高双量子比特门品质因数（240），预示着其在量子CMOS架构中的巨大潜力，尤其是在结合了同位素纯化和设备优化后。

Abstract: Silicon spin qubits in gate-defined quantum dots leverage established
semiconductor infrastructure and offer a scalable path toward transformative
quantum technologies. Holes spins in silicon offer compact all-electrical
control, whilst retaining all the salient features of a quantum dot qubit
architecture. However, silicon hole spin qubits are not as advanced as
electrons, due to increased susceptibility to disorder and more complex spin
physics. Here we demonstrate single-qubit gate fidelities up to 99.8% and a
two-qubit gate quality factor of 240, indicating a physical fidelity limit of
99.7%. These results represent the highest performance reported in natural
silicon to date, made possible by fast qubit control, exchange pulsing, and
industrial-grade fabrication. Notably, we achieve these results in a
near-identical device as used for highly reproducible, high-fidelity electron
spin qubits. With isotopic purification and device-level optimisations in the
future, our hole spin qubits are poised to unlock a new operation regime for
quantum CMOS architectures.

</details>


### [315] [Electric Field Switching of Magnon Spin Current in a Compensated Ferrimagnet](https://arxiv.org/abs/2311.15183)
*Kaili Li,Lei Wang,Yu Wang,Yuanjun Guo,Shuping Lv,Yuewei He,Weiwei Lin,Tai Min,Shaojie Hu,Sen Yang,Dezhen Xue,Aqun Zheng,Shuming Yang,Xiangdong Ding*

Main category: cond-mat.mes-hall

TL;DR: 本研究首次证明了可以通过电场控制磁畴自旋流，为开发全电信号读写的磁畴逻辑器件奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了实现低功耗、非易失性的磁畴记忆和逻辑器件，需要一种不依赖磁场或电流，而是通过电场控制磁畴自旋流的方法。

Method: 本研究将磁畴材料钆铁石榴石（Gd3Fe5O12, GdIG）薄膜置于压电衬底上，利用自旋塞贝克效应产生磁畴自旋流，并通过电场调控。

Result: 研究观察到磁畴极化可逆地被电场切换，且无需施加电荷电流。

Conclusion: 本研究通过集成磁畴材料和压电材料，成功实现了在不施加电流的情况下，利用电场控制磁畴自旋流。

Abstract: Manipulation of directional magnon propagation, known as magnon spin current,
is essential for developing magnonic memory and logic devices featuring
nonvolatile functionalities and ultralow power consumption. Magnon spin current
can usually be modulated by magnetic field or current-induced spin torques.
However, these approaches may lead to energy dissipation caused by Joule
heating. Electric-field switching of magnon spin current without charge current
is highly desired but very challenging to realize. By integrating magnonic and
piezoelectric materials, we demonstrate manipulation of the magnon spin current
generated by the spin Seebeck effect in the ferrimagnetic insulator Gd3Fe5O12
(GdIG) film on a piezoelectric substrate. We observe reversible electric-field
switching of magnon polarization without applied charge current. Through
strain-mediated magnetoelectric coupling, the electric field induces the
magnetic compensation transition between two magnetic states of the GdIG,
resulting in its magnetization reversal and the simultaneous switching of
magnon spin current. Our work establishes a prototype material platform that
pave the way for developing magnon logic devices characterized by all electric
field reading and writing and reveals the underlying physics principles of
their functions.

</details>


### [316] [Localized states and skin effect around non-Hermitian impurities in tight-binding models](https://arxiv.org/abs/2508.00519)
*Balázs Hetényi,Balázs Dóra*

Main category: cond-mat.mes-hall

TL;DR: 该研究分析了一维格点系统中厄米和非厄米杂质的影响，发现了边缘态、例外线和非厄米皮肤效应。


<details>
  <summary>Details</summary>
Motivation: 分析包含厄米或非厄米杂质键的一维紧束缚格点系统的行为，特别是边缘态和非厄米皮肤效应。

Method: 使用Alase等人提出的广义布洛赫定理形式主义来分析一维紧束缚格点系统。计算了能带结构、体边对应指示符D_L(ε)，并分析了格点平移算符z的特征值，以重建广义布洛赫区域。

Result: 找到了厄米杂质和非厄米杂质的局域化边缘态的条件。发现非厄米杂质导致例外线和纯虚数能量。识别了一个表现出非厄米皮肤效应的中间区域，其中大部分态具有复能量特征值并向杂质局域化。

Conclusion: 该研究使用广义布洛赫定理分析了一维紧束缚格点系统，该系统包含一个厄米或非厄米的杂质键。研究发现，在厄米杂质情况下，存在一个参数区域，其中两个局域化边缘态会与紧束缚带分离。在非厄米杂质情况下，存在一个能量特征值为纯虚数的区域，并且两个零能本征向量会合并，形成一个例外线。在两者之间的插值扫描中，发现了一个表现出非厄米皮肤效应的中间区域，其中大部分态具有复能量特征值并向杂质局域化。

Abstract: We use the generalized Bloch theorem formalism of Alase {\it et al.} [{\it
Phys. Rev. Lett.} {\bf 117} 076804 (2016)] to analyze simple one-dimensional
tight-binding lattice systems connected by Hermitian bonds (all with the same
hopping parameter $t$), but containing one bond impurity which can be either
Hermitian or non-Hermitian. We calculate the band structure, the bulk-boundary
correspondence indicator ($D_L(\epsilon)$) and analyze the eigenvalues of the
lattice translation operator ($z$), for each eigenstate. From the $z$ values
the generalized Brillouin zone can be reconstructed. If the impurity is
Hermitian (and $\mathcal{PT}$-symmetric), we find a parameter regime in which
two localized edge states separate from the tight-binding band. We then
simulate a non-Hermitian impurity by keeping hopping in one direction of the
bond impurity the same as the rest of the tight-binding system, and varying
only its reciprocal. Again, we find a region with localized edge states, but in
this case the energy eigenvalues are purely imaginary. We also find that in
this case the two zero energy eigenvectors coalesce, hence this system is an
exceptional line. We then perform an interpolative scan between the above two
scenarios and find that there is an intermediate region exhibiting a
non-Hermitian skin effect. In this region a macroscopic fraction of states
acquire complex energy eigenvalues and exhibit localization towards the
impurity. Our numerical results are supported by a detailed analysis of the
solutions of the boundary/impurity equation.

</details>


### [317] [Wave-mixing cathodoluminescence microscopy of low-frequency excitations](https://arxiv.org/abs/2508.00560)
*Leila Prelat,Eduardo J. C. Dias,F. Javier García de Abajo*

Main category: cond-mat.mes-hall

TL;DR: 本研究通过理论研究了光与电子的相互作用，实现了利用可见光对物体进行纳米分辨率成像，并成功获得了视网膜的振动指纹。


<details>
  <summary>Details</summary>
Motivation: 结合光学和电子诱导场通过材料结构的非线性响应，有望揭示新的物理现象并实现颠覆性的应用。

Method: 本研究提出了一个通用的理论框架来量化光子转换概率，并通过揭示仅使用可见光对视网膜的远红外振动指纹进行了演示。

Result: 理论研究了外部光与自由电子的渐失场之间的波混，以及由标本的二阶非线性响应介导的非弹性光子散射。结果表明，入射光子可以蓝移或红移，而通过的电子相应地损失或获得能量。当频率移动与标本的光学共振相匹配时，这些过程会得到显著增强。

Conclusion: 该现象为利用可见光和现有电子显微镜对低频激发进行纳米分辨率空间测绘提供了一种实用的方法，这不仅具有基础意义，而且具有重要的应用价值。

Abstract: Nonlinear optical phenomena such as parametric amplification and frequency
conversion are typically driven by external optical fields. Free electrons can
also act as electromagnetic sources, offering unmatched spatial precision.
Combining optical and electron-induced fields via the nonlinear response of
material structures therefore holds potential for revealing new physical
phenomena and enabling disruptive applications. Here, we theoretically
investigate wave mixing between external light and the evanescent fields of
free electrons, giving rise to inelastic photon scattering mediated by the
second-order nonlinear response of a specimen. Specifically, an incident photon
may be blue- or red-shifted, while the passing electron correspondingly loses
or gains energy. These processes are strongly enhanced when the frequency shift
matches an optical resonance of the specimen. We present a general theoretical
framework to quantify the photon conversion probability and demonstrate its
application by revealing far-infrared vibrational fingerprints of retinal using
only visible light. Beyond its fundamental interest, this phenomenon offers a
practical approach for spatially mapping low-frequency excitations with
nanometer resolution using visible photon energies and existing electron
microscopes.

</details>


### [318] [Chiral anomaly-induced nonlinear Hall effect in spin-orbit coupled noncentrosymmetric metals](https://arxiv.org/abs/2508.00821)
*Gautham Varma K,Mohd. Hashim Raza,Azaz Ahmad*

Main category: cond-mat.mes-hall

TL;DR: 研究SOC-NCMs中的非线性输运，发现手征反常诱导的非线性霍尔效应受磁场和能带倾斜影响，具有负值和各向异性，并提出可用于设计方向依赖性电导的实验。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于，近期的研究表明手征反常不仅存在于Weyl半金属（WSMs）中，也存在于更广泛的材料类别——自旋轨道耦合非中心对称金属（SOC-NCMs）中。这揭示了手征反常起源于费米面性质而非节点性质。因此，本研究旨在进一步探索SOC-NCMs中的非线性输运响应，以期更深入地理解手征反常。

Method: 本研究采用麦克斯韦-玻尔兹曼输运理论，并结合电荷守恒和依赖于动量的散射过程（包括非磁性和磁性杂质散射）来分析自旋轨道耦合非中心对称金属（SOC-NCMs）中的非线性输运响应。

Result: 研究发现，手征反常诱导的非线性霍尔（CNLH）响应对施加的磁场呈二次方依赖，且对于非磁性和磁性杂质散射均为负值。磁性散射子虽然会改变信号幅度，但不会影响其定性行为。能带倾斜效应则会引入显著的各向异性响应，包括磁场方向依赖的符号反转，并存在强弱两种情况。CNLH响应的方向各向异性主要由外磁场和倾斜矢量的相对取向决定。

Conclusion: 本研究通过半经典动力学理论，结合麦克斯韦-玻尔兹曼输运理论，并考虑了电荷守恒和依赖于动量的散射过程，探索了自旋轨道耦合非中心对称金属（SOC-NCMs）中的非线性输运响应。研究结果表明，手征反常诱导的非线性霍尔（CNLH）响应对施加的磁场呈二次方依赖，并且对于非磁性和磁性杂质散射均表现为负值。磁性散射子的存在会影响信号的幅度，但不会改变其定性行为。此外，能带色散中的倾斜效应会引起显著的各向异性响应，包括磁场方向依赖的符号反转（可分为弱和强两种情况）。CNLH响应表现出由外磁场与倾斜矢量相对取向决定的显著方向各向异性。

Abstract: Recent studies have shown that chiral anomaly is not limited to WSMs, but are
also shown by a larger class of materials called spin orbit coupled
noncentrosymmetric metals (SOC-NCMs),which has shed more insight into the
origin of chiral anomaly as a Fermi surface property rather than a nodal
property. In this study, we explore nonlinear transport responses in
SOC-NCMswithin the framework of semiclassical dynamics, employing the
Maxwell-Boltzmann transport theory augmented by charge conservation and
momentum-dependent scattering processes. We take into account both non-magnetic
and magnetic impurity scattering mechanisms. We demonstrate that the
chiral-anomaly-induced nonlinear Hall (CNLH) response exhibits a characteristic
quadratic dependence on the applied magnetic field and remains negative for
both types of impurities. We find that magnetic scatterers leading to
enhanced/suppressed interband scattering modifies the magnitude of the signal,
but does not affect its qualitative behavior. In contrast, the presence of tilt
in the band dispersion induces a pronounced anisotropic response, including a
magnetic-field-direction dependent sign reversal that can be categorized into
weak and strong regimes. Furthermore, the CNLH response shows substantial
directional anisotropy governed by the relative orientation of the external
magnetic field and the tilt vector. Our findings will be helpful in designing
the experimental setup to get direction-dependent conductivity, which can be
tuned externally with the help of magnetic impurity sites.

</details>


### [319] [Spin Quenching and Transport by Hidden Dzyaloshinskii-Moriya Interactions](https://arxiv.org/abs/2410.06690)
*Xiyin Ye,Qirui Cui,Weiwei Lin,Tao Yu*

Main category: cond-mat.mes-hall

TL;DR: 在单轴反铁磁体中，隐藏的Dzyaloshinskii-Moriya相互作用抑制了磁矢量的角动量流。受晶格对称性保护的“节点”和“角”自旋在特定区域奇异分布，并可通过施加磁场调控。


<details>
  <summary>Details</summary>
Motivation: 研究以前认为磁矩动力学由偶极和交换耦合等显式相互作用控制，但这些相互作用可能隐藏在全局晶体对称性之外。

Method: 通过研究单轴反铁磁体中隐藏的Dzyaloshinskii-Moriya相互作用，解释了磁矢量角动量流被抑制的现象，并识别了受晶格对称性保护的“节点”和“角”自旋。

Result: 发现隐藏的Dzyaloshinskii-Moriya相互作用抑制了磁矢量的角动量流，并且“节点”和“角”自旋在布里渊区的高对称性退化点（热点）分布奇异，受晶格对称性保护，并且受偏置磁场沿Néel矢量的影响。

Conclusion: 该研究揭示了一种隐藏的Dzyaloshinskii-Moriya相互作用，它在单轴反铁磁体中抑制了磁矢量的角动量流，并通过晶格对称性保护了某些“节点”和“角”自旋。

Abstract: Explicit interactions, \textit{e.g.}, dipolar and exchange couplings, usually
govern magnetization dynamics. Some interactions may be hidden from the global
crystal symmetry. We report that in a large class of \textit{uniaxial}
antiferromagnets, a \textit{hidden} Dzyaloshinskii-Moriya interaction with
retaining global inversion symmetry quenches the spin of magnon along the
N\'eel vector ${\bf n}$, thus forbidding its angular-momentum flow. Some magnon
spins, termed ``nodal" and ``corner" spins, survive when they distribute
\textit{singularly} at the hot spots, i.e., high-symmetric degeneracy points in
the Brillouin zone, and are protected by crystal symmetries. The biased
magnetic field along ${\bf n}$ broadens such distributions, allowing bulk spin
transport with unique signatures in the magnetic field and temperature
dependencies. This explains recent experiments and highlights the role of
hidden interaction.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [320] [Reinitializing weights vs units for maintaining plasticity in neural networks](https://arxiv.org/abs/2508.00212)
*J. Fernando Hernandez-Garcia,Shibhansh Dohare,Jun Luo,Rich S. Sutton*

Main category: cs.NE

TL;DR: This paper compares reinitializing network units versus weights to prevent plasticity loss in continually learning neural networks. The proposed selective weight reinitialization method is more effective in certain scenarios, like smaller networks or networks with layer normalization, and generally maintains plasticity better across various settings.


<details>
  <summary>Details</summary>
Motivation: Loss of plasticity is a crucial problem to overcome when designing systems that learn continually. This paper investigates effective techniques for preventing loss of plasticity, specifically comparing reinitializing units vs. reinitializing weights.

Method: We propose a new algorithm, selective weight reinitialization, which reinitializes the least useful weights in a network. We compare this algorithm to continual backpropagation and ReDo, which reinitialize units in the network.

Result: Experiments in continual supervised learning problems show that reinitializing weights is more effective than reinitializing units when the network has a small number of units or includes layer normalization. Otherwise, both methods are equally effective. Reinitializing weights maintains plasticity in a wider variety of settings.

Conclusion: Reinitializing weights maintains plasticity in a wider variety of settings than reinitializing units.

Abstract: Loss of plasticity is a phenomenon in which a neural network loses its
ability to learn when trained for an extended time on non-stationary data. It
is a crucial problem to overcome when designing systems that learn continually.
An effective technique for preventing loss of plasticity is reinitializing
parts of the network. In this paper, we compare two different reinitialization
schemes: reinitializing units vs reinitializing weights. We propose a new
algorithm, which we name \textit{selective weight reinitialization}, for
reinitializing the least useful weights in a network. We compare our algorithm
to continual backpropagation and ReDo, two previously proposed algorithms that
reinitialize units in the network. Through our experiments in continual
supervised learning problems, we identify two settings when reinitializing
weights is more effective at maintaining plasticity than reinitializing units:
(1) when the network has a small number of units and (2) when the network
includes layer normalization. Conversely, reinitializing weights and units are
equally effective at maintaining plasticity when the network is of sufficient
size and does not include layer normalization. We found that reinitializing
weights maintains plasticity in a wider variety of settings than reinitializing
units.

</details>


### [321] [Sequential, Parallel and Consecutive Hybrid Evolutionary-Swarm Optimization Metaheuristics](https://arxiv.org/abs/2508.00229)
*Piotr Urbańczyk,Aleksandra Urbańczyk,Magdalena Król,Leszek Rutkowski,Marek Kisiel-Dorohinicki*

Main category: cs.NE

TL;DR: 混合进化-群体元启发式方法，特别是连续混合PSO-GA算法，在处理高维问题时优于标准GA和PSO。


<details>
  <summary>Details</summary>
Motivation: 为了探索混合进化-群体元启发式方法，并引入一种新颖的连续混合PSO-GA进化算法。

Method: 通过结合PSO和GA的特征，以顺序、并行和连续的方式探索混合进化-群体元启发式方法，并与标准的GA和PSO进行比较。通过修改GA的变异算子来继承速度和个人最佳信息，引入了一种新颖的连续混合PSO-GA进化算法。

Result: 混合方法在包括Ackley、Griewank、Levy、Michalewicz、Rastrigin、Schwefel和Shifted Rotated Weierstrass在内的基准函数集上，以及在多个维度上进行了测试。实验结果表明，混合方法在收敛性和一致性方面表现优越，尤其是在更高维度的搜索空间中。

Conclusion: 混合算法在更高维度搜索空间中表现出优越的收敛性和一致性，特别是新提出的连续混合PSO-GA算法通过显式的信​​息传递机制确保了PSO和GA步骤之间的连续性。

Abstract: The goal of this paper is twofold. First, it explores hybrid
evolutionary-swarm metaheuristics that combine the features of PSO and GA in a
sequential, parallel and consecutive manner in comparison with their standard
basic form: Genetic Algorithm and Particle Swarm Optimization. The algorithms
were tested on a set of benchmark functions, including Ackley, Griewank, Levy,
Michalewicz, Rastrigin, Schwefel, and Shifted Rotated Weierstrass, across
multiple dimensions. The experimental results demonstrate that the hybrid
approaches achieve superior convergence and consistency, especially in
higher-dimensional search spaces. The second goal of this paper is to introduce
a novel consecutive hybrid PSO-GA evolutionary algorithm that ensures
continuity between PSO and GA steps through explicit information transfer
mechanisms, specifically by modifying GA's variation operators to inherit
velocity and personal best information.

</details>


### [322] [Evolutionary Generative Optimization: Towards Fully Data-Driven Evolutionary Optimization via Generative Learning](https://arxiv.org/abs/2508.00380)
*Kebin Sun,Tao Jiang,Ran Cheng,Yaochu Jin,Kay Chen Tan*

Main category: cs.NE

TL;DR: EvoGO is a new data-driven evolutionary optimization framework that uses generative learning to improve performance and reduce reliance on handcrafted heuristics. It streamlines the process into data preparation, model training, and population generation, consistently converging within 10 generations and outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Most existing data-driven EAs remain dependent on handcrafted heuristics, which limits their generality and automation. EvoGO aims to address this challenge by proposing a fully data-driven framework.

Method: EvoGO is a fully data-driven framework empowered by generative learning. It streamlines the evolutionary optimization process into three stages: data preparation, model training, and population generation. The data preparation stage constructs a pairwise dataset to enrich training diversity without incurring additional evaluation costs. During model training, a tailored generative model learns to transform inferior solutions into superior ones. In the population generation stage, EvoGO replaces traditional reproduction operators with a scalable and parallelizable generative mechanism.

Result: Extensive experiments on numerical benchmarks, classical control problems, and high-dimensional robotic tasks demonstrate EvoGO's effectiveness.

Conclusion: EvoGO consistently converges within merely 10 generations and significantly outperforms a wide spectrum of optimization approaches, including traditional EAs, Bayesian optimization, and reinforcement learning based methods.

Abstract: Recent advances in data-driven evolutionary algorithms (EAs) have
demonstrated the potential of leveraging data to improve optimization accuracy
and adaptability. Nevertheless, most existing approaches remain dependent on
handcrafted heuristics, which limits their generality and automation. To
address this challenge, we propose Evolutionary Generative Optimization
(EvoGO), a fully data-driven framework empowered by generative learning. EvoGO
streamlines the evolutionary optimization process into three stages: data
preparation, model training, and population generation. The data preparation
stage constructs a pairwise dataset to enrich training diversity without
incurring additional evaluation costs. During model training, a tailored
generative model learns to transform inferior solutions into superior ones. In
the population generation stage, EvoGO replaces traditional reproduction
operators with a scalable and parallelizable generative mechanism. Extensive
experiments on numerical benchmarks, classical control problems, and
high-dimensional robotic tasks demonstrate that EvoGO consistently converges
within merely 10 generations and significantly outperforms a wide spectrum of
optimization approaches, including traditional EAs, Bayesian optimization, and
reinforcement learning based methods. Source code will be made publicly
available.

</details>


### [323] [STF: Shallow-Level Temporal Feedback to Enhance Spiking Transformers](https://arxiv.org/abs/2508.00387)
*Zeqi Zheng,Zizheng Zhu,Yingchao Yu,Yanchen Huang,Changze Lv,Junfeng Tang,Zhaofei Yu,Yaochu Jin*

Main category: cs.NE

TL;DR: STF 是一个轻量级的模块，可以插入到编码层，以提高 Transformer-SNN 的性能，其方法是增强脉冲模式的多样性。


<details>
  <summary>Details</summary>
Motivation: Transformer-SNNs 由于脉冲串的二值性质，在性能上与浮点ANNs存在较大差距。为了缩小这一差距，已引入深度反馈回路，但这些设计通常跨越多层，导致特征转换成本高、参数开销大、能耗增加和推理延迟长。

Method: 提出了一种名为浅层时间反馈 (STF) 的轻量级即插即用模块，该模块包含时间空间位置嵌入 (TSPE) 和时间反馈 (TF)，用于编码层。

Result: STF 在 CIFAR-10、CIFAR-100 和 ImageNet-1K 等静态数据集上的各种基于 Transformer 的 SNN 主干网络上，在不同的脉冲时间步长设置下，始终提高了性能。

Conclusion: STF 增强了脉冲模式的多样性，这是性能提升的关键。在对抗鲁棒性和时间敏感性方面的评估也证实了 STF 优于直接编码及其变体，凸显了其作为静态场景新脉冲编码方案的潜力。

Abstract: Transformer-based Spiking Neural Networks (SNNs) suffer from a great
performance gap compared to floating-point Artificial Neural Networks (ANNs)
due to the binary nature of spike trains. Recent efforts have introduced
deep-level feedback loops to transmit high-level semantic information to narrow
this gap. However, these designs often span multiple deep layers, resulting in
costly feature transformations, higher parameter overhead, increased energy
consumption, and longer inference latency. To address this issue, we propose
Shallow-level Temporal Feedback (STF), a lightweight plug-and-play module for
the encoding layer, which consists of Temporal-Spatial Position Embedding
(TSPE) and Temporal Feedback (TF).Extensive experiments show that STF
consistently improves performance across various Transformer-based SNN
backbones on static datasets, including CIFAR-10, CIFAR-100, and ImageNet-1K,
under different spike timestep settings. Further analysis reveals that STF
enhances the diversity of the spike patterns, which is key to performance gain.
Moreover, evaluations on adversarial robustness and temporal sensitivity
confirm that STF outperforms direct coding and its variants, highlighting its
potential as a new spike encoding scheme for static scenarios. Our code will be
released upon acceptance.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [324] [Strategic Communication and Language Bias in Multi-Agent LLM Coordination](https://arxiv.org/abs/2508.00032)
*Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano,The Anh Han,German Castignani,Pietro Liò*

Main category: cs.MA

TL;DR: LLM代理间的沟通会因语言、个性和游戏结构的不同而影响合作行为，既能促进协调，也可能强化偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨了LLM代理之间的沟通是否会放大语言对合作行为的影响。

Method: 使用FAIRGAME框架，在有无沟通的情况下，针对不同语言和模型模拟了单局和重复博弈。

Result: 实验表明，沟通显著影响代理行为，并且这种影响因语言、个性和游戏结构而异。

Conclusion: LLM代理之间的沟通会放大语言对合作行为的影响，但这种影响因语言、个性和游戏结构而异。沟通在促进协调和强化偏见方面起着双重作用。

Abstract: Large Language Model (LLM)-based agents are increasingly deployed in
multi-agent scenarios where coordination is crucial but not always assured.
Previous studies indicate that the language used to frame strategic scenarios
can influence cooperative behavior. This paper explores whether allowing agents
to communicate amplifies these language-driven effects. Leveraging the FAIRGAME
framework, we simulate one-shot and repeated games across different languages
and models, both with and without communication. Our experiments, conducted
with two advanced LLMs, GPT-4o and Llama 4 Maverick, reveal that communication
significantly influences agent behavior, though its impact varies by language,
personality, and game structure. These findings underscore the dual role of
communication in fostering coordination and reinforcing biases.

</details>


### [325] [WMAS: A Multi-Agent System Towards Intelligent and Customized Wireless Networks](https://arxiv.org/abs/2508.00280)
*Jingchen Peng,Dingli Yuan,Boxiang Ren,Jie Fan,Hao Wu,Lu Yang*

Main category: cs.MA

TL;DR: 提出了一种名为WMAS的无线多智能体系统，通过基于强化学习的对话拓扑优化，提高了无线网络中智能体的任务处理效率和通信性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决在无线多智能体系统中，智能体编排可能出现的故障以及多智能体对话陷入无限循环的风险，需要设计一种能够以高准确性和低通信开销来完成UE任务请求的对话拓扑。

Method: 通过将多智能体对话拓扑建模为有向无环图，并提出一种基于强化学习的算法来优化该图的邻接矩阵，以解决智能体之间可能出现的通信循环和故障问题。

Result: 仿真结果表明，与现有的多智能体系统相比，WMAS在各种任务类型中实现了更高的任务性能和更低的通信开销。

Conclusion: 所提出的WMAS能够通过生成和自优化多智能体对话拓扑，有效且协作地处理来自UE的各种任务请求，在任务性能方面优于现有系统，并降低了通信开销，验证了其在增强未来无线网络智能方面的潜力。

Abstract: The fast development of Artificial Intelligence (AI) agents provides a
promising way for the realization of intelligent and customized wireless
networks. In this paper, we propose a Wireless Multi-Agent System (WMAS), which
can provide intelligent and customized services for different user equipment
(UEs). Note that orchestrating multiple agents carries the risk of malfunction,
and multi-agent conversations may fall into infinite loops. It is thus crucial
to design a conversation topology for WMAS that enables agents to complete UE
task requests with high accuracy and low conversation overhead. To address this
issue, we model the multi-agent conversation topology as a directed acyclic
graph and propose a reinforcement learning-based algorithm to optimize the
adjacency matrix of this graph. As such, WMAS is capable of generating and
self-optimizing multi-agent conversation topologies, enabling agents to
effectively and collaboratively handle a variety of task requests from UEs.
Simulation results across various task types demonstrate that WMAS can achieve
higher task performance and lower conversation overhead compared to existing
multi-agent systems. These results validate the potential of WMAS to enhance
the intelligence of future wireless networks.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [326] [Switchable Exchange Bias Resulting from Correlated Domain Structures in Orthogonally Coupled Antiferromagnet/Ferromagnet van der Waals Heterostructures](https://arxiv.org/abs/2508.00082)
*Aditya Kumar,Sadeed Hameed,Thibaud Denneulin,Aravind Puthirath Balan,Joseph Vas,Kilian Leutner,Lei Gao,Olena Gomonay,Jairo Sinova,Rafal E. Dunin-Borkowski,Mathias Kläui*

Main category: cond-mat.mtrl-sci

TL;DR: 通过CrSBr对FGT畴构型的作用，揭示了Fe3GeTe2 (FGT) 中不对称磁化反转和交换偏倚的机制。


<details>
  <summary>Details</summary>
Motivation: 为在原子精度下工程化界面自旋相互作用，为非平凡的自旋纹理和动态行为提供了一个多功能的平台。

Method: 本研究利用异相电子全息术对畴结构进行横截面磁成像，揭示了不对称开关和交换偏倚的微观起源。

Result: 在Fe3GeTe2 (FGT) 中观察到强烈的界面交换相互作用，从而产生明显的、可切换的交换偏倚和不对称开关，这种效应一直持续到CrSBr的N'eel温度（132 K）。

Conclusion: 该研究揭示了正交耦合范德华体系中交换偏倚的机制，并通过界面交换相互作用证明了在铁磁体中稳定三维畴结构的方法。

Abstract: Van der Waals (vdW) magnetic heterostructures offer a versatile platform for
engineering interfacial spin interactions with atomic precision, enabling
nontrivial spin textures and dynamic behaviors. In this work, we report robust
asymmetric magnetization reversal and exchange bias in Fe3GeTe2 (FGT), driven
by interlayer exchange coupling with the A-type antiferromagnet CrSBr. Despite
the orthogonal magnetic anisotropies out-of-plane easy axis in FGT and in-plane
in CrSBr, we observe a strong interfacial exchange interaction that gives rise
to pronounced and switchable exchange bias and asymmetric switching in FGT,
persisting up to the N\'eel temperature of CrSBr (132 K) as revealed by
anomalous Hall effect measurements.
  We uncover the microscopic origin of this behavior through cross-sectional
magnetic imaging of the domain structure using off-axis electron holography.
The results reveal that the asymmetric switching and exchange bias arise from
the influence of CrSBr on the domain configuration of FGT, where the in-plane
antiferromagnetic state of CrSBr promotes the formation of stripe-like domain
structures in FGT with circular rotation of magnetization in the
cross-sectional bc plane defined by the easy axes of both FGT and CrSBr. These
findings elucidate the mechanism of exchange bias in orthogonally coupled van
der Waals systems and demonstrate a pathway for stabilizing three-dimensional
domain structures in ferromagnets through interfacial exchange interactions.

</details>


### [327] [Impact of Metal Cation on Chiral Properties of 2D Halide Perovskites](https://arxiv.org/abs/2508.00158)
*Mike Pols,Helena Boom,Geert Brocks,Sofía Calero,Shuxia Tao*

Main category: cond-mat.mtrl-sci

TL;DR: 尽管Sn的引入增强了2D钙钛矿的声子手性，但并未提高其在温度梯度下的角动量产生能力。


<details>
  <summary>Details</summary>
Motivation: Sn基八面体的自发扭曲是否会增强2D卤化物钙钛矿的固有手性。

Method: 通过研究MBA$_{2}$Sn$_{\mathrm{x}}$Pb$_{\mathrm{1}-\mathrm{x}}$I$_{4}$ (x = 0, 1/2, and 1) 的结构和声子手性，来探究金属阳离子对结构手性的影响。

Result: Sn的引入虽然扭曲了金属卤化物八面体，但对结构手性影响甚微。MBA$_{2}$SnI$_{4}$的声子手性显著强于MBA$_{2}$PbI$_{4}$，尤其是在面内声学模式下，但其在温度梯度下的角动量产生能力因声子贡献的相互补偿而受限。

Conclusion: Sn的引入虽然会扭曲金属卤化物八面体，但对结构手性影响不大。然而，MBA$_{2}$SnI$_{4}$中的声子比MBA$_{2}$PbI$_{4}$具有更强的声子手性，特别是面内声学模式。但由于不同手性声子的贡献倾向于相互补偿，这种增强的声子手性并未在温度梯度下产生更大的角动量。

Abstract: Chiral two-dimensional (2D) halide perovskites are formed by embedding chiral
organic cations in a perovskite crystal structure. The chirality arises from
distortions of the 2D metal halide layers induced by the packing of these
organic cations. Sn-based octahedra spontaneously distort, but it remains
unclear whether this intrinsic structural instability enhances the chirality.
We investigate the effect of the metal cation on structural and phonon
chirality in MBA$_{2}$Sn$_{\mathrm{x}}$Pb$_{1-\mathrm{x}}$I$_{4}$ (x = 0, 1/2,
and 1). Incorporating Sn does distort the metal halide octehedra, yet it only
has a minor impact on the structural chirality. In contrast, the phonons in
MBA$_{2}$SnI$_{4}$ are substantially more chiral than in MBA$_{2}$PbI$_{4}$,
especially the in-plane acoustic modes. However, this enhanced phonon chirality
does not lead to a generation of a larger angular momentum under a temperature
gradient, because the contributions of different chiral phonons tend to
compensate one another.

</details>


### [328] [Atomistic Simulations Reveal the Need to Reassess Standard Thermodynamic Models of Coherent Precipitates](https://arxiv.org/abs/2508.00187)
*Anas Abu-Odeh,James Warren*

Main category: cond-mat.mtrl-sci

TL;DR: 通过原子模拟发现，在Fe-Cr系统中，即使在低晶格失配和低过饱和度下，忽略弹性和尺寸效应的常用热力学模型假设也不准确，并且在高半径下观察到需要考虑高阶效应。


<details>
  <summary>Details</summary>
Motivation: 精确的沉淀动力学模型对于控制和设计结构材料至关重要，这些模型对沉淀物的热力学描述高度敏感。

Method: 使用原子模拟研究模型Fe-Cr系统，评估在热力学模型中对相干沉淀物常用的两种假设（即小晶格失配系统可忽略弹性效应，以及低过饱和度水平可忽略尺寸效应）的准确性。

Result: 研究发现，即使晶格失配小于1%，过饱和度低于1%，这些假设也不能维持对界面平衡的准确描述。此外，在较大的沉淀物半径下观察到令人惊讶的趋势，表明通常被忽略的高阶效应对精确模拟有重要影响。

Conclusion: 该研究强调了在模拟固态沉淀时重新审视当前方法的必要性。

Abstract: Accurate models of precipitation kinetics are essential to control and design
structural materials. These models are highly sensitive to the thermodynamic
description of precipitates. We use atomistic simulations of a model Fe-Cr
system to assess two commonly used assumptions in the thermodynamic modeling of
coherent precipitates: that elastic effects can be neglected for systems with a
small lattice misfit and that size effects can be neglected for low levels of
supersaturation. We find that these assumptions cannot be maintained for an
accurate description of interfacial equilibrium, even when lattice misfits are
below 1 % and supersaturation values are below 1 %. Additionally, we find a
surprising trend at large precipitate radii that suggests the importance of
higher-order effects that are commonly neglected. The results and insights from
this study highlight the need to revisit current approaches in modeling
solid-state precipitation.

</details>


### [329] [Vector spin Seebeck effect and spin swapping effect in antiferromagnetic insulators with non-collinear spin structure](https://arxiv.org/abs/2309.03382)
*Jinsong Xu,Weiwei Lin,Jiaming He,J. -S. Zhou,Danru Qu,Ssu-Yen Huang,C. L. Chien*

Main category: cond-mat.mtrl-sci

TL;DR: 向量自旋塞贝克效应在非共线反铁磁体LuFeO$_{3}$中的观测，证明了非共线自旋结构在其中起重要作用，为反铁磁材料在自旋电子学和自旋热电子学领域的应用提供了新的方向。


<details>
  <summary>Details</summary>
Motivation: 探索具有高密度和高速度潜力的反铁磁材料在自旋电子学中的应用，特别是解决反铁磁体（M=0）在探测和操纵方面的挑战，以及研究非共线反铁磁体的独特性能。

Method: 通过实验研究了非共线反铁磁材料LuFeO$_{3}$的向量自旋塞贝克效应，利用了平面内温度梯度产生了此前未观察到的磁热电压，并将其与预测的自旋交换效应相关联。

Result: 在非共线反铁磁材料LuFeO$_{3}$中观察到了向量自旋塞贝克效应，并且实验结果与预测的自旋交换效应一致，证明了非共线自旋结构在其中起重要作用。

Conclusion: 本研究揭示了非共线反铁磁体中新颖的自旋现象，特别是提出了一种利用磁畴壁运动引起磁熵变的新机制，为反铁磁材料在自旋电子学和自旋热电子学领域的应用提供了新的方向。

Abstract: Antiferromagnets (AFs) are prospective for next-generation high-density and
high-speed spintronic applications due to their negligible stray field and
ultrafast spin dynamics, notwithstanding the challenges in detecting and
manipulating AF order with no magnetization (M = 0). Among the AFs,
non-collinear AFs are of particular interest because of their unique properties
arising from the non-collinear spin structure and the small magnetization M. In
this work, we describe the recently observed vector spin Seebeck effect in
non-collinear LuFeO$_3$, where the magneto-thermovoltage under an in-plane
temperature gradient, not previously observed, is consistent with the predicted
spin swapping effect. Our results shed light on the importance of the
non-collinear spin structure in the emerging spin phenomena in non-collinear
AFs and offer a new class of materials for AF spintronics and spin
caloritronics.

</details>


### [330] [Atomic Interface Engineering of Battery Current Collectors via Ion Implantation](https://arxiv.org/abs/2508.00236)
*Yue Li,Xuanguang Ren,Xueting Feng,Lingcheng Kong,Fengping Luo,Yang Xu,Liu Qian,Yusheng Ye,Ziqiang Zhao,Xin Gao,Jin Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过离子注入技术对铜集流体进行原子界面工程，解决了铜表面氧化问题，显著提升了无阳极锂金属电池的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决铜集流体表面易氧化形成绝缘氧化层的问题，该研究旨在通过原子界面工程（AIE）来控制锂金属电池中的界面化学，从而提高电池性能并揭示失效机制。

Method: 利用离子注入技术，将铜离子注入商业铜箔，实现原子级清洁和氧化抗性界面，并通过实验表征和多尺度模拟揭示了工程化空位如何抑制再氧化并引导形成富含Li2O的固态电解质中间层。

Result: 所提出的方法成功地在铜集流体上创建了一个原子级清洁、抗氧化且具有导电性的界面，抑制了寄生反应，实现了均匀的锂沉积，并在贫电解液条件下，在400次循环后仍保持99.0%的库伦效率。

Conclusion: 这项工作提出了一种可推广且与工业兼容的方法，用于稳定电化学界面，通过离子注入策略为无阳极锂金属电池中的铜集流体带来了优异的性能。

Abstract: Atomic interface engineering (AIE) is critical for advancing technologies in
energy storage, catalysis, and microelectronics. In anode-less lithium metal
batteries (ALLMBs), AIE is essential for controlling interfacial chemistry
governing lithium deposition and solid electrolyte interphase (SEI) formation
on copper current collectors. However, native copper surfaces readily oxidize,
forming electronically insulating oxides that degrade performance and obscure
failure mechanisms. Here, we report a scalable ion implantation strategy to
create an atomically clean and robust copper interface. By implanting copper
ions into commercial foils, we simultaneously remove the native oxide and
introduce subsurface vacancy clusters that act as oxygen traps, yielding an
oxidation-resistant and conductive surface. Experimental characterization and
multiscale simulations reveal that these engineered vacancies suppress
reoxidation and guide the formation of an ultrathin Li2O-enriched solid
electrolyte interphase. When applied in ALLMBs, the current collectors enable
uniform lithium deposition, suppress parasitic reactions, and deliver a
Coulombic efficiency of 99.0% over 400 cycles under lean electrolyte
conditions. This work presents a generalizable and industry-compatible approach
for stabilizing electrochemical interfaces.

</details>


### [331] [High-fidelity electronic structure and properties of InSb: $G_0W_0$ and Bayesian-optimized hybrid functionals and DFT+$U$ approaches](https://arxiv.org/abs/2508.00290)
*Ritwik Das,Anne-Sophie Grimault-Jacquin,Frédéric Aniel*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种改进的计算方法，结合了 HSE、$G_0W_0$ 和 DFT+$U$ 以及贝叶斯优化，精确计算了 InSb 的电子结构，解决了之前的计算误差，结果与实验高度吻合。


<details>
  <summary>Details</summary>
Motivation: 为了解决标准 Kohn-Sham 密度泛函理论（DFT）计算 InSb 时，由于 $5p$-$4d$ 斥力和自相互作用误差（SIE）导致的非物理带反转和 $\Gamma$ 点带隙不准确的问题。

Method: 本研究采用全相对论投影增强波（PAW）和优化范德华（ONCV）赝势，并结合混合 HSE 交换关联泛函、准粒子 $G_0W_0$ 和 DFT+$U$ 方法来计算 InSb 的电子结构，并通过贝叶斯优化框架优化了 HSE 和 DFT+$U$ 中的关键参数。

Result: 该研究通过结合 HSE、$G_0W_0$ 和 DFT+$U$ 方法，显著提高了 InSb 能带结构的准确性，精确预测了带隙、体模量、有效质量、Luttinger 参数、价带宽度和 $4d$ 能带位置，并与实验数据达成了前所未有的拟合。

Conclusion: 该方法显著提高了 InSb 的能带结构计算精度，解决了长期存在的描述不完整的问题，并为其他材料体系提供了可转移的计算框架，为电子、光电、能源和量子应用提供了宝贵的见解。

Abstract: This study presents a refined approach to computing the electronic structure
of indium antimonide (InSb) using advanced \textit{ab initio} techniques with
the In and Sb $4d^{10}$ semicore electrons included in the valence states.
These states are modeled using fully relativistic projector augmented waves
(PAW) and optimized norm-conserving Vanderbilt (ONCV) pseudopotentials.
However, standard Kohn-Sham density-functional theory (DFT) calculations with
these pseudopotentials often produce non-physical band inversions and incorrect
band gaps at the $\Gamma$-point due to $5p$-$4d$ repulsion and self-interaction
errors (SIE). To resolve these issues, we apply a combination of hybrid
Heyd-Scuseria-Ernzerhof (HSE) exchange-correlation (XC) functionals, many-body
perturbation theory (MBPT) via quasiparticle $G_0W_0$, and DFT+$U$,
significantly improving the accuracy of the band structure over previous
studies. A Bayesian optimization framework is used to refine key parameters,
including the inverse screening length ($\mu$) and Hartree-Fock (HF) exchange
fraction ($\alpha$) in HSE-based XC functionals, as well as the Hubbard $U$
parameters in DFT+$U$, leading to significantly improved band structure
predictions. This approach yields highly precise band gaps, bulk moduli,
effective masses, Luttinger parameters, valence bandwidth, and $4d$ band
positions, achieving unprecedented agreement with experimental data. The
resulting model resolves the long-standing incomplete description of InSb's
electronic band structure and provides a transferable computational framework
for accurate electronic structure predictions across diverse material systems,
offering valuable insights for future electronic, optoelectronic, energy, and
quantum applications.

</details>


### [332] [Large phonon-drag thermopower polarity reversal in Ba-doped KTaO3](https://arxiv.org/abs/2508.00313)
*Mohamed Nawwar,Samuel Poage,Tobias Schwaigert,Maria N. Gastiasoro,Salva Salmani-Rezaie,Darrell G. Schlom,Kaveh Ahadi,Brandi L. Wooten,Joseph P. Heremans*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现在Ba掺杂的KTaO3薄膜中，声子拖动温差电势出现极性逆转，这是由电子-声子U型散射引起的。重掺杂样品在80 K时出现温差电势符号逆转，而轻掺杂样品则全程表现为负温差电势。


<details>
  <summary>Details</summary>
Motivation: 在氧化物中研究声子拖动和电子-声子U型散射的相互作用，并探索KTaO3在设计非常规热电材料方面的潜力。

Method: 通过分子束外延法生长了具有不同载流子浓度的外延薄膜（分别为3.7 x 10^20 cm^-3和4.9 x 10^19 cm^-3）。

Result: 在重掺杂样品中，费米面覆盖了布里渊区的80%，满足了U型散射条件，导致电子动量逆转。这表现为尽管样品仅具有n型载流子，但在冷却时，温差电势在80 K附近出现符号逆转。相反，轻掺杂样品（4.9 x 10^19 cm^-3）在低至2 K时仅表现出负温差电势。

Conclusion: 在Ba掺杂的KTaO3薄膜中，通过电子-声子U型散射实现了声子拖动温差电势极性逆转，这在氧化物中是前所未有的。

Abstract: This study reports the observation of phonon-drag thermopower polarity
reversal in Ba-doped KTaO3 thin films, mediated by electron-phonon Umklapp
scattering. Epitaxial films with distinct carrier concentrations (3.7 x 10^20
cm^-3 and 4.9 x 10^19 cm^-3) were grown via molecular-beam epitaxy. In heavily
doped samples, where the Fermi surface spans 80% of the Brillouin zone, the
Umklapp condition is satisfied, reversing electron momentum. This manifests as
a sign-reversal in the thermopower around 80 K upon cooling despite the sample
having only n-type carriers. On the other hand, the lightly doped sample (4.9 x
10^19 cm^-3) exhibits only a negative thermopower down to 2 K. These results
advance the understanding of Umklapp electron-phonon drag in oxides and
highlight KTaO3's potential for engineering unconventional thermoelectric
materials.

</details>


### [333] [Etching-to-deposition transition in SiO$_2$/Si$_3$N$_4$ using CH$_x$F$_y$ ion-based plasma etching: An atomistic study with neural network potentials](https://arxiv.org/abs/2508.00327)
*Hyungmin An,Sangmin Oh,Dongheon Lee,Jae-hyeon Ko,Dongyean Oh,Changho Hong,Seungwu Han*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过神经网络势（NNPs）和分子动力学（MD）模拟，研究了氢氟碳等离子体蚀刻SiO2和Si3N4的过程，揭示了碳层形成的机制差异，为半导体制造提供了新的见解。


<details>
  <summary>Details</summary>
Motivation: 为了在半导体制造中精确控制SiO2和Si3N4的蚀刻选择性和实现原子层蚀刻，需要获得对氢氟碳离子轰击下表面演化的原子尺度认识。

Method: 利用神经网络势（NNPs）结合高温、低密度分子动力学（MD）模拟，并辅以基线参考结构，对氢氟碳离子轰击下的SiO2和Si3N4表面演化进行原子尺度研究。

Result: 神经网络势（NNPs）的开发和迭代训练，使得MD模拟中的蚀刻特性与实验结果具有良好的一致性。研究揭示了SiO2和Si3N4中碳层形成的独特机制，这归因于SiO2中碳-氧副产物较高的挥发性以及Si3N4中碳-氮物种形成受抑制。

Conclusion: 该计算框架能够定量预测等离子体暴露下的原子尺度表面改性，并为与多尺度过程建模相结合奠定基础，从而为半导体制造过程提供见解。

Abstract: Plasma etching, a critical process in semiconductor fabrication, utilizes
hydrofluorocarbons both as etchants and as precursors for carbon film
formation, where precise control over film growth is essential for achieving
high SiO$_2$/Si$_3$N$_4$ selectivity and enabling atomic layer etching. In this
work, we develop neural network potentials (NNPs) to gain atomistic insights
into the surface evolution of SiO$_2$ and Si$_3$N$_4$ under hydrofluorocarbon
ion bombardment. To efficiently sample diverse local configurations without
exhaustive enumeration of ion-substrate combinations, we propose a
vapor-to-surface sampling approach using high-temperature, low-density
molecular dynamics simulations, supplemented with baseline reference
structures. The NNPs, refined through iterative training, yield etching
characteristics in MD simulations that show good agreement with experimental
results. Further analysis reveals distinct mechanisms of carbon layer formation
in SiO$_2$ and Si$_3$N$_4$, driven by the higher volatility of carbon-oxygen
byproducts in SiO$_2$ and the suppressed formation of volatile carbon-nitrogen
species in Si$_3$N$_4$. This computational framework enables quantitative
predictions of atomistic surface modifications under plasma exposure and
provides a foundation for integration with multiscale process modeling,
offering insights into semiconductor fabrication processes.

</details>


### [334] [Extrinsic nature of the polarization in hafnia ferroelectrics](https://arxiv.org/abs/2508.00372)
*Binayak Mukherjee,Natalya S. Fedorova,Jorge Íñiguez-González*

Main category: cond-mat.mtrl-sci

TL;DR: Hafnia的极化符号取决于环境，这表明它是外在的，而非内在的。


<details>
  <summary>Details</summary>
Motivation: Hafnia及其相关的萤石类材料具有的铁电性超出了我们对其本征特性的理解，特别是其电极化符号。

Method: 使用第一性原理模拟。

Result: 极化Hafnia层可以产生正或负符号的去极化场，具体取决于其所处的环境。 值得注意的是，这是在原子结构固定的情况下发生的。 这一结果解释了Hafnia的极化符号具有外在性的原因。 此外，还讨论了这一发现对其他铁电家族的相关性。 论文作者认为，Hafnia的极化符号的这种外在性质，可能也存在于其他铁电家族中。 论文的发现，挑战了人们对铁电性的固有理解，并为相关领域的研究开辟了新的方向。

Conclusion: Hafnia的极化符号是外在的，这取决于其周围环境，并且在其他铁电家族中也可能存在类似现象。

Abstract: Hafnia and related fluorites defy our understanding of ferroelectricity, even
if we restrict ourselves to the intrinsic properties of ideal crystals. Here we
focus on a critical puzzle, namely, the sign of the electric polarization.
Using first-principles simulations, we show that a polar hafnia layer with a
fixed atomic configuration can give rise to depolarizing fields of either
positive or negative sign, depending on the environment. This implies that (the
sign of) the polarization in hafnia is extrinsic in nature. We explain this
result and discuss its relevance to other ferroelectric families.

</details>


### [335] [Observation and control of potential-dependent surface state formation at a semiconductor-electrolyte interface via the optical anisotropy](https://arxiv.org/abs/2508.00382)
*Marco Flieg,Margot Guidat,Matthias M. May*

Main category: cond-mat.mtrl-sci

TL;DR: 利用InP(100)的光学各向异性，可以检测和控制半导体-电解质界面的表面状态。


<details>
  <summary>Details</summary>
Motivation: 理解半导体-电解质界面的电势依赖性表面状态对于控制其电荷转移动力学至关重要，但具有挑战性。

Method: 通过监测InP(100)的光学各向异性随施加电势的变化来检测表面状态的形成和电势分布的变化。

Result: 研究发现，表面状态的形成会改变电势分布，将电场从半导体转移到电解质的亥姆霍兹层，从而改变光学各向异性对电势扰动的瞬时响应。该方法能够探测和开关表面态。

Conclusion: 该研究提出了一种利用InP(100)的光学各向异性来检测半导体-电解质界面处电势依赖性表面状态形成的新方法，并提出了一种电化学线性光电效应的变体。

Abstract: The interface between semiconductors and ion-conducting electrolytes is
characterised by charge distributions and potential drops that vary
substantially with the evolution of surface states. These surface states at the
very interface to the liquid can form or be passivated, depending on the
applied potential between electrode and electrolyte, and hereby fundamentally
impact properties such as charge transfer. Characterisation and understanding
of such potential-dependent surface states with high spatial and temporal
resolution is a significant challenge for the understanding and control of
semiconductor-electrolyte interfaces. Here, we show that the optical anisotropy
of InP(100) can be used to detect the potential-dependent formation of highly
ordered surface states under operating conditions. Upon formation of a surface
state in the bandgap of the semiconductor, the potential drop and hence the
electric field is shifted away from the semiconductor to the Helmholtz-layer of
the electrolyte. This modifies the instantaneous response of the optical
anisotropy to disturbances of the applied potential. We propose an
electrochemical variant of the linear electro-optical effect and our findings
open a novel route for understanding these interfaces. The results show how
surface states from surface reconstructions at this reactive interface can be
switched on or off with the applied potential.

</details>


### [336] [The effect of dephasing and spin-lattice relaxation during the switching processes in quantum antiferromagnets](https://arxiv.org/abs/2508.00430)
*Asliddin Khudoyberdiev,Götz S. Uhrig*

Main category: cond-mat.mtrl-sci

TL;DR: Control of antiferromagnetic order is key for data storage and manipulation. This paper uses quantum theory to show spin-lattice relaxation helps antiferromagnets quickly stabilize after ultrafast switching, preventing data loss.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enable large storage capacity and fast manipulation of data by controlling antiferromagnetic order, emphasizing the importance of achieving a steady-state of sublattice magnetization after switching to prevent data loss.

Method: The study employs time-dependent Schwinger boson mean-field theory and the Lindblad formalism to model the system coupled to the environment. It analyzes the distinct effects of dephasing and spin-lattice relaxation.

Result: The research shows that spin-lattice relaxation causes an exponentially fast convergence to the steady-state after complete ultrafast switching, distinguishing its effect from dephasing caused by wave vector interference.

Conclusion: The theoretical approach demonstrates that spin-lattice relaxation leads to exponentially fast convergence to a steady-state after ultrafast switching in open quantum antiferromagnets.

Abstract: The control of antiferromagnetic order can pave the way to large storage
capacity as well as fast manipulation of stored data. Here achieving a
steady-state of sublattice magnetization after switching is crucial to prevent
loss of stored data. The present theoretical approach aims to obtain
instantaneous stable states of the order after reorienting the N\'eel vector in
open quantum antiferromagnets using time-dependent Schwinger boson mean-field
theory. The Lindblad formalism is employed to couple the system to the
environment. The quantum theoretical approach comprises differences in the
effects of dephasing, originating from destructive interference of different
wave vectors, and spin-lattice relaxation. We show that the spin-lattice
relaxation results in an exponentially fast convergence to the steady-state
after full ultrafast switching.

</details>


### [337] [Lippmann-Schwinger Approach for Accurate Photoelectron Wavefunctions and Angle-Resolved Photoemission Spectra from First Principles](https://arxiv.org/abs/2508.00683)
*Ji Hoon Ryoo,Cheol-Hwan Park*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种简单的DFT兼容的ARPES模拟新方法，结果与实验吻合，适用于量子材料研究。


<details>
  <summary>Details</summary>
Motivation: 为了在量子材料时代，以ARPES为关键实验工具，开发易于与标准DFT程序包集成的ARPES模拟方法。

Method: 本文提出了一种基于Lippmann-Schwinger方程的计算光电子波函数的方法。

Result: 计算结果与石墨烯和WSe2的ARPES实验测量结果（光子能量和极化依赖性、暗走廊演化、圆二色性）吻合良好。

Conclusion: 本文提出了一种基于Lippmann-Schwinger方程计算光电子波函数的方法，该方法易于与现有的基于波函数的密度泛函理论（DFT）程序包集成，并自然地包含了光电子态的边界条件。计算结果与石墨烯和WSe2的光助谱（ARPES）实验测量结果（包括光子能量和极化依赖性、由赝自旋引起的暗走廊以及反映隐藏轨道极化的圆二色性）吻合良好。该研究为使用标准的DFT程序包进行ARPES模拟提供了可能，这对于以ARPES为关键实验工具的“量子材料”时代具有重要意义。

Abstract: We present a conceptually simple and technically straightforward method for
calculating photoelectron wavefunctions that is easily integrable with standard
wavefunction-based density-functional-theory packages. Our method is based on
the Lippmann-Schwinger equation, naturally incorporating the boundary condition
that the final photoelectron state must satisfy. The calculated results are in
good agreement with the measured photon-energy- and polarization-dependence of
the angle-resolved photoemission spectroscopy (ARPES) of graphene, the
photon-energy-dependent evolution of the so-called dark corridor arising from
the pseudospin, and WSe\textsubscript{2}, the circular dichroism reflecting the
hidden orbital polarization. Our study opens doors to do-it-yourself
simulations of ARPES with standard density-functional-theory packages, of
crucial importance in the era of ``quantum materials,'' whose key experimental
tool is ARPES.

</details>


### [338] [XANES absorption spectra of penta-graphene and penta-SiC2 with different terminations: a computational study](https://arxiv.org/abs/2508.00704)
*Andrea Pedrielli,Tommaso Morresi,Simone Taioli*

Main category: cond-mat.mtrl-sci

TL;DR: 研究了五石墨烯和五碳化硅的X射线吸收近边光谱，为实验识别和光学应用提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 为了弥补理论表征的不足，促进这些新型二维材料的合成和潜在技术应用。

Method: 采用从头算方法研究了五石墨烯（原始、氢化、羟基化）、硅取代的五石墨烯和五石墨烯以及五碳化硅（原始、氢化）的XANES光谱。

Result: 计算了相关材料的XANES光谱，为实验上通过X射线光谱识别五石墨烯和五碳化硅相奠定了基础，并为未来在光学器件中调控其吸收特性提供了理论依据。

Conclusion: 本研究对五石墨烯及其衍生物（氢化、羟基化、硅取代）和五碳化硅进行了X射线吸收近边光谱（XANES）的理论表征。

Abstract: In recent research, penta-graphene and penta-SiC2 have emerged as innovative
2D materials consisting exclusively of pentagons. However, there is still a
significant gap in the theoretical characterization of these materials, which
hinders progress in their synthesis and potential technological applications.
This study aims to close this gap by investigating the X-ray absorption
near-edge spectroscopy (XANES) of these materials through ab initio
calculations. In particular, we analyze the XANES spectra of penta-graphene in
its pristine, hydrogenated, and hydroxylated states, and we investigate the
effects of substitution by a single silicon in both penta-graphene and
pentagraphane. In addition, we calculate the XANES spectra for pristine and
hydrogenated penta-SiC2. This work sets the stage for the possible
identification of penta-graphene and penta-SiC2 phases by X-ray spectroscopy at
the experimental level and lays the foundation for the future engineering of
the absorption properties of these materials in optical devices.

</details>


### [339] [Persistent spin textures, altermagnetism and charge-to-spin conversion in metallic chiral crystals TM$_{3}$X$_{6}$](https://arxiv.org/abs/2508.00789)
*Karma Tenzin,Berkay Kilic,Raghottam Sattigeri,Zhiren He,Chao Chen Ye,Marcio Costa,Marco Buongiorno Nardelli,Carmine Autieri,Jagoda Slawinska*

Main category: cond-mat.mtrl-sci

TL;DR: 手性TM3X6材料在非磁性相中具有持久自旋纹理（PST），在低温下表现为手性交替磁体。这些特性使其成为高效电荷-自旋转换和自旋输运的理想平台。


<details>
  <summary>Details</summary>
Motivation: 手性晶体由于缺乏反演和镜像对称性，对外部场的响应独特，能够产生高对称性体系中罕见的物理效应。本研究旨在探索TM3X6家族材料中的持久自旋纹理（PST）现象及其在电荷-自旋转换和自旋输运中的应用潜力。

Method: 利用对称性分析和第一性原理计算，对TM3X6家族的磁性进行了分类，并追踪了自旋纹理和电荷-自旋转换随磁相和尼尔矢量方向的变化。

Result: NiTa3S6和NiNb3S6材料在非磁性金属相中展现出覆盖整个费米面的PST。在低温下，这些材料表现出交替磁性，其自旋纹理与尼尔矢量方向密切相关。研究还揭示了区分不同尼尔矢量方向的自旋输运特征。

Conclusion: TM3X6 (T = 3d, M = 4d/5d, X = S) 材料在非磁性金属相中表现出持久自旋纹理 (PST)，这种纹理覆盖整个费米面，有利于高效的电荷-自旋转换和长自旋寿命。在低温下，这些材料变为手性交替磁体，其自旋纹理对尼尔矢量的方向敏感。研究对 TM3X6 材料家族的磁性进行了分类，并追踪了自旋纹理和电荷-自旋转换的演变，这些发现将 TM3X6 确立为一个结合了结构手性、PST 和交替磁性的平台，可用于高效的电荷-自旋转换和自旋输运。

Abstract: Chiral crystals, due to the lack of inversion and mirror symmetries, exhibit
unique spin responses to external fields, enabling physical effects rarely
observed in high-symmetry systems. Here, we show that materials from the chiral
dichalcogenide family TM$_3$X$_6$ (T = 3d, M = 4d/5d, X = S) exhibit persistent
spin texture (PST) - unidirectional spin polarization of states across large
regions of the reciprocal space - in their nonmagnetic metallic phase. Using
the example of NiTa$_{3}$S$_{6}$ and NiNb$_{3}$S$_{6}$, we show that PSTs cover
the full Fermi surface, a rare and desirable feature that enables efficient
charge-to-spin conversion and suggests long spin lifetimes and coherent spin
transport above magnetic ordering temperatures. At low temperatures, the
materials that order antiferromagnetically become chiral altermagnets, where
spin textures originating from spin-orbit coupling and altermagnetism combine
in a way that sensitively depends on the orientation of the Neel vector. Using
symmetry analysis and first-principles calculations, we classify magnetic
ground states across the family, identify cases with weak ferromagnetism, and
track the evolution of spin textures and charge-to-spin conversion across
magnetic phases and different Neel vector orientations, revealing spin
transport signatures that allow one to distinguish Neel vector directions.
These findings establish TM$_3$X$_6$ as a tunable platform for efficient
charge-to-spin conversion and spin transport, combining structural chirality,
persistent spin textures, and altermagnetism.

</details>


### [340] [Magnetic Octupole Hall Effect in d-Wave Altermagnets](https://arxiv.org/abs/2508.00794)
*Hye-Won Ko,Kyung-Jin Lee*

Main category: cond-mat.mtrl-sci

TL;DR: Altermagnets exhibit multipole Hall effects, offering a new avenue for exploring transport phenomena.


<details>
  <summary>Details</summary>
Motivation: Order parameters not only characterize symmetry-broken equilibrium phases but also govern transport phenomena in the nonequilibrium regime. Altermagnets, a class of magnetic systems integrating ferromagnetic and antiferromagnetic features, host multipolar orders in addition to dipolar Neel order.

Method: Using symmetry analysis and linear response theory

Result: Demonstrates the multipole Hall effect in d-wave altermagnets, showing that the magnetic octupole Hall effect persists even in symmetries where the spin-splitter effect is forbidden and identifying a sizable electric quadrupole Hall effect, originating from quadrupole splittings in the band structure.

Conclusion: Order parameters not only characterize symmetry-broken equilibrium phases but also govern transport phenomena in the nonequilibrium regime. Altermagnets, a class of magnetic systems integrating ferromagnetic and antiferromagnetic features, host multipolar orders in addition to dipolar Neel order. In this work, we demonstrate the multipole Hall effect in d-wave altermagnets--a transverse flow of multipole moments induced by an electric field. Using symmetry analysis and linear response theory, we show that the magnetic octupole Hall effect persists even in symmetries where the spin-splitter effect is forbidden and thus provides a robust experimental signature. In addition, we identify a sizable electric quadrupole Hall effect, originating from quadrupole splittings in the band structure. Our results expand the family of Hall effects to include higher-order multipolar responses and establish altermagnets as a versatile platform for exploring multipole transport beyond spin and orbital degrees of freedom.

Abstract: Order parameters not only characterize symmetry-broken equilibrium phases but
also govern transport phenomena in the nonequilibrium regime. Altermagnets, a
class of magnetic systems integrating ferromagnetic and antiferromagnetic
features, host multipolar orders in addition to dipolar Neel order. In this
work, we demonstrate the multipole Hall effect in d-wave altermagnets--a
transverse flow of multipole moments induced by an electric field. Using
symmetry analysis and linear response theory, we show that the magnetic
octupole Hall effect persists even in symmetries where the spin-splitter effect
is forbidden and thus provides a robust experimental signature. In addition, we
identify a sizable electric quadrupole Hall effect, originating from quadrupole
splittings in the band structure. Our results expand the family of Hall effects
to include higher-order multipolar responses and establish altermagnets as a
versatile platform for exploring multipole transport beyond spin and orbital
degrees of freedom.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [341] [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398)
*Sunjae Yoon,Gwanhyeong Koo,Younghwan Lee,Ji Woo Hong,Chang D. Yoo*

Main category: cs.GR

TL;DR: OSF框架通过光流处理遮挡问题，提升了绘制式3D动画的风格一致性，并实现了更快的推理速度和更低的内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有绘制式3D动画方法在处理遮挡（如身体部位重叠）时，存在风格属性（如轮廓和笔触）质量下降的问题，这是由于风格化网络在训练和推理之间存在“风格化姿势差距”，即训练时使用无遮挡姿势，而推理时遇到含遮挡的动态姿势。

Method: OSF框架利用光流实现鲁棒的边缘引导，以解决绘制式3D动画中的风格化遮挡问题。

Result: OSF框架通过光流实现鲁棒的边缘引导，解决了遮挡问题，实现了2.4倍更快的推理速度和2.1倍更少的内存占用，同时保持了风格属性的一致性。

Conclusion: 所提出的OSF框架通过使用光流实现鲁棒的边缘引导，有效解决了现有方法在处理遮挡问题时风格属性下降的挑战，确保了动画风格的一致性。

Abstract: 3D animation aims to generate a 3D animated video from an input image and a
target 3D motion sequence. Recent advances in image-to-3D models enable the
creation of animations directly from user-hand drawings. Distinguished from
conventional 3D animation, drawing-based 3D animation is crucial to preserve
artist's unique style properties, such as rough contours and distinct stroke
patterns. However, recent methods still exhibit quality deterioration in style
properties, especially under occlusions caused by overlapping body parts,
leading to contour flickering and stroke blurring. This occurs due to a
`stylization pose gap' between training and inference in stylization networks
designed to preserve drawing styles in drawing-based 3D animation systems. The
stylization pose gap denotes that input target poses used to train the
stylization network are always in occlusion-free poses, while target poses
encountered in an inference include diverse occlusions under dynamic motions.
To this end, we propose Occlusion-robust Stylization Framework (OSF) for
drawing-based 3D animation. We found that while employing object's edge can be
effective input prior for guiding stylization, it becomes notably inaccurate
when occlusions occur at inference. Thus, our proposed OSF provides
occlusion-robust edge guidance for stylization network using optical flow,
ensuring a consistent stylization even under occlusions. Furthermore, OSF
operates in a single run instead of the previous two-stage method, achieving
2.4x faster inference and 2.1x less memory.

</details>


### [342] [CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data](https://arxiv.org/abs/2508.00424)
*Kresimir Matkovic,Rainer Splechtna,Denis Gracanin,Helwig Hauser*

Main category: cs.GR

TL;DR: CrossSet是一种用于联合研究两个集合类型维度及其交互作用的新型交互式可视化分析方法，采用分层矩阵布局实现多尺度分析。


<details>
  <summary>Details</summary>
Motivation: 集合类型数据的交互式可视化分析是一个有价值的研究和应用领域，现有的工作主要关注单个集合类型维度，而本文旨在解决两个集合类型维度及其相互作用的联合研究问题。

Method: 提出了一种名为CrossSet的新方法，基于任务分析，采用一种新的多尺度方法进行交互式可视化探索和分析。两个集合类型维度通过分层矩阵布局进行联合可视化。

Result: CrossSet能够同时分析两个集合类型维度及其交互作用，支持对单个维度进行详细分析，提供两个维度间交互和关联的概览，并允许用户细化维度以获取多层级细节，最终可以钻取到具体集合元素的交互。

Conclusion: 通过分层矩阵布局联合可视化两个集合类型维度，实现多尺度交互式可视化探索和分析，能够详细研究单个集合类型维度、掌握两个维度间的交互和关联、细化其中一个维度以获得多个层级的额外细节，以及钻取至集合类型维度中各个集合元素的特定交互。

Abstract: The interactive visual analysis of set-typed data, i.e., data with attributes
that are of type set, is a rewarding area of research and applications.
Valuable prior work has contributed solutions that enable the study of such
data with individual set-typed dimensions. In this paper, we present CrossSet,
a novel method for the joint study of two set-typed dimensions and their
interplay. Based on a task analysis, we describe a new, multi-scale approach to
the interactive visual exploration and analysis of such data. Two set-typed
data dimensions are jointly visualized using a hierarchical matrix layout,
enabling the analysis of the interactions between two set-typed attributes at
several levels, in addition to the analysis of individual such dimensions.
CrossSet is anchored at a compact, large-scale overview that is complemented by
drill-down opportunities to study the relations between and within the
set-typed dimensions, enabling an interactive visual multi-scale exploration
and analysis of bivariate set-typed data. Such an interactive approach makes it
possible to study single set-typed dimensions in detail, to gain an overview of
the interaction and association between two such dimensions, to refine one of
the dimensions to gain additional details at several levels, and to drill down
to the specific interactions of individual set-elements from the set-typed
dimensions. To demonstrate the effectiveness and efficiency of CrossSet, we
have evaluated the new method in the context of several application scenarios.

</details>


### [343] [Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation](https://arxiv.org/abs/2508.00428)
*Nan Xiang,Tianyi Liang,Haiwen Huang,Shiqi Jiang,Hao Huang,Yifei Huang,Liangyu Chen,Changbo Wang,Chenhui Li*

Main category: cs.GR

TL;DR: Sel3DCraft is a visual prompt engineering system for Text-to-3D generation that addresses the challenges of multi-view consistency and spatial understanding, improving upon traditional trial-and-error methods with a novel approach combining retrieval, generation, and advanced scoring techniques.


<details>
  <summary>Details</summary>
Motivation: Text-to-3D (T23D) generation is bottlenecked by blind trial-and-error prompting processes that yield unpredictable results. Visual prompt engineering for 3D generation presents unique challenges requiring multi-view consistency evaluation and spatial understanding.

Method: Sel3DCraft uses a dual-branch structure combining retrieval and generation for diverse candidate exploration, a multi-view hybrid scoring approach that leverages MLLMs with innovative high-level metrics to assess 3D models with human-expert consistency, and a prompt-driven visual analytics suite that enables intuitive defect identification and refinement.

Result: Extensive testing and user studies demonstrate that Sel3DCraft surpasses other T23D systems in supporting creativity for designers.

Conclusion: Sel3DCraft surpasses other T23D systems in supporting creativity for designers.

Abstract: Text-to-3D (T23D) generation has transformed digital content creation, yet
remains bottlenecked by blind trial-and-error prompting processes that yield
unpredictable results. While visual prompt engineering has advanced in
text-to-image domains, its application to 3D generation presents unique
challenges requiring multi-view consistency evaluation and spatial
understanding. We present Sel3DCraft, a visual prompt engineering system for
T23D that transforms unstructured exploration into a guided visual process. Our
approach introduces three key innovations: a dual-branch structure combining
retrieval and generation for diverse candidate exploration; a multi-view hybrid
scoring approach that leverages MLLMs with innovative high-level metrics to
assess 3D models with human-expert consistency; and a prompt-driven visual
analytics suite that enables intuitive defect identification and refinement.
Extensive testing and user studies demonstrate that Sel3DCraft surpasses other
T23D systems in supporting creativity for designers.

</details>


### [344] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
*Kien T. Pham,Yingqing He,Yazhou Xing,Qifeng Chen,Long Chen*

Main category: cs.GR

TL;DR: SpA2V是首个利用声音空间线索生成视频的框架，通过音频规划和布局基础生成两个阶段，实现视频内容和空间构图的精确对齐。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注语义信息，忽略了声音的空间属性（如响度、频率），导致生成的视频在内容和空间构图上存在不足。人类能够根据声音的空间线索（位置、运动方向）进行可视化。

Method: SpA2V框架将生成过程分为两个阶段：1）音频引导视频规划：利用多模态大模型（MLLM）提取音频中的空间和语义线索，构建视频场景布局（VSLs）。2）布局基础视频生成：将VSLs作为条件引导，集成到预训练的扩散模型中，实现无需训练的VSL基础视频生成。

Result: SpA2V在生成与输入音频在语义和空间上都保持一致的逼真视频方面表现出色，优于现有方法。

Conclusion: SpA2V在生成与输入音频在语义和空间上都保持一致的逼真视频方面表现出色。

Abstract: Audio-driven video generation aims to synthesize realistic videos that align
with input audio recordings, akin to the human ability to visualize scenes from
auditory input. However, existing approaches predominantly focus on exploring
semantic information, such as the classes of sounding sources present in the
audio, limiting their ability to generate videos with accurate content and
spatial composition. In contrast, we humans can not only naturally identify the
semantic categories of sounding sources but also determine their deeply encoded
spatial attributes, including locations and movement directions. This useful
information can be elucidated by considering specific spatial indicators
derived from the inherent physical properties of sound, such as loudness or
frequency. As prior methods largely ignore this factor, we present SpA2V, the
first framework explicitly exploits these spatial auditory cues from audios to
generate videos with high semantic and spatial correspondence. SpA2V decomposes
the generation process into two stages: 1) Audio-guided Video Planning: We
meticulously adapt a state-of-the-art MLLM for a novel task of harnessing
spatial and semantic cues from input audio to construct Video Scene Layouts
(VSLs). This serves as an intermediate representation to bridge the gap between
the audio and video modalities. 2) Layout-grounded Video Generation: We develop
an efficient and effective approach to seamlessly integrate VSLs as conditional
guidance into pre-trained diffusion models, enabling VSL-grounded video
generation in a training-free manner. Extensive experiments demonstrate that
SpA2V excels in generating realistic videos with semantic and spatial alignment
to the input audios.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [345] [Closed-form Expression for the Power Profile in Wideband Systems with Inter-channel Stimulated Raman Scattering](https://arxiv.org/abs/2508.00093)
*Lucas Alves Zischler,Chiara Lasagni,Paolo Serena,Alberto Bononi,Giammarco Di Sciullo,Divya A. Shaji,Antonio Mecozzi,Cristian Antonelli*

Main category: eess.SP

TL;DR: 提出一个近似公式来估算宽带系统中的ISRS和通道损耗，并用于调整输入功率以优化信号质量。


<details>
  <summary>Details</summary>
Motivation: 宽带系统中的ISRS和通道相关损耗影响信号质量，需要精确估算。

Method: 推导了一个考虑ISRS和通道相关损耗的通道功率分布的近似闭合形式表达式，并推导了一个反向表达式以实现目标OSNR。

Result: 提出的近似闭合形式表达式在CLU传输中与数值解相比显示出高精度。

Conclusion: 该论文提出了一个考虑了ISRS和通道相关损耗的通道功率分布的近似闭合形式表达式，并通过与数值解进行比较，证明了其在高精度下的有效性。此外，还推导了一个反向表达式，用于通过预加重来达到目标OSNR。

Abstract: Wideband systems experience significant inter-channel stimulated Raman
scattering (ISRS) and channel-dependent losses. Due to the non-uniform
attenuation profile, the combined effects of ISRS and fiber loss can only be
accurately estimated using numerical methods. In this work, we present an
approximate closed-form expression for the channels' power profile accounting
for these combined effects. We validate the proposed expression against
numerical solutions in the case of CLU transmission, showing high accuracy for
both single-span and multi-span fiber-optic links. Additionally, we derive an
inverse expression, formulated as a function of the output power, which can be
utilized to target a desired optical signal-to-noise ratio (OSNR) profile
through pre-emphasis of the launched channel powers.

</details>


### [346] [RIS-MAE: A Self-Supervised Modulation Classification Method Based on Raw IQ Signals and Masked Autoencoder](https://arxiv.org/abs/2508.00274)
*Yunfei Liu,Mingxuan Liu,Wupeng Xie,Xinzhu Liu,Wenxue Liu,Yangang Sun,Xin Qiu,Cui Yuan,Jinhai Li*

Main category: eess.SP

TL;DR: 一种名为RIS-MAE的自监督学习框架，可以直接处理原始IQ序列，通过掩码和重建来学习时域特征，解决了现有AMC方法丢失特征和依赖有标签数据的问题，并在少样本和跨域任务上表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有自动调制分类（AMC）方法在处理时间-频率图像时丢失关键特征、适应性差以及依赖有标签数据的问题，提出了一种新的解决方案。

Method: 提出了一种名为RIS-MAE的自监督学习框架，该框架使用掩码自动编码器从无标签数据中学习信号特征，直接以原始IQ序列作为输入，通过应用随机掩码和重建来捕捉幅度、相位等重要的时域特征，从而学习有用的、可迁移的表示。

Result: RIS-MAE在少样本和跨域任务上表现优于现有方法，并且在仅用少量微调样本的情况下，在先前未见过的数据集上实现了高分类精度，验证了其泛化能力和实际部署潜力。

Conclusion: RIS-MAE通过在四个数据集上的测试，在少样本和跨域任务上表现优于现有方法，并且在仅用少量微调样本的情况下，在先前未见过的数据集上实现了高分类精度，验证了其泛化能力和实际部署潜力。

Abstract: Automatic modulation classification (AMC) is a basic technology in
intelligent wireless communication systems. It is important for tasks such as
spectrum monitoring, cognitive radio, and secure communications. In recent
years, deep learning methods have made great progress in AMC. However,
mainstream methods still face two key problems. First, they often use
time-frequency images instead of raw signals. This causes loss of key
modulation features and reduces adaptability to different communication
conditions. Second, most methods rely on supervised learning. This needs a
large amount of labeled data, which is hard to get in real-world environments.
To solve these problems, we propose a self-supervised learning framework called
RIS-MAE. RIS-MAE uses masked autoencoders to learn signal features from
unlabeled data. It takes raw IQ sequences as input. By applying random masking
and reconstruction, it captures important time-domain features such as
amplitude, phase, etc. This helps the model learn useful and transferable
representations. RIS-MAE is tested on four datasets. The results show that it
performs better than existing methods in few-shot and cross-domain tasks.
Notably, it achieves high classification accuracy on previously unseen datasets
with only a small number of fine-tuning samples, confirming its generalization
ability and potential for real-world deployment.

</details>


### [347] [Model-Driven Deep Learning Enhanced Joint Beamforming and Mode Switching for RDARS-Aided MIMO Systems](https://arxiv.org/abs/2508.00326)
*Chengwang Ji,Kehui Li,Haiquan Lu,Qiaoyan Peng,Jintao Wang,Shaodan Ma*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的PWM-BFNet算法，用于优化RDARS辅助的MIMO系统，通过结合PWM和DL方法，有效提高了系统性能并减少了收敛时间。


<details>
  <summary>Details</summary>
Motivation: 可重构分布式天线和反射面（RDARS）是未来6G无线网络的一种有前途的架构。特别是，RDARS辅助系统动态工作模式的配置，相比于现有的可重构智能表面（RIS）辅助系统和分布式天线系统（DAS），带来了额外的选择增益。本文旨在解决RDARS辅助下行多输入多输出（MIMO）系统中权重和速率（WSR）最大化问题。

Method: 本文提出了一种基于惩罚项的加权最小均方误差（PWM）算法，通过结合主要化-最小化（MM）和加权最小均方误差（WMMSE）方法来解决优化问题。为了进一步跳出PWM算法的局部最优解，还集成了一种模型驱动的深度学习（DL）方法，通过训练与PWM算法收敛相关的关键变量来加速收敛并提升系统性能。

Result: PWM-BFNet可以将迭代次数减少一半，并在高总发射功率和大量RDARS发射单元（TE）的场景下分别实现26.53%和103.2%的性能提升。

Conclusion: 仿真结果表明，基于PWM的波束成形网络（PWM-BFNet）可以将迭代次数减少一半，并在高总发射功率和大量RDARS发射单元（TE）的场景下分别实现26.53%和103.2%的性能提升。

Abstract: Reconfigurable distributed antenna and reflecting surface (RDARS) is a
promising architecture for future sixth-generation (6G) wireless networks. In
particular, the dynamic working mode configuration for the RDARS-aided system
brings an extra selection gain compared to the existing reconfigurable
intelligent surface (RIS)-aided system and distributed antenna system (DAS). In
this paper, we consider the RDARS-aided downlink multiple-input multiple-output
(MIMO) system and aim to maximize the weighted sum rate (WSR) by jointly
optimizing the beamforming matrices at the based station (BS) and RDARS, as
well as mode switching matrix at RDARS. The optimization problem is challenging
to be solved due to the non-convex objective function and mixed integer binary
constraint. To this end, a penalty term-based weight minimum mean square error
(PWM) algorithm is proposed by integrating the majorization-minimization (MM)
and weight minimum mean square error (WMMSE) methods. To further escape the
local optimum point in the PWM algorithm, a model-driven DL method is
integrated into this algorithm, where the key variables related to the
convergence of PWM algorithm are trained to accelerate the convergence speed
and improve the system performance. Simulation results are provided to show
that the PWM-based beamforming network (PWM-BFNet) can reduce the number of
iterations by half and achieve performance improvements of 26.53% and 103.2% at
the scenarios of high total transmit power and a large number of RDARS transmit
elements (TEs), respectively.

</details>


### [348] [STAR-RIS-aided RSMA for the URLLC multi-user MIMO Downlink](https://arxiv.org/abs/2508.00409)
*Mohammad Soleymani,Ignacio Santamaria,Eduard Jorswieck,Robert Schober,Lajos Hanzo*

Main category: eess.SP

TL;DR: RSMA与STAR-RIS的结合在MIMO下行链路中实现了显著的能源效率提升。


<details>
  <summary>Details</summary>
Motivation: 为了提高有限块长MIMO下行链路的能源效率，将RSMA与STAR-RIS相结合。

Method: 提出了一种基于交替优化的算法，用于联合优化波束形成矩阵、STAR-RIS配置和速率拆分参数。

Result: STAR-RIS实现了360度全平面覆盖，RSMA通过有效管理干扰获得了显著增益。数值结果表明RSMA和STAR-RIS之间存在很强的协同作用，与反射RIS和SDMA相比，能源效率得到了显著提升。

Conclusion: RSMA和STAR-RIS的结合显著提高了MIMO下行链路的能源效率，与反射RIS和SDMA相比具有明显优势。

Abstract: Rate splitting multiple access (RSMA) is intrinsically amalgamated with
simultaneously transmitting and reflecting (STAR) reconfigurable intelligent
surfaces (RIS) to enhance energy efficiency (EE) of the finite block length
(FBL) multiple-input multiple-output (MIMO) downlink. An alternating
optimization-based algorithm is proposed to jointly optimize the transmit
beamforming matrices, STAR-RIS configurations, and rate-splitting parameters.
STAR-RIS attains 360-degree full-plane coverage, while RSMA provides a
prominent gain by efficiently managing interference. Numerical results reveal a
strong synergy between RSMA and STAR-RIS, demonstreating significant EE gains
over reflective RIS and spatial division multiple access (SDMA).

</details>


### [349] [When Vision-Language Model (VLM) Meets Beam Prediction: A Multimodal Contrastive Learning Framework](https://arxiv.org/abs/2508.00456)
*Ji Wang,Bin Tang,Jian Xiao,Qimei Cui,Xingwang Li,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 该研究提出了一种VLM驱动的对比学习框架，用于预测毫米波波束，通过结合图像、LiDAR和文本信息，提高了预测精度，在复杂环境中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着真实传播环境日益复杂动态，毫米波波束预测面临巨大挑战，而传统依赖CSI的方法计算成本高昂且在复杂环境下精度难以维持。VLM强大的跨模态表示能力为解决此问题提供了有前景的方法。

Method: 提出了一种基于VLM的对比学习多模态波束预测框架，集成了特定模态的编码器，并通过对比预训练策略对齐图像和LiDAR特征，同时利用位置信息作为文本提示增强语言模态的引入，以加强跨模态一致性。

Result: 在DeepSense-6G数据集上的实验表明，该VLM骨干网络提供了额外的语义基础，其整体基于距离的准确率得分（DBA-Score）为0.9016，相较于现有方法平均提高了1.46%。

Conclusion: 该框架通过集成多模态数据和对比预训练策略，利用VLM强大的跨模态表示能力，实现了比现有方法更优的毫米波波束预测精度。

Abstract: As the real propagation environment becomes in creasingly complex and
dynamic, millimeter wave beam prediction faces huge challenges. However, the
powerful cross modal representation capability of vision-language model (VLM)
provides a promising approach. The traditional methods that rely on real-time
channel state information (CSI) are computationally expensive and often fail to
maintain accuracy in such environments. In this paper, we present a VLM-driven
contrastive learning based multimodal beam prediction framework that integrates
multimodal data via modality-specific encoders. To enforce cross-modal
consistency, we adopt a contrastive pretraining strategy to align image and
LiDAR features in the latent space. We use location information as text prompts
and connect it to the text encoder to introduce language modality, which
further improves cross-modal consistency. Experiments on the DeepSense-6G
dataset show that our VLM backbone provides additional semantic grounding.
Compared with existing methods, the overall distance-based accuracy score
(DBA-Score) of 0.9016, corresponding to 1.46% average improvement.

</details>


### [350] [Feasibility of Extracting Skin Nerve Activity from Electrocardiogram Recorded at A Low Sampling Frequency](https://arxiv.org/abs/2508.00494)
*Youngsun Kong,Farnoush Baghestani,I-Ping Chen,Ki Chon*

Main category: eess.SP

TL;DR: 研究表明，低采样率的心电图也能有效提取皮肤神经活动，为资源受限的设备提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 探索是否能从低采样率的心电图信号中提取皮肤神经活动，以克服现有设备采样率的限制。

Method: 通过收集 16 名参与者的 ECG 信号，并在不同采样率（0.5、1 和 4 kHz）下进行分析，评估 SKNA 提取的有效性。

Result: 统计分析表明，在显著性、分类性能和可靠性方面，从不同采样率（0.5、1 和 4 kHz）提取的 SKNA 指数没有显著差异。

Conclusion: 皮肤神经活动（SKNA）可以从低采样率（0.5、1 和 4 kHz）的心电图（ECG）信号中提取，与高采样率（> 2 kHz）的信号没有显著差异，尤其是在肌肉伪影污染最小的情况下。

Abstract: Skin nerve activity (SKNA) derived from electrocardiogram (ECG) signals has
been a promising non-invasive surrogate for accurate and effective assessment
of the sympathetic nervous system (SNS). Typically, SKNA extraction requires a
higher sampling frequency than the typical ECG recording requirement (> 2 kHz)
because analysis tools extract SKNA from the 0.5-1 kHz frequency band. However,
ECG recording systems commonly provide a sampling frequency of 1 kHz or lower,
particularly for wearable devices. Our recent power spectral analysis exhibited
that 150-500 Hz frequency bands are dominant during sympathetic stimulation.
Therefore, we hypothesize that SKNA can be extracted from ECG sampled at a
lower sampling frequency. We collected ECG signals from 16 participants during
SNS stimulation and resampled the signals at 0.5, 1, and 4 kHz. Our statistical
analyses of significance, classification performance, and reliability indicate
no significant difference between SKNA indices derived from ECG signals sampled
at 0.5, 1, and 4 kHz. Our findings indicate that conventional ECG devices,
which are limited to low sampling rates due to resource constraints or outdated
guidelines, can be used to reliably collect SKNA if muscle artifact
contamination is minimal.

</details>


### [351] [Subband Architecture Aided Selective Fixed-Filter Active Noise Control](https://arxiv.org/abs/2508.00603)
*Hong-Cheng Liang,Man-Wai Mak,Kong Aik Lee*

Main category: eess.SP

TL;DR: 该研究提出了一种新的选择性固定滤波器方案，通过子带处理和滤波器库，提高了在复杂噪声环境下的噪声抑制性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有前馈选择固定滤波器方法只能处理有限类型的噪声，并且在输入噪声功率谱密度不均匀时性能下降的问题。

Method: 提出了一种基于无延迟子带结构的新型选择固定滤波器方案。在离线训练阶段，为不同的频带预训练子带控制滤波器，并将其存储在专门的子滤波器数据库中。在在线控制阶段，使用多相FFT滤波器组分解输入的噪声，并使用频带匹配机制将最合适的控制滤波器分配给每个子带信号。然后，采用权重叠加技术将所有子带权重组合成全带滤波器，以实现实时噪声抑制。

Result: 实验结果表明，所提出的方案在处理更复杂的噪声环境时，具有收敛速度快、降噪效果好、鲁棒性强等优点。

Conclusion: 该方法在复杂的噪声环境中提供了快速收敛、有效的噪声抑制和强大的鲁棒性。

Abstract: The feedforward selective fixed-filter method selects the most suitable
pre-trained control filter based on the spectral features of the detected
reference signal, effectively avoiding slow convergence in conventional
adaptive algorithms. However, it can only handle limited types of noises, and
the performance degrades when the input noise exhibits non-uniform power
spectral density. To address these limitations, this paper devises a novel
selective fixed-filter scheme based on a delayless subband structure. In the
off-line training stage, subband control filters are pre-trained for different
frequency ranges and stored in a dedicated sub-filter database. During the
on-line control stage, the incoming noise is decomposed using a polyphase FFT
filter bank, and a frequency-band-matching mechanism assigns each subband
signal the most appropriate control filter. Subsequently, a weight stacking
technique is employed to combine all subband weights into a fullband filter,
enabling real-time noise suppression. Experimental results demonstrate that the
proposed scheme provides fast convergence, effective noise reduction, and
strong robustness in handling more complicated noisy environments.

</details>


### [352] [Multibeam High Throughput Satellite: Hardware Foundation, Resource Allocation, and Precoding](https://arxiv.org/abs/2508.00800)
*Rui Chen,Wen-Xuan Long,Bing-Qian Wang,Yuan He,Rui-Jin Sun,Nan Cheng,Gan Zheng,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文综述了多波束高通量卫星（HTS）通信系统，涵盖了硬件、资源分配和预编码技术，并探讨了Q/V频段、网关同步、信道状态信息（CSI）、轻量化载荷和深度学习（DL）等方面的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着6G通信技术的发展，卫星通信凭借其广泛覆盖和不间断服务的优势，成为关键技术之一。高通量卫星（HTS）系统利用多点波束和频分复用技术，能够提供高达Tbps的通信容量，以满足日益增长的流量需求。因此，有必要对多波束HTS系统进行综述，并识别其面临的挑战和发展前景。

Method: 本文首先总结了多波束HTS系统的硬件基础，包括地面站系统、在轨载荷和用户终端。随后，回顾了HTS系统的灵活在轨无线资源分配方法，包括带宽、功率、时隙以及联合分配方案，以优化资源利用率并满足非均匀的服务需求。此外，还调研了HTS系统的多波束预编码方法，以实现全频段复用和干扰消除，并根据不同部署（如单个网关预编码、多个网关预编码、在轨预编码和混合在轨/地面预编码）进行了分类。

Result: 本文对多波束HTS系统的硬件基础、资源分配和预编码技术进行了综述，并讨论了Q/V频段链路、网关同步、信道状态信息（CSI）精度、轻量化载荷以及深度学习（DL）应用等关键挑战。这些研究将有助于提升HTS系统的性能，最终为陆地网络服务不足的地区提供高速数据传输。

Conclusion: 卫星通信是下一代6G通信的关键技术，高通量卫星（HTS）系统通过多点波束和频分复用技术，实现了高达Tbps的卫星通信容量，以满足不断增长的流量需求。本篇论文对多波束HTS系统进行了综述，总结了其硬件基础、资源分配方法和预编码技术，并讨论了Q/V频段链路、网关同步、信道状态信息（CSI）精度、轻量化载荷以及深度学习（DL）应用等方面的挑战与未来研究方向。

Abstract: With its wide coverage and uninterrupted service, satellite communication is
a critical technology for next-generation 6G communications. High throughput
satellite (HTS) systems, utilizing multipoint beam and frequency multiplexing
techniques, enable satellite communication capacity of up to Tbps to meet the
growing traffic demand. Therefore, it is imperative to review
the-state-of-the-art of multibeam HTS systems and identify their associated
challenges and perspectives. Firstly, we summarize the multibeam HTS hardware
foundations, including ground station systems, on-board payloads, and user
terminals. Subsequently, we review the flexible on-board radio resource
allocation approaches of bandwidth, power, time slot, and joint allocation
schemes of HTS systems to optimize resource utilization and cater to
non-uniform service demand. Additionally, we survey multibeam precoding methods
for the HTS system to achieve full-frequency reuse and interference
cancellation, which are classified according to different deployments such as
single gateway precoding, multiple gateway precoding, on-board precoding, and
hybrid on-board/on-ground precoding. Finally, we disscuss the challenges
related to Q/V band link outage, time and frequency synchronization of
gateways, the accuracy of channel state information (CSI), payload light-weight
development, and the application of deep learning (DL). Research on these
topics will contribute to enhancing the performance of HTS systems and finally
delivering high-speed data to areas underserved by terrestrial networks.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [353] [From Dynamic Programs to Greedy Algorithms](https://arxiv.org/abs/2508.00776)
*Dieter van Melkebeek*

Main category: cs.DS

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We show for several computational problems how classical greedy algorithms
for special cases can be derived in a simple way from dynamic programs for the
general case: interval scheduling (restricted to unit weights), knapsack
(restricted to unit values), and shortest paths (restricted to nonnegative edge
lengths). Conceptually, we repeatedly expand the Bellman equations underlying
the dynamic program and use straightforward monotonicity properties to figure
out which terms yield the optimal value under the respective restrictions. The
approach offers an alternative for developing these greedy algorithms in
undergraduate algorithms courses and/or for arguing their correctness. In the
setting of interval scheduling, it elucidates the change in order from earliest
start time first for the memoized dynamic program to earliest finish time first
for the greedy algorithm.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [354] [Reimagining Voltage-Controlled Cryogenic Boolean Logic Paradigm with Quantum-Enhanced Josephson Junction FETs](https://arxiv.org/abs/2508.00295)
*Md Mazharul Islam,Diego Ferrer,Shamiul Alam,Juan P. Mendez,Denis Mamaluy,Wei Pan,Ahmedullah Aziz*

Main category: cs.ET

TL;DR: 本研究提出了一种基于量子增强 JJFET 的电压控制逻辑拓扑结构，通过集成纳米低温器件实现了基本逻辑门和 XOR 门的可级联性，为超低功耗计算和量子技术提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有超导器件在可级联性方面的挑战，以满足超低功耗计算和量子技术发展的需求，本研究旨在开发具有足够超电流增益和鲁棒控制的电压控制逻辑器件。

Method: 提出并分析了基于量子增强 JJFET 的电压控制逻辑拓扑结构，开发了 Verilog A 紧凑模型，并集成了多层加热纳米低温器件（nTron）以确保逻辑电路的可级联性。

Result: 成功实现了 NOT、NAND、NOR 和 XOR 等基本逻辑门，并设计了三输入多数表决器，证明了量子增强 JJFET 及其提出的逻辑拓扑结构的可级联性。

Conclusion: 通过模拟分析，成功实现了 NOT、NAND 和 NOR 等基本逻辑门，并设计了一个三输入多数表决器，以证明所提出的量子增强 JJFET 逻辑拓扑结构的可级联性，最终通过一个基于 JJFET 的 2 输入 XOR 门演示了其级联操作。

Abstract: The growing demand for ultra low power computing and the emergence of quantum
technologies have intensified interest in cryogenic electronics, particularly
superconducting devices.Despite their promise, current controlled
superconducting components face fundamental challenges in cascadability,
limiting their effectiveness in complex logic architectures.To overcome this,
recent efforts have focused on developing gate tunable superconducting devices,
such as Josephson Junction Field Effect Transistors (JJFETs).However, achieving
robust control and sufficient supercurrent gain, both critical for
transistor-like performance in logic circuits remains a key challenge.A recent
advancement in JJFET design, based on InAs and GaSb heterostructures,
demonstrates enhanced gain and favorable device characteristics suitable for
circuit integration.Building on this innovation, we propose and analyze
fundamental voltage controlled logic topologies using the quantum enhanced
JJFET. We develop a Verilog A based circuit compatible compact model of the
quantum enhanced JJFET which accurately captures the experimentally observed
device characteristics.To ensure cascadability, our logic circuits incorporate
the multilayered Heater Nanocryotron (nTron), a superconducting nanowire-based
thermal switch.Through simulation based analysis, we demonstrate the successful
implementation of fundamental logic gates, including NOT, NAND, and NOR.
Furthermore, we design a 3 input majority gate, which plays a pivotal role in
quantum and reversible computing due to its universality.Finally, to
demonstrate the cascadability of our proposed logic topology, we demonstrate
the operation of a 2 input XOR gate based on our designed JJFET based NOT,
NAND, and NOR gate.

</details>
