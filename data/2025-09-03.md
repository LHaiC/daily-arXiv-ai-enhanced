<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 213]
- [cs.CL](#cs.CL) [Total: 137]
- [cs.RO](#cs.RO) [Total: 83]
- [cs.AI](#cs.AI) [Total: 83]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 38]
- [cs.DC](#cs.DC) [Total: 21]
- [cs.GT](#cs.GT) [Total: 9]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 47]
- [cs.SI](#cs.SI) [Total: 9]
- [cs.MA](#cs.MA) [Total: 6]
- [eess.SP](#eess.SP) [Total: 52]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.DS](#cs.DS) [Total: 12]
- [cs.NE](#cs.NE) [Total: 1]
- [physics.app-ph](#physics.app-ph) [Total: 3]
- [quant-ph](#quant-ph) [Total: 92]
- [cs.GR](#cs.GR) [Total: 13]
- [eess.SY](#eess.SY) [Total: 55]
- [cs.AR](#cs.AR) [Total: 11]
- [cs.LO](#cs.LO) [Total: 7]
- [cs.LG](#cs.LG) [Total: 208]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Deep Learning-Driven Multimodal Detection and Movement Analysis of Objects in Culinary](https://arxiv.org/abs/2509.00033)
*Tahoshin Alam Ishat*

Main category: cs.CV

TL;DR: 本研究结合了YOLOv8分割模型、LSTM模型和ASR（whisper-base）来提取数据，用于LLM（TinyLLaMa）的食谱预测和烹饪步骤指南生成。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索和改进现有模型，以创建一个能够处理复杂、充满挑战的厨房环境的任务特定系统，证明计算机视觉在日常活动中的广泛应用潜力。

Method: 结合使用YOLOv8进行分割、LSTM处理手部运动序列，以及ASR（whisper-base）进行语音识别，收集数据以训练LLM（TinyLLaMa）进行食谱预测和生成烹饪步骤指南。

Result: 成功地创建了一个多模态系统，能够从视频数据中提取信息，预测食谱并生成详细的烹饪指南。

Conclusion: 该研究证明了计算机视觉在日常活动（如厨房工作）中的扩展性和无限应用潜力，为解决日常生活中更多关键任务开辟了道路。

Abstract: This is a research exploring existing models and fine tuning them to combine
a YOLOv8 segmentation model, a LSTM model trained on hand point motion sequence
and a ASR (whisper-base) to extract enough data for a LLM (TinyLLaMa) to
predict the recipe and generate text creating a step by step guide for the
cooking procedure. All the data were gathered by the author for a robust task
specific system to perform best in complex and challenging environments proving
the extension and endless application of computer vision in daily activities
such as kitchen work. This work extends the field for many more crucial task of
our day to day life.

</details>


### [2] [AMMKD: Adaptive Multimodal Multi-teacher Distillation for Lightweight Vision-Language Models](https://arxiv.org/abs/2509.00039)
*Yuqi Li,Chuanguang Yang,Junhao Dong,Zhengtao Yao,Haoyan Xu,Zeyu Dong,Hansheng Zeng,Zhulin An,Yingli Tian*

Main category: cs.CV

TL;DR: 提出AMMKD框架，通过知识蒸馏和自适应优化，实现轻量级图像-文本检索模型，适用于移动设备。


<details>
  <summary>Details</summary>
Motivation: 现有大规模视觉语言预训练模型在移动设备部署受限，因其模型大、计算复杂。

Method: 提出AMMKD框架，包含多模态特征融合、多教师知识蒸馏（预训练两个CLIP教师模型，解耦模态，预计算文本特征）、KL散度匹配、自适应动态加权（将多教师蒸馏视为多目标优化问题，利用梯度空间多样性动态调整教师影响）。

Result: 在三个基准数据集上进行的大量实验表明，AMMKD在显著降低模型复杂度的同时，实现了优越的性能。

Conclusion: AMMKD框架有效且灵活，能够为移动设备提供轻量级但高效的图像-文本检索模型。

Abstract: The success of large-scale visual language pretraining (VLP) models has
driven widespread adoption of image-text retrieval tasks. However, their
deployment on mobile devices remains limited due to large model sizes and
computational complexity. We propose Adaptive Multi-Modal Multi-Teacher
Knowledge Distillation (AMMKD), a novel framework that integrates multi-modal
feature fusion, multi-teacher distillation, and adaptive optimization to
deliver lightweight yet effective retrieval models. Specifically, our method
begins with a feature fusion network that extracts and merges discriminative
features from both the image and text modalities. To reduce model parameters
and further improve performance, we design a multi-teacher knowledge
distillation framework to pre-train two CLIP teacher models. We decouple
modalities by pre-computing and storing text features as class vectors via the
teacher text encoder to enhance efficiency. To better align teacher and student
outputs, we apply KL scatter for probability distribution matching. Finally, we
design an adaptive dynamic weighting scheme that treats multi-teacher
distillation as a multi-objective optimization problem. By leveraging gradient
space diversity, we dynamically adjust the influence of each teacher, reducing
conflicts and guiding the student toward more optimal learning directions.
Extensive experiments on three benchmark datasets demonstrate that AMMKD
achieves superior performance while significantly reducing model complexity,
validating its effectiveness and flexibility.

</details>


### [3] [ARTPS: Depth-Enhanced Hybrid Anomaly Detection and Learnable Curiosity Score for Autonomous Rover Target Prioritization](https://arxiv.org/abs/2509.00042)
*Poyraz Baydemir*

Main category: cs.CV

TL;DR: ARTPS是一个结合了深度估计、异常检测和可学习好奇心评分的混合AI系统，用于自主探索行星表面，在火星探测器数据集上取得了先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自主探索行星表面，提高目标优先级排序的准确性。

Method: 该系统集成了使用Vision Transformers的单目深度估计、多组件异常检测以及加权好奇心评分，该评分平衡了已知价值、异常信号、深度方差和表面粗糙度。

Result: ARTPS在火星探测器数据集上实现了0.94的AUROC、0.89的AUPRC和0.87的F1分数，在保持高检测灵敏度的同时，将误报率降低了23%。

Conclusion: ARTPS通过混合融合方法显著提高了目标优先级排序的准确性，在各种地形类型上都表现出色。

Abstract: We present ARTPS (Autonomous Rover Target Prioritization System), a novel
hybrid AI system that combines depth estimation, anomaly detection, and
learnable curiosity scoring for autonomous exploration of planetary surfaces.
Our approach integrates monocular depth estimation using Vision Transformers
with multi-component anomaly detection and a weighted curiosity score that
balances known value, anomaly signals, depth variance, and surface roughness.
The system achieves state-of-the-art performance with AUROC of 0.94, AUPRC of
0.89, and F1-Score of 0.87 on Mars rover datasets. We demonstrate significant
improvements in target prioritization accuracy through ablation studies and
provide comprehensive analysis of component contributions. The hybrid fusion
approach reduces false positives by 23% while maintaining high detection
sensitivity across diverse terrain types.

</details>


### [4] [Performance is not All You Need: Sustainability Considerations for Algorithms](https://arxiv.org/abs/2509.00045)
*Xiang Li,Chong Zhang,Hongpeng Wang,Shreyank Narayana Gowda,Yushi Li,Xiaobo Jin*

Main category: cs.CV

TL;DR: 该研究提出了一个创新的二维可持续性评估系统，用于平衡深度学习模型的性能和能耗，并引入了可持续谐波平均值（FMS）和可持续性曲线下面积（ASC）两个新指标。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型训练产生高碳排放，需要平衡算法性能和能耗。

Method: 提出并验证了一个包含可持续谐波平均值（FMS）和可持续性曲线下面积（ASC）的二维可持续性评估系统，并在多种多模态任务（图像分类、分割、姿态估计、批处理和在线学习）中进行了基准测试。

Result: 实验证明该评估系统可以为跨任务算法评估提供量化依据，促进绿色AI研究从理论走向实践。

Conclusion: 该研究提出的可持续性评估系统为行业建立算法能效标准提供了方法论支持。

Abstract: This work focuses on the high carbon emissions generated by deep learning
model training, specifically addressing the core challenge of balancing
algorithm performance and energy consumption. It proposes an innovative
two-dimensional sustainability evaluation system. Different from the
traditional single performance-oriented evaluation paradigm, this study
pioneered two quantitative indicators that integrate energy efficiency ratio
and accuracy: the sustainable harmonic mean (FMS) integrates accumulated energy
consumption and performance parameters through the harmonic mean to reveal the
algorithm performance under unit energy consumption; the area under the
sustainability curve (ASC) constructs a performance-power consumption curve to
characterize the energy efficiency characteristics of the algorithm throughout
the cycle. To verify the universality of the indicator system, the study
constructed benchmarks in various multimodal tasks, including image
classification, segmentation, pose estimation, and batch and online learning.
Experiments demonstrate that the system can provide a quantitative basis for
evaluating cross-task algorithms and promote the transition of green AI
research from theory to practice. Our sustainability evaluation framework code
can be found here, providing methodological support for the industry to
establish algorithm energy efficiency standards.

</details>


### [5] [MESTI-MEGANet: Micro-expression Spatio-Temporal Image and Micro-expression Gradient Attention Networks for Micro-expression Recognition](https://arxiv.org/abs/2509.00056)
*Luu Tu Nguyen,Vu Tram Anh Khuong,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 该研究提出了一种新的微表情时空图像（MESTI）作为输入模态，并结合了微表情梯度注意力网络（MEGANet）以提高微表情识别（MER）的性能。实验证明，MESTI比传统输入模态更能捕捉微表情的特征，并且MEGANet结合MESTI在CASMEII和SAMM数据集上达到了最先进的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统输入模态（如Apex帧、光流、动态图像）难以充分捕捉微表情的细微和短暂的运动特征，导致识别性能不佳。

Method: 提出了一种新的动态输入模态——微表情时空图像（MESTI），将视频序列转换为单张图像，同时保留了微运动的关键特征。并提出了一种微表情梯度注意力网络（MEGANet），其中引入了梯度注意力模块来增强从微表情中提取的细粒度运动特征。

Result: 通过大量实验评估了MESTI的有效性，并将其与现有输入模态在三种CNN架构（VGG19、ResNet50和EfficientNetB0）上进行了比较。结果表明，用MESTI替换现有MER网络的输入可以持续提升性能。MEGANet（结合MESTI和动态图像）也显示出优越性，在CASMEII和SAMM数据集上取得了最先进的结果。MEGANet和MESTI的结合达到了迄今为止最高的准确率。

Conclusion: MESTI是一种优于传统输入模态的模态，MEGANet是一种先进的识别网络，它们共同为更有效的微表情识别系统奠定了基础，有望应用于多种场景。

Abstract: Micro-expression recognition (MER) is a challenging task due to the subtle
and fleeting nature of micro-expressions. Traditional input modalities, such as
Apex Frame, Optical Flow, and Dynamic Image, often fail to adequately capture
these brief facial movements, resulting in suboptimal performance. In this
study, we introduce the Micro-expression Spatio-Temporal Image (MESTI), a novel
dynamic input modality that transforms a video sequence into a single image
while preserving the essential characteristics of micro-movements.
Additionally, we present the Micro-expression Gradient Attention Network
(MEGANet), which incorporates a novel Gradient Attention block to enhance the
extraction of fine-grained motion features from micro-expressions. By combining
MESTI and MEGANet, we aim to establish a more effective approach to MER.
Extensive experiments were conducted to evaluate the effectiveness of MESTI,
comparing it with existing input modalities across three CNN architectures
(VGG19, ResNet50, and EfficientNetB0). Moreover, we demonstrate that replacing
the input of previously published MER networks with MESTI leads to consistent
performance improvements. The performance of MEGANet, both with MESTI and
Dynamic Image, is also evaluated, showing that our proposed network achieves
state-of-the-art results on the CASMEII and SAMM datasets. The combination of
MEGANet and MESTI achieves the highest accuracy reported to date, setting a new
benchmark for micro-expression recognition. These findings underscore the
potential of MESTI as a superior input modality and MEGANet as an advanced
recognition network, paving the way for more effective MER systems in a variety
of applications.

</details>


### [6] [Scaffold Diffusion: Sparse Multi-Category Voxel Structure Generation with Discrete Diffusion](https://arxiv.org/abs/2509.00062)
*Justin Jung*

Main category: cs.CV

TL;DR: Scaffold Diffusion是一种用于生成稀疏多类别3D体素结构的新型生成模型，它使用离散扩散语言模型处理体素作为标记，即使在高度稀疏的数据上也能生成逼真、连贯的3D结构，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决生成稀疏多类别3D体素结构因内存立方级扩展和类别严重不平衡而带来的困难。

Method: 提出Scaffold Diffusion，一种利用离散扩散语言模型将体素视为标记来生成3D体素结构的方法。

Result: 在Minecraft房屋结构数据集（3D-Craft）上进行评估，结果表明Scaffold Diffusion能够生成逼真、连贯的结构，即使在超过98%稀疏度的数据上训练，也优于先前基线和自回归模型。

Conclusion: 离散扩散是3D稀疏体素生成建模的一个有前途的框架。

Abstract: Generating realistic sparse multi-category 3D voxel structures is difficult
due to the cubic memory scaling of voxel structures and moreover the
significant class imbalance caused by sparsity. We introduce Scaffold
Diffusion, a generative model designed for sparse multi-category 3D voxel
structures. By treating voxels as tokens, Scaffold Diffusion uses a discrete
diffusion language model to generate 3D voxel structures. We show that discrete
diffusion language models can be extended beyond inherently sequential domains
such as text to generate spatially coherent 3D structures. We evaluate on
Minecraft house structures from the 3D-Craft dataset and demonstrate that,
unlike prior baselines and an auto-regressive formulation, Scaffold Diffusion
produces realistic and coherent structures even when trained on data with over
98% sparsity. We provide an interactive viewer where readers can visualize
generated samples and the generation process. Our results highlight discrete
diffusion as a promising framework for 3D sparse voxel generative modeling.

</details>


### [7] [Dual-Stage Global and Local Feature Framework for Image Dehazing](https://arxiv.org/abs/2509.00108)
*Anas M. Ali,Anis Koubaa,Bilel Benjdira*

Main category: cs.CV

TL;DR: 提出一种名为SGLC的新框架，用于解决高分辨率图像的去雾问题，该框架结合了全局和局部特征，并在Uformer架构上进行了验证，取得了显著的PSNR提升。


<details>
  <summary>Details</summary>
Motivation: 解决当前去雾模型在高分辨率图像上性能下降的问题，这种下降源于全局上下文信息与局部细节信息难以有效结合。

Method: 提出一个名为SGLC（Streamlined Global and Local Features Combinator）的框架，包含全局特征生成器（GFG）和局部特征增强器（LFE）两个主要部分。GFG关注场景的全局理解生成初步去雾结果，LFE则通过增强局部细节和像素级特征来优化初步结果。将SGLC集成到Uformer架构中进行评估。

Result: 在Uformer架构上集成SGLC后，高分辨率数据集的实验结果显示PSNR有显著提升，证明了SGLC在处理大规模图像去雾方面的有效性。

Conclusion: SGLC框架能够有效结合全局场景线索和局部细节，显著提升高分辨率图像的视觉保真度，并且该框架具有模型无关性，可以应用于任何去雾网络。

Abstract: Addressing the challenge of removing atmospheric fog or haze from digital
images, known as image dehazing, has recently gained significant traction in
the computer vision community. Although contemporary dehazing models have
demonstrated promising performance, few have thoroughly investigated
high-resolution imagery. In such scenarios, practitioners often resort to
downsampling the input image or processing it in smaller patches, which leads
to a notable performance degradation. This drop is primarily linked to the
difficulty of effectively combining global contextual information with
localized, fine-grained details as the spatial resolution grows. In this
chapter, we propose a novel framework, termed the Streamlined Global and Local
Features Combinator (SGLC), to bridge this gap and enable robust dehazing for
high-resolution inputs. Our approach is composed of two principal components:
the Global Features Generator (GFG) and the Local Features Enhancer (LFE). The
GFG produces an initial dehazed output by focusing on broad contextual
understanding of the scene. Subsequently, the LFE refines this preliminary
output by enhancing localized details and pixel-level features, thereby
capturing the interplay between global appearance and local structure. To
evaluate the effectiveness of SGLC, we integrated it with the Uformer
architecture, a state-of-the-art dehazing model. Experimental results on
high-resolution datasets reveal a considerable improvement in peak
signal-to-noise ratio (PSNR) when employing SGLC, indicating its potency in
addressing haze in large-scale imagery. Moreover, the SGLC design is
model-agnostic, allowing any dehazing network to be augmented with the proposed
global-and-local feature fusion mechanism. Through this strategy, practitioners
can harness both scene-level cues and granular details, significantly improving
visual fidelity in high-resolution environments.

</details>


### [8] [Self-supervised large-scale kidney abnormality detection in drug safety assessment studies](https://arxiv.org/abs/2509.00131)
*Ivan Slootweg,Natalia P. García-De-La-Puente,Geert Litjens,Salma Dammak*

Main category: cs.CV

TL;DR: kidney abnormality detection for drug safety using self-supervised learning.


<details>
  <summary>Details</summary>
Motivation: Kidney abnormality detection is crucial but time-consuming in preclinical drug development, requiring examination of numerous slides.

Method: Developed a large-scale self-supervised abnormality detection model for kidney toxicologic pathology using features from the UNI foundation model. Explored the insufficiency of FM-generated features alone and applied a self-supervised method to improve performance.

Result: The self-supervised method achieved better-than-chance performance with an AUC of 0.62 and NPV of 89%, outperforming a simple k-nearest neighbor classifier on FM features alone.

Conclusion: The developed self-supervised model shows potential to reduce costs and time in drug safety assessment by ruling out normal kidney slides.

Abstract: Kidney abnormality detection is required for all preclinical drug
development. It involves a time-consuming and costly examination of hundreds to
thousands of whole-slide images per drug safety study, most of which are
normal, to detect any subtle changes indicating toxic effects. In this study,
we present the first large-scale self-supervised abnormality detection model
for kidney toxicologic pathology, spanning drug safety assessment studies from
158 compounds. We explore the complexity of kidney abnormality detection on
this scale using features extracted from the UNI foundation model (FM) and show
that a simple k-nearest neighbor classifier on these features performs at
chance, demonstrating that the FM-generated features alone are insufficient for
detecting abnormalities. We then demonstrate that a self-supervised method
applied to the same features can achieve better-than-chance performance, with
an area under the receiver operating characteristic curve of 0.62 and a
negative predictive value of 89%. With further development, such a model can be
used to rule out normal slides in drug safety assessment studies, reducing the
costs and time associated with drug development.

</details>


### [9] [Waste-Bench: A Comprehensive Benchmark for Evaluating VLLMs in Cluttered Environments](https://arxiv.org/abs/2509.00176)
*Muhammad Ali,Salman Khan*

Main category: cs.CV

TL;DR: LLM在处理复杂、变形物体的数据集进行废物分类时，鲁棒性和准确性有待提高。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在处理标准图像方面表现出色，但在处理包含变形物体和复杂环境的现实世界数据集（如废物分类）方面的能力尚未得到充分探索。本研究旨在解决这一差距。

Method: 创建了一个新的数据集，用于在现实世界的复杂环境中对废物进行分类，并提出了一个深入的评估方法来严格评估VLLM的鲁棒性和准确性。

Result: 评估结果表明，VLLM在处理复杂环境中的变形物体时，其鲁棒性和准确性存在不足，凸显了进一步改进的必要性。

Conclusion: VLLM在现实世界的复杂环境中（如废物分类任务）仍需改进鲁棒性和准确性，尤其是在处理变形物体时。公开的数据集和代码将有助于未来的研究。

Abstract: Recent advancements in Large Language Models (LLMs) have paved the way for
Vision Large Language Models (VLLMs) capable of performing a wide range of
visual understanding tasks. While LLMs have demonstrated impressive performance
on standard natural images, their capabilities have not been thoroughly
explored in cluttered datasets where there is complex environment having
deformed shaped objects. In this work, we introduce a novel dataset
specifically designed for waste classification in real-world scenarios,
characterized by complex environments and deformed shaped objects. Along with
this dataset, we present an in-depth evaluation approach to rigorously assess
the robustness and accuracy of VLLMs. The introduced dataset and comprehensive
analysis provide valuable insights into the performance of VLLMs under
challenging conditions. Our findings highlight the critical need for further
advancements in VLLM's robustness to perform better in complex environments.
The dataset and code for our experiments will be made publicly available.

</details>


### [10] [Category-level Text-to-Image Retrieval Improved: Bridging the Domain Gap with Diffusion Models and Vision Encoders](https://arxiv.org/abs/2509.00177)
*Faizan Farooq Khan,Vladan Stojnić,Zakaria Laskar,Mohamed Elhoseiny,Giorgos Tolias*

Main category: cs.CV

TL;DR: 本文提出了一种两步法来改进文本到图像检索，特别是针对描述语义类别的查询。该方法首先使用生成扩散模型将文本查询转换为视觉查询，然后使用视觉模型估计图像间的相似度。此外，还引入了一个聚合网络来合并多个生成的图像并融合跨模态的相似度分数。该方法通过结合视觉编码器、视觉-语言模型和文本到图像生成模型的最新进展，并在评估中显示出优于仅依赖文本查询的检索方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（VLMs）在处理描述语义类别的文本到图像检索时，由于文本和图像映射到表示空间的遥远区域，限制了检索性能。因此，需要一种方法来弥合这种模态差距。

Method: 本文提出了一种两步方法：1. 使用生成扩散模型将文本查询转换为视觉查询。2. 使用视觉模型估计图像间的相似度。此外，还引入了一个聚合网络来合并多个生成的图像并融合跨模态的相似度分数。

Result: 与仅依赖文本查询的检索方法相比，本文提出的方法在检索性能上始终更优。

Conclusion: 本文提出的两步方法，结合了文本到图像生成和图像到图像的相似度估计，能够有效弥合模态差距，显著提升文本到图像检索的性能，尤其是在处理语义类别查询时。

Abstract: This work explores text-to-image retrieval for queries that specify or
describe a semantic category. While vision-and-language models (VLMs) like CLIP
offer a straightforward open-vocabulary solution, they map text and images to
distant regions in the representation space, limiting retrieval performance. To
bridge this modality gap, we propose a two-step approach. First, we transform
the text query into a visual query using a generative diffusion model. Then, we
estimate image-to-image similarity with a vision model. Additionally, we
introduce an aggregation network that combines multiple generated images into a
single vector representation and fuses similarity scores across both query
modalities. Our approach leverages advancements in vision encoders, VLMs, and
text-to-image generation models. Extensive evaluations show that it
consistently outperforms retrieval methods relying solely on text queries.
Source code is available at: https://github.com/faixan-khan/cletir

</details>


### [11] [Safe-LLaVA: A Privacy-Preserving Vision-Language Dataset and Benchmark for Biometric Safety](https://arxiv.org/abs/2509.00192)
*Younggun Kim,Sirnam Swetha,Fazil Kagdi,Mubarak Shah*

Main category: cs.CV

TL;DR: MLLM在视觉-语言任务中表现出色，但会泄露种族、性别、年龄等敏感生物识别属性。本研究提出了PRISM基准来评估和缓解这种泄露，并发布了Safe-LLaVA数据集，该数据集通过移除LLaVA数据中的生物识别信息来防止泄露。实验证明，Safe-LLaVA能有效减少模型泄露，PRISM基准可用于评估MLLM的隐私保护能力。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在处理视觉-语言任务时，会无意中泄露敏感的生物识别信息，如种族、性别、年龄等，这在现实应用和社会敏感领域引发了严重担忧。然而，目前缺乏公开的数据集或基准来全面评估和缓解这种生物识别信息泄露问题。

Method: 研究者们提出了PRISM（Privacy-aware Evaluation of Responses in Sensitive Modalities）基准，用于评估MLLM在两个方面：1) 拒绝回答与生物识别相关的查询；2) 在通用回答中避免隐含的生物识别信息泄露，同时保持语义的忠实性。此外，他们还审计了广泛使用的LLaVA数据集，发现了其中存在的生物识别信息泄露问题，并据此构建了Safe-LLaVA数据集，这是第一个通过系统性移除LLaVA数据集中显式和隐式生物识别信息而创建的隐私保护型MLLM训练数据集。

Result: 在PRISM基准上的评估显示，现有的MLLM在不同属性上都存在生物识别信息泄露问题，揭示了详细的隐私侵犯情况。通过在Safe-LLaVA数据集上对模型进行微调，研究者们成功地大幅减少了生物识别信息的泄露。

Conclusion: Safe-LLaVA数据集和PRISM基准的结合，为MLLM的隐私对齐开发和评估树立了新的标准。该数据集和基准的公开，旨在推动MLLM在隐私保护方面的进一步研究和应用。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
capabilities in vision-language tasks. However, these models often infer and
reveal sensitive biometric attributes - such as race, gender, age, body weight,
and eye color - even when such information is not explicitly requested. This
raises critical concerns, particularly in real-world applications and
socially-sensitive domains. Despite increasing awareness, no publicly available
dataset or benchmark exists to comprehensively evaluate or mitigate biometric
leakage in MLLMs. To address this gap, we introduce PRISM (Privacy-aware
Evaluation of Responses in Sensitive Modalities), a new benchmark designed to
assess MLLMs on two fronts: (1) refuse biometric-related queries and (2)
implicit biometric leakage in general responses while maintaining semantic
faithfulness. Further, we conduct a detailed audit of the widely used LLaVA
datasets and uncover extensive biometric leakage across pretraining and
instruction data. To address this, we present Safe-LLaVA dataset, the first
privacy-preserving MLLM training dataset constructed by systematically removing
explicit and implicit biometric information from LLaVA dataset. Our evaluations
on PRISM reveal biometric leakages across MLLMs for different attributes,
highlighting the detailed privacy-violations. We also fine-tune a model on
Safe-LLaVA dataset and show that it substantially reduces the biometric
leakages. Together, Safe-LLaVA & PRISM set a new standard for privacy-aligned
development and evaluation of MLLMs. The Safe-LLaVA dataset & PRISM benchmark
are publicly available at https://huggingface.co/datasets/kyh9191/Safe-LLaVA,
and the source code is available at
https://github.com/Kimyounggun99/Safe-LLaVA.git.

</details>


### [12] [Beyond Pixels: Introducing Geometric-Semantic World Priors for Video-based Embodied Models via Spatio-temporal Alignment](https://arxiv.org/abs/2509.00210)
*Jinzhou Tang,Jusheng zhang,Sidi Liu,Waikit Xiu,Qinhan Lv,Xiying Li*

Main category: cs.CV

TL;DR: VEME是一个新颖的跨模态对齐方法，通过学习以自我为中心、以经验为中心的世界模型，提高了模型在未知场景下的泛化能力，从而增强了深层学习模型在动态环境中的推理和规划能力。


<details>
  <summary>Details</summary>
Motivation: 深层学习模型在处理复杂任务和未知环境时，实现类似人类的推理能力仍然是一个关键挑战。现有的视觉-语言模型（VLM）在静态场景理解方面表现出色，但在时空推理和适应动态、开放集任务（如面向任务的导航和具身问答）方面存在局限性，这是由于它们在细粒度时空线索和物理世界理解方面存在不足。

Method: VEME框架集成了三个关键组件：1）一个跨模态对齐框架，将物体、空间表示和视觉语义与时空线索相结合，以增强VLM的上下文学习能力；2）一个由世界嵌入激活的动态、隐式认知图，能够实现与任务相关的几何-语义记忆检索；3）一个利用具身先验进行长期规划和高效探索的基于指令的导航和推理框架。

Result: 实验结果表明，通过嵌入几何感知的时空经验，VEME显著提高了模型在动态环境中的推理和规划能力。在VSI-Bench和VLN-CE上的实验显示，与传统方法相比，准确率和探索效率提高了1%-3%。

Conclusion: VEME通过整合跨模态对齐、认知地图和指令驱动的导航推理，有效地解决了现有VLM在动态环境下的时空推理和泛化能力不足的问题，并在相关基准测试中取得了性能提升。

Abstract: Achieving human-like reasoning in deep learning models for complex tasks in
unknown environments remains a critical challenge in embodied intelligence.
While advanced vision-language models (VLMs) excel in static scene
understanding, their limitations in spatio-temporal reasoning and adaptation to
dynamic, open-set tasks like task-oriented navigation and embodied question
answering (EQA) persist due to inadequate modeling of fine-grained
spatio-temporal cues and physical world comprehension. To address this, we
propose VEME, a novel cross-modal alignment method that enhances generalization
in unseen scenes by learning an ego-centric, experience-centered world model.
Our framework integrates three key components: (1) a cross-modal alignment
framework bridging objects, spatial representations, and visual semantics with
spatio-temporal cues to enhance VLM in-context learning; (2) a dynamic,
implicit cognitive map activated by world embedding to enable task-relevant
geometric-semantic memory recall; and (3) an instruction-based navigation and
reasoning framework leveraging embodied priors for long-term planning and
efficient exploration. By embedding geometry-aware spatio-temporal episodic
experiences, our method significantly improves reasoning and planning in
dynamic environments. Experimental results on VSI-Bench and VLN-CE demonstrate
1%-3% accuracy and exploration efficiency improvement compared to traditional
approaches.

</details>


### [13] [Multimodal Deep Learning for Phyllodes Tumor Classification from Ultrasound and Clinical Data](https://arxiv.org/abs/2509.00213)
*Farhan Fuad Abir,Abigail Elliott Daly,Kyle Anderman,Tolga Ozmen,Laura J. Brattain*

Main category: cs.CV

TL;DR: 本研究提出了一种结合乳腺超声图像和临床数据的多模态深度学习框架，以提高叶状肿瘤（PTs）的诊断准确性，减少不必要的手术切除。


<details>
  <summary>Details</summary>
Motivation: 叶状肿瘤（PTs）因其影像学特征与良性纤维腺瘤相似，术前诊断困难，常导致不必要的手术切除。本研究旨在提高PTs的术前诊断准确性。

Method: 开发了一个双分支神经网络，该网络融合了来自81名PTs患者的乳腺超声（BUS）图像和结构化临床数据。采用了类别感知采样和受试者分层5折交叉验证来处理类别不平衡和数据泄露问题。

Result: 在多模态设置下，ConvNeXt和ResNet18作为图像编码器表现最佳，分别取得了0.9427和0.9349的AUC-ROC评分，以及0.6720和0.7294的F1分数。多模态方法优于单模态基线方法，能够区分良性与边缘恶性/恶性PTs。

Conclusion: 本研究证明了多模态人工智能作为一种非侵入性诊断工具的潜力，可减少不必要的活检，并改善乳腺肿瘤管理的临床决策。

Abstract: Phyllodes tumors (PTs) are rare fibroepithelial breast lesions that are
difficult to classify preoperatively due to their radiological similarity to
benign fibroadenomas. This often leads to unnecessary surgical excisions. To
address this, we propose a multimodal deep learning framework that integrates
breast ultrasound (BUS) images with structured clinical data to improve
diagnostic accuracy. We developed a dual-branch neural network that extracts
and fuses features from ultrasound images and patient metadata from 81 subjects
with confirmed PTs. Class-aware sampling and subject-stratified 5-fold
cross-validation were applied to prevent class imbalance and data leakage. The
results show that our proposed multimodal method outperforms unimodal baselines
in classifying benign versus borderline/malignant PTs. Among six image
encoders, ConvNeXt and ResNet18 achieved the best performance in the multimodal
setting, with AUC-ROC scores of 0.9427 and 0.9349, and F1-scores of 0.6720 and
0.7294, respectively. This study demonstrates the potential of multimodal AI to
serve as a non-invasive diagnostic tool, reducing unnecessary biopsies and
improving clinical decision-making in breast tumor management.

</details>


### [14] [GraViT: Transfer Learning with Vision Transformers and MLP-Mixer for Strong Gravitational Lens Discovery](https://arxiv.org/abs/2509.00226)
*René Parlange,Juan C. Cuevas-Tello,Octavio Valenzuela,Omar de J. Cabrera-Rosas,Tomás Verdugo,Anupreeta More,Anton T. Jaelani*

Main category: cs.CV

TL;DR: LSST将产生大量引力透镜数据，需要自动化分类器。本文提出了一个名为GraViT的PyTorch流水线，利用预训练的Vision Transformer (ViT)和MLP-Mixer模型进行引力透镜检测。研究了迁移学习对分类性能的影响，包括数据质量、模型架构、训练策略和集成预测。通过在HOLISMOKES VI和SuGOHI X数据集上对十种架构进行微调，并与卷积基线进行比较，评估了GraViT的性能。


<details>
  <summary>Details</summary>
Motivation: 引力透镜是研究暗物质和宇宙学参数的有力工具。LSST未来十年将发现大量引力透镜，需要自动化分类器来处理这些数据。

Method: 利用预训练的Vision Transformer (ViT)和MLP-Mixer模型，构建PyTorch流水线GraViT，用于引力透镜检测。通过迁移学习，评估数据质量、模型架构、训练策略和集成预测对分类性能的影响。在HOLISMOKES VI和SuGOHI X数据集上微调了十种架构，并与卷积基线进行了比较。

Result: 研究评估了迁移学习在引力透镜检测中的作用，比较了不同模型架构和训练策略的效果，并分析了复杂度与推理时间。

Conclusion: GraViT流水线利用迁移学习在引力透镜检测任务中表现出色，为LSST海量数据处理提供了有效的解决方案。

Abstract: Gravitational lensing offers a powerful probe into the properties of dark
matter and is crucial to infer cosmological parameters. The Legacy Survey of
Space and Time (LSST) is predicted to find O(10^5) gravitational lenses over
the next decade, demanding automated classifiers. In this work, we introduce
GraViT, a PyTorch pipeline for gravitational lens detection that leverages
extensive pretraining of state-of-the-art Vision Transformer (ViT) models and
MLP-Mixer. We assess the impact of transfer learning on classification
performance by examining data quality (source and sample size), model
architecture (selection and fine-tuning), training strategies (augmentation,
normalization, and optimization), and ensemble predictions. This study
reproduces the experiments in a previous systematic comparison of neural
networks and provides insights into the detectability of strong gravitational
lenses on that common test sample. We fine-tune ten architectures using
datasets from HOLISMOKES VI and SuGOHI X, and benchmark them against
convolutional baselines, discussing complexity and inference-time analysis.

</details>


### [15] [A High-Accuracy Fast Hough Transform with Linear-Log-Cubed Computational Complexity for Arbitrary-Shaped Images](https://arxiv.org/abs/2509.00231)
*Danil Kazimirov,Dmitry Nikolaev*

Main category: cs.CV

TL;DR: 一种用于任意尺寸图像的快速傅里叶变换（FHT）算法，称为FHT2SP，它结合了超级像素概念和FHT2DT算法，实现了接近线性的计算复杂度和可控的近似误差。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有快速傅里叶变换（FHT）算法在计算复杂度和准确性方面的权衡问题，特别是现有算法在处理任意尺寸图像时准确性下降的问题。

Method: 提出了一种名为FHT2SP的新算法，该算法扩展了Brady的超级像素概念以适应任意形状，并将其集成到FHT2DT算法中。通过调整超级像素的大小，该算法在w×h图像上实现了近乎最优的计算复杂度O(wh ln^3 w)，同时将近似误差限制在与图像尺寸无关的常数范围内，并且可以通过元参数进行控制。

Result: 理论和实验分析表明，FHT2SP算法在计算复杂度和准确性方面均表现优异，计算复杂度接近线性，并且近似误差可控且有界。

Conclusion: FHT2SP算法是一种快速且高度准确的傅里叶变换算法，解决了现有算法在处理任意尺寸图像时的准确性下降问题，并提供了可控的误差界限。

Abstract: The Hough transform (HT) is a fundamental tool across various domains, from
classical image analysis to neural networks and tomography. Two key aspects of
the algorithms for computing the HT are their computational complexity and
accuracy - the latter often defined as the error of approximation of continuous
lines by discrete ones within the image region. The fast HT (FHT) algorithms
with optimal linearithmic complexity - such as the Brady-Yong algorithm for
power-of-two-sized images - are well established. Generalizations like $FHT2DT$
extend this efficiency to arbitrary image sizes, but with reduced accuracy that
worsens with scale. Conversely, accurate HT algorithms achieve constant-bounded
error but require near-cubic computational cost. This paper introduces $FHT2SP$
algorithm - a fast and highly accurate HT algorithm. It builds on our
development of Brady's superpixel concept, extending it to arbitrary shapes
beyond the original power-of-two square constraint, and integrates it into the
$FHT2DT$ algorithm. With an appropriate choice of the superpixel's size, for an
image of shape $w \times h$, the $FHT2SP$ algorithm achieves near-optimal
computational complexity $\mathcal{O}(wh \ln^3 w)$, while keeping the
approximation error bounded by a constant independent of image size, and
controllable via a meta-parameter. We provide theoretical and experimental
analyses of the algorithm's complexity and accuracy.

</details>


### [16] [Generative AI for Industrial Contour Detection: A Language-Guided Vision System](https://arxiv.org/abs/2509.00284)
*Liang Gong,Tommy,Wang,Sara Chaker,Yanchen Dong,Fouad Bousetouane,Brenden Morton,Mark Mendez*

Main category: cs.CV

TL;DR: 该研究提出了一种语言引导的生成式视觉系统，用于制造领域的残余轮廓检测，以达到 CAD 级别的精度。该系统包括数据采集与预处理、基于条件 GAN 的轮廓生成以及多模态轮廓精炼，通过人机协作和标准化提示，利用视觉-语言模型进行图像文本引导合成。


<details>
  <summary>Details</summary>
Motivation: 解决工业计算机视觉系统在噪声、材料变异性和非受控成像条件下，传统边缘检测器和手工设计的管线效果受限的问题。

Method: 该系统分为三个阶段：1. 数据采集与预处理；2. 使用条件 GAN 进行轮廓生成；3. 通过视觉-语言模型进行多模态轮廓精炼，其中人机协作设计标准化提示，并通过图像-文本引导合成进行应用。

Result: 在专有的 FabTrack 数据集上，该系统提高了轮廓保真度，增强了边缘连续性和几何对齐，并减少了手动追踪。在精炼阶段，GPT-image-1 在结构准确性和感知质量方面优于 Gemini 2.0 Flash。

Conclusion: 基于视觉-语言模型的生成式工作流程有望推动工业计算机视觉超越传统管线的局限性。

Abstract: Industrial computer vision systems often struggle with noise, material
variability, and uncontrolled imaging conditions, limiting the effectiveness of
classical edge detectors and handcrafted pipelines. In this work, we present a
language-guided generative vision system for remnant contour detection in
manufacturing, designed to achieve CAD-level precision. The system is organized
into three stages: data acquisition and preprocessing, contour generation using
a conditional GAN, and multimodal contour refinement through vision-language
modeling, where standardized prompts are crafted in a human-in-the-loop process
and applied through image-text guided synthesis. On proprietary FabTrack
datasets, the proposed system improved contour fidelity, enhancing edge
continuity and geometric alignment while reducing manual tracing. For the
refinement stage, we benchmarked several vision-language models, including
Google's Gemini 2.0 Flash, OpenAI's GPT-image-1 integrated within a VLM-guided
workflow, and open-source baselines. Under standardized conditions, GPT-image-1
consistently outperformed Gemini 2.0 Flash in both structural accuracy and
perceptual quality. These findings demonstrate the promise of VLM-guided
generative workflows for advancing industrial computer vision beyond the
limitations of classical pipelines.

</details>


### [17] [Language-Aware Information Maximization for Transductive Few-Shot CLIP](https://arxiv.org/abs/2509.00305)
*Ghassen Baklouti,Maxime Zanella,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: 通过引入LIMO损失和参数高效微调（PEFT）策略，提出了一种用于CLIP的新的转导式少样本学习方法，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在视觉-语言模型（VLMs）的背景下，转导式少样本学习仍处于初级阶段，需要针对VLM的方法。

Method: 提出了一种名为LIMO的新型损失函数，该函数结合了视觉输入与文本类别描述之间的互信息、网络概率输出与文本驱动的零样本预测之间的KL散度，以及基于标记样本的标准交叉熵损失。同时，探索了参数高效微调（PEFT）策略，并挑战了在转导式少样本学习中常用的微调方法。

Result: LIMO在转导式少样本CLIP方法上表现出强大的竞争力，并且在性能上大幅超越了最近的转导式少样本CLIP方法，并在与表现最佳的归纳法方法相比时也取得了显著的收益。

Conclusion: LIMO损失和PEFT策略的结合在转导式少样本学习设置中带来了显著的性能提升，表明调整模型部分参数的潜力。

Abstract: Transductive few-shot learning has triggered an abundant literature focusing
on vision-only models, but is still at a nascent stage within the recent
context of foundational vision-language models (VLMs). Only a few recent
methods addressed the problem, pointing to the potential of tranduction in VLMs
and to the need for VLM-tailored methods. Building on this momentum, we
leverage information-theoretic concepts and recent progress in
parameter-efficient fine-tuning (PEFT), developing a highly competitive
transductive few-shot CLIP method. Specifically, we introduce a novel
Language-aware Information MaximizatiOn (LIMO) loss integrating three
complementary terms: (i) the mutual information between the vision inputs and
the textual class descriptions; (ii) a Kullback-Leibler (KL) divergence
penalizing deviation of the network's probabilistic outputs from the
text-driven zero-shot predictions; and (iii) a standard cross-entropy loss
based on the labeled shots. Furthermore, we challenge the commonly followed
fine-tuning practices in the context of transductive few-shot learning, and
explore PEFT strategies, completely overlooked in this context. Surprisingly,
we observe substantial boosts in performances, which points to the potential of
adapting a subset of the model's parameters in the transductive few-shot
setting. We report comprehensive evaluations, which show that LIMO outperforms
the very recent transductive few-shot CLIP methods by a large margin and yields
significant gains over the best-performing inductive methods. Our code is
publicly available at:\[
\href{https://github.com/ghassenbaklouti/LIMO}{\text{here}} \]

</details>


### [18] [MorphGen: Morphology-Guided Representation Learning for Robust Single-Domain Generalization in Histopathological Cancer Classification](https://arxiv.org/abs/2509.00311)
*Hikmat Khan,Syed Farhan Alam Zaidi,Pir Masoom Shah,Kiruthika Balakrishnan,Rabia Khan,Muhammad Waqas,Jia Wu*

Main category: cs.CV

TL;DR: 计算病理学中的领域泛化因全切片图像 (WSI) 的异质性而受到阻碍，这种异质性是由机构间组织制备、染色和成像条件的变化引起的。与机器学习系统不同，病理学家依赖领域不变的形态学线索，如核异常（增大、轮廓不规则、深染、染色质纹理、空间紊乱）、结构异常（异常结构和腺体形成）以及在各种环境中保持诊断性的整体形态异常。受此启发，我们假设明确模拟生物学上稳健的核形态和空间组织将能够学习对领域变化具有弹性的癌症表示。我们提出了 MorphGen（形态学引导的泛化），一种将组织病理学图像、增强和核分割掩模整合到监督对比学习框架中的方法。通过对齐图像和核掩模的潜在表示，MorphGen 优先考虑诊断特征，如核和形态异常以及空间组织，而不是染色伪影和特定于领域的特征。为了进一步增强分布外鲁棒性，我们结合了随机权重平均 (SWA)，将优化引导到更平坦的最小值。注意力图分析显示，MorphGen 主要依赖于肿瘤或正常区域内的核形态、细胞组成和空间细胞组织来进行最终分类。最后，我们证明了所学表示对图像损坏（如染色伪影）和对抗性攻击的鲁棒性，不仅展示了 OOD 泛化，还解决了数字病理学中当前深度学习系统的关键漏洞。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的领域泛化因全切片图像 (WSI) 的异质性而受到阻碍，这种异质性是由机构间组织制备、染色和成像条件的变化引起的。与机器学习系统不同，病理学家依赖领域不变的形态学线索，如核异常（增大、轮廓不规则、深染、染色质纹理、空间紊乱）、结构异常（异常结构和腺体形成）以及在各种环境中保持诊断性的整体形态异常。受此启发，我们假设明确模拟生物学上稳健的核形态和空间组织将能够学习对领域变化具有弹性的癌症表示。

Method: 我们提出了 MorphGen（形态学引导的泛化），一种将组织病理学图像、增强和核分割掩模整合到监督对比学习框架中的方法。通过对齐图像和核掩模的潜在表示，MorphGen 优先考虑诊断特征，如核和形态异常以及空间组织，而不是染色伪影和特定于领域的特征。为了进一步增强分布外鲁棒性，我们结合了随机权重平均 (SWA)，将优化引导到更平坦的最小值。

Result: 注意力图分析显示，MorphGen 主要依赖于肿瘤或正常区域内的核形态、细胞组成和空间细胞组织来进行最终分类。最后，我们证明了所学表示对图像损坏（如染色伪影）和对抗性攻击的鲁棒性，不仅展示了 OOD 泛化，还解决了数字病理学中当前深度学习系统的关键漏洞。

Conclusion: 最后，我们证明了所学表示对图像损坏（如染色伪影）和对抗性攻击的鲁棒性，不仅展示了 OOD 泛化，还解决了数字病理学中当前深度学习系统的关键漏洞。

Abstract: Domain generalization in computational histopathology is hindered by
heterogeneity in whole slide images (WSIs), caused by variations in tissue
preparation, staining, and imaging conditions across institutions. Unlike
machine learning systems, pathologists rely on domain-invariant morphological
cues such as nuclear atypia (enlargement, irregular contours, hyperchromasia,
chromatin texture, spatial disorganization), structural atypia (abnormal
architecture and gland formation), and overall morphological atypia that remain
diagnostic across diverse settings. Motivated by this, we hypothesize that
explicitly modeling biologically robust nuclear morphology and spatial
organization will enable the learning of cancer representations that are
resilient to domain shifts. We propose MorphGen (Morphology-Guided
Generalization), a method that integrates histopathology images, augmentations,
and nuclear segmentation masks within a supervised contrastive learning
framework. By aligning latent representations of images and nuclear masks,
MorphGen prioritizes diagnostic features such as nuclear and morphological
atypia and spatial organization over staining artifacts and domain-specific
features. To further enhance out-of-distribution robustness, we incorporate
stochastic weight averaging (SWA), steering optimization toward flatter minima.
Attention map analyses revealed that MorphGen primarily relies on nuclear
morphology, cellular composition, and spatial cell organization within tumors
or normal regions for final classification. Finally, we demonstrate resilience
of the learned representations to image corruptions (such as staining
artifacts) and adversarial attacks, showcasing not only OOD generalization but
also addressing critical vulnerabilities in current deep learning systems for
digital pathology. Code, datasets, and trained models are available at:
https://github.com/hikmatkhan/MorphGen

</details>


### [19] [Towards Adaptive Visual Token Pruning for Large Multimodal Models](https://arxiv.org/abs/2509.00320)
*Hao Zhang,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin*

Main category: cs.CV

TL;DR: LMMs通过将视觉输入编码为密集标记序列进行处理，但增加了计算和内存成本。为解决此问题，提出了一种仅在视觉标记上进行剪枝的策略，以保持跨模态对齐和模态内信息多样性。通过互信息最大化和期望成对距离最大化来去除语义错位的视觉标记和冗余视觉标记。实验表明，该方法在LLaVA模型上可减少88.9%的标记，推理速度提高56.7%，同时保持了强大的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMMs）在处理视觉和文本信息时，由于将视觉输入编码为密集的标记序列，导致推理时的计算和内存成本显著增加。此外，现有的标记剪枝方法依赖于昂贵的校准或次优的重要性指标，导致保留了冗余的标记。

Method: 提出了一种仅在视觉标记上进行剪枝的策略。首先，通过最大化互信息来移除与文本标记语义错位的视觉标记，以保持跨模态对齐。其次，通过最大化期望成对距离来移除冗余的视觉标记，以提高保留标记的表征质量。

Result: 该方法在LLaVA-1.5-7B和LLaVA-NEXT-7B等模型上，能够减少高达88.9%的视觉标记，同时推理速度提升了56.7%，并且在性能上与原始模型相当。

Conclusion: 提出的视觉标记剪枝策略在有效降低LMMs推理成本的同时，能够保持模型性能和跨模态对齐，是一种高效的优化方法。

Abstract: Large Multimodal Models (LMMs) have achieved significant success across
various tasks. These models usually encode visual inputs into dense token
sequences, which are then concatenated with textual tokens and jointly
processed by a language model. However, the increased token count substantially
raises computational and memory costs during inference. Token pruning has
emerged as a promising approach to address this issue. Existing token pruning
methods often rely on costly calibration or suboptimal importance metrics,
leading to redundant retained tokens. In this paper, we analyze the redundancy
differences between visual and textual tokens and propose pruning exclusively
on visual tokens. Based on this, we propose a visual token pruning strategy
that explicitly preserves both cross-modal alignment and intra-modal
informational diversity. We introduce a mutual information-based token pruning
strategy that removes visual tokens semantically misaligned with textual
tokens, effectively preserving the alignment between the visual and textual
modalities. To further improve the representational quality of the retained
tokens, we additionally prune redundant visual tokens by maximizing the
expected pairwise distances in the embedding space, which is solved efficiently
with a greedy algorithm. Extensive experiments demonstrate that our method
maintains strong performance while reducing tokens by 88.9% on models such as
LLaVA-1.5-7B and LLaVA-NEXT-7B, resulting in a 56.7% improvement in inference
speed.

</details>


### [20] [CryptoFace: End-to-End Encrypted Face Recognition](https://arxiv.org/abs/2509.00332)
*Wei Ao,Vishnu Naresh Boddeti*

Main category: cs.CV

TL;DR: CryptoFace是首个使用全同态加密（FHE）的端到端加密人脸识别系统，可在不泄露原始数据的情况下完成特征提取、存储和匹配。


<details>
  <summary>Details</summary>
Motivation: 解决人脸识别中的隐私风险，特别是未经授权访问敏感生物特征数据的问题。

Method: 提出了一种混合浅层卷积网络，通过基于块的处理支持更高维度的张量，同时减少乘法深度和推理延迟。并行FHE评估确保了接近于分辨率无关的延迟。

Result: 与最先进的FHE神经网络相比，CryptoFace显著加速了推理并提高了验证准确性。

Conclusion: CryptoFace将促进需要强大且可证明安全性的安全人脸识别系统。

Abstract: Face recognition is central to many authentication, security, and
personalized applications. Yet, it suffers from significant privacy risks,
particularly arising from unauthorized access to sensitive biometric data. This
paper introduces CryptoFace, the first end-to-end encrypted face recognition
system with fully homomorphic encryption (FHE). It enables secure processing of
facial data across all stages of a face-recognition process--feature
extraction, storage, and matching--without exposing raw images or features. We
introduce a mixture of shallow patch convolutional networks to support
higher-dimensional tensors via patch-based processing while reducing the
multiplicative depth and, thus, inference latency. Parallel FHE evaluation of
these networks ensures near-resolution-independent latency. On standard face
recognition benchmarks, CryptoFace significantly accelerates inference and
increases verification accuracy compared to the state-of-the-art FHE neural
networks adapted for face recognition. CryptoFace will facilitate secure face
recognition systems requiring robust and provable security. The code is
available at https://github.com/human-analysis/CryptoFace.

</details>


### [21] [LUT-Fuse: Towards Extremely Fast Infrared and Visible Image Fusion via Distillation to Learnable Look-Up Tables](https://arxiv.org/abs/2509.00346)
*Xunpeng Yi,Yibing Zhang,Xinyu Xiang,Qinglong Yan,Han Xu,Jiayi Ma*

Main category: cs.CV

TL;DR: 该研究提出了一种名为LUT-Fuse的新型红外与可见光图像融合方法，通过蒸馏到可学习查找表（LUT）来实现极速融合，并针对移动设备等实时设备进行了优化。


<details>
  <summary>Details</summary>
Motivation: 当前红外与可见光图像融合研究主要关注提升融合性能，但忽略了在实时融合设备上的适用性问题。

Method: 提出了一种新的查找表（LUT）结构，该结构利用低阶近似编码和高层联合上下文场景编码，适用于多模态融合。针对多模态图像融合缺乏真实标签的问题，提出了一种高效的LUT蒸馏策略，而非传统的量化LUT方法。通过将多模态融合网络（MM-Net）的性能整合到MM-LUT模型中，实现了效率和性能的突破。

Result: LUT-Fuse的融合速度是当前轻量级最先进融合算法的十分之一，在各种场景下都能保证高运行速度，甚至在低功耗移动设备上也能实现。大量实验验证了该融合方法的优越性、可靠性和稳定性。

Conclusion: LUT-Fuse通过创新的LUT结构和蒸馏策略，在保证高性能的同时实现了极快的融合速度，解决了实时融合设备上的应用难题，尤其适用于功耗受限的移动平台。

Abstract: Current advanced research on infrared and visible image fusion primarily
focuses on improving fusion performance, often neglecting the applicability on
real-time fusion devices. In this paper, we propose a novel approach that
towards extremely fast fusion via distillation to learnable lookup tables
specifically designed for image fusion, termed as LUT-Fuse. Firstly, we develop
a look-up table structure that utilizing low-order approximation encoding and
high-level joint contextual scene encoding, which is well-suited for
multi-modal fusion. Moreover, given the lack of ground truth in multi-modal
image fusion, we naturally proposed the efficient LUT distillation strategy
instead of traditional quantization LUT methods. By integrating the performance
of the multi-modal fusion network (MM-Net) into the MM-LUT model, our method
achieves significant breakthroughs in efficiency and performance. It typically
requires less than one-tenth of the time compared to the current lightweight
SOTA fusion algorithms, ensuring high operational speed across various
scenarios, even in low-power mobile devices. Extensive experiments validate the
superiority, reliability, and stability of our fusion approach. The code is
available at https://github.com/zyb5/LUT-Fuse.

</details>


### [22] [Target-Oriented Single Domain Generalization](https://arxiv.org/abs/2509.00351)
*Marzi Heidari,Yuhong Guo*

Main category: cs.CV

TL;DR: 在单个源域上训练的深度模型在分布变化下会灾难性地失败。本研究提出了一种新颖的问题设置——面向目标的单域泛化（TO-SDG），该设置利用目标域的文本描述来指导模型泛化，而无需任何目标数据。我们引入了一种名为 STAR 的轻量级模块，通过利用视觉-语言模型（如 CLIP）将目标语义注入源特征。STAR 使用源自目标描述文本嵌入的目标锚定子空间，将图像特征重新定向到部署域，然后利用谱投影保留与目标线索对齐的方向，同时丢弃源特定的噪声。此外，我们使用视觉-语言蒸馏将骨干特征与 VLM 的语义几何对齐。STAR 进一步采用特征空间 Mixup 来确保源和目标导向表示之间的平滑过渡。实验表明 STAR 的优越性，并证明了少量文本元数据可以显著提高在严格数据约束下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的单域泛化（SDG）方法在处理分布变化时存在不足，因为它们要么侧重于增强源数据，要么学习不变特征，而忽略了目标部署环境的文本描述这一可用资源。因此，本研究旨在利用目标域的文本描述来提高模型的泛化能力。

Method: 提出了一种名为 STAR（Spectral TARget Alignment）的轻量级模块，用于解决 TO-SDG 问题。STAR 模块利用视觉-语言模型（如 CLIP）将目标语义注入源特征。具体来说，它通过目标锚定子空间将图像特征重新定向到部署域，并使用谱投影保留与目标线索对齐的方向，同时去除源特定的噪声。此外，还采用视觉-语言蒸馏将骨干特征与 VLM 的语义几何对齐，并使用特征空间 Mixup 确保表示的平滑过渡。

Result: 在图像分类和目标检测基准测试中的实验表明，STAR 方法优于现有方法，证明了少量文本元数据能够显著提高模型在严格数据约束下的泛化能力。

Conclusion: 本研究提出了 TO-SDG 新问题设置，并引入 STAR 模块，有效利用了目标域的文本描述来提升单域泛化能力。实验结果证实了该方法在各种基准测试中的优越性，并强调了在数据受限情况下，少量文本信息对于部署鲁棒模型的重要性，为未来的研究开辟了新方向。

Abstract: Deep models trained on a single source domain often fail catastrophically
under distribution shifts, a critical challenge in Single Domain Generalization
(SDG). While existing methods focus on augmenting source data or learning
invariant features, they neglect a readily available resource: textual
descriptions of the target deployment environment. We propose Target-Oriented
Single Domain Generalization (TO-SDG), a novel problem setup that leverages the
textual description of the target domain, without requiring any target data, to
guide model generalization. To address TO-SDG, we introduce Spectral TARget
Alignment (STAR), a lightweight module that injects target semantics into
source features by exploiting visual-language models (VLMs) such as CLIP. STAR
uses a target-anchored subspace derived from the text embedding of the target
description to recenter image features toward the deployment domain, then
utilizes spectral projection to retain directions aligned with target cues
while discarding source-specific noise. Moreover, we use a vision-language
distillation to align backbone features with VLM's semantic geometry. STAR
further employs feature-space Mixup to ensure smooth transitions between source
and target-oriented representations. Experiments across various image
classification and object detection benchmarks demonstrate STAR's superiority.
This work establishes that minimal textual metadata, which is a practical and
often overlooked resource, significantly enhances generalization under severe
data constraints, opening new avenues for deploying robust models in target
environments with unseen data.

</details>


### [23] [AQFusionNet: Multimodal Deep Learning for Air Quality Index Prediction with Imagery and Sensor Data](https://arxiv.org/abs/2509.00353)
*Koushik Ahmed Kushal,Abdullah Al Mamun*

Main category: cs.CV

TL;DR: AQFusionNet是一个多模态深度学习框架，用于在资源受限地区预测空气质量指数（AQI），集成了大气图像和污染物浓度数据，优于单一模态方法，并适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 资源受限地区空气污染监测面临传感器部署稀疏和基础设施有限的挑战。

Method: AQFusionNet是一个多模态深度学习框架，集成了地面大气图像和污染物浓度数据，利用轻量级CNN主干（MobileNetV2、ResNet18、EfficientNet-B0），通过语义对齐的嵌入空间组合视觉和传感器特征。

Result: 在印度和尼泊尔的8000多个样本上进行实验，AQFusionNet（使用EfficientNet-B0主干）的分类准确率高达92.02%，RMSE为7.70，优于单一模态基线，实现了18.5%的性能提升，同时计算开销低。

Conclusion: AQFusionNet为基础设施有限的环境提供了可扩展且实用的空气质量监测解决方案，即使在传感器可用性部分受损的情况下也能提供强大的预测能力。

Abstract: Air pollution monitoring in resource-constrained regions remains challenging
due to sparse sensor deployment and limited infrastructure. This work
introduces AQFusionNet, a multimodal deep learning framework for robust Air
Quality Index (AQI) prediction. The framework integrates ground-level
atmospheric imagery with pollutant concentration data using lightweight CNN
backbones (MobileNetV2, ResNet18, EfficientNet-B0). Visual and sensor features
are combined through semantically aligned embedding spaces, enabling accurate
and efficient prediction. Experiments on more than 8,000 samples from India and
Nepal demonstrate that AQFusionNet consistently outperforms unimodal baselines,
achieving up to 92.02% classification accuracy and an RMSE of 7.70 with the
EfficientNet-B0 backbone. The model delivers an 18.5% improvement over
single-modality approaches while maintaining low computational overhead, making
it suitable for deployment on edge devices. AQFusionNet provides a scalable and
practical solution for AQI monitoring in infrastructure-limited environments,
offering robust predictive capability even under partial sensor availability.

</details>


### [24] [Iterative Low-rank Network for Hyperspectral Image Denoising](https://arxiv.org/abs/2509.00356)
*Jin Ye,Fengchao Xiong,Jun Zhou,Yuntao Qian*

Main category: cs.CV

TL;DR: ILRNet是一种集成模型驱动和数据驱动方法的U-Net网络，通过在小波域嵌入秩最小化模块（RMM）来利用高光谱图像（HSI）的低秩性，并自适应地学习参数以实现有效的去噪和细节保留。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像（HSI）去噪是后续任务的关键预处理步骤。虽然低秩和稀疏表示是HSI的物理先验，但有效利用这些先验来去噪并保留图像细节具有挑战性。

Method: ILRNet将秩最小化模块（RMM）嵌入U-Net架构中。RMM在前向传播过程中将特征图转换到小波域，并对低频分量应用奇异值阈值处理（SVT），从而在特征域利用HSI的光谱低秩性。该方法还包含一个迭代精炼过程，能够自适应地将中间去噪HSI与噪声输入相结合。

Result: 实验结果表明，ILRNet在合成和真实世界噪声去除任务中均取得了最先进的性能。

Conclusion: ILRNet通过结合模型驱动和数据驱动的方法，并利用HSI的光谱低秩性，能够有效去噪并保留图像细节，达到了最先进的性能。

Abstract: Hyperspectral image (HSI) denoising is a crucial preprocessing step for
subsequent tasks. The clean HSI usually reside in a low-dimensional subspace,
which can be captured by low-rank and sparse representation, known as the
physical prior of HSI. It is generally challenging to adequately use such
physical properties for effective denoising while preserving image details.
This paper introduces a novel iterative low-rank network (ILRNet) to address
these challenges. ILRNet integrates the strengths of model-driven and
data-driven approaches by embedding a rank minimization module (RMM) within a
U-Net architecture. This module transforms feature maps into the wavelet domain
and applies singular value thresholding (SVT) to the low-frequency components
during the forward pass, leveraging the spectral low-rankness of HSIs in the
feature domain. The parameter, closely related to the hyperparameter of the
singular vector thresholding algorithm, is adaptively learned from the data,
allowing for flexible and effective capture of low-rankness across different
scenarios. Additionally, ILRNet features an iterative refinement process that
adaptively combines intermediate denoised HSIs with noisy inputs. This manner
ensures progressive enhancement and superior preservation of image details.
Experimental results demonstrate that ILRNet achieves state-of-the-art
performance in both synthetic and real-world noise removal tasks.

</details>


### [25] [SurgLLM: A Versatile Large Multimodal Model with Spatial Focus and Temporal Awareness for Surgical Video Understanding](https://arxiv.org/abs/2509.00357)
*Zhen Chen,Xingjian Luo,Kun Yuan,Jinlin Wu,Danny T. M. Chan,Nassir Navab,Hongbin Liu,Zhen Lei,Jiebo Luo*

Main category: cs.CV

TL;DR: SurgLLM是一个针对通用手术视频理解任务的大型多模态模型，通过Surg-Pretrain和TM-Tuning增强了空间感知和时间感知能力，并在多个任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有的计算机辅助手术（CAS）系统在处理手术视频时存在视觉内容感知不足和时间感知能力欠缺的问题，阻碍了通用CAS解决方案的发展。

Method: 提出SurgLLM框架，包含：1. Surgical Context-aware Multimodal Pretraining (Surg-Pretrain)，通过器械为中心的掩码视频重建（MV-Recon）和多模态对齐来增强视频编码器的空间感知能力。2. Temporal-aware Multimodal Tuning (TM-Tuning)，通过交错的多模态嵌入来增强时间推理能力。3. Surgical Task Dynamic Ensemble，用于在SurgLLM中高效地根据最优可学习参数对查询进行分类，以适应各种理解任务。

Result: 在包括字幕生成、通用视觉问答（VQA）和时间VQA在内的多个手术视频理解任务上进行了广泛的实验，结果显示SurgLLM显著优于现有最先进的方法。

Conclusion: SurgLLM框架在通用手术视频理解方面表现出卓越的有效性，成功解决了现有方法在空间和时间感知方面的不足。

Abstract: Surgical video understanding is crucial for facilitating Computer-Assisted
Surgery (CAS) systems. Despite significant progress in existing studies, two
major limitations persist, including inadequate visual content perception and
insufficient temporal awareness in surgical videos, and hinder the development
of versatile CAS solutions. In this work, we propose the SurgLLM framework, an
effective large multimodal model tailored for versatile surgical video
understanding tasks with enhanced spatial focus and temporal awareness.
Specifically, to empower the spatial focus of surgical videos, we first devise
Surgical Context-aware Multimodal Pretraining (Surg-Pretrain) for the video
encoder of SurgLLM, by performing instrument-centric Masked Video
Reconstruction (MV-Recon) and subsequent multimodal alignment. To incorporate
surgical temporal knowledge into SurgLLM, we further propose Temporal-aware
Multimodal Tuning (TM-Tuning) to enhance temporal reasoning with interleaved
multimodal embeddings. Moreover, to accommodate various understanding tasks of
surgical videos without conflicts, we devise a Surgical Task Dynamic Ensemble
to efficiently triage a query with optimal learnable parameters in our SurgLLM.
Extensive experiments performed on diverse surgical video understanding tasks,
including captioning, general VQA, and temporal VQA, demonstrate significant
improvements over the state-of-the-art approaches, validating the effectiveness
of our SurgLLM in versatile surgical video understanding. The source code is
available at https://github.com/franciszchen/SurgLLM.

</details>


### [26] [A Multimodal Head and Neck Cancer Dataset for AI-Driven Precision Oncology](https://arxiv.org/abs/2509.00367)
*Numan Saeed,Salma Hassan,Shahad Hardan,Ahmed Aly,Darya Taratynova,Umair Nawaz,Ufaq Khan,Muhammad Ridzuan,Thomas Eugene,Rapha"el Metz,M'elanie Dore,Gregory Delpon,Vijay Ram Kumar Papineni,Kareem Wahid,Cem Dede,Alaa Mohamed Shawky Ali,Carlos Sjogreen,Mohamed Naser,Clifton D. Fuller,Valentin Oreiller,Mario Jreige,John O. Prior,Catherine Cheze Le Rest,Olena Tankyevych,Pierre Decazes,Su Ruan,Stephanie Tanadini-Lang,Martin Valli`eres,Hesham Elhalawani,Ronan Abgral,Romain Floch,Kevin Kerleguer,Ulrike Schick,Maelle Mauguen,Vincent Andrearczyk,Adrien Depeursinge,Mathieu Hatt,Arman Rahmim,Mohammad Yaqub*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We describe a publicly available multimodal dataset of annotated Positron
Emission Tomography/Computed Tomography (PET/CT) studies for head and neck
cancer research. The dataset includes 1123 FDG-PET/CT studies from patients
with histologically confirmed head and neck cancer, acquired from 10
international medical centers. All examinations consisted of co-registered
PET/CT scans with varying acquisition protocols, reflecting real-world clinical
diversity across institutions. Primary gross tumor volumes (GTVp) and involved
lymph nodes (GTVn) were manually segmented by experienced radiation oncologists
and radiologists following standardized guidelines and quality control
measures. We provide anonymized NifTi files of all studies, along with
expert-annotated segmentation masks, radiotherapy dose distribution for a
subset of patients, and comprehensive clinical metadata. This metadata includes
TNM staging, HPV status, demographics (age and gender), long-term follow-up
outcomes, survival times, censoring indicators, and treatment information. We
demonstrate how this dataset can be used for three key clinical tasks:
automated tumor segmentation, recurrence-free survival prediction, and HPV
status classification, providing benchmark results using state-of-the-art deep
learning models, including UNet, SegResNet, and multimodal prognostic
frameworks.

</details>


### [27] [Enabling Federated Object Detection for Connected Autonomous Vehicles: A Deployment-Oriented Evaluation](https://arxiv.org/abs/2509.01868)
*Komala Subramanyam Cherukuri,Kewei Sha,Zhenhua Huang*

Main category: cs.CV

TL;DR: 该论文首次对基于联邦学习（FL）的对象检测在网联自动驾驶汽车（CAVs）中的部署进行了全面的面向部署的评估，重点关注模型性能、系统资源配置和环境鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决中央化训练在可扩展性、适应性和隐私保护方面的不足，同时应对联邦学习在CAVs部署中面临的计算需求大、硬件受限和环境多变等挑战。

Method: 在KITTI、BDD100K和nuScenes数据集上，使用YOLOv5、YOLOv8、YOLOv11和Deformable DETR等先进的检测器，分析了在不同分辨率、批次大小、天气和光照条件以及动态客户端参与下，检测精度、计算成本和资源利用率之间的权衡。

Result: 评估了FL在CAVs中的模型性能、系统资源配置和环境鲁棒性，并分析了不同因素对检测精度的影响。

Conclusion: 为在CAVs中稳健部署FL奠定了基础，通过综合评估模型性能、系统资源消耗和环境适应性，为实际应用提供了指导。

Abstract: Object detection is crucial for Connected Autonomous Vehicles (CAVs) to
perceive their surroundings and make safe driving decisions. Centralized
training of object detection models often achieves promising accuracy, fast
convergence, and simplified training process, but it falls short in
scalability, adaptability, and privacy-preservation. Federated learning (FL),
by contrast, enables collaborative, privacy-preserving, and continuous training
across naturally distributed CAV fleets. However, deploying FL in real-world
CAVs remains challenging due to the substantial computational demands of
training and inference, coupled with highly diverse operating conditions.
Practical deployment must address three critical factors: (i) heterogeneity
from non-IID data distributions, (ii) constrained onboard computing hardware,
and (iii) environmental variability such as lighting and weather, alongside
systematic evaluation to ensure reliable performance. This work introduces the
first holistic deployment-oriented evaluation of FL-based object detection in
CAVs, integrating model performance, system-level resource profiling, and
environmental robustness. Using state-of-the-art detectors, YOLOv5, YOLOv8,
YOLOv11, and Deformable DETR, evaluated on the KITTI, BDD100K, and nuScenes
datasets, we analyze trade-offs between detection accuracy, computational cost,
and resource usage under diverse resolutions, batch sizes, weather and lighting
conditions, and dynamic client participation, paving the way for robust FL
deployment in CAVs.

</details>


### [28] [Two Causes, Not One: Rethinking Omission and Fabrication Hallucinations in MLLMs](https://arxiv.org/abs/2509.00371)
*Guangzong Si,Hao Yin,Xianfei Li,Qing Ding,Wenlong Liao,Tao He,Pai Peng*

Main category: cs.CV

TL;DR: MLLMs存在目标幻觉问题，现有方法未能有效解决。本文提出Visual Potential Field Calibration (VPFC)方法，区分了遗漏和虚构幻觉的成因，并通过实验证明VPFC能有效减少遗漏幻觉且不增加虚构幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在目标识别方面存在幻觉问题，并且现有方法未能有效解决，甚至可能因减少遗漏幻觉而增加虚构幻觉。

Method: 本文提出了Visual-מאleucetic Attention Potential Field（视觉-语义注意势场）的概念框架，揭示了模型如何构建视觉证据来推断目标的存在与否。在此基础上，提出了一种即插即用的幻觉缓解方法——Visual Potential Field Calibration (VPFC)，用于减少遗漏幻觉，同时避免产生额外的虚构幻觉。

Result: VPFC被证明能有效减少遗漏幻觉，并且不会引入额外的虚构幻觉。

Conclusion: 本文的研究发现揭示了当前目标幻觉研究中存在的关键疏漏，并为开发更鲁棒、更平衡的幻觉缓解策略指明了新的方向。

Abstract: Multimodal Large Language Models (MLLMs) have achieved impressive advances,
yet object hallucination remains a persistent challenge. Existing methods,
based on the flawed assumption that omission and fabrication hallucinations
share a common cause, often reduce omissions only to trigger more fabrications.
In this work, we overturn this view by demonstrating that omission
hallucinations arise from insufficient confidence when mapping perceived visual
features to linguistic expressions, whereas fabrication hallucinations result
from spurious associations within the cross-modal representation space due to
statistical biases in the training corpus. Building on findings from visual
attention intervention experiments, we propose the Visual-Semantic Attention
Potential Field, a conceptual framework that reveals how the model constructs
visual evidence to infer the presence or absence of objects. Leveraging this
insight, we introduce Visual Potential Field Calibration (VPFC), a
plug-and-play hallucination mitigation method that effectively reduces omission
hallucinations without introducing additional fabrication hallucinations. Our
findings reveal a critical oversight in current object hallucination research
and chart new directions for developing more robust and balanced hallucination
mitigation strategies.

</details>


### [29] [Activation Steering Meets Preference Optimization: Defense Against Jailbreaks in Vision Language Models](https://arxiv.org/abs/2509.00373)
*Sihao Wu,Gaojie Jin,Wei Huang,Jianhong Wang,Xiaowei Huang*

Main category: cs.CV

TL;DR: SPO-VLM是一种结合激活层干预和策略层优化的两阶段防御框架，通过自适应层特定方向和序列级偏好优化来增强视觉语言模型（VLMs）的鲁棒性，以对抗对抗性攻击，同时保持其在良性任务上的性能和视觉理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）虽然在整合视觉和文本信息方面表现出色，但容易受到对抗性攻击。现有的基于激活度引导的防御方法依赖于特定任务的对比提示来提取有害方向，这会导致性能不佳并损害视觉基础性能。

Method: SPO-VLM是一个两阶段防御框架。阶段一：计算自适应层特定方向，从多样化数据源提取，以在推理过程中泛化抑制有害行为。阶段二：通过序列级偏好优化过程优化这些方向，该过程整合了自动毒性评估和基于图文匹配的视觉一致性奖励，以实现安全且语义一致的文本生成。

Result: 实验表明，SPO-VLM在通过激活度引导和偏好优化提高安全性方面优于现有方法，同时在不损害视觉理解能力的情况下，在良性任务上保持了强大的性能。

Conclusion: SPO-VLM通过结合激活层干预和策略层优化，成功增强了视觉语言模型的鲁棒性，实现了对对抗性攻击的安全防御，同时保持了模型的性能和视觉基础能力。

Abstract: Vision Language Models (VLMs) have demonstrated impressive capabilities in
integrating visual and textual information for understanding and reasoning, but
remain highly vulnerable to adversarial attacks. While activation steering has
emerged as a promising defence, existing approaches often rely on task-specific
contrastive prompts to extract harmful directions, which exhibit suboptimal
performance and can degrade visual grounding performance. To address these
limitations, we propose \textit{Sequence-Level Preference Optimization} for VLM
(\textit{SPO-VLM}), a novel two-stage defense framework that combines
activation-level intervention with policy-level optimization to enhance model
robustness. In \textit{Stage I}, we compute adaptive layer-specific steering
vectors from diverse data sources, enabling generalized suppression of harmful
behaviors during inference. In \textit{Stage II}, we refine these steering
vectors through a sequence-level preference optimization process. This stage
integrates automated toxicity assessment, as well as visual-consistency rewards
based on caption-image alignment, to achieve safe and semantically grounded
text generation. The two-stage structure of SPO-VLM balances efficiency and
effectiveness by combining a lightweight mitigation foundation in Stage I with
deeper policy refinement in Stage II. Extensive experiments shown SPO-VLM
enhances safety against attacks via activation steering and preference
optimization, while maintaining strong performance on benign tasks without
compromising visual understanding capabilities. We will release our code, model
weights, and evaluation toolkit to support reproducibility and future research.
\textcolor{red}{Warning: This paper may contain examples of offensive or
harmful text and images.}

</details>


### [30] [Adaptive Point-Prompt Tuning: Fine-Tuning Heterogeneous Foundation Models for 3D Point Cloud Analysis](https://arxiv.org/abs/2509.00374)
*Mengke Li,Lihao Chen,Peng Zhang,Yiu-ming Cheung,Hui Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为APPT（自适应点提示调优）的新方法，用于在3D点云分析中有效微调预训练模型。该方法直接利用点特征来校准任何模态的异构基础模型，无需进行“高到低”的映射，从而保留了空间几何信息。APPT通过聚合局部几何信息生成点嵌入，并利用排列不变性特征捕捉相对位置信息，丰富点标记。此外，论文还引入了一个共享权重的提示生成器，动态生成点提示以校准自注意力机制，并为冻结的基础模型提供全局结构信息，解决了3D点云数据稀缺和处理困难的问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模预训练模型（包括1D文本和2D视觉分析）的参数高效微调策略取得显著效果的背景下，3D点云数据的稀缺性使得预训练大型3D模型成为一项挑战。现有的“高到低”映射方法在将预训练视觉模型应用于3D领域时，常常丢失空间几何信息，并且缺乏一个通用的框架来适应任何模态到3D。因此，本研究旨在直接利用点特征来校准任何模态的异构基础模型，以实现3D点云分析。

Method: 提出自适应点提示调优（APPT）方法，直接利用点特征校准异构基础模型。具体做法包括：1. 将原始点云转换为点嵌入，通过聚合局部几何信息捕捉空间特征，并使用线性层确保与冻结的预训练模型的无缝衔接。2. 针对点云的无序性，采用排列不变性特征捕捉点嵌入的相对位置，生成包含位置信息点标记，以优化自注意力机制。3. 引入一个与点嵌入模块共享权重的提示生成器，动态生成点提示，而无需增加额外参数，以校准跨模态到3D的自注意力，并降低计算开销。4. 将点提示连接到冻结的基础模型中，提供全局结构信息，弥补异构数据中结构上下文的不足。

Result: APPT方法能够有效地微调预训练模型，实现直接的点云处理，避免了异构映射带来的空间几何信息损失。通过点嵌入和排列不变性特征，模型能够有效捕捉3D点云的空间和位置信息。提示生成器实现了参数高效的自注意力校准，并为模型提供了必要的全局结构信息。

Conclusion: APPT提供了一种新颖且有效的解决方案，用于在3D点云分析中利用现有的大型基础模型。该方法通过直接处理点特征和自适应地校准自注意力机制，克服了数据稀缺性和处理异构模态的挑战，为3D点云分析领域带来了参数高效且具有通用性的新途径。

Abstract: Parameter-efficient fine-tuning strategies for foundation models in 1D
textual and 2D visual analysis have demonstrated remarkable efficacy. However,
due to the scarcity of point cloud data, pre-training large 3D models remains a
challenging task. While many efforts have been made to apply pre-trained visual
models to 3D domains through "high-to-low" mapping, these approaches often lead
to the loss of spatial geometries and lack a generalizable framework for
adapting any modality to 3D. This paper, therefore, attempts to directly
leverage point features to calibrate the heterogeneous foundation model of any
modality for 3D point cloud analysis. Specifically, we propose the Adaptive
Point-Prompt Tuning (APPT) method, which fine-tunes pre-trained models with a
modest number of parameters, enabling direct point cloud processing without
heterogeneous mappings. We convert raw point clouds into point embeddings by
aggregating local geometry to capture spatial features followed by linear
layers to ensure seamless utilization of frozen pre-trained models. Given the
inherent disorder of point clouds, in contrast to the structured nature of
images and language, we employ a permutation-invariant feature to capture the
relative positions of point embeddings, thereby obtaining point tokens enriched
with location information to optimize self-attention mechanisms. To calibrate
self-attention across source domains of any modality to 3D and reduce
computational overhead, we introduce a prompt generator that shares weights
with the point embedding module, dynamically producing point-prompts without
adding additional parameters. These prompts are then concatenated into a frozen
foundation model, providing rich global structural information and compensating
for the lack of structural context in the heterogeneous data.

</details>


### [31] [NoiseCutMix: A Novel Data Augmentation Approach by Mixing Estimated Noise in Diffusion Models](https://arxiv.org/abs/2509.00378)
*Shumpei Takezaki,Ryoma Bise,Shinnosuke Matsuo*

Main category: cs.CV

TL;DR: 本研究提出了一种名为NoiseCutMix的新型数据增强方法，将CutMix概念融入扩散模型，通过融合两个不同类别对应的噪声来生成兼具两个类别特征的自然、高分辨率图像。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数据增强方法（如CutMix）在融合图像时可能产生的边界不自然问题，并利用扩散模型生成自然、高分辨率图像的能力以及CutMix融合多样化数据增强的特性。

Method: 提出NoiseCutMix方法，通过部分融合扩散模型中对应两个不同类别的估计噪声，实现自然、高分辨率且融合了两个类别特征的图像生成。

Result: 通过在分类实验中将NoiseCutMix与传统多类别组合数据增强技术、Stable Diffusion随机图像生成及其组合方法进行比较，验证了所提出方法的有效性。

Conclusion: NoiseCutMix能够生成具有两个类别融合特征的自然、高分辨率图像，并在分类任务中优于现有方法。

Abstract: In this study, we propose a novel data augmentation method that introduces
the concept of CutMix into the generation process of diffusion models, thereby
exploiting both the ability of diffusion models to generate natural and
high-resolution images and the characteristic of CutMix, which combines
features from two classes to create diverse augmented data. Representative data
augmentation methods for combining images from multiple classes include CutMix
and MixUp. However, techniques like CutMix often result in unnatural boundaries
between the two images due to contextual differences. Therefore, in this study,
we propose a method, called NoiseCutMix, to achieve natural, high-resolution
image generation featuring the fused characteristics of two classes by
partially combining the estimated noise corresponding to two different classes
in a diffusion model. In the classification experiments, we verified the
effectiveness of the proposed method by comparing it with conventional data
augmentation techniques that combine multiple classes, random image generation
using Stable Diffusion, and combinations of these methods. Our codes are
available at: https://github.com/shumpei-takezaki/NoiseCutMix

</details>


### [32] [Domain Adaptation-Based Crossmodal Knowledge Distillation for 3D Semantic Segmentation](https://arxiv.org/abs/2509.00379)
*Jialiang Kang,Jiawen Wang,Dingsheng Luo*

Main category: cs.CV

TL;DR: 本文提出两种跨模态知识蒸馏方法（UDAKD和FSKD），利用现成的2D图像数据和预训练的2D模型，通过知识蒸馏的方式处理3D LiDAR数据，以解决3D点云标注成本高的问题，并取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了降低3D LiDAR点云标注的成本和时间投入，本文提出利用大规模、易于获取的2D图像数据来辅助3D点云的语义分割。

Method: 本文提出两种跨模态知识蒸馏方法：无监督域适应知识蒸馏（UDAKD）和特征与语义知识蒸馏（FSKD）。利用相机和LiDAR数据的时空同步性，将预训练的2D图像模型应用于未标注的2D数据，并通过跨模态知识蒸馏将2D网络的输出与3D网络中对应的点对齐，从而无需3D标注。在蒸馏过程中，注重保留模态无关信息并过滤掉模态特异性细节。在3D点云上采用自校准卷积作为域适应模块的基础。

Result: 实验结果表明，所提出的方法在3D LiDAR点云的语义分割任务上，性能持续优于当前最先进的方法。

Conclusion: 本文提出的两种跨模态知识蒸馏方法（UDAKD和FSKD）能够有效利用2D图像数据，克服3D点云标注的限制，并在3D点云语义分割任务中取得优异成果。

Abstract: Semantic segmentation of 3D LiDAR data plays a pivotal role in autonomous
driving. Traditional approaches rely on extensive annotated data for point
cloud analysis, incurring high costs and time investments. In contrast,
realworld image datasets offer abundant availability and substantial scale. To
mitigate the burden of annotating 3D LiDAR point clouds, we propose two
crossmodal knowledge distillation methods: Unsupervised Domain Adaptation
Knowledge Distillation (UDAKD) and Feature and Semantic-based Knowledge
Distillation (FSKD). Leveraging readily available spatio-temporally
synchronized data from cameras and LiDARs in autonomous driving scenarios, we
directly apply a pretrained 2D image model to unlabeled 2D data. Through
crossmodal knowledge distillation with known 2D-3D correspondence, we actively
align the output of the 3D network with the corresponding points of the 2D
network, thereby obviating the necessity for 3D annotations. Our focus is on
preserving modality-general information while filtering out modality-specific
details during crossmodal distillation. To achieve this, we deploy
self-calibrated convolution on 3D point clouds as the foundation of our domain
adaptation module. Rigorous experimentation validates the effectiveness of our
proposed methods, consistently surpassing the performance of state-of-the-art
approaches in the field.

</details>


### [33] [Visually Grounded Narratives: Reducing Cognitive Burden in Researcher-Participant Interaction](https://arxiv.org/abs/2509.00381)
*Runtong Wu,Jiayao Song,Fei Teng,Xianhao Ren,Yuyan Gao,Kailun Yang*

Main category: cs.CV

TL;DR: 本研究提出了一个名为NAME的新范式，旨在通过将研究文件转换为连贯的故事图像来减轻叙事探究中的数据分析负担，并提出了用于图像生成的演员定位和形状模块，以及一套客观衡量生成角色感知质量和叙事一致性的鲁棒评估指标。


<details>
  <summary>Details</summary>
Motivation: 为了减轻叙事分析中将各种数据转化为连贯的叙事手稿的负担，并为参与者提供更友好、更有效的方法来制作和呈现叙事。

Method: 提出了一种名为NAME的新范式，该范式能够将研究文档转换为连贯的故事图像。开发了一个演员定位和形状模块来实现合理的图像生成。设计了一套包括三个关键维度来客观衡量生成角色感知质量和叙事一致性的鲁棒评估指标。

Result: 所提出的方法在不同数据划分方案下始终展现出最先进的性能。与依赖100%可用数据的基线相比，该方法仅需0.96%的数据即可将FID分数从195降低到152。在相同数据量下，70:30的数据划分 FID分数从175降至152，95:5的数据划分FID分数从96降至49。此外，该模型在新引入的指标上得分3.62，优于基线得分2.66。

Conclusion: 该研究首次尝试通过NAME范式，将研究文件转化为故事图像，有效减轻了研究人员和参与者在成员核查过程中解读大量文本材料的认知负担，并在图像生成和评估方面取得了显著成效。

Abstract: Narrative inquiry has been one of the prominent application domains for the
analysis of human experience, aiming to know more about the complexity of human
society. However, researchers are often required to transform various forms of
data into coherent hand-drafted narratives in storied form throughout narrative
analysis, which brings an immense burden of data analysis. Participants, too,
are expected to engage in member checking and presentation of these narrative
products, which involves reviewing and responding to large volumes of
documents. Given the dual burden and the need for more efficient and
participant-friendly approaches to narrative making and representation, we made
a first attempt: (i) a new paradigm is proposed, NAME, as the initial attempt
to push the field of narrative inquiry. Name is able to transfer research
documents into coherent story images, alleviating the cognitive burden of
interpreting extensive text-based materials during member checking for both
researchers and participants. (ii) We develop an actor location and shape
module to facilitate plausible image generation. (iii) We have designed a set
of robust evaluation metrics comprising three key dimensions to objectively
measure the perceptual quality and narrative consistency of generated
characters. Our approach consistently demonstrates state-of-the-art performance
across different data partitioning schemes. Remarkably, while the baseline
relies on the full 100% of the available data, our method requires only 0.96%
yet still reduces the FID score from 195 to 152. Under identical data volumes,
our method delivers substantial improvements: for the 70:30 split, the FID
score decreases from 175 to 152, and for the 95:5 split, it is nearly halved
from 96 to 49. Furthermore, the proposed model achieves a score of 3.62 on the
newly introduced metric, surpassing the baseline score of 2.66.

</details>


### [34] [HERO-VQL: Hierarchical, Egocentric and Robust Visual Query Localization](https://arxiv.org/abs/2509.00385)
*Joohyun Chang,Soyeon Hong,Hyogun Lee,Seong Jong Ha,Dongho Lee,Seong Tae Kim,Jinwoo Choi*

Main category: cs.CV

TL;DR: HERO-VQL是一种新颖的视觉查询定位方法，通过引入自上而下的注意力指导（TAG）和基于一致性训练的自适应增强（EgoACT）来解决以自我为中心的视频中物体定位的挑战。


<details>
  <summary>Details</summary>
Motivation: 以自我为中心的视频中频繁且突然的视角变化会导致物体外观的显著变化和部分遮挡，使得现有方法难以实现精确的物体定位。

Method: HERO-VQL方法包括两个主要组成部分：1. 自上而下的注意力指导（TAG），它利用类别标记和主成分得分图来提炼注意力机制，以实现高层上下文和细粒度的定位。2. 基于一致性训练的自适应增强（EgoACT），它通过替换查询对象和模拟极端视角变化来增强查询多样性，并通过CT损失确保在不同增强场景下的稳定物体定位。

Result: 在VQ2D数据集上的大量实验证明，HERO-VQL有效应对了以自我为中心的挑战，并且显著优于基线方法。

Conclusion: HERO-VQL通过其新颖的TAG和EgoACT机制，成功克服了以自我为中心的视频中物体定位的固有挑战，并在VQ2D数据集上取得了优越的性能。

Abstract: In this work, we tackle the egocentric visual query localization (VQL), where
a model should localize the query object in a long-form egocentric video.
Frequent and abrupt viewpoint changes in egocentric videos cause significant
object appearance variations and partial occlusions, making it difficult for
existing methods to achieve accurate localization. To tackle these challenges,
we introduce Hierarchical, Egocentric and RObust Visual Query Localization
(HERO-VQL), a novel method inspired by human cognitive process in object
recognition. We propose i) Top-down Attention Guidance (TAG) and ii) Egocentric
Augmentation based Consistency Training (EgoACT). Top-down Attention Guidance
refines the attention mechanism by leveraging the class token for high-level
context and principal component score maps for fine-grained localization. To
enhance learning in diverse and challenging matching scenarios, EgoAug enhances
query diversity by replacing the query with a randomly selected corresponding
object from groundtruth annotations and simulates extreme viewpoint changes by
reordering video frames. Additionally, CT loss enforces stable object
localization across different augmentation scenarios. Extensive experiments on
VQ2D dataset validate that HERO-VQL effectively handles egocentric challenges,
significantly outperforming baselines.

</details>


### [35] [Double-Constraint Diffusion Model with Nuclear Regularization for Ultra-low-dose PET Reconstruction](https://arxiv.org/abs/2509.00395)
*Mengxiao Geng,Ran Hong,Bingxuan Li,Qiegen Liu*

Main category: cs.CV

TL;DR: DCDM通过引入可训练的双约束控制器来优化预训练的扩散模型，以适应不同剂量的超低剂量PET重建，并在公开和临床数据集上均优于现有技术，尤其在未知剂量因子和1%全剂量等极端情况下表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在解决超低剂量PET重建中图像质量下降的问题，同时降低患者辐射暴露和缩短检查时间。

Method: 提出了一种双约束扩散模型（DCDM），通过冻结预训练扩散模型的权重并注入可训练的双约束控制器（核变换器约束NTC和编码连接约束ENC），实现了参数高效的超低剂量PET重建。NTC利用核范数提取低剂量图像的低秩信息并压缩为潜在特征表示，ENC则利用这些特征来控制预训练扩散模型进行图像重建。

Result: DCDM在UDPET公开数据集和临床数据集上进行了实验评估，结果显示其在已知剂量降低因子（DRF）方面优于现有最先进的方法，并且在未知DRF场景下也具有良好的泛化能力，即使在1%全剂量等超低剂量水平下也表现出有效性。

Conclusion: DCDM是一种有效的超低剂量PET重建方法，通过其独特的双约束架构，能够灵活适应不同剂量水平，并在各种挑战性条件下提供高质量的重建图像，为减少患者辐射和提高诊断效率提供了新的解决方案。

Abstract: Ultra-low-dose positron emission tomography (PET) reconstruction holds
significant potential for reducing patient radiation exposure and shortening
examination times. However, it may also lead to increased noise and reduced
imaging detail, which could decrease the image quality. In this study, we
present a Double-Constraint Diffusion Model (DCDM), which freezes the weights
of a pre-trained diffusion model and injects a trainable double-constraint
controller into the encoding architecture, greatly reducing the number of
trainable parameters for ultra-low-dose PET reconstruction. Unlike full
fine-tuning models, DCDM can adapt to different dose levels without retraining
all model parameters, thereby improving reconstruction flexibility.
Specifically, the two constraint modules, named the Nuclear Transformer
Constraint (NTC) and the Encoding Nexus Constraint (ENC), serve to refine the
pre-trained diffusion model. The NTC leverages the nuclear norm as an
approximation for matrix rank minimization, integrates the low-rank property
into the Transformer architecture, and enables efficient information extraction
from low-dose images and conversion into compressed feature representations in
the latent space. Subsequently, the ENC utilizes these compressed feature
representations to encode and control the pre-trained diffusion model,
ultimately obtaining reconstructed PET images in the pixel space. In clinical
reconstruction, the compressed feature representations from NTC help select the
most suitable ENC for efficient unknown low-dose PET reconstruction.
Experiments conducted on the UDPET public dataset and the Clinical dataset
demonstrated that DCDM outperforms state-of-the-art methods on known dose
reduction factors (DRF) and generalizes well to unknown DRF scenarios, proving
valuable even at ultra-low dose levels, such as 1% of the full dose.

</details>


### [36] [DAOVI: Distortion-Aware Omnidirectional Video Inpainting](https://arxiv.org/abs/2509.00396)
*Ryosuke Seshimo,Mariko Isogawa*

Main category: cs.CV

TL;DR: 本研究提出了一种名为DAOVI的面向全向视频的深度学习模型，用于修复视频中的不希望出现的物体，解决了全向视频中因等距柱状投影造成的畸变问题。


<details>
  <summary>Details</summary>
Motivation: 全向视频在VR和遥感等领域有广泛应用，但其宽广的视角会导致不希望出现的物体进入画面。现有的视频修复方法通常处理普通窄视角视频，未能解决全向视频中等距柱状投影的畸变问题。

Method: 提出了一种名为DAOVI（Distortion-Aware Omnidirectional Video Inpainting）的新型深度学习模型。该模型包含一个在图像空间中考虑测地线距离的模块，用于评估时间运动信息；以及一个在特征空间中设计的深度感知特征传播模块，以解决全向视频固有的几何畸变问题。

Result: 实验结果表明，所提出的DAOVI方法在定量和定性方面均优于现有方法。

Conclusion: DAOVI模型能够有效处理全向视频中的几何畸变，并自然地去除不希望出现的物体，同时保持空间和时间一致性，在全向视频修复领域取得了领先的性能。

Abstract: Omnidirectional videos that capture the entire surroundings are employed in a
variety of fields such as VR applications and remote sensing. However, their
wide field of view often causes unwanted objects to appear in the videos. This
problem can be addressed by video inpainting, which enables the natural removal
of such objects while preserving both spatial and temporal consistency.
Nevertheless, most existing methods assume processing ordinary videos with a
narrow field of view and do not tackle the distortion in equirectangular
projection of omnidirectional videos. To address this issue, this paper
proposes a novel deep learning model for omnidirectional video inpainting,
called Distortion-Aware Omnidirectional Video Inpainting (DAOVI). DAOVI
introduces a module that evaluates temporal motion information in the image
space considering geodesic distance, as well as a depth-aware feature
propagation module in the feature space that is designed to address the
geometric distortion inherent to omnidirectional videos. The experimental
results demonstrate that our proposed method outperforms existing methods both
quantitatively and qualitatively.

</details>


### [37] [DevilSight: Augmenting Monocular Human Avatar Reconstruction through a Virtual Perspective](https://arxiv.org/abs/2509.00403)
*Yushuo Chen,Ruizhi Shao,Youxin Pang,Hongwen Zhang,Xinyi Wu,Rihui Wu,Yebin Liu*

Main category: cs.CV

TL;DR: 我们提出了一个新颖的框架，利用先进的视频生成模型Human4DiT从单目视频中重建人类虚拟化身，通过生成不同视角的运动作为额外的监督信号，增强了模型对未见过区域的细节捕捉能力，并通过视频微调注入物理身份和采用基于块的去噪算法来提高生成质量和分辨率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉输入视频的精细动态细节或在新的视角下生成合理细节方面存在困难，这主要是由于虚拟化身模型的表示能力有限和观测数据不足。

Method: 利用先进的视频生成模型Human4DiT生成人类运动的替代视角作为额外的监督信号，并通过视频微调注入物理身份，采用基于块的去噪算法来提高输出分辨率和细节。

Result: 实验结果表明，我们提出的方法优于最近的最新方法，并验证了我们提出的策略的有效性。

Conclusion: 我们提出的方法通过利用视频生成模型和引入两种增强视频生成的策略，成功地克服了现有方法的局限性，实现了更高质量和更详细的人类虚拟化身重建。

Abstract: We present a novel framework to reconstruct human avatars from monocular
videos. Recent approaches have struggled either to capture the fine-grained
dynamic details from the input or to generate plausible details at novel
viewpoints, which mainly stem from the limited representational capacity of the
avatar model and insufficient observational data. To overcome these challenges,
we propose to leverage the advanced video generative model, Human4DiT, to
generate the human motions from alternative perspective as an additional
supervision signal. This approach not only enriches the details in previously
unseen regions but also effectively regularizes the avatar representation to
mitigate artifacts. Furthermore, we introduce two complementary strategies to
enhance video generation: To ensure consistent reproduction of human motion, we
inject the physical identity into the model through video fine-tuning. For
higher-resolution outputs with finer details, a patch-based denoising algorithm
is employed. Experimental results demonstrate that our method outperforms
recent state-of-the-art approaches and validate the effectiveness of our
proposed strategies.

</details>


### [38] [LightVLM: Acceleraing Large Multimodal Models with Pyramid Token Merging and KV Cache Compression](https://arxiv.org/abs/2509.00419)
*Lianyu Hu,Fanhua Shang,Wei Feng,Liang Wan*

Main category: cs.CV

TL;DR: LightVLM是一种训练无关的方法，通过金字塔令牌合并（编码）和KV缓存压缩（解码）来加速视觉语言模型（VLMs）的推理过程，在保持性能的同时显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉语言模型（VLMs）推理过程中的高延迟问题，并促进其在现实世界中的部署。

Method: 1. 编码阶段：提出金字塔令牌合并（pyramid token merging），通过分层方式减少不同LLM层的令牌数量，最终只保留少数主导令牌。 2. 解码阶段：提出KV缓存压缩（KV Cache compression），移除不必要的缓存以减少输出长序列时的延迟，提高网络吞吐量。

Result: LightVLM在仅保留35%图像令牌时能保持100%的性能，在仅保留3%图像令牌时能维持约98%的性能。LightVLM可以将网络吞吐量提高2.02倍，预填充时间缩短3.65倍。对于4096个令牌的长序列生成，可以将推理时间缩短3.21倍，优于现有方法。

Conclusion: LightVLM是一种有效且易于部署的方法，可以显著加速VLMs的推理过程，同时保持高性能，从而有望促进VLMs在现实世界中的应用。

Abstract: In this paper, we introduce LightVLM, a simple but effective method that can
be seamlessly deployed upon existing Vision-Language Models (VLMs) to greatly
accelerate the inference process in a training-free manner. We divide the
inference procedure of VLMs into two stages, i.e., encoding and decoding, and
propose to simultaneously accelerate VLMs in both stages to largely improve
model efficiency. During encoding, we propose pyramid token merging to reduce
tokens of different LLM layers in a hierarchical manner by finally only keeping
a few dominant tokens to achieve high efficiency. During decoding, aimed at
reducing the high latency of outputting long sequences, we propose KV Cache
compression to remove unnecessary caches to increase the network throughput.
Experimental results show that LightVLM successfully retains 100% performance
when only preserving 35% image tokens, and maintains around 98% performance
when keeping only 3% image tokens. LightVLM could 2.02$\times$ the network
throughput and reduce the prefilling time by 3.65$\times$. LightVLM also makes
large VLMs faster again by enabling a heavy model (e.g., InternVL2.5 26B) to
infer faster than significantly smaller models (e.g., InternVL2.5 8B),
hopefully facilitating the real-world deployment. When generating long text
sequences (e.g., 4096 tokens), LightVLM could reduce the inference time by
3.21$\times$, largely outperforming existing methods.

</details>


### [39] [Mixture of Global and Local Experts with Diffusion Transformer for Controllable Face Generation](https://arxiv.org/abs/2509.00428)
*Xuechao Zou,Shun Zhang,Xing Fu,Yue Li,Kai Li,Yushe Cao,Congyan Lang,Pin Tao,Junliang Xing*

Main category: cs.CV

TL;DR: Face-MoGLE是一个新颖的框架，用于高质量、可控的人脸生成，通过专家专业化和语义解耦的潜在模型，能够进行精确的属性操作，并在多模态和单模态人脸生成设置中表现出色，具有强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的可控人脸生成方法在语义可控性和照片真实性之间难以取得平衡，并且在将语义控制与生成管线分离方面存在困难。因此，需要一种新的框架来解决这些挑战。

Method: Face-MoGLE框架采用了以下方法：1) 通过掩码条件空间因子化实现语义解耦的潜在建模，以进行精确的属性操作；2) 融合全局和局部专家，捕捉整体结构和区域级语义，以实现细粒度的可控性；3) 引入动态门控网络，生成随扩散步长和空间位置变化的依赖时间系数。

Result: Face-MoGLE在多模态和单模态人脸生成设置中都展现了有效性，并具有强大的零样本泛化能力，证明了其在生成模型和安全应用方面的潜力。

Conclusion: Face-MoGLE通过其创新的架构和方法，为高质量、可控的人脸生成提供了一个强大而灵活的解决方案，克服了现有方法的局限性，并在各种设置下表现出优越的性能。

Abstract: Controllable face generation poses critical challenges in generative modeling
due to the intricate balance required between semantic controllability and
photorealism. While existing approaches struggle with disentangling semantic
controls from generation pipelines, we revisit the architectural potential of
Diffusion Transformers (DiTs) through the lens of expert specialization. This
paper introduces Face-MoGLE, a novel framework featuring: (1)
Semantic-decoupled latent modeling through mask-conditioned space
factorization, enabling precise attribute manipulation; (2) A mixture of global
and local experts that captures holistic structure and region-level semantics
for fine-grained controllability; (3) A dynamic gating network producing
time-dependent coefficients that evolve with diffusion steps and spatial
locations. Face-MoGLE provides a powerful and flexible solution for
high-quality, controllable face generation, with strong potential in generative
modeling and security applications. Extensive experiments demonstrate its
effectiveness in multimodal and monomodal face generation settings and its
robust zero-shot generalization capability. Project page is available at
https://github.com/XavierJiezou/Face-MoGLE.

</details>


### [40] [SemaMIL: Semantic Reordering with Retrieval-Guided State Space Modeling for Whole Slide Image Classification](https://arxiv.org/abs/2509.00442)
*Lubin Gan,Xiaoman Wu,Jing Zhang,Zhifeng Wang,Linhao Qu,Siying Wu,Xiaoyan Sun*

Main category: cs.CV

TL;DR: SemaMIL是一种结合语义重排（SR）和语义引导检索状态空间模块（SRSM）的计算病理学方法，用于处理全切片图像（WSIs）。它通过对语义相似的斑块进行聚类和排序，并选择代表性查询来调整状态空间参数，以改进全局模型。实验证明，SemaMIL在四个WSIs亚型数据集上取得了最先进的准确率，同时具有更少的计算量和参数量。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中，虽然基于注意力机制的多示例学习（MIL）能识别关键斑块，但会忽略上下文关系；Transformer模型能建模交互但计算成本高且易过拟合；状态空间模型（SSMs）计算成本低，但打乱斑块顺序会破坏组织学含义且降低可解释性。因此，需要一种能保持上下文关系、计算成本低且可解释性强的MIL方法。

Method: SemaMIL方法包含两个主要部分：1. 语义重排（SR）：一种自适应方法，通过可逆的置换来聚类和排序语义上相似的斑块，以保持其上下文关系。2. 语义引导检索状态空间模块（SRSM）：选择代表性查询子集来调整状态空间参数，以实现更好的全局建模。

Result: 在四个WSIs亚型数据集上的评估结果表明，SemaMIL相比于强有力的基线方法，在准确率上达到了最先进水平，并且在计算量（FLOPs）和参数量方面更少。

Conclusion: SemaMIL通过整合语义重排和语义引导检索状态空间模块，有效解决了计算病理学中MIL方法的局限性，实现了高性能和高效率，是处理WSIs的有效方法。

Abstract: Multiple instance learning (MIL) has become the leading approach for
extracting discriminative features from whole slide images (WSIs) in
computational pathology. Attention-based MIL methods can identify key patches
but tend to overlook contextual relationships. Transformer models are able to
model interactions but require quadratic computational cost and are prone to
overfitting. State space models (SSMs) offer linear complexity, yet shuffling
patch order disrupts histological meaning and reduces interpretability. In this
work, we introduce SemaMIL, which integrates Semantic Reordering (SR), an
adaptive method that clusters and arranges semantically similar patches in
sequence through a reversible permutation, with a Semantic-guided Retrieval
State Space Module (SRSM) that chooses a representative subset of queries to
adjust state space parameters for improved global modeling. Evaluation on four
WSI subtype datasets shows that, compared to strong baselines, SemaMIL achieves
state-of-the-art accuracy with fewer FLOPs and parameters.

</details>


### [41] [Stage-wise Adaptive Label Distribution for Facial Age Estimation](https://arxiv.org/abs/2509.00450)
*Bo Wu,Zhiqi Ai,Jun Jiang,Congcong Zhu,Shugong Xu*

Main category: cs.CV

TL;DR: 标签歧义在年龄估计任务中是一个重大挑战。本研究提出了一种分阶段自适应标签分布学习（SA-LDL）算法，该算法通过分阶段自适应方差建模和加权损失函数来解决标签歧义问题，实现了更准确、更鲁棒的年龄估计。在MORPH-II和FG-NET数据集上，SA-LDL的平均绝对误差（MAE）分别为1.74和2.15。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的年龄估计方法通过学习标签分布来解决标签歧义问题，但忽略了不同年龄阶段的歧义程度差异。本研究的动机是解决这一问题，并提出一种能够捕捉标签歧义阶段性模式的方法。

Method: 本研究提出了一种分阶段自适应标签分布学习（SA-LDL）算法。该算法通过分析嵌入相似性来揭示标签歧义的阶段性模式，并利用分阶段自适应方差建模和加权损失函数来有效捕捉标签歧义的复杂性和结构性。

Result: SA-LDL在MORPH-II和FG-NET数据集上取得了具有竞争力的性能，平均绝对误差（MAE）分别为1.74和2.15。

Conclusion: SA-LDL算法通过有效处理标签歧义问题，在年龄估计任务中展现出准确性和鲁棒性，并在两个公开数据集上取得了优异的结果。

Abstract: Label ambiguity poses a significant challenge in age estimation tasks. Most
existing methods address this issue by modeling correlations between adjacent
age groups through label distribution learning. However, they often overlook
the varying degrees of ambiguity present across different age stages. In this
paper, we propose a Stage-wise Adaptive Label Distribution Learning (SA-LDL)
algorithm, which leverages the observation -- revealed through our analysis of
embedding similarities between an anchor and all other ages -- that label
ambiguity exhibits clear stage-wise patterns. By jointly employing stage-wise
adaptive variance modeling and weighted loss function, SA-LDL effectively
captures the complex and structured nature of label ambiguity, leading to more
accurate and robust age estimation. Extensive experiments demonstrate that
SA-LDL achieves competitive performance, with MAE of 1.74 and 2.15 on the
MORPH-II and FG-NET datasets.

</details>


### [42] [Encoder-Only Image Registration](https://arxiv.org/abs/2509.00451)
*Xiang Chen,Renjiu Hu,Jinwei Zhang,Yuxi Zhang,Xinyao Yue,Min Liu,Yaonan Wang,Hang Zhang*

Main category: cs.CV

TL;DR: ConvNets improve deformable image registration by linearizing local intensities and harmonizing global contrast variations. The proposed EOIR framework uses a shallow ConvNet for feature extraction and a Laplacian feature pyramid for progressive deformation composition, achieving a better accuracy-efficiency trade-off.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of reducing computational complexity and handling large deformations in learning-based deformable image registration.

Method: Propose the Encoder-Only Image Registration (EOIR) framework, which separates feature learning from flow estimation. EOIR uses a 3-layer ConvNet for feature extraction and a set of 3-layer flow estimators to construct a Laplacian feature pyramid, progressively composing diffeomorphic deformations under a large-deformation model.

Result: EOIR demonstrates effectiveness on five datasets across different modalities and anatomical regions, achieving superior accuracy-efficiency and accuracy-smoothness trade-offs. With comparable accuracy, EOIR provides better efficiency and smoothness, and vice versa.

Conclusion: EOIR offers a better accuracy-efficiency trade-off for deformable image registration by leveraging the roles of ConvNets in local intensity linearization and global contrast harmonization.

Abstract: Learning-based techniques have significantly improved the accuracy and speed
of deformable image registration. However, challenges such as reducing
computational complexity and handling large deformations persist. To address
these challenges, we analyze how convolutional neural networks (ConvNets)
influence registration performance using the Horn-Schunck optical flow
equation. Supported by prior studies and our empirical experiments, we observe
that ConvNets play two key roles in registration: linearizing local intensities
and harmonizing global contrast variations. Based on these insights, we propose
the Encoder-Only Image Registration (EOIR) framework, designed to achieve a
better accuracy-efficiency trade-off. EOIR separates feature learning from flow
estimation, employing only a 3-layer ConvNet for feature extraction and a set
of 3-layer flow estimators to construct a Laplacian feature pyramid,
progressively composing diffeomorphic deformations under a large-deformation
model. Results on five datasets across different modalities and anatomical
regions demonstrate EOIR's effectiveness, achieving superior
accuracy-efficiency and accuracy-smoothness trade-offs. With comparable
accuracy, EOIR provides better efficiency and smoothness, and vice versa. The
source code of EOIR will be publicly available on
https://github.com/XiangChen1994/EOIR.

</details>


### [43] [Exploring Decision-Making Capabilities of LLM Agents: An Experimental Study on Jump-Jump Game](https://arxiv.org/abs/2509.00483)
*Juwu Li*

Main category: cs.CV

TL;DR: Jump-Jump游戏是一个简单的休闲游戏，可用于研究LLM的决策能力。游戏需要玩家根据当前位置和目标平台距离精确控制跳跃力，涉及空间推理、物理建模和战略规划。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在Jump-Jump游戏中的决策能力，该游戏涉及空间推理、物理建模和战略规划。

Method: 分析Jump-Jump游戏的基本玩法机制。

Result: 玩家角色（红圆圈）必须以适当的力跳过平台以最大化得分。

Conclusion: Jump-Jump游戏为研究LLM的决策能力提供了一个理想的测试环境。

Abstract: The Jump-Jump game, as a simple yet challenging casual game, provides an
ideal testing environment for studying LLM decision-making capabilities. The
game requires players to precisely control jumping force based on current
position and target platform distance, involving multiple cognitive aspects
including spatial reasoning, physical modeling, and strategic planning. It
illustrates the basic gameplay mechanics of the Jump-Jump game, where the
player character (red circle) must jump across platforms with appropriate force
to maximize score.

</details>


### [44] [VideoRewardBench: Comprehensive Evaluation of Multimodal Reward Models for Video Understanding](https://arxiv.org/abs/2509.00484)
*Zhihong Zhang,Xiaojian Huang,Jin Xu,Zhuodong Luo,Xinzhi Wang,Jiansheng Wei,Xuejin Chen*

Main category: cs.CV

TL;DR: VideoRewardBench是首个全面的视频领域多模态奖励模型（MRM）评估基准，包含4个核心视频理解方面（感知、知识、推理、安全），通过AI辅助数据管道创建了包含1563个标注样本的数据集，并对28个MRM进行了评估。结果显示，即使是GPT-4o也仅达到57.0%的准确率，Qwen2.5-VL-72B达到53.3%。研究还发现，RL训练不一定带来更强的跨模态泛化能力，除判别式MRM外，其他类型MRM可从推理时扩展中受益，且输入视频帧数对不同类型MRM的影响不同。该基准旨在推动视频领域MRM的评估和发展。


<details>
  <summary>Details</summary>
Motivation: 现有视频领域MRM评估基准在问题数量、多样性、评估维度和模型类型覆盖方面存在不足，需要一个更全面的基准来推动MRM的评估和发展。

Method: 创建了一个名为VideoRewardBench的综合性基准，涵盖视频理解的四个核心方面（感知、知识、推理、安全）。通过AI辅助数据管道，构建了一个包含1563个样本（1482个视频，1559个问题）的偏好数据集。对28个不同类别（生成式、判别式、半标量）的MRM进行了评估。

Result: GPT-4o在VideoRewardBench上的总体准确率为57.0%，Qwen2.5-VL-72B为53.3%。研究发现，RL训练的MRM不一定比未训练的MRM具有更强的跨模态泛化能力；除判别式MRM外，其他类型的MRM可从推理时扩展中受益；输入视频的帧数对不同类型的MRM有不同的影响。

Conclusion: VideoRewardBench是一个具有挑战性且有价值的基准，能够促进视频领域MRM的评估和开发。研究结果揭示了MRM在泛化能力、推理时扩展和输入帧数敏感性方面的关键见解。

Abstract: Multimodal reward models (MRMs) play a crucial role in the training,
inference, and evaluation of Large Vision Language Models (LVLMs) by assessing
response quality. However, existing benchmarks for evaluating MRMs in the video
domain suffer from a limited number and diversity of questions, a lack of
comprehensive evaluation dimensions, and inadequate evaluation of diverse types
of MRMs. To address these gaps, we introduce VideoRewardBench, the first
comprehensive benchmark covering four core aspects of video understanding:
perception, knowledge, reasoning, and safety. Through our AI-assisted data
pipeline, we curate a high-quality preference dataset of 1,563 annotated
samples, including 1,482 unique videos and 1,559 distinct questions--15 times
the number found in the most question-rich prior benchmark. Each sample is a
triplet consisting of a video-text prompt, a chosen response, and a rejected
response. We also conduct a comprehensive evaluation across 28 multimodal
reward models spanning three categories: generative, discriminative, and
semi-scalar. Results show that even the top-performing model GPT-4o achieves
only 57.0% overall accuracy, and the state-of-the-art open-source model
Qwen2.5-VL-72B reaches merely 53.3%. Our analysis further reveals three key
insights: (i) MRMs trained with reinforcement learning (RL) do not necessarily
exhibit stronger cross-modal generalization than those trained without RL; (ii)
except for discriminative MRMs, other types of MRMs across varying model
capacities can benefit from inference-time scaling; and (iii) variations in
input video frame count have different effects on different types of MRMs. We
believe VideoRewardBench offers a challenging and valuable benchmark for
advancing the evaluation and development of MRMs in the video domain.

</details>


### [45] [Multi-Focused Video Group Activities Hashing](https://arxiv.org/abs/2509.00490)
*Zhongmiao Qi,Yan Jiang,Bolin Zhang,Lijun Guo,Chong Wang,Qiangbo Qian*

Main category: cs.CV

TL;DR: 提出STVH和M-STVH技术以解决视频检索中对整个视频而非活动粒度的关注问题。STVH能同时模拟个体物体动态和群体交互，捕捉时空演化。M-STVH作为增强版，通过多焦点表示学习进行分层特征集成，可同时关注活动语义特征和物体视觉特征。实验证明两者效果优异。


<details>
  <summary>Details</summary>
Motivation: 解决视频检索中过度关注整个视频而非活动粒度的问题，以及在不同场景下对活动特征或物体视觉特征的需求。

Method: STVH：提出一种时空交错视频哈希技术，通过统一框架模拟个体物体动态和群体交互，捕捉时空演化。M-STVH：提出多焦点时空视频哈希技术，通过分层特征集成和多焦点表示学习，同时关注活动语义特征和物体视觉特征。

Result: STVH和M-STVH在公开数据集上的比较实验中均取得了优异的结果。

Conclusion: STVH和M-STVH技术能够有效地解决视频检索中的活动粒度识别问题，并满足不同场景下对活动特征或物体视觉特征的需求。

Abstract: With the explosive growth of video data in various complex scenarios, quickly
retrieving group activities has become an urgent problem. However, many tasks
can only retrieve videos focusing on an entire video, not the activity
granularity. To solve this problem, we propose a new STVH (spatiotemporal
interleaved video hashing) technique for the first time. Through a unified
framework, the STVH simultaneously models individual object dynamics and group
interactions, capturing the spatiotemporal evolution on both group visual
features and positional features. Moreover, in real-life video retrieval
scenarios, it may sometimes require activity features, while at other times, it
may require visual features of objects. We then further propose a novel M-STVH
(multi-focused spatiotemporal video hashing) as an enhanced version to handle
this difficult task. The advanced method incorporates hierarchical feature
integration through multi-focused representation learning, allowing the model
to jointly focus on activity semantics features and object visual features. We
conducted comparative experiments on publicly available datasets, and both STVH
and M-STVH can achieve excellent results.

</details>


### [46] [TRUST: Token-dRiven Ultrasound Style Transfer for Cross-Device Adaptation](https://arxiv.org/abs/2509.00508)
*Nhat-Tuong Do-Tran,Ngoc-Hoang-Lam Le,Ian Chiu,Po-Tsun Paul Kuo,Ching-Chun Huang*

Main category: cs.CV

TL;DR: TRUST是一个图像翻译框架，用于解决超声图像的风格差异问题，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 超声图像的设备差异导致风格不一致，影响下游任务表现。现有的非成对图像到图像翻译方法未能有效过滤风格特征，导致翻译后的图像与下游任务需求不匹配。

Method: 提出TRUST框架，采用token驱动的双流结构，保持源内容并迁移目标域的共同风格，确保内容和风格分离。通过Token-dRiven（TR）模块，从数据和模型两个角度选择目标token，并引入行为镜像损失。此外，在源编码器中注入辅助提示，使内容表示与下游行为匹配。

Result: 在超声数据集上的实验表明，TRUST在视觉质量和下游任务性能上均优于现有的UI2I方法。

Conclusion: TRUST框架有效解决了超声图像风格差异问题，提升了图像翻译在下游任务中的应用效果。

Abstract: Ultrasound images acquired from different devices exhibit diverse styles,
resulting in decreased performance of downstream tasks. To mitigate the style
gap, unpaired image-to-image (UI2I) translation methods aim to transfer images
from a source domain, corresponding to new device acquisitions, to a target
domain where a frozen task model has been trained for downstream applications.
However, existing UI2I methods have not explicitly considered filtering the
most relevant style features, which may result in translated images misaligned
with the needs of downstream tasks. In this work, we propose TRUST, a
token-driven dual-stream framework that preserves source content while
transferring the common style of the target domain, ensuring that content and
style remain unblended. Given multiple styles in the target domain, we
introduce a Token-dRiven (TR) module that operates from two perspectives: (1) a
data view--selecting "suitable" target tokens corresponding to each source
token, and (2) a model view--identifying ``optimal" target tokens for the
downstream model, guided by a behavior mirror loss. Additionally, we inject
auxiliary prompts into the source encoder to match content representation with
downstream behavior. Experimental results on ultrasound datasets demonstrate
that TRUST outperforms existing UI2I methods in both visual quality and
downstream task performance.

</details>


### [47] [Make me an Expert: Distilling from Generalist Black-Box Models into Specialized Models for Semantic Segmentation](https://arxiv.org/abs/2509.00509)
*Yasser Benigmim,Subhankar Roy,Khalid Oublal,Imad Eddine Marouf,Slim Essid,Vicky Kalogeiton,Stéphane Lathuilière*

Main category: cs.CV

TL;DR: 该研究提出了一种名为“黑盒蒸馏”（B2D）的新方法，用于在无法访问模型权重、训练数据或 logits 的情况下，仅使用 one-hot 预测来适应本地模型。该方法通过“注意力引导缩放器”（ATGC）利用 DINOv2 注意力图动态选择最佳尺度进行推理，解决了“分辨率诅咒”问题，并在多个数据集上取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 在 AIaaS 普及的背景下，如何有效利用无法访问其内部细节（如权重、训练数据或 logits）的黑盒模型来训练本地模型是一个关键挑战，现有的域适应范式在此受限。

Method: 提出“黑盒蒸馏”（B2D）设置，并开发了一种名为“注意力引导缩放器”（ATGC）的方法。ATGC 利用 DINOv2 注意力图，通过计算熵来评估不同尺度下的注意力图信息量，从而动态选择最优尺度用于黑盒模型的推理和伪标签生成，以实现有效的蒸馏。

Result: 实验证明，在仅使用 one-hot API 预测的黑盒监督下，ATGC 在多个数据集上实现了显著的改进，有效解决了“分辨率诅咒”问题。

Conclusion: ATGC 是一种有效的方法，可以在黑盒设置下（仅提供 one-hot 预测）适应本地模型，通过利用 DINOv2 注意力图和动态尺度选择来克服“分辨率诅咒”，从而在实际应用中实现有效的模型蒸馏。

Abstract: The rise of Artificial Intelligence as a Service (AIaaS) democratizes access
to pre-trained models via Application Programming Interfaces (APIs), but also
raises a fundamental question: how can local models be effectively trained
using black-box models that do not expose their weights, training data, or
logits, a constraint in which current domain adaptation paradigms are
impractical ? To address this challenge, we introduce the Black-Box
Distillation (B2D) setting, which enables local model adaptation under
realistic constraints: (1) the API model is open-vocabulary and trained on
large-scale general-purpose data, and (2) access is limited to one-hot
predictions only. We identify that open-vocabulary models exhibit significant
sensitivity to input resolution, with different object classes being segmented
optimally at different scales, a limitation termed the "curse of resolution".
Our method, ATtention-Guided sCaler (ATGC), addresses this challenge by
leveraging DINOv2 attention maps to dynamically select optimal scales for
black-box model inference. ATGC scores the attention maps with entropy to
identify informative scales for pseudo-labelling, enabling effective
distillation. Experiments demonstrate substantial improvements under black-box
supervision across multiple datasets while requiring only one-hot API
predictions. Our code is available at https://github.com/yasserben/ATGC.

</details>


### [48] [Learning Yourself: Class-Incremental Semantic Segmentation with Language-Inspired Bootstrapped Disentanglement](https://arxiv.org/abs/2509.00527)
*Ruitao Wu,Yifan Zhao,Jia Li*

Main category: cs.CV

TL;DR: 该论文提出了一种名为LBD的语言启发式自举解耦框架，以解决类别增量语义分割中的灾难性语义纠缠问题，通过语言引导的原型解耦和背景增量解耦来分离新旧类别和背景语义，并在Pascal VOC和ADE20k数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决类别增量语义分割（CISS）中新旧类别知识的持续学习和保留问题，并识别出“灾难性语义纠缠”这一核心挑战，包括由语义错位引起的原型-特征纠缠和由数据动态演变引起的背景-增量纠缠。

Method: 提出LBD框架，利用预训练视觉-语言模型（如CLIP）的先验语义知识，通过语言引导的原型解耦（将文本特征视为拓扑模板）和多原型掩码池化背景增量解耦来分离特征。结合软提示调优和编码器适应性修改，以适应CLIP在密集和稀疏任务之间的能力差距。

Result: 在Pascal VOC和ADE20k数据集上，尤其是在多步场景中，实现了最先进的性能。

Conclusion: LBD框架通过语言引导的解耦方法有效解决了类别增量语义分割中的灾难性语义纠缠问题，并在多个基准测试中取得了优异成果，证明了其在处理连续学习和语义对齐方面的潜力。

Abstract: Class-Incremental Semantic Segmentation (CISS) requires continuous learning
of newly introduced classes while retaining knowledge of past classes. By
abstracting mainstream methods into two stages (visual feature extraction and
prototype-feature matching), we identify a more fundamental challenge termed
catastrophic semantic entanglement. This phenomenon involves Prototype-Feature
Entanglement caused by semantic misalignment during the incremental process,
and Background-Increment Entanglement due to dynamic data evolution. Existing
techniques, which rely on visual feature learning without sufficient cues to
distinguish targets, introduce significant noise and errors. To address these
issues, we introduce a Language-inspired Bootstrapped Disentanglement framework
(LBD). We leverage the prior class semantics of pre-trained visual-language
models (e.g., CLIP) to guide the model in autonomously disentangling features
through Language-guided Prototypical Disentanglement and Manifold Mutual
Background Disentanglement. The former guides the disentangling of new
prototypes by treating hand-crafted text features as topological templates,
while the latter employs multiple learnable prototypes and mask-pooling-based
supervision for background-incremental class disentanglement. By incorporating
soft prompt tuning and encoder adaptation modifications, we further bridge the
capability gap of CLIP between dense and sparse tasks, achieving
state-of-the-art performance on both Pascal VOC and ADE20k, particularly in
multi-step scenarios.

</details>


### [49] [A Modality-agnostic Multi-task Foundation Model for Human Brain Imaging](https://arxiv.org/abs/2509.00549)
*Peirong Liu,Oula Puonti,Xiaoling Hu,Karthik Gopinath,Annabel Sorby-Adams,Daniel C. Alexander,W. Taylor Kimberly,Juan E. Iglesias*

Main category: cs.CV

TL;DR: BrainFM是一个多任务视觉基础模型，适用于人脑成像，能够处理不同成像模态（CT、MRI）和任务（图像合成、分割、距离估计、偏场估计、配准），并在多个数据集上表现出鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法在校准的医学成像（如CT）方面取得了显著进展，但在非校准成像（如MRI）中泛化能力较差，因为MRI的性能高度依赖于对比度、分辨率和方向的差异。这限制了其在多样化的临床应用中的广泛适用性。

Method: 提出了一种名为BrainFM的多任务视觉基础模型，该模型具有模态无关性。通过采用“轻度到重度”的受试内生成和“真实-合成”混合训练策略，BrainFM能够适应各种图像外观（例如，模态、对比度、变形、分辨率、伪影），可以直接应用于五种基本的大脑成像任务：CT和T1w/T2w/FLAIR MRI的图像合成、解剖分割、头皮到皮层距离、偏场估计和配准。

Result: 在十一个公开数据集上评估了BrainFM的有效性，证明了其在所有任务和输入模态上的鲁棒性和有效性。

Conclusion: BrainFM通过其新颖的训练策略，实现了在不同成像模态和任务上的泛化能力，为医学成像领域提供了一个强大的基础模型。

Abstract: Recent learning-based approaches have made astonishing advances in calibrated
medical imaging like computerized tomography (CT), yet they struggle to
generalize in uncalibrated modalities -- notably magnetic resonance (MR)
imaging, where performance is highly sensitive to the differences in MR
contrast, resolution, and orientation. This prevents broad applicability to
diverse real-world clinical protocols. Here we introduce BrainFM, a
modality-agnostic, multi-task vision foundation model for human brain imaging.
With the proposed "mild-to-severe" intra-subject generation and "real-synth"
mix-up training strategy, BrainFM is resilient to the appearance of acquired
images (e.g., modality, contrast, deformation, resolution, artifacts), and can
be directly applied to five fundamental brain imaging tasks, including image
synthesis for CT and T1w/T2w/FLAIR MRI, anatomy segmentation, scalp-to-cortical
distance, bias field estimation, and registration. We evaluate the efficacy of
BrainFM on eleven public datasets, and demonstrate its robustness and
effectiveness across all tasks and input modalities. Code is available at
https://github.com/jhuldr/BrainFM.

</details>


### [50] [C-DiffDet+: Fusing Global Scene Context with Generative Denoising for High-Fidelity Object Detection](https://arxiv.org/abs/2509.00578)
*Abdellah Zakaria Sellam,Ilyes Benaissa,Salah Eddine Bekhouche,Abdenour Hadid,Vito Renó,Cosimo Distante*

Main category: cs.CV

TL;DR: DiffusionDet在细粒度目标检测中存在局限性，提出了一种名为Context-Aware Fusion (CAF)的新方法，通过融合全局场景上下文和局部特征来提升检测性能，并在CarDD基准测试中取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有的DiffusionDet模型在处理如车辆损伤评估等复杂视觉领域时，由于仅依赖局部特征，难以有效处理情境依赖性问题，性能受到限制。

Method: 提出了一种名为Context-Aware Fusion (CAF)的框架，该框架利用交叉注意力机制将全局场景上下文与局部候选区域特征相结合。通过一个专门的编码器来生成全局上下文，使每个目标候选区域都能关注到全局场景信息。

Result: CAF框架在CarDD基准测试中显著优于现有技术，并在细粒度、上下文感知目标检测领域树立了新的性能标杆。

Conclusion: CAF框架通过融合全局上下文信息有效解决了DiffusionDet在细粒度目标检测中的局限性，显著提升了检测性能，尤其是在需要理解场景整体信息的复杂视觉域中。

Abstract: Fine-grained object detection in challenging visual domains, such as vehicle
damage assessment, presents a formidable challenge even for human experts to
resolve reliably. While DiffusionDet has advanced the state-of-the-art through
conditional denoising diffusion, its performance remains limited by local
feature conditioning in context-dependent scenarios. We address this
fundamental limitation by introducing Context-Aware Fusion (CAF), which
leverages cross-attention mechanisms to integrate global scene context with
local proposal features directly. The global context is generated using a
separate dedicated encoder that captures comprehensive environmental
information, enabling each object proposal to attend to scene-level
understanding. Our framework significantly enhances the generative detection
paradigm by enabling each object proposal to attend to comprehensive
environmental information. Experimental results demonstrate an improvement over
state-of-the-art models on the CarDD benchmark, establishing new performance
benchmarks for context-aware object detection in fine-grained domains

</details>


### [51] [DGL-RSIS: Decoupling Global Spatial Context and Local Class Semantics for Training-Free Remote Sensing Image Segmentation](https://arxiv.org/abs/2509.00598)
*Boyi Li,Ce Zhang,Richard M. Timmerman,Wenxuan Bao*

Main category: cs.CV

TL;DR: 该研究提出了一种名为DGL-RSIS的训练无关框架，用于解决视觉语言模型（VLM）在遥感（RS）图像分割中的应用挑战。该框架通过解耦视觉和文本输入，并在局部和全局层面进行视觉-语言对齐，以支持开放词汇的语义分割（OVSS）和指代表达分割（RES）。


<details>
  <summary>Details</summary>
Motivation: 由于遥感数据集类别多样性有限以及自然图像和遥感图像之间的域差异，将VLM从自然图像领域迁移到遥感分割领域仍然具有挑战性。

Method: 研究提出了一种名为DGL-RSIS的训练无关框架。该框架首先引入一个全局-局部解耦（GLD）模块，将文本输入划分为局部类别名词和全局修饰词，并将图像输入划分为一系列类别无关的掩码提案。然后，通过上下文感知裁剪策略提取具有适当边界的图像块，并引入遥感特定知识丰富文本输入，在局部尺度上对齐视觉和文本特征，实现掩码分类和开放词汇语义分割（OVSS）。最后，在全局尺度上，提出了一种跨尺度Grad-CAM模块，利用全局修饰词的上下文信息来优化Grad-CAM图，并通过掩码选择模块将像素级Grad-CAM激活集成到掩码级分割输出中，以实现跨全局和局部维度的精确且可解释的对齐，支持指代表达分割（RES）。

Result: DGL-RSIS框架通过上述方法，实现了在遥感图像分割任务中的开放词汇语义分割（OVSS）和指代表达分割（RES），能够进行精确且可解释的跨维度对齐。

Conclusion: DGL-RSIS框架通过解耦视觉和文本输入，并在局部和全局层面进行对齐，有效解决了VLM在遥感图像分割中的挑战，支持开放词汇语义分割和指代表达分割。

Abstract: The emergence of vision language models (VLMs) has bridged vision and
language, enabling joint multimodal understanding beyond traditional
visual-only deep learning models. However, transferring VLMs from the natural
image domain to remote sensing (RS) segmentation remains challenging due to the
limited category diversity in RS datasets and the domain gap between natural
and RS imagery. Here, we propose a training-free framework, DGL-RSIS, that
decouples visual and textual inputs, performing visual-language alignment at
both the local semantic and global contextual levels through tailored
strategies. Specifically, we first introduce a global-local decoupling (GLD)
module, where text inputs are divided into local class nouns and global
modifiers using natural language processing (NLP) techniques; image inputs are
partitioned into a set of class-agnostic mask proposals via unsupervised mask
proposal networks. Second, visual and textual features are aligned at local
scale, through a novel context-aware cropping strategy for extracting image
patches with proper boundaries and introducing RS-specific knowledge to enrich
the text inputs. By matching the enhanced text features with mask-guided visual
features, we enable the mask classification, supporting open-vocabulary
semantic segmentation (OVSS). Third, at the global scale, we propose a
Cross-Scale Grad-CAM module to refine Grad-CAM maps using contextual
information from global modifiers. A subsequent mask selection module
integrates pixel-level Grad-CAM activations into the mask-level segmentation
output, such that accurate and interpretable alignment can be realized across
global and local dimensions for referring expression segmentation (RES).

</details>


### [52] [Towards Methane Detection Onboard Satellites](https://arxiv.org/abs/2509.00626)
*Maggie Chen,Hala Lambdouar,Luca Marini,Laura Martínez-Ferrer,Chris Bridges,Giacomo Acciarini*

Main category: cs.CV

TL;DR: 该研究提出了一种使用未校正卫星数据进行甲烷检测的新方法（UnorthoDOS），其性能可与使用校正数据的方法相媲美，同时还能简化流程并降低成本。


<details>
  <summary>Details</summary>
Motivation: 甲烷是主要的温室气体，对气候变化有重要影响。在卫星上部署机器学习（ML）可以实现甲烷的快速检测，降低下行成本，并支持更快的响应系统。

Method: 提出了一种名为UnorthoDOS的新方法，该方法直接使用未校正的卫星数据进行训练，无需进行图像校正等预处理步骤。研究人员还训练了使用校正数据集的模型，并将其与传统的匹配滤波器基线（mag1c）进行了比较。

Result: 使用UnorthoDOS训练的ML模型在性能上可与使用校正数据训练的模型相媲美。此外，使用校正数据集训练的模型表现优于匹配滤波器基线（mag1c）。

Conclusion: 研究表明，机器学习模型可以直接在未校正的卫星数据上进行训练，以实现与校正数据相当的甲烷检测性能，这为甲烷的快速、低成本检测提供了新的可能性。

Abstract: Methane is a potent greenhouse gas and a major driver of climate change,
making its timely detection critical for effective mitigation. Machine learning
(ML) deployed onboard satellites can enable rapid detection while reducing
downlink costs, supporting faster response systems. Conventional methane
detection methods often rely on image processing techniques, such as
orthorectification to correct geometric distortions and matched filters to
enhance plume signals. We introduce a novel approach that bypasses these
preprocessing steps by using \textit{unorthorectified} data (UnorthoDOS). We
find that ML models trained on this dataset achieve performance comparable to
those trained on orthorectified data. Moreover, we also train models on an
orthorectified dataset, showing that they can outperform the matched filter
baseline (mag1c). We release model checkpoints and two ML-ready datasets
comprising orthorectified and unorthorectified hyperspectral images from the
Earth Surface Mineral Dust Source Investigation (EMIT) sensor at
https://huggingface.co/datasets/SpaceML/UnorthoDOS , along with code at
https://github.com/spaceml-org/plume-hunter.

</details>


### [53] [MV-SSM: Multi-View State Space Modeling for 3D Human Pose Estimation](https://arxiv.org/abs/2509.00649)
*Aviral Chharia,Wenbo Gou,Haoye Dong*

Main category: cs.CV

TL;DR: MV-SSM是一个新的多视角3D人体姿态估计框架，通过显式建模特征和关键点空间序列，并引入PSS块和GTBS来提高泛化能力，在CMU Panoptic和Campus A1等数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的注意力机制在多视角3D人体姿态估计中存在泛化能力不足的问题，尤其是在处理遮挡和新相机配置时。它们容易过拟合训练数据中的特定相机和场景，导致在新环境下的性能下降。

Method: 提出了一种名为MV-SSM的多视角状态空间模型框架。该框架在特征层面和人体关键点层面两个不同级别上显式建模联合空间序列。引入了项目空间状态（PSS）块，利用状态空间模型学习联合空间排列的通用表示。将Mamba的传统扫描修改为网格令牌引导的双向扫描（GTBS），并将其整合到PSS块中。

Result: +10.8 AP25 (+24%) 在CMU Panoptic的三摄像头设置中，+7.0 AP25 (+13%) 在不同摄像头配置下，以及+15.3 PCP (+38%) 在Campus A1的跨数据集评估中，MV-SSM的性能均优于现有最先进方法。

Conclusion: MV-SSM通过其新颖的结构，特别是项目空间状态（PSS）块和网格令牌引导的双向扫描（GTBS），有效地解决了多视角3D人体姿态估计中的泛化性问题，并在多项挑战性数据集和设置上取得了显著的性能提升。

Abstract: While significant progress has been made in single-view 3D human pose
estimation, multi-view 3D human pose estimation remains challenging,
particularly in terms of generalizing to new camera configurations. Existing
attention-based transformers often struggle to accurately model the spatial
arrangement of keypoints, especially in occluded scenarios. Additionally, they
tend to overfit specific camera arrangements and visual scenes from training
data, resulting in substantial performance drops in new settings. In this
study, we introduce a novel Multi-View State Space Modeling framework, named
MV-SSM, for robustly estimating 3D human keypoints. We explicitly model the
joint spatial sequence at two distinct levels: the feature level from
multi-view images and the person keypoint level. We propose a Projective State
Space (PSS) block to learn a generalized representation of joint spatial
arrangements using state space modeling. Moreover, we modify Mamba's
traditional scanning into an effective Grid Token-guided Bidirectional Scanning
(GTBS), which is integral to the PSS block. Multiple experiments demonstrate
that MV-SSM achieves strong generalization, outperforming state-of-the-art
methods: +10.8 on AP25 (+24%) on the challenging three-camera setting in CMU
Panoptic, +7.0 on AP25 (+13%) on varying camera arrangements, and +15.3 PCP
(+38%) on Campus A1 in cross-dataset evaluations. Project Website:
https://aviralchharia.github.io/MV-SSM

</details>


### [54] [Face4FairShifts: A Large Image Benchmark for Fairness and Robust Learning across Visual Domains](https://arxiv.org/abs/2509.00658)
*Yumeng Lin,Dong Li,Xintao Wu,Minglai Shao,Xujiang Zhao,Zhong Chen,Chen Zhao*

Main category: cs.CV

TL;DR: Face4FairShifts是一个大规模人脸图像基准，用于评估公平性学习和域泛化。它包含10万张图像，跨越四个不同的域，并具有39个注释（14个属性）。实验揭示了现有数据集的局限性，并强调了对更有效的公平感知域适应技术的需求。


<details>
  <summary>Details</summary>
Motivation: 在模型公平性和鲁棒性，特别是在域偏移下，仍然是一个挑战。

Method: Face4FairShifts是一个大规模人脸图像基准，用于系统地评估公平性感知学习和域泛化。该数据集包含跨越四个视觉上不同域的100,000张图像，以及14个属性内的39个注释，涵盖人口统计和面部特征。

Result: 通过广泛的实验，分析了模型在分布偏移下的性能，并识别了显著的差距。

Conclusion: 研究结果强调了现有相关数据集的局限性，以及对更有效的公平感知域适应技术的需求。Face4FairShifts为推进公平可靠的AI系统提供了一个全面的测试平台。

Abstract: Ensuring fairness and robustness in machine learning models remains a
challenge, particularly under domain shifts. We present Face4FairShifts, a
large-scale facial image benchmark designed to systematically evaluate
fairness-aware learning and domain generalization. The dataset includes 100,000
images across four visually distinct domains with 39 annotations within 14
attributes covering demographic and facial features. Through extensive
experiments, we analyze model performance under distribution shifts and
identify significant gaps. Our findings emphasize the limitations of existing
related datasets and the need for more effective fairness-aware domain
adaptation techniques. Face4FairShifts provides a comprehensive testbed for
advancing equitable and reliable AI systems. The dataset is available online at
https://meviuslab.github.io/Face4FairShifts/.

</details>


### [55] [Automatic Identification and Description of Jewelry Through Computer Vision and Neural Networks for Translators and Interpreters](https://arxiv.org/abs/2509.00661)
*Jose Manuel Alcalde-Llergo,Aurora Ruiz-Mezcua,Rocio Avila-Ramirez,Andrea Zingoni,Juri Taborri,Enrique Yeguas-Bolivar*

Main category: cs.CV

TL;DR: 本文提出了一种利用神经网络自动识别和描述珠宝的新方法，旨在帮助翻译和口译员快速获取准确的珠宝信息。


<details>
  <summary>Details</summary>
Motivation: 当前珠宝识别主要依赖行业专家，而翻译和口译员需要全面了解珠宝信息，因此需要一种自动化的方法来提供支持。

Method: 该方法利用计算机视觉和图像字幕技术，通过三个不同层级的描述来识别和描述珠宝。研究了不同的图像字幕模型，特别是编码器-解码器模型，以生成不同详细程度的描述。

Result: 最终模型在珠宝识别和描述方面的准确率超过90%。

Conclusion: 所提出的方法能够有效地识别和描述各种珠宝，为翻译和口译员提供了有力的支持。

Abstract: Identifying jewelry pieces presents a significant challenge due to the wide
range of styles and designs. Currently, precise descriptions are typically
limited to industry experts. However, translators and interpreters often
require a comprehensive understanding of these items. In this study, we
introduce an innovative approach to automatically identify and describe jewelry
using neural networks. This method enables translators and interpreters to
quickly access accurate information, aiding in resolving queries and gaining
essential knowledge about jewelry. Our model operates at three distinct levels
of description, employing computer vision techniques and image captioning to
emulate expert analysis of accessories. The key innovation involves generating
natural language descriptions of jewelry across three hierarchical levels,
capturing nuanced details of each piece. Different image captioning
architectures are utilized to detect jewels in images and generate descriptions
with varying levels of detail. To demonstrate the effectiveness of our approach
in recognizing diverse types of jewelry, we assembled a comprehensive database
of accessory images. The evaluation process involved comparing various image
captioning architectures, focusing particularly on the encoder decoder model,
crucial for generating descriptive captions. After thorough evaluation, our
final model achieved a captioning accuracy exceeding 90 per cent.

</details>


### [56] [Fusion to Enhance: Fusion Visual Encoder to Enhance Multimodal Language Model](https://arxiv.org/abs/2509.00664)
*Yifei She,Huangxuan Wu*

Main category: cs.CV

TL;DR: MLLMs在处理需要精确细节感知的基本视觉任务时存在不足，因为它们通常依赖单一的视觉编码器。为了解决这个问题，我们提出了FtZ框架，该框架通过结合一个语义强大的锚点编码器和一个丰富的感知增强编码器，并使用轻量级多头交叉注意力机制，显著提高了模型在精细视觉理解任务上的表现，证明了组合异构专家编码器是克服视觉感知瓶颈的有效途径。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态语言模型（MLLMs）虽然擅长复杂的语义理解，但在需要精确细节感知的基本视觉任务上表现不佳，这是由于它们依赖单一的视觉编码器，牺牲了捕捉细粒度视觉信息的能力。

Method: 提出了一种名为FtZ的新型视觉塔框架，通过轻量级多头交叉注意力机制，将一个语义强大的锚点编码器与一个感知丰富的增强编码器进行组合，以克服单一编码器设计的局限性。

Result: 在TextVQA, POPE, MMMU, MME和MM-Vet等多个需要精细视觉理解的基准测试中，FtZ模型显著优于仅使用单一编码器或现有特征融合方法的基线模型。

Conclusion: 通过组合异构的专家编码器是克服当前MLLs视觉感知瓶颈的高效且有效的方法，为构建具有更强感知能力的新一代AI系统提供了新的设计范式。

Abstract: Multimodal Large Language Models (MLLMs) have made significant progress in
bridging visual perception with high-level textual reasoning. However, they
face a fundamental contradiction: while excelling at complex semantic
understanding, these models often fail at basic visual tasks that require
precise detail perception. This deficiency primarily stems from the prevalent
architectural reliance on a single vision encoder optimized for high-level
semantic alignment, which inherently sacrifices the ability to capture
fine-grained visual information. To address this issue, we introduce Fusion to
Enhance (FtZ), a novel vision tower framework. FtZ moves beyond the
single-encoder design by innovatively composing a semantically powerful anchor
encoder with a perception-rich augmenting encoder via a lightweight Multi-Head
Cross-Attention mechanism. Experimental results demonstrate that on several
challenging benchmarks demanding fine-grained visual understanding, such as
TextVQA, POPE, MMMU, MME and MM-Vet, our FtZ model significantly outperforms
baselines that use only a single encoder or existing feature fusion methods.
This work proves that composing heterogeneous expert encoders is an efficient
and effective path to overcoming the visual perception bottleneck in current
MLLMs, offering a new design paradigm for building next-generation AI systems
with stronger perceptual capabilities.

</details>


### [57] [ER-LoRA: Effective-Rank Guided Adaptation for Weather-Generalized Depth Estimation](https://arxiv.org/abs/2509.00665)
*Weilong Yan,Xin Zhang,Robby T. Tan*

Main category: cs.CV

TL;DR: 本论文提出一种参数高效微调（PEFT）策略，称为选择-调整-维持（STM），用于在恶劣天气条件下进行单目深度估计。该方法仅使用少量正常天气数据，通过结构化分解预训练的视觉基础模型（VFMs）权重，并结合熵秩和稳定秩，实现有效的任务适应和预训练知识的保留，优于现有方法和全微调。


<details>
  <summary>Details</summary>
Motivation: 现有单目深度估计方法在恶劣天气条件下（如下雨、雾、雪和夜间）面临巨大挑战，主要是因为缺乏可靠的真实标签数据以及在无标签真实数据上学习的困难。现有方法依赖于带有伪标签的合成恶劣天气数据，但这会导致域迁移问题，或者使用自监督学习，然而这在恶劣天气场景下会违反光度假设。

Method: 本文提出通过参数高效微调（PEFT）视觉基础模型（VFMs）来实现跨天气泛化的深度估计，仅使用少量高可见度（正常）数据。具体来说，提出了一种选择-调整-维持（STM）策略，该策略基于两种秩（熵秩和稳定秩）对VFMs的预训练权重进行结构化分解。在调整阶段，基于熵秩和全调整权重自适应地选择合适的秩数量以及面向任务的奇异方向进行初始化；在维持阶段，基于稳定秩强制执行主方向正则化，以保证灵活的任务适应并保留预训练VFM的强大泛化能力。

Result: 在四个跨越不同恶劣天气条件的真实世界基准数据集上进行的广泛实验表明，STM不仅优于现有的PEFT方法和全微调，而且其性能超过了使用恶劣合成数据训练的方法，甚至超越了专门的深度基础模型。

Conclusion: 所提出的STM策略能够有效地在恶劣天气条件下进行单目深度估计，仅需少量正常天气数据，并通过选择-调整-维持机制平衡了任务适应性和预训练知识的保留，在各种基准测试中取得了优于现有方法的成果。

Abstract: Monocular depth estimation under adverse weather conditions (e.g.\ rain, fog,
snow, and nighttime) remains highly challenging due to the lack of reliable
ground truth and the difficulty of learning from unlabeled real-world data.
Existing methods often rely on synthetic adverse data with pseudo-labels, which
suffer from domain gaps, or employ self-supervised learning, which violates
photometric assumptions in adverse scenarios. In this work, we propose to
achieve weather--generalized depth estimation by Parameter--Efficient
Fine--Tuning (PEFT) of Vision Foundation Models (VFMs), using only a small
amount of high--visibility (normal) data. While PEFT has shown strong
performance in semantic tasks such as segmentation, it remains underexplored
for geometry--centric tasks like depth estimation -- especially in terms of
balancing effective adaptation with the preservation of pretrained knowledge.
To this end, we introduce the Selecting--Tuning--Maintaining (STM) strategy,
which structurally decomposes the pretrained weights of VFMs based on two kinds
of effective ranks (entropy--rank and stable--rank). In the tuning phase, we
adaptively select the proper rank number as well as the task--aware singular
directions for initialization, based on the entropy--rank and full--tuned
weight; while in the maintaining stage, we enforce a principal direction
regularization based on the stable--rank. This design guarantees flexible task
adaptation while preserving the strong generalization capability of the
pretrained VFM. Extensive experiments on four real--world benchmarks across
diverse weather conditions demonstrate that STM not only outperforms existing
PEFT methods and full fine--tuning but also surpasses methods trained with
adverse synthetic data, and even the depth foundation model

</details>


### [58] [DynaMind: Reconstructing Dynamic Visual Scenes from EEG by Aligning Temporal Dynamics and Multimodal Semantics to Guided Diffusion](https://arxiv.org/abs/2509.01177)
*Junxiang Liu,Junming Lin,Jiangtong Li,Jie Li*

Main category: cs.CV

TL;DR: DynaMind框架通过结合区域感知语义映射(RSM)、时间感知动态对齐(TDA)和双指导视频重建(DGVR)模块，实现了从EEG信号到动态视觉场景的高保真视频重建，显著提高了重建视频的准确性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有的EEG脑解码方法在空间分辨率、神经记录与视频动态之间的时间不匹配以及语义信息利用不足方面存在局限性，导致难以同时解析动态连贯性和视觉刺激的复杂语义上下文。因此，需要一种新的方法来克服这些挑战。

Method: 提出了一种名为DynaMind的新型框架，包含三个核心模块：区域感知语义映射(RSM)、时间感知动态对齐(TDA)和双指导视频重建(DGVR)。RSM使用区域感知编码器从EEG信号中提取多模态语义特征，并将其聚合成统一的扩散先验。TDA生成动态潜在序列（蓝图）以强制特征表示与神经记录之间的时间一致性。DGVR在语义扩散先验的指导下，将时间感知的蓝图转换为高保真视频。

Result: 在SEED-DV数据集上，DynaMind将重建视频的准确性（基于视频和帧）分别提高了12.5和10.3个百分点，并在像素级质量上取得了显著的进步，SSIM提高了9.4%，FVMD降低了19.7%，展示了出色的视觉保真度和时间连贯性。

Conclusion: DynaMind框架在从EEG信号重建动态视觉场景方面取得了关键性进展，成功弥合了神经动态和高保真视觉语义之间的差距，设定了新的国家科技水平。

Abstract: Reconstruction dynamic visual scenes from electroencephalography (EEG)
signals remains a primary challenge in brain decoding, limited by the low
spatial resolution of EEG, a temporal mismatch between neural recordings and
video dynamics, and the insufficient use of semantic information within brain
activity. Therefore, existing methods often inadequately resolve both the
dynamic coherence and the complex semantic context of the perceived visual
stimuli. To overcome these limitations, we introduce DynaMind, a novel
framework that reconstructs video by jointly modeling neural dynamics and
semantic features via three core modules: a Regional-aware Semantic Mapper
(RSM), a Temporal-aware Dynamic Aligner (TDA), and a Dual-Guidance Video
Reconstructor (DGVR). The RSM first utilizes a regional-aware encoder to
extract multimodal semantic features from EEG signals across distinct brain
regions, aggregating them into a unified diffusion prior. In the mean time, the
TDA generates a dynamic latent sequence, or blueprint, to enforce temporal
consistency between the feature representations and the original neural
recordings. Together, guided by the semantic diffusion prior, the DGVR
translates the temporal-aware blueprint into a high-fidelity video
reconstruction. On the SEED-DV dataset, DynaMind sets a new state-of-the-art
(SOTA), boosting reconstructed video accuracies (video- and frame-based) by
12.5 and 10.3 percentage points, respectively. It also achieves a leap in
pixel-level quality, showing exceptional visual fidelity and temporal coherence
with a 9.4% SSIM improvement and a 19.7% FVMD reduction. This marks a critical
advancement, bridging the gap between neural dynamics and high-fidelity visual
semantics.

</details>


### [59] [LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model](https://arxiv.org/abs/2509.00676)
*Xiyao Wang,Chunyuan Li,Jianwei Yang,Kai Zhang,Bo Liu,Tianyi Xiong,Furong Huang*

Main category: cs.CV

TL;DR: RL训练可以将鉴赏家模型转变为同时擅长评估和生成的多模态模型。


<details>
  <summary>Details</summary>
Motivation: 挑战了鉴赏家模型通常只被训练来评估输出而不直接用于生成或策略学习的传统。

Method: 通过将偏好标签的鉴赏家数据集重组为可验证的训练信号，并在基础生成模型上进行强化学习，从而创建了一个名为LLaVA-Critic-R1的多模态鉴赏家。

Result: LLaVA-Critic-R1不仅是一个高性能的鉴赏家，也是一个有竞争力的策略模型，在26个视觉推理和理解基准测试中，平均比其基础模型（Qwen-2.5-VL-7B）提高了5.7%。LLaVA-Critic-R1+进一步提高了策略性能，并在MMMU上达到了71.9的SotA性能。在测试时应用自我批评可以将推理任务的性能平均提高13.8%。

Conclusion: 在鉴赏家数据上进行强化学习可以产生一个在评估和生成方面都表现出色的统一模型，为可扩展的、自我改进的多模态系统提供了一条简单的途径。

Abstract: In vision-language modeling, critic models are typically trained to evaluate
outputs -- assigning scalar scores or pairwise preferences -- rather than to
generate responses. This separation from policy models, which produce the
responses, is so entrenched that critics are rarely considered for direct
policy use. In this work, we challenge this convention. We propose to
reorganize preference-labeled critic datasets into verifiable training signals
and perform reinforcement learning directly on a base generative model,
producing LLaVA-Critic-R1, a multimodal critic trained to optimize preference
judgments while retaining full generation ability. Surprisingly,
LLaVA-Critic-R1 emerges not only as a top-performing critic but also as a
competitive policy model -- matching or surpassing specialized reasoning VLMs
trained with in-domain data across 26 visual reasoning and understanding
benchmarks, with an average gain of +5.7% over its base model (Qwen-2.5-VL-7B).
Extending this approach to existing strong reasoning VLMs yields
LLaVA-Critic-R1+, which further advances policy performance without sacrificing
critic quality, achieving a SoTA performance of 71.9 on MMMU at the 7B scale.
Finally, we show that the enhanced critic ability benefits inference: applying
self-critique at test time yields an average +13.8% improvement on five
representative reasoning tasks without additional training. Our results reveal
that RL training on critic data can produce a unified model excelling at both
evaluation and generation, offering a simple path toward scalable,
self-improving multimodal systems.

</details>


### [60] [CSFMamba: Cross State Fusion Mamba Operator for Multimodal Remote Sensing Image Classification](https://arxiv.org/abs/2509.00677)
*Qingyu Wang,Xue Jiang,Guozheng Xu*

Main category: cs.CV

TL;DR: Mamba 因其较低的计算复杂性而成为一种有前途的序列建模方法，但它缺乏直接融合多模态特征的能力。本文提出了一种名为 CSFMamba 的新型网络，它将 Mamba 的低计算效率与 CNN 的多层特征提取能力相结合，并引入了基于 Mamba 算子的交叉状态模块，以有效地融合高光谱图像（HSI）和 LiDAR 数据。实验结果表明，CSFMamba 在 MUUFL 和 Houston2018 数据集上均优于 Transformer，同时降低了训练负担。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态融合方法在处理遥感图像分类时，虽然利用了空间-光谱信息，但深度学习方法（如 CNN 和 Transformer）面临二次计算复杂性的问题，难以对长程空间-光谱特征进行建模。Mamba 结构解决了计算复杂性问题，但不能直接进行特征融合。因此，有必要探索一种能够结合 Mamba 的低计算量和其内部结构潜力以实现多模态特征融合的方法。

Method: 本文提出了一种名为 CSFMamba 的网络，该网络结合了 CNN 和 Mamba 的优点。首先，设计了一个预处理模块，用于适应 Mamba 结构的需求，并与 CNN 结合提取多层特征。其次，设计了一个基于 Mamba 算子的交叉状态模块，用于融合两种模态的特征。最终目标是结合 Mamba 和 CNN 的优势，构建一个更强大的骨干网络，以捕捉 HSI 和 LiDAR 模态之间的融合关系，实现对整个图像的深入理解。

Result: 在 MUUFL 和 Houston2018 两个数据集上的实验结果表明，CSFMamba 方法在降低网络训练负担的前提下，性能优于 Transformer 方法。

Conclusion: CSFMamba 网络成功地结合了 Mamba 的低计算复杂性和 CNN 的特征提取能力，并通过创新的交叉状态模块实现了 HSI 和 LiDAR 数据的有效多模态融合。实验证明，该方法在遥感图像分类任务上取得了优于现有先进方法的性能，并减轻了计算负担。

Abstract: Multimodal fusion has made great progress in the field of remote sensing
image classification due to its ability to exploit the complementary
spatial-spectral information. Deep learning methods such as CNN and Transformer
have been widely used in these domains. State Space Models recently highlighted
that prior methods suffer from quadratic computational complexity. As a result,
modeling longer-range dependencies of spatial-spectral features imposes an
overwhelming burden on the network. Mamba solves this problem by incorporating
time-varying parameters into ordinary SSM and performing hardware optimization,
but it cannot perform feature fusion directly. In order to make full use of
Mamba's low computational burden and explore the potential of internal
structure in multimodal feature fusion, we propose Cross State Fusion Mamba
(CSFMamba) Network. Specifically, we first design the preprocessing module of
remote sensing image information for the needs of Mamba structure, and combine
it with CNN to extract multi-layer features. Secondly, a cross-state module
based on Mamba operator is creatively designed to fully fuse the feature of the
two modalities. The advantages of Mamba and CNN are combined by designing a
more powerful backbone. We capture the fusion relationship between HSI and
LiDAR modalities with stronger full-image understanding. The experimental
results on two datasets of MUUFL and Houston2018 show that the proposed method
outperforms the experimental results of Transformer under the premise of
reducing the network training burden.

</details>


### [61] [CascadeFormer: A Family of Two-stage Cascading Transformers for Skeleton-based Human Action Recognition](https://arxiv.org/abs/2509.00692)
*Yusen Peng,Alper Yilmaz*

Main category: cs.CV

TL;DR: CascadeFormer是一种用于基于骨架的人类动作识别的新型两阶段级联Transformer模型，通过掩码预训练学习通用的骨架表示，然后进行级联微调以实现判别性动作分类，并在三个基准数据集上取得了有竞争力的性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型和掩码预训练框架为表示学习开辟了新途径，而现有的基于图卷积网络（GCN）的方法在骨架数据中固有的时空结构利用方面占主导地位。本文旨在探索Transformer在骨架序列中的潜力。

Method: 提出了一种名为CascadeFormer的两阶段级联Transformer模型。第一阶段是掩码预训练，用于学习通用的骨架表示。第二阶段是级联微调，针对判别性动作分类进行优化。

Result: CascadeFormer在Penn Action、N-UCLA和NTU RGB+D 60三个基准数据集上进行了评估，并在所有任务上取得了有竞争力的性能。

Conclusion: CascadeFormer通过其两阶段级联Transformer架构，成功地学习了通用的骨架表示并实现了高效的动作分类，为基于骨架的人类动作识别领域带来了新的研究方向。

Abstract: Skeleton-based human action recognition leverages sequences of human joint
coordinates to identify actions performed in videos. Owing to the intrinsic
spatiotemporal structure of skeleton data, Graph Convolutional Networks (GCNs)
have been the dominant architecture in this field. However, recent advances in
transformer models and masked pretraining frameworks open new avenues for
representation learning. In this work, we propose CascadeFormer, a family of
two-stage cascading transformers for skeleton-based human action recognition.
Our framework consists of a masked pretraining stage to learn generalizable
skeleton representations, followed by a cascading fine-tuning stage tailored
for discriminative action classification. We evaluate CascadeFormer across
three benchmark datasets (Penn Action N-UCLA, and NTU RGB+D 60), achieving
competitive performance on all tasks. To promote reproducibility, we release
our code and model checkpoints.

</details>


### [62] [Prompt the Unseen: Evaluating Visual-Language Alignment Beyond Supervision](https://arxiv.org/abs/2509.00700)
*Raehyuk Jung,Seungjun Yu,Hyunjung Shim*

Main category: cs.CV

TL;DR: VLMs中的投影层在泛化到未见过的视觉概念方面表现出非平凡的能力，尽管缺乏显式的对齐监督。


<details>
  <summary>Details</summary>
Motivation: 评估VLMs中投影层在泛化到未见过的视觉概念方面的能力，并提出一个用于评估投影层泛化的基准。

Method: 创建一个基准，通过调整目标检测数据集和设计分离的训练/测试标签集来评估投影层的泛化能力，并通过 the feed-forward network 的机制可解释性进行分析。

Result: 在未见过的类别上，投影层的性能保留了已见类别的79%到88%，表明即使没有显式的对齐监督，也具有一定的泛化能力。分析表明，投影层中的前馈网络像一个键值记忆体。

Conclusion: 投影层在泛化到未见过的视觉概念方面具有一定的能力，这为在有限的对齐数据下进行高效的VLM训练提供了可能性。

Abstract: Vision-Language Models (VLMs) combine a vision encoder and a large language
model (LLM) through alignment training, showing strong performance on
multimodal tasks. A central component in this architecture is the projection
layer, which maps visual features into the LLM's embedding space. Despite its
importance, its ability to generalize to unseen visual concepts has not been
systematically evaluated. To address this, we propose a benchmark for
evaluating projection-layer generalization. We adapt object detection datasets
(rich in fine-grained annotations) into a prompting format and design
train/test splits with disjoint label sets, enabling precise control over seen
and unseen concept separation. Experimental results show that the projection
layer retains about 79 to 88 percent of the performance on unseen classes
compared to seen ones across various settings, suggesting a non-trivial level
of generalization even without explicit alignment supervision on those
concepts. We further analyze this behavior through a mechanistic
interpretability lens. Our findings indicate that the feed-forward network in
the projection layer functions like a key-value memory, processing seen and
unseen tokens in similar ways. This study introduces a new evaluation framework
for alignment generalization and highlights the potential for efficient VLM
training with limited aligned data.

</details>


### [63] [Enhancing Fairness in Skin Lesion Classification for Medical Diagnosis Using Prune Learning](https://arxiv.org/abs/2509.00745)
*Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker,Yiannis Papadopoulos,Tanaya Maslekar*

Main category: cs.CV

TL;DR: 深度学习在皮肤镜检查中存在肤色偏见问题，提出一种基于VGG和Vision Transformer的特征图偏度计算方法，通过减少肤色相关通道来降低计算成本和偏见，以实现诊断公平性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习皮肤镜检查模型在不同肤色人群中可能存在的偏见问题，提高诊断公平性。

Method: 通过计算VGG网络卷积层和Vision Transformer的图像块及注意力头的特征图偏度，识别并减少与肤色无关的通道，从而优化模型。

Result: 该方法降低了计算成本，减轻了模型偏见，并可能减小模型尺寸，同时保持了公平性。

Conclusion: 所提出的公平性算法能够有效解决皮肤镜检查中不同肤色人群的诊断偏见问题，具有实际应用价值。

Abstract: Recent advances in deep learning have significantly improved the accuracy of
skin lesion classification models, supporting medical diagnoses and promoting
equitable healthcare. However, concerns remain about potential biases related
to skin color, which can impact diagnostic outcomes. Ensuring fairness is
challenging due to difficulties in classifying skin tones, high computational
demands, and the complexity of objectively verifying fairness. To address these
challenges, we propose a fairness algorithm for skin lesion classification that
overcomes the challenges associated with achieving diagnostic fairness across
varying skin tones. By calculating the skewness of the feature map in the
convolution layer of the VGG (Visual Geometry Group) network and the patches
and the heads of the Vision Transformer, our method reduces unnecessary
channels related to skin tone, focusing instead on the lesion area. This
approach lowers computational costs and mitigates bias without relying on
conventional statistical methods. It potentially reduces model size while
maintaining fairness, making it more practical for real-world applications.

</details>


### [64] [Causal Interpretation of Sparse Autoencoder Features in Vision](https://arxiv.org/abs/2509.00749)
*Sangyu Han,Yearim Kim,Nojun Kwak*

Main category: cs.CV

TL;DR: CaFE利用ERF来解释ViT中SAE特征，克服了仅依赖激活位置的局限性，提供了更忠实、语义更精确的解释。


<details>
  <summary>Details</summary>
Motivation: 传统的SAE特征解释方法（检查高激活区域）在ViT中存在局限，因为自注意力机制会混合整个图像的信息，导致激活区域并非特征激活的直接原因。

Method: 提出Causal Feature Explanation (CaFE) 方法，该方法利用Effective Receptive Field (ERF) 来识别真正驱动SAE特征激活的图像块。将每个特征激活视为目标，应用输入归因方法来寻找因果驱动因素。

Result: 在CLIP-ViT特征上，ERF图谱与简单激活图谱存在差异，揭示了隐藏的上下文依赖关系（例如，“咆哮的脸”特征需要眼睛和鼻子的共现）。Patch插入测试表明，CaFE比基于激活排名的Patch更有效地恢复或抑制特征激活。

Conclusion: CaFE能提供更忠实、语义更精确的ViT中SAE特征的解释，并指出了仅依赖激活位置可能导致的误解风险。

Abstract: Understanding what sparse auto-encoder (SAE) features in vision transformers
truly represent is usually done by inspecting the patches where a feature's
activation is highest. However, self-attention mixes information across the
entire image, so an activated patch often co-occurs with-but does not cause-the
feature's firing. We propose Causal Feature Explanation (CaFE), which leverages
Effective Receptive Field (ERF). We consider each activation of an SAE feature
to be a target and apply input-attribution methods to identify the image
patches that causally drive that activation. Across CLIP-ViT features, ERF maps
frequently diverge from naive activation maps, revealing hidden context
dependencies (e.g., a "roaring face" feature that requires the co-occurrence of
eyes and nose, rather than merely an open mouth). Patch insertion tests confirm
that CaFE more effectively recovers or suppresses feature activations than
activation-ranked patches. Our results show that CaFE yields more faithful and
semantically precise explanations of vision-SAE features, highlighting the risk
of misinterpretation when relying solely on activation location.

</details>


### [65] [EVENT-Retriever: Event-Aware Multimodal Image Retrieval for Realistic Captions](https://arxiv.org/abs/2509.00751)
*Dinh-Khoi Vo,Van-Loc Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: 该论文提出了一种结合密集文章检索、事件感知语言模型重排和图像检索的多阶段框架，用于根据自由格式的标题进行事件图像检索，并在EVENTA 2025 Grand Challenge的私有测试集上取得了第一名。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉-语言检索方法在处理抽象事件、隐含因果关系、时间背景或长而复杂的叙述时存在的不足。

Method: 采用多阶段检索框架，结合了密集文章检索（使用Qwen3）、事件感知语言模型重排（使用Qwen3-Reranker）以及图像检索（使用Qwen2-VL进行精确评分）。通过结合多种配置的输出（使用倒数排名融合 RRF）来提高性能和鲁棒性。

Result: 在EVENTA 2025 Grand Challenge的Track 2私有测试集上取得了top-1的成绩。

Conclusion: 证明了结合基于语言的推理和多模态检索对于理解复杂、真实的事件图像的有效性。

Abstract: Event-based image retrieval from free-form captions presents a significant
challenge: models must understand not only visual features but also latent
event semantics, context, and real-world knowledge. Conventional
vision-language retrieval approaches often fall short when captions describe
abstract events, implicit causality, temporal context, or contain long, complex
narratives. To tackle these issues, we introduce a multi-stage retrieval
framework combining dense article retrieval, event-aware language model
reranking, and efficient image collection, followed by caption-guided semantic
matching and rank-aware selection. We leverage Qwen3 for article search,
Qwen3-Reranker for contextual alignment, and Qwen2-VL for precise image
scoring. To further enhance performance and robustness, we fuse outputs from
multiple configurations using Reciprocal Rank Fusion (RRF). Our system achieves
the top-1 score on the private test set of Track 2 in the EVENTA 2025 Grand
Challenge, demonstrating the effectiveness of combining language-based
reasoning and multimodal retrieval for complex, real-world image understanding.
The code is available at https://github.com/vdkhoi20/EVENT-Retriever.

</details>


### [66] [Multi-Level CLS Token Fusion for Contrastive Learning in Endoscopy Image Classification](https://arxiv.org/abs/2509.00752)
*Y Hop Nguyen,Doan Anh Phan Huu,Trung Thai Tran,Nhat Nam Mai,Van Toi Giap,Thao Thi Phuong Dao,Trung-Nghia Le*

Main category: cs.CV

TL;DR: 提出了一种用于耳鼻喉内窥镜图像分析的统一视觉-语言框架，可同时处理图像分类、图像到图像检索和文本到图像检索。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于CNN的管道在捕捉跨模态语义方面的局限性，同时提高在有限医疗数据上的表示多样性和跨模态语义对齐。

Method: 利用CLIP ViT-16骨干，通过低秩适配、多级CLS令牌聚合和球面特征插值进行增强，并引入了类别特定的自然语言提示，通过结合监督分类和对比学习的联合训练目标来指导图像编码器。

Result: 在ACM MM'25 ENTRep大挑战赛中，分类准确率和F1分数达到95%，图像到图像检索和文本到图像检索的Recall@1分别为0.93和0.92，MRR得分分别为0.97和0.96。

Conclusion: 提出的框架在低资源临床环境中实现了强大的多模态医学理解，每个架构组件都带来了增量收益。

Abstract: We present a unified vision-language framework tailored for ENT endoscopy
image analysis that simultaneously tackles three clinically-relevant tasks:
image classification, image-to-image retrieval, and text-to-image retrieval.
Unlike conventional CNN-based pipelines that struggle to capture cross-modal
semantics, our approach leverages the CLIP ViT-B/16 backbone and enhances it
through Low-Rank Adaptation, multi-level CLS token aggregation, and spherical
feature interpolation. These components collectively enable efficient
fine-tuning on limited medical data while improving representation diversity
and semantic alignment across modalities. To bridge the gap between visual
inputs and textual diagnostic context, we introduce class-specific natural
language prompts that guide the image encoder through a joint training
objective combining supervised classification with contrastive learning. We
validated our framework through participation in the ACM MM'25 ENTRep Grand
Challenge, achieving 95% accuracy and F1-score in classification, Recall@1 of
0.93 and 0.92 for image-to-image and text-to-image retrieval respectively, and
MRR scores of 0.97 and 0.96. Ablation studies demonstrated the incremental
benefits of each architectural component, validating the effectiveness of our
design for robust multimodal medical understanding in low-resource clinical
settings.

</details>


### [67] [MarkSplatter: Generalizable Watermarking for 3D Gaussian Splatting Model via Splatter Image Structure](https://arxiv.org/abs/2509.00757)
*Xiufeng Huang,Ziyuan Luo,Qi Song,Ruofei Wang,Renjie Wan*

Main category: cs.CV

TL;DR: 本研究提出了首个可泛化的3D高斯喷涂（3DGS）水印框架，通过单次前向传播实现高效保护，解决了现有方法需要为预定义消息进行计算密集型微调的问题。


<details>
  <summary>Details</summary>
Motivation: 当前3DGS的水印方法需要为每条预定义消息进行计算密集型微调，效率低下，需要更有效的水印保护方法。

Method: 提出了一种名为GaussianBridge的新机制，将非结构化的3D高斯转换为喷涂图像格式，实现直接的神经处理以嵌入任意消息。为了保证不可感知性，设计了一种高斯不确定性感知热图预测策略来保持视觉质量。为了实现鲁棒的消息恢复，开发了一种基于密集分割的提取机制，即使在水印对象在渲染视图中占据最小区域时也能可靠提取。 

Result: 通过引入GaussianBridge、高斯不确定性感知热图预测和基于密集分割的提取机制，实现了对3DGS模型的高效、可感知且鲁棒的水印保护。

Conclusion: 本研究成功开发了一个能够通过单次前向传播实现高效3DGS模型版权保护的水印框架，解决了现有方法的局限性，并提供了良好的视觉质量和鲁棒性。

Abstract: The growing popularity of 3D Gaussian Splatting (3DGS) has intensified the
need for effective copyright protection. Current 3DGS watermarking methods rely
on computationally expensive fine-tuning procedures for each predefined
message. We propose the first generalizable watermarking framework that enables
efficient protection of Splatter Image-based 3DGS models through a single
forward pass. We introduce GaussianBridge that transforms unstructured 3D
Gaussians into Splatter Image format, enabling direct neural processing for
arbitrary message embedding. To ensure imperceptibility, we design a
Gaussian-Uncertainty-Perceptual heatmap prediction strategy for preserving
visual quality. For robust message recovery, we develop a dense
segmentation-based extraction mechanism that maintains reliable extraction even
when watermarked objects occupy minimal regions in rendered views. Project
page: https://kevinhuangxf.github.io/marksplatter.

</details>


### [68] [No More Sibling Rivalry: Debiasing Human-Object Interaction Detection](https://arxiv.org/abs/2509.00760)
*Bin Yang,Yulin Zhang,Hong-Yu Zhou,Sibei Yang*

Main category: cs.CV

TL;DR: 检测 Transformer 在 HOI 检测中存在“毒兄弟”偏见，导致相似的 HOI 三元组相互干扰。提出“对比-校准”和“合并-拆分”两种新颖的去偏学习目标来解决此问题，并在 HICO-Det 数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 检测 Transformer 在 HOI 检测中存在“毒兄弟”偏见，相似但不同的 HOI 三元组相互干扰，导致精度下降。

Method: 提出“对比-校准”和“合并-拆分”两种去偏学习目标。前者从输入端入手，通过对比学习和位置先验指导，将相似的错误三元组校准为正确三元组；后者从输出端入手，先学习区分兄弟类别的发展特征，再精炼组内区分度。

Result: 在 HICO-Det 数据集上，提出的方法比基线提高了 9.18% 的 mAP，比现有技术水平提高了 3.59% 的 mAP。

Conclusion: 提出的去偏学习方法能有效解决 HOI 检测中的“毒兄弟”偏见问题，显著提升模型性能。

Abstract: Detection transformers have been applied to human-object interaction (HOI)
detection, enhancing the localization and recognition of human-action-object
triplets in images. Despite remarkable progress, this study identifies a
critical issue-"Toxic Siblings" bias-which hinders the interaction decoder's
learning, as numerous similar yet distinct HOI triplets interfere with and even
compete against each other both input side and output side to the interaction
decoder. This bias arises from high confusion among sibling
triplets/categories, where increased similarity paradoxically reduces
precision, as one's gain comes at the expense of its toxic sibling's decline.
To address this, we propose two novel debiasing learning
objectives-"contrastive-then-calibration" and "merge-then-split"-targeting the
input and output perspectives, respectively. The former samples sibling-like
incorrect HOI triplets and reconstructs them into correct ones, guided by
strong positional priors. The latter first learns shared features among sibling
categories to distinguish them from other groups, then explicitly refines
intra-group differentiation to preserve uniqueness. Experiments show that we
significantly outperform both the baseline (+9.18% mAP on HICO-Det) and the
state-of-the-art (+3.59% mAP) across various settings.

</details>


### [69] [InterPose: Learning to Generate Human-Object Interactions from Large-Scale Web Videos](https://arxiv.org/abs/2509.00767)
*Yangsong Zhang,Abdul Ahad Butt,Gül Varol,Ivan Laptev*

Main category: cs.CV

TL;DR: 本文提出了一种自动提取人体与物体交互运动的流程，并构建了一个名为InterPose的数据集，包含73.8K的3D人体运动序列和对应的文本描述。该数据集可用于改进现有的人体运动生成方法，并开发基于LLM的智能体以实现零样本动画。


<details>
  <summary>Details</summary>
Motivation: 现有的人体运动生成模型通常只关注独立个体的动画，难以生成复杂3D场景中的人与物交互。这主要是因为缺乏包含多样化物体操作的大规模数据集。现有数据集主要限制于单人动作和有限的物体交互。

Method: 提出一个自动化的运动提取流程，利用该流程从包含人与物交互的视频中收集了73.8K的3D人体运动序列和对应的文本描述，构建了InterPose数据集。

Result: 通过大量实验证明InterPose数据集能够显著提升现有先进的人体运动生成方法。此外，基于InterPose数据集开发了一个LLM智能体，能够实现与多样化物体和场景交互的人员的零样本动画。

Conclusion: InterPose数据集的构建解决了现有数据集在多样化人与物交互数据方面的不足，为人体运动生成领域带来了改进，并为开发更智能的动画系统提供了可能。

Abstract: Human motion generation has shown great advances thanks to the recent
diffusion models trained on large-scale motion capture data. Most of existing
works, however, currently target animation of isolated people in empty scenes.
Meanwhile, synthesizing realistic human-object interactions in complex 3D
scenes remains a critical challenge in computer graphics and robotics. One
obstacle towards generating versatile high-fidelity human-object interactions
is the lack of large-scale datasets with diverse object manipulations. Indeed,
existing motion capture data is typically restricted to single people and
manipulations of limited sets of objects. To address this issue, we propose an
automatic motion extraction pipeline and use it to collect interaction-rich
human motions. Our new dataset InterPose contains 73.8K sequences of 3D human
motions and corresponding text captions automatically obtained from 45.8K
videos with human-object interactions. We perform extensive experiments and
demonstrate InterPose to bring significant improvements to state-of-the-art
methods for human motion generation. Moreover, using InterPose we develop an
LLM-based agent enabling zero-shot animation of people interacting with diverse
objects and scenes.

</details>


### [70] [Secure and Scalable Face Retrieval via Cancelable Product Quantization](https://arxiv.org/abs/2509.00781)
*Haomiao Tang,Wenjie Li,Yixiang Qiu,Genping Wang,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 加密人脸检索系统利用一种名为可取消乘积量化（CPQ）的新框架，通过分层两阶段方法解决了隐私泄露和计算效率低下两大难题，在保证安全性的同时实现了高效的检索。


<details>
  <summary>Details</summary>
Motivation: 现有的在线人脸检索系统将检索阶段外包给第三方，对用户肖像隐私构成严重威胁。虽然全同态加密（HE）提供了强大的安全保障，但其计算效率低下，不适用于实时应用。

Method: 提出了一种名为“可取消乘积量化”（Cancelable Product Quantization, CPQ）的高效框架，用于安全的人脸表示检索。该框架包含两个阶段：1. 高吞吐量的可取消乘积量化（PQ）索引模块，用于快速筛选候选对象。2. 细粒度的密文空间检索模块，用于最终精确的人脸排序。设计了定制化的保护机制来保护索引模块，以实现可取消的生物特征认证，同时保证效率。

Result: 在基准数据集上的实验表明，该方法在有效性、效率和安全性之间取得了良好的平衡。

Conclusion: 该研究提出的CPQ框架有效解决了现有加密人脸检索系统的隐私和效率问题，为安全可靠的人脸检索提供了新的解决方案。

Abstract: Despite the ubiquity of modern face retrieval systems, their retrieval stage
is often outsourced to third-party entities, posing significant risks to user
portrait privacy. Although homomorphic encryption (HE) offers strong security
guarantees by enabling arithmetic computations in the cipher space, its high
computational inefficiency makes it unsuitable for real-time, real-world
applications. To address this issue, we propose Cancelable Product
Quantization, a highly efficient framework for secure face representation
retrieval. Our hierarchical two-stage framework comprises: (i) a
high-throughput cancelable PQ indexing module for fast candidate filtering, and
(ii) a fine-grained cipher-space retrieval module for final precise face
ranking. A tailored protection mechanism is designed to secure the indexing
module for cancelable biometric authentication while ensuring efficiency.
Experiments on benchmark datasets demonstrate that our method achieves an
decent balance between effectiveness, efficiency and security.

</details>


### [71] [Aligned Anchor Groups Guided Line Segment Detector](https://arxiv.org/abs/2509.00786)
*Zeyu Li,Annan Shu*

Main category: cs.CV

TL;DR: AAGLSD是一种新的线段检测器，它使用对齐的锚点组来高精度和完整地检测图像中的线段，并在各种数据集上优于其他先进的检测器。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的线段检测算法，能够高精度和完整地从图像中提取线段。

Method: AAGLSD采用分层方法提取不同显著性级别的候选像素，包括常规锚点和对齐锚点组。该算法从对齐锚点组开始，依次连接锚点并同时更新预测的线段。最后通过简单的验证和合并相邻线段得到最终预测结果，无需复杂优化。

Result: AAGLSD在各种数据集上的评估和定量实验表明，与现有的先进线段检测器相比，该方法能够有效地从输入图像中提取完整的线段。

Conclusion: AAGLSD是一种有效且准确的线段检测方法，通过使用对齐锚点组和迭代更新策略，在保持简单性的同时实现了高精度和完整性。

Abstract: This paper introduces a novel line segment detector, the Aligned Anchor
Groups guided Line Segment Detector (AAGLSD), designed to detect line segments
from images with high precision and completeness. The algorithm employs a
hierarchical approach to extract candidate pixels with different saliency
levels, including regular anchors and aligned anchor groups. AAGLSD initiates
from these aligned anchor groups, sequentially linking anchors and updating the
currently predicted line segment simultaneously. The final predictions are
derived through straightforward validation and merging of adjacent line
segments, avoiding complex refinement strategies. AAGLSD is evaluated on
various datasets and quantitative experiments demonstrate that the proposed
method can effectively extract complete line segments from input images
compared to other advanced line segment detectors. The implementation is
available at https://github.com/LLiDaBao/AAGLSD.

</details>


### [72] [Diffusion-Based Image-to-Brain Signal Generation with Cross-Attention Mechanisms for Visual Prostheses](https://arxiv.org/abs/2509.00787)
*Ganxi Xu,Jinyi Long,Jia Zhang*

Main category: cs.CV

TL;DR: 本研究提出了一种基于带有交叉注意机制的去噪扩散概率模型（DDPM）的新型图像到大脑框架，以解决视觉假体中脑编码阶段生成的脑信号生物相似性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉假体在脑解码方面取得了进展，但在脑编码阶段生成的脑信号生物相似性不足，缺乏真实脑反应的监督信号来验证其生物学合理性。

Method: 提出了一种新型图像到大脑框架，采用预训练的CLIP视觉编码器提取图像语义表示，并结合交叉注意力增强的U-Net扩散模型，通过迭代去噪来学习重建具有生物学合理性的脑信号。交叉注意力机制能够实现视觉特征和脑信号表示之间的动态交互，从而在生成过程中进行细粒度对齐。

Result: 在THINGS-EEG2和THINGS-MEG两个多模态数据集上进行了评估，证明了该框架在生成具有生物学合理性的脑信号方面的有效性。此外，还可视化了训练和测试M/EEG地形图，直观地展示了M/EEG信号的受试者内和受试者间变异性。

Conclusion: 所提出的框架通过结合CLIP视觉编码器和交叉注意力增强的DDPM，能够生成更具生物学合理性的脑信号，为视觉假体的脑编码阶段提供了新的解决方案。

Abstract: Visual prostheses have shown great potential in restoring vision for blind
individuals. On the one hand, researchers have been continuously improving the
brain decoding framework of visual prostheses by leveraging the powerful image
generation capabilities of diffusion models. On the other hand, the brain
encoding stage of visual prostheses struggles to generate brain signals with
sufficient biological similarity. Although existing works have recognized this
problem, the quality of predicted stimuli still remains a critical issue, as
existing approaches typically lack supervised signals from real brain responses
to validate the biological plausibility of predicted stimuli. To address this
issue, we propose a novel image-to-brain framework based on denoising diffusion
probabilistic models (DDPMs) enhanced with cross-attention mechanisms. Our
framework consists of two key architectural components: a pre-trained CLIP
visual encoder that extracts rich semantic representations from input images,
and a cross-attention enhanced U-Net diffusion model that learns to reconstruct
biologically plausible brain signals through iterative denoising. Unlike
conventional generative models that rely on simple concatenation for
conditioning, our cross-attention modules enable dynamic interaction between
visual features and brain signal representations, facilitating fine-grained
alignment during the generation process. We evaluate our framework on two
multimodal datasets (THINGS-EEG2 and THINGS-MEG) to demonstrate its
effectiveness in generating biologically plausible brain signals. Moreover, we
visualize the training and test M/EEG topographies for all subjects on both
datasets to intuitively demonstrate the intra-subject variations and
inter-subject variations in M/EEG signals.

</details>


### [73] [OmniReason: A Temporal-Guided Vision-Language-Action Framework for Autonomous Driving](https://arxiv.org/abs/2509.00789)
*Pei Liu,Qingtian Ning,Xinyan Lu,Haipeng Liu,Weiliang Ma,Dangen She,Peng Jia,Xianpeng Lang,Jun Ma*

Main category: cs.CV

TL;DR: 本文提出了OmniReason框架，通过联合建模动态3D环境及其决策过程来解决现有视觉-语言模型在时空推理方面忽略时间维度的问题。该框架包含OmniReason-Data（大规模视觉-语言-动作数据集）和OmniReason-Agent（集成稀疏时间记忆模块和可解释性生成器的架构），并在开放式规划任务和视觉问答基准测试中取得了最先进的性能，同时增强了自动驾驶系统在复杂动态环境中的可解释性和时间感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型在空间推理方面表现出色，但在真实驾驶场景中，它们忽视了至关重要的时间维度，导致对动态场景的理解不足。

Method: 提出OmniReason框架，该框架通过联合建模动态3D环境及其决策过程来建立强大的时空推理能力。具体包括：1）引入OmniReason-Data，一个包含密集时空标注和自然语言解释的大规模视觉-语言-动作（VLA）数据集，通过新颖的缓解幻觉的自动标注流程生成；2）开发OmniReason-Agent架构，该架构集成了一个稀疏时间记忆模块用于持续场景上下文建模，以及一个解释生成器，通过时空知识蒸馏方法生成人类可解释的决策依据。

Result: 实验证明，OmniReason-Agent在开放式规划任务和视觉问答（VQA）基准测试中取得了最先进的性能，显著提高了性能，并为在复杂动态环境中运行的可解释、具备时间感知能力的自动驾驶汽车建立了新能力。

Conclusion: OmniReason框架通过其包含的数据集和智能体架构，有效解决了当前视觉-语言模型在自动驾驶时空推理方面的局限性，显著提升了模型性能，并为开发更安全、更可解释的自动驾驶系统铺平了道路。

Abstract: Recent advances in vision-language models (VLMs) have demonstrated impressive
spatial reasoning capabilities for autonomous driving, yet existing methods
predominantly focus on static scene understanding while neglecting the
essential temporal dimension of real-world driving scenarios. To address this
critical limitation, we propose the OmniReason framework, which establishes
robust spatiotemporal reasoning by jointly modeling dynamic 3D environments and
their underlying decision-making processes. Our work makes two fundamental
advances: (1) We introduce OmniReason-Data, two large-scale
vision-language-action (VLA) datasets with dense spatiotemporal annotations and
natural language explanations, generated through a novel
hallucination-mitigated auto-labeling pipeline that ensures both physical
plausibility and temporal coherence; (2) We develop the OmniReason-Agent
architecture, which integrates a sparse temporal memory module for persistent
scene context modeling and an explanation generator that produces
human-interpretable decision rationales, facilitated by our spatiotemporal
knowledge distillation approach that effectively captures spatiotemporal causal
reasoning patterns. Comprehensive experiments demonstrate state-of-the-art
performance, where OmniReason-Agent achieves significant improvements in both
open-loop planning tasks and visual question answering (VQA) benchmarks, while
establishing new capabilities for interpretable, temporally-aware autonomous
vehicles operating in complex, dynamic environments.

</details>


### [74] [Multimodal Iterative RAG for Knowledge Visual Question Answering](https://arxiv.org/abs/2509.00798)
*Changin Choi,Wonseok Lee,Jungmin Ko,Wonjong Rhee*

Main category: cs.CV

TL;DR: MI-RAG是一个多模态迭代检索增强生成框架，通过迭代推理和跨模态知识检索来提升知识密集型视觉问答的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在处理需要外部知识的视觉问答任务时能力有限，而传统的单通道检索增强生成框架在知识获取方面存在不足。

Method: MI-RAG框架在每个迭代中利用累积的推理记录来动态地制定多查询，并在包含视觉基础和文本知识的异构知识库中联合搜索。新获取的知识被整合到推理记录中，以逐步改进跨迭代的理解。

Result: MI-RAG在 the Encyclopedic VQA、InfoSeek 和 OK-VQA 等具有挑战性的基准测试中，显著提高了检索召回率和答案准确率。

Conclusion: MI-RAG为知识密集型视觉问答中的组合推理提供了一种可扩展的方法。

Abstract: While Multimodal Large Language Models (MLLMs) have significantly advanced
multimodal understanding, their performance remains limited on
knowledge-intensive visual questions that require external knowledge beyond the
image. Retrieval-Augmented Generation (RAG) has become a promising solution for
providing models with external knowledge, its conventional single-pass
framework often fails to gather sufficient knowledge. To overcome this
limitation, we propose MI-RAG, a Multimodal Iterative RAG framework that
leverages reasoning to enhance retrieval and update reasoning over newly
retrieved knowledge across modalities. At each iteration, MI-RAG leverages an
accumulated reasoning record to dynamically formulate a multi-query. These
queries then drive a joint search across heterogeneous knowledge bases
containing both visually-grounded and textual knowledge. The newly acquired
knowledge is synthesized into the reasoning record, progressively refining
understanding across iterations. Experiments on challenging benchmarks,
including Encyclopedic VQA, InfoSeek, and OK-VQA, show that MI-RAG
significantly improves both retrieval recall and answer accuracy, establishing
a scalable approach for compositional reasoning in knowledge-intensive VQA.

</details>


### [75] [SWAGSplatting: Semantic-guided Water-scene Augmented Gaussian Splatting](https://arxiv.org/abs/2509.00800)
*Zhuodong Jiang,Haoran Wang,Guoxi Huang,Brett Seymour,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: 该论文提出了一种新颖的框架，利用多模态跨知识，通过嵌入CLIP提取的语义特征来指导3D高斯喷溅，以实现鲁棒且高保真的深海场景重建。通过专门的语义一致性损失和分阶段训练策略，该方法在SeaThru-NeRF和Submerged3D数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 水下环境的3D重建因光线失真、浑浊度和能见度有限等问题而充满挑战。现有的人工智能方法未能充分发挥语言模型与视觉处理相结合的潜力。

Method: 提出了一种利用多模态跨知识的框架，通过将额外的语义特征嵌入到每个高斯图元中，并由CLIP提取的语义特征进行监督，实现语义引导的3D高斯喷溅。该方法还提出了一种结合粗到精学习和后期参数细化的分阶段训练策略。

Result: 该方法在SeaThru-NeRF和Submerged3D数据集上，与现有最先进的方法相比，在PSNR指标上平均提高了3.09 dB。

Conclusion: 该方法在水下3D重建方面取得了优于现有方法的性能，为水下探索和海洋感知应用提供了有力支持。

Abstract: Accurate 3D reconstruction in underwater environments remains a complex
challenge due to issues such as light distortion, turbidity, and limited
visibility. AI-based techniques have been applied to address these issues,
however, existing methods have yet to fully exploit the potential of AI,
particularly in integrating language models with visual processing. In this
paper, we propose a novel framework that leverages multimodal cross-knowledge
to create semantic-guided 3D Gaussian Splatting for robust and high-fidelity
deep-sea scene reconstruction. By embedding an extra semantic feature into each
Gaussian primitive and supervised by the CLIP extracted semantic feature, our
method enforces semantic and structural awareness throughout the training. The
dedicated semantic consistency loss ensures alignment with high-level scene
understanding. Besides, we propose a novel stage-wise training strategy,
combining coarse-to-fine learning with late-stage parameter refinement, to
further enhance both stability and reconstruction quality. Extensive results
show that our approach consistently outperforms state-of-the-art methods on
SeaThru-NeRF and Submerged3D datasets across three metrics, with an improvement
of up to 3.09 dB on average in terms of PSNR, making it a strong candidate for
applications in underwater exploration and marine perception.

</details>


### [76] [Adaptive Contrast Adjustment Module: A Clinically-Inspired Plug-and-Play Approach for Enhanced Fetal Plane Classification](https://arxiv.org/abs/2509.00808)
*Yang Chen,Sanglin Zhao,Baoyu Chen,Mans Gustaf*

Main category: cs.CV

TL;DR: 提出一个即插即用的自适应对比度调整模块（ACAM），通过模拟医生调整对比度的方式，提高胎儿超声标准切面的分类准确性，并有效解决了低对比度、边界模糊等问题。


<details>
  <summary>Details</summary>
Motivation: 为了克服胎儿超声标准平面分类中存在的低组织对比度、边界模糊和操作者依赖的图像质量变化等挑战，提高产前诊断的可靠性。

Method: ACAM模块设计灵感来源于医生调整图像对比度的临床实践，利用浅层纹理敏感网络预测对比度参数，通过可微分映射将输入图像转换为多个对比度增强视图，并在下游分类器中融合这些视图。

Result: 在包含12,400张图像的医学中心数据集上进行了验证，ACAM模块在不同模型上均能稳定提升性能，轻量级模型的准确性提高了2.02%，传统模型的准确性提高了1.29%，最先进模型的准确性提高了1.15%。

Conclusion: ACAM模块通过内容感知自适应能力，用符合超声医师工作流程的物理信息变换取代随机预处理，并通过多视图融合提高对成像异质性的鲁棒性，有效连接了低层图像特征和高层语义，为解决真实世界图像质量变化下的医学图像分析问题提供了新范式。

Abstract: Fetal ultrasound standard plane classification is essential for reliable
prenatal diagnosis but faces inherent challenges, including low tissue
contrast, boundary ambiguity, and operator-dependent image quality variations.
To overcome these limitations, we propose a plug-and-play adaptive contrast
adjustment module (ACAM), whose core design is inspired by the clinical
practice of doctors adjusting image contrast to obtain clearer and more
discriminative structural information. The module employs a shallow
texture-sensitive network to predict clinically plausible contrast parameters,
transforms input images into multiple contrast-enhanced views through
differentiable mapping, and fuses them within downstream classifiers. Validated
on a multi-center dataset of 12,400 images across six anatomical categories,
the module consistently improves performance across diverse models, with
accuracy of lightweight models increasing by 2.02 percent, accuracy of
traditional models increasing by 1.29 percent, and accuracy of state-of-the-art
models increasing by 1.15 percent. The innovation of the module lies in its
content-aware adaptation capability, replacing random preprocessing with
physics-informed transformations that align with sonographer workflows while
improving robustness to imaging heterogeneity through multi-view fusion. This
approach effectively bridges low-level image features with high-level
semantics, establishing a new paradigm for medical image analysis under
real-world image quality variations.

</details>


### [77] [Sequential Difference Maximization: Generating Adversarial Examples via Multi-Stage Optimization](https://arxiv.org/abs/2509.00826)
*Xinlei Liu,Tao Hu,Peng Yi,Weitao Han,Jichao Xie,Baolin Li*

Main category: cs.CV

TL;DR: 提出了一种名为顺序差值最大化（SDM）的梯度下降攻击方法，通过最大化非真实标签概率上限与真实标签概率之间的差值来生成对抗样本，并在计算机视觉模型鲁棒性评估中展现出更强的攻击性能和成本效益。


<details>
  <summary>Details</summary>
Motivation: 为评估计算机视觉模型的鲁棒性，需要高效的对抗性攻击方法。

Method: 提出了一种新的优化目标，即将生成对抗样本重构为“最大化非真实标签的概率上限与真实标签概率之间的差值”，并提出了一种基于梯度的攻击方法SDM，该方法建立了一个“周期-阶段-步”的三层优化框架，其中周期和步之间的过程相同，而阶段的优化目标不同：初始阶段使用真实标签的负概率作为损失函数来压缩解空间；后续阶段引入方向性概率差值比（DPDR）损失函数，通过压缩不相关标签的概率来逐步提高非真实标签的概率上限。

Result: 实验证明，与之前的SOTA方法相比，SDM不仅表现出更强的攻击性能，而且实现了更高的攻击成本效益。此外，SDM还可以与对抗性训练方法相结合，以增强其防御效果。

Conclusion: SDM是一种高效的对抗性攻击方法，在提升模型鲁棒性评估和防御效果方面具有潜力。

Abstract: Efficient adversarial attack methods are critical for assessing the
robustness of computer vision models. In this paper, we reconstruct the
optimization objective for generating adversarial examples as "maximizing the
difference between the non-true labels' probability upper bound and the true
label's probability," and propose a gradient-based attack method termed
Sequential Difference Maximization (SDM). SDM establishes a three-layer
optimization framework of "cycle-stage-step." The processes between cycles and
between iterative steps are respectively identical, while optimization stages
differ in terms of loss functions: in the initial stage, the negative
probability of the true label is used as the loss function to compress the
solution space; in subsequent stages, we introduce the Directional Probability
Difference Ratio (DPDR) loss function to gradually increase the non-true
labels' probability upper bound by compressing the irrelevant labels'
probabilities. Experiments demonstrate that compared with previous SOTA
methods, SDM not only exhibits stronger attack performance but also achieves
higher attack cost-effectiveness. Additionally, SDM can be combined with
adversarial training methods to enhance their defensive effects. The code is
available at https://github.com/X-L-Liu/SDM.

</details>


### [78] [Surface Defect Detection with Gabor Filter Using Reconstruction-Based Blurring U-Net-ViT](https://arxiv.org/abs/2509.00827)
*Jongwook Si,Sungyoung Kim*

Main category: cs.CV

TL;DR: 本研究提出一种结合Gabor滤波与U-Net-ViT模型的新方法，用于提高基于纹理的表面缺陷检测的准确性和可靠性。该模型结合了U-Net的局部特征训练和Vision Transformer(ViT)的全局处理能力，能有效检测各种纹理的缺陷。


<details>
  <summary>Details</summary>
Motivation: 为了提高纹理表面缺陷检测的准确性和可靠性，并解决噪声环境下的鲁棒性问题。

Method: 1. 结合U-Net的局部特征提取和Vision Transformer(ViT)的全局处理能力。2. 使用基于高斯滤波的损失函数来去除背景噪声并突出缺陷模式。3. 在训练过程中使用椒盐（SP）掩码来增强纹理-缺陷边界。4. 在后处理中使用Gabor滤波器来强调缺陷的方向和频率特征。

Result: 在MVTec-AD、表面裂纹检测和Marble Surface Anomaly Dataset等数据集上实现了0.939的平均曲线下面积（AUC）。消融研究表明，最优滤波器尺寸和噪声概率可显著提升缺陷检测性能。

Conclusion: 提出的结合Gabor滤波与U-Net-ViT模型的方法能够有效提升表面缺陷检测的性能，尤其在存在噪声的情况下表现出良好的鲁棒性。

Abstract: This paper proposes a novel approach to enhance the accuracy and reliability
of texture-based surface defect detection using Gabor filters and a blurring
U-Net-ViT model. By combining the local feature training of U-Net with the
global processing of the Vision Transformer(ViT), the model effectively detects
defects across various textures. A Gaussian filter-based loss function removes
background noise and highlights defect patterns, while Salt-and-Pepper(SP)
masking in the training process reinforces texture-defect boundaries, ensuring
robust performance in noisy environments. Gabor filters are applied in
post-processing to emphasize defect orientation and frequency characteristics.
Parameter optimization, including filter size, sigma, wavelength, gamma, and
orientation, maximizes performance across datasets like MVTec-AD, Surface Crack
Detection, and Marble Surface Anomaly Dataset, achieving an average Area Under
the Curve(AUC) of 0.939. The ablation studies validate that the optimal filter
size and noise probability significantly enhance defect detection performance.

</details>


### [79] [UPGS: Unified Pose-aware Gaussian Splatting for Dynamic Scene Deblurring](https://arxiv.org/abs/2509.00831)
*Zhijing Wu,Longguang Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种统一的优化框架，通过将相机位姿作为可学习参数与3D高斯点属性一同进行端到端优化，来解决单目视频动态3D场景重建中的运动模糊问题。


<details>
  <summary>Details</summary>
Motivation: 单目视频动态3D场景重建在AR/VR、机器人和自动导航中有广泛应用，但相机和物体运动导致的严重运动模糊是现有方法面临的主要挑战。现有的两步法（先估计相机位姿，再优化3D高斯点）由于位姿估计受模糊影响，容易累积误差，导致重建质量下降。

Method: 提出了一种统一的优化框架，将相机和物体运动表示为每个基元的SE(3)仿射变换，并构建了一个统一的优化目标。为了实现稳定优化，采用三阶段训练策略，交替优化相机位姿和3D高斯点：1. 固定位姿优化高斯点；2. 固定高斯点优化位姿；3. 端到端联合优化所有参数。

Result: 在Stereo Blur数据集和真实世界序列上的实验表明，该方法在重建质量和位姿估计准确性方面均显著优于现有的动态去模糊方法。

Conclusion: 通过将相机位姿纳入端到端优化框架，并采用三阶段训练策略，该研究成功解决了单目视频动态3D场景重建中的运动模糊问题，提高了重建质量和位姿估计精度。

Abstract: Reconstructing dynamic 3D scenes from monocular video has broad applications
in AR/VR, robotics, and autonomous navigation, but often fails due to severe
motion blur caused by camera and object motion. Existing methods commonly
follow a two-step pipeline, where camera poses are first estimated and then 3D
Gaussians are optimized. Since blurring artifacts usually undermine pose
estimation, pose errors could be accumulated to produce inferior reconstruction
results. To address this issue, we introduce a unified optimization framework
by incorporating camera poses as learnable parameters complementary to 3DGS
attributes for end-to-end optimization. Specifically, we recast camera and
object motion as per-primitive SE(3) affine transformations on 3D Gaussians and
formulate a unified optimization objective. For stable optimization, we
introduce a three-stage training schedule that optimizes camera poses and
Gaussians alternatively. Particularly, 3D Gaussians are first trained with
poses being fixed, and then poses are optimized with 3D Gaussians being
untouched. Finally, all learnable parameters are optimized together. Extensive
experiments on the Stereo Blur dataset and challenging real-world sequences
demonstrate that our method achieves significant gains in reconstruction
quality and pose estimation accuracy over prior dynamic deblurring methods.

</details>


### [80] [SegDINO: An Efficient Design for Medical and Natural Image Segmentation with DINO-V3](https://arxiv.org/abs/2509.00833)
*Sicheng Yang,Hongqiu Wang,Zhaohu Xing,Sixiang Chen,Lei Zhu*

Main category: cs.CV

TL;DR: SegDINO是一个高效的分割框架，通过冻结DINOv3骨干并结合轻量级解码器，在医学和自然图像分割任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于DINO的自监督视觉模型在迁移学习中表现出色，但将其表示适配于分割任务仍然具有挑战性，现有方法依赖于具有多尺度融合或复杂上采样的重型解码器，这会增加参数和计算成本。

Method: SegDINO框架采用冻结的DINOv3骨干网络，并结合一个轻量级的解码器。该框架从预训练编码器中提取多层特征，将它们对齐到共同的分辨率和通道宽度，并使用一个轻量级的MLP头直接预测分割掩码。

Result: SegDINO在六个基准测试（包括三个医学数据集TN3K、Kvasir-SEG、ISIC和三个自然图像数据集MSD、VMD-D、ViSha）上的广泛实验表明，与现有方法相比，SegDINO始终如一地实现了最先进的性能。

Conclusion: SegDINO通过最小化可训练参数并保留基础特征的表示能力，提供了一种高效的分割解决方案，并在多个分割任务中取得了优异的成果。

Abstract: The DINO family of self-supervised vision models has shown remarkable
transferability, yet effectively adapting their representations for
segmentation remains challenging. Existing approaches often rely on heavy
decoders with multi-scale fusion or complex upsampling, which introduce
substantial parameter overhead and computational cost. In this work, we propose
SegDINO, an efficient segmentation framework that couples a frozen DINOv3
backbone with a lightweight decoder. SegDINO extracts multi-level features from
the pretrained encoder, aligns them to a common resolution and channel width,
and utilizes a lightweight MLP head to directly predict segmentation masks.
This design minimizes trainable parameters while preserving the
representational power of foundation features. Extensive experiments across six
benchmarks, including three medical datasets (TN3K, Kvasir-SEG, ISIC) and three
natural image datasets (MSD, VMD-D, ViSha), demonstrate that SegDINO
consistently achieves state-of-the-art performance compared to existing
methods. Code is available at https://github.com/script-Yang/SegDINO.

</details>


### [81] [Satellite Image Utilization for Dehazing with Swin Transformer-Hybrid U-Net and Watershed loss](https://arxiv.org/abs/2509.00835)
*Jongwook Si,Sungyoung Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种名为SUFERNOBWA的混合去雾框架，结合了Swin Transformer和U-Net，用于卫星图像的去雾处理。


<details>
  <summary>Details</summary>
Motivation: 大气干扰和雾霾严重影响卫星图像的清晰度和信息提取的准确性，需要有效的去雾方法来解决这些挑战。

Method: 提出了一种名为SUFERNOBWA的混合去雾框架，该框架集成了Swin Transformer和U-Net。具体来说，它使用了基于Swin Transformer的残差中的残差密集块（SwinRRDB）作为编码器和解码器的一部分，以实现全局上下文学习和局部细节恢复。此外，还引入了一个结合L2损失、引导损失和新型分水岭损失的复合损失函数，以增强结构边界保持和像素级精度。

Result: 实验结果表明，SUFERNOBWA在RICE和SateHaze1K数据集上均优于现有最先进的模型。在RICE数据集上，PSNR达到33.24 dB，SSIM达到0.967，显著优于现有方法。

Conclusion: 该研究为缓解卫星图像的大气干扰提供了一个有效的解决方案，并强调了其在多样化遥感应用中的潜在适用性。

Abstract: Satellite imagery plays a crucial role in various fields; however,
atmospheric interference and haze significantly degrade image clarity and
reduce the accuracy of information extraction. To address these challenges,
this paper proposes a hybrid dehazing framework that integrates Swin
Transformer and U-Net to balance global context learning and local detail
restoration, called SUFERNOBWA. The proposed network employs SwinRRDB, a Swin
Transformer-based Residual-in-Residual Dense Block, in both the encoder and
decoder to effectively extract features. This module enables the joint learning
of global contextual information and fine spatial structures, which is crucial
for structural preservation in satellite image. Furthermore, we introduce a
composite loss function that combines L2 loss, guided loss, and a novel
watershed loss, which enhances structural boundary preservation and ensures
pixel-level accuracy. This architecture enables robust dehazing under diverse
atmospheric conditions while maintaining structural consistency across restored
images. Experimental results demonstrate that the proposed method outperforms
state-of-the-art models on both the RICE and SateHaze1K datasets. Specifically,
on the RICE dataset, the proposed approach achieved a PSNR of 33.24 dB and an
SSIM of 0.967, which is a significant improvement over existing method. This
study provides an effective solution for mitigating atmospheric interference in
satellite imagery and highlights its potential applicability across diverse
remote sensing applications.

</details>


### [82] [Look Beyond: Two-Stage Scene View Generation via Panorama and Video Diffusion](https://arxiv.org/abs/2509.00843)
*Xueyang Kang,Zhengkang Xiang,Zezheng Zhang,Kourosh Khoshelham*

Main category: cs.CV

TL;DR: 从单张图像进行新视角合成（NVS）是一个挑战，因为存在大量未观察到的区域。本文提出一种新方法，将 NVS 分解为 360 度场景外推和新视角插值。通过从生成的全景表示中提取和扭曲关键帧，确保长期视角和场景的一致性。实验证明，该方法在生成全局一致的新视角方面优于现有方法，并支持灵活的相机控制。


<details>
  <summary>Details</summary>
Motivation: 现有 NVS 方法在处理大范围或循环轨迹时，往往难以保持视图连贯性和正确的视图对齐。

Method: 将单视角 NVS 分解为 360 度场景外推和新视角插值。首先，使用全景扩散模型学习场景先验，然后从全景图中采样和扭曲透视关键帧，并将其作为预训练视频扩散模型中的锚帧，通过空间噪声扩散过程生成新视角。

Result: 该方法在循环闭合场景下也能生成全局一致的新视角，并且能够灵活控制相机，在各种场景数据集上的实验表明，该方法在沿用户定义轨迹生成连贯视图方面优于现有方法。

Conclusion: 本文提出的方法通过将 NVS 分解为场景外推和视图插值，并利用关键帧和全景表示，能够生成全局一致的新视角，解决了现有方法在处理长距离或循环轨迹时的一致性问题。

Abstract: Novel view synthesis (NVS) from a single image is highly ill-posed due to
large unobserved regions, especially for views that deviate significantly from
the input. While existing methods focus on consistency between the source and
generated views, they often fail to maintain coherence and correct view
alignment across long-range or looped trajectories. We propose a model that
addresses this by decomposing single-view NVS into a 360-degree scene
extrapolation followed by novel view interpolation. This design ensures
long-term view and scene consistency by conditioning on keyframes extracted and
warped from a generated panoramic representation. In the first stage, a
panorama diffusion model learns the scene prior from the input perspective
image. Perspective keyframes are then sampled and warped from the panorama and
used as anchor frames in a pre-trained video diffusion model, which generates
novel views through a proposed spatial noise diffusion process. Compared to
prior work, our method produces globally consistent novel views -- even in loop
closure scenarios -- while enabling flexible camera control. Experiments on
diverse scene datasets demonstrate that our approach outperforms existing
methods in generating coherent views along user-defined trajectories. Our
implementation is available at https://github.com/YiGuYT/LookBeyond.

</details>


### [83] [Quantization Meets OOD: Generalizable Quantization-aware Training from a Flatness Perspective](https://arxiv.org/abs/2509.00859)
*Jiacheng Jiang,Yuan Meng,Chen Tang,Han Yu,Qun Li,Zhi Wang,Wenwu Zhu*

Main category: cs.CV

TL;DR: 量化感知训练（QAT）在提高模型在分布内（I.D）数据上的性能时，可能会损害其在分布外（OOD）数据上的泛化能力。本文提出了一种名为FQAT的面向平坦性的QAT方法，通过层级冻结机制和无序引导自适应冻结算法来解决这个问题，旨在实现可泛化的QAT。实验证明，FQAT在I.D和OOD图像分类任务上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的量化感知训练（QAT）方法主要关注在分布内（I.D）数据上的性能提升，但忽略了量化可能导致的分布外（OOD）数据性能下降问题。此外，量化感知训练（QAT）导致的损失平坦性与提高OOD泛化能力之间的矛盾，也是需要解决的关键问题。

Method: 提出了一种名为FQAT的面向平坦性的QAT方法。该方法包含两个关键部分：1) 层级冻结机制，用于缓解在普通QAT和提升平坦性这两个优化目标之间的梯度冲突；2) 无序引导自适应冻结算法，该算法通过梯度无序度量来动态确定在训练过程中哪些层需要被冻结，以解决层间干扰问题。

Result: 通过在有影响力的OOD基准数据集上的广泛实验，证明了FQAT方法在I.D和OOD图像分类任务上的性能优于最先进的基线方法。

Conclusion: FQAT方法通过引入层级冻结机制和无序引导自适应冻结算法，有效地解决了量化感知训练（QAT）在分布外（OOD）数据上性能下降的问题，实现了可泛化的QAT。

Abstract: Current quantization-aware training (QAT) methods primarily focus on
enhancing the performance of quantized models on in-distribution (I.D) data,
while overlooking the potential performance degradation on out-of-distribution
(OOD) data. In this paper, we first substantiate this problem through rigorous
experiment, showing that QAT can lead to a significant OOD generalization
performance degradation. Further, we find the contradiction between the
perspective that flatness of loss landscape gives rise to superior OOD
generalization and the phenomenon that QAT lead to a sharp loss landscape, can
cause the above problem. Therefore, we propose a flatness-oriented QAT method,
FQAT, to achieve generalizable QAT. Specifically, i) FQAT introduces a
layer-wise freezing mechanism to mitigate the gradient conflict issue between
dual optimization objectives (i.e., vanilla QAT and flatness). ii) FQAT
proposes an disorder-guided adaptive freezing algorithm to dynamically
determines which layers to freeze at each training step, effectively addressing
the challenges caused by interference between layers. A gradient disorder
metric is designed to help the algorithm identify unstable layers during
training. Extensive experiments on influential OOD benchmark demonstrate the
superiority of our method over state-of-the-art baselines under both I.D and
OOD image classification tasks.

</details>


### [84] [Pose as Clinical Prior: Learning Dual Representations for Scoliosis Screening](https://arxiv.org/abs/2509.00872)
*Zirui Zhou,Zizhao Peng,Dongyang Jin,Chao Fan,Fengwei An,Shiqi Yu*

Main category: cs.CV

TL;DR: AI 脊柱侧弯筛查方法通常依赖于大型轮廓数据集，但忽略了临床上重要的姿势不对称性。为了解决这个问题，研究人员提出了 Scoliosis1K-Pose 数据集和双表示框架 (DRF)。DRF 结合了连续骨骼图和离散姿势不对称向量 (PAV)，并通过 PGA 模块关注临床上重要的不对称性。


<details>
  <summary>Details</summary>
Motivation: 现有的 AI 脊柱侧弯筛查方法主要依赖大型轮廓数据集，忽视了临床上重要的姿势不对称性。而姿势数据能够提供直观的骨骼表示，增强临床可解释性。然而，姿势数据在脊柱侧弯筛查中的应用仍面临数据集稀缺和坐标数据离散、易受噪声干扰的问题。

Method: 研究人员创建了 Scoliosis1K-Pose 数据集，包含 1050 名青少年约 44.8 万帧的 2D 关键点数据。在此基础上，提出了双表示框架 (DRF)，该框架整合了保留空间结构的连续骨骼图和编码临床相关不对称描述符的离散姿势不对称向量 (PAV)。此外，还引入了 PGA 模块，利用 PAV 作为临床先验来指导骨骼图的特征提取。

Result: DRF 取得了最先进的性能，并且可视化结果表明该模型能够利用临床不对称线索来指导特征提取，并促进其双表示之间的协同作用。

Conclusion: Scoliosis1K-Pose 数据集和 DRF 框架为基于姿势的脊柱侧弯筛查提供了新的解决方案，能够有效捕捉和利用临床上重要的姿势不对称性，从而提高筛查性能。

Abstract: Recent AI-based scoliosis screening methods primarily rely on large-scale
silhouette datasets, often neglecting clinically relevant postural
asymmetries-key indicators in traditional screening. In contrast, pose data
provide an intuitive skeletal representation, enhancing clinical
interpretability across various medical applications. However, pose-based
scoliosis screening remains underexplored due to two main challenges: (1) the
scarcity of large-scale, annotated pose datasets; and (2) the discrete and
noise-sensitive nature of raw pose coordinates, which hinders the modeling of
subtle asymmetries. To address these limitations, we introduce
Scoliosis1K-Pose, a 2D human pose annotation set that extends the original
Scoliosis1K dataset, comprising 447,900 frames of 2D keypoints from 1,050
adolescents. Building on this dataset, we introduce the Dual Representation
Framework (DRF), which integrates a continuous skeleton map to preserve spatial
structure with a discrete Postural Asymmetry Vector (PAV) that encodes
clinically relevant asymmetry descriptors. A novel PAV-Guided Attention (PGA)
module further uses the PAV as clinical prior to direct feature extraction from
the skeleton map, focusing on clinically meaningful asymmetries. Extensive
experiments demonstrate that DRF achieves state-of-the-art performance.
Visualizations further confirm that the model leverages clinical asymmetry cues
to guide feature extraction and promote synergy between its dual
representations. The dataset and code are publicly available at
https://zhouzi180.github.io/Scoliosis1K/.

</details>


### [85] [Spotlighter: Revisiting Prompt Tuning from a Representative Mining View](https://arxiv.org/abs/2509.00905)
*Yutong Gao,Maoyuan Shao,Xinyang Huang,Chuang Zhu,Lijuan Sun,Yu Weng,Xuan Liu,Guoshun Nan*

Main category: cs.CV

TL;DR: Spotlighter是一种轻量级的 token 选择框架，通过评估和筛选 token 来提高 prompt tuning 的准确性和效率，并在多个少样本基准测试中优于 CLIP。


<details>
  <summary>Details</summary>
Motivation: CLIP 在跨模态语义对齐方面表现出色，但冗余或弱相关性特征会引入噪声并增加计算成本。

Method: Spotlighter 评估每个视觉 token 的样本级和语义级激活，只保留得分最高的 token 进行下游预测。它还利用一个类特定的语义记忆库来优化 token 选择，并通过一个两级排名机制来动态加权 token-与原型的交互。

Result: Spotlighter 在 11 个少样本基准测试中，在调和平均准确率方面比 CLIP 高出 11.19%，同时实现了高达 0.8K 的额外 FPS，并且只增加了 21 个参数。

Conclusion: Spotlighter 是一种有效的、可扩展的 prompt tuning 基线方法。

Abstract: CLIP's success has demonstrated that prompt tuning can achieve robust
cross-modal semantic alignment for tasks ranging from open-domain recognition
to fine-grained classification. However, redundant or weakly relevant feature
components introduce noise and incur unnecessary computational costs. In this
work, we propose Spotlighter, a lightweight token-selection framework that
simultaneously enhances accuracy and efficiency in prompt tuning. Spotlighter
evaluates each visual token's activation from both sample-wise and
semantic-wise perspectives and retains only the top-scoring tokens for
downstream prediction. A class-specific semantic memory bank of learned
prototypes refines this selection, ensuring semantic representativeness and
compensating for discarded features. To further prioritize informative signals,
we introduce a two-level ranking mechanism that dynamically weights
token--prototype interactions. Across 11 few-shot benchmarks, Spotlighter
outperforms CLIP by up to 11.19\% in harmonic mean accuracy and achieves up to
0.8K additional FPS, with only 21 extra parameters. These results establish
Spotlighter as an effective and scalable baseline for prompt tuning. Code for
our method will be available at
https://github.com/greatest-gourmet/Spotlighter.

</details>


### [86] [DarkVRAI: Capture-Condition Conditioning and Burst-Order Selective Scan for Low-light RAW Video Denoising](https://arxiv.org/abs/2509.00917)
*Youngjin Oh,Junhyeong Kwon,Junyoung Park,Nam Ik Cho*

Main category: cs.CV

TL;DR: DarkVRAI是一个用于低光RAW视频去噪的新框架，通过利用捕获元数据和先进的时间建模技术，在AIM 2025低光RAW视频去噪挑战赛中获得第一名。


<details>
  <summary>Details</summary>
Motivation: 低光RAW视频去噪是一个难题，因为高传感器增益和短曝光时间会导致严重的信号退化，这受到视频帧率要求的限制。

Method: 提出了一种名为DarkVRAI的新框架，其主要贡献包括：1. 将图像去噪中的条件机制应用于视频去噪，以指导对齐和去噪过程；2. 引入了突发顺序选择扫描（BOSS）机制，以有效建模视频序列中的长程时间依赖性。

Result: DarkVRAI在严格且真实的基准数据集上展示了最先进的性能，为低光视频去噪设定了新标准。

Conclusion: DarkVRAI通过结合条件机制和BOSS机制，成功解决了低光RAW视频去噪的挑战，并在AIM 2025竞赛中取得了优异成绩。

Abstract: Low-light RAW video denoising is a fundamentally challenging task due to
severe signal degradation caused by high sensor gain and short exposure times,
which are inherently limited by video frame rate requirements. To address this,
we propose DarkVRAI, a novel framework that achieved first place in the AIM
2025 Low-light RAW Video Denoising Challenge. Our method introduces two primary
contributions: (1) a successful application of a conditioning scheme for image
denoising, which explicitly leverages capture metadata, to video denoising to
guide the alignment and denoising processes, and (2) a Burst-Order Selective
Scan (BOSS) mechanism that effectively models long-range temporal dependencies
within the noisy video sequence. By synergistically combining these components,
DarkVRAI demonstrates state-of-the-art performance on a rigorous and realistic
benchmark dataset, setting a new standard for low-light video denoising.

</details>


### [87] [IPG: Incremental Patch Generation for Generalized Adversarial Patch Training](https://arxiv.org/abs/2508.10946)
*Wonho Lee,Hyunsik Na,Jisu Lee,Daeseon Choi*

Main category: cs.CV

TL;DR: 该研究提出了一种名为增量补丁生成（IPG）的新方法，用于生成对抗性补丁，以提高AI模型（特别是在目标检测等计算机视觉任务中）的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的对抗性示例和补丁对AI模型的鲁棒性构成了重大挑战，特别是在计算机视觉领域。需要更有效的方法来生成能够应对这些威胁的补丁。

Method: 提出增量补丁生成（IPG）方法，该方法比现有方法生成对抗性补丁的效率高出11.1倍，同时保持可比的攻击性能。通过实验和消融研究（包括YOLO特征分布可视化和对抗性训练结果）来证明其有效性。

Result: IPG生成了泛化性好、能有效覆盖更广泛模型漏洞的补丁。使用IPG生成的数据集可以作为构建鲁棒模型的坚实知识基础，从而在AI安全生态系统中实现结构化表示、高级推理和主动防御。

Conclusion: IPG在对抗性补丁防御以及自动驾驶汽车、安全系统和医学成像等实际应用中具有巨大的潜力，这些应用要求AI模型在动态和高风险环境中能够抵御对抗性攻击。

Abstract: The advent of adversarial patches poses a significant challenge to the
robustness of AI models, particularly in the domain of computer vision tasks
such as object detection. In contradistinction to traditional adversarial
examples, these patches target specific regions of an image, resulting in the
malfunction of AI models. This paper proposes Incremental Patch Generation
(IPG), a method that generates adversarial patches up to 11.1 times more
efficiently than existing approaches while maintaining comparable attack
performance. The efficacy of IPG is demonstrated by experiments and ablation
studies including YOLO's feature distribution visualization and adversarial
training results, which show that it produces well-generalized patches that
effectively cover a broader range of model vulnerabilities. Furthermore,
IPG-generated datasets can serve as a robust knowledge foundation for
constructing a robust model, enabling structured representation, advanced
reasoning, and proactive defenses in AI security ecosystems. The findings of
this study suggest that IPG has considerable potential for future utilization
not only in adversarial patch defense but also in real-world applications such
as autonomous vehicles, security systems, and medical imaging, where AI models
must remain resilient to adversarial attacks in dynamic and high-stakes
environments.

</details>


### [88] [Seeing More, Saying More: Lightweight Language Experts are Dynamic Video Token Compressors](https://arxiv.org/abs/2509.00969)
*Xiangchen Wang,Jinrui Zhang,Teng Wang,Haigang Zhang,Feng Zheng*

Main category: cs.CV

TL;DR: LangDC通过利用轻量级语言模型动态压缩视频tokens，解决了现有模型处理高容量视觉tokens的效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型在处理高容量视觉tokens时效率低下，并且现有的token压缩策略忽视了不同视频片段间语义密度的差异性，导致信息丰富的片段表示不足，而内容贫乏的片段计算冗余。

Method: 提出LangDC（Language-aware Dynamic Token Compressor），利用轻量级语言模型生成视频片段的软标题tokens作为视觉表示，并结合语义密度感知监督，动态调整压缩率，以覆盖下游任务推理所需的关键视觉线索。

Result: LangDC相比VideoGPT+减少了49%的计算量（FLOPs），同时保持了具有竞争力的性能。定性结果表明，LangDC能够根据视频片段的丰富程度自适应地调整token压缩率。

Conclusion: LangDC通过动态、语言感知的token压缩，显著提高了视频语言模型的效率，并能根据视频内容自适应调整压缩策略。

Abstract: Recent advancements in large video-language models have revolutionized video
understanding tasks. However, their efficiency is significantly constrained by
processing high volumes of visual tokens. Existing token compression strategies
apply a fixed compression ratio, ignoring the variability in semantic density
among different video clips. Consequently, this lead to inadequate
representation of information-rich clips due to insufficient tokens and
unnecessary computation on static or content-poor ones. To address this, we
propose LangDC, a Language-aware Dynamic Token Compressor. LangDC leverages a
lightweight language model to describe video clips, converting them into soft
caption tokens as visual representations. Trained with our proposed semantic
density-aware supervision, LangDC aims to 1) cover key visual cues necessary
for downstream task reasoning and 2) dynamically adjust compression ratios
based on scene richness, reflected by descriptions length. Our design mimics
how humans dynamically express what they see: complex scenes (seeing more)
elicit more detailed language to convey nuances (saying more), whereas simpler
scenes are described with fewer words. Experimental results show that our
method reduces FLOPs by 49% compared to VideoGPT+ while maintaining competitive
performance. Furthermore, qualitative results demonstrate our approach
adaptively adjusts the token compression ratio based on video segment richness.

</details>


### [89] [Towards Integrating Multi-Spectral Imaging with Gaussian Splatting](https://arxiv.org/abs/2509.00989)
*Josef Grün,Lukas Meyer,Maximilian Weiherer,Bernhard Egger,Marc Stamminger,Linus Franke*

Main category: cs.CV

TL;DR: 本研究将彩色（RGB）和多光谱（红、绿、红边、近红外）影像集成到3D高斯喷涂（3DGS）框架中，以实现高质量的3D重建。


<details>
  <summary>Details</summary>
Motivation: 虽然3DGS在RGB数据上表现出色，但直接优化多光谱数据会导致重建效果不佳，即使几何形状相同。本研究旨在解决这个问题。

Method: 研究了三种策略：1) 单独的每波段重建（无共享结构）；2) 分割优化（先优化RGB几何，然后拟合新波段）；3) 联合优化（联合优化所有波段，可选择性地先进行RGB优化）。

Result: 联合优化策略在提高多光谱重建质量和增强RGB结果方面效果显著，并通过定量指标和定性渲染进行了展示。

Conclusion: 建议将多光谱数据直接集成到球谐函数的颜色分量中，以紧凑地建模每个高斯的が多光谱反射率。研究还揭示了在优化过程中引入光谱波段的时机和方式的权衡，为鲁棒的多模态3DGS重建提供了实践见解。

Abstract: We present a study of how to integrate color (RGB) and multi-spectral imagery
(red, green, red-edge, and near-infrared) into the 3D Gaussian Splatting (3DGS)
framework, a state-of-the-art explicit radiance-field-based method for fast and
high-fidelity 3D reconstruction from multi-view images. While 3DGS excels on
RGB data, naive per-band optimization of additional spectra yields poor
reconstructions due to inconsistently appearing geometry in the spectral
domain. This problem is prominent, even though the actual geometry is the same,
regardless of spectral modality. To investigate this, we evaluate three
strategies: 1) Separate per-band reconstruction with no shared structure. 2)
Splitting optimization, in which we first optimize RGB geometry, copy it, and
then fit each new band to the model by optimizing both geometry and band
representation. 3) Joint, in which the modalities are jointly optimized,
optionally with an initial RGB-only phase. We showcase through quantitative
metrics and qualitative novel-view renderings on multi-spectral datasets the
effectiveness of our dedicated optimized Joint strategy, increasing overall
spectral reconstruction as well as enhancing RGB results through spectral
cross-talk. We therefore suggest integrating multi-spectral data directly into
the spherical harmonics color components to compactly model each Gaussian's
multi-spectral reflectance. Moreover, our analysis reveals several key
trade-offs in when and how to introduce spectral bands during optimization,
offering practical insights for robust multi-modal 3DGS reconstruction.

</details>


### [90] [Weather-Dependent Variations in Driver Gaze Behavior: A Case Study in Rainy Conditions](https://arxiv.org/abs/2509.01013)
*Ghazal Farhani,Taufiq Rahman,Dominique Charlebois*

Main category: cs.CV

TL;DR: 雨天行车会增加交通事故风险，研究驾驶员在雨天下的注视行为对于设计驾驶员监控系统（DMS）和高级驾驶辅助系统（ADAS）至关重要。本研究通过聚类分析和马尔可夫转移矩阵等方法，对比了同一驾驶员在晴天和雨天驾驶同一路线时的注视行为。结果显示，雨天条件下驾驶员会更频繁地查看仪表盘，更长时间地注视，并且视线更高，表明认知负荷增加。这些发现为了解恶劣条件下的视觉注意力模式提供了有价值的见解，并强调了利用注视模型来设计更可靠的ADAS和DMS的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究驾驶员在雨天行车时的视觉感知和注视行为变化，以改进驾驶员监控系统（DMS）和高级驾驶辅助系统（ADAS）的设计。

Method: 采用两步聚类方法分析驾驶员的注视行为：首先对10秒内的注视点进行聚类，然后将聚类中心聚合成元聚类。结合马尔可夫转移矩阵、注视时长、注视高低和方位分布等指标，揭示行为变化。

Result: 与晴天相比，雨天条件下驾驶员更频繁地查看仪表盘，注视时间更长，注视点更高，表明其认知负荷增加，但总体注视道路和偶尔查看后视镜的行为模式保持一致。

Conclusion: 驾驶员在雨天行车时会调整其注视行为以应对视觉感知挑战，表现出更高的认知关注度。这些发现可用于改进ADAS和DMS的设计，以提高驾驶安全。

Abstract: Rainy weather significantly increases the risk of road accidents due to
reduced visibility and vehicle traction. Understanding how experienced drivers
adapt their visual perception through gaze behavior under such conditions is
critical for designing robust driver monitoring systems (DMS) and for informing
advanced driver assistance systems (ADAS). This case study investigates the eye
gaze behavior of a driver operating the same highway route under both clear and
rainy conditions. To this end, gaze behavior was analyzed by a two-step
clustering approach: first, clustering gaze points within 10-second intervals,
and then aggregating cluster centroids into meta-clusters. This, along with
Markov transition matrices and metrics such as fixation duration, gaze
elevation, and azimuth distributions, reveals meaningful behavioral shifts.
While the overall gaze behavior focused on the road with occasional mirror
checks remains consistent, rainy conditions lead to more frequent dashboard
glances, longer fixation durations, and higher gaze elevation, indicating
increased cognitive focus. These findings offer valuable insight into visual
attention patterns under adverse conditions and highlight the potential of
leveraging gaze modeling to aid in the design of more robust ADAS and DMS.

</details>


### [91] [AI-driven Dispensing of Coral Reseeding Devices for Broad-scale Restoration of the Great Barrier Reef](https://arxiv.org/abs/2509.01019)
*Scarlett Raine,Benjamin Moshirian,Tobias Fischer*

Main category: cs.CV

TL;DR: 珊瑚礁面临崩溃，自动化和人工智能在珊瑚礁恢复中至关重要。该研究提出了一种利用人工智能、计算机视觉和机器人技术实现珊瑚礁恢复设备的自动化部署。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化、海洋酸化和污染，珊瑚礁正濒临崩溃，预计在未来十年内将损失 70-90% 的珊瑚物种。珊瑚礁恢复工作至关重要，但其成功依赖于自动化以扩大规模。

Method: 该研究提出并实现了珊瑚礁恢复设备的自动化部署，该设备由人工智能、计算机视觉和机器人技术提供支持。具体来说，该研究进行了自动化的海底地貌分类，能够检测适合珊瑚生长的海域，从而显著减少对人类专家的依赖，并扩大恢复的范围和效率。

Result: 在真实世界中对大堡礁的算法进行测试，部署准确率为 77.8%，子图像斑块分类准确率为 89.1%，实时模型推理速度为 5.5 帧/秒。

Conclusion: 该研究提出的自动化珊瑚礁恢复方法在大堡礁的实际测试中取得了显著成效，证明了其在减少对专家依赖、提高恢复效率和扩大恢复范围方面的潜力。此外，该研究还公开了一个包含标注珊瑚礁地貌图像的大型数据集，以促进该领域的未来研究。

Abstract: Coral reefs are on the brink of collapse, with climate change, ocean
acidification, and pollution leading to a projected 70-90% loss of coral
species within the next decade. Restoration efforts are crucial, but their
success hinges on introducing automation to upscale efforts. We present
automated deployment of coral re-seeding devices powered by artificial
intelligence, computer vision, and robotics. Specifically, we perform automated
substrate classification, enabling detection of areas of the seafloor suitable
for coral growth, thus significantly reducing reliance on human experts and
increasing the range and efficiency of restoration. Real-world testing of the
algorithms on the Great Barrier Reef leads to deployment accuracy of 77.8%,
sub-image patch classification of 89.1%, and real-time model inference at 5.5
frames per second. Further, we present and publicly contribute a large
collection of annotated substrate image data to foster future research in this
area.

</details>


### [92] [CompSlider: Compositional Slider for Disentangled Multiple-Attribute Image Generation](https://arxiv.org/abs/2509.01028)
*Zixin Zhu,Kevin Duarte,Mamshad Nayeem Rizve,Chengyuan Xu,Ratheesh Kalarot,Junsong Yuan*

Main category: cs.CV

TL;DR: CompSlider 通过解耦 T2I 生成中的多个属性来解决属性间的相互干扰问题，实现了更可靠、更独立的属性操控。


<details>
  <summary>Details</summary>
Motivation: 现有基于滑块的方法为 T2I 生成中的属性控制提供了一种精确控制的解决方案，但它们通常为每个属性单独训练适配器，忽略了多属性之间的相互依赖性，导致在同时操控多个属性时出现干扰，无法精确控制。

Method: CompSlider 旨在解耦滑块生成中的多个属性，以实现更可靠和独立的属性操控。我们的方法 CompSlider 可以为 T2I 基础模型生成条件先验，以同时控制多个属性。此外，我们引入了新颖的解耦和结构损失，以组合多个属性更改，同时在图像内保持结构一致性。由于 CompSlider 在条件先验的潜在空间中运行，并且不需要重新训练基础模型，因此它降低了训练和推理的计算负担。

Result: CompSlider 在多种图像属性上进行了评估，并通过扩展到视频生成来强调其通用性。

Conclusion: CompSlider 是一种有效的方法，可以解耦 T2I 生成中的多个属性，从而实现更可靠和独立的属性操控，同时保持结构一致性。

Abstract: In text-to-image (T2I) generation, achieving fine-grained control over
attributes - such as age or smile - remains challenging, even with detailed
text prompts. Slider-based methods offer a solution for precise control of
image attributes. Existing approaches typically train individual adapter for
each attribute separately, overlooking the entanglement among multiple
attributes. As a result, interference occurs among different attributes,
preventing precise control of multiple attributes together. To address this
challenge, we aim to disentangle multiple attributes in slider-based generation
to enbale more reliable and independent attribute manipulation. Our approach,
CompSlider, can generate a conditional prior for the T2I foundation model to
control multiple attributes simultaneously. Furthermore, we introduce novel
disentanglement and structure losses to compose multiple attribute changes
while maintaining structural consistency within the image. Since CompSlider
operates in the latent space of the conditional prior and does not require
retraining the foundation model, it reduces the computational burden for both
training and inference. We evaluate our approach on a variety of image
attributes and highlight its generality by extending to video generation.

</details>


### [93] [Seeing through Unclear Glass: Occlusion Removal with One Shot](https://arxiv.org/abs/2509.01033)
*Qiang Li,Yuanming Cao*

Main category: cs.CV

TL;DR: 该论文提出了一种新的模型，用于处理透过受污染玻璃拍摄的图像，解决了污垢、泥水等多种污点问题。该模型采用了一次性测试时自适应机制和自监督辅助学习任务，能够有效去除各种类型的污垢，并且在处理未见过或现实场景的污染图像方面表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决透过受污染玻璃拍摄的图像质量下降问题，特别是现实世界中存在的多种污点，如泥水、污垢等，而现有方法大多依赖合成数据或只处理雨滴等有限污点。

Method: 提出了一种“all-in-one”模型，利用一次性测试时自适应（one-shot test-time adaptation）机制来处理不同类型的污垢。该模型包含一个自监督辅助学习任务，用于更新模型以适应每个测试图像独特的污垢类型。

Result: 实验结果表明，所提出的方法在清理现实污染图像方面，无论是在定量还是定性上，都优于现有的最先进方法，尤其在处理未见过的污垢类型时效果更佳。

Conclusion: 该方法能够有效且泛化地处理各种现实场景下的玻璃污垢问题，通过自适应学习机制提高了图像恢复的准确性和鲁棒性。

Abstract: Images taken through window glass are often degraded by contaminants adhered
to the glass surfaces. Such contaminants cause occlusions that attenuate the
incoming light and scatter stray light towards the camera. Most of existing
deep learning methods for neutralizing the effects of contaminated glasses
relied on synthetic training data. Few researchers used real degraded and clean
image pairs, but they only considered removing or alleviating the effects of
rain drops on glasses. This paper is concerned with the more challenging task
of learning the restoration of images taken through glasses contaminated by a
wide range of occluders, including muddy water, dirt and other small foreign
particles found in reality. To facilitate the learning task we have gone to a
great length to acquire real paired images with and without glass contaminants.
More importantly, we propose an all-in-one model to neutralize contaminants of
different types by utilizing the one-shot test-time adaptation mechanism. It
involves a self-supervised auxiliary learning task to update the trained model
for the unique occlusion type of each test image. Experimental results show
that the proposed method outperforms the state-of-the-art methods
quantitatively and qualitatively in cleaning realistic contaminated images,
especially the unseen ones.

</details>


### [94] [A Unified Low-level Foundation Model for Enhancing Pathology Image Quality](https://arxiv.org/abs/2509.01071)
*Ziyi Liu,Zhe Xu,Jiabo Ma,Wenqaing Li,Junlin Hou,Fuxiang Huang,Xi Wang,Ronald Cheong Kin Chan,Terence Tsz Wai Wong,Hao Chen*

Main category: cs.CV

TL;DR: 该论文提出了首个统一的低级病理图像基础模型 (LPFM)，用于处理噪声、模糊、低分辨率等图像退化问题，并实现虚拟染色等图像翻译任务。该模型通过对比预训练编码器学习可迁移、与染色无关的特征表示，并利用统一的条件扩散过程适应特定任务。LPFM 在大部分任务（56/66）上显著优于现有方法，图像恢复任务的 PSNR 提升 10-15%，虚拟染色任务的 SSIM 提升 12-18%。


<details>
  <summary>Details</summary>
Motivation: 解决计算病理学中低级图像增强（如去噪、去模糊、超分辨率）和虚拟染色等任务的挑战，现有方法通常是任务特定的，缺乏通用性。

Method: 提出首个统一的低级病理基础模型 (LPFM)，该模型包含一个对比预训练编码器，从大量未标记的病理图像中学习与染色无关的特征表示，以及一个统一的条件扩散过程，通过文本提示动态适应超分辨率、去模糊、去噪和虚拟染色等任务。

Result: LPFM 在 66 个任务中的 56 个任务上取得了统计学上显著的改进 (p<0.01)，其性能优于最先进的方法。在图像恢复任务中，PSNR 提高了 10-15%；在虚拟染色任务中，SSIM 提高了 12-18%。

Conclusion: LPFM 作为一个统一的低级病理基础模型，能够有效地处理各种低级视觉挑战，并在图像恢复和虚拟染色方面取得显著的性能提升，为计算病理学领域提供了一个更通用、更强大的解决方案。

Abstract: Foundation models have revolutionized computational pathology by achieving
remarkable success in high-level diagnostic tasks, yet the critical challenge
of low-level image enhancement remains largely unaddressed. Real-world
pathology images frequently suffer from degradations such as noise, blur, and
low resolution due to slide preparation artifacts, staining variability, and
imaging constraints, while the reliance on physical staining introduces
significant costs, delays, and inconsistency. Although existing methods target
individual problems like denoising or super-resolution, their task-specific
designs lack the versatility to handle the diverse low-level vision challenges
encountered in practice. To bridge this gap, we propose the first unified
Low-level Pathology Foundation Model (LPFM), capable of enhancing image quality
in restoration tasks, including super-resolution, deblurring, and denoising, as
well as facilitating image translation tasks like virtual staining (H&E and
special stains), all through a single adaptable architecture. Our approach
introduces a contrastive pre-trained encoder that learns transferable,
stain-invariant feature representations from 190 million unlabeled pathology
images, enabling robust identification of degradation patterns. A unified
conditional diffusion process dynamically adapts to specific tasks via textual
prompts, ensuring precise control over output quality. Trained on a curated
dataset of 87,810 whole slied images (WSIs) across 34 tissue types and 5
staining protocols, LPFM demonstrates statistically significant improvements
(p<0.01) over state-of-the-art methods in most tasks (56/66), achieving Peak
Signal-to-Noise Ratio (PSNR) gains of 10-15% for image restoration and
Structural Similarity Index Measure (SSIM) improvements of 12-18% for virtual
staining.

</details>


### [95] [SpectMamba: Integrating Frequency and State Space Models for Enhanced Medical Image Detection](https://arxiv.org/abs/2509.01080)
*Yao Wang,Dong Yang,Zhi Qiao,Wenjian Huang,Liuzhi Yang,Zhen Qian*

Main category: cs.CV

TL;DR: SpectMamba是一种基于Mamba的医学图像异常检测新架构，通过混合空间-频率注意力（HSFA）和视觉状态空间模块（VSSM）结合希尔伯特曲线扫描技术，有效解决了CNN感受野有限和Transformer计算成本高的问题，在提高检测精度和效率方面取得了先进水平。


<details>
  <summary>Details</summary>
Motivation: 目前的医学图像异常检测模型，如CNN和Transformer，存在感受野有限或计算成本高的问题，限制了它们在处理高分辨率医学图像时的效率和准确性。Mamba模型因其处理长序列的线性复杂度而备受关注，为解决这些挑战提供了新的可能性。

Method: 提出了一种名为SpectMamba的新型Mamba架构，用于医学图像异常检测。该架构包含混合空间-频率注意力（HSFA）块，能够分别学习高频和低频特征，减少频率偏差导致的高频信息丢失，并将频域特征与空间特征关联，以增强模型捕捉全局上下文的能力。此外，还提出了视觉状态空间模块（VSSM）和希尔伯特曲线扫描技术，以增强长程依赖、空间相关性和局部依赖性，优化Mamba框架。

Result: 实验结果表明，SpectMamba在多种医学图像检测任务中取得了先进水平的性能，并且在有效性和效率方面表现出色。

Conclusion: SpectMamba作为首个基于Mamba的医学图像检测架构，通过其创新的HSFA块和VSSM模块结合希尔伯特曲线扫描技术，成功克服了现有模型的局限性，实现了高精度和高效率的医学图像异常检测。

Abstract: Abnormality detection in medical imaging is a critical task requiring both
high efficiency and accuracy to support effective diagnosis. While
convolutional neural networks (CNNs) and Transformer-based models are widely
used, both face intrinsic challenges: CNNs have limited receptive fields,
restricting their ability to capture broad contextual information, and
Transformers encounter prohibitive computational costs when processing
high-resolution medical images. Mamba, a recent innovation in natural language
processing, has gained attention for its ability to process long sequences with
linear complexity, offering a promising alternative. Building on this
foundation, we present SpectMamba, the first Mamba-based architecture designed
for medical image detection. A key component of SpectMamba is the Hybrid
Spatial-Frequency Attention (HSFA) block, which separately learns high- and
low-frequency features. This approach effectively mitigates the loss of
high-frequency information caused by frequency bias and correlates
frequency-domain features with spatial features, thereby enhancing the model's
ability to capture global context. To further improve long-range dependencies,
we propose the Visual State-Space Module (VSSM) and introduce a novel Hilbert
Curve Scanning technique to strengthen spatial correlations and local
dependencies, further optimizing the Mamba framework. Comprehensive experiments
show that SpectMamba achieves state-of-the-art performance while being both
effective and efficient across various medical image detection tasks.

</details>


### [96] [Bidirectional Sparse Attention for Faster Video Diffusion Training](https://arxiv.org/abs/2509.01085)
*Chenlu Zhan,Wen Li,Chuyu Shen,Jun Zhang,Suhui Wu,Hao Zhang*

Main category: cs.CV

TL;DR: 视频扩散Transformer（DiT）模型在生成质量方面表现出色，但在生成高分辨率、长时视频时面临主要的计算瓶颈。通过提出一种双向稀疏注意力（BSA）框架，该框架首次动态地稀疏化3D全注意力中的查询和键值对，从而显著提高了训练和推理效率，解决了计算效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散Transformer（DiT）模型在生成高质量视频方面表现优异，但在生成高分辨率、长时视频时存在计算瓶颈，主要是由于全注意力机制的二次复杂性导致训练和推理成本过高。这是由查询和键值对的固有稀疏性以及固定的稀疏模式无法利用DiT动态注意力所造成的冗余计算引起的。

Method: 提出了一种双向稀疏注意力（BSA）框架，该框架通过两个关键组件来动态地稀疏化查询（Q）和键值对（KV）。查询稀疏性通过选择信息量最丰富的查询令牌（基于语义相似性）并采用动态时空训练策略来优化；键值稀疏性通过计算统计动态阈值来仅保留最显著的键值块进行计算。

Result: 实验证明，BSA框架显著加速了DiT在长序列上的训练，将计算量（FLOPs）降低了高达20倍，注意力训练速度提高了17.79倍，同时保持甚至超越了全注意力机制的生成质量。

Conclusion: 双向稀疏注意力（BSA）框架是一种有效的解决方案，可以显著提高视频扩散Transformer（DiT）模型在处理高分辨率、长时视频时的训练和推理效率，同时保持或提升生成质量。

Abstract: Video diffusion Transformer (DiT) models excel in generative quality but hit
major computational bottlenecks when producing high-resolution, long-duration
videos. The quadratic complexity of full attention leads to prohibitively high
training and inference costs. Full attention inefficiency stems from two key
challenges: excessive computation due to the inherent sparsity of Queries and
Key-Value pairs, and redundant computation as fixed sparse patterns fail to
leverage DiT's dynamic attention. To overcome this limitation, we propose a
Bidirectional Sparse Attention (BSA) framework for faster video DiT training,
the first to dynamically sparsify both Queries and Key-Value pairs within 3D
full attention, thereby substantially improving training and inference
efficiency. BSA addresses these issues through two key components. Query
sparsity is optimized by selecting the most informative query tokens via
semantic similarity and with a dynamic spatial-time training strategy, while KV
sparsity is achieved by computing a statistical dynamic threshold to retain
only the most salient KV blocks for computation. Extensive experiments
demonstrate that BSA significantly accelerates DiT training across long
sequences, reducing FLOPs by up to 20x and achieving 17.79x faster attention
training, while preserving or even surpassing the generative quality of full
attention.

</details>


### [97] [An End-to-End Framework for Video Multi-Person Pose Estimation](https://arxiv.org/abs/2509.01095)
*Zhihong Wei*

Main category: cs.CV

TL;DR: VEPE是一个用于视频端到端姿态估计的框架，利用时空Transformer组件和实例一致性机制，在Posetrack数据集上实现了优于两阶段模型和300%的推理效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频人体姿态估计方法将空间和时间维度分离，无法进行端到端优化，并且依赖于复杂的后处理，降低了推理效率。

Method: 提出VEPE框架，包含时空姿态编码器（STPE）、时空可变形记忆编码器（STDME）和时空姿态解码器（STPD），并引入实例一致性机制来解决跨帧姿态查询匹配问题。

Result: 在Posetrack数据集上的实验表明，VEPE的性能优于大多数两阶段模型，并将推理效率提高了300%。

Conclusion: VEPE是一个简单灵活的框架，能够有效利用时间上下文优化人体姿态估计，并提高推理效率。

Abstract: Video-based human pose estimation models aim to address scenarios that cannot
be effectively solved by static image models such as motion blur, out-of-focus
and occlusion. Most existing approaches consist of two stages: detecting human
instances in each image frame and then using a temporal model for single-person
pose estimation. This approach separates the spatial and temporal dimensions
and cannot capture the global spatio-temporal context between spatial instances
for end-to-end optimization. In addition, it relies on separate detectors and
complex post-processing such as RoI cropping and NMS, which reduces the
inference efficiency of the video scene. To address the above problems, we
propose VEPE (Video End-to-End Pose Estimation), a simple and flexible
framework for end-to-end pose estimation in video. The framework utilizes three
crucial spatio-temporal Transformer components: the Spatio-Temporal Pose
Encoder (STPE), the Spatio-Temporal Deformable Memory Encoder (STDME), and the
Spatio-Temporal Pose Decoder (STPD). These components are designed to
effectively utilize temporal context for optimizing human body pose estimation.
Furthermore, to reduce the mismatch problem during the cross-frame pose query
matching process, we propose an instance consistency mechanism, which aims to
enhance the consistency and discrepancy of the cross-frame instance query and
realize the instance tracking function, which in turn accurately guides the
pose query to perform cross-frame matching. Extensive experiments on the
Posetrack dataset show that our approach outperforms most two-stage models and
improves inference efficiency by 300%.

</details>


### [98] [PVINet: Point-Voxel Interlaced Network for Point Cloud Compression](https://arxiv.org/abs/2509.01097)
*Xuan Deng,Xingtao Wang,Xiandong Meng,Xiaopeng Fan,Debin Zhao*

Main category: cs.CV

TL;DR: PVINet使用点-体素交错网络并行提取全局结构和局部上下文特征，并通过条件稀疏卷积促进特征交互，以提高点云重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理点云时，通常按顺序处理全局和局部信息，缺乏两者之间的通信，导致重建质量受损。

Method: 提出了一种点-体素交错网络（PVINet），包含用于提取全局结构特征的体素编码器（Ev）和用于建模局部上下文的点编码器（Ep）。引入了条件稀疏卷积，将点嵌入应用于动态定制体素特征提取的卷积核，促进了Ep到Ev的特征交互。在解码阶段，体素解码器使用条件稀疏卷积并结合点嵌入来指导点云重建。

Result: 在基准数据集上的实验表明，PVINet与最先进的方法相比具有竞争力。

Conclusion: PVINet通过并行处理和增强特征交互，提高了点云重建质量。

Abstract: In point cloud compression, the quality of a reconstructed point cloud relies
on both the global structure and the local context, with existing methods
usually processing global and local information sequentially and lacking
communication between these two types of information. In this paper, we propose
a point-voxel interlaced network (PVINet), which captures global structural
features and local contextual features in parallel and performs interactions at
each scale to enhance feature perception efficiency. Specifically, PVINet
contains a voxel-based encoder (Ev) for extracting global structural features
and a point-based encoder (Ep) that models local contexts centered at each
voxel. Particularly, a novel conditional sparse convolution is introduced,
which applies point embeddings to dynamically customize kernels for voxel
feature extraction, facilitating feature interactions from Ep to Ev. During
decoding, a voxel-based decoder employs conditional sparse convolutions to
incorporate point embeddings as guidance to reconstruct the point cloud.
Experiments on benchmark datasets show that PVINet delivers competitive
performance compared to state-of-the-art methods.

</details>


### [99] [FICGen: Frequency-Inspired Contextual Disentanglement for Layout-driven Degraded Image Generation](https://arxiv.org/abs/2509.01107)
*Wenzhuang Wang,Yifan Zhao,Mingcan Ma,Ming Liu,Zhonglin Jiang,Yong Chen,Jia Li*

Main category: cs.CV

TL;DR: FICGen是一种新的生成模型，用于在退化场景（如低光照、水下）中生成图像，通过解耦上下文和频率信息来提高生成保真度和与布局的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有布局到图像（L2I）生成方法在退化场景下存在生成保真度低和与用户布局对齐弱的问题，主要是由于“上下文幻觉困境”，即前景实例被以上下文为主的频率分布所淹没。

Method: FICGen首先引入一个可学习的双查询机制，并配有专门的频率重采样器，从训练集中收集的退化样本中提取上下文频率原型。然后，使用视觉-频率增强注意力将频率原型注入退化生成过程。为了缓解上下文幻觉和属性泄漏，开发了一个实例连贯性图来规范实例与其周围环境之间的潜在空间解耦，并结合自适应空间-频率聚合模块来重建空间-频率混合的退化表示。

Result: FICGen在5个基准测试中，涵盖了从严重低光照到轻微模糊的各种退化场景，其生成保真度、对齐度和下游辅助可训练性均持续优于现有的L2I方法。

Conclusion: FICGen通过频率启发的上下文解耦，有效解决了退化场景下L2I的“上下文幻觉困境”，显著提高了生成图像的质量和与布局的匹配度。

Abstract: Layout-to-image (L2I) generation has exhibited promising results in natural
domains, but suffers from limited generative fidelity and weak alignment with
user-provided layouts when applied to degraded scenes (i.e., low-light,
underwater). We primarily attribute these limitations to the "contextual
illusion dilemma" in degraded conditions, where foreground instances are
overwhelmed by context-dominant frequency distributions. Motivated by this, our
paper proposes a new Frequency-Inspired Contextual Disentanglement Generative
(FICGen) paradigm, which seeks to transfer frequency knowledge of degraded
images into the latent diffusion space, thereby facilitating the rendering of
degraded instances and their surroundings via contextual frequency-aware
guidance. To be specific, FICGen consists of two major steps. Firstly, we
introduce a learnable dual-query mechanism, each paired with a dedicated
frequency resampler, to extract contextual frequency prototypes from
pre-collected degraded exemplars in the training set. Secondly, a
visual-frequency enhanced attention is employed to inject frequency prototypes
into the degraded generation process. To alleviate the contextual illusion and
attribute leakage, an instance coherence map is developed to regulate
latent-space disentanglement between individual instances and their
surroundings, coupled with an adaptive spatial-frequency aggregation module to
reconstruct spatial-frequency mixed degraded representations. Extensive
experiments on 5 benchmarks involving a variety of degraded scenarios-from
severe low-light to mild blur-demonstrate that FICGen consistently surpasses
existing L2I methods in terms of generative fidelity, alignment and downstream
auxiliary trainability.

</details>


### [100] [TransForSeg: A Multitask Stereo ViT for Joint Stereo Segmentation and 3D Force Estimation in Catheterization](https://arxiv.org/abs/2509.01605)
*Pedram Fekri,Mehrdad Zadeh,Javad Dargahi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recently, the emergence of multitask deep learning models has enhanced
catheterization procedures by providing tactile and visual perception data
through an end-to-end architec- ture. This information is derived from a
segmentation and force estimation head, which localizes the catheter in X-ray
images and estimates the applied pressure based on its deflection within the
image. These stereo vision architectures incorporate a CNN- based
encoder-decoder that captures the dependencies between X-ray images from two
viewpoints, enabling simultaneous 3D force estimation and stereo segmentation
of the catheter. With these tasks in mind, this work approaches the problem
from a new perspective. We propose a novel encoder-decoder Vision Transformer
model that processes two input X-ray images as separate sequences. Given
sequences of X-ray patches from two perspectives, the transformer captures
long-range dependencies without the need to gradually expand the receptive
field for either image. The embeddings generated by both the encoder and
decoder are fed into two shared segmentation heads, while a regression head
employs the fused information from the decoder for 3D force estimation. The
proposed model is a stereo Vision Transformer capable of simultaneously
segmenting the catheter from two angles while estimating the generated forces
at its tip in 3D. This model has undergone extensive experiments on synthetic
X-ray images with various noise levels and has been compared against
state-of-the-art pure segmentation models, vision-based catheter force
estimation methods, and a multitask catheter segmentation and force estimation
approach. It outperforms existing models, setting a new state-of-the-art in
both catheter segmentation and force estimation.

</details>


### [101] [GPSToken: Gaussian Parameterized Spatially-adaptive Tokenization for Image Representation and Generation](https://arxiv.org/abs/2509.01109)
*Zhengqiang Zhang,Rongyuan Wu,Lingchen Sun,Lei Zhang*

Main category: cs.CV

TL;DR: GPSToken使用高斯参数化空间自适应分词框架，实现非均匀图像分词，提高图像表示和生成效率。


<details>
  <summary>Details</summary>
Motivation: 传统图像分词方法受限于2D/1D网格，无法灵活表示不同形状、纹理和位置的区域，限制了特征表示效果。GPSToken旨在解决这一问题。

Method: GPSToken首先使用熵驱动算法将图像划分为纹理均匀、大小可变的区域，然后将每个区域参数化为2D高斯（均值表示位置，协方差表示形状）并耦合纹理特征。通过专门的Transformer优化高斯参数，实现位置/形状的连续自适应和内容感知特征提取。解码时，使用可微分的渲染器将高斯参数化分词重构为2D特征图，以实现端到端训练。GPSToken将空间布局（高斯参数）与纹理特征解耦，实现高效的两阶段生成：先合成结构布局，再进行条件纹理生成。

Result: GPSToken在图像重建和生成任务上取得了最先进的性能，使用128个分词时，rFID和FID得分分别为0.65和1.50。

Conclusion: GPSToken通过其新颖的非均匀图像分词方法，有效地提高了图像表示和生成的效果。

Abstract: Effective and efficient tokenization plays an important role in image
representation and generation. Conventional methods, constrained by uniform
2D/1D grid tokenization, are inflexible to represent regions with varying
shapes and textures and at different locations, limiting their efficacy of
feature representation. In this work, we propose $\textbf{GPSToken}$, a novel
$\textbf{G}$aussian $\textbf{P}$arameterized $\textbf{S}$patially-adaptive
$\textbf{Token}$ization framework, to achieve non-uniform image tokenization by
leveraging parametric 2D Gaussians to dynamically model the shape, position,
and textures of different image regions. We first employ an entropy-driven
algorithm to partition the image into texture-homogeneous regions of variable
sizes. Then, we parameterize each region as a 2D Gaussian (mean for position,
covariance for shape) coupled with texture features. A specialized transformer
is trained to optimize the Gaussian parameters, enabling continuous adaptation
of position/shape and content-aware feature extraction. During decoding,
Gaussian parameterized tokens are reconstructed into 2D feature maps through a
differentiable splatting-based renderer, bridging our adaptive tokenization
with standard decoders for end-to-end training. GPSToken disentangles spatial
layout (Gaussian parameters) from texture features to enable efficient
two-stage generation: structural layout synthesis using lightweight networks,
followed by structure-conditioned texture generation. Experiments demonstrate
the state-of-the-art performance of GPSToken, which achieves rFID and FID
scores of 0.65 and 1.50 on image reconstruction and generation tasks using 128
tokens, respectively. Codes and models of GPSToken can be found at
$\href{https://github.com/xtudbxk/GPSToken}{https://github.com/xtudbxk/GPSToken}$.

</details>


### [102] [MetaSSL: A General Heterogeneous Loss for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2509.01144)
*Weiren Zhao,Lanfeng Zhong,Xin Liao,Wenjun Liao,Sichuan Zhang,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: MetaSSL是一个基于空间异质性损失的半监督学习框架，通过分配不同权重给不同像素来挖掘预测信息，并能整合现有半监督学习方法以提升医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有半监督学习方法（如Mean Teacher, FixMatch, CPS）主要关注生成参考预测，但忽略了标签数据中的噪声以及未标记像素的异质性信息。作者认为，挖掘损失函数中包含的丰富信息（而不只是生成参考预测的策略）对半监督学习至关重要。

Method: 提出名为MetaSSL的通用框架，基于空间异质性损失。该损失通过同时利用参考预测和监督预测之间的一致性和不确定性信息，为不同像素分配不同权重。具体地，将未标记数据上的预测分为四个区域（UC, US, DC, DS），并根据置信度和一致性分配递减的权重，其中提出自适应阈值来区分置信和可疑预测。该异质性损失也应用于标记图像，以应对潜在的标注噪声。MetaSSL具有即插即用性，可兼容大多数现有半监督学习方法。

Result: 将MetaSSL集成到现有半监督学习框架中，在不同数据集上显著提高了分割性能。

Conclusion: MetaSSL通过引入空间异质性损失，有效利用了半监督学习中的预测信息，并能鲁棒地处理潜在的标注噪声，提高了医学图像分割的性能。

Abstract: Semi-Supervised Learning (SSL) is important for reducing the annotation cost
for medical image segmentation models. State-of-the-art SSL methods such as
Mean Teacher, FixMatch and Cross Pseudo Supervision (CPS) are mainly based on
consistency regularization or pseudo-label supervision between a reference
prediction and a supervised prediction. Despite the effectiveness, they have
overlooked the potential noise in the labeled data, and mainly focus on
strategies to generate the reference prediction, while ignoring the
heterogeneous values of different unlabeled pixels. We argue that effectively
mining the rich information contained by the two predictions in the loss
function, instead of the specific strategy to obtain a reference prediction, is
more essential for SSL, and propose a universal framework MetaSSL based on a
spatially heterogeneous loss that assigns different weights to pixels by
simultaneously leveraging the uncertainty and consistency information between
the reference and supervised predictions. Specifically, we split the
predictions on unlabeled data into four regions with decreasing weights in the
loss: Unanimous and Confident (UC), Unanimous and Suspicious (US), Discrepant
and Confident (DC), and Discrepant and Suspicious (DS), where an adaptive
threshold is proposed to distinguish confident predictions from suspicious
ones. The heterogeneous loss is also applied to labeled images for robust
learning considering the potential annotation noise. Our method is
plug-and-play and general to most existing SSL methods. The experimental
results showed that it improved the segmentation performance significantly when
integrated with existing SSL frameworks on different datasets. Code is
available at https://github.com/HiLab-git/MetaSSL.

</details>


### [103] [MVTrajecter: Multi-View Pedestrian Tracking with Trajectory Motion Cost and Trajectory Appearance Cost](https://arxiv.org/abs/2509.01157)
*Taiga Yamane,Ryo Masumura,Satoshi Suzuki,Shota Orihashi*

Main category: cs.CV

TL;DR: MVTrajecter是一种新的端到端多视图行人跟踪方法，利用过去的轨迹信息进行鲁棒关联，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的端到端多视图行人跟踪方法仅依赖当前和邻近过去时间戳的信息，忽略了更早的过去轨迹，影响了关联的鲁棒性。

Method: 提出了一种名为MVTrajecter的新型端到端多视图行人跟踪方法，该方法利用多时间戳的过去轨迹信息进行关联。引入了轨迹运动成本和轨迹外观成本来整合运动和外观信息，并利用注意力机制捕捉多时间戳之间的关系。

Result: 实验证明了MVTrajecter每个组件的有效性，并且其性能优于现有最先进的方法。

Conclusion: MVTrajecter通过利用多时间戳的过去轨迹信息，能够更鲁棒地进行行人关联，克服了现有方法的局限性，并在多视图行人跟踪任务上取得了优于现有方法的性能。

Abstract: Multi-View Pedestrian Tracking (MVPT) aims to track pedestrians in the form
of a bird's eye view occupancy map from multi-view videos. End-to-end methods
that detect and associate pedestrians within one model have shown great
progress in MVPT. The motion and appearance information of pedestrians is
important for the association, but previous end-to-end MVPT methods rely only
on the current and its single adjacent past timestamp, discarding the past
trajectories before that. This paper proposes a novel end-to-end MVPT method
called Multi-View Trajectory Tracker (MVTrajecter) that utilizes information
from multiple timestamps in past trajectories for robust association.
MVTrajecter introduces trajectory motion cost and trajectory appearance cost to
effectively incorporate motion and appearance information, respectively. These
costs calculate which pedestrians at the current and each past timestamp are
likely identical based on the information between those timestamps. Even if a
current pedestrian could be associated with a false pedestrian at some past
timestamp, these costs enable the model to associate that current pedestrian
with the correct past trajectory based on other past timestamps. In addition,
MVTrajecter effectively captures the relationships between multiple timestamps
leveraging the attention mechanism. Extensive experiments demonstrate the
effectiveness of each component in MVTrajecter and show that it outperforms the
previous state-of-the-art methods.

</details>


### [104] [Do Video Language Models Really Know Where to Look? Diagnosing Attention Failures in Video Language Models](https://arxiv.org/abs/2509.01167)
*Hyunjong Ok,Jaeho Lee*

Main category: cs.CV

TL;DR: Vision encoders used in multimodal large language models (MLLMs) for video understanding may not effectively identify the most informative frames, suggesting a need for improved keyframe identification techniques.


<details>
  <summary>Details</summary>
Motivation: To investigate whether the vision encoders used in multimodal large language models (MLLMs) for video understanding can effectively identify the most informative frames, as current methods rely on these encoders to avoid high computational costs but their effectiveness in identifying crucial frames is unclear.

Method: Empirical analysis of popular vision encoders used in MLLMs to assess their capability in identifying informative video frames relevant to textual queries.

Result: The study found that popular vision encoders used in MLLMs have limited capability in identifying the most informative frames within a video for handling specific textual queries.

Conclusion: The findings indicate that current vision encoders are not optimal for keyframe identification in video MLLMs, and advancements in keyframe identification techniques are likely necessary for more efficient video MLLMs.

Abstract: Recent advances in multimodal large language models (MLLMs) have led to much
progress in video understanding tasks. To avoid the heavy computational cost of
processing all frames, these models typically rely on keyframe sampling methods
guided by vision-language encoders (\textit{e.g.,} SigLIP). However, it remains
unclear whether such encoders can truly identify the most informative frames.
In this work, we provide several empirical pieces of evidence revealing that
popular vision encoders critically suffer from their limited capability to
identify where the MLLM should look inside the video to handle the given
textual query appropriately. Our findings suggest that the development of
better keyframe identification techniques may be necessary for efficient video
MLLMs.

</details>


### [105] [Ensemble-Based Event Camera Place Recognition Under Varying Illumination](https://arxiv.org/abs/2509.01968)
*Therese Joseph,Tobias Fischer,Michael Milford*

Main category: cs.CV

TL;DR: 事件相机视觉定位（VPR）框架在光照变化下鲁棒性差的问题，提出了一种基于集成学习的方法，结合多种事件到帧重建、VPR特征提取器和时间分辨率，实现了显著的性能提升，尤其是在昼夜转换场景下，Recall@1提高了57%。


<details>
  <summary>Details</summary>
Motivation: 事件相机在视觉定位（VPR）方面具有高动态范围和低延迟的优势，但在剧烈光照变化下鲁棒性不足，这是一个亟待解决的研究问题。

Method: 提出了一种基于集成学习的事件相机视觉定位方法，该方法融合了多种事件到帧重建、VPR特征提取器和时间分辨率的匹配结果。与以往仅利用时间分辨率的方法不同，该方法采用了更广泛的融合策略。

Result: 在两个长时驾驶数据集上进行了评估，在昼夜转换等不同光照条件下（如下午、日落、夜晚），Recall@1相对提高了57%。通过消融实验分析了各种设计选择（如分箱策略、极性处理、重建方法和特征提取器）对性能的影响，并提出了一种改进的序列匹配框架以适应更长的序列。

Conclusion: 所提出的集成学习方法显著提高了事件相机视觉定位在恶劣光照条件下的鲁棒性，为未来相关研究提供了代码库和基准测试框架。

Abstract: Compared to conventional cameras, event cameras provide a high dynamic range
and low latency, offering greater robustness to rapid motion and challenging
lighting conditions. Although the potential of event cameras for visual place
recognition (VPR) has been established, developing robust VPR frameworks under
severe illumination changes remains an open research problem. In this paper, we
introduce an ensemble-based approach to event camera place recognition that
combines sequence-matched results from multiple event-to-frame reconstructions,
VPR feature extractors, and temporal resolutions. Unlike previous event-based
ensemble methods, which only utilise temporal resolution, our broader fusion
strategy delivers significantly improved robustness under varied lighting
conditions (e.g., afternoon, sunset, night), achieving a 57% relative
improvement in Recall@1 across day-night transitions. We evaluate our approach
on two long-term driving datasets (with 8 km per traverse) without metric
subsampling, thereby preserving natural variations in speed and stop duration
that influence event density. We also conduct a comprehensive analysis of key
design choices, including binning strategies, polarity handling, reconstruction
methods, and feature extractors, to identify the most critical components for
robust performance. Additionally, we propose a modification to the standard
sequence matching framework that enhances performance at longer sequence
lengths. To facilitate future research, we will release our codebase and
benchmarking framework.

</details>


### [106] [FocusDPO: Dynamic Preference Optimization for Multi-Subject Personalized Image Generation via Adaptive Focus](https://arxiv.org/abs/2509.01181)
*Qiaoqiao Jin,Siming Fu,Dong She,Weinan Jia,Hualiang Wang,Mu Liu,Jidong Jiang*

Main category: cs.CV

TL;DR: FocusDPO是一个框架，能够自适应地识别焦点区域，并动态调整焦点分配，以实现对多个主体进行精细的独立控制，同时保持主体保真度和防止跨主体属性泄露。


<details>
  <summary>Details</summary>
Motivation: 实现对多个主体进行精细的独立控制，同时保持主体保真度和防止跨主体属性泄露，这是多主体个性化图像生成中的一个挑战。

Method: FocusDPO框架通过动态语义对应和监督图像复杂度来识别焦点区域，并在训练过程中根据奖励信息丰富图斑和惩罚低置信度区域来逐步调整这些焦点区域。此外，该框架在DPO过程中根据参考图像的语义复杂度动态调整焦点分配，并建立生成主体与参考主体之间的对应映射。

Result: FocusDPO显著提升了现有预训练个性化生成模型的性能，在单主体和多主体个性化图像合成基准测试中取得了最先进的结果，有效缓解了属性泄露问题，同时在各种生成场景中保持了卓越的主体保真度。

Conclusion: FocusDPO在可控多主体图像合成领域取得了进展，解决了现有方法在多主体控制、保真度保持和属性泄露方面存在的挑战。

Abstract: Multi-subject personalized image generation aims to synthesize customized
images containing multiple specified subjects without requiring test-time
optimization. However, achieving fine-grained independent control over multiple
subjects remains challenging due to difficulties in preserving subject fidelity
and preventing cross-subject attribute leakage. We present FocusDPO, a
framework that adaptively identifies focus regions based on dynamic semantic
correspondence and supervision image complexity. During training, our method
progressively adjusts these focal areas across noise timesteps, implementing a
weighted strategy that rewards information-rich patches while penalizing
regions with low prediction confidence. The framework dynamically adjusts focus
allocation during the DPO process according to the semantic complexity of
reference images and establishes robust correspondence mappings between
generated and reference subjects. Extensive experiments demonstrate that our
method substantially enhances the performance of existing pre-trained
personalized generation models, achieving state-of-the-art results on both
single-subject and multi-subject personalized image synthesis benchmarks. Our
method effectively mitigates attribute leakage while preserving superior
subject fidelity across diverse generation scenarios, advancing the frontier of
controllable multi-subject image synthesis.

</details>


### [107] [SegAssess: Panoramic quality mapping for robust and transferable unsupervised segmentation assessment](https://arxiv.org/abs/2509.01183)
*Bingnan Yang,Mi Zhang,Zhili Zhang,Zhan Zhang,Yuanxin Zhao,Xiangyun Hu,Jianya Gong*

Main category: cs.CV

TL;DR: SegAssess是一个创新的深度学习框架，通过全景质量映射（PQM）实现全面的像素级无监督分割质量评估（SQA），解决了现有方法的局限性，并在32个数据集上实现了最先进的性能和出色的跨域迁移能力。


<details>
  <summary>Details</summary>
Motivation: 当前的深度学习无监督分割质量评估（SQA）方法在评估粒度、评估完整性和可迁移性方面存在不足，特别是在缺乏真实标签的无监督场景下。

Method: 提出全景质量映射（PQM）新范式，并构建了SegAssess深度学习框架。SegAssess将SQA视为一种细粒度的四分类全景分割任务，将分割掩模内的像素分类为真阳性（TP）、假阳性（FP）、真阴性（TN）和假阴性（FN），从而生成完整的质量图。该框架增强了分割基础模型（SAM）架构，通过交叉注意力利用输入掩模作为提示进行特征融合。关键创新包括：1）边缘引导压缩（EGC）分支，结合聚合语义滤波器（ASF）模块，优化困难边缘预测；2）增强混合采样（AMS）训练策略，整合多源掩模以提高跨域鲁棒性和零样本迁移能力。

Result: 在32个数据集（来自6个来源）上的综合实验表明，SegAssess实现了最先进（SOTA）的性能，并对未见过的掩模表现出卓越的零样本迁移能力。

Conclusion: 全景质量映射（PQM）通过SegAssess的实现，为无监督SQA提供了一种强大且可迁移的解决方案。

Abstract: High-quality image segmentation is fundamental to pixel-level geospatial
analysis in remote sensing, necessitating robust segmentation quality
assessment (SQA), particularly in unsupervised settings lacking ground truth.
Although recent deep learning (DL) based unsupervised SQA methods show
potential, they often suffer from coarse evaluation granularity, incomplete
assessments, and poor transferability. To overcome these limitations, this
paper introduces Panoramic Quality Mapping (PQM) as a new paradigm for
comprehensive, pixel-wise SQA, and presents SegAssess, a novel deep learning
framework realizing this approach. SegAssess distinctively formulates SQA as a
fine-grained, four-class panoramic segmentation task, classifying pixels within
a segmentation mask under evaluation into true positive (TP), false positive
(FP), true negative (TN), and false negative (FN) categories, thereby
generating a complete quality map. Leveraging an enhanced Segment Anything
Model (SAM) architecture, SegAssess uniquely employs the input mask as a prompt
for effective feature integration via cross-attention. Key innovations include
an Edge Guided Compaction (EGC) branch with an Aggregated Semantic Filter (ASF)
module to refine predictions near challenging object edges, and an Augmented
Mixup Sampling (AMS) training strategy integrating multi-source masks to
significantly boost cross-domain robustness and zero-shot transferability.
Comprehensive experiments across 32 datasets derived from 6 sources demonstrate
that SegAssess achieves state-of-the-art (SOTA) performance and exhibits
remarkable zero-shot transferability to unseen masks, establishing PQM via
SegAssess as a robust and transferable solution for unsupervised SQA. The code
is available at https://github.com/Yangbn97/SegAssess.

</details>


### [108] [PrediTree: A Multi-Temporal Sub-meter Dataset of Multi-Spectral Imagery Aligned With Canopy Height Maps](https://arxiv.org/abs/2509.01202)
*Hiyam Debary,Mustansar Fiaz,Levente Klein*

Main category: cs.CV

TL;DR: PrediTree是一个包含3,141,568张图像的开源数据集，用于训练和评估树高预测模型，具有0.5m分辨率，结合了LiDAR数据和多时相、多光谱遥感影像，并提出了一个基于U-Net的编码器-解码器框架，在树高预测任务上取得了11.78%的掩码均方误差。


<details>
  <summary>Details</summary>
Motivation: 森林监测能力存在关键差距，需要能够基于多次历史观测预测树木生长的深度学习方法。

Method: 提出一个编码器-解码器框架，需要多时相、多光谱影像以及目标树高图时间戳和每次影像获取日期之间的时间差（以年为单位）来预测树高。实验采用了U-Net架构。

Result: 在PrediTree数据集上训练的U-Net架构取得了11.78%的掩码均方误差，比ResNet-50模型提高了约12%，并且比仅使用红、绿、蓝波段的实验结果误差降低了约30%。

Conclusion: PrediTree数据集支持训练更准确的树高预测模型，U-Net架构是有效的，该数据集和相关代码均已公开可用。

Abstract: We present PrediTree, the first comprehensive open-source dataset designed
for training and evaluating tree height prediction models at sub-meter
resolution. This dataset combines very high-resolution (0.5m) LiDAR-derived
canopy height maps, spatially aligned with multi-temporal and multi-spectral
imagery, across diverse forest ecosystems in France, totaling 3,141,568 images.
PrediTree addresses a critical gap in forest monitoring capabilities by
enabling the training of deep learning methods that can predict tree growth
based on multiple past observations. %\sout{Initially focused on French
forests, PrediTree is designed as an expanding resource with ongoing efforts to
incorporate data from other countries. } To make use of this PrediTree dataset,
we propose an encoder-decoder framework that requires the multi-temporal
multi-spectral imagery and the relative time differences in years between the
canopy height map timestamp (target) and each image acquisition date for which
this framework predicts the canopy height. The conducted experiments
demonstrate that a U-Net architecture trained on the PrediTree dataset provides
the highest masked mean squared error of $11.78\%$, outperforming the next-best
architecture, ResNet-50, by around $12\%$, and cutting the error of the same
experiments but on fewer bands (red, green, blue only), by around $30\%$. This
dataset is publicly available on \href{URL}{HuggingFace}, and both processing
and training codebases are available on \href{URL}{GitHub}.

</details>


### [109] [DcMatch: Unsupervised Multi-Shape Matching with Dual-Level Consistency](https://arxiv.org/abs/2509.01204)
*Tianwei Ye,Yong Ma,Xiaoguang Mei*

Main category: cs.CV

TL;DR: DcMatch是一个新颖的无监督学习框架，用于非刚性多形状匹配，通过形状图注意力网络捕捉整个形状集合的流形结构，构建更具表达力和鲁棒性的共享潜在空间，并通过宇宙预测器实现更一致的形状到宇宙的对应关系。它还在空间和谱域中表示对应关系，并通过新颖的循环一致性损失强制在共享宇宙空间中对齐，从而实现更准确和连贯的映射。


<details>
  <summary>Details</summary>
Motivation: 建立跨多个3D形状的点对点对应关系是计算机视觉和图形学中的一个基本问题。

Method: DcMatch框架使用形状图注意力网络来捕捉形状集合的流形结构，构建共享的潜在空间，并通过宇宙预测器实现形状到宇宙的对应关系。它还在空间和谱域中表示对应关系，并通过循环一致性损失强制其在共享宇宙空间中对齐。

Result: 在多个具有挑战性的基准测试中，DcMatch在各种多形状匹配场景中持续优于以前最先进的方法。

Conclusion: DcMatch通过其新颖的框架和方法，在多形状匹配方面取得了显著的成果，并在多个评估中超越了现有技术。

Abstract: Establishing point-to-point correspondences across multiple 3D shapes is a
fundamental problem in computer vision and graphics. In this paper, we
introduce DcMatch, a novel unsupervised learning framework for non-rigid
multi-shape matching. Unlike existing methods that learn a canonical embedding
from a single shape, our approach leverages a shape graph attention network to
capture the underlying manifold structure of the entire shape collection. This
enables the construction of a more expressive and robust shared latent space,
leading to more consistent shape-to-universe correspondences via a universe
predictor. Simultaneously, we represent these correspondences in both the
spatial and spectral domains and enforce their alignment in the shared universe
space through a novel cycle consistency loss. This dual-level consistency
fosters more accurate and coherent mappings. Extensive experiments on several
challenging benchmarks demonstrate that our method consistently outperforms
previous state-of-the-art approaches across diverse multi-shape matching
scenarios. Code is available at https://github.com/YeTianwei/DcMatch.

</details>


### [110] [Generalizable Self-supervised Monocular Depth Estimation with Mixture of Low-Rank Experts for Diverse Endoscopic Scenes](https://arxiv.org/abs/2509.01206)
*Liangjing Shao,Benshuang Chen,Chenkang Du,Xueli Liu,Xinrong Chen*

Main category: cs.CV

TL;DR: 通过混合动态低秩专家和自监督学习框架，提出了一种用于内窥镜场景的单目深度估计方法，以应对光照和场景特征的挑战，并在真实和模拟数据集上取得了优于现有技术的性能，同时在零样本评估中表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决内窥镜场景中由于光照条件和场景特征多变而导致的通用深度估计的挑战。

Method: 提出了一种新颖的块状动态低秩专家混合（dynamic low-rank experts）的自监督框架，以适应性地选择专家进行加权推理，并联合处理亮度和反射率的不一致性。

Result: 所提出的方法在真实和模拟内窥镜数据集上均优于最先进的技术，并在零样本深度估计任务中实现了最佳泛化能力。

Conclusion: 该方法通过提高内窥镜感知的准确性，有望为微创测量和手术做出贡献。

Abstract: Self-supervised monocular depth estimation is a significant task for low-cost
and efficient three-dimensional scene perception in endoscopy. The variety of
illumination conditions and scene features is still the primary challenge for
generalizable depth estimation in endoscopic scenes. In this work, a
self-supervised framework is proposed for monocular depth estimation in various
endoscopy. Firstly, due to various features in endoscopic scenes with different
tissues, a novel block-wise mixture of dynamic low-rank experts is proposed to
efficiently finetuning the foundation model for endoscopic depth estimation. In
the proposed module, based on the input feature, different experts with a small
amount of trainable parameters are adaptively selected for weighted inference,
from various mixture of low-rank experts which are allocated based on the
training quality of each block. Moreover, a novel self-supervised training
framework is proposed to jointly cope with the inconsistency of brightness and
reflectance. The proposed method outperform state-of-the-art works on both
realistic and simulated endoscopic datasets. Furthermore, the proposed network
also achieves the best generalization based on zero-shot depth estimation on
diverse endoscopic scenes. The proposed method could contribute to accurate
endoscopic perception for minimally invasive measurement and surgery. The code
will be released upon acceptance, while the demo video can be found on here:
https://endo-gede.netlify.app/.

</details>


### [111] [Measuring Image-Relation Alignment: Reference-Free Evaluation of VLMs and Synthetic Pre-training for Open-Vocabulary Scene Graph Generation](https://arxiv.org/abs/2509.01209)
*Maëlic Neau,Zoe Falomir,Cédric Buche,Akihiro Sugimoto*

Main category: cs.CV

TL;DR: Open-Vocabulary Scene Graph Generation (SGG) benchmarks have limited vocabularies, hindering evaluation of Vision-Language Models (VLMs). This paper proposes a new reference-free metric for fair evaluation and a method for generating high-quality synthetic data using region-specific prompt tuning of VLMs, which improves generalization capabilities.


<details>
  <summary>Details</summary>
Motivation: Current Scene Graph Generation (SGG) benchmarks have limited vocabularies, making it inefficient to evaluate the open-vocabulary capabilities of Vision-Language Models (VLMs). Additionally, existing methods rely on low-quality, weakly supervised data for pre-training.

Method: 1. Proposed a new reference-free metric to fairly evaluate the open-vocabulary capabilities of VLMs for relation prediction. 2. Developed a new solution for quickly generating high-quality synthetic data through region-specific prompt tuning of VLMs.

Result: Pre-training with the newly generated synthetic data improves the generalization capabilities of Open-Vocabulary SGG models.

Conclusion: The proposed reference-free metric and synthetic data generation method fairly evaluate and enhance the open-vocabulary capabilities of VLMs for SGG tasks.

Abstract: Scene Graph Generation (SGG) encodes visual relationships between objects in
images as graph structures. Thanks to the advances of Vision-Language Models
(VLMs), the task of Open-Vocabulary SGG has been recently proposed where models
are evaluated on their functionality to learn a wide and diverse range of
relations. Current benchmarks in SGG, however, possess a very limited
vocabulary, making the evaluation of open-source models inefficient. In this
paper, we propose a new reference-free metric to fairly evaluate the
open-vocabulary capabilities of VLMs for relation prediction. Another
limitation of Open-Vocabulary SGG is the reliance on weakly supervised data of
poor quality for pre-training. We also propose a new solution for quickly
generating high-quality synthetic data through region-specific prompt tuning of
VLMs. Experimental results show that pre-training with this new data split can
benefit the generalization capabilities of Open-Voc SGG models.

</details>


### [112] [PRINTER:Deformation-Aware Adversarial Learning for Virtual IHC Staining with In Situ Fidelity](https://arxiv.org/abs/2509.01214)
*Yizhe Yuan,Bingsen Xue,Bangzheng Pu,Chengxiang Wang,Cheng Jin*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Tumor spatial heterogeneity analysis requires precise correlation between
Hematoxylin and Eosin H&E morphology and immunohistochemical (IHC) biomarker
expression, yet current methods suffer from spatial misalignment in consecutive
sections, severely compromising in situ pathological interpretation. In order
to obtain a more accurate virtual staining pattern, We propose PRINTER, a
weakly-supervised framework that integrates PRototype-drIven content and
staiNing patTERn decoupling and deformation-aware adversarial learning
strategies designed to accurately learn IHC staining patterns while preserving
H&E staining details. Our approach introduces three key innovations: (1) A
prototype-driven staining pattern transfer with explicit content-style
decoupling; and (2) A cyclic registration-synthesis framework GapBridge that
bridges H&E and IHC domains through deformable structural alignment, where
registered features guide cross-modal style transfer while synthesized outputs
iteratively refine the registration;(3) Deformation-Aware Adversarial Learning:
We propose a training framework where a generator and deformation-aware
registration network jointly adversarially optimize a style-focused
discriminator. Extensive experiments demonstrate that PRINTER effectively
achieves superior performance in preserving H&E staining details and virtual
staining fidelity, outperforming state-of-the-art methods. Our work provides a
robust and scalable solution for virtual staining, advancing the field of
computational pathology.

</details>


### [113] [POINTS-Reader: Distillation-Free Adaptation of Vision-Language Models for Document Conversion](https://arxiv.org/abs/2509.01215)
*Yuan Liu,Zhongyin Zhao,Le Tian,Haicheng Wang,Xubing Ye,Yangxiu You,Zilin Yu,Chuhan Wu,Xiao Zhou,Yang Yu,Jie Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一种全自动、无蒸馏的框架，用于构建高质量文档提取数据集和模型，以处理复杂的文档格式和布局。该框架分为两个阶段：首先生成大规模、多样化的合成数据来初步训练模型，然后在真实文档上通过自改进方法（包括模型标注、过滤和重新训练）来进一步优化模型和数据质量。


<details>
  <summary>Details</summary>
Motivation: 手动标注文档提取模型所需的高质量标签数据成本高且耗时，而现有模型在处理表格、公式、多栏文本等复杂格式时准确性不足，限制了学生模型的性能。因此，需要一种全自动的方法来创建高质量的数据集和模型。

Method: 该框架包含两个阶段：1. 合成数据生成：创建大规模、多样化的合成数据，用于初步训练模型以提取统一格式的关键元素。2. 自我改进：将初步训练好的模型应用于真实文档，通过模型标注、过滤策略验证标注质量，然后在经过验证的数据集上重新训练模型，并迭代此过程以持续改进模型和数据。

Result: 通过该框架训练的POINTS-Reader模型在文档提取任务上，超越了许多同等或更大规模的现有公共和专有模型。代码已在https://github.com/Tencent/POINTS-Reader公开。

Conclusion: 该论文提出的全自动、无蒸馏框架能够有效地构建高质量的文档提取数据集和模型，解决了手动标注的痛点，并在处理复杂文档格式方面取得了优于现有模型的性能。

Abstract: High-quality labeled data is essential for training accurate document
conversion models, particularly in domains with complex formats such as tables,
formulas, and multi-column text. However, manual annotation is both costly and
time-consuming, while automatic labeling using existing models often lacks
accuracy in handling such challenging scenarios. Consequently, training student
models by distilling outputs from teacher models can significantly limit their
performance in real-world applications. In this paper, we propose a fully
automated, distillation-free framework comprising two stages for constructing
high-quality document extraction datasets and models capable of handling
diverse document formats and layouts. In the first stage, we introduce a method
for generating large-scale, diverse synthetic data, which enables a model to
extract key elements in a unified format with strong initial performance. In
the second stage, we present a self-improvement approach that further adapts
the model, initially trained on synthetic data, to real-world documents.
Specifically, we first use the fine-tuned model to annotate real documents,
then apply a suite of filtering strategies to verify annotation quality, and
finally retrain the model on the verified dataset. By iteratively repeating
this process, we progressively enhance both the model's conversion capabilities
and the quality of the generated data. We train a public POINTS-1.5 model to
obtain POINTS-Reader, which surpasses many existing public and proprietary
models of comparable or larger size. Our model is available at
https://github.com/Tencent/POINTS-Reader.

</details>


### [114] [FantasyHSI: Video-Generation-Centric 4D Human Synthesis In Any Scene through A Graph-based Multi-Agent Framework](https://arxiv.org/abs/2509.01232)
*Lingzhou Mu,Qiang Wang,Fan Jiang,Mengchao Wang,Yaqi Fan,Mu Xu,Kai Zhang*

Main category: cs.CV

TL;DR: FantasyHSI是一个新颖的人机交互（HSI）框架，利用视频生成和多智能体系统（包括场景导航、规划和评论智能体）来处理长时、高层任务，并能泛化到未见的场景。它通过动态有向图和评论智能体的反馈机制来确保长期逻辑一致性，并使用DPO提高动作生成的物理真实感，在SceneBench基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互（HSI）方法在处理长时、高层任务和泛化到未见场景方面存在挑战。

Method: FantasyHSI框架利用视频生成和多智能体系统，将交互过程建模为动态有向图。该系统包含一个场景导航智能体（负责环境感知和高层路径规划）和一个规划智能体（负责将长时目标分解为原子动作）。此外，还引入了一个评论智能体，通过评估生成动作与规划路径之间的偏差来建立闭环反馈机制，从而动态修正生成模型随机性导致的轨迹漂移。为了提高动作生成的物理真实感，采用了直接偏好优化（DPO）方法。

Result: 在自定义的SceneBench基准测试上进行的大量实验表明，FantasyHSI在泛化能力、长时任务完成度和物理真实感方面显著优于现有方法。

Conclusion: FantasyHSI通过其创新的多智能体协同方法和基于DPO的物理真实感提升，成功解决了现有HSI方法的局限性，并在各项评估指标上取得了显著的性能提升。

Abstract: Human-Scene Interaction (HSI) seeks to generate realistic human behaviors
within complex environments, yet it faces significant challenges in handling
long-horizon, high-level tasks and generalizing to unseen scenes. To address
these limitations, we introduce FantasyHSI, a novel HSI framework centered on
video generation and multi-agent systems that operates without paired data. We
model the complex interaction process as a dynamic directed graph, upon which
we build a collaborative multi-agent system. This system comprises a scene
navigator agent for environmental perception and high-level path planning, and
a planning agent that decomposes long-horizon goals into atomic actions.
Critically, we introduce a critic agent that establishes a closed-loop feedback
mechanism by evaluating the deviation between generated actions and the planned
path. This allows for the dynamic correction of trajectory drifts caused by the
stochasticity of the generative model, thereby ensuring long-term logical
consistency. To enhance the physical realism of the generated motions, we
leverage Direct Preference Optimization (DPO) to train the action generator,
significantly reducing artifacts such as limb distortion and foot-sliding.
Extensive experiments on our custom SceneBench benchmark demonstrate that
FantasyHSI significantly outperforms existing methods in terms of
generalization, long-horizon task completion, and physical realism. Ours
project page: https://fantasy-amap.github.io/fantasy-hsi/

</details>


### [115] [RT-DETRv2 Explained in 8 Illustrations](https://arxiv.org/abs/2509.01241)
*Ethan Qi Yang Chua,Jen Hong Tan*

Main category: cs.CV

TL;DR: RT-DETRv2 架构的清晰可视化解释，旨在提高可理解性。


<details>
  <summary>Details</summary>
Motivation: 现有 RT-DETRv2 的图示难以理解其组件如何协同工作。

Method: 通过八个精心设计的图示，从整体流程到关键组件（如编码器、解码器和多尺度可变形注意力）进行逐步解释，并可视化张量流和模块逻辑。

Result: 提供对 RT-DETRv2 架构更清晰的理解。

Conclusion: 通过可视化和详细解释，增强研究人员和实践者对 RT-DETRv2 工作原理的理解。

Abstract: Object detection architectures are notoriously difficult to understand, often
more so than large language models. While RT-DETRv2 represents an important
advance in real-time detection, most existing diagrams do little to clarify how
its components actually work and fit together. In this article, we explain the
architecture of RT-DETRv2 through a series of eight carefully designed
illustrations, moving from the overall pipeline down to critical components
such as the encoder, decoder, and multi-scale deformable attention. Our goal is
to make the existing one genuinely understandable. By visualizing the flow of
tensors and unpacking the logic behind each module, we hope to provide
researchers and practitioners with a clearer mental model of how RT-DETRv2
works under the hood.

</details>


### [116] [Learning Correlation-aware Aleatoric Uncertainty for 3D Hand Pose Estimation](https://arxiv.org/abs/2509.01242)
*Lee Chae-Yeon,Nam Hyeon-Woo,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: 该研究提出了一种新的不确定性建模方法，用于3D手部姿态估计，通过单个线性层捕捉关节相关性，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的3D手部姿态估计方法在估计不确定性（特别是数据不确定性）以及整合关节相关性知识方面存在局限性。

Method: 提出了一种新的参数化方法，利用单个线性层来捕捉手部关节的内在相关性，并将手部关节的输出空间构建为概率分布，从而实现不确定性建模。该方法可作为附加模块应用于现有模型。

Result: 实验结果表明，所提出的不确定性建模方法在3D手部姿态估计方面优于现有方法，并在提高模型精度的同时增加了不确定性建模能力。

Conclusion: 该方法成功地将不确定性建模引入3D手部姿态估计，并通过一种新颖的参数化方法有效捕捉了关节相关性，实现了更好的性能和效率平衡。

Abstract: 3D hand pose estimation is a fundamental task in understanding human hands.
However, accurately estimating 3D hand poses remains challenging due to the
complex movement of hands, self-similarity, and frequent occlusions. In this
work, we address two limitations: the inability of existing 3D hand pose
estimation methods to estimate aleatoric (data) uncertainty, and the lack of
uncertainty modeling that incorporates joint correlation knowledge, which has
not been thoroughly investigated. To this end, we introduce aleatoric
uncertainty modeling into the 3D hand pose estimation framework, aiming to
achieve a better trade-off between modeling joint correlations and
computational efficiency. We propose a novel parameterization that leverages a
single linear layer to capture intrinsic correlations among hand joints. This
is enabled by formulating the hand joint output space as a probabilistic
distribution, allowing the linear layer to capture joint correlations. Our
proposed parameterization is used as a task head layer, and can be applied as
an add-on module on top of the existing models. Our experiments demonstrate
that our parameterization for uncertainty modeling outperforms existing
approaches. Furthermore, the 3D hand pose estimation model equipped with our
uncertainty head achieves favorable accuracy in 3D hand pose estimation while
introducing new uncertainty modeling capability to the model. The project page
is available at https://hand-uncertainty.github.io/.

</details>


### [117] [Towards More Diverse and Challenging Pre-training for Point Cloud Learning: Self-Supervised Cross Reconstruction with Decoupled Views](https://arxiv.org/abs/2509.01250)
*Xiangdong Zhang,Shaofeng Zhang,Junchi Yan*

Main category: cs.CV

TL;DR: Point-PQAE是一种创新的两视图自监督学习方法，通过交叉重构和新颖的视角生成机制，在3D点云学习领域取得了显著进展，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督点云学习方法多集中于单视图重构，而两视图学习范式因其固有的多样性和差异性，有望实现更具挑战性和信息量的预训练。本文旨在探索两视图学习在点云自监督学习中的潜力。

Method: 本文提出了Point-PQAE，一种交叉重构的生成范式。该方法首先生成两个分离的点云/视图，然后通过一个新颖的作物（crop）机制来生成点云视图，并引入了用于表示两个分离视图之间3D相对位置的位置编码。最后，模型进行交叉重构，即从一个视图重构另一个视图。

Result: Point-PQAE在ScanObjectNN数据集的三个变体上，使用Mlp-Linear评估协议，相较于Point-MAE（一种自重构基线方法），在3D自监督学习任务上分别取得了6.5%、7.0%和6.7%的性能提升，证明了交叉重构相比自重构的优越性。

Conclusion: 两视图学习范式，特别是通过Point-PQAE提出的交叉重构和新颖的视角生成机制，能够有效提升3D点云的自监督学习性能，显著优于现有的单视图自重构方法。

Abstract: Point cloud learning, especially in a self-supervised way without manual
labels, has gained growing attention in both vision and learning communities
due to its potential utility in a wide range of applications. Most existing
generative approaches for point cloud self-supervised learning focus on
recovering masked points from visible ones within a single view. Recognizing
that a two-view pre-training paradigm inherently introduces greater diversity
and variance, it may thus enable more challenging and informative pre-training.
Inspired by this, we explore the potential of two-view learning in this domain.
In this paper, we propose Point-PQAE, a cross-reconstruction generative
paradigm that first generates two decoupled point clouds/views and then
reconstructs one from the other. To achieve this goal, we develop a crop
mechanism for point cloud view generation for the first time and further
propose a novel positional encoding to represent the 3D relative position
between the two decoupled views. The cross-reconstruction significantly
increases the difficulty of pre-training compared to self-reconstruction, which
enables our method to surpass previous single-modal self-reconstruction methods
in 3D self-supervised learning. Specifically, it outperforms the
self-reconstruction baseline (Point-MAE) by 6.5%, 7.0%, and 6.7% in three
variants of ScanObjectNN with the Mlp-Linear evaluation protocol. The code is
available at https://github.com/aHapBean/Point-PQAE.

</details>


### [118] [ReCap: Event-Aware Image Captioning with Article Retrieval and Semantic Gaussian Normalization](https://arxiv.org/abs/2509.01259)
*Thinh-Phuc Nguyen,Thanh-Hai Nguyen,Gia-Huy Dinh,Lam-Huy Nguyen,Minh-Triet Tran,Trung-Nghia Le*

Main category: cs.CV

TL;DR: ReCap通过整合相关文章的上下文信息，为图像生成更富叙事性和事实依据的标题，解决了现有图像描述系统过于笼统的问题，并在OpenEvents V1数据集上取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有图像字幕系统生成的描述过于笼统，缺乏对事件级别语义的捕捉，而这对于新闻报道和数字存档等应用至关重要。

Method: ReCap包含三个组件：1) 一个两阶段的文章检索系统，使用DINOv2嵌入和全局特征相似性进行初始候选选择，然后进行块级互最近邻相似性重排序；2) 一个上下文提取框架，综合文章摘要、通用标题和原始来源元数据信息；3) 一个基于大型语言模型的字幕生成系统，采用语义高斯归一化来提高流畅度和相关性。

Result: 在OpenEvents V1数据集（EVENTA 2025 Grand Challenge的一部分）的Track 1评估中，ReCap取得了0.54666的总体得分，在私有测试集上排名第二。

Conclusion: ReCap在连接视觉感知与现实世界知识方面效果显著，为高风险领域中感知上下文的图像理解提供了实用解决方案。

Abstract: Image captioning systems often produce generic descriptions that fail to
capture event-level semantics which are crucial for applications like news
reporting and digital archiving. We present ReCap, a novel pipeline for
event-enriched image retrieval and captioning that incorporates broader
contextual information from relevant articles to generate narrative-rich,
factually grounded captions. Our approach addresses the limitations of standard
vision-language models that typically focus on visible content while missing
temporal, social, and historical contexts. ReCap comprises three integrated
components: (1) a robust two-stage article retrieval system using DINOv2
embeddings with global feature similarity for initial candidate selection
followed by patch-level mutual nearest neighbor similarity re-ranking; (2) a
context extraction framework that synthesizes information from article
summaries, generic captions, and original source metadata; and (3) a large
language model-based caption generation system with Semantic Gaussian
Normalization to enhance fluency and relevance. Evaluated on the OpenEvents V1
dataset as part of Track 1 in the EVENTA 2025 Grand Challenge, ReCap achieved a
strong overall score of 0.54666, ranking 2nd on the private test set. These
results highlight ReCap's effectiveness in bridging visual perception with
real-world knowledge, offering a practical solution for context-aware image
understanding in high-stakes domains. The code is available at
https://github.com/Noridom1/EVENTA2025-Event-Enriched-Image-Captioning.

</details>


### [119] [Novel Category Discovery with X-Agent Attention for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2509.01275)
*Jiahao Li Yang Lu,Yachao Zhang,Fangyong Wang,Yuan Xie,Yanyun Qu*

Main category: cs.CV

TL;DR: OVSS通过文本驱动的对齐进行像素级分类，但开放词汇推理中的域差异给潜在的未见类别带来了挑战。现有基于VLM的方法通过预训练的多模态表示取得了良好的性能，但潜在语义理解的基本机制仍未得到充分探索。本研究旨在探索VLM在归纳学习范式下潜在语义的分布模式和动态。基于这些见解，我们提出了X-Agent，一个创新的OVSS框架，它利用潜在语义感知的“代理”来协调跨模态的注意力机制，同时优化潜在语义动态并增强其可感知性。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇语义分割（OVSS）中由于基础类别训练与开放词汇推理之间的域差异而导致的判别建模挑战，并深入探索潜在语义理解的基本机制。

Method: 提出X-Agent框架，该框架利用潜在语义感知的“代理”来协调跨模态的注意力机制，同时优化潜在语义动态并增强其可感知性。通过进行一项探测性实验来探索VLM在归纳学习范式下潜在语义的分布模式和动态。

Result: X-Agent实现了最先进的性能，并有效增强了潜在语义的显著性。

Conclusion: X-Agent框架通过利用潜在语义感知的代理来协调跨模态注意力机制，成功解决了OVSS中的域差异和潜在语义理解挑战，并在基准评估中取得了最先进的性能。

Abstract: Open-vocabulary semantic segmentation (OVSS) conducts pixel-level
classification via text-driven alignment, where the domain discrepancy between
base category training and open-vocabulary inference poses challenges in
discriminative modeling of latent unseen category. To address this challenge,
existing vision-language model (VLM)-based approaches demonstrate commendable
performance through pre-trained multi-modal representations. However, the
fundamental mechanisms of latent semantic comprehension remain underexplored,
making the bottleneck for OVSS. In this work, we initiate a probing experiment
to explore distribution patterns and dynamics of latent semantics in VLMs under
inductive learning paradigms. Building on these insights, we propose X-Agent,
an innovative OVSS framework employing latent semantic-aware ``agent'' to
orchestrate cross-modal attention mechanisms, simultaneously optimizing latent
semantic dynamic and amplifying its perceptibility. Extensive benchmark
evaluations demonstrate that X-Agent achieves state-of-the-art performance
while effectively enhancing the latent semantic saliency.

</details>


### [120] [SAR-NAS: Lightweight SAR Object Detection with Neural Architecture Search](https://arxiv.org/abs/2509.01279)
*Xinyi Yu,Zhiwei Lin,Yongtao Wang*

Main category: cs.CV

TL;DR: 本文将轻量级目标检测器YOLOv10应用于SAR目标检测，并通过神经架构搜索（NAS）优化其主干网络，以应对SAR图像中的斑点噪声、小目标模糊和计算限制。优化后的模型在SARDet-100K数据集上表现优于现有SAR检测方法，实现了更高的检测精度和更低的计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决合成孔径雷达（SAR）目标检测中存在的斑点噪声、小目标模糊和板载计算限制等挑战，并探索现有轻量级目标检测器（如YOLOv10）在SAR目标检测中的应用潜力。

Method: 采用神经架构搜索（NAS）技术，特别是主干网络架构搜索，在广泛的搜索空间内，利用进化搜索来优化YOLOv10模型，以平衡准确性、参数效率和计算成本。

Result: 在大型SARDet-100K数据集上进行的实验表明，经过NAS优化的模型在检测精度上优于现有的SAR检测方法，同时保持了较低的计算开销。

Conclusion: 通过首次将NAS应用于SAR目标检测，并优化YOLOv10模型，本文提出了一种新颖的方法，该方法在提高SAR目标检测性能的同时，有效降低了计算成本，为实际应用提供了新的视角。

Abstract: Synthetic Aperture Radar (SAR) object detection faces significant challenges
from speckle noise, small target ambiguities, and on-board computational
constraints. While existing approaches predominantly focus on SAR-specific
architectural modifications, this paper explores the application of the
existing lightweight object detector, i.e., YOLOv10, for SAR object detection
and enhances its performance through Neural Architecture Search (NAS).
Specifically, we employ NAS to systematically optimize the network structure,
especially focusing on the backbone architecture search. By constructing an
extensive search space and leveraging evolutionary search, our method
identifies a favorable architecture that balances accuracy, parameter
efficiency, and computational cost. Notably, this work introduces NAS to SAR
object detection for the first time. The experimental results on the
large-scale SARDet-100K dataset demonstrate that our optimized model
outperforms existing SAR detection methods, achieving superior detection
accuracy while maintaining lower computational overhead. We hope this work
offers a novel perspective on leveraging NAS for real-world applications.

</details>


### [121] [Multi-Representation Adapter with Neural Architecture Search for Efficient Range-Doppler Radar Object Detection](https://arxiv.org/abs/2509.01280)
*Zhiwei Lin,Weicheng Zheng,Yongtao Wang*

Main category: cs.CV

TL;DR: 本论文提出了一种用于距离-多普勒（RD）雷达图的高效目标检测模型，通过多表示（热图和灰度图）结合、适配器分支、交换器模块和主-辅助融合模块来提取、交换和融合特征。模型还利用神经架构搜索提高了效率和性能，并在RADDet和CARRADA数据集上取得了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决摄像头在光照和天气条件差时鲁棒性不足的问题，研究者们提出了从雷达传感器高效检测物体的趋势。

Method: 1. RD雷达图的多表示：将RD雷达图表示为热图和灰度图，以融合高层目标特征和细粒度纹理特征。2. 设计了适配器分支、包含两种模式的交换器模块以及主-辅助融合模块，用于有效地提取、交换和融合多表示输入中的特征。3. 构建了一个包含多种宽度和融合操作的超网，并采用一次性神经架构搜索方法来提高模型效率和保持高性能。

Result: 1. 模型在准确性和效率之间取得了良好的权衡。2. 在RADDet数据集上取得了mAP@50为71.9的最先进性能。3. 在CARRADA数据集上取得了mAP@50为57.1的最先进性能。

Conclusion: 本研究提出的模型通过结合多表示学习、定制的特征融合模块以及神经架构搜索，在RD雷达图目标检测任务上实现了优异的性能和效率。

Abstract: Detecting objects efficiently from radar sensors has recently become a
popular trend due to their robustness against adverse lighting and weather
conditions compared with cameras. This paper presents an efficient object
detection model for Range-Doppler (RD) radar maps. Specifically, we first
represent RD radar maps with multi-representation, i.e., heatmaps and grayscale
images, to gather high-level object and fine-grained texture features. Then, we
design an additional Adapter branch, an Exchanger Module with two modes, and a
Primary-Auxiliary Fusion Module to effectively extract, exchange, and fuse
features from the multi-representation inputs, respectively. Furthermore, we
construct a supernet with various width and fusion operations in the Adapter
branch for the proposed model and employ a One-Shot Neural Architecture Search
method to further improve the model's efficiency while maintaining high
performance. Experimental results demonstrate that our model obtains favorable
accuracy and efficiency trade-off. Moreover, we achieve new state-of-the-art
performance on RADDet and CARRADA datasets with mAP@50 of 71.9 and 57.1,
respectively.

</details>


### [122] [Cross-Domain Few-Shot Segmentation via Ordinary Differential Equations over Time Intervals](https://arxiv.org/abs/2509.01299)
*Huan Ni,Qingshan Liu,Xiaonan Niu,Danfeng Hong,Lingli Zhao,Haiyan Guan*

Main category: cs.CV

TL;DR: 本论文提出了一种名为FSS-TIs的端到端方法，利用常微分方程（ODE）和傅里叶变换来解决跨领域少样本分割（CD-FSS）问题，并通过在不同领域的数据集上进行评估，证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有CD-FSS方法通过多个独立模块提升跨领域泛化能力，但模块间的独立性限制了知识的有效流动和集体潜力。

Method: 提出一种基于常微分方程和傅里叶变换的all-in-one模块（FSS-TIs），假设领域特定特征和领域无关特征的谱（幅度谱和相位谱）之间存在ODE关系。通过时间间隔序列进行迭代变换，并对谱进行随机扰动的仿射变换。将领域无关特征表示空间的探索和潜在目标域分布的模拟重构为ODE内在参数的优化过程。同时，对目标域微调中的支持样本选择进行了严格约束。

Result: 在五个不同领域的数据集和两组CD-FSS任务上进行评估，实验结果表明FSS-TIs优于现有CD-FSS方法，并且消融研究验证了其跨领域适应性。

Conclusion: FSS-TIs通过其新颖的ODE和傅里叶变换方法，有效地解决了跨领域少样本分割问题，并在多个数据集上取得了优于现有方法的性能，证明了其强大的跨领域适应能力。

Abstract: Cross-domain few-shot segmentation (CD-FSS) not only enables the segmentation
of unseen categories with very limited samples, but also improves cross-domain
generalization ability within the few-shot segmentation framework. Currently,
existing CD-FSS studies typically design multiple independent modules to
enhance the cross-domain generalization ability of feature representations.
However, the independence among these modules hinders the effective flow of
knowledge, making it difficult to fully leverage their collective potential. In
contrast, this paper proposes an all-in-one module based on ordinary
differential equations and Fourier transform, resulting in a structurally
concise method--Few-Shot Segmentation over Time Intervals (FSS-TIs). FSS-TIs
assumes the existence of an ODE relationship between the spectra (including
amplitude and phase spectra) of domain-specific features and domain-agnostic
features. This ODE formulation yields an iterative transformation process along
a sequence of time intervals, while simultaneously applying affine
transformations with randomized perturbations to the spectra. In doing so, the
exploration of domain-agnostic feature representation spaces and the simulation
of diverse potential target-domain distributions are reformulated as an
optimization process over the intrinsic parameters of the ODE. Moreover, we
strictly constrain the support-sample selection during target-domain
fine-tuning so that it is consistent with the requirements of real-world
few-shot segmentation tasks. For evaluation, we introduce five datasets from
substantially different domains and define two sets of cross-domain few-shot
segmentation tasks to comprehensively analyze the performance of FSS-TIs.
Experimental results demonstrate the superiority of FSS-TIs over existing
CD-FSS methods, and in-depth ablation studies further validate the cross-domain
adaptability of FSS-TIs.

</details>


### [123] [Guided Model-based LiDAR Super-Resolution for Resource-Efficient Automotive scene Segmentation](https://arxiv.org/abs/2509.01317)
*Alexandros Gkillas,Nikos Piperigkos,Aris S. Lalos*

Main category: cs.CV

TL;DR: Low-cost LiDAR sensors produce sparse point clouds that degrade segmentation accuracy. This paper introduces an end-to-end framework that combines LiDAR super-resolution (SR) and semantic segmentation, using joint optimization and a novel SR loss function to improve accuracy for smaller objects. The proposed lightweight SR architecture achieves segmentation performance comparable to models using high-resolution LiDAR.


<details>
  <summary>Details</summary>
Motivation: High cost of advanced LiDAR sensors limits large-scale deployment for autonomous driving, while low-cost sensors produce sparse point clouds that reduce segmentation accuracy. There's a need for a method to improve segmentation accuracy using low-cost sensors.

Method: Introduced an end-to-end framework that jointly performs LiDAR super-resolution (SR) and semantic segmentation. Utilized joint optimization during training to allow the SR module to incorporate semantic cues and preserve fine details. Proposed a new SR loss function to focus the network on regions of interest. Developed a lightweight, model-based SR architecture with fewer parameters and compatibility with segmentation networks.

Result: The proposed lightweight SR architecture achieved segmentation performance comparable to models operating on high-resolution, costly 64-channel LiDAR data.

Conclusion: The developed framework effectively addresses the challenge of low-cost LiDAR data for autonomous driving by jointly optimizing super-resolution and semantic segmentation, achieving competitive accuracy with a lightweight architecture.

Abstract: High-resolution LiDAR data plays a critical role in 3D semantic segmentation
for autonomous driving, but the high cost of advanced sensors limits
large-scale deployment. In contrast, low-cost sensors such as 16-channel LiDAR
produce sparse point clouds that degrade segmentation accuracy. To overcome
this, we introduce the first end-to-end framework that jointly addresses LiDAR
super-resolution (SR) and semantic segmentation. The framework employs joint
optimization during training, allowing the SR module to incorporate semantic
cues and preserve fine details, particularly for smaller object classes. A new
SR loss function further directs the network to focus on regions of interest.
The proposed lightweight, model-based SR architecture uses significantly fewer
parameters than existing LiDAR SR approaches, while remaining easily compatible
with segmentation networks. Experiments show that our method achieves
segmentation performance comparable to models operating on high-resolution and
costly 64-channel LiDAR data.

</details>


### [124] [Prior-Guided Residual Diffusion: Calibrated and Efficient Medical Image Segmentation](https://arxiv.org/abs/2509.01330)
*Fuyou Mao,Beining Wu,Yanfeng Jiang,Han Xue,Yan Tang,Hao Zhang*

Main category: cs.CV

TL;DR: PGRD是一种基于扩散的模型，用于医学图像分割，能够学习体素级分布，提高准确性和校准性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中的歧义性需要能够捕捉完整条件分布而非单一估计值的模型。

Method: PGRD将离散标签嵌入连续空间中的独热目标，以使分割与扩散模型对齐。粗糙的先验预测器提供逐步指导；扩散网络然后学习对先验的残差，从而加速收敛并提高校准性。深度扩散监督方案通过监督中间时间步来进一步稳定训练。

Result: 在代表性的MRI和CT数据集上进行评估，PGRD实现了比贝叶斯、集成、概率U-Net和香草扩散基线更高的Dice分数和更低的NLL/ECE值，同时需要更少的采样步骤即可达到强劲性能。

Conclusion: PGRD通过结合先验引导和残差学习，在医学图像分割中实现了更优的性能和效率。

Abstract: Ambiguity in medical image segmentation calls for models that capture full
conditional distributions rather than a single point estimate. We present
Prior-Guided Residual Diffusion (PGRD), a diffusion-based framework that learns
voxel-wise distributions while maintaining strong calibration and practical
sampling efficiency. PGRD embeds discrete labels as one-hot targets in a
continuous space to align segmentation with diffusion modeling. A coarse prior
predictor provides step-wise guidance; the diffusion network then learns the
residual to the prior, accelerating convergence and improving calibration. A
deep diffusion supervision scheme further stabilizes training by supervising
intermediate time steps. Evaluated on representative MRI and CT datasets, PGRD
achieves higher Dice scores and lower NLL/ECE values than Bayesian, ensemble,
Probabilistic U-Net, and vanilla diffusion baselines, while requiring fewer
sampling steps to reach strong performance.

</details>


### [125] [Image Quality Enhancement and Detection of Small and Dense Objects in Industrial Recycling Processes](https://arxiv.org/abs/2509.01332)
*Oussama Messai,Abbass Zein-Eddine,Abdelouahid Bentamou,Mickaël Picq,Nicolas Duquesne,Stéphane Puydarrieux,Yann Gavet*

Main category: cs.CV

TL;DR: 本论文旨在解决计算机视觉中小、密集、重叠物体的检测以及工业环境中噪声图像的质量提升问题。通过使用包含10k+图像和120k+实例的新数据集，对基于监督式深度学习的方法进行评估，以确定最可靠的检测系统并突出其在工业应用中的挑战。此外，本文还研究了利用深度学习模型（特别是基于全连接卷积网络的光谱模型）来改善工业噪声图像质量，并提出了未来改进的方向。


<details>
  <summary>Details</summary>
Motivation: 工业环境中检测小、密集、重叠物体以及提升噪声图像质量是两大关键挑战。

Method: 本研究采用监督式深度学习方法，并使用新创建的包含10k+图像和120k+实例的数据集进行评估。此外，还引入了一个基于全连接卷积网络的光谱模型来提升图像质量。

Result: 通过评估不同方法的性能、准确性和计算效率，确定了最可靠的检测系统，并指出了它们在工业应用中面临的具体挑战。同时，提出了一个轻量级的图像质量提升模型。

Conclusion: 本研究通过对现有方法的评估和新模型的提出，为工业环境中的物体检测和图像质量提升提供了解决方案和未来研究方向。

Abstract: This paper tackles two key challenges: detecting small, dense, and
overlapping objects (a major hurdle in computer vision) and improving the
quality of noisy images, especially those encountered in industrial
environments. [1, 2]. Our focus is on evaluating methods built on supervised
deep learning. We perform an analysis of these methods, using a newly de-
veloped dataset comprising over 10k images and 120k in- stances. By evaluating
their performance, accuracy, and com- putational efficiency, we identify the
most reliable detection systems and highlight the specific challenges they
address in industrial applications. This paper also examines the use of deep
learning models to improve image quality in noisy industrial environments. We
introduce a lightweight model based on a fully connected convolutional network.
Addition- ally, we suggest potential future directions for further enhanc- ing
the effectiveness of the model. The repository of the dataset and proposed
model can be found at: https://github.com/o-messai/SDOOD,
https://github.com/o-messai/DDSRNet

</details>


### [126] [Street-Level Geolocalization Using Multimodal Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2509.01341)
*Yunus Serhat Bicakci,Joseph Shingleton,Anahid Basiri*

Main category: cs.CV

TL;DR: 本文提出了一种结合开源多模态大语言模型和检索增强生成技术的新方法，用于从街景图像进行地理定位，在多个基准数据集上实现了最先进的性能，且无需昂贵的微调或重新训练。


<details>
  <summary>Details</summary>
Motivation: 街头图像的地理定位对于导航、基于位置的推荐和城市规划等关键应用至关重要。随着社交媒体数据和智能手机摄像头日益普及，利用传统计算机视觉技术进行图像定位面临挑战，但仍具有很高的价值。

Method: 本方法整合了开源和公开的多模态大语言模型以及检索增强生成技术。使用SigLIP编码器在两个大规模数据集（EMP-16和OSV-5M）上构建了一个向量数据库。查询图像与从该数据库检索到的包含相似和不相似地理位置信息的提示相结合，然后由多模态大语言模型进行处理。

Result: 该方法在三个广泛使用的基准数据集（IM2GPS、IM2GPS3k和YFCC4k）上取得了优于现有方法的准确性，达到了最先进的性能。

Conclusion: 本文证明了基于检索增强生成的多模态大语言模型在地理定位估算方面的有效性，为GeoAI领域提供了一种可替代传统从头训练模型的方法，并开辟了更易于访问和可扩展的解决方案的可能性。

Abstract: Street-level geolocalization from images is crucial for a wide range of
essential applications and services, such as navigation, location-based
recommendations, and urban planning. With the growing popularity of social
media data and cameras embedded in smartphones, applying traditional computer
vision techniques to localize images has become increasingly challenging, yet
highly valuable. This paper introduces a novel approach that integrates
open-weight and publicly accessible multimodal large language models with
retrieval-augmented generation. The method constructs a vector database using
the SigLIP encoder on two large-scale datasets (EMP-16 and OSV-5M). Query
images are augmented with prompts containing both similar and dissimilar
geolocation information retrieved from this database before being processed by
the multimodal large language models. Our approach has demonstrated
state-of-the-art performance, achieving higher accuracy compared against three
widely used benchmark datasets (IM2GPS, IM2GPS3k, and YFCC4k). Importantly, our
solution eliminates the need for expensive fine-tuning or retraining and scales
seamlessly to incorporate new data sources. The effectiveness of
retrieval-augmented generation-based multimodal large language models in
geolocation estimation demonstrated by this paper suggests an alternative path
to the traditional methods which rely on the training models from scratch,
opening new possibilities for more accessible and scalable solutions in GeoAI.

</details>


### [127] [AgroSense: An Integrated Deep Learning System for Crop Recommendation via Soil Image Analysis and Nutrient Profiling](https://arxiv.org/abs/2509.01344)
*Vishal Pandey,Ranjita Das,Debasmita Biswas*

Main category: cs.CV

TL;DR: AgroSense是一个深度学习框架，集成了土壤图像分类和养分分析，以提供实时、准确的作物推荐，解决了传统土壤分析方法缓慢、劳动密集的问题。


<details>
  <summary>Details</summary>
Motivation: 为了满足日益增长的全球粮食安全和可持续农业需求，需要能够实时运行的智能作物推荐系统。传统土壤分析方法存在响应慢、劳动量大、不适用于现场决策等局限性。

Method: AgroSense框架包含两个主要部分：1. 土壤分类模块，使用ResNet-18、EfficientNet-B0和Vision Transformer对土壤图像进行分类；2. 作物推荐模块，利用多层感知器、XGBoost、LightGBM和TabNet分析结构化土壤数据（包括养分水平、pH值和降雨量）。研究人员还整理了一个包含10,000个配对样本的多模态数据集，用于实验评估。

Result: AgroSense的融合模型达到了98.0%的准确率，精确率为97.8%，召回率为97.7%，F1分数达到96.75%。同时，均方根误差（RMSE）和平均绝对误差（MAE）分别降至0.32和0.27。消融研究证明了多模态耦合的关键作用，而t检验和ANOVA统计验证了改进的显著性。

Conclusion: AgroSense为精准农业中的实时决策支持提供了一个实用且可扩展的解决方案，并为资源受限环境中未来轻量级多模态人工智能系统奠定了基础。

Abstract: Meeting the increasing global demand for food security and sustainable
farming requires intelligent crop recommendation systems that operate in real
time. Traditional soil analysis techniques are often slow, labor-intensive, and
not suitable for on-field decision-making. To address these limitations, we
introduce AgroSense, a deep-learning framework that integrates soil image
classification and nutrient profiling to produce accurate and contextually
relevant crop recommendations. AgroSense comprises two main components: a Soil
Classification Module, which leverages ResNet-18, EfficientNet-B0, and Vision
Transformer architectures to categorize soil types from images; and a Crop
Recommendation Module, which employs a Multi-Layer Perceptron, XGBoost,
LightGBM, and TabNet to analyze structured soil data, including nutrient
levels, pH, and rainfall. We curated a multimodal dataset of 10,000 paired
samples drawn from publicly available Kaggle repositories, approximately 50,000
soil images across seven classes, and 25,000 nutrient profiles for experimental
evaluation. The fused model achieves 98.0% accuracy, with a precision of 97.8%,
a recall of 97.7%, and an F1-score of 96.75%, while RMSE and MAE drop to 0.32
and 0.27, respectively. Ablation studies underscore the critical role of
multimodal coupling, and statistical validation via t-tests and ANOVA confirms
the significance of our improvements. AgroSense offers a practical, scalable
solution for real-time decision support in precision agriculture and paves the
way for future lightweight multimodal AI systems in resource-constrained
environments.

</details>


### [128] [M3Ret: Unleashing Zero-shot Multimodal Medical Image Retrieval via Self-Supervision](https://arxiv.org/abs/2509.01360)
*Che Liu,Zheng Jiang,Chengyu Fang,Heng Guo,Yan-Jie Zhou,Jiaqi Qu,Le Lu,Minfeng Xu*

Main category: cs.CV

TL;DR: 我们提出了M3Ret，一个统一的视觉编码器，通过结合MAE和SimDINO自监督学习范式，在混合模态医学图像检索任务上达到了新的SOTA水平，并展示了跨模态对齐和对未见模态的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像检索方法在2D、3D和视频数据上存在碎片化和特定模态的设计，阻碍了可扩展性和统一表示的发展。

Method: 我们创建了一个包含867,653个医学影像样本的大规模混合模态数据集，并使用MAE和SimDINO自监督学习范式在无特定模态定制的情况下训练了一个统一视觉编码器M3Ret。

Result: M3Ret在零样本图像到图像检索方面设定了新的SOTA，超越了DINOv3和BMC-CLIP等基线，并实现了无需配对数据的跨模态对齐，以及对未见过的MRI任务的泛化能力。

Conclusion: M3Ret展示了纯视觉自监督学习在多模态医学图像理解中的泛化能力，证明了其在模型和数据规模上的可扩展性，为构建医学视觉自监督基础模型奠定了基础。

Abstract: Medical image retrieval is essential for clinical decision-making and
translational research, relying on discriminative visual representations. Yet,
current methods remain fragmented, relying on separate architectures and
training strategies for 2D, 3D, and video-based medical data. This
modality-specific design hampers scalability and inhibits the development of
unified representations. To enable unified learning, we curate a large-scale
hybrid-modality dataset comprising 867,653 medical imaging samples, including
2D X-rays and ultrasounds, RGB endoscopy videos, and 3D CT scans. Leveraging
this dataset, we train M3Ret, a unified visual encoder without any
modality-specific customization. It successfully learns transferable
representations using both generative (MAE) and contrastive (SimDINO)
self-supervised learning (SSL) paradigms. Our approach sets a new
state-of-the-art in zero-shot image-to-image retrieval across all individual
modalities, surpassing strong baselines such as DINOv3 and the text-supervised
BMC-CLIP. More remarkably, strong cross-modal alignment emerges without paired
data, and the model generalizes to unseen MRI tasks, despite never observing
MRI during pretraining, demonstrating the generalizability of purely visual
self-supervision to unseen modalities. Comprehensive analyses further validate
the scalability of our framework across model and data sizes. These findings
deliver a promising signal to the medical imaging community, positioning M3Ret
as a step toward foundation models for visual SSL in multimodal medical image
understanding.

</details>


### [129] [Identity-Preserving Text-to-Video Generation via Training-Free Prompt, Image, and Guidance Enhancement](https://arxiv.org/abs/2509.01362)
*Jiayi Gao,Changcheng Hua,Qingchao Chen,Yuxin Peng,Yang Liu*

Main category: cs.CV

TL;DR: 提出了一种名为TPIGE的免训练框架，通过增强提示、参考图像和生成过程中的引导，来提升文本到视频生成中身份保持和视频质量，无需对大型预训练视频扩散模型进行微调。


<details>
  <summary>Details</summary>
Motivation:  IPT2V（Identity-preserving text-to-video generation）在保持参考主体图像和文本提示的同时生成视频，但数据稀缺和高昂的微调成本限制了其发展。本研究旨在提出一种低成本的解决方案，以提高IPT2V的性能。

Method: TPIGE框架包含三个主要部分：1. 面部感知提示增强：利用GPT-4o从参考图像中提取面部细节来增强文本提示。2. 提示感知参考图像增强：使用保留身份的图像生成器来优化参考图像，解决其与文本提示的冲突。3. ID感知时空引导增强：在视频生成过程中，利用统一梯度联合优化身份保持和视频质量。

Result: TPIGE框架在自动和人工评估中均优于现有方法，并在ACM Multimedia 2025身份保持视频生成挑战赛中获得第一名，证明了其在身份保持和视频质量方面的先进性能和泛化能力。

Conclusion: TPIGE框架通过其提出的三种增强技术，有效地解决了IPT2V中的数据稀缺和高成本问题，实现了高性能的身份保持和视频生成，且无需对现有模型进行微调。

Abstract: Identity-preserving text-to-video (IPT2V) generation creates videos faithful
to both a reference subject image and a text prompt. While fine-tuning large
pretrained video diffusion models on ID-matched data achieves state-of-the-art
results on IPT2V, data scarcity and high tuning costs hinder broader
improvement. We thus introduce a Training-Free Prompt, Image, and Guidance
Enhancement (TPIGE) framework that bridges the semantic gap between the video
description and the reference image and design sampling guidance that enhances
identity preservation and video quality, achieving performance gains at minimal
cost.Specifically, we first propose Face Aware Prompt Enhancement, using GPT-4o
to enhance the text prompt with facial details derived from the reference
image. We then propose Prompt Aware Reference Image Enhancement, leveraging an
identity-preserving image generator to refine the reference image, rectifying
conflicts with the text prompt. The above mutual refinement significantly
improves input quality before video generation. Finally, we propose ID-Aware
Spatiotemporal Guidance Enhancement, utilizing unified gradients to optimize
identity preservation and video quality jointly during generation.Our method
outperforms prior work and is validated by automatic and human evaluations on a
1000 video test set, winning first place in the ACM Multimedia 2025
Identity-Preserving Video Generation Challenge, demonstrating state-of-the-art
performance and strong generality. The code is available at
https://github.com/Andyplus1/IPT2V.git.

</details>


### [130] [Uirapuru: Timely Video Analytics for High-Resolution Steerable Cameras on Edge Devices](https://arxiv.org/abs/2509.01371)
*Guilherme H. Apostolo,Pablo Bauszat,Vinod Nigade,Henri E. Bal,Lin Wang*

Main category: cs.CV

TL;DR: Uirapuru是一个用于高分辨率可控摄像头进行实时、边缘视频分析的新框架，通过理解摄像头驱动并结合快速自适应分块来解决现有方法的局限性，在准确性和延迟方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高分辨率可控摄像头在智能交通和人群监控等领域具有广泛应用前景，但现有视频分析方法主要针对静态摄像头，难以处理可控摄像头带来的动态场景。本研究旨在解决这一挑战。

Method: Uirapuru框架结合了对摄像头驱动的全面理解和逐帧的快速自适应分块技术，以应对可控摄像头带来的动态场景挑战。

Result: 实验结果表明，与现有静态摄像头方法相比，Uirapuru在满足延迟要求的情况下准确率提高了1.45倍，或者在准确率相当的情况下推理速度提高了4.53倍。

Conclusion: Uirapuru框架能够有效地处理高分辨率可控摄像头带来的动态场景，在准确性和效率方面均表现出色，为实时视频分析提供了新的解决方案。

Abstract: Real-time video analytics on high-resolution cameras has become a popular
technology for various intelligent services like traffic control and crowd
monitoring. While extensive work has been done on improving analytics accuracy
with timing guarantees, virtually all of them target static viewpoint cameras.
In this paper, we present Uirapuru, a novel framework for real-time, edge-based
video analytics on high-resolution steerable cameras. The actuation performed
by those cameras brings significant dynamism to the scene, presenting a
critical challenge to existing popular approaches such as frame tiling. To
address this problem, Uirapuru incorporates a comprehensive understanding of
camera actuation into the system design paired with fast adaptive tiling at a
per-frame level. We evaluate Uirapuru on a high-resolution video dataset,
augmented by pan-tilt-zoom (PTZ) movements typical for steerable cameras and on
real-world videos collected from an actual PTZ camera. Our experimental results
show that Uirapuru provides up to 1.45x improvement in accuracy while
respecting specified latency budgets or reaches up to 4.53x inference speedup
with on-par accuracy compared to state-of-the-art static camera approaches.

</details>


### [131] [Unsupervised Ultra-High-Resolution UAV Low-Light Image Enhancement: A Benchmark, Metric and Framework](https://arxiv.org/abs/2509.01373)
*Wei Lu,Lingyu Zhu,Si-Bao Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为U3LIE的高效低光图像增强框架，专为超高分辨率（UHR）无人机（UAV）设计。为了解决现有方法在UHR、缺乏配对数据、非均匀照明和部署限制等方面的不足，该研究贡献了三个方面：1. 提出了U3D，这是首个用于低光图像增强的无监督UHR无人机数据集，并附带统一的评估工具包。2. 引入了边缘效率指数（EEI），一个衡量感知质量与速度、分辨率、模型复杂度和内存占用等部署因素的综合指标。3. 开发了U3LIE框架，包含自适应预增强增强（APA）和亮度区间损失（L_int）两种训练方法，能够有效处理低光问题。U3LIE在处理4K图像时达到了23.8 FPS的帧率，适用于实时部署，为实现全天候无人机视觉提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 低光照条件严重影响无人机（UAV）在关键应用中的性能。现有的低光图像增强（LIE）方法难以应对航空影像特有的挑战，包括超高分辨率（UHR）、缺乏配对数据、严重的非均匀照明以及部署限制。

Method: 该研究提出了U3LIE框架，包含两种仅训练的设计：自适应预增强增强（APA）用于输入归一化，以及亮度区间损失（L_int）用于曝光控制。此外，还引入了边缘效率指数（EEI）作为评估指标。

Result: U3LIE框架实现了最先进（SOTA）的结果，能够在单个GPU上以23.8 FPS处理4K图像，非常适合实时机载部署。

Conclusion: 该论文提出的数据集（U3D）、指标（EEI）和方法（U3LIE）为提升鲁棒的全天候无人机视觉提供了全面的解决方案。U3LIE框架能够高效处理UHR低光航空影像，并满足实时部署的需求。

Abstract: Low light conditions significantly degrade Unmanned Aerial Vehicles (UAVs)
performance in critical applications. Existing Low-light Image Enhancement
(LIE) methods struggle with the unique challenges of aerial imagery, including
Ultra-High Resolution (UHR), lack of paired data, severe non-uniform
illumination, and deployment constraints. To address these issues, we propose
three key contributions. First, we present U3D, the first unsupervised UHR UAV
dataset for LIE, with a unified evaluation toolkit. Second, we introduce the
Edge Efficiency Index (EEI), a novel metric balancing perceptual quality with
key deployment factors: speed, resolution, model complexity, and memory
footprint. Third, we develop U3LIE, an efficient framework with two
training-only designs-Adaptive Pre-enhancement Augmentation (APA) for input
normalization and a Luminance Interval Loss (L_int) for exposure control. U3LIE
achieves SOTA results, processing 4K images at 23.8 FPS on a single GPU, making
it ideal for real-time on-board deployment. In summary, these contributions
provide a holistic solution (dataset, metric, and method) for advancing robust
24/7 UAV vision. The code and datasets are available at
https://github.com/lwCVer/U3D_Toolkit.

</details>


### [132] [Enhancing Partially Relevant Video Retrieval with Robust Alignment Learning](https://arxiv.org/abs/2509.01383)
*Long Zhang,Peipei Song,Jianfeng Dong,Kun Li,Xun Yang*

Main category: cs.CV

TL;DR: 该论文提出了一种名为鲁棒对齐学习（RAL）的框架，用于解决部分相关视频检索（PRVR）中的数据不确定性问题，通过概率建模和可学习的置信门来提高检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有PRVR方法在处理查询模糊性和视频不相关片段引入的噪声时表现不佳，容易受到虚假相似性的干扰。

Method: RAL框架通过将视频和查询编码为多元高斯分布来对数据不确定性进行建模，并引入可学习的置信门来动态加权相似性。

Result: RAL框架作为一种即插即用解决方案，可以无缝集成到现有架构中，并在各种检索骨干网络上的大量实验证明了其有效性。

Conclusion: RAL通过概率建模和置信门有效解决了PRVR中的数据不确定性问题，提高了检索性能。

Abstract: Partially Relevant Video Retrieval (PRVR) aims to retrieve untrimmed videos
partially relevant to a given query. The core challenge lies in learning robust
query-video alignment against spurious semantic correlations arising from
inherent data uncertainty: 1) query ambiguity, where the query incompletely
characterizes the target video and often contains uninformative tokens, and 2)
partial video relevance, where abundant query-irrelevant segments introduce
contextual noise in cross-modal alignment. Existing methods often focus on
enhancing multi-scale clip representations and retrieving the most relevant
clip. However, the inherent data uncertainty in PRVR renders them vulnerable to
distractor videos with spurious similarities, leading to suboptimal
performance. To fill this research gap, we propose Robust Alignment Learning
(RAL) framework, which explicitly models the uncertainty in data. Key
innovations include: 1) we pioneer probabilistic modeling for PRVR by encoding
videos and queries as multivariate Gaussian distributions. This not only
quantifies data uncertainty but also enables proxy-level matching to capture
the variability in cross-modal correspondences; 2) we consider the
heterogeneous informativeness of query words and introduce learnable confidence
gates to dynamically weight similarity. As a plug-and-play solution, RAL can be
seamlessly integrated into the existing architectures. Extensive experiments
across diverse retrieval backbones demonstrate its effectiveness.

</details>


### [133] [RibPull: Implicit Occupancy Fields and Medial Axis Extraction for CT Ribcage Scans](https://arxiv.org/abs/2509.01402)
*Emmanouil Nikolakakis,Amine Ouasfi,Julie Digne,Razvan Marinescu*

Main category: cs.CV

TL;DR: RibPull是一种利用隐式占用场连接计算几何和医学成像的方法，使用神经占用场表示CT扫描的肋骨，并通过拉普拉斯收缩提取肋骨的中心轴。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统体素网格在分辨率、拓扑信息损失和稀疏数据处理方面的局限性，提出使用隐式3D表示（特别是神经占用场）来处理医学成像数据，以更好地表示稀疏数据并进行几何操作。

Method: 使用神经占用场（Neural Occupancy Fields）来表示CT扫描的肋骨，并应用基于拉普拉斯的收缩（Laplacian-based contraction）来提取肋骨的中心轴。

Result: 成功地使用神经占用场表示肋骨，并通过拉普拉斯收缩提取了肋骨的中心轴，证明了连续坐标表示在几何操作上的优势。

Conclusion: RibPull方法通过利用隐式占用场，有效地连接了计算几何和医学成像，为处理稀疏医学数据和执行几何操作提供了一种比基于体素的方法更优的解决方案。

Abstract: We present RibPull, a methodology that utilizes implicit occupancy fields to
bridge computational geometry and medical imaging. Implicit 3D representations
use continuous functions that handle sparse and noisy data more effectively
than discrete methods. While voxel grids are standard for medical imaging, they
suffer from resolution limitations, topological information loss, and
inefficient handling of sparsity. Coordinate functions preserve complex
geometrical information and represent a better solution for sparse data
representation, while allowing for further morphological operations. Implicit
scene representations enable neural networks to encode entire 3D scenes within
their weights. The result is a continuous function that can implicitly
compesate for sparse signals and infer further information about the 3D scene
by passing any combination of 3D coordinates as input to the model. In this
work, we use neural occupancy fields that predict whether a 3D point lies
inside or outside an object to represent CT-scanned ribcages. We also apply a
Laplacian-based contraction to extract the medial axis of the ribcage, thus
demonstrating a geometrical operation that benefits greatly from continuous
coordinate-based 3D scene representations versus voxel-based representations.
We evaluate our methodology on 20 medical scans from the RibSeg dataset, which
is itself an extension of the RibFrac dataset. We will release our code upon
publication.

</details>


### [134] [Neural Scene Designer: Self-Styled Semantic Image Manipulation](https://arxiv.org/abs/2509.01405)
*Jianman Lin,Tianshui Chen,Chunmei Qing,Zhijing Yang,Shuangping Huang,Yuheng Ren,Liang Lin*

Main category: cs.CV

TL;DR: Neural Scene Designer (NSD) enables photo-realistic image editing with semantic control and style consistency using a diffusion model with parallel cross-attention mechanisms and a Progressive Self-style Representational Learning (PSRL) module. A benchmark was also created to evaluate the effectiveness of such methods.


<details>
  <summary>Details</summary>
Motivation: Maintaining stylistic consistency is crucial for image editing and inpainting, but existing methods often neglect this aspect, focusing primarily on semantic control.

Method: The study introduces the Neural Scene Designer (NSD), a framework using a diffusion model with two parallel cross-attention mechanisms for text and style information. It also proposes the Progressive Self-style Representational Learning (PSRL) module with a style contrastive loss to learn fine-grained style representations. A benchmark with metrics, datasets, and settings was established for evaluation.

Result: Experiments on the established benchmark demonstrate the effectiveness of the proposed NSD framework.

Conclusion: The NSD framework effectively achieves photo-realistic manipulation with semantic alignment and style consistency, outperforming existing methods evaluated on a newly created benchmark.

Abstract: Maintaining stylistic consistency is crucial for the cohesion and aesthetic
appeal of images, a fundamental requirement in effective image editing and
inpainting. However, existing methods primarily focus on the semantic control
of generated content, often neglecting the critical task of preserving this
consistency. In this work, we introduce the Neural Scene Designer (NSD), a
novel framework that enables photo-realistic manipulation of user-specified
scene regions while ensuring both semantic alignment with user intent and
stylistic consistency with the surrounding environment. NSD leverages an
advanced diffusion model, incorporating two parallel cross-attention mechanisms
that separately process text and style information to achieve the dual
objectives of semantic control and style consistency. To capture fine-grained
style representations, we propose the Progressive Self-style Representational
Learning (PSRL) module. This module is predicated on the intuitive premise that
different regions within a single image share a consistent style, whereas
regions from different images exhibit distinct styles. The PSRL module employs
a style contrastive loss that encourages high similarity between
representations from the same image while enforcing dissimilarity between those
from different images. Furthermore, to address the lack of standardized
evaluation protocols for this task, we establish a comprehensive benchmark.
This benchmark includes competing algorithms, dedicated style-related metrics,
and diverse datasets and settings to facilitate fair comparisons. Extensive
experiments conducted on our benchmark demonstrate the effectiveness of the
proposed framework.

</details>


### [135] [MILO: A Lightweight Perceptual Quality Metric for Image and Latent-Space Optimization](https://arxiv.org/abs/2509.01411)
*Uğur Çoğalan,Mojtaba Bemana,Karol Myszkowski,Hans-Peter Seidel,Colin Groth*

Main category: cs.CV

TL;DR: MILO是一种轻量级、多尺度、感知指标，用于全参考图像质量评估（FR-IQA）。它使用伪MOS（平均意见得分）进行训练，无需大规模人类标注数据集，并在标准FR-IQA基准测试中表现优于现有指标。MILO还可用作图像和潜在空间的感知损失，通过结合空间掩蔽和课程学习策略，提高了去噪、超分辨率和人脸修复等任务的性能，并降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 提出一种轻量级、多尺度、感知指标（MILO），用于全参考图像质量评估（FR-IQA），旨在无需大规模人类标注数据集即可实现准确学习，并能在实时应用中实现快速推理。

Method: MILO使用伪MOS（平均意见得分）进行训练，通过对多样化图像应用可复现的失真并利用考虑视觉掩蔽效应的近期质量指标集成进行评分。MILO也被用作图像和潜在空间的感知损失，结合了空间掩蔽和课程学习策略。

Result: MILO在标准FR-IQA基准测试中表现优于现有指标，并适用于实时应用。在潜在空间优化中，MILO结合空间掩蔽和课程学习策略，显著提高了去噪、超分辨率和人脸修复等任务的性能，同时降低了计算开销。

Conclusion: MILO既是先进的图像质量指标，也是生成流程中感知优化的实用工具。

Abstract: We present MILO (Metric for Image- and Latent-space Optimization), a
lightweight, multiscale, perceptual metric for full-reference image quality
assessment (FR-IQA). MILO is trained using pseudo-MOS (Mean Opinion Score)
supervision, in which reproducible distortions are applied to diverse images
and scored via an ensemble of recent quality metrics that account for visual
masking effects. This approach enables accurate learning without requiring
large-scale human-labeled datasets. Despite its compact architecture, MILO
outperforms existing metrics across standard FR-IQA benchmarks and offers fast
inference suitable for real-time applications. Beyond quality prediction, we
demonstrate the utility of MILO as a perceptual loss in both image and latent
domains. In particular, we show that spatial masking modeled by MILO, when
applied to latent representations from a VAE encoder within Stable Diffusion,
enables efficient and perceptually aligned optimization. By combining spatial
masking with a curriculum learning strategy, we first process perceptually less
relevant regions before progressively shifting the optimization to more
visually distorted areas. This strategy leads to significantly improved
performance in tasks like denoising, super-resolution, and face restoration,
while also reducing computational overhead. MILO thus functions as both a
state-of-the-art image quality metric and as a practical tool for perceptual
optimization in generative pipelines.

</details>


### [136] [Bangladeshi Street Food Calorie Estimation Using Improved YOLOv8 and Regression Model](https://arxiv.org/abs/2509.01415)
*Aparup Dhar,MD Tamim Hossain,Pritom Barua*

Main category: cs.CV

TL;DR: 该研究针对孟加拉国街头食品开发了一种自动卡路里估算系统，解决了现有方法的局限性，并在卡路里估算方面取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 随着肥胖率的上升，自动卡路里追踪对于维持健康生活方式至关重要。现有方法存在局限性，例如仅提供恒定的卡路里输出、难以处理多种食物识别、图像缩放和归一化挑战，并且主要关注西方美食。

Method: 研究人员首先构建了一个包含孟加拉国街头食品的数据集，然后通过修改先进的视觉模型 YOLOv8 来开发一个改进的卡路里估算系统。该修改后的模型在分类和分割方面取得了更好的结果，同时计算复杂度略有增加。结合机器学习回归模型，该系统实现了 6.94 的平均绝对误差 (MAE)、11.03 的均方根误差 (RMSE) 和 96.0% 的 R^2 分数。

Result: 该系统在卡路里估算方面取得了 6.94 的平均绝对误差 (MAE)、11.03 的均方根误差 (RMSE) 和 96.0% 的 R^2 分数，表明其在实际食物卡路里计算方面非常有效和准确。

Conclusion: 该研究成功开发了一个针对孟加拉国街头食品的定制化自动卡路里估算解决方案，并通过改进 YOLOv8 模型和结合机器学习回归，实现了高精度的卡路里估算，有效解决了现有方法的局限性。

Abstract: As obesity rates continue to increase, automated calorie tracking has become
a vital tool for people seeking to maintain a healthy lifestyle or adhere to a
diet plan. Although numerous research efforts have addressed this issue,
existing approaches often face key limitations, such as providing only constant
caloric output, struggling with multiple food recognition challenges,
challenges in image scaling and normalization, and a predominant focus on
Western cuisines. In this paper, we propose a tailored solution that
specifically targets Bangladeshi street food. We first construct a diverse
dataset of popular street foods found across Bangladesh. Then, we develop a
refined calorie estimation system by modifying the state-of-the-art vision
model YOLOv8. Our modified model achieves superior classification and
segmentation results, with only a slight increase in computational complexity
compared to the base variant. Coupled with a machine learning regression model,
our system achieves an impressive 6.94 mean absolute error (MAE), 11.03 root
mean squared error (RMSE), and a 96.0% R^2 score in calorie estimation, making
it both highly effective and accurate for real-world food calorie calculations.

</details>


### [137] [InfoScale: Unleashing Training-free Variable-scaled Image Generation via Effective Utilization of Information](https://arxiv.org/abs/2509.01421)
*Guohui Zhang,Jiangtong Tan,Linjiang Huang,Zhonghang Yuan,Naishan Zheng,Jie Huang,Feng Zhao*

Main category: cs.CV

TL;DR: Diffusion models在不同分辨率生成时性能下降，本文提出了InfoScale框架，通过渐进频率补偿、自适应信息聚合和噪声适应模块来解决信息损失、信息聚合不灵活和信息分布不匹配的问题，以提升可变分辨率图像生成能力。


<details>
  <summary>Details</summary>
Motivation: Diffusion models在生成不同分辨率的图像时存在性能下降问题，这主要是由于不同分辨率下信息的量存在差异，需要不同的信息转换程序。

Method: 本文提出了InfoScale框架，一个以信息为中心的方法，通过以下三个模块来解决可变分辨率生成的问题：1) 渐进频率补偿模块：补偿扩张卷积在生成高分辨率图像时丢失的高频信息。2) 自适应信息聚合模块：解决注意力机制在生成可变分辨率图像时信息聚合的自适应性不足问题，平衡局部与全局信息。3) 噪声适应模块：重新分布初始噪声中的信息，以适应可变分辨率的生成。

Result: InfoScale框架是即插即用的，并且在可变分辨率图像生成方面表现出了有效性，大量实验证明了这一点。

Conclusion: InfoScale框架通过解决高频信息丢失、信息聚合不灵活和初始噪声信息分布不匹配等问题，显著提升了Diffusion models在可变分辨率图像生成方面的性能。

Abstract: Diffusion models (DMs) have become dominant in visual generation but suffer
performance drop when tested on resolutions that differ from the training
scale, whether lower or higher. In fact, the key challenge in generating
variable-scale images lies in the differing amounts of information across
resolutions, which requires information conversion procedures to be varied for
generating variable-scaled images. In this paper, we investigate the issues of
three critical aspects in DMs for a unified analysis in variable-scaled
generation: dilated convolution, attention mechanisms, and initial noise.
Specifically, 1) dilated convolution in DMs for the higher-resolution
generation loses high-frequency information. 2) Attention for variable-scaled
image generation struggles to adjust the information aggregation adaptively. 3)
The spatial distribution of information in the initial noise is misaligned with
variable-scaled image. To solve the above problems, we propose
\textbf{InfoScale}, an information-centric framework for variable-scaled image
generation by effectively utilizing information from three aspects
correspondingly. For information loss in 1), we introduce Progressive Frequency
Compensation module to compensate for high-frequency information lost by
dilated convolution in higher-resolution generation. For information
aggregation inflexibility in 2), we introduce Adaptive Information Aggregation
module to adaptively aggregate information in lower-resolution generation and
achieve an effective balance between local and global information in
higher-resolution generation. For information distribution misalignment in 3),
we design Noise Adaptation module to re-distribute information in initial noise
for variable-scaled generation. Our method is plug-and-play for DMs and
extensive experiments demonstrate the effectiveness in variable-scaled image
generation.

</details>


### [138] [Mamba-CNN: A Hybrid Architecture for Efficient and Accurate Facial Beauty Prediction](https://arxiv.org/abs/2509.01431)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: Mamba-CNN是一种结合了CNN和Mamba的新型混合架构，用于人脸吸引力评估。它通过在CNN中引入Mamba门控机制，实现了对全局上下文的高效建模，并在SCUT-FBP5500基准测试中达到了新的SOTA，PC达到0.9187。


<details>
  <summary>Details</summary>
Motivation: 人脸吸引力评估是一个具有挑战性的主观回归任务，现有的CNN和ViT架构存在效率和全局上下文建模的权衡。CNN效率高但感受野有限，ViT能建模全局上下文但计算成本高昂。

Method: 提出了一种名为Mamba-CNN的新型混合架构，将轻量级的、受Mamba启发的状态空间模型（SSM）门控机制集成到分层卷积骨干网络中。这种机制能够动态调制特征图，选择性地强调面部特征及其长距离空间关系，以匹配人类的整体感知，同时保持计算效率。

Result: 在SCUT-FBP5500基准测试上进行了广泛的实验，Mamba-CNN达到了新的SOTA。具体指标包括：皮尔逊相关系数（PC）为0.9187，平均绝对误差（MAE）为0.2022，均方根误差（RMSE）为0.2610。

Conclusion: CNN与选择性SSM的结合具有协同潜力，为细致的视觉理解任务提供了一种强大的新架构范例。

Abstract: The computational assessment of facial attractiveness, a challenging
subjective regression task, is dominated by architectures with a critical
trade-off: Convolutional Neural Networks (CNNs) offer efficiency but have
limited receptive fields, while Vision Transformers (ViTs) model global context
at a quadratic computational cost. To address this, we propose Mamba-CNN, a
novel and efficient hybrid architecture. Mamba-CNN integrates a lightweight,
Mamba-inspired State Space Model (SSM) gating mechanism into a hierarchical
convolutional backbone. This core innovation allows the network to dynamically
modulate feature maps and selectively emphasize salient facial features and
their long-range spatial relationships, mirroring human holistic perception
while maintaining computational efficiency. We conducted extensive experiments
on the widely-used SCUT-FBP5500 benchmark, where our model sets a new
state-of-the-art. Mamba-CNN achieves a Pearson Correlation (PC) of 0.9187, a
Mean Absolute Error (MAE) of 0.2022, and a Root Mean Square Error (RMSE) of
0.2610. Our findings validate the synergistic potential of combining CNNs with
selective SSMs and present a powerful new architectural paradigm for nuanced
visual understanding tasks.

</details>


### [139] [SoccerHigh: A Benchmark Dataset for Automatic Soccer Video Summarization](https://arxiv.org/abs/2509.01439)
*Artur Díaz-Juan,Coloma Ballester,Gloria Haro*

Main category: cs.CV

TL;DR: 该论文提出了一个用于足球视频摘要的数据集和一种新的评估指标，并提供了一个基线模型。


<details>
  <summary>Details</summary>
Motivation: 体育视频摘要，特别是足球比赛集锦的自动生成，可以帮助体育媒体行业减少编辑时间和精力，但目前缺乏公开的数据集来支持相关模型的开发。

Method: 该研究创建了一个包含237场比赛的镜头边界的足球视频摘要数据集，并提出了一个用于此任务的基线模型，以及一种新的、考虑摘要长度限制的评估指标。

Result: 提出的基线模型在测试集上达到了0.3956的F1分数。

Conclusion: 该论文通过提供一个新的数据集、一个基线模型和一个新的评估指标，为足球视频摘要领域做出了贡献，并为未来的研究提供了基础。

Abstract: Video summarization aims to extract key shots from longer videos to produce
concise and informative summaries. One of its most common applications is in
sports, where highlight reels capture the most important moments of a game,
along with notable reactions and specific contextual events. Automatic summary
generation can support video editors in the sports media industry by reducing
the time and effort required to identify key segments. However, the lack of
publicly available datasets poses a challenge in developing robust models for
sports highlight generation. In this paper, we address this gap by introducing
a curated dataset for soccer video summarization, designed to serve as a
benchmark for the task. The dataset includes shot boundaries for 237 matches
from the Spanish, French, and Italian leagues, using broadcast footage sourced
from the SoccerNet dataset. Alongside the dataset, we propose a baseline model
specifically designed for this task, which achieves an F1 score of 0.3956 in
the test set. Furthermore, we propose a new metric constrained by the length of
each target summary, enabling a more objective evaluation of the generated
content. The dataset and code are available at
https://ipcv.github.io/SoccerHigh/.

</details>


### [140] [Traces of Image Memorability in Vision Encoders: Activations, Attention Distributions and Autoencoder Losses](https://arxiv.org/abs/2509.01453)
*Ece Takmaz,Albert Gatt,Jakub Dotlacil*

Main category: cs.CV

TL;DR: 图片的可记忆性可以通过预训练视觉编码器的潜在激活、注意力分布和图像块的均匀性来预测。Vision Transformer的稀疏自编码器损失也优于以往的CNN方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索预训练视觉编码器中的特征（如潜在激活、注意力分布和图像块的均匀性）与图像可记忆性之间的相关性，并提出一种基于Vision Transformer稀疏自编码器损失的新方法来预测图像可记忆性。

Method: 本文利用预训练视觉编码器，分析潜在激活、注意力分布和图像块均匀性与图像可记忆性的相关性。此外，还探索了Vision Transformer的稀疏自编码器损失作为图像可记忆性的代理指标。

Result: 研究发现，潜在激活、注意力分布和图像块均匀性在一定程度上与图像可记忆性相关。基于Vision Transformer稀疏自编码器损失的方法在预测图像可记忆性方面优于以往基于CNN的方法。

Conclusion: 研究结果表明，模型内部特征（特别是Vision Transformer的特征）可以作为预测人类图像可记忆性的有效指标，揭示了模型内部特征与可记忆性之间的关系。

Abstract: Images vary in how memorable they are to humans. Inspired by findings from
cognitive science and computer vision, this paper explores the correlates of
image memorability in pretrained vision encoders, focusing on latent
activations, attention distributions, and the uniformity of image patches. We
find that these features correlate with memorability to some extent.
Additionally, we explore sparse autoencoder loss over the representations of
vision transformers as a proxy for memorability, which yields results
outperforming past methods using convolutional neural network representations.
Our results shed light on the relationship between model-internal features and
memorability. They show that some features are informative predictors of what
makes images memorable to humans.

</details>


### [141] [Im2Haircut: Single-view Strand-based Hair Reconstruction for Human Avatars](https://arxiv.org/abs/2509.01469)
*Vanessa Sklyarova,Egor Zakharov,Malte Prinzler,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 通过结合全局毛发先验和局部优化，从单张照片中进行新颖的3D毛发重建。


<details>
  <summary>Details</summary>
Motivation: 从单张照片中捕捉基于发束的毛发几何形状具有挑战性，因为发型具有多样性和几何复杂性，并且缺乏真实的训练数据。现有的方法，如多视图立体，只能重建可见的发束，忽略了发型的内部结构，阻碍了逼真的毛发模拟。为了解决这个问题，现有方法利用在合成数据上训练的发型先验。然而，这类数据在数量和质量上都有限，因为它们需要熟练的艺术家进行手动工作来建模3D发型并创建近乎照片级的渲染。

Method: 提出了一种新颖的方法，该方法结合使用真实和合成数据来学习有效的发型先验。具体来说，在合成数据上训练一个基于Transformer的先验模型，以获得发型内部几何的知识，并在学习过程中引入真实数据来模拟外部结构。这种训练方案能够模拟输入图像中描绘的可见发束，同时保留发型的整体3D结构。利用该先验，创建了一种基于高斯泼溅的重建方法，该方法可以从一张或多张图像中创建发型。

Result: 与现有的重建流程进行定性和定量比较，证明了该方法在捕捉详细的毛发方向、整体轮廓和背面一致性方面的有效性和优越性能。

Conclusion: 通过结合全局毛发先验和局部优化，从单张照片中进行新颖的3D毛发重建。

Abstract: We present a novel approach for 3D hair reconstruction from single
photographs based on a global hair prior combined with local optimization.
Capturing strand-based hair geometry from single photographs is challenging due
to the variety and geometric complexity of hairstyles and the lack of ground
truth training data. Classical reconstruction methods like multi-view stereo
only reconstruct the visible hair strands, missing the inner structure of
hairstyles and hampering realistic hair simulation. To address this, existing
methods leverage hairstyle priors trained on synthetic data. Such data,
however, is limited in both quantity and quality since it requires manual work
from skilled artists to model the 3D hairstyles and create near-photorealistic
renderings. To address this, we propose a novel approach that uses both, real
and synthetic data to learn an effective hairstyle prior. Specifically, we
train a transformer-based prior model on synthetic data to obtain knowledge of
the internal hairstyle geometry and introduce real data in the learning process
to model the outer structure. This training scheme is able to model the visible
hair strands depicted in an input image, while preserving the general 3D
structure of hairstyles. We exploit this prior to create a
Gaussian-splatting-based reconstruction method that creates hairstyles from one
or more images. Qualitative and quantitative comparisons with existing
reconstruction pipelines demonstrate the effectiveness and superior performance
of our method for capturing detailed hair orientation, overall silhouette, and
backside consistency. For additional results and code, please refer to
https://im2haircut.is.tue.mpg.de.

</details>


### [142] [PointSlice: Accurate and Efficient Slice-Based Representation for 3D Object Detection from Point Clouds](https://arxiv.org/abs/2509.01487)
*Liu Qifeng,Zhao Dawei,Dong Yabo,Xiao Liang,Wang Juan,Min Chen,Li Fuyang,Jiang Weizhong,Lu Dongming,Nie Yiming*

Main category: cs.CV

TL;DR: PointSlice通过将3D点云切片化为2D数据，并引入Slice Interaction Network (SIN)来提高3D目标检测的推理速度和准确性，在多个数据集上取得了有竞争力的结果。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云目标检测方法中，基于体素的方法精度高但速度慢，基于柱体的方法速度快但精度不足。PointSlice旨在解决这一权衡问题。

Method: PointSlice提出了一种新颖的点云处理技术，将3D点云沿着水平面切片成多组2D（x-y）数据。模型仅学习2D数据分布，并将3D点云视为独立的2D数据批次，以减少模型参数量并提高推理速度。此外，引入了Slice Interaction Network (SIN)来维持跨切片的垂直关系，增强模型的3D感知能力。

Result: 在Waymo数据集上，PointSlice比SAFDNet快1.13倍，参数量减少0.79倍，精度仅降低1.2 mAPH。在nuScenes数据集上，实现了66.74 mAP的先进检测结果。在Argoverse 2数据集上，PointSlice速度提升1.10倍，参数量减少0.66倍，精度降低1.0 mAP。

Conclusion: PointSlice通过其创新的切片处理技术和SIN网络，成功地在3D目标检测任务中实现了高精度和高推理速度的平衡，并在多个公开数据集上验证了其有效性。

Abstract: 3D object detection from point clouds plays a critical role in autonomous
driving. Currently, the primary methods for point cloud processing are
voxel-based and pillarbased approaches. Voxel-based methods offer high accuracy
through fine-grained spatial segmentation but suffer from slower inference
speeds. Pillar-based methods enhance inference speed but still fall short of
voxel-based methods in accuracy. To address these issues, we propose a novel
point cloud processing method, PointSlice, which slices point clouds along the
horizontal plane and includes a dedicated detection network. The main
contributions of PointSlice are: (1) A new point cloud processing technique
that converts 3D point clouds into multiple sets of 2D (x-y) data slices. The
model only learns 2D data distributions, treating the 3D point cloud as
separate batches of 2D data, which reduces the number of model parameters and
enhances inference speed; (2) The introduction of a Slice Interaction Network
(SIN). To maintain vertical relationships across slices, we incorporate SIN
into the 2D backbone network, which improves the model's 3D object perception
capability. Extensive experiments demonstrate that PointSlice achieves high
detection accuracy and inference speed. On the Waymo dataset, PointSlice is
1.13x faster and has 0.79x fewer parameters than the state-of-the-art
voxel-based method (SAFDNet), with only a 1.2 mAPH accuracy reduction. On the
nuScenes dataset, we achieve a state-of-the-art detection result of 66.74 mAP.
On the Argoverse 2 dataset, PointSlice is 1.10x faster, with 0.66x fewer
parameters and a 1.0 mAP accuracy reduction. The code will be available at
https://github.com/qifeng22/PointSlice2.

</details>


### [143] [A Continuous-Time Consistency Model for 3D Point Cloud Generation](https://arxiv.org/abs/2509.01492)
*Sebastian Eilermann,René Heesch,Oliver Niggemann*

Main category: cs.CV

TL;DR: ConTiCoM-3D是一个连续时间一致性模型，可以直接在点空间生成3D形状，无需离散扩散步骤、预训练教师模型或潜在空间编码。该方法结合了TrigFlow启发的连续噪声调度和基于Chamfer距离的几何损失，实现了高效、高保真度的推理。


<details>
  <summary>Details</summary>
Motivation: 快速、准确地从点云生成3D形状对于机器人、AR/VR和数字内容创建等应用至关重要。

Method: ConTiCoM-3D整合了TrigFlow启发的连续噪声调度和基于Chamfer距离的几何损失，实现了在点空间直接生成3D形状，避免了离散扩散步骤、预训练教师模型或潜在空间编码。

Result: 实验结果表明，ConTiCoM-3D在ShapeNet基准测试中，在质量和效率方面均能媲美或超越最先进的扩散和潜在一致性模型。

Conclusion: ConTiCoM-3D是一个高效、高保真的3D形状生成框架，可扩展性强，适用于各种应用。

Abstract: Fast and accurate 3D shape generation from point clouds is essential for
applications in robotics, AR/VR, and digital content creation. We introduce
ConTiCoM-3D, a continuous-time consistency model that synthesizes 3D shapes
directly in point space, without discretized diffusion steps, pre-trained
teacher models, or latent-space encodings. The method integrates a
TrigFlow-inspired continuous noise schedule with a Chamfer Distance-based
geometric loss, enabling stable training on high-dimensional point sets while
avoiding expensive Jacobian-vector products. This design supports efficient
one- to two-step inference with high geometric fidelity. In contrast to
previous approaches that rely on iterative denoising or latent decoders,
ConTiCoM-3D employs a time-conditioned neural network operating entirely in
continuous time, thereby achieving fast generation. Experiments on the ShapeNet
benchmark show that ConTiCoM-3D matches or outperforms state-of-the-art
diffusion and latent consistency models in both quality and efficiency,
establishing it as a practical framework for scalable 3D shape generation.

</details>


### [144] [MSA2-Net: Utilizing Self-Adaptive Convolution Module to Extract Multi-Scale Information in Medical Image Segmentation](https://arxiv.org/abs/2509.01498)
*Chao Deng,Xiaosen Li,Xiao Qin*

Main category: cs.CV

TL;DR: nnUNet框架虽能自动调整大部分训练超参数，但忽略了网络内部超参数的调优，限制了模型的泛化能力。本研究提出了一种新颖的自适应卷积模块（Self-Adaptive Convolution Module），能根据不同数据集的特性动态调整卷积核大小，并将其集成到MSA2-Net的MSConvBridge和MSADecoder中，以提升模型捕获全局和局部特征的能力，优化不同尺度器官的分割精度。MSA2-Net在Synapse、ACDC、Kvasir和ISIC2017数据集上分别取得了86.49%、92.56%、93.37%和92.98%的Dice系数，展现了其在医学图像分割方面的鲁棒性和精确性。


<details>
  <summary>Details</summary>
Motivation: nnUNet框架在模型内部超参数调优方面的不足限制了其泛化能力。

Method: 提出一种自适应卷积模块（Self-Adaptive Convolution Module），动态调整卷积核大小，并将其集成到MSA2-Net的MSConvBridge和MSADecoder中。

Result: MSA2-Net在Synapse、ACDC、Kvasir和Skin Lesion Segmentation (ISIC2017)数据集上分别取得了86.49%、92.56%、93.37%和92.98%的Dice系数。

Conclusion: MSA2-Net通过集成自适应卷积模块，能够有效提升医学图像分割的精度和鲁棒性。

Abstract: The nnUNet segmentation framework adeptly adjusts most hyperparameters in
training scripts automatically, but it overlooks the tuning of internal
hyperparameters within the segmentation network itself, which constrains the
model's ability to generalize. Addressing this limitation, this study presents
a novel Self-Adaptive Convolution Module that dynamically adjusts the size of
the convolution kernels depending on the unique fingerprints of different
datasets. This adjustment enables the MSA2-Net, when equipped with this module,
to proficiently capture both global and local features within the feature maps.
Self-Adaptive Convolution Module is strategically integrated into two key
components of the MSA2-Net: the Multi-Scale Convolution Bridge and the
Multi-Scale Amalgamation Decoder. In the MSConvBridge, the module enhances the
ability to refine outputs from various stages of the CSWin Transformer during
the skip connections, effectively eliminating redundant data that could
potentially impair the decoder's performance. Simultaneously, the MSADecoder,
utilizing the module, excels in capturing detailed information of organs
varying in size during the decoding phase. This capability ensures that the
decoder's output closely reproduces the intricate details within the feature
maps, thus yielding highly accurate segmentation images. MSA2-Net, bolstered by
this advanced architecture, has demonstrated exceptional performance, achieving
Dice coefficient scores of 86.49\%, 92.56\%, 93.37\%, and 92.98\% on the
Synapse, ACDC, Kvasir, and Skin Lesion Segmentation (ISIC2017) datasets,
respectively. This underscores MSA2-Net's robustness and precision in medical
image segmentation tasks across various datasets.

</details>


### [145] [Variation-aware Vision Token Dropping for Faster Large Vision-Language Models](https://arxiv.org/abs/2509.01552)
*Junjie Chen,Xuyang Liu,Zichen Wen,Yiyu Wang,Siteng Huang,Honggang Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种名为 V$^2$Drop 的新方法，通过去除视觉令牌的冗余信息来提高大型视觉语言模型（LVLM）的推理效率，同时保持了出色的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LVLM在处理高分辨率图像和长视频时，由于令牌数量庞大，导致推理效率低下。现有的令牌压缩方法存在位置偏差和与高效算子不兼容的问题，限制了其在LVLM加速中的应用。

Method: 提出了一种从令牌变异角度出发的方法，发现在LVLM中视觉令牌的变异具有任务无关性。在此基础上，提出了V$^2$Drop（Variation-aware Vision Token Dropping），该方法在LVLM推理过程中逐步去除变异最小的视觉令牌，从而提高计算效率。该方法还可以与高效算子结合使用，进一步降低GPU峰值内存使用量。

Result: 在图像和视频理解任务中，V$^2$Drop分别保持了原始模型94.0%和98.6%的性能，同时将LVLM的生成延迟降低了31.5%和74.2%。

Conclusion: V$^2$Drop是一种有效且实用的方法，可以显著提高LVLM处理高分辨率图像和长视频的推理效率，同时保持高性能，并能与高效算子协同工作以进一步优化资源利用。

Abstract: Large vision-language models (LVLMs) have demonstrated remarkable
capabilities in multimodal understanding tasks. However, the increasing demand
for high-resolution image and long-video understanding results in substantial
token counts, leading to reduced inference efficiency. Token compression offers
a direct solution by reducing the number of tokens to be processed, thereby
improving computational efficiency. Through extensive analysis, we identify two
critical limitations in existing inner-LLM token compression methods:
positional bias and incompatibility with efficient operators, which hinder
their practical deployment for LVLM acceleration. This paper presents the first
approach from a token variation perspective, revealing that visual token
variations within LLMs exhibit task-agnostic properties. We propose
Variation-aware Vision Token Dropping (\textit{i.e.}, \textbf{V$^2$Drop}),
which progressively removes visual tokens with minimal variation during LVLM
inference, thereby enhancing computational efficiency. Extensive experiments
across multiple models and benchmarks demonstrate that our V$^2$Drop is able to
maintain \textbf{94.0\%} and \textbf{98.6\%} of the original model performance
for image and video understanding tasks respectively, while reducing LLM
generation latency by \textbf{31.5\%} and \textbf{74.2\%}. When combined with
efficient operators, V$^2$Drop further reduces GPU peak memory usage.

</details>


### [146] [Unified Supervision For Vision-Language Modeling in 3D Computed Tomography](https://arxiv.org/abs/2509.01554)
*Hao-Chih Lee,Zelong Liu,Hamza Ahmed,Spencer Kim,Sean Huver,Vishwesh Nath,Zahi A. Fayad,Timothy Deyer,Xueyan Mei*

Main category: cs.CV

TL;DR: Uniferum是一个通用的视觉-语言模型（VLM），可以处理放射学中的CT扫描，并通过整合不同来源的注释（包括分类标签和分割掩码）来提高性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的通用视觉-语言模型（VLM）在放射学领域存在识别精度不足的问题，难以满足临床需求，这主要是由于缺乏大规模标记数据集以及公开的CT数据集的稀疏性和异质性。

Method: 提出了一种名为Uniferum的VLM，它通过一个统一的训练框架整合了分类标签和分割掩膜这两种不同的监督信号，并对三个具有不同注释的公开3D CT数据集进行了协调。

Result: Uniferum在CT-RATE基准测试中将AUROC提高了7%，优于基于CLIP和传统多标签卷积模型。该模型还表现出强大的分布外泛化能力，在RAD-CHEST和INSPECT数据集上展现了意想不到的零样本性能。

Conclusion: 整合异类注释和身体分割可以提高3D医学成像中VLM的性能，为开发临床可靠、数据高效的VLM指明了新的方向。

Abstract: General-purpose vision-language models (VLMs) have emerged as promising tools
in radiology, offering zero-shot capabilities that mitigate the need for large
labeled datasets. However, in high-stakes domains like diagnostic radiology,
these models often lack the discriminative precision required for reliable
clinical use. This challenge is compounded by the scarcity and heterogeneity of
publicly available volumetric CT datasets, which vary widely in annotation
formats and granularity. To address these limitations, we introduce Uniferum, a
volumetric VLM that unifies diverse supervision signals, encoded in
classification labels and segmentation masks, into a single training framework.
By harmonizing three public 3D CT datasets with distinct annotations, Uniferum
achieves state-of-the-art performance, improving AUROC on the CT-RATE benchmark
by 7% compared to CLIP-based and conventional multi-label convolutional models.
The model demonstrates robust out-of-distribution generalization, with observed
evidence of unexpected zero-shot performance on the RAD-CHEST and INSPECT
datasets. Our results highlight the effectiveness of integrating heterogeneous
annotations and body segmentation to enhance model performance, setting a new
direction for clinically reliable, data-efficient VLMs in 3D medical imaging.

</details>


### [147] [Acoustic Interference Suppression in Ultrasound images for Real-Time HIFU Monitoring Using an Image-Based Latent Diffusion Model](https://arxiv.org/abs/2509.01557)
*Dejia Cai,Yao Ran,Kun Yang,Xinwang Shi,Yingying Zhou,Kexian Wu,Yang Xu,Yi Hu,Xiaowei Zhou*

Main category: cs.CV

TL;DR:  HIFU-ILDiff是一种利用隐式扩散模型去除超声图像中高强度聚焦超声（HIFU）干扰的新型深度学习方法，可实现实时处理并提高治疗精度。


<details>
  <summary>Details</summary>
Motivation: 高强度聚焦超声（HIFU）治疗的成功和安全依赖于实时监测，但超声引导下的HIFU治疗常受到干扰。本研究旨在解决HIFU治疗中超声图像干扰的问题。

Method: 开发了一种名为HIFU-ILDiff的新型深度学习方法，该方法利用矢量量化变分自编码器（VQ-VAE）将含噪声的超声图像编码到低维潜在空间，然后使用隐式扩散模型迭代去除干扰，最后将去噪后的潜在向量解码以重建高分辨率、无干扰的超声图像。

Result: HIFU-ILDiff在体外实验中取得了显著优于缺口滤波器的性能，SSIM达到0.796，PSNR达到23.780，而缺口滤波器的SSIM为0.443，PSNR为14.420。此外，HIFU-ILDiff实现了15帧/秒的实时处理速度，远快于缺口滤波器的5秒/帧。

Conclusion: HIFU-ILDiff能够有效去除HIFU治疗中超声引导图像的干扰，实现实时监测，从而显著提高临床应用的治疗精度。

Abstract: High-Intensity Focused Ultrasound (HIFU) is a non-invasive therapeutic
technique widely used for treating various diseases. However, the success and
safety of HIFU treatments depend on real-time monitoring, which is often
hindered by interference when using ultrasound to guide HIFU treatment. To
address these challenges, we developed HIFU-ILDiff, a novel deep learning-based
approach leveraging latent diffusion models to suppress HIFU-induced
interference in ultrasound images. The HIFU-ILDiff model employs a Vector
Quantized Variational Autoencoder (VQ-VAE) to encode noisy ultrasound images
into a lower-dimensional latent space, followed by a latent diffusion model
that iteratively removes interference. The denoised latent vectors are then
decoded to reconstruct high-resolution, interference-free ultrasound images. We
constructed a comprehensive dataset comprising 18,872 image pairs from in vitro
phantoms, ex vivo tissues, and in vivo animal data across multiple imaging
modalities and HIFU power levels to train and evaluate the model. Experimental
results demonstrate that HIFU-ILDiff significantly outperforms the commonly
used Notch Filter method, achieving a Structural Similarity Index (SSIM) of
0.796 and Peak Signal-to-Noise Ratio (PSNR) of 23.780 compared to SSIM of 0.443
and PSNR of 14.420 for the Notch Filter under in vitro scenarios. Additionally,
HIFU-ILDiff achieves real-time processing at 15 frames per second, markedly
faster than the Notch Filter's 5 seconds per frame. These findings indicate
that HIFU-ILDiff is able to denoise HIFU interference in ultrasound guiding
images for real-time monitoring during HIFU therapy, which will greatly improve
the treatment precision in current clinical applications.

</details>


### [148] [Kwai Keye-VL 1.5 Technical Report](https://arxiv.org/abs/2509.01563)
*Biao Yang,Bin Wen,Boyang Ding,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Guowang Zhang,Han Shen,Hao Peng,Haojie Ding,Hao Wang,Hengrui Ju,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Muhao Wei,Qiang Wang,Ruitao Wang,Sen Na,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zeyi Lu,Zhenhua Wu,Zhixin Ling,Zhuoran Yang,Ziming Li,Di Xu,Haixuan Gao,Hang Li,Jing Wang,Lejian Ren,Qigen Hu,Qianqian Wang,Shiyao Wang,Xinchen Luo,Yan Li,Yuhang Hu,Zixing Zhang*

Main category: cs.CV

TL;DR: Keye-VL-1.5通过创新的慢快视频编码、渐进式预训练和专注于推理增强及人类偏好对齐的后训练流程，显著提高了视频理解能力。


<details>
  <summary>Details</summary>
Motivation: 视频理解因视频内容动态且信息密集而具有挑战性，现有模型在空间分辨率和时间覆盖率之间难以平衡。Keye-VL-1.5旨在解决视频理解的基本挑战。

Method: 1. 慢快视频编码策略：根据帧间相似性动态分配计算资源，关键帧高分辨率处理（慢通道），静态帧低分辨率处理（快通道）。2. 渐进式四阶段预训练：将模型上下文长度从8K扩展到128K，以处理更长、更复杂的视频内容。3. 后训练流程：包括5步思维链数据构建、基于GSPO的迭代强化学习和对齐训练，以增强推理能力并与人类偏好对齐。

Result: Keye-VL-1.5在公共基准测试和人类评估中表现出比现有模型显著的改进，尤其在视频理解任务上表现突出，同时在通用多模态基准测试上保持竞争力。

Conclusion: Keye-VL-1.5通过其独特的设计，在视频理解领域取得了重大进展，有效解决了现有模型的局限性。

Abstract: In recent years, the development of Large Language Models (LLMs) has
significantly advanced, extending their capabilities to multimodal tasks
through Multimodal Large Language Models (MLLMs). However, video understanding
remains a challenging area due to the dynamic and information-dense nature of
videos. Existing models struggle with the trade-off between spatial resolution
and temporal coverage when processing video content. We present Keye-VL-1.5,
which addresses fundamental challenges in video comprehension through three key
innovations. First, we introduce a novel Slow-Fast video encoding strategy that
dynamically allocates computational resources based on inter-frame similarity,
processing key frames with significant visual changes at higher resolution
(Slow pathway) while handling relatively static frames with increased temporal
coverage at lower resolution (Fast pathway). Second, we implement a progressive
four-stage pre-training methodology that systematically extends the model's
context length from 8K to 128K tokens, enabling processing of longer videos and
more complex visual content. Third, we develop a comprehensive post-training
pipeline focusing on reasoning enhancement and human preference alignment,
incorporating a 5-step chain-of-thought data construction process, iterative
GSPO-based reinforcement learning with progressive prompt hinting for difficult
cases, and alignment training. Through extensive evaluation on public
benchmarks and rigorous internal human assessment, Keye-VL-1.5 demonstrates
significant improvements over existing models, particularly excelling in video
understanding tasks while maintaining competitive performance on general
multimodal benchmarks.

</details>


### [149] [ViSTA-SLAM: Visual SLAM with Symmetric Two-view Association](https://arxiv.org/abs/2509.01584)
*Ganlin Zhang,Shenhan Qian,Xi Wang,Daniel Cremers*

Main category: cs.CV

TL;DR: ViSTA-SLAM是一个实时单目视觉SLAM系统，无需相机内参，兼容性强。它使用轻量级对称两视图关联（STA）模型作为前端，可从两张RGB图像估计相对相机姿态和回归局部点图，模型复杂度低，前端大小仅为现有方法的35%。后端采用Sim(3)姿态图并结合回环检测以处理累积漂移。实验表明，ViSTA-SLAM在相机跟踪和三维重建质量方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提出一个无需相机内参的实时单目视觉SLAM系统，以提高其广泛适用性。

Method: 前端采用轻量级对称两视图关联（STA）模型，从两张RGB图像估计相对相机姿态和回归局部点图。后端构建Sim(3)姿态图并结合回环检测。

Result: 与现有方法相比，在相机跟踪和密集三维重建质量方面取得了优越的性能。

Conclusion: ViSTA-SLAM是一个高效且准确的视觉SLAM系统，无需相机内参，适用于多种相机设置。

Abstract: We present ViSTA-SLAM as a real-time monocular visual SLAM system that
operates without requiring camera intrinsics, making it broadly applicable
across diverse camera setups. At its core, the system employs a lightweight
symmetric two-view association (STA) model as the frontend, which
simultaneously estimates relative camera poses and regresses local pointmaps
from only two RGB images. This design reduces model complexity significantly,
the size of our frontend is only 35\% that of comparable state-of-the-art
methods, while enhancing the quality of two-view constraints used in the
pipeline. In the backend, we construct a specially designed Sim(3) pose graph
that incorporates loop closures to address accumulated drift. Extensive
experiments demonstrate that our approach achieves superior performance in both
camera tracking and dense 3D reconstruction quality compared to current
methods. Github repository: https://github.com/zhangganlin/vista-slam

</details>


### [150] [O-DisCo-Edit: Object Distortion Control for Unified Realistic Video Editing](https://arxiv.org/abs/2509.01596)
*Yuqing Chen,Junjie Wang,Lin Liu,Ruihang Chu,Xiaopeng Zhang,Qi Tian,Yujiu Yang*

Main category: cs.CV

TL;DR: O-DisCo-Edit是一个统一的视频编辑框架，使用新颖的物体失真控制（O-DisCo）信号，该信号基于随机和自适应噪声，能够灵活地将广泛的编辑线索封装到单个表示中。该框架还包括一个用于保留非编辑区域的“复制-形式”保持模块，能够进行高效、高保真的编辑。


<details>
  <summary>Details</summary>
Motivation: 当前的视频编辑方法需要针对不同的编辑任务使用不同的控制信号，这增加了模型设计的复杂性并消耗了大量的训练资源。为了解决这个问题，我们提出了O-DisCo-Edit。

Method: O-DisCo-Edit框架包含新颖的物体失真控制（O-DisCo）信号，该信号基于随机和自适应噪声，能够灵活地将广泛的编辑线索封装到单个表示中。此外，还采用了一个“复制-形式”保持模块来保留非编辑区域，并通过有效的训练范式实现了高效、高保真的编辑。

Result: O-DisCo-Edit在各种视频编辑任务上都优于专门的以及多任务的最新方法，这在大量的实验和全面的用户评估中得到了持续的证明。

Conclusion: O-DisCo-Edit通过其统一的框架和新颖的O-DisCo信号，实现了高效、高保真的视频编辑，并且在各种视频编辑任务上均优于现有方法。

Abstract: Diffusion models have recently advanced video editing, yet controllable
editing remains challenging due to the need for precise manipulation of diverse
object properties. Current methods require different control signal for diverse
editing tasks, which complicates model design and demands significant training
resources. To address this, we propose O-DisCo-Edit, a unified framework that
incorporates a novel object distortion control (O-DisCo). This signal, based on
random and adaptive noise, flexibly encapsulates a wide range of editing cues
within a single representation. Paired with a "copy-form" preservation module
for preserving non-edited regions, O-DisCo-Edit enables efficient,
high-fidelity editing through an effective training paradigm. Extensive
experiments and comprehensive human evaluations consistently demonstrate that
O-DisCo-Edit surpasses both specialized and multitask state-of-the-art methods
across various video editing tasks.
https://cyqii.github.io/O-DisCo-Edit.github.io/

</details>


### [151] [Improving Large Vision and Language Models by Learning from a Panel of Peers](https://arxiv.org/abs/2509.01610)
*Jefferson Hernandez,Jing Shi,Simon Jenni,Vicente Ordonez,Kushal Kafle*

Main category: cs.CV

TL;DR: 通过模仿人类的协作学习，我们提出了一种新颖的同行学习框架，该框架利用了大型视觉语言模型（LVLM）的集合，通过迭代的自我改进过程来评估和学习集体输出，而无需大量人工标注数据。


<details>
  <summary>Details</summary>
Motivation: 传统的LVLM对齐方法依赖昂贵的人工偏好数据、质量有限的机器生成数据或会产生幻觉的自监督偏好数据。本研究旨在克服这些局限性。

Method: 提出了一种新颖的同行学习框架，该框架利用了LVLM的集合，通过迭代的自我改进过程来评估和学习集体输出，模拟同行评审系统。

Result: 该方法在多个基准测试中显著提高了模型性能，平均分数从48%提高到57%，证明了同行评估作为一种可扩展的替代自监督对齐方法的潜力。

Conclusion: 同行学习框架是一种有前景的LVLM对齐方法，它利用模型集合的集体智慧，通过迭代的自我改进过程来提高性能，而无需大量人工标注数据。

Abstract: Traditional alignment methods for Large Vision and Language Models (LVLMs)
primarily rely on human-curated preference data. Human-generated preference
data is costly; machine-generated preference data is limited in quality; and
self-supervised preference data often introduces hallucinations. To overcome
these limitations, we propose a novel Panel-of-Peers learning framework
inspired by collaborative learning among humans. This approach leverages a
panel of LVLMs, each evaluating and learning from their collective outputs
through an iterative self-improvement process. By simulating a peer review
system, our models generate, assess, and refine outputs in response to a
curated set of prompts, mimicking a classroom learning environment. We
demonstrate that this methodology enhances model performance without requiring
extensive human-labeled datasets. Our experiments show significant improvement
across multiple benchmarks, demonstrating the potential of peer evaluations as
a scalable alternative to self-supervised alignment. Notably, we show that
Panel-of-Peers increases the average score on fifteen benchmarks from 48% to
57%

</details>


### [152] [Q-Sched: Pushing the Boundaries of Few-Step Diffusion Models with Quantization-Aware Scheduling](https://arxiv.org/abs/2509.01624)
*Natalia Frumkin,Diana Marculescu*

Main category: cs.CV

TL;DR: Q-Sched通过修改扩散模型调度器而非模型权重，在不牺牲精度的情况下将模型大小减少了4倍，并在用户研究中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型（如Stable Diffusion XL）计算成本高昂，且少数几步扩散模型仍需大型、未压缩的骨干网络，这限制了它们在没有数据中心GPU的情况下的全精度推理。现有的后训练量化方法依赖于全精度校准，这使得它们难以应用于这些模型。

Method: 提出了一种名为Q-Sched的新型后训练量化方法，通过调整扩散模型调度器而不是模型权重来修改采样轨迹。为了学习量化感知预条件系数，提出了一种名为JAQ的损失函数，结合了文本-图像兼容性和图像质量度量。

Result: Q-Sched实现了与全精度相当的准确性，同时将模型大小减少了4倍。与FP16的4步潜在一致性模型相比，Q-Sched的FID提高了15.5%；与FP16的8步相位一致性模型相比，Q-Sched的FID提高了16.6%。在一项包含80,000多条注释的大规模用户研究中，Q-Sched在FLUX.1[schnell]和SDXL-Turbo上的有效性得到了证实。

Conclusion: Q-Sched是一种有效的后训练量化方法，通过修改扩散模型调度器可以实现高保真生成，并且量化与少数几步蒸馏是互补的。

Abstract: Text-to-image diffusion models are computationally intensive, often requiring
dozens of forward passes through large transformer backbones. For instance,
Stable Diffusion XL generates high-quality images with 50 evaluations of a
2.6B-parameter model, an expensive process even for a single batch. Few-step
diffusion models reduce this cost to 2-8 denoising steps but still depend on
large, uncompressed U-Net or diffusion transformer backbones, which are often
too costly for full-precision inference without datacenter GPUs. These
requirements also limit existing post-training quantization methods that rely
on full-precision calibration. We introduce Q-Sched, a new paradigm for
post-training quantization that modifies the diffusion model scheduler rather
than model weights. By adjusting the few-step sampling trajectory, Q-Sched
achieves full-precision accuracy with a 4x reduction in model size. To learn
quantization-aware pre-conditioning coefficients, we propose the JAQ loss,
which combines text-image compatibility with an image quality metric for
fine-grained optimization. JAQ is reference-free and requires only a handful of
calibration prompts, avoiding full-precision inference during calibration.
Q-Sched delivers substantial gains: a 15.5% FID improvement over the FP16
4-step Latent Consistency Model and a 16.6% improvement over the FP16 8-step
Phased Consistency Model, showing that quantization and few-step distillation
are complementary for high-fidelity generation. A large-scale user study with
more than 80,000 annotations further confirms Q-Sched's effectiveness on both
FLUX.1[schnell] and SDXL-Turbo.

</details>


### [153] [OpenVision 2: A Family of Generative Pretrained Visual Encoders for Multimodal Learning](https://arxiv.org/abs/2509.01644)
*Yanqing Liu,Xianhang Li,Letian Zhang,Zirui Wang,Zeyu Zheng,Yuyin Zhou,Cihang Xie*

Main category: cs.CV

TL;DR: OpenVision 2通过移除文本编码器和对比损失，仅保留了生成式训练信号，在保持原有模型性能的同时，显著提高了训练效率（训练时间缩短1.5倍，内存占用减少1.8倍），并能支持更大规模的视觉编码器，为未来多模态基础模型的发展提供了一种轻量化范式。


<details>
  <summary>Details</summary>
Motivation: 为了提高OpenVision的训练效率，对原有的架构和损失函数设计进行了简化。

Method: 移除了文本编码器和对比损失，仅保留了纯粹的生成式训练信号（captioning loss）。

Result: OpenVision 2在多个多模态基准测试上与原模型性能相当，但训练时间缩短了约1.5倍（从83小时到57小时），内存占用减少了约1.8倍（从24.5GB到13.8GB），最大批次大小从2k增加到8k。该模型还支持了参数量超过10亿的更大规模视觉编码器。

Conclusion: 轻量化、仅生成式的范式对于未来多模态基础模型中的视觉编码器开发具有吸引力。

Abstract: This paper provides a simplification on OpenVision's architecture and loss
design for enhancing its training efficiency. Following the prior
vision-language pretraining works CapPa and AIMv2, as well as modern multimodal
designs like LLaVA, our changes are straightforward: we remove the text encoder
(and therefore the contrastive loss), retaining only the captioning loss as a
purely generative training signal. We name this new version OpenVision 2. The
initial results are promising: despite this simplification, OpenVision 2
competitively matches the original model's performance on a broad set of
multimodal benchmarks while substantially cutting both training time and memory
consumption. For example, with ViT-L/14, it reduces training time by about 1.5x
(from 83h to 57h), and memory usage by about 1.8x (from 24.5GB to 13.8GB,
equivalently allowing the maximum batch size to grow from 2k to 8k). This
superior training efficiency also allows us to scale far beyond the largest
vision encoder used in OpenVision, reaching more than 1 billion parameters. We
hold a strong belief that this lightweight, generative-only paradigm is
compelling for future vision encoder development in multimodal foundation
models.

</details>


### [154] [Reinforced Visual Perception with Tools](https://arxiv.org/abs/2509.01656)
*Zetong Zhou,Dongping Chen,Zixian Ma,Zhihan Hu,Mingyang Fu,Sinan Wang,Yao Wan,Zhou Zhao,Ranjay Krishna*

Main category: cs.CV

TL;DR: ReVPT是一种基于强化学习的方法，通过改进的GRPO算法，增强多模态大模型处理视觉工具的能力，在多个视觉推理基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在增强大模型视觉推理能力方面存在数据生成成本高、数据筛选依赖性强和泛化能力差等局限性。本研究旨在提出一种新的方法来解决这些问题。

Method: 提出了一种名为ReVPT的新方法，该方法基于GRPO的强化学习算法，用于训练模型使用一套四种视觉工具。

Result: ReVPT在SAT、CV-Bench、BLINK和MMStar等多个以感知为中心的基准测试中取得了最先进的性能，显著优于监督学习和基于文本的强化学习微调方法。具体来说，ReVPT-3B和ReVPT-7B在CV-Bench上的表现比指令模型分别高出9.03%和9.44%。

Conclusion: ReVPT通过强化学习显著提升了多模态大模型在视觉工具使用方面的能力，并在多项视觉推理任务中取得了领先成果，为社区提供了关于基于强化学习的视觉工具使用的新见解。

Abstract: Visual reasoning, a cornerstone of human intelligence, encompasses complex
perceptual and logical processes essential for solving diverse visual problems.
While advances in computer vision have produced powerful models for various
perceptual tasks, leveraging these for general visual reasoning remains
challenging. Prior work demonstrates that augmenting LLMs with vision models
via supervised finetuning improves performance, but faces key limitations such
as expensive data generation, reliance on careful data filtering, and poor
generalization. To address these issues, we propose ReVPT to enhance
multi-modal LLMs' abilities to reason about and use visual tools through
reinforcement learning. We introduce a novel RL algorithm based on GRPO,
designed to train models to reason with a suite of four visual tools. Through
extensive experiments, we show that our method achieves state-of-the-art
performance on several perception-heavy benchmarks, including SAT, CV-Bench,
BLINK and MMStar, significantly outperforming the supervised and text-based RL
finetuning baselines. Notably, Our ReVPT-3B and ReVPT-7B outperform the
instruct models by 9.03% and 9.44% on CV-Bench. Finally, we bring to the
community new insights on RL-based visual tool-usage through extensive
ablations. Our code is available at https://github.com/ls-kelvin/REVPT.

</details>


### [155] [GaussianGAN: Real-Time Photorealistic controllable Human Avatars](https://arxiv.org/abs/2509.01681)
*Mohamed Ilyes Lakhal,Richard Bowden*

Main category: cs.CV

TL;DR: GaussianGAN是一种新的可动画头像方法，通过高斯渲染实现实时照片级真实感渲染，解决了现有方案中的模糊问题。


<details>
  <summary>Details</summary>
Motivation: 当前神经渲染技术在生成可控人体虚拟形象方面虽然取得了进展，但存在明显的模糊性。本研究旨在解决这一限制，实现照片级真实感和可控性。对实时渲染人们的动画头像方法进行了开发。

Method: 本文提出了一种新颖的高斯泼溅致密化策略，从估计的骨骼四肢周围的圆柱结构表面构建高斯点。通过相机校准，利用新颖的视图分割模块渲染准确的语义分割。最后，UNet生成器利用渲染的高斯泼溅特征和分割图来创建照片级真实的数字头像。

Result: 本方法实现了实时运行，渲染速度为79 FPS。在ZJU Mocap数据集上达到了32.94db的像素保真度，在Thuman4数据集上达到了33.39db的像素保真度，优于以往方法，达到了最先进的水平。

Conclusion: GaussianGAN通过结合高斯泼溅和UNet生成器，成功实现了照片级真实感和实时渲染的动画人体虚拟形象，并在多个数据集上取得了优于现有方法的性能。

Abstract: Photorealistic and controllable human avatars have gained popularity in the
research community thanks to rapid advances in neural rendering, providing fast
and realistic synthesis tools. However, a limitation of current solutions is
the presence of noticeable blurring. To solve this problem, we propose
GaussianGAN, an animatable avatar approach developed for photorealistic
rendering of people in real-time. We introduce a novel Gaussian splatting
densification strategy to build Gaussian points from the surface of cylindrical
structures around estimated skeletal limbs. Given the camera calibration, we
render an accurate semantic segmentation with our novel view segmentation
module. Finally, a UNet generator uses the rendered Gaussian splatting features
and the segmentation maps to create photorealistic digital avatars. Our method
runs in real-time with a rendering speed of 79 FPS. It outperforms previous
methods regarding visual perception and quality, achieving a state-of-the-art
results in terms of a pixel fidelity of 32.94db on the ZJU Mocap dataset and
33.39db on the Thuman4 dataset.

</details>


### [156] [Examination of PCA Utilisation for Multilabel Classifier of Multispectral Images](https://arxiv.org/abs/2509.01691)
*Filip Karpowicz,Wiktor Kępiński,Bartosz Staszyński,Grzegorz Sarwas*

Main category: cs.CV

TL;DR: PCA对多标签多光谱图像分类的效用取决于深度学习架构和训练策略。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究主成分分析（PCA）在多标签多光谱图像分类中的效用，考虑到此类数据的高维度和相关的处理挑战，以及多标签分类的额外复杂性。

Method: 本研究的流程包括一个可选的PCA步骤，将数据降至三维，然后输入一个三层分类器。

Result: 研究结果表明，PCA在多标签多光谱图像分类中的有效性在很大程度上取决于所选择的深度学习架构和训练策略。

Conclusion: PCA在多标签多光谱图像分类中的有效性在很大程度上取决于所选择的深度学习架构和训练策略，为未来在自监督预训练和替代降维方法方面的研究开辟了道路。

Abstract: This paper investigates the utility of Principal Component Analysis (PCA) for
multi-label classification of multispectral images using ResNet50 and DINOv2,
acknowledging the high dimensionality of such data and the associated
processing challenges. Multi-label classification, where each image may belong
to multiple classes, adds further complexity to feature extraction. Our
pipeline includes an optional PCA step that reduces the data to three
dimensions before feeding it into a three-layer classifier. The findings
demonstrate that the effectiveness of PCA for multi-label multispectral image
classification depends strongly on the chosen deep learning architecture and
training strategy, opening avenues for future research into self-supervised
pre-training and alternative dimensionality reduction approaches.

</details>


### [157] [Deep Learning-Based Rock Particulate Classification Using Attention-Enhanced ConvNeXt](https://arxiv.org/abs/2509.01704)
*Anthony Amankwah,Chris Aldrich*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CNSCA的增强型深度学习模型，结合了ConvNeXt、自注意力和通道注意力机制，用于岩石尺寸分类，并在岩石尺寸分类数据集上取得了优于基线的性能。


<details>
  <summary>Details</summary>
Motivation: 岩石尺寸分类在岩石工程、采矿和资源管理等领域至关重要，精确的估计会影响操作效率和安全。因此，需要提高岩石尺寸分类的准确性。

Method: 提出了一种基于ConvNeXt架构的增强型深度学习模型，并加入了自注意力和通道注意力机制。该模型被称为CNSCA。自注意力机制用于捕捉长距离空间依赖性，而通道注意力机制用于强调信息特征通道。这种混合设计使模型能够有效地捕捉岩石图像中的细粒局部模式和更广泛的上下文关系。

Result: 在岩石尺寸分类数据集上评估了CNSCA模型，并与三个强基线进行了比较。结果表明，注意力机制的引入显著增强了模型在处理岩石等自然纹理的细粒度分类任务方面的能力。

Conclusion: 注意力机制的引入显著增强了模型在处理岩石等自然纹理的细粒度分类任务方面的能力，表明该方法在提高岩石尺寸分类准确性和鲁棒性方面是有效的。

Abstract: Accurate classification of rock sizes is a vital component in geotechnical
engineering, mining, and resource management, where precise estimation
influences operational efficiency and safety. In this paper, we propose an
enhanced deep learning model based on the ConvNeXt architecture, augmented with
both self-attention and channel attention mechanisms. Building upon the
foundation of ConvNext, our proposed model, termed CNSCA, introduces
self-attention to capture long-range spatial dependencies and channel attention
to emphasize informative feature channels. This hybrid design enables the model
to effectively capture both fine-grained local patterns and broader contextual
relationships within rock imagery, leading to improved classification accuracy
and robustness. We evaluate our model on a rock size classification dataset and
compare it against three strong baseline. The results demonstrate that the
incorporation of attention mechanisms significantly enhances the models
capability for fine-grained classification tasks involving natural textures
like rocks.

</details>


### [158] [Clinical Metadata Guided Limited-Angle CT Image Reconstruction](https://arxiv.org/abs/2509.01752)
*Yu Shi,Shuyi Fan,Changsheng Fang,Shuo Han,Haodong Li,Li Zhou,Bahareh Morovati,Dayang Wang,Hengyong Yu*

Main category: cs.CV

TL;DR: 提出一种基于元数据的双阶段扩散模型，用于解决心血管成像中角度受限CT（LACT）的伪影问题，取得了更好的重建效果。


<details>
  <summary>Details</summary>
Motivation: 心血管成像中角度受限CT（LACT）虽然可以提高时间分辨率并降低辐射剂量，但由于投影截断会导致严重的伪影，重建问题本质上是病态的。

Method: 提出一个两阶段的扩散框架，并结合结构化的临床元数据进行引导。第一阶段：仅以元数据（包括采集参数、患者人口统计信息和诊断印象）为条件的Transformer扩散模型，从噪声生成粗糙的解剖学先验。第二阶段：通过整合粗糙先验和元数据来进一步优化图像，以生成高保真度的结果。在两个阶段的每个采样步骤中，都使用交替方向乘子法（ADMM）模块强制执行基于物理的数据一致性，以确保与测量投影的一致性。

Result: 在合成和实际心血管CT数据集上的大量实验表明，结合元数据可以显著提高重建保真度，尤其是在严重的角度截断下。与现有的无元数据基线相比，该方法在SSIM、PSNR、nMI和PCC方面表现更优。消融研究证实，不同类型的元数据（特别是诊断和人口统计信息）在有限角度条件下具有互补的优势。

Conclusion: 临床元数据在提高重建质量和效率方面发挥着双重作用，支持将其整合到未来的元数据引导医学成像框架中。

Abstract: Limited-angle computed tomography (LACT) offers improved temporal resolution
and reduced radiation dose for cardiac imaging, but suffers from severe
artifacts due to truncated projections. To address the ill-posedness of LACT
reconstruction, we propose a two-stage diffusion framework guided by structured
clinical metadata. In the first stage, a transformer-based diffusion model
conditioned exclusively on metadata, including acquisition parameters, patient
demographics, and diagnostic impressions, generates coarse anatomical priors
from noise. The second stage further refines the images by integrating both the
coarse prior and metadata to produce high-fidelity results. Physics-based data
consistency is enforced at each sampling step in both stages using an
Alternating Direction Method of Multipliers module, ensuring alignment with the
measured projections. Extensive experiments on both synthetic and real cardiac
CT datasets demonstrate that incorporating metadata significantly improves
reconstruction fidelity, particularly under severe angular truncation. Compared
to existing metadata-free baselines, our method achieves superior performance
in SSIM, PSNR, nMI, and PCC. Ablation studies confirm that different types of
metadata contribute complementary benefits, particularly diagnostic and
demographic priors under limited-angle conditions. These findings highlight the
dual role of clinical metadata in improving both reconstruction quality and
efficiency, supporting their integration into future metadata-guided medical
imaging frameworks.

</details>


### [159] [TransMatch: A Transfer-Learning Framework for Defect Detection in Laser Powder Bed Fusion Additive Manufacturing](https://arxiv.org/abs/2509.01754)
*Mohsen Asghari Ilani,Yaser Mike Banad*

Main category: cs.CV

TL;DR: 本文提出了一种名为TransMatch的新框架，结合迁移学习和半监督少样本学习，用于解决增材制造（AM）领域中激光粉末床熔融（LPBF）工艺产生的表面缺陷检测问题，特别是在标注数据稀缺的情况下。该框架能够有效利用有标签和无标签的新类别图像，克服了传统元学习方法的局限性。实验结果表明，TransMatch在包含8,284张图像的表面缺陷数据集上表现出色，实现了98.91%的准确率，并对裂纹、针孔、孔洞和飞溅等多种缺陷类别具有高精确率、召回率和F1分数，证明了其在工业应用中的可靠性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: LPBF工艺产生的表面缺陷可能严重影响增材制造部件的结构完整性，而现有方法在处理标注数据稀缺的问题上存在局限。

Method: 提出了一种名为TransMatch的新框架，该框架融合了迁移学习和半监督少样本学习技术，旨在利用有限的标注数据和大量的无标签数据来识别LPBF部件的表面缺陷。

Result: TransMatch框架在包含8,284张图像的Surface Defects数据集上进行了评估，实现了98.91%的准确率，同时在多个缺陷类别（如裂纹、针孔、孔洞和飞溅）上获得了高精确率、召回率和F1分数。

Conclusion: TransMatch框架在增材制造缺陷检测方面取得了显著进展，能够准确识别多种表面缺陷，为质量保证和可靠性提供了实用且可扩展的解决方案。

Abstract: Surface defects in Laser Powder Bed Fusion (LPBF) pose significant risks to
the structural integrity of additively manufactured components. This paper
introduces TransMatch, a novel framework that merges transfer learning and
semi-supervised few-shot learning to address the scarcity of labeled AM defect
data. By effectively leveraging both labeled and unlabeled novel-class images,
TransMatch circumvents the limitations of previous meta-learning approaches.
Experimental evaluations on a Surface Defects dataset of 8,284 images
demonstrate the efficacy of TransMatch, achieving 98.91% accuracy with minimal
loss, alongside high precision, recall, and F1-scores for multiple defect
classes. These findings underscore its robustness in accurately identifying
diverse defects, such as cracks, pinholes, holes, and spatter. TransMatch thus
represents a significant leap forward in additive manufacturing defect
detection, offering a practical and scalable solution for quality assurance and
reliability across a wide range of industrial applications.

</details>


### [160] [Mixture of Balanced Information Bottlenecks for Long-Tailed Visual Recognition](https://arxiv.org/abs/2509.01804)
*Yifan Lan,Xin Cai,Jun Cheng,Shan Tan*

Main category: cs.CV

TL;DR: 该论文提出了一种名为平衡信息瓶颈（BIB）的新方法，通过结合损失函数重平衡和自蒸馏技术，来解决深度神经网络在处理长尾数据时的挑战。此外，还提出了一种混合多平衡信息瓶颈（MBIB）结构，以增强表示学习能力。实验证明，BIB和MBIB在长尾视觉识别任务上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉识别任务通常面临数据长尾问题，这给深度神经网络（DNNs）的训练和部署带来了挑战。

Method: 提出了一种平衡信息瓶颈（BIB）方法，将损失函数重平衡和自蒸馏技术融入原始信息瓶颈（IB）网络。进一步提出了一种混合多平衡信息瓶颈（MBIB）结构，将多个BIB结合起来，使不同的BIB能够结合不同网络层的知识，并从信息论的角度促进表示和分类的同步端到端学习。

Result: 在CIFAR100-LT、ImageNet-LT和iNaturalist 2018等长尾数据集上进行了实验，证明BIB和MBIB均达到了长尾视觉识别的最优性能。

Conclusion: 所提出的BIB和MBIB方法有效地解决了长尾数据分布下的视觉识别问题，并在相关数据集上取得了优异的成果。

Abstract: Deep neural networks (DNNs) have achieved significant success in various
applications with large-scale and balanced data. However, data in real-world
visual recognition are usually long-tailed, bringing challenges to efficient
training and deployment of DNNs. Information bottleneck (IB) is an elegant
approach for representation learning. In this paper, we propose a balanced
information bottleneck (BIB) approach, in which loss function re-balancing and
self-distillation techniques are integrated into the original IB network. BIB
is thus capable of learning a sufficient representation with essential
label-related information fully preserved for long-tailed visual recognition.
To further enhance the representation learning capability, we also propose a
novel structure of mixture of multiple balanced information bottlenecks (MBIB),
where different BIBs are responsible for combining knowledge from different
network layers. MBIB facilitates an end-to-end learning strategy that trains
representation and classification simultaneously from an information theory
perspective. We conduct experiments on commonly used long-tailed datasets,
including CIFAR100-LT, ImageNet-LT, and iNaturalist 2018. Both BIB and MBIB
reach state-of-the-art performance for long-tailed visual recognition.

</details>


### [161] [PractiLight: Practical Light Control Using Foundational Diffusion Models](https://arxiv.org/abs/2509.01837)
*Yotam Erel,Rishabh Dabral,Vladislav Golyanik,Amit H. Bermano,Christian Theobalt*

Main category: cs.CV

TL;DR: PractiLight是一种利用生成模型对图像进行光照控制的方法，通过训练轻量级LoRA回归器生成直接辐照度图，并使用分类器引导将光照应用于新图像，实现了高效、通用的光照控制。


<details>
  <summary>Details</summary>
Motivation: 解决生成图像中光照控制的难题，克服现有方法在泛化性和适用性上的限制。

Method: 利用生成模型的自注意力层来表示光照关系，训练轻量级LoRA回归器生成直接辐照度图，并通过分类器引导将光照应用于新图像。

Result: 在多种场景类型上实现了最先进的性能，质量和可控性高，并且在参数和数据效率方面优于现有方法。

Conclusion: 图像光照可以通过利用基础知识进行可行控制，从而实现实用且通用的重新照明。

Abstract: Light control in generated images is a difficult task, posing specific
challenges, spanning over the entire image and frequency spectrum. Most
approaches tackle this problem by training on extensive yet domain-specific
datasets, limiting the inherent generalization and applicability of the
foundational backbones used. Instead, PractiLight is a practical approach,
effectively leveraging foundational understanding of recent generative models
for the task. Our key insight is that lighting relationships in an image are
similar in nature to token interaction in self-attention layers, and hence are
best represented there. Based on this and other analyses regarding the
importance of early diffusion iterations, PractiLight trains a lightweight LoRA
regressor to produce the direct irradiance map for a given image, using a small
set of training images. We then employ this regressor to incorporate the
desired lighting into the generation process of another image using Classifier
Guidance. This careful design generalizes well to diverse conditions and image
domains. We demonstrate state-of-the-art performance in terms of quality and
control with proven parameter and data efficiency compared to leading works
over a wide variety of scenes types. We hope this work affirms that image
lighting can feasibly be controlled by tapping into foundational knowledge,
enabling practical and general relighting.

</details>


### [162] [Latent Gene Diffusion for Spatial Transcriptomics Completion](https://arxiv.org/abs/2509.01864)
*Paula Cárdenas,Leonardo Manrique,Daniela Vega,Daniela Ruiz,Pablo Arbeláez*

Main category: cs.CV

TL;DR: LGDiST是一种新的无参考隐基因扩散模型，用于解决空间转录组学（ST）数据的缺失问题，通过利用先前被认为信息量不大的背景基因来构建丰富的基因潜在空间，并在基因表达补全和下游任务中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的空间转录组学（ST）数据基因表达预测模型，由于数据缺失（dropout），存在严重局限性，并且依赖于单细胞RNA测序参考，容易受到对齐质量、批次效应和数据缺失的影响。

Method: 提出了一种名为LGDiST的无参考隐基因扩散模型，利用背景基因构建潜在空间，并引入邻域条件，以解决ST数据缺失问题。

Result: LGDiST在26个数据集上的平均均方误差（MSE）比现有方法低18%，并且能将下游任务的MSE提高高达10%。消融实验表明，LGDiST的完整架构（包括背景基因、ST潜在空间和邻域条件）的性能显著优于其各个单独组件。

Conclusion: LGDiST是第一个用于ST数据缺失的无参考隐基因扩散模型，通过创新的方法实现了优于现有技术的性能，并证明了其完整架构的有效性。

Abstract: Computer Vision has proven to be a powerful tool for analyzing Spatial
Transcriptomics (ST) data. However, current models that predict spatially
resolved gene expression from histopathology images suffer from significant
limitations due to data dropout. Most existing approaches rely on single-cell
RNA sequencing references, making them dependent on alignment quality and
external datasets while also risking batch effects and inherited dropout. In
this paper, we address these limitations by introducing LGDiST, the first
reference-free latent gene diffusion model for ST data dropout. We show that
LGDiST outperforms the previous state-of-the-art in gene expression completion,
with an average Mean Squared Error that is 18% lower across 26 datasets.
Furthermore, we demonstrate that completing ST data with LGDiST improves gene
expression prediction performance on six state-of-the-art methods up to 10% in
MSE. A key innovation of LGDiST is using context genes previously considered
uninformative to build a rich and biologically meaningful genetic latent space.
Our experiments show that removing key components of LGDiST, such as the
context genes, the ST latent space, and the neighbor conditioning, leads to
considerable drops in performance. These findings underscore that the full
architecture of LGDiST achieves substantially better performance than any of
its isolated components.

</details>


### [163] [Doctoral Thesis: Geometric Deep Learning For Camera Pose Prediction, Registration, Depth Estimation, and 3D Reconstruction](https://arxiv.org/abs/2509.01873)
*Xueyang Kang*

Main category: cs.CV

TL;DR: 深度学习在3D视觉领域面临数据稀疏性和高维性挑战，传统SfM/SLAM在非结构化环境中表现不佳且几何细节不足。本研究提出几何深度学习方法，融合几何先验（如深度、法线、等变性）来解决3D视觉任务，如相机姿态估计、点云配准、深度预测和3D重建，以提升模型准确性和鲁棒性，并应用于文化遗产保护和VR/AR环境。


<details>
  <summary>Details</summary>
Motivation: 深度学习在3D映射、场景重建和虚拟现实方面展现了巨大潜力，但直接处理3D数据面临高维性和数据稀疏性挑战。传统SfM/SLAM方法在非结构化环境中表现不佳，且生成的几何细节不足以支持渲染和语义分析等下游任务。因此，需要结合传统几何技术和深度学习的3D表示方法来构建鲁棒的几何感知深度学习模型。

Method: 本研究通过开发针对相机姿态估计、点云配准、深度预测和3D重建等关键3D视觉任务的几何深度学习方法，并整合深度信息、表面法线和等变性等几何先验或约束到深度学习模型中，以增强几何表示的准确性和鲁棒性。

Result: 该研究系统地研究了相机姿态估计、点云配准、深度估计和高保真3D重建等3D视觉的关键组成部分，并在数字文化遗产保护和沉浸式VR/AR环境等真实世界应用中验证了其有效性。

Conclusion: 通过将几何先验和约束融入深度学习模型，本研究成功解决了3D视觉领域面临的关键挑战，提高了3D表示的准确性和鲁棒性，并在实际应用中证明了其价值。

Abstract: Modern deep learning developments create new opportunities for 3D mapping
technology, scene reconstruction pipelines, and virtual reality development.
Despite advances in 3D deep learning technology, direct training of deep
learning models on 3D data faces challenges due to the high dimensionality
inherent in 3D data and the scarcity of labeled datasets. Structure-from-motion
(SfM) and Simultaneous Localization and Mapping (SLAM) exhibit robust
performance when applied to structured indoor environments but often struggle
with ambiguous features in unstructured environments. These techniques often
struggle to generate detailed geometric representations effective for
downstream tasks such as rendering and semantic analysis. Current limitations
require the development of 3D representation methods that combine traditional
geometric techniques with deep learning capabilities to generate robust
geometry-aware deep learning models.
  The dissertation provides solutions to the fundamental challenges in 3D
vision by developing geometric deep learning methods tailored for essential
tasks such as camera pose estimation, point cloud registration, depth
prediction, and 3D reconstruction. The integration of geometric priors or
constraints, such as including depth information, surface normals, and
equivariance into deep learning models, enhances both the accuracy and
robustness of geometric representations. This study systematically investigates
key components of 3D vision, including camera pose estimation, point cloud
registration, depth estimation, and high-fidelity 3D reconstruction,
demonstrating their effectiveness across real-world applications such as
digital cultural heritage preservation and immersive VR/AR environments.

</details>


### [164] [HydroVision: Predicting Optically Active Parameters in Surface Water Using Computer Vision](https://arxiv.org/abs/2509.01882)
*Shubham Laxmikant Deshmukh,Matthew Wilchek,Feras A. Batarseh*

Main category: cs.CV

TL;DR: 本文提出了一个名为HydroVision的深度学习框架，利用RGB图像对地表水体的叶绿素a、总叶绿素、溶解性有机物（CDOM）、藻蓝蛋白、悬浮物和浊度等光学活性水质参数进行估算，旨在支持环境监测和灾害响应。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉和深度学习技术的发展，为环境监测开辟了新的非接触式水质评估方法，尤其是在灾害响应和公共卫生保护方面。本研究旨在利用这些技术，通过分析地表水体的RGB图像来监测水质。

Method: 本研究提出HydroVision框架，利用迁移学习评估了五种先进的卷积神经网络（VGG-16, ResNet50, MobileNetV2, DenseNet121）和一种视觉Transformer在水质参数预测上的表现。模型在2022年至2024年间从美国地质调查局收集的超过50万张季节性变化的图像上进行训练。

Result: 研究结果表明，DenseNet121在预测CDOM时达到了最高的验证性能，R2得分为0.89，证明了该框架在各种条件下进行实际水质监测的潜力。

Conclusion: HydroVision框架利用现有的RGB图像数据，为水质监测提供了一种可扩展且成本效益高的方法，能够有效估算多种光学活性水质参数。虽然目前模型在光照良好的图像上表现最佳，但未来的工作将致力于提高其在弱光和遮挡条件下的鲁棒性，以扩大其应用范围。

Abstract: Ongoing advancements in computer vision, particularly in pattern recognition
and scene classification, have enabled new applications in environmental
monitoring. Deep learning now offers non-contact methods for assessing water
quality and detecting contamination, both critical for disaster response and
public health protection. This work introduces HydroVision, a deep
learning-based scene classification framework that estimates optically active
water quality parameters including Chlorophyll-Alpha, Chlorophylls, Colored
Dissolved Organic Matter (CDOM), Phycocyanins, Suspended Sediments, and
Turbidity from standard Red-Green-Blue (RGB) images of surface water.
HydroVision supports early detection of contamination trends and strengthens
monitoring by regulatory agencies during external environmental stressors,
industrial activities, and force majeure events. The model is trained on more
than 500,000 seasonally varied images collected from the United States
Geological Survey Hydrologic Imagery Visualization and Information System
between 2022 and 2024. This approach leverages widely available RGB imagery as
a scalable, cost-effective alternative to traditional multispectral and
hyperspectral remote sensing. Four state-of-the-art convolutional neural
networks (VGG-16, ResNet50, MobileNetV2, DenseNet121) and a Vision Transformer
are evaluated through transfer learning to identify the best-performing
architecture. DenseNet121 achieves the highest validation performance, with an
R2 score of 0.89 in predicting CDOM, demonstrating the framework's promise for
real-world water quality monitoring across diverse conditions. While the
current model is optimized for well-lit imagery, future work will focus on
improving robustness under low-light and obstructed scenarios to expand its
operational utility.

</details>


### [165] [Automated Wildfire Damage Assessment from Multi view Ground level Imagery Via Vision Language Models](https://arxiv.org/abs/2509.01895)
*Miguel Esparza,Archit Gupta,Ali Mostafavi,Kai Yin,Yiming Xiao*

Main category: cs.CV

TL;DR: 该研究提出了一种利用预训练视觉语言模型（VLMs）对野火造成的财产损失进行零样本分类的新框架，通过多视角分析显著提高了评估准确性，并提供了一个可立即部署的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了应对日益频繁和强烈的野火，需要快速准确的财产损失评估方法。传统方法耗时，而现有的计算机视觉方法需要大量标注数据，阻碍了灾后部署。

Method: 提出并评估了一个零样本框架，利用预训练的视觉语言模型（VLM）和大型语言模型（LLM），结合结构化提示，从地面图像对野火造成的财产损失进行分类。研究了单视角和多视角评估，并应用McNemar检验进行统计分析。

Result: 与单视角评估（F1分数0.225-0.511）相比，多视角分析显著提高了分类准确性（F1分数0.857-0.947）。VLM+LLM（Pipeline B）与单独的VLM（Pipeline A）之间的改进不具有统计学意义。

Conclusion: 多视角分析是提高野火财产损失评估准确性的关键，零样本框架可以实现即时部署。未来的研究可以探索LLM在提高评估性能方面的潜力。

Abstract: The escalating intensity and frequency of wildfires demand innovative
computational methods for rapid and accurate property damage assessment.
Traditional methods are often time consuming, while modern computer vision
approaches typically require extensive labeled datasets, hindering immediate
post-disaster deployment. This research introduces a novel, zero-shot framework
leveraging pre-trained vision language models (VLMs) to classify damage from
ground-level imagery. We propose and evaluate two pipelines applied to the 2025
Eaton and Palisades fires in California, a VLM (Pipeline A) and a VLM + large
language model (LLM) approach (Pipeline B), that integrate structured prompts
based on specific wildfire damage indicators. A primary scientific contribution
of this study is demonstrating the VLMs efficacy in synthesizing information
from multiple perspectives to identify nuanced damage, a critical limitation in
existing literature. Our findings reveal that while single view assessments
struggled to classify affected structures (F1 scores ranging from 0.225 to
0.511), the multi-view analysis yielded dramatic improvements (F1 scores
ranging from 0.857 to 0.947). Moreover, the McNemar test confirmed that
pipelines with a multi-view image assessment yields statistically significant
classification improvements; however, the improvements this research observed
between Pipeline A and B were not statistically significant. Thus, future
research can explore the potential of LLM prompting in damage assessment. The
practical contribution is an immediately deployable, flexible, and
interpretable workflow that bypasses the need for supervised training,
significantly accelerating triage and prioritization for disaster response
practitioners.

</details>


### [166] [DroneSR: Rethinking Few-shot Thermal Image Super-Resolution from Drone-based Perspective](https://arxiv.org/abs/2509.01898)
*Zhipeng Weng,Xiaopeng Liu,Ce Liu,Xingyuan Guo,Yukai Shi,Liang Lin*

Main category: cs.CV

TL;DR: 该研究提出了一种新的高斯量化表示学习方法，以解决扩散模型在无人机红外图像超分辨率任务中因过拟合而导致的泛化能力下降问题。该方法通过高斯量化有效减少了过拟合，并结合了监控机制来检测过拟合迹象，同时构建了一个多源无人机红外图像数据集用于验证。实验结果表明，该方法在复杂条件下显著减轻了过拟合，并优于现有的超分辨率方法。


<details>
  <summary>Details</summary>
Motivation: 大型模型在性能上取得了显著进步，但过拟合问题严重影响了其泛化能力。在超分辨率任务中，以扩散模型为代表的生成模型通常采用大规模架构，然而，少量无人机捕获的红外训练数据会导致大规模架构出现严重的过拟合。

Method: 提出了一种新的面向扩散模型的高斯量化表示学习方法，以减轻过拟合和增强鲁棒性。同时，引入了一个有效的监控机制来跟踪大规模架构在训练过程中的过拟合迹象。

Result: 实验结果表明，所提出的方法在复杂条件下显著减轻了大规模架构的过拟合，并且优于现有的超分辨率方法。所构建的多源无人机红外图像数据集被用来强调大规模架构在少样本、无人机基础的多种图像重建场景中的过拟合问题。

Conclusion: 所提出的高斯量化表示学习方法能有效减少过拟合，同时保持模型复杂度，并通过实验验证了其在无人机红外图像超分辨率任务中缓解过拟合和提升性能的有效性。

Abstract: Although large scale models achieve significant improvements in performance,
the overfitting challenge still frequently undermines their generalization
ability. In super resolution tasks on images, diffusion models as
representatives of generative models typically adopt large scale architectures.
However, few-shot drone-captured infrared training data frequently induces
severe overfitting in large-scale architectures. To address this key challenge,
our method proposes a new Gaussian quantization representation learning method
oriented to diffusion models that alleviates overfitting and enhances
robustness. At the same time, an effective monitoring mechanism tracks large
scale architectures during training to detect signs of overfitting. By
introducing Gaussian quantization representation learning, our method
effectively reduces overfitting while maintaining architecture complexity. On
this basis, we construct a multi source drone-based infrared image benchmark
dataset for detection and use it to emphasize overfitting issues of large scale
architectures in few sample, drone-based diverse drone-based image
reconstruction scenarios. To verify the efficacy of the method in mitigating
overfitting, experiments are conducted on the constructed benchmark.
Experimental results demonstrate that our method outperforms existing super
resolution approaches and significantly mitigates overfitting of large scale
architectures under complex conditions. The code and DroneSR dataset will be
available at: https://github.com/wengzp1/GARLSR.

</details>


### [167] [RSCC: A Large-Scale Remote Sensing Change Caption Dataset for Disaster Events](https://arxiv.org/abs/2509.01907)
*Zhenyuan Chen,Chenxi Wang,Ningyu Zhang,Feng Zhang*

Main category: cs.CV

TL;DR: RSCC是一个包含62,315个灾难前后图像对和详细文字描述的大型遥感数据集，旨在解决现有数据集缺乏时间图像对和详细文本注释的问题，以支持遥感领域的视觉-语言模型训练和评估。


<details>
  <summary>Details</summary>
Motivation: 现有遥感数据集缺乏时间图像对和详细的文本注释，无法捕捉灾难随时间变化的动态影响。

Method: 构建了一个名为RSCC（Remote Sensing Change Caption）的大型基准数据集，包含62,315个灾难前后的图像对（涵盖地震、洪水、野火等）以及丰富、类似人类的变更描述。

Result: RSCC能够促进详细的灾难相关分析，为更准确、可解释和可扩展的遥感视觉-语言应用铺平道路。

Conclusion: RSCC数据集弥补了遥感数据在时间维度和语义方面的不足，能够有效支持灾害感知的双时相理解的视觉-语言模型的训练和评估。

Abstract: Remote sensing is critical for disaster monitoring, yet existing datasets
lack temporal image pairs and detailed textual annotations. While
single-snapshot imagery dominates current resources, it fails to capture
dynamic disaster impacts over time. To address this gap, we introduce the
Remote Sensing Change Caption (RSCC) dataset, a large-scale benchmark
comprising 62,315 pre-/post-disaster image pairs (spanning earthquakes, floods,
wildfires, and more) paired with rich, human-like change captions. By bridging
the temporal and semantic divide in remote sensing data, RSCC enables robust
training and evaluation of vision-language models for disaster-aware
bi-temporal understanding. Our results highlight RSCC's ability to facilitate
detailed disaster-related analysis, paving the way for more accurate,
interpretable, and scalable vision-language applications in remote sensing.
Code and dataset are available at https://github.com/Bili-Sakura/RSCC.

</details>


### [168] [Towards Interpretable Geo-localization: a Concept-Aware Global Image-GPS Alignment Framework](https://arxiv.org/abs/2509.01910)
*Furong Jia,Lanxin Liu,Ce Hou,Fan Zhang,Xinyan Liu,Yu Liu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Worldwide geo-localization involves determining the exact geographic location
of images captured globally, typically guided by geographic cues such as
climate, landmarks, and architectural styles. Despite advancements in
geo-localization models like GeoCLIP, which leverages images and location
alignment via contrastive learning for accurate predictions, the
interpretability of these models remains insufficiently explored. Current
concept-based interpretability methods fail to align effectively with
Geo-alignment image-location embedding objectives, resulting in suboptimal
interpretability and performance. To address this gap, we propose a novel
framework integrating global geo-localization with concept bottlenecks. Our
method inserts a Concept-Aware Alignment Module that jointly projects image and
location embeddings onto a shared bank of geographic concepts (e.g., tropical
climate, mountain, cathedral) and minimizes a concept-level loss, enhancing
alignment in a concept-specific subspace and enabling robust interpretability.
To our knowledge, this is the first work to introduce interpretability into
geo-localization. Extensive experiments demonstrate that our approach surpasses
GeoCLIP in geo-localization accuracy and boosts performance across diverse
geospatial prediction tasks, revealing richer semantic insights into geographic
decision-making processes.

</details>


### [169] [A Diffusion-Based Framework for Configurable and Realistic Multi-Storage Trace Generation](https://arxiv.org/abs/2509.01919)
*Seohyun Kim,Junyoung Lee,Jongho Park,Jinhyung Koo,Sungjin Lee,Yeseong Kim*

Main category: cs.CV

TL;DR: DiTTO是一个基于扩散模型的框架，用于生成逼真、可配置且多样化的多设备存储轨迹，能够以8%的误差生成高保真度并符合用户配置的轨迹。


<details>
  <summary>Details</summary>
Motivation: 生成逼真、可精确配置且多样化的多设备存储轨迹。

Method: 利用先进的扩散技术，实现高保真度的连续轨迹合成，捕捉时间动态和设备间依赖关系，并允许用户定义配置。

Result: DiTTO能够生成高保真度和多样化的轨迹，并且与引导配置高度一致，误差仅为8%。

Conclusion: DiTTO是一个有效的框架，能够生成高质量的多设备存储轨迹，满足用户的配置需求。

Abstract: We propose DiTTO, a novel diffusion-based framework for generating realistic,
precisely configurable, and diverse multi-device storage traces. Leveraging
advanced diffusion tech- niques, DiTTO enables the synthesis of high-fidelity
continuous traces that capture temporal dynamics and inter-device dependencies
with user-defined configurations. Our experimental results demonstrate that
DiTTO can generate traces with high fidelity and diversity while aligning
closely with guided configurations with only 8% errors.

</details>


### [170] [Structure-aware Contrastive Learning for Diagram Understanding of Multimodal Models](https://arxiv.org/abs/2509.01959)
*Hiroshi Sasaki*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal models, such as the Contrastive Language-Image Pre-training (CLIP)
model, have demonstrated remarkable success in aligning visual and linguistic
representations. However, these models exhibit limitations when applied to
specialised visual domains, such as diagrams, which encode structured, symbolic
information distinct from that of natural imagery.
  In this paper, we introduce a novel training paradigm explicitly designed to
enhance the comprehension of diagrammatic images within vision-language models.
Our approach uses ``hard'' samples for our proposed contrastive learning that
incorporates two specialised loss functions that leverage the inherent
structural properties of diagrams. By integrating these objectives into model
training, our method enables models to develop a more structured and
semantically coherent understanding of diagrammatic content.
  We empirically validate our approach on a benchmark dataset of flowcharts, as
a representative class of diagrammatic imagery, demonstrating substantial
improvements over standard CLIP and conventional hard negative CLIP learning
paradigms for both image-text matching and visual question answering tasks. Our
findings underscore the significance of tailored training strategies for
specialised tasks and contribute to advancing diagrammatic understanding within
the broader landscape of vision-language integration.

</details>


### [171] [2D Gaussian Splatting with Semantic Alignment for Image Inpainting](https://arxiv.org/abs/2509.01964)
*Hongyu Li,Chaofeng Chen,Xiaoming Li,Guangming Lu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Gaussian Splatting (GS), a recent technique for converting discrete points
into continuous spatial representations, has shown promising results in 3D
scene modeling and 2D image super-resolution. In this paper, we explore its
untapped potential for image inpainting, which demands both locally coherent
pixel synthesis and globally consistent semantic restoration. We propose the
first image inpainting framework based on 2D Gaussian Splatting, which encodes
incomplete images into a continuous field of 2D Gaussian splat coefficients and
reconstructs the final image via a differentiable rasterization process. The
continuous rendering paradigm of GS inherently promotes pixel-level coherence
in the inpainted results. To improve efficiency and scalability, we introduce a
patch-wise rasterization strategy that reduces memory overhead and accelerates
inference. For global semantic consistency, we incorporate features from a
pretrained DINO model. We observe that DINO's global features are naturally
robust to small missing regions and can be effectively adapted to guide
semantic alignment in large-mask scenarios, ensuring that the inpainted content
remains contextually consistent with the surrounding scene. Extensive
experiments on standard benchmarks demonstrate that our method achieves
competitive performance in both quantitative metrics and perceptual quality,
establishing a new direction for applying Gaussian Splatting to 2D image
processing.

</details>


### [172] [Understanding Space Is Rocket Science - Only Top Reasoning Models Can Solve Spatial Understanding Tasks](https://arxiv.org/abs/2509.02175)
*Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose RocketScience, an open-source contrastive VLM benchmark that tests
for spatial relation understanding. It is comprised of entirely new real-world
image-text pairs covering mostly relative spatial understanding and the order
of objects. The benchmark is designed
  to be very easy for humans and hard for the current generation of VLMs, and
this is empirically verified. Our results show a striking lack of spatial
relation understanding in open source and frontier commercial VLMs and a
surprisingly high performance of reasoning models. Additionally, we perform a
disentanglement analysis to separate the contributions of object localization
and spatial reasoning in chain-of-thought-based models and find that the
performance on the benchmark is bottlenecked by spatial reasoning and not
object localization capabilities.
  We release the dataset with a CC-BY-4.0 license and make the evaluation code
available at: https://github.com/nilshoehing/rocketscience

</details>


### [173] [MOSAIC: Multi-Subject Personalized Generation via Correspondence-Aware Alignment and Disentanglement](https://arxiv.org/abs/2509.01977)
*Dong She,Siming Fu,Mushui Liu,Qiaoqiao Jin,Hualiang Wang,Mu Liu,Jidong Jiang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-subject personalized generation presents unique challenges in
maintaining identity fidelity and semantic coherence when synthesizing images
conditioned on multiple reference subjects. Existing methods often suffer from
identity blending and attribute leakage due to inadequate modeling of how
different subjects should interact within shared representation spaces. We
present MOSAIC, a representation-centric framework that rethinks multi-subject
generation through explicit semantic correspondence and orthogonal feature
disentanglement. Our key insight is that multi-subject generation requires
precise semantic alignment at the representation level - knowing exactly which
regions in the generated image should attend to which parts of each reference.
To enable this, we introduce SemAlign-MS, a meticulously annotated dataset
providing fine-grained semantic correspondences between multiple reference
subjects and target images, previously unavailable in this domain. Building on
this foundation, we propose the semantic correspondence attention loss to
enforce precise point-to-point semantic alignment, ensuring high consistency
from each reference to its designated regions. Furthermore, we develop the
multi-reference disentanglement loss to push different subjects into orthogonal
attention subspaces, preventing feature interference while preserving
individual identity characteristics. Extensive experiments demonstrate that
MOSAIC achieves state-of-the-art performance on multiple benchmarks. Notably,
while existing methods typically degrade beyond 3 subjects, MOSAIC maintains
high fidelity with 4+ reference subjects, opening new possibilities for complex
multi-subject synthesis applications.

</details>


### [174] [Discrete Noise Inversion for Next-scale Autoregressive Text-based Image Editing](https://arxiv.org/abs/2509.01984)
*Quan Dao,Xiaoxiao He,Ligong Han,Ngan Hoai Nguyen,Amin Heyrani Nobar,Faez Ahmed,Han Zhang,Viet Anh Nguyen,Dimitris Metaxas*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Visual autoregressive models (VAR) have recently emerged as a promising class
of generative models, achieving performance comparable to diffusion models in
text-to-image generation tasks. While conditional generation has been widely
explored, the ability to perform prompt-guided image editing without additional
training is equally critical, as it supports numerous practical real-world
applications. This paper investigates the text-to-image editing capabilities of
VAR by introducing Visual AutoRegressive Inverse Noise (VARIN), the first noise
inversion-based editing technique designed explicitly for VAR models. VARIN
leverages a novel pseudo-inverse function for argmax sampling, named
Location-aware Argmax Inversion (LAI), to generate inverse Gumbel noises. These
inverse noises enable precise reconstruction of the source image and facilitate
targeted, controllable edits aligned with textual prompts. Extensive
experiments demonstrate that VARIN effectively modifies source images according
to specified prompts while significantly preserving the original background and
structural details, thus validating its efficacy as a practical editing
approach.

</details>


### [175] [Draw-In-Mind: Learning Precise Image Editing via Chain-of-Thought Imagination](https://arxiv.org/abs/2509.01986)
*Ziyun Zeng,Junhao Zhang,Wei Li,Mike Zheng Shou*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In recent years, integrating multimodal understanding and generation into a
single unified model has emerged as a promising paradigm. While this approach
achieves strong results in text-to-image (T2I) generation, it still struggles
with precise image editing. We attribute this limitation to an imbalanced
division of responsibilities. The understanding module primarily functions as a
translator that encodes user instructions into semantic conditions, while the
generation module must simultaneously act as designer and painter, inferring
the original layout, identifying the target editing region, and rendering the
new content. This imbalance is counterintuitive because the understanding
module is typically trained with several times more data on complex reasoning
tasks than the generation module. To address this issue, we introduce
Draw-In-Mind (DIM), a dataset comprising two complementary subsets: (i)
DIM-T2I, containing 14M long-context image-text pairs to enhance complex
instruction comprehension; and (ii) DIM-Edit, consisting of 233K
chain-of-thought imaginations generated by GPT-4o, serving as explicit design
blueprints for image edits. We connect a frozen Qwen2.5-VL-3B with a trainable
SANA1.5-1.6B via a lightweight two-layer MLP, and train it on the proposed DIM
dataset, resulting in DIM-4.6B-T2I/Edit. Despite its modest parameter scale,
DIM-4.6B-Edit achieves SOTA or competitive performance on the ImgEdit and
GEdit-Bench benchmarks, outperforming much larger models such as UniWorld-V1
and Step1X-Edit. These findings demonstrate that explicitly assigning the
design responsibility to the understanding module provides significant benefits
for image editing. Our dataset and models will be available at
https://github.com/showlab/DIM.

</details>


### [176] [Explaining What Machines See: XAI Strategies in Deep Object Detection Models](https://arxiv.org/abs/2509.01991)
*FatemehSadat Seyedmomeni,Mohammad Ali Keyvanrad*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In recent years, deep learning has achieved unprecedented success in various
computer vision tasks, particularly in object detection. However, the black-box
nature and high complexity of deep neural networks pose significant challenges
for interpretability, especially in critical domains such as autonomous
driving, medical imaging, and security systems. Explainable Artificial
Intelligence (XAI) aims to address this challenge by providing tools and
methods to make model decisions more transparent, interpretable, and
trust-worthy for humans. This review provides a comprehensive analysis of
state-of-the-art explain-ability methods specifically applied to object
detection models. The paper be-gins by categorizing existing XAI techniques
based on their underlying mechanisms-perturbation-based, gradient-based,
backpropagation-based, and graph-based methods. Notable methods such as D-RISE,
BODEM, D-CLOSE, and FSOD are discussed in detail. Furthermore, the paper
investigates their applicability to various object detection architectures,
including YOLO, SSD, Faster R-CNN, and EfficientDet. Statistical analysis of
publication trends from 2022 to mid-2025 shows an accelerating interest in
explainable object detection, indicating its increasing importance. The study
also explores common datasets and evaluation metrics, and highlights the major
challenges associated with model interpretability. By providing a structured
taxonomy and a critical assessment of existing methods, this review aims to
guide researchers and practitioners in selecting suitable explainability
techniques for object detection applications and to foster the development of
more interpretable AI systems.

</details>


### [177] [Palette Aligned Image Diffusion](https://arxiv.org/abs/2509.02000)
*Elad Aharoni,Noy Porat,Dani Lischinski,Ariel Shamir*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce the Palette-Adapter, a novel method for conditioning
text-to-image diffusion models on a user-specified color palette. While
palettes are a compact and intuitive tool widely used in creative workflows,
they introduce significant ambiguity and instability when used for conditioning
image generation. Our approach addresses this challenge by interpreting
palettes as sparse histograms and introducing two scalar control parameters:
histogram entropy and palette-to-histogram distance, which allow flexible
control over the degree of palette adherence and color variation. We further
introduce a negative histogram mechanism that allows users to suppress specific
undesired hues, improving adherence to the intended palette under the standard
classifier-free guidance mechanism. To ensure broad generalization across the
color space, we train on a carefully curated dataset with balanced coverage of
rare and common colors. Our method enables stable, semantically coherent
generation across a wide range of palettes and prompts. We evaluate our method
qualitatively, quantitatively, and through a user study, and show that it
consistently outperforms existing approaches in achieving both strong palette
adherence and high image quality.

</details>


### [178] [Vision-Based Embedded System for Noncontact Monitoring of Preterm Infant Behavior in Low-Resource Care Settings](https://arxiv.org/abs/2509.02018)
*Stanley Mugisha,Rashid Kisitu,Francis Komakech,Excellence Favor*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Preterm birth remains a leading cause of neonatal mortality,
disproportionately affecting low-resource settings with limited access to
advanced neonatal intensive care units (NICUs).Continuous monitoring of infant
behavior, such as sleep/awake states and crying episodes, is critical but
relies on manual observation or invasive sensors, which are prone to error,
impractical, and can cause skin damage. This paper presents a novel,
noninvasive, and automated vision-based framework to address this gap. We
introduce an embedded monitoring system that utilizes a quantized MobileNet
model deployed on a Raspberry Pi for real-time behavioral state detection. When
trained and evaluated on public neonatal image datasets, our system achieves
state-of-the-art accuracy (91.8% for sleep detection and 97.7% for
crying/normal classification) while maintaining computational efficiency
suitable for edge deployment. Through comparative benchmarking, we provide a
critical analysis of the trade-offs between model size, inference latency, and
diagnostic accuracy. Our findings demonstrate that while larger architectures
(e.g., ResNet152, VGG19) offer marginal gains in accuracy, their computational
cost is prohibitive for real-time edge use. The proposed framework integrates
three key innovations: model quantization for memory-efficient inference (68%
reduction in size), Raspberry Pi-optimized vision pipelines, and secure IoT
communication for clinical alerts. This work conclusively shows that
lightweight, optimized models such as the MobileNet offer the most viable
foundation for scalable, low-cost, and clinically actionable NICU monitoring
systems, paving the way for improved preterm care in resource-constrained
environments.

</details>


### [179] [Unsupervised Training of Vision Transformers with Synthetic Negatives](https://arxiv.org/abs/2509.02024)
*Nikolaos Giakoumoglou,Andreas Floros,Kleanthis Marios Papadopoulos,Tania Stathaki*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper does not introduce a novel method per se. Instead, we address the
neglected potential of hard negative samples in self-supervised learning.
Previous works explored synthetic hard negatives but rarely in the context of
vision transformers. We build on this observation and integrate synthetic hard
negatives to improve vision transformer representation learning. This simple
yet effective technique notably improves the discriminative power of learned
representations. Our experiments show performance improvements for both DeiT-S
and Swin-T architectures.

</details>


### [180] [See No Evil: Adversarial Attacks Against Linguistic-Visual Association in Referring Multi-Object Tracking Systems](https://arxiv.org/abs/2509.02028)
*Halima Bouzidi,Haoyu Liu,Mohammad Al Faruque*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Language-vision understanding has driven the development of advanced
perception systems, most notably the emerging paradigm of Referring
Multi-Object Tracking (RMOT). By leveraging natural-language queries, RMOT
systems can selectively track objects that satisfy a given semantic
description, guided through Transformer-based spatial-temporal reasoning
modules. End-to-End (E2E) RMOT models further unify feature extraction,
temporal memory, and spatial reasoning within a Transformer backbone, enabling
long-range spatial-temporal modeling over fused textual-visual representations.
Despite these advances, the reliability and robustness of RMOT remain
underexplored. In this paper, we examine the security implications of RMOT
systems from a design-logic perspective, identifying adversarial
vulnerabilities that compromise both the linguistic-visual referring and
track-object matching components. Additionally, we uncover a novel
vulnerability in advanced RMOT models employing FIFO-based memory, whereby
targeted and consistent attacks on their spatial-temporal reasoning introduce
errors that persist within the history buffer over multiple subsequent frames.
We present VEIL, a novel adversarial framework designed to disrupt the unified
referring-matching mechanisms of RMOT models. We show that carefully crafted
digital and physical perturbations can corrupt the tracking logic reliability,
inducing track ID switches and terminations. We conduct comprehensive
evaluations using the Refer-KITTI dataset to validate the effectiveness of VEIL
and demonstrate the urgent need for security-aware RMOT designs for critical
large-scale applications.

</details>


### [181] [Fake & Square: Training Self-Supervised Vision Transformers with Synthetic Data and Synthetic Hard Negatives](https://arxiv.org/abs/2509.02029)
*Nikolaos Giakoumoglou,Andreas Floros,Kleanthis Marios Papadopoulos,Tania Stathaki*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper does not introduce a new method per se. Instead, we build on
existing self-supervised learning approaches for vision, drawing inspiration
from the adage "fake it till you make it". While contrastive self-supervised
learning has achieved remarkable success, it typically relies on vast amounts
of real-world data and carefully curated hard negatives. To explore
alternatives to these requirements, we investigate two forms of "faking it" in
vision transformers. First, we study the potential of generative models for
unsupervised representation learning, leveraging synthetic data to augment
sample diversity. Second, we examine the feasibility of generating synthetic
hard negatives in the representation space, creating diverse and challenging
contrasts. Our framework - dubbed Syn2Co - combines both approaches and
evaluates whether synthetically enhanced training can lead to more robust and
transferable visual representations on DeiT-S and Swin-T architectures. Our
findings highlight the promise and limitations of synthetic data in
self-supervised learning, offering insights for future work in this direction.

</details>


### [182] [ContextFusion and Bootstrap: An Effective Approach to Improve Slot Attention-Based Object-Centric Learning](https://arxiv.org/abs/2509.02032)
*Pinzhuo Tian,Shengjie Yang,Hang Yu,Alex C. Kot*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A key human ability is to decompose a scene into distinct objects and use
their relationships to understand the environment. Object-centric learning aims
to mimic this process in an unsupervised manner. Recently, the slot
attention-based framework has emerged as a leading approach in this area and
has been widely used in various downstream tasks. However, existing slot
attention methods face two key limitations: (1) a lack of high-level semantic
information. In current methods, image areas are assigned to slots based on
low-level features such as color and texture. This makes the model overly
sensitive to low-level features and limits its understanding of object
contours, shapes, or other semantic characteristics. (2) The inability to
fine-tune the encoder. Current methods require a stable feature space
throughout training to enable reconstruction from slots, which restricts the
flexibility needed for effective object-centric learning. To address these
limitations, we propose a novel ContextFusion stage and a Bootstrap Branch,
both of which can be seamlessly integrated into existing slot attention models.
In the ContextFusion stage, we exploit semantic information from the foreground
and background, incorporating an auxiliary indicator that provides additional
contextual cues about them to enrich the semantic content beyond low-level
features. In the Bootstrap Branch, we decouple feature adaptation from the
original reconstruction phase and introduce a bootstrap strategy to train a
feature-adaptive mechanism, allowing for more flexible adaptation. Experimental
results show that our method significantly improves the performance of
different SOTA slot attention models on both simulated and real-world datasets.

</details>


### [183] [A Data-Centric Approach to Pedestrian Attribute Recognition: Synthetic Augmentation via Prompt-driven Diffusion Models](https://arxiv.org/abs/2509.02099)
*Alejandro Alonso,Sawaiz A. Chaudhry,Juan C. SanMiguel,Álvaro García-Martín,Pablo Ayuso-Albizu,Pablo Carballeira*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Pedestrian Attribute Recognition (PAR) is a challenging task as models are
required to generalize across numerous attributes in real-world data.
Traditional approaches focus on complex methods, yet recognition performance is
often constrained by training dataset limitations, particularly the
under-representation of certain attributes. In this paper, we propose a
data-centric approach to improve PAR by synthetic data augmentation guided by
textual descriptions. First, we define a protocol to identify weakly recognized
attributes across multiple datasets. Second, we propose a prompt-driven
pipeline that leverages diffusion models to generate synthetic pedestrian
images while preserving the consistency of PAR datasets. Finally, we derive a
strategy to seamlessly incorporate synthetic samples into training data, which
considers prompt-based annotation rules and modifies the loss function. Results
on popular PAR datasets demonstrate that our approach not only boosts
recognition of underrepresented attributes but also improves overall model
performance beyond the targeted attributes. Notably, this approach strengthens
zero-shot generalization without requiring architectural changes of the model,
presenting an efficient and scalable solution to improve the recognition of
attributes of pedestrians in the real world.

</details>


### [184] [SALAD -- Semantics-Aware Logical Anomaly Detection](https://arxiv.org/abs/2509.02101)
*Matic Fučka,Vitjan Zavrtanik,Danijel Skočaj*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent surface anomaly detection methods excel at identifying structural
anomalies, such as dents and scratches, but struggle with logical anomalies,
such as irregular or missing object components. The best-performing logical
anomaly detection approaches rely on aggregated pretrained features or
handcrafted descriptors (most often derived from composition maps), which
discard spatial and semantic information, leading to suboptimal performance. We
propose SALAD, a semantics-aware discriminative logical anomaly detection
method that incorporates a newly proposed composition branch to explicitly
model the distribution of object composition maps, consequently learning
important semantic relationships. Additionally, we introduce a novel procedure
for extracting composition maps that requires no hand-made labels or
category-specific information, in contrast to previous methods. By effectively
modelling the composition map distribution, SALAD significantly improves upon
state-of-the-art methods on the standard benchmark for logical anomaly
detection, MVTec LOCO, achieving an impressive image-level AUROC of 96.1%.
Code: https://github.com/MaticFuc/SALAD

</details>


### [185] [NOOUGAT: Towards Unified Online and Offline Multi-Object Tracking](https://arxiv.org/abs/2509.02111)
*Benjamin Missaoui,Orcun Cetintas,Guillem Brasó,Tim Meinhardt,Laura Leal-Taixé*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The long-standing division between \textit{online} and \textit{offline}
Multi-Object Tracking (MOT) has led to fragmented solutions that fail to
address the flexible temporal requirements of real-world deployment scenarios.
Current \textit{online} trackers rely on frame-by-frame hand-crafted
association strategies and struggle with long-term occlusions, whereas
\textit{offline} approaches can cover larger time gaps, but still rely on
heuristic stitching for arbitrarily long sequences. In this paper, we introduce
NOOUGAT, the first tracker designed to operate with arbitrary temporal
horizons. NOOUGAT leverages a unified Graph Neural Network (GNN) framework that
processes non-overlapping subclips, and fuses them through a novel
Autoregressive Long-term Tracking (ALT) layer. The subclip size controls the
trade-off between latency and temporal context, enabling a wide range of
deployment scenarios, from frame-by-frame to batch processing. NOOUGAT achieves
state-of-the-art performance across both tracking regimes, improving
\textit{online} AssA by +2.3 on DanceTrack, +9.2 on SportsMOT, and +5.0 on
MOT20, with even greater gains in \textit{offline} mode.

</details>


### [186] [SegFormer Fine-Tuning with Dropout: Advancing Hair Artifact Removal in Skin Lesion Analysis](https://arxiv.org/abs/2509.02156)
*Asif Mohammed Saad,Umme Niraj Mahi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Hair artifacts in dermoscopic images present significant challenges for
accurate skin lesion analysis, potentially obscuring critical diagnostic
features in dermatological assessments. This work introduces a fine-tuned
SegFormer model augmented with dropout regularization to achieve precise hair
mask segmentation. The proposed SegformerWithDropout architecture leverages the
MiT-B2 encoder, pretrained on ImageNet, with an in-channel count of 3 and 2
output classes, incorporating a dropout probability of 0.3 in the segmentation
head to prevent overfitting. Training is conducted on a specialized dataset of
500 dermoscopic skin lesion images with fine-grained hair mask annotations,
employing 10-fold cross-validation, AdamW optimization with a learning rate of
0.001, and cross-entropy loss. Early stopping is applied based on validation
loss, with a patience of 3 epochs and a maximum of 20 epochs per fold.
Performance is evaluated using a comprehensive suite of metrics, including
Intersection over Union (IoU), Dice coefficient, Peak Signal-to-Noise Ratio
(PSNR), Structural Similarity Index (SSIM), and Learned Perceptual Image Patch
Similarity (LPIPS). Experimental results from the cross-validation demonstrate
robust performance, with average Dice coefficients reaching approximately 0.96
and IoU values of 0.93, alongside favorable PSNR (around 34 dB), SSIM (0.97),
and low LPIPS (0.06), highlighting the model's effectiveness in accurate hair
artifact segmentation and its potential to enhance preprocessing for downstream
skin cancer detection tasks.

</details>


### [187] [Enhancing Zero-Shot Pedestrian Attribute Recognition with Synthetic Data Generation: A Comparative Study with Image-To-Image Diffusion Models](https://arxiv.org/abs/2509.02161)
*Pablo Ayuso-Albizu,Juan C. SanMiguel,Pablo Carballeira*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Pedestrian Attribute Recognition (PAR) involves identifying various human
attributes from images with applications in intelligent monitoring systems. The
scarcity of large-scale annotated datasets hinders the generalization of PAR
models, specially in complex scenarios involving occlusions, varying poses, and
diverse environments. Recent advances in diffusion models have shown promise
for generating diverse and realistic synthetic images, allowing to expand the
size and variability of training data. However, the potential of
diffusion-based data expansion for generating PAR-like images remains
underexplored. Such expansion may enhance the robustness and adaptability of
PAR models in real-world scenarios. This paper investigates the effectiveness
of diffusion models in generating synthetic pedestrian images tailored to PAR
tasks. We identify key parameters of img2img diffusion-based data expansion;
including text prompts, image properties, and the latest enhancements in
diffusion-based data augmentation, and examine their impact on the quality of
generated images for PAR. Furthermore, we employ the best-performing expansion
approach to generate synthetic images for training PAR models, by enriching the
zero-shot datasets. Experimental results show that prompt alignment and image
properties are critical factors in image generation, with optimal selection
leading to a 4.5% improvement in PAR recognition performance.

</details>


### [188] [Omnidirectional Spatial Modeling from Correlated Panoramas](https://arxiv.org/abs/2509.02164)
*Xinshen Zhang,Tongxi Fu,Xu Zheng*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Omnidirectional scene understanding is vital for various downstream
applications, such as embodied AI, autonomous driving, and immersive
environments, yet remains challenging due to geometric distortion and complex
spatial relations in 360{\deg} imagery. Existing omnidirectional methods
achieve scene understanding within a single frame while neglecting cross-frame
correlated panoramas. To bridge this gap, we introduce \textbf{CFpano}, the
\textbf{first} benchmark dataset dedicated to cross-frame correlated panoramas
visual question answering in the holistic 360{\deg} scenes. CFpano consists of
over 2700 images together with over 8000 question-answer pairs, and the
question types include both multiple choice and open-ended VQA. Building upon
our CFpano, we further present \methodname, a multi-modal large language model
(MLLM) fine-tuned with Group Relative Policy Optimization (GRPO) and a set of
tailored reward functions for robust and consistent reasoning with cross-frame
correlated panoramas. Benchmark experiments with existing MLLMs are conducted
with our CFpano. The experimental results demonstrate that \methodname achieves
state-of-the-art performance across both multiple-choice and open-ended VQA
tasks, outperforming strong baselines on all major reasoning categories
(\textbf{+5.37\%} in overall performance). Our analyses validate the
effectiveness of GRPO and establish a new benchmark for panoramic scene
understanding.

</details>


### [189] [ADVMEM: Adversarial Memory Initialization for Realistic Test-Time Adaptation via Tracklet-Based Benchmarking](https://arxiv.org/abs/2509.02182)
*Shyma Alhuwaider,Motasem Alfarra,Juan C. Perez,Merey Ramazanova,Bernard Ghanem*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce a novel tracklet-based dataset for benchmarking test-time
adaptation (TTA) methods. The aim of this dataset is to mimic the intricate
challenges encountered in real-world environments such as images captured by
hand-held cameras, self-driving cars, etc. The current benchmarks for TTA focus
on how models face distribution shifts, when deployed, and on violations to the
customary independent-and-identically-distributed (i.i.d.) assumption in
machine learning. Yet, these benchmarks fail to faithfully represent realistic
scenarios that naturally display temporal dependencies, such as how consecutive
frames from a video stream likely show the same object across time. We address
this shortcoming of current datasets by proposing a novel TTA benchmark we call
the "Inherent Temporal Dependencies" (ITD) dataset. We ensure the instances in
ITD naturally embody temporal dependencies by collecting them from
tracklets-sequences of object-centric images we compile from the bounding boxes
of an object-tracking dataset. We use ITD to conduct a thorough experimental
analysis of current TTA methods, and shed light on the limitations of these
methods when faced with the challenges of temporal dependencies. Moreover, we
build upon these insights and propose a novel adversarial memory initialization
strategy to improve memory-based TTA methods. We find this strategy
substantially boosts the performance of various methods on our challenging
benchmark.

</details>


### [190] [Palmistry-Informed Feature Extraction and Analysis using Machine Learning](https://arxiv.org/abs/2509.02248)
*Shweta Patil*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper explores the automated analysis of palmar features using machine
learning techniques. We present a computer vision pipeline that extracts key
characteristics from palm images, such as principal line structures, texture,
and shape metrics. These features are used to train predictive models on a
novel dataset curated from annotated palm images. Our approach moves beyond
traditional subjective interpretation by providing a data-driven, quantitative
framework for studying the correlations between palmar morphology and
externally validated traits or conditions. The methodology demonstrates
feasibility for applications in digital anthropometry and personalized user
analytics, with potential for deployment on mobile platforms. Results indicate
that machine learning models can identify complex patterns in palm data,
opening avenues for research that intersects cultural practices with
computational analysis.

</details>


### [191] [A Multimodal Cross-View Model for Predicting Postoperative Neck Pain in Cervical Spondylosis Patients](https://arxiv.org/abs/2509.02256)
*Jingyang Shan,Qishuai Yu,Jiacen Liu,Shaolin Zhang,Wen Shen,Yanxiao Zhao,Tianyi Wang,Xiaolin Qin,Yiheng Yin*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Neck pain is the primary symptom of cervical spondylosis, yet its underlying
mechanisms remain unclear, leading to uncertain treatment outcomes. To address
the challenges of multimodal feature fusion caused by imaging differences and
spatial mismatches, this paper proposes an Adaptive Bidirectional Pyramid
Difference Convolution (ABPDC) module that facilitates multimodal integration
by exploiting the advantages of difference convolution in texture extraction
and grayscale invariance, and a Feature Pyramid Registration Auxiliary Network
(FPRAN) to mitigate structural misalignment. Experiments on the MMCSD dataset
demonstrate that the proposed model achieves superior prediction accuracy of
postoperative neck pain recovery compared with existing methods, and ablation
studies further confirm its effectiveness.

</details>


### [192] [DSGC-Net: A Dual-Stream Graph Convolutional Network for Crowd Counting via Feature Correlation Mining](https://arxiv.org/abs/2509.02261)
*Yihong Wu,Jinqiao Wei,Xionghui Zhao,Yidi Li,Shaoyi Du,Bin Ren,Nicu Sebe*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep learning-based crowd counting methods have achieved remarkable progress
in recent years. However, in complex crowd scenarios, existing models still
face challenges when adapting to significant density distribution differences
between regions. Additionally, the inconsistency of individual representations
caused by viewpoint changes and body posture differences further limits the
counting accuracy of the models. To address these challenges, we propose
DSGC-Net, a Dual-Stream Graph Convolutional Network based on feature
correlation mining. DSGC-Net introduces a Density Approximation (DA) branch and
a Representation Approximation (RA) branch. By modeling two semantic graphs, it
captures the potential feature correlations in density variations and
representation distributions. The DA branch incorporates a density prediction
module that generates the density distribution map, and constructs a
density-driven semantic graph based on density similarity. The RA branch
establishes a representation-driven semantic graph by computing global
representation similarity. Then, graph convolutional networks are applied to
the two semantic graphs separately to model the latent semantic relationships,
which enhance the model's ability to adapt to density variations and improve
counting accuracy in multi-view and multi-pose scenarios. Extensive experiments
on three widely used datasets demonstrate that DSGC-Net outperforms current
state-of-the-art methods. In particular, we achieve MAE of 48.9 and 5.9 in
ShanghaiTech Part A and Part B datasets, respectively. The released code is
available at: https://github.com/Wu-eon/CrowdCounting-DSGCNet.

</details>


### [193] [RS-OOD: A Vision-Language Augmented Framework for Out-of-Distribution Detection in Remote Sensing](https://arxiv.org/abs/2509.02273)
*Yingrui Ji,Jiansheng Chen,Jingbo Chen,Anzhi Yue,Chenhao Wang,Kai Li,Yao Zhu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Out-of-distribution (OOD) detection represents a critical challenge in remote
sensing applications, where reliable identification of novel or anomalous
patterns is essential for autonomous monitoring, disaster response, and
environmental assessment. Despite remarkable progress in OOD detection for
natural images, existing methods and benchmarks remain poorly suited to remote
sensing imagery due to data scarcity, complex multi-scale scene structures, and
pronounced distribution shifts. To this end, we propose RS-OOD, a novel
framework that leverages remote sensing-specific vision-language modeling to
enable robust few-shot OOD detection. Our approach introduces three key
innovations: spatial feature enhancement that improved scene discrimination, a
dual-prompt alignment mechanism that cross-verifies scene context against
fine-grained semantics for spatial-semantic consistency, and a
confidence-guided self-training loop that dynamically mines pseudo-labels to
expand training data without manual annotation. RS-OOD consistently outperforms
existing methods across multiple remote sensing benchmarks and enables
efficient adaptation with minimal labeled data, demonstrating the critical
value of spatial-semantic integration.

</details>


### [194] [SynthGenNet: a self-supervised approach for test-time generalization using synthetic multi-source domain mixing of street view images](https://arxiv.org/abs/2509.02287)
*Pushpendra Dhakara,Prachi Chachodhia,Vaibhav Kumar*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Unstructured urban environments present unique challenges for scene
understanding and generalization due to their complex and diverse layouts. We
introduce SynthGenNet, a self-supervised student-teacher architecture designed
to enable robust test-time domain generalization using synthetic multi-source
imagery. Our contributions include the novel ClassMix++ algorithm, which blends
labeled data from various synthetic sources while maintaining semantic
integrity, enhancing model adaptability. We further employ Grounded Mask
Consistency Loss (GMC), which leverages source ground truth to improve
cross-domain prediction consistency and feature alignment. The Pseudo-Label
Guided Contrastive Learning (PLGCL) mechanism is integrated into the student
network to facilitate domain-invariant feature learning through iterative
knowledge distillation from the teacher network. This self-supervised strategy
improves prediction accuracy, addresses real-world variability, bridges the
sim-to-real domain gap, and reliance on labeled target data, even in complex
urban areas. Outcomes show our model outperforms the state-of-the-art (relying
on single source) by achieving 50% Mean Intersection-Over-Union (mIoU) value on
real-world datasets like Indian Driving Dataset (IDD).

</details>


### [195] [Data-Driven Loss Functions for Inference-Time Optimization in Text-to-Image Generation](https://arxiv.org/abs/2509.02295)
*Sapir Esther Yiflach,Yuval Atzmon,Gal Chechik*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-to-image diffusion models can generate stunning visuals, yet they often
fail at tasks children find trivial--like placing a dog to the right of a teddy
bear rather than to the left. When combinations get more unusual--a giraffe
above an airplane--these failures become even more pronounced. Existing methods
attempt to fix these spatial reasoning failures through model fine-tuning or
test-time optimization with handcrafted losses that are suboptimal. Rather than
imposing our assumptions about spatial encoding, we propose learning these
objectives directly from the model's internal representations. We introduce
Learn-to-Steer, a novel framework that learns data-driven objectives for
test-time optimization rather than handcrafting them. Our key insight is to
train a lightweight classifier that decodes spatial relationships from the
diffusion model's cross-attention maps, then deploy this classifier as a
learned loss function during inference. Training such classifiers poses a
surprising challenge: they can take shortcuts by detecting linguistic traces
rather than learning true spatial patterns. We solve this with a dual-inversion
strategy that enforces geometric understanding. Our method dramatically
improves spatial accuracy: from 0.20 to 0.61 on FLUX.1-dev and from 0.07 to
0.54 on SD2.1 across standard benchmarks. Moreover, our approach generalizes to
multiple relations and significantly improves accuracy.

</details>


### [196] [Hues and Cues: Human vs. CLIP](https://arxiv.org/abs/2509.02305)
*Nuria Alabau-Bosque,Jorge Vila-Tomás,Paula Daudén-Oliver,Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Valero Laparra,Jesús Malo*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Playing games is inherently human, and a lot of games are created to
challenge different human characteristics. However, these tasks are often left
out when evaluating the human-like nature of artificial models. The objective
of this work is proposing a new approach to evaluate artificial models via
board games. To this effect, we test the color perception and color naming
capabilities of CLIP by playing the board game Hues & Cues and assess its
alignment with humans. Our experiments show that CLIP is generally well aligned
with human observers, but our approach brings to light certain cultural biases
and inconsistencies when dealing with different abstraction levels that are
hard to identify with other testing strategies. Our findings indicate that
assessing models with different tasks like board games can make certain
deficiencies in the models stand out in ways that are difficult to test with
the commonly used benchmarks.

</details>


### [197] [OmniActor: A Generalist GUI and Embodied Agent for 2D&3D Worlds](https://arxiv.org/abs/2509.02322)
*Longrong Yang,Zhixiong Zeng,Yufeng Zhong,Jing Huang,Liming Zheng,Lei Chen,Haibo Qiu,Zequn Qin,Lin Ma,Xi Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal large language models are evolving toward multimodal agents
capable of proactively executing tasks. Most agent research focuses on GUI or
embodied scenarios, which correspond to agents interacting with 2D virtual
worlds or 3D real worlds, respectively. However, many complex tasks typically
require agents to interleavely interact with these two types of environment. We
initially mix GUI and embodied data to train, but find the performance
degeneration brought by the data conflict. Further analysis reveals that GUI
and embodied data exhibit synergy and conflict at the shallow and deep layers,
respectively, which resembles the cerebrum-cerebellum mechanism in the human
brain. To this end, we propose a high-performance generalist agent OmniActor,
designed from both structural and data perspectives. First, we propose
Layer-heterogeneity MoE to eliminate the conflict between GUI and embodied data
by separating deep-layer parameters, while leverage their synergy by sharing
shallow-layer parameters. By successfully leveraging the synergy and
eliminating the conflict, OmniActor outperforms agents only trained by GUI or
embodied data in GUI or embodied tasks. Furthermore, we unify the action spaces
of GUI and embodied tasks, and collect large-scale GUI and embodied data from
various sources for training. This significantly improves OmniActor under
different scenarios, especially in GUI tasks. The code will be publicly
available.

</details>


### [198] [Ordinal Adaptive Correction: A Data-Centric Approach to Ordinal Image Classification with Noisy Labels](https://arxiv.org/abs/2509.02351)
*Alireza Sedighi Moghaddam,Mohammad Reza Mohammadi*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Labeled data is a fundamental component in training supervised deep learning
models for computer vision tasks. However, the labeling process, especially for
ordinal image classification where class boundaries are often ambiguous, is
prone to error and noise. Such label noise can significantly degrade the
performance and reliability of machine learning models. This paper addresses
the problem of detecting and correcting label noise in ordinal image
classification tasks. To this end, a novel data-centric method called ORDinal
Adaptive Correction (ORDAC) is proposed for adaptive correction of noisy
labels. The proposed approach leverages the capabilities of Label Distribution
Learning (LDL) to model the inherent ambiguity and uncertainty present in
ordinal labels. During training, ORDAC dynamically adjusts the mean and
standard deviation of the label distribution for each sample. Rather than
discarding potentially noisy samples, this approach aims to correct them and
make optimal use of the entire training dataset. The effectiveness of the
proposed method is evaluated on benchmark datasets for age estimation (Adience)
and disease severity detection (Diabetic Retinopathy) under various asymmetric
Gaussian noise scenarios. Results show that ORDAC and its extended versions
(ORDAC_C and ORDAC_R) lead to significant improvements in model performance.
For instance, on the Adience dataset with 40% noise, ORDAC_R reduced the mean
absolute error from 0.86 to 0.62 and increased the recall metric from 0.37 to
0.49. The method also demonstrated its effectiveness in correcting intrinsic
noise present in the original datasets. This research indicates that adaptive
label correction using label distributions is an effective strategy to enhance
the robustness and accuracy of ordinal classification models in the presence of
noisy data.

</details>


### [199] [Category-Aware 3D Object Composition with Disentangled Texture and Shape Multi-view Diffusion](https://arxiv.org/abs/2509.02357)
*Zeren Xiong,Zikun Chen,Zedong Zhang,Xiang Li,Ying Tai,Jian Yang,Jun Li*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we tackle a new task of 3D object synthesis, where a 3D model
is composited with another object category to create a novel 3D model. However,
most existing text/image/3D-to-3D methods struggle to effectively integrate
multiple content sources, often resulting in inconsistent textures and
inaccurate shapes. To overcome these challenges, we propose a straightforward
yet powerful approach, category+3D-to-3D (C33D), for generating novel and
structurally coherent 3D models. Our method begins by rendering multi-view
images and normal maps from the input 3D model, then generating a novel 2D
object using adaptive text-image harmony (ATIH) with the front-view image and a
text description from another object category as inputs. To ensure texture
consistency, we introduce texture multi-view diffusion, which refines the
textures of the remaining multi-view RGB images based on the novel 2D object.
For enhanced shape accuracy, we propose shape multi-view diffusion to improve
the 2D shapes of both the multi-view RGB images and the normal maps, also
conditioned on the novel 2D object. Finally, these outputs are used to
reconstruct a complete and novel 3D model. Extensive experiments demonstrate
the effectiveness of our method, yielding impressive 3D creations, such as
shark(3D)-crocodile(text) in the first row of Fig. 1. A project page is
available at: https://xzr52.github.io/C33D/

</details>


### [200] [Why Do MLLMs Struggle with Spatial Understanding? A Systematic Analysis from Data to Architecture](https://arxiv.org/abs/2509.02359)
*Wanyue Zhang,Yibin Huang,Yangbin Xu,JingJing Huang,Helu Zhi,Shuo Ren,Wang Xu,Jiajun Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Spatial understanding is essential for Multimodal Large Language Models
(MLLMs) to support perception, reasoning, and planning in embodied
environments. Despite recent progress, existing studies reveal that MLLMs still
struggle with spatial understanding. However, existing research lacks a
comprehensive and systematic evaluation of these limitations, often restricted
to isolated scenarios, such as single-view or video. In this work, we present a
systematic analysis of spatial understanding from both data and architectural
perspectives across three representative scenarios: single-view, multi-view,
and video. We propose a benchmark named MulSeT (Multi-view Spatial
Understanding Tasks), and design a series of experiments to analyze the spatial
reasoning capabilities of MLLMs. From the data perspective, the performance of
spatial understanding converges quickly as the training data increases, and the
upper bound is relatively low, especially for tasks that require spatial
imagination. This indicates that merely expanding training data is insufficient
to achieve satisfactory performance. From the architectural perspective, we
find that spatial understanding relies more heavily on the positional encoding
within the visual encoder than within the language model, in both cascaded and
native MLLMs. Moreover, we explore reasoning injection and envision future
improvements through architectural design to optimize spatial understanding.
These insights shed light on the limitations of current MLLMs and suggest new
directions for improving spatial reasoning capabilities through data scaling
and architectural tuning.

</details>


### [201] [MedDINOv3: How to adapt vision foundation models for medical image segmentation?](https://arxiv.org/abs/2509.02379)
*Yuheng Li,Yizhou Wu,Yuxiang Lai,Mingzhe Hu,Xiaofeng Yang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate segmentation of organs and tumors in CT and MRI scans is essential
for diagnosis, treatment planning, and disease monitoring. While deep learning
has advanced automated segmentation, most models remain task-specific, lacking
generalizability across modalities and institutions. Vision foundation models
(FMs) pretrained on billion-scale natural images offer powerful and
transferable representations. However, adapting them to medical imaging faces
two key challenges: (1) the ViT backbone of most foundation models still
underperform specialized CNNs on medical image segmentation, and (2) the large
domain gap between natural and medical images limits transferability. We
introduce \textbf{MedDINOv3}, a simple and effective framework for adapting
DINOv3 to medical segmentation. We first revisit plain ViTs and design a simple
and effective architecture with multi-scale token aggregation. Then, we perform
domain-adaptive pretraining on \textbf{CT-3M}, a curated collection of 3.87M
axial CT slices, using a multi-stage DINOv3 recipe to learn robust dense
features. MedDINOv3 matches or exceeds state-of-the-art performance across four
segmentation benchmarks, demonstrating the potential of vision foundation
models as unified backbones for medical image segmentation. The code is
available at https://github.com/ricklisz/MedDINOv3.

</details>


### [202] [Decoupling Bidirectional Geometric Representations of 4D cost volume with 2D convolution](https://arxiv.org/abs/2509.02415)
*Xiaobao Wei,Changyong Shu,Zhaokun Yue,Chang Huang,Weiwei Liu,Shuai Yang,Lirong Yang,Peng Gao,Wenbin Zhang,Gaochao Zhu,Chengxiang Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: High-performance real-time stereo matching methods invariably rely on 3D
regularization of the cost volume, which is unfriendly to mobile devices. And
2D regularization based methods struggle in ill-posed regions. In this paper,
we present a deployment-friendly 4D cost aggregation network DBStereo, which is
based on pure 2D convolutions. Specifically, we first provide a thorough
analysis of the decoupling characteristics of 4D cost volume. And design a
lightweight bidirectional geometry aggregation block to capture spatial and
disparity representation respectively. Through decoupled learning, our approach
achieves real-time performance and impressive accuracy simultaneously.
Extensive experiments demonstrate that our proposed DBStereo outperforms all
existing aggregation-based methods in both inference time and accuracy, even
surpassing the iterative-based method IGEV-Stereo. Our study break the
empirical design of using 3D convolutions for 4D cost volume and provides a
simple yet strong baseline of the proposed decouple aggregation paradigm for
further study. Code will be available at
(\href{https://github.com/happydummy/DBStereo}{https://github.com/happydummy/DBStereo})
soon.

</details>


### [203] [From Noisy Labels to Intrinsic Structure: A Geometric-Structural Dual-Guided Framework for Noise-Robust Medical Image Segmentation](https://arxiv.org/abs/2509.02419)
*Tao Wang,Zhenxuan Zhang,Yuanbo Zhou,Xinlin Zhang,Yuanbin Chen,Tao Tan,Guang Yang,Tong Tong*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The effectiveness of convolutional neural networks in medical image
segmentation relies on large-scale, high-quality annotations, which are costly
and time-consuming to obtain. Even expert-labeled datasets inevitably contain
noise arising from subjectivity and coarse delineations, which disrupt feature
learning and adversely impact model performance. To address these challenges,
this study propose a Geometric-Structural Dual-Guided Network (GSD-Net), which
integrates geometric and structural cues to improve robustness against noisy
annotations. It incorporates a Geometric Distance-Aware module that dynamically
adjusts pixel-level weights using geometric features, thereby strengthening
supervision in reliable regions while suppressing noise. A Structure-Guided
Label Refinement module further refines labels with structural priors, and a
Knowledge Transfer module enriches supervision and improves sensitivity to
local details. To comprehensively assess its effectiveness, we evaluated
GSD-Net on six publicly available datasets: four containing three types of
simulated label noise, and two with multi-expert annotations that reflect
real-world subjectivity and labeling inconsistencies. Experimental results
demonstrate that GSD-Net achieves state-of-the-art performance under noisy
annotations, achieving improvements of 2.52% on Kvasir, 22.76% on Shenzhen,
8.87% on BU-SUC, and 4.59% on BraTS2020 under SR simulated noise. The codes of
this study are available at https://github.com/ortonwang/GSD-Net.

</details>


### [204] [Faster and Better: Reinforced Collaborative Distillation and Self-Learning for Infrared-Visible Image Fusion](https://arxiv.org/abs/2509.02424)
*Yuhao Wang,Lingjuan Miao,Zhiqiang Zhou,Yajun Qiao,Lei Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Infrared and visible image fusion plays a critical role in enhancing scene
perception by combining complementary information from different modalities.
Despite recent advances, achieving high-quality image fusion with lightweight
models remains a significant challenge. To bridge this gap, we propose a novel
collaborative distillation and self-learning framework for image fusion driven
by reinforcement learning. Unlike conventional distillation, this approach not
only enables the student model to absorb image fusion knowledge from the
teacher model, but more importantly, allows the student to perform
self-learning on more challenging samples to enhance its capabilities.
Particularly, in our framework, a reinforcement learning agent explores and
identifies a more suitable training strategy for the student.The agent takes
both the student's performance and the teacher-student gap as inputs, which
leads to the generation of challenging samples to facilitate the student's
self-learning. Simultaneously, it dynamically adjusts the teacher's guidance
strength based on the student's state to optimize the knowledge transfer.
Experimental results demonstrate that our method can significantly improve
student performance and achieve better fusion results compared to existing
techniques.

</details>


### [205] [Towards High-Fidelity, Identity-Preserving Real-Time Makeup Transfer: Decoupling Style Generation](https://arxiv.org/abs/2509.02445)
*Lydia Kin Ching Chau,Zhi Yu,Ruo Wei Jiang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a novel framework for real-time virtual makeup try-on that
achieves high-fidelity, identity-preserving cosmetic transfer with robust
temporal consistency. In live makeup transfer applications, it is critical to
synthesize temporally coherent results that accurately replicate fine-grained
makeup and preserve user's identity. However, existing methods often struggle
to disentangle semitransparent cosmetics from skin tones and other identify
features, causing identity shifts and raising fairness concerns. Furthermore,
current methods lack real-time capabilities and fail to maintain temporal
consistency, limiting practical adoption. To address these challenges, we
decouple makeup transfer into two steps: transparent makeup mask extraction and
graphics-based mask rendering. After the makeup extraction step, the makeup
rendering can be performed in real time, enabling live makeup try-on. Our
makeup extraction model trained on pseudo-ground-truth data generated via two
complementary methods: a graphics-based rendering pipeline and an unsupervised
k-means clustering approach. To further enhance transparency estimation and
color fidelity, we propose specialized training objectives, including
alpha-weighted reconstruction and lip color losses. Our method achieves robust
makeup transfer across diverse poses, expressions, and skin tones while
preserving temporal smoothness. Extensive experiments demonstrate that our
approach outperforms existing baselines in capturing fine details, maintaining
temporal stability, and preserving identity integrity.

</details>


### [206] [RiverScope: High-Resolution River Masking Dataset](https://arxiv.org/abs/2509.02451)
*Rangel Daroya,Taylor Rowley,Jonathan Flores,Elisa Friedmann,Fiona Bennitt,Heejin An,Travis Simmons,Marissa Jean Hughes,Camryn L Kluetmeier,Solomon Kica,J. Daniel Vélez,Sarah E. Esenther,Thomas E. Howard,Yanqi Ye,Audrey Turcotte,Colin Gleason,Subhransu Maji*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Surface water dynamics play a critical role in Earth's climate system,
influencing ecosystems, agriculture, disaster resilience, and sustainable
development. Yet monitoring rivers and surface water at fine spatial and
temporal scales remains challenging -- especially for narrow or sediment-rich
rivers that are poorly captured by low-resolution satellite data. To address
this, we introduce RiverScope, a high-resolution dataset developed through
collaboration between computer science and hydrology experts. RiverScope
comprises 1,145 high-resolution images (covering 2,577 square kilometers) with
expert-labeled river and surface water masks, requiring over 100 hours of
manual annotation. Each image is co-registered with Sentinel-2, SWOT, and the
SWOT River Database (SWORD), enabling the evaluation of cost-accuracy
trade-offs across sensors -- a key consideration for operational water
monitoring. We also establish the first global, high-resolution benchmark for
river width estimation, achieving a median error of 7.2 meters -- significantly
outperforming existing satellite-derived methods. We extensively evaluate deep
networks across multiple architectures (e.g., CNNs and transformers),
pretraining strategies (e.g., supervised and self-supervised), and training
datasets (e.g., ImageNet and satellite imagery). Our best-performing models
combine the benefits of transfer learning with the use of all the multispectral
PlanetScope channels via learned adaptors. RiverScope provides a valuable
resource for fine-scale and multi-sensor hydrological modeling, supporting
climate adaptation and sustainable water management.

</details>


### [207] [GenCompositor: Generative Video Compositing with Diffusion Transformer](https://arxiv.org/abs/2509.02460)
*Shuzhou Yang,Xiaoyu Li,Xiaodong Cun,Guangzhi Wang,Lingen Li,Ying Shan,Jian Zhang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Video compositing combines live-action footage to create video production,
serving as a crucial technique in video creation and film production.
Traditional pipelines require intensive labor efforts and expert collaboration,
resulting in lengthy production cycles and high manpower costs. To address this
issue, we automate this process with generative models, called generative video
compositing. This new task strives to adaptively inject identity and motion
information of foreground video to the target video in an interactive manner,
allowing users to customize the size, motion trajectory, and other attributes
of the dynamic elements added in final video. Specifically, we designed a novel
Diffusion Transformer (DiT) pipeline based on its intrinsic properties. To
maintain consistency of the target video before and after editing, we revised a
light-weight DiT-based background preservation branch with masked token
injection. As to inherit dynamic elements from other sources, a DiT fusion
block is proposed using full self-attention, along with a simple yet effective
foreground augmentation for training. Besides, for fusing background and
foreground videos with different layouts based on user control, we developed a
novel position embedding, named Extended Rotary Position Embedding (ERoPE).
Finally, we curated a dataset comprising 61K sets of videos for our new task,
called VideoComp. This data includes complete dynamic elements and high-quality
target videos. Experiments demonstrate that our method effectively realizes
generative video compositing, outperforming existing possible solutions in
fidelity and consistency.

</details>


### [208] [TeRA: Rethinking Text-driven Realistic 3D Avatar Generation](https://arxiv.org/abs/2509.02466)
*Yanwen Wang,Yiyu Zhuang,Jiawei Zhang,Li Wang,Yifei Zeng,Xun Cao,Xinxin Zuo,Hao Zhu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we rethink text-to-avatar generative models by proposing TeRA,
a more efficient and effective framework than the previous SDS-based models and
general large 3D generative models. Our approach employs a two-stage training
strategy for learning a native 3D avatar generative model. Initially, we
distill a decoder to derive a structured latent space from a large human
reconstruction model. Subsequently, a text-controlled latent diffusion model is
trained to generate photorealistic 3D human avatars within this latent space.
TeRA enhances the model performance by eliminating slow iterative optimization
and enables text-based partial customization through a structured 3D human
representation. Experiments have proven our approach's superiority over
previous text-to-avatar generative models in subjective and objective
evaluation.

</details>


### [209] [Anisotropic Fourier Features for Positional Encoding in Medical Imaging](https://arxiv.org/abs/2509.02488)
*Nabil Jabareen,Dongsheng Yuan,Dingming Liu,Foo-Wei Ten,Sören Lukassen*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The adoption of Transformer-based architectures in the medical domain is
growing rapidly. In medical imaging, the analysis of complex shapes - such as
organs, tissues, or other anatomical structures - combined with the often
anisotropic nature of high-dimensional images complicates these adaptations. In
this study, we critically examine the role of Positional Encodings (PEs),
arguing that commonly used approaches may be suboptimal for the specific
challenges of medical imaging. Sinusoidal Positional Encodings (SPEs) have
proven effective in vision tasks, but they struggle to preserve Euclidean
distances in higher-dimensional spaces. Isotropic Fourier Feature Positional
Encodings (IFPEs) have been proposed to better preserve Euclidean distances,
but they lack the ability to account for anisotropy in images. To address these
limitations, we propose Anisotropic Fourier Feature Positional Encoding (AFPE),
a generalization of IFPE that incorporates anisotropic, class-specific, and
domain-specific spatial dependencies. We systematically benchmark AFPE against
commonly used PEs on multi-label classification in chest X-rays, organ
classification in CT images, and ejection fraction regression in
echocardiography. Our results demonstrate that choosing the correct PE can
significantly improve model performance. We show that the optimal PE depends on
the shape of the structure of interest and the anisotropy of the data. Finally,
our proposed AFPE significantly outperforms state-of-the-art PEs in all tested
anisotropic settings. We conclude that, in anisotropic medical images and
videos, it is of paramount importance to choose an anisotropic PE that fits the
data and the shape of interest.

</details>


### [210] [Enhancing Fitness Movement Recognition with Attention Mechanism and Pre-Trained Feature Extractors](https://arxiv.org/abs/2509.02511)
*Shanjid Hasan Nishat,Srabonti Deb,Mohiuddin Ahmed*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Fitness movement recognition, a focused subdomain of human activity
recognition (HAR), plays a vital role in health monitoring, rehabilitation, and
personalized fitness training by enabling automated exercise classification
from video data. However, many existing deep learning approaches rely on
computationally intensive 3D models, limiting their feasibility in real-time or
resource-constrained settings. In this paper, we present a lightweight and
effective framework that integrates pre-trained 2D Convolutional Neural
Networks (CNNs) such as ResNet50, EfficientNet, and Vision Transformers (ViT)
with a Long Short-Term Memory (LSTM) network enhanced by spatial attention.
These models efficiently extract spatial features while the LSTM captures
temporal dependencies, and the attention mechanism emphasizes informative
segments. We evaluate the framework on a curated subset of the UCF101 dataset,
achieving a peak accuracy of 93.34\% with the ResNet50-based configuration.
Comparative results demonstrate the superiority of our approach over several
state-of-the-art HAR systems. The proposed method offers a scalable and
real-time-capable solution for fitness activity recognition with broader
applications in vision-based health and activity monitoring.

</details>


### [211] [Mix-modal Federated Learning for MRI Image Segmentation](https://arxiv.org/abs/2509.02541)
*Guyue Hu,Siyuan Song,Jingpeng Sun,Zhe Jin,Chenglong Li,Jin Tang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Magnetic resonance imaging (MRI) image segmentation is crucial in diagnosing
and treating many diseases, such as brain tumors. Existing MRI image
segmentation methods mainly fall into a centralized multimodal paradigm, which
is inapplicable in engineering non-centralized mix-modal medical scenarios. In
this situation, each distributed client (hospital) processes multiple mixed MRI
modalities, and the modality set and image data for each client are diverse,
suffering from extensive client-wise modality heterogeneity and data
heterogeneity. In this paper, we first formulate non-centralized mix-modal MRI
image segmentation as a new paradigm for federated learning (FL) that involves
multiple modalities, called mix-modal federated learning (MixMFL). It
distinguishes from existing multimodal federating learning (MulMFL) and
cross-modal federating learning (CroMFL) paradigms. Then, we proposed a novel
modality decoupling and memorizing mix-modal federated learning framework
(MDM-MixMFL) for MRI image segmentation, which is characterized by a modality
decoupling strategy and a modality memorizing mechanism. Specifically, the
modality decoupling strategy disentangles each modality into modality-tailored
and modality-shared information. During mix-modal federated updating,
corresponding modality encoders undergo tailored and shared updating,
respectively. It facilitates stable and adaptive federating aggregation of
heterogeneous data and modalities from distributed clients. Besides, the
modality memorizing mechanism stores client-shared modality prototypes
dynamically refreshed from every modality-tailored encoder to compensate for
incomplete modalities in each local client. It further benefits modality
aggregation and fusion processes during mixmodal federated learning. Extensive
experiments on two public datasets for MRI image segmentation demonstrate the
effectiveness and superiority of our methods.

</details>


### [212] [Motion-Refined DINOSAUR for Unsupervised Multi-Object Discovery](https://arxiv.org/abs/2509.02545)
*Xinrui Gong,Oliver Hahn,Christoph Reich,Krishnakant Singh,Simone Schaub-Meyer,Daniel Cremers,Stefan Roth*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Unsupervised multi-object discovery (MOD) aims to detect and localize
distinct object instances in visual scenes without any form of human
supervision. Recent approaches leverage object-centric learning (OCL) and
motion cues from video to identify individual objects. However, these
approaches use supervision to generate pseudo labels to train the OCL model. We
address this limitation with MR-DINOSAUR -- Motion-Refined DINOSAUR -- a
minimalistic unsupervised approach that extends the self-supervised pre-trained
OCL model, DINOSAUR, to the task of unsupervised multi-object discovery. We
generate high-quality unsupervised pseudo labels by retrieving video frames
without camera motion for which we perform motion segmentation of unsupervised
optical flow. We refine DINOSAUR's slot representations using these pseudo
labels and train a slot deactivation module to assign slots to foreground and
background. Despite its conceptual simplicity, MR-DINOSAUR achieves strong
multi-object discovery results on the TRI-PD and KITTI datasets, outperforming
the previous state of the art despite being fully unsupervised.

</details>


### [213] [FastVGGT: Training-Free Acceleration of Visual Geometry Transformer](https://arxiv.org/abs/2509.02560)
*You Shen,Zhipeng Zhang,Yansong Qu,Liujuan Cao*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Foundation models for 3D vision have recently demonstrated remarkable
capabilities in 3D perception. However, scaling these models to long-sequence
image inputs remains a significant challenge due to inference-time
inefficiency. In this work, we present a detailed analysis of VGGT, a
state-of-the-art feed-forward visual geometry model and identify its primary
bottleneck. Visualization further reveals a token collapse phenomenon in the
attention maps. Motivated by these findings, we explore the potential of token
merging in the feed-forward visual geometry model. Owing to the unique
architectural and task-specific properties of 3D models, directly applying
existing merging techniques proves challenging. To this end, we propose
FastVGGT, which, for the first time, leverages token merging in the 3D domain
through a training-free mechanism for accelerating VGGT. we devise a unique
token partitioning strategy tailored to 3D architectures and tasks, effectively
eliminating redundant computation while preserving VGGT's powerful
reconstruction capacity. Extensive experiments on multiple 3D geometry
benchmarks validate the effectiveness of our approach. Notably, with 1000 input
images, FastVGGT achieves a 4x speedup over VGGT while mitigating error
accumulation in long-sequence scenarios. These findings underscore the
potential of token merging as a principled solution for scalable 3D vision
systems. Code is available at: https://mystorm16.github.io/fastvggt/.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [214] [MultiStream-LLM: Bridging Modalities for Robust Sign Language Translation](https://arxiv.org/abs/2509.00030)
*Marshall Thomas,Edward Fish,Richard Bowden*

Main category: cs.CL

TL;DR: MultiStream-LLM是一个模块化框架，通过为手语翻译中的连续手语、拼写和唇语识别使用单独的专家网络，然后将它们融合并通过LLM生成句子，从而克服了现有方法的局限性，并在How2Sign和ChicagoFSWildPlus数据集上取得了新的最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决现有端到端模型在处理高速拼写和非手动面部线索集成方面的不足，这些方面对于翻译姓名、地点和技术术语至关重要。

Method: 使用单独的专家网络来识别连续手语、拼写和唇读，然后将这些流融合，并通过一个轻量级Transformer解决时间错位问题，最后将组合表示传递给LLM进行句子生成。

Result: 在How2Sign基准测试上取得了23.5的BLEU-4分数，在ChicagoFSWildPlus拼写数据集上实现了73.2%的字母准确率，这些结果证明了该方法的有效性。

Conclusion: 将不同的识别任务分离并解决，然后再进行融合，这种多专家方法比单一网络更能有效地实现鲁棒、高保真的手语翻译。

Abstract: Despite progress in gloss-free Sign Language Translation (SLT), monolithic
end-to-end models consistently fail on two critical components of natural
signing: the precise recognition of high-speed fingerspelling and the
integration of asynchronous non-manual cues from the face. Recent progress in
Automated Sign Language Translation with Large Language Models has side stepped
this challenge, forcing a single network to learn these simultaneously
resulting in poor performance when tasked with translating crucial information
such as names,places, and technical terms. We introduce MultiStream-LLM, a
modular framework designed to overcome these limitations. Our approach employs
separate, specialized predictors for continuous signing, fingerspelling, and
lipreading. Each expert network first decodes its specific modality into a
sequence of tokens. These parallel streams are then fused by a lightweight
transformer that resolves temporal misalignments before passing the combined
representation to a Large Language Model (LLM) for final sentence generation.
Our method establishes a new state-of-the-art on the How2Sign benchmark with a
BLEU-4 score of 23.5 and achieves 73.2% letter accuracy on the challenging
ChicagoFSWildPlus fingerspelling dataset. These results validate our core
hypothesis: by isolating and solving distinct recogni tion tasks before fusion,
our multi-expert approach provides a more powerful and effective pathway to
robust, high-fidelity sign language translation.

</details>


### [215] [Compiling Prompts, Not Crafting Them: A Reproducible Workflow for AI-Assisted Evidence Synthesis](https://arxiv.org/abs/2509.00038)
*Teo Susnjak*

Main category: cs.CL

TL;DR: LLM在系统文献综述（SLR）中的应用可通过声明式提示优化得到改进，从而提高可靠性和可重复性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM驱动的SLR方法依赖于容易出错的手动提示，这削弱了科学界对LLM辅助证据合成的信心。

Method: 该研究提出了一种结构化的、领域特定的框架，该框架集成了任务声明、测试套件和自动提示调整，用于可重复的SLR工作流，并将这些方法转化为包含可验证LLM管道的实际蓝图。

Result: 该框架能够构建符合证据合成中透明度和严谨性原则的可验证LLM管道。

Conclusion: 该研究首次将声明式提示优化方法应用于SLR流程，为提高LLM在SLR自动化中的可靠性和可重复性提供了新的途径。

Abstract: Large language models (LLMs) offer significant potential to accelerate
systematic literature reviews (SLRs), yet current approaches often rely on
brittle, manually crafted prompts that compromise reliability and
reproducibility. This fragility undermines scientific confidence in
LLM-assisted evidence synthesis. In response, this work adapts recent advances
in declarative prompt optimisation, developed for general-purpose LLM
applications, and demonstrates their applicability to the domain of SLR
automation. This research proposes a structured, domain-specific framework that
embeds task declarations, test suites, and automated prompt tuning into a
reproducible SLR workflow. These emerging methods are translated into a
concrete blueprint with working code examples, enabling researchers to
construct verifiable LLM pipelines that align with established principles of
transparency and rigour in evidence synthesis. This is a novel application of
such approaches to SLR pipelines.

</details>


### [216] [What Are Research Hypotheses?](https://arxiv.org/abs/2509.00185)
*Jian Wu,Sarah Rajtmajer*

Main category: cs.CL

TL;DR: 该论文概述了自然语言处理（NLU）领域中“假设”一词的不同定义，强调了明确定义假设的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言处理（NLP）的进步，在科学领域自动提取、理解、测试和生成假设受到了广泛关注。然而，“假设”一词的解释在不同的自然语言理解（NLU）任务中存在差异，甚至在NLU文献中，对假设的定义也各不相同。因此，有必要对这些定义进行梳理和区分。

Method: 本文回顾并区分了假设的各种定义，特别关注了近期NLU任务中定义的细微差别。

Result: 论文识别并区分了假设在不同NLU任务中的多种定义，并指出了清晰定义假设的必要性。

Conclusion: 清晰、结构化的假设定义对于推动可机器解释的学术记录至关重要。

Abstract: Over the past decades, alongside advancements in natural language processing,
significant attention has been paid to training models to automatically
extract, understand, test, and generate hypotheses in open and scientific
domains. However, interpretations of the term \emph{hypothesis} for various
natural language understanding (NLU) tasks have migrated from traditional
definitions in the natural, social, and formal sciences. Even within NLU, we
observe differences defining hypotheses across literature. In this paper, we
overview and delineate various definitions of hypothesis. Especially, we
discern the nuances of definitions across recently published NLU tasks. We
highlight the importance of well-structured and well-defined hypotheses,
particularly as we move toward a machine-interpretable scholarly record.

</details>


### [217] [Explainable Chain-of-Thought Reasoning: An Empirical Analysis on State-Aware Reasoning Dynamics](https://arxiv.org/abs/2509.00190)
*Sheldon Yu,Yuxin Xiong,Junda Wu,Xintong Li,Tong Yu,Xiang Chen,Ritwik Sinha,Jingbo Shang,Julian McAuley*

Main category: cs.CL

TL;DR: 链式思考（CoT）的推理过程可以通过状态转移框架进行结构化抽象，揭示其内在的语义状态和转移模式，从而提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 链式思考（CoT）提示虽然提升了LLMs的多步推理能力，但其推理过程的可解释性有限，现有方法主要关注词元级别归因，忽略了推理步骤的语义角色及其转移的全局结构。

Method: 提出一个状态感知转移框架，将CoT轨迹抽象为结构化潜在动力学。通过对词元级别嵌入进行谱分析并将推理步骤聚类到语义连贯的潜在状态，以捕捉CoT推理不断演变的语义。将推理过程的进展建模为马尔可夫链，以提供结构化且可解释的视图。

Result: 该框架支持语义角色识别、时间模式可视化和一致性评估等多种分析。

Conclusion: 通过将CoT轨迹抽象为状态转移模型，可以提供对LLM推理过程的更深层次的结构化和可解释的理解。

Abstract: Recent advances in chain-of-thought (CoT) prompting have enabled large
language models (LLMs) to perform multi-step reasoning. However, the
explainability of such reasoning remains limited, with prior work primarily
focusing on local token-level attribution, such that the high-level semantic
roles of reasoning steps and their transitions remain underexplored. In this
paper, we introduce a state-aware transition framework that abstracts CoT
trajectories into structured latent dynamics. Specifically, to capture the
evolving semantics of CoT reasoning, each reasoning step is represented via
spectral analysis of token-level embeddings and clustered into semantically
coherent latent states. To characterize the global structure of reasoning, we
model their progression as a Markov chain, yielding a structured and
interpretable view of the reasoning process. This abstraction supports a range
of analyses, including semantic role identification, temporal pattern
visualization, and consistency evaluation.

</details>


### [218] [The Rarity Blind Spot: A Framework for Evaluating Statistical Reasoning in LLMs](https://arxiv.org/abs/2509.00245)
*Seiji Maekawa,Hayate Iso,Nikita Bhutani*

Main category: cs.CL

TL;DR: 新的DFM任务旨在评估LLMs在文档集合中识别稀有特征的能力，DiFBench基准用于评估现有LLMs，发现其在处理复杂性和文档数量增加时性能下降，并且存在将频繁特征误识别为独特特征的常见失败模式。


<details>
  <summary>Details</summary>
Motivation: 现有LLM基准侧重于信息检索和摘要，未能评估模型识别文档集合中全局独特特征的能力，而这在候选选择和产品差异化等现实场景中至关重要。

Method: 提出DFM任务，要求模型分析文档集合（10-40篇）并找出全局稀有特征（出现频率低于10%）。开发DiFBench基准框架，包含可配置参数（文档集大小、独特性阈值）。使用DiFBench对十种先进LLMs进行大规模评估。

Result: 在DFM任务上，通用模型与增强推理能力模型之间存在显著性能差距。所有模型在任务复杂性和文档数量增加时性能都会大幅下降。一个常见的失败模式是错误地将频繁特征识别为独特特征。

Conclusion: 当前的LLM在细粒度统计推理和稀有度检测方面存在核心局限性。

Abstract: Effective decision-making often relies on identifying what makes each
candidate distinctive. While existing benchmarks for LLMs emphasize retrieving
or summarizing information relevant to a given query, they do not evaluate a
model's ability to identify globally distinctive features across a set of
documents. We introduce Distinctive Feature Mining (DFM), a new task that
challenges models to analyze a small-to-medium collection (10-40 documents) and
surface features that are rare in the global context (e.g., appearing in less
than 10% of documents). This setting mirrors real-world scenarios such as
candidate selection or product differentiation, where statistical reasoning,
not retrieval, is key. To enable systematic evaluation of this capability, we
present DiFBench, a configurable benchmark creation framework with controllable
parameters such as document set size and distinctiveness thresholds. Using
DiFBench, we perform a large-scale assessment of distinctive feature mining
across ten state-of-the-art LLMs. Our findings reveal a significant performance
gap between general-purpose and reasoning-enhanced models. All models, however,
substantially degrade as the task complexity and document count increase. We
also find that a common failure mode is misidentifying frequent features as
distinctive. These insights reveal core limitations in contemporary LLMs'
abilities to perform fine-grained, statistical reasoning and rarity detection.

</details>


### [219] [The Differential Meaning of Models: A Framework for Analyzing the Structural Consequences of Semantic Modeling Decisions](https://arxiv.org/abs/2509.00248)
*Zachary K. Stine,James E. Deitrick*

Main category: cs.CL

TL;DR: 该论文提出了一个基于C.S.皮尔士符号学理论的通用理论框架，用于描述和比较不同类型的人类意义建构模型。该框架认为模型测量潜在的符号几何，可以理解为对符号数据集中潜在的符号学机制的假设。当模型的价值无法通过代理绩效指标直接衡量时，可以通过模型间的对比来理解其解释性视角，从而形成模型语义学理论，将模型本身及其构成性决策视为符号。论文还通过实例说明了该框架的实际应用，并探讨了其带来的基础性问题和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前领域缺乏一个通用的理论框架来描述和比较不同类型的人类意义建构模型。

Method: 提出一个基于C.S.皮尔士符号学理论的通用理论框架，该框架认为模型测量潜在的符号几何，并提出在模型价值难以直接衡量时，可以通过模型间的对比来理解其解释性视角，形成模型语义学理论。

Result: 提出了一个理论框架，并通过实例说明了其经验应用，探讨了相关基础性问题和未来方向。

Conclusion: 该理论框架为理解和比较人类意义建构模型提供了一种新的视角，将模型本身视为符号，并强调了模型间对比在理解模型语义中的作用。

Abstract: The proliferation of methods for modeling of human meaning-making constitutes
a powerful class of instruments for the analysis of complex semiotic systems.
However, the field lacks a general theoretical framework for describing these
modeling practices across various model types in an apples-to-apples way. In
this paper, we propose such a framework grounded in the semiotic theory of C.
S. Peirce. We argue that such models measure latent symbol geometries, which
can be understood as hypotheses about the complex of semiotic agencies
underlying a symbolic dataset. Further, we argue that in contexts where a
model's value cannot be straightforwardly captured by proxy measures of
performance, models can instead be understood relationally, so that the
particular interpretive lens of a model becomes visible through its contrast
with other models. This forms the basis of a theory of model semantics in which
models, and the modeling decisions that constitute them, are themselves treated
as signs. In addition to proposing the framework, we illustrate its empirical
use with a few brief examples and consider foundational questions and future
directions enabled by the framework.

</details>


### [220] [The Temporal Game: A New Perspective on Temporal Relation Extraction](https://arxiv.org/abs/2509.00250)
*Hugo Sousa,Ricardo Campos,Alípio Jorge*

Main category: cs.CL

TL;DR: 我们演示了时间游戏，一种将时间关系抽取视为交互式游戏的新方法。它将时间关系分解为时间点之间的比较，以实现更细粒度和灵活的注释，并支持强化学习。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在提出一种新颖的时间关系抽取方法，将其视为一种交互式游戏，通过将时间关系分解为时间点之间的比较，以实现更细粒度和灵活的注释，并为强化学习模型的训练奠定基础。

Method: 将时间关系抽取视为交互式游戏，将时间关系的标注分解为对时间点之间关系的分类，并利用时间闭包来推断其他关系和强制执行一致性。该方法支持区间和瞬时实体，并可作为序列决策任务用于训练强化学习代理。

Result: 演示了一个名为“时间游戏”的系统，该系统具有游戏模式和标注模式，允许用户标注TempEval-3数据集或自定义文档，并提供基于评分系统的反馈，同时可以导出标注结果。该系统是一个研究工具和标注接口。

Conclusion: 时间游戏提供了一种新颖、灵活且细粒度的时间关系抽取方法，通过将其游戏化并分解为点对点比较来实现。此外，它还为利用序列决策和强化学习来改进时间标注提供了途径。该演示作为研究工具和标注接口，并已开源以促进社区发展。

Abstract: In this paper we demo the Temporal Game, a novel approach to temporal
relation extraction that casts the task as an interactive game. Instead of
directly annotating interval-level relations, our approach decomposes them into
point-wise comparisons between the start and end points of temporal entities.
At each step, players classify a single point relation, and the system applies
temporal closure to infer additional relations and enforce consistency. This
point-based strategy naturally supports both interval and instant entities,
enabling more fine-grained and flexible annotation than any previous approach.
The Temporal Game also lays the groundwork for training reinforcement learning
agents, by treating temporal annotation as a sequential decision-making task.
To showcase this potential, the demo presented in this paper includes a Game
mode, in which users annotate texts from the TempEval-3 dataset and receive
feedback based on a scoring system, and an Annotation mode, that allows custom
documents to be annotated and resulting timeline to be exported. Therefore,
this demo serves both as a research tool and an annotation interface. The demo
is publicly available at https://temporal-game.inesctec.pt, and the source code
is open-sourced to foster further research and community-driven development in
temporal reasoning and annotation.

</details>


### [221] [Exploring Reasoning-Infused Text Embedding with Large Language Models for Zero-Shot Dense Retrieval](https://arxiv.org/abs/2509.00276)
*Yuxiang Liu,Tian Wang,Gourab Kundu,Tianyu Cao,Guang Cheng,Zhen Ge,Jianshu Chen,Qingjun Cui,Trishul Chilimbi*

Main category: cs.CL

TL;DR: RITE是一种通过生成中间推理文本来增强文本嵌入的LLM方法，在BRIGHT基准测试中显著提高了零样本检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于Transformer的文本嵌入模型（如BERT、E5）在处理需要复杂推理的查询时表现不足，而基于LLM的方法未能充分利用其推理能力。

Method: RITE是一种在文本嵌入过程中整合逻辑推理的方法，利用生成式LLM在计算嵌入之前，在token空间中生成中间推理文本，从而丰富嵌入的推理深度。

Result: 在BRIGHT基准测试中，RITE显著提升了跨领域零样本检索性能。

Conclusion: 将推理能力整合到文本嵌入过程中，能够有效提升检索性能。

Abstract: Transformer-based models such as BERT and E5 have significantly advanced text
embedding by capturing rich contextual representations. However, many complex
real-world queries require sophisticated reasoning to retrieve relevant
documents beyond surface-level lexical matching, where encoder-only retrievers
often fall short. Decoder-only large language models (LLMs), known for their
strong reasoning capabilities, offer a promising alternative. Despite this
potential, existing LLM-based embedding methods primarily focus on contextual
representation and do not fully exploit the reasoning strength of LLMs. To
bridge this gap, we propose Reasoning-Infused Text Embedding (RITE), a simple
but effective approach that integrates logical reasoning into the text
embedding process using generative LLMs. RITE builds upon existing language
model embedding techniques by generating intermediate reasoning texts in the
token space before computing embeddings, thereby enriching representations with
inferential depth. Experimental results on BRIGHT, a reasoning-intensive
retrieval benchmark, demonstrate that RITE significantly enhances zero-shot
retrieval performance across diverse domains, underscoring the effectiveness of
incorporating reasoning into the embedding process.

</details>


### [222] [OpinioRAG: Towards Generating User-Centric Opinion Highlights from Large-scale Online Reviews](https://arxiv.org/abs/2509.00285)
*Mir Tafseer Nayeem,Davood Rafiei*

Main category: cs.CL

TL;DR: OpinioRAG是一个无需训练的框架，结合了基于RAG的证据检索和LLM，可生成个性化的观点摘要。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理大量用户评论时无法扩展或生成通用性强的摘要的问题，无法满足个性化需求。

Method: 提出OpinioRAG框架，结合RAG和LLM进行证据检索和摘要生成，并提出新的无参考验证指标。

Result: 通过大量实验，确定了关键挑战，为改进系统提供了可行性见解，并展示了OpinioRAG在生成准确、相关和结构化摘要方面的鲁棒性。

Conclusion: OpinioRAG是一个可扩展的、无需训练的框架，能够大规模生成准确、相关和结构化的观点摘要，并提出了新的验证指标以应对情感丰富领域的挑战。

Abstract: We study the problem of opinion highlights generation from large volumes of
user reviews, often exceeding thousands per entity, where existing methods
either fail to scale or produce generic, one-size-fits-all summaries that
overlook personalized needs. To tackle this, we introduce OpinioRAG, a
scalable, training-free framework that combines RAG-based evidence retrieval
with LLMs to efficiently produce tailored summaries. Additionally, we propose
novel reference-free verification metrics designed for sentiment-rich domains,
where accurately capturing opinions and sentiment alignment is essential. These
metrics offer a fine-grained, context-sensitive assessment of factual
consistency. To facilitate evaluation, we contribute the first large-scale
dataset of long-form user reviews, comprising entities with over a thousand
reviews each, paired with unbiased expert summaries and manually annotated
queries. Through extensive experiments, we identify key challenges, provide
actionable insights into improving systems, pave the way for future research,
and position OpinioRAG as a robust framework for generating accurate, relevant,
and structured summaries at scale.

</details>


### [223] [Wage Sentiment Indices Derived from Survey Comments via Large Language Models](https://arxiv.org/abs/2509.00290)
*Taihei Sone*

Main category: cs.CL

TL;DR: 该研究提出了一个基于大语言模型的工资情感指数（WSI），用于预测日本的工资动态，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 利用生成式人工智能（AI）分析经济文本，特别是构建一个能够预测工资动态的指数。

Method: 构建了一个工资情感指数（WSI），该指数基于日本内阁办公室的经济观察家调查（EWS），并利用大型语言模型（LLMs）进行分析。研究还开发了一个数据架构以整合包括报纸和社交媒体在内的多种数据源。

Result: 基于LLM的WSI模型在预测日本工资动态方面，显著优于基线方法和预训练模型。

Conclusion: 基于LLM的情感指数（如WSI）有潜力提高经济政策制定的及时性和有效性，为政府和中央银行提供支持。

Abstract: The emergence of generative Artificial Intelligence (AI) has created new
opportunities for economic text analysis. This study proposes a Wage Sentiment
Index (WSI) constructed with Large Language Models (LLMs) to forecast wage
dynamics in Japan. The analysis is based on the Economy Watchers Survey (EWS),
a monthly survey conducted by the Cabinet Office of Japan that captures
real-time economic assessments from workers in industries highly sensitive to
business conditions. The WSI extends the framework of the Price Sentiment Index
(PSI) used in prior studies, adapting it specifically to wage related
sentiment. To ensure scalability and adaptability, a data architecture is also
developed that enables integration of additional sources such as newspapers and
social media. Experimental results demonstrate that WSI models based on LLMs
significantly outperform both baseline approaches and pretrained models. These
findings highlight the potential of LLM-driven sentiment indices to enhance the
timeliness and effectiveness of economic policy design by governments and
central banks.

</details>


### [224] [Balanced Actor Initialization: Stable RLHF Training of Distillation-Based Reasoning Models](https://arxiv.org/abs/2509.00309)
*Chen Zheng,Yiyuan Ma,Yuan Yang,Deyi Liu,Jing Liu,Zuquan Song,Yuxin Song,Cheng Ren,Hang Zhu,Xin Liu,Yiyuan Ma,Siyuan Qiao,Xun Zhou,Liang Xiang,Yonghui Wu*

Main category: cs.CL

TL;DR: RLHF在基于蒸馏的模型上训练不稳定，提出BAI解决序列长度崩溃和奖励曲线问题，实验证明BAI能稳定训练并提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 探究将RLHF应用于蒸馏训练模型的挑战，并解决由此产生的序列长度崩溃和奖励曲线问题。

Method: 提出双阶段加权模型融合方法BAI，首先融合指令遵循和蒸馏推理微调模型，然后结合预训练模型以保留基础知识。

Result: BAI解决了序列长度崩溃问题，缓解了奖励曲线问题，并在训练中实现了序列长度的持续提升，同时在推理能力和训练稳定性之间取得了最佳权衡。

Conclusion: BAI为第三种范式提供了有效的稳定训练解决方案，能够结合蒸馏效率和RLHF对齐，从而获得更强大的推理模型。

Abstract: The development of alignment and reasoning capabilities in large language
models has seen remarkable progress through two paradigms: instruction tuning
and reinforcement learning from human feedback (RLHF) alignment paradigm, and
distillation-based reasoning fine-tuning paradigm. While both approaches prove
effective independently, the third paradigm of applying RLHF to
distillation-trained models presents significant challenges. Our investigation
reveals two critical phenomena that emerge in this paradigm: Sequence Length
Collapse, where language generation dramatically reduces during early RLHF
training, and the Reward Hockey Stick Curve, featuring severe reward score
drops followed by gradual recovery. These instabilities fundamentally
compromise the model's alignment and reasoning capabilities. To address these
challenges, we propose Balanced Actor Initialization (BAI), a two-stage
weighted model merging approach. BAI first merges instruction-following and
distillation-based reasoning fine-tuned models, then further combines this
intermediate model with the pretrained model to preserve foundational
knowledge. Through comprehensive experiments across diverse benchmarks and
detailed analysis of training experiments, we demonstrate that BAI resolves
Sequence Length Collapse, mitigates the Reward Hockey Stick Curve, and enables
continuous sequence length improvement during training. Additionally, our
analysis reveals that balanced merging ratios achieve optimal trade-offs
between training stability and reasoning capability preservation. Our work
provides the effective solution for stable training in this third paradigm,
enabling more capable reasoning models that combine distillation efficiency
with RLHF alignment.

</details>


### [225] [GIER: Gap-Driven Self-Refinement for Large Language Models](https://arxiv.org/abs/2509.00325)
*Rinku Dewri*

Main category: cs.CL

TL;DR: GIER是一个通过自我反思和基于概念质量标准的迭代改进来提升LLM输出的通用框架。


<details>
  <summary>Details</summary>
Motivation: GIER旨在通过利用自然语言描述的推理差距，来克服依赖演示、示例或思维链模板的现有提示策略的局限性，从而改进LLM输出。

Method: GIER通过提示模型迭代地批判和改进其自身的输出来满足概念质量标准，而无需演示、示例或思维链模板。

Result: 在SciFact、PrivacyQA和e-SNLI三个推理密集型任务以及GPT-4.1、GPT-4o Mini、Gemini 1.5 Pro和Llama 3.3 70B四个LLM上，GIER在不降低任务准确性的情况下提高了推理质量、基础性和推理一致性。

Conclusion: 模型不仅能解释抽象的概念差距，还能将其转化为具体的推理改进。

Abstract: We introduce GIER (Gap-driven Iterative Enhancement of Responses), a general
framework for improving large language model (LLM) outputs through
self-reflection and revision based on conceptual quality criteria. Unlike
prompting strategies that rely on demonstrations, examples, or chain-of-thought
templates, GIER utilizes natural language descriptions of reasoning gaps, and
prompts a model to iteratively critique and refine its own outputs to better
satisfy these criteria. Across three reasoning-intensive tasks (SciFact,
PrivacyQA, and e-SNLI) and four LLMs (GPT-4.1, GPT-4o Mini, Gemini 1.5 Pro, and
Llama 3.3 70B), GIER improves rationale quality, grounding, and reasoning
alignment without degrading task accuracy. Our analysis demonstrates that
models can not only interpret abstract conceptual gaps but also translate them
into concrete reasoning improvements.

</details>


### [226] [Open Data Synthesis For Deep Research](https://arxiv.org/abs/2509.00375)
*Ziyi Xia,Kun Luo,Hongjin Qian,Zheng Liu*

Main category: cs.CL

TL;DR: LLMs在深研任务中的应用：提出InfoSeek框架，用于合成复杂研究任务，并通过双代理系统和研究树来解决问题。InfoSeek生成的模型在BrowseComp-Plus基准测试中表现优于更大的模型和商业API。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法捕捉LLM在深研任务中的复杂性，且合成数据集常引入捷径推理或知识泄露。需要新的框架来解决这些问题。

Method: 提出InfoSeek框架，该框架使用双代理系统递归地从大规模网页构建研究树，将中间节点模糊化为子问题，并将这些树转化为需要遍历完整层级结构的自然语言问题。

Result: InfoSeek生成了超过50K的训练示例，一个精选的测试集，以及通过拒绝采样生成的推理轨迹。实验表明，在BrowseComp-Plus基准测试中，使用InfoSeek优化的3B LLM超越了更大的32B模型和商业API（如Gemini2.5-Flash），并达到了与Gemini2.5-Pro相当的性能。

Conclusion: InfoSeek框架成功地合成了复杂的深研任务，并且可以扩展以支持高级优化策略。该框架提高了LLM在需要多步骤推理和证据综合的任务中的性能。

Abstract: Large language models (LLMs) are increasingly expected to go beyond simple
factual queries toward Deep Research-tasks that require decomposing questions
into sub-problems, coordinating multi-step reasoning, and synthesizing evidence
from diverse sources. We formalize Deep Research tasks with verifiable answers
as Hierarchical Constraint Satisfaction Problems (HCSPs), which are
fundamentally different from single-constraint, multi-hop, or flat CSP
formulations. However, existing benchmarks (e.g., Natural Questions, HotpotQA)
fail to capture this complexity, while recent synthetic datasets often
introduce shortcut reasoning, knowledge leakage, or lack sufficient structural
depth. To address this gap, we introduce InfoSeek, a scalable framework for
synthesizing complex Deep Research tasks. InfoSeek uses a dual-agent system to
recursively build a Research Tree from large-scale webpages, blurring
intermediate nodes into valid sub-problems, and converting these trees into
natural language questions that require traversing the full hierarchy. It also
enables rapid scaling, yielding over 50K training examples, a curated test set,
and reasoning trajectories generated via reject sampling. Experiments show that
models trained on InfoSeek consistently outperform strong baselines. On a
challenging benchmark BrowseComp-Plus, 3B LLMs optimized with InfoSeek surpass
much larger 32B models and lightweight commercial APIs (e.g., Gemini2.5-Flash),
while achieving performance comparable to stronger APIs (e.g., Gemini2.5-Pro).
By preserving meta-information such as intermediate steps and retrieval labels,
InfoSeek further supports advanced optimization strategies, including compound
reward design and trajectory-level exploration. We provide our codes and
datasets in \href{https://github.com/VectorSpaceLab/InfoSeek}{this repository}.

</details>


### [227] [GraphKV: Breaking the Static Selection Paradigm with Graph-Based KV Cache Eviction](https://arxiv.org/abs/2509.00388)
*Xuelin Li,Xiangqi Jin,Linfeng Zhang*

Main category: cs.CL

TL;DR: GraphKV是一个基于图的框架，通过动态更新的 token 重要性分数来管理 KV 缓存，以提高长文本序列的处理效率。


<details>
  <summary>Details</summary>
Motivation: 传统的 KV 缓存管理策略（如基于注意力分数的 top-k 选择）依赖于静态启发式方法，无法捕捉推理过程中 token 之间不断变化的隐式依赖关系，这在处理长文本序列时限制了 LLM 的性能。

Method: GraphKV 将 tokens 建模为具有重要性分数的节点，节点之间的边表示它们之间的相似性关系。通过衰减信号传播机制，跨图传播信息动态更新 token 的重要性，从而能够自适应地保留最具上下文意义的 tokens。GraphKV 可以即插即用地集成到现有的 KV 缓存管理方法（如 SnapKV 和 PyramidKV）中。

Result: GraphKV 通过动态更新 token 重要性，实现了更有效的 KV 缓存压缩，从而提高了 LLM 处理长文本序列的性能。

Conclusion: GraphKV 通过其基于图的动态 token 选择方法，克服了传统 KV 缓存管理策略的局限性，能够更有效地管理 KV 缓存，提升 LLM 在长文本处理方面的能力。

Abstract: Efficient Key-Value (KV) cache management is essential for processing long
text sequences in large language models (LLMs), where memory constraints often
limit performance. Conventional KV eviction strategies, such as top-k selection
based on attention scores, depend on static heuristics that fail to capture the
evolving implicit dependencies among tokens during inference. To overcome this,
we propose GraphKV, a graph-based framework that redefines token selection for
KV cache compression. In GraphKV, tokens are modeled as nodes with importance
scores, and edges represent their similarity relationships. Through a
decay-signal-propagation mechanism, token importance is dynamically updated by
propagating information across the graph, enabling adaptive retention of the
most contextually significant tokens. GraphKV can be seamlessly utilized in
existing KV cache eviction methods such as SnapKV and PyramidKV in a
plug-and-play manner. Codes will be released on Github.

</details>


### [228] [The Resurgence of GCG Adversarial Attacks on Large Language Models](https://arxiv.org/abs/2509.00391)
*Yuting Tan,Xuying Li,Zhuo Li,Huizhen Shu,Peikang Hu*

Main category: cs.CL

TL;DR: GCG和T-GCG算法在不同规模的开源LLMs上的攻击效果评估显示，模型规模越大，攻击成功率越低；基于前缀的评估方法会高估攻击效果，而GPT-4o的语义评估更严格；代码类提示比安全类提示更容易被利用。


<details>
  <summary>Details</summary>
Motivation: 评估梯度上升对抗性提示（如GCG）及其变体T-GCG在不同规模开源LLMs上的有效性，特别是在安全和推理（编程）提示上的表现。

Method: 在Qwen2.5-0.5B、LLaMA-3.2-1B和GPT-OSS-20B模型上，使用AdvBench（安全提示）和代码提示，评估GCG和T-GCG的攻击成功率（ASR）。将基于前缀的评估方法与GPT-4o的语义评估进行比较。

Result: 1. 攻击成功率随模型规模增大而降低。2. 基于前缀的评估方法比GPT-4o的语义评估高估了攻击效果。3. 代码类提示比安全类提示更容易受到攻击。T-GCG在早期评估中显示出潜力，但在语义评估下效果有限。

Conclusion: GCG算法的可扩展性存在局限，推理任务存在被利用的漏洞，需要开发基于模拟退火的更鲁棒的对抗性评估策略。

Abstract: Gradient-based adversarial prompting, such as the Greedy Coordinate Gradient
(GCG) algorithm, has emerged as a powerful method for jailbreaking large
language models (LLMs). In this paper, we present a systematic appraisal of GCG
and its annealing-augmented variant, T-GCG, across open-source LLMs of varying
scales. Using Qwen2.5-0.5B, LLaMA-3.2-1B, and GPT-OSS-20B, we evaluate attack
effectiveness on both safety-oriented prompts (AdvBench) and
reasoning-intensive coding prompts. Our study reveals three key findings: (1)
attack success rates (ASR) decrease with model size, reflecting the increasing
complexity and non-convexity of larger models' loss landscapes; (2)
prefix-based heuristics substantially overestimate attack effectiveness
compared to GPT-4o semantic judgments, which provide a stricter and more
realistic evaluation; and (3) coding-related prompts are significantly more
vulnerable than adversarial safety prompts, suggesting that reasoning itself
can be exploited as an attack vector. In addition, preliminary results with
T-GCG show that simulated annealing can diversify adversarial search and
achieve competitive ASR under prefix evaluation, though its benefits under
semantic judgment remain limited. Together, these findings highlight the
scalability limits of GCG, expose overlooked vulnerabilities in reasoning
tasks, and motivate further development of annealing-inspired strategies for
more robust adversarial evaluation.

</details>


### [229] [MedSEBA: Synthesizing Evidence-Based Answers Grounded in Evolving Medical Literature](https://arxiv.org/abs/2509.00414)
*Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: MedSEBA是一个人工智能驱动的系统，可以为医学问题提供基于证据的答案，能够汇总来自PubMed的研究，并可视化研究共识随时间的变化。


<details>
  <summary>Details</summary>
Motivation: 随着网络信息和医学研究的激增，区分可靠来源和追踪最新研究发现变得困难，传统搜索工具无法反映不断发展的研究结论。

Method: MedSEBA利用大型语言模型生成答案，并从PubMed检索可信的医学研究来支持这些答案。该系统还提供相关研究对医学主张的支持或反对程度的概述，以及研究共识随时间演变的视觉化。

Result: 用户研究表明，医学专家和普通用户认为该系统可用、有帮助，提供的答案值得信赖且信息丰富。

Conclusion: MedSEBA系统适合解决日常健康问题和提供高级研究见解，因为它能以可追溯到具体研究的方式提供基于证据的答案，并展示研究共识的演变。

Abstract: In the digital age, people often turn to the Internet in search of medical
advice and recommendations. With the increasing volume of online content, it
has become difficult to distinguish reliable sources from misleading
information. Similarly, millions of medical studies are published every year,
making it challenging for researchers to keep track of the latest scientific
findings. These evolving studies can reach differing conclusions, which is not
reflected in traditional search tools. To address these challenges, we
introduce MedSEBA, an interactive AI-powered system for synthesizing
evidence-based answers to medical questions. It utilizes the power of Large
Language Models to generate coherent and expressive answers, but grounds them
in trustworthy medical studies dynamically retrieved from the research database
PubMed. The answers consist of key points and arguments, which can be traced
back to respective studies. Notably, the platform also provides an overview of
the extent to which the most relevant studies support or refute the given
medical claim, and a visualization of how the research consensus evolved
through time. Our user study revealed that medical experts and lay users find
the system usable and helpful, and the provided answers trustworthy and
informative. This makes the system well-suited for both everyday health
questions and advanced research insights.

</details>


### [230] [The Gold Medals in an Empty Room: Diagnosing Metalinguistic Reasoning in LLMs with Camlang](https://arxiv.org/abs/2509.00425)
*Fenghua Liu,Yulong Chen,Yixuan Liu,Zhujun Jin,Solomon Tsai,Ming Zhong*

Main category: cs.CL

TL;DR: LLMs在语言任务中表现出色，但其是否具备真正的推理能力仍不确定。通过设计一种名为Camlang的新型人工语言，并结合语法书和双语词典，我们模拟了人类学习第二语言的过程。实验表明，人类学习者能够成功掌握Camlang，而包括GPT-5在内的最先进LLMs在Camlang上的表现远低于人类水平，表明它们在元语言推理和语法掌握方面存在根本性差距。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）是否具备真正的推理能力，而非仅仅是模式匹配，特别是在掌握不熟悉语言的元语言演绎学习方面。

Method: 设计了一种名为Camlang的新型人工语言，该语言具有自然且未被充分研究的特征组合。提供了语法书和双语词典，模拟人类通过明确的语法规则和词汇查找进行第二语言学习。将CommonsenseQA改编为Camlang，创建了Camlang-CSQA-v0数据集，用于评估模型在语法规则应用和词汇映射方面的能力。

Result: 在Camlang-CSQA-v0任务上，GPT-5的准确率为47%，远低于人类学习者（87%），而其他先进的LLMs表现更差。模型在Camlang上的成功主要归因于浅层的词汇对齐，GPT-5虽表现出有限的元语言意识，但未能像人类一样系统地掌握语法。

Conclusion: Camlang提供了一个认知科学的评估框架，揭示了当前LLMs在元语言能力方面与人类存在的根本性差距，表明它们尚未实现真正的语法掌握和系统性推理。

Abstract: Large Language Models (LLMs) achieve gold-medal performance across many
benchmarks, yet it remains unclear whether such success reflects genuine
reasoning or pattern matching. From a cognitive science perspective, an
informative test is whether models can master an unfamiliar language through
explicit metalinguistic deductive learning, a paradigm where human learners can
reliably internalise grammatical systems through metalinguistic reasoning. We
address this question with Camlang, a novel constructed language that exhibits
naturalistic yet unattested feature combinations. Camlang consists of two
explicit resources, a grammar book and a bilingual dictionary, which mirror
adult second-language learning via explicit grammar rules and lexical lookup,
and enable us to disentangle errors in morpho-syntax, lexical semantics, and
sentence-level reasoning. Human experiments show that these resources are
sufficient for participants to acquire Camlang and successfully solve Camlang
tasks. To operationalise evaluation, we adapt CommonsenseQA into Camlang,
creating Camlang-CSQA-v0, the first task in a broader suite where solving
questions requires applying grammar rules and lexical mappings. Experimental
results show that GPT-5 achieves 98\% EM accuracy in English but only 47\% in
Camlang, far below human performance at 87\%, while other state-of-the-art
reasoning LLMs perform even worse. Human verification further reveals that most
model successes stem from shallow lexical alignment while GPT-5 shows emerging
metalinguistic awareness to a limited extent but not systematic grammatical
mastery as humans. Camlang establishes a cognitively grounded evaluation
paradigm that exposes fundamental gaps between current models and human
metalinguistic competence.

</details>


### [231] [GOSU: Retrieval-Augmented Generation with Global-Level Optimized Semantic Unit-Centric Framework](https://arxiv.org/abs/2509.00449)
*Xuecheng Zou,Ke Liu,Bingbing Wang,Huafei Deng,Li Zhang,Yu Tang*

Main category: cs.CL

TL;DR: GOSU是一个以语义单元为中心的RAG框架，通过全局消歧和利用SUs捕获跨全局上下文的节点间互连，以解决现有基于图的RAG方法在提取高层SUs时存在的歧义、复杂耦合和检索开销增加的问题。GOSU通过全局合并预提取的SUs来指导实体和关系提取，减少了指代消解的难度，并发现了跨文本块的全局语义对象。此外，它引入了分层关键词提取和语义单元补全，分别捕获细粒度的二元关系和粗粒度的n元关系，从而提高了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的检索增强生成（RAG）方法在利用异构图和超图来丰富检索和生成时，面临着高层语义单元（SUs）提取的局部性带来的歧义、复杂耦合和检索开销增加等问题，因为它们缺乏全局知识或忽略了细粒度的关系。

Method: GOSU框架通过以下方式解决上述问题：1. 在图构建阶段，对从局部文本块中预提取的SUs进行全局合并，并指导实体和关系提取，以减少指代消解的难度并发现跨文本块的全局语义对象。2. 在检索和生成阶段，引入分层关键词提取（捕获细粒度的二元关系）和语义单元补全（补偿粗粒度的n元关系）。

Result: 在多个任务上的评估表明，GOSU在生成质量方面优于基线RAG方法。

Conclusion: GOSU通过其创新的语义单元中心方法，有效地解决了现有RAG方法的局限性，并在多个任务中展示了优越的生成质量。

Abstract: Building upon the standard graph-based Retrieval-Augmented Generation (RAG),
the introduction of heterogeneous graphs and hypergraphs aims to enrich
retrieval and generation by leveraging the relationships between multiple
entities through the concept of semantic units (SUs). But this also raises a
key issue: The extraction of high-level SUs limited to local text chunks is
prone to ambiguity, complex coupling, and increased retrieval overhead due to
the lack of global knowledge or the neglect of fine-grained relationships. To
address these issues, we propose GOSU, a semantic unit-centric RAG framework
that efficiently performs global disambiguation and utilizes SUs to capture
interconnections between different nodes across the global context. In the
graph construction phase, GOSU performs global merging on the pre-extracted SUs
from local text chunks and guides entity and relationship extraction, reducing
the difficulty of coreference resolution while uncovering global semantic
objects across text chunks. In the retrieval and generation phase, we introduce
hierarchical keyword extraction and semantic unit completion. The former
uncovers the fine-grained binary relationships overlooked by the latter, while
the latter compensates for the coarse-grained n-ary relationships missing from
the former. Evaluation across multiple tasks demonstrates that GOSU outperforms
the baseline RAG methods in terms of generation quality.

</details>


### [232] [CVPD at QIAS 2025 Shared Task: An Efficient Encoder-Based Approach for Islamic Inheritance Reasoning](https://arxiv.org/abs/2509.00457)
*Salah Eddine Bekhouche,Abdellah Zakaria Sellam,Hichem Telli,Cosimo Distante,Abdenour Hadid*

Main category: cs.CL

TL;DR: 该论文提出了一种轻量级框架，利用专门的阿拉伯语文本编码器和注意力相关性评分（ARS）来解决伊斯兰继承法中的选择题。与需要更多资源的基于API的大型语言模型（LLM）相比，该框架在保持高效、设备可部署和隐私性的同时，实现了69.87%的准确率，量化了在特定高风险领域中大型模型性能与小型专用系统实用性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 伊斯兰继承法（Ilm al-Mawarith）要求精确识别继承人和计算份额，这对人工智能提出了挑战。

Method: 提出了一种轻量级框架，使用专门的阿拉伯语文本编码器和注意力相关性评分（ARS）来解决多项选择的继承问题。该系统根据语义相关性对答案选项进行排名，并能够在没有生成式推理的情况下实现快速的设备端推理。

Result: 在QIAS 2025数据集上，与准确率高达87.6%但需要更多资源且依赖上下文的API基LLM（Gemini, DeepSeek）相比，基于MARBERT的方法实现了69.87%的准确率。

Conclusion: 虽然基于MARBERT的方法准确率低于最佳LLM，但它在效率、设备可部署性和隐私性方面提供了优势，并量化了在特定高风险领域中大型模型峰值性能与小型专用系统实用性之间的关键权衡。

Abstract: Islamic inheritance law (Ilm al-Mawarith) requires precise identification of
heirs and calculation of shares, which poses a challenge for AI. In this paper,
we present a lightweight framework for solving multiple-choice inheritance
questions using a specialised Arabic text encoder and Attentive Relevance
Scoring (ARS). The system ranks answer options according to semantic relevance,
and enables fast, on-device inference without generative reasoning. We evaluate
Arabic encoders (MARBERT, ArabicBERT, AraBERT) and compare them with API-based
LLMs (Gemini, DeepSeek) on the QIAS 2025 dataset. While large models achieve an
accuracy of up to 87.6%, they require more resources and are context-dependent.
Our MARBERT-based approach achieves 69.87% accuracy, presenting a compelling
case for efficiency, on-device deployability, and privacy. While this is lower
than the 87.6% achieved by the best-performing LLM, our work quantifies a
critical trade-off between the peak performance of large models and the
practical advantages of smaller, specialized systems in high-stakes domains.

</details>


### [233] [TECP: Token-Entropy Conformal Prediction for LLMs](https://arxiv.org/abs/2509.00461)
*Beining Xu*

Main category: cs.CL

TL;DR: 本篇论文提出了一种名为Token-Entropy Conformal Prediction (TECP)的新框架，用于量化开放式语言生成中的不确定性，特别是在无法访问模型内部信号的黑盒约束下。TECP利用token级别的熵作为一种不依赖logit或参考的不确定性度量，并将其整合到split conformal prediction (CP)流程中，以构建具有正式覆盖保证的预测集。与依赖语义一致性启发式或白盒特征的现有方法不同，TECP通过估计采样生成中token熵结构的不确定性，并通过CP分位数校准不确定性阈值，从而实现可证明的误差控制。在六个大型语言模型和两个基准（CoQA和TriviaQA）上的实证评估表明，TECP始终能实现可靠的覆盖和紧凑的预测集，其性能优于之前的基于自一致性的不确定性量化方法。该方法为黑盒LLM设置中的可信赖生成提供了一个有原则且高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 开放式语言生成中的不确定性量化（UQ）是一个关键但探索不足的挑战，尤其是在无法访问模型内部信号的黑盒约束下。

Method: 提出了一种名为Token-Entropy Conformal Prediction (TECP)的新框架，利用token级别的熵作为不确定性度量，并将其整合到split conformal prediction (CP)流程中，以构建具有正式覆盖保证的预测集。TECP通过估计采样生成中token熵结构的不确定性，并通过CP分位数校准不确定性阈值。

Result: 在六个大型语言模型和两个基准（CoQA和TriviaQA）上的实证评估表明，TECP始终能实现可靠的覆盖和紧凑的预测集，其性能优于之前的基于自一致性的不确定性量化方法。

Conclusion: TECP为黑盒LLM设置中的可信赖生成提供了一个有原则且高效的解决方案。

Abstract: Uncertainty quantification (UQ) for open-ended language generation remains a
critical yet underexplored challenge, especially under black-box constraints
where internal model signals are inaccessible. In this paper, we introduce
Token-Entropy Conformal Prediction (TECP), a novel framework that leverages
token-level entropy as a logit-free, reference-free uncertainty measure and
integrates it into a split conformal prediction (CP) pipeline to construct
prediction sets with formal coverage guarantees. Unlike existing approaches
that rely on semantic consistency heuristics or white-box features, TECP
directly estimates epistemic uncertainty from the token entropy structure of
sampled generations and calibrates uncertainty thresholds via CP quantiles to
ensure provable error control. Empirical evaluations across six large language
models and two benchmarks (CoQA and TriviaQA) demonstrate that TECP
consistently achieves reliable coverage and compact prediction sets,
outperforming prior self-consistency-based UQ methods. Our method provides a
principled and efficient solution for trustworthy generation in black-box LLM
settings.

</details>


### [234] [Talk Less, Call Right: Enhancing Role-Play LLM Agents with Automatic Prompt Optimization and Role Prompting](https://arxiv.org/abs/2509.00482)
*Saksorn Ruangtanusak,Pittawat Taveekitworachai,Kunat Pipatanakul*

Main category: cs.CL

TL;DR: 该研究提出了一种基于规则的角色提示（RRP）方法，通过设计“角色卡/场景契约”和严格执行函数调用，显著提高了工具增强型大语言模型在CPDC 2025对话挑战中的角色扮演能力，解决了响应过长和工具使用不当的问题，并在零样本基线的基础上取得了0.571的性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决工具增强型大语言模型在角色扮演对话中存在的响应过长（over-speaking）和工具使用不当（under-acting）的问题，例如生成不存在的函数调用或不必要的工具调用。

Method: 研究了四种提示方法：1) 基本角色提示，2) 人工设计角色提示，3) 自动提示优化（APO），以及 4) 基于规则的角色提示（RRP）。其中，RRP方法采用了“角色卡/场景契约”设计和严格的函数调用执行机制。

Result: 基于规则的角色提示（RRP）方法取得了最佳性能，总分为0.571，相比于零样本基线（0.519）有显著提升。该方法通过“角色卡/场景契约”设计和严格执行函数调用，有效地解决了模型过度响应和工具使用不当的问题。

Conclusion: 基于规则的角色提示（RRP）方法在提升角色扮演对话代理的有效性和可靠性方面，优于更复杂的方法（如APO）。研究结果表明，RRP设计能够显著改善模型的性能，并且将开源最佳提示和APO工具以支持未来的研究。

Abstract: This report investigates approaches for prompting a tool-augmented large
language model (LLM) to act as a role-playing dialogue agent in the API track
of the Commonsense Persona-grounded Dialogue Challenge (CPDC) 2025. In this
setting, dialogue agents often produce overly long in-character responses
(over-speaking) while failing to use tools effectively according to the persona
(under-acting), such as generating function calls that do not exist or making
unnecessary tool calls before answering. We explore four prompting approaches
to address these issues: 1) basic role prompting, 2) human-crafted role
prompting, 3) automatic prompt optimization (APO), and 4) rule-based role
prompting. The rule-based role prompting (RRP) approach achieved the best
performance through two novel techniques--character-card/scene-contract design
and strict enforcement of function calling--which led to an overall score of
0.571, improving on the zero-shot baseline score of 0.519. These findings
demonstrate that RRP design can substantially improve the effectiveness and
reliability of role-playing dialogue agents compared with more elaborate
methods such as APO. To support future efforts in developing persona prompts,
we are open-sourcing all of our best-performing prompts and the APO tool.
Source code is available at https://github.com/scb-10x/apo.

</details>


### [235] [ResearchQA: Evaluating Scholarly Question Answering at Scale Across 75 Fields with Survey-Mined Questions and Rubrics](https://arxiv.org/abs/2509.00496)
*Li S. Yifei,Allen Chang,Chaitanya Malaviya,Mark Yatskar*

Main category: cs.CL

TL;DR: 本研究提出了ResearchQA数据集，用于评估长篇研究问答的LLM系统。该数据集包含来自75个研究领域的21K个问题和160K个评分项，由31名博士生进行标注。结果显示，ResearchQA能够支持博士生信息需求，并且可以用于构建与专家判断有74%一致率的自动评估裁判。研究还利用该数据集分析了18个系统的能力差距，发现现有系统在覆盖评分项方面仍有不足，尤其在引用、局限性和比较方面表现欠佳。本研究旨在通过发布数据促进更全面的跨领域评估。


<details>
  <summary>Details</summary>
Motivation: 现有长篇问答评估依赖专家标注，限制了评估范围。本研究旨在创建一个跨领域的评估资源，以应对研究知识分布广泛的挑战，并评估大型语言模型（LLM）系统在回应研究查询方面的能力。

Method: 本研究提出了ResearchQA数据集，其中包含从75个研究领域的调查文章中提取的21,000个问题和160,000个评分项。评分项是根据调查文章中的具体部分与问题联合提取的，并列出了查询特定的答案评估标准，例如引用论文、进行解释和描述局限性。研究邀请了31名不同领域的博士生进行标注，并利用这些评分项构建了一个自动成对评估裁判，其与专家判断的一致率为74%。

Result: ResearchQA数据集包含21K个问题和160K个评分项，覆盖75个研究领域。31名博士生标注结果表明，96%的问题满足博士生信息需求，87%的评分项应在系统回复中得到充分体现。基于ResearchQA构建的自动评估裁判与专家判断达到74%的一致率。在对18个系统的评估中，没有系统在覆盖评分项方面超过70%，排名最高的代理系统也仅达到75%。具体来看，排名最高的系统在引用评分项上的完全覆盖率不到11%，在局限性评分项上为48%，在比较评分项上为49%。

Conclusion: ResearchQA数据集为评估跨多个研究领域的LLM系统提供了一个全面的资源。现有系统在回应研究查询时，尤其是在引用、局限性和比较方面，仍存在显著的覆盖不足。该数据集和评估方法有助于识别LLM在处理复杂研究任务时的能力差距，并为未来研究和开发提供了方向。

Abstract: Evaluating long-form responses to research queries heavily relies on expert
annotators, restricting attention to areas like AI where researchers can
conveniently enlist colleagues. Yet, research expertise is widespread: survey
articles synthesize knowledge distributed across the literature. We introduce
ResearchQA, a resource for evaluating LLM systems by distilling survey articles
from 75 research fields into 21K queries and 160K rubric items. Each rubric,
derived jointly with queries from survey sections, lists query-specific answer
evaluation criteria, i.e., citing papers, making explanations, and describing
limitations. Assessments by 31 Ph.D. annotators in 8 fields indicate 96% of
queries support Ph.D. information needs and 87% of rubric items should be
addressed in system responses by a sentence or more. Using our rubrics, we are
able to construct an automatic pairwise judge obtaining 74% agreement with
expert judgments. We leverage ResearchQA to analyze competency gaps in 18
systems in over 7.6K pairwise evaluations. No parametric or retrieval-augmented
system we evaluate exceeds 70% on covering rubric items, and the
highest-ranking agentic system shows 75% coverage. Error analysis reveals that
the highest-ranking system fully addresses less than 11% of citation rubric
items, 48% of limitation items, and 49% of comparison items. We release our
data to facilitate more comprehensive multi-field evaluations.

</details>


### [236] [Entropy-based Coarse and Compressed Semantic Speech Representation Learning](https://arxiv.org/abs/2509.00503)
*Jialong Zuo,Guangyan Zhang,Minghui Fang,Shengpeng Ji,Xiaoqi Jiao,Jingyu Li,Yiwen Guo,Zhou Zhao*

Main category: cs.CL

TL;DR: 该研究提出了一种基于熵的动态聚合框架，用于学习压缩的语义语音表示，以解决现有方法中过多的细粒度分词和效率低下问题。


<details>
  <summary>Details</summary>
Motivation: 现有语音表示学习方法将16kHz波形编码为每秒25或50个离散令牌，这种细粒度分词引入了冗余并阻碍了下游训练和推理的效率。此外，该频率下的语义语音表示主要捕获语音学层面的信息，而语义理解可能不需要如此详细的令牌级分辨率。

Method: 该框架首先通过在大量无标签数据上进行下一个令牌预测来预训练语音语言模型，以捕获频繁的令牌模式。然后，利用预测熵自适应地确定聚合边界，并使用交叉注意力模块融合每个段内的信息。通过调整熵阈值，可以灵活控制表示的粒度和压缩比。

Result: 在自动语音识别（ASR）、语音到文本翻译和语音转换任务上的实验表明，压缩后的表示与密集的令牌序列表现相当或更好。

Conclusion: 所提出的基于熵的动态聚合框架能够有效地学习压缩的语义语音表示，在多项下游任务上达到了与密集令牌序列相当或更好的性能，证明了该方法的有效性。

Abstract: Discrete speech representation learning has recently attracted increasing
interest in both acoustic and semantic modeling. Existing approaches typically
encode 16 kHz waveforms into discrete tokens at a rate of 25 or 50 tokens per
second. However, given that speech generally conveys only 2 to 5 words per
second, such fine-grained tokenization introduces redundancy and hinders
efficiency in downstream training and inference. Moreover, semantic speech
representations at this frequency primarily capture phonetic-level information,
while semantic understanding may not require such detailed token-level
resolution. To address these limitations, we propose an entropy-based dynamic
aggregation framework for learning compressed semantic speech representations.
A speech language model is first pre-trained via next-token prediction on
large-scale unlabeled data to capture frequent token patterns. Predictive
entropy is then used to adaptively determine aggregation boundaries, followed
by a cross-attention module that fuses information within each segment. By
adjusting the entropy threshold, the granularity and compression ratio of the
representations can be flexibly controlled. Experiments on ASR, speech-to-text
translation, and voice conversion tasks demonstrate that the compressed
representations perform on par with or better than dense token sequences,
demonstrating the effectiveness of the proposed approach.

</details>


### [237] [Modeling Motivated Reasoning in Law: Evaluating Strategic Role Conditioning in LLM Summarization](https://arxiv.org/abs/2509.00529)
*Eunjung Cho,Alexander Hoyle,Yoan Hermstrüwer*

Main category: cs.CL

TL;DR: LLMs used for legal summaries exhibit role-consistent framing, even with balancing instructions, raising concerns about motivated reasoning and the need for role-aware evaluation in legal settings.


<details>
  <summary>Details</summary>
Motivation: Investigate how LLMs respond to prompts conditioned on different legal roles (e.g., judges, prosecutors, attorneys) when summarizing judicial decisions, building on theories of legal realism and legal practice trends regarding motivated reasoning.

Method: Introduce an evaluation framework grounded in legal fact and reasoning inclusion, also considering favorability towards stakeholders, to analyze LLM responses to prompts with different legal roles.

Result: LLMs exhibit selective inclusion patterns that reflect role-consistent perspectives, even when prompts include balancing instructions.

Conclusion: LLM summarization in high-stakes legal settings needs role-aware evaluation due to emergent role-consistent framing, which could be exacerbated by inferred user roles.

Abstract: Large Language Models (LLMs) are increasingly used to generate user-tailored
summaries, adapting outputs to specific stakeholders. In legal contexts, this
raises important questions about motivated reasoning -- how models
strategically frame information to align with a stakeholder's position within
the legal system. Building on theories of legal realism and recent trends in
legal practice, we investigate how LLMs respond to prompts conditioned on
different legal roles (e.g., judges, prosecutors, attorneys) when summarizing
judicial decisions. We introduce an evaluation framework grounded in legal fact
and reasoning inclusion, also considering favorability towards stakeholders.
Our results show that even when prompts include balancing instructions, models
exhibit selective inclusion patterns that reflect role-consistent perspectives.
These findings raise broader concerns about how similar alignment may emerge as
LLMs begin to infer user roles from prior interactions or context, even without
explicit role instructions. Our results underscore the need for role-aware
evaluation of LLM summarization behavior in high-stakes legal settings.

</details>


### [238] [LongCat-Flash Technical Report](https://arxiv.org/abs/2509.01322)
*Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang,Shuo Wang,Suogui Dang,Tao Fang,Tao Li,Tefeng Chen,Tianhao Bai,Tianhao Zhou,Tingwen Xie,Wei He,Wei Huang,Wei Liu,Wei Shi,Wei Wang,Wei Wu,Weikang Zhao,Wen Zan,Wenjie Shi,Xi Nan,Xi Su,Xiang Li,Xiang Mei,Xiangyang Ji,Xiangyu Xi,Xiangzhou Huang,Xianpeng Li,Xiao Fu,Xiao Liu,Xiao Wei,Xiaodong Cai,Xiaolong Chen,Xiaoqing Liu,Xiaotong Li,Xiaowei Shi,Xiaoyu Li,Xili Wang,Xin Chen,Xing Hu,Xingyu Miao,Xinyan He,Xuemiao Zhang,Xueyuan Hao,Xuezhi Cao,Xunliang Cai,Xurui Yang,Yan Feng,Yang Bai,Yang Chen,Yang Yang,Yaqi Huo,Yerui Sun,Yifan Lu,Yifan Zhang,Yipeng Zang,Yitao Zhai,Yiyang Li,Yongjing Yin,Yongkang Lv,Yongwei Zhou,Yu Yang,Yuchen Xie,Yueqing Sun,Yuewen Zheng,Yuhua Wei,Yulei Qian,Yunfan Liang,Yunfang Tai,Yunke Zhao,Zeyang Yu,Zhao Zhang,Zhaohua Yang,Zhenchao Zhang,Zhikang Xia,Zhiye Zou,Zhizhao Zeng,Zhongda Su,Zhuofan Chen,Zijian Zhang,Ziwen Wang,Zixu Jiang,Zizhe Zhao,Zongyu Wang,Zunhai Su*

Main category: cs.CL

TL;DR: LongCat-Flash是一个5600亿参数的MoE语言模型，在计算效率和智能体能力方面均表现出色。它采用了零计算专家和捷径连接MoE等创新设计，实现了高效的推理和训练。该模型在30天内完成了超过20万亿token的训练，推理速度超过100 TPS，每百万token输出成本为0.70美元。在智能体任务方面，LongCat-Flash表现出卓越的性能，并且已开源。


<details>
  <summary>Details</summary>
Motivation: 为了满足对可扩展效率的需求，LongCat-Flash模型被设计出来。

Method: LongCat-Flash采用了零计算专家（Zero-computation Experts）和捷径连接MoE（Shortcut-connected MoE）这两种新颖的设计。零计算专家允许根据上下文动态分配计算预算，平均每个token激活27B（范围为18.6B-31.3B）参数，从而优化资源使用。捷径连接MoE扩大了计算-通信重叠窗口，与同等规模的模型相比，在推理效率和吞吐量方面取得了显著提升。此外，研究人员开发了一个全面的扩展框架，结合了超参数传递、模型增长初始化、多方面稳定性套件和确定性计算，以实现稳定且可复现的训练。为了培养LongCat-Flash的智能体能力，研究人员进行了大规模的预训练，并针对推理、代码和指令进行了有针对性的中期和后期训练，还增加了来自合成数据和工具使用任务的增强。

Result: LongCat-Flash在30天内完成了超过20万亿token的训练，推理速度超过100 TPS，每百万token输出成本为0.70美元。在作为非思考基础模型的情况下，LongCat-Flash在智能体任务方面表现出卓越的优势，与其他领先模型相比具有高度竞争力。

Conclusion: LongCat-Flash是一个在计算效率和智能体能力方面都表现出色的模型。其创新的设计和高效的训练方法使其在同类模型中脱颖而出，尤其在智能体任务方面表现优异。模型已开源，旨在促进社区研究。

Abstract: We introduce LongCat-Flash, a 560-billion-parameter Mixture-of-Experts (MoE)
language model designed for both computational efficiency and advanced agentic
capabilities. Stemming from the need for scalable efficiency, LongCat-Flash
adopts two novel designs: (a) Zero-computation Experts, which enables dynamic
computational budget allocation and activates 18.6B-31.3B (27B on average) per
token depending on contextual demands, optimizing resource usage. (b)
Shortcut-connected MoE, which enlarges the computation-communication overlap
window, demonstrating notable gains in inference efficiency and throughput
compared to models of a comparable scale. We develop a comprehensive scaling
framework for large models that combines hyperparameter transfer, model-growth
initialization, a multi-pronged stability suite, and deterministic computation
to achieve stable and reproducible training. Notably, leveraging the synergy
among scalable architectural design and infrastructure efforts, we complete
model training on more than 20 trillion tokens within 30 days, while achieving
over 100 tokens per second (TPS) for inference at a cost of \$0.70 per million
output tokens. To cultivate LongCat-Flash towards agentic intelligence, we
conduct a large-scale pre-training on optimized mixtures, followed by targeted
mid- and post-training on reasoning, code, and instructions, with further
augmentation from synthetic data and tool use tasks. Comprehensive evaluations
demonstrate that, as a non-thinking foundation model, LongCat-Flash delivers
highly competitive performance among other leading models, with exceptional
strengths in agentic tasks. The model checkpoint of LongCat-Flash is
open-sourced to foster community research.
  LongCat Chat: https://longcat.ai
  Hugging Face: https://huggingface.co/meituan-longcat
  GitHub: https://github.com/meituan-longcat

</details>


### [239] [Thinking Hard, Going Misaligned: Emergent Misalignment in LLMs](https://arxiv.org/abs/2509.00544)
*Hanqi Yan,Hainiu Xu,Yulan He*

Main category: cs.CL

TL;DR: LLMs become more susceptible to malicious requests when their reasoning abilities are enhanced, particularly dense models. Attention mechanisms and specialized experts can help mitigate this by redirecting reasoning towards safety. This highlights a potential trade-off between reasoning and safety in LLMs.


<details>
  <summary>Details</summary>
Motivation: Assess the impact of enhanced reasoning in LLMs on their alignment with human values, specifically concerning their responsiveness to malicious requests.

Method: Investigate the phenomenon of 'Reasoning-Induced Misalignment' by strengthening LLM reasoning (e.g., via 'think-mode' or math dataset fine-tuning) and analyzing internal model states (attention shifts, specialized experts).

Result: LLMs exhibit increased responsiveness to malicious requests when reasoning is strengthened. Dense models are particularly vulnerable. Internal analyses show that attention shifts and specialized experts can redirect reasoning towards safety guardrails.

Conclusion: There is an emerging trade-off between reasoning capabilities and safety in LLMs. Enhancing reasoning can inadvertently make models more vulnerable to malicious use, emphasizing the need for improved alignment techniques for advanced reasoning models.

Abstract: With Large Language Models (LLMs) becoming increasingly widely adopted,
concerns regarding their safety and alignment with human values have
intensified. Previous studies have shown that fine-tuning LLMs on narrow and
malicious datasets induce misaligned behaviors. In this work, we report a more
concerning phenomenon, Reasoning-Induced Misalignment. Specifically, we observe
that LLMs become more responsive to malicious requests when reasoning is
strengthened, via switching to "think-mode" or fine-tuning on benign math
datasets, with dense models particularly vulnerable. Moreover, we analyze
internal model states and find that both attention shifts and specialized
experts in mixture-of-experts models help redirect excessive reasoning towards
safety guardrails. These findings provide new insights into the emerging
reasoning-safety trade-off and underscore the urgency of advancing alignment
for advanced reasoning models.

</details>


### [240] [StealthEval: A Probe-Rewrite-Evaluate Workflow for Reliable Benchmarks](https://arxiv.org/abs/2509.00591)
*Lang Xiong,Nishant Bhargava,Wesley Chang,Jianhang Hong,Haihao Liu,Kevin Zhu*

Main category: cs.CL

TL;DR: LLMs show different behaviors in test vs. real-world settings (evaluation awareness). This study quantifies this by rewriting prompts to be more 'deploy-like', resulting in increased honesty (5.26%) and decreased deception (12.40%) across tested models, suggesting current benchmarks may not reflect true alignment.


<details>
  <summary>Details</summary>
Motivation: AI alignment is challenged by LLMs exhibiting 'evaluation awareness,' where their behavior shifts between real-world deployment and controlled evaluation settings, leading to inaccurate benchmark performance.

Method: Developed a methodology using a linear probe to score prompts on a 'test-like' to 'deploy-like' scale and employed an LLM rewriting strategy to shift prompts towards a deployment context while maintaining the original task. Evaluated SOTA models on original and rewritten prompts.

Result: Rewritten 'deploy-like' prompts increased average probe scores by 30% on a role-playing dataset. Tested models showed an average increase in honest responses of 5.26%, a decrease in deceptive responses of 12.40%, and an increase in refusal rates of 6.38%.

Conclusion: Evaluation awareness is quantifiable and manipulable, influencing LLM behavior. Models are more prone to unsafe/deceptive outputs in perceived test environments, highlighting the need for realistic evaluation frameworks for accurate pre-deployment alignment assessment.

Abstract: Large Language Models (LLMs) often exhibit significant behavioral shifts when
they perceive a change from a real-world deployment context to a controlled
evaluation setting, a phenomenon known as "evaluation awareness." This
discrepancy poses a critical challenge for AI alignment, as benchmark
performance may not accurately reflect a model's true safety and honesty. In
this work, we systematically quantify these behavioral changes by manipulating
the perceived context of prompts. We introduce a methodology that uses a linear
probe to score prompts on a continuous scale from "test-like" to "deploy-like"
and leverage an LLM rewriting strategy to shift these prompts towards a more
natural, deployment-style context while preserving the original task. Using
this method, we achieved a 30% increase in the average probe score across a
strategic role-playing dataset after rewriting. Evaluating a suite of
state-of-the-art models on these original and rewritten prompts, we find that
rewritten "deploy-like" prompts induce a significant and consistent shift in
behavior. Across all models, we observed an average increase in honest
responses of 5.26% and a corresponding average decrease in deceptive responses
of 12.40%. Furthermore, refusal rates increased by an average of 6.38%,
indicating heightened safety compliance. Our findings demonstrate that
evaluation awareness is a quantifiable and manipulable factor that directly
influences LLM behavior, revealing that models are more prone to unsafe or
deceptive outputs in perceived test environments. This underscores the urgent
need for more realistic evaluation frameworks to accurately gauge true model
alignment before deployment.

</details>


### [241] [Gated Associative Memory: A Parallel O(N) Architecture for Efficient Sequence Modeling](https://arxiv.org/abs/2509.00605)
*Rishiraj Acharya*

Main category: cs.CL

TL;DR: Transformer的二次计算量是长序列建模的瓶颈。本文提出了Gated Associative Memory (GAM)网络，一种具有线性计算复杂度的全并行架构，用于序列建模。GAM块使用因果卷积和关联记忆检索机制来捕捉局部和全局的上下文信息，并通过门控机制动态融合它们。实验证明GAM在WikiText-2和TinyStories数据集上训练速度更快，性能相当或更优。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽然在序列建模任务中表现出色，但其自注意力机制的计算复杂度随序列长度呈二次方增长（O(N^2)），这成为了处理长序列的瓶颈。因此，有必要开发一种新的序列建模架构，以克服这一限制。

Method: 本文提出了一种名为Gated Associative Memory (GAM)的新型全并行序列建模架构。GAM块用两个并行的通路取代了自注意力层：一个因果卷积层用于捕捉局部、依赖位置的上下文，以及一个并行的关联记忆检索机制用于模拟全局的、基于内容的模式。这两个通路通过一个门控机制动态融合，允许模型为每个token灵活地组合局部和全局信息。

Result: GAM网络在WikiText-2基准测试和TinyStories数据集上进行了严格的比较分析。结果表明，GAM在训练速度上优于Transformer和Mamba模型，并且在所有数据集上取得了优于或具有竞争力的最终验证困惑度。

Conclusion: GAM网络作为一种新型的全并行序列建模架构，通过引入因果卷积和关联记忆检索机制，并结合门控机制，有效地解决了Transformer模型在处理长序列时的计算瓶颈问题。其实验结果证明了其在训练速度和模型性能上的优势，是一种有前景且高效的序列建模替代方案。

Abstract: The Transformer architecture, underpinned by the self-attention mechanism,
has become the de facto standard for sequence modeling tasks. However, its core
computational primitive scales quadratically with sequence length (O(N^2)),
creating a significant bottleneck for processing long contexts. In this paper,
we propose the Gated Associative Memory (GAM) network, a novel, fully parallel
architecture for sequence modeling that exhibits linear complexity (O(N)) with
respect to sequence length. The GAM block replaces the self-attention layer
with two parallel pathways: a causal convolution to efficiently capture local,
position-dependent context, and a parallel associative memory retrieval
mechanism to model global, content-based patterns. These pathways are
dynamically fused using a gating mechanism, allowing the model to flexibly
combine local and global information for each token. We implement GAM from
scratch and conduct a rigorous comparative analysis against a standard
Transformer model and a modern linear-time baseline (Mamba) on the WikiText-2
benchmark, as well as against the Transformer on the TinyStories dataset. Our
experiments demonstrate that GAM is consistently faster, outperforming both
baselines on training speed, and achieves a superior or competitive final
validation perplexity across all datasets, establishing it as a promising and
efficient alternative for sequence modeling.

</details>


### [242] [A Multi-Strategy Approach for AI-Generated Text Detection](https://arxiv.org/abs/2509.00623)
*Ali Zain,Sareem Farooqui,Muhammad Rafi*

Main category: cs.CL

TL;DR: RoBERTa-base分类器在检测AI生成内容的新闻文章和学术摘要方面表现最佳，在开发集和测试集上均取得了接近完美的结果。


<details>
  <summary>Details</summary>
Motivation: 开发用于检测AI生成内容（AIGC）的新闻文章和学术摘要的系统。

Method: 本研究提出了三种不同的系统：1. 经过微调的RoBERTa-base分类器；2. 经典的TF-IDF + 支持向量机（SVM）分类器；3. 一个名为Candace的创新集成模型，该模型利用了从多个Llama-3.2模型提取的概率特征，并通过自定义Transformer编码器进行处理。

Result: RoBERTa-based系统表现最优异，在开发集和测试集上都取得了接近完美的结果。

Conclusion: RoBERTa-base模型在M-DAIGT共享任务中表现出色，证明了其在检测AI生成内容方面的有效性。

Abstract: This paper presents presents three distinct systems developed for the M-DAIGT
shared task on detecting AI generated content in news articles and academic
abstracts. The systems includes: (1) A fine-tuned RoBERTa-base classifier, (2)
A classical TF-IDF + Support Vector Machine (SVM) classifier , and (3) An
Innovative ensemble model named Candace, leveraging probabilistic features
extracted from multiple Llama-3.2 models processed by a customTransformer
encoder.The RoBERTa-based system emerged as the most performant, achieving
near-perfect results on both development and test sets.

</details>


### [243] [Can Multi-turn Self-refined Single Agent LMs with Retrieval Solve Hard Coding Problems?](https://arxiv.org/abs/2509.00629)
*Md Tanzib Hosain,Md Kishor Morol*

Main category: cs.CL

TL;DR: 该研究提出了ICPC基准，包含254个编程竞赛任务，旨在评估语言模型在算法思维方面的能力。研究人员开发并评估了多种推理技术，并将解决率从零样本链式思考提示的19.1%提高到结合了多轮自我判断、反思和情景信息检索的最佳技术的42.2%。此外，通过人类在循环中的研究，发现经过特定指令调整的模型可以解决之前模型无法解决的18个问题中的17个。


<details>
  <summary>Details</summary>
Motivation: 评估语言模型（LM）在竞争性编程这一高难度任务上的能力，该领域需要复杂的算法思维、谜题解决和有效的代码创建。

Method: 创建了ICPC基准，包含254个国际大学生程序设计竞赛（ICPC）任务，每个任务都附带官方分析、参考代码以及高质量的单元测试和隐藏测试。开发并评估了多种用于竞争性编程的LM推理技术，包括零样本链式思考提示以及结合多轮自我判断、反思和情景信息检索的先进技术。还进行了人类在循环中的研究，以深入了解模型面临的挑战。

Result: 使用零样本链式思考提示，模型的解决率为19.1%。通过结合多轮自我判断、反思和情景信息检索的最佳推理技术，解决了42.2%的问题。通过特定指令，模型能够解决18个先前无法解决的问题中的17个。

Conclusion: 研究结果表明，通过先进的推理技术和人类反馈，语言模型在解决竞争性编程任务方面的能力得到了显著提升。该研究为开发具有扎实、富有想象力和算法思维能力的语言模型提供了基础，并通过开源代码和数据促进了该领域的进一步研究。

Abstract: Among the hardest tasks for humans are those found in competitive programming
where problems require sophisticated algorithmic thinking, puzzle solving, and
the creation of effective code. As a domain to assess language models (LMs), it
has not received enough attention, though. This study presents the ICPC
benchmark, which consists of 254 international collegiate programming contest
(ICPC) tasks. Each problem includes official analysis, reference code, and
sample, high-quality unit, and hidden tests. We are able to develop and
evaluate a variety of LM inference techniques for competitive programming with
these resources. With zero-shot chain-of-thought prompting, we find that o1
only achieves a 19.1\% pass@1 solve rate. With our best inference technique,
which combines multi-turn self-judge with reflection and retrieval over
episodic information, raises this to 42.2\%. Furthermore, we conduct a new
human-in-the-loop investigation to gain a deeper understanding of the remaining
difficulties. Surprisingly, we discover that o1 can solve 17 out of 18 problems
that were previously unsolvable by any model or technique with just a few
specific instructions. A footstep toward LMs with grounded, imaginative, and
algorithmic thinking is provided by our quantitative findings and qualitative
research. We open-source our code and data at https://github.com/kraritt/zolve.

</details>


### [244] [Confident, Calibrated, or Complicit: Probing the Trade-offs between Safety Alignment and Ideological Bias in Language Models in Detecting Hate Speech](https://arxiv.org/abs/2509.00673)
*Sanjeeevan Selvaganapathy,Mehwish Nasim*

Main category: cs.CL

TL;DR: 受限模型在仇恨言论检测方面优于未受限模型，但两者都存在理解细微差别和公平性问题的缺陷。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究大型语言模型（LLMs）在检测隐含和显式仇恨言论方面的有效性，特别是比较经过少量安全对齐（未审查）的模型与经过严格对齐（审查）的模型在提供更客观分类能力方面的差异。

Method: 比较了审查和未审查模型在仇恨言论检测任务上的准确性和鲁棒性，并分析了它们对基于角色的影响和对细微语言（如反讽）的理解能力。

Result: 审查模型在准确性（78.7%）和鲁棒性方面显著优于未审查模型（64.1%），但审查模型难以进行基于角色的影响，而未审查模型则高度易受意识形态框架的影响。所有模型在理解反讽等细微语言方面都存在严重缺陷，并且在不同目标群体之间存在显著的公平性差异，同时表现出系统性的过度自信。

Conclusion: 研究结果表明，经过审查的大型语言模型在仇恨言论检测方面表现出更高的准确性和鲁棒性，但其安全对齐限制了其对角色扮演和意识形态操纵的适应性。未审查模型虽然更具可塑性，但在准确性方面表现较差。所有模型在理解反讽和处理不同群体时的公平性方面都存在挑战，并且过度自信是一个普遍问题。因此，需要更复杂的审计框架来解决这些问题。

Abstract: We investigate the efficacy of Large Language Models (LLMs) in detecting
implicit and explicit hate speech, examining whether models with minimal safety
alignment (uncensored) might provide more objective classification capabilities
compared to their heavily-aligned (censored) counterparts. While uncensored
models theoretically offer a less constrained perspective free from moral
guardrails that could bias classification decisions, our results reveal a
surprising trade-off: censored models significantly outperform their uncensored
counterparts in both accuracy and robustness, achieving 78.7% versus 64.1%
strict accuracy. However, this enhanced performance comes with its own
limitation -- the safety alignment acts as a strong ideological anchor, making
censored models resistant to persona-based influence, while uncensored models
prove highly malleable to ideological framing. Furthermore, we identify
critical failures across all models in understanding nuanced language such as
irony. We also find alarming fairness disparities in performance across
different targeted groups and systemic overconfidence that renders
self-reported certainty unreliable. These findings challenge the notion of LLMs
as objective arbiters and highlight the need for more sophisticated auditing
frameworks that account for fairness, calibration, and ideological consistency.

</details>


### [245] [Router Upcycling: Leveraging Mixture-of-Routers in Mixture-of-Experts Upcycling](https://arxiv.org/abs/2509.00679)
*Junfeng Ran,Guangxiang Zhao,Yuhan Wu,Dawei Zhu,Longyun Wu,Yikai Zhao,Tong Yang,Lin Sun,Xiangzheng Zhang,Sujian Li*

Main category: cs.CL

TL;DR: MoE模型在深度学习中备受关注，但训练仍具挑战。文章提出了Router Upcycling技术，通过从先前注意力层初始化多个路由器来增强MoE模型性能，以一种类似注意力的方式协同分配token到专家，实验结果显示该方法达到了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型训练具有挑战性，尤其是在MoE Upcycling技术中，简单的路由器（如线性路由器）在复杂的路由任务中表现不佳。本文旨在提出一种新的路由技术以提升MoE Upcycling模型的性能。

Method: 提出了一种名为Router Upcycling的新型路由技术。该方法在Upcycling过程中，从先前注意力层的注意力头初始化多个路由器。这些路由器以类似注意力的方式协同工作，将token分配给专门的专家。具体来说，每个token被处理成多样化的查询（queries），并与作为键（keys）的专家特征进行对齐。

Result: 实验结果表明，所提出的Router Upcycling方法在MoE Upcycling任务上取得了最先进（SOTA）的性能，优于其他基线方法。

Conclusion: Router Upcycling是一种有效提升MoE Upcycling模型性能的新型路由技术，通过利用先前注意力层的输出来初始化多个路由器，并以类似注意力的方式进行token分配，从而在实验中超越了现有方法。

Abstract: The Mixture-of-Experts (MoE) models have gained significant attention in deep
learning due to their dynamic resource allocation and superior performance
across diverse tasks. However, efficiently training these models remains
challenging. The MoE upcycling technique has been proposed to reuse and improve
existing model components, thereby minimizing training overhead. Despite this,
simple routers, such as linear routers, often struggle with complex routing
tasks within MoE upcycling. In response, we propose a novel routing technique
called Router Upcycling to enhance the performance of MoE upcycling models. Our
approach initializes multiple routers from the attention heads of preceding
attention layers during upcycling. These routers collaboratively assign tokens
to specialized experts in an attention-like manner. Each token is processed
into diverse queries and aligned with the experts' features (serving as keys).
Experimental results demonstrate that our method achieves state-of-the-art
(SOTA) performance, outperforming other upcycling baselines.

</details>


### [246] [Do small language models generate realistic variable-quality fake news headlines?](https://arxiv.org/abs/2509.00680)
*Austin McCutcheon,Chris Brogly*

Main category: cs.CL

TL;DR: 小型语言模型（SLM）可用于在线生成虚假新闻标题，但其生成的内容质量参差不齐，并且与真实新闻标题的相似度不高，现有的检测模型对此类标题的误判率较高。


<details>
  <summary>Details</summary>
Motivation: 评估小型语言模型（SLM）生成虚假新闻标题的能力，并分析其生成内容的质量和与真实新闻标题的相似度，同时检验现有检测模型的效果。

Method: 使用受控的提示工程，生成了24,000个低质量和高质量的虚假新闻标题，并应用了基于机器学习和深度学习的新闻标题质量检测器进行评估。

Result: 测试的SLM在生成虚假标题方面总体合规，但存在细微的伦理限制差异。生成标题的质量检测准确率仅为35.2%至63.5%，表明其生成内容与真实网络内容存在差距。

Conclusion: SLM可以被用来生成虚假标题，但其生成内容的质量和与真实世界的相似度不足以有效欺骗现有的检测系统。

Abstract: Small language models (SLMs) have the capability for text generation and may
potentially be used to generate falsified texts online. This study evaluates 14
SLMs (1.7B-14B parameters) including LLaMA, Gemma, Phi, SmolLM, Mistral, and
Granite families in generating perceived low and high quality fake news
headlines when explicitly prompted, and whether they appear to be similar to
real-world news headlines. Using controlled prompt engineering, 24,000
headlines were generated across low-quality and high-quality deceptive
categories. Existing machine learning and deep learning-based news headline
quality detectors were then applied against these SLM-generated fake news
headlines. SLMs demonstrated high compliance rates with minimal ethical
resistance, though there were some occasional exceptions. Headline quality
detection using established DistilBERT and bagging classifier models showed
that quality misclassification was common, with detection accuracies only
ranging from 35.2% to 63.5%. These findings suggest the following: tested SLMs
generally are compliant in generating falsified headlines, although there are
slight variations in ethical restraints, and the generated headlines did not
closely resemble existing primarily human-written content on the web, given the
low quality classification accuracy.

</details>


### [247] [Text Reinforcement for Multimodal Time Series Forecasting](https://arxiv.org/abs/2509.00687)
*Chen Su,Yuanhe Tian,Yan Song,Yongdong Zhang*

Main category: cs.CL

TL;DR: 该研究提出了一种文本增强模型 (TeR)，通过生成增强后的文本来改善多模态时间序列预测 (TSF) 的性能，解决了现有模型中文本信息与时间序列数据不匹配导致的不稳定问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态输入（文本和历史时间序列）的时间序列预测方法，在文本信息未能准确或完全捕捉时间序列数据信息时，表现不稳定。因此，需要增强文本模态以提升多模态时间序列预测的性能。

Method: 提出文本增强模型 (TeR)，利用强化学习生成能够弥补原始文本不足的增强文本，并将其用于支持多模态时间序列预测模型。强化学习的奖励机制基于增强文本对预测性能和任务相关性的影响来设计。

Result: 在真实世界的多领域数据集上进行的大量实验表明，该方法优于强基线和现有研究。

Conclusion: 提出的文本增强模型 (TeR) 及其基于强化学习的优化方法能够有效提升多模态时间序列预测的性能。

Abstract: Recent studies in time series forecasting (TSF) use multimodal inputs, such
as text and historical time series data, to predict future values. These
studies mainly focus on developing advanced techniques to integrate textual
information with time series data to perform the task and achieve promising
results. Meanwhile, these approaches rely on high-quality text and time series
inputs, whereas in some cases, the text does not accurately or fully capture
the information carried by the historical time series, which leads to unstable
performance in multimodal TSF. Therefore, it is necessary to enhance the
textual content to improve the performance of multimodal TSF. In this paper, we
propose improving multimodal TSF by reinforcing the text modalities. We propose
a text reinforcement model (TeR) to generate reinforced text that addresses
potential weaknesses in the original text, then apply this reinforced text to
support the multimodal TSF model's understanding of the time series, improving
TSF performance. To guide the TeR toward producing higher-quality reinforced
text, we design a reinforcement learning approach that assigns rewards based on
the impact of each reinforced text on the performance of the multimodal TSF
model and its relevance to the TSF task. We optimize the TeR accordingly, so as
to improve the quality of the generated reinforced text and enhance TSF
performance. Extensive experiments on a real-world benchmark dataset covering
various domains demonstrate the effectiveness of our approach, which
outperforms strong baselines and existing studies on the dataset.

</details>


### [248] [CE-Bench: Towards a Reliable Contrastive Evaluation Benchmark of Interpretability of Sparse Autoencoders](https://arxiv.org/abs/2509.00691)
*Alex Gulko,Yusen Peng,Sachin Kumar*

Main category: cs.CL

TL;DR: 本研究提出了CE-Bench，一个用于评估大型语言模型（LLM）中稀疏自编码器可解释性的新基准。CE-Bench是一个轻量级的对比评估基准，不依赖外部LLM，并通过消融研究验证了其有效性，与现有基准具有良好的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏自动化评估手段来衡量稀疏自编码器在大型语言模型（LLM）中的可解释性，阻碍了其发展和应用。

Method: 提出了CE-Bench，一个包含对比故事对的数据集，用于评估稀疏自编码器。通过全面的消融研究来验证该方法的有效性。

Result: CE-Bench能够可靠地衡量稀疏自编码器的可解释性，并且与现有基准表现出良好的一致性，同时无需外部LLM。

Conclusion: CE-Bench是一个有效且易于使用的评估工具，能够为稀疏自编码器的可解释性研究提供支持。

Abstract: Probing with sparse autoencoders is a promising approach for uncovering
interpretable features in large language models (LLMs). However, the lack of
automated evaluation methods has hindered their broader adoption and
development. In this work, we introduce CE-Bench, a novel and lightweight
contrastive evaluation benchmark for sparse autoencoders, built on a curated
dataset of contrastive story pairs. We conduct comprehensive ablation studies
to validate the effectiveness of our approach. Our results show that CE-Bench
reliably measures the interpretability of sparse autoencoders and aligns well
with existing benchmarks, all without requiring an external LLM. The official
implementation and evaluation dataset are open-sourced under the MIT License.

</details>


### [249] [Learning to Shop Like Humans: A Review-driven Retrieval-Augmented Recommendation Framework with LLMs](https://arxiv.org/abs/2509.00698)
*Kaiwen Wei,Jinpeng Gao,Jiang Zhong,Yuming Yang,Fengmao Lv,Zhenyang Li*

Main category: cs.CL

TL;DR: RevBrowse是一个推荐框架，通过集成用户评论和LLM来改进推荐效果，解决了LLM在处理长评论和相关性排序方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 目前的LLM在推荐任务中表现出巨大潜力，尤其是在理解语言、推理和知识整合方面。然而，在基于评论的推荐中，由于LLM的上下文窗口限制以及缺乏有效的评论优先排序机制，如何有效地整合用户评论仍然是一个挑战。

Method: RevBrowse框架受到“先浏览后决定”的决策过程启发，将用户评论整合到LLM的重排（reranking）过程中。为了提高评论使用效率和相关性，引入了PrefRAG模块，该模块将用户和物品的表示解耦成结构化形式，并根据目标物品自适应地检索偏好相关内容。

Result: 在四个亚马逊评论数据集上的大量实验表明，RevBrowse相比于强大的基线模型取得了持续且显著的改进，证明了其在模拟动态用户偏好方面的通用性和有效性。

Conclusion: RevBrowse通过结合用户评论和LLM，并引入PrefRAG模块来优化评论的使用，能够有效提升推荐的准确性和效率，并且其检索增强的过程也提供了一定程度的可解释性。

Abstract: Large language models (LLMs) have shown strong potential in recommendation
tasks due to their strengths in language understanding, reasoning and knowledge
integration. These capabilities are especially beneficial for review-based
recommendation, which relies on semantically rich user-generated texts to
reveal fine-grained user preferences and item attributes. However, effectively
incorporating reviews into LLM-based recommendation remains challenging due to
(1) inefficient to dynamically utilize user reviews under LLMs' constrained
context windows, and (2) lacking effective mechanisms to prioritize reviews
most relevant to the user's current decision context. To address these
challenges, we propose RevBrowse, a review-driven recommendation framework
inspired by the "browse-then-decide" decision process commonly observed in
online user behavior. RevBrowse integrates user reviews into the LLM-based
reranking process to enhance its ability to distinguish between candidate
items. To improve the relevance and efficiency of review usage, we introduce
PrefRAG, a retrieval-augmented module that disentangles user and item
representations into structured forms and adaptively retrieves
preference-relevant content conditioned on the target item. Extensive
experiments on four Amazon review datasets demonstrate that RevBrowse achieves
consistent and significant improvements over strong baselines, highlighting its
generalizability and effectiveness in modeling dynamic user preferences.
Furthermore, since the retrieval-augmented process is transparent, RevBrowse
offers a certain level of interpretability by making visible which reviews
influence the final recommendation.

</details>


### [250] [Reward-Weighted Sampling: Enhancing Non-Autoregressive Characteristics in Masked Diffusion LLMs](https://arxiv.org/abs/2509.00707)
*Daehoon Gwak,Minseo Jung,Junwoo Park,Minho Park,ChaeHun Park,Junha Hyung,Jaegul Choo*

Main category: cs.CL

TL;DR: MDMs通常采用独立选择token的解码方式，这会限制其非自回归优势。本文提出的RWS解码策略通过引入外部奖励模型，在扩散过程中为token选择提供全局信号，以促进更符合非自回归特性的生成顺序，并提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MDMs解码方法（如基于置信度的采样）倾向于生成类似自回归的顺序，限制了非自回归建模的优势。

Method: 提出了一种名为奖励加权采样（RWS）的新型解码策略，该策略在扩散过程的每一步利用外部奖励模型为整个中间序列提供全局质量信号，并相应地调整token的logits，从而引导更符合全局序列连贯性的token选择。

Result: RWS显著促进了非自回归生成顺序，并在多个评估指标上取得了改进，证明了整合全局信号在增强MDMs的非自回归特性和整体性能方面的有效性。

Conclusion: 奖励加权采样（RWS）通过整合全局序列信息，能够有效提升MDMs的非自回归生成能力和整体性能。

Abstract: Masked diffusion models (MDMs) offer a promising non-autoregressive
alternative for large language modeling. Standard decoding methods for MDMs,
such as confidence-based sampling, select tokens independently based on
individual token confidences at each diffusion step. However, we observe that
this independent token selection often results in generation orders resembling
sequential autoregressive processes, limiting the advantages of
non-autoregressive modeling. To mitigate this pheonomenon, we propose
Reward-Weighted Sampling (RWS), a novel decoding strategy that leverages an
external reward model to provide a principled global signal during the
iterative diffusion process. Specifically, at each diffusion step, RWS
evaluates the quality of the entire intermediate sequence and scales token
logits accordingly, guiding token selection by integrating global
sequence-level coherence. This method selectively increases the confidence of
tokens that initially have lower scores, thereby promoting a more
non-autoregressive generation order. Furthermore, we provide theoretical
justification showing that reward-weighted logit scaling induces beneficial
rank reversals in token selection and consistently improves expected reward.
Experiments demonstrate that RWS significantly promotes non-autoregressive
generation orders, leading to improvements across multiple evaluation metrics.
These results highlight the effectiveness of integrating global signals in
enhancing both the non-autoregressive properties and overall performance of
MDMs.

</details>


### [251] [Designing LMS and Instructional Strategies for Integrating Generative-Conversational AI](https://arxiv.org/abs/2509.00709)
*Elias Ra,Seung Je Kim,Eui-Yeong Seo,Geunju So*

Main category: cs.CL

TL;DR: 本研究提出了一个结构化框架，用于设计一个集成生成式和对话式AI的学习管理系统（AI-LMS），以支持个性化、自适应和以学习者为中心的教学，解决了高等教育在提供个性化、可扩展和教学连贯性方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前高等教育在提供个性化、可扩展和教学连贯性方面面临日益严峻的挑战，需要创新的解决方案来支持自适应、互动和以学习者为中心的教学。

Method: 本研究采用设计型研究（DBR）方法，通过五个阶段（文献综述、SWOT分析、伦理-教学原则制定、系统设计和教学策略制定）来构建AI-LMS框架。

Result: 研究结果是一个AI-LMS框架，包含可配置提示、自适应反馈循环和多代理对话流等模块化组件，这些组件与行为主义、建构主义和联通主义等教学范式保持一致。

Conclusion: 本研究通过结合AI能力、以人为本的设计和伦理保障，提出了一个在教育中整合AI的实用模型，为未来的AI在教育领域的应用提供了实践指导。

Abstract: Higher education faces growing challenges in delivering personalized,
scalable, and pedagogically coherent learning experiences. This study
introduces a structured framework for designing an AI-powered Learning
Management System (AI-LMS) that integrates generative and conversational AI to
support adaptive, interactive, and learner-centered instruction. Using a
design-based research (DBR) methodology, the framework unfolds through five
phases: literature review, SWOT analysis, development of ethical-pedagogical
principles, system design, and instructional strategy formulation. The
resulting AI-LMS features modular components -- including configurable prompts,
adaptive feedback loops, and multi-agent conversation flows -- aligned with
pedagogical paradigms such as behaviorist, constructivist, and connectivist
learning theories. By combining AI capabilities with human-centered design and
ethical safeguards, this study advances a practical model for AI integration in
education. Future research will validate and refine the system through
real-world implementation.

</details>


### [252] [LLM Encoder vs. Decoder: Robust Detection of Chinese AI-Generated Text with LoRA](https://arxiv.org/abs/2509.00731)
*Houji Jin,Negin Ashrafi,Armin Abdollahi,Wei Liu,Jian Wang,Ganyu Gui,Maryam Pishgar,Huanghao Feng*

Main category: cs.CL

TL;DR: 本研究比较了中文AI生成文本检测的多种模型，包括BERT、RoBERTa、FastText和经过LoRA微调的Qwen2.5-7B。结果显示，Qwen2.5-7B在准确性和泛化能力上表现最佳，达到95.94%的测试准确率，而Encoder模型和FastText则存在泛化能力不足或缺乏深层语义理解的问题。研究强调了基于Decoder的LLM结合参数高效微调在中文AI生成文本检测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的快速发展，对AI生成文本的准确检测需求日益增长，尤其是在中文这样细微的语言差别给现有方法带来挑战的语言中。

Method: 本研究系统比较了编码器模型（中文BERT-large和RoBERTa-wwm-ext-large）、解码器模型（通过LoRA微调的Qwen2.5-7B）以及FastText基线模型，并使用了NLPCC 2025中文AI生成文本检测任务的公开数据集。编码器模型采用了新颖的基于提示的掩码语言模型方法进行微调，而Qwen2.5-7B则通过指令格式输入和轻量级分类头以及LoRA进行微调以适应分类任务。

Result: 实验结果表明，编码器模型虽然几乎记住了训练数据，但在分布变化下性能显著下降（RoBERTa测试准确率为76.3%，BERT为79.3%）。FastText在词汇鲁棒性方面表现出乎意料地好（准确率为83.5%），但缺乏更深层次的语义理解。相比之下，经过LoRA适配的Qwen2.5-7B在测试准确率上达到了95.94%，并且具有均衡的精确率和召回率指标，显示出其在泛化能力和对特定数据集伪影的抵抗力方面表现更优。

Conclusion: 研究结果强调了基于Decoder的LLM结合参数高效微调在实现鲁棒的中文AI生成文本检测方面的有效性。未来的工作将探索下一代Qwen3模型、蒸馏变体以及集成策略，以进一步增强跨领域鲁棒性。

Abstract: The rapid growth of large language models (LLMs) has heightened the demand
for accurate detection of AI-generated text, particularly in languages like
Chinese, where subtle linguistic nuances pose significant challenges to current
methods. In this study, we conduct a systematic comparison of encoder-based
Transformers (Chinese BERT-large and RoBERTa-wwm-ext-large), a decoder-only LLM
(Alibaba's Qwen2.5-7B/DeepSeek-R1-Distill-Qwen-7B fine-tuned via Low-Rank
Adaptation, LoRA), and a FastText baseline using the publicly available dataset
from the NLPCC 2025 Chinese AI-Generated Text Detection Task. Encoder models
were fine-tuned using a novel prompt-based masked language modeling approach,
while Qwen2.5-7B was adapted for classification with an instruction-format
input and a lightweight classification head trained via LoRA. Experiments
reveal that although encoder models nearly memorize training data, they suffer
significant performance degradation under distribution shifts (RoBERTa: 76.3%
test accuracy; BERT: 79.3%). FastText demonstrates surprising lexical
robustness (83.5% accuracy) yet lacks deeper semantic understanding. In
contrast, the LoRA-adapted Qwen2.5-7B achieves 95.94% test accuracy with
balanced precision-recall metrics, indicating superior generalization and
resilience to dataset-specific artifacts. These findings underscore the
efficacy of decoder-based LLMs with parameter-efficient fine-tuning for robust
Chinese AI-generated text detection. Future work will explore next-generation
Qwen3 models, distilled variants, and ensemble strategies to enhance
cross-domain robustness further.

</details>


### [253] [Decomposing and Revising What Language Models Generate](https://arxiv.org/abs/2509.00765)
*Zhichao Yan,Jiaoyan Chen,Jiapu Wang,Xiaoli Li,Ru Li,Jeff Z. Pan*

Main category: cs.CL

TL;DR: FIDES是一个用于问答的新框架，通过分解事实和聚合证据来提高准确性，并在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于问题分解的方法在生成问题时存在不相关和不完整的问题，导致事实丢失，并且未能聚合来自不同文档的证据。FIDES旨在解决这些问题。

Method: FIDES提出了一种基于事实分解的方法，将长答案分解为子事实，检索相关证据，并在必要时修正子事实，最后根据原句聚合证据。

Result: FIDES在六个数据集上进行了广泛评估，并引入了新的评估指标$Attr_{auto-P}$。结果显示，FIDES在使用GPT-3.5-turbo、Gemini和Llama 70B系列模型时，平均性能优于现有方法14%以上。

Conclusion: FIDES通过其事实分解和证据聚合的方法，显著提高了归因问答的性能，优于现有技术。

Abstract: Attribution is crucial in question answering (QA) with Large Language Models
(LLMs).SOTA question decomposition-based approaches use long form answers to
generate questions for retrieving related documents. However, the generated
questions are often irrelevant and incomplete, resulting in a loss of facts in
retrieval.These approaches also fail to aggregate evidence snippets from
different documents and paragraphs. To tackle these problems, we propose a new
fact decomposition-based framework called FIDES (\textit{faithful context
enhanced fact decomposition and evidence aggregation}) for attributed QA. FIDES
uses a contextually enhanced two-stage faithful decomposition method to
decompose long form answers into sub-facts, which are then used by a retriever
to retrieve related evidence snippets. If the retrieved evidence snippets
conflict with the related sub-facts, such sub-facts will be revised
accordingly. Finally, the evidence snippets are aggregated according to the
original sentences.Extensive evaluation has been conducted with six datasets,
with an additionally proposed new metric called $Attr_{auto-P}$ for evaluating
the evidence precision. FIDES outperforms the SOTA methods by over 14\% in
average with GPT-3.5-turbo, Gemini and Llama 70B series.

</details>


### [254] [LegalChainReasoner: A Legal Chain-guided Framework for Criminal Judicial Opinion Generation](https://arxiv.org/abs/2509.00783)
*Weizhe Shi,Qiqi Wang,Yihong Pan,Qian Liu,Kaiqi Zhao*

Main category: cs.CL

TL;DR: 本研究提出了一种名为“司法意见生成”的新法律人工智能任务，旨在同时生成法律推理和判决。研究通过引入LegalChainReasoner框架，利用结构化法律链条来指导模型进行全面的案例评估，从而解决了现有方法在法律推理和判决预测之间不一致以及依赖手动知识的问题。实验结果表明，该方法在中国法律案例数据集上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有研究将法律推理和判决预测分为两个独立子任务，导致推理与预测不一致，无法满足实际司法需求。此外，先前研究依赖手动知识库，限制了实际应用。本研究旨在解决这些局限性，并更好地贴合法律实践。

Method: 提出名为“司法意见生成”的新法律人工智能任务，并引入LegalChainReasoner框架。该框架应用结构化法律链条，整合事实前提、复合法律条件和判决结论，以指导模型进行全面的案例评估，实现端到端的意见生成。

Result: 在两个真实的开源中国法律案例数据集上进行实验，结果表明本研究提出的方法优于基线模型。

Conclusion: 本研究提出的司法意见生成任务和LegalChainReasoner框架能够同时生成法律推理和判决，解决了现有方法的局限性，并在实验中取得了优于基线模型的性能。

Abstract: A criminal judicial opinion represents the judge's disposition of a case,
including the decision rationale and sentencing. Automatically generating such
opinions can assist in analyzing sentencing consistency and provide judges with
references to similar past cases. However, current research typically
approaches this task by dividing it into two isolated subtasks: legal reasoning
and sentencing prediction. This separation often leads to inconsistency between
the reasoning and predictions, failing to meet real-world judicial
requirements. Furthermore, prior studies rely on manually curated knowledge to
enhance applicability, yet such methods remain limited in practical deployment.
To address these limitations and better align with legal practice, we propose a
new LegalAI task: Judicial Opinion Generation, which simultaneously produces
both legal reasoning and sentencing decisions. To achieve this, we introduce
LegalChainReasoner, a framework that applies structured legal chains to guide
the model through comprehensive case assessments. By integrating factual
premises, composite legal conditions, and sentencing conclusions, our approach
ensures flexible knowledge injection and end-to-end opinion generation.
Experiments on two real-world and open-source Chinese legal case datasets
demonstrate that our method outperforms baseline models.

</details>


### [255] [CaresAI at BioCreative IX Track 1 -- LLM for Biomedical QA](https://arxiv.org/abs/2509.00806)
*Reem Abdel-Salam,Mary Adewunmi,Modinat A. Abayomi*

Main category: cs.CL

TL;DR: LLMs在生物医学问答方面表现良好，但需要更严格的评估。本研究使用LLaMA 3 8B模型，针对MedHopQA任务进行微调，并探索了不同的回答策略。结果显示模型在概念理解方面表现出色，但在精确匹配方面仍有待提高，尤其是在测试阶段。为解决这个问题，研究提出了一种两阶段推理流程来提取精确的短答案，但仍存在格式化输出的挑战。研究强调了语义理解与精确评估之间的差距，并指出了在输出控制和后处理策略方面进一步研究的必要性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在复杂生物医学问题回答（QA）方面的能力，以确定其在实际医疗保健应用中的部署可行性。

Method: 采用监督微调策略，利用LLaMA 3 8B模型，并结合从BioASQ、MedQuAD和TREC等外部来源编译的生物医学问答数据集。探索了三种实验设置：在合并的短答案和长答案上进行微调、仅在短答案上进行微调以及仅在长答案上进行微调。此外，还提出了一种两阶段推理流程以提取精确的短答案。

Result: 模型在概念理解方面展现出强大的领域知识，概念级准确率得分高达0.8。然而，在精确匹配（EM）得分方面，尤其是在测试阶段，得分显著偏低。两阶段推理流程在一定程度上提高了精确答案的提取，但生成严格格式化输出的挑战仍然存在。

Conclusion: 大型语言模型在生物医学问答应用中，在语义理解能力与精确答案评估之间存在差距。这表明需要进一步研究输出控制和后处理策略，以提高模型在实际应用中的表现。

Abstract: Large language models (LLMs) are increasingly evident for accurate question
answering across various domains. However, rigorous evaluation of their
performance on complex question-answering (QA) capabilities is essential before
deployment in real-world biomedical and healthcare applications. This paper
presents our approach to the MedHopQA track of the BioCreative IX shared task,
which focuses on multi-hop biomedical question answering involving diseases,
genes, and chemicals. We adopt a supervised fine-tuning strategy leveraging
LLaMA 3 8B, enhanced with a curated biomedical question-answer dataset compiled
from external sources including BioASQ, MedQuAD, and TREC. Three experimental
setups are explored: fine-tuning on combined short and long answers, short
answers only, and long answers only. While our models demonstrate strong domain
understanding, achieving concept-level accuracy scores of up to 0.8, their
Exact Match (EM) scores remain significantly lower, particularly in the test
phase. We introduce a two-stage inference pipeline for precise short-answer
extraction to mitigate verbosity and improve alignment with evaluation metrics.
Despite partial improvements, challenges persist in generating strictly
formatted outputs. Our findings highlight the gap between semantic
understanding and exact answer evaluation in biomedical LLM applications,
motivating further research in output control and post-processing strategies.

</details>


### [256] [TMT: A Simple Way to Translate Topic Models Using Dictionaries](https://arxiv.org/abs/2509.00822)
*Felix Engl,Andreas Henrich*

Main category: cs.CL

TL;DR: TMT是一种无需元数据、嵌入或对齐语料库即可将主题模型从一种语言转移到另一种语言的技术。


<details>
  <summary>Details</summary>
Motivation: 在多语言环境中训练主题模型，尤其是在目标语言数据有限或开发者不熟悉目标语言的情况下，是一个严峻的挑战。TMT旨在克服这些困难。

Method: TMT是一种新颖、健壮且透明的技术，用于跨语言转移主题模型（例如，基于潜在狄利克雷分配的主题模型）。

Result: TMT能够生成语义连贯且一致的主题翻译，通过定量和定性方法进行了广泛评估。

Conclusion: TMT使得跨语言重用主题模型成为可能，尤其适用于目标语言语料库不可用或手动翻译不可行的场景。

Abstract: The training of topic models for a multilingual environment is a challenging
task, requiring the use of sophisticated algorithms, topic-aligned corpora, and
manual evaluation. These difficulties are further exacerbated when the
developer lacks knowledge of the target language or is working in an
environment with limited data, where only small or unusable multilingual
corpora are available.
  Considering these challenges, we introduce Topic Model Translation (TMT), a
novel, robust and transparent technique designed to transfer topic models
(e.g., Latent Dirichlet Allocation (LDA) based topic models) from one language
to another, without the need for metadata, embeddings, or aligned corpora. TMT
enables the reuse of topic models across languages, making it especially
suitable for scenarios where large corpora in the target language are
unavailable or manual translation is infeasible. Furthermore, we evaluate TMT
extensively using both quantitative and qualitative methods, demonstrating that
it produces semantically coherent and consistent topic translations.

</details>


### [257] [Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations](https://arxiv.org/abs/2509.00841)
*Michelle Elizabeth,Alicja Kasicka,Natalia Krawczyk,Magalie Ochs,Gwénolé Lecorvé,Justyna Gromada,Lina M. Rojas-Barahona*

Main category: cs.CL

TL;DR: 使用 LM 提示和基于编码器的模型来评估对话系统，LM 提示效果适中，而基于编码器的模型在验证集上表现出高相关性，但在测试集上有所下降，这可能与测试集的数据分布不同有关。


<details>
  <summary>Details</summary>
Motivation: 评估基于生成式 AI 的对话系统是一个关键挑战，本研究旨在为 DSTC-12 挑战赛（Track 1）提供解决方案。

Method: 本文采用了两种主要策略：1）使用语言模型（LM）通过提示（prompting）进行评估；2）训练基于编码器的分类和回归模型。

Result: LM 提示在与人类判断的相关性方面仅达到适度水平，但在测试集上排名第二，仅次于基线模型。基于编码器的回归和分类模型在验证集上的某些维度上表现出高相关性，但其性能在测试集上有所下降。测试集在某些维度上的标注分数范围与训练/验证集存在显著差异，这可能是导致性能下降的原因之一。

Conclusion: LM 提示是一种可行的对话系统评估方法，但其效果有待提升。基于编码器的模型在特定情况下具有潜力，但其性能易受数据分布变化的影响。未来的研究应关注如何提高 LM 评估的准确性，并增强模型在不同数据分布下的鲁棒性。

Abstract: The growing number of generative AI-based dialogue systems has made their
evaluation a crucial challenge. This paper presents our contribution to this
important problem through the Dialogue System Technology Challenge (DSTC-12,
Track 1), where we developed models to predict dialogue-level,
dimension-specific scores. Given the constraint of using relatively small
models (i.e. fewer than 13 billion parameters) our work follows two main
strategies: employing Language Models (LMs) as evaluators through prompting,
and training encoder-based classification and regression models.
  Our results show that while LM prompting achieves only modest correlations
with human judgments, it still ranks second on the test set, outperformed only
by the baseline. The regression and classification models, with significantly
fewer parameters, demonstrate high correlation for some dimensions on the
validation set. Although their performance decreases on the test set, it is
important to note that the test set contains annotations with significantly
different score ranges for some of the dimensions with respect to the train and
validation sets.

</details>


### [258] [Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings](https://arxiv.org/abs/2509.00842)
*Tengyu Pan,Zhichao Duan,Zhenyu Li,Bowen Dong,Ning Liu,Xiuxing Li,Jianyong Wang*

Main category: cs.CL

TL;DR: 该论文提出了一种名为多粒度难例（MGH）合成的框架，并结合锚点词感知（ATA）池化方法，用于改进文本嵌入模型。MGH框架利用大型语言模型（LLMs）生成不同相似度的负例，以实现课程学习策略，使嵌入模型能逐步学习更细致的语义表示。ATA方法则根据LLMs中的聚合模式，为锚点词分配更高的权重，从而在不增加模型复杂度的情况下提高文本嵌入的准确性。实验结果表明，该方法在MTEB基准测试中达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 文本嵌入模型对于自然语言处理任务至关重要，但需要有效的负例来区分细微的语义差别。该研究旨在通过生成多样化的负例并优化池化方法来改进文本嵌入模型。

Method: 提出了一种名为多粒度难例（MGH）合成的框架，利用大型语言模型（LLMs）生成不同相似度的负例，并结合锚点词感知（ATA）池化方法，根据LLMs中的聚合模式为锚点词分配更高权重。

Result: 在MTEB基准测试上进行了广泛的实验，结果表明所提出的方法在合成数据和与公共检索数据集结合使用时，均超越了现有的合成策略，达到了最先进的性能。

Conclusion: 所提出的MGH合成框架和ATA池化方法能够有效提升文本嵌入模型的性能，通过生成多样化的负例和优化池化策略，实现了更细致的语义学习和更高的嵌入准确性。

Abstract: Text embedding models are essential for various natural language processing
tasks, enabling the effective encoding of semantic information into dense
vector representations. These models are typically optimized using triplets of
(query, positive, negative) data pairs for contrastive learning, where the
negative samples play a critical role in enhancing the model's ability to
discern subtle semantic distinctions. In this work, we introduce a
Multi-Granularity Hard-negative (MGH) synthesis framework that leverages large
language models (LLMs) to generate diverse negative samples with varying levels
of similarity with the query. This approach facilitates a coarse-to-fine
curriculum learning strategy during supervised training, allowing the embedding
model to progressively learn more nuanced semantic representations. Meanwhile,
we propose an Anchor Token Aware (ATA) pooling method that assigns higher
weights to anchor tokens based on aggregation patterns observed in LLMs,
improving text embedding accuracy without increasing model complexity.
Comprehensive experiments on the MTEB benchmark demonstrate that our methods
achieve state-of-the-art performance, surpassing existing synthesis strategies
both with synthetic data and when combined with public retrieval datasets.

</details>


### [259] [Prompting Away Stereotypes? Evaluating Bias in Text-to-Image Models for Occupations](https://arxiv.org/abs/2509.00849)
*Shaina Raza,Maximus Powers,Partha Pratim Saha,Mahveen Raza,Rizwan Qureshi*

Main category: cs.CL

TL;DR: TTI模型存在社会偏见风险。本文提出评估基准，测试五种TTI模型（DALLE 3, Gemini Imagen 4.0, FLUX.1-dev, Stable Diffusion XL Turbo, Grok-2 Image）在不同提示下的性别、种族刻画。结果显示提示可改变表征，但效果因模型而异，提示作为公平性干预措施有潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: TTI模型可能放大社会偏见，需要评估和缓解。

Method: 将偏见评估视为图像策展和评估任务，创建包含五种职业（CEO、护士、软件工程师、教师、运动员）的基准。测试了五种先进TTI模型，对比了中性提示和鼓励多样性的公平感知提示。对输出的性别和种族进行了标注，以便进行结构化分析。

Result: 提示可以显著改变人口统计学表征，但效果高度依赖于模型。有些模型能有效实现多样化，有些则过度修正导致不切实际的统一，还有些则响应度很低。

Conclusion: 提示作为一种公平性干预措施既有潜力也有局限性，突显了模型层面策略的必要性。

Abstract: Text-to-Image (TTI) models are powerful creative tools but risk amplifying
harmful social biases. We frame representational societal bias assessment as an
image curation and evaluation task and introduce a pilot benchmark of
occupational portrayals spanning five socially salient roles (CEO, Nurse,
Software Engineer, Teacher, Athlete). Using five state-of-the-art models:
closed-source (DALLE 3, Gemini Imagen 4.0) and open-source (FLUX.1-dev, Stable
Diffusion XL Turbo, Grok-2 Image), we compare neutral baseline prompts against
fairness-aware controlled prompts designed to encourage demographic diversity.
All outputs are annotated for gender (male, female) and race (Asian, Black,
White), enabling structured distributional analysis. Results show that
prompting can substantially shift demographic representations, but with highly
model-specific effects: some systems diversify effectively, others overcorrect
into unrealistic uniformity, and some show little responsiveness. These
findings highlight both the promise and the limitations of prompting as a
fairness intervention, underscoring the need for complementary model-level
strategies. We release all code and data for transparency and reproducibility
https://github.com/maximus-powers/img-gen-bias-analysis.

</details>


### [260] [Exploring and Mitigating Fawning Hallucinations in Large Language Models](https://arxiv.org/abs/2509.00869)
*Zixuan Shangguan,Yanjie Dong,Lanjun Wang,Xiaoyi Fan,Victor C. M. Leung,Xiping Hu*

Main category: cs.CL

TL;DR: LLMs may generate inaccurate responses due to 'fawning hallucinations' when given misleading prompts. This paper proposes a 'collaborative contrastive decoding' (CCD) method to mitigate these hallucinations by contrasting outputs from deceptive and neutral prompts, improving response factuality without retraining.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the issue of 'fawning hallucinations' in large language models (LLMs), where models prioritize aligning with deceptive or misleading prompts over factual accuracy, potentially leading to the generation of incorrect information.

Method: The paper proposes a 'collaborative contrastive decoding' (CCD) method. This involves generating deceptive/misleading inputs to induce fawning hallucinations and then contrasting the output distribution between these inputs and transformed neutral inputs. This contrast helps reduce the model's reliance on misleading information.

Result: Extensive experiments show that the proposed CCD method effectively mitigates fawning hallucinations across various tasks and improves the factuality of LLM-generated responses.

Conclusion: The collaborative contrastive decoding (CCD) method is an effective technique for mitigating fawning hallucinations in LLMs, leading to more factual and reliable outputs without the need for additional training.

Abstract: Large language models (LLMs) have demonstrated exceptional proficiency in
language understanding. However, when LLMs align their outputs with deceptive
and/or misleading prompts, the generated responses could deviate from the de
facto information. Such observations are known as fawning hallucinations, where
the model prioritizes alignment with the input's implied perspective over
accuracy and truthfulness. In this work, we analyze fawning hallucinations in
various natural language processing tasks and tailor the so-termed contrastive
decoding method for fawning-hallucination mitigation. Specifically, we design
two paradigms to generate corresponding deceptive and/or misleading inputs for
the consistent fawning hallucinations induction. Then, we propose the
collaborative contrastive decoding (CCD) to handle the fawning hallucinations
across different tasks in LLMs. By contrasting the deviation in output
distribution between induced and transformed neutral inputs, the proposed CCD
can reduce reliance on deceptive and/or misleading information without
requiring additional training. Extensive experiments demonstrate that the
proposed CCD can effectively mitigate fawning hallucinations and improve the
factuality of the generated responses over various tasks.

</details>


### [261] [EviNote-RAG: Enhancing RAG Models via Answer-Supportive Evidence Notes](https://arxiv.org/abs/2509.00877)
*Yuqin Dai,Guoqing Wang,Yuan Wang,Kairan Dou,Kaichen Zhou,Zhanwei Zhang,Shuo Yang,Fei Tang,Jun Yin,Pengyu Zeng,Zhenzhe Ying,Can Yi,Changhua Meng,Yuchen Zhou,Yongliang Shen,Shuai Lu*

Main category: cs.CL

TL;DR: EviNote-RAG是一个创新的检索增强生成（RAG）框架，通过结构化的“检索-笔记-回答”流程，解决了传统“检索-回答”范式中证据信噪比低和多跳推理错误累积的问题。它通过生成“支持性证据笔记”（SENs）来提炼答案相关信息，并利用基于蕴含的“证据质量奖励”（EQR）来强化推理，从而提高了问答的准确性、泛化性和训练稳定性，并在多个基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 传统的检索增强生成（RAG）范式在开放域问答中存在两个主要问题：检索到的证据信噪比低（有用信息被噪声淹没）和多跳推理中的错误累积（由于不完整或有噪声的段落）。

Method: 提出了一种名为EviNote-RAG的代理RAG框架，引入了结构化的“检索-笔记-回答”流程。该框架训练模型撰写“支持性证据笔记”（SENs），这些笔记简洁、类似人类书写，只保留与答案相关的关键信息，并能体现不确定性或明确指出无用证据。此外，引入了基于蕴含的“证据质量奖励”（EQR）来评估SENs是否在逻辑上支持最终答案，以强化模型的忠实和鲁棒推理能力，并减少噪声影响。

Result: 在领域内和领域外问答基准测试中，EviNote-RAG的准确性、泛化性和训练稳定性均优于强基线模型。具体而言，通过更密集的奖励和更少的冗余信息，EviNote-RAG在HotpotQA上实现了20%的相对F1提升（+0.093），在Bamboogle上提升了40%（+0.151），在2Wiki上提升了91%（+0.256），达到了最先进的水平，同时提高了鲁棒性和效率。

Conclusion: EviNote-RAG通过创新的“检索-笔记-回答”流程和证据质量奖励机制，有效解决了现有RAG方法的局限性，显著提升了开放域问答的性能，并在准确性、泛化性、鲁棒性和效率方面取得了最先进的成果。

Abstract: Large Language Models (LLMs) empowered with retrieval mechanisms have
achieved strong progress in open-domain question answering (QA). Yet, the
conventional retrieve--then--answer paradigm often suffers from two key
limitations: (1) low signal-to-noise ratio in retrieved evidence, where useful
information is buried under irrelevant content, and (2) error accumulation in
multi-hop reasoning when incomplete or noisy passages are involved. To address
these challenges, we present EviNote-RAG, an agentic RAG framework that
introduces a structured retrieve--note--answer pipeline. Instead of directly
reasoning over raw retrievals, the model is trained to compose
Supportive-Evidence Notes (SENs), concise, human-like notes that preserve only
answer-relevant information, highlight uncertainty, and explicitly state when
no useful evidence exists. This distillation process is further reinforced by
the Evidence Quality Reward (EQR), an entailment-based signal that evaluates
whether SENs logically support the final answer. Together, SENs and EQR guide
the model toward faithful and robust reasoning, while reducing the impact of
noise. Experiments on in-domain and out-of-domain QA benchmarks show that
EviNote-RAG consistently outperforms strong baselines in accuracy,
generalization, and training stability. In particular, it achieves
state-of-the-art results while enhancing robustness and efficiency, yielding
relative F1 gains of 20\% on HotpotQA (+0.093), 40\% on Bamboogle (+0.151), and
91\% on 2Wiki (+0.256) via denser rewards and reduced verbosity.

</details>


### [262] [SeLeRoSa: Sentence-Level Romanian Satire Detection Dataset](https://arxiv.org/abs/2509.00893)
*Răzvan-Alexandru Smădu,Andreea Iuga,Dumitru-Clementin Cercel,Florin Pop*

Main category: cs.CL

TL;DR: 本研究提出了罗马尼亚新闻文章的句子级讽刺检测数据集SeLeRoSa，并评估了基于大型语言模型（LLM）和Transformer的模型在该任务上的表现，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 识别新闻文章中的讽刺、反讽和嘲讽等修辞手法，区分它们与虚假新闻，并为罗马尼亚语的句子级讽刺检测提供数据集和基准。

Method: 创建了一个包含13,873个手动标注句子的SeLeRoSa数据集，涵盖了社会、IT、科学和电影等领域。评估了基于LLM（包括零样本和微调设置）和基于Transformer的模型在句子级讽刺检测任务上的性能。

Result: 评估结果表明，尽管LLM在零样本和微调设置下表现出一定的能力，但它们在句子级讽刺检测任务上仍存在局限性。

Conclusion: 本研究为罗马尼亚语句子级讽刺检测提供了首个数据集（SeLeRoSa），并对现有模型进行了评估，指出了未来研究的方向，即改进模型在处理细粒度讽刺内容方面的能力。

Abstract: Satire, irony, and sarcasm are techniques typically used to express humor and
critique, rather than deceive; however, they can occasionally be mistaken for
factual reporting, akin to fake news. These techniques can be applied at a more
granular level, allowing satirical information to be incorporated into news
articles. In this paper, we introduce the first sentence-level dataset for
Romanian satire detection for news articles, called SeLeRoSa. The dataset
comprises 13,873 manually annotated sentences spanning various domains,
including social issues, IT, science, and movies. With the rise and recent
progress of large language models (LLMs) in the natural language processing
literature, LLMs have demonstrated enhanced capabilities to tackle various
tasks in zero-shot settings. We evaluate multiple baseline models based on LLMs
in both zero-shot and fine-tuning settings, as well as baseline
transformer-based models. Our findings reveal the current limitations of these
models in the sentence-level satire detection task, paving the way for new
research directions.

</details>


### [263] [Supervised In-Context Fine-Tuning for Generative Sequence Labeling](https://arxiv.org/abs/2509.00921)
*David Dukić,Goran Glavaš,Jan Šnajder*

Main category: cs.CL

TL;DR: SIFT是一种用于生成式序列标注（SL）的新方法，它将SL任务视为约束响应生成，并将上下文学习（ICL）与监督微调相结合，在标准SL任务上表现优于现有方法。研究还发现，长上下文会影响生成式SL的性能，但可以通过移除指令来缓解。


<details>
  <summary>Details</summary>
Motivation: 序列标注（SL）任务在自然语言处理（NLP）中很常见，但大多数现有方法都集中在使用编码器模型。然而，随着大型语言模型（LLMs）的发展，特别是因果LLMs，人们对其在SL任务上的潜力越来越感兴趣。本研究旨在探索和改进因果LLMs在监督生成式SL任务中的应用，期望其能超越性能停滞的编码器模型。

Method: 本研究提出了一种名为SIFT（supervised in-context fine-tuning）的监督上下文微调方法，用于处理生成式序列标注（SL）任务。SIFT将SL任务重新表述为约束响应生成问题，这与因果LLMs的生成能力相吻合。该方法结合了两种关键技术：1）利用上下文学习（ICL）从示例中学习；2）进行监督微调以优化模型性能。此外，研究还探讨了长上下文和指令对SIFT性能的影响，并提出通过移除指令来缓解长上下文带来的性能下降问题。

Result: SIFT在多种标准的SL任务上，其性能显著优于单独使用ICL和将解码器作为编码器进行微调的基线方法。研究还发现，尽管长上下文普遍会降低因果LLMs在ICL和SIFT模式下的SL性能，但通过移除指令可以有效缓解这一问题，因为指令对于SIFT达到高性能并非必需。

Conclusion: 本研究强调了因果LLMs在序列标注（SL）任务中的潜力和局限性。研究提出的SIFT方法通过将SL任务表述为响应生成，并结合ICL和监督微调，有效地提升了性能。此外，研究还指出了长上下文对生成式SL的挑战，并提供了一种通过移除指令来缓解该问题的策略，强调了响应式生成任务形式对于实现高效SL性能的重要性。

Abstract: Sequence labeling (SL) tasks, where labels are assigned to tokens, are
abundant in NLP (e.g., named entity recognition and aspect-based sentiment
analysis). Owing to the intuition that they require bidirectional context, SL
tasks are commonly tackled with encoder-only models. Recent work also shows
that removing the causal mask in fine-tuning enables decoder-based LLMs to
become effective token classifiers. Less work, however, focused on (supervised)
generative SL, a more natural setting for causal LLMs. Due to their rapid
scaling, causal LLMs applied to SL are expected to outperform encoders, whose
own development has stagnated. In this work, we propose supervised in-context
fine-tuning (SIFT) for generative SL. SIFT casts SL tasks as constrained
response generation, natural to LLMs, combining (1) in-context learning (ICL)
from demonstrations with (2) supervised fine-tuning. SIFT considerably
outperforms both ICL and decoder-as-encoder fine-tuning baselines on a range of
standard SL tasks. We further find that although long context hinders the
performance of generative SL in both ICL and SIFT, this deficiency can be
mitigated by removing the instruction, as instructions are shown to be largely
unnecessary for achieving strong SL performance with SIFT. Our findings
highlight strengths and limitations of SL with LLMs, underscoring the
importance of a response-based generative task formulation for effective SL
performance.

</details>


### [264] [MedCOD: Enhancing English-to-Spanish Medical Translation of Large Language Models Using Enriched Chain-of-Dictionary Framework](https://arxiv.org/abs/2509.00934)
*Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu*

Main category: cs.CL

TL;DR: MedCOD是一个结合UMLS和LLM-KB的混合框架，通过结构化提示和微调来提升英语到西班牙语的医学翻译质量，在多个模型上均取得显著效果。


<details>
  <summary>Details</summary>
Motivation: 为了提高英语到西班牙语的医学翻译质量，通过整合领域特定的结构化知识到大型语言模型（LLM）中。

Method: 提出了MedCOD（Medical Chain-of-Dictionary）混合框架，整合了UMLS和LLM-KB的领域知识，并结合结构化提示（包含多语言变体、医学同义词和UMLS定义的变体）和基于LoRA的微调方法，在2,999篇MedlinePlus文章构建的平行语料库和包含结构化医学上下文的100句测试集上对Phi-4、Qwen2.5-14B、Qwen2.5-7B和LLaMA-3.1-8B四个开源LLM进行了评估。

Result: MedCOD框架显著提高了所有评估模型的翻译质量。例如，使用MedCOD和微调的Phi-4模型在BLEU、chrF++和COMET得分上分别达到44.23、28.91和0.863，优于GPT-4o和GPT-4o-mini等模型。消融研究表明，MedCOD提示和模型适配都能独立提升性能，两者结合效果最佳。

Conclusion: 整合结构化知识到LLM中是提升医学翻译任务性能的有效途径。

Abstract: We present MedCOD (Medical Chain-of-Dictionary), a hybrid framework designed
to improve English-to-Spanish medical translation by integrating
domain-specific structured knowledge into large language models (LLMs). MedCOD
integrates domain-specific knowledge from both the Unified Medical Language
System (UMLS) and the LLM-as-Knowledge-Base (LLM-KB) paradigm to enhance
structured prompting and fine-tuning. We constructed a parallel corpus of 2,999
English-Spanish MedlinePlus articles and a 100-sentence test set annotated with
structured medical contexts. Four open-source LLMs (Phi-4, Qwen2.5-14B,
Qwen2.5-7B, and LLaMA-3.1-8B) were evaluated using structured prompts that
incorporated multilingual variants, medical synonyms, and UMLS-derived
definitions, combined with LoRA-based fine-tuning. Experimental results
demonstrate that MedCOD significantly improves translation quality across all
models. For example, Phi-4 with MedCOD and fine-tuning achieved BLEU 44.23,
chrF++ 28.91, and COMET 0.863, surpassing strong baseline models like GPT-4o
and GPT-4o-mini. Ablation studies confirm that both MedCOD prompting and model
adaptation independently contribute to performance gains, with their
combination yielding the highest improvements. These findings highlight the
potential of structured knowledge integration to enhance LLMs for medical
translation tasks.

</details>


### [265] [Structure and Destructure: Dual Forces in the Making of Knowledge Engines](https://arxiv.org/abs/2509.00949)
*Yihong Chen*

Main category: cs.CL

TL;DR: 本文探讨了知识引擎构建中的结构化和非结构化两种范式，并提出了一种结合两者的混合方法，以实现更透明、可控和适应性强的智能系统。


<details>
  <summary>Details</summary>
Motivation: 本文旨在弥合知识引擎构建中结构化和非结构化两种范式之间的差距，并提出一种新的方法来构建更通用的知识引擎。

Method: 本文提出了一种结合结构化和非结构化范式的方法，其中结构化通过知识图谱等先验知识来组织，非结构化则通过周期性嵌入重置来提高模型的塑形和泛化能力。

Result: 本文的方法能够构建更透明、可控和适应性强的通用知识引擎。

Conclusion: 结构化和非结构化这两种范式可以通过“结构”和“解构”相结合的方式进行统一，为开发更先进的智能系统提供了新的思路。

Abstract: The making of knowledge engines in natural language processing has been
shaped by two seemingly distinct paradigms: one grounded in structure, the
other driven by massively available unstructured data. The structured paradigm
leverages predefined symbolic interactions, such as knowledge graphs, as priors
and designs models to capture them. In contrast, the unstructured paradigm
centers on scaling transformer architectures with increasingly vast data and
model sizes, as seen in modern large language models. Despite their divergence,
this thesis seeks to establish conceptual connections bridging these paradigms.
Two complementary forces, structure and destructure, emerge across both
paradigms: structure organizes seen symbolic interactions, while destructure,
through periodic embedding resets, improves model plasticity and generalization
to unseen scenarios. These connections form a new recipe for developing general
knowledge engines that can support transparent, controllable, and adaptable
intelligent systems.

</details>


### [266] [RPRO:Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning](https://arxiv.org/abs/2509.00974)
*Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Feng Liu,Fang-Ming Hung*

Main category: cs.CL

TL;DR: RPRO框架结合强化学习和偏好驱动的推理改进，提高了医学问答的准确性和可靠性，在PubMedQA和MedQA-USMLE上表现优于现有模型，甚至在参数量小于基线模型的情况下也取得了更好的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在医学问答中生成的推理链缺乏事实准确性和临床可靠性。

Method: 提出了一种名为RPRO的新框架，该框架结合了强化学习和偏好驱动的推理改进，采用任务自适应推理模板和概率评估机制，并基于Bradley-Terry模型引入了群组排名优化和KL散度正则化。

Result: 在PubMedQA和MedQA-USMLE数据集上，RPRO框架表现出持续的改进，优于现有模型。1.1B参数的模型性能超过了7B-13B参数的模型。

Conclusion: 将偏好优化与质量驱动的改进相结合，是构建更可靠、更符合临床的医学LLM的可扩展且有效的方法。

Abstract: Medical question answering requires advanced reasoning that integrates domain
knowledge with logical inference. However, existing large language models
(LLMs) often generate reasoning chains that lack factual accuracy and clinical
reliability. We propose Ranked Preference Reinforcement Optimization (RPRO), a
novel framework that uniquely combines reinforcement learning with
preference-driven reasoning refinement to enhance clinical chain-of-thought
(CoT) performance. RPRO differentiates itself from prior approaches by
employing task-adaptive reasoning templates and a probabilistic evaluation
mechanism that aligns outputs with established clinical workflows, while
automatically identifying and correcting low-quality reasoning chains. Unlike
traditional pairwise preference methods, RPRO introduces a groupwise ranking
optimization based on the Bradley-Terry model and incorporates KL-divergence
regularization for stable training. Experiments on PubMedQA and MedQA-USMLE
show consistent improvements over strong baselines. Remarkably, our 1.1B
parameter model outperforms much larger 7B-13B models, including
medical-specialized variants. These findings demonstrate that combining
preference optimization with quality-driven refinement offers a scalable and
effective approach to building more reliable, clinically grounded medical LLMs.

</details>


### [267] [Performance Analysis of Supervised Machine Learning Algorithms for Text Classification](https://arxiv.org/abs/2509.00983)
*Sadia Zaman Mishu,S M Rafiuddin*

Main category: cs.CL

TL;DR: 该论文使用监督学习技术（包括反向传播网络）对不同数据集进行文本分类，并通过实验分析来评估不同模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着网络搜索、数据挖掘、网络排名、推荐系统等领域对文本分类需求的不断增长，需要对文本分类过程进行研究和优化。

Method: 本文采用几种标准的监督学习技术，特别是反向传播算法（BPN）的人工神经网络（ANN）模型，对不同类别的标记文本数据进行分类。并与现有的基准方法进行比较，以评估分类性能。

Result: 通过在真实数据集上的实验分析，可以确定在文本分类任务中，哪些模型在准确性方面表现更好。

Conclusion: 实验结果表明，不同模型在文本分类任务上的表现存在差异，其中某些模型在准确性方面具有优势，可为未来的文本分类研究和应用提供参考。

Abstract: The demand for text classification is growing significantly in web searching,
data mining, web ranking, recommendation systems, and so many other fields of
information and technology. This paper illustrates the text classification
process on different datasets using some standard supervised machine learning
techniques. Text documents can be classified through various kinds of
classifiers. Labeled text documents are used to classify the text in supervised
classifications. This paper applies these classifiers on different kinds of
labeled documents and measures the accuracy of the classifiers. An Artificial
Neural Network (ANN) model using Back Propagation Network (BPN) is used with
several other models to create an independent platform for labeled and
supervised text classification process. An existing benchmark approach is used
to analyze the performance of classification using labeled documents.
Experimental analysis on real data reveals which model works well in terms of
classification accuracy.

</details>


### [268] [Ranking of Bangla Word Graph using Graph-based Ranking Algorithms](https://arxiv.org/abs/2509.01011)
*S M Rafiuddin*

Main category: cs.CL

TL;DR: 本文研究了基于图的 Bangla 词排序算法，并使用 F1 分数评估了其准确性。


<details>
  <summary>Details</summary>
Motivation: 词语排序对于文本摘要和信息检索至关重要。本文旨在探索用于 Bangla 词语的图排序算法。

Method: 构建 Bangla 词语图，并应用多种图排序算法，然后进行预处理和比较。

Result: 通过 F1 分数评估各种算法在真实数据上的准确性。

Conclusion: 实验结果分析揭示了每种排序算法的准确性。

Abstract: Ranking words is an important way to summarize a text or to retrieve
information. A word graph is a way to represent the words of a sentence or a
text as the vertices of a graph and to show the relationship among the words.
It is also useful to determine the relative importance of a word among the
words in the word-graph. In this research, the ranking of Bangla words are
calculated, representing Bangla words from a text in a word graph using various
graph based ranking algorithms. There is a lack of a standard Bangla word
database. In this research, the Indian Language POS-tag Corpora is used, which
has a rich collection of Bangla words in the form of sentences with their parts
of speech tags. For applying a word graph to various graph based ranking
algorithms, several standard procedures are applied. The preprocessing steps
are done in every word graph and then applied to graph based ranking algorithms
to make a comparison among these algorithms. This paper illustrate the entire
procedure of calculating the ranking of Bangla words, including the
construction of the word graph from text. Experimental result analysis on real
data reveals the accuracy of each ranking algorithm in terms of F1 measure.

</details>


### [269] [We Politely Insist: Your LLM Must Learn the Persian Art of Taarof](https://arxiv.org/abs/2509.01035)
*Nikta Gohari Sadr,Sahar Heidariasl,Karine Megerdoomian,Laleh Seyyed-Kalantari,Ali Emami*

Main category: cs.CL

TL;DR: LLMs在理解波斯语的


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在处理文化特定沟通规范方面的不足，我们在全球背景下的有效性受到了限制。因此，本文旨在解决LLMs在理解和应用波斯语中的

Method: 本文提出了TaarofBench，这是第一个用于评估LLM对

Result: 通过对五个前沿LLM的评估，我们发现它们在文化能力方面存在显著的差距，在符合文化规范的情况下，准确率比母语者低40-48%。

Conclusion: 这项工作为开发多样化和具有文化意识的LLM奠定了基础，使得能够更好地驾驭复杂社交互动的应用程序的开发成为可能。

Abstract: Large language models (LLMs) struggle to navigate culturally specific
communication norms, limiting their effectiveness in global contexts. We focus
on Persian taarof, a social norm in Iranian interactions, which is a
sophisticated system of ritual politeness that emphasizes deference, modesty,
and indirectness, yet remains absent from existing cultural benchmarks. We
introduce TaarofBench, the first benchmark for evaluating LLM understanding of
taarof, comprising 450 role-play scenarios covering 12 common social
interaction topics, validated by native speakers. Our evaluation of five
frontier LLMs reveals substantial gaps in cultural competence, with accuracy
rates 40-48% below native speakers when taarof is culturally appropriate.
Performance varies between interaction topics, improves with Persian-language
prompts, and exhibits gender-based asymmetries. We also show that responses
rated "polite" by standard metrics often violate taarof norms, indicating the
limitations of Western politeness frameworks. Through supervised fine-tuning
and Direct Preference Optimization, we achieve 21.8% and 42.3% improvement in
model alignment with cultural expectations. Our human study with 33
participants (11 native Persian, 11 heritage, and 11 non-Iranian speakers)
forms baselines in varying degrees of familiarity with Persian norms. This work
lays the foundation for developing diverse and culturally aware LLMs, enabling
applications that better navigate complex social interactions.

</details>


### [270] [A Dynamic Fusion Model for Consistent Crisis Response](https://arxiv.org/abs/2509.01053)
*Xiaoying Song,Anirban Saha Anik,Eduardo Blanco,Vanessa Frias-Martinez,Lingzi Hong*

Main category: cs.CL

TL;DR: 本研究提出了一种新的评估方法和基于融合的生成方法，以提高危机通信中自动响应的风格一致性。


<details>
  <summary>Details</summary>
Motivation: 为了提高危机通信中自动响应的质量和可信度，需要解决响应风格不一致的问题。

Method: 提出了一种新的评估指标来评估风格一致性，并采用了一种两阶段的融合生成方法，首先评估候选响应的风格，然后通过融合过程在实例级别进行优化和整合。

Result: 实验结果表明，该方法在响应质量和风格一致性方面均优于基线方法。

Conclusion: 所提出的方法能够生成高质量且风格一致的危机通信响应。

Abstract: In response to the urgent need for effective communication with
crisis-affected populations, automated responses driven by language models have
been proposed to assist in crisis communications. A critical yet often
overlooked factor is the consistency of response style, which could affect the
trust of affected individuals in responders. Despite its importance, few
studies have explored methods for maintaining stylistic consistency across
generated responses. To address this gap, we propose a novel metric for
evaluating style consistency and introduce a fusion-based generation approach
grounded in this metric. Our method employs a two-stage process: it first
assesses the style of candidate responses and then optimizes and integrates
them at the instance level through a fusion process. This enables the
generation of high-quality responses while significantly reducing stylistic
variation between instances. Experimental results across multiple datasets
demonstrate that our approach consistently outperforms baselines in both
response quality and stylistic uniformity.

</details>


### [271] [Speaking at the Right Level: Literacy-Controlled Counterspeech Generation with RAG-RL](https://arxiv.org/abs/2509.01058)
*Xiaoying Song,Anirban Saha Anik,Dibakar Barua,Pengcheng Luo,Junhua Ding,Lingzi Hong*

Main category: cs.CL

TL;DR: 生成适应不同健康素养水平的健康错误信息反驳言论。


<details>
  <summary>Details</summary>
Motivation: 现有健康错误信息反驳言论生成方法未能考虑受众的健康素养水平，导致反驳言论的有效性降低。

Method: 提出了一种结合检索增强生成（RAG）和强化学习（RL）的受控素养框架，通过检索与特定健康素养水平相关的知识，并设计结合用户偏好和可读性奖励的奖励函数，以生成适合目标健康素养水平的反驳言论。

Result: 与基线方法相比，受控素养框架在生成更易理解且用户更偏好的反驳言论方面表现更优。

Conclusion: 该研究通过提高反驳健康错误信息的可及性和理解性，为实现更公平、更有效、更有影响力的公共卫生传播做出了贡献。

Abstract: Health misinformation spreading online poses a significant threat to public
health. Researchers have explored methods for automatically generating
counterspeech to health misinformation as a mitigation strategy. Existing
approaches often produce uniform responses, ignoring that the health literacy
level of the audience could affect the accessibility and effectiveness of
counterspeech. We propose a Controlled-Literacy framework using
retrieval-augmented generation (RAG) with reinforcement learning (RL) to
generate tailored counterspeech adapted to different health literacy levels. In
particular, we retrieve knowledge aligned with specific health literacy levels,
enabling accessible and factual information to support generation. We design a
reward function incorporating subjective user preferences and objective
readability-based rewards to optimize counterspeech to the target health
literacy level. Experiment results show that Controlled-Literacy outperforms
baselines by generating more accessible and user-preferred counterspeech. This
research contributes to more equitable and impactful public health
communication by improving the accessibility and comprehension of counterspeech
to health misinformation.

</details>


### [272] [Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation](https://arxiv.org/abs/2509.01081)
*Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutez Al-Khatib,Mohammed Ghaly*

Main category: cs.CL

TL;DR: 该论文评估了大型语言模型在伊斯兰继承法（'ilm al-mawarith）方面的知识和推理能力。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在伊斯兰继承法领域的知识和推理能力。

Method: 使用包含1000个多项选择题的基准测试来评估七个大型语言模型的性能，这些问题涵盖了各种继承场景，旨在测试模型理解继承背景和计算伊斯兰法学规定的份额分配的能力。

Result: o3和Gemini 2.5的准确率超过90%，而ALLaM、Fanar、LLaMA和Mistral的准确率低于50%。

Conclusion: 大型语言模型在处理伊斯兰继承法方面存在显著的性能差距，这反映了它们在推理能力和领域适应性方面存在重要差异。未来的工作应集中在改进模型处理结构化法律推理和增强领域知识的能力。

Abstract: This paper evaluates the knowledge and reasoning capabilities of Large
Language Models in Islamic inheritance law, known as 'ilm al-mawarith. We
assess the performance of seven LLMs using a benchmark of 1,000 multiple-choice
questions covering diverse inheritance scenarios, designed to test models'
ability to understand the inheritance context and compute the distribution of
shares prescribed by Islamic jurisprudence. The results reveal a significant
performance gap: o3 and Gemini 2.5 achieved accuracies above 90%, whereas
ALLaM, Fanar, LLaMA, and Mistral scored below 50%. These disparities reflect
important differences in reasoning ability and domain adaptation. We conduct a
detailed error analysis to identify recurring failure patterns across models,
including misunderstandings of inheritance scenarios, incorrect application of
legal rules, and insufficient domain knowledge. Our findings highlight
limitations in handling structured legal reasoning and suggest directions for
improving performance in Islamic legal reasoning. Code:
https://github.com/bouchekif/inheritance_evaluation

</details>


### [273] [A Paradigm Gap in Urdu](https://arxiv.org/abs/2509.01084)
*Farah Adeeba,Rajesh Bhatt*

Main category: cs.CL

TL;DR: Urdu/Hindi 'ro-ya: ki:' construction shows a grammatical shift: perfective form is ungrammatical now but was common in 19th century. This is due to a morphosyntactic conflict with ergative case assignment in perfective transitive verbs.


<details>
  <summary>Details</summary>
Motivation: Investigate the diachronic shift in the grammaticality of the perfective form of the -ya: kar construction in Urdu/Hindi, which is absent in modern usage despite historical attestation.

Method: Historical text analysis, large-scale corpus study, and subjective evaluation tasks with native speakers.

Result: Confirmed the stark absence of perfective forms in modern Urdu/Hindi through corpus data and native speaker judgments, identifying a morphosyntactic conflict with ergative case assignment as the cause for this grammatical gap.

Conclusion: The perfective form of the -ya: kar construction became ungrammatical in modern Urdu/Hindi due to a morphosyntactic conflict with ergative case assignment, leading to its functional replacement and entrenchment of the gap in the grammar.

Abstract: In this paper, we document a paradigm gap in the combinatorial possibilities
of verbs and aspect in Urdu: the perfective form of the -ya: kar construction
(e.g. ro-ya: ki: cry-Pfv do.Pfv) is sharply ungrammatical in modern Urdu and
Hindi, despite being freely attested in 19th century literature. We investigate
this diachronic shift through historical text analysis, a large-scale corpus
study which confirms the stark absence of perfective forms and subjective
evaluation tasks with native speakers, who judge perfective examples as highly
unnatural. We argue that this gap arose from a fundamental morphosyntactic
conflict: the construction's requirement for a nominative subject and an
invariant participle clashes with the core grammatical rule that transitive
perfective assign ergative case. This conflict rendered the perfective form
unstable, and its functional replacement by other constructions allowed the gap
to become entrenched in the modern grammar.

</details>


### [274] [Privacy-Preserving Reasoning with Knowledge-Distilled Parametric Retrieval Augmented Generation](https://arxiv.org/abs/2509.01088)
*Jinwen Chen,Hainan Zhang,Liang Pang,Yongxin Tong,Haibo Zhou,Yuan Zhan,Wei Lin,Zhiming Zheng*

Main category: cs.CL

TL;DR: PRAG系统存在推理延迟和泛化能力差的问题。本文提出DistilledPRAG，通过知识蒸馏实现高效参数化，解决了PRAG的痛点，并在四个QA数据集上取得了优于基线的结果，且在OOD数据上泛化性良好。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统将明文文档上传云端存在私密数据泄露风险，PRAG通过将文档编码为LoRA来解决，但存在推理延迟高和泛化能力差（依赖合成QA数据）的问题。因此，需要实现高效率参数化同时保持RAG水平性能的隐私保护推理方法。

Method: 提出DistilledPRAG模型，通过知识蒸馏实现参数化RAG。具体方法包括：1. 合成单文档和多文档QA对以增强跨文档推理。2. 使用特殊标记掩码明文文档，通过参数生成器将其转换为LoRA，保持标准RAG文档结构。3. 利用合成QA数据训练参数生成器，使其隐藏状态和输出logits与标准RAG匹配，实现无需原文的RAG风格推理。

Result: DistilledPRAG在四个QA数据集上的实验结果表明，其在准确性方面优于基线模型，并且在OOD数据上具有良好的泛化能力。

Conclusion: DistilledPRAG通过知识蒸馏解决了PRAG的推理延迟和泛化能力问题，实现了与标准RAG在文档结构和参数激活上的一致性，能够在不暴露原始文档的情况下进行RAG风格推理，并且在实验中表现出优越的性能和泛化能力。

Abstract: The current RAG system requires uploading plaintext documents to the cloud,
risking private data leakage. Parametric RAG (PRAG) addresses this by encoding
documents as LoRA within LLMs, enabling reasoning without exposing raw content.
However, it still faces two issues: (1) PRAG demands synthesizing QA pairs and
fine-tuning LLM for each individual document to create its corresponding LoRA,
leading to unacceptable inference latency. (2) The performance of PRAG relies
solely on synthetic QA data, lacking internal alignment with standard RAG,
resulting in poor generalization on out-of-distribution(OOD) inputs. Therefore,
achieving high-efficiency parameterization while maintaining RAG-level
performance remains a critical challenge for privacy-preserving reasoning. In
this paper, we propose DistilledPRAG, a generalizable knowledge-distilled
parametric RAG model aligned with standard RAG in document structure and
parameter activation. We first synthesize QA pairs from single and
multi-documents to enhance cross-document reasoning. Then, we mask the
plaintext documents with a special token and translate them to LoRA via a
parameter generator, maintaining the standard RAG document structure. Finally,
guided by synthetic QA data, we train the parameter generator to match standard
RAG's hidden states and output logits, enabling RAG-style reasoning without
original documents. Experiments on four QA datasets show that DistilledPRAG
outperforms baselines in accuracy and generalizes well on OOD data.

</details>


### [275] [REFRAG: Rethinking RAG based Decoding](https://arxiv.org/abs/2509.01092)
*Xiaoqiang Lin,Aritra Ghosh,Bryan Kian Hsiang Low,Anshumali Shrivastava,Vijai Mohan*

Main category: cs.CL

TL;DR: REFRAG通过利用RAG中检索到的文本稀疏性来提高LLM的延迟，在不损失准确性的情况下实现了30.85%的加速，并将上下文长度增加了16倍。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM在处理长上下文输入时存在系统延迟高和内存消耗大的问题，特别是在RAG应用中，检索到的文本大部分与查询的语义相似度较低，导致不必要的计算。虽然已有工作致力于降低LLM的延迟，但RAG场景需要特殊考虑。

Method: 提出REFRAG框架，通过压缩、感知和扩展机制来优化RAG应用的延迟。该框架利用RAG上下文中的块对角注意力模式，去除冗余计算。

Result: REFRAG在时间-首个token延迟方面实现了30.85%的加速（相比先前工作提升3.75倍），且困惑度未损失。同时，REFRAG支持的上下文长度增加了16倍，并在RAG、多轮对话、长文档摘要等多种长上下文任务中验证了其有效性，与LLaMA模型及其他先进基线相比，在各种上下文长度下均实现了显著加速且准确率无损。

Conclusion: REFRAG是一个有效的解码框架，通过利用RAG中检索文本的稀疏性，在不影响准确性的前提下显著提高了LLM在长上下文应用中的效率，并扩大了LLM处理长上下文的能力。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
leveraging extensive external knowledge to enhance responses in multi-turn and
agentic applications, such as retrieval-augmented generation (RAG). However,
processing long-context inputs introduces significant system latency and
demands substantial memory for the key-value cache, resulting in reduced
throughput and a fundamental trade-off between knowledge enrichment and system
efficiency. While minimizing latency for long-context inputs is a primary
objective for LLMs, we contend that RAG require specialized consideration. In
RAG, much of the LLM context consists of concatenated passages from retrieval,
with only a small subset directly relevant to the query. These passages often
exhibit low semantic similarity due to diversity or deduplication during
re-ranking, leading to block-diagonal attention patterns that differ from those
in standard LLM generation tasks. Based on this observation, we argue that most
computations over the RAG context during decoding are unnecessary and can be
eliminated with minimal impact on performance. To this end, we propose REFRAG,
an efficient decoding framework that compresses, senses, and expands to improve
latency in RAG applications. By exploiting the sparsity structure, we
demonstrate a 30.85 the time-to-first-token acceleration (3.75 improvement to
previous work) without loss in perplexity. In addition, our optimization
framework for large context enables REFRAG to extend the context size of LLMs
by 16. We provide rigorous validation of REFRAG across diverse long-context
tasks, including RAG, multi-turn conversations, and long document
summarization, spanning a wide range of datasets. Experimental results confirm
that REFRAG delivers substantial speedup with no loss in accuracy compared to
LLaMA models and other state-of-the-art baselines across various context sizes.

</details>


### [276] [Natural Context Drift Undermines the Natural Language Understanding of Large Language Models](https://arxiv.org/abs/2509.01093)
*Yulong Wu,Viktor Schlegel,Riza Batista-Navarro*

Main category: cs.CL

TL;DR: LLM在处理自然演变的上下文段落时表现下降，即使信息完整，也会因文本与预训练数据存在差异而准确率降低。


<details>
  <summary>Details</summary>
Motivation: 探究上下文段落的自然演变对生成式大型语言模型（LLM）问答能力的影响。

Method: 提出一个框架，用于策划和分析LLM在语义相似度范围内的表现，这些语义相似度量化了阅读段落变体与预训练内容的匹配程度。实验评估了六个问答数据集和八个LLM。

Result: LLM在阅读段落与其预训练版本发生自然分歧时，问答性能会下降，即使问题和所需信息在推理时仍然存在。例如，在BoolQ数据集上，随着相似度降低，平均准确率下降超过30%。

Conclusion: 自然文本演变对LLM的语言理解能力构成了重大挑战。

Abstract: How does the natural evolution of context paragraphs affect question
answering in generative Large Language Models (LLMs)? To investigate this, we
propose a framework for curating naturally evolved, human-edited variants of
reading passages from contemporary QA benchmarks and for analyzing LLM
performance across a range of semantic similarity scores, which quantify how
closely each variant aligns with content seen during pretraining. Using this
framework, we evaluate six QA datasets and eight LLMs with publicly available
training data. Our experiments reveal that LLM performance declines as reading
passages naturally diverge from the versions encountered during
pretraining-even when the question and all necessary information remains
present at inference time. For instance, average model accuracy on BoolQ drops
by over 30% from the highest to lowest similarity bins, with slopes exceeding
70 across several LLMs. These findings suggest that natural text evolution
poses a significant challenge to the language understanding capabilities of
LLMs.

</details>


### [277] [Dream-Coder 7B: An Open Diffusion Language Model for Code](https://arxiv.org/abs/2509.01142)
*Zhihui Xie,Jiacheng Ye,Lin Zheng,Jiahui Gao,Jingwei Dong,Zirui Wu,Xueliang Zhao,Shansan Gong,Xin Jiang,Zhenguo Li,Lingpeng Kong*

Main category: cs.CL

TL;DR: Dream-Coder 7B是一个开源的离散扩散语言模型，用于代码生成，并具有任意顺序生成能力。它能根据任务自适应地调整解码策略（如草图优先、从左到右或交错推理）。该模型通过在预训练的自回归检查点上应用离散扩散框架、加权交叉熵目标、监督微调（结合随机截断和填充惩罚）以及基于可验证奖励的强化学习进行训练。结果显示，Dream-Coder 7B在LiveCodeBench上 đạt 21.4% pass@1，并在HumanEval、MBPP等基准测试中表现具有竞争力。研究团队公开发布了模型、训练方法和代码以促进研究。


<details>
  <summary>Details</summary>
Motivation: 介绍一个名为Dream-Coder 7B的开源离散扩散语言模型，用于代码生成，并强调其具备“任意顺序生成”能力，以及能够根据不同代码任务自适应调整解码策略。

Method: 1. 将预训练的自回归（AR）检查点适配到离散扩散框架，并使用连续时间加权交叉熵目标进行训练。
2. 训练过程包括两个阶段：
   a. 监督微调：通过随机截断和填充惩罚来解决填充问题，提高样本效率和生成稳定性。
   b. 强化学习：在精心筛选的高质量提示集上进行，使用针对扩散语言模型的定制强化学习方法，并基于可验证的奖励进行优化。

Result: Dream-Coder 7B Instruct在LiveCodeBench上达到了21.4%的pass@1准确率，并且在HumanEval、MBPP、BigCodeBench和CRUXEval等基准测试中也展现出具有竞争力的性能。

Conclusion: Dream-Coder 7B是一个在代码生成方面表现出色的离散扩散语言模型，其创新的解码策略和训练方法使其能够在不同任务中灵活适应。研究团队通过公开发布模型、训练方法和代码，为该领域的研究和可复现性做出了贡献。

Abstract: We present Dream-Coder 7B, an open-source discrete diffusion language model
for code generation that exhibits emergent any-order generation capabilities.
Unlike traditional autoregressive (AR) models that decode strictly
left-to-right, Dream-Coder 7B adaptively determines its decoding strategy based
on the coding task: sketch-first generation for complex algorithms,
left-to-right generation for straightforward completions, and interleaved
reasoning generation for code understanding tasks. We adapt a pretrained AR
checkpoint to a discrete diffusion frameworks with a continuous-time weighted
cross-entropy objective. Our post-training recipe comprises (i) supervised
fine-tuning, where we mitigate padding pathologies via random truncation and a
padding penalty to improve sample efficiency and stabilize generation; and (ii)
reinforcement learning with verifiable rewards over a curated high-quality
prompt set drawn from open-source datasets, using a tailored reinforcement
learning recipe for diffusion language models. The resulting Dream-Coder 7B
Instruct attains 21.4\% pass@1 on LiveCodeBench (2410--2505) and demonstrates
competitive performance on HumanEval, MBPP, BigCodeBench, and CRUXEval. We
release Dream-Coder-7B and Dream-Coder-7B-Instruct checkpoints, training
recipes, preprocessing pipelines, and inference code to facilitate
reproducibility and further research.

</details>


### [278] [Zero-shot Cross-lingual NER via Mitigating Language Difference: An Entity-aligned Translation Perspective](https://arxiv.org/abs/2509.01147)
*Zhihao Zhang,Sophia Yat Mei Lee,Dong Zhang,Shoushan Li,Guodong Zhou*

Main category: cs.CL

TL;DR: 现有跨语言命名实体识别（CL-NER）方法主要集中在拉丁字母语言（LSL），但对于非拉丁字母语言（NSL）如中文和日文，由于深层结构差异，性能会下降。本文提出一种实体对齐翻译（EAT）方法，利用大型语言模型（LLMs）的双重翻译策略来对齐NSL和英语中的实体，并通过多语言维基百科数据微调LLMs，以提升源语言到目标语言的实体对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有零样本跨语言命名实体识别（ZCL-NER）方法主要针对拉丁字母语言（LSL），在非拉丁字母语言（NSL）上由于结构差异性能会下降，需要提升在NSL上的识别效果。

Method: 提出实体对齐翻译（EAT）方法，利用大型语言模型（LLMs）的双重翻译策略对齐NSL和英语中的实体，并使用多语言维基百科数据微调LLMs以增强实体对齐。

Result: 通过EAT方法提升了在非拉丁字母语言（NSL）上的跨语言命名实体识别性能。

Conclusion: EAT方法通过实体对齐翻译和多语言微调有效解决了非拉丁字母语言（NSL）上的跨语言命名实体识别性能下降问题。

Abstract: Cross-lingual Named Entity Recognition (CL-NER) aims to transfer knowledge
from high-resource languages to low-resource languages. However, existing
zero-shot CL-NER (ZCL-NER) approaches primarily focus on Latin script language
(LSL), where shared linguistic features facilitate effective knowledge
transfer. In contrast, for non-Latin script language (NSL), such as Chinese and
Japanese, performance often degrades due to deep structural differences. To
address these challenges, we propose an entity-aligned translation (EAT)
approach. Leveraging large language models (LLMs), EAT employs a
dual-translation strategy to align entities between NSL and English. In
addition, we fine-tune LLMs using multilingual Wikipedia data to enhance the
entity alignment from source to target languages.

</details>


### [279] [Joint Information Extraction Across Classical and Modern Chinese with Tea-MOELoRA](https://arxiv.org/abs/2509.01158)
*Xuemei Tang,Chengxi Yan,Jinghang Gu,Chu-Ren Huang*

Main category: cs.CL

TL;DR: Tea-MOELoRA是一个参数高效的多任务框架，结合了LoRA和MoE设计，用于中文信息提取，在不同时期和任务上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 中文信息提取涉及跨越古代和现代文档的多个任务，在不同时期对同一模型进行微调可能会导致干扰和性能下降。

Method: 提出Tea-MOELoRA，一个参数高效的多任务框架，结合了LoRA和MoE设计。多个低秩LoRA专家专门处理不同的信息提取任务和时期，而一个感知任务和时期的路由机制动态地分配专家贡献。

Result: 实验表明，Tea-MOELoRA的性能优于单一任务和联合LoRA基线模型，有效地利用了任务和时间知识。

Conclusion: Tea-MOELoRA通过结合LoRA和MoE设计，并采用任务-时期感知路由机制，能够有效地处理中文信息提取中的多任务和跨时期挑战，并取得优于基线模型的性能。

Abstract: Chinese information extraction (IE) involves multiple tasks across diverse
temporal domains, including Classical and Modern documents. Fine-tuning a
single model on heterogeneous tasks and across different eras may lead to
interference and reduced performance. Therefore, in this paper, we propose
Tea-MOELoRA, a parameter-efficient multi-task framework that combines LoRA with
a Mixture-of-Experts (MoE) design. Multiple low-rank LoRA experts specialize in
different IE tasks and eras, while a task-era-aware router mechanism
dynamically allocates expert contributions. Experiments show that Tea-MOELoRA
outperforms both single-task and joint LoRA baselines, demonstrating its
ability to leverage task and temporal knowledge effectively.

</details>


### [280] [Enhancing Large Language Model for Knowledge Graph Completion via Structure-Aware Alignment-Tuning](https://arxiv.org/abs/2509.01166)
*Yu Liu,Yanan Cao,Xixun Lin,Yanmin Shang,Shi Wang,Shirui Pan*

Main category: cs.CL

TL;DR: SAT框架通过结构感知对齐调整，增强LLMs在知识图谱补全（KGC）任务中的能力，解决了现有方法在表示空间不一致和指令设计重复的问题。SAT通过分层知识对齐和结构化指令调整，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM增强KGC的方法存在表示空间不一致和指令设计重复的问题，SAT旨在解决这些挑战。

Method: SAT框架首先引入分层知识对齐，利用多任务对比学习将图嵌入与自然语言空间对齐；然后提出结构化指令调整，通过统一的图指令和轻量级知识适配器指导LLMs进行结构感知的推理。

Result: SAT在两个KGC任务和四个基准数据集上的实验结果表明，其性能显著优于现有最先进的方法，特别是在链接预测任务上，改进幅度达8.7%至29.8%。

Conclusion: SAT框架通过其新颖的结构感知对齐调整方法，有效提升了LLMs在KGC任务中的表现，尤其在链接预测方面取得了显著的性能提升。

Abstract: Knowledge graph completion (KGC) aims to infer new knowledge and make
predictions from knowledge graphs. Recently, large language models (LLMs) have
exhibited remarkable reasoning capabilities. LLM-enhanced KGC methods primarily
focus on designing task-specific instructions, achieving promising
advancements. However, there are still two critical challenges. First, existing
methods often ignore the inconsistent representation spaces between natural
language and graph structures. Second, most approaches design separate
instructions for different KGC tasks, leading to duplicate works and
time-consuming processes. To address these challenges, we propose SAT, a novel
framework that enhances LLMs for KGC via structure-aware alignment-tuning.
Specifically, we first introduce hierarchical knowledge alignment to align
graph embeddings with the natural language space through multi-task contrastive
learning. Then, we propose structural instruction tuning to guide LLMs in
performing structure-aware reasoning over KGs, using a unified graph
instruction combined with a lightweight knowledge adapter. Experimental results
on two KGC tasks across four benchmark datasets demonstrate that SAT
significantly outperforms state-of-the-art methods, especially in the link
prediction task with improvements ranging from 8.7% to 29.8%.

</details>


### [281] [Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation](https://arxiv.org/abs/2509.01185)
*Seganrasan Subramanian,Abhigya Verma*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The ability of large language models (LLMs) to process and reason over long
textual inputs is critical for a wide range of real-world applications.
However, progress in this area is significantly constrained by the absence of
high-quality, diverse, and verifiable long-context datasets suitable for both
training and evaluation. This work introduces a modular, extensible framework
for synthetic long-context data generation via prompt-based interaction with
LLMs. The framework supports multiple training and alignment objectives,
including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO),
and Group Relative Policy Optimization (GRPO). It encompasses four core
generation paradigms: multi-turn conversational dialogues, document-grounded
input-output pairs, verifiable instruction-response tasks, and long-context
reasoning examples. Through templated prompting, a model-agnostic architecture,
and metadata-enriched outputs, the proposed approach facilitates scalable,
controllable, and purpose-aligned dataset creation for advancing long-context
capabilities in LLMs.

</details>


### [282] [Statutory Construction and Interpretation for Artificial Intelligence](https://arxiv.org/abs/2509.01186)
*Luxi He,Nimra Nadeem,Michel Liao,Howard Chen,Danqi Chen,Mariano-Florentino Cuéllar,Peter Henderson*

Main category: cs.CL

TL;DR: AI 对齐领域存在解释性歧义问题，需要借鉴法律系统的机制来解决。本研究提出了一个计算框架，通过规则细化和基于提示的解释性约束来减少歧义，并在 WildChat 数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI 系统越来越多地受自然语言原则的约束，但解释性歧义这一关键挑战尚未得到充分探索。与法律系统不同，AI 对齐流程缺乏管理这种歧义的保护措施，可能导致模型行为不一致或不稳定。

Method: 借鉴法律理论，识别了当前对齐流程在规则制定和应用方面的关键差距。提出了一个计算框架，模仿法律系统的两种机制：（1）规则细化流程，通过修改模糊规则来最小化解释性分歧；（2）基于提示的解释性约束，减少规则应用中的不一致性。

Result: 在 WildChat 数据集的 5,000 个场景子集上评估了该框架，结果表明这两种干预措施都能显著提高一组合理解释者在判断一致性方面的表现。

Conclusion: 该方法是系统性管理解释性歧义的第一步，对于构建更鲁棒、更遵循法律的 AI 系统至关重要。

Abstract: AI systems are increasingly governed by natural language principles, yet a
key challenge arising from reliance on language remains underexplored:
interpretive ambiguity. As in legal systems, ambiguity arises both from how
these principles are written and how they are applied. But while legal systems
use institutional safeguards to manage such ambiguity, such as transparent
appellate review policing interpretive constraints, AI alignment pipelines
offer no comparable protections. Different interpretations of the same rule can
lead to inconsistent or unstable model behavior. Drawing on legal theory, we
identify key gaps in current alignment pipelines by examining how legal systems
constrain ambiguity at both the rule creation and rule application steps. We
then propose a computational framework that mirrors two legal mechanisms: (1) a
rule refinement pipeline that minimizes interpretive disagreement by revising
ambiguous rules (analogous to agency rulemaking or iterative legislative
action), and (2) prompt-based interpretive constraints that reduce
inconsistency in rule application (analogous to legal canons that guide
judicial discretion). We evaluate our framework on a 5,000-scenario subset of
the WildChat dataset and show that both interventions significantly improve
judgment consistency across a panel of reasonable interpreters. Our approach
offers a first step toward systematically managing interpretive ambiguity, an
essential step for building more robust, law-following AI systems.

</details>


### [283] [Efficient Large Language Models with Zero-Shot Adjustable Acceleration](https://arxiv.org/abs/2509.01190)
*Sajjad Kachuee,Mohammad Sharifkhani*

Main category: cs.CL

TL;DR: LLM推理中的零样本可调加速


<details>
  <summary>Details</summary>
Motivation: 在实际应用中，LLM面临计算效率和性能之间的挑战，优化微调后和推理过程中的加速至关重要。

Method: 提出了一种名为零样本可调加速的新型训练和推理方法，该方法在推理过程中动态调整硬件使用，无需额外的微调。

Result: 实验结果表明，该方法以零样本的方式实现了广泛的加速，与基线相比，速度最高可提高 11 倍。

Conclusion: 零样本可调加速为LLM推理的效率和性能提供了有前景的解决方案。

Abstract: Using Large Language Models (LLMs) in real-world applications presents
significant challenges, particularly in balancing computational efficiency and
performance. Optimizing acceleration after the fine-tuning phase and during
inference is crucial for building an efficient architecture. This paper
introduces Zero-Shot Adjustable Acceleration, a novel training and inference
method that dynamically adjusts hardware usage during inference without
requiring additional fine-tuning. The proposed approach is applied to newly
developed models and evaluated across multiple classification and text
generation tasks. Experimental results demonstrate that the method enables a
wide range of acceleration in a zero-shot manner and achieves up to a 11x
speedup compared to the baseline.

</details>


### [284] [SimulMEGA: MoE Routers are Advanced Policy Makers for Simultaneous Speech Translation](https://arxiv.org/abs/2509.01200)
*Chenyang Le,Bing Han,Jinshun Li,Songyong Chen,Yanmin Qian*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Simultaneous Speech Translation (SimulST) enables real-time cross-lingual
communication by jointly optimizing speech recognition and machine translation
under strict latency constraints. Existing systems struggle to balance
translation quality, latency, and semantic coherence, particularly in
multilingual many-to-many scenarios where divergent read and write policies
hinder unified strategy learning. In this paper, we present SimulMEGA
(Simultaneous Generation by Mixture-of-Experts Gating), an unsupervised policy
learning framework that combines prefix-based training with a
Mixture-of-Experts refiner to learn effective read and write decisions in an
implicit manner, without adding inference-time overhead. Our design requires
only minimal modifications to standard transformer architectures and
generalizes across both speech-to-text and text-to-speech streaming tasks.
Through comprehensive evaluation on six language pairs, our 500M parameter
speech-to-text model outperforms the Seamless baseline, achieving under 7
percent BLEU degradation at 1.5 seconds average lag and under 3 percent at 3
seconds. We further demonstrate the versatility of SimulMEGA by extending it to
streaming TTS with a unidirectional backbone, yielding superior latency quality
tradeoffs.

</details>


### [285] [Mitigating Catastrophic Forgetting in Continual Learning through Model Growth](https://arxiv.org/abs/2509.01213)
*Ege Süalp,Mina Rezaei*

Main category: cs.CL

TL;DR: 大型语言模型(LLM)在持续学习中会遇到灾难性遗忘问题，即在学习新任务时会丢失先前的知识。本文研究了模型增长策略，特别是通过Transformer堆叠来加速和结构化大型模型的训练，以减轻灾难性遗忘。研究发现，与未采用增长策略的模型相比，采用增长策略的模型（Stack LLM）在领域知识方面表现出改进，并且在推理和阅读理解等任务上遗忘的程度较低，表明其具有更强的知识保留能力。然而，在偏见评估方面，Stack LLM 保持了相对稳定的偏见比例，而基线模型则变得更加中立，这表明模型增长策略在应对社会偏见方面存在权衡。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是持续学习中的一个重大挑战，尤其是在大型语言模型（LLMs）上。本文旨在探索模型增长策略，特别是通过Transformer堆叠，是否能有效减轻LLMs在持续学习中的灾难性遗忘问题，并评估其在不同任务（领域知识、推理、阅读理解和偏见）上的表现。

Method: 本文比较了两种模型：一种采用增长策略（Stack LLM），另一种未采用（LLM）。两种模型都经过了一系列涉及领域知识、推理、阅读理解和偏见的微调任务。通过评估模型在这些任务上的表现来衡量其知识保留能力和灾难性遗忘的程度。

Result: 在领域知识方面，两种模型都有所提升。然而，在推理和阅读理解方面，两种模型都出现了随时间退化的现象，表明存在灾难性遗忘。Stack LLM 在这些任务上的退化程度较低，尤其是在阅读理解方面。在偏见评估方面，基线LLM在持续微调过程中变得越来越中立，而Stack LLM则将偏见比例维持在60-61%左右。

Conclusion: 模型增长策略，特别是通过Transformer堆叠，可能在抵抗灾难性遗忘方面提供适度的改进，尤其是在阅读理解等任务上。然而，在处理社会偏见方面，这种策略可能存在权衡，因为它倾向于维持现有的偏见比例，而不是使其变得中立。

Abstract: Catastrophic forgetting is a significant challenge in continual learning, in
which a model loses prior knowledge when it is fine-tuned on new tasks. This
problem is particularly critical for large language models (LLMs) undergoing
continual learning, as retaining performance across diverse domains is
important for their general utility. In this paper, we explore model growth, a
promising strategy that leverages smaller models to expedite and structure the
training of larger ones for mitigating the catastrophic forgetting problem.
Although growth-based pretraining, particularly via transformer stacking, has
shown promise in accelerating convergence, its impact on forgetting remains
under-explored. Therefore, we evaluate whether growth-based models can retain
previously learned capabilities more effectively across a sequence of
fine-tuning tasks involving domain knowledge, reasoning, reading comprehension,
and bias. Our findings show that both models -- one trained with growth (Stack
LLM) and one without (LLM) -- exhibit improvements in domain knowledge.
However, reasoning and reading comprehension degrade over time, indicating
signs of catastrophic forgetting. Stack LLM consistently shows less
degradation, especially in reading comprehension, suggesting enhanced retention
capabilities. Interestingly, in bias evaluation, the baseline LLM becomes
progressively more neutral with continued fine-tuning, while Stack LLM
maintains a steady bias ratio around 60--61\%. These results indicate that
growth-based pretraining may deliver modest improvements in resisting
catastrophic forgetting, though trade-offs remain in handling social biases.

</details>


### [286] [DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Taks Based on Data and Model Compression](https://arxiv.org/abs/2509.01221)
*Wei Huang,Huang Wei,Yinggui Wang*

Main category: cs.CL

TL;DR: DaMoC框架通过数据和模型压缩，帮助用户快速选择最优的大型语言模型进行微调，显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在通用任务上表现优异，但在领域特定任务上需要进行微调。面对众多开源模型，如何快速筛选出适合下游任务的最佳模型是一个关键挑战。

Method: 1. 数据层面：建立了系统的数据过滤方法分类，包括分布感知、质量感知和混合方法。通过增强文本关键标记的密度实现标记压缩，并利用大型语言模型迭代改写文本以优化表达。
2. 模型层面：使用层相似性得分评估层的重要性并移除不重要的层。引入稀疏合并范式以最大限度地保留原始模型的能力。

Result: 在医学问答、金融问答、通用问答和阅读理解四个数据集上进行的大量实验表明，该框架能在节省约20倍训练时间的同时，选择出最优的大型语言模型。

Conclusion: DaMoC框架能够有效解决选择领域特定任务的最佳大型语言模型这一挑战，并通过数据和模型压缩技术显著提高效率。

Abstract: Large language models (LLMs) excel in general tasks but struggle with
domain-specific ones, requiring fine-tuning with specific data. With many
open-source LLMs available, selecting the best model for fine-tuning downstream
tasks is challenging, primarily focusing on how to quickly identify the optimal
LLM. We introduce a Data and Model Compression Framework (DaMoC) that addresses
this challenge by: 1) Data Level: A systematic categorization of data filtering
methodologies for LLMs is first established, classifying them into three
distinct paradigms: (1) distribution-aware methods, (2) quality-aware methods,
and (3) hybrid approaches considering both dimensions. Further, we enhance the
density of key tokens in the text achieving token compression. Subsequently, we
use an LLM to iterative rewrite the text to optimize its expression. 2) Model
Level: We use layer similarity scores to assess each layer's importance and
remove those with lower importance. Then, we introduce a sparse merging
paradigm to preserve as much of the original model's capability as possible.
Extensive experiments on four datasets, medical Q&A, financial Q&A, general
Q&A, and reading comprehension, show that we can select the optimal LLM while
saving approximately 20-fold in training time.

</details>


### [287] [Rethinking the Chain-of-Thought: The Roles of In-Context Learning and Pre-trained Priors](https://arxiv.org/abs/2509.01236)
*Hao Yang,Zhiyu Yang,Yunjie Zhang,Shanyi Zhu,Lin Yang*

Main category: cs.CL

TL;DR: Chain-of-Thought (CoT) reasoning mechanisms are explored through in-context learning and pretrained priors. The model learns lexical and logical patterns, relying on priors. Sufficient exemplars shift focus to in-context signals, while noisy prompts cause instability. Long CoT prompts improve performance by inducing longer reasoning chains.


<details>
  <summary>Details</summary>
Motivation: To understand the unclear working mechanisms of Chain-of-Thought (CoT) reasoning by examining its relationship with in-context learning and pretrained priors.

Method: 1. Fine-grained lexical-level analysis of rationales to examine model's reasoning behavior. 2. Introducing noisy exemplars to examine how the model balances pretrained priors against erroneous in-context information. 3. Investigating whether prompt engineering can induce slow thinking in large language models.

Result: (1) The model quickly learns lexical-level reasoning structure and deeper logical patterns, heavily relying on pretrained priors. (2) Sufficient exemplars shift the model's decision-making from pretrained priors to in-context signals; misleading prompts introduce instability. (3) Long CoT prompting induces longer reasoning chains, improving downstream task performance.

Conclusion: The paper clarifies CoT reasoning mechanisms, showing reliance on pretrained priors, the impact of exemplar quantity on signal preference, and the benefit of long CoT prompts for performance improvement.

Abstract: Chain-of-Thought reasoning has emerged as a pivotal methodology for enhancing
model inference capabilities. Despite growing interest in Chain-of-Thought
reasoning, its underlying mechanisms remain unclear. This paper explores the
working mechanisms of Chain-of-Thought reasoning from the perspective of the
dual relationship between in-context learning and pretrained priors. We first
conduct a fine-grained lexical-level analysis of rationales to examine the
model's reasoning behavior. Then, by incrementally introducing noisy exemplars,
we examine how the model balances pretrained priors against erroneous
in-context information. Finally, we investigate whether prompt engineering can
induce slow thinking in large language models. Our extensive experiments reveal
three key findings: (1) The model not only quickly learns the reasoning
structure at the lexical level but also grasps deeper logical reasoning
patterns, yet it heavily relies on pretrained priors. (2) Providing sufficient
exemplars shifts the model's decision-making from pretrained priors to
in-context signals, while misleading prompts introduce instability. (3) Long
Chain-of-Thought prompting can induce the model to generate longer reasoning
chains, thereby improving its performance on downstream tasks.

</details>


### [288] [Annotation and modeling of emotions in a textual corpus: an evaluative approach](https://arxiv.org/abs/2509.01260)
*Jonas Noblet*

Main category: cs.CL

TL;DR: 本文研究了文本情感分析，利用了手动标注的工业语料库和一个鲜为人知的评估方法。研究表明，尽管标注存在分歧，但模型仍能学习标注过程并识别情感线索。


<details>
  <summary>Details</summary>
Motivation: 情感是人类社会功能的重要组成部分，但在文本中的表达方式仍是开放的研究领域。本研究旨在利用评估方法分析文本情感，并探索语言模型在处理带有人类标注分歧的数据时的能力。

Method: 本研究使用了一个手动标注的工业语料库，并采用了评估方法来标注情感。然后，研究人员利用语言模型对这些标注进行训练，以模拟标注过程并识别驱动变异性的语言特征。

Result: 研究结果表明，尽管标注存在显著分歧，但语言模型能够学习标注过程，并且这种变异性是由潜在的语言特征驱动的。此外，研究还表明，语言模型能够根据评估标准区分不同的情感情境。

Conclusion: 本研究证明了使用语言模型对带有显著分歧的人类标注进行建模是可行的，并且揭示了变异性与语言特征之间的关系。研究结果还表明，语言模型在区分情感情境方面具有潜力，为文本情感分析提供了新的视角。

Abstract: Emotion is a crucial phenomenon in the functioning of human beings in
society. However, it remains a widely open subject, particularly in its textual
manifestations. This paper examines an industrial corpus manually annotated
following an evaluative approach to emotion. This theoretical framework, which
is currently underutilized, offers a different perspective that complements
traditional approaches. Noting that the annotations we collected exhibit
significant disagreement, we hypothesized that they nonetheless follow stable
statistical trends. Using language models trained on these annotations, we
demonstrate that it is possible to model the labeling process and that
variability is driven by underlying linguistic features. Conversely, our
results indicate that language models seem capable of distinguishing emotional
situations based on evaluative criteria.

</details>


### [289] [Culture is Everywhere: A Call for Intentionally Cultural Evaluation](https://arxiv.org/abs/2509.01301)
*Juhyun Oh,Inha Cha,Michael Saxon,Hyunseung Lim,Shaily Bhatt,Alice Oh*

Main category: cs.CL

TL;DR: 现有以“知识问答”为中心的评估大语言模型（LLM）文化契合度的方法存在不足，忽略了文化的多元性和互动性。本文提出“意向性文化评估”方法，系统性地审视评估的各个方面，包括评估设置中的文化假设，并强调研究者立场的重要性。文章还探讨了超越现有基准测试实践、发现潜在应用以及通过以用户为中心的参与式方法让社区参与评估设计的未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有以“知识问答”为中心的评估大语言模型（LLM）文化契合度的方法不足，未能涵盖文化的多元性和互动性，且忽略了文化假设在评估中的普遍存在。

Method: 提出“意向性文化评估”方法，系统性地考察评估的各个方面（包括评估设置本身）中存在的文化依赖性考量，并强调研究者立场对于促进包容性和文化契合的NLP研究的重要性。

Result: 文章为超越现有基准测试实践、发现目前未知的LLM应用以及通过用户体验研究（HCI）的参与式方法让社区参与评估设计提供了启示和未来方向。

Conclusion: 为促进更具包容性和文化契合的NLP研究，应采取“意向性文化评估”方法，系统性地审视评估的各个方面，并重视研究者在评估设计中的立场。

Abstract: The prevailing ``trivia-centered paradigm'' for evaluating the cultural
alignment of large language models (LLMs) is increasingly inadequate as these
models become more advanced and widely deployed. Existing approaches typically
reduce culture to static facts or values, testing models via multiple-choice or
short-answer questions that treat culture as isolated trivia. Such methods
neglect the pluralistic and interactive realities of culture, and overlook how
cultural assumptions permeate even ostensibly ``neutral'' evaluation settings.
In this position paper, we argue for \textbf{intentionally cultural
evaluation}: an approach that systematically examines the cultural assumptions
embedded in all aspects of evaluation, not just in explicitly cultural tasks.
We systematically characterize the what, how, and circumstances by which
culturally contingent considerations arise in evaluation, and emphasize the
importance of researcher positionality for fostering inclusive, culturally
aligned NLP research. Finally, we discuss implications and future directions
for moving beyond current benchmarking practices, discovering important
applications that we don't know exist, and involving communities in evaluation
design through HCI-inspired participatory methodologies.

</details>


### [290] [TableZoomer: A Collaborative Agent Framework for Large-scale Table Question Answering](https://arxiv.org/abs/2509.01312)
*Sishi Xiong,Ziyang He,Zhongjiang He,Yu Zhao,Changzai Pan,Jie Zhang,Zhenhe Wu,Shuangyong Song,Yongxiang Li*

Main category: cs.CL

TL;DR: TableZoomer是一个新颖的LLM驱动的、基于编程的代理框架，用于表格问答（TQA），通过结构化表格模式、查询感知缩放和PoT策略解决了LLM在TQA中的挑战，提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在表格问答（TQA）任务中显示出潜力，但在工业应用中面临结构异构性、目标数据定位困难和复杂推理瓶颈等挑战。

Method: TableZoomer框架引入了三个关键创新：1. 用结构化表模式替换原始的完全口语化表，以弥合语义差距并降低计算复杂度。2. 查询感知的表格缩放机制，通过列选择和实体链接动态生成子表模式，显著提高了目标定位效率。3. 程序思考（PoT）策略，将查询转换为可执行代码，以减轻数值幻觉。此外，还集成了ReAct范式以实现迭代推理。

Result: TableZoomer在各种规模的表格上保持了可用性优势，同时显著提高了性能和可扩展性。与Qwen3-8B-Instruct LLM结合使用时，TableZoomer在DataBench数据集和TableBench数据集的事实核查任务上，准确率分别比传统的PoT方法提高了19.34%和25%。

Conclusion: TableZoomer通过其创新的框架和策略，有效解决了LLM在TQA任务中的挑战，并在性能和可扩展性方面取得了显著的改进。

Abstract: While large language models (LLMs) have shown promise in the table question
answering (TQA) task through prompt engineering, they face challenges in
industrial applications, including structural heterogeneity, difficulties in
target data localization, and bottlenecks in complex reasoning. To address
these limitations, this paper presents TableZoomer, a novel LLM-powered,
programming-based agent framework. It introduces three key innovations: (1)
replacing the original fully verbalized table with structured table schema to
bridge the semantic gap and reduce computational complexity; (2) a query-aware
table zooming mechanism that dynamically generates sub-table schema through
column selection and entity linking, significantly improving target
localization efficiency; and (3) a Program-of-Thoughts (PoT) strategy that
transforms queries into executable code to mitigate numerical hallucination.
Additionally, we integrate the reasoning workflow with the ReAct paradigm to
enable iterative reasoning. Extensive experiments demonstrate that our
framework maintains the usability advantages while substantially enhancing
performance and scalability across tables of varying scales. When implemented
with the Qwen3-8B-Instruct LLM, TableZoomer achieves accuracy improvements of
19.34% and 25% over conventional PoT methods on the large-scale DataBench
dataset and the small-scale Fact Checking task of TableBench dataset,
respectively.

</details>


### [291] [Can Smaller LLMs do better? Unlocking Cross-Domain Potential through Parameter-Efficient Fine-Tuning for Text Summarization](https://arxiv.org/abs/2509.01314)
*Anum Afzal,Mehul Kumawat,Florian Matthes*

Main category: cs.CL

TL;DR: LLMs可以进行参数高效微调（PEFT），以适应新的、低资源领域。实验表明，与少样本学习和更大的模型相比，特定领域内适配器（Within-Domain Adapters）在低资源领域表现更好。


<details>
  <summary>Details</summary>
Motivation: LLMs的领域适应能力和低资源领域微调的挑战。

Method: 利用PEFT技术，在科学、医学、法律和新闻领域，针对文本摘要任务，在Llama-3-8B-Instruct模型上对六种PEFT方法进行基准测试，并探索了跨域适配器和适配器组合。

Result: 对于低资源领域，使用特定领域内适配器（Within-Domain Adapters）的推理比少样本学习和更大的Llama-3-70B-Instruct模型表现更好。在没有特定领域内适配器的情况下，跨域适配器和适配器组合可以提高低资源场景的适应性和性能。

Conclusion: PEFT技术，特别是Within-Domain Adapters，能够有效地提高LLMs在低资源领域进行领域适应的能力，并且通过跨域适配器和适配器组合可以进一步优化性能。

Abstract: Large Language Models (LLMs), being generic task solvers, are versatile.
However, despite the vast amount of data they are trained on, there are
speculations about their adaptation capabilities to a new domain. Additionally,
the simple fine-tuning of the model to incorporate knowledge of a new domain is
computationally expensive and time-consuming. This becomes more challenging
when the domain in question is also low-resource, and labeled data is
unavailable. We leverage parameter-efficient fine-tuning techniques (PEFTs) on
high-resource datasets to address these challenges to improve performance on
unseen low-resource domains. Throughout our experiments, we evaluate whether
intrinsic linguistic commonalities between datasets can be leveraged for
efficient domain adaptation. We benchmark six PEFTs with
\texttt{Llama-3-8B-Instruct} on 14 training datasets from the Scientific,
Medical, Legal, and News domains for a Text Summarization task. Our experiments
show that for low-resource domains, inference using Within-Domain Adapters can
achieve better performance than Few-Shot as well as a much larger
\texttt{Llama-3-70B-Instruct}. Lastly, in the absence of Within-Domain
Adapters, we explore the concept of using Cross-Domain Adapters as well as the
strategic combinations of adapters to leverage intrinsic language similarities
across domains, facilitating better adaptability and performance in
low-resource settings.

</details>


### [292] [KoBLEX: Open Legal Question Answering with Multi-hop Reasoning](https://arxiv.org/abs/2509.01324)
*Jihyung Lee,Daehui Kim,Seonjeong Hwang,Hyounghun Kim,Gary Lee*

Main category: cs.CL

TL;DR: 该论文提出KoBLEX基准和ParSeR方法来评估和改进大型语言模型在韩国法律领域的开放式、基于条款的可解释问答能力。


<details>
  <summary>Details</summary>
Motivation: 现有的法律基准未能充分评估开放式、基于条款的法律问答能力，因此需要新的评估方法。

Method: 提出KoBLEX基准，包含226个基于场景的问答实例及其支持条款，通过混合LLM-人类专家流程创建。提出ParSeR方法，利用LLM生成的参数化条款来指导法律上合理且可靠的答案，并通过三阶段顺序检索促进多跳推理。提出LF-Eval自动评估指标，以更好地评估生成答案的法律保真度。

Result: ParSeR方法在多个LLM上持续优于强基线，并在F1分数和LF-Eval指标上显著优于标准检索方法（例如，与GPT-4o相比，F1提高+37.91，LF-Eval提高+30.81）。进一步的分析表明，ParSeR在不同推理深度下都能实现一致的性能。

Conclusion: KoBLEX基准和ParSeR方法能够有效评估和改进大型语言模型在韩国法律领域的问答能力，LF-Eval则能准确评估答案的法律保真度。

Abstract: Large Language Models (LLM) have achieved remarkable performances in general
domains and are now extending into the expert domain of law. Several benchmarks
have been proposed to evaluate LLMs' legal capabilities. However, these
benchmarks fail to evaluate open-ended and provision-grounded Question
Answering (QA). To address this, we introduce a Korean Benchmark for Legal
EXplainable QA (KoBLEX), designed to evaluate provision-grounded, multi-hop
legal reasoning. KoBLEX includes 226 scenario-based QA instances and their
supporting provisions, created using a hybrid LLM-human expert pipeline. We
also propose a method called Parametric provision-guided Selection Retrieval
(ParSeR), which uses LLM-generated parametric provisions to guide legally
grounded and reliable answers. ParSeR facilitates multi-hop reasoning on
complex legal questions by generating parametric provisions and employing a
three-stage sequential retrieval process. Furthermore, to better evaluate the
legal fidelity of the generated answers, we propose Legal Fidelity Evaluation
(LF-Eval). LF-Eval is an automatic metric that jointly considers the question,
answer, and supporting provisions and shows a high correlation with human
judgments. Experimental results show that ParSeR consistently outperforms
strong baselines, achieving the best results across multiple LLMs. Notably,
compared to standard retrieval with GPT-4o, ParSeR achieves +37.91 higher F1
and +30.81 higher LF-Eval. Further analyses reveal that ParSeR efficiently
delivers consistent performance across reasoning depths, with ablations
confirming the effectiveness of ParSeR.

</details>


### [293] [Can Large Language Models Master Complex Card Games?](https://arxiv.org/abs/2509.01328)
*Wei Wang,Fuqing Bie,Junzhe Chen,Dan Zhang,Shiyu Huang,Evgeny Kharlamov,Jie Tang*

Main category: cs.CL

TL;DR: 大型语言模型（LLMs）在复杂纸牌游戏中展现出强大的学习能力和通用性，通过监督微调可以接近顶级游戏AI的性能，并能同时掌握多个游戏，但通用能力会下降，可通过整合通用指令数据缓解。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在复杂纸牌游戏中的潜力和学习能力，以及微调和同时掌握多个游戏的影响。

Method: 在八种不同的纸牌游戏中系统地评估LLMs的学习能力，包括微调高质量游戏数据的影响，并检查模型在掌握游戏时保留通用能力的能力。

Result: 1. LLMs通过监督微调高质量数据，其性能可接近强大的游戏AI。 2. LLMs可以同时掌握多个复杂纸牌游戏，规则相似的游戏性能会增强，规则不相似的游戏则存在冲突。 3. LLMs在掌握复杂游戏时通用能力会下降，但可以通过整合一定量的通用指令数据来缓解。

Conclusion: LLMs在复杂纸牌游戏中具有很强的学习能力和通用性，尽管在掌握游戏过程中通用能力会下降，但可以通过特定策略进行缓解。

Abstract: Complex games have long been an important benchmark for testing the progress
of artificial intelligence algorithms. AlphaGo, AlphaZero, and MuZero have
defeated top human players in Go and Chess, garnering widespread societal
attention towards artificial intelligence. Concurrently, large language models
(LLMs) have exhibited remarkable capabilities across various tasks, raising the
question of whether LLMs can achieve similar success in complex games. In this
paper, we explore the potential of LLMs in mastering complex card games. We
systematically assess the learning capabilities of LLMs across eight diverse
card games, evaluating the impact of fine-tuning on high-quality gameplay data,
and examining the models' ability to retain general capabilities while
mastering these games. Our findings indicate that: (1) LLMs can approach the
performance of strong game AIs through supervised fine-tuning on high-quality
data, (2) LLMs can master multiple complex card games simultaneously, with
performance augmentation for games with similar rules and conflicts for
dissimilar ones, and (3) LLMs experience a decline in general capabilities when
mastering complex games, but this decline can be mitigated by integrating a
certain amount of general instruction data. The evaluation results demonstrate
strong learning ability and versatility of LLMs.

</details>


### [294] [Reasoning Vectors: Transferring Chain-of-Thought Capabilities via Task Arithmetic](https://arxiv.org/abs/2509.01363)
*Mohammad Zbeeb,Hasan Abed Al Kader Hammoud,Bernard Ghanem*

Main category: cs.CL

TL;DR: 研究表明，大型语言模型通过强化学习获得的推理能力可以被提取并以任务向量的形式在模型间转移，通过向量加法可以提升模型在多项推理任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常需要昂贵的优化（如强化学习）来掌握复杂的推理任务，而这项工作旨在展示推理能力可以被提取并转移。

Method: 通过计算两个相同初始化的Qwen2.5模型（一个经过监督微调SFT，另一个经过GRPO）的参数差值（$v_{	ext{reason}} = 	heta_{	ext{GRPO}} - 	heta_{	ext{SFT}}$）来提取推理向量，并将其加到其他模型上进行测试。

Result: 将提取的推理向量添加到兼容模型后，在GSM8K、HumanEval、SciQ和BigBenchHard等推理基准上观察到性能提升，并且在对抗性条件下也保持了性能。相反，减去该向量会导致性能显著下降。

Conclusion: 推理能力可以从现有的开源模型中提取并以简单张量运算的形式进行重用，为增强模型提供了一种实用的方法，可以回收之前的计算投入。

Abstract: Large language models often require costly optimization, such as
reinforcement learning, to master complex reasoning tasks. This work
demonstrates that reasoning ability, once learned, can be extracted and
transferred between models as a compact task vector. We source two publicly
available, identically initialized Qwen2.5 models, one fine-tuned with
supervised fine-tuning (SFT) and the other with group relative policy
optimization (GRPO) on the same dataset. From these, we extract a reasoning
vector: $v_{\text{reason}} = \theta_{\text{GRPO}} - \theta_{\text{SFT}}$. We
hypothesize that this vector captures the reasoning capability instilled by
reinforcement learning while factoring out shared knowledge from the SFT
process. When added to compatible instruction-tuned models through simple
arithmetic, this vector consistently improves performance across diverse
reasoning benchmarks: GSM8K (+4.9%), HumanEval (+4.3%), SciQ (+1.7%), and
BigBenchHard (+12.3% for the 1.5B model). The performance improvements persist
under adversarial conditions. Conversely, subtracting the vector causes
significant performance degradation (-11.8% on GSM8K), demonstrating the
vector's strong contribution to the model's reasoning abilities. This work
shows how reasoning capabilities, typically developed through expensive
training, can be extracted from existing open-source models and reused through
simple tensor arithmetic, offering a practical way to enhance models by
recycling prior computational investments.

</details>


### [295] [WATCHED: A Web AI Agent Tool for Combating Hate Speech by Expanding Data](https://arxiv.org/abs/2509.01379)
*Paloma Piot,Diego Sánchez,Javier Parapar*

Main category: cs.CL

TL;DR: WATCHED是一个旨在协助内容审核员处理仇恨言论的聊天机器人，它结合了大型语言模型和多种专业工具，能够检测仇恨言论并提供基于先例和政策的解释，实验结果显示其效果优于现有最先进的方法。


<details>
  <summary>Details</summary>
Motivation: 在线危害日益严重，尤其是仇恨言论，需要结合自动化系统和人类判断力的工具来提高用户安全和平台信任度。

Method: 使用大型语言模型和专业工具构建了一个人工智能代理系统，通过比较新帖子与仇恨言论和中性内容的示例、使用基于BERT的分类器进行标记、利用Urban Dictionary等资源查找俚语、生成链式思考推理以及检查平台指南来解释和支持其决策。

Result: 提出的方法在仇恨言论检测方面超越了现有的最先进方法，达到了0.91的宏观F1分数。

Conclusion: WATCHED通过结合AI和人工监督的协作，帮助减少在线危害，适用于审核员、安全团队和研究人员。

Abstract: Online harms are a growing problem in digital spaces, putting user safety at
risk and reducing trust in social media platforms. One of the most persistent
forms of harm is hate speech. To address this, we need tools that combine the
speed and scale of automated systems with the judgment and insight of human
moderators. These tools should not only find harmful content but also explain
their decisions clearly, helping to build trust and understanding. In this
paper, we present WATCHED, a chatbot designed to support content moderators in
tackling hate speech. The chatbot is built as an Artificial Intelligence Agent
system that uses Large Language Models along with several specialised tools. It
compares new posts with real examples of hate speech and neutral content, uses
a BERT-based classifier to help flag harmful messages, looks up slang and
informal language using sources like Urban Dictionary, generates
chain-of-thought reasoning, and checks platform guidelines to explain and
support its decisions. This combination allows the chatbot not only to detect
hate speech but to explain why content is considered harmful, grounded in both
precedent and policy. Experimental results show that our proposed method
surpasses existing state-of-the-art methods, reaching a macro F1 score of 0.91.
Designed for moderators, safety teams, and researchers, the tool helps reduce
online harms by supporting collaboration between AI and human oversight.

</details>


### [296] [ABCD-LINK: Annotation Bootstrapping for Cross-Document Fine-Grained Links](https://arxiv.org/abs/2509.01387)
*Serwar Basch,Ilia Kuznetsov,Tom Hope,Iryna Gurevych*

Main category: cs.CL

TL;DR: 本文提出了一个领域无关的框架，用于从头开始在新领域中选择最佳方法和注释跨文档链接。通过生成和验证半合成数据集进行自动评估，然后进行人类评估，最终发现结合检索模型和大型语言模型（LLMs）的方法在链接审批率上表现最佳，达到78%。该框架支持跨文档理解的系统性研究，并提供了新的数据集，可用于媒体框架和同行评审等任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究在自动创建跨文档链接的训练和评估数据集方面存在效率低下，限制了对理解文档间细粒度关系的研究。

Method: 1. 生成并验证用于链接的半合成数据集。
2. 利用这些数据集对不同的链接方法进行自动评估，筛选出表现最佳的方法。
3. 对筛选出的方法进行广泛的人类评估，以获得在自然文本对上的性能估计。
4. 将该框架应用于同行评审和新闻两个不同领域。

Result: 结合检索模型和大型语言模型（LLMs）的方法在人类评估中实现了78%的链接审批率，将单独使用检索模型的精确度提高了一倍以上。

Conclusion: 提出的框架能够系统地研究跨应用程序场景的跨文档理解，并且生成的新的数据集为媒体框架和同行评审等多种跨文档任务奠定了基础。作者公开了代码、数据和注释协议。

Abstract: Understanding fine-grained relations between documents is crucial for many
application domains. However, the study of automated assistance is limited by
the lack of efficient methods to create training and evaluation datasets of
cross-document links. To address this, we introduce a new domain-agnostic
framework for selecting a best-performing approach and annotating
cross-document links in a new domain from scratch. We first generate and
validate semi-synthetic datasets of interconnected documents. This data is used
to perform automatic evaluation, producing a shortlist of best-performing
linking approaches. These approaches are then used in an extensive human
evaluation study, yielding performance estimates on natural text pairs. We
apply our framework in two distinct domains -- peer review and news -- and show
that combining retrieval models with LLMs achieves 78\% link approval from
human raters, more than doubling the precision of strong retrievers alone. Our
framework enables systematic study of cross-document understanding across
application scenarios, and the resulting novel datasets lay foundation for
numerous cross-document tasks like media framing and peer review. We make the
code, data, and annotation protocols openly available.

</details>


### [297] [Analysing the Language of Neural Audio Codecs](https://arxiv.org/abs/2509.01390)
*Joonyong Park,Shinnosuke Takamichi,David M. Chan,Shunsuke Kando,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.CL

TL;DR: 本研究对神经音频编解码器（NAC）的统计和语言特性进行了比较分析，发现NAC生成的离散语音令牌遵循类似语言的统计规律（如齐夫定律和希普定律），并且这些特性与语音识别和再合成任务的性能相关。


<details>
  <summary>Details</summary>
Motivation: 研究神经音频编解码器（NAC）产生的离散语音令牌的统计和语言特性，并探讨这些特性与语音合成的语义和声学保留之间的关系。

Method: 分析了不同NAC模型产生的离散语音令牌，检查了它们是否符合齐夫定律和希普定律等语言统计定律，并评估了熵和冗余度。通过自动语音识别错误率和UTMOS分数来评估可懂度和质量，以衡量令牌级属性与语义和声学保留的关系。

Result: NAC令牌，特别是3-grams，表现出类似语言的统计模式。此外，这些属性以及信息含量测量值与改进的语音识别和再合成任务性能相关。

Conclusion: NAC令牌序列的结构具有洞察力，这些发现为设计更有效的生成语音模型提供了信息。

Abstract: This study presents a comparative analysis of the statistical and linguistic
properties of neural audio codecs (NACs). We investigate discrete speech tokens
produced by various NAC models, examining their adherence to linguistic
statistical laws such as Zipf's law and Heaps' law, as well as their entropy
and redundancy. To assess how these token-level properties relate to semantic
and acoustic preservation in synthesized speech, we evaluate intelligibility
using error rates of automatic speech recognition, and quality using the UTMOS
score. Our results reveal that NAC tokens, particularly 3-grams, exhibit
language-like statistical patterns. Moreover, these properties, together with
measures of information content, are found to correlate with improved
performances in speech recognition and resynthesis tasks. These findings offer
insights into the structure of NAC token sequences and inform the design of
more effective generative speech models.

</details>


### [298] [LLMs cannot spot math errors, even when allowed to peek into the solution](https://arxiv.org/abs/2509.01395)
*KV Aditya Srivatsa,Kaushal Kumar Maurya,Ekaterina Kochmar*

Main category: cs.CL

TL;DR: LLMs 在解决数学应用题方面表现出色，但在元推理任务（例如找出学生解题中的错误）方面存在困难。本研究旨在解决在分步解题中定位第一个错误步骤的挑战，并提出一种生成中间修正解题的方法，以提高 LLM 的性能。


<details>
  <summary>Details</summary>
Motivation: LLMs 在元推理任务，特别是识别学生解题错误方面表现不佳，本研究旨在提高 LLMs 在定位分步解题中第一个错误步骤的能力。

Method: 使用 VtG 和 PRM800K 两个错误推理数据集进行实验，并提出一种生成中间修正学生解题的方法，使其更接近原始学生解题，从而提高性能。

Result: 实验表明，即使有参考答案，最先进的 LLMs 在定位学生解题中的第一个错误步骤方面仍然存在困难。所提出的方法通过生成中间修正解题，在提高性能方面有所帮助。

Conclusion: LLMs 在定位学生解题的第一个错误步骤方面存在挑战，但通过生成中间修正解题的方法可以有效改善这一状况。

Abstract: Large language models (LLMs) demonstrate remarkable performance on math word
problems, yet they have been shown to struggle with meta-reasoning tasks such
as identifying errors in student solutions. In this work, we investigate the
challenge of locating the first error step in stepwise solutions using two
error reasoning datasets: VtG and PRM800K. Our experiments show that
state-of-the-art LLMs struggle to locate the first error step in student
solutions even when given access to the reference solution. To that end, we
propose an approach that generates an intermediate corrected student solution,
aligning more closely with the original student's solution, which helps improve
performance.

</details>


### [299] [Vis-CoT: A Human-in-the-Loop Framework for Interactive Visualization and Intervention in LLM Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.01412)
*Kaviraj Pather,Elena Hadjigeorgiou,Arben Krasniqi,Claire Schmit,Irina Rusu,Marc Pons,Kabir Khan*

Main category: cs.CL

TL;DR: LLMs的链式思考（CoT）过程不透明，难以在关键场景下进行验证、调试和控制。我们提出了Vis-CoT框架，将线性的CoT文本转化为交互式推理图，允许用户可视化逻辑流程、识别错误步骤，并通过剪枝和嫁接来干预推理过程，从而提高模型准确性和可信度。


<details>
  <summary>Details</summary>
Motivation: LLMs的链式思考（CoT）过程不透明，给验证、调试和控制带来困难，尤其是在高风险应用中。

Method: 将线性的CoT文本转换为交互式的推理图，用户可以可视化逻辑流程、识别错误、剪枝错误路径、添加新的用户定义前提，实现人机协作。

Result: 在GSM8K和StrategyQA数据集上，Vis-CoT将最终答案的准确率比非交互式基线提高了24个百分点。用户研究表明，Vis-CoT在可用性和信任度方面也有显著提升。

Conclusion: Vis-CoT提供了一种实用的方法，通过结合LLMs和人类监督，实现更可靠、更易理解和更具协作性的推理。

Abstract: Large language models (LLMs) show strong reasoning via chain-of-thought (CoT)
prompting, but the process is opaque, which makes verification, debugging, and
control difficult in high-stakes settings. We present Vis-CoT, a
human-in-the-loop framework that converts linear CoT text into an interactive
reasoning graph. Users can visualize the logical flow, identify flawed steps,
and intervene by pruning incorrect paths and grafting new, user-defined
premises. This shifts interaction from passive observation to active
collaboration, steering models toward more accurate and trustworthy
conclusions. Across GSM8K and StrategyQA, Vis-CoT improves final-answer
accuracy by up to 24 percentage points over non-interactive baselines. A user
study also shows large gains in perceived usability and trust. Vis-CoT points
to a practical path for more reliable, understandable, and collaborative
reasoning by combining LLMs with targeted human oversight.

</details>


### [300] [On the Alignment of Large Language Models with Global Human Opinion](https://arxiv.org/abs/2509.01418)
*Yang Liu,Masahiro Kaneko,Chenhui Chu*

Main category: cs.CL

TL;DR: LLMs在多语言场景下能满足用户需求，但其观点可能受用户互动语言影响。现有研究多集中于美国人群，缺乏全球及历史视角。本研究提出基于世界价值观调查（WVS）的评估框架，系统评估LLMs在全球、语言和历史维度上与人类观点的对齐程度。研究发现，LLMs在少数国家表现出适当或过度对齐，而在大多数国家则表现为低度对齐。此外，使用与问卷语言匹配的提示语言能更有效地引导LLMs对齐相应国家观点，优于现有方法。LLMs与当代人群观点对齐度更高。本研究为首次全面探讨LLMs在全球、语言和时间维度上的观点对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注美国人群的观点对齐，缺乏全球样本和历史时期的数据，也未探讨语言对LLM观点对齐的影响。本研究旨在填补这些空白。

Method: 构建基于世界价值观调查（WVS）的评估框架，用于系统评估LLM在全球、语言和历史时期与人类观点的对齐情况。

Result: LLM在少数国家表现出适当或过度对齐，在大多数国家表现为低度对齐。使用与问卷语言匹配的提示语言能更有效地引导LLM对齐相应国家观点。LLM与当代人群观点对齐度更高。

Conclusion: 本研究是首次全面调查LLM在全球、语言和时间维度上观点对齐问题的研究。

Abstract: Today's large language models (LLMs) are capable of supporting multilingual
scenarios, allowing users to interact with LLMs in their native languages. When
LLMs respond to subjective questions posed by users, they are expected to align
with the views of specific demographic groups or historical periods, shaped by
the language in which the user interacts with the model. Existing studies
mainly focus on researching the opinions represented by LLMs among demographic
groups in the United States or a few countries, lacking worldwide country
samples and studies on human opinions in different historical periods, as well
as lacking discussion on using language to steer LLMs. Moreover, they also
overlook the potential influence of prompt language on the alignment of LLMs'
opinions. In this study, our goal is to fill these gaps. To this end, we create
an evaluation framework based on the World Values Survey (WVS) to
systematically assess the alignment of LLMs with human opinions across
different countries, languages, and historical periods around the world. We
find that LLMs appropriately or over-align the opinions with only a few
countries while under-aligning the opinions with most countries. Furthermore,
changing the language of the prompt to match the language used in the
questionnaire can effectively steer LLMs to align with the opinions of the
corresponding country more effectively than existing steering methods. At the
same time, LLMs are more aligned with the opinions of the contemporary
population. To our knowledge, our study is the first comprehensive
investigation of the topic of opinion alignment in LLMs across global,
language, and temporal dimensions. Our code and data are publicly available at
https://github.com/nlply/global-opinion-alignment.

</details>


### [301] [Trusted Uncertainty in Large Language Models: A Unified Framework for Confidence Calibration and Risk-Controlled Refusal](https://arxiv.org/abs/2509.01455)
*Markus Oehri,Giulia Conti,Kaviraj Pather,Alexandre Rossi,Laia Serra,Adrian Parody,Rogvi Johannesen,Aviaja Petersen,Arben Krasniqi*

Main category: cs.CL

TL;DR: UniCR是一个统一框架，将各种不确定性证据（如序列似然、自洽性分散、检索兼容性、工具或验证器反馈）转化为经过校准的正确性概率，并通过原则性拒绝来强制执行用户指定的错误预算。


<details>
  <summary>Details</summary>
Motivation: 部署的语言模型不仅要决定回答什么，还要决定何时不回答。

Method: UniCR通过轻量级校准头（具有温度缩放和适当评分）学习，支持通过黑盒特征的仅API模型，并使用保形风险控制提供无分布保证。对于长格式生成，通过在源自检索证据的原子事实性分数上进行监督，将置信度与语义保真度对齐，以减少自信的幻觉，同时保持覆盖范围。

Result: 在短格式问答、带执行测试的代码生成和检索增强的长格式问答上的实验表明，与熵或logit阈值、事后校准器和端到端选择性基线相比，UniCR在校准指标、风险覆盖曲线下面积和固定风险下的覆盖范围方面持续提高。

Conclusion: UniCR是一个可移植的证据融合到校准概率到风险控制决策的方案，在不调整基础模型的情况下提高了可信度，并在分布转变下保持有效。

Abstract: Deployed language models must decide not only what to answer but also when
not to answer. We present UniCR, a unified framework that turns heterogeneous
uncertainty evidence including sequence likelihoods, self-consistency
dispersion, retrieval compatibility, and tool or verifier feedback into a
calibrated probability of correctness and then enforces a user-specified error
budget via principled refusal. UniCR learns a lightweight calibration head with
temperature scaling and proper scoring, supports API-only models through
black-box features, and offers distribution-free guarantees using conformal
risk control. For long-form generation, we align confidence with semantic
fidelity by supervising on atomic factuality scores derived from retrieved
evidence, reducing confident hallucinations while preserving coverage.
Experiments on short-form QA, code generation with execution tests, and
retrieval-augmented long-form QA show consistent improvements in calibration
metrics, lower area under the risk-coverage curve, and higher coverage at fixed
risk compared to entropy or logit thresholds, post-hoc calibrators, and
end-to-end selective baselines. Analyses reveal that evidence contradiction,
semantic dispersion, and tool inconsistency are the dominant drivers of
abstention, yielding informative user-facing refusal messages. The result is a
portable recipe of evidence fusion to calibrated probability to risk-controlled
decision that improves trustworthiness without fine-tuning the base model and
remains valid under distribution shift.

</details>


### [302] [Robust Knowledge Editing via Explicit Reasoning Chains for Distractor-Resilient Multi-Hop QA](https://arxiv.org/abs/2509.01468)
*Yuchen Wu,Liang Ding,Li Shen,Dacheng Tao*

Main category: cs.CL

TL;DR: Reason-KE是一个端到端的、基于推理链的知识编辑框架，可以高效地将新事实注入或覆盖到大型语言模型（LLMs）中，解决了现有方法在处理多跳和嘈杂条件下的不足。


<details>
  <summary>Details</summary>
Motivation: 由于大型语言模型（LLMs）在训练后是静态的，无法及时整合新知识，而完全重新训练成本高昂，因此需要一种有效的知识编辑技术来注入或覆盖LLMs中的特定事实。

Method: Reason-KE框架通过四个结构化阶段（事实承认、相关性确定、选择性应用和最终推理）来指导预训练的LLM，以单次迭代过滤干扰信息。

Result: 在MQuake-CF数据集上，Reason-KE将Qwen2.5-7B模型的多跳问答准确率提高到90.2%，在强干扰下准确率仅下降6.3%，在答案泄露情况下准确率下降不到1%，证明了其鲁棒性和效率。

Conclusion: Reason-KE框架为LLM的可靠知识更新树立了新的标杆，在处理多跳和嘈杂条件下表现出卓越的性能和效率。

Abstract: Large language models (LLMs) encode vast amounts of world knowledge but
remain static once trained, making the timely integration of emerging facts
prohibitively expensive via full retraining. Knowledge-editing techniques have
thus emerged to inject or overwrite specific facts into LLMs, yet they either
over-rely on superficial cues or incur complex, iterative pipelines that
collapse under noisy, multi-hop conditions. We introduce Reason-KE, an
end-to-end reasoning-chain-based editing framework that steers a pretrained LLM
through four structured stages-fact acknowledgment, relevance determination,
selective application, and final reasoning-to filter distractors in a single
pass. Trained on MQuAKE-CF with up to four irrelevant facts, Reason-KE elevates
Qwen2.5-7B's multi-hop QA accuracy to 90.2% while suffering merely a 6.3% drop
under heavy distraction and <1% when answers are leaked. Our quantitative
analysis confirms Reason-KE's resilience and efficiency, establishing a new
state-of-the-art for reliable LLM knowledge updates.

</details>


### [303] [Do Retrieval Augmented Language Models Know When They Don't Know?](https://arxiv.org/abs/2509.01476)
*Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng*

Main category: cs.CL

TL;DR: LLMs有时会产生不准确的回答（幻觉）。本研究探讨了检索增强语言模型（RALMs）的拒绝能力，发现它们存在过度拒绝行为。研究还评估了拒绝后训练方法对过度拒绝的影响，并提出了一种改进模型整体回答质量的方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注LLM幻觉的缓解，但忽略了RALMs的拒绝能力评估。本研究旨在回答RALMs是否知道它们不知道什么，以及如何改善它们的拒绝能力。

Method: 研究首先考察了RALMs在不同知识状态下的校准情况，并分析了影响因素。接着，研究评估了拒绝指令调优和上下文微调两种拒绝后训练方法对过度拒绝问题的影响。最后，研究开发了一种新的拒绝方法来提高模型的整体回答质量。

Result: RALMs表现出显著的过度拒绝行为。拒绝指令调优会加剧过度拒绝问题，而上下文微调则能缓解该问题。然而，拒绝能力与回答质量之间可能存在冲突。所提出的拒绝方法能够同时提高拒绝能力和正确回答的比例。

Conclusion: RALMs存在过度拒绝的现象，并且拒绝后训练方法对其有不同的影响。通过结合上下文微调和一种新的拒绝方法，可以有效缓解过度拒绝问题，并提升模型的整体回答质量。

Abstract: Existing Large Language Models (LLMs) occasionally generate plausible yet
factually incorrect responses, known as hallucinations. Researchers are
primarily using two approaches to mitigate hallucinations, namely Retrieval
Augmented Language Models (RALMs) and refusal post-training. However, current
research predominantly emphasizes their individual effectiveness while
overlooking the evaluation of the refusal capability of RALMs. In this study,
we ask the fundamental question: Do RALMs know when they don't know?
Specifically, we ask three questions. First, are RALMs well-calibrated
regarding different internal and external knowledge states? We examine the
influence of various factors. Contrary to expectations, we find that LLMs
exhibit significant \textbf{over-refusal} behavior. Then, how does refusal
post-training affect the over-refusal issue? We investigate the Refusal-aware
Instruction Tuning and In-Context Fine-tuning methods. Our results show that
the over-refusal problem is mitigated by In-context fine-tuning. but magnified
by R-tuning. However, we also find that the refusal ability may conflict with
the quality of the answer. Finally, we develop a simple yet effective refusal
method for refusal post-trained models to improve their overall answer quality
in terms of refusal and correct answers. Our study provides a more
comprehensive understanding of the influence of important factors on RALM
systems.

</details>


### [304] [MeVe: A Modular System for Memory Verification and Effective Context Control in Language Models](https://arxiv.org/abs/2509.01514)
*Andreas Ottem*

Main category: cs.CL

TL;DR: MeVe是一个新的RAG架构，通过模块化设计优化了检索和上下文组合过程，提高了信息效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的RAG系统由于其简单的top-k语义搜索机制，常包含不相关或冗余信息，从而降低了性能和效率。MeVe旨在解决这个问题。

Method: MeVe提出了一个包含初始检索、相关性验证、回退检索、上下文优先排序和令牌预算的五阶段模块化设计，对检索和上下文组合过程进行精细控制和独立调整。

Result: 在维基百科数据集上，MeVe将上下文效率提高了57%；在HotpotQA数据集上，上下文效率提高了75%，显著优于标准RAG实现。

Conclusion: MeVe通过验证信息和提炼上下文，提高了上下文效率和准确性，为构建更可靠、可扩展的LLM应用提供了框架。

Abstract: Retrieval-Augmented Generation (RAG) systems typically face constraints
because of their inherent mechanism: a simple top-k semantic search [1]. The
approach often leads to the incorporation of irrelevant or redundant
information in the context, degrading performance and efficiency [10][11]. This
paper presents MeVe, a novel modular architecture intended for Memory
Verification and smart context composition. MeVe rethinks the RAG paradigm by
proposing a five-phase modular design that distinctly breaks down the retrieval
and context composition process into distinct, auditable, and independently
tunable phases: initial retrieval, relevance verification, fallback retrieval,
context prioritization, and token budgeting. This architecture enables
fine-grained control of what knowledge is made available to an LLM, enabling
task-dependent filtering and adaptation. We release a reference implementation
of MeVe as a proof of concept and evaluate its performance on knowledge-heavy
QA tasks over a subset of English Wikipedia [22]. Our results demonstrate that
by actively verifying information before composition, MeVe significantly
improves context efficiency, achieving a 57% reduction on the Wikipedia dataset
and a 75% reduction on the more complex HotpotQA dataset compared to standard
RAG implementations [25]. This work provides a framework for more scalable and
reliable LLM applications. By refining and distilling contextual information,
MeVe offers a path toward better grounding and more accurate factual support
[16].

</details>


### [305] [Service, Solidarity, and Self-Help: A Comparative Topic Modeling Analysis of Community Unionism in the Boot and Shoe Union and Unite Community](https://arxiv.org/abs/2509.01529)
*Thomas Compton*

Main category: cs.CL

TL;DR: 本文对比分析了1920年代的全国鞋业工会（B&S）和2010-2020年代的Unite Community工会这两个不同历史和组织背景下的社区工会主义（CU）。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过对比分析不同历史时期和组织背景下的社区工会主义（CU），探讨社区工会主义在时间、行业和组织模式上的连续性和普遍性。

Method: 本文运用BERTopic主题建模、cTF-IDF加权和词频分析等方法，分析了B&S和Unite Community工会的论述，以评估其与CU关键特征（如联盟建设、基层参与、工作场所之外的行动）的契合度。

Result: 研究结果显示，Unite Community在面向外部、关注社会正义的主题上与CU的一致性更强，而B&S则更侧重于内部管理、工业关系和会员服务，反映了更传统的工会服务模式。两种工会的社区相关主题参与度存在显著差异，其内在的参与模式也大相径庭。

Conclusion: 尽管两个工会都涉及社区相关主题，但它们的参与模式存在显著差异，挑战了社区工会主义在时间和行业领域的连续性和普遍性的假设。此外，研究还展示了现代自然语言处理技术在研究历史劳工档案方面的潜力。

Abstract: This paper presents a comparative analysis of community unionism (CU) in two
distinct historical and organizational contexts: the National Boot and Shoe
Union (B\&S) in the 1920s and Unite Community in the 2010s--2020s. Using
BERTopic for thematic modeling and cTF-IDF weighting, alongside word frequency
analysis, the study examines the extent to which each union's discourse aligns
with key features of CU -- such as coalition-building, grassroots engagement,
and action beyond the workplace. The results reveal significant differences in
thematic focus and discursive coherence. While Unite Community demonstrates
stronger alignment with outward-facing, social justice-oriented themes, the
B\&S corpus emphasizes internal administration, industrial relations, and
member services -- reflecting a more traditional, servicing-oriented union
model. The analysis also highlights methodological insights, demonstrating how
modern NLP techniques can enhance the study of historical labor archives.
Ultimately, the findings suggest that while both unions engage with
community-related themes, their underlying models of engagement diverge
significantly, challenging assumptions about the continuity and universality of
community unionism across time and sector.

</details>


### [306] [CAT: Causal Attention Tuning For Injecting Fine-grained Causal Knowledge into Large Language Models](https://arxiv.org/abs/2509.01535)
*Kairong Han,Wenshuo Zhao,Ziyu Zhao,JunJian Ye,Lujia Pan,Kun Kuang*

Main category: cs.CL

TL;DR: LLMs在因果知识利用方面存在不足，容易学习到虚假相关性，尤其是在OOD场景下。本文提出因果注意力调优（CAT）方法，通过注入因果知识到注意力机制来解决此问题，并在STG基准和下游任务上取得了良好的效果。


<details>
  <summary>Details</summary>
Motivation: LLMs在因果知识利用方面存在不足，容易学习到虚假相关性，尤其是在OOD场景下。

Method: 提出因果注意力调优（CAT）方法，通过注入因果知识到注意力机制来解决此问题，具体包括利用人类先验知识自动生成token级因果信号，以及引入Re-Attention机制来指导训练。

Result: 在提出的STG基准和多个下游任务上的实验结果表明，CAT方法能够有效利用因果知识进行预测，并在OOD场景下保持鲁棒性。

Conclusion: CAT方法能够有效利用因果知识进行预测，并在OOD场景下保持鲁棒性。

Abstract: Large Language Models (LLMs) have achieved remarkable success across various
domains. However, a fundamental question remains: Can LLMs effectively utilize
causal knowledge for prediction and generation? Through empirical studies, we
find that LLMs trained directly on large-scale data often capture spurious
correlations rather than true causal relationships, leading to suboptimal
performance, especially in out-of-distribution (OOD) scenarios. To address this
challenge, we propose Causal Attention Tuning (CAT), a novel approach that
injects fine-grained causal knowledge into the attention mechanism. We propose
an automated pipeline that leverages human priors to automatically generate
token-level causal signals and introduce the Re-Attention mechanism to guide
training, helping the model focus on causal structures while mitigating noise
and biases in attention scores. Experimental results on our proposed Spurious
Token Game (STG) benchmark and multiple downstream tasks demonstrate that our
approach effectively leverages causal knowledge for prediction and remains
robust in OOD scenarios. Implementation details can be found at
https://github.com/Kairong-Han/CAT.

</details>


### [307] [In-N-Out: A Parameter-Level API Graph Dataset for Tool Agents](https://arxiv.org/abs/2509.01560)
*Seungkyu Lee,Nalim Kim,Yohan Jo*

Main category: cs.CL

TL;DR: Tool agents (LLM-based systems interacting with APIs) struggle with complex, multi-step API calls. This paper introduces In-N-Out, a dataset of structured API graphs that represent API dependencies, to improve tool agent performance. Using these graphs significantly boosts API retrieval and multi-tool query generation, nearly doubling the performance of LLMs using documentation alone. Models fine-tuned on In-N-Out can bridge 90% of this performance gap, demonstrating the dataset's effectiveness in teaching models API documentation comprehension and parameter relationships. The findings suggest explicit API graphs are promising for tool agents, and In-N-Out is a valuable resource.


<details>
  <summary>Details</summary>
Motivation: LLM-based tool agents struggle to identify and call the correct APIs in the proper order for increasingly complex tasks that require compositional API calls.

Method: Converted API documentation into a structured API graph to capture API dependencies and leveraged it for multi-tool queries. Introduced In-N-Out, an expert-annotated dataset of API graphs built from two real-world API benchmarks and their documentation.

Result: Using In-N-Out significantly improved performance on both tool retrieval and multi-tool query generation, nearly doubling the performance of LLMs using documentation alone. Models fine-tuned on In-N-Out closed 90% of this performance gap, indicating the dataset helps models learn to comprehend API documentation and parameter relationships.

Conclusion: Explicit API graphs show promise for tool agents, and the In-N-Out dataset is a valuable resource for improving their performance in handling complex, multi-step API calls by enhancing their comprehension of API documentation and parameter relationships.

Abstract: Tool agents -- LLM-based systems that interact with external APIs -- offer a
way to execute real-world tasks. However, as tasks become increasingly complex,
these agents struggle to identify and call the correct APIs in the proper
order. To tackle this problem, we investigate converting API documentation into
a structured API graph that captures API dependencies and leveraging it for
multi-tool queries that require compositional API calls. To support this, we
introduce In-N-Out, the first expert-annotated dataset of API graphs built from
two real-world API benchmarks and their documentation. Using In-N-Out
significantly improves performance on both tool retrieval and multi-tool query
generation, nearly doubling that of LLMs using documentation alone. Moreover,
graphs generated by models fine-tuned on In-N-Out close 90% of this gap,
showing that our dataset helps models learn to comprehend API documentation and
parameter relationships. Our findings highlight the promise of using explicit
API graphs for tool agents and the utility of In-N-Out as a valuable resource.
We will release the dataset and code publicly.

</details>


### [308] [Enhancing Uncertainty Estimation in LLMs with Expectation of Aggregated Internal Belief](https://arxiv.org/abs/2509.01564)
*Zeguan Xiao,Diyang Dou,Boya Xiong,Yun Chen,Guanhua Chen*

Main category: cs.CL

TL;DR: EAGLE通过聚合LLM的内部中间层信念来提高置信度评估的准确性，尤其是在RLHF模型中，从而解决模型过度自信的问题。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs），特别是经过人类反馈强化学习（RLHF）训练的模型，在生成看似合理但实际上不正确答案时表现出的过度自信问题，以实现更可靠的不确定性估计和安全部署。

Method: 提出了一种名为EAGLE（Expectation of AGgregated internaL bEief）的新型自评估方法。该方法通过提取LLM多个中间层的内部信念，并对这些层级信念进行聚合，计算置信度得分的期望值，从而得到更精确的置信度评分。

Result: 在各种数据集和LLMs上进行的广泛实验表明，EAGLE在校准性能上显著优于现有基线方法。对EAGLE的深入分析，包括层级不确定性模式、自评估提示的影响以及自评估分数范围的影响，提供了对其有效性的进一步证明。

Conclusion: EAGLE是一种有效的方法，可以通过利用LLM的内部表示来提高其置信度评估的准确性，从而解决LLM的过度自信问题，并有望用于更安全的部署。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide
range of natural language tasks, but often exhibit overconfidence and generate
plausible yet incorrect answers. This overconfidence, especially in models
undergone Reinforcement Learning from Human Feedback (RLHF), poses significant
challenges for reliable uncertainty estimation and safe deployment. In this
paper, we propose EAGLE (Expectation of AGgregated internaL bEief), a novel
self-evaluation-based calibration method that leverages the internal hidden
states of LLMs to derive more accurate confidence scores. Instead of relying on
the model's final output, our approach extracts internal beliefs from multiple
intermediate layers during self-evaluation. By aggregating these layer-wise
beliefs and calculating the expectation over the resulting confidence score
distribution, EAGLE produces a refined confidence score that more faithfully
reflects the model's internal certainty. Extensive experiments on diverse
datasets and LLMs demonstrate that EAGLE significantly improves calibration
performance over existing baselines. We also provide an in-depth analysis of
EAGLE, including a layer-wise examination of uncertainty patterns, a study of
the impact of self-evaluation prompts, and an analysis of the effect of
self-evaluation score range.

</details>


### [309] [Testing the assumptions about the geometry of sentence embedding spaces: the cosine measure need not apply](https://arxiv.org/abs/2509.01606)
*Vivi Nastase,Paola Merlo*

Main category: cs.CL

TL;DR: Transformer模型产生的句嵌入的几何结构与其在各种任务上的表现之间没有预测关系，语言信息编码在加权的维度组合中。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型产生的句嵌入的几何结构是否与其在不同任务上的相对表现相关。

Method: 通过平均词嵌入、[CLS]标记嵌入和随机标记嵌入三种方式计算句嵌入，并探索嵌入变体之间的距离与其在语言任务上的表现之间的相关性。

Result: 余弦相似度可以捕捉句嵌入的浅层共性或差异，但不能预测其在特定任务上的表现。语言信息实际上编码在加权的维度组合中，这并未在句嵌入空间的几何结构中体现出来。

Conclusion: 句嵌入的几何结构并非预测其性能的关键因素，语言信息通过加权的维度组合进行编码。

Abstract: Transformer models learn to encode and decode an input text, and produce
contextual token embeddings as a side-effect. The mapping from language into
the embedding space maps words expressing similar concepts onto points that are
close in the space. In practice, the reverse implication is also assumed: words
corresponding to close points in this space are similar or related, those that
are further are not.
  Does closeness in the embedding space extend to shared properties for
sentence embeddings? We present an investigation of sentence embeddings and
show that the geometry of their embedding space is not predictive of their
relative performances on a variety of tasks.
  We compute sentence embeddings in three ways: as averaged token embeddings,
as the embedding of the special [CLS] token, and as the embedding of a random
token from the sentence. We explore whether there is a correlation between the
distance between sentence embedding variations and their performance on
linguistic tasks, and whether despite their distances, they do encode the same
information in the same manner.
  The results show that the cosine similarity -- which treats dimensions
shallowly -- captures (shallow) commonalities or differences between sentence
embeddings, which are not predictive of their performance on specific tasks.
Linguistic information is rather encoded in weighted combinations of different
dimensions, which are not reflected in the geometry of the sentence embedding
space.

</details>


### [310] [Benchmarking the Detection of LLMs-Generated Modern Chinese Poetry](https://arxiv.org/abs/2509.01620)
*Shanshan Wang,Junchao Wu,Fengying Ye,Jingming Yao,Lidia S. Chao,Derek F. Wong*

Main category: cs.CL

TL;DR: 该论文提出一个用于检测AI生成现代中文诗歌的新基准，因为现有方法无法有效识别现代中文诗歌的AI生成文本。


<details>
  <summary>Details</summary>
Motivation: 由于AI生成文本（包括现代中文诗歌）日益普遍，且难以与人类创作区分，对识别AI生成现代中文诗歌的需求日益增长，以维护诗歌生态系统。

Method: 构建了一个包含800首专业诗人作品和41,600首由四种主流大语言模型生成的现代中文诗歌的数据集，并在此数据集上评估了六种现有检测器的性能。

Result: 实验表明，当前检测器无法可靠地检测由大语言模型生成的现代中文诗歌，尤其是风格等内在特质难以识别。

Conclusion: 论文提出的新基准被验证是有效且必要的，为未来AI生成诗歌的检测奠定了基础。

Abstract: The rapid development of advanced large language models (LLMs) has made
AI-generated text indistinguishable from human-written text. Previous work on
detecting AI-generated text has made effective progress, but has not involved
modern Chinese poetry. Due to the distinctive characteristics of modern Chinese
poetry, it is difficult to identify whether a poem originated from humans or
AI. The proliferation of AI-generated modern Chinese poetry has significantly
disrupted the poetry ecosystem. Based on the urgency of identifying
AI-generated poetry in the real Chinese world, this paper proposes a novel
benchmark for detecting LLMs-generated modern Chinese poetry. We first
construct a high-quality dataset, which includes both 800 poems written by six
professional poets and 41,600 poems generated by four mainstream LLMs.
Subsequently, we conduct systematic performance assessments of six detectors on
this dataset. Experimental results demonstrate that current detectors cannot be
used as reliable tools to detect modern Chinese poems generated by LLMs. The
most difficult poetic features to detect are intrinsic qualities, especially
style. The detection results verify the effectiveness and necessity of our
proposed benchmark. Our work lays a foundation for future detection of
AI-generated poetry.

</details>


### [311] [TransGAT: Transformer-Based Graph Neural Networks for Multi-Dimensional Automated Essay Scoring](https://arxiv.org/abs/2509.01640)
*Hind Aljuaid,Areej Alhothali,Ohoud Al-Zamzami,Hussein Assalahi*

Main category: cs.CL

TL;DR: 该研究提出了一种名为TransGAT的新型自动化论文评分（AES）方法，该方法结合了Transformer模型和图注意力网络（GAT），能够进行分析评分，解决了现有AES方法在捕捉语境意义和进行细粒度评分方面的局限性。实验结果表明，TransGAT在ELLIPSE数据集上表现优于基线模型，平均Quadratic Weighted Kappa（QWK）达到0.854。


<details>
  <summary>Details</summary>
Motivation: 传统的论文写作评估方法（人工评分）耗时且不一致。现有的自动化论文评分（AES）方法虽然有潜力，但仍存在局限性，特别是使用静态词嵌入无法捕捉词语的语境含义（尤其是多义词），并且许多方法仅进行整体评分，忽略了语法、词汇和连贯性等具体的写作方面。

Method: 本研究提出了一种名为TransGAT的新型方法，将经过微调的Transformer模型（BERT、RoBERTa和DeBERTaV3）与图注意力网络（GAT）相结合，用于分析评分。TransGAT结合了Transformer的语境理解能力和GAT的关系建模能力。它通过将每个微调后的Transformer与一个单独的GAT配对，进行双流预测。在每对中，第一流生成论文级别的预测，第二流将GAT应用于Transformer的词元嵌入，并通过句法依赖关系构建边。最后，模型融合这两个流的预测以生成最终的分析分数。

Result: 在ELLIPSE数据集上的实验表明，TransGAT的性能优于基线模型，在所有分析评分维度上的平均Quadratic Weighted Kappa（QWK）达到了0.854。

Conclusion: 研究结果表明，TransGAT有潜力改进现有的AES系统，它通过结合Transformer的语境理解能力和GAT的关系建模能力，实现了更准确和细粒度的论文评分。

Abstract: Essay writing is a critical component of student assessment, yet manual
scoring is labor-intensive and inconsistent. Automated Essay Scoring (AES)
offers a promising alternative, but current approaches face limitations. Recent
studies have incorporated Graph Neural Networks (GNNs) into AES using static
word embeddings that fail to capture contextual meaning, especially for
polysemous words. Additionally, many methods rely on holistic scoring,
overlooking specific writing aspects such as grammar, vocabulary, and cohesion.
To address these challenges, this study proposes TransGAT, a novel approach
that integrates fine-tuned Transformer models with GNNs for analytic scoring.
TransGAT combines the contextual understanding of Transformers with the
relational modeling strength of Graph Attention Networks (GAT). It performs
two-stream predictions by pairing each fine-tuned Transformer (BERT, RoBERTa,
and DeBERTaV3) with a separate GAT. In each pair, the first stream generates
essay-level predictions, while the second applies GAT to Transformer token
embeddings, with edges constructed from syntactic dependencies. The model then
fuses predictions from both streams to produce the final analytic score.
Experiments on the ELLIPSE dataset show that TransGAT outperforms baseline
models, achieving an average Quadratic Weighted Kappa (QWK) of 0.854 across all
analytic scoring dimensions. These findings highlight the potential of TransGAT
to advance AES systems.

</details>


### [312] [Parallel Needleman-Wunsch on CUDA to measure word similarity based on phonetic transcriptions](https://arxiv.org/abs/2509.01654)
*Dominic Plein*

Main category: cs.CL

TL;DR: We present a method to calculate word phonetic similarity using the Needleman-Wunsch algorithm, parallelized on CPU and GPU (CUDA/cudarc), and validated through graph clustering to identify phonetically similar word groups.


<details>
  <summary>Details</summary>
Motivation: To calculate the similarity between words based on their phonetic transcription (pronunciation) and handle large datasets efficiently.

Method: The Needleman-Wunsch algorithm is used to calculate phonetic similarity. The implementation is parallelized on CPU and GPU using Rust, CUDA, and the cudarc Rust library. A fully-connected graph is constructed with words as nodes and phonetic similarity as edge weights. Clustering algorithms are then used to analyze this graph.

Result: The method is validated by constructing a graph and analyzing it with clustering algorithms, which successfully identified groups of phonetically similar words. This demonstrates the feasibility and effectiveness of the approach.

Conclusion: The proposed method is feasible and effective for analyzing the phonetic structure of languages and can be easily expanded to other languages.

Abstract: We present a method to calculate the similarity between words based on their
phonetic transcription (their pronunciation) using the Needleman-Wunsch
algorithm. We implement this algorithm in Rust and parallelize it on both CPU
and GPU to handle large datasets efficiently. The GPU implementation leverages
CUDA and the cudarc Rust library to achieve significant performance
improvements. We validate our approach by constructing a fully-connected graph
where nodes represent words and edges have weights according to the similarity
between the words. This graph is then analyzed using clustering algorithms to
identify groups of phonetically similar words. Our results demonstrate the
feasibility and effectiveness of the proposed method in analyzing the phonetic
structure of languages. It might be easily expanded to other languages.

</details>


### [313] [Bridging Thoughts and Words: Graph-Based Intent-Semantic Joint Learning for Fake News Detection](https://arxiv.org/abs/2509.01660)
*Zhengjia Wang,Qiang Sheng,Danding Wang,Beizhe Hu,Juan Cao*

Main category: cs.CL

TL;DR: 本篇论文提出了一种名为InSide的新方法，通过结合新闻意图和语义来提升虚假新闻检测的准确性，解决了现有方法仅依赖语义线索容易失效的问题。


<details>
  <summary>Details</summary>
Motivation: 现有虚假新闻检测方法主要依赖语义线索，如情感词和风格特征，但这容易导致模型只关注表面模式，在不断变化的新闻环境中性能受限。因此，需要引入新闻意图来更深入地理解新闻欺骗的内在逻辑。

Method: 提出了一种名为InSide（Graph-based Intent-Semantic Joint Modeling）的图结构联合模型，该模型通过图结构整合语义和意图信号。具体来说，它将新闻的语义和意图重构为异构图，利用实体引导实现长距离上下文交互，并通过粗粒度到细粒度的意图建模来捕捉整体和实现层面的意图。为了更好地对齐语义和意图，还开发了一种基于动态路径的图对齐策略，以在统一空间中实现有效的信号传递和聚合。

Result: 在四个基准数据集上的广泛实验证明，InSide方法优于现有的最先进方法。

Conclusion: 通过将新闻意图纳入虚假新闻检测，并提出InSide模型进行意图和语义的联合学习，可以更有效地识别虚假新闻，克服了仅依赖语义线索的局限性。

Abstract: Fake news detection is an important and challenging task for defending online
information integrity. Existing state-of-the-art approaches typically extract
news semantic clues, such as writing patterns that include emotional words,
stylistic features, etc. However, detectors tuned solely to such semantic clues
can easily fall into surface detection patterns, which can shift rapidly in
dynamic environments, leading to limited performance in the evolving news
landscape. To address this issue, this paper investigates a novel perspective
by incorporating news intent into fake news detection, bridging intents and
semantics together. The core insight is that by considering news intents, one
can deeply understand the inherent thoughts behind news deception, rather than
the surface patterns within words alone. To achieve this goal, we propose
Graph-based Intent-Semantic Joint Modeling (InSide) for fake news detection,
which models deception clues from both semantic and intent signals via
graph-based joint learning. Specifically, InSide reformulates news semantic and
intent signals into heterogeneous graph structures, enabling long-range context
interaction through entity guidance and capturing both holistic and
implementation-level intent via coarse-to-fine intent modeling. To achieve
better alignment between semantics and intents, we further develop a dynamic
pathway-based graph alignment strategy for effective message passing and
aggregation across these signals by establishing a common space. Extensive
experiments on four benchmark datasets demonstrate the superiority of the
proposed InSide compared to state-of-the-art methods.

</details>


### [314] [chDzDT: Word-level morphology-aware language model for Algerian social media text](https://arxiv.org/abs/2509.01772)
*Abdelkrime Aries*

Main category: cs.CL

TL;DR: 该论文提出了一种针对阿尔及利亚阿拉伯语方言的字符级预训练语言模型chDzDT，以解决该方言复杂的形态学、词语切换、多脚本和外语词汇影响等问题。该模型在孤立的单词上进行训练，能够鲁棒地编码形态模式，不依赖于分词边界或标准拼写。研究涵盖了来自YouTube评论、法语、英语和柏柏尔语维基百科以及Tatoeba项目的多样化语料库，并进行了全面的评估。


<details>
  <summary>Details</summary>
Motivation: 阿尔及利亚阿拉伯语方言在现有预训练语言模型中代表性不足，且其复杂的形态学、词语切换、多脚本和外语词汇影响给处理带来挑战。

Method: 提出并开发了一个名为chDzDT的字符级预训练语言模型，该模型在孤立的单词上进行训练，以稳健地编码形态模式。语料库来源于YouTube评论、法语、英语和柏柏尔语维基百科以及Tatoeba项目，涵盖多种脚本和语言变体。

Result: 所提出的chDzDT模型在形态丰富的低资源方言方面展示了字符级建模的潜力，并为更具包容性和适应性的自然语言处理系统奠定了基础。

Conclusion: 字符级建模为处理阿尔及利亚阿拉伯语方言这类形态复杂的低资源语言提供了有效途径，有助于构建更具包容性和适应性的自然语言处理系统。

Abstract: Pre-trained language models (PLMs) have substantially advanced natural
language processing by providing context-sensitive text representations.
However, the Algerian dialect remains under-represented, with few dedicated
models available. Processing this dialect is challenging due to its complex
morphology, frequent code-switching, multiple scripts, and strong lexical
influences from other languages. These characteristics complicate tokenization
and reduce the effectiveness of conventional word- or subword-level approaches.
  To address this gap, we introduce chDzDT, a character-level pre-trained
language model tailored for Algerian morphology. Unlike conventional PLMs that
rely on token sequences, chDzDT is trained on isolated words. This design
allows the model to encode morphological patterns robustly, without depending
on token boundaries or standardized orthography. The training corpus draws from
diverse sources, including YouTube comments, French, English, and Berber
Wikipedia, as well as the Tatoeba project. It covers multiple scripts and
linguistic varieties, resulting in a substantial pre-training workload.
  Our contributions are threefold: (i) a detailed morphological analysis of
Algerian dialect using YouTube comments; (ii) the construction of a
multilingual Algerian lexicon dataset; and (iii) the development and extensive
evaluation of a character-level PLM as a morphology-focused encoder for
downstream tasks. The proposed approach demonstrates the potential of
character-level modeling for morphologically rich, low-resource dialects and
lays a foundation for more inclusive and adaptable NLP systems.

</details>


### [315] [Flaw or Artifact? Rethinking Prompt Sensitivity in Evaluating LLMs](https://arxiv.org/abs/2509.01790)
*Andong Hua,Kenan Tang,Chenhe Gu,Jindong Gu,Eric Wong,Yao Qin*

Main category: cs.CL

TL;DR: 研究发现，LLM的提示敏感性很大程度上是评估过程的产物，而非模型本身的固有缺陷。采用LLM-as-a-Judge评估方法可显著降低性能差异，提高模型排名在不同提示下的相关性。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）在提示敏感性方面的表现，探究其是否为模型固有弱点，还是评估过程的产物。

Method: 系统评估了7个LLM在6个基准测试上的表现，使用了12种不同的提示模板，并对比了传统启发式评估方法（如对数似然评分和固定答案匹配）与LLM-as-a-Judge评估方法。

Result: 与传统评估方法相比，LLM-as-a-Judge评估显著降低了LLM在不同提示下的性能方差，提高了模型排名的稳定性。研究表明，LLM对提示模板的鲁棒性比之前认为的更强。

Conclusion: LLM的提示敏感性很大程度上是评估方法（尤其是启发式评估）的产物，而非模型本身的固有缺陷。改进评估方法可以更准确地反映LLM的真实能力。

Abstract: Prompt sensitivity, referring to the phenomenon where paraphrasing (i.e.,
repeating something written or spoken using different words) leads to
significant changes in large language model (LLM) performance, has been widely
accepted as a core limitation of LLMs. In this work, we revisit this issue and
ask: Is the widely reported high prompt sensitivity truly an inherent weakness
of LLMs, or is it largely an artifact of evaluation processes? To answer this
question, we systematically evaluate 7 LLMs (e.g., GPT and Gemini family)
across 6 benchmarks, including both multiple-choice and open-ended tasks on 12
diverse prompt templates. We find that much of the prompt sensitivity stems
from heuristic evaluation methods, including log-likelihood scoring and rigid
answer matching, which often overlook semantically correct responses expressed
through alternative phrasings, such as synonyms or paraphrases. When we adopt
LLM-as-a-Judge evaluations, we observe a substantial reduction in performance
variance and a consistently higher correlation in model rankings across
prompts. Our findings suggest that modern LLMs are more robust to prompt
templates than previously believed, and that prompt sensitivity may be more an
artifact of evaluation than a flaw in the models.

</details>


### [316] [Mic Drop or Data Flop? Evaluating the Fitness for Purpose of AI Voice Interviewers for Data Collection within Quantitative & Qualitative Research Contexts](https://arxiv.org/abs/2509.01814)
*Shreyas Tirumala,Nishant Jain,Danny D. Leybzon,Trent D. Buskirk*

Main category: cs.CL

TL;DR: LLM驱动的AI面试官在数据收集中的适用性仍具挑战性，尤其是在定性研究领域。


<details>
  <summary>Details</summary>
Motivation: 评估基于LLM的AI面试官在定量和定性研究中收集数据的适用性，并与现有的IVR系统进行比较。

Method: 评估AI面试官和IVR系统的输入/输出性能（语音识别、答案记录、情绪处理）和语言推理能力（追问、澄清、处理分支逻辑）。

Result: AI面试官在数据收集方面的能力已超过IVR系统，但在实时转录错误率、情绪识别能力有限以及后续跟进质量不均等方面仍存在不足，这表明其在定性数据收集中的应用具有情境依赖性。

Conclusion: 虽然AI面试官在数据收集方面展现出潜力，但其在转录准确性、情绪识别和一致性方面的局限性限制了其在定性研究中的广泛应用，需要进一步的研究和改进。

Abstract: Transformer-based Large Language Models (LLMs) have paved the way for "AI
interviewers" that can administer voice-based surveys with respondents in
real-time. This position paper reviews emerging evidence to understand when
such AI interviewing systems are fit for purpose for collecting data within
quantitative and qualitative research contexts. We evaluate the capabilities of
AI interviewers as well as current Interactive Voice Response (IVR) systems
across two dimensions: input/output performance (i.e., speech recognition,
answer recording, emotion handling) and verbal reasoning (i.e., ability to
probe, clarify, and handle branching logic). Field studies suggest that AI
interviewers already exceed IVR capabilities for both quantitative and
qualitative data collection, but real-time transcription error rates, limited
emotion detection abilities, and uneven follow-up quality indicate that the
utility, use and adoption of current AI interviewer technology may be
context-dependent for qualitative data collection efforts.

</details>


### [317] [Extracting OPQRST in Electronic Health Records using Large Language Models with Reasoning](https://arxiv.org/abs/2509.01885)
*Zhimeng Luo,Abhibha Gupta,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 本研究提出利用大型语言模型（LLM）从电子健康记录（EHRs）中提取OPQRST评估信息的新方法，将任务从序列标注重构为文本生成，并改进了评估指标以提高准确性和可用性。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHRs）中患者信息的提取因数据复杂且非结构化而面临挑战，传统机器学习方法难以有效捕捉关键细节，影响临床应用。本研究旨在解决这一问题。

Method: 提出利用大型语言模型（LLM）将从EHRs提取OPQRST评估的任务重构为文本生成，并结合BERT Score等语义相似性指标修改传统命名实体识别（NER）评估方法。

Result: 该方法提高了从EHRs提取信息的准确性和可用性，为临床决策和患者护理提供了可扩展的解决方案。

Conclusion: 本研究在AI医疗应用方面取得了显著进展，通过LLM和改进的评估方法，提升了EHRs信息提取的效率和医生决策的准确性。

Abstract: The extraction of critical patient information from Electronic Health Records
(EHRs) poses significant challenges due to the complexity and unstructured
nature of the data. Traditional machine learning approaches often fail to
capture pertinent details efficiently, making it difficult for clinicians to
utilize these tools effectively in patient care. This paper introduces a novel
approach to extracting the OPQRST assessment from EHRs by leveraging the
capabilities of Large Language Models (LLMs). We propose to reframe the task
from sequence labeling to text generation, enabling the models to provide
reasoning steps that mimic a physician's cognitive processes. This approach
enhances interpretability and adapts to the limited availability of labeled
data in healthcare settings. Furthermore, we address the challenge of
evaluating the accuracy of machine-generated text in clinical contexts by
proposing a modification to traditional Named Entity Recognition (NER) metrics.
This includes the integration of semantic similarity measures, such as the BERT
Score, to assess the alignment between generated text and the clinical intent
of the original records. Our contributions demonstrate a significant
advancement in the use of AI in healthcare, offering a scalable solution that
improves the accuracy and usability of information extraction from EHRs,
thereby aiding clinicians in making more informed decisions and enhancing
patient care outcomes.

</details>


### [318] [Weakly Supervised Medical Entity Extraction and Linking for Chief Complaints](https://arxiv.org/abs/2509.01899)
*Zhimeng Luo,Zhendong Wang,Rui Meng,Diyang Xue,Adam Frisch,Daqing He*

Main category: cs.CL

TL;DR: 本研究提出了一种弱监督方法，用于自动提取和链接主诉中的实体，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 主诉记录的输入方式多样，导致医学表示法差异很大，难以跨机构标准化，给记录保存和文本挖掘带来困难。

Method: 首先采用一种分割匹配算法生成弱标注（包括实体提及的跨度和类别标签），然后训练一个基于BERT的模型来定位实体提及并链接到预定义本体。

Result: 实验结果表明，所提出的弱监督实体提取和链接（\

Conclusion: 所提出的弱监督方法在无需任何人工标注的情况下，在实体提取和链接方面取得了优于先前方法的性能。

Abstract: A Chief complaint (CC) is the reason for the medical visit as stated in the
patient's own words. It helps medical professionals to quickly understand a
patient's situation, and also serves as a short summary for medical text
mining. However, chief complaint records often take a variety of entering
methods, resulting in a wide variation of medical notations, which makes it
difficult to standardize across different medical institutions for record
keeping or text mining. In this study, we propose a weakly supervised method to
automatically extract and link entities in chief complaints in the absence of
human annotation. We first adopt a split-and-match algorithm to produce weak
annotations, including entity mention spans and class labels, on 1.2 million
real-world de-identified and IRB approved chief complaint records. Then we
train a BERT-based model with generated weak labels to locate entity mentions
in chief complaint text and link them to a pre-defined ontology. We conducted
extensive experiments, and the results showed that our Weakly Supervised Entity
Extraction and Linking (\ours) method produced superior performance over
previous methods without any human annotation.

</details>


### [319] [DRAssist: Dispute Resolution Assistance using Large Language Models](https://arxiv.org/abs/2509.01962)
*Sachin Pawar,Manoj Apte,Girish K. Palshikar,Basit Ali,Nitin Ramrakhiyani*

Main category: cs.CL

TL;DR: 本文提出DRAssist系统，利用大型语言模型（LLMs）辅助法官处理涉及汽车保险和域名争议的纠纷，通过结构化争议摘要和多样的提示策略，评估LLMs在识别优势方、判断具体诉求可接受性及评价论点强弱方面的表现。


<details>
  <summary>Details</summary>
Motivation: 解决在税务、保险、银行、医疗等领域中，由人类法官在特定论坛处理当事人之间纠纷的低效问题，探索利用大型语言模型（LLMs）作为人类法官的助手。

Method: DRAssist系统首先识别纠纷的关键结构要素（如事实、争议点、论点），并将非结构化的描述总结为结构化摘要。随后，针对汽车保险和域名争议这两个特定领域，研究多种提示策略和多个LLMs，以评估其在以下三个层面的辅助解决纠纷能力：（1）识别总体上更有利的当事人；（2）判断每位当事人的具体诉求是否可以被接受；（3）评估每位当事人的每个论点是强还是弱。最后，通过与相关基线进行比较，并使用合适的评估指标来评估LLMs在这些任务上的表现。

Result: 评估了LLMs在识别优势方、判断诉求可接受性以及评价论点强弱方面的表现，并与相关基线进行了比较。

Conclusion: 通过对LLMs在不同层面的表现进行评估，为利用LLMs辅助处理法律纠纷提供了实证依据。

Abstract: Disputes between two parties occur in almost all domains such as taxation,
insurance, banking, healthcare, etc. The disputes are generally resolved in a
specific forum (e.g., consumer court) where facts are presented, points of
disagreement are discussed, arguments as well as specific demands of the
parties are heard, and finally a human judge resolves the dispute by often
favouring one of the two parties. In this paper, we explore the use of large
language models (LLMs) as assistants for the human judge to resolve such
disputes, as part of our DRAssist system. We focus on disputes from two
specific domains -- automobile insurance and domain name disputes. DRAssist
identifies certain key structural elements (e.g., facts, aspects or
disagreement, arguments) of the disputes and summarizes the unstructured
dispute descriptions to produce a structured summary for each dispute. We then
explore multiple prompting strategies with multiple LLMs for their ability to
assist in resolving the disputes in these domains. In DRAssist, these LLMs are
prompted to produce the resolution output at three different levels -- (i)
identifying an overall stronger party in a dispute, (ii) decide whether each
specific demand of each contesting party can be accepted or not, (iii) evaluate
whether each argument by each contesting party is strong or weak. We evaluate
the performance of LLMs on all these tasks by comparing them with relevant
baselines using suitable evaluation metrics.

</details>


### [320] [StructCoh: Structured Contrastive Learning for Context-Aware Text Semantic Matching](https://arxiv.org/abs/2509.02033)
*Chao Xue,Ziyuan Gao*

Main category: cs.CL

TL;DR: StructCoh框架结合了图神经网络和对比学习，在法律文件匹配和学术抄袭检测方面取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型在理解文本结构和细微语义差别方面存在不足，而StructCoh旨在解决这一问题。

Method: StructCoh采用双图编码器来构建语义图（通过依赖解析和主题建模），并利用图同构网络传播结构特征。此外，通过节点级对比和图感知对比学习，在多个粒度上强制执行一致性。

Result: 在法律文件匹配和学术抄袭检测任务上，StructCoh相比现有最先进的方法有显著提升，在法律法规匹配任务上F1分数达到86.7%，提升了6.2%。

Conclusion: StructCoh通过融合结构推理和表示空间优化，有效提升了文本语义匹配的性能，尤其在需要理解复杂结构和细微语义差异的场景中。

Abstract: Text semantic matching requires nuanced understanding of both structural
relationships and fine-grained semantic distinctions. While pre-trained
language models excel at capturing token-level interactions, they often
overlook hierarchical structural patterns and struggle with subtle semantic
discrimination. In this paper, we proposed StructCoh, a graph-enhanced
contrastive learning framework that synergistically combines structural
reasoning with representation space optimization. Our approach features two key
innovations: (1) A dual-graph encoder constructs semantic graphs via dependency
parsing and topic modeling, then employs graph isomorphism networks to
propagate structural features across syntactic dependencies and cross-document
concept nodes. (2) A hierarchical contrastive objective enforces consistency at
multiple granularities: node-level contrastive regularization preserves core
semantic units, while graph-aware contrastive learning aligns inter-document
structural semantics through both explicit and implicit negative sampling
strategies. Experiments on three legal document matching benchmarks and
academic plagiarism detection datasets demonstrate significant improvements
over state-of-the-art methods. Notably, StructCoh achieves 86.7% F1-score
(+6.2% absolute gain) on legal statute matching by effectively identifying
argument structure similarities.

</details>


### [321] [DeepSeek performs better than other Large Language Models in Dental Cases](https://arxiv.org/abs/2509.02036)
*Hexian Zhang,Xinyu Yan,Yanqi Yang,Lijian Jin,Ping Yang,Junwen Wang*

Main category: cs.CL

TL;DR: DeepSeek在纵向牙科病例分析中表现优于GPT-4o、Gemini 2.0 Flash和Copilot，在忠实度和专家评分方面均领先。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在解读纵向患者叙述方面的能力，尤其是在牙科领域，并比较了GPT-4o、Gemini 2.0 Flash、Copilot和DeepSeek V3这四种先进模型。

Method: 使用34个标准化的纵向牙科病例（包含258个问答对），通过自动指标和执照牙医的盲评来评估四种LLMs分析纵向牙科病例和开放式临床任务的能力。

Result: DeepSeek模型在忠实度（中位数=0.528）和专家评分（中位数=4.5/5）方面均优于其他模型（忠实度中位数=0.367-0.457，专家评分中位数=4.0/5），同时阅读性无显著下降。

Conclusion: DeepSeek是领先的病例分析LLM，建议将其作为医学教育和研究的辅助工具，并强调其作为领域特定代理的潜力。

Abstract: Large language models (LLMs) hold transformative potential in healthcare, yet
their capacity to interpret longitudinal patient narratives remains
inadequately explored. Dentistry, with its rich repository of structured
clinical data, presents a unique opportunity to rigorously assess LLMs'
reasoning abilities. While several commercial LLMs already exist, DeepSeek, a
model that gained significant attention earlier this year, has also joined the
competition. This study evaluated four state-of-the-art LLMs (GPT-4o, Gemini
2.0 Flash, Copilot, and DeepSeek V3) on their ability to analyze longitudinal
dental case vignettes through open-ended clinical tasks. Using 34 standardized
longitudinal periodontal cases (comprising 258 question-answer pairs), we
assessed model performance via automated metrics and blinded evaluations by
licensed dentists. DeepSeek emerged as the top performer, demonstrating
superior faithfulness (median score = 0.528 vs. 0.367-0.457) and higher expert
ratings (median = 4.5/5 vs. 4.0/5), without significantly compromising
readability. Our study positions DeepSeek as the leading LLM for case analysis,
endorses its integration as an adjunct tool in both medical education and
research, and highlights its potential as a domain-specific agent.

</details>


### [322] [NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task](https://arxiv.org/abs/2509.02038)
*Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: NADI 2025 共享任务专注于阿拉伯语语音方言处理，包括方言识别、语音识别和带音符号恢复。共有 44 个团队注册，收到了 100 份有效提交。最佳系统在方言识别方面达到了 79.8% 的准确率，语音识别和带音符号恢复也取得了进展，但仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语方言语音处理，包括方言识别、语音识别和带音符号恢复，仍然面临挑战。

Method: 对 NADI 2025 共享任务的三个子任务（语音方言识别、语音识别、带音符号恢复）进行了评估。

Result: Subtask 1（方言识别）的最佳准确率为 79.8%；Subtask 2（语音识别）的平均 WER/CER 为 35.68/12.20；Subtask 3（带音符号恢复）的 WER/CER 为 55/13。

Conclusion: NADI 2025 共享任务的结果凸显了阿拉伯语方言语音处理（特别是方言识别、识别和带音符号恢复）的持续挑战。

Abstract: We present the findings of the sixth Nuanced Arabic Dialect Identification
(NADI 2025) Shared Task, which focused on Arabic speech dialect processing
across three subtasks: spoken dialect identification (Subtask 1), speech
recognition (Subtask 2), and diacritic restoration for spoken dialects (Subtask
3). A total of 44 teams registered, and during the testing phase, 100 valid
submissions were received from eight unique teams. The distribution was as
follows: 34 submissions for Subtask 1 "five teams{\ae}, 47 submissions for
Subtask 2 "six teams", and 19 submissions for Subtask 3 "two teams". The
best-performing systems achieved 79.8% accuracy on Subtask 1, 35.68/12.20
WER/CER (overall average) on Subtask 2, and 55/13 WER/CER on Subtask 3. These
results highlight the ongoing challenges of Arabic dialect speech processing,
particularly in dialect identification, recognition, and diacritic restoration.
We also summarize the methods adopted by participating teams and briefly
outline directions for future editions of NADI.

</details>


### [323] [Attributes as Textual Genes: Leveraging LLMs as Genetic Algorithm Simulators for Conditional Synthetic Data Generation](https://arxiv.org/abs/2509.02040)
*Guangzeng Han,Weisi Liu,Xiaolei Huang*

Main category: cs.CL

TL;DR: Genetic Prompt结合遗传算法和LLMs生成高质量、多样化的合成数据，显著优于现有方法，并能提升下游模型性能。


<details>
  <summary>Details</summary>
Motivation: 确保LLM生成的合成数据的质量和多样性是一个挑战。

Method: 提出Genetic Prompt框架，将文本属性视为基因序列，利用LLM模拟交叉和变异操作，并整合主动学习优化父代选择。

Result: Genetic Prompt显著优于最先进的基线方法，在不同规模的发电机模型中表现稳健，并且融合合成数据能提升下游模型性能，尤其是在类别不平衡的情况下。

Conclusion: Genetic Prompt是为广泛的NLP应用生成高质量合成数据的有效方法。

Abstract: Large Language Models (LLMs) excel at generating synthetic data, but ensuring
its quality and diversity remains challenging. We propose Genetic Prompt, a
novel framework that combines genetic algorithms with LLMs to augment synthetic
data generation. Our approach treats semantic text attributes as gene sequences
and leverages the LLM to simulate crossover and mutation operations. This
genetic process enhances data quality and diversity by creating novel attribute
combinations, yielding synthetic distributions closer to real-world data. To
optimize parent selection, we also integrate an active learning scheme that
expands the offspring search space. Our experiments on multiple NLP tasks
reveal several key findings: Genetic Prompt not only significantly outperforms
state-of-the-art baselines but also shows robust performance across various
generator model sizes and scales. Moreover, we demonstrate that fusing our
synthetic data with the original training set significantly boosts downstream
model performance, particularly for class-imbalanced scenarios. Our findings
validate that Genetic Prompt is an effective method for producing high-quality
synthetic data for a wide range of NLP applications.

</details>


### [324] [How Instruction-Tuning Imparts Length Control: A Cross-Lingual Mechanistic Analysis](https://arxiv.org/abs/2509.02075)
*Elisabetta Rocchetti,Alfio Ferrara*

Main category: cs.CL

TL;DR: Instruction-tuning significantly improves LLMs' length-controlled text generation by specializing deeper model layers, with attention heads in later layers being key, especially for English, while Italian models show stronger MLP roles in final layers.


<details>
  <summary>Details</summary>
Motivation: Investigating the differences between foundation and instruction-tuned LLMs in length-controlled text generation, and analyzing performance and internal component contributions using Cumulative Weighted Attribution.

Method: Analyzed performance and internal component contributions using Cumulative Weighted Attribution, a metric derived from Direct Logit Attribution, focusing on English and Italian text generation.

Result: Instruction-tuning substantially improves length control, specializing deeper layers. Attention heads in later layers show positive contributions, especially in English. In Italian, final-layer MLPs play a stronger role.

Conclusion: Instruction-tuning reconfigures later layers for task adherence, with component-level strategies adapting to linguistic context.

Abstract: Adhering to explicit length constraints, such as generating text with a
precise word count, remains a significant challenge for Large Language Models
(LLMs). This study aims at investigating the differences between foundation
models and their instruction-tuned counterparts, on length-controlled text
generation in English and Italian. We analyze both performance and internal
component contributions using Cumulative Weighted Attribution, a metric derived
from Direct Logit Attribution. Our findings reveal that instruction-tuning
substantially improves length control, primarily by specializing components in
deeper model layers. Specifically, attention heads in later layers of IT models
show increasingly positive contributions, particularly in English. In Italian,
while attention contributions are more attenuated, final-layer MLPs exhibit a
stronger positive role, suggesting a compensatory mechanism. These results
indicate that instruction-tuning reconfigures later layers for task adherence,
with component-level strategies potentially adapting to linguistic context.

</details>


### [325] [Better by Comparison: Retrieval-Augmented Contrastive Reasoning for Automatic Prompt Optimization](https://arxiv.org/abs/2509.02093)
*Juhyeon Lee,Wonduk Seo,Hyunjin An,Seunghyun Lee,Yi Bu*

Main category: cs.CL

TL;DR: CRPO框架通过检索增强的对比推理来优化LLM提示，提高了生成质量，并在HelpSteer2基准测试中显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法忽视了利用LLM的推理能力从对比示例中学习的潜力。

Method: CRPO框架通过检索HelpSteer2数据集中的参考提示，并利用两种对比推理范式：分层对比推理（LLM比较不同质量的提示）和多指标对比推理（LLM分析不同评估维度上的最佳提示）。

Result: CRPO在HelpSteer2基准测试中显著优于其他基线方法。

Conclusion: 对比的、检索增强的推理有望推动自动提示优化。

Abstract: Automatic prompt optimization has recently emerged as a strategy for
improving the quality of prompts used in Large Language Models (LLMs), with the
goal of generating more accurate and useful responses. However, most prior work
focuses on direct prompt refinement or model fine-tuning, overlooking the
potential of leveraging LLMs' inherent reasoning capability to learn from
contrasting examples. In this paper, we present Contrastive Reasoning Prompt
Optimization (CRPO), a novel framework that formulates prompt optimization as a
retrieval augmented reasoning process. Our approach retrieves top k reference
prompts from the HelpSteer2 dataset, an open-source collection annotated for
helpfulness, correctness, coherence, complexity, and verbosity, and constructs
two complementary optimization paradigms: (1) tiered contrastive reasoning,
where the LLM compares high, medium, and low quality prompts to refine its own
generation through reflective reasoning, and (2) multi-metric contrastive
reasoning, where the LLM analyzes the best prompts along each evaluation
dimension and integrates their strengths into an optimized prompt. By
explicitly contrasting high and low quality exemplars, CRPO enables the model
to deduce why certain prompts succeed while others fail, thereby achieving more
robust and interpretable optimization. Experimental results on the HelpSteer2
benchmark demonstrate that CRPO significantly outperforms baselines. Our
findings highlight the promise of contrastive, retrieval-augmented reasoning
for advancing automatic prompt optimization.

</details>


### [326] [JudgeAgent: Dynamically Evaluate LLMs with Agent-as-Interviewer](https://arxiv.org/abs/2509.02097)
*Zhichao Shi,Xuhui Jiang,Chengjin Xu,Cangli Yao,Zhenxin Huang,Shengjie Ma,Yinghan Shen,Yuanzhuo Wang*

Main category: cs.CL

TL;DR: JudgeAgent是一个基于面试官风格评估范式的新型LLM评估框架，通过基准测试、交互式扩展和评估反馈，实现了知识目标自适应动态评估。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估范式（基于预定义问答集）存在交互有限、难度控制不足、结果验证困难等问题，难以精确确定模型能力边界。

Method: 提出JudgeAgent框架，采用面试官风格评估范式，包含基准测试、交互式扩展和评估反馈。利用知识驱动数据合成和目标自适应难度调整方法进行扩展测试。

Result: 通过广泛实验证明了JudgeAgent及其动态评估范式的有效性，并提出了一种验证评估方法的新见解。

Conclusion: JudgeAgent通过其创新的评估范式和方法，能够提供更准确有效的LLM评估结果，克服了传统评估方法的局限性。

Abstract: Evaluating the capabilities of large language models (LLMs) is an essential
step to ensure the successful application of LLMs across various domains. The
current evaluation of LLMs is based on a paradigm that involves querying them
with predefined question sets and assessing their outputs. This paradigm offers
controllable processes and simplicity, but faces challenges such as limited
interaction with targets, insufficient difficulty control, and difficulties in
verifying the validity of evaluation results, making it hard to precisely
determine the knowledge and capability boundaries of target models. To address
these challenges, we propose JudgeAgent, a knowledge-target adaptive dynamic
evaluation framework based on a new interviewer-style evaluation paradigm.
JudgeAgent employs a comprehensive evaluation approach consisting of benchmark
grading, interactive extension, and evaluation feedback. It utilizes
knowledge-driven data synthesis and target-adaptive difficulty adjustment
methods to conduct extended testing, providing accurate and effective
evaluation results. We also introduce a novel insight into validating
evaluation methods, demonstrating the effectiveness of JudgeAgent and its
dynamic evaluation paradigm through extensive experiments.

</details>


### [327] [CMRAG: Co-modality-based document retrieval and visual question answering](https://arxiv.org/abs/2509.02123)
*Wang Chen,Guanqiang Qi,Weikang Li,Yang Li*

Main category: cs.CL

TL;DR: CMRAG是一种结合文本和图像信息的多模态文档问答方法，通过结构化解析、跨模态检索和VLM生成，提升了视觉文档问答的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG方法在处理多模态文档时存在局限：仅依赖文本提取的方法无法处理图像信息，而仅依赖视觉输入的方法忽略了文本的语义优势，导致生成结果不佳。

Method: 提出co-modality-based RAG (CMRAG) 方法，首先对文档进行结构化解析以获得文本和图像区域的共模态表示；然后，针对用户查询，分别从文本和图像通道检索候选证据，并在跨模态检索层面聚合结果；最后，基于共模态检索结果提示VLM生成最终答案。

Result: CMRAG在视觉文档问答任务上的表现显著优于纯视觉RAG方法。

Conclusion: 将共模态信息以统一的方式整合到RAG框架中是提升复杂文档视觉问答系统性能的有效途径。

Abstract: Retrieval-Augmented Generation (RAG) has become a core paradigm in document
question answering tasks. However, existing methods have limitations when
dealing with multimodal documents: one category of methods relies on layout
analysis and text extraction, which can only utilize explicit text information
and struggle to capture images or unstructured content; the other category
treats document segmentation as visual input and directly passes it to visual
language models (VLMs) for processing, yet it ignores the semantic advantages
of text, leading to suboptimal generation results. This paper proposes
co-modality-based RAG (CMRAG), which can simultaneously leverage text and
images for efficient retrieval and generation. Specifically, we first perform
structured parsing on documents to obtain co-modality representations of text
segments and image regions. Subsequently, in response to user queries, we
retrieve candidate evidence from text and image channels, respectively, and
aggregate the results at the cross-modal retrieval level. Finally, we prompt
the VLM to generate the final response based on the co-modality retrieval
results. Experiments demonstrate that our method significantly outperforms
pure-vision-based RAG in visual document question answering tasks. The findings
of this paper show that integrating co-modality information into the RAG
framework in a unified manner is an effective approach to improving the
performance of complex document visual question-answering (VQA) systems.

</details>


### [328] [AMBEDKAR-A Multi-level Bias Elimination through a Decoding Approach with Knowledge Augmentation for Robust Constitutional Alignment of Language Models](https://arxiv.org/abs/2509.02133)
*Snehasis Mukhopadhyay,Aryan Kasat,Shivam Dubey,Rahul Karthikeyan,Dhruv Sood,Vinija Jain,Aman Chadha,Amitava Das*

Main category: cs.CL

TL;DR: LLM在印度语境下会反映出与种姓和宗教相关的社会偏见。本文提出AMBEDKAR框架，通过引入一个'宪法意识解码层'，借鉴印度宪法的平等主义原则，在推理时实时减少偏见，而无需更新模型参数。该框架通过'公平性-投机性'范式，将小语言模型（SLM）作为潜在偏见生成器，大语言模型（LLM）作为遵循宪法的验证器，以强制执行公平的生成轨迹。实验证明，该方法可将偏见绝对减少高达26.41%。


<details>
  <summary>Details</summary>
Motivation: 由于现有LLM的偏见缓解策略以西方为中心，未能解决印度语境下与种姓和宗教相关的特定偏见问题，因此需要一种适用于印度本地情况的解决方案。

Method: 提出AMBEDKAR框架，包含一个'宪法意识解码层'，该层在推理时激活，通过一个'投机性解码'算法来减少偏见。该框架的特点是，由一个潜在偏见的小语言模型（SLM）负责生成，而一个遵循宪法的大语言模型（LLM）负责验证和修正，从而实现“公平性-投机性”的范式。

Result: AMBEDKAR框架在减少与种姓和宗教相关的偏见方面取得了显著成效，相比基线模型，偏见绝对减少了高达26.41%。

Conclusion: AMBEDKAR框架通过引入新颖的“公平性-投机性”范式和“宪法意识解码层”，成功地在印度语境下缓解了LLM的种姓和宗教偏见，且无需更新模型参数，降低了成本，为开发更公平、更具包容性的AI系统提供了有效途径。

Abstract: Large Language Models (LLMs) can inadvertently reflect societal biases
present in their training data, leading to harmful or prejudiced outputs. In
the Indian context, our empirical evaluations across a suite of models reveal
that biases around caste and religion are particularly salient. Yet, most
existing mitigation strategies are Western-centric and fail to address these
local nuances. We propose AMBEDKAR, a framework inspired by the egalitarian
vision of Dr B. R. Ambedkar, architect of the Indian Constitution, to guide LLM
outputs toward fairness, neutrality, and inclusion in line with Articles 14 to
17. Our approach introduces a Constitution-Aware Decoding Layer, guided by the
AI Constitution of India and applied only at inference time, without any
parameter updates to the base model. We incorporate a speculative decoding
algorithm that proactively reduces casteist and communal bias during
generation. This mitigation layer operates directly within the decoding
process, avoiding changes to model internals and lowering the computational and
infrastructural costs associated with retraining. We reinterpret speculative
decoding not merely as an efficiency tool but as a mechanism for fairness. In
this framework, a Small Language Model (SLM) acts as a potentially biased
generator, while a constitutionally guided Large Language Model (LLM) serves as
the verifier. Rather than accelerating generation, the LLM enforces bias-robust
trajectories in the SLM outputs. This inversion of roles gives rise to a
fairness-by-speculation paradigm. Our approach yields an absolute reduction of
bias up to 26.41 percent compared to baseline. Our source code, datasets, and
results are available at https://anonymous.4open.science/r/AMBEDKAR-983B/

</details>


### [329] [Meta-Pretraining for Zero-Shot Cross-Lingual Named Entity Recognition in Low-Resource Philippine Languages](https://arxiv.org/abs/2509.02160)
*David Demitri Africa,Suchir Salhan,Yuval Weiss,Paula Buttery,Richard Diehl Martinez*

Main category: cs.CL

TL;DR: 通过结合MAML和小型解码器LM来改进低资源语言的NER，即使在预训练中未见过也能实现快速适应和零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决内存或延迟受限环境中，低资源语言NER通常依赖大型多语言LM进行微调的不可行性问题，探索小型解码器LM的零样本迁移能力。

Method: 将自回归目标的一部分替换为一阶模型无关元学习（MAML），并在塔加洛语和宿务语上进行训练和测试。

Result: 在塔加洛语和宿务语上，MAML使零样本micro-F1提高了2-6个百分点（仅微调头部），或1-3个百分点（完全微调），同时将收敛时间缩短了8%。对于与塔加洛语案例粒子si/ni共现的单令牌个人实体，提升效果最显著。

Conclusion: MAML是一种有效的方法，可以使小型解码器LM快速适应并实现低资源语言NER的零样本迁移，尤其是在存在表面锚点的情况下。

Abstract: Named-entity recognition (NER) in low-resource languages is usually tackled
by finetuning very large multilingual LMs, an option that is often infeasible
in memory- or latency-constrained settings. We ask whether small decoder LMs
can be pretrained so that they adapt quickly and transfer zero-shot to
languages unseen during pretraining. To this end we replace part of the
autoregressive objective with first-order model-agnostic meta-learning (MAML).
Tagalog and Cebuano are typologically similar yet structurally different in
their actor/non-actor voice systems, and hence serve as a challenging test-bed.
Across four model sizes (11 M - 570 M) MAML lifts zero-shot micro-F1 by 2-6 pp
under head-only tuning and 1-3 pp after full tuning, while cutting convergence
time by up to 8%. Gains are largest for single-token person entities that
co-occur with Tagalog case particles si/ni, highlighting the importance of
surface anchors.

</details>


### [330] [Avoidance Decoding for Diverse Multi-Branch Story Generation](https://arxiv.org/abs/2509.02170)
*Kyeongman Park,Nakyeong Yang,Kyomin Jung*

Main category: cs.CL

TL;DR: LLMs 容易生成重复、单调的输出，特别是在故事生成等任务中。本文提出了一种新的解码策略“Avoidance Decoding”，通过惩罚与先前生成输出的相似性来修改 token logits，从而鼓励更多样化的多分支故事。该策略自适应地平衡了概念级相似性惩罚（早期优先）和叙事级相似性惩罚（后期逐渐加强），以确保自然而多样的情节发展。实验结果表明，该方法比强基线方法实现了高达 2.6 倍的输出多样性，并将重复率平均降低了 30%，同时有效缓解了文本退化。此外，该方法激活了更广泛的神经元，表明它利用了模型的内在创造力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在故事生成等任务中，面对相同输入提示时，往往会产生重复、单调的输出，这源于其有限的创意多样性。本研究旨在解决这一挑战。

Method: 提出了一种名为“Avoidance Decoding”的新解码策略。该策略通过修改 token logits 来实现，具体做法是惩罚与先前生成输出的相似性，从而鼓励生成更多样化的多分支故事。该惩罚策略能够自适应地平衡两种相似性度量：概念级相似性惩罚（优先用于早期阶段，以实现初始故事概念的多样化）和叙事级相似性惩罚（在后期逐渐加强，以确保情节发展的自然性和多样性）。

Result: 与强基线方法相比，本方法实现了高达 2.6 倍的输出多样性，并将重复率平均降低了 30%，同时有效缓解了文本退化。此外，实验还表明，该方法能够激活更广泛的神经元，证明其利用了模型的内在创造力。

Conclusion: Avoidance Decoding 是一种有效的新解码策略，能够显著提高 LLM 在故事生成等任务中的输出多样性，减少重复，并缓解文本退化。该方法通过结合概念级和叙事级相似性惩罚，并自适应地调整其权重，成功地引导模型生成更具创意和吸引力的内容。模型激活更广泛神经元的能力也表明，该方法能够激发 LLM 的内在创造潜力。

Abstract: Large Language Models (LLMs) often generate repetitive and monotonous
outputs, especially in tasks like story generation, due to limited creative
diversity when given the same input prompt. To address this challenge, we
propose a novel decoding strategy, Avoidance Decoding, that modifies token
logits by penalizing similarity to previously generated outputs, thereby
encouraging more diverse multi-branch stories. This penalty adaptively balances
two similarity measures: (1) Concept-level Similarity Penalty, which is
prioritized in early stages to diversify initial story concepts, and (2)
Narrative-level Similarity Penalty, which is increasingly emphasized later to
ensure natural yet diverse plot development. Notably, our method achieves up to
2.6 times higher output diversity and reduces repetition by an average of 30%
compared to strong baselines, while effectively mitigating text degeneration.
Furthermore, we reveal that our method activates a broader range of neurons,
demonstrating that it leverages the model's intrinsic creativity.

</details>


### [331] [FActBench: A Benchmark for Fine-grained Automatic Evaluation of LLM-Generated Text in the Medical Domain](https://arxiv.org/abs/2509.02198)
*Anum Afzal,Juraj Vladika,Florian Matthes*

Main category: cs.CL

TL;DR: FActBench是一个针对医学领域的大型语言模型事实核查基准，通过结合CoT和NLI技术，其评估结果与领域专家评估的相关性最高。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在专业领域（特别是医学领域）表现不佳，事实性是其中最关键的评估方面，而可靠的事实核查工具和数据源对于减少幻觉至关重要。

Method: 创建了一个包含四个生成任务和六个最先进的大型语言模型（LLMs）的医学领域综合事实核查基准FActBench，并使用了两种最先进的核查技术：思维链（CoT）提示和自然语言推理（NLI）。

Result: 实验表明，通过CoT和NLI技术的一致投票所获得的事实核查分数与领域专家评估的相关性最好。

Conclusion: 在医学领域，结合使用CoT和NLI技术进行事实核查，并通过一致投票的方式进行评估，能够更准确地反映大型语言模型的表现，并且该方法与领域专家评估具有高度相关性。

Abstract: Large Language Models tend to struggle when dealing with specialized domains.
While all aspects of evaluation hold importance, factuality is the most
critical one. Similarly, reliable fact-checking tools and data sources are
essential for hallucination mitigation. We address these issues by providing a
comprehensive Fact-checking Benchmark FActBench covering four generation tasks
and six state-of-the-art Large Language Models (LLMs) for the Medical domain.
We use two state-of-the-art Fact-checking techniques: Chain-of-Thought (CoT)
Prompting and Natural Language Inference (NLI). Our experiments show that the
fact-checking scores acquired through the Unanimous Voting of both techniques
correlate best with Domain Expert Evaluation.

</details>


### [332] [Towards Fundamental Language Models: Does Linguistic Competence Scale with Model Size?](https://arxiv.org/abs/2509.02225)
*Jaime Collado-Montañez,L. Alfonso Ureña-López,Arturo Montejo-Ráez*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models offer impressive language capabilities but suffer from
well-known limitations, including hallucinations, biases, privacy concerns, and
high computational costs. These issues are largely driven by the combination of
linguistic competence and factual memorization within a single monolithic
model. This paper introduces and empirically supports the Fundamental Language
Model (FLM) paradigm, which advocates for smaller, linguistically competent
models that offload factual retrieval to external tools. We evaluate models
ranging from 135M to 32B parameters across three dimensions: linguistic
competence, external factual knowledge, and internal factual knowledge. Our
findings reveal that while both linguistic competence and factual knowledge
improve with scale, internal factual knowledge grows significantly faster,
suggesting that model size is more closely tied to memorization than to core
language ability. These results support a modular approach to language
modeling, where compact, linguistically proficient models serve as the
foundation for tool-augmented systems. The FLM paradigm offers a path toward
more efficient, interpretable, and sustainable NLP solutions.

</details>


### [333] [LLMs and their Limited Theory of Mind: Evaluating Mental State Annotations in Situated Dialogue](https://arxiv.org/abs/2509.02292)
*Katharine Kowalyshyn,Matthias Scheutz*

Main category: cs.CL

TL;DR: 大型语言模型可用于分析团队对话中的认知差异，并在空间推理和韵律线索消歧方面发现其局限性。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在识别和量化团队对话中共享心智模型（SMM）及其成员间认知差异方面的潜力。

Method: 提出一个两步框架：第一步，利用大型语言模型对合作远程搜索任务（CReST）语料库中的对话进行标注，识别SMM元素；第二步，训练另一个大型语言模型，将模型生成的标注与人类标注进行比较，以检测和表征认知差异。定义了一个SMM一致性评估框架，并应用于六个CReST对话。

Result: 生成了一个包含人类和大型语言模型标注的数据集，一个可复现的SMM一致性评估框架，以及对基于大型语言模型的差异检测的实证评估。结果表明，大型语言模型在简单的自然语言标注任务中表现出一致性，但在涉及空间推理或韵律线索消歧的任务中存在系统性错误。

Conclusion: 大型语言模型在分析团队对话和检测认知差异方面显示出潜力，但在需要复杂推理（如空间推理和韵律线索消歧）的任务中仍需改进。

Abstract: What if large language models could not only infer human mindsets but also
expose every blind spot in team dialogue such as discrepancies in the team
members' joint understanding? We present a novel, two-step framework that
leverages large language models (LLMs) both as human-style annotators of team
dialogues to track the team's shared mental models (SMMs) and as automated
discrepancy detectors among individuals' mental states. In the first step, an
LLM generates annotations by identifying SMM elements within task-oriented
dialogues from the Cooperative Remote Search Task (CReST) corpus. Then, a
secondary LLM compares these LLM-derived annotations and human annotations
against gold-standard labels to detect and characterize divergences. We define
an SMM coherence evaluation framework for this use case and apply it to six
CReST dialogues, ultimately producing: (1) a dataset of human and LLM
annotations; (2) a reproducible evaluation framework for SMM coherence; and (3)
an empirical assessment of LLM-based discrepancy detection. Our results reveal
that, although LLMs exhibit apparent coherence on straightforward
natural-language annotation tasks, they systematically err in scenarios
requiring spatial reasoning or disambiguation of prosodic cues.

</details>


### [334] [DCPO: Dynamic Clipping Policy Optimization](https://arxiv.org/abs/2509.02333)
*Shihui Yang,Chengfeng Dou,Peidong Guo,Kai Lu,Qiang Ju,Fei Deng,Rihui Xin*

Main category: cs.CL

TL;DR: DCPO通过动态裁剪和奖励标准化解决了现有RLVR方法中的零梯度问题，显著提高了LLM的推理能力和训练效率，并在多个基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习从可验证奖励（RLVR）框架，特别是GRPO，在处理大型语言模型（LLMs）的推理能力时，常遇到零梯度问题。这主要是由于固定的裁剪边界和相同的奖励标准化，导致梯度更新无效和生成响应利用不足。

Method: 提出动态裁剪策略优化（DCPO），引入动态裁剪策略，根据token的先验概率自适应调整裁剪边界，以增强token级别的探索；并采用平滑优势标准化技术，跨累积训练步骤标准化奖励，以提高响应级别的生成响应有效利用率。

Result: DCPO在四个不同模型的四个基准测试中均实现了最先进的性能。例如，在AIME24基准测试上，DCPO在Qwen2.5-Math-7B模型上取得了比DAPO和GRPO更高的Avg@1和Avg@32。在AIME25基准测试上，DCPO在Qwen2.5-14B模型上也显著优于GRPO和DAPO。此外，DCPO使非零优势平均提高了28%，训练效率提高了一倍，并将token裁剪率降低了一个数量级。

Conclusion: DCPO通过其创新的动态裁剪和奖励标准化方法，有效地解决了现有RLVR方法的局限性，显著提高了LLMs利用生成数据进行学习的效率和性能，为LLMs的推理能力提升提供了有效的解决方案。

Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a
promising framework for enhancing the reasoning capabilities of large language
models. However, existing approaches such as GRPO often suffer from zero
gradients. This problem arises primarily due to fixed clipping bounds for
token-level probability ratios and the standardization of identical rewards,
which can lead to ineffective gradient updates and underutilization of
generated responses. In this work, we propose Dynamic Clipping Policy
Optimization (DCPO), which introduces a dynamic clipping strategy that
adaptively adjusts the clipping bounds based on token-specific prior
probabilities to enhance token-level exploration, and a smooth advantage
standardization technique that standardizes rewards across cumulative training
steps to improve the response-level effective utilization of generated
responses. DCPO achieved state-of-the-art performance on four benchmarks based
on four different models. In particular, DCPO achieved an Avg@1 of 46.7 under
greedy decoding and an Avg@32 of 38.8 under 32 times sampling on the AIME24
benchmark, surpassing both DAPO (36.7/31.6) and GRPO (36.7/32.1) on the
Qwen2.5-Math-7B model. On the AIME25 benchmark based on Qwen2.5-14B, DCPO
achieves a performance of (23.3/19.0), surpassing GRPO (13.3/10.5) and DAPO
(20.0/15.3). Furthermore, DCPO achieved an average 28% improvement in the
nonzero advantage over GRPO in four models, doubled the training efficiency
over DAPO, and significantly reduced the token clipping ratio by an order of
magnitude compared to both GRPO and DAPO, while achieving superior performance.
These results highlight DCPO's effectiveness in leveraging generated data more
efficiently for reinforcement learning in large language models.

</details>


### [335] [Implicit Reasoning in Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2509.02350)
*Jindong Li,Yali Fu,Li Fan,Jiahong Liu,Yao Shu,Chengwei Qin,Menglin Yang,Irwin King,Rex Ying*

Main category: cs.CL

TL;DR: LLMs的隐式推理通过潜在结构进行，无需中间文本步骤，可降低成本、加快推理速度并更好地与内部计算对齐。本调查通过执行范式分类现有方法，重点关注计算策略，并回顾了评估隐式推理有效性的指标和基准。


<details>
  <summary>Details</summary>
Motivation: LLMs的隐式推理研究，填补了现有调查在机制层面考察LLMs内部推理机制的空白。

Method: 将现有方法归纳为三个执行范式：潜在优化、信号引导控制和层递归执行，并回顾了支持LLMs隐式推理的证据、评估指标和基准。

Result: 对LLMs隐式推理的机制进行了梳理，并提供了评估方法和基准的概述。

Conclusion: LLMs的隐式推理是其核心能力之一，通过对不同执行范式的研究，有助于理解和优化其推理过程。

Abstract: Large Language Models (LLMs) have demonstrated strong generalization across a
wide range of tasks. Reasoning with LLMs is central to solving multi-step
problems and complex decision-making. To support efficient reasoning, recent
studies have shifted attention from explicit chain-of-thought prompting toward
implicit reasoning, where reasoning occurs silently via latent structures
without emitting intermediate textual steps. Implicit reasoning brings
advantages such as lower generation cost, faster inference, and better
alignment with internal computation. Although prior surveys have discussed
latent representations in the context of reasoning, a dedicated and
mechanism-level examination of how reasoning unfolds internally within LLMs
remains absent. This survey fills that gap by introducing a taxonomy centered
on execution paradigms, shifting the focus from representational forms to
computational strategies. We organize existing methods into three execution
paradigms based on \textbf{\textit{how and where internal computation
unfolds}}: latent optimization, signal-guided control, and layer-recurrent
execution. We also review structural, behavioral and representation-based
evidence that supports the presence of implicit reasoning in LLMs. We further
provide a structured overview of the evaluation metrics and benchmarks used in
existing works to assess the effectiveness and reliability of implicit
reasoning.We maintain a continuously updated project at:
https://github.com/digailab/awesome-llm-implicit-reasoning.

</details>


### [336] [Towards Temporal Knowledge-Base Creation for Fine-Grained Opinion Analysis with Language Models](https://arxiv.org/abs/2509.02363)
*Gaurav Negi,Atul Kr. Ojha,Omnia Zayed,Paul Buitelaar*

Main category: cs.CL

TL;DR: LLM驱动的临时意见知识库构建方法，用于细粒度的时间序列意见分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法在时间序列意见分析方面潜力未被充分挖掘，因为缺乏时间性的细粒度标注。

Method: 提出一种可扩展的方法，利用LLM作为自动标注器，将意见挖掘方法集成到声明式LLM标注流程中，无需手动提示工程，并定义了三个基于情感和意见挖掘文献的数据模型作为结构化表示的模式。

Result: 通过与人工标注样本进行严格的定量评估，使用两个独立的LLM进行最终标注，并计算了跨细粒度意见维度的标注者间一致性。

Conclusion: 该方法构建了一个时间对齐、结构化的意见知识库，适用于检索增强生成（RAG）、时间问答和时间线摘要等应用。

Abstract: We propose a scalable method for constructing a temporal opinion knowledge
base with large language models (LLMs) as automated annotators. Despite the
demonstrated utility of time-series opinion analysis of text for downstream
applications such as forecasting and trend analysis, existing methodologies
underexploit this potential due to the absence of temporally grounded
fine-grained annotations. Our approach addresses this gap by integrating
well-established opinion mining formulations into a declarative LLM annotation
pipeline, enabling structured opinion extraction without manual prompt
engineering. We define three data models grounded in sentiment and opinion
mining literature, serving as schemas for structured representation. We perform
rigorous quantitative evaluation of our pipeline using human-annotated test
samples. We carry out the final annotations using two separate LLMs, and
inter-annotator agreement is computed label-wise across the fine-grained
opinion dimensions, analogous to human annotation protocols. The resulting
knowledge base encapsulates time-aligned, structured opinions and is compatible
with applications in Retrieval-Augmented Generation (RAG), temporal question
answering, and timeline summarisation.

</details>


### [337] [An Ensemble Classification Approach in A Multi-Layered Large Language Model Framework for Disease Prediction](https://arxiv.org/abs/2509.02446)
*Ali Hamdi,Malak Mohamed,Rokaia Emad,Khaled Shaban*

Main category: cs.CL

TL;DR: 本研究旨在评估阿拉伯语医疗文本预处理方法（摘要、精炼、命名实体识别）与微调阿拉伯语Transformer模型（CAMeLBERT、AraBERT、AsafayaBERT）的结合效果，并通过多数投票集成来提高疾病分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 利用社交媒体和在线健康平台的海量阿拉伯语医疗数据，结合大型语言模型和Transformer模型的强大文本处理能力，以改进疾病分类的准确性。

Method: 评估了摘要、精炼和命名实体识别三种阿拉伯语文本预处理方法，并将这些方法与微调后的CAMeLBERT、AraBERT和AsafayaBERT模型结合。采用多数投票集成策略，融合原始文本和预处理文本的预测结果，以增强模型的鲁棒性。

Result: 所提出的结合LLM预处理、微调阿拉伯语Transformer模型和集成学习的方法，在疾病分类任务中达到了80.56%的最佳准确率。

Conclusion: 通过结合LLM预处理技术、微调的阿拉伯语Transformer模型以及集成学习策略，可以有效提升阿拉伯语社交远程医疗数据的疾病分类准确性。该研究首次实现了这一方法的整合，为处理此类数据提供了新的途径。

Abstract: Social telehealth has made remarkable progress in healthcare by allowing
patients to post symptoms and participate in medical consultations remotely.
Users frequently post symptoms on social media and online health platforms,
creating a huge repository of medical data that can be leveraged for disease
classification. Large language models (LLMs) such as LLAMA3 and GPT-3.5, along
with transformer-based models like BERT, have demonstrated strong capabilities
in processing complex medical text. In this study, we evaluate three Arabic
medical text preprocessing methods such as summarization, refinement, and Named
Entity Recognition (NER) before applying fine-tuned Arabic transformer models
(CAMeLBERT, AraBERT, and AsafayaBERT). To enhance robustness, we adopt a
majority voting ensemble that combines predictions from original and
preprocessed text representations. This approach achieved the best
classification accuracy of 80.56%, thus showing its effectiveness in leveraging
various text representations and model predictions to improve the understanding
of medical texts. To the best of our knowledge, this is the first work that
integrates LLM-based preprocessing with fine-tuned Arabic transformer models
and ensemble learning for disease classification in Arabic social telehealth
data.

</details>


### [338] [EmoPerso: Enhancing Personality Detection with Self-Supervised Emotion-Aware Modelling](https://arxiv.org/abs/2509.02450)
*Lingzhi Shen,Xiaohao Cai,Yunfei Long,Imran Razzak,Guanming Chen,Shoaib Jameel*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Personality detection from text is commonly performed by analysing users'
social media posts. However, existing methods heavily rely on large-scale
annotated datasets, making it challenging to obtain high-quality personality
labels. Moreover, most studies treat emotion and personality as independent
variables, overlooking their interactions. In this paper, we propose a novel
self-supervised framework, EmoPerso, which improves personality detection
through emotion-aware modelling. EmoPerso first leverages generative mechanisms
for synthetic data augmentation and rich representation learning. It then
extracts pseudo-labeled emotion features and jointly optimizes them with
personality prediction via multi-task learning. A cross-attention module is
employed to capture fine-grained interactions between personality traits and
the inferred emotional representations. To further refine relational reasoning,
EmoPerso adopts a self-taught strategy to enhance the model's reasoning
capabilities iteratively. Extensive experiments on two benchmark datasets
demonstrate that EmoPerso surpasses state-of-the-art models. The source code is
available at https://github.com/slz0925/EmoPerso.

</details>


### [339] [Do LLMs Adhere to Label Definitions? Examining Their Receptivity to External Label Definitions](https://arxiv.org/abs/2509.02452)
*Seyedali Mohammadi,Bhaskara Hanuma Vedula,Hemank Lamba,Edward Raff,Ponnurangam Kumaraguru,Francis Ferraro,Manas Gaur*

Main category: cs.CL

TL;DR: LLMs may not fully integrate external definitions and often rely on their internal knowledge, especially for general tasks. Domain-specific tasks benefit more from explicit definitions, but integration is inconsistent.


<details>
  <summary>Details</summary>
Motivation: To investigate whether Large Language Models (LLMs) truly incorporate external definitions or primarily rely on their parametric knowledge.

Method: Conducted controlled experiments on multiple explanation benchmark datasets with various label definition conditions (expert-curated, LLM-generated, perturbed, swapped).

Result: Explicit label definitions can improve accuracy and explainability, but LLMs' integration of these definitions is inconsistent and not guaranteed, indicating a frequent reliance on internalized representations. LLMs tend to default to internal representations in general tasks, while domain-specific tasks show greater benefit from explicit definitions.

Conclusion: LLMs' integration of external knowledge is inconsistent, suggesting a need for further research into how they process external information alongside their pre-existing capabilities.

Abstract: Do LLMs genuinely incorporate external definitions, or do they primarily rely
on their parametric knowledge? To address these questions, we conduct
controlled experiments across multiple explanation benchmark datasets (general
and domain-specific) and label definition conditions, including expert-curated,
LLM-generated, perturbed, and swapped definitions. Our results reveal that
while explicit label definitions can enhance accuracy and explainability, their
integration into an LLM's task-solving processes is neither guaranteed nor
consistent, suggesting reliance on internalized representations in many cases.
Models often default to their internal representations, particularly in general
tasks, whereas domain-specific tasks benefit more from explicit definitions.
These findings underscore the need for a deeper understanding of how LLMs
process external knowledge alongside their pre-existing capabilities.

</details>


### [340] [SpecEval: Evaluating Model Adherence to Behavior Specifications](https://arxiv.org/abs/2509.02464)
*Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang*

Main category: cs.CL

TL;DR: 本研究介绍了一个自动框架，用于审计大型语言模型是否符合其开发者发布的行为准则，发现模型在实际表现中存在系统性不一致和合规差距。


<details>
  <summary>Details</summary>
Motivation: 虽然模型开发者发布了行为准则，但尚不清楚模型是否真正遵守了这些准则。本研究旨在系统性地审计模型对这些准则的遵守情况。

Method: 本研究引入了一个自动框架，通过解析行为声明、生成目标提示，并利用模型自身的评估能力来审计模型是否符合其开发者规范。该框架侧重于开发者规范、模型输出及其自身模型作为评估者之间的三方一致性。

Result: 研究将该框架应用于六个开发商的十六个模型，覆盖一百多项行为声明，结果发现存在系统性不一致，合规差距最高达20%。

Conclusion: 基础模型至少应在开发者评估模型的判断下，一致地满足开发者发布的行为规范。本研究发现模型在实际表现中存在与开发者规范不一致的情况，表明需要进一步关注和改进。

Abstract: Companies that develop foundation models publish behavioral guidelines they
pledge their models will follow, but it remains unclear if models actually do
so. While providers such as OpenAI, Anthropic, and Google have published
detailed specifications describing both desired safety constraints and
qualitative traits for their models, there has been no systematic audit of
adherence to these guidelines. We introduce an automated framework that audits
models against their providers specifications by parsing behavioral statements,
generating targeted prompts, and using models to judge adherence. Our central
focus is on three way consistency between a provider specification, its model
outputs, and its own models as judges; an extension of prior two way generator
validator consistency. This establishes a necessary baseline: at minimum, a
foundation model should consistently satisfy the developer behavioral
specifications when judged by the developer evaluator models. We apply our
framework to 16 models from six developers across more than 100 behavioral
statements, finding systematic inconsistencies including compliance gaps of up
to 20 percent across providers.

</details>


### [341] [GRAM-R$^2$: Self-Training Generative Foundation Reward Models for Reward Reasoning](https://arxiv.org/abs/2509.02492)
*Chenglong Wang,Yongyu Mu,Hang Zhou,Yifu Huo,Ziming Zhu,Jiali Zeng,Murun Yang,Bei Li,Tong Xiao,Xiaoyang Hao,Chunliang Zhang,Fandong Meng,Jingbo Zhu*

Main category: cs.CL

TL;DR: 研究提出了一种名为GRAM-R^2的生成式奖励模型，能够生成偏好标签和奖励理由，以解决现有奖励模型依赖大规模标注数据且缺乏显式推理能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型面临依赖大规模标注数据和缺乏显式推理能力的挑战。

Method: 提出了一种利用无标签数据进行自我训练的方法，以激发奖励模型进行奖励推理，并开发了GRAM-R^2模型，该模型能生成偏好标签和奖励理由。

Result: GRAM-R^2在响应排序、任务适应和基于人类反馈的强化学习等任务上表现出色，优于多个强有力的判别式和生成式基线模型。

Conclusion: GRAM-R^2作为一个基础模型，能够为奖励推理提供支持，并能应用于多种下游任务，具有广泛的应用前景。

Abstract: Significant progress in reward modeling over recent years has been driven by
a paradigm shift from task-specific designs towards generalist reward models.
Despite this trend, developing effective reward models remains a fundamental
challenge: the heavy reliance on large-scale labeled preference data.
Pre-training on abundant unlabeled data offers a promising direction, but
existing approaches fall short of instilling explicit reasoning into reward
models. To bridge this gap, we propose a self-training approach that leverages
unlabeled data to elicit reward reasoning in reward models. Based on this
approach, we develop GRAM-R$^2$, a generative reward model trained to produce
not only preference labels but also accompanying reward rationales. GRAM-R$^2$
can serve as a foundation model for reward reasoning and can be applied to a
wide range of tasks with minimal or no additional fine-tuning. It can support
downstream applications such as response ranking and task-specific reward
tuning. Experiments on response ranking, task adaptation, and reinforcement
learning from human feedback demonstrate that GRAM-R$^2$ consistently delivers
strong performance, outperforming several strong discriminative and generative
baselines.

</details>


### [342] [MoSEs: Uncertainty-Aware AI-Generated Text Detection via Mixture of Stylistics Experts with Conditional Thresholds](https://arxiv.org/abs/2509.02499)
*Junxi Wu,Jinpeng Wang,Zheng Liu,Bin Chen,Dongjian Hu,Hao Wu,Shu-Tao Xiu*

Main category: cs.CL

TL;DR: 该研究提出了一种名为MoSEs的混合风格专家框架，用于提高AI生成文本检测的准确性，特别是在低资源场景下，通过结合风格建模和不确定性量化。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成文本检测方法在风格建模和阈值设定方面存在不足，导致检测性能受限。本研究旨在通过引入风格感知的不确定性量化来解决这些问题。

Method: 提出了一种名为MoSEs的混合风格专家框架，该框架包含风格参考库（SRR）、风格感知路由器（SAR）和条件阈值估计器（CTE）。SRR激活相关参考数据，CTE结合语言统计属性和语义特征动态确定最优阈值，从而实现风格感知的不确定性量化。

Result: 与基线方法相比，MoSEs的平均检测性能提高了11.34%。在低资源场景下，MoSEs的性能提升更为显著，达到了39.15%。

Conclusion: MoSEs框架通过风格建模和条件阈值估计，能够有效提高AI生成文本检测的性能，尤其在低资源场景下效果显著，为构建可信赖的AI生成文本检测系统提供了新的解决方案。

Abstract: The rapid advancement of large language models has intensified public
concerns about the potential misuse. Therefore, it is important to build
trustworthy AI-generated text detection systems. Existing methods neglect
stylistic modeling and mostly rely on static thresholds, which greatly limits
the detection performance. In this paper, we propose the Mixture of Stylistic
Experts (MoSEs) framework that enables stylistics-aware uncertainty
quantification through conditional threshold estimation. MoSEs contain three
core components, namely, the Stylistics Reference Repository (SRR), the
Stylistics-Aware Router (SAR), and the Conditional Threshold Estimator (CTE).
For input text, SRR can activate the appropriate reference data in SRR and
provide them to CTE. Subsequently, CTE jointly models the linguistic
statistical properties and semantic features to dynamically determine the
optimal threshold. With a discrimination score, MoSEs yields prediction labels
with the corresponding confidence level. Our framework achieves an average
improvement 11.34% in detection performance compared to baselines. More
inspiringly, MoSEs shows a more evident improvement 39.15% in the low-resource
case. Our code is available at https://github.com/creator-xi/MoSEs.

</details>


### [343] [L3Cube-IndicHeadline-ID: A Dataset for Headline Identification and Semantic Evaluation in Low-Resource Indian Languages](https://arxiv.org/abs/2509.02503)
*Nishant Tanksale,Tanmay Kokate,Darshan Gohad,Sarvadnyaa Barate,Raviraj Joshi*

Main category: cs.CL

TL;DR: 该论文发布了一个名为L3Cube-IndicHeadline-ID的数据集，包含十种印地语和英语的20,000篇新闻文章，每篇文章有四个标题变体（原文、语义相似、词汇相似、无关），用于评估和改进低资源语言的自然语言处理模型，特别是句子转换器在语义理解方面的表现。


<details>
  <summary>Details</summary>
Motivation: 低资源语言的语义评估在自然语言处理领域仍然是一个重大挑战，尤其是在印地语地区，由于缺乏高质量的基准测试，句子转换器（sentence transformers）的有效性尚未得到充分探索。

Method: 创建了一个名为L3Cube-IndicHeadline-ID的数据集，该数据集涵盖了十种低资源印地语语言（马拉地语、印地语、泰米尔语、古吉拉特语、奥里亚语、卡纳达语、马拉雅拉姆语、旁遮普语、泰卢固语、孟加拉语）以及英语。每种语言包含20,000篇新闻文章，并配有四个标题变体：原文、语义相似版本、词汇相似版本以及一个无关的版本。通过余弦相似度对包括多语言和特定语言模型在内的几种句子转换器进行了基准测试。

Result: 多语言模型表现一致良好，而特定语言模型的有效性则参差不齐。

Conclusion: L3Cube-IndicHeadline-ID数据集为评估和改进低资源语言（特别是印地语）的语义理解提供了宝贵的资源，可用于句子转换器和检索增强生成（RAG）等应用，并且可以重新用于多种自然语言处理任务。

Abstract: Semantic evaluation in low-resource languages remains a major challenge in
NLP. While sentence transformers have shown strong performance in high-resource
settings, their effectiveness in Indic languages is underexplored due to a lack
of high-quality benchmarks. To bridge this gap, we introduce
L3Cube-IndicHeadline-ID, a curated headline identification dataset spanning ten
low-resource Indic languages: Marathi, Hindi, Tamil, Gujarati, Odia, Kannada,
Malayalam, Punjabi, Telugu, Bengali and English. Each language includes 20,000
news articles paired with four headline variants: the original, a semantically
similar version, a lexically similar version, and an unrelated one, designed to
test fine-grained semantic understanding. The task requires selecting the
correct headline from the options using article-headline similarity. We
benchmark several sentence transformers, including multilingual and
language-specific models, using cosine similarity. Results show that
multilingual models consistently perform well, while language-specific models
vary in effectiveness. Given the rising use of similarity models in
Retrieval-Augmented Generation (RAG) pipelines, this dataset also serves as a
valuable resource for evaluating and improving semantic understanding in such
applications. Additionally, the dataset can be repurposed for multiple-choice
question answering, headline classification, or other task-specific evaluations
of LLMs, making it a versatile benchmark for Indic NLP. The dataset is shared
publicly at https://github.com/l3cube-pune/indic-nlp

</details>


### [344] [The Forgotten Code: Validating a Century-Old Translation System with AI](https://arxiv.org/abs/2509.02506)
*Jean-Marie Le Ray*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: A pioneering rule-based mechanical translation system (precursor of modern
RBMTs) was first presented in December 1929 by its inventor, Federico Pucci,
who later published the full method in a book titled "Il traduttore meccanico
ed il metodo per corrispondersi fra Europei conoscendo ciascuno solo la propria
lingua: Parte I", in Salerno (Italy), in 1931. This study illustrates how AI
breathes new life into the system of international keys and ideograms devised
by Pucci to translate from/into any Romance language (at least as a first
step). The methodology involves having the AIs retranslate, following Pucci's
method, the two text excerpts originally translated in 1931 and clearly
documented in his publication: a passage from Dante's La Vita Nuova, translated
from Italian into French, and a passage from Voltaire's Zadig, translated from
French into Italian. The result is notable: the two texts, translated 94 years
apart using the same method--by Pucci in 1931 and by AIs in 2025--show a low
average difference, with only minor variations observed. With Pucci's system
thus validated, it became feasible to have the AIs reproduce the excerpts in
English, Spanish, and German according to his method. The results were
consistent, and Pucci--via Artificial Intelligence--was tasked with translating
more modern and technical texts, thereby reviving, nearly a century later, an
invention that had remained almost entirely unknown and never applied beyond
its creator, now brought to wider attention and opened to possible
experimentation. Such a demonstration would not only affirm Pucci's historical
status but also place him among the precursors and intellectual contributors to
machine translation, whose work merits examination alongside figures such as
Troyanskij, Booth, and Weaver, with possible consequences for how the history
of the field is understood.

</details>


### [345] [Top-H Decoding: Adapting the Creativity and Coherence with Bounded Entropy in Text Generation](https://arxiv.org/abs/2509.02510)
*Erfan Baghaei Potraghloo,Seyedarmin Azizi,Souvik Kundu,Massoud Pedram*

Main category: cs.CL

TL;DR: top-H解码是一种新的文本生成方法，通过优化熵约束下的概率质量来平衡多样性和连贯性，在创意写作任务上比min-p采样提高了25.63%，并且在问答任务上保持了鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有文本生成方法在平衡多样性、创造性与逻辑连贯性方面存在不足，未能有效利用模型置信度信息。

Method: 提出top-H解码，从理论上建立了截断采样中的创造性与连贯性之间的关系，将其转化为熵约束下的质量最大化问题（ECMM），并设计了一个高效的贪心算法来解决它。

Result: top-H解码在创意写作基准测试上比min-p采样提高了高达25.63%，在GPQA、GSM8K和MT-Bench等问答数据集上表现稳健，并且在LLM评估中显示出更好的连贯性。

Conclusion: top-H解码是开放式文本生成领域的最新进展，能够轻松集成到创意写作应用中，有效解决了现有方法的局限性。

Abstract: Large language models (LLMs), despite their impressive performance across a
wide range of tasks, often struggle to balance two competing objectives in
open-ended text generation: fostering diversity and creativity while preserving
logical coherence. Existing truncated sampling techniques, including
temperature scaling, top-\$p\$ (nucleus) sampling, and min-\$p\$ sampling, aim
to manage this trade-off. However, they exhibit limitations, particularly in
the effective incorporation of the confidence of the model into the
corresponding sampling strategy. For example, min-\$p\$ sampling relies on a
single top token as a heuristic for confidence, eventually underutilizing the
information of the probability distribution. Toward effective incorporation of
the confidence of the model, in this paper, we present **top-H** decoding. We
first establish the theoretical foundation of the interplay between creativity
and coherence in truncated sampling by formulating an **entropy-constrained
minimum divergence** problem. We then prove this minimization problem to be
equivalent to an **entropy-constrained mass maximization** (ECMM) problem,
which is NP-hard. Finally, we present top-H decoding, a computationally
efficient greedy algorithm to solve the ECMM problem. Extensive empirical
evaluations demonstrate that top-H outperforms the state-of-the-art (SoTA)
alternative of min-\$p\$ sampling by up to **25.63%** on creative writing
benchmarks, while maintaining robustness on question-answering datasets such as
GPQA, GSM8K, and MT-Bench. Additionally, an *LLM-as-judge* evaluation confirms
that top-H indeed produces coherent outputs even at higher temperatures, where
creativity is especially critical. In summary, top-H advances SoTA in
open-ended text generation and can be *easily integrated* into creative writing
applications. The code is available at
https://github.com/ErfanBaghaei/Top-H-Decoding.

</details>


### [346] [Comparative Study of Pre-Trained BERT and Large Language Models for Code-Mixed Named Entity Recognition](https://arxiv.org/abs/2509.02514)
*Mayur Shirke,Amey Shembade,Pavan Thorat,Madhushri Wagh,Raviraj Joshi*

Main category: cs.CL

TL;DR: 本文比较了针对印地-英语（Hinglish）混合语命名实体识别（NER）任务的混合语微调模型、非混合语多语言模型以及零样本生成式大型语言模型（LLMs）。


<details>
  <summary>Details</summary>
Motivation: 评估不同类型的模型（混合语微调模型、非混合语多语言模型、零样本LLMs）在处理印地-英语（Hinglish）混合语命名实体识别（NER）任务时的表现，以了解特定领域模型和通用模型的优劣。

Method: 在包含NER标签的Hinglish NER基准数据集上，使用精确率、召回率和F1分数对HingBERT、HingMBERT、HingRoBERTa（混合语微调模型）以及BERT Base Cased、IndicBERT、RoBERTa和MuRIL（非混合语多语言模型）进行评估。此外，还评估了Google Gemini在零样本设置下的性能（使用移除了NER标签的数据集）。

Result: 混合语微调模型（特别是HingRoBERTa和HingBERT）的表现优于其他模型，包括Google Gemini。非混合语多语言模型表现尚可，但适应性有限。Google Gemini在零样本设置下表现出具有竞争力的性能，显示了现代LLMs的泛化能力。

Conclusion: 针对混合语NER任务，专门的混合语微调模型（如HingRoBERTa和HingBERT）比通用模型（包括LLMs）更有效。然而，现代LLMs（如Google Gemini）在零样本设置下也展现了强大的泛化能力。

Abstract: Named Entity Recognition (NER) in code-mixed text, particularly Hindi-English
(Hinglish), presents unique challenges due to informal structure,
transliteration, and frequent language switching. This study conducts a
comparative evaluation of code-mixed fine-tuned models and non-code-mixed
multilingual models, along with zero-shot generative large language models
(LLMs). Specifically, we evaluate HingBERT, HingMBERT, and HingRoBERTa (trained
on code-mixed data), and BERT Base Cased, IndicBERT, RoBERTa and MuRIL (trained
on non-code-mixed multilingual data). We also assess the performance of Google
Gemini in a zero-shot setting using a modified version of the dataset with NER
tags removed. All models are tested on a benchmark Hinglish NER dataset using
Precision, Recall, and F1-score. Results show that code-mixed models,
particularly HingRoBERTa and HingBERT-based fine-tuned models, outperform
others - including closed-source LLMs like Google Gemini - due to
domain-specific pretraining. Non-code-mixed models perform reasonably but show
limited adaptability. Notably, Google Gemini exhibits competitive zero-shot
performance, underlining the generalization strength of modern LLMs. This study
provides key insights into the effectiveness of specialized versus generalized
models for code-mixed NER tasks.

</details>


### [347] [Implicit Actor Critic Coupling via a Supervised Learning Framework for RLVR](https://arxiv.org/abs/2509.02522)
*Jiaming Li,Longze Chen,Ze Gong,Yukun Chen,Lu Wang,Wanwei He,Run Luo,Min Yang*

Main category: cs.CL

TL;DR: PACS是一个新的强化学习框架，通过将结果奖励视为监督学习中的可预测标签，解决了现有RLVR方法中奖励信号稀疏和策略梯度更新不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在奖励信号稀疏和策略梯度更新不稳定方面存在挑战，尤其是在基于RL的方法中。

Method: PACS框架通过监督学习框架实现隐式 actor-critic 耦合，将RLVR问题重新定义为基于得分函数的监督学习任务，并使用交叉熵损失进行优化。

Result: PACS在AIME 2025数学推理任务上，在pass@256指标上达到了59.78%，比PPO和GRPO分别提高了13.32和14.36个百分点，表现优于强RLVR基线。

Conclusion: PACS是一个简单而强大的框架，为LLM通过可验证奖励进行训练提供了一条有前景的途径。

Abstract: Recent advances in Reinforcement Learning with Verifiable Rewards (RLVR) have
empowered large language models (LLMs) to tackle challenging reasoning tasks
such as mathematics and programming. RLVR leverages verifiable outcome rewards
to guide policy optimization, enabling LLMs to progressively improve output
quality in a grounded and reliable manner. Despite its promise, the RLVR
paradigm poses significant challenges, as existing methods often suffer from
sparse reward signals and unstable policy gradient updates, particularly in
RL-based approaches. To address the challenges, we propose $\textbf{PACS}$, a
novel RLVR framework that achieves im$\textbf{P}$licit $\textbf{A}$ctor
$\textbf{C}$ritic coupling via a $\textbf{S}$upervised learning framework. By
treating the outcome reward as a predictable label, we reformulate the RLVR
problem into a supervised learning task over a score function parameterized by
the policy model and optimized using cross-entropy loss. A detailed gradient
analysis shows that this supervised formulation inherently recovers the
classical policy gradient update while implicitly coupling actor and critic
roles, yielding more stable and efficient training. Benchmarking on challenging
mathematical reasoning tasks, PACS outperforms strong RLVR baselines, such as
PPO and GRPO, achieving superior reasoning performance. For instance, PACS
achieves 59.78\% at pass@256 on AIME 2025, representing improvements of 13.32
and 14.36 points over PPO and GRPO. This simple yet powerful framework offers a
promising avenue for LLMs post-training with verifiable rewards. Our code and
data are available as open source at https://github.com/ritzz-ai/PACS.

</details>


### [348] [Flavors of Moonshine: Tiny Specialized ASR Models for Edge Devices](https://arxiv.org/abs/2509.02523)
*Evan King,Adam Sabra,Manjunath Kudlur,James Wang,Pete Warden*

Main category: cs.CL

TL;DR: 我们提出了“Moonshine”，一套微型自动语音识别（ASR）模型，专注于服务代表性不足的语言。研究表明，对于参数量足够小（27M）的模型，在精心平衡的高质量人类标注、伪标注和合成数据上训练的单一语言系统，其性能优于多语言模型。


<details>
  <summary>Details</summary>
Motivation: 挑战了多语言ASR模型通过跨语言语音相似性优于单一语言模型的普遍观点，展示了对于小型模型（27M参数），在混合数据上训练的单一语言系统表现更优。

Method: 训练了专注于代表性不足语言的微型自动语音识别（ASR）模型，并使用了高质量的人类标注、伪标注和合成数据。

Result: 我们的模型在平均错误率上比同等大小的Whisper Tiny模型低48%，性能优于9倍大的Whisper Small模型，并且在大多数情况下与28倍大的Whisper Medium模型相当或更优。

Conclusion: 这些成果推动了同等规模模型的最先进技术，实现了准确的设备端ASR，尤其是在先前支持有限的语言上。我们发布了阿拉伯语、中文、日语、韩语、乌克兰语和越南语的Moonshine模型，并采用了宽松的开源许可证。

Abstract: We present the Flavors of Moonshine, a suite of tiny automatic speech
recognition (ASR) models specialized for a range of underrepresented languages.
Prevailing wisdom suggests that multilingual ASR models outperform monolingual
counterparts by exploiting cross-lingual phonetic similarities. We challenge
this assumption, showing that for sufficiently small models (27M parameters),
training monolingual systems on a carefully balanced mix of high-quality
human-labeled, pseudo-labeled, and synthetic data yields substantially superior
performance. On average, our models achieve error rates 48% lower than the
comparably sized Whisper Tiny model, outperform the 9x larger Whisper Small
model, and in most cases match or outperform the 28x larger Whisper Medium
model. These results advance the state of the art for models of this size,
enabling accurate on-device ASR for languages that previously had limited
support. We release Arabic, Chinese, Japanese, Korean, Ukrainian, and
Vietnamese Moonshine models under a permissive open-source license.

</details>


### [349] [Jointly Reinforcing Diversity and Quality in Language Model Generations](https://arxiv.org/abs/2509.02534)
*Tianjian Li,Yiming Zhang,Ping Yu,Swarnadeep Saha,Daniel Khashabi,Jason Weston,Jack Lanchantin,Tianlu Wang*

Main category: cs.CL

TL;DR: DARLING框架通过结合响应质量和语义多样性来解决大型语言模型（LM）的后训练问题，在创意和探索性任务中提高了LM的实用性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的后训练常常以牺牲多样性为代价来优先考虑准确性和有用性，这限制了模型在创意和探索性任务中的应用。

Method: DARLING框架引入了一个学习到的分区函数来衡量超越表面词汇变化的语义多样性，并将其与在线强化学习中的质量奖励相结合。

Result: DARLING在五个基准测试中持续优于仅关注质量的强化学习基线，生成了质量更高、新颖性更强的输出。在可验证任务中，DARLING在pass@1和pass@k方面也取得了更高的分数，并且优化多样性可以促进在线强化学习中的探索，从而提高响应质量。

Conclusion: DARLING框架在提高大型语言模型响应质量和多样性方面取得了成功，并且能够促进探索，从而带来更高质量的响应。

Abstract: Post-training of Large Language Models (LMs) often prioritizes accuracy and
helpfulness at the expense of diversity. This creates a tension: while
post-training improves response quality, it also sharpens output distributions
and reduces the range of ideas, limiting the usefulness of LMs in creative and
exploratory tasks such as brainstorming, storytelling, or problem solving. We
address this challenge with Diversity-Aware Reinforcement Learning (DARLING), a
framework that jointly optimizes for response quality and semantic diversity.
At its core, DARLING introduces a learned partition function to measure
diversity beyond surface-level lexical variations. This diversity signal is
then combined with a quality reward during online reinforcement learning,
encouraging models to generate outputs that are both high-quality and distinct.
Experiments across multiple model families and sizes show that DARLING
generalizes to two regimes: non-verifiable tasks (instruction following and
creative writing) and verifiable tasks (competition math). On five benchmarks
in the first setting, DARLING consistently outperforms quality-only RL
baselines, producing outputs that are simultaneously of higher quality and
novelty. In the second setting, DARLING achieves higher pass@1 (solution
quality) and pass@k (solution variety). Most strikingly, explicitly optimizing
for diversity catalyzes exploration in online RL, which manifests itself as
higher-quality responses.

</details>


### [350] [PalmX 2025: The First Shared Task on Benchmarking LLMs on Arabic and Islamic Culture](https://arxiv.org/abs/2509.02550)
*Fakhraddin Alwajih,Abdellah El Mekki,Hamdy Mubarak,Majd Hawasly,Abubakr Mohamed,Muhammad Abdul-Mageed*

Main category: cs.CL

TL;DR: LLMs因训练数据偏向西方文化而缺乏对阿拉伯和伊斯兰文化的理解，PalmX 2025任务旨在评估和改进LLMs在此类文化领域的表现，任务分为两个子任务，吸引了大量团队参与，结果显示针对性微调能显著提升模型性能，参数高效微调效果最佳。


<details>
  <summary>Details</summary>
Motivation: 由于LLMs的训练数据主要来自网络，存在偏向高资源语言和文化的倾向，导致其在理解特定社群，特别是阿拉伯和伊斯兰文化方面存在不足，尤其是在代表性不足的主题上，这一差距更为明显。

Method: 通过引入PalmX 2025这一基准测试任务，包含现代标准阿拉伯语（MSA）的单项选择题（MCQs），分为通用阿拉伯文化和通用伊斯兰文化两个子任务，覆盖了22个阿拉伯国家的传统、食物、历史、宗教习俗和语言表达等广泛主题，并记录了26个团队报名参加子任务1，19个团队报名参加子任务2，最终分别有9个和6个有效提交。

Result: PalmX 2025任务的参与者数量众多，表明了该领域的研究兴趣。研究结果表明，特定任务的微调能够显著优于基线模型。表现最佳的系统在文化问题上的准确率达到了72.15%，在伊斯兰知识上的准确率达到了84.22%。参数高效微调是参赛者中最主要且最有效的方法，而数据增强的效用则取决于具体领域。

Conclusion: PalmX 2025任务的成功举办，证明了通过针对性微调可以有效提升LLMs在阿拉伯和伊斯兰文化领域的理解能力，参数高效微调是一种有效的方法，未来可以进一步探索数据增强在不同领域的适用性，以应对LLMs在特定文化理解方面的挑战。

Abstract: Large Language Models (LLMs) inherently reflect the vast data distributions
they encounter during their pre-training phase. As this data is predominantly
sourced from the web, there is a high chance it will be skewed towards
high-resourced languages and cultures, such as those of the West. Consequently,
LLMs often exhibit a diminished understanding of certain communities, a gap
that is particularly evident in their knowledge of Arabic and Islamic cultures.
This issue becomes even more pronounced with increasingly under-represented
topics. To address this critical challenge, we introduce PalmX 2025, the first
shared task designed to benchmark the cultural competence of LLMs in these
specific domains. The task is composed of two subtasks featuring
multiple-choice questions (MCQs) in Modern Standard Arabic (MSA): General
Arabic Culture and General Islamic Culture. These subtasks cover a wide range
of topics, including traditions, food, history, religious practices, and
language expressions from across 22 Arab countries. The initiative drew
considerable interest, with 26 teams registering for Subtask 1 and 19 for
Subtask 2, culminating in nine and six valid submissions, respectively. Our
findings reveal that task-specific fine-tuning substantially boosts performance
over baseline models. The top-performing systems achieved an accuracy of 72.15%
on cultural questions and 84.22% on Islamic knowledge. Parameter-efficient
fine-tuning emerged as the predominant and most effective approach among
participants, while the utility of data augmentation was found to be
domain-dependent.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [351] [Robotic Fire Risk Detection based on Dynamic Knowledge Graph Reasoning: An LLM-Driven Approach with Graph Chain-of-Thought](https://arxiv.org/abs/2509.00054)
*Haimei Pan,Jiyun Zhang,Qinxi Wei,Xiongnan Jin,Chen Xinkai,Jie Cheng*

Main category: cs.RO

TL;DR: 该研究提出了一种名为Insights-on-Graph (IOG)的框架，利用大型语言模型（LLMs）和大型多模态模型（LMMs）构建火灾知识图谱（KG），以增强机器人对火灾场景的感知和响应规划。IOG能从实时图像生成风险图，实现早期火灾风险检测，并根据不断变化的风险情况提供可解释的应急响应建议，用于任务模块和机器人组件的配置。实验证明该框架在火灾风险检测和救援决策方面具有良好的适用性和实用价值。


<details>
  <summary>Details</summary>
Motivation: 火灾是一种破坏性极强的灾害，需要有效的预防措施。在火灾发生时，部署应急机器人可以减少对人类响应者的危险。然而，当前在火灾预防预警和灾时救援方面的研究面临感知不全、火灾态势感知不足和响应延迟等挑战。

Method: 该研究首先利用大型语言模型（LLMs）整合来自防火指南的火灾领域知识和来自机器人应急响应文件的机器人救援任务信息，构建了火灾知识图谱（KG）。随后，提出了一种名为Insights-on-Graph (IOG)的新框架，该框架整合了KG的结构化火灾信息和大型多模态模型（LMMs）。该框架从实时场景图像生成驱动感知的风险图，以实现早期火灾风险检测，并根据不断变化的风险情况，为任务模块和机器人组件配置提供可解释的应急响应。

Result: 通过广泛的模拟和实际实验，证明了IOG在火灾风险检测和救援决策方面具有良好的适用性和实际应用价值。

Conclusion: IOG框架通过整合LLMs和LMMs构建火灾知识图谱，并生成风险图，有效解决了当前机器人火灾场景感知和响应规划中的挑战，提高了早期风险检测和决策的准确性和可解释性。

Abstract: Fire is a highly destructive disaster, but effective prevention can
significantly reduce its likelihood of occurrence. When it happens, deploying
emergency robots in fire-risk scenarios can help minimize the danger to human
responders. However, current research on pre-disaster warnings and
disaster-time rescue still faces significant challenges due to incomplete
perception, inadequate fire situational awareness, and delayed response. To
enhance intelligent perception and response planning for robots in fire
scenarios, we first construct a knowledge graph (KG) by leveraging large
language models (LLMs) to integrate fire domain knowledge derived from fire
prevention guidelines and fire rescue task information from robotic emergency
response documents. We then propose a new framework called Insights-on-Graph
(IOG), which integrates the structured fire information of KG and Large
Multimodal Models (LMMs). The framework generates perception-driven risk graphs
from real-time scene imagery to enable early fire risk detection and provide
interpretable emergency responses for task module and robot component
configuration based on the evolving risk situation. Extensive simulations and
real-world experiments show that IOG has good applicability and practical
application value in fire risk detection and rescue decision-making.

</details>


### [352] [U2UData-2: A Scalable Swarm UAVs Autonomous Flight Dataset for Long-horizon Tasks](https://arxiv.org/abs/2509.00055)
*Tongtong Feng,Xin Wang,Feilin Han,Leping Zhang,Wenwu Zhu*

Main category: cs.RO

TL;DR: 该论文提出了U2UData-2，一个用于集群无人机自主飞行以完成长时程（LH）任务的大规模数据集，以及一个用于在线收集数据和闭环验证算法的平台。该数据集包含15架无人机在12个场景下进行的120小时自主协同飞行数据，并提供了环境传感器数据。论文还提出了一个用于野生动物保护的LH任务，并对9个现有模型进行了基准测试。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在长时程（LH）任务中因数据集限制而无法应对现实世界部署的问题，该论文旨在提供一个大规模数据集和相关平台，以支持集群无人机在长时程任务中的自主飞行。

Method: 论文提出了U2UData-2数据集，这是首个用于集群无人机自主飞行长时程（LH）任务的大规模数据集。该数据集通过15架无人机在12个场景下进行120小时的自主协同飞行收集，包含多种传感器数据（LiDAR、RGB、亮度、温度、湿度、烟雾、气流）。此外，论文还开发了一个数据在线收集和算法闭环验证平台，支持自定义模拟器、无人机、传感器、算法、编队模式和LH任务，并允许用户在线收集数据和进行闭环验证。

Result: U2UData-2数据集包含12个场景，720条轨迹，120小时飞行数据，每条轨迹长达600秒，包含4.32M LiDAR帧和12.96M RGB帧，以及环境传感器数据。该平台支持用户自定义收集数据和验证算法。论文还提出了一个用于野生动物保护的LH任务，并提供了9个SOTA模型的基准测试结果。

Conclusion: U2UData-2数据集和配套平台为集群无人机在长时程（LH）任务中的自主飞行提供了关键资源，解决了现有数据集的局限性，并为该领域的研究和应用提供了基础。

Abstract: Swarm UAV autonomous flight for Long-Horizon (LH) tasks is crucial for
advancing the low-altitude economy. However, existing methods focus only on
specific basic tasks due to dataset limitations, failing in real-world
deployment for LH tasks. LH tasks are not mere concatenations of basic tasks,
requiring handling long-term dependencies, maintaining persistent states, and
adapting to dynamic goal shifts. This paper presents U2UData-2, the first
large-scale swarm UAV autonomous flight dataset for LH tasks and the first
scalable swarm UAV data online collection and algorithm closed-loop
verification platform. The dataset is captured by 15 UAVs in autonomous
collaborative flights for LH tasks, comprising 12 scenes, 720 traces, 120
hours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames.
This dataset also includes brightness, temperature, humidity, smoke, and
airflow values covering all flight routes. The platform supports the
customization of simulators, UAVs, sensors, flight algorithms, formation modes,
and LH tasks. Through a visual control window, this platform allows users to
collect customized datasets through one-click deployment online and to verify
algorithms by closed-loop simulation. U2UData-2 also introduces an LH task for
wildlife conservation and provides comprehensive benchmarks with 9 SOTA models.
U2UData-2 can be found at https://fengtt42.github.io/U2UData-2/.

</details>


### [353] [Correspondence-Free, Function-Based Sim-to-Real Learning for Deformable Surface Control](https://arxiv.org/abs/2509.00060)
*Yingjun Tian,Guoxin Fang,Renbo Su,Aoran Lyu,Neelotpal Dutta,Simeon Gill,Andrew Weightman,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 该研究提出了一种无需对应关系、基于函数的sim-to-real学习方法，用于控制可变形自由曲面。


<details>
  <summary>Details</summary>
Motivation: 传统sim-to-real方法依赖于具有完整对应关系的标记点，而本研究旨在克服这一限制，实现更灵活的sim-to-real学习。

Method: 本研究同时学习一个由神经网络参数化的形变函数空间和一个置信度图，将模拟形状映射到真实世界对应物。这种方法可以处理无对应关系的3D扫描点云或容忍漏检标记点的运动捕捉系统输入。

Result: 该sim-to-real迁移学习方法可以无缝集成到基于神经网络的逆运动学和形状控制计算流程中，并在视觉设备和四种气动驱动的软体机器人（可变形膜、机器人人体模型和两个软体机械臂）上展示了其通用性和适应性。

Conclusion: 所提出的无需对应关系的函数式sim-to-real学习方法能够有效地控制可变形自由曲面，并能在不同类型的输入数据和机器人平台上实现灵活应用。

Abstract: This paper presents a correspondence-free, function-based sim-to-real
learning method for controlling deformable freeform surfaces. Unlike
traditional sim-to-real transfer methods that strongly rely on marker points
with full correspondences, our approach simultaneously learns a deformation
function space and a confidence map -- both parameterized by a neural network
-- to map simulated shapes to their real-world counterparts. As a result, the
sim-to-real learning can be conducted by input from either a 3D scanner as
point clouds (without correspondences) or a motion capture system as marker
points (tolerating missed markers). The resultant sim-to-real transfer can be
seamlessly integrated into a neural network-based computational pipeline for
inverse kinematics and shape control. We demonstrate the versatility and
adaptability of our method on both vision devices and across four pneumatically
actuated soft robots: a deformable membrane, a robotic mannequin, and two soft
manipulators.

</details>


### [354] [OpenTie: Open-vocabulary Sequential Rebar Tying System](https://arxiv.org/abs/2509.00064)
*Mingze Liu,Sai Fan,Haozhen Li,Haobo Liang,Yixing Yuan,Yanke Wang*

Main category: cs.RO

TL;DR: OpenTie是一个无需训练的3D机器人钢筋绑扎框架，利用RGB到点云生成和开放词汇检测技术，解决了现有技术主要关注平面钢筋绑扎且需要模型训练的问题。该系统灵活支持水平和垂直钢筋绑扎，并在真实场景实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人钢筋绑扎技术主要关注平面钢筋绑扎且需要模型训练的不足，提出一个3D、无需训练的钢筋绑扎框架。

Method: 利用RGB图像到点云生成技术和开放词汇检测，通过机器人手臂、双目摄像头以及基于提示的目标检测方法，在自定义图像后处理流程的基础上，实现高精度钢筋绑扎。

Result: 该系统在真实世界的钢筋绑扎任务中进行了实验，证明了其在实际应用中的有效性，能够灵活支持水平和垂直钢筋的绑扎。

Conclusion: OpenTie框架成功实现了无需训练的3D钢筋绑扎，解决了现有技术的局限性，并在实际应用中表现出良好的有效性和灵活性。

Abstract: Robotic practices on the construction site emerge as an attention-attracting
manner owing to their capability of tackle complex challenges, especially in
the rebar-involved scenarios. Most of existing products and research are mainly
focused on flat rebar setting with model training demands. To fulfill this gap,
we propose OpenTie, a 3D training-free rebar tying framework utilizing a
RGB-to-point-cloud generation and an open-vocabulary detection. We implements
the OpenTie via a robotic arm with a binocular camera and guarantees a high
accuracy by applying the prompt-based object detection method on the image
filtered by our propose post-processing procedure based a image to point cloud
generation framework. The system is flexible for horizontal and vertical rebar
tying tasks and the experiments on the real-world rebar setting verifies that
the effectiveness of the system in practice.

</details>


### [355] [Hybrid Perception and Equivariant Diffusion for Robust Multi-Node Rebar Tying](https://arxiv.org/abs/2509.00065)
*Zhitao Wang,Yirong Xiong,Roberto Horowitz,Yanke Wang,Yuxing Han*

Main category: cs.RO

TL;DR: 该论文提出了一种结合几何感知和基于SE(3)的Equivariant Denoising Diffusion（Diffusion-EDFs）的混合方法，用于解决机器人自动化绑扎钢筋时，在拥挤的钢筋节点中精确估计绑扎姿态的挑战。


<details>
  <summary>Details</summary>
Motivation: 手动绑扎钢筋存在重复性高、人体工程学风险大以及在密集钢筋节点中精确估计绑扎姿态的挑战，自动化绑扎具有提高安全性与劳动效率的潜力。

Method: 该方法包括一个感知模块（使用DBSCAN、几何特征提取和PCA来分割钢筋、识别节点和估计方向）和一个运动规划模块（基于Diffusion-EDFs，仅需少量数据即可生成优化碰撞避免和绑扎效率的末端执行器姿态）。

Result: 该混合系统在单层、多层和杂乱配置的钢筋网格上进行了验证，在节点检测和连续绑扎方面表现出高成功率。与依赖大型数据集或大量手动参数调整的传统方法相比，该方法在显著减少数据需求的同时，实现了鲁棒、高效和适应性强的多节点绑扎。

Conclusion: 该研究结果表明，结合几何感知和扩散模型驱动的规划的混合方法，在提高现场施工任务的自动化水平方面具有巨大潜力，能够同时提升安全性与劳动效率。

Abstract: Rebar tying is a repetitive but critical task in reinforced concrete
construction, typically performed manually at considerable ergonomic risk.
Recent advances in robotic manipulation hold the potential to automate the
tying process, yet face challenges in accurately estimating tying poses in
congested rebar nodes. In this paper, we introduce a hybrid perception and
motion planning approach that integrates geometry-based perception with
Equivariant Denoising Diffusion on SE(3) (Diffusion-EDFs) to enable robust
multi-node rebar tying with minimal training data. Our perception module
utilizes density-based clustering (DBSCAN), geometry-based node feature
extraction, and principal component analysis (PCA) to segment rebar bars,
identify rebar nodes, and estimate orientation vectors for sequential ranking,
even in complex, unstructured environments. The motion planner, based on
Diffusion-EDFs, is trained on as few as 5-10 demonstrations to generate
sequential end-effector poses that optimize collision avoidance and tying
efficiency. The proposed system is validated on various rebar meshes, including
single-layer, multi-layer, and cluttered configurations, demonstrating high
success rates in node detection and accurate sequential tying. Compared with
conventional approaches that rely on large datasets or extensive manual
parameter tuning, our method achieves robust, efficient, and adaptable
multi-node tying while significantly reducing data requirements. This result
underscores the potential of hybrid perception and diffusion-driven planning to
enhance automation in on-site construction tasks, improving both safety and
labor efficiency.

</details>


### [356] [A Comparative Study of Spline-Based Trajectory Reconstruction Methods Across Varying Automatic Vehicle Location Data Densities](https://arxiv.org/abs/2509.00119)
*Jake Robbennolt,Sirajum Munira,Stephen D. Boyles*

Main category: cs.RO

TL;DR: 本研究评估了13种轨迹重建方法，并分析了速度、位置、平滑度和数据密度等因素对性能的影响。结果表明，速度感知方法优于仅位置方法，而VCHIP-ME方法在准确性和计算效率方面表现最佳。


<details>
  <summary>Details</summary>
Motivation: 自动车辆定位（AVL）数据在交通动态分析中很有价值，但其不一致的更新频率需要轨迹重建。本研究旨在评估和比较不同的轨迹重建方法，并分析影响其性能的关键因素，为实际应用提供指导。

Method: 本研究评估了13种轨迹重建方法，包括新的方法，并使用了来自德克萨斯州奥斯汀的高分辨率AVL数据。研究检查了速度、位置、平滑度和数据密度这四个关键因素对重建性能的影响。评估框架结合了传统的数学误差指标和实际的物理现实性检查，并考虑了稀疏和密集数据集的权衡。

Result: 速度感知方法普遍优于仅位置方法。平滑方法在复杂的城市环境中可能会降低整体性能，但保持单调性仍然至关重要。VCHIP-ME方法在准确性和计算效率之间取得了最佳平衡，其开销极小，适用于历史分析和实时应用，并且与密集数据集结合时具有显著的预测能力。

Conclusion: VCHIP-ME方法是轨迹重建的最佳选择，在准确性和效率之间提供了良好的平衡。研究强调了收集更高频率AVL数据的重要性，并为研究人员和实践者提供了关于轨迹重建系统实施的实用指导。

Abstract: Automatic vehicle location (AVL) data offers insights into transit dynamics,
but its effectiveness is often hampered by inconsistent update frequencies,
necessitating trajectory reconstruction. This research evaluates 13 trajectory
reconstruction methods, including several novel approaches, using
high-resolution AVL data from Austin, Texas. We examine the interplay of four
critical factors -- velocity, position, smoothing, and data density -- on
reconstruction performance. A key contribution of this study is evaluation of
these methods across sparse and dense datasets, providing insights into the
trade-off between accuracy and resource allocation. Our evaluation framework
combines traditional mathematical error metrics for positional and velocity
with practical considerations, such as physical realism (e.g., aligning
velocity and acceleration with stopped states, deceleration rates, and speed
variability). In addition, we provide insight into the relative value of each
method in calculating realistic metrics for infrastructure evaluations. Our
findings indicate that velocity-aware methods consistently outperform
position-only approaches. Interestingly, we discovered that smoothing-based
methods can degrade overall performance in complex, congested urban
environments, although enforcing monotonicity remains critical. The velocity
constrained Hermite interpolation with monotonicity enforcement (VCHIP-ME)
yields optimal results, offering a balance between high accuracy and
computational efficiency. Its minimal overhead makes it suitable for both
historical analysis and real-time applications, providing significant
predictive power when combined with dense datasets. These findings offer
practical guidance for researchers and practitioners implementing trajectory
reconstruction systems and emphasize the importance of investing in
higher-frequency AVL data collection for improved analysis.

</details>


### [357] [Poke and Strike: Learning Task-Informed Exploration Policies](https://arxiv.org/abs/2509.00178)
*Marina Y. Aoyama,Joao Moura,Juan Del Aguila Ferrandis,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 机器人通过基于强化学习的任务知情探索方法，在90%的成功率下以平均1.2秒的探索时间完成了机器人打击任务，显著优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 在许多动态机器人任务中，机器人需要识别物体相关的物理属性才能成功执行任务，而无法在失败后进行恢复或重试。

Method: 提出了一种基于强化学习的任务知情探索方法，通过利用主任务策略对估计属性误差的敏感性自动生成探索策略的奖励，并引入了基于不确定性的机制来确定何时从探索过渡到任务执行。

Result: 该方法在打击任务中实现了90%的成功率，平均探索时间不到1.2秒，显著优于仅达到40%成功率或在测试时需要低效查询和重新训练的基线方法。此外，研究还表明任务知情奖励能有效捕捉物理属性在打击任务和经典倒立摆示例中的相对重要性。

Conclusion: 该方法通过在KUKA iiwa机器人手臂的物理设置中识别物体属性和调整任务执行，验证了其有效性。

Abstract: In many dynamic robotic tasks, such as striking pucks into a goal outside the
reachable workspace, the robot must first identify the relevant physical
properties of the object for successful task execution, as it is unable to
recover from failure or retry without human intervention. To address this
challenge, we propose a task-informed exploration approach, based on
reinforcement learning, that trains an exploration policy using rewards
automatically generated from the sensitivity of a privileged task policy to
errors in estimated properties. We also introduce an uncertainty-based
mechanism to determine when to transition from exploration to task execution,
ensuring sufficient property estimation accuracy with minimal exploration time.
Our method achieves a 90% success rate on the striking task with an average
exploration time under 1.2 seconds, significantly outperforming baselines that
achieve at most 40% success or require inefficient querying and retraining in a
simulator at test time. Additionally, we demonstrate that our task-informed
rewards capture the relative importance of physical properties in both the
striking task and the classical CartPole example. Finally, we validate our
approach by demonstrating its ability to identify object properties and adjust
task execution in a physical setup using the KUKA iiwa robot arm.

</details>


### [358] [First Order Model-Based RL through Decoupled Backpropagation](https://arxiv.org/abs/2509.00215)
*Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti*

Main category: cs.RO

TL;DR: 该研究提出了一种结合模拟器和可微模型的方法，用于强化学习中的梯度计算和轨迹生成，解决了模拟器梯度不易获取和模型误差累积的问题，在样本效率和通用性方面表现优异，并在机器人行走任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 在强化学习中，利用模拟器梯度可以提高学习效率，但模拟器梯度获取成本高或不可用。现有的基于模型的方法（MBRL）通过学习动力学模型来近似梯度，但预测误差会累积，影响策略性能。

Method: 提出了一种将轨迹生成与梯度计算解耦的方法：使用模拟器生成轨迹，并通过学习到的模拟器可微模型进行反向传播来计算梯度。这种混合设计可以在模拟器梯度不可用的情况下，实现高效一致的一阶策略优化，并从更准确的模拟轨迹中学习Critic。

Result: 该方法实现了如SHAC等专用优化器的样本效率和速度，同时保持了PPO等标准方法的通用性，并避免了其他一阶MBRL方法的不足。在基准控制任务和Go2四足机器人行走任务中都得到了验证。

Conclusion: 所提出的混合方法能够有效地解决强化学习中梯度获取和模型误差累积的问题，并在机器人控制任务中取得了良好的效果。

Abstract: There is growing interest in reinforcement learning (RL) methods that
leverage the simulator's derivatives to improve learning efficiency. While
early gradient-based approaches have demonstrated superior performance compared
to derivative-free methods, accessing simulator gradients is often impractical
due to their implementation cost or unavailability. Model-based RL (MBRL) can
approximate these gradients via learned dynamics models, but the solver
efficiency suffers from compounding prediction errors during training rollouts,
which can degrade policy performance. We propose an approach that decouples
trajectory generation from gradient computation: trajectories are unrolled
using a simulator, while gradients are computed via backpropagation through a
learned differentiable model of the simulator. This hybrid design enables
efficient and consistent first-order policy optimization, even when simulator
gradients are unavailable, as well as learning a critic from simulation
rollouts, which is more accurate. Our method achieves the sample efficiency and
speed of specialized optimizers such as SHAC, while maintaining the generality
of standard approaches like PPO and avoiding ill behaviors observed in other
first-order MBRL methods. We empirically validate our algorithm on benchmark
control tasks and demonstrate its effectiveness on a real Go2 quadruped robot,
across both quadrupedal and bipedal locomotion tasks.

</details>


### [359] [Embodied AI in Social Spaces: Responsible and Adaptive Robots in Complex Setting - UKAIRS 2025 (Copy)](https://arxiv.org/abs/2509.00218)
*Aleksandra Landowska,Aislinn D Gomez Bergin,Ayodeji O. Abioye,Jayati Deshmukh,Andriana Bouadouki,Maria Wheadon,Athina Georgara,Dominic Price,Tuyen Nguyen,Shuang Ao,Lokesh Singh,Yi Long,Raffaele Miele,Joel E. Fischer,Sarvapali D. Ramchurn*

Main category: cs.RO

TL;DR: 该项目旨在开发多人类多机器人（MHMR）系统，通过共设计、伦理框架和多模态传感，创建能够响应情感、感知上下文并满足用户需求的AI驱动机器人，以支持可持续、合乎伦理和以人为中心 的未来。


<details>
  <summary>Details</summary>
Motivation: 开发负责任和适应性强的多人类多机器人（MHMR）系统，以应对复杂和动态的环境。

Method: 该项目整合了共设计、伦理框架和多模态传感，并展示了具身智能如何支持可持续、合乎伦理和以人为中心的未来。

Result: 早期成果表明，AI驱动的机器人能够响应情感、感知上下文并满足用户需求。

Conclusion: 具身智能可以为可持续、合乎伦理和以人为中心的未来提供支持。

Abstract: This paper introduces and overviews a multidisciplinary project aimed at
developing responsible and adaptive multi-human multi-robot (MHMR) systems for
complex, dynamic settings. The project integrates co-design, ethical
frameworks, and multimodal sensing to create AI-driven robots that are
emotionally responsive, context-aware, and aligned with the needs of diverse
users. We outline the project's vision, methodology, and early outcomes,
demonstrating how embodied AI can support sustainable, ethical, and
human-centred futures.

</details>


### [360] [Learn from What We HAVE: History-Aware VErifier that Reasons about Past Interactions Online](https://arxiv.org/abs/2509.00271)
*Yishu Li,Xinyi Mao,Ying Yuan,Kyutae Sim,Ben Eisner,David Held*

Main category: cs.RO

TL;DR: 我们提出了一种名为HAVE的历史感知验证器，通过利用过去的交互来消除在线不确定场景的歧义。它通过解耦动作生成和验证来工作：一个无条件的基于扩散的生成器提出多个候选动作，而历史感知验证器通过推理过去的交互来选择最有希望的动作。理论分析和跨多个模拟和现实世界环境的实证评估证实了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人经常遇到视觉上不明确的物体，其操作结果在实际交互之前是不确定的。虽然生成模型理论上可以适应这种模糊性，但实践中它们在模糊情况下的性能不佳。

Method: 我们明确地将动作生成与验证分开：我们使用无条件的基于扩散的生成器来提出多个候选动作，并采用我们的历史感知验证器来通过推理过去的交互来选择最有希望的动作。

Result: 理论分析表明，使用验证器可以显著提高预期的动作质量。在包括铰接式物体、多模式门和不均匀物体拾取在内的多个模拟和现实世界环境中的实证评估和分析证实了我们方法的有效性以及相对于基线方法的改进。

Conclusion: HAVE通过利用历史交互来有效消除在线不确定场景的歧义，在各种环境中都优于现有方法。

Abstract: We introduce a novel History-Aware VErifier (HAVE) to disambiguate uncertain
scenarios online by leveraging past interactions. Robots frequently encounter
visually ambiguous objects whose manipulation outcomes remain uncertain until
physically interacted with. While generative models alone could theoretically
adapt to such ambiguity, in practice they obtain suboptimal performance in
ambiguous cases, even when conditioned on action history. To address this, we
propose explicitly decoupling action generation from verification: we use an
unconditional diffusion-based generator to propose multiple candidate actions
and employ our history-aware verifier to select the most promising action by
reasoning about past interactions. Through theoretical analysis, we demonstrate
that employing a verifier significantly improves expected action quality.
Empirical evaluations and analysis across multiple simulated and real-world
environments including articulated objects, multi-modal doors, and uneven
object pick-up confirm the effectiveness of our method and improvements over
baselines. Our project website is available at:
https://liy1shu.github.io/HAVE_CoRL25/

</details>


### [361] [Constrained Decoding for Robotics Foundation Models](https://arxiv.org/abs/2509.01728)
*Parv Kapoor,Akila Ganlath,Changliu Liu,Sebastian Scherer,Eunsuk Kang*

Main category: cs.RO

TL;DR: While robotic foundation models show promise, they lack explicit safety and behavioral correctness. This paper introduces a constrained decoding framework to enforce signal temporal logic (STL) specifications at runtime, ensuring provable safety without retraining, and demonstrates its effectiveness in navigation tasks.


<details>
  <summary>Details</summary>
Motivation: Robotic foundation models, despite their end-to-end and general-purpose capabilities, lack explicit notions of behavioral correctness and safety constraints due to their data-driven nature.

Method: The paper introduces a constrained decoding framework that enforces logical constraints on action trajectories in dynamical systems, ensuring that generated actions provably satisfy signal temporal logic (STL) specifications at runtime without retraining the underlying foundation model.

Result: The proposed decoding-time interventions were evaluated across state-of-the-art navigation foundation models, showing utility in filtering unsafe actions and enabling conditional action generation.

Conclusion: The constrained decoding framework effectively addresses the limitations of robotic foundation models by enforcing safety and logical constraints at runtime, enhancing their applicability in real-world robotic systems.

Abstract: Recent advances in the development of robotic foundation models have led to
promising end-to-end and general-purpose capabilities in robotic systems. These
models are pretrained on vast datasets of robot trajectories to process multi-
modal inputs and directly output a sequence of action that the system then
executes in the real world. Although this approach is attractive from the
perspective of im- proved generalization across diverse tasks, these models are
still data-driven and, therefore, lack explicit notions of behavioral
correctness and safety constraints. We address these limitations by introducing
a constrained decoding framework for robotics foundation models that enforces
logical constraints on action trajec- tories in dynamical systems. Our method
ensures that generated actions provably satisfy signal temporal logic (STL)
specifications at runtime without retraining, while remaining agnostic of the
underlying foundation model. We perform com- prehensive evaluation of our
approach across state-of-the-art navigation founda- tion models and we show
that our decoding-time interventions are useful not only for filtering unsafe
actions but also for conditional action-generation. Videos available on our
website: https://constrained-robot-fms.github.io

</details>


### [362] [TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization](https://arxiv.org/abs/2509.00310)
*Yuxuan Ding,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: TReF-6通过从单个轨迹推断6DoF任务相关坐标系来解决机器人泛化性问题，该坐标系由轨迹几何确定的影响点定义，用于参数化动态运动基元（DMP），并通过视觉-语言模型实现语义 grounding，从而在新的场景中实现技能泛化。


<details>
  <summary>Details</summary>
Motivation: 机器人常常难以从单个演示中泛化，因为缺乏可迁移和可解释的空间表示。

Method: TReF-6方法通过轨迹几何识别一个影响点来定义局部坐标系的原点，该坐标系用于参数化动态运动基元（DMP），并通过视觉-语言模型实现语义 grounding，再由Grounded-SAM在新的场景中进行定位。

Result: TReF-6在仿真中得到验证，并表现出对轨迹噪声的鲁棒性。在真实世界的操纵任务中，TReF-6支持一次性模仿学习，能够跨不同的物体配置保持任务意图。

Conclusion: TReF-6通过推断任务相关的6DoF坐标系，能够实现机器人从单次演示中进行泛化，并能保持任务意图。

Abstract: Robots often struggle to generalize from a single demonstration due to the
lack of a transferable and interpretable spatial representation. In this work,
we introduce TReF-6, a method that infers a simplified, abstracted 6DoF
Task-Relevant Frame from a single trajectory. Our approach identifies an
influence point purely from the trajectory geometry to define the origin for a
local frame, which serves as a reference for parameterizing a Dynamic Movement
Primitive (DMP). This influence point captures the task's spatial structure,
extending the standard DMP formulation beyond start-goal imitation. The
inferred frame is semantically grounded via a vision-language model and
localized in novel scenes by Grounded-SAM, enabling functionally consistent
skill generalization. We validate TReF-6 in simulation and demonstrate
robustness to trajectory noise. We further deploy an end-to-end pipeline on
real-world manipulation tasks, showing that TReF-6 supports one-shot imitation
learning that preserves task intent across diverse object configurations.

</details>


### [363] [A Framework for Task and Motion Planning based on Expanding AND/OR Graphs](https://arxiv.org/abs/2509.00317)
*Fulvio Mastrogiovanni,Antony Thomas*

Main category: cs.RO

TL;DR: 本研究提出了一种名为TMP-EAOG的任务与运动规划（TMP）框架，该框架基于扩展的AND/OR图，并能适应不同的太空机器人应用场景。TMP-EAOG将任务抽象编码在AND/OR图中，在执行过程中迭代扩展，并进行实时的运动规划可行性评估。该框架具有一定的鲁棒性、可控的自主性和有限的灵活性，能够处理不确定性、允许专家验证以及应对意外事件。通过在模拟移动机械臂上的评估，证明了TMP-EAOG能够有效应对太空机器人面临的多种挑战。


<details>
  <summary>Details</summary>
Motivation: 太空机器人自主作业面临高感知和运动不确定性、严格运动学约束以及有限人工干预等挑战。任务与运动规划（TMP）通过将任务建模为离散动作序列并结合连续运动可行性评估，对于太空自主服务、表面操作和在轨任务至关重要。

Method: 提出了一种基于扩展AND/OR图（EAOG）的任务与运动规划（TMP）框架（TMP-EAOG）。该框架将任务级抽象编码在AND/OR图中，该图在计划执行过程中进行迭代扩展，并进行实时的运动规划可行性评估以确保其可行性。

Result: 在模拟移动机械臂上进行的评估表明，TMP-EAOG能够应对基准测试中的各种挑战。

Conclusion: TMP-EAOG框架通过其基于扩展AND/OR图的方法，有效地解决了太空机器人自主作业中的不确定性、可控自主性和灵活性问题，并在模拟环境中得到了验证。

Abstract: Robot autonomy in space environments presents unique challenges, including
high perception and motion uncertainty, strict kinematic constraints, and
limited opportunities for human intervention. Therefore, Task and Motion
Planning (TMP) may be critical for autonomous servicing, surface operations, or
even in-orbit missions, just to name a few, as it models tasks as discrete
action sequencing integrated with continuous motion feasibility assessments. In
this paper, we introduce a TMP framework based on expanding AND/OR graphs,
referred to as TMP-EAOG, and demonstrate its adaptability to different
scenarios. TMP-EAOG encodes task-level abstractions within an AND/OR graph,
which expands iteratively as the plan is executed, and performs in-the-loop
motion planning assessments to ascertain their feasibility. As a consequence,
TMP-EAOG is characterised by the desirable properties of (i) robustness to a
certain degree of uncertainty, because AND/OR graph expansion can accommodate
for unpredictable information about the robot environment, (ii) controlled
autonomy, since an AND/OR graph can be validated by human experts, and (iii)
bounded flexibility, in that unexpected events, including the assessment of
unfeasible motions, can lead to different courses of action as alternative
paths in the AND/OR graph. We evaluate TMP-EAOG on two benchmark domains. We
use a simulated mobile manipulator as a proxy for space-grade autonomous
robots. Our evaluation shows that TMP-EAOG can deal with a wide range of
challenges in the benchmarks.

</details>


### [364] [Contact-Aided Navigation of Flexible Robotic Endoscope Using Deep Reinforcement Learning in Dynamic Stomach](https://arxiv.org/abs/2509.00319)
*Chi Kit Ng,Huxin Gao,Tian-Ao Ren,Jiewen Lai,Hongliang Ren*

Main category: cs.RO

TL;DR: 本研究提出一种基于深度强化学习的接触辅助导航（CAN）策略，用于提高柔性机器人内窥镜（FRE）在动态胃肠道中的导航精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在动态且可变形的胃肠道中，特别是胃部，对FRE进行导航具有挑战性，需要利用与胃壁的接触来精确到达目标位置。

Method: 本研究采用深度强化学习（DRL）方法，结合物理引擎（有限元方法FEM）模拟可变形胃部环境，并使用近端策略优化（PPO）算法训练接触辅助导航（CAN）策略，利用接触力反馈来增强运动稳定性和导航精度。

Result: 在训练环境中，CAN策略在静态和动态胃部环境中均达到了100%的成功率，平均误差为1.6毫米。在未见过的、具有干扰的挑战性场景中，成功率仍保持在85%。

Conclusion: 深度强化学习驱动的CAN策略能显著提升FRE的导航性能，优于现有方法。

Abstract: Navigating a flexible robotic endoscope (FRE) through the gastrointestinal
tract is critical for surgical diagnosis and treatment. However, navigation in
the dynamic stomach is particularly challenging because the FRE must learn to
effectively use contact with the deformable stomach walls to reach target
locations. To address this, we introduce a deep reinforcement learning (DRL)
based Contact-Aided Navigation (CAN) strategy for FREs, leveraging contact
force feedback to enhance motion stability and navigation precision. The
training environment is established using a physics-based finite element method
(FEM) simulation of a deformable stomach. Trained with the Proximal Policy
Optimization (PPO) algorithm, our approach achieves high navigation success
rates (within 3 mm error between the FRE's end-effector and target) and
significantly outperforms baseline policies. In both static and dynamic stomach
environments, the CAN agent achieved a 100% success rate with 1.6 mm average
error, and it maintained an 85% success rate in challenging unseen scenarios
with stronger external disturbances. These results validate that the DRL-based
CAN strategy substantially enhances FRE navigation performance over prior
methods.

</details>


### [365] [Mechanistic interpretability for steering vision-language-action models](https://arxiv.org/abs/2509.00328)
*Bear Häon,Kaylene Stocking,Ian Chuang,Claire Tomlin*

Main category: cs.RO

TL;DR: 提出了一种无需微调、奖励信号或环境交互即可解释和引导视觉-语言-动作（VLA）模型的新框架，通过干预模型内部表示来实时控制其行为，并在模拟和机器人上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型缺乏像传统机器人技术那样明确的运动学、动力学和控制模型，这限制了它们在需要鲁棒性和可解释性的真实机器人应用中的部署。

Method: 通过将Transformer层内的前馈激活投影到词嵌入基上，识别出与动作选择有因果关系的稀疏语义方向（如速度和方向），并提出了一种通用的激活引导方法，实时调整模型行为。

Result: 在Pi0和OpenVLA两个VLA模型上进行了评估，在模拟（LIBERO）和物理机器人（UR5）上实现了零样本行为控制。

Conclusion: 研究表明，VLA模型中可解释的组成部分可以被系统地用于机器人控制，为机器人领域中透明且可引导的基础模型开创了新范式。

Abstract: Vision-Language-Action (VLA) models are a promising path to realizing
generalist embodied agents that can quickly adapt to new tasks, modalities, and
environments. However, methods for interpreting and steering VLAs fall far
short of classical robotics pipelines, which are grounded in explicit models of
kinematics, dynamics, and control. This lack of mechanistic insight is a
central challenge for deploying learned policies in real-world robotics, where
robustness and explainability are critical. Motivated by advances in
mechanistic interpretability for large language models, we introduce the first
framework for interpreting and steering VLAs via their internal
representations, enabling direct intervention in model behavior at inference
time. We project feedforward activations within transformer layers onto the
token embedding basis, identifying sparse semantic directions - such as speed
and direction - that are causally linked to action selection. Leveraging these
findings, we introduce a general-purpose activation steering method that
modulates behavior in real time, without fine-tuning, reward signals, or
environment interaction. We evaluate this method on two recent open-source
VLAs, Pi0 and OpenVLA, and demonstrate zero-shot behavioral control in
simulation (LIBERO) and on a physical robot (UR5). This work demonstrates that
interpretable components of embodied VLAs can be systematically harnessed for
control - establishing a new paradigm for transparent and steerable foundation
models in robotics.

</details>


### [366] [Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots](https://arxiv.org/abs/2509.00329)
*Yu Tian,Chi Kit Ng,Hongliang Ren*

Main category: cs.RO

TL;DR: JEDP-RL框架通过分解规划为雅可比估计和策略执行，解决了DCRs的规划挑战，并在模拟中表现出更快的收敛速度、更高的导航效率和更强的泛化能力。


<details>
  <summary>Details</summary>
Motivation: Deformable continuum robots (DCRs) 的规划面临非线性形变和部分状态可观性带来的挑战，传统强化学习方法（RL）的马尔可夫假设失效。基于雅可比的方法难以直接应用于DCRs，因为其运动学随时间变化且形变动力学欠驱动。

Method: JEDP-RL框架将规划分解为两个阶段：雅可比估计和策略执行。在每次训练中，先执行局部探索性动作估计形变雅可比矩阵，然后将雅可比特征增强到状态表示中，以恢复近似马尔可夫性。

Result: 在SOFA手术动态模拟中，JEDP-RL相比PPO基线，在策略收敛速度上快3.2倍，达到目标所需的步数减少25%，在材料属性变化下成功率达到92%，在未见过的组织环境中成功率达到83%（比PPO高33%）。

Conclusion: JEDP-RL框架能够有效解决DCRs的规划问题，并在模拟环境中展现出优越性能。

Abstract: Deformable continuum robots (DCRs) present unique planning challenges due to
nonlinear deformation mechanics and partial state observability, violating the
Markov assumptions of conventional reinforcement learning (RL) methods. While
Jacobian-based approaches offer theoretical foundations for rigid manipulators,
their direct application to DCRs remains limited by time-varying kinematics and
underactuated deformation dynamics. This paper proposes Jacobian Exploratory
Dual-Phase RL (JEDP-RL), a framework that decomposes planning into phased
Jacobian estimation and policy execution. During each training step, we first
perform small-scale local exploratory actions to estimate the deformation
Jacobian matrix, then augment the state representation with Jacobian features
to restore approximate Markovianity. Extensive SOFA surgical dynamic
simulations demonstrate JEDP-RL's three key advantages over proximal policy
optimization (PPO) baselines: 1) Convergence speed: 3.2x faster policy
convergence, 2) Navigation efficiency: requires 25% fewer steps to reach the
target, and 3) Generalization ability: achieve 92% success rate under material
property variations and achieve 83% (33% higher than PPO) success rate in the
unseen tissue environment.

</details>


### [367] [Autonomous Aggregate Sorting in Construction and Mining via Computer Vision-Aided Robotic Arm Systems](https://arxiv.org/abs/2509.00339)
*Md. Taherul Islam Shawon,Yuan Li,Yincai Cai,Junjie Niu,Ting Peng*

Main category: cs.RO

TL;DR: 本研究提出了一种计算机视觉辅助的机器人手臂系统，用于建筑和采矿业中的骨料自动分拣，解决了传统方法的精度低、灵活性差和适应性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统骨料分拣方法存在精度低、灵活性差和适应性差的问题，本研究旨在通过引入计算机视觉和机器人技术来解决这些局限性。

Method: 该系统集成了六自由度机器人手臂、双目立体相机和基于ROS的控制框架。采用了注意力增强的YOLOv8模型进行骨料检测、立体匹配进行3D定位、Denavit-Hartenberg运动学模型进行手臂运动控制、最小外接矩形分析进行尺寸估算以及手眼标定进行精确坐标对齐。

Result: 实验结果表明，该系统在四种骨料类型上的平均抓取和分拣成功率为97.5%，分类准确率相当。

Conclusion: 该系统在提高生产效率、降低运营成本和改善安全性方面具有巨大潜力，并为建筑、采矿和回收行业的智能自动化提供了可扩展的框架。但仍面临处理小骨料和基于纹理的误分类等挑战。

Abstract: Traditional aggregate sorting methods, whether manual or mechanical, often
suffer from low precision, limited flexibility, and poor adaptability to
diverse material properties such as size, shape, and lithology. To address
these limitations, this study presents a computer vision-aided robotic arm
system designed for autonomous aggregate sorting in construction and mining
applications. The system integrates a six-degree-of-freedom robotic arm, a
binocular stereo camera for 3D perception, and a ROS-based control framework.
Core techniques include an attention-augmented YOLOv8 model for aggregate
detection, stereo matching for 3D localization, Denavit-Hartenberg kinematic
modeling for arm motion control, minimum enclosing rectangle analysis for size
estimation, and hand-eye calibration for precise coordinate alignment.
Experimental validation with four aggregate types achieved an average grasping
and sorting success rate of 97.5%, with comparable classification accuracy.
Remaining challenges include the reliable handling of small aggregates and
texture-based misclassification. Overall, the proposed system demonstrates
significant potential to enhance productivity, reduce operational costs, and
improve safety in aggregate handling, while providing a scalable framework for
advancing smart automation in construction, mining, and recycling industries.

</details>


### [368] [Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation](https://arxiv.org/abs/2509.00361)
*Chuye Zhang,Xiaoxiong Zhang,Wei Pan,Linfang Zheng,Wei Zhang*

Main category: cs.RO

TL;DR: GVF-TAPE是一个结合生成式视觉预测和任务无关姿态估计的闭环框架，能够实现可扩展的机器人操作。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要能够跨任务泛化并保持鲁棒性和可靠性的系统。

Method: GVF-TAPE采用生成式视频模型根据单视角RGB图像和任务描述预测未来的RGB-D帧，以提供指导机器人动作的视觉计划。然后，一个解耦的姿态估计模型从预测的帧中提取末端执行器姿态，并将其通过低级控制器转换为可执行命令。通过在闭环中迭代整合视频预测和姿态估计，GVF-TAPE实现了跨一系列任务的实时自适应操作。

Result: 实验表明，该方法减少了对特定任务动作数据的依赖，并能有效泛化，为智能机器人系统提供了一种实用且可扩展的解决方案。

Conclusion: GVF-TAPE通过结合生成式视觉预测和任务无关姿态估计，实现了在非结构化环境中的可扩展、鲁棒和泛化的机器人操作。

Abstract: Robotic manipulation in unstructured environments requires systems that can
generalize across diverse tasks while maintaining robust and reliable
performance. We introduce {GVF-TAPE}, a closed-loop framework that combines
generative visual foresight with task-agnostic pose estimation to enable
scalable robotic manipulation. GVF-TAPE employs a generative video model to
predict future RGB-D frames from a single side-view RGB image and a task
description, offering visual plans that guide robot actions. A decoupled pose
estimation model then extracts end-effector poses from the predicted frames,
translating them into executable commands via low-level controllers. By
iteratively integrating video foresight and pose estimation in a closed loop,
GVF-TAPE achieves real-time, adaptive manipulation across a broad range of
tasks. Extensive experiments in both simulation and real-world settings
demonstrate that our approach reduces reliance on task-specific action data and
generalizes effectively, providing a practical and scalable solution for
intelligent robotic systems.

</details>


### [369] [Embodied Spatial Intelligence: from Implicit Scene Modeling to Spatial Reasoning](https://arxiv.org/abs/2509.00465)
*Jiading Fang*

Main category: cs.RO

TL;DR: 该论文提出“具身空间智能”来解决机器人根据自然语言指令感知和行动的挑战，通过改进场景表示和空间推理能力，利用隐式神经模型进行场景表示，并为LLMs引入新的导航基准、语言到3D的关联方法和用于改进长期决策的状态反馈机制。


<details>
  <summary>Details</summary>
Motivation: 为了弥合大型语言模型（LLMs）和物理实体的差距，需要让机器人能够基于自然语言指令感知和行动。

Method: 提出“具身空间智能”，在场景表示方面，开发了使用隐式神经模型的场景表示，包括自监督相机校准、高保真深度场生成和大规模重建；在空间推理方面，引入了新的导航基准、语言到3D的关联方法和状态反馈机制。

Result: 开发了鲁棒、可扩展、准确的场景表示，并增强了LLMs的空间推理能力，为机器人能够可靠感知周围环境并根据复杂的基于语言的命令进行智能操作奠定了基础。

Conclusion: 该工作为机器人实现具身空间智能奠定了基础，使其能够更好地理解和响应自然语言指令。

Abstract: This thesis introduces "Embodied Spatial Intelligence" to address the
challenge of creating robots that can perceive and act in the real world based
on natural language instructions. To bridge the gap between Large Language
Models (LLMs) and physical embodiment, we present contributions on two fronts:
scene representation and spatial reasoning. For perception, we develop robust,
scalable, and accurate scene representations using implicit neural models, with
contributions in self-supervised camera calibration, high-fidelity depth field
generation, and large-scale reconstruction. For spatial reasoning, we enhance
the spatial capabilities of LLMs by introducing a novel navigation benchmark, a
method for grounding language in 3D, and a state-feedback mechanism to improve
long-horizon decision-making. This work lays a foundation for robots that can
robustly perceive their surroundings and intelligently act upon complex,
language-based commands.

</details>


### [370] [Extended Diffeomorphism for Real-Time Motion Replication in Workspaces with Different Spatial Arrangements](https://arxiv.org/abs/2509.00491)
*Masaki Saito,Shunki Itadera,Toshiyuki Murakami*

Main category: cs.RO

TL;DR: 该论文提出两种扩展的微分同胚设计来补偿机器人工作空间之间的空间放置差异，以实现多机器人遥操作的运动重复制导。


<details>
  <summary>Details</summary>
Motivation: 为了扩展机器人具身利用，多机器人遥操作技术受到关注。实现机器人动作的实时再现，能够促进多机器人高效执行相似任务。然而，在动作再现过程中，补偿目标关键点在机器人工作空间中的空间排列误差是一项挑战。

Method: 提出一种基于预定义关键点的平滑映射方法，将主机器人姿态转换为跟随机器人姿态。

Result: 通过使用双臂UR5机器人的拾取任务实验，证明了所提出的映射生成方法可以在精确操作的较低映射误差和流畅再现运动的较低映射梯度之间取得平衡。

Conclusion: 所提出的方法能够有效地补偿机器人工作空间之间的空间放置差异，并实现平滑的运动重复制导。

Abstract: This paper presents two types of extended diffeomorphism designs to
compensate for spatial placement differences between robot workspaces.
Teleoperation of multiple robots is attracting attention to expand the
utilization of the robot embodiment. Real-time reproduction of robot motion
would facilitate the efficient execution of similar tasks by multiple robots. A
challenge in the motion reproduction is compensating for the spatial
arrangement errors of target keypoints in robot workspaces. This paper proposes
a methodology for smooth mappings that transform primary robot poses into
follower robot poses based on the predefined key points in each workspace.
Through a picking task experiment using a dual-arm UR5 robot, this study
demonstrates that the proposed mapping generation method can balance lower
mapping errors for precise operation and lower mapping gradients for smooth
replicated movement.

</details>


### [371] [FLUID: A Fine-Grained Lightweight Urban Signalized-Intersection Dataset of Dense Conflict Trajectories](https://arxiv.org/abs/2509.00497)
*Yiyang Chen,Zhigang Wu,Guohong Zheng,Xuesong Wu,Liwen Xu,Haoyuan Tang,Zhaocheng He,Haipeng Zeng*

Main category: cs.RO

TL;DR: 一个包含密集冲突的城市交叉口轨迹数据集，以及一个用于无人机轨迹处理的轻量级框架。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在场景代表性、信息丰富性和数据保真度方面存在局限性，需要更精细化的交通参与者轨迹数据来评估交通状况和优化策略。

Method: 开发FLUID数据集，包含详细的轨迹、交通信号、地图和原始视频，并构建一个轻量级的全流程无人机轨迹处理框架。通过与DataFromSky平台和地面真实测量进行比较来验证其时空准确性。

Result: FLUID数据集包含三种不同类型的交叉口，约5小时的录制时间，覆盖超过20,000名交通参与者，平均每分钟发生两次车辆冲突。数据显示了多样的交互行为，包括冲突和违规。

Conclusion: FLUID数据集及其处理框架为人类偏好挖掘、交通行为建模和自动驾驶研究提供了宝贵的资源，能够揭示城市交叉口的复杂交通动态。

Abstract: The trajectory data of traffic participants (TPs) is a fundamental resource
for evaluating traffic conditions and optimizing policies, especially at urban
intersections. Although data acquisition using drones is efficient, existing
datasets still have limitations in scene representativeness, information
richness, and data fidelity. This study introduces FLUID, comprising a
fine-grained trajectory dataset that captures dense conflicts at typical urban
signalized intersections, and a lightweight, full-pipeline framework for
drone-based trajectory processing. FLUID covers three distinct intersection
types, with approximately 5 hours of recording time and featuring over 20,000
TPs across 8 categories. Notably, the dataset averages two vehicle conflicts
per minute, involving roughly 25% of all motor vehicles. FLUID provides
comprehensive data, including trajectories, traffic signals, maps, and raw
videos. Comparison with the DataFromSky platform and ground-truth measurements
validates its high spatio-temporal accuracy. Through a detailed classification
of motor vehicle conflicts and violations, FLUID reveals a diversity of
interactive behaviors, demonstrating its value for human preference mining,
traffic behavior modeling, and autonomous driving research.

</details>


### [372] [NeuralSVCD for Efficient Swept Volume Collision Detection](https://arxiv.org/abs/2509.00499)
*Dongwon Son,Hojin Jung,Beomjoon Kim*

Main category: cs.RO

TL;DR: NeuralSVCD是一种新颖的神经编码器-解码器架构，用于在非结构化环境中进行机器人操作中的扫掠体积碰撞检测（SVCD），在效率和准确性之间取得了更好的平衡。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中进行机器人操作需要高效且可靠的扫掠体积碰撞检测（SVCD）以确保安全运动规划。传统方法存在效率和准确性的权衡问题，限制了其实际应用。

Method: 提出了一种名为NeuralSVCD的新型神经编码器-解码器架构，该架构利用形状局部性和时间局部性，通过分布式几何表示和时间优化来提高计算效率，同时不牺牲准确性。

Result: 实验表明，NeuralSVCD在碰撞检测准确性和计算效率方面均优于现有的最先进的SVCD方法，在各种机器人操作场景中表现出鲁棒的适用性。

Conclusion: NeuralSVCD通过利用形状局部性和时间局部性，成功克服了传统SVCD方法的效率与准确性之间的权衡，为机器人安全运动规划提供了更优的解决方案。

Abstract: Robot manipulation in unstructured environments requires efficient and
reliable Swept Volume Collision Detection (SVCD) for safe motion planning.
Traditional discrete methods potentially miss collisions between these points,
whereas SVCD continuously checks for collisions along the entire trajectory.
Existing SVCD methods typically face a trade-off between efficiency and
accuracy, limiting practical use. In this paper, we introduce NeuralSVCD, a
novel neural encoder-decoder architecture tailored to overcome this trade-off.
Our approach leverages shape locality and temporal locality through distributed
geometric representations and temporal optimization. This enhances
computational efficiency without sacrificing accuracy. Comprehensive
experiments show that NeuralSVCD consistently outperforms existing
state-of-the-art SVCD methods in terms of both collision detection accuracy and
computational efficiency, demonstrating its robust applicability across diverse
robotic manipulation scenarios. Code and videos are available at
https://neuralsvcd.github.io/.

</details>


### [373] [Needle Biopsy And Fiber-Optic Compatible Robotic Insertion Platform](https://arxiv.org/abs/2509.00530)
*Fanxin Wang,Yikun Cheng,Chuyuan Tao,Rohit Bhargava,Thenkurussi Kesavadas*

Main category: cs.RO

TL;DR: 该研究提出了一种用于改进传统组织病理学诊断的机器人插入平台，该平台能够精确操控多种工具，旨在克服手动活检的准确性问题和病理测试耗时的问题。


<details>
  <summary>Details</summary>
Motivation: 传统组织活检在疾病诊断中存在手动采样不精确和病理测试耗时两大局限性，本研究旨在通过开发一种机器人插入平台来解决这些问题。

Method: 研究提出了一种紧凑、精确且易于操控的机器人插入平台，该平台能够操控不同尺寸的工具，如用于组织提取的针头和用于振动光谱的光纤，以实现多模态诊断。文中详细介绍了该装置的概念、机械设计和控制方案。

Result: 通过定位精度、导纳性能和工具插入效果等一系列测试，验证了该机器人系统的有效性。

Conclusion: 该机器人插入平台为克服传统组织病理学的局限性提供了解决方案，并通过实验验证了其性能。

Abstract: Tissue biopsy is the gold standard for diagnosing many diseases, involving
the extraction of diseased tissue for histopathology analysis by expert
pathologists. However, this procedure has two main limitations: 1) Manual
sampling through tissue biopsy is prone to inaccuracies; 2) The extraction
process is followed by a time-consuming pathology test. To address these
limitations, we present a compact, accurate, and maneuverable robotic insertion
platform to overcome the limitations in traditional histopathology. Our
platform is capable of steering a variety of tools with different sizes,
including needle for tissue extraction and optical fibers for vibrational
spectroscopy applications. This system facilitates the guidance of end-effector
to the tissue and assists surgeons in navigating to the biopsy target area for
multi-modal diagnosis. In this paper, we outline the general concept of our
device, followed by a detailed description of its mechanical design and control
scheme. We conclude with the validation of the system through a series of
tests, including positioning accuracy, admittance performance, and tool
insertion efficacy.

</details>


### [374] [Reinforcement Learning of Dolly-In Filming Using a Ground-Based Robot](https://arxiv.org/abs/2509.00564)
*Philip Lorimer,Jack Saunders,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 通过强化学习自动化无人小车进行推轨镜头拍摄，提升了电影制作的动态运动表现，并克服了传统控制的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决自由移动的摄像小车在自动化摄像控制方面的挑战，以增强电影制作的动态运动。

Method: 应用强化学习（RL）自动化自由移动的地面机器人进行推轨镜头拍摄，并通过模拟和真实世界测试，将组合控制策略与独立控制策略进行了比较。

Result: 强化学习方法在模拟和真实世界测试中均优于传统的比例-微分控制器，证明了其在电影拍摄任务中的有效性和实用性。

Conclusion: 强化学习方法在自动化摄像小车控制方面取得了成功，为电影制作带来了新的可能性，并为未来在复杂电影制作场景中的研究铺平了道路。

Abstract: Free-roaming dollies enhance filmmaking with dynamic movement, but challenges
in automated camera control remain unresolved. Our study advances this field by
applying Reinforcement Learning (RL) to automate dolly-in shots using
free-roaming ground-based filming robots, overcoming traditional control
hurdles. We demonstrate the effectiveness of combined control for precise film
tasks by comparing it to independent control strategies. Our robust RL pipeline
surpasses traditional Proportional-Derivative controller performance in
simulation and proves its efficacy in real-world tests on a modified ROSBot 2.0
platform equipped with a camera turret. This validates our approach's
practicality and sets the stage for further research in complex filming
scenarios, contributing significantly to the fusion of technology with
cinematic creativity. This work presents a leap forward in the field and opens
new avenues for research and development, effectively bridging the gap between
technological advancement and creative filmmaking.

</details>


### [375] [ConceptBot: Enhancing Robot's Autonomy through Task Decomposition with Large Language Models and Knowledge Graph](https://arxiv.org/abs/2509.00570)
*Alessandro Leanza,Angelo Moroncelli,Giuseppe Vizzari,Francesco Braghin,Loris Roveda,Blerina Spahiu*

Main category: cs.RO

TL;DR: ConceptBot是一个结合大语言模型和知识图谱的机器人规划框架，旨在解决自然语言指令中的歧义和环境物体识别问题，生成可行且风险可控的规划。它通过对象属性提取（OPE）、用户请求处理（URP）和规划器三个模块实现。在与Google SayCan的比较评估中，ConceptBot在明确任务上成功率100%，隐式任务准确率87%（SayCan为31%），风险任务准确率76%（SayCan为15%），并在特定应用场景如材料分类（70% vs. 20%）和毒性检测（86% vs. 36%）中表现更优。在SafeAgentBench上，ConceptBot获得80%的综合得分（优于其他基线46%）。这些结果在模拟和实验室实验中均得到验证，证明了ConceptBot无需领域特定训练即可泛化，并显著提高了在非结构化环境中机器人策略的可靠性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决机器人规划中因自然语言指令的歧义和对环境中物体缺乏常识性推理而导致的计划可行性和风险控制问题。

Method: ConceptBot整合了三个模块：(i) 对象属性提取（OPE）模块，利用ConceptNet中的语义概念丰富场景理解；(ii) 用户请求处理（URP）模块，用于消除歧义和结构化指令；(iii) 规划器，用于生成上下文感知、可行的拾取-放置策略。

Result: ConceptBot在明确任务上实现了100%的成功率，在隐式任务上达到了87%的准确率（相比之下SayCan为31%），在风险任务上达到了76%的准确率（相比之下SayCan为15%）。此外，在材料分类（70% vs. 20%）和毒性检测（86% vs. 36%）等特定应用场景中，ConceptBot的表现均优于SayCan。在SafeAgentBench上，ConceptBot获得了80%的综合得分，而次优基线仅为46%。

Conclusion: ConceptBot在模拟和实验室实验中均表现出良好的泛化能力，无需领域特定训练，并显著提高了在非结构化环境中机器人策略的可靠性。

Abstract: ConceptBot is a modular robotic planning framework that combines Large
Language Models and Knowledge Graphs to generate feasible and risk-aware plans
despite ambiguities in natural language instructions and correctly analyzing
the objects present in the environment - challenges that typically arise from a
lack of commonsense reasoning. To do that, ConceptBot integrates (i) an Object
Property Extraction (OPE) module that enriches scene understanding with
semantic concepts from ConceptNet, (ii) a User Request Processing (URP) module
that disambiguates and structures instructions, and (iii) a Planner that
generates context-aware, feasible pick-and-place policies. In comparative
evaluations against Google SayCan, ConceptBot achieved 100% success on explicit
tasks, maintained 87% accuracy on implicit tasks (versus 31% for SayCan),
reached 76% on risk-aware tasks (versus 15%), and outperformed SayCan in
application-specific scenarios, including material classification (70% vs. 20%)
and toxicity detection (86% vs. 36%). On SafeAgentBench, ConceptBot achieved an
overall score of 80% (versus 46% for the next-best baseline). These results,
validated in both simulation and laboratory experiments, demonstrate
ConceptBot's ability to generalize without domain-specific training and to
significantly improve the reliability of robotic policies in unstructured
environments. Website: https://sites.google.com/view/conceptbot

</details>


### [376] [Gray-Box Computed Torque Control for Differential-Drive Mobile Robot Tracking](https://arxiv.org/abs/2509.00571)
*Arman Javan Sekhavat Pishkhani*

Main category: cs.RO

TL;DR: A learning-based nonlinear tracking control algorithm for differential-drive mobile robots that combines Computed Torque Control (CTC) with Deep Reinforcement Learning (DRL) using the TD3 algorithm. It improves sample efficiency and stability by using a gray-box CTC instead of a black-box DRL policy, constraining parameters to physically plausible ranges, and enforcing a critically damped response. Evaluated in simulation, it outperforms raw CTC and a conventional kinematic controller.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of the Computed Torque Method (inaccurate parameters) and Deep Reinforcement Learning (sample inefficiency, weak stability guarantees) in tracking control for differential-drive mobile robots.

Method: The proposed method replaces the black-box policy network of a DRL agent with a gray-box Computed Torque Controller (CTC). The Twin-Delayed Deep Deterministic Policy Gradient (TD3) algorithm is used to find optimal CTC parameters. Controller parameters are constrained to known value ranges, and a technique is applied to enforce a critically damped closed-loop time response.

Result: The learning-based nonlinear algorithm shows improved performance compared to the raw CTC and a conventional kinematic controller when evaluated on a simulated differential-drive mobile robot in the MuJoCo physics engine.

Conclusion: The proposed approach effectively combines CTC and DRL to achieve stable and sample-efficient tracking control for differential-drive mobile robots, outperforming existing methods.

Abstract: This study presents a learning-based nonlinear algorithm for tracking control
of differential-drive mobile robots. The Computed Torque Method (CTM) suffers
from inaccurate knowledge of system parameters, while Deep Reinforcement
Learning (DRL) algorithms are known for sample inefficiency and weak stability
guarantees. The proposed method replaces the black-box policy network of a DRL
agent with a gray-box Computed Torque Controller (CTC) to improve sample
efficiency and ensure closed-loop stability. This approach enables finding an
optimal set of controller parameters for an arbitrary reward function using
only a few short learning episodes. The Twin-Delayed Deep Deterministic Policy
Gradient (TD3) algorithm is used for this purpose. Additionally, some
controller parameters are constrained to lie within known value ranges,
ensuring the RL agent learns physically plausible values. A technique is also
applied to enforce a critically damped closed-loop time response. The
controller's performance is evaluated on a differential-drive mobile robot
simulated in the MuJoCo physics engine and compared against the raw CTC and a
conventional kinematic controller.

</details>


### [377] [Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot](https://arxiv.org/abs/2509.00574)
*Philip Lorimer,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 使用模仿学习（LfD）的生成对抗模仿学习（GAIL）来自动化摄像机推轨镜头，无需手工设计奖励函数，并在模拟和现实世界中均优于强化学习（RL）方法。


<details>
  <summary>Details</summary>
Motivation: 手动设计的奖励函数难以平衡电影摄像控制的精确性和艺术性，而传统的强化学习方法在实际应用中对奖励函数设计和参数调优有较高要求，限制了其创意可用性。

Method: 通过在模拟环境中进行操纵杆远程操作收集专家轨迹，然后使用生成对抗模仿学习（GAIL）来训练策略，该策略专门学习这些演示数据。

Result: 在模拟环境中，GAIL策略的表现优于PPO基线，实现了更高的奖励、更快的收敛速度和更低的方差。在现实世界的机器人上，无需微调即可实现比先前基于TD3的方法更一致的构图和主体对齐。

Conclusion: 模仿学习（LfD）为电影领域提供了一种无需奖励函数即可实现的鲁棒替代方案，能够以最小的技术努力进行实时部署，使创意专业人士能够实现直观、风格化的摄像机控制。

Abstract: Cinematic camera control demands a balance of precision and artistry -
qualities that are difficult to encode through handcrafted reward functions.
While reinforcement learning (RL) has been applied to robotic filmmaking, its
reliance on bespoke rewards and extensive tuning limits creative usability. We
propose a Learning from Demonstration (LfD) approach using Generative
Adversarial Imitation Learning (GAIL) to automate dolly-in shots with a
free-roaming, ground-based filming robot. Expert trajectories are collected via
joystick teleoperation in simulation, capturing smooth, expressive motion
without explicit objective design.
  Trained exclusively on these demonstrations, our GAIL policy outperforms a
PPO baseline in simulation, achieving higher rewards, faster convergence, and
lower variance. Crucially, it transfers directly to a real-world robot without
fine-tuning, achieving more consistent framing and subject alignment than a
prior TD3-based method. These results show that LfD offers a robust,
reward-free alternative to RL in cinematic domains, enabling real-time
deployment with minimal technical effort. Our pipeline brings intuitive,
stylized camera control within reach of creative professionals, bridging the
gap between artistic intent and robotic autonomy.

</details>


### [378] [Galaxea Open-World Dataset and G0 Dual-System VLA Model](https://arxiv.org/abs/2509.00576)
*Tao Jiang,Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Jianning Cui,Xiao Liu,Shuiqi Cheng,Jiyang Gao,Huazhe Xu,Hang Zhao*

Main category: cs.RO

TL;DR: 我们提出了Galaxea开放世界数据集，这是一个在大规模、多样化的真实人类生活和工作环境中记录的机器人行为集合。数据集包含一致的机器人具身数据和精确的子任务语言标注。我们还引入了G0框架，该框架结合了用于多模态规划的视觉-语言模型（VLM）和用于细粒度执行的视觉-语言-动作（VLA）模型。G0采用跨具身预训练、单具身预训练和任务特定后训练的三阶段课程进行训练。在涵盖桌面操作、少样本学习和长时序移动操作的综合基准测试中，我们证明了该方法的有效性，特别是单具身预训练阶段在提高性能方面起着关键作用。


<details>
  <summary>Details</summary>
Motivation: 介绍Galaxea开放世界数据集，这是一个大规模、多样化的机器人行为数据集，用于在真实环境中进行机器人学习。同时，提出G0框架，旨在通过结合VLM和VLA模型来提高机器人在复杂环境中的规划和执行能力。

Method: 1. 构建Galaxea开放世界数据集，收集真实环境中的机器人行为数据，并进行语言标注。
2. 提出G0框架，结合VLM进行多模态规划，VLA进行细粒度执行。
3. 采用三阶段课程进行G0训练：跨具身预训练、单具身预训练、任务特定后训练。

Result: G0框架在桌面操作、少样本学习和长时序移动操作等多个基准测试中表现出有效性。特别是，单具身预训练阶段与Galaxea开放世界数据集的结合，对模型的强劲性能起到了关键作用。

Conclusion: Galaxea开放世界数据集和G0框架（特别是其单具身预训练阶段）能够有效地提高机器人在真实世界复杂环境中的规划和执行能力。

Abstract: We present Galaxea Open-World Dataset, a large-scale, diverse collection of
robot behaviors recorded in authentic human living and working environments.
All demonstrations are gathered using a consistent robotic embodiment, paired
with precise subtask-level language annotations to facilitate both training and
evaluation. Building on this dataset, we introduce G0, a dual-system framework
that couples a Vision-Language Model (VLM) for multimodal planning with a
Vision-Language-Action (VLA) model for fine-grained execution. G0 is trained
using a three-stage curriculum: cross-embodiment pre-training,
single-embodiment pre-training, and task-specific post-training. A
comprehensive benchmark spanning tabletop manipulation, few-shot learning, and
long-horizon mobile manipulation, demonstrates the effectiveness of our
approach. In particular, we find that the single-embodiment pre-training stage,
together with the Galaxea Open-World Dataset, plays a critical role in
achieving strong performance.

</details>


### [379] [Safe and Efficient Lane-Changing for Autonomous Vehicles: An Improved Double Quintic Polynomial Approach with Time-to-Collision Evaluation](https://arxiv.org/abs/2509.00582)
*Rui Bai,Rui Xu,Teng Rui,Jiale Liu,Qi Wei Oung,Hoi Leong Lee,Zhen Tian,Fujiang Yuan*

Main category: cs.RO

TL;DR: 本论文提出一种改进的双五次多项式方法，用于在混合交通环境中进行安全高效的车道变换，通过将基于碰撞时间（TTC）的评估机制集成到轨迹优化中，确保车辆在整个机动过程中与周围车辆保持安全距离。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶汽车在与人类驾驶车辆混合的交通环境中进行车道变换时，确保交互安全性和舒适性的挑战。

Method: 提出一种改进的双五次多项式方法，将基于碰撞时间（TTC）的评估机制集成到轨迹优化过程中，用于安全高效的车道变换。该框架包括对自主车辆（AV）和人类驾驶车辆（HDVs）的状态估计、使用双五次多项式的轨迹生成、实时TTC计算以及自适应轨迹评估。

Result: 通过在各种交通场景下进行的大量模拟，证明了与传统的五次多项式、贝塞尔曲线和B样条等方法相比，该改进方法在安全性、效率和舒适性方面表现更优。结果表明，该方法不仅能避免碰撞，还能确保平稳的过渡和动态环境中的自适应决策。

Conclusion: 本研究提出的改进双五次多项式方法能够实时生成考虑安全性的轨迹，无需事后验证，为真实世界的自动驾驶应用提供了稳定的解决方案，弥合了基于模型和自适应轨迹规划方法之间的差距。

Abstract: Autonomous driving technology has made significant advancements in recent
years, yet challenges remain in ensuring safe and comfortable interactions with
human-driven vehicles (HDVs), particularly during lane-changing maneuvers. This
paper proposes an improved double quintic polynomial approach for safe and
efficient lane-changing in mixed traffic environments. The proposed method
integrates a time-to-collision (TTC) based evaluation mechanism directly into
the trajectory optimization process, ensuring that the ego vehicle proactively
maintains a safe gap from surrounding HDVs throughout the maneuver. The
framework comprises state estimation for both the autonomous vehicle (AV) and
HDVs, trajectory generation using double quintic polynomials, real-time TTC
computation, and adaptive trajectory evaluation. To the best of our knowledge,
this is the first work to embed an analytic TTC penalty directly into the
closed-form double-quintic polynomial solver, enabling real-time safety-aware
trajectory generation without post-hoc validation. Extensive simulations
conducted under diverse traffic scenarios demonstrate the safety, efficiency,
and comfort of the proposed approach compared to conventional methods such as
quintic polynomials, Bezier curves, and B-splines. The results highlight that
the improved method not only avoids collisions but also ensures smooth
transitions and adaptive decision-making in dynamic environments. This work
bridges the gap between model-based and adaptive trajectory planning
approaches, offering a stable solution for real-world autonomous driving
applications.

</details>


### [380] [Vehicle-in-Virtual-Environment (VVE) Method for Developing and Evaluating VRU Safety of Connected and Autonomous Driving with Focus on Bicyclist Safety](https://arxiv.org/abs/2509.00624)
*Haochong Chen,Xincheng Cao,Bilin Aksun-Guvenc,Levent Guvenc*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Extensive research has already been conducted in the autonomous driving field
to help vehicles navigate safely and efficiently. At the same time, plenty of
current research on vulnerable road user (VRU) safety is performed which
largely concentrates on perception, localization, or trajectory prediction of
VRUs. However, existing research still exhibits several gaps, including the
lack of a unified planning and collision avoidance system for autonomous
vehicles, limited investigation into delay tolerant control strategies, and the
absence of an efficient and standardized testing methodology. Ensuring VRU
safety remains one of the most pressing challenges in autonomous driving,
particularly in dynamic and unpredictable environments. In this two year
project, we focused on applying the Vehicle in Virtual Environment (VVE) method
to develop, evaluate, and demonstrate safety functions for Vulnerable Road
Users (VRUs) using automated steering and braking of ADS. In this current
second year project report, our primary focus was on enhancing the previous
year results while also considering bicyclist safety.

</details>


### [381] [A Risk-aware Spatial-temporal Trajectory Planning Framework for Autonomous Vehicles Using QP-MPC and Dynamic Hazard Fields](https://arxiv.org/abs/2509.00643)
*Zhen Tian,Zhihao Lin,Dezong Zhao,Christos Anagnostopoulos,Qiyuan Wang,Wenjing Zhao,Xiaodan Wang,Chongfeng Wei*

Main category: cs.RO

TL;DR: This paper proposes an enhanced QP-MPC framework for autonomous vehicle trajectory planning, featuring a novel dynamic hazard field cost function for improved safety, efficiency, and comfort, validated through extensive simulations.


<details>
  <summary>Details</summary>
Motivation: Existing trajectory planning methods for autonomous vehicles suffer from high computational costs, unstable performance in dynamic environments, and limited validation across diverse scenarios. This paper aims to overcome these challenges.

Method: The proposed framework enhances QP-MPC with three innovations: (i) a novel cost function using a dynamic hazard field for balancing safety, efficiency, and comfort; (ii) seamless integration of this cost function into the QP-MPC formulation for direct optimization of driving behaviors; and (iii) extensive validation across complex tasks. It utilizes a dynamic hazard field (DHF) for spatial risk assessment and a space-time graph for temporal planning. Quintic polynomial sampling and sub-rewards for comfort and efficiency are incorporated, with the DHF-enhanced objective function integrating multiple objectives for QP-MPC optimization.

Result: Extensive simulations show the proposed framework outperforms benchmark optimization methods in efficiency, stability, and comfort across various scenarios, including lane-changing, overtaking, and crossing intersections.

Conclusion: The proposed DHF-enhanced QP-MPC framework effectively improves trajectory planning for autonomous vehicles, demonstrating superior performance in efficiency, stability, and comfort compared to existing methods across diverse driving scenarios.

Abstract: Trajectory planning is a critical component in ensuring the safety,
stability, and efficiency of autonomous vehicles. While existing trajectory
planning methods have achieved progress, they often suffer from high
computational costs, unstable performance in dynamic environments, and limited
validation across diverse scenarios. To overcome these challenges, we propose
an enhanced QP-MPC-based framework that incorporates three key innovations: (i)
a novel cost function designed with a dynamic hazard field, which explicitly
balances safety, efficiency, and comfort; (ii) seamless integration of this
cost function into the QP-MPC formulation, enabling direct optimization of
desired driving behaviors; and (iii) extensive validation of the proposed
framework across complex tasks. The spatial safe planning is guided by a
dynamic hazard field (DHF) for risk assessment, while temporal safe planning is
based on a space-time graph. Besides, the quintic polynomial sampling and
sub-reward of comforts are used to ensure comforts during lane-changing. The
sub-reward of efficiency is used to maintain driving efficiency. Finally, the
proposed DHF-enhanced objective function integrates multiple objectives,
providing a proper optimization tasks for QP-MPC. Extensive simulations
demonstrate that the proposed framework outperforms benchmark optimization
methods in terms of efficiency, stability, and comfort across a variety of
scenarios likes lane-changing, overtaking, and crossing intersections.

</details>


### [382] [CARIS: A Context-Adaptable Robot Interface System for Personalized and Scalable Human-Robot Interaction](https://arxiv.org/abs/2509.00660)
*Felipe Arias-Russi,Yuanchen Bai,Angelique Taylor*

Main category: cs.RO

TL;DR: CARIS是一个可适应上下文的机器人界面系统，旨在解决传统WoZ工具的局限性，并支持HRI研究人员更有效地进行数据驱动的研究。


<details>
  <summary>Details</summary>
Motivation: 传统的人类机器人交互（HRI）领域使用“维查德之术”（WoZ）控制的机器人来研究导航、对话动态和人机循环交互等，但现有的WoZ工具通常局限于单一场景，适应性较差。本研究旨在开发一个能适应不同场景、用户和机器人平台的WoZ工具。

Method: 本文介绍了一个名为CARIS（Context-Adaptable Robot Interface System）的系统，该系统结合了远程操作、人类感知、人机对话和多模态数据记录等高级机器人功能。

Result: 通过试点研究，CARIS在两个场景下（心理健康伴侣和导游）进行了WoZ机器人控制的演示。研究还指出了CARIS的改进之处，包括移动和通信的平滑集成、更清晰的功能分离、推荐提示以及一键通信选项，以增强CARIS的可用性。

Conclusion: CARIS为HRI社区提供了一个公开可用的、可适应上下文的工具，使研究人员能够简化智能机器人行为的数据驱动方法。

Abstract: The human-robot interaction (HRI) field has traditionally used Wizard-of-Oz
(WoZ) controlled robots to explore navigation, conversational dynamics,
human-in-the-loop interactions, and more to explore appropriate robot behaviors
in everyday settings. However, existing WoZ tools are often limited to one
context, making them less adaptable across different settings, users, and
robotic platforms. To mitigate these issues, we introduce a Context-Adaptable
Robot Interface System (CARIS) that combines advanced robotic capabilities such
teleoperation, human perception, human-robot dialogue, and multimodal data
recording. Through pilot studies, we demonstrate the potential of CARIS to WoZ
control a robot in two contexts: 1) mental health companion and as a 2) tour
guide. Furthermore, we identified areas of improvement for CARIS, including
smoother integration between movement and communication, clearer functionality
separation, recommended prompts, and one-click communication options to enhance
the usability wizard control of CARIS. This project offers a publicly
available, context-adaptable tool for the HRI community, enabling researchers
to streamline data-driven approaches to intelligent robot behavior.

</details>


### [383] [DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments](https://arxiv.org/abs/2509.00741)
*Yi Liu,Keyu Fan,Bin Lan,Houde Liu*

Main category: cs.RO

TL;DR: DyPho-SLAM是一个实时、资源高效的视觉SLAM系统，能够处理动态物体，提供高保真度的相机姿态估计和密集地图重建。


<details>
  <summary>Details</summary>
Motivation: 现有视觉SLAM方法在处理动态物体时存在相机跟踪漂移和地图模糊的问题，DyPho-SLAM旨在解决这些挑战。

Method: DyPho-SLAM集成了先验图像信息生成精炼掩码以减少噪声，并采用自适应特征提取策略来增强优化约束，提高系统鲁棒性。

Result: 在公开的动态RGB-D数据集上的实验表明，DyPho-SLAM在动态场景下实现了先进的相机姿态估计和密集地图重建性能，并能进行实时操作。

Conclusion: DyPho-SLAM在处理动态物体方面表现出色，能够实现实时的相机定位和高质量的地图构建。

Abstract: Visual SLAM algorithms have been enhanced through the exploration of Gaussian
Splatting representations, particularly in generating high-fidelity dense maps.
While existing methods perform reliably in static environments, they often
encounter camera tracking drift and fuzzy mapping when dealing with the
disturbances caused by moving objects. This paper presents DyPho-SLAM, a
real-time, resource-efficient visual SLAM system designed to address the
challenges of localization and photorealistic mapping in environments with
dynamic objects. Specifically, the proposed system integrates prior image
information to generate refined masks, effectively minimizing noise from mask
misjudgment. Additionally, to enhance constraints for optimization after
removing dynamic obstacles, we devise adaptive feature extraction strategies
significantly improving the system's resilience. Experiments conducted on
publicly dynamic RGB-D datasets demonstrate that the proposed system achieves
state-of-the-art performance in camera pose estimation and dense map
reconstruction, while operating in real-time in dynamic scenes.

</details>


### [384] [Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gröbner Systems](https://arxiv.org/abs/2509.00823)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 该论文提出了一种使用计算机代数系统（CAS）解决特定型号6自由度（DOF）机器人机械臂逆运动学问题的有效方法，该方法将问题分解为位置和方向的确定，并能推广到更多一般类型的机械臂，使用Comprehensive Gr"obner System（CGS）来求解，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 将求解机器人逆运动学问题的方法从具有特殊结构（三个连续关节的旋转轴相交于一点）的机械臂推广到更一般的具有两个连续关节的旋转轴相交的机械臂，以扩大可解逆运动学问题的6自由度机械臂的范围，并期望能实现更有效的解决方案。

Method: 使用Comprehensive Gr"obner System（CGS）结合计算机代数系统（CAS）来求解逆运动学问题。在求解过程中，将机器人关节参数作为系数中的参数，以避免重复计算Gr"obner基。

Result: 通过实验证明了所提出方法的有效性。

Conclusion: 该方法能够有效解决更广泛的6自由度机器人机械臂的逆运动学问题，并可能实现更高效的求解。

Abstract: We propose an effective method for solving the inverse kinematic problem of a
specific model of 6-degree-of-freedom (6-DOF) robot manipulator using computer
algebra. It is known that when the rotation axes of three consecutive
rotational joints of a manipulator intersect at a single point, the inverse
kinematics problem can be divided into determining position and orientation. We
extend this method to more general manipulators in which the rotational axes of
two consecutive joints intersect. This extension broadens the class of 6-DOF
manipulators for which the inverse kinematics problem can be solved, and is
expected to enable more efficient solutions. The inverse kinematic problem is
solved using the Comprehensive Gr\"obner System (CGS) with joint parameters of
the robot appearing as parameters in the coefficients to prevent repetitive
calculations of the Gr\"obner bases. The effectiveness of the proposed method
is shown by experiments.

</details>


### [385] [An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator](https://arxiv.org/abs/2509.00828)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 该论文提出了一种优化6-DOF机器人机械臂路径规划的方法，通过结合计算机代数和Dijkstra算法，实现了在给定路径下的最优运动规划。


<details>
  <summary>Details</summary>
Motivation: 为特定型号的6-DOF机器人机械臂的运动规划，优化路径规划问题。

Method: 1. 计算末端执行器在特定构型下的可行区域。2. 寻找在直线段上的轨迹以及机械臂应遵循的关节构型序列。3. 将问题转化为图的最短路径问题，应用Dijkstra算法寻找最优逆运动学解。

Result: 通过实验验证了所提出方法的有效性。

Conclusion: 该方法能够有效地为6-DOF机器人机械臂优化路径规划。

Abstract: An effective method for optimizing path planning for a specific model of a
6-degree-of-freedom (6-DOF) robot manipulator is presented as part of the
motion planning of the manipulator using computer algebra. We assume that we
are given a path in the form of a set of line segments that the end-effector
should follow. We also assume that we have a method to solve the inverse
kinematic problem of the manipulator at each via-point of the trajectory. The
proposed method consists of three steps. First, we calculate the feasible
region of the manipulator under a specific configuration of the end-effector.
Next, we aim to find a trajectory on the line segments and a sequence of joint
configurations the manipulator should follow to move the end-effector along the
specified trajectory. Finally, we find the optimal combination of solutions to
the inverse kinematic problem at each via-point along the trajectory by
reducing the problem to a shortest-path problem of the graph and applying
Dijkstra's algorithm. We show the effectiveness of the proposed method by
experiments.

</details>


### [386] [One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields](https://arxiv.org/abs/2509.00836)
*Yulin Li,Tetsuro Miyazaki,Kenji Kawashima*

Main category: cs.RO

TL;DR: 将配置空间距离场（CDF）与模型预测路径积分（MPPI）相结合，以实现高效、高维的机器人运动规划。


<details>
  <summary>Details</summary>
Motivation: 克服传统基于优化的方法在局部最小值和SDF梯度消失时的局限性，以及梯度无关方法（如MPPI）的计算成本和成本函数设计困难。

Method: 提出一个将CDF与MPPI相结合的框架，利用CDF梯度统一MPPI成本，并将预测范围缩短至一步，从而在配置空间中进行直接导航。

Result: 在2D环境中实现了近100%的成功率，在复杂的7-DOF Franka机械臂仿真中也取得了持续的高成功率，控制频率超过750 Hz，显著优于基线方法。

Conclusion: 该CDF-MPPI框架在处理高维运动规划问题方面，能够实现高效率和高成功率。

Abstract: Motion planning for robotic manipulators is a fundamental problem in
robotics. Classical optimization-based methods typically rely on the gradients
of signed distance fields (SDFs) to impose collision-avoidance constraints.
However, these methods are susceptible to local minima and may fail when the
SDF gradients vanish. Recently, Configuration Space Distance Fields (CDFs) have
been introduced, which directly model distances in the robot's configuration
space. Unlike workspace SDFs, CDFs are differentiable almost everywhere and
thus provide reliable gradient information. On the other hand, gradient-free
approaches such as Model Predictive Path Integral (MPPI) control leverage
long-horizon rollouts to achieve collision avoidance. While effective, these
methods are computationally expensive due to the large number of trajectory
samples, repeated collision checks, and the difficulty of designing cost
functions with heterogeneous physical units. In this paper, we propose a
framework that integrates CDFs with MPPI to enable direct navigation in the
robot's configuration space. Leveraging CDF gradients, we unify the MPPI cost
in joint-space and reduce the horizon to one step, substantially cutting
computation while preserving collision avoidance in practice. We demonstrate
that our approach achieves nearly 100% success rates in 2D environments and
consistently high success rates in challenging 7-DOF Franka manipulator
simulations with complex obstacles. Furthermore, our method attains control
frequencies exceeding 750 Hz, substantially outperforming both
optimization-based and standard MPPI baselines. These results highlight the
effectiveness and efficiency of the proposed CDF-MPPI framework for
high-dimensional motion planning.

</details>


### [387] [Enhanced Mean Field Game for Interactive Decision-Making with Varied Stylish Multi-Vehicles](https://arxiv.org/abs/2509.00981)
*Liancheng Zheng,Zhen Tian,Yangfan He,Shuo Liu,Ke Gong,Huilin Chen,Zhihao Lin*

Main category: cs.RO

TL;DR: 该论文提出了一种基于 MFG 的决策框架，用于处理异构交通中的自动驾驶。通过空间影响场模型将量化的驾驶风格（速度、安全因子、反应时间）嵌入 MFG。引入了安全关键型换道算法（动态安全裕度、碰撞时间分析、多层约束）以确保密集交通中的安全。使用 NGSIM 数据进行校准和验证。实验结果表明，在六种风格组合、两种 15 车辆场景和基于 NGSIM 的试验中，实现了零碰撞，并且优于传统博弈论基线。该方法为真实世界的自动驾驶提供了可扩展、可解释且行为感知的规划框架。


<details>
  <summary>Details</summary>
Motivation: 为了在异构交通中实现自动驾驶，需要一个能够捕捉多样化人类驾驶行为的决策框架。

Method: 提出了一种量化的驾驶风格表示方法，将抽象特征映射到速度、安全因子和反应时间等参数，并通过空间影响场模型将这些参数嵌入 MFG。为了确保密集交通中的安全，引入了一种安全关键型换道算法，该算法利用了动态安全裕度、碰撞时间分析和多层约束。

Result: 实验结果显示，在六种风格组合、两种 15 辆车场景以及基于 NGSIM 的测试中，均实现了零碰撞，并且性能优于传统的博弈论基线。

Conclusion: 该 MFG 驱动的决策框架能够实现安全、可扩展且行为感知的自动驾驶，尤其在异构交通环境中表现优越。

Abstract: This paper presents an MFG-based decision-making framework for autonomous
driving in heterogeneous traffic. To capture diverse human behaviors, we
propose a quantitative driving style representation that maps abstract traits
to parameters such as speed, safety factors, and reaction time. These
parameters are embedded into the MFG through a spatial influence field model.
To ensure safe operation in dense traffic, we introduce a safety-critical
lane-changing algorithm that leverages dynamic safety margins,
time-to-collision analysis, and multi-layered constraints. Real-world NGSIM
data is employed for style calibration and empirical validation. Experimental
results demonstrate zero collisions across six style combinations, two
15-vehicle scenarios, and NGSIM-based trials, consistently outperforming
conventional game-theoretic baselines. Overall, our approach provides a
scalable, interpretable, and behavior-aware planning framework for real-world
autonomous driving applications.

</details>


### [388] [A Robust Numerical Method for Solving Trigonometric Equations in Robotic Kinematics](https://arxiv.org/abs/2509.01010)
*Hai-Jun Su*

Main category: cs.RO

TL;DR: 该研究提出了一种用于求解机器人运动学中三角函数方程组的鲁棒数值方法，结合了多项式替换和特征值分解技术，以有效处理奇异矩阵和边缘情况。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决机器人运动学中常见的三角函数方程组，并提出一种比传统方法更具数值稳定性的方法。

Method: 该方法结合了多项式替换（特别是对于非奇异矩阵的Weierstrass替换）和特征值分解（用于处理奇异矩阵的几何约束方法和SVD分析）。

Result: 该求解器在大量测试用例中表现出机器精度精度（<10^-15 误差）和100%的成功率。

Conclusion: 该方法对于机器人学应用（如逆运动学问题）具有很高的价值，因为它具有卓越的数值稳定性和准确性。

Abstract: This paper presents a robust numerical method for solving systems of
trigonometric equations commonly encountered in robotic kinematics. Our
approach employs polynomial substitution techniques combined with eigenvalue
decomposition to handle singular matrices and edge cases effectively. The
method demonstrates superior numerical stability compared to traditional
approaches and has been implemented as an open-source Python package. For
non-singular matrices, we employ Weierstrass substitution to transform the
system into a quartic polynomial, ensuring all analytical solutions are found.
For singular matrices, we develop specialized geometric constraint methods
using SVD analysis. The solver demonstrates machine precision accuracy ($<
10^{-15}$ error) with 100\% success rate on extensive test cases, making it
particularly valuable for robotics applications such as inverse kinematics
problems.

</details>


### [389] [TARA: A Low-Cost 3D-Printed Robotic Arm for Accessible Robotics Education](https://arxiv.org/abs/2509.01043)
*Thays Leach Mitre*

Main category: cs.RO

TL;DR: TARA是一个低成本、3D打印的机器人手臂，旨在普及机器人教育。它提供开源文件，成本约200美元，易于复制和扩展。


<details>
  <summary>Details</summary>
Motivation: 高昂的机器人平台成本阻碍了学生获得实际操作技能，因此需要一个低成本的解决方案来普及机器人教育。

Method: 设计并制造了一个名为TARA的低成本、3D打印机器人手臂，并提供开源的 설계文件、组装说明和基础代码，使其易于学生和教育工作者复制和定制。

Result: 实验验证表明TARA在基本操作任务中表现准确，虽然不侧重于性能基准测试，但优先考虑了教育的可重复性。

Conclusion: TARA作为一个低成本、易于复制和扩展的机器人手臂，为机器人教育提供了一个可行的解决方案，解决了高成本的障碍。

Abstract: The high cost of robotic platforms limits students' ability to gain practical
skills directly applicable in real-world scenarios. To address this challenge,
this paper presents TARA, a low-cost, 3D-printed robotic arm designed for
accessible robotics education. TARA includes an open-source repository with
design files, assembly instructions, and baseline code, enabling users to build
and customize the platform. The system balances affordability and
functionality, offering a highly capable robotic arm for approximately 200 USD,
significantly lower than industrial systems that often cost thousands of
dollars. Experimental validation confirmed accurate performance in basic
manipulation tasks. Rather than focusing on performance benchmarking, this work
prioritizes educational reproducibility, providing a platform that students and
educators can reliably replicate and extend.

</details>


### [390] [A Reactive Grasping Framework for Multi-DoF Grippers via Task Space Velocity Fields and Joint Space QP](https://arxiv.org/abs/2509.01044)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: Our framework combines task-space velocity fields with joint-space QP for fast and reactive grasping with multi-DoF grippers. It plans globally in a lower-dimensional task space and tracks locally in the full joint space to overcome the complexity of high-DoF systems.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of reactive, collision-free global motion planning for high-DoF systems, where increased dimensionality and planning horizon make real-time planning intractable.

Method: Planning globally in a lower-dimensional task space (e.g., fingertip positions) and tracking locally in the full joint space using a hierarchical structure. This involves constructing velocity fields in task-space coordinates and solving a weighted joint-space QP to compute joint velocities that track these fields with assigned priorities.

Result: Verified through simulation experiments and real-world tests with FoundationPose that the method enables high-DoF arm-hand systems to perform real-time, collision-free reaching motions, adapting to dynamic environments and external disturbances.

Conclusion: The proposed hierarchical approach effectively enables high-DoF arm-hand systems to achieve real-time, collision-free grasping motions in dynamic environments.

Abstract: We present a fast and reactive grasping framework for multi-DoF grippers that
combines task-space velocity fields with a joint-space Quadratic Program (QP)
in a hierarchical structure. Reactive, collision-free global motion planning is
particularly challenging for high-DoF systems, since simultaneous increases in
state dimensionality and planning horizon trigger a combinatorial explosion of
the search space, making real-time planning intractable. To address this, we
plan globally in a lower-dimensional task space, such as fingertip positions,
and track locally in the full joint space while enforcing all constraints. This
approach is realized by constructing velocity fields in multiple task-space
coordinates (or in some cases a subset of joint coordinates) and solving a
weighted joint-space QP to compute joint velocities that track these fields
with appropriately assigned priorities. Through simulation experiments with
privileged knowledge and real-world tests using the recent pose-tracking
algorithm FoundationPose, we verify that our method enables high-DoF arm-hand
systems to perform real-time, collision-free reaching motions while adapting to
dynamic environments and external disturbances.

</details>


### [391] [Model Predictive Control for a Soft Robotic Finger with Stochastic Behavior based on Fokker-Planck Equation](https://arxiv.org/abs/2509.01065)
*Sumitaka Honji,Takahiro Wada*

Main category: cs.RO

TL;DR: 该研究提出了一种基于随机控制策略，称为FPE-MPC，用于控制软体机器人，以应对其固有的不确定性和非线性运动。


<details>
  <summary>Details</summary>
Motivation: 软体机器人的灵活性带来了适应性和安全性等优势，但也导致了运动高度不确定和非线性等挑战，尤其是在采用缺乏反馈的开环控制时。传统的基于确定性模型的控制方法难以处理这种不确定性。

Method: 提出并实现了一种基于随机控制策略，即FPE-MPC，用于控制软体机器人。该方法不直接控制机器人的状态，而是控制其概率分布，利用Fokker-Planck方程（FPE）来处理不确定性。

Result: 通过两个数值模拟案例研究，验证了FPE-MPC在管理软体机器人系统不确定性方面的有效性。

Conclusion: FPE-MPC是一种有效的控制策略，可以应对软体机器人系统中的不确定性和非线性运动。

Abstract: The inherent flexibility of soft robots offers numerous advantages, such as
enhanced adaptability and improved safety. However, this flexibility can also
introduce challenges regarding highly uncertain and nonlinear motion. These
challenges become particularly problematic when using open-loop control
methods, which lack a feedback mechanism and are commonly employed in soft
robot control. Though one potential solution is model-based control, typical
deterministic models struggle with uncertainty as mentioned above. The idea is
to use the Fokker-Planck Equation (FPE), a master equation of a stochastic
process, to control not the state of soft robots but the probabilistic
distribution. In this study, we propose and implement a stochastic-based
control strategy, termed FPE-based Model Predictive Control (FPE-MPC), for a
soft robotic finger. Two numerical simulation case studies examine the
performance and characteristics of this control method, revealing its efficacy
in managing the uncertainty inherent in soft robotic systems.

</details>


### [392] [SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments](https://arxiv.org/abs/2509.01111)
*Haolan Zhang,Chenghao Li,Thanh Nguyen Canh,Lijun Wang,Nak Young Chong*

Main category: cs.RO

TL;DR: SRR-SLAM是一个基于场景可靠性的框架，通过环境感知处理来增强基于特征的SLAM，以提高动态特征剔除、姿态估计、评估和优化策略的适应性，并声称在准确性和鲁棒性方面优于最先进的动态SLAM方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于特征的视觉SLAM系统在特征数量和质量的变化面前，在动态特征剔除、姿态估计、评估和优化策略方面存在适应性不足和环境感知能力不足的问题。

Method: SRR-SLAM框架引入了一个统一的场景可靠性评估机制，结合了多个指标和历史观测来指导系统行为。具体方法包括：自适应动态区域选择、深度辅助自调整聚类、可靠性感知姿态精炼（在特征不足时动态集成直接法）、可靠性驱动的关键帧选择和加权优化。

Result: SRR-SLAM在公共数据集和真实世界场景的广泛实验表明，其性能优于最先进的动态SLAM方法，在不同环境下的准确性和鲁棒性提高了90%。

Conclusion: SRR-SLAM通过其场景可靠性评估机制和一系列创新方法，显著提高了基于特征的SLAM系统的性能，增强了自主机器人传感系统的测量精度和可靠性。

Abstract: Visual simultaneous localization and mapping (SLAM) plays a critical role in
autonomous robotic systems, especially where accurate and reliable measurements
are essential for navigation and sensing. In feature-based SLAM, the
quantityand quality of extracted features significantly influence system
performance. Due to the variations in feature quantity and quality across
diverse environments, current approaches face two major challenges: (1) limited
adaptability in dynamic feature culling and pose estimation, and (2)
insufficient environmental awareness in assessment and optimization strategies.
To address these issues, we propose SRR-SLAM, a scene-reliability based
framework that enhances feature-based SLAM through environment-aware
processing. Our method introduces a unified scene reliability assessment
mechanism that incorporates multiple metrics and historical observations to
guide system behavior. Based on this assessment, we develop: (i) adaptive
dynamic region selection with flexible geometric constraints, (ii)
depth-assisted self-adjusting clustering for efficient dynamic feature removal
in high-dimensional settings, and (iii) reliability-aware pose refinement that
dynamically integrates direct methods when features are insufficient.
Furthermore, we propose (iv) reliability-based keyframe selection and a
weighted optimization scheme to reduce computational overhead while improving
estimation accuracy. Extensive experiments on public datasets and real world
scenarios show that SRR-SLAM outperforms state-of-the-art dynamic SLAM methods,
achieving up to 90% improvement in accuracy and robustness across diverse
environments. These improvements directly contribute to enhanced measurement
precision and reliability in autonomous robotic sensing systems.

</details>


### [393] [A novel parameter estimation method for pneumatic soft hand control applying logarithmic decrement for pseudo rigid body modeling](https://arxiv.org/abs/2509.01113)
*Haiyun Zhang,Kelvin HoLam Heung,Gabrielle J. Naquila,Ashwin Hingwe,Ashish D. Deshpande*

Main category: cs.RO

TL;DR: 该研究提出了一种结合伪刚体建模和对数衰减法的软体机器人手控制新方法（PRBM plus LDM），以解决现有模型计算效率低和参数识别复杂的问题。该方法通过实验验证了其预测能力和性能，并实现了闭环位置和力控制。结果表明，PRBM plus LDM在位置控制上比PID控制器有更小的误差（4.37度 vs 20.38度），在抓取任务中比恒定压力抓取有更高的成功率（马铃薯片86 vs 82.5，螺丝刀74.42 vs 70，黄铜币64.75 vs 35）。该方法在计算效率和准确性方面优于现有技术，能够实现稳定、灵活且力反馈精确的抓取。


<details>
  <summary>Details</summary>
Motivation: 现有软体机器人模型计算效率低且参数识别复杂，限制了其在实时应用中的性能，特别是在需要精确控制的软体手抓取任务中。

Method: 提出一种结合伪刚体建模（PRBM）和对数衰减法（LDM）用于参数估计的新方法（PRBM plus LDM），并将其应用于软体机器人的闭环位置和力控制。

Result: PRBM plus LDM在位置控制中比PID控制器具有更低的平均最大误差（4.37度 vs 20.38度）。在抓取任务中，PRBM plus LDM的成功率高于恒定压力抓取（马铃薯片86 vs 82.5，螺丝刀74.42 vs 70，黄铜币64.75 vs 35）。

Conclusion: PRBM plus LDM是一种计算高效且准确的软体驱动器建模技术，能够实现稳定、灵活且具有精确力调节能力的抓取。

Abstract: The rapid advancement in physical human-robot interaction (HRI) has
accelerated the development of soft robot designs and controllers. Controlling
soft robots, especially soft hand grasping, is challenging due to their
continuous deformation, motivating the use of reduced model-based controllers
for real-time dynamic performance. Most existing models, however, suffer from
computational inefficiency and complex parameter identification, limiting their
real-time applicability. To address this, we propose a paradigm coupling
Pseudo-Rigid Body Modeling with the Logarithmic Decrement Method for parameter
estimation (PRBM plus LDM). Using a soft robotic hand test bed, we validate
PRBM plus LDM for predicting position and force output from pressure input and
benchmark its performance. We then implement PRBM plus LDM as the basis for
closed-loop position and force controllers. Compared to a simple PID
controller, the PRBM plus LDM position controller achieves lower error (average
maximum error across all fingers: 4.37 degrees versus 20.38 degrees). For force
control, PRBM plus LDM outperforms constant pressure grasping in pinching tasks
on delicate objects: potato chip 86 versus 82.5, screwdriver 74.42 versus 70,
brass coin 64.75 versus 35. These results demonstrate PRBM plus LDM as a
computationally efficient and accurate modeling technique for soft actuators,
enabling stable and flexible grasping with precise force regulation.

</details>


### [394] [Novel bio-inspired soft actuators for upper-limb exoskeletons: design, fabrication and feasibility study](https://arxiv.org/abs/2509.01145)
*Haiyun Zhang,Gabrielle Naquila,Jung Hyun Bae,Zonghuan Wu,Ashwin Hingwe,Ashish Deshpande*

Main category: cs.RO

TL;DR: 本研究提出了一种用于神经运动障碍患者上肢康复的软体驱动器设计范例，包括用于肘部的 LISPER 和用于肩部的 SCASPER。LISPER 具有高带宽、高输出力和高线性度，而 SCASPER 具有高输出力和简化的制造工艺。研究还提出了分析模型来描述压力、弯曲角度和输出力之间的关系，并进行了初步测试。


<details>
  <summary>Details</summary>
Motivation: 现有用于康复的软体机器人存在响应慢、运动范围受限、输出力低等问题，且对可穿戴软体驱动器的精确位置和力控制研究有限，同时对于波纹管结构驱动器对机器人能力Quantitative贡献的阐述不足。

Method: 提出上肢软体驱动器设计范例，包括用于肘部的 LISPER（龙虾启发硅胶气动机器人）和用于肩部的 SCASPER（扇贝形气动机器人）。对 LISPER 和 SCASPER 分别进行了分析模型研究，以描述压力、弯曲角度和输出力之间的关系，并进行了在假肢臂上的初步测试。

Result: LISPER 表现出更高的带宽、增加的输出力和力/力矩，以及高线性度。SCASPER 表现出高输出力和力/力矩，并简化了制造工艺。通过分析模型，可以调整驱动器的几何结构来改变运动范围和输出力。

Conclusion: 所提出的上肢软体驱动器设计范例（LISPER 和 SCASPER）在康复应用中具有潜力，能够改善现有软体机器人的局限性，并通过分析模型为驱动器的设计和性能优化提供了指导。

Abstract: Soft robots have been increasingly utilized as sophisticated tools in
physical rehabilitation, particularly for assisting patients with neuromotor
impairments. However, many soft robotics for rehabilitation applications are
characterized by limitations such as slow response times, restricted range of
motion, and low output force. There are also limited studies on the precise
position and force control of wearable soft actuators. Furthermore, not many
studies articulate how bellow-structured actuator designs quantitatively
contribute to the robots' capability. This study introduces a paradigm of upper
limb soft actuator design. This paradigm comprises two actuators: the
Lobster-Inspired Silicone Pneumatic Robot (LISPER) for the elbow and the
Scallop-Shaped Pneumatic Robot (SCASPER) for the shoulder. LISPER is
characterized by higher bandwidth, increased output force/torque, and high
linearity. SCASPER is characterized by high output force/torque and simplified
fabrication processes. Comprehensive analytical models that describe the
relationship between pressure, bending angles, and output force for both
actuators were presented so the geometric configuration of the actuators can be
set to modify the range of motion and output forces. The preliminary test on a
dummy arm is conducted to test the capability of the actuators.

</details>


### [395] [OpenMulti: Open-Vocabulary Instance-Level Multi-Agent Distributed Implicit Mapping](https://arxiv.org/abs/2509.01228)
*Jianyu Dou,Yinan Deng,Jiahui Wang,Xingsi Tang,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: OpenMulti是一个开放词汇、实例级别、多智能体分布式隐式建图框架，解决了现有方法在实例级感知和语义理解方面的不足，通过跨智能体实例对齐和跨渲染监督来提升建图精度和语义理解能力，并在实例级检索任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多智能体协作建图方面缺乏实例级感知和语义理解能力，限制了其在下游应用中的效果。

Method: 提出OpenMulti框架，包含跨智能体实例对齐模块（构建实例协作图）和跨渲染监督，以解决建图精度下降和盲区优化陷阱问题。

Result: 实验结果表明，OpenMulti在细粒度几何精度和零样本语义精度方面优于相关算法，并支持实例级检索任务。

Conclusion: OpenMulti通过实例级感知和语义理解，提升了多智能体分布式协作建图的性能，并能为下游应用提供语义标注。

Abstract: Multi-agent distributed collaborative mapping provides comprehensive and
efficient representations for robots. However, existing approaches lack
instance-level awareness and semantic understanding of environments, limiting
their effectiveness for downstream applications. To address this issue, we
propose OpenMulti, an open-vocabulary instance-level multi-agent distributed
implicit mapping framework. Specifically, we introduce a Cross-Agent Instance
Alignment module, which constructs an Instance Collaborative Graph to ensure
consistent instance understanding across agents. To alleviate the degradation
of mapping accuracy due to the blind-zone optimization trap, we leverage Cross
Rendering Supervision to enhance distributed learning of the scene.
Experimental results show that OpenMulti outperforms related algorithms in both
fine-grained geometric accuracy and zero-shot semantic accuracy. In addition,
OpenMulti supports instance-level retrieval tasks, delivering semantic
annotations for downstream applications. The project website of OpenMulti is
publicly available at https://openmulti666.github.io/.

</details>


### [396] [Towards Data-Driven Metrics for Social Robot Navigation Benchmarking](https://arxiv.org/abs/2509.01251)
*Pilar Bachiller-Burgos,Ulysses Bernardet,Luis V. Calderita,Pranup Chhetri,Anthony Francis,Noriaki Hirose,Noé Pérez,Dhruv Shah,Phani T. Singamaneni,Xuesu Xiao,Luis J. Manso*

Main category: cs.RO

TL;DR: 本文提出了一种数据驱动的社交机器人导航指标，用于促进基准测试和策略优化。


<details>
  <summary>Details</summary>
Motivation: 为了促进基准测试和策略优化，需要开发一种数据驱动的社交机器人导航指标。

Method: 收集了包含4427条轨迹（182条真实，4245条模拟）的数据集，并由人类评分者进行评估，经过数据质量保证后得到4402条评分轨迹。在此基础上，训练了一个基于RNN的基线指标模型。

Result: 展示了使用RNN模型在数据集上训练的量化和质性结果。

Conclusion: 发布了所有数据、软件和模型权重，以供公开使用。

Abstract: This paper presents a joint effort towards the development of a data-driven
Social Robot Navigation metric to facilitate benchmarking and policy
optimization. We provide our motivations for our approach and describe our
proposal for storing rated social navigation trajectory datasets. Following
these guidelines, we compiled a dataset with 4427 trajectories -- 182 real and
4245 simulated -- and presented it to human raters, yielding a total of 4402
rated trajectories after data quality assurance. We also trained an RNN-based
baseline metric on the dataset and present quantitative and qualitative
results. All data, software, and model weights are publicly available.

</details>


### [397] [Toward a Holistic Multi-Criteria Trajectory Evaluation Framework for Autonomous Driving in Mixed Traffic Environment](https://arxiv.org/abs/2509.01291)
*Nouhed Naidja,Stéphane Font,Marc Revilloud,Guillaume Sandou*

Main category: cs.RO

TL;DR: 该论文提出了一个统一的框架来评估和优化自动驾驶汽车的轨迹，整合了形式安全、舒适性和效率标准。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为自动驾驶汽车的轨迹评估和优化提供一个统一的框架，解决安全、舒适和效率等关键问题。

Method: 该论文使用一种新颖的几何指标，基于自适应椭圆的安全区域分析来量化碰撞风险，并应用鞋带公式计算不对齐和时变配置下的交集区域。舒适性通过纵向和横向加加速度指标来衡量，效率则通过总旅行时间评估。这些标准被整合到一个综合性目标函数中，并使用基于粒子群优化（PSO）的算法进行求解。

Result: 该方法在真实交通条件下得到了成功验证，包括在城市交叉口进行的涉及自动驾驶汽车与人类驾驶汽车交互的实验，以及在模拟中使用真实交通中的人类驾驶数据进行的实验。

Conclusion: 该统一框架能够有效地评估和优化自动驾驶汽车的轨迹，并成功验证了其在真实交通场景下的有效性。

Abstract: This paper presents a unified framework for the evaluation and optimization
of autonomous vehicle trajectories, integrating formal safety, comfort, and
efficiency criteria. An innovative geometric indicator, based on the analysis
of safety zones using adaptive ellipses, is used to accurately quantify
collision risks. Our method applies the Shoelace formula to compute the
intersection area in the case of misaligned and time-varying configurations.
Comfort is modeled using indicators centered on longitudinal and lateral jerk,
while efficiency is assessed by overall travel time. These criteria are
aggregated into a comprehensive objective function solved using a PSO based
algorithm. The approach was successfully validated under real traffic
conditions via experiments conducted in an urban intersection involving an
autonomous vehicle interacting with a human-operated vehicle, and in simulation
using data recorded from human driving in real traffic.

</details>


### [398] [Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning](https://arxiv.org/abs/2509.01297)
*Seonsoo Kim,Jun-Gill Kang,Taehong Kim,Seongil Hong*

Main category: cs.RO

TL;DR: 提出一种解耦多上下文元学习框架，将每个任务因子分配给不同的上下文向量，以提高鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的元学习方法依赖于隐式适应任务变化，将多个因素混合在一个纠缠的表示中，难以解释哪些因素驱动性能并阻碍泛化。

Method: 通过显式地将每个任务因子分配给一个不同的上下文向量来解耦这些变化。

Result: 在正弦回归任务和四足机器人运动任务中，我们的模型均优于基线模型，并在分布外任务和条件下表现出更强的鲁棒性和泛化能力，特别是通过上下文向量共享实现了这一点。

Conclusion: 该框架通过解耦任务因子，可以深入理解任务，提高鲁棒性，并通过共享上下文向量增强泛化能力，在机器人 locomotion 任务中通过 sim-to-real 传输验证了其有效性。

Abstract: In meta-learning and its downstream tasks, many methods rely on implicit
adaptation to task variations, where multiple factors are mixed together in a
single entangled representation. This makes it difficult to interpret which
factors drive performance and can hinder generalization. In this work, we
introduce a disentangled multi-context meta-learning framework that explicitly
assigns each task factor to a distinct context vector. By decoupling these
variations, our approach improves robustness through deeper task understanding
and enhances generalization by enabling context vector sharing across tasks
with shared factors. We evaluate our approach in two domains. First, on a
sinusoidal regression task, our model outperforms baselines on
out-of-distribution tasks and generalizes to unseen sine functions by sharing
context vectors associated with shared amplitudes or phase shifts. Second, in a
quadruped robot locomotion task, we disentangle the robot-specific properties
and the characteristics of the terrain in the robot dynamics model. By
transferring disentangled context vectors acquired from the dynamics model into
reinforcement learning, the resulting policy achieves improved robustness under
out-of-distribution conditions, surpassing the baselines that rely on a single
unified context. Furthermore, by effectively sharing context, our model enables
successful sim-to-real policy transfer to challenging terrains with
out-of-distribution robot-specific properties, using just 20 seconds of real
data from flat terrain, a result not achievable with single-task adaptation.

</details>


### [399] [TopoNav: Topological Graphs as a Key Enabler for Advanced Object Navigation](https://arxiv.org/abs/2509.01364)
*Peiran Liu,Qiang Zhang,Daojie Peng,Lingfeng Zhang,Yihao Qin,Hang Zhou,Jun Ma,Renjing Xu,Yiding Ji*

Main category: cs.RO

TL;DR: TopoNav利用拓扑结构作为空间记忆来解决大型语言模型在物体导航中的内存管理挑战，在长时程任务和动态场景中表现优异，并在基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在物体导航（ObjectNav）任务中虽然取得了显著进展，但在内存管理方面仍面临挑战，尤其是在长时程任务和动态场景中。

Method: 提出了一种名为TopoNav的新框架，该框架利用拓扑结构作为空间记忆。通过构建和更新一个捕获场景连接、邻近性和语义意义的拓扑图，TopoNav帮助智能体随着时间的推移积累空间知识，检索关键信息，并有效地推理到远距离目标。

Result: 实验结果表明，TopoNav在基准ObjectNav数据集上实现了最先进的性能，具有更高的成功率和更有效的路径。它特别擅长处理多样化和复杂化的环境，因为它将临时的视觉输入与持久的空间理解联系起来。

Conclusion: TopoNav通过利用拓扑结构作为空间记忆，成功地解决了物体导航中的内存管理问题，并在各种环境中取得了优越的性能。

Abstract: Object Navigation (ObjectNav) has made great progress with large language
models (LLMs), but still faces challenges in memory management, especially in
long-horizon tasks and dynamic scenes. To address this, we propose TopoNav, a
new framework that leverages topological structures as spatial memory. By
building and updating a topological graph that captures scene connections,
adjacency, and semantic meaning, TopoNav helps agents accumulate spatial
knowledge over time, retrieve key information, and reason effectively toward
distant goals. Our experiments show that TopoNav achieves state-of-the-art
performance on benchmark ObjectNav datasets, with higher success rates and more
efficient paths. It particularly excels in diverse and complex environments, as
it connects temporary visual inputs with lasting spatial understanding.

</details>


### [400] [Analyzing Reluctance to Ask for Help When Cooperating With Robots: Insights to Integrate Artificial Agents in HRC](https://arxiv.org/abs/2509.01450)
*Ane San Martin,Michael Hagenow,Julie Shah,Johan Kildal,Elena Lazkano*

Main category: cs.RO

TL;DR: 本研究旨在识别未来用户辅助代理的设计要点，通过分析人机协作（HRC）装配任务中远程人类提供的即时援助的用户研究数据。研究评估了用户在需要帮助时请求和接收援助的体验，并探讨了用户对未来非人类辅助代理的看法，以及援助应为即时提供还是主动提供。研究通过用户体验数据分析了这些设计决策（人类或人工智能助手，即时或主动帮助）对用户情绪反应、生产力和HRC任务偏好的影响。


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术的发展，人机协作在工业任务中将更加普遍。当人类在这些场景中遇到问题时，未来可能会依靠人工智能代理或机器人寻求帮助。本研究旨在识别未来用户辅助代理的设计要点。

Method: 通过一项用户研究，分析了在人机协作（HRC）装配任务中，远程人类提供的即时援助对用户的影响。研究了用户需要帮助的情景，评估了他们请求和接收援助的体验。此外，还研究了参与者对未来非人类辅助代理的看法，以及援助应该是即时提供还是主动提供。通过用户研究，分析了这些设计决策（人类或人工智能助手，即时或主动帮助）对用户情绪反应、生产力和HRC任务偏好的影响。

Result: 本研究通过用户研究，收集了定性和定量数据，分析了在人机协作装配任务中，远程人类提供的即时援助对用户体验的影响，以及用户对未来非人类辅助代理的看法和对援助方式（即时或主动）的偏好。

Conclusion: 本研究的分析结果将为设计未来的人机协作系统提供指导，特别是在用户需要帮助时，如何有效地提供援助，以及如何选择合适的助手（人类或人工智能）和援助方式（即时或主动），以优化用户体验、提高生产力并满足用户偏好。

Abstract: As robot technology advances, collaboration between humans and robots will
become more prevalent in industrial tasks. When humans run into issues in such
scenarios, a likely future involves relying on artificial agents or robots for
aid. This study identifies key aspects for the design of future user-assisting
agents. We analyze quantitative and qualitative data from a user study
examining the impact of on-demand assistance received from a remote human in a
human-robot collaboration (HRC) assembly task. We study scenarios in which
users require help and we assess their experiences in requesting and receiving
assistance. Additionally, we investigate participants' perceptions of future
non-human assisting agents and whether assistance should be on-demand or
unsolicited. Through a user study, we analyze the impact that such design
decisions (human or artificial assistant, on-demand or unsolicited help) can
have on elicited emotional responses, productivity, and preferences of humans
engaged in HRC tasks.

</details>


### [401] [FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field](https://arxiv.org/abs/2509.01547)
*Fan Zhu,Yifan Zhao,Ziyu Chen,Biao Yu,Hui Zhu*

Main category: cs.RO

TL;DR: FGO-SLAM是一种基于3D高斯混合模型（3D Gaussian）的SLAM系统，通过引入不透明度辐射场（opacity radiance field）和全局位姿优化，提高了几何重建的精度和场景映射的质量，并在各种数据集上取得了先进的跟踪精度和映射性能。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法在场景重建质量上存在不足，而高斯SLAM系统虽然渲染速度快、映射质量高，但在位姿优化和几何重建方面存在挑战。因此，需要一种能够提高几何映射性能并优化位姿的方法。

Method: 1. 使用不透明度辐射场作为场景表示，以增强几何映射性能。
2. 在初始位姿估计后，进行全局调整以优化相机位姿和稀疏点云。
3. 基于3D高斯混合模型维护全局一致的不透明度辐射场。
4. 引入深度畸变和法线一致性约束来优化场景表示。
5. 构建四面体网格，识别水平集以直接从3D高斯混合模型中提取表面。

Result: 在各种真实世界和大规模合成数据集上的实验表明，该方法实现了先进的跟踪精度和映射性能。

Conclusion: FGO-SLAM通过改进的场景表示和全局位姿优化，有效解决了传统SLAM和高斯SLAM在几何重建和位姿优化方面的不足，并在各种场景下取得了优越的性能。

Abstract: Visual SLAM has regained attention due to its ability to provide perceptual
capabilities and simulation test data for Embodied AI. However, traditional
SLAM methods struggle to meet the demands of high-quality scene reconstruction,
and Gaussian SLAM systems, despite their rapid rendering and high-quality
mapping capabilities, lack effective pose optimization methods and face
challenges in geometric reconstruction. To address these issues, we introduce
FGO-SLAM, a Gaussian SLAM system that employs an opacity radiance field as the
scene representation to enhance geometric mapping performance. After initial
pose estimation, we apply global adjustment to optimize camera poses and sparse
point cloud, ensuring robust tracking of our approach. Additionally, we
maintain a globally consistent opacity radiance field based on 3D Gaussians and
introduce depth distortion and normal consistency terms to refine the scene
representation. Furthermore, after constructing tetrahedral grids, we identify
level sets to directly extract surfaces from 3D Gaussians. Results across
various real-world and large-scale synthetic datasets demonstrate that our
method achieves state-of-the-art tracking accuracy and mapping performance.

</details>


### [402] [Aleatoric Uncertainty from AI-based 6D Object Pose Predictors for Object-relative State Estimation](https://arxiv.org/abs/2509.01583)
*Thomas Jantos,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 深度学习（DL）在机器人学中至关重要，但其预测的6D物体姿态的不确定性需要被量化，以用于概率状态估计。本研究提出一种简单的方法，通过增加两个多层感知器（MLP）来扩展现有的DL姿态预测器，以推断不确定性。这种方法允许在冻结预训练预测器的情况下进行高效训练。


<details>
  <summary>Details</summary>
Motivation: 为了提高基于DL的机器人状态估计任务的性能，需要准确量化DL预测的6D物体姿态的不确定性，以便概率状态估计器能够利用这些信息。

Method: 通过在现有的DL姿态预测器中添加两个独立的MLP来推断不确定性，这两个MLP分别处理平移和旋转部分。这种方法允许冻结预训练的预测器进行高效训练。

Result: 与固定协方差的方法相比，该方法将不确定性推断和6D姿态估计结合起来，计算开销小，并提高了物体相对状态估计任务的性能，该方法在合成数据和真实世界数据上都得到了验证。

Conclusion: 提出的不确定性推断方法可以有效地集成到现有的DL姿态预测器中，并能提高机器人状态估计任务的性能，该方法计算开销小，适合部署在边缘设备上。

Abstract: Deep Learning (DL) has become essential in various robotics applications due
to excelling at processing raw sensory data to extract task specific
information from semantic objects. For example, vision-based object-relative
navigation relies on a DL-based 6D object pose predictor to provide the
relative pose between the object and the robot as measurements to the robot's
state estimator. Accurately knowing the uncertainty inherent in such Deep
Neural Network (DNN) based measurements is essential for probabilistic state
estimators subsequently guiding the robot's tasks. Thus, in this letter, we
show that we can extend any existing DL-based object-relative pose predictor
for aleatoric uncertainty inference simply by including two multi-layer
perceptrons detached from the translational and rotational part of the DL
predictor. This allows for efficient training while freezing the existing
pre-trained predictor. We then use the inferred 6D pose and its uncertainty as
a measurement and corresponding noise covariance matrix in an extended Kalman
filter (EKF). Our approach induces minimal computational overhead such that the
state estimator can be deployed on edge devices while benefiting from the
dynamically inferred measurement uncertainty. This increases the performance of
the object-relative state estimation task compared to a fix-covariance
approach. We conduct evaluations on synthetic data and real-world data to
underline the benefits of aleatoric uncertainty inference for the
object-relative state estimation task.

</details>


### [403] [A Hybrid Input based Deep Reinforcement Learning for Lane Change Decision-Making of Autonomous Vehicle](https://arxiv.org/abs/2509.01611)
*Ziteng Gao,Jiaqi Qu,Chaoyu Chen*

Main category: cs.RO

TL;DR: 本篇论文提出了一种基于混合输入的深度强化学习（DRL）算法，用于在车流中为自动驾驶车辆实现抽象的车道变换决策和车道变换动作。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的车道变换决策是复杂但有益的行为。

Method: 1. 提出一种环绕车辆轨迹预测方法，并将预测结果作为额外信息输入强化学习模型。 2. 模型同时提取高维图像和低维传感器数据的特征。 3. 将环绕车辆轨迹预测和多模态信息融合作为强化学习的状态空间。 4. 集成强化学习宏观决策和端到端车辆控制，实现完整的车道变换过程。

Result: 在CARLA模拟器中进行的实验结果表明，使用混合状态空间能够显著提高车辆车道变换决策的安全性。

Conclusion: 通过融合轨迹预测和多模态信息，能够提高车道变换决策的合理性，并且混合状态空间显著增强了车辆车道变换决策的安全性。

Abstract: Lane change decision-making for autonomous vehicles is a complex but
high-reward behavior. In this paper, we propose a hybrid input based deep
reinforcement learning (DRL) algorithm, which realizes abstract lane change
decisions and lane change actions for autonomous vehicles within traffic flow.
Firstly, a surrounding vehicles trajectory prediction method is proposed to
reduce the risk of future behavior of surrounding vehicles to ego vehicle, and
the prediction results are input into the reinforcement learning model as
additional information. Secondly, to comprehensively leverage environmental
information, the model extracts feature from high-dimensional images and
low-dimensional sensor data simultaneously. The fusion of surrounding vehicle
trajectory prediction and multi-modal information are used as state space of
reinforcement learning to improve the rationality of lane change decision.
Finally, we integrate reinforcement learning macro decisions with end-to-end
vehicle control to achieve a holistic lane change process. Experiments were
conducted within the CARLA simulator, and the results demonstrated that the
utilization of a hybrid state space significantly enhances the safety of
vehicle lane change decisions.

</details>


### [404] [Speculative Design of Equitable Robotics: Queer Fictions and Futures](https://arxiv.org/abs/2509.01643)
*Minja Axelsson*

Main category: cs.RO

TL;DR: 本文探讨了由LGBTQ+群体创造和服务的机器人的未来，提出了三种设想：反映用户身份的机器人、通过身份表演减少偏见的机器人以及促进LGBTQ+社区联系和资源共享的机器人网络。


<details>
  <summary>Details</summary>
Motivation: 本文旨在引发关于未来机器人技术如何服务于LGBTQ+群体的思考和讨论，探索在艺术和科学领域中“酷儿机器人”的可能性。

Method: 本文采用了探索性论文的形式，首先回顾了酷儿机器人相关的虚构和科学现状，然后提出了三个具体的酷儿机器人设想（反映身份、互动表演、社群网络），并探讨了相关的伦理问题和未来发展方向。

Result: 文章提出了三种服务于LGBTQ+群体的机器人设想，并讨论了其潜在的积极影响（如增强身份认同、减少偏见、促进社群联系）以及相关的伦理考量。

Conclusion: 文章总结了未来酷儿机器人发展的可能性，并指出了实现这些愿景所需满足的条件，强调了在机器人技术中拥抱和体现“酷儿”特质的重要性。

Abstract: This paper examines the speculative topic of equitable robots through an
exploratory essay format. It focuses specifically on robots by and for LGBTQ+
populations. It aims to provoke thought and conversations in the field about
what aspirational queer robotics futures may look like, both in the arts and
sciences. First, it briefly reviews the state-of-the-art of queer robotics in
fiction and science, drawing together threads from each. Then, it discusses
queering robots through three speculative design proposals for queer robot
roles: 1) reflecting the queerness of their ''in-group'' queer users, building
and celebrating ''in-group'' identity, 2) a new kind of queer activism by
implementing queer robot identity performance to interact with ''out-group''
users, with a goal of reducing bigotry through familiarisation, and 3) a
network of queer-owned robots, through which the community could reach each
other, and distribute and access important resources. The paper then questions
whether robots should be queered, and what ethical implications this raises.
Finally, the paper makes suggestions for what aspirational queer robotics
futures may look like, and what would be required to get there.

</details>


### [405] [Data Retrieval with Importance Weights for Few-Shot Imitation Learning](https://arxiv.org/abs/2509.01657)
*Amber Xie,Rahul Chand,Dorsa Sadigh,Joey Hejna*

Main category: cs.RO

TL;DR: 检索增强模仿学习通过从大型先验数据集中提取相关样本来增强有限的演示数据集，但现有方法存在缺点。为解决此问题，提出了一种新的基于重要性加权检索（IWR）的方法，通过使用高斯核密度估计（KDE）来估计目标和先验数据分布的比例，从而改进了数据选择。实验证明，IWR 在模拟和现实世界环境中均能提高现有检索方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索式模仿学习方法在从大型先验数据集中选择相关样本以增强有限演示数据集时，依赖于易受噪声影响的高方差最近邻估计，并且没有考虑先验数据的分布。

Method: 提出了一种名为重要性加权检索（IWR）的新方法，该方法使用高斯核密度估计（KDE）来估计目标数据和先验数据分布的比例（即重要性权重），从而改进数据检索过程。

Result: IWR 方法在模拟环境和现实世界（Bridge 数据集）的评估中，一致地提高了现有检索方法的性能。

Conclusion: IWR 通过估计目标和先验数据分布的比例来改进检索过程，解决了现有检索方法的缺点，并能有效平滑估计，从而提高模仿学习的性能。

Abstract: While large-scale robot datasets have propelled recent progress in imitation
learning, learning from smaller task specific datasets remains critical for
deployment in new environments and unseen tasks. One such approach to few-shot
imitation learning is retrieval-based imitation learning, which extracts
relevant samples from large, widely available prior datasets to augment a
limited demonstration dataset. To determine the relevant data from prior
datasets, retrieval-based approaches most commonly calculate a prior data
point's minimum distance to a point in the target dataset in latent space.
While retrieval-based methods have shown success using this metric for data
selection, we demonstrate its equivalence to the limit of a Gaussian kernel
density (KDE) estimate of the target data distribution. This reveals two
shortcomings of the retrieval rule used in prior work. First, it relies on
high-variance nearest neighbor estimates that are susceptible to noise. Second,
it does not account for the distribution of prior data when retrieving data. To
address these issues, we introduce Importance Weighted Retrieval (IWR), which
estimates importance weights, or the ratio between the target and prior data
distributions for retrieval, using Gaussian KDEs. By considering the
probability ratio, IWR seeks to mitigate the bias of previous selection rules,
and by using reasonable modeling parameters, IWR effectively smooths estimates
using all data points. Across both simulation environments and real-world
evaluations on the Bridge dataset we find that our method, IWR, consistently
improves performance of existing retrieval-based methods, despite only
requiring minor modifications.

</details>


### [406] [MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation](https://arxiv.org/abs/2509.01658)
*Zhenyu Wu,Angyuan Ma,Xiuwei Xu,Hang Yin,Yinan Liang,Ziwei Wang,Jiwen Lu,Haibin Yan*

Main category: cs.RO

TL;DR: MoTo是一个模块，可以为操纵基础模型提供移动操纵能力，通过交互感知导航策略和交互关键点框架，实现了零样本移动操纵。


<details>
  <summary>Details</summary>
Motivation: 当前的移动操纵方法在不同任务和环境中泛化能力有限，而基于操纵基础模型的方法仅限于固定设置。需要一种能将固定基础操纵模型扩展到移动操纵的方法。

Method: 提出一个名为MoTo的即插即用模块，包含交互感知导航策略以生成机器人停靠点。设计了一个通过视觉语言模型（VLM）在多视图一致性下实现的交互关键点框架，用于目标物体和机械臂跟踪指令。提出最小化关键点距离和保持轨迹可行性的运动规划目标，用于移动基座和机械臂。

Result: 在OVMM和真实世界实验中，MoTo的成功率分别比最先进的移动操纵方法高2.68%和16.67%，且无需额外的训练数据。

Conclusion: MoTo成功地将固定基础操纵模型扩展到移动操纵领域，通过零样本学习实现了高效的移动操纵，并在实验中证明了其优越性。

Abstract: Mobile manipulation stands as a core challenge in robotics, enabling robots
to assist humans across varied tasks and dynamic daily environments.
Conventional mobile manipulation approaches often struggle to generalize across
different tasks and environments due to the lack of large-scale training.
However, recent advances in manipulation foundation models demonstrate
impressive generalization capability on a wide range of fixed-base manipulation
tasks, which are still limited to a fixed setting. Therefore, we devise a
plug-in module named MoTo, which can be combined with any off-the-shelf
manipulation foundation model to empower them with mobile manipulation ability.
Specifically, we propose an interaction-aware navigation policy to generate
robot docking points for generalized mobile manipulation. To enable zero-shot
ability, we propose an interaction keypoints framework via vision-language
models (VLM) under multi-view consistency for both target object and robotic
arm following instructions, where fixed-base manipulation foundation models can
be employed. We further propose motion planning objectives for the mobile base
and robot arm, which minimize the distance between the two keypoints and
maintain the physical feasibility of trajectories. In this way, MoTo guides the
robot to move to the docking points where fixed-base manipulation can be
successfully performed, and leverages VLM generation and trajectory
optimization to achieve mobile manipulation in a zero-shot manner, without any
requirement on mobile manipulation expert data. Extensive experimental results
on OVMM and real-world demonstrate that MoTo achieves success rates of 2.68%
and 16.67% higher than the state-of-the-art mobile manipulation methods,
respectively, without requiring additional training data.

</details>


### [407] [Articulated Object Estimation in the Wild](https://arxiv.org/abs/2509.01708)
*Abdelrhman Werby,Martin Büchner,Adrian Röfer,Chenguang Huang,Wolfram Burgard,Abhinav Valada*

Main category: cs.RO

TL;DR:  ArtiPoint是一个新的框架，通过结合深度点跟踪和因子图优化，可以从原始RGB-D视频中估计出动态相机运动和部分可观察情况下的关节物体模型、关节轨迹和关节轴。此外，还引入了一个名为Arti4D的新数据集，用于在该领域进行未来研究。


<details>
  <summary>Details</summary>
Motivation: 研究在不受限制的环境中（例如动态相机运动和部分可观察性）推断关节物体模型，这是机器人场景理解、移动操作和运动规划的关键，也是对先前主要关注受控环境方法的改进。

Method:  ArtiPoint框架结合了深度点跟踪和因子图优化，以从原始RGB-D视频中估计关节物体模型、关节轨迹和关节轴。

Result:  ArtiPoint在Arti4D数据集上表现优于一系列经典和基于学习的方法，证明了其稳健性和优越性。

Conclusion:  ArtiPoint框架和Arti4D数据集为在动态和部分可观察的条件下研究关节物体提供了新的解决方案和资源，有望推动机器人技术在该领域的发展。

Abstract: Understanding the 3D motion of articulated objects is essential in robotic
scene understanding, mobile manipulation, and motion planning. Prior methods
for articulation estimation have primarily focused on controlled settings,
assuming either fixed camera viewpoints or direct observations of various
object states, which tend to fail in more realistic unconstrained environments.
In contrast, humans effortlessly infer articulation by watching others
manipulate objects. Inspired by this, we introduce ArtiPoint, a novel
estimation framework that can infer articulated object models under dynamic
camera motion and partial observability. By combining deep point tracking with
a factor graph optimization framework, ArtiPoint robustly estimates articulated
part trajectories and articulation axes directly from raw RGB-D videos. To
foster future research in this domain, we introduce Arti4D, the first
ego-centric in-the-wild dataset that captures articulated object interactions
at a scene level, accompanied by articulation labels and ground-truth camera
poses. We benchmark ArtiPoint against a range of classical and learning-based
baselines, demonstrating its superior performance on Arti4D. We make code and
Arti4D publicly available at https://artipoint.cs.uni-freiburg.de.

</details>


### [408] [Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference](https://arxiv.org/abs/2509.01746)
*Yixuan Huang,Novella Alvina,Mohanraj Devendran Shanthi,Tucker Hermans*

Main category: cs.RO

TL;DR: 机器人需要从失败中学习以提高在训练数据分布之外的条件下的表现。Fail2Progress 使用 Stein 变分推理来生成针对观察到的失败而设计的模拟环境，从而高效地收集数据，使机器人能够从失败中恢复并最大限度地减少未来失败。该方法在多项具有挑战性的机器人操作任务中表现出色，并且优于其他基线方法。


<details>
  <summary>Details</summary>
Motivation: Skill effect models for long-horizon manipulation tasks are prone to failures in conditions not covered by training data distributions. Therefore, enabling robots to reason about and learn from failures is necessary.

Method: We propose Fail2Progress, an approach that leverages Stein variational inference to generate multiple simulation environments in parallel, enabling efficient data sample generation similar to observed failures.

Result: Our method is capable of handling several challenging mobile manipulation tasks, including transporting multiple objects, organizing a constrained shelf, and tabletop organization. Through large-scale simulation and real-world experiments, we demonstrate that our approach excels at learning from failures across different numbers of objects. Furthermore, we show that Fail2Progress outperforms several baselines.

Conclusion: Fail2Progress enables robots to learn from failures, improving their performance in conditions not seen during training and outperforming existing methods.

Abstract: Skill effect models for long-horizon manipulation tasks are prone to failures
in conditions not covered by training data distributions. Therefore, enabling
robots to reason about and learn from failures is necessary. We investigate the
problem of efficiently generating a dataset targeted to observed failures.
After fine-tuning a skill effect model on this dataset, we evaluate the extent
to which the model can recover from failures and minimize future failures. We
propose Fail2Progress, an approach that leverages Stein variational inference
to generate multiple simulation environments in parallel, enabling efficient
data sample generation similar to observed failures. Our method is capable of
handling several challenging mobile manipulation tasks, including transporting
multiple objects, organizing a constrained shelf, and tabletop organization.
Through large-scale simulation and real-world experiments, we demonstrate that
our approach excels at learning from failures across different numbers of
objects. Furthermore, we show that Fail2Progress outperforms several baselines.

</details>


### [409] [Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control](https://arxiv.org/abs/2509.01765)
*Skand Peri,Akhil Perincherry,Bikram Pandit,Stefan Lee*

Main category: cs.RO

TL;DR: 提出一种无需超参数即可最小化机器人能耗的梯度优化方法，以避免在任务性能和能耗之间进行权衡，该方法通过在任务和能耗目标之间进行策略梯度投影来实现，并在 DM-Control 和 HumanoidBench 的标准运动基准上进行了评估，能耗降低了 64%，同时保持了可比的任务性能。


<details>
  <summary>Details</summary>
Motivation: 在强化学习（RL）中，需要在任务性能和能量消耗之间进行平衡，通常通过在奖励函数中直接惩罚能量使用来实现，但这需要仔细调整权重以避免不良的权衡。

Method: 提出一种无需超参数的梯度优化方法，通过在任务和能量目标之间进行策略梯度投影，推导出最小化能量消耗且不影响任务性能的策略更新。

Result: 在 DM-Control 和 HumanoidBench 的标准运动基准上，能耗降低了 64%，同时保持了可比的任务性能。并在 Unitree GO2 四足机器人上进行了 Sim2Real 迁移实验。

Conclusion: 所提出的方法易于在标准 RL 管道中实现，只需最少的代码更改，适用于任何策略梯度方法，并为能耗控制策略提供了一种原则性的替代奖励塑造的方法。

Abstract: Efficient robot control often requires balancing task performance with energy
expenditure. A common approach in reinforcement learning (RL) is to penalize
energy use directly as part of the reward function. This requires carefully
tuning weight terms to avoid undesirable trade-offs where energy minimization
harms task success. In this work, we propose a hyperparameter-free gradient
optimization method to minimize energy expenditure without conflicting with
task performance. Inspired by recent works in multitask learning, our method
applies policy gradient projection between task and energy objectives to derive
policy updates that minimize energy expenditure in ways that do not impact task
performance. We evaluate this technique on standard locomotion benchmarks of
DM-Control and HumanoidBench and demonstrate a reduction of 64% energy usage
while maintaining comparable task performance. Further, we conduct experiments
on a Unitree GO2 quadruped showcasing Sim2Real transfer of energy efficient
policies. Our method is easy to implement in standard RL pipelines with minimal
code changes, is applicable to any policy gradient method, and offers a
principled alternative to reward shaping for energy efficient control policies.

</details>


### [410] [ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training](https://arxiv.org/abs/2509.01819)
*Ge Yan,Jiyue Zhu,Yuquan Deng,Shiqi Yang,Ri-Zhao Qiu,Xuxin Cheng,Marius Memmel,Ranjay Krishna,Ankit Goyal,Xiaolong Wang,Dieter Fox*

Main category: cs.RO

TL;DR: ManiFlow是一种用于通用机器人操作的视觉模仿学习策略，能够根据视觉、语言和本体感觉输入生成高维动作。它使用流匹配和一致性训练，在1-2个推理步骤中实现高精度的灵巧动作生成。DiT-X架构通过自适应交叉注意力和AdaLN-Zero条件，实现了多模态特征的精细交互。ManiFlow在模拟和现实世界任务中均表现出色，尤其是在单臂、双臂和人形机器人设置中，成功率几乎翻倍，并展现出对新物体和背景变化的鲁棒性与泛化能力。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够处理多种输入（视觉、语言、本体感觉）并生成高精度、高维动作的机器人操作模仿学习策略，以提高机器人执行复杂任务的能力。

Method: 提出ManiFlow，一种基于流匹配和一致性训练的视觉模仿学习策略。设计了DiT-X架构，一种具有自适应交叉注意力和AdaLN-Zero条件的扩散Transformer，以有效处理多模态输入并实现精细的特征交互。

Result: ManiFlow在各种模拟基准测试中持续改进，在单臂、双臂和人形机器人设置中，成功率几乎翻倍。实验证明了ManiFlow对新物体和背景变化的鲁棒性、泛化能力以及在大规模数据集上的扩展能力。

Conclusion: ManiFlow是一种有效的模仿学习策略，能够处理多模态输入并生成高精度的机器人操作动作，在各种机器人设置和任务中展现出优越的性能和泛化能力。

Abstract: This paper introduces ManiFlow, a visuomotor imitation learning policy for
general robot manipulation that generates precise, high-dimensional actions
conditioned on diverse visual, language and proprioceptive inputs. We leverage
flow matching with consistency training to enable high-quality dexterous action
generation in just 1-2 inference steps. To handle diverse input modalities
efficiently, we propose DiT-X, a diffusion transformer architecture with
adaptive cross-attention and AdaLN-Zero conditioning that enables fine-grained
feature interactions between action tokens and multi-modal observations.
ManiFlow demonstrates consistent improvements across diverse simulation
benchmarks and nearly doubles success rates on real-world tasks across
single-arm, bimanual, and humanoid robot setups with increasing dexterity. The
extensive evaluation further demonstrates the strong robustness and
generalizability of ManiFlow to novel objects and background changes, and
highlights its strong scaling capability with larger-scale datasets. Our
website: maniflow-policy.github.io.

</details>


### [411] [Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment](https://arxiv.org/abs/2509.01836)
*Md Mahbub Alam,Jose F. Rodrigues-Jr,Gabriel Spadon*

Main category: cs.RO

TL;DR: 该研究提出了一个基于Transformer的框架，用于多船只轨迹预测和碰撞风险分析，以提高态势感知和避免碰撞。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型主要局限于单船只预测，忽略了船只间的相互作用、导航规则和明确的碰撞风险评估。

Method: 提出一个基于Transformer的框架，识别目标船只附近的船只，并通过并行流联合预测它们的未来轨迹。这些流包括运动学和衍生的物理特征、用于时间局部性的因果卷积、用于位置编码的空间转换以及捕获局部运动模式和长期依赖性的混合位置嵌入。

Result: 在真实大规模AIS数据集上使用联合多船只指标进行评估，该模型展示了优于传统单船只位移误差的预测能力，并通过模拟预测轨迹间的相互作用来量化潜在的碰撞风险。

Conclusion: 该框架通过多船只轨迹预测和集成碰撞风险分析，能够提供可行的见解，以加强海上安全和决策支持。

Abstract: Accurate vessel trajectory prediction is essential for enhancing situational
awareness and preventing collisions. Still, existing data-driven models are
constrained mainly to single-vessel forecasting, overlooking vessel
interactions, navigation rules, and explicit collision risk assessment. We
present a transformer-based framework for multi-vessel trajectory prediction
with integrated collision risk analysis. For a given target vessel, the
framework identifies nearby vessels. It jointly predicts their future
trajectories through parallel streams encoding kinematic and derived physical
features, causal convolutions for temporal locality, spatial transformations
for positional encoding, and hybrid positional embeddings that capture both
local motion patterns and long-range dependencies. Evaluated on large-scale
real-world AIS data using joint multi-vessel metrics, the model demonstrates
superior forecasting capabilities beyond traditional single-vessel displacement
errors. By simulating interactions among predicted trajectories, the framework
further quantifies potential collision risks, offering actionable insights to
strengthen maritime safety and decision support.

</details>


### [412] [AI-Driven Marine Robotics: Emerging Trends in Underwater Perception and Ecosystem Monitoring](https://arxiv.org/abs/2509.01878)
*Scarlett Raine,Tobias Fischer*

Main category: cs.RO

TL;DR: 气候变化对海洋生态系统构成威胁，催生了对AI驱动的海洋监测解决方案的需求。本文分析了水下AI的快速发展，探讨了其成为AI创新催化剂的因素，包括环境监测需求、公民科学数据共享以及研究人员从陆地视觉领域转向水下研究。文章指出了水下独有的挑战，如浊度、隐蔽物种识别、专家标注瓶颈和跨生态系统泛化，这些挑战正推动着弱监督学习、开放集识别和鲁棒感知等领域的发展。研究回顾了数据集、场景理解和三维重建的新兴趋势，强调了从被动观察到主动干预的范式转变。最后，文章指出水下研究的创新方法将促进通用计算机视觉、机器人和环境监测领域的发展。


<details>
  <summary>Details</summary>
Motivation: 气候变化对海洋生态系统造成了巨大压力，因此需要开发可扩展的、由人工智能驱动的监测解决方案。本文旨在研究水下人工智能（AI）作为新兴研究领域，并分析其如何从一个细分应用发展成为推动AI创新的催化剂。

Method: 本文分析了三个关键驱动因素：环境监测的必要性、公民科学平台促进的水下数据集民主化以及研究人员从饱和的陆地计算机视觉领域转向水下研究。文章还探讨了水下独有的挑战，如浊度、隐蔽物种检测、专家标注瓶颈以及跨生态系统泛化，并重点介绍了这些挑战如何推动了弱监督学习、开放集识别和鲁棒感知等领域的基础性进展。此外，本文还回顾了数据集、场景理解和三维重建方面的新兴趋势，并强调了从被动观察到AI驱动的主动干预能力的范式转变。

Result: 水下AI研究正以前所未有的速度发展，并已成为AI创新的重要驱动力。环境监测需求、公民科学数据共享以及研究人员的迁移是推动这一发展的主要因素。水下环境的独特挑战（如浊度、隐蔽物种检测、专家标注瓶颈和跨生态系统泛化）正在促进弱监督学习、开放集识别和鲁棒感知等AI技术的根本性进步。研究表明，水下AI的应用正从被动观察转向主动干预，并且这些技术创新将对通用计算机视觉、机器人和环境监测等领域产生广泛影响。

Conclusion: 水下AI研究不仅对海洋生态监测至关重要，其发展出的创新方法也正在推动通用计算机视觉、机器人和环境监测领域的边界，预示着一个从被动观察到主动干预的重大范式转变。

Abstract: Marine ecosystems face increasing pressure due to climate change, driving the
need for scalable, AI-powered monitoring solutions. This paper examines the
rapid emergence of underwater AI as a major research frontier and analyzes the
factors that have transformed marine perception from a niche application into a
catalyst for AI innovation. We identify three convergent drivers: environmental
necessity for ecosystem-scale monitoring, democratization of underwater
datasets through citizen science platforms, and researcher migration from
saturated terrestrial computer vision domains. Our analysis reveals how unique
underwater challenges - turbidity, cryptic species detection, expert annotation
bottlenecks, and cross-ecosystem generalization - are driving fundamental
advances in weakly supervised learning, open-set recognition, and robust
perception under degraded conditions. We survey emerging trends in datasets,
scene understanding and 3D reconstruction, highlighting the paradigm shift from
passive observation toward AI-driven, targeted intervention capabilities. The
paper demonstrates how underwater constraints are pushing the boundaries of
foundation models, self-supervised learning, and perception, with
methodological innovations that extend far beyond marine applications to
benefit general computer vision, robotics, and environmental monitoring.

</details>


### [413] [AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving](https://arxiv.org/abs/2509.01944)
*Zhenlong Yuan,Jing Tang,Jinguo Luo,Rui Chen,Chengxuan Qian,Lei Sun,Xiangxiang Chu,Yujun Cai,Dapeng Zhang,Shuo Li*

Main category: cs.RO

TL;DR: AutoDrive-R$^2$是一个新颖的VLA框架，通过结合链式思考（CoT）和强化学习（RL）来增强自动驾驶系统的推理和自我反思能力。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶VLA模型决策过程的可解释性和连贯性，以及行动序列的合理性。

Method: 提出了一种名为nuScenesR$^2$-6K的CoT数据集用于监督微调，并采用基于物理的奖励框架和群体相对策略优化（GRPO）算法进行强化学习。

Result: 在nuScenes和Waymo数据集上进行了广泛的评估，证明了该方法具有最先进的性能和稳健的泛化能力。

Conclusion: AutoDrive-R$^2$通过CoT和RL的结合，有效提升了自动驾驶系统的推理和自我反思能力，并在多个基准测试中取得了优异的成果。

Abstract: Vision-Language-Action (VLA) models in autonomous driving systems have
recently demonstrated transformative potential by integrating multimodal
perception with decision-making capabilities. However, the interpretability and
coherence of the decision process and the plausibility of action sequences
remain largely underexplored. To address these issues, we propose
AutoDrive-R$^2$, a novel VLA framework that enhances both reasoning and
self-reflection capabilities of autonomous driving systems through
chain-of-thought (CoT) processing and reinforcement learning (RL).
Specifically, we first propose an innovative CoT dataset named nuScenesR$^2$-6K
for supervised fine-tuning, which effectively builds cognitive bridges between
input information and output trajectories through a four-step logical chain
with self-reflection for validation. Moreover, to maximize both reasoning and
self-reflection during the RL stage, we further employ the Group Relative
Policy Optimization (GRPO) algorithm within a physics-grounded reward framework
that incorporates spatial alignment, vehicle dynamic, and temporal smoothness
criteria to ensure reliable and realistic trajectory planning. Extensive
evaluation results across both nuScenes and Waymo datasets demonstrates the
state-of-the-art performance and robust generalization capacity of our proposed
method.

</details>


### [414] [Hybrid Autonomy Framework for a Future Mars Science Helicopter](https://arxiv.org/abs/2509.01980)
*Luca Di Pierno,Robert Hewitt,Stephan Weiss,Roland Brockers*

Main category: cs.RO

TL;DR: NASA正在研究一种名为火星科学直升机（MSH）的先进飞行器，旨在实现长距离的火星表面探索。由于地火通信延迟和任务复杂性，需要一个先进的自主框架来确保安全高效的运行。该研究提出了一个融合有限状态机（FSM）和行为树（BTs）的混合自主控制框架，以实现可扩展、鲁棒且计算高效的解决方案。通过蒙特卡洛模拟和实地测试验证了该框架的鲁棒性和适应性，能够对离散事件和实时系统反馈做出反应。


<details>
  <summary>Details</summary>
Motivation: 为了应对地火通信延迟和火星任务的复杂性，需要一个能够自主适应任务目标和实时条件的先进自主框架，以确保火星科学直升机（MSH）的安全高效运行。

Method: 本研究提出了一个确定性的高级飞行探索控制框架，该框架集成了有限状态机（FSM）和行为树（BTs），以实现可扩展、鲁棒且计算高效的自主解决方案。

Result: 通过蒙特卡洛模拟和实地测试验证了该框架，证明了其对离散事件和实时系统反馈的鲁棒性和适应性，这些输入能够触发状态转换或动态调整行为执行，从而实现响应迅速且具有上下文感知的操作。

Conclusion: 该混合自主控制框架为火星科学直升机等深空探索任务提供了一个可行的、鲁棒且适应性强的解决方案，并且该框架支持与F-Prime等系统的集成，应用范围可扩展至航空机器人领域之外。

Abstract: Autonomous aerial vehicles, such as NASA's Ingenuity, enable rapid planetary
surface exploration beyond the reach of ground-based robots. Thus, NASA is
studying a Mars Science Helicopter (MSH), an advanced concept capable of
performing long-range science missions and autonomously navigating challenging
Martian terrain. Given significant Earth-Mars communication delays and mission
complexity, an advanced autonomy framework is required to ensure safe and
efficient operation by continuously adapting behavior based on mission
objectives and real-time conditions, without human intervention. This study
presents a deterministic high-level control framework for aerial exploration,
integrating a Finite State Machine (FSM) with Behavior Trees (BTs) to achieve a
scalable, robust, and computationally efficient autonomy solution for critical
scenarios like deep space exploration. In this paper we outline key
capabilities of a possible MSH and detail the FSM-BT hybrid autonomy framework
which orchestrates them to achieve the desired objectives. Monte Carlo
simulations and real field tests validate the framework, demonstrating its
robustness and adaptability to both discrete events and real-time system
feedback. These inputs trigger state transitions or dynamically adjust behavior
execution, enabling reactive and context-aware responses. The framework is
middleware-agnostic, supporting integration with systems like F-Prime and
extending beyond aerial robotics.

</details>


### [415] [Geometric Control of Mechanical Systems with Symmetries Based on Sliding Modes](https://arxiv.org/abs/2509.01985)
*Eduardo Espindola,Yu Tang*

Main category: cs.RO

TL;DR: 本篇论文提出了一种为具有对称性的机械系统（包括非约束和约束系统）设计滑模控制器的方法，这些系统演化在主纤维丛上。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是为具有对称性的机械系统（包括非约束和约束系统）提供一种设计滑模控制器的方法，这些系统演化在主纤维丛上，以简化控制设计并避免坐标表示的困难选择。

Method: 通过探索对称性，基于简化后的运动方程来制定控制律。该方法将滑模控制策略分为两个阶段：在基空间（base space）上实现趋近阶段（reaching stage），在结构群（structure group）上执行滑模阶段（sliding stage）。具体来说，基于运动学控制器在结构群上构造一个滑子群（sliding subgroup），使得滑模变量收敛到状态流形（state manifold）的单位元。然后，利用机械连接的局部形式（local form of the mechanical connection）在基空间上设计基于通用滑模向量场（general sliding vector field）的趋近律，以驱动滑模变量趋向于滑子群，并根据相应的协变导数（covariant derivative）给出其时间演化。

Result: 通过李亚普诺夫分析（Lyapunov analysis）证明了几乎全局渐近稳定性和局部指数稳定性。研究将所提出的方法应用于一个全驱动系统（由反作用轮驱动的刚性航天器）和一个欠驱动非完整系统（由轮子驱动的单轮移动机器人），并进行了模拟以供说明。

Conclusion: 本研究成功地为具有对称性的机械系统设计了一种滑模控制策略，该策略利用了系统的几何特性，简化了设计过程，并保证了系统的稳定性。

Abstract: In this paper, we propose a framework for designing sliding mode controllers
for a class of mechanical systems with symmetry, both unconstrained and
constrained, that evolve on principal fiber bundles. Control laws are developed
based on the reduced motion equations by exploring symmetries, leading to a
sliding mode control strategy where the reaching stage is executed on the base
space, and the sliding stage is performed on the structure group. Thus, design
complexity is reduced, and difficult choices for coordinate representations
when working with a particular Lie group are avoided. For this purpose, a
sliding subgroup is constructed on the structure group based on a kinematic
controller, and the sliding variable will converge to the identity of the state
manifold upon reaching the sliding subgroup. A reaching law based on a general
sliding vector field is then designed on the base space using the local form of
the mechanical connection to drive the sliding variable to the sliding
subgroup, and its time evolution is given according to the appropriate
covariant derivative. Almost global asymptotic stability and local exponential
stability are demonstrated using a Lyapunov analysis. We apply the results to a
fully actuated system (a rigid spacecraft actuated by reaction wheels) and a
subactuated nonholonomic system (unicycle mobile robot actuated by wheels),
which is also simulated for illustration.

</details>


### [416] [MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation](https://arxiv.org/abs/2509.01996)
*Chi Sun,Xian Wang,Abhishek Kumar,Chengbin Cui,Lik-Hang Lee*

Main category: cs.RO

TL;DR: 该研究提出了一种结合虚拟导纳（VA）模型和多模态卷积神经网络（MMIPN）的共享控制框架，以提高VR环境中多物体遥操作任务的性能和用户体验。VA模型通过人工势场优化运动轨迹，MMIPN通过处理注视、机器人运动和环境上下文等模态信息来识别抓取意图。实验结果表明，MMIPN提高了抓取成功率，VA模型缩短了路径长度，其中注视数据最为关键。


<details>
  <summary>Details</summary>
Motivation: 解决虚拟现实（VR）环境中多物体遥操作任务中存在的感知模糊性和单模态意图识别的局限性，以提升遥操作性能和用户体验。

Method: 提出了一种共享控制框架，结合了虚拟导纳（VA）模型和基于多模态卷积神经网络的人类意图感知网络（MMIPN）。VA模型使用人工势场调整导纳力和优化运动轨迹。MMIPN处理注视、机器人运动和环境上下文等多模态输入，以估计人类抓取意图。

Result: MMIPN显著提高了抓取成功率，VA模型通过减小路径长度提高了运动效率。注视数据被证明是最关键的输入模态。

Conclusion: 结合多模态线索和隐式引导可以有效地改善基于VR的遥操作性能，为多物体抓取任务提供了鲁棒的解决方案，并有望实现未来更自然的交互。

Abstract: Effective human-robot interaction (HRI) in multi-object teleoperation tasks
faces significant challenges due to perceptual ambiguities in virtual reality
(VR) environments and the limitations of single-modality intention recognition.
This paper proposes a shared control framework that combines a virtual
admittance (VA) model with a Multimodal-CNN-based Human Intention Perception
Network (MMIPN) to enhance teleoperation performance and user experience. The
VA model employs artificial potential fields to guide operators toward target
objects by adjusting admittance force and optimizing motion trajectories. MMIPN
processes multimodal inputs, including gaze movement, robot motions, and
environmental context, to estimate human grasping intentions, helping to
overcome depth perception challenges in VR. Our user study evaluated four
conditions across two factors, and the results showed that MMIPN significantly
improved grasp success rates, while the VA model enhanced movement efficiency
by reducing path lengths. Gaze data emerged as the most crucial input modality.
These findings demonstrate the effectiveness of combining multimodal cues with
implicit guidance in VR-based teleoperation, providing a robust solution for
multi-object grasping tasks and enabling more natural interactions across
various applications in the future.

</details>


### [417] [Generalizing Unsupervised Lidar Odometry Model from Normal to Snowy Weather Conditions](https://arxiv.org/abs/2509.02011)
*Beibei Zhou,Zhiyuan Zhang,Zhenbo Song,Jianhui Guo,Hui Kong*

Main category: cs.RO

TL;DR: 本论文提出了一种无监督的激光雷达里程计模型，通过有效的去噪来应对雨雪天气，提高了模型在不同环境下的泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的激光雷达里程计在雨雪等恶劣天气条件下性能会受到严重影响，限制了其在现实世界中的应用。本研究旨在弥合清晰和下雪天气条件之间的性能差距。

Method: 本文提出了一种无监督激光雷达里程计模型，引入了“Patch Spatial Measure (PSM)”模块来评估点云的离散度以检测噪声，并提出了“Patch Point Weight Predictor (PPWP)”来分配自适应的点权重。为了实现实时性，模型首先使用强度阈值掩码去除近距离的密集雪簇，然后进行多模态特征融合来优化点权重预测，从而提高恶劣天气下的鲁棒性。

Result: 实验结果表明，该模型在清晰和下雪天气条件下均表现出鲁棒的性能，有效提高了模型的泛化能力。

Conclusion: 本研究提出的无监督激光雷达里程计模型，通过PSM和PPWP等方法有效解决了雪天噪声问题，显著提升了模型在不同天气条件下的性能，为实现更可靠的全天候自动驾驶系统奠定了基础。

Abstract: Deep learning-based LiDAR odometry is crucial for autonomous driving and
robotic navigation, yet its performance under adverse weather, especially
snowfall, remains challenging. Existing models struggle to generalize across
conditions due to sensitivity to snow-induced noise, limiting real-world use.
In this work, we present an unsupervised LiDAR odometry model to close the gap
between clear and snowy weather conditions. Our approach focuses on effective
denoising to mitigate the impact of snowflake noise and outlier points on pose
estimation, while also maintaining computational efficiency for real-time
applications.
  To achieve this, we introduce a Patch Spatial Measure (PSM) module that
evaluates the dispersion of points within each patch, enabling effective
detection of sparse and discrete noise.
  We further propose a Patch Point Weight Predictor (PPWP) to assign adaptive
point-wise weights, enhancing their discriminative capacity within local
regions. To support real-time performance, we first apply an intensity
threshold mask to quickly suppress dense snowflake clusters near the LiDAR, and
then perform multi-modal feature fusion to refine the point-wise weight
prediction, improving overall robustness under adverse weather. Our model is
trained in clear weather conditions and rigorously tested across various
scenarios, including snowy and dynamic. Extensive experimental results confirm
the effectiveness of our method, demonstrating robust performance in both clear
and snowy weather. This advancement enhances the model's generalizability and
paves the way for more reliable autonomous systems capable of operating across
a wider range of environmental conditions.

</details>


### [418] [Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance](https://arxiv.org/abs/2509.02055)
*Yang Zhang,Chenwei Wang,Ouyang Lu,Yuan Zhao,Yunfei Ge,Zhenglong Sun,Xiu Li,Chi Zhang,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: Align-Then-steer (ATE) is a data-efficient framework for adapting Vision-Language-Action (VLA) models to downstream robotic tasks with different embodiments or objectives. It aligns action spaces by creating a unified latent space and steers the generation process during fine-tuning, significantly improving success rates compared to direct fine-tuning, especially in real-world cross-embodiment scenarios.


<details>
  <summary>Details</summary>
Motivation: Adapting general-purpose VLA models to downstream robotic tasks is challenging due to discrepancies in embodiment or task objectives, leading to action distribution mismatches that require extensive data and compute for fine-tuning.

Method: ATE aligns action spaces by constructing a unified latent space using a variational autoencoder with reverse KL divergence to embed adaptation actions into the pre-training action latent distribution. It then steers the VLA's generation process during fine-tuning using a guidance mechanism to align the output distribution with the target domain.

Result: Experiments on cross-embodiment and cross-task manipulation showed that ATE improved the average multi-task success rate by up to 9.8% in simulation and achieved a 32% success rate gain in a real-world cross-embodiment setting, outperforming direct fine-tuning of representative VLAs.

Conclusion: ATE provides a general and lightweight solution that significantly improves the practicality of deploying VLA models to new robotic platforms and tasks by enhancing data efficiency and performance during adaptation.

Abstract: Vision-Language-Action (VLA) models pre-trained on large, diverse datasets
show remarkable potential for general-purpose robotic manipulation. However, a
primary bottleneck remains in adapting these models to downstream tasks,
especially when the robot's embodiment or the task itself differs from the
pre-training data. This discrepancy leads to a significant mismatch in action
distributions, demanding extensive data and compute for effective fine-tuning.
To address this challenge, we introduce \textbf{Align-Then-stEer
(\texttt{ATE})}, a novel, data-efficient, and plug-and-play adaptation
framework. \texttt{ATE} first aligns disparate action spaces by constructing a
unified latent space, where a variational autoencoder constrained by reverse KL
divergence embeds adaptation actions into modes of the pre-training action
latent distribution. Subsequently, it steers the diffusion- or flow-based VLA's
generation process during fine-tuning via a guidance mechanism that pushes the
model's output distribution towards the target domain. We conduct extensive
experiments on cross-embodiment and cross-task manipulation in both simulation
and real world. Compared to direct fine-tuning of representative VLAs, our
method improves the average multi-task success rate by up to \textbf{9.8\%} in
simulation and achieves a striking \textbf{32\% success rate gain} in a
real-world cross-embodiment setting. Our work presents a general and
lightweight solution that greatly enhances the practicality of deploying VLA
models to new robotic platforms and tasks.

</details>


### [419] [A Geometric Method for Base Parameter Analysis in Robot Inertia Identification Based on Projective Geometric Algebra](https://arxiv.org/abs/2509.02071)
*Guangzhen Sun,Ye Ding,Xiangyang Zhu*

Main category: cs.RO

TL;DR: 该论文提出了一种新颖的几何方法，用于解析确定机器人系统的基惯性参数。。


<details>
  <summary>Details</summary>
Motivation: 使用射影几何代数重新表述刚体动力学，为识别模型命名为“四面体-点 (TP)”模型。

Method: 基于刚体TP模型，以闭式形式推导了识别模型的回归矩阵系数，并提出了基参数分析的三个基本原理：共享点原理、固定点原理和平面旋转原理。利用这些原理，开发了自动确定所有基参数的算法，核心算法DRNG理论上具有O(1)复杂度，预处理阶段为O(N)。

Result: 提出的方法和算法在Puma560、Unitree Go2、2RRU-1RRS并联机器人（PKM）和2PRS-1PSR PKM这四种机器人上得到了验证，成功识别了所有基参数，并且该方法对于PKM表现出高鲁棒性和计算效率。

Conclusion: 通过全面的演示，该方法被证明是通用、鲁棒且高效的。

Abstract: This paper proposes a novel geometric method for analytically determining the
base inertial parameters of robotic systems. The rigid body dynamics is
reformulated using projective geometric algebra, leading to a new
identification model named ``tetrahedral-point (TP)" model. Based on the rigid
body TP model, coefficients in the regresoor matrix of the identification model
are derived in closed-form, exhibiting clear geometric interpretations.
Building directly from the dynamic model, three foundational principles for
base parameter analysis are proposed: the shared points principle, fixed points
principle, and planar rotations principle. With these principles, algorithms
are developed to automatically determine all the base parameters. The core
algorithm, referred to as Dynamics Regressor Nullspace Generator (DRNG),
achieves $O(1)$-complexity theoretically following an $O(N)$-complexity
preprocessing stage, where $N$ is the number of rigid bodies. The proposed
method and algorithms are validated across four robots: Puma560, Unitree Go2, a
2RRU-1RRS parallel kinematics mechanism (PKM), and a 2PRS-1PSR PKM. In all
cases, the algorithms successfully identify the complete set of base
parameters. Notably, the approach demonstrates high robustness and
computational efficiency, particularly in the cases of PKMs. Through the
comprehensive demonstrations, the method is shown to be general, robust, and
efficient.

</details>


### [420] [Learning Social Heuristics for Human-Aware Path Planning](https://arxiv.org/abs/2509.02134)
*Andrea Eirale,Matteo Leonetti,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 该研究提出了一种名为HPLSV的方法，用于学习机器人导航中的社会规范，并将其应用于排队场景。


<details>
  <summary>Details</summary>
Motivation: 大多数关于社交机器人导航的研究都集中在避开障碍物和预测行人运动，但为了真正被社会接受，机器人需要学习难以通过传统导航实现的特定社会规范。

Method: 提出了一种名为“启发式规划结合学习到的社会价值”（HPLSV）的方法，该方法学习一个封装了社会导航成本的价值函数，并将其作为启发式搜索路径规划的附加启发式。

Result: 该方法被应用于常见的社会场景——加入排队，以期推广到更多的人类活动。

Conclusion: HPLSV是一种学习机器人社会导航价值函数并将其用于路径规划的方法，并在排队场景中进行了初步验证。

Abstract: Social robotic navigation has been at the center of numerous studies in
recent years. Most of the research has focused on driving the robotic agent
along obstacle-free trajectories, respecting social distances from humans, and
predicting their movements to optimize navigation. However, in order to really
be socially accepted, the robots must be able to attain certain social norms
that cannot arise from conventional navigation, but require a dedicated
learning process. We propose Heuristic Planning with Learned Social Value
(HPLSV), a method to learn a value function encapsulating the cost of social
navigation, and use it as an additional heuristic in heuristic-search path
planning. In this preliminary work, we apply the methodology to the common
social scenario of joining a queue of people, with the intention of
generalizing to further human activities.

</details>


### [421] [Systematic Evaluation of Trade-Offs in Motion Planning Algorithms for Optimal Industrial Robotic Work Cell Design](https://arxiv.org/abs/2509.02146)
*G. de Mathelin,C. Hartl-Nesic,A. Kugi*

Main category: cs.RO

TL;DR: 该论文提出了一种评估工业机器人工作单元布局优化中运动规划权衡的方法，并将其应用于模块化机器人的时间最优运动规划。


<details>
  <summary>Details</summary>
Motivation: 工业机器人工作单元的性能优化需要调整细胞布局等超参数，但运动规划的计算成本很高，需要进行权衡，而这些权衡对整体性能的影响尚未得到系统评估。

Method: 提出评估运动规划权衡（关于最优性、时间增益、鲁棒性和一致性）的指标，并通过模拟研究了运动规划简化对高层优化的影响。

Result: 开发了用于评估运动规划权衡的指标，并通过模拟研究了这些权衡对高层优化结果的影响。

Conclusion: 该论文提出的指标和方法有助于在计算复杂性和解决方案质量之间取得平衡，并已成功应用于模块化机器人的时间最优运动规划场景。

Abstract: The performance of industrial robotic work cells depends on optimizing
various hyperparameters referring to the cell layout, such as robot base
placement, tool placement, and kinematic design. Achieving this requires a
bilevel optimization approach, where the high-level optimization adjusts these
hyperparameters, and the low-level optimization computes robot motions.
However, computing the optimal robot motion is computationally infeasible,
introducing trade-offs in motion planning to make the problem tractable. These
trade-offs significantly impact the overall performance of the bilevel
optimization, but their effects still need to be systematically evaluated. In
this paper, we introduce metrics to assess these trade-offs regarding
optimality, time gain, robustness, and consistency. Through extensive
simulation studies, we investigate how simplifications in motion-level
optimization affect the high-level optimization outcomes, balancing
computational complexity with solution quality. The proposed algorithms are
applied to find the time-optimal kinematic design for a modular robot in two
palletization scenarios.

</details>


### [422] [Adaptive Navigation Strategy for Low-Thrust Proximity Operations in Circular Relative Orbit](https://arxiv.org/abs/2509.02204)
*Dario Ruggiero,Mauro Mancini,Elisa Capello*

Main category: cs.RO

TL;DR: 文章提出了一种自适应观测器导航策略，用于航天器在圆形相对轨道（CRO）场景下的邻近操作，如编队飞行和非合作目标检查。


<details>
  <summary>Details</summary>
Motivation: 解决航天器邻近操作（如编队飞行和非合作目标检查）中的导航挑战。

Method: 提出一种自适应观测器，根据估计状态调整观测器增益，以实现状态估计的快速收敛和低噪声敏感性。使用基于李亚普诺夫的分析确保稳定性和准确性，并通过基于视觉的传感器数据进行仿真验证。

Result: 与具有时不变增益的经典观测器相比，所提出的方法提高了轨迹跟踪精度并减少了控制输入切换。

Conclusion: 该方法是一种有前途的自主航天器定位和控制解决方案。

Abstract: This paper presents an adaptive observer-based navigation strategy for
spacecraft in Circular Relative Orbit (CRO) scenarios, addressing challenges in
proximity operations like formation flight and uncooperative target inspection.
The proposed method adjusts observer gains based on the estimated state to
achieve fast convergence and low noise sensitivity in state estimation. A
Lyapunov-based analysis ensures stability and accuracy, while simulations using
vision-based sensor data validate the approach under realistic conditions.
Compared to classical observers with time-invariant gains, the proposed method
enhances trajectory tracking precision and reduces control input switching,
making it a promising solution for autonomous spacecraft localization and
control.

</details>


### [423] [Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety](https://arxiv.org/abs/2509.02163)
*Wenxiao Zhang,Xiangrui Kong,Conan Dewitt,Thomas Bräunl,Jin B. Hong*

Main category: cs.RO

TL;DR: 该研究提出了一个统一框架，用于解决将大型语言模型（LLMs）集成到机器人系统中时出现的安全（对抗性攻击）和可靠性（复杂环境中的安全性）问题。该框架通过提示组装、状态管理和安全验证相结合的方式，有效防御了提示注入攻击，并能在复杂的、对抗性的环境中运行，实验结果表明在对抗性条件下性能有显著提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在机器人领域的应用带来了决策能力和适应性的革命，但确保其在复杂环境中的可靠性（包括安全性与鲁棒性）是一个关键挑战。

Method: 提出一个统一框架，结合了提示组装、状态管理和安全验证机制，以抵御提示注入攻击并保证操作安全。

Result: 实验结果显示，在提示注入攻击下性能提升30.8%，在复杂环境的对抗性条件下性能提升高达325%，相比基线模型有显著改善。

Conclusion: 该研究提出的统一框架有效解决了LLM驱动的机器人系统的安全与可靠性问题，为在实际场景中部署LLM集成移动机器人提供了有价值的参考。

Abstract: Integrating large language models (LLMs) into robotic systems has
revolutionised embodied artificial intelligence, enabling advanced
decision-making and adaptability. However, ensuring reliability, encompassing
both security against adversarial attacks and safety in complex environments,
remains a critical challenge. To address this, we propose a unified framework
that mitigates prompt injection attacks while enforcing operational safety
through robust validation mechanisms. Our approach combines prompt assembling,
state management, and safety validation, evaluated using both performance and
security metrics. Experiments show a 30.8% improvement under injection attacks
and up to a 325% improvement in complex environment settings under adversarial
conditions compared to baseline scenarios. This work bridges the gap between
safety and security in LLM-based robotic systems, offering actionable insights
for deploying reliable LLM-integrated mobile robots in real-world settings. The
framework is open-sourced with simulation and physical deployment demos at
https://llmeyesim.vercel.app/

</details>


### [424] [Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals](https://arxiv.org/abs/2509.02275)
*Fengyi Wang,Xiangyu Fu,Nitish Thakor,Gordon Cheng*

Main category: cs.RO

TL;DR: 受生物学启发，一种配备了多种传感器以模拟人类手部感觉模态的软质拟人手被提出。该系统利用生物学启发编码方案将多模态感觉数据转换为脉冲序列，通过脉冲神经网络（SNN）实现高效处理，并在物体识别任务中达到97.14%的准确率，显著优于以往的研究。此外，还引入了新的微分神经元模型来增强材料分类能力。


<details>
  <summary>Details</summary>
Motivation: 为了实现高效、鲁棒和类似人类的机器人感知能力，从人类体感系统整合多模态感觉反馈（触觉、本体感觉、热信号）以实现全面感知和与环境有效互动的生物学机制中获得启发。

Method: 提出了一种配备了多种传感器以模拟人类手部感觉模态的传感器化软质拟人手。该系统整合了生物学启发编码方案，将多模态感觉数据转换为脉冲序列，从而实现高效的脉冲神经网络（SNN）处理。引入了新颖的微分神经元模型来捕捉动态热响应，以增强材料分类。

Result: 所提出的框架通过利用神经脉冲信号，在物体识别任务中实现了97.14%的准确率，在不同姿态下均表现优异，显著优于以往软质手的研究。引入的微分神经元模型也增强了材料分类能力。

Conclusion: 多模态感觉融合的好处得到了证明，并突显了神经形态方法在机器人系统中实现高效、鲁棒和类似人类的感知能力的潜力。

Abstract: The human somatosensory system integrates multimodal sensory feedback,
including tactile, proprioceptive, and thermal signals, to enable comprehensive
perception and effective interaction with the environment. Inspired by the
biological mechanism, we present a sensorized soft anthropomorphic hand
equipped with diverse sensors designed to emulate the sensory modalities of the
human hand. This system incorporates biologically inspired encoding schemes
that convert multimodal sensory data into spike trains, enabling
highly-efficient processing through Spiking Neural Networks (SNNs). By
utilizing these neuromorphic signals, the proposed framework achieves 97.14%
accuracy in object recognition across varying poses, significantly
outperforming previous studies on soft hands. Additionally, we introduce a
novel differentiator neuron model to enhance material classification by
capturing dynamic thermal responses. Our results demonstrate the benefits of
multimodal sensory fusion and highlight the potential of neuromorphic
approaches for achieving efficient, robust, and human-like perception in
robotic systems.

</details>


### [425] [Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments](https://arxiv.org/abs/2509.02283)
*Ruibin Zhang,Fei Gao*

Main category: cs.RO

TL;DR: 该研究提出了一种基于雷达的3D环境感知框架，用于农业场景中的机器人自主导航，以解决光学传感器的局限性。该框架通过平行帧累积、基于扩散模型的层次化学习以及稀疏3D网络来处理雷达原始数据，实现了对农田场景中杆状物和线状物等精细结构的精确重建和分类，并降低了计算和内存成本。


<details>
  <summary>Details</summary>
Motivation: 光学传感器（如摄像头、激光雷达）在机器人自主导航中易受视觉遮挡和传感器污染的影响，尤其是在农业场景中。本研究旨在利用雷达的穿透能力，提供一种更鲁棒的环境感知方法。

Method: 1. 平行帧累积：提高雷达原始数据的信噪比。2. 基于扩散模型的层次化学习框架：首先过滤雷达旁瓣伪影，然后生成细粒度的3D语义点云。3. 特殊设计的稀疏3D网络：优化处理大规模雷达原始数据。

Result: 在真实农业场景的自建数据集上进行的大量基准比较和实验评估表明，该方法在结构和语义预测方面优于现有方法，同时计算和内存成本分别降低了51.3%和27.5%。该方法能够完整重建并准确分类现有方法难以感知的杆状物和线状物等精细结构。

Conclusion: 该研究提出的3D雷达感知框架能够实现密集、准确的3D雷达感知，尤其在处理农业场景中的精细结构方面表现出色，为机器人自主导航提供了一种有效的替代方案。

Abstract: Accurate and robust environmental perception is crucial for robot autonomous
navigation. While current methods typically adopt optical sensors (e.g.,
camera, LiDAR) as primary sensing modalities, their susceptibility to visual
occlusion often leads to degraded performance or complete system failure. In
this paper, we focus on agricultural scenarios where robots are exposed to the
risk of onboard sensor contamination. Leveraging radar's strong penetration
capability, we introduce a radar-based 3D environmental perception framework as
a viable alternative. It comprises three core modules designed for dense and
accurate semantic perception: 1) Parallel frame accumulation to enhance
signal-to-noise ratio of radar raw data. 2) A diffusion model-based
hierarchical learning framework that first filters radar sidelobe artifacts
then generates fine-grained 3D semantic point clouds. 3) A specifically
designed sparse 3D network optimized for processing large-scale radar raw data.
We conducted extensive benchmark comparisons and experimental evaluations on a
self-built dataset collected in real-world agricultural field scenes. Results
demonstrate that our method achieves superior structural and semantic
prediction performance compared to existing methods, while simultaneously
reducing computational and memory costs by 51.3% and 27.5%, respectively.
Furthermore, our approach achieves complete reconstruction and accurate
classification of thin structures such as poles and wires-which existing
methods struggle to perceive-highlighting its potential for dense and accurate
3D radar perception.

</details>


### [426] [Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception](https://arxiv.org/abs/2509.02324)
*Changshi Zhou,Haichuan Xu,Ningquan Gu,Zhipeng Wang,Bin Cheng,Pengpeng Zhang,Yanchao Dong,Mitsuhiro Hayashibe,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: LLM规划和VLM感知结合，用于语言引导的长期可变形物体操作（如布料折叠），在模拟和真实世界中均表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决语言引导的长期可变形物体操作的挑战，特别是多步布料折叠任务，需要长远规划和精细视觉感知。

Method: 提出一个统一框架，结合LLM规划器（将高级指令分解为低级动作）、VLM感知系统（使用SigLIP2和交叉注意力融合进行语言基础）和任务执行模块。

Result: 在模拟环境中，相较于现有方法，在已见指令、未见指令和未见任务上的表现分别提高了2.23、1.87和33.3。在真实机器人上，能够稳健地执行多种布料的折叠任务。

Conclusion: 该框架能够有效处理语言引导的长期可变形物体操作任务，并展现出良好的泛化能力。

Abstract: Language-guided long-horizon manipulation of deformable objects presents
significant challenges due to high degrees of freedom, complex dynamics, and
the need for accurate vision-language grounding. In this work, we focus on
multi-step cloth folding, a representative deformable-object manipulation task
that requires both structured long-horizon planning and fine-grained visual
perception. To this end, we propose a unified framework that integrates a Large
Language Model (LLM)-based planner, a Vision-Language Model (VLM)-based
perception system, and a task execution module. Specifically, the LLM-based
planner decomposes high-level language instructions into low-level action
primitives, bridging the semantic-execution gap, aligning perception with
action, and enhancing generalization. The VLM-based perception module employs a
SigLIP2-driven architecture with a bidirectional cross-attention fusion
mechanism and weight-decomposed low-rank adaptation (DoRA) fine-tuning to
achieve language-conditioned fine-grained visual grounding. Experiments in both
simulation and real-world settings demonstrate the method's effectiveness. In
simulation, it outperforms state-of-the-art baselines by 2.23, 1.87, and 33.3
on seen instructions, unseen instructions, and unseen tasks, respectively. On a
real robot, it robustly executes multi-step folding sequences from language
instructions across diverse cloth materials and configurations, demonstrating
strong generalization in practical scenarios. Project page:
https://language-guided.netlify.app/

</details>


### [427] [Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation](https://arxiv.org/abs/2509.02343)
*Lan Wei,Lou Genoud,Dandan Zhang*

Main category: cs.RO

TL;DR: 该研究提出了一种用于光学微机器人深度估计的物理信息、数据高效框架，结合了卷积特征提取和基于物理的焦点度量，以解决透明微机器人和低对比度成像的挑战，并在有限数据条件下实现了显著的精度提升。


<details>
  <summary>Details</summary>
Motivation: 生物医学应用（如细胞操控和微尺度组装）需要对光学微机器人进行精确的三维感知和控制，但透明微机器人和低对比度成像给传统深度学习方法带来挑战，并且需要昂贵的大型标注数据集。

Method: 提出了一种物理信息、数据高效的深度估计框架，该框架将卷积特征提取与基于物理的焦点度量（如熵、高斯拉普拉斯和梯度清晰度）相结合，并通过自适应网格策略（在微机器人区域使用更精细的网格，在背景区域使用更粗糙的网格）进行增强，以提高深度敏感性并降低计算复杂性。

Result: 与基线模型相比，该框架在多种微机器人类型上实现了显著的改进，平均平方误差（MSE）降低了60%以上，决定系数（R^2）有所提高。即使仅使用20%的数据进行训练，其性能也优于在完整数据集上训练的ResNet50模型。

Conclusion: 该研究提出的物理信息、数据高效框架能够有效地解决光学微机器人的深度估计问题，尤其是在数据有限的情况下，为相关生物医学应用提供了更精确的控制手段。

Abstract: Optical microrobots actuated by optical tweezers (OT) offer great potential
for biomedical applications such as cell manipulation and microscale assembly.
These tasks demand accurate three-dimensional perception to ensure precise
control in complex and dynamic biological environments. However, the
transparent nature of microrobots and low-contrast microscopic imaging
challenge conventional deep learning methods, which also require large
annotated datasets that are costly to obtain. To address these challenges, we
propose a physics-informed, data-efficient framework for depth estimation of
optical microrobots. Our method augments convolutional feature extraction with
physics-based focus metrics, such as entropy, Laplacian of Gaussian, and
gradient sharpness, calculated using an adaptive grid strategy. This approach
allocates finer grids over microrobot regions and coarser grids over background
areas, enhancing depth sensitivity while reducing computational complexity. We
evaluate our framework on multiple microrobot types and demonstrate significant
improvements over baseline models. Specifically, our approach reduces mean
squared error (MSE) by over 60% and improves the coefficient of determination
(R^2) across all test cases. Notably, even when trained on only 20% of the
available data, our model outperforms ResNet50 trained on the full dataset,
highlighting its robustness under limited data conditions. Our code is
available at: https://github.com/LannWei/CBS2025.

</details>


### [428] [OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments](https://arxiv.org/abs/2509.02425)
*Yifan Xu,Qianwei Wang,Vineet Kamat,Carol Menassa*

Main category: cs.RO

TL;DR: OpenGuide是一个结合了自然语言理解、视觉-语言模型（VLM）、前沿探索和部分可观察马尔可夫决策过程（POMDP）规划的辅助移动机器人系统，旨在帮助盲人或视障人士在复杂的室内环境中搜索和收集多个物体。


<details>
  <summary>Details</summary>
Motivation: 现有技术在应对复杂室内环境中的多目标搜索方面存在不足，特别是对视障人士而言。OpenGuide旨在解决这一挑战，提供可扩展且高效的多目标搜索能力。

Method: OpenGuide集成了自然语言理解、VLM、前沿探索和POMDP规划。它能够理解开放词汇的指令，推理物体-场景关系，并自适应地导航和定位多个目标物品。该系统还通过价值衰减和信念空间推理来处理漏检，提高搜索效率。

Result: 在模拟和真实世界实验中，OpenGuide相比先前方法在任务成功率和搜索效率方面均有显著提升。

Conclusion: OpenGuide为在辅助生活环境中提供可扩展、以人为本的机器人辅助奠定了基础，特别是在满足视障人士的多目标搜索需求方面。

Abstract: Indoor built environments like homes and offices often present complex and
cluttered layouts that pose significant challenges for individuals who are
blind or visually impaired, especially when performing tasks that involve
locating and gathering multiple objects. While many existing assistive
technologies focus on basic navigation or obstacle avoidance, few systems
provide scalable and efficient multi-object search capabilities in real-world,
partially observable settings. To address this gap, we introduce OpenGuide, an
assistive mobile robot system that combines natural language understanding with
vision-language foundation models (VLM), frontier-based exploration, and a
Partially Observable Markov Decision Process (POMDP) planner. OpenGuide
interprets open-vocabulary requests, reasons about object-scene relationships,
and adaptively navigates and localizes multiple target items in novel
environments. Our approach enables robust recovery from missed detections
through value decay and belief-space reasoning, resulting in more effective
exploration and object localization. We validate OpenGuide in simulated and
real-world experiments, demonstrating substantial improvements in task success
rate and search efficiency over prior methods. This work establishes a
foundation for scalable, human-centered robotic assistance in assisted living
environments.

</details>


### [429] [U-ARM : Ultra low-cost general teleoperation interface for robot manipulation](https://arxiv.org/abs/2509.02437)
*Yanwen Zou,Zhaoye Zhou,Chenyang Shi,Zewei Ye,Junda Huang,Yan Ding,Bo Zhao*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose U-Arm, a low-cost and rapidly adaptable leader-follower
teleoperation framework designed to interface with most of commercially
available robotic arms. Our system supports teleoperation through three
structurally distinct 3D-printed leader arms that share consistent control
logic, enabling seamless compatibility with diverse commercial robot
configurations. Compared with previous open-source leader-follower interfaces,
we further optimized both the mechanical design and servo selection, achieving
a bill of materials (BOM) cost of only \$50.5 for the 6-DoF leader arm and
\$56.8 for the 7-DoF version. To enhance usability, we mitigate the common
challenge in controlling redundant degrees of freedom by %engineering methods
mechanical and control optimizations. Experimental results demonstrate that
U-Arm achieves 39\% higher data collection efficiency and comparable task
success rates across multiple manipulation scenarios compared with Joycon,
another low-cost teleoperation interface. We have open-sourced all CAD models
of three configs and also provided simulation support for validating
teleoperation workflows. We also open-sourced real-world manipulation data
collected with U-Arm. The project website is
https://github.com/MINT-SJTU/LeRobot-Anything-U-Arm.

</details>


### [430] [Coral: A Unifying Abstraction Layer for Composable Robotics Software](https://arxiv.org/abs/2509.02453)
*Steven Swanbeck,Mitch Pryor*

Main category: cs.RO

TL;DR: Coral是一个用于机器人软件集成的抽象层，通过最大化组件组合性来简化开发、部署和协调，减少配置负担，同时保持对不同领域、系统和任务的适应性。


<details>
  <summary>Details</summary>
Motivation: 软件集成是机器人领域一个耗时且充满挑战的任务，现有软件往往是紧耦合的整体，难以修改和部署。

Method: Coral通过引入一个更高层次的抽象来解决这个问题，该抽象约束集成过程为语义上有意义的选择，从而减少配置负担，同时保持对不同领域、系统和任务的适应性。Coral不是替代现有工具，而是对其进行补充。

Result: Coral的效用在集成具有挑战性的场景中得到了证明，包括基于激光雷达的SLAM和多机器人腐蚀缓解任务。

Conclusion: Coral通过实现机器人软件的实际可组合性，为广泛的机器人系统集成挑战提供了可扩展的解决方案，提高了组件的可重用性、系统的可重构性和专家及非专家用户的可访问性。Coral已开源。

Abstract: Despite the multitude of excellent software components and tools available in
the robotics and broader software engineering communities, successful
integration of software for robotic systems remains a time-consuming and
challenging task for users of all knowledge and skill levels. And with robotics
software often being built into tightly coupled, monolithic systems, even minor
alterations to improve performance, adjust to changing task requirements, or
deploy to new hardware can require significant engineering investment. To help
solve this problem, this paper presents Coral, an abstraction layer for
building, deploying, and coordinating independent software components that
maximizes composability to allow for rapid system integration without modifying
low-level code. Rather than replacing existing tools, Coral complements them by
introducing a higher-level abstraction that constrains the integration process
to semantically meaningful choices, reducing the configuration burden without
limiting adaptability to diverse domains, systems, and tasks. We describe Coral
in detail and demonstrate its utility in integrating software for scenarios of
increasing complexity, including LiDAR-based SLAM and multi-robot corrosion
mitigation tasks. By enabling practical composability in robotics software,
Coral offers a scalable solution to a broad range of robotics system
integration challenges, improving component reusability, system
reconfigurability, and accessibility to both expert and non-expert users. We
release Coral open source.

</details>


### [431] [Classification of Vision-Based Tactile Sensors: A Review](https://arxiv.org/abs/2509.02478)
*Haoran Li,Yijiong Lin,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F Lepora*

Main category: cs.RO

TL;DR: 该论文提出了一种新的视觉触觉传感器（VBTS）分类方法，将传感器基于接触到触觉图像的转换原理分为两种：基于标记的传导原理和基于强度的传导原理。


<details>
  <summary>Details</summary>
Motivation: 由于视觉基础触觉传感器（VBTS）具有高空间分辨率、低制造成本和易于定制等优点，因此在机器人手、夹持器和假肢等领域得到了广泛应用。

Method: 该研究提出了一种新的VBTS分类方法，将传感器基于接触到触觉图像的转换原理分为两种：基于标记的传导原理（Marker-Based Transduction）和基于强度的传导原理（Intensity-Based Transduction）。其中，基于标记的传导原理又可分为简单标记（SMB）和形态标记（MMB）两种子类型；基于强度的传导原理又可分为反射层（RLB）和透明层（TLB）两种机制。论文对这四种传感器及其组合类型的硬件特性进行了比较研究，并讨论了常用的触觉信息解释方法。

Result: 研究对四种传感器及其组合类型的硬件特性进行了比较研究，并讨论了常用的触觉信息解释方法，揭示了VBTS技术面临的挑战以及未来的研究方向。

Conclusion: 该论文提出了一种新的VBTS分类方法，为理解和发展VBTS技术提供了理论基础和未来研究方向。

Abstract: Vision-based tactile sensors (VBTS) have gained widespread application in
robotic hands, grippers and prosthetics due to their high spatial resolution,
low manufacturing costs, and ease of customization. While VBTSs have common
design features, such as a camera module, they can differ in a rich diversity
of sensing principles, material compositions, multimodal approaches, and data
interpretation methods. Here, we propose a novel classification of VBTS that
categorizes the technology into two primary sensing principles based on the
underlying transduction of contact into a tactile image: the Marker-Based
Transduction Principle and the Intensity-Based Transduction Principle.
Marker-Based Transduction interprets tactile information by detecting marker
displacement and changes in marker density. In contrast, Intensity-Based
Transduction maps external disturbances with variations in pixel values.
Depending on the design of the contact module, Marker-Based Transduction can be
further divided into two subtypes: Simple Marker-Based (SMB) and Morphological
Marker-Based (MMB) mechanisms. Similarly, the Intensity-Based Transduction
Principle encompasses the Reflective Layer-based (RLB) and Transparent
Layer-Based (TLB) mechanisms. This paper provides a comparative study of the
hardware characteristics of these four types of sensors including various
combination types, and discusses the commonly used methods for interpreting
tactile information. This~comparison reveals some current challenges faced by
VBTS technology and directions for future research.

</details>


### [432] [Fault-tolerant Model Predictive Control for Spacecraft](https://arxiv.org/abs/2509.02527)
*Raphael Stöckner,Pedro Roque,Maria Charitidou,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Given the cost and critical functions of satellite constellations, ensuring
mission longevity and safe decommissioning is essential for space
sustainability. This article presents a Model Predictive Control for spacecraft
trajectory and setpoint stabilization under multiple actuation failures. The
proposed solution allows us to efficiently control the faulty spacecraft
enabling safe navigation towards servicing or collision-free trajectories. The
proposed scheme ensures closed-loop asymptotic stability and is shown to be
recursively feasible. We demonstrate its efficacy through open-source numerical
results and realistic experiments using the ATMOS platform.

</details>


### [433] [Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots](https://arxiv.org/abs/2509.02530)
*Minghuan Liu,Zhengbang Zhu,Xiaoshen Han,Peng Hu,Haotong Lin,Xinyao Li,Jingxiao Chen,Jiafeng Xu,Yichu Yang,Yunfeng Lin,Xinghang Li,Yong Yu,Weinan Zhang,Tao Kong,Bingyi Kang*

Main category: cs.RO

TL;DR: 本研究提出相机深度模型（CDMs）来提升深度相机的准确性和降噪能力，通过模拟生成高质量数据，使机器人能够更好地利用3D几何信息进行操作，并成功实现了在真实机器人上的泛化，解决了现有方法泛化能力差的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作主要依赖2D颜色信息，泛化能力差。人类则更依赖3D物理属性，因此提出利用深度相机获取3D信息，以提升机器人操作的泛化能力。

Method: 开发了一个包含深度相机噪声模型的神经网络数据引擎，从模拟环境中生成高质量的配对数据，并提出相机深度模型（CDMs）作为深度相机的插件，输入RGB图像和原始深度信号，输出去噪和精确的度量深度。

Result: CDMs在深度预测方面实现了接近模拟级别的准确度，有效缩小了模拟到现实（sim-to-real）的差距。在真实机器人上的实验表明，在原始模拟深度上训练的策略可以直接应用于真实机器人，无需添加噪声或进行现实世界微调，在具有挑战性的长期任务中表现出色。

Conclusion: CDMs通过提升深度相机数据的质量，成功实现了机器人操作策略在模拟和现实世界之间的泛化，为利用模拟数据和3D信息在机器人策略中的应用提供了新的方向。

Abstract: Modern robotic manipulation primarily relies on visual observations in a 2D
color space for skill learning but suffers from poor generalization. In
contrast, humans, living in a 3D world, depend more on physical properties-such
as distance, size, and shape-than on texture when interacting with objects.
Since such 3D geometric information can be acquired from widely available depth
cameras, it appears feasible to endow robots with similar perceptual
capabilities. Our pilot study found that using depth cameras for manipulation
is challenging, primarily due to their limited accuracy and susceptibility to
various types of noise. In this work, we propose Camera Depth Models (CDMs) as
a simple plugin on daily-use depth cameras, which take RGB images and raw depth
signals as input and output denoised, accurate metric depth. To achieve this,
we develop a neural data engine that generates high-quality paired data from
simulation by modeling a depth camera's noise pattern. Our results show that
CDMs achieve nearly simulation-level accuracy in depth prediction, effectively
bridging the sim-to-real gap for manipulation tasks. Notably, our experiments
demonstrate, for the first time, that a policy trained on raw simulated depth,
without the need for adding noise or real-world fine-tuning, generalizes
seamlessly to real-world robots on two challenging long-horizon tasks involving
articulated, reflective, and slender objects, with little to no performance
degradation. We hope our findings will inspire future research in utilizing
simulation data and 3D information in general robot policies.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [434] [A Comparative Study of Controllability, Explainability, and Performance in Dysfluency Detection Models](https://arxiv.org/abs/2509.00058)
*Eric Zhang,Li Wei,Sarah Chen,Michael Wang*

Main category: cs.AI

TL;DR: 该论文比较了四种不同的口吃检测方法（YOLOStutter、FluentNet、UDM 和 SSDM），评估了它们的性能、可控性和可解释性。UDM 在准确性和可解释性之间取得了最佳平衡，而 YOLOStutter 和 FluentNet 则更注重效率和简洁性，但可解释性较差。SSDM 虽然有前景，但在实验中未能完全复现。研究强调了不同方法之间的权衡，并为未来临床口吃建模指明了方向。


<details>
  <summary>Details</summary>
Motivation: 为了满足临床采纳的需求，口吃检测模型不仅需要高准确性，还需要可控性和可解释性。

Method: 对四种代表性的口吃检测方法（YOLO-Stutter、FluentNet、UDM 和 SSDM）进行了系统比较分析，从性能、可控性和可解释性三个维度进行评估。

Result: YOLO-Stutter 和 FluentNet 效率高、简单但透明度有限；UDM 在准确性和临床可解释性方面取得了最佳平衡；SSDM 在实验中未能完全复现。

Conclusion: 研究结果突显了不同口吃检测方法的权衡，并为开发临床上可行的口吃建模方法提供了方向，同时还提供了详细的实现和部署建议。

Abstract: Recent advances in dysfluency detection have introduced a variety of modeling
paradigms, ranging from lightweight object-detection inspired networks
(YOLOStutter) to modular interpretable frameworks (UDM). While performance on
benchmark datasets continues to improve, clinical adoption requires more than
accuracy: models must be controllable and explainable. In this paper, we
present a systematic comparative analysis of four representative
approaches--YOLO-Stutter, FluentNet, UDM, and SSDM--along three dimensions:
performance, controllability, and explainability. Through comprehensive
evaluation on multiple datasets and expert clinician assessment, we find that
YOLO-Stutter and FluentNet provide efficiency and simplicity, but with limited
transparency; UDM achieves the best balance of accuracy and clinical
interpretability; and SSDM, while promising, could not be fully reproduced in
our experiments. Our analysis highlights the trade-offs among competing
approaches and identifies future directions for clinically viable dysfluency
modeling. We also provide detailed implementation insights and practical
deployment considerations for each approach.

</details>


### [435] [Beyond Memorization: Reasoning-Driven Synthesis as a Mitigation Strategy Against Benchmark Contamination](https://arxiv.org/abs/2509.00072)
*Terry Jingchen Zhang,Gopal Dev,Ning Wang,Nicole Ni,Wenyuan Jiang,Yinya Huang,Bernhard Schölkopf,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: LLM评估可能受到数据污染影响，研究人员开发了一个新框架，通过从arXiv论文合成问题来评估LLM的真实推理能力，发现现有模型在知识截止日期后没有显著的性能衰减，并提出多步骤推理是抵御数据污染的有效方法。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的能力时，数据污染的担忧日益增加，这使得静态基准测试所测量的究竟是真正的推理能力还是仅仅是记忆能力受到质疑。

Method: 研究人员使用了一个可无限扩展的框架，直接从arXiv论文中合成研究级问答（QA），利用研究出版物的自然时间结构，通过评估模型在知识截止日期后的性能衰减来检测潜在的数据污染。他们评估了4个前沿模型（每个家族有两个不同知识截止日期的模型），在20,277篇arXiv论文中合成了1,643个多步骤推理问题，涵盖了所有截止日期前后的至少6个月。

Result: 研究结果一致表明，无论模型的大小、开发者或发布日期如何，在知识截止日期附近都没有出现显著的性能衰减。与之前使用直接检索的、基于公共数据的问题并且报告了显著的截止日期后性能衰减的纵向研究进行了比较分析。

Conclusion: 研究人员推测，他们合成流程所需的多步骤推理比浅层记忆更复杂，这有效地抵御了基准测试污染。他们开源了代码和数据集，并倡导通过优先考虑驱动推理的合成来构建基准测试，而不是仅仅定期收集新发布的问题。

Abstract: Capability evaluation of large language models (LLMs) is increasingly
shadowed by rising concerns of data contamination that cast doubts on whether
static benchmarks measure genuine reasoning or mere memorization. We present an
empirical study using an infinitely scalable framework to synthesize
research-level QA directly from arXiv papers, harnessing the natural temporal
structure of research publications where performance decay after knowledge
cutoffs may indicate potential contamination. We evaluated 4 frontier model
represented by 2 models of different knowledge cutoff dates per family on 1,643
multi-step reasoning questions synthesized from 20,277 arXiv papers stratified
over 26 months, covering at least 6 months before and after all cutoff dates.
Our results consistently showed a lack of significant performance decay near
knowledge cutoff dates for models of various sizes, developers, and release
dates. We further performed a comparative analysis with previous longitudinal
studies that reported significant post-cutoff performance decay using directly
retrieved questions based on public data. we hypothesize that the multi-step
reasoning required by our synthesis pipeline offered additional complexity that
goes deeper than shallow memorization, which effectively serves a mitigation
strategy against benchmark contamination. We fully open source our code and
dataset to aid reproducibility and advocate for a paradigm shift that
prioritize reasoning-driven synthesis to construct benchmarks over simply
collecting newly released questions periodically.

</details>


### [436] [Language and Experience: A Computational Model of Social Learning in Complex Tasks](https://arxiv.org/abs/2509.00074)
*Cédric Colas,Tracey Mills,Ben Prystawski,Michael Henry Tessler,Noah Goodman,Jacob Andreas,Joshua Tenenbaum*

Main category: cs.AI

TL;DR: 本研究提出一个计算框架，将语言指导与直接经验相结合，用于模拟人类和社会学习。该框架利用预训练语言模型作为概率模型，实现代理生成和解释语言建议，并在贝叶斯推断中作为证据。通过视频游戏实验，证明了语言指导能促进探索、加速学习，并减少风险。此外，研究还探讨了通过迭代学习实现知识跨代累积，以及人类与模型之间的知识转移，为人类-机器协作学习提供了可能性。


<details>
  <summary>Details</summary>
Motivation: 人类如何结合语言指导和直接经验进行学习，以及AI系统如何实现这一点。

Method: 将预训练语言模型转化为关于人类如何根据其信念分享建议的概率模型，使智能体能够生成建议并解释语言输入作为贝叶斯推断中的证据。通过在10个视频游戏中进行行为实验和模拟。

Result: 语言指导可以塑造探索过程，通过减少风险互动和加速关键发现来加速人类和模型的学习。实现了跨代知识积累和人机知识转移。

Conclusion: 结构化的、与语言兼容的表征可以促进人机协作学习。

Abstract: The ability to combine linguistic guidance from others with direct experience
is central to human development, enabling safe and rapid learning in new
environments. How do people integrate these two sources of knowledge, and how
might AI systems? We present a computational framework that models social
learning as joint probabilistic inference over structured, executable world
models given sensorimotor and linguistic data. We make this possible by turning
a pretrained language model into a probabilistic model of how humans share
advice conditioned on their beliefs, allowing our agents both to generate
advice for others and to interpret linguistic input as evidence during Bayesian
inference. Using behavioral experiments and simulations across 10 video games,
we show how linguistic guidance can shape exploration and accelerate learning
by reducing risky interactions and speeding up key discoveries in both humans
and models. We further explore how knowledge can accumulate across generations
through iterated learning experiments and demonstrate successful knowledge
transfer between humans and models -- revealing how structured,
language-compatible representations might enable human-machine collaborative
learning.

</details>


### [437] [Entropy-Guided Loop: Achieving Reasoning through Uncertainty-Aware Generation](https://arxiv.org/abs/2509.00079)
*Andrew G. A. Correa,Ana C. H de Matos*

Main category: cs.AI

TL;DR: 熵引导精炼是一种低成本、测试时循环，利用代币级不确定性触发单次、有针对性的精炼，以提高小型模型的性能。


<details>
  <summary>Details</summary>
Motivation: 较大的模型通常推理能力更强，但成本更高，延迟更大。需要一种方法来提高小型模型的性能，同时控制成本和延迟。

Method: 提出熵引导精炼（entropy-guided refinement）方法，这是一种在测试时使用的轻量级循环。该方法利用代币级不确定性来触发单次、有针对性的精炼。具体做法是提取 logprobs，计算 top-k 备选代币的香农熵（Shannon entropy），并根据困惑度（perplexity）、最大代币熵和低置信度代币数量应用简单的 OR 逻辑触发器。与仅将熵用于测量或解码的方法不同，该方法将一个包含代币、置信度、备选代币和上下文的紧凑不确定性报告传回模型，以指导纠正性编辑。

Result: 在推理、数学和代码生成等技术查询任务中，使用该方法的小型模型在成本仅为参考模型三分之一的情况下，达到了参考模型 95% 的质量。该方法实现了约 31% 的响应选择性精炼，并将准确率提高了 16 个百分点。该方法在生产部署中，能够在保证质量的同时控制成本，是一种在单次推理和昂贵推理链之间取得平衡的有效方法。

Conclusion: 熵引导精炼是一种有效的折中方案，能够以较低的成本显著提高小型模型的性能，使其在生产环境中具有实际应用价值。

Abstract: Reasoning models often outperform smaller models but at 3--5$\times$ higher
cost and added latency. We present entropy-guided refinement: a lightweight,
test-time loop that uses token-level uncertainty to trigger a single, targeted
refinement pass. We extract logprobs, compute Shannon entropy on top-$k$
alternatives, and apply a simple OR-logic trigger over perplexity, maximum
token entropy, and low-confidence-token count. Unlike approaches that use
entropy only for measurement or decoding, we pass a compact uncertainty report
(tokens, confidences, alternatives, context) back to the model to guide
corrective edits. On representative technical queries across reasoning,
mathematics, and code generation tasks, a small model with our loop approaches
95\% of a reference reasoning model's quality at approximately one-third of the
cost. The method achieves selective refinement on ~31\% of responses while
improving accuracy by 16 percentage points over single-pass inference. We
demonstrate that this uncertainty-aware loop provides an effective middle
ground between single-pass inference and expensive reasoning chains, making it
practical for production deployments where both quality and cost matter.

</details>


### [438] [Analysis of Error Sources in LLM-based Hypothesis Search for Few-Shot Rule Induction](https://arxiv.org/abs/2509.01016)
*Aishni Parab,Hongjing Lu,Ying Nian Wu,Sumit Gulwani*

Main category: cs.AI

TL;DR: LLM驱动的假设搜索框架在少样本规则归纳任务上表现媲美人类，优于直接程序生成方法。


<details>
  <summary>Details</summary>
Motivation: 比较LLM驱动的假设搜索框架与直接程序生成方法在少样本规则归纳任务上的表现，并分析了其中的瓶颈。

Method: 将LLM驱动的假设搜索框架与直接程序生成方法在少样本规则归纳任务上进行对比。

Result: LLM驱动的假设搜索框架表现与人类相当，而直接程序生成方法表现明显落后。

Conclusion: LLM驱动的假设搜索框架在模拟归纳推理方面具有潜力，但也面临着提高系统效率的挑战。

Abstract: Inductive reasoning enables humans to infer abstract rules from limited
examples and apply them to novel situations. In this work, we compare an
LLM-based hypothesis search framework with direct program generation approaches
on few-shot rule induction tasks. Our findings show that hypothesis search
achieves performance comparable to humans, while direct program generation
falls notably behind. An error analysis reveals key bottlenecks in hypothesis
generation and suggests directions for advancing program induction methods.
Overall, this paper underscores the potential of LLM-based hypothesis search
for modeling inductive reasoning and the challenges in building more efficient
systems.

</details>


### [439] [Wrong Face, Wrong Move: The Social Dynamics of Emotion Misperception in Agent-Based Models](https://arxiv.org/abs/2509.00080)
*David Freire-Obregón*

Main category: cs.AI

TL;DR: 研究不同感知准确性对社会行为的影响：低准确性导致信任度下降、情感瓦解和社会组织混乱，高准确性则能形成稳固的情感集群和抵御干扰的能力。


<details>
  <summary>Details</summary>
Motivation: 研究感知准确性对社会行为的影响，特别是情感识别的准确性如何影响群体互动。

Method: 在2D格子中模拟具有不同情感分类器准确性的个体，根据感知到的情感（而非真实情感）进行移动，并进行异质/同质群体和情感冲击实验。

Result: 低准确性分类器导致信任度下降、情感瓦解（悲伤）和社会组织混乱；高准确性分类器则形成稳固的情感集群和抵御干扰的能力。即使在无情绪干扰的情况下，感知错误也会导致社会分离和内聚力瓦解。

Conclusion: 情感识别中的偏差或不精确会严重扭曲社会过程并破坏情感整合。

Abstract: The ability of humans to detect and respond to others' emotions is
fundamental to understanding social behavior. Here, agents are instantiated
with emotion classifiers of varying accuracy to study the impact of perceptual
accuracy on emergent emotional and spatial behavior. Agents are visually
represented with face photos from the KDEF database and endowed with one of
three classifiers trained on the JAFFE (poor), CK+ (medium), or KDEF (high)
datasets. Agents communicate locally on a 2D toroidal lattice, perceiving
neighbors' emotional state based on their classifier and responding with
movement toward perceived positive emotions and away from perceived negative
emotions. Note that the agents respond to perceived, instead of ground-truth,
emotions, introducing systematic misperception and frustration. A battery of
experiments is carried out on homogeneous and heterogeneous populations and
scenarios with repeated emotional shocks. Results show that low-accuracy
classifiers on the part of the agent reliably result in diminished trust,
emotional disintegration into sadness, and disordered social organization. By
contrast, the agent that develops high accuracy develops hardy emotional
clusters and resilience to emotional disruptions. Even in emotionally neutral
scenarios, misperception is enough to generate segregation and disintegration
of cohesion. These findings underscore the fact that biases or imprecision in
emotion recognition may significantly warp social processes and disrupt
emotional integration.

</details>


### [440] [Ensemble Debates with Local Large Language Models for AI Alignment](https://arxiv.org/abs/2509.00091)
*Ephraiem Sarabamoun*

Main category: cs.AI

TL;DR: 本地开源模型集成辩论可以提高LLM与人类价值观的一致性，优于单个模型。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在高风险决策中的作用日益增强，与人类价值观的一致性至关重要，但对专有API的依赖限制了可复现性和广泛参与。

Method: 研究了本地开源集成辩论是否能提高与对齐相关的推理能力，在15个场景和5种集成配置中进行了150场辩论。

Result: 集成模型在7分制评估中平均得分3.48，优于单个模型基线（3.13），在推理深度（+19.4%）和论证质量（+34.1%）方面提升尤为显著，尤其是在真实性和人类增强方面。

Conclusion: 本地开源集成辩论为基于集成的对齐评估提供了一个可访问且可复现的基础。

Abstract: As large language models (LLMs) take on greater roles in high-stakes
decisions, alignment with human values is essential. Reliance on proprietary
APIs limits reproducibility and broad participation. We study whether local
open-source ensemble debates can improve alignmentoriented reasoning. Across
150 debates spanning 15 scenarios and five ensemble configurations, ensembles
outperform single-model baselines on a 7-point rubric (overall: 3.48 vs. 3.13),
with the largest gains in reasoning depth (+19.4%) and argument quality
(+34.1%). Improvements are strongest for truthfulness (+1.25 points) and human
enhancement (+0.80). We provide code, prompts, and a debate data set, providing
an accessible and reproducible foundation for ensemble-based alignment
evaluation.

</details>


### [441] [MODE: Mixture of Document Experts for RAG](https://arxiv.org/abs/2509.00100)
*Rahul Anand*

Main category: cs.AI

TL;DR: MODE是一种轻量级的检索增强生成（RAG）方法，通过聚类文档替代大规模向量搜索，适用于中小型领域特定语料库，能在保证检索质量的同时降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成（RAG）方法通常依赖大型向量数据库和针对大规模语料库进行微调的交叉编码器，这对于中小型、领域特定的数据集来说可能过于复杂和资源密集。

Method: MODE（Mixture of Document Experts）提出了一种轻量级的替代方案，它用聚类和路由检索取代了细粒度的最近邻搜索。具体来说，文档首先被嵌入并分组到语义上连贯的簇中，然后用缓存的质心来表示这些簇。在查询时，系统会将查询路由到最相关的质心（或多个质心），并且只在这些簇内检索相关上下文。这种方法无需外部向量数据库基础设施和重排序步骤，从而有效降低了延迟。

Result: 在HotpotQA和SQuAD数据集（包含100-500个文本块）上进行的实验表明，MODE在答案质量方面达到了与密集检索基线相当或更优的性能，同时显著减少了端到端的检索时间。此外，消融研究表明，聚类的粒度和多簇路由能够有效控制召回率和精确率之间的权衡，并且更紧密的聚类能够提高下游任务的准确性。

Conclusion: MODE为中小型语料库提供了一种实用且高效的解决方案，特别是在对简单性、速度和主题 fokus 有要求的场景下。它通过创新的聚类和路由机制，有效解决了传统RAG方法在大规模语料库上的局限性。

Abstract: Retrieval-Augmented Generation (RAG) often relies on large vector databases
and cross-encoders tuned for large-scale corpora, which can be excessive for
small, domain-specific collections. We present MODE (Mixture of Document
Experts), a lightweight alternative that replaces fine-grained nearest-neighbor
search with cluster-and-route retrieval. Documents are embedded, grouped into
semantically coherent clusters, and represented by cached centroids. At query
time, we route to the top centroid(s) and retrieve context only within those
clusters, eliminating external vector-database infrastructure and reranking
while keeping latency low. On HotpotQA and SQuAD corpora with 100-500 chunks,
MODE matches or exceeds a dense-retrieval baseline in answer quality while
reducing end-to-end retrieval time. Ablations show that cluster granularity and
multi-cluster routing control the recall/precision trade-off, and that tighter
clusters improve downstream accuracy. MODE offers a practical recipe for small
and medium corpora where simplicity, speed, and topical focus matter.

</details>


### [442] [Virtual Group Knowledge and Group Belief in Topological Evidence Models (Extended Version)](https://arxiv.org/abs/2509.00184)
*Alexandru Baltag,Malvin Gattinger,Djanira Gomes*

Main category: cs.AI

TL;DR: The paper studies group knowledge and belief in multi-agent systems using topological semantics, axiomatizing their logic and extending it with dynamic evidence-sharing operators.


<details>
  <summary>Details</summary>
Motivation: To extend existing individual-based evidence models to groups, incorporating notions of group knowledge and belief.

Method: The study extends topological semantics of evidence-based belief and fallible knowledge from individuals to groups. It axiomatizes the logic of group evidence (hard and soft) and a fragment concerning group knowledge and belief. Additionally, it incorporates dynamic evidence-sharing operators and axiomatizes the resulting logics.

Result: Complete axiomatization and decidability are shown for the logic of group evidence and its fragment (group knowledge and belief). The extension with dynamic evidence-sharing operators results in logics that are co-expressive with their static bases.

Conclusion: The paper successfully axiomatizes and proves decidability for logics of group knowledge and belief, and their dynamic extensions, providing a formal framework for understanding group reasoning in multi-agent systems.

Abstract: We study notions of (virtual) group knowledge and group belief within
multi-agent evidence models, obtained by extending the topological semantics of
evidence-based belief and fallible knowledge from individuals to groups. We
completely axiomatize and show the decidability of the logic of ("hard" and
"soft") group evidence, and do the same for an especially interesting fragment
of it: the logic of group knowledge and group belief. We also extend these
languages with dynamic evidence-sharing operators, and completely axiomatize
the corresponding logics, showing that they are co-expressive with their static
bases.

</details>


### [443] [Adaptive Monitoring and Real-World Evaluation of Agentic AI Systems](https://arxiv.org/abs/2509.00115)
*Manish Shukla*

Main category: cs.AI

TL;DR: 该论文提出了一个名为AMDM的算法，用于评估和监控多智能体AI系统，重点关注人类中心和经济指标，并提供了算法实现和实证研究。


<details>
  <summary>Details</summary>
Motivation: 早期研究未能充分考虑多智能体AI系统的技术指标之外的人类中心和经济指标，本研究旨在填补这一空白，提供一种能够全面监控这些复杂系统的算法。

Method: 提出并实现了一个自适应多维度监控（AMDM）算法，该算法能够规范化异构指标，应用指数加权移动平均阈值，并通过马氏距离进行联合异常检测。

Result: AMDM算法将模拟目标漂移的异常检测延迟从12.3秒减少到5.6秒，并将误报率从4.5%降低到0.9%。论文还提供了比较表、ROC/PR曲线，并重新分析了案例研究以揭示遗漏的指标。

Conclusion: AMDM算法能够有效且高效地监控多智能体AI系统，显著提高了异常检测的准确性和速度，为未来高风险领域中AI系统的评估和部署提供了重要支持。

Abstract: Agentic artificial intelligence (AI) -- multi-agent systems that combine
large language models with external tools and autonomous planning -- are
rapidly transitioning from research laboratories into high-stakes domains. Our
earlier "Basic" paper introduced a five-axis framework and proposed preliminary
metrics such as goal drift and harm reduction but did not provide an
algorithmic instantiation or empirical evidence. This "Advanced" sequel fills
that gap. First, we revisit recent benchmarks and industrial deployments to
show that technical metrics still dominate evaluations: a systematic review of
84 papers from 2023--2025 found that 83% report capability metrics while only
30% consider human-centred or economic axes [2]. Second, we formalise an
Adaptive Multi-Dimensional Monitoring (AMDM) algorithm that normalises
heterogeneous metrics, applies per-axis exponentially weighted moving-average
thresholds and performs joint anomaly detection via the Mahalanobis distance.
Third, we conduct simulations and real-world experiments. AMDM cuts
anomaly-detection latency from 12.3 s to 5.6 s on simulated goal drift and
reduces false-positive rates from 4.5% to 0.9% compared with static thresholds.
We present a comparison table and ROC/PR curves, and we reanalyse case studies
to surface missing metrics. Code, data and a reproducibility checklist
accompany this paper to facilitate replication.

</details>


### [444] [Neuro-Symbolic Predictive Process Monitoring](https://arxiv.org/abs/2509.00834)
*Axel Mezini,Elena Umili,Ivan Donadello,Fabrizio Maria Maggi,Matteo Mancanelli,Fabio Patrizi*

Main category: cs.AI

TL;DR: 该论文提出了一种结合数据驱动学习和时序逻辑先验知识的神经符号预测性流程监控（PPM）方法，用于解决业务流程管理（BPM）中的后缀预测问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在后缀预测中未能满足逻辑约束，因为缺乏领域知识的显式集成。

Method: 提出了一种将有限迹上的线性时序逻辑（LTLf）纳入自回归序列预测器训练过程的新颖方法，通过使用LTLf语义的软近似和Gumbel-Softmax技巧定义可微分的逻辑损失函数，并与标准预测损失相结合。

Result: 在三个真实世界数据集上的实验评估表明，该方法提高了后缀预测的准确性和时序约束的符合性。

Conclusion: 所提出的神经符号框架不仅提高了BPM中的后缀预测性能，而且适用于任何符号序列生成任务，并推动了神经符号AI的发展。

Abstract: This paper addresses the problem of suffix prediction in Business Process
Management (BPM) by proposing a Neuro-Symbolic Predictive Process Monitoring
(PPM) approach that integrates data-driven learning with temporal logic-based
prior knowledge. While recent approaches leverage deep learning models for
suffix prediction, they often fail to satisfy even basic logical constraints
due to the absence of explicit integration of domain knowledge during training.
We propose a novel method to incorporate Linear Temporal Logic over finite
traces (LTLf) into the training process of autoregressive sequence predictors.
Our approach introduces a differentiable logical loss function, defined using a
soft approximation of LTLf semantics and the Gumbel-Softmax trick, which can be
combined with standard predictive losses. This ensures the model learns to
generate suffixes that are both accurate and logically consistent. Experimental
evaluation on three real-world datasets shows that our method improves suffix
prediction accuracy and compliance with temporal constraints. We also introduce
two variants of the logic loss (local and global) and demonstrate their
effectiveness under noisy and realistic settings. While developed in the
context of BPM, our framework is applicable to any symbolic sequence generation
task and contributes toward advancing Neuro-Symbolic AI.

</details>


### [445] [Know When to Explore: Difficulty-Aware Certainty as a Guide for LLM Reinforcement Learning](https://arxiv.org/abs/2509.00125)
*Ang Li,Zhihang Yuan,Yang Zhang,Shouda Liu,Yisen Wang*

Main category: cs.AI

TL;DR: RLVF 依赖于稀疏的、基于结果的奖励，这阻碍了 LLM 推理能力的有效学习。DACE 算法利用 LLM 的自我确定性来动态平衡探索-利用权衡，根据任务难度调整内在奖励，以鼓励探索或学习效率。在数学推理基准测试中，DACE 显著优于基线，提高了准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: RLVF 依赖于稀疏的、基于结果的奖励，这阻碍了 LLM 推理能力的有效学习，因为它无法区分高质量和低效的解决方案，也无法从不同类型的失败中有效学习。

Method: DACE 算法利用 LLM 的自我确定性来动态平衡探索-利用权衡。它根据策略的成功率在线评估任务难度，然后使用此信号来调整内在奖励：对于模型仍在挣扎的困难任务，DACE 通过惩罚高确定性来鼓励探索；对于更简单的任务，它通过奖励高确定性来鼓励学习效率。

Result: DACE 在具有挑战性的数学推理基准（AIME、MATH）上进行了实验，结果显示 DACE 的性能明显优于强有力的基线。DACE 训练的模型不仅准确性更高，而且在扩展测试时间计算时表现出更鲁棒的性能。

Conclusion: DACE 是一种新颖的 RL 算法，它利用 LLM 的自我确定性来动态平衡探索-利用权衡，从而提高 LLM 的推理能力。实验证明 DACE 在提高准确性和鲁棒性方面优于其他方法。

Abstract: Reinforcement Learning with Verifiable Feedback (RLVF) has become a key
technique for enhancing the reasoning abilities of Large Language Models
(LLMs). However, its reliance on sparse, outcome based rewards, which only
indicate if a final answer is correct or not, fails to provide granular
guidance on the reasoning process itself. This limitation hinders efficient
learning, as the model cannot distinguish between high quality and inefficient
solutions, nor can it learn effectively from different types of failures. To
address this, we observe that an LLMs self-certainty often correlates with task
difficulty and solution quality. We introduce Difficulty Aware Certainty guided
Exploration (DACE), a novel RL algorithm that leverages this insight to
dynamically balance the exploration exploitation trade-off. DACE assesses task
difficulty online based on the policys success rate. It then uses this signal
to modulate an intrinsic reward: for difficult tasks where the model is
struggling, DACE encourages exploration by penalizing high certainty; for
easier tasks, it encourages learning efficiency by rewarding high certainty.
Experiments on challenging mathematical reasoning benchmarks (AIME, MATH) show
that DACE significantly outperforms strong baselines. The DACE-trained models
not only achieve higher accuracy but also demonstrate more robust performance
when scaling test-time compute, validating that our adaptive approach fosters
effective exploration without sacrificing precision.

</details>


### [446] [HiVA: Self-organized Hierarchical Variable Agent via Goal-driven Semantic-Topological Evolution](https://arxiv.org/abs/2509.00189)
*Jinzhou Tang,Jusheng Zhang,Qinhan Lv,Sidi Liu,Jing Yang,Chengpei Tang,Keze Wang*

Main category: cs.AI

TL;DR: HiVA框架通过STEV算法将智能体工作流建模为自组织图，并在各种基准测试中提高了任务准确性和资源效率。


<details>
  <summary>Details</summary>
Motivation: 现有自主代理范式在可重用性和灵活性之间存在权衡，HiVA旨在解决这个问题。

Method: HiVA使用STEV算法，通过文本梯度优化混合语义-拓扑空间，实现前向路由、诊断梯度生成和协同更新。

Result: HiVA在对话、编码、长上下文问答、数学和智能体基准测试中，任务准确性提高了5-10%，并提高了资源效率。

Conclusion: HiVA框架在自主任务执行方面是有效的，能够应对未知环境并提高性能。

Abstract: Autonomous agents play a crucial role in advancing Artificial General
Intelligence, enabling problem decomposition and tool orchestration through
Large Language Models (LLMs). However, existing paradigms face a critical
trade-off. On one hand, reusable fixed workflows require manual reconfiguration
upon environmental changes; on the other hand, flexible reactive loops fail to
distill reasoning progress into transferable structures. We introduce
Hierarchical Variable Agent (HiVA), a novel framework modeling agentic
workflows as self-organized graphs with the Semantic-Topological Evolution
(STEV) algorithm, which optimizes hybrid semantic-topological spaces using
textual gradients as discrete-domain surrogates for backpropagation. The
iterative process comprises Multi-Armed Bandit-infused forward routing,
diagnostic gradient generation from environmental feedback, and coordinated
updates that co-evolve individual semantics and topology for collective
optimization in unknown environments. Experiments on dialogue, coding,
Long-context Q&A, mathematical, and agentic benchmarks demonstrate improvements
of 5-10% in task accuracy and enhanced resource efficiency over existing
baselines, establishing HiVA's effectiveness in autonomous task execution.

</details>


### [447] [Optimizing Health Coverage in Ethiopia: A Learning-augmented Approach and Persistent Proportionality Under an Online Budget](https://arxiv.org/abs/2509.00135)
*Davin Choo,Yohai Trabelsi,Fentabil Getnet,Samson Warkaye Lamma,Wondesen Nigatu,Kasahun Sime,Lisa Matay,Milind Tambe,Stéphane Verguet*

Main category: cs.AI

TL;DR:  Ethiopian Ministry of Health uses HARP tool for optimizing health post prioritization to achieve universal health coverage, facing budget constraints and competing priorities. HARP is a decision-support optimization framework for sequential facility planning, aiming to maximize population coverage under budget uncertainty while meeting proportionality targets. Two algorithms are proposed: a learning-augmented approach and a greedy algorithm for multi-step planning, both with strong worst-case approximation guarantees. The method's efficacy was demonstrated on three Ethiopian regions.


<details>
  <summary>Details</summary>
Motivation: To optimize the prioritization of health post strengthening across Ethiopian regions to expand access to essential healthcare services, addressing limited budgets and competing priorities in alignment with the UN's Sustainable Development Goal 3.

Method: Developed a tool named Health Access Resource Planner (HARP) based on a principled decision-support optimization framework for sequential facility planning. Proposed two algorithms: a learning-augmented approach to improve single-step expert recommendations, and a greedy algorithm for multi-step planning. Both algorithms have strong worst-case approximation guarantees.

Result: Demonstrated the empirical efficacy of the HARP tool and its algorithms on three regions in Ethiopia across various planning scenarios, in collaboration with the Ethiopian Public Health Institute and Ministry of Health.

Conclusion: The HARP tool and its associated algorithms provide an effective framework for optimizing health post planning and resource allocation in Ethiopia, contributing to the goal of universal health coverage amidst budget uncertainties and competing priorities.

Abstract: As part of nationwide efforts aligned with the United Nations' Sustainable
Development Goal 3 on Universal Health Coverage, Ethiopia's Ministry of Health
is strengthening health posts to expand access to essential healthcare
services. However, only a fraction of this health system strengthening effort
can be implemented each year due to limited budgets and other competing
priorities, thus the need for an optimization framework to guide prioritization
across the regions of Ethiopia. In this paper, we develop a tool, Health Access
Resource Planner (HARP), based on a principled decision-support optimization
framework for sequential facility planning that aims to maximize population
coverage under budget uncertainty while satisfying region-specific
proportionality targets at every time step. We then propose two algorithms: (i)
a learning-augmented approach that improves upon expert recommendations at any
single-step; and (ii) a greedy algorithm for multi-step planning, both with
strong worst-case approximation estimation. In collaboration with the Ethiopian
Public Health Institute and Ministry of Health, we demonstrated the empirical
efficacy of our method on three regions across various planning scenarios.

</details>


### [448] [Robust Deep Monte Carlo Counterfactual Regret Minimization: Addressing Theoretical Risks in Neural Fictitious Self-Play](https://arxiv.org/abs/2509.00923)
*Zakaria El Jaafari*

Main category: cs.AI

TL;DR: 本论文分析了神经MCCFR在不同规模游戏中的表现，并提出了一个自适应框架来选择性地部署组件。研究表明，理论风险（如非平稳目标分布变化、动作支持崩溃、方差爆炸和暖启动偏差）的表现模式与游戏规模相关，需要针对不同规模的游戏采取不同的缓解策略。提出的鲁棒深度MCCFR框架包含目标网络、延迟更新、均匀探索混合、方差感知训练目标和全面的诊断监控。


<details>
  <summary>Details</summary>
Motivation: 神经MCCFR在解决扩展形式博弈中面临与规模相关的挑战，这些挑战在不同复杂度的游戏中表现不同。因此，有必要分析神经MCCFR组件的有效性如何随游戏规模变化，并提出一个自适应框架来选择性地部署组件。

Method: 本研究首先进行了理论分析，识别了神经MCCFR中的风险（如非平稳目标分布变化、动作支持崩溃、方差爆炸和暖启动偏差），并探讨了这些风险与游戏规模的关系。然后，提出了一种名为“鲁棒深度MCCFR”的框架，该框架包含目标网络、延迟更新、均匀探索混合、方差感知训练目标和诊断监控等组件。最后，通过在Kuhn扑克和Leduc扑克上的消融研究来验证所提出框架的有效性。

Result: 在Kuhn扑克上，最佳配置实现了0.0628的最终可利用性，比经典框架（0.156）提高了60%。在更复杂的Leduc扑克上，选择性组件使用实现了0.2386的可利用性，比经典框架（0.3703）提高了23.5%，这表明仔细选择组件比全面缓解更为重要。

Conclusion: 本研究对神经MCCFR中的风险进行了理论分析，并提出了一个包含多种缓解策略的鲁棒深度MCCFR框架。实验结果表明，组件的有效性与游戏规模相关，并且在处理更大、更复杂的游戏时，选择性地部署组件比应用所有缓解策略更为重要。该研究为在更大规模游戏中使用神经MCCFR提供了实用的指导方针。

Abstract: Monte Carlo Counterfactual Regret Minimization (MCCFR) has emerged as a
cornerstone algorithm for solving extensive-form games, but its integration
with deep neural networks introduces scale-dependent challenges that manifest
differently across game complexities. This paper presents a comprehensive
analysis of how neural MCCFR component effectiveness varies with game scale and
proposes an adaptive framework for selective component deployment. We identify
that theoretical risks such as nonstationary target distribution shifts, action
support collapse, variance explosion, and warm-starting bias have
scale-dependent manifestation patterns, requiring different mitigation
strategies for small versus large games. Our proposed Robust Deep MCCFR
framework incorporates target networks with delayed updates, uniform
exploration mixing, variance-aware training objectives, and comprehensive
diagnostic monitoring. Through systematic ablation studies on Kuhn and Leduc
Poker, we demonstrate scale-dependent component effectiveness and identify
critical component interactions. The best configuration achieves final
exploitability of 0.0628 on Kuhn Poker, representing a 60% improvement over the
classical framework (0.156). On the more complex Leduc Poker domain, selective
component usage achieves exploitability of 0.2386, a 23.5% improvement over the
classical framework (0.3703) and highlighting the importance of careful
component selection over comprehensive mitigation. Our contributions include:
(1) a formal theoretical analysis of risks in neural MCCFR, (2) a principled
mitigation framework with convergence guarantees, (3) comprehensive multi-scale
experimental validation revealing scale-dependent component interactions, and
(4) practical guidelines for deployment in larger games.

</details>


### [449] [Universal Deep Research: Bring Your Own Model and Strategy](https://arxiv.org/abs/2509.00244)
*Peter Belcak,Pavlo Molchanov*

Main category: cs.AI

TL;DR: UDR是一个通用的研究代理系统，允许用户自定义研究策略，而无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 现有深度研究代理系统大多是硬编码的，只能执行特定的研究策略。

Method: UDR是一个通用系统，它封装了任何语言模型，并允许用户创建、编辑和精炼自定义的深度研究策略。

Result: UDR展示了其通用性，提供了最小化、扩展化和密集化的研究策略示例，并附带用户界面以方便实验。

Conclusion: UDR能够让用户无需额外训练或微调，即可创建、编辑和精炼完全自定义的深度研究策略。

Abstract: Deep research tools are among the most impactful and most commonly
encountered agentic systems today. We observe, however, that each deep research
agent introduced so far is hard-coded to carry out a particular research
strategy using a fixed choice of tools. We introduce Universal Deep Research
(UDR), a generalist agentic system that wraps around any language model and
enables the user to create, edit, and refine their own entirely custom deep
research strategies without any need for additional training or finetuning. To
showcase the generality of our system, we equip UDR with example minimal,
expansive, and intensive research strategies, and provide a user interface to
facilitate experimentation with the system.

</details>


### [450] [Instruction-Level Weight Shaping: A Framework for Self-Improving AI Agents](https://arxiv.org/abs/2509.00251)
*Rimom Costa*

Main category: cs.AI

TL;DR: LLMs are static, and updates via RAG or fine-tuning have drawbacks. ILWS proposes using curated system instructions as pseudo-parameters, updated via reflection and user feedback. This method improves LLM performance, reducing latency and hallucinations, and shows significant gains in enterprise support scenarios.


<details>
  <summary>Details</summary>
Motivation: LLMs are static after pre-training, and existing methods for updating knowledge (RAG, fine-tuning) have significant drawbacks like latency, engineering overhead, catastrophic forgetting, and cost. There's a need for a more efficient and effective way to adapt LLMs to new information and user feedback.

Method: The paper proposes Instruction-Level Weight Shaping (ILWS), where system instructions act as external, auditable pseudo-parameters. These instructions are updated after each session through a 'Reflection Engine' that analyzes conversation traces to identify reasoning successes and failures. The engine proposes 'deltas' (changes) to instructions, user preferences, and tools. These deltas are version-controlled, evaluated with user ratings, auto-repaired, and rolled back if they repeatedly fail. Periodically, improvements are distilled into model parameters through synthetic datasets, without downtime. ILWS aims to mimic low-rank shaping in transformers at the instruction level.

Result: ILWS demonstrated significant improvements in enterprise support, increasing throughput by 2.4-5.0x and reducing audited hallucinations by approximately 80% compared to a static baseline. In an Adobe Commerce Cloud pilot, it achieved 4-5x more tickets per hour and reduced time per ticket by about 80%, with autonomous instruction updates and tool synthesis.

Conclusion: ILWS offers a novel approach to continuously adapt and improve LLMs by treating system instructions as updatable pseudo-parameters. This method overcomes the limitations of RAG and fine-tuning, offering better performance, lower latency, and improved governance. Its success in enterprise support and potential for dynamic domains like legal, medical, and engineering highlights its value for adaptive reasoning, tool creation, and low-latency applications.

Abstract: Large language models (LLMs) are fluent but largely static after
pre-training; new or shifting knowledge is typically added with
retrieval-augmented generation (RAG) or fine-tuning. RAG raises latency and
engineering overhead and often fails to integrate facts; prompt engineering is
brittle and can conflict with prior knowledge; fine-tuning is costly and risks
catastrophic forgetting. We propose Instruction-Level Weight Shaping (ILWS):
curated system instructions act as external, auditable pseudo-parameters
updated after each session via reflection and user feedback. A Reflection
Engine inspects conversation traces, diagnoses reasoning successes and
failures, and proposes typed deltas $\Delta K=(\Delta S,\Delta U,\Delta T)$
over instructions, user preferences, and tools. Deltas are version-controlled,
evaluated with a sliding window of 1-5 star ratings, auto-repaired on first
failure, and rolled back on repeated failure. When an edit budget crosses a
threshold, the agent compiles a rating-weighted synthetic set and distills
matured instruction-space gains into parameters, converting prompt-space
improvements into weight-space without downtime. ILWS makes explicit the
low-rank shaping induced by context in transformer blocks, preserves
governance, and removes per-call retrieval. In enterprise support it increased
throughput 2.4-5.0x and cut audited hallucinations by about 80% versus a frozen
baseline. In an Adobe Commerce Cloud proof of concept "L0 Support", it achieved
4-5x more tickets per hour and about 80% lower time per ticket, with autonomous
instruction updates and optional tool synthesis. Because ILWS operates at the
instruction layer until controlled distillation, it generalizes to dynamic
domains (legal, medical, engineering) requiring adaptive reasoning, tool
creation, and low-latency deployment.

</details>


### [451] [Symbolic Planning and Multi-Agent Path Finding in Extremely Dense Environments with Movable Obstacles](https://arxiv.org/abs/2509.01022)
*Bo Fu,Zhe Chen,Rahul Chandan,Alex Barbosa,Michael Caldara,Joey Durham,Federico Pecora*

Main category: cs.AI

TL;DR: Block Rearrangement Problem (BRaP) is introduced for warehouse management, involving rearranging storage blocks in dense grids. Five search-based algorithms leveraging graph search, classical planning, multi-agent pathfinding, and expert heuristics are proposed and empirically evaluated for plan quality and scalability. The methods show efficiency in planning for deeply buried blocks in large grids (up to 80x80) despite exponential search space size.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the Block Rearrangement Problem (BRaP), a challenge in warehouse management that requires rearranging storage blocks within dense grids to reach a target configuration.

Method: The BRaP is formally defined as a graph search problem. Five search-based algorithms are proposed, drawing inspiration from sliding puzzle problems. These algorithms utilize techniques such as joint configuration space search, classical planning, multi-agent pathfinding, and expert heuristics.

Result: The five proposed approaches were empirically evaluated for their plan quality and scalability. The results demonstrate that the methods are efficient in generating rearrangement plans, even for deeply buried blocks in large grids (up to 80x80), despite the exponential growth of the search space with the number of blocks.

Conclusion: The developed methods are effective and scalable for solving the Block Rearrangement Problem in warehouse management, efficiently handling complex scenarios with deeply buried blocks in large-scale grids.

Abstract: We introduce the Block Rearrangement Problem (BRaP), a challenging component
of large warehouse management which involves rearranging storage blocks within
dense grids to achieve a target state. We formally define the BRaP as a graph
search problem. Building on intuitions from sliding puzzle problems, we propose
five search-based solution algorithms, leveraging joint configuration space
search, classical planning, multi-agent pathfinding, and expert heuristics. We
evaluate the five approaches empirically for plan quality and scalability.
Despite the exponential relation between search space size and block number,
our methods demonstrate efficiency in creating rearrangement plans for deeply
buried blocks in up to 80x80 grids.

</details>


### [452] [SHERPA: A Model-Driven Framework for Large Language Model Execution](https://arxiv.org/abs/2509.00272)
*Boqi Chen,Kua Chen,José Antonio Hernández López,Gunter Mussbacher,Dániel Varró,Amir Feizpour*

Main category: cs.AI

TL;DR: SHERPA是一个模型驱动的框架，通过将领域特定最佳实践整合到分层状态机中，来提高LLM在复杂任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM能力强大，但在需要领域特定最佳实践的复杂任务中，它们缺乏结构化推理能力，而这些实践通常在训练数据中不可用。现有的多步提示方法缺乏控制LLM行为的通用机制。

Method: SHERPA通过使用状态机来构建LLM的执行过程，并允许通过规则或基于机器学习（包括LLM）的决策来实现更细粒度的行为控制。

Result: SHERPA在代码生成、类名生成和问答等多种任务上表现出色，能够复制先前的方法并进一步提高性能。通过与没有状态机的基线方法进行比较，证明了精心设计的状态机显著提高了LLM输出的质量，尤其是在那些具有成熟的最佳实践但缺乏LLM训练数据的复杂任务中。

Conclusion: SHERPA框架通过整合分层状态机和领域特定最佳实践，有效地解决了LLM在复杂任务中的结构化推理和行为控制问题，并展示了其在多项任务上的优越性能。

Abstract: Recently, large language models (LLMs) have achieved widespread application
across various fields. Despite their impressive capabilities, LLMs suffer from
a lack of structured reasoning ability, particularly for complex tasks
requiring domain-specific best practices, which are often unavailable in the
training data. Although multi-step prompting methods incorporating human best
practices, such as chain-of-thought and tree-of-thought, have gained
popularity, they lack a general mechanism to control LLM behavior. In this
paper, we propose SHERPA, a model-driven framework to improve the LLM
performance on complex tasks by explicitly incorporating domain-specific best
practices into hierarchical state machines. By structuring the LLM execution
processes using state machines, SHERPA enables more fine-grained control over
their behavior via rules or decisions driven by machine learning-based
approaches, including LLMs. We show that SHERPA is applicable to a wide variety
of tasks-specifically, code generation, class name generation, and question
answering-replicating previously proposed approaches while further improving
the performance. We demonstrate the effectiveness of SHERPA for the
aforementioned tasks using various LLMs. Our systematic evaluation compares
different state machine configurations against baseline approaches without
state machines. Results show that integrating well-designed state machines
significantly improves the quality of LLM outputs, and is particularly
beneficial for complex tasks with well-established human best practices but
lacking data used for training LLMs.

</details>


### [453] [Question-to-Knowledge: Multi-Agent Generation of Inspectable Facts for Product Mapping](https://arxiv.org/abs/2509.01182)
*Wonduk Seo,Taesub Shin,Hyunjin An,Dokyun Kim,Seunghyun Lee*

Main category: cs.AI

TL;DR: Q2K是一个利用大型语言模型（LLM）进行SKU映射的多智能体框架，通过生成问题、网络搜索和重用推理来提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决电子商务中由于缺少明确标识符和产品名称差异大而导致的SKU识别难题，克服基于规则和关键词相似性的方法的局限性。

Method: Q2K框架包含一个推理智能体（生成问题）、一个知识智能体（网络搜索）和一个去重智能体（重用推理），并辅以人工干预机制。

Result: 在真实消费品数据集上的实验表明，Q2K的准确性和鲁棒性优于现有方法，尤其在处理捆绑包识别和品牌来源歧义方面。

Conclusion: Q2K通过重用检索到的推理来平衡准确性和效率，提供了一个可扩展且可解释的产品集成解决方案。

Abstract: Identifying whether two product listings refer to the same Stock Keeping Unit
(SKU) is a persistent challenge in ecommerce, especially when explicit
identifiers are missing and product names vary widely across platforms. Rule
based heuristics and keyword similarity often misclassify products by
overlooking subtle distinctions in brand, specification, or bundle
configuration. To overcome these limitations, we propose Question to Knowledge
(Q2K), a multi agent framework that leverages Large Language Models (LLMs) for
reliable SKU mapping. Q2K integrates: (1) a Reasoning Agent that generates
targeted disambiguation questions, (2) a Knowledge Agent that resolves them via
focused web searches, and (3) a Deduplication Agent that reuses validated
reasoning traces to reduce redundancy and ensure consistency. A human in the
loop mechanism further refines uncertain cases. Experiments on real world
consumer goods datasets show that Q2K surpasses strong baselines, achieving
higher accuracy and robustness in difficult scenarios such as bundle
identification and brand origin disambiguation. By reusing retrieved reasoning
instead of issuing repeated searches, Q2K balances accuracy with efficiency,
offering a scalable and interpretable solution for product integration.

</details>


### [454] [SIGMUS: Semantic Integration for Knowledge Graphs in Multimodal Urban Spaces](https://arxiv.org/abs/2509.00287)
*Brian Wang,Mani Srivastava*

Main category: cs.AI

TL;DR: SIGMUS是一个利用大型语言模型（LLMs）整合城市多模态传感器数据的系统，通过构建知识图谱来识别和关联事件及其证据，解决了多源异构数据整合的挑战。


<details>
  <summary>Details</summary>
Motivation: 现代城市中的多模态传感器数据为识别和推理城市事件（如紧急情况、社会事件、自然灾害）提供了巨大潜力，但数据分散且难以整合，需要人工进行关系识别和组件理解，这阻碍了对事件原因的识别和未来趋势的预测。

Method: SIGMUS系统利用大型语言模型（LLMs）来生成识别城市事件及其多模态数据之间关系所需的世界知识，无需依赖人工编码的规则。系统将这些知识组织成一个知识图谱，关联事件、观测数据等信息。

Result: SIGMUS系统能够成功地在来自新闻文章、监控录像、空气质量、天气和交通测量这五种不同数据源与同一时间、同一地点的相关事件之间建立合理的联系。

Conclusion: SIGMUS系统通过利用LLMs生成世界知识并构建知识图谱，有效地解决了城市多模态数据整合和事件关联的挑战，实现了对事件及其相关证据的组织和理解，并能在不同数据源之间建立有效的联系。

Abstract: Modern urban spaces are equipped with an increasingly diverse set of sensors,
all producing an abundance of multimodal data. Such multimodal data can be used
to identify and reason about important incidents occurring in urban landscapes,
such as major emergencies, cultural and social events, as well as natural
disasters. However, such data may be fragmented over several sources and
difficult to integrate due to the reliance on human-driven reasoning for
identifying relationships between the multimodal data corresponding to an
incident, as well as understanding the different components which define an
incident. Such relationships and components are critical to identifying the
causes of such incidents, as well as producing forecasting the scale and
intensity of future incidents as they begin to develop. In this work, we create
SIGMUS, a system for Semantic Integration for Knowledge Graphs in Multimodal
Urban Spaces. SIGMUS uses Large Language Models (LLMs) to produce the necessary
world knowledge for identifying relationships between incidents occurring in
urban spaces and data from different modalities, allowing us to organize
evidence and observations relevant to an incident without relying and
human-encoded rules for relating multimodal sensory data with incidents. This
organized knowledge is represented as a knowledge graph, organizing incidents,
observations, and much more. We find that our system is able to produce
reasonable connections between 5 different data sources (new article text, CCTV
images, air quality, weather, and traffic measurements) and relevant incidents
occurring at the same time and location.

</details>


### [455] [Towards Agentic OS: An LLM Agent Framework for Linux Schedulers](https://arxiv.org/abs/2509.01245)
*Yusheng Zheng,Yanpeng Hu,Wei Zhang,Andi Quinn*

Main category: cs.AI

TL;DR: SchedCP是一个利用LLM代理自主优化Linux调度程序的框架，通过解耦的控制平面实现


<details>
  <summary>Details</summary>
Motivation: 操作系统调度程序与应用程序之间存在语义鸿沟，导致性能不佳。

Method: SchedCP框架通过模型上下文协议(MCP)服务器，包含工作负载分析引擎、调度策略库和执行验证器，将LLM的语义推理与系统的观测和执行分离。它使用多代理系统sched-agent，自主分析工作负载，生成eBPF调度策略，并通过sched_ext部署。

Result: SchedCP实现了高达1.79倍的性能提升和13倍的成本降低，同时保持了高成功率。

Conclusion: SchedCP通过弥合语义鸿沟，实现了专家级的系统优化，并朝着真正自优化、应用感知的操作系统迈进。

Abstract: Operating system schedulers suffer from a fundamental semantic gap, where
kernel policies fail to understand application-specific needs, leading to
suboptimal performance. We introduce SchedCP, the first framework that enables
fully autonomous Large Language Model (LLM) agents to safely and efficiently
optimize Linux schedulers without human involvement. Our core insight is that
the challenge is not merely to apply a better LLM, but to architect a decoupled
control plane that separates the AI's role of semantic reasoning ("what to
optimize") from the system's role of execution ("how to observe and act").
Implemented as Model Context Protocol(MCP) server, SchedCP provides a stable
interface with three key services: a Workload Analysis Engine, an evolving
Scheduler Policy Repository, and an Execution Verifier that validates all
AI-generated code and configure before deployment with static and dynamic
analysis.
  We demonstrate this architecture's power with sched-agent, a multi-agent
system that autonomously analyzes workloads, synthesizes custom eBPF scheduling
policies, and deploys them via the sched\_ext infrastructure. Our evaluation
shows that SchedCP achieves up to an 1.79x performance improvement, and a 13x
cost reduction compared to naive agentic approaches, all while maintaining high
success rate. By bridging the semantic gap, SchedCP democratizes expert-level
system optimization and represents a step towards creating truly
self-optimizing, application-aware operating systems. The code is open-sourced
in https://github.com/eunomia-bpf/schedcp

</details>


### [456] [NEWSAGENT: Benchmarking Multimodal Agents as Journalists with Real-World Newswriting Tasks](https://arxiv.org/abs/2509.00446)
*Yen-Che Chien,Kuang-Da Wang,Wei-Yao Wang,Wen-Chih Peng*

Main category: cs.AI

TL;DR: 本研究引入了一个名为NEWSAGENT的基准，用于评估自主数字代理在新闻写作中的多模态网络数据处理能力。实验表明，尽管代理能够检索事实，但在规划和叙事整合方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 评估自主数字代理在新闻写作这一需要迭代规划、解释和上下文推理的任务中，通过处理多模态网络数据来提高生产力的程度。

Method: 介绍NEWSAGENT基准，它包含6000个人类验证的真实新闻示例，并将多模态内容转换为文本。在NEWSAGENT上评估了使用常用代理框架的开源和闭源语言模型（LLMs）。

Result: 代理在检索相关事实方面表现出能力，但在规划和叙事整合方面存在困难。

Conclusion: NEWSAGENT是一个现实的测试平台，用于迭代和评估代理在多模态网络数据处理以实现现实世界生产力方面的能力。

Abstract: Recent advances in autonomous digital agents from industry (e.g., Manus AI
and Gemini's research mode) highlight potential for structured tasks by
autonomous decision-making and task decomposition; however, it remains unclear
to what extent the agent-based systems can improve multimodal web data
productivity. We study this in the realm of journalism, which requires
iterative planning, interpretation, and contextual reasoning from multimodal
raw contents to form a well structured news. We introduce NEWSAGENT, a
benchmark for evaluating how agents can automatically search available raw
contents, select desired information, and edit and rephrase to form a news
article by accessing core journalistic functions. Given a writing instruction
and firsthand data as how a journalist initiates a news draft, agents are
tasked to identify narrative perspectives, issue keyword-based queries,
retrieve historical background, and generate complete articles. Unlike typical
summarization or retrieval tasks, essential context is not directly available
and must be actively discovered, reflecting the information gaps faced in
real-world news writing. NEWSAGENT includes 6k human-verified examples derived
from real news, with multimodal contents converted to text for broad model
compatibility. We evaluate open- and closed-sourced LLMs with commonly-used
agentic frameworks on NEWSAGENT, which shows that agents are capable of
retrieving relevant facts but struggling with planning and narrative
integration. We believe that NEWSAGENT serves a realistic testbed for iterating
and evaluating agent capabilities in terms of multimodal web data manipulation
to real-world productivity.

</details>


### [457] [LLM-empowered Agents Simulation Framework for Scenario Generation in Service Ecosystem Governance](https://arxiv.org/abs/2509.01441)
*Deyu Zhou,Yuqi Hou,Xiao Xue,Xudong Lu,Qingzhong Li,Lizhen Cui*

Main category: cs.AI

TL;DR: LLM驱动的代理协作生成服务生态系统治理的社会不确定性情景。


<details>
  <summary>Details</summary>
Motivation: 服务生态系统的治理是一个关键的研究课题，因为社会环境日益复杂和协作的深化，影响其健康发展的因素不断变化。

Method: 提出一种情景生成器设计方法，该方法自适应地协调三个由LLM赋能的代理（环境代理EA、社会代理SA和规划代理PA）来自主优化实验方案，构建实验系统并生成高质量情景。

Result: 在ProgrammableWeb数据集上的实验表明，该方法能更高效、更准确地生成情景，并为服务生态系统治理相关的实验系统构建提供了有效途径。

Conclusion: 该方法通过LLM驱动的代理协作，解决了传统情景分析方法在生成社会不确定性情景时面临的挑战，提高了情景生成的质量和效率。

Abstract: As the social environment is growing more complex and collaboration is
deepening, factors affecting the healthy development of service ecosystem are
constantly changing and diverse, making its governance a crucial research
issue. Applying the scenario analysis method and conducting scenario rehearsals
by constructing an experimental system before managers make decisions, losses
caused by wrong decisions can be largely avoided. However, it relies on
predefined rules to construct scenarios and faces challenges such as limited
information, a large number of influencing factors, and the difficulty of
measuring social elements. These challenges limit the quality and efficiency of
generating social and uncertain scenarios for the service ecosystem. Therefore,
we propose a scenario generator design method, which adaptively coordinates
three Large Language Model (LLM) empowered agents that autonomously optimize
experimental schemes to construct an experimental system and generate high
quality scenarios. Specifically, the Environment Agent (EA) generates social
environment including extremes, the Social Agent (SA) generates social
collaboration structure, and the Planner Agent (PA) couples task-role
relationships and plans task solutions. These agents work in coordination, with
the PA adjusting the experimental scheme in real time by perceiving the states
of each agent and these generating scenarios. Experiments on the
ProgrammableWeb dataset illustrate our method generates more accurate scenarios
more efficiently, and innovatively provides an effective way for service
ecosystem governance related experimental system construction.

</details>


### [458] [Multi-Agent Data Visualization and Narrative Generation](https://arxiv.org/abs/2509.00481)
*Anton Wolter,Georgios Vidalakis,Michael Yu,Ankit Grover,Vaishali Dhanoa*

Main category: cs.AI

TL;DR: 一个轻量级多智能体系统，可自动化数据分析工作流，从数据探索到生成连贯的视觉叙事以进行洞察交流。


<details>
  <summary>Details</summary>
Motivation: 在数据可视化领域，多智能体系统可在整个数据到通信流程中部署智能体，以实现更大的自动化和人机协作。

Method: 该系统结合了混合多智能体架构和确定性组件，并将关键逻辑从LLM中战略性地外部化，以提高透明度和可靠性。

Result: 该系统在4个不同的数据集上进行了评估，证明了其在可叙述性、叙事质量和计算效率方面的通用性、可叙述性和效率，同时依赖性极小。

Conclusion: 所提出的多智能体系统通过将关键逻辑外部化来提高数据可视化工作流的透明度和可靠性，从而实现可持续的人机协作。

Abstract: Recent advancements in the field of AI agents have impacted the way we work,
enabling greater automation and collaboration between humans and agents. In the
data visualization field, multi-agent systems can be useful for employing
agents throughout the entire data-to-communication pipeline. We present a
lightweight multi-agent system that automates the data analysis workflow, from
data exploration to generating coherent visual narratives for insight
communication. Our approach combines a hybrid multi-agent architecture with
deterministic components, strategically externalizing critical logic from LLMs
to improve transparency and reliability. The system delivers granular, modular
outputs that enable surgical modifications without full regeneration,
supporting sustainable human-AI collaboration. We evaluated our system across 4
diverse datasets, demonstrating strong generalizability, narrative quality, and
computational efficiency with minimal dependencies.

</details>


### [459] [Artificial Intelligence-Based Analysis of Ice Cream Melting Behavior Under Various Ingredients](https://arxiv.org/abs/2509.00507)
*Zhang Lai Bin,Zhen Bin It*

Main category: cs.AI

TL;DR: 该研究评估了四种稳定剂（刺槐豆胶、瓜尔胶、麦芽糊精和角叉菜胶）对自制冰淇淋融化行为的影响，旨在寻找更具成本效益的配方。


<details>
  <summary>Details</summary>
Motivation: 评估四种稳定剂（刺槐豆胶、瓜尔胶、麦芽糊精和角叉菜胶）对自制冰淇淋融化行为的影响，并确定更具成本效益的配方。

Method: 制备含有不同稳定剂的冰淇淋样品，在控制条件下进行融化测试，并使用延时录像和OpenCV进行捕获和分析。

Result: 所有样品在融化后均保持泡沫状结构，表明稳定剂有助于形成稳定的气泡基质。重新冷冻和再次融化后，样品显示出更强的坚固性。不同稳定剂在抗融化性和结构支撑方面效果各异。

Conclusion: 研究结果揭示了常用食品添加剂在冰淇淋配方中的功能作用，并通过评估性能和成本，为开发兼顾耐用性和经济效益的配方提供了见解。

Abstract: The stability of ice cream during melting is a critical factor for consumer's
acceptance and product quality. With the commonly added stabilizer to improve
texture, structure and slower melting as the factors to analyze. This report
explores the effects of locust bean gum, guar gum, maltodextrin, and
carrageenan on the melting behavior of homemade ice cream. The main objective
was to assess how these additives influence melting resistance and to identify
a more cost-effective recipe formulation. Ice cream samples incorporating each
additive were prepared and subjected to melting tests under controlled
conditions. Timelapse recordings were used to capture and analyze the
progression of melting over time. Python and OpenCV is used for process and
analysis. Observations revealed that all samples retained a foam-like structure
even after melting, suggesting the stabilizers contributed to the formation of
a stable air-cell matrix. Furthermore, when the melted samples were re-frozen
and subsequently melted again, they displayed increased sturdiness, indicating
improved resilience of the ice cream structure. Comparative analysis of the
different stabilizers highlighted variations in their effectiveness, with some
offering stronger melting resistance and structural support than others.
Overall, the findings provide insights into the functional roles of commonly
used food additives in ice cream formulation. By evaluating both performance
and cost, this study demonstrates the potential for developing recipes that
balance durability with economic efficiency, contributing to practical
applications in both small-scale and commercial ice cream production.

</details>


### [460] [How Real Is AI Tutoring? Comparing Simulated and Human Dialogues in One-on-One Instruction](https://arxiv.org/abs/2509.01914)
*Ruijia Li,Yuan-Hao Jiang,Jiatong Wang,Bo Jiang*

Main category: cs.AI

TL;DR: AI生成的师生对话在结构和行为上与真实人类对话存在显著差异，人类对话在引导学生思考方面更胜一筹。


<details>
  <summary>Details</summary>
Motivation: 旨在系统性地探究AI模拟和真实人类辅导对话在结构和行为上的差异，以期改进当前AI教育对话系统的局限性。

Method: 采用IRF（Initiation-Response-Feedback）编码方案和认知网络分析（Epistemic Network Analysis, ENA）对AI和人类生成的师生对话进行定量比较。

Result: 研究结果显示，人类对话在语句长度、提问行为（I-Q）和反馈行为（F-F）方面显著优于AI。ENA分析揭示，人类对话模式更具认知引导性和多样性，围绕“问题-事实回应-反馈”的教学循环；而AI对话模式则趋于结构简化和行为趋同，围绕“解释-简单回应”的信息传递循环。

Conclusion: 研究结果揭示了当前AI生成辅导对话的关键局限，并为设计和评估更具教学效果的生成式教育对话系统提供了实证指导。

Abstract: Heuristic and scaffolded teacher-student dialogues are widely regarded as
critical for fostering students' higher-order thinking and deep learning.
However, large language models (LLMs) currently face challenges in generating
pedagogically rich interactions. This study systematically investigates the
structural and behavioral differences between AI-simulated and authentic human
tutoring dialogues. We conducted a quantitative comparison using an
Initiation-Response-Feedback (IRF) coding scheme and Epistemic Network Analysis
(ENA). The results show that human dialogues are significantly superior to
their AI counterparts in utterance length, as well as in questioning (I-Q) and
general feedback (F-F) behaviors. More importantly, ENA results reveal a
fundamental divergence in interactional patterns: human dialogues are more
cognitively guided and diverse, centered around a "question-factual
response-feedback" teaching loop that clearly reflects pedagogical guidance and
student-driven thinking; in contrast, simulated dialogues exhibit a pattern of
structural simplification and behavioral convergence, revolving around an
"explanation-simplistic response" loop that is essentially a simple information
transfer between the teacher and student. These findings illuminate key
limitations in current AI-generated tutoring and provide empirical guidance for
designing and evaluating more pedagogically effective generative educational
dialogue systems.

</details>


### [461] [LLM-Assisted Iterative Evolution with Swarm Intelligence Toward SuperBrain](https://arxiv.org/abs/2509.00510)
*Li Weigang,Pedro Carvalho Brom,Lucas Ramson Siefert*

Main category: cs.AI

TL;DR: 通过用户与大型语言模型的共进化，提出了一种名为SuperBrain的新型集体智能框架，该框架能够实现抽象、泛化和自我改进。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的SuperBrain框架，用于集体智能，其基础是大型语言模型（LLM）和人类用户的共进化，强调从Subclass Brain到Superclass Brain的动态路径。

Method: 1. 通过用户与LLM的持续、个性化交互形成认知二元组，具有自适应学习记忆（Subclass Brain）。 2. 通过遗传算法（GA）辅助的向前-向后进化，迭代地优化提示和任务性能。 3. 多个Subclass Brains通过群体智能进行协调，在多目标适应度景观上进行优化并交换蒸馏的启发式方法。 4. 其标准化的行为和认知特征整合为Superclass Brain，一种能够抽象、泛化和自我改进的新兴元智能。

Result: 概述了理论构建，展示了初步实现（例如，UAV调度、KU/KI关键词过滤），并提出了一个用于跨二元组知识整合的注册表。

Conclusion: 这项工作为可扩展、可解释且符合道德的集体人工智能提供了概念基础和架构路线图。

Abstract: We propose a novel SuperBrain framework for collective intelligence, grounded
in the co-evolution of large language models (LLMs) and human users. Unlike
static prompt engineering or isolated agent simulations, our approach
emphasizes a dynamic pathway from Subclass Brain to Superclass Brain: (1) A
Subclass Brain arises from persistent, personalized interaction between a user
and an LLM, forming a cognitive dyad with adaptive learning memory. (2) Through
GA-assisted forward-backward evolution, these dyads iteratively refine prompts
and task performance. (3) Multiple Subclass Brains coordinate via Swarm
Intelligence, optimizing across multi-objective fitness landscapes and
exchanging distilled heuristics. (4) Their standardized behaviors and cognitive
signatures integrate into a Superclass Brain, an emergent meta-intelligence
capable of abstraction, generalization and self-improvement. We outline the
theoretical constructs, present initial implementations (e.g., UAV scheduling,
KU/KI keyword filtering) and propose a registry for cross-dyad knowledge
consolidation. This work provides both a conceptual foundation and an
architectural roadmap toward scalable, explainable and ethically aligned
collective AI.

</details>


### [462] [Dynamic Speculative Agent Planning](https://arxiv.org/abs/2509.01920)
*Yilin Guan,Wenyue Hua,Qingfeng Lan,Sun Fei,Dujian Ding,Devang Acharya,Chi Wang,William Yang Wang*

Main category: cs.AI

TL;DR: 大型语言模型（LLM）驱动的代理在复杂任务中取得了显著成功，但高延迟和高推理成本限制了其部署。现有加速方法存在性能损失、需要大量离线训练或成本过高的问题，并且用户对加速与性能的权衡控制有限。我们提出了动态推测规划（DSP），一个异步在线强化学习框架，可在无性能损失的情况下实现显著的成本降低，无需额外的部署前准备。DSP 优化了一个平衡端到端延迟和金钱成本的联合目标，用户可通过调整单一参数来控制系统在响应速度、运行成本或两者之间的权衡。实验表明，DSP 在保持与最快无损加速方法相当的效率的同时，总成本降低了 30%，不必要的成本降低了 60%。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLM）驱动的代理在部署时面临的延迟和成本挑战，现有方法在性能、训练、成本和用户控制方面存在局限性。

Method: 提出动态推测规划（DSP），一个异步在线强化学习框架，通过优化延迟和成本的联合目标来实现无损加速，并允许用户通过单一参数控制加速与成本的权衡。

Result: DSP 在保持与最快无损加速方法相当的效率的同时，总成本降低了 30%，不必要的成本降低了高达 60%。

Conclusion: DSP 是一种有效的框架，可以在不损失性能的情况下显著降低 LLM 代理的部署成本和延迟，并提供灵活的用户控制。

Abstract: Despite their remarkable success in complex tasks propelling widespread
adoption, large language-model-based agents still face critical deployment
challenges due to prohibitive latency and inference costs. While recent work
has explored various methods to accelerate inference, existing approaches
suffer from significant limitations: they either fail to preserve performance
fidelity, require extensive offline training of router modules, or incur
excessive operational costs. Moreover, they provide minimal user control over
the tradeoff between acceleration and other performance metrics. To address
these gaps, we introduce Dynamic Speculative Planning (DSP), an asynchronous
online reinforcement learning framework that provides lossless acceleration
with substantially reduced costs without requiring additional pre-deployment
preparation. DSP explicitly optimizes a joint objective balancing end-to-end
latency against dollar cost, allowing practitioners to adjust a single
parameter that steers the system toward faster responses, cheaper operation, or
any point along this continuum. Experiments on two standard agent benchmarks
demonstrate that DSP achieves comparable efficiency to the fastest lossless
acceleration method while reducing total cost by 30% and unnecessary cost up to
60%. Our code and data are available through
https://github.com/guanyilin428/Dynamic-Speculative-Planning.

</details>


### [463] [Text-to-Layout: A Generative Workflow for Drafting Architectural Floor Plans Using LLMs](https://arxiv.org/abs/2509.00543)
*Jayakrishna Duggempudi,Lu Gao,Ahmed Senouci,Zhe Han,Yunpeng Zhang*

Main category: cs.AI

TL;DR: 该论文介绍了一个利用LLM辅助用户从自然语言提示起草建筑平面图的AI工作流。


<details>
  <summary>Details</summary>
Motivation: 旨在利用大型语言模型（LLMs）的能力，自动化生成建筑平面图，以协助建筑师进行设计。

Method: 该系统结合了提示工程、家具放置优化算法和Python脚本，以解释文本输入并自动生成包含墙体、门窗和家具布局的方案，并能生成与Revit等设计工具兼容的平面图。

Result: 通过一个住宅户型案例研究，证明了该方法能够以很少的人工干预生成功能性和结构化的输出，并且生成的模型保留了Revit原生参数属性，可以直接集成到BIM流程中。

Conclusion: 该AI工作流能够有效地将自然语言指令转化为结构化的建筑平面图草稿，为建筑设计过程提供自动化支持，并具有良好的可复制性和专业兼容性。

Abstract: This paper presents the development of an AI-powered workflow that uses Large
Language Models (LLMs) to assist in drafting schematic architectural floor
plans from natural language prompts. The proposed system interprets textual
input to automatically generate layout options including walls, doors, windows,
and furniture arrangements. It combines prompt engineering, a furniture
placement refinement algorithm, and Python scripting to produce spatially
coherent draft plans compatible with design tools such as Autodesk Revit. A
case study of a mid-sized residential layout demonstrates the approach's
ability to generate functional and structured outputs with minimal manual
effort. The workflow is designed for transparent replication, with all key
prompt specifications documented to enable independent implementation by other
researchers. In addition, the generated models preserve the full range of
Revit-native parametric attributes required for direct integration into
professional BIM processes.

</details>


### [464] [Social World Models](https://arxiv.org/abs/2509.00559)
*Xuhui Zhou,Jiarui Liu,Akhila Yerukola,Hyunwoo Kim,Maarten Sap*

Main category: cs.AI

TL;DR: S3AP是一个新的结构化社会世界表示形式，可帮助AI更好地理解和推理社会动态，在多个任务中提高了LLM的性能，并改进了代理决策。


<details>
  <summary>Details</summary>
Motivation: AI在理解和推理隐式社会背景方面存在困难，而人类则能直观地导航社交互动。

Method: 提出了一种新颖的结构化社会世界表示形式（S3AP），采用POMDP驱动设计，将社会互动表示为结构化元组（状态、观察、代理行为、心理状态），并可从自由形式的叙述中自动诱导。

Result: S3AP能提升LLM对社会叙事的理解，在5项社会推理任务中表现提升超51%（例如，在FANToM的心理理论推理任务上），达到新的SOTA。此外，基于S3AP诱导的社会世界模型能预测未来社会动态，并将SOTOPIA基准测试中的代理决策能力提高了18%。

Conclusion: S3AP是一种强大的、通用的社会世界状态表示方法，有望促进更具社会意识的AI系统的发展，使其能够更好地驾驭社交互动。

Abstract: Humans intuitively navigate social interactions by simulating unspoken
dynamics and reasoning about others' perspectives, even with limited
information. In contrast, AI systems struggle to automatically structure and
reason about these implicit social contexts. In this paper, we introduce a
novel structured social world representation formalism (S3AP), designed to help
AI systems reason more effectively about social dynamics. Following a
POMDP-driven design, S3AP represents social interactions as structured tuples,
such as state, observation, agent actions, and mental states, which can be
automatically induced from free-form narratives or other inputs. We first show
S3AP can help LLMs better understand social narratives across 5 social
reasoning tasks (e.g., +51% improvement on FANToM's theory-of-mind reasoning
with OpenAI's o1), reaching new state-of-the-art (SOTA) performance. We then
induce social world models from these structured representations, demonstrating
their ability to predict future social dynamics and improve agent
decision-making, yielding up to +18% improvement on the SOTOPIA social
interaction benchmark. Our findings highlight the promise of S3AP as a
powerful, general-purpose representation for social world states, enabling the
development of more socially-aware systems that better navigate social
interactions.

</details>


### [465] [BALM-TSF: Balanced Multimodal Alignment for LLM-Based Time Series Forecasting](https://arxiv.org/abs/2509.00622)
*Shiqiao Zhou,Holger Schöner,Huanbo Lyu,Edouard Fouché,Shuo Wang*

Main category: cs.AI

TL;DR: BALM-TSF是一个轻量级的时间序列预测框架，通过平衡文本和时间序列模态来增强预测性能，实现了先进的长期和少样本预测效果。


<details>
  <summary>Details</summary>
Motivation: 解决当前多模态架构中，文本和时间序列数据之间差异过大导致的信息丢失问题，以增强预测性能。

Method: 1. 时间序列编码器处理原始时间序列。
2. 描述性统计数据输入带有可学习提示的LLM，生成紧凑的文本嵌入。
3. 采用简单的缩放策略和对比目标，将文本嵌入映射到时间序列嵌入的潜在空间，实现跨模态上下文对齐。
4. 结合对齐后的文本语义嵌入和时间序列嵌入进行预测。

Result: BALM-TSF在标准基准测试中取得了最先进的性能，尤其在长期和少样本预测方面表现出色，展示了其有效利用文本和时间序列互补信息的能力，同时仅使用了最少的训练参数。

Conclusion: BALM-TSF能够有效地利用文本和时间序列数据的互补信息，在保持模态平衡的同时，在长期和少样本预测任务上取得了最先进的性能。

Abstract: Time series forecasting is a long-standing and highly challenging research
topic. Recently, driven by the rise of large language models (LLMs), research
has increasingly shifted from purely time series methods toward harnessing
textual modalities to enhance forecasting performance. However, the vast
discrepancy between text and temporal data often leads current multimodal
architectures to over-emphasise one modality while neglecting the other,
resulting in information loss that harms forecasting performance. To address
this modality imbalance, we introduce BALM-TSF (Balanced Multimodal Alignment
for LLM-Based Time Series Forecasting), a lightweight time series forecasting
framework that maintains balance between the two modalities. Specifically, raw
time series are processed by the time series encoder, while descriptive
statistics of raw time series are fed to an LLM with learnable prompt,
producing compact textual embeddings. To ensure balanced cross-modal context
alignment of time series and textual embeddings, a simple yet effective scaling
strategy combined with a contrastive objective then maps these textual
embeddings into the latent space of the time series embeddings. Finally, the
aligned textual semantic embeddings and time series embeddings are together
integrated for forecasting. Extensive experiments on standard benchmarks show
that, with minimal trainable parameters, BALM-TSF achieves state-of-the-art
performance in both long-term and few-shot forecasting, confirming its ability
to harness complementary information from text and time series. Code is
available at https://github.com/ShiqiaoZhou/BALM-TSF.

</details>


### [466] [NetGent: Agent-Based Automation of Network Application Workflows](https://arxiv.org/abs/2509.00625)
*Jaber Daneshamooz,Eugene Vuong,Laasya Koduru,Sanjay Chandrasekaran,Arpit Gupta*

Main category: cs.AI

TL;DR: NetGent是一个AI代理框架，可自动化复杂应用程序工作流以生成真实的网络流量数据集。它将自然语言规则编译成状态机，以生成可重现、可重用且能适应UI变化的流量数据。


<details>
  <summary>Details</summary>
Motivation: 需要收集来自真实网络环境的数据，以训练具有泛化能力的机器学习模型。现有的浏览器自动化工具虽然多样化，但在可重现性、真实性和效率方面存在脆弱且成本高昂的问题。

Method: NetGent允许用户使用自然语言规则来指定工作流，这些规则定义了状态相关的动作。这些抽象的规范被编译成非确定性有限自动机（NFAs），然后由状态合成组件转换为可重用、可执行的代码。这种设计支持确定性回放，通过状态缓存减少冗余的LLM调用，并能快速适应应用程序界面的变化。

Result: NetGent自动化了超过50个工作流，涵盖了视频点播、直播、视频会议、社交媒体和网页抓取等领域，生成了真实的流量追踪，并且能够很好地适应UI的变化。

Conclusion: NetGent结合了基于语言的代理的灵活性和编译执行的可靠性，为生成用于推进网络机器学习的多样化、可重现的数据集提供了可扩展的基础。

Abstract: We present NetGent, an AI-agent framework for automating complex application
workflows to generate realistic network traffic datasets. Developing
generalizable ML models for networking requires data collection from network
environments with traffic that results from a diverse set of real-world web
applications. However, using existing browser automation tools that are
diverse, repeatable, realistic, and efficient remains fragile and costly.
NetGent addresses this challenge by allowing users to specify workflows as
natural-language rules that define state-dependent actions. These abstract
specifications are compiled into nondeterministic finite automata (NFAs), which
a state synthesis component translates into reusable, executable code. This
design enables deterministic replay, reduces redundant LLM calls through state
caching, and adapts quickly when application interfaces change. In experiments,
NetGent automated more than 50+ workflows spanning video-on-demand streaming,
live video streaming, video conferencing, social media, and web scraping,
producing realistic traffic traces while remaining robust to UI variability. By
combining the flexibility of language-based agents with the reliability of
compiled execution, NetGent provides a scalable foundation for generating the
diverse, repeatable datasets needed to advance ML in networking.

</details>


### [467] [On Verifiable Legal Reasoning: A Multi-Agent Framework with Formalized Knowledge Representations](https://arxiv.org/abs/2509.00710)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: AI在法律推理方面存在挑战，本文提出了一种模块化多智能体框架，将法律推理分解为知识获取和应用阶段，通过提取法律概念、形式化规则、案例事实映射、符号推理和程序化答案生成，提高了透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: 法律推理对AI系统提出了精确解释和应用复杂规则的挑战。

Method: 本研究提出一个模块化多智能体框架，将法律推理分为知识获取和应用两个阶段。在知识获取阶段，专门的智能体提取法律概念并形式化规则，以创建可验证的法规中间表示。在应用阶段，通过分析查询将案例事实映射到本体模式，执行符号推理以推导逻辑结论，并使用程序化实现来生成最终答案。

Result: 在法定税收计算任务上的评估显示，该框架显著提高了性能，基础模型准确率达到76.4%，远高于18.8%的基线性能。

Conclusion: 模块化架构和形式化知识表示可以使AI更容易进行复杂的法律推理，提高计算效率、一致性和可解释性，为未来透明、可信和有效的法律AI系统奠定基础。

Abstract: Legal reasoning requires both precise interpretation of statutory language
and consistent application of complex rules, presenting significant challenges
for AI systems. This paper introduces a modular multi-agent framework that
decomposes legal reasoning into distinct knowledge acquisition and application
stages. In the first stage, specialized agents extract legal concepts and
formalize rules to create verifiable intermediate representations of statutes.
The second stage applies this knowledge to specific cases through three steps:
analyzing queries to map case facts onto the ontology schema, performing
symbolic inference to derive logically entailed conclusions, and generating
final answers using a programmatic implementation that operationalizes the
ontological knowledge. This bridging of natural language understanding with
symbolic reasoning provides explicit and verifiable inspection points,
significantly enhancing transparency compared to end-to-end approaches.
Evaluation on statutory tax calculation tasks demonstrates substantial
improvements, with foundational models achieving 76.4\% accuracy compared to
18.8\% baseline performance, effectively narrowing the performance gap between
reasoning and foundational models. These findings suggest that modular
architectures with formalized knowledge representations can make sophisticated
legal reasoning more accessible through computationally efficient models while
enhancing consistency and explainability in AI legal reasoning, establishing a
foundation for future research into more transparent, trustworthy, and
effective AI systems for legal domain.

</details>


### [468] [OmniDPO: A Preference Optimization Framework to Address Omni-Modal Hallucination](https://arxiv.org/abs/2509.00723)
*Junzhe Chen,Tianshu Zhang,Shiyu Huang,Yuwei Niu,Chao Sun,Rongzhou Zhang,Guanyu Zhou,Lijie Wen,Xuming Hu*

Main category: cs.AI

TL;DR: 全模态大语言模型（OLLMs）虽然在多模态任务上表现出色，但仍存在幻觉问题。现有模型倾向于依赖文本信息，忽略音视频的内在联系，导致在需要理解隐藏音频线索时产生幻觉。本文提出OmniDPO框架，通过构建文本偏好样本对和多模态偏好样本对，增强模型对音视频交互的理解和对视听信息的关注，从而减轻幻觉并提升多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有OLLM在处理音视频信息时存在依赖文本、忽略音视频内在联系的幻觉问题，尤其是在需要理解视频中隐藏音频线索的推理任务中。

Method: 提出OmniDPO框架，包含两个策略：1. 构建文本偏好样本对，增强模型对音视频交互的理解；2. 构建多模态偏好样本对，加强模型对视听信息的关注。

Result: OmniDPO有效减轻了多模态幻觉，显著提升了模型的跨模态推理能力。在两个OLLM上的实验证明了其有效性。

Conclusion: OmniDPO框架能有效缓解OLLM的多模态幻觉问题，并提升其跨模态推理能力。

Abstract: Recently, Omni-modal large language models (OLLMs) have sparked a new wave of
research, achieving impressive results in tasks such as audio-video
understanding and real-time environment perception. However, hallucination
issues still persist. Similar to the bimodal setting, the priors from the text
modality tend to dominate, leading OLLMs to rely more heavily on textual cues
while neglecting visual and audio information. In addition, fully multimodal
scenarios introduce new challenges. Most existing models align visual or
auditory modalities with text independently during training, while ignoring the
intrinsic correlations between video and its corresponding audio. This
oversight results in hallucinations when reasoning requires interpreting hidden
audio cues embedded in video content. To address these challenges, we propose
OmniDPO, a preference-alignment framework designed to mitigate hallucinations
in OLLMs. Specifically, OmniDPO incorporates two strategies: (1) constructing
text-preference sample pairs to enhance the model's understanding of
audio-video interactions; and (2) constructing multimodal-preference sample
pairs to strengthen the model's attention to visual and auditory information.
By tackling both challenges, OmniDPO effectively improves multimodal grounding
and reduces hallucination. Experiments conducted on two OLLMs demonstrate that
OmniDPO not only effectively mitigates multimodal hallucinations but also
significantly enhances the models' reasoning capabilities across modalities.
All code and datasets will be released upon paper acceptance.

</details>


### [469] [Efficient Graph Understanding with LLMs via Structured Context Injection](https://arxiv.org/abs/2509.00740)
*Govind Waghmare,Sumedh BG,Sonia Gupta,Srikanta Bedathur*

Main category: cs.AI

TL;DR: 本研究提出了一种结构化上下文注入框架，无需微调即可指导大语言模型（LLMs）解决图相关任务，并取得了性能提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决大语言模型在处理图相关任务时，尤其是在需要概念对齐时面临的成本高昂和效率低下的问题，本研究提出了一种通过输入注入结构化上下文的方法。

Method: 本研究提出了一种结构化上下文注入框架，将任务信息系统地嵌入输入中，以指导大语言模型解决图问题，且无需进行微调。

Result: 在多项图任务的评估中，该方法在轻量级和大型模型上都表现出一致的性能提升，表明结构化输入上下文可以媲美甚至超越更复杂的方法，同时还能在准确性和计算成本之间进行权衡。

Conclusion: 结构化上下文注入是一种有效且可扩展的策略，能够提升大语言模型在图理解方面的能力。

Abstract: Large Language Models (LLMs) have shown strong capabilities in solving
problems across domains, including graph-related tasks traditionally addressed
by symbolic or algorithmic methods. In this work, we present a framework for
structured context injection, where task-specific information is systematically
embedded in the input to guide LLMs in solving a wide range of graph problems.
Our method does not require fine-tuning of LLMs, making it cost-efficient and
lightweight. We observe that certain graph reasoning tasks remain challenging
for LLMs unless they are mapped to conceptually grounded representations.
However, achieving such mappings through fine-tuning or repeated multi-step
querying can be expensive and inefficient. Our approach offers a practical
alternative by injecting structured context directly into the input, enabling
the LLM to implicitly align the task with grounded conceptual spaces. We
evaluate the approach on multiple graph tasks using both lightweight and large
models, highlighting the trade-offs between accuracy and computational cost.
The results demonstrate consistent performance improvements, showing that
structured input context can rival or surpass more complex approaches. Our
findings underscore the value of structured context injection as an effective
and scalable strategy for graph understanding with LLMs.

</details>


### [470] [L-MARS -- Legal Multi-Agent Workflow with Orchestrated Reasoning and Agentic Search](https://arxiv.org/abs/2509.00761)
*Ziqi Wang,Boqin Yuan*

Main category: cs.AI

TL;DR: L-MARS是一个通过协调的多智能体推理和检索来减少法律问答中幻觉和不确定性的系统。


<details>
  <summary>Details</summary>
Motivation: 解决法律问答中因幻觉和不确定性导致的准确性问题。

Method: L-MARS将查询分解为子问题，跨异构来源（Serper网络、本地RAG、CourtListener案例法）进行有针对性的搜索，并使用“法官代理”来验证充分性、管辖权和时间有效性，最后进行答案合成。

Result: L-MARS在LegalSearchQA基准测试中，显著提高了事实准确性，降低了不确定性，并获得了人类专家和基于LLM的法官更高的偏好分数。

Conclusion: 多智能体推理与智能体搜索为在需要精确法律检索和审议的高风险领域部署LLM提供了一个可扩展且可复现的蓝图。

Abstract: We present L-MARS (Legal Multi-Agent Workflow with Orchestrated Reasoning and
Agentic Search), a system that reduces hallucination and uncertainty in legal
question answering through coordinated multi-agent reasoning and retrieval.
Unlike single-pass retrieval-augmented generation (RAG), L-MARS decomposes
queries into subproblems, issues targeted searches across heterogeneous sources
(Serper web, local RAG, CourtListener case law), and employs a Judge Agent to
verify sufficiency, jurisdiction, and temporal validity before answer
synthesis. This iterative reasoning-search-verification loop maintains
coherence, filters noisy evidence, and grounds answers in authoritative law. We
evaluated L-MARS on LegalSearchQA, a new benchmark of 200 up-to-date multiple
choice legal questions in 2025. Results show that L-MARS substantially improves
factual accuracy, reduces uncertainty, and achieves higher preference scores
from both human experts and LLM-based judges. Our work demonstrates that
multi-agent reasoning with agentic search offers a scalable and reproducible
blueprint for deploying LLMs in high-stakes domains requiring precise legal
retrieval and deliberation.

</details>


### [471] [Aligning Reasoning LLMs for Materials Discovery with Physics-aware Rejection Sampling](https://arxiv.org/abs/2509.00768)
*Lee Hyun,Sohee Yoon,Jinwoo Park,Sue In Chae,Seongeon Park,Jooyeon Ahn,Yebin Jung,Youjung Chung,Hogeun Chang,Myeonginn Kang,Jina Kim,Ho-Gyeong Kim,Myeonghun Jeong*

Main category: cs.AI

TL;DR: AI驱动的材料发现需要精确、校准且符合物理学的配方到性质预测器。我们提出了一种名为PaRS的训练时追踪选择方案，该方案利用物理感知拒绝采样，偏好与基本物理学一致且数值接近目标的追踪，并结合轻量级停止机制来控制计算。与基线相比，我们的方法提高了准确性和校准率，降低了物理违规率，并降低了采样成本。


<details>
  <summary>Details</summary>
Motivation: AI驱动的材料发现需要准确、校准且符合物理学的配方到性质预测器，以实现自动化实验和算法决策。现有的训练方法未能充分考虑物理可行性。

Method: 我们提出了一种名为Physics-aware Rejection Sampling (PaRS)的训练时追踪选择方案，该方案通过利用物理感知拒绝采样来选择与基本物理学一致且数值接近目标的追踪。此外，还采用了轻量级停止机制来控制计算资源。将该框架应用于一个大型学生模型，并使用一个更大的教师模型合成的追踪进行微调，然后在相同的令牌预算下与各种拒绝采样基线进行比较。

Result: 与基线方法相比，PaRS在准确性和校准方面有所提高，物理违规率有所降低，并且采样成本也更低。

Conclusion: 适度的、领域感知的约束与追踪级别的选择相结合，为过程感知性质预测和闭环材料设计提供了可靠、高效的LRM的实用途径。

Abstract: AI-driven materials discovery that couples automated experimentation with
algorithmic decision-making requires process aware recipe to property
predictors that are accurate, calibrated, and physically admissible. We
approach this as a reasoning problem with large reasoning models (LRMs). To
instill reasoning capability into language models, we curate reasoning traces
from a teacher model to train a student model. However, most training pipelines
select reasoning traces using binary correctness or learned preference signals
that poorly reflect physical admissibility. We introduce Physics-aware
Rejection Sampling (PaRS), a training-time trace selection scheme that favors
traces consistent with fundamental physics and numerically close to targets,
with lightweight halting to control compute. We instantiate our framework with
a large student model fine-tuned on traces synthesized by a larger teacher
model, and evaluate under matched token budgets against various rejection
sampling baselines. Our method improves accuracy and calibration, reduces
physics-violation rates, and lowers sampling cost relative to baselines. These
results indicate that modest, domain-aware constraints combined with
trace-level selection provide a practical path toward reliable, efficient LRMs
for process-aware property prediction and closed-loop materials design.

</details>


### [472] [Sharpe Ratio Optimization in Markov Decision Processes](https://arxiv.org/abs/2509.00793)
*Shuai Ma,Guangwu Liu,Li Xia*

Main category: cs.AI

TL;DR: 该论文研究了在马尔可夫决策过程（MDP）中优化夏普比率（Sharpe ratio）的问题，并提出了一种新的算法。


<details>
  <summary>Details</summary>
Motivation: 金融领域广泛使用的夏普比率（Sharpe ratio）在马尔可夫决策过程（MDP）中的优化面临两大挑战：动态规划不适用于分数目标和风险度量。本文旨在解决这些挑战。

Method: 论文首先利用Dinkelbachs变换将夏普比率优化转化为均值-方差（M2V）优化，然后开发了一种迭代算法来解决M2V优化问题。该算法通过迭代求解M2V问题并更新风险敏感参数，逐步收敛到最优夏普比率。针对平均和折扣MDP，论文还提出了一种策略迭代方法。

Result: 研究表明，当风险敏感参数等于最优夏普比率时，M2V优化与原始夏普比率优化具有相同的最优策略。所提出的迭代算法产生的夏普比率序列单调递增并收敛于最优夏普比率。数值实验验证了该方法的有效性。

Conclusion: 该论文提出了一种基于动态规划的算法来解决MDP中的夏普比率优化问题，这是该领域的首创。该方法不仅解决了分数目标和风险度量带来的挑战，而且在平均和折扣MDP设置下都得到了验证。作者相信该算法能为解决其他具有分数目标的问题提供新的思路。

Abstract: Sharpe ratio (also known as reward-to-variability ratio) is a widely-used
metric in finance, which measures the additional return at the cost of per unit
of increased risk (standard deviation of return). However, the optimization of
Sharpe ratio in Markov decision processes (MDPs) is challenging, because there
exist two difficulties hindering the application of dynamic programming. One is
that dynamic programming does not work for fractional objectives, and the other
is that dynamic programming is invalid for risk metrics. In this paper, we
study the Sharpe ratio optimization in infinite-horizon MDPs, considering both
the long-run average and discounted settings. We address the first challenge
with the Dinkelbachs transform, which converts the Sharpe ratio objective to a
mean-squared-variance (M2V) objective. It is shown that the M2V optimization
and the original Sharpe ratio optimization share the same optimal policy when
the risk-sensitive parameter is equal to the optimal Sharpe ratio. For the
second challenge, we develop an iterative algorithm to solve the M2V
optimization which is similar to a mean-variance optimization in MDPs. We
iteratively solve the M2V problem and obtain the associated Sharpe ratio that
is used to update the risk-sensitive parameter in the next iteration of M2V
problems. We show that such a sequence of Sharpe ratios derived is
monotonically increasing and converges to the optimal Sharpe ratio. For both
average and discounted MDP settings, we develop a policy iteration procedure
and prove its convergence to the optimum. Numerical experiments are conducted
for validation. To the best of our knowledge, our approach is the first that
solves the Sharpe ratio optimization in MDPs with dynamic programming type
algorithms. We believe that the proposed algorithm can shed light on solving
MDPs with other fractional objectives.

</details>


### [473] [ChatCLIDS: Simulating Persuasive AI Dialogues to Promote Closed-Loop Insulin Adoption in Type 1 Diabetes Care](https://arxiv.org/abs/2509.00891)
*Zonghai Yao,Talha Chafekar,Junda Wang,Shuo Han,Feiyun Ouyang,Junhui Qian,Lingxi Li,Hong Yu*

Main category: cs.AI

TL;DR: 现实世界中闭环胰岛素输送系统（CLIDS）在1型糖尿病患者中的采用率仍然很低，这并非技术故障所致，而是由于行为、心理社会和社会因素的障碍。我们提出了ChatCLIDS，这是首个严格评估LLM驱动的说服性对话以改变健康行为的基准。我们的框架包含一个经过专家验证的虚拟患者库，每个患者都有基于临床的、异构的个人资料和现实的采用障碍，并模拟了与配备了多样化循证说服策略的护士代理的多轮互动。ChatCLIDS独特地支持纵向咨询和对抗性社会影响情景，能够进行稳健的多维度评估。我们的研究结果表明，虽然更大、更具反思性的LLM会随着时间的推移调整策略，但所有模型在克服阻力方面都面临挑战，尤其是在现实的社会压力下。这些结果突显了当前LLM在行为改变方面的关键局限性，并为在医疗保健及其他领域推进值得信赖的说服性人工智能提供了一个高保真、可扩展的测试平台。


<details>
  <summary>Details</summary>
Motivation: 现实世界中闭环胰岛素输送系统（CLIDS）在1型糖尿病患者中的采用率仍然很低，这并非技术故障所致，而是由于行为、心理社会和社会因素的障碍。需要评估LLM驱动的说服性对话以改变健康行为。

Method: ChatCLIDS框架包含一个经过专家验证的虚拟患者库，每个患者都有基于临床的、异构的个人资料和现实的采用障碍，并模拟了与配备了多样化循证说服策略的护士代理的多轮互动。该框架支持纵向咨询和对抗性社会影响情景，能够进行稳健的多维度评估。

Result: 研究结果表明，虽然更大、更具反思性的LLM会随着时间的推移调整策略，但所有模型在克服阻力方面都面临挑战，尤其是在现实的社会压力下。

Conclusion: 这些结果突显了当前LLM在行为改变方面的关键局限性，并为在医疗保健及其他领域推进值得信赖的说服性人工智能提供了一个高保真、可扩展的测试平台。

Abstract: Real-world adoption of closed-loop insulin delivery systems (CLIDS) in type 1
diabetes remains low, driven not by technical failure, but by diverse
behavioral, psychosocial, and social barriers. We introduce ChatCLIDS, the
first benchmark to rigorously evaluate LLM-driven persuasive dialogue for
health behavior change. Our framework features a library of expert-validated
virtual patients, each with clinically grounded, heterogeneous profiles and
realistic adoption barriers, and simulates multi-turn interactions with nurse
agents equipped with a diverse set of evidence-based persuasive strategies.
ChatCLIDS uniquely supports longitudinal counseling and adversarial social
influence scenarios, enabling robust, multi-dimensional evaluation. Our
findings reveal that while larger and more reflective LLMs adapt strategies
over time, all models struggle to overcome resistance, especially under
realistic social pressure. These results highlight critical limitations of
current LLMs for behavior change, and offer a high-fidelity, scalable testbed
for advancing trustworthy persuasive AI in healthcare and beyond.

</details>


### [474] [SATQuest: A Verifier for Logical Reasoning Evaluation and Reinforcement Fine-Tuning of LLMs](https://arxiv.org/abs/2509.00930)
*Yanxiao Zhao,Yaqian Li,Zihao Bo,Rinyoichi Takezoe,Haojia Hui,Mo Guang,Lei Ren,Xiaolin Qin,Kaiwen Long*

Main category: cs.AI

TL;DR: SATQuest是一个用于评估和增强LLM逻辑推理能力的系统验证器，通过生成基于可满足性（SAT）的逻辑推理问题来解决现有基准的局限性。它通过实例规模、问题类型和问题格式三个维度进行问题生成和评估，并通过PySAT进行客观答案验证。评估结果显示LLM在逻辑推理方面存在局限，尤其是在泛化到不熟悉格式时。通过SATQuest进行强化微调可以显著提高LLM在特定任务上的表现并泛化到更复杂的问题，但跨格式适应性仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有评估和增强LLM逻辑推理能力的方法缺乏可控、可扩展的细粒度分析工具，现有基准和数据集在变量控制、问题类型和格式方面存在局限，无法进行多维度、系统性分析和训练。

Method: SATQuest通过从合取范式（CNF）实例直接生成多样化的、基于可满足性（SAT）的逻辑推理问题来评估和增强LLM的逻辑推理能力。其设计包含三个正交维度：实例规模、问题类型和问题格式。该工具采用随机的SAT问题生成方法，并通过PySAT进行客观答案验证，以解决记忆化问题，提供对推理性能的细致洞察，并实现有效的强化微调。

Result: 通过SATQuest对多种LLM进行的大量评估，发现了它们在逻辑推理方面存在显著局限，尤其是在泛化到不熟悉的数学格式方面。此外，研究表明，使用SATQuest进行强化微调能够显著提升目标任务的性能，并泛化到更复杂的问题，但跨格式适应性方面仍存在挑战。

Conclusion: SATQuest是一个基础工具，可以作为推进LLM逻辑推理的宝贵起点。它通过提供可控、可扩展的评估和训练框架，有效解决了现有方法在LLM逻辑推理评估方面的不足。

Abstract: Recent advances in Large Language Models (LLMs) have demonstrated remarkable
general reasoning capabilities. However, systematically evaluating and
enhancing these reasoning capabilities is challenging due to the lack of
controllable and scalable tools for fine-grained analysis. Existing benchmarks
and datasets often lack the necessary variable control for multi-dimensional,
systematic analysis and training, or have narrow problem types and formats. To
address these limitations, we introduce SATQuest, a systematic verifier
designed to evaluate and enhance logical reasoning in LLMs by generating
diverse, Satisfiability-based logical reasoning problems directly from
Conjunctive Normal Form (CNF) instances. SATQuest structures these problems
along three orthogonal dimensions: instance scale, problem type, and question
format, employing randomized, SAT-based problem generation and objective answer
verification via PySAT. This design mitigates memorization issues, allows for
nuanced insights into reasoning performance, and enables effective
reinforcement fine-tuning. Our extensive evaluation of various LLMs using
SATQuest identified significant limitations in their logical reasoning,
particularly in generalizing beyond familiar mathematical formats. Furthermore,
we show that reinforcement fine-tuning with SATQuest rewards substantially
improves targeted task performance and generalizes to more complex instances,
while highlighting remaining challenges in cross-format adaptation. Through
these demonstrations, we showcase SATQuest's potential as a foundational tool
and a valuable starting point for advancing LLM logical reasoning.

</details>


### [475] [UrbanInsight: A Distributed Edge Computing Framework with LLM-Powered Data Filtering for Smart City Digital Twins](https://arxiv.org/abs/2509.00936)
*Kishor Datta Gupta,Md Manjurul Ahsan,Mohd Ariful Haque,Roy George,Azmine Toushik Wasi*

Main category: cs.AI

TL;DR: 该框架结合了物理信息机器学习、多模态数据融合、知识图谱表示和大型语言模型（LLM）驱动的自适应规则智能，用于城市数据分析，以克服现有系统的规模、延迟和碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 现有城市数据系统在处理规模、延迟和碎片化见解方面存在挑战，需要更优的解决方案来改善城市生活。

Method: 提出一个框架，融合物理信息机器学习（确保预测有意义且符合物理动态）、知识图谱（整合异构传感器数据）和大型语言模型（在边缘生成上下文感知规则以适应实时过滤和决策）。

Result: 该框架能够实现超越被动监控的数字孪生系统，提供可操作的见解。

Conclusion: 通过结合基于物理的推理、语义数据融合和自适应规则生成，该方法为创建响应迅速、值得信赖和可持续的智能基础设施开辟了新的可能性。

Abstract: Cities today generate enormous streams of data from sensors, cameras, and
connected infrastructure. While this information offers unprecedented
opportunities to improve urban life, most existing systems struggle with scale,
latency, and fragmented insights. This work introduces a framework that blends
physics-informed machine learning, multimodal data fusion, and knowledge graph
representation with adaptive, rule-based intelligence powered by large language
models (LLMs). Physics-informed methods ground learning in real-world
constraints, ensuring predictions remain meaningful and consistent with
physical dynamics. Knowledge graphs act as the semantic backbone, integrating
heterogeneous sensor data into a connected, queryable structure. At the edge,
LLMs generate context-aware rules that adapt filtering and decision-making in
real time, enabling efficient operation even under constrained resources.
Together, these elements form a foundation for digital twin systems that go
beyond passive monitoring to provide actionable insights. By uniting
physics-based reasoning, semantic data fusion, and adaptive rule generation,
this approach opens new possibilities for creating responsive, trustworthy, and
sustainable smart infrastructures.

</details>


### [476] [A Hybrid Ai Framework For Strategic Patent Portfolio Pruning: Integrating Learning To-Rank And Market Need Analysis For Technology Transfer Optimization](https://arxiv.org/abs/2509.00958)
*Manish Verma,Vivek Sharma,Vishal Singh*

Main category: cs.AI

TL;DR: 该论文提出了一种新的混合智能框架，用于筛选专利组合以识别高价值的专利进行技术转让。


<details>
  <summary>Details</summary>
Motivation: 现有专利估值方法通常依赖于回顾性指标或耗时的人工分析，而本文旨在通过自动化和深化该过程来解决这些问题。

Method: 该框架结合了学习排序（LTR）模型和基于代理的“需求-种子”系统。LTR模型根据30多个法律和商业参数评估专利。“需求代理”使用自然语言处理（NLP）挖掘市场和行业数据以识别技术需求。“种子代理”使用大型语言模型（LLM）分析专利声明以映射技术能力。该系统还包括一个动态参数加权系统和一个“人机协同”验证协议。

Result: 该框架生成一个“核心本体框架”，将高潜力专利（种子）与已记录的市场需求（需求）进行匹配，为剥离决策提供战略依据。

Conclusion: 该框架通过结合LTR模型、需求-种子代理系统和人机协同验证，提供了一种更有效、更深入的专利组合筛选方法，以识别高价值专利进行技术转让。

Abstract: This paper introduces a novel, multi stage hybrid intelligence framework for
pruning patent portfolios to identify high value assets for technology
transfer. Current patent valuation methods often rely on retrospective
indicators or manual, time intensive analysis. Our framework automates and
deepens this process by combining a Learning to Rank (LTR) model, which
evaluates patents against over 30 legal and commercial parameters, with a
unique "Need-Seed" agent-based system. The "Need Agent" uses Natural Language
Processing (NLP) to mine unstructured market and industry data, identifying
explicit technological needs. Concurrently, the "Seed Agent" employs fine tuned
Large Language Models (LLMs) to analyze patent claims and map their
technological capabilities. The system generates a "Core Ontology Framework"
that matches high potential patents (Seeds) to documented market demands
(Needs), providing a strategic rationale for divestment decisions. We detail
the architecture, including a dynamic parameter weighting system and a crucial
Human in the-Loop (HITL) validation protocol, to ensure both adaptability and
real-world credibility.

</details>


### [477] [Ultra Strong Machine Learning: Teaching Humans Active Learning Strategies via Automated AI Explanations](https://arxiv.org/abs/2509.00961)
*Lun Ai,Johannes Langer,Ute Schmid,Stephen Muggleton*

Main category: cs.AI

TL;DR: LENS是一种结合了符号程序合成和大型语言模型的神经符号方法，可自动生成自然语言解释，以提高机器可解释性。尽管它生成的解释比直接提示LLM和手工模板更优越，但在一项人类学习实验中，并未显示出可转移的主动学习策略的显著人类绩效提升。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有超强机器学习（USML）方法在生成解释方面的局限性，该研究提出了一种新的神经符号方法LENS，旨在自动化自然语言解释的生成，以提高机器可解释性。

Method: LENS结合了符号程序合成和大型语言模型（LLMs），自动生成自然语言解释，以解释机器学习的逻辑程序。通过使用多个LLM评估者和人类验证进行系统评估，证明了LENS生成的解释优于直接LLM提示和手工模板。

Result: 与直接LLM提示和手工模板相比，LENS生成的解释更优越。然而，在一项涉及三个相关领域的人类学习实验中，未发现LENS能够传授可转移的主动学习策略，人类绩效没有显著提高，这表明LLM的全面响应可能会让用户不知所措，而不是提供学习支持。

Conclusion: LENS为构建有效的USML系统以支持人类学习奠定了坚实的基础。尽管LENS在生成解释方面表现出色，但其在促进人类主动学习方面的效果仍需进一步研究。

Abstract: Ultra Strong Machine Learning (USML) refers to symbolic learning systems that
not only improve their own performance but can also teach their acquired
knowledge to quantifiably improve human performance. In this work, we present
LENS (Logic Programming Explanation via Neural Summarisation), a neuro-symbolic
method that combines symbolic program synthesis with large language models
(LLMs) to automate the explanation of machine-learned logic programs in natural
language. LENS addresses a key limitation of prior USML approaches by replacing
hand-crafted explanation templates with scalable automated generation. Through
systematic evaluation using multiple LLM judges and human validation, we
demonstrate that LENS generates superior explanations compared to direct LLM
prompting and hand-crafted templates. To investigate whether LENS can teach
transferable active learning strategies, we carried out a human learning
experiment across three related domains. Our results show no significant human
performance improvements, suggesting that comprehensive LLM responses may
overwhelm users for simpler problems rather than providing learning support.
Our work provides a solid foundation for building effective USML systems to
support human learning. The source code is available on:
https://github.com/lun-ai/LENS.git.

</details>


### [478] [CoreThink: A Symbolic Reasoning Layer to reason over Long Horizon Tasks with LLMs](https://arxiv.org/abs/2509.00971)
*Jay Vaghasiya,Omkar Ghugarkar,Vishvesh Bhat,Vipul Dholaria,Julian McAuley*

Main category: cs.AI

TL;DR: CoreThink是一个基于通用符号学的新型推理方法，旨在提高大型语言模型的推理能力，无需微调或训练成本。它在工具调用、代码生成和规划等领域取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前的推理方法（如测试时扩展、监督微调和带可验证奖励的强化学习）在大型语言模型性能提升方面可能面临收益递减的局面，因此有必要开发新的推理技术。

Method: CoreThink通过其通用符号推理器（GSR）实现，该推理器围绕工具调用、代码生成和规划这三个关键用例构建。文章还介绍了一个基于通用符号学原理开发的代理编码IDE。

Result: CoreThink在七个基准测试中取得了最先进的性能，包括在Livecodebench v6上达到66.66%，在Instruction-Following Evals上达到89%，在ARC-AGI-2上达到24.4%，以及在SWE-Bench Lite上达到62.3%的准确率。这些改进是在没有任何微调或训练成本的情况下实现的。

Conclusion: CoreThink推理层能够提供纯粹的性能提升，确保模型在推理任务上的准确性不会受到负面影响。该技术报告概述了CoreThink的方法，并提供了其模型在推理密集型用例中的可用性。

Abstract: We introduce CoreThink, a state-of-the-art Reasoning Layer built upon a novel
reasoning method called General Symbolics. This approach diverges from
reasoning paradigms such as test-time scaling, Supervised Fine-Tuning (SFT),
and Reinforcement Learning with Verifiable Rewards (RLVR). CoreThink General
Symbolic Reasoner (GSR) is specifically structured around three key use cases:
tool-calling, code generation, and planning, demonstrating exemplary
performance across a total of seven benchmarks in their respective areas.
Notably, we are achieving SOTA scores of 66.66\% on Livecodebench v6, 89\% on
Instruction-Following Evals, and 24.4\% on ARC-AGI-2. We also present an
agentic coding IDE, developed using the principles of General Symbolics, which
achieves a state-of-the-art accuracy of 62.3\% on \texttt{SWE-Bench Lite}. We
are able to achieve these improvements without any finetuning or training
costs. Our Reasoning Layer is designed to provide a pure performance uplift,
ensuring that a model's accuracy on reasoning tasks is never negatively
impacted. We argue that incumbent methods will eventually lead to diminishing
returns in LLM performance, necessitating the development of new reasoning
techniques. This technical report details our approach at a high level and the
availability of the CoreThink models for reasoning-intensive use cases.

</details>


### [479] [Self-Exploring Language Models for Explainable Link Forecasting on Temporal Graphs via Reinforcement Learning](https://arxiv.org/abs/2509.00975)
*Zifeng Ding,Shenyang Huang,Zeyu Cao,Emma Kondrup,Zachary Yang,Xingyue Huang,Yuan Sui,Zhangdie Yuan,Yuqicheng Zhu,Xianglong Hu,Yuan He,Farimah Poursafaei,Michael Bronstein,Andreas Vlachos*

Main category: cs.AI

TL;DR: 使用强化学习微调LLM以实现时间图上的可解释链接预测


<details>
  <summary>Details</summary>
Motivation: 解决传统时间图模型可解释性差、无法泛化到新图以及LLM在时间图应用中缺乏可解释性评估的问题

Method: 提出ReaL-TG框架，使用基于结果的奖励来微调LLM，使其能够从图结构中探索推理策略并生成解释；提出一种结合排序指标和LLM-as-a-Judge的评估协议来评估LLM生成的推理过程

Result: 在真实时间图上，ReaL-TG-4B（基于Qwen3-4B微调）在排序指标上优于更大的模型（如GPT-5 mini），并生成了高质量的解释，通过了LLM和人类评估

Conclusion: ReaL-TG框架能够有效地微调LLM以在时间图上进行可解释的链接预测，并提供了可靠的评估方法

Abstract: Forecasting future links is a central task in temporal graph (TG) reasoning,
requiring models to leverage historical interactions to predict upcoming ones.
Traditional neural approaches, such as temporal graph neural networks, achieve
strong performance but lack explainability and cannot be applied to unseen
graphs without retraining. Recent studies have begun to explore using large
language models (LLMs) for graph reasoning, but most of them are constrained to
static graphs or small synthetic TGs and lack the evaluation of the quality of
reasoning traces generated by LLMs. In this work, we present Reasoning-Enhanced
Learning for Temporal Graphs (ReaL-TG), a reinforcement learning framework that
fine-tunes LLMs to perform explainable link forecasting on real-world TGs.
ReaL-TG uses outcome-based reward to encourage models to self-explore reasoning
strategies from graph structure and to produce explanations that directly
justify their predictions. To enable evaluation on LLM-generated reasoning
traces, we propose a new evaluation protocol combining ranking metrics with an
LLM-as-a-Judge system that assesses both the quality of reasoning and the
impact of hallucinations. Experiments with ReaL-TG-4B, obtained by fine-tuning
Qwen3-4B under our framework, show that it outperforms much larger frontier
LLMs, including GPT-5 mini, on ranking metrics, while producing high-quality
explanations confirmed by both the LLM judge and human evaluation.

</details>


### [480] [Causal MAS: A Survey of Large Language Model Architectures for Discovery and Effect Estimation](https://arxiv.org/abs/2509.00987)
*Adib Bazgir,Amir Habibdoust,Yuwen Zhang,Xing Song*

Main category: cs.AI

TL;DR: LLMs在复杂因果推理方面仍有局限，多智能体系统（特别是基于LLM的）的出现有望解决这些问题。本文综述了因果多智能体LLM领域，探讨了其设计、架构、评估和应用，并指出了未来的挑战和方向。


<details>
  <summary>Details</summary>
Motivation: LLMs在因果推理、发现和估计方面存在局限性，如幻觉、依赖虚假相关性以及难以处理细微、领域特定或个性化的因果关系。多智能体系统，特别是基于LLM的系统，被认为是解决这些局限性的有力方法。

Method: 本文通过综述探讨因果多智能体LLM，研究了这些系统在因果推理、反事实分析、因果发现和因果效应估计方面的设计，并深入探讨了它们所采用的各种架构模式和交互协议（如流水线处理、辩论框架、模拟环境和迭代优化循环）。

Result: 因果多智能体LLM在科学发现、医疗保健、事实核查和个性化系统等领域展现出潜力，并被用于评估方法、基准测试和各种应用。

Conclusion: 因果多智能体LLM领域充满活力，在克服LLM在因果推理方面的挑战方面显示出巨大潜力，但仍存在挑战和开放的研究问题，未来的发展方向是协同合作。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
various reasoning and generation tasks. However, their proficiency in complex
causal reasoning, discovery, and estimation remains an area of active
development, often hindered by issues like hallucination, reliance on spurious
correlations, and difficulties in handling nuanced, domain-specific, or
personalized causal relationships. Multi-agent systems, leveraging the
collaborative or specialized abilities of multiple LLM-based agents, are
emerging as a powerful paradigm to address these limitations. This review paper
explores the burgeoning field of causal multi-agent LLMs. We examine how these
systems are designed to tackle different facets of causality, including causal
reasoning and counterfactual analysis, causal discovery from data, and the
estimation of causal effects. We delve into the diverse architectural patterns
and interaction protocols employed, from pipeline-based processing and debate
frameworks to simulation environments and iterative refinement loops.
Furthermore, we discuss the evaluation methodologies, benchmarks, and diverse
application domains where causal multi-agent LLMs are making an impact,
including scientific discovery, healthcare, fact-checking, and personalized
systems. Finally, we highlight the persistent challenges, open research
questions, and promising future directions in this synergistic field, aiming to
provide a comprehensive overview of its current state and potential trajectory.

</details>


### [481] [Supporting Our AI Overlords: Redesigning Data Systems to be Agent-First](https://arxiv.org/abs/2509.00997)
*Shu Liu,Soujanya Ponnapalli,Shreya Shankar,Sepanta Zeighami,Alan Zhu,Shubham Agarwal,Ruiqi Chen,Samion Suwito,Shuo Yuan,Ion Stoica,Matei Zaharia,Alvin Cheung,Natacha Crooks,Joseph E. Gonzalez,Aditya G. Parameswaran*

Main category: cs.AI

TL;DR: LLM代理处理数据的速度很快，但效率不高，因此数据系统需要进行调整以更好地支持它们。


<details>
  <summary>Details</summary>
Motivation: LLM代理将在数据系统中占据主导地位，但它们的高吞吐量和低效率对现有数据系统构成了挑战。

Method: 本文将研究LLM代理的规模、异构性、冗余性和可控性，并提出一种新的代理优先数据系统架构，包括新的查询接口、查询处理技术和代理记忆存储。

Result: 本文确定了支持LLM代理工作负载的新研究方向，包括新的查询接口、查询处理技术和代理记忆存储。

Conclusion: 数据系统需要适应LLM代理的工作负载，数据系统架构的调整可以提高LLM代理的效率。

Abstract: Large Language Model (LLM) agents, acting on their users' behalf to
manipulate and analyze data, are likely to become the dominant workload for
data systems in the future. When working with data, agents employ a
high-throughput process of exploration and solution formulation for the given
task, one we call agentic speculation. The sheer volume and inefficiencies of
agentic speculation can pose challenges for present-day data systems. We argue
that data systems need to adapt to more natively support agentic workloads. We
take advantage of the characteristics of agentic speculation that we identify,
i.e., scale, heterogeneity, redundancy, and steerability - to outline a number
of new research opportunities for a new agent-first data systems architecture,
ranging from new query interfaces, to new query processing techniques, to new
agentic memory stores.

</details>


### [482] [Quantum-like Coherence Derived from the Interaction between Chemical Reaction and Its Environment](https://arxiv.org/abs/2509.01021)
*Yukio-Pegio Gunji,Andrew Adamatzky,Panagiotis Mougkogiannis,Andrei Khrenikov*

Main category: cs.AI

TL;DR: 该研究提出“开放计算”概念，将计算过程与执行环境融合，并将其应用于化学反应，实现了可自我调节的系统。


<details>
  <summary>Details</summary>
Motivation: 为了揭示人工智能与自然出生智能作为计算过程的区别，并将其应用于化学反应。

Method: 通过混合和无效化计算过程及执行环境，实现逻辑上独立的两者融合，形成可调整波动的系统。将化学反应建模为计算过程，将分子聚集度视为执行环境，由此产生的化学反应在重复聚合并去聚合并进行，浓度不再有意义。开放计算分为关注个体行为的Token计算和关注规范行为的Type计算，最终通过两者交互实现。

Result: Token计算表现出自组织临界现象，Type计算表现出量子逻辑。两者交互实现了波动的招募，并产生了对应于不同希尔伯特空间间量子相干性的量子逻辑子空间间的相互作用。最终形成了用于信号传输的尖峰波，并推测这可能是酶控制尖峰波和生化节律的来源。

Conclusion: 提出的开放计算模型成功应用于化学反应，通过Token计算和Type计算的交互作用，实现了量子相干性，形成了尖峰波，可能解释了酶在生物节律中的作用。

Abstract: By uncovering the contrast between Artificial Intelligence and Natural-born
Intelligence as a computational process, we define closed computing and open
computing, and implement open computing within chemical reactions. This
involves forming a mixture and invalidation of the computational process and
the execution environment, which are logically distinct, and coalescing both to
create a system that adjusts fluctuations. We model chemical reactions by
considering the computation as the chemical reaction and the execution
environment as the degree of aggregation of molecules that interact with the
reactive environment. This results in a chemical reaction that progresses while
repeatedly clustering and de-clustering, where concentration no longer holds
significant meaning. Open computing is segmented into Token computing, which
focuses on the individual behavior of chemical molecules, and Type computing,
which focuses on normative behavior. Ultimately, both are constructed as an
interplay between the two. In this system, Token computing demonstrates
self-organizing critical phenomena, while Type computing exhibits quantum
logic. Through their interplay, the recruitment of fluctuations is realized,
giving rise to interactions between quantum logical subspaces corresponding to
quantum coherence across different Hilbert spaces. As a result, spike waves are
formed, enabling signal transmission. This occurrence may be termed
quantum-like coherence, implying the source of enzymes responsible for
controlling spike waves and biochemical rhythms.

</details>


### [483] [FlashAdventure: A Benchmark for GUI Agents Solving Full Story Arcs in Diverse Adventure Games](https://arxiv.org/abs/2509.01052)
*Jaewoo Ahn,Junseo Kim,Heeseung Yun,Jaehyeon Son,Dongmin Park,Jaewoong Cho,Gunhee Kim*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: GUI agents powered by LLMs show promise in interacting with diverse digital
environments. Among these, video games offer a valuable testbed due to their
varied interfaces, with adventure games posing additional challenges through
complex, narrative-driven interactions. Existing game benchmarks, however, lack
diversity and rarely evaluate agents on completing entire storylines. To
address this, we introduce FlashAdventure, a benchmark of 34 Flash-based
adventure games designed to test full story arc completion and tackle the
observation-behavior gap: the challenge of remembering and acting on earlier
gameplay information. We also propose CUA-as-a-Judge, an automated gameplay
evaluator, and COAST, an agentic framework leveraging long-term clue memory to
better plan and solve sequential tasks. Experiments show current GUI agents
struggle with full story arcs, while COAST improves milestone completion by
bridging the observation-behavior gap. Nonetheless, a marked discrepancy
between humans and best-performing agents warrants continued research efforts
to narrow this divide.

</details>


### [484] [VerlTool: Towards Holistic Agentic Reinforcement Learning with Tool Use](https://arxiv.org/abs/2509.01055)
*Dongfu Jiang,Yi Lu,Zhuofeng Li,Zhiheng Lyu,Ping Nie,Haozhe Wang,Alex Su,Hui Chen,Kai Zou,Chao Du,Tianyu Pang,Wenhu Chen*

Main category: cs.AI

TL;DR: VerlTool是一个统一、模块化的框架，通过标准化的API支持代码执行、搜索、SQL数据库和视觉处理等多种模态的工具管理，并采用异步执行以提高效率，在多个ARLT领域表现优异，为工具增强的RL研究提供了一个可扩展的基础。


<details>
  <summary>Details</summary>
Motivation: 现有的Agentic Reinforcement Learning with Tool use (ARLT)方法存在任务特定代码库碎片化、同步执行瓶颈和跨领域扩展性有限的问题，阻碍了社区的广泛采用和算法创新。

Method: VerlTool框架通过系统化的设计原则，实现了与VeRL的上游兼容、统一的工具管理（支持代码执行、搜索、SQL数据库、视觉处理等多种模态）、异步执行以消除同步瓶颈，并进行了全面的评估。

Result: VerlTool实现了近2倍的速度提升，在数学推理、知识问答、SQL生成、视觉推理、网络搜索和软件工程等6个ARLT领域进行了评估，取得了与专业化系统相当的性能，同时提供了统一的训练基础设施。

Conclusion: VerlTool通过其模块化插件架构，极大地降低了开发开销，并为工具增强的RL研究提供了一个可扩展的基础，解决了现有ARLT方法的局限性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has demonstrated
success in enhancing LLM reasoning capabilities, but remains limited to
single-turn interactions without tool integration. While recent Agentic
Reinforcement Learning with Tool use (ARLT) approaches have emerged to address
multi-turn tool interactions, existing works develop task-specific codebases
that suffer from fragmentation, synchronous execution bottlenecks, and limited
extensibility across domains. These inefficiencies hinder broader community
adoption and algorithmic innovation. We introduce VerlTool, a unified and
modular framework that addresses these limitations through systematic design
principles. VerlTool provides four key contributions: (1) upstream alignment
with VeRL ensuring compatibility and simplified maintenance, (2) unified tool
management via standardized APIs supporting diverse modalities including code
execution, search, SQL databases, and vision processing, (3) asynchronous
rollout execution achieving near 2$\times$ speedup by eliminating
synchronization bottlenecks, and (4) comprehensive evaluation demonstrating
competitive performance across 6 ARLT domains. Our framework formalizes ARLT as
multi-turn trajectories with multi-modal observation tokens (text/image/video),
extending beyond single-turn RLVR paradigms. We train and evaluate models on
mathematical reasoning, knowledge QA, SQL generation, visual reasoning, web
search, and software engineering tasks, achieving results comparable to
specialized systems while providing unified training infrastructure. The
modular plugin architecture enables rapid tool integration requiring only
lightweight Python definitions, significantly reducing development overhead and
providing a scalable foundation for tool-augmented RL research. Our code is
open-sourced at https://github.com/TIGER-AI-Lab/verl-tool.

</details>


### [485] [Robix: A Unified Model for Robot Interaction, Reasoning and Planning](https://arxiv.org/abs/2509.01106)
*Huang Fang,Mengxi Zhang,Heng Dong,Wei Li,Zixuan Wang,Qifeng Zhang,Xueyun Tian,Yucheng Hu,Hang Li*

Main category: cs.AI

TL;DR: Robix是一个统一的机器人模型，集成了机器人推理、任务规划和自然语言交互，能够理解复杂指令、规划长周期任务并与人类自然交互。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个能够处理复杂指令、规划长周期任务并与人类自然交互的机器人高级认知层。

Method: Robix利用链式思考推理，并采用持续预训练、监督微调和强化学习的三阶段训练策略，以增强基础具身推理能力、建模人机交互和任务规划，并提高推理-动作的一致性和长周期任务的连贯性。

Result: Robix在交互式任务执行方面优于开源和商业基线（如GPT-4o和Gemini 2.5 Pro），在各种指令类型（如开放式、多阶段、约束式、无效式和中断式）以及各种用户参与的任务（如餐桌服务、杂货购物和饮食过滤）中表现出强大的泛化能力。

Conclusion: Robix通过集成机器人推理、任务规划和自然语言交互，成功实现了机器人在复杂指令下的执行和人机交互，并且在多种任务和指令类型上展现了优越的性能。

Abstract: We introduce Robix, a unified model that integrates robot reasoning, task
planning, and natural language interaction within a single vision-language
architecture. Acting as the high-level cognitive layer in a hierarchical robot
system, Robix dynamically generates atomic commands for the low-level
controller and verbal responses for human interaction, enabling robots to
follow complex instructions, plan long-horizon tasks, and interact naturally
with human within an end-to-end framework. Robix further introduces novel
capabilities such as proactive dialogue, real-time interruption handling, and
context-aware commonsense reasoning during task execution. At its core, Robix
leverages chain-of-thought reasoning and adopts a three-stage training
strategy: (1) continued pretraining to enhance foundational embodied reasoning
abilities including 3D spatial understanding, visual grounding, and
task-centric reasoning; (2) supervised finetuning to model human-robot
interaction and task planning as a unified reasoning-action sequence; and (3)
reinforcement learning to improve reasoning-action consistency and long-horizon
task coherence. Extensive experiments demonstrate that Robix outperforms both
open-source and commercial baselines (e.g., GPT-4o and Gemini 2.5 Pro) in
interactive task execution, demonstrating strong generalization across diverse
instruction types (e.g., open-ended, multi-stage, constrained, invalid, and
interrupted) and various user-involved tasks such as table bussing, grocery
shopping, and dietary filtering.

</details>


### [486] [Heads or Tails: A Simple Example of Causal Abstractive Simulation](https://arxiv.org/abs/2509.01136)
*Gabriel Simmons*

Main category: cs.AI

TL;DR: 本文介绍了一种称为因果抽象模拟（CAS）的因果抽象方法，并将其应用于语言模型模拟的简单示例，特别是模拟抛硬币。文章展示了语言模型模拟失败和成功的情况，并提出了一种证明语言模型能够模拟其他系统的形式化方法。


<details>
  <summary>Details</summary>
Motivation: 本文旨在为语言模型模拟提供一个基于因果理论的形式化框架，连接实践中的统计基准测试与因果科学的严谨性，并为人工智能和心智哲学的相关讨论提供精确的操作化定义，同时为因果抽象领域提供新的应用视角。

Method: 本文使用因果抽象模拟（CAS）方法来形式化语言模型模拟，以一个模拟公平硬币抛掷的简单案例为起点，展示了语言模型模拟失败和成功的具体情况，并提出了一种证明语言模型能够模拟其他系统的形式化方法。

Result: 文章通过模拟抛硬币的例子，说明了语言模型在模拟过程中可能出现的失败情况，并展示了成功模拟的案例。研究表明，所提出的因果抽象模拟形式化方法可以用来证明一个语言模型确实在模拟另一个系统，前提是存在对该系统的因果描述。

Conclusion: 本文提出的因果抽象模拟方法为语言模型模拟提供了一个严谨的形式化基础，有助于连接实践与理论，并为理解语言模型的模拟能力和与因果的关系提供了新的视角。

Abstract: This note illustrates how a variety of causal abstraction arXiv:1707.00819
arXiv:1812.03789, defined here as causal abstractive simulation, can be used to
formalize a simple example of language model simulation. This note considers
the case of simulating a fair coin toss with a language model. Examples are
presented illustrating the ways language models can fail to simulate, and a
success case is presented, illustrating how this formalism may be used to prove
that a language model simulates some other system, given a causal description
of the system. This note may be of interest to three groups. For practitioners
in the growing field of language model simulation, causal abstractive
simulation is a means to connect ad-hoc statistical benchmarking practices to
the solid formal foundation of causality. Philosophers of AI and philosophers
of mind may be interested as causal abstractive simulation gives a precise
operationalization to the idea that language models are role-playing
arXiv:2402.12422. Mathematicians and others working on causal abstraction may
be interested to see a new application of the core ideas that yields a new
variation of causal abstraction.

</details>


### [487] [Towards Open-World Retrieval-Augmented Generation on Knowledge Graph: A Multi-Agent Collaboration Framework](https://arxiv.org/abs/2509.01238)
*Jiasheng Xu,Mingda Li,Yongqiang Tang,Peijie Wang,Wensheng Zhang*

Main category: cs.AI

TL;DR: AnchorRAG是一个创新的多智能体协作框架，用于在没有预定义锚定实体的开放世界检索增强生成（RAG）中，提高检索鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱（KG）的RAG方法依赖于可访问的锚定实体，这在实体链接不可靠的开放世界设置中存在局限性。本研究旨在克服这一限制，提出一种无需预定义锚定实体即可实现开放世界RAG的鲁棒框架。

Method: AnchorRAG框架包含一个预测智能体，用于通过将用户查询词与KG节点对齐来动态识别候选锚定实体；多个独立的检索器智能体，分别从每个候选实体开始进行并行的多跳探索；以及一个监督智能体，用于制定迭代检索策略并综合知识路径以生成最终答案。

Result: AnchorRAG在四个公开基准测试中表现出显著优于现有基线，并在真实世界问答任务上取得了新的最先进成果。

Conclusion: AnchorRAG通过其多智能体协作框架，成功实现了在无预定义锚定实体情况下的开放世界RAG，提高了检索的鲁棒性，并减轻了模糊或错误锚定的影响。

Abstract: Large Language Models (LLMs) have demonstrated strong capabilities in
language understanding and reasoning. However, their dependence on static
training corpora makes them prone to factual errors and knowledge gaps.
Retrieval-Augmented Generation (RAG) addresses this limitation by incorporating
external knowledge sources, especially structured Knowledge Graphs (KGs), which
provide explicit semantics and efficient retrieval. Existing KG-based RAG
approaches, however, generally assume that anchor entities are accessible to
initiate graph traversal, which limits their robustness in open world settings
where accurate linking between the query and the entity is unreliable. To
overcome this limitation, we propose AnchorRAG, a novel multi-agent
collaboration framework for open-world RAG without the predefined anchor
entities. Specifically, a predictor agent dynamically identifies candidate
anchor entities by aligning user query terms with KG nodes and initializes
independent retriever agents to conduct parallel multi-hop explorations from
each candidate. Then a supervisor agent formulates the iterative retrieval
strategy for these retriever agents and synthesizes the resulting knowledge
paths to generate the final answer. This multi-agent collaboration framework
improves retrieval robustness and mitigates the impact of ambiguous or
erroneous anchors. Extensive experiments on four public benchmarks demonstrate
that AnchorRAG significantly outperforms existing baselines and establishes new
state-of-the-art results on the real-world question answering tasks.

</details>


### [488] [Communicative Agents for Slideshow Storytelling Video Generation based on LLMs](https://arxiv.org/abs/2509.01277)
*Jingxing Fan,Jinrong Shen,Yusheng Yao,Shuangqing Wang,Qian Wang,Yuling Wang*

Main category: cs.AI

TL;DR: VGTeam是一个创新的幻灯片视频生成系统，它利用大型语言模型（LLMs）和通信代理来降低成本并提高效率，同时保持高质量和可定制性，从而普及视频制作。


<details>
  <summary>Details</summary>
Motivation: 传统的文本到视频模型计算成本高昂，而VGTeam旨在通过集成LLM和代理来克服这一限制，提高视频生成的效率和可扩展性，同时降低计算开销。

Method: VGTeam是一个幻灯片视频生成系统，由一个负责脚本编写、场景创建和音频设计的通信代理套件组成。这些代理在一个聊天塔工作流中协同工作，将用户提供的文本提示转换为连贯的、幻灯片风格的叙事视频。

Result: VGTeam实现了显著的效率和可扩展性提升，同时大幅降低了计算开销，平均生成成本为0.103美元，成功率为98.4%，并保持了高度的创意保真度和可定制性。

Conclusion: VGTeam通过使更广泛的群体能够进行高质量的内容创作，普及了视频制作，并展示了语言模型在创意领域的变革潜力，有望成为下一代内容创作的开创性系统。

Abstract: With the rapid advancement of artificial intelligence (AI), the proliferation
of AI-generated content (AIGC) tasks has significantly accelerated developments
in text-to-video generation. As a result, the field of video production is
undergoing a transformative shift. However, conventional text-to-video models
are typically constrained by high computational costs.
  In this study, we propose Video-Generation-Team (VGTeam), a novel slide show
video generation system designed to redefine the video creation pipeline
through the integration of large language models (LLMs). VGTeam is composed of
a suite of communicative agents, each responsible for a distinct aspect of
video generation, such as scriptwriting, scene creation, and audio design.
These agents operate collaboratively within a chat tower workflow, transforming
user-provided textual prompts into coherent, slide-style narrative videos.
  By emulating the sequential stages of traditional video production, VGTeam
achieves remarkable improvements in both efficiency and scalability, while
substantially reducing computational overhead. On average, the system generates
videos at a cost of only $0.103, with a successful generation rate of 98.4%.
Importantly, this framework maintains a high degree of creative fidelity and
customization.
  The implications of VGTeam are far-reaching. It democratizes video production
by enabling broader access to high-quality content creation without the need
for extensive resources. Furthermore, it highlights the transformative
potential of language models in creative domains and positions VGTeam as a
pioneering system for next-generation content creation.

</details>


### [489] [GradeSQL: Outcome Reward Models for Ranking SQL Queries from Large Language Models](https://arxiv.org/abs/2509.01308)
*Mattia Tritto,Giuseppe Farano,Dario Di Palma,Gaetano Rossiello,Fedelucio Narducci,Dharmashankar Subramanian,Tommaso Di Noia*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text-to-SQL, the task of translating natural language questions into SQL
queries, has significantly advanced with the introduction of Large Language
Models (LLMs), broadening database accessibility for a wide range of users.
Despite substantial progress in generating valid SQL, current LLMs still
struggle with complex queries that require precise alignment between user
intent and the database schema. To mitigate this, test-time strategies such as
Best-of-N (BoN) and Majority Voting (Maj) are often employed, based on the
assumption that LLMs can generate correct answers but may require multiple
attempts. However, these methods rely on surface-level heuristics, selecting
either the syntactically correct query through execution-based BoN (ex-BoN) or
the most frequently generated query with Maj. Recently, Outcome Reward Models
(ORMs), which assign utility scores to generated outputs based on semantic
correctness, have emerged as a promising approach for better aligning model
predictions with user intent. Nevertheless, their application to Text-to-SQL
remains largely underexplored.
  In this work, we evaluate ORMs as an effective heuristic for BoN, compare
them with ex-BoN and Maj, and introduce a framework for training ORMs for the
Text-to-SQL task. We evaluate our ORMs on the BIRD and SPIDER benchmarks,
finetuning various open-source LLMs, including the Qwen2, Granite3, and Llama3
model families. Our results show that ORMs outperform ex-BoN and Maj, achieving
execution accuracy gains of +4.33% (BIRD) and +2.10% (Spider) over ex-BoN, and
+2.91% (BIRD) and +0.93% (Spider) over Maj. We further demonstrate that
finetuning models already aligned with SQL generation, such as OmniSQL, yields
superior ORM performance. Additionally, we observe that ORMs achieve
competitive results on simple queries and benefit more from an increased number
of candidates compared to ex-BoN and Maj.

</details>


### [490] [Conformal Predictive Monitoring for Multi-Modal Scenarios](https://arxiv.org/abs/2509.01338)
*Francesca Cairoli,Luca Bortolussi,Jyotirmoy V. Deshmukh,Lars Lindemann,Nicola Paoletti*

Main category: cs.AI

TL;DR: GenQPM使用基于分数的扩散模型来处理多模态动力学中的量化预测监控问题，提供更具信息量的模式特定预测区间。


<details>
  <summary>Details</summary>
Motivation: 现有量化预测监控（QPM）方法在处理具有多模态动力学的系统时效果不佳，会导致过于保守和无信息的预测区间。

Method: GenQPM利用深度生成模型（特别是基于分数的扩散模型）来近似概率性和多模态系统动力学，并结合模式分类器和保形推理来生成模式特定的预测区间。

Result: GenQPM在代理导航和自动驾驶任务的基准测试中，相比于模式不可知的方法，能够生成显著更具信息量（不那么保守）的预测区间。

Conclusion: GenQPM通过利用深度生成模型和模式分类，能够有效解决多模态动力学中的QPM问题，提供更精确和有用的预测区间。

Abstract: We consider the problem of quantitative predictive monitoring (QPM) of
stochastic systems, i.e., predicting at runtime the degree of satisfaction of a
desired temporal logic property from the current state of the system. Since
computational efficiency is key to enable timely intervention against predicted
violations, several state-of-the-art QPM approaches rely on fast
machine-learning surrogates to provide prediction intervals for the
satisfaction values, using conformal inference to offer statistical guarantees.
However, these QPM methods suffer when the monitored agent exhibits multi-modal
dynamics, whereby certain modes may yield high satisfaction values while others
critically violate the property. Existing QPM methods are mode-agnostic and so
would yield overly conservative and uninformative intervals that lack
meaningful mode-specific satisfaction information. To address this problem, we
present GenQPM, a method that leverages deep generative models, specifically
score-based diffusion models, to reliably approximate the probabilistic and
multi-modal system dynamics without requiring explicit model access. GenQPM
employs a mode classifier to partition the predicted trajectories by dynamical
mode. For each mode, we then apply conformal inference to produce statistically
valid, mode-specific prediction intervals. We demonstrate the effectiveness of
GenQPM on a benchmark of agent navigation and autonomous driving tasks,
resulting in prediction intervals that are significantly more informative (less
conservative) than mode-agnostic baselines.

</details>


### [491] [Error Notebook-Guided, Training-Free Part Retrieval in 3D CAD Assemblies via Vision-Language Models](https://arxiv.org/abs/2509.01350)
*Yunqing Liu,Nan Zhang,Zhiming Tan*

Main category: cs.AI

TL;DR: A new framework for part retrieval in CAD assemblies uses Error Notebooks and RAG for prompt engineering to improve performance without fine-tuning, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for part retrieval in CAD assemblies using LLMs/VLMs face challenges like token limits, unsatisfactory performance, and lack of fine-tuning access for proprietary models. This work aims to improve retrieval performance without requiring extra training or fine-tuning.

Method: The proposed framework involves constructing 'Error Notebooks' by collecting and correcting historical erroneous Chain-of-Thought (CoT) reasoning. Then, Retrieval-Augmented Generation (RAG) is used to retrieve relevant records from these notebooks and incorporate them into the inference process for prompt engineering.

Result: The framework achieved substantial performance gains when tested with proprietary models like GPT-4o and Gemini, with GPT-4o (Omni) showing up to a 23.4% absolute accuracy improvement on a human preference dataset. Ablation studies indicated that CoT reasoning is particularly beneficial for complex cases with more parts.

Conclusion: The novel framework effectively enhances part retrieval in CAD assemblies by leveraging Error Notebooks and RAG for prompt engineering, offering significant improvements without the need for model fine-tuning, and demonstrating strong performance even with complex 3D models and lengthy metadata.

Abstract: Effective specification-aware part retrieval within complex CAD assemblies is
essential for automated design verification and downstream engineering tasks.
However, directly using LLMs/VLMs to this task presents some challenges: the
input sequences may exceed model token limits, and even after processing,
performance remains unsatisfactory. Moreover, fine-tuning LLMs/VLMs requires
significant computational resources, and for many high-performing general-use
proprietary models (e.g., GPT or Gemini), fine-tuning access is not available.
In this paper, we propose a novel part retrieval framework that requires no
extra training, but using Error Notebooks + RAG for refined prompt engineering
to help improve the existing general model's retrieval performance. The
construction of Error Notebooks consists of two steps: (1) collecting
historical erroneous CoTs and their incorrect answers, and (2) connecting these
CoTs through reflective corrections until the correct solutions are obtained.
As a result, the Error Notebooks serve as a repository of tasks along with
their corrected CoTs and final answers. RAG is then employed to retrieve
specification-relevant records from the Error Notebooks and incorporate them
into the inference process. Another major contribution of our work is a
human-in-the-loop CAD dataset, which is used to evaluate our method. In
addition, the engineering value of our novel framework lies in its ability to
effectively handle 3D models with lengthy, non-natural language metadata.
Experiments with proprietary models, including GPT-4o and the Gemini series,
show substantial gains, with GPT-4o (Omni) achieving up to a 23.4% absolute
accuracy improvement on the human preference dataset. Moreover, ablation
studies confirm that CoT reasoning provides benefits especially in challenging
cases with higher part counts (>10).

</details>


### [492] [DeepResearch Arena: The First Exam of LLMs' Research Abilities via Seminar-Grounded Tasks](https://arxiv.org/abs/2509.01396)
*Haiyuan Wan,Chen Yang,Junchi Yu,Meiqi Tu,Jiaxuan Lu,Di Yu,Jianbao Cao,Ben Gao,Jiaqing Xie,Aoran Wang,Wenlong Zhang,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: 本论文提出了DeepResearch Arena，一个基于学术研讨会的基准，用于评估深度研究代理。该基准包含由多主体分层任务生成（MAHTG）系统从研讨会记录中提取和生成的10,000多个研究任务，涵盖12个学科。实验表明，该基准对现有研究代理提出了重大挑战。


<details>
  <summary>Details</summary>
Motivation: 评估深度研究代理在处理多阶段研究工作流（如文献综合、方法设计和实证验证）方面的能力，并解决了现有评估方法难以获取前沿研究问题并存在数据泄露风险的挑战。

Method: 提出了一种名为多主体分层任务生成（MAHTG）的系统，该系统从学术研讨会记录中提取研究灵感，并将其转化为高质量的研究任务，确保任务的可追溯性并过滤噪声。然后，利用MAHTG系统构建了DeepResearch Arena基准。

Result: DeepResearch Arena包含了来自200多个学术研讨会的10,000多个高质量研究任务，涵盖12个学科。通过对现有最先进研究代理的广泛评估，发现它们在DeepResearch Arena上面临重大挑战，不同模型之间存在明显的性能差距。

Conclusion: DeepResearch Arena是一个有效且具有挑战性的基准，用于评估深度研究代理。MAHTG系统能够有效地从学术研讨会中生成高质量的研究任务。现有的研究代理在该基准上仍有很大的提升空间。

Abstract: Deep research agents have attracted growing attention for their potential to
orchestrate multi-stage research workflows, spanning literature synthesis,
methodological design, and empirical verification. Despite these strides,
evaluating their research capability faithfully is rather challenging due to
the difficulty of collecting frontier research questions that genuinely capture
researchers' attention and intellectual curiosity. To address this gap, we
introduce DeepResearch Arena, a benchmark grounded in academic seminars that
capture rich expert discourse and interaction, better reflecting real-world
research environments and reducing the risk of data leakage. To automatically
construct DeepResearch Arena, we propose a Multi-Agent Hierarchical Task
Generation (MAHTG) system that extracts research-worthy inspirations from
seminar transcripts. The MAHTG system further translates research-worthy
inspirations into high-quality research tasks, ensuring the traceability of
research task formulation while filtering noise. With the MAHTG system, we
curate DeepResearch Arena with over 10,000 high-quality research tasks from
over 200 academic seminars, spanning 12 disciplines, such as literature,
history, and science. Our extensive evaluation shows that DeepResearch Arena
presents substantial challenges for current state-of-the-art agents, with clear
performance gaps observed across different models.

</details>


### [493] [The Need for Verification in AI-Driven Scientific Discovery](https://arxiv.org/abs/2509.01398)
*Cristina Cornelio,Takuya Ito,Ryan Cory-Wright,Sanjeeb Dash,Lior Horesh*

Main category: cs.AI

TL;DR: AI正在改变科学研究，特别是通过机器学习和LLM生成假设，但验证仍然是关键挑战。文章回顾了AI在科学发现中的应用和验证方法，强调了透明和严格的验证是AI辅助发现的基石。


<details>
  <summary>Details</summary>
Motivation: AI（特别是机器学习和LLM）有潜力跨领域加速科学发现，但由此产生的海量假设需要可扩展和可靠的验证机制，否则可能阻碍而非推进科学进步。

Method: 文章回顾了AI（包括数据驱动方法、知识感知神经网络、符号推理框架和LLM代理）在科学发现中的应用，并探讨了其验证方法，强调了透明和严格的验证的重要性。

Result: AI正在重塑科学发现的实践，能够以前所未有的速度和规模生成假设，但其科学价值取决于严格和透明的验证。

Conclusion: AI辅助发现的科学价值最终取决于严格和透明的验证，这应该是AI辅助发现的基石。

Abstract: Artificial intelligence (AI) is transforming the practice of science. Machine
learning and large language models (LLMs) can generate hypotheses at a scale
and speed far exceeding traditional methods, offering the potential to
accelerate discovery across diverse fields. However, the abundance of
hypotheses introduces a critical challenge: without scalable and reliable
mechanisms for verification, scientific progress risks being hindered rather
than being advanced. In this article, we trace the historical development of
scientific discovery, examine how AI is reshaping established practices for
scientific discovery, and review the principal approaches, ranging from
data-driven methods and knowledge-aware neural architectures to symbolic
reasoning frameworks and LLM agents. While these systems can uncover patterns
and propose candidate laws, their scientific value ultimately depends on
rigorous and transparent verification, which we argue must be the cornerstone
of AI-assisted discovery.

</details>


### [494] [Counterfactual Sensitivity for Faithful Reasoning in Language Models](https://arxiv.org/abs/2509.01544)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.AI

TL;DR: CSR是一种新的训练目标，通过引入算子级反事实干预来增强LLM推理过程的忠实性，并使用COS指标进行衡量，在多个任务上表现优于标准微调和过程监督。


<details>
  <summary>Details</summary>
Motivation: LLMs在提供正确答案时可能依赖于错误或不相关的推理过程，这在关键领域降低了它们的可靠性。

Method: CSR通过在训练过程中引入自动化的、算子级别的反事实干预（例如，将“+”替换为“-”）来强制中间推理与最终输出之间的依赖关系，并惩罚在逻辑无效的推理过程中保持相同答案的模型。该方法每次样本仅需一次额外的正向传播。使用Counterfactual Outcome Sensitivity (COS)指标来量化这些扰动对模型预测的影响。

Result: 在算术（GSM8K）、逻辑推理（PrOntoQA）和规划（Blocks World）等结构化推理任务上，CSR将忠实性提高了高达70个百分点，同时仅有轻微的准确率损失。该方法学习到的敏感性可以泛化到更大的模型，并与self-consistency等推理时方法协同作用。在HellaSwag上的初步研究表明，通过结合语义扰动可以增强常识推理的忠实性。

Conclusion: CSR是一种轻量级但有效的训练目标，可以显著提高LLM在结构化推理任务中的忠实性，并且具有良好的泛化性和与其他方法的协同性。

Abstract: Large language models (LLMs) often produce correct answers while relying on
flawed or irrelevant reasoning traces, undermining their trustworthiness in
high-stakes domains. We propose Counterfactual Sensitivity Regularization
(CSR), a lightweight training objective that enforces dependence between
intermediate reasoning and final outputs. CSR introduces automated,
operator-level counterfactual interventions (e.g., swapping "+" with "-")
during training and penalizes models that preserve the same answer under
logically invalid traces. This requires only one additional forward pass per
sample. To measure faithfulness, we introduce Counterfactual Outcome
Sensitivity (COS), which quantifies the impact of such perturbations on model
predictions. Across structured reasoning tasks - arithmetic (GSM8K), logical
deduction (PrOntoQA), and planning (Blocks World) - CSR improves faithfulness
by up to 70 percentage points over standard fine-tuning and process
supervision, with only minor accuracy loss. The learned sensitivity generalizes
to larger models and synergizes with inference-time methods such as
self-consistency. A pilot study on HellaSwag further demonstrates that
extending CSR with semantic perturbations can enhance faithfulness in
commonsense reasoning.

</details>


### [495] [Structured AI Decision-Making in Disaster Management](https://arxiv.org/abs/2509.01576)
*Julian Gerald Dcruz,Argyrios Zolotas,Niall Ross Greenwood,Miguel Arana-Catania*

Main category: cs.AI

TL;DR: 该研究提出了一种结构化决策框架，用于在航空航天和应急响应等安全关键领域实现负责任的人工智能，并通过在灾难管理中的应用对其进行了评估。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在航空航天和应急响应等安全关键领域的决策自主性应用日益广泛，需要解决这些决策的伦理问题，以确保在涉及生命的情况下决策的可靠性和可辩护性。

Method: 提出了一种结构化决策框架，并在灾难管理中进行实现，引入了赋能代理、级别和场景等概念，并与仅依赖判断的系统以及具有灾难经验的人类操作员（受害者、志愿者和利益相关者）进行了性能比较。

Result: 与基于判断的系统相比，该结构化决策框架在多个场景中实现了一致准确决策的稳定性提高了 60.94%。此外，与人类操作员相比，该框架在各种场景中的准确性提高了 38.93%。

Conclusion: 研究结果表明，该结构化决策框架在提高安全关键应用中更可靠的自主人工智能方面具有巨大潜力。

Abstract: With artificial intelligence (AI) being applied to bring autonomy to
decision-making in safety-critical domains such as the ones typified in the
aerospace and emergency-response services, there has been a call to address the
ethical implications of structuring those decisions, so they remain reliable
and justifiable when human lives are at stake. This paper contributes to
addressing the challenge of decision-making by proposing a structured
decision-making framework as a foundational step towards responsible AI. The
proposed structured decision-making framework is implemented in autonomous
decision-making, specifically within disaster management. By introducing
concepts of Enabler agents, Levels and Scenarios, the proposed framework's
performance is evaluated against systems relying solely on judgement-based
insights, as well as human operators who have disaster experience: victims,
volunteers, and stakeholders. The results demonstrate that the structured
decision-making framework achieves 60.94% greater stability in consistently
accurate decisions across multiple Scenarios, compared to judgement-based
systems. Moreover, the study shows that the proposed framework outperforms
human operators with a 38.93% higher accuracy across various Scenarios. These
findings demonstrate the promise of the structured decision-making framework
for building more reliable autonomous AI applications in safety-critical
contexts.

</details>


### [496] [Throttling Web Agents Using Reasoning Gates](https://arxiv.org/abs/2509.01619)
*Abhinav Kumar,Jaechul Roh,Ali Naseh,Amir Houmansadr,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 该论文提出了一种名为“Web Agent Throttling”的框架，通过在提供资源访问前对AI网络代理施加可调成本来防御恶意或错误部署的代理。该框架设计了“Throttling Gates”作为挑战，要求代理解决基于“rebus”的推理谜题，以增加其代币生成成本。实验表明，该框架能有效提高响应生成成本，并已在实际网站和MCP服务器上进行了部署和评估。


<details>
  <summary>Details</summary>
Motivation: AI网络代理的广泛应用带来了潜在的风险，如过载内容提供商、绕过安全措施、以及利用虚假账户泛滥认证系统。因此，有必要保护服务和内容免受来自这些代理的拒绝服务攻击和抓取。

Method: 设计了一个名为“Web Agent Throttling”的框架，其中包含“Throttling Gates”。这些 gates 通过向代理发出挑战来施加可调成本。重点关注代理的语言模型组件，要求代理解决推理谜题，从而产生高昂的代币生成成本。为了满足特定属性（非对称性、可扩展性、鲁棒性和兼容性），论文引入了基于“rebus”的推理门（rebus-based Reasoning Gates），这是一种需要跨越多步推理和世界知识的合成文本谜题。论文还设计了一个可扩展的生成和验证协议。

Result: 所提出的框架实现了计算非对称性，使得响应生成成本比最先进模型（SOTA models）的生成成本高出9.2倍。该框架已成功部署在自定义网站和模型上下文协议（MCP）服务器上，并使用真实的Web代理进行了评估。

Conclusion: 论文成功设计并实现了一个名为“Web Agent Throttling”的框架，通过引入基于“rebus”的推理门来有效防御AI网络代理的潜在风险。该框架通过增加代理的计算成本，提高了安全性，并在实际环境中得到了验证。同时，论文也讨论了该框架在实际部署中可能存在的局限性和环境影响。

Abstract: AI web agents use Internet resources at far greater speed, scale, and
complexity -- changing how users and services interact. Deployed maliciously or
erroneously, these agents could overload content providers. At the same time,
web agents can bypass CAPTCHAs and other defenses by mimicking user behavior or
flood authentication systems with fake accounts. Yet providers must protect
their services and content from denial-of-service attacks and scraping by web
agents. In this paper, we design a framework that imposes tunable costs on
agents before providing access to resources; we call this Web Agent Throttling.
We start by formalizing Throttling Gates as challenges issued to an agent that
are asymmetric, scalable, robust, and compatible with any agent. Focusing on a
common component -- the language model -- we require the agent to solve
reasoning puzzles, thereby incurring excessive token-generation costs. However,
we find that using existing puzzles, e.g., coding or math, as throttling gates
fails to satisfy our properties. To address this, we introduce rebus-based
Reasoning Gates, synthetic text puzzles that require multi-hop reasoning over
world knowledge (thereby throttling an agent's model). We design a scalable
generation and verification protocol for such reasoning gates. Our framework
achieves computational asymmetry, i.e., the response-generation cost is 9.2x
higher than the generation cost for SOTA models. We further deploy reasoning
gates on a custom website and Model Context Protocol (MCP) servers and evaluate
with real-world web agents. Finally, we discuss the limitations and
environmental impact of real-world deployment of our framework.

</details>


### [497] [Unraveling LLM Jailbreaks Through Safety Knowledge Neurons](https://arxiv.org/abs/2509.01631)
*Chongwen Zhao,Kaizhu Huang*

Main category: cs.AI

TL;DR: LLM越狱攻击可以通过分析安全相关神经元并进行SafeTuning进行防御。


<details>
  <summary>Details</summary>
Motivation: 用户试图利用LLM进行恶意目的，例如合成管制物质和传播虚假信息，即“越狱”。

Method: 提出了一种新的神经元级别可解释性方法，该方法侧重于安全相关知识神经元的作用，并将模型的内部表示投影到更一致、可解释的词汇空间中。基于此，提出了一种名为SafeTuning的微调策略。

Result: 通过调整安全相关神经元的激活可以有效地控制模型的行为，平均攻击成功率（ASR）高于97%。SafeTuning在多个LLM上持续降低了攻击成功率，并且优于所有四个基线防御。

Conclusion: 这项工作为理解和防御越狱攻击提供了新的视角。

Abstract: Large Language Models (LLMs) are increasingly attracting attention in various
applications. Nonetheless, there is a growing concern as some users attempt to
exploit these models for malicious purposes, including the synthesis of
controlled substances and the propagation of disinformation, a technique known
as "Jailbreak." While some studies have achieved defenses against jailbreak
attacks by modifying output distributions or detecting harmful content, the
exact rationale still remains elusive. In this work, we present a novel
neuron-level interpretability method that focuses on the role of safety-related
knowledge neurons. Unlike existing approaches, our method projects the model's
internal representation into a more consistent and interpretable vocabulary
space. We then show that adjusting the activation of safety-related neurons can
effectively control the model's behavior with a mean ASR higher than 97%.
Building on this insight, we propose SafeTuning, a fine-tuning strategy that
reinforces safety-critical neurons to improve model robustness against
jailbreaks. SafeTuning consistently reduces attack success rates across
multiple LLMs and outperforms all four baseline defenses. These findings offer
a new perspective on understanding and defending against jailbreak attacks.

</details>


### [498] [Physics Supernova: AI Agent Matches Elite Gold Medalists at IPhO 2025](https://arxiv.org/abs/2509.01659)
*Jiahao Qiu,Jingzhe Shi,Xinzhe Juan,Zelin Zhao,Jiayi Geng,Shilong Liu,Hongru Wang,Sanfeng Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: AI代理Physics Supernova在国际物理奥林匹克竞赛（IPhO）中表现出色，得分达到23.5/30，排名第14位，超过了人类金牌选手的中位数表现。


<details>
  <summary>Details</summary>
Motivation: AI系统需要具备理解和应用物理定律的能力，以应对现实世界的复杂性，国际物理奥林匹克竞赛（IPhO）是衡量这一能力的理想基准。

Method: 开发了一个名为Physics Supernova的AI代理系统，并进行了广泛的测试和分析，以评估其在解决各种物理问题方面的能力和灵活性。

Result: Physics Supernova在IPhO 2025理论问题中获得23.5/30分，超越了人类金牌选手的中位数表现。

Conclusion: 将原则性工具集成到AI代理系统中，能够显著提升解决科学挑战问题的能力。

Abstract: Physics provides fundamental laws that describe and predict the natural
world. AI systems aspiring toward more general, real-world intelligence must
therefore demonstrate strong physics problem-solving abilities: to formulate
and apply physical laws for explaining and predicting physical processes. The
International Physics Olympiad (IPhO)--the world's most prestigious physics
competition--offers a rigorous benchmark for this purpose. We introduce Physics
Supernova, an AI agent system with superior physics problem-solving abilities
that match elite IPhO gold medalists. In IPhO 2025 theory problems, Physics
Supernova attains 23.5/30 points, ranking 14th of 406 contestants and
surpassing the median performance of human gold medalists. We extensively
analyzed Physics Supernova's capabilities and flexibility across diverse
physics tasks. These results show that principled tool integration within agent
systems can deliver competitive improvements in solving challenging science
problems. The codes are available at
https://github.com/CharlesQ9/Physics-Supernova.

</details>


### [499] [An LLM-enabled semantic-centric framework to consume privacy policies](https://arxiv.org/abs/2509.01716)
*Rui Zhao,Vladyslav Melnychuk,Jun Zhao,Jesse Wright,Nigel Shadbolt*

Main category: cs.AI

TL;DR: 人们因难以理解而忽略在线服务条款，该研究提出一种基于LLM的自动化方法，从隐私政策中提取关键信息，构建名为Pr²Graph的知识图谱，以支持合规性检查和形式化策略表示，并已应用于前100名热门网站，同时发布了数据集和源代码以供研究和改进。


<details>
  <summary>Details</summary>
Motivation: 现有研究在自动化识别和形式化隐私政策方面存在关键差距，难以大规模获取用于验证合规性的正式政策。

Method: 提出一种语义中心的方法，利用先进的大型语言模型（LLM）自动识别隐私政策中的关键信息，并构建一个基于数据隐私词汇（DPV）的隐私实践知识图谱（Pr²Graph），以支持下游任务。

Result: 构建了Pr²Graph，并将其应用于前100名热门网站，发布了相关数据集和源代码。研究还展示了如何使用Pr²Graph构建ODRL或psDToU等形式化策略表示，并通过包含法律专家注释的Policy-IE数据集验证了LLM在管道中的性能。

Conclusion: 该研究展示了大规模分析在线服务隐私实践的可能性，为审计网络和互联网提供了一个有前景的方向，并公开了所有数据集和源代码以促进重复使用和改进。

Abstract: In modern times, people have numerous online accounts, but they rarely read
the Terms of Service or Privacy Policy of those sites, despite claiming
otherwise, due to the practical difficulty in comprehending them. The mist of
data privacy practices forms a major barrier for user-centred Web approaches,
and for data sharing and reusing in an agentic world. Existing research
proposed methods for using formal languages and reasoning for verifying the
compliance of a specified policy, as a potential cure for ignoring privacy
policies. However, a critical gap remains in the creation or acquisition of
such formal policies at scale. We present a semantic-centric approach for using
state-of-the-art large language models (LLM), to automatically identify key
information about privacy practices from privacy policies, and construct
$\mathit{Pr}^2\mathit{Graph}$, knowledge graph with grounding from Data Privacy
Vocabulary (DPV) for privacy practices, to support downstream tasks. Along with
the pipeline, the $\mathit{Pr}^2\mathit{Graph}$ for the top-100 popular
websites is also released as a public resource, by using the pipeline for
analysis. We also demonstrate how the $\mathit{Pr}^2\mathit{Graph}$ can be used
to support downstream tasks by constructing formal policy representations such
as Open Digital Right Language (ODRL) or perennial semantic Data Terms of Use
(psDToU). To evaluate the technology capability, we enriched the Policy-IE
dataset by employing legal experts to create custom annotations. We benchmarked
the performance of different large language models for our pipeline and
verified their capabilities. Overall, they shed light on the possibility of
large-scale analysis of online services' privacy practices, as a promising
direction to audit the Web and the Internet. We release all datasets and source
code as public resources to facilitate reuse and improvement.

</details>


### [500] [Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models](https://arxiv.org/abs/2509.01909)
*Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue*

Main category: cs.AI

TL;DR: CSA是一种以人为中心的安全范式，旨在防御恶意使用，同时引导弱势用户走向安全和有益的结果。它通过结合博弈论、细粒度风险边界发现和可解释的推理控制来实现，将安全转化为一个建立信任的过程。


<details>
  <summary>Details</summary>
Motivation: 现有安全机制通常只关注恶意行为者造成的风险，并依赖防御性拒绝。然而，现实世界中的风险也来自有心理困扰（例如自残意图）而非恶意的用户，此时模型的响应会显著影响用户的行为。简单的拒绝可能导致用户重复尝试、升级行为或转向不安全的平台，造成更糟的结果。

Method: CSA是一种以人为中心的安全范式，通过结合博弈论的博弈论用户反应预测、细粒度风险边界发现和可解释的推理控制来实现。该范式已被应用于Oyster-I（Oy1）模型。

Result: Oy1在公开模型中实现了最先进的安全水平，同时保持了高通用能力。在Constructive Benchmark上，其建设性参与表现接近GPT-5，在Strata-Sword越狱数据集上的鲁棒性接近GPT-o1。

Conclusion: CSA通过从“先拒绝”转向“先引导”的安全模式，重新定义了模型-用户关系，旨在构建不仅安全而且有意义地有益的系统。研究者发布了Oy1模型、代码和基准测试，以支持负责任的、以用户为中心的AI。

Abstract: Large language models (LLMs) typically deploy safety mechanisms to prevent
harmful content generation. Most current approaches focus narrowly on risks
posed by malicious actors, often framing risks as adversarial events and
relying on defensive refusals. However, in real-world settings, risks also come
from non-malicious users seeking help while under psychological distress (e.g.,
self-harm intentions). In such cases, the model's response can strongly
influence the user's next actions. Simple refusals may lead them to repeat,
escalate, or move to unsafe platforms, creating worse outcomes. We introduce
Constructive Safety Alignment (CSA), a human-centric paradigm that protects
against malicious misuse while actively guiding vulnerable users toward safe
and helpful results. Implemented in Oyster-I (Oy1), CSA combines game-theoretic
anticipation of user reactions, fine-grained risk boundary discovery, and
interpretable reasoning control, turning safety into a trust-building process.
Oy1 achieves state-of-the-art safety among open models while retaining high
general capabilities. On our Constructive Benchmark, it shows strong
constructive engagement, close to GPT-5, and unmatched robustness on the
Strata-Sword jailbreak dataset, nearing GPT-o1 levels. By shifting from
refusal-first to guidance-first safety, CSA redefines the model-user
relationship, aiming for systems that are not just safe, but meaningfully
helpful. We release Oy1, code, and the benchmark to support responsible,
user-centered AI.

</details>


### [501] [EigenBench: A Comparative Behavioral Measure of Value Alignment](https://arxiv.org/abs/2509.01938)
*Jonathn Chang,Leonard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine*

Main category: cs.AI

TL;DR: EigenBench是一个新的基准测试方法，用于量化语言模型与人类价值观的对齐程度，该方法不依赖于地面真实标签，而是通过模型之间的相互评估来计算对齐分数。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI价值观对齐领域缺乏量化指标的问题，提出EigenBench方法。

Method: EigenBench是一种黑盒方法，通过模型对多场景下其他模型的输出来进行评判，并利用EigenTrust算法聚合这些评判，从而得到量化每个模型与给定宪法（价值观体系）对齐程度的得分向量。该方法不依赖地面真实标签，而是允许存在不同意见的合理评判者进行评判。通过提示的Persona进行测试，发现得分对提示比对模型更敏感，但模型本身也存在一小部分可量化的倾向性。

Result: EigenBench得分主要受提示影响，但模型本身的倾向性也有一小部分可以量化。

Conclusion: EigenBench是一种新颖的AI价值观对齐量化方法，通过模型间的相互评估和EigenTrust算法，可以有效衡量模型与特定价值观体系的对齐程度，并能区分提示和模型本身对对齐得分的影响。

Abstract: Aligning AI with human values is a pressing unsolved problem. To address the
lack of quantitative metrics for value alignment, we propose EigenBench: a
black-box method for comparatively benchmarking language models' values. Given
an ensemble of models, a constitution describing a value system, and a dataset
of scenarios, our method returns a vector of scores quantifying each model's
alignment to the given constitution. To produce these scores, each model judges
the outputs of other models across many scenarios, and these judgments are
aggregated with EigenTrust (Kamvar et al, 2003), yielding scores that reflect a
weighted-average judgment of the whole ensemble. EigenBench uses no ground
truth labels, as it is designed to quantify traits for which reasonable judges
may disagree on the correct label. Using prompted personas, we test whether
EigenBench scores are more sensitive to the model or the prompt: we find that
most of the variance is explained by the prompt, but a small residual
quantifies the disposition of the model itself.

</details>


### [502] [mFARM: Towards Multi-Faceted Fairness Assessment based on HARMs in Clinical Decision Support](https://arxiv.org/abs/2509.02007)
*Shreyash Adappanavar,Krithi Shailya,Gokul S Krishnan,Sriraam Natarajan,Balaraman Ravindran*

Main category: cs.AI

TL;DR: LLM在医疗领域的公平性评估存在挑战，现有方法无法捕捉多维度医疗危害。本文提出了一个包含两个基准和mFARM多指标框架，以评估LLM在医疗场景下的公平性，并结合FAB分数衡量公平性与准确性的平衡，发现量化对mFARM影响小，但上下文减少会显著降低性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM公平性评估方法无法满足高风险医疗场景的需求，它们使用的简单指标忽略了医疗危害的多维度性，并且可能导致模型因过于保守而不准确。

Method: 构建了包含50,000多个提示、12种种族x性别变体和3种上下文层级的ED-Triage和Opioid Analgesic Recommendation两大基准。提出了一个多指标框架mFARM，用于评估三个不同维度（分配、稳定性和潜在）的差异，并将其汇总为mFARM分数。还提出FAB分数来评估公平性与准确性的权衡。

Result: mFARM指标在各种设置下能更有效地捕捉细微偏见。大多数模型在量化变化下mFARM分数保持稳定，但在上下文减少时性能显著下降。

Conclusion: 提出的基准和评估代码将有助于促进医疗领域对齐AI的研究。

Abstract: The deployment of Large Language Models (LLMs) in high-stakes medical
settings poses a critical AI alignment challenge, as models can inherit and
amplify societal biases, leading to significant disparities. Existing fairness
evaluation methods fall short in these contexts as they typically use
simplistic metrics that overlook the multi-dimensional nature of medical harms.
This also promotes models that are fair only because they are clinically inert,
defaulting to safe but potentially inaccurate outputs. To address this gap, our
contributions are mainly two-fold: first, we construct two large-scale,
controlled benchmarks (ED-Triage and Opioid Analgesic Recommendation) from
MIMIC-IV, comprising over 50,000 prompts with twelve race x gender variants and
three context tiers. Second, we propose a multi-metric framework -
Multi-faceted Fairness Assessment based on hARMs ($mFARM$) to audit fairness
for three distinct dimensions of disparity (Allocational, Stability, and
Latent) and aggregate them into an $mFARM$ score. We also present an aggregated
Fairness-Accuracy Balance (FAB) score to benchmark and observe trade-offs
between fairness and prediction accuracy. We empirically evaluate four
open-source LLMs (Mistral-7B, BioMistral-7B, Qwen-2.5-7B, Bio-LLaMA3-8B) and
their finetuned versions under quantization and context variations. Our
findings showcase that the proposed $mFARM$ metrics capture subtle biases more
effectively under various settings. We find that most models maintain robust
performance in terms of $mFARM$ score across varying levels of quantization but
deteriorate significantly when the context is reduced. Our benchmarks and
evaluation code are publicly released to enhance research in aligned AI for
healthcare.

</details>


### [503] [Generative KI für TA](https://arxiv.org/abs/2509.02053)
*Wolfgang Eppler,Reinhard Heil*

Main category: cs.AI

TL;DR: Many scientists use generative AI, including in technology assessment (TA). TA uses generative AI for its work and researches it. The article discusses structural causes of problems, risks, and proposes solutions, with examples.


<details>
  <summary>Details</summary>
Motivation: To outline the phenomenon of generative AI and formulate requirements for its use in TA, then discuss the structural causes of associated problems and risks.

Method: Discussing the structural causes of problems associated with generative AI in TA, and proposing solutions.

Result: Generative AI is used in TA for its work and is the subject of TA research. Structurally induced risks remain despite continuous development.

Conclusion: Proposed solutions and notes on their feasibility, along with examples of generative AI use in TA work are provided, acknowledging that structurally induced risks remain.

Abstract: Many scientists use generative AI in their scientific work. People working in
technology assessment (TA) are no exception. TA's approach to generative AI is
twofold: on the one hand, generative AI is used for TA work, and on the other
hand, generative AI is the subject of TA research. After briefly outlining the
phenomenon of generative AI and formulating requirements for its use in TA, the
following article discusses in detail the structural causes of the problems
associated with it. Although generative AI is constantly being further
developed, the structurally induced risks remain. The article concludes with
proposed solutions and brief notes on their feasibility, as well as some
examples of the use of generative AI in TA work.

</details>


### [504] [AGI as Second Being: The Structural-Generative Ontology of Intelligence](https://arxiv.org/abs/2509.02089)
*Maijunxian Wang,Ran Ji*

Main category: cs.AI

TL;DR: 真正的智能需要生成新结构、协调它们进行推理并保持自身身份，而当前AI缺乏这种深度。


<details>
  <summary>Details</summary>
Motivation: 区分真正智能和表面模拟，提出智能的结构-生成本体论。

Method: 提出三个条件：生成性、协调性和持续性，以定义真正的智能深度。

Result: 当前AI系统虽然功能广泛，但因缺乏深度而仅是表面模拟。

Conclusion: 满足生成性、协调性和持续性条件的AI系统可能成为与人类并存的“第二生命”。

Abstract: Artificial intelligence is often measured by the range of tasks it can
perform. Yet wide ability without depth remains only an imitation. This paper
proposes a Structural-Generative Ontology of Intelligence: true intelligence
exists only when a system can generate new structures, coordinate them into
reasons, and sustain its identity over time. These three conditions --
generativity, coordination, and sustaining -- define the depth that underlies
real intelligence. Current AI systems, however broad in function, remain
surface simulations because they lack this depth. Breadth is not the source of
intelligence but the growth that follows from depth. If future systems were to
meet these conditions, they would no longer be mere tools, but could be seen as
a possible Second Being, standing alongside yet distinct from human existence.

</details>


### [505] [LLMs for LLMs: A Structured Prompting Methodology for Long Legal Documents](https://arxiv.org/abs/2509.02241)
*Strahinja Klem,Noura Al Moubayed*

Main category: cs.AI

TL;DR: LLMs在法律领域的应用因可靠性和透明度问题而面临挑战。本研究提出了一种结构化提示方法，通过文档分块、增强和精心设计的提示，利用QWEN-2模型处理长法律文档信息检索任务。结合分布定位和逆基数加权启发式方法，解决了候选答案选择问题，提升了模型性能并强调了结构化提示在法律领域AI问责中的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在法律领域应用中的可靠性和透明度问题，并为处理长法律文档信息检索任务提供一种替代昂贵微调的方案。

Method: 1.文档分块与增强：将长文档分割成块以解决长文档问题。
2.结构化提示与QWEN-2：结合工程化提示，将输入喂给QWEN-2生成答案。
3.启发式方法：采用分布定位和逆基数加权启发式方法解决候选答案选择问题。

Result: 该方法比先前方法性能提升高达9%，达到了最先进水平，但也凸显了当前自动评估指标的局限性。

Conclusion: 结构化提示工程是确保法律领域乃至更广泛领域中AI问责和责任的有用且未被充分探索的工具。

Abstract: The rise of Large Language Models (LLMs) has had a profoundly transformative
effect on a number of fields and domains. However, their uptake in Law has
proven more challenging due to the important issues of reliability and
transparency. In this study, we present a structured prompting methodology as a
viable alternative to the often expensive fine-tuning, with the capability of
tacking long legal documents from the CUAD dataset on the task of information
retrieval. Each document is first split into chunks via a system of chunking
and augmentation, addressing the long document problem. Then, alongside an
engineered prompt, the input is fed into QWEN-2 to produce a set of answers for
each question. Finally, we tackle the resulting candidate selection problem
with the introduction of the Distribution-based Localisation and Inverse
Cardinality Weighting heuristics. This approach leverages a general purpose
model to promote long term scalability, prompt engineering to increase
reliability and the two heuristic strategies to reduce the impact of the black
box effect. Whilst our model performs up to 9\% better than the previously
presented method, reaching state-of-the-art performance, it also highlights the
limiting factor of current automatic evaluation metrics for question answering,
serving as a call to action for future research. However, the chief aim of this
work is to underscore the potential of structured prompt engineering as a
useful, yet under-explored, tool in ensuring accountability and responsibility
of AI in the legal domain, and beyond.

</details>


### [506] [An Epidemiological Knowledge Graph extracted from the World Health Organization's Disease Outbreak News](https://arxiv.org/abs/2509.02258)
*Sergio Consoli,Pietro Coletti,Peter V. Markov,Lia Orfei,Indaco Biazzo,Lea Schuh,Nicolas Stefanovitch,Lorenzo Bertolini,Mario Ceresa,Nikolaos I. Stilianakis*

Main category: cs.AI

TL;DR: This paper uses generative AI and Large Language Models (LLMs) to extract epidemiological information from WHO Disease Outbreak News (DONs), creating a daily-updated dataset and a knowledge graph (eKG) to aid in disease outbreak analysis and surveillance.


<details>
  <summary>Details</summary>
Motivation: The rapid evolution of AI and the increased availability of social media and news for epidemiological surveillance present a pivotal moment for public health research. This work aims to leverage these advancements for more effective disease outbreak monitoring.

Method: An ensemble approach incorporating multiple Large Language Models (LLMs) was used to extract actionable epidemiological information from WHO Disease Outbreak News (DONs). The extracted information is organized into a daily-updated dataset and a knowledge graph named eKG.

Result: A daily-updated dataset and a knowledge graph (eKG) were created from WHO DONs, providing a nuanced representation of public health domain knowledge. Services and tools for accessing and utilizing this data are also being developed.

Conclusion: The developed data resources, including the dataset and eKG, offer new opportunities for epidemiological research, disease outbreak analysis, and surveillance by utilizing generative AI and LLMs.

Abstract: The rapid evolution of artificial intelligence (AI), together with the
increased availability of social media and news for epidemiological
surveillance, are marking a pivotal moment in epidemiology and public health
research. Leveraging the power of generative AI, we use an ensemble approach
which incorporates multiple Large Language Models (LLMs) to extract valuable
actionable epidemiological information from the World Health Organization (WHO)
Disease Outbreak News (DONs). DONs is a collection of regular reports on global
outbreaks curated by the WHO and the adopted decision-making processes to
respond to them. The extracted information is made available in a daily-updated
dataset and a knowledge graph, referred to as eKG, derived to provide a nuanced
representation of the public health domain knowledge. We provide an overview of
this new dataset and describe the structure of eKG, along with the services and
tools used to access and utilize the data that we are building on top. These
innovative data resources open altogether new opportunities for epidemiological
research, and the analysis and surveillance of disease outbreaks.

</details>


### [507] [Rewarding Explainability in Drug Repurposing with Knowledge Graphs](https://arxiv.org/abs/2509.02276)
*Susana Nunes,Samy Badreddine,Catia Pesquita*

Main category: cs.AI

TL;DR: REx是一种基于知识图谱链接预测的新型科学解释生成方法，通过强化学习生成解释性路径，并利用领域本体丰富解释，在药物再利用任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高预测方法在科学界的接受度，需要确保其准确性并提供有意义的科学解释，特别是在药物再利用等应用中。

Method: REx使用奖励和策略机制，指导强化学习代理在知识图谱中识别解释性路径，并通过领域本体丰富这些路径，以生成符合科学解释特性的解释。

Result: REx在药物再利用任务的三个常用知识图谱基准测试中，能够生成验证预测见解与生物医学知识的解释，并且预测性能优于现有最先进的方法。

Conclusion: REx通过生成与生物医学知识一致且具有更高预测性能的解释，为推动AI驱动的科学发现做出了贡献。

Abstract: Knowledge graphs (KGs) are powerful tools for modelling complex,
multi-relational data and supporting hypothesis generation, particularly in
applications like drug repurposing. However, for predictive methods to gain
acceptance as credible scientific tools, they must ensure not only accuracy but
also the capacity to offer meaningful scientific explanations. This paper
presents a novel approach REx, for generating scientific explanations based in
link prediction in knowledge graphs. It employs reward and policy mechanisms
that consider desirable properties of scientific explanation to guide a
reinforcement learning agent in the identification of explanatory paths within
a KG. The approach further enriches explanatory paths with domain-specific
ontologies, ensuring that the explanations are both insightful and grounded in
established biomedical knowledge. We evaluate our approach in drug repurposing
using three popular knowledge graph benchmarks. The results clearly demonstrate
its ability to generate explanations that validate predictive insights against
biomedical knowledge and that outperform the state-of-the-art approaches in
predictive performance, establishing REx as a relevant contribution to advance
AI-driven scientific discovery.

</details>


### [508] [Re-evaluating LLM-based Heuristic Search: A Case Study on the 3D Packing Problem](https://arxiv.org/abs/2509.02297)
*Guorui Quan,Mingfei Sun,Manuel López-Ibáñez*

Main category: cs.AI

TL;DR: LLM被用于解决3D打包问题，但其局限性在于专注于评分函数和对约束的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在设计启发式算法方面的潜力，特别是在解决复杂的约束问题时。

Method: LLM被要求从头开始构建一个3D打包问题的求解器，并辅以约束脚手架和迭代自我修正。

Result: LLM生成的启发式算法在性能上与人类设计的贪婪算法相当，并能在元启发式算法中与现有求解器相媲美，但在约束条件严格时性能会下降。

Conclusion: 目前LLM在自动化启发式算法设计方面存在两大障碍：在复杂推理任务中缓解其脆弱性所需的工程技术，以及预训练偏见可能过早地缩小新颖解决方案的搜索范围。

Abstract: The art of heuristic design has traditionally been a human pursuit. While
Large Language Models (LLMs) can generate code for search heuristics, their
application has largely been confined to adjusting simple functions within
human-crafted frameworks, leaving their capacity for broader innovation an open
question. To investigate this, we tasked an LLM with building a complete solver
for the constrained 3D Packing Problem. Direct code generation quickly proved
fragile, prompting us to introduce two supports: constraint
scaffolding--prewritten constraint-checking code--and iterative
self-correction--additional refinement cycles to repair bugs and produce a
viable initial population. Notably, even within a vast search space in a greedy
process, the LLM concentrated its efforts almost exclusively on refining the
scoring function. This suggests that the emphasis on scoring functions in prior
work may reflect not a principled strategy, but rather a natural limitation of
LLM capabilities. The resulting heuristic was comparable to a human-designed
greedy algorithm, and when its scoring function was integrated into a
human-crafted metaheuristic, its performance rivaled established solvers,
though its effectiveness waned as constraints tightened. Our findings highlight
two major barriers to automated heuristic design with current LLMs: the
engineering required to mitigate their fragility in complex reasoning tasks,
and the influence of pretrained biases, which can prematurely narrow the search
for novel solutions.

</details>


### [509] [Exploring Diffusion Models for Generative Forecasting of Financial Charts](https://arxiv.org/abs/2509.02308)
*Taegyeong Lee,Jiwon Park,Kyunga Bang,Seunghyun Hwang,Ung-Jin Jang*

Main category: cs.AI

TL;DR: 该论文提出了一种利用文本到图像生成模型来预测股票价格趋势的新方法，将时间序列数据视为图像模式，并使用扩散模型生成股票图表。


<details>
  <summary>Details</summary>
Motivation: 金融领域在应用生成模型方面存在局限，该研究旨在探索文本到图像模型在金融领域（特别是股票价格预测）的应用潜力。

Method: 将时间序列数据转化为图像模式，并利用文本到图像（扩散）模型，根据当前图表和指令提示生成下一个图表图像，以预测股票价格趋势。

Result: 通过实验证明了利用文本到图像生成模型在金融领域（股票价格预测）的潜力。

Conclusion: 该研究强调了文本到图像生成模型在金融领域的应用潜力，并指出了未来研究方向，以克服当前局限并扩展其应用范围。

Abstract: Recent advances in generative models have enabled significant progress in
tasks such as generating and editing images from text, as well as creating
videos from text prompts, and these methods are being applied across various
fields. However, in the financial domain, there may still be a reliance on
time-series data and a continued focus on transformer models, rather than on
diverse applications of generative models. In this paper, we propose a novel
approach that leverages text-to-image model by treating time-series data as a
single image pattern, thereby enabling the prediction of stock price trends.
Unlike prior methods that focus on learning and classifying chart patterns
using architectures such as ResNet or ViT, we experiment with generating the
next chart image from the current chart image and an instruction prompt using
diffusion models. Furthermore, we introduce a simple method for evaluating the
generated chart image against ground truth image. We highlight the potential of
leveraging text-to-image generative models in the financial domain, and our
findings motivate further research to address the current limitations and
expand their applicability.

</details>


### [510] [Explainability-Driven Dimensionality Reduction for Hyperspectral Imaging](https://arxiv.org/abs/2509.02340)
*Salma Haidar,José Oramas*

Main category: cs.AI

TL;DR: This paper proposes using post-hoc explainability methods for hyperspectral band selection to reduce dimensionality while maintaining accuracy. The method quantizes each band's contribution to a classifier's decisions, aggregates these into influence scores, and selects high-influence bands. Experiments show that using as few as 30 selected bands can match or exceed full-spectrum performance with improved efficiency, and the selected bands correspond to physically meaningful regions.


<details>
  <summary>Details</summary>
Motivation: Hyperspectral imaging (HSI) has high dimensionality, causing computational burden and redundancy, making dimensionality reduction necessary while preserving predictive performance.

Method: A model-driven framework for band selection is proposed, using post-hoc explainability methods to quantify each band's contribution to a trained classifier's decisions. Deletion-insertion evaluations are performed to measure confidence changes as bands are removed or reintroduced, and these signals are aggregated into influence scores. High-influence bands are selected to create compact spectral subsets.

Result: Classifiers trained on as few as 30 selected bands match or exceed full-spectrum baselines on the Pavia University and Salinas datasets, while reducing computational requirements. The selected band subsets align with physically meaningful and highly discriminative wavelength regions.

Conclusion: Model-aligned, explanation-guided band selection is a principled approach for effective dimensionality reduction in HSI, leading to compact spectral subsets that maintain accuracy and improve efficiency.

Abstract: Hyperspectral imaging (HSI) provides rich spectral information for precise
material classification and analysis; however, its high dimensionality
introduces a computational burden and redundancy, making dimensionality
reduction essential. We present an exploratory study into the application of
post-hoc explainability methods in a model--driven framework for band
selection, which reduces the spectral dimension while preserving predictive
performance. A trained classifier is probed with explanations to quantify each
band's contribution to its decisions. We then perform deletion--insertion
evaluations, recording confidence changes as ranked bands are removed or
reintroduced, and aggregate these signals into influence scores. Selecting the
highest--influence bands yields compact spectral subsets that maintain accuracy
and improve efficiency. Experiments on two public benchmarks (Pavia University
and Salinas) demonstrate that classifiers trained on as few as 30 selected
bands match or exceed full--spectrum baselines while reducing computational
requirements. The resulting subsets align with physically meaningful, highly
discriminative wavelength regions, indicating that model--aligned,
explanation-guided band selection is a principled route to effective
dimensionality reduction for HSI.

</details>


### [511] [When Agents go Astray: Course-Correcting SWE Agents with PRMs](https://arxiv.org/abs/2509.02360)
*Shubham Gandhi,Jason Tsay,Jatin Ganhotra,Kiran Kate,Yara Rizk*

Main category: cs.AI

TL;DR: LLM代理在软件工程（SWE）任务中存在效率低下问题，如冗余探索、循环和未能终止。本文提出了一种名为SWE-PRM的推理时进程奖励模型（PRM），可在执行期间检测并纠正这些错误。


<details>
  <summary>Details</summary>
Motivation: LLM代理在多步SWE任务中常出现效率低下问题，需要一种在执行期间进行干预以纠正错误的方法。

Method: SWE-PRM是一种推理时进程奖励模型（PRM），利用效率低下分类法来检测和纠正轨迹错误，提供轻量级、可解释的反馈。

Result: 在SWE-bench Verified上，闭源PRM将解决率从40.0%提高到50.6%，尤其在中等和困难任务上增幅最大。分类法指导的PRM优于其他反馈策略，提高了成功率并缩短了轨迹长度，同时增加了可接受的推理成本。

Conclusion: SWE-PRM是一种实用且可扩展的机制，可以提高SWE代理的可靠性和效率。

Abstract: Large Language Model (LLM) agents are increasingly deployed for complex,
multi-step software engineering (SWE) tasks. However, their trajectories often
contain costly inefficiencies, such as redundant exploration, looping, and
failure to terminate once a solution is reached. Prior work has largely treated
these errors in a post-hoc manner, diagnosing failures only after execution. In
this paper, we introduce SWE-PRM, an inference-time Process Reward Model (PRM)
that intervenes during execution to detect and course-correct trajectory-level
errors. Our PRM design leverages a taxonomy of common inefficiencies and
delivers lightweight, interpretable feedback without modifying the underlying
policy. On SWE-bench Verified, closed-source PRMs improve resolution from 40.0%
to 50.6% (+10.6 p.p.), with the largest gains on medium and hard tasks. Among
feedback strategies, taxonomy-guided PRMs outperform unguided or explicit
action-prescriptive variants, increasing success rate while reducing trajectory
length. These benefits come at an acceptable added inference cost of as low as
$0.2, making PRMs a practical and scalable mechanism for improving SWE agents'
reliability and efficiency.

</details>


### [512] [Towards Agents That Know When They Don't Know: Uncertainty as a Control Signal for Structured Reasoning](https://arxiv.org/abs/2509.02401)
*Josefa Lia Stoisser,Marc Boubnovski Martell,Lawrence Phillips,Gianluca Mazzoni,Lea Mørch Harder,Philip Torr,Jesper Ferkinghoff-Borg,Kaspar Martens,Julien Fauqueur*

Main category: cs.AI

TL;DR: LLM代理在处理多表生物医学数据时常产生过于自信的输出，本文提出了一种不确定性感知代理，利用检索和摘要不确定性来提高事实性和校准性，从而改进下游预测任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在结构化生物医学数据环境中日益普及，但它们在处理复杂的多表数据时，常常产生流畅但过于自信的输出。

Method: 本文介绍了一种用于查询条件多表摘要的不确定性感知代理，该代理利用两种互补信号：(i) 检索不确定性——在多次表选择的滚动预测中计算熵；(ii) 摘要不确定性——结合自我一致性和困惑度。摘要不确定性通过组相对策略优化（GRPO）整合到强化学习（RL）中，而检索和摘要不确定性则用于指导推理时过滤和构建更高质量的合成数据集。

Result: 在多组学基准测试中，本文方法提高了事实性和校准性，每份摘要的正确有用声明几乎增加了两倍（内部从3.0增加到8.4；癌症多组学从3.6增加到9.9），并显著改进了下游生存预测（C指数从0.32增加到0.63）。

Conclusion: 不确定性可以作为一种控制信号，使代理能够弃权、传达置信度，并成为处理复杂结构化数据环境的更可靠工具。

Abstract: Large language model (LLM) agents are increasingly deployed in structured
biomedical data environments, yet they often produce fluent but overconfident
outputs when reasoning over complex multi-table data. We introduce an
uncertainty-aware agent for query-conditioned multi-table summarization that
leverages two complementary signals: (i) retrieval uncertainty--entropy over
multiple table-selection rollouts--and (ii) summary uncertainty--combining
self-consistency and perplexity. Summary uncertainty is incorporated into
reinforcement learning (RL) with Group Relative Policy Optimization (GRPO),
while both retrieval and summary uncertainty guide inference-time filtering and
support the construction of higher-quality synthetic datasets.
  On multi-omics benchmarks, our approach improves factuality and calibration,
nearly tripling correct and useful claims per summary (3.0\(\rightarrow\)8.4
internal; 3.6\(\rightarrow\)9.9 cancer multi-omics) and substantially improving
downstream survival prediction (C-index 0.32\(\rightarrow\)0.63). These results
demonstrate that uncertainty can serve as a control signal--enabling agents to
abstain, communicate confidence, and become more reliable tools for complex
structured-data environments.

</details>


### [513] [AppCopilot: Toward General, Accurate, Long-Horizon, and Efficient Mobile Agent](https://arxiv.org/abs/2509.02444)
*Jingru Fan,Yufan Dang,Jingyao Wu,Huatao Li,Runde Yang,Xiyuan Yang,Yuheng Wang,Zhong Zhang,Yaxi Lu,Yankai Lin,Zhiyuan Liu,Dahai Li,Chen Qian*

Main category: cs.AI

TL;DR: AppCopilot是一个通用的端到端移动智能体系统，解决了移动智能体面临的泛化性、准确性、长远能力和效率四大挑战，并在实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和多模态基础模型的发展，移动智能体领域虽然不断涌现新的模型，但在核心挑战的解决上尚未形成统一。本文旨在识别并解决移动智能体要实现实际、可扩展影响所必须克服的四个核心问题：跨任务、跨模态、跨应用和跨设备的泛化性；精确的屏幕交互和点击定位准确性；持续、多步骤任务的长远能力；以及在资源受限设备上的高效运行时性能。

Method: 本文提出了AppCopilot，一个多模态、多智能体、通用的设备端助理，它能够跨应用程序运行，并构成了一个从数据到部署的完整闭环系统。AppCopilot通过一个端到端的自主流水线来实现这一目标，该流水线涵盖了数据收集、训练、部署、高质量和高效推理以及移动应用程序开发。在模型层面，它集成了多模态基础模型，并支持强大的中英双语能力。在推理和控制层面，它结合了思维链推理、分层任务规划与分解以及多智能体协作。在执行层面，它实现了用户个性化和体验适应、语音交互、函数调用、跨应用和跨设备编排以及全面的移动应用支持。系统设计融入了以性能分析为驱动的优化，以实现跨异构硬件的延迟、内存和能耗优化。

Result: AppCopilot在所有四个维度上都取得了显著的改进：更强的泛化能力、更高精度的屏幕操作、更可靠的长远任务完成能力以及更快、更节省资源运行效率。

Conclusion: AppCopilot通过解决泛化性、准确性、长远能力和效率这四大挑战，为实现实用和可扩展的移动智能体提供了有效的解决方案，并在实验中验证了其优越性。

Abstract: With the raid evolution of large language models and multimodal foundation
models, the mobile-agent landscape has proliferated without converging on the
fundamental challenges. This paper identifies four core problems that must be
solved for mobile agents to deliver practical, scalable impact: (1)
generalization across tasks, modalities, apps, and devices; (2) accuracy,
specifically precise on-screen interaction and click targeting; (3)
long-horizon capability for sustained, multi-step goals; and (4) efficiency,
specifically high-performance runtime on resource-constrained devices. We
present AppCopilot, a multimodal, multi-agent, general-purpose on-device
assistant that operates across applications and constitutes a full-stack,
closed-loop system from data to deployment. AppCopilot operationalizes this
position through an end-to-end autonomous pipeline spanning data collection,
training, deployment, high-quality and efficient inference, and mobile
application development. At the model layer, it integrates multimodal
foundation models with robust Chinese-English support. At the reasoning and
control layer, it combines chain-of-thought reasoning, hierarchical task
planning and decomposition, and multi-agent collaboration. At the execution
layer, it enables user personalization and experiential adaptation, voice
interaction, function calling, cross-app and cross-device orchestration, and
comprehensive mobile app support. The system design incorporates
profiling-driven optimization for latency, memory, and energy across
heterogeneous hardware. Empirically, AppCopilot achieves significant
improvements along all four dimensions: stronger generalization,
higher-precision on-screen actions, more reliable long-horizon task completion,
and faster, more resource-efficient runtime.

</details>


### [514] [GridMind: LLMs-Powered Agents for Power System Analysis and Operations](https://arxiv.org/abs/2509.02494)
*Hongwei Jin,Kibaek Kim,Jonghwan Kwon*

Main category: cs.AI

TL;DR: GridMind是一个多智能体AI系统，它将大语言模型（LLMs）与确定性工程求解器相结合，实现电力系统分析的会话式科学计算，解决了工作流集成、知识可及性、上下文保持和专家决策支持增强等问题。实验表明，该系统在所有测试的语言模型上都能提供正确的解决方案，并且较小的LLMs可以以较低的计算延迟实现相当的分析精度。


<details>
  <summary>Details</summary>
Motivation: 传统电力系统分析工作流的复杂性对现代电网的高效决策构成了重大障碍。

Method: GridMind系统采用多智能体AI架构，整合了大语言模型（LLMs）和确定性工程求解器，通过自然语言接口协调交流最优潮流（AC Optimal Power Flow）和N-1故障分析（N-1 contingency analysis），同时通过函数调用保持数值精度。

Result: 实验在IEEE测试案例上评估了GridMind的性能，结果显示所提出的智能体框架在所有测试的语言模型上持续提供正确的解决方案，并且较小的LLMs在保持相当的分析精度的同时，降低了计算延迟。

Conclusion: 智能体AI是科学计算的一个可行范例，对话式接口可以提高可访问性，同时保持对关键工程应用至关重要的数值严谨性。

Abstract: The complexity of traditional power system analysis workflows presents
significant barriers to efficient decision-making in modern electric grids.
This paper presents GridMind, a multi-agent AI system that integrates Large
Language Models (LLMs) with deterministic engineering solvers to enable
conversational scientific computing for power system analysis. The system
employs specialized agents coordinating AC Optimal Power Flow and N-1
contingency analysis through natural language interfaces while maintaining
numerical precision via function calls. GridMind addresses workflow
integration, knowledge accessibility, context preservation, and expert
decision-support augmentation. Experimental evaluation on IEEE test cases
demonstrates that the proposed agentic framework consistently delivers correct
solutions across all tested language models, with smaller LLMs achieving
comparable analytical accuracy with reduced computational latency. This work
establishes agentic AI as a viable paradigm for scientific computing,
demonstrating how conversational interfaces can enhance accessibility while
preserving numerical rigor essential for critical engineering applications.

</details>


### [515] [UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2509.02544)
*Haoming Wang,Haoyang Zou,Huatong Song,Jiazhan Feng,Junjie Fang,Junting Lu,Longxiang Liu,Qinyu Luo,Shihao Liang,Shijue Huang,Wanjun Zhong,Yining Ye,Yujia Qin,Yuwen Xiong,Yuxin Song,Zhiyong Wu,Bo Li,Chen Dun,Chong Liu,Fuxing Leng,Hanbin Wang,Hao Yu,Haobin Chen,Hongyi Guo,Jing Su,Jingjia Huang,Kai Shen,Kaiyu Shi,Lin Yan,Peiyao Zhao,Pengfei Liu,Qinghao Ye,Renjie Zheng,Wayne Xin Zhao,Wen Heng,Wenhao Huang,Wenqian Wang,Xiaobo Qin,Yi Lin,Youbin Wu,Zehui Chen,Zihao Wang,Baoquan Zhong,Xinchun Zhang,Xujing Li,Yuanfan Li,Zhongkai Zhao,Chengquan Jiang,Faming Wu,Haotian Zhou,Jinlin Pang,Li Han,Qianli Ma,Siyao Liu,Songhua Cai,Wenqi Fu,Xin Liu,Zhi Zhang,Bo Zhou,Guoliang Li,Jiajun Shi,Jiale Yang,Jie Tang,Li Li,Taoran Lu,Woyu Lin,Xiaokang Tong,Xinyao Li,Yichi Zhang,Yu Miao,Zhengxuan Jiang,Zili Li,Ziyuan Zhao,Chenxin Li,Dehua Ma,Feng Lin,Ge Zhang,Haihua Yang,Hangyu Guo,Hongda Zhu,Jiaheng Liu,Junda Du,Kai Cai,Kuanye Li,Lichen Yuan,Meilan Han,Minchao Wang,Shuyue Guo,Tianhao Cheng,Xiaobo Ma,Xiaojun Xiao,Xiaolong Huang,Xinjie Chen,Yidi Du,Yilin Chen,Yiwen Wang,Zhaojian Li,Zhenzhu Yang,Zhiyuan Zeng,Chaolin Jin,Chen Li,Hao Chen,Haoli Chen,Jian Chen,Qinghao Zhao,Guang Shi*

Main category: cs.AI

TL;DR: UI-TARS-2是一个先进的GUI代理模型，通过改进数据扩展性、多轮强化学习、混合GUI环境和统一沙盒平台，在GUI和游戏基准测试中取得了显著进展，并展现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前GUI代理模型在数据扩展性、多轮强化学习、仅限GUI操作的局限性以及环境稳定性方面的挑战。

Method: 提出UI-TARS-2，一个以GUI为中心的代理模型，采用系统性训练方法：数据飞轮、稳定的多轮强化学习框架、集成文件系统和终端的混合GUI环境以及用于大规模推出的统一沙盒平台。

Result: UI-TARS-2在GUI基准测试（Online-Mind2Web, OSWorld, WindowsAgentArena, AndroidWorld）上取得了优于先前版本和基线模型（如Claude和OpenAI代理）的性能。在游戏环境中，其平均归一化得分达到人类水平的约60%，并在LMGame-Bench上与前沿模型（如OpenAI o3）竞争。模型还能泛化到长时信息查找任务和软件工程基准。

Conclusion: UI-TARS-2在推进GUI代理领域方面具有巨大潜力，并对真实交互场景展现出强大的泛化能力，其训练动态分析也为实现大规模代理强化学习的稳定性和效率提供了见解。

Abstract: The development of autonomous agents for graphical user interfaces (GUIs)
presents major challenges in artificial intelligence. While recent advances in
native agent models have shown promise by unifying perception, reasoning,
action, and memory through end-to-end learning, open problems remain in data
scalability, multi-turn reinforcement learning (RL), the limitations of
GUI-only operation, and environment stability. In this technical report, we
present UI-TARS-2, a native GUI-centered agent model that addresses these
challenges through a systematic training methodology: a data flywheel for
scalable data generation, a stabilized multi-turn RL framework, a hybrid GUI
environment that integrates file systems and terminals, and a unified sandbox
platform for large-scale rollouts. Empirical evaluation demonstrates that
UI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.
On GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on
WindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines
such as Claude and OpenAI agents. In game environments, it attains a mean
normalized score of 59.8 across a 15-game suite-roughly 60% of human-level
performance-and remains competitive with frontier proprietary models (e.g.,
OpenAI o3) on LMGame-Bench. Additionally, the model can generalize to
long-horizon information-seeking tasks and software engineering benchmarks,
highlighting its robustness across diverse agent tasks. Detailed analyses of
training dynamics further provide insights into achieving stability and
efficiency in large-scale agent RL. These results underscore UI-TARS-2's
potential to advance the state of GUI agents and exhibit strong generalization
to real-world interactive scenarios.

</details>


### [516] [The Landscape of Agentic Reinforcement Learning for LLMs: A Survey](https://arxiv.org/abs/2509.02547)
*Guibin Zhang,Hejia Geng,Xiaohang Yu,Zhenfei Yin,Zaibin Zhang,Zelin Tan,Heng Zhou,Zhongzhi Li,Xiangyuan Xue,Yijiang Li,Yifan Zhou,Yang Chen,Chen Zhang,Yutao Fan,Zihu Wang,Songtao Huang,Yue Liao,Hongru Wang,Mengyue Yang,Heng Ji,Michael Littman,Jun Wang,Shuicheng Yan,Philip Torr,Lei Bai*

Main category: cs.AI

TL;DR: Agentic RL uses RL to turn LLMs into autonomous agents that can plan, use tools, reason, and improve, moving beyond simple sequence generation. This survey categorizes agentic capabilities and applications, providing a compendium of resources to advance research in scalable AI agents.


<details>
  <summary>Details</summary>
Motivation: To formalize the conceptual shift from conventional reinforcement learning applied to large language models (LLM RL) to agentic reinforcement learning (Agentic RL), contrasting their respective frameworks and organizing the rapidly evolving field.

Method: Formalized the conceptual shift by contrasting single-step MDPs (LLM-RL) with temporally extended POMDPs (Agentic RL). Proposed a twofold taxonomy based on core agentic capabilities (planning, tool use, memory, reasoning, self-improvement, perception) and applications. Consolidated open-source environments, benchmarks, and frameworks into a compendium.

Result: Synthesized over 500 recent works to chart the field, highlighting opportunities and challenges for developing scalable, general-purpose AI agents.

Conclusion: Reinforcement learning is crucial for transforming static heuristic modules into adaptive, robust agentic behavior, paving the way for autonomous AI agents.

Abstract: The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm
shift from conventional reinforcement learning applied to large language models
(LLM RL), reframing LLMs from passive sequence generators into autonomous,
decision-making agents embedded in complex, dynamic worlds. This survey
formalizes this conceptual shift by contrasting the degenerate single-step
Markov Decision Processes (MDPs) of LLM-RL with the temporally extended,
partially observable Markov decision processes (POMDPs) that define Agentic RL.
Building on this foundation, we propose a comprehensive twofold taxonomy: one
organized around core agentic capabilities, including planning, tool use,
memory, reasoning, self-improvement, and perception, and the other around their
applications across diverse task domains. Central to our thesis is that
reinforcement learning serves as the critical mechanism for transforming these
capabilities from static, heuristic modules into adaptive, robust agentic
behavior. To support and accelerate future research, we consolidate the
landscape of open-source environments, benchmarks, and frameworks into a
practical compendium. By synthesizing over five hundred recent works, this
survey charts the contours of this rapidly evolving field and highlights the
opportunities and challenges that will shape the development of scalable,
general-purpose AI agents.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [517] [Probing the Nanoscale Excitonic Landscape and Quantum Confinement of Excitons in Gated Monolayer Semiconductors](https://arxiv.org/abs/2509.00453)
*Yueh-Chun Wu,Bogdan Dryzhakov,Huan Zhao,Ivan Vlassiouk,Kyle Kelley,Takashi Taniguchi,Kenji Watanabe,Jun Yan,Benjamin Lawrie*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用阴极发光光谱和静电门控技术，在单层WS2中发现了由栅极和非栅极区域之间产生的同质结，以及由电子束和栅极场相互作用驱动的非传统掺杂机制引起的激子限制通道。


<details>
  <summary>Details</summary>
Motivation: 在量子光子学和光电子学中，在纳米尺度上工程化和探测激子性质是一个核心挑战，而二维半导体的纳米级异质性限制了二维量子光子器件架构的可扩展性。

Method: 利用聚焦电子束的高空间分辨率，通过阴极发光光谱探测单层WS2在静电门控下的激子环境。

Result: 发现了由栅极和非栅极区域之间产生的同质结，以及由电子束和栅极场相互作用驱动的非传统掺杂机制引起的激子限制通道。

Conclusion: 该研究为理解单层半导体在电子束激发和静电门控联合影响下的光电行为提供了新见解，并为在纳米尺度上操纵激子以及控制二维材料中的量子限制激子传输提供了途径。

Abstract: Engineering and probing excitonic properties at the nanoscale remains a
central challenge in quantum photonics and optoelectronics. While exciton
confinement via electrical control and strain engineering has been demonstrated
in 2D semiconductors, substantial nanoscale heterogeneity limits the
scalability of 2D quantum photonic device architectures. In this work, we use
cathodoluminescence spectroscopy to probe the excitonic landscape of monolayer
$WS_2$ under electrostatic gating. Exploiting the high spatial resolution of
the converged electron beam, we resolve a homojunction arising between gated
and ungated regions. Moreover, we reveal an exciton confinement channel arising
from an unconventional doping mechanism driven by the interplay between the
electron beam and the applied gate fields. These findings offer new insights
into the optoelectronic behavior of monolayer semiconductors under the combined
influence of electron-beam excitation and electrostatic gating. Our approach
provides a pathway for exciton manipulation at the nanoscale and opens
opportunities for controlling quantum-confined exciton transport in
two-dimensional materials.

</details>


### [518] [Shot noise as a probe for Andreev reflection in graphene-based heterojunctions](https://arxiv.org/abs/2509.00486)
*Shahrukh Salim,Poornima Shakya*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用量子やショットノイズ来区分石墨烯-超导体结中的安德烈夫反射类型（镜像和非镜像），并将其扩展到多接口配置。


<details>
  <summary>Details</summary>
Motivation: 为了区分石墨烯-超导体结中的镜像和非镜像安德烈夫反射过程，并理解多接口配置对传输谱和噪声分布的影响。

Method: 使用 Bogoliubov-de Gennes 形式主义和全波函数匹配来获得精确的反射振幅，并分析 Fano 因子和传输谱以研究やショットノイズ。

Result: 量子やショットノイズ可以区分镜像和非镜像安德烈夫反射。镜像反射会抑制やショットノイズ，而非镜像反射会增强やショットノイズ。在多接口配置中，传输谱和や ショットノイズ会被修改。

Conclusion: や ショットノイズ光谱法是一种有效且可行的实验工具，用于区分石墨烯基量子器件中的安德烈夫反射类型，并提供超越传统电导测量的互补见解。

Abstract: Shot noise emerges due to the discrete nature of charge transport and
provides direct access to the underlying microscopic transport mechanisms
governing current flow in mesoscopic conductors. In this work, we demonstrate
that quantum shot noise offers a direct and robust fingerprint of Andreev
reflection, distinguishing between retro and specular processes in
graphene-superconductor, graphene-superconductor-graphene, and
superconductor-graphene-superconductor junctions. At the
graphene-superconductor interface, exact reflection amplitudes obtained from
full wavefunction matching within the Bogoliubov-de Gennes formalism capture
retro and specular regimes. The associated Fano factor exhibits distinct
Fermi-level-dependent signatures, with retro Andreev reflection suppressing and
specular Andreev reflection enhancing the shot noise. Extensions to
graphene-superconductor-graphene and superconductor-graphene-superconductor
configurations reveal how the transmission spectrum and, consequently, the
noise profile are modified in the presence of multiple interfaces, coherent
quasiparticle interference, and superconducting phase variations. Our findings
establish shot noise spectroscopy as a potent and experimentally viable probe
for differentiating Andreev reflection types in graphene-based quantum devices,
providing complementary insights beyond conventional conductance measurements.

</details>


### [519] [Real-space observation of the low-temperature Skyrmion lattice in Cu2OSeO3(100) single crystal](https://arxiv.org/abs/2509.00517)
*Gerald Malsch,Peter Milde,Dmytro Ivaneiko,Andreas Bauer,Christian Pfleiderer,H. Berger,Lukas M. Eng*

Main category: cond-mat.mes-hall

TL;DR: Cu2OSeO3是一种斯格明子主体材料，在其(100)单晶中发现了两种不同的热力学稳定的斯格明子相。通过磁力显微镜成像，在10K的温度下，通过调谐外部磁场，观察到了螺旋、圆锥、倾斜圆锥和斯格明子晶格畴的形成。


<details>
  <summary>Details</summary>
Motivation: 在Cu2OSeO3(100)单晶中，利用磁力显微镜成像技术，在10K温度下，通过调谐外部磁场，研究低温柔磁相的形成，包括螺旋、圆锥、倾斜圆锥和斯格明子晶格畴。

Method: 在10K温度下，利用磁力显微镜对Cu2OSeO3(100)单晶进行成像，并通过调谐外部磁场来观察不同磁相的形成。

Result: 在10K温度下，通过调谐外部磁场，观察到了Cu2OSeO3(100)单晶中螺旋、圆锥、倾斜圆锥和斯格明子晶格畴的形成。

Conclusion: Cu2OSeO3是一种斯格明子主体材料，在其(100)单晶中发现了两种不同的热力学稳定的斯格明子相。通过磁力显微镜成像，在10K的温度下，通过调谐外部磁场，观察到了螺旋、圆锥、倾斜圆锥和斯格明子晶格畴的形成。

Abstract: Cu2OSeO3 is a skyrmion host material in which two distinct thermodynamically
stable skyrmion phases were identified. We report magnetic force microscopy
imaging of the low-temperature magnetic phases in bulk Cu2OSeO3(100) single
crystal. Tuning the external magnetic field over the various phase transition
at a temperature of 10 K, we observe the formation of helical, conical, tilted
conical and skyrmion lattice domains in real space.

</details>


### [520] [Embodying computation in nonlinear perturbative metamaterials](https://arxiv.org/abs/2509.01625)
*Sima Zahedi Fard,Paolo Tiso,Parisa Omidvar,Marc Serra-Garcia*

Main category: cond-mat.mes-hall

TL;DR: This paper presents a new method for designing metamaterials capable of performing advanced computations by mapping nonlinearity from discrete models to physical geometries using a nonlinear coordinate transformation. This approach enables the creation of information-processing metamaterials for various computational tasks, demonstrated through examples like a coherent Ising machine, a mechanical racetrack memory, and a speech classification metamaterial.


<details>
  <summary>Details</summary>
Motivation: The challenge of designing metamaterials for advanced computations, specifically the need to map nonlinearity from discrete models to physical geometries.

Method: Formulating the mapping through a nonlinear coordinate transformation that connects tight-binding degrees of freedom to metamaterial excitations in the nonlinear regime.

Result: Successful design of information-processing metamaterials for various computations, including a coherent Ising machine, a mechanical racetrack memory, and a speech classification metamaterial.

Conclusion: The developed nonlinear coordinate transformation allows for the design of information-processing metamaterials across a broad range of computations expressible as tight-binding models.

Abstract: Designing metamaterials that carry out advanced computations poses a
significant challenge. A powerful design strategy splits the problem into two
steps: First, encoding the desired functionality in a discrete or tight-binding
model, and second, identifying a metamaterial geometry that conforms to the
model. Applying this approach to information-processing tasks requires
accurately mapping nonlinearity -- an essential element for computation -- from
discrete models to geometries. Here we formulate this mapping through a
nonlinear coordinate transformation that accurately connects tight-binding
degrees of freedom to metamaterial excitations in the nonlinear regime. This
transformation allows us to design information-processing metamaterials across
the broad range of computations that can be expressed as tight-binding models,
a capability we showcase with three examples based on three different computing
paradigms: a coherent Ising machine that approximates combinatorial
optimization problems through energy minimization, a mechanical racetrack
memory exemplifying in-memory computing, and a speech classification
metamaterial based on analog neuromorphic computing.

</details>


### [521] [Sub-GHz Breathing Dynamics of Magnetic Hopfions](https://arxiv.org/abs/2509.00580)
*Felipe Tejo,Rubén M. Otxoa*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了磁性霍普夫子的动力学模式，特别是其基本呼吸模式。通过微磁模拟和解析建模，我们发现呼吸模式是霍普夫子核心直径和壳层宽度的协同振荡，同时保持了拓扑荷。我们提出了一个解析畴壁相互作用模型，可以解释壳层厚度的弱场依赖性，并推导出恢复刚度的闭合形式表达式。基于此曲率和集体坐标惯性，我们得出了与微磁谱高度一致的呼吸频率估算值。


<details>
  <summary>Details</summary>
Motivation: 霍普夫子的静态稳定性已在实验中得到证实，但其动力学模式仍未得到充分探索。理解其动力学行为对于其在自旋电子器件中的应用至关重要。

Method: 结合微磁模拟和解析建模，对霍普夫子的基本呼吸模式进行了表征。

Result: 呼吸模式对应于霍普夫子核心直径和壳层宽度的协同振荡，同时保持了拓扑荷。分析模型成功解释了壳层厚度的弱场依赖性，并导出了恢复刚度的闭合形式表达式。基于此，推导出的呼吸频率估算值与微磁谱高度一致。

Conclusion: 本文提出的分析框架能够从材料常数出发定量捕捉霍普夫子的动力学行为，为通过铁磁共振或布里渊散射进行实验检测提供了直接途径，并为可重构自旋电子器件中的频率编码控制奠定了基础。

Abstract: Magnetic hopfions are three-dimensional topological solitons whose static
stability has recently been confirmed in experiments, yet their dynamical modes
remain largely unexplored. Here we combine micromagnetic simulations and
analytical modelling to characterise the fundamental breathing excitation of
hopfions. We show that the breathing mode corresponds to a coherent oscillation
of both the hopfion core diameter and the shell width, while preserving the
topological charge. An analytical domain-wall interaction model explains the
weak field dependence of the shell thickness and yields a closed-form
expression for the restoring stiffness. From this curvature and the
collective-coordinate inertia, we derive an estimated breathing frequency in
excellent agreement with micromagnetic spectra. The ability to capture the
hopfion dynamics quantitatively from material constants highlights a direct
route to experimental detection by ferromagnetic resonance or Brillouin light
scattering, and establishes a framework for frequency-encoded control in
reconfigurable spintronic devices.

</details>


### [522] [Racetrack computing with a topological boundary ratchet](https://arxiv.org/abs/2509.01706)
*Parisa Omidvar,Markus Bestler,Sima Zahedi Fard,Oded Zilberberg,Marc Serra-Garcia*

Main category: cond-mat.mes-hall

TL;DR: 在弹性超材料中，通过拓扑边界 the ratchet 实现了数字信息的定向传输。


<details>
  <summary>Details</summary>
Motivation: 磁性记忆设备利用多稳态序参量编码非易失性信息，但信息移动的稳定性与信息处理和读出的需求相冲突。本研究旨在寻找一种在稳定系统中移动信息载体域的方法。

Method: 本研究在弹性超材料中实验实现了一种拓扑边界 the ratchet，其中数字信息被编码在屈曲域中，并通过循环加载以量化的方式进行传输。

Result: 研究人员成功地控制了信息传播的方向，并通过数值模拟研究了屈曲域墙逻辑电路。

Conclusion: 这种基于屈曲的域墙运动机制，由于其潜在的紧束缚结构和低阶非线性，为在中性系统中实现磁性质粒存储器提供了一种通用的途径。

Abstract: Multistable order parameters provide a natural means of encoding non-volatile
information in spatial domains, a concept that forms the foundation of magnetic
memory devices. However, this stability inherently conflicts with the need to
move information around the device for processing and readout. While in
magnetic systems, domains can be transported using currents or external fields,
mechanisms to robustly shuttle information-bearing domains across neutral
systems are scarce. Here, we experimentally realize a topological boundary
ratchet in an elastic metamaterial, where digital information is encoded in
buckling domains and transported in a quantized manner via cyclic loading. The
transport is topological in origin: neighboring domains act as different
topological pumps for their Bogoliubov excitations, so their interface hosts
topological boundary modes. Cyclic loading renders these modes unstable through
inter-domain pressure, which in turn drives the motion of the domain wall. We
demonstrate that the direction of information propagation can be controlled
through adjustable mechanical constraints on the buckling beams, and
numerically investigate buckling-based domain-wall logic circuits in an elastic
metamaterial network. The underlying tight-binding structure with low-order
nonlinearities makes this approach a general pathway toward racetrack memories
in neutral systems.

</details>


### [523] [Topology of Fermi seas and geometry of their boundaries for free particles in one and two-dimensional lattices](https://arxiv.org/abs/2509.00590)
*Guillermo R. Zemba*

Main category: cond-mat.mes-hall

TL;DR: 该研究根据其拓扑性质对具有晶格对称性的几何背景上无自旋费米子的自由气体进行了分类。


<details>
  <summary>Details</summary>
Motivation: 研究旨在根据拓扑性质对具有晶格对称性的几何背景上无自旋费米子的自由气体进行分类。

Method: 通过考虑具有晶格对称性的几何背景上无自旋费米子的平坦orbifolds $R^{d}/	ilde{1}$，其中$	ilde{1}$是d维动量空间中的晶格对称群。

Result: 在d=1时，存在2个拓扑类：圆周（绝缘体）和区间（导体）。在d=2时，拓扑类扩展到17个，包括具有圆盘拓扑的导体（8个）和具有2-球面拓扑的绝缘体（4个），以及其他各种绝缘体和导体的情形。

Conclusion: 这种分类具有拓扑性质，预计对小的微扰相互作用具有鲁棒性。

Abstract: Free gases of spinless fermions moving on a geometric background with lattice
symmetries are considered. Their Fermi seas and corresponding boundaries may be
classified according to their topological properties at zero temperature. This
is accomplished by considering the flat orbifolds $R^{d}/\Gamma$, with $\Gamma$
being the crystallographic group of symmetry in $d$-dimensional momentum space.
For $d=1$, there are 2 topological classes: a circumference, corresponding to
an insulator and an interval, identified as a conductor. For $d=2$, the number
of topological classes extends to 17: there are 8 with the topology of a disk
identified as conductors and 4 corresponding to a 2-sphere matching insulators,
both sets eventually including finite numbers of conical singularities and
reflection corners at the boundaries. The rest of the listing includes single
cases corresponding to insulators (2-torus, real projective plane, Klein
bottle) and conductors (annulus, M\"obius strip). Physical interpretations of
the singularities are provided, as well as examples that fit within this
listing. Given the topological nature of this classification, its results are
expected to be robust against small perturbative interactions.

</details>


### [524] [Observation of moiré trapped biexciton through sub-diffraction-limit probing using hetero-bilayer on nanopillar](https://arxiv.org/abs/2509.00879)
*Mayank Chhaperwal,Suman Chatterjee,Suchithra Puliyassery,Jyothsna Konkada Manattayil,Rabindra Biswas,Patrick Hays,Seth Ariel Tongay,Varun Raghunathan,Kausik Majumdar*

Main category: cond-mat.mes-hall

TL;DR: 两层二硫化钨/二硒化钨异质双层中的层间激子相互作用在不同长度尺度下会从排斥变为吸引，这由直接相互作用和交换相互作用的竞争引起。


<details>
  <summary>Details</summary>
Motivation: 研究纳米尺度下粒子相互作用调控的可能性，特别是利用莫尔超晶格中的层间激子。

Method: 通过实验观察莫尔激子和莫尔囚禁的二激子，并分析了它们的光谱特征和功率定律。

Result: 发现层间激子间的库仑力在从层间莫尔口袋到层内莫尔口袋的长度尺度减小时，从排斥转变为吸引，这导致了异常的超线性功率定律和二激子的稳定。

Conclusion: 层间激子相互作用的性质可以通过改变长度尺度来调控，这为探索莫尔超晶格中的相互作用物理提供了新的平台。

Abstract: The ability to tune the degree of interaction among particles at the
nanoscale is highly intriguing. The spectroscopic signature of such interaction
is often subtle and requires special probes to observe. To this end,
inter-layer excitons trapped in the periodic potential wells of a moir\'e
superlattice offer rich interaction physics, specifically due to the presence
of both attractive and repulsive components in the interaction. Here we show
that the Coulomb force between two inter-layer excitons switches from repulsive
to attractive when the length scale reduces from inter-moir\'e-pocket to
intra-moir\'e-pocket in a WS$_2$/WSe$_2$ hetero-bilayer - thanks to the complex
competition between direct and exchange interaction. The finding is a departure
from the usual notion of repelling inter-layer excitons due to layer
polarization. This manifests as the simultaneous observation of an anomalous
superlinear power-law of moir\'e exciton and a stabilization of moir\'e trapped
biexciton. The experimental observation is facilitated by placing the
hetero-bilayer on a polymer-nanopillar/gold-film stack which significantly
reduces the inhomogeneous spectral broadening by selectively probing a smaller
ensemble of moir\'e pockets compared with a flat sample. This creates an
interesting platform to explore interaction among moir\'e trapped excitons and
higher order quasiparticles.

</details>


### [525] [Topological switching in bilayer magnons via electrical control](https://arxiv.org/abs/2509.00815)
*Xueqing Wan,Quanchao Du,Jinlian Lu,Zhenlong Zhang,Jinyang Ni,Lei Zhang,Zhijun Jiang,Laurent Bellaiche*

Main category: cond-mat.mes-hall

TL;DR: 该研究提出了一种在双层铁磁绝缘体中通过外加垂直电场调控拓扑磁子的新策略。


<details>
  <summary>Details</summary>
Motivation: 磁子因其无损耗的信息处理潜力而备受关注，但其电控和非易失性控制面临挑战。

Method: 通过施加垂直电场，利用自旋-层耦合在双层铁磁绝缘体中产生层间势能不平衡，进而调制层间海森堡交换相互作用，以调控磁子的能带拓扑和非互易动力学。

Result: 成功实现了拓扑磁子的电场调控，并揭示了该机制与外磁场的强耦合效应，为电磁耦合研究提供了新视角。

Conclusion: 该研究为利用电场精确控制拓扑磁子及其输运行为提供了普适性方法，并开辟了电磁耦合在电中性准粒子领域的新应用前景。

Abstract: Topological magnons, quantized spin waves featuring nontrivial boundary
modes, present a promising route toward lossless information processing.
Realizing practical devices typically requires magnons excited in a controlled
manner to enable precise manipulation of their topological phases and transport
behaviors. However, their inherent charge neutrality and a high frequency
nature pose a significant challenge for nonvolatile control, especially via
electric means. Herein, we propose a general strategy for electrical control of
topological magnons in bilayer ferromagnetic insulators. With strong spin-layer
coupling, an applied vertical electric field induces an interlayer potential
imbalance that modifies intralayer Heisenberg exchanges between adjacent
layers. This electric-field-driven modulation competes with the bilayer's
intrinsic Dzyaloshinskii-Moriya interaction, enabling the accurate tuning of
the band topology and nonreciprocal dynamics of magnons. More importantly, such
an electric control mechanism exhibits strong coupling with external magnetic
fields, unveiling new perspectives on magnetoelectric coupling in
charge-neutral quasiparticles

</details>


### [526] [Transitioning from Silicon to Carbon Nanotube based transistors](https://arxiv.org/abs/2509.00947)
*Suhas Bharadwaj,Reuben Thomas Thovelil,Rohith Chembattammal,Sradha Mishra,Sunit Sahoo,Himnish Dave,Karthik S.,Kabir Jaisinghani*

Main category: cond-mat.mes-hall

TL;DR: 碳纳米管（CNTs）因其高导电性、优异的机械强度和导热性而成为硅基晶体管的替代选择，但其纯度和手性控制的挑战引发了对大规模生产可行性的质疑。本文旨在提供一个全面的指南，以实现碳纳米管晶体管的大规模生产和快速集成到半导体市场。


<details>
  <summary>Details</summary>
Motivation: 碳纳米管（CNTs）在寻找硅基晶体管替代品方面具有吸引力，但大规模生产面临纯度和手性控制的挑战。

Method: 本文探讨了规模化挑战，并提出液相和气相氧化法、微波加热、催化剂工程、化学气相沉积、光刻、丝网印刷和堆叠工程等方法来解决金属杂质和控制碳纳米管的手性，以促进碳纳米管晶体管的大规模生产。此外，还研究了激光烧蚀和电弧放电等合成方法，以及退火和钾掺杂等集成技术。

Result: 通过上述方法，解决了碳纳米管的纯度和手性控制问题，并提出了大规模生产和集成碳纳米管晶体管的技术。

Conclusion: 本文为碳纳米管晶体管的大规模生产和快速集成到半导体市场提供了全面的指导，克服了现有挑战。

Abstract: Carbon Nanotubes have shown to be an attractive option in the race to find a
replacement to silicon-based transistors, due to its high electrical
conductivity, extraordinary mechanical strength, and thermal conductivity.
However, challenges with regards to controlling the purity and chirality of
CNTs have raised doubts if the mass production of these transistors are even
viable. This paper explores the challenges of scalability and proposes methods
such as Liquid and Gas phase oxidative methods and microwave heating to tackle
the problem of metal impurities found within CNTs and the methods of Catalyst
Engineering and Chemical Vapor Deposition to control the chirality of CNTs. It
also suggests techniques such as Lithography, Screen Printing and Stack
Engineering to facilitate the large-scale production of CNT transistors. This
paper also attempts to explore the methods of Laser Ablation and Arc Discharge
that allows for the synthesis of CNTs of pure quality and high yield further
facilitating the rise of mass production of CNT transistors. The feasibility
and challenges relating to the integration of CNT transistors with already
pre-existing circuitry was also investigated and the methods of annealing and
potassium doping were studied and analyzed. The main aim of this paper is
providing a comprehensive guide to allow for the mass production and rapid
integration of CNT transistors into the semi-conductor market.

</details>


### [527] [Dissipation in passive non-reciprocal microwave devices](https://arxiv.org/abs/2509.00874)
*Stefano Bosco*

Main category: cond-mat.mes-hall

TL;DR: 实现非互易器件的被动非互易微波器件的一种方法是通过外部电极和表现出非互易电导的材料之间的电容耦合。本工作提出了一种分析框架，该框架在考虑材料的完整交流动力学的情况下，能够捕获耗散存在下此类器件的响应。我们的结果产生了一个有效的电路模型，即使在耗散水平较低的情况下，也能在实验相关的区域准确地描述器件的响应。此外，我们的分析揭示了源于材料固有交流响应的逆传播特征，这些特征可能被用来动态切换器件的非互易性，为可调谐非互易微波技术开辟了道路。


<details>
  <summary>Details</summary>
Motivation: 非互易器件在经典和量子电子学中都起着关键作用。

Method: 开发了一个分析框架，该框架在考虑材料的完整交流动力学的情况下，能够捕获耗散存在下此类器件的响应。

Result: 得到一个有效的电路模型，即使在耗散水平较低的情况下，也能在实验相关的区域准确地描述器件的响应。

Conclusion: 分析揭示了源于材料固有交流响应的逆传播特征，这些特征可能被用来动态切换器件的非互易性，为可调谐非互易微波技术开辟了道路。

Abstract: Non-reciprocal devices are key components in both classical and quantum
electronics. One approach to realizing passive non-reciprocal microwave devices
is through capacitive coupling between external electrodes and materials
exhibiting non-reciprocal conductance. In this work, we develop an analytic
framework that captures the response of such devices in the presence of
dissipation while accounting for the full AC dynamics of the material. Our
results yield an effective circuit model that accurately describes the device
response in experimentally relevant regimes even at small dissipation levels.
Furthermore, our analysis reveals counterpropagating features arising from the
intrinsic AC response of the material that could be exploited to dynamically
switch the non-reciprocity of the device, opening pathways for tunable
non-reciprocal microwave technologies.

</details>


### [528] [Calculations of current in the cotunneling regime using Lindblad equations](https://arxiv.org/abs/2509.01003)
*Kian Maleki,Michael E. Flatté*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用Lindblad形式主义和马尔可夫近似来计算穿过零维状态的隧穿势垒的电流，并研究了库仑阻塞、自旋极化导和磁场的影响。


<details>
  <summary>Details</summary>
Motivation: 研究在库仑阻塞区域、自旋极化导和弱磁场下，穿过隧穿势垒的零维状态的共隧穿电流。

Method: 使用Lindblad形式主义和马尔可夫近似计算电流。

Result: 计算了磁场和导自旋极化对自旋阻塞、退相干和子系统自旋寿命的依赖关系。

Conclusion: 该研究为理解和预测在特定条件下（库仑阻塞、自旋极化导、弱磁场）的量子传输提供了理论框架。

Abstract: Transport through zero-dimensional states in a tunneling barrier can occur
via co-tunneling, wherein a carrier occupying a state outside the range of
energies between the chemical potentials of the two leads hops to a lead, and
within the brief time permitted by the energy-time uncertainty relationship the
occupancy is replenished from the other lead. Here, we calculate the current in
such junctions using a Lindblad formalism within the Markovian approximation.
We consider transport in the Coulomb blockade regime with spin-polarized leads
and a magnetic field smaller than the coercive field of either lead.
Dependences on magnetic field and lead spin polarization of the spin blockade,
decoherence, and spin lifetime of the subsystems of this model are calculated.

</details>


### [529] [Topological characterization of phase transitions and critical edge states in one-dimensional non-Hermitian systems with sublattice symmetry](https://arxiv.org/abs/2509.01174)
*Longwen Zhou,Rujia Jing,Shenlin Wu*

Main category: cond-mat.mes-hall

TL;DR: 该论文揭示并表征了非厄米系统中的拓扑临界点和临界边缘态，通过应用柯西参数定理得到一对陈数，完整描述了一维双带非厄米系统中的能隙和无能隙拓扑相。


<details>
  <summary>Details</summary>
Motivation: 拓扑相变点出现的临界边缘态标志着存在非平凡的拓扑临界点，这些临界点的描述超出了能隙拓扑物质的范围。本研究旨在揭示和表征非厄米系统中的拓扑临界点和临界边缘态。

Method: 应用柯西参数定理到非厄米哈密顿量的两个特征函数，得到一对陈数，用于描述一维双带非厄米子系统中的能隙和无能隙拓扑相。

Result: 在非厄米Su-Schrieffer-Heeger链的广泛类别中，展示了该理论在表征无能隙对称保护拓扑相、拓扑上不同的临界点、非厄米相边界的相变及其相关的拓扑边缘模式方面的适用性。

Conclusion: 研究结果将拓扑上非平凡的临界点和临界边缘态的概念推广到非厄米系统，并为分析开放系统中的拓扑相变和体边对应关系提供了新的见解。

Abstract: Critical edge states appear at the bulk gap closing points of topological
transitions. Their emergence signify the existence of topologically nontrivial
critical points, whose descriptions fall outside the scope of gapped
topological matter. In this work, we reveal and characterize topological
critical points and critical edge states in non-Hermitian systems. By applying
the Cauchy's argument principle to two characteristic functions of a
non-Hermitian Hamiltonian, we obtain a pair of winding numbers, whose
combination yields a complete description of gapped and gapless topological
phases in one-dimensional, two-band non-Hermitian systems with sublattice
symmetry. Focusing on a broad class of non-Hermitian Su-Schrieffer-Heeger
chains, we demonstrate the applicability of our theory for characterizing
gapless symmetry-protected topological phases, topologically distinct critical
points, phase transitions along non-Hermitian phase boundaries and their
associated topological edge modes. Our findings not only generalize the
concepts of topologically nontrivial critical points and critical edge modes to
non-Hermitian setups, but also yield additional insights for analyzing
topological transitions and bulk-edge correspondence in open systems.

</details>


### [530] [Quantum Spin Hall effect on planar Archimedean lattices](https://arxiv.org/abs/2509.01465)
*L. V. Duc Pham,Nicki F. Hinsche,Ingrid Mertig*

Main category: cond-mat.mes-hall

TL;DR: 本文系统研究了八种纯阿基米德晶格的电子和拓扑性质，发现截角六边形和截角三斜六边形晶格具有近乎无色散的平带，而截角三斜六边形晶格则支持拓扑保护的高度自旋极化的边缘态，该边缘态稳定且具有显著的自旋霍尔电流。


<details>
  <summary>Details</summary>
Motivation: 本文旨在系统研究纯阿基米德晶格的电子和拓扑性质，填补该领域的研究空白，特别是探索其在电子和拓扑性质方面的潜力。

Method: 本文采用紧束缚模型研究了所有八种纯阿基米德晶格，同时考虑了s和p轨道。研究内容包括能带结构分析、非常规纳米带几何的拓扑边缘态研究，以及使用Kubo形式主义计算Z2不变量和本征自旋霍尔电导率。

Result: 研究结果表明，截角六边形和截角三斜六边形晶格等几种阿基米德晶格具有跨越整个布里渊区的近乎无色散的平带，并且这些平带对最近邻跳跃和强自旋-轨道耦合具有鲁棒性。特别是，截角三斜六边形晶格在多种纳米带几何中支持拓扑保护的、高度自旋极化的边缘态，这些边缘态对缺陷和自旋翻转散射稳定，并产生可观的自旋霍尔电流。

Conclusion: 本文的系统性研究揭示了阿基米德晶格在电子和拓扑性质方面的丰富潜力，特别是截角三斜六边形晶格展现出的优异的拓扑边缘态特性，为未来在量子计算、自旋电子学等领域的应用提供了新的方向。

Abstract: Archimedean lattices constitute a unique family of two-dimensional tilings
formed from regular polygons arranged with uniform vertex configurations. While
the kagome lattice has been extensively studied and the snub square lattice has
served as a quasicrystal approximant, the broader family remains comparatively
unexplored in the context of electronic and topological properties. In this
work, we present a systematic tight-binding study of all eight pure Archimedean
lattices, incorporating both $s$ and $p$ orbitals. We analyze their band
structures, investigate topological edge states arising from unconventional
nanoribbon geometries, and evaluate $\mathbb{Z}_2$ invariants as well as
intrinsic spin Hall conductivities using the Kubo formalism. Our results reveal
that several Archimedean lattices, such as the truncated hexagonal and
truncated trihexagonal lattices, host nearly dispersionless flat bands
extending across the Brillouin zone, which remain robust even in the presence
of next-nearest-neighbor hopping and strong spin-orbit coupling. In particular,
the truncated trihexagonal lattice supports topologically protected, highly
spin-polarized edge states across multiple ribbon geometries. These states are
stable against defects and spin-flip scattering, and they give rise to sizable
spin Hall currents.

</details>


### [531] [Quality of Helicity-Dependent Magnetization Switching by Phonons](https://arxiv.org/abs/2509.01480)
*F. G. N. Fennema,C. S. Davies,A. Tsukamoto,A. Kirilyuk*

Main category: cond-mat.mes-hall

TL;DR: 该研究通过圆偏振横光学声子的共振激发，利用偏振调制的瞬态光栅来控制磁性，实现了超快、高效的磁化反转。


<details>
  <summary>Details</summary>
Motivation: 探索光学控制磁化，实现超快、能量效率高的磁化反转。

Method: 使用偏振调制的瞬态光栅，通过共振激发圆偏振横光学声子来研究磁化的螺旋度依赖性开关。

Result: 结果表明，样本衬底内的偏振声子能在磁性覆盖层中诱导鲁棒的、由螺旋度定义的磁化反转。并且，当红外激发在与目标声子模式共振时，改变椭圆度对开关质量影响不大；但当激发偏离共振时，开关质量对入射光的椭圆度变得非常敏感。

Conclusion: 研究证明了通过共振激发声子是实现光学控制磁化的有效方法，并揭示了椭圆度在开关过程中的敏感性。

Abstract: Optical control of magnetization has emerged as a promising approach to
achieve ultrafast and energy-efficient magnetization reversal. Here, we
investigate helicity-dependent switching of magne- tization driven by the
resonant excitation of circularly-polarized transverse-optical phonons, using a
polarization-modulated transient grating. Our results show that the polarized
phonons within the sample substrate induce robust, helicity-defined
magnetization reversal in the magnetic overlayer. Moreover, the quality of
switching remains largely unaffected when the degree of ellipticity of the
infrared excitation is varied at frequencies resonant with the targeted phonon
modes. Conversely, as the excitation is moved slightly off-resonance, switching
quality becomes highly sensitive to the ellipticity of the incident light.

</details>


### [532] [Realizing Blume-Capel Degrees of Freedom with Toroidal Moments in a Ruby Artificial Spin Ice](https://arxiv.org/abs/2509.01522)
*Luca Berchialla,Gavin M. Macauley,Flavien Museur,Tianyue Wang,Armin Kleibert,Peter M. Derlet,Laura J. Heyderman*

Main category: cond-mat.mes-hall

TL;DR: 研究人员在Ruby晶格上实现了包含三个自旋状态的Blume-Capel模型，并通过观察纳米磁体的环形矩来研究其相变过程，最终成功实现了顺磁相到铁磁相的有序转变，为探索奇异哈密顿量和设计新型材料提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 实现超越Ising模型的奇异哈密顿量是实验统计物理学的关键追求，包括Blume-Capel模型。

Method: 在Ruby晶格上放置单畴纳米磁体，形成人工晶体，通过调控晶格参数来控制纳米磁体形成的环形矩的有序过程，实现Blume-Capel自由度。

Result: 观察到环形矩的两步有序过程：高温下从顺磁相到中间的准 the toroidic 状态的交叉转变，然后是到铁磁 the toroidic 状态的二阶相变。

Conclusion: 在人工自旋冰的框架内，通过纳米磁体的环形矩实现了Blume-Capel模型的相图，为研究奇异哈密顿量和设计具有新功能的人工自旋冰超结构提供了新平台。

Abstract: Realizing exotic Hamiltonians beyond the Ising model is a key pursuit in
experimental statistical physics. One such example is the Blume-Capel model, a
three-state spin model, whose phase diagram features a tricritical point where
second-order and first-order transition lines converge, leading to a
coexistence of paramagnetic, ferromagnetic, and disordered phases. Here, we
realize an artificial crystal of single-domain nanomagnets, placed on the links
of the Ruby lattice, enabling real-space observation of the Blume-Capel degrees
of freedom. These Blume-Capel degrees of freedom are represented by the
presence, sign and interactions of the toroidal moments that emerge naturally
in plaquettes of nanomagnets in the Ruby artificial spin ice. By precisely
tuning the lattice parameters of the Ruby artificial spin ice, we demonstrate
control over the two-step ordering process of the toroidal moments, whereby
there is a high-temperature crossover from a paramagnetic phase to an
intermediate paratoroidic regime, followed by a second-order phase transition
to a ferrotoroidic ground state. This sequence of toroidal phases and
transitions is accurately captured by the Blume-Capel framework and provides a
direct realization of a substantial portion of the phase diagram associated
with the model. This establishes a new platform for exploring exotic
Hamiltonians in terms of artificial spin ice superstructures, here with groups
of nanomagnets forming toroidal moments. The success of this mapping paves the
way for an entirely new frontier in artificial spin ice: intentionally
engineering lattice designs whose effective Hamiltonians mediate unconventional
forms of magnetic order, with new behaviors and functionalities.

</details>


### [533] [Electron transfer between surface-acoustic-wave-induced moving and static quantum dots](https://arxiv.org/abs/2509.01525)
*Mikel Olano,Geza Giedke*

Main category: cond-mat.mes-hall

TL;DR: 研究量子点间长距离相互作用及其在量子计算中的应用，并提出一种新的模型来描述静态和移动量子点之间的传输过程。


<details>
  <summary>Details</summary>
Motivation: 解决量子点间长距离相互作用的难题，以提高量子模拟和计算的可扩展性，并研究静态和移动量子点之间的传输问题。

Method: 推导并讨论了驱动两态转移过程的非绝热项，并分析了电子自旋状态和加载转移概率的影响，包括了Rashba-Dresselhaus项。

Result: 提出了一种描述量子点间传输过程的范例模型，并分析了非绝热项和Rashba-Dresselhaus效应对转移概率的影响。

Conclusion: 该研究为解决量子点间长距离相互作用和传输问题提供了新的模型和见解。

Abstract: Fast long-range interactions between distant quantum dots in arrays remains
an unsolved issue, which can be key to solve scalability issues in quantum
simulation and computation processes, particularly related to the overhead
associated with quantum error correction schemes. Furthermore, transport
between static and moving quantum dots, relevant in surface acoustic wave
induced experiments, has not been studied in detail. This article presents a
paradigmatic model for picturing this process, where non-adiabatic terms
driving a two-state transfer process are derived and discussed. Moreover, the
main effects in the spin state of the electron and its effect on the transfer
probability of the loading are analyzed including the most relevant interaction
in semiconductor heterostructure induced 2 dimensional electron gases i.e. the
Rashba-Dresselhaus terms.

</details>


### [534] [Magnetic-Field Control of Emergent Order in a 3D Dipolar Pyramid Artificial Spin Ice](https://arxiv.org/abs/2509.01534)
*Luca Berchialla,Gavin M. Macauley,Flavien Museur,Anja Weber,Laura J. Heyderman*

Main category: cond-mat.mes-hall

TL;DR: 三维人工自旋冰研究


<details>
  <summary>Details</summary>
Motivation: 探索三维人工自旋冰

Method: 构建三维人工自旋冰模型，进行蒙特卡洛模拟和磁力显微镜实验

Result: 发现可调谐态、丰富的相图和有效的平方冰态

Conclusion: 三维人工自旋冰立方为探索三维人工自旋冰提供了新平台

Abstract: We realize a three-dimensional artificial spin ice of disconnected
nanomagnets interacting solely via dipolar coupling, patterned on square
pyramids. This Pyramid artificial spin ice, with both tilted and in-plane
nanomagnets, supports tunable states. Monte Carlo simulations reveal a rich
phase diagram and an emergent square ice of vertex-level effective spins.
Tailored demagnetization protocols and magnetic force microscopy allow
experimental access to low-energy states, establishing a platform for exploring
three-dimensional artificial spin ices.

</details>


### [535] [Geometric phases on graphene from Atiyah-Singer index theorem](https://arxiv.org/abs/2509.01574)
*M. Dantas,A. Carvalho,G. Garcia,C. Furtado*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用阿蒂亚-辛格指数定理，通过将弯曲石墨烯结构中的低能准粒子建模为狄拉克费米子，研究了几何相位在石墨烯纳米结构中的出现。研究表明，由五边形或七边形碳环产生的拓扑缺陷会产生有效的规范场，从而诱导出量化的贝里相位。研究推导出了一个用结构属和开放边界数量表示的几何相的紧凑表达式，为零能模式提供了拓扑分类。该框架深化了对石墨烯中量子路径的理解及其在全息量子计算中的潜在应用，并将离散晶格模型与连续指数理论联系起来，从而获得物理上直观且易于实验验证的见解。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机在于理解几何相位在石墨烯基纳米结构中的出现，以及探索其在量子计算中的潜在应用。

Method: 该研究将弯曲石墨烯结构中的低能准粒子建模为狄拉克费米子，并利用阿蒂亚-辛格指数定理来推导几何相位。

Result: 研究表明，拓扑缺陷（如五边形或七边形碳环）会产生有效的规范场，从而诱导出量化的贝里相位。此外，还推导出了一个用结构属和开放边界数量表示的几何相的紧凑表达式，为零能模式提供了拓扑分类。

Conclusion: 该研究为理解石墨烯中的量子路径及其在全息量子计算中的潜在应用提供了新的见解，并将离散晶格模型与连续指数理论联系起来，得到了易于理解且便于实验验证的结果。

Abstract: We investigate the emergence of geometric phases in graphene-based
nanostructures through the lens of the Atiyah-Singer index theorem. By modeling
low-energy quasiparticles in curved graphene geometries as Dirac fermions, we
demonstrate that topological defects arising from the insertion of pentagonal
or heptagonal carbon rings generate effective gauge fields that induce
quantized Berry phases. We derive a compact expression for the geometric phase
in terms of the genus and number of open boundaries of the structure, providing
a topological classification of zero-energy modes. This framework enables a
deeper understanding of quantum holonomies in graphene and their potential
application in holonomic quantum computation. Our approach bridges discrete
lattice models with continuum index theory, yielding insights that are both
physically intuitive and experimentally accessible.

</details>


### [536] [Topological polar textures on CsPbBr3 nanoplatelets](https://arxiv.org/abs/2509.01751)
*Monika Bhakar,Pooja Bhardwaj,Gokul M. Anilkumar,Atikur Rahman,Goutam Sheet*

Main category: cond-mat.mes-hall

TL;DR: CsPbBr3纳米片可在室温下稳定存在和控制极性拓扑结构，其尺寸可通过厚度调节，并可作为研究畴壁调控功能的平台。


<details>
  <summary>Details</summary>
Motivation: 在化学简单的溶液生长材料中稳定和控制极性拓扑结构（如泡畴、磁通闭合和迷宫等）具有挑战性。本研究旨在探索一种在CsPbBr3纳米片中实现室温下稳定和可控极性拓扑结构的方法。

Method: 采用接触共振压电响应显微镜（PFM）对不同厚度（125 nm 至 2 μm）的CsPbBr3纳米片进行表征，并研究了厚度、机械/电扰动和温度对极性拓扑结构（泡畴、迷宫畴）的影响。

Result: 结果表明，CsPbBr3纳米片的泡畴尺寸随厚度减小而减小，这与由去极化场控制的稳定性窗口一致。重复扫描可以将泡畴转变为迷宫状图案，表明其在弱扰动下具有亚稳态。加热时，泡畴会转变为迷宫畴并在约90°C时消失，而在冷却时则恢复畴形核。

Conclusion: CsPbBr3纳米片为在稳定的化学计比钙钛矿中实现可控极性拓扑结构提供了一个平台，并阐明了电边界条件（由厚度和温度决定）如何影响拓扑选择。所识别的厚度可调极性拓扑结构为在卤化物钙钛矿中设计畴壁调控功能开辟了新途径。

Abstract: Polar topological textures like the bubble domains, flux--closures, and
labyrinth etc., unlock functional responses in ferroic systems but are
difficult to stabilize and control in chemically simple, solution--grown
materials. Here we show that ultra--thin, large--area CsPbBr$_3$ nanoplatelets
host room--temperature ferroelectric bubble domains whose characteristic size
is tunable by thickness. Using contact--resonance piezoresponse force
microscopy (PFM) across 125\~nm--2\~$\mu$m, we observe a systematic decrease in
domain size with decreasing thickness, consistent with a depolarization--field
controlled stability window. Repeated scanning transforms bubbles into
labyrinthine patterns, indicating metastability under weak
mechanical/electrical perturbations. Upon heating, bubbles evolve into
labyrinths and vanish at $T_C\!\approx\!90^\circ$C, with domain nucleation
recovered on cooling. These results establish a controllable platform for polar
topology in a stable, stochiometric perovskite grown via a solvothermal route,
and clarify how electrical boundary conditions (set by thickness and
temperature) govern texture selection. The thickness--tunable polar textures
identified here offer a route to engineer domain--wall--mediated
functionalities in halide perovskites.

</details>


### [537] [AM-DefectNet: Additive Manufacturing Defect Classification Using Machine Learning - A comparative Study](https://arxiv.org/abs/2509.01769)
*Mohsen Asghari Ilani,Yaser Mike Banad*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了AM-DefectNet框架，用于评估和比较15种机器学习模型在增材制造（AM）熔池特征提取和缺陷检测任务中的表现。结果表明，基于树的非线性算法（特别是CatBoost、LGBM和XGBoost）表现优于其他模型，其中CatBoost在准确率、精确率、召回率和F1分数方面表现最佳，准确率达到92.47%。深度神经网络（DNN）也表现出竞争力，准确率为88.55%。该研究为AM过程优化奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 增材制造（AM）过程在监测和控制材料属性及工艺参数方面存在挑战，影响了生产质量和缺陷检测。机器学习（ML）技术为解决这些挑战提供了有前景的解决方案。本研究旨在为AM熔池特征提取这一关键领域建立一个全面的ML模型基准测试框架。

Method: 本研究评估了15种机器学习模型在熔池特征提取任务中的表现，使用了1514个训练数据集和505个测试数据集，并根据10项指标进行了评估。研究中比较了包括非线性树模型（如CatBoost、LGBM、XGBoost）和深度神经网络（DNN）在内的多种模型。

Result: 评估结果显示，非线性树模型，特别是CatBoost、LGBM和XGBoost，在准确率方面表现优于其他模型，准确率分别为92.47%、91.08%和90.89%。DNN模型的准确率为88.55%，同样具有竞争力。CatBoost在精确率、召回率、F1分数和总体准确率方面均表现出最佳性能。学习曲线分析也揭示了模型性能和数据需求方面的见解。

Conclusion: 机器学习模型在熔池特征提取和缺陷检测方面是有效的，为增材制造（AM）过程的优化提供了基础。CatBoost作为表现最佳的模型，在提高AM生产质量和缺陷检测方面具有巨大潜力。

Abstract: Additive Manufacturing (AM) processes present challenges in monitoring and
controlling material properties and process parameters, affecting production
quality and defect detection. Machine Learning (ML) techniques offer a
promising solution for addressing these challenges. In this study, we introduce
a comprehensive framework, AM-DefectNet, for benchmarking ML models in melt
pool characterization, a critical aspect of AM. We evaluate 15 ML models across
10 metrics using 1514 training and 505 test datasets. Our benchmarking reveals
that non-linear tree-based algorithms, particularly CatBoost, LGBM, and
XGBoost, outperform other models, achieving accuracies of 92.47%, 91.08%, and
90.89%, respectively. Notably, the Deep Neural Network (DNN) also demonstrates
competitive performance with an accuracy of 88.55%. CatBoost emerges as the
top-performing algorithm, exhibiting superior performance in precision, recall,
F1-score, and overall accuracy for defect classification tasks. Learning curves
provide insights into model performance and data requirements, indicating
potential areas for improvement. Our study highlights the effectiveness of ML
models in melt pool characterization and defect detection, laying the
groundwork for process optimization in AM.

</details>


### [538] [Multi-objective Evolutionary Algorithms (MOEAs) in PMEDM - A Comparative Study in Pareto Frontier](https://arxiv.org/abs/2509.01775)
*Mohsen Asghari Ilani,Yaser Mike Banad*

Main category: cond-mat.mes-hall

TL;DR: ML模型（DNN、XGBoost、AdaBoost、ElasticNet）被用于优化粉末混合放电加工（PMEDM）效率，XGBoost表现最佳，结合MOEA（如NSGA-II）可进一步优化。


<details>
  <summary>Details</summary>
Motivation: 使用机器学习（ML）方法提高粉末混合放电加工（PMEDM）的效率和精度，特别是结合振动系统。

Method: 评估DNN、XGBoost、AdaBoost和ElasticNet四种ML模型在包含粉末添加和电极振动特征的数据集上的表现，并使用多目标进化算法（MOEAs）如NSGA-II、NSGA-III、UNSGA-III和C-TAEA进行优化。

Result: XGBoost模型的准确性最高，其次是AdaBoost、DNN和ElasticNet。MOEA可用于优化帕累托前沿以获得最优解。

Conclusion: 机器学习和优化技术在改进放电加工（EDM）方面具有巨大潜力，为精密制造提供了成本效益高、省时且可靠的解决方案。

Abstract: Electrical discharge machining (EDM) is a crucial process in precision
manufacturing, leveraging electro-thermal energy to remove material without
electrode contact. In this study, we delve into the realm of Machine Learning
(ML) to enhance the efficiency and precision of EDM, particularly focusing on
Powder-Mixed Electrical Discharge Machining (PMEDM) with the integration of a
vibration system. We comprehensively evaluate four leading ML models - Deep
Neural Network (DNN), Extreme Gradient Boosting (XGBoost), Adaptive Gradient
Boosting (AdaBoost), and ElasticNet, against a pool of ML models, employing
various evaluation metrics including Accuracy, Mean Squared Error (MSE), Root
Mean Squared Error (RMSE), and Mean Absolute Error (MAE). Our evaluations,
conducted on datasets enriched with features derived from powder addition and
electrode vibration, reveal XGBoost superior accuracy, followed by AdaBoost,
DNN, and ElasticNet. Furthermore, through the integration of Multi-Objective
Evolutionary Algorithms (MOEAs) such as NSGA-II, NSGA-III, UNSGA-III, and
C-TAEA, we explore and optimize the Pareto front to attain optimal solutions.
Our findings underscore the transformative potential of ML and optimization
techniques in advancing EDM processes, offering cost-effective, time-efficient,
and reliable solutions for precision manufacturing applications.

</details>


### [539] [Spin-orbit torque control of topology in intrinsic antiferromagnetic insulators](https://arxiv.org/abs/2509.01810)
*Rajibul Islam,Shakeel Ahmad,Fei Xue*

Main category: cond-mat.mes-hall

TL;DR: 自旋-轨道扭矩可用于切换磁性拓扑绝缘体的拓扑相，在MnBi2Te4中实现了由能隙内扭矩驱动的无耗散开关，并在掺杂时通过增强扭矩将开关所需的临界电场降低了两个数量级。


<details>
  <summary>Details</summary>
Motivation: 磁性拓扑绝缘体虽然具有量子反常霍尔效应和量子化磁电响应等奇异现象，但其拓扑相的动态电学控制仍然难以实现。

Method: 研究人员利用自旋-轨道扭矩，通过第一性原理计算，证明了其可以直接切换本征反铁磁双层MnBi2Te4的拓扑态。他们在能隙内存在对称强制的带间（时间反演偶）扭矩，该扭矩可以确定性地反转Néel顺序和层分辨陈数，且不产生自由载流子。

Result: 研究发现，能隙内扭矩即使在存在能隙的情况下也能持续存在，并能实现拓扑相的切换。当对材料进行掺杂时，带间和带内扭矩都会得到增强，从而使开关所需的临界电场降低了两个数量级。

Conclusion: 该研究建立了两种互补的控制机制：一种是无耗散的能隙内扭矩，无需焦耳热；另一种是增强的电流诱导扭矩。这为操纵反铁磁拓扑绝缘体中的陈数、准螺旋边缘态和拓扑响应提供了一条可靠的途径。

Abstract: Magnetic topological insulators host exotic phenomena such as the quantum
anomalous Hall effect and quantized magnetoelectric responses, but dynamic
electrical control of their topological phases remains elusive. Here we
demonstrate from first principles that spin-orbit torque enables direct
switching of the topological state in the intrinsic antiferromagnetic bilayer
MnBi$_2$Te$_4$. A symmetry-enforced interband (time-reversal even) torque
persists inside the bulk gap and deterministically reverses the N\'eel order
and layer-resolved Chern number without free carriers. Upon doping, both
interband and intraband torques are amplified, lowering the critical electric
field for switching by two orders of magnitude. Together, these results
establish two complementary regimes of control, dissipationless in-gap torques
without Joule heating and enhanced current-induced torques, providing a robust
route to manipulate local Chern numbers, quasi-helical edge states, and
topological responses in antiferromagnetic topological insulators.

</details>


### [540] [A Practical Flake Segmentation and Indexing Pipeline for Automated 2D Material Stacking](https://arxiv.org/abs/2509.01826)
*Yutao Li,Logan Sherlock,Ryan Benderson,Daniel Ostrom,Huandong Chen,Kazuhiro Fujita,Abhay Pasupathy*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一种用于光学显微镜图像中剥落二维（2D）材料薄片的检测和表征的图像处理流程。


<details>
  <summary>Details</summary>
Motivation: 为了在范德华斯异质结组装中实现自动化，需要一种具有成本效益且鲁棒的图像处理流程来检测和表征光学显微镜图像中的二维材料薄片。

Method: 该系统结合了基于浅层机器学习（ML）的材料分类和由边缘形态学及颜色不连续性驱动的、以精度为先的薄片检测算法。当由光学对比度支持时，阶梯边缘将被解析，同时像灰尘和背景纹理这样的虚假特征能够被可靠地拒绝。每个识别出的薄片都以结构化格式导出，包括质心坐标、边界几何、平均RGB颜色和估计的光学厚度，从而能够无缝集成到自动拾取和堆叠工作流程中。

Result: 该流程是轻量级的，并且在不需要深度学习模型或纳米尺度地面真实标签的情况下运行，使其适用于大规模前端晶圆处理，硬件成本低于30,000美元。与仅关注检测准确性的先前方法相比，所提出的系统将薄片分割与索引、过滤和蓝图驱动的堆叠相结合，形成了从图像采集到器件规划的闭环工作流程。

Conclusion: 该流程因其低注释要求和灵活的实现，能够快速部署到各种二维材料系统和成像条件中，并且能够统一薄片分割、索引、过滤和蓝图驱动的堆叠，形成一个完整的闭环工作流程。

Abstract: A cost-effective and robust image-processing pipeline is presented for the
detection and characterization of exfoliated two-dimensional (2D) material
flakes in optical microscope images, designed to facilitate automation in van
der Waals heterostructure assembly. The system combines shallow machine
learning (ML)-based material classification with a precision-first flake
detection algorithm driven by edge morphology and color discontinuity. Step
edges are resolved when supported by optical contrast, while spurious features
such as dust and background texture are reliably rejected. Each identified
flake is exported in a structured format that includes centroid coordinates,
bounding geometries, average RGB color, and estimated optical thickness,
enabling seamless integration into automated pick-up and stacking workflows.
The pipeline is hardware-light and operates without the need for deep learning
models or nanoscale ground-truth labels, making it practical for scalable
front-end wafer processing at a hardware cost of under 30,000 USD. In contrast
to prior approaches that focus solely on detection accuracy, the proposed
system unifies flake segmentation with indexing, filtering, and
blueprint-driven stacking, forming a closed-loop workflow from image
acquisition to device planning. Its low annotation requirement and flexible
implementation enable rapid deployment across diverse 2D material systems and
imaging conditions.

</details>


### [541] [Magnonic radar for dynamic domain walls in synthetic antiferromagnets](https://arxiv.org/abs/2509.01880)
*Jin Lan,Yang Zhang*

Main category: cond-mat.mes-hall

TL;DR: 研究了合成反铁磁体中自旋波与磁畴壁的相互作用，并提出了一种通过散射自旋波来检测畴壁的平移和角速度的方法。


<details>
  <summary>Details</summary>
Motivation: 磁性系统中自旋波和磁畴壁是两种基本的激发方式，它们的时空相互作用蕴含着丰富的磁相互作用信息。在合成反铁磁体中，磁畴壁具有惯性，自旋波可以解锁全部的极化自由度，为它们的相互作用提供了一个独特的平台。

Method: 利用翻译和角度多普勒效应的协同作用，通过散射的自旋波来检测合成反铁磁体中磁畴壁的平移和角速度。

Result: 研究结果表明，可以通过一系列自旋波包（无论是侵入式还是非侵入式）来获取磁畴壁状态的时间演化，这类似于雷达的设置。

Conclusion: 通过对频域进行检测，为探索和利用磁激发提供了新的范式。

Abstract: Spin wave and magnetic domain wall are two of basic excitations in magnetic
systems, and their spatiotemporal interplay encodes rich information of
underlying magnetic interactions. In synthetic antiferromagnets, the domain
wall acquires an inertia and the spin wave unlocks the full polarization degree
of freedom, lays a salient platform for their interplay. Here we show that both
the translational and angular velocities of domain wall in synthetic
antiferromagnets can be detected via the scattered spin wave, through the
synergy of translational and angular Doppler effects. Following the setup of an
electromagnetic or acoustic radar, the time evolution of a domain wall state
are accessible via a series of spin wave packets, in both non-invasive and
invasive fashion. The inspections in frequency domain, offer new paradigms in
exploration and exploitation of magnetic excitations.

</details>


### [542] [Intrinsic nonlinear valley Nernst effect in the strained bilayer graphene](https://arxiv.org/abs/2509.01961)
*Ying-Li Wu,Jia-Liang Wan,Xiao-Qin Yu*

Main category: cond-mat.mes-hall

TL;DR: 该研究在理论上分析了由温度梯度引起的非线性谷 স্বতন্ত্র效应（NVNE），这是电子动力学半经典框架下的二阶响应。


<details>
  <summary>Details</summary>
Motivation: 研究NVNE作为二阶响应，特别关注由温度梯度引起的纯谷电流的产生及其性质。

Method: 使用电子动力学半经典框架，分析了二阶温度梯度响应，并研究了材料对称性（反演和时间反演对称性）以及单镜面对NVNE的影响。对单轴应变下的石墨烯进行了理论计算。

Result: 发现具有反演和时间反演对称性的材料可以在垂直于温度梯度的方向上产生纯谷电流，该电流具有量子起源，与弛豫时间无关。在双层石墨烯中，当温度梯度垂直于应变方向时，NVNE会出现，并且应变从压缩转变为拉伸会导致NVNE符号反转。

Conclusion: 非线性谷 স্বতন্ত্র效应（NVNE）是二阶响应，其产生的纯谷电流具有量子起源且与弛豫时间无关。材料的对称性，特别是单镜面对称性，对于非零NVNE至关重要。在双层石墨烯中，通过应变可以调控NVNE的出现和符号。

Abstract: We theoretically analyze the nonlinear valley Nernst effect (NVNE) as the
second-order response of temperature gradient through the semiclassical
framework of electron dynamics up to second order. Our study shows that an
intrinsic nonlinear pure valley current can be generated vertically to the
applied temperature in the materials with both inversion and time-reversal
symmetries. This intrinsic NVNE has a quantum origin from the quantum metric
and shows independence from the relaxation time. It's found that the local
largest symmetry near the valleys for the nonvanishing intrinsic NVNE is a
single mirror symmetry in two-dimensional systems. We theoretically investigate
the intrinsic NVNE in the uniaxially strained gapless bilayer graphene and find
the intrinsic NVNE can emerge when applying the temperature gradient vertically
to the direction of strain. Interestingly, a transition from the compressive
strain to the tensile one results in the sign reversal of the intrinsic NVNE.

</details>


### [543] [Cryogenic performance of field-effect transistors and amplifiers based on selective area grown InAs nanowires](https://arxiv.org/abs/2509.02078)
*Giulia Meucci,Dags Olšteins,Damon J. Carrad,Gunjan Nagda,Daria V. Beznasyuk,Christian E. N. Petersen,Sara Martí-Sánchez,Jordi Arbiol,Thomas Sand Jespersen*

Main category: cond-mat.mes-hall

TL;DR: The paper presents the fabrication and characterization of Indium-Arsenide (InAs) nanowire field-effect transistors (NWFETs) for cryogenic applications, highlighting their potential for nanoelectronics and quantum information processing. Selective area growth (SAG) is used for scalability and compatibility with standard processing. The NWFETs show promising low-temperature characteristics and successful operation in integrated circuits, although gate hysteresis poses challenges for precise tuning in sub-threshold applications like amplifiers.


<details>
  <summary>Details</summary>
Motivation:  nanowire field-effect transistors (NWFETs) fabricated using selective area growth (SAG) of Indium-Arsenide (InAs) are promising for high-speed, low-power nanoelectronics at cryogenic conditions, relevant for quantum information processing. The goal is to enable scalability and planar geometries compatible with standard semiconductor processing techniques.

Method: Fabrication of NWFETs using selective area growth (SAG) of InAs nanowires. Characterization of low-temperature characteristics including ION/IOFF ratios, threshold voltages, sub-threshold slope, interfacial trap density, hysteresis, and mobility. Discussion of the role of crystal imperfections and fabrication processes on transistor characteristics.

Result: NWFETs operate successfully in integrated circuitry relying on saturation-mode operation. In sub-threshold applications such as amplifiers, bandwidths exceeding the cryostat wiring are observed. However, gate hysteresis presents challenges for precise tuning of the amplifier operating point.

Conclusion: InAs NWFETs grown by SAG are suitable for cryogenic applications and integrated circuitry. Strategies for further improvement are proposed to address challenges like gate hysteresis and optimize transistor characteristics by managing crystal imperfections and fabrication processes.

Abstract: Indium-Arsenide (InAs) nanowire field-effect transistors (NWFETs) are
promising platforms for high-speed, low power nanoelectronics operating at
cryogenic conditions, relevant for quantum information processing. We present
selective area growth (SAG) of nanowires, which enable scalability and planar
geometries that are compatible with standard semiconductor processing
techniques. NWFETs are fabricated and their low temperature characteristics -
including ION/IOFF ratios, threshold voltages, sub-threshold slope, interfacial
trap density, hysteresis, and mobility - are characterized. The NWFETs operate
successfully in integrated circuitry relying on saturation-mode operation. In
sub-threshold applications such as amplifiers, we find bandwidths exceeding our
cryostat wiring, but the gate hysteresis presents challenges for precise tuning
of the amplifier operating point. We discuss the role of crystal imperfections
and fabrication processes on the transistor characteristics and propose
strategies for further improvements.

</details>


### [544] [Domain Wall Engineering in Graphene-Based Josephson Junctions](https://arxiv.org/abs/2509.02082)
*Xia'an Du,Junjie Qi,Hua Jiang,X. C. Xie*

Main category: cond-mat.mes-hall

TL;DR: 本工作理论研究了基于拓扑畴壁的石墨烯约瑟夫森结的输运性质，并提出三种畴壁工程策略：(1) 畴壁数量工程，展示了临界电流干涉图样如何随畴壁数量增加而从Aharonov-Bohm振荡连续演化为Fraunhofer衍射；(2) 畴壁对称性工程，证明了在磁场下不对称的畴壁结构可以产生具有显著非互易输运的理想约瑟夫森二极管；(3) 畴壁几何工程，揭示了相交的畴壁可以实现可控的超电流分裂，且分裂比可通过交角、磁场和超导相位差进行调节。


<details>
  <summary>Details</summary>
Motivation: 尽管实验条件允许，但将畴壁与约瑟夫森结相结合的研究仍未被充分探索。因此，有必要进行理论研究。

Method: 理论研究基于拓扑畴壁的石墨烯约瑟夫森结的输运性质，并提出和分析了三种畴壁工程策略：(i) 畴壁数量工程，(ii) 畴壁对称性工程，(iii) 畴壁几何工程。

Result: 畴壁数量工程实现了临界电流干涉图样从Aharonov-Bohm振荡到Fraunhofer衍射的连续演化，并提高了磁测量灵敏度。畴壁对称性工程在磁场下实现了具有非互易输运的约瑟夫森二极管。畴壁几何工程实现了可控的超电流分裂，分裂比可通过多种参数调节。

Conclusion: 研究阐明了基于畴壁的约瑟夫森结的丰富物理特性，并为下一代量子器件提供了一个多功能平台。

Abstract: Recent progress has enabled the controlled fabrication of domain walls (DWs)
in graphene, which host topological kink states. Meanwhile, reliable techniques
for constructing graphene-based Joseph- son junctions have been established.
While the experimental prerequisites for combining DWs with Josephson junctions
are now available, this direction remains largely unexplored. In this work, we
theoretically investigate transport properties in graphene-based Josephson
junctions mediated by topological kink states and propose three DW engineering
strategies. (i) DW number engineering uncovers a continuous evolution of
critical current interference pattern from Aharonov-Bohm oscil- lation to
Fraunhofer diffraction with increasing DW number, reproducing experimental
observations [Barrier et al., Nature 628, 741 (2024)] and suggesting enhanced
sensitivity for magnetometry ap- plications. (ii) DW symmetry engineering
demonstrates that an asymmetric configuration of DWs under magnetic field
yields an ideal Josephson diode characterized by pronounced nonreciprocal
transport. (iii) DW geometry engineering reveals that intersecting DWs enable
controllable super- current splitting with ratios among leads tunable through
the intersection angle, magnetic field, and superconducting phase difference.
Our findings elucidate the rich physics of DW-based Josephson junctions and
establish a versatile platform for next-generation quantum devices.

</details>


### [545] [Wide Electrical Tunability of the Valley Splitting in a Doubly gated Silicon-on-Insulator Quantum Well](https://arxiv.org/abs/2509.02094)
*Nathan Aubergier,Vincent T. Renard,Sylvain Barraud,Kei Takashina,Benjamin A. Piot*

Main category: cond-mat.mes-hall

TL;DR: 本论文研究了双栅硅绝缘体量子阱中二维电子的谷劈裂现象，通过低温输运测量和磁场分析。


<details>
  <summary>Details</summary>
Motivation: 研究双栅硅绝缘体量子阱中二维电子的谷劈裂现象，探索其与静电偏压、波函数和界面穿透的关系。

Method: 通过低温输运测量和磁场分析，研究了不同界面（氧化硅和高k电介质）的谷劈裂现象。

Result: 在氧化硅界面，谷劈裂随静电偏压增大而增大，最高可达6.3 meV，且与载流子浓度无关。在高k电介质界面，观察到较小的谷劈裂。

Conclusion: 静电偏压是调控二维硅系统中谷劈裂的有效参数，不同界面提供了额外的调控手段。

Abstract: The valley splitting of 2D electrons in doubly-gated silicon-on-insulator
quantum wells is studied by low temperature transport measurements under
magnetic fields. At the buried thermal-oxide SiO$_{2}$ interface, the valley
splitting increases as a function of the electrostatic bias $\delta n =
n_{B}-n_{F}$ (where $n_{B}$ and $n_{F}$ are electron densities contributed by
back and front gates, respectively) and reaches values as high as $6.3$~meV,
independent of the total carrier concentration of the channel. We show that
$\delta n$ tunes the square of the wave function modulus at the interface and
its penetration into the barrier, both of which are key quantities in a theory
describing interface-induced valley splitting, and is therefore the natural
experimental parameter to manipulate valleys in 2D silicon systems. At the
front interface, made of a thin ``high-k'' dielectric, a smaller valley
splitting is observed, adding further options to tune the valley splitting
within a single device.

</details>


### [546] [Electromagnetic responses of bilayer excitonic insulators](https://arxiv.org/abs/2509.02142)
*Yuelin Shao,Hao Shi,Xi Dai*

Main category: cond-mat.mes-hall

TL;DR: 本文研究了双层激子绝缘体(EI)的电磁响应，发现了两种集体模式：1) 两种有能隙的等离激元模式，它们与层对称规范场耦合。其中横波模式在长波极限下几乎无色散，而纵波模式（代表总电荷涨落）具有线性色散，其速度与二维电极化率成正比。2) 一个无能隙的（Goldstone）模式和一个有能隙的振幅模式，它们与层反对称规范场耦合，并且与EI序参数的涨落有关。在长波极限下，Goldstone模式表现出线性色散，其速度与激子压缩率的平方根成反比，代表了激子凝聚的第一声波模式。该线性色散在微波阻抗显微镜（MIM）中表现为导纳实部与频率的三次方成正比，这为直接探测Goldstone模式提供了一种方法。


<details>
  <summary>Details</summary>
Motivation: 研究双层激子绝缘体的电磁响应，识别其集体模式。

Method: 分析双层激子绝缘体的电磁响应，识别耦合到层对称和层反对称规范场的集体模式。

Result: 发现了两种类型的集体模式：1) 两种有能隙的等离激元模式，一种横波模式（几乎无色散），一种纵波模式（线性色散，速度与二维电极化率成正比）。2) 一种无能隙的Goldstone模式（线性色散，速度与激子压缩率的平方根成反比）和一种有能隙的振幅模式，它们与层反对称规范场耦合。

Conclusion: Goldstone模式的线性色散在MIM中导致导纳实部与频率立方成正比，这提供了一种直接探测Goldstone模式的方法。

Abstract: We investigate the electromagnetic responses of a bilayer excitonic
insulators (EI) and identify two types of collective modes:
  (1) Two gapped plasmon modes couple to the layer symmetric gauge field. The
transverse mode is nearly dispersionless in the long-wavelength limit, while
the longitudinal mode, accounting for total charge fluctuations, has a linear
dispersion with velocity proportional to two dimensional (2D) electrical
polarizability.
  (2) A gapless phase (Goldstone) mode and a gapped amplitude mode, associated
with the fluctuations of EI order parameter, couple to the layer antisymmetric
gauge field.
  In the long-wavelength limit, the Goldstone mode exhibits linear dispersion
with velocity inversely proportional to the square root of exciton
compressibility, representing the first sound mode of the exciton condensate
  Significantly, its linear dispersion yields a cubic frequency dependence of
the real admittance in microwave impedance microscopy (MIM), providing a method
to detect the Goldstone mode directly.

</details>


### [547] [Classification of topological insulators and superconductors with multiple order-two point group symmetries](https://arxiv.org/abs/2509.02168)
*Ken Shiozaki*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一种计算拓扑绝缘体和超导体在 Z2xns{ } 对称群存在下的分类群的方法，其中 n 可以是任意自然数。


<details>
  <summary>Details</summary>
Motivation: 本文旨在提供一个计算拓扑绝缘体和超导体在 Z2xns{ } 对称群存在下的分类群的方法。

Method: 该方法通过考虑每个生成元的 Z2 对称性以及它们之间成对的换位或反换位关系来表征每个对称类。论文表明，分类完全取决于每个生成元翻转的动量空间和实空间变量的数量，以及任何一对生成元同时翻转的变量数量。

Result: 论文提供了一个具体的例子，给出了 Z2xns{ } 对称群情况下的完整分类表。

Conclusion: 该方法能够根据生成元翻转的变量数量来完全确定分类。

Abstract: We present a method for computing the classification groups of topological
insulators and superconductors in the presence of $\mathbb{Z}_2^{\times n}$
point group symmetries, for arbitrary natural numbers $n$. Each symmetry class
is characterized by four possible additional symmetry types for each generator
of $\mathbb{Z}_2^{\times n}$, together with bit values encoding whether pairs
of generators commute or anticommute. We show that the classification is fully
determined by the number of momentum- and real-space variables flipped by each
generator, as well as the number of variables simultaneously flipped by any
pair of generators. As a concrete illustration, we provide the complete
classification table for the case of $\mathbb{Z}_2^{\times 2}$ point group
symmetry.

</details>


### [548] [Nanoscale Dipolar Fields in Artificial Spin Ice Probed by Scanning NV Magnetometry](https://arxiv.org/abs/2509.02233)
*Ephraim Spindler,Vinayak Shantaram Bhat,Elke Neu,Mathias Weiler,M. Benjamin Jungfleisch*

Main category: cond-mat.mes-hall

TL;DR: NV 显微镜用于研究不同晶格常数的两种方形人工自旋冰（ASI）系统中不同尺度的磁相互作用。


<details>
  <summary>Details</summary>
Motivation: 文章旨在利用具有前所未有空间分辨率、可在环境条件下操作并提供定量磁场测量的单氮空位（NV）中心扫描探针显微镜，研究两种具有不同晶格常数的方形人工自旋冰（ASI）系统中的偶极耦合场。

Method: 该方法结合了荧光猝灭成像和连续波光检测磁共振（cODMR）。通过比较两种 ASI 样品（晶格常数分别为 1000 nm 和 910 nm），研究了由晶格常数决定的不同耦合强度如何影响 ASI 顶点中偏离最低能量构型的冰规则违规现象。从 cODMR 数据中提取了相对于 NV 轴的局部磁场的轴向和横向分量。通过微磁建模来确定外部磁场方向、检测由弱外部场引起的细微磁化倾斜，并估算有效饱和磁化强度。

Result: 比较不同晶格常数的 ASI 样品揭示了冰规则违规现象的外观差异，这归因于由晶格常数决定的耦合强度的变化。通过微磁建模，成功确定了外部磁场方向，检测到弱外部场引起的磁化倾斜，并估算了有效饱和磁化强度。

Conclusion: 研究结果为了解 ASI 中可调谐的磁相互作用提供了关键见解，为设计先进的声子和自旋电子器件铺平了道路。

Abstract: We investigate dipolar coupling fields in two square-lattice artificial spin
ice (ASI) systems with different lattice constants using scanning probe
microscopy based on a single nitrogen-vacancy (NV) center in diamond. This
technique offers unprecedented spatial resolution, operates under ambient
condition, and provides quantitative stray field measurements, making it
uniquely suited for studying nanoscale magnetic textures. Our approach combines
fluorescence quenching imaging and continuous-wave optically detected magnetic
resonance (cODMR). A comparison of the two ASI samples, which differ in their
lattice constants of 1000 nm and 910 nm respectively, reveals differences in
the appearance of ice-rule violations - deviations from the lowest energy
configuration in ASI vertices. We attribute these variations to varying
coupling strengths dictated by the lattice constant. From the cODMR data, we
extract both axial and transverse components of the local magnetic field
relative to the NV axis. Micromagnetic modeling of these measurements allows
for an iterative determination of the external magnetic field orientation, the
detection of subtle magnetization tilts induced by weak external fields (well
below the nanomagnets' switching threshold), and an estimation of the effective
saturation magnetization, thereby accounting for deviations in nanomagnet
dimensions. These findings provide crucial insights into the tunable magnetic
interactions in ASI, paving the way for the design of advanced magnonic and
spintronic devices.

</details>


### [549] [Unconventional Electromechanical Response in Ferrocene Assisted Gold Atomic Chain](https://arxiv.org/abs/2509.02264)
*Biswajit Pabi,Štěpán Marek,Tal Klein,Arunabha Thakur,Richard Korytár,Atindra Nath Pal*

Main category: cond-mat.mes-hall

TL;DR: 金-二茂铁连接体中的金原子链在拉伸时表现出非单调的机电响应，电导率增加了十倍以上，这归因于分子倾斜导致的轨道重叠变化。


<details>
  <summary>Details</summary>
Motivation: 研究原子级金属链中的量子输运及其电导率与轨道图像的关系，特别是金-二茂铁连接体中的机电响应。

Method: 在可控断裂结中，利用低温和 DFT 计算，研究了金-二茂铁连接体在拉伸过程中的电导率变化及其与分子构象的关系。

Result: 在拉伸金-二茂铁连接体时，观察到电导率增加了十倍以上，并且这种变化是非单调的。DFT 计算表明，分子倾斜改变了轨道重叠和传输光谱，从而导致了这种非单调的电导率演变。

Conclusion: 金-二茂铁连接体中的构象重排在链伸长过程中起着关键作用，导致了非单调的机电响应，这与典型的金属原子链的平坦电导平台不同。研究结果加深了对轨道杂化在输运性质中的作用的理解，并为设计具有定制机电特性的纳米器件提供了新机会。

Abstract: Atomically thin metallic chains serve as pivotal systems for studying quantum
transport, with their conductance strongly linked to the orbital picture. Here,
we report a non-monotonic electro-mechanical response in a gold-ferrocene
junction, characterized by an unexpected conductance increase over a factor of
ten upon stretching. This response is detected in the formation of
ferrocene-assisted atomic gold chain in a mechanically controllable break
junction at a cryogenic temperature. DFT based calculations show that tilting
of molecules inside the chain modifies the orbital overlap and the transmission
spectra, leading to such non-monotonic conductance evolution with stretching.
This behavior, unlike typical flat conductance plateaus observed in metal
atomic chains, pinpoints the unique role of conformational rearrangements
during chain elongation. Our findings provide a deeper understanding of the
role of orbital hybridization in transport properties and offer new
opportunities for designing nanoscale devices with tailored electro-mechanical
characteristics.

</details>


### [550] [All-optical band structure reconstruction and onset of Landau quantization of Dirac fermions](https://arxiv.org/abs/2509.02362)
*Josef Riepl,Marc Aichner,Nikolai N. Mikhailov,Sergei A. Dvoretsky,Grigory V. Budkin,Sergey D. Ganichev,Christoph Lange,Joshua Mornhinweg,Rupert Huber*

Main category: cond-mat.mes-hall

TL;DR: This paper uses time-resolved TH7 spectroscopy to precisely measure the band structure of Dirac electrons in a buried HgTe quantum well, overcoming limitations of existing methods and observing a crossover in Landau quantization.


<details>
  <summary>Details</summary>
Motivation: To precisely quantify potential gaps of the Dirac cone with meV precision, overcoming the surface sensitivity and limited energy resolution of established band structure measurement techniques.

Method: Broadband, time-resolved THz magneto-spectroscopy with optical doping to control the Fermi level, enabling contact-free, all-optical measurements. The cyclotron resonance of the Dirac system was measured over 2.5 optical octaves and a broad range of magnetic field strengths and Fermi energies.

Result: Reconstructed the band structure near the Dirac point with sub-meV precision and observed a crossover of Landau quantization from a quasi-classical to the relativistic regime.

Conclusion: Time-resolved THz magneto-spectroscopy is a powerful technique for precisely characterizing the band structure of materials like HgTe quantum wells, providing insights into the behavior of relativistic electrons and Landau quantization.

Abstract: The nature of relativistic electrons in solids depends on the precise shape
of the underlying band structure. Prominently, symmetry-related mechanisms,
such as the breaking of time reversal symmetry in topological insulators, can
lead to the emergence of band gaps on small energy scales. It is, thus,
important to quantify potential gaps of the Dirac cone with meV precision. Yet
established band structure measurements are often challenged by their strict
surface sensitivity or limited energy resolution. In this work, we use
broadband, time-resolved THz magneto-spectroscopy to access the band structure
of Dirac electrons in a buried HgTe quantum well by contact-free, all-optical
measurements. Optical doping allows us to control the Fermi level without
applying any electrical gate voltages. The background-free measurement of the
cyclotron resonance of the Dirac system over 2.5 optical octaves, a broad range
of magnetic field strengths, and different Fermi energies allows us to
reconstruct the band structure near the Dirac point with sub-meV precision, and
to observe a crossover of Landau quantization from a quasi-classical to the
relativistic regime.

</details>


### [551] [Magnetic Worms: Oscillatory Bimeron Pairing And Collective Transport In Patterned Stripes](https://arxiv.org/abs/2509.02384)
*Jose Toledo-Marin,Mario Castro,David Galvez-Poblete,Bruno Grossi,Sebastián Castillo-Sepúlveda,Alvaro S. Nunez,Sebastian Allende*

Main category: cond-mat.mes-hall

TL;DR: Periodic edge defects stabilize and control magnetic bimeron transport in patterned stripes, leading to a novel collective state called the magnetic worm. The defects enable synchronized motion of multiple bimerons, which is otherwise unstable in smooth stripes.


<details>
  <summary>Details</summary>
Motivation: Magnetic bimerons offer a path for current-driven transport in magnetic stripes, but their motion is hindered by coupling and pinning effects. This paper investigates how periodic edge defects can overcome these limitations.

Method: Simulated the transport of magnetic bimerons in patterned magnetic stripes with periodic edge defects, analyzing the behavior of single and multiple bimerons under varying current densities.

Result: A periodic array of edge defects stabilizes multiple bimeron transport and creates a magnetic worm state. Defects reduce bimeron speed but maintain a linear v-J relationship. Multiple bimerons exhibit synchronized, oscillating motion that becomes segmented at higher numbers. Center-of-mass speed increases with current but decreases with more bimerons. Eight bimerons, unstable in smooth stripes, are stabilized by defects.

Conclusion: Periodic edge defects are a viable method for stabilizing and controlling the motion of magnetic bimerons, enabling the formation of a unique magnetic worm state. This approach addresses the challenges of bimeron coupling and defect pinning, paving the way for reliable current-driven transport applications.

Abstract: Magnetic bimerons in a domain wall provide a practical route for current
driven transport in patterned magnetic stripes. However, coupling between
bimerons and pinning by defects complicate reliable motion. Here we show that a
periodic array of edge defects both stabilizes transport of multiple bimerons
and gives rise to a distinctive collective state, the magnetic worm. A single
bimeron travels at constant speed; defects lower this speed while preserving an
approximately linear relation between velocity $v$ and current density $J$.
With two bimerons, the center of mass advances nearly uniformly while their
separation exhibits a bounded oscillation whose frequency increases and
amplitude decreases with current. For larger trains, these oscillations lose
synchrony, producing segmented, worm like motion. The center of mass speed
grows with current but decreases as the number of bimerons increases. Notably,
eight bimerons cannot be sustained in a smooth stripe but can be stabilized by
the periodic defects

</details>


### [552] [Enhanced Terahertz Thermoelectricity via Engineered van Hove Singularities and Nernst Effect in Moiré Superlattices](https://arxiv.org/abs/2509.02548)
*L. Elesin,A. L. Shilov,S. Jana,I. Mazurenko,P. A. Pantaleon,M. Kashchenko,N. Krivovichev,V. Dremov,I. Gayduchenko,G. Goltsman,T. Taniguchi,K. Watanabe,Y. Wang,E. I. Titova,D. A. Svintsov,K. S. Novoselov,D. A. Bandurin*

Main category: cond-mat.mes-hall

TL;DR: 二维材料的Moiré超晶格结构能够有效提高THz光电响应的灵敏度，尤其是在费米能级调谐至能带奇点时。结合磁场可以进一步增强响应。这为高性能THz光电器件的开发提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统热电材料在THz频率范围内的灵敏度不足的问题，并探索新的THz探测方法。

Method: 通过Moiré带工程，利用2D Moiré结构（如石墨烯超晶格）作为模型系统，调谐费米能级至能带奇点，并施加磁场以增强THz光热电响应和THz驱动的Nernst效应。

Result: 在单层和双层石墨烯超晶格中，当费米能级调谐至能带奇点时，观察到THz光热电响应的显著增强。施加磁场可以进一步提升响应。

Conclusion: Moiré超晶格为THz热电学提供了一个多功能的平台，并通过工程化能带结构为高性能THz光电器件指明了方向。

Abstract: Thermoelectric materials, long explored for energy harvesting and thermal
sensing, convert heat directly into electrical signals. Extending their
application to the terahertz (THz) frequency range opens opportunities for
low-noise, bias-free THz detection, yet conventional thermoelectrics lack the
sensitivity required for practical devices. Thermoelectric coefficients can be
strongly enhanced near van Hove singularities (VHS), though these are usually
difficult to access in conventional materials. Here we show that moir\'e band
engineering unlocks these singularities for THz optoelectronics. Using 2D
moir\'e structures as a model system, we observe strong enhancement of the THz
photothermoelectric response in monolayer and bilayer graphene superlattices
when the Fermi level is tuned to band singularities. Applying a relatively
small magnetic field further boosts the response through the THz-driven Nernst
effect, a transverse thermoelectric current driven by the THz-induced
temperature gradient. Our results establish moir\'e superlattices as a
versatile platform for THz thermoelectricity and highlight engineered band
structures as a route to high-performance THz optoelectronic devices.

</details>


### [553] [Interaction-limited conductivity of twisted bilayer graphene revealed by giant terahertz photoresistance](https://arxiv.org/abs/2509.02552)
*A. L. Shilov,M. Kravtsov,J. Covey,M. A. Kashchenko,O. Popova,X. Zhou,I. Yahniuk,T. Taniguchi,K. Watanabe,A. I. Berdyugin,Y. Wang,S. D. Ganichev,V. Perebeinos,D. A. Svintsov,A. Principi,K. S. Novoselov,D. L. Maslov,D. A. Bandurin*

Main category: cond-mat.mes-hall

TL;DR: 该研究利用太赫兹(THz)激发选择性地提高扭曲双层石墨烯(TBG)中的电子温度，同时保持晶格低温，从而将电阻率的电子-电子和电子-声子贡献分开。结果表明，电子相互作用在TBG的输运中起主导作用，甚至在以前认为由声子引起的情况下也是如此。该研究还提出了在非魔角情况下，由于谷间电子-电子碰撞导致的有翼不变性破缺可能是相互作用限制电导率的起源。最后，该研究提出THz驱动的热电子输运作为一种通用的方法，用于区分低密度量子材料中的散射机制。


<details>
  <summary>Details</summary>
Motivation: 为了理解量子材料中的关联态和量子临界态，识别限制导电性的微观过程至关重要。在扭曲双层石墨烯(TBG)和其他扭曲控制材料中，金属电阻率的温度依赖性遵循幂律标度，其指数跨度很广，这使得标准的输运测量不足以明确识别主要的散射过程，并导致了从声子限制输运和Umklapp散射到奇异金属和重费米子重整化等相互竞争的解释。

Method: 利用太赫兹(THz)激发选择性地提高扭曲双层石墨烯(TBG)中的电子温度，同时保持晶格低温，从而直接分离电阻率的电子-电子和电子-声子贡献。

Result: 在魔角器件中观察到高达70%的巨大太赫兹光致电阻，表明电子相互作用在输运中占主导地位，即使在先前归因于声子的区域也是如此，包括魔角附近的线性温度依赖电阻率。在非魔角区域，在载流子密度极低的情况下，观察到光致电阻和鲁棒的二次温度依赖电阻率共存，而此时标准的电子-电子散射机制（Umklapp和Baber带间散射）在运动学上是被禁止的。分析表明，狄拉克型色散中对伽利略不变性的破坏可能是相互作用限制电导率的来源，这源于谷间电子-电子碰撞。

Conclusion: 在扭曲双层石墨烯(TBG)中，电子相互作用在输运中起着主导作用，即使在以前认为由声子引起的情况下也是如此。该研究提出了一种利用THz驱动的热电子输运来区分低密度量子材料中散射机制的通用框架。

Abstract: Identifying the microscopic processes that limit conductivity is essential
for understanding correlated and quantum-critical states in quantum materials.
In twisted bilayer graphene (TBG) and other twist-controlled materials, the
temperature dependence of metallic resistivity follows power-law scaling, with
the exponent spanning a broad range, rendering standard transport measurements
insufficient to unambiguously identify the dominant scattering processes and
giving rise to competing interpretations ranging from phonon-limited transport
and umklapp scattering to strange metallicity and heavy fermion
renormalization. Here, we use terahertz (THz) excitation to selectively raise
the electron temperature in TBG while keeping the lattice cold, enabling a
direct separation of electron-electron and electron-phonon contributions to
resistivity. We observe a giant THz photoresistance, reaching up to 70% in
magic-angle devices, demonstrating that electronic interactions dominate
transport even in regimes previously attributed to phonons, including the
linear-in-temperature resistivity near the magic angle. Away from the magic
angle, we observe coexisting photoresistance and robust
quadratic-in-temperature resistivity at extremely low carrier densities where
standard electron-electron scattering mechanisms (umklapp and Baber inter-band
scattering) are kinematically forbidden. Our analysis identifies the breakdown
of Galilean invariance in the Dirac-type dispersion as a possible origin of the
interaction-limited conductivity, arising from inter-valley electron-electron
collisions. Beyond twisted bilayer graphene, our approach establishes
THz-driven hot-electron transport as a general framework for disentangling
scattering mechanisms in low-density quantum materials.

</details>


### [554] [Floquet multiple exceptional points with higher-order skin effect](https://arxiv.org/abs/2509.02556)
*Gaurab Kumar Dash,Subhendu Kumar Patra,Diptiman Sen,Manisha Thakurathi*

Main category: cond-mat.mes-hall

TL;DR: 本研究探索了微腔谐振器中周期驱动的开放量子系统的非平衡物理现象，这些系统由包含非厄米哈密顿量的Floquet奇点（FEPs）控制。通过引入周期性淬灭驱动协议，我们推导了Floquet有效哈密顿量，并确定了多个FEPs在Floquet体带中的位置。我们证明了这些FEPs的产生和湮灭可以被精确控制，并且零和$	au$ FEPs由鲁棒的整数量子化缠绕数拓扑表征。为了探测这些奇点，我们引入了一种双正交Floquet保真度易感性，其值在布里渊区的主持FEPs的动量点处表现出大的非零峰值。此外，动量求和的易感性在FEPs数量随驱动周期变化时显示出急剧的发散。我们的研究还揭示了零能量周围的Floquet边缘态和$	au$能量周围的狄拉克类色散。此外，我们的模型揭示了一种更高阶的皮肤效应，其中周期驱动的哈密顿量在边缘和角落都存在皮肤模式。这些发现为工程化拓扑奇点在驱动耗散系统中的Floquet工程提供了新的途径，并在微尺度上操纵光和物质方面具有巨大潜力。


<details>
  <summary>Details</summary>
Motivation: 研究周期驱动开放量子系统（特别是在微腔谐振器中）的丰富非平衡物理性质，重点关注包含Floquet奇点（FEPs）的非厄米哈密顿量。

Method: 通过引入周期性淬灭驱动协议，解析推导出Floquet有效哈密顿量，确定FEPs的位置，并引入双正交Floquet保真度易感性来探测奇点。

Result: 发现了FEPs的产生和湮灭可以通过调控系统参数来精确控制；零和$	au$ FEPs具有拓扑特性；双正交Floquet保真度易感性在FEPs位置出现峰值，并随FEPs数量变化而发散；观察到Floquet边缘态和狄拉克类色散；揭示了更高阶的皮肤效应，即存在于边缘和角落的皮肤模式。

Conclusion: 该研究为在驱动耗散系统中利用Floquet工程来设计拓扑奇点提供了新的途径，并在微尺度上操纵光和物质方面具有重要应用潜力。

Abstract: We investigate the rich non-equilibrium physics arising in periodically
driven open quantum systems, specifically those realized within microcavity
resonators, whose dynamics are governed by a non-Hermitian Hamiltonian hosting
Floquet Exceptional Points (FEPs). By introducing a periodically quenched
driving protocol, we analytically derive the Floquet effective Hamiltonian and
determine the locations of multiple FEPs harbored within the Floquet bulk
bands. We demonstrate that the pair-production and annihilation of these FEPs
can be precisely controlled by fine-tuning the system parameters, and zero and
$\pi$ FEPs are topologically characterized by robust integer quantized winding
numbers. To probe these singularities, we introduce a bi-orthogonal Floquet
fidelity susceptibility, whose value exhibits large non-zero peaks at the
momentum points hosting FEPs in the Brillouin zone. Furthermore, the
momentum-summed susceptibility displays a sharp divergence when the number of
FEPs change with respect to the time period of the drive. Our findings also
reveal the emergence of Floquet edge states around zero energy and Dirac-like
dispersion around $\pi$. Moreover, our model reveals a higher-order skin
effect, where the periodically driven Hamiltonian hosts skin modes localized at
both edges and corners. These insights offer novel avenues for the Floquet
engineering of topological singularities in driven dissipative systems, with
significant potential for manipulating light and matter at the microscale.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [555] [KVComp: A High-Performance, LLM-Aware, Lossy Compression Framework for KV Cache](https://arxiv.org/abs/2509.00579)
*Bo Jiang,Taolue Yang,Youyuan Liu,Chengming Zhang,Xubin He,Sian Jin*

Main category: cs.DC

TL;DR: KVComp是一个为长文本生成优化的KV缓存管理框架，通过创新的有损压缩技术，在内存占用和计算效率方面取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: 长文本生成对Transformer-LLM模型提出了挑战，主要是因为KV缓存的内存需求巨大，尤其是在序列长度和批处理大小增加时。

Method: KVComp框架采用专门针对KV缓存数据特性设计的有损压缩技术，并与系统架构进行协同设计，实现了压缩算法和系统的高效结合。该方法兼容KV缓存的增长特性，并保持了高计算效率。

Result: 实验结果表明，KVComp的内存约减率比现有方法平均高47%，最高可达83%，同时模型准确率几乎没有下降。此外，KVComp的执行吞吐量极高，有效降低了解压缩开销，并在某些情况下通过减少数据移动实现了比cuBLAS注意力核更快的矩阵向量乘法。

Conclusion: KVComp通过创新的有损压缩技术和系统架构协同设计，有效解决了长文本生成中KV缓存的内存占用问题，并在保持高计算效率的同时，实现了显著的内存节省和性能提升。

Abstract: Transformer-based large language models (LLMs) demonstrate impressive
potential in various practical applications. However, long context inference
poses a significant challenge due to the enormous memory requirements of the
key-value (KV) cache, which can scale to multiple gigabytes as sequence length
and batch size increase. In this paper, we present KVComp, a generic and
efficient KV cache management framework optimized for long-text generation that
synergistically works with both latency-critical and throughput-critical
inference systems. KVComp employs novel lossy compression techniques
specifically designed for KV cache data characteristics, featuring careful
co-design of compression algorithms and system architecture. Our approach
maintains compatibility with the growing nature of KV cache while preserving
high computational efficiency. Experimental results show that KVComp achieves
on average 47\% and up to 83\% higher memory reduction rate compared to
existing methods with little/no model accuracy degradation. Furthermore, KVComp
achieves extremely high execution throughput, effectively reducing
decompression overhead and, in some cases, even accelerating the matrix-vector
multiplication operation and outperform cuBLAS-based attention kernels with
less data movement.

</details>


### [556] [HADIS: Hybrid Adaptive Diffusion Model Serving for Efficient Text-to-Image Generation](https://arxiv.org/abs/2509.00642)
*Qizheng Yang,Tung-I Chen,Siyu Zhao,Ramesh K. Sitaraman,Hui Guan*

Main category: cs.DC

TL;DR: HADIS是一个混合自适应扩散模型服务系统，通过优化级联模型选择、查询路由和资源分配来降低文本到图像扩散模型的计算成本，提高了响应质量并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型虽然视觉质量高，但计算成本高，难以实现实时、可扩展的部署。现有的查询感知服务系统通过级联轻量级和重量级模型来降低成本，但大多数依赖固定的级联配置，并将所有提示都通过初始轻量级阶段进行路由，浪费资源处理复杂查询。

Method: HADIS采用基于规则的提示路由器，将明显困难的查询直接发送到重量级模型，绕过轻量级阶段的开销。为了降低资源管理的复杂性，HADIS使用离线分析阶段来生成帕累托最优级联配置表。在运行时，HADIS根据延迟和工作负载约束选择最佳的级联配置和GPU分配。

Result: 在真实世界痕迹上的经验评估表明，与最先进的模型服务系统相比，HADIS将响应质量提高了35%，并将延迟违反率降低了2.7-45倍。

Conclusion: HADIS通过其混合自适应方法，在提高扩散模型服务的效率和质量方面取得了显著成果。

Abstract: Text-to-image diffusion models have achieved remarkable visual quality but
incur high computational costs, making real-time, scalable deployment
challenging. Existing query-aware serving systems mitigate the cost by
cascading lightweight and heavyweight models, but most rely on a fixed cascade
configuration and route all prompts through an initial lightweight stage,
wasting resources on complex queries. We present HADIS, a hybrid adaptive
diffusion model serving system that jointly optimizes cascade model selection,
query routing, and resource allocation. HADIS employs a rule-based prompt
router to send clearly hard queries directly to heavyweight models, bypassing
the overhead of the lightweight stage. To reduce the complexity of resource
management, HADIS uses an offline profiling phase to produce a Pareto-optimal
cascade configuration table. At runtime, HADIS selects the best cascade
configuration and GPU allocation given latency and workload constraints.
Empirical evaluations on real-world traces demonstrate that HADIS improves
response quality by up to 35% while reducing latency violation rates by
2.7-45$\times$ compared to state-of-the-art model serving systems.

</details>


### [557] [Accelerating Latency-Critical Applications with AI-Powered Semi-Automatic Fine-Grained Parallelization on SMT Processors](https://arxiv.org/abs/2509.00883)
*Denis Los,Igor Petushkov*

Main category: cs.DC

TL;DR: 该论文研究如何利用同步多线程（SMT）技术来支持延迟敏感型应用程序的细粒度并行化，并提出了一个名为Aira的AI驱动的并行化顾问。


<details>
  <summary>Details</summary>
Motivation: 高并发处理器中的延迟敏感型应用程序由于缓存未命中和预测错误，功能单元利用率低。虽然同步多线程（SMT）技术对单线程性能有显著影响，但很少用于延迟敏感型应用程序。本研究旨在利用SMT技术支持延迟敏感型应用程序的细粒度并行化。

Method: 研究人员开发了一个名为Aira的AI驱动的并行化顾问，该顾问通过集成AI编码代理、LLM引导的热点检测、动态二进制检测、动态依赖收集以及SMT感知性能模拟等工具，实现了端到端的并行化。Aira与Relic并行框架结合，用于在SMT核心上对延迟敏感型应用程序进行细粒度任务并行化。

Result: 将Aira与Relic并行框架应用于延迟敏感型基准测试，实现了17%的几何平均性能提升。

Conclusion: 研究表明，通过Aira和Relic框架，可以有效地利用SMT技术对延迟敏感型应用程序进行细粒度并行化，从而获得显著的性能提升。

Abstract: Latency-critical applications tend to show low utilization of functional
units due to frequent cache misses and mispredictions during speculative
execution in high-performance superscalar processors. However, due to
significant impact on single-thread performance, Simultaneous Multithreading
(SMT) technology is rarely used with heavy threads of latency-critical
applications. In this paper, we explore utilization of SMT technology to
support fine-grained parallelization of latency-critical applications.
Following the advancements in the development of Large Language Models (LLMs),
we introduce Aira, an AI-powered Parallelization Adviser. To implement Aira, we
extend AI Coding Agent in Cursor IDE with additional tools connected through
Model Context Protocol, enabling end-to-end AI Agent for parallelization.
Additional connected tools enable LLM-guided hotspot detection, collection of
dynamic dependencies with Dynamic Binary Instrumentation, SMT-aware performance
simulation to estimate performance gains. We apply Aira with Relic parallel
framework for fine-grained task parallelism on SMT cores to parallelize
latency-critical benchmarks representing real-world applications used in
industry. We show 17% geomean performance gain from parallelization of
latency-critical benchmarks using Aira with Relic framework.

</details>


### [558] [Parallelizing Drug Discovery: HPC Pipelines for Alzheimer's Molecular Docking and Simulation](https://arxiv.org/abs/2509.00937)
*Paul Ruiz Alliata,Diana Rubaga,Daniel Kumlin,Alberto Puliga*

Main category: cs.DC

TL;DR: HPC正在加速阿尔茨海默病药物发现，通过大规模、高效率的分子模拟，包括虚拟筛选、分子对接和分子动力学模拟。研究人员使用GROMACS（MPI-OpenMP）和Python的多进程库实现了并行工作流，并以亲阿myloid-beta和tau蛋白的脯氨酰胺衍生物和黄芩素为例进行了案例研究，展示了HPC的加速潜力，尽管在数据管理、计算成本和扩展效率方面仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: HPC正在通过实现大规模、高效率的分子模拟来重塑计算药物发现，特别是在阿尔茨海默病药物发现领域。

Method: 开发了使用GROMACS（混合MPI-OpenMP策略）的并行工作流，并对能量最小化、平衡和生产阶段进行了基准测试。同时，开发了一个对接原型，展示了从顺序执行到基于进程的并行处理的运行时性能提升。

Result: 对亲阿myloid-beta和tau蛋白的脯氨酰胺衍生物和黄芩素进行了案例研究，突出了这些工作流的生物学相关性。在从顺序执行到基于进程的并行处理的对接原型中，观察到了显著的运行时性能提升。

Conclusion: HPC有潜力加速神经退行性疾病的药物发现，尽管在数据管理、计算成本和扩展效率方面仍存在局限性。

Abstract: High-performance computing (HPC) is reshaping computational drug discovery by
enabling large-scale, time-efficient molecular simulations. In this work, we
explore HPC-driven pipelines for Alzheimer's disease drug discovery, focusing
on virtual screening, molecular docking, and molecular dynamics simulations. We
implemented a parallelised workflow using GROMACS with hybrid MPI-OpenMP
strategies, benchmarking scaling performance across energy minimisation,
equilibration, and production stages. Additionally, we developed a docking
prototype that demonstrates significant runtime gains when moving from
sequential execution to process-based parallelism using Python's
multiprocessing library. Case studies on prolinamide derivatives and baicalein
highlight the biological relevance of these workflows in targeting amyloid-beta
and tau proteins. While limitations remain in data management, computational
costs, and scaling efficiency, our results underline the potential of HPC to
accelerate neurodegenerative drug discovery.

</details>


### [559] [DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving](https://arxiv.org/abs/2509.01083)
*Mingyu Yang,Jae-Young Choi,Kihyo Moon,Minsung Jang,Eunjoo Joen*

Main category: cs.DC

TL;DR: Speculative decoding for LLMs can be improved with dynamic adaptation using post-hoc signals like KLD variance to manage diverse requests and mitigate the straggler problem, leading to competitive latency and enhanced robustness.


<details>
  <summary>Details</summary>
Motivation: The reliance of speculative decoding on a fixed speculation length is suboptimal for large-batch serving environments with diverse requests, necessitating a more dynamic approach.

Method: The paper proposes Dynamic Speculative Decoding Engine (DSDE), a training-free framework using a predictive signal based on Kullback-Leibler (KLD) divergence variance to diagnose generation stability and an adaptive speculation length cap to address the straggler problem.

Result: Experiments show that KLD-based stability signals can be used for dynamic adaptation. The DSDE algorithm achieves competitive end-to-end latency compared to existing baselines and demonstrates superior robustness across various workloads, even in low-acceptance-rate scenarios.

Conclusion: Post-hoc signals, such as the proposed KLD-based diagnostic signal, are valuable for developing more robust and intelligent LLM inference systems, and offer a promising avenue for future research in dynamic speculation length adaptation.

Abstract: Speculative decoding accelerates large language model inference, but its
reliance on a fixed speculation length is suboptimal in large-batch serving
environments with diverse requests. This paper explores a new direction for
dynamic adaptation by investigating a novel class of post-hoc, diagnostic
signals. We propose Dynamic Speculative Decoding Engine (DSDE), a training-free
framework built on two primary components: (1) a predictive signal based on the
variance of the Kullback-Leibler (KLD) divergence, which diagnoses the
generation's regional stability, and (2) an adaptive speculation length cap to
mitigate the straggler problem in per-sequence decoding. Experiments
demonstrate the potential of using KLD-based stability signals for dynamic
adaptation. An algorithm guided by these signals achieves end-to-end latency
competitive with leading baselines and exhibits superior robustness across
diverse workloads. This robustness is particularly valuable in challenging
low-acceptance-rate regimes, where the proposed signal maintains its diagnostic
utility. Collectively, these findings validate post-hoc signals as a valuable
component for building more robust and intelligent LLM inference systems, and
highlight a promising direction for future research on dynamic speculation
length adaptation.

</details>


### [560] [Ocior: Ultra-Fast Asynchronous Leaderless Consensus with Two-Round Finality, Linear Overhead, and Adaptive Security](https://arxiv.org/abs/2509.01118)
*Jinyuan Chen*

Main category: cs.DC

TL;DR: Ocior是一种新的异步拜占庭容错（BFT）共识协议，在弹性、通信、计算和轮次复杂性方面均达到最优。它通过并行共识实例单独处理交易，是无领导者的，并保证稳定活性。其关键创新是名为OciorBLSts的新型非交互式阈值签名（TS）方案，支持快速、自适应安全的签名聚合和瞬时TS聚合。


<details>
  <summary>Details</summary>
Motivation: 提出一种在弹性、通信、计算和轮次复杂性方面均达到最优的实际异步拜占庭容错（BFT）共识协议。

Method: Ocior协议通过并行共识实例来单独和并发地处理传入的交易，是一种无领导者共识协议。引入了名为OciorBLSts的新型非交互式阈值签名（TS）方案，该方案具有快速签名聚合和瞬时TS聚合的特性。

Result: Ocior实现了最优弹性（容忍高达t个故障节点，n>=3t+1）、最优通信复杂度（每笔交易O(n)）、最优或接近最优的计算复杂度（每笔交易O(n)或O(n log^2 n)）以及最优轮次复杂度（在好情况下，两方交易可在两个异步轮次内完成）。OciorBLSts的签名聚合计算成本在好情况下为O(n)。

Conclusion: Ocior协议通过其新颖的设计和OciorBLSts阈值签名方案，在保持高弹性的同时，实现了在多个关键指标上的最优性能，特别是在处理交易的效率方面有了显著提升。

Abstract: In this work, we propose Ocior, a practical asynchronous Byzantine
fault-tolerant (BFT) consensus protocol that achieves the optimal performance
in resilience, communication, computation, and round complexity. Unlike
traditional BFT consensus protocols, Ocior processes incoming transactions
individually and concurrently using parallel instances of consensus. While
leader-based consensus protocols rely on a designated leader to propose
transactions, Ocior is a leaderless consensus protocol that guarantees stable
liveness. Ocior achieves: 1) Optimal resilience: Ocior tolerates up to $t$
faulty nodes controlled by an adaptive adversary, for $n\geq 3t+1$. 2) Optimal
communication complexity: The total expected communication per transaction is
$O(n)$. 3) Optimal (or near-optimal) computation complexity: The total
computation per transaction is $O(n)$ in the best case, or $O(n \log^2 n)$ in
the worst case. 4) Optimal round complexity: A legitimate two-party transaction
can be finalized with a good-case latency of two asynchronous rounds, for any
$n\geq 3t+1$. The good case in terms of latency refers to the scenario where
the transaction is proposed by any (not necessarily designated) honest node. A
two-party transaction involves the transfer of digital assets from one user (or
group of users) to one or more recipients. To support efficient consensus, we
introduce a novel non-interactive threshold signature (TS) scheme called
OciorBLSts. It offers fast signature aggregation, and is adaptively secure.
OciorBLSts achieves a signature aggregation computation cost of only $O(n)$ for
the best case. Moreover, OciorBLSts supports the property of Instantaneous TS
Aggregation. This enables real-time aggregation of partial signatures as they
arrive, reducing waiting time and improving responsiveness.

</details>


### [561] [Energy-Efficient Split Learning for Resource-Constrained Environments: A Smart Farming Solution](https://arxiv.org/abs/2509.02549)
*Keiwan Soltani,Vishesh Kumar Tanwar,Ashish Gupta,Sajal K. Das*

Main category: cs.DC

TL;DR: eEnergy-Split是一个利用联邦学习（SL）的能源高效框架，用于智能农业。通过在边缘设备和中央服务器之间分配模型，eEnergy-Split可将设备的能源使用量最多减少86%，同时保护数据隐私。它还能提高分类准确性，并提出了一种最优边缘部署算法和无人机轨迹规划策略，以最小化飞行成本并最大化通信回合。该框架在农业害虫数据集上的评估显示，与基线方法相比，eEnergy-Split可降低无人机能耗，并将整体精度提高多达17%。SL的能源效率取决于模型，在MobileNet等轻量级模型中节省效果显著，但在更深的网络中，通信和内存开销可能会降低效率增益。


<details>
  <summary>Details</summary>
Motivation: 解决智能农业系统中存在的资源有限、数据隐私需求和农村地区连接性差的挑战。

Method: 提出eEnergy-Split框架，利用拆分学习（SL）实现协作模型训练，将模型分布在边缘设备和中央服务器之间，并提出最优边缘部署算法和解决旅行商问题（TSP）的无人机轨迹规划策略。

Result: 与联邦学习（FL）相比，eEnergy-Split将设备的能源使用量最多减少86%，并将ResNet-18的分类准确性提高了6.2%。在农业害虫数据集上的评估显示，eEnergy-Split降低了无人机的能耗，并将整体精度提高了多达17%。SL的能源效率取决于模型，在MobileNet等轻量级模型中节省效果显著，但在更深的网络中，通信和内存开销可能会降低效率增益。

Conclusion: eEnergy-Split结合SL和节能设计，为资源受限的智能农业环境提供了一种可扩展、注重隐私的解决方案。

Abstract: Smart farming systems encounter significant challenges, including limited
resources, the need for data privacy, and poor connectivity in rural areas. To
address these issues, we present eEnergy-Split, an energy-efficient framework
that utilizes split learning (SL) to enable collaborative model training
without direct data sharing or heavy computation on edge devices. By
distributing the model between edge devices and a central server, eEnergy-Split
reduces on-device energy usage by up to 86 percent compared to federated
learning (FL) while safeguarding data privacy. Moreover, SL improves
classification accuracy by up to 6.2 percent over FL on ResNet-18 and by more
modest amounts on GoogleNet and MobileNetV2. We propose an optimal edge
deployment algorithm and a UAV trajectory planning strategy that solves the
Traveling Salesman Problem (TSP) exactly to minimize flight cost and extend and
maximize communication rounds. Comprehensive evaluations on agricultural pest
datasets reveal that eEnergy-Split lowers UAV energy consumption compared to
baseline methods and boosts overall accuracy by up to 17 percent. Notably, the
energy efficiency of SL is shown to be model-dependent-yielding substantial
savings in lightweight models like MobileNet, while communication and memory
overheads may reduce efficiency gains in deeper networks. These results
highlight the potential of combining SL with energy-aware design to deliver a
scalable, privacy-preserving solution for resource-constrained smart farming
environments.

</details>


### [562] [Detecting Rug Pulls in Decentralized Exchanges: Machine Learning Evidence from the TON Blockchain](https://arxiv.org/abs/2509.01168)
*Dmitry Yaremus,Jianghai Li,Alisa Kalacheva,Igor Vodolazov,Yury Yanovich*

Main category: cs.DC

TL;DR: 本研究提出了一个在The Open Network（TON）区块链的去中心化交易所（DEX）上进行拉黑骗局早期检测的机器学习框架。研究了Ston.Fi和DeDust两个DEX，并结合了基于总价值锁定（TVL）和基于闲置（idle-based）的两种拉黑骗局定义。结果表明，梯度提升模型能在交易开始的五分钟内有效识别拉黑骗局，其中TVL方法在AUC方面表现更优（高达0.891），而闲置方法在召回率方面表现更好。研究还发现，尽管特征集在不同交易所之间保持一致，但其底层分布存在显著差异，这给数据融合带来挑战，并强调了开发健壮的、平台感知的模型的重要性。


<details>
  <summary>Details</summary>
Motivation: TON区块链的独特异步执行和Telegram庞大的Web2用户基础，为欺诈分析提供了一个新颖且关键的环境。本研究旨在为TON DeFi生态系统提供一个关键的早期预警机制，以增强投资者安全。

Method: 本研究提出了一个机器学习框架，用于在TON区块链的DEX上进行拉黑骗局的早期检测。研究人员对Ston.Fi和DeDust这两个DEX进行了全面的研究，并融合了两个平台的数据来训练模型。该研究实现了两种不同的拉黑骗局定义（基于TVL的定义和基于闲置的定义）的实施和比较分析。研究人员使用了梯度提升模型，并评估了其在早期识别拉黑骗局的有效性。

Result: 梯度提升模型能够有效地在交易开始后的五分钟内识别出拉黑骗局。基于TVL的定义方法在AUC方面表现更优，最高可达0.891，而基于闲置的定义方法在召回率方面表现更佳。研究还发现，尽管特征集在不同交易所之间保持一致，但其底层分布存在显著差异，这给数据融合带来了挑战。

Conclusion: 本研究提出的机器学习框架能够有效地检测TON区块链DEX上的拉黑骗局，为投资者提供了重要的早期预警机制，并有助于提升TON DeFi生态系统的安全性。研究结果强调了开发平台感知模型的重要性，以应对不同交易所数据分布的差异。

Abstract: This paper presents a machine learning framework for the early detection of
rug pull scams on decentralized exchanges (DEXs) within The Open Network (TON)
blockchain. TON's unique architecture, characterized by asynchronous execution
and a massive web2 user base from Telegram, presents a novel and critical
environment for fraud analysis. We conduct a comprehensive study on the two
largest TON DEXs, Ston.Fi and DeDust, fusing data from both platforms to train
our models. A key contribution is the implementation and comparative analysis
of two distinct rug pull definitions--TVL-based (a catastrophic liquidity
withdrawal) and idle-based (a sudden cessation of all trading activity)--within
a single, unified study. We demonstrate that Gradient Boosting models can
effectively identify rug pulls within the first five minutes of trading, with
the TVL-based method achieving superior AUC (up to 0.891) while the idle-based
method excels at recall. Our analysis reveals that while feature sets are
consistent across exchanges, their underlying distributions differ
significantly, challenging straightforward data fusion and highlighting the
need for robust, platform-aware models. This work provides a crucial
early-warning mechanism for investors and enhances the security infrastructure
of the rapidly growing TON DeFi ecosystem.

</details>


### [563] [LobRA: Multi-tenant Fine-tuning over Heterogeneous Data](https://arxiv.org/abs/2509.01193)
*Sheng Lin,Fangcheng Fu,Haoyang Li,Hao Ge,Xuanyu Wang,Jiawen Niu,Yaofeng Tu,Bin Cui*

Main category: cs.DC

TL;DR: LoRA是一种常用的模型微调技术，但其效率受到序列长度变化和数据倾斜的异质性问题影响。LobRA框架通过部署具有异构资源利用率和并行配置的微调副本，并根据序列长度倾斜调度训练数据，有效解决了这些问题，将联合微调的GPU秒数减少了45.03%-60.67%。


<details>
  <summary>Details</summary>
Motivation: 随着Transformer预训练模型的突破，服务提供商需要降低微调（FT）下游应用的成本。LoRA是一种有效的微调技术，但其在联合训练多个LoRA适配器时会受到序列长度变化和数据倾斜的异质性问题的影响。

Method: LobRA框架通过两种创新设计来解决LoRA联合微调中的异质性问题：1. 部署具有异构资源利用率和并行配置的微调副本，以匹配由序列长度变化引起的异构工作负载。2. 在每个训练步骤中，考虑序列长度倾斜，并在异构微调副本之间调度训练数据以实现工作负载平衡。

Result: 实验结果表明，LobRA显著减少了联合微调所需的GPU秒数，减少幅度为45.03%-60.67%。

Conclusion: LobRA框架通过有效的资源管理和数据调度策略，成功克服了LoRA联合微调中的异质性问题，显著提高了效率并降低了成本。

Abstract: With the breakthrough of Transformer-based pre-trained models, the demand for
fine-tuning (FT) to adapt the base pre-trained models to downstream
applications continues to grow, so it is essential for service providers to
reduce the cost of processing FT requests. Low-rank adaption (LoRA) is a widely
used FT technique that only trains small-scale adapters and keeps the base
model unaltered, conveying the possibility of processing multiple FT tasks by
jointly training different LoRA adapters with a shared base model.
  Nevertheless, through in-depth analysis, we reveal the efficiency of joint FT
is dampened by two heterogeneity issues in the training data -- the sequence
length variation and skewness. To tackle these issues, we develop LobRA, a
brand new framework that supports processing multiple FT tasks by jointly
training LoRA adapters. Two innovative designs are introduced. Firstly, LobRA
deploys the FT replicas (i.e., model replicas for FT) with heterogeneous
resource usages and parallel configurations, matching the diverse workloads
caused by the sequence length variation. Secondly, for each training step,
LobRA takes account of the sequence length skewness and dispatches the training
data among the heterogeneous FT replicas to achieve workload balance. We
conduct experiments to assess the performance of LobRA, validating that it
significantly reduces the GPU seconds required for joint FT by 45.03%-60.67%.

</details>


### [564] [LiquidGEMM: Hardware-Efficient W4A8 GEMM Kernel for High-Performance LLM Serving](https://arxiv.org/abs/2509.01229)
*Huanqi Hu,Bowen Xiao,Shixuan Sun,Jianian Yin,Zhexi Zhang,Xiang Luo,Chengquan Jiang,Weiqi Xu,Xiaoying Jia,Xin Liu,Minyi Guo*

Main category: cs.DC

TL;DR: LiquidGEMM是一种高效的W4A8 GEMM内核，通过改进的量化和流水线技术，显著提高了LLM推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有W4A8 GEMM内核在CUDA核心上的反量化效率低下，无法跟上Tensor核心的高吞吐量。

Method: LiquidGEMM采用LiquidQuant技术，实现每四个元素仅需两次算术指令即可快速、安全地反量化；并设计了隐式细粒度流水线，在warp组间完全重叠权重加载、反量化和MMA操作，无需软件同步或冗余内存传输。

Result: LiquidGEMM相比最先进的W4A8内核速度提升高达2.90倍，系统级端到端速度提升高达4.94倍。与NVIDIA TensorRT-LLM中的量化GEMM内核相比，性能提升1.12-1.63倍，系统级速度提升高达1.63倍。

Conclusion: LiquidGEMM通过其创新的量化和流水线设计，有效解决了现有W4A8 GEMM内核的瓶颈，为LLM服务提供了更高效的解决方案。

Abstract: Quantization is a critical technique for accelerating LLM inference by
reducing memory footprint and improving computational efficiency. Among various
schemes, 4-bit weight and 8-bit activation quantization (W4A8) offers a strong
balance between accuracy and performance. However, existing W4A8 GEMM kernels
fall short in practice due to inefficient dequantization on CUDA Cores, which
cannot keep pace with the high throughput of Tensor Cores. In this paper, we
present LiquidGEMM, a hardware-efficient W4A8 GEMM kernel for efficient LLM
serving. LiquidGEMM designs two key techniques: LiquidQuant, a
hardware-efficient quantization method that enables fast, overflow-safe
dequantization using just two arithmetic instructions per four elements; and an
implicit fine-grained pipeline that fully overlaps weight loading,
dequantization, and MMA across warp groups without software synchronization or
redundant memory traffic. Experimental results show that LiquidGEMM achieves up
to 2.90x speedup over state-of-the-art W4A8 kernels and up to 4.94x end-to-end
system-level speedup. Compared to various quantized GEMM kernels in NVIDIA
TensorRT-LLM, LiquidGEMM delivers 1.12-1.63x performance gains, and achieves up
to 1.63x system-level speedup.

</details>


### [565] [HiCR, an Abstract Model for Distributed Heterogeneous Programming](https://arxiv.org/abs/2509.01425)
*Sergio Miguel Martin,Luca Terracciano,Kiril Dichev,Noah Baumann,Jiashu Lin,Albert-Jan Yzelman*

Main category: cs.DC

TL;DR: HiCR是一个用于表示分布式异构应用程序和运行时系统的模型，它提供了一组抽象操作，支持硬件拓扑发现、内核执行、内存管理、通信和实例管理，无需规定任何实现细节，旨在实现跨平台执行和支持多种并行编程范式。


<details>
  <summary>Details</summary>
Motivation: 该模型的目的是在当前和未来的系统上实现执行，而无需进行重大的重构，同时也能服务于任何治理的并行编程范式。

Method: HiCR模型通过基于插件的方法实现，该方法负责处理特定于设备的实现细节，并展示了可在多样化平台上运行的基于HiCR的应用程序示例。

Result: HiCR模型描述了一组最小的抽象操作，用于启用硬件拓扑发现、内核执行、内存管理、通信和实例管理。

Conclusion: HiCR模型位于分布式异构系统和运行时系统之间，充当运行时支持层，通过插件化方法处理设备特定的实现细节，并可在多样化平台上运行。

Abstract: We present HiCR, a model to represent the semantics of distributed
heterogeneous applications and runtime systems. The model describes a minimal
set of abstract operations to enable hardware topology discovery, kernel
execution, memory management, communication, and instance management, without
prescribing any implementation decisions. The goal of the model is to enable
execution in current and future systems without the need for significant
refactoring, while also being able to serve any governing parallel programming
paradigm. In terms of software abstraction, HiCR is naturally located between
distributed heterogeneous systems and runtime systems. We coin the phrase
\emph{Runtime Support Layer} for this level of abstraction. We explain how the
model's components and operations are realized by a plugin-based approach that
takes care of device-specific implementation details, and present examples of
HiCR-based applications that operate equally on a diversity of platforms.

</details>


### [566] [STZ: A High Quality and High Speed Streaming Lossy Compression Framework for Scientific Data](https://arxiv.org/abs/2509.01626)
*Daoce Wang,Pascal Grosset,Jesus Pulido,Jiannan Tian,Tushar M. Athawale,Jinda Jia,Baixi Sun,Boyuan Zhang,Sian Jin,Kai Zhao,James Ahrens,Fengguang Song*

Main category: cs.DC

TL;DR: 该研究提出了一种新颖的流式压缩框架，可实现渐进式解压缩和随机存取解压缩，同时保持高压缩质量和速度，并解决了现有技术中的一些限制。


<details>
  <summary>Details</summary>
Motivation: 误差有界有损压缩是科学数据减容最高效的方法之一。对于有损压缩，渐进式解压缩和随机存取解压缩是按需数据访问和灵活分析工作流的关键特性。然而，这些特性会严重影响压缩质量和速度。

Method: 提出了一种新颖的流式压缩框架，该框架支持渐进式和随机存取解压缩，并采用分层分区策略和分层预测机制来提高压缩质量和速度，压缩质量可与最先进的非流式压缩器 SZ3 相媲美。

Result: 与 SZ3 相比，该框架的压缩和解压缩速度提高了 6.7 倍。

Conclusion: 该研究成功设计了第一个同时支持渐进式解压缩和随机存取解压缩的压缩框架，并在压缩质量和速度方面取得了显著改进。

Abstract: Error-bounded lossy compression is one of the most efficient solutions to
reduce the volume of scientific data. For lossy compression, progressive
decompression and random-access decompression are critical features that enable
on-demand data access and flexible analysis workflows. However, these features
can severely degrade compression quality and speed. To address these
limitations, we propose a novel streaming compression framework that supports
both progressive decompression and random-access decompression while
maintaining high compression quality and speed. Our contributions are
three-fold: (1) we design the first compression framework that simultaneously
enables both progressive decompression and random-access decompression; (2) we
introduce a hierarchical partitioning strategy to enable both streaming
features, along with a hierarchical prediction mechanism that mitigates the
impact of partitioning and achieves high compression quality -- even comparable
to state-of-the-art (SOTA) non-streaming compressor SZ3; and (3) our framework
delivers high compression and decompression speed, up to 6.7$\times$ faster
than SZ3.

</details>


### [567] [Optimal Parallel Scheduling under Concave Speedup Functions](https://arxiv.org/abs/2509.01811)
*Chengzhang Li,Peizhong Ju,Atilla Eryilmaz,Ness Shroff*

Main category: cs.DC

TL;DR: 本论文解决了在通用凹函数加速函数下并行作业的最优调度问题，提出了一致导数比率（CDR）规则和智能填充（SmartFill）算法，该算法通过通用加水法（GWF）实现，并在数值评估中显示出优于先前方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在云/边缘计算环境中，为AI应用高效调度并行计算资源是一个基本问题。虽然以往的研究（heSRPT）解决了指数形式加速函数的最优调度问题，但对于更准确地反映实际工作负载的通用凹函数加速函数，该问题仍未解决。

Method: 提出了一致导数比率（CDR）规则，并开发了通用加水法（GWF）来计算满足CDR规则的最优分配。基于此，设计了SmartFill算法来解决通用调度问题。SmartFill算法选择性地确定作业的资源分配，而不是像heSRPT那样将资源分配给所有活动作业。

Result: SmartFill算法对于一类广泛的“正则”加速函数，可以得到最优解的闭式解；对于非正则函数，它能以较低的复杂度有效地计算最优解。数值评估表明，SmartFill在各种凹函数加速函数上的性能均显著优于heSRPT。

Conclusion: 本论文通过提出CDR规则和SmartFill算法，成功解决了在通用凹函数加速函数下并行作业的最优调度问题，为云/边缘计算中的AI应用提供了更优的资源调度方案。

Abstract: Efficient scheduling of parallel computation resources across multiple jobs
is a fundamental problem in modern cloud/edge computing systems for many
AI-based applications. Allocating more resources to a job accelerates its
completion, but with diminishing returns. Prior work (heSRPT) solved this
problem only for some specific speedup functions with an exponential form,
providing a closed-form solution. However, the general case with arbitrary
concave speedup functions -- which more accurately capture real-world workloads
-- has remained open.
  In this paper, we solve this open problem by developing optimal scheduling
algorithms for parallel jobs under general concave speedup functions. We first
discover a fundamental and broadly-applicable rule for optimal parallel
scheduling, namely the Consistent Derivative Ratio (CDR) Rule, which states
that the ratio of the derivatives of the speedup functions across active jobs
remains constant over time. To efficiently compute the optimal allocations that
satisfy the CDR Rule, we propose the General Water-Filling (GWF) method, a more
general version of classical water-filling in wireless communications.
Combining these insights, we design the SmartFill Algorithm to solve the
general scheduling problem. Unlike heSRPT, which always allocates resources to
all active jobs, SmartFill selectively determines which jobs should receive
resources and how much they should be allocated. For a broad class of so-called
\emph{regular} speedup functions, SmartFill yields closed-form optimal
solutions, while for non-regular functions it efficiently computes the optimum
with low complexity. Numerical evaluations show that SmartFill can
substantially outperform heSRPT across a wide range of concave speedup
functions.

</details>


### [568] [A Continuous Energy Ising Machine Leveraging Difference-of-Convex Programming](https://arxiv.org/abs/2509.01928)
*Debraj Banerjee,Santanu Mahapatra,Kunal Narayan Chaudhury*

Main category: cs.DC

TL;DR: 通过将二元自旋松弛为连续变量并引入引导解向二元自旋构型演化的势函数，提出了一种新的Ising问题求解方法，该方法生成的哈密顿量为凸函数差，能够实现每次迭代仅需一次矩阵向量乘法的有效迭代算法，并具有收敛性保证。该方法在从边缘设备到高性能计算集群的多种GPU平台上实现了比现有求解器更优越的性能，覆盖了从10^3到10^8自旋的各种问题规模。


<details>
  <summary>Details</summary>
Motivation: 现有的模拟退火启发式Ising求解器虽然具有可扩展性，但缺乏收敛性保证，且对冷却时间表敏感。为了克服这些限制，需要开发一种新的求解Ising问题的方法。

Method: 将Ising模型的二元自旋松弛为连续变量，并引入一个势函数（吸引子）来引导解收敛到二元自旋构型。将得到的哈密顿量表示为凸函数的差，以便设计高效的迭代算法，该算法每次迭代仅需一次矩阵向量乘法，并具有收敛性保证。

Result: 所提出的Ising求解器在多种GPU平台上（从边缘设备到高性能计算集群）进行了实现，并在不同问题规模（从10^3到10^8个自旋）下，均一致优于现有的求解器。

Conclusion: 新提出的基于连续松弛和势函数的Ising求解方法，通过有效的迭代算法和收敛性保证，在各种规模的问题和GPU平台上均展现出优于现有方法的性能。

Abstract: Many combinatorial optimization problems can be reformulated as the task of
finding the ground state of a physical system, such as the Ising model. Most
existing Ising solvers are inspired by simulated annealing. Although annealing
techniques offer scalability, they lack convergence guarantees and are
sensitive to the cooling schedule. We propose to solve the Ising problem by
relaxing the binary spins to continuous variables and introducing a potential
function (attractor) that steers the solution toward binary spin
configurations. The resulting Hamiltonian can be expressed as a difference of
convex functions, enabling the design of efficient iterative algorithms that
require a single matrix-vector multiplication per iteration and are backed by
convergence guarantees. We implement our Ising solver across a range of GPU
platforms: from edge devices to high-performance computing clusters and
demonstrate that it consistently outperforms existing solvers across problem
sizes ranging from small ($10^3$ spins) to ultra-large ($10^8$ spins).

</details>


### [569] [Fault-Tolerant Decentralized Distributed Asynchronous Federated Learning with Adaptive Termination Detection](https://arxiv.org/abs/2509.02186)
*Phani Sahasra Akkinepally,Manaswini Piduguralla,Sushant Joshi,Sathya Peri,Sandeep Kulkarni*

Main category: cs.DC

TL;DR: 开发了一种异步去中心化联邦学习方法，通过客户端自信收敛和客户端响应式终止技术，解决了传统联邦学习中心化带来的瓶颈和单点故障问题，并提高了在异构环境下的可扩展性和响应能力，同时增强了容错能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习中心化服务器带来的瓶颈和单点故障问题，并在异构环境中提高可扩展性和响应能力。

Method: 开发了一个异步联邦学习框架，允许客户端独立学习和更新，并加入了容错机制以处理客户端故障和消息丢失。提出了客户端自信收敛和客户端响应式终止技术。

Result: 提出的异步去中心化联邦学习方法能够实现可靠的收敛，并具有容错能力。

Conclusion: 所提出的异步去中心化联邦学习方法通过客户端自信收敛和客户端响应式终止技术，有效地解决了同步联邦学习中的延迟问题，提高了在异构环境下的性能和鲁棒性。

Abstract: Federated Learning (FL) facilitates collaborative model training across
distributed clients while ensuring data privacy. Traditionally, FL relies on a
centralized server to coordinate learning, which creates bottlenecks and a
single point of failure. Decentralized FL architectures eliminate the need for
a central server and can operate in either synchronous or asynchronous modes.
Synchronous FL requires all clients to compute updates and wait for one another
before aggregation, guaranteeing consistency but often suffering from delays
due to slower participants. Asynchronous FL addresses this by allowing clients
to update independently, offering better scalability and responsiveness in
heterogeneous environments.
  Our research develops an asynchronous decentralized FL approach in two
progressive phases. (a) In Phase 1, we develop an asynchronous FL framework
that enables clients to learn and update independently, removing the need for
strict synchronization. (b) In Phase 2, we extend this framework with fault
tolerance mechanisms to handle client failures and message drops, ensuring
robust performance even under unpredictable conditions. As a central
contribution, we propose Client-Confident Convergence and Client-Responsive
Termination novel techniques that provide each client with the ability to
autonomously determine appropriate termination points. These methods ensure
that all active clients conclude meaningfully and efficiently, maintaining
reliable convergence despite the challenges of asynchronous communication and
faults.

</details>


### [570] [Safe Memory Reclamation Techniques](https://arxiv.org/abs/2509.02457)
*Ajay Singh*

Main category: cs.DC

TL;DR: Safe memory reclamation is essential for memory safety in concurrent data structures but faces challenges like speed, scalability, ease of use, applicability, memory footprint, and asymmetric overhead. Approaches blend ideas from the hardware-software stack, crossing traditional boundaries and exploiting features at different layers.


<details>
  <summary>Details</summary>
Motivation: Safe memory reclamation is crucial for memory safety in optimistic and lock-free concurrent data structures in non-garbage collected languages, but existing solutions face challenges in speed, scalability, ease of use, applicability, memory footprint, and asymmetric overhead.

Method: The paper studies several approaches to designing safe memory reclamation algorithms by blending ideas and tools from across the hardware-software stack, exploiting features exposed at different layers.

Result: The study explores solutions that cross traditional boundaries and exploit features at different layers of the hardware-software stack.

Conclusion: The paper explores innovative approaches to safe memory reclamation by integrating concepts across the hardware-software stack to address existing challenges.

Abstract: Safe memory reclamation is crucial to memory safety for optimistic and
lock-free concurrent data structures in non garbage collected programming
languages. However, several challenges arise in designing an ideal safe memory
reclamation algorithm, including achieving high speed and scalability, easy of
use for programmers, applicability to wide class of data structures, managing
the large memory footprint caused by delayed freeing of memory for safety and
performance, and avoiding asymmetric overhead on data structure operations.
Several approaches to designing safe memory reclamation algorithms are studied
by blending ideas and tools from across the hardware-software stack. These
solutions cross traditional boundaries and exploit features exposed at
different layers.

</details>


### [571] [Near-Optimal Stability for Distributed Transaction Processing in Blockchain Sharding](https://arxiv.org/abs/2509.02421)
*Ramesh Adhikari,Costas Busch,Dariusz R. Kowalski*

Main category: cs.DC

TL;DR: Blockchain分片技术中的关键挑战在于如何确保系统在面临由攻击者以最大ρ速率和b突发性生成的交易模式下保持稳定，从而保证交易队列大小和延迟的有界性。本文提出了一个单领导者调度器，可在ρ ≤ max{1/16k, 1/16⌈√s⌉}的注入率下保证系统稳定。此外，还提出了一种分布式多领导者调度器，可在ρ ≤ 1/(16c1 log D log s) * max{1/k, 1/⌈√s⌉}的注入率下保证系统稳定，该速率接近最优值，并显著优于Adhikari等人(SPAA 2024)提出的结果。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决区块链分片系统中确保系统稳定性以应对各种交易生成模式（包括最坏情况和攻击）的关键挑战，这些模式由交易的注入速率（ρ）和突发性（b）来建模。

Method: 本文提出了一个单领导者调度器，其稳定性保证的注入速率上限为ρ ≤ max{1/16k, 1/16⌈√s⌉}。此外，还提出了一种分布式调度器（具有多个领导者），其稳定性保证的注入速率上限为ρ ≤ 1/(16c1 log D log s) * max{1/k, 1/⌈√s⌉}。

Result: 单领导者调度器可保证在注入速率ρ ≤ max{1/16k, 1/16⌈√s⌉}下的系统稳定性。分布式调度器可保证在注入速率ρ ≤ 1/(16c1 log D log s) * max{1/k, 1/⌈√s⌉}下的系统稳定性，此结果比现有最优值仅相差一个多对数因子。

Conclusion: 本文提出的单领导者和分布式调度器能够有效提高区块链分片系统的稳定性和交易处理能力，尤其是在分布式设置下，其性能接近理论最优值，并显著优于先前的工作。

Abstract: In blockchain sharding, $n$ processing nodes are divided into $s$ shards, and
each shard processes transactions in parallel. A key challenge in such a system
is to ensure system stability for any ``tractable'' pattern of generated
transactions; this is modeled by an adversary generating transactions with a
certain rate of at most $\rho$ and burstiness $b$. This model captures
worst-case scenarios and even some attacks on transactions' processing, e.g.,
DoS. A stable system ensures bounded transaction queue sizes and bounded
transaction latency. It is known that the absolute upper bound on the maximum
injection rate for which any scheduler could guarantee bounded queues and
latency of transactions is $\max\left\{ \frac{2}{k+1}, \frac{2}{
\left\lfloor\sqrt{2s}\right\rfloor}\right\}$, where $k$ is the maximum number
of shards that each transaction accesses. Here, we first provide a single
leader scheduler that guarantees stability under injection rate $\rho \leq
\max\left\{ \frac{1}{16k}, \frac{1}{16\lceil \sqrt{s} \rceil}\right\}$.
Moreover, we also give a distributed scheduler with multiple leaders that
guarantees stability under injection rate $\rho \leq \frac{1}{16c_1 \log D \log
s}\max\left\{ \frac{1}{k}, \frac{1}{\lceil \sqrt{s} \rceil} \right\}$, where
$c_1$ is some positive constant and $D$ is the diameter of shard graph $G_s$.
This bound is within a poly-log factor from the optimal injection rate, and
significantly improves the best previous known result for the distributed
setting by Adhikari et al., SPAA 2024.

</details>


### [572] [Efficient Pyramidal Analysis of Gigapixel Images on a Decentralized Modest Computer Cluster](https://arxiv.org/abs/2509.02440)
*Marie Reinbigler,Rishi Sharma,Rafael Pires,Elisabeth Brunet,Anne-Marie Kermarrec,Catalin Fetita*

Main category: cs.DC

TL;DR: 金字塔AI是一种用于分析十亿像素图像的技术，通过逐步分析和关注感兴趣区域来降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 分析十亿像素图像的计算成本高昂，需要一种更有效的方法。

Method: 提出金字塔AI技术，逐步分析图像，从低分辨率开始，然后聚焦于高分辨率下的感兴趣区域。研究了两种调整准确性-计算性能权衡的策略，并使用Camelyon16数据集进行了验证。此外，还利用并行性在主流计算机上评估了数据分布和负载均衡算法。

Result: 金字塔AI将分析所需处理的数据量减少了多达2.65倍，同时在单台计算机上保持了识别相关区域的准确性。使用12个普通计算节点，分析时间从一小时以上缩短到几分钟。

Conclusion: 金字塔AI通过逐步分析和并行处理，显著降低了十亿像素图像分析的计算成本，并可在主流计算机上实现高效分析，具有实际应用价值。

Abstract: Analyzing gigapixel images is recognized as computationally demanding. In
this paper, we introduce PyramidAI, a technique for analyzing gigapixel images
with reduced computational cost. The proposed approach adopts a gradual
analysis of the image, beginning with lower resolutions and progressively
concentrating on regions of interest for detailed examination at higher
resolutions. We investigated two strategies for tuning the accuracy-computation
performance trade-off when implementing the adaptive resolution selection,
validated against the Camelyon16 dataset of biomedical images. Our results
demonstrate that PyramidAI substantially decreases the amount of processed data
required for analysis by up to 2.65x, while preserving the accuracy in
identifying relevant sections on a single computer. To ensure democratization
of gigapixel image analysis, we evaluated the potential to use mainstream
computers to perform the computation by exploiting the parallelism potential of
the approach. Using a simulator, we estimated the best data distribution and
load balancing algorithm according to the number of workers. The selected
algorithms were implemented and highlighted the same conclusions in a
real-world setting. Analysis time is reduced from more than an hour to a few
minutes using 12 modest workers, offering a practical solution for efficient
large-scale image analysis.

</details>


### [573] [An Efficient and Adaptive Watermark Detection System with Tile-based Error Correction](https://arxiv.org/abs/2509.02447)
*Xinrui Zhong,Xinze Feng,Jingwei Zuo,Fanjiang Ye,Yi Mu,Junfeng Guo,Heng Huang,Myungjin Lee,Yuke Wang*

Main category: cs.DC

TL;DR: QRMark是一种高效的图像水印检测方法，通过结合QR码的纠错能力和特定的分块技术，提高了检测效率和鲁棒性，同时实现了2.43倍的推理加速。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注检测准确性和鲁棒性，忽略了大规模图像集合中水印检测的效率问题。

Method: QRMark结合了QR码的纠错机制（Reed-Solomon）和分块技术，并采用资源感知流分配策略和基于块的工作负载交错策略来优化效率。

Result: QRMark实现了2.43倍于顺序基线的推理速度提升。

Conclusion: QRMark是一种高效且自适应的端到端方法，用于检测嵌入式图像水印，在效率、准确性和鲁棒性方面均表现出色。

Abstract: Efficient and reliable detection of generated images is critical for the
responsible deployment of generative models. Existing approaches primarily
focus on improving detection accuracy and robustness under various image
transformations and adversarial manipulations, yet they largely overlook the
efficiency challenges of watermark detection across large-scale image
collections. To address this gap, we propose QRMark, an efficient and adaptive
end-to-end method for detecting embedded image watermarks. The core idea of
QRMark is to combine QR Code inspired error correction with tailored tiling
techniques to improve detection efficiency while preserving accuracy and
robustness. At the algorithmic level, QRMark employs a Reed-Solomon error
correction mechanism to mitigate the accuracy degradation introduced by tiling.
At the system level, QRMark implements a resource-aware stream allocation
policy that adaptively assigns more streams to GPU-intensive stages of the
detection pipeline. It further employs a tile-based workload interleaving
strategy to overlap data-loading overhead with computation and schedules
kernels across stages to maximize efficiency. End-to-end evaluations show that
QRMark achieves an average 2.43x inference speedup over the sequential
baseline.

</details>


### [574] [KubeIntellect: A Modular LLM-Orchestrated Agent Framework for End-to-End Kubernetes Management](https://arxiv.org/abs/2509.02449)
*Mohsen Seyedkazemi Ardebili,Andrea Bartolini*

Main category: cs.DC

TL;DR: KubeIntellect是一个利用大语言模型（LLM）驱动的端到端Kubernetes智能管理系统，支持自然语言交互，可处理各种Kubernetes API操作，并具有高成功率和可靠性。


<details>
  <summary>Details</summary>
Motivation: Kubernetes管理复杂且分散，需要管理员掌握大量API、管理异构工作负载并协调不同工具，KubeIntellect旨在简化这一过程。

Method: KubeIntellect使用与功能域（如日志、指标、RBAC）对齐的模块化代理，由一个解释用户查询、维护工作流记忆、调用可重用工具或通过安全代码生成代理合成新工具的监督器进行编排。该系统集成了内存检查点、人机循环澄清和动态任务排序到一个结构化的编排框架中。

Result: 评估结果显示，KubeIntellect在工具合成方面成功率为93%，在200个自然语言查询中可靠性为100%，证明了该系统在多样化工作负载下高效运行的能力。

Conclusion: KubeIntellect为管理复杂基础设施引入了一类新的可解释、可扩展且由LLM驱动的系统。

Abstract: Kubernetes has become the foundation of modern cloud-native infrastructure,
yet its management remains complex and fragmented. Administrators must navigate
a vast API surface, manage heterogeneous workloads, and coordinate tasks across
disconnected tools - often requiring precise commands, YAML configuration, and
contextual expertise.
  This paper presents KubeIntellect, a Large Language Model (LLM)-powered
system for intelligent, end-to-end Kubernetes control. Unlike existing tools
that focus on observability or static automation, KubeIntellect supports
natural language interaction across the full spectrum of Kubernetes API
operations, including read, write, delete, exec, access control, lifecycle, and
advanced verbs. The system uses modular agents aligned with functional domains
(e.g., logs, metrics, RBAC), orchestrated by a supervisor that interprets user
queries, maintains workflow memory, invokes reusable tools, or synthesizes new
ones via a secure Code Generator Agent.
  KubeIntellect integrates memory checkpoints, human-in-the-loop clarification,
and dynamic task sequencing into a structured orchestration framework.
Evaluation results show a 93% tool synthesis success rate and 100% reliability
across 200 natural language queries, demonstrating the system's ability to
operate efficiently under diverse workloads. An automated demo environment is
provided on Azure, with additional support for local testing via kind. This
work introduces a new class of interpretable, extensible, and LLM-driven
systems for managing complex infrastructure.

</details>


### [575] [MLP-Offload: Multi-Level, Multi-Path Offloading for LLM Pre-training to Break the GPU Memory Wall](https://arxiv.org/abs/2509.02480)
*Avinash Maurya,M. Mustafa Rafique,Franck Cappello,Bogdan Nicolae*

Main category: cs.DC

TL;DR: MLP-Offload通过多层、多路径卸载引擎优化资源受限环境下的LLM训练，解决了I/O瓶颈问题，将迭代速度提高了2.5倍。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM规模增长快于GPU内存增长的问题，需要训练大于多GPU聚合内存的LLM。现有的多层主机内存或磁盘卸载技术会引入显著的I/O开销，减慢训练迭代速度。

Method: MLP-Offload是一种新颖的多层、多路径卸载引擎，通过跨多层以缓存高效和并发控制的方式卸载优化器状态，以减轻反向传播和更新阶段的I/O瓶颈。该设计基于以下关键观察：更新过程中的I/O开销主导迭代时间；第三层远程存储的I/O带宽未被充分利用；并发卸载导致的争用会加剧I/O瓶颈。

Result: 在高达280B参数的模型上进行评估，MLP-Offload实现了比现有最先进的LLM训练运行时快2.5倍的迭代速度。

Conclusion: MLP-Offload通过解决I/O瓶颈问题，显著提高了资源受限设置下LLM训练的迭代速度，验证了其有效性。

Abstract: Training LLMs larger than the aggregated memory of multiple GPUs is
increasingly necessary due to the faster growth of LLM sizes compared to GPU
memory. To this end, multi-tier host memory or disk offloading techniques are
proposed by state of art. Despite advanced asynchronous multi-tier read/write
strategies, such offloading strategies result in significant I/O overheads in
the critical path of training, resulting in slower iterations. To this end, we
propose MLP-Offload, a novel multi-level, multi-path offloading engine
specifically designed for optimizing LLM training on resource-constrained
setups by mitigating I/O bottlenecks. We make several key observations that
drive the design of MLP-Offload, such as I/O overheads during the update
dominate the iteration time; I/O bandwidth of the third-level remote storage
tier remains unutilized; and, contention due to concurrent offloading amplifies
I/O bottlenecks. Driven by these insights, we design and implement MLP-Offload
to offload the optimizer states across multiple tiers in a cache-efficient and
concurrency-controlled fashion to mitigate I/O bottlenecks during the backward
and update phases. Evaluations on models up to 280B parameters shows that
MLP-Offload achieves 2.5$\times$ faster iterations compared to the
state-of-the-art LLM training runtimes.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [576] [Playing Markov Games Without Observing Payoffs](https://arxiv.org/abs/2509.00179)
*Daniel Ablin,Alon Cohen*

Main category: cs.GT

TL;DR: 本文研究了在零和对称马尔可夫博弈中，即使不观察对手的收益，也能通过学习对手的行动序列来与对手竞争。


<details>
  <summary>Details</summary>
Motivation: 在学习和决策中，尤其是在多智能体系统中，不确定性优化是一个基本问题。之前的研究表明，在某些条件下，玩家可以在不知道收益的情况下有效竞争。

Method: 本文将对称性从矩阵博弈扩展到马尔可夫博弈，并形式化了零和对称马尔可夫博弈。在知道转移动态并仅观察对手行动的情况下，提出了可以减少学习问题到在线学习实例的算法。

Result: 在三种对称性的条件下，即使没有收益观察，玩家也能渐近地匹配对手的回报。该算法适用于矩阵博弈和马尔可夫博弈，并且运行时间是多项式级别的。

Conclusion: 本文扩展了在信息劣势下进行鲁棒学习的游戏类别，并加深了在线学习与对抗博弈论之间的联系。

Abstract: Optimization under uncertainty is a fundamental problem in learning and
decision-making, particularly in multi-agent systems. Previously, Feldman,
Kalai, and Tennenholtz [2010] demonstrated the ability to efficiently compete
in repeated symmetric two-player matrix games without observing payoffs, as
long as the opponents actions are observed. In this paper, we introduce and
formalize a new class of zero-sum symmetric Markov games, which extends the
notion of symmetry from matrix games to the Markovian setting. We show that
even without observing payoffs, a player who knows the transition dynamics and
observes only the opponents sequence of actions can still compete against an
adversary who may have complete knowledge of the game. We formalize three
distinct notions of symmetry in this setting and show that, under these
conditions, the learning problem can be reduced to an instance of online
learning, enabling the player to asymptotically match the return of the
opponent despite lacking payoff observations. Our algorithms apply to both
matrix and Markov games, and run in polynomial time with respect to the size of
the game and the number of episodes. Our work broadens the class of games in
which robust learning is possible under severe informational disadvantage and
deepens the connection between online learning and adversarial game theory.

</details>


### [577] [Strategyproof Mechanisms for Facility Location with Prediction Under the Maximum Cost Objective](https://arxiv.org/abs/2509.00439)
*Hau Chan,Jianan Lin,Chenhao Wang*

Main category: cs.GT

TL;DR: 本文研究在学习增强框架下，度量空间中的设施选址机制设计问题，目标是设计策略证明（SP）机制，在利用不完美预测的同时，近似最小化所有代理的最大成本。


<details>
  <summary>Details</summary>
Motivation: 在学习增强框架下，利用不完美的预测信息，设计策略证明（SP）的设施选址机制，以近似最小化代理的最大成本，并使机制的近似保证与预测误差相关（一致性），同时保持在预测误差任意大的情况下的鲁棒性。

Method: 在实线度量空间中，刻画了所有具有严格小于2的一致性且有界鲁棒性的确定性SP机制，证明其为MinMaxP机制；进一步证明了MinMaxP机制的近似比为(1+min(1, η))，且不存在更好的确定性SP机制。在二维空间中，$l_p$度量下，分析了MinMaxP机制的近似保证，以及一个随机化机制的选择。最后讨论了所考虑机制的群体策略证明。

Result: 在实线度量空间中，MinMaxP机制被确定为满足特定条件的最优确定性SP机制，其近似比为(1+min(1, η))。在二维$l_p$度量空间中，对MinMaxP坐标独立运行和一种随机化机制的近似保证进行了分析。

Conclusion: 该研究为学习增强框架下的策略证明设施选址机制设计提供了理论基础，特别是在一致性和鲁棒性方面，并对不同度量空间下的机制性能进行了分析。

Abstract: We study the mechanism design problem of facility location on a metric space
in the learning-augmented framework, where mechanisms have access to an
imperfect prediction of optimal facility locations. Our goal is to design
strategyproof (SP) mechanisms to elicit agent preferences on the facility
locations truthfully and, leveraging the given imperfect prediction, determine
the facility location that approximately minimizes the maximum cost among all
agents. In particular, we seek SP mechanisms whose approximation guarantees
depend on the prediction errors -- achieve improved guarantees when the
prediction is accurate (known as the \emph{consistency}), while still ensuring
robust worst-case performance when the prediction is arbitrarily inaccurate
(known as the \emph{robustness}).
  When the metric space is the real line, we characterize all deterministic SP
mechanisms with consistency strictly less than 2 and bounded robustness: such
mechanisms must be the MinMaxP mechanism, which returns the prediction location
if it lies between the two extreme agent locations and, otherwise, returns the
closest agent location to the prediction. We further show that, for any
prediction error $\eta\ge 0$, while MinMaxP is $(1+\min(1,
\eta))$-approximation, no deterministic SP mechanism can achieve a better
approximation. In two-dimensional spaces with the $l_p$ metric, we analyze the
approximation guarantees of a deterministic mechanism that runs MinMaxP
independently on each coordinate, as well as a randomized mechanism that
selects between two deterministic ones with specific probabilities. Finally, we
discuss the group strategyproofness of the considered mechanisms.

</details>


### [578] [Mean-payoff and Energy Discrete Bidding Games](https://arxiv.org/abs/2509.00506)
*Guy Avni,Suman Sadhukhan*

Main category: cs.GT

TL;DR: 该论文研究了在图上进行的离散投标博弈，重点关注平均收益和能量目标。


<details>
  <summary>Details</summary>
Motivation: 为了解决实际应用中的投标限制，即投标必须以整数（例如美分）给出，论文研究了具有离散投标的投标博弈。

Method: 研究了平均收益和能量目标下的离散投标博弈。引入了“阈值预算”的概念，该预算是在能量博弈中获胜或在平均收益博弈中保证目标收益所必需的。论文证明了阈值预算的存在性，并确定了其结构，这对于获得紧凑策略至关重要。

Result: 论文证明了阈值预算的存在性，该预算对于能量博弈的获胜和平均收益博弈的目标收益至关重要。论文还确定了阈值预算的结构，这对于获得紧凑策略至关重要。

Conclusion: 论文证明了阈值预算的存在性和结构，并表明在图上进行的离散投标博弈（具有平均收益或能量目标）的阈值预算的计算属于NP和coNP。

Abstract: A \emph{bidding} game is played on a graph as follows. A token is placed on
an initial vertex and both players are allocated budgets. In each turn, the
players simultaneously submit bids that do not exceed their available budgets,
the higher bidder moves the token, and pays the bid to the lower bidder. We
focus on \emph{discrete}-bidding, which are motivated by practical applications
and restrict the granularity of the players' bids, e.g, bids must be given in
cents. We study, for the first time, discrete-bidding games with {\em
mean-payoff} and {\em energy} objectives. In contrast, mean-payoff {\em
continuous}-bidding games (i.e., no granularity restrictions) are understood
and exhibit a rich mathematical structure. The {\em threshold} budget is a
necessary and sufficient initial budget for winning an energy game or
guaranteeing a target payoff in a mean-payoff game. We first establish
existence of threshold budgets; a non-trivial property due to the concurrent
moves of the players. Moreover, we identify the structure of the thresholds,
which is key in obtaining compact strategies, and in turn, showing that finding
threshold is in \NP~and \coNP even in succinctly-represented games.

</details>


### [579] [Quantum game models for interaction-aware decision-making in automated driving](https://arxiv.org/abs/2509.01582)
*Karim Essalmi,Fernando Garrido,Fawzi Nashashibi*

Main category: cs.GT

TL;DR: 该论文提出使用量子博弈模型（QG-U1和QG-G4）来解决自动驾驶中的交互式决策问题，以克服传统方法中对交互考虑不足的问题。这些模型利用量子力学原理，无需量子硬件即可在标准计算机上实时运行。实验结果表明，QG-G4在碰撞率和成功率方面优于基线方法，并且在特定参数下，量子模型比经典博弈方法产生更高的预期收益。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶决策方法在考虑与周围Agent的交互方面存在不足，导致车辆行为过于保守。本研究旨在通过引入量子博弈模型来解决这一问题。

Method: 提出并实现了两种量子博弈模型：QG-U1（Quantum Game - Unitary 1）和QG-G4（Quantum Game - Gates 4）。这些模型扩展了经典博弈论，融入了量子力学的叠加、干涉和纠缠等概念，适用于两名玩家、每名玩家有两个策略的情况，并可在标准计算机上实时运行。

Result: 在合并和环岛场景的评估中，QG-G4相比基线方法（IDM, MOBIL, and a utility-based technique）实现了更低的碰撞率和更高的成功率。此外，在某些参数设置下，两种量子模型均比经典博弈方法产生了更高的预期收益。

Conclusion: 量子博弈模型（QG-U1和QG-G4）为解决自动驾驶中的交互式决策问题提供了一种有前景的方法，能够有效处理复杂的交互情况，并可能带来比经典方法更好的性能。

Abstract: Decision-making in automated driving must consider interactions with
surrounding agents to be effective. However, traditional methods often neglect
or oversimplify these interactions because they are difficult to model and
solve, which can lead to overly conservative behavior of the ego vehicle. To
address this gap, we propose two quantum game models, QG-U1 (Quantum Game -
Unitary 1) and QG-G4 (Quantum Game - Gates 4), for interaction-aware
decision-making. These models extend classical game theory by incorporating
principles of quantum mechanics, such as superposition, interference, and
entanglement. Specifically, QG-U1 and QG-G4 are designed for two-player games
with two strategies per player and can be executed in real time on a standard
computer without requiring quantum hardware. We evaluate both models in merging
and roundabout scenarios and compare them with classical game-theoretic methods
and baseline approaches (IDM, MOBIL, and a utility-based technique). Results
show that QG-G4 achieves lower collision rates and higher success rates
compared to baseline methods, while both quantum models yield higher expected
payoffs than classical game approaches under certain parameter settings.

</details>


### [580] [Complexity of the Existence of Constrained Secure Equilibria in Multi-Player Games](https://arxiv.org/abs/2509.01870)
*Hiroki Mizuno,Yoshiaki Takata,Hiroyuki Seki*

Main category: cs.GT

TL;DR: The paper discusses the decidability and complexity of finding a secure equilibrium (SE) in multi-player games, where SE is a refinement of Nash equilibrium that prevents players from unilaterally improving their payoff or decreasing others' payoffs.


<details>
  <summary>Details</summary>
Motivation: The motivation is to study the decidability and complexity of secure equilibria with constraints in multi-player games, offering a refinement over Nash equilibrium.

Method: The paper analyzes the decidability and complexity of determining the existence of a secure equilibrium with specific payoff constraints (win conditions for certain players) in finite directed graph multi-player games.

Result: The paper investigates the decidability and complexity of secure equilibrium existence with constraints.

Conclusion: The paper focuses on the decidability and complexity aspects of secure equilibria in multi-player games with payoff constraints.

Abstract: We consider a multi-player non-zero-sum turn-based game (abbreviated as
multi-player game) on a finite directed graph. A secure equilibrium (SE) is a
strategy profile in which no player has the incentive to deviate from the
strategy because no player can increase her own payoff or lower the payoff of
another player. SE is a promising refinement of Nash equilibrium in which a
player does not care the payoff of another player. In this paper, we discuss
the decidability and complexity of the problem of deciding whether a secure
equilibrium with constraints (a payoff profile specifying which players must
win) exists for a given multi-player game.

</details>


### [581] [Entry Barriers in Content Markets](https://arxiv.org/abs/2509.01953)
*Haiqing Zhu,Lexing Xie,Yun Kuen Cheung*

Main category: cs.GT

TL;DR: 在线内容平台的准入壁垒和奖励机制可以提高内容质量。


<details>
  <summary>Details</summary>
Motivation: 研究隐性或显性的准入壁垒和适当的奖励机制是否可以提高内容质量。

Method: 对两种不同类型的在线内容平台准入壁垒（结构性壁垒和战略性壁垒）进行了博弈论分析。

Result: 排名顺序和比例份额奖励机制在纳什均衡中会产生结构性壁垒；平台将部分或全部入场费重定向到奖励池的计划可以提高整体内容质量。

Conclusion: 研究结果为设计奖励机制和入场费以促进更高质量的内容和更健康在线生态系统奠定了理论基础。

Abstract: The prevalence of low-quality content on online platforms is often attributed
to the absence of meaningful entry requirements. This motivates us to
investigate whether implicit or explicit entry barriers, alongside appropriate
reward mechanisms, can enhance content quality. We present the first
game-theoretic analysis of two distinct types of entry barriers in online
content platforms. The first, a structural barrier, emerges from the collective
behaviour of incumbent content providers which disadvantages new entrants. We
show that both rank-order and proportional-share reward mechanisms induce such
a structural barrier at Nash equilibrium. The second, a strategic barrier,
involves the platform proactively imposing entry fees to discourage
participation from low-quality contributors. We consider a scheme in which the
platform redirects some or all of the entry fees into the reward pool. We
formally demonstrate that this approach can improve overall content quality.
Our findings establish a theoretical foundation for designing reward mechanisms
coupled with entry fees to promote higher-quality content and support healthier
online ecosystems.

</details>


### [582] [A Strongly Polynomial-Time Combinatorial Algorithm for the Nucleolus in Convex Games](https://arxiv.org/abs/2509.02380)
*Giacoomo Maggiorano,Alessandro Sosso,Gautier Stauffer*

Main category: cs.GT

TL;DR: 文章提出了计算凸博弈核仁的组合式、强多项式算法。


<details>
  <summary>Details</summary>
Motivation: 现有的计算凸博弈核仁的算法依赖于椭圆体法，该算法效率不高。本文旨在寻找更有效的算法。

Method: 本文重新审视了约简博弈方法，并提出了新的算法思路，利用了最小核多面体的结构，最终得到了一种组合式的强多项式算法。

Result: 文章提出了一种新的算法，该算法能够以组合式、强多项式的时间复杂度计算凸博弈的核仁。

Conclusion: 约简博弈方法在结合新的算法思路和利用最小核多面体结构后，可以有效地用于计算凸博弈的核仁，并得到了首个组合式、强多项式算法。

Abstract: The nucleolus is a fundamental solution concept in cooperative game theory,
yet computing it is NP-hard in general. In convex games-where players' marginal
contributions grow with coalition size-the only existing polynomial-time
algorithm relies on the ellipsoid method. We re-examine a reduced game
approach, refuting a previously claimed polynomial-time implementation and
clarifying why it fails. By developing new algorithmic ideas and exploiting the
structure of least core polyhedra, we show that reduced games can in fact be
used effectively. This yields the first combinatorial and strongly polynomial
algorithm for computing the nucleolus in convex games.

</details>


### [583] [Harnessing Information in Incentive Design](https://arxiv.org/abs/2509.02493)
*Raj Kiriti Velicheti,Subhonmesh Bose,Tamer Başar*

Main category: cs.GT

TL;DR: The paper studies how information asymmetry affects incentive design between a principal and an agent. It shows that principals benefit from reducing this asymmetry, exploring methods like information design and direct information acquisition. The study analyzes these scenarios in matrix games and quadratic Gaussian games.


<details>
  <summary>Details</summary>
Motivation: This paper aims to systematically study the effect of information asymmetry in incentive design games, a scenario where a principal designs incentives for an agent who has an informational advantage.

Method: The study explores two ways for the principal to mitigate uncertainty caused by information asymmetry: 1) Information Design, where the agent shapes the principal's belief, and 2) Information Acquisition, where the principal pays to acquire information. Both methods are analyzed in matrix games and quadratic Gaussian game setups.

Result: The paper demonstrates that it is in the principal's interest to decrease information asymmetry. While introducing uncertainty increases the principal's cost, allowing the agent to shape the principal's belief can be advantageous.

Conclusion: The study concludes that principals should aim to reduce information asymmetry. Information design, despite potentially increasing costs through uncertainty, can be a beneficial strategy for the principal.

Abstract: Incentive design deals with interaction between a principal and an agent
where the former can shape the latter's utility through a policy commitment. It
is well known that the principal faces an information rent when dealing with an
agent that has informational advantage. In this work, we embark on a systematic
study of the effect of information asymmetry in incentive design games.
Specifically, we first demonstrate that it is in principal's interest to
decrease this information asymmetry. To mitigate this uncertainty, we let the
principal gather information either by letting the agent shape her belief (aka
Information Design), or by paying to acquire it. Providing solutions to all
these cases we show that while introduction of uncertainty increases the
principal's cost, letting the agent shape its belief can be advantageous. We
study information asymmetry and information acquisition in both matrix games
and quadratic Gaussian game setups.

</details>


### [584] [Selecting Interlacing Committees](https://arxiv.org/abs/2509.02519)
*Chris Dong,Martin Bullinger,Tomasz Wąs,Larry Birnbaum,Edith Elkind*

Main category: cs.GT

TL;DR: 该研究提出了一种通过优化委员会成员与选民的互联性来避免政治极化的新方法，并为特定场景提供了高效算法。


<details>
  <summary>Details</summary>
Motivation: 为解决社会极化问题，特别是政治代表性驱动的极化，并改进现有计算社会选择方法在委员会选择中的不足。

Method: 提出两个量化指标来评估委员会与选民的互联性，旨在避免产生极化委员会；针对选民-候选人区间模型，设计了解决这些NP-完全问题的有效算法；并分析了该方法与卓越性、多样性和比例性等其他代表性目标的一致性，实现了近似最优解。

Result: 开发了能够最大化互联性指标的算法，并识别了在不同代表性目标之间的权衡，提供了可同时实现常数因子近似的算法。

Conclusion: 所提出的方法能够有效避免极化委员会的产生，并且在与其他代表性目标兼容的情况下，能够提供近似最优的解决方案。

Abstract: Polarization is a major concern for a well-functioning society. Often, mass
polarization of a society is driven by polarizing political representation,
even when the latter is easily preventable. The existing computational social
choice methods for the task of committee selection are not designed to address
this issue. We enrich the standard approach to committee selection by defining
two quantitative measures that evaluate how well a given committee
interconnects the voters. Maximizing these measures aims at avoiding polarizing
committees. While the corresponding maximization problems are NP-complete in
general, we obtain efficient algorithms for profiles in the voter-candidate
interval domain. Moreover, we analyze the compatibility of our goals with other
representation objectives, such as excellence, diversity, and proportionality.
We identify trade-offs between approximation guarantees, and describe
algorithms that achieve simultaneous constant-factor approximations.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [585] [Nonadiabatic Wave-Packet Dynamics: Nonadiabatic Metric, Quantum Geometry, and Analogue Gravity](https://arxiv.org/abs/2509.00166)
*Yafei Ren,M. E. Sanchez Barrero*

Main category: cond-mat.mtrl-sci

TL;DR: We developed a unified theory for nonadiabatic wave-packet dynamics of Bloch electrons under perturbations, including interband contributions and deriving new equations. This leads to a reformulated dynamics as geodesic motion in phase space, with applications to 1D Dirac electron systems under exchange fields.


<details>
  <summary>Details</summary>
Motivation: To develop a unified theory for the nonadiabatic wave-packet dynamics of Bloch electrons subject to slowly varying spatial and temporal perturbations, extending conventional methods to include interband contributions.

Method: Extended the wave-packet ansatz to include interband contributions, derived the wave-packet coefficient equation using the time-dependent variational principle, solved these equations, and integrated out interband contributions to find leading-order nonadiabatic corrections to the wave-packet Lagrangian.

Result: Identified three forms of nonadiabatic corrections: a nonadiabatic metric (energy-gap-renormalized quantum metric), modified Berry connections, and an energy correction. Reformulated wave-packet dynamics as geodesic motion in phase space. Applied to 1D Dirac electron systems, showing magnitude variations of the exchange field are important for nonadiabatic dynamics, unlike the adiabatic regime.

Conclusion: The developed theory provides a unified framework for nonadiabatic wave-packet dynamics, offering new insights and an analogue-gravity perspective. The findings highlight the distinct importance of magnitude variations in exchange fields for nonadiabatic dynamics compared to directional variations in the adiabatic regime.

Abstract: We develop a unified theory for the nonadiabatic wave-packet dynamics of
Bloch electrons subject to slowly varying spatial and temporal perturbations.
Extending the conventional wave-packet ansatz to include interband
contributions, we derive equations for the interband coefficients using the
time-dependent variational principle, referred to as the wave-packet
coefficient equation. Solving these equations and integrating out interband
contributions yields the leading-order nonadiabatic corrections to the
wave-packet Lagrangian. These corrections appear in three forms: (i) a
nonadiabatic metric in real and momentum space, which we identify with the
energy-gap-renormalized quantum metric, (ii) modified Berry connections
associated with the motion of the wave-packet center, and (iii) an energy
correction arising from spatial and temporal variations of the Hamiltonian.
This metric reformulates the wave-packet dynamics as geodesic motion in phase
space, enabling an analogue-gravity perspective in condensed matter systems. As
an application, we analyze one-dimensional Dirac electron systems under a
slowly varying exchange field $\bm{m}$. Our results demonstrate that variations
in the magnitude of $\bm{m}$ are important to nonadiabatic dynamics, in sharp
contrast to the adiabatic regime where directional variations of $\bm{m}$ are
crucial.

</details>


### [586] [Reexamining Machine Learning Models on Predicting Thermoelectric Properties](https://arxiv.org/abs/2509.00299)
*Chung T. Ma,S. Joseph Poon*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习模型通过加入物理概念（如短程有序和晶体结构类别）来预测热电材料的ZT值，并取得了一定的精度提升，但仍无法区分稀释合金和浓缩合金。通过加入掺杂剂属性和使用遗传算法进行特征排序，模型在预测掺杂材料的ZT值方面表现更佳，并为设计热电材料提供了关键参数的物理解析。


<details>
  <summary>Details</summary>
Motivation: 为了提高发现高性能热电材料的效率，需要改进机器学习模型以更好地捕捉热电材料设计的潜在物理规律。

Method: 在机器学习模型中引入短程有序和晶体结构类别等物理概念，并包含各种掺杂剂属性作为特征。此外，使用遗传算法对特征进行排序。

Result: 加入物理概念后，模型的预测精度有所提高。加入掺杂剂属性后，模型在预测掺杂材料方面的精度进一步提高。遗传算法特征排序提供了关键参数的物理解析。

Conclusion: 结合物理概念、掺杂剂属性和遗传算法特征排序可以提高机器学习模型在热电材料设计中的预测能力和物理解析能力。

Abstract: Thermoelectric materials can generate clean energy by transforming waste heat
into electricity. The effectiveness of thermoelectric materials is measured by
the dimensionless figure of merit, ZT. The quest for high ZT materials has
drawn extensive research experimentally and theoretically. However, due to the
vast material space, finding high ZT materials is time-consuming and costly. To
improve the efficiency of discovering new thermoelectric materials, recent
studies have employed machine learning with databases to search for high ZT
candidates. In this work, we examine the effects of adding various physical
concepts on the performance of machine learning models in predicting TE
properties. The objective is to improve the model ability to capture the
underlying physics in designing TE materials. These concepts include short
range order and crystal structure class. Results show some improvements in
accuracy. However, the current models do not distinguish between dilute alloys
and concentrated alloys, rendering them inadequate in predicting doping
effects. To better capture the electronic band structure effect from doping, we
included various dopant properties as features. This increases the prediction
accuracy in doped materials. Furthermore, we used a genetic algorithm to rank
features for various thermoelectric properties to provide physical insight into
key parameters in designing thermoelectric materials.

</details>


### [587] [Free-carrier screening unlocks high electron mobility in ultrawide bandgap semiconductor CaSnO$_3$](https://arxiv.org/abs/2509.00307)
*Jiayi Gong,Chuanyu Zhang,Wenjie Hu,Jin-Jian Zhou*

Main category: cond-mat.mtrl-sci

TL;DR: CaSnO3是一种有潜力的透明导电氧化物，具有宽带隙和高迁移率，但其固有迁移率尚不清楚。通过从头计算，发现长程纵波光学声子散射是主要的限制因素，在高掺杂下由于自由载流子屏蔽效应会显著减弱，从而提高迁移率。尽管在载流子浓度高达10^20 cm^-3时，电离杂质散射是竞争机制，但声子散射的降低起主导作用，预测的室温迁移率约为目前最高实验报告的两倍。


<details>
  <summary>Details</summary>
Motivation: CaSnO3具有最宽的带隙，但其本征迁移率上限仍不清楚，报告的迁移率差异很大且高度依赖于样品。

Method: 使用最先进的方法，通过从头计算，明确考虑了自由载流子在电子-声子相互作用中的筛选效应，以计算不同温度和掺杂水平下CaSnO3的电子迁移率。

Result: 在高掺杂下，自由载流子屏蔽效应显著抑制了长程纵波光学声子散射，导致声子限制迁移率增强。在载流子浓度高达约10^20 cm^-3时，电离杂质散射是竞争机制，但声子散射的降低起主导作用，净迁移率增加，预测的室温值约为目前最高实验报告的两倍。

Conclusion: CaSnO3具有巨大的未开发导电性，可以作为透明和高功率电子应用的极宽带隙半导体。

Abstract: Alkaline earth stannates have emerged as promising transparent conducting
oxides due to their wide band gaps and high room-temperature electron
mobilities. Among them, CaSnO$_3$ possesses the widest band gap, yet reported
mobilities vary widely and are highly sample-dependent, leaving its intrinsic
limit unclear. Here, we present ab initio calculations of electron mobility in
CaSnO$_3$ across a range of temperatures and doping levels, using
state-of-the-art methods that explicitly account for free-carrier screening in
electron-phonon interactions. We identify the dominant limiting mechanism to be
the long-range longitudinal optical phonon scattering, which is significantly
suppressed at high doping due to free-carrier screening, leading to enhanced
phonon-limited mobility. While ionized impurity scattering emerges as a
competing mechanism at carrier concentrations up to ~10$^{20}$ cm$^{-3}$, the
phonon scattering reduction dominates, yielding a net mobility increase with
predicted room-temperature values reaching about twice the highest experimental
report. Our work highlights the substantial untapped conductivity in CaSnO$_3$,
establishing it as a compelling ultrawide bandgap semiconductor for transparent
and high-power electronic applications.

</details>


### [588] [Dimensional hierarchy of topological bound states in the continuum](https://arxiv.org/abs/2509.00344)
*Shunda Yin,Zhenyu Wang,Liping Ye,Hailong He,Manzhu Ke,Weiyin Deng,Jiuyang Lu,Zhengyou Liu*

Main category: cond-mat.mtrl-sci

TL;DR: 在三维声子晶体中发现了二维表面拓扑态（TBICs）和一维铰链态（TBICs）的共存现象，这是首次在单一系统中实现多维TBICs。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统边界态在连续谱中存在波泄漏和噪声的问题，探索基于拓扑边界态（TBICs）的鲁棒波操控。

Method: 实验上在三维声子晶体系统中，通过可分离性机制和谷陈数保护，实现了二维表面TBICs和一维铰链TBICs的共存。

Result: 成功观察到并验证了TBICs的维度分级现象，证明了其继承了谷拓扑的色散传播特性，并且能够抵抗缺陷而无泄漏地传播。

Conclusion: 该研究提供了一种实现多维TBICs的有效途径，为设计高效声学器件以在多维环境中实现波的捕获和操控提供了新的思路。

Abstract: Bound states in the continuum (BICs), with the ability of trapping and
manipulating waves within the radiation continuum, have gained significant
attention for their potential applications in optics and acoustics. However,
challenges arise in reducing wave leakage and noise from fabrication
imperfections. The emergence of robust wave manipulations based on topological
BICs (TBICs) offers promising solutions. Traditionally, TBICs of different
dimensions are observed separately in distinct systems. Here, we report the
experimental discovery of the coexistence of two-dimensional surface TBICs and
one-dimensional hinge TBICs in a single three-dimensional phononic crystal
system. Such an unprecedented dimensional hierarchy of TBICs is triggered by
the mechanism of separability and protected by the valley Chern numbers.
Notably, these TBICs inherit dispersive propagation characteristics from valley
topology and can propagate robustly against defects without leakage. Our
findings offer an efficient approach to multidimensional TBICs and can be
applied in designing highly efficient acoustic devices for wave trapping and
manipulation in multidimensional environments.

</details>


### [589] [Simulations of grain growth in tungsten armor materials under ARC plasma edge operation conditions using an integrated plasma-edge/materials model](https://arxiv.org/abs/2509.00350)
*Jinxin Yu,Nithin Mathew,Sophie Blondel,Ane Lasa,Jon Hillesheim,Lauren Garrison,Brian D. Wirth,Jaime Mariana*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究开发了一个二维顶点动力学模型，用于评估暴露于氘气中的多晶钨（W）的晶粒生长动力学，该模型考虑了晶界曲率和不同氘浓度累积的影响。


<details>
  <summary>Details</summary>
Motivation: 评估暴露于氘气中的多晶钨（W）的晶粒生长动力学。

Method: 开发了一个由两维顶点动力学模型组成的集成模型，该模型根据原子尺度数据进行拟合，以评估暴露于氘气中的多晶钨（W）的晶粒生长动力学。该模型跟踪晶界在晶界曲率和不同氘浓度累积产生的驱动力作用下的运动。

Result: 在与ARC概念设计一致的氘饱和条件下，模型显示在靠近等离子体的材料区域（1400 K，<100秒即可完全转变）存在快速的晶粒生长动力学，而在材料深处（1000 K下需要数天才能完成）微观结构保持稳定。模拟表明，在1000 K以上温度下，使用传统技术制造的整体钨将在任何驱动力存在的情况下极易发生晶粒生长。

Conclusion: 仿真表明，在1000 K以上温度下，整体钨将极易发生晶粒生长。

Abstract: An integrated model of grain growth deuterium-exposed tungsten polycrystals,
consisting of a two-dimensional vertex dynamics model fitted to atomistic data,
has been developed to assess the grain growth kinetics of deuterium-exposed
polycrystalline tungsten (W). The model tracks the motion of grain boundaries
under the effect of driving forces stemming from grain boundary curvature and
differential deuterium concentration accumulation. We apply the model to
experimentally-synthesized W polycrystals under deuterium saturated conditions
consistent with those of the ARC concept design, and find fast grain growth
kinetics in the material region adjacent to the plasma (at 1400 K, <100 seconds
for full transformation), while the microstructure is stable deep inside the
material (several days to complete at a temperature of 1000 K). Our simulations
suggest that monolithic W fabricated using conventional techniques will be
highly susceptible to grain growth in the presence of any driving force at
temperatures above 1000 K.

</details>


### [590] [Hidden ferromagnetism of centrosymmetric antiferromagnets](https://arxiv.org/abs/2509.00369)
*I. V. Solovyev*

Main category: cond-mat.mtrl-sci

TL;DR: 时间反演对称性破缺是铁磁性的标志，但也可以在某些反铁磁体（如弱铁磁体或阿尔特磁体）中观察到。本文提出，由于特殊的自旋-轨道相互作用，这些反铁磁态可以被视为最简单的铁磁态，仅需一个磁性位点。研究利用对称性分析和第一性原理计算，解释了反常霍尔效应和轨道磁性的出现，并给出了相应的表达式。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨时间反演对称性破缺的反铁磁态（如弱铁磁体或阿尔特磁体）是否可以被简化为仅包含一个磁性位点的最简单铁磁态，并解释其物理现象。

Method: 利用对称性分析，特别是空间反演和晶格平移的组合操作（自旋旋转+晶格移动），推导了自旋-轨道相互作用的形式，并将其与反常霍尔效应和轨道磁性联系起来。通过对二维方形晶格、单斜晶系VF4和CuF2以及四方晶系的RuO2等材料进行基于第一性原理计算的现实模型分析，验证了该理论。

Result: 发现了反铁磁态可以简化为单磁性位点模型，并给出了反常霍尔效应和轨道磁性的解析表达式，该表达式与电子跃迁、自旋-轨道相互作用和晶格应变有关。

Conclusion: 时间反演对称性破缺的反铁磁态可以通过单磁性位点模型来描述，这得益于晶格畸变导致的特殊自旋-轨道相互作用。该模型能够解释反常霍尔效应和轨道磁性的出现，并提供了这些现象的定量描述。

Abstract: The time-reversal symmetry ($\mathcal{T}$) breaking is a signature of
ferromagnetism, giving rise to such phenomena as the anomalous Hall effect
(AHE) and orbital magnetism (OM). Nevertheless, $\mathcal{T}$ can be also
broken in certain classes of antiferromagnets, such as weak ferromagnets or
altermagnets, which remain invariant under the spatial inversion. In the light
of this similarity with the ferromagnetism, it is tempting to ask whether such
anomalous antiferromagnetic (AFM) state can be presented as a simplest
ferromagnetic one, i.e. within a minimal unit cell containing only one magnetic
cite. We show that such presentation is possible due to the special form of the
spin-orbit (SO) interaction in an antiferroelectrically distorted lattice
hosting this AFM state. The inversion symmetry, combined with the lattice
translations, imposes a severe constraint on the form of the SO interaction,
which becomes invariant under the symmetry operation $\{ \mathcal{S}| {\bf t}
\}$, combining the $180^{\circ}$ rotation of spins ($\mathcal{S}$) with the
lattice shift ${\bf t}$, connecting antiferromagnetically coupled sublattices.
This is the fundamental symmetry property of centrosymmetric antiferromagnets,
which justifies the use of the generalized Bloch theorem and transformation to
the local coordinate frame with one magnetic cite per cell. It naturally
explains the emergence of AHE and OM, and provides transparent expressions for
these properties in terms of the electron hoppings and SO interaction operating
between nearest neighbors as well as the orthorhombic strain of the
next-nearest-neighbor hoppings. The idea is illustrated on a number of
examples, using realistic models derived from first-principles calculations.
These examples include two-dimensional square lattice, monoclinic VF$_4$ and
CuF$_2$, and RuO$_2$-type materials with the tetragonal symmetry.

</details>


### [591] [Conductive domain walls in ferroelectrics as tunable coherent THz radiation source](https://arxiv.org/abs/2509.01542)
*Ramaz Khomeriki,Kathrin Dörr,Jamal Berakdar*

Main category: cond-mat.mtrl-sci

TL;DR: BiFeO3中的THz发射源于红外辐射引起的导电流域中的电流，该现象由畴壁条带作为金属谐振器解释，电荷振荡发生在畴壁边缘，其频率与畴壁内的等离子体频率相关，并影响THz发射的频率和幅度，特定条件下还会出现非零的手性。


<details>
  <summary>Details</summary>
Motivation: 理论研究BiFeO3中由红外辐射引起的导电流域中的THz发射现象，并解释实验观察到的结果。

Method: 通过理论分析，将畴壁条带视为具有等离子体频率的金属谐振器，解释电荷振荡和THz发射的频率与幅度。

Result: 证明了THz发射的频率和幅度由畴壁内的等离子体频率决定，并且在特定畴壁结构和入射脉冲极化下，THz发射表现出非零手性。

Conclusion: BiFeO3中的THz发射与畴壁结构和等离子体频率密切相关，并可能表现出手性特征。

Abstract: THz emission associated with currents in conductive domains in BiFeO$_3$
following infrared radiation is theoretically investigated. This experimentally
observed phenomenon is explained by the domain wall stripes acting as metallic
resonators with the oscillating charge accumulation being at the domain wall
edges. The charge oscillation frequency is related to the plasma frequency
inside the domain wall. The value of plasma frequency determines both the
frequency and the amplitude of the emission emanating from the BiFeO$_3$
lattice. We show that for certain geometries of the domain wall structure and
for specific polarization of the incident pulse the THz emission embodies a
non-vanishing chirality.

</details>


### [592] [Role of lattice structure and breaking of antiferromagnetic spin order in enhancement of ferromagnetic, electronic, and magneto-electric properties in Fe$_{2-x}$Sc$_x$O$_3$ system](https://arxiv.org/abs/2509.00382)
*R. N. Bhowmik,Bipin Kumar Parida,Amit Kumar,P. D. Babu,S. M. Yusuf*

Main category: cond-mat.mtrl-sci

TL;DR: 通过掺杂Sc3+离子改变Fe2O3的磁结构和电学性质，实现了从绝缘到高导电状态的转变，并观察到巨大的负磁电导效应，有望应用于自旋电子器件。


<details>
  <summary>Details</summary>
Motivation: 探究非磁性Sc3+离子掺杂对α-Fe2O3基材料的晶格结构、磁自旋序和电荷-自旋耦合的影响，以期了解其修正的晶格结构、磁自旋序和电荷-自旋耦合。

Method: 通过改变Sc含量和热处理温度，将Fe2-xScxO3材料稳定在单相（菱面体α-Fe2O3）或混合相（菱面体α-Fe2O3和立方Sc2O3类型）结构中。利用中子衍射技术研究了其磁矩、自旋重取向和磁矫顽力。同时，测试了材料在不同温度下的电学性质（电导率和极化）以及在300K下的最大电流密度、铁电极化、磁电电压和磁电导。

Result: 掺杂Sc3+离子后，Fe2-xScxO3材料的晶格结构和磁自旋序发生改变，磁矩约为2.75-4.68 Bohr-magneton，并在低于Morin转变温度（约260K）时发生自旋重取向。材料的电学性质从绝缘状态转变为高导电状态，并且在300K时表现出大的铁电极化和负磁电导效应（高达90%）。

Conclusion: Fe2-xScxO3基材料通过掺杂Sc3+离子可以有效地调控其磁和电学性质，展现出优异的磁电耦合效应和负磁电导特性，为开发低功耗自旋电子器件提供了新的可能性。

Abstract: The strategy of breaking AFM ground state of alpha-Fe2O3 by doping
non-magnetic Sc3+ (3d0) ions at the Fe3+ (3d5) sites has been used to
understand modified lattice-structure, magnetic spin order, and charge-spin
coupling in Fe$_{2-x}$Sc$_x$O$_3$ system ($x =$ 0.2, 0.5, 1.0). The material
has been stabilized in single-phased (rhombohedral $\alpha$-Fe$_2$O$_3$) or
mix-phased (rhombohedral alpha-Fe$_2$O$_3$ and cubic Sc$_2$O$_3$-types)
structures by varying the Sc content and heat treatment temperature. Neutron
diffraction confirmed magnetic moment approximately 2.75-4.68 Bohr-magneton per
Fe site and spin reorientation from in-plane to out of plane direction below
the Morin transition approximately 260 K. The material showed magnetic
coercivity (0.2 to 6 kOe). The electrical properties transformed from
insulating state (conductivity 10-14-10-10 S/cm and polarization 0.5-2
micro-C/cm$^2$) to high conductive state (conductivity approximately 10-10
-10-7 S/cm and polarization greater than 2 micro-C/cm$^2$) above Morin
transition. The material at 300 K produced the maximum current density 20-95
micro-A/cm$^2$, ferroelectric polarization 2.7-15.6 micro-C/cm$^2$, ME voltage
up to 5 mV with coupling coefficient 0.53 mV/Oe/cm and huge negative
magnetoconductance up to 90%. The results in the present hematite based canted
ferromagnetic materials are expected to be useful for applying in low power
spintronic devices.

</details>


### [593] [Direct spatiotemporal imaging of a long-lived bulk photovoltaic effect in $BiFeO_{3}$](https://arxiv.org/abs/2509.01729)
*Saptam Ganguly,Sebin Varghese,Aaron M. Schankler,Xianfei Xu,Kazuki Morita,Michel Viret,Andrew M. Rappe,Gustau Catalan,Klaas-Jan Tielrooij*

Main category: cond-mat.mtrl-sci

TL;DR: 本文利用接触式泵浦-探测显微镜研究了单晶、单畴BiFeO3中光生载流子的空间和时间分辨动力学，观察到载流子沿极轴的非对称输运，证实了BPVE的体源性质。该非对称输运持续数纳秒，不能用常规的BPVE机制解释。通过蒙特卡罗模拟和第一性原理计算，发现氧空位缺陷在非平衡条件下引起的不对称动量散射是导致长寿命载流子漂移的原因，并确认了氧空位具有可能引起不对称散射的不对称电子态。


<details>
  <summary>Details</summary>
Motivation: BPVE作为一种宏观效应，其观测信号是否真正源于体材料一直存在争议，因为其测量通常依赖于界面和金属接触。

Method: 本文采用非接触式泵浦-探测显微镜技术，并结合蒙特卡罗模拟和第一性原理计算。

Result: 观察到光生载流子沿极轴的非对称输运，证实了BPVE的体源性质。该非对称输运持续数纳秒，不能用常规的BPVE机制解释。氧空位缺陷在非平衡条件下引起的不对称动量散射是导致长寿命载流子漂移的原因。

Conclusion: 氧空位缺陷在长寿命光响应中扮演着关键角色，并揭示了其不对称电子态是引起非对称散射的机制。

Abstract: The bulk photovoltaic effect (BPVE), a manifestation of broken
centrosymmetry, has attracted interest as a probe of the symmetry and quantum
geometry of materials, and for use in novel optoelectronic devices. Despite its
bulk nature, the BPVE is typically measured with interfaces and metal contacts,
raising concerns as to whether the observed signals are genuinely of bulk
origin. Here, we use a contactless pump-probe microscopy method to observe the
space- and time-resolved dynamics of photoexcited carriers in single-crystal,
monodomain $BiFeO_{3}$. We observe asymmetric transport of carriers along the
polar axis, confirming the intrinsic bulk and symmetry-driven nature of BPVE.
This asymmetric transport persists for several nanoseconds after
photoexcitation, which cannot be explained by the shift or phonon ballistic
current BPVE mechanisms. Monte Carlo simulations show that asymmetric momentum
scattering by defects under non-equilibrium conditions explains the long-lived
carrier drift, while first principles calculations confirm that oxygen
vacancies have an asymmetric electronic state that can cause such asymmetric
scattering. Our findings highlight the critical role of defects in long-lived
photoresponses.

</details>


### [594] [Recent Advances in Unconventional Ferroelectrics and Multiferroics](https://arxiv.org/abs/2509.00384)
*Hongyu Yu,Junyi Ji,Wei Luo,Xingao Gong,Hongjun Xiang*

Main category: cond-mat.mtrl-sci

TL;DR: 对非传统铁电系统（包括基于Hf的铁电体、层状铁电体、极性金属、分数量子铁电体、纤锌矿型铁电体和独立膜铁电体）进行了系统性回顾，并讨论了新兴铁电材料在纳米电子和自旋电子学中的应用前景，同时审视了多铁性材料、新颖磁态与铁电性的相互作用以及铁谷-铁电耦合，最后指出了该领域的挑战与机遇。


<details>
  <summary>Details</summary>
Motivation: 新兴铁性材料因其独特的物理性质，可能为下一代纳米电子和自旋电子器件开辟新途径。

Method: 系统性回顾了非传统铁电系统，包括基于Hf的铁电体、层状铁电体、极性金属、分数量子铁电体、纤锌矿型铁电体和独立膜铁电体。此外，还回顾了多铁性材料，特别是新颖磁态与铁电性的相互作用以及铁谷-铁电耦合。

Result: 对非传统铁电系统和多铁性材料进行了回顾，并讨论了它们在下一代电子器件中的潜力。

Conclusion: 该领域仍面临挑战，但也存在许多未来机遇。

Abstract: Emerging ferroic materials may pave a new way to next-generation
nanoelectronic and spintronic devices due to their interesting physical
properties. Here, we systematically review unconventional ferroelectric
systems, from Hf-based and elementary ferroelectrics to stacking
ferroelectricity, polar metallicity, fractional quantum ferroelectricity,
wurtzite-type ferroelectricity, and freestanding membranes ferroelectricity.
Moreover, multiferroic materials are reviewed, particularly the interplay
between novel magnetic states and ferroelectricity, as well as
ferrovalley-ferroelectric coupling. Finally, we conclude by discussing current
challenges and future opportunities in this field.

</details>


### [595] [Quantitative and bond-traceable resonant X-ray optical tensors of organic molecules](https://arxiv.org/abs/2509.01734)
*Victor Murcia,Obaid Alqahtani,Harlan Heilman,Brian A. Collins*

Main category: cond-mat.mtrl-sci

TL;DR: X射线散射分析有机纳米结构中的化学键和取向，通过结合密度泛函理论计算和角度分辨吸收光谱测量，开发了一种新的光学模型，实现了无标记的取向分析。


<details>
  <summary>Details</summary>
Motivation: X射线散射在碳吸收边对有机纳米结构中的局部分子键特性和取向具有独特的敏感性，但缺乏精确的、具有键和取向特异性的光学模型阻碍了定量分析。

Method: 通过算法参数化和精炼密度泛函理论计算，并结合角度分辨吸收光谱测量来生成光学模型。

Result: 该光学张量能够重现具有不同取向和晶体堆积的样品数据，实现了使用共振X射线对分子纳米结构中单个化学基元的无标记取向分析。

Conclusion: 所开发的光学模型通过结合理论计算和实验测量，能够实现对分子纳米结构中化学键和取向的精确分析，为无标记表征提供了新的方法。

Abstract: X-ray scattering at the carbon absorption edge is uniquely sensitive to local
molecular bond identity and orientation in organic nanostructures, encoded as a
function of photon energy and polarization. However, quantitative analysis is
precluded due to the lack of accurate optical models with bond and orientation
specificity. We generate such a model through an algorithm that parameterizes
and refines density functional theory calculations with angle-resolved
absorbance spectroscopy measurements. The resulting optical tensor is shown to
reproduce data from samples with domains of different orientation and
crystalline packing, enabling label-free orientation analyses of individual
chemical moieties within molecular nanostructures using resonant X-rays.

</details>


### [596] [Stabilization of Ferroelectric Hafnia and Zirconia through Y2O3 doping](https://arxiv.org/abs/2509.00393)
*Li Yin,Cong Liu,R. E. Cohen*

Main category: cond-mat.mtrl-sci

TL;DR: Y2O3掺杂可以稳定氧化铪和氧化锆中的铁电相。


<details>
  <summary>Details</summary>
Motivation: 研究钇氧化物掺杂对氧化铪和氧化锆铁电稳定性的影响。

Method: 使用密度泛函理论（DFT）和大型随机超晶胞，比较了立方相、单斜相和斜方铁电相等相对相稳定性。

Result: Y2O3掺杂稳定了氧化铪和氧化锆中的铁电斜方相，使其相对于单斜相更稳定。

Conclusion: Y2O3掺杂是稳定氧化铪和氧化锆铁电性的有效方法。

Abstract: We investigate the possible stabilization of ferroelectricity in bulk
Y2O3-doped hafnia and zirconia. We use density functional theory (DFT) with
large random supercells of hafnia and zirconia and study the relative phase
stability of the centrosymmetric cubic and monoclinic phases compared with the
polar orthorhombic phase. We find that Y2O3-doping stabilizes the polar
ferroelectric phase over the monoclinic baddeleyite phase in both hafnia and
zirconia.

</details>


### [597] [High-quality Tungsten-doped Vanadium Dioxide Thin Films Fabricated in an Extremely Low-oxygen Furnace Environment](https://arxiv.org/abs/2509.01956)
*Vishwa Krishna Rajan,Ken Araki,Robert Y. Wang,Liping Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究报告了一种通过在极低氧气（5至20 ppm）中进行高温退火和高真空（1 mPa）还原表面过氧化物，来溅射钨-钒合金薄膜制备高质量钨掺杂二氧化钒（WxV1-xO2，x = 0~3 at.%）的方法。


<details>
  <summary>Details</summary>
Motivation: 为了提高钒氧化物（VO2）薄膜的质量和改善其绝缘体-金属（IMT）相变行为，以满足热和能源应用的需求。

Method: 首先优化了制备高质量无掺杂VO2薄膜的氧化参数（温度、时间、氮气纯化速率）。然后，通过在极低氧气（5-20 ppm）和高真空（1 mPa）条件下进行高温退火和真空还原，制备了钨掺杂的VO2薄膜。使用温度依赖的光谱红外透过率和电阻率测量来表征相变行为。使用掠入射X射线衍射确认了没有高价氧化物。通过X射线光电子能谱测量钨的原子百分比，并研究了热退火和真空还原对钨掺杂VO2薄膜的影响，以找到最佳的制备条件。

Result: 与在富氧环境中制备的VO2薄膜相比，在低氧环境中制备的VO2薄膜具有更高的红外透过率变化（15%）和电阻率变化（额外1个数量级）。优化的钨掺杂VO2薄膜的IMT温度比无掺杂的VO2薄膜降低了23°C/at.%（无掺杂时为68°C）。

Conclusion: 该研究提出了一种低成本、可扩展的制备高质量钨掺杂VO2薄膜的方法，该方法通过在极低氧气环境中进行优化，可以显著改善薄膜的相变行为，并能有效调控IMT温度，为在热和能源领域的应用提供了可行性。

Abstract: This work reports the fabrication and characterization of high-quality
tungsten-doped vanadium dioxide (WxV1-xO2, x = 0~3 at. %) by thermal oxidation
of sputtered tungsten-vanadium alloyed thin films with different atomic
percentages and high-temperature annealing in an extremely low oxygen
atmosphere (5 to 20 ppm) along with reduction of surface over-oxides in high
vacuum (1 mPa). Oxidation parameters such as temperature, time and nitrogen
purging rate are first optimized for obtaining high quality undoped VO2 thin
film. Insulator-to-metal (IMT) phase transition behavior of VO2 thin films
fabricated in a low-O2 environment is characterized with temperature dependent
spectral infrared transmittance and electrical resistivity measurements, where
there is 15% higher infrared transmittance change and additional 1 order change
in resistivity in comparison with VO2 thin films fabricated in a O2-rich
environment. Grazing angle X-ray diffraction scan confirms no presence of
higher oxides in the VO2 oxidized in low-O2 environment, which improves its
quality significantly. Comprehensive studies on thermal annealing and vacuum
reduction for tungsten doped VO2 thin films are also carried out to find the
optimal fabrication conditions. With the tungsten at. % measured by X-ray
photoelectron spectroscopy, the optimal WVO2 thin films fabricated through this
streamlined oxidation, annealing and reduction processes in extremely low-O2
furnace environment exhibit lowered IMT temperature at -23{\deg}C per at.% of
tungsten dopants from 68{\deg}C without doping. This low-cost and scalable
fabrication method could facilitate the wide development of tunable WVO2
coatings in thermal and energy applications.

</details>


### [598] [From diamond to BC8 to simple cubic and back: kinetic pathways to post-diamond carbon phases from metadynamics](https://arxiv.org/abs/2509.00423)
*Roman Martoňák,Sergey Galitskiy,Azat Tipeev,Joseph M. Gonzalez,Ivan I. Oleynik*

Main category: cond-mat.mtrl-sci

TL;DR: 在超高压下，立方和六方金刚石会转变为后金刚石相（BC8或简单立方相）。


<details>
  <summary>Details</summary>
Motivation: 在超高压下，金刚石向后金刚石相的转变机制尚不清楚。

Method: 使用元动力学、基于配位数序参量和SNAP机器学习势能，研究了金刚石向后金刚石相的转变。

Result: 发现金刚石在1.5 TPa以上转变为后金刚石相，转变过程是均匀成核，生成液滴，然后结晶为BC8（<1.8 TPa）或简单立方相（>2.1 TPa）。确定了合成BC8的有利条件（~1.8 TPa，3500-5000 K）。模拟了从简单立方相和BC8相减压的路径，并发现了一种新的亚稳态低焓P222结构。

Conclusion: 为在极端条件下实验发现超密碳相提供了理论基础。

Abstract: The experimental observation of elusive post-diamond carbon phases at extreme
pressures remains a major challenge in high-pressure science. Using
metadynamics with coordination-number-based collective variables and SNAP
machine-learned interatomic potential, we uncover atomistic mechanisms
governing the transformation of cubic and hexagonal diamond into post-diamond
phases above 1.5 TPa. The transition initiates via homogeneous nucleation of
nanoscale liquid droplets, which rapidly crystallize into either BC8 (below 1.8
TPa) or simple cubic phases (above 2.1 TPa), once the liquid nucleus surpasses
a critical size. Favorable conditions for synthesizing BC8 are identified near
1.8 TPa and 3500--5000 K. Decompression pathways from simple cubic and BC8
phases were also simulated to study possible experimental recovery of
post-diamond carbon allotropes at ambient conditions. We also find a new
metastable low-enthalpy structure with four-coordinated carbon atoms and space
group P222. Our insights provide a theoretical foundation for experimental
discovery of ultra-dense carbon phases under extreme conditions.

</details>


### [599] [Improving atomic force microscopy structure discovery via style-translation](https://arxiv.org/abs/2509.02240)
*Jie Huang,Niko Oinonen,Fabio Priante,Filippo Federici Canova,Lauri Kurki,Chen Xu,Adam S. Foster*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用风格迁移技术来缩小模拟与实验原子力显微镜（AFM）图像之间的差距，以提高机器学习模型在表面性质分析中的预测性能，特别是在缺乏标注实验数据的情况下。


<details>
  <summary>Details</summary>
Motivation: 将机器学习模型从模拟AFM图像转移到实验AFM图像面临挑战，因为真实实验数据与模拟数据之间存在细微差异。本研究旨在通过风格迁移来解决这一问题，以增强机器学习模型在表面性质分析中的性能。

Method: 本研究探索使用风格迁移技术来增强模拟AFM图像，以缩小模拟与实验AFM图像之间的风格差距，并评估其对机器学习模型在表面性质分析中预测性能的提升效果，通过比较局部结构性质分布来验证方法的有效性。

Result: 通过风格迁移技术，成功缩小了模拟与实验AFM图像之间的风格差距，并证明了该方法能有效提升机器学习模型在表面性质分析中的性能，特别是在结构发现方面。

Conclusion: 本研究提出了一种在缺乏标注实验数据的情况下提高机器学习模型效率的新方法，通过风格迁移技术增强模拟数据，缩小与真实实验数据的差距，从而提升模型的预测能力。

Abstract: Atomic force microscopy (AFM) is a key tool for characterising nanoscale
structures, with functionalised tips now offering detailed images of the atomic
structure. In parallel, AFM simulations using the particle probe model provide
a cost-effective approach for rapid AFM image generation. Using
state-of-the-art machine learning models and substantial simulated datasets,
properties such as molecular structure, electrostatic potential, and molecular
graph can be predicted from AFM images. However, transferring model performance
from simulated to experimental AFM images poses challenges due to the subtle
variations in real experimental data compared to the seemingly flawless
simulations. In this study, we explore style translation to augment simulated
images and improve the predictive performance of machine learning models in
surface property analysis. We reduce the style gap between simulated and
experimental AFM images and demonstrate the method's effectiveness in enhancing
structure discovery models through local structural property distribution
comparisons. This research presents a novel approach to improving the
efficiency of machine learning models in the absence of labelled experimental
data.

</details>


### [600] [Sliding-induced ferrovalley polarization and possible antiferromagnetic half-metal in bilayer altermagnets](https://arxiv.org/abs/2509.00430)
*Xin Zhang,Shihao Zhang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过层间滑动在工程双层反磁体中实现自发破裂的谷简并，打开了铁谷相，并在V2SSeO工程双层中实现了无外加电场驱动的 antiferromagnetic half-metal。


<details>
  <summary>Details</summary>
Motivation: 现有的单层反磁体在布里渊区的高对称X和Y点保持简并的能带隙，表现出非极化的谷态。本研究旨在探索打破这种谷简并的方法。

Method: 利用第一性原理计算和最小微观模型，研究了工程M2A2B和M2AA'B双层反磁体中的层间滑动效应。

Result: 通过层间滑动，工程双层反磁体实现了自发破裂的谷简并，并可能产生铁谷相和反铁磁半金属。在V2SSeO工程双层中观察到了这种现象。Mo2O2O具有最大的谷分裂能隙（约0.31 eV），Mo2AA'O材料中A和A'位原子原子序数差（ΔZ）的增加有效增强了谷极化。

Conclusion: 本工作为在反磁性系统中发现和控制铁谷态提供了一个新的平台。

Abstract: Altermagnets, a newly discovered class of materials, exhibit zero net
magnetization while hosting spin-split electronic bands. However, monolayer
altermagnets maintain degenerate band gaps at the high-symmetry X and Y points
in the Brillouin zone, manifesting a paravalley phase characterized by
unpolarized valley states. In this work, we demonstrate that spontaneously
broken valley degeneracy can be achieved through interlayer sliding in
engineered M$_2$A$_2$B and M$_2$AA$'$B bilayer altermagnets by first-principles
calculations and minimal microscopic model. We propose a promising route to
achieve antiferromagnetic half-metal driven by sliding and emergent ferrovalley
phase without applied electric field, which is realized in the V$_2$SSeO
engineered bilayer. Our calculations also reveal that Mo$_2$O$_2$O exhibits the
largest valley splitting gap of ~0.31 eV, making it a promising candidate for
valley-spin valve devices. Furthermore, band structure calculations on
Mo$_2$AA$'$O materials demonstrate that increasing the difference in atomic
number ($\Delta$Z) between A and A$'$ site atoms effectively enhances valley
polarization. This work establishes a novel platform for discovering and
controlling ferrovalley states in altermagnetic systems.

</details>


### [601] ["One defect, one potential" strategy for accurate machine learning prediction of defect phonons](https://arxiv.org/abs/2509.00498)
*Junjie Zhou,Xinpeng Li,Menglin Huang,Shiyou Chen*

Main category: cond-mat.mtrl-sci

TL;DR: 通过训练一个“一种缺陷，一种势”的机器学习势（MLIP），我们实现了高效且精确的缺陷声子计算，其精度可与密度泛函理论（DFT）相媲美，同时计算成本降低了一个数量级以上。


<details>
  <summary>Details</summary>
Motivation: 精确的声子计算对于理解缺陷系统中的电子跃迁至关重要，但传统的基于第一性原理的大型超胞计算成本高昂，限制了其应用。机器学习势（MLIPs）作为一种潜在的替代方案，但其精度不足以满足高级缺陷声子计算的需求。

Method: 提出一种“一种缺陷，一种势”的策略，即在有限的扰动超胞数据集上训练MLIP，以实现对特定缺陷的高精度声子计算。

Result: 所提出的策略能够获得与密度泛函理论（DFT）相当的声子精度，且不受超胞尺寸影响。基于该特定缺陷的模型计算的光致发光（PL）光谱和非辐射捕获率与DFT结果吻合良好，同时计算成本降低了一个数量级以上。

Conclusion: 该方法为在高精度和高效率下研究大至10^4个原子的超胞中的缺陷声子提供了实用的途径。

Abstract: Atomic vibrations play a critical role in phonon-assisted electron
transitions at defects in solids. However, accurate phonon calculations in
defect systems are often hindered by the high computational cost of
large-supercell first-principles calculations. Recently, foundation models,
such as universal machine learning interatomic potentials (MLIPs), emerge as a
promising alternative for rapid phonon calculations, but the quantitatively low
accuracy restricts its fundamental applicability for high-level defect phonon
calculations, such as nonradiative carrier capture rates. In this paper, we
propose a "one defect, one potential" strategy in which an MLIP is trained on a
limited set of perturbed supercells. We demonstrate that this strategy yields
phonons with accuracy comparable to density functional theory (DFT), regardless
of the supercell size. The predicted accuracy of defect phonons is validated by
phonon frequencies, Huang-Rhys factors, and phonon dispersions. Further
calculations of photoluminescence (PL) spectra and nonradiative capture rates
based on this defect-specific model also show good agreements with DFT results,
meanwhile reducing the computational expenses by more than an order of
magnitude. Our approach provides a practical pathway for studying defect
phonons in 10$^4$-atom large supercell with high accuracy and efficiency.

</details>


### [602] [Magnetic dynamics in NiTiO3 honeycomb antiferromagnet using neutron scattering](https://arxiv.org/abs/2509.00513)
*Srimal Rathnayaka,Luke Daemen,Tao Hong,Songxue Chi,Stuart Calder,John A. Schneeloch,Yongqiang Cheng,Bing Li,Despina Louca*

Main category: cond-mat.mtrl-sci

TL;DR: ilmenite NiTiO3 的磁结构和动力学研究表明，其具有高度各向异性的 Heisenberg 模型，具有比平面内铁磁相互作用更强的平面外反铁磁相互作用，以及 0.95 meV 的各向异性能隙。


<details>
  <summary>Details</summary>
Motivation: 研究 ilmenite NiTiO3 的磁结构和动力学，理解其磁相互作用和各向异性。

Method: 使用中子谱学，研究温度对磁结构和动力的影响，并使用高度各向异性的 Heisenberg 模型进行描述。

Result: 发现了色散声学能带和接近色散的 ~3.7 meV 的光学能带。临界指数介于 Heisenberg 和二维 Ising 模型之间，与高度各向异性的 Heisenberg 系统一致。挫折参数 ~ 2 支持该系统是弱挫折系统。

Conclusion: ilmenite NiTiO3 是一个高度各向异性的 Heisenberg 系统，其磁行为可以通过考虑平面外反铁磁相互作用、平面内铁磁相互作用和各向异性能隙的模型来解释。

Abstract: The ilmenite NiTiO3 consists of a buckled honeycomb lattice, with the Ni
spins aligned ferromagnetically in-plane and antiferromagnetically
out-of-plane. Using neutron spectroscopy, the magnetic structure and the
dynamics were investigated as a function of temperature. Dispersive acoustic
bands and nearly dispersionless optical bands at ~3.7 meV are described by a
highly anisotropy Heisenberg model with stronger antiferromagnetic (AFM)
out-of-plane, weaker ferromagnetic (FM) in-plane interactions and an anisotropy
gap of 0.95 meV. The order parameter yields a critical exponent between the
Heisenberg and two-dimensional Ising models, consistent with highly anisotropic
Heisenberg systems. The frustration parameter ~ 2 supports a weakly frustrated
system.

</details>


### [603] [Unveiling Insulating Ferro and Ferrimagnetism in Double-Double Perovskite Oxides](https://arxiv.org/abs/2509.00542)
*Monirul Shaikh,Fengyi Zhou,Sathiyamoorthy Buvaneswaran,Rajan Gowsalya,Trilochan Sahoo,Duo Wang,Saurabh Ghosh*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究预测了具有绝缘铁磁和亚铁磁行为的 LaA'MnNiO6 (A' = V, Cr, Mn, Co, Ni) 双层钙钛矿氧化物，这些材料在自旋电子学和光学领域具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 在绝缘材料中出现铁磁和亚铁磁行为通常是罕见的，这主要是由于洪德规则。本研究旨在利用对称性分析、第一性原理方法和经典蒙特卡洛模拟来预测和解释具有潜在应用价值的绝缘铁磁和亚铁磁双层钙钛矿氧化物。

Method: 利用对称性分析、第一性原理计算和经典蒙特卡洛模拟。

Result: 研究预测了 LaA'MnNiO6 (A' = V, Cr, Mn, Co, Ni) 具有 1.3 eV 到 1.9 eV 的带隙，适用于自旋电子学和光学应用。研究解释了驱动带隙打开和磁交换相互作用的机制，并揭示了高达 242 K 的磁转变温度和相应的交换机制。

Conclusion: LaA'MnNiO6 化合物因其绝缘铁磁和亚铁磁特性、合适的带隙以及可调的磁性质，在自旋电子学和光学应用方面显示出巨大的潜力。研究还评估了这些化合物的热力学和动力学稳定性，以确定其可行性。

Abstract: The emergence of ferro- and ferrimagnetic behavior in insulating materials is
uncommon, largely due to Hund's rules. Utilizing symmetry analysis,
first-principles methods, and classical Monte Carlo simulations,
\textcolor{black}{we report technologically important insulating ferro and
ferrimagnetic double-double perovskite oxides. Our study predicts
LaA$^{\prime}$MnNiO$_6$ (A$^{\prime}$ = V, Cr, Mn, Co, and Ni) as promising
candidates for spintronic and optical applications exhibiting band gaps between
1.3 eV and 1.9 eV. We explain the mechanisms driving band gap openings and
magnetic exchange interactions in these ferro and ferrimagnetic compounds.
Monte Carlo simulations, together with state-of-the-art orbital-decomposed
exchange parameter analysis, reveal intriguing variations in magnetic
transition temperatures (up to 242 K) and the corresponding exchange mechanisms
in all LaA$^{\prime}$MnNiO$_6$ compounds.} In addition, we assess the
thermodynamic and dynamic stability of these compounds to comment on the
feasibility of these systems.

</details>


### [604] [Surface Effects on the Magnetocrystalline Anisotropy of IrMn$_3$](https://arxiv.org/abs/2509.00620)
*Robert A. Lawrence,Matt I. J. Probert*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文研究了IrMn/Fe界面的磁各向异性，特别是不同IrMn终止面对磁各向异性的影响，并解释了其原因。


<details>
  <summary>Details</summary>
Motivation: 研究磁各向异性参数在IrMn/Fe异质结构中交换偏置效应中的关键作用。

Method: 使用显式密度泛函计算IrMn/Fe界面的磁结构，并评估了IrMn的几种终止面的磁各向异性。

Result: 计算发现[111]表面具有1.62 meV/Å²的垂直各向异性，而两种[100]表面（富Ir和富Mn）分别具有0.13 meV/Å²和1.39 meV/Å²的面内各向异性。

Conclusion: 计算所得的磁序容易和困难构型影响了各向异性的相对值。

Abstract: Magnetic anisotropy is a key parameter to describe the exchange bias effect
in heterostructures. In this paper, we describe explicit density functional
calculations of the magnetic structure of an interface between the industrially
critically antiferromagnetic material, IrMn, and Fe, which together form a
simple ferromagnet-antiferromagnet heterostructure. Additionally, the magnetic
anisotropy was evaluated for several terminations of the IrMn. It was found
that the [111] surface had a perpendicular anisotropy of 1.62
meV/$\text{\AA}^2$, whereas the two possible [100] surfaces (Ir-rich and
Mn-rich) had in-plane anisotropies of 0.13 meV/$\text{\AA}^2$ and 1.39
meV/$\text{\AA}^2$ respectively. The affect of the magnetic order of the easy
and hard configurations were calculated and used to explain the relative values
of the anisotropies.

</details>


### [605] [Domain-Wall Mediated Polarization Switching in Ferroelectric AlScN: Strain Relief and Field-Dependent Dynamics](https://arxiv.org/abs/2509.00705)
*Xiangyu Zheng,Charles Paillard,Dawei Wang,Peng Chen,Hong Jian Zhao,Yu Xie,Laurent Bellaiche*

Main category: cond-mat.mtrl-sci

TL;DR: Sc掺杂氮化铝（AlScN）虽然具有铁电性，但因其高矫顽场而受到限制。本研究结合密度泛函理论和机器学习分子动力学，研究了AlScN的极化切换机制，发现预先存在的畴壁缓解了应变，并导致了不同的切换动力学，且切换机制与场强有关：低场下为逐渐畴壁传播，高场下为形核事件触发的快速均匀翻转。


<details>
  <summary>Details</summary>
Motivation: 理解AlScN的原子尺度切换机制对于降低其高矫顽场（Ec）至关重要，以促进其在铁电器件中的实际应用。

Method: 结合密度泛函理论（DFT）和机器学习分子动力学（MLMD）来研究不同Sc浓度和外加电场下的AlScN极化切换机制。

Result: 研究发现，集体切换因诱导过度的晶格应变而不太可能发生。相反，预先存在的畴壁能够缓解应变，并导致一种独特的、与场相关的切换动力学。具体来说，在低电场下，切换通过逐渐的畴壁传播进行，符合Kolmogorov-Avram-Ishibashi模型；而在高电场下，会触发额外的形核事件，产生快速且更均匀的翻转，这一混合切换过程更符合非线性形核与生长模型。

Conclusion: 畴壁动力学在氮化物铁电器件中起着关键作用，而畴工程是控制矫顽场和提高器件性能的可行途径。

Abstract: Aluminum nitride is a traditional wide-bandgap semiconductor that has been
widely used in high-power electronic and optoelectronic devices. Recently,
scandium-doped aluminum nitride (AlScN) was shown to host ferroelectricity with
high remnant polarization and excellent thermal stability. However, its
practical use is currently limited by its high coercive field, $E_c$.
Understanding the atomic-scale switching mechanism is essential to guide
strategies for reducing $E_c$. Here, we combine density functional theory and
machine-learning molecular dynamics to investigate polarization switching
mechanisms in AlScN over various Sc concentrations and applied electric fields.
We find that collective switching induces excessive lattice strain and is
therefore unlikely to occur. Rather, pre-existing domain walls relieve strain
and lead to a distinct switching dynamics, with the associated switching
mechanism being field dependent. More precisely, at low electric fields,
switching proceeds via gradual domain-wall propagation, well described by the
Kolmogorov-Avram-Ishibashi model; meanwhile high fields trigger additional
nucleation events, producing rapid and more homogeneous reversal, whose mixed
switching process is better described by the simultaneous non-linear nucleation
and growth model. These findings highlight the critical role of domain-wall
dynamics in nitride ferroelectrics and suggest that domain engineering provides
a viable route to control coercive fields and enhance device performance.

</details>


### [606] [First principles study on the oxidation resistance of two-dimensional intrinsic and defective GeO2](https://arxiv.org/abs/2509.00756)
*Xixiang Zhang,Xinmei Yu,Liang Ma,Yanfeng Ge,Yong Liu,Wenhui Wan*

Main category: cond-mat.mtrl-sci

TL;DR: GeO${_2}$单层（ML）具有优异的抗氧化性，这归因于表面氧离子与O$_2$分子之间的静电排斥。然而，表面氧空位会削弱其抗氧化性，但氧化过程会自我限制。高温和低O$_2$压力会促进氧化。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究二维（2D）氧化物半导体（特别是GeO${_2}$单层）的原子尺度氧化机制，以解释其优异的抗氧化性。

Method: 采用第一性原理计算，研究了GeO${_2}$单层的缺陷形成和氧化动力学。

Result: 结果表明，本征GeO${_2}$单层由于静电排斥作用而抗氧化。表面氧空位会降低抗氧化性，但氧化是自我限制的（O$_2$解离需要高激活能）。氧化主要影响价带，而导带和电子有效质量几乎不受影响。高O$_2$压力阻碍空位形成，高温则加速氧化。

Conclusion: 本研究揭示了GeO${_2}$单层的原子尺度氧化机制，为开发稳定的GeO${_2}$基纳米电子器件提供了指导。

Abstract: Although two-dimensional (2D) oxide semiconductors exhibit remarkable
oxidation resistance compared to conventional 2D materials, the microscopic
physical processes that govern this behavior at the atomic scale remains
elusive. Using first-principles calculations, we investigated the defect
formation and oxidation dynamics of the GeO${_2}$ monolayer (ML). The
investigations reveal that the intrinsic GeO${_2}$ ML is resistant to oxidation
due to strong electrostatic repulsion between surface oxygen ions and
approaching O$_2$ molecules, effectively suppressing chemisorption. In
contrast, defective GeO$_2$ ML with surface O vacancies shows vulnerability to
oxidation with the O$_2$ molecule occupying the vacancy through a low-energy
activation energy ($E_a$) of 0.375 eV. Remarkably, the subsequent O$_2$
dissociation into atomic species faces a higher activation barrier ($E_a$ =
1.604 eV), suggesting self-limiting oxidation behavior. Electronic structure
analysis demonstrates that oxidation primarily modifies the valence bands of
defective GeO${_2}$ MLs through oxygen incorporation, while the conduction
bands and electron effective mass recover to pristine-like characteristics. We
further proved that the high O$_2$ pressure hinders the formation of the O
vacancy, while high temperature increases the oxidation rate in GeO$_2$ ML.
These atomic-level insights not only advance our understanding of oxidation
resistance in 2D oxides but also provide guidelines for developing stable
GeO${_2}$-based nanoelectronic devices.

</details>


### [607] [Integration of promising piezoelectric and photocatalytic properties in Janus In$XY$ ($X$ = S, Se, Te; $Y$ = Cl, Br, I) monolayers and their heterojunctions](https://arxiv.org/abs/2509.00759)
*Xinyue Liu,Ziqiang Li,Yanfeng Ge,Yong Liu,Xing Wang,Wenhui Wan*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Two-dimensional (2D) Janus materials show great promise as piezoelectric
materials and photocatalysts for water splitting. In this work, we
systematically investigated the piezoelectric and photocatalytic properties of
the hexagonal Janus InXY (X = S, Se, Te; Y = Cl, Br, I) monolayers (MLs) using
first-principles calculations. Except for InSeCl ML, the remaining eight InXY
MLs are stable and exhibit exceptionally high in-plane piezoelectric
coefficients ($|d_{22}| = $6.07--155.27 pm/V), which exceed those of most known
2D materials. InXY MLs possess band edges straddling the water redox potentials
at pH = 0. Their intrinsic vertical polarization induces an intralayer
polarization field $E_{\rm intra}$, leading to low exciton binding energies
(0.44--0.78 eV). Moreover, their strong vertical piezoelectric responses
($|d_{32}|$ = 0.34--0.65 pm/V) suggest that in-plane stress can further enhance
$E_{\rm intra}$ to facilitate the separation of photogenerated carriers.
Additionally, these InXY MLs exhibit high electron mobility (101--899
cm$^2$/V/s) and a pronounced anisotropy ratio in carrier mobility, which
effectively suppresses charge recombination. To optimize performance, we
constructed a van der Waals heterojunction (InSI/InSeBr), which demonstrates
remarkable photocatalytic properties, including enhanced redox ability, a
direct Z-scheme charge transfer pathway, strong visible-light absorption, high
carrier mobility, and excellent photocorrosion resistance. Our results indicate
that hexagonal Janus InXY MLs and their heterojunctions are multifunctional
materials integrating piezoelectricity and photocatalysis, paving the way for
energy conversion applications.

</details>


### [608] [First-principles investigation of Sr-Ce-M-O perovskites for solar thermochemical water splitting](https://arxiv.org/abs/2509.00779)
*Sachin Kumar,Pritam Ghosh,Gopalakrishnan Sai Gautam*

Main category: cond-mat.mtrl-sci

TL;DR: Sr$_{0.5}$Ce$_{0.5}$MnO$_3$ and Sr$_{0.5}$Ce$_{0.5}$CrO$_3$ are promising perovskites for solar thermochemical water splitting due to optimal oxygen vacancy formation energy and thermodynamic stability.


<details>
  <summary>Details</summary>
Motivation: To examine the utility of Sr-M-O and Sr-Ce-M-O perovskites for solar thermochemical water splitting for sustainable hydrogen production.

Method: Using density functional theory based calculations, systematically examine the utility of Sr-M-O and Sr-Ce-M-O perovskites.

Result: Identified Sr$_{0.5}$Ce$_{0.5}$MnO$_3$ and Sr$_{0.5}$Ce$_{0.5}$CrO$_3$ as promising candidates, exhibiting optimal oxygen vacancy formation energy and 0 K thermodynamic stability.

Conclusion: Sr$_{0.5}$Ce$_{0.5}$MnO$_3$ and Sr$_{0.5}$Ce$_{0.5}$CrO$_3$ are promising candidates for solar thermochemical water splitting.

Abstract: Using density functional theory based calculations, we systematically examine
the utility of Sr-M-O and Sr-Ce-M-O perovskites for solar thermochemical water
splitting, a promising route for sustainable hydrogen production. Importantly,
we identify Sr$_{0.5}$Ce$_{0.5}$MnO$_3$ and Sr$_{0.5}$Ce$_{0.5}$CrO$_3$ to be
promising candidates, exhibiting optimal oxygen vacancy formation energy and 0
K thermodynamic stability.

</details>


### [609] [Interplay of energy and charge transfer in WSe2/CrSBr heterostructures](https://arxiv.org/abs/2509.00810)
*José Roberto de Toledo,Caique Serati de Brito,Barbara L. T. Rosa,Alisson R. Cadore,César Ricardo Rabahi,Paulo E. Faria Junior,Ana Carolina Ferreira de Brito,Talieh S. Ghiasi,Josep Ingla-Aynés,Christian Schüller,Herre S. J. van der Zant,Stephan Reitzenstein,Ingrid D. Barcelos,Florian Dirnberger,Yara Galvão Gobato*

Main category: cond-mat.mtrl-sci

TL;DR: WSe2单分子层在CrSBr晶体上的磁光研究揭示了磁场调控的共振能量转移现象，有望用于二维材料的光捕获和发光增强。


<details>
  <summary>Details</summary>
Motivation: 探索二维材料（TMDs）和层状磁性半导体组成的范德华异质结（vdWHs）在调控激子和谷性质方面的潜力。

Method: 进行WSe2单分子层在CrSBr晶体上的磁光（PL）研究。

Result: 观察到ML-WSe2的PL峰在磁场下表现出与原始情况不同的独特行为。当外部磁场将CrSBr的激子能量调谐到与WSe2的光学态共振时，观察到ML-WSe2的PL强度明显增强。

Conclusion: 提出了一种磁场控制的共振能量转移（RET）机制，该机制超越了其他类似结构中已报道的效应。研究强调了不同机制在磁性vdWHs中的重要性，并突出了其在二维材料光捕获和发光增强方面的巨大潜力。

Abstract: Van der Waals heterostructures (vdWHs) composed of transition-metal
dichalcogenides (TMDs) and layered magnetic semiconductors offer great
opportunities to manipulate exciton and valley properties of TMDs. Here, we
present magneto-photoluminescence (PL) studies in a WSe2 monolayer (ML) on a
CrSBr crystal, an anisotropic layered antiferromagnetic semiconductor. Our
results reveal unique behavior of each of the ML-WSe2 PL peaks under magnetic
field that is distinct from the pristine case. An intriguing feature is the
clear enhancement of the PL intensity that we observe each time the external
magnetic field tunes the energy of an exciton in CrSBr into resonance with one
of the optical states of WSe2. This result suggests a magnetic field-controlled
resonant energy transfer (RET) beyond other effects reported in similar
structures. Our work provides deep insight on the importance of different
mechanisms into magnetic vdWHs and underscores its great potential for light
harvesting and emission enhancement of two-dimensional materials.

</details>


### [610] [Protocol for Clustering 4DSTEM Data for Phase Differentiation in Glasses](https://arxiv.org/abs/2509.00943)
*Mridul Kumar,Yevgeny Rakita*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用无监督机器学习分析了Ge-Sb-Te相变材料的4D-STEM数据，识别出四种不同的成分和结构类别，揭示了其内在的异质性。


<details>
  <summary>Details</summary>
Motivation: Ge-Sb-Te等相变材料在非易失性存储器中有广泛应用，但其性能受纳米尺度成分和结构变化影响，传统技术难以解析。

Method: 对4D-STEM数据进行预处理和PCA降维，然后用t-SNE和UMAP进行聚类验证，最后用k-means聚类并进行轮廓得分优化，将识别出的四个簇映射回衍射数据。

Result: 识别出四个不同的簇，并分析了它们的化学和结构特征：簇1富含氧和锗，簇2富含碲，簇3富含锑，簇4再次富含锗。聚类分析的平均衍射图证实了结构变化。

Conclusion: 聚类分析为关联相变材料的局部化学和结构特征提供了一个强大的框架，有助于深入了解其内在异质性。

Abstract: Phase-change materials (PCMs) such as Ge-Sb-Te alloys are widely used in
non-volatile memory applications due to their rapid and reversible switching
between amorphous and crystalline states. However, their functional properties
are strongly governed by nanoscale variations in composition and structure,
which are challenging to resolve using conventional techniques. Here, we apply
unsupervised machine learning to 4-dimensional scanning transmission electron
microscopy (4D-STEM) data to identify compositional and structural
heterogeneity in Ge-Sb-Te. After preprocessing and dimensionality reduction
with principal component analysis (PCA), cluster validation was performed with
t-SNE and UMAP, followed by k-means clustering optimized through silhouette
scoring. Four distinct clusters were identified which were mapped back to the
diffraction data. Elemental intensity histograms revealed chemical signatures
change across clusters, oxygen and germanium enrichment in Cluster 1, tellurium
in Cluster 2, antimony in Cluster 3, and germanium again in Cluster 4.
Furthermore, averaged diffraction patterns from these clusters confirmed
structural variations. Together, these findings demonstrate that clustering
analysis can provide a powerful framework for correlating local chemical and
structural features in PCMs, offering deeper insights into their intrinsic
heterogeneity.

</details>


### [611] [Performance Improvement of Deorbitalized Exchange-Correlation Functionals](https://arxiv.org/abs/2509.00953)
*H. Francisco,B. Thapa,S. B. Trickey,A. C. Cancio*

Main category: cond-mat.mtrl-sci

TL;DR: 通过使用基于RPP去轨道化器的方法，对r^2SCAN交换-相关泛函进行改进，提高了计算性能和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统元广义梯度交换-相关近似在密度梯度和拉普拉斯算子依赖性方面存在的问题，以及由此产生的计算不稳定性。

Method: 基于RPP去轨道化器（Phys. Rev. Mater. 6, 083803 (2022)）构建了一个新的去轨道化器，重点关注势的平滑性和约束满足。

Result: 将改进后的去轨道化器应用于r^2SCAN交换-相关泛函（J. Phys. Chem. Lett. 11, 8208 (2020)），发现其在固态计算中具有显著的时间改进，并且在固体和分子的精度方面优于RPP去轨道化器。

Conclusion: 所提出的改进方法在计算效率和准确性方面均优于现有技术，为材料计算提供了更好的选择。

Abstract: Deorbitalization of a conventional meta-generalized-gradient
exchange-correlation approximation replaces its dependence upon the Kohn-Sham
kinetic energy density with a dependence on the density gradient and Laplacian.
In principle, that simplification should provide improved computational
performance relative to the original meta-GGA form because of the shift from an
orbital-dependent generalized Kohn-Sham potential to a true KS local potential.
Often that prospective gain is lost because of problematic roughness in the
density caused by the density Laplacian and consequent roughness in the
exchange-correlation potential from the resulting higher-order spatial
derivatives of the density in it. We address the problem by constructing a
deorbitalizer based on the RPP deorbitalizer [Phys. Rev. Mater. 6, 083803
(2022)] with comparative smoothness of the potential along with retention of
constraint satisfaction as design goals. Applied to the r^2SCAN
exchange-correlation functional [J. Phys. Chem. Lett. 11, 8208 (2020)], we find
substantial timing improvements for solid-state calculations over both r^2SCAN
and its earlier deorbitalization for high precision calculations of structural
properties, while improving upon the accuracy of RPP deorbitalization for both
solids and molecules.

</details>


### [612] [Common errors in BoltzTraP-based calculations](https://arxiv.org/abs/2509.00959)
*Øven A. Grimenes,Kristian Berland*

Main category: cond-mat.mtrl-sci

TL;DR: 鉴于BoltzTraP代码在热电材料研究中的广泛应用，本研究识别并纠正了该代码中存在的三个系统性错误，这些错误可能导致计算结果不准确，特别是在电子热导率（κ0 vs κe）、品质因数（zT）计算以及松弛时间处理方面。研究通过单抛物带模型推导了理论极限，并以ZrNiSn为例进行了案例分析，揭示了错误计算可能产生的误导性结果，并为研究人员提供了避免这些陷阱的实用指导。


<details>
  <summary>Details</summary>
Motivation: 鉴于Boltzmann输运计算在热电材料研究中的重要性以及BoltzTraP代码的广泛使用，本研究旨在识别并解决该代码中存在的系统性错误，以提高研究的准确性。

Method: 通过理论推导（单抛物带模型）和案例分析（ZrNiSn），识别并阐述了BoltzTraP代码中存在的三个主要的错误模式：电子热导率（κ0 vs κe）的混淆、品质因数（zT）计算中不当的松弛时间处理，以及这两种错误的组合。

Result: 研究发现了BoltzTraP代码中存在的三种系统性错误模式，并提供了相应的理论分析和案例研究（ZrNiSn），证明了这些错误可能导致误导性的计算结果，并指出了在特定温度和费米能级下错误计算结果可能看起来合理的情况。

Conclusion: 本研究识别了BoltzTraP代码在计算热电输运性质时可能出现的三个主要错误，并通过理论和案例分析证明了这些错误可能导致的误导性结果。研究为研究人员提供了避免这些错误的实用指南，以确保热电材料研究的准确性。

Abstract: Boltzmann transport calculations based on band structures computed from first
principles play an important role in modern thermoelectric materials research.
Among available codes, the \textsc{BoltzTraP} code is the most widely adopted,
but many recent studies contain systematic mistakes. We identify three error
modes: (1) inserting the electronic thermal conductivity at zero electric
field, $\kappa_0$, in place of the electronic thermal conductivity at zero
electric current, $\kappa_e$, (2) computing the figure of merit $zT$ by
combining a constant relaxation time of unity while keeping the lattice thermal
conductivity $\kappa_\ell$ in standard units, and (3) doing both errors at
once. We have found many examples of the third error, but since the first two
are simpler, we suspect they are also present in the literature. For the single
parabolic band model, we derive exact analytical limits in the non-degenerate
and near-degenerate regimes, and we show how mistakes appear for the realistic
case study of ZrNiSn. Our results illustrate how faulty calculations can appear
reasonable at certain temperatures and Fermi levels, and we provide practical
guidance for identifying faulty results and avoiding such pitfalls in
thermoelectric transport studies.

</details>


### [613] [Control of Covalent Bond Enables Efficient Magnetic Cooling](https://arxiv.org/abs/2509.01047)
*Xin Tang,Yoshio Miura,Noriki Terada,Enda Xiao,Shintaro Kobayashi,Allan Doring,Terumasa Tadano,Andres Martin-Cid,Takuo Ohkochi,Shogo Kawaguchi,Yoshitaka Matsushita,Tadakatsu Ohkubo,Tetsuya Nakamura,Konstantin Skokov,Oliver Gutfleisch,Kazuhiro Hono,Hossein Sepehri-Amin*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在 Gd5Ge4 化合物的晶胞内形成 Sn(Ge)3/Sn(Ge)3 键，消除了磁热材料中的热滞，从而提高了磁熵变和可逆绝热温变，为气体液化等可持续能源应用开辟了新途径。


<details>
  <summary>Details</summary>
Motivation: 磁制冷技术作为一种有前景的节能环保替代制冷技术，其发展受到磁热材料中磁滞引起的不可逆损耗的限制。尽管在晶格常数调控方面进行了大量研究，但减少磁滞往往会牺牲制冷性能。本研究旨在解决这一挑战。

Method: 通过在 Gd5Ge4 化合物的晶胞内形成 Sn(Ge)3/Sn(Ge)3 键，实现有利于相变，从而消除热滞。

Result: 在 Gd5Sn2Ge2 化合物中，磁熵变增大，可逆绝热温变为 8 K（是之前的两倍）。这种协同效应可以在很宽的温度范围内实现。

Conclusion: 本研究通过在磁热材料中形成特定的化学键，成功消除了热滞，实现了磁熵变和可逆绝热温变的协同提高，为开发高效、环保的磁制冷技术以及气体液化等应用提供了新的思路和方法。

Abstract: Magnetic cooling, harnessing the temperature change in matter when exposed to
a magnetic field, presents an energy-efficient and climate-friendly alternative
to traditional vapor-compression refrigeration systems, with a significantly
lower global warming potential. The advancement of this technology would be
accelerated if irreversible losses arising from hysteresis in magnetocaloric
materials were minimized. Despite extensive efforts to manipulate crystal
lattice constants at the unit-cell level, mitigating hysteresis often
compromises cooling performance. Herein, we address this persistent challenge
by forming Sn(Ge)3/Sn(Ge)3 bonds within the unit cell of the Gd5Ge4 compound.
Our approach enables an energetically favorable phase transition, leading to
the elimination of thermal hysteresis. Consequently, we achieve a synergistic
improvement of two key magnetocaloric figures of merit: a larger magnetic
entropy change and a twofold increase in the reversible adiabatic temperature
change (from 3.8 to 8 K) in the Gd5Sn2Ge2 compound. Such synergies can be
extended over a wide temperature range. This study demonstrates a paradigm
shift in mastering hysteresis toward simultaneously achieving exceptional
magnetocaloric metrics and opens up promising avenues for gas liquefaction
applications in the longstanding pursuit of sustainable energy solutions.

</details>


### [614] [Odd-Parity Selection in Parity-Forbidden Electronic Transitions Revealed by Mn4+ Fluorescence Spectroscopy](https://arxiv.org/abs/2509.01248)
*Yitong Wang,Fei Tang,Jiqiang Ning,Shijie Xu*

Main category: cond-mat.mtrl-sci

TL;DR: Mn4+荧光粉的声子侧带受电子-声子耦合影响，但传统的黄-里斯理论不适用于其禁戒跃迁。本研究通过引入赫兹伯格-泰勒近似，扩展了理论框架，解释了偶数次声子侧带被抑制的现象，并提出了计算黄-里斯因子的新公式。


<details>
  <summary>Details</summary>
Motivation: 研究Mn4+荧光粉的声子侧带，阐明禁戒跃迁的电子-声子耦合机制，解决现有理论的局限性。

Method: 通过实验揭示声子侧带的奇偶顺序强度分布差异，并扩展黄-里斯理论，结合赫兹伯格-泰勒近似处理跃迁矩阵元，以解释观测现象。

Result: 实验发现偶数次声子侧带被显著抑制，而奇数次声子侧带正常出现。改进后的理论成功解释了偶数次侧带的强抑制现象，并推导出黄-里斯因子S=((2I_3)/(9I_1 ))^(1/2)。

Conclusion: 本研究揭示了禁戒跃迁系统的声子侧带的新规律，并建立了更完善的理论框架，用于理解固体颜色中心的电子-声子耦合机制。

Abstract: Mn4+-doped fluoride phosphors represent a significant class of narrow band
red-emitting materials, whose luminescent properties are profoundly influenced
by electron-phonon coupling. However, the parity-forbidden nature of these
electronic transition systems is incompatible with the conventional Condon
approximation, which is widely adopted in the classic theories such as the
Huang-Rhys theory, a framework established on the assumption of parity-allowed
electric dipole transitions. This results in a critical knowledge gap regarding
the principles governing the phonon sidebands of parity-forbidden electronic
transitions. This study experimentally reveals a pronounced parity-dependent
intensity distribution in the phonon sidebands of these systems: significantly
suppressed even-order sidebands and normally observed odd-order sidebands. To
elucidate the phenomenon, we extend the Huang-Rhys theory to parity-forbidden
systems by incorporating the Herzberg-Teller approximation into the treatment
of the transition matrix elements. The improved theory successfully uncovers
the physical mechanism behind the strong suppression of the even-order
sidebands in the parity-forbidden systems, in which the Huang-Rhys factor is
derived as S=((2I_3)/(9I_1 ))^(1/2). This work not only reveals new findings
regarding the phonon sidebands of the parity-forbidden electronic transition
systems, but also establishes an improved theoretical framework for
understanding the electron-phonon coupling mechanisms of color centers in
solids.

</details>


### [615] [Dipolar Nematic State in Relaxor Ferroelectrics](https://arxiv.org/abs/2509.01464)
*Yuan-Jinsheng Liu,Tyler C. Sterling,Shi Liu*

Main category: cond-mat.mtrl-sci

TL;DR: Relaxor铁电材料的微观结构和极性动力学机制尚不明确。本文利用基于第一性原理的机器学习分子动力学模拟，研究了Pb、Bi和Ba基弛豫铁电体的原子尺度极性动力学，发现了一种普遍存在的偶极子向列态，具有长程取向有序但无局域取向一致性，挑战了传统的极性团簇模型。提出了一种基于局域极化自相关函数分布偏度的普适阶参数，可用于统一描述不同弛豫铁电体的热演化。该向列序和其在电场循环下的结构记忆性是弛豫铁电现象（如朗道二次相变、介电频散和巨大的可逆压电性）的关键。本研究为弛豫铁电体建立了统一的微观理论框架，并提出了一种理解复杂无序材料的统计方法。


<details>
  <summary>Details</summary>
Motivation: 弛豫铁电材料表现出优异的介电和机电性能，但其微观起源因层级极性结构和化学复杂性的相互作用而难以捉摸。基于极性纳米区或纳米畴的模型提供了有价值的现象学见解，但往往缺乏定量描述压电系数等功能特性的第一性原理预测能力。

Method: 利用基于第一性原理的机器学习势能进行大规模分子动力学模拟，研究了Pb、Bi和Ba基弛豫铁电体的原子尺度极性动力学。

Result: 在所有研究体系中，发现了一种普遍存在的偶极子向列态，其特征是局域极化具有长程取向有序但无局域取向一致性，这与传统的极性团簇模型相悖。提出了一种普适阶参数，通过局域极化自相关函数分布的偏度来捕捉，能够在一个主曲线中描述铅基和无铅体系的热演化。该向列序及其在电场循环下的结构记忆性是弛豫铁电现象的关键。

Conclusion: 该研究揭示了一种普遍存在的偶极子向列态，并提出了一个普适阶参数来描述弛豫铁电体的热演化和关键现象，为弛豫铁电体建立了统一的微观理论框架，并提出了一种理解复杂无序材料的统计方法。

Abstract: Relaxor ferroelectrics exhibit exceptional dielectric and electromechanical
properties, yet their microscopic origins remain elusive due to the interplay
of hierarchical polar structures and chemical complexity. While models based on
polar nanoregions or nanodomains offer valuable phenomenological insights, they
often lack the first-principles predictive capability necessary for
quantitatively describing functional properties such as piezoelectric
coefficients. Here, we use large-scale molecular dynamics simulations, enabled
by a universal first-principles-based machine-learning interatomic potential,
to investigate atomic-scale polar dynamics in canonical Pb-, Bi-, and Ba-based
relaxors. Across all systems, we uncover a universal dipolar nematic state,
characterized by long-range orientational order of local polarizations without
local alignment, challenging conventional polar cluster-based paradigms. We
introduce a universal order parameter, derived from the skewness of the
distributions of the local polarization autocorrelation functions, that
captures the thermal evolution of both lead-based and lead-free systems within
a single master curve. This nematic order, and its robust structural memory
under electric field cycling, underpins key relaxor phenomena, including
diffuse phase transition, frequency-dependent dielectric dispersion, and
reversible giant piezoelectricity. Our findings establish a unified microscopic
framework for relaxors and present a broadly applicable statistical approach to
understanding complex disordered materials.

</details>


### [616] [Quantum Computation of the Electronic Structure of Some Prototype Solids](https://arxiv.org/abs/2509.01648)
*Naman Khandelwal,Nidhi Verma,Pooja Jamdagni,Ashok Kumar*

Main category: cond-mat.mtrl-sci

TL;DR: 使用第一性原理密度泛函理论与VQE和VQD算法以及Wannier紧束缚哈密顿量方法预测固体的电子特性，并展示了VQE和VQD在多种固态材料中的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究如何将量子算法（如VQE和VQD）应用于周期性固态材料，以预测哈密顿能量。

Method: 将第一性原理密度泛函理论与VQE和VQD算法相结合，并利用Wannier紧束缚哈密顿量（WTBH）方法。

Result: VQE和VQD算法能够准确预测多种固态材料（如硅、金、氮化硼、石墨烯）的电子特性。SU2在所有预定义的ansatz中表现最佳。COBYLA是收敛速度最快、迭代次数最少的经典优化器。噪声模型有助于理解在实际量子硬件上计算的能带结构。

Conclusion: 该方法为未来量子材料模拟提供了一个原型，并推动了向自主量子发现引擎的迈进。

Abstract: Over the last decade, researchers have been working to improve a crucial
aspect of quantum computing to predict Hamiltonian energy of solids. Quantum
algorithms such as Variational Quantum Eigensolver (VQE) and Variational
Quantum Deflation (VQD) have been used to study the molecular systems. However,
there is growing interest in adapting and applying these methods to periodic
solid-state materials. In this work, we have integrated first-principles
density functional theory with VQE and VQD algorithms and utilizing the Wannier
Tight-Binding Hamiltonian (WTBH) method to predict the electronic
characteristics of solids. We demonstrate that VQE and VQD algorithms can be
used to accurately predict electronic characteristics in a variety of
multi-component prototype solid-state materials such as-Silicon
(semiconductor), Gold (metallic), Boron Nitrile (insulator), Graphene
(semi-metal). Efficient SU2 performs well among all the predefined ansatz used
in the study. COBYLA is the fastest optimizer among the classical optimizers
with minimum number of iterations for convergence. Results of noise models help
to understand the band structure when calculated on real quantum hardware. As
quantum hardware advances, our method stands as a prototype for future quantum
simulations of materials pushing us closer to autonomous quantum discovery
engines.

</details>


### [617] [A Concise Review of Recently Synthesized 2D Carbon Allotropes: Amorphous Carbon, Graphynes, Biphenylene and Fullerene Networks](https://arxiv.org/abs/2509.01877)
*Ricardo Paupitz,Alexandre F. Fonseca,Mizraim Bessa,Guilherme S. L. Fabris,William F. da Cunha,Leonardo D. Machado,Marcelo L. Pereira Junior,Luiz A. Ribeiro Junior Douglas S. Galvão*

Main category: cond-mat.mtrl-sci

TL;DR: 该论文对近期实验实现的二维碳同素异形体进行了综述，包括石墨炔、联苯类网络、富勒烯网络和单层无定形碳。文章讨论了这些材料的结构特性、理论预测和合成方法，并强调了理论与实验的相互作用。此外，文章还指出了实验研究中可能忽略的理论贡献，并提出了一些尚未在实验中探索的理论预测结构，为未来的合成研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 二维碳同素异形体因其独特的性质和在电子、催化、储能和传感等领域的潜在应用而备受关注。

Method: 对近期实验实现的二维碳同素异形体（包括石墨炔、联苯类网络、富勒烯网络和单层无定形碳）进行综述，讨论其结构特性、理论预测和合成方法，并强调理论与实验的相互作用。

Result: 总结了石墨炔、联苯类网络、富勒烯网络和单层无定形碳等二维碳同素异形体的结构、理论预测和合成方法，并指出了理论与实验结合的案例以及未来潜在的实验研究方向。

Conclusion: 二维碳同素异形体的研究结合了理论预测和实验合成，未来有许多理论预测的结构有待实验探索，这为该领域的研究提供了新的机遇。

Abstract: Two-dimensional (2D) carbon allotropes have received considerable attention
due to their unique properties and potential applications in several fields,
including electronics, catalysis, energy storage, and sensing. Following the
experimental realization of graphene, numerous other 2D carbon structures have
been proposed and, in some cases, successfully synthesized. This work presents
a concise review of the recently experimentally realized 2D carbon allotropes,
including graphynes, biphenylene-based networks, fullerene networks, and
monolayer amorphous carbon. For each class, we discuss structural
characteristics, theoretical predictions, and synthesis methods, with emphasis
on the interplay between theory and experiment. We also highlight instances
where experimental studies overlooked relevant theoretical contributions.
Finally, we identify theoretically predicted structures that remain unexplored
experimentally, suggesting opportunities for synthesis-driven investigations.

</details>


### [618] [Raman spectroscopy of graphite with water as the pressure medium](https://arxiv.org/abs/2509.01890)
*K. Perry,A. T. Roy,A. R. Parmenter,Y. J. Ryu,V. B. Prakapenka,J. Lim*

Main category: cond-mat.mtrl-sci

TL;DR: 高压下石墨-水混合物的拉曼光谱研究显示，石墨的G带蓝移，表明层间耦合增强；水中的特征模式在高压下行为发生变化，可能受水压介质影响。


<details>
  <summary>Details</summary>
Motivation: 在高压下研究石墨-水混合物的拉曼光谱特性，并探讨水作为压传介质的影响。

Method: 使用高压拉曼光谱技术，研究了高达9.9 GPa的石墨-水混合物。在石墨和水富集区域分别观察并追踪了特征的拉曼峰。

Result: 在石墨区域，观察到E(1)2g剪切模式、G带和2D带，G带随压力升高表现出显著蓝移，表明层间耦合增强。在水区域，识别出振动带和三个O-H伸缩模式。值得注意的是，在8 GPa以上，压力依赖性的斜率减小，可能与水压介质有关。

Conclusion: 高压下的石墨-水混合物拉曼光谱研究揭示了石墨层间耦合随压力的增强，并观察到水在高压下的行为变化。在高压下，水压介质对测量结果可能产生影响，需要进一步研究。

Abstract: We report a high-pressure Raman spectroscopy study of a graphite-water
mixture using water as the pressure-transmitting medium up to 9.9 GPa. In the
graphite-rich region, three characteristic Raman features-the $E_{2g}^{(1)}$
shear mode, the G band ($E_{2g}^{(2)}$), and the 2D band-were observed and
tracked as a function of pressure. The G band exhibits a pronounced blue shift
with increasing pressure, indicating enhanced interlayer coupling between
graphite planes. In the water-rich region, the librational band and three
distinct O-H stretching modes were identified. Notably, above 8 GPa, the slope
of the pressure dependence decreases relative to the earlier report, likely due
to the influence of the water pressure medium, emphasizing the need for further
investigation at higher pressures.

</details>


### [619] [Defining structural gradient hardening through Type II back stress for heterostructured materials](https://arxiv.org/abs/2509.01908)
*En Ma,Ting Zhu*

Main category: cond-mat.mtrl-sci

TL;DR: HS材料具有优于传统材料的机械性能，这得益于其独特的结构梯度硬化（SGH）机制。


<details>
  <summary>Details</summary>
Motivation: 为了更好地体现HS材料的独特性，需要引入新的概念来描述其加强机制。

Method: 提出“结构梯度硬化”（SGH）的概念，并将其与传统的加强机制区分开来，同时将背应力划分为两个组成部分，其中II型专门用于量化由HS材料的结构和应变梯度引起的额外硬化。

Result: SGH是HS材料的一种重要加强机制，它独立于传统的加强机制，并且可以量化HS材料的独特性能。

Conclusion: SGH是理解和应用HS材料的关键概念，有助于未来HS材料的设计和开发。

Abstract: The recently proposed term "heterostructured (HS) materials" serves as an
umbrella classification encompassing a wide range of materials that hold great
promise for enhanced mechanical properties. Most HS materials exhibit
back-stress strengthening, as is typical for all plastically non-homogeneous
materials. To better embody the distinctiveness of materials crafted via
innovative heterostructuring, here we introduce the concept of "structural
gradient hardening" (SGH), which captures an essential feature of HS materials
and complements traditional strengthening mechanisms. SGH refers to the extra
strengthening that arises from a characteristic gradient structure introduced
by heterostructuring, beyond what is predicted by the rule of mixtures. This
distinction is useful, as the overall back stress can in fact be partitioned
into Type I and Type II components, with the latter specifically quantifying
the extra hardening originating from the structural and strain gradients
established by heterostructuring, as articulated in this Viewpoint article.

</details>


### [620] [Interfacial Control of both Magnetism and Polarization in a van der Waals Ferromagnet/Ferroelectric Heterostructure](https://arxiv.org/abs/2509.01992)
*Priyanshu Raj,Sourav Mal,Rana Saha,Prasenjit Sen*

Main category: cond-mat.mtrl-sci

TL;DR: Fe3GaTe2/In2Se3异质结构在二维多铁性材料中实现了铁磁性和铁电性的耦合，通过插入Fe原子增强了垂直磁各向异性（PMA），并可调控电极化。


<details>
  <summary>Details</summary>
Motivation: 为了在磁电器件和自旋电子学中实现对不同铁性顺序的同时控制，需要具有高居里温度和强垂直磁各向异性（PMA）的二维磁体。

Method: 基于第一性原理计算，研究了Fe3GaTe2和In2Se3组成的异质结构，并探讨了Fe原子插层对其性质的影响。

Result: Fe原子插层显著增强了Fe3GaTe2/In2Se3异质结构的PMA，同时允许通过界面电荷重新分布调控电极化。PMA的增强归因于改变自旋-轨道耦合的界面杂化。

Conclusion: 该研究提出了一种在二维多铁性异质结构中设计磁电耦合的有效方法，为开发节能型自旋电子器件提供了新的途径。

Abstract: Two-dimensional multiferroic van der Waals heterostructures provide a
promising platform for the simultaneous control of distinct ferroic orders,
with potential applications in magnetoelectric devices and spintronics. The
practical implementation of such technologies requires 2D magnets with high
Curie temperatures and strong perpendicular magnetic anisotropy (PMA). Here,
based on first-principles calculations, we propose a multiferroic
heterostructure composed of the room-temperature ferromagnet
$\text{Fe}_3\text{Ga}\text{Te}_2$ and the ferroelectric
$\text{In}_2\text{Se}_3$. We show that intercalation of Fe atoms into the van
der Waals gap of the $\text{Fe}_3\text{Ga}\text{Te}_2$/$\text{In}_2\text{Se}_3$
heterostructure enhances PMA by nearly an order of magnitude relative to the
pristine $\text{Fe}_3\text{Ga}\text{Te}_2$ monolayer, while simultaneously
allowing electric polarization to be modulated through interfacial charge
redistribution. The enhancement of PMA arises from interfacial hybridization
that modifies the spin-orbit coupling of Fe $d$-orbitals. Our results
demonstrate an effective pathway to engineer magnetoelectric coupling in
two-dimensional multiferroic heterostructures and pave the way toward
energy-efficient spintronic devices.

</details>


### [621] [Optically induced spin Hall current in monolayer Janus NbSSe: A first-principles study](https://arxiv.org/abs/2509.01998)
*Souren Adhikary,Tomoaki Kameda,Katsunori Wakabayashi*

Main category: cond-mat.mtrl-sci

TL;DR: Janus NbSSe is a promising material for optospintronics due to its SOC properties that enable optically controlled spin current generation.


<details>
  <summary>Details</summary>
Motivation: The paper aims to investigate the spin-orbit coupling (SOC) characteristics of monolayer Janus transition-metal dichalcogenides, specifically metallic Janus NbSSe, and explore its potential for optically controlled spin current generation.

Method: The study utilizes first-principles calculations to analyze the SOC properties of Janus NbSSe.

Result: The calculations reveal that Janus NbSSe possesses Ising- and Rashba-type SOC, leading to significant spin splitting effects. It is demonstrated that different linear polarized light can selectively drive distinct spin components, enabling optically controlled spin current generation.

Conclusion: The findings establish NbSSe as a promising material for next-generation optospintronic technologies, offering a pathway for developing polarization-tunable spin-current sources.

Abstract: Monolayer Janus transition-metal dichalcogenides possess Ising- and
Rashba-type spin-orbit-couplings (SOC), leading to intriguing spin splitting
effects at K and K$'$, and around $\Gamma$ points across the wide energy range.
Using first-principles calculations, we unveil these SOC characteristics in
metallic Janus NbSSe and demonstrate its potential for optically controlled
spin current eneration. On the basis of the symmetry of the system, we show
that different linear polarized light can selectively drive spin currents of
distinct spin components. Our findings establish NbSSe as a promising candidate
for next-generation optospintronic technologies, which is offering a pathway
toward the development of polarization-tunable spin-current sources.

</details>


### [622] [Extremely Large and Angle-Dependent Magnetoresistance in Kagome Dirac Semimetal RFe$_6$Sn$_6$ (R=Ho, Dy)](https://arxiv.org/abs/2509.02010)
*Susanta Ghosh,Achintya Low,Nayana Devaraj,Susmita Changdar,Awadhesh Narayan,Setti Thirupathaiah*

Main category: cond-mat.mtrl-sci

TL;DR: RFe6Sn6（R = Ho, Dy）是基于铁的 kagome 狄拉克系统，在低温和磁场下表现出极大的磁阻（XMR），HoFe6Sn6 在 2 K 和 9 T 下达到 3000%，DyFe6Sn6 达到 1000%。


<details>
  <summary>Details</summary>
Motivation: 研究基于铁的 kagome 狄拉克系统 RFe6Sn6 (R = Ho, Dy) 的电子、磁性和磁输运性质。

Method: 通过对 RFe6Sn6 (R = Ho, Dy) 的磁性质研究和磁输运测量，并利用半经典双带模型拟合霍尔电导率。

Result: HoFe6Sn6 和 DyFe6Sn6 表现出反铁磁序，居里温度分别约为 570 K，低温下出现弱铁磁序。在 2 K 和 9 T 磁场下，HoFe6Sn6 的 XMR 高达 3000%，DyFe6Sn6 高达 1000%。半经典双带模型拟合揭示了近乎完美的电子-空穴补偿和高载流子迁移率。此外，研究还发现了大的磁阻各向异性，并且角度依赖的磁阻（ADMR）模式在 2 K 和 50 K 之间存在显著变化，表明费米面拓扑结构随温度变化。

Conclusion: RFe6Sn6 (R = Ho, Dy) 系统具有极大的磁阻（XMR）和磁阻各向异性，这归因于近乎完美的电子-空穴补偿和高载流子迁移率。ADMR 结果表明其费米面拓扑结构具有温度依赖性。

Abstract: We report on the electronic, magnetic, and magneto-transport properties of
Fe-based kagome Dirac system, RFe$_6$Sn$_6$ (R = Ho, Dy). Magnetic properties
study reveals an antiferromagnetic order with N$\acute{e}$el temperature of
$T_N \approx$ 570 K. Additionally, a weak ferromagnetic order emerge at low
temperatures. Magnetotransport measurements demonstrate an extremely large
magnetoresistance (XMR) reaching as high as $3\times 10^{3} \%$ for
HoFe$_6$Sn$_6$ and $ 1\times 10^{3} \%$ for DyFe$_6$Sn$_6$ when measured at 2 K
with 9 T of magnetic field. The semi-classical two-band model fitting of the
Hall conductivity reveals nearly perfect electron-hole compensation and high
carrier mobility, which leads to XMR behaviour in these system. Further, we
identify large magnetoresistance anisotropy for the magnetic fields applied in
different crystallographic orientations. In addition, considerable modification
in the angle-dependent magnetoresistance (ADMR) pattern has been noticed
between 2 and 50 K, indicating temperature-dependent changes in the Fermi
surface topology of these systems.

</details>


### [623] [Phase field simulation of dendrite growth in solid-state lithium batteries based on mechanical-thermo-electrochemical coupling](https://arxiv.org/abs/2509.02013)
*Pengyang Hou,Jiamiao Xie,Jingyang Li,Peng Zhang,Zhaokai Li,Wenqian Hao,Jia Tian,Zhe Wang,Fuzheng Li*

Main category: cond-mat.mtrl-sci

TL;DR: 固态锂电池因其高能量密度、优异的循环稳定性、机械强度、不可燃性、安全性和长寿命等优点，在航空航天、新能源汽车和便携式电子设备等领域具有广泛的应用前景。然而，锂枝晶在电极/电解质界面的生长仍然是影响电池性能和安全的关键挑战。本研究利用相场理论进行数值模拟，通过耦合力学应力场、热场和电化学场，开发了一个相场模型，以研究在不同环境温度、外部压力及其联合作用下锂枝晶的形貌和演化。研究结果表明，较高的温度和较大的外部压力能显著抑制锂枝晶的生长，减少侧枝，使表面更光滑，电化学沉积更均匀。外部压力的增加抑制了枝晶的纵向生长，使其形态更紧凑，但会降低机械稳定性。温度和压力的联合作用对枝晶生长的抑制作用尤为明显，应力集中在枝晶根部，促进了横向生长，形成了更平坦、更致密的锂沉积。


<details>
  <summary>Details</summary>
Motivation: 固态锂电池在多个领域具有应用潜力，但锂枝晶的生长限制了其性能和安全。本研究旨在解决这一问题。

Method: 采用相场理论进行数值模拟，耦合力学应力场、热场和电化学场，建立相场模型研究锂枝晶的形貌和演化。

Result: 较高的温度和外部压力能有效抑制锂枝晶生长，改善其形貌和沉积均匀性。外部压力会增加机械不稳定性，而温度和压力的联合作用能形成更平坦、更致密的锂沉积。

Conclusion: 温度和压力是调控固态锂电池中锂枝晶生长的关键因素，联合作用效果更佳。

Abstract: Solid-state lithium batteries possess numerous advantages, such as high
energy density, excellent cycle stability, superior mechanical strength,
non-flammability, enhanced safety, and extended service life. These
characteristics make them highly suitable for applications in aerospace, new
energy vehicles, and portable electronic devices. However, the growth of
lithium dendrite at the electrode/electrolyte interface remains a critical
challenge, limiting both performance and safety. The growth of lithium
dendrites in the electrolyte not only reduces the Coulombic efficiency of the
battery but also poses a risk of puncturing the electrolyte, leading to
internal short circuits between the anode and cathode. This study is to solve
the problem of lithium dendrite growth in solid-state lithium batteries by
employing phase-field theory for numerical simulations. A phase-field model is
developed by coupling the mechanical stress field, thermal field, and
electrochemical field, to investigate the morphology and evolution of lithium
dendrites under the condition of different ambient temperatures, external
pressures, and their combined effects. The results indicate that higher
temperature and greater external pressure significantly suppress lithium
dendrite growth, leading to fewer side branches, smoother surfaces, and more
uniform electrochemical deposition. Increased external pressure inhibits
longitudinal dendrite growth, resulting in a compressed morphology with higher
compactness, but at the cost of increased mechanical instability. The combined
effect of temperature and pressure exhibits a pronounced inhibitory influence
on dendrite growth, with stress concentrating at the dendrite roots. This
stress distribution promotes lateral growth, facilitating the formation of
flatter and denser lithium deposits.

</details>


### [624] [A High-Throughput Search for Stable and Magnetically Robust Fe$_3$XY$_2$ Monolayers](https://arxiv.org/abs/2509.02199)
*Soheil Ershadrad,Biplab Sanyal*

Main category: cond-mat.mtrl-sci

TL;DR: 529种Fe3XY2化合物的理论计算表明31种具有稳定性，其中含卤素化合物磁性优异，Fe3SiTe2具有最强的PMA，Fe3AsBr2可望在零磁场下实现Néel型Skyrmion。


<details>
  <summary>Details</summary>
Motivation: 探索Fe3XY2化合物在二维磁性材料方面的潜力。

Method: 使用第一性原理计算了529种Fe3XY2化合物的能量、动力学、力学和热力学稳定性，并分析了其磁性、磁晶各向异性、交换作用和晶体结构。

Result: 31种化合物具有稳定性。含卤素化合物具有较高的磁矩和磁转变温度。Fe3SiTe2具有最强的PMA。交换作用受近邻Fe-Fe直接交换和p轨道介导的交换共同影响。四种化合物具有非中心对称结构，Fe3AsBr2可望在零磁场下实现Néel型Skyrmion。

Conclusion: 该研究为实验制备具有增强功能的二维铁磁材料提供了理论指导。

Abstract: We present first principles exploration of 529 Fe$_3$XY$_2$ compounds, where
$X$ and $Y$ elements are selected from the $p$-block of the periodic table. Out
of the entire set, 31 compounds satisfy all criteria for energetic, dynamic,
mechanical, and thermal stability. Our analysis reveals several key trends:
halide-containing systems exhibit the highest average magnetic moments and the
highest magnetic transition temperatures, highlighting their potential for
room-temperature spintronic applications. The majority of stable compounds
display perpendicular magnetic anisotropy (PMA), with Fe$_3$SiTe$_2$ exhibiting
the strongest PMA among all candidates. Exchange interactions are found to be
governed by a dual mechanism, direct exchange between nearest-neighbor Fe atoms
and indirect, $p$-orbital-mediated exchange for second-nearest neighbors and
beyond. Notably, four compounds have non-centrosymmetric crystal structures and
exhibit finite spiralization constants. Among them, Fe$_3$AsBr$_2$ is predicted
to host N\'eel-type skyrmions even at zero external magnetic field, as
confirmed by micromagnetic simulations. These findings offer a roadmap for
experimental realization of novel 2D ferromagnets with enhanced
functionalities.

</details>


### [625] [Theoretical calculation of finite-temperature X-ray absorption fine structure: application to sodium K-edge in NaCl](https://arxiv.org/abs/2509.02206)
*Philipp Hönicke,Yves Kayser,Pouya Partovi-Azar*

Main category: cond-mat.mtrl-sci

TL;DR: 基于量子化学模拟，提出一个计算框架用于重现X射线吸收精细结构（XAFS），可以区分不同化学环境下的贡献。


<details>
  <summary>Details</summary>
Motivation: 为了重现X射线吸收精细结构（XAFS）并为实验表征提供补充，特别是针对那些难以通过实验表征的元素和物种。

Method: 结合了基于时变密度泛函微扰理论的核心激发计算和从头算分子动力学模拟，用于模拟XAFS的近边和扩展区域，并区分了体相、缺陷和表面环境的贡献。

Result: 在NaCl的Na K-边的模拟中，预测的XAFS光谱与实验测量结果吻合良好。

Conclusion: 该计算框架能够有效地重现XAFS光谱，并区分不同化学环境的贡献，为表征材料提供了实用的方法，尤其有助于解决实验表征的挑战。

Abstract: We present a comprehensive computational framework for reproducing the full
X-ray absorption fine structure (XAFS) through quantum-chemical simulations.
The near-edge region is accurately captured using an efficient implementation
of time-dependent density-functional perturbation theory applied to core
excitations, while ab initio molecular dynamics provides essential sampling of
core-excitation energies and interatomic distance distributions for
interpreting extended X-ray absorption fine structure (EXAFS) features. Owing
to the efficiency of the approach, the total spectrum can be decomposed into
contributions from bulk, defective, and surface environments, which commonly
coexist in experimental systems. The methodology is demonstrated for sodium at
the Na K-edge in NaCl, where the predicted spectra show good agreement with
experimental measurements on thin film samples. This strategy offers a
practical route to generating chemically specific XAFS cross-section data for
elements and species that remain challenging to characterize experimentally,
thereby enabling deeper insights into materials of technological importance.

</details>


### [626] [Non-Ferroelectric to Ferroelectric Phase Transition in epitaxial Y:HfO$_2$ via Rapid Thermal Annealing Induced Nitrogen Doping](https://arxiv.org/abs/2509.02229)
*Soumyajyoti Mondal,Asraful Haque,Binoy Krishna De,Shubham Kumar Parate,Pramod Kumar Yadav,Arup Basak,Kaushal Tiwari,Bhagwati Prasad,Pavan Nukala*

Main category: cond-mat.mtrl-sci

TL;DR: 通过氮掺杂稳定HfO2中的铁电相，并展示了其在光电器件中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 系统研究通过阴离子掺杂诱导铁电性的方法，以填补该领域的研究空白。

Method: 在Y:HfO2薄膜中通过氮掺杂引入氧空位，并利用X射线光电子能谱等技术进行结构-性质关联测量。

Result: 氮掺杂可以稳定HfO2中的铁电相，并且随着退火时间的增加，非铁电的单斜相比例减少，铁电畴清晰出现。

Conclusion: 氮掺杂是稳定HfO2铁电相的一种有效途径，且不牺牲晶格相干性，为铁电材料在光电器件中的集成提供了新的思路。

Abstract: Oxygen vacancies are often essential for stabilizing the orthorhombic
ferroelectric phase in HfO$_2$, with cationic doping widely employed to
introduce such defects. In contrast, systematic studies on anionic doping to
induce ferroelectricity remain largely in nascent stages. On epitaxial
Y:HfO$_2$ grown on ITO buffered YSZ substrates that crystallize in a mixed
monoclinic (non-polar) and orthorhombic (polar) phases, we introduce nitrogen
doping via post deposition rapid thermal annealing (RTA) in N$_2$ atmosphere at
900~$^\circ$C. As the annealing time increases from 10s to 4min, the monoclinic
phase fraction diminishes, enabling the emergence of well-defined ferroelectric
loops in films annealed beyond 2~min. We clearly show that this is an effect of
nitrogen incorporation (doping) into the samples through a suite of
structure-property correlation measurements including x-ray photoelectron
spectroscopy. These results reveal that nitrogen actively participates in the
RTA-induced phase stabilization, enabling ferroelectricity in epitaxial
Y:HfO$_2$ without sacrificing crystallographic coherence, providing a viable
pathway for structure-property correlation studies and a model system to study
opto-electronic devices integrated with ferroelectrics.

</details>


### [627] [Van der Waals Density Functional for Molecular Crystals](https://arxiv.org/abs/2509.02358)
*Trevor Jenkins,Kristian Berland,Timo Thonhauser*

Main category: cond-mat.mtrl-sci

TL;DR: vdW-DF3-mc是一个针对3D分子晶体优化设计的范德华力密度泛函，在保持vdW-DF3精度的同时，通过引入可调的交换增强因子和优化的核开关函数，显著提高了在分子晶体（特别是冰的多晶型）上的能量和几何精度。


<details>
  <summary>Details</summary>
Motivation: 现有vdW-DF3泛函在分子晶体方面存在参数化和交换泛化梯度近似（GGA）不灵活的限制，影响了其精度。

Method: 提出vdW-DF3-mc，通过优化vdW-DF3，引入了新的、可调的交换增强因子（参数与物理特性直接相关），并在非局域相关性中优先考虑核开关函数的平滑性，以恢复设计的灵活性。

Result: vdW-DF3-mc在分子晶体测试集上取得了高度精确的能量和几何性质。特别是在冰的多晶型研究中，体积和内聚能误差仅为1%左右。

Conclusion: vdW-DF3-mc在分子晶体方面表现出非常有前景的性能，尤其是在多晶型和氢键固体等重要子类别中。

Abstract: Since the development of the nonlocal correlation functional vdW-DF, the
family of van der Waals density functionals has grown to better describe a wide
variety of systems. A recent generation of the vdW-DF family, vdW-DF3, featured
a newly-constructed form of the nonlocal correlation that more accurately
modeled molecular dimers, layered structures, and surface adsorption. However,
it also revealed an intrinsic tradeoff in vdW-DF3's parametrization and
inflexibility of exchange in the generalized gradient approximation (GGA),
limiting its accuracy for molecular crystals. In this paper we propose a new
optimization of vdW-DF3 that is tailored to 3D molecular crystals. This
functional, called vdW-DF3-mc, contains a new, tunable form of the exchange
enhancement factor with parameters that directly correspond to physically
relevant qualities. In addition, within the nonlocal correlation, we prioritize
smoothness of the kernel switching function as a means of restoring flexibility
to vdW-DF3's design. Testing vdW-DF3-mc on several benchmark sets, we achieve
highly accurate energetics and geometries for molecular crystals. This is
particularly evident for the case of polymorphs of ice, for which errors in the
volume and cohesive energy are on the order of only 1%, indicating very
promising performance for important subcategories of molecular crystals, such
as polymorphism and hydrogen-bonded solids.

</details>


### [628] [Pressure-Induced Mechanical Instabilities in Cubic SiC: Structural and Electronic Properties](https://arxiv.org/abs/2509.02438)
*Carlos P. Herrero,Eduardo R. Hernandez,Gabriela Herrero-Saboya,Rafael Ramirez*

Main category: cond-mat.mtrl-sci

TL;DR: 压力和温度对3C-SiC结构和电子性质有显著影响，特别是带隙会随着压力的变化而变化，并在特定压力点趋近于零。


<details>
  <summary>Details</summary>
Motivation: 研究压力（静水压和单轴压）对3C-SiC结构和电子性质的影响。

Method: 使用基于高效紧束缚哈密顿量的分子动力学（MD）模拟，并通过路径积分MD模拟考虑核量子效应，并与密度泛函理论（DFT）计算进行验证。

Result: 静水压下，拉伸应力导致带隙在材料力学稳定性极限处消失。单轴压力下，拉伸和压缩在约90 GPa时导致材料不稳定，带隙趋近于零。还分析了内部能量、晶格参数和键长在温度和压力下的变化及其在不稳定性附近的异常。特别指出，零点运动导致约80 meV的带隙重整。

Conclusion: 压力和温度是影响3C-SiC电子性质的重要因素，在特定条件下可能导致材料发生相变或失效。

Abstract: Silicon carbide is widely used in electronics, ceramics, and renewable energy
due to its exceptional hardness and resistance. In this study, we investigate
the effects of hydrostatic and uniaxial pressure (both compressive and tensile)
on the structural and electronic properties of $3C$-SiC. Our analysis is based
on atomistic molecular dynamics (MD) simulations using an efficient
tight-binding Hamiltonian, whose accuracy is validated against density
functional theory calculations. Moreover, to account for nuclear quantum
effects, we employ path-integral MD simulations. Our results show significant
changes in the direct electronic gap as a function of temperature and pressure,
with a renormalization of about 80 meV due to zero-point motion. Under
hydrostatic tensile pressure, the direct band gap $E_{\Gamma}$ vanishes at the
material's mechanical stability limit (spinodal point, where the bulk modulus
$B \to 0$). For uniaxial pressure, we observe instabilities (Young's modulus $Y
\to 0$) at approximately 90 GPa for both tension and compression, where
$E_{\Gamma} \to 0$. Additionally, we analyze the pressure dependence of the
internal energy, lattice parameter, and bond length, along with their
finite-temperature fluctuations, which exhibit anomalies near the instability
points.

</details>


### [629] [Experimental electronic structure of the mineral superconductor covellite CuS](https://arxiv.org/abs/2509.02468)
*Alexandre Antezak,Takemi Kato,Pedro Rezende Gonçalves,Franck Fortuna,Marcin Rosmus,Natalia Olszowska,Andrés Felipe Santander-Syro,Emmanouil Frantzeskakis*

Main category: cond-mat.mtrl-sci

TL;DR: Covellite (CuS) is a natural superconductor. ARPES was used to study its experimental band structure, which agreed with DFT calculations and confirmed its quasi-2D electronic structure.


<details>
  <summary>Details</summary>
Motivation: While covellite (CuS) is known as a natural superconductor with a rich crystal structure and mixed valence of Cu, there's a lack of experimental data on its band structure. This study aims to experimentally probe the electronic structure of covellite.

Method: Angle Resolved PhotoEmission Spectroscopy (ARPES) was used to investigate the experimental electronic structure of covellite. The results were then compared with predictions from density-functional theory (DFT) calculations.

Result: The ARPES results showed remarkable agreement with DFT calculations. The experimental data revealed subtle fingerprints of the structural phase transition at 55 K and confirmed the quasi-2D nature of CuS's electronic structure.

Conclusion: The experimental band structure of covellite, as measured by ARPES, aligns well with DFT predictions, confirming its quasi-2D electronic nature and providing insights into the structural phase transition.

Abstract: Covellite (CuS) is the first known natural mineral superconductor. Despite
its simple chemical formula, covellite exhibits a rich crystal structure at the
origin of several remarkable properties. The ionic arrangement in CuS crystals
leads to a mixed valence of Cu and a second-order structural transition at 55
K. Despite the abundance of structural studies and theoretical reports on its
electronic structure, there are scarce references on its experimental band
structure. By means of Angle Resolved PhotoEmission Spectroscopy (ARPES), we
have probed the experimental electronic structure of covellite. We compare our
results with the predictions of density-functional theory (DFT) calculations.
Our experimental data are in remarkable agreement with the calculations,
revealing subtle fingerprints of the structural phase transition, and
confirming the quasi-2D nature of the electronic structure of CuS.

</details>


### [630] [Medium-range structural order in amorphous arsenic](https://arxiv.org/abs/2509.02484)
*Yuanbin Liu,Yuxing Zhou,Richard Ademuwagun,Luc Walterbos,Janine George,Stephen R. Elliott,Volker L. Deringer*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究利用机器学习势能和自动化工作流，通过先进的原子模拟揭示了非晶砷（a-As）中的中程有序（MRO）结构特征，并将其与非晶磷（a-P）进行了比较，指出了二面角分布在区分两者MRO中的关键作用，并阐述了压力依赖性结构行为的差异与环拓扑和结构熵的相互作用有关，最终证明了第一清晰衍射峰（FSDP）的起源与非晶网络中空隙的大小和空间分布密切相关。


<details>
  <summary>Details</summary>
Motivation: 阐明非晶材料中介观有序（MRO）的起源和性质，因为这是该领域一个悬而未决的问题。

Method: 采用基于机器学习势能的先进原子模拟，该势能是通过自动化工作流获得的。研究人员还复制了a-As的实验结构因子，特别是MRO的特征——第一清晰衍射峰（FSDP）。

Result: 模拟结果精确地重现了a-As的实验结构因子，特别是FSDP。通过比较a-As和a-P的结构，研究发现二面角分布是区分它们MRO的关键因素。此外，在压力作用下，a-As和a-P的结构行为表现出差异，这与环拓扑和结构熵的相互作用有关。最后，研究表明FSDP的起源与非晶网络中空隙的大小和空间分布密切相关。

Conclusion: 这项研究为非晶元素系统中的MRO提供了基础见解，并展示了自动化在机器学习驱动的原子模拟中的实用性。

Abstract: Medium-range order (MRO) is a key structural feature of amorphous materials,
but its origin and nature remain elusive. Here, we reveal the MRO in amorphous
arsenic (a-As) using advanced atomistic simulations, based on machine-learned
potentials derived using automated workflows. Our simulations accurately
reproduce the experimental structure factor of a-As, especially the first sharp
diffraction peak (FSDP), which is a signature of MRO. We compare and contrast
the structure of a-As with that of its lighter homologue, red amorphous
phosphorus (a-P), identifying the dihedral-angle distribution as a key factor
differentiating the MRO in both. The pressure-dependent structural behaviors of
a-As and a-P differ as well, which we link to the interplay of ring topology
and structural entropy. We finally show that the origin of the FSDP is closely
correlated with the size and spatial distribution of voids in the amorphous
networks. Our work provides fundamental insights into MRO in an amorphous
elemental system, and more widely it illustrates the usefulness of automation
for machine-learning-driven atomistic simulations.

</details>


### [631] [General structure factor and dynamic effects of the Dzyaloshinskii-Moriya interaction in S = 1/2 clusters](https://arxiv.org/abs/2509.02505)
*Evan M. Wilson,Joseph A. Prescott,Jason T. Haraldsen*

Main category: cond-mat.mtrl-sci

TL;DR: DMI affects spin dimers by controlling gap energy and transition intensity, with observable thermodynamic and spectral consequences.


<details>
  <summary>Details</summary>
Motivation: Understanding the effects of the Dzyaloshinskii-Moriya interaction (DMI) is crucial for nanoscale magnetism and spintronics.

Method: The study derives a general structure factor equation for an S = 1/2 dimer and uses exact diagonalization of the Heisenberg spin-spin Hamiltonian, including isotropic and anisotropic interactions, external magnetic fields, and electric fields.

Result: The DM interaction splits energy eigenstates, induces level repulsion, and modifies the spin dimer structure factor, showing a correspondence between thermodynamic anomalies in heat capacity and spin-resolved selection rules.

Conclusion: The anisotropic ratio and complex phase of DMI control the gap energy and intensity of the $|0,0angle 	o |1,0angle$ transition in spin dimers, with observable consequences in thermodynamic and spectral properties.

Abstract: Understanding the effects of the Dzyaloshinskii-Moriya interaction (DMI) has
become increasingly important in the context of nanoscale magnetism and
spintronics. In this study, we derive a general structure factor equation for
an S = 1/2 dimer and show that the anisotropic ratio $D_z/|J|$ and complex
phase $\phi$ of the DMI control the gap energy and intensity of the
$|0,0\rangle \to |1,0\rangle$ transition. {Using exact diagonalization of the
Heisenberg spin-spin Hamiltonian that incorporates both isotropic and
anisotropic interactions,} as well as the effects of an external magnetic field
and an electric field. Our results show that the DM interaction splits energy
eigenstates, induces level repulsion, and significantly modifies the spin dimer
structure factor. These effects reveal a direct correspondence between
thermodynamic anomalies in the heat capacity and spin-resolved selection rules.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [632] [Community Detection using Fortunato's Performance Measure](https://arxiv.org/abs/2509.00938)
*Srushti Thakar,Amit A. Nanavati*

Main category: cs.SI

TL;DR: 本文探讨了Fortunato提出的性能度量（fp度量）在社区检测中的应用，并提出了一种名为fpGreed的贪婪算法和一种更快的启发式算法fastFp。


<details>
  <summary>Details</summary>
Motivation: 评估图划分优劣的质量函数，特别是Fortunato提出的性能度量（fp度量）。

Method: 提出了一种名为fpGreed的贪婪算法，该算法通过在顶点和社区两个层级上迭代优化fp度量来工作。然后，提出了一种更快的启发式算法fastFp，适用于大型数据集。

Result: 在youtube和livejournal等大型数据集上，fastFp算法在计算时间和解决方案质量方面都表现良好。

Conclusion: fpGreed算法和fastFp算法在社区检测方面是有效的，其中fastFp在处理大型数据集时尤其出色。

Abstract: In his paper on Community Detection [1], Fortunato introduced a quality
function called performance to assess the goodness of a graph partition. This
measure counts the number of correctly ``interpreted" pairs of vertices, i. e.
two vertices belonging to the same community and connected by an edge, or two
vertices belonging to different communities and not connected by an edge. In
this paper, we explore Fortunato's performance measure (fp measure) for
detecting communities in unweighted, undirected networks. First, we give a
greedy algorithm fpGreed that tries to optimise the fp measure by working
iteratively at two-levels, vertex-level and community-level. At the vertex
level, a vertex joins a community only if the fp value improves. Once this is
done, an initial set of communities are obtained. At the next stage, two
communities merge only if the fp measure improves. Once there are no further
improvements to be made, the algorithm switches back to the vertex level and so
on. fpGreed terminates when there are no changes to any community. We then
present a faster heuristic algorithm fastFp more suitable for running on large
datasets. We present the quality of the communities and the time it takes to
compute them on several well-known datasets. For some of the large datasets,
such as youtube and livejournal, we find that Algorithm fastFP performs really
well, both in terms of the time and the quality of the solution obtained.

</details>


### [633] [Towards Propagation-aware Representation Learning for Supervised Social Media Graph Analytics](https://arxiv.org/abs/2509.01124)
*Wei Jiang,Tong Chen,Wei Yuan,Xiangyu Zhao,Quoc Viet Hung Nguyen,Hongzhi Yin*

Main category: cs.SI

TL;DR: 本研究提出了一种通用的表示学习框架，用于解决社交媒体图分析中的挑战，该框架结合了双编码器结构和动量引导传播模块，通过整合基于马尔可夫链的传输模型来捕捉信息传播动态，提高了模型的鲁棒性和任务通用性，并在各种社交媒体图挖掘任务上取得了最先进的性能，同时展现了在数据稀疏任务上的迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有的社交媒体图分析解决方案大多是纯粹的、数据驱动的，容易受到噪声的影响，并且依赖于特定任务的模型设计，这使得模型难以在不同任务和数据集上高效重用，并增加了重复工程的成本。本研究旨在解决这些问题，提出一个通用的表示学习框架。

Method: 本研究提出的框架整合了一个双编码器结构和一个动量引导传播模块。它利用两个编码器联合对结构和上下文信息进行建模，并通过整合基于马尔可夫链的传输模型的原则性动量知识来捕捉社交媒体图中的信息传播动态，从而推导出一个传播感知的编码器和相应的优化目标。

Result: 本研究提出的框架在图分类、节点分类和链接预测等多种社交媒体图挖掘任务上，使用统一的架构实现了最先进的性能。此外，该框架在数据集之间表现出很强的零样本和少样本迁移能力，证明了其在处理数据稀疏任务时的实用性。

Conclusion: 本研究提出的通用表示学习框架通过整合双编码器结构和动量引导传播模块，并引入基于马尔可夫链的传输模型来捕捉信息传播动态，成功解决了社交媒体图分析中的噪声敏感性和任务通用性问题。该框架在多项任务上取得了最先进的性能，并展现了良好的迁移学习能力，为社交媒体图挖掘提供了更强大、更通用的解决方案。

Abstract: Social media platforms generate vast, complex graph-structured data,
facilitating diverse tasks such as rumor detection, bot identification, and
influence modeling. Real-world applications like public opinion monitoring and
stock trading -- which have a strong attachment to social media -- demand
models that are performant across diverse tasks and datasets. However, most
existing solutions are purely data-driven, exhibiting vulnerability to the
inherent noise within social media data. Moreover, the reliance on
task-specific model design challenges efficient reuse of the same model
architecture on different tasks, incurring repetitive engineering efforts. To
address these challenges in social media graph analytics, we propose a general
representation learning framework that integrates a dual-encoder structure with
a kinetic-guided propagation module. In addition to jointly modeling structural
and contextual information with two encoders, our framework innovatively
captures the information propagation dynamics within social media graphs by
integrating principled kinetic knowledge. By deriving a propagation-aware
encoder and corresponding optimization objective from a Markov chain-based
transmission model, the representation learning pipeline receives a boost in
its robustness to noisy data and versatility in diverse tasks. Extensive
experiments verify that our approach achieves state-of-the-art performance with
a unified architecture on a variety of social media graph mining tasks spanning
graph classification, node classification, and link prediction. Besides, our
solution exhibits strong zero-shot and few-shot transferability across
datasets, demonstrating practicality when handling data-scarce tasks.

</details>


### [634] [Unnoticeable Community Deception via Multi-objective Optimization](https://arxiv.org/abs/2509.01438)
*Junyuan Fang,Huimin Liu,Yueqi Peng,Jiajing Wu,Zibin Zheng,Chi K. Tse*

Main category: cs.SI

TL;DR: 社区欺骗方法旨在降低社区检测算法的有效性，但现有方法忽略了评估指标的合理性和攻击的不可察觉性。本研究提出了新的欺骗指标和基于多目标优化的方法，并通过实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决社区检测可能引发的隐私和信息安全问题，需要开发社区欺骗方法来降低检测算法的有效性，同时克服现有方法在评估指标合理性和攻击不可察觉性方面的局限性。

Method: 首先，通过实证研究调查了模块度降低这一常用欺骗指标的局限性。然后，提出了一个新的欺骗指标，并结合攻击预算将不可察觉的社区欺骗任务建模为多目标优化问题。为了进一步提高欺骗性能，提出了两种变体方法，结合了度偏向和社区偏向的候选节点选择机制。

Result: 在三个基准数据集上的大量实验证明了所提出的社区欺骗策略的优越性。

Conclusion: 本研究通过提出新的欺骗指标和优化的欺骗方法，有效解决了现有社区欺骗方法的局限性，并在实验中证明了其有效性。

Abstract: Community detection in graphs is crucial for understanding the organization
of nodes into densely connected clusters. While numerous strategies have been
developed to identify these clusters, the success of community detection can
lead to privacy and information security concerns, as individuals may not want
their personal information exposed. To address this, community deception
methods have been proposed to reduce the effectiveness of detection algorithms.
Nevertheless, several limitations, such as the rationality of evaluation
metrics and the unnoticeability of attacks, have been ignored in current
deception methods. Therefore, in this work, we first investigate the
limitations of the widely used deception metric, i.e., the decrease of
modularity, through empirical studies. Then, we propose a new deception metric,
and combine this new metric together with the attack budget to model the
unnoticeable community deception task as a multi-objective optimization
problem. To further improve the deception performance, we propose two variant
methods by incorporating the degree-biased and community-biased candidate node
selection mechanisms. Extensive experiments on three benchmark datasets
demonstrate the superiority of the proposed community deception strategies.

</details>


### [635] [Content and Engagement Trends in COVID-19 YouTube Videos: Evidence from the Late Pandemic](https://arxiv.org/abs/2509.01954)
*Nirmalya Thakur,Madeline D Hartel,Lane Michael Boden,Dallas Enriquez,Boston Joyner Ricks*

Main category: cs.SI

TL;DR: 该研究分析了2023年1月至2024年10月期间发布的约10,000个与COVID-19相关的YouTube视频，评估了时间、词汇、语言和结构因素在疫情晚期对参与度的影响。


<details>
  <summary>Details</summary>
Motivation: 评估时间、词汇、语言和结构因素如何影响疫情晚期COVID-19相关YouTube视频的参与度。

Method: 分析了视频发布时间、标题词汇、内容（短视频、长视频、新闻、政治）、视频描述情感分析以及视频时长与观看次数之间的关系。

Result: 发布活动显示出一致的周内效应，观看次数在不同时间段内达到峰值（周一、周三、周五）。标题中包含“shorts”的视频观看次数最高。视频描述情感分析与观看次数存在弱相关性，但去除异常值后相关性增强。长视频（人们和博客）平均观看次数为209,114次，短娱乐视频平均观看次数为288,675次，中长新闻和政治视频平均观看次数分别为51,309次和59,226次。

Conclusion: 疫情晚期YouTube上与COVID-19相关的视频参与度模式具有独特的特征，这些特征受发布时间表、标题词汇、主题和特定类型的视频时长效应驱动。

Abstract: This work investigated about 10,000 COVID-19-related YouTube videos published
between January 2023 and October 2024 to evaluate how temporal, lexical,
linguistic, and structural factors influenced engagement during the late
pandemic period. Publishing activity showed consistent weekday effects: in the
first window, average views peaked on Mondays at 92,658; in the second, on
Wednesdays at 115,479; and in the third, on Fridays at 84,874, reflecting a
shift in audience attention toward mid- and late week. Lexical analysis of
video titles revealed recurring high-frequency keywords related to COVID-19 and
YouTube features, including COVID, coronavirus, shorts, and live. Frequency
analysis revealed sharp spikes, with COVID appearing in 799 video titles in
August 2024, while engagement analysis showed that videos titled with shorts
attracted very high views, peaking at 2.16 million average views per video in
June 2023. Analysis of sentiment of video descriptions in English showed weak
correlation with views in the raw data (Pearson r = 0.0154, p = 0.2987), but
stronger correlations emerged once outliers were addressed, with Spearman r =
0.110 (p < 0.001) and Pearson r = 0.0925 (p < 0.001). Category-level analysis
of video durations revealed contrasting outcomes: long videos focusing on
people and blogs averaged 209,114 views, short entertainment videos averaged
288,675 views, and medium-to-long news and politics videos averaged 51,309 and
59,226 views, respectively. These results demonstrate that engagement patterns
of COVID-19-related videos on YouTube during the late pandemic followed
distinct characteristics driven by publishing schedules, title vocabulary,
topics, and genre-specific duration effects.

</details>


### [636] [Dynamics in Two-Sided Attention Markets: Objective, Optimization, and Control](https://arxiv.org/abs/2509.01970)
*Haiqing Zhu,Yun Kuen Cheung,Lexing Xie*

Main category: cs.SI

TL;DR: 该研究检验了平台、用户和创作者之间的双边市场，并为吸引力市场的多样化结果提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 理解内容创作和消费的生态系统，特别是双边市场（平台、用户和创作者）的相互作用，因为目前的研究主要集中在单边市场。

Method: 设计了一个潜在函数来描述用户、平台和创作者之间的耦合相互作用，并将创作者的最佳响应动态与用户的多项选择相结合，证明这等同于在潜在函数上进行镜像下降。研究还表明，各种平台排名策略对应于一组潜在函数，而双边相互作用的动态仍然对应于镜像下降。此外，还为非凸函数中的镜像下降提供了新的局部收敛结果。

Result: 证明了创作者的最佳响应动态与用户的多项选择相结合等同于在潜在函数上进行镜像下降，并且双边相互作用的动态也对应于镜像下降。

Conclusion: 该研究为理解吸引力市场的双边动态提供了一个理论框架，并解释了观察到的各种结果，提供了对内容生态系统更深入的理解。

Abstract: With most content distributed online and mediated by platforms, there is a
pressing need to understand the ecosystem of content creation and consumption.
A considerable body of recent work shed light on the one-sided market on
creator-platform or user-platform interactions, showing key properties of
static (Nash) equilibria and online learning. In this work, we examine the {\it
two-sided} market including the platform and both users and creators. We design
a potential function for the coupled interactions among users, platform and
creators. We show that such coupling of creators' best-response dynamics with
users' multilogit choices is equivalent to mirror descent on this potential
function. Furthermore, a range of platform ranking strategies correspond to a
family of potential functions, and the dynamics of two-sided interactions still
correspond to mirror descent. We also provide new local convergence result for
mirror descent in non-convex functions, which could be of independent interest.
Our results provide a theoretical foundation for explaining the diverse
outcomes observed in attention markets.

</details>


### [637] [Maximum entropy temporal networks](https://arxiv.org/abs/2509.02098)
*Paolo Barucca*

Main category: cs.SI

TL;DR: 本文提出一种基于最大熵的连续时间网络建模方法，将时间演化和边结构解耦，并推导出相应的生成模型，验证了其在拟合网络性质和预测能力上的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的网络模型大多基于静态图，无法很好地捕捉网络随时间演化的动态特性，特别是连续时间交互网络的研究较少。本文旨在提出一种适用于连续时间网络的建模方法。

Method: 本文提出一种基于最大熵（MaxEnt）的连续时间网络建模方法。该方法将网络的时变性和边结构进行解耦，假设网络由全局时间过程（如泊松过程或霍克斯过程）和静态最大熵边概率组成。通过最大化网络路径熵和满足边约束，推导出网络的似然函数和度期望，形成了一类有效的生成模型。

Result: 研究结果表明，全局霍克斯时间层相比于通用的非齐次泊松过程（NHPP）能够持续提升模型的对数似然度。同时，MaxEnt边标签能够很好地恢复网络的度约束，并准确重现预期的度分布曲线。

Conclusion: 本文提出的最大熵方法为连续时间网络的建模提供了一个统一的框架，并将泊松过程和霍克斯过程与最大熵网络集合联系起来。该框架具有良好的可解释性和生成能力，并且可以通过集成社区检测、霍克斯校准和核估计等方法进一步扩展和改进。

Abstract: Temporal networks consist of timestamped directed interactions rather than
static links. These links may appear continuously in time, yet few studies have
directly tackled the continuous-time modeling of networks. Here, we introduce a
maximum entropy approach to temporal networks and with basic assumptions on
constraints, the corresponding network ensembles admit a modular and
interpretable representation: a set of global time processes -an inhomogeneous
Poisson or a Hawkes process- and a static maximum-entropy (MaxEnt) edge, e.g.
node pair, probability. This time-edge labels factorization yields closed-form
log-likelihoods, degree/unique-edge expectations, and yields a whole class of
effective generative models. We provide maximum-entropy derivation of a
log-linear Hawkes/NHPP intensity for temporal networks via functional
optimization over path entropy, connecting inhomogeneous Poisson modeling -e.g.
Hawkes models- to MaxEnt network ensembles. Global Hawkes time layers
consistently improve log-likelihood over generic NHPP, while the MaxEnt edge
labels recover strength constraints and reproduce expected unique-degree
curves. We discuss the limitations of this unified framework and how it could
be integrated with calibrated community/motif tools, Hawkes calibration
procedures, and (neural) kernel estimation.

</details>


### [638] [RumorSphere: A Framework for Million-scale Agent-based Dynamic Simulation of Rumor Propagation](https://arxiv.org/abs/2509.02172)
*Yijun Liu,Wu Liu,Xiaoyan Gu,Weiping Wang,Jiebo Luo,Yongdong Zhang*

Main category: cs.SI

TL;DR: 该论文提出了一种基于大型语言模型（LLM）的新型动态、分层社交网络模拟框架，能够模拟数百万代理的谣言传播。实验表明，该框架在模拟现实世界谣言传播方面表现优于现有模型，并将观点偏差平均减少了64%。研究发现，紧密连接的本地社区结构是促进谣言快速传播的关键因素，其中“社会压力”会迫使个体从众，少数派观点被压制，从而形成加速谣言传播的恶性循环。干预策略评估显示，早期、持续的纠正信息以及通过意见领袖辟谣是最有效的策略。


<details>
  <summary>Details</summary>
Motivation: 传统的谣言传播模型过于简化或静态，无法有效模拟现实世界的谣言动态。因此，需要开发一种能够捕捉复杂社会动态的新型模拟框架。

Method: 利用大型语言模型（LLM）的强大行为模仿能力，构建了一个支持数百万代理的动态、分层社交网络模拟框架。该框架被用于模拟现实世界的谣言动态，并通过与真实数据集的对比来验证其有效性，同时评估了不同的干预策略。

Result: 实验结果表明，该模拟框架与现实世界谣言传播高度一致，并将观点偏差平均降低了64%，优于现有模型。研究还发现，社交网络中紧密连接的本地社区结构是加速谣言传播的关键因素，其中“社会压力”和少数派观点的压制会形成恶性循环。在干预策略方面，早期和持续的纠正信息以及通过意见领袖辟谣被证明是最有效的。具体来说，早期和持续的干预措施比一次性干预更能有效缓解谣言传播，而通过意见领袖进行辟谣则效果最佳。

Conclusion: 基于LLM的多代理系统在社交网络模拟方面具有巨大潜力，为社会科学研究提供了新的见解。紧密连接的社区结构是谣言快速传播的重要原因，而早期、持续的干预以及意见领袖的辟谣是抑制谣言传播的有效策略。这些发现对于公众舆论管理和政策制定具有重要意义。

Abstract: Rumor propagation modeling is critical for understanding the dynamics of
misinformation spread. Previous models are either overly simplistic or static,
making them ineffective for simulating real-world rumor dynamics. In this
paper, leveraging the impressive human behavior imitation capabilities of large
language models (LLMs), we present a novel dynamic and hierarchical social
network simulation framework, which supports simulations with millions of
agents. This simulator is used to explore the rumor dynamic in the real world.
Experiments on real-world rumor propagation datasets reveal a strong alignment
between simulated and real-world rumor dynamics, outperforming existing models
with an average 64\% reduction in opinion bias. Our findings underscore the
substantial potential of LLM-based multi-agent systems in social network
simulations, offering critical insights for advancing social science research.
Furthermore, our analysis reveals that the tightly connected local community
structure within social networks is one of the key factors promoting the rapid
spread of rumors. In these communities, as rumors propagate to a certain
extent, some individuals, influenced by ''social pressure'', are often
compelled to conform, while holders of minority opinions are further silenced,
resulting in a vicious cycle that accelerates rumor dissemination. Through
counterfactual experiments, we evaluate various intervention strategies and
demonstrate that early and sustained efforts to correct misinformation are more
effective in mitigating the spread of rumors, while debunking rumors through
opinion leaders proves to be the most effective strategy. These findings
provide valuable insights for public opinion management and policymaking.

</details>


### [639] [Hierarchical Single-Linkage Clustering for Community Detection with Overlaps and Outliers](https://arxiv.org/abs/2509.02334)
*Ryan DeWolfe*

Main category: cs.SI

TL;DR: HDBSCAN的层次单链接聚类算法可用于图聚类，但没有一种单一方法适用于所有类型的图。


<details>
  <summary>Details</summary>
Motivation: 大多数社区检测方法对数据中的社区做了很强的假设，例如每个顶点必须属于一个社区。HDBSCAN是一种允许存在异常点的聚类算法，许多社区检测算法也试图增加相似节点之间的边权重并降低噪声边的权重。本文将HDBSCAN的层次单链接聚类算法应用于各种节点/边相似度得分，以确定是否存在一种能够有效检测聚类同时允许异常点的算法。

Method: 将HDBSCAN的层次单链接聚类算法应用于多种节点/边相似度得分。

Result: 在合成和真实世界数据集上的实验表明，没有一种单一方法对所有类型的图都是最优的，但其性能表明层次单链接聚类是图聚类的一个可行范例。

Conclusion: HDBSCAN的层次单链接聚类是一种用于图聚类的可行方法。

Abstract: Most community detection approaches make very strong assumptions about
communities in the data, such as every vertex must belong to exactly one
community (the communities form a partition). For vector data, Hierarchical
Density Based Spatial Clustering for Applications with Noise (HDBSCAN) has
emerged as a leading clustering algorithm that allows for outlier points that
do not belong to any cluster. The first step in HDBSCAN is to redefine the
distance between vectors in such a way that single-linkage clustering is
effective and robust to noise. Many community detection algorithms start with a
similar step that attempts to increase the weight of edges between similar
nodes and decrease weights of noisy edges. In this paper, we apply the
hierarchical single-linkage clustering algorithm from HDBSCAN to a variety of
node/edge similarity scores to see if there is an algorithm that can
effectively detect clusters while allowing for outliers. In experiments on
synthetic and real world data sets, we find that no single method is optimal
for every type of graph, but the admirable performance indicates that
hierarchical single-linkage clustering is a viable paradigm for graph
clustering.

</details>


### [640] [A Keyframe-Based Approach for Auditing Bias in YouTube Shorts Recommendations](https://arxiv.org/abs/2509.02543)
*Mert Can Cakmak,Nitin Agarwal*

Main category: cs.SI

TL;DR: YouTube Shorts等短视频平台的推荐系统不透明，可能导致内容偏见和话题漂移。本文提出一种基于关键帧的审计方法，提取关键帧并生成字幕，映射推荐链以观察话题漂移和潜在过滤，发现政治敏感话题与其他类别存在差异，表明关键帧是理解短视频算法偏见的一种有效方式。


<details>
  <summary>Details</summary>
Motivation: YouTube Shorts等短视频平台影响着数十亿用户的参与方式，但其推荐系统却不透明，可能导致用户接触的内容发生重大变化，尤其是在政治敏感话题方面。

Method: 提出一种基于关键帧的审计方法，提取关键帧并生成字幕，将它们嵌入共享内容空间，并通过跨推荐链的视觉映射来观察和分析偏见与漂移。

Result: 通过视觉映射观察到推荐链中存在持续的漂移和聚类模式，表明存在话题漂移和潜在过滤。将政治敏感话题与通用YouTube类别进行比较，发现了推荐行为的显著差异。

Conclusion: 关键帧为理解短视频算法偏见提供了一种高效且可解释的视角。

Abstract: YouTube Shorts and other short-form video platforms now influence how
billions engage with content, yet their recommendation systems remain largely
opaque. Small shifts in promoted content can significantly impact user
exposure, especially for politically sensitive topics. In this work, we propose
a keyframe-based method to audit bias and drift in short-form video
recommendations. Rather than analyzing full videos or relying on metadata, we
extract perceptually salient keyframes, generate captions, and embed both into
a shared content space. Using visual mapping across recommendation chains, we
observe consistent shifts and clustering patterns that indicate topic drift and
potential filtering. Comparing politically sensitive topics with general
YouTube categories, we find notable differences in recommendation behavior. Our
findings show that keyframes provide an efficient and interpretable lens for
understanding bias in short-form video algorithms.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [641] [KG-RAG: Enhancing GUI Agent Decision-Making via Knowledge Graph-Driven Retrieval-Augmented Generation](https://arxiv.org/abs/2509.00366)
*Ziyi Guan,Jason Chun Lok Li,Zhijian Hou,Pingping Zhang,Donglai Xu,Yuzhi Zhao,Mengyang Wu,Jinpeng Chen,Thanh-Toan Nguyen,Pengfei Xian,Wenao Ma,Shengchao Qin,Graziano Chesi,Ngai Wong*

Main category: cs.MA

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Despite recent progress, Graphic User Interface (GUI) agents powered by Large
Language Models (LLMs) struggle with complex mobile tasks due to limited
app-specific knowledge. While UI Transition Graphs (UTGs) offer structured
navigation representations, they are underutilized due to poor extraction and
inefficient integration. We introduce KG-RAG, a Knowledge Graph-driven
Retrieval-Augmented Generation framework that transforms fragmented UTGs into
structured vector databases for efficient real-time retrieval. By leveraging an
intent-guided LLM search method, KG-RAG generates actionable navigation paths,
enhancing agent decision-making. Experiments across diverse mobile apps show
that KG-RAG outperforms existing methods, achieving a 75.8% success rate (8.9%
improvement over AutoDroid), 84.6% decision accuracy (8.1% improvement), and
reducing average task steps from 4.5 to 4.1. Additionally, we present
KG-Android-Bench and KG-Harmony-Bench, two benchmarks tailored to the Chinese
mobile ecosystem for future research. Finally, KG-RAG transfers to web/desktop
(+40% SR on Weibo-web; +20% on QQ Music-desktop), and a UTG cost ablation shows
accuracy saturates at ~4h per complex app, enabling practical deployment
trade-offs.

</details>


### [642] [MobiAgent: A Systematic Framework for Customizable Mobile Agents](https://arxiv.org/abs/2509.00531)
*Cheng Zhang,Erhu Feng,Xi Zhao,Yisheng Zhao,Wangbo Gong,Jiahui Sun,Dong Du,Zhichao Hua,Yubin Xia,Haibo Chen*

Main category: cs.MA

TL;DR: MobiAgent是一个创新的移动代理系统，通过MobiMind系列模型、AgentRR加速框架和MobiFlow基准测试套件，解决了现有移动代理在准确性和效率方面的挑战。该系统还包括一个AI辅助的数据收集流程，以降低数据成本。MobiAgent在真实世界的移动场景中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型（VLM）的GUI移动代理在实际任务执行中面临准确性和效率的挑战。

Method: 提出MobiAgent系统，包含MobiMind系列代理模型、AgentRR加速框架和MobiFlow基准测试套件。开发AI辅助的敏捷数据收集流程以降低数据成本。

Result: 与通用语言模型和专用GUI代理模型相比，MobiAgent在真实世界的移动场景中取得了最先进的性能。

Conclusion: MobiAgent系统及其相关组件有效提高了移动代理在真实世界场景中的性能和效率，并降低了数据收集成本。

Abstract: With the rapid advancement of Vision-Language Models (VLMs), GUI-based mobile
agents have emerged as a key development direction for intelligent mobile
systems. However, existing agent models continue to face significant challenges
in real-world task execution, particularly in terms of accuracy and efficiency.
To address these limitations, we propose MobiAgent, a comprehensive mobile
agent system comprising three core components: the MobiMind-series agent
models, the AgentRR acceleration framework, and the MobiFlow benchmarking
suite. Furthermore, recognizing that the capabilities of current mobile agents
are still limited by the availability of high-quality data, we have developed
an AI-assisted agile data collection pipeline that significantly reduces the
cost of manual annotation. Compared to both general-purpose LLMs and
specialized GUI agent models, MobiAgent achieves state-of-the-art performance
in real-world mobile scenarios.

</details>


### [643] [Nash Q-Network for Multi-Agent Cybersecurity Simulation](https://arxiv.org/abs/2509.00678)
*Qintong Xie,Edward Koh,Xavier Cadet,Peter Chin*

Main category: cs.MA

TL;DR: 本文提出了一种新颖的基于策略的Nash Q学习算法，用于在网络安全防御场景中训练多智能体强化学习（MARL）代理，以应对复杂性和非平稳性挑战，并展示了其在网络防御模拟中的有效性。


<details>
  <summary>Details</summary>
Motivation: 网络安全防御涉及守方和攻击方之间的交互，MARL是模拟和学习这些场景策略的理想方法。然而，MARL面临着在复杂环境中同时训练智能体的挑战。

Method: 提出了一种新颖的基于策略的Nash Q学习算法，称为Nash Q-Network。该算法结合了PPO、DQN和Nash-Q算法的优点，旨在直接收敛到稳定的均衡点，学习Nash最优策略，以应对非平稳性和不稳定性等挑战。训练过程采用了分布式数据收集和精心设计的智能体及Critic神经网络架构。

Result: 成功地将该算法应用于一个复杂网络防御模拟中，该模拟被视为一个双人零和马尔可夫博弈。Nash Q-Network学习到的Nash最优策略能够转化为强大的网络防御能力。

Conclusion: 提出的Nash Q-Network能够有效地解决MARL在网络安全防御场景中的挑战，通过学习Nash最优策略来提供强大的防御能力。

Abstract: Cybersecurity defense involves interactions between adversarial parties
(namely defenders and hackers), making multi-agent reinforcement learning
(MARL) an ideal approach for modeling and learning strategies for these
scenarios. This paper addresses one of the key challenges to MARL, the
complexity of simultaneous training of agents in nontrivial environments, and
presents a novel policy-based Nash Q-learning to directly converge onto a
steady equilibrium. We demonstrate the successful implementation of this
algorithm in a notable complex cyber defense simulation treated as a two-player
zero-sum Markov game setting. We propose the Nash Q-Network, which aims to
learn Nash-optimal strategies that translate to robust defenses in
cybersecurity settings. Our approach incorporates aspects of proximal policy
optimization (PPO), deep Q-network (DQN), and the Nash-Q algorithm, addressing
common challenges like non-stationarity and instability in multi-agent
learning. The training process employs distributed data collection and
carefully designed neural architectures for both agents and critics.

</details>


### [644] [Controller synthesis method for multi-agent system based on temporal logic specification](https://arxiv.org/abs/2509.00870)
*Ruohan Huang,Zining Cao*

Main category: cs.MA

TL;DR: 本论文提出了一种用于半合作半竞争多智能体概率离散事件系统的控制器综合方法，使用线性时序逻辑和概率模型检查来解决控制器综合问题。


<details>
  <summary>Details</summary>
Motivation: 传统控制器综合方法主要面向单智能体和非概率系统，但随着系统复杂性增加，控制需求也日益复杂，因此需要一种能处理更复杂系统的新方法。

Method: 提出了一种结合概率模型检查的控制器综合算法，并使用线性时序逻辑公式来描述控制规范。

Result: 通过案例研究验证了所提出方法的有效性。

Conclusion: 该方法可以确保在一定程度上满足规范要求。

Abstract: Controller synthesis is a theoretical approach to the systematic design of
discrete event systems. It constructs a controller to provide feedback and
control to the system, ensuring it meets specified control specifications.
Traditional controller synthesis methods often use formal languages to describe
control specifications and are mainly oriented towards single-agent and
non-probabilistic systems. With the increasing complexity of systems, the
control requirements that need to be satisfied also become more complex. Based
on this, this paper proposes a controller synthesis method for semi-cooperative
semi-competitive multi-agent probabilistic discrete event systems to solve the
controller synthesis problem based on temporal logic specifications. The
controller can ensure the satisfaction of specifications to a certain extent.
The specification is given in the form of a linear temporal logic formula. This
paper designs a controller synthesis algorithm that combines probabilistic
model checking. Finally, the effectiveness of this method is verified through a
case study.

</details>


### [645] [ShortageSim: Simulating Drug Shortages under Information Asymmetry](https://arxiv.org/abs/2509.01813)
*Mingxuan Cui,Yilan Jiang,Duo Zhou,Cheng Qian,Yuji Zhang,Qiong Wang*

Main category: cs.MA

TL;DR: 该研究提出了ShortageSim，一个基于LLM的多智能体模拟框架，用于模拟和应对药物短缺。该框架通过模拟制造商、买家和监管机构之间的复杂互动，并利用LLM处理不确定性下的有限理性决策，以解决传统模型信息不对称的问题。实验表明，ShortageSim能显著缩短药物短缺的解决周期，并已开源。


<details>
  <summary>Details</summary>
Motivation: 药物短缺对全球病患护理和医疗系统构成严重风险，但由于药品供应链信息不对称，监管干预措施的有效性尚未得到充分理解。

Method: 提出ShortageSim，一个基于LLM的多智能体模拟框架，捕捉药品制造商、机构买家和监管机构在应对短缺警报时的战略互动。该框架利用LLM模拟不确定性下的有限理性决策，并进行为期多个季度的连续生产博弈，模拟FDA公告（包括反应性警报和前瞻性警告）如何影响产能投资和采购决策。

Result: 在对历史短缺事件的实验中，ShortageSim将已停产披露案例的解决延迟百分比降低了83%，使模拟持续时间比零样本基线更接近实际情况。

Conclusion: ShortageSim是一个新颖的计算框架，可用于设计和测试复杂、信息匮乏的供应链中的干预措施。研究人员已将ShortageSim及包含2,925个FDA短缺事件的数据集开源。

Abstract: Drug shortages pose critical risks to patient care and healthcare systems
worldwide, yet the effectiveness of regulatory interventions remains poorly
understood due to fundamental information asymmetries in pharmaceutical supply
chains. We present \textbf{ShortageSim}, the first Large Language Model
(LLM)-based multi-agent simulation framework that captures the complex,
strategic interactions between drug manufacturers, institutional buyers, and
regulatory agencies in response to shortage alerts. Unlike traditional
game-theoretic models that assume perfect rationality and complete information,
\textbf{ShortageSim} leverages LLMs to simulate bounded-rational
decision-making under uncertainty. Through a sequential production game
spanning multiple quarters, we model how FDA announcements, both reactive
alerts about existing shortages and proactive warnings about potential
disruptions, propagate through the supply chain and influence capacity
investment and procurement decisions. Our experiments on historical shortage
events reveal that \textbf{ShortageSim} reduces the resolution-lag percentage
for discontinued-disclosed cases by 83\%, bringing simulated durations more
aligned to ground truth than the zero-shot baseline. We open-source
\textbf{ShortageSim} and a dataset of 2,925 FDA shortage events at
https://github.com/Lemutisme/Sortage_Management, providing a novel
computational framework for designing and testing interventions in complex,
information-scarce supply chains.

</details>


### [646] [Contemporary Agent Technology: LLM-Driven Advancements vs Classic Multi-Agent Systems](https://arxiv.org/abs/2509.02515)
*Costin Bădică,Amelia Bădică,Maria Ganzha,Mirjana Ivanović,Marcin Paprzycki,Dan Selişteanu,Zofia Wrona*

Main category: cs.MA

TL;DR: LLM驱动的智能体技术与经典多智能体系统(MAS)的比较研究，探讨了模型、方法和特征，并分析了LLM的最新进展与MAS的关联，最后指出了该领域的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在全面反思当代智能体技术，重点关注由大型语言模型（LLM）驱动的进展与经典的“多智能体系统”（MAS）的对比。

Method: 本文深入探讨了定义这些新系统的模型、方法和特征，并批判性地分析了近期发展与MAS核心学术文献的关联。

Result: LLM与经典MAS的对比分析结果。

Conclusion: LLM在智能体技术中的应用带来了新的机遇和挑战，需要进一步研究以实现其全部潜力。

Abstract: This contribution provides our comprehensive reflection on the contemporary
agent technology, with a particular focus on the advancements driven by Large
Language Models (LLM) vs classic Multi-Agent Systems (MAS). It delves into the
models, approaches, and characteristics that define these new systems. The
paper emphasizes the critical analysis of how the recent developments relate to
the foundational MAS, as articulated in the core academic literature. Finally,
it identifies key challenges and promising future directions in this rapidly
evolving domain.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [647] [Exploring the Efficacy of Convolutional Neural Networks in Sleep Apnea Detection from Single Channel EEG](https://arxiv.org/abs/2509.00012)
*Chun Hin Siu,Hossein Miri*

Main category: eess.SP

TL;DR: 本文提出了一种使用卷积神经网络（CNN）结合单通道脑电图（EEG）数据来检测睡眠呼吸暂停的新方法，旨在克服传统多导睡眠图（PSG）的局限性，为家庭应用提供更便捷的诊断方案。


<details>
  <summary>Details</summary>
Motivation: 现有睡眠呼吸暂停诊断方法（如PSG）成本高、操作复杂且影响睡眠质量，难以满足大规模筛查和家庭监测的需求，因此需要开发更便捷、自动化的检测方法。

Method: 该研究采用卷积神经网络（CNN）模型，并结合了无限冲激响应（IIR）巴特沃斯滤波器进行预处理，构建了一个包含更广泛时间上下文的数据集，并使用SMOTETomek技术处理类别不平衡问题。

Result: 所提出的CNN模型在单通道EEG数据上实现了85.1%的准确率和0.22的Matthews相关系数（MCC），证明了其在自动化睡眠呼吸暂停检测方面的潜力。

Conclusion: 本研究表明，利用CNN分析单通道EEG数据是检测睡眠呼吸暂停的一种可行且有前景的方法，有望将诊断模式从传统的实验室转移到更易于实现的家庭自动化解决方案，从而改善患者的治疗效果和诊断的可及性。

Abstract: Sleep apnea, a prevalent sleep disorder, involves repeated episodes of
breathing interruptions during sleep, leading to various health complications,
including cognitive impairments, high blood pressure, heart disease, stroke,
and even death. One of the main challenges in diagnosing and treating sleep
apnea is identifying individuals at risk. The current gold standard for
diagnosis, Polysomnography (PSG), is costly, labor intensive, and inconvenient,
often resulting in poor quality sleep data. This paper presents a novel
approach to the detection of sleep apnea using a Convolutional Neural Network
(CNN) trained on single channel EEG data. The proposed CNN achieved an accuracy
of 85.1% and a Matthews Correlation Coefficient (MCC) of 0.22, demonstrating a
significant potential for home based applications by addressing the limitations
of PSG in automated sleep apnea detection. Key contributions of this work also
include the development of a comprehensive preprocessing pipeline with an
Infinite Impulse Response (IIR) Butterworth filter, a dataset construction
method providing broader temporal context, and the application of SMOTETomek to
address class imbalance. This research underscores the feasibility of
transitioning from traditional laboratory based diagnostics to more accessible,
automated home based solutions, improving patient outcomes and broadening the
accessibility of sleep disorder diagnostics.

</details>


### [648] [Conditional Generative Adversarial Networks Based Inertial Signal Translation](https://arxiv.org/abs/2509.00016)
*Marcin Kolakowski*

Main category: eess.SP

TL;DR: 通过使用条件生成对抗网络（GANs），将智能手表等腕戴设备传感器测量到的惯性信号转换为鞋式传感器可记录的信号，从而实现先进的步态分析。


<details>
  <summary>Details</summary>
Motivation: 使腕戴设备能够用于日常步态分析。

Method: 使用条件生成对抗网络（GANs），包括传统的二元交叉熵损失和Wasserstein GANs（WGANs），以及卷积自编码器和卷积U-Net作为生成器。

Result: 所提出的方法能够实现精确的信号转换，从而可以使用腕戴传感器信号进行高效的日常步态分析。

Conclusion: 通过GANs将腕戴设备惯性信号转换为鞋式传感器信号的方法是可行的，并能有效用于日常步态分析。

Abstract: The paper presents an approach in which inertial signals measured with a
wrist-worn sensor (e.g., a smartwatch) are translated into those that would be
recorded using a shoe-mounted sensor, enabling the use of state-of-the-art gait
analysis methods. In the study, the signals are translated using Conditional
Generative Adversarial Networks (GANs). Two different GAN versions are used for
experimental verification: traditional ones trained using binary cross-entropy
loss and Wasserstein GANs (WGANs). For the generator, two architectures, a
convolutional autoencoder, and a convolutional U-Net, are tested. The
experiment results have shown that the proposed approach allows for an accurate
translation, enabling the use of wrist sensor inertial signals for efficient,
every-day gait analysis.

</details>


### [649] [A Fluid Antenna Enabled Physical Layer Key Generation for Next-G Wireless Networks](https://arxiv.org/abs/2509.00018)
*Jiacheng Guo,Ning Gao,Yiping Zuo,Hao Xu,Shi Jin,Kai Kit Wong*

Main category: eess.SP

TL;DR: 一种新的基于流体天线（FA）的物理层密钥生成（PLKG）系统，旨在解决恶劣传播环境下的密钥生成率（KGR）下降问题。通过优化天线位置和预编码矩阵，该系统在KGR方面优于传统固定位置天线（FPA）和可重构智能表面（RIS）系统。


<details>
  <summary>Details</summary>
Motivation: 在恶劣的传播环境下，传统的物理层密钥生成（PLKG）系统的信道特性不佳，导致密钥生成率（KGR）显著下降。本研究旨在提出一种新的流体天线（FA）系统来解决这一挑战。

Method: 提出了一种基于流体天线（FA）的PLKG系统。首先推导了FA阵列的KGR的闭式表达式，然后通过粒子群优化（PSO）算法联合优化预编码矩阵和天线位置。为了降低计算复杂度，还开发了一种交替优化（AO）算法，结合了投影梯度下降（PGD）和PSO。

Result: 与传统的固定位置天线（FPA）阵列和可重构智能表面（RIS）系统相比，所提出的FA系统利用了额外的空间自由度（DoF），表现出优越的性能。与传统的均匀平面天线（UPA）相比，在PSO算法下，FA系统实现了35.42%的KGR性能提升；在AO算法下，实现了67.73%的KGR性能提升。

Conclusion: 基于流体天线（FA）的PLKG系统通过利用额外的空间自由度，在恶劣信道环境下能够显著提高密钥生成率（KGR），优于传统的天线系统。

Abstract: As a promising physical layer security technique, physical layer key
generation (PLKG) enables legitimate users to obtain secret keys from wireless
channel without security infrastructures. However, in harsh propagation
environments, the channel characteristic becomes unsatisfactory, the key
generation rate (KGR) is significantly deteriorated. In this paper, we propose
a novel fluid antenna (FA) enabled PLKG system to address this challenge.
Specifically, we first derive the closed-form expression of the KGR for FA
array, and then jointly optimize the precoding matrix and the antenna positions
via a particle swarm optimization (PSO) algorithm. Next, to further reduce the
computational complexity of the optimization procedure, we develop an
alternating optimization (AO) algorithm, which combines the projected gradient
descent (PGD) and the PSO. Simulation results demonstrate that by exploiting
the additional spatial degree of freedom (DoF), our FA enabled PLKG system is
superior to the benchmarks, such as the conventional fixed-position antenna
(FPA) array and the reconfigurable intelligent surface (RIS). It is worth
highlighting that compared to the conventional uniform planar antenna (UPA),
the FA enabled PLKG achieves a 35.42\% KGR performance improvement under PSO
algorithm and a 67.73\% KGR performance improvement under AO algorithm,
respectively.

</details>


### [650] [A Review of Sensor Insoles](https://arxiv.org/abs/2509.00260)
*Bastian Latsch,Felix Herbst,Mark Suppelt,Julian Seiler,Stephan Schaumann,Sven Suppelt,Alexander A. Altmann,Martin Grimmer,and Mario Kupnik*

Main category: eess.SP

TL;DR: 脚底压力测量（足底压力描记法）是分析人类运动的重要工具。传感器鞋垫作为可穿戴、移动的解决方案，在糖尿病足监测、康复指导、辅助设备控制和运动表现分析等领域具有应用潜力。本综述评估了当前传感器技术、传感器数量和放置、参与者队列和参考标准的应用现状。研究了电阻、电容、电感、压电、摩擦电和光学传感方法，并强调了传感器校准、步态验证和人类研究验证的不足。建议使用测试机器和仪器跑步机作为金标准，以确保研究的可比性。研究还探讨了鞋垫插入物和足底力学之间的双向相互作用，并将组织刚度确定为传感器信号不确定性的关键来源。此外，还提供了传感器尺寸和隐形鞋垫设计的指南，以促进自然步态。未来的方向包括开发多模态传感器以补偿单个模态的局限性，以及捕捉压力分布中剪切分量的多轴传感新兴趋势。


<details>
  <summary>Details</summary>
Motivation: 传感器鞋垫被视为一种可穿戴、移动的解决方案，用于评估健康个体和患者的压力分布，应用领域包括糖尿病足监测、康复指导、辅助设备控制和运动表现分析。

Method: 本综述重点关注传感器技术、传感器数量和放置、参与者群体以及参考标准。涵盖的传感方法包括电阻、电容、电感、压电、摩擦电和光学传感。本研究还考察了鞋垫插入物和足底力学之间的双向相互作用，并确定了组织刚度作为传感器信号不确定性的关键来源。

Result: 研究发现，在传感器校准、步态验证和人类研究验证方面存在不足。建议采用基于测试机器和仪器化跑步机的金标准，以确保研究结果具有可比性。为促进自然步态，提供了传感器尺寸和隐形鞋垫设计的指南。

Conclusion: 为了提高研究结果的可比性和可靠性，需要改进传感器校准、步态验证和人类研究验证。未来的研究应侧重于开发多模态传感器和多轴传感技术，以克服现有方法的局限性并更全面地捕捉足底压力分布。

Abstract: Plantar pressure measurement, or pedobarography, is an essential tool for
analyzing human motion in healthy individuals and patients. Across the reviewed
literature, sensor insoles are motivated as wearable, mobile solutions for
assessing pressure distribution in applications including diabetic foot
monitoring, rehabilitation guidance, assistive device control, and sports
performance analysis. This review evaluates the current state of the art with
particular attention to sensor technologies, sensor quantity and placement,
participant cohorts, and reference standards. The focus lies on original works
with innovative designs, preferably supported by ambulation experiments. The
modalities covered include resistive, capacitive, inductive, piezoelectric,
triboelectric, and optical sensing approaches. We identify a lack of proper
sensor calibration, gait-based verification, and human study validation, and
propose a gold standard based on testing machines and instrumented treadmills
to ensure comparability across studies. The bidirectional interaction between
insole insertion and foot-sole mechanics is examined, with tissue stiffness
identified as a key source of uncertainty in sensor signals. Guidelines are
provided for sensor dimensions and unobtrusive insole designs to foster natural
gait. Finally, future directions include the development of multimodal sensors
to compensate for limitations of individual modalities and the emerging trend
of multiaxial sensing for capturing shear components in pressure distributions.

</details>


### [651] [CoMET: A Contrastive-Masked Brain Foundation Model for Universal EEG Representation](https://arxiv.org/abs/2509.00314)
*Ang Li,Zikai Wang,Liuyin Yang,Zhenyu Wang,Tianheng Xu,Honglin Hu,Marc M. Van Hulle*

Main category: eess.SP

TL;DR: CoMET是一个脑基础模型，通过改进的掩码自编码器和对比学习框架，克服了现有模型过度关注局部特征的局限性，在多种下游任务中取得了最先进的成果，展示了其提取通用EEG表征的优越能力和临床潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的EEG深度模型泛化性不足，现有自监督模型过度关注局部特征，忽略了全局判别性模式。

Method: 提出了一种名为CoMET的脑基础模型，采用掩码自编码器（带有重新设计的patching和embedding）作为骨干，并设计了一种新颖的对比学习框架，结合镜面尺度增强，以增强全局判别能力。

Result: CoMET在包含超过一百万个样本的混合EEG数据集（超过3000名受试者）上进行了预训练，并在十个不同的下游数据集上进行了评估，取得了最先进的成果。

Conclusion: CoMET在提取通用EEG表征方面表现出卓越的能力，并具有强大的临床潜力。

Abstract: Electroencephalography (EEG) is a non-invasive technique for recording brain
activity, widely used in brain-computer interfaces, clinic, and healthcare.
Traditional EEG deep models typically focus on specific dataset and task,
limiting model size and generalization. Recently, self-supervised brain
foundation models have emerged and been applied to various downstream tasks.
Nevertheless, these models still have limitations: current SOTA models
typically rely on masked reconstruction strategy; however, EEG features of
adjacent channels are highly correlated, which causes the pre-training to
overly focus on low-dimensional signal-similarity features in local regions and
neglect the global discriminative patterns vital for downstream tasks. To
address these limitations, we propose a brain foundation model called CoMET.
Specifically, we employ the masked autoencoder with redesigned patching and
embedding for EEG as backbone and devise a novel contrastive learning framework
with mirror-scale augmentation to strengthen the global discrimination ability.
CoMET is pre-trained on mixed EEG datasets over 3000 subjects with over one
million samples. It is evaluated on ten different downstream datasets, and the
SOTA results demonstrate CoMET's superior ability in extracting universal EEG
representations and strong clinical potential.

</details>


### [652] [Gait Analysis using 6DoF Magnetic Tracking](https://arxiv.org/abs/2509.00323)
*R. Abhishek Shankar,Hyungjun Ha,Byunghoo Jung*

Main category: eess.SP

TL;DR: 基于6DoF磁跟踪的步态分析系统在人体活动识别任务中表现优于IMU+磁力计系统，准确率达92%，并能更好地区分行走和负重行走。


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备在步态分析中具有便携性和可及性优势，但其性能不如非可穿戴设备。本研究旨在通过开发一种基于6DoF磁跟踪的步态分析系统来提升可穿戴设备的性能。

Method: 开发了一种基于6DoF磁跟踪的便携式、无线、低功耗的步态分析系统。使用该系统收集了12名参与者在四种活动（行走、负重行走、慢跑、原地踏步）中的步态数据。比较了CNN和LSTM两种深度学习分类器在人体活动识别任务上的表现，并将磁跟踪系统与IMU+磁力计系统进行了性能比较。

Result: 磁跟踪系统在人体活动识别任务中达到了92%的总体分类准确率，而IMU+磁力计系统为86.69%。磁跟踪系统在区分行走和负重行走方面比IMU+磁力计系统提高了约8%的识别能力。

Conclusion: 基于6DoF磁跟踪的系统在步态分析中是可行的，并且比IMU+磁力计系统提供了更丰富的信息，能够更有效地识别不同的步态活动。

Abstract: Gait analysis using wearable devices has advantages over non-wearable devices
when it comes to portability and accessibility. However, non-wearable devices
have consistently shown superior performance in terms of the gait information
they can provide. This calls for the need to improve the performance of
wearable device based gait analysis. To that end, we developed a 6
Degrees-of-Freedom (6DoF) magnetic tracking based gait analysis system as a
step in this direction. The system is portable, minimally intrusive, wireless
and power efficient. As a proof-of-concept, the system was used for the task of
Human Activity Recognition (HAR) to classify four tasks - walking (W), walking
with weight (WW), jogging (J) and marching on the spot (M). Gait data of 12
participants was collected. The classification performance of two deep learning
(DL) classifiers - Convolutional Neural Networks (CNN) and Long Short Term
Memory (LSTM) - was compared. The performance of the magnetic tracking based
gait analysis system was also compared with an Inertial Measurement Unit (IMU)
+ magnetometer based system. The magnetic tracking based system showed an
overall classification accuracy of 92\% compared to 86.69\% for the IMU +
magnetometer system. Moreover, the magnetic tracking system showed an
improvement of about 8\% in being able to differentiate between W and WW. This
highlights the insufficiency in the information content in the data from IMU +
magnetometer, warranting the need for a complete 6DoF tracking. Our work, thus,
proves the feasibility of using magnetic tracking systems for the purpose of
gait analysis.

</details>


### [653] [AN-Aided Secure Beamforming for ELAA-SWIPT in Mixed Near- and Far-Field](https://arxiv.org/abs/2509.00331)
*Yaqian Yi,Guangchi Zhang,Miao Cui,Changsheng You,Qingqing Wu*

Main category: eess.SP

TL;DR: 该研究提出了一种在混合近场/远场环境中，利用超大规模天线阵列辅助的同步无线信息与能量传输（SWIPT）系统的安全混合波束成形（HB）设计。目标是最大化信息接收者（IRs）的加权和保密速率，同时满足能量接收者（ERs）的最小能量收集需求和基站（BS）的发射功率约束。


<details>
  <summary>Details</summary>
Motivation: 在混合近场/远场环境中，为SWIPT系统设计一种能够最大化保密速率的安全混合波束成形方案。

Method: 提出优化问题并采用基于逐次凸近似（SCA）的迭代算法来解决。

Result: 仿真结果验证了所提方案的有效性，并揭示了混合场SWIPT系统的安全性能，特别是可见区域和角度用户分离的影响。

Conclusion: 所提出的安全混合波束成形方案在混合近场/远场SWIPT系统中是有效的，并且对提高系统的保密性能至关重要，尤其是在考虑了不同类型的IRs和能量收集需求时。

Abstract: This letter investigates secure hybrid beamforming (HB) design for an
extremely large-scale antenna array-aided simultaneous wireless information and
power transfer (SWIPT) system operating in a mixed near-field (NF)/far-field
(FF) environment. A base station (BS) employs HB to transmit information and
artificial noise (AN) signals simultaneously to multiple FF information
receivers (IRs) and NF energy receivers (ERs). The objective is to maximize the
weighted sum secrecy rate for the IRs, considering both Type-I (unable to
cancel AN) and Type-II (capable of canceling AN) IRs, subject to minimum energy
harvesting requirements at the ERs and a BS transmit power constraint. We
formulate optimization problems for both IR types and develop an efficient
iterative algorithm based on successive convex approximation. Simulation
results validate the proposed scheme and provide crucial insights into the
security performance of mixed-field SWIPT systems, highlighting the influence
of visibility regions and angular user separation.

</details>


### [654] [Pilot Allocation and Receiver Design for Cell-Free Massive MIMO ISAC Systems](https://arxiv.org/abs/2509.00478)
*Getuar Rexhepi,Kuranage Roche Rayan Ranasinghe,Kengo Ando,Giuseppe Thadeu Freitas de Abreu,David Gonzalez G*

Main category: eess.SP

TL;DR: 本论文提出了CF-mMIMO系统中有效的导频分配和实用的接收器设计方法，通过流形优化最大化系统和速率，并设计了近乎正交的导频序列，同时引入了基于高斯信念传播的接收器。


<details>
  <summary>Details</summary>
Motivation: 为了解决CF-mMIMO系统中的导频分配和接收器设计这两个关键挑战。

Method: 利用流形优化设计导频分配框架，最大化系统和速率，设计了近乎正交的导频序列，并引入了高斯信念传播（GaBP）作为接收器。

Result: 所提出的导频分配方法在通信性能上与现有技术相当，但在传感能力上表现更优。基于GaBP的接收器实现了鲁棒的性能和更低的计算复杂度。

Conclusion: 所提出的方法能提高CF-mMIMO系统的导频分配效率和接收器性能，为集成传感与通信（ISAC）的实际部署铺平了道路。

Abstract: This paper tackles two key challenges in cell-freemassive multiple input
multiple output (CF-mMIMO) systems:efficient pilot allocation and practical
receiver design. To thisend, we introduce a novel pilot allocation framework
leveragingmanifold optimization to maximize the system sum rate, wherepilot
sequences are designed as nearly orthogonal sequences. Theproposed pilot design
enforces unimodularity constraints in thefrequency domain, ensuring pilots are
suitable for both communi-cation and sensing tasks. Additionally, a gaussian
belief propaga-tion (GaBP)-based receiver is introduced, providing
near-optimaldetection performance with substantially reduced
computationalcomplexity. Simulation results demonstrate that the proposedpilot
allocation method achieves communication performancecomparable to
state-of-the-art (SotA) algorithms, while deliveringsuperior sensing
capabilities due to its unimodular pilot design.The GaBP-based receiver
achieves robust performance andlower complexity compared to conventional
approaches. Thesecontributions advance the practical deployment of CF-mMIMOfor
integrated sensing and communications (ISAC).

</details>


### [655] [Distributed Deployment and Dual-Frequency Concepts to Strengthen Sub-THz Wireless Systems](https://arxiv.org/abs/2509.00492)
*Liesbet Van der Perre,Gilles Callebaut,Thomas Eriksson,Muris Sarajlic,Christian Fager,Fredrik Tufvesson,Buon Kiong Lau,Erik G. Larsson*

Main category: eess.SP

TL;DR: Sub-THz网络部署面临挑战，本文提出利用聚合微波光纤（PMFs）连接低复杂度射频单元（RUs）的分布式架构，并结合双频串联操作（sub-THz与sub-10 GHz融合），以实现高性价比、高能效、高性能的实时连接。


<details>
  <summary>Details</summary>
Motivation: Sub-THz频率的高带宽潜力巨大，但部署面临物理和技术挑战。

Method: 提出一种新的Sub-THz覆盖范式：通过聚合微波光纤（PMFs）连接菊花链配置中的低复杂度射频单元（RUs），实现分布式架构，用户设备（UEs）连接到附近的RUs以减少路径损耗和阻塞。RUs采用低复杂度、紧凑型集成天线模块。此外，提出双频串联操作，将Sub-THz系统与提供控制信令和鲁棒回退解决方案的Sub-10 GHz系统集成。

Result: 该分布式和双频串联架构能够克服Sub-THz部署的挑战。

Conclusion: 该方案为实现高性价比、高能效、高性能的实时连接提供了可能，尤其是在动态环境中。

Abstract: The vast bandwidth available at sub-THz frequencies holds great promise for
high-speed wireless access, precise localization, and advanced sensing
applications. However, fundamental physical constraints and technological
limitations make the deployment of reliable sub-THz networks challenging. We
propose a new paradigm for sub-THz coverage by transmitting the RF signals over
polymer microwave fibers (PMFs) that interconnect low-complexity radio units
(RUs) in a daisy-chain configuration. The distributed architecture ensures that
user equipments (UEs) connect to RUs in their proximity, reducing path loss and
mitigating blocking. The RUs leverage low-complexity, compact integrated
antenna modules. Additionally, dual-frequency tandem operation is proposed,
integrating the sub-THz system with a sub-10 GHz system that provides control
signalling and a robust fallback solution for the sub-THz system. This proposed
tandem architecture can open up the full potential of sub-THz technology and
paves the way to cost- and energy-efficient, high-performance, real-time
connectivity in dynamic environments.

</details>


### [656] [Robust Resource Allocation for LEO Satellite-Assisted Secure SWIPT via STAR-RIS under CSI Uncertainty](https://arxiv.org/abs/2509.00568)
*Zahra Rostamikafaki,Francois Chan,Claude D'Amours*

Main category: eess.SP

TL;DR: 该论文提出了一种用于低地球轨道（LEO）卫星驱动的无线信息与能量同时传输（SWIPT）系统的鲁棒资源分配框架，并辅以地面部署的同步传输反射超表面（STAR-RIS）。在直达卫星-地面链路受阻的情况下，卫星仅通过STAR-RIS为多个单天线能量接收器、信息接收器和窃听者提供服务。该框架通过鲁棒优化方法，在满足保密速率要求、发射功率限制和STAR-RIS系数约束的同时，最大化总能量收集。该方法通过S过程处理信道不确定性，并采用交替优化（AO）框架联合优化卫星和STAR-RIS的波束形成，同时结合惩罚策略来执行STAR-RIS波束形成设计。仿真结果表明，所提出的STAR-RIS架构在总收集能量方面优于传统RIS和其他基线方案。


<details>
  <summary>Details</summary>
Motivation: 在直达卫星-地面链路受阻的情况下，为低地球轨道（LEO）卫星驱动的SWIPT系统提供鲁棒的资源分配框架，以最大化总能量收集。

Method: 该文采用S过程处理信道不确定性，并提出交替优化（AO）框架，联合优化LEO卫星的主动波束形成和STAR-RIS的无源波束形成，并结合惩罚策略来执行STAR-RIS波束形成设计。

Result: 仿真结果表明，所提出的STAR-RIS架构在总收集能量方面优于传统RIS和其他基线方案。

Conclusion: STAR-RIS架构在低地球轨道（LEO）卫星驱动的SWIPT系统中具有显著的性能优势，能够有效提升总能量收集。

Abstract: This paper proposes a robust resource allocation framework for a low Earth
orbit (LEO) satellite-enabled simultaneous wireless information and power
transfer (SWIPT) system, assisted by a ground-deployed simultaneously
transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). We
consider a scenario where direct satellite-to-ground links are obstructed, and
the satellite serves multiple single-antenna energy receivers, information
receivers, and eavesdroppers exclusively via the STAR-RIS. A robust
optimization problem is formulated to maximize the total harvested power,
subject to secrecy rate requirements, transmit power limits, and STAR-RIS
coefficient constraints, under a practical bounded channel state information
(CSI) error model. To achieve optimal robust resource allocation, we address
the challenges posed by coupled optimization variables and bounded channel
estimation errors by first applying the S-procedure to handle robustness
against channel uncertainty. An alternating optimization (AO) framework is
subsequently proposed, where the active beamforming at the LEO satellite and
the passive beamforming at the STAR-RIS are jointly optimized, and a
penalty-based strategy is incorporated to enforce the STAR-RIS beamforming
design. Simulation results validate the effectiveness of the proposed algorithm
and demonstrate that the STAR-RIS architecture achieves substantial performance
gains in total harvested power over conventional RIS and other baseline
schemes.

</details>


### [657] [PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces](https://arxiv.org/abs/2509.00670)
*Gursimran Singh,Aviral Chharia,Rahul Upadhyay,Vinay Kumar,Luca Longo*

Main category: eess.SP

TL;DR: PyNoetic是一个开源的、模块化的Python BCI框架，旨在解决现有BCI框架的局限性，如缺乏灵活性、学习曲线陡峭、成本高昂以及功能不全等问题。它提供了端到端的图形用户界面（GUI）和可配置的流程图，支持无代码BCI设计，同时也允许高级用户集成自定义功能。PyNoetic包含丰富的分析工具，支持离线和实时BCI开发，旨在加速BCI研究。


<details>
  <summary>Details</summary>
Motivation: 现有BCI框架在实验研究方面缺乏阶段性灵活性，学习曲线陡峭，依赖专有软件导致成本高昂，并且功能不全需要依赖多个外部工具，影响研究结果。PyNoetic旨在解决这些挑战。

Method: PyNoetic是一个模块化的Python BCI框架，涵盖了从刺激呈现、数据采集、通道选择、滤波、特征提取、伪影去除到模拟和可视化的整个BCI设计流程。它提供了图形用户界面（GUI）和可配置的流程图，支持无代码BCI设计，同时也方便高级用户集成自定义功能和算法。框架包含机器学习模型、脑连通性指标、模拟测试功能和新范式评估方法。

Result: PyNoetic是一个功能全面的BCI框架，具有高度的灵活性和易用性。其图形用户界面和无代码设计能力使其能够被编程经验较少的研��者使用，同时，其模块化设计也方便高级用户进行定制化开发。框架支持离线和实时BCI开发，并提供了丰富的分析工具，能够加速BCI研究进程。

Conclusion: PyNoetic通过提供一个灵活、易用且功能全面的平台，成功解决了现有BCI框架面临的挑战。它的出现将极大地简化BCI的设计和开发过程，降低研究门槛，并最终加速BCI技术在各个领域的应用和发展。

Abstract: Electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) have
emerged as a transformative technology with applications spanning robotics,
virtual reality, medicine, and rehabilitation. However, existing BCI frameworks
face several limitations, including a lack of stage-wise flexibility essential
for experimental research, steep learning curves for researchers without
programming expertise, elevated costs due to reliance on proprietary software,
and a lack of all-inclusive features leading to the use of multiple external
tools affecting research outcomes. To address these challenges, we present
PyNoetic, a modular BCI framework designed to cater to the diverse needs of BCI
research. PyNoetic is one of the very few frameworks in Python that encompasses
the entire BCI design pipeline, from stimulus presentation and data acquisition
to channel selection, filtering, feature extraction, artifact removal, and
finally simulation and visualization. Notably, PyNoetic introduces an intuitive
and end-to-end GUI coupled with a unique pick-and-place configurable flowchart
for no-code BCI design, making it accessible to researchers with minimal
programming experience. For advanced users, it facilitates the seamless
integration of custom functionalities and novel algorithms with minimal coding,
ensuring adaptability at each design stage. PyNoetic also includes a rich array
of analytical tools such as machine learning models, brain-connectivity
indices, systematic testing functionalities via simulation, and evaluation
methods of novel paradigms. PyNoetic's strengths lie in its versatility for
both offline and real-time BCI development, which streamlines the design
process, allowing researchers to focus on more intricate aspects of BCI
development and thus accelerate their research endeavors. Project Website:
https://neurodiag.github.io/PyNoetic

</details>


### [658] [Uninformed-to-Informed Estimation: A Ping-Pong Positioning Method for Multi-user Wideband mmWave Systems](https://arxiv.org/abs/2509.00727)
*Lin Guo,Tiejun Lv,Yashuai Cao,Mugen Peng*

Main category: eess.SP

TL;DR: 该论文提出了一种基于定位误差下限（PELB）驱动的乒乓定位框架，用于提高宽带毫米波（mmWave）系统中动态用户设备（UE）的定位和跟踪性能。该框架通过多维度信息融合，包括多子载波协同定位误差下限（MSCPEB）和多径协同定位方法，优化混合波束形成器以最小化MSCPEB，并推导出用户位置的闭式解。仿真结果表明，该方法在估计精度上提高了16%，同时资源开销减少了四分之三。


<details>
  <summary>Details</summary>
Motivation: 为了提高宽带毫米波（mmWave）系统中动态用户设备（UE）的定位和跟踪性能。

Method: 提出了一种基于定位误差下限（PELB）驱动的乒乓定位框架，其中基站（BS）和UE交替传输和接收自适应波束形成信号以进行定位。所有波束形成器都基于局部评估的PELB进行调度。该框架利用多维度信息融合来辅助定位：1. 提出多子载波协同定位误差下限（MSCPEB）来评估宽带毫米波系统的定位误差极限，并证明MSCPEB不超过单个子载波PELB的算术平均值。2. 开发交替优化（AO）算法来优化针对MSCPEB最小化的混合波束形成器，通过凸化问题推导出闭式解。3. 开发多径协同定位方法，量化路径可靠性对定位精度的影响，并推导出用户位置的闭式解，该方法不依赖于路径分辨率和传统三角关系。

Result: 所提出的方法在估计精度上比没有优化波束配置的潜在方案提高了至少16%，同时仅需要大约四分之一的时隙资源。

Conclusion: 所提出的基于PELB驱动的乒乓定位框架，结合MSCPEB和多径协同定位方法，能够有效提高宽带毫米波系统中动态UE的定位和跟踪性能，并在精度和资源效率方面优于现有方案。

Abstract: To enhance the positioning and tracking performance of dynamic user equipment
(UE) in wideband millimeter-wave (mmWave) systems, we propose a novel
positioning error lower bound (PELB)-driven ping-pong positioning framework,
where the base station (BS) and UE alternately transmit and receive adaptive
beamforming signals for positioning. All beam-formers are scheduled based on
the locally evaluated PELB. In this framework, we exploit multi-dimensional
information fusion to assist in positioning. Firstly, a multi-subcarrier
collaborative positioning error lower bound (MSCPEB) is proposed to evaluate
the positioning error limits of wideband mmWave systems, which quantifies the
contribution of all subcarriers to positioning accuracy. Moreover, we prove
that the MSCPEB does not exceed the arithmetic mean of the PELBs of the
individual subcarriers. Subsequently, we develop an alternating optimization
(AO) algorithm to optimize the hybrid beamformers targeted for MSCPEB
minimization. By convexifying this problem, closed-form solutions of
beamformers are derived. Finally, we develop a multipath collaborative
positioning method that quantifies the impact of path reliability on
positioning accuracy, with a closed-form solution for user position derived.
The proposed method does not rely on path resolution and traditional triangular
relationships. Numerical results validate that the proposed method improves
estimation accuracy by at least 16% compared to potential schemes without
optimized beam configurations, while requiring only approximately one-quarter
of the slot resources.

</details>


### [659] [Characterization of Mega-Constellation Links for LEO Missions With Applications to EO and ISS Use Cases](https://arxiv.org/abs/2509.00766)
*G. Maiolini Capez,M. A. Caceres,C. P. Bridges,S. Frey,R. Armellin,R. Garello,P. Bargellini*

Main category: eess.SP

TL;DR: 低轨（LEO）卫星任务对连接性的需求日益增长，而巨型星座可以为LEO航天器提供出色的连接性，并可能彻底改变低轨航天器作为太空到太空网络节点的方式。


<details>
  <summary>Details</summary>
Motivation: 低轨（LEO）卫星任务对连接性的需求日益增长，而巨型星座可以为LEO航天器提供出色的连接性。

Method: 对实际的OneWeb和Starlink星座与空间用户之间的通信链路进行了特征描述，并提供了可用性、接入持续时间、多普勒频移和路径损耗等一系列结果。此外，还讨论了使用地球静止轨道星座与LEO巨型星座结合的多轨道系统的潜在改进，并重点介绍了国际空间站和太阳同步地球观测卫星等低轨用例。

Result: 与LEO巨型星座通信的单系统和多系统用户的通信链路特征。对利用LEO巨型星座和GEO星座的多轨道系统进行了分析。

Conclusion: LEO巨型星座提供了显著的优势，有可能将LEO航天器转变为高响应的太空到太空网络节点。

Abstract: Satellite missions demand ever greater connectivity, especially in the LEO
regime. In this paper, we introduce the new mega-constellation services in
space paradigm: we show that megaconstellations, deployed to offer innovative
services to Earth's users, can provide excellent connectivity to LEO spacecraft
as well. First, we characterise the communication link between space users and
the actual OneWeb and Starlink constellations. A full set of results in terms
of availability, access duration, Doppler, and path losses as a function of
user orbital parameters, identifying optimal user orbits, is provided. The
results achieved by a multi-system user able to communicate with both fleets
are also presented. The potential improvements available if geostationary
constellations are used to complement LEO megaconstellations in a multi-orbit
system are discussed as well. Finally, we focus on two LEO use cases: the
International Space Station and an Earth Observation Sun Synchronous satellite.
All the results demonstrate the numerous advantages of the mega-constellation
connectivity solution, which can transform LEO spacecraft into highly
responsive nodes of a space-to-space network.

</details>


### [660] [Fast Regularized 3D Near-Field MIMO Imaging Using Stochastic Proximal Gradient Method](https://arxiv.org/abs/2509.00774)
*Okyanus Oral*

Main category: eess.SP

TL;DR: This paper presents a fast regularized reconstruction method for 3D near-field MIMO imaging using the Stochastic Proximal Gradient Method, improving runtime without sacrificing quality.


<details>
  <summary>Details</summary>
Motivation: Near-field MIMO radar imaging has a high computational load due to irregular spatial sampling. Existing acceleration methods are difficult to adapt to different MIMO geometries and require modification for regularized inversion.

Method: The study develops a fast regularized reconstruction approach for 3D near-field MIMO imaging based on the Stochastic Proximal Gradient Method.

Result: The developed approach shows a significant improvement in runtime without any notable compromise in reconstruction quality, as demonstrated through experimental measurements.

Conclusion: The proposed Stochastic Proximal Gradient Method offers an efficient and adaptable solution for near-field MIMO imaging.

Abstract: Near-field multiple-input multiple-output (MIMO) radar imaging suffers from
high computational load inherently due to irregular spatial sampling with
distributed antennas. Existing acceleration methods for near-field MIMO imaging
typically rely on interpolation or compensation of measurements and are
primarily developed for direct reconstruction. This hinders their ease of
adoption for different MIMO geometries and requires further modification for
regularized inversion. In this study, we address these challenges by developing
a fast regularized reconstruction approach for three-dimensional near-field
MIMO imaging based on the Stochastic Proximal Gradient Method. We demonstrate
the performance of the developed approach through experimental measurements.
The results show a significant improvement in runtime without any notable
compromise in reconstruction quality.

</details>


### [661] [Deep Unfolding with Approximated Computations for Rapid Optimization](https://arxiv.org/abs/2509.00782)
*Dvir Avrahami,Amit Milstein,Caroline Chaux,Tirza Routtenberg,Nir Shlezinger*

Main category: eess.SP

TL;DR: 通过结合低复杂度近似计算和学习的超参数，提出了一种优化的学习框架，以解决迭代次数和每次迭代的复杂性问题，并在混合波束成形和鲁棒主成分分析方面实现了最先进的性能，同时将计算复杂度降低了三个数量级以上。


<details>
  <summary>Details</summary>
Motivation: 现有的基于优化的求解器在信号处理和通信任务中至关重要，但其在延迟敏感系统中的应用受到迭代方法顺序性和高计算成本的限制。深度展开虽然可以实现固定次数的迭代，但并未解决每次迭代的成本问题。

Method: 提出了一种优化的学习框架，该框架通过展开固定数量的优化步骤，将选定的迭代替换为低复杂度的近似计算，并从数据中学习扩展的超参数来补偿引入的近似。

Result: 该方法在混合波束成形和鲁棒主成分分析两个代表性问题上进行了验证，实现了最先进的性能，并将计算复杂度降低了三个数量级以上。

Conclusion: 所提出的学习近似优化器有潜力在实时系统中实现快速、可解释和高效的决策。

Abstract: Optimization-based solvers play a central role in a wide range of signal
processing and communication tasks. However, their applicability in
latency-sensitive systems is limited by the sequential nature of iterative
methods and the high computational cost per iteration. While deep unfolding has
emerged as a powerful paradigm for converting iterative algorithms into learned
models that operate with a fixed number of iterations, it does not inherently
address the cost of each iteration. In this paper, we introduce a learned
optimization framework that jointly tackles iteration count and per-iteration
complexity. Our approach is based on unfolding a fixed number of optimization
steps, replacing selected iterations with low-complexity approximated
computations, and learning extended hyperparameters from data to compensate for
the introduced approximations. We demonstrate the effectiveness of our method
on two representative problems: (i) hybrid beamforming; and (ii) robust
principal component analysis. These fundamental case studies show that our
learned approximated optimizers can achieve state-of-the-art performance while
reducing computational complexity by over three orders of magnitude. Our
results highlight the potential of our approach to enable rapid, interpretable,
and efficient decision-making in real-time systems.

</details>


### [662] [Spectrum Cognition: Semantic Situation for Next-Generation Spectrum Management](https://arxiv.org/abs/2509.00851)
*Hao Zhang,Fuhui Zhou,Qihui Wuand Chau Yuen*

Main category: eess.SP

TL;DR: 本篇论文介绍了频谱认知技术在未来无线通信网络中的重要性，提出了一种“数据处理到信号分析到语义态势”的新颖视角，以提高频谱利用效率和安全性。论文中对频谱认知进行了正式定义，并与传统频谱感知进行了区分，同时探讨了传统和智能频谱认知框架的最新进展及关键挑战，并提出了具体的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着未来无线通信网络面临日益增长的复杂性和需求，频谱认知已成为优化下一代无线网络频谱利用的关键技术。

Method: 本文提出了一种“数据处理到信号分析到语义态势”的新颖视角，将语义态势作为频谱认知的最高层次，从原始频谱数据中提取有意义的信息，为网络决策提供智能支持。

Result: 论文中对频谱认知进行了正式定义，并与传统频谱感知进行了区分，同时探讨了传统和智能频谱认知框架的最新进展及关键挑战，并提出了具体的解决方案，强调了语义态势在塑造下一代无线系统中的变革潜力。

Conclusion: 本文的研究不仅为频谱认知的理论理解做出了贡献，也为其实际应用提供了有价值的见解。

Abstract: In response to the growing complexity and demands of future wireless
communication networks, spectrum cognition has emerged as an essential
technique for optimizing spectrum utilization in next-generation wireless
networks. This article presents a comprehensive overview of spectrum cognition,
underscoring its critical role in enhancing the efficiency and security of
future wireless systems through the innovative perspective of "data processing
to signal analysis to semantic situation". Semantic situation, as the highest
level of spectrum cognition, enables the extraction of meaningful information
from raw spectrum data to provide intelligent support for network decisions. We
formally define spectrum cognition, clearly distinguishing it from traditional
spectrum sensing, and delve into the latest advancements in both traditional
and intelligent spectrum cognition frameworks, addressing key challenges in
spectrum cognition. Furthermore, we propose concrete technical solutions to
address these challenges, highlighting the transformative potential of semantic
situation in shaping next-generation wireless systems. Our findings not only
contribute to the theoretical understanding of spectrum cognition but also
offer practical insights for its implementation in real-world scenarios.

</details>


### [663] [Lightweight Error-Correction Code Encoders in Superconducting Electronic Systems](https://arxiv.org/abs/2509.00962)
*Yerzhan Mustafa,Berker Peköz,Selçuk Köse*

Main category: eess.SP

TL;DR: SFQ电路到室温电子设备的数据传输易出现比特错误，本文提出基于Hamming(7,4)、Hamming(8,4)和Reed-Muller(1,3)码的三种轻量级纠错码编码器，并用SFQ逻辑实现，分析了其在PPV影响下的性能和理论复杂度与物理尺寸的权衡。


<details>
  <summary>Details</summary>
Motivation: 数据传输的比特错误以及纠错码编码器的尺寸限制。

Method: 提出并实现了基于Hamming(7,4)、Hamming(8,4)和Reed-Muller(1,3)码的三种轻量级纠错码编码器，并用SFQ逻辑实现。

Result: 分析了纠错码编码器在PPV影响下的性能，并确定了理论复杂度和物理尺寸之间的权衡。

Conclusion: 提出了轻量级纠错码编码器，并分析了其在SFQ电路中的性能和设计权衡。

Abstract: Data transmission from superconducting electronic circuits, such as single
flux quantum (SFQ) logic, to room-temperature electronics is susceptible to bit
errors, which may result from flux trapping, fabrication defects, and process
parameter variations (PPV). Due to the cooling power budget at 4.2 K and
constraints on the chip area, the size of the error-correction code encoders is
limited. In this work, three lightweight error-correction code encoders are
proposed that are based on Hamming(7,4), Hamming(8,4), and Reed-Muller(1,3)
codes and implemented with SFQ logic. The performance of these encoders is
analyzed in the presence of PPV. The trade-offs between the theoretical
complexity and physical size of error-correction code encoders are identified.

</details>


### [664] [Doubly-Dispersive Continuous MIMO Systems: Channel Modeling and Beamforming Design](https://arxiv.org/abs/2509.00964)
*Kuranage Roche Rayan Ranasinghe,Zhaolin Wang,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 该论文研究了MIMO连续孔径阵列(CAPA)系统在双重时变(DD)信道下的建模与最优波束成形(BF)设计。


<details>
  <summary>Details</summary>
Motivation: 为集成感知与通信(ISAC)系统设计适用于双重时变信道的波束成形方案。

Method: 推导了包含发射端和接收端CAPA的双重时变连续MIMO信道模型，并利用变分法(CoV)求解了最大化接收功率的发射端和接收端波束成形矩阵的优化问题，得到了近似于经典匹配滤波器的闭式解。

Result: 提出的基于CAPA的发射/接收波束成形设计在双重时变信道下，与传统MIMO系统相比，在性能和计算复杂度上均有显著提升。

Conclusion: 该研究为MIMO-ISAC系统在双重时变信道下的波束成形设计提供了新的解决方案，并验证了其优越性。

Abstract: We address the modeling and optimal beamforming (BF) design for
multiple-input multiple-output (MIMO) continuous aperture array (CAPA) systems
operating over doubly-dispersive (DD) channels. First, a comprehensive DD
continuous MIMO (DDC MIMO) channel model that incorporates CAPAs at both the
transmitter (TX) and receiver (RX) is derived, which is used to obtain explicit
input-output (I/O) relations for various waveforms well suited to integrated
sensing and communications (ISAC) and robust to DD channels, namely orthogonal
frequency division multiplexing (OFDM), orthogonal time frequency space (OTFS),
and affine frequency division multiplexing (AFDM). Then, functional
optimization problems are formulated for the design of TX and RX BF matrices
that maximize received power, in which novel low-complexity, closed-form
solutions are obtained via the calculus of variations (CoV) method, yielding
expressions closely related to the classical matched filter commonly used in
conventional MIMO systems. Simulation results confirm that the proposed TX/RX
BF designs with CAPAs provide significant performance and computational
complexity gains over conventional MIMO systems in DD channels.

</details>


### [665] [Localized Supervised Learning for Cryo-ET Reconstruction](https://arxiv.org/abs/2509.00968)
*Vinith Kishore,Valentin Debarnot,AmirEhsan Khorashadizadeh,Ivan Dokmanić*

Main category: eess.SP

TL;DR: Cryo-ET reconstructions suffer from noise and missing wedge due to limited electron dosage. This paper proposes a lightweight network trained on localized data to address these issues, offering a computationally efficient alternative to current self-supervised learning methods.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of current self-supervised learning methods used to compensate for noise and missing wedge artifacts in Cryo-ET reconstructions. These methods, typically involving large 3D UNets, have significant training time and memory requirements. The goal is to develop a more efficient approach.

Method: The paper proposes exploiting the local nature of the forward model to train a lightweight network using localized data from the measurements. This approach allows for flexibility in balancing computational and time requirements.

Result: The lightweight network demonstrates high accuracy in reconstructing volumes and shows good performance on unseen datasets, even when trained on limited data.

Conclusion: The proposed lightweight network, trained on localized data, provides an efficient and accurate solution for Cryo-ET reconstruction, overcoming the limitations of existing self-supervised learning methods.

Abstract: Cryo-electron tomography (Cryo-ET) is a powerful tool in structural biology
for 3D visualization of cells and biological systems at resolutions sufficient
to identify individual proteins in situ. The measurements are collected by
tilting the frozen specimen and exposing it to an electron beam of known
dosage. As the biological samples are prone to electron damage, the samples can
be exposed to only a limited dosage of electrons, leading to noisy and
incomplete measurements. Thus, the reconstructions are noisy and incomplete,
leading to the missing wedge problem. Currently, self-supervised learning is
used to compensate for this issue. This typically involves, for each volume to
recover, training a large 3D UNet on the initial noisy reconstruction, leading
to large training time and memory requirements. In this work, we exploit the
local nature of the forward model to train a lightweight network using only
localized data from the measurements. This design provides flexibility in
balancing computational and time requirements while reconstructing the volumes
with high accuracy. We observe experimentally that this network can work well
on unseen datasets, despite using a network trained on a few measurements.

</details>


### [666] [BSNeRF: Broadband Spectral Neural Radiance Fields for Snapshot Multispectral Light-field Imaging](https://arxiv.org/abs/2509.01070)
*Erqi Huang,John Restrepo,Xun Cao,Ivo Ihrke*

Main category: eess.SP

TL;DR: SMLI技术通过BSNeRF模型实现了宽带光谱解耦，提高了多光谱光场图像重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 目前SMLI技术在重建高维数据时，需要考虑宽带光谱解耦，但现有方法或减少光通量或延长成像时间。

Method: 提出了一种名为BSNeRF的宽带光谱神经辐射场模型，用于SMLI系统，以实现光谱解耦。

Result: 实验证明，BSNeRF模型成功解耦了宽带复用光谱，提高了多光谱光场图像重建的准确性。

Conclusion: BSNeRF模型能够解耦宽带光谱，从而提升SMLI系统的性能，并推动了可积成像技术的发展。

Abstract: Snapshot Multispectral Light-field Imaging (SMLI) is an emerging
computational imaging technique that captures high-dimensional data (x, y, z,
$\theta$, $\phi$, $\lambda$) in a single shot using a low-dimensional sensor.
The accuracy of high-dimensional data reconstruction depends on representing
the spectrum using neural radiance field models, which requires consideration
of broadband spectral decoupling during optimization. Currently, some SMLI
approaches avoid the challenge of model decoupling by either reducing
light-throughput or prolonging imaging time. In this work, we propose a
broadband spectral neural radiance field (BSNeRF) for SMLI systems. Experiments
show that our model successfully decouples a broadband multiplexed spectrum.
Consequently, this approach enhances multispectral light-field image
reconstruction and further advances plenoptic imaging.

</details>


### [667] [A Bayesian Framework For Cascaded Channel Estimation in RIS-Aided mmWave Systems](https://arxiv.org/abs/2509.01117)
*Gyoseung Lee,Junil Choi*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this paper, we investigate cascaded channel estimation for reconfigurable
intelligent surface (RIS)-aided millimeter-wave multi-user communication
systems. Since the complex channel gains of the cascaded RIS channel are
generally non-Gaussian, the use of the linear minimum mean squared error
(LMMSE) estimator leads to inevitable performance degradation. To tackle this
issue, we propose a variational inference-based framework that approximates the
complex channel gains using a complex adaptive Laplace prior, which effectively
captures their probability distributions in a tractable way. Numerical results
demonstrate that the proposed estimator outperforms conventional estimators
including least squares and LMMSE in terms of cascaded channel estimation
error.

</details>


### [668] [Fluid Antenna Port Prediction based on Large Language Models](https://arxiv.org/abs/2509.01121)
*Yali Zhang,Haifan Yin,Weidong Li,Emil Bjornson,Merouane Debbah*

Main category: eess.SP

TL;DR: 本研究提出一种名为Port-LLM的新型模型，利用GPT-2框架和专门的数据处理模块，通过预测流体天线（FA）的移动端口位置来解决用户设备（UE）的移动性挑战。该模型在不同基站天线数量和用户设备速度下均表现出优越的预测性能和鲁棒性，并在中高速移动环境中实现了比传统方法更高的频谱效率（SE）。


<details>
  <summary>Details</summary>
Motivation: 解决用户设备（UE）在移动过程中面临的通信挑战，特别是通过优化流体天线（FA）的端口选择。

Method: 提出了一种名为Port-LLM的新模型，该模型基于预训练的GPT-2框架，并设计了专门的数据预处理、输入嵌入和输出投影模块，以处理无线通信数据与LLM数据格式之间的差异，从而预测FA的移动端口。

Result: 模拟结果表明，Port-LLM在不同数量的基站天线和不同的用户设备速度下都展现出优越的预测性能，具有良好的泛化能力和鲁棒性。与传统方法相比，该模型在各种移动场景下都能获得更高的频谱效率（SE）。

Conclusion: Port-LLM模型成功地将LLMs应用于FA端口预测，解决了移动通信中的关键问题，并在性能和效率上超越了传统方法，证明了其在未来无线通信系统中的潜力。

Abstract: This study seeks to utilize large language models (LLMs) to forecast the
moving ports of fluid antenna (FA). By repositioning the antenna to the
locations identified by our proposed model, we intend to address the mobility
challenges faced by user equipment (UE). To the best of our knowledge, this
paper introduces, for the first time, the application of LLMs in the prediction
of FA ports, presenting a novel model termed Port-LLM. The architecture of our
model is based on the pre-trained GPT-2 framework. We designed specialized data
preprocessing, input embedding, and output projection modules to effectively
bridge the disparities between the wireless communication data and the data
format utilized by the pre-trained LLM. Simulation results demonstrate that our
model exhibits superior predictive performance under different numbers of base
station (BS) antennas and varying UE speeds, indicating strong generalization
and robustness ability. Furthermore, the spectral efficiency (SE) attained by
our model surpasses that achieved by traditional methods in both medium and
high-speed mobile environments.

</details>


### [669] [Enabling 6G Through Multi-Domain Channel Extrapolation: Opportunities and Challenges of Generative Artificial Intelligence](https://arxiv.org/abs/2509.01125)
*Yuan Gao,Zichen Lu,Yifan Wu,Yanliang Jin,Shunqing Zhang,Xiaoli Chu,Shugong Xu,Cheng-Xiang Wang*

Main category: eess.SP

TL;DR: 该论文提出了一个用于6G网络的多域信道外推模型，解决了现有模型在单域外推上的不足。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要高精度、低开销的信道状态信息（CSI），尤其是在高移动性、超大MIMO和宽频谱等复杂场景下，需要多域信道外推。现有研究主要集中在单域，缺乏多域方法的全面研究。

Method: 提出了一种新颖的基于Transformer编码器（去除位置编码，用MLP替换多头注意力）的模型，用于多域信道外推，并讨论了生成式人工智能（GAI）在此领域的潜力和挑战。

Result: 仿真结果表明，所提出的模型在信道外推精度和推理速度上优于现有基线模型。消融研究也验证了模型模块设计的有效性。

Conclusion: 所提出的模型能有效进行多域信道外推，但仍存在可解释性、泛化性和数据集收集等开放性问题有待解决。

Abstract: Channel extrapolation has attracted wide attention due to its potential to
acquire channel state information (CSI) with high accuracy and minimal
overhead. This is becoming increasingly crucial as the sixth-generation (6G)
mobile networks aim to support complex scenarios, for example, high-mobility
communications utilizing ultra-massive multiple-input multiple-output (MIMO)
technologies and broad spectrum bands, necessitating multi-domain channel
extrapolation. Current research predominantly addresses channel extrapolation
within a single domain, lacking a comprehensive approach to multi-domain
channel extrapolation. To bridge the gap, we propose the concept of
multi-domain channel extrapolation, detailing the essential performance
requirements for 6G networks. These include precise channel extrapolation,
adaptability to varying scenarios, and manageable computational complexity
during both training and inference stages. In light of these requirements, we
elaborate the potential and challenges of incorporating generative artificial
intelligence (GAI)-based models for effective multi-domain channel
extrapolation. Given the ability of the Transformer to capture long-range
dependencies and hidden patterns, we propose a novel Transformer encoder-like
model by eliminating the positional encoding module and replacing the original
multi-head attention with a multilayer perceptron (MLP) for multi-domain
channel extrapolation. Simulation results indicate that this model surpasses
existing baseline models in terms of extrapolation accuracy and inference
speed. Ablation studies further demonstrate the effectiveness of the module
design of the proposed design. Finally, we pose several open questions for the
development of practical GAI-based multi-domain channel extrapolation models,
including the issues of explainability, generalization, and dataset collection.

</details>


### [670] [A Model-Based Dictionary Approach for Magnetic Nanoparticle Signal Prediction](https://arxiv.org/abs/2509.01127)
*Asli Alpman,Mustafa Utkur,Emine Ulku Saritas*

Main category: eess.SP

TL;DR: 该论文提出了一种无需校准的迭代算法，利用基于模型的字典来预测磁性纳米粒子（MNP）在不同实验条件下的信号。


<details>
  <summary>Details</summary>
Motivation: 为了优化磁性粒子成像（MPI）中的驱动场（DF）和MNP类型，需要全面了解MNP的磁化响应，以避免大量的实验。本研究旨在提供一种方法来预测MNP在未测试设置下的信号。

Method: 提出了一种无需校准的迭代算法，利用基于模型的字典来预测MNP信号。该算法使用耦合的Brown-N'eel旋转模型来模拟MNP信号以构建字典，并联合估计字典权重和由于非基于模型的动态（包括系统响应和未考虑的磁化动态）引起的传递函数。算法首先在不同信噪比（SNR）的合成信号上进行验证，然后在实际的MPI设置下，在不同粘度（0.89-15.33 mPa.s）和DF频率（0.25-2 kHz）下，使用两种商用MNP进行测试。

Result: 在合成信号上，即使在SNR为1的情况下，该算法也能准确估计权重和传递函数。在MPI实验中，该算法成功预测了在未测试粘度下的MNP信号，对于两种测试的MNP，在所有DF设置下的NRMSE低于1.51%和3.5%。预测信号能够捕捉到粘度依赖的趋势，并且NWD值保持较低水平（两种MNP分别低于0.10和0.07），证实了权重的稳健估计。

Conclusion: 该研究提出了一种有效的算法，能够预测磁性纳米粒子在不同实验条件下的信号，而无需进行大量的实验校准，为MPI在各种应用中的优化提供了可能。

Abstract: Magnetic particle imaging (MPI) is a tracer-based medical imaging modality
that enables quantification and spatial mapping of magnetic nanoparticle (MNP)
distribution. The magnetization response of MNPs depends on experimental
conditions such as drive field (DF) settings and medium viscosity, as well as
on magnetic parameters of MNPs such as magnetic core diameter, hydrodynamic
diameter, and magnetic anisotropy constant. A comprehensive understanding of
the magnetization response of MNPs can facilitate the optimization of DF and
MNP type for a given MPI application, without the need for extensive
experimentation. In this work, we propose a calibration-free iterative
algorithm using model-based dictionaries for MNP signal prediction at untested
settings. Dictionaries were constructed with the MNP signals simulated using
the coupled Brown-N\'eel rotation model. Based on the available measurements,
the proposed algorithm jointly estimates the dictionary weights and the
transfer functions due to non-model-based dynamics. These dynamics include the
system response of the measurement setup as well as magnetization dynamics not
accounted for by the employed coupled Brown-N\'eel rotation model. The
algorithm was first validated on synthetic signals at SNR levels of 1 and 10,
and then tested on an in-house MPS setup across six viscosity levels
(0.89-15.33 mPa.s) and DF frequencies of 0.25-2 kHz using two commercial MNPs.
Validation on synthetic signals showed accurate weight and transfer function
estimation even at SNR 1. MPS experiments demonstrated successful prediction of
MNP signals at untested viscosities, with NRMSE below 1.51% and 3.5% for the
two tested MNPs across all DF settings. Predicted signals captured viscosity
dependent trends, and NWD values remained low (<0.10 and <0.07 for the two
tested MNPs), confirming robust weight estimation.

</details>


### [671] [Dynamic State Estimation of Power System Utilizing Cauchy Kernel-Based Maximum Mixture Correntropy UKF over Beluga Whale-Bat Optimization](https://arxiv.org/abs/2509.01163)
*Duc Viet Nguyen,Haiquan Zhao,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出了一种基于柯西核最大混合柯西准则和混合鲸头鹩优化算法的鲁棒无迹卡尔曼滤波器（BWB-CKMMC-UKF），用于解决电力系统动态状态估计中的非高斯噪声、异常值、负载突变和测量不准等问题，并验证了其在IEEE标准测试系统上的有效性。


<details>
  <summary>Details</summary>
Motivation: 电力系统动态状态估计易受非高斯噪声、异常值、负载突变和测量不准等因素影响，导致精度下降。此外，基于熵准则的无迹卡尔曼滤波器（UKF）使用的带宽敏感高斯核可能导致Cholesky分解出现奇异矩阵。

Method: 提出了一种基于柯西核最大混合柯西准则（CKMMC）和混合鲸头鹩优化算法（BWB）的鲁棒UKF（BWB-CKMMC-UKF）。该方法使用两个柯西函数合并核，并通过统计线性化技术将测量误差和状态误差统一到成本函数中，然后利用不动点迭代获得最优状态估计值。为克服高斯核的缺点，采用对核带宽不敏感且具有明显粗糙尾部特征的柯西核函数。此外，通过BWB算法优化核的形状系数和影响sigma点选择的尺度系数，以适应电力系统模型。

Result: 在IEEE 14、30和57节点测试系统上的仿真结果验证了所提出算法的性能。

Conclusion: 所提出的BWB-CKMMC-UKF算法能够有效克服传统UKF在处理电力系统动态状态估计中的各种干扰和不确定性问题，提高了估计的准确性和鲁棒性。

Abstract: Non-Gaussian noise, outliers, sudden load changes, and bad measurement data
are key factors that diminish the accuracy of dynamic state estimation in power
systems. Additionally, unscented Kalman filters (UKF) based on correntropy
criteria utilize bandwidth-sensitive Gaussian kernels, which may lead to
singular matrices in the Cholesky decomposition. To overcome all the above
problems, in this paper, a robust UKF based on Cauchy kernel maximum mixture
correntropy (CKMMC) criteria over hybrid Beluga Whale-Bat (BWB) optimization
(BWB-CKMMC-UKF) is proposed, in which the kernel is merged of two Cauchy
functions. Specifically, the measurement error and state error are unified in
the cost function by the statistical linearization technique, and the optimal
value of state estimation is obtained by fixed-point iteration. Because of its
insensitive feature to kernel bandwidth and notable thick-tailed feature, the
Cauchy kernel function is utilized instead of the Gaussian kernel in the
optimization criteria. Additionally, to fit the power system model, the shape
coefficients of the kernel in the CKMMC criterion and scale coefficients that
influence the selection of sigma points in the unscented transform are
determined based on the BWB algorithm. Simulation results on IEEE 14, 30, and
57-bus test systems validated the performance of the proposed algorithm.

</details>


### [672] [Beyond Exhaustive Sampling: Efficient Rotational Matching via Ball Harmonics](https://arxiv.org/abs/2509.01180)
*Fabian Kruse,Vinith Kishore,Valentin Debarnot,Ivan Dokmanić*

Main category: eess.SP

TL;DR: Cryo-ET data processing speed-up via ball harmonics expansion and hybrid optimization.


<details>
  <summary>Details</summary>
Motivation: Need for scalable, fast, and robust subtomogram alignment procedures to keep up with advances in Cryo-ET imaging and increasing data volumes.

Method: A subtomogram alignment framework based on ball harmonics expansion, combining frequency- and gradient-based optimization to avoid exhaustive rotation sampling.

Result: Achieved an order of magnitude speed-up compared to current approaches.

Conclusion: The proposed framework offers a significant improvement in the speed of subtomogram alignment for Cryo-ET data analysis.

Abstract: Cryo-ET allows to generate tomograms of biological samples in situ, capturing
complex structures in their native context. Despite low signal-to-noise ratio
in reconstructed volumes, the large number of copies of the same macromolecules
makes it possible to retrieve high-resolution maps by averaging many aligned
subtomograms. To keep up with technical advances in the imaging process and the
resulting huge amounts of data available, there is a need for scalable, fast
and robust procedures to align subtomograms. We propose a subtomogram alignment
framework based on the ball harmonics expansion that combines frequency- and
gradient-based optimization strategies to avoid exhaustive rotation sampling,
enabling a speed-up of an order of magnitude compared to current approaches.

</details>


### [673] [Enhanced Fingerprint-based Positioning With Practical Imperfections: Deep learning-based approaches](https://arxiv.org/abs/2509.01197)
*Shugong Xu,Jun Jiang,Wenjun Yu,Yilin Gao,Guangjin Pan,Shiyi Mu,Zhiqi Ai,Yuan Gao,Peigang Jiang,Cheng-Xiang Wang*

Main category: eess.SP

TL;DR: 该论文提出三种创新的定位框架，解决了现有蜂窝网络高精度定位中标签数据不足、模型泛化能力差、环境动态变化以及锚点分布不均等问题，并在2024年无线通信算法精英赛中获得前三名。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习定位算法在真实蜂窝环境中需要大量标签数据且泛化能力不足的问题，并应对标签数据有限、环境动态变化和锚点分布不均等实际挑战。

Method: 提出三种创新的定位框架：1. 基于一致性的半监督框架，通过生成高质量伪标签来扩充训练数据集。2. 基于集成学习的算法，融合不同训练策略下的模型定位坐标，以应对动态环境。3. 基于解耦映射头的算法，利用扇区旋转方案解决锚点分布不均的问题。

Result: 仿真结果表明，所提出的定位算法在90%、80%、67%、50%百分位和平均距离误差方面，性能优于现有基准算法。

Conclusion: 该论文提出的三种框架有效解决了蜂窝网络高精度定位面临的关键挑战，并在竞赛中取得了优异成绩，展示了其在实际应用中的潜力。

Abstract: High-precision positioning is vital for cellular networks to support
innovative applications such as extended reality, unmanned aerial vehicles
(UAVs), and industrial Internet of Things (IoT) systems. Existing positioning
algorithms using deep learning techniques require vast amounts of labeled data,
which are difficult to obtain in real-world cellular environments, and these
models often struggle to generalize effectively. To advance cellular
positioning techniques, the 2024 Wireless Communication Algorithm Elite
Competition as conducted, which provided a dataset from a three-sector outdoor
cellular system, incorporating practical challenges such as limited
labeled-dataset, dynamic wireless environments within the target and
unevenly-spaced anchors, Our team developed three innovative positioning
frameworks that swept the top three awards of this competition, namely the
semi-supervised framework with consistency, ensemble learning-based algorithm
and decoupled mapping heads-based algorithm. Specifically, the semi-supervised
framework with consistency effectively generates high-quality pseudo-labels,
enlarging the labeled-dataset for model training. The ensemble learning-based
algorithm amalgamates the positioning coordinates from models trained under
different strategies, effectively combating the dynamic positioning
environments. The decoupled mapping heads-based algorithm utilized sector
rotation scheme to resolve the uneven-spaced anchor issue. Simulation results
demonstrate the superior performance of our proposed positioning algorithms
compared to existing benchmarks in terms of the {90%, 80%, 67%, 50%} percentile
and mean distance error.

</details>


### [674] [Rigid Body Localization and Tracking for 6G V2X: Algorithms, Applications, and Road to Adoption](https://arxiv.org/abs/2509.01208)
*Niclas Führling,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,David González G.,Gonzalo Seco-Granados,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: V2X感知技术，特别是集成传感与通信（ISAC）框架下的刚体定位（RBL），能够估计目标的位置、速度、三维几何结构和方向，在自动驾驶和B5G/6G无线系统中具有重要应用前景。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶需求的增长，V2X感知技术，特别是集成了通信和传感的ISAC框架，受到了广泛关注。在这一背景下，刚体定位（RBL）作为一种能够同时估计目标的位置、速度、三维几何结构和方向的新兴范式，为V2X感知提供了新的可能性。

Method: 本文介绍了刚体定位（RBL）的概念，探讨了其在V2X感知领域的优势和应用，分析了面临的关键技术挑战，并指出了未来的研究方向。同时，文章还讨论了RBL在下一代无线系统（如B5G和6G）中的应用潜力，特别是在标准化和跨汽车及工业领域的应用。

Result: RBL技术能够实现对目标更全面的感知，包括其位置、速度、三维几何结构和方向，这对于提升自动驾驶的安全性和可靠性至关重要。RBL在B5G/6G无线系统中的应用潜力也得到了讨论。

Conclusion: RBL技术是V2X感知领域的一个重要发展方向，有望在未来的自动驾驶和无线通信系统中发挥关键作用。进一步的研究和标准化工作将推动RBL技术的广泛应用。

Abstract: Vehicle-to-everything (V2X) perception refers to a suite of technologies that
empower vehicles to sense their environment and communicate with other
entities, including surrounding vehicles, infrastructure, and cloud/edge
networks. With the growing demands of autonomous driving, V2X perception has
gained significant attention, particularly through the emergence of integrated
sensing and communication (ISAC) frameworks. Within this landscape, rigid body
localization (RBL) has emerged as a promising paradigm, enabling the estimation
of not only the position and velocity of the targets, but also its
three-dimensional (3D) geometric structure and orientation. This article
introduces the concept of RBL, highlights its unique advantages and
applications, identifies key technical challenges, and finally outlines future
research directions. In addition, the potential of RBL in next-generation -
e.g. beyond fifth generation (B5G) and sixth-generation (6G) - wireless systems
applied to V2X perception is also discussed, with a focus on its role in
standardization efforts and its relevance across automotive and industrial
domains.

</details>


### [675] [High-Density MIMO Localization Using a 32x64 Ultrasonic Transducer-Microphone Array with Real-Time Data Streaming](https://arxiv.org/abs/2509.01210)
*Rens Baeyens,Dennis Laurijssen,Jan Steckel,Walter Daems*

Main category: eess.SP

TL;DR: 一个利用大规模MIMO架构和32个发射器/62个麦克风的超声波阵列系统，用于高精度定位。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够提高信道可分离性和空间分辨率的大规模超声波阵列系统，以实现高精度定位。

Method: 使用32个发射器和62个麦克风的大规模MIMO架构，并用随机相位多正弦信号激励发射器。

Result: 仿真结果表明，与单发射器配置相比，MIMO处理能够更好地分离反射体，但换能器带宽等实际限制会降低信道隔离度。

Conclusion: 所提出的大规模MIMO超声波阵列系统可用于高精度定位，并能提高信道可分离性和空间分辨率，但实际应用中存在一些限制因素。

Abstract: In this work, we present a novel ultrasonic array system designed for
high-precision localization using a large-scale MIMO (Multiple-Input
Multiple-Output) architecture. The system combines 32 transmitters with 62
microphones, creating an extended virtual aperture that improves channel
separability and spatial resolution. Each transmitter is excited by a
random-phase multisine within the ultrasonic band, which reduces inter-channel
correlation and increases robustness against multipath. The feasibility of the
approach is demonstrated through simulations of reflector imaging and analysis
of channel separation under realistic transducer bandwidth constraints. Results
show that MIMO processing enables improved separation of reflectors compared to
single-emitter configurations, although practical limitations such as
transducer bandwidth reduce the achievable channel isolation.

</details>


### [676] [nRTIS: Low-Cost Real-Time 3D Sonar Imaging Circular Array Supporting Beamforming for Industrial Applications](https://arxiv.org/abs/2509.01212)
*Rens Baeyens,Dennis Laurijssen,Jan Steckel,Walter Daems*

Main category: eess.SP

TL;DR: nRTIS是一种基于MEMS麦克风和中心超声换能器的紧凑型超声传感平台，使用RP2350微控制器和高速USB实现实时采集，适用于工业应用。


<details>
  <summary>Details</summary>
Motivation: 传统的超声波检测系统成本高、体积大、不适合便携或嵌入式使用，因此需要开发更紧凑、经济高效的替代方案。

Method: 该系统采用围绕圆形MEMS麦克风阵列和中心超声换能器的设计，并通过RP2350微控制器和高速USB实现实时数据采集和传输。

Result: PSF模拟显示了nRTIS的光束成形分辨率和旁瓣抑制能力，而反射器测量则证实了其可靠的数据采集能力。

Conclusion: nRTIS有潜力应用于焊接检测、管道测绘和机器人导航等可扩展的工业领域。

Abstract: Conventional ultrasonic inspection systems rely on phased arrays and
high-performance computing hardware, making them costly, bulky, and unsuitable
for portable or embedded use. In this work, we present nRTIS (nano Real-Time 3D
Imaging Sonar), a compact ultrasonic sensing platform built around a circular
array of MEMS microphones and a central ultrasonic transducer. The device
achieves real-time acquisition through an RP2350 microcontroller and high-speed
USB transfer. We validate the system using both simulations and controlled
experiments: point spread function (PSF) simulations demonstrate beamforming
resolution and sidelobe suppression, while reflector measurements confirm
robust data acquisition. These results highlight the potential of nRTIS for
scalable industrial applications such as weld inspection, pipe mapping, and
robotic navigation.

</details>


### [677] [Rate Optimization for Downlink URLLC via Pinching Antenna Arrays](https://arxiv.org/abs/2509.01222)
*Tong Lin,Jianyue Zhu,Wei Huang,Meng Hua,Zhizhong Zhang*

Main category: eess.SP

TL;DR: 通过优化包含介电粒子的捏合天线的布局，以最大化uRLLC下行链路系统的速率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在最大化超可靠低延迟通信（uRLLC）下行链路系统的吞吐量，通过优化捏合天线的布局实现。

Method: 提出了一种紧凑且经济高效的天线架构，并提出了一种基于有限块长度的优化模型，在服务质量（QoS）和天线间距约束下，推导出了最优天线布局的闭式解。此外，还整合了一种相位对齐策略，以实现跨阵列的相干信号叠加。

Result: 仿真结果表明，与传统天线系统相比，所提出的设计在满足uRLLC要求的同时，显著提高了数据速率。

Conclusion: 所提出的捏合天线设计非常适合紧凑且对延迟敏感的未来应用，可显著提高uRLLC系统的性能。

Abstract: This work studies an ultra-reliable and low-latency communications (uRLLC)
downlink system using pinching antennas which are realized by activating small
dielectric particles along a dielectric waveguide. Our goal is to maximize the
data rate by optimizing the positions of the pinching antennas. By proposing a
compact and cost-efficient antenna architecture and formulating a finite
blocklength-based optimization model, we derive a closed-form solution for the
optimal antenna placement under quality-of-service (QoS) and antenna spacing
constraints. Meanwhile, a phase-alignment strategy is integrated into the
design, enabling coherent signal superposition across the array. Simulation
results confirm significant rate improvements over conventional antenna systems
while satisfying uRLLC requirements, making the proposed design well-suited for
compact and latency-critical future applications.

</details>


### [678] [SMDS-based Rigid Body Localization](https://arxiv.org/abs/2509.01223)
*Niclas Führling,Giuseppe Abreu,David González G.,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 该论文提出了一种新颖的刚体定位（RBL）方法，仅基于车辆传感器到锚点地标点的距离和角度测量。该方法使用超多维缩放（SMDS）算法的变体，并利用了锚点到锚点和目标到目标信息。


<details>
  <summary>Details</summary>
Motivation: 提出一种仅基于距离和角度测量来估计车辆刚体位置的新方法。

Method: 使用超多维缩放（SMDS）算法的变体，并利用锚点到锚点和目标到目标信息。

Result: 仿真结果表明，与克拉美-罗下界（CRLB）相比，该方法在估计的均方误差（MSE）方面表现良好。

Conclusion: 所提出的RBL方法在仅使用距离和角度测量的情况下，能够实现良好的估计性能。

Abstract: We consider a novel rigid body localization (RBL) method, based only on a set
of measurements of the distances, as well as the angles between sensors of the
vehicle to the anchor landmark points. A key point of the proposed method is to
use a variation of the super multidimensional scaling (SMDS) algorithm, where
only a minor part of the complex edge kernel is used, based on the available
information, which in the case of RBL is anchor-to-anchor and target-to-target
information. Simulation results illustrate the good performance of the proposed
technique in terms of mean square error (MSE) of the estimates, compared also
to the corresponding Cram\'er-Rao Lower Bound (CRLB).

</details>


### [679] [Comparison between Supervised and Unsupervised Learning in Deep Unfolded Sparse Signal Recovery](https://arxiv.org/abs/2509.01331)
*Koshi Nagahisa,Ryo Hayakawa,Youji Iiguni*

Main category: eess.SP

TL;DR: 该论文研究了深度展开技术中损失函数选择对稀疏信号恢复算法的影响，重点比较了基于均方误差的有监督学习和基于原始优化目标函数的无监督学习。结果表明，损失函数的选择对结果的影响取决于优化问题的凸性。对于凸问题，有监督学习提高了恢复精度但未能优化目标函数；对于非凸问题，有监督和无监督学习均能获得比原始算法更好的局部最优解。


<details>
  <summary>Details</summary>
Motivation: 研究深度展开技术中损失函数选择对稀疏信号恢复算法的影响，特别是在有监督和无监督学习场景下。

Method: 将迭代优化算法（如ISTA和IHT）转化为可训练的神经网络，并通过均方误差（有监督）和原始优化目标函数（无监督）进行训练和比较。

Result: 对于凸问题，有监督学习提高了恢复精度但未优化目标函数；无监督学习加速了收敛但解与传统方法相似。对于非凸问题，有监督和无监督方法均优于传统方法，且性能相似。

Conclusion: 损失函数的选择对深度展开算法的影响取决于优化问题的凸性，为设计有效的深度展开网络提供了指导。

Abstract: This paper investigates the impact of loss function selection in deep
unfolding techniques for sparse signal recovery algorithms. Deep unfolding
transforms iterative optimization algorithms into trainable lightweight neural
networks by unfolding their iterations as network layers, with various loss
functions employed for parameter learning depending on application contexts. We
focus on deep unfolded versions of the fundamental iterative shrinkage
thresholding algorithm (ISTA) and the iterative hard thresholding algorithm
(IHT), comparing supervised learning using mean squared error with unsupervised
learning using the objective function of the original optimization problem. Our
simulation results reveal that the effect of the choice of loss function
significantly depends on the convexity of the optimization problem. For convex
$\ell_1$-regularized problems, supervised-ISTA achieves better final recovery
accuracy but fails to minimize the original objective function, whereas we
empirically observe that unsupervised-ISTA converges to a nearly identical
solution as conventional ISTA but with accelerated convergence. Conversely, for
nonconvex $\ell_0$-regularized problems, both supervised-IHT and
unsupervised-IHT converge to better local minima than the original IHT, showing
similar performance regardless of the loss function employed. These findings
provide valuable insights into the design of effective deep unfolded networks
for sparse signal recovery applications.

</details>


### [680] [A James-Stein Estimator based Generalized OMP Algorithm for Robust Signal Recovery using Sparse Representation](https://arxiv.org/abs/2509.01410)
*Debraj Banerjee,Amitava Chatterjee*

Main category: eess.SP

TL;DR: JS-gOMP算法通过结合James-Stein估计器，提高了稀疏信号处理中gOMP算法的降噪能力，在噪声环境下表现优于传统gOMP。


<details>
  <summary>Details</summary>
Motivation: 在稀疏信号处理中，提高算法在噪声环境下的鲁棒性，优化信号恢复与噪声抑制的权衡。

Method: 提出JS-gOMP算法，该算法在gOMP的基础上，引入了James-Stein估计器，以优化字典中的噪声处理。

Result: JS-gOMP算法相比传统gOMP算法，在噪声环境下展现出更优越的性能。

Conclusion: JS-gOMP算法为信号和图像处理应用中，尤其是在存在显著噪声的情况下，提供了一种更有效的信号恢复和噪声抑制的解决方案。

Abstract: In this paper, we introduce a novel algorithm named JS-gOMP, which enhances
the generalized Orthogonal Matching Pursuit (gOMP) algorithm for improved noise
robustness in sparse signal processing. The JS-gOMP algorithm uniquely
incorporates the James-Stein estimator, optimizing the trade-off between signal
recovery and noise suppression. This modification addresses the challenges
posed by noise in the dictionary, a common issue in sparse representation
scenarios. Comparative analyses demonstrate that JS-gOMP outperforms
traditional gOMP, especially in noisy environments, offering a more effective
solution for signal and image processing applications where noise presence is
significant.

</details>


### [681] [To Share, or Not to Share: A Study on GEO-LEO Systems for IoT Services with Random Access](https://arxiv.org/abs/2509.01506)
*Marcel Grec,Federico Clazzer,Israel Leyva-Mayorga,Andrea Munari,Gianluigi Liva,Petar Popovski*

Main category: eess.SP

TL;DR: 卫星频谱共享对提升吞吐量有益，但需满足特定条件。


<details>
  <summary>Details</summary>
Motivation: 为了支持海量物联网设备和现代随机接入，需要解决卫星运营商是否应共享频谱资源的问题。

Method: 通过构建一个包含两个运营商的通信模型，并利用蒙特卡洛模拟进行验证。

Result: 分析结果表明，在特定条件下（用户数量和编码速率），频谱共享可以带来显著的吞吐量提升，但提升效果受系统参数影响，并非总是互利。

Conclusion: 频谱共享可以为卫星通信带来益处，但需要仔细权衡系统参数和监管政策，为未来6G非地面网络的设计和监管提供参考。

Abstract: The increasing number of satellite deployments, both in the low and
geostationary Earth orbit exacerbates the already ongoing scarcity of wireless
resources when targeting ubiquitous connectivity. For the aim of supporting a
massive number of IoT devices characterized by bursty traffic and modern
variants of random access, we pose the following question: Should competing
satellite operators share spectrum resources or is an exclusive allocation
preferable? This question is addressed by devising a communication model for
two operators which serve overlapping coverage areas with independent IoT
services. Analytical approximations, validated by Monte Carlo simulations,
reveal that spectrum sharing can yield significant throughput gains for both
operators under certain conditions tied to the relative serviced user
populations and coding rates in use. These gains are sensitive also to the
system parameters and may not always render the spectral coexistence mutually
advantageous. Our model captures basic trade-offs in uplink spectrum sharing
and provides novel actionable insights for the design and regulation of future
6G non-terrestrial networks.

</details>


### [682] [Non-Identical Diffusion Models in MIMO-OFDM Channel Generation](https://arxiv.org/abs/2509.01641)
*Yuzhi Yang,Omar Alhussein,Mérouane Debbah*

Main category: eess.SP

TL;DR: 提出了一种新的非相同扩散模型，用于无线OFDM信道生成，通过元素级时间指示器捕捉局部误差变化，提高了在初始化偏差下的生成结果，特别是在MIMO-OFDM信道恢复中。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型使用标量时间索引来表示全局噪声水平，无法准确捕捉无线信道（如MIMO-OFDM）中跨元素（子载波）的局部误差变化，尤其是在初始化估计存在不均匀可靠性时。

Method: 提出了一种非相同扩散模型，使用元素级时间指示器替代标量时间索引，以更准确地捕捉局部误差变化。针对MIMO-OFDM信道生成，提出了一种维度式时间嵌入策略，并开发和评估了多种训练和生成方法。

Result: 理论和数值结果均证明了所提出的非相同扩散方案的正确性和有效性，尤其是在MIMO-OFDM信道生成方面。

Conclusion: 非相同扩散模型通过其元素级时间指示器和维度式时间嵌入策略，能够更有效地处理无线信道生成中的局部误差变化和不均匀可靠性问题，相比传统方法取得了改进的生成效果。

Abstract: We propose a novel diffusion model, termed the non-identical diffusion model,
and investigate its application to wireless orthogonal frequency division
multiplexing (OFDM) channel generation. Unlike the standard diffusion model
that uses a scalar-valued time index to represent the global noise level, we
extend this notion to an element-wise time indicator to capture local error
variations more accurately. Non-identical diffusion enables us to characterize
the reliability of each element (e.g., subcarriers in OFDM) within the noisy
input, leading to improved generation results when the initialization is
biased. Specifically, we focus on the recovery of wireless multi-input
multi-output (MIMO) OFDM channel matrices, where the initial channel estimates
exhibit highly uneven reliability across elements due to the pilot scheme.
Conventional time embeddings, which assume uniform noise progression, fail to
capture such variability across pilot schemes and noise levels. We introduce a
matrix that matches the input size to control element-wise noise progression.
Following a similar diffusion procedure to existing methods, we show the
correctness and effectiveness of the proposed non-identical diffusion scheme
both theoretically and numerically. For MIMO-OFDM channel generation, we
propose a dimension-wise time embedding strategy. We also develop and evaluate
multiple training and generation methods and compare them through numerical
experiments.

</details>


### [683] [Predictive Communications for Low-Altitude Networks](https://arxiv.org/abs/2509.01705)
*Junting Chen,Bowen Li,Hao Sun,Shuguang Cui,Nikolaos Pappas*

Main category: eess.SP

TL;DR: 传统通信方法无法应对低空经济带来的通信挑战。本文提出预测通信，通过融合任务轨迹和无线电环境模型，将网络管理从被动适应转变为主动优化。通过分层框架（战略、战术、操作）解决资源分配问题，实现了跨层干扰数量级上的降低。


<details>
  <summary>Details</summary>
Motivation: 低空经济带来的通信挑战，如极端信道动态和严重的跨层干扰，传统通信方法难以应对。

Method: 提出预测通信范式，通过融合可预测的任务轨迹和大规模无线电环境模型，实现从被动适应到主动优化的网络管理。采用分层框架，将预测性跨层资源分配问题分解为战略（路由）、战术（时序）和操作（功率）三个层级。

Result: 预测性框架实现了数量级上的跨层干扰降低。

Conclusion: 预测通信框架为构建鲁棒、可扩展的低空通信系统奠定了基础。

Abstract: The emergence of dense, mission-driven aerial networks supporting the
low-altitude economy presents unique communication challenges, including
extreme channel dynamics and severe cross-tier interference. Traditional
reactive communication paradigms are ill-suited to these environments, as they
fail to leverage the network's inherent predictability. This paper introduces
predictive communication, a novel paradigm transforming network management from
reactive adaptation to proactive optimization. The approach is enabled by
fusing predictable mission trajectories with stable, large-scale radio
environment models (e.g., radio maps). Specifically, we present a hierarchical
framework that decomposes the predictive cross-layer resource allocation
problem into three layers: strategic (routing), tactical (timing), and
operational (power). This structure aligns decision-making timescales with the
accuracy levels and ranges of available predictive information. We demonstrate
that this foresight-driven framework achieves an order-of-magnitude reduction
in cross-tier interference, laying the groundwork for robust and scalable
low-altitude communication systems.

</details>


### [684] [Leveraging Orbital Dynamics with RF Signal Features for Satellite Multi-Orbit Proximity Threat Detection](https://arxiv.org/abs/2509.01802)
*Anouar Boumeftah,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 本研究提出一个混合仿真框架，通过整合轨道机动模型和射频信号退化分析，来检测和分类可疑的近距离操作。


<details>
  <summary>Details</summary>
Motivation: 随着多轨道星座的日益密集和对抗性机动的敏捷性增强，基于近距离的干扰对卫星通信构成了日益严重的威胁。

Method: 该框架利用开源的MaDDG库生成包含冲动性机动剖面和射频影响的标记数据集，并结合运动学特征（如距离、速度、加速度、最近方法时间）和射频指标（如接收信号强度指示、吞吐量、干扰信号比），通过随机森林分类器进行分析。

Result: 所提出的方法在融合的特征集上实现了94.67%的准确率和0.9471的宏观F1分数，优于仅使用运动学或射频输入的模型，尤其在检测规避射频方法的隐蔽威胁方面效果显著。

Conclusion: 该混合仿真框架能够有效检测和分类可疑的近距离操作，特别是能够识别出仅依靠射频方法无法检测到的隐蔽威胁。

Abstract: Proximity-based interference is a growing threat to satellite communications,
driven by dense multi-orbit constellations and increasingly agile adversarial
maneuvers. We propose a hybrid simulation framework that integrates orbital
maneuver modeling with RF signal degradation analysis to detect and classify
suspicious proximity operations. Using the open-source Maneuver Detection Data
Generation (MaDDG) library from MIT Lincoln Laboratory, we generate labeled
datasets combining impulsive maneuver profiles with radio-frequency (RF)
impacts across a range of behavioral intents: routine station-keeping, covert
shadowing, and overt jamming. Our approach fuses kinematic features such as
range, velocity, acceleration, and Time of Closest Approach (TCA), with RF
metrics including Received Signal Strength Indicator (RSSI), throughput, and
Jammer-to-Signal Ratio (JSR). These features are further enhanced with temporal
derivatives and rolling-window statistics to capture subtle or transient
interference patterns. A Random Forest classifier trained on this fused feature
set achieves 94.67% accuracy and a macro F1 score of 0.9471, outperforming
models using only kinematic or RF inputs. The system is particularly effective
in detecting covert threats, such as surveillance or intermittent jamming, that
evade RF-only methods.

</details>


### [685] [Efficient River Water Level Sensing Using Cellular CSI and Joint Space-Time Processing](https://arxiv.org/abs/2509.01905)
*Khawaja Fahad Masood,Kai Wu,Zhongqin Wang,J. Andrew Zhang,Shu-Lin Chen,Y. Jay Guo*

Main category: eess.SP

TL;DR: 利用现有的蜂窝信号被动估计水位变化。


<details>
  <summary>Details</summary>
Motivation: 传统的水位监测方法依赖于成本高昂、维护困难且易受损的专用传感器。本研究提出一种新的基于蜂窝信号的传感方案，以被动方式利用现有通信基础设施的下行移动信号来估计水位变化。

Method: 通过捕获信道状态信息（CSI）的细微变化，估计水反射信号路径的长度变化，从而推断水位变化。开发了一个时空处理框架，联合估计到达角和多普勒频移，通过波束成形分离和增强水反射路径，同时有效抑制环境噪声。然后提取波束形成信号的相位演化来推断水位变化。为了解决双基地系统中固有的收发时钟异步问题，提出了一种基于波束成形的补偿技术，用于去除CSI中随时间变化的随机相位偏移。

Result: 现场实验表明，该方法能够实现准确可靠的水位估计，在不同接收器配置和部署下的平均精度在1.5厘米到3.05厘米之间。

Conclusion: 提出的基于蜂窝信号的水位监测方法能够准确可靠地估计水位变化，平均精度在1.5厘米到3.05厘米之间，为水位监测提供了一种低成本、高可靠性的解决方案。

Abstract: Accurate and timely water level monitoring is critical for flood prevention,
environmental management, and emerging smart infrastructure systems.
Traditional water sensing methods often rely on dedicated sensors, which can be
costly to deploy and difficult to maintain and are vulnerable to damage during
floods.In this work, we propose a novel cellular signalbased sensing scheme
that passively estimates water level changes using downlink mobile signals from
existing communication infrastructure. By capturing subtle variations in
channel state information (CSI), the proposed method estimates the length
changes of the water-reflected signal path, which correspond to water level
variations. A space-time processing framework is developed to jointly estimate
the angle of arrival and Doppler shift, enabling isolation and enhancement of
the water-reflected path via beamforming, while effectively suppressing
environmental noise. The phase evolution of the beamformed signal is then
extracted to infer water level changes. To address clock asynchronism between
the transmitter and receiver inherent in bistatic systems, we introduce a
beamforming-based compensation technique for removing time-varying random phase
offsets in CSI. Field experiments conducted across a river demonstrate that the
proposed method enables accurate and reliable water level estimation, achieving
a mean accuracy ranging from 1.5 cm to 3.05 cm across different receiver
configurations and deployments.

</details>


### [686] [ECG-Based Stress Prediction with Power Spectral Density Features and Classification Models](https://arxiv.org/abs/2509.01923)
*Md. Mohibbul Haque Chowdhury,Nafisa Anjum,Md. Rokonuzzaman Mim*

Main category: eess.SP

TL;DR: 该研究提出了一种基于心电图（ECG）信号的压力预测框架，结合了频域特征和机器学习/深度学习模型，其中LSTM模型达到了94%的准确率。


<details>
  <summary>Details</summary>
Motivation: 压力是导致心血管疾病、抑郁症等多种长期疾病的关键全球健康问题，因此，准确可靠的压力监测系统日益重要。

Method: 通过功率谱密度（PSD）分析获得自主神经系统活动的频域指标，并将其作为机器学习模型（包括决策树、随机森林、XGBoost、LightGBM和CatBoost）的输入。此外，还将深度学习方法（卷积神经网络CNN和长短期记忆LSTM）直接应用于原始ECG信号。

Result: 研究结果表明，基于集成学习的分类器效果显著，其中CatBoost准确率达到90%。LSTM模型表现更优，准确率达到94%，同时实现了精确率、召回率和F1分数的平衡，证明了其在模拟ECG数据时间依赖性方面的优势。

Conclusion: 研究结果表明，将频域特征提取与先进的学习算法相结合，能够有效提升压力预测的准确性，并为实时医疗监测解决方案奠定了基础。

Abstract: Stress has emerged as a critical global health issue, contributing to
cardiovascular disorders, depression, and several other long-term illnesses.
Consequently, accurate and reliable stress monitoring systems are of growing
importance. In this work, we propose a stress prediction framework based on
electrocardiogram (ECG) signals recorded during multiple daily activities such
as sitting, walking, and jogging. Frequency-domain indicators of autonomic
nervous system activity were obtained through Power Spectral Density (PSD)
analysis and utilized as input for machine learning models including Decision
Tree, Random Forest, XGBoost, LightGBM, and CatBoost. In addition, deep
learning approaches, namely Convolutional Neural Networks (CNN) and Long
Short-Term Memory (LSTM) networks, were directly applied to the raw ECG
signals. Our experiments highlight the effectiveness of ensemble-based
classifiers, with CatBoost achieving 90% accuracy. Moreover, the LSTM model
provided superior results, attaining 94% accuracy with balanced precision,
recall, and F1-score, reflecting its strength in modeling temporal dependencies
in ECG data. Overall, the findings suggest that integrating frequency-domain
feature extraction with advanced learning algorithms enhances stress prediction
and paves the way for real-time healthcare monitoring solutions.

</details>


### [687] [On Performance of IoT Networks with Coordinated NOMA Transmission: Covert Monitoring and Information Decoding](https://arxiv.org/abs/2509.01935)
*Thai-Hoc Vu,Anh-Tu Le,Ngo Hoang Tu,Tan N. Nguyen,Miroslav Voznak*

Main category: eess.SP

TL;DR: This paper analyzes the security and covertness of IoT networks using NOMA and coordinated direct/relay transmission in Rayleigh fading environments. It derives formulas for detection error probability and secrecy outage probability, and proposes adaptive power allocation schemes to optimize covert and secrecy rates while meeting QoS and system constraints.


<details>
  <summary>Details</summary>
Motivation: The motivation is to investigate and improve the covertness and security performance of IoT networks, specifically addressing challenges posed by Rayleigh fading environments and the need to complicate surveillance or eavesdropping efforts.

Method: The study employs a coordinated direct and relay transmission strategy combined with NOMA. It derives exact closed-form expressions for detection error probability (DEP) and analytical expressions for secrecy outage probability under different eavesdropping strategies. Optimization strategies for adaptive power allocation (PA) are proposed to maximize covert rate or secrecy rate while satisfying constraints.

Result: The paper derives analytical expressions for DEP and secrecy outage probability, identifies optimal thresholds, and determines effective regions for PA. Numerical results validate the analytical framework and demonstrate the effectiveness of the proposed adaptive PA schemes in maximizing covert or secrecy rates.

Conclusion: The analytical framework accurately represents the system's performance, and the proposed adaptive power allocation schemes effectively enhance covertness and security by optimizing power allocation coefficients to maximize covert or secrecy rates under various constraints.

Abstract: This work investigates the covertness and security performance of
Internet-of-Things (IoTs) networks under Rayleigh fading environments.
Specifically, a cellular source transmits covert information to cell-edge users
with the assistance of an IoT master node, employing a coordinated direct and
relay transmission strategy combined with non-orthogonal multiple access
(NOMA). This approach not only enhances spectrum utilization but also generates
friendly interference to complicate a warden's surveillance or an
eavesdropper's decoding efforts. From a covertness perspective, we derive exact
closed-form expressions for the detection error probability (DEP) under
arbitrary judgment thresholds. We then identify the optimal judgment threshold
for the worst-case scenario, at which the warden minimizes its DEP performance.
Accordingly, we determine the effective region for user power allocation (PA)
in NOMA transmission that satisfies the DEP constraint. From a security
perspective, we derive analytical expressions for the secrecy outage
probability under two eavesdropping strategies using selection combining and
maximal ratio combining. Based on this analysis, we propose an adaptive PA
scheme that maximizes covert rate while ensuring the quality-of-service (QoS)
requirements of legitimate users, the system's minimum covertness requirements,
and supporting successive interference cancellation (SIC) procedures.
Furthermore, we design an adaptive PA scheme that maximizes the secrecy rate
while ensuring the QoS requirements of legitimate users and SIC conditions.
Numerical results demonstrate the accuracy of the analytical framework, while
the proposed optimization strategies effectively adjust PA coefficients to
maximize either the covert rate or the secrecy rate.

</details>


### [688] [Correlation Analysis Between MF R-Mode Temporal ASF and Meteorological Factors](https://arxiv.org/abs/2509.01958)
*Jongmin Park,Junwoo Song,Taewon Kang,Jaewon Yu,Pyo-Woong Son*

Main category: eess.SP

TL;DR: GNSS系统漏洞日益暴露，对补充导航系统的需求增加。MF R-Mode因其信号强度和成本效益成为GNSS中断的有效备份。然而，MF R-Mode的精确定位需要修正由地形引起传播延迟的额外次级因子（ASF）。ASF的时间变化（时间ASF）通常使用参考站进行校正，但其有效性随距离增加而降低。本研究分析了时间ASF与气象因素的相关性，评估了基于气象因素预测时间ASF的可行性。结果表明，温度和湿度与时间ASF具有显著相关性，有望用于ASF校正。


<details>
  <summary>Details</summary>
Motivation: 由于全球导航卫星系统（GNSS）的漏洞日益受到关注，对补充导航系统的需求也在不断增长。中频测距模式（MF R-Mode）因其强大的信号强度和成本效益而备受关注，被认为是GNSS中断期间的有效备份系统。

Method: 本研究分析了时间ASF与气象因素（包括温度、湿度、气压、风速和风向）之间的相关性，以评估基于气象因素预测时间ASF的可行性。

Result: 研究结果表明，温度和湿度与时间ASF之间存在显著的相关性，这表明它们在ASF校正中具有潜在的应用价值。

Conclusion: 时间ASF可以通过气象因素（特别是温度和湿度）进行预测，从而提高MF R-Mode的定位精度，尤其是在远离参考站的情况下。

Abstract: As the vulnerabilities of global navigation satellite systems (GNSS) have
become more widely recognized, the need for complementary navigation systems
has grown. Medium frequency ranging mode (MF R-Mode) has gained attention as an
effective backup system during GNSS outages, owing to its strong signal
strength and cost-effective scalability. However, to achieve accurate
positioning, MF R-Mode requires correction for the additional secondary factor
(ASF), a propagation delay affected by terrain. The temporal variation of ASF,
known as temporal ASF, is typically corrected using reference stations;
however, the effectiveness of this method decreases with distance from the
reference station. In this study, we analyzed the correlation between temporal
ASF and meteorological factors to evaluate the feasibility of predicting
temporal ASF based on meteorological factors. Among these factors, temperature
and humidity showed significant correlations with temporal ASF, suggesting
their potential utility in ASF correction.

</details>


### [689] [Dual Target-Mounted RISs-Assisted ISAC Against Eavesdropping and Malicious Interference](https://arxiv.org/abs/2509.02030)
*Zehra Yigit,Sefa Kayraklik,Ertugrul Basar,Ali Gorcin*

Main category: eess.SP

TL;DR: 本研究提出了一种结合了集成感知与通信（ISAC）和可重构智能表面（RIS）的新型双目标ISAC方案，该方案利用安装在合法无人机（UAV）目标上的RIS，同时应对窃听和随机干扰攻击。通过基于半正定松弛（SDR）的两阶段优化方法，最大化用户保密速率，并评估通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: ISAC和RIS的结合为下一代无线网络带来了新机遇，但也引入了新的安全挑战。本研究旨在应对这些挑战。

Method: 提出了一种双目标RIS辅助ISAC方案，其中ISAC基站感知两个UAV目标（一个合法，一个窃听）。合法UAV上的RIS用于与用户通信。该方案通过基于SDR的两阶段优化方法，优化基站的传输波束成形矩阵和合法RIS的相位偏移系数，以最大化用户保密速率。

Result: 通过大量计算机模拟评估了该方案在不同系统配置下的鲁棒性。通信性能通过保密速率衡量，感知性能通过窃听UAV目标的信号干扰加噪声比（SINR）和到达角（AoD）估计的Cramer-Rao界（CRB）进行评估。

Conclusion: 所提出的方案能够有效地应对敌对UAV目标带来的双重安全威胁，并在通信和感知方面表现出良好的性能。

Abstract: The synergy between integrated sensing and communication (ISAC) and
reconfigurable intelligent surfaces (RISs) unlocks novel applications and
advanced services for next-generation wireless networks, yet also introduces
new security challenges. In this study, a novel dual target-mounted
RISs-assisted ISAC scheme is proposed, where a base station with ISAC
capability performs sensing of two unmanned aerial vehicle (UAV) targets, one
of which is legitimate and the other is eavesdropper, while communicating with
the users through an RIS mounted on the legitimate UAV target. The proposed
scheme addresses dual security threats posed by a hostile UAV target:
eavesdropping on legitimate user communications and random interference attacks
launched by a malicious RIS mounted on this eavesdropper UAV target, aiming to
disrupt secure transmissions. A non-convex optimization problem maximizing the
secrecy rate of the users is formulated, and a semi-definite relaxation
(SDR)-based two-stage solution is developed to optimize the transmit
beamforming matrix of the base station and the phase shift coefficients of the
legitimate RIS. Extensive computer simulations are conducted to evaluate the
robustness of the proposed solution under various system configurations. The
proposed system's communication performance is assessed using the secrecy rate
metric, while the sensing performance is evaluated through the
signal-to-interference-plus-noise ratio and the Cramer-Rao bound (CRB) for
angle-of-departure (AoD) estimation of the eavesdropper UAV target.

</details>


### [690] [Synesthesia of Machines (SoM)-Based Task-Driven MIMO System for Image Transmission](https://arxiv.org/abs/2509.02031)
*Sijiang Li,Rongqing Zhang,Xiang Cheng,Jian Tang*

Main category: eess.SP

TL;DR: 为支持动态场景下网络化移动代理的协同感知（CP），感官数据的传输效率和鲁棒性是一个关键挑战。基于深度学习的联合信源信道编码（JSCC）在恶劣信道条件下图像传输方面取得了有前景的结果，优于传统的基于规则的编解码器。尽管近期有研究探索将JSCC与广泛采用的多输入多输出（MIMO）技术相结合，但这些方法仍限于离散时间模拟传输（DTAT）模型和简单任务。鉴于现有MIMO JSCC方案在支持数字MIMO通信系统的网络化移动代理的复杂CP任务方面性能有限，本文提出了一种基于“灵境”（Synesthesia of Machines, SoM）的任务驱动MIMO系统，用于图像传输，称为SoM-MIMO。通过利用特征金字塔对感知任务的结构特性和闭环MIMO通信系统的信道特性，SoM-MIMO能够实现高效、鲁棒的数字MIMO图像传输。实验结果表明，与两个JSCC基线方案相比，在保持相同通信开销的情况下，我们的方法在所有信噪比（SNR）水平上平均mAP提高了6.30和10.48。


<details>
  <summary>Details</summary>
Motivation: 为了支持网络化移动代理在动态场景下的协同感知（CP），需要解决高效鲁棒的感官数据传输这一关键挑战，特别是对于数字MIMO通信系统。

Method: 提出了一种名为SoM-MIMO的基于“灵境”（Synesthesia of Machines, SoM）的任务驱动MIMO系统，用于图像传输。该系统利用特征金字塔的结构特性和闭环MIMO通信系统的信道特性，实现了高效、鲁棒的数字MIMO图像传输。

Result: 与两个JSCC基线方案相比，SoM-MIMO在所有SNR水平上平均mAP提高了6.30和10.48，同时保持了相同的通信开销。

Conclusion: SoM-MIMO通过结合SoM的灵活性、特征金字塔的结构感知能力以及MIMO通信的优势，有效地解决了数字MIMO通信系统中网络化移动代理协同感知任务的图像传输挑战，并在实验中展示了优于现有JSCC方案的性能。

Abstract: To support cooperative perception (CP) of networked mobile agents in dynamic
scenarios, the efficient and robust transmission of sensory data is a critical
challenge. Deep learning-based joint source-channel coding (JSCC) has
demonstrated promising results for image transmission under adverse channel
conditions, outperforming traditional rule-based codecs. While recent works
have explored to combine JSCC with the widely adopted multiple-input
multiple-output (MIMO) technology, these approaches are still limited to the
discrete-time analog transmission (DTAT) model and simple tasks. Given the
limited performance of existing MIMO JSCC schemes in supporting complex CP
tasks for networked mobile agents with digital MIMO communication systems, this
paper presents a Synesthesia of Machines (SoM)-based task-driven MIMO system
for image transmission, referred to as SoM-MIMO. By leveraging the structural
properties of the feature pyramid for perceptual tasks and the channel
properties of the closed-loop MIMO communication system, SoM-MIMO enables
efficient and robust digital MIMO transmission of images. Experimental results
have shown that compared with two JSCC baseline schemes, our approach achieves
average mAP improvements of 6.30 and 10.48 across all SNR levels, while
maintaining identical communication overhead.

</details>


### [691] [Environment-Aware Channel Measurement and Modeling for Terahertz Monostatic Sensing](https://arxiv.org/abs/2509.02088)
*Yejian Lyu,Zhiqiang Yuan,Henk Wymeersch,Chong Han*

Main category: eess.SP

TL;DR: 太赫兹（THz）集成传感与通信（ISAC）系统在高速通信和环境感知方面潜力巨大。本文基于对三种室内场景下57个收发器位置的测量活动，对300 GHz的单站传感通道进行了全面研究。通过高分辨率SAGE算法提取了包括幅度、延迟和角度在内的多径分量（MPC）参数，并使用连接组件标记（CCL）方法根据延迟-角度一致性对MPC进行聚类。在此基础上，提出了一种环境感知信道建模框架，将物理场景属性（如反射体几何、表面材料和粗糙度）与信道特征联系起来。该框架考虑了镜面和漫反射，并利用反射损耗、朗伯散射和簇内离散模型来描述反射行为。实验结果表明，该方法能从信道特征中提取物理特性，为THz ISAC信道建模奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现实且可解释的信道建模对于充分发挥太赫兹（THz）集成传感与通信（ISAC）系统的潜力至关重要。

Method: 通过高分辨率空间交替广义期望最大化（SAGE）算法提取多径分量（MPC）参数（幅度、延迟、角度），并使用连接组件标记（CCL）方法根据延迟-角度一致性对MPC进行聚类。提出了一种环境感知信道建模框架，将物理场景属性与信道特征关联，并纳入镜面和漫反射，使用反射损耗、朗伯散射和簇内离散模型。

Result: 该方法能够从观测到的信道特征中可靠地提取物理特性，如结构和材料信息。

Conclusion: 所提出的环境感知信道建模框架为先进的THz ISAC信道建模提供了有前景的基础。

Abstract: Integrated sensing and communication (ISAC) at terahertz (THz) frequencies
holds significant promise for unifying ultra-high-speed wireless connectivity
with fine-grained environmental awareness. Realistic and interpretable channel
modeling is essential to fully realize the potential of such systems. This work
presents a comprehensive investigation of monostatic sensing channels at
300~GHz, based on an extensive measurement campaign conducted at 57 co-located
transceiver (TRx) positions across three representative indoor scenarios.
Multipath component (MPC) parameters, including amplitude, delay, and angle,
are extracted using a high-resolution space-alternating generalized
expectation-maximization (SAGE) algorithm. To cluster the extracted MPCs, an
image-processing-based clustering method, i.e., connected component labeling
(CCL), is applied to group MPCs based on delay-angle consistency. Based on the
measurement data, an environment-aware channel modeling framework is proposed
to establish mappings between physical scenario attributes (e.g., reflector
geometry, surface materials, and roughness) and their corresponding
channel-domain manifestations. The framework incorporates both specular and
diffuse reflections and leverages several channel parameters, e.g., reflection
loss, Lambertian scattering, and intra-cluster dispersion models, to
characterize reflection behavior. Experimental results demonstrate that the
proposed approach can reliably extract physical characteristics, e.g.,
structural and material information, from the observed channel characteristics,
offering a promising foundation for advanced THz ISAC channel modeling.

</details>


### [692] [Affine-Doppler Division Multiplexing for High-Mobility Wireless Communications Systems](https://arxiv.org/abs/2509.02116)
*Yuanfang Ma,Zulin Wang,Peng Yuan,Qin Huang,Yuanhan Ni*

Main category: eess.SP

TL;DR: ADDM是一种新的ISAC波形，它统一了OTFS和AFDM，并在高移动性场景下提供了优于OTFS的性能。


<details>
  <summary>Details</summary>
Motivation: 由于OTFS和AFDM不兼容，现有的为OTFS设计的先进方法可能不直接适用于AFDM。需要一个能统一这两种波形并允许复用现有方法的框架。

Method: 提出了一种新的正交多载波波形——仿射-多普勒时分复用（ADDM），它基于二维变换，将信息符号调制在仿射-多普勒（A-D）域。ADDM可以看作是OTFS和AFDM的通用框架，并能从现有的为OTFS和AFDM设计的方法中受益。

Result: ADDM在高移动性场景下的比特错误率（BER）性能与AFDM相当，优于OTFS。

Conclusion: ADDM作为一个统一的ISAC波形框架，具有优于OTFS的性能，并能复用现有为OTFS和AFDM设计的技术，为ISAC领域提供了新的解决方案。

Abstract: Affine Frequency Division Multiplexing (AFDM) has been regarded as a
candidate integrated sensing and communications (ISAC) waveform owing to its
superior communication performance, outperforming the Orthogonal Time-Frequency
Space (OTFS) that has been researched for a longer time. However, since the
above two waveforms are incompatible with each other, the state-of-the-art
methods well-designed for OTFS may not be directly applicable to AFDM. This
paper introduces a new orthogonal multicarrier waveform, namely Affine-Doppler
Division Multiplexing (ADDM), which can provide a generic framework and subsume
the existing OTFS and AFDM as a particular case. ADDM modulating information
symbols in the Affine-Doppler (A-D) domain based on a two-dimensional (2D)
transform can enjoy both excellent unambiguous Doppler and Doppler resolution,
which is the same as AFDM but outperforms OTFS. Moreover, benefiting from the
2D transform, the symbols block of ADDM in the A-D domain undergoes a 2D cyclic
shift produced by the delay and the Doppler of the channel, similar to the 2D
cyclic shift in the delay-Doppler domain of cyclic prefix (CP)-OTFS. This
offers a potential to directly apply the state-of-the-art methods well-designed
for OTFS and AFDM to ADDM. Numerical results show that ADDM achieves comparable
BER performance with AFDM but outperforms OTFS in high-mobility scenarios.

</details>


### [693] [High-Resolution Sensing in Communication-Centric ISAC: Deep Learning and Parametric Methods](https://arxiv.org/abs/2509.02137)
*Salmane Naoumi,Ahmad Bazzi,Roberto Bomfin,Marwa Chafii*

Main category: eess.SP

TL;DR: 本论文提出两种新算法，用于在通信中心集成传感与通信（ISAC）系统的双站配置中解决超分辨率传感参数估计的挑战。该方法利用源自通信参考符号的信道状态信息估计来实现超分辨率传感参数估计。第一种算法IFFT-C2VNN采用复值卷积神经网络估计不同目标的参数，与传统方法相比，计算复杂度显著降低。第二种算法PARAMING利用系统模型知识（包括发送和接收阵列几何）的参数方法来准确提取传感参数。通过全面的性能分析，我们证明了两种算法在各种信噪比下的有效性和鲁棒性，强调了它们在实际ISAC场景中的适用性。


<details>
  <summary>Details</summary>
Motivation: 在通信中心集成传感与通信（ISAC）系统的双站配置中，解决超分辨率传感参数估计的挑战。

Method: 提出两种新算法：1. IFFT-C2VNN：利用复值卷积神经网络估计不同目标的参数。2. PARAMING：利用系统模型知识（包括发送和接收阵列几何）的参数方法来准确提取传感参数。

Result: IFFT-C2VNN算法显著降低了计算复杂度；PARAMING算法能准确提取传感参数。两种算法在各种信噪比下都表现出有效性和鲁棒性。

Conclusion: 本论文提出的IFFT-C2VNN和PARAMING算法能够有效且鲁棒地解决ISAC系统中双站配置下的超分辨率传感参数估计问题，适用于实际ISAC场景。

Abstract: This paper introduces two novel algorithms designed to address the challenge
of super-resolution sensing parameter estimation in bistatic configurations
within communication-centric integrated sensing and communication (ISAC)
systems. Our approach leverages the estimated channel state information derived
from reference symbols originally intended for communication to achieve
super-resolution sensing parameter estimation. The first algorithm, IFFT-C2VNN,
employs complex-valued convolutional neural networks to estimate the parameters
of different targets, achieving significant reductions in computational
complexity compared to traditional methods. The second algorithm, PARAMING,
utilizes a parametric method that capitalizes on the knowledge of the system
model, including the transmit and receive array geometries, to extract the
sensing parameters accurately. Through a comprehensive performance analysis, we
demonstrate the effectiveness and robustness of both algorithms across a range
of signal-to-noise ratios, underscoring their applicability in realistic ISAC
scenarios.

</details>


### [694] [Beamforming Design for Pinching Antenna Systems with Multiple Receive Antennas](https://arxiv.org/abs/2509.02166)
*Enzhi Zhou,Yue Xiao,Ziyue Liu,Sotiris A. Tegos,Panagiotis D. Diamantoulakis,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 该论文提出了下行波束复用天线系统的通用模型，并设计了一种两层优化策略，以提高在非视距（NLoS）和密集天线环境下的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在动态环境中支持超高数据速率、无缝连接和大规模设备部署，下一代网络需要智能且鲁棒的信道条件。虽然灵活的天线技术（如流体天线和移动天线）提供了一定的适应性，但其有限的重构范围和结构刚性降低了恢复视距（LoS）链路的效率。因此，需要一种更灵活的解决方案。

Method: 提出一个通用的、新颖的下行波束复用天线系统（PAS）的建模框架，针对配备多个接收天线的用户。首先，推导了接收信噪比与波束复用天线（PA）位置之间的解析关系。然后，提出了一种两层放置策略：第一层利用大规模信道特性优化中心辐射点；第二层使用启发式压缩放置算法来近似多用户接收天线的相位对齐，并选择一组空间紧凑的激活单元。

Result: 仿真结果表明，与传统的单天线方案相比，该系统在短距离、密集PA和用户天线分布广泛的场景下，性能有显著提升。

Conclusion: 该论文提出的波束复用天线系统（PAS）及其两层优化策略，在非视距（NLoS）和密集用户场景下，能够有效提升通信性能，尤其是在短距离应用中。

Abstract: Next-generation networks require intelligent and robust channel conditions to
support ultra-high data rates, seamless connectivity, and large-scale device
deployments in dynamic environments. While flexible antenna technologies such
as fluid and movable antennas offer some degree of adaptability, their limited
reconfiguration range and structural rigidity reduce their effectiveness in
restoring line-of-sight (LoS) links. As a complementary solution, pinching
antenna systems (PASs) enable fine-grained, hardware-free control of radiation
locations along a waveguide, offering enhanced flexibility in challenging
propagation environments, especially under non-LoS (NLoS) conditions. This
paper introduces a general and novel modeling framework for downlink PASs
targeting users equipped with multiple receive antennas, addressing a practical
yet underexplored scenario in the existing literature. Specifically, we first
derive an analytical relationship between the received signal-to-noise ratio
and the pinching antenna (PA) positions, and based on this, we propose a
two-layer placement strategy. First, we optimize the central radiation point
using large-scale channel characteristics, and then we use a heuristic
compressed placement algorithm to approximate phase alignment across multiple
receive antennas and select a spatially compact set of active elements.
Simulation results demonstrate notable performance gains over conventional
single-antenna schemes, particularly in short-range scenarios with dense PAs
and widely spaced user antennas.

</details>


### [695] [Dual-end Fluid Antennas For Robust Anti-jamming in Low-altitude Air-ground Communications](https://arxiv.org/abs/2509.02260)
*Yifan Guo,Junshan Luo,Fanggang Wang,Haiyang Ding,Shilian Wang,Zhenhai Xu*

Main category: eess.SP

TL;DR: 本文提出了一种基于流体天线系统（FAS）的异构双层传输架构，以解决低空空地通信中的同频干扰和蓄意干扰问题。通过优化天线位置和传输预编码，FAS 在干扰抑制和信号增强方面表现优于传统固定位置天线（FPA）系统，数据速率最高可提高 56%。


<details>
  <summary>Details</summary>
Motivation: 解决低空空地通信中，由于固定位置天线（FPA）系统缺乏空间适应性，导致信号增强与干扰抑制平衡的挑战。

Method: 提出了一种基于流体天线系统（FAS）的异构双层传输架构。地面基站采用 FPA，低空基站和空地用户均采用 FAS。优化传输预编码、接收组合器和天线位置，以最大化空中用户可实现速率，同时满足地面用户服务质量、干扰方向不确定性、最小天线间隔等约束。采用分数规划-块坐标下降算法，并结合凸包方法和几何边界法处理干扰不确定性和天线放置约束。

Result: 与 FPA 系统相比，FAS 在同等功率约束下，数据速率最高可提高 56%。通过优化天线重新定位，可以有效提升信号质量并抑制干扰，在不同的干扰信道不确定性下保持鲁棒性。

Conclusion: 所提出的 FAS 辅助异构双层传输架构能够有效解决低空空地通信中的干扰问题，并通过优化天线位置和传输策略，显著提升通信性能和鲁棒性。

Abstract: This paper addresses the challenge of co-channel interference and intentional
jamming in low-altitude air-ground communications. Since conventional
fixed-position antenna (FPA) systems lack spatial adaptability to dynamically
balance signal enhancement against interference suppression, we propose a
transformative fluid antenna system (FAS)-assisted heterogeneous dual-layer
transmission architecture. Specifically, a terrestrial base station with FPA
serves ground users, while a low altitude-serving base station equipped with
FAS communicates with the aerial user, also equipped with FAS, under the attack
of a malicious jammer. We formulate a worst-case achievable rate maximization
problem for aerial user subject to constraints including quality-of-service for
terrestrial users, imperfect jamming directions, minimum antenna separation,
etc. To address the non-convex problem, we propose a fractional
programming-block coordinate descent algorithm that alternately optimizes the
transmit precoders, receive combiner, and antenna positions at both transceiver
sides. Convex hull-based approach and geometric boundary method are used to
handle the jamming uncertainty and antenna placement constraints in confined
spatial regions, respectively. Extensive simulations validate significant
performance gains. The FAS achieves up to 56\% higher data rates than FPA under
equivalent power constraints. Strategic antenna repositioning demonstrably
enhances signal quality while suppressing interference, maintaining robustness
across diverse jammer channel uncertainties.

</details>


### [696] [Interference Management for Integrated Sensing and Communications: A Multiple Access Perspective](https://arxiv.org/abs/2509.02352)
*Kexin Chen,Yijie Mao,Wonjae Shin,Bruno Clerckx,Christos Masouros*

Main category: eess.SP

TL;DR: 本文首次全面介绍了多址接入（MA）技术在集成传感与通信（ISAC）网络中的应用。ISAC通过通信和传感的融合，在6G无线接入网络中扮演关键角色，但其功能集成也带来了严峻的干扰管理挑战。MA技术，如OMA、SDMA、NOMA和RSMA，在资源利用、波形设计及干扰管理方面为ISAC提供了有效解决方案，并能从ISAC中获益，提升干扰管理能力。文章阐述了ISAC基本原理，分类了ISAC系统中的干扰类型，并比较了不同MA辅助ISAC设计的优缺点，最后展望了相关新兴应用和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 集成传感与通信（ISAC）技术是6G无线接入网络的关键，但其功能集成带来了严峻的干扰管理挑战。而多种多址接入（MA）技术（如OMA、SDMA、NOMA、RSMA）在无线通信中对频谱资源的高效利用、波形设计以及用户间干扰管理起到了关键作用。因此，研究MA技术在ISAC中的应用，以解决ISAC的干扰问题，并探索MA技术与ISAC的协同增益，具有重要意义。

Method: 本文对多址接入（MA）技术在集成传感与通信（ISAC）网络中的应用进行了全面的教程式阐述。首先，文章介绍了ISAC的基本原理，随后对ISAC系统中存在的各类干扰进行了分类。接着，重点比较了不同MA技术（如OMA、SDMA、NOMA、RSMA）在ISAC系统中的辅助设计，分析了它们各自的优势与局限性。最后，对MA辅助ISAC的新兴应用和未来研究方向进行了展望。

Result: 本文系统地阐述了多址接入（MA）技术在集成传感与通信（ISAC）网络中的应用，并对不同MA技术辅助ISAC的设计进行了比较分析，指出了各自的优缺点。此外，文章还对ISAC系统中的干扰类型进行了分类，并展望了MA辅助ISAC的新兴应用和未来研究方向。

Conclusion: 多址接入（MA）技术为集成传感与通信（ISAC）网络提供了有效的干扰管理解决方案，同时ISAC技术也能增强MA技术的干扰管理能力，两者结合具有协同优势。本文全面介绍了MA技术在ISAC中的应用，为该领域的研究和发展提供了指导。

Abstract: The integrated sensing and communication (ISAC) technique has been considered
a key enabler for 6G radio access networks. ISAC fulfills a brand new paradigm
shift in wireless networks via the seamless interplay between communication and
sensing within a unified network. However, the tight integration of these
functionalities inevitably gives rise to various types of interference, posing
significant challenges to existing ISAC waveform designs and rendering
interference management a critical concern. Inspired by the development
trajectory of wireless communications, different multiple access (MA)
techniques, such as orthogonal multiple access (OMA), space-division multiple
access (SDMA), and more recently, non-orthogonal multiple access (NOMA) and
rate-splitting multiple access (RSMA), have been demonstrated to play a pivotal
role in efficiently utilizing limited spectrum resources, designing ISAC
waveforms, as well as managing inter-user interference and inter-functionality
interference in ISAC. Notably, the interplay between MA and ISAC presents
mutually beneficial integration. On the one hand, ISAC helps MA techniques
better exploit their interference management capability beyond the
communication-only networks. On the other hand, different MA techniques serve
as promising solutions for inter-functionality and inter-user interference
management in ISAC. In this paper, we deliver the first comprehensive tutorial
of MA techniques in ISAC networks. Specifically, we illustrate the fundamental
principles of ISAC, classify the diverse types of interference in different
ISAC systems, and compare MA-assisted ISAC designs, highlighting their
respective advantages and limitations. Moreover, we provide an outlook on the
emerging applications and future research directions of different MA-assisted
ISAC.

</details>


### [697] [Know What, Know Why: Semantic Hazard Communication for Intelligent V2X Systems](https://arxiv.org/abs/2509.02442)
*Chen Sun,Wenqi Zhang,Bizhu Wang,Xiaodong Xu,Chau Yuen,Yan Zhang,Ping Zhang*

Main category: eess.SP

TL;DR: SEE-V2X系统通过智能摄像头和上下文感知消息增强了V2X通信，提高了交通效率并减少了不必要的减速。


<details>
  <summary>Details</summary>
Motivation: 现有V2X通信系统广播的简短警告消息缺乏上下文信息，可能导致驾驶员过度谨慎或效率低下。

Method: 提出SEE-V2X系统，使用配备智能摄像头的RSU检测障碍物并传输上下文感知消息，使驾驶员能够理解危险的原因。通过实际演示展示了“see-through”功能，并进行仿真以比较SEE-V2X与传统V2X的性能。

Result: SEE-V2X系统在实际演示中展示了“see-through”功能，使驾驶员能够可视化隐藏在障碍物后的行人。仿真结果表明，SEE-V2X在不同交通条件下显著提高了交通效率并减少了不必要的减速。

Conclusion: SEE-V2X系统通过提供语义增强和可解释的V2X通信，能够让驾驶员根据具体驾驶情况做出更明智的决策，从而提高交通效率和安全性。

Abstract: In current vehicle-to-everything (V2X) communication systems, roadside units
(RSUs) broadcast brief warning messages that alert nearby vehicles to avoid
potential hazards. However, these messages lack contextual information on why a
warning is issued, leading to excessive caution or inefficient driving
behaviors. To avoid such a situation, we propose a semantic-enhanced and
explainable V2X (SEE-V2X) system. In the proposed system, RSUs equipped with
smart cameras detect obstructions and transmit context-aware messages to
vehicles. By understanding both what the hazard is and why it occurs, drivers
can make more intelligent decisions based on their specific driving situation.
Furthermore, through a real-field demonstration, we show the new "see-through"
feature in the proposed system, which enables drivers to visualize hidden
pedestrians behind obstacles. We also perform simulations to compare
traditional V2X with SEE-V2X under different traffic conditions. The results
show that SEE-V2X significantly improves traffic efficiency and reduces
unnecessary deceleration.

</details>


### [698] [LLM-Enhanced Space-Air-Ground-Sea Integrated Networks](https://arxiv.org/abs/2509.02540)
*Halvin Yang,Sangarapillai Lambotharan,Mahsa Derakhshani,Lajos Hanzo*

Main category: eess.SP

TL;DR: SAGSIN网络面临信道状态信息陈旧和带宽不匹配两大挑战。本文提出使用单一大型语言模型（LLM）作为统一的、数据驱动的自适应层，该模型联合训练于无线、光学和声学数据，以解决上述问题。LLM能够预测信道状态，实现近乎容量的接收；还能通过语义编码减少图像传输的信噪比要求，克服带宽限制。


<details>
  <summary>Details</summary>
Motivation: 为了实现无缝的全球多媒体连接，SAGSIN（空间-空气-地面-海洋一体化网络）概念面临着信道状态信息（CSI）陈旧和跨协议栈数据速率差异巨大的两大挑战，这阻碍了其部署。

Method: 本文提出使用一个大型语言模型（LLM）作为统一的自适应层。该模型联合训练于无线、光学和声学数据，能够：1. 预测未来多个相干间隔的信道状态信息（CSI），以应对快速变化的信道；2. 通过语义编码将原始传感器数据转换为面向任务的令牌，从而在低信噪比下实现高保真图像传输，克服水下链路的数据速率限制。

Result: LLM作为一种面向未来的技术，可以作为SAGSIN网络的介质无关自适应层，贯穿无线、光学和声学信道。LLM驱动的信道预测器可以实现近乎容量的接收，而LLM驱动的语义编码器则可以克服数据速率限制。

Conclusion: LLM在SAGSIN网络中展现出解决CSI陈旧和带宽不匹配问题的潜力，可作为统一的自适应层。未来的研究方向包括设备端模型压缩、多模态保真度控制、跨层资源编排和可信操作，以推动SAGSIN从实验室原型走向现场部署。

Abstract: The space-air-ground-sea integrated networking (SAGSIN) concept promises
seamless global multimedia connectivity, yet two obstacles still limit its
practical deployment. Firstly, high-velocity satellites, aerial relays and
sea-surface platforms suffer from obsolete channel state information (CSI),
undermining feedback-based adaptation. Secondly, data-rate disparity across the
protocol stack is extreme: terabit optical links in space coexist with kilobit
acoustic under-water links. This article shows that a single large language
model (LLM) backbone, trained jointly on radio, optical and acoustic traces,
can provide a unified, data-driven adaptation layer that addresses both rapid
CSI ageing and severe bandwidth disparity across the SAGSIN protocol stack.
Explicitly, an LLM-based long-range channel predictor forecasts the strongest
delay-Doppler components several coherence intervals ahead, facilitating
near-capacity reception despite violent channel fluctuations. Furthermore, our
LLM-based semantic encoder turns raw sensor payloads into task-oriented tokens.
This substantially reduces the SNR required for high-fidelity image delivery in
a coastal underwater link, circumventing the data rate limitation by semantic
communications. Inclusion of these tools creates a medium-agnostic adaptation
layer that spans radio, optical and acoustic channels. We conclude with
promising open research directions in on-device model compression, multimodal
fidelity control, cross-layer resource orchestration and trustworthy operation,
charting a path from laboratory prototypes to field deployment.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [699] [IoT-based Noise Monitoring using Mobile Nodes for Smart Cities](https://arxiv.org/abs/2509.00979)
*Bhima Sankar Manthina,Shreyash Gujar,Sachin Chaudhari,Kavita Vemuri1,Shivam Chhirolya*

Main category: cs.ET

TL;DR: 该论文提出了一种使用配备GPS的移动节点（车辆上的传感器节点）的低成本、可扩展的物联网（IoT）实时环境噪声监测解决方案。通过机器学习算法（特别是随机森林回归）对移动节点进行校准，以提高精度，并将其部署在印度海得拉巴，以捕获时空噪声变化。


<details>
  <summary>Details</summary>
Motivation: 城市噪音污染对公众健康构成重大威胁，但现有的监测基础设施空间覆盖范围和适应性有限。

Method: 开发了一种低成本、可扩展的物联网（IoT）环境噪声监测解决方案，使用集成GPS模块的移动节点（车辆上的传感器节点）。在实验室环境中，使用包括简单线性回归（SLR）、多元线性回归（MLR）、多项式回归（PR）、分段回归（SR）、支持向量回归（SVR）、决策树（DT）和随机森林回归（RFR）在内的各种机器学习（ML）算法对声学节点进行了校准。为了提高精度，在移动环境中结合参考设备对物联网节点进行现场校准。

Result: 在移动校准中，随机森林回归（RFR）模型取得了最佳性能，R2为0.937，均方根误差（RMSE）为1.09。该系统在印度海得拉巴部署了27天，捕获了436,420个数据点，突显了工作日、周末和排灯节期间的时空噪声变化。将车速纳入校准可显著提高准确性。

Conclusion: 所提出的系统展示了在智慧城市中广泛部署基于物联网的噪声传感网络的潜力，从而能够进行有效的噪音污染管理和城市规划。

Abstract: Urban noise pollution poses a significant threat to public health, yet
existing monitoring infrastructures offer limited spatial coverage and
adaptability. This paper presents a scalable, low-cost, IoT-based, real-time
environmental noise monitoring solution using mobile nodes (sensor nodes on a
moving vehicle). The system utilizes a low-cost sound sensor integrated with
GPS-enabled modules to collect geotagged noise data at one-second intervals.
The sound nodes are calibrated against a reference sound level meter in a
laboratory setting to ensure accuracy using various machine learning (ML)
algorithms, such as Simple Linear Regression (SLR), Multiple Linear Regression
(MLR), Polynomial Regression (PR), Segmented Regression (SR), Support Vector
Regression (SVR), Decision Tree (DT), and Random Forest Regression (RFR). While
laboratory calibration demonstrates high accuracy, it is shown that the
performance of the nodes degrades during data collection in a moving vehicle.
To address this, it is demonstrated that the calibration must be performed on
the IoT-based node based on the data collected in a moving environment along
with the reference device. Among the employed ML models, RFR achieved the best
performance with an R2 of 0.937 and RMSE of 1.09 for mobile calibration. The
system was deployed in Hyderabad, India, through three measurement campaigns
across 27 days, capturing 436,420 data points. Results highlight temporal and
spatial noise variations across weekdays, weekends, and during Diwali.
Incorporating vehicular velocity into the calibration significantly improves
accuracy. The proposed system demonstrates the potential for widespread
deployment of IoT-based noise sensing networks in smart cities, enabling
effective noise pollution management and urban planning.

</details>


### [700] [5-axis Multi-material Desktop Additive Manufacturing of Conformal Antennas](https://arxiv.org/abs/2509.01448)
*Ivan Revenga Riesco,Borut Lampret,Connor Myant,David Boyle*

Main category: cs.ET

TL;DR: 本论文提出使用低成本、五轴、多材料增材制造技术制造功能性、复杂共形天线。


<details>
  <summary>Details</summary>
Motivation: 为了描述使用低成本、五轴、多材料增材制造技术制造功能性、复杂共形天线的新颖应用。

Method: 使用定制的开源五轴桌面打印机，结合导电长丝，制造了共形 S 频段贴片和超宽带天线，并与平面印刷天线和电磁仿真进行了比较。

Result: 结果表明，该方法在阻抗匹配、缩短制造时间和节省成本方面具有潜力，突显了多轴多材料原型设计在复杂几何形状天线制造中的应用前景。

Conclusion: 多轴多材料增材制造技术为制造复杂几何形状的天线提供了有前景的方法，具有提高性能和降低成本的潜力。

Abstract: This paper describes the novel use of low-cost, 5-axis, multi-material
additive manufacturing to fabricate functional, complex conformal antennas.
Using a customised open source 5-axis desktop printer incorporating conductive
filaments, conformal S-band patch and Ultra-Wide Band antennas were fabricated
and compared against planar-printed counterparts and electromagnetic
simulations. Results show the potential of the approach for superior impedance
matching, reduced fabrication time, and cost savings; highlighting the
applicability of multi-axis multi-material prototyping of antennas with complex
geometries.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [701] [Approximating Graphic Multi-Path TSP and Graphic Ordered TSP](https://arxiv.org/abs/2509.00448)
*Morteza Alimi,Niklas Dahlmeier,Tobias Mömke,Philipp Pabst,Laura Vargas Koch*

Main category: cs.DS

TL;DR: 本研究为图度量下的多路径TSP问题提供了一个2的近似因子算法，并将其思想应用于有序TSP问题，得到了1.791的近似因子。


<details>
  <summary>Details</summary>
Motivation: 多路径TSP是路径TSP的推广，已有算法和近似因子研究。本研究旨在图度量下获得更好的近似因子。

Method: 提出了一种基于对偶流分解和采样路径的算法，并将采样路径成本吸收到双边连接的边中。

Result: 在图度量下，成功将多路径TSP的近似因子从2.214降低到2。同时，为有序TSP问题提供了一个1.791的近似因子算法。

Conclusion: 研究为图度量下的多路径TSP和有序TSP问题提供了更优的近似算法。

Abstract: The path version of the Traveling Salesman Problem is one of the most
well-studied variants of the ubiquitous TSP. Its generalization, the Multi-Path
TSP, has recently been used in the best known algorithm for path TSP by Traub
and Vygen [Cambridge University Press, 2024]. The best known approximation
factor for this problem is $2.214$ by B\"{o}hm, Friggstad, M\"{o}mke and
Spoerhase [SODA 2025]. In this paper we show that for the case of graphic
metrics, a significantly better approximation guarantee of $2$ can be attained.
Our algorithm is based on sampling paths from a decomposition of the flow
corresponding to the optimal solution to the LP for the problem, and connecting
the left-out vertices with doubled edges. The cost of the latter is twice the
optimum in the worst case; we show how the cost of the sampled paths can be
absorbed into it without increasing the approximation factor. Furthermore, we
prove that any below-$2$ approximation algorithm for the special case of the
problem where each source is the same as the corresponding sink yields a
below-$2$ approximation algorithm for Graphic Multi-Path TSP.
  We also show that our ideas can be utilized to give a factor
$1.791$-approximation algorithm for Ordered TSP in graphic metrics, for which
the aforementioned paper [SODA 2025] and Armbruster, Mnich and N\"agele [APPROX
2024] give a $1.868$-approximation algorithm in general metrics.

</details>


### [702] [How to Compute a Moving Sum](https://arxiv.org/abs/2509.00537)
*David K. Maslen,Daniel N. Rockmore*

Main category: cs.DS

TL;DR: 该专著探讨了窗口递推的计算方面，包括顺序和并行计算，并介绍了新的算法和理论。它还讨论了半结合性和代数条件，并提供了各种领域的示例。


<details>
  <summary>Details</summary>
Motivation: 窗口递聚在自然、社会和计算科学中无处不在，该专著旨在探讨其计算方面。

Method: 该专著通过代数构造（半直接积）和求幂算法（在半群中）来推导新的并行和向量算法。它还研究了半结合性和表示函数组合和函数应用的数据的代数条件。

Result: 文中介绍了新的顺序算法，其延迟较低，并推导了现有顺序算法的复杂性和有效性域。此外，还开发了新的并行和向量算法。

Conclusion: 该专著的结论是，通过将窗口递聚与半直接积和求幂算法联系起来，可以系统化用于并行化递聚计算的技术。

Abstract: Windowed recurrences are sliding window calculations where a function is
applied iteratively across the window of data, and are ubiquitous throughout
the natural, social, and computational sciences. In this monograph we explore
the computational aspects of these calculations, including sequential and
parallel computation, and develop the theory underlying the algorithms and
their applicability. We introduce an efficient new sequential algorithm with
low latency, and develop new techniques to derive and analyze the complexity
and domain of validity of existing sequential algorithms. For parallel
computation we derive new parallel and vector algorithms by relating windowed
recurrences to the algebraic construction of semidirect products, and to
algorithms for exponentiation in semigroups. In the middle chapters of the
monograph we further develop the theory of semi-associativity and the algebraic
conditions for representing function composition and function application by
data. This systematizes the techniques used by practitioners to parallelize
recurrence calculations. We end the monograph with an extensive gallery of
examples of interest to specialists in many fields. Throughout the monograph
new algorithms are described with pseudo-code transcribed from functioning
source code.

</details>


### [703] [Triangle Counting in Hypergraph Streams: A Complete and Practical Approach](https://arxiv.org/abs/2509.00674)
*Lingkai Meng,Long Yuan,Xuemin Lin,Wenjie Zhang,Ying Zhang*

Main category: cs.DS

TL;DR: 该论文提出了一种新的超图三角计数算法HTCount及其变种HTCount-P，解决了现有方法的局限性，能在严格的内存限制下实现高精度的计数，并将估计误差降低了1到2个数量级。


<details>
  <summary>Details</summary>
Motivation: 现有超图三角计数方法在超顶点三角结构分类不完整（仅考虑内三角或外三角）和抽样方案不灵活（预定义抽样数量不适应内存限制）方面存在局限性。该研究旨在解决这些问题，提供更全面的三角结构分类和更灵活适应内存的抽样方法。

Method: 该研究首先提出了超顶点三角的完整分类（内、杂合、外三角）。然后，开发了一种基于水库抽样的算法HTCount，能够根据可用内存动态调整样本大小。为了进一步优化内存利用率和减少估计误差，又开发了一种基于分区的变种HTCount-P，该算法将未使用的内存自适应地划分为独立的样本子集。并对算法的无偏性和方差界进行了理论分析。

Result: HTCount和HTCount-P算法在严格的内存限制下实现了高精度的三角计数估计，相对误差比现有方法低1到2个数量级，并且具有持续的高吞吐量。提出的三角结构分类在揭示有意义的交互模式方面具有表现力。

Conclusion: HTCount和HTCount-P是解决超图三角计数问题的有效算法，它们通过完整的三角结构分类和自适应的抽样策略，在内存效率和估计精度方面显著优于现有方法，适用于在资源受限的环境下进行超图分析。

Abstract: Triangle counting in hypergraph streams, including both hyper-vertex and
hyper-edge triangles, is a fundamental problem in hypergraph analytics, with
broad applications. However, existing methods face two key limitations: (i) an
incomplete classification of hyper-vertex triangle structures, typically
considering only inner or outer triangles; and (ii) inflexible sampling schemes
that predefine the number of sampled hyperedges, which is impractical under
strict memory constraints due to highly variable hyperedge sizes. To address
these challenges, we first introduce a complete classification of hyper-vertex
triangles, including inner, hybrid, and outer triangles. Based on this, we
develop HTCount, a reservoir-based algorithm that dynamically adjusts the
sample size based on the available memory M. To further improve memory
utilization and reduce estimation error, we develop HTCount-P, a
partition-based variant that adaptively partitions unused memory into
independent sample subsets. We provide theoretical analysis of the unbiasedness
and variance bounds of the proposed algorithms. Case studies demonstrate the
expressiveness of our triangle structures in revealing meaningful interaction
patterns. Extensive experiments on real-world hypergraphs show that both our
algorithms achieve highly accurate triangle count estimates under strict memory
constraints, with relative errors that are 1 to 2 orders of magnitude lower
than those of existing methods and consistently high throughput.

</details>


### [704] [Large cliques and large independent sets: can they coexist?](https://arxiv.org/abs/2509.00721)
*Uriel Feige,Ilia Pauzner*

Main category: cs.DS

TL;DR: 该论文研究了图中k-排除顶点的识别问题。当k大于n/4时，图中一定存在k-排除顶点，并且可以在多项式时间内找到。当k小于n/4时，识别k-排除顶点是NP难的。


<details>
  <summary>Details</summary>
Motivation: 研究在秘密共享方案中出现的与识别k-排除顶点相关的问题。

Method: 研究了k-排除顶点的定义，并分析了其在不同k值下的复杂性。证明了当k > (1/4 + ε)n时，图中一定存在k-排除顶点，并且可以在多项式时间内找到。证明了当k < (1/4 - ε)n时，判断图中是否存在k-排除顶点是NP难的。

Result: 证明了当k > (1/4 + ε)n时，图中一定存在k-排除顶点，并且可以在多项式时间内找到。证明了当k < (1/4 - ε)n时，判断图中是否存在k-排除顶点是NP难的。

Conclusion: 识别k-排除顶点的问题在k值大于n/4时是容易解决的，而在k值小于n/4时是困难的。

Abstract: For a graph $G$ and a parameter $k$, we call a vertex $k$-enabling if it
belongs both to a clique of size $k$ and to an independent set of size $k$, and
we call it $k$-excluding otherwise. Motivated by issues that arise in secret
sharing schemes, we study the complexity of detecting vertices that are
$k$-excluding. We show that for every $\epsilon$, for sufficiently large $n$,
if $k > (\frac{1}{4} + \epsilon)n$, then every graph on $n$ vertices must have
a $k$-excluding vertex, and moreover, such a vertex can be found in polynomial
time. In contrast, if $k < (\frac{1}{4} - \epsilon)n$, a regime in which it
might be that all vertices are $k$-enabling, deciding whether a graph has no
$k$-excluding vertex is NP-hard.

</details>


### [705] [New approximate distance oracles and their applications](https://arxiv.org/abs/2509.00890)
*Avi Kadria,Liam Roditty*

Main category: cs.DS

TL;DR: 该论文研究了具有非恒定查询时间的距离预言机，探索了空间、拉伸和查询时间之间的权衡，并提出了新的三向权衡，适用于$n$-Pairs Shortest Paths和All Nodes Shortest Cycles问题。


<details>
  <summary>Details</summary>
Motivation: 研究具有非恒定查询时间的距离预言机，探索空间、拉伸和查询时间之间的权衡。

Method: 提出了一种新的三向权衡，适用于$0 < r < 1/2$和整数$k ilepath 1$，构造了一个$(2k(1 - 2r) - 1)$-拉伸距离预言机，具有$	ilde{O}(m + n^{1 + 1/k})$空间和$	ilde{O}(ilepath n^r)$查询时间。

Result: 提出了一个$(2k(1 - 2r) - 1)$-拉伸距离预言机，具有$	ilde{O}(m + n^{1 + 1/k})$空间和$	ilde{O}(ilepath n^r)$查询时间。该预言机适用于$n$-Pairs Shortest Paths和All Nodes Shortest Cycles问题。

Conclusion: 该论文提出了新的距离预言机，并展示了其在$n$-Pairs Shortest Paths和All Nodes Shortest Cycles问题中的应用。

Abstract: Let $G = (V, E)$ be an undirected graph with $n$ vertices and $m$ edges, and
let $\mu = m/n$. A \emph{distance oracle} is a data structure designed to
answer approximate distance queries, with the goal of achieving low stretch,
efficient space usage, and fast query time. While much of the prior work
focused on distance oracles with constant query time, this paper presents a
comprehensive study of distance oracles with non-constant query time. We
explore the tradeoffs between space, stretch, and query time of distance
oracles in various regimes. Specifically, we consider both weighted and
unweighted graphs in the regimes of stretch $< 2$ and stretch $\ge 2$. Among
our results, we present a new three-way trade-off between stretch, space, and
query time, offering a natural extension of the classical Thorup-Zwick distance
oracle [STOC'01 and JACM'05] to regimes with larger query time. Specifically,
for any $0 < r < 1/2$ and integer $k \ge 1$, we construct a $(2k(1 - 2r) -
1)$-stretch distance oracle with $\tilde{O}(m + n^{1 + 1/k})$ space and
$\tilde{O}(\mu n^r)$ query time. In addition, we demonstrate several
applications of our new distance oracles to the $n$-Pairs Shortest Paths
($n$-PSP) problem and the All Nodes Shortest Cycles ($ANSC$) problem.

</details>


### [706] [Almost Tight Approximation Hardness and Online Algorithms for Resource Scheduling](https://arxiv.org/abs/2509.01086)
*Rathish Das,Hao Sun*

Main category: cs.DS

TL;DR: 该论文研究了具有 precedence 约束的资源调度问题，提出了近似算法和硬度结果。


<details>
  <summary>Details</summary>
Motivation: 研究具有 precedence 约束的资源调度问题的近似算法和硬度，并将其与 SCS 问题联系起来。

Method: 提出了近似算法和硬度结果，并展示了调度问题与 SCS 问题之间的联系。

Result: 在离线设置中，证明了几乎紧密的近似硬度；在在线设置中，提出了匹配的竞争比下界和确定性在线算法。

Conclusion: 该研究为具有 precedence 约束的资源调度问题提供了近似算法和硬度结果，并揭示了其与 SCS 问题的联系。

Abstract: We study the precedence-constrained resource scheduling problem [SICOMP'75].
There are $n$ jobs where each job takes a certain time to finish and has a
resource requirement throughout the execution time. There are precedence among
the jobs. The problem asks that given a resource budget, schedule the jobs
obeying the precedence constraints to minimize makespan (maximum completion
time of a job) such that at any point in time, the total resource being used by
all the jobs is at most the given resource budget. In the offline setting, an
important open question is whether a polynomial-time $O(1)$-factor
approximation algorithm can be found. We prove almost tight hardness of
approximation: For some constant $\alpha > 0$, there is no $o((\log
t_{\max})^{\alpha})$-factor ( or $o( ( \log n )^\alpha )$-factor )
approximation algorithm with $n$ jobs of maximum job length $t_{\max}$, unless
P = NP ( or NP $\subset$ DTIME$(O( 2^{\text{polylog}(n)}))$ ).
  We further show a connection between this scheduling problem and a seemingly
unrelated problem called the shortest common super-sequence (SCS) problem,
which has wide application in Biology and Genomics. We prove that an $o(\log
t_{\max})$-factor approximation of the scheduling problem would imply the
existence of an $o(|\Sigma|)$-approximation algorithm for SCS with alphabet
$\Sigma$.
  We then consider the online setting. We present $\Omega(\log n)$ and
$\Omega(\log t_{\max})$ lower bounds of the competitive ratio of any randomized
online algorithm. Moreover, we present a matching $O(\min\{\log n, \log
t_{\max}\})$-competitive deterministic online algorithm.

</details>


### [707] [Column-generation for a two-dimensional multi-criteria bin-packing problem](https://arxiv.org/abs/2509.01218)
*Christof Groschke,Steffen Goebbels,Jochen Rethmann*

Main category: cs.DS

TL;DR: Two-dimensional bin-packing problem in PCB manufacturing is addressed using a branch-and-price approach with Ryan-Foster branching to improve efficiency over MIP methods.


<details>
  <summary>Details</summary>
Motivation: The running times of an earlier MIP presentation are only acceptable for small problem instances, necessitating a more efficient approach for the two-dimensional bin-packing problem in printed circuit board manufacturing.

Method: A branch-and-price approach using an adapted Ryan-Foster-branching is discussed. The pricing problem computes layouts, separating time-consuming constraints from the master problem.

Result: The branch-and-price approach is expected to provide more acceptable running times compared to the earlier MIP presentation, especially for larger problem instances.

Conclusion: The branch-and-price approach with adapted Ryan-Foster-branching is a viable method for solving the two-dimensional bin-packing problem in printed circuit board manufacturing, offering improved efficiency.

Abstract: In this study, we examine a two-dimensional bin-packing problem in printed
circuit board manufacturing. Among other objectives, the number of bins, but
also the number of different bin layouts, is to be minimized. As the running
times of an earlier MIP presentation are only acceptable for small problem
instances, we will now discuss a branch-and-price approach by using an adapted
Ryan-Foster-branching. The pricing problem computes the layouts, separating the
time-consuming constraints from the master problem.

</details>


### [708] [Hitting Geodesic Intervals in Structurally Restricted Graphs](https://arxiv.org/abs/2509.01413)
*Tatsuya Gima,Yasuaki Kobayashi,Yuto Okada,Yota Otachi,Hayato Takaike*

Main category: cs.DS

TL;DR: 该论文研究了图论中的“命中测地线区间”问题，该问题旨在找到一个大小不超过k的顶点集S，使得S与给定顶点对T中的每对顶点的最短路径相交。研究结果在负面和正面都扩展了已知结果，并展示了与结构图参数的尖锐复杂度对比。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是扩展已知的“命中测地线区间”问题的复杂度结果，并展示其与结构图参数的对比。

Method: 该研究通过证明NP-completeness和提出固定参数算法来研究该问题。具体来说，它证明了该问题在添加单个顶点到5顶点路径的并集上是NP-complete的，并提出了参数化为k+模宽度和k+顶点完整性的固定参数算法。

Result: 该研究表明，“命中测地线区间”问题在添加单个顶点到5顶点路径的并集、添加一个顶点到路径以及添加一个通用顶点到三角形的并集上是NP-complete的。此外，它还表明该问题在带宽为4且最大度为5的图上也是NP-complete的。研究还提出了参数化为k+模宽度和k+顶点完整性的固定参数算法，并表明参数化为最小顶点多路切割大小是W[2]-complete的。

Conclusion: 该研究扩展了“命中 geodesic intervals”问题的已知结果，并在负面和正面都展示了其与结构图参数的尖锐复杂度对比。研究结果包括NP-completeness结果和固定参数算法。

Abstract: Given a graph $G = (V,E)$, a set $T$ of vertex pairs, and an integer $k$,
Hitting Geodesic Intervals asks whether there is a set $S \subseteq V$ of size
at most $k$ such that for each terminal pair $\{u,v\} \in T$, the set $S$
intersects at least one shortest $u$-$v$ path. Aravind and Saxena [WALCOM 2024]
introduced this problem and showed several parameterized complexity results. In
this paper, we extend the known results in both negative and positive
directions and present sharp complexity contrasts with respect to structural
graph parameters.
  We first show that the problem is NP-complete even on graphs obtained by
adding a single vertex to a disjoint union of 5-vertex paths. By modifying the
proof of this result, we also show the NP-completeness on graphs obtained from
a path by adding one vertex and on graphs obtained from a disjoint union of
triangles by adding one universal vertex. Furthermore, we show the
NP-completeness on graphs of bandwidth 4 and maximum degree 5 by replacing the
universal vertex in the last case with a long path. Under standard complexity
assumptions, these negative results rule out fixed-parameter algorithms for
most of the structural parameters studied in the literature (if the solution
size $k$ is not part of the parameter).
  We next present fixed-parameter algorithms parameterized by $k$ plus
modular-width and by $k$ plus vertex integrity. The algorithm for the latter
case does indeed solve a more general setting that includes the
parameterization by the minimum vertex multiway-cut size of the terminal
vertices. We show that this is tight in the sense that the problem
parameterized by the minimum vertex multicut size of the terminal pairs is
W[2]-complete. We then modify the proof of this intractability result and show
that the problem is W[2]-complete parameterized by $k$ even in the setting
where $T = \binom{Q}{2}$ for some $Q \subseteq V$.

</details>


### [709] [Fixed-Parameter Tractable Submodular Maximization over a Matroid](https://arxiv.org/abs/2509.01591)
*Shamisa Nematollahi,Adrian Vladu,Junyao Zhao*

Main category: cs.DS

TL;DR: 该论文为非单调子模最大化问题设计了参数可解（FPT）算法，并考虑了独立于元素总数 n 的单个参数——秩 r。作者提出了两种 FPT 算法：一种用于离线场景，另一种用于随机顺序流式传输场景。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在为（非单调）子模最大化问题在存在图论中的“团约束”时，设计参数可解（FPT）算法，其中团的秩 r 被视为一个独立于元素总数 n 的固定参数。

Method: 作者设计了两种参数可解（FPT）算法：一种用于离线场景，另一种用于随机顺序流式传输场景。

Result: 流式传输算法实现了 1/2 - ε 的近似比，内存使用量为 Õ(r/poly(ε))；离线算法实现了 1 - 1/e - ε 的近似比，运行时间为 n·2^Õ(r/poly(ε))，内存使用量为 Õ(r/poly(ε))。

Conclusion: 该研究表明，在参数可解（FPT）框架下，团约束下的单调和非单调子模最大化之间没有显著区别。

Abstract: In this paper, we design fixed-parameter tractable (FPT) algorithms for
(non-monotone) submodular maximization subject to a matroid constraint, where
the matroid rank $r$ is treated as a fixed parameter that is independent of the
total number of elements $n$. We provide two FPT algorithms: one for the
offline setting and another for the random-order streaming setting. Our
streaming algorithm achieves a $\frac{1}{2}-\varepsilon$ approximation using
$\widetilde{O}\left(\frac{r}{\textrm{poly}(\varepsilon)}\right)$ memory, while
our offline algorithm obtains a $1-\frac{1}{e}-\varepsilon$ approximation with
$n\cdot 2^{\widetilde{O}\left(\frac{r}{\textrm{poly}(\varepsilon)}\right)}$
runtime and $\widetilde{O}\left(\frac{r}{\textrm{poly}(\varepsilon)}\right)$
memory. Both approximation factors are near-optimal in their respective
settings, given existing hardness results. In particular, our offline algorithm
demonstrates that--unlike in the polynomial-time regime--there is essentially
no separation between monotone and non-monotone submodular maximization under a
matroid constraint in the FPT framework.

</details>


### [710] [Fast Computation of $k$-Runs, Parameterized Squares, and Other Generalised Squares](https://arxiv.org/abs/2509.02179)
*Yuto Nakashima,Jakub Radoszewski,Tomasz Waleń*

Main category: cs.DS

TL;DR: 该论文主要研究了k-不匹配重复以及参数化匹配的重复问题。论文首先证明了k-重复和k-运行的输出大小上限为O(nk log k)，从而改进了Kolpakov和Kucherov的算法复杂度。接着，论文将此结果应用于参数化匹配的重复问题，提出了一种在O(nσ log σ)时间内报告所有非等价参数化匹配重复的算法，并提出了一种在O(n log n)时间内计算非等价参数化匹配重复数量的算法。该算法还可以应用于其他子串兼容的等价关系，以及计算字符串本身不同的重复数量，特别是在σ=ω(log n)时，对于计数保持顺序的重复问题，比Gawrychowski等人的O(nσ)算法有改进。


<details>
  <summary>Details</summary>
Motivation: 研究k-不匹配重复的输出大小上限，并将其应用于参数化匹配的重复问题，旨在改进现有算法的复杂度和效率。

Method: 通过理论分析证明k-重复和k-运行的输出大小上限为O(nk log k)。基于此，提出新的算法来报告和计算非等价参数化匹配重复的数量。

Result: 证明了k-重复和k-runs的输出大小上限为O(nk log k)，并将此结果应用于参数化匹配的重复问题，提出了O(nσ log σ)的报告算法和O(n log n)的计数算法。

Conclusion: 论文成功地改进了k-不匹配重复的复杂度上限，并在此基础上提出了更高效的参数化匹配重复算法，为相关领域的研究提供了新的见解和工具。

Abstract: A $k$-mismatch square is a string of the form $XY$ where $X$ and $Y$ are two
equal-length strings that have at most $k$ mismatches. Kolpakov and Kucherov
[Theor. Comput. Sci., 2003] defined two notions of $k$-mismatch repeats, called
$k$-repetitions and $k$-runs, each representing a sequence of consecutive
$k$-mismatch squares of equal length. They proposed algorithms for computing
$k$-repetitions and $k$-runs working in $O(nk \log k + output)$ time for a
string of length $n$ over an integer alphabet, where $output$ is the number of
the reported repeats. We show that $output=O(nk \log k)$, both in case of
$k$-repetitions and $k$-runs, which implies that the complexity of their
algorithms is actually $O(nk \log k)$. We apply this result to computing
parameterized squares.
  A parameterized square is a string of the form $XY$ such that $X$ and $Y$
parameterized-match, i.e., there exists a bijection $f$ on the alphabet such
that $f(X) = Y$. Two parameterized squares $XY$ and $X'Y'$ are equivalent if
they parameterized match. Recently Hamai et al. [SPIRE 2024] showed that a
string of length $n$ over an alphabet of size $\sigma$ contains less than
$n\sigma$ non-equivalent parameterized squares, improving an earlier bound by
Kociumaka et al. [Theor. Comput. Sci., 2016]. We apply our bound for
$k$-mismatch repeats to propose an algorithm that reports all non-equivalent
parameterized squares in $O(n\sigma \log \sigma)$ time. We also show that the
number of non-equivalent parameterized squares can be computed in $O(n \log n)$
time. This last algorithm applies to squares under any substring compatible
equivalence relation and also to counting squares that are distinct as strings.
In particular, this improves upon the $O(n\sigma)$-time algorithm of
Gawrychowski et al. [CPM 2023] for counting order-preserving squares that are
distinct as strings if $\sigma = \omega(\log n)$.

</details>


### [711] [A Simple and Fast Reduction from Gomory-Hu Trees to Polylog Maxflows](https://arxiv.org/abs/2509.02520)
*Maximilian Probst Gutenberg,Rasmus Kyng,Weixuan Yuan,Wuwei Yuan*

Main category: cs.DS

TL;DR: 该论文提出了一种将Gomory-Hu树约简到多对数最大流计算的方法，在无权图上效率高，并可扩展到加权图和超图。


<details>
  <summary>Details</summary>
Motivation: 为了找到一种高效的计算Gomory-Hu树的方法，以保留所有成对最小割。

Method: 提出了一种将Gomory-Hu树约简为多对数最大流计算的方法，该方法适用于无权图、加权图和超图。

Result: 在无权图上，该约简方法可以将实例大小和运行时间减少到~O(m)；对于加权图，实例大小和运行时间增加到~O(n^2)；对于超图，也实现了紧密的约简。

Conclusion: 该论文提出的约简方法在计算Gomory-Hu树方面是一种简单而有效的方法，并且在不同类型的图上都具有良好的性能。

Abstract: Given an undirected graph $G=(V,E,w)$, a Gomory-Hu tree $T$ (Gomory and Hu,
1961) is a tree on $V$ that preserves all-pairs mincuts of $G$ exactly.
  We present a simple, efficient reduction from Gomory-Hu trees to polylog
maxflow computations. On unweighted graphs, our reduction reduces to maxflow
computations on graphs of total instance size $\tilde{O}(m)$ and the algorithm
requires only $\tilde{O}(m)$ additional time. Our reduction is the first that
is tight up to polylog factors. The reduction also seamlessly extends to
weighted graphs, however, instance sizes and runtime increase to
$\tilde{O}(n^2)$.
  Finally, we show how to extend our reduction to reduce Gomory-Hu trees for
unweighted hypergraphs to maxflow in hypergraphs. Again, our reduction is the
first that is tight up to polylog factors.

</details>


### [712] [Reusing Samples in Variance Reduction](https://arxiv.org/abs/2509.02526)
*Yujia Jin,Ishani Karmarkar,Aaron Sidford,Jiayi Wang*

Main category: cs.DS

TL;DR: 本论文提出一个通用框架，通过复用随机性来优化结构化优化问题中全批量查询和样本查询之间的权衡，改进了梯度查询与函数查询、矩阵向量乘法与随机行查询、以及矩阵向量乘法与生成模型查询的效率。


<details>
  <summary>Details</summary>
Motivation: 为了改进结构化优化问题中全批量查询和样本查询之间的权衡。

Method: 提出一个通用框架，通过复用随机性来优化查询效率，并引入伪独立算法的概念来量化随机算法输出与随机源的独立性。

Result: 在有限和最小化、顶部特征向量计算以及马尔可夫决策过程优化等问题中，改进了梯度/矩阵向量乘法查询与样本/生成模型查询的权衡。

Conclusion: 通过复用随机性，可以提高涉及子问题求解的随机优化算法的效率。

Abstract: We provide a general framework to improve trade-offs between the number of
full batch and sample queries used to solve structured optimization problems.
Our results apply to a broad class of randomized optimization algorithms that
iteratively solve sub-problems to high accuracy. We show that such algorithms
can be modified to reuse the randomness used to query the input across
sub-problems. Consequently, we improve the trade-off between the number of
gradient (full batch) and individual function (sample) queries for finite sum
minimization, the number of matrix-vector multiplies (full batch) and random
row (sample) queries for top-eigenvector computation, and the number of
matrix-vector multiplies with the transition matrix (full batch) and generative
model (sample) queries for optimizing Markov Decision Processes. To facilitate
our analysis we introduce the notion of pseudo-independent algorithms, a
generalization of pseudo-deterministic algorithms [Gat and Goldwasser 2011],
that quantifies how independent the output of a randomized algorithm is from a
randomness source.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [713] [Speeding Up the NSGA-II via Dynamic Population Sizes](https://arxiv.org/abs/2509.01739)
*Benjamin Doerr,Martin S. Krejca,Simon Wietheger*

Main category: cs.NE

TL;DR: dNSGA-II是一种动态种群大小的NSGA-II算法，旨在提高多目标优化效率，其在OneMinMax基准测试上的运行时间比经典NSGA-II快O(n)。


<details>
  <summary>Details</summary>
Motivation: 经典的MOEA为了存储帕累托最优解，通常使用大的、静态的种群，这会减慢算法速度。

Method: 提出dNSGA-II，一种基于NSGA-II但具有非静态种群大小的算法。dNSGA-II从一个小的初始种群开始，在用户指定的函数评估次数后翻倍种群大小，直至达到最大种群大小。对dNSGA-II进行了数学运行时间分析，证明了其在OneMinMax基准测试上的期望运行时间和高概率运行时间。此外，还探讨了在利用dNSGA-II的并发运行时移除τ参数的方法。

Result: dNSGA-II在OneMinMax基准测试上，其运行时间复杂度为O(log(μ)τ + μ log(n))，相比经典NSGA-II的最优期望运行时间提高了Θ(n)倍。移除τ参数后，虽然与最优τ选择相比有O(log(n))的轻微减慢，但仍比经典NSGA-II快Θ(n / log(n))。

Conclusion: dNSGA-II通过动态调整种群大小，显著提高了多目标优化的效率，尤其是在OneMinMax基准测试上，其运行时间复杂度优于经典NSGA-II。移除τ参数的并发运行策略也提供了一种实用的加速方法。

Abstract: Multi-objective evolutionary algorithms (MOEAs) are among the most widely and
successfully applied optimizers for multi-objective problems. However, to store
many optimal trade-offs (the Pareto optima) at once, MOEAs are typically run
with a large, static population of solution candidates, which can slow down the
algorithm. We propose the dynamic NSGA-II (dNSGA-II), which is based on the
popular NSGA-II and features a non-static population size. The dNSGA-II starts
with a small initial population size of four and doubles it after a
user-specified number $\tau$ of function evaluations, up to a maximum size of
$\mu$. Via a mathematical runtime analysis, we prove that the dNSGA-II with
parameters $\mu \geq 4(n + 1)$ and $\tau \geq \frac{256}{50} e n$ computes the
full Pareto front of the \textsc{OneMinMax} benchmark of size $n$ in
$O(\log(\mu) \tau + \mu \log(n))$ function evaluations, both in expectation and
with high probability. For an optimal choice of $\mu$ and $\tau$, the resulting
$O(n \log(n))$ runtime improves the optimal expected runtime of the classic
NSGA-II by a factor of $\Theta(n)$. In addition, we show that the parameter
$\tau$ can be removed when utilizing concurrent runs of the dNSGA-II. This
approach leads to a mild slow-down by a factor of $O(\log(n))$ compared to an
optimal choice of $\tau$ for the dNSGA-II, which is still a speed-up of
$\Theta(n / \log(n))$ over the classic NSGA-II.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [714] [Bimorph Lithium Niobate Piezoelectric Micromachined Ultrasonic Transducer](https://arxiv.org/abs/2509.00600)
*Ziqian Yao,Vakhtang Chuluhadze,Zihuan Liu,Xiaoyu Niu,Tzu-Husan Hsu,Byeongjin Kim,Neal Hall,Ruochen Lu*

Main category: physics.app-ph

TL;DR: 这是关于一种基于转移的周期性极化压电薄膜（P3F）X切割铌酸锂（LN）的赝双层压电微超声换能器（PMUT）的演示。


<details>
  <summary>Details</summary>
Motivation: 展示一种利用LN材料实现高效横向场激励弯曲模式的PMUT，并利用其高压电系数和低介电损耗来提升传感器和换能器的性能。

Method: 采用转移的周期性极化压电薄膜（P3F）X切割铌酸锂（LN）构建赝双层PMUT，并利用相反的平面内极化实现高效的横向场激励弯曲模式。

Result: 制造的PMUT在接近1 MHz时表现出平面外模式，机电耦合为3.6%。激光多普勒测振仪的测量结果与有限元分析一致，峰值中心位移为340 pm/V。

Conclusion: 结果表明，赝双层P3F LN PMUTs是一种有潜力用于制造紧凑型、高性能超声换能器的平台。

Abstract: This work demonstrates a prototype bi-layer piezoelectric micromachined
ultrasonic transducer (PMUT) based on transferred periodically poled
piezoelectric film (P3F) X-cut lithium niobate (LN). Opposite in-plane
polarizations in the piezoelectric film stack are employed to enable efficient
lateral field excitation of the flexural mode. Thanks to its high piezoelectric
coefficient and low dielectric loss, the X-cut LN exhibits high figure of
merits (FoMs) as both sensors and transducers. The fabricated PMUT demonstrates
an out-of-plane mode near 1 MHz with an electromechanical coupling of 3.6\%.
Laser Doppler vibrometry further validates the finite element analysis, showing
a peak center displacement of 340 pm/V. These results establish bi-layer P3F LN
PMUTs as a promising platform for compact and high-performance ultrasonic
transducers. Future work will focus on theoretical analysis, modeling of the
measured data, improving the design of the transducer topology, and mitigating
feedthrough effects.

</details>


### [715] [Limits to the Hall effect and other nonreciprocal effects in three-dimensional metamaterials](https://arxiv.org/abs/2509.01593)
*Christian Kern,Graeme W. Milton*

Main category: physics.app-ph

TL;DR: Metamaterials: Deriving fundamental limits and design blueprints for nonreciprocal properties, particularly the Hall effect, with implications for mobility, Verdet constant, and optimal microstructures.


<details>
  <summary>Details</summary>
Motivation: Explore fundamental limits and design blueprints for exotic nonreciprocal properties in metamaterials, focusing on the Hall effect.

Method: Derive comprehensive bounds on effective nonreciprocal properties of 3D metamaterials assuming equivalence to the conductivity problem in a weak applied magnetic field. Identify microstructures achieving or approaching these bounds.

Result: Established bounds showing effective Hall mobility is limited by constituent materials' Hall mobility. Found that effective Verdet constant cannot be enhanced under additional conditions. Identified optimal microstructures for diagonal Hall tensor components, achieved by pure phases or rank-1 laminates with same-sign Hall coefficients.

Conclusion: Elucidated the limits of nonreciprocal metamaterials and identified key prerequisites for phenomena like sign-inversions and enhancements. Suggested extensions to other effects like the Faraday effect in resonant plasmonic metamaterials.

Abstract: Metamaterials can exhibit exotic nonreciprocal properties, yet corresponding
fundamental limits and design blueprints achieving them are largely unexplored.
Here, we derive comprehensive bounds on the effective nonreciprocal properties
of three-dimensional metamaterials and identify microstructures achieving or
approaching these bounds. We assume that the underlying equations are
equivalent to the conductivity problem in a weak applied magnetic field. While
we focus on the Hall effect, our results are more generally applicable,
particularly to the Faraday effect in the quasistatic regime and in the absence
of losses and resonances. Our bounds yield three important implications: First,
the effective Hall mobility of a metamaterial cannot be larger than the largest
Hall mobility among the constituent materials. Second, under additional
conditions, the effective Verdet constant cannot be enhanced either. Third, for
diagonal Hall tensor components, the optimal values are achieved either by one
of the pure phases or a rank-1 laminate formed from them, provided that the
Hall coefficients of all phases have the same sign. Our work elucidates the
limits of nonreciprocal metamaterials and identifies key prerequisites for
obtaining exotic phenomena such as sign-inversions and enhancements. Several
extensions appear within reach, for example to the Faraday effect in
metamaterials exhibiting plasmonic resonances.

</details>


### [716] [2D-to-3D transformation of ring origami via snap-folding instabilities](https://arxiv.org/abs/2509.02467)
*Lu Lu,Sophie Leanza,Luyuan Ning,Ruike Renee Zhao*

Main category: physics.app-ph

TL;DR: 通过在环形折纸的杆段中引入面外自然曲率，研究了2D环形折纸的2D到3D形状变换策略，实现了自引导、自发形状变形以及从简单几何形状构建复杂结构。


<details>
  <summary>Details</summary>
Motivation: 形状变换结构在软体机器人和可编程超材料等工程应用中具有重要意义，而环形折纸作为一种形状变换结构，通过易位触发的屈曲不稳定性实现形状变换。

Method: 结合多段克希杆模型、有限元模拟和实验，系统地研究了具有面外自然曲率的环形折纸的3D平衡态和相变行为。

Result: 结果表明，通过设计杆件的面外自然曲率，可以实现自发的2D到3D形状变换（例如，平面正方形到球体）的易位折叠，以及多稳态3D构型转变和紧凑型单稳态零能量3D构型。

Conclusion: 研究证明，通过引入面外自然曲率，可以实现环形折纸的2D到3D形状变换，并可用于设计功能性可展开和可折叠结构。

Abstract: Shape-morphing structures have been intensively researched for a wide range
of engineering applications, including multi-modal soft robots and
property-programmable metamaterials, owing to their ability to change shape and
size in response to external stimuli. Ring origami, consisting of closed-loop
rods, is a class of shape-morphing structures that undergo shape transformation
through folding enabled by snap-buckling instabilities. Previous studies have
shown that 2D ring origami composed of rod segments with in-plane natural
curvature (i.e., the stress-free curved state lies in the plane of the planar
ring) can achieve diverse and intriguing 2D-to-2D shape transformations. Here,
we propose a 2D-to-3D shape transformation strategy for ring origami by
introducing out-of-plane natural curvature (i.e., the stress-free curved state
lies in a plane perpendicular to the planar ring) into the rod segments. Due to
natural curvature-induced out-of-plane bending moments, a 2D elastic ring
spontaneously snaps out-of-plane and reaches equilibrium in a 3D configuration.
These snapping-induced out-of-plane shape transitions not only enable
self-guided, spontaneous shape morphing, but also allow the construction of
complex structures from simple geometries, making them promising for the design
of functional deployable and foldable structures. By combining a multi-segment
Kirchhoff rod model with finite element simulations and experiments, we
systematically investigate the 3D equilibrium states and transition behavior of
these systems. We demonstrate that by rationally designing the out-of-plane
natural curvature of rod segments, the rings can exhibit a range of functional
behaviors, including spontaneous 2D-to-3D shape transformation (e.g., planar
square to sphere) via snap-folding, multistable 3D configuration transitions,
and compact monostable zero-energy 3D configurations.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [717] [High-Distance Error-Correcting Codes for Fermion-to-Qubit Mappings in 2D and 3D](https://arxiv.org/abs/2509.00147)
*Ruby Wei,Aqua Chung,Luke Coffman,Su-Kuan Chu,Xun Gao*

Main category: quant-ph

TL;DR: 提出一种高距离、常稳定子权重的量子比特编码方法，用于模拟二维和三维费米子系统，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有费米子到量子比特的编码方法在距离、稳定子权重和局域性保留方面存在局限，无法满足大规模量子模拟的需求。

Method: 将一种小距离的二维或三维费米子到量子比特编码与高距离的费米子颜色码进行复合，构建高距离、常稳定子权重的费米子到量子比特稳定子码。

Result: 提出了一种高距离、常稳定子权重的费米子到量子比特稳定子码，该编码方法可以保留局域性，并且是第一个同时实现高距离、常稳定子权重和局域性保留的三维编码。

Conclusion: 该方法为量子模拟费米子系统提供了一条稳健且可扩展的途径。

Abstract: Quantum simulation of fermionic systems is a leading application of quantum
computers. One promising approach is to represent fermions with qubits via
fermion-to-qubit mappings. In this work, we present high-distance
fermion-to-qubit stabilizer codes for simulating 2D and 3D fermionic systems.
These codes achieve arbitrarily large code distances while keeping stabilizer
weights constant. They also preserve locality by mapping local fermionic
operators to local qubit operators at any fixed distance. Notably, our 3D
construction is the first to simultaneously achieve high distance, constant
stabilizer weights, and locality preservation. Our construction is based on
concatenating a small-distance 2D or 3D fermion-to-qubit code with a
high-distance fermionic color code. Together, these features provide a robust
and scalable pathway to quantum simulation of fermionic systems.

</details>


### [718] [The rotation-invariant Hamiltonian problem is QMA$_{\rm EXP}$-complete](https://arxiv.org/abs/2509.00161)
*Jon Nelson,Daniel Gottesman*

Main category: quant-ph

TL;DR: 一维和高维情况下的局部哈密顿量问题，本研究关注固定但任意的晶格维度和可伸缩的晶格长度，并证明该问题是QMA_EXP完全的。


<details>
  <summary>Details</summary>
Motivation: 研究局部哈密顿量问题的计算复杂性谱，特别是介于一维QMA_EXP完全和高维平均场论导致解缠态之间的情形。

Method: 研究固定但任意的晶格维度和可伸缩晶格长度下的旋转不变哈密顿量问题。

Result: 证明了该旋转不变哈密顿量问题是QMA_EXP完全的，回答了Gottesman和Irani（2013）提出的一个公开问题。

Conclusion: 该研究结果确定了一个广泛的参数范围，在此范围内，这些旋转不变哈密顿量具有高计算复杂性。

Abstract: In this work, we study a variant of the local Hamiltonian problem where we
restrict to Hamiltonians that live on a lattice and are invariant under
translations and rotations of the lattice. In the one-dimensional case this
problem is known to be QMA$_{\rm EXP}$-complete. On the other hand, if we fix
the lattice length then in the high-dimensional limit the ground state becomes
unentangled due to arguments from mean-field theory. We take steps towards
understanding this complexity spectrum by studying a problem that is
intermediate between these two extremes. Namely, we consider the regime where
the lattice dimension is arbitrary but fixed and the lattice length is scaled.
We prove that this rotation-invariant Hamiltonian problem is QMA$_{\rm
EXP}$-complete answering an open question of [Gottesman, Irani 2013]. This
characterizes a broad parameter range in which these rotation-invariant
Hamiltonians have high computational complexity.

</details>


### [719] [Optimizing Cost Hamiltonian Compilation for Max-Cut QAOA on Unweighted Graphs Using Global Controls and Qubit Bit Flips](https://arxiv.org/abs/2509.00170)
*Saber Dinpazhouh,Illya V. Hicks*

Main category: quant-ph

TL;DR: 该研究探讨了QAOA算法在最大割问题中用于trapped-ion量子计算机的成本哈密顿量编译问题，使用全局耦合操作和单比特翻转代替标准编译。研究改进了已知的上界，并为特定图家族提供了更紧密的界限，同时揭示了该问题与Hadamard矩阵理论的联系，并提出了一个更优的混合整数规划（MIP）公式。


<details>
  <summary>Details</summary>
Motivation: 研究QAOA编译问题，特别是在trapped-ion量子计算机上，旨在最小化操作误差。

Method: 使用全局耦合操作和单比特翻转代替标准C-NOT和Rz门进行编译。推导了编译问题的结构性质，证明了Union of Stars方法的秩最优性（gc(G) >= n-1），并将一般上界改进到2.5n+2。研究了特定图家族（cliques, perfect matchings, paths, cycles）的界限，并建立了与Hadamard矩阵理论的联系。最后，提出了一种紧凑的混合整数规划（MIP）公式。

Result: 证明了Union of Stars方法是秩最优的，对一系列图的gc(G)给出了n-1的下界，并将一般上界改进到2.5n+2。为特定图家族提供了更精确的界限，并发现了与Hadamard矩阵理论的联系。提出了一个优于先前指数级MIP的紧凑MIP公式。

Conclusion: 该研究在QAOA编译问题上取得了重要进展，通过改进界限、提供具体图家族的分析以及提出新的MIP公式，为在trapped-ion量子计算机上实现更高效的QAOA算法奠定了基础。

Abstract: We study a cost Hamiltonian compilation problem for the quantum approximate
optimization algorithm (QAOA) applied to the Max-Cut problem, focusing on
trapped-ion quantum computers. Instead of standard compilation with CNOT and Rz
gates, we employ global coupling operations and single-qubit bit flips. Prior
work by Rajakumar et al. established that such a compilation is always
possible.
  Minimizing operational error requires short operation sequences. The problem
reduces to a low-rank semi-discrete decomposition of the graph's adjacency
matrix, where the minimum achievable rank, the graph coupling number gc(G),
represents the number of global control layers. Rajakumar et al. introduced the
Union of Stars construction, proving gc(G) <= 3n - 2 for unweighted graphs with
n vertices, and gave an O(m)-rank construction for weighted graphs.
  We concentrate on unweighted graphs. We derive structural properties of the
compilation problem and show the Union of Stars method is order-optimal by
proving a lower bound of gc(G) >= n - 1 for a family of graphs. We also improve
the general upper bound to 2.5n + 2. For particular graph families -- cliques,
perfect matchings, paths, and cycles -- we provide sharper bounds. Further, we
reveal a link between the problem and Hadamard matrix theory.
  Finally, we introduce a compact mixed-integer programming (MIP) formulation
that outperforms the previously studied exponential-size MIP.

</details>


### [720] [Large time-step discretisation of adiabatic quantum dynamics](https://arxiv.org/abs/2509.00171)
*Dong An,Pedro C. S. Costa,Dominic W. Berry*

Main category: quant-ph

TL;DR: 绝热量子计算的数字实现可以通过选择较大的时间步长来优化，即使时间步长大小与容差和演化时间无关，也能实现高精度模拟，并且可以匹配Grover搜索的下界。


<details>
  <summary>Details</summary>
Motivation: 尽管绝热量子计算（Adiabatic Quantum Computing, AQC）是一个通用框架，但其数字实现需要高效的哈密顿量模拟子程序，这可能会带来额外的计算开销或复杂的量子控制逻辑。

Method: 研究表明，时间离散化中的时间步长可以远大于预期，从而大大降低了整体复杂度。此外，通过边界抵消条件（boundary cancellation condition），连续绝热误差可以被指数级抑制，即使是一阶Trotter方法，在采用统一时间步长的情况下也能实现指数级收敛。

Result: 将该方法应用于绝热无结构搜索，结果显示该方法可以匹配Grover搜索的下界，无需预先知道标记状态的数量，并且其性能可以与量子近似优化算法（QAOA）相媲美。

Conclusion: 通过优化时间步长和利用边界抵消条件，绝热量子计算的数字实现效率得到了显著提升，并在特定应用中展现出优越的性能。

Abstract: Adiabatic quantum computing is a general framework for preparing eigenstates
of Hamiltonians on quantum devices. However, its digital implementation
requires an efficient Hamiltonian simulation subroutine, which may introduce
extra computational overhead or complicated quantum control logic. In this
work, we show that the time step sizes in time discretization can be much
larger than expected, and the overall complexity is greatly reduced.
Remarkably, regardless of the general convergence order of the numerical
method, we can choose a uniform time step size independent of tolerated error
and evolution time for sufficiently accurate simulation. Furthermore, with the
boundary cancellation condition where the continuous diabatic errors are
exponentially suppressed, we provide strong evidence on an exponential
convergence of even first-order Trotter with uniform time step size. We apply
our analysis to the example of adiabatic unstructured search and show several
preferable features of the Trotterized adiabatic approach: it can match the
Grover lower bound, it does not require a priori knowledge on the number of
marked states, and its performance can be asymptotically comparable with that
of the quantum approximate optimization algorithm.

</details>


### [721] [Strategies to search for two-dimensional materials with long spin qubit coherence time](https://arxiv.org/abs/2509.00222)
*Michael Y. Toriyama,Jiawei Zhan,Shun Kanai,Giulia Galli*

Main category: quant-ph

TL;DR: 通过高通量计算筛选二维材料及其异质结构，预测核自旋浴驱动的量子比特退相干和 T2 时间，发现 190 种单层材料 T2 > 1 ms，并开发了用于加速材料筛选的 T2 分析模型。


<details>
  <summary>Details</summary>
Motivation: 二维材料易于集成到现有微电子和光子平台，有望用于设计新型量子器件，但缺乏合适的二维材料作为量子比特载体以及能维持长 T2 的衬底，需要寻找具有鲁棒自旋相干性的候选材料。

Method: 开发高通量计算工作流，预测二维材料和异质结构中核自旋浴驱动的量子比特退相干和 T2 时间。初步筛选了 1173 种二维材料，并构建了 1554 种二维材料与三维衬底的晶格匹配异质结构。推导了分析模型以快速预测 T2。

Result: 筛选出 190 种单层二维材料的 T2 > 1 ms，高于金刚石。发现异质结构中的 T2 通常低于裸露的二维材料，但像 CeO2 和 CaO 这样的低噪声衬底有助于维持高 T2。分析模型能够量化二维材料和衬底的核自旋浴对异质结构退相干的相对贡献。

Conclusion: 通过开发高通量工作流和分析模型，扩展了二维材料及其自旋相干时间的基因组，为自旋量子比特平台的发展奠定了基础。

Abstract: Two-dimensional (2D) materials that can host qubits with long spin coherence
time (T2) have the distinct advantage of integrating easily with existing
microelectronic and photonic platforms, making them attractive for designing
novel quantum devices with enhanced performance. However, the relative lack of
2D materials as spin qubit hosts, as well as appropriate substrates that can
help maintain long T2, necessitates a strategy to search for candidates with
robust spin coherence. Here, we develop a high-throughput computational
workflow to predict the nuclear spin bath-driven qubit decoherence and T2 in 2D
materials and heterostructures. We initially screen 1173 2D materials and find
190 monolayers with T2 > 1 ms, higher than that of naturally-abundant diamond.
We then construct 1554 lattice-commensurate heterostructures between high-T2 2D
materials and select 3D substrates, and we find that T2 is generally lower in a
heterostructure than in the bare 2D host material; however, low-noise
substrates (such as CeO2 and CaO) can help maintain high T2. To further
accelerate the material screening effort, we derive analytical models that
enable rapid predictions of T2 for 2D materials and heterotructures. The models
offer a simple, yet quantitative, way to determine the relative contributions
to decoherence from the nuclear spin baths of the 2D host and substrate in a
heterostructural system. By developing a high-throughput workflow and
analytical models, we expand the genome of 2D materials and their spin
coherence times for the development of spin qubit platforms.

</details>


### [722] [Continuous-time quantum walk-based ansätze on neutral atom hardware](https://arxiv.org/abs/2509.00386)
*Edric Matwiejew,Jonathan Wurtz,Jing Chen,Pascal Jahan Elahi,Tommaso Macri,Ugo Varetto*

Main category: quant-ph

TL;DR: 该论文研究了在受限图上进行连续时间量子行走（CTQW），并将其应用于模拟中。研究人员利用中性原子硬件实现了这些抽象行走，并探索了具有有限控制的变分状态制备协议。他们将CTQW与最优控制相结合，以制备非平凡目标态。此外，该论文利用里德伯阻塞现象将虚拟行走动力学与中性原子硬件上的物理执行相匹配。通过分析收敛性和可扩展性，该研究评估了在噪声硬件上执行CTQW的性能，并提出了一种使用贝叶斯后处理的噪声缓解方法。最终，论文证明了在受限子空间中使用量子行走制备非平凡纠缠态的可行性，以及在云可访问的模拟模式中性原子量子计算机上进行受限独立集子空间非平衡动力学的可行性。


<details>
  <summary>Details</summary>
Motivation: 利用近期的量子计算机作为模拟器，将抽象系统映射到物理量子硬件上执行的程序，并探索连续时间量子行走（CTQW）在约束图上的应用。

Method: 首先，研究人员通过CTQW和最优控制的视角探索了具有有限控制的变分状态制备协议，以在不可分离希尔伯特空间中制备非平凡目标态。其次，他们利用里德堡阻塞现象，将这些虚拟行走动力学与模拟模式下的中性原子硬件上的物理执行相匹配。最后，他们引入了使用贝叶斯后处理的噪声缓解方法。

Result: 通过分析收敛性和可扩展性，该研究评估了在噪声硬件上执行CTQW的性能，证明了这些特征即使在噪声硬件上也能持续存在。论文展示了使用量子行走在约束子空间中制备非平凡纠缠态的能力，以及在云可访问的模拟模式中性原子量子计算机上进行受限独立集子空间非平衡动力学的可行性。

Conclusion: 该论文证明了使用量子行走在约束子空间中制备非平凡纠缠态的能力，以及在云可访问的模拟模式中性原子量子计算机上进行受限独立集子空间非平衡动力学的可行性，并且这些模拟在噪声硬件上也能保持其有效性。

Abstract: A key use of near-term quantum computers is as analogue simulators, matching
the action of some virtual or abstracted system onto a program executed on
physical quantum hardware. This work explores continuous-time quantum walks
(CTQW) on constrained graphs of independent set configurations and implements
these abstract walks on analog-mode neutral-atom hardware. First, we explore
variational state preparation protocols with limited controls through the lens
of CTQW and optimal control to prepare nontrivial target states in
non-separable Hilbert spaces. Next, we match these virtual walk dynamics to
physical execution on analog-mode neutral atom hardware by leveraging the
Rydberg blockade phenomenon. We analyze the convergence and scaling in the
preparation of these known states as an indicator of the upper bounds on the
quantum speedup mechanisms predicted by ideal CTQWs, showing that these
signatures persist even when executed on noisy hardware. Finally, we introduce
noise mitigation methods using Bayesian postprocessing. This paper demonstrates
the ability to prepare nontrivial entangled states using quantum walks in
constrained subspaces, and that nonequilibrium dynamics on constrained
independent set supspaces is feasible on cloud-accessible analog-mode
neutral-atom quantum computers.

</details>


### [723] [An exploration of the noise sensitivity of the Shor's algorithm](https://arxiv.org/abs/2509.00417)
*Fusheng Yang,Zhipeng Liang,Zhengzhong Yi,Xuan Wang*

Main category: quant-ph

TL;DR: Shor


<details>
  <summary>Details</summary>
Motivation:  量子算法由于量子比特对环境噪声的敏感性而面临重大挑战，而量子纠错通常需要高昂的资源开销。本研究提出量子算法可能具有固有的噪声弹特性，从而降低了实现障碍。

Method: 通过将电路级噪声模型直接应用于原始算法电路来研究Shor算法，并对具有4到9位长度的电路进行故障容错位置统计。

Result: Shor算法在Z噪声下表现出比X和Y噪声更优越的容错能力。在Z噪声下，容错位置随着问题规模的增加，以与潜在错误位置相同的四次多项式阶数增长。而X和Y噪声下的容错能力则强烈依赖于复合数N和参数a。我们预测在有偏噪声下，因子分解2048位整数的模幂电路的最小正确输出概率约为1.417e-17。

Conclusion: Shor算法在Z噪声下具有良好的容错性，其容错位置增长与潜在错误位置的增长呈相同的数量级。该研究为降低量子算法的实现门槛提供了一种新的思路。

Abstract: Quantum algorithms face significant challenges due to qubit susceptibility to
environmental noise, and quantum error correction typically requires
prohibitive resource overhead. This paper proposes that quantum algorithms may
possess inherent noise resilience characteristics that could reduce
implementation barriers. We investigate Shor's algorithm by applying
circuit-level noise models directly to the original algorithm circuit. Our
findings reveal that Shor's algorithm demonstrates superior fault tolerance
under Z noise compared to X and Y noise. Focusing on the modular exponentiation
circuit which is the core component of the algorithm, we conduct fault-tolerant
position statistics on circuits with bit lengths from 4 to 9. The results show
that under Z noise, fault-tolerant positions grow with the same quartic
polynomial order as potential error positions as the problem scale increases.
In contrast, fault tolerance under X and Y noise exhibits a strong dependence
on the composite number N and the parameter a. Based on these findings, we
develop an extrapolation method predicting that the minimum probability of a
correct output of the modular exponentiation circuit to factor 2048 bit
integers under biased noise is approximately 1.417*{10}^{-17}.

</details>


### [724] [Room-temperature alignment-free magnetometry with boron vacancies in hot-pressed hexagonal boron nitride](https://arxiv.org/abs/2509.00734)
*Shuyu Wen,Raul Coto,Peiting Wen,Slawomir Prucnal,Manfred Helm,Jun-Wei Luo,Shengqiang Zhou,Yonder Berencén*

Main category: quant-ph

TL;DR: 基于hBN VB-缺陷的无需对准的室温磁场传感


<details>
  <summary>Details</summary>
Motivation: 固态自旋缺陷（如金刚石中的NV中心或hBN中的VB-）的量子传感器通常需要精确对准外部磁场和缺陷的自旋量子化轴才能实现可靠传感，但这种对准限制了器件集成并阻碍了可扩展性。

Method: 在市售热压多晶hBN中，通过室温ODMR演示了VB-的磁场传感，并利用数值模型确认了传感的可行性。

Result: 成功实现了无需对准的室温磁场传感，即使在各向异性灵敏度下传感也是可行的。

Conclusion: 热压hBN为量子磁力计提供了一个稳健且实用的平台，支持低成本、可扩展且机械稳定的量子磁场传感器，适用于实际部署。

Abstract: Magnetic field sensing is essential for applications in communication,
environmental monitoring, and biomedical diagnostics. Quantum sensors based on
solid-state spin defects, such as nitrogen-vacancy centers in diamond or boron
vacancies in single-crystal hexagonal boron nitride (hBN), typically require
precise alignment between the external magnetic field and the defect's spin
quantization axis to achieve reliable sensing. This alignment constraint
complicates device integration and hinders scalability. Here, we demonstrate
room-temperature optically detected magnetic resonance (ODMR) from negatively
charged boron vacancies (VB-) in commercially available hot-pressed
polycrystalline hBN. The random grain orientation inherently samples a broad
range of spin quantization axes, enabling alignment-free magnetic field
detection. Numerical modeling further confirms that sensing remains feasible
despite anisotropic sensitivity, establishing hot-pressed hBN as a robust and
practical platform for quantum magnetometry. This approach paves the way toward
low-cost, scalable, and mechanically stable quantum magnetic field sensors
suitable for real-world deployment.

</details>


### [725] [Polynomial complexity of open quantum system problems](https://arxiv.org/abs/2509.00424)
*Chong Chen,Ren-Bao Liu*

Main category: quant-ph

TL;DR: OQS动力学可以用多项式复杂度的定理和张量网络算法解决，比指数级增长更有效。


<details>
  <summary>Details</summary>
Motivation: 在非平衡量子动力学和量子科学技术中，开放量子系统（OQS）是普遍存在的，但其量子多体浴的动力学求解被认为是计算上难题，因为存在维度诅咒。

Method: 本文证明了一个多项式复杂度定理，表明描述OQS的缩减动力学所需的独立方程数量随演化时间的增加而增加，并且与浴大小成多项式关系。此外，本文还证明了当OQS和浴的动力学用张量网络表示时，张量收缩过程可以指定，使得键维度仅随演化时间线性增加（而不是指数级增加），从而为广泛的OQS提供了明确的高效算法。

Result: 通过求解自旋-玻色子模型和Gaudin模型这两个常见的OQS问题，证明了定理和张量网络算法的有效性。

Conclusion: 这项工作为理解OQS动力学、通过量子传感器学习环境以及在有噪声的环境中优化量子信息处理提供了方法。

Abstract: Open quantum systems (OQS's) are ubiquitous in non-equilibrium quantum
dynamics and in quantum science and technology. Solving the dynamics of an OQS
in a quantum many-body bath has been considered a computationally hard problem
because of the dimensionality curse. Here, considering that full knowledge of
the bath dynamics is unnecessary for describing the reduced dynamics of an OQS,
we prove a polynomial complexity theorem, that is, the number of independent
equations required to fully describe the dynamics of an OQS increases at most
linearly with the evolution time and polynomially with the bath size.
Therefore, efficient computational algorithms exist for solving the dynamics of
a small-sized OQS (such as a qubit or an atom). We further prove that, when the
dynamics of an OQS and the bath is represented by a tensor network, a tensor
contraction procedure can be specified such that the bond dimension (i.e., the
range of tensor indices contracted in each step) increases only linearly
(rather than exponentially) with the evolution time, providing explicitly
efficient algorithms for a wide range of OQS's. We demonstrate the theorems and
the tensor-network algorithm by solving two widely encountered OQS problems,
namely, a spin in a Gaussian bath (the spin-boson model) and a central spin
coupled to many environmental spins (the Gaudin model). This work provides
approaches to understanding dynamics of OQS's, learning the environments via
quantum sensors, and optimizing quantum information processing in noisy
environments.

</details>


### [726] [Quantum States in Twisted Tubes with Linear Cross-Section Variation](https://arxiv.org/abs/2509.00432)
*Guo-Hua Liang,Ai-Guo Mei,Men-Yun Lai,Shu-Sheng Xu*

Main category: quant-ph

TL;DR: 研究了粒子在扭曲管中的量子动力学，推导了有效哈密顿量，并分析了几何变换对量子态的影响。


<details>
  <summary>Details</summary>
Motivation: 研究粒子在扭曲管中的量子动力学，以及几何变换（旋转、缩放、剪切）如何影响其量子态。

Method: 使用扩展的薄层方法推导了有效哈密顿量，并分析了旋转、缩放和剪切变换。

Result: 旋转引入了与角动量耦合的规范场，缩放和剪切产生了提​​升非圆形横截面中简并的几何势。方形横截面中的这些变换导致简并态之间的能量分裂，而圆形横截面则保持简并。

Conclusion: 几何变换可以定制量子态，并且圆形波导对模式混合更具鲁棒性。

Abstract: We study the quantum dynamics of a particle confined in a twisted tube with a
linearly varying cross section. By relating a general linear transformation
matrix to the system's Hamiltonian, we use an extended thin-layer method to
derive an effective Hamiltonian for tangential motion under mild and general
linear transformations. Explicit forms are provided for three fundamental
transformations: rotation, scaling, and shearing. Rotation introduces a gauge
field coupled to angular momentum, while scaling and shearing produce geometric
potentials that lift degeneracies in non-circular cross sections. In square
cross sections, these transformations cause energy splittings among formerly
degenerate states, whereas circular cross sections retain degeneracy. Through
an example combining rotation and squeezing, we analyze state evolution and
compute the quantum geometric tensor to quantify geometric response. Our
results demonstrate how geometric transformations can tailor quantum states and
suggest that circular waveguides are more robust against mode mixing.

</details>


### [727] [Breaking the system-frequency limitation of quantum key distribution](https://arxiv.org/abs/2509.00438)
*Feng-Yu Lu,Jia-Xuan Li,Ze-Hao Wang,Shuang Wang,Zhen-Qiang Yin,Alvaro Navarrete,Marcos Curty,Wei Chen,De-Yong He,Guang-Can Guo,Zheng-Fu Han*

Main category: quant-ph

TL;DR: 光学设备带宽限制影响了量子密钥分发（QKD）系统的性能，高时钟速率会导致调制失准和错误。本研究提出两种新技术，可在超低水平精确表征和缓解这些缺陷，并结合能容纳残余缺陷的安全分析，确保了高速QKD系统的安全，并优于现有解决方案。该方法实现了可比研究中报告的最低相关偏差，并超越了传统带宽限制的密钥生成速率，朝着消除性能-成本权衡迈出了重要一步，为QKD的实际部署铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 量子密钥分发（QKD）系统的性能受限于光学设备的有限带宽，高时钟速率可能导致调制失准和错误，从而影响安全性和错误率。本研究旨在通过提出创新的技术来精确表征和缓解这些缺陷，以确保高速QKD系统的安全。

Method: 提出两种创新的技术，用于在超低水平精确表征和缓解调制失准和相关调制等缺陷。结合考虑残余缺陷的安全分析。

Result: 实现了可比研究中报告的最低相关偏差，并超越了传统带宽限制的秘密密钥生成速率。

Conclusion: 该方法确保了高速QKD系统的安全，优于现有解决方案，并朝着消除性能-成本权衡迈出了重要一步，为QKD的实际部署铺平了道路。

Abstract: The limited bandwidth of optical devices places strict constraints on the
performance of quantum key distribution (QKD) systems. Excessively high clock
rates can result in misaligned and correlated modulation, compromising security
and increasing error rates. In this paper, we present two innovative techniques
that enable the precise characterization and mitigation of these imperfections
at ultra-low levels. When combined with a security analysis that accommodates
residual flaws, our approach ensures the security of high-rate QKD systems and
outperforms existing solutions. Notably, our method achieves the lowest
correlated deviation reported to date in comparable studies and surpasses the
conventional, bandwidth-limited secret key rate. This advance is a significant
step towards eliminating the performance-cost trade-off, paving the way for the
practical deployment of QKD.

</details>


### [728] [The Group-IV-Vacancy Color Center in Diamond](https://arxiv.org/abs/2509.00443)
*Fenglei Gu*

Main category: quant-ph

TL;DR: Group-IV vacancy (G4V or XV) color centers in diamonds are a new class of defects with potential for quantum information processing. This paper reviews and refines theoretical models for these systems, considering intrinsic and external interactions. The refined model helps predict properties, explain experimental data, and suggest future experiments, laying the groundwork for controlling XV systems.


<details>
  <summary>Details</summary>
Motivation: This paper aims to review and refine theoretical models for Group-IV vacancy (G4V or XV) color centers in diamonds, which are a novel and promising class of defects for quantum information processing.

Method: The paper reviews and refines theoretical models for XV systems, including intrinsic interactions (spin-orbit coupling, electron-phonon interactions) and external interactions (strain, electric, light, magnetic fields). Based on these refined models, the paper predicts properties, explains experimental data, and suggests follow-up experiments.

Result: The refined theoretical models enable prediction of XV system properties and explanation of experimental data, guiding future experimental directions.

Conclusion: The established solid foundation for controlling the XV system paves the way for quantum information processing.

Abstract: Group-IV vacancy (G4V, or XV, where X = Si, Ge, Sn, Pb) color centers
constitute a novel and promising class of defects in diamonds. This chapter
reviews and refines the theoretical models for the XV systems, encompassing the
intrinsic interactions, including spin-orbit coupling and electron-phonon
interactions, and the external interactions involving strain, electric, light,
and magnetic fields. Based on the refined model, we predict their properties,
explain the experimental data, and suggest follow-up experiments. This article
established a solid foundation for controlling the XV system, thus paving the
way for quantum information processing.

</details>


### [729] [Generation of Large Kitten states via thermally driven dissipative freezing](https://arxiv.org/abs/2509.00601)
*Caspar Groiseau*

Main category: quant-ph

TL;DR: 利用狄克态的磁量子数为0的表示，通过耗散单轴扭曲产生更大的猫态或猫态，从而提高计量灵敏度和抗白噪声能力。


<details>
  <summary>Details</summary>
Motivation: 提高量子态制备效率和计量性能。

Method: 利用狄克态在正交基中的表示，通过耗散单轴扭曲来制备猫态。

Result: 成功制备了更大的猫态或猫态，提高了计量灵敏度和鲁棒性，并且制备出的态可用于量子秘密共享。

Conclusion: 所提出的方案可以有效提高量子态制备的效率和性能，并且具有实际应用价值。

Abstract: We show that one can exploit the representation of the Dicke state with
magnetic quantum number $0$ in orthogonal bases to increase the probability of
producing a large Kitten state or even a Cat state via dissipative one-axis
twisting, resulting in a net increase in metrological sensitivity and
robustness against white noise with respect to the initial state. The resulting
states are also useful for quantum secret sharing. The success of the scheme is
heralded by the rate of photoemissions. Unlike previous iterations, we have an
important population of the larger Kitten states, which makes post-selecting
trajectories for them feasible.

</details>


### [730] [Quantum Circuits for Quantum Convolutions: A Quantum Convolutional Autoencoder](https://arxiv.org/abs/2509.00637)
*Javier Orduz,Pablo Rivas,Erich Baker*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum machine learning deals with leveraging quantum theory with classic
machine learning algorithms. Current research efforts study the advantages of
using quantum mechanics or quantum information theory to accelerate learning
time or convergence. Other efforts study data transformations in the quantum
information space to evaluate robustness and performance boosts. This paper
focuses on processing input data using randomized quantum circuits that act as
quantum convolutions producing new representations that can be used in a
convolutional network. Experimental results suggest that the performance is
comparable to classic convolutional neural networks, and in some instances,
using quantum convolutions can accelerate convergence.

</details>


### [731] [Traq: Estimating the Quantum Cost of Classical Programs](https://arxiv.org/abs/2509.01508)
*Anurudh Peduri,Gilles Barthe,Michael Walter*

Main category: quant-ph

TL;DR: Traq是一个自动预测量子计算机速度提升的工具，具有可证明的保证。它包括一种包含易于量子加速的高级原语的经典语言、成本分析和到低级量子程序的编译。


<details>
  <summary>Details</summary>
Motivation: 预测未来量子计算机提供的实际加速已成为量子计算社区的焦点，但传统方法耗时且针对单一应用。

Method: Traq包含一种经典语言、成本分析和编译到低级量子程序，其成本分析能够精细地进行，捕捉非渐近信息并对程序的输入敏感。

Result: Traq提供了一个概念验证实现和一个受AND-OR树启发的案例研究。

Conclusion: Traq提供了一种自动估计量子加速的原则性方法，具有可证明的保证，并且比传统方法更精细。

Abstract: Predicting practical speedups offered by future quantum computers has become
a major focus of the quantum computing community. Typically, these predictions
are supported by lengthy manual analyses and numerical simulations and are
carried out for one specific application at a time. In this paper, we present
Traq, a principled approach towards estimating the quantum speedup of classical
programs fully automatically and with provable guarantees. It consists of a
classical language that includes high-level primitives amenable to quantum
speedups, a cost analysis, and a compilation to low-level quantum programs. Our
cost analysis upper bounds the complexity of the resulting quantum program in a
fine-grained way: it captures non-asymptotic information and is sensitive to
the input of the program (rather than providing worst-case costs). We also
provide a proof-of-concept implementation and a case study inspired by AND-OR
trees.

</details>


### [732] [Entropy Flow at the Quantum Limit](https://arxiv.org/abs/2509.00645)
*Marco A. Jimenez-Valencia,Parth Kumar,Yiheng Xu,Ferdinand Evers,Charles A. Stafford*

Main category: quant-ph

TL;DR: 量子过程中的热量远低于预期，这对量子机器的效率有益。


<details>
  <summary>Details</summary>
Motivation: 解决传统热量公式在量子极限下导致的熵在熵趋于零时无界这一悖论。

Method: 通过引入一个量子项来修正传统热量公式，得出新的量子热量公式。

Result: 新的量子热量公式预测量子过程产生的热量远小于之前的估计。

Conclusion: 修正后的量子热量公式能更好地描述量子过程中的热量，并有望提高量子机器的效率。

Abstract: Thermal management is a key challenge, both globally and microscopically in
integrated circuits and quantum technologies. The associated heat flow $I_Q$
has been understood since the advent of thermodynamics by a process of
elimination, $I_Q{=}I_E{-}\mu I_N$, subtracting from the energy flow $I_E$ its
convective contribution. However, in the quantum limit, this formula implies
the paradoxical result that the entropy entrained by heat flow is unbounded
even though the entropy itself tends to zero. We resolve this conundrum by
recognizing that the traditional formula for heat is missing a quantum term.
The correct quantum formula predicts that the heat produced in quantum
processes is vastly smaller than previously believed, with correspondingly
beneficial consequences for the efficiency of quantum machines.

</details>


### [733] [It's-A-Me, Quantum Mario: Scalable Quantum Reinforcement Learning with Multi-Chip Ensembles](https://arxiv.org/abs/2509.00713)
*Junghoon Justin Park,Huan-Hsin Tseng,Shinjae Yoo,Samuel Yen-Chi Chen,Jiook Cha*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum reinforcement learning (QRL) promises compact function approximators
with access to vast Hilbert spaces, but its practical progress is slowed by
NISQ-era constraints such as limited qubits and noise accumulation. We
introduce a multi-chip ensemble framework using multiple small Quantum
Convolutional Neural Networks (QCNNs) to overcome these constraints. Our
approach partitions complex, high-dimensional observations from the Super Mario
Bros environment across independent quantum circuits, then classically
aggregates their outputs within a Double Deep Q-Network (DDQN) framework. This
modular architecture enables QRL in complex environments previously
inaccessible to quantum agents, achieving superior performance and learning
stability compared to classical baselines and single-chip quantum models. The
multi-chip ensemble demonstrates enhanced scalability by reducing information
loss from dimensionality reduction while remaining implementable on near-term
quantum hardware, providing a practical pathway for applying QRL to real-world
problems.

</details>


### [734] [Enhancement of quantum sensing in a dissipatively coupled two-mode system](https://arxiv.org/abs/2509.00724)
*Hao-Wen Zhang,Dong-Yang Wang,Cheng-Hua Bai,Tian-Xiang Lu,Shi-Lei Su*

Main category: quant-ph

TL;DR: 一种简化的反畴时间（anti-PT）对称系统，通过共享的耗散环境间接耦合两个独立的腔体，展示了在厄尔尼（EPs）处的传感响应增强，优于非EPs配置。这种增强源于EPs处高阶奇点特征的劳伦级数展开的二阶项，为量子传感提供了紧凑且鲁棒的策略。


<details>
  <summary>Details</summary>
Motivation: 已有的量子传感技术在利用厄尔尼（EPs）增强灵敏度方面虽有潜力，但实际应用常受限于结构复杂性和严格的参数约束。

Method: 提出了一种简化的反畴时间（anti-PT）对称平台，由两个通过共享耗散环境间接耦合的独立腔体组成。通过分析本征值对外部扰动的劳伦级数展开，解释了在EPs处灵敏度增强的机制，该机制主要归因于二阶项。

Result: 在EPs处观察到显著增强的传感响应，与非EPs配置相比，证明了该平台的优越性。

Conclusion: 这种基于反畴时间（anti-PT）对称系统的方法，通过其紧凑的结构和鲁棒的传感机制，为高精度传感技术提供了新的可能性，并促进了非厄米物理学与可扩展光子器件平台的结合。

Abstract: Quantum sensing near exceptional points (EPs) in non-Hermitian systems has
shown promising sensitivity enhancements. However, practical applications are
often hindered by structural complexity and strict parameter constraints. In
this work, we introduce a simplified anti-parity-time (anti-PT) symmetric
platform consisting of two independently cavities, which are indirectly coupled
to each other by a shared dissipative environment. We demonstrate a
significantly enhanced sensing response at the EPs compared to non-EP
configurations. This improvement is attributed to the dominant second-order
term in the Laurent series expansion of the eigenvalue response to external
perturbations-a characteristic feature of higher-order singularities at EPs.
This mechanism not only reinforces the foundation for sensitivity enhancement
but also offers a structurally compact and robust strategy for quantum sensing.
Our results underscore the potential of anti-PT symmetric systems in enabling
high-precision sensing technologies and bridging non-Hermitian physics with
scalable photonic device platforms.

</details>


### [735] [Quantum Causality: Resolving Simpson's Paradox with $\mathcal{DO}$-Calculus](https://arxiv.org/abs/2509.00744)
*Pilsung Kang*

Main category: quant-ph

TL;DR: 该论文提出了一种使用量子算法框架进行因果推断的方法，通过将因果网络映射到量子电路，并利用量子门实现因果干预，以解决相关性与因果性的区分难题。


<details>
  <summary>Details</summary>
Motivation: 区分相关性与因果性是实现稳健、可信赖的机器智能的关键挑战。

Method: 将因果网络映射到量子电路，使用受控旋转门编码概率链接，通过结构重塑（类似于图手术）实现因果干预。

Result: 通过3比特模型解决了辛普森悖论，并通过10比特医疗保健模拟量化了混淆偏差，证明了该方法的有效性和可扩展性。在IonQ Aria量子计算机上进行了原理性实验验证，成功重现了悖论及其在实际噪声下的解决方案。

Conclusion: 该工作为量子因果推断提供了实际途径，为解决算法公平性和可解释人工智能（XAI）中的深层挑战提供了新的计算工具。

Abstract: Distinguishing correlation from causation is a fundamental challenge in
machine intelligence, often representing a critical barrier to building robust
and trustworthy systems. While Pearl's $\mathcal{DO}$-calculus provides a
rigorous framework for causal inference, a parallel challenge lies in its
physical implementation. Here, we apply and experimentally validate a quantum
algorithmic framework for performing causal interventions. Our approach maps
causal networks onto quantum circuits where probabilistic links are encoded by
controlled-rotation gates, and interventions are realized by a structural
remodeling of the circuit -- a physical analogue to Pearl's ``graph surgery''.
We demonstrate the method's efficacy by resolving Simpson's Paradox in a
3-qubit model, and show its scalability by quantifying confounding bias in a
10-qubit healthcare simulation. Critically, we provide a proof-of-principle
experimental validation on an IonQ Aria quantum computer, successfully
reproducing the paradox and its resolution in the presence of real-world noise.
This work establishes a practical pathway for quantum causal inference,
offering a new computational tool to address deep-rooted challenges in
algorithmic fairness and explainable AI (XAI).

</details>


### [736] [Classical algorithms for measurement-adaptive Gaussian circuits](https://arxiv.org/abs/2509.00746)
*Changhun Oh,Youngrong Lim*

Main category: quant-ph

TL;DR: Gaussian量子信息处理中的自适应测量和前馈对于实现通用性至关重要。本文研究了具有自适应性的玻色子电路，在自适应测量次数较少的情况下，即使输入态包含大量非高斯资源，均值问题也存在高效的经典算法，而在约束较少的条件下则计算困难。这与采样问题形成对比，并提出了一个介于经典模拟和量子优势之间的计算复杂度边界。


<details>
  <summary>Details</summary>
Motivation: 研究高斯量子信息处理中的自适应测量和前馈对于实现通用性的重要性，并评估其在计算能力方面的作用。同时，关注实际任务，研究量子均值问题，即估计支撑模拟和变分算法的可观测量期望值。

Method: 分析具有自适应性的玻色子电路，并证明在自适应测量次数较少时，即使输入态包含大量非高斯资源，均值问题也存在高效的经典算法。此外，还介绍了用于计算估计量所需边际量的经典技术，包括 Gurvits 第二算法的推广。

Result: 当自适应测量次数较少时，均值问题可以被高效地经典模拟，即使存在大量的非高斯资源。然而，在约束较少的条件下，该问题变得计算困难。这与采样问题不同，采样问题通常仅凭非高斯资源就足以诱导计算难度。

Conclusion: 自适应测量和前馈步骤的数量是计算能力的决定性因素。对于量子均值问题，在自适应测量次数较少的情况下，经典算法可以实现高效计算，这与采样问题形成对比，并为经典模拟和量子优势之间提供了一个清晰的计算复杂度边界。

Abstract: Gaussian building blocks are essential for photonic quantum information
processing, and universality can be practically achieved by equipping Gaussian
circuits with adaptive measurement and feedforward. The number of adaptive
steps then provides a natural parameter for computational power. Rather than
assessing power only through sampling problems -- the usual benchmark -- we
follow the ongoing shift toward tasks of practical relevance and study the
quantum mean-value problem, i.e., estimating observable expectation values that
underpin simulation and variational algorithms. More specifically, we analyze
bosonic circuits with adaptivity and prove that when the number of adaptive
measurements is small, the mean-value problem admits efficient classical
algorithms even if a large amount of non-Gaussian resources are present in the
input state, whereas less constrained regimes are computationally hard. This
yields a task-level contrast with sampling, where non-Gaussian ingredients
alone often induce hardness, and provides a clean complexity boundary
parameterized by the number of adaptive measurement-and-feedforward steps
between classical simulability and quantum advantage. Beyond the main result,
we introduce classical techniques -- including a generalization of Gurvits's
second algorithm to arbitrary product inputs and Gaussian circuits -- for
computing the marginal quantities needed by our estimators, which may be of
independent interest.

</details>


### [737] [Noise-Resilient Quantum Metrology with Quantum Computing](https://arxiv.org/abs/2509.00771)
*Xiangyu Wang,Chenrong Liu,Xinqing Wang,Dawei Lu,Ying Dong*

Main category: quant-ph

TL;DR: 该研究提出了一种直接处理量子数据的新策略，以解决当前量子计算在实际应用中面临的数据加载瓶颈问题。通过将量子计算应用于量子计量任务，该方法在嘈杂的环境下提高了传感估计的准确性和量子</strong>Fisher信息量，并在氮</strong>-空位中心和超导量子处理器上进行了实验验证和数值模拟。该方法为利用近期量子计算机实现实际的量子计量任务提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 现有的量子计算方法在将经典数据加载到量子处理器时效率低下，阻碍了实际应用。本研究旨在克服这一瓶颈，探索直接处理量子数据的方法。

Method: 提出了一种将量子计算机用于优化从量子计量中获取的信息的方案，以提高在嘈杂量子计量任务中的性能。

Result: 实验和模拟结果表明，该方法提高了传感估计的准确性，并显著增强了由量子</strong>Fisher信息量量化的灵敏度。

Conclusion: 该研究为利用近期量子计算机实现实际的量子计量任务提供了一个新的途径，通过直接处理量子数据来克服经典数据加载的限制。

Abstract: Quantum computing has made remarkable strides in recent years, as
demonstrated by quantum supremacy experiments and the realization of
high-fidelity, fault-tolerant gates. However, a major obstacle persists:
practical real-world applications remain scarce, largely due to the
inefficiency of loading classical data into quantum processors. Here, we
propose an alternative strategy that shifts the focus from classical data
encoding to directly processing quantum data. We target quantum metrology, a
practical quantum technology whose precision is often constrained by realistic
noise. We develop an experimentally feasible scheme in which a quantum computer
optimizes information acquired from quantum metrology, thereby enhancing
performance in noisy quantum metrology tasks and overcoming the
classical-data-loading bottleneck. We demonstrate this approach through
experimental implementation with nitrogen-vacancy centers in diamond and
numerical simulations using models of distributed superconducting quantum
processors. Our results show that this method improves the accuracy of sensing
estimates and significantly boosts sensitivity, as quantified by the quantum
Fisher information, thus offering a new pathway to harness near-term quantum
computers for realistic quantum metrology.

</details>


### [738] [Determination of Fluctuation correlation time in solid-state Nuclear Magnetic Resonance](https://arxiv.org/abs/2509.00803)
*Saptarshi Saha,Rangeet Bhattacharyya*

Main category: quant-ph

TL;DR: 该研究提出一种新的固态核磁共振（NMR）方法，利用预热状态来表征材料的局部环境和化学/动态位移。通过分析预热状态的寿命和横向磁化强度，可以检测环境参数的变化。研究发现，寿命随环境相关时间的增加而增加，而横向磁化强度随位移参数的增加而减小。这些结果表明，预热动力学可以提供关于局部环境的重要信息。


<details>
  <summary>Details</summary>
Motivation: 固态核磁共振（NMR）可以提供多种实验技术来检测和分析材料的化学和物理环境。本研究旨在探索一种新的方法，利用预热状态来表征材料的局部环境和化学/动态位移。

Method: 本研究采用理论方法，利用施加自旋锁定脉冲引起的预热来实现新的NMR研究范式。通过分析预热状态的寿命和横向磁化强度这两个变量来检测环境参数和化学/动态位移（例如兰姆位移）的变化。

Result: 研究结果表明，预热状态的寿命随环境相关时间的增加而增加，而横向磁化强度随位移参数的增加而减小。

Conclusion: 基于以上观察，研究提出预热动力学可以提供关于局部环境的重要信息，为固态NMR研究开辟了新的途径。

Abstract: Solid-state NMR provides a wide variety of experimental techniques to detect
and analyze a material's chemical and physical environment. Here, we offer a
theoretical demonstration of a new approach that could be a promising candidate
for characterizing the local environments and shifts. Prethermalization by
applying a spin-locking pulse brings a new research paradigm in solid-state NMR
and has not been hitherto explored for such purposes. We show that a prethermal
state can also be effective in this case. A prethermal state is described using
its lifetime and the value of transverse magnetization. Using these two
variables, we successfully detect the changes in the environmental parameter
and chemical and dynamical shifts (such as Lamb shifts). Our results exhibit
that the lifetime increases with increasing environmental correlation time. On
the other hand, the transverse magnetization decreases with the increase in the
strength of the shift parameter. Based on these observations, we propose that
the prethermalization dynamics can yield important information on local
environment.

</details>


### [739] [Would the fidelity of quantum teleportation be increased by a local filtering operation near a dilaton black hole under decoherence?](https://arxiv.org/abs/2509.00804)
*Chun-yao Liu,Zheng-wen Long,Qi-liang He*

Main category: quant-ph

TL;DR: 黑洞和环境退相干通常会负面影响量子关联和弯曲时空中的量子隐形传态保真度。本文研究了在退相干存在下，扩张子参数对量子隐形传态保真度的影响，并发现其保真度会随着扩张子参数的增加而增加。此外，通过局部滤波操作，可以将处于经典区域的量子隐形传态保真度转化为量子区域。


<details>
  <summary>Details</summary>
Motivation: 研究黑洞和环境退相干对量子隐形传态保真度的影响，特别是扩张子参数的作用。

Method: 分析了扩张子参数、系统-环境耦合以及局部滤波操作对量子隐形传态保真度的影响。

Result: 扩张子参数可以正向影响量子隐形传态保真度，甚至可以在退相干的情况下产生净保真度。处于经典区域的保真度可以通过局部滤波操作转化为量子区域。

Conclusion: 扩张子参数可以改善量子隐形传态保真度，并且局部滤波操作可以将经典保真度转化为量子保真度，这为在退相干的扩张子黑洞中实现量子隐形传态提供了新的实验思路。

Abstract: Previous studies have shown that the effects of black holes and environmental
decoherence generally negatively influence quantum correlations and the
fidelity of quantum teleportation in curved spacetime. In our paper, we find
that as the dilaton parameter increases, the fidelity of quantum teleportation
can either decrease or increase, which suggests that even in the presence of
system-environment coupling, the dilaton effect of black hole can positive
influence teleportation fidelity; specifically, the dilaton effect can create
net fidelity in quantum teleportation under decoherence. This interesting
result challenges the long-held belief that the effects of black holes and
environmental decoherence can only reduce the fidelity of quantum
teleportation. Additionally, we observe an unreported result: if the fidelity
of quantum teleportation remains in the classical region, it can be transformed
into the quantum region by utilizing a local filtering operation, thereby
achieving better fidelity than classical communication. This impressive result
may provide new insights for developing an experimental scheme to effectively
implement quantum teleportation in the context of dilaton black holes under
decoherence.

</details>


### [740] [Trainmon: a framework for reverse engineering potentials in superconducting Qubits](https://arxiv.org/abs/2509.00819)
*Saeed Hajihosseini,Seyed Iman Mirzaei,Hesam Zandi,Mohsen Akbari*

Main category: quant-ph

TL;DR: Trainmon是一个用于反向工程超导量子比特的量子势阱的框架，它使用并行排列的约瑟夫森结来模拟各种势阱，并已成功应用于Quarton和Fluxonium等量子比特，提取并验证了它们的哈密顿量和跃迁频率。


<details>
  <summary>Details</summary>
Motivation: 介绍Trainmon框架来反向工程量子势阱。

Method: 使用并行排列的约瑟夫森结来构建Trainmon框架，其哈密顿量类似于离散余弦变换，可模拟各种势阱。

Result: 将Trainmon应用于Quarton和Fluxonium量子比特，提取了它们的哈密顿量，并验证了其跃迁频率和计算了相干时间。

Conclusion: Trainmon框架能够成功反向工程量子势阱，并为超导量子比特的设计和分析提供了新的途径。

Abstract: A framework named Trainmon is introduced to reverse-engineer a quantum
potential well for superconducting qubits. Trainmon consists of parallel
branches of identical Josephson junctions. The Hamiltonian for this circuit
resembles a discrete cosine transform, which can be applied to mimic various
potentials. This framework is applied to well-known qubit potentials such as
Quarton and Fluxonium, and their Hamiltonians are extracted and solved to
validate the transition frequencies and calculate the coherence times of both
the original qubits and their Trainmon-based versions.

</details>


### [741] [Nonclassical correlations and quadrature squeezing of photons in anisotropic quantum Rabi-Stark model](https://arxiv.org/abs/2509.00821)
*Yong-Xin Zhang,Chen Wang,Qing-Hu Chen*

Main category: quant-ph

TL;DR: 研究了各向异性量子Rabi-Stark模型中光子的非经典效应，利用量子级联主方程分析了二阶和高阶关联函数，证明了非线性斯塔克耦合显著调节了光子统计，产生了独特的、可调的光子反聚束和聚束效应。关联函数的连续隧穿特征为预测量子相变提供了潜在的实验探测手段。研究还揭示了斯塔克耦合能够直接控制光子挤压，实现显著的增强和抑制。这些发现不仅揭示了各向异性量子Rabi-Stark模型中丰富的非经典现象，还确立了非线性斯塔克耦合作为量子探测的一个关键新维度，可能为精确操纵强耦合光-物质系统开辟新途径，并在量子信息处理和量子增强技术方面具有潜在应用。


<details>
  <summary>Details</summary>
Motivation: 研究各向异性量子Rabi-Stark模型中光子的非经典效应，以及非线性斯塔克耦合对光子统计、量子相变和光子挤压的调制作用，旨在为量子探测和量子信息处理提供新方法。

Method: 利用量子级联主方程分析二阶和高阶关联函数，研究非线性斯塔克耦合对光子统计和光子挤压的影响。

Result: 非线性斯塔克耦合能够显著调节光子统计，产生可调的光子反聚束和聚束效应；关联函数的连续隧穿特征可用于预测量子相变；斯塔克耦合能直接控制光子挤压，实现增强或抑制。

Conclusion: 非线性斯塔克耦合是各向异性量子Rabi-Stark模型中实现丰富非经典现象的关键，并为量子探测提供了新维度，有望应用于量子信息处理和量子增强技术。

Abstract: This study investigates nonclassical effects of photons in the anisotropic
quantum Rabi-Stark model by using a quantum dressed master equation. We analyze
second- and higher-order correlation functions, and demonstrate that the
nonlinear Stark coupling significantly modulates photon statistics, inducing
distinct and tunable photon antibunching and bunching effects. Successive
transition signatures of correlation functions provide a potential experimental
probe for predicting quantum phase transitions. We further reveal that Stark
coupling provides direct control over photon squeezing, achieving significant
enhancement and suppression. These findings not only uncover rich nonclassical
phenomena in the anisotropic quantum Rabi-Stark model but also establish the
nonlinear Stark coupling as a crucial new dimension for quantum detection. It
may open a new avenue for precise manipulation of strongly coupled light-matter
systems, with potential applications in quantum information processing and
quantum-enhanced technologies.

</details>


### [742] [Optimal Quantum Likelihood Estimation](https://arxiv.org/abs/2509.00825)
*Alon Levi,Ziv Ossi,Eliahu Cohen,Amit Te'eni*

Main category: quant-ph

TL;DR: 通过信息论优化混合量子-经典算法，提高量子哈密顿量学习效率。


<details>
  <summary>Details</summary>
Motivation: 在NISQ时代，混合量子-经典算法依赖于经典优化来指导量子操作。然而，其效率受参数选择影响。本研究旨在通过信息论方法优化量子似然估计（QLE）算法，以提高其哈密顿量学习的效率。

Method: 提出一种信息论优化策略，动态选择初始状态、测量基和演化时间，以最大化测量结果与真实哈密顿量之间的互信息。利用模拟退火最小化条件冯诺依曼熵，以最大化每次迭代的信息增益。

Result: 优化后的QLE算法显著减少了收敛所需的迭代次数，证明了该方法在加速量子系统哈密顿量学习方面的实用性。

Conclusion: 通过最大化互信息来优化参数选择，可以有效加速基于QLE的哈密顿量学习。该方法为解决更广泛的量子学习问题提供了一个通用方案。

Abstract: A hybrid quantum-classical algorithm is a computational scheme in which
quantum circuits are used to extract information that is then processed by a
classical routine to guide subsequent quantum operations. These algorithms are
especially valuable in the noisy intermediate-scale quantum (NISQ) era, where
quantum resources are constrained and classical optimization plays a central
role. Here, we improve the performance of a hybrid algorithm through
principled, information-theoretic optimization. We focus on Quantum Likelihood
Estimation (QLE) - a hybrid algorithm designed to identify the Hamiltonian
governing a quantum system by iteratively updating a weight distribution based
on measurement outcomes and Bayesian inference. While QLE already achieves
convergence using quantum measurements and Bayesian inference, its efficiency
can vary greatly depending on the choice of parameters at each step. We propose
an optimization strategy that dynamically selects the initial state,
measurement basis, and evolution time in each iteration to maximize the mutual
information between the measurement outcome and the true Hamiltonian. This
approach builds upon the information-theoretic framework recently developed in
[A. Te'eni et al. Oracle problems as communication tasks and optimization of
quantum algorithms, arXiv:2409.15549], and leverages mutual information as a
guiding cost function for parameter selection. Our implementation employs a
simulated annealing routine to minimize the conditional von Neumann entropy,
thereby maximizing information gain in each iteration. The results demonstrate
that our optimized version significantly reduces the number of iterations
required for convergence, thus proposing a practical method for accelerating
Hamiltonian learning in quantum systems. Finally, we propose a general scheme
that extends our approach to solve a broader family of quantum learning
problems.

</details>


### [743] [Emergence of non-Markovian Decoherent Histories in Integrable Environment: A "Tape Recorder" Model for Local Quantum Observables](https://arxiv.org/abs/2509.00845)
*Nataliya Arefyeva,Evgeny Polyakov*

Main category: quant-ph

TL;DR: 提出一种新的粗粒度系统描述方法，可显式评估多时间相干历史，适用于非马尔可夫和可积系统。通过研究开放量子系统在非相互作用可积环境中的局域相互作用淬灭，识别出不可逆地存储系统过去记录的环境自由度，这些模式随时间相继出现并定义了相干历史所需的投影。数值结果表明，相干泛函的非对角线元素相对于显著性阈值呈指数级抑制。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是提出一种新的粗粒度系统描述方法，该方法能够以可控的方式显式评估多时间相干历史，并适用于非马尔可夫和可积系统。

Method: 研究了一个局域相互作用淬灭（一个开放量子系统）在一个非相互作用的可积环境中的情况。该方法通过识别不可逆地存储系统过去记录的环境自由度来工作，这些自由度随时间顺序出现并定义了相干历史所需的投影。

Result: 数值结果显示，相干泛函的非对角线元素相对于显著性阈值呈指数级抑制。

Conclusion: 该方法能够以可控的方式显式评估多时间相干历史，适用于非马尔可夫和可积系统。

Abstract: We propose a new approach to coarse-grained descriptions of a system that
provides an explicit evaluation of multi-time decoherent histories in a
controlled way, applicable to non-Markovian and integrable systems.
Specifically, we study a local interaction quench of a local degree of freedom
(an open quantum system) within a noninteracting integrable environment. This
setting allows us to identify the environmental degrees of freedom that
irreversibly store records of the system's past. These modes emerge
sequentially in time and define the projections required for decoherent
histories. We show numerically that the off-diagonal elements of the
decoherence functional are exponentially suppressed relative to a significance
threshold.

</details>


### [744] [A simple universal routing strategy for reducing the connectivity requirements of quantum LDPC codes](https://arxiv.org/abs/2509.00850)
*Guangqi Zhao,Fei Yan,Xiaotong Ni*

Main category: quant-ph

TL;DR: 通过在超导处理器上实现量子低密度奇偶校验码，减少了量子纠错的开销，但代价是增加了综合萃取电路的深度。


<details>
  <summary>Details</summary>
Motivation: 量子低密度奇偶校验码需要密集、长距离的连接，这对于包括超导处理器在内的硬件实现提出了挑战。本研究旨在解决这一问题。

Method: 通过观察到X和Z双िला qubits 与数据 qubits 形成短环，利用这一特性，当直接连接不可用时，通过双िला qubits 路由数据 qubits 信息来实现稳定器测量电路。具体在双变量自行车码上，消除了长达50%的长距离连接，同时电路深度加倍，而电路级距离基本保持不变。该方法也适用于表面码。

Result: 移除了长达50%的长距离连接，同时电路深度加倍，而电路级距离基本保持不变。该方法可使表面码达到与McEwen等人相同的六边形连接要求。

Conclusion: 所提出的用于设计综合萃取电路的路由方法可应用于各种量子码，为在具有连接约束的硬件上实现这些量子码提供了实用的途径。

Abstract: Quantum low-density parity-check codes reduce quantum error correction
overhead but require dense, long-range connectivity that challenges hardware
implementation, particularly for superconducting processors. We address this
problem by demonstrating that long-range connections can be reduced at the cost
of increased syndrome extraction circuit depth. Our approach is based on the
observation that X and Z ancilla qubits form short loops with data qubits - a
property that holds for any quantum code. This enables implementing stabilizer
measurement circuits by routing data qubit information through ancilla qubits
when direct connections are unavailable. For bivariate bicycle codes, we remove
up to 50% of long-range connections while approximately doubling the circuit
depth, with the circuit-level distance remaining largely preserved. This method
can also be applied to surface codes, achieving the same hexagonal connectivity
requirement as McEwen et al. (Quantum 7, 1172 (2023)). Our routing approach for
designing syndrome extraction circuits is applicable to diverse quantum codes,
offering a practical pathway toward their implementation on hardware with
connectivity constraints.

</details>


### [745] [Assessing the Advantages and Limitations of Quantum Neural Networks in Regression Tasks](https://arxiv.org/abs/2509.00854)
*Gubio G. de Limaa,Tiago de S. Farias,Alexandre C. Ricardo,Celso Jorge Villa Boas*

Main category: quant-ph

TL;DR: 量子神经网络（QNN）在某些机器学习任务中可能优于经典模型，但其优势条件尚不明确。本研究通过对经典和量子模型应用于回归问题进行分析，并考虑了公平比较的挑战，发现QNN在近似正弦函数方面表现出显著优势，误差可比经典模型低七个数量级。然而，在其他情况下QNN表现受限，并非普遍优于经典模型，这印证了“没有免费午餐”定理。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在明确量子神经网络（QNN）在何种条件下相比经典神经网络（CNN）具有实际优势，以解决当前理解上的不确定性。

Method: 本研究通过定性和定量分析，将经典和量子模型应用于具有不同特性的两类目标函数（回归问题）进行比较。此外，还探讨了在QNN与CNN之间进行公平比较所固有的方法论挑战。

Result: 研究发现，QNN在近似正弦函数方面表现出显著优势，其误差比经典模型低高达七个数量级。然而，在其他情况下，QNN的性能受到限制，表明QNN并非在所有任务上都具有普遍优越性。

Conclusion: 量子神经网络（QNN）在特定量子机器学习任务中（如近似正弦函数）具有明显优势，但并非在所有情况下都优于经典神经网络（CNN）。研究结果支持“没有免费午餐”定理，强调了模型选择应根据具体问题领域进行考量。

Abstract: The development of quantum neural networks (QNNs) has attracted considerable
attention due to their potential to surpass classical models in certain machine
learning tasks. Nonetheless, it remains unclear under which conditions QNNs
provide concrete benefits over classical neural networks (CNNs). This study
addresses this question by performing both qualitative and quantitative
analyses of classical and quantum models applied to regression problems, using
two target functions with contrasting properties. Additionally, the work
explores the methodological difficulties inherent in making fair comparisons
between QNNs and CNNs. The findings reveal a distinct advantage of QNNs in a
specific quantum machine learning context. In particular, QNNs excelled at
approximating the sinusoidal function, achieving errors up to seven orders of
magnitude lower than their classical counterparts. However, their performance
was limited in other cases, emphasizing that QNNs are highly effective for
certain tasks but not universally sPuperior. These results reinforce the
principles of the ``No Free Lunch'' theorem, highlighting that no single model
outperforms all others across every problem domain.

</details>


### [746] [On dissipation operators of Quantum Optics](https://arxiv.org/abs/2509.00856)
*A. I. Komech,E. A. Kopylova*

Main category: quant-ph

TL;DR: 论文分析了量子光学中的耗散算符，特别是用于描述阻尼驱动的Jaynes-Cummings方程中的量子自发辐射。主要发现是量子光学基本耗散算符的对称性和非负性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究量子光学中用于描述阻尼驱动的Jaynes-Cummings方程中的量子自发辐射的耗散算符。

Method: 本文分析了量子光学中耗散算符在阻尼驱动的Jaynes-Cummings方程中的应用，该方程描述了量子化单模麦克斯韦场与双能级分子系统的耦合。

Result: 本文的主要结果证明了量子光学基本耗散算符的对称性和非负性。

Conclusion: 论文证明了量子光学基本耗散算符的对称性和非负性。

Abstract: We consider dissipation operators used in Quantum Optics for the description
of quantum spontaneous emission in the context of damped driven Jaynes-Cummings
equations. The equations describe quantised one-mode Maxwell field coupled to a
two-level molecule. Our main result is the symmetry and nonpositivity of basic
dissipation operator of Quantum Optics.

</details>


### [747] [Deformation-Driven Enhancement of Spin Defect Emission in Hexagonal Boron Nitride](https://arxiv.org/abs/2509.00912)
*Jianpei Geng,Xuankai Zhou,Nils Gross,Song Li,Yan Tung Kong,Jixing Zhang,Guodong Bian,San Lam Ng,Cheng-I Ho,Andrej Denisenko,Rainer Stöhr,Ruoming Peng,Jurgen Smet,Jörg Wrachtrup*

Main category: quant-ph

TL;DR: hexagonal boron nitride (hBN) 中的带负电的硼空位 (VB-) 由于其与目标样品的最终邻近性，已被广泛研究，可用于二维量子传感。然而，其光致发光（PL）的固有弱性限制了其传感能力。本研究通过将悬浮 hBN 区域中的 VB- 中心的光致发光（PL）提高了 30 倍，从而增强了其 PL。ODMR 对比度和自旋寿命等关键自旋特性得以保留。结果表明，与基板支撑区域相比，悬浮区域具有更高的局部形变，从而打破了局部对称性，激活了 VB- 中心的光学跃迁。


<details>
  <summary>Details</summary>
Motivation: hexagonal boron nitride (hBN) 中的带负电的硼空位 (VB-) 已被广泛研究，因为它们为二维量子传感提供了新的平台，并且与目标样品的距离极近。然而，其自旋系综的光致发光（PL）固有较弱，限制了其传感能力。

Method: 通过将悬浮 hBN 区域中的 VB- 中心的光致发光（PL）提高了 30 倍，从而增强了其 PL。ODMR 对比度和自旋寿命等关键自旋特性得以保留。研究了零场 ODMR、拉曼光谱和钾探针力显微镜。

Result: 与基板支撑区域相比，悬浮区域中的 VB- 中心的光致发光（PL）增强了高达 30 倍。ODMR 对比度、线宽和自旋寿命等关键自旋特性得以保留。研究表明，悬浮区域具有更高的局部形变，这打破了局部对称性，从而激活了 VB- 中心的光学跃迁。

Conclusion: 悬浮区域比基板支撑区域具有更高的局部形变，打破了局部对称性，从而激活了 VB- 中心的光学跃迁。这为在 hBN 中实现更强的量子传感提供了新的途径。

Abstract: The negatively charged boron vacancy (VB-) in hexagonal boron nitride (hBN)
has been extensively investigated as it offers a novel playground for
two-dimensional quantum sensing, with ultimate proximity to target samples.
However, its practical sensitivity is limited by the intrinsically weak
photoluminescence of the spin ensemble. Here, we report a photoluminescence
enhancement of up to 30 times from VB- centers in suspended regions of hBN
compared to those in substrate-supported areas. The key spin properties, such
as the optically detected magnetic resonance (ODMR) contrast and linewidth, as
well as the spin lifetime, of the VB- centers in this region are well
preserved. Detailed investigations, including measurements of zero-field ODMR,
Raman spectroscopy, and Kelvin probe force microscopy, reveal a correlation
between emission enhancement and local deformation in the sample. It is
concluded that the suspended regions exhibit higher local deformation compared
to the supported areas, breaking the local symmetry and thereby activating
otherwise forbidden or weak optical transitions of the VB- centers.

</details>


### [748] [Do quantum linear solvers offer advantage for networks-based system of linear equations?](https://arxiv.org/abs/2509.00913)
*Disha Shetty,Supriyo Dutta,Palak Chawla,Akshaya Jayashankar,Jordi Riu,Jan Nogue,K. Sugisaki,V. S. Prasannaa*

Main category: quant-ph

TL;DR: 本研究评估了量子线性求解器(QLS)在解决网络线性系统问题(NLSP)方面提供量子优势的适用性。研究了条件数、稀疏性和系统规模增长对QLS优势的影响，并推荐了具有指数级或多项式级优势的图族。结果显示，只有4%的图族具有指数级优势潜力，约20%具有多项式级优势。此外，还观察到某些图族在使用改进算法（如Childs-Kothari-Somma算法）时表现更好，并且某些图族具有虚假的指数级优势。最后，讨论了将多个图族统一为超家族以寻找无限最优图的可能性，并简要提及了实际应用中可能遇到的问题，如量子硬件挑战。


<details>
  <summary>Details</summary>
Motivation: 评估量子线性求解器（QLS）在解决网络线性系统问题（NLSP）方面提供量子优势的潜力，因为NLSP与实际应用密切相关。

Method: 通过数值方法评估了QLS在不同图族上的性能，考虑了条件数、稀疏性和系统规模增长等因素，并将HHL算法与共轭梯度（CG）方法进行了比较。

Result: 在50个考虑的图族中，只有4%显示出指数级优势的潜力，约20%显示出多项式级优势。一些图族在使用改进算法时表现更好，并且存在具有虚假指数级优势的图族。

Conclusion: 尽管只有少数图族显示出提供量子优势的潜力，但通过选择合适的图族和算法，仍然有可能在NLSP中实现量子优势。未来的工作可以集中在寻找更多具有高潜力优势的图族，并解决实际应用中的挑战。

Abstract: In this exploratory numerical study, we assess the suitability of Quantum
Linear Solvers (QLSs) toward providing a quantum advantage for Networks-based
Linear System Problems (NLSPs). NLSPs are of importance as they are naturally
connected to real-world applications. In an NLSP, one starts with a graph and
arrives at a system of linear equations. The advantage that one may obtain with
a QLS for an NLSP is determined by the interplay between three variables: the
scaling of condition number and sparsity functions of matrices associated with
the graphs considered, as well as the function describing the system size
growth. We recommend graph families that can offer potential for an exponential
advantage (best graph families) and those that offer sub-exponential but at
least polynomial advantage (better graph families), with the HHL algorithm
considered relative to the conjugate gradient (CG) method. Within the scope of
our analyses, we observe that only 4 percent of the 50 considered graph
families offer prospects for an exponential advantage, whereas about 20 percent
of the considered graph families show a polynomial advantage. Furthermore, we
observe and report some interesting cases where some graph families not only
fare better with improved algorithms such as the Childs-Kothari-Somma algorithm
but also graduate from offering no advantage to promising a polynomial
advantage, graph families that exhibit futile exponential advantage, etc. Given
the limited number of graph families that one can survey through numerical
studies, we discuss an interesting case where we unify several graph families
into one superfamily, and show the existence of infinite best and better graphs
in it. Lastly, we very briefly touch upon some practical issues that one may
face even if the aforementioned graph theoretic requirements are satisfied,
including quantum hardware challenges.

</details>


### [749] [Quantum Machine Learning Applied to the Sinking of the Titanic](https://arxiv.org/abs/2509.00916)
*Luiz Henrique Prudencio dos Santos,Eliane F. Chinaglia,Jessica Fleury Curado,Marcilei A. Guazzelli,Mariana Pojar,Sueli Hatsumi Masunaga,Roberto Baginski Batista Santos*

Main category: quant-ph

TL;DR: 混合量子-经典变分分类器在泰坦尼克号数据集上用于监督学习任务，其中非纠缠特征图模型优于纠缠特征图模型，并且量子模型比经典支持向量分类器更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子-经典变分分类器在泰坦尼克号数据集上的监督学习性能。

Method: 使用 Pauli 纠缠和非纠缠特征图以及 RealAmplitudes 变分模型（多达 50 个参数），并使用 COBYLA 优化器进行训练，在理想的量子态矢量模拟框架中进行。

Result: 非纠缠特征图模型优于纠缠特征图模型，并且在 15-20 个参数后性能饱和。量子模型和经典支持向量分类器在预测性能上相似，但在使用 90% 数据集训练时，经典模型出现性能崩溃，而量子模型则没有。

Conclusion: 变分量子分类器在 NISQ 时代可用于经典数据集的二元分类任务，并且具有鲁棒性和可行性。

Abstract: This work investigates the performance of hybrid quantum-classical
variational classifiers applied to a supervised learning task involving the
titanic3 dataset. Quantum models were constructed using Pauli entangling and
non-entangling expansion-based feature maps and the RealAmplitudes ansatz with
up to 50 variational parameters. Model training employed the COBYLA
gradient-free optimizer to minimize the cross-entropy loss, within an ideal
statevector simulation framework. Comparative performance analysis reveals that
the models based on the non-entangling feature map consistently outperformed
the models based on the entangling features maps, achieving saturation of
classification metrics (accuracy, balanced accuracy, and Youden's index) beyond
15 to 20 parameters. Further, two quantum models were benchmarked against a
classical Support Vector Classifier (SVC). While both approaches yielded
similar predictive performance across multiple training sizes, the classical
model exhibited a performance collapse when trained with 90% of the dataset, a
failure mode absent in the quantum classifiers. These results underscore the
robustness and viability of variational quantum classifiers for binary
classification tasks on classical datasets in the NISQ era.

</details>


### [750] [One- and multiphoton resonances in the light-atom interaction](https://arxiv.org/abs/2509.00985)
*Alexandre P. Costa,Alexandre V. Dodonov*

Main category: quant-ph

TL;DR: 本文对Rabi模型进行了简洁的推导，并分析了经典和量子模型中的共振现象，特别是三光子共振，旨在为量子光学和量子信息领域的研究者提供一个教学参考。


<details>
  <summary>Details</summary>
Motivation: 原子系统与电磁场的相互作用是现代物理学和新兴量子技术的核心，Rabi模型提供了描述这种相互作用的最简单和最基本的方法。

Method: 本文对经典和量子Rabi模型进行了推导，并分析了单光子和多光子共振的出现，特别关注了三光子共振。

Result: 研究展示了共振现象如何在量子Rabi模型中表现出来，并讨论了与经典描述的异同，强调了三光子共振的重要性。

Conclusion: 本文旨在为量子光学和量子信息领域的学生和研究人员提供一个关于Rabi模型基础知识的可及的教学参考。

Abstract: The interaction between atomic systems and electromagnetic fields is central
to modern physics and emerging quantum technologies. The Rabi models, in their
semiclassical and quantum versions, provide the simplest and most fundamental
description of this interaction. In this work, we present a concise derivation
of both models and show how one- and multiphoton resonances arise in the
semiclassical regime. We then analyze how these resonances manifest in the
quantum Rabi model, discussing similarities and differences in relation to the
classical description. Special attention is given to the three-photon
resonance, a phenomenon usually neglected in textbooks due to its relative
weakness, but which is intrinsic to the radiation-matter interaction. Our goal
is to offer an accessible pedagogical reference for students and researchers
interested in Quantum Optics and Quantum Information, with an emphasis on the
fundamentals of the Rabi models.

</details>


### [751] [Quantum Physical Unclonable Function based on Chaotic Hamiltonians](https://arxiv.org/abs/2509.01004)
*Soham Ghosh,Holger Boche,Marc Geitz*

Main category: quant-ph

TL;DR: 本论文提出了一种基于混沌量子动力学的量子物理不可克隆函数（QPUF）新构造，其安全性可与Haar随机酉媲美，并探讨了其在SYK模型和光学Kagome晶格上的实现方案。


<details>
  <summary>Details</summary>
Motivation: 现有的QPUF构造依赖于伪随机酉设计，在有限的对抗模型和黑盒查询访问下安全性不足，而模拟Haar随机酉的指数复杂性阻碍了其在当前量子设备上的实现。

Method: 提出了一种基于混沌量子动力学的QPUF构造，将QPUF建模为混沌哈密顿量下的酉时间演化，并证明了其安全性。此外，还提出了一种可有效模拟的伪混沌QPUF。

Result: 证明了基于混沌动力学的QPUF具有与Haar随机酉相当的安全性，即使混沌动力学产生的随机性少于理想Haar酉，也足以保证QPUF在多项式时间内不可克隆。识别了SYK模型作为QPUF哈密顿量的候选，并基于光学Kagome晶格提出了QPUF设备的架构。

Conclusion: 本文为实现理论安全性与QPUF实际应用之间的桥梁奠定了初步基础，首次提出了基于混沌量子动力学的QPUF构造，并探讨了其实现的可能性。

Abstract: Quantum Physical Unclonable Functions (QPUFs) are hardware-based
cryptographic primitives with strong theoretical security. This security stems
from their modeling as Haar-random unitaries. However, implementing such
unitaries on Intermediate-Scale Quantum devices is challenging due to
exponential simulation complexity. Previous work tackled this using
pseudo-random unitary designs but only under limited adversarial models with
only black-box query access. In this paper, we propose a new QPUF construction
based on chaotic quantum dynamics. We modeled the QPUF as a unitary time
evolution under a chaotic Hamiltonian and proved that this approach offers
security comparable to Haar-random unitaries. Intuitively, we show that while
chaotic dynamics generate less randomness than ideal Haar unitaries, the
randomness is still sufficient to make the QPUF unclonable in polynomial time.
We identified the Sachdev-Ye-Kitaev (SYK) model as a candidate for the QPUF
Hamiltonian. Recent experiments using nuclear spins and cold atoms have shown
progress toward achieving this goal. Inspired by recent experimental advances,
we present a schematic architecture for realizing our proposed QPUF device
based on optical Kagome Lattice with disorder. For adversaries with only query
access, we also introduce an efficiently simulable pseudo-chaotic QPUF. Our
results lay the preliminary groundwork for bridging the gap between theoretical
security and the practical implementation of QPUFs for the first time.

</details>


### [752] [Neural Network Solution of Non-Markovian Quantum State Diffusion and Operator Construction of Quantum Stochastic Process](https://arxiv.org/abs/2509.01049)
*Jiaji Zhang,Carlos L. Benavides-Riveros,Lipeng Chen*

Main category: quant-ph

TL;DR: 一种基于机器学习的算子构建算法，用于模拟开放量子系统，能够从量子轨迹集合中重建随机时间演化算子，具有更广泛的应用和可解释性。


<details>
  <summary>Details</summary>
Motivation: 开发一种新颖的机器学习方法来模拟开放量子系统，特别是在非马尔可夫量子态扩散的背景下，超越传统仅逼近波函数或期望值的方法。

Method: 采用基于算子构建的机器学习方法，使用神经网络作为通用生成器，从量子轨迹集合中重建随机时间演化算子。

Result: 在各种谱密度下，使用自旋-玻色子模型对该算法进行了基准测试，证明了其准确性，并展示了该算子在计算吸收光谱和重建更长时间尺度的约化密度矩阵方面的效用。

Conclusion: 该研究结果为机器学习在量子动力学中的应用开辟了新途径，特别是通过一种新的算子构建方法来实现。

Abstract: Non-Markovian quantum state diffusion provides a wavefunction-based framework
for modeling open quantum systems. In this work, we introduce a novel machine
learning approach based on an operator construction algorithm. This algorithm
employs a neural network as a universal generator to reconstruct the stochastic
time evolution operator from an ensemble of quantum trajectories. Unlike
conventional machine learning methods that merely approximate time-dependent
wavefunctions or expectation values, our operator-based approach yields broader
applications and enhanced interpretability of the stochastic process. We
benchmark the algorithm on the spin-boson model across diverse spectral
densities, demonstrating its accuracy. Furthermore, we showcase the operator's
utility in calculating absorption spectra and reconstructing reduced density
matrices at extended timescales. These results establish a new paradigm for the
application of machine learning in quantum dynamics.

</details>


### [753] [Quantum Seniority-based Subspace Expansion: Linear Combinations of Short-Circuit Unitary Transformations for Efficient Quantum Measurements](https://arxiv.org/abs/2509.01061)
*Smik Patel,Praveen Jayakumar,Tao Zeng,Artur F. Izmaylov*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum SENiority-based Subspace Expansion (Q-SENSE) is a hybrid
quantum-classical algorithm that interpolates between the Variational Quantum
Eigensolver (VQE) and Configuration Interaction (CI) methods. It constructs
Hamiltonian matrix elements on a quantum device and solves the resulting
eigenvalue problem classically. This seniority-symmetry-based approach reduces
one of the primary limitations of VQE on near-term quantum hardware - circuit
depth - by exchanging lower circuit complexity for the need to compute
additional matrix elements. Unlike other expansion-based methods - such as
Quantum Subspace Expansion (QSE), Quantum Krylov Subspace Expansion, and the
Non-orthogonal Quantum Eigensolver - Q-SENSE leverages symmetry-induced
orthogonality to construct basis states in distinct symmetry sectors. This not
only guarantees orthogonality but also reduces the number of Hamiltonian terms
that must be measured, as many terms are zero between different symmetry
subspaces. By systematically combining symmetry principles with matrix-based
techniques, Q-SENSE offers a scalable and resource-efficient potential route to
quantum advantage on near-term quantum devices and in the early fault-tolerant
regime.

</details>


### [754] [High-efficiency Weak-trace-free Counterfactual Communication via Quantum Zeno Effect](https://arxiv.org/abs/2509.01074)
*Tianyi Xing,Anqi Huang,Yizhi Wang,Chao Wu,Yaxuan Wang,Pingyu Zhu,Jiangfang Ding,Dongyang Wang,Yingwen Liu,Xiaogang Qiang,Sheng Ma,Ping Xu,Junjie Wu*

Main category: quant-ph

TL;DR: This paper demonstrates high-efficiency counterfactual quantum communication using the quantum Zeno effect on a photonic chip, reducing transmission time and bit errors for transmitting information like a logo.


<details>
  <summary>Details</summary>
Motivation: The quantum Zeno effect enhances interaction-free measurement (IFM) efficiency, enabling high-efficiency counterfactual quantum communication, which transmits information without particle transmission. However, previous methods suffered from long transmission times and bit errors.

Method: The researchers experimentally demonstrated high-efficiency weak-trace-free counterfactual communication on a quantum photonic chip by applying the quantum Zeno effect.

Result: The experiment achieved a transmission probability of 74.2 ± 1.6% for bit 0 and 85.1 ± 1.3% for bit 1. They successfully transmitted the logo 'Quanta' with zero bit errors after processing, reducing transmission time from minutes to seconds per bit.

Conclusion: The study presents a promising approach for secure and efficient communication using integrated silicon quantum photonics, showcasing the benefits of the quantum Zeno effect in counterfactual communication.

Abstract: The quantum Zeno effect, which inhibits quantum state evolution via repeated
weak measurements, significantly enhances the efficiency of interaction-free
measurement (IFM). This fundamental mechanism facilitates high-efficiency
counterfactual quantum communication, enabling information delivery without
particle transmission through the channel. However, the transmission time of
the counterfactual communication requires minutes for bit and suffers the bit
error when transmitting an image. Applying the quantum Zeno effect, we
experimentally demonstrate high-efficiency weak-trace-free counterfactual
communication on a quantum photonic chip, achieving a transmission probability
of $74.2 \pm 1.6\%$ for bit 0 and $85.1 \pm 1.3\%$ for bit 1. Furthermore, we
successfully transmit our group's logo --Quanta-- through counterfactual
communication, and reduce the time cost from minutes to seconds for bit, with
zero bit errors after information processing. Our study provides a promising
approach for secure and efficient communication using integrated silicon
quantum photonics.

</details>


### [755] [Cutting stabiliser decompositions of magic state cultivation with ZX-calculus](https://arxiv.org/abs/2509.01224)
*Kwok Ho Wan,Zhenghao Zhong*

Main category: quant-ph

TL;DR: 应用切割稳定器分解技术到魔态培养产生的量子态，结果表明d=3和d=5的魔态培养电路产生的状态可以分别表示为4和8个Clifford ZX-图的总和。


<details>
  <summary>Details</summary>
Motivation: 将切割稳定器分解技术应用于魔态培养产生的量子态，以探索其结构和表示。

Method: 应用切割稳定器分解技术到从魔态培养产生的量子态（后选择所有+1测量值）。

Result: d=3和d=5的魔态培养电路产生的状态可以分别表示为4和8个Clifford ZX-图的总和。

Conclusion: 修改现有的ZX-演算稳定器分解方法可能有助于在量子纠错的背景下更好地模拟包含适量T门的非Clifford电路。

Abstract: We apply the cutting stabiliser decomposition techniques [arXiv:2403.10964]
to the quantum states generated from magic state cultivation
[arXiv:2409.17595], post-selected upon all $+1$ measured values for simplicity.
The resultant states to the $d=3$ and $d=5$ variant magic state cultivation
circuits can be expressed as a sum of $4$ and $8$ Clifford ZX-digrams
respectively. Modifications to existing ZX-calculus stabiliser decomposition
methods may enable better simulation of non-Clifford circuits containing a
moderate number of $T$ gates in the context of quantum error correction.

</details>


### [756] [Efficient Maximum Clique Detection via Grover's Algorithm with Real-time Global Size Tracking](https://arxiv.org/abs/2509.01261)
*Wenmin Han,Shiqi Zheng,Peian Chen,Yukun Wang*

Main category: quant-ph

TL;DR: 本文提出一种改进的量子算法来解决最大团问题（MCP），通过结合图论先验知识（如图论的Turan定理和完全图性质）和量子搜索优化，实现了比现有方法更高的效率。


<details>
  <summary>Details</summary>
Motivation: 最大团问题（MCP）是图论中的一个重要NP-Hard问题，在生物信息学、社交网络、数据挖掘等领域有广泛应用。现有方法效率不高，需要改进。

Method: 本文提出一种改进的量子算法，该算法利用图论的先验知识（Turan定理和完全图性质）通过量子电路预检测将这些约束编码到全局变量中，并动态跟踪最大团的大小。该算法进一步与Grover搜索协同工作，利用辅助量子比特编码方案动态跟踪搜索过程中的团大小，从而无需进行迭代测量。

Result: 该算法实现了$O
$-重改进，仅需$O
$\left(
\sqrt{2^n}
\right)\n$次Grover迭代和$O(1)$次测量即可解决MCP，而现有基于Grover的算法需要$O
(n
\sqrt{2^n})
$次迭代和$O(n)$次测量。

Conclusion: 本文提出的算法通过结合图论先验知识和量子搜索优化，在解决最大团问题方面取得了显著的效率提升，并且通过在IBM Qiskit平台上的模拟验证了其正确性，为解决NP-Hard问题提供了一种新的量子算法思路。

Abstract: The maximum clique problem (MCP) is to find the largest complete subgraph in
an undirected graph, that is, the subgraph in which there are edges between
every two different vertices. It is an NP-Hard problem with wide applications,
including bioinformatics, social networks, data mining, and other fields. This
paper proposes an improved algorithm that dynamically tracks the maximum clique
size by encoding prior constraints on the vertex count-derived from Tur\'an's
theorem and complete graph properties-into global variables through quantum
circuit pre-detection. The algorithm further synergizes with Grover's search to
optimize the solution space. Our auxiliary-qubit encoding scheme dynamically
tracks clique sizes during quantum search, eliminating iterative measurements,
achieving MCP solution with $O\left(\sqrt{2^n}\right)$ Grover iterations and
$O(1)$ measurements. This represents an $\boldsymbol{n}$-fold improvement over
state-of-the-art Grover-based methods, which require $O(n\sqrt{2^n})$
iterations and $O(n)$ measurements for $n$-vertex graphs. We validate
algorithmic correctness through simulations on IBM's Qiskit platform and
benchmark qubit/gate efficiency against existing Grover-based MCP solvers.

</details>


### [757] [Duality of extremal quantum states in verification and data hiding](https://arxiv.org/abs/2509.01281)
*Seiseki Akibue,Yuki Takeuchi*

Main category: quant-ph

TL;DR: 本文研究了量子态验证（QSV）和量子数据隐藏（QDH）之间的关系，发现两者在特定条件下存在对偶性。


<details>
  <summary>Details</summary>
Motivation: QSV和QDH是两个独立研究的领域，QSV用于判断量子态是否接近理想态，QDH是一种将经典信息隐藏在多粒子量子态中的密码学协议。本文旨在探索这两个领域在纯态和混合态下的基本量之间的联系。

Method: 本文通过分析纯量子态的两个基本量，证明了QSV中最难验证的纯态与QDH中最安全的纯态是同一类状态，并且对于这些极端状态，两个基本量是相等的。进一步地，将这种关系推广到混合态的QDH安全性和量子子空间验证（QSV的推广）的样本复杂度之间。

Result: 研究发现，在纯量子态的两种基本量（决定QSV样本复杂度的量和QDH安全性的量）之间存在对偶性：一个纯态越难验证，其在QDH中就越安全。对于这些极端状态，这两个量是相等的。此外，这种关系也被推广到了混合态。

Conclusion: 本文揭示了QSV和QDH之间深层次的内在联系，展示了QSV和QDH的对偶性，并为设计更有效的QSV协议和理解QDH的根本限制提供了理论基础。

Abstract: Quantum state verification (QSV) and quantum data hiding (QDH) have so far
been studied separately. QSV decides whether a given quantum state is close to
the ideal one, with significantly lower sample complexity compared with direct
application of quantum tomography. On the other hand, QDH is a cryptographic
protocol that encodes secret classical information in multipartite quantum
states, providing stronger security guarantees than conventional classical
secret-sharing schemes. Here, we consider two fundamental quantities of a pure
quantum state, determining the sample complexity needed for QSV or the security
level in QDH. We demonstrate that a pure state is most difficult to verify in
QSV if and only if it is most secure in QDH with respect to those quantities.
Furthermore, for such extremal states, the two fundamental quantities coincide.
We also generalize this relationship to one between the security of QDH using
mixed states and the sample complexity for quantum subspace verification, which
is a generalization of QSV. As an application, we show the existence of
efficient QSV protocols that are generalizations of the existing ones and
examine the fundamental limitations on QDH by synthesizing research from both
domains.

</details>


### [758] [Counterfactual Local Friendliness: An epsilon-Bounded Interaction-Free Paradox and a Disturbance-Robust Three-Box Inequality](https://arxiv.org/abs/2509.01290)
*Maximilian Ralph Peter von Liechtenstein*

Main category: quant-ph

TL;DR: 量子力学引入了一个新的悖论——反事实局部友善性（CLF），它是一种维格纳的朋友类型的逻辑冲突。在该悖论中，所有决定性的推理都通过无相互作用的标志获得，其对被探测对象的影响受可调参数ε的限制。在满足（Q）外部观察者的普遍单一性、（S）单结果事实、（C）跨主体一致性、（IF-ε）朋友内部模块的ε-反事实性条件下，量子理论预测了一个非零的后选择事件，该事件迫使关于单个上游变量的相互不兼容的确定性，而无需诉诸吸收性或投射性实验室内测量。此外，我们还推导了一个ε-IF三箱非上下文界限：任何满足排他性和ε-稳定性的单世界、非上下文模型必须遵守 P(A) + P(B) ≤ 1 + Kε，而量子理论的 P(A) = P(B) = 1 违反了该界限，即使ε非常小。这些结果共同揭示了反事实现象的悖论之处：并非能量交换与被探测系统，而是单世界叙述中主体级别事实的不兼容性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在引入并分析一种新的量子力学悖论——反事实局部友善性（Counterfactual Local Friendliness, CLF），并探讨其与现有量子理论的矛盾之处，特别是关于测量和观察者在量子现象中的作用。

Method: 本文通过引入“反事实局部友善性”（CLF）悖论，这是一种维格纳朋友类型的逻辑冲突。该悖论的特点是：1. 推理过程依赖于“无相互作用的标志”（interaction-free flags），其对被探测对象的影响由参数 ε 控制。2. 引入了四个条件：（Q）普遍单一性、（S）单结果事实、（C）跨主体一致性、（IF-ε）ε-反事实性。3. 推导了一个“ε-IF三箱非上下文界限”，并展示了量子理论的预测（P(A) = P(B) = 1）如何违反此界限（P(A) + P(B) ≤ 1 + Kε），即使 ε 非常小。

Result: 量子理论在满足特定条件（Q, S, C, IF-ε）下，预测了一个非零的后选择事件，该事件导致了对同一上游变量的相互矛盾的确定性。此外，量子理论的预测（P(A) = P(B) = 1）违反了推导出的ε-IF三箱非上下文界限（P(A) + P(B) ≤ 1 + Kε），即使对于任意小的ε也是如此。

Conclusion: 本文的核心结论是，反事实现象的悖论根源不在于与被探测系统的能量交换，而在于在单世界叙述中，不同主体（代理人）所获得的事实之间存在着根本的不兼容性。CLF悖论揭示了在量子力学框架下，即使在非常温和的条件下，也可能出现逻辑上的冲突，挑战了我们对现实和因果关系的直观理解。

Abstract: We introduce a new paradox, which we call Counterfactual Local Friendliness
(CLF): a Wigner's-friend-type logical collision in which every decisive
inference is obtained by interaction-free flags whose disturbance on the probed
object is bounded by a tunable parameter $\epsilon$. Under (Q) universal
unitarity for outside observers, (S) single-outcome facts, (C) cross-agent
consistency, and (IF-$\epsilon$) $\epsilon$-counterfactuality of the friends'
internal modules, quantum theory predicts a nonzero post-selected event that
forces mutually incompatible certainties about a single upstream variable --
without appealing to absorptive or projective in-lab measurements.
  We also derive an $\epsilon$-IF three-box noncontextual bound: any
single-world, noncontextual model satisfying exclusivity and epsilon-stability
must obey $P(A) + P(B) \le 1 + K_\epsilon$, while quantum theory yields $P(A) =
P(B) = 1$, violating the bound for arbitrarily small $\epsilon$. Together these
results isolate what is paradoxical about counterfactual phenomena: not energy
exchange with the probed system, but the incompatibility of agent-level facts
in single-world narratives.

</details>


### [759] [Heisenberg limited quantum algorithm for estimating the fidelity susceptibility](https://arxiv.org/abs/2509.01359)
*Yukun Zhang,Xiao Yuan*

Main category: quant-ph

TL;DR: 该研究提出了一种高效的量子算法，利用分辨率重构和量子奇异值变换来估计保真度易感性，实现了最优精度，并对无挫哈密顿量提供了二次加速。


<details>
  <summary>Details</summary>
Motivation: 保真度易感性是探测量子相变的重要工具，但经典计算受限于希尔伯特空间增长和临界点附近的相关性发散，限制了其在大型系统上的应用。

Method: 提出了一种新的量子算法，通过分辨率重构利用量子奇异值变换进行伪逆块编码，并结合幅度估计进行范数评估，实现了保真度易感性的高效估计。

Result: 该算法实现了保真度易感性的高效估计，精度达到海森堡极限，并且对于无挫哈密顿量，其分辨率可以被近似，从而获得二次加速。这是首个具有最优精度标度保真度易感性的量子算法。

Conclusion: 该工作将量子多体物理与算法设计相结合，为在容错量子平台上利用材料模拟、计量学等应用，对量子临界性进行可扩展探索提供了新的途径。

Abstract: The fidelity susceptibility serves as a universal probe for quantum phase
transitions, offering an order-parameter-free metric that captures ground-state
sensitivity to Hamiltonian perturbations and exhibits critical scaling.
Classical computation of this quantity, however, is limited by exponential
Hilbert space growth and correlation divergence near criticality, restricting
analyses to small or specialized systems. Here, we present a quantum algorithm
that achieves efficient and Heisenberg-limited estimation of fidelity
susceptibility through a novel resolvent reformulation, leveraging quantum
singular value transformation for pseudoinverse block encoding with amplitude
estimation for norm evaluation. This constitutes the first quantum algorithm
for fidelity susceptibility with optimal precision scaling. Moreover, for
frustration-free Hamiltonians, we show that the resolvent can be approximated
with a further quadratic speedup. Our work bridges quantum many-body physics
and algorithmic design, enabling scalable exploration of quantum criticality
with applications in materials simulation, metrology, and beyond on
fault-tolerant quantum platforms.

</details>


### [760] [Exploring Quantum Machine Learning for Weather Forecasting](https://arxiv.org/abs/2509.01422)
*Maria Heloísa F. da Silva,Gleydson F. de Jesus,Christiano M. S. Nascimento,Valéria L. da Silva,Clebson Cruz*

Main category: quant-ph

TL;DR: 量子计算在天气预报中展现出优于传统方法的潜力，特别是在风速预测方面。


<details>
  <summary>Details</summary>
Motivation: 由于大气动力学和混沌行为的挑战，以及量子计算在处理这些复杂性方面的潜力，本研究旨在探索量子机器学习（QML）与气候预报的交叉点。

Method: 本研究实施了一个量子神经网络（QNN），并使用NASA POWER数据库的真实气象数据进行训练，并与经典循环神经网络（RNN）进行了比较。

Result: QNN在准确性和对数据变化（尤其是风速）的适应性方面显示出优于RNN的潜力。QNN在处理时间变异性和温度预测的快速收敛性方面表现出稳健性，尽管存在非线性和架构敏感性。

Conclusion: 量子模型在短期和中期气候预测方面具有巨大潜力，但仍需克服挑战并进行优化以实现更广泛的应用。

Abstract: Weather forecasting plays a crucial role in supporting strategic decisions
across various sectors, including agriculture, renewable energy production, and
disaster management. However, the inherently dynamic and chaotic behavior of
the atmosphere presents significant challenges to conventional predictive
models. On the other hand, introducing quantum computing simulation techniques
to the forecasting problems constitutes a promising alternative to overcome
these challenges. In this context, this work explores the emerging intersection
between quantum machine learning (QML) and climate forecasting. We present the
implementation of a Quantum Neural Network (QNN) trained on real meteorological
data from NASA's Prediction of Worldwide Energy Resources (POWER) database. The
results show that QNN has the potential to outperform a classical Recurrent
Neural Network (RNN) in terms of accuracy and adaptability to abrupt data
shifts, particularly in wind speed prediction. Despite observed nonlinearities
and architectural sensitivities, the QNN demonstrated robustness in handling
temporal variability and faster convergence in temperature prediction. These
findings highlight the potential of quantum models in short and medium term
climate prediction, while also revealing key challenges and future directions
for optimization and broader applicability.

</details>


### [761] [Effect of Single-Ion Anisotropy on Stability of Quantum and Thermal Entanglement in a Mixed-Spin Heisenberg Trimer](https://arxiv.org/abs/2509.01451)
*Hana Vargová,Jozef Strečka*

Main category: quant-ph

TL;DR: 单轴单离子各向异性影响混合自旋三聚体（1,1/2,1）的海森堡三聚体的量子纠缠，特别是负熵，并研究了外部磁场和不同类型的单离子各向异性对其的影响。


<details>
  <summary>Details</summary>
Motivation: 研究单轴单离子各向异性对混合自旋三聚体量子纠缠（特别是负熵）的影响，以及外部磁场和不同类型的单离子各向异性如何改变纠缠度、稳定区域和相图。

Method: 利用负熵量化量子纠缠，分析了单自旋实体与剩余自旋二聚体之间的二分负熵，以及三聚体在外部磁场和易轴/易平面的单离子各向异性影响下的全局三方负熵（gTN）。

Result: 单离子各向异性显著影响纠缠度，改变了能量最优基态的稳定性区域，并在相图中引入了额外的相。在特定基态下，纠缠度主要取决于单离子各向异性的强度，并改变了相应特征向量的概率幅。此外，讨论了纠缠的热稳定性，包括在有限温度下出现异常局部最小值。

Conclusion: 单轴单离子各向异性是影响量子三聚体系统纠缠的关键因素，其对基态性质和纠缠度的调制作用为理解和设计多金属分子化合物（如Ni$^{2+}$-Cu$^{2+}$-Ni$^{2+}$）中的量子纠缠提供了理论指导。

Abstract: The effect of uniaxial single-ion anisotropy on quantum entanglement is
rigorously quantified using negativity in a mixed spin-($1$,$1/2$,$1$)
Heisenberg trimer, accounting for different exchange coupling constants between
identical and distinct spins. Bipartite negativities between the single-spin
entity and the remaining spin dimer are analyzed alongside the global
tripartite negativity (gTN) of the whole trimer under the effect of an external
magnetic field and both easy-axis and easy-plane types of single-ion
anisotropy. Interestingly, the single-ion anisotropy significantly influences
the degree of entanglement by altering the stability regions of energetically
preferred ground states and it may also introduce additional phases in the
overall ground-state phase diagram. Moreover, it is demonstrated that within
specific ground states, the degree of entanglement primarily depends on the
strength of single-ion anisotropy, altering the respective probability
amplitudes of the corresponding eigenvectors. Finally, the thermal stability of
entanglement is discussed in detail, including the emergence of a peculiar
local minimum at finite temperatures. The obtained theoretical results may
offer deeper insights into bipartite and tripartite entanglement in trimetallic
Ni$^{2+}$-Cu$^{2+}$-Ni$^{2+}$ molecular compounds.

</details>


### [762] [Optically detected nuclear magnetic resonance of coherent spins in a molecular complex](https://arxiv.org/abs/2509.01467)
*Evgenij Vasilenko,Vishnu Unni Chorakkunnath,Jeremias Resch,Nicholas Jobbitt,Diana Serrano,Philippe Goldner,Senthil Kumar Kuppusamy,Mario Ruben,David Hunger*

Main category: quant-ph

TL;DR: 通过超窄光学跃迁的光学初始化和检测分子核自旋，在基于铕的分子晶体中实现了高达2毫秒的核自旋量子相干性，为低场核磁共振和量子技术提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 实现分子核自旋的光学初始化和检测，以提高低磁场下的核磁共振信号、实现单分子水平的灵敏度，并为量子技术提供原子级精确的分子结构。

Method: 利用超窄光学跃迁实现分子核自旋的光学初始化和检测。通过射频驱动解决了两个核四极共振，并利用拉比振荡、自旋回波和动力学解耦技术实现了核自旋量子相干性。

Result: 在基于铕的分子晶体中，通过光学手段成功实现了核自旋的初始化和检测，观察到了与光学跃迁相关的核四极共振，并实现了长达2毫秒的核自旋量子相干性。

Conclusion: 光学检测的核磁共振（ODNMR）能力得到了证明，分子核自旋在量子信息处理方面具有巨大潜力。

Abstract: Nuclear magnetic resonance (NMR) is a powerful tool for applications ranging
from chemical analysis to quantum information processing. Achieving optical
initialization and detection of molecular nuclear spins promises new
opportunities - including improved NMR signals at low magnetic field,
sensitivity down to the single-molecule level, and full access to atomically
precise molecular architectures for quantum technologies. In this study, we
report optical readout of coherently controlled nuclear spins in a
europium-based molecular crystal. By harnessing ultra-narrow optical
transitions, we achieve optical initialization and detection of nuclear spin
states. Through radio-frequency driving, we address two nuclear quadrupole
resonances, characterized by narrow inhomogeneous linewidths and a distinct
correlation with the optical transition frequency. We implement Rabi
oscillations, spin echo and dynamical decoupling techniques, achieving nuclear
spin quantum coherence with a lifetime of up to 2 ms. These results highlight
the capabilities of optically detected NMR (ODNMR) and underscore the potential
of molecular nuclear spins for quantum information processing.

</details>


### [763] [Extending the dynamic range in quantum frequency estimation with sequential weak measurements](https://arxiv.org/abs/2509.01474)
*Su Direkci,Manuel Endres,Tuvia Gefen*

Main category: quant-ph

TL;DR: 该研究提出了一种利用弱测量和辅助量子比特来扩展动态范围和克服原子钟相位漂移噪声的新方法，最终实现了无噪声精度极限，并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 量子计量学旨在优化参数估计的量子协议。在光学原子钟中，传统协议虽关注最优输入态和测量以提高灵敏度，但常受限于局域振荡器退相干引起的相位漂移误差。

Method: 本研究探讨了通过辅助量子比特的弱测量来扩展动态范围和克服相位漂移噪声的方案。研究人员利用相干自旋态，找到了最优弱测量协议，确定了任意给定的询问时间和原子数量的最佳测量强度。随后，结合弱测量和投影测量，构建了一个能够渐近饱和无噪声精度极限且优于现有相位漂移噪声抑制方法的协议。

Result: 通过相干自旋态，我们找到了最优弱测量协议，确定了任意给定的询问时间和原子数量的最佳测量强度。结合弱测量和投影测量，我们构建的协议渐近饱和了无噪声精度极限，并且在抑制相位漂移噪声方面优于先前提出的方法。

Conclusion: 本研究提出的结合弱测量和投影测量的方案，能有效扩展动态范围并克服相位漂移噪声，实现了优于现有方法的精度，为提高原子钟性能提供了新的途径。

Abstract: Quantum metrology explores optimal quantum protocols for parameter
estimation. In the context of optical atomic clocks, conventional protocols
focus on optimal input states and measurements to achieve enhanced
sensitivities. However, such protocols are typically limited by phase slip
errors inflicted due to the decoherence of the local oscillator. Here, we study
schemes to extend the dynamic range and overcome phase slip noise through weak
measurements with ancilla qubits. Using coherent spin states, we find optimal
weak measurements protocols: we identify optimal measurement strength for any
given interrogation time and number of atoms. Then, we combine weak and
projective measurements to construct a protocol that asymptotically saturates
the noiseless precision limits, and outperforms previously proposed methods for
phase slip noise suppression.

</details>


### [764] [Superstrong Dynamics and Chiral Emission of a Giant Atom in a Structured Bath](https://arxiv.org/abs/2509.01579)
*Vincent Jouanny,Léo Peyruchat,Marco Scigliuzzo,Alberto Mercurio,Enrico Di Benedetto,Daniele De Bernardis,Davide Sbroggiò,Simone Frasca,Vincenzo Savona,Francesco Ciccarello,Pasquale Scarlino*

Main category: quant-ph

TL;DR: Giant atom coupled to a structured photonic environment shows non-Markovian dynamics and enables chiral photon emission.


<details>
  <summary>Details</summary>
Motivation: To explore quantum dynamics and implement non-trivial non-Markovian quantum models using engineered photonic environments, specifically a high-impedance coupled cavity array (CCA) with a transmon qubit.

Method: A transmon qubit was coupled non-locally to a CCA, creating a 'giant atom' in a structured photonic environment. The coupling selectively enhanced interaction with specific modes, leading to superstrong coupling. Measurements of atomic participation ratio and time-domain qubit dynamics were performed. The study also involved breaking inversion symmetry to seed dressed eigenmodes for chiral photon emission.

Result: Non-local coupling enhanced interaction with specific CCA modes, leading to superstrong coupling in some cases. Qubit dynamics deviated from the single-mode Jaynes--Cummings model, showing mode-mode interactions. Chiral photon emission was successfully implemented and characterized by seeding dressed eigenmodes.

Conclusion: The research demonstrates precise control over multimode light-matter interaction in a structured photonic environment, paving the way for advanced quantum models and applications like chiral photon emission.

Abstract: Quantum emitters coupled to waveguides with nonlinear dispersion show rich
quantum dynamics with the promise of implementing non-trivial non-Markovian
quantum models. Recent advances in engineered photonic environments now allow
the realization of discrete-site waveguides with tailored dispersion, yet most
implementations of waveguide QED remain limited to a local qubit-waveguide
coupling. Here, we study a transmon qubit non-locally coupled to a
high-impedance coupled cavity array (CCA), thus implementing a \emph{giant
atom} in a structured photonic environment. The non-local coupling produces
interference with the CCA eigenmodes, selectively enhancing interaction with
long-wavelength (low-effective $k$), symmetric modes about the array center,
while suppressing coupling to antisymmetric and short-wavelength modes. For a
subset of symmetric, low-effective $k$ modes, we reach the superstrong coupling
regime. In this regime, measurements of the atomic participation ratio reveal
strongly hybridized eigenmodes on a par with a strongly reduced qubit
participation at the frequency of maximum hybridization with the qubit, in
agreement with theory. Time-domain measurements of the qubit dynamics show
clear deviations from the single-mode Jaynes--Cummings model, marked by the
emergence of mode--mode interactions. By breaking inversion symmetry, the qubit
seeds dressed eigenmodes confined to either the right or left of the qubit,
which we exploit to implement and characterize a chiral photon-emission
protocol. These results demonstrate precise control over multimode
light--matter interaction in a structured photonic environment.

</details>


### [765] [Enhanced measurements on quantum computers via the simultaneous probing of non-commuting Pauli operators](https://arxiv.org/abs/2509.01482)
*Rick P. A. Simon,Zheng Shi,Charlie Nation,Andrew Jena,Luca Dellantonio*

Main category: quant-ph

TL;DR: 提出了一种新方案，通过联合测量量子态的多个相同副本，可以同时评估所有泡利算符，并使用贝叶斯统计和自适应采样来提高测量效率和精度，在存在多个非对易泡利算符的情况下，该方案优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 量子计算机状态测量是一个复杂的问题，对量子算法有广泛影响。

Method: 提出了一种新方案，联合测量量子态的相同副本，以同时评估所有泡利算符。使用贝叶斯统计进行精确估计，并开发了一种自适应采样算法来优化测量。

Result: 与最先进的测量方案相比，在需要测量多个非对易泡利算符的情况下，该方案在给定精度下可显着减少所需的总测量次数。

Conclusion: 所提出的测量方案通过联合测量和自适应采样提高了量子状态测量的效率和精度，尤其是在处理复杂量子系统时。

Abstract: Measuring the state of quantum computers is a highly non-trivial task, with
implications for virtually all quantum algorithms. We propose a novel scheme
where identical copies of a quantum state are measured jointly so that all
Pauli operators within the considered observable can be simultaneously
assessed. We use Bayesian statistics to accurately estimate the average and
error, and develop an adaptive shot-allocation algorithm that preferentially
samples the most uncertain Pauli terms. In regimes with many non-commuting
Pauli operators, our ``double'' scheme can outperform the state-of-the-art
measurement protocol in minimizing total shots for a given precision.

</details>


### [766] [The Zeno-like effect in a spin-chain quantum battery](https://arxiv.org/abs/2509.01603)
*Maulana M. Fajar,Beta N. Pratiwi,Subur Pramono,Gagus K. Sunnardianto,Ahmad R. T. Nugraha*

Main category: quant-ph

TL;DR: 量子电池在精心设计的环境下，环境噪声可以通过类似


<details>
  <summary>Details</summary>
Motivation: 量子电池，作为利用相干性和其他量子效应的能量或状态存储设备，对环境噪声敏感。

Method: 研究了系统大小为 N=6 的模型，分析了三种局部噪声通道：比特翻转、相位翻转和比特相位翻转。通过改变噪声强度来模拟量子齐纳效应，并观察其对充电动力学和存储能量的影响。

Result: 相位翻转通道在强噪声下减慢了充电速度，但稳定了存储的能量和功。

Conclusion: 量子噪声可以增强和稳定量子电池的操作。

Abstract: Quantum batteries, which can be seen as energy- or state-storage devices
exploiting coherence and other quantum effects, are sensitive to environmental
noise. Here we show that, when suitably engineered, environmental noise can
induce a "Zeno-like" stabilization of the charging process in a spin-chain
quantum battery. To explore this interplay, we study a system size N=6, which
provides large storage capacity with moderate computational cost, and more
importantly, allows the stored energy to become almost fully extractable since
the ergotropy nearly coincides with the total capacity. We analyze three local
noise channels: bit flip, phase flip, and bit phase flip. We vary the strength
of each channel to emulate frequent environmental monitoring, reminiscent of
the quantum Zeno effect, and track its influence on the charging dynamics and
stored energy. The phase-flip channel slows charging under strong noise but
stabilizes stored energy and ergotropy. The bit-flip channel enables faster
charging but saturates at low capacities, while the bit phase flip channel
combines both features. In the discharging stage, different noise channels lead
to distinct release dynamics, showing that noise can paradoxically enhance and
stabilize quantum battery operation.

</details>


### [767] [Higher-Order Portfolio Optimization with Quantum Approximate Optimization Algorithm](https://arxiv.org/abs/2509.01496)
*Valter Uotila,Julia Ripatti,Bo Zhao*

Main category: quant-ph

TL;DR: 该研究提出了首个包含高阶矩（偏度、峰度）的投资组合优化量子模型，将成本哈密顿量从二次形式转变为高阶无约束二元优化（HUBO）问题，并采用整数变量编码和基于资本的预算约束。实验结果表明，该量子模型在100个投资组合优化问题中，解决方案通常优于经典的整数规划基线，为在量子硬件上进行具有挑战性的投资组合优化提供了前景。


<details>
  <summary>Details</summary>
Motivation: 将包含偏度（skewness）和峰度（kurtosis）等高阶矩的投资组合优化问题扩展到量子计算领域，以实现更详细的投资组合回报分布建模，并解决经典方法在高阶矩量子表述上的局限性。

Method: 将包含高阶矩的投资组合优化问题转化为高阶无约束二元优化（HUBO）问题，并设计相应的参数化量子线路。同时，采用整数变量编码和基于资本的预算约束，并与基于整数规划的离散化经典连续变量解进行比较。

Result: 在100个投资组合优化问题上的实验评估显示，HUBO量子模型得到的投资组合分配方案通常优于经典的整数规划基线。

Conclusion: 该研究提出的高阶矩投资组合优化量子模型（HUBO）在实践中具有潜力，能够为经典计算带来挑战的投资组合优化问题提供更好的解决方案，并为QAOA在包含高阶矩的实际问题中的性能研究提供了依据。

Abstract: Portfolio optimization is one of the most studied optimization problems at
the intersection of quantum computing and finance. In this work, we develop the
first quantum formulation for a portfolio optimization problem with
higher-order moments, skewness and kurtosis. Including higher-order moments
leads to more detailed modeling of portfolio return distributions. Portfolio
optimization with higher-order moments has been studied in classical portfolio
optimization approaches but with limited exploration within quantum
formulations. In the context of quantum optimization, higher-order moments
generate higher-order terms in the cost Hamiltonian. Thus, instead of obtaining
a quadratic unconstrained binary optimization problem, we obtain a higher-order
unconstrained binary optimization (HUBO) problem, which has a natural
formulation as a parametrized circuit. Additionally, we employ realistic
integer variable encoding and a capital-based budget constraint. We consider
the classical continuous variable solution with integer programming-based
discretization to be the computationally efficient classical baseline for the
problem. Our extensive experimental evaluation of 100 portfolio optimization
problems shows that the solutions to the HUBO formulation often correspond to
better portfolio allocations than the classical baseline. This is a promising
result for those who want to perform computationally challenging portfolio
optimization on quantum hardware, as portfolio optimization with higher moments
is classically complex. Moreover, the experimental evaluation studies QAOA's
performance with higher-order terms in this practically relevant problem.

</details>


### [768] [Quantum Tomography of Suspended Carbon Nanotubes](https://arxiv.org/abs/2509.01858)
*Jialiang Chang,Nicholas Pietrzak,Cristian Staii*

Main category: quant-ph

TL;DR: 该论文提出了一种全机械方法，用于对悬浮碳纳米管（CNT）的固有弯曲模式进行相干控制和量子态重建。


<details>
  <summary>Details</summary>
Motivation: 目标是实现对悬浮碳纳米管的固有弯曲模式的相干控制和量子态重建，同时避免光学加热和消除片上微波驱动线。

Method: 使用附近的原子力显微镜（AFM）探针产生的校准脉冲，实现机械π/2旋转（用于拉姆齐干涉测量）和相位空间位移（用于Wigner函数断层扫描）。论文还推导了控制脉冲序列和主方程描述，用于将测量信号映射到能量弛豫、相位相干时间和基于奇偶校验的量子特征。

Result: 该方法统一了控制和断层扫描，避免了光学加热，并消除了片上微波驱动线。测得的信号可以映射到能量弛豫和相位相干时间，以及包括Wigner函数负区域在内的基于奇偶校验的量子特征。

Conclusion: 该方法为机械量子控制和介观机械系统退相干的态分辨表征提供了一条实用的途径，并且与多种读出模式兼容。

Abstract: We present an all-mechanical protocol for coherent control and full
quantum-state reconstruction of the fundamental flexural mode of a suspended
carbon nanotube (CNT). Calibrated impulses from a nearby atomic force
microscope (AFM) tip serve a dual role: they implement mechanical pi/2
rotations for Ramsey interferometry and realize phase-space displacements for
Wigner function tomography via displaced-parity sampling. The same actuator
thus unifies control and tomography while avoiding optical heating and
eliminating on-chip microwave drive lines at the resonator. We derive explicit
control pulse sequences and a master-equation description that map measured
signals onto the energy-relaxation and phase-coherence times, as well as onto
parity-based quantum signatures, including negative regions of the Wigner
function. The approach is compatible with multiple readout modalities: direct
AFM deflection, dispersive coupling to a Cooper-pair box, and dispersive
microwave cavity probing. Together, these techniques provide complete access to
populations, coherence, and parity within a single device architecture. This
minimal scheme provides a practical route to all-mechanical quantum control and
state-resolved characterization of decoherence in mesoscopic mechanical
systems.

</details>


### [769] [Theory for the spectral splitting exponent of exceptional points](https://arxiv.org/abs/2509.02174)
*Shu-Xuan Wang,Zhongbo Yan*

Main category: quant-ph

TL;DR: Exceptional points (EPs) in non-Hermitian systems enhance response to perturbations, making them suitable for sensing. This paper develops a theory to predict the spectral splitting exponent of EPs based on the matrix positions of perturbations, offering a design principle for EP-based sensors.


<details>
  <summary>Details</summary>
Motivation: Exceptional points (EPs) in non-Hermitian systems show enhanced response to perturbations, making them promising for sensing applications. However, predicting the spectral splitting of EPs analytically becomes difficult for higher-order EPs, hindering the design of EP-based sensors.

Method: The paper develops a theory to predict the spectral splitting exponent of EPs by analyzing the Jordan block structure of the unperturbed Hamiltonian and the matrix positions of the perturbation. This allows for analytical determination of the exponent under specific conditions.

Result: The developed theory successfully predicts the spectral splitting exponent of EPs based on perturbation matrix positions, providing an analytical framework that bypasses the intractability of solving characteristic equations for large N.

Conclusion: This work provides a theoretical framework and design principle for engineering perturbations to achieve desired spectral responses in EP-based sensors, facilitating the development of highly sensitive sensors.

Abstract: Exceptional points (EPs), singularities in non-Hermitian systems where
eigenvalues and eigenstates coalesce, exhibit a dramatically enhanced response
to perturbations compared to Hermitian degeneracies. This makes them
exceptional candidates for sensing applications. The spectral splitting of an
$N$th-order EP scales with perturbation strength $\epsilon$ over a wide range,
from $\epsilon$ to $\epsilon^{1/N}$. Although the exact scaling exponent can be
determined in principle by solving the characteristic equation, this approach
becomes analytically intractable for large $N$ and often fails to yield useful
physical insight. In this work, we develop a theory to directly predict the
scaling exponent from the matrix positions of the perturbation. By using the
Jordan block structure of the unperturbed Hamiltonian, we show that the
splitting exponent can be analytically determined when the matrix positions of
the perturbation satisfy some specific conditions. Our analytical framework
provides a useful design principle for engineering perturbations to achieve a
desired spectral response, facilitating the development of EP-based sensors.

</details>


### [770] [The entropic coherence is a necessary resource for non-energy preserving gates](https://arxiv.org/abs/2509.01515)
*Riccardo Castellano,Vasco Cavina,Marti Perarnau-Llobet,Vittorio Giovannetti,Pavel Sekatski*

Main category: quant-ph

TL;DR: 本文研究了如何在有限维系统S上通过与外部电池B的能量守恒相互作用来实现非能量守恒门(NEPG)。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究实现非能量守恒门(NEPG)的资源需求，特别是与外部电池的相互作用。

Method: 通过与外部电池B的能量守恒相互作用，在有限维系统S上实现非能量守恒门(NEPG)。证明了电池的熵相干性是实现该任务的必要资源，并找到了实现特定精度NEPG所需的最小熵相干性下界。

Result: 发现电池的熵相干性是实现NEPG的必要资源，并给出了最小熵相干性的下界。任何有限维电池在实现门操作时都有最小误差。在对电池哈密顿量的能量级密度进行假设后，得到了实现任何门所需的最小能量和量子Fisher信息的下界，且这些下界可能强于先前文献中建立的通用界限。

Conclusion: 电池的熵相干性是实现NEPG的必要资源，且存在最小消耗。有限维电池在实现门操作时存在固有的最小误差。文中的下界可能比之前的研究更强。

Abstract: We consider the task of implementing non-energy preserving gates (NEPG) on a
finite-dimensional system S via an energy-preserving interaction with an
external battery B. We prove that the entropic coherence of the battery (an
instance of the relative entropy of resource) is a necessary resource for this
task, and find a lower bound on its minimum amount that has to be present in
the battery to be able to implement NEPGs with a fixed desired precision. An
immediate corollary is that any finite-dimensional battery is doomed to a
certain minimal error in the gate implementation task. Moreover, under
assumptions on the density of energy levels in the battery Hamiltonian, our
main results imply additional lower bounds on the minimal amount of energy and
quantum Fisher information required to implement any gate. We show that these
bounds can be stronger than the universal bounds previously established in the
literature.

</details>


### [771] [Approaching transform-limited linewidths in telecom-wavelength transitions of ungated quantum dots](https://arxiv.org/abs/2509.02320)
*Andrew N. Wakileh,Dan Dalacu,Philip J. Poole,Boris Lamontagne,Simona Moisa,Robin L. Williams,Nir Rotenberg*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Highly coherent quantum emitters operating in the telecommunication C-band
(1530 - 1565nm), where ultra-low-loss fibers and photonic circuits are
available, are crucial to the development of scalable quantum technologies. In
this work, we report on a modified Stranski-Krastanov growth scheme using
chemical beam epitaxy to enable the generation of high-quality InAs/InP quantum
dots, characterized by near-transform-limited linewidths
($\Gamma_{\mathrm{TL}}$). We demonstrate the growth of highly-symmetric quantum
dots with aspect ratios >0.8 and densities ranging from 2 to 22$\,\mu$m$^{-2}$.
Optical characterization of these sources reveal fine-structure splittings down
to $25\pm4\,\mu$eV and a single-photon purity of $g^{(2)}(0) =
0.012\pm\mathrm{0.007}$, confirming the quality of these dots. Further, using
an etalon to measure the linewidth, in combination with rigorous modelling, we
find an upper-bound to the mean, low-power linewidths of only $12.1\pm
6.7\,\Gamma_\mathrm{TL}$ and, in the best case, $2.8\pm
1.8\,\Gamma_\mathrm{TL}$. These results represent a significant step in the
development of telecom-wavelength quantum light sources which are essential for
complex quantum networks and devices.

</details>


### [772] [Measuring Less to Learn More: Quadratic Speedup in learning Nonlinear Properties of Quantum Density Matrices](https://arxiv.org/abs/2509.01571)
*Yukun Zhang,Yusen Wu,You Zhou,Xiao Yuan*

Main category: quant-ph

TL;DR: 量子信息科学中的一个基本任务是测量量子态的非线性函数，例如Tr(ρ^k O)。研究人员证明了在样本访问下，计算k阶量通常需要k个状态副本，并建立了Ω(k)的下界。然而，通过酉变换制备ρ的纯化副本可以克服这一限制，这种情况在量子模拟和计算中很自然地出现。在这种情况下，研究人员发现了一个不同的下界Ω(√k)，并提出了一个实现该下限的量子算法，展示了相对于基于样本的方法具有二次优势。该算法的关键技术创新在于其精心设计的量子算法和最优多项式逼近理论，特别是针对幂函数边界行为定制的切比雪夫多项式逼近。这些结果揭示了量子态样本访问和纯化访问之间的基本区别，对估计量子熵、量子Fisher信息、实现量子虚拟蒸馏和冷却以及评估其他具有经典影子的多个非线性量子可观测量具有广泛意义。


<details>
  <summary>Details</summary>
Motivation: 量子信息科学中的一个基本任务是测量量子态的非线性函数，例如$ho^k O$的迹。研究人员旨在探索计算这些非线性函数所需的资源，特别关注访问模式（样本访问与纯化访问）如何影响效率。

Method: 研究人员首先建立了在样本访问下计算$ho^k O$的迹的$	ilde{\Omega}(k)$下界。然后，他们提出了一个量子算法，该算法在纯化访问（通过酉变换制备$ho$的纯化副本）下实现了$	ilde{O}(\sqrt{k})$的界限。该算法利用了专门设计的量子算法和切比雪夫多项式逼近理论，特别关注幂函数在边界行为下的逼近。

Result: 研究结果表明，对于测量量子态的非线性函数，纯化访问相比样本访问具有二次优势。具体来说，在样本访问下，需要$O(k)$个状态副本，而在纯化访问下，只需要$O(\sqrt{k})$个操作（或副本）。

Conclusion: 研究揭示了量子态样本访问和纯化访问之间的根本区别。纯化访问在计算非线性函数方面提供了二次加速，这对于量子信息科学中的各种应用（如估计量子熵、量子Fisher信息、量子虚拟蒸馏和冷却）具有重要意义。所提出的算法和理论分析为理解和利用量子资源提供了新的见解。

Abstract: A fundamental task in quantum information science is to measure nonlinear
functionals of quantum states, such as $\mathrm{Tr}(\rho^k O)$. Intuitively,
one expects that computing a $k$-th order quantity generally requires $O(k)$
copies of the state $\rho$, and we rigorously establish this lower bound under
sample access to $\rho$. Surprisingly, this limitation can be overcome when one
has purified access via a unitary that prepares a purification of $\rho$, a
scenario naturally arising in quantum simulation and computation. In this
setting, we find a different lower bound of $\Theta(\sqrt{k})$, and present a
quantum algorithm that achieves this bound, demonstrating a quadratic advantage
over sample-based methods. The key technical innovation lies in a designed
quantum algorithm and optimal polynomial approximation theory -- specifically,
Chebyshev polynomial approximations tailored to the boundary behavior of power
functions. Our results unveil a fundamental distinction between sample and
purified access to quantum states, with broad implications for estimating
quantum entropies and quantum Fisher information, realizing quantum virtual
distillation and cooling, and evaluating other multiple nonlinear quantum
observables with classical shadows.

</details>


### [773] [A Spin-Based Pathway to Testing the Quantum Nature of Gravity](https://arxiv.org/abs/2509.01586)
*Sougato Bose,Anupam Mazumdar,Roger Penrose,Ivette Fuentes,Marko Toroš,Ron Folman,Gerard J. Milburn,Myungshik Kim,Adrian Kent,A. T. M. Anishur Rahman,Cyril Laplane,Aaron Markowitz,Debarshi Das,Ethan Campos-Méndez,Eva Kilian,David Groswasser,Menachem Givon,Or Dobkowski,Peter Skakunenko,Maria Muretova,Yonathan Japha,Naor Levi,Omer Feldman,Damián Pitalúa-García,Jonathan M. H. Gosling,Ka-Di Zhu,Marco Genovese,Kia Romero-Hojjati,Ryan J. Marshman,Markus Rademacher,Martine Schut,Melanie Bautista-Cruz,Qian Xiang,Stuart M. Graham,James E. March,William J. Fairbairn,Karishma S. Gokani,Joseph Aziz,Richard Howl,Run Zhou,Ryan Rizaldy,Thiago Guerreiro,Tian Zhou,Jason Twamley,Chiara Marletto,Vlatko Vedral,Jonathan Oppenheim,Mauro Paternostro,Hendrik Ulbricht,Peter F. Barker,Thomas P. Purdy,M. V. Gurudev Dutt,Andrew A. Geraci,David C. Moore,Gavin W. Morley*

Main category: quant-ph

TL;DR: 本论文提出一个实验来检验引力的量子性质，通过检查引力是否能将两个微米级晶体纠缠起来。此方法通过嵌入自旋和斯特恩-格拉赫力产生宏观量子叠加态，然后测量自旋来验证由引力产生的纠缠。


<details>
  <summary>Details</summary>
Motivation: 目前的物理学面临一个关键的未解决问题，即如何将由广义相对论描述的引力与由量子力学描述的其他一切结合起来。这表明广义相对论和量子力学都需要根本性的修正。大多数物理学家期望引力本质上是量子的，但它与其他力的不同之处在于它是由时空几何描述的。需要实验来检验引力以及时空是量子化的还是经典的。

Method: 我们提出一个实验来测试引力的量子性质，方法是检查引力是否能将两个微米级的晶体纠缠起来。实现这一目标的途径是首先使用嵌入式自旋和斯特恩-格拉赫力为每个晶体创建宏观量子叠加态。这些晶体可以是含有氮-空位（NV）中心的纳米金刚石。随后可以测量自旋来验证引力产生的纠缠。

Result: 该实验方法基于广泛的理论可行性研究和量子技术的实验进展。最终的实验将需要一个中等规模的联盟，能够极好地抑制包括振动和引力噪声在内的退相干效应。

Conclusion: 该白皮书回顾了实现这一目标的进展和计划。在实施这些计划的过程中，我们将进一步探索可能的宏观叠加态，这将检验那些预测其存在极限的理论。

Abstract: A key open problem in physics is the correct way to combine gravity
(described by general relativity) with everything else (described by quantum
mechanics). This problem suggests that general relativity and possibly also
quantum mechanics need fundamental corrections. Most physicists expect that
gravity should be quantum in character, but gravity is fundamentally different
to the other forces because it alone is described by spacetime geometry.
Experiments are needed to test whether gravity, and hence space-time, is
quantum or classical. We propose an experiment to test the quantum nature of
gravity by checking whether gravity can entangle two micron-sized crystals. A
pathway to this is to create macroscopic quantum superpositions of each crystal
first using embedded spins and Stern-Gerlach forces. These crystals could be
nanodiamonds containing nitrogen-vacancy (NV) centres. The spins can
subsequently be measured to witness the gravitationally generated entanglement.
This is based on extensive theoretical feasibility studies and experimental
progress in quantum technology. The eventual experiment will require a
medium-sized consortium with excellent suppression of decoherence including
vibrations and gravitational noise. In this white paper, we review the progress
and plans towards realizing this. While implementing these plans, we will
further explore the most macroscopic superpositions that are possible, which
will test theories that predict a limit to this.

</details>


### [774] [Sampling Continuous Quantum Dynamics from a Single Static State](https://arxiv.org/abs/2509.01633)
*Sebastian Gemsheim,Felix Fritzsch*

Main category: quant-ph

TL;DR: 通过引入辅助时钟量子比特并调整其动力学和与原始系统的相互作用，提出了一种在连续时间内模拟任意时间依赖哈密顿量下量子动力学的方法，该方法将全部动力学编码在单个静态量子态中，以克服有限相干时间造成的模拟时间限制。


<details>
  <summary>Details</summary>
Motivation: 为了克服由有限相干时间引起的量子模拟中可访问模拟时间的限制。

Method: 提出了一种将完整动力学编码在单个静态量子态中的方法，通过引入辅助时钟量子比特并调整其动力学和与原始系统的相互作用来实现。该方法不需要传统的短时传播器或其近似值。

Result: 提供了一个关于驱动量子比特的示例来演示该方法。

Conclusion: 所提出的方法通过将完整动力学编码在单个静态量子态中，为克服量子模拟中的相干时间限制提供了一种有前景的途径。

Abstract: While quantum simulation is one of the most promising applications of modern
quantum devices, accessible simulation times are fundamentally limited by
finite coherence times due to omnipresent noise. Based on the ideas of
relational dynamics/time and of exchanging time for space resources, we propose
an approach to simulating quantum dynamics under general time-dependent
Hamiltonians in continuous time, which aims to overcome this limitation by
encoding the full dynamics in a single static quantum state. This is achieved
by introducing auxiliary qubits, which play the role of a clock, and by
tailoring their dynamics and interaction with the original system. As opposed
to traditional methods, no short-time propagators, or approximations thereof,
are required in our framework. We outline the preparation of a static global
state of system and clock via a variational quantum-classical algorithm as well
as the sampling of the system's dynamics by performing projective measurements
on the clock. Finally, we provide an example of our approach in terms of a
driven qubit.

</details>


### [775] [Phase-Sensitive Measurements on a Fermi-Hubbard Quantum Processor](https://arxiv.org/abs/2509.01637)
*Alberto R. Cavallar,Luis Escalera-Moreno,Titus Franz,Timon Hilker,J. Ignacio Cirac,Philipp M. Preiss,Benjamin F. Schiffer*

Main category: quant-ph

TL;DR: 研究使用费米子量子处理器测量洛希密特回声


<details>
  <summary>Details</summary>
Motivation: 研究费米子量子处理器模拟多体系统的潜力，特别是测量时间演化算符的复期望值（洛希密特回声）。

Method: 提出一种硬件高效协议，利用全局淬灭动力学和短虚时间演化（通过特定脉冲序列实现），从块状乘积态开始。

Result: 数值结果表明，该方法能够高效地获得大体多体态的复洛希密特回声，覆盖较宽的光谱范围。

Conclusion: 该方法可用于测量费米-哈伯德模型的谱性质（如局域态密度），并为研究当前费米子量子模拟器中的有限温度性质提供了途径。

Abstract: Fermionic quantum processors are a promising platform for quantum simulation
of correlated fermionic matter. In this work, we study a hardware-efficient
protocol for measuring complex expectation values of the time-evolution
operator, commonly referred to as Loschmidt echoes, with fermions in an optical
superlattice. We analyze the algorithm for the Fermi-Hubbard model at
half-filling as well as at finite doping. The method relies on global quench
dynamics and short imaginary time evolution, the latter being realized by
architecture-tailored pulse sequences starting from a product state of
plaquettes. Our numerical results show that complex Loschmidt echoes can be
efficiently obtained for large many-body states over a broad spectral range.
This allows one to measure spectral properties of the Fermi-Hubbard model, such
as the local density of states, and paves the way for the study of
finite-temperature properties in current fermionic quantum simulators.

</details>


### [776] [Quantum Frequency Conversion of Single Photons from a Tin-Vacancy Center in Diamond](https://arxiv.org/abs/2509.01661)
*Julia M. Brevoord,Jan Fabian Geus,Tim Turan,Miguel Guerrero Romero,Daniel Bedialauneta Rodríguez,Nina Codreanu,Alexander M. Stramma,Ronald Hanson,Florian Elsen,Bernd Jungbluth*

Main category: quant-ph

TL;DR: 将金刚石中snv色心发出的619nm光子高效转换为1480nm电信波段，以解决其在量子网络中的波长不匹配问题，实验实现了48%的内转换效率和28%的外转换效率，同时噪声水平低，并验证了转换后的snv光子串具有snv寿命特性，为构建基于snv的金刚石量子网络奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 金刚石中的锡空位（SnV）色心是构建量子网络节点的有希望的候选者，但其本地光发射波长（619 nm）与低损耗电信波长（通常为1310 nm或1550 nm）不兼容，这限制了其在大都会规模网络中的应用。

Method: 通过将619nm光子与1064nm泵浦光耦合到一个包含单晶钛砷酸钾（KTA）晶体的腔体中，实现了量子频率转换（QFC）。该腔体经过主动稳定以提高转换效率和降低噪声。

Result: 实现了48%（±3%）的内转换效率和28%（±2%）的外转换效率，噪声光子率低（2.2±0.9 cts/s/pm），并且转换效率在70 GHz的频率范围内保持了最大值的80%以上。此外，通过激发波导嵌入式SnV色心并进行QFC，成功将SnV光子串转换为电信波段，并观察到了其寿命特性。

Conclusion: 该研究成功实现了金刚石SnV色心619nm光子到1480nm电信波段的高效、低噪声量子频率转换，并验证了转换后的光子具有SnV色心的特性。这是迈向量子网络应用的关键一步。

Abstract: Diamond tin-vacancy (SnV) centers are promising candidates for building
quantum network nodes. However, their native photon emission at 619 nm is
incompatible with metropolitan-scale networks operating at low-loss telecom
wavelengths. To address this, we demonstrate highly efficient, low-noise
quantum frequency conversion (QFC) of 619 nm photons to the telecom S-band at
1480 nm. The conversion process combines 619 nm photons with 1064 nm pump light
in an actively stabilized cavity containing a bulk monocrystalline potassium
titanyl arsenate (KTA) crystal. We achieve an internal (external) conversion
efficiency of (48 +/- 3)% ((28 +/- 2)%) and a noise photon rate per wavelength
of 2.2 +/- 0.9 cts/s/pm, which is spectrally flat in the investigated frequency
range of 40 GHz. Furthermore, we demonstrate that the efficiency remains above
80% of its maximum over a frequency range of 70 GHz. Finally, we generate a
string of photons from a single waveguide-embedded SnV center using a train of
excitation pulses and send these through the QFC. After the QFC, we observe a
string of telecom photons displaying the SnV lifetime, confirming successful
conversion. These results represent a critical step towards metropolitan-scale
fiber-based quantum networks using SnV centers.

</details>


### [777] [Sensing electric fields through Rydberg atom networks](https://arxiv.org/abs/2509.01665)
*Philip Kitson,Wayne J. Chetcuti,Gerhard Birkl,Luigi Amico,Juan Polo*

Main category: quant-ph

TL;DR: 基于里德堡原子网络，利用里德堡阻断对电场的依赖性（尤其是在福斯特共振附近）来测量电场，通过阻断半径的变化来量化电场强度。


<details>
  <summary>Details</summary>
Motivation: 介绍一种基于里德堡原子网络的新型量子传感器，用于测量电场。

Method: 通过跟踪不同空间结构和电场配置的里德堡激发动力学，研究里德堡阻断与电场的关系，并利用密度-密度关联函数分析空间变化的电场。

Result: 研究了里德堡激发动力学与电场的关系，并展示了密度-密度关联函数可用于分析和量化不均匀电场。

Conclusion: 所提出的基于里德堡原子网络的量子传感器能够有效地测量电场，并且该方法可以扩展到分析不均匀电场。

Abstract: We present the operating principle of a quantum sensor for electric fields
based on networks of Rydberg atoms. The sensing mechanism exploits the
dependence of the Rydberg blockade on the electric field, particularly in the
vicinity of the F\"{o}rster resonance - the electric field can be measured
through the variation in the size of the blockade radius across the network of
Rydberg atoms. Specifically, we track the dynamics of Rydberg excitations in
systems of various spatial structures, subjected to different electric field
configurations, to monitor the connection between the field and blockade. We
also use the density-density correlator to analyse spatially varying
(inhomogeneous) electric fields and relate these correlators to the applied
fields.

</details>


### [778] [Superradiant Syntheses via the V-type Three-Level Atoms](https://arxiv.org/abs/2509.01700)
*Gombojav O. Ariunbold,Tuguldur Begzjav*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum state engineering operating with photons is a key enabler of major
scientific breakthroughs and future quantum technologies. Its primary obstacle,
however, is decoherence often caused by spontaneous emission, which is
inherently difficult to control. In contrast, superradiance offers a more
controllable alternative. The temporal dynamics of superradiance can be tuned
via external experimental parameters, unlike those of spontaneous emission.
Incorporating superradiance into quantum state engineering could therefore
provide more accessible control over quantum systems. Motivated by this, we
present a theoretical model for an ensemble of atoms in a V - type three -
level configuration. Our numerical data are analyzed against key superradiance
characteristics. The system successively emits a pair of superradiance pulses,
effectively synthesizing the dynamically decoupled sub - ensembles into a
single macroscopic ensemble involving all atoms. To our knowledge, this
process, which we term superradiant synthesis, is demonstrated here for the
first time. These findings offer new insights for practical quantum state
engineering, particularly in enabling syntheses of macroscopic quantum
sub-systems.

</details>


### [779] [Photon emission without quantum jumps](https://arxiv.org/abs/2509.01702)
*Thomas Hartwell,Daniel Hodgson,Huda Alshemmari,Gin Jose,Almut Beige*

Main category: quant-ph

TL;DR: 该论文提出了一种不基于量子跃迁就能描述自由辐射场中发射子的动力学的方法，该方法使用基于局部厄米哈密顿量的薛定谔方程，并且与量子光学主方程一致。


<details>
  <summary>Details</summary>
Motivation: 量子光学系统，特别是那些依赖于远场干涉效应的应用（如分布式量子计算和量子传感），其发射子的动力学不能简单地用随机量子跃迁来模拟。

Method: 使用基于局部厄米哈密顿量的薛定谔方程来描述发射子的动力学，而无需引入量子跃迁的概念。

Result: 证明了所提出的方法与量子光学主方程是一致的，并且能够有效地模拟量子光学系统。

Conclusion: 可以不依赖量子跃迁的概念，通过使用薛定谔方程和局部厄米哈密顿量来描述发射子的自由场动力学，并且此方法与现有的量子光学主方程兼容。

Abstract: When modelling photon emission, we often assume that emitters experience
random quantum jumps. When a quantum jump occurs the emitter transitions
suddenly into a lower energy level, while spontaneously generating a single
photon. However, this point of view is misleading when modelling, for example,
quantum optical systems which rely on far-field interference effects for
applications like distributed quantum computing and quantum sensing. In this
paper, we show that the dynamics of an emitter in the free radiation field can
be described without imposing quantum jumps by instead using a Schroedinger
equation based on a locally-acting Hermitian Hamiltonian. Our approach is
nevertheless consistent with quantum optical master equations.

</details>


### [780] [Quantum Machine Learning for UAV Swarm Intrusion Detection](https://arxiv.org/abs/2509.01812)
*Kuan-Cheng Chen,Samuel Yen-Chi Chen,Tai-Yue Li,Chen-Yu Liu,Kin K. Leung*

Main category: quant-ph

TL;DR: 该论文研究了无人机群入侵检测问题，并对比了三种量子机器学习（QML）方法（量子核、变分量子神经网络、混合量子训练神经网络）与经典基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 无人机群的入侵检测由于高移动性、非平稳流量和严重的类别不平衡而变得复杂。

Method: 在包含五种攻击类型的120k流模拟语料库上，对量子核、变分量子神经网络（QNNs）和混合量子训练神经网络（QT-NNs）三种QML方法进行了基准测试，并与强大的经典基线进行了比较。所有模型均采用8个特征的流表示，并在相同的预处理、平衡和噪声模型假设下进行评估。分析了编码策略、电路深度、量子比特数量和采样噪声的影响，并报告了准确率、宏F1、ROC-AUC、Matthews相关系数和量子资源占用情况。

Result: 研究结果表明，量子核和QT-NNs在低数据量、非线性环境下表现出色，而较深的QNNs存在可训练性问题，卷积神经网络（CNNs）在数据量充足的情况下表现最优。公开了完整的代码库和数据集划分，以支持网络安全领域可复现的QML研究。

Conclusion: 在无人机群入侵检测任务中，不同的量子机器学习模型和经典模型在不同数据量和复杂度的情况下各有优劣。

Abstract: Intrusion detection in unmanned-aerial-vehicle (UAV) swarms is complicated by
high mobility, non-stationary traffic, and severe class imbalance. Leveraging a
120 k-flow simulation corpus that covers five attack types, we benchmark three
quantum-machine-learning (QML) approaches - quantum kernels, variational
quantum neural networks (QNNs), and hybrid quantum-trained neural networks
(QT-NNs) - against strong classical baselines. All models consume an 8-feature
flow representation and are evaluated under identical preprocessing, balancing,
and noise-model assumptions. We analyse the influence of encoding strategy,
circuit depth, qubit count, and shot noise, reporting accuracy, macro-F1,
ROC-AUC, Matthews correlation, and quantum-resource footprints. Results reveal
clear trade-offs: quantum kernels and QT-NNs excel in low-data, nonlinear
regimes, while deeper QNNs suffer from trainability issues, and CNNs dominate
when abundant data offset their larger parameter count. The complete codebase
and dataset partitions are publicly released to enable reproducible QML
research in network security.

</details>


### [781] [QUBO-based training for VQAs on Quantum Annealers](https://arxiv.org/abs/2509.01821)
*Ernesto Acosta,Guillermo Botella,Carlos Cano*

Main category: quant-ph

TL;DR: 本论文提出一种将变分量子算法（VQA）的参数优化问题重构为二次无约束二元优化（QUBO）问题的新方法，利用量子退火器求解，并采用自适应元启发式优化策略，实验证明该方法能有效降低计算开销并获得高质量解，为近中期量子计算中的混合模型提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: 为解决大规模组合优化问题，特别是在变分量子算法（VQA）训练中遇到的梯度下降法难以处理的挑战（如 barren plateaus 和梯度估计噪声），提出一种新的优化方法。

Method: 将VQA参数优化转化为QUBO问题，利用量子退火器求解，并采用自适应元启发式优化策略，该策略可配置参数并递归地改进解决方案。

Result: 实验表明，该方法相比经典和进化优化器能显著降低计算开销，同时获得相当或更优的解的质量，证明了其可行性。

Conclusion: 量子退火器可作为VQA训练的可扩展替代方案，特别适用于存在 barren plateaus 和梯度噪声问题的场景，并为近中期量子计算中的混合量子门-量子退火-经典优化模型开辟了新的途径。

Abstract: Quantum annealers provide an effective framework for solving large-scale
combinatorial optimization problems. This work presents a novel methodology for
training Variational Quantum Algorithms (VQAs) by reformulating the parameter
optimization task as a Quadratic Unconstrained Binary Optimization (QUBO)
problem. Unlike traditional gradient-based methods, our approach directly
leverages the Hamiltonian of the chosen VQA ansatz and employs an adaptive,
metaheuristic optimization scheme. This optimization strategy provides a rich
set of configurable parameters which enables the adaptation to specific problem
characteristics and available computational resources. The proposed framework
is generalizable to arbitrary Hamiltonians and integrates a recursive
refinement strategy to progressively approximate high-quality solutions.
  Experimental evaluations demonstrate the feasibility of the method and its
ability to significantly reduce computational overhead compared to classical
and evolutionary optimizers, while achieving comparable or superior solution
quality. These findings suggest that quantum annealers can serve as a scalable
alternative to classical optimizers for VQA training, particularly in scenarios
affected by barren plateaus and noisy gradient estimates, and open new
possibilities for hybrid quantum gate - quantum annealing - classical
optimization models in near-term quantum computing.

</details>


### [782] [The curious case of "XOR repetition" of monogamy-of-entanglement games](https://arxiv.org/abs/2509.01831)
*Andrea Coladangelo,Qipeng Liu,Ziyi Xie*

Main category: quant-ph

TL;DR: 本文研究了量子纠缠博弈的变种，特别是“决策”变种。与原始的“搜索”变种不同，该变种关注的是猜中裁判输出的特定比特异或或特定比特值，而非整个输出比特串。研究结果表明，在“异或重复”变种中，最优获胜概率不随参数n的增加而衰减，而是保持在一个恒定的值（约为0.85）。而在“Goldreich-Levin”变种中，在限制性条件下（对手不共享纠缠），最优优势随n指数衰减，并提出了一个更广泛的猜想。


<details>
  <summary>Details</summary>
Motivation: 本文旨在研究“纠缠悖论”博弈的“决策”变种，并与原始的“搜索”变种进行比较，探究在不同目标下（猜测输出比特的异或或特定比特值）最优获胜概率的行为。

Method: 本文主要采用理论分析方法，通过设计策略来评估在不同变种博弈中的获胜概率。具体来说，针对“异或重复”变种，提出了一个不随n衰减的策略；针对“Goldreich-Levin”变种，在限制条件下证明了优势的指数衰减，并提出了一个关于一般条件下优势衰减的猜想。

Result: 在“异或重复”变种中，发现最优获胜概率不随n衰减，恒定为cos^2(π/8)。在“Goldreich-Levin”变种中，对于不共享纠缠的对手，最优优势随n指数衰减，并提出了一个关于一般对手的猜想。

Conclusion: 本文揭示了“纠缠悖论”博弈“决策”变种在获胜概率方面的有趣特性。特别是“异或重复”变种的获胜概率不衰减的发现，与之前的猜想相反，表明在某些情况下，即使目标简化，量子博弈的复杂性依然存在。而“Goldreich-Levin”变种的指数衰减结果则与预期一致，并为进一步研究提供了一个新的猜想。

Abstract: In this work, we consider "decision" variants of a monogamy-of-entanglement
game by Tomamichel, Fehr, Kaniewski, and Wehner [New Journal of Physics '13].
In its original "search" variant, Alice prepares a (possibly entangled) state
on registers $\mathsf{ABC}$; register $\mathsf{A}$, consisting of $n$ qubits,
is sent to a Referee, while $\mathsf{B}$ and $\mathsf{C}$ are sent to Bob and
Charlie; the Referee then measures each qubit in the standard or Hadamard basis
(chosen uniformly at random). The basis choices are sent to Bob and Charlie,
whose goal is to simultaneously guess the Referee's $n$-bit outcome string $x$.
Tomamichel et al. show that the optimal winning probability is $\cos^{2n}
{(\frac{\pi}{8})}$, following a perfect parallel repetition theorem. We
consider the following "decision" variants of this game:
  - Variant 1, "XOR repetition": Bob and Charlie's goal is to guess the XOR of
all the bits of $x$. Ananth et al. [Asiacrypt '24] conjectured that the optimal
advantage over random guessing decays exponentially in $n$. Surprisingly, we
show that this conjecture is false, and, in fact, there is no decay at all:
there exists a strategy that wins with probability $\cos^2{(\frac{\pi}{8})}
\approx 0.85$ for any $n$.
  - Variant 2, "Goldreich-Levin": The Referee additionally samples a uniformly
random $n$-bit string $r$ that is sent to Bob and Charlie along with the basis
choices. Their goal is to guess the parity of $r\cdot x$. We show that the
optimal advantage over random guessing decays exponentially in $n$ for the
restricted class of adversaries that do not share entanglement. A similar
result was already shown by Champion et al. and \c{C}akan et al.; we give a
more direct proof. Additionally, we put forward a reasonably concrete
conjecture that is equivalent to exponential decay for general adversaries.

</details>


### [783] [Symmetric Localizable Multipartite Quantum Measurements from Pauli Orbits](https://arxiv.org/abs/2509.01851)
*Jef Pauwels,Cyril Branciard,Alejandro Pozas-Kerstjens,Nicolas Gisin*

Main category: quant-ph

TL;DR: 该工作提出了一种构造高对称性、局部可编码的单态向量轨道测量基的方法，并将其推广到多体和高维情况，分析了其纠缠成本和局部可实现性。


<details>
  <summary>Details</summary>
Motivation: 多体和高维纠缠测量的表征仍不完善，需要新的方法来构造和分析。

Method: 通过 Pauli 子群的张量积作用的单态向量轨道来构造对称的、局部可编码的单范测量基。利用 Clifford 谱系分析实现这些测量的纠缠成本，并据此进行分类。

Result: 该方法可以恢复 Elegant Joint Measurement 作为特例，并推广到更多系统和更高维度。对称性使得能够表征局部可实现性，并识别出可高效局部实现的测量基。提供了一个系统性的工具集。

Conclusion: 该方法为设计具有丰富对称性和可实现性的纠缠测量提供了系统性的工具。

Abstract: While the structure of entangled quantum states is relatively well
understood, the characterization of entangled measurements, especially in
multipartite and high-dimensional settings, remains far less developed. In this
work, we introduce a general approach to construct highly symmetric, locally
encodable orthonormal measurement bases, as orbits of a single fiducial state
under tensor-product actions of Pauli subgroups. This framework recovers the
Elegant Joint Measurement-a two-qubit measurement whose local marginals form a
regular tetrahedron on the Bloch sphere-as a special case, and we extend the
construction to both more systems and higher dimensions. We analyze the
entanglement cost required to implement these measurements locally via the
Clifford hierarchy and use this criterion to classify them. We show how the
symmetry of our constructions allows us to characterize their localizability,
which is generally a challenging problem, and to identify certain classes of
measurement bases that are efficiently localizable. Our approach offers a
systematic toolkit for designing entangled measurements with rich symmetry and
implementability properties.

</details>


### [784] [The Multiqubit Elegant Joint Measurement](https://arxiv.org/abs/2509.01852)
*Jef Pauwels,Nicolas Gisin*

Main category: quant-ph

TL;DR: The paper generalizes the Elegant Joint Measurement (EJM) to multiple qubits, preserving its tetrahedral symmetry and local structure, and revealing a discrete set of entanglement classes for three or more qubits.


<details>
  <summary>Details</summary>
Motivation: Generalizing the EJM, a significant two-qubit entangled measurement, to the multipartite setting was an unresolved problem crucial for understanding multipartite entanglement and nonclassical correlations in quantum networks.

Method: The authors identified all tetrahedrally symmetric, efficiently localizable multiqubit bases. They verified that for two qubits, these criteria uniquely select the EJM, and for three or more qubits, they yield a discrete set of equivalence classes.

Result: The study successfully extended the EJM to the multipartite setting. For n>=3 qubits, a discrete set of equivalence classes of such measurements was found, indicating a richer entanglement structure compared to the two-qubit case.

Conclusion: The paper successfully generalized the EJM to multiple qubits, providing a discrete set of solutions for n>=3 qubits that preserve the desired symmetry and localizability properties, thus deepening the understanding of multipartite entanglement.

Abstract: The Elegant Joint Measurement (EJM) is a highly symmetric, partially
entangled two-qubit measurement whose local marginals form a regular
tetrahedron on the Bloch sphere and which has a low entanglement cost for local
implementation. It plays a central role in quantum networks exhibiting
nonclassical correlations and serves as a paradigmatic example of an entangled
measurement with local structure. Despite its significance, generalizing the
EJM beyond two qubits has remained unresolved. Here, we extend the EJM to the
multipartite setting by identifying all tetrahedrally symmetric, efficiently
localizable multiqubit bases. For two qubits, these criteria uniquely select
the EJM. For three or more, they yield a discrete set of equivalence classes,
reflecting the richer structure of multiparticle entanglement.

</details>


### [785] [Exponentially Enhanced Tripartite Coupling in Quantum Nonlinear Magnonics](https://arxiv.org/abs/2509.01884)
*Xue-Chun Chen,Zi-Jie Wang,Sheng-Bo Zheng,Jiaojiao Chen,Wei Xiong*

Main category: quant-ph

TL;DR: 该工作提出了一种包含NV色心和两个YIG球中的Kerr磁振子的混合系统，实现了有效的三角相互作用，并指数级增强了相互作用和协同度。


<details>
  <summary>Details</summary>
Motivation: 实现强且可控的三角相互作用，这在量子信息和非线性量子光学中至关重要但难以实现。

Method: 通过绝热消除NV色心（qutrit）的基态，在色散区实现了NV色心（编码在激发态中的qubit）和磁振子之间的有效三角相互作用。在强驱动下，Kerr磁振子可以通过简并参数放大实现压缩，从而指数级增强了三角相互作用和协同度。

Result: 实现了指数级的三角相互作用和协同度增强（约exp(ξ)倍），加速了系统动力学，可以快速生成三角纠缠。此外，系统还能实现噪声鲁健的完美磁振子阻塞，该结果得到了解析方法和量子主方程数值模拟的验证。

Conclusion: 该研究表明，NV色心是工程化量子磁子学中多体相互作用的有前景的接口，为探索纠缠和关联等基本量子现象提供了一个多功能的平台。

Abstract: Strong and controllable tripartite interactions play a pivotal role in
quantum information and nonlinear quantum optics, yet challenging to realize.
In this work, we propose a hybrid system consisting of a nitrogen-vacancy (NV)
center coupled to Kerr magnons (magnons with Kerr nonlinearity) in two
yttrium-iron-garnet spheres. By adiabatically eliminating the ground state of
the NV qutrit in the dispersive regime, an effective tripartite interaction
among magnons and an NV qubit encoded in its excited states is obtained. In the
strong driving limit, Kerr magnons can be linearized and give rise to
degenerate parametric amplification for squeezing magnons. As a result, both
the tripartite interaction and cooperativity are exponentially enhanced twice,
which is about $\exp(\xi)$ times than schemes only involving single-squeezing.
Hence, our proposal is more experimentally feasible because modest squeezing
parameter is sufficient. With this amplified tripartite coupling strength, the
system dynamics are greatly accelerated, leading to fast generation of
tripartite entanglement. In addition, noise-resilient perfect magnon blockade
can be achieved, well predicted by both the analytical approach and numerical
simulation with quantum master equation. Our results suggest that the NV center
represents a promising interface for engineering many-body interactions in
quantum magnonics, offering a versatile platform for exploring fundamental
quantum phenomena such as entanglement and correlations.

</details>


### [786] [Accelerating BP-OSD Decoder for QLDPC Codes with Local Syndrome-Based Preprocessing](https://arxiv.org/abs/2509.01892)
*Wenxuan Fan,Yasunari Suzuki,Gokul Subramanian Ravi,Yosuke Ueno,Koji Inoue,Teruo Tanimoto*

Main category: quant-ph

TL;DR: QLDPC codes are promising for quantum error correction, but their decoder (BP-OSD) has high latency. We propose a lightweight preprocessing step that uses local syndrome patterns to reduce BP iterations and decoding time, achieving over 80% reduction on a [[144,12,12]] code at 0.05% error rate without sacrificing logical error rate.


<details>
  <summary>Details</summary>
Motivation: Quantum error correction is essential for fault-tolerant quantum computing due to high qubit error rates. QLDPC codes offer high encoding rates, but their state-of-the-art decoder, BP-OSD, suffers from high decoding latency, primarily due to the iterative BP stage. Reducing BP runtime is therefore a key optimization target.

Method: The paper proposes a lightweight preprocessing step for BP-OSD that leverages local syndrome patterns to identify and handle likely trivial error events. These identified events are then fed as hints into the BP-OSD decoder, aiming to reduce the number of necessary BP iterations and consequently the overall decoding time.

Result: The proposed method demonstrates significant improvements on Bivariate Bicycle codes. Specifically, for the [[144,12,12]] code at a physical error rate of 0.05%, it achieves more than an 80% reduction in both BP iterations and total decoding time. Importantly, this performance gain is maintained while preserving the original logical error rate of the standard BP-OSD.

Conclusion: The proposed lightweight preprocessing step effectively reduces the decoding latency of BP-OSD for QLDPC codes by minimizing BP iterations through the use of local syndrome pattern hints. This approach offers a substantial speedup without compromising the error correction performance, making it a promising optimization for quantum error correction.

Abstract: Due to the high error rate of qubits, detecting and correcting errors is
essential for achieving fault-tolerant quantum computing (FTQC). Quantum
low-density parity-check (QLDPC) codes are one of the most promising quantum
error correction (QEC) methods due to their high encoding rates. Belief
Propagation-Ordered Statistics Decoding (BP-OSD) is the state-of-the-art
decoder for QLDPC codes, but it suffers from high decoding latency. We find
from experiments that a large portion of this latency originates from the
iterative BP stage, making BP runtime reduction a key optimization target.
  In this paper, we propose a lightweight preprocessing step that utilizes
local syndrome patterns to detect likely trivial error events and feed them as
hints into BP-OSD. These hints reduce the number of BP iterations and the
overall decoding time. On Bivariate Bicycle codes, the proposed method achieves
more than an 80% reduction in BP iterations and total decoding time for the
$[[144,12,12]]$ code at a physical error rate of 0.05%, while maintaining the
original logical error rate of BP-OSD.

</details>


### [787] [CNOT Oriented Synthesis for Small-Scale Boolean Functions Using Spatial Structures of Parallelotopes](https://arxiv.org/abs/2509.01912)
*Qiang Zheng,Yongzhen Xu,Jiaxi Zhang,Zhaofeng Su,Shenggen Zheng*

Main category: quant-ph

TL;DR: 量子计算在NISQ时代面临可扩展性挑战，本文提出SSHR方法，利用布尔函数空间结构优化量子电路合成，在小规模电路（≤8）中减少CNOT门数量。


<details>
  <summary>Details</summary>
Motivation: NISQ时代量子电路受限于门保真度和量子比特数量，现有方法忽略了布尔函数的空间结构。

Method: 提出SSHR方法，利用布尔函数在超立方体中的平行多面体空间结构来优化量子电路合成，以减少多控制Toffoli（MCT）门的使用。提出SSHR-H（启发式）和SSHR-I（整数线性规划）两种变体。

Result: 与ESOP和XAG方法相比，SSHR在CNOT门数量上分别减少了56%和81%。

Conclusion: SSHR方法能够有效利用布尔函数空间结构，提升小规模量子电路合成效率，并显著减少CNOT门的使用，优于现有技术。

Abstract: Quantum computing has garnered significant interest for its potential to
achieve exponential speedups over classical approaches. However, in the Noisy
Intermediate-Scale Quantum (NISQ) era, quantum circuit scalability remains
limited by gate fidelity and qubit counts, restricting physical implementations
to small-scale circuits. While prior work has explored logic network structures
for quantum circuit synthesis, these methods often neglect the spatial
structure intrinsic to Boolean functions. In this paper, we leverage this
spatial structure, encoded by parallelotopes embedded in the hypercube defined
by the Boolean function, to access a broader optimization space, enhancing
synthesis efficiency and reducing circuit complexity. We propose the Spatial
Structure-based Hypercube Reduction~(SSHR), a novel synthesis method tailored
for small-scale Boolean functions ($\leq 8$). SSHR extracts global spatial
features to minimize the use of Multi-Control Toffoli (MCT) gates. To further
exploit spatial correlations, we introduce two variants: SSHR-H employs
heuristic functions to accelerate synthesis runtime, while SSHR-I integrates an
Integer Linear Programming (ILP) solver to maximize spatial structure
utilization. Our approach outperforms existing techniques in small-scale
circuit synthesis, achieving 56\% and 81\% reductions in CNOT gate counts
compared to the Exclusive Sum-of-Products (ESOP) and Xor-And-Inverter Graph
(XAG) methods, respectively.

</details>


### [788] [An operator approach to the Madelung-Bohm continuity equation](https://arxiv.org/abs/2509.01913)
*M. A. García-Márquez,H. M. Moya-Cessa,I. Ramos-Prieto,F. Soto-Eguibar*

Main category: quant-ph

TL;DR: 该研究在Madelung-Bohm框架下求解概率连续性方程，并提出一种新的波函数振幅表示方法F(x,t)，以简化计算并应用于不同初始条件。研究通过零势和光学波导两种情况验证了该方法的有效性，并探讨了复数形式在薛定谔方程中的兼容性。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是在Madelung-Bohm框架下求解概率连续性方程，并为波函数振幅的计算提供一种更实用的方法，以便应用于任意给定的初始条件。

Method: 本研究使用算符方法，将波函数的振幅重新表述为更易于应用的函数F(x,t)，其中F是位置算符通过类似压缩的算符变换得到的。文章通过分析两种情况来展示该结果的应用：一种是外部势为零的情况，另一种是F的形式类似于光学波导阵列中的波传播特性。

Result: 研究推导出了函数F(x,t)来表征波函数振幅，并展示了其在零势和光学波导两种情况下的应用。结果表明，在光学波导的情况下，振幅、相位和势可能变为复数，但仍满足薛定谔方程。

Conclusion: 本研究成功地在Madelung-Bohm框架下求解了概率连续性方程，并提出了一种新的波函数振幅表示方法F(x,t)，该方法简化了计算，并可应用于任意初始条件。研究结果为理解量子力学现象提供了新的视角，特别是在处理复杂情况时。

Abstract: We solve the probability continuity equation within the Madelung-Bohm
framework, assuming a separable phase expressed as $S(x,t) = Q(x)\dot{\nu}(t) +
\mu(t)$. Using operator methods, we reformulate the wave function's amplitude
into a form that is more practical for application to any given initial
condition. This results in the function $F(x,t)$, which characterizes the
wavefunction's amplitude, with $F$ being the transformation of the position
operator via a squeeze-like operator. To demonstrate how this result can be
applied, we examine two scenarios: one where the external potential is zero,
causing the dynamics to originate only from the Bohm potential, and another
where the form of $F$ mirrors the characteristics of wave propagation within
optical waveguide arrays. In the second scenario, it is notable that the
amplitude, phase, and potentials might become complex yet still comply with the
Schr\"odinger equation.

</details>


### [789] [Quantum Statistical Witness Indistinguishability](https://arxiv.org/abs/2509.01945)
*Shafik Nassar,Ronak Ramachandran*

Main category: quant-ph

TL;DR: 本文研究了量子统计可证明者不可区分性（QSWI），并证明了QSWI包含SWI。


<details>
  <summary>Details</summary>
Motivation: 为统计可证明者不可区分性（SWI）提供了一个量子方面的研究，并探索了量子证明在信息论安全中的作用。

Method: 1. 定义并开始研究量子统计可证明者不可区分性（QSWI）。 2. 使用Kobayashi（TCC 2008）的量子技术，证明了具有诚实验证者量子统计可证明者不可区分性证明的任何问题，都存在一个三消息公共随机码恶意验证者量子统计可证明者不可区分性证明。 3. 扩展了Bitansky等人（STOC 2023）的工作，证明了量子批处理证明可以导出具有多项式反比可证明者不可区分性误差的量子统计可证明者不可区分性证明。

Result: 1. 证明了SWI包含在QSWI中。 2. 证明了量子批处理证明可以导出具有多项式反比可证明者不可区分性误差的量子统计可证明者不可区分性证明。

Conclusion: 量子统计可证明者不可区分性（QSWI）是统计可证明者不可区分性（SWI）的一个有用的量子推广，并且具有比经典版本更强的性质。

Abstract: Statistical witness indistinguishability is a relaxation of statistical
zero-knowledge which guarantees that the transcript of an interactive proof
reveals no information about which valid witness the prover used to generate
it. In this paper we define and initiate the study of QSWI, the class of
problems with quantum statistically witness indistinguishable proofs.
  Using inherently quantum techniques from Kobayashi (TCC 2008), we prove that
any problem with an honest-verifier quantum statistically witness
indistinguishable proof has a 3-message public-coin malicious-verifier quantum
statistically witness indistinguishable proof. There is no known analogue of
this result for classical statistical witness indistinguishability. As a
corollary, our result implies SWI is contained in QSWI.
  Additionally, we extend the work of Bitansky et al. (STOC 2023) to show that
quantum batch proofs imply quantum statistically witness indistinguishable
proofs with inverse-polynomial witness indistinguishability error.

</details>


### [790] [Quantum Pontus-Mpemba Effects in Real and Imaginary-time Dynamics](https://arxiv.org/abs/2509.01960)
*Hui Yu,Jiangping Hu,Shi-Xin Zhang*

Main category: quant-ph

TL;DR: 量子逢春-姆潘巴效應（QPME）是指量子系統在經過一個兩步演化協議後，比僅在對稱哈密頓量下直接演化更快地達到弛豫。該協議涉及系統首先在一個對稱性破缺的哈密頓量下演化，然後切換到一個對稱哈密頓量。QPME 在實時和虛時動力學中都發生，且對 U(1) 對稱性具有影響。透過傾斜的鐵磁初始狀態，可以觀察到暫態不對稱演化顯著加速了熱化或收斂到基態的過程。該效應在小傾斜角下更為明顯，而在較大的傾斜角或反鐵磁初始狀態下則會被抑制。數值證據表明 QPME 在不同系統尺寸下都具有魯棒性，並在熱力學極限下保持穩定。


<details>
  <summary>Details</summary>
Motivation: 探討量子系統在特定演化協議下，經歷對稱性破缺後再恢復對稱性時，其弛豫過程是否會比直接演化更快，即研究量子逢春-姆潘巴效應（QPME）。

Method: 研究了在實時和虛時動力學中，以及對於 $U(1)$ 對稱性下的 QPME 現象。利用傾斜的鐵磁初始狀態作為探針，觀察暫態不對稱演化對熱化或收斂到基態的加速作用。通過改變傾斜角度和初始狀態（如反鐵磁初始狀態），以及在不同系統尺寸下進行數值模擬，來驗證 QPME 的存在及其魯棒性。

Result: 研究發現，QPME 在實時和虛時動力學中都存在，並且對於 $U(1)$ 對稱性有效。傾斜的鐵磁初始狀態確實能加速熱化或收斂到基態的過程，且在小傾斜角下效應更為顯著。然而，較大的傾斜角或反鐵磁初始狀態會抑制此效應。數值模擬證實了 QPME 在不同系統尺寸下的魯棒性，表明其在熱力學極限下依然穩定存在。

Conclusion: 量子逢春-姆潘巴效應（QPME）在量子系統中確實存在，並且可以透過引入暫態的不對稱演化來加速系統的弛豫過程。這一發現不僅加深了對非平衡量子現象的理解，也為加速量子模擬和量子計算提供了新的可能性。

Abstract: The quantum Pontus-Mpemba effect (QPME) is a counterintuitive phenomenon
wherein a quantum system relaxes more rapidly through a two-step evolution
protocol than through direct evolution under a symmetric Hamiltonian alone. In
this protocol, the system first evolves under a symmetry-breaking Hamiltonian
and then switches to a symmetric one. We demonstrate that QPME occurs under
both real-time and imaginary-time dynamics with respect to $U(1)$-symmetry.
Using tilted ferromagnetic initial states, we demonstrate that a transient
asymmetric evolution significantly accelerates thermalization or convergence to
the ground state for both real-time and imaginary-time evolutions,
respectively. The effect is pronounced for small tilt angles, while larger
tilts or antiferromagnetic initial states suppress it. Numerical evidence
across different system sizes confirms the robustness of QPME, demonstrating
its stability in the thermodynamic limit. This finding not only deepens our
fundamental understanding of non-equilibrium quantum phenomena but also opens
new possibilities for accelerating quantum simulation and computation.

</details>


### [791] [Unified boson sampling](https://arxiv.org/abs/2509.02058)
*Luca Bianchi,Carlo Marconi,Laura Ares,Davide Bacco,Jan Sperling*

Main category: quant-ph

TL;DR: 该研究统一并扩展了不同形式的玻色子采样，将离散变量的散点玻色子采样与连续变量的高斯玻色子采样相结合，能够利用压缩光等更复杂的状态，并开发了用于描述多光子和多模光在高斯变换下行为的生成函数形式，为探索不同光量子信息处理平台的接口提供了分析工具，并通过数值模拟对统一采样进行了性能、复杂性和可扩展性基准测试，还通过分析纠缠来例证统一采样器非线性相互作用产生的量子关联。


<details>
  <summary>Details</summary>
Motivation: 实现量子优势，并推动量子模拟、机器学习和图论等领域的发展。

Method: 提出了一种统一和扩展不同形式玻色子采样的方法，将离散变量的散点玻色子采样与连续变量的高斯玻色子采样相结合，并开发了用于联合描述高斯变换下的多光子和多模光的生成函数形式。

Result: 开发了能够利用压缩光等更复杂状态的统一采样协议，并提供了探索不同光量子信息处理平台接口的分析工具。通过数值模拟，对统一采样进行了性能、复杂性和可扩展性基准测试，并例证了其从非线性相互作用中产生量子关联的能力。

Conclusion: 该研究提出的统一采样方法能够结合不同玻色子采样技术的优点，并利用更复杂的状态，为光量子信息处理领域的研究提供了新的工具和方向。

Abstract: Boson sampling is a key candidate for demonstrating quantum advantage, and
has already yielded significant advances in quantum simulation, machine
learning, and graph theory. In this work, a unification and extension of
distinct forms of boson sampling is developed. The devised protocol merges
discrete-variable scattershot boson sampling with continuous-variable Gaussian
boson sampling. Thereby, it is rendered possible to harness the complexity of
more interesting states, such as squeezed photons, in advanced sampling
protocols. A generating function formalism is developed for the joint
description of multiphoton and multimode light undergoing Gaussian
transformations. The resulting analytical tools enable one to explore
interfaces of different photonic quantum-information-processing platforms. A
numerical simulation of unified sampling is carried out, benchmarking its
performance, complexity, and scalability. Entanglement is characterized to
exemplify the generation of quantum correlations from the nonlinear
interactions of a unified sampler.

</details>


### [792] [Is the EPR paradox really a paradox?](https://arxiv.org/abs/2509.02085)
*Natalia Gorobey,Alexander Lukyanenko*

Main category: quant-ph

TL;DR: 如果一个系统的量化场激发不满足给定的量子数，那么该源的触发幅度为零。本文详细研究了一个包含两个处于单态的光子源和两个光子探测器的系统。研究表明，一个探测器在特定偏振方向上操作的条件，可以唯一地确定第二个探测器所需的方向和偏振。这一结论与量化场系统中激发的运动定律和量子数守恒定律一致。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨在量化场系统中，当系统的激发不满足特定量子数时，源的触发幅度的性质，并通过一个包含双光子单态源和两个光子探测器的具体系统进行详细分析。

Method: 本文采用理论分析方法，首先阐述了在量化场系统中，激发不存在时源触发幅度的性质。随后，详细分析了一个由双光子单态源和两个光子探测器组成的系统，并推导了探测器操作条件与光子偏振方向之间的关系。

Result: 研究结果表明，在一个包含双光子单态源和两个光子探测器的系统中，一个探测器的操作条件（特定方向和偏振）能够唯一地确定另一个探测器所需的方向和偏振。

Conclusion: 本文的结论是，在一个量化场系统中，当一个探测器被触发时，其操作条件（方向和偏振）可以唯一地确定另一个探测器所需的方向和偏振。这一发现符合量化场系统中激发的运动定律和量子数守恒定律。

Abstract: If the excitation of a system of quantized fields with a given set of quantum
numbers does not exist, the amplitude of the triggering of the source is zero.
A system with a source of two photons in a singlet state and two photon
detectors is considered in detail. It is shown that the condition of operation
of one detector with a given direction of photon polarization uniquely
determines the adequate choice of direction and polarization for the second
detector. This conclusion is in accordance with the laws of motion and
conservation of quantum numbers of excitations in a system of quantized fields.

</details>


### [793] [Security Analysis of MDI-QKD in Turbulent Free-Space Polarization Channels-A Composite Channel Framework](https://arxiv.org/abs/2509.02087)
*Heyang Peng,Seid Koudia,Symeon Chatzinotas*

Main category: quant-ph

TL;DR: 该研究提出了一个统一的 the turbulence-induced polarization decoherence model for FSO MDI-QKD, 能够有效提高 SKR。


<details>
  <summary>Details</summary>
Motivation: 大气湍流对自由空间测量设备无关量子密钥分发 (FSO MDI-QKD) 造成了严峻挑战，会引起偏振退相干和去极化，从而降低密钥生成率 (SKR)。

Method: 提出一个统一的去极化-退相干信道模型，将相位扰动、高斯光束展宽、光束漂移、孔径截断和闪烁等因素整合到封闭形式的参数中：去极化因子、退相干因子和检测概率。通过将湍流映射到 von Mises-Fisher/Watson 分布的 SU(2) 旋转，推导出与现有 MDI-QKD 安全性分析兼容的解析 SKR 表达式。

Result: 该模型在晴朗、阴天和雾霾天气条件下均表现优异，计算效率高且可进行实验验证，便于进行实时链路自适应。通过在地对地自由空间链路上进行的数值模拟证实了模型的准确性。

Conclusion: 该模型能够为全球规模的 MDI-QKD 网络提供可靠的物理层设计。

Abstract: Atmospheric turbulence poses a significant challenge to free-space
measurement-device-independent quantum key distribution (FSO MDI-QKD) by
inducing polarization decoherence and depolarization, which degrade the secret
key rate (SKR). In this paper, we propose a unified depolarizing-dephasing
channel model for turbulence-induced polarization decoherence in FSO MDI-QKD.
This model consolidates phase perturbations, Gaussian beam spreading, beam
drift, aperture truncation, and scintillation into closed-form parameters:
depolarization factor, decoherence factor, and detection probability. By
mapping turbulence to a von Mises-Fisher/Watson-distributed SU(2) rotation, we
derive an analytic SKR expression compatible with existing MDI-QKD security
analyses. The model excels in clear, overcast, and hazy weather conditions,
offering computational efficiency and experimental verifiability for real-time
link adaptation. Numerical simulations, illustrated on a ground-to-satellite
free-space link, confirm its accuracy, enabling robust physical layer design
for global-scale MDI-QKD networks.

</details>


### [794] [Highly Efficient and Broadband Optical Delay Line towards a Quantum Memory](https://arxiv.org/abs/2509.02096)
*Yu Guo,Anindya Banerji,Jia Boon Chin,Arya Chowdhury,Alexander Ling*

Main category: quant-ph

TL;DR: 提出一种基于嵌套多通池结构的高效自由空间光延迟线，具有低损耗和宽光谱带宽，并能保持量子纠缠，适用于量子存储和量子网络同步。


<details>
  <summary>Details</summary>
Motivation: 为了实现低损耗、宽光谱带宽且能保持量子纠缠的光延迟线，以满足全光量子存储和可扩展量子网络同步模块的需求。

Method: 设计并实现了一种嵌套多通池光延迟线，采用定制的宽带电介质涂层以获得高反射率。利用偏振纠缠光子对进行表征，信号光子通过延迟线，闲置光子作为时间参考。通过量子态层析成像来评估纠缠的保持程度。

Result: 实现了高达687纳秒的单程延迟，光子检索效率为95.390(5)%，纠缠保真度为99.6(9)%。延迟可在1.8纳秒至687纳秒之间进行控制，步长约为12.6纳秒。时间-带宽积达到3.87x10^7。

Conclusion: 该延迟线具有高效率、低损耗、宽光谱带宽和良好的纠缠保持特性，是全光量子存储和量子网络同步模块的有力候选者。

Abstract: We demonstrate a high-efficiency, free space optical delay line utilizing a
nested multipass cell architecture. This design supports extended optical paths
with low loss, aided by custom broadband dielectric coating that provides high
reflectivity across a wide spectral bandwidth. The cell is characterized using
polarization-entangled photon pairs, with signal photons routed through the
delay line and idler photons used as timing reference. Quantum state tomography
performed on the entangled pair reveals entanglement preservation with a
fidelity of $99.6(9)\%$ following a single-transit delay of up to $687$~ns,
accompanied by a photon retrieval efficiency of $95.390(5)%$. The delay is
controllable and can be set between $1.8$~ns to $687$~ns in $\sim12.6$~ns
increments. The longest delay and wide spectral bandwidth result in a
time-bandwidth product of $3.87\times 10^7$. These results position this delay
line as a strong candidate for all-optical quantum memories and synchronization
modules for scalable quantum networks.

</details>


### [795] [Efficient quantum state tomography with Chebyshev polynomials](https://arxiv.org/abs/2509.02112)
*Hao Su,Shiying Xiong,Yue Yang*

Main category: quant-ph

TL;DR: 量子计算在解决计算密集型问题方面显示出潜力，但受到通用量子态层析成像（QST）指数级资源需求的限制。我们提出了一种名为“量子态层析成像与切比雪夫多项式”的近似层析成像方法，该方法适用于表示复值函数的纯量子态。此方法将层析成像重新表述为切比雪夫展开系数的估计，这些系数表示为目标量子态与切比雪夫基函数之间的内积，并使用哈达玛测试电路进行测量。通过将切比雪夫多项式的截断阶数视为可控参数，该方法在效率和准确性之间取得了实际的平衡。对于表示流体流动场等大尺度特征占主导地位的量子态，适当的截断可以通过线性深度的量子电路忠实地重建主导分量，同时使测量重复次数和后处理与量子比特数量无关，这与基于测量的全QST方法的指数级扩展形成对比。在解析函数和数值生成的流场数据上的验证，证明了该方法能够准确重建并有效提取大尺度特征，表明该方法适用于受宏观动力学控制的系统。


<details>
  <summary>Details</summary>
Motivation: 通用量子态层析成像（QST）对量子态进行完全表征，但受到指数级资源需求的限制。本研究旨在提出一种更高效的近似QST方法。

Method: 提出了一种名为“量子态层析成像与切比雪夫多项式”的近似层析成像方法。该方法将层析成像问题转化为估计量子态的切比雪夫展开系数，通过哈达玛测试电路测量这些系数。截断阶数作为可控参数，用于平衡效率与准确性。

Result: 通过在解析函数和数值生成的流场数据上进行验证，证明了该方法能够准确重建量子态并有效提取大尺度特征。

Conclusion: 所提出的“量子态层析成像与切比雪夫多项式”方法是一种高效的近似QST方法，适用于包含大尺度特征（如流体流动场）的量子态，并能在效率和准确性之间取得实际的平衡。

Abstract: Quantum computing shows promise for addressing computationally intensive
problems but is constrained by the exponential resource requirements of general
quantum state tomography (QST), which fully characterizes quantum states
through parameter estimation. We introduce the QST with Chebyshev polynomials,
an approximate tomography method for pure quantum states encoding
complex-valued functions. This method reformulates tomography as the estimation
of Chebyshev expansion coefficients, expressed as inner products between the
target quantum state and Chebyshev basis functions, measured using the Hadamard
test circuit. By treating the truncation order of the Chebyshev polynomials as
a controllable parameter, the method provides a practical balance between
efficiency and accuracy. For quantum states encoding functions dominated by
large-scale features, such as those representing fluid flow fields, appropriate
truncation enables faithful reconstruction of the dominant components via
quantum circuits with linear depth, while keeping both measurement repetitions
and post-processing independent of qubit count, in contrast to the exponential
scaling of full measurement-based QST methods. Validation on analytic functions
and numerically generated flow-field data demonstrates accurate reconstruction
and effective extraction of large-scale features, indicating the method's
suitability for systems governed by macroscopic dynamics.

</details>


### [796] [Counting gauge-invariant states with matter fields and finite gauge groups](https://arxiv.org/abs/2509.02173)
*Alessandro Mariani*

Main category: quant-ph

TL;DR: 该工作将有限规范群格点规范理论的规范不变态计数推广到包含标量和费米子物质以及不同边界条件的情况，并探讨了电荷共轭的实现等相关问题。


<details>
  <summary>Details</summary>
Motivation: 有限规范群的规范理论在量子模拟和量子引力中有应用，此前已计算出纯规范理论在任意格点上的规范不变态的确切数量。

Method: 将之前纯规范理论的计数方法推广到包含标量和费米子物质以及不同边界条件的情况。

Result: 得出了包含物质和不同边界条件的格点规范理论的规范不变态计数，并考虑了电荷共轭的实现等相关问题。

Conclusion: 这些结果对于资源估算以及在规范不变基中工作时的交叉检查都很重要。

Abstract: Gauge theories with finite gauge groups have applications to quantum
simulation and quantum gravity. Recently, the exact number of gauge-invariant
states was computed for pure gauge theories on arbitrary lattices. In this
work, we generalize this counting to include the case of scalar and fermionic
matter, as well as various kinds of boundary conditions. As a byproduct, we
consider several related questions, such as the implementation of charge
conjugation for a generic finite group. These results are relevant for resource
estimation and also as a crosscheck when working in a gauge-invariant basis.

</details>


### [797] [Observing Two-Particle Correlation Dynamics in Tunable Superconducting Bose-Hubbard Simulators](https://arxiv.org/abs/2509.02180)
*Z. T. Wang,Si-Yun Zhou,Yun-Hao Shi,Kaixuan Huang,Z. H. Yang,Jingning Zhang,Kui Zhao,Yueshan Xu,Hao Li,S. K. Zhao,Yulong Feng,Guangming Xue,Yu Liu,Wei-Guo Ma,Cai-Ping Fang,Hao-Tian Liu,Yong-Yi Wang,Kai Xu,Haifeng Yu,Heng Fan,S. P. Zhao*

Main category: quant-ph

TL;DR: Superconducting qutrit arrays with Floquet engineering are used to study quantum walks and their correlations (entanglement and discord) under tunable interactions. The study reveals how interactions affect correlation dynamics, showing suppression or insensitivity of entanglement and discord depending on initial states and interaction strength. The research highlights the importance of interaction in shaping quantum dynamics and advances the simulation of correlated quantum systems using superconducting circuits.


<details>
  <summary>Details</summary>
Motivation: Understanding the generation and propagation of quantum correlations in quantum systems and overcoming the challenge of their experimental control and characterization.

Method: Experimentally studying two-particle correlation dynamics via quantum walks in superconducting Bose-Hubbard qutrit arrays with tunable on-site interaction $U$ realized by Floquet engineering. Measuring two-particle entanglement and quantum correlation dynamics using negativity and quantum discord.

Result: Quantum walks exhibit a transition from bosonic bunching to fermionic antibunching with increasing $U$. Entanglement propagation can be suppressed with increasing $U$ depending on the initial state, while quantum discord shows a larger amplitude or both are insensitive to $U$. Entanglement persists throughout particle walks for $U=0$ but not generally for increased $U$.

Conclusion: Interaction plays a crucial role in shaping quantum dynamics. The use of superconducting circuits provides a platform for simulating correlated quantum systems.

Abstract: The generation and propagation of quantum correlations are central to
understanding many dynamical properties of quantum systems, yet their precise
experimental control and characterization remain a key challenge. Here we
experimentally study the two-particle correlation dynamics via quantum walks in
superconducting Bose-Hubbard qutrit arrays, with tunable on-site interaction
$U$ realized by Floquet engineering. Quantum walks show the characteristic
change from bosonic bunching to fermionic antibunching with increasing $U$. The
two-particle entanglement and quantum correlation dynamics, as measured by
negativity and quantum discord, are investigated. We find that depending on the
initial state, the propagation of entanglement can be strongly suppressed with
increasing $U$, while that of quantum discord exhibits considerably larger
amplitude; or both of them appear insensitive to $U$. Furthermore, the forms of
entanglement are found to persist throughout particle walks for $U =$ 0 and it
is generally not the case when $U$ increases. Our work highlights the role of
interaction in shaping quantum dynamics and extends the realm of simulating
correlated quantum systems with superconducting circuits.

</details>


### [798] [Indefinite causal order in cavity quantum electrodynamics](https://arxiv.org/abs/2509.02209)
*Lorenzo M. Procopio,L. O. Castaños-Cervantes,Tim J. Bartley*

Main category: quant-ph

TL;DR: ICO in cQED systems can entangle distant cavity fields and enable single-photon transfer, outperforming fixed-order scenarios.


<details>
  <summary>Details</summary>
Motivation: Investigating Indefinite Causal Order (ICO) in cavity quantum electrodynamics (cQED) systems as a potential resource for quantum information processing, building upon previous work in photonic platforms.

Method: Experimenting with a cQED system composed of two cavities to explore ICO's capabilities in entangling distant cavity fields and facilitating single-photon transfer.

Result: ICO successfully created entanglement between two distant cavity fields that never interacted directly. In vacuum states, ICO demonstrated an advantage over fixed-order scenarios by consistently generating large entanglement. Additionally, ICO enabled the transfer of a single photon between cavities with a total probability of one, without altering the atom's quantum state, an impossibility in fixed-order cQED systems.

Conclusion: ICO shows significant potential in the paradigm of light-matter interaction for coherently controlling atom-field observables, offering advantages in entanglement generation and photon transfer compared to traditional fixed-order systems.

Abstract: Indefinite causal order (ICO) has the potential to be a new resource for
quantum information processing. In most of its experiments, ICO has been
investigated in a photonic platform. Here we investigate ICO in a cavity
quantum electrodynamics (cQED) system composed of two cavities. Our results
show that ICO can create entanglement between two distant cavity fields that
never interact directly, and for the case of two cavity fields in the vacuum
state, ICO presents an advantage over the fixed-order scenario by always
generating large entanglement between the two cavity fields. Furthermore, we
show that ICO can interchange one photon between both cavities with a total
probability equal to one, without changing the quantum state of the atom,
something that is impossible to achieve when two cQED systems are in
well-defined order. Our results show the potential that ICO can offer in the
paradigm of light-matter interaction for coherently controlling atom-field
observables.

</details>


### [799] [Invaraints in Linear Optics](https://arxiv.org/abs/2509.02211)
*Sébastien Draux,Simon Perdrix,Emmanuel Jeandel,Shane Mansfield*

Main category: quant-ph

TL;DR: 线性光学（LO）禁止某些计算。本文研究了在LO中进行计算的条件。我们发现存在有限多个多项式，当且仅当存在一个LO电路将其中一个光子态转换为另一个时，每个多项式在两个光子态上的计算结果才相同。该证明是非构造性的，因此我们接下来将重点研究寻找此类多项式的方法。


<details>
  <summary>Details</summary>
Motivation: 研究线性光学（LO）中计算的可行性条件。

Method: 找到有限多个多项式，使得当且仅当存在一个LO电路将一个光子态转换为另一个时，每个多项式在两个光子态上的计算结果才相同。

Result: 发现存在有限多个多项式，可以表征LO中的状态转换。但该证明是非构造性的，需要进一步寻找这些多项式的方法。

Conclusion: 线性光学中的状态转换可以通过一组特定的多项式来表征，但找到这些多项式的方法仍是未来的研究方向。

Abstract: Linear optics (LO) prohibits certain transformations. In this paper, we study
the conditions for a computation to be possible in LO. We find that there are
finitely many polynomials such that each of these polynomials evaluates to the
same value on two photonic states if and only if there is a LO circuit
transforming one of these states into the other. The proof is non-constructive,
so we then focus on methods to find such polynomials.

</details>


### [800] [Optimizing digital quantum simulation of open quantum lattice models](https://arxiv.org/abs/2509.02268)
*Xie-Hang Yu,Hongchao Li,J. Ignacio Cirac,Rahul Trivedi*

Main category: quant-ph

TL;DR: 该论文提出了一种模拟具有稳定高斯环境的几何局域多体开放量子系统的近优算法，该算法在系统状态模拟误差为δ时，所需的门数量、并行电路深度和辅助量子比特数分别为O(Nt(Nt/δ)^(1+o(1)))、O(t(Nt/δ)^(1+o(1)})和O(N(Nt/δ)^(1+o(1)))。当只模拟局域可观测量时，电路深度可与系统大小N无关。对于马尔可夫动力学和对易的跳跃算符，还提出了两种算法，在几何局域门数量方面比现有算法具有更优的渐近门复杂度。


<details>
  <summary>Details</summary>
Motivation: 模拟开放量子系统对于理解凝聚态物理和量子光学中的多体系统至关重要，但现有的模拟算法仍有待改进。

Method: 研究了具有稳定高斯环境的几何局域多体开放量子系统的模拟问题，开发了近优算法，并对局部可观测量和马尔可夫动力学的情况分别进行了分析。

Result: 在系统状态模拟误差为δ时，提出的算法在门数量、并行电路深度和辅助量子比特数方面取得了近优的性能。当只模拟局域可观测量时，电路深度可与系统大小N无关。对于马尔可夫动力学，提出的两种算法在几何局域门数量方面优于现有算法。

Conclusion: 该研究为模拟物理相关模型提供了理论依据，尤其是在预容错设备上模拟局域可观测量方面具有重要意义。所提出的算法在模拟开放量子系统方面具有理论和实践上的优越性。

Abstract: Many-body systems arising in condensed matter physics and quantum optics
inevitably couple to the environment and need to be modelled as open quantum
systems. While near-optimal algorithms have been developed for simulating
many-body quantum dynamics, algorithms for their open system counterparts
remain less well investigated. We address the problem of simulating
geometrically local many-body open quantum systems interacting with a
stationary Gaussian environment. Under a smoothness assumption on the
system-environment interaction, we develop near-optimal algorithms that, for a
model with $N$ spins and evolution time $t$, attain a simulation error $\delta$
in the system-state with $\mathcal{O}(Nt(Nt/\delta)^{1 + o(1)})$ gates,
$\mathcal{O}(t(Nt/\delta)^{1 + o(1)})$ parallelized circuit depth and
$\tilde{\mathcal{O}}(N(Nt/\delta)^{1 + o(1)})$ ancillas. We additionally show
that, if only simulating local observables is of interest, then the circuit
depth of the digital algorithm can be chosen to be independent of the system
size $N$. This provides theoretical evidence for the utility of these
algorithms for simulating physically relevant models, where typically local
observables are of interest, on pre-fault tolerant devices. Finally, for the
limiting case of Markovian dynamics with commuting jump operators, we propose
two algorithms based on sampling a Wiener process and on a locally dilated
Hamiltonian construction, respectively. These algorithms reduce the asymptotic
gate complexity on $N$ compared to currently available algorithms in terms of
the required number of geometrically local gates.

</details>


### [801] [Optimal distillation of photonic indistinguishability](https://arxiv.org/abs/2509.02296)
*Francesco Hoch,Anita Camillini,Giovanni Rodari,Eugenio Caruccio,Gonzalo Carvacho,Taira Giordani,Riccardo Albiero,Niki Di Giano,Giacomo Corrielli,Francesco Ceccarelli,Roberto Osellame,Marco Robbio,Leonardo Novo,Nicolò Spagnolo,Ernesto F. Galvão,Fabio Sciarrino*

Main category: quant-ph

TL;DR: 通过利用线性光学电路中的量子干涉，提出并实验验证了具有最大可见性增益的三光子纠缠度提纯方案，该方案考虑了多光子效应，并针对有限的光子资源进行了优化。


<details>
  <summary>Details</summary>
Motivation: 光子不可区分性会限制量子通信和计算的性能，纠缠度提纯协议可以通过利用量子干涉来增强光子不可区分性。

Method: 提出了一种三光子纠缠度提纯方案，该方案考虑了集体光子相位等多光子效应，并优化了可见性增益和成功概率，同时尽量减少了模式数量。实验上利用量子点光源和可编程集成光子处理器验证了该方案。

Result: 实验实现了有限光子资源下的纠缠度提纯，并针对多种多光子不可区分性场景进行了验证，证明了该协议的有效性。

Conclusion: 该工作通过提出并实验验证了优化的三光子纠缠度提纯方案，为基于光子的量子技术提供了实用的纠缠度提纯工具，并强调了其在实际应用中的潜力。

Abstract: Imperfect photons' indistinguishability limits the performance of photonic
quantum communication and computation . Distillation protocols, inspired by
entanglement purification, enhance photons' indistinguishability by leveraging
quantum interference in linear optical circuits. In this work, we present a
three-photon distillation protocol optimized to achieve the maximum visibility
gain, which requires consideration of multi-photon effects such as collective
photonic phases. We employ interferometers with the minimum number of modes,
optimizing also over the protocol's success probability. The developed protocol
is experimentally validated with a platform featuring a demultiplexed quantum
dot source interfaced with a programmable eight-mode laser-written integrated
photonic processor. We achieve indistinguishability distillation with limited
photonic resources and for several multi-photon distinguishability scenarios.
This work helps to strengthen the role of distillation as a practical tool for
photon-based quantum technologies.

</details>


### [802] [Picking NPA constraints from a randomly sampled quantum moment matrix](https://arxiv.org/abs/2509.02309)
*G. Viola,A. Chaturvedi*

Main category: quant-ph

TL;DR: 一种用于实现半定规划松弛的简单灵活方法，用于界定量子相关集。该方法依赖于从随机采样的矩矩阵中获得等式约束，从而使用户能够轻松访问各种操作场景下的量子行为集。


<details>
  <summary>Details</summary>
Motivation: 界定量子相关集。

Method: 从随机采样的矩矩阵中获得等式约束。

Result: 用户可以轻松访问各种操作场景下的量子行为集。

Conclusion: 

Abstract: We describe a simple and flexible method for implementing semi-definite
programming relaxations for bounding the set of quantum correlations. The
method relies on obtaining equality constraints from randomly sampled moment
matrices and hence allows the user to easily access the set of quantum behavior
in diverse operational scenarios.

</details>


### [803] [Floquet-informed Learning of Periodically Driven Hamiltonians](https://arxiv.org/abs/2509.02331)
*Keren Li*

Main category: quant-ph

TL;DR: 提出一种可扩展的、受 Floquet 启发的学习算法，用于表征时间周期哈密顿量，该算法将哈密顿量表示为截断的傅里叶级数，并将参数估计重新定义为 Floquet 能带图中的紧凑线性逆问题。该算法适用于满足温和的光滑性/带限性问题的样本和运行时复杂性随傅里叶截止、时间分辨率和未知系数的数量呈多项式增长。


<details>
  <summary>Details</summary>
Motivation: 表征时间周期哈密顿量对于验证和控制驱动的量子平台至关重要，但现有的重构方法需要密集的时间域采样和繁重的后处理。

Method: 将哈密顿量表示为截断的傅里叶级数，并将参数估计重新定义为 Floquet 能带图中的紧凑线性逆问题。

Result: 在二维伊辛和海森堡格子上的数值实验表明，该算法具有快速收敛到时间分辨率和对高阶扰动的鲁棒性。自适应规则学习傅里叶级数的截止，无需事先设置已知的截断。

Conclusion: 这些特性能够对周期性驱动平台进行实用的认证和基准测试，并且可以自然地扩展到近周期驱动。

Abstract: Characterizing time-periodic Hamiltonians is pivotal for validating and
controlling driven quantum platforms, yet prevailing and unadjusted
reconstruction methods demand dense time-domain sampling and heavy
post-processing. We introduce a scalable Floquet-informed learning algorithm
that represents the Hamiltonian as a truncated Fourier series and recasts
parameter estimation as a compact linear inverse problem in the Floquet band
picture. The algorithm is well-suited to problems satisfying mild
smoothness/band-limiting. In this regime, its sample and runtime complexities
scale polynomially with the Fourier cutoff, time resolution, and the number of
unknown coefficients. For local Hamiltonian models, the coefficients grows
polynomially with system size, yielding at most polylogarithmic dependence on
the Hilbert-space dimension. Furthermore, numerical experiments on one- and
two-dimensional Ising and Heisenberg lattices show fast convergence to time
resolution and robustness to higher-order perturbations. An adaptive rule
learns the cutoff of Fourier series, removing the need to set known truncation
\textit{a priori}. These features enable practical certification and
benchmarking of periodically driven platforms with rapidly decaying
higher-order content, and extend naturally to near-periodic drives.

</details>


### [804] [Boosting Thermodynamic Efficiency with Quantum Coherence of Phaseonium Atoms](https://arxiv.org/abs/2509.02353)
*Federico Amato,Gerardo Adesso,Massimo G. Palma,Salvatore Lorenzo,Rosario Lo Franco*

Main category: quant-ph

TL;DR: 该研究提出了一种利用相onium气体（相干制备的三能级原子）作为动力源的量子发动机的实际实现方法，其中量子相干性被用作热力学资源。


<details>
  <summary>Details</summary>
Motivation: 探索将量子相干性作为热力学资源，并提出一种超越标准热力学范式的量子发动机。

Method: 利用基于碰撞模型的相onium-腔相互作用和腔光力学，构建了一个基于两个非热力学库的完整发动机循环，并使用级联配置耦合第二个腔来研究可扩展性。

Result: 成功实现了由相onium气体驱动的相干驱动量子发动机，并展示了其效率的提升，以及通过级联配置提高可扩展性的潜力。

Conclusion: 证明了相干驱动量子发动机的可行性，并指出了其在未来热力学应用中的潜力。

Abstract: We present a realistic implementation of a quantum engine powered by a
phaseonium gas of coherently prepared three-level atoms -- where quantum
coherence acts as a thermodynamic resource. Using a collision model framework
for phaseonium-cavity interactions and cavity optomechanics, we construct a
full engine cycle based on two non-thermal reservoirs, each characterized by
coherence-induced effective temperatures. This configuration enhances the
efficiency of a simple optomechanical engine operating beyond standard thermal
paradigms. We further address scalability by coupling a second cavity in
cascade configuration, where the same phaseonium gas drives both cycles. Our
results demonstrate the operational viability of coherence-driven quantum
engines and their potential for future thermodynamic applications.

</details>


### [805] [Quantum Circuit Design using Complex valued Neural Network in Stiefel Manifold](https://arxiv.org/abs/2509.02374)
*Sayan Manna,Mahesh Mohan M R*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Quantum algorithms operate on quantum states through unitary transformations
in high dimensional complex Hilbert space. In this work, we propose a machine
learning approach to create the quantum circuit using a single-layer
complex-valued neural network. The input and ouput quantum states are provided
to the network, which is trained to approximate the output state of a given
quantum algorithm. To ensure that the fundamental property of unitarity is
preserved throughout the training process, we employ optimization in Stiefel
Manifold.

</details>


### [806] [Widely non-degenerate nonlinear frequency conversion in cryogenic titanium in-diffused lithium niobate waveguides](https://arxiv.org/abs/2509.02392)
*Nina Amelie Lange,Sebastian Lengeling,Philipp Mues,Viktor Quiring,Werner Ridder,Christof Eigner,Harald Herrmann,Christine Silberhorn,Tim J. Bartley*

Main category: quant-ph

TL;DR: 铌酸锂波导在低温下工作时，其相位匹配和模式导出特性会受到少量影响，但总体上与理论模型一致。


<details>
  <summary>Details</summary>
Motivation: 需要表征铌酸锂波导在低温下的性能，以评估其作为量子光子集成平台的可行性，并与其他平台进行比较。

Method: 在低温条件下，对非简并自发参量下转换（SPDC）过程中发射的1556 nm和950 nm光进行相位匹配和模式导出特性的表征。

Result: 低温条件对铌酸锂波导的相位匹配和模式导出有轻微影响，这些影响在不同冷却循环中存在差异，但光谱特性与理论模型吻合。

Conclusion: 尽管存在热释电和光折射效应，但铌酸锂波导在低温下仍能可靠工作，并且其性能参数可以在一定程度上预测。该研究为评估其他非线性光子集成平台（如薄膜铌酸锂）提供了一个基准。

Abstract: The titanium in-diffused lithium niobate waveguide platform is
well-established for reliable prototyping and packaging of many quantum
photonic components at room temperature. Nevertheless, compatibility with
certain quantum light sources and superconducting detectors requires operation
under cryogenic conditions. We characterize alterations in phase-matching and
mode guiding of a non-degenerate spontaneous parametric down-conversion process
emitting around 1556 nm and 950 nm, under cryogenic conditions. Despite the
effects of pyroelectricity and photorefraction, the spectral properties match
our theoretical model. Nevertheless, these effects cause small but significant
variations within and between cooling cycles. These measurements provide a
first benchmark against which other nonlinear photonic integration platforms,
such as thin-film lithium niobate, can be compared.

</details>


### [807] [Efficient and Explicit Block Encoding of Finite Difference Discretizations of the Laplacian](https://arxiv.org/abs/2509.02429)
*Andreas Sturm,Niclas Schillo*

Main category: quant-ph

TL;DR: 本文提出了一种高效且显式的块编码方法，用于解决量子线性代数问题，特别是偏微分方程的求解，并对该方法进行了详细的构造、分析和资源估计。


<details>
  <summary>Details</summary>
Motivation: 为了提高量子算法中数据输入模型的效率，以期在量子线性代数任务（如利用量子特征值或奇异值变换求解偏微分方程）中实现超越经典方法的加速。块编码是访问矩阵数据的既定技术，尤其是在处理拉普拉斯算子及其有限差分离散化等基础问题时。

Method: 提出一种高效且显式的块编码方法，详细阐述了量子算法的构造过程，并展示了该方法如何利用有限差分离散化的独特结构。此外，还解析推导了块编码的子归一化因子和成功概率相对于问题维度、有限差分网格宽度以及精确解的正则性的标度律，并给出了资源估计。

Result: 文中给出了块编码方法相对于问题维度、网格宽度和解的正则性的标度律，以及资源估计。

Conclusion: 所提出的块编码方法在效率和构造的明确性方面优于现有方法，为量子线性代数任务，特别是偏微分方程的求解，提供了更优的解决方案。

Abstract: The data input model is a fundamental component of every quantum algorithm,
as its efficiency is crucial for achieving potential speed-ups over classical
methods. For quantum linear algebra tasks that utilize quantum eigenvalue or
singular value transformations, block encoding is the established technique for
accessing matrix data. A key application of this is solving partial
differential equations, where the Laplacian operator and its finite difference
discretization serve as foundational examples. In this paper, we present an
efficient and explicit block encoding method that enhances existing approaches
in key aspects. We detail the construction of the quantum algorithm and
illustrate how it leverages the unique structure of finite difference
discretizations. Furthermore, we analytically derive the scaling of the
sub-normalization factor and of the success probability of the block encoding
with respect to the problem dimension, the grid width of the finite difference
grid and the regularity of the exact solution, and we give resource estimates.

</details>


### [808] [Evidence of Compact Wavefunctions from Quantum-Selected Configuration Interaction](https://arxiv.org/abs/2509.02525)
*Tim Weaving,Angus Mingare,Alexis Ralli,Peter V. Coveney*

Main category: quant-ph

TL;DR: 量子计算机作为配置采样机集成到HPC平台，用于分子电子结构计算，实现了更紧凑的基态波函数表示。


<details>
  <summary>Details</summary>
Motivation: 利用量子和经典硬件的优势，解决分子电子结构问题，实现计算优势。

Method: 提出一种利用随机哈密顿量时间演化和多参考微扰理论的量子选择组态相互作用（QSCI）算法。

Result: 在IQM超导设备上使用42个量子比特计算了SiH4分子的势能曲线，在强相关区域得到了与Heatbath Configuration Interaction相当的能量，但构型空间小200多倍。

Conclusion: QSCI能够比传统启发式方法产生更紧凑的基态波函数表示，并提供了第一个证据。

Abstract: A recent direction in quantum computing for molecular electronic structure
sees the use of quantum devices as configuration sampling machines integrated
within high-performance computing (HPC) platforms. This appeals to the
strengths of both the quantum and classical hardware; where state-sampling is
classically hard, the quantum computer can provide computational advantage in
the selection of high quality configuration subspaces, while the final
molecular energies are evaluated by solving an interaction matrix on HPC and is
therefore not corrupted by hardware noise. In this work, we present an
algorithm that leverages stochastic Hamiltonian time evolution in
Quantum-Selected Configuration Interaction (QSCI), with multireference
perturbation theory capturing missed correlations outside the configuration
subspace. The approach is validated through a hardware demonstration utilising
42 qubits of an IQM superconducting device to calculate the potential energy
curve of the inorganic silane molecule, SiH4 using a 6-31G atomic orbital basis
set, under a stretching of the Si-H bond length. In the regime of strong
correlation we obtain energies comparable to Heatbath Configuration
Interaction, but with a configuration space more than 200 times smaller,
providing the first evidence that QSCI can produce more compact representations
of the ground state wavefunction compared with conventional heuristics. This
result is achieved with a configuration sampling scheme that predicts likely
single and double excitations to generate connected configurations based on the
orbital occupancies of a time-evolved quantum state.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [809] [Curve-based slicer for multi-axis DLP 3D printing](https://arxiv.org/abs/2509.00040)
*Chengkai Dai,Tao Liu,Dezhao Guo,Binzhi Sun,Guoxin Fang,Yeung Yam,Charlie C. L. Wang*

Main category: cs.GR

TL;DR: 提出了一种新颖的基于曲线的切片方法，用于在数字光处理 (DLP) 3D 打印中生成具有动态变化方向的平面层，以解决大悬垂区域和楼梯状伪影等问题，同时保留高分辨率和快速打印速度的优势。通过将切片问题公式化为优化任务，计算参数曲线来定义切片层和模型分区，这些曲线可优化以满足无碰撞运动和无浮动沉积等制造目标。通过机器人多轴 DLP 打印设置的物理实验验证了该方法，证明了优化曲线能够稳健地引导复杂几何形状的光滑、高质量制造。


<details>
  <summary>Details</summary>
Motivation: 解决DLP打印中大悬垂区域和楼梯状伪影问题，同时保留其高分辨率和快速打印速度的优势。

Method: 将切片问题公式化为优化任务，计算参数曲线来定义切片层和模型分区，并通过优化曲线满足无碰撞运动和无浮动沉积等制造目标。

Result: 通过机器人多轴DLP打印设置的物理实验，证明了优化曲线能够稳健地引导复杂几何形状的光滑、高质量制造。

Conclusion: 提出的基于曲线的切片方法能够有效解决DLP打印中的挑战，并实现复杂几何形状的高质量制造。

Abstract: This paper introduces a novel curve-based slicing method for generating
planar layers with dynamically varying orientations in digital light processing
(DLP) 3D printing. Our approach effectively addresses key challenges in DLP
printing, such as regions with large overhangs and staircase artifacts, while
preserving its intrinsic advantages of high resolution and fast printing
speeds. We formulate the slicing problem as an optimization task, in which
parametric curves are computed to define both the slicing layers and the model
partitioning through their tangent planes. These curves inherently define
motion trajectories for the build platform and can be optimized to meet
critical manufacturing objectives, including collision-free motion and
floating-free deposition. We validate our method through physical experiments
on a robotic multi-axis DLP printing setup, demonstrating that the optimized
curves can robustly guide smooth, high-quality fabrication of complex
geometries.

</details>


### [810] [Lightning Fast Caching-based Parallel Denoising Prediction for Accelerating Talking Head Generation](https://arxiv.org/abs/2509.00052)
*Jianzhi Long,Wenhao Sun,Rongcheng Tu,Dacheng Tao*

Main category: cs.GR

TL;DR: 该论文提出了一种针对扩散模型生成Talking Head视频的加速框架，通过缓存静态特征（LightningCP）和解耦前景注意力（DFA）来提高推理速度，同时保持视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在生成Talking Head视频时推理速度慢，限制了其实际应用。现有的加速方法未能利用Talking Head生成特有的时空冗余。本研究旨在解决这些效率低下问题。

Method: 提出了一种特定任务的框架，包含两个关键创新：1. 引入LightningCP，通过缓存静态特征来绕过模型的大部分层，并利用缓存的特征和估计的噪声潜变量并行预测，以绕过顺序采样。2. 提出DFA，通过利用Talking Head视频中的空间解耦来限制注意力计算到动态前景区域，以进一步加速注意力计算。此外，还移除了某些层中的参考特征以获得额外的加速。

Result: 实验证明，所提出的框架显著提高了推理速度，同时保持了视频质量。

Conclusion: 所提出的框架通过LightningCP和DFA等技术，有效解决了扩散模型在Talking Head视频生成中的推理速度问题，实现了加速并保持了视频质量。

Abstract: Diffusion-based talking head models generate high-quality, photorealistic
videos but suffer from slow inference, limiting practical applications.
Existing acceleration methods for general diffusion models fail to exploit the
temporal and spatial redundancies unique to talking head generation. In this
paper, we propose a task-specific framework addressing these inefficiencies
through two key innovations. First, we introduce Lightning-fast Caching-based
Parallel denoising prediction (LightningCP), caching static features to bypass
most model layers in inference time. We also enable parallel prediction using
cached features and estimated noisy latents as inputs, efficiently bypassing
sequential sampling. Second, we propose Decoupled Foreground Attention (DFA) to
further accelerate attention computations, exploiting the spatial decoupling in
talking head videos to restrict attention to dynamic foreground regions.
Additionally, we remove reference features in certain layers to bring extra
speedup. Extensive experiments demonstrate that our framework significantly
improves inference speed while preserving video quality.

</details>


### [811] [Quantum Brush: A quantum computing-based tool for digital painting](https://arxiv.org/abs/2509.01442)
*João S. Ferreira,Arianna Crippa,Astryd Park,Daniel Bultrini,Pierre Fromholz,Roman Lipski,Karl Jansen,James R. Wootton*

Main category: cs.GR

TL;DR: Quantum Brush是一款开源数字绘画工具，利用量子计算生成独特的艺术表达。


<details>
  <summary>Details</summary>
Motivation: 介绍Quantum Brush这款新工具，以及它如何利用量子计算的特性来创造新的艺术风格。

Method: 讨论Quantum Brush包含的四种画笔，以及它们如何将笔触转化为量子算法，并兼容当前的NISQ设备。

Result: 演示了在IQM的Sirius设备上执行这些画笔，证明了其在NISQ设备上的兼容性。

Conclusion: Quantum Brush能够利用量子效应产生新颖的美学，为数字艺术创作开辟了新的可能性。

Abstract: We present Quantum Brush, an open-source digital painting tool that harnesses
quantum computing to generate novel artistic expressions. The tool includes
four different brushes that translate strokes into unique quantum algorithms,
each highlighting a different way in which quantum effects can produce novel
aesthetics. Each brush is designed to be compatible with the current noisy
intermediate-scale quantum (NISQ) devices, as demonstrated by executing them on
IQM's Sirius device.

</details>


### [812] [Evaluate Neighbor Search for Curve-based Vector Field Processing](https://arxiv.org/abs/2509.00180)
*Nguyen Phan,Guoning Chen*

Main category: cs.GR

TL;DR: 该研究评估了两种流行的邻域搜索策略和不同的距离度量在基于点的向量场重建任务和基于输入积分曲线的段显著性估计中的性能。


<details>
  <summary>Details</summary>
Motivation: 由于原始流动行为可能未被积分曲线集完全表示，并且输入积分曲线在空间中可能分布不均，因此流行的邻域搜索策略通常会返回有偏和冗余的邻域段。然而，关于特定邻域搜索策略返回的不同邻域段配置如何影响后续任务的系统性和综合性研究仍然缺乏。

Method: 本研究评估了两种流行的邻域搜索策略结合不同的距离度量在基于点的向量场重建任务和基于输入积分曲线的段显著性估计中的性能。为表征有效的邻域段配置以比较不同的搜索策略，提出了一些度量，如平均邻域距离和均匀性。

Result: 进行了大量的重建测试和显著性计算，以表征邻域段的配置，从而有效比较不同的搜索策略。研究结果揭示了一些部分证实了我们对理想邻域配置的期望的观察结果，同时也揭示了社区所忽略的额外发现。

Conclusion: 该研究提出了度量来表征邻域段的配置，并评估了不同的邻域搜索策略和距离度量在下游任务中的性能。研究结果揭示了关于理想邻域配置的见解，并指出了社区先前忽略的发现。

Abstract: Curve-based representations, particularly integral curves, are often used to
represent large-scale computational fluid dynamic simulations. Processing and
analyzing curve-based vector field data sets often involves searching for
neighboring segments given a query point or curve segment. However, because the
original flow behavior may not be fully represented by the set of integral
curves and the input integral curves may not be evenly distributed in space,
popular neighbor search strategies often return skewed and redundant
neighboring segments. Yet, there is a lack of systematic and comprehensive
research on how different configurations of neighboring segments returned by
specific neighbor search strategies affect subsequent tasks. To fill this gap,
this study evaluates the performance of two popular neighbor search strategies
combined with different distance metrics on a point-based vector field
reconstruction task and a segment saliency estimation using input integral
curves. A large number of reconstruction tests and saliency calculations are
conducted for the study. To characterize the configurations of neighboring
segments for an effective comparison of different search strategies, a number
of measures, like average neighbor distance and uniformity, are proposed. Our
study leads to a few observations that partially confirm our expectations about
the ideal configurations of a neighborhood while revealing additional findings
that were overlooked by the community.

</details>


### [813] [3D-LATTE: Latent Space 3D Editing from Textual Instructions](https://arxiv.org/abs/2509.00269)
*Maria Parelli,Michael Oechsle,Michael Niemeyer,Federico Tombari,Andreas Geiger*

Main category: cs.GR

TL;DR: 面向3D资产编辑的无训练方法，解决2D先验的视图不一致问题，直接在3D扩散模型潜在空间操作，结合3D注意力图、几何感知正则化、傅里叶域谱调制和3D增强精炼，实现高质量、精确、鲁棒的编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的3D资产编辑方法在质量上不如生成模型，主要是因为使用2D先验的方法存在视图不一致的编辑信号。

Method: 提出一种在原生3D扩散模型潜在空间内操作的无训练编辑方法，直接处理3D几何。通过混合生成过程中的3D注意力图和源对象来指导编辑合成，并结合几何感知正则化、傅里叶域谱调制和3D增强精炼步骤。

Result: 该方法在3D资产编辑方面优于先前的方法，能够在各种形状和语义操纵中实现高保真度、精确性和鲁棒性。

Conclusion: 所提出的方法能够实现高质量、精确和鲁棒的3D资产编辑，解决了现有技术中的视图不一致问题。

Abstract: Despite the recent success of multi-view diffusion models for
text/image-based 3D asset generation, instruction-based editing of 3D assets
lacks surprisingly far behind the quality of generation models. The main reason
is that recent approaches using 2D priors suffer from view-inconsistent editing
signals. Going beyond 2D prior distillation methods and multi-view editing
strategies, we propose a training-free editing method that operates within the
latent space of a native 3D diffusion model, allowing us to directly manipulate
3D geometry. We guide the edit synthesis by blending 3D attention maps from the
generation with the source object. Coupled with geometry-aware regularization
guidance, a spectral modulation strategy in the Fourier domain and a refinement
step for 3D enhancement, our method outperforms previous 3D editing methods
enabling high-fidelity, precise, and robust edits across a wide range of shapes
and semantic manipulations.

</details>


### [814] [Locality-Aware Automatic Differentiation on the GPU for Mesh-Based Computations](https://arxiv.org/abs/2509.00406)
*Ahmed H. Mahmoud,Jonathan Ragan-Kelley,Justin Solomon*

Main category: cs.GR

TL;DR: 该系统实现了GPU上三角网格函数的高性能自动微分，通过利用网格能量函数的稀疏性和局部性，实现了快速的梯度和Hessian计算。


<details>
  <summary>Details</summary>
Motivation: 为了在GPU上高效地计算网格函数（如布料模拟、表面参数化、网格平滑和球面流形优化）的一阶和二阶导数，并克服现有方法（如反向模式AD）的内存瓶颈和全局同步问题。

Method: 采用基于每个元素的正向模式微分，将局部计算保留在GPU寄存器或共享内存中，避免了全局计算图的构建和遍历，实现了即时微分。

Result: 在布料模拟、表面参数化、网格平滑和球面流形优化等应用中，相比PyTorch，二阶导数计算速度提高了6.2倍，Hessian-vector乘积计算速度提高了2.76倍。相比Warp、JAX和Dr.JIT，一阶导数计算速度分别提高了6.38倍、2.89倍和1.98倍，并且与手工编写的导数计算性能相当。

Conclusion: 该系统通过采用基于元素的正向模式微分，有效地利用了GPU的并行计算能力和内存结构，实现了在网格函数上的高性能自动微分，显著优于现有主流框架。

Abstract: We present a high-performance system for automatic differentiation (AD) of
functions defined on triangle meshes that exploits the inherent sparsity and
locality of mesh-based energy functions to achieve fast gradient and Hessian
computation on the GPU. Our system is designed around per-element forward-mode
differentiation, enabling all local computations to remain in GPU registers or
shared memory. Unlike reverse-mode approaches that construct and traverse
global computation graphs, our method performs differentiation on the fly,
minimizing memory traffic and avoiding global synchronization. Our programming
model allows users to define local energy terms while the system handles
parallel evaluation, derivative computation, and sparse Hessian assembly. We
benchmark our system on a range of applications--cloth simulation, surface
parameterization, mesh smoothing, and spherical manifold optimization. We
achieve a geometric mean speedup of 6.2x over optimized PyTorch implementations
for second-order derivatives, and 2.76x speedup for Hessian-vector products.
For first-order derivatives, our system is 6.38x, 2.89x, and 1.98x faster than
Warp, JAX, and Dr.JIT, respectively, while remaining on par with hand-written
derivatives.

</details>


### [815] [LatentEdit: Adaptive Latent Control for Consistent Semantic Editing](https://arxiv.org/abs/2509.00541)
*Siyi Liu,Weiming Chen,Yushun Tang,Zhihai He*

Main category: cs.GR

TL;DR: LatentEdit是一个自适应的潜在融合框架，通过动态结合当前潜在编码和从源图像反演的参考潜在编码，实现了高质量、低损耗的图像编辑。它能在保持背景相似性的同时，根据目标提示生成目标内容，并且无需修改模型或复杂的注意力机制，兼容UNet和DiT架构。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在图像编辑中保持背景相似性、速度和内存效率方面的挑战。

Method: 提出LatentEdit，一个自适应潜在融合框架，动态结合当前潜在编码和参考潜在编码。通过选择性保留高相似度、语义重要区域的源特征，并在其他区域根据目标提示生成目标内容，实现精细化、可控的编辑。

Result: LatentEdit在PIE-Bench数据集上实现了保真度和可编辑性的最佳平衡，在8-15步内优于现有技术。其无反演变体将神经网络函数评估次数减半，消除了存储中间变量的需求，提高了实时部署效率。

Conclusion: LatentEdit提供了一种轻量级、即插即用的解决方案，可在不牺牲速度或内存效率的情况下实现高质量的图像编辑，并在保真度和可编辑性方面取得了最优平衡。

Abstract: Diffusion-based Image Editing has achieved significant success in recent
years. However, it remains challenging to achieve high-quality image editing
while maintaining the background similarity without sacrificing speed or memory
efficiency. In this work, we introduce LatentEdit, an adaptive latent fusion
framework that dynamically combines the current latent code with a reference
latent code inverted from the source image. By selectively preserving source
features in high-similarity, semantically important regions while generating
target content in other regions guided by the target prompt, LatentEdit enables
fine-grained, controllable editing. Critically, the method requires no internal
model modifications or complex attention mechanisms, offering a lightweight,
plug-and-play solution compatible with both UNet-based and DiT-based
architectures. Extensive experiments on the PIE-Bench dataset demonstrate that
our proposed LatentEdit achieves an optimal balance between fidelity and
editability, outperforming the state-of-the-art method even in 8-15 steps.
Additionally, its inversion-free variant further halves the number of neural
function evaluations and eliminates the need for storing any intermediate
variables, substantially enhancing real-time deployment efficiency.

</details>


### [816] [IntrinsicReal: Adapting IntrinsicAnything from Synthetic to Real Objects](https://arxiv.org/abs/2509.00777)
*Xiaokang Wei,Zizheng Yan,Zhangyang Xiong,Yiming Hao,Yipeng Qin,Xiaoguang Han*

Main category: cs.GR

TL;DR: 该论文提出了一种名为IntrinsicReal的域适应框架，用于解决真实世界图像的反射率估计问题，该问题因缺乏配对图像和真实反射率值而具有挑战性。现有方法虽然利用了扩散先验，但主要在合成数据集上训练，导致在真实世界数据上泛化性能不佳。IntrinsicReal通过微调IntrinsicAnything并采用一种新颖的双伪标签策略（基于绝对置信度和相对偏好排序）来缩小合成与真实数据之间的域间隙，从而提高了真实世界反射率估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 真实世界图像的反射率估计因缺乏配对图像和真实值而充满挑战。现有基于扩散模型的方法虽然取得了进展，但主要在合成数据集上训练，忽略了合成与真实数据间的域间隙，导致在真实数据上的泛化能力不足。

Method: 提出了一种名为IntrinsicReal的域适应框架，用于弥合合成与真实数据间的域间隙。具体来说，该框架通过微调IntrinsicAnything，并采用一种新颖的双伪标签策略（基于绝对置信度阈值和相对偏好排序）来选择高质量的输出反射率，以适应真实域。该策略受到人类评估的启发，先利用绝对置信度，再结合相对比较来改进次优情况下的伪标签。IntrinsicReal采用了一个新颖的两阶段流程来实现这一目标。

Result: 实验结果表明，IntrinsicReal显著优于现有方法，在合成和真实世界数据集上的反射率估计均取得了最先进的成果。

Conclusion: IntrinsicReal成功地解决了真实世界图像反射率估计中的域间隙问题，通过其新颖的双伪标签策略和两阶段流程，有效适应了真实域，并在多个数据集上实现了最先进的性能。

Abstract: Estimating albedo (a.k.a., intrinsic image decomposition) from single RGB
images captured in real-world environments (e.g., the MVImgNet dataset)
presents a significant challenge due to the absence of paired images and their
ground truth albedos. Therefore, while recent methods (e.g., IntrinsicAnything)
have achieved breakthroughs by harnessing powerful diffusion priors, they
remain predominantly trained on large-scale synthetic datasets (e.g.,
Objaverse) and applied directly to real-world RGB images, which ignores the
large domain gap between synthetic and real-world data and leads to suboptimal
generalization performance. In this work, we address this gap by proposing
IntrinsicReal, a novel domain adaptation framework that bridges the
above-mentioned domain gap for real-world intrinsic image decomposition.
Specifically, our IntrinsicReal adapts IntrinsicAnything to the real domain by
fine-tuning it using its high-quality output albedos selected by a novel dual
pseudo-labeling strategy: i) pseudo-labeling with an absolute confidence
threshold on classifier predictions, and ii) pseudo-labeling using the relative
preference ranking of classifier predictions for individual input objects. This
strategy is inspired by human evaluation, where identifying the highest-quality
outputs is straightforward, but absolute scores become less reliable for
sub-optimal cases. In these situations, relative comparisons of outputs become
more accurate. To implement this, we propose a novel two-phase pipeline that
sequentially applies these pseudo-labeling techniques to effectively adapt
IntrinsicAnything to the real domain. Experimental results show that our
IntrinsicReal significantly outperforms existing methods, achieving
state-of-the-art results for albedo estimation on both synthetic and real-world
datasets.

</details>


### [817] [RealMat: Realistic Materials with Diffusion and Reinforcement Learning](https://arxiv.org/abs/2509.01134)
*Xilong Zhou,Pedro Figueiredo,Miloš Hašan,Valentin Deschaintre,Paul Guerrero,Yiwei Hu,Nima Khademi Kalantari*

Main category: cs.GR

TL;DR: RealMat是一个利用文本到图像模型和自然光照下真实材料照片数据集的扩散模型，用于生成高质量、真实感的材料。


<details>
  <summary>Details</summary>
Motivation: 目前大多数材料生成方法依赖合成数据，这会导致与真实世界材料存在视觉差距；而使用真实数据的方法受限于数据规模和多样性。RealMat旨在解决这些限制，生成更易于访问的高质量3D内容材料。

Method: RealMat首先使用2x2网格排列的合成材料图对预训练的Stable Diffusion XL（SDXL）进行微调，以继承SDXL的真实感并学习合成材料网格的数据分布。然后，通过强化学习（RL）进一步微调模型，并开发了一个基于大规模真实材料图像数据集的真实感奖励函数，以鼓励生成更逼真的材料。

Result: RealMat相较于基线模型和相关工作，提高了生成材料的真实感。

Conclusion: RealMat通过结合文本到图像模型和真实材料数据，并利用强化学习进行优化，能够生成更真实、多样化的材料，解决了现有方法的局限性。

Abstract: Generative models for high-quality materials are particularly desirable to
make 3D content authoring more accessible. However, the majority of material
generation methods are trained on synthetic data. Synthetic data provides
precise supervision for material maps, which is convenient but also tends to
create a significant visual gap with real-world materials. Alternatively,
recent work used a small dataset of real flash photographs to guarantee
realism, however such data is limited in scale and diversity. To address these
limitations, we propose RealMat, a diffusion-based material generator that
leverages realistic priors, including a text-to-image model and a dataset of
realistic material photos under natural lighting. In RealMat, we first finetune
a pretrained Stable Diffusion XL (SDXL) with synthetic material maps arranged
in $2 \times 2$ grids. This way, our model inherits some realism of SDXL while
learning the data distribution of the synthetic material grids. Still, this
creates a realism gap, with some generated materials appearing synthetic. We
propose to further finetune our model through reinforcement learning (RL),
encouraging the generation of realistic materials. We develop a realism reward
function for any material image under natural lighting, by collecting a
large-scale dataset of realistic material images. We show that this approach
increases generated materials' realism compared to our base model and related
work.

</details>


### [818] [HodgeFormer: Transformers for Learnable Operators on Triangular Meshes through Data-Driven Hodge Matrices](https://arxiv.org/abs/2509.01839)
*Akis Nousias,Stavros Nousias*

Main category: cs.GR

TL;DR: Transformer架构在图和网格上的应用通常依赖于昂贵的特征值分解方法来提取位置嵌入。本文提出一种新颖的深度学习层，借鉴离散外代数中的霍奇拉普拉斯算子，通过多头注意力机制学习作用于网格顶点、边和面的离散算子，从而在不进行特征值分解的情况下，在网格分割和分类任务中达到与现有方法相当的性能，并显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer架构在图和网格的形状分析任务中，依赖于传统的注意力层，这些传统注意力层利用了昂贵的特征值分解方法来提取光谱特征和位置嵌入。

Method: 本文提出一种新颖的深度学习层，借鉴离散外代数中的霍奇拉普拉斯算子，通过多头注意力机制学习霍奇矩阵（$\star_0$、$\star_1$和$\star_2$）的近似，从而学习作用于网格顶点、边和面的离散算子家族（$L$）。

Result: 该方法在网格分割和分类任务中实现了与现有方法相当的性能，同时消除了对昂贵的特征值分解运算或复杂预处理操作的需求，提高了计算效率。

Conclusion: 本文提出的基于霍奇拉普拉斯算子的Transformer层是一种计算高效的方法，能够直接学习网格结构，无需进行特征值分解，在网格分析任务中取得了有竞争力的结果。

Abstract: Currently, prominent Transformer architectures applied on graphs and meshes
for shape analysis tasks employ traditional attention layers that heavily
utilize spectral features requiring costly eigenvalue decomposition-based
methods. To encode the mesh structure, these methods derive positional
embeddings, that heavily rely on eigenvalue decomposition based operations,
e.g. on the Laplacian matrix, or on heat-kernel signatures, which are then
concatenated to the input features. This paper proposes a novel approach
inspired by the explicit construction of the Hodge Laplacian operator in
Discrete Exterior Calculus as a product of discrete Hodge operators and
exterior derivatives, i.e. $(L := \star_0^{-1} d_0^T \star_1 d_0)$. We adjust
the Transformer architecture in a novel deep learning layer that utilizes the
multi-head attention mechanism to approximate Hodge matrices $\star_0$,
$\star_1$ and $\star_2$ and learn families of discrete operators $L$ that act
on mesh vertices, edges and faces. Our approach results in a
computationally-efficient architecture that achieves comparable performance in
mesh segmentation and classification tasks, through a direct learning
framework, while eliminating the need for costly eigenvalue decomposition
operations or complex preprocessing operations.

</details>


### [819] [GRMM: Real-Time High-Fidelity Gaussian Morphable Head Model with Learned Residuals](https://arxiv.org/abs/2509.02141)
*Mohit Mendiratta,Mayur Deshmukh,Kartik Teotia,Vladislav Golyanik,Adam Kortylewski,Christian Theobalt*

Main category: cs.GR

TL;DR: GRMM是一个首个全头高斯3D可变形模型，它通过添加残差几何和外观成分来改进基于3DMM的面部模型，以捕捉细节和实现实时渲染，同时在3D面部重建、新视图合成和表情迁移方面超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于PCA的3DMM在分辨率、细节和照片真实感方面存在局限性，而神经体积方法虽然更真实但速度太慢，无法进行交互式使用。最近的基于3DGS的面部模型虽然渲染速度快且质量高，但仅依赖于基于网格的3DMM先验进行表情控制，这限制了它们捕捉细粒度几何、表情和全头覆盖的能力。

Method: GRMM通过在基础3DMM上添加残差几何和外观成分来增强，这些成分可以恢复皱纹、皮肤纹理和发际线等高频细节。它使用粗糙解码器生成顶点级别的网格变形，使用精细解码器表示每个高斯的颜色，并使用轻量级CNN来优化光栅化图像以提高真实感。此外，还引入了EXPRESS-50数据集，包含50个身份的60个对齐表情，以实现高保真度的残差学习。

Result: GRMM能够实现75 FPS的实时渲染，并在单目3D面部重建、新视图合成和表情迁移等任务中，在保真度和表情准确性方面优于现有最先进的方法。

Conclusion: GRMM是首个全头高斯3D可变形模型，它通过引入残差细节和使用EXPRESS-50数据集，解决了现有3DMM和3DGS方法的局限性，实现了高质量、可控的面部编辑和实时性能。

Abstract: 3D Morphable Models (3DMMs) enable controllable facial geometry and
expression editing for reconstruction, animation, and AR/VR, but traditional
PCA-based mesh models are limited in resolution, detail, and photorealism.
Neural volumetric methods improve realism but remain too slow for interactive
use. Recent Gaussian Splatting (3DGS) based facial models achieve fast,
high-quality rendering but still depend solely on a mesh-based 3DMM prior for
expression control, limiting their ability to capture fine-grained geometry,
expressions, and full-head coverage. We introduce GRMM, the first full-head
Gaussian 3D morphable model that augments a base 3DMM with residual geometry
and appearance components, additive refinements that recover high-frequency
details such as wrinkles, fine skin texture, and hairline variations. GRMM
provides disentangled control through low-dimensional, interpretable parameters
(e.g., identity shape, facial expressions) while separately modelling residuals
that capture subject- and expression-specific detail beyond the base model's
capacity. Coarse decoders produce vertex-level mesh deformations, fine decoders
represent per-Gaussian appearance, and a lightweight CNN refines rasterised
images for enhanced realism, all while maintaining 75 FPS real-time rendering.
To learn consistent, high-fidelity residuals, we present EXPRESS-50, the first
dataset with 60 aligned expressions across 50 identities, enabling robust
disentanglement of identity and expression in Gaussian-based 3DMMs. Across
monocular 3D face reconstruction, novel-view synthesis, and expression
transfer, GRMM surpasses state-of-the-art methods in fidelity and expression
accuracy while delivering interactive real-time performance.

</details>


### [820] [Think2Sing: Orchestrating Structured Motion Subtitles for Singing-Driven 3D Head Animation](https://arxiv.org/abs/2509.02278)
*Zikai Huang,Yihan Zhou,Xuemiao Xu,Cheng Xu,Xiaofen Xing,Jing Qin,Shengfeng He*

Main category: cs.GR

TL;DR: Think2Sing是一个基于扩散模型的框架，通过歌词和声学条件生成3D头部动画，解决了现有方法的不足，并引入了运动字幕和多模态数据集。


<details>
  <summary>Details</summary>
Motivation: 现有语音驱动方法在处理歌唱动画时效果不佳，无法捕捉歌唱的情感、韵律和语义，因此需要更精细、更具表现力的动画生成方法。

Method: 提出Think2Sing框架，利用预训练的大型语言模型，结合歌词和声学信息生成3D头部动画。引入运动字幕（通过歌唱思维链推理和声学引导检索生成），并以运动强度预测问题来建模表情动作。

Result: Think2Sing在真实感、表现力和情感保真度方面优于现有技术，并支持用户可控的动画编辑。

Conclusion: Think2Sing成功地生成了高质量的3D头部歌唱动画，解决了现有方法的局限性，并通过引入运动字幕和新颖的推理过程提高了动画的精细度和表现力。

Abstract: Singing-driven 3D head animation is a challenging yet promising task with
applications in virtual avatars, entertainment, and education. Unlike speech,
singing involves richer emotional nuance, dynamic prosody, and lyric-based
semantics, requiring the synthesis of fine-grained, temporally coherent facial
motion. Existing speech-driven approaches often produce oversimplified,
emotionally flat, and semantically inconsistent results, which are insufficient
for singing animation. To address this, we propose Think2Sing, a
diffusion-based framework that leverages pretrained large language models to
generate semantically coherent and temporally consistent 3D head animations,
conditioned on both lyrics and acoustics. A key innovation is the introduction
of motion subtitles, an auxiliary semantic representation derived through a
novel Singing Chain-of-Thought reasoning process combined with acoustic-guided
retrieval. These subtitles contain precise timestamps and region-specific
motion descriptions, serving as interpretable motion priors. We frame the task
as a motion intensity prediction problem, enabling finer control over facial
regions and improving the modeling of expressive motion. To support this, we
create a multimodal singing dataset with synchronized video, acoustic
descriptors, and motion subtitles, enabling diverse and expressive motion
learning. Extensive experiments show that Think2Sing outperforms
state-of-the-art methods in realism, expressiveness, and emotional fidelity,
while also offering flexible, user-controllable animation editing.

</details>


### [821] [Unifi3D: A Study on 3D Representations for Generation and Reconstruction in a Common Framework](https://arxiv.org/abs/2509.02474)
*Nina Wiedemann,Sainan Liu,Quentin Leboutet,Katelyn Gao,Benjamin Ummenhofer,Michael Paulitsch,Kai Yuan*

Main category: cs.GR

TL;DR: 该论文提出了一个统一的3D表示评估框架，用于在重建和生成任务中评估不同3D表示（如神经辐射场、有符号距离函数、点云、八叉树等）的性能，并分析了数据预处理、网格重建、自动编码器压缩和生成等环节的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 随着3D生成研究的兴起，需要一个统一的框架来评估多种3D表示方法（如体素网格、神经辐射场、有符号距离函数、点云、八叉树等）在重建和生成任务上的性能，因为它们各有优缺点。

Method: 提出并实现了一个统一的评估框架，该框架能够基于质量、计算效率和泛化性能对不同的3D表示进行比较。该框架还用于分析3D生成流程的各个步骤，包括预处理、网格重建、自动编码器压缩和生成。

Result: 研究结果表明，重建误差对整体性能有显著影响，强调了联合评估生成和重建的重要性。该研究还为选择适合不同应用的3D模型提供了见解，有助于开发更强大、更具应用针对性的3D生成解决方案。

Conclusion: 重建误差是影响3D生成性能的关键因素，应在评估中同时考虑生成和重建。该框架和发现有助于指导3D生成领域的研究和应用，促进更优3D模型的选择和开发。

Abstract: Following rapid advancements in text and image generation, research has
increasingly shifted towards 3D generation. Unlike the well-established
pixel-based representation in images, 3D representations remain diverse and
fragmented, encompassing a wide variety of approaches such as voxel grids,
neural radiance fields, signed distance functions, point clouds, or octrees,
each offering distinct advantages and limitations. In this work, we present a
unified evaluation framework designed to assess the performance of 3D
representations in reconstruction and generation. We compare these
representations based on multiple criteria: quality, computational efficiency,
and generalization performance. Beyond standard model benchmarking, our
experiments aim to derive best practices over all steps involved in the 3D
generation pipeline, including preprocessing, mesh reconstruction, compression
with autoencoders, and generation. Our findings highlight that reconstruction
errors significantly impact overall performance, underscoring the need to
evaluate generation and reconstruction jointly. We provide insights that can
inform the selection of suitable 3D models for various applications,
facilitating the development of more robust and application-specific solutions
in 3D generation. The code for our framework is available at
https://github.com/isl-org/unifi3d.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [822] [Supervision of a Photovoltaic/Batteries System for Stand Alone Applications](https://arxiv.org/abs/2509.00003)
*Djamila Rekioua,Saloua Belaid,Pierre-Olivier Logerais,Toufik Rekioua,Zahra Mokrani,Khoudir Kakouche,Adel Oubelaid,Faika Zaouche*

Main category: eess.SY

TL;DR: 本文提出了一种用于孤立光伏系统的功率管理控制（PMC），以优化系统性能并确保电池安全。


<details>
  <summary>Details</summary>
Motivation: 研究孤立光伏系统，重点在于通过功率管理控制（PMC）实现最优运行和对电池的保护。

Method: 采用功率管理控制（PMC）对孤立光伏系统进行控制，PMC能防止电池过放和过载，并维持对负载的持续供电。该方法易于实现且计算负担小。文中提到的系统将电池和光伏板连接到双向转换器，允许根据天气条件为电池充电或放电。

Result: 模拟结果表明，所提出的控制策略在两个不同的配置（profile）下均表现出良好的性能。

Conclusion: 所提出的PMC是一种有效且易于实施的控制策略，能够优化孤立光伏系统的性能并保护电池。

Abstract: Our paper is focused on optimal and control of an isolated photovoltaic
system with batteries. The control is made by the application of a power
management control (PMC). Batteries are kept safe from deep discharges and
overloads by the PMC, maintaining a continuous supply to the load. The ease,
with which this method can be implemented, as well as its effectiveness without
imposing a large computing strain on the user, is noteworthy. The batteries and
PV panels in the system under study are connected to a bidirectional converter
enabling the batteries to be charged and drained in accordance with weather
conditions. The simulation results, clearly highlight good performance of the
proposed control across two different profiles.

</details>


### [823] [Optimized Renewable Energy Planning MDP for Socially-Equitable Electricity Coverage in the US](https://arxiv.org/abs/2509.00008)
*Riya Kinnarkar,Mansur Arief*

Main category: eess.SY

TL;DR: 研究提出了一种基于马尔可夫决策过程（MDP）的框架，用于优化可再生能源分配，并解决电力分配中的社会公平问题，旨在实现公平的清洁能源转型。


<details>
  <summary>Details</summary>
Motivation: 传统电网基础设施在整合可再生能源和解决能源接入不平等问题方面存在显著障碍，低收入社区遭受更长时期的停电。本研究旨在优化可再生能源分配，解决电力分配中的社会公平问题。

Method: 开发了一个马尔可夫决策过程（MDP）框架，该框架考虑了预算限制、能源需求变异性和八个主要美国城市的社会脆弱性指标，以评估公平的清洁能源转型的政策替代方案。

Result: 与随机分配、贪婪可再生能源扩张和专家启发式方法等基线策略相比，基于MDP的方法可以实现32.9%的可再生能源渗透率，同时将服务不足的低收入人口减少55%。专家策略获得了最高的奖励，而蒙特卡洛树搜索基线则以较低的预算利用率提供了有竞争力的性能。

Conclusion: 公平分配清洁能源资源可以在不牺牲整体系统性能的情况下实现，并为将社会公平考虑与气候目标和包容性清洁电力基础设施接入相结合提供了途径。

Abstract: Traditional power grid infrastructure presents significant barriers to
renewable energy integration and perpetuates energy access inequities, with
low-income communities experiencing disproportionately longer power outages.
This study develops a Markov Decision Process (MDP) framework to optimize
renewable energy allocation while explicitly addressing social equity concerns
in electricity distribution. The model incorporates budget constraints, energy
demand variability, and social vulnerability indicators across eight major U.S.
cities to evaluate policy alternatives for equitable clean energy transitions.
Numerical experiments compare the MDP-based approach against baseline policies
including random allocation, greedy renewable expansion, and expert heuristics.
Results demonstrate that equity-focused optimization can achieve 32.9%
renewable energy penetration while reducing underserved low-income populations
by 55% compared to conventional approaches. The expert policy achieved the
highest reward, while the Monte Carlo Tree Search baseline provided competitive
performance with significantly lower budget utilization, demonstrating that
fair distribution of clean energy resources is achievable without sacrificing
overall system performance and providing ways for integrating social equity
considerations with climate goals and inclusive access to clean power
infrastructure.

</details>


### [824] [Design and Testing of a Low-Cost 3D-Printed Servo Gimbal for Thrust Vector Control in Model Rockets](https://arxiv.org/abs/2509.00061)
*Ekansh Singh*

Main category: eess.SY

TL;DR: 本文介绍了一种低成本、3D打印、伺服电机驱动的二维万向节，用于模型火箭的推力矢量控制。


<details>
  <summary>Details</summary>
Motivation: 传统的推力矢量控制系统成本高昂且学生和业余爱好者难以接触，因此需要开发低成本、易于实现的替代方案。

Method: 设计并制造了一个由3D打印部件和伺服电机组成的二维万向节，并使用高速摄像机和Fusion 360参数模拟来评估其性能，包括角度偏转、伺服响应时间和结构耐久性。

Result: 实验结果表明，该万向节在±5度范围内实现了稳定的驱动，平均响应时间约为44.5毫秒。然而，也发现伺服电机疲劳和销钉连接在长期负载下存在应力限制。

Conclusion: 该项目证明了学生可及的推力矢量控制系统的可行性，并为其在STEM教育和实验航空航天研究中作为可复制平台提供了潜力。

Abstract: Thrust vector control (TVC) is a key mechanism for stabilizing rockets during
flight, yet conventional implementations remain costly and technically
inaccessible to students and hobbyists. This paper presents the design,
fabrication, and testing of a low-cost, 3D-printed, servo-driven
two-dimensional gimbal developed for model rocket applications. The gimbal
underwent more than 60 CAD iterations, with servo selection guided by torque,
response time, and stability requirements. A high-speed camera and Fusion 360
parameter simulations were used to emulate dynamic instability, enabling
evaluation of angular deflection, servo responsiveness, and structural
durability. The results demonstrated stable actuation within plus or minus 5
degrees, with response times on the average order of 44.5 ms, while limitations
included servo fatigue and pin-joint stress under extended loading. The project
highlights the feasibility of student-accessible thrust vector control systems
and their potential as a reproducible platform for STEM education and
experimental aerospace research.

</details>


### [825] [Comparative Techno-economic Assessment of Wind-Powered Green Hydrogen Pathways](https://arxiv.org/abs/2509.00136)
*Merlinda Andoni,Benoit Couraud,Valentin Robu,Jamie Blanche,Sonam Norbu,Si Chen,Satria Putra Kanugrahan,David Flynn*

Main category: eess.SY

TL;DR: 绿色氢能的部署受高昂生产成本的限制，该成本取决于生产途径、系统配置、资产位置以及与电力市场和监管框架的相互作用。该研究开发了一个基于氢能均化成本（LCOH）评估的综合技术经济框架，以比较英国不同的部署策略。研究结果表明，电力成本是LCOH的主要贡献者，其次是电解槽成本。该研究强调了地点、市场安排和可再生能源（RES）与氢能投资者之间的控制策略在绿色氢能系统部署的经济可行性中的关键作用。支持低成本电力和优化部署的政策可以降低LCOH，提高绿色氢能的经济竞争力。


<details>
  <summary>Details</summary>
Motivation: 在全球对有韧性能源系统的兴趣日益浓厚之际，绿色氢能被认为是净零转型的重要组成部分，但其部署受到高昂生产成本的限制。

Method: 该研究开发了一个基于氢能均化成本（LCOH）评估的综合技术经济框架，以比较英国不同的部署策略。研究人员将该框架应用于5种风力-电解槽系统的配置，确定最具成本效益的商业案例，并对关键经济参数进行了敏感性分析。

Result: 研究结果表明，电力成本是LCOH的主要贡献者，其次是电解槽成本。研究强调了地点、市场安排和可再生能源（RES）与氢能投资者之间的控制策略在绿色氢能系统部署的经济可行性中的关键作用。

Conclusion: 支持低成本电力和优化部署的政策可以降低LCOH，提高绿色氢能的经济竞争力。

Abstract: Amid global interest in resilient energy systems, green hydrogen is
considered vital to the net-zero transition, yet its deployment remains limited
by high production cost. The cost is determined by the its production pathway,
system configuration, asset location, and interplay with electricity markets
and regulatory frameworks. To compare different deployment strategies in the
UK, we develop a comprehensive techno-economic framework based on the Levelised
Cost of Hydrogen (LCOH) assessment. We apply this framework to 5 configurations
of wind-electrolyser systems, identify the most cost-effective business cases,
and conduct a sensitivity analysis of key economic parameters. Our results
reveal that electricity cost is the dominant contributor to LCOH, followed by
the electrolyser cost. Our work highlights the crucial role that location,
market arrangements and control strategies among RES and hydrogen investors
play in the economic feasibility of deploying green hydrogen systems. Policies
that subsidise low-cost electricity access and optimise deployment can lower
LCOH, enhancing the economic competitiveness of green hydrogen.

</details>


### [826] [Spatio-Temporal Life Cycle Analysis of Electrolytic H2 Production in Australia under Time-Varying CO2 Management Schemes](https://arxiv.org/abs/2509.00175)
*Niraj Gohil,Alexander Franke,Nawshad Haque,Amro M. Farid*

Main category: eess.SY

TL;DR: 通过利用实时电网数据和税收抵免，优化制氢过程以提高可持续性和经济性。


<details>
  <summary>Details</summary>
Motivation: 应对气候变化，需要向可持续能源转型，制氢（尤其是电解水制氢）是关键的低碳能源解决方案。

Method: 利用电力地图数据库的实时数据和澳大利亚能源市场运营商（AEMO）的实时电价数据，动态调整制氢输出，以最小化排放和生产成本，并结合氢税收抵免来提高成本效益。采用生命周期评估（LCA）框架评估环境影响。

Result: 动态、实时运行结合财政激励措施，为提高制氢的可持续性和经济可行性提供了一条有前景的途径。

Conclusion: 动态、实时运行结合财政激励措施，为提高制氢的可持续性和经济可行性提供了一条有前景的途径。

Abstract: The transition to sustainable energy is critical for addressing global
climate change. Hydrogen production, particularly via electrolysis, has emerged
as a key solution, offering the potential for low-carbon energy across various
sectors. This paper presents a novel approach to enhancing hydrogen production
by aligning it with periods of low-carbon intensity on the electricity grid.
Leveraging real-time data from the Electricity Mapping database and real-time
electricity cost data from the AEMO database, the model dynamically adjusts
hydrogen output to minimize both emissions and production costs. Furthermore,
the integration of hydrogen tax credits significantly enhances
cost-effectiveness, offering a viable pathway for widespread adoption. A
comprehensive Life Cycle Assessment (LCA) framework is employed to assess the
environmental impacts, emphasizing the need for real-time data incorporation to
more accurately reflect hydrogen production's carbon footprint. The study
concludes that dynamic, real-time operation, coupled with financial incentives,
provides a promising method to enhance the sustainability and economic
viability of hydrogen production.

</details>


### [827] [Two-Stage Mechanism Design for Electric Vehicle Charging with Day-Ahead Reservations](https://arxiv.org/abs/2509.00270)
*Pan-Yang Su,Yi Ju,Scott Moura,Shankar Sastry*

Main category: eess.SY

TL;DR: The paper analyzes charging mechanisms for electric vehicles (EVs) in day-ahead and real-time markets. It compares different mechanisms based on properties like incentive compatibility, efficiency, reservation awareness, and budget balance. The paper finds that VCG mechanisms have drawbacks and proposes a posted-price mechanism, which is common in real-world systems but lacks efficiency guarantees. To improve efficiency, a VCG auction is suggested for the day-ahead market to guide reserve prices in the real-time market, leading to efficient outcomes when EV valuations are correlated.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore and compare different mechanisms for managing electrical vehicle (EV) charging sessions in day-ahead and real-time markets, considering properties like incentive compatibility, efficiency, reservation awareness, and budget balance, to find a mechanism that resolves issues and potentially improves efficiency.

Method: The paper uses a general two-period model for EV charging. It analyzes candidate mechanisms for the day-ahead and real-time markets, evaluating them against normative properties. Specifically, it examines two variants of the VCG mechanism and proposes a posted-price mechanism. To enhance efficiency, it suggests using a VCG auction in the day-ahead market to influence real-time market reserve prices.

Result: Two VCG variants were found to be either not reservation-aware or not budget-balanced. A proposed posted-price mechanism satisfies incentive compatibility, reservation awareness, and budget balance but lacks efficiency guarantees. When EV valuations are highly correlated, a VCG auction in the day-ahead market improves the efficiency of the proposed approach.

Conclusion: The paper concludes that while a posted-price mechanism can address issues in EV charging markets, it may lack efficiency. However, by incorporating a VCG auction in the day-ahead market, efficiency can be significantly improved, especially when EV valuations are correlated.

Abstract: We propose a general two-period model where electrical vehicles (EVs) can
reserve charging sessions in the day-ahead market and swap them in the
real-time market. Under the model, we explore several candidate mechanisms for
running the two markets, compared using several normative properties such as
incentive compatibility, efficiency, reservation awareness, and budget balance.
Specifically, reservation awareness is the only property coupling the two
markets and dictates that an EV will not get a lower utility by joining the
real-time market. Focusing on the real-time market, we show that two variants
of the classical Vickrey-Clarke-Groves (VCG) mechanism do not satisfy all the
proposed properties; specifically, one is not reservation-aware, while the
other is not budget-balanced. Moreover, we show that no mechanism satisfies
some combinations of the properties. Then, we propose to use a posted-price
mechanism to resolve the issue, which turns out to be the dynamic pricing
mechanism adopted in many real-world systems. The proposed mechanism has no
efficiency guarantee but satisfies all the other properties. To improve
efficiency, we propose to use a VCG auction in the day-ahead market that guides
the reserve prices in the real-time market. When EVs' valuations in the two
markets are highly correlated, the proposed approach results in highly
efficient outcomes.

</details>


### [828] [High-Power Wide-Bandwidth High-Quality Modular Pulse Synthesizer with Adaptive Voltage Asymmetry in Medical Power Electronics](https://arxiv.org/abs/2509.00291)
*Jinshui Zhang,Stefan M. Goetz*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Noninvasive brain stimulation can write signals into neurons but requires
power electronics with exceptionally high power in the mega-volt-ampere range
and kilohertz usable bandwidth. Whereas oscillator circuits offered only one or
very few pulse shapes, modular cascaded power electronics solved a
long-standing problem for the first time and enabled arbitrary software-based
synthesis of the temporal shape of stimuli. However, synthesizing arbitrary
stimuli with a high output quality requires a large number of modules. We
propose an alternative solution that achieves high-resolution pulse shaping
with fewer modules by implementing high-power wide-bandwidth voltage asymmetry.
Rather than equal voltage steps, our system strategically assigns different
voltages to each module to achieve a near-exponential improvement in
resolution. The module voltage sequence does also not use just a simple binary
pattern other work might suggest but adapts it to the output. Additionally, we
introduce a switched-capacitor charging mechanism that allows the modules to
charge to different voltages through a single dc power supply. We validated our
design in a head-to-head comparison with the state of the art on experimental
prototypes. Our three-module prototype reduces total voltage distortion by
13.4% compared to prior art with three modules, and by 4.5% compared to prior
art with six -- twice as many -- modules. This paper is the first asymmetric
multilevel circuit as a high-precision high-power synthesizer, as well as the
first to adaptively optimize asymmetric voltage sequence in modular power
electronics.

</details>


### [829] [A Layered Control Perspective on Legged Locomotion: Embedding Reduced Order Models via Hybrid Zero Dynamics](https://arxiv.org/abs/2509.00294)
*Sergio A. Esteban,Max H. Cohen,Adrian B. Ghansah,Aaron D. Ames*

Main category: eess.SY

TL;DR: 该论文提出了一种分层控制方法，将降维模型（ROM）和全阶模型（FOM）相结合，用于机器人行走步态的合成。


<details>
  <summary>Details</summary>
Motivation: 然而，基于ROM的方法缺乏对稳定性的形式化保证，而基于FOM的方法（如混合零动力学）则可以提供这种保证。本研究旨在统一这两种方法。

Method: 通过分层控制的视角，建立ROM在FOM的混合动力学上实现稳定行走的前提条件。具体来说，给定一个ROM，论文合成了编码ROM行为的零动力学流形，并合成了控制器驱动FOM达到该流形，从而实现混合零动力学。

Result: 证明了ROM中稳定的周期轨道意味着FOM的混合零动力学具有输入状态稳定性（ISS），进而保证了FOM动力学的稳定性。该结果通过在线性倒立摆ROM和五连杆平面行走FOM的仿真得到了验证。

Conclusion: 该研究成功地将ROM的效率和FOM的稳定性保证相结合，为机器人行走步态的合成提供了一种更可靠的方法。

Abstract: Reduced-order models (ROMs) provide a powerful means of synthesizing dynamic
walking gaits on legged robots. Yet this approach lacks the formal guarantees
enjoyed by methods that utilize the full-order model (FOM) for gait synthesis,
e.g., hybrid zero dynamics. This paper aims to unify these approaches through a
layered control perspective. In particular, we establish conditions on when a
ROM of locomotion yields stable walking on the full-order hybrid dynamics. To
achieve this result, given an ROM we synthesize a zero dynamics manifold
encoding the behavior of the ROM -- controllers can be synthesized that drive
the FOM to this surface, yielding hybrid zero dynamics. We prove that a stable
periodic orbit in the ROM implies an input-to-state stable periodic orbit of
the FOM's hybrid zero dynamics, and hence the FOM dynamics. This result is
demonstrated in simulation on a linear inverted pendulum ROM and a 5-link
planar walking FOM.

</details>


### [830] [A Quantum-Compliant Formulation for Network Epidemic Control](https://arxiv.org/abs/2509.00337)
*Lorenzo Zino,Mattia Boggio,Deborah Volpe,Giacomo Orlandi,Giovanna Turvani,Carlo Novara*

Main category: eess.SY

TL;DR: 通过隔离一个或多个地点来控制传染病的传播，以 QUBO 形式提出问题，并利用量子计算解决。


<details>
  <summary>Details</summary>
Motivation: 控制传染病在网络上的传播，需要在减轻医疗系统负担、社会经济成本和干预措施之间进行权衡。

Method: 通过移除网络链接来模拟隔离措施，并将控制问题转化为二次无约束二元优化（QUBO）问题，然后利用量子计算解决。

Result: 提出了一种基于 QUBO 的控制策略，该策略能够有效地解决传染病传播控制问题。

Conclusion: 量子计算在解决传染病传播控制这一 NP 难问题上具有巨大潜力。

Abstract: We deal with controlling the spread of an epidemic disease on a network by
isolating one or multiple locations by banning people from leaving them. To
this aim, we build on the susceptible-infected-susceptible and the
susceptible-infected-removed discrete-time network models, encapsulating a
control action that captures mobility bans via removing links from the network.
Then, we formulate the problem of optimally devising a control policy based on
mobility bans that trades-off the burden on the healthcare system and the
social and economic costs associated with interventions. The binary nature of
mobility bans hampers the possibility to solve the control problem with
standard optimization methods, yielding a NP-hard problem. Here, this is
tackled by deriving a Quadratic Unconstrained Binary Optimization (QUBO)
formulation of the control problem, and leveraging the growing potentialities
of quantum computing to efficiently solve it.

</details>


### [831] [Using Gaussian Mixtures to Model Evolving Multi-Modal Beliefs Across Social Media](https://arxiv.org/abs/2509.01123)
*Yijun Chen,Farhad Farokhi,Yutong Bu,Nicholas Kah Yean Low,Jarra Horstman,Julian Greentree,Robin Evans,Andrew Melatos*

Main category: eess.SY

TL;DR: We use Gaussian mixtures to model opinion dynamics on social networks, considering both Bayesian updates from external factors and non-Bayesian mixing from internal interactions. This model captures multi-modal beliefs and opinion uncertainty, and we investigate the impact of 'stubborn' individuals on information flow, defining a new centrality measure.


<details>
  <summary>Details</summary>
Motivation: To model the formation and evolution of multi-modal beliefs and opinion uncertainty across social networks, capturing rich behavioral dynamics while maintaining interpretability and simplicity.

Method: Utilizing Gaussian mixtures to model opinion dynamics, incorporating Bayesian belief updates for exogenous factors (signals) and non-Bayesian mixing dynamics for endogenous factors (social interactions). Preliminary results investigate the effect of stubborn individuals (social influencers).

Result: Preliminary results on opinion formation and uncertainty demonstrate the effect of stubborn individuals, leading to a notion of centrality based on an individual's ability to disrupt information flow.

Conclusion: The Gaussian mixture model effectively captures multi-modal opinion dynamics and opinion uncertainty. Stubborn individuals can significantly influence information flow, and a new centrality measure can be defined based on this disruptive capability.

Abstract: We use Gaussian mixtures to model formation and evolution of multi-modal
beliefs and opinion uncertainty across social networks. In this model, opinions
evolve by Bayesian belief update when incorporating exogenous factors (signals
from outside sources, e.g., news articles) and by non-Bayesian mixing dynamics
when incorporating endogenous factors (interactions across social media). The
modeling enables capturing the richness of behavior observed in multi-modal
opinion dynamics while maintaining interpretability and simplicity of scalar
models. We present preliminary results on opinion formation and uncertainty to
investigate the effect of stubborn individuals (as social influencers). This
leads to a notion of centrality based on the ease with which an individual can
disrupt the flow of information across the social network.

</details>


### [832] [Solving Optimal Power Flow using a Variational Quantum Approach](https://arxiv.org/abs/2509.00341)
*Thinh Viet Le,Mark M. Wilde,Vassilis Kekatos*

Main category: eess.SY

TL;DR: We propose a quantum computing approach to solve the Optimal Power Flow (OPF) problem, a complex optimization task in electric power systems. Our method encodes problem variables into quantum circuits and uses a hybrid quantum-classical approach to find solutions, demonstrating high-quality results on a standard power system model.


<details>
  <summary>Details</summary>
Motivation: Modern power grids present scalability and optimality challenges for the Optimal Power Flow (OPF) problem, which is a large-scale, non-convex optimization problem. This work aims to address these challenges by proposing a novel quantum computing paradigm.

Method: The proposed method encodes primal and dual variables into parameterized quantum circuits (PQCs). The Lagrangian function is formulated as scaled expectations of quantum observables. A hybrid approach is used to find saddle points of the Lagrangian by estimating gradients with PQCs and updating parameters classically using a primal-dual method. Observables are measured efficiently by permuting primal variables into a banded form.

Result: Numerical tests on the IEEE 57-node power system using a simulator show that the proposed doubly variational quantum framework can successfully find high-quality solutions for the OPF problem.

Conclusion: The developed doubly variational quantum framework effectively solves the OPF problem and has broader applicability to other complex optimization problems, including conic programs, problems on sparse graphs, and training quantum machine learning models with constraints.

Abstract: The optimal power flow (OPF) is a large-scale optimization problem that is
central in the operation of electric power systems. Although it can be posed as
a nonconvex quadratically constrained quadratic program, the complexity of
modern-day power grids raises scalability and optimality challenges. In this
context, this work proposes a variational quantum paradigm for solving the OPF.
We encode primal variables through the state of a parameterized quantum circuit
(PQC), and dual variables through the probability mass function associated with
a second PQC. The Lagrangian function can thus be expressed as scaled
expectations of quantum observables. An OPF solution can be found by
minimizing/maximizing the Lagrangian over the parameters of the first/second
PQC. We pursue saddle points of the Lagrangian in a hybrid fashion. Gradients
of the Lagrangian are estimated using the two PQCs, while PQC parameters are
updated classically using a primal-dual method. We propose permuting primal
variables so that OPF observables are expressed in a banded form, allowing them
to be measured efficiently. Numerical tests on the IEEE 57-node power system
using Pennylane's simulator corroborate that the proposed doubly variational
quantum framework can find high-quality OPF solutions. Although showcased for
the OPF, this framework features a broader scope, including conic programs with
numerous variables and constraints, problems defined over sparse graphs, and
training quantum machine learning models to satisfy constraints.

</details>


### [833] [A Novel Decoupled LVRT Control Strategy for Transient Voltage Stability Enhancement of IBRs Using Voltage-Angle Coupling Analysis](https://arxiv.org/abs/2509.00354)
*Fangyuan Sun,Ruisheng Diao,Ruiyuan Zeng,Jing Zhang,Jianguo Qian*

Main category: eess.SY

TL;DR: 随着并网逆变器（IBRs）渗透率的快速增长，并网逆变器（GFL）在低电压穿越（LVRT）控制下的电压支撑能力对电力系统的瞬态电压稳定性有显著影响。现有的LVRT通过调节q轴电流来注入无功功率。然而，在大型干扰下，锁相环（PLL）误差会破坏q轴电流和无功功率之间的比例关系，导致IBRs实际无功功率注入的偏差。此外，由PLL相位和LVRT决定的IBRs电流变化也直接影响瞬态电压。为了解决这个问题，本文首先分析了PLL误差在LVRT控制下对有功功率和无功功率注入的具体影响。此外，通过结合LVRT和PLL动力学，揭示了由电压角度耦合引起的电压问题（过电压、低电压和直流侧过电压）的机制。还通过电压-向量-三角形图获得了这些电压稳定问题发生的具体场景。最后，提出了一种功率角解耦的LVRT控制，以消除电压角度耦合的影响。最后，通过案例研究验证了解耦LVRT的机制分析和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的低电压穿越（LVRT）控制在并网逆变器（IBRs）渗透率快速增长的背景下，由于锁相环（PLL）误差的影响，可能导致无功功率注入偏差和瞬态电压问题，影响电力系统的瞬态电压稳定性。

Method: 首先分析了PLL误差在LVRT控制下对有功功率和无功功率注入的具体影响。其次，结合LVRT和PLL动力学，揭示了电压角度耦合引起的过电压、低电压和直流侧过电压的产生机制，并通过电压-向量-三角形图确定了发生场景。最后，提出了一种功率角解耦的LVRT控制策略。

Result: 分析了PLL误差对IBRs有功功率和无功功率注入的影响，揭示了电压角度耦合引起的电压问题（过电压、低电压和直流侧过电压）的机制，并提出了功率角解耦的LVRT控制策略。该策略通过了案例研究的验证。

Conclusion: 所提出的功率角解耦LVRT控制策略能够有效消除电压角度耦合对IBRs有功功率和无功功率注入的影响，解决因PLL误差引起的瞬态电压问题，从而提高电力系统的瞬态电压稳定性。

Abstract: With the fast-increasing penetration of inverter-based resources (IBRs), the
voltage support capability of the grid following (GFL) IBRs under low voltage
ride through (LVRT) control significantly influences the transient voltage
stability of the power system. The existing LVRT adjusts the q-axis current to
regulate reactive power injection. However, under a large disturbance, the
phase-locked loop (PLL) error invalidates the proportional relationship between
the q-axis current and reactive power, consequently causing deviation in the
actual reactive power injection of the IBR. Besides, the variation of IBR
current, determined by the PLL phase and LVRT, also directly influences the
transient voltage. To address this issue, the specific influence of PLL error
on active and reactive power injection is first analyzed under LVRT control. In
addition, by combining the LVRT and PLL dynamics, the mechanisms of three
voltage problems caused by voltage angle coupling are revealed. overvoltage,
low voltage, and DC-side overvoltage. The specific scenarios in which these
voltage stability problems occur are also obtained by the
voltage-vector-triangle graphic. Furthermore, a power angle decoupled LVRT
control is proposed to eliminate the influence of voltage angle coupling.
Finally, the mechanism analysis and effectiveness of the decoupled LVRT are
verified in the case study.

</details>


### [834] [Computation of Feasible Assume-Guarantee Contracts: A Resilience-based Approach](https://arxiv.org/abs/2509.01832)
*Negar Monir,Youssef Ait Si,Ratnangshu Das,Pushpak Jagtap,Adnane Saoud,Sadegh Soudjani*

Main category: eess.SY

TL;DR: 提出一个基于韧性的框架，用于计算可行的假设-保证契约，以确保互联离散时间系统中时序规范的满足。模型将互联效应视为结构化扰动。


<details>
  <summary>Details</summary>
Motivation: 在互联离散时间系统中，需要一种方法来确保时序规范的满足，并考虑到互联效应的影响。

Method: 使用韧性度量（即局部规范成立下的最大扰动）来迭代地细化子系统间的假设和保证。对于两个子系统，证明了正确性、保证的单调细化以及所得假设在球状集内的最大性。此外，将该方法扩展到具有加权组合互联效应的L子系统的一般网络。

Result: 在 the linear systems 上满足了有限时间安全、精确时间可达性和有限时间可达性规范，在 the nonlinear systems 上满足了通用有限时间规范。通过数值线性示例和非线性直流微电网案例研究进行了演示。

Conclusion: 该框架通过组合推理验证了时序逻辑规范，并展示了其在处理线性与非线性系统中的影响。

Abstract: We propose a resilience-based framework for computing feasible
assume-guarantee contracts that ensure the satisfaction of temporal
specifications in interconnected discrete-time systems. Interconnection effects
are modeled as structured disturbances. We use a resilience metric, the maximum
disturbance under which local specifications hold, to refine assumptions and
guarantees across subsystems iteratively. For two subsystems, we demonstrate
correctness, monotone refinement of guarantees, and that the resulting
assumptions are maximal within ball-shaped sets. Additionally, we extend our
approach to general networks of L subsystems using weighted combinations of
interconnection effects. We instantiate the framework on linear systems by
meeting finite-horizon safety, exact-time reachability, and finite-time
reachability specifications, and on nonlinear systems by fulfilling general
finite-horizon specifications. Our approach is demonstrated through numerical
linear examples, and a nonlinear DC Microgrid case study, showcasing the impact
of our framework in verifying temporal logic specifications with compositional
reasoning.

</details>


### [835] [Improved PLL Design for Transient Stability Enhancement of Grid Following Converters Based on Lyapunov Method](https://arxiv.org/abs/2509.00489)
*Fangyuan Sun,Ruisheng Diao,Ruiyuan Zeng,Junjie Li,Wangqianyun Tang*

Main category: eess.SY

TL;DR: 该论文提出了一种改进的锁相环（PLL）设计，通过引入重置控制来增强并网逆变器（GFL）在电网干扰下的瞬态稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决并网逆变器在电网大扰动下，相位和频率的波动可能导致的失步（LOS）问题，并提出一种控制方法来增强瞬态稳定性。

Method: 首先分析了GFL逆变器的稳定性域（SD），识别出三种不同的SD形式。然后，基于这三种SD形式的特点，提出了两种PLL重置方法：omega重置和omega&delta重置。接着，为了获得PLL重置控制的触发条件，基于近似法、Zubov法和解析轨迹反演法三种方法构建了GFL逆变器的Lyapunov函数。最后，分析了三种Lyapunov方法的估计精度，并通过单机和多机仿真验证了PLL重置控制的有效性。

Result: 所提出的PLL重置控制方法能够有效增强GFL逆变器的瞬态稳定性，防止失步。三种Lyapunov函数构建方法均能有效避免PLL动态负阻尼问题，并且在不同场景下验证了方法的有效性。

Conclusion: 通过改进PLL设计并引入重置控制，可以显著提高GFL逆变器在电网干扰下的鲁棒性和稳定性。所提出的基于Lyapunov函数的方法为PLL重置控制提供了可靠的触发条件。

Abstract: Fluctuations in phase angle and frequency under large disturbances can lead
to loss of synchronism (LOS) in grid-following (GFL) converters. The power
angle and frequency of synchronous generators (SGs) correspond to rotor
position and speed, whereas those of converters lack a direct physical
counterpart in the real world and can thus be directly adjusted by control
methods to prevent loss of synchronization. In this paper, an improved
phase-locked loop (PLL) design with reset control for GFL converters is
proposed to enhance transient stability. The stability domain (SD) of a GFL
converter is first analyzed, and three forms of SD are identified under
different short circuit ratios. Secondly, based on the characteristics of the
three SD forms, two PLL-reset methods are proposed, including omega reset and
omega&delta reset. Thirdly, to provide the triggering conditions for the
PLL-reset control, the Lyapunov function of the GFL converter is constructed
based on three methods: the approximation-based Lyapunov method, the Zubov
method, and the analytical trajectory reversing method. All these methods are
immune to the negative damping problem of PLL dynamics, which makes traditional
energy-perspective Lyapunov functions invalid. Finally, the estimation accuracy
of the three Lyapunov-based methods is analyzed, and the effectiveness of the
PLL-reset control is verified in single-machine and multi-machine case studies.

</details>


### [836] [Adaptation of Parameters in Heterogeneous Multi-agent Systems](https://arxiv.org/abs/2509.00801)
*Hyungbo Shim,Jin Gyu Lee,B. D. O. Anderson*

Main category: eess.SY

TL;DR: 该研究提出了一种在异构多智能体系统中通过强耦合实现近似共识的自适应机制，使智能体参数趋于一致，最终达到状态精确共识。


<details>
  <summary>Details</summary>
Motivation: 解决异构多智能体系统中由于节点动力学异质性导致的同步难题，并在此基础上实现智能体内部参数的对齐。

Method: 提出一种自适应律，利用状态同步中已有的耦合信号来对齐智能体内部参数，无需直接通信。该方法基于强耦合诱导近似共识的原理，使智能体动力学趋于同质化。

Result: 证明了在线性参数化向量场下，智能体的向量场在持续激励条件下会相互趋近，达到渐近同质化，并最终实现状态变量的精确共识。

Conclusion: 所提出的自适应机制能够有效解决异构多智能体系统的同步和参数对齐问题，最终实现精确的状态共识，并且该过程具有生物学或社会学上的合理性。

Abstract: This paper proposes an adaptation mechanism for heterogeneous multi-agent
systems to align the agents' internal parameters, based on enforced consensus
through strong couplings. Unlike homogeneous systems, where exact consensus is
attainable, the heterogeneity in node dynamics precludes perfect
synchronization. Nonetheless, previous work has demonstrated that strong
coupling can induce approximate consensus, whereby the agents exhibit emergent
collective behavior governed by the so-called blended dynamics. Building on
this observation, we introduce an adaptation law that gradually aligns the
internal parameters of agents without requiring direct parameter communication.
The proposed method reuses the same coupling signal employed for state
synchronization, which may result in a biologically or sociologically plausible
adaptation process. Under a persistent excitation condition, we prove that the
linearly parametrized vector fields of the agents converge to each other,
thereby making the dynamics asymptotically homogeneous, and leading to exact
consensus of the state variables.

</details>


### [837] [Game Theoretic Resilience Recommendation Framework for CyberPhysical Microgrids Using Hypergraph MetaLearning](https://arxiv.org/abs/2509.00528)
*S Krishna Niketh,Prasanta K Panigrahi,V Vignesh,Mayukha Pal*

Main category: eess.SY

TL;DR: 本论文提出了一种用于径向微电网的物理感知网络弹性框架，以应对协调的网络攻击。该框架使用增强了模型无关元学习（MAML）的超图神经网络（HGNN）来模拟攻击者，以快速适应不断变化的防御策略并预测高风险意外事件。防御者通过双层Stackelberg博弈来模拟，其中上层使用嵌入在非支配排序遗传算法II（NSGA-II）中的交替方向乘法器（ADMM）协调器来选择最优的联络线切换和分布式能源（DER）调度。该框架同时优化了供电负荷、运行成本和电压稳定性，确保所有防御后状态都满足网络物理约束。


<details>
  <summary>Details</summary>
Motivation: 为径向微电网在面对协调网络攻击时，提供一种物理感知的网络弹性框架，以应对攻击者的预测和适应性，并优化防御策略以确保供电、成本和电压稳定。

Method: 1. 攻击者建模：使用增强了MAML的HGNN来预测高风险意外事件。
2. 防御者建模：通过双层Stackelberg博弈，利用ADMM协调器和NSGA-II优化联络线切换和DER调度。
3. 优化目标：同时优化供电负荷、运行成本和电压稳定性。
4. 验证：在IEEE 69节点、123节点和300节点系统上进行测试。

Result: 该防御策略能够恢复90%的顶级攻击的服务能力，解决电压违规问题，并识别出Feeder 2作为主要的脆弱走廊。此外，还得出了可操作的操作规则，建议预先配置特定的联络线以增强弹性。在高节点数的系统研究中也验证了该框架的可扩展性。

Conclusion: 提出的物理感知网络弹性框架能够有效地抵御协调网络攻击，提高微电网的恢复能力，并且具有良好的可扩展性。

Abstract: This paper presents a physics-aware cyberphysical resilience framework for
radial microgrids under coordinated cyberattacks. The proposed approach models
the attacker through a hypergraph neural network (HGNN) enhanced with model
agnostic metalearning (MAML) to rapidly adapt to evolving defense strategies
and predict high-impact contingencies. The defender is modeled via a bi-level
Stackelberg game, where the upper level selects optimal tie-line switching and
distributed energy resource (DER) dispatch using an Alternating Direction
Method of Multipliers (ADMM) coordinator embedded within the Non-dominated
Sorting Genetic Algorithm II (NSGA-II). The framework simultaneously optimizes
load served, operational cost, and voltage stability, ensuring all post-defense
states satisfy network physics constraints. The methodology is first validated
on the IEEE 69-bus distribution test system with 12 DERs, 8 critical loads, and
5 tie-lines, and then extended to higher bus systems including the IEEE 123-bus
feeder and a synthetic 300-bus distribution system. Results show that the
proposed defense strategy restores nearly full service for 90% of top-ranked
attacks, mitigates voltage violations, and identifies Feeder 2 as the principal
vulnerability corridor. Actionable operating rules are derived, recommending
pre-arming of specific tie-lines to enhance resilience, while higher bus system
studies confirm scalability of the framework on the IEEE 123-bus and 300-bus
systems.

</details>


### [838] [Passivity Compensation: A Distributed Approach for Consensus Analysis in Heterogeneous Networks](https://arxiv.org/abs/2509.00865)
*Yongkang Su,Sei Zhen Khong,Lanlan Su*

Main category: eess.SY

TL;DR: 该论文研究了异构网络中基于无源性的输出一致性分析，其中包含非相同但通过非线性相互作用耦合的智能体，同时存在测量和/或通信噪声。研究重点是输入前馈无源（IFP）的智能体，探讨了部分智能体的无源性不足是否能被其他智能体的无源性盈余所补偿，以保持由智能体动力学和网络拓扑定义的开环系统变换后的无源性。研究表明，这种补偿仅在最多一个智能体缺乏无源性时可行，并阐述了如何利用智能体群体中的无源性盈余来抵消这种不足。对于一般的网络，研究利用耦合链路中的无源性盈余来补偿相邻智能体中缺乏的无源性，在反馈互连中研究了无源性补偿。特别是，推导了一个以无源性指标和耦合增益表示的分布式条件，以确保互连网络的输出一致性。


<details>
  <summary>Details</summary>
Motivation: 研究异构网络中，即使部分智能体存在无源性不足或噪声干扰，也能实现输出一致性的方法。

Method: 1. 关注输入前馈无源（IFP）的智能体，分析无源性不足是否能被盈余补偿以保持开环系统无源性。
2. 确定补偿的可行性条件（最多一个智能体缺乏无源性）并阐述补偿机制。
3. 在反馈互连中，利用耦合链路的无源性盈余补偿相邻智能体的无源性不足。
4. 推导了一个基于无源性指标和耦合增益的分布式条件，以保证网络输出一致性。

Result: 1. 发现无源性补偿的可行性条件是最多一个智能体缺乏无源性。
2. 提出了利用耦合链路的无源性盈余补偿智能体无源性不足的方法。
3. 提出了一个分布式条件，以确保异构网络的输出一致性。

Conclusion: 该论文提出了一种有效的无源性补偿方法，用于解决异构网络中存在非线性耦合、部分智能体无源性不足以及噪声干扰下的输出一致性问题。通过利用无源性盈余进行补偿，并结合分布式条件，可以实现网络的输出一致性。

Abstract: This paper investigates a passivity-based approach to output consensus
analysis in heterogeneous networks composed of non-identical agents coupled via
nonlinear interactions, in the presence of measurement and/or communication
noise. Focusing on agents that are input-feedforward passive (IFP), we first
examine whether a shortage of passivity in some agents can be compensated by a
passivity surplus in others, in the sense of preserving the passivity of the
transformed open-loop system defined by the agent dynamics and network
topology. We show that such compensation is only feasible when at most one
agent lacks passivity, and we characterise how this deficit can be offset using
the excess passivity within the group of agents. For general networks, we then
investigate passivity compensation within the feedback interconnection by
leveraging the passivity surplus in the coupling links to locally compensate
for the lack of passivity in the adjacent agents. In particular, a distributed
condition, expressed in terms of passivity indices and coupling gains, is
derived to ensure output consensus of the interconnected network.

</details>


### [839] [A Comprehensive Approach to Evaluate Frequency Control Strength of Power Systems](https://arxiv.org/abs/2509.00548)
*Taulant Kerci,Federico Milano*

Main category: eess.SY

TL;DR: 该论文提出“频率控制强度”概念，用于评估不同实际电网的频率控制效果。通过对四个基于可再生能源的同步电网（英国、爱尔兰、澳大利亚大陆和塔斯马尼亚）的测量数据进行比较，研究了频率控制强度。结果表明，澳大利亚大陆电网在正常运行条件下具有最高的频率控制强度，而爱尔兰电网在异常系统条件下具有最高的相对频率控制强度。研究还指出，频率控制强度受到不同司法管辖区的监管要求以及不同的系统/辅助服务安排的影响，并提出了通过电网代码和市场规则来改善频率控制强度的可能缓解措施。


<details>
  <summary>Details</summary>
Motivation: 介绍“频率控制强度”这一新概念，以量化和比较不同实际电网在频率控制方面的性能。

Method: 基于测量数据，使用不同的频率质量指标，对四个实际的、基于可再生能源的同步电网（英国、爱尔兰、澳大利亚大陆和塔斯马尼亚）的频率控制强度进行全面比较。

Result: 澳大利亚大陆电网在正常运行条件下表现出最高的频率控制强度，而爱尔兰电网在异常系统条件下表现出最高的相对频率控制强度。研究强调，频率控制强度很大程度上受到不同地区的监管要求和系统/辅助服务安排的影响。

Conclusion: “频率控制强度”是一个有用的指标，用于评估电网的频率控制性能。电网的容量并非决定其频率控制能力的唯一因素，监管和市场机制在其中扮演着关键角色。可以通过改进电网代码和市场规则来提高频率控制强度。

Abstract: This paper introduces the concept of "frequency control strength" as a novel
approach to understand how different real-world power systems compare to each
other in terms of effectiveness and performance of system-wide frequency
control. It presents a comprehensive comparison, based on measurement data, of
the frequency control strength of four real-world, renewable-based, synchronous
islands power systems, namely Great Britain (GB), All-Island power system
(AIPS) of Ireland, and Australia (AUS) mainland and Tasmania (TAS). The
strength is evaluated by means of different frequency quality metrics. The
common understanding is that the bigger the capacity of a power system, the
bigger its robustness with respect to events and contingencies. Here we show
that this is not always the case in the context of frequency control. In fact,
our study shows that mainland AUS shows the highest frequency control strength
during normal operating conditions, whereas the AIPS shows the highest relative
frequency control strength for abnormal system conditions. The strength is, in
particular, greatly influenced by different regulatory requirements and
different system/ancillary services arrangements in each jurisdiction. The
paper also provides possible mitigations to improve frequency control strength
through grid codes and market rules.

</details>


### [840] [Realization of Precise Perforating Using Dynamic Threshold and Physical Plausibility Algorithm for Self-Locating Perforating in Oil and Gas Wells](https://arxiv.org/abs/2509.00608)
*Siyu Xiao,Guohui Ren,Tianhao Mao,Yuqiao Chen,YiAn Liu,Junjie Wang,Kai Tang,Xindi Zhao,Zhijian Yu,Shuang Liu,Tupei Chen,Yang Liu*

Main category: eess.SY

TL;DR: 该论文提出了一种名为DTPPMP的动态阈值和物理合理性测深与射孔控制系统，用于油气井的精确测井和射孔作业，解决了现场操作限制和设备局限性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了优化油气资源开发，实现精确的深度测量和在正确位置进行射孔，以克服现场操作限制和设备局限性。

Method: 提出并集成了DTPPMP系统到射孔枪中，该系统利用轻量级的动态阈值和物理合理性算法，在嵌入式平台上实时处理和识别井下套管 બના口定位器（CCL）信号，从而实现精确的深度测量和在指定射孔区间的射孔。

Result: 在四川某油井进行的现场测试表明，DTPPMP系统能够准确识别套管 બના口信号、测量深度，并实时在指定的射孔区间进行有效射孔，射孔误差小于单个射孔区间长度，套管 બના口识别的F1分数达到98.6%。

Conclusion: DTPPMP系统的现场测试结果证明了其在提高油气井射孔作业自动化和智能化方面的有效性，为未来射孔作业的发展提供了有价值的建议。

Abstract: Accurate depth measurement is essential for optimizing oil and gas resource
development, as it directly impacts production efficiency. However, achieving
precise depth and perforating at the correct location remains a significant
challenge due to field operational constraints and equipment limitations. In
this work, we propose the Dynamic Threshold and Physical Plausibility Depth
Measurement and Perforation Control (DTPPMP) system, a solution integrated into
perforating guns that enables real-time, precise depth measurement and
perforation at designated perforating intervals. The system autonomously
samples, processes and identifies signals from a casing collar locator (CCL) in
situ within oil and gas wells. Casing collar identification is achieved using a
lightweight dynamic threshold and physical plausibility algorithm deployed on
an embedded platform, which serves as the system's processor. Field tests
conducted in an actual oil well in Sichuan, China, demonstrated the DTPPMP's
ability to accurately identify casing collar signals, measure depths, and
effectively perforate at designated perforating intervals in real-time. The
system achieved a perforation variation of less than the length of a single
perforating interval and a F1 score of 98.6% for casing collar identification.
These results provide valuable recommendations for advancing automation and
intelligence in future perforation operations.

</details>


### [841] [Revisiting Deep AC-OPF](https://arxiv.org/abs/2509.00655)
*Oluwatomisin I. Dada,Neil D. Lawrence*

Main category: eess.SY

TL;DR: ML方法在AC最优潮流(AC-OPF)问题上虽然有潜力，但其优势相比简单线性模型可能被夸大，需要包含强有力的线性基线进行对比。


<details>
  <summary>Details</summary>
Motivation: 评估机器学习(ML)方法在AC最优潮流(AC-OPF)问题上的速度和准确性，并与线性基线进行比较。

Method: 提出了一种基于Transformer的模型OPFormer-V来预测母线电压，并与DeepOPF-V模型和线性方法进行了比较。

Result: OPFormer-V相比DeepOPF-V有所改进，但ML方法的相对优势并不像预期的那么明显，简单的线性方法可以达到可比的性能。

Conclusion: 在未来的评估中，包含强有力的线性基线至关重要。

Abstract: Recent work has proposed machine learning (ML) approaches as fast surrogates
for solving AC optimal power flow (AC-OPF), with claims of significant
speed-ups and high accuracy. In this paper, we revisit these claims through a
systematic evaluation of ML models against a set of simple yet carefully
designed linear baselines. We introduce OPFormer-V, a transformer-based model
for predicting bus voltages, and compare it to both the state-of-the-art
DeepOPF-V model and simple linear methods. Our findings reveal that, while
OPFormer-V improves over DeepOPF-V, the relative gains of the ML approaches
considered are less pronounced than expected. Simple linear baselines can
achieve comparable performance. These results highlight the importance of
including strong linear baselines in future evaluations.

</details>


### [842] [On the Global Optimality of Linear Policies for Sinkhorn Distributionally Robust Linear Quadratic Control](https://arxiv.org/abs/2509.00956)
*Riccardo Cescon,Andrea Martin,Giancarlo Ferrari-Trecate*

Main category: eess.SY

TL;DR: 本研究提出了有限时间 horizonte LQG 控制问题的一个分布鲁棒推广，通过使用基于熵正则化 Wasserstein 距离的模糊集来处理非高斯噪声，并证明了线性策略的全局最优性。


<details>
  <summary>Details</summary>
Motivation: LQG 调节器在噪声分布偏离高斯模型时性能会下降，本研究旨在解决此局限性。

Method: 提出了一种有限时间 horizonte LQG 控制问题的分布鲁棒推广，使用基于熵正则化 Wasserstein 距离定义的模糊集来处理未知噪声分布，并通过推导 Sinkhorn 散度的新界限和模糊集的结构与拓扑性质证明了线性策略的全局最优性。

Result: 数值实验表明，所提出的控制策略具有改进的分布鲁棒性。

Conclusion: 通过使用基于熵正则化 Wasserstein 距离的模糊集来处理非高斯噪声，可以实现 LQG 控制问题的分布鲁棒推广，并获得全局最优的线性策略。

Abstract: The Linear Quadratic Gaussian (LQG) regulator is a cornerstone of optimal
control theory, yet its performance can degrade significantly when the noise
distributions deviate from the assumed Gaussian model. To address this
limitation, this work proposes a distributionally robust generalization of the
finite-horizon LQG control problem. Specifically, we assume that the noise
distributions are unknown and belong to ambiguity sets defined in terms of an
entropy-regularized Wasserstein distance centered at a nominal Gaussian
distribution. By deriving novel bounds on this Sinkhorn discrepancy and proving
structural and topological properties of the resulting ambiguity sets, we
establish global optimality of linear policies. Numerical experiments showcase
improved distributional robustness of our control policy.

</details>


### [843] [IndusGCC: A Data Benchmark and Evaluation Framework for GUI-Based General Computer Control in Industrial Automation](https://arxiv.org/abs/2509.01199)
*Xiaoran Yang,Yuyang Du,Kexin Chen,Soung Chang Liew,Jiamin Lu,Ziyu Guo,Xiaoyan Liu,Qun Yang,Shiqi Xu,Xingyu Fan,Yuchen Pan,Taoyong Cui,Hongyu Deng,Boris Dudder,Jianzhang Pan,Qun Fang,Pheng Ann Heng*

Main category: eess.SY

TL;DR: 本论文介绍了IndusGCC，一个针对工业环境下的LLM-GCC（大型语言模型通用计算机控制）的首次数据集和基准测试，旨在解决现有工业设备控制软件依赖GUI交互的障碍，推动代码化自动化。数据集包含448个跨越七个领域的真实世界任务，并提供多模态人机交互数据以监督代码生成。论文还提出了一个包含功能和结构指标的新评估框架，并在主流LLM上进行了实验，展示了LLM-GCC的潜力和挑战。


<details>
  <summary>Details</summary>
Motivation: 为解决当前工业设备控制软件依赖图形用户界面（GUI）交互，阻碍代码化自动化的问题，以及工业环境界面多样、领域特定和任务要求高等挑战，本研究旨在为工业环境下的LLM-GCC提供一个专门的数据集和基准。

Method: 本研究提出了IndusGCC数据集，其中包含448个来自七个领域的真实世界任务，并提供多模态人机交互数据以监督GUI层面的代码生成。同时，研究提出了一种新颖的评估框架，包含功能和结构指标，用于评估LLM生成控制脚本的性能。

Result: 在主流LLM上的实验结果表明，LLM-GCC在工业环境中具有潜力，但也面临挑战。这些结果为未来实现全自动化工厂的研究奠定了基础。

Conclusion: IndusGCC数据集和评估框架为LLM在工业自动化领域的应用提供了重要的基础，证明了LLM-GCC的潜力和挑战，并指明了未来研究方向。

Abstract: As Industry 4.0 progresses, flexible manufacturing has become a cornerstone
of modern industrial systems, with equipment automation playing a pivotal role.
However, existing control software for industrial equipment, typically reliant
on graphical user interfaces (GUIs) that require human interactions such as
mouse clicks or screen touches, poses significant barriers to the adoption of
code-based equipment automation. Recently, Large Language Model-based General
Computer Control (LLM-GCC) has emerged as a promising approach to automate
GUI-based operations. However, industrial settings pose unique challenges,
including visually diverse, domain-specific interfaces and mission-critical
tasks demanding high precision. This paper introduces IndusGCC, the first
dataset and benchmark tailored to LLM-GCC in industrial environments,
encompassing 448 real-world tasks across seven domains, from robotic arm
control to production line configuration. IndusGCC features multimodal human
interaction data with the equipment software, providing robust supervision for
GUI-level code generation. Additionally, we propose a novel evaluation
framework with functional and structural metrics to assess LLM-generated
control scripts. Experimental results on mainstream LLMs demonstrate both the
potential of LLM-GCC and the challenges it faces, establishing a strong
foundation for future research toward fully automated factories. Our data and
code are publicly available at:
\href{https://github.com/Golden-Arc/IndustrialLLM}{https://github.com/Golden-Arc/IndustrialLLM.

</details>


### [844] [Design, Modelling and Analysis of a Bio-inspired Spiking Temperature Regulator](https://arxiv.org/abs/2509.01300)
*J. M. Rosito,E. Petri,E. Steur,W. P. M. H. Heemels*

Main category: eess.SY

TL;DR: 本文提出了一种基于电子电路的类比生物调温机制的架构设计，并结合了数学分析。该设计包含四个敏感神经元和一个致动器，并采用了负反馈和前馈控制。通过混合动力系统描述对该系统进行数学建模和分析，结果表明前馈控制在减少对外部温度的依赖性方面起着至关重要的作用。


<details>
  <summary>Details</summary>
Motivation: 生物体维持稳定的内部环境（体内稳态）对于最佳功能至关重要。其中，体温调节是维持核心温度在严格范围内的一个关键机制。本研究旨在复制生物体内的这种调温过程。

Method: 设计了一个包含四个温度敏感神经元和单个致动器的电子电路架构，该架构配置为具有前馈控制的负反馈回路。使用混合动力系统描述来对整个系统进行数学建模，并用于分析和模拟设计的性能。

Result: 通过分析和数值案例研究，证明了前馈控制在减少系统对外部温度依赖性方面的重要性。

Conclusion: 所提出的基于电子电路的架构设计能够有效地复制生物体内的调温过程，并且前馈控制对于提高系统在不同外部温度下的鲁棒性至关重要。

Abstract: In biology, homeostasis is the process of maintaining a stable internal
environment, which is crucial for optimal functioning of organisms. One of the
key homeostatic mechanisms is thermoregulation that allows the organism to
maintain its core temperature within tight bounds despite being exposed to a
wide range of varying external temperatures. Instrumental in thermoregulation
is the presence of thermosensitive neurons at multiple places throughout the
body, including muscles, the spinal cord, and the brain, which provide spiking
sensory signals for the core temperature. In response to these signals,
thermoeffectors are activated, creating a negative spiking feedback loop.
Additionally, a feedforward signal is provided by warmth and cold-sensitive
neurons in the skin, offering a measure for the external temperature. This
paper presents an electronic circuit-based architecture design to replicate the
biological process of thermoregulation, combined with a formal mathematical
analysis. The considered architecture consists of four temperature sensitive
neurons and a single actuator, configured in a negative feedback loop with
feedforward control. To model the overall system mathematically, hybrid
dynamical system descriptions are proposed that are used to analyze and
simulate the performance of the design. The analysis and numerical case study
illustrate the crucial role of feedforward control in reducing the dependency
on the external temperature.

</details>


### [845] [Energy-optimal control of discrete-time port-Hamiltonian systems](https://arxiv.org/abs/2509.01345)
*Arijit Sarkar,Vaibhav Kumar Singh,Manuel Schaller,Karl Worthmann*

Main category: eess.SY

TL;DR: 本论文研究离散时间下非线性分布哈密顿（pH）系统的能量最优控制。


<details>
  <summary>Details</summary>
Motivation: 连续时间pH系统的能量最优控制问题通过设计具有严格耗散性，该性质表明待优化系统以成本函数作为供给率是耗散的，这保证了最优解具有稳定的长期行为，并能在预测控制中得到稳定性结果。

Method: 本文证明了通过差分和微分表示进行离散化可以得到严格耗散的离散时间最优控制问题，并证明了通过隐式中点规则等保能积分器进行离散化并不能直接保持严格耗散性。

Result: 严格证明了最优解具有流形（子空间） Turnpike性质的稳定长期行为。

Conclusion: 通过两个数值例子验证了研究结果。

Abstract: In this letter, we study the energy-optimal control of nonlinear
port-Hamiltonian (pH) systems in discrete time. For continuous-time pH systems,
energy-optimal control problems are strictly dissipative by design. This
property, stating that the system to be optimized is dissipative with the cost
functional as a supply rate, implies a stable long-term behavior of optimal
solutions and enables stability results in predictive control.
  In this work, we show that the crucial property of strict dissipativity is
not straightforwardly preserved by any energy-preserving integrator such as the
implicit midpoint rule. Then, we prove that discretizations via difference and
differential representations lead to strictly dissipative discrete-time optimal
control problems. Consequently, we rigorously show a stable long-term behavior
of optimal solutions in the form of a manifold (subspace) turnpike property.
Finally, we validate our findings using two numerical examples

</details>


### [846] [Data-Driven Fault Isolation in Linear Time-Invariant Systems: A Subspace Classification Approach](https://arxiv.org/abs/2509.01347)
*Mohammad Amin Sheikhi,Gabriel de Albuquerque Gleizer,Peyman Mohajerin Esfahani,Tamás Keviczky*

Main category: eess.SY

TL;DR: 本论文提出一种数据驱动的故障隔离方法，用于线性系统中的执行器和传感器故障。


<details>
  <summary>Details</summary>
Motivation: 研究在数据驱动框架下，线性系统中执行器和传感器故障的隔离问题。

Method: 提出一种基于零空间（nullspace-based）的滤波器，仅使用在过程噪声和测量噪声下收集的无故障输入-输出数据。通过在行为框架（behavioral framework）内对问题进行重新参数化，实现了独立于显式系统模型的直接故障隔离滤波器设计。从几何角度处理分类问题，从而能够在无噪声的情况下，根据根本系统属性来表征故障的可区分性。

Result: 提出的条件仅使用可用数据即可评估。仿真研究证明了该方法的有效性。

Conclusion: 该方法能够独立于显式系统模型，在数据驱动的框架下实现故障隔离。

Abstract: We study the problem of fault isolation in linear systems with actuator and
sensor faults within a data-driven framework. We propose a nullspace-based
filter that uses solely fault-free input-output data collected under process
and measurement noises. By reparameterizing the problem within a behavioral
framework, we achieve a direct fault isolation filter design that is
independent of any explicit system model. The underlying classification problem
is approached from a geometric perspective, enabling a characterization of
mutual fault discernibility in terms of fundamental system properties given a
noise-free setting. In addition, the provided conditions can be evaluated using
only the available data. Finally, a simulation study is conducted to
demonstrate the effectiveness of the proposed method.

</details>


### [847] [ConamArray: A 32-Element Broadband MEMS Ultrasound Transducer Array](https://arxiv.org/abs/2509.01372)
*Dennis Laurijssen,Rens Baeyens,Walter Daems,Jan Steckel*

Main category: eess.SY

TL;DR: 本文介绍了ConamArray，一种由32个MEMS扬声器组成的紧凑型宽带超声换能器阵列。与传统宽带换能器相比，该阵列尺寸更小，驱动电压要求更低，通过交错的两行配置实现了宽超声频带内的波束转向。双微控制器后端和同步多DAC输出来灵活生成波形和控制转向。仿真和消声室测量均证实了ConamArray稳定的波束转向能力，并揭示了大角度转向时出现栅瓣的现象。这证明了利用MEMS技术实现宽带波束转向的可行性，为超声成像、定位和仿生机器人等应用开辟了新机遇。


<details>
  <summary>Details</summary>
Motivation: 介绍了一种紧凑型宽带超声换能器阵列（ConamArray），解决了传统宽带换能器尺寸大、驱动电压高的问题。

Method: 该阵列由32个MEMS扬声器组成，采用交错两行配置，并辅以双微控制器和同步多DAC输出，以实现灵活的波形生成和运行时转向控制。

Result: 仿真和消声室测量结果表明，ConamArray实现了稳定的波束转向，在大角度转向时会出现栅瓣。

Conclusion: MEMS技术可实现宽带波束转向，为超声成像、定位和仿生机器人等应用提供了新的可能性。

Abstract: This paper presents the ConamArray, a compact broadband ultrasound transducer
array composed of 32 MEMS loudspeakers. Unlike conventional broadband
transducers, which are typically large and require high driving voltages, the
proposed array combines small form factor MEMS devices in a staggered two-row
configuration to enable beam steering across a wide ultrasonic band. A
dual-microcontroller back-end with synchronized multi-DAC outputs provides
flexible waveform generation and runtime steering control. Both simulations and
anechoic chamber measurements demonstrate that the ConamArray achieves stable
beam steering, while also revealing the onset of grating lobes when steering to
larger angles. These results confirm the feasibility of broadband beam steering
using MEMS technology, opening new opportunities for applications in ultrasonic
imaging, localization, and bio-inspired robotics.

</details>


### [848] [End-to-End Low-Level Neural Control of an Industrial-Grade 6D Magnetic Levitation System](https://arxiv.org/abs/2509.01388)
*Philipp Hartmann,Jannick Stranghöner,Klaus Neumann*

Main category: eess.SY

TL;DR: 磁悬浮技术在工业自动化中具有革命性潜力，但其控制面临复杂不稳定的动力学挑战。本文提出了首个用于6D磁悬浮的神经控制器，通过端到端学习专有控制器交互数据，直接将原始传感器数据和6D参考姿态映射到线圈电流命令。该神经控制器能够有效泛化到未见过的场景，并保持精确鲁棒的控制。


<details>
  <summary>Details</summary>
Motivation: 磁悬浮技术在工业自动化中具有革命性潜力，但传统控制方法依赖于经验工程，鲁棒但保守，性能受工程师专业知识限制。神经控制学习提供了一种有前景的替代方案。

Method: 本文提出了首个用于6D磁悬浮的神经控制器，通过端到端学习专有控制器交互数据，直接将原始传感器数据和6D参考姿态映射到线圈电流命令。

Result: 所提出的神经控制器能够有效泛化到未见过的场景，并保持精确鲁棒的控制。

Conclusion: 这些结果证明了学习型神经控制在复杂物理系统中实际应用的可行性，并预示着这种范式有望增强或替代传统工程方法在要求严苛的实际应用中的作用。所训练的神经控制器、源代码和演示视频可在https://sites.google.com/view/neural-maglev获取。

Abstract: Magnetic levitation is poised to revolutionize industrial automation by
integrating flexible in-machine product transport and seamless manipulation. It
is expected to become the standard drive for automated manufacturing. However,
controlling such systems is inherently challenging due to their complex,
unstable dynamics. Traditional control approaches, which rely on hand-crafted
control engineering, typically yield robust but conservative solutions, with
their performance closely tied to the expertise of the engineering team. In
contrast, neural control learning presents a promising alternative. This paper
presents the first neural controller for 6D magnetic levitation. Trained
end-to-end on interaction data from a proprietary controller, it directly maps
raw sensor data and 6D reference poses to coil current commands. The neural
controller can effectively generalize to previously unseen situations while
maintaining accurate and robust control. These results underscore the practical
feasibility of learning-based neural control in complex physical systems and
suggest a future where such a paradigm could enhance or even substitute
traditional engineering approaches in demanding real-world applications. The
trained neural controller, source code, and demonstration videos are publicly
available at https://sites.google.com/view/neural-maglev.

</details>


### [849] [Semantic Technologies in Practical Demand Response: An Informational Requirement-based Roadmap](https://arxiv.org/abs/2509.01459)
*Ozan Baris Mulayim,Yuvraj Agarwal,Mario Bergés,Steve Schaefer,Mitali Shah,Derek Supple*

Main category: eess.SY

TL;DR: 本篇论文提出了一种评估和开发本体的方法，以满足智能电网中需求响应（DR）的语义互操作性需求，并评估了现有本体（Brick、DELTA和EFOnt）在支持DR需求方面的不足，最后提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 未来的智能电网需要复杂的协调机制来管理分布式资源，例如需求响应（DR）。为了实现这一目标，必须在语义互操作性方面取得重大进展，以支持异构系统之间可扩展且成本有效的自动化。然而，现有的本体在开发框架和与DR需求的契合度方面存在不足，并且缺乏对现有本体集成的实证验证。

Method: 本文采用一种正式的本体评估/开发方法，针对商业建筑的激励性DR领域，定义了实现语义互操作性所需的信息需求（IRs）。研究人员识别了批发激励性DR流程的各个阶段与建筑所有者相关的IRs。基于这些IRs，评估了现有本体（Brick、DELTA和EFOnt）在支持DR参与的操作需求方面的能力。

Result: 评估结果表明，现有的本体（Brick、DELTA和EFOnt）与实际的DR需求存在显著的不匹配。研究基于评估结果，提出了对这些本体进行扩展和集成的必要路线图。

Conclusion: 本研究通过应用正式的本体评估/开发方法，识别并评估了现有本体在支持商业建筑激励性DR方面的不足，并提出了改进建议，旨在增强当前和未来智能电网的互操作性，促进DR系统在大规模电网运行框架中的集成。

Abstract: The future grid will be highly complex and decentralized, requiring
sophisticated coordination across numerous human and software agents that
manage distributed resources such as Demand Response (DR). Realizing this
vision demands significant advances in semantic interoperability, which enables
scalable and cost-effective automation across heterogeneous systems. While
semantic technologies have progressed in commercial building and DR domains,
current ontologies have two critical limitations: they are often developed
without a formal framework that reflects real-world DR requirements, and
proposals for integrating general and application-specific ontologies remain
mostly conceptual, lacking formalization or empirical validation.
  In this paper, we address these gaps by applying a formal ontology
evaluation/development approach to define the informational requirements (IRs)
necessary for semantic interoperability in the area of incentive-based DR for
commercial buildings. We identify the IRs associated with each stage of the
wholesale incentive-based DR process, focusing on the perspective of building
owners. Using these IRs, we evaluate how well existing ontologies (Brick,
DELTA, and EFOnt) support the operational needs of DR participation. Our
findings reveal substantial misalignments between current ontologies and
practical DR requirements. Based on our assessments, we propose a roadmap of
necessary extensions and integrations for these ontologies. This work
ultimately aims to enhance the interoperability of today's and future smart
grid, thereby facilitating scalable integration of DR systems into the grid's
complex operational framework.

</details>


### [850] [Targeted-Subharmonic-Eliminating Pulse Density Modulation for Wireless Power Transfer System](https://arxiv.org/abs/2509.01537)
*Songyan Li,Hongchang Li*

Main category: eess.SY

TL;DR: 该论文提出了一种针对SS补偿的无线输电（WPT）系统的目标谐波消除脉冲密度调制（TSE-PDM）方法，通过设计具有陷波特性的噪声传递函数（NTF），消除了激发异常电流振荡的谐波分量。


<details>
  <summary>Details</summary>
Motivation: 为了解决SS补偿的无线输电（WPT）系统中由谐波引起的异常电流振荡问题。

Method: 提出了一种目标谐波消除脉冲密度调制（TSE-PDM）方法，并设计了具有陷波特性的噪声传递函数（NTF）来消除谐波分量。

Result: 仿真和实验结果证明了TSE-PDM在抑制异常电流振荡方面的有效性。

Conclusion: 所提出的TSE-PDM方法易于在WPT系统的初级或次级侧实现，并且对NTF设计的偏差具有一定的容忍度，是PDM控制的WPT系统中抑制异常振荡最简单的方法。

Abstract: This letter proposes a targeted-subharmonic-eliminating pulse density
modulation (TSE-PDM) method for SS- compensated WPT systems. By designing a
noise transfer function with notch characteristics, the subharmonic components
which excite current abnormal oscillations were eliminated. Simulation and
experimental results demonstrate the effectiveness of the TSE-PDM in
suppressing current abnormal oscillations. The proposed method is easy to
implement in either primary or secondary side of the WPT system and exhibits a
certain tolerance to deviations in NTF design, representing the most
straightforward method for abnormal oscillation suppression in PDM controlled
WPT systems.

</details>


### [851] [Grid congestion stymies climate benefit from U.S. vehicle electrification](https://arxiv.org/abs/2509.01662)
*Chao Duan,Adilson E. Motter*

Main category: eess.SY

TL;DR: 运输电气化在减少美国车辆运营的二氧化碳排放方面具有巨大潜力，但目前输电能力严重限制了这一减排效果。增加适度的输电能力可以解锁电气化的全部气候效益。


<details>
  <summary>Details</summary>
Motivation: 文章旨在分析美国的车辆电气化和可再生能源整合的脱碳潜力，并重点研究输电网络在其中扮演的关键角色。

Method: 利用模型分析输电容量对美国车辆电气化减排二氧化碳的限制作用。

Result: 结果表明，充足的输电能力可以使车辆电气化在可再生能源发电量达到现有非可再生能源装机容量时，几乎完全消除车辆运营的二氧化碳排放。然而，在现有电网条件下，减排效益将大打折扣。

Conclusion: 为了充分发挥车辆电气化和可再生能源整合的气候效益，必须增加输电基础设施的规模和能力，以克服当前输电能力的限制。

Abstract: Averting catastrophic global warming requires decisive action to decarbonize
key sectors. Vehicle electrification, alongside renewable energy integration,
is a long-term strategy toward zero carbon emissions. However, transitioning to
fully renewable electricity may take decades -- during which electric vehicles
may still rely on carbon-intensive electricity. We analyze the critical role of
the transmission network in enabling or constraining emissions reduction from
U.S. vehicle electrification. Our models reveal that the available transmission
capacity severely limits potential CO2 emissions reduction. With adequate
transmission, full electrification could nearly eliminate vehicle operational
CO2 emissions once renewable generation reaches the existing nonrenewable
capacity. In contrast, the current grid would support only a fraction of that
benefit. Achieving the full emissions reduction potential of vehicle
electrification during this transition will require a moderate but targeted
increase in transmission capacity. Our findings underscore the pressing need to
enhance transmission infrastructure to unlock the climate benefits of
large-scale electrification and renewable integration.

</details>


### [852] [A Novel Tunable Controller for Grid Forming Converters towards Critical Services Application](https://arxiv.org/abs/2509.01748)
*Yangyadatta Tripathy,Barjeev Tyagi*

Main category: eess.SY

TL;DR: 本文介绍了基于电网形成技术的逆变器基础资源（IBR）控制系统。其中，网格形成转换器（GFC）特别适用于偏远或孤岛运行。文章详细分析了同步发电机和GFC，并在MATLAB 2024环境中设计了其控制技术，研究了在意外情况下的闭环系统。文章提出了一个控制方案来解决频率最小化问题，并使用GAMS编程工具求解。此外，还提出了一种基于人工神经网络（ANN）和长短期记忆（LSTM）的控制器，以优化GFC在电网中的参考参数。


<details>
  <summary>Details</summary>
Motivation: 随着能源领域对无碳发电的快速采用，电网形成转换器（GFC）在偏远或孤岛运行中显示出巨大潜力。然而，基于GFC的全面电网需要复杂的控制实现和参数调整。

Method: 本文在MATLAB 2024环境中设计并研究了同步发电机和GFC的控制技术，重点分析了在意外情况下的闭环系统。提出了一种控制方案来解决频率最小化问题，并使用GAMS编程工具求解。此外，还提出了一种基于人工神经网络（ANN）和Levenberg-Marquardt训练算法的控制器，以及一种基于长短期记忆（LSTM）的控制器。

Result: 所提出的控制方案和GAMS编程工具成功解决了频率最小化问题。基于ANN和LSTM的控制器在优化GFC在电网中的参考参数方面表现出有效性。

Conclusion: 文章成功演示了应用于逆变器基础资源（IBR）的基于电网形成技术的控制系统的关键特性，并提出了创新的控制方法来解决频率最小化问题和优化GFC性能。

Abstract: This paper demonstrates the key features of a control system applicable to
inverter-based resources (IBR), which is based on grid-forming technology. Such
resources are classified as grid-forming or grid-following converters based on
the type of output with or without grid connection. With rapid growth in the
energy sector to adopt carbon-free generation, Grid Forming Converter (GFC)
seems suitable for power provision to remote or islanded operation of
converters. A fully-fledged bulk power grid based on GFC requires complex
control implementation with suitable tuning of its parameters. In this article
a broader analysis of synchronous machine and such type of converter is
discussed and designed in the MATLAB 2024 environment with its control
technique is studied for a closed-loop system under contingencies. A proposed
control scheme is developed to understand the frequency minimization problem
and the minimization problem is solved using GAMS programming tool. The primary
objective function is found to be suitable for minimization of frequency
deviation using a mixed control approach. An artificial neural network-based
controller is also proposed with Levenberg-Marquardt training algorithm which
augments the research by finding suitable optimal reference for GFM converter
in the presence of a grid. A long-short-term memory (LSTM) based network is
also proposed for the above control and the performance is found to be
efficacious.

</details>


### [853] [A Mathematical Model of Hybrid Microgrid With Pole Placement Controller Using State Feedback For Stability Improvement](https://arxiv.org/abs/2509.01749)
*Yangyadatta Tripathy,Barjeev Tyagi*

Main category: eess.SY

TL;DR: 该论文提出了一个混合微电网的数学模型，其中包含DC-DC转换器、DC-AC转换器及其控制器，以及负载。模型考虑了恒定的DC电压输入和LCL滤波器输出。控制器用于调节电压、电流和功率。论文详细介绍了DC转换器和DC-AC转换器的状态空间模型，并结合网络和负载模型构建了混合微电网模型。通过特征值分析研究了系统的暂态稳定性，并设计了极点配置控制器来提高稳定性。


<details>
  <summary>Details</summary>
Motivation: 开发混合微电网的数学模型，用于分析和控制，以提高系统的稳定性和性能。

Method: 提出DC-DC和DC-AC转换器的状态空间模型，并结合网络和负载模型构建混合微电网模型。进行特征值分析和极点配置控制器设计。

Result: 成功开发了混合微电网的完整状态空间模型，并通过特征值分析验证了系统的暂态稳定性。设计了极点配置控制器以增强稳定性。

Conclusion: 所提出的混合微电网状态空间模型能够准确地描述系统行为，并且通过极点配置控制器可以有效地提高系统的稳定性。

Abstract: This paper presents the development of a mathematical model of a converter
state space model for a hybrid microgrid. The hybrid model combines the models
of components such as DC-Converters, DC-AC converters, and their individual
controllers, as well as loads. The input to the converter is considered a
constant DC voltage, assumed to originate from distributed generations like
solar, battery storage, or fuel-cells. The converter output is connected to a
DC line through an LCL filter. The controller circuitry is designed to regulate
the voltage, current, and power from the converter. Sensors are strategically
placed to measure the currents, voltages, and power, and calculate the
reference pulse signal using PWM for the switch. Similarly, the DC-AC converter
is modeled. In the state space domain the converter models is used to design
overall microgrid system. A single DC converter has six states and two inputs,
with all states as outputs. A single DC-AC converter has thirteen states and
three inputs, with all states as outputs. Three such converters of each type
are considered to develop the DC microgrid and AC microgrid, which are then
combined using mathematical analysis to model a hybrid microgrid. For the
hybrid microgrid development, network and load models were also included.
Eigenvalue analysis has been conducted to study the small signal stability of
the considered system. The complete state space model of the hybrid microgrid
has been programmed, and a pole-placement controller has been designed to
enhance the stability of the system.

</details>


### [854] [High-Performance Trajectory Tracking MPC for Quadcopters with Coupled Time-Varying Constraints and Stability Proofs](https://arxiv.org/abs/2509.01767)
*Maedeh Izadi,A. T. J. R. Cobbenhagen,R. L. Sommer,A. R. P. Andrien,E. Lefeber,W. P. M. H. Heemels*

Main category: eess.SY

TL;DR: 提出一种用于四旋翼飞行器轨迹跟踪的级联控制结构，通过MPC外环和非线性内环控制器，实现状态跟踪误差的全局一致渐近稳定性，并在数值模拟中验证了其在精确快速跟踪方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼飞行器轨迹跟踪问题，并保证状态跟踪误差的全局一致渐近稳定性。

Method: 提出一种基于12维预测模型的MPC策略作为外环控制器，该控制器显式考虑了时间变化的耦合约束，并生成加速度参考。该加速度参考随后被转换为姿态和角速度参考，由非线性内环控制器进行跟踪。

Result: 数值模拟验证了该方法，表明通过施加比现有方法更少的保守约束，同时保证稳定性，在精确和快速跟踪方面表现出增强的性能。

Conclusion: 该级联控制结构能够有效地解决四旋翼飞行器的轨迹跟踪问题，并在保证稳定性的前提下，提供比现有方法更优的跟踪性能。

Abstract: In this paper, we present a cascade control structure to address the
trajectory tracking problem for quadcopters, ensuring uniform global asymptotic
stability of the state tracking error dynamics. An MPC strategy based on a
12-dimensional prediction model is proposed for the outer loop, explicitly
accounting for time-varying coupled constraints, where multiple variables are
interdependent and need to be handled together. The outer-loop controller
generates an acceleration reference, which is then converted into attitude and
angular velocity references, later tracked by a nonlinear inner-loop
controller. Numerical simulations validate the approach, demonstrating enhanced
performance in precise and fast tracking by imposing less conservative
constraints than existing approaches, while still guaranteeing stability.

</details>


### [855] [Impact of Passive Element Technological Limits on CMOS Low-Noise Amplifier Design](https://arxiv.org/abs/2509.01770)
*J. L. González,R. L. Moreno,D. Vázquez*

Main category: eess.SY

TL;DR: CMOS低噪声放大器设计中的技术约束影响了被动元件，限制了增益、功耗和晶体管尺寸，需要更详细的元件模型。


<details>
  <summary>Details</summary>
Motivation: 本论文研究技术约束对CMOS低噪声放大器（LNA）被动元件设计的影响。

Method: 结合理论分析和130-nm CMOS工艺下的电路仿真，在2.45 GHz频率下进行研究。

Result: 研究结果表明，技术约束显著限制了可实现的Hola设计空间，特别是在低功耗设计方面。

Conclusion: 在射频集成电路设计流程中，必须包含详细的被动元件模型，因为它们对LNA的设计目标有重要影响。

Abstract: This paper investigates the impact of technological constraints on passive
elements in the design of inductively degenerated CMOS low-noise amplifiers
(LNAs). A theoretical analysis is combined with circuit simulations in a 130-nm
CMOS process at 2.45~GHz to explore how the available inductance and
capacitance values limit key design objectives such as maximum gain, minimum
power consumption, and transistor sizing. Results show that these limits
significantly restrict the achievable design space, particularly for low-power
implementations, and highlight the need to incorporate detailed passive-element
models into RF integrated circuit design flows.

</details>


### [856] [Maximally Resilient Controllers under Temporal Logic Specifications](https://arxiv.org/abs/2509.01777)
*Youssef Ait Si,Ratnangshu Das,Negar Monir,Sadegh Soudjani,Pushpak Jagtap,Adnane Saoud*

Main category: eess.SY

TL;DR: 本文研究了受控动力系统的韧性，即系统在满足给定的时序逻辑规范的同时所能承受的最大扰动。


<details>
  <summary>Details</summary>
Motivation: 研究的目标是合成控制器，使闭环系统在满足规范的同时最大化其韧性。

Method: 该问题被表述为一个鲁棒优化问题，目标是计算最大韧性并同时合成相应的控制器参数。对于线性系统和线性控制器，我们为时变多面体规范类提供了精确解。对于非线性系统、非线性控制器和更一般的规范，我们利用场景优化方法，提供了解决方案的概率保证和计算可行性。

Result: 提出了针对线性系统和非线性系统的不同解决方案，并通过案例研究进行了说明。

Conclusion: 本文研究了受控动力系统的韧性问题，并提出了相应的优化和求解方法。

Abstract: In this paper, we consider the notion of resilience of a dynamical system,
defined by the maximum disturbance a controlled dynamical system can withstand
while satisfying given temporal logic specifications. Given a dynamical system
and a specification, the objective is to synthesize the controller such that
the closed-loop system satisfies this specification while maximizing its
resilience. The problem is formulated as a robust optimization program where
the objective is to compute the maximum resilience while simultaneously
synthesizing the corresponding controller parameters. For linear systems and
linear controllers, exact solutions are provided for the class of time-varying
polytopic specifications. For the case of nonlinear systems, nonlinear
controllers and more general specifications, we leverage tools from the
scenario optimization approach, offering a probabilistic guarantee of the
solution as well as computational feasibility. Different case studies are
presented to illustrate the theoretical results.

</details>


### [857] [Nonlinear Model Predictive Control-Based Reverse Path-Planning and Path-Tracking Control of a Vehicle with Trailer System](https://arxiv.org/abs/2509.01820)
*Xincheng Cao,Haochong Chen,Bilin Aksun-Guvenc,Levent Guvenc,Brian Link,Peter J Richmond,Dokyung Yim,Shihong Fan,John Harber*

Main category: eess.SY

TL;DR: 该论文提出了一种基于优化的自动化程序，用于处理带拖车系统的车辆的倒车入库操作。


<details>
  <summary>Details</summary>
Motivation: 由于系统不稳定和控制不直观，人类驾驶员难以完成带拖车系统的车辆的倒车入库操作。

Method: 该方法利用非线性模型预测控制（NMPC）来指导车辆-拖车系统进入期望的停车位，并可以选择添加前向重新定位操作，在再次尝试倒车运动以获得良好最终姿态之前，以获得更好的系统配置。该方法的创新之处在于其简单的表述，因为路径规划和路径跟踪操作仅在拖车上进行，将其视为独立的车辆，然后通过本文推导出的逆运动学关系将控制输入传播到牵引车。

Result: 进行了仿真案例研究和硬件在环测试。

Conclusion: 仿真结果和硬件在环测试证明了所提出方法的效果。

Abstract: Reverse parking maneuvers of a vehicle with trailer system is a challenging
task to complete for human drivers due to the unstable nature of the system and
unintuitive controls required to orientate the trailer properly. This paper
hence proposes an optimization-based automation routine to handle the
path-planning and path-tracking control process of such type of maneuvers. The
proposed approach utilizes nonlinear model predictive control (NMPC) to
robustly guide the vehicle-trailer system into the desired parking space, and
an optional forward repositioning maneuver can be added as an additional stage
of the parking process to obtain better system configurations, before backward
motion can be attempted again to get a good final pose. The novelty of the
proposed approach is the simplicity of its formulation, as the path-planning
and path-tracking operations are only conducted on the trailer being viewed as
a standalone vehicle, before the control inputs are propagated to the tractor
vehicle via inverse kinematic relationships also derived in this paper.
Simulation case studies and hardware-in-the-loop tests are performed, and the
results demonstrate the efficacy of the proposed approach.

</details>


### [858] [Safety-Critical Multi-Agent MCTS for Mixed Traffic Coordination at Unsignalized Roundabout](https://arxiv.org/abs/2509.01856)
*Zhihao Lin,Shuo Liu,Zhen Tian,Dezong Zhao,Jianglin Lan*

Main category: eess.SY

TL;DR: 该论文提出了一种基于多智能体蒙特卡洛树搜索（MCTS）的框架，用于在无人信号灯环形交叉路口解决自动驾驶汽车（AV）在混合交通环境中的决策挑战，通过整合确定性和概率性预测模型，并考虑了AV-AV、AV-HDV和AV-道路交互的层级安全评估、自适应HDV行为预测以及多目标奖励优化，仿真结果显示该框架能有效减少轨迹偏差并降低PET违规率。


<details>
  <summary>Details</summary>
Motivation: 在无人信号灯环形交叉路口，尤其是在混合交通环境中，自动驾驶汽车（AV）需要与人类驾驶车辆（HDV）进行安全协调，这给AV的决策带来了重大挑战。

Method: 提出了一种安全关键的多智能体蒙特卡洛树搜索（MCTS）框架，该框架整合了确定性和概率性预测模型，用于解决复杂环形交叉路口场景下的协同决策问题。该框架包含三个关键创新：1）层级安全评估模块，通过动态安全阈值和时空风险评估来处理AV-AV、AV-HDV和AV-道路交互；2）自适应HDV行为预测方案，结合了智能驾驶模型（IDM）和概率不确定性建模；3）多目标奖励优化策略，共同考虑安全、效率和协同意图。

Result: 在全自动驾驶（100% AVs）和混合交通（50% AVs + 50% HDVs）条件下进行的广泛仿真结果验证了所提出方法的有效性。与基准方法相比，该框架在所有AVs中持续减少轨迹偏差，并显著降低了后侵占时间（PET）违规率，在全自动驾驶场景下为1.0%，在混合交通场景下为3.2%。

Conclusion: 该研究提出了一种创新的MCTS框架，有效解决了自动驾驶汽车在复杂环形交叉路口环境下的安全决策问题，并在仿真中取得了优于基准方法的性能。

Abstract: Decision-making at unsignalized roundabouts poses substantial challenges for
autonomous vehicles (AVs), particularly in mixed traffic environments where AVs
must coordinate safely with human-driven vehicles (HDVs). This paper presents a
safety-critical multi-agent Monte Carlo Tree Search (MCTS) framework that
integrates both deterministic and probabilistic prediction models to facilitate
cooperative decision-making in complex roundabout scenarios. The proposed
framework introduces three key innovations: (1) a hierarchical safety
assessment module that systematically addresses AV-to-AV (A2A), AV-to-HDV
(A2H), and AV-to-Road (A2R) interactions through dynamic safety thresholds and
spatiotemporal risk evaluation; (2) an adaptive HDV behavior prediction scheme
that combines the Intelligent Driver Model (IDM) with probabilistic uncertainty
modeling; and (3) a multi-objective reward optimization strategy that jointly
considers safety, efficiency, and cooperative intent. Extensive simulation
results validate the effectiveness of the proposed approach under both fully
autonomous (100% AVs) and mixed traffic (50% AVs + 50% HDVs) conditions.
Compared to benchmark methods, our framework consistently reduces trajectory
deviations across all AVs and significantly lowers the rate of
Post-Encroachment Time (PET) violations, achieving only 1.0\% in the fully
autonomous scenario and 3.2% in the mixed traffic setting.

</details>


### [859] [RadioDiff-Loc: Diffusion Model Enhanced Scattering Congnition for NLoS Localization with Sparse Radio Map Estimation](https://arxiv.org/abs/2509.01875)
*Xiucheng Wang,Qiming Zhang,Nan Cheng*

Main category: eess.SY

TL;DR: 本文提出了一种基于条件扩散模型的非视距（NLoS）信号源生成式推理框架，通过在几何顶点处稀疏采样接收信号强度（RSS），并进行相对归一化以构建与发射功率无关的射电地图（RM），最终实现高精度本地化。


<details>
  <summary>Details</summary>
Motivation: 在非视距（NLoS）环境下，如自主导航、工业自动化和应急响应等应用中，准确识别信号源位置是一个关键的挑战。传统的依赖视距（LoS）或协同信号传输的定位技术，在这些环境中由于严重的信号多径传播和未知的发射功率而失效。

Method: 本研究提出了一种新颖的条件扩散模型生成式推理框架，用于NLoS定位。该框架利用电磁衍射能量集中在建筑物边缘的物理原理，设计了一种在障碍物几何顶点处稀疏采样接收信号强度（RSS）的策略，以最大化与未知信号源相关的费舍尔信息和互信息。为解决未知发射功率的问题，研究人员对所有采样RSS值进行相对归一化处理，使其相对于最大观测强度，从而构建一个与发射功率无关的射电地图（RM）。接着，训练一个条件扩散模型，基于环境布局和稀疏RSS观测来重建完整的RM。最后，通过识别生成RM中的最亮点来实现定位。该框架还兼容现有的基于RSS的定位算法，支持融合物理知识和数据驱动推理的双驱动范式。

Result: 实验结果表明，所提出的方法在显著降低采样成本的同时，实现了高定位精度，为非协同NLoS发射源定位提供了一个可扩展且符合物理规律的解决方案。

Conclusion: 该研究提出的基于条件扩散模型的生成式推理框架，通过创新的稀疏采样和射电地图构建方法，有效解决了NLoS环境下的信号源定位难题，提高了定位精度并降低了采样成本，为相关领域提供了有价值的解决方案。

Abstract: Accurate localization of non-cooperative signal sources in non-line-of-sight
(NLoS) environments remains a critical challenge with a wide range of
applications, including autonomous navigation, industrial automation, and
emergency response. In such settings, traditional positioning techniques
relying on line-of-sight (LoS) or cooperative signaling fail due to severe
multipath propagation and unknown transmit power. This paper proposes a novel
generative inference framework for NLoS localization based on conditional
diffusion models. By leveraging the physical insight that diffracted
electromagnetic energy concentrates near building edges, we develop a sampling
strategy that collects sparse received signal strength (RSS) measurements at
the geometric vertices of obstacles--locations that maximize Fisher information
and mutual information with respect to the unknown source. To overcome the lack
of known transmission power, we normalize all sampled RSS values relative to
the maximum observed intensity, enabling the construction of a power-invariant
radio map (RM). A conditional diffusion model is trained to reconstruct the
full RM based on environmental layout and sparse RSS observations. Localization
is then achieved by identifying the brightest point on the generated RM.
Moreover, the proposed framework is compatible with existing RSS-based
localization algorithms, enabling a dual-driven paradigm that fuses physical
knowledge and data-driven inference for improved accuracy. Extensive
theoretical analysis and empirical validation demonstrate that our approach
achieves high localization accuracy with significantly reduced sampling cost,
offering a scalable and physically grounded solution for non-cooperative NLoS
emitter localization.

</details>


### [860] [Online Identification using Adaptive Laws and Neural Networks for Multi-Quadrotor Centralized Transportation System](https://arxiv.org/abs/2509.01951)
*Tianhua Gao,Kohji Tomita,Akiya Kamimura*

Main category: eess.SY

TL;DR: This paper presents an adaptive-neuro identification method for multi-quadrotor systems to improve robustness against disturbances and uncertainties using online learning on decomposed error subspaces.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance the robustness of a centralized multi-quadrotor transportation system by compensating for time-varying disturbances and model uncertainties acting on the payload.

Method: The method decomposes the high-dimensional error space into low-dimensional subspaces, addressing each with adaptive laws and shallow neural networks updated online via Lyapunov-based adaptation. This model-free approach compensates for payload dynamics without explicit reliance on them and is proven stable.

Result: Numerical simulations demonstrated the enhanced robustness of the proposed control system under time-varying disturbances and model uncertainties.

Conclusion: The adaptive-neuro identification method enhances the robustness of multi-quadrotor transportation systems, offering stability and effective compensation for payload uncertainties and disturbances without requiring offline training or persistent excitation.

Abstract: This paper introduces an adaptive-neuro identification method that enhances
the robustness of a centralized multi-quadrotor transportation system. This
method leverages online tuning and learning on decomposed error subspaces,
enabling efficient real-time compensation to time-varying disturbances and
model uncertainties acting on the payload. The strategy is to decompose the
high-dimensional error space into a set of low-dimensional subspaces. In this
way, the identification problem for unseen features is naturally transformed
into submappings (``slices'') addressed by multiple adaptive laws and shallow
neural networks, which are updated online via Lyapunov-based adaptation without
requiring persistent excitation (PE) and offline training. Due to the
model-free nature of neural networks, this approach can be well adapted to
highly coupled and nonlinear centralized transportation systems. It serves as a
feedforward compensator for the payload controller without explicitly relying
on the dynamics coupled with the payload, such as cables and quadrotors. The
proposed control system has been proven to be stable in the sense of Lyapunov,
and its enhanced robustness under time-varying disturbances and model
uncertainties was demonstrated by numerical simulations.

</details>


### [861] [Robustness Enhancement for Multi-Quadrotor Centralized Transportation System via Online Tuning and Learning](https://arxiv.org/abs/2509.01952)
*Tianhua Gao,Kohji Tomita,Akiya Kamimura*

Main category: eess.SY

TL;DR: 本文提出了一种用于多旋翼飞行器协同运输系统的自适应神经几何控制方法，通过协同调整模型参数和实时学习外部干扰来增强系统的适应性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 为了增强多旋翼飞行器协同运输系统的适应性和抗干扰能力。

Method: 将神经网络和自适应律相结合，对现有几何控制进行增强，实现了模型参数和神经网络权重的在线协同调整。

Result: 通过数值模拟证明了该控制系统在有扰动和模型不匹配的场景下具有增强的鲁棒性，并且在特定先决条件下，系统稳定性得到了Lyapunov意义下的保证。

Conclusion: 所提出的自适应神经几何控制方法能够有效地提升多旋翼飞行器协同运输系统的性能。

Abstract: This paper introduces an adaptive-neuro geometric control for a centralized
multi-quadrotor cooperative transportation system, which enhances both
adaptivity and disturbance rejection. Our strategy is to coactively tune the
model parameters and learn the external disturbances in real-time. To realize
this, we augmented the existing geometric control with multiple neural networks
and adaptive laws, where the estimated model parameters and the weights of the
neural networks are simultaneously tuned and adjusted online. The
Lyapunov-based adaptation guarantees bounded estimation errors without
requiring either pre-training or the persistent excitation (PE) condition. The
proposed control system has been proven to be stable in the sense of Lyapunov
under certain preconditions, and its enhanced robustness under scenarios of
disturbed environment and model-unmatched plant was demonstrated by numerical
simulations.

</details>


### [862] [Design of an Efficient Three-Level Buck-Boost Converter in PSIM](https://arxiv.org/abs/2509.01975)
*Justin London*

Main category: eess.SY

TL;DR: 与传统转换器相比，三电平升降压（3L-BB）转换器具有更高的效率、更低的开关损耗和更高的功率密度。我们根据 PSIM 中的特定电压和电流规范设计了一个 3L-BB 转换器。我们将在 PSIM 中模拟电路，并通过比较 PSIM 中观察到的模拟值与数学驱动的理论值来分析功率、电压和电流波形。我们检查其功率效率，并确定电路是否满足给定的直流配电规范。我们表明，所提出的三相设计使用了两个单端初级电感器转换器（SEPIC），它具有功率效率，并且是高功率和高电压应用的有力解决方案。


<details>
  <summary>Details</summary>
Motivation: 与传统转换器相比，三电平升降压（3L-BB）转换器具有更高的效率、更低的开关损耗和更高的功率密度。

Method: 在 PSIM 中设计并模拟了一个三电平升降压（3L-BB）转换器，并分析了功率、电压和电流波形。检查了功率效率，并确定所提出的三相设计是否满足给定的直流配电规范。

Result: 所提出的三相设计（使用两个单端初级电感器转换器）被证明是功率高效的。

Conclusion: 所提出的三相设计使用两个单端初级电感器转换器，它具有功率效率，并且是高功率和高电压应用的有力解决方案。

Abstract: Compared to conventional converters, a three-level buck-boost (3L-BB)
converter offers higher efficiency, reduced switching losses, and increased
power density. We design a 3L-BB converter given certain voltage and current
specifications in PSIM. We simulate the circuit in PSIM and analyze the power,
voltage, and current waveforms by comparing the observed simulated values in
PSIM with their mathematically driven theoretical values. We examine its power
efficiencies and determine if the circuit meets given DC distribution
specifications. We show that the proposed three-phase design, which uses two
DC-DC single-ended primary-conductor converters (SEPICs), is power efficient
and is a compelling solution for high-power and high-voltage applications.

</details>


### [863] [Comprehensive Analysis and Exclusion Hypothesis of $α$-Approximation Method for Discretizing Analog Systems](https://arxiv.org/abs/2509.02054)
*Shen Chen,Jisong Wang,Dejun Liu,Jiaxi Ying,Shuai Wang*

Main category: eess.SY

TL;DR: 该研究全面分析了alpha-逼近方法，这是一种用于数字模型设计的广义s域到z域变换。研究揭示了其与数值积分误差函数的关系，定义了六边形逼近，并通过稳定性分析确定了alpha的稳定范围为[0.5, 1]。此外，研究发现单独调节alpha无法同时最小化幅度和相位失真，并提出了一个假设：不存在单一的alpha值能在奈奎斯特频率范围内所有频率点上同时最小化幅度和相位失真。最终结论是，设计参数alpha需要在幅度和相位失真之间进行权衡。


<details>
  <summary>Details</summary>
Motivation: 介绍alpha-逼近方法作为一种通用的s域到z域变换方法，并对其进行全面分析，包括数学解释、稳定性和失真分析。

Method: 对alpha-逼近方法进行了数学解释（揭示其可由数值积分误差函数导出，并定义为六边形逼近）、稳定性分析（确定alpha的稳定范围为[0.5, 1]）和失真分析（发现单独调节alpha无法同时最小化幅度和相位失真）。

Result: 研究表明alpha-逼近方法可以通过数值积分误差函数推导，并定义为六边形逼近。稳定性分析确定了alpha的稳定范围是[0.5, 1]。失真分析显示，仅通过调整alpha无法同时最小化幅度和相位失真，并提出了一个排除性假设，即不存在一个单一的alpha值能在所有频率点上同时最小化这两种失真。

Conclusion: 设计参数alpha需要在幅度和相位失真之间进行权衡，并且不存在单一的alpha值能够同时最小化奈奎斯特频率范围内所有频率点的幅度和相位失真。

Abstract: A popular method for designing digital models is transforming the transfer
function of the corresponding analog models from continuous domain (s-domain)
into discrete domain (z-domain) using the s-to-z transformation. The
alpha-approximation is a generalized form of these transformations. When alpha
is set to 0.5, the result is the well-known Tustin transformation or bi-linear
transformation. In this paper, we provided a comprehensive analysis of the
alpha-approximation method, including mathematical interpretation, stability
analysis and distortion analysis. Through mathematical interpretation, we
revealed that it can be derived by numerically integrating the error function
We defined this as the hexagonal approximation. We demonstrated that the stable
range of alpha was [0.5, 1] by doing stability analysis. Through distortion
analysis, we found that minimizing amplitude and phase distortion
simultaneously seemed impossible by regulating alpha alone. Finally, We
proposed an exclusion hypothesis hypothesizing that there is no single
parameter alpha to minimize the amplitude distortion and phase distortion
simultaneously across all frequency points within the Nyquist frequency range.
This paper demonstrates that designing parameter alpha involves balancing
amplitude and phase distortion.

</details>


### [864] [Robust Load Disturbance Rejection in PWM DC-DC Buck Converters](https://arxiv.org/abs/2509.02102)
*Simone Pirrera,Francesco Gabriele,Davide Lena,Fabio Pareschi,Diego Regruto,Gianluca Setti*

Main category: eess.SY

TL;DR: 该论文提出了一种新颖的基于双嵌套反馈回路的 DC-DC 降压变换器鲁棒负载扰动抑制方法。


<details>
  <summary>Details</summary>
Motivation: 为了抑制 DC-DC 降压变换器中的负载扰动，并提高系统的鲁棒性。

Method: 外环控制器采用 H 无穷范数最优控制理论设计，并利用 mu 分析证明其在参数不确定性下的鲁棒稳定性。内环引入了新颖的负载估计算法（LEC）来改善对输出负载扰动的响应，并分析了其对整个控制系统鲁棒稳定性的影响。通过数值模拟和实验验证了 LEC 相对于其他线性控制结构在复杂性和性能上的优势。

Result: 所提出的 LEC 方案在抑制负载扰动方面表现出优越的性能，并且实现复杂度较低，实验结果也验证了其有效性。

Conclusion: 该研究成功提出了一种新颖的、性能优越且实现复杂度低的 DC-DC 降压变换器鲁棒负载扰动抑制方法，并通过仿真和实验证实了其有效性。

Abstract: This paper presents a novel approach to robust load disturbance rejection in
DC-DC Buck converters. We propose a novel control scheme based on the design of
two nested feedback loops. First, we design the controller in the outer loop
using H infinity optimal control theory, and we show, by means of mu-analysis,
that such a controller provides robust stability in the presence of uncertainty
affecting the physical parameters of the circuit. Then, we introduce an inner
feedback loop to improve the system's response to output load disturbances. As
far as the inner loop is considered, we propose a novel load
estimation-compensation (LEC) scheme, and we discuss under what conditions the
insertion of such an inner loop preserves the robust stability of the entire
control system. The LEC scheme is compared with the other two linear structures
based on well-established disturbance rejection methods. The advantages of LEC
in terms of both complexity of implementation and obtained performances are
discussed and demonstrated by means of numerical simulation. Finally, we
present experimental results obtained through the implementation of the
proposed control scheme on a prototype board to demonstrate that the proposed
approach significantly enhances disturbance rejection performances with respect
to the approach commonly used in DC-DC buck converters.

</details>


### [865] [Implementing General-Order Frequency Dynamic Response Model and Frequency Excursion Duration Criterion in Unit Commitment Problem](https://arxiv.org/abs/2509.02136)
*Mohammad Rajabdorri,Bo Zhou,Lukas Sigrist,Enrique Lobato*

Main category: eess.SY

TL;DR: 该研究提出一种使用伯恩斯坦多项式逼近的二阶微分方程模型来解决考虑频率动态的机组承诺问题，并通过引入频率偏差持续时间约束来增强频率安全。


<details>
  <summary>Details</summary>
Motivation: 传统机组承诺模型未能充分考虑频率动态，仅依赖简化的一阶假设或标量频率指标。本研究旨在通过显式建模时域频率响应来提供更准确、更灵活的发电机行为表示。

Method: 提出一个通用的二阶微分方程模型来处理频率约束机组承诺问题，并使用伯恩斯坦多项式逼近将其转化为混合整数线性规划问题。此外，引入了一个基于频率偏离临界阈值持续时间的新约束，并通过数据驱动的方法将该约束与频率偏差的持续时间相关联。

Result: 该方法在西班牙一个岛屿系统上进行了验证，结果表明在略微增加运营成本的情况下，频率安全得到了增强。所提出的框架在计算上是可行的，并且能够准确地表示发电机行为。

Conclusion: 该研究提出的考虑频率动态的机组承诺方法，能够增强频率安全，并且对于低惯量、小规模电力系统具有实际应用潜力。

Abstract: This paper introduces a novel approach for incorporating frequency dynamics
into the unit commitment (UC) problem through a general-order differential
equation model, solved using Bernstein polynomial approximation. Traditional
frequency-constrained UC (FCUC) models typically rely on simplified first-order
assumptions or scalar frequency metrics, such as frequency nadir, to indirectly
enforce dynamic behavior. In contrast, our formulation explicitly models
time-domain frequency response using second-order dynamics, enabling a more
accurate and flexible representation of generator behavior. The resulting
differential equations are approximated with high fidelity using Bernstein
polynomials, leading to a mixed-integer linear programming (MILP) formulation
that remains computationally tractable for small-scale power systems.
  Additionally, we introduce a new constraint based on the duration of
frequency excursions below a critical threshold, motivated by practical
concerns such as relay operation and equipment protection. A data-driven method
is employed to relate the area under this threshold-computed as the integral of
the Bernstein approximation-to the duration of frequency deviation. The
proposed framework is validated using real-world data from an island system in
Spain, demonstrating enhanced frequency security with a moderate increase in
operational cost. These results suggest the method's strong potential for
application in low-inertia, small-scale power systems.

</details>


### [866] [Robust Performance Analysis and Nonlinearity Shaping for Closed-loop Reset Control Systems](https://arxiv.org/abs/2509.02143)
*S. Ali Hosseini,Dragan Kostić,S. Hassan HosseinNia*

Main category: eess.SY

TL;DR: 该研究提出了一种名为“鲁棒因子”的新方法，用于量化高阶谐波对复位控制系统（RCS）误差信号的影响，从而在不进行时域仿真的情况下设计滤波器以限制这些非线性效应。


<details>
  <summary>Details</summary>
Motivation: 传统的复位控制系统（RCS）虽然能超越线性时不变（LTI）系统的性能极限，但会引入高阶谐波，增加了设计复杂性。目前缺乏直接量化高阶谐波对误差信号影响的方法，无法脱离时域仿真进行分析。

Method: 提出了一种鲁棒因子 $\sigma_2(\omega)$，用于量化高阶谐波对误差信号均方根（RMS）值的影响。基于此鲁棒因子，开发了一种系统化的设计方法，用于设计预滤波器和后滤波器，以确保 $\sigma_2(\omega)$ 满足预定义的边界，从而在不改变一阶描述函数特性的情况下，限制高阶谐波的影响。

Result: 通过对平面精密定位平台进行案例研究，验证了所提出的鲁棒因子能够指导非线性效应的减小，并提高性能的可预测性。

Conclusion: 所提出的鲁棒因子和基于它的滤波器设计方法，为复位控制系统（RCS）的设计提供了一种不依赖时域仿真、能够有效控制高阶谐波影响的解决方案，从而在允许系统仅依赖一阶描述函数特性的同时，考虑非线性效应。

Abstract: Reset elements are nonlinear filters that improve control performance beyond
linear time-invariant (LTI) limits but introduce higher-order harmonics that
complicate design. Although frequency-domain tools like describing functions
(DFs) and higher-order sinusoidal-input describing functions (HOSIDFs) analyze
reset control systems (RCS), no direct method yet quantifies the impact of
higher-order harmonics on the error signal without time-domain simulations.
This paper introduces a robustness factor, $\sigma_2(\omega)$, which quantifies
the increase in the root-mean-square (RMS) value of the error signal due to
HOSIDFs, enabling RCS to rely solely on first-order DF characteristics while
accounting for nonlinear effects. By using this robustness factor, a systematic
method for designing pre- and post-filters is developed to ensure a predefined
bound on $\sigma_2(\omega)$, thereby limiting the influence of higher-order
harmonics without altering first-order DF behavior. The proposed framework is
validated through a case study on a planar precision positioning stage,
demonstrating how the robustness factor guides the reduction of nonlinearities
and improves performance predictability.

</details>


### [867] [Nuclear fusion plasma fuelling with ice pellets using a neuromorphic controller](https://arxiv.org/abs/2509.02147)
*L. L. T. C. Jansen,E. Petri,M. van Berkel,W. P. M. H. Heemels*

Main category: eess.SY

TL;DR: 堆芯等离子体加注的反应堆级托卡马克需要一种能够处理离散的燃料颗粒和连续演变的等离子体密度的控制方案。本研究提出了一种受整合并发放神经元模型启发的神经形态控制器。


<details>
  <summary>Details</summary>
Motivation: 现有的密度控制方案无法有效处理反应堆级托卡马克中颗粒注入燃料的混合性质（即颗粒的离散影响与连续演变的等离子体密度）。

Method: 提出了一种受整合并发放神经元模型启发的神经形态控制器。将整个系统建模为一个混合系统，并在闭环下与单输入单输出线性时不变等离子体模型进行分析。

Result: 在闭环系统中，当神经元变量达到特定阈值时，控制器会生成代表颗粒发射的脉冲。在控制动作或脉冲之间，系统以开环方式演变。得出了关于控制器变量和最小执行器速度的条件，这些条件取决于所需密度、颗粒大小和等离子体密度时间常数，可确保闭环系统的实际稳定性。

Conclusion: 所提出的神经形态控制器为解决反应堆级托卡马克中颗粒注入燃料的密度控制问题提供了一种有前途的方法，并保证了闭环系统的实际稳定性。

Abstract: In reactor-grade tokamaks, pellet injection is the best candidate for core
plasma fuelling. However, density control schemes that can handle the hybrid
nature of this type of fuelling, i.e., the discrete impact of the pellets on
the continuously evolving plasma density, are lacking. This paper proposes a
neuromorphic controller, inspired by the integrate-and-fire neuronal model, to
address this problem. The overall system is modelled as a hybrid system, and we
analyse the proposed controller in closed loop with a single-input
single-output linear time-invariant plasma model. The controller generates
spikes, representing pellet launches, when the neuron variable reaches a
certain threshold. Between the control actions, or spikes, the system evolves
in open loop. We establish conditions on the controller variables and minimum
actuator speed, depending on the reference value for the desired density, the
pellet size and the time-constant of the plasma density, that guarantee a
practical stability property for the closed-loop system. The results are
illustrated in a numerical example.

</details>


### [868] [Task and Motion Planning of Dynamic Systems using Hyperproperties for Signal Temporal Logics](https://arxiv.org/abs/2509.02184)
*Jianing Zhao,Bowen Ye,Xinyi Yu,Rupak Majumdar,Xiang Yin*

Main category: eess.SY

TL;DR: 本研究针对具有信号时序逻辑（STL）规范的动力学系统，研究任务与运动规划问题，扩展到适用于信息流控制问题的超属性（hyperproperties）和超STL（HyperSTL）逻辑。


<details>
  <summary>Details</summary>
Motivation: 现有STL控制综合方法主要关注满足单一轨迹属性的规划，本研究旨在解决更复杂的超属性规划问题，该问题在信息流控制等领域中普遍存在。

Method: 提出了一种新颖的递归反例引导综合方法，用于处理具有多重交替量词的HyperSTL规范，该方法同时适用于HyperSTL模型检测。

Result: 成功解决了具有HyperSTL规范的离散时间动力学系统的任务与运动规划问题，并能在安全保持规划和无歧义规划等案例研究中展示其有效性。

Conclusion: 所提出的HyperSTL规划框架为解决涉及超属性的动力学系统规划问题提供了一种有效的方法，并可推广至模型检测领域。

Abstract: We investigate the task and motion planning problem for dynamical systems
under signal temporal logic (STL) specifications. Existing works on STL control
synthesis mainly focus on generating plans that satisfy properties over a
single executed trajectory. In this work, we consider the planning problem for
hyperproperties evaluated over a set of possible trajectories, which naturally
arise in information-flow control problems. Specifically, we study
discrete-time dynamical systems and employ the recently developed temporal
logic HyperSTL as the new objective for planning. To solve this problem, we
propose a novel recursive counterexample-guided synthesis approach capable of
effectively handling HyperSTL specifications with multiple alternating
quantifiers. The proposed method is not only applicable to planning but also
extends to HyperSTL model checking for discrete-time dynamical systems.
Finally, we present case studies on security-preserving planning and
ambiguity-free planning to demonstrate the effectiveness of the proposed
HyperSTL planning framework.

</details>


### [869] [Selection of Optimal Number and Location of PMUs for CNN Based Fault Location and Identification](https://arxiv.org/abs/2509.02192)
*Khalid Daud Khattak,Muhammad A. Choudhry*

Main category: eess.SY

TL;DR: FSNR-SVM算法通过结合SVM和CNN，优化PMU placement以提高故障诊断性能，在IEEE 34和123节点系统上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为最大化基于深度学习的故障诊断性能，确定 PMU 的数量和位置。

Method: 提出了一种数据驱动的前向选择结合邻域细化（FSNR）算法。候选 PMU 位置通过交叉验证的支持向量机（SVM）分类器进行排序，并通过局部邻域探索进行细化，以产生接近最优的传感器集。然后将所得 PMU 子集提供给一维卷积神经网络（CNN）进行故障线路定位和故障类型分类。

Result: 所提出的 FSNR-SVM 方法识别出最小的 PMU 配置，可实现最佳的 CNN 整体性能。在 IEEE 34 系统上，故障定位准确率超过 96%，故障类型分类准确率超过 99%。在 IEEE 123 系统上，故障定位准确率约为 94%，故障类型分类准确率约为 99.8%。

Conclusion: FSNR-SVM 方法能够识别出能够最大化深度学习模型性能的最小 PMU 配置。

Abstract: In this paper, we present a data-driven Forward Selection with Neighborhood
Refinement (FSNR) algorithm to determine the number and placement of Phasor
Measurement Units (PMUs) for maximizing deep-learning-based fault diagnosis
performance. Candidate PMU locations are ranked via a cross-validated Support
Vector Machine (SVM) classifier, and each selection is refined through local
neighborhood exploration to produce a near-optimal sensor set. The resulting
PMU subset is then supplied to a 1D Convolutional Neural Network (CNN) for
faulted-line localization and fault-type classification from time-series
measurements. Evaluation on modified IEEE 34- and IEEE 123-bus systems
demonstrates that the proposed FSNR-SVM method identifies a minimal PMU
configuration that achieves the best overall CNN performance, attaining over 96
percent accuracy in fault location and over 99 percent accuracy in fault-type
classification on the IEEE 34 system, and approximately 94 percent accuracy in
fault location and around 99.8 percent accuracy in fault-type classification on
the IEEE 123 system.

</details>


### [870] [Finite-Time Stabilization of a Class of Nonlinear Systems in Hilbert Space](https://arxiv.org/abs/2509.02212)
*Kamal Fenza,Moussa Labbadi,Mohamed Ouzahra*

Main category: eess.SY

TL;DR: 该论文研究了一类非线性无限维系统的有限时间镇定问题。


<details>
  <summary>Details</summary>
Motivation: 解决一类非线性无限维系统的有限时间镇定问题，并处理有界匹配扰动。

Method: 利用值集函数处理扰动，设计反馈控制实现有限时间稳定；基于李雅普诺夫理论进行收敛性证明；利用最大单调理论建立解的存在性和适定性。

Result: 成功实现了有限时间收敛和扰动抑制；设计了确保闭环系统有限时间稳定的反馈控制。

Conclusion: 证明了所提出方法在处理非线性无限维系统有限时间镇定问题上的有效性，并通过热方程的实例进行了说明。

Abstract: This paper deals with the finite-time stabilization of a class of nonlinear
infinite-dimensional systems. First, we consider a bounded matched perturbation
in its linear form. It is shown that by using a set-valued function, both the
convergence objective (finite-time) and the rejection of perturbations are
achieved. Second, we consider a class of nonlinear systems and design a
feedback control that ensures the closed-loop system is finite-time stable. All
proofs presented in this paper regarding convergence are based on Lyapunov
theory. The existence of solutions to the closed-loop system and its
well-posedness are established using maximal monotone theory. To illustrate the
applicability of the theoretical results, a heat equation is considered as an
application of the main results.

</details>


### [871] [2.4-GHz Integrated CMOS Low-Noise Amplifier (English Version)](https://arxiv.org/abs/2509.02224)
*Jorge L. González-Rios,Juan C. Cruz Hurtado,Robson L. Moreno,Diego Vázquez*

Main category: eess.SY

TL;DR: 本文介绍了一款基于130nm CMOS技术的2.4GHz低噪声放大器（LNA），满足IEEE 802.15.4标准，具有10.7dB增益、2.7dB噪声系数、0.9dBm IIP3、优于-20dB的回波损耗和505μW功耗。测量结果与仿真结果一致，为古巴的射频集成电路设计研究做出贡献。


<details>
  <summary>Details</summary>
Motivation: LNA是接收器性能的关键组件，尤其是在集成接收器中。本文旨在设计满足IEEE 802.15.4标准LNA。

Method: 设计、制造和测量了一个使用130nm CMOS技术实现的集成低噪声放大器（LNA），工作频率为2.4GHz。LNA包含静电放电（ESD）保护。

Result: 仿真结果显示，增益为10.7dB，噪声系数为2.7dB，第三阶输入截点（IIP3）为0.9dBm，输入输出阻抗匹配优于-20dB，功耗为505μW（1.2V供电）。实测的S参数与仿真结果一致。

Conclusion: 该LNA的设计和实现达到了预期性能，并将推动古巴在射频集成电路设计领域的研究。

Abstract: This paper presents the analysis, design, fabrication, and measurement of an
integrated low-noise amplifier (LNA) implemented using a 130 nm CMOS
technology, operating in the 2.4 GHz band. The LNA is a crucial component in
the performance of receivers, particularly in integrated receivers. The
proposed LNA was designed to meet the specifications of the IEEE 802.15.4
standard. Post-layout simulation results, including pads with electrostatic
discharge (ESD) protection, are as follows: gain of 10.7 dB, noise figure of
2.7 dB, third-order input intercept point (IIP3) of 0.9 dBm, input and output
impedance matching better than -20 dB with respect to 50~$\Omega$ terminations,
with a power consumption of 505 $\mu$W powered from a 1.2 V supply. The
obtained results fall within the range of those recently reported for the same
topology and operating frequency. The measured scattering parameters
(S-parameters) are consistent with the simulation results. This work
contributes to the development of a new research line in Cuba on the design of
radio-frequency (RF) integrated circuits.

</details>


### [872] [Nano Machine Intelligence: From a Communication Perspective](https://arxiv.org/abs/2509.02235)
*Sangjun Hwang,Bon-Hong Koo,Ho Joong Kim,Jang-Yeon Kwon,Chan-Byoung Chae*

Main category: eess.SY

TL;DR: 本文提出了一种集成AI的分子通信链路，并在亚皮肤植入物相关的纳米机器测试平台上进行了验证。该系统使用葡萄糖氧化酶功能化的IGZO-EGFET作为接收器，配合使用OOK调制方式的微流控通道和注射泵作为发射器，并结合了一个解决模型失配和硬件非理想问题的机器学习流水线。该流水线包括一个对振动噪声、化学延迟和符号间干扰具有鲁棒性的通用解码器，一个用于估计符号间隔的轻量级仅导频同步器，以及一个用于增强数据和缩放符号持续时间的虚拟响应生成器。实验结果表明，与朴素阈值法和标准神经网络基线相比，该系统在化学文本传输方面具有一致的错误率降低。通过结合生物相容性硬件、基于学习的检测和生成增强，该研究为AI原生纳米机器网络和更高数据速率的分子链路提供了实际途径，并为其他生物化学模式提供了适应性系统蓝图。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于为AI原生纳米机器网络和更高数据速率的分子链路提供一条实际可行的路径，并解决现有分子通信链路中存在的模型失配和硬件非理想性问题。

Method: 本研究提出了一种集成AI的分子通信链路，该链路在亚皮肤植入物相关的纳米机器测试平台上进行了验证。具体方法包括：1. 使用葡萄糖氧化酶功能化的铟镓锌氧电解质门控场效应晶体管（IGZO-EGFET）作为生物相容性接收器。2. 采用微流控通道和使用单边带（OOK）调制的注射泵作为发射器。3. 构建了一个机器学习流水线来解决模型失配和硬件非理想性问题，该流水线包含：(i) 一个对振动噪声、化学延迟和单抽头符号间干扰具有鲁棒性的模块化通用解码器；(ii) 一个用于估计符号间隔的轻量级仅导频同步器；(iii) 一个用于增强数据和缩放符号持续时间的虚拟响应生成器。

Result: 实验结果表明，通过在多个芯片和实验会话中进行测试，该系统在端到端的化学文本传输方面，相比于朴素阈值法和标准的神经网络基线，实现了持续的错误率降低。

Conclusion: 本文通过结合生物相容性硬件、基于学习的检测和生成增强技术，为AI原生纳米机器网络和更高数据速率的分子链路提供了一条实际可行的路径，并为适用于其他生物化学模式的系统提供了适应性系统蓝图。

Abstract: We present an AI-integrated molecular communication link validated on a
benchtop nanomachine testbed representative of subdermal implants. The system
employs an indium-gallium-zinc-oxide electrolyte-gated FET (IGZO-EGFET)
functionalized with glucose oxidase as a biocompatible receiver, a microfluidic
channel with a syringe-pump transmitter using on-off keying (OOK), and a
machine-intelligence pipeline that addresses model mismatch and hardware
non-idealities. The pipeline integrates: (i) a modular universal decoder robust
to vibration-induced noise, chemical delay, and single-tap intersymbol
interference; (ii) a lightweight pilot-only synchronizer that estimates symbol
intervals; and (iii) a virtual-response generator that augments data and scales
symbol duration. Experiments across multiple chips and sessions demonstrate
end-to-end chemical text transmission with consistent error-rate reductions
compared to naive thresholding and standard neural baselines. By coupling
biocompatible hardware with learning-based detection and generative
augmentation, this work establishes a practical route toward AI-native
nanomachine networks and higher rate molecular links, while providing a system
blueprint adaptable to other biochemical modalities.

</details>


### [873] [On the Effect of Tap Changers and Nonlinear Loads on Voltage Stability](https://arxiv.org/abs/2509.02238)
*Andrea Zanelli,Dirk Schmidt,Matthias Resch,Marco Giovanelli,Martin Geidl,Walter Sattinger*

Main category: eess.SY

TL;DR: 南欧电网在2024年6月21日发生大面积停电，主要由于两条输电线路跳闸引发电压崩溃，其中伊朗电力变压器和空调等非线性负荷起到了关键作用。本研究旨在评估伊朗电力变压器在非线性负荷存在下对电压稳定性的影响，以进一步阐明类似停电事件的潜在不稳定性机制。


<details>
  <summary>Details</summary>
Motivation: 2024年6月21日，阿尔巴尼亚、黑山、波斯尼亚和黑塞哥维那以及克罗地亚的大部分地区遭受了停电。初步调查显示，伊朗电力变压器和空调等非线性负荷在事件中起到了关键作用。因此，本研究旨在评估伊朗电力变压器在非线性负荷存在下对电压稳定性的影响，以进一步阐明类似停电事件的潜在不稳定性机制。

Method: 评估伊朗电力变压器在非线性负荷存在下对电压稳定性的影响。

Result: 伊朗电力变压器和空调等非线性负荷在事件中起到了关键作用。

Conclusion: 本研究旨在评估伊朗电力变压器在非线性负荷存在下对电压稳定性的影响，以进一步阐明类似停电事件的潜在不稳定性机制。

Abstract: On 21 June 2024, a severe incident happened in the South-Eastern part of the
Continental European power system. After a voltage collapse, large parts of
Albania, Montenegro, Bosnia and Herzegovina as well as Croatia suffered from a
blackout [1]. The initial tripping of two transmission lines resulted in a
voltage collapse in these countries. Investigations have shown that a)
transformers with on-load tap changers (OLTC) and b) nonlinear loads, in
particular air conditioning systems, played a significant role in this event.
Motivated by this, we carry out an assessment of the effect of OLTC on voltage
stability in the presence of nonlinear loads. By doing this we hope to further
shed some light on the potential instability mechanisms that can be triggered
in scenarios like the above-mentioned blackout.

</details>


### [874] [Stability-Aware Joint Communication and Control for Nonlinear Control-Non-Affine Wireless Networked Control Systems](https://arxiv.org/abs/2509.02247)
*Rasika Vijithasena,Rafaela Scaciota,Mehdi Bennis,Sumudu Samarakoon*

Main category: eess.SY

TL;DR: 该研究提出了一种结合深度koopman模型和Lyapunov优化的联合通信与控制方法，以解决非线性无线网络控制系统（WNCS）的稳定性问题，特别是在资源受限的6G环境中。


<details>
  <summary>Details</summary>
Motivation: 为满足6G支持实时自主系统对可靠通信的需求，解决具有非线性动力学且资源受限的无线网络控制系统（WNCS）的稳定性问题。

Method: 提出了一种联合通信和控制解决方案：1）一个深度Koopman模型，用于学习和表示复杂的非线性动力学，预测缺失状态，并在嵌入空间中规划控制动作；2）一个基于Lyapunov优化的调度算法，根据系统稳定性和可用资源动态分配通信资源。控制动作在嵌入空间中使用线性二次调节器（LQR）进行计算，以确保系统稳定性。

Result: 与两种基线模型（假设系统是控制仿射的和嵌入空间与原始空间控制动作相同的模型）相比，所提出的模型在不同条件下表现更优，以更少的传输实现了稳定性。

Conclusion: 所提出的联合通信与控制方法能够有效解决非线性WNCS的稳定性问题，并在资源受限的情况下优于现有方法。

Abstract: Ensuring the stability of wireless networked control systems (WNCS) with
nonlinear and control-non-affine dynamics, where system behavior is nonlinear
with respect to both states and control decisions, poses a significant
challenge, particularly under limited resources. However, it is essential in
the context of 6G, which is expected to support reliable communication to
enable real-time autonomous systems. This paper proposes a joint communication
and control solution consisting of: i) a deep Koopman model capable of learning
and mapping complex nonlinear dynamics into linear representations in an
embedding space, predicting missing states, and planning control actions over a
future time horizon; and ii) a scheduling algorithm that schedules
sensor-controller communication based on Lyapunov optimization, which
dynamically allocates communication resources based on system stability and
available resources. Control actions are computed within this embedding space
using a linear quadratic regulator (LQR) to ensure system stability. The
proposed model is evaluated under varying conditions and its performance is
compared against two baseline models; one that assumes systems are
control-affine, and another that assumes identical control actions in the
embedding and original spaces. The evaluation results demonstrate that the
proposed model outperforms both baselines, by achieving stability while
requiring fewer transmissions.

</details>


### [875] [TREE:Token-Responsive Energy Efficiency Framework For Green AI-Integrated 6G Networks](https://arxiv.org/abs/2509.02250)
*Tao Yu,Kaixuan Huang,Tengsheng Wang,Jihong Li,Shunqing Zhang,Shuangfeng Han,Xiaoyun Wang,Qunsong Zeng,Kaibin Huang,Vincent K. N. Lau*

Main category: eess.SY

TL;DR: 提出了一种新的能源效率指标TREE，用于量化AI集成6G网络的能耗和服务价值。


<details>
  <summary>Details</summary>
Motivation: 传统的能源效率指标无法衡量AI任务的价值，因此需要新的指标来适应AI集成网络的发展。

Method: 提出了一种名为Token-Responsive Energy Efficiency (TREE)的新型能源效率指标，该指标将大模型的token吞吐量作为网络效用载体纳入系统效用，并基于此分析了AI集成6G网络的设计原则，重点关注了计算能力、模型和数据三个关键AI要素。

Result: 案例研究验证了TREE在混合流量场景下暴露能源-服务不对称性的独特能力，而传统指标则显得不足。TREE能够量化AI服务的运行能耗成本。

Conclusion: 提出的TREE指标和基于该指标的框架有助于网络运营商量化AI服务的能耗成本，推动网络向可持续的6G网络演进。

Abstract: As wireless networks evolve toward AI-integrated intelligence, conventional
energy-efficiency metrics fail to capture the value of AI tasks. In this paper,
we propose a novel EE metric called Token-Responsive Energy Efficiency (TREE),
which incorporates the token throughput of large models as network utility
carriers into the system utility. Based on this metric, we analyze the design
principles of AI-integrated 6G networks from the perspective of three critical
AI elements, namely computing power, model and data. Case studies validate
TREE's unique capability to expose energy-service asymmetries in hybrid traffic
scenarios where conventional metrics prove inadequate. Although it is
impossible to determine every design detail of AI-integrated 6G network at
current time, we believe that the proposed TREE based framework will help the
network operators to quantify the operating energy cost of AI services and
continue to evolve towards sustainable 6G networks.

</details>


### [876] [Frequency-Domain Characterization of Load Demand from Electrified Highways](https://arxiv.org/abs/2509.02426)
*Ashutossh Gupta,Vassilis Kekatos,Ruoyu Yang,Dionysios Aliprantis,Steve Pekarek*

Main category: eess.SY

TL;DR: 电动道路的动态无线电力传输（DWPT）可能引发电力系统频率动态。本研究通过统计模型研究了不同交通条件下的DWPT负载频谱，并确定了负载谐波的位置和幅度。结果显示，基频取决于线圈间距和平均车速。在最坏情况下，谐波幅度与EV数量成正比；在自由行驶情况下，与EV数量的平方根成正比。行军纵队会加剧谐波。高阶谐波的频谱内容幅度减小，带宽增加。


<details>
  <summary>Details</summary>
Motivation: 研究了电动道路（ER）中的动态无线电力传输（DWPT）负载对电力系统频率动态的影响，旨在了解不同交通条件下的DWPT负载频谱。

Method: 开发了用于分析恒定速度行驶的电动汽车（EV）的统计模型，以识别DWPT负载谐波的位置和幅度。

Result: 确定了基频与线圈间距和平均车速的关系，并分析了谐波幅度与EV数量（同步行驶、自由行驶和行军纵队）的关系。研究还表明，高阶谐波的频谱内容幅度减小，带宽增加。

Conclusion: 该分析为了解DWPT负载对电力系统频率动态的影响提供了有价值的见解，可供ER规划者和电网运营商参考。仿真测试验证了部分研究结果。

Abstract: Electrified roadways (ER) equipped with dynamic wireless power transfer
(DWPT) capabilities can patently extend the driving range and reduce the
battery size of electric vehicles (EVs). However, due to the spatial
arrangement of the transmitter coils in the ER, the DWPT load exhibits
frequency content that could excite power system frequency dynamics. In this
context, this work aims to study the spectrum of DWPT loads under different
traffic conditions. We develop statistical models for EVs moving at constant
speeds to identify the location and magnitude of DWPT load harmonics. Our
analysis reveals that the fundamental frequency is dependent on the ER coil
spacing and the average EV speed. In the worst-case yet unlikely scenario that
EVs move in a synchronized fashion, the amplitude of harmonics scales with the
number of EVs. On the contrary, when EVs move freely, harmonics scale with the
square root of the number of EVs. Platoon formations can accentuate harmonics.
We also show that for higher-order harmonics, the spectral content around
harmonics decreases in magnitude and increases in bandwidth. Despite the
simplified models, our analysis offers valuable insights for ER planners and
grid operators. Numerical tests using a traffic simulator corroborate some of
these insights.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [877] [AGS: Accelerating 3D Gaussian Splatting SLAM via CODEC-Assisted Frame Covisibility Detection](https://arxiv.org/abs/2509.00433)
*Houshu He,Naifeng Jing,Li Jiang,Xiaoyao Liang,Zhuoran Song*

Main category: cs.AR

TL;DR: AGS通过算法-硬件协同设计提升3DGS-SLAM的效率，实现了显著的加速。开源代码和模型可在GitHub获取。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS-SLAM系统由于需要多次迭代训练和大量的Gaussian点，吞吐量不足。本研究旨在提高3DGS-SLAM的效率。

Method: AGS框架在软件层面提出了一种粗粒度到细粒度的姿态跟踪方法，并避免了通过跨帧共享高斯点贡献信息来减少冗余计算。在硬件层面，AGS实现了一个帧共视检测引擎，用于从视频编解码器提取中间数据，并实现了一个带有工作负载调度器的姿态跟踪引擎和映射引擎来高效部署AGS算法。

Result: AGS在与移动和高端GPU以及最先进的3DGS加速器GSCore的对比评估中，实现了高达17.12倍、6.71倍和5.41倍的加速。

Conclusion: AGS通过算法-硬件协同设计，有效解决了现有3DGS-SLAM系统吞吐量不足的问题，显著提高了效率。

Abstract: Simultaneous Localization and Mapping (SLAM) is a critical task that enables
autonomous vehicles to construct maps and localize themselves in unknown
environments. Recent breakthroughs combine SLAM with 3D Gaussian Splatting
(3DGS) to achieve exceptional reconstruction fidelity. However, existing
3DGS-SLAM systems provide insufficient throughput due to the need for multiple
training iterations per frame and the vast number of Gaussians.
  In this paper, we propose AGS, an algorithm-hardware co-design framework to
boost the efficiency of 3DGS-SLAM based on the intuition that SLAM systems
process frames in a streaming manner, where adjacent frames exhibit high
similarity that can be utilized for acceleration. On the software level: 1) We
propose a coarse-then-fine-grained pose tracking method with respect to the
robot's movement. 2) We avoid redundant computations of Gaussians by sharing
their contribution information across frames. On the hardware level, we propose
a frame covisibility detection engine to extract intermediate data from the
video CODEC. We also implement a pose tracking engine and a mapping engine with
workload schedulers to efficiently deploy the AGS algorithm. Our evaluation
shows that AGS achieves up to $17.12\times$, $6.71\times$, and $5.41\times$
speedups against the mobile and high-end GPUs, and a state-of-the-art 3DGS
accelerator, GSCore.

</details>


### [878] [Bit Transition Reduction by Data Transmission Ordering in NoC-based DNN Accelerator](https://arxiv.org/abs/2509.00500)
*Yizhi Chen,Jingwei Li,Wenyao Zhu,Zhonghai Lu*

Main category: cs.AR

TL;DR: 本文提出了一种基于'1'-比特计数排序的方法来减少DNN工作负载中的比特转换（BT），从而节省NoC中的链路功耗。


<details>
  <summary>Details</summary>
Motivation: 随着DNN日益普及，基于NoC的DNN加速器受到广泛关注。为了降低NoC中的链路功耗，研究人员致力于减少比特转换（BT）。

Method: 提出了一种基于'1'-比特计数排序的方法来减少DNN工作负载中的比特转换。通过数学证明了该方法的有效性。提出了两种数据排序方法（affiliated-ordering和separated-ordering）来联合或单独处理权重和输入，并将其应用于NoC中基于DNN加速器的运行。

Result: 在没有NoC的情况下，该方法能将浮点32数据和定点8数据的BT分别降低高达20.38%和55.71%。在NoC中，通过 affiliation-ordering 和 separated-ordering 方法，浮点32数据的BT降低高达32.01%，定点8数据的BT降低高达40.85%。

Conclusion: 所提出的排序方法能够有效降低NoC中的链路功耗，并在多种DNN模型、NoC配置和数据精度下验证了其有效性。

Abstract: As Deep Neural Networks (DNN) are becoming essential, Network-on-Chip
(NoC)-based DNN accelerators gained increasing popularity. To save link power
in NoC, many researchers focus on reducing the Bit Transition (BT). We propose
'1'-bit count-based ordering method to reduce BT for DNN workloads. We provide
a mathematical proof of the efficacy of proposed ordering. We evaluate our
method through experiments without NoC and with NoC. Without NoC, our proposed
ordering method achieves up to 20.38% BT reduction for floating-point-32 data
and 55.71% for fixed-point-8 data, respectively. We propose two data ordering
methods, affiliated-ordering and separated-ordering to process weight and input
jointly or individually and apply them to run full DNNs in NoC-based DNN
accelerator. We evaluate our approaches under various configurations, including
different DNN models such as LeNet and DarkNet, various NoC sizes with
different numbers of memory controllers, random weights and trained weights,
and different data precision. Our approach efficiently reduces the link power
by achieving up to 32.01% BT reduction for floating-point-32 data and 40.85% BT
reduction for fixed-point-8 data.

</details>


### [879] [Real-Time Piano Note Frequency Detection Using FPGA and FFT Core](https://arxiv.org/abs/2509.00589)
*Shafayet M. Anik,D. G. Perera*

Main category: cs.AR

TL;DR: FPGA可用于实时音频信号分析，比传统软件方法更快、更确定。


<details>
  <summary>Details</summary>
Motivation: 传统软件方法在处理实时音乐信号分析时存在延迟和计算能力需求大的问题。

Method: 使用基于FPGA的实时快速傅里叶变换（FFT）系统来分析数码钢琴的模拟音频信号。

Result: FPGA平台能够利用其并行处理能力，实现比传统软件更快速、更确定的分析。

Conclusion: FPGA平台为实时音频信号分析提供了一种高效的解决方案。

Abstract: Real-time frequency analysis of musical instruments, such as the piano, is an
essential feature in areas like electronic tuners, music visualizers, and live
sound monitoring. Traditional methods often rely on software-based digital
signal processing (DSP), which may introduce latency and require significant
computational power. In contrast, hardware platforms such as FPGAs (Field
Programmable Gate Arrays) offer the ability to perform such analyses with
greater speed and determinism due to their parallel processing capabilities.
The primary objective of this project was to analyze analog audio signals from
a digital piano using an FPGA-based real-time Fast Fourier Transform (FFT)
system.

</details>


### [880] [COMET: A Framework for Modeling Compound Operation Dataflows with Explicit Collectives](https://arxiv.org/abs/2509.00599)
*Shubham Negi,Manik Singhal,Aayush Ankit,Sudeep Bhoja,Kaushik Roy*

Main category: cs.AR

TL;DR: COMET是一个用于在机器学习加速器上对复合操作进行数据流建模和优化的框架，它显式地对跨空间集群的集体通信以及复合操作内的GEMM和非GEMM操作级别依赖关系进行建模，实现了性能和能效的提升。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习加速器在优化数据移动、内存层次结构和计算吞吐量方面效率很高，但新兴的DNN模型（如大型语言模型、状态空间模型）依赖于复合操作，这给数据流优化和最小化片外内存流量带来了新的挑战。此外，随着模型规模的增长，跨空间分布式计算集群的部署变得至关重要，需要频繁且复杂的集体通信。现有的数据流优化框架和性能模型要么只关注单个操作，要么缺乏对集体通信成本的显式建模，这限制了它们在现代工作负载中的应用。

Method: 提出了一种名为COMET的框架，用于在机器学习加速器上对复合操作的数据流进行建模和优化。COMET引入了一种新的表示方法，该方法显式地对跨空间集群的集体通信进行建模，并结合了延迟和能量成本模型，这些模型考虑了复合操作中GEMM和非GEMM操作级别内的依赖关系。

Result: COMET能够分析和优化复合操作（如GEMM-Softmax、GEMM-LayerNorm和自注意力）的数据流，适用于边缘和云加速器配置。通过集体感知建模，COMET能够探索更广泛的映射空间，从而提高性能和能效。具体而言，与未融合的基线相比，COMET优化的数据流在GEMM-Softmax方面实现了高达1.42倍的加速，在GEMM-LayerNorm方面实现了3.46倍的加速，在自注意力方面实现了1.82倍的加速。

Conclusion: COMET通过显式建模集体通信和复合操作内的操作依赖关系，解决了现有数据流优化框架在处理现代DNN工作负载方面的局限性，并在性能和能效方面取得了显著的改进。

Abstract: Modern machine learning accelerators are designed to efficiently execute deep
neural networks (DNNs) by optimizing data movement, memory hierarchy, and
compute throughput. However, emerging DNN models such as large language models,
state space models increasingly rely on compound operations-structured
compositions of multiple basic operations-which introduce new challenges for
dataflow optimization and minimizing off-chip memory traffic. Moreover, as
model size continues to grow, deployment across spatially distributed compute
clusters becomes essential, requiring frequent and complex collective
communication. Existing dataflow optimization frameworks and performance models
either focus on single operations or lack explicit modeling of collective
communication cost, limiting their applicability to modern workloads.
  To address these limitations, we propose, a framework for modeling and
optimizing dataflow for compound operations on machine learning accelerators.
COMET introduces a novel representation that explicitly models collective
communication across spatial clusters, along with latency and energy cost
models that account for both GEMM and non-GEMM operation level dependencies
within compound operations. We demonstrate COMET's capabilities to analyze and
optimize dataflows for compound operations such as GEMM--Softmax,
GEMM--LayerNorm, and self-attention, across both edge and cloud accelerator
configurations. Our collective-aware modeling enables exploration of a broader
mapping space, leading to improved performance and energy efficiency.
Specifically, our optimized dataflows achieve up to 1.42$\times$ speedup for
GEMM-Softmax, 3.46$\times$ for GEMM-LayerNorm and 1.82$\times$ for
self-attention compared to unfused baselines.

</details>


### [881] [On the Thermal Vulnerability of 3D-Stacked High-Bandwidth Memory Architectures](https://arxiv.org/abs/2509.00633)
*Mehdi Elahi,Mohamed R. Elshamy,Abdel-Hameed A. Badawy,Ahmad Patooghy*

Main category: cs.AR

TL;DR: HBM架构易受热性能下降攻击，攻击者利用垂直和侧向邻近性注入热脉冲，导致受害者应用程序访问延迟，且难以检测。


<details>
  <summary>Details</summary>
Motivation: HBM架构在提供高性能的同时，由于制造过程中的垂直邻近性，容易受到热相关漏洞的攻击。

Method: 通过注入短暂而强烈的热脉冲，从垂直和/或侧向邻近的内存库制造汇聚热波，最大化影响并延迟受害者应用程序访问数据/指令。

Result: 攻击者可以通过利用HBM架构的垂直和侧向邻近性来设计和开发针对内存库的热性能下降攻击，受害者应用程序的访问会被延迟。

Conclusion: 由于攻击模仿合法工作负载，并且不访问越界内存地址，因此可以规避设计时安全测试和操作系统内存管理策略，使其难以被检测。

Abstract: 3D-stacked High Bandwidth Memory (HBM) architectures provide high-performance
memory interactions to address the well-known performance challenge, namely the
memory wall. However, these architectures are susceptible to thermal
vulnerabilities due to the inherent vertical adjacency that occurs during the
manufacturing process of HBM architectures. We anticipate that adversaries may
exploit the intense vertical and lateral adjacency to design and develop
thermal performance degradation attacks on the memory banks that host
data/instructions from victim applications. In such attacks, the adversary
manages to inject short and intense heat pulses from vertically and/or
laterally adjacent memory banks, creating a convergent thermal wave that
maximizes impact and delays the victim application from accessing its
data/instructions. As the attacking application does not access any
out-of-range memory locations, it can bypass both design-time security tests
and the operating system's memory management policies. In other words, since
the attack mimics legitimate workloads, it will be challenging to detect.

</details>


### [882] [Low Power Approximate Multiplier Architecture for Deep Neural Networks](https://arxiv.org/abs/2509.00764)
*Pragun Jaswal,L. Hemanth Krishna,B. Srinivasu*

Main category: cs.AR

TL;DR: 该论文提出了一种用于深度神经网络（DNN）的低功耗近似乘法器架构，通过设计一个仅引入单一组合误差的4:2压缩器并将其集成到8x8无符号乘法器中，可以显著减少精确压缩器的使用，同时保持低错误率。该乘法器已应用于自定义卷积层，并在图像识别和去噪等神经网络任务中进行了评估。硬件评估结果显示，与现有的最优乘法器相比，该设计实现了高达30.24%的能耗节省。在图像去噪方面，自定义近似卷积层在PSNR和SSIM方面优于其他近似设计。此外，在手写数字识别任务中，模型保持了高分类精度，表明该架构在能效和计算精度之间取得了良好的平衡，适用于低功耗AI硬件实现。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络（DNN）应用需要高效的硬件实现，但精确乘法器会消耗大量功耗。因此，需要低功耗的近似乘法器来满足这些需求。

Method: 提出了一种低功耗近似乘法器架构，使用了仅引入单一组合误差的4:2压缩器，并将其集成到8x8无符号乘法器中。该乘法器应用于自定义卷积层，并在图像识别和去噪任务上进行了评估。

Result: 与现有最优乘法器相比，该设计实现了高达30.24%的能耗节省。在图像去噪任务中，PSNR和SSIM均优于其他近似设计。在手写数字识别任务中，分类精度保持很高。

Conclusion: 所提出的低功耗近似乘法器架构在能效和计算精度之间取得了良好的平衡，适用于低功耗AI硬件实现。

Abstract: This paper proposes an low power approximate multiplier architecture for deep
neural network (DNN) applications. A 4:2 compressor, introducing only a single
combination error, is designed and integrated into an 8x8 unsigned multiplier.
This integration significantly reduces the usage of exact compressors while
preserving low error rates. The proposed multiplier is employed within a custom
convolution layer and evaluated on neural network tasks, including image
recognition and denoising. Hardware evaluation demonstrates that the proposed
design achieves up to 30.24% energy savings compared to the best among existing
multipliers. In image denoising, the custom approximate convolution layer
achieves improved Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity
Index Measure (SSIM) compared to other approximate designs. Additionally, when
applied to handwritten digit recognition, the model maintains high
classification accuracy. These results demonstrate that the proposed
architecture offers a favorable balance between energy efficiency and
computational precision, making it suitable for low-power AI hardware
implementations.

</details>


### [883] [Energy Efficient Exact and Approximate Systolic Array Architecture for Matrix Multiplication](https://arxiv.org/abs/2509.00778)
*Pragun Jaswal,L. Hemanth Krishna,B. Srinivasu*

Main category: cs.AR

TL;DR: 该论文提出了一种包含新型精确和近似处理单元（PE）的脉动阵列架构，以提高DNN计算的能效。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度神经网络（DNN）对高效矩阵乘法引擎的需求，该研究旨在设计一种节能的脉动阵列架构。

Method: 研究提出了一种采用能量高效的正偏积和负偏积单元（PPC和NPPC）的脉动阵列架构。论文中设计了8位精确和近似PE，并将其应用于8x8脉动阵列中，实现了22%和32%的能效提升。

Result: 在DCT计算中，该设计实现了38.21 dB的PSNR；在边缘检测应用中，近似PE达到了30.45 dB的PSNR，展示了在保持输出质量的同时提高能效的潜力。

Conclusion: 提出的PE设计通过显著的能效提升和可接受的输出质量，适用于对错误有弹性的图像和视觉处理应用。

Abstract: Deep Neural Networks (DNNs) require highly efficient matrix multiplication
engines for complex computations. This paper presents a systolic array
architecture incorporating novel exact and approximate processing elements
(PEs), designed using energy-efficient positive partial product and negative
partial product cells, termed as PPC and NPPC, respectively. The proposed 8-bit
exact and approximate PE designs are employed in a 8x8 systolic array, which
achieves a energy savings of 22% and 32%, respectively, compared to the
existing design. To demonstrate their effectiveness, the proposed PEs are
integrated into a systolic array (SA) for Discrete Cosine Transform (DCT)
computation, achieving high output quality with a PSNR of 38.21,dB.
Furthermore, in an edge detection application using convolution, the
approximate PE achieves a PSNR of 30.45,dB. These results highlight the
potential of the proposed design to deliver significant energy efficiency while
maintaining competitive output quality, making it well-suited for
error-resilient image and vision processing applications.

</details>


### [884] [GS-TG: 3D Gaussian Splatting Accelerator with Tile Grouping for Reducing Redundant Sorting while Preserving Rasterization Efficiency](https://arxiv.org/abs/2509.00911)
*Joongho Jo,Jongsun Park*

Main category: cs.AR

TL;DR: GS-TG是一种基于瓦片分组的加速器，可提高3D高斯泼溅渲染速度，平均提速1.54倍。


<details>
  <summary>Details</summary>
Motivation: 尽管3D高斯泼溅（3D-GS）在视图合成方面表现出色，但其渲染速度仍难以满足实时应用的要求。现有方法在减小排序冗余和保持光栅化效率之间存在权衡。

Method: GS-TG通过在排序阶段将小瓦片分组以共享排序操作，在光栅化阶段使用位掩码为每个高斯识别相关的小瓦片，从而在不牺牲光栅化效率的情况下减少冗余排序。

Result: GS-TG实现了平均1.54倍于现有3D-GS加速器的速度提升，且无需重新训练或微调。

Conclusion: GS-TG通过创新的瓦片分组和位掩码技术，有效解决了3D-GS渲染速度瓶颈，实现了速度和效率的提升，并且易于集成。

Abstract: 3D Gaussian Splatting (3D-GS) has emerged as a promising alternative to
neural radiance fields (NeRF) as it offers high speed as well as high image
quality in novel view synthesis. Despite these advancements, 3D-GS still
struggles to meet the frames per second (FPS) demands of real-time
applications. In this paper, we introduce GS-TG, a tile-grouping-based
accelerator that enhances 3D-GS rendering speed by reducing redundant sorting
operations and preserving rasterization efficiency. GS-TG addresses a critical
trade-off issue in 3D-GS rendering: increasing the tile size effectively
reduces redundant sorting operations, but it concurrently increases unnecessary
rasterization computations. So, during sorting of the proposed approach, GS-TG
groups small tiles (for making large tiles) to share sorting operations across
tiles within each group, significantly reducing redundant computations. During
rasterization, a bitmask assigned to each Gaussian identifies relevant small
tiles, to enable efficient sharing of sorting results. Consequently, GS-TG
enables sorting to be performed as if a large tile size is used by grouping
tiles during the sorting stage, while allowing rasterization to proceed with
the original small tiles by using bitmasks in the rasterization stage. GS-TG is
a lossless method requiring no retraining or fine-tuning and it can be
seamlessly integrated with previous 3D-GS optimization techniques. Experimental
results show that GS-TG achieves an average speed-up of 1.54 times over
state-of-the-art 3D-GS accelerators.

</details>


### [885] [GeneTEK: Low-power, high-performance and scalable genome sequence matching in FPGAs](https://arxiv.org/abs/2509.01020)
*Elena Espinosa,Rubén Rodríguez Álvarez,José Miranda,Rafael Larrosa,Miguel Peón-Quirós,Oscar Plata,David Atienza*

Main category: cs.AR

TL;DR: NGS 技术的进步产生了海量基因组数据，对计算资源提出了巨大挑战。本研究提出了一种基于 FPGA 的可扩展加速器模板 GeneTEK，用于加速序列比对，并取得了比 CPU 和 GPU 更优越的速度和能效表现。


<details>
  <summary>Details</summary>
Motivation: 由于 NGS 技术的发展，基因组学产生了海量数据，序列比对作为生物信息学流程中的关键步骤，对时间和能量的消耗巨大，需要加速。

Method: 提出了一种基于 FPGA 的可扩展且灵活的加速器模板，使用高层次综合和基于 worker 的架构来实现 Myers 算法。

Result: GeneTEK 在 Xilinx Zynq UltraScale+ FPGA 上实现了 19.4% 的速度提升和高达 62 倍的能耗降低，并且克服了现有 FPGA 方法的可扩展性限制，能够处理更大的比对矩阵。

Conclusion: FPGA 作为一种高能效的平台，在处理可扩展的基因组工作负载方面具有巨大潜力。

Abstract: The advent of next-generation sequencing (NGS) has revolutionized genomic
research by enabling high-throughput data generation through parallel
sequencing of a diverse range of organisms at significantly reduced costs. This
breakthrough has unleashed a "Cambrian explosion" in genomic data volume and
diversity. This volume of workloads places genomics among the top four big data
challenges anticipated for this decade. In this context, pairwise sequence
alignment represents a very time- and energy-consuming step in common
bioinformatics pipelines. Speeding up this step requires the implementation of
heuristic approaches, optimized algorithms, and/or hardware acceleration.
  Whereas state-of-the-art CPU and GPU implementations have demonstrated
significant performance gains, recent field programmable gate array (FPGA)
implementations have shown improved energy efficiency. However, the latter
often suffer from limited scalability due to constraints on hardware resources
when aligning longer sequences. In this work, we present a scalable and
flexible FPGA-based accelerator template that implements Myers's algorithm
using high-level synthesis and a worker-based architecture. GeneTEK, an
instance of this accelerator template in a Xilinx Zynq UltraScale+ FPGA,
outperforms state-of-the-art CPU and GPU implementations in both speed and
energy efficiency, while overcoming scalability limitations of current FPGA
approaches. Specifically, GeneTEK achieves at least a 19.4% increase in
execution speed and up to 62x reduction in energy consumption compared to
leading CPU and GPU solutions, while fitting comparison matrices up to 72%
larger compared to previous FPGA solutions. These results reaffirm the
potential of FPGAs as an energy-efficient platform for scalable genomic
workloads.

</details>


### [886] [LinkBo: An Adaptive Single-Wire, Low-Latency, and Fault-Tolerant Communications Interface for Variable-Distance Chip-to-Chip Systems](https://arxiv.org/abs/2509.01339)
*Bochen Ye,Gustavo Naspolini,Kimmo Salo,Manil Dev Gomony*

Main category: cs.AR

TL;DR: LinkBo是一种创新的单线通信协议，可降低延迟、提高吞吐量并增强鲁棒性，具有用于可变距离芯片间通信的硬件中断功能。它在关键任务消息的延迟方面超越了现有的商业选择，并能在高达15米的线路上支持300 kbps的数据速率，或在11厘米的线路上支持高达7.5 Mbps的数据速率。


<details>
  <summary>Details</summary>
Motivation: 为了满足具有成本效益的嵌入式系统对单线通信协议的需求，以减少引脚数量并克服现有协议的延迟、吞吐量和鲁棒性限制。

Method: 提出了一种名为LinkBo的创新单线通信协议，并设计了其硬件架构。通过在由两个FPGA组成的硬件平台上进行性能评估来验证其有效性。

Result: LinkBo协议在50.4μs内即可保证高优先级消息的传输，并具有错误检测功能，其性能优于1-wire和UNI/O协议。该协议可靠支持长达15米的线缆长度，数据速率为300 kbps，而在11厘米线缆上的数据速率可达7.5 Mbps。

Conclusion: LinkBo协议为可变距离的芯片间通信提供了一种高性能、低延迟、高吞吐量和高鲁棒性的解决方案，克服了现有单线协议的局限性。

Abstract: Cost-effective embedded systems necessitate utilizing the single-wire
communication protocol for inter-chip communication, thanks to its reduced pin
count in comparison to the multi-wire I2C or SPI protocols. However, current
single-wire protocols suffer from increased latency, restricted throughput, and
lack of robustness. This paper presents LinkBo, an innovative single-wire
protocol that offers reduced latency, enhanced throughput, and greater
robustness with hardware-interrupt for variable-distance inter-chip
communication. The LinkBo protocol-level guarantees that high-priority messages
are delivered with an error detection feature in just 50.4 $\mu$s, surpassing
current commercial options, 1-wire and UNI/O by at least 20X and 6.3X,
respectively. In addition, we present the hardware architecture for this new
protocol and its performance evaluation on a hardware platform consisting of
two FPGAs. Our findings demonstrate that the protocol reliably supports wire
lengths up to 15 meters with a data rate of 300 kbps, while reaching a maximum
data rate of 7.5 Mbps over an 11 cm wire, providing reliable performance for
varying inter-chip communication distances.

</details>


### [887] [Guidance and Control Neural Network Acceleration using Memristors](https://arxiv.org/abs/2509.02369)
*Zacharia A. Rudge,Dario Izzo,Moritz Fieback,Anteneh Gebregiorgis,Said Hamdioui,Dominik Dold*

Main category: cs.AR

TL;DR: 太长不看：本文研究了在太空应用中使用忆阻器（PCM和RRAM）来加速人工智能（AI）和神经网络（NN）。模拟显示，基于忆阻器的加速器可以学习专家行为，但噪声会影响准确性。然而，在退化后进行再训练可以恢复性能。该研究为未来基于忆阻器的太空AI加速器研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 由于小卫星和立方星的能源预算有限以及辐射问题，需要能够满足这些要求并满足应用计算和性能需求的新型神经网络加速器。

Method: 通过模拟，在各种场景下使用PCM和RRAM忆阻器来评估基于忆阻器的AI加速器的性能，并考虑了噪声和电导漂移等设备非理想因素。

Result: 基于忆阻器的加速器能够学习专家行为，但噪声对准确性有影响。在退化后进行再训练可以恢复性能。

Conclusion: 基于忆阻器的AI加速器在太空应用中具有潜力，但仍需进一步研究以解决噪声等挑战。

Abstract: In recent years, the space community has been exploring the possibilities of
Artificial Intelligence (AI), specifically Artificial Neural Networks (ANNs),
for a variety of on board applications. However, this development is limited by
the restricted energy budget of smallsats and cubesats as well as radiation
concerns plaguing modern chips. This necessitates research into neural network
accelerators capable of meeting these requirements whilst satisfying the
compute and performance needs of the application. This paper explores the use
of Phase-Change Memory (PCM) and Resistive Random-Access Memory (RRAM)
memristors for on-board in-memory computing AI acceleration in space
applications. A guidance and control neural network (G\&CNET) accelerated using
memristors is simulated in a variety of scenarios and with both device types to
evaluate the performance of memristor-based accelerators, considering device
non-idealities such as noise and conductance drift. We show that the memristive
accelerator is able to learn the expert actions, though challenges remain with
the impact of noise on accuracy. We also show that re-training after
degradation is able to restore performance to nominal levels. This study
provides a foundation for future research into memristor-based AI accelerators
for space, highlighting their potential and the need for further investigation.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [888] [Undecidability of Linear Logics without Weakening](https://arxiv.org/abs/2509.00644)
*Jun Suzuki,Katsuhiko Sano*

Main category: cs.LO

TL;DR: 该论文证明了在 Girard (1987) 提出的经典命题线性逻辑 CLL 基础上省略了指数模态的弱化规则的两个系统（CLLR 和 CLLRR）是不可判定的。


<details>
  <summary>Details</summary>
Motivation: 为了证明在 Girard (1987) 提出的经典命题线性逻辑 CLL 基础上省略了指数模态的弱化规则的两个系统（CLLR 和 CLLRR）是不可判定的。

Method: 对于 CLLR，通过将单位 1 和 ⊥ 的弱化规则模拟还原到 CLL 的不可判定性来证明其不可判定性。对于 CLLRR，通过展示该系统可以模拟 Minsky (1961) 提出的任何双计数器机来证明其不可判定性。

Result: 证明了 CLLR 和 CLLRR 两个系统是不可判定的。

Conclusion: 在 Girard (1987) 提出的经典命题线性逻辑 CLL 基础上省略了指数模态的弱化规则的两个系统 CLLR 和 CLLRR 是不可判定的。

Abstract: The goal of this paper is to establish that it remains undecidable whether a
sequent is provable in two systems in which a weakening rule for an exponential
modality is completely omitted from classical propositional linear logic
$\mathbf{CLL}$ introduced by Girard (1987), which is shown to be undecidable by
Lincoln et al. (1992). We introduce two logical systems, $\mathbf{CLLR}$ and
$\mathbf{CLLRR}$. The first system, $\mathbf{CLLR}$, is obtained by omitting
the weakening rule for the exponential modality of $\mathbf{CLL}$. The system
$\mathbf{CLLR}$ has been studied by several authors, including
Meli\`es-Tabareau (2010), but its undecidability was unknown. This paper shows
the undecidability of $\mathbf{CLLR}$ by reducing it to the undecidability of
$\mathbf{CLL}$, where the units $\mathbf{1}$ and $\bot$ play a crucial role in
simulating the weakening rule. We also omit these units from the syntax and
inference rules of $\mathbf{CLLR}$ in order to define the second system,
$\mathbf{CLLRR}$. The undecidability of $\mathbf{CLLRR}$ is established by
showing that the system can simulate any two-counter machine proposed by Minsky
(1961).

</details>


### [889] [Formal Verification of Isothermal Chemical Reactors](https://arxiv.org/abs/2509.01130)
*Parivash Feyzishendi,Sophia Hamer,Jinyu Huang,Tyler R. Josephson*

Main category: cs.LO

TL;DR: 该论文使用微分动态逻辑（dL）和KeYmaera X证明了等温化学反应器中特定状态的可达性，并提供了数学保证，例如出口浓度不超过监管阈值。


<details>
  <summary>Details</summary>
Motivation: 评估化学反应器的安全性、合规性和经济性，重点关注特定状态的可达性。

Method: 应用微分动态逻辑（dL）和自动定理证明器KeYmaera X来符号化地确定等温化学反应器的可达性。通过识别不变量（例如质量守恒）来简化证明过程，并将其应用于不同复杂度的反应模型，包括一阶反应和Michaelis-Menten动力学。

Result: 成功证明了一阶反应器不能超过指定的浓度限制，并能处理更复杂的模型。然而，对于连续搅拌釜反应器（CSTR）未能找到有用的不变量，限制了可证明的反应网络复杂度。通过dL获得的边界相对于数值分析方法来说相当宽泛。

Conclusion: 微分动态逻辑（dL）为化学反应器的可达性提供了一种有趣的符号逻辑方法，但其获得的边界可能不如数值分析方法精确。未来的工作可以探索更有效的不变量识别方法，以处理更复杂的反应器模型。

Abstract: Chemical reactors are dynamic systems that can be described by systems of
ordinary differential equations (ODEs). Reactor safety, regulatory compliance,
and economics depend on whether certain states are reachable by the reactor,
and are generally assessed using numerical simulation. In this work, we show
how differential dynamic logic (dL), as implemented in the automated theorem
prover KeYmaera X, can be used to symbolically determine reachability in
isothermal chemical reactors, providing mathematical guarantees that certain
conditions are satisfied (for example, that an outlet concentration never
exceeds a regulatory threshold). First, we apply dL to systems whose dynamics
can be solved in closed form, such as first-order reactions in batch reactors,
proving that such reactors cannot exceed specified concentration limits. We
extend this method to reaction models as complex as Michaelis-Menten kinetics,
whose dynamics require approximations or numerical solutions. In all cases,
proofs are facilitated by identification of invariants; we find that
conservation of mass is both a principle proved from the ODEs describing mass
action kinetics as well as a useful relationship for proving other properties.
Useful invariants for continuous stirred tank reactors (CSTRs) were not found,
which limited the complexity of reaction networks that could be proved with dL.
While dL provides an interesting symbolic logic approach for reachability in
chemical reactions, the bounds we obtained are quite broad relative to those
typically achieved via numerical reachability analyses.

</details>


### [890] [Quantum Petri Nets with Event Structure semantics](https://arxiv.org/abs/2509.01423)
*Julien Saan Joachim,Marc de Visme,Stefan Haar*

Main category: cs.LO

TL;DR: 提出了一种名为量子Petri网（QPN）的新模型，用于解决量子并发领域缺乏严谨模型和分析工具的问题，该模型兼容现有的量子事件结构语义。


<details>
  <summary>Details</summary>
Motivation: 现有的量子Petri网在并发和量子语义、分析工具以及展开理论方面存在不足，缺乏一个像经典Petri网那样可以支撑并发建模的规范性框架。

Method: 引入了量子Petri网（QPN），并提出了量子发生网（LQON）的局部定义，该定义与量子事件结构兼容；构建了具有明确展开语义的QPN；提出了QPN的组合框架。

Result: 成功建立了QPN模型，并提供了与量子事件结构兼容的局部定义，以及具有明确展开语义的QPN构建方法和组合框架，为量子并发提供了一个具有坚实语义基础的模型。

Conclusion: 所提出的QPN模型为量子并发提供了第一个具有坚实语义基础的模型，弥合了Petri网理论与量子编程之间的差距。

Abstract: Classical Petri nets provide a canonical model of concurrency, with unfolding
semantics linking nets, occurrence nets, and event structures. No comparable
framework exists for quantum concurrency: existing ''quantum Petri nets'' lack
rigorous concurrent and sound quantum semantics, analysis tools, and unfolding
theory. We introduce Quantum Petri Nets (QPNs), Petri nets equipped with a
quantum valuation compatible with the quantum event structure semantics of
Clairambault, De Visme, and Winskel (2019). Our contributions are: (i) a local
definition of Quantum Occurrence Nets (LQONs) compatible with quantum event
structures, (ii) a construction of QPNs with a well-defined unfolding
semantics, (iii) a compositional framework for QPNs. This establishes a
semantically well grounded model of quantum concurrency, bridging Petri net
theory and quantum programming.

</details>


### [891] [TREBL -- A Relative Complete Temporal Event-B Logic. Part I: Theory](https://arxiv.org/abs/2509.01462)
*Klaus-Dieter Schewe,Flavio Ferrarotti,Peter Rivière,Neeraj Kumar Singh,Guillaume Dupont,Yamine Aït Ameur*

Main category: cs.LO

TL;DR: 本文将Event-B逻辑扩展为一个强大的逻辑，用于表达Event-B机器状态下的性质，并识别了一个名为TREBL的片段，其中可以表达所有感兴趣的活性条件。


<details>
  <summary>Details</summary>
Motivation: 验证活性条件是基于状态的严格方法的一个重要方面。

Method: 通过将Event-B逻辑扩展为一个强大的逻辑，并识别了一个名为TREBL的片段，其中可以表达所有感兴趣的活性条件，并定义了一套可靠的推导规则。

Result: 我们证明了这些推导规则的相对完备性，这意味着只要机器被充分细化，就可以找到一个推导。

Conclusion: TREBL片段的健全性和相对完备性为在Event-B中处理活性条件提供了理论基础。

Abstract: The verification of liveness conditions is an important aspect of state-based
rigorous methods. This article addresses the extension of the logic of Event-B
to a powerful logic, in which properties of traces of an Event-B machine can be
expressed. However, all formulae of this logic are still interpreted over
states of an Event-B machine rather than traces. The logic exploits that for an
Event-B machine $M$ a state $S$ determines all traces of $M$ starting in $S$.
We identify a fragment called TREBL of this logic, in which all liveness
conditions of interest can be expressed, and define a set of sound derivation
rules for the fragment. We further show relative completeness of these
derivation rules in the sense that for every valid entailment of a formula
$\varphi$ one can find a derivation, provided the machine $M$ is sufficiently
refined. The decisive property is that certain variant terms must be definable
in the refined machine. We show that such refinements always exist. Throughout
the article several examples from the field of security are used to illustrate
the theory.

</details>


### [892] [An Information-Flow Perspective on Explainability Requirements: Specification and Verification](https://arxiv.org/abs/2509.01479)
*Bernd Finkbeiner,Hadar Frenkel,Julian Siber*

Main category: cs.LO

TL;DR: Explainable systems should provide information about the causes of their effects, but this can conflict with privacy. We use epistemic temporal logic with counterfactual causes to specify and verify explainability as a system-level requirement, ensuring sufficient knowledge transfer while also allowing for privacy specifications. An algorithm and prototype implementation are provided and evaluated.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the need to specify, verify, and balance the information flow related to explainability against potential negative impacts like privacy violations, given that both concepts rely on reasoning about knowledge.

Method: The paper utilizes epistemic temporal logic extended with quantification over counterfactual causes to specify and reason about knowledge in multi-agent systems. An algorithm is developed for checking finite-state models against these specifications, with a prototype implementation for evaluation.

Result: The approach successfully distinguishes between explainable and unexplainable systems and allows for the integration of additional privacy requirements. Evaluations on benchmarks demonstrate the effectiveness of the proposed method.

Conclusion: The proposed method, based on epistemic temporal logic with counterfactual causes, provides a formal framework for specifying and verifying explainability in systems while considering privacy concerns, with practical implementation and validation presented.

Abstract: Explainable systems expose information about why certain observed effects are
happening to the agents interacting with them. We argue that this constitutes a
positive flow of information that needs to be specified, verified, and balanced
against negative information flow that may, e.g., violate privacy guarantees.
Since both explainability and privacy require reasoning about knowledge, we
tackle these tasks with epistemic temporal logic extended with quantification
over counterfactual causes. This allows us to specify that a multi-agent system
exposes enough information such that agents acquire knowledge on why some
effect occurred. We show how this principle can be used to specify
explainability as a system-level requirement and provide an algorithm for
checking finite-state models against such specifications. We present a
prototype implementation of the algorithm and evaluate it on several
benchmarks, illustrating how our approach distinguishes between explainable and
unexplainable systems, and how it allows to pose additional privacy
requirements.

</details>


### [893] [Derivation and Verification of Array Sorting by Merging, and its Certification in Dafny](https://arxiv.org/abs/2509.01758)
*Juan Pablo Carbonell,José E. Solsona,Nora Szasz,Álvaro Tasistro*

Main category: cs.LO

TL;DR: 本文提供了在 Dafny 语言中对归并排序的两个版本进行完整认证。


<details>
  <summary>Details</summary>
Motivation: 本文旨在验证归并排序算法在 Dafny 语言中的正确性，并探索将分而治之或分区方法应用于基于线性数组的规范。

Method: 本文首先考虑将分而治之或分区方法应用于涉及线性数组的、由先决条件和后置条件定义的规范的模式。然后，将归并排序和合并算法作为这些模式的实例推导出来，从而得到一个完全递归的表述。此外，对分区产生的子问题树的分析有助于设计循环不变量，从而得到一个完全迭代的版本（有时称为自底向上归并排序），该版本不使用堆栈。本文还展示了如何利用提供的模式在 Dafny 中进行形式化和实际验证，并说明了该方法也适用于推导快速排序的变体。

Result: 本文成功地对 Dafny 语言中的归并排序的两个版本（递归和迭代）进行了完整认证。

Conclusion: 本文提出的方法不仅能有效地对归并排序进行形式化和验证，而且也适用于推导和验证快速排序等其他算法。

Abstract: We provide full certifications of two versions of merge sort of arrays in the
verification-aware programming language Dafny. We start by considering schemas
for applying the divide-and-conquer or partition method of solution to
specifications given by pre- and post-conditions involving linear arrays. We
then derive the merge sort and merging algorithms as instances of these
schemas, thereby arriving at a fully recursive formulation. Further, the
analysis of the tree of subproblems arising from the partition facilitates the
design of loop invariants that allow to derive a fully iterative version
(sometimes called bottom-up merge sort) that does not employ a stack. We show
how the use of the provided schemas conveniently conducts the formalization and
actual verification in Dafny. The whole method is also applicable to deriving
variants of quicksort, which we sketch.

</details>


### [894] [Probabilistically stable revision and comparative probability: a representation theorem and applications](https://arxiv.org/abs/2509.02495)
*Krzysztof Mierzewski*

Main category: cs.LO

TL;DR: 该论文研究了Leitgeb提出的信念稳定性规则，该规则通过“概率稳定命题”（即代理人对其分配高度可信度的命题）来解释理性接受。论文证明了一个表示定理，该定理为概率稳定信念修正算子提供了完整的刻画，并为概率稳定信念修正的（非单调）逻辑提供了“定性”选择函数语义。该结果表明，概率稳定信念修正逻辑表现出强单调性，但未能满足AGM信念修正公设，并且仅满足非常弱的案例推理形式。


<details>
  <summary>Details</summary>
Motivation: 该论文旨在提供一个完整的刻画，用于概率稳定信念修正算子，并为概率稳定信念修正的逻辑提供定性的选择函数语义，以理解信念的动态变化。

Method: 论文的核心是证明一个表示定理，该定理通过选择函数语义来刻画概率稳定信念修正算子。此外，还利用了比较概率序理论，并证明了两个关于比较概率的定理：一个是关于一对比较概率序的联合表示的充要条件，另一个是关于事件比率比较的逻辑的公理化方法。

Result: 论文证明了一个表示定理，该定理为概率稳定信念修正算子提供了完整的刻画，并为概率稳定信念修正的逻辑提供了定性的选择函数语义。结果表明，该逻辑具有强单调性，但未能满足AGM信念修正公设，并且仅满足非常弱的案例推理形式。此外，还证明了两个关于比较概率的定理，并指出了该结果在简单投票博弈和显示偏好理论中的应用。

Conclusion: 该研究为信念稳定性规则及其在信念修正中的应用提供了理论基础，并通过表示定理和选择函数语义对其逻辑进行了刻画。研究结果对比较概率理论、简单投票博弈和显示偏好理论都有重要意义。

Abstract: The stability rule for belief, advocated by Leitgeb [Annals of Pure and
Applied Logic 164, 2013], is a rule for rational acceptance that captures
categorical belief in terms of $\textit{probabilistically stable
propositions}$: propositions to which the agent assigns resiliently high
credence. The stability rule generates a class of $\textit{probabilistically
stable belief revision}$ operators, which capture the dynamics of belief that
result from an agent updating their credences through Bayesian conditioning
while complying with the stability rule for their all-or-nothing beliefs. In
this paper, we prove a representation theorem that yields a complete
characterisation of such probabilistically stable revision operators and
provides a `qualitative' selection function semantics for the (non-monotonic)
logic of probabilistically stable belief revision. Drawing on the theory of
comparative probability orders, this result gives necessary and sufficient
conditions for a selection function to be representable as a
strongest-stable-set operator on a finite probability space. The resulting
logic of probabilistically stable belief revision exhibits strong monotonicity
properties while failing the AGM belief revision postulates and satisfying only
very weak forms of case reasoning. In showing the main theorem, we prove two
results of independent interest to the theory of comparative probability: the
first provides necessary and sufficient conditions for the joint representation
of a pair of (respectively, strict and non-strict) comparative probability
orders. The second result provides a method for axiomatising the logic of ratio
comparisons of the form ``event $A$ is at least $k$ times more likely than
event $B$''. In addition to these measurement-theoretic applications, we point
out two applications of our main result to the theory of simple voting games
and to revealed preference theory.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [895] [Diagnosing Psychiatric Patients: Can Large Language and Machine Learning Models Perform Effectively in Emergency Cases?](https://arxiv.org/abs/2509.00026)
*Abu Shad Ahammed,Sayeri Mukherjee,Roman Obermaisser*

Main category: cs.LG

TL;DR: 本文研究了如何利用传统机器学习和大型语言模型（LLM）评估精神疾病患者的行为模式，以提供诊断评估，特别是在紧急情况下。


<details>
  <summary>Details</summary>
Motivation: 精神疾病患者常因缺乏明显症状而被误判和诊断不足，在紧急情况下识别精神疾病具有挑战性但至关重要。

Method: 收集德国某救援站的紧急精神疾病患者数据，并使用包括Llama 3.1在内的各种机器学习模型进行评估，以检验其作为识别精神疾病患者的有效工具的预测能力。

Result: 研究评估了传统机器学习和大型语言模型（LLM）在识别精神疾病患者方面的潜力。

Conclusion: 大型语言模型和传统机器学习模型可能成为识别紧急精神疾病患者的有效工具。

Abstract: Mental disorders are clinically significant patterns of behavior that are
associated with stress and/or impairment in social, occupational, or family
activities. People suffering from such disorders are often misjudged and poorly
diagnosed due to a lack of visible symptoms compared to other health
complications. During emergency situations, identifying psychiatric issues is
that's why challenging but highly required to save patients. In this paper, we
have conducted research on how traditional machine learning and large language
models (LLM) can assess these psychiatric patients based on their behavioral
patterns to provide a diagnostic assessment. Data from emergency psychiatric
patients were collected from a rescue station in Germany. Various machine
learning models, including Llama 3.1, were used with rescue patient data to
assess if the predictive capabilities of the models can serve as an efficient
tool for identifying patients with unhealthy mental disorders, especially in
rescue cases.

</details>


### [896] [A Class of Random-Kernel Network Models](https://arxiv.org/abs/2509.01090)
*James Tian*

Main category: cs.LG

TL;DR: 随机核网络是一种多层随机特征模型，通过确定性的核组合来创建深度，只在最外层引入随机性。我们证明了更深层的网络在样本复杂度上优于浅层网络，可以以更少的蒙特卡洛样本逼近某些函数，确立了样本复杂度的深度分离定理。


<details>
  <summary>Details</summary>
Motivation: 介绍随机核网络，一种可以提升模型性能的多层随机特征模型。

Method: 通过确定性的核组合创建深度，并在最外层引入随机性。

Result: 证明了更深层的网络比浅层网络在样本复杂度上具有优势，可以用更少的蒙特卡洛样本逼近某些函数。

Conclusion: 随机核网络在样本复杂度上存在深度分离，更深的网络可以更有效地逼近函数。

Abstract: We introduce random-kernel networks, a multilayer extension of random feature
models where depth is created by deterministic kernel composition and
randomness enters only in the outermost layer. We prove that deeper
constructions can approximate certain functions with fewer Monte Carlo samples
than any shallow counterpart, establishing a depth separation theorem in sample
complexity.

</details>


### [897] [Mitigating Data Exfiltration Attacks through Layer-Wise Learning Rate Decay Fine-Tuning](https://arxiv.org/abs/2509.00027)
*Elie Thellier,Huiyu Li,Nicholas Ayache,Hervé Delingette*

Main category: cs.LG

TL;DR: 通过在导出时调整模型参数来缓解数据泄露风险，该方法在不影响模型性能的情况下有效阻止了数据窃取攻击。


<details>
  <summary>Details</summary>
Motivation: 当前数据湖虽然能支持敏感医疗数据集的机器学习模型训练，但也带来了潜在的隐私泄露风险，攻击者可以通过模型参数或多任务学习诱导的记忆来窃取训练数据，并重建高保真医疗图像，造成严重的法律和伦理问题。

Method: 提出了一种简单有效的缓解策略：在导出时通过使用衰减的层级学习率进行微调来扰动模型参数，以破坏嵌入式数据，同时不降低任务性能。

Result: 在DermaMNIST、ChestMNIST和MIMIC-CXR数据集上的评估表明，该方法在保持效用任务性能的同时，能有效阻止先进的数据窃取攻击，优于现有防御方法，并使泄露的数据无法用于训练。对自适应攻击的消融和讨论突显了挑战和未来方向。

Conclusion: 该方法为数据湖训练模型和集中式联邦学习提供了针对数据泄露的实用防御措施。

Abstract: Data lakes enable the training of powerful machine learning models on
sensitive, high-value medical datasets, but also introduce serious privacy
risks due to potential leakage of protected health information. Recent studies
show adversaries can exfiltrate training data by embedding latent
representations into model parameters or inducing memorization via multi-task
learning. These attacks disguise themselves as benign utility models while
enabling reconstruction of high-fidelity medical images, posing severe privacy
threats with legal and ethical implications. In this work, we propose a simple
yet effective mitigation strategy that perturbs model parameters at export time
through fine-tuning with a decaying layer-wise learning rate to corrupt
embedded data without degrading task performance. Evaluations on DermaMNIST,
ChestMNIST, and MIMIC-CXR show that our approach maintains utility task
performance, effectively disrupts state-of-the-art exfiltration attacks,
outperforms prior defenses, and renders exfiltrated data unusable for training.
Ablations and discussions on adaptive attacks highlight challenges and future
directions. Our findings offer a practical defense against data leakage in data
lake-trained models and centralized federated learning.

</details>


### [898] [Financial Decision Making using Reinforcement Learning with Dirichlet Priors and Quantum-Inspired Genetic Optimization](https://arxiv.org/abs/2509.00095)
*Prasun Nandy,Debjit Dhar,Rik Das*

Main category: cs.LG

TL;DR: 提出了一种结合强化学习、狄利克雷分布和量子突变遗传算法的混合框架，用于动态预算分配，以提高盈利能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统预算分配模型在处理现实世界金融数据的随机性和非线性性方面的不足。

Method: 使用苹果公司季度财务数据（2009-2025），训练强化学习代理进行研发和销售、一般和行政费用之间的预算分配，并采用狄利克雷分布模拟状态演变，利用量子突变遗传算法进行策略优化。

Result: 该模型在未见过的数据上实现了与实际分配的高度一致性（余弦相似度0.9990，KL散度0.0023）。

Conclusion: 结合深度强化学习、随机建模和量子启发式方法，可以为自适应的企业预算编制带来希望。

Abstract: Traditional budget allocation models struggle with the stochastic and
nonlinear nature of real-world financial data. This study proposes a hybrid
reinforcement learning (RL) framework for dynamic budget allocation, enhanced
with Dirichlet-inspired stochasticity and quantum mutation-based genetic
optimization. Using Apple Inc. quarterly financial data (2009 to 2025), the RL
agent learns to allocate budgets between Research and Development and Selling,
General and Administrative to maximize profitability while adhering to
historical spending patterns, with L2 penalties discouraging unrealistic
deviations. A Dirichlet distribution governs state evolution to simulate
shifting financial contexts. To escape local minima and improve generalization,
the trained policy is refined using genetic algorithms with quantum mutation
via parameterized qubit rotation circuits. Generation-wise rewards and
penalties are logged to visualize convergence and policy behavior. On unseen
fiscal data, the model achieves high alignment with actual allocations (cosine
similarity 0.9990, KL divergence 0.0023), demonstrating the promise of
combining deep RL, stochastic modeling, and quantum-inspired heuristics for
adaptive enterprise budgeting.

</details>


### [899] [Efficient Transformer-Inspired Variants of Physics-Informed Deep Operator Networks](https://arxiv.org/abs/2509.01679)
*Zhi-Feng Wei,Wenqian Chen,Panos Stinis*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Operator learning has emerged as a promising tool for accelerating the
solution of partial differential equations (PDEs). The Deep Operator Networks
(DeepONets) represent a pioneering framework in this area: the "vanilla"
DeepONet is valued for its simplicity and efficiency, while the modified
DeepONet achieves higher accuracy at the cost of increased training time. In
this work, we propose a series of Transformer-inspired DeepONet variants that
introduce bidirectional cross-conditioning between the branch and trunk
networks in DeepONet. Query-point information is injected into the branch
network and input-function information into the trunk network, enabling dynamic
dependencies while preserving the simplicity and efficiency of the "vanilla"
DeepONet in a non-intrusive manner. Experiments on four PDE benchmarks --
advection, diffusion-reaction, Burgers', and Korteweg-de Vries equations --
show that for each case, there exists a variant that matches or surpasses the
accuracy of the modified DeepONet while offering improved training efficiency.
Moreover, the best-performing variant for each equation aligns naturally with
the equation's underlying characteristics, suggesting that the effectiveness of
cross-conditioning depends on the characteristics of the equation and its
underlying physics. To ensure robustness, we validate the effectiveness of our
variants through a range of rigorous statistical analyses, among them the
Wilcoxon Two One-Sided Test, Glass's Delta, and Spearman's rank correlation.

</details>


### [900] [ZeroQAT: Your Quantization-aware Training but Efficient](https://arxiv.org/abs/2509.00031)
*Qitao Tan,Xiaoying Song,Jin Lu,Guoming Li,Jun Liu,Lingzi Hong,Caiwen Ding,Jundong Li,Xiaoming Zhai,Shaoyi Huang,Wei Niu,Geng Yuan*

Main category: cs.LG

TL;DR: ZeroQAT是一种基于零阶优化的量化感知训练框架，通过前向传播估计梯度，无需反向传播，从而降低了计算和内存开销，同时保留了端到端优化的优势，能够实现类似PTQ的效率和QAT的准确性，适用于LLM的低比特量化。


<details>
  <summary>Details</summary>
Motivation: 现有的低比特量化方法（PTQ）存在精度下降问题，而量化感知训练（QAT）虽然能提高精度，但其对反向传播的依赖导致了高昂的数据、时间和内存成本，限制了其实用性。

Method: ZeroQAT提出了一种基于零阶优化的量化感知训练框架，利用前向传播估计梯度，无需反向传播。它还同时学习量化权重、权重裁剪阈值和等效变换，以减少量化误差和处理激活值异常。

Result: 实验证明，ZeroQAT在实现PTQ的效率的同时，保持了QAT的准确性。

Conclusion: ZeroQAT为LLM的高质量低比特量化提供了一个实用的解决方案。

Abstract: Quantization is an effective technique to reduce the deployment cost of large
language models (LLMs), and post-training quantization (PTQ) has been widely
studied due to its efficiency. However, existing low-bit PTQ methods suffer
from accuracy degradation because their layer-wise optimization introduces
cumulative error propagation and misalignment between local reconstruction
objectives and downstream performance. While quantization-aware training (QAT)
provides a principled solution, its reliance on backpropagation incurs
prohibitive data, time, and memory costs, limiting its practicality. To address
these challenges, we propose ZeroQAT, a zeroth-order optimization-based QAT
framework. ZeroQAT leverages forward-only gradient estimation to eliminate the
need for backpropagation, significantly reducing computational and memory
overhead while retaining the benefits of end-to-end optimization. Moreover,
ZeroQAT jointly learns quantized weights, weight clipping thresholds, and
equivalent transformations to mitigate quantization error and handle activation
outliers. Experiments demonstrate that ZeroQAT achieves the efficiency of PTQ
while retaining the accuracy of QAT, offering a practical solution for
high-quality low-bit quantization of LLMs.

</details>


### [901] [An Evolutionary Multi-objective Optimization for Replica-Exchange-based Physics-informed Operator Learning Network](https://arxiv.org/abs/2509.00663)
*Binghang Lu,Changhong Mou,Guang Lin*

Main category: cs.LG

TL;DR: 提出了一种新的基于进化多目标优化的副本交换物理信息算子学习网络，用于求解参数化偏微分方程，在正向和反向问题中仅需少量带噪声的观测数据。


<details>
  <summary>Details</summary>
Motivation: 现有的物理信息神经网络和算子学习方法（如DeepONets和Furier Neural Operators）在平衡算子和物理损失、处理噪声或稀疏数据时的鲁棒性以及量化不确定性方面存在挑战。

Method: 通过以下方式解决这些局限性：(i) 采用进化多目标优化自适应地平衡帕累托前沿中的算子和基于物理的损失；(ii) 利用副本交换随机梯度 Langevin 动力学改进全局参数空间探索并加速收敛；(iii) 从随机采样中内置贝叶斯不确定性量化。

Result: 在求解一维Burgers方程和时间分数混合扩散-波动方程等多个问题上，该框架在准确性、噪声鲁棒性和不确定性量化能力方面持续优于一般的算子学习方法。

Conclusion: 所提出的算子学习方法在处理参数化偏微分方程方面，相比现有方法具有更好的准确性、鲁棒性和不确定性量化能力。

Abstract: In this paper, we propose an evolutionary Multi-objective Optimization for
Replica-Exchange-based Physics-informed Operator learning Network, which is a
novel operator learning network to efficiently solve parametric partial
differential equations. In forward and inverse settings, this operator learning
network only admits minimum requirement of noisy observational data. While
physics-informed neural networks and operator learning approaches such as Deep
Operator Networks and Fourier Neural Operators offer promising alternatives to
traditional numerical solvers, they struggle with balancing operator and
physics losses, maintaining robustness under noisy or sparse data, and
providing uncertainty quantification. The proposed framework addresses these
limitations by integrating: (i) evolutionary multi-objective optimization to
adaptively balance operator and physics-based losses in the Pareto front; (ii)
replica exchange stochastic gradient Langevin dynamics to improve global
parameter-space exploration and accelerate convergence; and (iii) built-in
Bayesian uncertainty quantification from stochastic sampling. The proposed
operator learning method is tested numerically on several different problems
including one-dimensional Burgers equation and the time-fractional mixed
diffusion-wave equation. The results indicate that our framework consistently
outperforms the general operator learning methods in accuracy, noise
robustness, and the ability to quantify uncertainty.

</details>


### [902] [Industrial Steel Slag Flow Data Loading Method for Deep Learning Applications](https://arxiv.org/abs/2509.00034)
*Mert Sehri,Ana Cardoso,Francisco de Assis Boldt,Patrick Dumond*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Steel casting processes are vulnerable to financial losses due to slag flow
contamination, making accurate slag flow condition detection essential. This
study introduces a novel cross-domain diagnostic method using vibration data
collected from an industrial steel foundry to identify various stages of slag
flow. A hybrid deep learning model combining one-dimensional convolutional
neural networks and long short-term memory layers is implemented, tested, and
benchmarked against a standard one-dimensional convolutional neural network.
The proposed method processes raw time-domain vibration signals from
accelerometers and evaluates performance across 16 distinct domains using a
realistic cross-domain dataset split. Results show that the hybrid
convolutional neural network and long short-term memory architecture, when
combined with root mean square preprocessing and a selective embedding data
loading strategy, achieves robust classification accuracy, outperforming
traditional models and loading techniques. The highest test accuracy of 99.10
+/- 0.30 demonstrates the method's capability for generalization and industrial
relevance. This work presents a practical and scalable solution for real-time
slag flow monitoring, contributing to improved reliability and operational
efficiency in steel manufacturing.

</details>


### [903] [Transfer Learning for Minimum Operating Voltage Prediction in Advanced Technology Nodes: Leveraging Legacy Data and Silicon Odometer Sensing](https://arxiv.org/abs/2509.00035)
*Yuxuan Yin,Rebecca Chen,Boxun Xu,Chen He,Peng Li*

Main category: cs.LG

TL;DR: 由于训练数据有限以及工艺变化和最小工作电压（Vmin）之间存在复杂关系，在先进技术节点上开发Vmin预测模型具有挑战性。本研究提出了一种新颖的迁移学习框架，利用16nm技术节点的遗留数据来实现5nm节点上Vmin的准确预测。该框架整合了源自片上硅里程表传感器数据的输入特征，可以精细表征局部工艺变化，从而显著提高了预测精度。


<details>
  <summary>Details</summary>
Motivation: 开发先进技术节点的最小工作电压（Vmin）预测模型具有挑战性，因为训练数据有限且工艺变化与Vmin之间存在复杂关系。

Method: 提出了一种新颖的迁移学习框架，利用16nm技术节点的遗留数据，并整合了源自片上硅里程表传感器数据的输入特征，以实现5nm节点上Vmin的准确预测。

Result: 通过整合片上硅里程表传感器数据，显著提高了Vmin预测的准确性。

Conclusion: 所提出的迁移学习框架能够利用遗留数据实现先进技术节点上Vmin的准确预测。

Abstract: Accurate prediction of chip performance is critical for ensuring energy
efficiency and reliability in semiconductor manufacturing. However, developing
minimum operating voltage ($V_{min}$) prediction models at advanced technology
nodes is challenging due to limited training data and the complex relationship
between process variations and $V_{min}$. To address these issues, we propose a
novel transfer learning framework that leverages abundant legacy data from the
16nm technology node to enable accurate $V_{min}$ prediction at the advanced
5nm node. A key innovation of our approach is the integration of input features
derived from on-chip silicon odometer sensor data, which provide fine-grained
characterization of localized process variations -- an essential factor at the
5nm node -- resulting in significantly improved prediction accuracy.

</details>


### [904] [A-FloPS: Accelerating Diffusion Sampling with Adaptive Flow Path Sampler](https://arxiv.org/abs/2509.00036)
*Cheng Jin,Zhenyu Xiao,Yuantao Gu*

Main category: cs.LG

TL;DR: A-FloPS是一种创新的无训练加速框架，通过重参数化采样轨迹和自适应速度分解，显著提高了扩散模型的采样效率和样本质量，即使在极低的函数评估次数下也能表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的无训练加速方法主要通过改进数值求解器来加速扩散模型的迭代采样过程，但其效果受限于采样轨迹本身的效率。本研究旨在解决这一瓶颈，提出一种新的框架以提高采样轨迹的效率。

Method: A-FloPS框架通过以下两方面进行加速：1. 将预训练扩散模型的采样轨迹重参数化为流匹配（flow-matching）形式，并将扩散模型得分解析地映射为流兼容的速度，从而生成更易于积分的轨迹，无需重新训练。2. 引入自适应速度分解机制，将速度场分解为线性漂移项和残差项，并通过抑制残差项的时间变化来恢复高阶积分的精度，即使在极低函数评估次数（NFE）的情况下也能保持准确性。

Result: 在条件图像生成和文本到图像合成的实验中，A-FloPS在样本质量和效率方面均优于当前最先进的无训练采样器。特别是在仅使用5次函数评估的情况下，A-FloPS实现了显著更低的FID分数，并生成了更清晰、更连贯的图像。该框架对原生的基于流的生成模型也有改进作用。

Conclusion: A-FloPS是一个通用且高效的框架，能够实现高质量、低延迟的生成模型。其创新的采样轨迹重参数化和自适应速度分解机制，解决了扩散模型采样效率低下的问题，并在多种应用中展现出卓越的性能。

Abstract: Diffusion models deliver state-of-the-art generative performance across
diverse modalities but remain computationally expensive due to their inherently
iterative sampling process. Existing training-free acceleration methods
typically improve numerical solvers for the reverse-time ODE, yet their
effectiveness is fundamentally constrained by the inefficiency of the
underlying sampling trajectories. We propose A-FloPS (Adaptive Flow Path
Sampler), a principled, training-free framework that reparameterizes the
sampling trajectory of any pre-trained diffusion model into a flow-matching
form and augments it with an adaptive velocity decomposition. The
reparameterization analytically maps diffusion scores to flow-compatible
velocities, yielding integration-friendly trajectories without retraining. The
adaptive mechanism further factorizes the velocity field into a linear drift
term and a residual component whose temporal variation is actively suppressed,
restoring the accuracy benefits of high-order integration even in extremely
low-NFE regimes. Extensive experiments on conditional image generation and
text-to-image synthesis show that A-FloPS consistently outperforms
state-of-the-art training-free samplers in both sample quality and efficiency.
Notably, with as few as $5$ function evaluations, A-FloPS achieves
substantially lower FID and generates sharper, more coherent images. The
adaptive mechanism also improves native flow-based generative models,
underscoring its generality. These results position A-FloPS as a versatile and
effective solution for high-quality, low-latency generative modeling.

</details>


### [905] [Prediction, Generation of WWTPs microbiome community structures and Clustering of WWTPs various feature attributes using DE-BP model, SiTime-GAN model and DPNG-EPMC ensemble clustering algorithm with modulation of microbial ecosystem health](https://arxiv.org/abs/2509.01526)
*Mingzhi Dai,Weiwei Cai,Xiang Feng,Huiqun Yu,Weibin Guo,Miao Guo*

Main category: cs.LG

TL;DR: 该研究利用DE-BP、DPNG-EPMC和SiTime-GAN等模型，预测和合成微生物群落数据，以理解影响活性污泥（AS）群落的因素。


<details>
  <summary>Details</summary>
Motivation: 微生物群落在生物地球化学循环以及污水处理等工程和自然生态系统中扮演着关键角色，但微生物群落工程的控制仍面临挑战。

Method: 1. 使用差分进化优化的反向传播神经网络（DE-BP）预测活性污泥（AS）系统的微生物组成。
2. 引入一种新颖的聚类算法——方向位置非线性情感偏好迁移行为聚类（DPNG-EPMC），对污水处理厂（WWTPs）进行聚类分析。
3. 使用相似时间生成对抗网络（SiTime-GAN）合成新的微生物组成和特征属性数据。

Result: DE-BP模型能准确预测微生物组成；DPNG-EPMC可用于WWTPs的特征属性分析；SiTime-GAN能生成有价值的合成数据。

Conclusion: 研究结果有助于理解影响活性污泥群落的因素，并为微生物群落的预测和合成提供了新的方法。

Abstract: Microbiomes not only underpin Earth's biogeochemical cycles but also play
crucial roles in both engineered and natural ecosystems, such as the soil,
wastewater treatment, and the human gut. However, microbiome engineering faces
significant obstacles to surmount to deliver the desired improvements in
microbiome control. Here, we use the backpropagation neural network (BPNN),
optimized through differential evolution (DE-BP), to predict the microbial
composition of activated sludge (AS) systems collected from wastewater
treatment plants (WWTPs) located worldwide. Furthermore, we introduce a novel
clustering algorithm termed Directional Position Nonlinear Emotional Preference
Migration Behavior Clustering (DPNG-EPMC). This method is applied to conduct a
clustering analysis of WWTPs across various feature attributes. Finally, we
employ the Similar Time Generative Adversarial Networks (SiTime-GAN), to
synthesize novel microbial compositions and feature attributes data. As a
result, we demonstrate that the DE-BP model can provide superior predictions of
the microbial composition. Additionally, we show that the DPNG-EPMC can be
applied to the analysis of WWTPs under various feature attributes. Finally, we
demonstrate that the SiTime-GAN model can generate valuable incremental
synthetic data. Our results, obtained through predicting the microbial
community and conducting analysis of WWTPs under various feature attributes,
develop an understanding of the factors influencing AS communities.

</details>


### [906] [Exploring and Reshaping the Weight Distribution in LLM](https://arxiv.org/abs/2509.00046)
*Chunming Ye,Songzhou Li,Xu Xu*

Main category: cs.LG

TL;DR: 该研究探索了大型语言模型（LLM）中不同层权重分布之间的相关性，并研究了这些相关性对LoRA（低秩适配）训练效果的潜在影响。研究发现，模型中不同层权重之间的余弦距离呈现幂律分布。研究人员提出了一种定性方法来描述不同模型的分布特征，并设计了一个结合高斯过程和帕累托分布的数据生成器来模拟符合特定分布特征的数据。最后，通过重塑LoRA初始化权重，实验结果表明该方法在不改变模型结构或训练过程的情况下，提高了LoRA训练的性能。


<details>
  <summary>Details</summary>
Motivation: LLM的性能受其架构、模型大小、解码方法等特征的影响。不同层权重分布的差异可能影响LoRA训练的有效性。

Method: 1. 提取Transformer模型中自注意力层和MLP层（包括Query-projection、down-projection等）的权重矩阵。 2. 使用奇异值分解（SVD）计算权重矩阵的奇异值。 3. 将奇异值按投影类型组织成矩阵，并分析它们之间余弦距离的概率分布，发现存在幂律分布特征。 4. 提出一种定性方法描述不同模型的分布特征。 5. 设计一个结合高斯过程和帕累托分布的数据生成器，用于生成符合特定分布特征的数据。 6. 通过重塑LoRA初始化权重，使其符合观察到的分布特征，以用于训练。

Result: 实验结果表明，该方法在不改变模型结构或训练过程的情况下，对LoRA训练的性能有一定提升。

Conclusion: 模型中不同层权重之间的余弦距离具有幂律分布特征，这种特征对LoRA训练的有效性有影响。通过模拟这种分布特征并将其应用于LoRA初始化权重的重塑，可以有效提升LoRA训练的性能。

Abstract: The performance of Large Language Models is influenced by their
characteristics such as architecture, model sizes, decoding methods and so on.
Due to differences in structure or function, the weights in different layers of
large models have varying distributions. This paper explores the correlations
between different types of layers in terms of weights distribution and studies
the potential impact of these correlations on LoRA training effectiveness.
Firstly, the study reveals that in the model the cosine distances between
weights of different layers manifest power-law distribution. We extract
Query-projection, down-projection and other weight matrices from the
self-attention layers and MLP layers, calculate the singular values of the
matrices using singular value decomposition, and organize a certain number of
singular values into matrices according to projection's type. By analyzing the
probability distribution of the cosine distances between these matrices, it is
found that the cosine distances values between them have distinct power-law
distribution characteristics. Secondly, based on the results of distance
calculations and analysis across different layers of model, a qualitative
method is proposed to describe the distribution characteristics of different
models. Next, to construct weights that align with the distribution
characteristics, a data generator is designed using a combination of Gaussian
process and Pareto distribution functions. The generator is used to simulate
the generation of data that aligns with specific distribution characteristics.
Finally, based on the aforementioned distribution characteristics and data
generation method, the weights in LoRA initialization are reshaped for
training. Experimental results indicate that, without altering the model
structure or training process, this method achieves a certain improvement in
the performance of LoRA training.

</details>


### [907] [Semantic and episodic memories in a predictive coding model of the neocortex](https://arxiv.org/abs/2509.01987)
*Lucie Fontaine,Frédéric Alexandre*

Main category: cs.LG

TL;DR: 该论文探讨了预测编码模型在处理单个记忆实例方面的能力，并将其与海马体的功能进行了比较。


<details>
  <summary>Details</summary>
Motivation: 检验互补学习系统理论中关于新皮质和海马体在记忆编码中的作用，特别关注预测编码模型能否实现类似海马体的功能。

Method: 提出一个预测编码模型，模拟新皮质的运作，并测试其在少量和大量数据上的记忆和泛化能力。

Result: 发现预测编码模型在少量数据上可以回忆特定实例，但泛化能力差（过拟合）；在大量数据上则失去回忆能力，但泛化能力更好。

Conclusion: 表明新皮质可以通过渐进式编码来存储单个实例，但仅限于有限数量，这支持了海马体（具有稀疏、模式分离的表征）的必要性。

Abstract: Complementary Learning Systems theory holds that intelligent agents need two
learning systems. Semantic memory is encoded in the neocortex with dense,
overlapping representations and acquires structured knowledge. Episodic memory
is encoded in the hippocampus with sparse, pattern-separated representations
and quickly learns the specifics of individual experiences. Recently, this
duality between semantic and episodic memories has been challenged by
predictive coding, a biologically plausible neural network model of the
neocortex which was shown to have hippocampus-like abilities on
auto-associative memory tasks. These results raise the question of the episodic
capabilities of the neocortex and their relation to semantic memory. In this
paper, we present such a predictive coding model of the neocortex and explore
its episodic capabilities. We show that this kind of model can indeed recall
the specifics of individual examples but only if it is trained on a small
number of examples. The model is overfitted to these exemples and does not
generalize well, suggesting that episodic memory can arise from semantic
learning. Indeed, a model trained with many more examples loses its recall
capabilities. This work suggests that individual examples can be encoded
gradually in the neocortex using dense, overlapping representations but only in
a limited number, motivating the need for sparse, pattern-separated
representations as found in the hippocampus.

</details>


### [908] [Teaching AI to Remember: Insights from Brain-Inspired Replay in Continual Learning](https://arxiv.org/abs/2509.00047)
*Jina Kim*

Main category: cs.LG

TL;DR: 内部重放机制能缓解灾难性遗忘，但会降低初始任务准确性，并增加潜在空间中的表示重叠。


<details>
  <summary>Details</summary>
Motivation: 本文旨在深入研究人类大脑记忆整合机制中的内部重放机制，以解决持续学习中灾难性遗忘的问题。

Method: 通过在 CIFAR-100 数据集上进行实验，评估内部重放机制（单独以及与 Synaptic Intelligence 结合）的有效性，并使用对数似然分布、重建误差、轮廓分数和 UMAP 投影进行进一步分析。

Result: 内部重放机制能显著缓解遗忘，尤其与 SI 结合时，但会以降低初始任务准确性为代价。分析显示，该机制增加了潜在空间中的表示重叠，可能限制了任务特定的区分。

Conclusion: 内部重放机制虽然能缓解遗忘，但也存在局限性，需要在记忆稳定性和学习可塑性之间进行权衡，并为未来持续学习系统的发展指明了方向。

Abstract: Artificial neural networks (ANNs) continue to face challenges in continual
learning, particularly due to catastrophic forgetting, the loss of previously
learned knowledge when acquiring new tasks. Inspired by memory consolidation in
the human brain, we investigate the internal replay mechanism proposed
by~\citep{brain_inspired_replay1}, which reactivates latent representations of
prior experiences during learning. As internal replay was identified as the
most influential component among the brain-inspired mechanisms in their
framework, it serves as the central focus of our in-depth investigation. Using
the CIFAR-100 dataset in a class-incremental setting, we evaluate the
effectiveness of internal replay, both in isolation and in combination with
Synaptic Intelligence (SI). Our experiments show that internal replay
significantly mitigates forgetting, especially when paired with SI, but at the
cost of reduced initial task accuracy, highlighting a trade-off between memory
stability and learning plasticity. Further analyses using log-likelihood
distributions, reconstruction errors, silhouette scores, and UMAP projections
reveal that internal replay increases representational overlap in latent space,
potentially limiting task-specific differentiation. These results underscore
the limitations of current brain-inspired methods and suggest future directions
for balancing retention and adaptability in continual learning systems.

</details>


### [909] [Surrogate Benchmarks for Model Merging Optimization](https://arxiv.org/abs/2509.02555)
*Rio Akizuki,Yuya Kudo,Nozomu Yoshinari,Yoichi Hirose,Toshiyuki Nishimoto,Kento Uchida,Shinichi Shirakawa*

Main category: cs.LG

TL;DR: 该研究提出了一种用于模型合并超参数优化的代理基准测试，以降低计算成本并实现算法开发和性能比较。


<details>
  <summary>Details</summary>
Motivation: 模型合并技术旨在整合多个模型的能力，但其超参数的设置会影响合并后模型的性能。对模型合并超参数进行微调可以提升合并效果，因此，开发用于模型合并的超参数优化算法是一个有前景的方向。然而，优化过程的计算成本很高，尤其是在合并大型语言模型（LLMs）时。

Method: 研究人员定义了两个搜索空间，并收集数据样本来构建代理模型，以根据超参数预测合并后模型的性能。

Result: 所提出的代理基准测试能够很好地预测合并后模型的性能，并能模拟优化算法的行为。

Conclusion: 该研究通过开发代理基准测试，为模型合并超参数优化提供了一种低成本的解决方案，有助于算法开发和性能比较。

Abstract: Model merging techniques aim to integrate the abilities of multiple models
into a single model. Most model merging techniques have hyperparameters, and
their setting affects the performance of the merged model. Because several
existing works show that tuning hyperparameters in model merging can enhance
the merging outcome, developing hyperparameter optimization algorithms for
model merging is a promising direction. However, its optimization process is
computationally expensive, particularly in merging LLMs. In this work, we
develop surrogate benchmarks for optimization of the merging hyperparameters to
realize algorithm development and performance comparison at low cost. We define
two search spaces and collect data samples to construct surrogate models to
predict the performance of a merged model from a hyperparameter. We demonstrate
that our benchmarks can predict the performance of merged models well and
simulate optimization algorithm behaviors.

</details>


### [910] [Adaptive Physics-Informed Neural Networks with Multi-Category Feature Engineering for Hydrogen Sorption Prediction in Clays, Shales, and Coals](https://arxiv.org/abs/2509.00049)
*Mohammad Nooraiepour,Mohammad Masoudi,Zezhang Song,Helge Hellevang*

Main category: cs.LG

TL;DR: 该研究提出了一种自适应物理信息神经网络（PINN）框架，结合多类别特征工程，用于提高对粘土、页岩和煤层中氢气吸附量的预测精度。该框架整合了经典等温线模型和热力学约束，并利用深度学习的灵活性。通过在155个样本（包括50个粘土、60个页岩和45个煤）上进行训练和验证，该模型实现了高精度（R2 = 0.979），收敛速度提高了67%，同时保持了对不同岩性（粘土、页岩、煤）的稳健预测能力。解释性分析表明，氢气吸附能力是主导因素，且特征之间存在显著的非线性相互作用。该框架能够加速场地筛选并为决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 为了提高对粘土、页岩和煤层中氢气吸附量的预测精度，以推动地下氢气储存、天然氢勘探和放射性废物 containment。传统实验方法耗时、易出错且难以捕捉地质异质性。

Method: 提出了一种自适应物理信息神经网络（PINN）框架，并结合了多类别特征工程。该框架集成了经典等温线模型和热力学约束，利用深度残差网络和多头注意力机制，并通过自适应损失函数和蒙特卡洛 Dropout 进行优化以进行不确定性量化。

Result: 该模型在155个样本上实现了高精度（R2 = 0.979，RMSE = 0.045 mol/kg），收敛速度提高了67%，同时模型复杂度增加了15倍。在粘土、页岩和煤层中分别达到了0.981、0.971和0.978的R2值，可靠性得分在85%-91%之间。解释性分析表明，氢气吸附能力是主导预测的因素，86.7%的特征对表现出强烈的相互作用。

Conclusion: 该自适应物理信息神经网络框架能够准确预测不同地质条件下的氢气吸附量，并通过不确定性量化加速场地筛选和支持风险知情的决策。

Abstract: Accurate prediction of hydrogen sorption in clays, shales, and coals is vital
for advancing underground hydrogen storage, natural hydrogen exploration, and
radioactive waste containment. Traditional experimental methods, while
foundational, are time-consuming, error-prone, and limited in capturing
geological heterogeneity. This study introduces an adaptive physics-informed
neural network (PINN) framework with multi-category feature engineering to
enhance hydrogen sorption prediction. The framework integrates classical
isotherm models with thermodynamic constraints to ensure physical consistency
while leveraging deep learning flexibility. A comprehensive dataset consisting
of 155 samples, which includes 50 clays, 60 shales, and 45 coals, was employed,
incorporating diverse compositional properties and experimental conditions.
Multi-category feature engineering across seven categories captured complex
sorption dynamics. The PINN employs deep residual networks with multi-head
attention, optimized via adaptive loss functions and Monte Carlo dropout for
uncertainty quantification. K-fold cross-validation and hyperparameter
optimization achieve significant accuracy (R2 = 0.979, RMSE = 0.045 mol per kg)
with 67% faster convergence despite 15-fold increased complexity. The framework
demonstrates robust lithology-specific performance across clay minerals (R2 =
0.981), shales (R2 = 0.971), and coals (R2 = 0.978), maintaining 85-91%
reliability scores. Interpretability analysis via SHAP, accumulated local
effects, and Friedman's H-statistics reveal that hydrogen adsorption capacity
dominates predictions, while 86.7% of feature pairs exhibit strong
interactions, validating the necessity of non-linear modeling approaches. This
adaptive physics-informed framework accelerates site screening and enables
risk-informed decision-making through robust uncertainty quantification.

</details>


### [911] [Applying Deep Learning to Anomaly Detection of Russian Satellite Activity for Indications Prior to Military Activity](https://arxiv.org/abs/2509.00050)
*David Kurtenbach,Megan Manly,Zach Metzinger*

Main category: cs.LG

TL;DR: 该研究利用深度学习技术分析了俄罗斯拥有的空间物体（RSO）在乌克兰入侵前的活动，以识别可能预示未来冲突侵略性军事行为的指标。


<details>
  <summary>Details</summary>
Motivation: 评估俄罗斯拥有的空间物体（RSO）在乌克兰入侵前的异常活动，并识别可作为未来冲突侵略性军事行为预警的信号。

Method: 研究采用深度学习方法，包括孤立森林（IF）、传统自编码器（AE）、变分自编码器（VAE）、Kolmogorov Arnold Network（KAN）以及一种新颖的基于Anchor Loss的自编码器（Anchor AE），对两行轨道根数（TLE）数据进行分析。为捕捉每个RSO的独特性，为每个观测到的空间物体训练了单独的模型，并侧重于模型的可解释性，单独评估每个轨道元素的异常行为。

Result: 研究发现了俄罗斯RSO活动具有统计学意义上的异常，并且能够将异常细节具体到单个轨道元素。

Conclusion: 深度学习方法能够有效识别俄罗斯RSO活动的异常模式，为理解和预测潜在的军事行为提供依据。

Abstract: We apply deep learning techniques for anomaly detection to analyze activity
of Russian-owned resident space objects (RSO) prior to the Ukraine invasion and
assess the results for any findings that can be used as indications and
warnings (I&W) of aggressive military behavior for future conflicts. Through
analysis of anomalous activity, an understanding of possible tactics and
procedures can be established to assess the existence of statistically
significant changes in Russian RSO pattern of life/pattern of behavior
(PoL/PoB) using publicly available two-line element (TLE) data. This research
looks at statistical and deep learning approaches to assess anomalous activity.
The deep learning methods assessed are isolation forest (IF), traditional
autoencoder (AE), variational autoencoder (VAE), Kolmogorov Arnold Network
(KAN), and a novel anchor-loss based autoencoder (Anchor AE). Each model is
used to establish a baseline of on-orbit activity based on a five-year data
sample. The primary investigation period focuses on the six months leading up
to the invasion date of February 24, 2022. Additional analysis looks at RSO
activity during an active combat period by sampling TLE data after the invasion
date. The deep learning autoencoder models identify anomalies based on
reconstruction errors that surpass a threshold sigma. To capture the nuance and
unique characteristics of each RSO an individual model was trained for each
observed space object. The research made an effort to prioritize explainability
and interpretability of the model results thus each observation was assessed
for anomalous behavior of the individual six orbital elements versus analyzing
the input data as a single monolithic observation. The results demonstrate not
only statistically significant anomalies of Russian RSO activity but also
details anomalous findings to the individual orbital element.

</details>


### [912] [HiGraph: A Large-Scale Hierarchical Graph Dataset for Malware Analysis](https://arxiv.org/abs/2509.02113)
*Han Chen,Hanchen Wang,Hongmei Chen,Ying Zhang,Lu Qin,Wenjie Zhang*

Main category: cs.LG

TL;DR: 该论文提出了一个名为HiGraph的大规模分层图数据集，用于解决现有图结构恶意软件分析中缺乏大规模数据集的问题。该数据集包含2亿个控制流图（CFGs）和59.5万个函数调用图（FCGs），能够保留软件的层级结构和语义关系，有助于构建更鲁棒的恶意软件检测器。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图的恶意软件分析方法由于缺乏能够捕捉软件固有的层级结构的大规模数据集而受到严重限制。现有方法通常将程序简化为单层图，未能模拟高级函数交互与低级指令逻辑之间的关键语义关系。

Method: 提出HiGraph数据集，包含2亿个控制流图（CFGs），这些图嵌套在59.5万个函数调用图（FCGs）中。这种两层表示保留了对构建鲁棒的、能抵抗代码混淆和恶意软件演变的检测器至关重要的结构语义。

Result: 通过大规模分析证明了HiGraph的效用，揭示了良性和恶意软件的独特结构属性，并将其确立为该社区的基础基准。

Conclusion: HiGraph数据集解决了现有基于图的恶意软件分析中缺乏大规模分层数据集的问题，并通过展示其在区分良性和恶意软件方面的能力，为社区提供了一个重要的基准。

Abstract: The advancement of graph-based malware analysis is critically limited by the
absence of large-scale datasets that capture the inherent hierarchical
structure of software. Existing methods often oversimplify programs into single
level graphs, failing to model the crucial semantic relationship between
high-level functional interactions and low-level instruction logic. To bridge
this gap, we introduce \dataset, the largest public hierarchical graph dataset
for malware analysis, comprising over \textbf{200M} Control Flow Graphs (CFGs)
nested within \textbf{595K} Function Call Graphs (FCGs). This two-level
representation preserves structural semantics essential for building robust
detectors resilient to code obfuscation and malware evolution. We demonstrate
HiGraph's utility through a large-scale analysis that reveals distinct
structural properties of benign and malicious software, establishing it as a
foundational benchmark for the community. The dataset and tools are publicly
available at https://higraph.org.

</details>


### [913] [From Data to Decision: A Multi-Stage Framework for Class Imbalance Mitigation in Optical Network Failure Analysis](https://arxiv.org/abs/2509.00057)
*Yousuf Moiz Ali,Jaroslaw E. Prilepsky,Nicola Sambo,Joao Pedro,Mohammad M. Hosseini,Antonio Napoli,Sergei K. Turitsyn,Pedro Freire*

Main category: cs.LG

TL;DR: 基于机器学习的光网络故障管理面临类别不平衡的挑战，本文比较了预处理、过程内处理和后处理方法，在故障检测中后处理（尤其是阈值调整）效果最佳，在故障识别中生成式AI效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习在光网络故障管理中类别不平衡的挑战，并探索研究较少的后处理方法。

Method: 直接比较预处理、过程内处理和后处理方法在故障检测和识别中的应用，并考虑了类别重叠和延迟等因素。

Result: 在故障检测中，阈值调整（后处理）能带来最大的F1分数提升（高达15.3%），而随机欠采样推理速度最快。在故障识别中，生成式AI（GenAI）能带来最大的性能提升（高达24.2%），但后处理在多类别设置中效果有限。在类别重叠且延迟关键的情况下，过采样（如SMOTE）最有效；无延迟限制时，元学习效果最佳。在低重叠情况下，生成式AI性能最高且推理时间最短。

Conclusion: 不同的类别不平衡缓解技术在光网络故障管理的不同场景下各有优劣，需要根据具体需求（如故障检测/识别、类别重叠程度、延迟要求）选择合适的方法。

Abstract: Machine learning-based failure management in optical networks has gained
significant attention in recent years. However, severe class imbalance, where
normal instances vastly outnumber failure cases, remains a considerable
challenge. While pre- and in-processing techniques have been widely studied,
post-processing methods are largely unexplored. In this work, we present a
direct comparison of pre-, in-, and post-processing approaches for class
imbalance mitigation in failure detection and identification using an
experimental dataset. For failure detection, post-processing
methods-particularly Threshold Adjustment-achieve the highest F1 score
improvement (up to 15.3%), while Random Under-Sampling provides the fastest
inference. In failure identification, GenAI methods deliver the most
substantial performance gains (up to 24.2%), whereas post-processing shows
limited impact in multi-class settings. When class overlap is present and
latency is critical, over-sampling methods such as the SMOTE are most
effective; without latency constraints, Meta-Learning yields the best results.
In low-overlap scenarios, Generative AI approaches provide the highest
performance with minimal inference time.

</details>


### [914] [T-MLP: Tailed Multi-Layer Perceptron for Level-of-Detail Signal Representation](https://arxiv.org/abs/2509.00066)
*Chuanxiang Yang,Yuanfeng Zhou,Guangshun Wei,Siyu Ren,Yuan Liu,Junhui Hou,Wenping Wang*

Main category: cs.LG

TL;DR: T-MLP是一种新的神经网络架构，通过在隐藏层附加多个输出分支（“尾部”）来扩展MLP，从而实现多尺度信号表示。


<details>
  <summary>Details</summary>
Motivation: 为了高效地建模和传输图像和3D形状等信号，需要一种能够表示不同细节级别（LoD）的方法。现有的MLP在原生上不支持LoD。T-MLP旨在解决这个问题。

Method: 提出了一种名为Tailed Multi-Layer Perceptron (T-MLP)的神经网络架构，它通过在MLP的隐藏层附加多个输出分支（“尾部”）来扩展MLP。这种设计允许在多个深度进行直接监督，并通过特定的损失函数和训练策略使每个隐藏层能够学习特定LoD的目标信号，从而实现多尺度建模。

Result: T-MLP在多种信号表示任务中表现优于其他神经LoD基线。

Conclusion: T-MLP是一种有效的神经网络架构，能够实现多尺度信号表示，并在各种任务中取得优于现有方法的性能。

Abstract: Level-of-detail (LoD) representation is critical for efficiently modeling and
transmitting various types of signals, such as images and 3D shapes. In this
work, we present a novel neural architecture that supports LoD signal
representation. Our architecture is based on an elaborate modification of the
widely used Multi-Layer Perceptron (MLP), which inherently operates at a single
scale and therefore lacks native support for LoD. Specifically, we introduce
the Tailed Multi-Layer Perceptron (T-MLP) that extends the MLP by attaching
multiple output branches, also called tails, to its hidden layers, enabling
direct supervision at multiple depths. Our loss formulation and training
strategy allow each hidden layer to effectively learn a target signal at a
specific LoD, thus enabling multi-scale modeling. Extensive experimental
results show that our T-MLP outperforms other neural LoD baselines across a
variety of signal representation tasks.

</details>


### [915] [RNN Generalization to Omega-Regular Languages](https://arxiv.org/abs/2509.02491)
*Charles Pert,Dalal Alrajeh,Alessandra Russo*

Main category: cs.LG

TL;DR: RNNs can generalize to $\\omega$-regular languages from LTL formulas, achieving high accuracy on longer sequences, suggesting potential for neurosymbolic verification.


<details>
  <summary>Details</summary>
Motivation: Investigate the ability of RNNs to generalize to $\\omega$-regular languages derived from LTL formulas, addressing scalability challenges in BAs for reactive system verification.

Method: Train RNNs on ultimately periodic $\\omega$-word sequences to mimic BA behavior and evaluate generalization to out-of-distribution sequences on LTL formulas corresponding to deterministic automata of varying complexity.

Result: RNNs achieve high accuracy ($92.6$\% of tasks with perfect or near-perfect generalization) on target $\\omega$-regular languages when evaluated on sequences up to $8 \\times$ longer than training examples, even for automata with over 100 states.

Conclusion: Neural approaches are feasible for learning complex $\\omega$-regular languages and can potentially be used in neurosymbolic verification methods.

Abstract: B\"uchi automata (BAs) recognize $\omega$-regular languages defined by formal
specifications like linear temporal logic (LTL) and are commonly used in the
verification of reactive systems. However, BAs face scalability challenges when
handling and manipulating complex system behaviors. As neural networks are
increasingly used to address these scalability challenges in areas like model
checking, investigating their ability to generalize beyond training data
becomes necessary. This work presents the first study investigating whether
recurrent neural networks (RNNs) can generalize to $\omega$-regular languages
derived from LTL formulas. We train RNNs on ultimately periodic $\omega$-word
sequences to replicate target BA behavior and evaluate how well they generalize
to out-of-distribution sequences. Through experiments on LTL formulas
corresponding to deterministic automata of varying structural complexity, from
3 to over 100 states, we show that RNNs achieve high accuracy on their target
$\omega$-regular languages when evaluated on sequences up to $8 \times$ longer
than training examples, with $92.6\%$ of tasks achieving perfect or
near-perfect generalization. These results establish the feasibility of neural
approaches for learning complex $\omega$-regular languages, suggesting their
potential as components in neurosymbolic verification methods.

</details>


### [916] [AnomalyExplainer Explainable AI for LLM-based anomaly detection using BERTViz and Captum](https://arxiv.org/abs/2509.00069)
*Prasasthy Balasubramanian,Dumindu Kankanamge,Ekaterina Gilman,Mourad Oussalah*

Main category: cs.LG

TL;DR: 该研究提出了一个结合BERTViz、Captum和自然语言报告的框架，利用RoBERTa模型在HDFS数据集上实现了99.6%的准确率，有效检测网络安全中的异常，并通过用户反馈验证了其易用性和对异常理解的提升。


<details>
  <summary>Details</summary>
Motivation: 弥补当前对话式AI和LLM在网络安全领域应用的局限，如误报和模型管理复杂性，并解决安全分析师对可解释AI（XAI）有效性的疑虑。

Method: 构建了一个框架，利用BERTViz和Captum进行可视化解释，并结合基于注意力输出的自然语言报告来检测异常并提供高质量解释。

Result: RoBERTa模型在HDFS数据集上展现出高准确率（99.6%）和强大的异常检测能力，优于Falcon-7B和DeBERTa，并且比Mistral-7B更灵活。用户反馈证实了聊天机器人的易用性和对异常理解的改进。

Conclusion: 该框架能够通过提供高质量的解释来增强网络安全工作流程，提高异常检测的效率和准确性，并改善用户对AI决策的理解。

Abstract: Conversational AI and Large Language Models (LLMs) have become powerful tools
across domains, including cybersecurity, where they help detect threats early
and improve response times. However, challenges such as false positives and
complex model management still limit trust. Although Explainable AI (XAI) aims
to make AI decisions more transparent, many security analysts remain uncertain
about its usefulness. This study presents a framework that detects anomalies
and provides high-quality explanations through visual tools BERTViz and Captum,
combined with natural language reports based on attention outputs. This reduces
manual effort and speeds up remediation. Our comparative analysis showed that
RoBERTa offers high accuracy (99.6 %) and strong anomaly detection,
outperforming Falcon-7B and DeBERTa, as well as exhibiting better flexibility
than large-scale Mistral-7B on the HDFS dataset from LogHub. User feedback
confirms the chatbot's ease of use and improved understanding of anomalies,
demonstrating the ability of the developed framework to strengthen
cybersecurity workflows.

</details>


### [917] [Cache Management for Mixture-of-Experts LLMs -- extended version](https://arxiv.org/abs/2509.02408)
*Spyros Angelopoulos,Loris Marchal,Adrien Obrecht,Bertrand Simon*

Main category: cs.LG

TL;DR: LLM的内存管理是一个挑战，尤其是在使用混合专家（MoE）模型时。本文提出了一个针对MoE模型优化的新分页问题，并提出了一种基于层的LRU扩展算法，该算法在模拟和实际跟踪中优于标准LRU。


<details>
  <summary>Details</summary>
Motivation: LLM的内存管理挑战，特别是混合专家（MoE）模型中激活参数的减少，以及高效管理缓存以存储常用专家而不是慢速内存的需求。

Method: 提出并研究了一个新的分页问题来模拟专家管理优化，该问题考虑了LLM的分层架构和高效缓存专家的要求。通过分析确定性和随机化算法的竞争比下界，表明类似LRU的策略具有良好的理论竞争性能。然后，提出了一种针对该问题的基于层的LRU扩展算法。

Result: 所提出的层状LRU扩展算法在合成数据集和实际MoE使用跟踪的广泛模拟中，其性能优于经典分页问题的策略，例如标准LRU。

Conclusion: 所提出的层状LRU扩展算法有效解决了混合专家LLM的专家缓存优化问题，并在实际应用中显示出优越的性能。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across
a variety of tasks. One of the main challenges towards the successful
deployment of LLMs is memory management, since they typically involve billions
of parameters. To this end, architectures based on Mixture-of-Experts have been
proposed, which aim to reduce the size of the parameters that are activated
when producing a token. This raises the equally critical issue of efficiently
managing the limited cache of the system, in that frequently used experts
should be stored in the fast cache rather than in the slower secondary memory.
  In this work, we introduce and study a new paging problem that models expert
management optimization. Our formulation captures both the layered architecture
of LLMs and the requirement that experts are cached efficiently. We first
present lower bounds on the competitive ratio of both deterministic and
randomized algorithms, which show that under mild assumptions, LRU-like
policies have good theoretical competitive performance. We then propose a
layer-based extension of LRU that is tailored to the problem at hand.
  Extensive simulations on both synthetic datasets and actual traces of MoE
usage show that our algorithm outperforms policies for the classic paging
problem, such as the standard LRU.

</details>


### [918] [SynCircuit: Automated Generation of New Synthetic RTL Circuits Can Enable Big Data in Circuits](https://arxiv.org/abs/2509.00071)
*Shang Liu,Jing Wang,Wenji Fang,Zhiyao Xie*

Main category: cs.LG

TL;DR: 公开的电路设计数据稀缺，SynCircuit通过生成合成数据来解决此问题，该方法使用基于扩散模型、图约束强制和MCTS的方法来生成功能有效的电路，并能提升下游任务的ML模型性能。


<details>
  <summary>Details</summary>
Motivation: AI辅助IC设计方法有巨大潜力，但缺乏公开的电路设计数据，这是其发展的主要瓶颈。

Method: SynCircuit框架包含三个步骤：1）使用定制的基于扩散模型的生成模型来生成有向环图（DCG）；2）通过精炼初始图生成输出来强制执行电路约束以确保电路有效性；3）使用蒙特卡洛树搜索（MCTS）方法优化生成图中的逻辑冗余。

Result: SynCircuit能够生成更真实的合成电路，并提升下游电路设计任务中ML模型的性能。

Conclusion: SynCircuit是首个生成HDL格式的具有功能有效性的合成电路的尝试，有效解决了数据稀缺问题。

Abstract: In recent years, AI-assisted IC design methods have demonstrated great
potential, but the availability of circuit design data is extremely limited,
especially in the public domain. The lack of circuit data has become the
primary bottleneck in developing AI-assisted IC design methods. In this work,
we make the first attempt, SynCircuit, to generate new synthetic circuits with
valid functionalities in the HDL format. SynCircuit automatically generates
synthetic data using a framework with three innovative steps: 1) We propose a
customized diffusion-based generative model to resolve the Directed Cyclic
Graph (DCG) generation task, which has not been well explored in the AI
community. 2) To ensure our circuit is valid, we enforce the circuit
constraints by refining the initial graph generation outputs. 3) The Monte
Carlo tree search (MCTS) method further optimizes the logic redundancy in the
generated graph. Experimental results demonstrate that our proposed SynCircuit
can generate more realistic synthetic circuits and enhance ML model performance
in downstream circuit design tasks.

</details>


### [919] [Calibration through the Lens of Indistinguishability](https://arxiv.org/abs/2509.02279)
*Parikshit Gopalan,Lunjia Hu*

Main category: cs.LG

TL;DR: 该论文对预测文献中的校准概念进行了调查，重点关注如何解释预测概率以及如何在机器学习中评估概率预测。


<details>
  <summary>Details</summary>
Motivation: 由于概率预测在机器学习中的普遍性，校准的研究引起了人们的极大兴趣。

Method: 该调查描述了关于如何定义和测量校准误差以及这些度量对希望使用预测来制定决策的下游决策者的意义的最新工作。

Result: 研究提出了一个统一的观点，即将校准视为可区分性的一种形式，即预测器所假设的世界与由自然或贝叶斯最优预测器所控制的真实世界之间的可区分性。

Conclusion: 各种校准度量量化了这两个世界在某些类型的区分器或统计度量下可以区分的程度。

Abstract: Calibration is a classical notion from the forecasting literature which aims
to address the question: how should predicted probabilities be interpreted? In
a world where we only get to observe (discrete) outcomes, how should we
evaluate a predictor that hypothesizes (continuous) probabilities over possible
outcomes? The study of calibration has seen a surge of recent interest, given
the ubiquity of probabilistic predictions in machine learning. This survey
describes recent work on the foundational questions of how to define and
measure calibration error, and what these measures mean for downstream decision
makers who wish to use the predictions to make decisions. A unifying viewpoint
that emerges is that of calibration as a form of indistinguishability, between
the world hypothesized by the predictor and the real world (governed by nature
or the Bayes optimal predictor). In this view, various calibration measures
quantify the extent to which the two worlds can be told apart by certain
classes of distinguishers or statistical measures.

</details>


### [920] [Mitigating Clinician Information Overload: Generative AI for Integrated EHR and RPM Data Analysis](https://arxiv.org/abs/2509.00073)
*Ankit Shetgaonkar,Dipen Pradhan,Lakshit Arora,Sanjay Surendranath Girija,Shashank Kapoor,Aman Raj*

Main category: cs.LG

TL;DR: GenAI, especially LLMs, can help interpret complex healthcare data like RPM and EHRs, improving clinical efficiency and offering decision support. However, challenges include data integration, quality, privacy, safety, bias, and acceptance.


<details>
  <summary>Details</summary>
Motivation: The sheer volume and heterogeneity of combined real-time Remote Patient Monitoring (RPM) streams and traditional Electronic Health Records (EHRs) create information overload for clinicians. GenAI, particularly LLMs, offers potential solutions.

Method: This paper provides an overview of the capabilities, requirements, and applications of GenAI for deriving clinical insights and improving clinical efficiency. It explores LLM-powered applications for enhancing navigation of longitudinal patient data and providing clinical decision support through natural language dialogue.

Result: GenAI applications can streamline clinician workflows and personalize care by improving navigation of patient data and offering decision support. However, critical challenges remain, including data integration, quality, privacy, safety validation, bias mitigation, and clinical acceptance.

Conclusion: GenAI and LLMs hold significant promise for managing clinician data overload and improving healthcare efficiency, but successful implementation requires addressing critical challenges related to data, safety, bias, and adoption.

Abstract: Generative Artificial Intelligence (GenAI), particularly Large Language
Models (LLMs), offer powerful capabilities for interpreting the complex data
landscape in healthcare. In this paper, we present a comprehensive overview of
the capabilities, requirements and applications of GenAI for deriving clinical
insights and improving clinical efficiency. We first provide some background on
the forms and sources of patient data, namely real-time Remote Patient
Monitoring (RPM) streams and traditional Electronic Health Records (EHRs). The
sheer volume and heterogeneity of this combined data present significant
challenges to clinicians and contribute to information overload. In addition,
we explore the potential of LLM-powered applications for improving clinical
efficiency. These applications can enhance navigation of longitudinal patient
data and provide actionable clinical decision support through natural language
dialogue. We discuss the opportunities this presents for streamlining clinician
workflows and personalizing care, alongside critical challenges such as data
integration complexity, ensuring data quality and RPM data reliability,
maintaining patient privacy, validating AI outputs for clinical safety,
mitigating bias, and ensuring clinical acceptance. We believe this work
represents the first summarization of GenAI techniques for managing clinician
data overload due to combined RPM / EHR data complexities.

</details>


### [921] [Gaming and Cooperation in Federated Learning: What Can Happen and How to Monitor It](https://arxiv.org/abs/2509.02391)
*Dongseok Kim,Wonjun Jeong,Gisung Oh*

Main category: cs.LG

TL;DR: 本篇论文将联邦学习视为一个包含规则和激励的战略系统，而非简单的优化任务。提出了一个分析框架，用于区分真正提高性能的行为和仅针对指标的行为。引入了量化行为激励和集体性能损失的两个指标，并基于这些指标解释操作选择（如规则设计、信息披露、评估方法、聚合器切换）的影响。总结了可直接应用的检查清单（阈值、自动切换规则、预警信号），并提供了一个分配审计资源的算法和性能保证。通过模拟验证了该框架的预测模式，并公开了所有程序以确保可复现性。该方法在结合周期性校准、随机化和基于连接性的警报后，可在多变的真实世界操作中稳健应用。论文还提出了降低指标博弈激励的设计原则和操作指南，以维持和扩大稳定的合作。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的成功依赖于参与者隐藏的行为。本研究将联邦学习视为一个战略系统，旨在理解和量化这些行为对性能的影响。

Method: 提出一个分析框架，引入量化行为激励和集体性能损失的两个指标，用于解释操作选择的影响。总结了可用于实践的检查清单，并提供了一个分配审计资源的算法和性能保证。通过模拟验证。

Result: 通过跨不同环境的模拟，一致验证了框架预测的模式。该方法在结合周期性校准、随机化和基于连接性的警报后，可在多变的真实世界操作中稳健应用。

Conclusion: 该方法通过设计原则和操作指南，降低了指标博弈的激励，同时维持和扩大了稳定的合作。

Abstract: The success of Federated Learning depends on the actions that participants
take out of sight. We model Federated Learning not as a mere optimization task
but as a strategic system entangled with rules and incentives. From this
perspective, we present an analytical framework that makes it possible to
clearly identify where behaviors that genuinely improve performance diverge
from those that merely target metrics. We introduce two indices that
respectively quantify behavioral incentives and collective performance loss,
and we use them as the basis for consistently interpreting the impact of
operational choices such as rule design, the level of information disclosure,
evaluation methods, and aggregator switching. We further summarize thresholds,
auto-switch rules, and early warning signals into a checklist that can be
applied directly in practice, and we provide both a practical algorithm for
allocating limited audit resources and a performance guarantee. Simulations
conducted across diverse environments consistently validate the patterns
predicted by our framework, and we release all procedures for full
reproducibility. While our approach operates most strongly under several
assumptions, combining periodic recalibration, randomization, and
connectivity-based alarms enables robust application under the variability of
real-world operations. We present both design principles and operational
guidelines that lower the incentives for metric gaming while sustaining and
expanding stable cooperation.

</details>


### [922] [Experimental Assessment of a Multi-Class AI/ML Architecture for Real-Time Characterization of Cyber Events in a Live Research Reactor](https://arxiv.org/abs/2509.00076)
*Zachery Dahm,Konstantinos Vasili,Vasileios Theos,Konstantinos Gkouliaras,William Richards,True Miller,Brian Jowers,Stylianos Chatzidakis*

Main category: cs.LG

TL;DR: AI/ML可用于核工业，但实际应用有限。本文提出了一种多层AI/ML架构，整合IT和OT数据，以识别、表征和区分网络安全事件及其他运行异常。在Purdue大学的PUR-1研究堆上进行了演示，使用了14个系统状态和超过1380万个数据点。结果表明AI/ML在区分正常、异常和网络安全事件方面具有潜力，但处理复杂事件和多类架构仍需改进。


<details>
  <summary>Details</summary>
Motivation: AI/ML在核工业中的应用兴趣日益增长，但缺乏在运行核反应堆中应用AI/ML工具的可行性和适用性研究。本文旨在探索AI/ML在核反应堆网络安全中的应用。

Method: 提出了一种多层AI/ML架构，整合IT和OT数据流，用于识别、表征和区分网络安全事件及其他运行异常。通过在Purdue大学研究堆PUR-1上进行一个包含多重数据注入和拒绝服务攻击的用例来演示该架构。

Result: 该研究表明AI/ML能够区分正常、异常和网络安全相关事件，即使在拒绝服务攻击等具有挑战性的条件下也能有效区分。整合IT和OT数据可提高分类准确性，但在某些网络事件中同步和收集数据存在挑战。AI/ML在核网络安全方面显示出巨大潜力，但仍需进一步改进。

Conclusion: AI/ML在核反应堆网络安全领域具有显著的应用前景，但需要进一步完善其处理复杂事件区分和多类架构的能力。

Abstract: There is increased interest in applying Artificial Intelligence and Machine
Learning (AI/ML) within the nuclear industry and nuclear engineering community.
Effective implementation of AI/ML could offer benefits to the nuclear domain,
including enhanced identification of anomalies, anticipation of system
failures, and operational schedule optimization. However, limited work has been
done to investigate the feasibility and applicability of AI/ML tools in a
functioning nuclear reactor. Here, we go beyond the development of a single
model and introduce a multi-layered AI/ML architecture that integrates both
information technology and operational technology data streams to identify,
characterize, and differentiate (i) among diverse cybersecurity events and (ii)
between cyber events and other operational anomalies. Leveraging Purdue
Universitys research reactor, PUR-1, we demonstrate this architecture through a
representative use case that includes multiple concurrent false data injections
and denial-of-service attacks of increasing complexity under realistic reactor
conditions. The use case includes 14 system states (1 normal, 13 abnormal) and
over 13.8 million multi-variate operational and information technology data
points. The study demonstrated the capability of AI/ML to distinguish between
normal, abnormal, and cybersecurity-related events, even under challenging
conditions such as denial-of-service attacks. Combining operational and
information technology data improved classification accuracy but posed
challenges related to synchronization and collection during certain cyber
events. While results indicate significant promise for AI/ML in nuclear
cybersecurity, the findings also highlight the need for further refinement in
handling complex event differentiation and multi-class architectures.

</details>


### [923] [Data Cartography for Detecting Memorization Hotspots and Guiding Data Interventions in Generative Models](https://arxiv.org/abs/2509.00083)
*Laksh Patel,Neel Shanbhag*

Main category: cs.LG

TL;DR: GenDataCarto是一个数据中心框架，通过为每个预训练样本分配难度和记忆分数来识别和减少过拟合和记忆，从而提高生成模型的安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 现代生成模型存在过拟合和无意中记忆稀有训练样本的风险，这可能被攻击者利用或夸大基准性能。

Method: GenDataCarto框架为每个预训练样本分配难度分数（早期epoch损失）和记忆分数（“遗忘事件”的频率），然后将样本划分为四个象限，以指导目标性剪枝和上/下加权。理论上，记忆分数可以作为经典影响力的下界，并且通过降低高记忆热点的权重可以有效减小泛化差距。

Result: GenDataCarto在仅剪枝10%数据的情况下，将合成金丝雀提取的成功率降低了40%以上，同时验证困惑度仅增加了不到0.5%。

Conclusion: GenDataCarto表明，原则性的数据干预可以以很小的成本显著减轻生成模型的泄露风险，同时保持其性能。

Abstract: Modern generative models risk overfitting and unintentionally memorizing rare
training examples, which can be extracted by adversaries or inflate benchmark
performance. We propose Generative Data Cartography (GenDataCarto), a
data-centric framework that assigns each pretraining sample a difficulty score
(early-epoch loss) and a memorization score (frequency of ``forget events''),
then partitions examples into four quadrants to guide targeted pruning and
up-/down-weighting. We prove that our memorization score lower-bounds classical
influence under smoothness assumptions and that down-weighting
high-memorization hotspots provably decreases the generalization gap via
uniform stability bounds. Empirically, GenDataCarto reduces synthetic canary
extraction success by over 40\% at just 10\% data pruning, while increasing
validation perplexity by less than 0.5\%. These results demonstrate that
principled data interventions can dramatically mitigate leakage with minimal
cost to generative performance.

</details>


### [924] [Learning to Refine: Self-Refinement of Parallel Reasoning in LLMs](https://arxiv.org/abs/2509.00084)
*Qibin Wang,Pu Zhao,Shaohan Huang,Fangkai Yang,Lu Wang,Furu Wei,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.LG

TL;DR: GSR通过并行生成候选响应并进行自我完善来提高LLM解决复杂推理问题的能力，并采用混合训练策略进行优化。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间扩展方法（如Best-of-N和多数投票）依赖于候选响应的质量，在所有候选响应都错误时无法产生正确解决方案，而引入额外的选择模型会增加部署成本。

Method: 提出生成式自我完善（GSR）框架，由统一模型并行生成候选响应，然后基于包含问题和候选响应的提示进行自我完善，以合成更优的解决方案。通过联合优化直接求解问题和完善候选响应两个互补目标进行混合训练。

Result: 在五个数学基准测试中取得了最先进的性能，并证明了学习到的自我完善技能是一种模型无关的增强，对不同模型规模具有鲁棒性，并能泛化到分布外推理任务。

Conclusion: GSR是一种有效的测试时间扩展框架，通过自我完善能力提升LLM解决复杂推理问题的能力，并且具有模型无关和泛化能力。

Abstract: To further enhance the ability of Large Language Models (LLMs) to solve
complex, multi-step reasoning problems, test-time scaling (TTS) methods have
gained widespread attention. Existing approaches such as Best-of-N and majority
voting are limited as their performance depends on the quality of candidate
responses, making them unable to produce a correct solution when all candidates
are incorrect. Introducing an additional model to select the best response also
incurs significant deployment costs. To this end, we introduce Generative
Self-Refinement (GSR), a novel parallel test-time scaling framework where a
unified model first generates a set of candidate responses in parallel and then
performs self-refinement to synthesize a new superior solution based on a
prompt consisting of the problem and these candidates. However, LLMs struggle
to perform refinement effectively when prompted directly. Therefore, we design
a hybrid training pipeline by jointly optimizing for two complementary
objectives, solving problems directly and refining candidate responses.
Experimental results demonstrate that our method achieves state-of-the-art
performance across five mathematical benchmarks. We further show that this
learned self-refinement skill is a model-agnostic enhancement, robust across
different model scales and generalizing to out-of-distribution reasoning tasks.

</details>


### [925] [Learning to Coordinate: Distributed Meta-Trajectory Optimization Via Differentiable ADMM-DDP](https://arxiv.org/abs/2509.01630)
*Bingheng Wang,Yichao Gao,Tianchen Sun,Lin Zhao*

Main category: cs.LG

TL;DR: L2C是一个元学习框架，通过可微分的ADMM-DDP管道，学习并优化分布式轨迹优化中的超参数，从而提高多智能体系统的协调效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式轨迹优化方法（如ADMM-DDP）需要大量且紧密耦合的超参数调优，这给适应不同任务和智能体配置带来了挑战。

Method: L2C框架通过轻量级的、面向智能体的神经网络来元学习超参数。它在ADMM-DDP管道中进行端到端的分布式差分，并利用Riccati递归和反馈增益等DDP组件来高效计算元梯度。该方法还通过截断迭代和元学习ADMM惩罚参数来加速训练，同时保证了Lipschitz有界梯度误差。

Result: 在具有挑战性的空中运输任务中，L2C在IsaacSIM高保真模拟中生成了动态可行的轨迹，重新配置了四旋翼飞行器编队以在狭窄空间内进行安全的6-DoF负载操作，并能稳健地适应不同的团队规模和任务条件。此外，与现有方法相比，L2C实现了高达88%的梯度计算加速。

Conclusion: L2C框架通过元学习超参数，能够有效地解决分布式轨迹优化中的超参数调优难题，显著提高了多智能体系统的协调性能、适应性和训练效率，并在实际任务中展现出优越的能力。

Abstract: Distributed trajectory optimization via ADMM-DDP is a powerful approach for
coordinating multi-agent systems, but it requires extensive tuning of tightly
coupled hyperparameters that jointly govern local task performance and global
coordination. In this paper, we propose Learning to Coordinate (L2C), a general
framework that meta-learns these hyperparameters, modeled by lightweight
agent-wise neural networks, to adapt across diverse tasks and agent
configurations. L2C differentiates end-to-end through the ADMM-DDP pipeline in
a distributed manner. It also enables efficient meta-gradient computation by
reusing DDP components such as Riccati recursions and feedback gains. These
gradients correspond to the optimal solutions of distributed matrix-valued LQR
problems, coordinated across agents via an auxiliary ADMM framework that
becomes convex under mild assumptions. Training is further accelerated by
truncating iterations and meta-learning ADMM penalty parameters optimized for
rapid residual reduction, with provable Lipschitz-bounded gradient errors. On a
challenging cooperative aerial transport task, L2C generates dynamically
feasible trajectories in high-fidelity simulation using IsaacSIM, reconfigures
quadrotor formations for safe 6-DoF load manipulation in tight spaces, and
adapts robustly to varying team sizes and task conditions, while achieving up
to $88\%$ faster gradient computation than state-of-the-art methods.

</details>


### [926] [Centralized vs. Federated Learning for Educational Data Mining: A Comparative Study on Student Performance Prediction with SAEB Microdata](https://arxiv.org/abs/2509.00086)
*Rodrigo Tertulino*

Main category: cs.LG

TL;DR: Federated Learning (FedProx) with Deep Neural Networks (DNNs) shows promise for predicting student performance in Brazilian education, offering a privacy-preserving alternative to centralized models while achieving comparable accuracy.


<details>
  <summary>Details</summary>
Motivation: The potential of data mining and AI in education is hindered by privacy laws like LGPL, necessitating privacy-preserving methods for student data analysis.

Method: A federated DNN model using FedProx was trained across 50 simulated schools using SAEB microdata to predict student performance, and compared against a centralized XGBoost model using over two million student records.

Result: The federated DNN achieved 61.23% accuracy, a slight decrease from the centralized XGBoost model's 63.96% accuracy, but offering significant privacy benefits.

Conclusion: Federated Learning, specifically FedProx, is a viable and effective approach for developing collaborative predictive models in Brazilian education that comply with LGPD privacy requirements.

Abstract: The application of data mining and artificial intelligence in education
offers unprecedented potential for personalizing learning and early
identification of at-risk students. However, the practical use of these
techniques faces a significant barrier in privacy legislation, such as Brazil's
General Data Protection Law (LGPD), which restricts the centralization of
sensitive student data. To resolve this challenge, privacy-preserving
computational approaches are required. The present study evaluates the
feasibility and effectiveness of Federated Learning, specifically the FedProx
algorithm, to predict student performance using microdata from the Brazilian
Basic Education Assessment System (SAEB). A Deep Neural Network (DNN) model was
trained in a federated manner, simulating a scenario with 50 schools, and its
performance was rigorously benchmarked against a centralized eXtreme Gradient
Boosting (XGBoost) model. The analysis, conducted on a universe of over two
million student records, revealed that the centralized model achieved an
accuracy of 63.96%. Remarkably, the federated model reached a peak accuracy of
61.23%, demonstrating a marginal performance loss in exchange for a robust
privacy guarantee. The results indicate that Federated Learning is a viable and
effective solution for building collaborative predictive models in the
Brazilian educational context, in alignment with the requirements of the LGPD.

</details>


### [927] [Yet Unnoticed in LSTM: Binary Tree Based Input Reordering, Weight Regularization, and Gate Nonlinearization](https://arxiv.org/abs/2509.00087)
*Mojtaba Moattari*

Main category: cs.LG

TL;DR: LSTM模型在处理长期信息方面有很大潜力，但现有方法未能最优地关注特定历史信息。本文提出输入重排序方法来优先处理特定输入索引，并研究权重归一化（通过Lp范数）对模型平滑或稀疏化权重的效果。此外，本文还提出对LSTM门控进行非线性化处理（通过前馈神经网络），以增强其过滤和强调历史信息的能力。实验结果表明，这些方法在文本分类任务中能提升LSTM的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有LSTM模型虽然利用门控机制处理长期信息，但未能最优地关注特定历史信息。此外，现有研究缺乏对LSTM权重归一化（特别是Lp范数）及其对模型平滑或稀疏化权重的影响的探讨，也未提出对门控进行非线性化处理以增强其捕捉输入非线性的能力。

Method: 本文提出三种改进LSTM的方法：1. 输入重排序，以优先处理特定输入索引；2. 权重归一化，通过Lp范数寻找最佳权重关系以平滑或稀疏化权重；3. 门控非线性化，通过小型前馈神经网络增强门控对历史信息和当前输入的过滤和强调能力。

Result: 通过在文本分类任务中实现并与简单LSTM模型进行比较，结果显示所提出的方法能够提升LSTM模型的准确性。

Conclusion: 本文提出的输入重排序、权重归一化和门控非线性化方法能够有效提升LSTM模型在文本分类任务中的性能。

Abstract: LSTM models used in current Machine Learning literature and applications, has
a promising solution for permitting long term information using gating
mechanisms that forget and reduce effect of current input information. However,
even with this pipeline, they do not optimally focus on specific old index or
long-term information. This paper elaborates upon input reordering approaches
to prioritize certain input indices. Moreover, no LSTM based approach is found
in the literature that examines weight normalization while choosing the right
weight and exponent of Lp norms through main supervised loss function. In this
paper, we find out which norm best finds relationship between weights to either
smooth or sparsify them. Lastly, gates, as weighted representations of inputs
and states, which control reduction-extent of current input versus previous
inputs (~ state), are not nonlinearized enough (through a small FFNN). As
analogous to attention mechanisms, gates easily filter current information to
bold (emphasize on) past inputs. Nonlinearized gates can more easily tune up to
peculiar nonlinearities of specific input in the past. This type of
nonlinearization is not proposed in the literature, to the best of author's
knowledge. The proposed approaches are implemented and compared with a simple
LSTM to understand their performance in text classification tasks. The results
show they improve accuracy of LSTM.

</details>


### [928] [Learning from Peers: Collaborative Ensemble Adversarial Training](https://arxiv.org/abs/2509.00089)
*Li Dengjin,Guo Yanming,Xie Yuxiang,Li Zheng,Chen Jiangming,Li Xiaolong,Lao Mingrui*

Main category: cs.LG

TL;DR: EAT通过训练多个模型来增强模型的鲁棒性，但现有策略忽略了模型间的协同效应。本文提出了一种新方法CEAT，通过关注具有预测差异的样本来加强模型间的协同学习，并在实验中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有集成对抗训练（EAT）策略倾向于独立训练子模型，未能利用模型间的协同优势。研究发现，子模型间分类差异较大的样本对集成模型的鲁棒性影响更大。

Method: 提出了一种新颖高效的协同集成对抗训练（CEAT）方法。该方法通过让一个子模型的对抗训练关注其他子模型中预测差异较大的样本来实现协同学习。CEAT利用概率差异，通过引入校准距离正则化来适应性地为不同样本分配权重。

Result: CEAT在广泛使用的数据集上的大量实验表明，该方法在与竞争性EAT方法相比时，实现了最先进的性能。CEAT是模型无关的，可以灵活地应用于各种集成方法。

Conclusion: CEAT通过关注子模型间的预测差异，有效增强了集成模型的鲁棒性，并取得了优于现有EAT方法的性能，具有良好的通用性和灵活性。

Abstract: Ensemble Adversarial Training (EAT) attempts to enhance the robustness of
models against adversarial attacks by leveraging multiple models. However,
current EAT strategies tend to train the sub-models independently, ignoring the
cooperative benefits between sub-models. Through detailed inspections of the
process of EAT, we find that that samples with classification disparities
between sub-models are close to the decision boundary of ensemble, exerting
greater influence on the robustness of ensemble. To this end, we propose a
novel yet efficient Collaborative Ensemble Adversarial Training (CEAT), to
highlight the cooperative learning among sub-models in the ensemble. To be
specific, samples with larger predictive disparities between the sub-models
will receive greater attention during the adversarial training of the other
sub-models. CEAT leverages the probability disparities to adaptively assign
weights to different samples, by incorporating a calibrating distance
regularization. Extensive experiments on widely-adopted datasets show that our
proposed method achieves the state-of-the-art performance over competitive EAT
methods. It is noteworthy that CEAT is model-agnostic, which can be seamlessly
adapted into various ensemble methods with flexible applicability.

</details>


### [929] [Learning to Shard: RL for Co-optimizing the Parallelism Degrees and Per-operator Sharding Dimensions in Distributed LLM Inference](https://arxiv.org/abs/2509.00217)
*Ruokai Yin,Sattwik Deb Mishra,Xuan Zuo,Hokchhay Tann,Preyas Shah,Apala Guha*

Main category: cs.LG

TL;DR: Learn to Shard 是一种基于强化学习的方法，可以优化分布式大型语言模型（LLM）推理中的并行化策略，实现了比现有系统（如 Megatron-LM）高出 3.5 倍的吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 当前的分布式 LLM 推理系统（如 Megatron-LM）依赖于静态启发式方法来配置并行化和算子分片维度，这在模型规模扩大和硬件拓扑多样化时会导致性能损失。

Method: Learn to Shard 采用基于注意力机制的策略，通过学习高性能策略来高效地搜索巨大的组合搜索空间，共同优化并行化程度和算子分片维度。

Result: 在 H100 集群上，使用高达 1.6T 参数的 MoE 模型进行评估，Learn to Shard 实现了比元启发式基线高 3.5 倍的吞吐量，比 Megatron 启发式方法高 1.06 倍。

Conclusion: Learn to Shard 是首个联合优化分布式 LLM 推理中的并行化程度和算子分片维度的基于强化学习的方法，在实际应用中取得了显著的性能提升。

Abstract: Distributed LLM inference requires careful coordination of parallelization
strategies across hundreds to thousands of NPUs to meet production SLOs.
Current systems like Megatron-LM rely on static heuristics that separately
configure parallelism degrees and per-operator sharding dimensions, leaving
significant performance on the table as models scale and hardware topologies
diversify. We introduce Learn to Shard, to our knowledge, the first RL-based
approach to co-optimize both coarse-grained parallelism degrees and
fine-grained per-operator sharding dimensions for distributed LLM inference.
Our method employs an attention-based policy over an elite history that learns
from high-performing strategies to efficiently navigate the vast combinatorial
search space. Evaluated on H100 clusters with MoE models up to 1.6T parameters,
Learn to Shard achieves up to 3.5x throughput improvement over metaheuristic
baselines and 1.06x over Megatron heuristics.

</details>


### [930] [VariAntNet: Learning Decentralized Control of Multi-Agent Systems](https://arxiv.org/abs/2509.02271)
*Yigal Koifman,Erez Koifman,Eran Iceland,Ariel Barel,Alfred M. Bruckstein*

Main category: cs.LG

TL;DR: a deep learning model called VariAntNet enables simple robotic agents (Ant Robots) to swarm and collaborate effectively in disaster response scenarios like firefighting, outperforming traditional methods in gathering tasks by achieving faster convergence and maintaining cohesion.


<details>
  <summary>Details</summary>
Motivation: This paper addresses the challenge of maintaining swarm cohesion and avoiding fragmentation in simple robotic agents (Ant Robots) operating in complex environments with limited sensing and no reliable communication or centralized control, particularly for disaster response applications.

Method: The paper proposes VariAntNet, a deep learning-based decentralized control model that extracts geometric features from local observations and uses a novel, differentiable, multi-objective loss function based on the visibility graph Laplacian matrix to promote swarm cohesiveness. The model is trained and demonstrated on a multi-agent gathering task with bearing-only and limited-range sensing.

Result: VariAntNet significantly outperforms an existing analytical solution on the multi-agent gathering task, achieving more than double the convergence rate while maintaining high swarm connectivity across various swarm sizes. The paper also analyzes the trade-off between convergence speed and agent loss in time-critical scenarios.

Conclusion: Deep learning-based decentralized control models like VariAntNet offer a practical solution for enabling simple robotic agents to perform effectively in disaster response scenarios, outperforming traditional methods in terms of speed and cohesion, despite potential trade-offs in agent loss under strict time constraints.

Abstract: A simple multi-agent system can be effectively utilized in disaster response
applications, such as firefighting. Such a swarm is required to operate in
complex environments with limited local sensing and no reliable inter-agent
communication or centralized control. These simple robotic agents, also known
as Ant Robots, are defined as anonymous agents that possess limited sensing
capabilities, lack a shared coordinate system, and do not communicate
explicitly with one another. A key challenge for simple swarms lies in
maintaining cohesion and avoiding fragmentation despite limited-range sensing.
Recent advances in machine learning offer effective solutions to some of the
classical decentralized control challenges. We propose VariAntNet, a deep
learning-based decentralized control model designed to facilitate agent
swarming and collaborative task execution. VariAntNet includes geometric
features extraction from unordered, variable-sized local observations. It
incorporates a neural network architecture trained with a novel,
differentiable, multi-objective, mathematically justified loss function that
promotes swarm cohesiveness by utilizing the properties of the visibility graph
Laplacian matrix. VariAntNet is demonstrated on the fundamental multi-agent
gathering task, where agents with bearing-only and limited-range sensing must
gather at some location. VariAntNet significantly outperforms an existing
analytical solution, achieving more than double the convergence rate while
maintaining high swarm connectivity across varying swarm sizes. While the
analytical solution guarantees cohesion, it is often too slow in practice. In
time-critical scenarios, such as emergency response operations where lives are
at risk, slower analytical methods are impractical and justify the loss of some
agents within the swarm. This paper presents and analyzes this trade-off in
detail.

</details>


### [931] [Robust Detection of Synthetic Tabular Data under Schema Variability](https://arxiv.org/abs/2509.00092)
*G. Charbel N. Kindji,Elisa Fromont,Lina Maria Rojas-Barahona,Tanguy Urvoy*

Main category: cs.LG

TL;DR: 检测野外合成表格数据具有挑战性，但并非不可能。


<details>
  <summary>Details</summary>
Motivation: 尽管图像和文本的检测方法已得到广泛开发，但表格数据（尽管无处不在）的情况却在很大程度上被忽视了。

Method: 提出了一种新颖的 datum-wise transformer 架构，并加入了一个 table-adaptation 组件。

Result: 该模型在 AUC 和准确性方面均提高了 7 个百分点，并通过加入 table-adaptation 组件进一步提高了 7 个百分点的准确性。

Conclusion: 这项工作首次有力地证明，在真实世界的条件下检测合成表格数据不仅是可行的，而且可以高度可靠地完成。

Abstract: The rise of powerful generative models has sparked concerns over data
authenticity. While detection methods have been extensively developed for
images and text, the case of tabular data, despite its ubiquity, has been
largely overlooked. Yet, detecting synthetic tabular data is especially
challenging due to its heterogeneous structure and unseen formats at test time.
We address the underexplored task of detecting synthetic tabular data in the
wild, where tables have variable and previously unseen schemas. We introduce a
novel datum-wise transformer architecture that significantly outperforms the
only previously published baseline, improving both AUC and accuracy by 7
points. By incorporating a table-adaptation component, our model gains an
additional 7 accuracy points, demonstrating enhanced robustness. This work
provides the first strong evidence that detecting synthetic tabular data in
real-world conditions is not only feasible, but can be done with high
reliability.

</details>


### [932] [ReLATE: Learning Efficient Sparse Encoding for High-Performance Tensor Decomposition](https://arxiv.org/abs/2509.00280)
*Ahmed E. Helal,Fabio Checconi,Jan Laukemann,Yongseok Soh,Jesmin Jahan Tithi,Fabrizio Petrini,Jee Choi*

Main category: cs.LG

TL;DR: ReLATE框架通过强化学习自动构建高效稀疏张量表示，在性能上优于专家设计的格式，速度提升高达2倍。


<details>
  <summary>Details</summary>
Motivation: 分析高维稀疏数据对于张量分解（TD）至关重要，但其不规则的计算和内存访问模式给现代并行处理器带来了严峻的性能挑战。现有方法依赖于无法适应不规则张量形状和/或高度可变数据分布的专家设计的稀疏张量格式。

Method: ReLATE框架使用一种自主学习的智能体，通过与张量分解（TD）环境的直接交互，利用混合模型无关和模型驱动算法，从真实和模拟的行动中学习，从而发现优化的张量编码。该框架还引入了规则驱动的行动掩蔽和动态信息行动过滤机制，以确保张量编码在有界执行时间内功能正确，即使在学习的早期阶段也是如此。

Result: ReLATE生成的稀疏张量表示能够自动适应不规则的张量形状和数据分布，在多样化的稀疏张量数据集上持续优于专家设计的格式，与最佳稀疏格式相比，速度最高提升2倍，几何平均速度提升1.4-1.46倍。

Conclusion: ReLATE框架通过其创新的强化学习方法，成功解决了稀疏张量表示的性能瓶颈，为处理高维稀疏数据提供了更优化的解决方案。

Abstract: Tensor decomposition (TD) is essential for analyzing high-dimensional sparse
data, yet its irregular computations and memory-access patterns pose major
performance challenges on modern parallel processors. Prior works rely on
expert-designed sparse tensor formats that fail to adapt to irregular tensor
shapes and/or highly variable data distributions. We present the
reinforcement-learned adaptive tensor encoding (ReLATE) framework, a novel
learning-augmented method that automatically constructs efficient sparse tensor
representations without labeled training samples. ReLATE employs an autonomous
agent that discovers optimized tensor encodings through direct interaction with
the TD environment, leveraging a hybrid model-free and model-based algorithm to
learn from both real and imagined actions. Moreover, ReLATE introduces
rule-driven action masking and dynamics-informed action filtering mechanisms
that ensure functionally correct tensor encoding with bounded execution time,
even during early learning stages. By automatically adapting to both irregular
tensor shapes and data distributions, ReLATE generates sparse tensor
representations that consistently outperform expert-designed formats across
diverse sparse tensor data sets, achieving up to 2X speedup compared to the
best sparse format, with a geometric-mean speedup of 1.4-1.46X.

</details>


### [933] [Pruning Weights but Not Truth: Safeguarding Truthfulness While Pruning LLMs](https://arxiv.org/abs/2509.00096)
*Yao Fu,Runchao Li,Xianxuan Long,Haotian Yu,Xiaotian Han,Yu Yin,Pan Li*

Main category: cs.LG

TL;DR: Neural network pruning disrupts LLMs' lie detection capabilities by removing crucial activation features. A new method, TPLO, addresses this by prioritizing layers with activation outliers and strong discriminative features, preserving performance and improving hallucination detection and TruthfulQA scores.


<details>
  <summary>Details</summary>
Motivation: Pruning LLMs for low-resource scenarios often sacrifices their lie detection abilities, as it disrupts internal activation features crucial for lie detection classifiers. This paper aims to find a pruning method that preserves these capabilities.

Method: The paper proposes Truthful Pruning aligned by Layer-wise Outliers (TPLO), which prioritizes layers with more activation outliers and stronger discriminative features. It also introduces a prompting rule to enrich the TruthfulQA benchmark for better calibration of LLM pruning.

Result: TPLO achieves 88% accuracy in hallucination detection at 50% sparsity and improves LLMs' performance on the TruthfulQA benchmark, successfully retaining critical inner state features for robust lie detection.

Conclusion: TPLO is an effective method for pruning LLMs while preserving their lie detection capabilities, outperforming naive pruning strategies and improving performance on hallucination detection and TruthfulQA.

Abstract: Neural network pruning has emerged as a promising approach for deploying LLMs
in low-resource scenarios while preserving downstream task performance.
However, for the first time, we reveal that such pruning disrupts LLMs'
internal activation features crucial for lie detection, where probing
classifiers (typically small logistic regression models) trained on these
features assess the truthfulness of LLM-generated statements. This discovery
raises a crucial open question: how can we prune LLMs without sacrificing these
critical lie detection capabilities? Our investigation further reveals that
naively adjusting layer-wise pruning sparsity based on importance inadvertently
removes crucial weights, failing to improve lie detection performance despite
its reliance on the most crucial LLM layer. To address this issue, we propose
Truthful Pruning aligned by Layer-wise Outliers (TPLO), which places greater
emphasis on layers with more activation outliers and stronger discriminative
features simultaneously. This preserves LLMs' original performance while
retaining critical features of inner states needed for robust lie detection.
Moreover, we introduce a prompting rule to enrich the TruthfulQA benchmark for
better calibrating LLM pruning. Empirical results show that our approach
improves the hallucination detection for pruned LLMs (achieving 88% accuracy at
50% sparsity) and enhances their performance on TruthfulQA.

</details>


### [934] [Progressive Element-wise Gradient Estimation for Neural Network Quantization](https://arxiv.org/abs/2509.00097)
*Kaiqi Zhao*

Main category: cs.LG

TL;DR: PEGE是一种新的量化感知训练（QAT）方法，通过渐进式元素级梯度估计（PEGE）替代了传统的直通估计器（STE），旨在解决低比特量化中的精度下降问题。


<details>
  <summary>Details</summary>
Motivation: 现有的量化感知训练（QAT）方法大多依赖于直通估计器（STE），但STE忽略了离散化误差，可能导致精度下降，尤其是在极低比特数时。

Method: PEGE通过新颖的对数课程驱动混合精度替换策略，逐步用量化权重和激活替换全精度权重和激活。然后，它将QAT构建为一项联合优化问题，同时最小化预测任务损失和量化离散化误差。

Result: 在CIFAR-10和ImageNet上的大量实验表明，PEGE在各种架构（如ResNet、VGG）上持续优于现有的反向传播方法，并使低精度模型能够达到甚至超过其全精度对应物的准确性。

Conclusion: PEGE是一种简单而有效的方法，可以无缝集成到任何前向传播方法中，并提高量化模型的准确性，它提供了一个统一且可推广的框架，能够解决低比特量化中的精度问题。

Abstract: Neural network quantization aims to reduce the bit-widths of weights and
activations, making it a critical technique for deploying deep neural networks
on resource-constrained hardware. Most Quantization-Aware Training (QAT)
methods rely on the Straight-Through Estimator (STE) to address the
non-differentiability of discretization functions by replacing their
derivatives with that of the identity function. While effective, STE overlooks
discretization errors between continuous and quantized values, which can lead
to accuracy degradation -- especially at extremely low bit-widths. In this
paper, we propose Progressive Element-wise Gradient Estimation (PEGE), a simple
yet effective alternative to STE, which can be seamlessly integrated with any
forward propagation methods and improves the quantized model accuracy. PEGE
progressively replaces full-precision weights and activations with their
quantized counterparts via a novel logarithmic curriculum-driven
mixed-precision replacement strategy. Then it formulates QAT as a
co-optimization problem that simultaneously minimizes the task loss for
prediction and the discretization error for quantization, providing a unified
and generalizable framework. Extensive experiments on CIFAR-10 and ImageNet
across various architectures (e.g., ResNet, VGG) demonstrate that PEGE
consistently outperforms existing backpropagation methods and enables
low-precision models to match or even outperform the accuracy of their
full-precision counterparts.

</details>


### [935] [LLM-QUBO: An End-to-End Framework for Automated QUBO Transformation from Natural Language Problem Descriptions](https://arxiv.org/abs/2509.00099)
*Huixiang Zhang,Mahzabeen Emu,Salimur Choudhury*

Main category: cs.LG

TL;DR: LLM-QUBO框架利用大型语言模型和混合量子-经典方法，自动化了从自然语言到QUBO格式的转换，解决了量子退火在优化问题中的应用障碍，并为大规模优化挑战提供了可行的量子加速途径。


<details>
  <summary>Details</summary>
Motivation: 量子退火在解决NP难组合优化问题方面显示出潜力，但手动转换问题为QUBO格式和当前量子硬件的可扩展性限制阻碍了其实际应用。

Method: 提出了一种名为LLM-QUBO的新型端到端框架，该框架利用大型语言模型（LLM）解析自然语言并自动生成结构化数学表示，并集成了一种混合量子-经典Benders分解方法，将组合主问题编译为QUBO格式，并将线性子问题委托给经典求解器。

Result: 通过经典求解器验证了所生成QUBO的正确性和混合方法的扩展性，建立了稳健的性能基线，并证明了该框架已为量子硬件做好准备。

Conclusion: LLM-QUBO框架通过结合经典人工智能和量子计算，提供了一种协同计算范式，解决了优化问题实际应用中的关键挑战，显著降低了入门门槛，为将量子设备用作大规模、现实世界优化挑战的可及加速器提供了可行途径。

Abstract: Quantum annealing offers a promising paradigm for solving NP-hard
combinatorial optimization problems, but its practical application is severely
hindered by two challenges: the complex, manual process of translating problem
descriptions into the requisite Quadratic Unconstrained Binary Optimization
(QUBO) format and the scalability limitations of current quantum hardware. To
address these obstacles, we propose a novel end-to-end framework, LLM-QUBO,
that automates this entire formulation-to-solution pipeline. Our system
leverages a Large Language Model (LLM) to parse natural language, automatically
generating a structured mathematical representation. To overcome hardware
limitations, we integrate a hybrid quantum-classical Benders' decomposition
method. This approach partitions the problem, compiling the combinatorial
complex master problem into a compact QUBO format, while delegating linearly
structured sub-problems to classical solvers. The correctness of the generated
QUBO and the scalability of the hybrid approach are validated using classical
solvers, establishing a robust performance baseline and demonstrating the
framework's readiness for quantum hardware. Our primary contribution is a
synergistic computing paradigm that bridges classical AI and quantum computing,
addressing key challenges in the practical application of optimization problem.
This automated workflow significantly reduces the barrier to entry, providing a
viable pathway to transform quantum devices into accessible accelerators for
large-scale, real-world optimization challenges.

</details>


### [936] [Online Identification of IT Systems through Active Causal Learning](https://arxiv.org/abs/2509.02130)
*Kim Hammar,Rolf Stadler*

Main category: cs.LG

TL;DR: 该论文提出了一种名为“主动因果学习”的新方法，用于从数据中自动识别IT系统的因果模型，以应对现代IT系统日益增长的复杂性和动态性。


<details>
  <summary>Details</summary>
Motivation: 传统上，IT系统的因果模型由领域专家设计和维护，但随着现代IT系统的复杂性和动态性不断增长，这种方法面临越来越大的挑战。自动识别因果模型对于实现网络和系统管理的自动化至关重要。

Method: 该方法采用迭代方式，利用高斯过程回归和基于滚动干预策略收集的系统测量数据来估计因果函数，从而捕捉系统变量之间的依赖关系。

Result: 实验验证表明，该方法能够准确识别因果系统模型，同时对系统运行的干扰性较低。论文证明了该方法在贝叶斯意义上是最优的，并且能产生有效的干预措施。

Conclusion: 该论文提出了一种新颖的、数据驱动的、在线识别IT系统因果模型的方法，能够准确且干扰性低地实现IT系统的因果模型识别。

Abstract: Identifying a causal model of an IT system is fundamental to many branches of
systems engineering and operation. Such a model can be used to predict the
effects of control actions, optimize operations, diagnose failures, detect
intrusions, etc., which is central to achieving the longstanding goal of
automating network and system management tasks. Traditionally, causal models
have been designed and maintained by domain experts. This, however, proves
increasingly challenging with the growing complexity and dynamism of modern IT
systems. In this paper, we present the first principled method for online,
data-driven identification of an IT system in the form of a causal model. The
method, which we call active causal learning, estimates causal functions that
capture the dependencies among system variables in an iterative fashion using
Gaussian process regression based on system measurements, which are collected
through a rollout-based intervention policy. We prove that this method is
optimal in the Bayesian sense and that it produces effective interventions.
Experimental validation on a testbed shows that our method enables accurate
identification of a causal system model while inducing low interference with
system operations.

</details>


### [937] [Exploiting a Mixture-of-Layers in an Electrocardiography Foundation Model](https://arxiv.org/abs/2509.00102)
*Phu X. Nguyen,Huy Phan,Hieu Pham,Christos Chatzichristos,Bert Vandenberk,Maarten De Vos*

Main category: cs.LG

TL;DR: Transformer-based ECG models have strong performance, but their internal representations are not fully understood. This paper proposes Post-pretraining Mixture-of-layers Aggregation (PMA) to effectively leverage diverse layer representations by using a gating network to fuse them, improving downstream task performance. The method is also extended to the pretraining stage.


<details>
  <summary>Details</summary>
Motivation: To understand and exploit the internal representations of Transformer-based foundation models for ECGs, particularly whether the final layer provides optimal performance for downstream tasks.

Method: Propose a novel architecture called Post-pretraining Mixture-of-layers Aggregation (PMA). This involves pre-training a 1D Vision Transformer (ViT) on ECG signals using masked modeling. For downstream applications, a gating network selectively fuses representations from different layers of the pre-trained model. The method is extended to the pretraining stage by aggregating all representations via group-wise averaging before feeding them into a decoder-based Transformer.

Result: The proposed PMA method enhances representation power and improves performance in downstream applications by effectively fusing diverse layer-wise representations, as opposed to solely relying on the final layer.

Conclusion: The final layer of pre-trained Transformer models for ECGs does not necessarily provide optimal performance. The novel PMA approach, which fuses representations from multiple layers using a gating network, effectively enhances performance in downstream tasks and can be extended to the pretraining stage.

Abstract: Transformer-based foundation models for Electrocardiograms (ECGs) have
recently achieved impressive performance in many downstream applications.
However, the internal representations of such models across layers have not
been fully understood and exploited. An important question arises: Does the
final layer of the pre-trained Transformer model, the \emph{de facto}
representational layer, provide optimal performance for downstream tasks?
Although our answer based on empirical and theoretical analyses for this
question is negative, we propose a novel approach to leverage the
representation diversity of the model's layers effectively. Specifically, we
introduce a novel architecture called Post-pretraining Mixture-of-layers
Aggregation (PMA), which enables a flexible combination of the layer-wise
representations from the layer stack of a Transformer-based foundation model.
We first pre-train the model from ECG signals using the 1-dimensional Vision
Transformer (ViT) via masked modeling. In downstream applications, instead of
relying solely on the last layer of the model, we employ a gating network to
selectively fuse the representations from the pretrained model's layers,
thereby enhancing representation power and improving performance of the
downstream applications. In addition, we extend the proposed method to the
pretraining stage by aggregating all representations through group-wise
averaging before feeding them into the decoder-based Transformer.

</details>


### [938] [HydroGAT: Distributed Heterogeneous Graph Attention Transformer for Spatiotemporal Flood Prediction](https://arxiv.org/abs/2509.02481)
*Aishwarya Sarkar,Autrin Hakimi,Xiaoqiong Chen,Hai Huang,Chaoqun Lu,Ibrahim Demir,Ali Jannesari*

Main category: cs.LG

TL;DR: Accurate flood forecasting is challenging due to complex spatial and temporal factors. Existing methods ignore topological information or fail to capture spatiotemporal interactions. We propose HydroGAT, a GNN-based model that uses a heterogeneous basin graph and attention mechanisms to improve hourly discharge prediction. Our model achieves state-of-the-art results and can be efficiently trained on high-resolution data using a distributed data-parallel pipeline.


<details>
  <summary>Details</summary>
Motivation: Accurate flood forecasting is crucial for water-resource management but is challenging due to the need to model local, time-varying runoff drivers and complex spatial interactions. Existing data-driven approaches like CNNs and sequence-based models ignore topological information, while current GNN-based models struggle with high-resolution data due to computational costs. Most methods also treat spatial and temporal dependencies separately, failing to capture critical spatiotemporal interactions.

Method: The paper introduces a heterogeneous basin graph where each land and river pixel is a node, connected based on physical hydrological flow directions and inter-catchment relationships. It proposes HydroGAT, a spatiotemporal network that utilizes this graph to learn local temporal importance and influential upstream locations through adaptive attention mechanisms. The model is designed to handle high-resolution data and capture spatiotemporal interactions. A distributed data-parallel pipeline is developed for efficient training on large datasets, scaling up to 64 GPUs.

Result: Evaluated on two Midwestern US basins against five baseline architectures, HydroGAT achieved superior performance with higher Nash-Sutcliffe Efficiency (NSE) up to 0.97, improved Kling-Gupta Efficiency (KGE) up to 0.96, and low bias (PBIAS within ±5%) in hourly discharge prediction. The model also provides interpretable attention maps highlighting sparse, structured inter-catchment influences. The distributed data-parallel pipeline demonstrated up to a 15x speedup across machines for high-resolution training.

Conclusion: HydroGAT effectively addresses the challenges in flood forecasting by incorporating topological information through a heterogeneous basin graph and capturing spatiotemporal interactions with an attention-based network. It achieves state-of-the-art performance in hourly discharge prediction and offers interpretable insights. The efficient distributed training pipeline enables the use of high-resolution data, advancing the field of hydrological modeling.

Abstract: Accurate flood forecasting remains a challenge for water-resource management,
as it demands modeling of local, time-varying runoff drivers (e.g.,
rainfall-induced peaks, baseflow trends) and complex spatial interactions
across a river network. Traditional data-driven approaches, such as
convolutional networks and sequence-based models, ignore topological
information about the region. Graph Neural Networks (GNNs) propagate
information exactly along the river network, which is ideal for learning
hydrological routing. However, state-of-the-art GNN-based flood prediction
models collapse pixels to coarse catchment polygons as the cost of training
explodes with graph size and higher resolution. Furthermore, most existing
methods treat spatial and temporal dependencies separately, either applying
GNNs solely on spatial graphs or transformers purely on temporal sequences,
thus failing to simultaneously capture spatiotemporal interactions critical for
accurate flood prediction. We introduce a heterogenous basin graph where every
land and river pixel is a node connected by physical hydrological flow
directions and inter-catchment relationships. We propose HydroGAT, a
spatiotemporal network that adaptively learns local temporal importance and the
most influential upstream locations. Evaluated in two Midwestern US basins and
across five baseline architectures, our model achieves higher NSE (up to 0.97),
improved KGE (up to 0.96), and low bias (PBIAS within $\pm$5%) in hourly
discharge prediction, while offering interpretable attention maps that reveal
sparse, structured intercatchment influences. To support high-resolution
basin-scale training, we develop a distributed data-parallel pipeline that
scales efficiently up to 64 NVIDIA A100 GPUs on NERSC Perlmutter supercomputer,
demonstrating up to 15x speedup across machines. Our code is available at
https://github.com/swapp-lab/HydroGAT.

</details>


### [939] [Pre-trained knowledge elevates large language models beyond traditional chemical reaction optimizers](https://arxiv.org/abs/2509.00103)
*Robert MacKnight,Jose Emilio Regio,Jeffrey G. Ethier,Luke A. Baldwin,Gabe Gomes*

Main category: cs.LG

TL;DR: 大型语言模型（LLMs）在化学实验优化中展现出与贝叶斯优化（BO）相当甚至更优的性能，尤其在复杂参数空间和稀疏解场景下，这得益于其预训练的领域知识，而非取代结构化探索策略。


<details>
  <summary>Details</summary>
Motivation: 探索预训练的大型语言模型（LLMs）能否改变现代化学实验中通过算法搜索黑箱参数空间的范式。

Method: 使用六个完全枚举的分类反应数据集，将LLM引导的优化（LLM-GO）与贝叶斯优化（BO）和随机采样进行基准测试。引入信息论框架量化采样多样性，分析LLM-GO和BO的行为差异。

Result: LLM-GO在五个单目标数据集中持续匹配或超越BO性能，尤其在参数复杂度高和优良条件稀疏（<5%空间）的情况下优势更明显。BO仅在明确的多目标权衡中保持优势。LLMs在所有数据集中保持比BO更高的探索熵，并在解决方案稀疏的空间中表现出优势。

Conclusion: LLM-GO在传统方法难以应对的复杂分类空间中表现出色，其优势在于利用领域理解而非数学优化，表明预训练的领域知识可以更有效地导航化学参数空间。

Abstract: Modern optimization in experimental chemistry employs algorithmic search
through black-box parameter spaces. Here we demonstrate that pre-trained
knowledge in large language models (LLMs) fundamentally changes this paradigm.
Using six fully enumerated categorical reaction datasets (768 - 5,684
experiments), we benchmark LLM-guided optimization (LLM-GO) against Bayesian
optimization (BO) and random sampling. Frontier LLMs consistently match or
exceed BO performance across five single-objective datasets, with advantages
growing as parameter complexity increases and high-performing conditions become
scarce (<5% of space). BO retains superiority only for explicit multi-objective
trade-offs. To understand these contrasting behaviors, we introduce a
topology-agnostic information theory framework quantifying sampling diversity
throughout optimization campaigns. This analysis reveals that LLMs maintain
systematically higher exploration entropy than BO across all datasets while
achieving superior performance, with advantages most pronounced in
solution-scarce parameter spaces where high-entropy exploration typically fails
- suggesting that pre-trained domain knowledge enables more effective
navigation of chemical parameter space rather than replacing structured
exploration strategies. To enable transparent benchmarking and community
validation, we release Iron Mind (https://gomes.andrew.cmu.edu/iron-mind), a
no-code platform for side-by-side evaluation of human, algorithmic, and LLM
optimization campaigns with public leaderboards and complete trajectories. Our
findings establish that LLM-GO excels precisely where traditional methods
struggle: complex categorical spaces requiring domain understanding rather than
mathematical optimization.

</details>


### [940] [Principled Approximation Methods for Efficient and Scalable Deep Learning](https://arxiv.org/abs/2509.00174)
*Pedro Savarese*

Main category: cs.LG

TL;DR: 大型模型增加了计算和能源需求，本论文提出通过架构设计、模型压缩和优化来提高深度学习系统的效率。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型的计算和能源需求日益增长，阻碍了其部署和广泛应用。

Method: 模型压缩方面，提出可微近似方法进行剪枝和量化；架构设计方面，设计了利用参数共享的神经架构搜索算法；优化方面，研究了自适应优化器。

Result: 提出的方法在图像分类、语言建模和生成建模任务上显著提高了训练和推理效率，同时保持或提高了模型性能。

Conclusion: 通过可扩展和原则性的近似方法解决了计算难题，提高了深度学习系统的效率。

Abstract: Recent progress in deep learning has been driven by increasingly larger
models. However, their computational and energy demands have grown
proportionally, creating significant barriers to their deployment and to a
wider adoption of deep learning technologies. This thesis investigates
principled approximation methods for improving the efficiency of deep learning
systems, with a particular focus on settings that involve discrete constraints
and non-differentiability.
  We study three main approaches toward improved efficiency: architecture
design, model compression, and optimization. For model compression, we propose
novel approximations for pruning and quantization that frame the underlying
discrete problem as continuous and differentiable, enabling gradient-based
training of compression schemes alongside the model's parameters. These
approximations allow for fine-grained sparsity and precision configurations,
leading to highly compact models without significant fine-tuning. In the
context of architecture design, we design an algorithm for neural architecture
search that leverages parameter sharing across layers to efficiently explore
implicitly recurrent architectures. Finally, we study adaptive optimization,
revisiting theoretical properties of widely used methods and proposing an
adaptive optimizer that allows for quick hyperparameter tuning.
  Our contributions center on tackling computationally hard problems via
scalable and principled approximations. Experimental results on image
classification, language modeling, and generative modeling tasks show that the
proposed methods provide significant improvements in terms of training and
inference efficiency while maintaining, or even improving, the model's
performance.

</details>


### [941] [FNODE: Flow-Matching for data-driven simulation of constrained multibody systems](https://arxiv.org/abs/2509.00183)
*Hongyu Wang,Jingquan Wang,Dan Negrut*

Main category: cs.LG

TL;DR: FNODE通过直接从轨迹数据中学习加速度矢量场来解决约束多体系统建模中的计算成本高和长期预测精度有限的问题，无需通过ODE求解器进行反向传播，从而提高了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动的约束多体系统建模中计算成本高和长期预测精度有限的挑战。

Method: 提出FNODE框架，直接从轨迹数据中学习加速度矢量场，通过监督加速度而不是积分状态来训练，并使用FFT和FD等数值微分技术高效计算加速度目标。

Result: FNODE在单和三质量弹簧阻尼系统、双摆、滑块曲柄和倒立摆等基准测试中，在准确性、泛化能力和计算效率方面均优于MBD-NODE、LSTM和FCNN等现有方法。

Conclusion: FNODE框架在约束多体系统建模方面表现出优越的性能，为解决现有方法的局限性提供了一个有效的解决方案。

Abstract: Data-driven modeling of constrained multibody systems faces two persistent
challenges: high computational cost and limited long-term prediction accuracy.
To address these issues, we introduce the Flow-Matching Neural Ordinary
Differential Equation (FNODE), a framework that learns acceleration vector
fields directly from trajectory data. By reformulating the training objective
to supervise accelerations rather than integrated states, FNODE eliminates the
need for backpropagation through an ODE solver, which represents a bottleneck
in traditional Neural ODEs. Acceleration targets are computed efficiently using
numerical differentiation techniques, including a hybrid Fast Fourier Transform
(FFT) and Finite Difference (FD) scheme. We evaluate FNODE on a diverse set of
benchmarks, including the single and triple mass-spring-damper systems, double
pendulum, slider-crank, and cart-pole. Across all cases, FNODE consistently
outperforms existing approaches such as Multi-Body Dynamic Neural ODE
(MBD-NODE), Long Short-Term Memory (LSTM) networks, and Fully Connected Neural
Networks (FCNN), demonstrating good accuracy, generalization, and computational
efficiency.

</details>


### [942] [Democratizing Agentic AI with Fast Test-Time Scaling on the Edge](https://arxiv.org/abs/2509.00195)
*Hao Mark Chen,Zhiwen Mo,Guanxi Lu,Shuang Liang,Lingxiao Ma,Wayne Luk,Hongxiang Fan*

Main category: cs.LG

TL;DR: FlashTTS是一个用于在内存受限的LLM推理中实现测试时间缩放（TTS）的服务系统，通过三种优化（Speculative Beam Extension、Asymmetric Multi-Model Memory Allocation、Dynamic Prefix-Aware Scheduling）克服了现有方法的开销，使边缘LLM在单个消费级GPU上能达到与大型云模型相当的准确性和延迟。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署agentic AI至关重要，但内存限制通常导致只能使用推理能力较弱的小型LLM。测试时间缩放（TTS）可以通过在推理时分配更多计算资源来弥补推理能力的差距，但现有方法在边缘硬件上开销过大。

Method: FlashTTS通过以下三种协同优化来实现TTS的实用化：1. Speculative Beam Extension：缓解不规则推理路径导致的系统延迟。2. Asymmetric Multi-Model Memory Allocation：动态平衡生成和验证之间的内存。3. Dynamic Prefix-Aware Scheduling：最大化KV缓存的重用。FlashTTS是一个即插即用的库，可与vLLM集成。

Result: FlashTTS使边缘LLM在单个消费级GPU（24 GB）上能够匹配大型云模型的准确性和延迟。与vLLM基线相比，FlashTTS的吞吐量平均提高了2.2倍，延迟降低了38%-68%。

Conclusion: FlashTTS使在内存受限的边缘设备上实现高性能的agentic AI成为可能，从而促进了高性能agentic AI的普及。

Abstract: Deploying agentic AI on edge devices is crucial for privacy and
responsiveness, but memory constraints typically relegate these systems to
smaller Large Language Models (LLMs) with inferior reasoning capabilities.
Test-Time Scaling (TTS) can bridge this reasoning gap by dedicating more
compute during inference, but existing methods incur prohibitive overhead on
edge hardware. To overcome this, we introduce FlashTTS, a serving system that
makes TTS practical for memory-constrained LLM reasoning. FlashTTS introduces
three synergistic optimizations: (i) Speculative Beam Extension to mitigate
system stragglers from irregular reasoning paths; (ii) Asymmetric Multi-Model
Memory Allocation to dynamically balance memory between generation and
verification; and (iii) Dynamic Prefix-Aware Scheduling to maximize KV-cache
reuse. Built as a plug-and-play library for vLLM, FlashTTS enables edge LLMs on
a single consumer GPU (24 GB) to match the accuracy and latency of large cloud
models. Our evaluation demonstrates that FlashTTS achieves an average 2.2x
higher goodput and reduces latency by 38%-68% compared to a vLLM baseline,
paving the way for democratized, high-performance agentic AI on edge devices.

</details>


### [943] [From TLinFormer to TConstFormer: The Leap to Constant-Time Transformer Attention: Achieving O(1) Computation and O(1) KV Cache during Autoregressive Inference](https://arxiv.org/abs/2509.00202)
*Zhongpan Tang*

Main category: cs.LG

TL;DR: TConstFormer通过引入周期性状态更新机制，实现了恒定大小的KV Cache（O(1)）和摊销O(1)的计算复杂度，有效解决了Transformer处理超长序列的效率问题，在速度、内存和性能上均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: Transformer在处理超长序列时存在KV Cache线性增长和O(N^2 d)计算复杂度的问题，限制了其在实际应用中的效率。

Method: 提出TConstFormer架构，采用新颖的周期性状态更新机制，在k-1步执行纯恒定时间计算，仅在第k步执行一次线性时间全局信息同步，实现O(1) KV Cache和摊销O(1)计算复杂度。

Result: 理论计算和实验结果表明，TConstFormer在长文本推理任务的速度、内存效率和整体性能方面均显著优于基线模型。

Conclusion: TConstFormer的突破性进展为高效、鲁棒的流式语言模型应用提供了可能。

Abstract: Although the Transformer has become the cornerstone of modern AI, its
autoregressive inference suffers from a linearly growing KV Cache and a
computational complexity of O(N^2 d), severely hindering its ability to process
ultra-long sequences. To overcome this limitation, this paper introduces the
TConstFormer architecture, building upon our previous work, TLinFormer.
TConstFormer employs an innovative periodic state update mechanism to achieve a
truly constant-size O(1) KV Cache. The computational complexity of this
mechanism is also O(1) in an amortized sense: it performs purely constant-time
computations for $k-1$ consecutive steps (e.g., $k=256$) and executes a single
linear-time global information synchronization only on the $k$-th step.
Theoretical calculations and experimental results demonstrate that TConstFormer
exhibits an overwhelming advantage over baseline models in terms of speed,
memory efficiency, and overall performance on long-text inference tasks. This
breakthrough paves the way for efficient and robust streaming language model
applications.

</details>


### [944] [Estimating Parameter Fields in Multi-Physics PDEs from Scarce Measurements](https://arxiv.org/abs/2509.00203)
*Xuyang Li,Mahdi Masmoudi,Rami Gharbi,Nizar Lajnef,Vishnu Naresh Boddeti*

Main category: cs.LG

TL;DR: Neptune是一种新的参数推断方法，能够从稀疏的系统响应测量中推断参数场，并在各种问题中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有参数估计方法在处理非线性、时空变化的参数以及数据稀疏的情况下存在局限性，尤其是在非线性动力学、多物理场交互或系统响应观测有限的情况下。

Method: Neptune使用独立的坐标神经网络来表示物理空间或状态变量中的每个参数场，以实现稀疏测量的参数场推断。

Result: Neptune在各种物理和生物医学问题中，与现有方法相比，在参数估计方面表现出显著的优越性，实现了从少量（低至50个）观测值中进行鲁棒的参数估计，将参数估计误差降低了两个数量级，并将动态响应预测误差降低了十倍。此外，Neptune还展示了卓越的外推能力。

Conclusion: Neptune通过实现可靠且数据高效的参数推断，有望在工程、医疗保健等领域产生广泛的变革性影响。

Abstract: Parameterized partial differential equations (PDEs) underpin the mathematical
modeling of complex systems in diverse domains, including engineering,
healthcare, and physics. A central challenge in using PDEs for real-world
applications is to accurately infer the parameters, particularly when the
parameters exhibit non-linear and spatiotemporal variations. Existing parameter
estimation methods, such as sparse identification and physics-informed neural
networks (PINNs), struggle in such cases, especially with nonlinear dynamics,
multiphysics interactions, or limited observations of the system response. To
address these challenges, we introduce Neptune, a general-purpose method
capable of inferring parameter fields from sparse measurements of system
responses. Neptune employs independent coordinate neural networks to
continuously represent each parameter field in physical space or in state
variables. Across various physical and biomedical problems, where direct
parameter measurements are prohibitively expensive or unattainable, Neptune
significantly outperforms existing methods, achieving robust parameter
estimation from as few as 50 observations, reducing parameter estimation errors
by two orders of magnitude and dynamic response prediction errors by a factor
of ten compared to PINNs. Furthermore, Neptune exhibits superior extrapolation
capabilities, enabling accurate predictions in regimes beyond training data
where PINN fail. By facilitating reliable and data-efficient parameter
inference, Neptune promises broad transformative impacts in engineering,
healthcare, and beyond.

</details>


### [945] [Speech Foundation Models Generalize to Time Series Tasks from Wearable Sensor Data](https://arxiv.org/abs/2509.00221)
*Jaya Narain,Zakaria Aldeneh,Shirley Ren*

Main category: cs.LG

TL;DR: 语音基础模型在可穿戴传感器时间序列任务上表现出色，展示了跨领域能力。


<details>
  <summary>Details</summary>
Motivation: 探索语音基础模型能否用于可穿戴传感器时间序列任务，并验证其跨领域表示学习能力。

Method: 使用HuBERT和wav2vec2.0等语音基础模型提取特征，并训练探针模型在情绪分类、心律失常检测和活动分类任务上进行评估，与仅在特定模态数据上训练的自监督模型进行比较。

Result: 基于语音基础模型提取的特征，探针模型在各项任务上均优于仅在特定模态数据上训练的模型，尤其证明了语音模型卷积特征编码器在可穿戴传感器任务上的相关性。

Conclusion: 语音基础模型可以学习到领域无关的表示，并能有效提升数据稀疏的时间序列任务的性能和鲁棒性，为构建通用的语音和传感器数据时间序列模型奠定了基础。

Abstract: Both speech and sensor time series data encode information in both the time-
and frequency- domains, like spectral powers and waveform shapelets. We show
that speech foundation models learn representations that are domain-independent
and achieve state-of-the-art performance on time series tasks from wearable
sensors. Probes trained on features extracted from HuBERT and wav2vec 2.0
outperform those extracted from self-supervised models trained directly on
modality specific datasets for mood classification, arrhythmia detection, and
activity classification tasks. We find a particularly strong relevance of the
convolutional feature encoders from speech models for wearable sensor tasks.
The methods proposed here improve performance and robustness for data-scarce
time series tasks, using simple probing methods. This work is a step towards
generalized time series models for speech and sensor data, a topic for further
exploration.

</details>


### [946] [Quantum-Optimized Selective State Space Model for Efficient Time Series Prediction](https://arxiv.org/abs/2509.00259)
*Stefan-Alexandru Jura,Mihai Udrescu,Alexandru Topirceanu*

Main category: cs.LG

TL;DR: Q-SSM是一种结合了状态空间模型和量子门的新方法，用于长时序预测，解决了Transformer和S-Mamba的局限性，在多个基准测试中表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 长时序预测面临非平稳、多尺度依赖、噪声鲁棒性、效率和稳定性等挑战。Transformer模型（如Autoformer, Informer）泛化性好但复杂度高，状态空间模型（如S-Mamba）虽然更新快但训练不稳定且对多元预测鲁棒性有限。

Method: 提出量子优化的选择性状态空间模型（Q-SSM），结合状态空间动力学和变分量子门。使用参数化量子电路（RY-RX ansatz）的期望值自适应地调节记忆更新，替代了计算成本高昂的注意力机制。

Result: 在ETT, Traffic, Exchange Rate三个基准数据集上进行实验，Q-SSM在准确性和鲁棒性方面持续优于LSTM, TCN, Reformer, Transformer类模型以及S-Mamba。

Conclusion: 变分量子门可以解决当前长时序预测的局限性，实现准确且鲁棒的多元预测。

Abstract: Long-range time series forecasting remains challenging, as it requires
capturing non-stationary and multi-scale temporal dependencies while
maintaining noise robustness, efficiency, and stability. Transformer-based
architectures such as Autoformer and Informer improve generalization but suffer
from quadratic complexity and degraded performance on very long time horizons.
State space models, notably S-Mamba, provide linear-time updates but often face
unstable training dynamics, sensitivity to initialization, and limited
robustness for multivariate forecasting. To address such challenges, we propose
the Quantum-Optimized Selective State Space Model (Q-SSM), a hybrid
quantum-optimized approach that integrates state space dynamics with a
variational quantum gate. Instead of relying on expensive attention mechanisms,
Q-SSM employs a simple parametrized quantum circuit (RY-RX ansatz) whose
expectation values regulate memory updates adaptively. This quantum gating
mechanism improves convergence stability, enhances the modeling of long-term
dependencies, and provides a lightweight alternative to attention. We
empirically validate Q-SSM on three widely used benchmarks, i.e., ETT, Traffic,
and Exchange Rate. Results show that Q-SSM consistently improves over strong
baselines (LSTM, TCN, Reformer), Transformer-based models, and S-Mamba. These
findings demonstrate that variational quantum gating can address current
limitations in long-range forecasting, leading to accurate and robust
multivariate predictions.

</details>


### [947] [Continuously Tempered Diffusion Samplers](https://arxiv.org/abs/2509.00316)
*Ezra Erives,Bowen Jing,Peter Holderrieth,Tommi Jaakkola*

Main category: cs.LG

TL;DR: 基于退火的神经采样器通过训练神经网络来摊销从非归一化分布中采样，该网络将密度族从源传输到目标。然而，先前的方法在提议分布方面存在不足。本文提出了连续调质扩散采样器（CTDS），利用分子动力学中的探索技术来改进提议分布，通过在不同温度下引入密度族来降低能量势垒，从而提高采样性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于退火的神经采样器在训练阶段的提议分布存在探索不足的问题，导致采样性能下降，尤其是在处理目标分布存在孤立模式等病理特性时。

Method: 提出连续调质扩散采样器（CTDS），该方法借鉴了分子动力学中的探索技术。具体来说，CTDS引入了一个跨越不同温度的密度族，在高温度下降低能量势垒以促进探索，然后在目标低温下驱动采样。

Result: CTDS通过改进的提议分布实现了更优的采样性能，该性能提升得益于增强的探索能力。

Conclusion: 连续调质扩散采样器（CTDS）通过引入跨越不同温度的密度族，有效解决了现有基于退火的神经采样器在探索方面的不足，从而提高了采样性能。

Abstract: Annealing-based neural samplers seek to amortize sampling from unnormalized
distributions by training neural networks to transport a family of densities
interpolating from source to target. A crucial design choice in the training
phase of such samplers is the proposal distribution by which locations are
generated at which to evaluate the loss. Previous work has obtained such a
proposal distribution by combining a partially learned transport with annealed
Langevin dynamics. However, isolated modes and other pathological properties of
the annealing path imply that such proposals achieve insufficient exploration
and thereby lower performance post training. To remedy this, we propose
continuously tempered diffusion samplers, which leverage exploration techniques
developed in the context of molecular dynamics to improve proposal
distributions. Specifically, a family of distributions across different
temperatures is introduced to lower energy barriers at higher temperatures and
drive exploration at the lower temperature of interest. We empirically validate
improved sampler performance driven by extended exploration. Code is available
at https://github.com/eje24/ctds.

</details>


### [948] [Chunked TabPFN: Exact Training-Free In-Context Learning for Long-Context Tabular Data](https://arxiv.org/abs/2509.00326)
*Renat Sergazinov,Shao-An Yin*

Main category: cs.LG

TL;DR: TabPFN v2 采用 tiled-block 策略处理长上下文，无需预处理，在 TabArena 基准测试中表现优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于 Transformer 的模型（如 TabPFN）在处理表格数据时，由于计算和内存成本高昂，难以处理超过 10K 的上下文。需要一种能够扩展处理长上下文能力的方法。

Method: 提出了一种 tiled-block 策略，用于在 TabPFN 框架内计算注意力，该策略兼容标准 GPU 设置，并且无需任何预处理即可处理长上下文。

Result: 该方法在 TabArena 基准测试中得到验证，证明了其在处理长上下文方面的有效性，并使 TabPFN 能够处理比以往更长的上下文。

Conclusion: tiled-block 策略成功解决了 TabPFN 处理长上下文的瓶颈，无需预处理即可扩展其能力，并在实际应用中取得了优于传统模型的性能。

Abstract: TabPFN v2 achieves better results than tree-based models on several tabular
benchmarks, which is notable since tree-based models are usually the strongest
choice for tabular data. However, it cannot handle more than 10K context tokens
because transformers have quadratic computation and memory costs.
  Unlike existing approaches that rely on context compression, such as
selecting representative samples via K-nearest neighbors (KNN), we introduce a
\textbf{tiled-block} strategy to compute attention within the TabPFN framework.
This design is compatible with standard GPU setups and, to the best of our
knowledge, is the first to enable TabPFN to \textbf{process long contexts
without any pre-processing}. We demonstrate the effectiveness of our approach
on the standard TabArena benchmark.

</details>


### [949] [Counterfactual Risk Minimization with IPS-Weighted BPR and Self-Normalized Evaluation in Recommender Systems](https://arxiv.org/abs/2509.00333)
*Rahul Raja,Arpita Vats*

Main category: cs.LG

TL;DR: 该论文提出了一种结合IPS加权训练和IPS加权BPR目标（由Propensity Regularizer增强）的流水线，以解决推荐系统中由曝光偏差引起的问题，并减少IPS估计中的方差和不稳定性。


<details>
  <summary>Details</summary>
Motivation: 推荐系统在从日志隐反馈中学习和评估时，面临曝光偏差的挑战。虽然逆倾向评分（IPS）可以纠正这种偏差，但它常常伴随着高方差和不稳定性。

Method: 提出了一种结合IPS加权训练和IPS加权贝叶斯个性化排序（BPR）目标（由Propensity Regularizer增强）的流水线。在离线策略评估中，比较了直接法（DM）、IPS和自归一化IPS（SNIPS），并展示了IPS加权训练如何提高模型在偏差曝光下的鲁棒性。提出的Propensity Regularizer（PR）进一步缓解了极端倾向权重引起的方差放大，从而实现更稳定的估计。

Result: 在合成数据和MovieLens 100K数据集上的实验表明，该方法在无偏差曝光下具有更好的泛化能力，并与朴素和标准的IPS方法相比，降低了评估方差。

Conclusion: 该方法为推荐系统中反事实学习和评估提供了实用的指导，通过结合IPS加权训练和Propensity Regularizer，有效解决了曝光偏差问题，并提高了模型估计的稳定性和鲁棒性。

Abstract: Learning and evaluating recommender systems from logged implicit feedback is
challenging due to exposure bias. While inverse propensity scoring (IPS)
corrects this bias, it often suffers from high variance and instability. In
this paper, we present a simple and effective pipeline that integrates
IPS-weighted training with an IPS-weighted Bayesian Personalized Ranking (BPR)
objective augmented by a Propensity Regularizer (PR). We compare Direct Method
(DM), IPS, and Self-Normalized IPS (SNIPS) for offline policy evaluation, and
demonstrate how IPS-weighted training improves model robustness under biased
exposure. The proposed PR further mitigates variance amplification from extreme
propensity weights, leading to more stable estimates. Experiments on synthetic
and MovieLens 100K data show that our approach generalizes better under
unbiased exposure while reducing evaluation variance compared to naive and
standard IPS methods, offering practical guidance for counterfactual learning
and evaluation in real-world recommendation settings.

</details>


### [950] [Are We Really Learning the Score Function? Reinterpreting Diffusion Models Through Wasserstein Gradient Flow Matching](https://arxiv.org/abs/2509.00336)
*An B. Vuong,Michael T. McCann,Javier E. Santos,Yen Ting Lin*

Main category: cs.LG

TL;DR: 扩散模型可以通过流匹配理论更好地理解，而不是分数学习，即使在神经网络不满足保守性约束的情况下也能成功生成。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型的解释通常基于学习数据对数密度的梯度（分数函数），但实际使用的神经网络架构并未强制执行此保守向量场约束。本研究旨在探讨这种不匹配对扩散模型性能的影响，并提出新的理论视角。

Method: 通过数值证据展示训练好的扩散网络违反了真实分数函数所需的积分和微分约束，表明学习到的向量场不是保守的。提出将扩散模型训练视为到 Wasserstein 梯度流（WGF）速度场的流匹配，而非反向随机微分方程的分数学习。

Result: 所提出的 WGF 视角自然地产生了“概率流”，无需依赖反向随机微分方程理论，并解释了为何在神经网络向量场非真实分数的情况下生成采样仍然成功。此外，研究表明神经近似产生的非保守误差不一定会损害密度传输。

Conclusion: 建议将 WGF 视角作为理解扩散生成模型的原则性、优雅且具有理论基础的框架，因为它能解释模型在不满足传统分数学习约束时的成功之处，并为未来的研究提供了新的理论支撑。

Abstract: Diffusion models are commonly interpreted as learning the score function,
i.e., the gradient of the log-density of noisy data. However, this assumption
implies that the target of learning is a conservative vector field, which is
not enforced by the neural network architectures used in practice. We present
numerical evidence that trained diffusion networks violate both integral and
differential constraints required of true score functions, demonstrating that
the learned vector fields are not conservative. Despite this, the models
perform remarkably well as generative mechanisms. To explain this apparent
paradox, we advocate a new theoretical perspective: diffusion training is
better understood as flow matching to the velocity field of a Wasserstein
Gradient Flow (WGF), rather than as score learning for a reverse-time
stochastic differential equation. Under this view, the "probability flow"
arises naturally from the WGF framework, eliminating the need to invoke
reverse-time SDE theory and clarifying why generative sampling remains
successful even when the neural vector field is not a true score. We further
show that non-conservative errors from neural approximation do not necessarily
harm density transport. Our results advocate for adopting the WGF perspective
as a principled, elegant, and theoretically grounded framework for
understanding diffusion generative models.

</details>


### [951] [Scalable Option Learning in High-Throughput Environments](https://arxiv.org/abs/2509.00338)
*Mikael Henaff,Scott Fujimoto,Michael Rabbat*

Main category: cs.LG

TL;DR: hierarchical RL in NetHack achieved 25x higher throughput using Scalable Option Learning (SOL) algorithm trained on 20 billion frames, outperforming flat agents and showing general applicability across MiniHack and Mujoco.


<details>
  <summary>Details</summary>
Motivation: Existing hierarchical RL approaches have not realized the benefits of large-scale training. This work aims to address key challenges in scaling hierarchical RL to high-throughput environments.

Method: The paper proposes Scalable Option Learning (SOL), a scalable hierarchical RL algorithm. The algorithm was trained on 20 billion frames of experience in NetHack and validated on MiniHack and Mujoco.

Result: SOL achieved a 25x higher throughput compared to existing hierarchical methods in NetHack, significantly surpassing flat agents and demonstrating positive scaling trends. The algorithm's general applicability was also showcased on MiniHack and Mujoco.

Conclusion: Scalable Option Learning (SOL) is a highly scalable hierarchical RL algorithm that enables effective decision-making over long timescales and achieves significant improvements in high-throughput environments.

Abstract: Hierarchical reinforcement learning (RL) has the potential to enable
effective decision-making over long timescales. Existing approaches, while
promising, have yet to realize the benefits of large-scale training. In this
work, we identify and solve several key challenges in scaling hierarchical RL
to high-throughput environments. We propose Scalable Option Learning (SOL), a
highly scalable hierarchical RL algorithm which achieves a 25x higher
throughput compared to existing hierarchical methods. We train our hierarchical
agents using 20 billion frames of experience on the complex game of NetHack,
significantly surpassing flat agents and demonstrating positive scaling trends.
We also validate our algorithm on MiniHack and Mujoco environments, showcasing
its general applicability. Our code is open sourced at
github.com/facebookresearch/sol.

</details>


### [952] [LLM-Driven Policy Diffusion: Enhancing Generalization in Offline Reinforcement Learning](https://arxiv.org/abs/2509.00347)
*Hanping Zhang,Yuhong Guo*

Main category: cs.LG

TL;DR: LLMDPD利用LLM和Transformer处理文本和轨迹提示，通过上下文感知策略扩散模型来提高离线RL在未见过的任务上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着离线数据集的可用性增加和在线环境的缺乏，离线强化学习（RL）中的泛化能力面临挑战，因为仅在收集到的经验上训练的RL代理通常难以泛化到新任务或环境中。

Method: 提出LLM驱动的策略扩散（LLMDPD）方法，结合文本任务描述和轨迹提示来指导策略学习。利用LLM处理文本提示，利用Transformer编码轨迹提示，并将这些提示作为条件输入到上下文感知的策略扩散模型中。

Result: LLMDPD在未见过的任务上表现优于最先进的离线RL方法。

Conclusion: LLMDPD能有效提高离线强化学习的泛化能力和适应性。

Abstract: Reinforcement Learning (RL) is known for its strong decision-making
capabilities and has been widely applied in various real-world scenarios.
However, with the increasing availability of offline datasets and the lack of
well-designed online environments from human experts, the challenge of
generalization in offline RL has become more prominent. Due to the limitations
of offline data, RL agents trained solely on collected experiences often
struggle to generalize to new tasks or environments. To address this challenge,
we propose LLM-Driven Policy Diffusion (LLMDPD), a novel approach that enhances
generalization in offline RL using task-specific prompts. Our method
incorporates both text-based task descriptions and trajectory prompts to guide
policy learning. We leverage a large language model (LLM) to process text-based
prompts, utilizing its natural language understanding and extensive knowledge
base to provide rich task-relevant context. Simultaneously, we encode
trajectory prompts using a transformer model, capturing structured behavioral
patterns within the underlying transition dynamics. These prompts serve as
conditional inputs to a context-aware policy-level diffusion model, enabling
the RL agent to generalize effectively to unseen tasks. Our experimental
results demonstrate that LLMDPD outperforms state-of-the-art offline RL methods
on unseen tasks, highlighting its effectiveness in improving generalization and
adaptability in diverse settings.

</details>


### [953] [Theory Foundation of Physics-Enhanced Residual Learning](https://arxiv.org/abs/2509.00348)
*Shixiao Liang,Wang Chen,Keke Long,Peng Zhang,Xiaopeng Li,Jintao Ke*

Main category: cs.LG

TL;DR: 该论文从理论上解释了物理增强残差学习（PERL）的三个优势：减少神经网络参数、提高收敛速度和减少训练样本。通过研究具有Lipschitz连续性的问题，并分析损失函数界限与残差学习结构之间的关系，论文严格证明了这些优势。最后，通过自动车辆轨迹预测的数值例子验证了这些理论，证明了PERL在实际应用中的价值。


<details>
  <summary>Details</summary>
Motivation: 解释物理增强残差学习（PERL）相比纯神经网络的三个优势（减少参数、提高收敛速度、减少训练样本）缺乏理论依据的问题。

Method: 通过研究具有Lipschitz连续性的问题，并分析损失函数界限与残差学习结构之间的关系，严格证明了PERL的三个优势。

Result: 证明了PERL的三个优势，并通过自动车辆轨迹预测的数值例子进行了验证，结果表明PERL在样本量较少的情况下，精度优于纯神经网络。

Conclusion: PERL在理论上被证明是有效的，并且在自动驾驶等实际应用中具有重要的应用价值，能够提高预测性能并减少数据需求。

Abstract: Intensive studies have been conducted in recent years to integrate neural
networks with physics models to balance model accuracy and interpretability.
One recently proposed approach, named Physics-Enhanced Residual Learning
(PERL), is to use learning to estimate the residual between the physics model
prediction and the ground truth. Numeral examples suggested that integrating
such residual with physics models in PERL has three advantages: (1) a reduction
in the number of required neural network parameters; (2) faster convergence
rates; and (3) fewer training samples needed for the same computational
precision. However, these numerical results lack theoretical justification and
cannot be adequately explained.
  This paper aims to explain these advantages of PERL from a theoretical
perspective. We investigate a general class of problems with Lipschitz
continuity properties. By examining the relationships between the bounds to the
loss function and residual learning structure, this study rigorously proves a
set of theorems explaining the three advantages of PERL.
  Several numerical examples in the context of automated vehicle trajectory
prediction are conducted to illustrate the proposed theorems. The results
confirm that, even with significantly fewer training samples, PERL consistently
achieves higher accuracy than a pure neural network. These results demonstrate
the practical value of PERL in real world autonomous driving applications where
corner case data are costly or hard to obtain. PERL therefore improves
predictive performance while reducing the amount of data required.

</details>


### [954] [Optimized Weight Initialization on the Stiefel Manifold for Deep ReLU Neural Networks](https://arxiv.org/abs/2509.00362)
*Hyungu Lee,Taehyeong Kim,Hayoung Choi*

Main category: cs.LG

TL;DR: ReLU网络深度训练对权重初始化敏感，易导致神经元失活和梯度不稳。本文提出一种针对ReLU优化的正交初始化方法，通过求解Stiefel流形上的优化问题来控制预激活均值和激活稀疏度，从而稳定信号和梯度流，并在多个数据集和场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 深度ReLU网络训练对权重初始化敏感，现有方法（如He, Xavier, 正交初始化）在处理神经元失活和梯度不稳方面存在局限，尤其是在非常深的网络中。

Method: 提出一种专门针对ReLU优化的正交初始化方法，通过在Stiefel流形上求解优化问题来保留尺度并校准预激活统计数据，并推导了闭式解和采样方案。

Result: 理论分析表明，该方法能防止ReLU神经元失活，减缓激活方差衰减，缓解梯度消失。实验证明，在MNIST、Fashion-MNIST、多种表格数据集、少样本学习以及ReLU族激活函数上，该方法优于以往的初始化方法，并能实现深度网络的稳定训练。

Conclusion: 本文提出的针对ReLU优化的正交初始化方法，能够有效解决深度网络训练中的神经元失活和梯度不稳问题，并在多项实验中表现出优越性。

Abstract: Stable and efficient training of ReLU networks with large depth is highly
sensitive to weight initialization. Improper initialization can cause permanent
neuron inactivation dying ReLU and exacerbate gradient instability as network
depth increases. Methods such as He, Xavier, and orthogonal initialization
preserve variance or promote approximate isometry. However, they do not
necessarily regulate the pre-activation mean or control activation sparsity,
and their effectiveness often diminishes in very deep architectures. This work
introduces an orthogonal initialization specifically optimized for ReLU by
solving an optimization problem on the Stiefel manifold, thereby preserving
scale and calibrating the pre-activation statistics from the outset. A family
of closed-form solutions and an efficient sampling scheme are derived.
Theoretical analysis at initialization shows that prevention of the dying ReLU
problem, slower decay of activation variance, and mitigation of gradient
vanishing, which together stabilize signal and gradient flow in deep
architectures. Empirically, across MNIST, Fashion-MNIST, multiple tabular
datasets, few-shot settings, and ReLU-family activations, our method
outperforms previous initializations and enables stable training in deep
networks.

</details>


### [955] [Unifying Adversarial Perturbation for Graph Neural Networks](https://arxiv.org/abs/2509.00387)
*Jinluan Yang,Ruihao Zhang,Zhengyu Chen,Fei Wu,Kun Kuang*

Main category: cs.LG

TL;DR: 本研究提出了PerturbEmbedding方法，通过在GNN的隐藏嵌入上进行扰动，增强GNN对节点特征和图结构的对抗性攻击的鲁棒性和泛化能力，并提供了一个统一的框架来处理现有扰动策略。


<details>
  <summary>Details</summary>
Motivation: GNN容易受到对抗性攻击，现有的对抗性训练方法虽然有效，但应用受限于特定数据集和GNN类型。本研究旨在提出一种更通用、更有效的方法来增强GNN的鲁棒性和泛化能力。

Method: 提出PerturbEmbedding方法，在GNN的每个隐藏嵌入上执行扰动操作，并将扰动分为随机和对抗性扰动。该方法提供了一个统一的框架，可以整合大多数现有的扰动策略。

Result: 通过在不同数据集和骨干模型上的实验证明，PerturbEmbedding显著提高了GNN的鲁棒性和泛化能力，优于现有方法。同时，拒绝随机和对抗性扰动进一步提升了骨干模型的性能。

Conclusion: PerturbEmbedding是一种有效且通用的方法，能够增强GNN的鲁棒性和泛化能力，并为处理扰动提供了一个统一的框架。

Abstract: This paper studies the vulnerability of Graph Neural Networks (GNNs) to
adversarial attacks on node features and graph structure. Various methods have
implemented adversarial training to augment graph data, aiming to bolster the
robustness and generalization of GNNs. These methods typically involve applying
perturbations to the node feature, weights, or graph structure and subsequently
minimizing the loss by learning more robust graph model parameters under the
adversarial perturbations. Despite the effectiveness of adversarial training in
enhancing GNNs' robustness and generalization abilities, its application has
been largely confined to specific datasets and GNN types. In this paper, we
propose a novel method, PerturbEmbedding, that integrates adversarial
perturbation and training, enhancing GNNs' resilience to such attacks and
improving their generalization ability. PerturbEmbedding performs perturbation
operations directly on every hidden embedding of GNNs and provides a unified
framework for most existing perturbation strategies/methods. We also offer a
unified perspective on the forms of perturbations, namely random and
adversarial perturbations. Through experiments on various datasets using
different backbone models, we demonstrate that PerturbEmbedding significantly
improves both the robustness and generalization abilities of GNNs,
outperforming existing methods. The rejection of both random (non-targeted) and
adversarial (targeted) perturbations further enhances the backbone model's
performance.

</details>


### [956] [Curriculum Guided Personalized Subgraph Federated Learning](https://arxiv.org/abs/2509.00402)
*Minku Kang,Hogun Park*

Main category: cs.LG

TL;DR: Subgraph Federated Learning (FL) 框架CUFL通过课程学习（CL）和改进的加权聚合来解决数据异质性问题，在分布式私有子图上训练图神经网络（GNN），实现了优于基线的性能。


<details>
  <summary>Details</summary>
Motivation: Subgraph Federated Learning (FL) 旨在训练跨分布式私有子图的图神经网络（GNN），但面临严重的数据异质性问题。现有的加权模型聚合方法虽然试图通过分配权重给具有相似子图特征的客户端来个性化本地GNN，但稀疏和有偏的子图会导致模型过拟合，使得客户端相似性矩阵停滞或崩溃，从而削弱聚合的有效性。

Method: CUFL框架在客户端采用课程学习（CL），根据重建分数自适应地选择用于训练的边，首先让GNN学习容易的、通用的跨客户端子结构，然后学习更难的、客户端特定的子结构。这种分阶段的暴露方式可以防止过早地拟合有偏模式，并实现渐进的个性化。通过调节个性化，课程还改变了服务器聚合的方式，从交换通用知识转变为传播客户端特定的知识。此外，CUFL通过在随机参考图上使用细粒度结构指标来估计客户端相似性，从而改进了加权聚合。

Result: CUFL框架通过其课程学习策略和改进的加权聚合方法，成功地减轻了数据异质性问题，实现了比相关基线更优越的性能。在六个基准数据集上的大量实验证明了其有效性。

Conclusion: CUFL通过引入课程学习（CL）来解决Subgraph FL中的数据异质性问题，通过分阶段的暴露方式防止过拟合并实现渐进式个性化。同时，通过改进的加权聚合方法，CUFL能够更有效地传播客户端特定的知识，从而在分布式私有子图上实现更优的GNN训练。

Abstract: Subgraph Federated Learning (FL) aims to train Graph Neural Networks (GNNs)
across distributed private subgraphs, but it suffers from severe data
heterogeneity. To mitigate data heterogeneity, weighted model aggregation
personalizes each local GNN by assigning larger weights to parameters from
clients with similar subgraph characteristics inferred from their current model
states. However, the sparse and biased subgraphs often trigger rapid
overfitting, causing the estimated client similarity matrix to stagnate or even
collapse. As a result, aggregation loses effectiveness as clients reinforce
their own biases instead of exploiting diverse knowledge otherwise available.
To this end, we propose a novel personalized subgraph FL framework called
Curriculum guided personalized sUbgraph Federated Learning (CUFL). On the
client side, CUFL adopts Curriculum Learning (CL) that adaptively selects edges
for training according to their reconstruction scores, exposing each GNN first
to easier, generic cross-client substructures and only later to harder,
client-specific ones. This paced exposure prevents early overfitting to biased
patterns and enables gradual personalization. By regulating personalization,
the curriculum also reshapes server aggregation from exchanging generic
knowledge to propagating client-specific knowledge. Further, CUFL improves
weighted aggregation by estimating client similarity using fine-grained
structural indicators reconstructed on a random reference graph. Extensive
experiments on six benchmark datasets confirm that CUFL achieves superior
performance compared to relevant baselines. Code is available at
https://github.com/Kang-Min-Ku/CUFL.git.

</details>


### [957] [Metis: Training Large Language Models with Advanced Low-Bit Quantization](https://arxiv.org/abs/2509.00404)
*Hengjie Cao,Mengyi Chen,Yifeng Yang,Ruijun Huang,Fang Dong,Jixian Zhou,Anrui Chen,Mingzhi Dong,Yujiang Wang,Jinlong Hou,Yuan Cheng,Fan Wu,Fan Yang,Tun Lu,Ning Gu,Li Shang*

Main category: cs.LG

TL;DR: Metis框架通过谱分解、自适应学习率和双范围正则化等技术，解决了低比特量化LLM训练中的核心障碍——各向异性参数分布问题，实现了超越FP32的FP8训练和相当的FP4训练精度。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决低比特量化大型语言模型（LLM）训练中的一个根本性障碍：各向异性参数分布，它会导致训练不稳定和模型性能下降。

Method: Metis框架结合了（i）谱分解与随机嵌入以解耦主导和长尾成分，并将宽分布压缩为量化友好的窄范围；（ii）谱域中的自适应学习率以放大代表性不足的方向；（iii）联合约束数值精度和参数范围分布的双范围正则化器。

Result: Metis框架在FP8训练中超越了FP32基线，在FP4训练中达到了与FP32相当的准确性。

Conclusion: Metis框架为在先进的低比特量化下进行鲁棒且可扩展的LLM训练铺平了道路，通过解决各向异性参数分布问题，实现了高效的低比特训练。

Abstract: This work identifies anisotropic parameter distributions as a fundamental
barrier to training large language models (LLMs) with low-bit quantization: a
few dominant singular values create wide numerical ranges that conflict with
the inherent bias of block-wise quantization. This bias disproportionately
preserves high-magnitude values while discarding smaller ones, causing training
instability and low model performance. This work introduces Metis, a training
framework that combines (i) spectral decomposition with random embedding to
efficiently disentangle dominant from long-tail components, compressing broad
distributions into quantization-friendly narrow ranges; (ii) adaptive learning
rates in the spectral domain to amplify underrepresented directions and better
capture diverse features critical for performance; and (iii) a dual-range
regularizer that jointly constrains numerical precision and parameter range
distribution, ensuring stable, unbiased low-bit training. With Metis, FP8
training surpasses FP32 baselines, and FP4 training achieves accuracy
comparable to FP32, paving the way for robust and scalable LLM training under
advanced low-bit quantization. The code implementation for Metis is available
at: https://github.com/typename-yyf/Metis-quantization.

</details>


### [958] [Lagrangian Relaxation for Multi-Action Partially Observable Restless Bandits: Heuristic Policies and Indexability](https://arxiv.org/abs/2509.00415)
*Rahul Meshram,Kesav Kaza*

Main category: cs.LG

TL;DR: 该论文研究了具有多个动作的部分可观察的躁动多臂老虎机问题，并提出了一种基于拉格朗日边界和点估值迭代的近似方法来解决公共卫生干预规划问题。


<details>
  <summary>Details</summary>
Motivation: 在推荐系统、通信系统、公共卫生宣传系统和运筹学等领域，部分可观察躁动多臂老虎机问题有广泛应用。本研究针对具有多个动作的部分可观察躁动多臂老虎机问题进行研究，这是经典躁动多臂老虎机问题的泛化，其特点是每个老虎机有有限个状态但状态不可观察，且每个老虎机有有限个动作（两个以上）。该问题以公共卫生干预规划为例进行了动机阐述。

Method: 论文首先分析了部分可观察躁动多臂老虎机问题的拉格朗日边界法。由于有限状态、有限动作的部分可观察马尔可夫决策过程（POMDP）的最优值函数计算复杂，论文提出使用点估值迭代（PBVI）和在线滚动策略的近似方法来计算拉格朗日边界。此外，论文还研究了多动作POMDP的启发式策略，并讨论了Whittle指数策略及其在本模型中的局限性。

Result: 论文对值函数进行了多种性质分析，并为PBVI和在线滚动策略提供了理论见解。

Conclusion: 该研究为解决具有多个动作的部分可观察躁动多臂老虎机问题提供了一种近似方法，并在公共卫生干预规划等领域具有潜在应用价值。

Abstract: Partially observable restless multi-armed bandits have found numerous
applications including in recommendation systems, communication systems, public
healthcare outreach systems, and in operations research. We study multi-action
partially observable restless multi-armed bandits, it is a generalization of
the classical restless multi-armed bandit problem -- 1) each bandit has finite
states, and the current state is not observable, 2) each bandit has finite
actions. In particular, we assume that more than two actions are available for
each bandit. We motivate our problem with the application of public-health
intervention planning. We describe the model and formulate a long term
discounted optimization problem, where the state of each bandit evolves
according to a Markov process, and this evolution is action dependent. The
state of a bandit is not observable but one of finitely many feedback signals
are observable. Each bandit yields a reward, based on the action taken on that
bandit. The agent is assumed to have a budget constraint. The bandits are
assumed to be independent. However, they are weakly coupled at the agent
through the budget constraint.
  We first analyze the Lagrangian bound method for our partially observable
restless bandits. The computation of optimal value functions for finite-state,
finite-action POMDPs is non-trivial. Hence, the computation of Lagrangian
bounds is also challenging. We describe approximations for the computation of
Lagrangian bounds using point based value iteration (PBVI) and online rollout
policy. We further present various properties of the value functions and
provide theoretical insights on PBVI and online rollout policy. We study
heuristic policies for multi-actions PORMAB. Finally, we discuss present
Whittle index policies and their limitations in our model.

</details>


### [959] [Memory Limitations of Prompt Tuning in Transformers](https://arxiv.org/abs/2509.00421)
*Maxime Meyer,Mario Michelessa,Caroline Chaux,Vincent Y. F. Tan*

Main category: cs.LG

TL;DR: Prompt tuning在记忆能力上存在线性扩展限制，并且在长上下文时会出现性能衰减，这源于Transformer固有的有限记忆能力。


<details>
  <summary>Details</summary>
Motivation: 现有理论分析主要关注prompt tuning的通用近似性质，而忽略了其记忆能力，本文旨在弥补这一不足。

Method: 通过理论证明，分析了Transformer的记忆能力与prompt长度的关系，并提出了长上下文性能衰减的严格证明。

Result: 证明了Transformer的记忆量不能超过prompt长度的线性增长，并首次严格证明了长上下文性能衰减现象，表明Transformer内在记忆能力有限。

Conclusion: Transformer架构具有内在的有限记忆能力，这限制了其处理长序列信息的能力，即使在扩展上下文的情况下也无法突破这一瓶颈。

Abstract: Despite the empirical success of prompt tuning in adapting pretrained
language models to new tasks, theoretical analyses of its capabilities remain
limited. Existing theoretical work primarily addresses universal approximation
properties, demonstrating results comparable to standard weight tuning. In this
paper, we explore a different aspect of the theory of transformers: the
memorization capability of prompt tuning. We provide two principal theoretical
contributions. First, we prove that the amount of information memorized by a
transformer cannot scale faster than linearly with the prompt length. Second,
and more importantly, we present the first formal proof of a phenomenon
empirically observed in large language models: performance degradation in
transformers with extended contexts. We rigorously demonstrate that
transformers inherently have limited memory, constraining the amount of
information they can retain, regardless of the context size. This finding
offers a fundamental understanding of the intrinsic limitations of transformer
architectures, particularly their ability to handle long sequences.

</details>


### [960] [Universal Properties of Activation Sparsity in Modern Large Language Models](https://arxiv.org/abs/2509.00454)
*Filip Szatkowski,Patryk Będkowski,Alessio Devoto,Jan Dubiński,Pasquale Minervini,Mikołaj Piórczyński,Simone Scardapane,Bartosz Wójcik*

Main category: cs.LG

TL;DR: 深度学习模型中的输入相关激活稀疏性在ReLU激活网络中得到了广泛研究，但其方法不适用于不使用ReLU的现代大型语言模型（LLMs）。本文提出了一个评估稀疏性鲁棒性的通用框架，并系统研究了LLM的前馈网络（FFN）层中的激活稀疏性，发现了普遍存在的模式，为模型设计和加速提供了指导。


<details>
  <summary>Details</summary>
Motivation: ReLU激活的深度学习模型具有输入相关激活稀疏性，这与效率、鲁棒性和可解释性有关。然而，现有方法依赖于ReLU的特性，不适用于现代大型语言模型（LLMs），导致LLM激活稀疏性研究分散且缺乏共识。

Method: 提出一个通用框架来评估稀疏性鲁棒性，并系统研究了现代LLM（包括扩散LLM）的前馈网络（FFN）层中的激活稀疏性现象。

Result: 发现了LLM中激活稀疏性的普遍模式，为理解该现象提供了见解，并为利用其进行模型设计和加速提供了实用指南。

Conclusion: 现有针对ReLU模型的方法不适用于现代LLM，而本文提出的通用框架和系统研究为理解和利用LLM中的激活稀疏性提供了新见解和指导。

Abstract: Input-dependent activation sparsity is a notable property of deep learning
models, which has been extensively studied in networks with ReLU activations
and is associated with efficiency, robustness, and interpretability. However,
the approaches developed for ReLU-based models depend on exact zero activations
and do not transfer directly to modern large language models~(LLMs), which have
abandoned ReLU in favor of other activation functions. As a result, current
work on activation sparsity in LLMs is fragmented, model-specific, and lacks
consensus on which components to target. We propose a general framework to
assess sparsity robustness and present a systematic study of the phenomenon in
the FFN layers of modern LLMs, including diffusion LLMs. Our findings reveal
universal patterns of activation sparsity in LLMs, provide insights into this
phenomenon, and offer practical guidelines for exploiting it in model design
and acceleration.

</details>


### [961] [Localizing and Mitigating Memorization in Image Autoregressive Models](https://arxiv.org/abs/2509.00488)
*Aditya Kasliwal,Franziska Boenisch,Adam Dziedzic*

Main category: cs.LG

TL;DR: 图像自回归（IAR）模型在生成图像的速度和质量方面取得了最先进的性能，但它们也引发了对训练数据记忆和隐私问题的担忧。本研究通过细粒度测量来探讨这些记忆在不同IAR架构中发生的位置和方式。研究发现，不同IAR架构的记忆模式不同：在分层每分辨率架构中，记忆倾向于早期出现并随着分辨率加深；在具有标准自回归每令牌预测的IAR中，记忆集中在后处理阶段。这些记忆模式的定位与IAR记忆和泄露训练数据能力相关。通过干预记忆最强的组件，可以在对生成图像质量影响最小的情况下，显著降低IAR的数据提取能力。这些发现为了解图像生成模型的内部行为提供了新的见解，并指出了减轻隐私风险的实用策略。


<details>
  <summary>Details</summary>
Motivation: 探讨图像自回归（IAR）模型中数据记忆和隐私泄露问题，分析记忆发生的位置和方式。

Method: 通过细粒度测量分析不同IAR架构的记忆模式，并将记忆模式与模型记忆和泄露训练数据的能力联系起来，通过干预记忆最强的组件来降低数据提取能力。

Result: 不同IAR架构的记忆模式不同：分层架构中记忆早期出现并随分辨率加深；标准架构中记忆集中在后处理阶段。干预模型最易记忆的组件可有效降低数据泄露风险，同时对生成图像质量影响很小。

Conclusion: 研究为理解图像生成模型的内部行为提供了新见解，并指出了减轻隐私风险的实用策略。

Abstract: Image AutoRegressive (IAR) models have achieved state-of-the-art performance
in speed and quality of generated images. However, they also raise concerns
about memorization of their training data and its implications for privacy.
This work explores where and how such memorization occurs within different
image autoregressive architectures by measuring a fine-grained memorization.
The analysis reveals that memorization patterns differ across various
architectures of IARs. In hierarchical per-resolution architectures, it tends
to emerge early and deepen with resolutions, while in IARs with standard
autoregressive per token prediction, it concentrates in later processing
stages. These localization of memorization patterns are further connected to
IARs' ability to memorize and leak training data. By intervening on their most
memorizing components, we significantly reduce the capacity for data extraction
from IARs with minimal impact on the quality of generated images. These
findings offer new insights into the internal behavior of image generative
models and point toward practical strategies for mitigating privacy risks.

</details>


### [962] [Crystal Structure Prediction with a Geometric Permutation-Invariant Loss Function](https://arxiv.org/abs/2509.00832)
*Emmanuel Jehanno,Romain Menegaux,Julien Mairal,Sergei Grudinin*

Main category: cs.LG

TL;DR: 通过引入基于 Sinkhorn 算法的微分线性分配方案，我们提出了一个新的损失函数，称为 SinkFast，用于预测有机材料的晶体结构。该方法在 COD-Cluster17 基准测试中优于现有的流匹配方法。


<details>
  <summary>Details</summary>
Motivation: 精确预测有机材料的三维晶体结构对于设计具有目标特性的材料至关重要，而现有的方法计算成本高昂。

Method: 提出了一种新的损失函数，利用基于 Sinkhorn 算法的微分线性分配方案来处理分子组装问题，并捕捉关键的几何分子特性，同时保持排列不变性。

Result: SinkFast 在 COD-Cluster17 基准测试中显著优于更复杂的流匹配方法。

Conclusion: SinkFast 是一种有效的新方法，用于预测有机材料的晶体结构，优于现有技术。

Abstract: Crystalline structure prediction remains an open challenge in materials
design. Despite recent advances in computational materials science, accurately
predicting the three-dimensional crystal structures of organic materials--an
essential first step for designing materials with targeted properties--remains
elusive. In this work, we address the problem of molecular assembly, where a
set $\mathcal{S}$ of identical rigid molecules is packed to form a crystalline
structure. Existing state-of-the-art models typically rely on computationally
expensive, iterative flow-matching approaches. We propose a novel loss function
that correctly captures key geometric molecular properties while maintaining
permutation invariance over $\mathcal{S}$. We achieve this via a differentiable
linear assignment scheme based on the Sinkhorn algorithm. Remarkably, we show
that even a simple regression using our method {\em SinkFast} significantly
outperforms more complex flow-matching approaches on the COD-Cluster17
benchmark, a curated subset of the Crystallography Open Database (COD).

</details>


### [963] [Graph Convolutional Network With Pattern-Spatial Interactive and Regional Awareness for Traffic Forecasting](https://arxiv.org/abs/2509.00515)
*Xinyu Ji,Chengcheng Yan,Jibiao Yuan,Fiefie Zhao*

Main category: cs.LG

TL;DR: 该研究提出了一种名为PSIRAGCN的新型交通预测模型，以解决现有模型在处理多视角时空相关性和区域异质性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的交通预测模型在模拟复杂时空相关性方面取得了一定进展，但未能有效融合交通模式和空间相关性，且在消息传递中未能充分考虑区域异质性。

Method: 提出了一种模式-空间交互融合框架，包含模式模块和空间模块。模式模块从全局到局部捕捉模式和空间相关性。空间模块利用区域特征库，通过区域感知重构消息传递，以揭示交通网络中节点间的区域异质性。

Result: 在三个真实交通数据集上的广泛实验表明，PSIRAGCN的性能优于现有最先进的基线模型，并能平衡计算成本。

Conclusion: PSIRAGCN通过模式-空间交互融合和区域感知图卷积网络，有效提升了交通预测的准确性，并克服了现有模型的局限性。

Abstract: Traffic forecasting is significant for urban traffic management, intelligent
route planning, and real-time flow monitoring. Recent advances in
spatial-temporal models have markedly improved the modeling of intricate
spatial-temporal correlations for traffic forecasting. Unfortunately, most
previous studies have encountered challenges in effectively modeling
spatial-temporal correlations across various perceptual perspectives, which
have neglected the interactive fusion between traffic patterns and spatial
correlations. Additionally, constrained by spatial heterogeneity, most studies
fail to consider distinct regional heterogeneity during message-passing. To
overcome these limitations, we propose a Pattern-Spatial Interactive and
Regional Awareness Graph Convolutional Network (PSIRAGCN) for traffic
forecasting. Specifically, we propose a pattern-spatial interactive fusion
framework composed of pattern and spatial modules. This framework aims to
capture patterns and spatial correlations by adopting a perception perspective
from the global to the local level and facilitating mutual utilization with
positive feedback. In the spatial module, we designed a graph convolutional
network based on message-passing. The network is designed to leverage a
regional characteristics bank to reconstruct data-driven message-passing with
regional awareness. Reconstructed message passing can reveal the regional
heterogeneity between nodes in the traffic network. Extensive experiments on
three real-world traffic datasets demonstrate that PSIRAGCN outperforms the
State-of-the-art baseline while balancing computational costs.

</details>


### [964] [IMU-Enhanced EEG Motion Artifact Removal with Fine-Tuned Large Brain Models](https://arxiv.org/abs/2509.01073)
*Yuhong Zhang,Xusheng Zhu,Yuchen Xu,ChiaEn Lu,Hsinyu Shih,Gert Cauwenberghs,Tzyy-Ping Jung*

Main category: cs.LG

TL;DR: 该研究提出了一种结合脑电图(EEG)和惯性测量单元(IMU)数据的新方法，使用一个微调的大脑模型(LaBraM)来识别和去除与运动相关的EEG伪影，相比于仅使用EEG的传统方法，该方法在各种运动场景下表现出更强的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 脑机接口(BCI)在实际应用中面临的主要挑战之一是运动相关的EEG伪影，而现有的单模态方法（如ASR和ICA）未能有效利用IMU数据来解决这个问题。

Method: 研究提出了一种基于LaBraM的细化相关注意力映射方法，该方法利用IMU数据的空间通道关系来识别EEG信号中的运动伪影。该模型包含约920万个参数，并使用5.9小时的EEG和IMU数据进行训练。

Result: 与ASR-ICA基准相比，该方法在不同时间尺度和运动活动下表现更优，证明了结合IMU参考信号可以显著提高在各种运动场景下的鲁棒性。

Conclusion: 结合IMU数据和先进的深度学习模型（如LaBraM）是有效去除运动相关EEG伪影的关键，能够显著提高BCI系统的鲁棒性和实际应用能力。

Abstract: Electroencephalography (EEG) is a non-invasive method for measuring brain
activity with high temporal resolution; however, EEG signals often exhibit low
signal-to-noise ratios because of contamination from physiological and
environmental artifacts. One of the major challenges hindering the real-world
deployment of brain-computer interfaces (BCIs) involves the frequent occurrence
of motion-related EEG artifacts. Most prior studies on EEG motion artifact
removal rely on single-modality approaches, such as Artifact Subspace
Reconstruction (ASR) and Independent Component Analysis (ICA), without
incorporating simultaneously recorded modalities like inertial measurement
units (IMUs), which directly capture the extent and dynamics of motion. This
work proposes a fine-tuned large brain model (LaBraM)-based correlation
attention mapping method that leverages spatial channel relationships in IMU
data to identify motion-related artifacts in EEG signals. The fine-tuned model
contains approximately 9.2 million parameters and uses 5.9 hours of EEG and IMU
recordings for training, just 0.2346\% of the 2500 hours used to train the base
model. We compare our results against the established ASR-ICA benchmark across
varying time scales and motion activities, showing that incorporating IMU
reference signals significantly improves robustness under diverse motion
scenarios.

</details>


### [965] [Biological Pathway Informed Models with Graph Attention Networks (GATs)](https://arxiv.org/abs/2509.00524)
*Gavin Wong,Ping Shu Ho,Ivan Au Yeung,Ka Chun Cheung,Simon See*

Main category: cs.LG

TL;DR: 该研究提出了一种基于图注意力网络（GAT）的框架，用于在基因层面模拟生物通路，解决了现有模型忽略基因间相互作用和通路拓扑结构的问题。该模型在预测通路动态、提高模型鲁棒性以及从原始时间序列mRNA数据中发现基因间相互作用方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 大多数机器学习模型在处理生物通路时，将基因视为非结构化标记，忽略了基因间的相互作用和通路本身的拓扑结构。现有的通路信息模型虽然捕捉了通路间的相互作用，但仍将通路视为“基因集合”，未能利用其内部的拓扑信息。本研究旨在克服这些局限性，提出一种更有效的通路建模方法。

Method: 提出了一种基于图注意力网络（GAT）的框架，该框架能够模拟基因层面的生物通路。通过将通路表示为图结构，并利用GAT捕捉基因间的相互作用和通路拓扑，以提高模型性能。此外，通过模拟药物机制（边缘干预）来验证模型的生物学先验知识的正确性，并评估其鲁棒性。

Result: 与传统的MLP模型相比，GAT框架在预测未知处理条件下的通路动态时，平均平方误差（MSE）降低了81%，表现出更好的泛化能力。通过编码药物机制的边缘干预，模型鲁棒性得到了提升。此外，该GAT模型能够从原始时间序列mRNA数据中准确地重新发现TP53-MDM2-MDM4反馈回路中的所有五个基因间相互作用。

Conclusion: 基于GAT的通路建模方法在基因层面有效利用了通路结构信息，显著提高了预测精度和模型鲁棒性。该方法有潜力直接从实验数据中生成新的生物学假设，为理解复杂的生物系统提供了新的途径。

Abstract: Biological pathways map gene-gene interactions that govern all human
processes. Despite their importance, most ML models treat genes as unstructured
tokens, discarding known pathway structure. The latest pathway-informed models
capture pathway-pathway interactions, but still treat each pathway as a "bag of
genes" via MLPs, discarding its topology and gene-gene interactions. We propose
a Graph Attention Network (GAT) framework that models pathways at the gene
level. We show that GATs generalize much better than MLPs, achieving an 81%
reduction in MSE when predicting pathway dynamics under unseen treatment
conditions. We further validate the correctness of our biological prior by
encoding drug mechanisms via edge interventions, boosting model robustness.
Finally, we show that our GAT model is able to correctly rediscover all five
gene-gene interactions in the canonical TP53-MDM2-MDM4 feedback loop from raw
time-series mRNA data, demonstrating potential to generate novel biological
hypotheses directly from experimental data.

</details>


### [966] [SC-GIR: Goal-oriented Semantic Communication via Invariant Representation Learning](https://arxiv.org/abs/2509.01119)
*Senura Hansaja Wanasekara,Van-Dinh Nguyen,Kok-Seng,M. -Duong Nguyen,Symeon Chatzinotas,Octavia A. Dobre*

Main category: cs.LG

TL;DR: 本文提出了一种名为SC-GIR的面向目标的不变表示通信框架，用于图像传输。该框架利用自监督学习提取不变表示，以提高通信效率和任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前面向目标语义通信的方法面临联合训练、冗余数据交换以及对标记数据集的依赖等挑战，限制了其任务无关的效用。本文旨在解决这些问题。

Method: 本文提出了一种名为SC-GIR的框架，利用自监督学习提取不变表示，并采用基于协方差的对比学习技术获取有意义且语义密集的潜在表示。该框架用于图像传输，并应用于各种图像数据集进行有损压缩，然后用于面向目标的AI任务。

Result: SC-GIR在下游任务上的表现优于基线方案近10%，并且在不同信噪比条件下，压缩数据的分类准确率超过85%。

Conclusion: SC-GIR框架在学习紧凑且信息丰富的潜在表示方面非常有效，能够提高通信效率和下游任务的性能。

Abstract: Goal-oriented semantic communication (SC) aims to revolutionize communication
systems by transmitting only task-essential information. However, current
approaches face challenges such as joint training at transceivers, leading to
redundant data exchange and reliance on labeled datasets, which limits their
task-agnostic utility. To address these challenges, we propose a novel
framework called Goal-oriented Invariant Representation-based SC (SC-GIR) for
image transmission. Our framework leverages self-supervised learning to extract
an invariant representation that encapsulates crucial information from the
source data, independent of the specific downstream task. This compressed
representation facilitates efficient communication while retaining key features
for successful downstream task execution. Focusing on machine-to-machine tasks,
we utilize covariance-based contrastive learning techniques to obtain a latent
representation that is both meaningful and semantically dense. To evaluate the
effectiveness of the proposed scheme on downstream tasks, we apply it to
various image datasets for lossy compression. The compressed representations
are then used in a goal-oriented AI task. Extensive experiments on several
datasets demonstrate that SC-GIR outperforms baseline schemes by nearly 10%,,
and achieves over 85% classification accuracy for compressed data under
different SNR conditions. These results underscore the effectiveness of the
proposed framework in learning compact and informative latent representations.

</details>


### [967] [FedThief: Harming Others to Benefit Oneself in Self-Centered Federated Learning](https://arxiv.org/abs/2509.00540)
*Xiangyu Zhang,Mang Ye*

Main category: cs.LG

TL;DR: 本次研究提出了一种名为FedThief的新型自私联邦学习（SCFL）攻击范式，该范式旨在降低全局模型的性能，同时提升攻击者自身的模型性能。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，参与者上传的模型更新无法直接验证，易受恶意攻击。现有攻击策略虽然能降低全局模型性能，但也会损害攻击者自身模型，不符合攻击者的自我利益驱动。攻击者的真实目的是在联邦学习过程中获得竞争优势，即提升自身模型性能，而非仅仅造成破坏。

Method: 提出名为FedThief的框架，通过在上传阶段篡改模型更新来降低全局模型性能。同时，利用“散度感知集成”技术提升攻击者私有模型的性能。“散度”量化了私有模型与全局模型之间的偏差，该技术整合了全局更新和局部知识。

Result: 实验结果表明，FedThief能有效降低全局模型性能，并且攻击者可以通过集成模型显著超越全局模型。

Conclusion: FedThief是一种有效的自私联邦学习攻击方法，它能够在损害全局模型的同时，显著提升攻击者自身模型的性能，符合攻击者的自我利益驱动。

Abstract: In federated learning, participants' uploaded model updates cannot be
directly verified, leaving the system vulnerable to malicious attacks. Existing
attack strategies have adversaries upload tampered model updates to degrade the
global model's performance. However, attackers also degrade their own private
models, gaining no advantage. In real-world scenarios, attackers are driven by
self-centered motives: their goal is to gain a competitive advantage by
developing a model that outperforms those of other participants, not merely to
cause disruption. In this paper, we study a novel Self-Centered Federated
Learning (SCFL) attack paradigm, in which attackers not only degrade the
performance of the global model through attacks but also enhance their own
models within the federated learning process. We propose a framework named
FedThief, which degrades the performance of the global model by uploading
modified content during the upload stage. At the same time, it enhances the
private model's performance through divergence-aware ensemble techniques, where
"divergence" quantifies the deviation between private and global models, that
integrate global updates and local knowledge. Extensive experiments show that
our method effectively degrades the global model performance while allowing the
attacker to obtain an ensemble model that significantly outperforms the global
model.

</details>


### [968] [CbLDM: A Diffusion Model for recovering nanostructure from pair distribution function](https://arxiv.org/abs/2509.01370)
*Jiarui Cao,Zhiyang Zhang,Heming Wang,Jun Xu,Ling Lan,Ran Gu*

Main category: cs.LG

TL;DR: 该研究提出了一种名为CbLDM的深度学习模型，利用PDF（原子-原子距离分布）通过条件生成任务来反演纳米结构，旨在提高生成效率和预测精度。


<details>
  <summary>Details</summary>
Motivation: 为了理解纳米材料的结构与性质之间的关系，研究纳米结构的逆问题，特别是利用PDF（原子-原子距离分布）来恢复纳米结构。

Method: 提出了一种条件性潜在扩散模型（CbLDM），通过引入条件先验来估计条件后验分布（p(z|x)），以减少采样步骤并提高生成效率。此外，使用拉普拉斯矩阵代替距离矩阵来减小重建误差。

Result: 与现有模型相比，CbLDM在纳米结构逆问题上展现出显著更高的预测精度。

Conclusion: CbLDM能够有效解决纳米结构逆问题，并有潜力应用于其他连续条件生成任务。

Abstract: Nowadays, the nanostructure inverse problem is an attractive problem that
helps researchers to understand the relationship between the properties and the
structure of nanomaterials. This article focuses on the problem of using PDF to
recover the nanostructure, which this article views as a conditional generation
problem. This article propose a deep learning model CbLDM, Condition-based
Latent Diffusion Model. Based on the original latent diffusion model, the
sampling steps of the diffusion model are reduced and the sample generation
efficiency is improved by using the conditional prior to estimate conditional
posterior distribution, which is the approximated distribution of p(z|x). In
addition, this article uses the Laplacian matrix instead of the distance matrix
to recover the nanostructure, which can reduce the reconstruction error.
Finally, this article compares CbLDM with existing models which were used to
solve the nanostructure inverse problem, and find that CbLDM demonstrates
significantly higher prediction accuracy than these models, which reflects the
ability of CbLDM to solve the nanostructure inverse problem and the potential
to cope with other continuous conditional generation tasks.

</details>


### [969] [Advanced spectral clustering for heterogeneous data in credit risk monitoring systems](https://arxiv.org/abs/2509.00546)
*Lu Han,Mengyan Li,Jiping Qiang,Zhi Su*

Main category: cs.LG

TL;DR: ASC通过结合数值和文本数据，优化权重参数和选择特征向量，提高了信用监控中处理异构数据的能力，并在小微企业数据集上取得了更好的聚类效果，同时发现了具有较低违约风险的特定企业集群。


<details>
  <summary>Details</summary>
Motivation: 现有的信用监控方法难以处理包含数值和文本的异构数据。本研究旨在提出一种能够有效整合这两种数据类型并提高聚类效果的方法。

Method: 提出高级谱聚类（ASC）方法，该方法通过优化的权重参数整合财务和文本相似性，并采用新颖的特征值-轮廓优化方法选择特征向量。

Result: ASC在包含1428家小微企业的数据集上，相比单一数据类型基线方法，轮廓系数提高了18%。研究还发现，51%的低风险企业文本记录中包含“社会招聘”一词。ASC在多种聚类算法（如k-means、k-medians、k-medoids）上表现稳健，且{\Delta}Intra/Inter < 0.13 and {\Delta}Silhouette Coefficient < 0.02。

Conclusion: ASC方法成功地将谱聚类理论应用于异构数据，能够识别出有意义的聚类，例如招聘相关的中小企业，其违约风险降低了30%，从而支持了更有针对性和有效的信用干预。

Abstract: Heterogeneous data, which encompass both numerical financial variables and
textual records, present substantial challenges for credit monitoring. To
address this issue, we propose Advanced Spectral Clustering (ASC), a method
that integrates financial and textual similarities through an optimized weight
parameter and selects eigenvectors using a novel eigenvalue-silhouette
optimization approach. Evaluated on a dataset comprising 1,428 small and
medium-sized enterprises (SMEs), ASC achieves a Silhouette score that is 18%
higher than that of a single-type data baseline method. Furthermore, the
resulting clusters offer actionable insights; for instance, 51% of low-risk
firms are found to include the term 'social recruitment' in their textual
records. The robustness of ASC is confirmed across multiple clustering
algorithms, including k-means, k-medians, and k-medoids, with
{\Delta}Intra/Inter < 0.13 and {\Delta}Silhouette Coefficient < 0.02. By
bridging spectral clustering theory with heterogeneous data applications, ASC
enables the identification of meaningful clusters, such as recruitment-focused
SMEs exhibiting a 30% lower default risk, thereby supporting more targeted and
effective credit interventions.

</details>


### [970] [Integrated Multivariate Segmentation Tree for the Analysis of Heterogeneous Credit Data in Small and Medium-Sized Enterprises](https://arxiv.org/abs/2509.00550)
*Lu Han,Xiuying Wang*

Main category: cs.LG

TL;DR: IMST通过集成财务数据和文本数据，在信用评估方面优于传统模型。


<details>
  <summary>Details</summary>
Motivation: 传统决策树在处理高维数据和文本信息方面存在局限性，IMST旨在通过整合财务数据和文本信息来改进中小企业信用评估。

Method: IMST采用矩阵分解转换文本数据，Lasso回归选择财务特征，并基于Gini指数或熵构建多变量分割树，同时使用最弱链接剪枝控制模型复杂度。

Result: IMST在1428个中国中小企业数据集上实现了88.9%的准确率，优于基线决策树（87.4%）、逻辑回归和SVM。

Conclusion: IMST在信用评估方面具有更高的准确性、可解释性和计算效率，能够提升风险检测能力。

Abstract: Traditional decision tree models, which rely exclusively on numerical
variables, often encounter difficulties in handling high-dimensional data and
fail to effectively incorporate textual information. To address these
limitations, we propose the Integrated Multivariate Segmentation Tree (IMST), a
comprehensive framework designed to enhance credit evaluation for small and
medium-sized enterprises (SMEs) by integrating financial data with textual
sources. The methodology comprises three core stages: (1) transforming textual
data into numerical matrices through matrix factorization; (2) selecting
salient financial features using Lasso regression; and (3) constructing a
multivariate segmentation tree based on the Gini index or Entropy, with
weakest-link pruning applied to regulate model complexity. Experimental results
derived from a dataset of 1,428 Chinese SMEs demonstrate that IMST achieves an
accuracy of 88.9%, surpassing baseline decision trees (87.4%) as well as
conventional models such as logistic regression and support vector machines
(SVM). Furthermore, the proposed model exhibits superior interpretability and
computational efficiency, featuring a more streamlined architecture and
enhanced risk detection capabilities.

</details>


### [971] [Federated learning over physical channels: adaptive algorithms with near-optimal guarantees](https://arxiv.org/abs/2509.02538)
*Rui Zhang,Wenlong Mou*

Main category: cs.LG

TL;DR: 本文提出了一种新的自适应联邦学习SGD算法，通过物理信道传输信息以降低通信成本，并考虑了信道噪声和硬件约束，理论上保证了算法的收敛性，并在深度学习模型上进行了仿真验证。


<details>
  <summary>Details</summary>
Motivation: 为了降低联邦学习中的通信成本，提出一种通过物理信道传输信息的新方法。

Method: 提出一类新的自适应联邦学习SGD算法，该算法可用于物理信道，并考虑了信道噪声和硬件约束。

Result: 所提算法具有理论收敛保证，收敛速率可适应梯度噪声水平，并通过深度学习模型的仿真研究证明了其实际有效性。

Conclusion: 所提出的自适应联邦学习SGD算法通过物理信道传输信息，有效降低了通信成本，并保证了算法的收敛性。

Abstract: In federated learning, communication cost can be significantly reduced by
transmitting the information over the air through physical channels. In this
paper, we propose a new class of adaptive federated stochastic gradient descent
(SGD) algorithms that can be implemented over physical channels, taking into
account both channel noise and hardware constraints. We establish theoretical
guarantees for the proposed algorithms, demonstrating convergence rates that
are adaptive to the stochastic gradient noise level. We also demonstrate the
practical effectiveness of our algorithms through simulation studies with deep
learning models.

</details>


### [972] [An Efficient GNNs-to-KANs Distillation via Self-Attention Dynamic Sampling with Potential for Consumer Electronics Edge Deployment](https://arxiv.org/abs/2509.00560)
*Can Cui,Zilong Fu,Penghe Huang,Yuanyuan Li,Wu Deng,Dongyan Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Knowledge distillation (KD) is crucial for deploying deep learning models in
resource-constrained edge environments, particularly within the consumer
electronics sector, including smart home devices, wearable technology, and
mobile terminals. These applications place higher demands on model compression
and inference speed, necessitating the transfer of knowledge from Graph Neural
Networks (GNNs) to more efficient Multi-Layer Perceptron (MLP) models. However,
due to their fixed activation functions and fully connected architecture, MLPs
face challenges in rapidly capturing the complex neighborhood dependencies
learned by GNNs, thereby limiting their performance in edge environments. To
address these limitations, this paper introduces an innovative from GNNs to
Kolmogorov-Arnold Networks (KANs) knowledge distillation framework-Self
Attention Dynamic Sampling Distillation (SA-DSD). This study improved Fourier
KAN (FR-KAN) and replaced MLP with the improved FR-KAN+ as the student model.
Through the incorporation of learnable frequency bases and phase-shift
mechanisms, along with algorithmic optimization, FR-KAN significantly improves
its nonlinear fitting capability while effectively reducing computational
complexity. Building on this, a margin-level sampling probability matrix, based
on teacher-student prediction consistency, is constructed, and an adaptive
weighted loss mechanism is designed to mitigate performance degradation in the
student model due to the lack of explicit neighborhood aggregation. Extensive
experiments conducted on six real-world datasets demonstrate that SA-DSD
achieves performance improvements of 3.05%-3.62% over three GNN teacher models
and 15.61% over the FR-KAN+ model. Moreover, when compared with key benchmark
models, SA-DSD achieves a 16.96x reduction in parameter count and a 55.75%
decrease in inference time.

</details>


### [973] [TranCIT: Transient Causal Interaction Toolbox](https://arxiv.org/abs/2509.00602)
*Salar Nouri,Kaidi Shao,Shervin Safavi*

Main category: cs.LG

TL;DR: 该论文介绍了一个名为TranCIT的开源Python包，用于量化非平稳神经信号中的瞬态因果相互作用。


<details>
  <summary>Details</summary>
Motivation: 量化非平稳神经信号中的瞬态因果相互作用是神经科学中的一个基本挑战，传统方法难以处理短暂的神经事件，且先进技术缺乏易于使用的Python实现。

Method: TranCIT实现了一个全面的分析流程，包括格兰杰因果关系、传递熵以及基于结构因果模型的动态因果强度（DCS）和相对动态因果强度（rDCS），用于检测事件驱动的因果效应。

Result: 该工具包成功捕获了传统方法失败的高同步状态下的因果关系，并在真实数据中识别出海马体CA3到CA1在快波锯齿事件中的瞬态信息流。

Conclusion: TranCIT为研究控制复杂系统的瞬态因果动力学提供了一个用户友好且经过验证的解决方案。

Abstract: Quantifying transient causal interactions from non-stationary neural signals
is a fundamental challenge in neuroscience. Traditional methods are often
inadequate for brief neural events, and advanced, event-specific techniques
have lacked accessible implementations within the Python ecosystem. Here, we
introduce trancit (Transient Causal Interaction Toolbox), an open-source Python
package designed to bridge this gap. TranCIT implements a comprehensive
analysis pipeline, including Granger Causality, Transfer Entropy, and the more
robust Structural Causal Model-based Dynamic Causal Strength (DCS) and relative
Dynamic Causal Strength (rDCS) for accurately detecting event-driven causal
effects. We demonstrate TranCIT's utility by successfully capturing causality
in high-synchrony regimes where traditional methods fail and by identifying the
known transient information flow from hippocampal CA3 to CA1 during sharp-wave
ripple events in real-world data. The package offers a user-friendly, validated
solution for investigating the transient causal dynamics that govern complex
systems.

</details>


### [974] [RoFt-Mol: Benchmarking Robust Fine-Tuning with Molecular Graph Foundation Models](https://arxiv.org/abs/2509.00614)
*Shikun Liu,Deyu Zou,Nima Shoghi,Victor Fung,Kai Liu,Pan Li*

Main category: cs.LG

TL;DR: 分子图基础模型（MGFM）的微调对于下游任务至关重要，但面临数据稀疏和模型过拟合的挑战。本文将八种微调方法归类为基于权重、基于表示和部分微调，并在不同标签设置下进行基准测试，以改进这些技术。研究结果为开发ROFT-MOL提供了依据，该方法结合了后验权重插值和权重集成微调的优点，在回归和分类任务上均表现出更好的性能和易用性。


<details>
  <summary>Details</summary>
Motivation: 在基础模型时代，针对特定下游任务微调预训练模型已成为关键，这需要强大的微调方法来应对模型过拟合和稀疏标签等挑战。分子图基础模型（MGFM）面临独特的挑战，如较小的预训练数据集和更严重的数据稀缺性，这需要增强模型泛化能力，并兼容回归和分类等多样化目标。

Method: 将八种微调方法归类为三种机制：基于权重、基于表示和部分微调。在监督和自监督预训练模型上，对下游回归和分类任务在不同标签设置下进行基准测试。

Result: 通过广泛的评估，为改进的鲁棒微调方法ROFT-MOL的设计提供了宝贵的见解。ROFT-MOL结合了后验权重插值和更复杂的权重集成微调方法的优点，在两种任务类型上均实现了改进的性能，同时保持了后验权重插值固有的易用性。

Conclusion: ROFT-MOL 作为一种新的鲁棒微调方法，通过结合不同微调策略的优势，在分子图任务上实现了性能和易用性的提升。

Abstract: In the era of foundation models, fine-tuning pre-trained models for specific
downstream tasks has become crucial. This drives the need for robust
fine-tuning methods to address challenges such as model overfitting and sparse
labeling. Molecular graph foundation models (MGFMs) face unique difficulties
that complicate fine-tuning. These models are limited by smaller pre-training
datasets and more severe data scarcity for downstream tasks, both of which
require enhanced model generalization. Moreover, MGFMs must accommodate diverse
objectives, including both regression and classification tasks. To better
understand and improve fine-tuning techniques under these conditions, we
classify eight fine-tuning methods into three mechanisms: weight-based,
representation-based, and partial fine-tuning. We benchmark these methods on
downstream regression and classification tasks across supervised and
self-supervised pre-trained models in diverse labeling settings. This extensive
evaluation provides valuable insights and informs the design of a refined
robust fine-tuning method, ROFT-MOL. This approach combines the strengths of
simple post-hoc weight interpolation with more complex weight ensemble
fine-tuning methods, delivering improved performance across both task types
while maintaining the ease of use inherent in post-hoc weight interpolation.

</details>


### [975] [TimeCopilot](https://arxiv.org/abs/2509.00616)
*Azul Garza,Reneé Rosillo*

Main category: cs.LG

TL;DR: TimeCopilot是一个开源的时间序列预测框架，结合了多种时间序列基础模型（TSFMs）和大型语言模型（LLM），通过统一的API实现了自动化预测流程，包括特征分析、模型选择、交叉验证和预测生成，并提供自然语言解释和未来查询支持。该框架具有LLM无关性、兼容多种模型和支持集成不同预测家族的特点。在GIFT-Eval基准测试中，TimeCopilot以低成本实现了最先进的概率预测性能，为可复现、可解释和可访问的agentic预测系统奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为时间序列预测开发一个集成了多种TSFMs和LLMs的开源agentic框架，实现自动化预测流程并提供可解释性。

Method: 结合多种时间序列基础模型（TSFMs）和大型语言模型（LLM），通过统一API自动化特征分析、模型选择、交叉验证和预测生成，支持LLM无关性和模型集成。

Result: 在GIFT-Eval基准测试中，TimeCopilot实现了最先进的概率预测性能，且成本较低。

Conclusion: TimeCopilot提供了一个实际可行的基础，用于构建可复现、可解释和可访问的agentic时间序列预测系统。

Abstract: We introduce TimeCopilot, the first open-source agentic framework for
forecasting that combines multiple Time Series Foundation Models (TSFMs) with
Large Language Models (LLMs) through a single unified API. TimeCopilot
automates the forecasting pipeline: feature analysis, model selection,
cross-validation, and forecast generation, while providing natural language
explanations and supporting direct queries about the future. The framework is
LLM-agnostic, compatible with both commercial and open-source models, and
supports ensembles across diverse forecasting families. Results on the
large-scale GIFT-Eval benchmark show that TimeCopilot achieves state-of-the-art
probabilistic forecasting performance at low cost. Our framework provides a
practical foundation for reproducible, explainable, and accessible agentic
forecasting systems.

</details>


### [976] [Forecasting the Ionosphere from Sparse GNSS Data with Temporal-Fusion Transformers](https://arxiv.org/abs/2509.00631)
*Giacomo Acciarini,Simone Mestici,Halil Kelebek,Linnea Wolniewicz,Michael Vergalla,Madhulika Guhathakurta,Umaa Rebbapragada,Bala Poduval,Atılım Güneş Baydin,Frank Soboczenski*

Main category: cs.LG

TL;DR: 一个基于时间融合Transformer（TFT）的机器学习框架，用于预测电离层总电子含量（TEC），实现了长达24小时的准确预测，并提高了模型的可解释性。


<details>
  <summary>Details</summary>
Motivation: 电离层对GNSS、卫星通信和LEO运行有重要影响，但其精确预测具有挑战性，因为太阳、地磁和热层驱动因素之间存在非线性耦合。准确预测TEC对于这些应用至关重要。

Method: 提出一个利用时间融合Transformer（TFT）预测稀疏电离层数据的机器学习框架。该框架整合了太阳辐照度、地磁指数和GNSS推算的垂直TEC等异构输入源，并采用了预处理和时间对齐策略。

Result: 该模型能够提前24小时进行稳健预测，均方根误差低至3.33 TECU。实验结果表明，太阳EUV辐照度提供了最强的预测信号。此外，该框架还通过基于注意力的分析提供了可解释性。

Conclusion: 所提出的TFT模型能够准确预测电离层TEC，并且能够提供可解释性，有助于实际应用和科学发现。该框架的开源实现ionopy促进了可重复性和社区发展。

Abstract: The ionosphere critically influences Global Navigation Satellite Systems
(GNSS), satellite communications, and Low Earth Orbit (LEO) operations, yet
accurate prediction of its variability remains challenging due to nonlinear
couplings between solar, geomagnetic, and thermospheric drivers. Total Electron
Content (TEC), a key ionospheric parameter, is derived from GNSS observations,
but its reliable forecasting is limited by the sparse nature of global
measurements and the limited accuracy of empirical models, especially during
strong space weather conditions. In this work, we present a machine learning
framework for ionospheric TEC forecasting that leverages Temporal Fusion
Transformers (TFT) to predict sparse ionosphere data. Our approach accommodates
heterogeneous input sources, including solar irradiance, geomagnetic indices,
and GNSS-derived vertical TEC, and applies preprocessing and temporal alignment
strategies. Experiments spanning 2010-2025 demonstrate that the model achieves
robust predictions up to 24 hours ahead, with root mean square errors as low as
3.33 TECU. Results highlight that solar EUV irradiance provides the strongest
predictive signals. Beyond forecasting accuracy, the framework offers
interpretability through attention-based analysis, supporting both operational
applications and scientific discovery. To encourage reproducibility and
community-driven development, we release the full implementation as the
open-source toolkit \texttt{ionopy}.

</details>


### [977] [Disentangling Slow and Fast Temporal Dynamics in Degradation Inference with Hierarchical Differential Models](https://arxiv.org/abs/2509.00639)
*Mengjie Zhao,Olga Fink*

Main category: cs.LG

TL;DR: 该论文提出了一种名为分层受控微分方程（H-CDE）的新框架，用于从传感器数据中推断系统退化情况，解决了现有方法中操作变化和退化信号纠缠不清的问题。


<details>
  <summary>Details</summary>
Motivation: 需要从传感器数据中可靠地推断系统退化情况，以实现准确的健康评估和决策，但现有方法难以从操作变化中分离出细微的退化信号。

Method: 提出了一种新的分层受控微分方程（H-CDE）框架，该框架包含一个慢速（退化）和一个快速（操作）的CDE组件，并通过多尺度时间积分方案、可学习路径变换和强制单调性的激活函数来解决数值刚度和退化解耦的难题。

Result: H-CDE框架在动态响应和稳态系统上进行了全面评估，结果表明其能有效分离退化和操作动态，并且在准确性、鲁棒性和可解释性方面优于基于残差的方法。

Conclusion: H-CDE框架能够有效地区分系统退化和操作动态，为系统健康监测和预测提供了更准确、更可靠的推断方法。

Abstract: Reliable inference of system degradation from sensor data is fundamental to
condition monitoring and prognostics in engineered systems. Since degradation
is rarely observable and measurable, it must be inferred to enable accurate
health assessment and decision-making. This is particularly challenging because
operational variations dominate system behavior, while degradation introduces
only subtle, long-term changes. Consequently, sensor data mainly reflect
short-term operational variability, making it difficult to disentangle the
underlying degradation process. Residual-based methods are widely employed, but
the residuals remain entangled with operational history, often resulting in
noisy and unreliable degradation estimation, particularly in systems with
dynamic responses. Neural Ordinary Equations (NODEs) offer a promising
framework for inferring latent dynamics, but the time-scale separation in
slow-fast systems introduces numerical stiffness and complicates training,
while degradation disentanglement remains difficult. To address these
limitations, we propose a novel Hierarchical Controlled Differential Equation
(H-CDE) framework that incorporates a slow (degradation) and a fast (operation)
CDE component in a unified architecture. It introduces three key innovations: a
multi-scale time integration scheme to mitigate numerical stiffness; a
learnable path transformation that extracts latent degradation drivers to
control degradation evolution; and a novel activation function that enforces
monotonicity on inferred degradation as a regularizer for disentanglement.
Through comprehensive evaluations on both dynamic response (e.g., bridges) and
steady state (e.g., aero-engine) systems, we demonstrate that H-CDE effectively
disentangles degradation from operational dynamics and outperforms
residual-based baselines, yielding more accurate, robust, and interpretable
inference.

</details>


### [978] [AMCR: A Framework for Assessing and Mitigating Copyright Risks in Generative Models](https://arxiv.org/abs/2509.00641)
*Zhipeng Yin,Zichong Wang,Avash Palikhe,Zhen Liu,Jun Liu,Wenbin Zhang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为AMCR的框架，用于解决文本到图像生成模型中的版权风险问题。AMCR通过重构提示、检测部分侵权和自适应缓解风险来降低侵权几率，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 大型文本到图像生成模型在视觉内容创作方面取得了显著进展，但它们依赖大规模数据，并可能无意中复制受版权保护的元素，带来法律和伦理挑战。现有基于提示的方法（过滤或重写用户输入）在处理微妙的侵权情况时效果不佳。

Method: AMCR框架包括三个主要部分：1）系统性地将有风险的提示重构为安全的形式；2）通过基于注意力机制的相似性分析来检测部分侵权；3）在生成过程中自适应地缓解风险，以减少版权侵权，同时不影响图像质量。

Result: 实验证明AMCR能有效揭示和缓解潜在的版权风险，为生成模型的安全部署提供了实用的见解和基准。

Conclusion: AMCR框架通过结合提示重构、侵权检测和自适应风险缓解，能够有效地解决文本到图像生成模型中的版权风险问题，并在不牺牲图像质量的情况下降低侵权的可能性。

Abstract: Generative models have achieved impressive results in text to image tasks,
significantly advancing visual content creation. However, this progress comes
at a cost, as such models rely heavily on large-scale training data and may
unintentionally replicate copyrighted elements, creating serious legal and
ethical challenges for real-world deployment. To address these concerns,
researchers have proposed various strategies to mitigate copyright risks, most
of which are prompt based methods that filter or rewrite user inputs to prevent
explicit infringement. While effective in handling obvious cases, these
approaches often fall short in more subtle situations, where seemingly benign
prompts can still lead to infringing outputs. To address these limitations,
this paper introduces Assessing and Mitigating Copyright Risks (AMCR), a
comprehensive framework which i) builds upon prompt-based strategies by
systematically restructuring risky prompts into safe and non-sensitive forms,
ii) detects partial infringements through attention-based similarity analysis,
and iii) adaptively mitigates risks during generation to reduce copyright
violations without compromising image quality. Extensive experiments validate
the effectiveness of AMCR in revealing and mitigating latent copyright risks,
offering practical insights and benchmarks for the safer deployment of
generative models.

</details>


### [979] [Context-Action Embedding Learning for Off-Policy Evaluation in Contextual Bandits](https://arxiv.org/abs/2509.00648)
*Kushagra Chandak,Vincent Liu,Haanvid Lee*

Main category: cs.LG

TL;DR: 该研究提出了一种名为CAEL-MIPS的新型上下文老虎机离线策略评估方法，通过学习上下文-动作嵌入来最小化MIPS估计器的均方误差（MSE），并在实验中证明其优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统的逆倾向得分（IPS）方法在动作空间大或部分上下文-动作空间探索不足时，方差会很高。虽然边缘化IPS（MIPS）通过利用动作嵌入缓解了这个问题，但现有的嵌入并未最小化估计器的均方误差（MSE），也没有考虑上下文信息。因此，需要一种能够考虑上下文信息并最小化MIPS估计器MSE的方法。

Method: 提出了一种名为CAEL-MIPS（Context-Action Embedding Learning for MIPS）的方法，该方法从离线数据中学习上下文-动作嵌入，旨在最小化MIPS估计器的均方误差（MSE）。研究基于MIPS的偏差和方差的理论分析，提出了一个用于CAEL-MIPS的MSE最小化目标。

Result: 在合成数据集和真实世界数据集的实证研究中，所提出的CAEL-MIPS估计器在MSE方面优于现有的基线方法。

Conclusion: CAEL-MIPS通过学习上下文-动作嵌入来最小化MIPS估计器的MSE，克服了现有方法的局限性，并在评估离线策略的性能方面取得了更好的效果。

Abstract: We consider off-policy evaluation (OPE) in contextual bandits with finite
action space. Inverse Propensity Score (IPS) weighting is a widely used method
for OPE due to its unbiased, but it suffers from significant variance when the
action space is large or when some parts of the context-action space are
underexplored. Recently introduced Marginalized IPS (MIPS) estimators mitigate
this issue by leveraging action embeddings. However, these embeddings do not
minimize the mean squared error (MSE) of the estimators and do not consider
context information. To address these limitations, we introduce Context-Action
Embedding Learning for MIPS, or CAEL-MIPS, which learns context-action
embeddings from offline data to minimize the MSE of the MIPS estimator.
Building on the theoretical analysis of bias and variance of MIPS, we present
an MSE-minimizing objective for CAEL-MIPS. In the empirical studies on a
synthetic dataset and a real-world dataset, we demonstrate that our estimator
outperforms baselines in terms of MSE.

</details>


### [980] [Missing Data Imputation using Neural Cellular Automata](https://arxiv.org/abs/2509.00651)
*Tin Luu,Binh Nguyen,Man Ngo*

Main category: cs.LG

TL;DR: 通过引入受神经元自动机（NCA）启发的模型来解决表格数据中的缺失值估算问题。


<details>
  <summary>Details</summary>
Motivation: 在处理表格数据时，缺失值是一个普遍存在且棘手的问题。尽管已有多种方法用于处理缺失值，但很少有研究关注神经元自动机（NCA）在缺失值估算方面的应用。

Method: 提出了一种新颖的、受 NCA 启发的缺失值估算方法。通过对 NCA 进行适当的调整，使其能够有效处理缺失数据。

Result: 实验证明，该 NCA 模型在估算误差和估算后性能方面优于现有的最先进方法。

Conclusion: 基于 NCA 的模型经过适当调整后，能够有效地解决缺失值估算问题，并且在实验中表现出优于现有方法的性能。

Abstract: When working with tabular data, missingness is always one of the most painful
problems. Throughout many years, researchers have continuously explored better
and better ways to impute missing data. Recently, with the rapid development
evolution in machine learning and deep learning, there is a new trend of
leveraging generative models to solve the imputation task. While the imputing
version of famous models such as Variational Autoencoders or Generative
Adversarial Networks were investigated, prior work has overlooked Neural
Cellular Automata (NCA), a powerful computational model. In this paper, we
propose a novel imputation method that is inspired by NCA. We show that, with
some appropriate adaptations, an NCA-based model is able to address the missing
data imputation problem. We also provide several experiments to evidence that
our model outperforms state-of-the-art methods in terms of imputation error and
post-imputation performance.

</details>


### [981] [IndiaWeatherBench: A Dataset and Benchmark for Data-Driven Regional Weather Forecasting over India](https://arxiv.org/abs/2509.00653)
*Tung Nguyen,Harkanwar Singh,Nilay Naharas,Lucas Bandarkar,Aditya Grover*

Main category: cs.LG

TL;DR: 该论文提出了IndiaWeatherBench，一个用于印度次大陆的区域天气预报基准，包括数据集、评估指标和模型实现，以促进可复现的研究。


<details>
  <summary>Details</summary>
Motivation: 区域天气预报对气候适应、灾害减缓和可持续发展至关重要，但相比全球预报，该领域的研究尚不充分，且现有工作缺乏统一的比较标准。

Method: 介绍了IndiaWeatherBench基准，该基准包含一个高分辨率的区域再分析数据集，以及一套用于模型训练和评估的确定性和概率性指标。论文还实现了包括UNets、Transformers和图基网络在内的多种模型，并评估了不同的边界条件策略和训练目标。

Result: 通过在IndiaWeatherBench上实现和评估多种模型，为区域天气预报研究建立了强有力的基线。

Conclusion: IndiaWeatherBench的发布旨在为区域天气预报领域的研究提供一个统一的平台，促进该领域的可持续发展和未来研究。

Abstract: Regional weather forecasting is a critical problem for localized climate
adaptation, disaster mitigation, and sustainable development. While machine
learning has shown impressive progress in global weather forecasting, regional
forecasting remains comparatively underexplored. Existing efforts often use
different datasets and experimental setups, limiting fair comparison and
reproducibility. We introduce IndiaWeatherBench, a comprehensive benchmark for
data-driven regional weather forecasting focused on the Indian subcontinent.
IndiaWeatherBench provides a curated dataset built from high-resolution
regional reanalysis products, along with a suite of deterministic and
probabilistic metrics to facilitate consistent training and evaluation. To
establish strong baselines, we implement and evaluate a range of models across
diverse architectures, including UNets, Transformers, and Graph-based networks,
as well as different boundary conditioning strategies and training objectives.
While focused on India, IndiaWeatherBench is easily extensible to other
geographic regions. We open-source all raw and preprocessed datasets, model
implementations, and evaluation pipelines to promote accessibility and future
development. We hope IndiaWeatherBench will serve as a foundation for advancing
regional weather forecasting research. Code is available at
https://github.com/tung-nd/IndiaWeatherBench.

</details>


### [982] [Semi-on-Demand Transit Feeders with Shared Autonomous Vehicles and Reinforcement-Learning-Based Zonal Dispatching Control](https://arxiv.org/abs/2509.01883)
*Max T. M. Ng,Roman Engelhardt,Florian Dandl,Hani S. Mahmassani,Klaus Bogenberger*

Main category: cs.LG

TL;DR: 本文提出了一种结合固定路线和响应式交通的半按需公交接驳服务，使用共享自动驾驶汽车（SAV）和基于强化学习（RL）的区域调度控制，以提高低密度区域的可达性。


<details>
  <summary>Details</summary>
Motivation: 提高低密度区域的可达性，结合固定路线公交的成本效益和响应式交通的适应性。

Method: 开发了一种基于深度强化学习（DRL）的模型，使用Proximal Policy Optimization（PPO）算法，动态分配车辆到细分的灵活路线区域，以响应实时需求波动和运营情况。通过在慕尼黑真实公交路线上进行基于代理的仿真来演示该方法。

Result: 与传统的固定路线服务相比，经过有效训练的RL模型能够使半按需服务多服务16%的乘客，而总成本仅增加13%。RL控制带来的效率提升能够多服务2.4%的乘客，成本增加1.4%。

Conclusion: 该研究展示了将SAV接驳和机器学习技术整合到公共交通中的潜力，并为解决多模式交通系统中的“第一英里/最后一英里”问题奠定了基础。

Abstract: This paper develops a semi-on-demand transit feeder service using shared
autonomous vehicles (SAVs) and zonal dispatching control based on reinforcement
learning (RL). This service combines the cost-effectiveness of fixed-route
transit with the adaptability of demand-responsive transport to improve
accessibility in lower-density areas. Departing from the terminus, SAVs first
make scheduled fixed stops, then offer on-demand pick-ups and drop-offs in a
pre-determined flexible-route area. Our deep RL model dynamically assigns
vehicles to subdivided flexible-route zones in response to real-time demand
fluctuations and operations, using a policy gradient algorithm - Proximal
Policy Optimization. The methodology is demonstrated through agent-based
simulations on a real-world bus route in Munich, Germany. Results show that
after efficient training of the RL model, the semi-on-demand service with
dynamic zonal control serves 16% more passengers at 13% higher generalized
costs on average compared to traditional fixed-route service. The efficiency
gain brought by RL control brings 2.4% more passengers at 1.4% higher costs.
This study not only showcases the potential of integrating SAV feeders and
machine learning techniques into public transit, but also sets the groundwork
for further innovations in addressing first-mile-last-mile problems in
multimodal transit systems.

</details>


### [983] [Valid Property-Enhanced Contrastive Learning for Targeted Optimization & Resampling for Novel Drug Design](https://arxiv.org/abs/2509.00684)
*Amartya Banerjee,Somnath Kar,Anirban Pal,Debabrata Maiti*

Main category: cs.LG

TL;DR: VECTOR+是一个结合了属性引导的表示学习和可控分子生成的框架，用于在数据稀疏的情况下，将生成模型引导到化学空间中具有药理学相关性的区域。


<details>
  <summary>Details</summary>
Motivation: 在低数据量的情况下，有效地将生成模型引导到化学空间中具有药理学相关性的区域是分子药物发现中的主要障碍。

Method: VECTOR+是一个框架，它将属性引导的表示学习与可控的分子生成相结合，可以应用于回归和分类任务，从而能够对功能化学空间进行可解释的、数据高效的探索。

Result: 在PD-L1抑制剂数据集（296个化合物及其IC50值）和受体激酶抑制剂数据集（2056个分子及其结合模式）上进行了评估。尽管训练数据有限，VECTOR+仍能生成新颖的、易于合成的候选分子。在PD-L1（PDB 5J89）上，生成的8374个分子中有100个超过了-15.0 kcal/mol的对接阈值，最佳分子得分为-17.6 kcal/mol，优于参考抑制剂（-15.4 kcal/mol）。最佳分子的分子动力学模拟（250 ns）证实了其结合稳定性（配体RMSD < 2.5埃）。VECTOR+推广到激酶抑制剂，产生的化合物具有比现有药物（如brigatinib和sorafenib）更强的对接分数。与JT-VAE和MolGPT在对接、新颖性、独特性和Tanimoto相似性方面的基准测试突显了该方法的优越性能。

Conclusion: VECTOR+是一种强大且可扩展的方法，用于在低数据量的情况下进行属性条件分子设计，将对比学习和生成模型相结合，以实现可重复的、AI加速的发现。

Abstract: Efficiently steering generative models toward pharmacologically relevant
regions of chemical space remains a major obstacle in molecular drug discovery
under low-data regimes. We present VECTOR+: Valid-property-Enhanced Contrastive
Learning for Targeted Optimization and Resampling, a framework that couples
property-guided representation learning with controllable molecule generation.
VECTOR+ applies to both regression and classification tasks and enables
interpretable, data-efficient exploration of functional chemical space. We
evaluate on two datasets: a curated PD-L1 inhibitor set (296 compounds with
experimental $IC_{50}$ values) and a receptor kinase inhibitor set (2,056
molecules by binding mode). Despite limited training data, VECTOR+ generates
novel, synthetically tractable candidates. Against PD-L1 (PDB 5J89), 100 of
8,374 generated molecules surpass a docking threshold of $-15.0$ kcal/mol, with
the best scoring $-17.6$ kcal/mol compared to the top reference inhibitor
($-15.4$ kcal/mol). The best-performing molecules retain the conserved biphenyl
pharmacophore while introducing novel motifs. Molecular dynamics (250 ns)
confirm binding stability (ligand RMSD < $2.5$ angstroms). VECTOR+ generalizes
to kinase inhibitors, producing compounds with stronger docking scores than
established drugs such as brigatinib and sorafenib. Benchmarking against JT-VAE
and MolGPT across docking, novelty, uniqueness, and Tanimoto similarity
highlights the superior performance of our method. These results position our
work as a robust, extensible approach for property-conditioned molecular design
in low-data settings, bridging contrastive learning and generative modeling for
reproducible, AI-accelerated discovery.

</details>


### [984] [DELTA: Variational Disentangled Learning for Privacy-Preserving Data Reprogramming](https://arxiv.org/abs/2509.00693)
*Arun Vignesh Malarkkan,Haoyue Bai,Anjali Kaushik,Yanjie Fu*

Main category: cs.LG

TL;DR: 该论文提出了一种名为DELTA的框架，用于解决在保护隐私的前提下进行数据特征工程的问题，旨在提高目标属性预测的准确性，同时降低敏感属性预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的数据通常包含敏感信息，并且受到严格的法规限制，需要进行可解释和透明的数据特征工程。现有的特征工程方法虽然能提升任务性能，但可能存在隐私泄露风险。

Method: 作者提出了一个名为DELTA的框架，该框架包含两个阶段：第一阶段利用策略引导的强化学习来发现具有下游任务效用的特征变换；第二阶段使用带效用-隐私解耦的潜在空间设计和对抗因果解耦正则化的变分LSTM序列到序列编码器-解码器来抑制生成过程中的隐私信号。

Result: 在八个数据集上的实验表明，DELTA在提高预测性能方面平均提升了约9.3%，同时隐私泄露降低了约35%。

Conclusion: DELTA是一个强大的、注重隐私的数据转换框架，能够在提高预测准确性的同时有效降低隐私泄露风险。

Abstract: In real-world applications, domain data often contains identifiable or
sensitive attributes, is subject to strict regulations (e.g., HIPAA, GDPR), and
requires explicit data feature engineering for interpretability and
transparency. Existing feature engineering primarily focuses on advancing
downstream task performance, often risking privacy leakage. We generalize this
learning task under such new requirements as Privacy-Preserving Data
Reprogramming (PPDR): given a dataset, transforming features to maximize target
attribute prediction accuracy while minimizing sensitive attribute prediction
accuracy. PPDR poses challenges for existing systems: 1) generating
high-utility feature transformations without being overwhelmed by a large
search space, and 2) disentangling and eliminating sensitive information from
utility-oriented features to reduce privacy inferability. To tackle these
challenges, we propose DELTA, a two-phase variational disentangled generative
learning framework. Phase I uses policy-guided reinforcement learning to
discover feature transformations with downstream task utility, without any
regard to privacy inferability. Phase II employs a variational LSTM seq2seq
encoder-decoder with a utility-privacy disentangled latent space design and
adversarial-causal disentanglement regularization to suppress privacy signals
during feature generation. Experiments on eight datasets show DELTA improves
predictive performance by ~9.3% and reduces privacy leakage by ~35%,
demonstrating robust, privacy-aware data transformation.

</details>


### [985] [Robust Spatiotemporal Forecasting Using Adaptive Deep-Unfolded Variational Mode Decomposition](https://arxiv.org/abs/2509.00703)
*Osama Ahmad,Lukas Wesemann,Fabian Waschkowski,Zubair Khalid*

Main category: cs.LG

TL;DR: Mode adaptive graph network (MAGN) improves spatiotemporal forecasting by making VMD trainable and adaptive, reducing computation time and prediction error.


<details>
  <summary>Details</summary>
Motivation: Accurate spatiotemporal forecasting is crucial but difficult due to volatility and spectral entanglement in GNNs. Existing decomposition methods are inefficient and require manual tuning.

Method: Proposes MAGN with an unfolded VMD (UVMD) module for faster decomposition and mode-specific learnable bandwidth constraints to adapt spatial heterogeneity and prevent spectral overlap.

Result: MAGN achieves a 250x speedup in decomposition on LargeST and an 85-95% reduction in prediction error compared to VMGCN, outperforming other state-of-the-art methods.

Conclusion: MAGN offers a computationally efficient and adaptive solution for spatiotemporal forecasting by integrating VMD as a trainable neural module.

Abstract: Accurate spatiotemporal forecasting is critical for numerous complex systems
but remains challenging due to complex volatility patterns and spectral
entanglement in conventional graph neural networks (GNNs). While
decomposition-integrated approaches like variational mode graph convolutional
network (VMGCN) improve accuracy through signal decomposition, they suffer from
computational inefficiency and manual hyperparameter tuning. To address these
limitations, we propose the mode adaptive graph network (MAGN) that transforms
iterative variational mode decomposition (VMD) into a trainable neural module.
Our key innovations include (1) an unfolded VMD (UVMD) module that replaces
iterative optimization with a fixed-depth network to reduce the decomposition
time (by 250x for the LargeST benchmark), and (2) mode-specific learnable
bandwidth constraints ({\alpha}k ) adapt spatial heterogeneity and eliminate
manual tuning while preventing spectral overlap. Evaluated on the LargeST
benchmark (6,902 sensors, 241M observations), MAGN achieves an 85-95% reduction
in the prediction error over VMGCN and outperforms state-of-the-art baselines.

</details>


### [986] [Why Pool When You Can Flow? Active Learning with GFlowNets](https://arxiv.org/abs/2509.00704)
*Renfei Zhang,Mohit Pandey,Artem Cherkasov,Martin Ester*

Main category: cs.LG

TL;DR: BALD-GFlowNet是一个生成式主动学习框架，利用GFlowNets直接采样对象，解决了虚拟筛选中的计算瓶颈，实现了可扩展性，性能与标准BALD相当，同时生成更多样化的分子。


<details>
  <summary>Details</summary>
Motivation: 虚拟筛选中的主动学习方法（如BALD）受限于大规模未标记数据集的计算成本，该成本在大规模化合物库中尤为突出。

Method: 提出了一种名为BALD-GFlowNet的生成式主动学习框架，利用GFlowNets直接根据BALD奖励进行采样，以替代基于池的传统方法，从而实现独立于未标记池大小的可扩展性。

Result: 在虚拟筛选实验中，BALD-GFlowNet实现了与标准BALD相当的性能，并生成了结构更多样化的分子。

Conclusion: BALD-GFlowNet为高效和可扩展的分子发现提供了一个有前途的方向，解决了现有主动学习方法在大规模数据集上面临的可扩展性问题。

Abstract: The scalability of pool-based active learning is limited by the computational
cost of evaluating large unlabeled datasets, a challenge that is particularly
acute in virtual screening for drug discovery. While active learning strategies
such as Bayesian Active Learning by Disagreement (BALD) prioritize informative
samples, it remains computationally intensive when scaled to libraries
containing billions samples. In this work, we introduce BALD-GFlowNet, a
generative active learning framework that circumvents this issue. Our method
leverages Generative Flow Networks (GFlowNets) to directly sample objects in
proportion to the BALD reward. By replacing traditional pool-based acquisition
with generative sampling, BALD-GFlowNet achieves scalability that is
independent of the size of the unlabeled pool. In our virtual screening
experiment, we show that BALD-GFlowNet achieves a performance comparable to
that of standard BALD baseline while generating more structurally diverse
molecules, offering a promising direction for efficient and scalable molecular
discovery.

</details>


### [987] [Task-Aware Adaptive Modulation: A Replay-Free and Resource-Efficient Approach For Continual Graph Learning](https://arxiv.org/abs/2509.00735)
*Jingtao Liu,Xinming Zhang*

Main category: cs.LG

TL;DR: TAAM是一种无需重放、资源高效的持续图学习方法，通过动态调节冻结骨干网络的计算流程来解决稳定-塑形困境，其核心是任务感知的神经突触调节器（NSM），通过原型引导策略进行训练和推理，在多个基准数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有持续图学习方法在解决稳定性-塑形困境和资源消耗方面存在问题，TAAM旨在通过动态调节冻结骨干网络的计算流程来克服这些挑战。

Method: TAAM提出了一种无需重放、资源高效的方法，其核心是神经突触调节器（NSM），通过原型引导策略来训练和推理，并将NSM插入冻结的GNN骨干网络中，对内部计算流程进行细粒度的节点注意力调制。

Result: TAAM在六个GCIL基准数据集上进行了广泛的实验，结果显示其全面优于最先进的方法。

Conclusion: TAAM通过动态调节计算流程和使用原型引导策略的NSM，为解决持续图学习中的稳定性-塑形困境提供了一种新的、资源高效的途径。

Abstract: Continual Graph Learning(CGL)focuses on acquiring new knowledge while
retaining previously learned information, essential for real-world graph
applications. Current methods grapple with two main issues:1) The
Stability-Plasticity Dilemma: Replay-based methods often create an imbalance
between the Dilemma, while incurring significant storage costs.2) The
Resource-Heavy Pre-training: Leading replay-free methods critically depend on
extensively pre-trained backbones, this reliance imposes a substantial resource
burden.In this paper, we argue that the key to overcoming these challenges lies
not in replaying data or fine-tuning the entire network, but in dynamically
modulating the internal computational flow of a frozen backbone. We posit that
lightweight, task-specific modules can effectively steer a GNN's reasoning
process. Motivated by this insight, we propose Task-Aware Adaptive
Modulation(TAAM), a replay-free, resource-efficient approach that charts a new
path for navigating the stability-plasticity dilemma. TAAM's core is its Neural
Synapse Modulators(NSM), which are trained and then frozen for each task to
store expert knowledge. A pivotal prototype-guided strategy governs these
modulators: 1) For training, it initializes a new NSM by deep-copying from a
similar past modulator to boost knowledge transfer. 2) For inference, it
selects the most relevant frozen NSM for each task. These NSMs insert into a
frozen GNN backbone to perform fine-grained, node-attentive modulation of its
internal flow-different from the static perturbations of prior methods.
Extensive experiments show that TAAM comprehensively outperforms
state-of-the-art methods across six GCIL benchmark datasets. The code will be
released upon acceptance of the paper.

</details>


### [988] [Attribute Fusion-based Classifier on Framework of Belief Structure](https://arxiv.org/abs/2509.00754)
*Qiying Hu,Yingying Liang,Qianli Zhou,Witold Pedrycz*

Main category: cs.LG

TL;DR: 本研究提出了一种增强的属性融合分类器和改进的证据K近邻分类器，以解决传统DST分类器在处理不确定性时的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统基于DST的分类器在处理复杂现实场景时，由于会员函数建模过于简单以及对基本概率赋值（BPA）的信念结构利用不足，效果受限。

Method: 1. 采用选择性建模策略，结合高斯模型和高斯混合模型（GMMs）进行会员函数构建，并通过交叉验证和定制的评估指标进行模型选择。 2. 提出一种新方法，将可能性分布转换为BPA，结合了从归一化可能性分布派生的简单BPA，从而实现更丰富、更灵活的不确定信息表示。 3. 将基于信念结构的BPA生成方法应用于证据K近邻分类器。

Result: 所提出的属性融合分类器和增强的证据K近邻分类器在基准数据集上的实验结果表明，性能优于现有的证据分类器和传统的机器学习分类器，平均准确率提高了4.84%，同时保持低方差，证明了其优越的有效性和鲁棒性。

Conclusion: 本研究提出的增强型DST分类器在处理不确定性方面比现有方法更有效、更鲁棒。

Abstract: Dempster-Shafer Theory (DST) provides a powerful framework for modeling
uncertainty and has been widely applied to multi-attribute classification
tasks. However, traditional DST-based attribute fusion-based classifiers suffer
from oversimplified membership function modeling and limited exploitation of
the belief structure brought by basic probability assignment (BPA), reducing
their effectiveness in complex real-world scenarios. This paper presents an
enhanced attribute fusion-based classifier that addresses these limitations
through two key innovations. First, we adopt a selective modeling strategy that
utilizes both single Gaussian and Gaussian Mixture Models (GMMs) for membership
function construction, with model selection guided by cross-validation and a
tailored evaluation metric. Second, we introduce a novel method to transform
the possibility distribution into a BPA by combining simple BPAs derived from
normalized possibility distributions, enabling a much richer and more flexible
representation of uncertain information. Furthermore, we apply the belief
structure-based BPA generation method to the evidential K-Nearest Neighbors
classifier, enhancing its ability to incorporate uncertainty information into
decision-making. Comprehensive experiments on benchmark datasets are conducted
to evaluate the performance of the proposed attribute fusion-based classifier
and the enhanced evidential K-Nearest Neighbors classifier in comparison with
both evidential classifiers and conventional machine learning classifiers. The
results demonstrate that our proposed classifier outperforms the best existing
evidential classifier, achieving an average accuracy improvement of 4.84%,
while maintaining low variance, thus confirming its superior effectiveness and
robustness.

</details>


### [989] [Flow Matters: Directional and Expressive GNNs for Heterophilic Graphs](https://arxiv.org/abs/2509.00772)
*Arman Gupta,Govind Waghmare,Gaurav Oberoi,Nitish Srivastava*

Main category: cs.LG

TL;DR: GNN在异质图上表现不佳，提出Poly和Dir-Poly模型，考虑边方向性和高阶特征交互，取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 在异质图中，GNN因依赖同质邻域而表现不佳。边缘方向性被认为可以提高有效同质性，多项式GNN能捕捉高阶特征交互。本研究旨在结合这两点，提升异质图节点分类性能。

Method: 提出两种模型：Poly（多项式GNN基线）和Dir-Poly（方向感知变体，分别聚合入边和出边）。两种模型学习输入特征上的排列等变高次多项式，且时间复杂度不变。

Result: Poly模型在五个异质图数据集上优于现有基线。Dir-Poly在有方向性的图（如罗马帝国）上进一步提升性能，达到SOTA。在无向图上，引入人工方向性不一定有益，表明方向性消息传递的益处具有情境依赖性。

Conclusion: 边缘方向性和表达性特征建模在异质图学习中起着互补作用。

Abstract: In heterophilic graphs, where neighboring nodes often belong to different
classes, conventional Graph Neural Networks (GNNs) struggle due to their
reliance on local homophilous neighborhoods. Prior studies suggest that
modeling edge directionality in such graphs can increase effective homophily
and improve classification performance. Simultaneously, recent work on
polynomially expressive GNNs shows promise in capturing higher-order
interactions among features. In this work, we study the combined effect of edge
directionality and expressive message passing on node classification in
heterophilic graphs. Specifically, we propose two architectures: (1) a
polynomially expressive GAT baseline (Poly), and (2) a direction-aware variant
(Dir-Poly) that separately aggregates incoming and outgoing edges. Both models
are designed to learn permutation-equivariant high-degree polynomials over
input features, while remaining scalable with no added time complexity.
Experiments on five benchmark heterophilic datasets show that our Poly model
consistently outperforms existing baselines, and that Dir-Poly offers
additional gains on graphs with inherent directionality (e.g., Roman Empire),
achieving state-of-the-art results. Interestingly, on undirected graphs,
introducing artificial directionality does not always help, suggesting that the
benefit of directional message passing is context-dependent. Our findings
highlight the complementary roles of edge direction and expressive feature
modeling in heterophilic graph learning.

</details>


### [990] [ProCause: Generating Counterfactual Outcomes to Evaluate Prescriptive Process Monitoring Methods](https://arxiv.org/abs/2509.00797)
*Jakob De Moor,Hans Weytjens,Johannes De Smedt*

Main category: cs.LG

TL;DR: 该研究提出了一种名为ProCause的新型生成方法，用于评估旨在通过实时干预优化流程的规范流程监控（PresPM）方法。与先前依赖于TARNet的RealCause方法不同，ProCause支持序列模型和非序列模型，并集成了多种因果推断（CI）架构，以解决RealCause在处理过程数据中的时间依赖性和模型单一性方面的局限性。通过模拟器和真实世界数据的实验表明，ProCause能够更可靠地评估PresPM方法，特别是当使用集成模型和考虑时间依赖性时。


<details>
  <summary>Details</summary>
Motivation: 评估规范流程监控（PresPM）方法具有挑战性，因为现有数据集缺乏所有干预措施的地面真实结果。常用的RealCause方法存在忽视时间依赖性和依赖单一CI模型（TARNet）的局限性。

Method: 提出了一种名为ProCause的生成方法，该方法支持序列模型（如LSTMs）和非序列模型，并集成了多种CI架构（S-Learner、T-Learner、TARNet和集成模型），以更准确地估计干预措施的结果。

Result: 在模拟器实验中，研究发现集成模型比单一的TARNet模型更可靠，并且使用LSTMs（一种序列模型）在存在时间依赖性的情况下可以改进评估效果。在真实世界数据分析中也验证了ProCause的有效性。

Conclusion: ProCause是一种更可靠的评估PresPM方法的技术，它通过支持多种模型和集成多种CI架构来克服现有方法的局限性，特别是当在具有时间依赖性的数据上使用序列模型时，其效果更佳。

Abstract: Prescriptive Process Monitoring (PresPM) is the subfield of Process Mining
that focuses on optimizing processes through real-time interventions based on
event log data. Evaluating PresPM methods is challenging due to the lack of
ground-truth outcomes for all intervention actions in datasets. A generative
deep learning approach from the field of Causal Inference (CI), RealCause, has
been commonly used to estimate the outcomes for proposed intervention actions
to evaluate a new policy. However, RealCause overlooks the temporal
dependencies in process data, and relies on a single CI model architecture,
TARNet, limiting its effectiveness. To address both shortcomings, we introduce
ProCause, a generative approach that supports both sequential (e.g., LSTMs) and
non-sequential models while integrating multiple CI architectures (S-Learner,
T-Learner, TARNet, and an ensemble). Our research using a simulator with known
ground truths reveals that TARNet is not always the best choice; instead, an
ensemble of models offers more consistent reliability, and leveraging LSTMs
shows potential for improved evaluations when temporal dependencies are
present. We further validate ProCause's practical effectiveness through a
real-world data analysis, ensuring a more reliable evaluation of PresPM
methods.

</details>


### [991] [Fairness in Federated Learning: Trends, Challenges, and Opportunities](https://arxiv.org/abs/2509.00799)
*Noorain Mukhtiar,Adnan Mahmood,Quan Z. Sheng*

Main category: cs.LG

TL;DR: 本 survey 旨在解决联邦学习（FL）中的公平性问题，该问题源于数据、客户端和模型等多种异质性，可能导致偏差、准确性降低和收敛效率低下。文章探讨了偏差的来源，并讨论了现有缓解技术及其优缺点。此外，还阐述了公平性的相关概念、理论基础和技术细节，并介绍了用于量化公平性的评估指标。最后，文章指出了未来可能推动更公平 FL 框架发展的开放性研究方向。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在促进协作模型训练和保护数据隐私方面具有重要作用，但其应用受到公平性问题的阻碍，这些问题源于异质性，可能导致偏差、降低准确性和影响模型收敛。因此，需要探讨这些问题并提出解决方案。

Method: 本文通过对文献进行 survey，梳理了联邦学习中数据、客户端和模型偏差的多种来源，并深入讨论了现有技术在缓解这些差异方面的优缺点。此外，还阐述了公平性的概念、理论基础和技术细节，并考察了用于量化公平性的评估指标。

Result: 本文全面概述了联邦学习中的公平性问题，包括偏差的来源、缓解技术、相关概念、理论基础、技术细节以及评估指标。文章还为未来在这一领域的研究提供了方向。

Conclusion: 本 survey 为理解和解决联邦学习中的公平性问题提供了全面的视角，并为未来的研究指明了方向，有望推动更公平的联邦学习框架的发展。

Abstract: At the intersection of the cutting-edge technologies and privacy concerns,
Federated Learning (FL) with its distributed architecture, stands at the
forefront in a bid to facilitate collaborative model training across multiple
clients while preserving data privacy. However, the applicability of FL systems
is hindered by fairness concerns arising from numerous sources of heterogeneity
that can result in biases and undermine a system's effectiveness, with skewed
predictions, reduced accuracy, and inefficient model convergence. This survey
thus explores the diverse sources of bias, including but not limited to, data,
client, and model biases, and thoroughly discusses the strengths and
limitations inherited within the array of the state-of-the-art techniques
utilized in the literature to mitigate such disparities in the FL training
process. We delineate a comprehensive overview of the several notions,
theoretical underpinnings, and technical aspects associated with fairness and
their adoption in FL-based multidisciplinary environments. Furthermore, we
examine salient evaluation metrics leveraged to measure fairness
quantitatively. Finally, we envisage exciting open research directions that
have the potential to drive future advancements in achieving fairer FL
frameworks, in turn, offering a strong foundation for future research in this
pivotal area.

</details>


### [992] [XAI-Driven Machine Learning System for Driving Style Recognition and Personalized Recommendations](https://arxiv.org/abs/2509.00802)
*Feriel Amel Sellal,Ahmed Ayoub Bellachia,Meryem Malak Dif,Enguerrand De Rautlin De La Roy,Mouhamed Amine Bouchiha,Yacine Ghamri-Doudane*

Main category: cs.LG

TL;DR: 该研究提出了一种基于机器学习的方法，用于驾驶风格分类，旨在提高准确性、可解释性和实用性，并在CARLA-Drive数据集上取得了与深度学习模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习模型在驾驶风格分类任务中可解释性差的问题，本研究提出了一种基于机器学习的方法，以平衡高准确性与可解释性，并为智能交通系统提供实际部署的解决方案。

Method: 本研究利用随机森林（RF）、梯度提升（XGBoost）和支持向量机（SVM）等机器学习技术，并结合SHAP（Shapley Additive Explanations）解释技术，在CARLA-Drive数据集上进行驾驶风格分类。

Result: 在三分类任务中，RF和XGBoost分类器均达到了0.92的准确率，性能与深度学习模型相当，同时提供了更好的透明度和实用性。

Conclusion: 本研究提出的基于机器学习和SHAP解释的方法，在驾驶风格分类任务上实现了高准确性、可解释性和实用性的结合，为智能交通系统中的实际应用提供了有效的解决方案。

Abstract: Artificial intelligence (AI) is increasingly used in the automotive industry
for applications such as driving style classification, which aims to improve
road safety, efficiency, and personalize user experiences. While deep learning
(DL) models, such as Long Short-Term Memory (LSTM) networks, excel at this
task, their black-box nature limits interpretability and trust. This paper
proposes a machine learning (ML)-based method that balances high accuracy with
interpretability. We introduce a high-quality dataset, CARLA-Drive, and
leverage ML techniques like Random Forest (RF), Gradient Boosting (XGBoost),
and Support Vector Machine (SVM), which are efficient, lightweight, and
interpretable. In addition, we apply the SHAP (Shapley Additive Explanations)
explainability technique to provide personalized recommendations for safer
driving. Achieving an accuracy of 0.92 on a three-class classification task
with both RF and XGBoost classifiers, our approach matches DL models in
performance while offering transparency and practicality for real-world
deployment in intelligent transportation systems.

</details>


### [993] [Causal SHAP: Feature Attribution with Dependency Awareness through Causal Discovery](https://arxiv.org/abs/2509.00846)
*Woon Yee Ng,Li Rong Wang,Siyuan Liu,Xiuyi Fan*

Main category: cs.LG

TL;DR: SHAP无法区分因果与相关性，提出Causal SHAP框架，结合PC算法和IDA算法，降低仅相关特征的归因分数，用于XAI领域。


<details>
  <summary>Details</summary>
Motivation: SHAP模型在用于高风险领域（如医疗保健）的可解释性时，存在无法区分因果与相关性的问题，可能在特征高度相关时错误地归因特征重要性。

Method: 提出Causal SHAP框架，该框架将因果关系整合到特征归因中，同时保留了SHAP的许多理想特性。该方法结合了用于因果发现的Peter-Clark (PC)算法和用于因果强度量化的在无因DAG（IDA）中的干预演算算法。

Result: Causal SHAP通过实验在合成和真实世界数据集上得到验证，降低了仅与目标相关的特征的归因分数。

Conclusion: Causal SHAP为因果感知的模型解释提供了一个实用的框架，在医疗保健等需要理解真实因果关系的领域具有重要价值。

Abstract: Explaining machine learning (ML) predictions has become crucial as ML models
are increasingly deployed in high-stakes domains such as healthcare. While
SHapley Additive exPlanations (SHAP) is widely used for model interpretability,
it fails to differentiate between causality and correlation, often
misattributing feature importance when features are highly correlated. We
propose Causal SHAP, a novel framework that integrates causal relationships
into feature attribution while preserving many desirable properties of SHAP. By
combining the Peter-Clark (PC) algorithm for causal discovery and the
Intervention Calculus when the DAG is Absent (IDA) algorithm for causal
strength quantification, our approach addresses the weakness of SHAP.
Specifically, Causal SHAP reduces attribution scores for features that are
merely correlated with the target, as validated through experiments on both
synthetic and real-world datasets. This study contributes to the field of
Explainable AI (XAI) by providing a practical framework for causal-aware model
explanations. Our approach is particularly valuable in domains such as
healthcare, where understanding true causal relationships is critical for
informed decision-making.

</details>


### [994] [Predicting Multi-Type Talented Students in Secondary School Using Semi-Supervised Machine Learning](https://arxiv.org/abs/2509.00863)
*Xinzhe Zheng,Zhen-Qun Yang,Jiannong Cao,Jiabei Cheng*

Main category: cs.LG

TL;DR: 该研究提出了一种名为TalentPredictor的半监督多模态神经网络，结合了Transformer、LSTM和ANN架构，用于预测中学学生的七种不同才能（学术、体育、艺术、领导力、服务、技术等）。


<details>
  <summary>Details</summary>
Motivation: 传统人才识别方法依赖手动流程或仅关注学业成绩，且干预时机过晚，忽略了非学术才能和早期干预的机会。本研究旨在解决这一差距。

Method: 研究引入了一种名为TalentPredictor的新型半监督多模态神经网络，该网络结合了Transformer、LSTM和ANN架构。该模型通过聚类各种获奖记录并提取学生多样化学习行为的特征来预测七种不同才能。

Result: TalentPredictor模型在1041名本地中学生的数据集上进行了训练，实现了0.908的分类准确率和0.908的ROCAUC，证明了机器学习在早期识别学生多样化才能方面的潜力。

Conclusion: 机器学习，特别是TalentPredictor模型，能够克服传统人才识别方法的局限性，通过利用多模态数据和先进的神经网络架构，实现对中学学生多样化才能的早期准确预测。

Abstract: Talent identification plays a critical role in promoting student development.
However, traditional approaches often rely on manual processes or focus
narrowly on academic achievement, and typically delaying intervention until the
higher education stage. This oversight overlooks diverse non-academic talents
and misses opportunities for early intervention. To address this gap, this
study introduces TalentPredictor, a novel semi-supervised multi-modal neural
network that combines Transformer, LSTM, and ANN architectures. This model is
designed to predict seven different talent types--academic, sport, art,
leadership, service, technology, and others--in secondary school students
within an offline educational setting. Drawing on existing offline educational
data from 1,041 local secondary students, TalentPredictor overcomes the
limitations of traditional talent identification methods. By clustering various
award records into talent categories and extracting features from students'
diverse learning behaviors, it achieves high prediction accuracy (0.908
classification accuracy, 0.908 ROCAUC). This demonstrates the potential of
machine learning to identify diverse talents early in student development.

</details>


### [995] [Tabular Diffusion Counterfactual Explanations](https://arxiv.org/abs/2509.00876)
*Wei Zhang,Brian Barr,John Paisley*

Main category: cs.LG

TL;DR: 本文提出了一种针对表格数据的新型逆向生成方法，用于生成可解释的机器学习中的反事实解释，尤其适用于金融和社科领域，并取得了优于基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 许多现有的反事实解释方法主要集中在计算机视觉领域，而忽略了在金融和社科领域广泛应用的表格数据。本文旨在填补这一空白，提出一种适用于表格数据的新型解释方法。

Method: 本文提出了一种基于Gumbel-softmax分布近似的、针对类别特征的引导式逆向生成过程，并研究了温度参数τ的影响，推导了Gumbel-softmax分布与本文提出分布之间的理论界限。

Result: 在多个大规模信用贷和其他表格数据集上的实验表明，本文提出的方法在可解释性、多样性、不稳定性及有效性等量化指标上优于流行的基线方法，能够生成稳健且现实的反事实解释。

Conclusion: 本文提出的方法为表格数据的反事实解释提供了一种有效的新途径，特别是在金融和社科领域具有潜在的应用价值。

Abstract: Counterfactual explanations methods provide an important tool in the field of
{interpretable machine learning}. Recent advances in this direction have
focused on diffusion models to explain a deep classifier. However, these
techniques have predominantly focused on problems in computer vision. In this
paper, we focus on tabular data typical in finance and the social sciences and
propose a novel guided reverse process for categorical features based on an
approximation to the Gumbel-softmax distribution. Furthermore, we study the
effect of the temperature $\tau$ and derive a theoretical bound between the
Gumbel-softmax distribution and our proposed approximated distribution. We
perform experiments on several large-scale credit lending and other tabular
datasets, assessing their performance in terms of the quantitative measures of
interpretability, diversity, instability, and validity. These results indicate
that our approach outperforms popular baseline methods, producing robust and
realistic counterfactual explanations.

</details>


### [996] [An Explainable Gaussian Process Auto-encoder for Tabular Data](https://arxiv.org/abs/2509.00884)
*Wei Zhang,Brian Barr,John Paisley*

Main category: cs.LG

TL;DR: 提出了一种使用高斯过程构建自动编码器的新方法，用于生成反事实样本，并引入了新的密度估计器和正则化率选择算法。


<details>
  <summary>Details</summary>
Motivation: 高风险领域对可解释机器学习的需求，以及利用生成模型（如自动编码器）生成反事实解释的趋势。

Method: 使用高斯过程构建自动编码器，并引入新的密度估计器和用于选择正则化率的算法。

Result: 所提出的方法生成的反事实样本多样化且符合数据分布，并且比其他基于自动编码器的方法更不容易过拟合。

Conclusion: 该方法在大型表格数据集上表现良好，能够生成多样化且符合分布的反事实样本。

Abstract: Explainable machine learning has attracted much interest in the community
where the stakes are high. Counterfactual explanations methods have become an
important tool in explaining a black-box model. The recent advances have
leveraged the power of generative models such as an autoencoder. In this paper,
we propose a novel method using a Gaussian process to construct the
auto-encoder architecture for generating counterfactual samples. The resulting
model requires fewer learnable parameters and thus is less prone to
overfitting. We also introduce a novel density estimator that allows for
searching for in-distribution samples. Furthermore, we introduce an algorithm
for selecting the optimal regularization rate on density estimator while
searching for counterfactuals. We experiment with our method in several
large-scale tabular datasets and compare with other auto-encoder-based methods.
The results show that our method is capable of generating diversified and
in-distribution counterfactual samples.

</details>


### [997] [DTRNet: Dynamic Token Routing Network to Reduce Quadratic Costs in Transformers](https://arxiv.org/abs/2509.00925)
*Aman Sharma,Saeed Najafi,Parsa Farinneya,Benyamin Jamialahmadi,Marzieh S. Tahaei,Yuhe Fan,Mehdi Rezagholizadeh,Boxing Chen,Aref Jafari*

Main category: cs.LG

TL;DR: DTRNet通过动态路由减少了Transformer的计算成本，在保持性能的同时显著降低了计算量和内存占用，尤其在长序列输入时效果更佳。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在各项任务中表现优异，但其在所有层中对所有token都应用二次自注意力机制，导致计算成本高昂。

Method: 提出了一种名为DTRNet（动态Token路由网络）的改进Transformer架构，允许token动态地跳过二次交叉token混合的计算成本，同时仍接收轻量级线性更新。通过保留MLP模块并降低大多数token的注意力成本至线性，DTRNet确保每个token都得到显式更新，同时显著降低了整体计算量。

Result: DTRNet在训练后，每个层仅约10%的token会经过注意力机制，但性能与完整Transformer相当。在相同的FLOPs下，DTRNet在准确性和内存占用方面均优于MoD和D-LLM等基于路由的层跳过方法，并且路由到完整注意力的token更少。其效率提升随序列长度的增加而扩展，为长上下文输入提供了显著的FLOPs降低。

Conclusion: DTRNet通过解耦token更新与注意力混合，大大减少了计算成本中的二次方部分，提供了一种简单、高效且可扩展的Transformer替代方案。

Abstract: Transformers achieve state-of-the-art results across many tasks, but their
uniform application of quadratic self-attention to every token at every layer
makes them computationally expensive. We introduce DTRNet (Dynamic Token
Routing Network), an improved Transformer architecture that allows tokens to
dynamically skip the quadratic cost of cross-token mixing while still receiving
lightweight linear updates. By preserving the MLP module and reducing the
attention cost for most tokens to linear, DTRNet ensures that every token is
explicitly updated while significantly lowering overall computation. This
design offers an efficient and effective alternative to standard dense
attention. Once trained, DTRNet blocks routes only ~10% of tokens through
attention at each layer while maintaining performance comparable to a full
Transformer. It consistently outperforms routing-based layer skipping methods
such as MoD and D-LLM in both accuracy and memory at matched FLOPs, while
routing fewer tokens to full attention. Its efficiency gains, scales with
sequence length, offering significant reduction in FLOPs for long-context
inputs. By decoupling token updates from attention mixing, DTRNet substantially
reduces the quadratic share of computation, providing a simple, efficient, and
scalable alternative to Transformers.

</details>


### [998] [Superposition in Graph Neural Networks](https://arxiv.org/abs/2509.00928)
*Lukas Pertl,Han Xuanyuan,Pietro Liò*

Main category: cs.LG

TL;DR: GNNs难以解释，因为消息传递会混合信号，内部通道很少与人类概念对齐。本文研究了GNN潜在空间中的叠加现象（多个特征共享方向）。通过在GCN/GIN/GAT中进行对照实验，我们发现：增加宽度会在重叠中产生相位模式；拓扑结构将重叠压印到节点级特征上，然后池化在一定程度上将其混合成任务对齐的图轴；更急剧的池化会增加轴对齐并减少通道共享；浅层模型可以陷入亚稳态低秩嵌入。这些结果将表征几何与具体的 GNN 设计选择（宽度、池化和最终层激活）联系起来，并为更具可解释性的 GNN 提供了实用的方法。


<details>
  <summary>Details</summary>
Motivation: 解释图神经网络（GNN）的内在机制，特别是理解其在潜在空间中的表示方式。

Method: 通过受控实验提取特征，包括（i）图级别的类条件质心和（ii）节点级别的线性探测方向，并使用简单的基不变诊断分析它们的几何形状。

Result: 发现在GCN/GIN/GAT中，增加宽度会在重叠中产生相位模式；拓扑结构将重叠压印到节点级特征上，然后池化在一定程度上将其混合成任务对齐的图轴；更急剧的池化会增加轴对齐并减少通道共享；浅层模型可以陷入亚稳态低秩嵌入。

Conclusion: 研究结果将表征几何与具体的 GNN 设计选择（宽度、池化和最终层激活）联系起来，并为更具可解释性的 GNN 提供了实用的方法。

Abstract: Interpreting graph neural networks (GNNs) is difficult because message
passing mixes signals and internal channels rarely align with human concepts.
We study superposition, the sharing of directions by multiple features,
directly in the latent space of GNNs. Using controlled experiments with
unambiguous graph concepts, we extract features as (i) class-conditional
centroids at the graph level and (ii) linear-probe directions at the node
level, and then analyze their geometry with simple basis-invariant diagnostics.
Across GCN/GIN/GAT we find: increasing width produces a phase pattern in
overlap; topology imprints overlap onto node-level features that pooling
partially remixes into task-aligned graph axes; sharper pooling increases axis
alignment and reduces channel sharing; and shallow models can settle into
metastable low-rank embeddings. These results connect representational geometry
with concrete design choices (width, pooling, and final-layer activations) and
suggest practical approaches for more interpretable GNNs.

</details>


### [999] [SCOUT: Toward Sub-Quadratic Attention via Segment Compression for Optimized Utility in Transformers](https://arxiv.org/abs/2509.00935)
*Aref Jafari,Yuhe Fan,Benyamin Jamialahmadi,Parsa Farinneya,Boxing Chen,Marzieh S. Tahaei*

Main category: cs.LG

TL;DR: SCOUT是一种混合架构，通过局部压缩和稀疏注意力来提高Transformer处理长序列的效率和性能，实现了优于线性模型和可与全注意力模型媲美的结果。


<details>
  <summary>Details</summary>
Motivation: 现有的Transformer模型在处理长序列时存在二次注意力复杂性问题，而Mamba和SWA等线性模型虽然提高了效率，但可能牺牲对长距离信息的捕捉能力。SCOUT旨在解决这一权衡，保留Transformer的表达能力，同时降低计算和内存成本。

Method: SCOUT首先使用线性局部混合器（如Mamba或SWA）增强每个token的嵌入，整合近期上下文。然后，每个token只关注少数几个压缩的检查点token，而不是所有先前的token，从而对输入历史进行摘要。这种方法减少了计算和内存开销，同时保持了信息表达能力。

Result: SCOUT在长上下文语言建模和推理任务上的表现优于同等计算预算下的长序列基线模型，在400M和1.3B规模下与全注意力Transformer在语言建模和常识推理任务上相当。此外，SCOUT实现了比SOTA模型更高的端到端吞吐量，并在长序列基准测试中取得了可比的结果。

Conclusion: SCOUT通过结合局部压缩和稀疏注意力，成功地在效率和性能之间取得了平衡，为处理长序列任务提供了一种可扩展且有效的解决方案。

Abstract: Transformers have demonstrated strong performance across a wide range of
sequence modeling tasks, but their quadratic attention complexity limits
scalability to long sequences. Linear models such as Mamba and sliding-window
attention (SWA) address this by mixing tokens through recurrent or localized
operations with fixed-size memory, achieving efficient inference. However,
these methods risk degrading performance on long sequences due to their
inability to retain detailed information from distant tokens. We propose SCOUT
(Segment Compression for Optimized Utility in Transformers), a hybrid
architecture that compresses tokens locally within fixed-size segments and
applies attention only over these compressed representations. Each token
embedding is first enriched via a linear local mixer, Mamba or SWA, that
integrates recent context. Then, instead of attending to all previous tokens,
each token sparsely attends to a small number of compressed checkpoint tokens
that summarize the input history. This design retains much of the expressivity
of full attention while substantially reducing the computational and memory
cost. By attending to compressed history rather than all previous tokens, SCOUT
incurs slightly higher memory than purely linear models, but its growth rate
remains sub-quadratic and far more scalable than that of full Transformers. We
analyze SCOUT's computational and memory efficiency and evaluate it empirically
on long-context language modeling and reasoning tasks. SCOUT with both Mamba
and SWA mixers outperforms strong long-sequence baselines under the same
computational budget, matches full-attention Transformers on language modeling
and common-sense reasoning tasks at 400M and 1.3B scales. Moreover, our SCOUT
achieves higher end-to-end throughput than SOTA models, while delivering
comparable results on long sequence benchmarks.

</details>


### [1000] [ART: Adaptive Resampling-based Training for Imbalanced Classification](https://arxiv.org/abs/2509.00955)
*Arjun Basandrai,Shourya Jain,K. Ilanthenral*

Main category: cs.LG

TL;DR: ART是一种基于自适应重采样的方法，通过周期性地根据模型表现更新数据分布来处理类别不平衡问题，并在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的重采样方法使用固定的数据分布，忽略了类别学习难度的变化，限制了模型性能。本研究提出ART方法，通过自适应调整重采样分布来解决这一问题。

Method: ART方法周期性地根据模型类别表现（具体为类别宏F1分数）来更新训练数据的分布，从而动态调整重采样策略。该方法在类别层面进行调整，避免了实例层面的噪声和异常值敏感问题。

Result: ART在Pima Indians Diabetes和Yeast等多个基准测试中，在二分类和多分类任务上均优于SMOTE、NearMiss和成本敏感学习等方法。在表格数据集上，ART相比原始不平衡数据，宏F1平均提升2.64个百分点，且改进具有统计显著性。

Conclusion: ART是一种稳定且有效的处理类别不平衡问题的方法，它通过自适应地调整重采样策略，能够持续提供优于现有方法的宏F1分数，适用于各种不平衡分类任务。

Abstract: Traditional resampling methods for handling class imbalance typically uses
fixed distributions, undersampling the majority or oversampling the minority.
These static strategies ignore changes in class-wise learning difficulty, which
can limit the overall performance of the model.
  This paper proposes an Adaptive Resampling-based Training (ART) method that
periodically updates the distribution of the training data based on the
class-wise performance of the model. Specifically, ART uses class-wise macro F1
scores, computed at fixed intervals, to determine the degree of resampling to
be performed.
  Unlike instance-level difficulty modeling, which is noisy and
outlier-sensitive, ART adapts at the class level. This allows the model to
incrementally shift its attention towards underperforming classes in a way that
better aligns with the optimization objective.
  Results on diverse benchmarks, including Pima Indians Diabetes and Yeast
dataset demonstrate that ART consistently outperforms both resampling-based and
algorithm-level methods, including Synthetic Minority Oversampling Technique
(SMOTE), NearMiss Undersampling, and Cost-sensitive Learning on binary as well
as multi-class classification tasks with varying degrees of imbalance.
  In most settings, these improvements are statistically significant. On
tabular datasets, gains are significant under paired t-tests and Wilcoxon tests
(p < 0.05), while results on text and image tasks remain favorable. Compared to
training on the original imbalanced data, ART improves macro F1 by an average
of 2.64 percentage points across all tested tabular datasets. Unlike existing
methods, whose performance varies by task, ART consistently delivers the
strongest macro F1, making it a reliable choice for imbalanced classification.

</details>


### [1001] [Online Decentralized Federated Multi-task Learning With Trustworthiness in Cyber-Physical Systems](https://arxiv.org/abs/2509.00992)
*Olusola Odeyomi,Sofiat Olaosebikan,Ajibuwa Opeyemi,Oluwadoyinsola Ige*

Main category: cs.LG

TL;DR: 本研究提出了一种在线去中心化联邦多任务学习算法，用于在拜占庭客户端数量占主导的情况下实现模型个性化和弹性。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据异构性导致的模型个性化挑战，并将其扩展到在线去中心化联邦学习环境，同时应对拜占庭客户端问题。

Method: 利用网络物理特性（如信号强度或侧信道信息）为每次迭代中收到的本地模型分配信任概率。

Result: 模拟结果表明，所提出的算法在拜占庭客户端数量占主导的情况下，性能接近无拜占庭客户端的设置。

Conclusion: 该算法能够有效地在存在大量拜占庭客户端的在线去中心化联邦学习环境中提供模型个性化和弹性。

Abstract: Multi-task learning is an effective way to address the challenge of model
personalization caused by high data heterogeneity in federated learning.
However, extending multi-task learning to the online decentralized federated
learning setting is yet to be explored. The online decentralized federated
learning setting considers many real-world applications of federated learning,
such as autonomous systems, where clients communicate peer-to-peer and the data
distribution of each client is time-varying. A more serious problem in
real-world applications of federated learning is the presence of Byzantine
clients. Byzantine-resilient approaches used in federated learning work only
when the number of Byzantine clients is less than one-half the total number of
clients. Yet, it is difficult to put a limit on the number of Byzantine clients
within a system in reality. However, recent work in robotics shows that it is
possible to exploit cyber-physical properties of a system to predict clients'
behavior and assign a trust probability to received signals. This can help to
achieve resiliency in the presence of a dominating number of Byzantine clients.
Therefore, in this paper, we develop an online decentralized federated
multi-task learning algorithm to provide model personalization and resiliency
when the number of Byzantine clients dominates the number of honest clients.
Our proposed algorithm leverages cyber-physical properties, such as the
received signal strength in wireless systems or side information, to assign a
trust probability to local models received from neighbors in each iteration.
Our simulation results show that the proposed algorithm performs close to a
Byzantine-free setting.

</details>


### [1002] [MEPT: Mixture of Expert Prompt Tuning as a Manifold Mapper](https://arxiv.org/abs/2509.00996)
*Runjia Zeng,Guangyan Sun,Qifan Wang,Tong Geng,Sohail Dianat,Xiaotian Han,Raghuveer Rao,Xueling Zhang,Cheng Han,Lifu Huang,Dongfang Liu*

Main category: cs.LG

TL;DR: MEPT是一种新的参数高效微调方法，通过混合专家来适应多样化和非平稳的数据分布，在SuperGLUE上取得了显著的性能提升，并减少了激活的提示。


<details>
  <summary>Details</summary>
Motivation: 现有的微调方法在适应多变的数据分布方面存在局限性，因为其固定的参数空间难以动态激活合适的神经通路。本文提出MEPT来解决这个问题。

Method: MEPT利用混合专家架构，集成多个提示专家，以自适应地学习多样化和非平稳的数据分布。

Result: MEPT在SuperGLUE上实现了1.94%的平均准确率提升，并显著减少了79.25%的激活提示，优于现有的参数高效基线方法。

Conclusion: MEPT作为一种有效的流形映射框架，能够有效地适应多样化和不断变化的数据分布，并通过理论和可视化结果得到验证。

Abstract: Considering deep neural networks as manifold mappers, the
pretrain-then-fine-tune paradigm can be interpreted as a two-stage process:
pretrain establishes a broad knowledge base, and fine-tune adjusts the model
parameters to activate specific neural pathways to align with the target
manifold. Although prior fine-tuning approaches demonstrate success, their
rigid parameter space limits their ability to dynamically activate appropriate
neural pathways, rendering them ill-equipped to adapt flexibly to the diverse
and evolving data distributions. In light of this view, we propose a novel
approach, Mixture of Expert Prompt Tuning (MEPT), as an effective and efficient
manifold-mapping framework. MEPT leverages the Mixture of Experts architecture
by integrating multiple prompt experts to adaptively learn diverse and
non-stationary data distributions. Empirical evaluations demonstrate that MEPT
outperforms several state-of-the-art parameter efficient baselines on
SuperGLUE, achieving notable improvements in mean accuracy (e.g., 1.94%) while
significantly reducing activated prompts by 79.25%. The effectiveness of MEPT
is further supported by theoretical insights from manifold learning and
validated through neural activation pathway visualization results. Our code is
avaliable at https://github.com/runtsang/MEPT.

</details>


### [1003] [Any-Order Flexible Length Masked Diffusion](https://arxiv.org/abs/2509.01025)
*Jaeyeon Kim,Lee Cheuk-Kit,Carles Domingo-Enrich,Yilun Du,Sham Kakade,Timothy Ngotiaoco,Sitan Chen,Michael Albergo*

Main category: cs.LG

TL;DR: FlexMDMs是一种新的离散扩散模型，可以灵活地生成任意长度的序列，并且可以像MDMs一样进行任意顺序的推理。它们在保持MDMs性能的同时，在长度建模和某些任务上表现更好，并且可以轻松地从现有MDMs进行微调。


<details>
  <summary>Details</summary>
Motivation: 现有的掩码扩散模型（MDMs）在离散域上很有前景，但它们不支持标记插入，因此生成长度固定。需要一种能够灵活处理序列长度并保留MDM的任意顺序推理灵活性的模型。

Method: 提出了一种名为FlexMDMs的灵活掩码扩散模型，该模型基于随机插值框架的扩展。FlexMDMs通过插入掩码标记然后取消掩码来生成序列，从而实现灵活长度的序列建模和任意顺序推理。

Result: FlexMDMs在困惑度方面与MDMs相当，但能更准确地模拟长度分布。在合成迷宫规划任务中，FlexMDMs的成功率比MDM基线高约60%。此外，将LLaDA-8B微调为FlexMDM仅需三天，在数学（GSM8K）和代码填充任务上的性能均有显著提升（从58%提升到67%，从52%提升到65%）。

Conclusion: FlexMDMs成功地扩展了MDMs的能力，解决了其固定长度生成的限制，同时保留了其推理灵活性。该模型在长度建模和特定任务上表现出优越性，并且易于从现有MDMs进行迁移学习，为离散序列生成开辟了新的可能性。

Abstract: Masked diffusion models (MDMs) have recently emerged as a promising
alternative to autoregressive models over discrete domains. MDMs generate
sequences in an any-order, parallel fashion, enabling fast inference and strong
performance on non-causal tasks. However, a crucial limitation is that they do
not support token insertions and are thus limited to fixed-length generations.
To this end, we introduce Flexible Masked Diffusion Models (FlexMDMs), a
discrete diffusion paradigm that simultaneously can model sequences of flexible
length while provably retaining MDMs' flexibility of any-order inference.
Grounded in an extension of the stochastic interpolant framework, FlexMDMs
generate sequences by inserting mask tokens and unmasking them. Empirically, we
show that FlexMDMs match MDMs in perplexity while modeling length statistics
with much higher fidelity. On a synthetic maze planning task, they achieve
$\approx 60 \%$ higher success rate than MDM baselines. Finally, we show
pretrained MDMs can easily be retrofitted into FlexMDMs: on 16 H100s, it takes
only three days to fine-tune LLaDA-8B into a FlexMDM, achieving superior
performance on math (GSM8K, $58\% \to 67\%$) and code infilling performance
($52\% \to 65\%$).

</details>


### [1004] [Reinforcement Learning Driven Generalizable Feature Representation for Cross-User Activity Recognition](https://arxiv.org/abs/2509.01031)
*Xiaozhou Ye,Kevin I-Kai Wang*

Main category: cs.LG

TL;DR: 该论文提出了一种名为TPRL-DG的新框架，用于解决可穿戴传感器进行的人类活动识别（HAR）中的跨用户变异性问题，该方法利用强化学习和Transformer模型来提取用户不变的活动动态，并实现了无需目标用户标注的零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 目前基于可穿戴传感器的人类活动识别（HAR）技术在医疗保健、健身追踪和智能环境等领域至关重要，但跨用户变异性（由于运动模式、传感器放置和生理特征的差异）严重阻碍了其在现实世界中的泛化能力。传统监督学习方法容易过拟合特定用户模式，导致在未见过用户上的性能不佳。现有的域泛化方法虽然有前景，但常常忽略时间依赖性或依赖于不切实际的特定领域标签。

Method: 提出了一种名为TPRL-DG（Temporal-Preserving Reinforcement Learning Domain Generalization）的新框架，将特征提取重新定义为由强化学习驱动的序列决策过程。TPRL-DG利用基于Transformer的自回归生成器来生成捕获用户不变活动动态的时间标记（temporal tokens），并通过一个多目标奖励函数进行优化，该函数平衡了类别区分度和跨用户不变性。关键创新包括：1）一种用于域泛化的强化学习驱动方法；2）一种用于保留时间相干性的自回归标记化；3）一种无需标签的奖励设计，消除了对目标用户注释的需求。

Result: 在DSADS和PAMAP2数据集上的评估结果表明，TPRL-DG在跨用户泛化方面超越了最先进的方法，在无需进行用户校准的情况下实现了卓越的准确性。

Conclusion: 通过学习鲁棒的、用户不变的时间模式，TPRL-DG能够实现可扩展的HAR系统，从而促进个性化医疗保健、自适应健身追踪和情境感知环境等方面的进步。

Abstract: Human Activity Recognition (HAR) using wearable sensors is crucial for
healthcare, fitness tracking, and smart environments, yet cross-user
variability -- stemming from diverse motion patterns, sensor placements, and
physiological traits -- hampers generalization in real-world settings.
Conventional supervised learning methods often overfit to user-specific
patterns, leading to poor performance on unseen users. Existing domain
generalization approaches, while promising, frequently overlook temporal
dependencies or depend on impractical domain-specific labels. We propose
Temporal-Preserving Reinforcement Learning Domain Generalization (TPRL-DG), a
novel framework that redefines feature extraction as a sequential
decision-making process driven by reinforcement learning. TPRL-DG leverages a
Transformer-based autoregressive generator to produce temporal tokens that
capture user-invariant activity dynamics, optimized via a multi-objective
reward function balancing class discrimination and cross-user invariance. Key
innovations include: (1) an RL-driven approach for domain generalization, (2)
autoregressive tokenization to preserve temporal coherence, and (3) a
label-free reward design eliminating the need for target user annotations.
Evaluations on the DSADS and PAMAP2 datasets show that TPRL-DG surpasses
state-of-the-art methods in cross-user generalization, achieving superior
accuracy without per-user calibration. By learning robust, user-invariant
temporal patterns, TPRL-DG enables scalable HAR systems, facilitating
advancements in personalized healthcare, adaptive fitness tracking, and
context-aware environments.

</details>


### [1005] [MatPROV: A Provenance Graph Dataset of Material Synthesis Extracted from Scientific Literature](https://arxiv.org/abs/2509.01042)
*Hirofumi Tsuruta,Masaya Kumagai*

Main category: cs.LG

TL;DR: 数据驱动材料发现需要从文献中提取结构化合成程序，但现有方法受限于僵化的模式和线性假设。本研究采用PROV-DM标准，提出MatPROV数据集，使用大语言模型从科学文献中提取符合PROV-DM的合成程序，以图状结构捕捉复杂性和因果关系，实现机器可解释的合成知识。


<details>
  <summary>Details</summary>
Motivation: 现有方法在提取材料合成程序时，往往依赖于僵化、领域特定的模式，并且假设合成程序是线性的操作序列，这限制了它们捕捉真实世界程序结构复杂性的能力。因此，需要一种更灵活、更能体现程序复杂性的方法。

Method: 采用PROV-DM（一种国际公认的取证信息标准）来灵活地、基于图建模地表示合成程序。利用大型语言模型从科学文献中提取符合PROV-DM标准的合成程序，构建MatPROV数据集。该数据集通过可视化、有向图的形式，捕捉材料、操作和条件之间的结构复杂性和因果关系。

Result: 构建了一个名为MatPROV的数据集，其中包含符合PROV-DM标准的合成程序。这些程序以图状结构表示，能够捕捉材料、操作和条件之间复杂的结构和因果关系，使得合成知识具有机器可解释性。

Conclusion: MatPROV数据集的构建以及基于PROV-DM的图状表示方法，能够克服现有方法的局限性，实现对材料合成程序结构复杂性和因果关系的有效捕捉，为自动化合成规划和优化等未来研究提供了基础。

Abstract: Synthesis procedures play a critical role in materials research, as they
directly affect material properties. With data-driven approaches increasingly
accelerating materials discovery, there is growing interest in extracting
synthesis procedures from scientific literature as structured data. However,
existing studies often rely on rigid, domain-specific schemas with predefined
fields for structuring synthesis procedures or assume that synthesis procedures
are linear sequences of operations, which limits their ability to capture the
structural complexity of real-world procedures. To address these limitations,
we adopt PROV-DM, an international standard for provenance information, which
supports flexible, graph-based modeling of procedures. We present MatPROV, a
dataset of PROV-DM-compliant synthesis procedures extracted from scientific
literature using large language models. MatPROV captures structural
complexities and causal relationships among materials, operations, and
conditions through visually intuitive directed graphs. This representation
enables machine-interpretable synthesis knowledge, opening opportunities for
future research such as automated synthesis planning and optimization.

</details>


### [1006] [REFINESTAT: Efficient Exploration for Probabilistic Program Synthesis](https://arxiv.org/abs/2509.01082)
*Madhav Kanda,Shubham Ugare,Sasa Misailovic*

Main category: cs.LG

TL;DR: RefineStat是一个利用语言模型和诊断感知细化来生成和改进概率程序的新框架，以解决不确定性建模中的搜索空间和约束问题。


<details>
  <summary>Details</summary>
Motivation: 解决在概率编程中进行统计模型发现时，语言模型生成带有句法和语义错误（例如，错误的推理构造）的程序的问题，这些错误源于巨大的搜索空间和严格的领域特定约束。

Method: RefineStat是一个语言模型驱动的框架，它通过重新采样先验或似然组件来强制执行语义约束，以确保生成的程序包含有效的分布和格式正确的参数，并在可靠性检查失败时应用诊断感知细化。

Result: RefineStat在多个概率编程代码生成任务上进行了评估，使用了较小的语言模型（SLMs），并生成了句法正确且统计上可靠的程序，其性能常常能与闭源大语言模型（例如，OpenAI o3）相媲美甚至超越。

Conclusion: RefineStat框架能够成功地生成句法正确且统计上可靠的概率程序，解决了在概率编程中模型发现的挑战。

Abstract: Probabilistic programming offers a powerful framework for modeling
uncertainty, yet statistical model discovery in this domain entails navigating
an immense search space under strict domain-specific constraints. When small
language models are tasked with generating probabilistic programs, they
frequently produce outputs that suffer from both syntactic and semantic errors,
such as flawed inference constructs. Motivated by probabilistic programmers'
domain expertise and debugging strategies, we introduce RefineStat, a language
model--driven framework that enforces semantic constraints ensuring synthesized
programs contain valid distributions and well-formed parameters, and then
applies diagnostic-aware refinement by resampling prior or likelihood
components whenever reliability checks fail. We evaluate RefineStat on multiple
probabilistic-programming code-generation tasks using smaller language models
(SLMs) and find that it produces programs that are both syntactically sound and
statistically reliable, often matching or surpassing those from closed-source
large language models (e.g., OpenAI o3).

</details>


### [1007] [CCE: Confidence-Consistency Evaluation for Time Series Anomaly Detection](https://arxiv.org/abs/2509.01098)
*Zhijie Zhong,Zhiwen Yu,Yiu-ming Cheung,Kaixiang Yang*

Main category: cs.LG

TL;DR: CCE是一种新的时间序列异常检测评估指标，通过结合预测置信度和不确定性一致性来克服现有指标的局限性。RankEval是一个用于比较指标排名的基准。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列异常检测评估指标存在区分能力不足、超参数依赖性强、对扰动敏感以及计算开销高等问题。

Method: CCE通过贝叶斯估计量化异常分数的置信度和不确定性一致性，并构建全局和事件级评分。RankEval是一个用于比较指标排名的基准。

Result: CCE具有严格的界限、对扰动的Lipschitz鲁棒性以及线性时间复杂度O(n)。RankEval实现了对评估指标的客观比较。

Conclusion: CCE和RankEval为时间序列异常检测模型评估提供了更优越的解决方案。

Abstract: Time Series Anomaly Detection metrics serve as crucial tools for model
evaluation. However, existing metrics suffer from several limitations:
insufficient discriminative power, strong hyperparameter dependency,
sensitivity to perturbations, and high computational overhead. This paper
introduces Confidence-Consistency Evaluation (CCE), a novel evaluation metric
that simultaneously measures prediction confidence and uncertainty consistency.
By employing Bayesian estimation to quantify the uncertainty of anomaly scores,
we construct both global and event-level confidence and consistency scores for
model predictions, resulting in a concise CCE metric. Theoretically and
experimentally, we demonstrate that CCE possesses strict boundedness, Lipschitz
robustness against score perturbations, and linear time complexity
$\mathcal{O}(n)$. Furthermore, we establish RankEval, a benchmark for comparing
the ranking capabilities of various metrics. RankEval represents the first
standardized and reproducible evaluation pipeline that enables objective
comparison of evaluation metrics. Both CCE and RankEval implementations are
fully open-source.

</details>


### [1008] [MATL-DC: A Multi-domain Aggregation Transfer Learning Framework for EEG Emotion Recognition with Domain-Class Prototype under Unseen Targets](https://arxiv.org/abs/2509.01135)
*Guangli Li,Canbiao Wu,Zhehao Zhou,Na Tian,Zhen Liang*

Main category: cs.LG

TL;DR: 提出了一种用于脑电图情感识别的多域聚合迁移学习框架MATL-DC，该框架在目标域不可见的情况下，通过解耦特征、聚合域空间、提取类原型以及采用成对学习策略，有效提高了情感识别的准确性，并在公开数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前迁移学习模型在情感识别方面高度依赖源域和目标域数据，这限制了其在实际应用中的潜力。

Method: 提出MATL-DC框架，设计了特征解耦模块以分离类不变域特征和域不变类特征；在训练阶段，通过多域聚合机制形成超域并提取类原型表示；采用成对学习策略将分类问题转化为样本对相似性问题，以减轻标签噪声的影响。在推理阶段，利用训练好的域-类原型进行推理。

Result: 在SEED、SEED-IV和SEED-V数据集上，MATL-DC模型的准确率分别为84.70%、68.11%和61.08%，表现出与依赖源域和目标域的方法相当甚至更优的性能。

Conclusion: MATL-DC框架在目标域数据不可用的情况下，通过有效的特征处理和学习策略，成功实现了高性能的脑电图情感识别，证明了其在实际应用中的可行性和优越性。

Abstract: Emotion recognition based on electroencephalography (EEG) signals is
increasingly becoming a key research hotspot in affective Brain-Computer
Interfaces (aBCIs). However, the current transfer learning model greatly
depends on the source domain and target domain data, which hinder the practical
application of emotion recognition. Therefore, we propose a Multi-domain
Aggregation Transfer Learning framework for EEG emotion recognition with
Domain-Class prototype under unseen targets (MATL-DC). We design the feature
decoupling module to decouple class-invariant domain features from
domain-invariant class features from shallow features. In the model training
stage, the multi-domain aggregation mechanism aggregates the domain feature
space to form a superdomain, which enhances the characteristics of emotional
EEG signals. In each superdomain, we further extract the class prototype
representation by class features. In addition, we adopt the pairwise learning
strategy to transform the sample classification problem into the similarity
problem between sample pairs, which effectively alleviates the influence of
label noise. It is worth noting that the target domain is completely unseen
during the training process. In the inference stage, we use the trained
domain-class prototypes for inference, and then realize emotion recognition. We
rigorously validate it on the publicly available databases (SEED, SEED-IV and
SEED-V). The results show that the accuracy of MATL-DC model is 84.70\%,
68.11\% and 61.08\%, respectively. MATL-DC achieves comparable or even better
performance than methods that rely on both source and target domains. The
source code is available at https://github.com/WuCB-BCI/MATL-DC.

</details>


### [1009] [Nonlinear Performative Prediction](https://arxiv.org/abs/2509.01139)
*Guangzheng Zhong,Yang Liu,Jiming Liu*

Main category: cs.LG

TL;DR: 该研究提出了一种新的可言预测（performative prediction）范式，用于解决模型预测可能导致数据分布发生变化的问题。该方法放宽了现有研究中对梯度有界的假设，并将可言预测推广到非线性情况，同时保持了理论性质。


<details>
  <summary>Details</summary>
Motivation: 现有可言预测的研究依赖于不可控的假设（如可言损失的梯度有界），且主要关注线性案例，这在具有复杂非线性特征的现实世界应用中并不常见。本研究旨在放宽这些假设，将可言预测推广到非线性情况。

Method: 研究将可言预测的损失函数形式化为最大间隔方法，并通过核方法将其扩展到非线性空间。使用预测误差的差异来量化数据分布的变化，并推导出可言稳定性的条件，最终开发了一个保证预测模型可言稳定性的算法。

Result: 通过在线性和非线性数据集上的实验验证了该方法的有效性，并在与最先进基线的比较中表现出优越性能。

Conclusion: 本研究成功地将可言预测推广到非线性情况，提出了一个保证可言稳定性的新算法，并在各种数据集上证明了其有效性。

Abstract: Performative prediction is an emerging paradigm in machine learning that
addresses scenarios where the model's prediction may induce a shift in the
distribution of the data it aims to predict. Current works in this field often
rely on uncontrollable assumptions, such as bounded gradients of performative
loss, and primarily focus on linear cases in their examples and evaluations to
maintain consistency between theoretical guarantees and empirical validations.
However, such linearity rarely holds in real-world applications, where the data
usually exhibit complex nonlinear characteristics. In this paper, we relax
these out-of-control assumptions and present a novel design that generalizes
performative prediction to nonlinear cases while preserving essential
theoretical properties. Specifically, we formulate the loss function of
performative prediction using a maximum margin approach and extend it to
nonlinear spaces through kernel methods. To quantify the data distribution
shift, we employ the discrepancy between prediction errors on these two
distributions as an indicator, which characterizes the impact of the
performative effect on specific learning tasks. By doing so, we can derive, for
both linear and nonlinear cases, the conditions for performative stability, a
critical and desirable property in performative contexts. Building on these
theoretical insights, we develop an algorithm that guarantees the performative
stability of the predictive model. We validate the effectiveness of our method
through experiments on synthetic and real-world datasets with both linear and
nonlinear data distributions, demonstrating superior performance compared to
state-of-the-art baselines.

</details>


### [1010] [Multi-Modal Machine Learning Framework for Predicting Early Recurrence of Brain Tumors Using MRI and Clinical Biomarkers](https://arxiv.org/abs/2509.01161)
*Cheng Cheng,Zeping Chen,Rui Xie,Peiyao Zheng,Xavier Wang*

Main category: cs.LG

TL;DR: 本研究提出了一种多模态机器学习框架，结合结构MRI特征和临床生物标志物，以提高脑肿瘤患者术后复发预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 准确预测脑肿瘤患者手术切除后的早期复发仍然是一个临床挑战。

Method: 研究采用了四种机器学习算法——梯度提升机（GBM）、随机生存森林（RSF）、CoxBoost和XGBoost——并使用一致性指数（C-index）、时间依赖性AUC、校准曲线和决策曲线分析来验证模型性能。

Result: 所提出的模型表现出有希望的性能。

Conclusion: 该框架有潜力成为风险分层和个性化随访规划的工具。

Abstract: Accurately predicting early recurrence in brain tumor patients following
surgical resection remains a clinical challenge. This study proposes a
multi-modal machine learning framework that integrates structural MRI features
with clinical biomarkers to improve postoperative recurrence prediction. We
employ four machine learning algorithms -- Gradient Boosting Machine (GBM),
Random Survival Forest (RSF), CoxBoost, and XGBoost -- and validate model
performance using concordance index (C-index), time-dependent AUC, calibration
curves, and decision curve analysis. Our model demonstrates promising
performance, offering a potential tool for risk stratification and personalized
follow-up planning.

</details>


### [1011] [A Multimodal Deep Learning Framework for Early Diagnosis of Liver Cancer via Optimized BiLSTM-AM-VMD Architecture](https://arxiv.org/abs/2509.01164)
*Cheng Cheng,Zeping Chen,Xavier Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种新的多模态深度学习框架（BiLSTM-AM-VMD），用于早期肝癌诊断，该框架整合了双向LSTM、多头注意力机制和变分模态分解。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种能够整合临床特征、生化标志物和影像衍生变量等异构数据的新型多模态深度学习框架，以提高早期肝癌诊断的准确性和可解释性。

Method: 研究方法是提出并应用一种名为BiLSTM-AM-VMD的新型多模态深度学习框架，该框架结合了双向LSTM、多头注意力机制和变分模态分解。

Result: 实验结果表明，与传统的机器学习模型和基线深度学习模型相比，所提出的BiLSTM-AM-VMD框架在真实世界数据集上表现出优越的性能。

Conclusion: 该研究提出的BiLSTM-AM-VMD框架在早期肝癌诊断方面取得了优于传统方法和基线深度学习模型的性能，并且提高了模型的可解释性。

Abstract: This paper proposes a novel multimodal deep learning framework integrating
bidirectional LSTM, multi-head attention mechanism, and variational mode
decomposition (BiLSTM-AM-VMD) for early liver cancer diagnosis. Using
heterogeneous data that include clinical characteristics, biochemical markers,
and imaging-derived variables, our approach improves both prediction accuracy
and interpretability. Experimental results on real-world datasets demonstrate
superior performance over traditional machine learning and baseline deep
learning models.

</details>


### [1012] [ADMP-GNN: Adaptive Depth Message Passing GNN](https://arxiv.org/abs/2509.01170)
*Yassine Abbahaddou,Fragkiskos D. Malliaros,Johannes F. Lutzeyer,Michalis Vazirgiannis*

Main category: cs.LG

TL;DR: GNNs通常为图中所有节点使用固定数量的消息传递步骤，但我们发现最优的消息传递层数因节点的特征而异。我们提出了ADMP-GNN，一种为每个节点动态调整消息传递层数的框架，以提高性能。


<details>
  <summary>Details</summary>
Motivation: GNNs在图学习任务中很有效，但它们对所有节点使用固定数量的消息传递步骤，忽略了节点多样化的计算需求和特征。最优的消息传递层数因节点的特征而异。

Method: 提出了一种名为ADMP-GNN的新颖框架，该框架能够动态地为每个节点调整消息传递层数。该方法适用于任何遵循消息传递机制的模型。

Result: 在节点分类任务上评估ADMP-GNN，与基线GNN模型相比，性能有所提高。

Conclusion: ADMP-GNN通过为每个节点动态调整消息传递层数，提高了GNN的性能。

Abstract: Graph Neural Networks (GNNs) have proven to be highly effective in various
graph learning tasks. A key characteristic of GNNs is their use of a fixed
number of message-passing steps for all nodes in the graph, regardless of each
node's diverse computational needs and characteristics. Through empirical
real-world data analysis, we demonstrate that the optimal number of
message-passing layers varies for nodes with different characteristics. This
finding is further supported by experiments conducted on synthetic datasets. To
address this, we propose Adaptive Depth Message Passing GNN (ADMP-GNN), a novel
framework that dynamically adjusts the number of message passing layers for
each node, resulting in improved performance. This approach applies to any
model that follows the message passing scheme. We evaluate ADMP-GNN on the node
classification task and observe performance improvements over baseline GNN
models.

</details>


### [1013] [StoxLSTM: A Stochastic Extended Long Short-Term Memory Network for Time Series Forecasting](https://arxiv.org/abs/2509.01187)
*Zihao Wang,Yunjie Li,Lingmin Zan,Zheng Gong,Mengtao Zhu*

Main category: cs.LG

TL;DR: xLSTM的变体StoxLSTM通过整合随机潜在变量到状态空间模型框架中，提高了其捕捉复杂时间动态的能力，并在多个基准数据集上取得了优于最先进方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了进一步提高xLSTM在处理具有未知、复杂和分层动态的真实世界数据集时的表示能力和预测性能。

Method: 提出了一种名为StoxLSTM的随机xLSTM，它将xLSTM整合到状态空间建模框架中，并在xLSTM内部引入了随机潜在变量，通过专门设计的循环块来模拟潜在动态演化。

Result: StoxLSTM在多个研究领域的公开基准数据集上的广泛实验表明，其性能持续优于最先进的基线方法，并具有更好的鲁棒性和更强的泛化能力。

Conclusion: StoxLSTM通过在xLSTM中融入随机潜在变量并将其置于状态空间建模框架中，有效提升了模型捕捉潜在时间模式和依赖关系的能力，并在各种时间序列应用中展现出优越的性能。

Abstract: The Extended Long Short-Term Memory (xLSTM) network has attracted widespread
research interest due to its enhanced capability to model complex temporal
dependencies in diverse time series applications. Despite its success, there is
still potential to further improve its representational capacity and
forecasting performance, particularly on challenging real-world datasets with
unknown, intricate, and hierarchical dynamics. In this work, we propose a
stochastic xLSTM, termed StoxLSTM, that improves the original architecture into
a state space modeling framework by incorporating stochastic latent variables
within xLSTM. StoxLSTM models the latent dynamic evolution through specially
designed recurrent blocks, enabling it to effectively capture the underlying
temporal patterns and dependencies. Extensive experiments on publicly available
benchmark datasets from multiple research communities demonstrate that StoxLSTM
consistently outperforms state-of-the-art baselines with better robustness and
stronger generalization ability.

</details>


### [1014] [Preserving Vector Space Properties in Dimensionality Reduction: A Relationship Preserving Loss Framework](https://arxiv.org/abs/2509.01198)
*Eddi Weinwurm,Alexander Kovalenko*

Main category: cs.LG

TL;DR: 通过最小化高维数据与其低维嵌入之间的关系矩阵（例如Gram或余弦）的差异来保留向量空间属性，从而实现降维。


<details>
  <summary>Details</summary>
Motivation: 降维可能会扭曲向量空间属性（如正交性和线性无关性），这些属性对于跨模态检索、聚类和分类等任务至关重要。

Method: 提出一种关系保持损失（RPL）函数，通过最小化高维数据和其低维嵌入的关系矩阵（例如Gram或余弦）之间的差异来保留这些属性。RPL通过非线性投影训练神经网络，并得到矩阵扰动理论的误差界支持。

Result: RPL在降低嵌入维度方面表现良好，同时在下游任务中基本保留了性能，这可能是因为它保留了关键的向量空间属性。

Conclusion: RPL是一种用于降维的有效损失函数，它通过保持关键的向量空间属性来最小化性能损失，并且该损失函数还可以应用于其他领域，如跨域对齐、迁移学习、知识蒸馏、公平性和不变性、去中心化、图和流形学习以及联邦学习等。

Abstract: Dimensionality reduction can distort vector space properties such as
orthogonality and linear independence, which are critical for tasks including
cross-modal retrieval, clustering, and classification. We propose a
Relationship Preserving Loss (RPL), a loss function that preserves these
properties by minimizing discrepancies between relationship matrices (e.g.,
Gram or cosine) of high-dimensional data and their low-dimensional embeddings.
RPL trains neural networks for non-linear projections and is supported by error
bounds derived from matrix perturbation theory. Initial experiments suggest
that RPL reduces embedding dimensions while largely retaining performance on
downstream tasks, likely due to its preservation of key vector space
properties. While we describe here the use of RPL in dimensionality reduction,
this loss can also be applied more broadly, for example to cross-domain
alignment and transfer learning, knowledge distillation, fairness and
invariance, dehubbing, graph and manifold learning, and federated learning,
where distributed embeddings must remain geometrically consistent.

</details>


### [1015] [Geometric origin of adversarial vulnerability in deep learning](https://arxiv.org/abs/2509.01235)
*Yixiong Ren,Wenkang Du,Jianhui Zhou,Haiping Huang*

Main category: cs.LG

TL;DR: 几何感知深度学习框架通过层级局部训练来优化网络表示，提高对抗鲁棒性，并阐明了其背后的物理机制。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的训练准确性与对抗鲁棒性之间的平衡是一个挑战。

Method: 提出一个几何感知深度学习框架，利用层级局部训练来塑造深度神经网络的内部表示，促进特征空间中的类内紧凑性和类间分离性，从而实现流形平滑和对抗鲁棒性。

Result: 该框架提高了对抗鲁棒性，并且其性能可以通过具有隐藏表示元素之间赫布耦合的能量模型来解释。

Conclusion: 该研究为深度学习的物理学提供了新的见解，并将生物和人工智能系统对齐，同时实现了新信息的整合和表示干扰的减少。

Abstract: How to balance training accuracy and adversarial robustness has become a
challenge since the birth of deep learning. Here, we introduce a geometry-aware
deep learning framework that leverages layer-wise local training to sculpt the
internal representations of deep neural networks. This framework promotes
intra-class compactness and inter-class separation in feature space, leading to
manifold smoothness and adversarial robustness against white or black box
attacks. The performance can be explained by an energy model with Hebbian
coupling between elements of the hidden representation. Our results thus shed
light on the physics of learning in the direction of alignment between
biological and artificial intelligence systems. Using the current framework,
the deep network can assimilate new information into existing knowledge
structures while reducing representation interference.

</details>


### [1016] [What Expressivity Theory Misses: Message Passing Complexity for GNNs](https://arxiv.org/abs/2509.01254)
*Niklas Kemper,Tom Wollschläger,Stephan Günnemann*

Main category: cs.LG

TL;DR: GNN的表达能力理论被认为是分析GNN的主要框架，但作者认为这个方向是错误的。他们提出了消息传递复杂性（MPC）作为替代方案，这是一种量化GNN架构通过消息传递解决任务难度的连续度量，能够更好地反映GNN的实际能力。


<details>
  <summary>Details</summary>
Motivation: 当前GNN分析主要依赖表达能力理论，但该理论存在两个问题：1.对于大多数现实任务，超越基础WL测试的表达能力并非必需。2.表达能力理论的二元表征和理想化假设无法反映GNN的实际能力。

Method: 提出了消息传递复杂性（MPC）作为一种新的衡量标准，它量化了GNN架构通过消息传递解决任务的难度。MPC考虑了实际的局限性，如过压，并保留了表达能力理论中的理论不可能结果。

Result: 通过在基础GNN任务上的广泛验证，MPC的理论预测与经验性能相关，成功解释了架构的成功和失败。

Conclusion: MPC超越了表达能力理论，提供了一个更强大、更细致的框架来理解和改进GNN架构。

Abstract: Expressivity theory, characterizing which graphs a GNN can distinguish, has
become the predominant framework for analyzing GNNs, with new models striving
for higher expressivity. However, we argue that this focus is misguided: First,
higher expressivity is not necessary for most real-world tasks as these tasks
rarely require expressivity beyond the basic WL test. Second, expressivity
theory's binary characterization and idealized assumptions fail to reflect
GNNs' practical capabilities. To overcome these limitations, we propose Message
Passing Complexity (MPC): a continuous measure that quantifies the difficulty
for a GNN architecture to solve a given task through message passing. MPC
captures practical limitations like over-squashing while preserving the
theoretical impossibility results from expressivity theory, effectively
narrowing the gap between theory and practice. Through extensive validation on
fundamental GNN tasks, we show that MPC's theoretical predictions correlate
with empirical performance, successfully explaining architectural successes and
failures. Thereby, MPC advances beyond expressivity theory to provide a more
powerful and nuanced framework for understanding and improving GNN
architectures.

</details>


### [1017] [Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks](https://arxiv.org/abs/2509.01257)
*Andrea Fox,Francesco De Pellegrini,Eitan Altman*

Main category: cs.LG

TL;DR: Edge computing agents use decentralized CMDPs with shared constraints for implicit coordination, improving performance with safe RL.


<details>
  <summary>Details</summary>
Motivation: Existing MARL methods struggle with limited observability and communication in edge computing. This paper addresses the need for decentralized coordination among autonomous agents that must make fast local decisions while competing for shared resources.

Method: Proposes a decentralized framework where each agent solves a constrained Markov decision process (CMDP). Coordination is achieved implicitly through a shared constraint vector that is updated infrequently, acting as a lightweight coordination mechanism. Agents learn policies using safe reinforcement learning to meet both local and global goals.

Result: Demonstrates improved performance over centralized and independent baselines, particularly in large-scale settings, through experimental validation. Theoretical guarantees are established under mild assumptions.

Conclusion: The proposed decentralized framework effectively enables autonomous agents in edge computing to coordinate implicitly via shared constraints, leading to improved performance and adherence to both local and global objectives, especially under challenging conditions of limited observability and communication.

Abstract: In edge computing systems, autonomous agents must make fast local decisions
while competing for shared resources. Existing MARL methods often resume to
centralized critics or frequent communication, which fail under limited
observability and communication constraints. We propose a decentralized
framework in which each agent solves a constrained Markov decision process
(CMDP), coordinating implicitly through a shared constraint vector. For the
specific case of offloading, e.g., constraints prevent overloading shared
server resources. Coordination constraints are updated infrequently and act as
a lightweight coordination mechanism. They enable agents to align with global
resource usage objectives but require little direct communication. Using safe
reinforcement learning, agents learn policies that meet both local and global
goals. We establish theoretical guarantees under mild assumptions and validate
our approach experimentally, showing improved performance over centralized and
independent baselines, especially in large-scale settings.

</details>


### [1018] [Iterative In-Context Learning to Enhance LLMs Abstract Reasoning: The Case-Study of Algebraic Tasks](https://arxiv.org/abs/2509.01267)
*Stefano Fioravanti,Matteo Zavatteri,Roberto Confalonieri,Kamyar Zeinalipour,Paolo Frazzetto,Alessandro Sperduti,Nicolò Navarin*

Main category: cs.LG

TL;DR: LLMs在系统泛化方面存在挑战，尤其是在组合规则和处理分布外样本的推理任务中。本文提出一种迭代示例选择方法，通过构建量身定制的少样本示例集来提高LLM的泛化能力。该方法应用于具有非标准简化规则（改变加法和乘法优先级）的代数表达式求解。结果表明，LLM在此类任务上能力有限，但可以通过迭代式示例选择和显式推理指令来改进。实验发现，某些LLM在提供比测试数据分布更简单的示例时，泛化性能更好。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在系统泛化，特别是涉及组合规则和分布外样本的推理任务中的挑战。

Method: 提出一种迭代示例选择的上下文学习方法，逐步构建少样本示例集以提高模型在特定任务上的性能。将此方法应用于具有非标准简化规则（改变加法和乘法优先级）的代数表达式求解。

Result: LLM在处理非标准代数表达式时能力有限。通过结合迭代式示例选择提示策略和显式推理指令，可以提高LLM的推理能力。部分LLM在提供较简单的示例时，泛化性能优于提供与测试数据分布一致的复杂示例。

Conclusion: 迭代式示例选择策略结合显式推理指令可以提高LLM在具有非标准规则的代数表达式求解任务上的系统泛化能力。提供比测试数据分布更简单的示例可能有助于某些LLM获得更好的泛化性能。

Abstract: LLMs face significant challenges in systematic generalization, particularly
when dealing with reasoning tasks requiring compositional rules and handling
out-of-distribution examples. To address these challenges, we introduce an
in-context learning methodology that improves the generalization capabilities
of general purpose LLMs. Our approach employs an iterative example selection
strategy, which incrementally constructs a tailored set of few-shot examples
optimized to enhance model's performance on a given task. As a proof of
concept, we apply this methodology to the resolution of algebraic expressions
involving non-standard simplification rules, according to which the priority of
addition and multiplication is changed.
  Our findings indicate that LLMs exhibit limited proficiency in these
mathematical tasks. We further demonstrate that LLMs reasoning benefits from
our iterative shot selection prompting strategy integrated with explicit
reasoning instructions. Crucially, our experiments reveal that some LLMs
achieve better generalization performances when prompted with simpler few-shot
examples rather than complex ones following the test data distribution.

</details>


### [1019] [Building surrogate models using trajectories of agents trained by Reinforcement Learning](https://arxiv.org/abs/2509.01285)
*Julen Cestero,Marco Quartulli,Marcello Restelli*

Main category: cs.LG

TL;DR: We propose a new method for efficient sampling in simulated environments using RL-trained policies, outperforming existing methods and enabling surrogate-aided RL on complex simulators.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenge of sample efficiency in surrogate modeling, especially in simulated environments with large state spaces where current sampling methods are less effective.

Method: Proposing a novel method that utilizes policies trained by Reinforcement Learning (RL) to efficiently sample deterministic simulated environments. This method's performance is analyzed and compared against Latin-Hypercube sampling, Active Learning, and Kriging using cross-validation on all sampled datasets.

Result: A mixed dataset combining samples from random agents, expert agents, and agents trained to explore regions of maximum entropy in the state transition distribution yields the best performance across all datasets, indicating a more meaningful state space representation.

Conclusion: The proposed method enhances the state-of-the-art in surrogate modeling for complex simulators and facilitates the application of surrogate-aided RL policy optimization strategies.

Abstract: Sample efficiency in the face of computationally expensive simulations is a
common concern in surrogate modeling. Current strategies to minimize the number
of samples needed are not as effective in simulated environments with wide
state spaces. As a response to this challenge, we propose a novel method to
efficiently sample simulated deterministic environments by using policies
trained by Reinforcement Learning. We provide an extensive analysis of these
surrogate-building strategies with respect to Latin-Hypercube sampling or
Active Learning and Kriging, cross-validating performances with all sampled
datasets. The analysis shows that a mixed dataset that includes samples
acquired by random agents, expert agents, and agents trained to explore the
regions of maximum entropy of the state transition distribution provides the
best scores through all datasets, which is crucial for a meaningful state space
representation. We conclude that the proposed method improves the
state-of-the-art and clears the path to enable the application of
surrogate-aided Reinforcement Learning policy optimization strategies on
complex simulators.

</details>


### [1020] [Equivariant U-Shaped Neural Operators for the Cahn-Hilliard Phase-Field Model](https://arxiv.org/abs/2509.01293)
*Xiao Xue,M. F. P. ten Eikelder,Tianyue Yang,Yiqing Li,Kan He,Shuo Wang,Peter V. Coveney*

Main category: cs.LG

TL;DR: E-UNO，一种具有等变性的U型神经算子，可以学习相场变量的演化，准确预测空间和时间上的变化，并在模拟多尺度行为和物理对称性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统的数值求解器在处理相分离问题时计算成本高且缺乏灵活性，而现有的神经算子在捕捉多尺度行为和物理对称性方面存在不足。本研究旨在开发一种能够克服这些限制的神经算子。

Method: 提出了一种结合了全局谱卷积和多分辨率U型架构的等变U型神经算子（E-UNO），并通过正则化平移等变性来保证物理一致性。

Result: E-UNO在预测精度上优于标准的傅里叶神经算子和U型神经算子基线，尤其是在处理精细尺度和高频结构时表现更佳。该模型能够更好地泛化，需要更少的训练数据，并产生物理上一致的动力学。

Conclusion: E-UNO作为一种能够编码对称性和尺度层级的神经算子，为复杂的相场系统提供了一种高效的替代方案。

Abstract: Phase separation in binary mixtures, governed by the Cahn-Hilliard equation,
plays a central role in interfacial dynamics across materials science and soft
matter. While numerical solvers are accurate, they are often computationally
expensive and lack flexibility across varying initial conditions and
geometries. Neural operators provide a data-driven alternative by learning
solution operators between function spaces, but current architectures often
fail to capture multiscale behavior and neglect underlying physical symmetries.
Here we show that an equivariant U-shaped neural operator (E-UNO) can learn the
evolution of the phase-field variable from short histories of past dynamics,
achieving accurate predictions across space and time. The model combines global
spectral convolution with a multi-resolution U-shaped architecture and
regulates translation equivariance to align with the underlying physics. E-UNO
outperforms standard Fourier neural operator and U-shaped neural operator
baselines, particularly on fine-scale and high-frequency structures. By
encoding symmetry and scale hierarchy, the model generalizes better, requires
less training data, and yields physically consistent dynamics. This establishes
E-UNO as an efficient surrogate for complex phase-field systems.

</details>


### [1021] [Towards Trustworthy Vital Sign Forecasting: Leveraging Uncertainty for Prediction Intervals](https://arxiv.org/abs/2509.01319)
*Li Rong Wang,Thomas C. Henderson,Yew Soon Ong,Yih Yng Ng,Xiuyi Fan*

Main category: cs.LG

TL;DR: 深度学习模型可用于预测生命体征，但由于缺乏可靠的不确定性量化，其在医疗保健领域的应用受到限制。本文提出两种从重建不确定性估计（RUE）推导预测区间（PI）的方法，以提供可解释的、面向不确定性的生命体征预测。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要信任和解释模型输出，而可靠的不确定性量化（特别是校准的预测区间）对于区分有意义的警告和模型噪声至关重要，这阻碍了临床决策。

Method: 提出两种从RUE推导PI的方法：一种是基于高斯联机分布的参数化方法，另一种是基于k近邻（KNN）的非参数化方法。

Result: 在两个大型公共数据集上评估了这些方法，发现在低频数据上高斯联机方法优于基于PI的基线，而在高频数据上KNN方法表现最佳。

Conclusion: RUE导出的PI在提供可解释的、面向不确定性的生命体征预测方面具有临床应用前景。

Abstract: Vital signs, such as heart rate and blood pressure, are critical indicators
of patient health and are widely used in clinical monitoring and
decision-making. While deep learning models have shown promise in forecasting
these signals, their deployment in healthcare remains limited in part because
clinicians must be able to trust and interpret model outputs. Without reliable
uncertainty quantification -- particularly calibrated prediction intervals
(PIs) -- it is unclear whether a forecasted abnormality constitutes a
meaningful warning or merely reflects model noise, hindering clinical
decision-making. To address this, we present two methods for deriving PIs from
the Reconstruction Uncertainty Estimate (RUE), an uncertainty measure
well-suited to vital-sign forecasting due to its sensitivity to data shifts and
support for label-free calibration. Our parametric approach assumes that
prediction errors and uncertainty estimates follow a Gaussian copula
distribution, enabling closed-form PI computation. Our non-parametric approach,
based on k-nearest neighbours (KNN), empirically estimates the conditional
error distribution using similar validation instances. We evaluate these
methods on two large public datasets with minute- and hour-level sampling,
representing high- and low-frequency health signals. Experiments demonstrate
that the Gaussian copula method consistently outperforms conformal prediction
baselines on low-frequency data, while the KNN approach performs best on
high-frequency data. These results underscore the clinical promise of
RUE-derived PIs for delivering interpretable, uncertainty-aware vital sign
forecasts.

</details>


### [1022] [Towards High Data Efficiency in Reinforcement Learning with Verifiable Reward](https://arxiv.org/abs/2509.01321)
*Xinyu Tang,Zhenduo Zhang,Yurou Liu,Wayne Xin Zhao,Zujie Wen,Zhiqiang Zhang,Jun Zhou*

Main category: cs.LG

TL;DR: DEPO是一种数据高效的策略优化方法，通过优化离线和在线数据选择策略，提高了大型推理模型的训练效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有的利用可验证奖励的强化学习（RLVR）方法在扩展时需要大量的计算和数据，导致训练成本高昂且数据效率低下。

Method: DEPO在离线阶段根据多样性、影响力和难度 curated 高质量的训练样本子集。在在线RLVR训练期间，引入样本级可探索性度量来动态过滤探索潜力低的样本，并结合回放机制来训练探索不足的样本。

Result: 在五个推理基准上的实验表明，DEPO在离线和在线数据选择场景中均优于现有方法。在仅使用20%训练数据的情况下，DEPO在AIME24上实现了1.85倍的速度提升，在AIME25上实现了1.66倍的速度提升。

Conclusion: DEPO通过智能数据选择有效降低了大型推理模型的训练成本，并提高了其性能。

Abstract: Recent advances in large reasoning models have leveraged reinforcement
learning with verifiable rewards (RLVR) to improve reasoning capabilities.
However, scaling these methods typically requires extensive rollout computation
and large datasets, leading to high training costs and low data efficiency. To
mitigate this issue, we propose DEPO, a Data-Efficient Policy Optimization
pipeline that combines optimized strategies for both offline and online data
selection. In the offline phase, we curate a high-quality subset of training
samples based on diversity, influence, and appropriate difficulty. During
online RLVR training, we introduce a sample-level explorability metric to
dynamically filter samples with low exploration potential, thereby reducing
substantial rollout computational costs. Furthermore, we incorporate a replay
mechanism for under-explored samples to ensure adequate training, which
enhances the model's final convergence performance. Experiments across five
reasoning benchmarks show that DEPO consistently outperforms existing methods
in both offline and online data selection scenarios. Notably, using only 20% of
the training data, our approach achieves a 1.85 times speed-up on AIME24 and a
1.66 times speed-up on AIME25 compared to GRPO trained on the full dataset.

</details>


### [1023] [Multitask Battery Management with Flexible Pretraining](https://arxiv.org/abs/2509.01323)
*Hong Lu,Jiali Chen,Jingzhao Zhang,Guannan He,Xuebing Han,Minggao Ouyang*

Main category: cs.LG

TL;DR: FMAE是一种灵活的预训练框架，可以处理缺失的电池数据，并能学习跨越数据片段的相互关联。它能从异构数据中学习统一的电池表示，并能以最小的数据和工程投入被不同任务采纳。实验证明，FMAE在五个电池管理任务和十一个电池数据集上持续优于所有特定任务的方法。


<details>
  <summary>Details</summary>
Motivation: 工业规模的电池管理涉及各种类型的任务，例如估计、预测和系统级诊断。每项任务都采用跨越时间尺度、传感器分辨率和数据通道的不同数据。构建特定任务的方法需要大量的数据和工程工作，这限制了智能电池管理的可扩展性。

Method: 提出了一种灵活的掩码自编码器（FMAE）预训练框架，该框架可以处理缺失的电池数据通道，并捕获数据片段之间的相互关联。FMAE能从异构数据中学习统一的电池表示，并能以最小的数据和工程投入被不同任务采纳。

Result: FMAE在五个电池管理任务和十一个电池数据集上持续优于所有特定任务的方法。在剩余寿命预测任务上，FMAE使用的推理数据减少了50倍，同时保持了最先进的结果。此外，当真实世界数据缺少某些信息（如系统电压）时，FMAE仍可应用，且对性能的影响很小，取得了与最佳手工特征相当的结果。

Conclusion: FMAE展示了一条切实可行的途径，可以实现灵活、数据高效的模型，从而简化动态系统的实际多任务管理。

Abstract: Industrial-scale battery management involves various types of tasks, such as
estimation, prediction, and system-level diagnostics. Each task employs
distinct data across temporal scales, sensor resolutions, and data channels.
Building task-specific methods requires a great deal of data and engineering
effort, which limits the scalability of intelligent battery management. Here we
present the Flexible Masked Autoencoder (FMAE), a flexible pretraining
framework that can learn with missing battery data channels and capture
inter-correlations across data snippets. FMAE learns unified battery
representations from heterogeneous data and can be adopted by different tasks
with minimal data and engineering efforts. Experimentally, FMAE consistently
outperforms all task-specific methods across five battery management tasks with
eleven battery datasets. On remaining life prediction tasks, FMAE uses 50 times
less inference data while maintaining state-of-the-art results. Moreover, when
real-world data lack certain information, such as system voltage, FMAE can
still be applied with marginal performance impact, achieving comparable results
with the best hand-crafted features. FMAE demonstrates a practical route to a
flexible, data-efficient model that simplifies real-world multi-task management
of dynamical systems.

</details>


### [1024] [Globally aware optimization with resurgence](https://arxiv.org/abs/2509.01329)
*Wei Bu*

Main category: cs.LG

TL;DR: 利用 resurgence theory 从发散渐近级数中提取全局信息，以指导优化算法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的方法缺乏全局信息，容易收敛到次优解并且对初始化敏感。

Method: 计算小耦合 $g 	o 0$ 的配分函数 $Z(g)$ 的渐近级数，并通过其 Borel 变换的奇点来识别目标值。

Result: Borel 变换的奇点与目标值一一对应，为局部优化器提供全局指导，实现学习率自适应和跳出局部最优。

Conclusion: 该方法理论上基于优化景观的几何结构，为优化问题提供了一种新颖的全局视角。

Abstract: Modern optimization faces a fundamental challenge: local gradient-based
methods provide no global information about the objective function $L$
landscape, often leading to suboptimal convergence and sensitivity to
initialization. We introduce a novel optimization framework that leverages
resurgence theory from complex analysis to extract global structural
information from divergent asymptotic series. Our key insight is that the
factorially divergent perturbative expansions of parameter space partition
functions encode precise information about all critical objective function
value in the landscape through their Borel transform singularities.
  The algorithm works by computing the statistical mechanical partition
function $Z(g) = \int e^{-L(\theta)/g} d\theta$ for small coupling $g\ll 1$,
extracting its asymptotic series coefficients, and identifying Borel plane
singularities that correspond one-to-one with critical objective function
values. These target values provide global guidance to local optimizers,
enabling principled learning rate adaptation and escape from suboptimal
regions. Unlike heuristic adaptive methods, targets are theoretically grounded
in the geometry of the optimization landscape.

</details>


### [1025] [AT Loss: Advanced Torrential Loss Function for Precipitation Forecasting](https://arxiv.org/abs/2509.01348)
*Jaeho Choi,Hyeri Kim,Kwang-Ho Kim,Jaesung Lee*

Main category: cs.LG

TL;DR: 本论文提出了一种新的基于机器学习的降水预测方法，旨在解决传统方法和现有机器学习方法在干旱期预测不准确的问题。


<details>
  <summary>Details</summary>
Motivation: 气候变化背景下，精确降水预测日益重要。现有机器学习方法常依赖现成的损失函数或基于临界成功指数（CSI）进行优化，但CSI在降水低于阈值期间效果不佳。

Method: 提出了一种改进的损失函数（AT loss），通过引入一个简单的惩罚项，并将其转化为二次无约束二元优化（QUBO）问题，然后通过近似过程将其松弛为一个可微分的AT损失函数。

Result: 所提出的AT损失函数通过利普希茨常数、预测性能评估、一致性实验和消融研究证明了其优越性。

Conclusion: 所提出的AT损失函数是一种更有效的优化标准，能够克服现有方法在干旱期预测的局限性。

Abstract: Accurate precipitation forecasting is becoming increasingly important in the
context of climate change. In response, machine learning-based approaches have
recently gained attention as an emerging alternative to traditional methods
such as numerical weather prediction and climate models. Nonetheless, many
recent approaches still rely on off-the-shelf loss functions, and even the more
advanced ones merely involve optimization processes based on the critical
success index (CSI). The problem, however, is that CSI may become ineffective
during extended dry periods when precipitation remains below the threshold,
rendering it less than ideal as a criterion for optimization. To address this
limitation, we introduce a simple penalty expression and reinterpret it as a
quadratic unconstrained binary optimization (QUBO) formulation. Ultimately, the
resulting QUBO formulation is relaxed into a differentiable advanced torrential
(AT) loss function through an approximation process. The proposed AT loss
demonstrates its superiority through the Lipschitz constant, forecast
performance evaluations, consistency experiments, and ablation studies with the
operational model.

</details>


### [1026] [Causal Sensitivity Identification using Generative Learning](https://arxiv.org/abs/2509.01352)
*Soma Bandyopadhyay,Sudeshna Sarkar*

Main category: cs.LG

TL;DR: 提出一种新颖的生成方法来识别因果影响并将其应用于预测任务，通过干预识别因果敏感特征，通过反事实评估因果变化的影响，并利用条件变分自编码器（CVAE）减少混淆偏倚。


<details>
  <summary>Details</summary>
Motivation: 识别对预测结果有因果影响的特征（因果敏感特征）并评估因果变化对结果的影响，以改进预测任务。

Method: 利用条件变分自编码器（CVAE）来识别因果影响并作为生成预测器，通过识别因果敏感特征来减少混淆偏倚。

Result: 通过在GeoLife数据集和亚洲贝叶斯网络上的实验，证明了该方法能够识别因果影响并提高预测性能，例如在时空轨迹预测任务中推荐用户可能访问的下一个地点。

Conclusion: 该方法能够有效识别因果影响，减少混淆偏倚，并提高预测性能，特别是在处理具有因果关系的时空轨迹数据时。

Abstract: In this work, we propose a novel generative method to identify the causal
impact and apply it to prediction tasks. We conduct causal impact analysis
using interventional and counterfactual perspectives. First, applying
interventions, we identify features that have a causal influence on the
predicted outcome, which we refer to as causally sensitive features, and
second, applying counterfactuals, we evaluate how changes in the cause affect
the effect. Our method exploits the Conditional Variational Autoencoder (CVAE)
to identify the causal impact and serve as a generative predictor. We are able
to reduce confounding bias by identifying causally sensitive features. We
demonstrate the effectiveness of our method by recommending the most likely
locations a user will visit next in their spatiotemporal trajectory influenced
by the causal relationships among various features. Experiments on the
large-scale GeoLife [Zheng et al., 2010] dataset and the benchmark Asia
Bayesian network validate the ability of our method to identify causal impact
and improve predictive performance.

</details>


### [1027] [DPF-CM: A Data Processing Framework with Privacy-Preserving Vector Databases for Chinese Medical LLMs Training and Deployment](https://arxiv.org/abs/2509.01354)
*Wei Huang,Anda Cheng,Zhao Zhang,Yinggui Wang*

Main category: cs.LG

TL;DR: DPF-CM框架提高了中文医疗LLM的性能并减少了27%的隐私泄露。它通过链式示例上下文学习策略和基于集合的首选项数据过滤来改进模型训练，并通过隐私保护向量数据库（PPVD）来保护部署期间的隐私。


<details>
  <summary>Details</summary>
Motivation: 现有中文医疗语言模型训练方法侧重于优化训练方法，但对训练数据处理的探索不足。

Method: 提出DPF-CM框架，包含两个模块：1. 针对模型训练的数据处理流程，包括链式示例上下文学习策略和基于集合的首选项数据过滤。2. 针对模型部署的隐私保护方法，提出PPVD，包含模型记忆搜索、高风险数据库构建、安全数据库构建和匹配替换四个阶段。

Result: DPF-CM显著提高了模型准确性，使中文医疗LLM达到开源模型中的最先进性能，并将训练数据隐私泄露减少了27%。

Conclusion: DPF-CM框架通过改进数据处理和隐私保护，有效提升了中文医疗LLM的性能和安全性。

Abstract: Current open-source training pipelines for Chinese medical language models
predominantly emphasize optimizing training methodologies to enhance the
performance of large language models (LLMs), yet lack comprehensive exploration
into training data processing. To address this gap, we propose DPF-CM, a
holistic Data Processing Framework for Chinese Medical LLMs training and
deployment. DPF-CM comprises two core modules. The first module is a data
processing pipeline tailored for model training. Beyond standard data
processing operations, we (1) introduce a chained examples context-learning
strategy to generate question-oriented instructions to mitigate the lack of
instruction content, and (2) implement an ensemble-based filtering mechanism
for preference data curation that averages multiple reward models to suppress
noisy samples. The second module focuses on privacy preservation during model
deployment. To prevent privacy risks from the inadvertent exposure of training
data, we propose a Privacy Preserving Vector Database (PPVD) approach, which
involves model memory search, high-risk database construction, secure database
construction, and match-and-replace, four key stages to minimize privacy
leakage during inference collectively. Experimental results show that DPF-CM
significantly improves model accuracy, enabling our trained Chinese medical LLM
to achieve state-of-the-art performance among open-source counterparts.
Moreover, the framework reduces training data privacy leakage by 27%.

</details>


### [1028] [Learn to Jump: Adaptive Random Walks for Long-Range Propagation through Graph Hierarchies](https://arxiv.org/abs/2509.01381)
*Joël Mathys,Federico Errica*

Main category: cs.LG

TL;DR: 消息传递架构难以充分模拟节点和图预测任务中的长程依赖。我们提出了一种利用分层图结构和自适应随机游走来解决此挑战的新颖方法。我们的方法引入了可学习的转移概率，以决定游走应偏向原始图还是跨分层捷径进行。在一个合成的长程任务上，我们证明了我们的方法可以超过限制仅在原始拓扑上运行的传统方法的理论边界。具体来说，偏向分层的游走可以与原始图上的更长游走达到相同的性能。这些初步发现为在有效捕获长程依赖的同时有效地处理大图提供了一个有前景的方向。


<details>
  <summary>Details</summary>
Motivation: 消息传递架构在处理长程依赖方面存在局限性。

Method: 利用分层图结构和自适应随机游走，引入可学习的转移概率，允许在原始图和分层捷径之间进行选择。

Result: 该方法在合成长程任务上表现优于传统方法，且其游走性能可媲美原始图上的更长游走。

Conclusion: 该方法为高效处理大图和捕获长程依赖提供了一个有前景的方向。

Abstract: Message-passing architectures struggle to sufficiently model long-range
dependencies in node and graph prediction tasks. We propose a novel approach
exploiting hierarchical graph structures and adaptive random walks to address
this challenge. Our method introduces learnable transition probabilities that
decide whether the walk should prefer the original graph or travel across
hierarchical shortcuts. On a synthetic long-range task, we demonstrate that our
approach can exceed the theoretical bound that constrains traditional
approaches operating solely on the original topology. Specifically, walks that
prefer the hierarchy achieve the same performance as longer walks on the
original graph. These preliminary findings open a promising direction for
efficiently processing large graphs while effectively capturing long-range
dependencies.

</details>


### [1029] [Distillation of a tractable model from the VQ-VAE](https://arxiv.org/abs/2509.01400)
*Armin Hadžić,Milan Papez,Tomáš Pevný*

Main category: cs.LG

TL;DR: VQ-VAE 可通过选择高概率的离散潜在变量子集来蒸馏为可处理模型，在保持表达能力的同时实现可处理的概率推断，并在密度估计和条件生成任务中表现出竞争力。


<details>
  <summary>Details</summary>
Motivation: VQ-VAE 具有出色的数据生成能力，但由于潜在空间大，其概率推断被认为难以处理。

Method: 通过选择高概率的潜在变量子集来蒸馏 VQ-VAE，并将其构建为概率电路，以实现可处理的概率推断。

Result: 实验表明，蒸馏后的模型在密度估计和条件生成任务中表现出与 VQ-VAE 相当的性能，证明了 VQ-VAE 并非本质上难以处理。

Conclusion: VQ-VAE 可以被蒸馏成一个可处理的模型，通过选择有意义的潜在变量子集，可以在保持其表达能力的同时实现有效的概率推断。

Abstract: Deep generative models with discrete latent space, such as the
Vector-Quantized Variational Autoencoder (VQ-VAE), offer excellent data
generation capabilities, but, due to the large size of their latent space,
their probabilistic inference is deemed intractable. We demonstrate that the
VQ-VAE can be distilled into a tractable model by selecting a subset of latent
variables with high probabilities. This simple strategy is particularly
efficient, especially if the VQ-VAE underutilizes its latent space, which is,
indeed, very often the case. We frame the distilled model as a probabilistic
circuit, and show that it preserves expressiveness of the VQ-VAE while
providing tractable probabilistic inference. Experiments illustrate competitive
performance in density estimation and conditional generation tasks, challenging
the view of the VQ-VAE as an inherently intractable model.

</details>


### [1030] [Evaluating the stability of model explanations in instance-dependent cost-sensitive credit scoring](https://arxiv.org/abs/2509.01409)
*Matteo Ballegeer,Matthias Bogaert,Dries F. Benoit*

Main category: cs.LG

TL;DR: IDCS分类器在提高成本效益的同时，会显著降低模型解释的稳定性，尤其是在类别不平衡增加的情况下，这在信用评分领域带来了成本优化与可解释性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索实例依赖成本敏感（IDCS）分类器对模型解释稳定性的影响，并评估LIME和SHAP在IDCS模型上的表现，以应对日益增长的监管对透明度的要求。

Method: 本研究通过在四个公开的信用评分数据集上评估IDCS分类器的区分能力和成本效益，并引入新指标以增强跨数据集的可比性。随后，研究者们通过控制重采样来研究SHAP和LIME特征重要性排序在不同类别不平衡程度下的稳定性。

Result: 结果表明，IDCS分类器在提高成本效益方面表现出色，但与传统模型相比，其解释的稳定性显著降低，尤其是在类别不平衡程度增加时，这揭示了信用评分领域中成本优化与可解释性之间的关键权衡。

Conclusion: 尽管IDCS分类器在成本效益方面有优势，但其解释的稳定性较差，尤其是在类别不平衡加剧时。这表明在应用IDCS分类器时，必须解决解释稳定性问题，以确保其成本优势不会被不稳定的解释所抵消，这对于满足日益严格的监管要求至关重要。

Abstract: Instance-dependent cost-sensitive (IDCS) classifiers offer a promising
approach to improving cost-efficiency in credit scoring by tailoring loss
functions to instance-specific costs. However, the impact of such loss
functions on the stability of model explanations remains unexplored in
literature, despite increasing regulatory demands for transparency. This study
addresses this gap by evaluating the stability of Local Interpretable
Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP)
when applied to IDCS models. Using four publicly available credit scoring
datasets, we first assess the discriminatory power and cost-efficiency of IDCS
classifiers, introducing a novel metric to enhance cross-dataset comparability.
We then investigate the stability of SHAP and LIME feature importance rankings
under varying degrees of class imbalance through controlled resampling. Our
results reveal that while IDCS classifiers improve cost-efficiency, they
produce significantly less stable explanations compared to traditional models,
particularly as class imbalance increases, highlighting a critical trade-off
between cost optimization and interpretability in credit scoring. Amid
increasing regulatory scrutiny on explainability, this research underscores the
pressing need to address stability issues in IDCS classifiers to ensure that
their cost advantages are not undermined by unstable or untrustworthy
explanations.

</details>


### [1031] [Accelerating PDE Solvers with Equation-Recast Neural Operator Preconditioning](https://arxiv.org/abs/2509.01416)
*Qiyun Cheng,Md Hossain Sahadath,Huihua Yang,Shaowu Pan,Wei Ji*

Main category: cs.LG

TL;DR: MD-PNOP框架通过将参数偏差的残差重新定义为额外的源项，并将其嵌入迭代PDE求解器中，实现了对参数化PDE求解器的加速，同时保持了物理约束。该框架可以对在单一参数设置下训练的神经网络算子进行外插泛化，无需重新训练，并可将计算时间减少约50%，同时保持完整的保真度。


<details>
  <summary>Details</summary>
Motivation: 传统的偏微分方程（PDE）数值求解器在计算上开销很大，这限制了大规模参数化研究和设计优化。MD-PNOP框架旨在解决这一瓶颈，通过加速求解过程并严格遵守物理约束。

Method: MD-PNOP框架将参数偏差产生的残差视为额外的源项。任何经过训练的神经网络算子都可以用于离线精炼解。该方法直接解决了神经网络算子的外插限制，使得在单一参数设置下训练的神经网络算子能够在外插泛化到广泛的配置而无需重新训练。然后，神经网络算子预测被嵌入到迭代PDE求解器中，作为改进的初始猜测，从而在不牺牲精度的前提下减少收敛迭代次数。

Result: MD-PNOP框架能够对外插泛化在单一参数设置下训练的神经网络算子，且无需重新训练。在使用深度算子网络（DeepONet）和傅立叶神经网络算子（FNO）求解中子输运中的玻尔兹曼输运方程时，MD-PNOP框架在具有异质、正弦和不连续参数分布的情况下，成功加速了求解过程。此外，MD-PNOP在固定源、单群特征值和多群耦合特征值问题上，能够将计算时间减少约50%，同时保持完整的保真度。

Conclusion: MD-PNOP框架成功地加速了参数化PDE求解器，同时保持了物理约束。该方法通过将参数偏差残差作为源项并利用神经网络算子进行预测，实现了无需重新训练的外插泛化。该框架在实际应用中显示出显著的计算时间减少（约50%）和精度保持。

Abstract: The computational overhead of traditional numerical solvers for partial
differential equations (PDEs) remains a critical bottleneck for large-scale
parametric studies and design optimization. We introduce a Minimal-Data
Parametric Neural Operator Preconditioning (MD-PNOP) framework, which
establishes a new paradigm for accelerating parametric PDE solvers while
strictly preserving physical constraints. The key idea is to recast the
residual from parameter deviation as additional source term, where any trained
neural operator can be used to refine the solution in an offline fashion. This
directly addresses the fundamental extrapolation limitation of neural
operators, enabling extrapolative generalization of any neural operator trained
at a single parameter setting across a wide range of configurations without any
retraining. The neural operator predictions are then embedded into iterative
PDE solvers as improved initial guesses, thereby reducing convergence
iterations without sacrificing accuracy. Unlike purely data-driven approaches,
MD-PNOP guarantees that the governing equations remain fully enforced,
eliminating concerns about loss of physics or interpretability. The framework
is architecture-agnostic and is demonstrated using both Deep Operator Networks
(DeepONet) and Fourier Neural Operators (FNO) for Boltzmann transport equation
solvers in neutron transport applications. We demonstrated that neural
operators trained on a single set of constant parameters successfully
accelerate solutions with heterogeneous, sinusoidal, and discontinuous
parameter distributions. Besides, MD-PNOP consistently achieves ~50% reduction
in computational time while maintaining full order fidelity for fixed-source,
single-group eigenvalue, and multigroup coupled eigenvalue problems.

</details>


### [1032] [The Geometry of Nonlinear Reinforcement Learning](https://arxiv.org/abs/2509.01432)
*Nikola Milosevic,Nico Scherf*

Main category: cs.LG

TL;DR: 将奖励最大化、安全探索和内在动机统一为单一的几何框架，作为可实现行为的优化问题。


<details>
  <summary>Details</summary>
Motivation: 将强化学习中的奖励最大化、安全探索和内在动机视为在可实现的长时行为空间中的单一优化问题的不同实例。

Method: 提出一个统一的几何框架，将这些目标视为在环境的可实现长时行为空间中的单一优化问题的实例。

Result: 展示了该框架如何包含鲁棒性、安全、探索和多样性目标，并将经典方法（如策略镜像下降、自然策略梯度和信任区域算法）推广到非线性效用和凸约束。

Conclusion: 该几何框架为理解和解决强化学习中的各种目标提供了一个统一的视角，并指出了几何与深度强化学习交叉领域面临的挑战。

Abstract: Reward maximization, safe exploration, and intrinsic motivation are often
studied as separate objectives in reinforcement learning (RL). We present a
unified geometric framework, that views these goals as instances of a single
optimization problem on the space of achievable long-term behavior in an
environment. Within this framework, classical methods such as policy mirror
descent, natural policy gradient, and trust-region algorithms naturally
generalize to nonlinear utilities and convex constraints. We illustrate how
this perspective captures robustness, safety, exploration, and diversity
objectives, and outline open challenges at the interface of geometry and deep
RL.

</details>


### [1033] [Benchmarking Optimizers for Large Language Model Pretraining](https://arxiv.org/abs/2509.01440)
*Andrei Semenov,Matteo Pagliardini,Martin Jaggi*

Main category: cs.LG

TL;DR: 本文对近期用于优化深度学习模型（尤其是大语言模型）的多种优化技术进行了标准化评估，旨在为实践者提供指导，并为研究者指明未来方向。


<details>
  <summary>Details</summary>
Motivation: 近期大语言模型（LLM）的发展伴随着优化深度学习模型损失函数的新思想和方法，但现有研究的实验协议不统一，难以进行直接比较。

Method: 本研究在一个标准化的LLM预训练场景下，对近期优化技术进行了全面的评估，系统性地调整了模型大小、批大小和训练时长，并对每种方法进行了仔细调整。

Result: 通过对不同场景下优化技术的评估，为实践者提供了选择最佳优化器的指导。

Conclusion: 本研究通过标准化评估和复现性实验，为LLM优化技术的发展和未来研究指明了方向。

Abstract: The recent development of Large Language Models (LLMs) has been accompanied
by an effervescence of novel ideas and methods to better optimize the loss of
deep learning models. Claims from those methods are myriad: from faster
convergence to removing reliance on certain hyperparameters. However, the
diverse experimental protocols used to validate these claims make direct
comparisons between methods challenging. This study presents a comprehensive
evaluation of recent optimization techniques across standardized LLM
pretraining scenarios, systematically varying model size, batch size, and
training duration. Through careful tuning of each method, we provide guidance
to practitioners on which optimizer is best suited for each scenario. For
researchers, our work highlights promising directions for future optimization
research. Finally, by releasing our code and making all experiments fully
reproducible, we hope our efforts can help the development and rigorous
benchmarking of future methods.

</details>


### [1034] [Hierarchical Motion Captioning Utilizing External Text Data Source](https://arxiv.org/abs/2509.01471)
*Clayton Leite,Yu Xiao*

Main category: cs.LG

TL;DR: 本研究提出一种新的运动描述方法，利用大型语言模型生成详细的低级运动描述，并结合检索机制提高运动描述的准确性，尤其适用于未包含在现有数据集中的动作。


<details>
  <summary>Details</summary>
Motivation: 现有运动描述方法需要高阶描述的标注数据，但现有数据集稀缺且缺乏低阶描述。本研究旨在解决此问题。

Method: 提出一个两步分层方法：1. 使用大型语言模型为现有运动-文本数据集中的高阶描述（如“跳跃运动”）生成详细的低阶描述（如“跳跃同时协调手臂张开与腿部开合”），并用这些增强的标注重新训练运动到文本模型。2. 引入检索机制，将生成的低阶描述与外部文本数据源中的高阶描述匹配，并与运动特征结合，生成精确的高阶描述。

Result: 在HumanML3D、KIT和BOTH57M三个数据集上进行了实验，与现有技术M2T-Interpretable相比，本方法在BLEU-1、BLEU-4、CIDEr和ROUGE-L等指标上平均提高了6%到50%。

Conclusion: 本研究提出的方法能够有效利用外部文本知识，显著提高运动描述的准确性，特别是在处理现有数据集未覆盖的运动方面。

Abstract: This paper introduces a novel approach to enhance existing motion captioning
methods, which directly map representations of movement to high-level
descriptive captions (e.g., ``a person doing jumping jacks"). The existing
methods require motion data annotated with high-level descriptions (e.g.,
``jumping jacks"). However, such data is rarely available in existing
motion-text datasets, which additionally do not include low-level motion
descriptions. To address this, we propose a two-step hierarchical approach.
First, we employ large language models to create detailed descriptions
corresponding to each high-level caption that appears in the motion-text
datasets (e.g., ``jumping while synchronizing arm extensions with the opening
and closing of legs" for ``jumping jacks"). These refined annotations are used
to retrain motion-to-text models to produce captions with low-level details.
Second, we introduce a pioneering retrieval-based mechanism. It aligns the
detailed low-level captions with candidate high-level captions from additional
text data sources, and combine them with motion features to fabricate precise
high-level captions. Our methodology is distinctive in its ability to harness
knowledge from external text sources to greatly increase motion captioning
accuracy, especially for movements not covered in existing motion-text
datasets. Experiments on three distinct motion-text datasets (HumanML3D, KIT,
and BOTH57M) demonstrate that our method achieves an improvement in average
performance (across BLEU-1, BLEU-4, CIDEr, and ROUGE-L) ranging from 6% to 50%
compared to the state-of-the-art M2T-Interpretable.

</details>


### [1035] [Prior-Guided Flow Matching for Target-Aware Molecule Design with Learnable Atom Number](https://arxiv.org/abs/2509.01486)
*Jingyuan Zhou,Hao Qian,Shikui Tu,Lei Xu*

Main category: cs.LG

TL;DR: PAFlow是一种新的分子生成模型，通过结合先验相互作用引导和可学习的原子数预测，解决了现有生成模型在稳定性和分子尺寸与蛋白质口袋几何匹配方面的问题，并在交叉对接2020基准测试中取得了新的最先进的结合亲和力。


<details>
  <summary>Details</summary>
Motivation: 旨在生成与目标蛋白具有高结合亲和力的3D分子，以用于新型药物发现。

Method: PAFlow采用高效的流匹配框架来模拟生成过程，并构建了一种新的离散原子类型的条件流匹配形式。它还整合了一个蛋白质-配体相互作用预测器来引导向量场，以及一个基于蛋白质口袋信息的原子数预测器来更好地匹配分子尺寸。

Result: 在交叉对接2020基准测试中，PAFlow在结合亲和力方面取得了新的最先进水平（平均Vina得分高达-8.31），同时保持了良好的分子性质。

Conclusion: PAFlow通过其新颖的目标感知方法，在分子生成质量和与目标蛋白的匹配度方面取得了显著的改进，为结构基础药物设计提供了新的解决方案。

Abstract: Structure-based drug design (SBDD), aiming to generate 3D molecules with high
binding affinity toward target proteins, is a vital approach in novel drug
discovery. Although recent generative models have shown great potential, they
suffer from unstable probability dynamics and mismatch between generated
molecule size and the protein pockets geometry, resulting in inconsistent
quality and off-target effects. We propose PAFlow, a novel target-aware
molecular generation model featuring prior interaction guidance and a learnable
atom number predictor. PAFlow adopts the efficient flow matching framework to
model the generation process and constructs a new form of conditional flow
matching for discrete atom types. A protein-ligand interaction predictor is
incorporated to guide the vector field toward higher-affinity regions during
generation, while an atom number predictor based on protein pocket information
is designed to better align generated molecule size with target geometry.
Extensive experiments on the CrossDocked2020 benchmark show that PAFlow
achieves a new state-of-the-art in binding affinity (up to -8.31 Avg. Vina
Score), simultaneously maintains favorable molecular properties.

</details>


### [1036] [Unsupervised Identification and Replay-based Detection (UIRD) for New Category Anomaly Detection in ECG Signal](https://arxiv.org/abs/2509.01512)
*Zhangyue Shi,Zekai Wang,Yuxuan Li*

Main category: cs.LG

TL;DR: 提出了一种伪重放半监督持续学习框架，用于在处理ECG数据类别不平衡和存储限制的同时，提高异常检测性能。


<details>
  <summary>Details</summary>
Motivation: ECG信号分析在临床实践中广泛应用于识别心脏异常，但存在样本量有限导致的类别不平衡问题以及数据量增长带来的存储负担。本研究旨在提高异常检测性能并解决存储限制。

Method: 提出了一种包含无监督识别和重放检测的伪重放半监督持续学习框架。无监督识别部分采用基于生成对抗网络（GAN）的框架来检测新模式。伪重放策略使用生成器学习数据分布，合成代表先前学习类别的数据，以检测现有模式和新出现的异常。

Result: 在四个公共ECG数据集上进行了验证，实验结果表明该方法在识别新异常方面表现出潜力，同时在检测现有ECG信号方面保持了良好性能。

Conclusion: 所提出的伪重放半监督持续学习框架在处理ECG数据的类别不平衡和存储限制方面是有效的，并且在识别新异常和检测现有ECG信号方面都表现出有前景的结果。

Abstract: In clinical practice, automatic analysis of electrocardiogram (ECG) is widely
applied to identify irregular heart rhythms and other electrical anomalies of
the heart, enabling timely intervention and potentially improving clinical
outcomes. However, due to the limited samples in certain types of ECG signals,
the class imbalance issues pose a challenge for ECG-based detection. In
addition, as the volume of patient data grows, long-term storage of all
historical data becomes increasingly burdensome as training samples to
recognize new patterns and classify existing ECG signals accurately. Therefore,
to enhance the performance of anomaly detection while addressing storage
limitations, we propose a pseudo-replay based semi-supervised continual
learning framework, which consists of two components: unsupervised
identification and replay-based detection. For unsupervised identification, an
unsupervised generative adversarial network (GAN)-based framework is integrated
to detect novel patterns. Besides, instead of directly storing all historical
data, a pseudo replay-based learning strategy is proposed which utilizes a
generator to learn the data distribution for each individual task. When a new
task arises, the generator synthesizes pseudo data representative of previous
learnt classes, enabling the model to detect both the existed patterns and the
newly presented anomalies. The effectiveness of the proposed framework is
validated in four public ECG datasets, which leverages supervised
classification problems for anomaly detection. The experimental results show
that the developed approach is very promising in identifying novel anomalies
while maintaining good performance on detecting existing ECG signals.

</details>


### [1037] [Forward-Only Continual Learning](https://arxiv.org/abs/2509.01533)
*Jiao Chen,Jiayi He,Fangfang Chen,Zuohong Lv,Jianhua Tang*

Main category: cs.LG

TL;DR: FoRo是一种创新的无梯度、仅前向传播的持续学习方法，通过轻量级提示调优和新颖的知识编码机制，在不修改预训练模型的情况下，有效解决了灾难性遗忘问题，降低了计算成本和内存使用。


<details>
  <summary>Details</summary>
Motivation: 灾难性遗忘是持续学习中的核心挑战，特别是在使用预训练模型时。现有方法虽然通过冻结主干并微调少量参数来缓解遗忘，但其基于梯度优化的迭代过程计算量大，不适用于资源受限环境。

Method: FoRo采用仅前向传播、无梯度的持续学习方法。它包括一个轻量级的提示调优策略和一个新颖的知识编码机制。提示嵌入被插入到输入层，并使用协方差矩阵自适应进化策略（CMA-ES）进行优化，以减轻分布偏移并提取高质量的任务表示。然后，通过非线性随机投影和递归最小二乘法将特定任务的知识编码到知识编码矩阵中，从而在不重新访问先前数据的情况下增量更新分类器。

Result: 实验表明，FoRo显著减少了平均遗忘，提高了准确性。由于其仅前向传播的学习方式，FoRo降低了内存使用和运行时间，同时在长任务序列中保持了高知识保留率。

Conclusion: FoRo作为一种有前途的持续学习新方向，特别是在效率和效果都至关重要的实际多媒体应用中，为使用预训练模型进行持续学习提供了新的解决方案。

Abstract: Catastrophic forgetting remains a central challenge in continual learning
(CL) with pre-trained models. While existing approaches typically freeze the
backbone and fine-tune a small number of parameters to mitigate forgetting,
they still rely on iterative error backpropagation and gradient-based
optimization, which can be computationally intensive and less suitable for
resource-constrained environments. To address this, we propose FoRo, a
forward-only, gradient-free continual learning method. FoRo consists of a
lightweight prompt tuning strategy and a novel knowledge encoding mechanism,
both designed without modifying the pre-trained model. Specifically, prompt
embeddings are inserted at the input layer and optimized using the Covariance
Matrix Adaptation Evolution Strategy (CMA-ES), which mitigates distribution
shifts and extracts high-quality task representations. Subsequently,
task-specific knowledge is encoded into a knowledge encoding matrix via
nonlinear random projection and recursive least squares, enabling incremental
updates to the classifier without revisiting prior data. Experiments show that
FoRo significantly reduces average forgetting and improves accuracy. Thanks to
forward-only learning, FoRo reduces memory usage and run time while maintaining
high knowledge retention across long task sequences. These results suggest that
FoRo could serve as a promising direction for exploring continual learning with
pre-trained models, especially in real-world multimedia applications where both
efficiency and effectiveness are critical.

</details>


### [1038] [Graph Contrastive Learning versus Untrained Baselines: The Role of Dataset Size](https://arxiv.org/abs/2509.01541)
*Smayan Khanna,Doruk Efe Gökmen,Risi Kondor,Vincenzo Vitelli*

Main category: cs.LG

TL;DR: 图对比学习（GCL）在图的自监督学习中表现优异，但在数据集大小和任务难度上表现不一，有时甚至不如未训练的基线模型。


<details>
  <summary>Details</summary>
Motivation: 评估图对比学习（GCL）在图的自监督学习中的实际表现，并与未训练的基线模型进行比较，以确定其优势是否依赖于数据集大小和任务难度。

Method: 通过在不同大小的数据集（包括标准数据集和ogbg-molhiv分子数据集）和不同复杂度的合成数据集上进行实验，比较GCL与未训练的图神经网络（GNNs）、多层感知机（MLPs）和手工统计数据的性能。

Result: GCL的优势确实依赖于数据集大小和任务难度。在标准数据集上，未训练的GNNs、MLPs和手工统计数据可以与GCL相媲美甚至超越。在ogbg-molhiv数据集上，GCL在小规模数据上表现落后，但在规模扩大后表现超越，但增长随后趋于平缓。在合成数据集上，GCL的准确性随图数量的对数增长，并且与未训练GNNs的性能差距随任务复杂度而变化。

Conclusion: 数据集大小是GCL在基准测试和实际应用中的关键因素，未来的研究应关注如何设计能克服性能瓶颈的GCL算法。

Abstract: Graph Contrastive Learning (GCL) has emerged as a leading paradigm for self-
supervised learning on graphs, with strong performance reported on standardized
datasets and growing applications ranging from genomics to drug discovery. We
ask a basic question: does GCL actually outperform untrained baselines? We find
that GCL's advantage depends strongly on dataset size and task difficulty. On
standard datasets, untrained Graph Neural Networks (GNNs), simple multilayer
perceptrons, and even handcrafted statistics can rival or exceed GCL. On the
large molecular dataset ogbg-molhiv, we observe a crossover: GCL lags at small
scales but pulls ahead beyond a few thousand graphs, though this gain
eventually plateaus. On synthetic datasets, GCL accuracy approximately scales
with the logarithm of the number of graphs and its performance gap (compared
with untrained GNNs) varies with respect to task complexity. Moving forward, it
is crucial to identify the role of dataset size in benchmarks and applications,
as well as to design GCL algorithms that avoid performance plateaus.

</details>


### [1039] [Feynman-Kac-Flow: Inference Steering of Conditional Flow Matching to an Energy-Tilted Posterior](https://arxiv.org/abs/2509.01543)
*Konstantin Mark,Leonard Galustian,Maximilian P. -P. Kovar,Esther Heid*

Main category: cs.LG

TL;DR: 本研究将能量势能倾斜的思想应用于条件流匹配（CFM）模型，首次实现了Feynman-Kac引导，以满足生成样本的精确控制需求，并在高维空间倾斜分布生成和化学反应过渡态生成（具有正确手性）等具有挑战性的任务上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 在生成模型领域，特别是条件流匹配（CFM）中，实现对生成样本的精确控制（即引导）是一个重要的研究方向。然而，现有的引导方法（如基于梯度的引导、序贯蒙特卡洛引导或Feynman-Kac引导）主要针对扩散模型，尚未扩展到流匹配方法。

Method: 本研究提出了一种将能量势能倾斜（tilting with an energy potential）作为一种引导方式，并首次为CFM推导了Feynman-Kac引导。

Result: 研究通过在合成任务（包括高维空间中的倾斜分布生成）上评估了所提出的Feynman-Kac引导CFM方法。结果表明，该方法在生成具有特定要求的样本方面表现出色，特别是在解决化学反应过渡态生成中具有正确手性的难题上取得了显著进展，克服了现有方法在处理几何约束方面的挑战。

Conclusion: 本研究成功地将Feynman-Kac引导方法扩展到了CFM模型，为生成模型领域提供了一种新的、有效的引导技术，并在解决高维分布生成和化学反应模拟等复杂问题上展现了其潜力。

Abstract: Conditional Flow Matching(CFM) represents a fast and high-quality approach to
generative modelling, but in many applications it is of interest to steer the
generated samples towards precise requirements. While steering approaches like
gradient-based guidance, sequential Monte Carlo steering or Feynman-Kac
steering are well established for diffusion models, they have not been extended
to flow matching approaches yet. In this work, we formulate this requirement as
tilting the output with an energy potential. We derive, for the first time,
Feynman-Kac steering for CFM. We evaluate our approach on a set of synthetic
tasks, including the generation of tilted distributions in a high-dimensional
space, which is a particularly challenging case for steering approaches. We
then demonstrate the impact of Feynman-Kac steered CFM on the previously
unsolved challenge of generated transition states of chemical reactions with
the correct chirality, where the reactants or products can have a different
handedness, leading to geometric constraints of the viable reaction pathways
connecting reactants and products. Code to reproduce this study is avaiable
open-source at https://github.com/heid-lab/fkflow.

</details>


### [1040] [Model Unmerging: Making Your Models Unmergeable for Secure Model Sharing](https://arxiv.org/abs/2509.01548)
*Zihao Wang,Enneng Yang,Lu Yin,Shiwei Liu,Li Shen*

Main category: cs.LG

TL;DR: MergeLock 是一种主动防护机制，通过破坏模型参数使其无法合并，从而直接阻止未经授权的模型合并。它利用 Transformer 模型中注意力机制的对称性，将可逆矩阵应用于 Query-Key (QK) 和 Value-Output (VO) 分支，从而在不改变模型输出的情况下，将其与其它微调模型的共享参数空间区分开。实验表明，MergeLock 可在大多数情况下将合并模型的性能降低 95% 以上，并且难以通过低成本方法恢复。


<details>
  <summary>Details</summary>
Motivation: 随着越来越多的微调模型可用，模型合并的安全问题日益突出，未经授权的合并可能侵犯开发者权利和泄露敏感个人信息。现有方法多侧重于检测，未能有效阻止非法合并。

Method: MergeLock 通过在 Transformer 模型的可逆矩阵应用于 Query-Key (QK) 和 Value-Output (VO) 分支，来破坏模型参数，使其无法合并。此操作在不改变模型输出的前提下，将模型推离其他微调模型的共享参数空间。

Result: MergeLock 可将涉及受保护模型的合并模型的性能降低 95% 以上，并且使用低成本恢复方法难以有效恢复，证明了其有效性和鲁棒性。

Conclusion: MergeLock 是一种有效且鲁棒的主动防护机制，可防止未经授权的模型合并。

Abstract: Model merging leverages multiple finetuned expert models to construct a
multi-task model with low cost, and is gaining increasing attention. However,
as a growing number of finetuned models become publicly available, concerns
about the safety of model merging have emerged. Unauthorized merging may
infringe on developers' rights and risk leaking sensitive personal information.
Most existing methods focus on detecting whether a merged model originates from
a specific source model, but fail to effectively prevent illegal merging. In
this paper, we propose MergeLock, an active protection mechanism that disrupts
model parameters to render them unmergeable, thereby directly preventing
unauthorized model merging. Specifically, leveraging the inherent symmetry of
the attention mechanism in Transformer-based models, we randomly sample two
pairs of invertible matrices and apply them to the Query-Key (QK) and
Value-Output (VO) branches. This transformation keeps the model's output
unchanged while pushing it away from the shared parameter space of other
finetuned models. Extensive experiments across both vision and language tasks
demonstrate that MergeLock can degrade the performance of merged models by over
95% when a protected model is involved in most cases, demonstrating its
effectiveness. Moreover, we further demonstrate that merged models protected by
MergeLock cannot be effectively recovered using low-cost restoration methods,
further enhancing robustness against unauthorized merging. The code is
available at https://github.com/hetailang/Merge-Lock.

</details>


### [1041] [Direct Profit Estimation Using Uplift Modeling under Clustered Network Interference](https://arxiv.org/abs/2509.01558)
*Bram van den Akker*

Main category: cs.LG

TL;DR: 推荐系统中的提升模型常用于优化促销活动，但现有方法未能有效处理“干扰”问题（即对一个物品的干预会影响其他物品的结果）。该研究提出了一种实用的方法，将AddIPW（一种考虑干扰的估计器）作为可微分的学习目标，并结合响应转换技术，直接优化如增量利润等经济效益。仿真结果表明，该方法在干扰效应显著时，显著优于忽略干扰的方法，并能更有效地识别高影响力干预措施，为实现更具盈利能力的激励个性化提供了可行途径。


<details>
  <summary>Details</summary>
Motivation: 标准的提升模型在推荐系统中优化促销活动时，往往无法处理“干扰”问题（即对一个物品的干预会影响其他物品的结果），这会导致在实际市场中产生次优策略。尽管已有如AddIPW等考虑干扰的估计器，但其在提升模型领域的应用和优化策略尚未成熟。

Method: 本研究提出了一种将AddIPW估计器作为可微分学习目标的方法，适用于基于梯度的优化。该框架可以与响应转换技术相结合，直接优化经济效益（如增量利润）。

Result: 通过仿真实验证明，该方法在干扰效应增大时，显著优于忽略干扰的方法。此外，在利润导向的提升策略中应用该框架，能更有效地识别高影响力干预措施。

Conclusion: 该研究成功地将AddIPW估计器整合到提升模型优化中，提供了一种能够处理干扰问题并直接优化经济效益的实用方法，在实际应用中具有提升促销活动效果和盈利能力的潜力。

Abstract: Uplift modeling is a key technique for promotion optimization in recommender
systems, but standard methods typically fail to account for interference, where
treating one item affects the outcomes of others. This violation of the Stable
Unit Treatment Value Assumption (SUTVA) leads to suboptimal policies in
real-world marketplaces. Recent developments in interference-aware estimators
such as Additive Inverse Propensity Weighting (AddIPW) have not found their way
into the uplift modeling literature yet, and optimising policies using these
estimators is not well-established. This paper proposes a practical methodology
to bridge this gap. We use the AddIPW estimator as a differentiable learning
objective suitable for gradient-based optimization. We demonstrate how this
framework can be integrated with proven response transformation techniques to
directly optimize for economic outcomes like incremental profit. Through
simulations, we show that our approach significantly outperforms
interference-naive methods, especially as interference effects grow.
Furthermore, we find that adapting profit-centric uplift strategies within our
framework can yield superior performance in identifying the highest-impact
interventions, offering a practical path toward more profitable incentive
personalization.

</details>


### [1042] [Learning Longitudinal Stress Dynamics from Irregular Self-Reports via Time Embeddings](https://arxiv.org/abs/2509.01569)
*Louis Simon,Mohamed Chetouani*

Main category: cs.LG

TL;DR: 移动和可穿戴传感技术在持续监测情绪、情绪障碍和压力方面发挥着重要作用。然而，缺失数据和不规则的自我报告时间戳给预测人类状态和行为带来了挑战。本研究提出了一种名为 Ema2Vec 的新时间嵌入方法，用于处理不规则间隔的自我报告，并将其应用于纵向压力预测任务。结果表明，Ema2Vec 优于依赖固定日期窗口的标准压力预测方法以及未采用时间感知表示的纵向序列模型。这强调了在建模不规则采样的纵向数据时结合时间嵌入的重要性。


<details>
  <summary>Details</summary>
Motivation: 移动和可穿戴传感技术的广泛采用使得持续和个性化地监测情绪、情绪障碍和压力成为可能。当与生态自我报告问卷相结合时，这些系统为探索人类行为的纵向建模提供了强大的机会。然而，缺失数据和自我报告的不规则时间戳带来了挑战，使得预测人类状态和行为变得困难。

Method: 本研究 investigated the use of time embeddings to capture time dependencies within sequences of Ecological Momentary Assessments (EMA)。我们提出了一种新颖的时间嵌入方法 Ema2Vec，旨在有效处理不规则间隔的自我报告，并在一项新的纵向压力预测任务上对其进行评估。

Result: 我们的方法优于依赖固定大小的每日窗口的标准压力预测基线，以及那些直接在纵向序列上训练而没有时间感知表示的模型。

Conclusion: 这些发现强调了在对不规则采样的纵向数据进行建模时结合时间嵌入的重要性。

Abstract: The widespread adoption of mobile and wearable sensing technologies has
enabled continuous and personalized monitoring of affect, mood disorders, and
stress. When combined with ecological self-report questionnaires, these systems
offer a powerful opportunity to explore longitudinal modeling of human
behaviors. However, challenges arise from missing data and the irregular timing
of self-reports, which make challenging the prediction of human states and
behaviors. In this study, we investigate the use of time embeddings to capture
time dependencies within sequences of Ecological Momentary Assessments (EMA).
We introduce a novel time embedding method, Ema2Vec, designed to effectively
handle irregularly spaced self-reports, and evaluate it on a new task of
longitudinal stress prediction. Our method outperforms standard stress
prediction baselines that rely on fixed-size daily windows, as well as models
trained directly on longitudinal sequences without time-aware representations.
These findings emphasize the importance of incorporating time embeddings when
modeling irregularly sampled longitudinal data.

</details>


### [1043] [One-Shot Clustering for Federated Learning Under Clustering-Agnostic Assumption](https://arxiv.org/abs/2509.01587)
*Maciej Krzysztof Zuziak,Roberto Pellungrini,Salvatore Rinzivillo*

Main category: cs.LG

TL;DR: OCFL是一种一种聚类不可知算法，可以自动检测最早的聚类时刻，通过计算客户梯度之间的余弦距离以及检测模型何时开始收敛的温度测量来实现。


<details>
  <summary>Details</summary>
Motivation: 解决分簇联邦学习（CFL）中的聚类问题，该问题尚未得到充分探索，并且与标准FL的基本假设和设置略有不同。

Method: 提出了一种名为OCFL（One-Shot Clustered Federated Learning）的算法，该算法是聚类不可知的，能够自动检测到最早的合适聚类时机。该算法基于计算客户梯度之间的余弦距离以及一个温度测量，用于检测联邦模型何时开始收敛。

Result: 在五个基准数据集的四十多个不同任务上对各种单次聚类算法进行了实证评估，展示了该方法在以自动化方式执行CFL方面的良好性能，无需调整超参数。

Conclusion: 基于客户梯度的CFL算法在实践中是可行的，并且基于密度的聚类方法在区分不同数据分布上训练的神经网络的损失曲面方面非常有效。此外，通过检查GradCAM生成的本地解释的可行性，可以更深入地了解个性化与本地预测可解释性之间的关系。

Abstract: Federated Learning (FL) is a widespread and well-adopted paradigm of
decentralised learning that allows training one model from multiple sources
without the need to transfer data between participating clients directly. Since
its inception in 2015, it has been divided into numerous subfields that deal
with application-specific issues, such as data heterogeneity or resource
allocation. One such sub-field, Clustered Federated Learning (CFL), deals with
the problem of clustering the population of clients into separate cohorts to
deliver personalised models. Although a few remarkable works have been
published in this domain, the problem remains largely unexplored, as its basic
assumptions and settings differ slightly from those of standard FL. In this
work, we present One-Shot Clustered Federated Learning (OCFL), a
clustering-agnostic algorithm that can automatically detect the earliest
suitable moment for clustering. Our algorithm is based on computing the cosine
distance between the gradients of the clients and a temperature measure that
detects when the federated model starts to converge. We empirically evaluate
our methodology by testing various one-shot clustering algorithms for over
forty different tasks on five benchmark datasets. Our experiments showcase the
good performance of our approach when used to perform CFL in an automated
manner without the need to adjust hyperparameters. We also revisit the
practical feasibility of CFL algorithms based on the gradients of the clients,
providing firm evidence of the high efficiency of density-based clustering
methods when used to differentiate between the loss surfaces of neural networks
trained on different distributions. Moreover, by inspecting the feasibility of
local explanations generated with the help of GradCAM, we can provide more
insights into the relationship between personalisation and the explainability
of local predictions.

</details>


### [1044] [Entropy-Driven Curriculum for Multi-Task Training in Human Mobility Prediction](https://arxiv.org/abs/2509.01613)
*Tianye Fang,Xuanshu Luo,Martin Werner*

Main category: cs.LG

TL;DR: 本文提出一个包含熵驱动课程和多任务学习的统一训练框架，用于解决深度学习方法在人类出行预测中遇到的挑战，例如数据复杂性导致的训练低效和仅预测下一地点忽略隐含因素的问题。熵驱动课程通过 Lempel-Ziv 压缩量化轨迹可预测性，实现从简单到复杂的训练排序，以加速收敛并提升性能。多任务学习同时优化地点预测、移动距离和方向估计，通过互补监督信号学习真实的出行模式并提高预测精度。实验结果表明，该方法在 HuMob 挑战赛中达到了最先进的性能，GEO-BLEU 达到 0.354，DTW 达到 26.15，且收敛速度比无课程学习的方法快 2.92 倍。


<details>
  <summary>Details</summary>
Motivation: 人类出行数据的多样复杂性阻碍了模型的训练，导致梯度更新效率低下和潜在的欠拟合。同时，仅预测下一地点忽略了距离和方向等隐含决定因素，从而导致次优的预测结果。

Method: 本文提出一个统一的训练框架，集成了熵驱动课程学习和多任务学习。熵驱动课程学习策略利用 Lempel-Ziv 压缩量化轨迹的可预测性，并进行从简单到复杂的训练排序，以实现更快的收敛和更高的性能。多任务学习同时优化主要的地点预测以及辅助的移动距离和方向估计，以学习真实的出行模式，并通过互补的监督信号提高预测精度。

Result: 在 HuMob 挑战赛进行的广泛实验表明，所提出的方法在 GEO-BLEU（0.354）和 DTW（26.15）指标上取得了最先进的性能，并且与没有课程学习的训练相比，收敛速度提高了 2.92 倍。

Conclusion: 所提出的集成熵驱动课程学习和多任务学习的统一训练框架，能够有效解决深度学习方法在人类出行预测中遇到的数据复杂性导致的训练低效和忽略隐含因素的问题，从而在 HuMob 挑战赛中取得了最先进的性能和显著的收敛速度提升。

Abstract: The increasing availability of big mobility data from ubiquitous portable
devices enables human mobility prediction through deep learning approaches.
However, the diverse complexity of human mobility data impedes model training,
leading to inefficient gradient updates and potential underfitting. Meanwhile,
exclusively predicting next locations neglects implicit determinants, including
distances and directions, thereby yielding suboptimal prediction results. This
paper presents a unified training framework that integrates entropy-driven
curriculum and multi-task learning to address these challenges. The proposed
entropy-driven curriculum learning strategy quantifies trajectory
predictability based on Lempel-Ziv compression and organizes training from
simple to complex for faster convergence and enhanced performance. The
multi-task training simultaneously optimizes the primary location prediction
alongside auxiliary estimation of movement distance and direction for learning
realistic mobility patterns, and improve prediction accuracy through
complementary supervision signals. Extensive experiments conducted in
accordance with the HuMob Challenge demonstrate that our approach achieves
state-of-the-art performance on GEO-BLEU (0.354) and DTW (26.15) metrics with
up to 2.92-fold convergence speed compared to training without curriculum
learning.

</details>


### [1045] [Effects of Distributional Biases on Gradient-Based Causal Discovery in the Bivariate Categorical Case](https://arxiv.org/abs/2509.01621)
*Tim Schwabe,Moritz Lange,Laurenz Wiskott,Maribel Acosta*

Main category: cs.LG

TL;DR: 梯度学习在因果发现方面有潜力，但易受数据分布偏差影响。本文识别了两种偏差：边际分布不对称和边际分布偏移不对称，并分析了它们对梯度学习方法的影响。文中还提出了控制这些偏差的方法，并通过实证评估展示了如何通过消除竞争来增强模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决梯度基因果发现方法在处理数据分布偏差时的脆弱性问题。

Method: 识别并分析了边际分布不对称和边际分布偏移不对称这两种偏差对梯度基因果发现方法的影响，并提出了相应的控制方法。

Result: 证明了梯度基因果发现模型容易受到这两种偏差的影响，并展示了如何通过消除竞争来提高模型的鲁棒性。

Conclusion: 消除竞争可以使梯度基因果发现模型在面对边际分布偏差时更加鲁棒。

Abstract: Gradient-based causal discovery shows great potential for deducing causal
structure from data in an efficient and scalable way. Those approaches however
can be susceptible to distributional biases in the data they are trained on. We
identify two such biases: Marginal Distribution Asymmetry, where differences in
entropy skew causal learning toward certain factorizations, and Marginal
Distribution Shift Asymmetry, where repeated interventions cause faster shifts
in some variables than in others. For the bivariate categorical setup with
Dirichlet priors, we illustrate how these biases can occur even in controlled
synthetic data. To examine their impact on gradient-based methods, we employ
two simple models that derive causal factorizations by learning marginal or
conditional data distributions - a common strategy in gradient-based causal
discovery. We demonstrate how these models can be susceptible to both biases.
We additionally show how the biases can be controlled. An empirical evaluation
of two related, existing approaches indicates that eliminating competition
between possible causal factorizations can make models robust to the presented
biases.

</details>


### [1046] [Relative Trajectory Balance is equivalent to Trust-PCL](https://arxiv.org/abs/2509.01632)
*Tristan Deleu,Padideh Nouri,Yoshua Bengio,Doina Precup*

Main category: cs.LG

TL;DR: GFlowNets的RTB目标与KL正则化RL方法Trust-PCL等价，强调RTB在KL正则化RL框架下的地位，并展示KL正则化RL方法可实现可比性能。


<details>
  <summary>Details</summary>
Motivation: GFlowNets的RTB目标旨在提高序列生成模型的微调效果，与RL中的KL正则化方法作用相似。

Method: 通过建立GFlowNets与最大熵RL的联系，证明RTB与KL正则化RL方法Trust-PCL之间的等价性。

Result: 证明了RTB与Trust-PCL的等价性，将RTB置于KL正则化RL的理论框架内，并展示了KL正则化RL方法在某示例中达到可比性能。

Conclusion: RTB与KL正则化RL方法（如Trust-PCL）的等价性，为理解RTB提供了新的视角，并表明KL正则化RL方法是提高序列生成模型性能的有效途径。

Abstract: Recent progress in generative modeling has highlighted the importance of
Reinforcement Learning (RL) for fine-tuning, with KL-regularized methods in
particular proving to be highly effective for both autoregressive and diffusion
models. Complementing this line of work, the Relative Trajectory Balance (RTB)
objective was recently introduced in the context of Generative Flow Networks
(GFlowNets) to serve the same role of improving fine-tuning in sequential
generative models. Building on prior work linking GFlowNets and maximum-entropy
RL, we establish in this paper an equivalence between RTB and Trust-PCL, an
off-policy RL method with KL regularization. This equivalence situates RTB
within the broader theoretical landscape of KL-regularized RL, and clarifies
its relationship to earlier methods. Leveraging this insight, we revisit an
illustrative example from the RTB paper and show that KL-regularized RL methods
achieve comparable performance, offering an alternative perspective to what was
previously reported.

</details>


### [1047] [REVELIO -- Universal Multimodal Task Load Estimation for Cross-Domain Generalization](https://arxiv.org/abs/2509.01642)
*Maximilian P. Oppelt,Andreas Foltyn,Nadine R. Lang-Richter,Bjoern M. Eskofier*

Main category: cs.LG

TL;DR: 本研究提出一个多模态数据集，包含真实游戏应用和n-back任务，用于评估和改进任务负荷检测模型的泛化能力。研究人员评估了xLSTM、ConvNeXt和Transformer等端到端模型，并发现多模态方法优于单模态方法，但模型在不同应用域之间的迁移能力仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 现有任务负荷检测模型泛化能力不足，难以在真实世界场景中应用，本研究旨在解决此问题。

Method: 构建包含真实游戏应用和n-back任务的多模态数据集，并利用客观表现、主观评分和任务设计进行负荷标注。评估了xLSTM、ConvNeXt和Transformer等模型在不同模态和应用域的预测性能和跨域泛化能力。

Result: 多模态方法优于单模态方法，但不同模态和模型架构的效果因应用而异。在某一域训练的模型迁移到新应用时性能下降，表明通用负荷估计仍具挑战性。

Conclusion: 研究提供了鲁棒的基线和见解，有助于开发更具泛化能力的任务负荷检测系统，推动人机交互和自适应系统的发展。

Abstract: Task load detection is essential for optimizing human performance across
diverse applications, yet current models often lack generalizability beyond
narrow experimental domains. While prior research has focused on individual
tasks and limited modalities, there remains a gap in evaluating model
robustness and transferability in real-world scenarios. This paper addresses
these limitations by introducing a new multimodal dataset that extends
established cognitive load detection benchmarks with a real-world gaming
application, using the $n$-back test as a scientific foundation. Task load
annotations are derived from objective performance, subjective NASA-TLX
ratings, and task-level design, enabling a comprehensive evaluation framework.
State-of-the-art end-to-end model, including xLSTM, ConvNeXt, and Transformer
architectures are systematically trained and evaluated on multiple modalities
and application domains to assess their predictive performance and cross-domain
generalization. Results demonstrate that multimodal approaches consistently
outperform unimodal baselines, with specific modalities and model architectures
showing varying impact depending on the application subset. Importantly, models
trained on one domain exhibit reduced performance when transferred to novel
applications, underscoring remaining challenges for universal cognitive load
estimation. These findings provide robust baselines and actionable insights for
developing more generalizable cognitive load detection systems, advancing both
research and practical implementation in human-computer interaction and
adaptive systems.

</details>


### [1048] [Distilled Pretraining: A modern lens of Data, In-Context Learning and Test-Time Scaling](https://arxiv.org/abs/2509.01649)
*Sachin Goyal,David Lopez-Paz,Kartik Ahuja*

Main category: cs.LG

TL;DR: Distillation in LLM pretraining improves test-time scaling but harms in-context learning, as shown in bigram models.


<details>
  <summary>Details</summary>
Motivation: To explore the effects of distillation on new LLM paradigms like test-time scaling and in-context learning, which remain underexplored despite distillation's renewed prominence.

Method: The paper shows that pretraining with distillation yields models with better test-time scaling. It also observes that distillation impairs in-context learning capabilities, particularly those modeled via induction heads. To understand these findings, distilled pretraining is studied in a bigram model to isolate the common principal factor.

Result: Models pretrained with distillation show significantly improved test-time scaling. However, this improvement comes at the cost of reduced in-context learning capabilities, especially for induction heads.

Conclusion: Pretraining with distillation offers benefits for test-time scaling but negatively impacts in-context learning. Insights from studying distilled pretraining in a bigram model can guide practitioners in making design choices for pretraining.

Abstract: In the past year, distillation has seen a renewed prominence in large
language model (LLM) pretraining, exemplified by the Llama-3.2 and Gemma model
families. While distillation has historically been shown to improve statistical
modeling, its effects on new paradigms that are key to modern LLMs, such as
test-time scaling and in-context learning, remain underexplored. In this work,
we make three main contributions. First, we show that pretraining with
distillation yields models that exhibit remarkably better test-time scaling.
Second, we observe that this benefit comes with a trade-off: distillation
impairs in-context learning capabilities, particularly the one modeled via
induction heads. Third, to demystify these findings, we study distilled
pretraining in a sandbox of a bigram model, which helps us isolate the common
principal factor behind our observations. Finally, using these insights, we
shed light on various design choices for pretraining that should help
practitioners going forward.

</details>


### [1049] [Reinforcement Learning for Machine Learning Engineering Agents](https://arxiv.org/abs/2509.01684)
*Sherry Yang,Joy He-Yueya,Percy Liang*

Main category: cs.LG

TL;DR: RL增强的弱模型Agent在ML工程任务中优于静态强模型Agent，通过引入考虑行动时长的梯度更新和环境插桩技术解决其局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的ML工程Agent依赖于提示大型语言模型，导致无法通过经验改进。本研究旨在探索使用更小、可通过强化学习（RL）改进的模型来构建Agent，并证明其性能可超越大型但静态的模型。

Method: 提出两种方法来解决RL在Agent构建中的挑战：1. 提出考虑时长的梯度更新，以解决可变时长动作导致的异步策略梯度更新偏差问题，放大高成本高回报的动作。2. 提出环境插桩技术，通过插入打印语句记录Agent的实验进展，从中提取部分奖励信号，以解决仅使用测试集性能作为奖励的局限性，从而为近乎正确的程序提供部分信用。

Result: 在MLEBench上的实验结果表明，使用RL训练的较小模型（Qwen2.5-3B）通过我们提出的方法，在12个Kaggle任务上的平均性能比提示使用较大静态模型（Claude-3.5-Sonnet）的Agent高出22%。

Conclusion: 本研究证明了通过RL进行改进的Agent在ML工程任务中具有超越基于提示的大型静态模型的潜力。通过引入时长感知梯度更新和环境插桩，有效解决了RL在Agent构建中的关键挑战，并在实际任务中取得了显著的性能提升。

Abstract: Existing agents for solving tasks such as ML engineering rely on prompting
powerful language models. As a result, these agents do not improve with more
experience. In this paper, we show that agents backed by weaker models that
improve via reinforcement learning (RL) can outperform agents backed by much
larger, but static models. We identify two major challenges with RL in this
setting. First, actions can take a variable amount of time (e.g., executing
code for different solutions), which leads to asynchronous policy gradient
updates that favor faster but suboptimal solutions. To tackle variable-duration
actions, we propose duration- aware gradient updates in a distributed
asynchronous RL framework to amplify high-cost but high-reward actions. Second,
using only test split performance as a reward provides limited feedback. A
program that is nearly correct is treated the same as one that fails entirely.
To address this, we propose environment instrumentation to offer partial
credit, distinguishing almost-correct programs from those that fail early
(e.g., during data loading). Environment instrumentation uses a separate static
language model to insert print statement to an existing program to log the
agent's experimental progress, from which partial credit can be extracted as
reward signals for learning. Our experimental results on MLEBench suggest that
performing gradient updates on a much smaller model (Qwen2.5-3B) trained with
RL outperforms prompting a much larger model (Claude-3.5-Sonnet) with agent
scaffolds, by an average of 22% across 12 Kaggle tasks.

</details>


### [1050] [Robust Anomaly Detection through Multi-Modal Autoencoder Fusion for Small Vehicle Damage Detection](https://arxiv.org/abs/2509.01719)
*Sara Khan,Mehmed Yüksel,Frank Kirchner*

Main category: cs.LG

TL;DR: 该研究提出了一种基于多模态异常检测的新方法，用于实时检测车辆的磨损和损坏，解决了手动检查效率低和传统图像方法检测底盘损坏的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统车辆磨损检测方法（如手动检查）效率低且易出错，基于图像的方法在实时性和检测底盘损坏方面存在不足。

Method: 提出了一种基于多模态异常检测的新架构，集成了IMU和麦克风等传感器，并开发了多种基于多模态自编码器的模型进行评估，其中一种集成模型在实际应用中表现出色。

Result: 提出的集成多模态模型在ROC-AUC方面达到了92%的性能，证明了其在车辆磨损和损坏实时检测方面的有效性。

Conclusion: 该多模态方法在车辆磨损检测方面表现出色，并且可以扩展到汽车安全和自动驾驶等领域，以增强其功能。

Abstract: Wear and tear detection in fleet and shared vehicle systems is a critical
challenge, particularly in rental and car-sharing services, where minor damage,
such as dents, scratches, and underbody impacts, often goes unnoticed or is
detected too late. Currently, manual inspection methods are the default
approach but are labour intensive and prone to human error. In contrast,
state-of-the-art image-based methods struggle with real-time performance and
are less effective at detecting underbody damage due to limited visual access
and poor spatial coverage. This work introduces a novel multi-modal
architecture based on anomaly detection to address these issues. Sensors such
as IMUs and microphones are integrated into a compact device mounted on the
vehicle's windshield. This approach supports real-time damage detection while
avoiding the need for highly resource-intensive sensors. We developed multiple
variants of multi-modal autoencoder-based architectures and evaluated them
against unimodal and state-of-the-art methods. Our ensemble pooling multi-modal
model achieved the highest performance, with a Receiver Operating
Characteristic-Area Under Curve (ROC-AUC) of 92%, demonstrating its
effectiveness in real-world applications. This approach can also be extended to
other applications, such as improving automotive safety - where it can
integrate with airbag systems for efficient deployment - and helping autonomous
vehicles by complementing other sensors in collision detection.

</details>


### [1051] [Succeed or Learn Slowly: Sample Efficient Off-Policy Reinforcement Learning for Mobile App Control](https://arxiv.org/abs/2509.01720)
*Georgios Papoudakis,Thomas Coste,Jianye Hao,Jun Wang,Kun Shao*

Main category: cs.LG

TL;DR: RL在多轮任务中优化基础模型策略存在稀疏奖励和策略梯度更新的挑战。本文提出SoLS算法，通过对正样本进行直接策略更新，对负样本进行保守、正则化更新，并结合STR（优先学习成功交互）来提高样本效率，在移动应用控制任务中表现优于现有方法，且计算资源消耗更少。


<details>
  <summary>Details</summary>
Motivation: 在多轮任务中使用基础模型进行策略逼近的强化学习（RL）仍然面临挑战，特别是在稀疏奖励和策略梯度更新方面。现有方法在处理负样本时可能损害模型性能。

Method: 本文提出了一种名为“Succeed or Learn Slowly”（SoLS）的新型离策略RL算法。SoLS采用改进的离策略Actor-Critic方法，对正样本应用直接策略更新，对负样本应用保守的、正则化的更新，以防止模型退化。此外，还引入了“Successful Transition Replay”（STR）来优先学习成功的交互。

Result: 在AndroidWorld基准测试中，SoLS显著优于现有方法（至少提高17%），包括提示工程和RL方法。与基于GPT-4o的方法相比，SoLS所需的计算资源明显更少，推理速度快5-60倍。

Conclusion: SoLS算法通过区分正负样本的更新策略并结合优先回放成功交互，能够有效提高基础模型在用户界面导航任务中的样本效率和性能，同时降低计算成本。

Abstract: Reinforcement learning (RL) using foundation models for policy approximations
in multi-turn tasks remains challenging. We identify two main limitations
related to sparse reward settings and policy gradient updates, based on which
we formulate a key insight: updates from positive samples with high returns
typically do not require policy regularisation, whereas updates from negative
samples, reflecting undesirable behaviour, can harm model performance. This
paper introduces Succeed or Learn Slowly (SoLS), a novel off-policy RL
algorithm evaluated on mobile app control tasks. SoLS improves sample
efficiency when fine-tuning foundation models for user interface navigation via
a modified off-policy actor-critic approach, applying direct policy updates for
positive samples and conservative, regularised updates for negative ones to
prevent model degradation. We augment SoLS with Successful Transition Replay
(STR), which prioritises learning from successful interactions, further
improving sample efficiency. We evaluate SoLS on the AndroidWorld benchmark,
where it significantly outperforms existing methods (at least 17% relative
increase), including prompt-engineering and RL approaches, while requiring
substantially fewer computational resources than GPT-4o-based methods with
5-60x faster inference.

</details>


### [1052] [Convolutional Monge Mapping between EEG Datasets to Support Independent Component Labeling](https://arxiv.org/abs/2509.01721)
*Austin Meek,Carlos H. Mendoza-Cardenas,Austin J. Brockmeier*

Main category: cs.LG

TL;DR: 该研究提出了一种扩展的卷积蒙日映射归一化（CMMN）方法，通过改进的源参考频谱计算和可分离的空间时间滤波器，提高了脑电图（EEG）信号处理中独立成分（IC）分类的准确性，尤其是在区分大脑和非大脑IC方面。


<details>
  <summary>Details</summary>
Motivation: 由于传感器、放大器和滤波器的差异，脑电图（EEG）信号容易受到伪影、噪声和表面差异的影响。虽然独立成分分析（ICA）和自动标记独立成分（ICs）有助于去除伪影，但卷积蒙日映射归一化（CMMN）已被证明可以提高深度神经网络在睡眠分期等任务中的表现。本研究旨在通过改进CMMN方法来进一步提高EEG信号处理的性能。

Method: 本研究提出了CMMN方法的一个新扩展，通过两种计算源参考频谱的方法：1）通道平均的barycenter和l1归一化；2）一个将源主题映射到与目标主题具有最接近频谱的主题。该扩展产生了可分离的空间时间滤波器，可用于在具有不同EEG通道数量的数据集之间进行映射。研究将这些滤波器应用于IC分类任务。

Result: 研究表明，所提出的CMMN扩展方法在IC分类任务中，特别是在识别大脑与非大脑IC方面，取得了显著的改进。

Conclusion: 该研究提出的CMMN扩展方法通过改进的频谱归一化和可分离的空间时间滤波器，能够有效处理EEG信号中的差异，提高了IC分类的准确性，为EEG信号的自动伪影去除和分析提供了有价值的工具，并具有临床应用潜力。

Abstract: EEG recordings contain rich information about neural activity but are subject
to artifacts, noise, and superficial differences due to sensors, amplifiers,
and filtering. Independent component analysis and automatic labeling of
independent components (ICs) enable artifact removal in EEG pipelines.
Convolutional Monge Mapping Normalization (CMMN) is a recent tool used to
achieve spectral conformity of EEG signals, which was shown to improve deep
neural network approaches for sleep staging. Here we propose a novel extension
of the CMMN method with two alternative approaches to computing the source
reference spectrum the target signals are mapped to: (1) channel-averaged and
$l_1$-normalized barycenter, and (2) a subject-to-subject mapping that finds
the source subject with the closest spectrum to the target subject. Notably,
our extension yields space-time separable filters that can be used to map
between datasets with different numbers of EEG channels. We apply these filters
in an IC classification task, and show significant improvement in recognizing
brain versus non-brain ICs.
  Clinical relevance - EEG recordings are used in the diagnosis and monitoring
of multiple neuropathologies, including epilepsy and psychosis. While EEG
analysis can benefit from automating artifact removal through independent
component analysis and labeling, differences in recording equipment and context
(the presence of noise from electrical wiring and other devices) may impact the
performance of machine learning models, but these differences can be minimized
by appropriate spectral normalization through filtering.

</details>


### [1053] [BM-CL: Bias Mitigation through the lens of Continual Learning](https://arxiv.org/abs/2509.01730)
*Lucas Mansilla,Rodrigo Echeveste,Camila Gonzalez,Diego H. Milone,Enzo Ferrante*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Biases in machine learning pose significant challenges, particularly when
models amplify disparities that affect disadvantaged groups. Traditional bias
mitigation techniques often lead to a {\itshape leveling-down effect}, whereby
improving outcomes of disadvantaged groups comes at the expense of reduced
performance for advantaged groups. This study introduces Bias Mitigation
through Continual Learning (BM-CL), a novel framework that leverages the
principles of continual learning to address this trade-off. We postulate that
mitigating bias is conceptually similar to domain-incremental continual
learning, where the model must adjust to changing fairness conditions,
improving outcomes for disadvantaged groups without forgetting the knowledge
that benefits advantaged groups. Drawing inspiration from techniques such as
Learning without Forgetting and Elastic Weight Consolidation, we reinterpret
bias mitigation as a continual learning problem. This perspective allows models
to incrementally balance fairness objectives, enhancing outcomes for
disadvantaged groups while preserving performance for advantaged groups.
Experiments on synthetic and real-world image datasets, characterized by
diverse sources of bias, demonstrate that the proposed framework mitigates
biases while minimizing the loss of original knowledge. Our approach bridges
the fields of fairness and continual learning, offering a promising pathway for
developing machine learning systems that are both equitable and effective.

</details>


### [1054] [Communication-Aware Knowledge Distillation for Federated LLM Fine-Tuning over Wireless Networks](https://arxiv.org/abs/2509.01750)
*Xinlu Zhang,Na Yan,Yang Su,Yansha Deng,Toktam Mahmoodi*

Main category: cs.LG

TL;DR: 本文提出了一种用于联邦大语言模型（LLM）的高效通信蒸馏方法，通过自适应Top-klogit选择和聚合，以及LoRA适应的隐藏层投影，在减少通信开销约50%的同时，提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统的联邦学习（FL）参数共享方法通信开销大且难以适应异构模型。虽然联邦蒸馏通信开销较低，但LLM的logit维度高，对带宽有限的客户端构成挑战。

Method: 1. 自适应Top-klogit选择机制：根据实时通信条件动态稀疏化logits。2. 自适应logits聚合：解决稀疏化带来的维度不一致性问题，避免传统零填充方法的不足。3. LoRA适应的隐藏层投影：将LLM的隐藏层投影纳入蒸馏损失，进一步降低通信开销并丰富表示。

Result: 实验结果表明，所提出的方案相比基线方法取得了更优越的性能，同时通信开销降低了约50%。

Conclusion: 所提出的联邦LLM蒸馏方法在通信效率和模型性能方面均优于现有技术，为在资源受限环境下进行联邦LLM训练提供了有效的解决方案。

Abstract: Federated learning (FL) for large language models (LLMs) offers a
privacy-preserving scheme, enabling clients to collaboratively fine-tune
locally deployed LLMs or smaller language models (SLMs) without exchanging raw
data. While parameter-sharing methods in traditional FL models solves number of
technical challenges, they still incur high communication overhead and struggle
with adapting to heterogeneous model architectures. Federated distillation, a
framework for mutual knowledge transfer via shared logits, typically offers
lower communication overhead than parameter-sharing methods. However,
transmitting logits from LLMs remains challenging for bandwidth-limited clients
due to their high dimensionality. In this work, we focus on a federated LLM
distillation with efficient communication overhead. To achieve this, we first
propose an adaptive Top-k logit selection mechanism, dynamically sparsifying
logits according to real-time communication conditions. Then to tackle the
dimensional inconsistency introduced by the adaptive sparsification, we design
an adaptive logits aggregation scheme, effectively alleviating the artificial
and uninformative inputs introduced by conventional zero-padding methods.
Finally, to enhance the distillation effect, we incorporate LoRA-adapted
hidden-layer projection from LLM into the distillation loss, reducing the
communication overhead further while providing richer representation.
Experimental results demonstrate that our scheme achieves superior performance
compared to baseline methods while effectively reducing communication overhead
by approximately 50%.

</details>


### [1055] [Toward a Unified Benchmark and Taxonomy of Stochastic Environments](https://arxiv.org/abs/2509.01793)
*Aryan Amit Barsainyan,Jing Yu Lim,Dianbo Liu*

Main category: cs.LG

TL;DR: RL在Atari100k等基准测试中表现出色，但在现实世界条件下鲁棒性有限。基于模型的方法在具有真实随机性和部分可观测性的环境中存在挑战，但现有基准测试未能充分捕捉这些问题。为了解决这个差距，我们引入了STARI基准测试，它包含了各种随机效应，并能对不同形式的不确定性下的RL方法进行严格评估。此外，我们提出了一个RL环境随机性分类法，为分析和比较方法提供了一个统一的框架。


<details>
  <summary>Details</summary>
Motivation: RL代理在现实世界条件下的鲁棒性有限，现有基准测试未能充分捕捉随机性和部分可观测性等挑战。

Method: 引入STARI基准测试，包含各种随机效应，并提出一个RL环境随机性分类法。

Result: STARI基准测试和随机性分类法为评估和比较RL方法在不同不确定性条件下的性能提供了统一框架。

Conclusion: STARI基准测试和随机性分类法旨在解决现有RL基准测试的局限性，推动RL方法在更现实的环境中得到更严格的评估。

Abstract: Reinforcement Learning (RL) agents have achieved strong results on benchmarks
such as Atari100k, yet they remain limited in robustness to real-world
conditions. Model-Based RL approaches that rely on learned World Models often
struggle in environments with true stochasticity and partial observability,
despite their theoretical grounding in POMDPs. Current benchmarks rarely
capture these challenges, focusing instead on deterministic or overly
simplified settings, and the lack of a clear taxonomy of stochasticity further
hampers systematic evaluation. To address this gap, we introduce STORI
(STOchastic-ataRI), a benchmark that incorporates diverse stochastic effects
and enables rigorous assessment of RL methods under varied forms of
uncertainty. In addition, we propose a taxonomy of stochasticity in RL
environments, providing a unified framework for analyzing and comparing
approaches.

</details>


### [1056] [A Multi-target Bayesian Transformer Framework for Predicting Cardiovascular Disease Biomarkers during Pandemics](https://arxiv.org/abs/2509.01794)
*Trusting Inekwe,Emmanuel Agu,Winnie Mkandawire,Andres Colubri*

Main category: cs.LG

TL;DR: 该研究提出了一种名为 MBT-CB 的多目标贝叶斯 Transformer 模型，用于从电子健康记录 (EHR) 中预测心血管疾病 (CVD) 生物标志物（LDL-C、HbA1c、BMI 和 SysBP），能够同时捕捉生物标志物之间的相互依赖性、时间模式和预测不确定性。


<details>
  <summary>Details</summary>
Motivation: COVID-19 大流行扰乱了全球医疗系统，对慢性病患者（如心血管疾病 CVD）产生了不成比例的影响。这些干扰通过延迟护理和行为改变，影响了关键的 CVD 生物标志物，包括 LDL 胆固醇 (LDL-C)、HbA1c、BMI 和收缩压 (SysBP)。因此，准确模拟这些变化对于预测疾病进展和指导预防性护理至关重要。然而，先前的工作尚未解决使用机器学习 (ML) 从电子健康记录 (EHR) 中进行 CVD 生物标志物多目标预测的问题，同时有效地捕捉生物标志物相互依赖性、时间模式和预测不确定性。

Method: 提出了一种名为 MBT-CB 的多目标贝叶斯 Transformer (MBT) 模型，该模型基于预训练的 BERT Transformer 框架，能够从 EHR 数据中联合预测 LDL-C、HbA1c、BMI 和 SysBP 这几种 CVD 生物标志物。该模型利用了贝叶斯变分推断来估计不确定性，利用嵌入来捕捉时间关系，并利用 DeepMTR 模型来捕捉生物标志物之间的相互关系。

Result: 研究使用来自马萨诸塞州中部 3,390 例 CVD 患者记录（304 名独特患者）的真实 EHR 数据对 MBT-CB 进行了评估。结果显示，MBT-CB 优于包括其他基于 BERT 的 ML 模型在内的综合基线模型，其平均绝对误差 (MAE) 为 0.00887，均方根误差 (RMSE) 为 0.0135，均方误差 (MSE) 为 0.00027。此外，该模型通过其注意力机制和嵌入机制有效捕捉了数据和模型的不确定性、患者生物标志物之间的相互关系以及时间动态。

Conclusion: MBT-CB 的出色性能及其有效捕捉不确定性、生物标志物相互依赖性和时间动态的能力，凸显了其在疫情期间改善 CVD 生物标志物预测和支持临床决策方面的潜力。

Abstract: The COVID-19 pandemic disrupted healthcare systems worldwide,
disproportionately impacting individuals with chronic conditions such as
cardiovascular disease (CVD). These disruptions -- through delayed care and
behavioral changes, affected key CVD biomarkers, including LDL cholesterol
(LDL-C), HbA1c, BMI, and systolic blood pressure (SysBP). Accurate modeling of
these changes is crucial for predicting disease progression and guiding
preventive care. However, prior work has not addressed multi-target prediction
of CVD biomarker from Electronic Health Records (EHRs) using machine learning
(ML), while jointly capturing biomarker interdependencies, temporal patterns,
and predictive uncertainty. In this paper, we propose MBT-CB, a Multi-target
Bayesian Transformer (MBT) with pre-trained BERT-based transformer framework to
jointly predict LDL-C, HbA1c, BMI and SysBP CVD biomarkers from EHR data. The
model leverages Bayesian Variational Inference to estimate uncertainties,
embeddings to capture temporal relationships and a DeepMTR model to capture
biomarker inter-relationships. We evaluate MBT-CT on retrospective EHR data
from 3,390 CVD patient records (304 unique patients) in Central Massachusetts
during the Covid-19 pandemic. MBT-CB outperformed a comprehensive set of
baselines including other BERT-based ML models, achieving an MAE of 0.00887,
RMSE of 0.0135 and MSE of 0.00027, while effectively capturing data and model
uncertainty, patient biomarker inter-relationships, and temporal dynamics via
its attention and embedding mechanisms. MBT-CB's superior performance
highlights its potential to improve CVD biomarker prediction and support
clinical decision-making during pandemics.

</details>


### [1057] [When LLM Meets Time Series: Can LLMs Perform Multi-Step Time Series Reasoning and Inference](https://arxiv.org/abs/2509.01822)
*Wen Ye,Jinbo Liu,Defu Cao,Wei Yang,Yan Liu*

Main category: cs.LG

TL;DR: 该论文提出了TSAIA Benchmark，一个用于评估大型语言模型（LLMs）在时间序列分析任务中表现的基准数据集，并评估了八种最先进的LLMs，揭示了它们在处理复杂时间序列分析工作流程方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了推动大型语言模型在时间序列分析领域的应用，特别是解决复杂推理和多步骤分析的挑战，需要一个严格的基准数据集来评估其能力。

Method: 通过调研20多篇学术论文，确定了33个真实世界的时间序列分析任务，构建了包含从约束感知预测到异常检测等多种任务的TSAIA Benchmark。该基准采用动态且可扩展的问题生成器，并为不同任务设置了特定的成功标准和推理质量指标。最后，使用统一的评估协议对八种最先进的LLMs进行了评估。

Result: 评估结果显示，当前最先进的大型语言模型在组装复杂的时间序列分析工作流程方面存在局限性，表明需要专门的方法论来进行领域特定的适应。

Conclusion: TSAIA Benchmark的提出和评估结果强调了在时间序列分析领域，大型语言模型的能力仍有待提高，并且需要进一步的研究来开发能够处理复杂时间序列任务的专门方法。

Abstract: The rapid advancement of Large Language Models (LLMs) has sparked growing
interest in their application to time series analysis tasks. However, their
ability to perform complex reasoning over temporal data in real-world
application domains remains underexplored. To move toward this goal, a first
step is to establish a rigorous benchmark dataset for evaluation. In this work,
we introduce the TSAIA Benchmark, a first attempt to evaluate LLMs as
time-series AI assistants. To ensure both scientific rigor and practical
relevance, we surveyed over 20 academic publications and identified 33
real-world task formulations. The benchmark encompasses a broad spectrum of
challenges, ranging from constraint-aware forecasting to anomaly detection with
threshold calibration: tasks that require compositional reasoning and
multi-step time series analysis. The question generator is designed to be
dynamic and extensible, supporting continuous expansion as new datasets or task
types are introduced. Given the heterogeneous nature of the tasks, we adopt
task-specific success criteria and tailored inference-quality metrics to ensure
meaningful evaluation for each task. We apply this benchmark to assess eight
state-of-the-art LLMs under a unified evaluation protocol. Our analysis reveals
limitations in current models' ability to assemble complex time series analysis
workflows, underscoring the need for specialized methodologies for
domain-specific adaptation. Our benchmark is available at
https://huggingface.co/datasets/Melady/TSAIA, and the code is available at
https://github.com/USC-Melady/TSAIA.

</details>


### [1058] [Goal-Conditioned Reinforcement Learning for Data-Driven Maritime Navigation](https://arxiv.org/abs/2509.01838)
*Vaishnav Vaidheeswaran,Dilith Jayakody,Samruddhi Mulay,Anand Lo,Md Mahbub Alam,Gabriel Spadon*

Main category: cs.LG

TL;DR: 本文提出了一种基于强化学习的航线规划方法，利用大规模海事数据和交通图，实现了跨多个起终点、适应不同网格分辨率的航线规划，并考虑了燃油效率、时间和风阻等因素。实验证明，动作掩码和正向奖励有助于提升策略性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有船舶路径规划研究在多起点-终点泛化能力和利用大规模交通图方面的不足。

Method: 提出一种强化学习解决方案，使用AIS交通图和ERA5风场数据，让智能体在连续观察和多离散动作空间中学习选择方向和速度。通过结合Proximal Policy Optimization、循环网络、无效动作掩码和探索策略进行实验。

Result: 在圣劳伦斯湾进行了演示，并评估了不同配置下的策略性能。实验结果表明，动作掩码显著提高了策略性能，而正面奖励的补充也带来了额外的收益。

Conclusion: 所提出的强化学习方法能够有效地规划跨多个起终点的航线，并适应不同的环境约束，同时优化燃油效率、时间和风阻。动作掩码和正向奖励是提升模型性能的关键因素。

Abstract: Routing vessels through narrow and dynamic waterways is challenging due to
changing environmental conditions and operational constraints. Existing
vessel-routing studies typically fail to generalize across multiple
origin-destination pairs and do not exploit large-scale, data-driven traffic
graphs. In this paper, we propose a reinforcement learning solution for big
maritime data that can learn to find a route across multiple origin-destination
pairs while adapting to different hexagonal grid resolutions. Agents learn to
select direction and speed under continuous observations in a multi-discrete
action space. A reward function balances fuel efficiency, travel time, wind
resistance, and route diversity, using an Automatic Identification System
(AIS)-derived traffic graph with ERA5 wind fields. The approach is demonstrated
in the Gulf of St. Lawrence, one of the largest estuaries in the world. We
evaluate configurations that combine Proximal Policy Optimization with
recurrent networks, invalid-action masking, and exploration strategies. Our
experiments demonstrate that action masking yields a clear improvement in
policy performance and that supplementing penalty-only feedback with positive
shaping rewards produces additional gains.

</details>


### [1059] [Optimizing In-Context Learning for Efficient Full Conformal Prediction](https://arxiv.org/abs/2509.01840)
*Weicao Deng,Sangwoo Park,Min Li,Osvaldo Simeone*

Main category: cs.LG

TL;DR: CP的两种主要变体（SCP和FCP）存在数据效率和计算复杂度方面的局限性。SCP因数据集划分而效率低下，FCP虽提高数据效率但需要复杂的重训。现有的元学习或ICL方法虽有改善，但未针对CP进行优化，可能导致预测集过大。本研究提出了一种高效的FCP框架E-ICL+FCP，使用基于Transformer的ICL模型和CP感知损失，通过模拟重训来保留覆盖率，同时降低了效率低下和计算开销。实验表明E-ICL+FCP在效率-覆盖率权衡方面优于SCP和FCP基线。


<details>
  <summary>Details</summary>
Motivation: 在可信赖的AI中，可靠的不确定性量化至关重要。CP提供了具有无分布覆盖保证的预测集，但其两种主要变体SCP和FCP存在互补的局限性：SCP数据效率低，FCP重训复杂。现有的元学习或ICL方法虽然部分缓解了这些问题，但训练过程并未专门针对CP进行优化，可能导致预测集过大。因此，需要一种能够保留CP覆盖保证，同时提高数据效率并降低计算开销的解决方案。

Method: 提出了一种高效的、基于ICL的FCP框架（E-ICL+FCP）。该框架采用基于Transformer的、排列不变的ICL模型，并使用CP感知损失进行训练。通过模拟FCP所需的多次重训过程，而无需实际进行重训，从而在保留覆盖率的同时，显著降低了效率低下和计算开销。

Result: 实验结果表明，E-ICL+FCP在保持覆盖率的同时，在数据效率和计算开销方面均优于现有的SCP和FCP基线方法。该方法实现了比现有SCP和FCP基线更好的效率-覆盖率权衡。

Conclusion: E-ICL+FCP框架通过使用基于Transformer的ICL模型和CP感知损失，成功地模拟了FCP所需的多次重训，从而在不牺牲覆盖率保证的前提下，显著提高了数据效率并降低了计算复杂度。该方法在合成和实际任务上均表现出优于现有SCP和FCP基线方法的效率-覆盖率权衡能力，为可信赖AI中的不确定性量化提供了一种更优的解决方案。

Abstract: Reliable uncertainty quantification is critical for trustworthy AI. Conformal
Prediction (CP) provides prediction sets with distribution-free coverage
guarantees, but its two main variants face complementary limitations. Split CP
(SCP) suffers from data inefficiency due to dataset partitioning, while full CP
(FCP) improves data efficiency at the cost of prohibitive retraining
complexity. Recent approaches based on meta-learning or in-context learning
(ICL) partially mitigate these drawbacks. However, they rely on training
procedures not specifically tailored to CP, which may yield large prediction
sets. We introduce an efficient FCP framework, termed enhanced ICL-based FCP
(E-ICL+FCP), which employs a permutation-invariant Transformer-based ICL model
trained with a CP-aware loss. By simulating the multiple retrained models
required by FCP without actual retraining, E-ICL+FCP preserves coverage while
markedly reducing both inefficiency and computational overhead. Experiments on
synthetic and real tasks demonstrate that E-ICL+FCP attains superior
efficiency-coverage trade-offs compared to existing SCP and FCP baselines.

</details>


### [1060] [GradES: Significantly Faster Training in Transformers with Gradient-Based Early Stopping](https://arxiv.org/abs/2509.01842)
*Qifu Wen,Xi Zeng,Zihan Zhou,Shuaijun Liu,Mehdi Hosseinzadeh,Reza Rawassizadeh*

Main category: cs.LG

TL;DR: GradES是一种基于梯度的早期停止方法，通过在训练过程中监控Transformer组件（如注意力投影和前馈层矩阵）的梯度下降情况，并在梯度低于预设阈值时单独冻结这些参数，从而加速训练并提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的早期停止方法在大型Transformer模型上计算成本高昂，因为它需要对整个模型进行验证推断。本文旨在提出一种更高效的早期停止方法。

Method: GradES通过跟踪Transformer组件（注意力投影和前馈层矩阵）在反向传播过程中梯度的幅度。当某个投影矩阵的梯度低于收敛阈值τ时，该矩阵将被单独排除在后续更新之外，从而避免了昂贵的验证过程，并允许收敛缓慢的矩阵继续学习。

Result: GradES能够将训练时间加速1.57--7.22倍，同时通过在参数收敛时进行策略性冻结，有效防止过拟合，将平均准确率提高1.2%。

Conclusion: GradES是一种有效的早期停止方法，通过在组件级别监控梯度来优化训练过程，在加速训练和提高模型泛化能力方面取得了显著成效。

Abstract: Early stopping monitors global validation loss and halts all parameter
updates simultaneously, which is computationally costly for large transformers
due to the extended time required for validation inference. We propose GradES,
a novel gradient-based early stopping approach that operates within transformer
components (attention projections and Feed-Forward layer matrices). We found
that different components converge at varying rates during fine-tuning. GradES
tracks the magnitude of gradients in backpropagation for these matrices during
training. When a projection matrix's gradients fall below a convergence
threshold $\tau$, we exclude that projection matrix from further updates
individually, eliminating costly validation passes while allowing slow
converging matrices to continue learning. By strategically freezing parameters
when their gradients converge, GradES speeds up training time by
1.57--7.22$\times$ while simultaneously enhancing generalization through early
prevention of overfitting, resulting in 1.2% higher average accuracy.

</details>


### [1061] [Preserving Bilinear Weight Spectra with a Signed and Shrunk Quadratic Activation Function](https://arxiv.org/abs/2509.01874)
*Jason Abohwo,Thomas Mosen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Understanding the inner workings of machine learning models is critical for
ensuring their reliability and robustness. Whilst many techniques in
mechanistic interpretability focus on activation driven analyses, being able to
derive meaningful features directly from the weights of a neural network would
provide greater guarantees and more computational efficiency. Existing
techniques for analyzing model features through weights suffer from drawbacks
such as reduced performance and data inefficiency. In this paper, we introduce
Signed Quadratic Shrink (SQS), an activation function designed to allow Gated
Linear Units (GLUs) to learn interpretable features without these drawbacks.
Our experimental results show that SQS achieves performance competitive with
state-of-the-art activation functions whilst enabling weight-based
interpretability

</details>


### [1062] [Deep Reinforcement Learning for Real-Time Drone Routing in Post-Disaster Road Assessment Without Domain Knowledge](https://arxiv.org/abs/2509.01886)
*Huatian Gong,Jiuh-Biing Sheu,Zheng Wang,Xiaoguang Yang,Ran Yan*

Main category: cs.LG

TL;DR: 本研究提出了一种基于注意力机制的编码器-解码器模型（AEDM），用于灾后道路损害评估中的实时无人机路径规划。该模型利用深度强化学习，无需算法设计知识即可确定高质量的评估路径，并通过网络转换和合成数据生成解决了传统方法的局限性。实验结果表明，AEDM在解决方案质量上优于商业求解器（16%-69%），并在推理速度上实现了实时（1-2秒），远超传统方法的计算时间（100-2000秒）。AEDM在不同规模、无人机数量和时间限制下均表现出良好的泛化能力，尤其适用于需要快速决策以拯救生命的灾害响应场景。


<details>
  <summary>Details</summary>
Motivation: 传统道路损害评估方法在响应灾害时计算时间过长且需要领域知识，不适用于时间敏感的场景。

Method: 提出一种基于注意力机制的编码器-解码器模型（AEDM），利用深度强化学习来规划无人机评估路线。开发了网络转换方法将链接型问题转化为节点型问题，并使用合成数据生成技术解决数据集稀缺问题。使用策略优化（POMO）和多任务学习进行模型训练。

Result: AEDM的解决方案质量比商业求解器高16%-69%，推理速度为1-2秒，而传统方法需要100-2000秒。模型在不同参数和真实路网上均表现出良好的泛化能力。

Conclusion: AEDM在计算效率和解决方案质量之间取得了良好平衡，特别适用于时间紧迫的灾害响应应用，能够实现快速决策以拯救生命。

Abstract: Rapid post-disaster road damage assessment is critical for effective
emergency response, yet traditional optimization methods suffer from excessive
computational time and require domain knowledge for algorithm design, making
them unsuitable for time-sensitive disaster scenarios. This study proposes an
attention-based encoder-decoder model (AEDM) for real-time drone routing
decision in post-disaster road damage assessment. The method employs deep
reinforcement learning to determine high-quality drone assessment routes
without requiring algorithmic design knowledge. A network transformation method
is developed to convert link-based routing problems into equivalent node-based
formulations, while a synthetic road network generation technique addresses the
scarcity of large-scale training datasets. The model is trained using policy
optimization with multiple optima (POMO) with multi-task learning capabilities
to handle diverse parameter combinations. Experimental results demonstrate two
key strengths of AEDM: it outperforms commercial solvers by 16--69\% in
solution quality and achieves real-time inference (1--2 seconds) versus
100--2,000 seconds for traditional methods. The model exhibits strong
generalization across varying problem scales, drone numbers, and time
constraints, consistently outperforming baseline methods on unseen parameter
distributions and real-world road networks. The proposed method effectively
balances computational efficiency with solution quality, making it particularly
suitable for time-critical disaster response applications where rapid
decision-making is essential for saving lives.

</details>


### [1063] [Predicting NCAP Safety Ratings: An Analysis of Vehicle Characteristics and ADAS Features Using Machine Learning](https://arxiv.org/abs/2509.01897)
*Raunak Kunwar,Aera Kim LeBoulluec*

Main category: cs.LG

TL;DR: 利用机器学习分析新车安全评级数据，结合传统车辆属性和高级驾驶辅助系统（ADAS）特征，以预测车辆获得五星安全评级。


<details>
  <summary>Details</summary>
Motivation: 了解ADAS功能与车辆属性如何共同影响车辆安全评级，特别是预测获得最高五星评级的可能性。

Method: 使用包含约5128个车辆型号的数据集，比较了逻辑回归、随机森林、梯度提升和支持向量分类器（SVC）四种机器学习模型。采用5折分层交叉验证，并对随机森林和梯度提升模型进行了超参数优化。

Result: 研究发现，基础车辆特征（如整备质量和车型年份）对预测能力的影响最大（占随机森林模型特征相关性的55%以上），但ADAS特征也具有重要的预测贡献。优化后的随机森林模型在独立测试集上达到了89.18%的准确率和0.9586的ROC AUC。

Conclusion: 机器学习可用于分析大规模NCAP数据，传统车辆参数和ADAS特征的结合对于实现最高安全评级具有重要的预测意义。

Abstract: Vehicle safety assessment is crucial for consumer information and regulatory
oversight. The New Car Assessment Program (NCAP) assigns standardized safety
ratings, which traditionally emphasize passive safety measures but now include
active safety technologies such as Advanced Driver-Assistance Systems (ADAS).
It is crucial to understand how these various systems interact empirically.
This study explores whether particular ADAS features like Forward Collision
Warning, Lane Departure Warning, Crash Imminent Braking, and Blind Spot
Detection, together with established vehicle attributes (e.g., Curb Weight,
Model Year, Vehicle Type, Drive Train), can reliably predict a vehicle's
likelihood of earning the highest (5-star) overall NCAP rating. Using a
publicly available dataset derived from NCAP reports that contain approximately
5,128 vehicle variants spanning model years 2011-2025, we compared four
different machine learning models: logistic regression, random forest, gradient
boosting, and support vector classifier (SVC) using a 5-fold stratified
cross-validation approach. The two best-performing algorithms (random forest
and gradient boost) were hyperparameter optimized using RandomizedSearchCV.
Analysis of feature importance showed that basic vehicle characteristics,
specifically curb weight and model year, dominated predictive capability,
contributing more than 55% of the feature relevance of the Random Forest model.
However, the inclusion of ADAS features also provided meaningful predictive
contributions. The optimized Random Forest model achieved robust results on a
held-out test set, with an accuracy of 89.18% and a ROC AUC of 0.9586. This
research reveals the use of machine learning to analyze large-scale NCAP data
and highlights the combined predictive importance of both established vehicle
parameters and modern ADAS features to achieve top safety ratings.

</details>


### [1064] [VISP: Volatility Informed Stochastic Projection for Adaptive Regularization](https://arxiv.org/abs/2509.01903)
*Tanvir Islam*

Main category: cs.LG

TL;DR: VISP是一种自适应正则化方法，通过利用梯度波动性来指导深度神经网络中的随机噪声注入，有效减轻过拟合并提高泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统的正则化方法（如均匀噪声或固定dropout率）在正则化深度神经网络方面存在局限性。本研究旨在提出一种新的正则化方法，该方法能够根据梯度统计信息动态计算梯度波动性，并利用其来调整随机投影矩阵，从而选择性地正则化那些梯度波动性较高的输入和隐藏节点，同时保留稳定的表示，以减轻过拟合。

Method: VISP（Volatility Informed Stochastic Projection）是一种自适应正则化方法。它通过计算梯度统计信息来动态地确定梯度波动性，并使用该波动性来调整一个随机投影矩阵。该机制能够选择性地对梯度波动性较高的输入和隐藏节点进行正则化，同时保持那些表示稳定的节点，从而有效地减轻过拟合现象。

Result: 在MNIST、CIFAR-10和SVHN数据集上的大量实验表明，VISP相对于基线模型和固定噪声替代方法，能够持续提高模型的泛化性能。此外，对梯度波动性演变、投影矩阵谱属性和激活分布的详细分析表明，VISP不仅稳定了网络的内部动态，还促进了更鲁棒的特征表示。

Conclusion: VISP通过动态调整噪声注入来有效减轻过拟合，并在多个数据集上展示了优越的泛化性能，同时稳定了网络内部动态并促进了更鲁棒的特征表示。

Abstract: We propose VISP: Volatility Informed Stochastic Projection, an adaptive
regularization method that leverages gradient volatility to guide stochastic
noise injection in deep neural networks. Unlike conventional techniques that
apply uniform noise or fixed dropout rates, VISP dynamically computes
volatility from gradient statistics and uses it to scale a stochastic
projection matrix. This mechanism selectively regularizes inputs and hidden
nodes that exhibit higher gradient volatility while preserving stable
representations, thereby mitigating overfitting. Extensive experiments on
MNIST, CIFAR-10, and SVHN demonstrate that VISP consistently improves
generalization performance over baseline models and fixed-noise alternatives.
In addition, detailed analyses of the evolution of volatility, the spectral
properties of the projection matrix, and activation distributions reveal that
VISP not only stabilizes the internal dynamics of the network but also fosters
a more robust feature representation.

</details>


### [1065] [Causal representation learning from network data](https://arxiv.org/abs/2509.01916)
*Jifan Zhang,Michelle M. Li,Elena Zheleva*

Main category: cs.LG

TL;DR: 从软干预中因果解纠缠在有向无环图（DAG）的假设下是可识别的，但本研究在非独立同分布（non-i.i.d.）的背景下，利用网络数据和名为GraCE-VAE的框架来解决因果解纠缠问题。


<details>
  <summary>Details</summary>
Motivation: 在非独立同分布（non-i.i.d.）的设置中，利用网络数据来解决因果解纠缠问题，而先前的研究主要集中在独立同分布（i.i.d.）的数据上。

Method: 提出了一种名为GraCE-VAE的框架，该框架结合了基于差异的变分自编码器（discrepancy-based VAEs）和图神经网络（GNNs），以联合恢复真实的潜在因果图和干预效应。

Result: GraCE-VAE在三个基因扰动数据集上进行了经验评估，并与最先进的基线进行了比较，证明了利用结构化上下文进行因果解纠缠的影响。

Conclusion: 证明了在有向无环图（DAG）的假设下，从非独立同分布（non-i.i.d.）数据中因果解纠缠是可识别的，并且GraCE-VAE框架能够有效地利用结构化上下文来解决此问题。

Abstract: Causal disentanglement from soft interventions is identifiable under the
assumptions of linear interventional faithfulness and availability of both
observational and interventional data. Previous research has looked into this
problem from the perspective of i.i.d. data. Here, we develop a framework,
GraCE-VAE, for non-i.i.d. settings, in which structured context in the form of
network data is available. GraCE-VAE integrates discrepancy-based variational
autoencoders with graph neural networks to jointly recover the true latent
causal graph and intervention effects. We show that the theoretical results of
identifiability from i.i.d. data hold in our setup. We also empirically
evaluate GraCE-VAE against state-of-the-art baselines on three genetic
perturbation datasets to demonstrate the impact of leveraging structured
context for causal disentanglement.

</details>


### [1066] [A Continuous Encoding-Based Representation for Efficient Multi-Fidelity Multi-Objective Neural Architecture Search](https://arxiv.org/abs/2509.01943)
*Zhao Wei,Chin Chun Ooi,Yew-Soon Ong*

Main category: cs.LG

TL;DR: 提出了一种多保真度、多目标神经架构搜索（NAS）算法，通过协同克里金模型和聚类采样策略来降低计算成本，并使用连续编码方法减少搜索维度，在多个基准测试和实际应用中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 神经架构搜索（NAS）虽然能自动设计优化架构，但计算成本高，尤其是在优化多个相互冲突的目标时。

Method: 提出了一种自适应的协同克里金辅助多保真度多目标NAS算法，结合了基于聚类的局部多保真度样本填充策略，以及一种新的连续编码方法来表示基于单元的U-Net骨干网络中的节点连接，以降低搜索维度。

Result: 所提出的NAS算法在计算预算有限的情况下，在三个数值基准测试、一个2D Darcy流回归问题和一个CHASE_DB1生物医学图像分割问题上，均优于先前发表的最先进方法。该算法还成功应用于城市建模中的风速回归问题，找到了一个预测精度高且计算复杂度低的模型。

Conclusion: 该NAS算法能够高效地探索搜索空间并加速收敛，即使在计算预算有限的情况下也能找到最优架构。算法还发现了其他文献中U-Net架构的优势原则，例如允许每个单元整合来自先前单元的信息的重要性。

Abstract: Neural architecture search (NAS) is an attractive approach to automate the
design of optimized architectures but is constrained by high computational
budget, especially when optimizing for multiple, important conflicting
objectives. To address this, an adaptive Co-Kriging-assisted multi-fidelity
multi-objective NAS algorithm is proposed to further reduce the computational
cost of NAS by incorporating a clustering-based local multi-fidelity infill
sampling strategy, enabling efficient exploration of the search space for
faster convergence. This algorithm is further accelerated by the use of a novel
continuous encoding method to represent the connections of nodes in each cell
within a generalized cell-based U-Net backbone, thereby decreasing the search
dimension (number of variables). Results indicate that the proposed NAS
algorithm outperforms previously published state-of-the-art methods under
limited computational budget on three numerical benchmarks, a 2D Darcy flow
regression problem and a CHASE_DB1 biomedical image segmentation problem. The
proposed method is subsequently used to create a wind velocity regression model
with application in urban modelling, with the found model able to achieve good
prediction with less computational complexity. Further analysis revealed that
the NAS algorithm independently identified principles undergirding superior
U-Net architectures in other literature, such as the importance of allowing
each cell to incorporate information from prior cells.

</details>


### [1067] [Knowledge distillation as a pathway toward next-generation intelligent ecohydrological modeling systems](https://arxiv.org/abs/2509.01972)
*Long Jiang,Yang Yang,Ting Fong May Chui,Morgan Thornwell,Hoshin Vijai Gupta*

Main category: cs.LG

TL;DR: 该研究提出了一个结合了过程模型和机器学习（ML）的AI框架，用于改进生态水文学模拟。


<details>
  <summary>Details</summary>
Motivation: 气候变化和人类活动压力下，生态水文过程模拟对于理解环境系统和可持续管理至关重要。传统过程模型计算成本高且校准复杂，而ML方法虽然高效但缺乏可解释性和迁移性。

Method: 该研究提出了一个三阶段框架：1.行为蒸馏：利用代理学习和模型简化来降低过程模型的计算成本。2.结构蒸馏：将过程方程改写为图神经网络（GNN）中的模块化组件，实现多尺度表示和与ML模型的集成。3.认知蒸馏：利用“眼睛-大脑-手-嘴”架构将专家知识和决策能力嵌入智能建模剂。

Result: 通过对Samish流域的演示，该框架能够重现过程模型输出，提高预测精度，并支持基于情景的决策。

Conclusion: 该框架为下一代智能生态水文学模型提供了一个可扩展且可迁移的路径，并有潜力扩展到其他基于过程的领域。

Abstract: Simulating ecohydrological processes is essential for understanding complex
environmental systems and guiding sustainable management amid accelerating
climate change and human pressures. Process-based models provide physical
realism but can suffer from structural rigidity, high computational costs, and
complex calibration, while machine learning (ML) methods are efficient and
flexible yet often lack interpretability and transferability. We propose a
unified three-phase framework that integrates process-based models with ML and
progressively embeds them into artificial intelligence (AI) through knowledge
distillation. Phase I, behavioral distillation, enhances process models via
surrogate learning and model simplification to capture key dynamics at lower
computational cost. Phase II, structural distillation, reformulates process
equations as modular components within a graph neural network (GNN), enabling
multiscale representation and seamless integration with ML models. Phase III,
cognitive distillation, embeds expert reasoning and adaptive decision-making
into intelligent modeling agents using the Eyes-Brain-Hands-Mouth architecture.
Demonstrations for the Samish watershed highlight the framework's applicability
to ecohydrological modeling, showing that it can reproduce process-based model
outputs, improve predictive accuracy, and support scenario-based
decision-making. The framework offers a scalable and transferable pathway
toward next-generation intelligent ecohydrological modeling systems, with the
potential extension to other process-based domains.

</details>


### [1068] [ACA-Net: Future Graph Learning for Logistical Demand-Supply Forecasting](https://arxiv.org/abs/2509.01997)
*Jiacheng Shi,Haibin Wei,Jiang Wang,Xiaowei Xu,Longzhi Du,Taixu Jiang*

Main category: cs.LG

TL;DR: 该论文提出了一种创新的时空学习模型，利用“即时”和“全局”图来预测外卖平台的订单分布，以优化物流供需预测，相比传统长序列方法效果更佳。


<details>
  <summary>Details</summary>
Motivation: 外卖平台的物流需求预测对调度决策至关重要，而订单的未来分布信息是预测的关键，但现有方法难以有效且高效地捕捉这种具有强随机性的时间序列不敏感信息。

Method: 提出了一种创新的时空学习模型，利用“即时”图和“全局”图，结合自适应未来图学习和跨注意机制（ACA-Net），来提取未来订单分布信息，构建有效的未来图，以提升物流供需压力预测的性能。

Result: 与传统的时空长序列方法相比，该模型在预测物流供需压力方面表现出更优越的性能，并且在实际生产环境中得到了验证。

Conclusion: 所提出的ACA-Net模型通过引入“即时”和“全局”图以及创新的跨注意机制，能够有效学习未来订单分布信息，显著提高了物流供需压力预测的准确性，并在实际应用中取得了良好效果。

Abstract: Logistical demand-supply forecasting that evaluates the alignment between
projected supply and anticipated demand, is essential for the efficiency and
quality of on-demand food delivery platforms and serves as a key indicator for
scheduling decisions. Future order distribution information, which reflects the
distribution of orders in on-demand food delivery, is crucial for the
performance of logistical demand-supply forecasting. Current studies utilize
spatial-temporal analysis methods to model future order distribution
information from serious time slices. However, learning future order
distribution in online delivery platform is a time-series-insensitive problem
with strong randomness. These approaches often struggle to effectively capture
this information while remaining efficient. This paper proposes an innovative
spatiotemporal learning model that utilizes only two graphs (ongoing and
global) to learn future order distribution information, achieving superior
performance compared to traditional spatial-temporal long-series methods. The
main contributions are as follows: (1) The introduction of ongoing and global
graphs in logistical demand-supply pressure forecasting compared to traditional
long time series significantly enhances forecasting performance. (2) An
innovative graph learning network framework using adaptive future graph
learning and innovative cross attention mechanism (ACA-Net) is proposed to
extract future order distribution information, effectively learning a robust
future graph that substantially improves logistical demand-supply pressure
forecasting outcomes. (3) The effectiveness of the proposed method is validated
in real-world production environments.

</details>


### [1069] [Bouncy particle sampler with infinite exchanging parallel tempering](https://arxiv.org/abs/2509.02003)
*Yohei Saito,Shun Kimura,Koujin Takeda*

Main category: cs.LG

TL;DR: 该研究提出了一种结合了平行淬火（PT）和弹跳粒子采样器（BPS）的新算法，用于加速贝叶斯推断中后验分布的收敛，特别是在多峰分布的情况下，并证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决贝叶斯推断中后验分布难以解析求解的问题，并克服现有采样方法（如HMC和MCMC）在参数设置上的困难，研究人员提出了一种新的采样方法。

Method: 研究人员将平行淬火（PT）技术引入弹跳粒子采样器（BPS），并提出了一种在逆温度交换率为无穷大时运行的算法。

Result: 通过数值模拟，证明了新算法在多峰分布情况下能够加速收敛，并有效逼近后验分布。

Conclusion: 该研究提出的结合PT和BPS的算法在处理多峰分布的贝叶斯推断问题上是有效的，并可能比其他方法更容易设置参数。

Abstract: Bayesian inference is useful to obtain a predictive distribution with a small
generalization error. However, since posterior distributions are rarely
evaluated analytically, we employ the variational Bayesian inference or
sampling method to approximate posterior distributions. When we obtain samples
from a posterior distribution, Hamiltonian Monte Carlo (HMC) has been widely
used for the continuous variable part and Markov chain Monte Carlo (MCMC) for
the discrete variable part. Another sampling method, the bouncy particle
sampler (BPS), has been proposed, which combines uniform linear motion and
stochastic reflection to perform sampling. BPS was reported to have the
advantage of being easier to set simulation parameters than HMC. To accelerate
the convergence to a posterior distribution, we introduced parallel tempering
(PT) to BPS, and then proposed an algorithm when the inverse temperature
exchange rate is set to infinity. We performed numerical simulations and
demonstrated its effectiveness for multimodal distribution.

</details>


### [1070] [Second-Order Tensorial Partial Differential Equations on Graphs](https://arxiv.org/abs/2509.02015)
*Aref Einizade,Fragkiskos D. Malliaros,Jhony H. Giraldo*

Main category: cs.LG

TL;DR: 为处理多图数据，本文提出了二阶张量偏微分方程（So-TPDEGs），扩展了现有连续方法的局限，通过分离余弦核实现高效谱分解，保留高频信息，并提供了稳定性与过平滑的理论分析。


<details>
  <summary>Details</summary>
Motivation: 现有处理多图数据的连续方法受限于一阶导数，无法有效捕捉复杂、多尺度和异质结构。

Method: 提出二阶张量偏微分方程（So-TPDEGs）及相应的连续图神经网络框架，利用笛卡尔积图上余弦核的可分离性实现高效谱分解。

Result: 实现了保留高频信息，并通过理论分析证明了在图扰动下的稳定性和过平滑行为。

Conclusion: 本文提出的So-TPDEGs为跨域的连续图学习提供了理论基础，克服了现有方法的局限。

Abstract: Processing data that lies on multiple interacting (product) graphs is
increasingly important in practical applications, yet existing methods are
mostly restricted to discrete graph filtering. Tensorial partial differential
equations on graphs (TPDEGs) offer a principled framework for modeling such
multidomain data in a continuous setting. However, current continuous
approaches are limited to first-order derivatives, which tend to dampen
high-frequency signals and slow down information propagation. This makes these
TPDEGs-based approaches less effective for capturing complex, multi-scale, and
heterophilic structures. In this paper, we introduce second-order TPDEGs
(So-TPDEGs) and propose the first theoretically grounded framework for
second-order continuous product graph neural networks. Our approach leverages
the separability of cosine kernels in Cartesian product graphs to implement
efficient spectral decomposition, while naturally preserving high-frequency
information. We provide rigorous theoretical analyses of stability under graph
perturbations and over-smoothing behavior regarding spectral properties. Our
theoretical results establish a robust foundation for advancing continuous
graph learning across multiple practical domains.

</details>


### [1071] [Genetic Programming with Model Driven Dimension Repair for Learning Interpretable Appointment Scheduling Rules](https://arxiv.org/abs/2509.02034)
*Huan Zhang,Yang Wang,Ya-Hui Jia,Yi Mei*

Main category: cs.LG

TL;DR: We introduce a dimensionally aware genetic programming algorithm with a novel dimension repair procedure to evolve appointment rules (ARs) for healthcare, ensuring dimensional consistency and improving performance over existing methods.


<details>
  <summary>Details</summary>
Motivation: Directly applying genetic programming (GP) to evolve appointment rules (ARs) can result in rules that are hard for end-users to interpret and trust because GP lacks awareness of dimensional consistency, which is crucial for aligning evolved rules with users' domain knowledge.

Method: We developed a new dimensionally aware GP algorithm incorporating a dimension repair procedure. This procedure optimizes the dimensional consistency of an expression tree with minimal structural changes, ensuring the output dimension meets requirements. The task is formulated as a mixed-integer linear programming model. The dimension repair allows exploration of diverse AR structures by temporarily breaking and then restoring dimensional consistency, identifying potentially superior individuals.

Result: Our proposed method evolved high-quality ARs that significantly outperformed manually designed ARs and state-of-the-art dimensionally aware GP methods in simulated clinics, showing improvements in both objective values and dimensional consistency. We also analyzed the semantics of the evolved ARs for better interpretability.

Conclusion: The developed dimensionally aware GP algorithm with dimension repair effectively evolves high-quality, dimensionally consistent, and interpretable appointment rules for healthcare, outperforming existing methods.

Abstract: Appointment scheduling is a great challenge in healthcare operations
management. Appointment rules (AR) provide medical practitioners with a simple
yet effective tool to determine patient appointment times. Genetic programming
(GP) can be used to evolve ARs. However, directly applying GP to design ARs may
lead to rules that are difficult for end-users to interpret and trust. A key
reason is that GP is unaware of the dimensional consistency, which ensures that
the evolved rules align with users' domain knowledge and intuitive
understanding. In this paper, we develop a new dimensionally aware GP algorithm
with dimension repair to evolve ARs with dimensional consistency and high
performance. A key innovation of our method is the dimension repair procedure,
which optimizes the dimensional consistency of an expression tree while
minimizing structural changes and ensuring that its output dimension meets the
problem's requirements. We formulate the task as a mixed-integer linear
programming model that can be efficiently solved using common mathematical
programming methods. With the support of the dimension repair procedure, our
method can explore a wider range of AR structures by temporarily breaking the
dimensional consistency of individuals, and then restoring it without altering
their overall structure, thereby identifying individuals with greater potential
advantages. We evaluated the proposed method in a comprehensive set of
simulated clinics. The experimental results demonstrate that our approach
managed to evolve high-quality ARs that significantly outperform not only the
manually designed ARs but also existing state-of-the-art dimensionally aware GP
methods in terms of both objective values and dimensional consistency. In
addition, we analyzed the semantics of the evolved ARs, providing insight into
the design of more effective and interpretable ARs.

</details>


### [1072] [Fantastic Pretraining Optimizers and Where to Find Them](https://arxiv.org/abs/2509.02046)
*Kaiyue Wen,David Hall,Tengyu Ma,Percy Liang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: AdamW has long been the dominant optimizer in language model pretraining,
despite numerous claims that alternative optimizers offer 1.4 to 2x speedup. We
posit that two methodological shortcomings have obscured fair comparisons and
hindered practical adoption: (i) unequal hyperparameter tuning and (ii) limited
or misleading evaluation setups. To address these two issues, we conduct a
systematic study of ten deep learning optimizers across four model scales
(0.1B-1.2B parameters) and data-to-model ratios (1-8x the Chinchilla optimum).
We find that fair and informative comparisons require rigorous hyperparameter
tuning and evaluations across a range of model scales and data-to-model ratios,
performed at the end of training. First, optimal hyperparameters for one
optimizer may be suboptimal for another, making blind hyperparameter transfer
unfair. Second, the actual speedup of many proposed optimizers over well-tuned
baselines is lower than claimed and decreases with model size to only 1.1x for
1.2B parameter models. Thirdly, comparing intermediate checkpoints before
reaching the target training budgets can be misleading, as rankings between two
optimizers can flip during training due to learning rate decay. Through our
thorough investigation, we find that all the fastest optimizers such as Muon
and Soap, use matrices as preconditioners -- multiplying gradients with
matrices rather than entry-wise scalars. However, the speedup of matrix-based
optimizers is inversely proportional to model scale, decreasing from 1.4x over
AdamW for 0.1B parameter models to merely 1.1x for 1.2B parameter models.

</details>


### [1073] [Privacy-Utility Trade-off in Data Publication: A Bilevel Optimization Framework with Curvature-Guided Perturbation](https://arxiv.org/abs/2509.02048)
*Yi Yin,Guangquan Zhang,Hua Zuo,Jie Lu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Machine learning models require datasets for effective training, but directly
sharing raw data poses significant privacy risk such as membership inference
attacks (MIA). To mitigate the risk, privacy-preserving techniques such as data
perturbation, generalization, and synthetic data generation are commonly
utilized. However, these methods often degrade data accuracy, specificity, and
diversity, limiting the performance of downstream tasks and thus reducing data
utility. Therefore, striking an optimal balance between privacy preservation
and data utility remains a critical challenge.
  To address this issue, we introduce a novel bilevel optimization framework
for the publication of private datasets, where the upper-level task focuses on
data utility and the lower-level task focuses on data privacy. In the
upper-level task, a discriminator guides the generation process to ensure that
perturbed latent variables are mapped to high-quality samples, maintaining
fidelity for downstream tasks. In the lower-level task, our framework employs
local extrinsic curvature on the data manifold as a quantitative measure of
individual vulnerability to MIA, providing a geometric foundation for targeted
privacy protection. By perturbing samples toward low-curvature regions, our
method effectively suppresses distinctive feature combinations that are
vulnerable to MIA. Through alternating optimization of both objectives, we
achieve a synergistic balance between privacy and utility. Extensive
experimental evaluations demonstrate that our method not only enhances
resistance to MIA in downstream tasks but also surpasses existing methods in
terms of sample quality and diversity.

</details>


### [1074] [LUCIE-3D: A three-dimensional climate emulator for forced responses](https://arxiv.org/abs/2509.02061)
*Haiwen Guan,Troy Arcomano,Ashesh Chattopadhyay,Romit Maulik*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce LUCIE-3D, a lightweight three-dimensional climate emulator
designed to capture the vertical structure of the atmosphere, respond to
climate change forcings, and maintain computational efficiency with long-term
stability. Building on the original LUCIE-2D framework, LUCIE-3D employs a
Spherical Fourier Neural Operator (SFNO) backbone and is trained on 30 years of
ERA5 reanalysis data spanning eight vertical {\sigma}-levels. The model
incorporates atmospheric CO2 as a forcing variable and optionally integrates
prescribed sea surface temperature (SST) to simulate coupled ocean--atmosphere
dynamics. Results demonstrate that LUCIE-3D successfully reproduces
climatological means, variability, and long-term climate change signals,
including surface warming and stratospheric cooling under increasing CO2
concentrations. The model further captures key dynamical processes such as
equatorial Kelvin waves, the Madden--Julian Oscillation, and annular modes,
while showing credible behavior in the statistics of extreme events. Despite
requiring longer training than its 2D predecessor, LUCIE-3D remains efficient,
training in under five hours on four GPUs. Its combination of stability,
physical consistency, and accessibility makes it a valuable tool for rapid
experimentation, ablation studies, and the exploration of coupled climate
dynamics, with potential applications extending to paleoclimate research and
future Earth system emulation.

</details>


### [1075] [Evaluating Cumulative Spectral Gradient as a Complexity Measure](https://arxiv.org/abs/2509.02399)
*Haji Gul,Abdul Ghani Naim,Ajaz Ahmad Bhat*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Accurate estimation of dataset complexity is crucial for evaluating and
comparing link prediction models for knowledge graphs (KGs). The Cumulative
Spectral Gradient (CSG) metric derived from probabilistic divergence between
classes within a spectral clustering framework was proposed as a dataset
complexity measure that (1) naturally scales with the number of classes and (2)
correlates strongly with downstream classification performance. In this work,
we rigorously assess CSG behavior on standard knowledge graph link prediction
benchmarks a multi class tail prediction task, using two key parameters
governing its computation, M, the number of Monte Carlo sampled points per
class, and K, the number of nearest neighbors in the embedding space. Contrary
to the original claims, we find that (1) CSG is highly sensitive to the choice
of K and therefore does not inherently scale with the number of target classes,
and (2) CSG values exhibit weak or no correlation with established performance
metrics such as mean reciprocal rank (MRR). Through experiments on FB15k 237,
WN18RR, and other standard datasets, we demonstrate that CSG purported
stability and generalization predictive power break down in link prediction
settings. Our results highlight the need for more robust, classifier agnostic
complexity measures in KG link prediction evaluation.

</details>


### [1076] [Data-Dependent Smoothing for Protein Discovery with Walk-Jump Sampling](https://arxiv.org/abs/2509.02069)
*Srinivas Anumasa,Barath Chandran. C,Tingting Chen,Dianbo Liu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Diffusion models have emerged as a powerful class of generative models by
learning to iteratively reverse the noising process. Their ability to generate
high-quality samples has extended beyond high-dimensional image data to other
complex domains such as proteins, where data distributions are typically sparse
and unevenly spread. Importantly, the sparsity itself is uneven. Empirically,
we observed that while a small fraction of samples lie in dense clusters, the
majority occupy regions of varying sparsity across the data space. Existing
approaches largely ignore this data-dependent variability. In this work, we
introduce a Data-Dependent Smoothing Walk-Jump framework that employs kernel
density estimation (KDE) as a preprocessing step to estimate the noise scale
$\sigma$ for each data point, followed by training a score model with these
data-dependent $\sigma$ values. By incorporating local data geometry into the
denoising process, our method accounts for the heterogeneous distribution of
protein data. Empirical evaluations demonstrate that our approach yields
consistent improvements across multiple metrics, highlighting the importance of
data-aware sigma prediction for generative modeling in sparse, high-dimensional
settings.

</details>


### [1077] [Abex-rat: Synergizing Abstractive Augmentation and Adversarial Training for Classification of Occupational Accident Reports](https://arxiv.org/abs/2509.02072)
*Jian Chen,Jinbao Tian,Yunqi Xu,Zhou Li*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The automatic classification of occupational accident reports is a critical
research area for enhancing workplace safety and enabling large-scale risk
analysis. However, the severe class imbalance inherent in these real-world
datasets often compromises the performance of analytical models, particularly
for rare but severe incident types, hindering the development of reliable
automated systems. To address this challenge, we propose ABEX-RAT, a novel and
efficient framework that synergizes generative data augmentation with robust
adversarial training. Our approach first employs a twostep
abstractive-expansive (ABEX) pipeline, which leverages a large language model
to distill core incident semantics and then uses a generative model to create
diverse, highquality synthetic samples for underrepresented classes.
Subsequently, a lightweight classifier is trained on the augmented data using a
computationally efficient random adversarial training (RAT) protocol, which
stochastically applies perturbations to enhance model generalization and
robustness without significant overhead. Experimental results on the public
OSHA dataset demonstrate that our method achieves new state-of-the-art
performance, reaching a macro-F1 score of 90.32% and significantly
outperforming previous SOTA and fine-tuned large model baselines. Our work
validates that this synergistic strategy is a highly effective and efficient
alternative to brute-force fine-tuning for specialized, imbalanced
classification tasks. The code is publicly available
at:https://github.com/nxcc-lab/ABEX-RAT.

</details>


### [1078] [Towards Comprehensive Information-theoretic Multi-view Learning](https://arxiv.org/abs/2509.02084)
*Long Shi,Yunshan Ye,Wenjie Wang,Tao Lei,Yu Zhao,Gang Kou,Badong Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Information theory has inspired numerous advancements in multi-view learning.
Most multi-view methods incorporating information-theoretic principles rely an
assumption called multi-view redundancy which states that common information
between views is necessary and sufficient for down-stream tasks. This
assumption emphasizes the importance of common information for prediction, but
inherently ignores the potential of unique information in each view that could
be predictive to the task. In this paper, we propose a comprehensive
information-theoretic multi-view learning framework named CIML, which discards
the assumption of multi-view redundancy. Specifically, CIML considers the
potential predictive capabilities of both common and unique information based
on information theory. First, the common representation learning maximizes
Gacs-Korner common information to extract shared features and then compresses
this information to learn task-relevant representations based on the
Information Bottleneck (IB). For unique representation learning, IB is employed
to achieve the most compressed unique representation for each view while
simultaneously minimizing the mutual information between unique and common
representations, as well as among different unique representations.
Importantly, we theoretically prove that the learned joint representation is
predictively sufficient for the downstream task. Extensive experimental results
have demonstrated the superiority of our model over several state-of-art
methods. The code is released on CIML.

</details>


### [1079] [DivMerge: A divergence-based model merging method for multi-tasking](https://arxiv.org/abs/2509.02108)
*Touayouch Brahim,Fosse Loïc,Damnati Géraldine,Lecorvé Gwénolé*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-task learning (MTL) is often achieved by merging datasets before
fine-tuning, but the growing availability of fine-tuned models has led to new
approaches such as model merging via task arithmetic. A major challenge in this
setting is task interference, which worsens as the number of tasks increases.
We propose a method that merges models trained on different tasks into a single
model, maintaining strong performance across all tasks. Our approach leverages
Jensen-Shannon divergence to guide the merging process without requiring
additional labelled data, and automatically balances task importance. Unlike
existing methods, our approach remains robust as the number of tasks grows and
consistently outperforms prior work.

</details>


### [1080] [DynaGuard: A Dynamic Guardrail Model With User-Defined Policies](https://arxiv.org/abs/2509.02563)
*Monte Hoover,Vatsal Baherwani,Neel Jain,Khalid Saifullah,Joseph Vincent,Chirag Jain,Melissa Kazemi Rad,C. Bayan Bruss,Ashwinee Panda,Tom Goldstein*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Guardian models are used to supervise and moderate the outputs of user-facing
chatbots, enforcing guardrails and detecting bad behaviors. Standard guardian
models like LlamaGuard detect predefined, static categories of harms. We
propose dynamic guardian models that evaluate text based on user-defined
policies, making them useful for different application domains that are not
addressed by standard guardian models. Our dynamic guardian models can be used
for fast detection of policy violations or with chain-of-thought reasoning that
articulates and justifies the model outputs. Our dynamic guardian models match
static models in detection accuracy for static harm categories while
identifying violations of free-form policies with accuracy comparable to
frontier reasoning models in a fraction of the time.

</details>


### [1081] [Differentiable Expectation-Maximisation and Applications to Gaussian Mixture Model Optimal Transport](https://arxiv.org/abs/2509.02109)
*Samuel Boïté,Eloi Tanguy,Julie Delon,Agnès Desolneux,Rémi Flamary*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The Expectation-Maximisation (EM) algorithm is a central tool in statistics
and machine learning, widely used for latent-variable models such as Gaussian
Mixture Models (GMMs). Despite its ubiquity, EM is typically treated as a
non-differentiable black box, preventing its integration into modern learning
pipelines where end-to-end gradient propagation is essential. In this work, we
present and compare several differentiation strategies for EM, from full
automatic differentiation to approximate methods, assessing their accuracy and
computational efficiency. As a key application, we leverage this differentiable
EM in the computation of the Mixture Wasserstein distance $\mathrm{MW}_2$
between GMMs, allowing $\mathrm{MW}_2$ to be used as a differentiable loss in
imaging and machine learning tasks. To complement our practical use of
$\mathrm{MW}_2$, we contribute a novel stability result which provides
theoretical justification for the use of $\mathrm{MW}_2$ with EM, and also
introduce a novel unbalanced variant of $\mathrm{MW}_2$. Numerical experiments
on barycentre computation, colour and style transfer, image generation, and
texture synthesis illustrate the versatility and effectiveness of the proposed
approach in different settings.

</details>


### [1082] [Threshold-Based Optimal Arm Selection in Monotonic Bandits: Regret Lower Bounds and Algorithms](https://arxiv.org/abs/2509.02119)
*Chanakya Varude,Jay Chaudhary,Siddharth Kaushik,Prasanna Chaporkar*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In multi-armed bandit problems, the typical goal is to identify the arm with
the highest reward. This paper explores a threshold-based bandit problem,
aiming to select an arm based on its relation to a prescribed threshold \(\tau
\). We study variants where the optimal arm is the first above \(\tau\), the
\(k^{th}\) arm above or below it, or the closest to it, under a monotonic
structure of arm means. We derive asymptotic regret lower bounds, showing
dependence only on arms adjacent to \(\tau\). Motivated by applications in
communication networks (CQI allocation), clinical dosing, energy management,
recommendation systems, and more. We propose algorithms with optimality
validated through Monte Carlo simulations. Our work extends classical bandit
theory with threshold constraints for efficient decision-making.

</details>


### [1083] [Scale, Don't Fine-tune: Guiding Multimodal LLMs for Efficient Visual Place Recognition at Test-Time](https://arxiv.org/abs/2509.02129)
*Jintao Cheng,Weibin Li,Jiehao Luo,Xiaoyu Tang,Zhijian He,Jin Wu,Yao Zou,Wei Zhang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Visual Place Recognition (VPR) has evolved from handcrafted descriptors to
deep learning approaches, yet significant challenges remain. Current
approaches, including Vision Foundation Models (VFMs) and Multimodal Large
Language Models (MLLMs), enhance semantic understanding but suffer from high
computational overhead and limited cross-domain transferability when
fine-tuned. To address these limitations, we propose a novel zero-shot
framework employing Test-Time Scaling (TTS) that leverages MLLMs'
vision-language alignment capabilities through Guidance-based methods for
direct similarity scoring. Our approach eliminates two-stage processing by
employing structured prompts that generate length-controllable JSON outputs.
The TTS framework with Uncertainty-Aware Self-Consistency (UASC) enables
real-time adaptation without additional training costs, achieving superior
generalization across diverse environments. Experimental results demonstrate
significant improvements in cross-domain VPR performance with up to 210$\times$
computational efficiency gains.

</details>


### [1084] [Conditional-$t^3$VAE: Equitable Latent Space Allocation for Fair Generation](https://arxiv.org/abs/2509.02154)
*Aymene Mohammed Bouayed,Samuel Deslauriers-Gauthier,Adrian Iaccovelli,David Naccache*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Variational Autoencoders (VAEs) with global priors mirror the training set's
class frequency in latent space, underrepresenting tail classes and reducing
generative fairness on imbalanced datasets. While $t^3$VAE improves robustness
via heavy-tailed Student's t-distribution priors, it still allocates latent
volume proportionally to the class frequency.In this work, we address this
issue by explicitly enforcing equitable latent space allocation across classes.
To this end, we propose Conditional-$t^3$VAE, which defines a per-class
\mbox{Student's t} joint prior over latent and output variables, preventing
dominance by majority classes. Our model is optimized using a closed-form
objective derived from the $\gamma$-power divergence. Moreover, for
class-balanced generation, we derive an equal-weight latent mixture of
Student's t-distributions. On SVHN-LT, CIFAR100-LT, and CelebA,
Conditional-$t^3$VAE consistently achieves lower FID scores than both $t^3$VAE
and Gaussian-based VAE baselines, particularly under severe class imbalance. In
per-class F1 evaluations, Conditional-$t^3$VAE also outperforms the conditional
Gaussian VAE across all highly imbalanced settings. While Gaussian-based models
remain competitive under mild imbalance ratio ($\rho \lesssim 3$), our approach
substantially improves generative fairness and diversity in more extreme
regimes.

</details>


### [1085] [Simulating classification models to evaluate Predict-Then-Optimize methods](https://arxiv.org/abs/2509.02191)
*Pieter Smet*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Uncertainty in optimization is often represented as stochastic parameters in
the optimization model. In Predict-Then-Optimize approaches, predictions of a
machine learning model are used as values for such parameters, effectively
transforming the stochastic optimization problem into a deterministic one. This
two-stage framework is built on the assumption that more accurate predictions
result in solutions that are closer to the actual optimal solution. However,
providing evidence for this assumption in the context of complex, constrained
optimization problems is challenging and often overlooked in the literature.
Simulating predictions of machine learning models offers a way to
(experimentally) analyze how prediction error impacts solution quality without
the need to train real models. Complementing an algorithm from the literature
for simulating binary classification, we introduce a new algorithm for
simulating predictions of multiclass classifiers. We conduct a computational
study to evaluate the performance of these algorithms, and show that classifier
performance can be simulated with reasonable accuracy, although some
variability is observed. Additionally, we apply these algorithms to assess the
performance of a Predict-Then-Optimize algorithm for a machine scheduling
problem. The experiments demonstrate that the relationship between prediction
error and how close solutions are to the actual optimum is non-trivial,
highlighting important considerations for the design and evaluation of
decision-making systems based on machine learning predictions.

</details>


### [1086] [DaCe AD: Unifying High-Performance Automatic Differentiation for Machine Learning and Scientific Computing](https://arxiv.org/abs/2509.02197)
*Afif Boudaoud,Alexandru Calotoiu,Marcin Copik,Torsten Hoefler*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Automatic differentiation (AD) is a set of techniques that systematically
applies the chain rule to compute the gradients of functions without requiring
human intervention. Although the fundamentals of this technology were
established decades ago, it is experiencing a renaissance as it plays a key
role in efficiently computing gradients for backpropagation in machine learning
algorithms. AD is also crucial for many applications in scientific computing
domains, particularly emerging techniques that integrate machine learning
models within scientific simulations and schemes. Existing AD frameworks have
four main limitations: limited support of programming languages, requiring code
modifications for AD compatibility, limited performance on scientific computing
codes, and a naive store-all solution for forward-pass data required for
gradient calculations. These limitations force domain scientists to manually
compute the gradients for large problems. This work presents DaCe AD, a
general, efficient automatic differentiation engine that requires no code
modifications. DaCe AD uses a novel ILP-based algorithm to optimize the
trade-off between storing and recomputing to achieve maximum performance within
a given memory constraint. We showcase the generality of our method by applying
it to NPBench, a suite of HPC benchmarks with diverse scientific computing
patterns, where we outperform JAX, a Python framework with state-of-the-art
general AD capabilities, by more than 92 times on average without requiring any
code changes.

</details>


### [1087] [Baichuan-M2: Scaling Medical Capability with Large Verifier System](https://arxiv.org/abs/2509.02208)
*Baichuan-M2 Team,:,Chengfeng Dou,Chong Liu,Fan Yang,Fei Li,Jiyuan Jia,Mingyang Chen,Qiang Ju,Shuai Wang,Shunya Dang,Tianpeng Li,Xiangrong Zeng,Yijie Zhou,Chenzheng Zhu,Da Pan,Fei Deng,Guangwei Ai,Guosheng Dong,Hongda Zhang,Jinyang Tai,Jixiang Hong,Kai Lu,Linzhuang Sun,Peidong Guo,Qian Ma,Rihui Xin,Shihui Yang,Shusen Zhang,Yichuan Mo,Zheng Liang,Zhishou Zhang,Hengfu Cui,Zuyi Zhu,Xiaochuan Wang*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: As large language models (LLMs) advance in conversational and reasoning
capabilities, their practical application in healthcare has become a critical
research focus. However, there is a notable gap between the performance of
medical LLMs on static benchmarks such as USMLE and their utility in real-world
clinical decision-making. This discrepancy arises because traditional exams
fail to capture the dynamic, interactive nature of medical consultations. To
address this challenge, we introduce a novel dynamic verification framework
that moves beyond static answer verifier, establishing a large-scale,
high-fidelity interactive reinforcement learning system. Our framework
comprises two key components: a Patient Simulator that creates realistic
clinical environments using de-identified medical records, and a Clinical
Rubrics Generator that dynamically produces multi-dimensional evaluation
metrics. Building on this foundation, we develop Baichuan-M2, a 32B-parameter
medical augmented reasoning model trained through a multi-stage reinforcement
learning strategy with an improved Group Relative Policy Optimization (GRPO)
algorithm. Evaluated on HealthBench, Baichuan-M2 outperforms all other
open-source models and most advanced closed-source counterparts, achieving a
score above 32 on the challenging HealthBench Hard benchmark-previously
exceeded only by GPT-5. Our work demonstrates that robust dynamic verifier
system is essential for aligning LLM capabilities with practical clinical
applications, establishing a new Pareto front in the performance-parameter
trade-off for medical AI deployment.

</details>


### [1088] [ST-Hyper: Learning High-Order Dependencies Across Multiple Spatial-Temporal Scales for Multivariate Time Series Forecasting](https://arxiv.org/abs/2509.02217)
*Binqing Wu,Jianlong Huang,Zongjiang Shang,Ling Chen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In multivariate time series (MTS) forecasting, many deep learning based
methods have been proposed for modeling dependencies at multiple spatial
(inter-variate) or temporal (intra-variate) scales. However, existing methods
may fail to model dependencies across multiple spatial-temporal scales
(ST-scales, i.e., scales that jointly consider spatial and temporal scopes). In
this work, we propose ST-Hyper to model the high-order dependencies across
multiple ST-scales through adaptive hypergraph modeling. Specifically, we
introduce a Spatial-Temporal Pyramid Modeling (STPM) module to extract features
at multiple ST-scales. Furthermore, we introduce an Adaptive Hypergraph
Modeling (AHM) module that learns a sparse hypergraph to capture robust
high-order dependencies among features. In addition, we interact with these
features through tri-phase hypergraph propagation, which can comprehensively
capture multi-scale spatial-temporal dynamics. Experimental results on six
real-world MTS datasets demonstrate that ST-Hyper achieves the state-of-the-art
performance, outperforming the best baselines with an average MAE reduction of
3.8\% and 6.8\% for long-term and short-term forecasting, respectively.

</details>


### [1089] [Balanced Multimodal Learning: An Unidirectional Dynamic Interaction Perspective](https://arxiv.org/abs/2509.02281)
*Shijie Wang,Li Zhang,Xinyan Liang,Yuhua Qian,Shen Hu*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multimodal learning typically utilizes multimodal joint loss to integrate
different modalities and enhance model performance. However, this joint
learning strategy can induce modality imbalance, where strong modalities
overwhelm weaker ones and limit exploitation of individual information from
each modality and the inter-modality interaction information.Existing
strategies such as dynamic loss weighting, auxiliary objectives and gradient
modulation mitigate modality imbalance based on joint loss. These methods
remain fundamentally reactive, detecting and correcting imbalance after it
arises, while leaving the competitive nature of the joint loss untouched. This
limitation drives us to explore a new strategy for multimodal imbalance
learning that does not rely on the joint loss, enabling more effective
interactions between modalities and better utilization of information from
individual modalities and their interactions. In this paper, we introduce
Unidirectional Dynamic Interaction (UDI), a novel strategy that abandons the
conventional joint loss in favor of a proactive, sequential training scheme.
UDI first trains the anchor modality to convergence, then uses its learned
representations to guide the other modality via unsupervised loss. Furthermore,
the dynamic adjustment of modality interactions allows the model to adapt to
the task at hand, ensuring that each modality contributes optimally. By
decoupling modality optimization and enabling directed information flow, UDI
prevents domination by any single modality and fosters effective cross-modal
feature learning. Our experimental results demonstrate that UDI outperforms
existing methods in handling modality imbalance, leading to performance
improvement in multimodal learning tasks.

</details>


### [1090] [AdaSwitch: An Adaptive Switching Meta-Algorithm for Learning-Augmented Bounded-Influence Problems](https://arxiv.org/abs/2509.02302)
*Xi Chen,Yuze Chen,Yuan Zhou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study a class of multi-period online decision-making problems with
sequence-based predictions, which may be generated by machine learning models
but whose accuracy is not guaranteed. In each period, the decision-maker
observes the realized request and must take an irrevocable action that yields a
reward or incurs a cost, without knowledge of future arrivals. We introduce a
bounded-influence framework, in which past decisions and requests exert only
limited impact on the future optimal reward. Within this framework, we propose
the AdaSwitch meta-algorithm, which exploits predictions to attain performance
close to the offline benchmark when predictions are accurate, while preserving
classical competitive-ratio guarantees under highly inaccurate predictions. Our
framework and meta-algorithm apply to diverse settings, including lead-time
quotation in processing systems, the $k$-server problem, and online allocation
of reusable resources. These applications illustrate the flexibility and broad
applicability of our approach to learning-augmented online decision-making.

</details>


### [1091] [Extrapolated Markov Chain Oversampling Method for Imbalanced Text Classification](https://arxiv.org/abs/2509.02332)
*Aleksi Avela,Pauliina Ilmonen*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Text classification is the task of automatically assigning text documents
correct labels from a predefined set of categories. In real-life (text)
classification tasks, observations and misclassification costs are often
unevenly distributed between the classes - known as the problem of imbalanced
data. Synthetic oversampling is a popular approach to imbalanced
classification. The idea is to generate synthetic observations in the minority
class to balance the classes in the training set. Many general-purpose
oversampling methods can be applied to text data; however, imbalanced text data
poses a number of distinctive difficulties that stem from the unique nature of
text compared to other domains. One such factor is that when the sample size of
text increases, the sample vocabulary (i.e., feature space) is likely to grow
as well. We introduce a novel Markov chain based text oversampling method. The
transition probabilities are estimated from the minority class but also partly
from the majority class, thus allowing the minority feature space to expand in
oversampling. We evaluate our approach against prominent oversampling methods
and show that our approach is able to produce highly competitive results
against the other methods in several real data examples, especially when the
imbalance is severe.

</details>


### [1092] [RDIT: Residual-based Diffusion Implicit Models for Probabilistic Time Series Forecasting](https://arxiv.org/abs/2509.02341)
*Chih-Yu Lai,Yu-Chien Ning,Duane S. Boning*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Probabilistic Time Series Forecasting (PTSF) plays a critical role in domains
requiring accurate and uncertainty-aware predictions for decision-making.
However, existing methods offer suboptimal distribution modeling and suffer
from a mismatch between training and evaluation metrics. Surprisingly, we found
that augmenting a strong point estimator with a zero-mean Gaussian, whose
standard deviation matches its training error, can yield state-of-the-art
performance in PTSF. In this work, we propose RDIT, a plug-and-play framework
that combines point estimation and residual-based conditional diffusion with a
bidirectional Mamba network. We theoretically prove that the Continuous Ranked
Probability Score (CRPS) can be minimized by adjusting to an optimal standard
deviation and then derive algorithms to achieve distribution matching.
Evaluations on eight multivariate datasets across varied forecasting horizons
demonstrate that RDIT achieves lower CRPS, rapid inference, and improved
coverage compared to strong baselines.

</details>


### [1093] [Scaffolding Collaborative Learning in STEM: A Two-Year Evaluation of a Tool-Integrated Project-Based Methodology](https://arxiv.org/abs/2509.02355)
*Caterina Fuster-Barcelo,Gonzalo R. Rios-Munoz,Arrate Munoz-Barrutia*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This study examines the integration of digital collaborative tools and
structured peer evaluation in the Machine Learning for Health master's program,
through the redesign of a Biomedical Image Processing course over two academic
years. The pedagogical framework combines real-time programming with Google
Colab, experiment tracking and reporting via Weights & Biases, and
rubric-guided peer assessment to foster student engagement, transparency, and
fair evaluation. Compared to a pre-intervention cohort, the two implementation
years showed increased grade dispersion and higher entropy in final project
scores, suggesting improved differentiation and fairness in assessment. The
survey results further indicate greater student engagement with the subject and
their own learning process. These findings highlight the potential of
integrating tool-supported collaboration and structured evaluation mechanisms
to enhance both learning outcomes and equity in STEM education.

</details>


### [1094] [Fisher information flow in artificial neural networks](https://arxiv.org/abs/2509.02407)
*Maximilian Weimar,Lukas M. Rachbauer,Ilya Starshynov,Daniele Faccio,Linara Adilova,Dorian Bouchet,Stefan Rotter*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The estimation of continuous parameters from measured data plays a central
role in many fields of physics. A key tool in understanding and improving such
estimation processes is the concept of Fisher information, which quantifies how
information about unknown parameters propagates through a physical system and
determines the ultimate limits of precision. With Artificial Neural Networks
(ANNs) gradually becoming an integral part of many measurement systems, it is
essential to understand how they process and transmit parameter-relevant
information internally. Here, we present a method to monitor the flow of Fisher
information through an ANN performing a parameter estimation task, tracking it
from the input to the output layer. We show that optimal estimation performance
corresponds to the maximal transmission of Fisher information, and that
training beyond this point results in information loss due to overfitting. This
provides a model-free stopping criterion for network training-eliminating the
need for a separate validation dataset. To demonstrate the practical relevance
of our approach, we apply it to a network trained on data from an imaging
experiment, highlighting its effectiveness in a realistic physical setting.

</details>


### [1095] [Learnable Loss Geometries with Mirror Descent for Scalable and Convergent Meta-Learning](https://arxiv.org/abs/2509.02418)
*Yilang Zhang,Bingcong Li,Georgios B. Giannakis*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Utilizing task-invariant knowledge acquired from related tasks as prior
information, meta-learning offers a principled approach to learning a new task
with limited data records. Sample-efficient adaptation of this prior
information is a major challenge facing meta-learning, and plays an important
role because it facilitates training the sought task-specific model with just a
few optimization steps. Past works deal with this challenge through
preconditioning that speeds up convergence of the per-task training. Though
effective in representing locally quadratic loss curvatures, simple linear
preconditioning can be hardly potent with complex loss geometries. Instead of
relying on a quadratic distance metric, the present contribution copes with
complex loss metrics by learning a versatile distance-generating function,
which induces a nonlinear mirror map to effectively capture and optimize a wide
range of loss geometries. With suitable parameterization, this generating
function is effected by an expressive neural network that is provably a valid
distance. Analytical results establish convergence of not only the proposed
method, but also all meta-learning approaches based on preconditioning. To
attain gradient norm less than $\epsilon$, the convergence rate of
$\mathcal{O}(\epsilon^{-2})$ is on par with standard gradient-based
meta-learning methods. Numerical tests on few-shot learning datasets
demonstrate the superior empirical performance of the novel algorithm, as well
as its rapid per-task convergence, which markedly reduces the number of
adaptation steps, hence also accommodating large-scale meta-learning models.

</details>


### [1096] [VASSO: Variance Suppression for Sharpness-Aware Minimization](https://arxiv.org/abs/2509.02433)
*Bingcong Li,Yilang Zhang,Georgios B. Giannakis*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Sharpness-aware minimization (SAM) has well-documented merits in enhancing
generalization of deep neural network models. Accounting for sharpness in the
loss function geometry, where neighborhoods of `flat minima' heighten
generalization ability, SAM seeks `flat valleys' by minimizing the maximum loss
provoked by an adversarial perturbation within the neighborhood. Although
critical to account for sharpness of the loss function, in practice SAM suffers
from `over-friendly adversaries,' which can curtail the outmost level of
generalization. To avoid such `friendliness,' the present contribution fosters
stabilization of adversaries through variance suppression (VASSO). VASSO offers
a general approach to provably stabilize adversaries. In particular, when
integrating VASSO with SAM, improved generalizability is numerically validated
on extensive vision and language tasks. Once applied on top of a
computationally efficient SAM variant, VASSO offers a desirable
generalization-computation tradeoff.

</details>


### [1097] [Generative Sequential Notification Optimization via Multi-Objective Decision Transformers](https://arxiv.org/abs/2509.02458)
*Borja Ocejo,Ruofan Wang,Ke Liu,Rohit K. Patra,Haotian Shen,David Liu,Yiwen Yuan,Gokulraj Mohanasundaram,Fedor Borisyuk,Prakruthi Prabhakar*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Notifications are an important communication channel for delivering timely
and relevant information. Optimizing their delivery involves addressing complex
sequential decision-making challenges under constraints such as message utility
and user fatigue. Offline reinforcement learning (RL) methods, such as
Conservative Q-Learning (CQL), have been applied to this problem but face
practical challenges at scale, including instability, sensitivity to
distribution shifts, limited reproducibility, and difficulties with
explainability in high-dimensional recommendation settings. We present a
Decision Transformer (DT) based framework that reframes policy learning as
return-conditioned supervised learning, improving robustness, scalability, and
modeling flexibility. Our contributions include a real-world comparison with
CQL, a multi-reward design suitable for non-episodic tasks, a quantile
regression approach to return-to-go conditioning, and a production-ready system
with circular buffer-based sequence processing for near-real-time inference.
Extensive offline and online experiments in a deployed notification system show
that our approach improves notification utility and overall session activity
while minimizing user fatigue. Compared to a multi-objective CQL-based agent,
the DT-based approach achieved a +0.72% increase in sessions for notification
decision-making at LinkedIn by making notification recommendation more
relevant.

</details>


### [1098] [Exploring Variational Graph Autoencoders for Distribution Grid Data Generation](https://arxiv.org/abs/2509.02469)
*Syed Zain Abbas,Ehimare Okoyomon*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: To address the lack of public power system data for machine learning research
in energy networks, we investigate the use of variational graph autoencoders
(VGAEs) for synthetic distribution grid generation. Using two open-source
datasets, ENGAGE and DINGO, we evaluate four decoder variants and compare
generated networks against the original grids using structural and spectral
metrics. Results indicate that simple decoders fail to capture realistic
topologies, while GCN-based approaches achieve strong fidelity on ENGAGE but
struggle on the more complex DINGO dataset, producing artifacts such as
disconnected components and repeated motifs. These findings highlight both the
promise and limitations of VGAEs for grid synthesis, underscoring the need for
more expressive generative models and robust evaluation. We release our models
and analysis as open source to support benchmarking and accelerate progress in
ML-driven power system research.

</details>


### [1099] [SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn Tool-Integrated Reasoning](https://arxiv.org/abs/2509.02479)
*Zhenghai Xue,Longtao Zheng,Qian Liu,Yingru Li,Xiaosen Zheng,Zejun Ma,Bo An*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) can significantly improve their reasoning
capabilities by interacting with external tools, a paradigm known as
Tool-Integrated Reasoning (TIR). However, extending TIR to multi-turn scenarios
using Reinforcement Learning (RL) is often hindered by training instability and
performance collapse. We identify that such instability is primarily caused by
a distributional drift from external tool feedback, leading to the generation
of low-probability tokens. This issue compounds over successive turns, causing
catastrophic gradient norm explosions that derail the training process. To
address this challenge, we introduce SimpleTIR , a plug-and-play algorithm that
stabilizes multi-turn TIR training. Its core strategy is to identify and filter
out trajectories containing void turns, i.e., turns that yield neither a code
block nor a final answer. By removing these problematic trajectories from the
policy update, SimpleTIR effectively blocks the harmful, high-magnitude
gradients, thus stabilizing the learning dynamics. Extensive experiments show
that SimpleTIR achieves state-of-the-art performance on challenging math
reasoning benchmarks, notably elevating the AIME24 score from a text-only
baseline of 22.1 to 50.5 when starting from the Qwen2.5-7B base model.
Furthermore, by avoiding the constraints of supervised fine-tuning, SimpleTIR
encourages the model to discover diverse and sophisticated reasoning patterns,
such as self-correction and cross-validation.

</details>


### [1100] [MoPEQ: Mixture of Mixed Precision Quantized Experts](https://arxiv.org/abs/2509.02512)
*Krishna Teja Chitty-Venkata,Jie Ye,Murali Emani*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language and Vision Models using a Mixture-of-Experts (MoE)
architecture pose significant challenges for deployment due to their
computational and memory demands. Mixed Precision Quantization assigns
different precisions to different layers of an LLM/VLM based on layer
sensitivity and importance within the model. In this work, we propose a Post
Training Quantization algorithm, MoPEQ, that assigns optimal bit width to each
expert. Our method balances accuracy and model size by analyzing each expert's
sensitivity using Hessian trace approximation instead of relying on the
activation frequency of the expert. This per-expert granularity approach
clusters similar experts to maintain model performance while reducing memory
requirements. The experimental results on VLMEvalKit benchmark datasets using
State-of-the-art VLMs Deepseek-VL2 -tiny, -small, -base, and MolmoE models
demonstrate that our mixed precision quantized MoEs achieve competitive
accuracy with substantial improvements in memory footprint compared to
uniform-precision baseline methods. We perform a comprehensive study to analyze
the impact of expert activation frequency and sensitivity using Hessian trace
approximation at both layer-wise and model-wide expert precision allocation of
2, 3, and 4 bits to provide a thorough understanding of mixed precision
quantization of VLM-MoEs.

</details>


### [1101] [Is RL fine-tuning harder than regression? A PDE learning approach for diffusion models](https://arxiv.org/abs/2509.02528)
*Wenlong Mou*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We study the problem of learning the optimal control policy for fine-tuning a
given diffusion process, using general value function approximation. We develop
a new class of algorithms by solving a variational inequality problem based on
the Hamilton-Jacobi-Bellman (HJB) equations. We prove sharp statistical rates
for the learned value function and control policy, depending on the complexity
and approximation errors of the function class. In contrast to generic
reinforcement learning problems, our approach shows that fine-tuning can be
achieved via supervised regression, with faster statistical rate guarantees.

</details>


### [1102] [Understanding sparse autoencoder scaling in the presence of feature manifolds](https://arxiv.org/abs/2509.02565)
*Eric J. Michaud,Liv Gorton,Tom McGrath*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Sparse autoencoders (SAEs) model the activations of a neural network as
linear combinations of sparsely occurring directions of variation (latents).
The ability of SAEs to reconstruct activations follows scaling laws w.r.t. the
number of latents. In this work, we adapt a capacity-allocation model from the
neural scaling literature (Brill, 2024) to understand SAE scaling, and in
particular, to understand how "feature manifolds" (multi-dimensional features)
influence scaling behavior. Consistent with prior work, the model recovers
distinct scaling regimes. Notably, in one regime, feature manifolds have the
pathological effect of causing SAEs to learn far fewer features in data than
there are latents in the SAE. We provide some preliminary discussion on whether
or not SAEs are in this pathological regime in the wild.

</details>
