<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 75]
- [cs.CL](#cs.CL) [Total: 38]
- [cs.AI](#cs.AI) [Total: 32]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.AR](#cs.AR) [Total: 1]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.SI](#cs.SI) [Total: 2]
- [cs.RO](#cs.RO) [Total: 26]
- [quant-ph](#quant-ph) [Total: 57]
- [cs.ET](#cs.ET) [Total: 2]
- [cs.GT](#cs.GT) [Total: 4]
- [eess.SP](#eess.SP) [Total: 21]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 16]
- [physics.app-ph](#physics.app-ph) [Total: 2]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 30]
- [cs.MA](#cs.MA) [Total: 4]
- [cs.DC](#cs.DC) [Total: 12]
- [eess.SY](#eess.SY) [Total: 21]
- [cs.LO](#cs.LO) [Total: 1]
- [cs.LG](#cs.LG) [Total: 64]
- [cs.NE](#cs.NE) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [CellPainTR: Generalizable Representation Learning for Cross-Dataset Cell Painting Analysis](https://arxiv.org/abs/2509.06986)
*Cedric Caruzzo,Jong Chul Ye*

Main category: cs.CV

TL;DR: CellPainTR是一个Transformer模型，可以有效整合大规模、异构的生物学数据集，克服批次效应，并在未见过的数据集上实现泛化。


<details>
  <summary>Details</summary>
Motivation: 当前大规模生物学研究面临整合海量异构数据集（如JUMP Cell Painting联盟）的挑战，而技术批次效应和缺乏可泛化模型是关键障碍。

Method: 提出了一种名为CellPainTR的、基于Transformer的架构，该架构通过引入特定来源的上下文标记（source-specific context tokens）来学习对批次效应具有鲁棒性的细胞形态基础表征，实现了无需微调即可对未见数据集进行有效的分布外（OOD）泛化。

Result: 在JUMP数据集上，CellPainTR的批次整合和生物信号保持能力优于ComBat和Harmony。在Bray et al.数据集的OOD任务中，CellPainTR在显著的域和特征偏移下仍保持高性能。

Conclusion: CellPainTR是迈向真正基于图像分析的、可实现可靠和可扩展的跨研究生物学分析的基础模型的重要一步。

Abstract: Large-scale biological discovery requires integrating massive, heterogeneous
datasets like those from the JUMP Cell Painting consortium, but technical batch
effects and a lack of generalizable models remain critical roadblocks. To
address this, we introduce CellPainTR, a Transformer-based architecture
designed to learn foundational representations of cellular morphology that are
robust to batch effects. Unlike traditional methods that require retraining on
new data, CellPainTR's design, featuring source-specific context tokens, allows
for effective out-of-distribution (OOD) generalization to entirely unseen
datasets without fine-tuning. We validate CellPainTR on the large-scale JUMP
dataset, where it outperforms established methods like ComBat and Harmony in
both batch integration and biological signal preservation. Critically, we
demonstrate its robustness through a challenging OOD task on the unseen Bray et
al. dataset, where it maintains high performance despite significant domain and
feature shifts. Our work represents a significant step towards creating truly
foundational models for image-based profiling, enabling more reliable and
scalable cross-study biological analysis.

</details>


### [2] [FusWay: Multimodal hybrid fusion approach. Application to Railway Defect Detection](https://arxiv.org/abs/2509.06987)
*Alexey Zhukov,Jenny Benois-Pineau,Amira Youssef,Akka Zemmari,Mohamed Mosbah,Virginie Taillandier*

Main category: cs.CV

TL;DR: 该论文提出了一种基于领域规则的多模态融合架构，结合了YOLOv8n和Vision Transformer（ViT）以及音频信息，用于检测铁路裂缝和表面缺陷，并在真实铁路数据集上进行了实验评估。


<details>
  <summary>Details</summary>
Motivation: 单一模态方法（仅图像）在检测铁路结构元素或缺陷时存在局限性，容易出现误报。当外观类似于正常结构元素时，会导致过度检测。

Method: 提出了一种新的多模态融合架构，该架构基于领域规则，并结合了YOLOv8n（用于快速对象检测）和Vision Transformer（ViT）。ViT用于融合从多个层（7、16和19）提取的特征图，并结合合成的音频表示，以检测两种缺陷类别：铁路裂缝和表面缺陷。融合在音频和图像之间进行。

Result: 在真实铁路数据集上的实验评估表明，所提出的多模态融合方法相比仅使用视觉的方法，在精确率和整体准确率方面提高了0.2个点。学生非配对t检验也证实了平均准确率差异的统计显著性。

Conclusion: 所提出的多模态融合方法能够有效提高铁路缺陷检测的性能，克服了单一视觉方法的局限性。

Abstract: Multimodal fusion is a multimedia technique that has become popular in the
wide range of tasks where image information is accompanied by a signal/audio.
The latter may not convey highly semantic information, such as speech or music,
but some measures such as audio signal recorded by mics in the goal to detect
rail structure elements or defects. While classical detection approaches such
as You Only Look Once (YOLO) family detectors can be efficiently deployed for
defect detection on the image modality, the single modality approaches remain
limited. They yield an overdetection in case of the appearance similar to
normal structural elements. The paper proposes a new multimodal fusion
architecture built on the basis of domain rules with YOLO and Vision
transformer backbones. It integrates YOLOv8n for rapid object detection with a
Vision Transformer (ViT) to combine feature maps extracted from multiple layers
(7, 16, and 19) and synthesised audio representations for two defect classes:
rail Rupture and Surface defect. Fusion is performed between audio and image.
Experimental evaluation on a real-world railway dataset demonstrates that our
multimodal fusion improves precision and overall accuracy by 0.2 points
compared to the vision-only approach. Student's unpaired t-test also confirms
statistical significance of differences in the mean accuracy.

</details>


### [3] [Frustratingly Easy Feature Reconstruction for Out-of-Distribution Detection](https://arxiv.org/abs/2509.06988)
*Yingsheng Wang,Shuo Lu,Jian Liang,Aihua Zheng,Ran He*

Main category: cs.CV

TL;DR: ClaFR是一种无需访问训练数据即可进行OOD检测的后验方法，它通过子空间投影，根据特征重建误差来评估OOD分数，并在多个OOD基准测试中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: OOD检测对于识别超出训练类别的数据至关重要，尤其是在安全应用中。现有的基于特征的后验方法通常需要访问训练数据，这在数据隐私保护场景下可能不适用。

Method: ClaFR首先对分类器的权重进行正交分解以提取类已知子空间，然后将原始数据特征映射到该子空间以获得新的数据表示。接着，通过计算子空间内数据的特征重建误差来确定OOD分数。

Result: 该方法在多个OOD基准测试中取得了领先的性能，并且不需要访问训练数据。

Conclusion: ClaFR是一种简单有效、无需访问训练数据即可进行OOD检测的后验方法，通过子空间投影和特征重建误差来确定OOD分数，具有良好的应用前景。

Abstract: Out-of-distribution (OOD) detection helps models identify data outside the
training categories, crucial for security applications. While feature-based
post-hoc methods address this by evaluating data differences in the feature
space without changing network parameters, they often require access to
training data, which may not be suitable for some data privacy scenarios. This
may not be suitable in scenarios where data privacy protection is a concern. In
this paper, we propose a simple yet effective post-hoc method, termed
Classifier-based Feature Reconstruction (ClaFR), from the perspective of
subspace projection. It first performs an orthogonal decomposition of the
classifier's weights to extract the class-known subspace, then maps the
original data features into this subspace to obtain new data representations.
Subsequently, the OOD score is determined by calculating the feature
reconstruction error of the data within the subspace. Compared to existing OOD
detection algorithms, our method does not require access to training data while
achieving leading performance on multiple OOD benchmarks. Our code is released
at https://github.com/Aie0923/ClaFR.

</details>


### [4] [Human-in-the-Loop: Quantitative Evaluation of 3D Models Generation by Large Language Models](https://arxiv.org/abs/2509.07010)
*Ahmed R. Sadik,Mariusz Bujny*

Main category: cs.CV

TL;DR: 本论文提出一个包含人类反馈的框架，用于量化评估大语言模型生成的3D模型，并提出了一系列度量指标来评估生成模型的几何和结构保真度。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型生成的3D模型的几何和结构保真度的方法仍然不完善，这限制了其在CAD设计、逆向工程和快速原型制作等领域的应用。

Method: 提出一个包含人类反馈的框架，并提出了一系列度量指标（包括体积精度、表面对齐、尺寸保真度和拓扑复杂度），以将大语言模型生成的模型与真实CAD参考进行基准比较。通过对L型支架组件进行案例研究，比较了四种输入模式（2D视图、等轴测图、结构树和代码提示）下的模型生成性能。

Result: 研究表明，随着语义丰富度的增加，生成保真度得到提高，其中代码级提示在所有度量标准上都实现了完美的重建。提出的量化评估方法可以显著加快收敛到真实值，尤其与仅基于视觉检查和人类直觉的传统定性方法相比。

Conclusion: 本研究提出的量化评估方法能够显著加快收敛速度，并为验证和优化用于各种CAD应用的大语言模型提供了一个可扩展的方法。

Abstract: Large Language Models are increasingly capable of interpreting multimodal
inputs to generate complex 3D shapes, yet robust methods to evaluate geometric
and structural fidelity remain underdeveloped. This paper introduces a human in
the loop framework for the quantitative evaluation of LLM generated 3D models,
supporting applications such as democratization of CAD design, reverse
engineering of legacy designs, and rapid prototyping. We propose a
comprehensive suite of similarity and complexity metrics, including volumetric
accuracy, surface alignment, dimensional fidelity, and topological intricacy,
to benchmark generated models against ground truth CAD references. Using an L
bracket component as a case study, we systematically compare LLM performance
across four input modalities: 2D orthographic views, isometric sketches,
geometric structure trees, and code based correction prompts. Our findings
demonstrate improved generation fidelity with increased semantic richness, with
code level prompts achieving perfect reconstruction across all metrics. A key
contribution of this work is demonstrating that our proposed quantitative
evaluation approach enables significantly faster convergence toward the ground
truth, especially compared to traditional qualitative methods based solely on
visual inspection and human intuition. This work not only advances the
understanding of AI assisted shape synthesis but also provides a scalable
methodology to validate and refine generative models for diverse CAD
applications.

</details>


### [5] [DIET-CP: Lightweight and Data Efficient Self Supervised Continued Pretraining](https://arxiv.org/abs/2509.06990)
*Bryan Rodas,Natalie Montesino,Jakob Ambsdorf,David Klindt,Randall Balestriero*

Main category: cs.CV

TL;DR: DIET-CP是一个简单的持续预训练策略，可以在只有1000张图像的小型数据集上，显著提升现有模型（如DINOv3）在特定领域的性能，并且不需要标签，引入的超参数也很少。


<details>
  <summary>Details</summary>
Motivation: 在专业领域，由于可用数据集规模很小，限制了SSL方法（监督学习方法）的应用，并且难以进行超参数搜索。此外，预训练模型通常只提供骨干权重，缺少继续预训练所需的重要信息。

Method: 提出DIET-CP，一个简单的持续预训练策略，它使用一个简单的目标，不需要标签，并且引入的超参数不比监督微调多。

Result: DIET-CP在不同数据模态和骨干模型中表现稳定，并显著提升了包括DINOv3在内的最先进模型性能，仅使用1000张图像。

Conclusion: DIET-CP是一个简单有效的持续预训练策略，可以帮助将强大的基础模型适配到新的目标领域，即使在数据有限的情况下也能取得显著的性能提升。

Abstract: Continued pretraining offers a promising solution for adapting foundation
models to a new target domain. However, in specialized domains, available
datasets are often very small, limiting the applicability of SSL methods
developed for large-scale pretraining and making hyperparameter search
infeasible. In addition, pretrained models are usually released as
backbone-weights only, lacking important information to continue pretraining.
We propose to bridge this gap with DIET-CP, a simple continued pretraining
strategy, where any strong foundation model can be steered towards the new data
distribution of interest. DIET-CP relies on a very simple objective, requires
no labels, and introduces no more hyperparameters than supervised finetuning.
It is stable across data modalities and backbone choices, while providing a
significant performance boost for state-of-the-art models such as DINOv3 using
only 1000 images.

</details>


### [6] [FedAPT: Federated Adversarial Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2509.06992)
*Kun Zhai,Siheng Chen,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: FedAPT是一种提高联邦提示调优（FPT）在非独立同分布（non-IID）设置下对抗性鲁棒性的新方法，通过类感知提示生成器和跨层生成器共享来解决类信息鸿沟问题，并在图像分类任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦提示调优（FPT）方法虽然能高效地进行跨客户端微调，但其调优后的模型容易受到对抗性攻击，导致下游任务分类错误。因此，需要一种能够增强FPT模型对抗性鲁棒性的新方法。

Method: 提出了一种名为FedAPT的新方法，通过以下两个关键组件来增强FPT的对抗性鲁棒性：1. 类感知提示生成器：解决FedAPT在non-IID设置下的类信息鸿沟问题，该生成器利用全局标签嵌入（编码跨客户端标签信息）来指导视觉提示的生成，使其与全局模型对齐。2. 跨层生成器共享：增强模型不同层之间提示的耦合性，进一步提高对抗性鲁棒性。

Result: FedAPT在多个图像分类数据集上的广泛实验表明，其在提高对抗性鲁棒性方面优于现有方法，并且在跨域和跨数据集场景下也表现出出色的泛化能力。

Conclusion: FedAPT通过引入类感知提示生成器和跨层生成器共享策略，有效解决了联邦提示调优在non-IID设置下的对抗性鲁棒性问题，并在图像分类任务中取得了显著的性能提升和良好的泛化能力，证明了其在实际应用中的潜力。

Abstract: Federated Prompt Tuning (FPT) is an efficient method for cross-client
collaborative fine-tuning of large Vision-Language Models (VLMs). However,
models tuned using FPT are vulnerable to adversarial attacks, leading to
misclassification in downstream tasks. In this work, we introduce Federated
Adversarial Prompt Tuning (\textbf{FedAPT}), a novel method designed to enhance
the adversarial robustness of FPT. We identify a key issue in FedAPT under
non-independent and identically distributed (non-IID) settings: a \textit{class
information gap} between clients and the global model. Clients rely solely on
limited local label information to generate adversarial samples for training,
while the global model must defend against adversarial attacks from global
labels. To address this issue, we propose a \textbf{class-aware prompt
generator} that generates visual prompts from text prompts. This generator is
guided by a \emph{Global Label Embedding} (serving as a ``beacon") which
encodes cross-client label information to create more globally-aligned visual
prompts. Additionally, we propose a \textbf{cross-layer generator sharing}
strategy to enhance prompt coupling across different layers of the model,
further boosting adversarial robustness. Extensive experiments on multiple
image classification datasets demonstrate the superiority of FedAPT in
improving adversarial robustness, outperforming existing methods by a large
margin. FedAPT also exhibits exceptional generalization in cross-domain and
cross-dataset scenarios, indicating its effectiveness in real-world
applications.

</details>


### [7] [Geospatial Foundational Embedder: Top-1 Winning Solution on EarthVision Embed2Scale Challenge (CVPR 2025)](https://arxiv.org/abs/2509.06993)
*Zirui Xu,Raphael Tang,Mike Bianco,Qi Zhang,Rishi Madhok,Nikolaos Karianakis,Fuxun Yu*

Main category: cs.CV

TL;DR:  Embed2Scale 挑战赛的获胜解决方案，将高光谱地理空间数据立方体嵌入到嵌入向量中，以促进各种下游任务。


<details>
  <summary>Details</summary>
Motivation: 开发基础地理空间模型，将高光谱地理空间数据立方体嵌入到嵌入向量中，以促进各种下游任务，例如分类、回归等。

Method: 在此技术报告中，我们介绍了我们提出的用于 Embed2Scale 挑战赛的 Top-1 获胜解决方案的方法。

Result: 在 Embed2Scale 挑战赛中获得 Top-1 获胜解决方案。

Conclusion: 

Abstract: EarthVision Embed2Scale challenge (CVPR 2025) aims to develop foundational
geospatial models to embed SSL4EO-S12 hyperspectral geospatial data cubes into
embedding vectors that faciliatetes various downstream tasks, e.g.,
classification, regression, etc. In this technical report, we introduce our
proposed method for the Top-1 winning solution on the Embed2Scale Challenge.

</details>


### [8] [VLMs-in-the-Wild: Bridging the Gap Between Academic Benchmarks and Enterprise Reality](https://arxiv.org/abs/2509.06994)
*Srihari Bandraupalli,Anupam Purwar*

Main category: cs.CV

TL;DR: 企业在部署视觉语言模型（VLM）时，面临学术评估与实际需求脱节的挑战。本研究提出了ViLD框架，包含十项关键业务任务和新颖的BlockWeaver算法，旨在弥合这一差距。通过构建包含7,500个样本的新基准数据集，并结合多种评估方法，ViLD对开源VLM进行了行业导向的评估，为企业部署提供了实践性见解。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言模型（VLM）评估基准未能反映企业部署的实际需求，尤其是在处理社交媒体内容分析等复杂场景时，现有方法依赖多项选择题和合成数据，存在局限性。

Method: 提出ViLD（VLM-in-the-Wild）框架，包含十项业务关键任务（如logo检测、OCR、场景检测等），并引入BlockWeaver算法来解决OCR输出比较问题。构建了一个包含7,500个样本的新基准数据集，结合语义匹配、传统指标和新方法进行评估。

Result: 通过ViLD框架对Qwen、MIMO和InternVL等领先的开源VLM以及一个强大的专有基线进行了基准测试，提供了首批基于行业和任务驱动的VLM能力评估，并为企业部署提供了可行性建议。

Conclusion: ViLD框架及其新颖的BlockWeaver算法，为评估VLM在企业环境中的实际应用能力提供了一个有效的解决方案，克服了现有基准的局限性，并为未来VLM在企业中的部署提供了重要的实践指导。

Abstract: Open-source Vision-Language Models show immense promise for enterprise
applications, yet a critical disconnect exists between academic evaluation and
enterprise deployment requirements. Current benchmarks rely heavily on
multiple-choice questions and synthetic data, failing to capture the complexity
of real-world business applications like social media content analysis. This
paper introduces VLM-in-the-Wild (ViLD), a comprehensive framework to bridge
this gap by evaluating VLMs on operational enterprise requirements. We define
ten business-critical tasks: logo detection, OCR, object detection, human
presence and demographic analysis, human activity and appearance analysis,
scene detection, camera perspective and media quality assessment, dominant
colors, comprehensive description, and NSFW detection. To this framework, we
bring an innovative BlockWeaver Algorithm that solves the challenging problem
of comparing unordered, variably-grouped OCR outputs from VLMs without relying
on embeddings or LLMs, achieving remarkable speed and reliability. To
demonstrate efficacy of ViLD, we constructed a new benchmark dataset of 7,500
diverse samples, carefully stratified from a corpus of one million real-world
images and videos. ViLD provides actionable insights by combining semantic
matching (both embedding-based and LLM-as-a-judge approaches), traditional
metrics, and novel methods to measure the completeness and faithfulness of
descriptive outputs. By benchmarking leading open-source VLMs (Qwen, MIMO, and
InternVL) against a powerful proprietary baseline as per ViLD framework, we
provide one of the first industry-grounded, task-driven assessment of VLMs
capabilities, offering actionable insights for their deployment in enterprise
environments.

</details>


### [9] [The Protocol Genome A Self Supervised Learning Framework from DICOM Headers](https://arxiv.org/abs/2509.06995)
*Jimmy Joseph*

Main category: cs.CV

TL;DR: Protocol Genome是一个利用DICOM头信息进行自监督学习的系统，在多个临床成像任务中提高了模型性能和校准度，尤其在外部验证集上表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 临床成像中的DICOM头部信息（如扫描仪型号、成像序列等）包含了影响图像质量和模型泛化的潜在混淆因素，传统的仅基于图像的模型难以在不同来源的数据上推广。本研究旨在利用这些结构化的DICOM头部信息来提高模型的泛化能力和鲁棒性。

Method: 本研究提出Protocol Genome系统，该系统将DICOM头部字段进行分词嵌入，并结合图像特征进行建模。具体包括三个部分：（1）协议-图像对比学习，（2）掩码协议预测，（3）协议-协议翻译。

Result: Protocol Genome在肺栓塞检测（AUROC 0.901 vs 0.847）、脑部MRI胶质瘤分级和胸部X光心增大检测任务上，相比SimCLR、MAE和ImageNet迁移学习等基线模型，外部验证集的AUROC分别提高了0.046, 0.058, 0.041。同时，模型的校准度（ECE）也从0.058降低到0.036，提高了25-37%。

Conclusion: Protocol Genome通过整合DICOM头部信息进行自监督学习，能够学习到对临床应用更鲁棒的图像表示，显著提高了在不同模态（CT, MRI, CXR）和不同厂商数据上的模型性能和校准度，并且在数据量有限的情况下仍能保持优势，可应用于PACS系统。

Abstract: In this paper, we introduce the Protocol Genome, a self-supervised learning
system that learns correlations from DICOM headers and achieves AUROC 0.901 (vs
0.847 baseline) and ECE 0.036 (vs 0.058) on fully held-out external validation.
Our method also improves calibration and robustness across modalities (CT, MRI,
CXR) and vendors. Clinical imaging is funneled through PACS/DICOM, where
procedure choices (scanner make/model, sequence, kernel, kVp, TR/TE, and slice
thickness) have consequences for contrast, noise, and artifact. These latent
confounders impede the generalization of image-only networks across sites. We
consider structured DICOM headers as a label and learn protocol-aware but
clinically robust image representations. Protocol Genome obtains tokenized
embeddings of de-identified header fields and models them along with image
features using: (1) protocol-image contrastive learning, (2) masked protocol
prediction, and (3) protocol-protocol translation. With 1.26M studies (7 health
systems, 31 scanners, 3 vendors; CT, MR, CR/DR), we experiment on: (A) chest CT
triage for PE, (B) brain MRI glioma grading, and (C) chest radiograph
cardiomegaly detection. Relative to strong SSL baselines (SimCLR, MAE) as well
as ImageNet transfer, Protocol Genome (+0.046: PE, +0.058: glioma, +0.041:
cardiomegaly) is associated with higher external AUROC; 25-37% calibration
improvements are obtained (p < 0.01, DeLong tests). While the gains may be
task-dependent, they are preserved with 10-20% of labeled data. From a clinical
point of view, the technique reduces false positives at protocol borders and is
applicable in a PACS (DICOM C-FIND/C-MOVE, DICOMweb QIDO/WADO). We publish a
model card and deployment guide, complete with both de-identification and bias
audits.

</details>


### [10] [Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems](https://arxiv.org/abs/2509.06996)
*Jie Zhang,Ting Xu,Gelei Deng,Runyi Hu,Han Qiu,Tianwei Zhang,Qing Guo,Ivor Tsang*

Main category: cs.CV

TL;DR: 当代视觉语言模型(VLMs)在识别损坏或部分遮挡的文字方面表现出严重不足，而人类则具有很强的适应性。模型在干净文本上表现良好，但在经过变形的文字上性能急剧下降，这表明它们过度依赖通用的视觉不变性，而忽视了支撑鲁棒文字能力所需的组合先验知识。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探究先进的视觉语言模型(VLMs)是否像人类一样，即使在文字不完整、组合或部分被遮挡的情况下，也能识别文字，即探究VLMs是否具备视觉韧性。

Method: 研究者构建了两个受心理物理学启发的基准测试，分别针对中文和英文字母。他们通过拼接、重组和叠加字形来创建“可见但不可读”的刺激材料，这些材料对模型来说难以识别，但对人类来说仍然清晰可见。

Result: 研究发现，尽管在干净文本上表现出色，但当前的VLMs在面对这些经过扰动的文字刺激时，性能严重下降，经常产生不相关或不连贯的输出。这表明模型在很大程度上依赖于通用的视觉不变性，但却未能充分利用对鲁棒文字识别至关重要的组合先验知识。

Conclusion: 当前VLMs在处理变形文字方面存在结构性局限，过度依赖视觉不变性而忽视了组合先验。未来的研究应着重于开发能够编码不同书写系统中的符号分割、组合和绑定的模型架构和训练策略，以应对在教育、可访问性、文化遗产和安全等领域部署多模态系统所面临的具体挑战。本研究发布了刺激生成代码、提示和评估协议，以促进透明的复制和后续研究。

Abstract: Writing is a universal cultural technology that reuses vision for symbolic
communication. Humans display striking resilience: we readily recognize words
even when characters are fragmented, fused, or partially occluded. This paper
investigates whether advanced vision language models (VLMs) share this
resilience. We construct two psychophysics inspired benchmarks across distinct
writing systems, Chinese logographs and English alphabetic words, by splicing,
recombining, and overlaying glyphs to yield ''visible but unreadable'' stimuli
for models while remaining legible to humans. Despite strong performance on
clean text, contemporary VLMs show a severe drop under these perturbations,
frequently producing unrelated or incoherent outputs. The pattern suggests a
structural limitation: models heavily leverage generic visual invariances but
under rely on compositional priors needed for robust literacy. We release
stimuli generation code, prompts, and evaluation protocols to facilitate
transparent replication and follow up work. Our findings motivate architectures
and training strategies that encode symbol segmentation, composition, and
binding across scripts, and they delineate concrete challenges for deploying
multimodal systems in education, accessibility, cultural heritage, and
security.

</details>


### [11] [K-Syn: K-space Data Synthesis in Ultra Low-data Regimes](https://arxiv.org/abs/2509.06997)
*Guan Yu,Zhang Jianhua,Liang Dong,Liu Qiegen*

Main category: cs.CV

TL;DR: 该研究提出了一种在频域进行特征学习和时间融合的动态心磁共振成像重建新方法，以解决数据稀疏问题。


<details>
  <summary>Details</summary>
Motivation: 由于心脏MRI固有的动态和复杂特性，实践中很难获得高质量和多样化的k空间数据，这阻碍了动态心脏MRI的稳健重建。

Method: 在频域进行特征级别学习，并采用时间融合策略作为生成指导来合成k空间数据。利用傅里叶变换的全局表示能力，在频域进行特征级别建模，并集成跨时间帧的k空间数据，通过多种融合策略来引导和优化生成轨迹。

Result: 实验结果表明，所提出的方法在低数据条件下具有强大的生成能力。

Conclusion: 该方法在低数据条件下显示出强大的生成能力，有望缓解动态MRI重建中的数据稀疏问题。

Abstract: Owing to the inherently dynamic and complex characteristics of cardiac
magnetic resonance (CMR) imaging, high-quality and diverse k-space data are
rarely available in practice, which in turn hampers robust reconstruction of
dynamic cardiac MRI. To address this challenge, we perform feature-level
learning directly in the frequency domain and employ a temporal-fusion strategy
as the generative guidance to synthesize k-space data. Specifically, leveraging
the global representation capacity of the Fourier transform, the frequency
domain can be considered a natural global feature space. Therefore, unlike
traditional methods that use pixel-level convolution for feature learning and
modeling in the image domain, this letter focuses on feature-level modeling in
the frequency domain, enabling stable and rich generation even with ultra
low-data regimes. Moreover, leveraging the advantages of feature-level modeling
in the frequency domain, we integrate k-space data across time frames with
multiple fusion strategies to steer and further optimize the generative
trajectory. Experimental results demonstrate that the proposed method possesses
strong generative ability in low-data regimes, indicating practical potential
to alleviate data scarcity in dynamic MRI reconstruction.

</details>


### [12] [Not All Splits Are Equal: Rethinking Attribute Generalization Across Unrelated Categories](https://arxiv.org/abs/2509.06998)
*Liviu Nicolae Fircă,Antonio Bărbălau,Dan Oneata,Elena Burceanu*

Main category: cs.CV

TL;DR: 模型难以泛化到语义和感知上不相关的类别，现有评估方法对训练测试集划分敏感，聚类方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 评估当前模型在语义和感知上不相关的类别之间泛化属性知识的能力。

Method: 引入基于LLM语义分组、嵌入相似度阈值、嵌入聚类和超类别划分的训练测试集划分策略，以评估模型泛化能力。

Result: 随着训练集和测试集之间相关性的降低，模型性能急剧下降，表明模型对划分策略非常敏感。聚类方法在降低隐藏相关性和保持可学习性之间取得了最佳平衡。

Conclusion: 当前模型的表征能力有限，泛化属性知识到不相关类别存在挑战。未来的基准测试需要考虑属性推理的构建。

Abstract: Can models generalize attribute knowledge across semantically and
perceptually dissimilar categories? While prior work has addressed attribute
prediction within narrow taxonomic or visually similar domains, it remains
unclear whether current models can abstract attributes and apply them to
conceptually distant categories. This work presents the first explicit
evaluation for the robustness of the attribute prediction task under such
conditions, testing whether models can correctly infer shared attributes
between unrelated object types: e.g., identifying that the attribute "has four
legs" is common to both "dogs" and "chairs". To enable this evaluation, we
introduce train-test split strategies that progressively reduce correlation
between training and test sets, based on: LLM-driven semantic grouping,
embedding similarity thresholding, embedding-based clustering, and
supercategory-based partitioning using ground-truth labels. Results show a
sharp drop in performance as the correlation between training and test
categories decreases, indicating strong sensitivity to split design. Among the
evaluated methods, clustering yields the most effective trade-off, reducing
hidden correlations while preserving learnability. These findings offer new
insights into the limitations of current representations and inform future
benchmark construction for attribute reasoning.

</details>


### [13] [MEGS$^{2}$: Memory-Efficient Gaussian Splatting via Spherical Gaussians and Unified Pruning](https://arxiv.org/abs/2509.07021)
*Jiarui Chen,Yikeng Chen,Yingshuang Zou,Ye Huang,Peng Wang,Yuan Liu,Yujing Sun,Wenping Wang*

Main category: cs.CV

TL;DR: MEGS$^{2}$通过优化原始数和每原始参数，引入了内存高效的3D高斯泼溅框架，实现了显著的显存减少，同时保持了可比的渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3D高斯泼溅（3DGS）方法内存消耗高，限制了其在边缘设备上的应用。现有的3DGS压缩方法主要关注存储压缩，未能解决渲染内存的关键瓶颈。

Method: MEGS$^{2}$框架通过以下方式解决内存问题：1. 使用轻量级的任意方向球面高斯瓣替代内存密集型球面谐波作为颜色表示。2. 提出一个统一的软剪枝框架，将原始数和瓣数剪枝建模为单一的约束优化问题。

Result: MEGS$^{2}$实现了50%的静态显存减少和40%的渲染显存减少，同时保持了可比的渲染质量。

Conclusion: MEGS$^{2}$是一种新颖的内存高效框架，通过联合优化原始数和每原始参数，实现了前所未有的内存压缩，解决了3DGS在内存方面的关键挑战。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a dominant novel-view synthesis
technique, but its high memory consumption severely limits its applicability on
edge devices. A growing number of 3DGS compression methods have been proposed
to make 3DGS more efficient, yet most only focus on storage compression and
fail to address the critical bottleneck of rendering memory. To address this
problem, we introduce MEGS$^{2}$, a novel memory-efficient framework that
tackles this challenge by jointly optimizing two key factors: the total
primitive number and the parameters per primitive, achieving unprecedented
memory compression. Specifically, we replace the memory-intensive spherical
harmonics with lightweight arbitrarily-oriented spherical Gaussian lobes as our
color representations. More importantly, we propose a unified soft pruning
framework that models primitive-number and lobe-number pruning as a single
constrained optimization problem. Experiments show that MEGS$^{2}$ achieves a
50% static VRAM reduction and a 40% rendering VRAM reduction compared to
existing methods, while maintaining comparable rendering quality.

</details>


### [14] [Moment- and Power-Spectrum-Based Gaussianity Regularization for Text-to-Image Models](https://arxiv.org/abs/2509.07027)
*Jisung Hwang,Jaihoon Kim,Minhyuk Sung*

Main category: cs.CV

TL;DR: 提出一种新颖的正则化损失，强制执行标准高斯性，使样本与标准高斯分布对齐，从而促进文本到图像模型潜在空间中的优化任务。该损失结合了空间域中的矩基正则化和谱域中的功率谱基正则化，并对随机置换的输入应用损失以确保排列不变性。该方法优于以前的高斯性正则化，可有效防止奖励破解并加速收敛。


<details>
  <summary>Details</summary>
Motivation: 为了改进文本到图像模型潜在空间中的优化任务，并提出一种能够促进样本与标准高斯分布对齐的新型正则化损失。

Method: 将高维样本的元素视为一维标准高斯变量，并定义了一个复合损失，该损失结合了空间域中的矩基正则化和谱域中的功率谱基正则化。为了确保排列不变性，将损失应用于随机置换的输入。

Result: 所提出的正则化方法在生成模型中用于文本到图像模型的测试时间奖励对齐，以增强美学和文本对齐。与以前的高斯性正则化方法相比，该方法表现更好，有效防止了奖励破解，并加速了收敛。

Conclusion: 提出了一种新颖的正则化损失，它通过强制执行标准高斯性来改进文本到图像模型潜在空间中的优化。该方法在增强美学和文本对齐方面优于现有方法，并能有效防止奖励破解和加速收敛。

Abstract: We propose a novel regularization loss that enforces standard Gaussianity,
encouraging samples to align with a standard Gaussian distribution. This
facilitates a range of downstream tasks involving optimization in the latent
space of text-to-image models. We treat elements of a high-dimensional sample
as one-dimensional standard Gaussian variables and define a composite loss that
combines moment-based regularization in the spatial domain with power
spectrum-based regularization in the spectral domain. Since the expected values
of moments and power spectrum distributions are analytically known, the loss
promotes conformity to these properties. To ensure permutation invariance, the
losses are applied to randomly permuted inputs. Notably, existing
Gaussianity-based regularizations fall within our unified framework: some
correspond to moment losses of specific orders, while the previous
covariance-matching loss is equivalent to our spectral loss but incurs higher
time complexity due to its spatial-domain computation. We showcase the
application of our regularization in generative modeling for test-time reward
alignment with a text-to-image model, specifically to enhance aesthetics and
text alignment. Our regularization outperforms previous Gaussianity
regularization, effectively prevents reward hacking and accelerates
convergence.

</details>


### [15] [SAM$^{*}$: Task-Adaptive SAM with Physics-Guided Rewards](https://arxiv.org/abs/2509.07047)
*Kamyar Barakati,Utkarsh Pratiush,Sheryl L. Sanchez,Aditya Raghavan,Delia J. Milliron,Mahshid Ahmadi,Philip D. Rack,Sergei V. Kalinin*

Main category: cs.CV

TL;DR: 通过基于奖励函数的优化来调整基础模型，以实现显微成像中的实时流数据分割。


<details>
  <summary>Details</summary>
Motivation: 基础模型（如Segment Anything Model）在图像分割任务中很有用，但其大量不透明的调整参数限制了它们在实时流数据分析中的应用。

Method: 提出了一种基于奖励函数的优化方法来微调基础模型，特别是Meta的Segment Anything Model（SAM），以创建SAM*。奖励函数可以根据成像系统的物理特性（如粒子大小分布、几何形状等）进行构建。

Result: 优化的SAM*模型能够更好地适应各种分割任务，并能进行实时流数据分割，在显微成像中分析细胞结构、材料界面和纳米特征方面表现出有效性。

Conclusion: 基于奖励函数的优化方法能够增强基础模型（如SAM）在显微成像等领域的适应性和性能，从而实现高效的实时流数据分割。

Abstract: Image segmentation is a critical task in microscopy, essential for accurately
analyzing and interpreting complex visual data. This task can be performed
using custom models trained on domain-specific datasets, transfer learning from
pre-trained models, or foundational models that offer broad applicability.
However, foundational models often present a considerable number of
non-transparent tuning parameters that require extensive manual optimization,
limiting their usability for real-time streaming data analysis. Here, we
introduce a reward function-based optimization to fine-tune foundational models
and illustrate this approach for SAM (Segment Anything Model) framework by
Meta. The reward functions can be constructed to represent the physics of the
imaged system, including particle size distributions, geometries, and other
criteria. By integrating a reward-driven optimization framework, we enhance
SAM's adaptability and performance, leading to an optimized variant, SAM$^{*}$,
that better aligns with the requirements of diverse segmentation tasks and
particularly allows for real-time streaming data segmentation. We demonstrate
the effectiveness of this approach in microscopy imaging, where precise
segmentation is crucial for analyzing cellular structures, material interfaces,
and nanoscale features.

</details>


### [16] [Enhancing Classification of Streaming Data with Image Distillation](https://arxiv.org/abs/2509.07049)
*Rwad Khatib,Yehudit Aperstein*

Main category: cs.CV

TL;DR: 通过数据蒸馏技术提升流式图像数据分类精度，DBC方法在准确性和效率上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在内存和计算资源有限的环境中，实现流式数据的有效分类，并利用数据蒸馏技术提高流式图像数据分类的精度。

Method: 应用数据蒸馏技术，提取数据流中的关键特征，以最小化计算需求并保留关键信息，同时与Hoeffding Trees、Adaptive Random Forest（通过嵌入适应图像数据）以及Reservoir Sampling Based Classification（RBC）进行比较。

Result: DBC方法实现了73.1%的准确率，优于传统方法和RBC技术。

Conclusion: 数据蒸馏是一种有效的方法，可以在处理复杂数据流时实现高准确性和高效率，为流式数据分类设定了新的标准。

Abstract: This study tackles the challenge of efficiently classifying streaming data in
envi-ronments with limited memory and computational resources. It delves into
the application of data distillation as an innovative approach to improve the
precision of streaming image data classification. By focusing on distilling
essential features from data streams, our method aims to minimize computational
demands while preserving crucial information for accurate classification. Our
investigation com-pares this approach against traditional algorithms like
Hoeffding Trees and Adap-tive Random Forest, adapted through embeddings for
image data. The Distillation Based Classification (DBC) demonstrated superior
performance, achieving a 73.1% accuracy rate, surpassing both traditional
methods and Reservoir Sam-pling Based Classification (RBC) technique. This
marks a significant advance-ment in streaming data classification, showcasing
the effectiveness of our method in processing complex data streams and setting
a new standard for accuracy and efficiency.

</details>


### [17] [Automated Evaluation of Gender Bias Across 13 Large Multimodal Models](https://arxiv.org/abs/2509.07050)
*Juan Manuel Contreras*

Main category: cs.CV

TL;DR: 大型多模态模型（LMMs）在性别刻板印象方面存在系统性偏差，并且会放大这些偏差，但偏差程度因模型而异。


<details>
  <summary>Details</summary>
Motivation: 识别和量化大型多模态模型（LMMs）在文本到图像生成中存在的性别偏见，并提供一个可扩展的、可比较的跨模型分析方法。

Method: 引入Aymara图像公平性评估基准，使用75个中性提示和LLM-as-a-judge系统来评估13个LMMs生成的965张图像中的性别代表性。

Result: LMMs会系统性地放大职业性别刻板印象，并在非刻板印象的职业中表现出默认男性偏见，偏差程度因模型而异。

Conclusion: 高偏见并非不可避免，而是设计选择的结果。需要标准化的自动化评估工具来促进AI开发的问责制和公平性。

Abstract: Large multimodal models (LMMs) have revolutionized text-to-image generation,
but they risk perpetuating the harmful social biases in their training data.
Prior work has identified gender bias in these models, but methodological
limitations prevented large-scale, comparable, cross-model analysis. To address
this gap, we introduce the Aymara Image Fairness Evaluation, a benchmark for
assessing social bias in AI-generated images. We test 13 commercially available
LMMs using 75 procedurally-generated, gender-neutral prompts to generate people
in stereotypically-male, stereotypically-female, and non-stereotypical
professions. We then use a validated LLM-as-a-judge system to score the 965
resulting images for gender representation. Our results reveal (p < .001 for
all): 1) LMMs systematically not only reproduce but actually amplify
occupational gender stereotypes relative to real-world labor data, generating
men in 93.0% of images for male-stereotyped professions but only 22.5% for
female-stereotyped professions; 2) Models exhibit a strong default-male bias,
generating men in 68.3% of the time for non-stereotyped professions; and 3) The
extent of bias varies dramatically across models, with overall male
representation ranging from 46.7% to 73.3%. Notably, the top-performing model
de-amplified gender stereotypes and approached gender parity, achieving the
highest fairness scores. This variation suggests high bias is not an inevitable
outcome but a consequence of design choices. Our work provides the most
comprehensive cross-model benchmark of gender bias to date and underscores the
necessity of standardized, automated evaluation tools for promoting
accountability and fairness in AI development.

</details>


### [18] [Faster VGGT with Block-Sparse Global Attention](https://arxiv.org/abs/2509.07120)
*Chung-Shien Brian Wang,Christian Schmidt,Jens Piekenbrinck,Bastian Leibe*

Main category: cs.CV

TL;DR: 通过使用块稀疏注意力机制优化Transformer，在保持性能的同时将推理速度提高了4倍，解决了现有模型在处理大型图像集时的运行时瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的多视图重建模型（如VGGT和$\pi^3$）虽然性能优异，但由于全局注意力层的二次复杂度，存在运行时瓶颈，限制了其处理大型图像集的能力。

Method: 提出了一种基于高度优化的块稀疏核的注意力机制，用于替代密集全局注意力。该方法通过分析全局注意力矩阵，发现大部分概率集中在对应于跨视图几何匹配的少量块-块交互上。

Result: 提出的块稀疏注意力机制在推理速度上提高了4倍，同时保持了与现有模型相当的任务性能。该方法无需重新训练骨干网络，可扩展至VGGT和$\\pi^3$模型，并支持大型图像集合。

Conclusion: 该方法通过引入块稀疏注意力机制，有效解决了现有Transformer在多视图重建中面临的运行时瓶颈问题，显著提高了推理效率，同时保持了性能，并在多个多视图基准测试中得到了验证。

Abstract: Efficient and accurate feed-forward multi-view reconstruction has long been
an important task in computer vision. Recent transformer-based models like VGGT
and $\pi^3$ have achieved impressive results with simple architectures, yet
they face an inherent runtime bottleneck, due to the quadratic complexity of
the global attention layers, that limits the scalability to large image sets.
In this paper, we empirically analyze the global attention matrix of these
models and observe that probability mass concentrates on a small subset of
patch-patch interactions that correspond to cross-view geometric matches.
Motivated by the structured attention and inspired by recent advancement in
large language models, we propose a replacement for the dense global attention
operation based on highly optimized block-sparse kernels, yielding up to
$4\times$ faster inference with comparable task performance. Our retrofit
requires no retraining of the backbone, extends to both VGGT and $\pi^3$, and
supports large image collections. Evaluations on a comprehensive suite of
multi-view benchmarks demonstrate the effectiveness of our approach.

</details>


### [19] [Detection and Recovery of Adversarial Slow-Pose Drift in Offloaded Visual-Inertial Odometry](https://arxiv.org/abs/2509.07130)
*Soruya Saha,Md Nurul Absur,Saptarshi Debroy*

Main category: cs.CV

TL;DR: 在边缘服务器上进行视觉-惯性里程计（VIO）时，存在因细微的姿态欺骗累积成显著的漂移而逃避启发式检查的服务器端威胁。本文提出了一种无监督、无标签的检测和恢复机制，该机制通过学习无攻击会话中的运动时间规律来检测运行时偏差并恢复姿态一致性。


<details>
  <summary>Details</summary>
Motivation: 当前的VIO解决方案将计算任务转移到边缘服务器，这可能导致服务器端受到攻击，其中细微的姿态欺骗会累积成显著的漂移，并逃避启发式检查。

Method: 提出了一种无监督、无标签的检测和恢复机制。该模型在无攻击会话中进行训练，以学习运动的时间规律，从而检测运行时偏差并启动恢复以恢复姿态一致性。

Result: 在具有挑战性的offloaded-VIO环境中，与无防御基线相比，在轨迹和姿态误差方面有了显著的改善。

Conclusion: 所提出的方法能够有效检测并恢复由姿态欺骗引起的VIO错误，从而提高VR体验的鲁棒性。

Abstract: Visual-Inertial Odometry (VIO) supports immersive Virtual Reality (VR) by
fusing camera and Inertial Measurement Unit (IMU) data for real-time pose.
However, current trend of offloading VIO to edge servers can lead server-side
threat surface where subtle pose spoofing can accumulate into substantial
drift, while evading heuristic checks. In this paper, we study this threat and
present an unsupervised, label-free detection and recovery mechanism. The
proposed model is trained on attack-free sessions to learn temporal
regularities of motion to detect runtime deviations and initiate recovery to
restore pose consistency. We evaluate the approach in a realistic offloaded-VIO
environment using ILLIXR testbed across multiple spoofing intensities.
Experimental results in terms of well-known performance metrics show
substantial reductions in trajectory and pose error compared to a no-defense
baseline.

</details>


### [20] [Realism to Deception: Investigating Deepfake Detectors Against Face Enhancement](https://arxiv.org/abs/2509.07178)
*Muhammad Saad Saeed,Ijaz Ul Haq,Khalid Malik*

Main category: cs.CV

TL;DR: 面部增强技术会降低深度伪影检测器的准确性，因为它们会扭曲生物特征。研究人员评估了传统和基于 GAN 的增强方法对不同检测器的影响，发现这些技术可以作为“反取证”工具，显著降低检测准确率。他们还进行了对抗性训练实验，以提高模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 面部增强技术在提高感观质量的同时，可能会损害生物特征，从而降低深度伪影检测器的准确性。本研究旨在调查这些技术是否会起到“反取证”的作用，通过降低检测准确率来促进深度伪影的传播。

Method: 本研究系统地评估了常用的面部增强方法（包括传统图像处理和基于 GAN 的方法）对朴素、空间和基于频率的检测方法的有效性。此外，还进行了对抗性训练实验，以评估模型暴露于面部增强转换后的鲁棒性。

Result: 在 FaceForensics++、DeepFakeDetection 和 CelebDF-v2 数据集上的实验表明，即使是基本的增强滤镜也能将检测准确率降低高达 64.63% (ASR)。基于 GAN 的技术进一步利用了这些漏洞，ASR 高达 75.12%。

Conclusion: 面部增强技术可以有效地作为“反取证”工具，降低深度伪影检测器的准确性。这强调了开发更具鲁棒性和适应性的取证方法的需求。

Abstract: Face enhancement techniques are widely used to enhance facial appearance.
However, they can inadvertently distort biometric features, leading to
significant decrease in the accuracy of deepfake detectors. This study
hypothesizes that these techniques, while improving perceptual quality, can
degrade the performance of deepfake detectors. To investigate this, we
systematically evaluate whether commonly used face enhancement methods can
serve an anti-forensic role by reducing detection accuracy. We use both
traditional image processing methods and advanced GAN-based enhancements to
evaluate the robustness of deepfake detectors. We provide a comprehensive
analysis of the effectiveness of these enhancement techniques, focusing on
their impact on Na\"ive, Spatial, and Frequency-based detection methods.
Furthermore, we conduct adversarial training experiments to assess whether
exposure to face enhancement transformations improves model robustness.
Experiments conducted on the FaceForensics++, DeepFakeDetection, and CelebDF-v2
datasets indicate that even basic enhancement filters can significantly reduce
detection accuracy achieving ASR up to 64.63\%. In contrast, GAN-based
techniques further exploit these vulnerabilities, achieving ASR up to 75.12\%.
Our results demonstrate that face enhancement methods can effectively function
as anti-forensic tools, emphasizing the need for more resilient and adaptive
forensic methods.

</details>


### [21] [Dimensionally Reduced Open-World Clustering: DROWCULA](https://arxiv.org/abs/2509.07184)
*Erencem Ozbey,Dimitrios I. Diochnos*

Main category: cs.CV

TL;DR: 本文提出了一种全无监督的方法来检测图像数据中的新类别，利用 Vision Transformers 估计簇的数量，并通过流形学习技术优化嵌入，在多个数据集上达到了新的最先进水平。


<details>
  <summary>Details</summary>
Motivation: 在监督学习中，对数据进行标注是关键，但需要大量的人力。在实际应用中，即使有了大量标注数据，未来仍可能出现新类别的样本，这使得问题更加复杂。现有工作主要集中在半监督方法来解决这种“开放世界”下的新类别发现问题。

Method: 本文提出了一种全无监督的方法。该方法利用 Vision Transformers（一种利用注意力机制生成向量嵌入的模型）来估计簇的数量。此外，还结合了流形学习技术，通过利用数据的内在几何结构来优化这些嵌入，从而提高图像聚类性能。

Result: 在 CIFAR-10、CIFAR-100、ImageNet-100 和 Tiny ImageNet 数据集上，我们在单模态聚类和新类别发现方面取得了新的最先进（State-of-the-Art）结果。无论在之前是否已知簇的数量的情况下，均取得了优异表现。

Conclusion: 本文提出了一种创新的全无监督方法，通过结合 Vision Transformers 和流形学习，有效地解决了图像分类中的新类别发现问题，并在多个标准数据集上取得了领先的性能。

Abstract: Working with annotated data is the cornerstone of supervised learning.
Nevertheless, providing labels to instances is a task that requires significant
human effort. Several critical real-world applications make things more
complicated because no matter how many labels may have been identified in a
task of interest, it could be the case that examples corresponding to novel
classes may appear in the future. Not unsurprisingly, prior work in this,
so-called, `open-world' context has focused a lot on semi-supervised
approaches.
  Focusing on image classification, somehow paradoxically, we propose a fully
unsupervised approach to the problem of determining the novel categories in a
particular dataset. Our approach relies on estimating the number of clusters
using Vision Transformers, which utilize attention mechanisms to generate
vector embeddings. Furthermore, we incorporate manifold learning techniques to
refine these embeddings by exploiting the intrinsic geometry of the data,
thereby enhancing the overall image clustering performance. Overall, we
establish new State-of-the-Art results on single-modal clustering and Novel
Class Discovery on CIFAR-10, CIFAR-100, ImageNet-100, and Tiny ImageNet. We do
so, both when the number of clusters is known or unknown ahead of time. The
code is available at: https://github.com/DROWCULA/DROWCULA.

</details>


### [22] [XBusNet: Text-Guided Breast Ultrasound Segmentation via Multimodal Vision-Language Learning](https://arxiv.org/abs/2509.07213)
*Raja Mallina,Bryar Shareef*

Main category: cs.CV

TL;DR: XBusNet是一个新颖的、双提示、双分支的多模态模型，结合了图像特征和临床文本，用于乳腺超声分割。它通过全局路径（CLIP Vision Transformer）编码全图像语义，并通过局部U-Net路径强调精确边界，该路径由描述形状、边缘和BI-RADS术语的提示进行调制。该模型在BLU数据集上实现了最先进的性能，尤其是在小病灶分割方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 精确的乳腺超声（BUS）分割有助于可靠的测量、定量分析和下游分类，但对于边缘模糊、斑点噪声明显的小病灶或低对比度病灶仍然具有挑战性。文本提示可以提供临床背景，但直接使用弱定位的文本-图像线索（如CAM/CLIP信号）往往产生粗糙、块状的响应，模糊边界，需要额外的机制来恢复精细边缘。

Method: 提出XBusNet，一个新颖的双提示、双分支多模态模型，结合图像特征和临床文本。全局路径基于CLIP Vision Transformer，编码以病灶大小和位置为条件的整个图像语义；局部U-Net路径强调精确边界，并由描述形状、边缘和BI-RADS术语的提示进行调制。提示从结构化元数据自动生成，无需手动点击。在BLU数据集上使用五折交叉验证进行评估，主要指标为Dice和IoU，并进行了分层分析和消融研究。

Result: XBusNet在BLU数据集上取得了最先进的性能，平均Dice为0.8765，IoU为0.8149，优于六个强大的基线模型。在小病灶方面，改善尤为显著，漏检区域减少，虚假激活也减少。消融研究表明，全局上下文、局部边界建模和基于提示的调制都做出了互补的贡献。

Conclusion: 结合全局语义和局部精度的双提示、双分支多模态设计，可以生成精确的BUS分割掩码，并提高对小病灶、低对比度病灶的分割鲁棒性。

Abstract: Background: Precise breast ultrasound (BUS) segmentation supports reliable
measurement, quantitative analysis, and downstream classification, yet remains
difficult for small or low-contrast lesions with fuzzy margins and speckle
noise. Text prompts can add clinical context, but directly applying weakly
localized text-image cues (e.g., CAM/CLIP-derived signals) tends to produce
coarse, blob-like responses that smear boundaries unless additional mechanisms
recover fine edges. Methods: We propose XBusNet, a novel dual-prompt,
dual-branch multimodal model that combines image features with clinically
grounded text. A global pathway based on a CLIP Vision Transformer encodes
whole-image semantics conditioned on lesion size and location, while a local
U-Net pathway emphasizes precise boundaries and is modulated by prompts that
describe shape, margin, and Breast Imaging Reporting and Data System (BI-RADS)
terms. Prompts are assembled automatically from structured metadata, requiring
no manual clicks. We evaluate on the Breast Lesions USG (BLU) dataset using
five-fold cross-validation. Primary metrics are Dice and Intersection over
Union (IoU); we also conduct size-stratified analyses and ablations to assess
the roles of the global and local paths and the text-driven modulation.
Results: XBusNet achieves state-of-the-art performance on BLU, with mean Dice
of 0.8765 and IoU of 0.8149, outperforming six strong baselines. Small lesions
show the largest gains, with fewer missed regions and fewer spurious
activations. Ablation studies show complementary contributions of global
context, local boundary modeling, and prompt-based modulation. Conclusions: A
dual-prompt, dual-branch multimodal design that merges global semantics with
local precision yields accurate BUS segmentation masks and improves robustness
for small, low-contrast lesions.

</details>


### [23] [Breast Cancer Detection in Thermographic Images via Diffusion-Based Augmentation and Nonlinear Feature Fusion](https://arxiv.org/abs/2509.07277)
*Sepehr Salem,M. Moein Esfahani,Jingyu Liu,Vince Calhoun*

Main category: cs.CV

TL;DR: 通过扩散模型进行数据增强和融合深度与传统非线性特征，用于乳腺癌热成像分类，实现高准确率。


<details>
  <summary>Details</summary>
Motivation: 医疗影像的深度学习常受数据稀疏性问题困扰。本研究旨在解决这一挑战，提出一个用于乳腺癌热成像分类的框架。

Method: 提出一个利用扩散概率模型（DPM）进行数据增强的框架。该框架融合了预训练的ResNet-50的深度特征和从U-Net分割的肿瘤中提取的手工非线性特征（如分形维度）。使用XGBoost分类器对融合后的特征进行训练。

Result: DPM数据增强效果优于传统方法和ProGAN基线。融合特征的XGBoost分类器达到了98.0%的准确率和98.1%的敏感度。消融研究和统计检验证实了DPM增强和非线性特征融合的重要性。

Conclusion: 本研究验证了先进的生成模型与可解释特征之间的协同作用，可用于创建高精度的医疗诊断工具。

Abstract: Data scarcity hinders deep learning for medical imaging. We propose a
framework for breast cancer classification in thermograms that addresses this
using a Diffusion Probabilistic Model (DPM) for data augmentation. Our
DPM-based augmentation is shown to be superior to both traditional methods and
a ProGAN baseline. The framework fuses deep features from a pre-trained
ResNet-50 with handcrafted nonlinear features (e.g., Fractal Dimension) derived
from U-Net segmented tumors. An XGBoost classifier trained on these fused
features achieves 98.0\% accuracy and 98.1\% sensitivity. Ablation studies and
statistical tests confirm that both the DPM augmentation and the nonlinear
feature fusion are critical, statistically significant components of this
success. This work validates the synergy between advanced generative models and
interpretable features for creating highly accurate medical diagnostic tools.

</details>


### [24] [Reconstruction Alignment Improves Unified Multimodal Models](https://arxiv.org/abs/2509.07295)
*Ji Xie,Trevor Darrell,Luke Zettlemoyer,XuDong Wang*

Main category: cs.CV

TL;DR: RecA是一种资源高效的后训练方法，利用视觉理解编码器嵌入作为密集的“文本提示”，在没有字幕的情况下提供丰富的监督，以改进统一多模态模型（UMMs）的生成和编辑保真度。


<details>
  <summary>Details</summary>
Motivation: 传统的UMMs依赖于稀疏且缺乏细微视觉细节的图像-文本对进行训练。

Method: RecA是一种后训练方法，它利用UMM的视觉理解嵌入作为文本提示，并对其进行优化，以通过自监督重建损失来重建输入图像，从而重新对齐理解和生成。

Result: RecA在GenEval（0.73→0.90）和DPGBench（80.93→88.15）上显著提高了图像生成性能，并提高了ImgEdit（3.38→3.75）和GEdit（6.94→7.25）的编辑基准。仅需27个GPU小时，性能就得到了提升。

Conclusion: RecA是一种高效且通用的UMM后训练对齐策略，能够显著提高生成和编辑保真度，并且优于许多更大的开源模型。

Abstract: Unified multimodal models (UMMs) unify visual understanding and generation
within a single architecture. However, conventional training relies on
image-text pairs (or sequences) whose captions are typically sparse and miss
fine-grained visual details--even when they use hundreds of words to describe a
simple image. We introduce Reconstruction Alignment (RecA), a
resource-efficient post-training method that leverages visual understanding
encoder embeddings as dense "text prompts," providing rich supervision without
captions. Concretely, RecA conditions a UMM on its own visual understanding
embeddings and optimizes it to reconstruct the input image with a
self-supervised reconstruction loss, thereby realigning understanding and
generation. Despite its simplicity, RecA is broadly applicable: across
autoregressive, masked-autoregressive, and diffusion-based UMMs, it
consistently improves generation and editing fidelity. With only 27 GPU-hours,
post-training with RecA substantially improves image generation performance on
GenEval (0.73$\rightarrow$0.90) and DPGBench (80.93$\rightarrow$88.15), while
also boosting editing benchmarks (ImgEdit 3.38$\rightarrow$3.75, GEdit
6.94$\rightarrow$7.25). Notably, RecA surpasses much larger open-source models
and applies broadly across diverse UMM architectures, establishing it as an
efficient and general post-training alignment strategy for UMMs

</details>


### [25] [DEPF: A UAV Multispectral Object Detector with Dual-Domain Enhancement and Priority-Guided Mamba Fusion](https://arxiv.org/abs/2509.07327)
*Shucong Li,Zhenyu Liu,Zijie Hong,Zhiheng Zhou,Xianghai Cao*

Main category: cs.CV

TL;DR: 本文提出了一种名为DEPF（双域增强和优先引导Mamba融合）的无人机多光谱目标检测方法，以解决低光照、小目标建模和Transformer计算复杂度高等挑战。


<details>
  <summary>Details</summary>
Motivation: 低光照、冗余信息干扰小目标建模、Transformer模型计算复杂度高是无人机多光谱遥感目标检测面临的挑战。

Method: 提出DEPF模型，包含双域增强模块（DDE）和优先引导Mamba融合模块（PGMF）。DDE通过跨尺度Mamba扫描（CSWM）和傅里叶细节恢复（FDR）增强低光照图像；PGMF引入优先扫描概念，根据模态差异的优先级分数，从局部目标特征开始融合。

Result: 在DroneVehicle和VEDAI数据集上的实验表明，DEPF在目标检测性能上优于现有最先进的方法。

Conclusion: DEPF模型有效解决了无人机多光谱遥感目标检测中的挑战，并在实验中取得了优于现有方法的性能。

Abstract: Multispectral remote sensing object detection is one of the important
application of unmanned aerial vehicle (UAV). However, it faces three
challenges. Firstly, the low-light remote sensing images reduce the
complementarity during multi-modality fusion. Secondly, the local small target
modeling is interfered with redundant information in the fusion stage easily.
Thirdly, due to the quadratic computational complexity, it is hard to apply the
transformer-based methods on the UAV platform. To address these limitations,
motivated by Mamba with linear complexity, a UAV multispectral object detector
with dual-domain enhancement and priority-guided mamba fusion (DEPF) is
proposed. Firstly, to enhance low-light remote sensing images, Dual-Domain
Enhancement Module (DDE) is designed, which contains Cross-Scale Wavelet Mamba
(CSWM) and Fourier Details Recovery block (FDR). CSWM applies cross-scale mamba
scanning for the low-frequency components to enhance the global brightness of
images, while FDR constructs spectrum recovery network to enhance the frequency
spectra features for recovering the texture-details. Secondly, to enhance local
target modeling and reduce the impact of redundant information during fusion,
Priority-Guided Mamba Fusion Module (PGMF) is designed. PGMF introduces the
concept of priority scanning, which starts from local targets features
according to the priority scores obtained from modality difference. Experiments
on DroneVehicle dataset and VEDAI dataset reports that, DEPF performs well on
object detection, comparing with state-of-the-art methods. Our code is
available in the supplementary material.

</details>


### [26] [G3CN: Gaussian Topology Refinement Gated Graph Convolutional Network for Skeleton-Based Action Recognition](https://arxiv.org/abs/2509.07335)
*Haiqing Ren,Zhongkai Luo,Heng Fan,Xiaohui Yuan,Guanchen Wang,Libo Zhang*

Main category: cs.CV

TL;DR: GCN在基于骨架的动作识别中表现出色，但难以区分歧义动作。本文提出G3CN，通过高斯滤波细化骨架拓扑和门控循环单元增强信息传播，从而提高歧义动作的识别精度，并在多个基准测试中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图卷积网络（GCN）的骨架动作识别方法在区分歧义动作方面存在局限性，因为它们在学习到的拓扑和空间特征表示能力上有所不足。

Method: 提出了一种名为高斯拓扑细化门控图卷积（G3CN）的新方法。该方法结合了高斯滤波器来细化骨架拓扑图，并集成了门控循环单元（GRUs）来增强骨架点之间的信息传播。

Result: G3CN在NTU RGB+D、NTU RGB+D 120和NW-UCLA基准测试中表现出色，尤其在区分歧义动作方面显示出显著的改进，并且能够很好地泛化到各种GCN骨干网络。

Conclusion: G3CN通过细化骨架拓扑和增强信息传播，有效解决了现有GCN方法在区分歧义动作方面的挑战，并在多个公开数据集上证明了其优越的性能。

Abstract: Graph Convolutional Networks (GCNs) have proven to be highly effective for
skeleton-based action recognition, primarily due to their ability to leverage
graph topology for feature aggregation, a key factor in extracting meaningful
representations. However, despite their success, GCNs often struggle to
effectively distinguish between ambiguous actions, revealing limitations in the
representation of learned topological and spatial features. To address this
challenge, we propose a novel approach, Gaussian Topology Refinement Gated
Graph Convolution (G$^{3}$CN), to address the challenge of distinguishing
ambiguous actions in skeleton-based action recognition. G$^{3}$CN incorporates
a Gaussian filter to refine the skeleton topology graph, improving the
representation of ambiguous actions. Additionally, Gated Recurrent Units (GRUs)
are integrated into the GCN framework to enhance information propagation
between skeleton points. Our method shows strong generalization across various
GCN backbones. Extensive experiments on NTU RGB+D, NTU RGB+D 120, and NW-UCLA
benchmarks demonstrate that G$^{3}$CN effectively improves action recognition,
particularly for ambiguous samples.

</details>


### [27] [Parse Graph-Based Visual-Language Interaction for Human Pose Estimation](https://arxiv.org/abs/2509.07385)
*Shibang Liu,Xuemei Xie,Guangming Shi*

Main category: cs.CV

TL;DR: PGVL是一种结合了视觉和语言信息的新方法，通过构建解析图和引入引导模块（GM）来提高人体姿态估计（HPE）的准确性，特别是在处理遮挡场景时。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多只关注单一模态，忽略了多模态融合的潜力。特别是语言信息包含丰富的姿态估计先验知识，但现有的视觉-语言融合方法由于全局特征融合，会削弱遮挡区域的响应，并导致对齐和定位失败。

Method: 提出了一种名为PGVL（Parse Graph-based Visual-Language）的交互方法，其核心是引导模块（GM）。PGVL通过自上而下的分解和自下而上的组合，首先构建特定模态的解析图，然后利用GM进行递归的双向交叉注意力，以实现有效的多模态信息融合。

Result: PGVL在主要的人体姿态估计数据集上进行了验证，并取得了良好的效果（具体效果未在摘要中量化）。

Conclusion: PGVL通过引入解析图和引导模块，有效融合了视觉和语言信息，解决了现有方法在处理遮挡场景时遇到的对齐和定位问题，提高了HPE的性能。

Abstract: Parse graphs boost human pose estimation (HPE) by integrating context and
hierarchies, yet prior work mostly focuses on single modality modeling,
ignoring the potential of multimodal fusion. Notably, language offers rich HPE
priors like spatial relations for occluded scenes, but existing visual-language
fusion via global feature integration weakens occluded region responses and
causes alignment and location failures. To address this issue, we propose Parse
Graph-based Visual-Language interaction (PGVL) with a core novel Guided Module
(GM). In PGVL, low-level nodes focus on local features, maximizing the
maintenance of responses in occluded areas and high-level nodes integrate
global features to infer occluded or invisible parts. GM enables high semantic
nodes to guide the feature update of low semantic nodes that have undergone
cross attention. It ensuring effective fusion of diverse information. PGVL
includes top-down decomposition and bottom-up composition. In the first stage,
modality specific parse graphs are constructed. Next stage. recursive
bidirectional cross-attention is used, purified by GM. We also design network
based on PGVL. The PGVL and our network is validated on major pose estimation
datasets. We will release the code soon.

</details>


### [28] [DreamLifting: A Plug-in Module Lifting MV Diffusion Models for 3D Asset Generation](https://arxiv.org/abs/2509.07435)
*Ze-Xin Yin,Jiaxiong Qiu,Liu Liu,Xinjie Wang,Wei Sui,Zhizhong Su,Jian Yang,Jin Xie*

Main category: cs.CV

TL;DR: LGAA是一个创新的框架，能够端到端地生成具有PBR材质的3D资产，它整合了几何建模和材质合成，并利用了多视角扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法在纹理合成方面存在不足，无法实现端到端的PBR材质3D资产生成。

Method: LGAA框架包含三个组件：LGAA Wrapper（适配多视角扩散模型）、LGAA Switcher（整合不同知识的扩散先验）和LGAA Decoder（预测具有PBR通道的2D高斯泼溅）。最后通过后处理提取高质量网格资产。

Result: LGAA在文本和图像条件的多视角扩散模型上都取得了优越的性能，能够生成高质量、可重光的网格资产。

Conclusion: LGAA通过模块化设计和知识保留机制，实现了高效的3D资产生成，并且能够灵活整合多种扩散先验。

Abstract: The labor- and experience-intensive creation of 3D assets with physically
based rendering (PBR) materials demands an autonomous 3D asset creation
pipeline. However, most existing 3D generation methods focus on geometry
modeling, either baking textures into simple vertex colors or leaving texture
synthesis to post-processing with image diffusion models. To achieve end-to-end
PBR-ready 3D asset generation, we present Lightweight Gaussian Asset Adapter
(LGAA), a novel framework that unifies the modeling of geometry and PBR
materials by exploiting multi-view (MV) diffusion priors from a novel
perspective. The LGAA features a modular design with three components.
Specifically, the LGAA Wrapper reuses and adapts network layers from MV
diffusion models, which encapsulate knowledge acquired from billions of images,
enabling better convergence in a data-efficient manner. To incorporate multiple
diffusion priors for geometry and PBR synthesis, the LGAA Switcher aligns
multiple LGAA Wrapper layers encapsulating different knowledge. Then, a tamed
variational autoencoder (VAE), termed LGAA Decoder, is designed to predict 2D
Gaussian Splatting (2DGS) with PBR channels. Finally, we introduce a dedicated
post-processing procedure to effectively extract high-quality, relightable mesh
assets from the resulting 2DGS. Extensive quantitative and qualitative
experiments demonstrate the superior performance of LGAA with both text-and
image-conditioned MV diffusion models. Additionally, the modular design enables
flexible incorporation of multiple diffusion priors, and the
knowledge-preserving scheme leads to efficient convergence trained on merely
69k multi-view instances. Our code, pre-trained weights, and the dataset used
will be publicly available via our project page:
https://zx-yin.github.io/dreamlifting/.

</details>


### [29] [In the Eye of MLLM: Benchmarking Egocentric Video Intent Understanding with Gaze-Guided Prompting](https://arxiv.org/abs/2509.07447)
*Taiying Peng,Jiacheng Hua,Miao Liu,Feng Lu*

Main category: cs.CV

TL;DR: 该研究提出了EgoGazeVQA基准，一个利用注视信息来增强多模态大语言模型（MLLMs）在理解以自我为中心的视频和回答相关问题能力的数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试忽略了注视信息在指示用户意图中的关键作用，而注视信息对于理解以自我为中心的视频至关重要，尤其是在利用MLLMs实现主动和个性化AI用户体验方面。

Method: 提出了EgoGazeVQA基准，包含由MLLMs生成并由人工标注员完善的基于注视的问答对。设计了注视引导的意图提示方法，该方法整合了空间、时间以及与意图相关线索。进行了与注视相关的微调实验，并分析了注视估计精度对提示效果的影响。

Result: 实验表明，现有的MLLMs在准确解读用户意图方面存在困难。而所提出的注视引导意图提示方法通过整合多维度线索，显著提高了模型性能。注视相关的微调以及注视估计精度的分析也提供了关于如何优化模型表现的见解。

Conclusion: 注视信息对于在以自我为中心的设置中实现更具个性化和有效性的AI助手具有重要价值。EgoGazeVQA基准和提出的方法为进一步研究和开发此类AI助手提供了基础。

Abstract: The emergence of advanced multimodal large language models (MLLMs) has
significantly enhanced AI assistants' ability to process complex information
across modalities. Recently, egocentric videos, by directly capturing user
focus, actions, and context in an unified coordinate, offer an exciting
opportunity to enable proactive and personalized AI user experiences with
MLLMs. However, existing benchmarks overlook the crucial role of gaze as an
indicator of user intent. To address this gap, we introduce EgoGazeVQA, an
egocentric gaze-guided video question answering benchmark that leverages gaze
information to improve the understanding of longer daily-life videos.
EgoGazeVQA consists of gaze-based QA pairs generated by MLLMs and refined by
human annotators. Our experiments reveal that existing MLLMs struggle to
accurately interpret user intentions. In contrast, our gaze-guided intent
prompting methods significantly enhance performance by integrating spatial,
temporal, and intent-related cues. We further conduct experiments on
gaze-related fine-tuning and analyze how gaze estimation accuracy impacts
prompting effectiveness. These results underscore the value of gaze for more
personalized and effective AI assistants in egocentric settings.

</details>


### [30] [GLEAM: Learning to Match and Explain in Cross-View Geo-Localization](https://arxiv.org/abs/2509.07450)
*Xudong Lu,Zhi Zheng,Yi Wan,Yongxiang Yao,Annan Wang,Renrui Zhang,Panwang Xia,Qiong Wu,Qingyun Li,Weifeng Lin,Xiangyu Zhao,Xue Yang,Hongsheng Li*

Main category: cs.CV

TL;DR: GLEAM-C通过统一多视图和多模态数据（包括无人机图像、街道地图、全景图和地面照片）并仅与卫星图像对齐，来解决现有跨视图地理定位（CVGL）方法在单一视图或模态上的限制及其缺乏可解释性的问题。GLEAM-X任务结合了跨视图对应预测和可解释推理，利用多模态大语言模型（MLLMs）的能力，并构建了一个双语基准。该模型在提高训练效率的同时，实现了与现有模型相当的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的CVGL方法主要局限于单一视图或模态，并且其直接的视觉匹配策略缺乏可解释性，无法解释匹配背后的原因。

Method: 提出GLEAM-C模型，统一多视图和多模态数据（包括无人机图像、街道地图、全景图和地面照片），仅通过与卫星图像对齐来进行处理。采用两阶段训练策略，并进行了优化实现，以提高训练效率。提出GLEAM-X任务，利用多模态大语言模型（MLLMs）进行可解释的跨视图推理，并构建了包含GPT-4o和Doubao-1.5-Thinking-Vision-Pro生成的数据的双语基准，其中测试集经过人工修订以进行系统评估。

Result: GLEAM-C实现了与现有特定模态的CVGL模型相当的准确性，并提高了训练效率。GLEAM-X通过结合推理能力，为CVGL任务带来了可解释性，并创建了一个用于评估可解释跨视图推理的双语基准。

Conclusion: GLEAM-C和GLEAM-X共同构成了一个全面的CVGL流程，整合了多模态、多视图对齐与可解释的对应分析，将准确的跨视图匹配与可解释的推理相结合，通过使模型能够更好地解释和匹配（Explain And Match）来推进地理定位技术。

Abstract: Cross-View Geo-Localization (CVGL) focuses on identifying correspondences
between images captured from distinct perspectives of the same geographical
location. However, existing CVGL approaches are typically restricted to a
single view or modality, and their direct visual matching strategy lacks
interpretability: they merely predict whether two images correspond, without
explaining the rationale behind the match. In this paper, we present GLEAM-C, a
foundational CVGL model that unifies multiple views and modalities-including
UAV imagery, street maps, panoramic views, and ground photographs-by aligning
them exclusively with satellite imagery. Our framework enhances training
efficiency through optimized implementation while achieving accuracy comparable
to prior modality-specific CVGL models through a two-phase training strategy.
Moreover, to address the lack of interpretability in traditional CVGL methods,
we leverage the reasoning capabilities of multimodal large language models
(MLLMs) to propose a new task, GLEAM-X, which combines cross-view
correspondence prediction with explainable reasoning. To support this task, we
construct a bilingual benchmark using GPT-4o and Doubao-1.5-Thinking-Vision-Pro
to generate training and testing data. The test set is further refined through
detailed human revision, enabling systematic evaluation of explainable
cross-view reasoning and advancing transparency and scalability in
geo-localization. Together, GLEAM-C and GLEAM-X form a comprehensive CVGL
pipeline that integrates multi-modal, multi-view alignment with interpretable
correspondence analysis, unifying accurate cross-view matching with explainable
reasoning and advancing Geo-Localization by enabling models to better Explain
And Match. Code and datasets used in this work will be made publicly accessible
at https://github.com/Lucky-Lance/GLEAM.

</details>


### [31] [XOCT: Enhancing OCT to OCTA Translation via Cross-Dimensional Supervised Multi-Scale Feature Learning](https://arxiv.org/abs/2509.07455)
*Pooya Khosravi,Kun Han,Anthony T. Wu,Arghavan Rezvani,Zexin Feng,Xiaohui Xie*

Main category: cs.CV

TL;DR: XOCT是一个新的深度学习框架，通过结合跨维度监督（CDS）和多尺度特征融合（MSFF）网络，实现了视网膜层感知的血管重建，解决了传统OCTA图像获取和深度学习翻译的局限性，能够生成更高质量的OCTA图像，提高眼科疾病诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的OCTA图像获取受运动敏感性和软件成本限制，深度学习方法在处理不同视网膜层血管差异和重建精细血管细节方面存在不足，影响了诊断的准确性和可靠性。

Method: 提出XOCT框架，包含两个关键模块：1. 跨维度监督（CDS）：利用2D层感知切片生成方式，提供逐层监督信号，使网络学习不同视网膜层的独立表征。2. 多尺度特征融合（MSFF）：通过多尺度特征提取和通道重加权策略，增强血管的描绘能力，捕捉多尺度血管细节。

Result: 在OCTA-500数据集上的实验表明，XOCT在图像重建方面表现出色，特别是在临床评估中至关重要的面 proyekcije（en-face projections）方面，显著提高了血管细节的重建质量。

Conclusion: XOCT通过其创新的CDS和MSFF模块，能够生成高质量、层感知的OCTA图像，克服了现有方法的局限性，有望提高OCTA的易用性、可靠性和诊断价值，为眼科疾病的检测和监测提供更好的工具。

Abstract: Optical Coherence Tomography Angiography (OCTA) and its derived en-face
projections provide high-resolution visualization of the retinal and choroidal
vasculature, which is critical for the rapid and accurate diagnosis of retinal
diseases. However, acquiring high-quality OCTA images is challenging due to
motion sensitivity and the high costs associated with software modifications
for conventional OCT devices. Moreover, current deep learning methods for
OCT-to-OCTA translation often overlook the vascular differences across retinal
layers and struggle to reconstruct the intricate, dense vascular details
necessary for reliable diagnosis. To overcome these limitations, we propose
XOCT, a novel deep learning framework that integrates Cross-Dimensional
Supervision (CDS) with a Multi-Scale Feature Fusion (MSFF) network for
layer-aware vascular reconstruction. Our CDS module leverages 2D layer-wise
en-face projections, generated via segmentation-weighted z-axis averaging, as
supervisory signals to compel the network to learn distinct representations for
each retinal layer through fine-grained, targeted guidance. Meanwhile, the MSFF
module enhances vessel delineation through multi-scale feature extraction
combined with a channel reweighting strategy, effectively capturing vascular
details at multiple spatial scales. Our experiments on the OCTA-500 dataset
demonstrate XOCT's improvements, especially for the en-face projections which
are significant for clinical evaluation of retinal pathologies, underscoring
its potential to enhance OCTA accessibility, reliability, and diagnostic value
for ophthalmic disease detection and monitoring. The code is available at
https://github.com/uci-cbcl/XOCT.

</details>


### [32] [Bias-Aware Machine Unlearning: Towards Fairer Vision Models via Controllable Forgetting](https://arxiv.org/abs/2509.07456)
*Sai Siddhartha Chary Aylapuram,Veeraraju Elluru,Shivang Agarwal*

Main category: cs.CV

TL;DR: 提出一种名为“偏见感知机器学习遗忘”的新范式，通过选择性地移除有偏见的样本或特征表示来减轻视觉模型中的各种偏见，并使用梯度上升、LoRA 和师生蒸馏等技术进行评估。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络常依赖训练数据中的虚假相关性，导致在医学和自动驾驶等安全关键领域的预测存在偏见或不公平。传统的偏见缓解方法通常需要从头开始重新训练或重新设计数据管道。

Method: 在 CUB-200-2011（姿势偏见）、CIFAR-10（合成斑块偏见）和 CelebA（微笑检测中的性别偏见）三个基准数据集上，采用梯度上升、LoRA 和师生蒸馏等技术，通过经验分析评估各种策略。

Result: 在 CUB-200 上，CIFAR-10 和 CelebA 数据集上，后验遗忘可将亚群差异在很大程度上减少，在 CUB-200 上的人口统计平价提高高达 94.86%，在 CIFAR-10 上提高 30.28%，在 CelebA 上提高 97.37%，且准确性损失最小。

Conclusion: 机器学习遗忘可以作为一种实用的框架，在不重新训练的情况下提高已部署的视觉系统的公平性。

Abstract: Deep neural networks often rely on spurious correlations in training data,
leading to biased or unfair predictions in safety-critical domains such as
medicine and autonomous driving. While conventional bias mitigation typically
requires retraining from scratch or redesigning data pipelines, recent advances
in machine unlearning provide a promising alternative for post-hoc model
correction. In this work, we investigate \textit{Bias-Aware Machine
Unlearning}, a paradigm that selectively removes biased samples or feature
representations to mitigate diverse forms of bias in vision models. Building on
privacy-preserving unlearning techniques, we evaluate various strategies
including Gradient Ascent, LoRA, and Teacher-Student distillation. Through
empirical analysis on three benchmark datasets, CUB-200-2011 (pose bias),
CIFAR-10 (synthetic patch bias), and CelebA (gender bias in smile detection),
we demonstrate that post-hoc unlearning can substantially reduce subgroup
disparities, with improvements in demographic parity of up to \textbf{94.86\%}
on CUB-200, \textbf{30.28\%} on CIFAR-10, and \textbf{97.37\%} on CelebA. These
gains are achieved with minimal accuracy loss and with methods scoring an
average of 0.62 across the 3 settings on the joint evaluation of utility,
fairness, quality, and privacy. Our findings establish machine unlearning as a
practical framework for enhancing fairness in deployed vision systems without
necessitating full retraining.

</details>


### [33] [ANYPORTAL: Zero-Shot Consistent Video Background Replacement](https://arxiv.org/abs/2509.07472)
*Wenshuo Gao,Xicheng Lan,Shuai Yang*

Main category: cs.CV

TL;DR: ANYPORTAL是一个创新的零样本视频背景替换框架，利用预训练的扩散模型，解决了现有方法在细节控制和前景一致性方面的不足，实现了高质量、时间连贯的视频背景替换。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成技术在满足用户意图和细节控制方面存在挑战，限制了其实际应用。

Method: ANYPORTAL框架整合了视频扩散模型的时序先验和图像扩散模型的重光照能力，并提出了一种用于像素级细节操作的精炼投影算法，以确保前景的一致性。

Result: 实验结果表明，ANYPORTAL在消费级GPU上实现了高质量的视频背景替换效果，具有实际应用价值。

Conclusion: ANYPORTAL是一个无需训练的框架，能够解决前景一致性和时间连贯性重光照的挑战，为视频内容创作和编辑提供了实用高效的解决方案。

Abstract: Despite the rapid advancements in video generation technology, creating
high-quality videos that precisely align with user intentions remains a
significant challenge. Existing methods often fail to achieve fine-grained
control over video details, limiting their practical applicability. We
introduce ANYPORTAL, a novel zero-shot framework for video background
replacement that leverages pre-trained diffusion models. Our framework
collaboratively integrates the temporal prior of video diffusion models with
the relighting capabilities of image diffusion models in a zero-shot setting.
To address the critical challenge of foreground consistency, we propose a
Refinement Projection Algorithm, which enables pixel-level detail manipulation
to ensure precise foreground preservation. ANYPORTAL is training-free and
overcomes the challenges of achieving foreground consistency and temporally
coherent relighting. Experimental results demonstrate that ANYPORTAL achieves
high-quality results on consumer-grade GPUs, offering a practical and efficient
solution for video content creation and editing.

</details>


### [34] [MedicalPatchNet: A Patch-Based Self-Explainable AI Architecture for Chest X-ray Classification](https://arxiv.org/abs/2509.07477)
*Patrick Wienholt,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn*

Main category: cs.CV

TL;DR: MedicalPatchNet是一个用于胸部X光片分类的可解释的深度学习模型，它将图像分割成块进行独立分类，然后聚合预测结果，从而实现决策的可视化。该模型在CheXpert数据集上表现出与EfficientNet-B0相当的分类性能，并在CheXlocalize数据集上显著提高了病理定位的准确性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在医学影像分类中表现出色，但可解释性差，限制了其在临床上的应用。因此，需要开发一种具有内在可解释性的模型，能够清晰地将诊断决策归因于图像的不同区域，以增强临床信任度。

Method: MedicalPatchNet将输入的胸部X光片分割成若干个非重叠的图像块（patches），然后对每个图像块独立进行分类。最后，通过聚合所有图像块的分类结果来得到整张图像的最终诊断。这种分块处理和独立分类的方式使得模型能够直观地展示每个图像块对诊断的贡献度，而无需事后解释技术。

Result: 在CheXpert数据集（包含223,414张图像）上训练的MedicalPatchNet，其分类性能（AUROC 0.907）与EfficientNet-B0（AUROC 0.908）相当。在CheXlocalize数据集上，MedicalPatchNet在病理定位方面的准确性（平均命中率0.485）显著优于Grad-CAM（平均命中率0.376），展现了其优越的可解释性。

Conclusion: MedicalPatchNet模型在胸部X光片分类任务中取得了与现有先进模型相媲美的性能，同时通过其内在的可解释性设计，能够提供清晰、可靠的诊断依据，从而提高临床医生对AI辅助诊断的信任度，减少“捷径学习”带来的风险。该模型及其代码的公开有助于推动可解释AI在医学影像领域的应用。

Abstract: Deep neural networks excel in radiological image classification but
frequently suffer from poor interpretability, limiting clinical acceptance. We
present MedicalPatchNet, an inherently self-explainable architecture for chest
X-ray classification that transparently attributes decisions to distinct image
regions. MedicalPatchNet splits images into non-overlapping patches,
independently classifies each patch, and aggregates predictions, enabling
intuitive visualization of each patch's diagnostic contribution without
post-hoc techniques. Trained on the CheXpert dataset (223,414 images),
MedicalPatchNet matches the classification performance (AUROC 0.907 vs. 0.908)
of EfficientNet-B0, while substantially improving interpretability:
MedicalPatchNet demonstrates substantially improved interpretability with
higher pathology localization accuracy (mean hit-rate 0.485 vs. 0.376 with
Grad-CAM) on the CheXlocalize dataset. By providing explicit, reliable
explanations accessible even to non-AI experts, MedicalPatchNet mitigates risks
associated with shortcut learning, thus improving clinical trust. Our model is
publicly available with reproducible training and inference scripts and
contributes to safer, explainable AI-assisted diagnostics across medical
imaging domains. We make the code publicly available:
https://github.com/TruhnLab/MedicalPatchNet

</details>


### [35] [LINR Bridge: Vector Graphic Animation via Neural Implicits and Video Diffusion Priors](https://arxiv.org/abs/2509.07484)
*Wenshuo Gao,Xicheng Lan,Luyao Zhang,Shuai Yang*

Main category: cs.CV

TL;DR: 通过结合隐式神经表征和文本到视频扩散模型，实现矢量图动画的自动化。


<details>
  <summary>Details</summary>
Motivation: 矢量图动画化能够提升可理解性和可控性，但手动制作成本高，因此需要自动化方法。

Method: 使用分层隐式神经表征来重建矢量图，并利用预训练文本到视频扩散模型的运动先验，通过视频评分蒸馏采样进行优化，最后通过扭曲矢量图实现动画。

Result: 生成了生动自然的矢量图动画，并在灵活性和动画质量方面显著优于现有技术。

Conclusion: 所提出的方法能够有效生成高质量的矢量图动画。

Abstract: Vector graphics, known for their scalability and user-friendliness, provide a
unique approach to visual content compared to traditional pixel-based images.
Animation of these graphics, driven by the motion of their elements, offers
enhanced comprehensibility and controllability but often requires substantial
manual effort. To automate this process, we propose a novel method that
integrates implicit neural representations with text-to-video diffusion models
for vector graphic animation. Our approach employs layered implicit neural
representations to reconstruct vector graphics, preserving their inherent
properties such as infinite resolution and precise color and shape constraints,
which effectively bridges the large domain gap between vector graphics and
diffusion models. The neural representations are then optimized using video
score distillation sampling, which leverages motion priors from pretrained
text-to-video diffusion models. Finally, the vector graphics are warped to
match the representations resulting in smooth animation. Experimental results
validate the effectiveness of our method in generating vivid and natural vector
graphic animations, demonstrating significant improvement over existing
techniques that suffer from limitations in flexibility and animation quality.

</details>


### [36] [Estimating forest carbon stocks from high-resolution remote sensing imagery by reducing domain shift with style transfer](https://arxiv.org/abs/2502.00784)
*Zhenyu Yu,Jinnian Wang*

Main category: cs.CV

TL;DR: 利用Swin Transformer模型和卫星遥感影像，提高了森林碳储量估算的准确性。


<details>
  <summary>Details</summary>
Motivation: 森林是重要的陆地碳库，其碳汇作用能有效降低大气CO2浓度、减缓气候变化。目前，森林碳储量监测和评估的总体趋势是整合地面监测样本数据和卫星遥感影像，以实现大规模观测，但现有技术需要提高精度。

Method: 使用GF-1 WFV和Landsat TM影像，结合Swin Transformer和风格迁移方法，将碳储量估算转化为图像翻译任务，以提取全局特征。

Result: 通过集成地面监测样本数据和卫星遥感影像，利用Swin Transformer提取全局特征，提高了森林碳储量估算的准确性。

Conclusion: Swin Transformer和风格迁移方法能够有效应用于森林碳储量估算，提高估算精度。

Abstract: Forests function as crucial carbon reservoirs on land, and their carbon sinks
can efficiently reduce atmospheric CO2 concentrations and mitigate climate
change. Currently, the overall trend for monitoring and assessing forest carbon
stocks is to integrate ground monitoring sample data with satellite remote
sensing imagery. This style of analysis facilitates large-scale observation.
However, these techniques require improvement in accuracy. We used GF-1 WFV and
Landsat TM images to analyze Huize County, Qujing City, Yunnan Province in
China. Using the style transfer method, we introduced Swin Transformer to
extract global features through attention mechanisms, converting the carbon
stock estimation into an image translation.

</details>


### [37] [Fine-Tuning Vision-Language Models for Visual Navigation Assistance](https://arxiv.org/abs/2509.07488)
*Xiao Li,Bharat Gandhi,Ming Zhan,Mohit Nehra,Zhicheng Zhang,Yuchen Sun,Meijia Song,Naisheng Zhang,Xi Wang*

Main category: cs.CV

TL;DR: 我们提出了一种结合视觉和语言模型的方法，用于视觉障碍者的室内导航，通过微调BLIP-2模型并使用新的评估指标来提高导航指令的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统室内导航系统由于缺乏精确的定位数据而效果不佳，因此需要一种能够结合图像和自然语言来辅助视觉障碍者进行室内导航的方法。

Method: 我们使用低秩适应（LoRA）技术对BLIP-2模型进行了微调，并使用了一个手动标注的室内导航数据集。我们还提出了一个新的评估指标，该指标通过强调方向和顺序变量来改进BERT F1分数。

Result: 微调后的模型在生成方向性指令方面有显著提高，克服了原始BLIP-2模型的局限性。

Conclusion: 我们提出的方法通过结合视觉和语言模型，并采用LoRA微调和改进的评估指标，能够为视觉障碍者提供更准确、更可靠的室内导航辅助，从而提高他们的独立性和可及性。

Abstract: We address vision-language-driven indoor navigation to assist visually
impaired individuals in reaching a target location using images and natural
language guidance. Traditional navigation systems are ineffective indoors due
to the lack of precise location data. Our approach integrates vision and
language models to generate step-by-step navigational instructions, enhancing
accessibility and independence. We fine-tune the BLIP-2 model with Low Rank
Adaptation (LoRA) on a manually annotated indoor navigation dataset. We propose
an evaluation metric that refines the BERT F1 score by emphasizing directional
and sequential variables, providing a more comprehensive measure of
navigational performance. After applying LoRA, the model significantly improved
in generating directional instructions, overcoming limitations in the original
BLIP-2 model.

</details>


### [38] [DiGS: Accurate and Complete Surface Reconstruction from 3D Gaussians via Direct SDF Learning](https://arxiv.org/abs/2509.07493)
*Wenzhi Guo,Bing Wang*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a powerful paradigm for
photorealistic view synthesis, representing scenes with spatially distributed
Gaussian primitives. While highly effective for rendering, achieving accurate
and complete surface reconstruction remains challenging due to the unstructured
nature of the representation and the absence of explicit geometric supervision.
In this work, we propose DiGS, a unified framework that embeds Signed Distance
Field (SDF) learning directly into the 3DGS pipeline, thereby enforcing strong
and interpretable surface priors. By associating each Gaussian with a learnable
SDF value, DiGS explicitly aligns primitives with underlying geometry and
improves cross-view consistency. To further ensure dense and coherent coverage,
we design a geometry-guided grid growth strategy that adaptively distributes
Gaussians along geometry-consistent regions under a multi-scale hierarchy.
Extensive experiments on standard benchmarks, including DTU, Mip-NeRF 360, and
Tanks& Temples, demonstrate that DiGS consistently improves reconstruction
accuracy and completeness while retaining high rendering fidelity.

</details>


### [39] [Generating Transferrable Adversarial Examples via Local Mixing and Logits Optimization for Remote Sensing Object Recognition](https://arxiv.org/abs/2509.07495)
*Chun Liu,Hailong Wang,Bingqian Zhu,Panpan Ding,Zheng Zheng,Tao Xu,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 提出一种新的局部混合和Logits优化框架，用于增强针对遥感应用的深度神经网络的对抗攻击的可迁移性，解决了现有全局混合策略破坏语义信息和交叉熵损失导致梯度消失的问题。


<details>
  <summary>Details</summary>
Motivation: 现有混合策略（如MixUp和MixCut）在生成对抗样本时存在破坏全局语义特征和优化过程中的梯度消失问题，限制了对抗攻击的效果和可迁移性。

Method: 提出一种新的框架，包括：1. 局部混合策略：仅混合图像的局部区域，以保留全局语义信息，生成多样化且语义一致的输入。2. Logits优化：将原本用于定向攻击的Logit损失适应于非定向攻击，以解决交叉熵损失导致的梯度消失问题。3. 扰动平滑损失：用于抑制高频噪声，提高对抗样本的可迁移性。

Result: 在FGSCR-42和MTARSI数据集上进行了广泛实验，与12种现有方法相比，在6种代理模型上均取得了优越性能。特别地，在使用ResNet作为MTARSI数据集上的代理模型时，黑盒攻击成功率平均提高了17.28%。

Conclusion: 所提出的局部混合和Logits优化框架能够有效生成高质量、高可迁移性的对抗样本，显著优于现有方法，为提高遥感应用中DNN的鲁棒性提供了新的途径。

Abstract: Deep Neural Networks (DNNs) are vulnerable to adversarial attacks, posing
significant security threats to their deployment in remote sensing
applications. Research on adversarial attacks not only reveals model
vulnerabilities but also provides critical insights for enhancing robustness.
Although current mixing-based strategies have been proposed to increase the
transferability of adversarial examples, they either perform global blending or
directly exchange a region in the images, which may destroy global semantic
features and mislead the optimization of adversarial examples. Furthermore,
their reliance on cross-entropy loss for perturbation optimization leads to
gradient diminishing during iterative updates, compromising adversarial example
quality. To address these limitations, we focus on non-targeted attacks and
propose a novel framework via local mixing and logits optimization. First, we
present a local mixing strategy to generate diverse yet semantically consistent
inputs. Different from MixUp, which globally blends two images, and MixCut,
which stitches images together, our method merely blends local regions to
preserve global semantic information. Second, we adapt the logit loss from
targeted attacks to non-targeted scenarios, mitigating the gradient vanishing
problem of cross-entropy loss. Third, a perturbation smoothing loss is applied
to suppress high-frequency noise and enhance transferability. Extensive
experiments on FGSCR-42 and MTARSI datasets demonstrate superior performance
over 12 state-of-the-art methods across 6 surrogate models. Notably, with
ResNet as the surrogate on MTARSI, our method achieves a 17.28% average
improvement in black-box attack success rate.

</details>


### [40] [MVAT: Multi-View Aware Teacher for Weakly Supervised 3D Object Detection](https://arxiv.org/abs/2509.07507)
*Saad Lahlali,Alexandre Fournier Montgieux,Nicolas Granger,Hervé Le Borgne,Quoc Cuong Pham*

Main category: cs.CV

TL;DR: 该研究提出了一种名为MVAT的框架，利用多视角和时间信息来解决弱监督3D目标检测中的投影歧义和物体可见性问题。通过教师-学生学习范式，MVAT能够从2D边界框生成高质量的伪标签，并最终在nuScenes和Waymo Open数据集上达到最先进的弱监督3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 3D数据标注成本高昂，现有的仅依赖2D边界框的弱监督方法存在投影歧义和物体部分可见性问题，难以准确估计3D边界框。

Method: MVAT框架聚合了时序多视角数据中的目标点云，构建尽可能密集和完整的3D物体表示。采用教师-学生学习范式：教师网络从单视角学习，但目标来自时间聚合的静态物体；然后教师生成高质量伪标签供学生网络从单视角学习。框架还包含多视角2D投影损失，以保证预测的3D边界框与所有可用的2D标注一致。

Result: 在nuScenes和Waymo Open数据集上，MVAT实现了最先进的弱监督3D目标检测性能，显著缩小了与全监督方法之间的差距，且无需任何3D边界框标注。

Conclusion: MVAT通过有效利用时序多视角信息，成功解决了弱监督3D目标检测中的关键挑战，并在公开数据集上取得了优异的性能。

Abstract: Annotating 3D data remains a costly bottleneck for 3D object detection,
motivating the development of weakly supervised annotation methods that rely on
more accessible 2D box annotations. However, relying solely on 2D boxes
introduces projection ambiguities since a single 2D box can correspond to
multiple valid 3D poses. Furthermore, partial object visibility under a single
viewpoint setting makes accurate 3D box estimation difficult. We propose MVAT,
a novel framework that leverages temporal multi-view present in sequential data
to address these challenges. Our approach aggregates object-centric point
clouds across time to build 3D object representations as dense and complete as
possible. A Teacher-Student distillation paradigm is employed: The Teacher
network learns from single viewpoints but targets are derived from temporally
aggregated static objects. Then the Teacher generates high quality
pseudo-labels that the Student learns to predict from a single viewpoint for
both static and moving objects. The whole framework incorporates a multi-view
2D projection loss to enforce consistency between predicted 3D boxes and all
available 2D annotations. Experiments on the nuScenes and Waymo Open datasets
demonstrate that MVAT achieves state-of-the-art performance for weakly
supervised 3D object detection, significantly narrowing the gap with fully
supervised methods without requiring any 3D box annotations. % \footnote{Code
available upon acceptance} Our code is available in our public repository
(\href{https://github.com/CEA-LIST/MVAT}{code}).

</details>


### [41] [EHWGesture -- A dataset for multimodal understanding of clinical gestures](https://arxiv.org/abs/2509.07525)
*Gianluca Amprimo,Alberto Ancilotto,Alessandro Savino,Fabio Quazzolo,Claudia Ferraris,Gabriella Olmo,Elisabetta Farella,Stefano Di Carlo*

Main category: cs.CV

TL;DR: EHWGesture是一个包含超过1100个手势视频的新型多模态数据集，旨在解决动态手势理解中的挑战，并特别关注临床评估。


<details>
  <summary>Details</summary>
Motivation: 现有的研究在理解动态手势方面存在挑战，尤其是在多模态、多视角、精确地面真值跟踪和动作质量评估方面的数据集不足。本研究旨在创建一个能够解决这些问题的数据集，以促进人机交互和临床手部灵巧性评估的研究。

Method: 创建了一个名为EHWGesture的新型多模态数据集，其中包含5种临床相关手势的1100多个视频记录（6小时）。数据由25名健康受试者使用RGB-D摄像头和事件摄像头采集，并利用动作捕捉系统提供精确的手部地标跟踪。所有设备都经过空间校准和同步。此外，视频根据执行速度进行分类，以模拟临床对手部灵巧性的评估。

Result: EHWGesture数据集包含超过1100个视频，由25名健康受试者使用RGB-D摄像头和事件摄像头采集，并配备了动作捕捉系统进行精确的手部跟踪。数据集包含5种临床相关手势，并按执行速度分类。初步实验证明了该数据集在手势分类、手势触发检测和动作质量评估方面的潜力。

Conclusion: EHWGesture数据集为多模态临床手势理解提供了一个全面的基准，有望推动该领域的研究和应用，特别是在评估手部灵巧性方面。

Abstract: Hand gesture understanding is essential for several applications in
human-computer interaction, including automatic clinical assessment of hand
dexterity. While deep learning has advanced static gesture recognition, dynamic
gesture understanding remains challenging due to complex spatiotemporal
variations. Moreover, existing datasets often lack multimodal and multi-view
diversity, precise ground-truth tracking, and an action quality component
embedded within gestures. This paper introduces EHWGesture, a multimodal video
dataset for gesture understanding featuring five clinically relevant gestures.
It includes over 1,100 recordings (6 hours), captured from 25 healthy subjects
using two high-resolution RGB-Depth cameras and an event camera. A motion
capture system provides precise ground-truth hand landmark tracking, and all
devices are spatially calibrated and synchronized to ensure cross-modal
alignment. Moreover, to embed an action quality task within gesture
understanding, collected recordings are organized in classes of execution speed
that mirror clinical evaluations of hand dexterity. Baseline experiments
highlight the dataset's potential for gesture classification, gesture trigger
detection, and action quality assessment. Thus, EHWGesture can serve as a
comprehensive benchmark for advancing multimodal clinical gesture
understanding.

</details>


### [42] [Universal Few-Shot Spatial Control for Diffusion Models](https://arxiv.org/abs/2509.07530)
*Kiet T. Nguyen,Chanhuyk Lee,Donggyun Kim,Dong Hoon Lee,Seunghoon Hong*

Main category: cs.CV

TL;DR: UFC是一个少样本学习的控制适配器，可以泛化到新的空间控制任务，只需少量数据即可达到与全监督基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的空间控制适配器在面对与训练任务差异很大的新空间控制条件时，适应性有限且训练成本高。

Method: UFC利用查询和支持条件之间的类比，通过匹配机制和对少量特定任务参数的更新来构建特定任务的控制特征。

Result: UFC在六个新的空间控制任务上进行了实验，在仅使用30个标注示例进行微调的情况下，实现了与空间条件一致的精细控制，并且在仅使用0.1%的训练数据进行微调时，性能与全监督基线相当。此外，UFC可应用于UNet和DiT等不同的扩散模型架构。

Conclusion: UFC是一种通用的少样本控制适配器，能够有效地泛化到新的空间控制任务，并且在不同扩散模型架构上都表现出色。

Abstract: Spatial conditioning in pretrained text-to-image diffusion models has
significantly improved fine-grained control over the structure of generated
images. However, existing control adapters exhibit limited adaptability and
incur high training costs when encountering novel spatial control conditions
that differ substantially from the training tasks. To address this limitation,
we propose Universal Few-Shot Control (UFC), a versatile few-shot control
adapter capable of generalizing to novel spatial conditions. Given a few
image-condition pairs of an unseen task and a query condition, UFC leverages
the analogy between query and support conditions to construct task-specific
control features, instantiated by a matching mechanism and an update on a small
set of task-specific parameters. Experiments on six novel spatial control tasks
show that UFC, fine-tuned with only 30 annotated examples of novel tasks,
achieves fine-grained control consistent with the spatial conditions. Notably,
when fine-tuned with 0.1% of the full training data, UFC achieves competitive
performance with the fully supervised baselines in various control tasks. We
also show that UFC is applicable agnostically to various diffusion backbones
and demonstrate its effectiveness on both UNet and DiT architectures. Code is
available at https://github.com/kietngt00/UFC.

</details>


### [43] [HU-based Foreground Masking for 3D Medical Masked Image Modeling](https://arxiv.org/abs/2509.07534)
*Jin Lee,Vu Dang,Gwang-Hyun Yu,Anh Le,Zahid Rahman,Jin-Ho Jang,Heonzoo Lee,Kun-Yung Kim,Jin-Sul Kim,Jin-Young Kim*

Main category: cs.CV

TL;DR: 通过基于HU的掩码策略提升3D医学图像分割的MIM方法


<details>
  <summary>Details</summary>
Motivation: MIM在3D医学图像中的应用受限于随机掩码策略，该策略忽略了解剖结构密度。

Method: 提出了一种基于HU测量的前景掩码策略，聚焦于内脏器官的强度分布，排除缺乏诊断意义的区域。

Result: 在五个公共3D医学成像数据集上进行了广泛实验，证明了所提出的掩码策略在分割质量和Dice分数方面持续提高了性能。

Conclusion: 基于HU的前景掩码策略在3D医学图像分割中是一种有效的方法，表明了领域中心MIM方法在表示学习中的潜力。

Abstract: While Masked Image Modeling (MIM) has revolutionized fields of computer
vision, its adoption in 3D medical image computing has been limited by the use
of random masking, which overlooks the density of anatomical objects. To
address this limitation, we enhance the pretext task with a simple yet
effective masking strategy. Leveraging Hounsfield Unit (HU) measurements, we
implement an HU-based Foreground Masking, which focuses on the intensity
distribution of visceral organs and excludes non-tissue regions, such as air
and fluid, that lack diagnostically meaningful features. Extensive experiments
on five public 3D medical imaging datasets demonstrate that our masking
consistently improves performance, both in quality of segmentation and Dice
score (BTCV:~84.64\%, Flare22:~92.43\%, MM-WHS:~90.67\%, Amos22:~88.64\%,
BraTS:~78.55\%). These results underscore the importance of domain-centric MIM
and suggest a promising direction for representation learning in medical image
segmentation. Implementation is available at github.com/AISeedHub/SubFore/.

</details>


### [44] [TextlessRAG: End-to-End Visual Document RAG by Speech Without Text](https://arxiv.org/abs/2509.07538)
*Peijin Xie,Shun Qian,Bingquan Liu,Dexin Wang,Lin Sun,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: TextlessRAG是一个端到端的框架，用于在视觉文档图像上进行基于语音的问答，无需进行语音识别、文本转语音和光学字符识别。


<details>
  <summary>Details</summary>
Motivation: 现有的工作未能解决通过语音查询视觉文档图像进行知识库问答的问题，而这种方式具有更广泛的应用潜力。

Method: TextlessRAG提出了一种完全无文本的流水线，直接解释语音、检索相关的视觉知识并生成答案，并引入了按布局进行重新排序的机制来改进检索。

Result: 该方法在效率和准确性方面都取得了显著的改进。

Conclusion: TextlessRAG是第一个用于大规模文档图像语音问答的端到端框架，并且发布了第一个双语语音-文档RAG数据集，以促进该领域的研究。

Abstract: Document images encapsulate a wealth of knowledge, while the portability of
spoken queries enables broader and flexible application scenarios. Yet, no
prior work has explored knowledge base question answering over visual document
images with queries provided directly in speech. We propose TextlessRAG, the
first end-to-end framework for speech-based question answering over large-scale
document images. Unlike prior methods, TextlessRAG eliminates ASR, TTS and OCR,
directly interpreting speech, retrieving relevant visual knowledge, and
generating answers in a fully textless pipeline. To further boost performance,
we integrate a layout-aware reranking mechanism to refine retrieval.
Experiments demonstrate substantial improvements in both efficiency and
accuracy. To advance research in this direction, we also release the first
bilingual speech--document RAG dataset, featuring Chinese and English voice
queries paired with multimodal document content. Both the dataset and our
pipeline will be made available at
repository:https://github.com/xiepeijinhit-hue/textlessrag

</details>


### [45] [PanoLAM: Large Avatar Model for Gaussian Full-Head Synthesis from One-shot Unposed Image](https://arxiv.org/abs/2509.07552)
*Peng Li,Yisheng He,Yingdong Hu,Yuan Dong,Weihao Yuan,Yuan Liu,Zilong Dong,Yike Guo*

Main category: cs.CV

TL;DR: 我们的框架可以在一次前向传播中从单个未设姿势的图像重建高斯头部模型，无需耗时的 GAN 逆转和测试时间优化。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模 3D 头部资产，我们提出了一个由训练好的 3D GAN 生成的大规模合成数据集，并仅使用合成数据来训练我们的框架。

Method: 我们引入了一个由稀疏的 FLAME 模型点与 transformer 块中的图像特征交互进行特征提取和粗略形状重建，然后进行致密化以实现高保真重建的粗略到精细的高斯头部生成流程。为了充分利用预训练 3D GAN 中存在的先验知识以实现有效重建，我们提出了一个双分支框架，它有效地聚合了结构化球形三平面特征和非结构化点状特征，以实现更有效的全头部高斯重建。

Result: 实验结果证明了我们框架的有效性。

Conclusion: 该框架可以快速地从单个未设姿势的图像进行高保真全头部高斯模型重建。

Abstract: We present a feed-forward framework for Gaussian full-head synthesis from a
single unposed image. Unlike previous work that relies on time-consuming GAN
inversion and test-time optimization, our framework can reconstruct the
Gaussian full-head model given a single unposed image in a single forward pass.
This enables fast reconstruction and rendering during inference. To mitigate
the lack of large-scale 3D head assets, we propose a large-scale synthetic
dataset from trained 3D GANs and train our framework using only synthetic data.
For efficient high-fidelity generation, we introduce a coarse-to-fine Gaussian
head generation pipeline, where sparse points from the FLAME model interact
with the image features by transformer blocks for feature extraction and coarse
shape reconstruction, which are then densified for high-fidelity
reconstruction. To fully leverage the prior knowledge residing in pretrained 3D
GANs for effective reconstruction, we propose a dual-branch framework that
effectively aggregates the structured spherical triplane feature and
unstructured point-based features for more effective Gaussian head
reconstruction. Experimental results show the effectiveness of our framework
towards existing work.

</details>


### [46] [Attention Maps in 3D Shape Classification for Dental Stage Estimation with Class Node Graph Attention Networks](https://arxiv.org/abs/2509.07581)
*Barkin Buyukcakir,Rocharles Cavalcante Fontenele,Reinhilde Jacobs,Jannick De Tobel,Patrick Thevissen,Dirk Vandermeulen,Peter Claes*

Main category: cs.CV

TL;DR: CGAT是一种用于3D形状识别的图注意力网络，通过可视化注意力机制来提高模型的可解释性，从而增强在高风险应用中的信任度。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型，尤其是在医学和法医学等高风险领域，其黑箱性质阻碍了人们对它们的信任和应用。本研究旨在解决3D形状识别任务中深度学习模型的可解释性问题。

Method: 提出了一种名为Class Node Graph Attention Network (CGAT)的新型网络架构，它利用图注意力卷积和内在注意力机制来解释其决策过程。研究中还评估了局部平均曲率和到质心的距离作为节点特征，以及模型深度，并引入了指向全局CLS节点的有向边。

Result: 在对CBCT图像中第三磨牙3D网格进行的Demirjian分期分配任务中，CGAT通过注意力可视化展现了其决策过程。结合局部平均曲率和到质心的距离作为节点特征，以及引入有向边到全局CLS节点，可以产生更直观的注意力图，并获得0.76的加权F1分数，同时提供更全面的注意力可视化。

Conclusion: CGAT架构能够生成人类可理解的注意力图，增强了模型的信任度，并有助于专家验证模型的决策。该模型不仅适用于牙科数据，还可广泛应用于其他基于图的分类和回归任务，从而在高风险环境中推广透明且具有竞争力的深度学习模型。

Abstract: Deep learning offers a promising avenue for automating many recognition tasks
in fields such as medicine and forensics. However, the black-box nature of
these models hinders their adoption in high-stakes applications where trust and
accountability are required. For 3D shape recognition tasks in particular, this
paper introduces the Class Node Graph Attention Network (CGAT) architecture to
address this need. Applied to 3D meshes of third molars derived from CBCT
images, for Demirjian stage allocation, CGAT utilizes graph attention
convolutions and an inherent attention mechanism, visualized via attention
rollout, to explain its decision-making process. We evaluated the local mean
curvature and distance to centroid node features, both individually and in
combination, as well as model depth, finding that models incorporating directed
edges to a global CLS node produced more intuitive attention maps, while also
yielding desirable classification performance. We analyzed the attention-based
explanations of the models, and their predictive performances to propose
optimal settings for the CGAT. The combination of local mean curvature and
distance to centroid as node features yielded a slight performance increase
with 0.76 weighted F1 score, and more comprehensive attention visualizations.
The CGAT architecture's ability to generate human-understandable attention maps
can enhance trust and facilitate expert validation of model decisions. While
demonstrated on dental data, CGAT is broadly applicable to graph-based
classification and regression tasks, promoting wider adoption of transparent
and competitive deep learning models in high-stakes environments.

</details>


### [47] [Temporal Image Forensics: A Review and Critical Evaluation](https://arxiv.org/abs/2509.07591)
*Robert Jöchl,Andreas Uhl*

Main category: cs.CV

TL;DR: 该综述全面概述了基于相机成像管线中时间相关痕迹的时间图像取证领域，提出了新的法证设定，并强调了可解释人工智能在验证时间图像取证技术可靠性方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 为时间图像取证领域提供一个全面的概述，重点关注时间相关痕迹，并探讨内容偏差和可解释人工智能在验证技术可靠性方面的重要性。

Method: 对现有文献进行回顾，提出新的法证设定，验证现场传感器缺陷的特性，分析和重新实现现有方法，并进行实验来探究神经网络在进行图像年龄估算时学习的特征以及其易受干扰的特性。

Result: 验证了现场传感器缺陷（生长速率和空间分布）的主要特性，揭示了利用现场传感器缺陷进行图像年龄估算的方法实际上利用了其他痕迹（很可能是内容偏差），并进一步研究了用于对指纹图像进行日期估算的神经网络所学习到的特征，最后证明了神经网络很容易被从学习年龄痕迹中分散注意力。

Conclusion: 现有的时间图像取证技术可能存在内容偏差问题，并且需要可解释的人工智能方法来验证其可靠性。未来的研究应关注开发更鲁棒的技术，以克服内容偏差并确保准确的年龄估算。

Abstract: Temporal image forensics is the science of estimating the age of a digital
image. Usually, time-dependent traces (age traces) introduced by the image
acquisition pipeline are exploited for this purpose. In this review, a
comprehensive overview of the field of temporal image forensics based on
time-dependent traces from the image acquisition pipeline is given. This
includes a detailed insight into the properties of known age traces (i.e.,
in-field sensor defects and sensor dust) and temporal image forensics
techniques. Another key aspect of this work is to highlight the problem of
content bias and to illustrate how important eXplainable Artificial
Intelligence methods are to verify the reliability of temporal image forensics
techniques. Apart from reviewing material presented in previous works, in this
review: (i) a new (probably more realistic) forensic setting is proposed; (ii)
the main properties (growth rate and spatial distribution) of in-field sensor
defects are verified; (iii) it is shown that a method proposed to utilize
in-field sensor defects for image age approximation actually exploits other
traces (most likely content bias); (iv) the features learned by a neural
network dating palmprint images are further investigated; (v) it is shown how
easily a neural network can be distracted from learning age traces. For this
purpose, previous work is analyzed, re-implemented if required and experiments
are conducted.

</details>


### [48] [Bias in Gender Bias Benchmarks: How Spurious Features Distort Evaluation](https://arxiv.org/abs/2509.07596)
*Yusuke Hirota,Ryo Hachiuma,Boyi Li,Ximing Lu,Michael Ross Boone,Boris Ivanovic,Yejin Choi,Marco Pavone,Yu-Chiang Frank Wang,Noa Garcia,Yuta Nakashima,Chao-Han Huck Yang*

Main category: cs.CV

TL;DR: 现有性别偏见评估基准存在因果混淆问题，可能扭曲模型偏见评估结果。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型（VLMs）中的性别偏见时，通常使用带性别标注的真实世界图像基准。然而，这些基准常包含性别与非性别特征（如物体、背景）之间的混淆关系，这可能导致偏见评估失准。

Method: 通过系统性地扰动（如遮蔽物体、模糊背景）四个常用基准（COCO-gender, FACET, MIAP, PHASE）中的非性别特征，并使用多种VLMs进行评估，以量化这些扰动对性别偏见评估指标的影响。

Result: 即使是轻微的扰动（如10%的物体遮蔽或轻微的背景模糊）也能显著改变偏见评估分数，对生成式VLMs的指标影响高达175%，对CLIP变体的指标影响高达43%。

Conclusion: 当前对性别偏见的评估很大程度上反映了模型对混淆特征的反应，而非真实的性别偏见，这严重影响了评估的可靠性。鉴于创建无混淆特征的基准非常困难，建议在报告偏见指标的同时，增加特征敏感性测量，以实现更可靠的偏见评估。

Abstract: Gender bias in vision-language foundation models (VLMs) raises concerns about
their safe deployment and is typically evaluated using benchmarks with gender
annotations on real-world images. However, as these benchmarks often contain
spurious correlations between gender and non-gender features, such as objects
and backgrounds, we identify a critical oversight in gender bias evaluation: Do
spurious features distort gender bias evaluation? To address this question, we
systematically perturb non-gender features across four widely used benchmarks
(COCO-gender, FACET, MIAP, and PHASE) and various VLMs to quantify their impact
on bias evaluation. Our findings reveal that even minimal perturbations, such
as masking just 10% of objects or weakly blurring backgrounds, can dramatically
alter bias scores, shifting metrics by up to 175% in generative VLMs and 43% in
CLIP variants. This suggests that current bias evaluations often reflect model
responses to spurious features rather than gender bias, undermining their
reliability. Since creating spurious feature-free benchmarks is fundamentally
challenging, we recommend reporting bias metrics alongside feature-sensitivity
measurements to enable a more reliable bias assessment.

</details>


### [49] [Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease](https://arxiv.org/abs/2509.07613)
*Fangqi Cheng,Surajit Ray,Xiaochen Yang*

Main category: cs.CV

TL;DR: Med-VLMs在医疗影像分析中表现出色，但存在数据利用不足、临床知识整合欠缺、计算资源消耗大以及3D影像效果有限等问题。本研究提出了一种数据高效的微调流程，将3D CT模型适配于3D MRI，并应用于阿尔茨海默病（AD）诊断。通过将结构化元数据转化为合成报告和引入预测MMSE分数的辅助任务，增强了文本输入和模型监督。该方法仅使用1500张训练图像，在AD诊断任务上取得了最先进的性能，优于使用10000张图像的现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的医学视觉语言模型（Med-VLMs）在报告生成和视觉问答等任务上表现出色，但存在利用患者元数据不足、缺乏临床诊断知识整合、计算资源消耗大以及在3D医学影像上效果有限等局限性。

Method: 提出一种数据高效的微调流程，将3D CT模型适配于3D MRI，并应用于阿尔茨海默病（AD）诊断。引入两项创新：1. 将结构化元数据转化为合成报告，丰富文本输入以改善图像-文本对齐。2. 增加一个辅助任务，训练模型预测迷你精神状态检查（MMSE）分数，为微调提供额外监督。对图像和文本模态应用轻量级提示调优。

Result: 该方法在两个AD数据集上取得了最先进的性能，仅使用1500张训练图像，优于使用10000张图像进行微调的现有方法。

Conclusion: 本研究提出的数据高效微调流程，通过整合患者元数据和引入辅助预测任务，有效提升了Med-VLMs在3D医学影像分析中的性能，尤其在AD诊断方面取得了显著成果。

Abstract: Medical vision-language models (Med-VLMs) have shown impressive results in
tasks such as report generation and visual question answering, but they still
face several limitations. Most notably, they underutilize patient metadata and
lack integration of clinical diagnostic knowledge. Moreover, most existing
models are typically trained from scratch or fine-tuned on large-scale 2D
image-text pairs, requiring extensive computational resources, and their
effectiveness on 3D medical imaging is often limited due to the absence of
structural information. To address these gaps, we propose a data-efficient
fine-tuning pipeline to adapt 3D CT-based Med-VLMs for 3D MRI and demonstrate
its application in Alzheimer's disease (AD) diagnosis. Our system introduces
two key innovations. First, we convert structured metadata into synthetic
reports, enriching textual input for improved image-text alignment. Second, we
add an auxiliary token trained to predict the mini-mental state examination
(MMSE) score, a widely used clinical measure of cognitive function that
correlates with AD severity. This provides additional supervision for
fine-tuning. Applying lightweight prompt tuning to both image and text
modalities, our approach achieves state-of-the-art performance on two AD
datasets using 1,500 training images, outperforming existing methods fine-tuned
on 10,000 images. Code will be released upon publication.

</details>


### [50] [Self-Supervised Cross-Encoder for Neurodegenerative Disease Diagnosis](https://arxiv.org/abs/2509.07623)
*Fangqi Cheng,Yingying Zhao,Xiaochen Yang*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的自监督交叉编码器框架，利用纵向MRI扫描的时间连续性进行监督，以解决深度学习诊断神经退行性疾病时对大量标记数据和可解释性不足的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在从MRI数据诊断神经退行性疾病时，过度依赖大量标记数据且学习到的表征缺乏可解释性。

Method: 提出了一种新颖的自监督交叉编码器框架，利用纵向MRI扫描的时间连续性进行监督。该框架将学习到的表征分为两个部分：通过对比学习约束的静态表征，捕捉稳定的解剖特征；以及通过输入梯度正则化引导的动态表征，反映时间变化，可用于下游分类任务的微调。

Result: 在阿尔茨海默病神经影像学倡议（ADNI）数据集上的实验结果表明，该方法实现了优于现有方法的分类准确性和可解释性。此外，学到的表征在开放获取影像学研究系列（OASIS）数据集上表现出强大的零样本泛化能力，在帕金森病进展标记物计划（PPMI）数据集上表现出跨任务泛化能力。

Conclusion: 所提出的自监督交叉编码器框架能够有效利用纵向MRI扫描的时间连续性，生成具有高准确性、可解释性强以及良好泛化能力的表征，为神经退行性疾病的诊断提供了新的解决方案。

Abstract: Deep learning has shown significant potential in diagnosing neurodegenerative
diseases from MRI data. However, most existing methods rely heavily on large
volumes of labeled data and often yield representations that lack
interpretability. To address both challenges, we propose a novel
self-supervised cross-encoder framework that leverages the temporal continuity
in longitudinal MRI scans for supervision. This framework disentangles learned
representations into two components: a static representation, constrained by
contrastive learning, which captures stable anatomical features; and a dynamic
representation, guided by input-gradient regularization, which reflects
temporal changes and can be effectively fine-tuned for downstream
classification tasks. Experimental results on the Alzheimer's Disease
Neuroimaging Initiative (ADNI) dataset demonstrate that our method achieves
superior classification accuracy and improved interpretability. Furthermore,
the learned representations exhibit strong zero-shot generalization on the Open
Access Series of Imaging Studies (OASIS) dataset and cross-task generalization
on the Parkinson Progression Marker Initiative (PPMI) dataset. The code for the
proposed method will be made publicly available.

</details>


### [51] [Semantic Watermarking Reinvented: Enhancing Robustness and Generation Quality with Fourier Integrity](https://arxiv.org/abs/2509.07647)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: 提出了一种名为Hermitian Symmetric Fourier Watermarking (SFW) 的新型语义水印嵌入方法，通过强制执行厄米对称性来保持频率完整性，并结合中心感知嵌入策略以抵抗裁剪攻击，从而提高了LDMs的鲁棒性和检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LDMs语义水印技术在抵抗再生攻击方面表现良好，但在频率完整性丢失的情况下，检测性能会下降，并且容易受到裁剪攻击。

Method: 提出并应用了Hermitian Symmetric Fourier Watermarking (SFW) 方法，该方法通过强制执行厄米对称性来保持频率完整性，并引入了中心感知嵌入策略来减少裁剪攻击的漏洞。

Result: 通过将SFW应用于现有语义水印方案，并结合中心感知嵌入策略，在各种攻击场景下实现了最先进的验证和识别性能，在图像保真度（FID和CLIP分数）和检测准确性方面均优于先前的方法。

Conclusion: 提出的SFW是一种有效的框架，能够平衡鲁棒性和图像保真度，解决了语义水印中的固有权衡问题。

Abstract: Semantic watermarking techniques for latent diffusion models (LDMs) are
robust against regeneration attacks, but often suffer from detection
performance degradation due to the loss of frequency integrity. To tackle this
problem, we propose a novel embedding method called Hermitian Symmetric Fourier
Watermarking (SFW), which maintains frequency integrity by enforcing Hermitian
symmetry. Additionally, we introduce a center-aware embedding strategy that
reduces the vulnerability of semantic watermarking due to cropping attacks by
ensuring robust information retention. To validate our approach, we apply these
techniques to existing semantic watermarking schemes, enhancing their
frequency-domain structures for better robustness and retrieval accuracy.
Extensive experiments demonstrate that our methods achieve state-of-the-art
verification and identification performance, surpassing previous approaches
across various attack scenarios. Ablation studies confirm the impact of SFW on
detection capabilities, the effectiveness of the center-aware embedding against
cropping, and how message capacity influences identification accuracy. Notably,
our method achieves the highest detection accuracy while maintaining superior
image fidelity, as evidenced by FID and CLIP scores. Conclusively, our proposed
SFW is shown to be an effective framework for balancing robustness and image
fidelity, addressing the inherent trade-offs in semantic watermarking. Code
available at https://github.com/thomas11809/SFWMark

</details>


### [52] [Beyond Motion Cues and Structural Sparsity: Revisiting Small Moving Target Detection](https://arxiv.org/abs/2509.07654)
*Guoyi Zhang,Siyang Chen,Guangsheng Xu,Zhihua Shen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: 提出一种基于张量低秩和稀疏分解的深度学习框架TenRPCANet，用于解决低信噪比、模糊视觉线索和杂乱背景下的小目标检测问题，并在红外小目标检测和空间目标检测任务上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的小目标检测方法依赖目标特定特征或运动线索，在复杂环境中鲁棒性不足。本文旨在提出一种对目标特性假设最小、鲁棒性更强的新型深度学习框架。

Method: 将小目标检测视为张量低秩和稀疏分解问题。提出名为TenRPCANet的深度神经网络，利用自注意力机制强制执行多阶张量低秩先验，并设计特征细化模块增强目标显著性。

Result: 该方法在多帧红外小目标检测和空间目标检测两个具有挑战性的任务上取得了最先进的性能。

Conclusion: 所提出的方法在小目标检测方面是有效且可推广的，证明了张量低秩先验在复杂背景下检测小目标的可行性。

Abstract: Small moving target detection is crucial for many defense applications but
remains highly challenging due to low signal-to-noise ratios, ambiguous visual
cues, and cluttered backgrounds. In this work, we propose a novel deep learning
framework that differs fundamentally from existing approaches, which often rely
on target-specific features or motion cues and tend to lack robustness in
complex environments. Our key insight is that small target detection and
background discrimination are inherently coupled, even cluttered video
backgrounds often exhibit strong low-rank structures that can serve as stable
priors for detection. We reformulate the task as a tensor-based low-rank and
sparse decomposition problem and conduct a theoretical analysis of the
background, target, and noise components to guide model design. Building on
these insights, we introduce TenRPCANet, a deep neural network that requires
minimal assumptions about target characteristics. Specifically, we propose a
tokenization strategy that implicitly enforces multi-order tensor low-rank
priors through a self-attention mechanism. This mechanism captures both local
and non-local self-similarity to model the low-rank background without relying
on explicit iterative optimization. In addition, inspired by the sparse
component update in tensor RPCA, we design a feature refinement module to
enhance target saliency. The proposed method achieves state-of-the-art
performance on two highly distinct and challenging tasks: multi-frame infrared
small target detection and space object detection. These results demonstrate
both the effectiveness and the generalizability of our approach.

</details>


### [53] [Visual-TableQA: Open-Domain Benchmark for Reasoning over Table Images](https://arxiv.org/abs/2509.07966)
*Boammani Aser Lompo,Marc Haraoui*

Main category: cs.CV

TL;DR: Visual-TableQA是一个大规模、开放域的多模态数据集，用于评估和增强在复杂表格图像上的视觉推理能力。该数据集包含2.5k个LaTeX渲染的表格和6k个推理密集型问答对，成本低于100美元。实验结果表明，在该数据集上微调的模型能够很好地泛化到外部基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有表格图像视觉推理的基准测试在规模、多样性或推理深度方面存在局限性，特别是在渲染的表格图像方面。

Method: 使用一个模块化、可扩展且全自动的生成流程，该流程涉及多个LLM协同工作，扮演生成、验证和启发等不同角色，以创建包含多样化推理模式和视觉结构的数据集。

Result: 在Visual-TableQA上微调的模型在外部基准测试中表现稳健，并且优于几个专有模型，尽管该数据集是合成的。

Conclusion: Visual-TableQA数据集能够有效地评估和提升模型在复杂表格图像上的视觉推理能力，并且生成的模型在其他基准测试上也表现出良好的泛化能力。

Abstract: Visual reasoning over structured data such as tables is a critical capability
for modern vision-language models (VLMs), yet current benchmarks remain limited
in scale, diversity, or reasoning depth, especially when it comes to rendered
table images. Addressing this gap, we introduce Visual-TableQA, a large-scale,
open-domain multimodal dataset specifically designed to evaluate and enhance
visual reasoning over complex tabular data. Our generation pipeline is modular,
scalable, and fully autonomous, involving multiple reasoning LLMs collaborating
across distinct roles: generation, validation, and inspiration. Visual-TableQA
comprises 2.5k richly structured LaTeX-rendered tables and 6k
reasoning-intensive QA pairs, all produced at a cost of under USD 100. To
promote diversity and creativity, our pipeline performs multi-model
collaborative data generation via cross-model prompting ('inspiration') and
LLM-jury filtering. Stronger models seed layouts and topics that weaker models
elaborate, collectively distilling diverse reasoning patterns and visual
structures into the dataset. Empirical results show that models fine-tuned on
Visual-TableQA generalize robustly to external benchmarks, outperforming
several proprietary models despite the dataset's synthetic nature. The full
pipeline and resources are publicly available at
https://github.com/AI-4-Everyone/Visual-TableQA.

</details>


### [54] [EDFFDNet: Towards Accurate and Efficient Unsupervised Multi-Grid Image Registration](https://arxiv.org/abs/2509.07662)
*Haokai Zhu,Bo Qu,Si-Yuan Cao,Runmin Zhang,Shujie Chen,Bailin Yang,Hui-Liang Shen*

Main category: cs.CV

TL;DR: EDFFDNet是一种用于图像配准的新型网络，通过自由变形和指数衰减基函数解决深度差异问题，并引入ASMA和渐进式相关细化策略来提高效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度图像配准方法在处理具有深度差异的真实场景时存在局限性。

Method: 提出EDFFDNet，采用自由变形和指数衰减基函数，并引入ASMA和渐进式相关细化策略。

Result: EDFFDNet在参数量、内存和总运行时间上分别减少了70.5%、32.6%和33.7%，PSNR提高了0.5 dB。EDFFDNet-2进一步提高了PSNR，同时保持了较低的计算成本。该方法还表现出良好的泛化能力。

Conclusion: EDFFDNet在效率和准确性方面优于现有方法，特别是在处理具有深度差异的真实场景时，并具有良好的泛化能力。

Abstract: Previous deep image registration methods that employ single homography,
multi-grid homography, or thin-plate spline often struggle with real scenes
containing depth disparities due to their inherent limitations. To address
this, we propose an Exponential-Decay Free-Form Deformation Network (EDFFDNet),
which employs free-form deformation with an exponential-decay basis function.
This design achieves higher efficiency and performs well in scenes with depth
disparities, benefiting from its inherent locality. We also introduce an
Adaptive Sparse Motion Aggregator (ASMA), which replaces the MLP motion
aggregator used in previous methods. By transforming dense interactions into
sparse ones, ASMA reduces parameters and improves accuracy. Additionally, we
propose a progressive correlation refinement strategy that leverages
global-local correlation patterns for coarse-to-fine motion estimation, further
enhancing efficiency and accuracy. Experiments demonstrate that EDFFDNet
reduces parameters, memory, and total runtime by 70.5%, 32.6%, and 33.7%,
respectively, while achieving a 0.5 dB PSNR gain over the state-of-the-art
method. With an additional local refinement stage,EDFFDNet-2 further improves
PSNR by 1.06 dB while maintaining lower computational costs. Our method also
demonstrates strong generalization ability across datasets, outperforming
previous deep learning methods.

</details>


### [55] [Mini-o3: Scaling Up Reasoning Patterns and Interaction Turns for Visual Search](https://arxiv.org/abs/2509.07969)
*Xin Lai,Junyi Li,Wei Li,Tao Liu,Tianjian Li,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Mini-o3是一个能够进行深度、多轮推理的系统，在视觉搜索任务上达到了最先进的性能，并通过增加交互轮次提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的开源方法在处理需要试错探索的困难任务时，推理模式单一且交互轮次有限，无法满足需求。

Method: Mini-o3通过构建Visual Probe Dataset、开发迭代数据收集流程以及提出一个防止因超轮次响应而被惩罚的策略，实现了深度、多轮推理。

Result: Mini-o3能够生成丰富的推理模式和深度思考路径，有效解决了具有挑战性的视觉搜索问题，并且在推理时自然地扩展到数十轮，准确性随轮次增加而提高。

Conclusion: Mini-o3通过扩展工具使用交互和引入多轮推理，克服了现有方法的局限性，在视觉搜索任务上取得了显著的成果。

Abstract: Recent advances in large multimodal models have leveraged image-based tools
with reinforcement learning to tackle visual problems. However, existing
open-source approaches often exhibit monotonous reasoning patterns and allow
only a limited number of interaction turns, making them inadequate for
difficult tasks that require trial-and-error exploration. In this work, we
address this limitation by scaling up tool-based interactions and introduce
Mini-o3, a system that executes deep, multi-turn reasoning -- spanning tens of
steps -- and achieves state-of-the-art performance on challenging visual search
tasks. Our recipe for reproducing OpenAI o3-style behaviors comprises three key
components. First, we construct the Visual Probe Dataset, a collection of
thousands of challenging visual search problems designed for exploratory
reasoning. Second, we develop an iterative data collection pipeline to obtain
cold-start trajectories that exhibit diverse reasoning patterns, including
depth-first search, trial-and-error, and goal maintenance. Third, we propose an
over-turn masking strategy that prevents penalization of over-turn responses
(those that hit the maximum number of turns) during reinforcement learning,
thereby balancing training-time efficiency with test-time scalability. Despite
training with an upper bound of only six interaction turns, our model generates
trajectories that naturally scale to tens of turns at inference time, with
accuracy improving as the number of turns increases. Extensive experiments
demonstrate that Mini-o3 produces rich reasoning patterns and deep thinking
paths, effectively solving challenging visual search problems.

</details>


### [56] [Nearest Neighbor Projection Removal Adversarial Training](https://arxiv.org/abs/2509.07673)
*Himanshu Singh,A. V. Subramanyam,Shivank Rajput,Mohan Kankanhalli*

Main category: cs.CV

TL;DR: 该研究提出了一种新的对抗训练框架，通过在特征空间中消除对抗样本和干净样本的类间依赖性来增强模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 标准对抗训练未能明确解决加剧对抗样本易感性的类间特征重叠问题。

Method: 该方法首先识别每个对抗样本的最近类间邻居，然后移除指向这些邻居的投影，以强制执行更强的特征可分离性。

Result: 在CIFAR-10、CIFAR-100和SVHN等标准基准上的广泛实验表明，该方法在鲁棒和干净的准确度方面都取得了与领先的对抗训练技术相媲美的影响力。

Conclusion: 为了增强深度神经网络的对抗鲁棒性，明确解决类间特征接近性至关重要。

Abstract: Deep neural networks have exhibited impressive performance in image
classification tasks but remain vulnerable to adversarial examples. Standard
adversarial training enhances robustness but typically fails to explicitly
address inter-class feature overlap, a significant contributor to adversarial
susceptibility. In this work, we introduce a novel adversarial training
framework that actively mitigates inter-class proximity by projecting out
inter-class dependencies from adversarial and clean samples in the feature
space. Specifically, our approach first identifies the nearest inter-class
neighbors for each adversarial sample and subsequently removes projections onto
these neighbors to enforce stronger feature separability. Theoretically, we
demonstrate that our proposed logits correction reduces the Lipschitz constant
of neural networks, thereby lowering the Rademacher complexity, which directly
contributes to improved generalization and robustness. Extensive experiments
across standard benchmarks including CIFAR-10, CIFAR-100, and SVHN show that
our method demonstrates strong performance that is competitive with leading
adversarial training techniques, highlighting significant achievements in both
robust and clean accuracy. Our findings reveal the importance of addressing
inter-class feature proximity explicitly to bolster adversarial robustness in
DNNs.

</details>


### [57] [CAViAR: Critic-Augmented Video Agentic Reasoning](https://arxiv.org/abs/2509.07680)
*Sachit Menon,Ahmet Iscen,Arsha Nagrani,Tobias Weyand,Carl Vondrick,Cordelia Schmid*

Main category: cs.CV

TL;DR: 现有视频理解模型在处理长视频和复杂推理任务时表现不佳，本文提出一种基于大型语言模型（LLM）的智能体，该智能体能够调用视频处理模块（子智能体或工具）来执行复杂的视频推理任务，并引入一个评论家来区分成功和失败的执行序列，在多个基准测试中取得了良好性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解模型在处理长视频和复杂推理任务时表现不佳，需要探索如何利用现有感知能力来执行更复杂的视频推理。

Method: 提出一个大型语言模型智能体，该智能体能够访问视频模块作为子智能体或工具。与固定程序不同，该智能体根据每次模块调用的结果来决定后续步骤。引入一个评论家来区分成功和失败的执行序列。

Result: 该智能体和评论家组合在 LVBench、Neptune 和 ActivityNet-RTL 等数据集上取得了强大的性能。

Conclusion: 通过结合 LLM 智能体和评论家，可以有效利用现有视频感知能力来解决复杂的视频推理问题，并在相关基准测试中取得显著成果。

Abstract: Video understanding has seen significant progress in recent years, with
models' performance on perception from short clips continuing to rise. Yet,
multiple recent benchmarks, such as LVBench, Neptune, and ActivityNet-RTL, show
performance wanes for tasks requiring complex reasoning on videos as queries
grow more complex and videos grow longer. In this work, we ask: can existing
perception capabilities be leveraged to successfully perform more complex video
reasoning? In particular, we develop a large language model agent given access
to video modules as subagents or tools. Rather than following a fixed procedure
to solve queries as in previous work such as Visual Programming, ViperGPT, and
MoReVQA, the agent uses the results of each call to a module to determine
subsequent steps. Inspired by work in the textual reasoning domain, we
introduce a critic to distinguish between instances of successful and
unsuccessful sequences from the agent. We show that the combination of our
agent and critic achieve strong performance on the previously-mentioned
datasets.

</details>


### [58] [SEEC: Segmentation-Assisted Multi-Entropy Models for Learned Lossless Image Compression](https://arxiv.org/abs/2509.07704)
*Chunhang Zheng,Zichang Ren,Dou Li*

Main category: cs.CV

TL;DR: SEEC 使用语义分割来辅助多个熵模型，以提高无损图像压缩的性能，并在基准数据集上实现了最先进的压缩率。


<details>
  <summary>Details</summary>
Motivation: 大多数现有的学习图像压缩方法使用单一的熵模型来估计整个图像的像素值概率分布，这限制了它们捕捉不同语义区域的多样化统计特征的能力。

Method: SEEC 框架首先提取图像特征，然后应用语义分割来识别不同的区域，为每个区域分配一个专门的熵模型来更好地捕捉其独特的统计特性。最后，采用多通道离散逻辑混合似然来有效地模拟像素值分布。

Result: SEEC 在基准数据集上实现了最先进的压缩率，同时只引入了极小的编码和解码延迟。

Conclusion: SEEC 通过利用语义分割来辅助多个熵模型，实现了比传统方法更优越的性能，并且支持基于提供的分割掩码的感兴趣区域（ROI）编码。

Abstract: Recently, learned image compression has attracted considerable attention due
to its superior performance over traditional methods. However, most existing
approaches employ a single entropy model to estimate the probability
distribution of pixel values across the entire image, which limits their
ability to capture the diverse statistical characteristics of different
semantic regions. To overcome this limitation, we propose Segmentation-Assisted
Multi-Entropy Models for Lossless Image Compression (SEEC). Our framework
utilizes semantic segmentation to guide the selection and adaptation of
multiple entropy models, enabling more accurate probability distribution
estimation for distinct semantic regions. Specifically, SEEC first extracts
image features and then applies semantic segmentation to identify different
regions, each assigned a specialized entropy model to better capture its unique
statistical properties. Finally, a multi-channel discrete logistic mixture
likelihood is employed to model the pixel value distributions effectively.
Experimental results on benchmark datasets demonstrate that SEEC achieves
state-of-the-art compression ratios while introducing only minimal encoding and
decoding latency. With superior performance, the proposed model also supports
Regions of Interest (ROIs) coding condition on the provided segmentation mask.
Our code is available at https://github.com/chunbaobao/SEEC.

</details>


### [59] [XSRD-Net: EXplainable Stroke Relapse Detection](https://arxiv.org/abs/2509.07772)
*Christian Gapp,Elias Tappeiner,Martin Welk,Karl Fritscher,Stephanie Mangesius,Constantin Eisenschink,Philipp Deisl,Michael Knoflach,Astrid E. Grams,Elke R. Gizewski,Rainer Schubert*

Main category: cs.CV

TL;DR: 通过分析患者的3D颅内CTA图像、心脏病史、年龄和性别，利用深度学习模型预测中风复发风险。


<details>
  <summary>Details</summary>
Motivation: 中风复发率高且死亡率高，因此早期识别高风险患者至关重要。

Method: 收集了2010年至2024年间的中风患者的3D颅内CTA图像、心脏病史、年龄和性别数据。训练了单一和多模态深度学习神经网络，分别用于二元复发检测（任务1）和无复发生存（RFS）时间预测及分类（任务2）。

Result: 在任务1中，仅使用表格数据即可达到0.84的AUC。在任务2中，多模态XSRD-net模型在测试集上的c指数为0.68，AUC为0.71。模型的可解释性分析显示，心脏病和颈动脉与中风复发及RFS时间预测相关。

Conclusion: 心脏病和颈动脉特征与中风复发风险和生存时间预测相关，为后续数据收集和模型优化提供了方向。

Abstract: Stroke is the second most frequent cause of death world wide with an annual
mortality of around 5.5 million. Recurrence rates of stroke are between 5 and
25% in the first year. As mortality rates for relapses are extraordinarily high
(40%) it is of utmost importance to reduce the recurrence rates. We address
this issue by detecting patients at risk of stroke recurrence at an early stage
in order to enable appropriate therapy planning. To this end we collected 3D
intracranial CTA image data and recorded concomitant heart diseases, the age
and the gender of stroke patients between 2010 and 2024. We trained single- and
multimodal deep learning based neural networks for binary relapse detection
(Task 1) and for relapse free survival (RFS) time prediction together with a
subsequent classification (Task 2). The separation of relapse from non-relapse
patients (Task 1) could be solved with tabular data (AUC on test dataset:
0.84). However, for the main task, the regression (Task 2), our multimodal
XSRD-net processed the modalities vision:tabular with 0.68:0.32 according to
modality contribution measures. The c-index with respect to relapses for the
multimodal model reached 0.68, and the AUC is 0.71 for the test dataset. Final,
deeper interpretability analysis results could highlight a link between both
heart diseases (tabular) and carotid arteries (vision) for the detection of
relapses and the prediction of the RFS time. This is a central outcome that we
strive to strengthen with ongoing data collection and model retraining.

</details>


### [60] [HairGS: Hair Strand Reconstruction based on 3D Gaussian Splatting](https://arxiv.org/abs/2509.07774)
*Yimin Pan,Matthias Nießner,Tobias Kirschstein*

Main category: cs.CV

TL;DR: 本文提出了一种基于3D高斯泼溅（3DGS）的头发几何重建方法，能够从多视角图像中恢复头发的拓扑结构，并在合成和真实世界数据集中进行了验证。


<details>
  <summary>Details</summary>
Motivation: 在计算机视觉领域，人体头发重建因其在虚拟现实和数字人建模中的应用而日益重要，但这是一个具有挑战性的问题。现有方法在评估重建质量时，往往忽略了头发的连接性和拓扑结构。

Method: 提出了一种多阶段方法：首先使用可微分高斯光栅化器重建详细的头发几何，然后通过一种新颖的合并方案将单个高斯片段合并成连贯的发束，最后在光度监督下对发束进行优化和生长。此外，还提出了一种新的评估指标来评估重建的拓扑准确性。

Result: 在合成和真实世界的数据集上进行了广泛的实验，证明该方法能够稳健地处理各种发型，并且重建效率高，通常在1小时内完成。

Conclusion: 所提出的方法能够从多视角图像中实现高效且拓扑准确的头发几何重建，并且能够处理各种发型。

Abstract: Human hair reconstruction is a challenging problem in computer vision, with
growing importance for applications in virtual reality and digital human
modeling. Recent advances in 3D Gaussians Splatting (3DGS) provide efficient
and explicit scene representations that naturally align with the structure of
hair strands. In this work, we extend the 3DGS framework to enable strand-level
hair geometry reconstruction from multi-view images. Our multi-stage pipeline
first reconstructs detailed hair geometry using a differentiable Gaussian
rasterizer, then merges individual Gaussian segments into coherent strands
through a novel merging scheme, and finally refines and grows the strands under
photometric supervision.
  While existing methods typically evaluate reconstruction quality at the
geometric level, they often neglect the connectivity and topology of hair
strands. To address this, we propose a new evaluation metric that serves as a
proxy for assessing topological accuracy in strand reconstruction. Extensive
experiments on both synthetic and real-world datasets demonstrate that our
method robustly handles a wide range of hairstyles and achieves efficient
reconstruction, typically completing within one hour.
  The project page can be found at: https://yimin-pan.github.io/hair-gs/

</details>


### [61] [RayGaussX: Accelerating Gaussian-Based Ray Marching for Real-Time and High-Quality Novel View Synthesis](https://arxiv.org/abs/2509.07782)
*Hugo Blanc,Jean-Emmanuel Deschaud,Alexis Paljic*

Main category: cs.CV

TL;DR: RayGaussX 通过引入体积渲染加速策略（如空空间跳跃和自适应采样）、增强光线连贯性、引入尺度正则化以及新的致密化标准，显著提高了 RayGauss 的训练和推理速度，同时改善了视觉质量，使其能够实现实时渲染。


<details>
  <summary>Details</summary>
Motivation: RayGauss 在合成和室内场景中实现了最先进的新视图合成渲染质量，但其计算成本限制了在真实世界场景中的实时渲染能力。需要一种更快的训练和推理方法。

Method: RayGaussX 在 RayGauss 的基础上，引入了体积渲染加速策略（空空间跳跃、自适应采样）、增强光线连贯性、尺度正则化以及新的致密化标准，以提高训练和推理速度并增强图形质量。

Result: RayGaussX 在真实世界数据集上实现了 5 倍到 12 倍的训练加速和 50 倍到 80 倍的渲染速度（FPS）提升，同时在 PSNR 上将视觉质量提高了高达 +0.56 dB。

Conclusion: RayGaussX 成功解决了 RayGauss 的计算成本问题，实现了在真实世界场景中进行实时渲染，并在性能和视觉质量上均取得了显著提升。

Abstract: RayGauss has achieved state-of-the-art rendering quality for novel-view
synthesis on synthetic and indoor scenes by representing radiance and density
fields with irregularly distributed elliptical basis functions, rendered via
volume ray casting using a Bounding Volume Hierarchy (BVH). However, its
computational cost prevents real-time rendering on real-world scenes. Our
approach, RayGaussX, builds on RayGauss by introducing key contributions that
accelerate both training and inference. Specifically, we incorporate volumetric
rendering acceleration strategies such as empty-space skipping and adaptive
sampling, enhance ray coherence, and introduce scale regularization to reduce
false-positive intersections. Additionally, we propose a new densification
criterion that improves density distribution in distant regions, leading to
enhanced graphical quality on larger scenes. As a result, RayGaussX achieves 5x
to 12x faster training and 50x to 80x higher rendering speeds (FPS) on
real-world datasets while improving visual quality by up to +0.56 dB in PSNR.
Project page with videos and code: https://raygaussx.github.io/.

</details>


### [62] [Faster, Self-Supervised Super-Resolution for Anisotropic Multi-View MRI Using a Sparse Coordinate Loss](https://arxiv.org/abs/2509.07798)
*Maja Schlereth,Moritz Schillinger,Katharina Breininger*

Main category: cs.CV

TL;DR: 本文提出一种新颖的多视图神经网络方法，通过融合两个低分辨率（LR）的MR图像，以无监督方式重建高分辨率（HR）图像，并在不牺牲质量的情况下显著加快了患者特定重建的速度。


<details>
  <summary>Details</summary>
Motivation: 在医学领域，高分辨率成像常常需要在成像时间和患者舒适度之间进行权衡。对于磁共振（MR）成像，为了在扫描时间和质量之间取得平衡，通常会采集两种不同低分辨率（LR）方向的各向异性扫描。然而，这些LR扫描通常由放射科医生单独分析，耗时且可能导致解释不准确。

Method: 提出一种新颖的多视图神经网络方法，通过融合两个正交的各向异性LR MR图像，以无监督方式重建解剖细节。该网络采用自监督学习方式进行训练，无需配对的高分辨率（HR）数据。为了优化模型，引入了一种稀疏坐标损失，能够处理任意尺度的LR图像。该方法结合了与患者无关的离线阶段和与患者相关的在线阶段。

Result: 在两个独立队列的MR图像上进行了评估。结果表明，与最先进（SOTA）的自监督SR方法相比，在不同的放大尺度下，超分辨率（SR）性能相当甚至有所提高。通过结合离线和在线阶段，实现了高达十倍的患者特定重建加速，同时保持了相似或更好的SR质量。

Conclusion: 所提出的多视图神经网络方法能够有效地融合多个LR MR图像，生成高质量的HR图像，并且在显著减少重建时间的同时，达到了与现有SOTA方法相当或更好的性能。

Abstract: Acquiring images in high resolution is often a challenging task. Especially
in the medical sector, image quality has to be balanced with acquisition time
and patient comfort. To strike a compromise between scan time and quality for
Magnetic Resonance (MR) imaging, two anisotropic scans with different
low-resolution (LR) orientations can be acquired. Typically, LR scans are
analyzed individually by radiologists, which is time consuming and can lead to
inaccurate interpretation. To tackle this, we propose a novel approach for
fusing two orthogonal anisotropic LR MR images to reconstruct anatomical
details in a unified representation. Our multi-view neural network is trained
in a self-supervised manner, without requiring corresponding high-resolution
(HR) data. To optimize the model, we introduce a sparse coordinate-based loss,
enabling the integration of LR images with arbitrary scaling. We evaluate our
method on MR images from two independent cohorts. Our results demonstrate
comparable or even improved super-resolution (SR) performance compared to
state-of-the-art (SOTA) self-supervised SR methods for different upsampling
scales. By combining a patient-agnostic offline and a patient-specific online
phase, we achieve a substantial speed-up of up to ten times for
patient-specific reconstruction while achieving similar or better SR quality.
Code is available at https://github.com/MajaSchle/tripleSR.

</details>


### [63] [SplatFill: 3D Scene Inpainting via Depth-Guided Gaussian Splatting](https://arxiv.org/abs/2509.07809)
*Mahtab Dahaghin,Milind G. Padalkar,Matteo Toso,Alessio Del Bue*

Main category: cs.CV

TL;DR: SplatFill 是一种新的深度引导方法，用于 3DGS 场景修复，可实现高质量的修复效果和更高的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的 3DGS 场景修复方法在处理遮挡或场景编辑产生的缺失区域时，常常导致细节模糊、出现瑕疵和几何不一致。

Method: SplatFill 结合了基于深度和基于对象的联合监督，以确保修复后的高斯点能够准确地放置在三维空间中并与周围的几何体对齐。此外，还提出了一种感知一致性的优化方案，可以选择性地识别和纠正不一致的区域，同时不破坏场景的其余部分。

Result: 与现有的基于 NeRF 和 3DGS 的修复方法相比，SplatFill 在视觉保真度方面表现更优，并且训练时间减少了 24.5%。

Conclusion: SplatFill 在视觉保真度、细节锐利度、瑕疵减少和跨视角一致性方面均优于现有方法，并提高了效率。

Abstract: 3D Gaussian Splatting (3DGS) has enabled the creation of highly realistic 3D
scene representations from sets of multi-view images. However, inpainting
missing regions, whether due to occlusion or scene editing, remains a
challenging task, often leading to blurry details, artifacts, and inconsistent
geometry. In this work, we introduce SplatFill, a novel depth-guided approach
for 3DGS scene inpainting that achieves state-of-the-art perceptual quality and
improved efficiency. Our method combines two key ideas: (1) joint depth-based
and object-based supervision to ensure inpainted Gaussians are accurately
placed in 3D space and aligned with surrounding geometry, and (2) we propose a
consistency-aware refinement scheme that selectively identifies and corrects
inconsistent regions without disrupting the rest of the scene. Evaluations on
the SPIn-NeRF dataset demonstrate that SplatFill not only surpasses existing
NeRF-based and 3DGS-based inpainting methods in visual fidelity but also
reduces training time by 24.5%. Qualitative results show our method delivers
sharper details, fewer artifacts, and greater coherence across challenging
viewpoints.

</details>


### [64] [Point Linguist Model: Segment Any Object via Bridged Large 3D-Language Model](https://arxiv.org/abs/2509.07825)
*Zhuoxu Huang,Mingqi Gao,Jungong Han*

Main category: cs.CV

TL;DR: 大型语言模型在3D目标分割中存在表示不对齐问题，本文提出了Point Linguist Model (PLM)框架，通过引入Object-centric Discriminative Representation (OcDR)和Geometric Reactivation Decoder (GRD)来解决此问题，并在多个3D分割任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于大型语言模型（LLM）的3D目标分割方法存在表示不对齐的局限性：LLM处理高层语义，而3D点云是密集的几何结构。这导致输入预处理困难，并且输出预测缺乏精细的几何精度。

Method: 本文提出了Point Linguist Model (PLM)框架。该框架包含两个关键组件：1. Object-centric Discriminative Representation (OcDR)，用于学习目标语义和场景关系的对象中心令牌，并采用硬负例感知训练目标来解决LLM令牌与3D点云之间的不对齐问题，增强对干扰项的鲁棒性。2. Geometric Reactivation Decoder (GRD)，通过结合OcDR令牌（包含LLM推断的几何信息）和相应的密集特征来预测分割掩码，从而保留完整的密集特征。

Result: PLM在ScanNetv2上取得了+7.3 mIoU的提升，在Multi3DRefer上取得了+6.0 mIoU的提升，并在涵盖4个不同任务的7个基准测试中均取得了持续的性能提升。

Conclusion: PLM通过引入对象中心推理有效解决了表示不对齐问题，为3D目标分割提供了更强大的鲁棒性和精度。

Abstract: 3D object segmentation with Large Language Models (LLMs) has become a
prevailing paradigm due to its broad semantics, task flexibility, and strong
generalization. However, this paradigm is hindered by representation
misalignment: LLMs process high-level semantic tokens, whereas 3D point clouds
convey only dense geometric structures. In prior methods, misalignment limits
both input and output. At the input stage, dense point patches require heavy
pre-alignment, weakening object-level semantics and confusing similar
distractors. At the output stage, predictions depend only on dense features
without explicit geometric cues, leading to a loss of fine-grained accuracy. To
address these limitations, we present the Point Linguist Model (PLM), a general
framework that bridges the representation gap between LLMs and dense 3D point
clouds without requiring large-scale pre-alignment between 3D-text or
3D-images. Specifically, we introduce Object-centric Discriminative
Representation (OcDR), which learns object-centric tokens that capture target
semantics and scene relations under a hard negative-aware training objective.
This mitigates the misalignment between LLM tokens and 3D points, enhances
resilience to distractors, and facilitates semantic-level reasoning within
LLMs. For accurate segmentation, we introduce the Geometric Reactivation
Decoder (GRD), which predicts masks by combining OcDR tokens carrying
LLM-inferred geometry with corresponding dense features, preserving
comprehensive dense features throughout the pipeline. Extensive experiments
show that PLM achieves significant improvements of +7.3 mIoU on ScanNetv2 and
+6.0 mIoU on Multi3DRefer for 3D referring segmentation, with consistent gains
across 7 benchmarks spanning 4 different tasks, demonstrating the effectiveness
of comprehensive object-centric reasoning for robust 3D understanding.

</details>


### [65] [Deep Learning-Based Burned Area Mapping Using Bi-Temporal Siamese Networks and AlphaEarth Foundation Datasets](https://arxiv.org/abs/2509.07852)
*Seyd Teymoor Seydi*

Main category: cs.CV

TL;DR: 本研究提出一种利用 AlphaEarth 数据集和 Siamese U-Net 深度学习模型实现自动化火烧迹地绘制的新方法。


<details>
  <summary>Details</summary>
Motivation: 准确及时地绘制火烧迹地对于环境监测、灾害管理和评估气候变化至关重要。

Method: 结合 AlphaEarth 数据集（包含高分辨率光学和热红外图像及地面真实注释）和 Siamese U-Net 深度学习架构，在 MTBS 数据集上进行训练，并在欧洲17个区域进行评估。

Result: 实验结果表明，该集成方法在测试数据集上实现了 95% 的总体准确率、0.6 的 IoU 和 74% 的 F1 分数，在各种生态系统中成功识别火烧迹地，尤其在检测部分燃烧植被和火线方面表现出色，证明了其可转移性和高泛化能力。

Conclusion: 该研究通过 AlphaEarth 数据集推动了自动化火灾损害评估的发展，并为全球火烧迹地监测提供了一个可扩展的解决方案。

Abstract: Accurate and timely mapping of burned areas is crucial for environmental
monitoring, disaster management, and assessment of climate change. This study
presents a novel approach to automated burned area mapping using the AlphaEArth
dataset combined with the Siamese U-Net deep learning architecture. The
AlphaEArth Dataset, comprising high-resolution optical and thermal infrared
imagery with comprehensive ground-truth annotations, provides an unprecedented
resource for training robust burned area detection models. We trained our model
with the Monitoring Trends in Burn Severity (MTBS) dataset in the contiguous US
and evaluated it with 17 regions cross in Europe. Our experimental results
demonstrate that the proposed ensemble approach achieves superior performance
with an overall accuracy of 95%, IoU of 0.6, and F1-score of 74% on the test
dataset. The model successfully identifies burned areas across diverse
ecosystems with complex background, showing particular strength in detecting
partially burned vegetation and fire boundaries and its transferability and
high generalization in burned area mapping. This research contributes to the
advancement of automated fire damage assessment and provides a scalable
solution for global burn area monitoring using the AlphaEarth dataset.

</details>


### [66] [D-LEAF: Localizing and Correcting Hallucinations in Multimodal LLMs via Layer-to-head Attention Diagnostics](https://arxiv.org/abs/2509.07864)
*Tiancheng Yang,Lin Zhang,Jiaye Lin,Guimin Hu,Di Wang,Lijie Hu*

Main category: cs.CV

TL;DR: MLLMs 容易产生幻觉，现有方法难以准确定位问题根源。本文提出 D-LEAF，通过 LIAE 和 IAF 定位问题层和头，实现 53% 的性能提升和约 4% 的准确率/F1 分数提升，有效减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有 MLLMs 存在幻觉问题，且现有方法难以精确定位导致幻觉的视觉注意力问题。

Method: 提出 LIAE 和 IAF 两个诊断方法，用于定位问题层和注意力头。基于诊断结果，提出 D-LEAF 方法，动态地在推理过程中纠正错误。

Result: D-LEAF 在图像描述任务上实现 53% 的相对提升，在 VQA 任务上准确率和 F1 分数提升约 4%，有效减少幻觉且保持了效率。

Conclusion: D-LEAF 是一种有效的、轻量级的、可应用于多种任务的方法，能够通过动态的注意力引导来解决 MLLMs 的幻觉问题。

Abstract: Multimodal Large Language Models (MLLMs) achieve strong performance on tasks
like image captioning and visual question answering, but remain prone to
hallucinations, where generated text conflicts with the visual input. Prior
work links this partly to insufficient visual attention, but existing
attention-based detectors and mitigation typically apply uniform adjustments
across layers and heads, obscuring where errors originate. In this paper, we
first show these methods fail to accurately localize problematic layers. Then,
we introduce two diagnostics: Layer Image Attention Entropy (LIAE) which flags
anomalous layers, and Image Attention Focus (IAF) which scores attention heads
within those layers. Analysis shows that LIAE pinpoints faulty layers and IAF
reliably ranks heads that warrant correction. Guided by these signals, we
propose Dynamic Layer-wise Entropy and Attention Fusion (D-LEAF), a
task-agnostic, attention-guided method that dynamically localizes and corrects
errors during inference with negligible overhead. Results show our D-LEAF
delivers a 53% relative improvement on standard captioning benchmarks, and on
VQA both accuracy and F1-score improve by approximately 4%, substantially
suppressing hallucinations while preserving efficiency.

</details>


### [67] [Active Membership Inference Test (aMINT): Enhancing Model Auditability with Multi-Task Learning](https://arxiv.org/abs/2509.07879)
*Daniel DeAlcala,Aythami Morales,Julian Fierrez,Gonzalo Mancera,Ruben Tolosana,Javier Ortega-Garcia*

Main category: cs.CV

TL;DR: aMINT通过训练一个同时识别训练数据的MINT模型来检测数据是否用于训练模型，实现了80%以上的准确率，提高了AI模型的透明度和安全性。


<details>
  <summary>Details</summary>
Motivation: 检测给定数据是否用于训练机器学习模型，并提高AI模型的透明度、安全性和隐私保护。

Method: 提出了一种新颖的多任务学习过程，同时训练原始模型（Audited Model）和MINT模型。MINT模型利用中间激活图来识别用于训练Audited Model的数据，并将模型的可审计性作为优化目标。

Result: 在包括MobileNet到Vision Transformers在内的多种神经网络上，于5个公共基准测试中，aMINT实现了超过80%的准确率，显著优于现有方法。

Conclusion: aMINT及其相关方法有助于提高AI模型的透明度，为AI部署提供更强的安全、隐私和版权保护。

Abstract: Active Membership Inference Test (aMINT) is a method designed to detect
whether given data were used during the training of machine learning models. In
Active MINT, we propose a novel multitask learning process that involves
training simultaneously two models: the original or Audited Model, and a
secondary model, referred to as the MINT Model, responsible for identifying the
data used for training the Audited Model. This novel multi-task learning
approach has been designed to incorporate the auditability of the model as an
optimization objective during the training process of neural networks. The
proposed approach incorporates intermediate activation maps as inputs to the
MINT layers, which are trained to enhance the detection of training data. We
present results using a wide range of neural networks, from lighter
architectures such as MobileNet to more complex ones such as Vision
Transformers, evaluated in 5 public benchmarks. Our proposed Active MINT
achieves over 80% accuracy in detecting if given data was used for training,
significantly outperforming previous approaches in the literature. Our aMINT
and related methodological developments contribute to increasing transparency
in AI models, facilitating stronger safeguards in AI deployments to achieve
proper security, privacy, and copyright protection.

</details>


### [68] [Object-level Correlation for Few-Shot Segmentation](https://arxiv.org/abs/2509.07917)
*Chunlin Wen,Yu Zhang,Jie Fan,Hongyuan Zhu,Xiu-Shen Wei,Yijun Wang,Zhiqiang Kou,Shuzhou Sun*

Main category: cs.CV

TL;DR: 现有方法主要建立图像级关联，但包含难以抑制的背景噪声。本文提出对象级关联网络（OCNet），通过挖掘查询图像中的通用对象并建立对象级关联，来克服图像级关联的局限性，实现更准确的少样本语义分割。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少样本语义分割中主要建立图像级关联，容易受到背景噪声的干扰，导致过拟合。因此，需要一种更有效的方法来处理对象级信息，尤其是在数据稀疏的情况下。

Method: 本文设计了一个对象级关联网络（OCNet），包含通用对象挖掘模块（GOMM）和关联构建模块（CCM）。GOMM通过学习显著性和高层相似性线索来构建查询通用对象特征，CCM则通过分配目标原型与通用对象特征进行匹配，建立对象级关联，从而挖掘目标特征并抑制背景噪声。

Result: 在PASCAL-5^i和COCO-20^i数据集上的大量实验表明，本文提出的模型达到了最先进的性能。

Conclusion: 所提出的OCNet通过引入对象级关联，能够有效挖掘查询目标特征并抑制背景噪声，在少样本语义分割任务上取得了优于现有方法的性能。

Abstract: Few-shot semantic segmentation (FSS) aims to segment objects of novel
categories in the query images given only a few annotated support samples.
Existing methods primarily build the image-level correlation between the
support target object and the entire query image. However, this correlation
contains the hard pixel noise, \textit{i.e.}, irrelevant background objects,
that is intractable to trace and suppress, leading to the overfitting of the
background. To address the limitation of this correlation, we imitate the
biological vision process to identify novel objects in the object-level
information. Target identification in the general objects is more valid than in
the entire image, especially in the low-data regime. Inspired by this, we
design an Object-level Correlation Network (OCNet) by establishing the
object-level correlation between the support target object and query general
objects, which is mainly composed of the General Object Mining Module (GOMM)
and Correlation Construction Module (CCM). Specifically, GOMM constructs the
query general object feature by learning saliency and high-level similarity
cues, where the general objects include the irrelevant background objects and
the target foreground object. Then, CCM establishes the object-level
correlation by allocating the target prototypes to match the general object
feature. The generated object-level correlation can mine the query target
feature and suppress the hard pixel noise for the final prediction. Extensive
experiments on PASCAL-${5}^{i}$ and COCO-${20}^{i}$ show that our model
achieves the state-of-the-art performance.

</details>


### [69] [ScoreHOI: Physically Plausible Reconstruction of Human-Object Interaction via Score-Guided Diffusion](https://arxiv.org/abs/2509.07920)
*Ao Li,Jinpeng Liu,Yixuan Zhu,Yansong Tang*

Main category: cs.CV

TL;DR: ScoreHOI是一个基于扩散的优化器，通过引入扩散先验来精确恢复人-物交互，并提出了一种接触驱动的迭代细化方法，以提高重建的准确性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 先前的优化方法在重建人-物交互时，由于缺乏交互的先验知识，常常难以获得物理上合理的结果。

Method: ScoreHOI利用基于分数的引导采样来控制扩散模型，以在图像观测和物体特征的条件下，重建人类和物体姿态的条件分布。在推理过程中，ScoreHOI通过用特定的物理约束来指导去噪过程，从而有效地改善了重建结果。此外，还提出了一种接触驱动的迭代细化方法来增强接触的合理性并提高重建精度。

Result: 在标准基准上的广泛评估表明，ScoreHOI的性能优于最先进的方法，在联合人-物交互重建方面实现了精确且鲁棒的改进。

Conclusion: ScoreHOI通过引入扩散先验和接触驱动的迭代细化方法，能够实现精确且鲁棒的人-物交互重建，优于现有技术。

Abstract: Joint reconstruction of human-object interaction marks a significant
milestone in comprehending the intricate interrelations between humans and
their surrounding environment. Nevertheless, previous optimization methods
often struggle to achieve physically plausible reconstruction results due to
the lack of prior knowledge about human-object interactions. In this paper, we
introduce ScoreHOI, an effective diffusion-based optimizer that introduces
diffusion priors for the precise recovery of human-object interactions. By
harnessing the controllability within score-guided sampling, the diffusion
model can reconstruct a conditional distribution of human and object pose given
the image observation and object feature. During inference, the ScoreHOI
effectively improves the reconstruction results by guiding the denoising
process with specific physical constraints. Furthermore, we propose a
contact-driven iterative refinement approach to enhance the contact
plausibility and improve the reconstruction accuracy. Extensive evaluations on
standard benchmarks demonstrate ScoreHOI's superior performance over
state-of-the-art methods, highlighting its ability to achieve a precise and
robust improvement in joint human-object interaction reconstruction.

</details>


### [70] [Multimodal Contrastive Pretraining of CBCT and IOS for Enhanced Tooth Segmentation](https://arxiv.org/abs/2509.07923)
*Moo Hyun Son,Juyoung Bae,Zelin Qiu,Jiale Peng,Kai Xin Li,Yifan Lin,Hao Chen*

Main category: cs.CV

TL;DR: 该研究提出了一个名为ToothMCL的多模态对比学习框架，用于牙齿分割，并发布了迄今为止最大的配对CBCT和IOS数据集CBCT-IOS3.8K，在多个独立数据集上实现了最先进的分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有牙齿分割方法缺乏严格验证，性能和临床应用有限，需要更精确的牙齿分割方法。

Method: 提出了一种名为ToothMCL的多模态对比学习框架，该框架整合了CBCT（体积）和IOS（表面）模态，通过对比学习捕捉模态不变的表征，以实现精确的多类别牙齿分割和FDI牙齿编号。同时，研究者收集并发布了CBCT-IOS3.8K数据集。

Result: ToothMCL在内部和外部测试中均实现了最先进的性能，Dice相似系数（DSC）在CBCT分割上提高了12%，在IOS分割上提高了8%。此外，ToothMCL在牙齿分组方面持续优于现有方法，并在不同的成像条件和临床场景中表现出鲁棒的泛化能力。

Conclusion: ToothMCL是一个有效的多模态预训练框架，能够提高牙齿分割的准确性和泛化能力，为数字牙科领域带来了显著的进步。

Abstract: Digital dentistry represents a transformative shift in modern dental
practice. The foundational step in this transformation is the accurate digital
representation of the patient's dentition, which is obtained from segmented
Cone-Beam Computed Tomography (CBCT) and Intraoral Scans (IOS). Despite the
growing interest in digital dental technologies, existing segmentation
methodologies frequently lack rigorous validation and demonstrate limited
performance and clinical applicability. To the best of our knowledge, this is
the first work to introduce a multimodal pretraining framework for tooth
segmentation. We present ToothMCL, a Tooth Multimodal Contrastive Learning for
pretraining that integrates volumetric (CBCT) and surface-based (IOS)
modalities. By capturing modality-invariant representations through multimodal
contrastive learning, our approach effectively models fine-grained anatomical
features, enabling precise multi-class segmentation and accurate identification
of F\'ed\'eration Dentaire Internationale (FDI) tooth numbering. Along with the
framework, we curated CBCT-IOS3.8K, the largest paired CBCT and IOS dataset to
date, comprising 3,867 patients. We then evaluated ToothMCL on a comprehensive
collection of independent datasets, representing the largest and most diverse
evaluation to date. Our method achieves state-of-the-art performance in both
internal and external testing, with an increase of 12\% for CBCT segmentation
and 8\% for IOS segmentation in the Dice Similarity Coefficient (DSC).
Furthermore, ToothMCL consistently surpasses existing approaches in tooth
groups and demonstrates robust generalizability across varying imaging
conditions and clinical scenarios.

</details>


### [71] [Accelerating Local AI on Consumer GPUs: A Hardware-Aware Dynamic Strategy for YOLOv10s](https://arxiv.org/abs/2509.07928)
*Mahmudul Islam Masum,Miad Islam,Arif I. Sarwat*

Main category: cs.CV

TL;DR: 本地AI在消费级硬件上性能受系统瓶颈限制，而非计算能力。本文提出一种名为“两阶段自适应推理”的算法，通过低分辨率初筛和高分辨率精筛，在COCO数据集上实现了1.85倍的速度提升，mAP仅损失5.51%。


<details>
  <summary>Details</summary>
Motivation: 本地AI日益普及，但现有对象检测模型的基准性能与在消费级硬件上的实际可行性之间存在显著差距。

Method: 提出了一种名为“两阶段自适应推理”的算法，这是一种模型无关的方法，无需架构更改。该算法使用快速、低分辨率的推理，仅在检测置信度低时才升级到高分辨率模型。对架构早期退出和分辨率自适应路由进行了比较分析。

Result: 在COCO数据集上，与PyTorch早期退出基线相比，该方法实现了1.85倍的速度提升，同时mAP仅损失5.51%。

Conclusion: 该研究为在消费级设备上部署高性能、实时的AI提供了一个实用且可复现的蓝图，将重点从纯粹的模型优化转移到硬件感知的推理策略，以最大限度地提高吞吐量。

Abstract: As local AI grows in popularity, there is a critical gap between the
benchmark performance of object detectors and their practical viability on
consumer-grade hardware. While models like YOLOv10s promise real-time speeds,
these metrics are typically achieved on high-power, desktop-class GPUs. This
paper reveals that on resource-constrained systems, such as laptops with RTX
4060 GPUs, performance is not compute-bound but is instead dominated by
system-level bottlenecks, as illustrated by a simple bottleneck test. To
overcome this hardware-level constraint, we introduce a Two-Pass Adaptive
Inference algorithm, a model-independent approach that requires no
architectural changes. This study mainly focuses on adaptive inference
strategies and undertakes a comparative analysis of architectural early-exit
and resolution-adaptive routing, highlighting their respective trade-offs
within a unified evaluation framework. The system uses a fast, low-resolution
pass and only escalates to a high-resolution model pass when detection
confidence is low. On a 5000-image COCO dataset, our method achieves a 1.85x
speedup over a PyTorch Early-Exit baseline, with a modest mAP loss of 5.51%.
This work provides a practical and reproducible blueprint for deploying
high-performance, real-time AI on consumer-grade devices by shifting the focus
from pure model optimization to hardware-aware inference strategies that
maximize throughput.

</details>


### [72] [Dynamic Scene 3D Reconstruction of an Uncooperative Resident Space Object](https://arxiv.org/abs/2509.07932)
*Bala Prenith Reddy Gopu,Timothy Jacob Huber,George M. Nehma,Patrick Quinn,Madhur Tiwari,Matt Ueckermann,David Hinckley,Christopher McKenna*

Main category: cs.CV

TL;DR: 本研究评估了现有3D重建算法在动态场景（例如，翻滚的非合作空间目标）中的性能，以支持在轨服务和空间碎片清除任务。


<details>
  <summary>Details</summary>
Motivation: 为了在轨服务和空间碎片清除任务中对非合作空间目标进行几何和运动特性评估，需要对其进行表征。本研究旨在评估现有3D重建算法在重建翻滚非合作目标方面的性能。

Method: 利用Isaac Sim开发了一个仿真环境，生成了在真实轨道光照条件下翻滚卫星的物理精确2D图像序列。然后，使用Neuralangelo算法对这些图像序列进行3D重建，并使用Cloud Compare（CC）将重建的3D网格与原始CAD模型进行比较。

Result: 在静态场景的初步结果表明，Neuralangelo算法具有良好的重建质量，生成的3D网格与原始CAD模型高度吻合，误差和伪影极小。重建的模型能够捕获任务规划的关键细节。

Conclusion: 所提出的仿真和评估方法为动态场景重建提供了一个基线，为未来在轨服务和空间碎片清除任务中对非合作空间目标的精确3D重建奠定了基础。

Abstract: Characterization of uncooperative Resident Space Objects (RSO) play a crucial
role in On-Orbit Servicing (OOS) and Active Debris Removal (ADR) missions to
assess the geometry and motion properties. To address the challenges of
reconstructing tumbling uncooperative targets, this study evaluates the
performance of existing state-of-the-art 3D reconstruction algorithms for
dynamic scenes, focusing on their ability to generate geometrically accurate
models with high-fidelity. To support our evaluation, we developed a simulation
environment using Isaac Sim to generate physics-accurate 2D image sequences of
tumbling satellite under realistic orbital lighting conditions. Our preliminary
results on static scenes using Neuralangelo demonstrate promising
reconstruction quality. The generated 3D meshes closely match the original CAD
models with minimal errors and artifacts when compared using Cloud Compare
(CC). The reconstructed models were able to capture critical fine details for
mission planning. This provides a baseline for our ongoing evaluation of
dynamic scene reconstruction.

</details>


### [73] [Feature Space Analysis by Guided Diffusion Model](https://arxiv.org/abs/2509.07936)
*Kimiaki Shirahama,Miki Yanobu,Kaduki Yamashita,Miho Ohsaki*

Main category: cs.CV

TL;DR: 本文提出了一种解码器，可以生成与用户指定的特征紧密匹配的图像，从而解决了深度神经网络（DNN）的黑盒性质问题，尤其是在视觉领域。该解码器可用于分析DNN的特征空间，识别图像中被编码的各种属性。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络（DNN）的黑盒性质问题，特别是分析其内部特征提取过程，以理解DNN如何编码图像信息。

Method: 实现了一个引导扩散模型作为解码器，该模型通过引导预训练扩散模型的反向图像生成过程，最小化每个步骤中干净图像的特征与用户指定特征之间的欧氏距离。

Result: 实验结果表明，该解码器生成的图像特征与用户指定的特征高度相似，并揭示了CLIP图像编码器、ResNet-50和视觉Transformer等DNN的特征空间中的宝贵见解。

Conclusion: 该解码器能够有效地分析不同DNN的特征空间，无需额外训练，并且可以在普通的商用GPU上运行，为理解DNN的内部工作机制提供了实用工具。

Abstract: One of the key issues in Deep Neural Networks (DNNs) is the black-box nature
of their internal feature extraction process. Targeting vision-related domains,
this paper focuses on analysing the feature space of a DNN by proposing a
decoder that can generate images whose features are guaranteed to closely match
a user-specified feature. Owing to this guarantee that is missed in past
studies, our decoder allows us to evidence which of various attributes in an
image are encoded into a feature by the DNN, by generating images whose
features are in proximity to that feature. Our decoder is implemented as a
guided diffusion model that guides the reverse image generation of a
pre-trained diffusion model to minimise the Euclidean distance between the
feature of a clean image estimated at each step and the user-specified feature.
One practical advantage of our decoder is that it can analyse feature spaces of
different DNNs with no additional training and run on a single COTS GPU. The
experimental results targeting CLIP's image encoder, ResNet-50 and vision
transformer demonstrate that images generated by our decoder have features
remarkably similar to the user-specified ones and reveal valuable insights into
these DNNs' feature spaces.

</details>


### [74] [One View, Many Worlds: Single-Image to 3D Object Meets Generative Domain Randomization for One-Shot 6D Pose Estimation](https://arxiv.org/abs/2509.07978)
*Zheng Geng,Nan Wang,Shaocong Xu,Chongjie Ye,Bohan Li,Zhaoxi Chen,Sida Peng,Hao Zhao*

Main category: cs.CV

TL;DR: 提出了一种名为OnePoseViaGen的流水线，通过结合多视图特征匹配和渲染-比较精炼来联合优化尺度和姿态，并使用文本引导的生成域随机化策略来丰富合成数据的纹理，从而在没有3D模型的情况下，从单个参考图像估计出任意未见物体的6D姿态。


<details>
  <summary>Details</summary>
Motivation: 为解决机器人长尾场景中，从单个参考图像估计任意未见物体6D姿态的挑战，特别是3D模型稀缺、单视图重建缺乏尺度信息以及域间隙问题。

Method: 提出OnePoseViaGen流水线，包括：1）粗到精对齐模块，结合多视图特征匹配和渲染-比较精炼，联合优化尺度和姿态。2）文本引导的生成域随机化策略，通过多样化纹理，用合成数据有效微调姿态估计器。

Result: 在YCBInEOAT、Toyota-Light、LM-O等具有挑战性的基准测试中，OnePoseViaGen取得了最先进的性能，显著优于先前的方法。在真实的机器人手上进行了稳健的灵巧抓取演示，验证了该方法在实际操作中的实用性。

Conclusion: OnePoseViaGen通过有效的姿态估计和高保真度的单视图3D生成，解决了在没有3D模型的情况下进行6D姿态估计的挑战，并在真实机器人操作中得到了验证。

Abstract: Estimating the 6D pose of arbitrary unseen objects from a single reference
image is critical for robotics operating in the long-tail of real-world
instances. However, this setting is notoriously challenging: 3D models are
rarely available, single-view reconstructions lack metric scale, and domain
gaps between generated models and real-world images undermine robustness. We
propose OnePoseViaGen, a pipeline that tackles these challenges through two key
components. First, a coarse-to-fine alignment module jointly refines scale and
pose by combining multi-view feature matching with render-and-compare
refinement. Second, a text-guided generative domain randomization strategy
diversifies textures, enabling effective fine-tuning of pose estimators with
synthetic data. Together, these steps allow high-fidelity single-view 3D
generation to support reliable one-shot 6D pose estimation. On challenging
benchmarks (YCBInEOAT, Toyota-Light, LM-O), OnePoseViaGen achieves
state-of-the-art performance far surpassing prior approaches. We further
demonstrate robust dexterous grasping with a real robot hand, validating the
practicality of our method in real-world manipulation. Project page:
https://gzwsama.github.io/OnePoseviaGen.github.io/

</details>


### [75] [Visual Representation Alignment for Multimodal Large Language Models](https://arxiv.org/abs/2509.07979)
*Heeji Yoon,Jaewoo Jung,Junwan Kim,Hyungyu Choi,Heeseong Shin,Sangbeom Lim,Honggyu An,Chaehyun Kim,Jisang Han,Donghyun Kim,Chanho Eom,Sunghwan Hong,Seungryong Kim*

Main category: cs.CV

TL;DR: MLLMs 在视觉指令微调方面表现出色，但在物体计数或空间推理等以视觉为中心的任务中存在不足，原因在于纯文本监督范式。为解决此问题，我们提出了 VIRAL，一种通过对齐 MLLMs 与预训练 VFMs 的内部视觉表征来保留关键视觉细节并补充 VFM 视觉知识的正则化策略。实验证明 VIRAL 在各项任务上均有提升，并进行了消融研究以验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的 MLLMs 在以视觉为中心的任务（如物体计数、空间推理）上表现不佳，原因在于其依赖的纯文本监督范式仅提供间接的视觉指导，并可能导致 MLLMs 在训练过程中丢失精细的视觉细节。

Method: 提出了一种名为 VIRAL（VIsual Representation ALignment）的正则化策略。该策略通过显式地对齐 MLLMs 的内部视觉表征与预训练视觉基础模型（VFMs）的表征来实现。

Result: VIRAL 策略在多个广泛采用的多模态基准测试中的所有任务上均取得了持续的改进。此外，通过全面的消融研究验证了该框架关键设计的有效性。

Conclusion: VIRAL 策略通过对齐 MLLMs 和 VFMs 的内部视觉表征，有效解决了 MLLMs 在视觉任务中的不足，提升了模型处理复杂视觉输入的能力，并为 MLLMs 的视觉信息整合开辟了新的方向。

Abstract: Multimodal large language models (MLLMs) trained with visual instruction
tuning have achieved strong performance across diverse tasks, yet they remain
limited in vision-centric tasks such as object counting or spatial reasoning.
We attribute this gap to the prevailing text-only supervision paradigm, which
provides only indirect guidance for the visual pathway and often leads MLLMs to
discard fine-grained visual details during training. In this paper, we present
VIsual Representation ALignment (VIRAL), a simple yet effective regularization
strategy that aligns the internal visual representations of MLLMs with those of
pre-trained vision foundation models (VFMs). By explicitly enforcing this
alignment, VIRAL enables the model not only to retain critical visual details
from the input vision encoder but also to complement additional visual
knowledge from VFMs, thereby enhancing its ability to reason over complex
visual inputs. Our experiments demonstrate consistent improvements across all
tasks on widely adopted multimodal benchmarks. Furthermore, we conduct
comprehensive ablation studies to validate the key design choices underlying
our framework. We believe this simple finding opens up an important direction
for the effective integration of visual information in training MLLMs.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [76] [MedBench-IT: A Comprehensive Benchmark for Evaluating Large Language Models on Italian Medical Entrance Examinations](https://arxiv.org/abs/2509.07135)
*Ruggero Marino Lazzaroni,Alessandro Angioi,Michelangelo Puliga,Davide Sanna,Roberto Marras*

Main category: cs.CL

TL;DR: LLMs在意大利医学入学考试中的表现需要一个专门的基准，MedBench-IT为此提供了17,410个问题，涵盖六个学科和三个难度级别。该基准还包括对模型准确性、可复现性、偏见和可读性的评估。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏针对非英语国家特定领域（如意大利医学大学入学考试）的大型语言模型（LLM）评估基准。

Method: 创建了一个名为MedBench-IT的基准，其中包含17,410个专家编写的多项选择题，涵盖生物、化学、逻辑、综合文化、数学和物理六个学科，并分为三个难度级别。对包括GPT-4o、Claude系列以及参数量小于300亿的开源模型在内的多种模型进行了评估，重点关注实际部署能力。此外，还进行了可复现性测试、顺序偏倚分析以及推理提示评估，并研究了问题可读性与模型性能之间的相关性。

Result: 在准确性方面，对多种模型进行了评估。可复现性测试显示，在不同学科下，响应一致性达到88.86%。顺序偏倚分析表明其影响很小。问题可读性与模型性能之间存在统计学上显著但微弱的负相关关系。

Conclusion: MedBench-IT是意大利NLP社区、教育科技开发者和从业者的宝贵资源，它填补了意大利医学领域LLM评估的空白，并提供了一种标准化的评估方法，有助于了解当前LLM在该领域的能力。

Abstract: Large language models (LLMs) show increasing potential in education, yet
benchmarks for non-English languages in specialized domains remain scarce. We
introduce MedBench-IT, the first comprehensive benchmark for evaluating LLMs on
Italian medical university entrance examinations. Sourced from Edizioni Simone,
a leading preparatory materials publisher, MedBench-IT comprises 17,410
expert-written multiple-choice questions across six subjects (Biology,
Chemistry, Logic, General Culture, Mathematics, Physics) and three difficulty
levels. We evaluated diverse models including proprietary LLMs (GPT-4o, Claude
series) and resource-efficient open-source alternatives (<30B parameters)
focusing on practical deployability.
  Beyond accuracy, we conducted rigorous reproducibility tests (88.86% response
consistency, varying by subject), ordering bias analysis (minimal impact), and
reasoning prompt evaluation. We also examined correlations between question
readability and model performance, finding a statistically significant but
small inverse relationship. MedBench-IT provides a crucial resource for Italian
NLP community, EdTech developers, and practitioners, offering insights into
current capabilities and standardized evaluation methodology for this critical
domain.

</details>


### [77] [The ML-SUPERB 2.0 Challenge: Towards Inclusive ASR Benchmarking for All Language Varieties](https://arxiv.org/abs/2509.07139)
*William Chen,Chutong Meng,Jiatong Shi,Martijn Bartelds,Shih-Heng Wang,Hsiu-Hsuan Wang,Rafael Mosquera,Sara Hincapie,Dan Jurafsky,Antonis Anastasopoulos,Hung-yi Lee,Karen Livescu,Shinji Watanabe*

Main category: cs.CL

TL;DR: ML-SUPERB 2.0 挑战赛通过包含200多种语言、口音和方言的新测试套件，推动了多语言语音识别技术的发展，并设立了基于DynaBench的在线评估服务器，收到了3支队伍的5份参赛作品，均优于基线模型，最佳模型在通用多语言测试集上实现了LID准确率23%的绝对提升和18%的CER降低，在口音和方言数据上，最佳模型将CER降低了30.2%，LID准确率提高了15.7%，证明了社区挑战赛在推动语音技术包容性方面的重要性。


<details>
  <summary>Details</summary>
Motivation: 近期的多语言自动语音识别（ASR）技术在不同语言和口音上的进展并不均衡，需要新的评估方法来推动技术发展。

Method: 构建了一个包含200多种语言、口音和方言的新测试套件，并基于DynaBench设立了一个在线评估服务器，允许参赛者灵活选择模型设计和架构。

Result: 收到了3支队伍的5份参赛作品，所有作品均优于基线模型。最佳参赛模型在通用多语言测试集上，LID准确率提升了23%，CER降低了18%；在口音和方言数据上，CER降低了30.2%，LID准确率提高了15.7%。

Conclusion: ML-SUPERB 2.0 挑战赛成功地展示了社区驱动的评估方法在推动多语言ASR技术发展和提高包容性方面的有效性。

Abstract: Recent improvements in multilingual ASR have not been equally distributed
across languages and language varieties. To advance state-of-the-art (SOTA) ASR
models, we present the Interspeech 2025 ML-SUPERB 2.0 Challenge. We construct a
new test suite that consists of data from 200+ languages, accents, and dialects
to evaluate SOTA multilingual speech models. The challenge also introduces an
online evaluation server based on DynaBench, allowing for flexibility in model
design and architecture for participants. The challenge received 5 submissions
from 3 teams, all of which outperformed our baselines. The best-performing
submission achieved an absolute improvement in LID accuracy of 23% and a
reduction in CER of 18% when compared to the best baseline on a general
multilingual test set. On accented and dialectal data, the best submission
obtained 30.2% lower CER and 15.7% higher LID accuracy, showing the importance
of community challenges in making speech technologies more inclusive.

</details>


### [78] [Toward Purpose-oriented Topic Model Evaluation enabled by Large Language Models](https://arxiv.org/abs/2509.07142)
*Zhiyin Tan,Jennifer D'Souza*

Main category: cs.CL

TL;DR: 本研究提出了一个使用大语言模型（LLM）自动评估动态演化主题模型的框架。


<details>
  <summary>Details</summary>
Motivation: 传统的自动评估指标（如一致性和多样性）在解释语义失败方面存在不足，而主题模型对于组织和检索学术内容至关重要。

Method: 引入一个包含九个基于LLM的指标的评估框架，涵盖词汇有效性、主题内部语义健全性、主题间结构健全性以及文档-主题对齐健全性四个关键维度。

Result: LLM基准指标提供了可解释、鲁棒且与任务相关的评估，揭示了传统指标通常会遗漏的主题模型（如冗余和语义漂移）的关键弱点。

Conclusion: LLM基准指标有助于开发可扩展、细粒度的评估工具，以在动态数据集中维持主题相关性。

Abstract: This study presents a framework for automated evaluation of dynamically
evolving topic models using Large Language Models (LLMs). Topic modeling is
essential for organizing and retrieving scholarly content in digital library
systems, helping users navigate complex and evolving knowledge domains.
However, widely used automated metrics, such as coherence and diversity, often
capture only narrow statistical patterns and fail to explain semantic failures
in practice. We introduce a purpose-oriented evaluation framework that employs
nine LLM-based metrics spanning four key dimensions of topic quality: lexical
validity, intra-topic semantic soundness, inter-topic structural soundness, and
document-topic alignment soundness. The framework is validated through
adversarial and sampling-based protocols, and is applied across datasets
spanning news articles, scholarly publications, and social media posts, as well
as multiple topic modeling methods and open-source LLMs. Our analysis shows
that LLM-based metrics provide interpretable, robust, and task-relevant
assessments, uncovering critical weaknesses in topic models such as redundancy
and semantic drift, which are often missed by traditional metrics. These
results support the development of scalable, fine-grained evaluation tools for
maintaining topic relevance in dynamic datasets. All code and data supporting
this work are accessible at
https://github.com/zhiyintan/topic-model-LLMjudgment.

</details>


### [79] [Towards EnergyGPT: A Large Language Model Specialized for the Energy Sector](https://arxiv.org/abs/2509.07177)
*Amal Chebbi,Babajide Kolade*

Main category: cs.CL

TL;DR: EnergyGPT是一个针对能源领域的LLM，通过微调LLaMA 3.1-8B模型实现，并在能源相关任务上优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 通用大语言模型在能源等专业领域的表现受限于其缺乏领域知识，因此需要专门的模型。

Method: 使用监督微调（SFT）方法，在能源相关文本语料库上对LLaMA 3.1-8B模型进行微调，并构建了完整的数据收集、模型微调、基准测试、评估和部署流程。

Result: EnergyGPT在大多数能源相关的语言理解和生成任务上表现优于基础模型。

Conclusion: 通过对LLaMA 3.1-8B模型进行领域特定微调，可以有效提升其在能源领域的性能，且无需大规模基础设施。

Abstract: Large Language Models have demonstrated impressive capabilities across
various domains. However, their general-purpose nature often limits their
effectiveness in specialized fields such as energy, where deep technical
expertise and precise domain knowledge are essential. In this paper, we
introduce EnergyGPT, a domain-specialized language model tailored for the
energy sector, developed by fine-tuning LLaMA 3.1-8B model using Supervised
Fine-Tuning on a high-quality, curated corpus of energy-related texts. We
present a complete development pipeline, including data collection and
curation, model fine-tuning, benchmark design and LLM-judge choice, evaluation
and deployment. Through this work, we demonstrate that our training strategy
enables improvements in domain relevance and performance without the need for
large-scale infrastructure. By evaluating the performance of the model using
domain-specific question-answering benchmarks, our results demonstrate that
EnergyGPT outperforms the base model in most of the energy-related language
understanding and generation tasks.

</details>


### [80] [DischargeSim: A Simulation Benchmark for Educational Doctor-Patient Communication at Discharge](https://arxiv.org/abs/2509.07188)
*Zonghai Yao,Michael Sun,Won Seok Jang,Sunjae Kwon,Soie Kwon,Hong Yu*

Main category: cs.CL

TL;DR: DischargeSim是一个新的基准测试，用于评估LLM在患者出院后教育方面的能力，模拟了LLM驱动的DoctorAgents和具有不同心理社会特征的PatientAgents之间的多轮对话。


<details>
  <summary>Details</summary>
Motivation: 当前的LLM基准测试主要关注就诊期间的诊断推理，忽略了患者就诊后的支持能力，而这是患者护理的关键环节。

Method: DischargeSim模拟了LLM驱动的DoctorAgents和具有不同心理社会特征的PatientAgents之间的多轮对话，涵盖了六个临床出院主题。评估维度包括对话质量、个性化文档生成（自由文本摘要和AHRQ清单）以及患者理解度（通过下游多项选择题测试）。

Result: 在18个LLM上的实验显示，出院教育能力存在显著差异，并且在不同患者画像上的表现各异。模型规模并非总是带来更好的教育结果，凸显了策略使用和内容优先级的权衡。

Conclusion: DischargeSim是LLM在就诊后临床教育领域进行基准测试和促进公平、个性化患者支持的初步尝试。

Abstract: Discharge communication is a critical yet underexplored component of patient
care, where the goal shifts from diagnosis to education. While recent large
language model (LLM) benchmarks emphasize in-visit diagnostic reasoning, they
fail to evaluate models' ability to support patients after the visit. We
introduce DischargeSim, a novel benchmark that evaluates LLMs on their ability
to act as personalized discharge educators. DischargeSim simulates post-visit,
multi-turn conversations between LLM-driven DoctorAgents and PatientAgents with
diverse psychosocial profiles (e.g., health literacy, education, emotion).
Interactions are structured across six clinically grounded discharge topics and
assessed along three axes: (1) dialogue quality via automatic and LLM-as-judge
evaluation, (2) personalized document generation including free-text summaries
and structured AHRQ checklists, and (3) patient comprehension through a
downstream multiple-choice exam. Experiments across 18 LLMs reveal significant
gaps in discharge education capability, with performance varying widely across
patient profiles. Notably, model size does not always yield better education
outcomes, highlighting trade-offs in strategy use and content prioritization.
DischargeSim offers a first step toward benchmarking LLMs in post-visit
clinical education and promoting equitable, personalized patient support.

</details>


### [81] [Rule-Based Moral Principles for Explaining Uncertainty in Natural Language Generation](https://arxiv.org/abs/2509.07190)
*Zahra Atf,Peter R Lewis*

Main category: cs.CL

TL;DR: LLMs在生成文本时，利用基于规则的道德原则来处理不确定性，提供了一种比概率方法更透明、更轻量级的选择。


<details>
  <summary>Details</summary>
Motivation: 解释LLM生成文本中的不确定性具有技术和伦理挑战，而现有的概率方法往往不透明且不符合对透明度的期望。

Method: 提出一个基于规则的道德原则框架来处理LLM中的不确定性。该框架利用道德心理学和美德伦理学的见解，定义了谨慎、尊重和责任等规则，并使用轻量级的Prolog引擎进行编码，以根据不确定性级别触发相应的系统操作和提供通俗的解释。

Result: 通过基于场景的模拟，对规则覆盖、公平性和信任校准进行了基准测试，并在临床和法律领域展示了用例，证明了该方法在提高信任度和可解释性方面的有效性。

Conclusion: 所提出的方法为在自然语言生成中负责任地处理不确定性提供了一种透明、轻量级的替代概率模型的方法。

Abstract: Large language models (LLMs) are increasingly used in high-stakes settings,
where explaining uncertainty is both technical and ethical. Probabilistic
methods are often opaque and misaligned with expectations of transparency. We
propose a framework based on rule-based moral principles for handling
uncertainty in LLM-generated text. Using insights from moral psychology and
virtue ethics, we define rules such as precaution, deference, and
responsibility to guide responses under epistemic or aleatoric uncertainty.
These rules are encoded in a lightweight Prolog engine, where uncertainty
levels (low, medium, high) trigger aligned system actions with plain-language
rationales. Scenario-based simulations benchmark rule coverage, fairness, and
trust calibration. Use cases in clinical and legal domains illustrate how moral
reasoning can improve trust and interpretability. Our approach offers a
transparent, lightweight alternative to probabilistic models for socially
responsible natural language generation.

</details>


### [82] [LLM Analysis of 150+ years of German Parliamentary Debates on Migration Reveals Shift from Post-War Solidarity to Anti-Solidarity in the Last Decade](https://arxiv.org/abs/2509.07274)
*Aida Kostikova,Ole Pütz,Steffen Eger,Olga Sabelfeld,Benjamin Paassen*

Main category: cs.CL

TL;DR: 本研究评估了大型语言模型（LLMs）在标注德国议会辩论中（反）团结类型方面的能力，并将其与人类标注进行了比较。研究结果表明，自2015年以来，德国议会中针对移民的（反）团结趋势发生了显著变化。


<details>
  <summary>Details</summary>
Motivation: 为了更深入地研究德国政治辩论中关于移民的言论，传统的手动标注方法在效率和规模上存在局限。本研究旨在利用大型语言模型（LLMs）来自动化这一标注过程，从而扩大分析范围。

Method: 本研究评估了多种大型语言模型（LLMs）在标注德国议会辩论中（反）团结子类型方面的表现，并将其与大量人类参考标注进行了比较。研究中还评估了模型大小、提示差异、微调、历史与当代数据的影响，并调查了系统性错误。

Result: 研究结果显示，在二战后的时期，德国议会中存在高度针对移民的团结言论。然而，自2015年以来，德国议会中针对移民的反团结趋势显著增强。LLMs在政治文本分析方面显示出巨大潜力。

Conclusion: 本研究强调了大型语言模型（LLMs）在政治文本分析方面的潜力，并指出了德国移民辩论的重要性。研究结果揭示了二战后德国议会中存在高度的移民团结，以及自2015年以来反团结趋势的增强，这表明了进一步研究的必要性。

Abstract: Migration has been a core topic in German political debate, from millions of
expellees post World War II over labor migration to refugee movements in the
recent past. Studying political speech regarding such wide-ranging phenomena in
depth traditionally required extensive manual annotations, limiting the scope
of analysis to small subsets of the data. Large language models (LLMs) have the
potential to partially automate even complex annotation tasks. We provide an
extensive evaluation of a multiple LLMs in annotating (anti-)solidarity
subtypes in German parliamentary debates compared to a large set of thousands
of human reference annotations (gathered over a year). We evaluate the
influence of model size, prompting differences, fine-tuning, historical versus
contemporary data; and we investigate systematic errors. Beyond methodological
evaluation, we also interpret the resulting annotations from a social science
lense, gaining deeper insight into (anti-)solidarity trends towards migrants in
the German post-World War II period and recent past. Our data reveals a high
degree of migrant-directed solidarity in the postwar period, as well as a
strong trend towards anti-solidarity in the German parliament since 2015,
motivating further research. These findings highlight the promise of LLMs for
political text analysis and the importance of migration debates in Germany,
where demographic decline and labor shortages coexist with rising polarization.

</details>


### [83] [Causal Attention with Lookahead Keys](https://arxiv.org/abs/2509.07301)
*Zhuoqing Song,Peng Sun,Huizhuo Yuan,Quanquan Gu*

Main category: cs.CL

TL;DR: CASTLE是一种新颖的注意力机制，通过不断更新键（key）来整合后续信息，同时保持自回归性质，并在语言模型基准测试中优于标准因果注意力。


<details>
  <summary>Details</summary>
Motivation: 标准因果注意力机制的QKV是静态的，只编码先前的上下文。然而，在某些场景下，需要一种能够整合后续信息的注意力机制，同时严格保持自回归性质。

Method: CASTLE通过不断更新每个token的key来整合后续信息，这些更新后的key被称为前瞻key。尽管机制看起来是顺序的，但通过数学推导，可以避免在每个位置显式地具体化前瞻key，从而实现高效的并行训练。

Result: 在语言模型基准测试中，CASTLE在各个模型规模上持续优于标准因果注意力，在验证困惑度方面有所降低，并在各种下游任务上有所改进。

Conclusion: CASTLE是一种高效且有效的注意力机制，能够超越标准因果注意力的性能，为语言模型带来了显著的改进。

Abstract: In standard causal attention, each token's query, key, and value (QKV) are
static and encode only preceding context. We introduce CAuSal aTtention with
Lookahead kEys (CASTLE), an attention mechanism that continually updates each
token's keys as the context unfolds. We term these updated keys lookahead keys
because they belong to earlier positions yet integrate information from tokens
that appear later relative to those positions, while strictly preserving the
autoregressive property. Although the mechanism appears sequential, we derive a
mathematical equivalence that avoids explicitly materializing lookahead keys at
each position and enables efficient parallel training. On language modeling
benchmarks, CASTLE consistently outperforms standard causal attention across
model scales, reducing validation perplexity and improving performance on a
range of downstream tasks.

</details>


### [84] [Basis Vector Metric: A Method for Robust Open-Ended State Change Detection](https://arxiv.org/abs/2509.07308)
*David Oprea,Sam Powers*

Main category: cs.CL

TL;DR: BVM方法在判断图像状态变化方面表现出色，在识别名词状态时优于其他方法，但在区分形容词方面与逻辑回归模型相当，仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 评估BVM（Basis Vectors Method）通过语言嵌入判断图像状态变化的能力。

Method: 使用MIT-States数据集（包含53,000张图像，225个名词，115个形容词）进行两项实验。实验一：将BVM与余弦相似度、点积、积量化、二进制索引、朴素贝叶斯和自定义神经网络进行比较，以评估其在区分名词状态方面的能力。实验二：将BVM与MIT-States论文提出的逻辑回归模型进行比较，以评估其在区分形容词方面的能力。

Result: 在实验一中，BVM在区分名词状态方面表现最佳。在实验二中，BVM在区分形容词方面的表现与逻辑回归模型相当，未发现显著优势。

Conclusion: BVM在区分名词状态方面是一种有效的方法。虽然在区分形容词方面未优于现有模型，但有改进和提高准确性的潜力。

Abstract: We test a new method, which we will abbreviate using the acronym BVM (Basis
Vectors Method), in its ability to judge the state changes in images through
using language embeddings. We used the MIT-States dataset, containing about
53,000 images, to gather all of our data, which has 225 nouns and 115
adjectives, with each noun having about 9 different adjectives, forming
approximately 1000 noun-adjective pairs. For our first experiment, we test our
method's ability to determine the state of each noun class separately against
other metrics for comparison. These metrics are cosine similarity, dot product,
product quantization, binary index, Naive Bayes, and a custom neural network.
Among these metrics, we found that our proposed BVM performs the best in
classifying the states for each noun. We then perform a second experiment where
we try using BVM to determine if it can differentiate adjectives from one
another for each adjective separately. We compared the abilities of BVM to
differentiate adjectives against the proposed method the MIT-States paper
suggests: using a logistic regression model. In the end, we did not find
conclusive evidence that our BVM metric could perform better than the logistic
regression model at discerning adjectives. Yet, we were able to find evidence
for possible improvements to our method; this leads to the chance of increasing
our method's accuracy through certain changes in our methodologies.

</details>


### [85] [Instance-level Performance Prediction for Long-form Generation Tasks](https://arxiv.org/abs/2509.07309)
*Chi-Yang Hsu,Alexander Braylan,Yiheng Su,Omar Alonso,Matthew Lease*

Main category: cs.CL

TL;DR: 该研究提出了一个用于长文本生成任务的实例级性能预测新基准，该基准具有多方面、细粒度的质量指标。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法在长文本生成任务上存在不足，需要更细粒度的性能预测方法。

Method: 提出了一种任务无关、模型无关、指标无关的框架，仅依赖于模型的黑盒输入和输出来预测连续的评估指标分数，并包含预测区间以量化不确定性。

Result: 在11个长文本数据集/任务上进行了评估，涉及多个LLM、基线和指标，结果表明仅使用16个训练样本即可有效预测分数。

Conclusion: 引入了一个新颖实用的任务、一个有价值的基准以及可供实际应用的基线。

Abstract: We motivate and share a new benchmark for instance-level performance
prediction of long-form generation tasks having multi-faceted, fine-grained
quality metrics. Our task-, model- and metric-agnostic formulation predicts
continuous evaluation metric scores given only black-box model inputs and
outputs. Beyond predicting point estimates of metric scores, the benchmark also
requires inferring prediction intervals to quantify uncertainty around point
estimates. Evaluation spans 11 long-form datasets/tasks with multiple LLMs,
baselines, and metrics per task. We show that scores can be effectively
predicted across long-form generation tasks using as few as 16 training
examples. Overall, we introduce a novel and useful task, a valuable benchmark
to drive progress, and baselines ready for practical adoption today.

</details>


### [86] [Does This Look Familiar to You? Knowledge Analysis via Model Internal Representations](https://arxiv.org/abs/2509.07311)
*Sihyun Park*

Main category: cs.CL

TL;DR: KAMIR是一种新的数据选择方法，通过分析模型的内部表征来评估训练数据，优于传统的基于提示的方法，并在各种任务上提高了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 监督微调（SFT）在将LLM的通用知识转化为特定任务的结构化响应方面起着至关重要的作用，但目前缺乏有效的数据选择方法，导致数据量增加不一定能提高性能，而数据预处理、采样和验证成本高昂。

Method: 提出了一种名为KAMIR的新方法，该方法通过计算模型每一层（块）的隐藏状态与给定输入的最终隐藏状态之间的相似性来分析数据。KAMIR利用模型对输入的熟悉度来选择有用的训练数据，并且可以应用于多种任务，如机器阅读理解和摘要。

Result: 实验表明，使用KAMIR选择的、模型不太熟悉的训练数据，可以获得更好的泛化性能，即使在小数据集和简单的分类器架构下也是如此。

Conclusion: KAMIR是一种有效且通用的数据选择方法，能够通过分析模型的内部表征来识别最有用的训练数据，从而提高LLM在各种任务上的泛化能力。

Abstract: Recent advances in large language models (LLMs) have been driven by
pretraining, supervised fine tuning (SFT), and alignment tuning. Among these,
SFT plays a crucial role in transforming a model 's general knowledge into
structured responses tailored to specific tasks. However, there is no clearly
established methodology for effective training data selection. Simply
increasing the volume of data does not guarantee performance improvements,
while preprocessing, sampling, and validation require substantial time and
cost.
  To address this issue, a variety of data selection methods have been
proposed. Among them, knowledge based selection approaches identify suitable
training data by analyzing the model 's responses. Nevertheless, these methods
typically rely on prompt engineering, making them sensitive to variations and
incurring additional costs for prompt design.
  In this study, we propose Knowledge Analysis via Model Internal
Representations (KAMIR), a novel approach that overcomes these limitations by
analyzing data based on the model 's internal representations. KAMIR computes
similarities between the hidden states of each layer (block) and the final
hidden states for a given input to assess the data. Unlike prior methods that
were largely limited to multiple choice tasks, KAMIR can be applied to a wide
range of tasks such as machine reading comprehension and summarization.
Moreover, it selects data useful for training based on the model 's familiarity
with the input, even with a small dataset and a simple classifier architecture.
Experiments across diverse task datasets demonstrate that training with less
familiar data leads to better generalization performance.

</details>


### [87] [Mitigating Attention Localization in Small Scale: Self-Attention Refinement via One-step Belief Propagation](https://arxiv.org/abs/2509.07324)
*Nakyung Lee,Yeongoon Kim,Minhae Oh,Suhwan Kim,Jin Woo Koo,Hyewon Jo,Jungwoo Lee*

Main category: cs.CL

TL;DR: SAOBP通过引入多跳关系来解决Transformer自注意力机制的局限性，提升了模型性能，尤其是在资源受限的情况下。


<details>
  <summary>Details</summary>
Motivation: Transformer-based self-attention机制存在注意力局限于有限的token，导致无法捕捉长距离依赖的问题。

Method: 提出SAOBP（Self-Attention One-step Belief Propagation）框架，通过信念传播过程注入多跳关系，并引入GTD（Global Token Dependency）量化多跳连接的贡献。

Result: SAOBP能防止深层网络的熵崩溃，并自适应地维持GTD在任务适宜的水平，从而提升模型性能，在小规模模型上也有显著效果。

Conclusion: SAOBP是一种有效的Transformer自注意力机制的改进框架，能够提升模型性能，尤其是在资源受限的情况下。

Abstract: Transformer-based self-attention mechanism serves as the core of modern
language models, yet it often suffers from localization, where attentions
collapse onto a limited subset of tokens and fail to capture long-range
dependencies. To address this issue, we propose Self-Attention One-step Belief
Propagation (SAOBP), a refinement framework that injects multi-hop
relationships through a belief propagation process. To interpret and quantify
these interactions, we introduce Global Token Dependency (GTD) that captures
the relative contribution of multihop connections within the attention graph.
Empirical results indicate that SAOBP helps prevent entropy collapse in deeper
layers and adaptively maintains GTD at task-appropriate levels, thereby
supporting improvements in model performance. Importantly, we observe
competitive gains in small-scale models, highlighting its potential for
improving inference quality in resource-constrained scenarios.

</details>


### [88] [PersonaFuse: A Personality Activation-Driven Framework for Enhancing Human-LLM Interactions](https://arxiv.org/abs/2509.07370)
*Yixuan Tang,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

TL;DR: PersonaFuse是一个新颖的LLM后训练框架，通过结合个性化适配器和动态路由网络，使LLM能够适应不同情境并表达不同个性，从而在社交情感智能方面取得显著进步，并且不牺牲通用推理能力或模型安全性，在以人为中心的AI系统发展方面迈出了重要一步。


<details>
  <summary>Details</summary>
Motivation: LLM在现实世界的对话中，特别是在社交和情感理解方面存在局限性，难以根据不同的社交和任务情境调整其沟通风格和情感表达。这促使研究者探索如何增强LLM的社交情感能力。

Method: PersonaFuse框架受到特质激活理论和“大五”人格模型的启发，采用混合专家（Mixture-of-Expert）架构，结合了个性化适配器（persona adapters）和一个动态路由网络（dynamic routing network），以实现情境化的特质表达。

Result: 实验结果表明，PersonaFuse在社交情感智能的多个维度上显著优于基线模型，同时保持了通用推理能力和模型安全性。此外，PersonaFuse在心理健康咨询和基于评论的客户服务等下游应用中也表现出一致的改进。与GPT-4o和DeepSeek等领先LLM相比，PersonaFuse在模型规模相对较小的情况下，取得了具有竞争力的响应质量。

Conclusion: PersonaFuse提供了一种有理论依据且实用的方法，用于开发增强社交情感能力的LLM，朝着更加以人为中心的AI系统迈出了重要一步。

Abstract: Recent advancements in Large Language Models (LLMs) demonstrate remarkable
capabilities across various fields. These developments have led to more direct
communication between humans and LLMs in various situations, such as social
companionship and psychological support. However, LLMs often exhibit
limitations in emotional perception and social competence during real-world
conversations. These limitations partly originate from their inability to adapt
their communication style and emotional expression to different social and task
contexts. In this work, we introduce PersonaFuse, a novel LLM post-training
framework that enables LLMs to adapt and express different personalities for
varying situations. Inspired by Trait Activation Theory and the Big Five
personality model, PersonaFuse employs a Mixture-of-Expert architecture that
combines persona adapters with a dynamic routing network, enabling contextual
trait expression. Experimental results show that PersonaFuse substantially
outperforms baseline models across multiple dimensions of social-emotional
intelligence. Importantly, these gains are achieved without sacrificing general
reasoning ability or model safety, which remain common limitations of direct
prompting and supervised fine-tuning approaches. PersonaFuse also delivers
consistent improvements in downstream human-centered applications, such as
mental health counseling and review-based customer service. Finally, human
preference evaluations against leading LLMs, including GPT-4o and DeepSeek,
demonstrate that PersonaFuse achieves competitive response quality despite its
comparatively smaller model size. These findings demonstrate that
PersonaFuse~offers a theoretically grounded and practical approach for
developing social-emotional enhanced LLMs, marking a significant advancement
toward more human-centric AI systems.

</details>


### [89] [Talking with Oompa Loompas: A novel framework for evaluating linguistic acquisition of LLM agents](https://arxiv.org/abs/2509.07389)
*Sankalp Tattwadarshi Swain,Anshika Krishnatray,Dhruv Kumar,Jagat Sesh Challa*

Main category: cs.CL

TL;DR: LLM代理在与仅理解Tinkatongue的机器人进行对话时，未能习得新语言，但在学习过程中展现出类似人类的学习策略。


<details>
  <summary>Details</summary>
Motivation: 评估LLM代理通过模式识别和交互反馈学习语言的能力，这是人类习得语言的核心特征，而现有研究尚未涉及此方面。

Method: 提出一个新颖的实验框架，让LLM代理学习并使用一种新构造的语言（Tinkatongue），并与只理解Tinkatongue的机器人进行对话。

Result: LLM代理在100次响应内未能建立对话，但其学习策略却模仿了人类的学习方法。

Conclusion: LLM代理在交互式学习方面存在不足，但其学习策略为设计更有效的交互式反馈模型提供了新的方向，并为评估基准的开发开辟了新途径。

Abstract: Existing evaluation studies on linguistic competence of large language models
(LLM agents) have focused primarily on vocabulary learning, morphological rule
induction, syntactic generalization, pragmatic inference, and cross-linguistic
transfer. However, none assess whether LLM agents can acquire a language
through pattern recognition and interactive feedback, a central feature of
human language acquisition. We propose a novel experimental framework in which
an LLM agent is evaluated on its ability to acquire and use a newly constructed
language (Tinkatongue) in conversation with a bot that understands only
Tinkatongue. Our findings show that LLM agents fail to establish a conversation
within 100 responses, yet they adopt distinct strategies that mirror human
approaches to language learning. The results suggest a new direction for
evaluation benchmarks and open pathways to model designs that learn more
effectively from interactive feedback.

</details>


### [90] [The Role of Exploration Modules in Small Language Models for Knowledge Graph Question Answering](https://arxiv.org/abs/2509.07399)
*Yi-Jie Cheng,Oscar Chew,Yun-Nung Chen*

Main category: cs.CL

TL;DR: 通过引入轻量级知识图谱探索模块，提升小型语言模型在知识图谱问答任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的小型语言模型在知识图谱问答任务上表现不佳，主要是因为它们在知识图谱遍历和推理方面能力有限。

Method: 提出使用简单高效的探索模块来代替语言模型进行知识图谱遍历。

Result: 实验结果表明，这些轻量级模块能够有效提升小型语言模型在知识图谱问答任务上的性能。

Conclusion: 轻量级探索模块可以有效增强小型语言模型在知识图谱问答任务中的能力。

Abstract: Integrating knowledge graphs (KGs) into the reasoning processes of large
language models (LLMs) has emerged as a promising approach to mitigate
hallucination. However, existing work in this area often relies on proprietary
or extremely large models, limiting accessibility and scalability. In this
study, we investigate the capabilities of existing integration methods for
small language models (SLMs) in KG-based question answering and observe that
their performance is often constrained by their limited ability to traverse and
reason over knowledge graphs. To address this limitation, we propose leveraging
simple and efficient exploration modules to handle knowledge graph traversal in
place of the language model itself. Experiment results demonstrate that these
lightweight modules effectively improve the performance of small language
models on knowledge graph question answering tasks. Source code:
https://github.com/yijie-cheng/SLM-ToG/.

</details>


### [91] [LongEmotion: Measuring Emotional Intelligence of Large Language Models in Long-Context Interaction](https://arxiv.org/abs/2509.07403)
*Weichu Liu,Jing Xiong,Yuxuan Hu,Zixuan Li,Minghuan Tan,Ningning Mao,Chenyang Zhao,Zhongwei Wan,Chaofan Tao,Wendong Xu,Hui Shen,Chengming Li,Lingpeng Kong,Ngai Wong*

Main category: cs.CL

TL;DR: 该研究提出了LongEmotion基准，用于评估大型语言模型在长上下文情感智能任务中的表现，并引入了检索增强生成（RAG）和协同情感建模（CoEM）方法来提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分涵盖长上下文场景下的情感智能（EI）的各个方面，尤其是在真实、复杂、多样且嘈杂的交互环境中。因此，需要一个专门针对长上下文EI任务设计的基准。

Method: 设计并提出了LongEmotion基准，包含情感分类、情感检测、情感问答、情感对话、情感摘要和情感表达等任务，平均输入长度达8777个token。引入了检索增强生成（RAG）和协同情感建模（CoEM）方法，并与标准提示方法进行了比较。RAG方法利用对话上下文和大型语言模型本身作为检索源。CoEM方法将任务分解为五个阶段，并结合了检索增强和有限的知识注入。

Result: 实验结果表明，RAG和CoEM方法在大多数长上下文EI任务上均能持续提升模型表现。此外，还对GPT系列模型进行了案例研究，展示了它们在EI方面的差异。

Conclusion: LongEmotion基准和所提出的RAG、CoEM方法能够有效提升大型语言模型在长上下文情感智能任务中的表现，推动LLMs在更实际、更贴近现实世界的EI应用方面的发展。

Abstract: Large language models (LLMs) make significant progress in Emotional
Intelligence (EI) and long-context understanding. However, existing benchmarks
tend to overlook certain aspects of EI in long-context scenarios, especially
under realistic, practical settings where interactions are lengthy, diverse,
and often noisy. To move towards such realistic settings, we present
LongEmotion, a benchmark specifically designed for long-context EI tasks. It
covers a diverse set of tasks, including Emotion Classification, Emotion
Detection, Emotion QA, Emotion Conversation, Emotion Summary, and Emotion
Expression. On average, the input length for these tasks reaches 8,777 tokens,
with long-form generation required for Emotion Expression. To enhance
performance under realistic constraints, we incorporate Retrieval-Augmented
Generation (RAG) and Collaborative Emotional Modeling (CoEM), and compare them
with standard prompt-based methods. Unlike conventional approaches, our RAG
method leverages both the conversation context and the large language model
itself as retrieval sources, avoiding reliance on external knowledge bases. The
CoEM method further improves performance by decomposing the task into five
stages, integrating both retrieval augmentation and limited knowledge
injection. Experimental results show that both RAG and CoEM consistently
enhance EI-related performance across most long-context tasks, advancing LLMs
toward more practical and real-world EI applications. Furthermore, we conducted
a comparative case study experiment on the GPT series to demonstrate the
differences among various models in terms of EI. Code is available on GitHub at
https://github.com/LongEmotion/LongEmotion, and the project page can be found
at https://longemotion.github.io/.

</details>


### [92] [AIxcellent Vibes at GermEval 2025 Shared Task on Candy Speech Detection: Improving Model Performance by Span-Level Training](https://arxiv.org/abs/2509.07459)
*Christian Rene Thelen,Patrick Gustav Blaneck,Tobias Bornheim,Niklas Grieger,Stephan Bialonski*

Main category: cs.CL

TL;DR: 自动检测社交媒体中的积极支持性语言（糖果言论）仍有待探索，限制了对其影响的系统分析。本研究使用德语 YouTube 语料库，通过 GBERT、Qwen3 Embedding 和 XLM-RoBERTa 等模型，对糖果言论进行了可靠检测。实验证明，在 GermEval 2025 糖果言论检测共享任务中，经过跨语言 RoBERTa-Large 模型在词级别训练后，在二元分类 F1 分数（0.8906）和分类词级别检测（严格 F1：0.6307）子任务上均表现优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 自动检测社交媒体中的积极支持性语言（糖果言论）对于理解其影响至关重要，但目前的研究尚不充分。

Method: 使用 GBERT、Qwen3 Embedding 和 XLM-RoBERTa 等模型，在 46k 条德语 YouTube 评论语料库上进行糖果言论的检测。特别地，训练了一个跨语言 XLM-RoBERTa-Large 模型进行词级别（span level）的糖果言论检测。

Result: 跨语言 XLM-RoBERTa-Large 模型在词级别训练后，在 GermEval 2025 糖果言论检测共享任务的二元分类 F1 分数（0.8906）和分类词级别检测（严格 F1：0.6307）子任务上均取得了最佳性能。

Conclusion: 跨语言模型在识别积极支持性语言方面是有效的。词级别训练、跨语言能力和支持表情符号的标记器可能提高了检测性能。

Abstract: Positive, supportive online communication in social media (candy speech) has
the potential to foster civility, yet automated detection of such language
remains underexplored, limiting systematic analysis of its impact. We
investigate how candy speech can be reliably detected in a 46k-comment German
YouTube corpus by monolingual and multilingual language models, including
GBERT, Qwen3 Embedding, and XLM-RoBERTa. We find that a multilingual
XLM-RoBERTa-Large model trained to detect candy speech at the span level
outperforms other approaches, ranking first in both binary positive F1: 0.8906)
and categorized span-based detection (strict F1: 0.6307) subtasks at the
GermEval 2025 Shared Task on Candy Speech Detection. We speculate that
span-based training, multilingual capabilities, and emoji-aware tokenizers
improved detection performance. Our results demonstrate the effectiveness of
multilingual models in identifying positive, supportive language.

</details>


### [93] [Understanding Stigmatizing Language Lexicons: A Comparative Analysis in Clinical Contexts](https://arxiv.org/abs/2509.07462)
*Yiliang Zhou,Di Hu,Tianchu Lyu,Jasmine Dhillon,Alexandra L. Beck,Gelareh Sadigh,Kai Zheng*

Main category: cs.CL

TL;DR: 医疗保健领域缺乏标准化的污名化语言词汇，现有词汇间存在差异且多为负面评价。


<details>
  <summary>Details</summary>
Motivation: 为解决医疗保健领域污名化语言导致的不公平问题，本研究旨在识别和比较现有的污名化语言词汇，并分析其中词汇的情感倾向。

Method: 通过系统性文献检索找到现有的污名化语言词汇，并进行比较分析，包括词汇间的相似性和差异性，以及基于已建立的情感数据集对词汇进行正面、负面或中性分类。

Result: 共识别出四个污名化语言词汇。分析显示，这些词汇间存在中等的语义相似性，大部分污名化术语涉及临床医生对感知到的负面行为的评判性表达。情感分析表明，大部分术语被归类为负面，但各词汇间存在差异。

Conclusion: 研究结果强调了建立标准化词汇的必要性，并指出了在临床文本中定义污名化语言所面临的挑战。

Abstract: Stigmatizing language results in healthcare inequities, yet there is no
universally accepted or standardized lexicon defining which words, terms, or
phrases constitute stigmatizing language in healthcare. We conducted a
systematic search of the literature to identify existing stigmatizing language
lexicons and then analyzed them comparatively to examine: 1) similarities and
discrepancies between these lexicons, and 2) the distribution of positive,
negative, or neutral terms based on an established sentiment dataset. Our
search identified four lexicons. The analysis results revealed moderate
semantic similarity among them, and that most stigmatizing terms are related to
judgmental expressions by clinicians to describe perceived negative behaviors.
Sentiment analysis showed a predominant proportion of negatively classified
terms, though variations exist across lexicons. Our findings underscore the
need for a standardized lexicon and highlight challenges in defining
stigmatizing language in clinical texts.

</details>


### [94] [From Scarcity to Efficiency: Investigating the Effects of Data Augmentation on African Machine Translation](https://arxiv.org/abs/2509.07471)
*Mardiyyah Oduwole,Oluwatosin Olajide,Jamiu Suleiman,Faith Hunja,Busayo Awobade,Fatimo Adebanjo,Comfort Akanni,Chinonyelum Igwe,Peace Ododo,Promise Omoigui,Steven Kolawole,Abraham Owodunni*

Main category: cs.CL

TL;DR: 本研究探讨了数据增强技术在改善低资源非洲语言的机器翻译系统中的应用，实验表明句子连接和回译以及切换技术能显著提高翻译性能。


<details>
  <summary>Details</summary>
Motivation: 非洲大陆的语言多样性给机器翻译带来了挑战和机遇，本研究旨在提高低资源非洲语言的机器翻译系统性能。

Method: 应用句子连接与回译以及切换这两种数据增强技术，并将其应用于六种非洲语言的机器翻译系统。

Result: 在所有六种非洲语言中，机器翻译性能通过BLEU分数平均提升了至少25%。

Conclusion: 所使用的数据增强技术能够显著改善低资源语言的机器翻译系统，为开发更强大的翻译系统做出了贡献。

Abstract: The linguistic diversity across the African continent presents different
challenges and opportunities for machine translation. This study explores the
effects of data augmentation techniques in improving translation systems in
low-resource African languages. We focus on two data augmentation techniques:
sentence concatenation with back translation and switch-out, applying them
across six African languages. Our experiments show significant improvements in
machine translation performance, with a minimum increase of 25\% in BLEU score
across all six languages.We provide a comprehensive analysis and highlight the
potential of these techniques to improve machine translation systems for
low-resource languages, contributing to the development of more robust
translation systems for under-resourced languages.

</details>


### [95] [HALT-RAG: A Task-Adaptable Framework for Hallucination Detection with Calibrated NLI Ensembles and Abstention](https://arxiv.org/abs/2509.07475)
*Saumya Goswami,Siddharth Kurra*

Main category: cs.CL

TL;DR: HALT-RAG是一个用于检测检索增强生成（RAG）管道输出中幻觉的后验验证系统，它使用来自NLI模型和词汇信号的通用特征来训练元分类器，并在HaluEval基准上实现了高F1分数。


<details>
  <summary>Details</summary>
Motivation: 生成式语言模型安全部署的关键挑战在于检测与其源文本不符或不受其支持的内容。

Method: HALT-RAG使用来自两个冻结的、现成的自然语言推理（NLI）模型的集成和轻量级词汇信号的通用特征集，训练一个简单的、校准过的、任务适应的元分类器。该系统采用严格的5折交叉验证（OOF）训练方案来防止数据泄露和产生无偏估计。

Result: 在HaluEval基准上，HALT-RAG在摘要、问答和对话任务上分别实现了0.7756、0.9786和0.7391的OOF F1分数。

Conclusion: HALT-RAG通过其通用特征集、轻量级任务适应分类器和精度约束决策策略，在摘要、问答和对话任务上取得了强大的性能。其良好的校准概率支持实用的弃权机制，为平衡模型性能和安全要求提供了可靠工具。

Abstract: Detecting content that contradicts or is unsupported by a given source text
is a critical challenge for the safe deployment of generative language models.
We introduce HALT-RAG, a post-hoc verification system designed to identify
hallucinations in the outputs of Retrieval-Augmented Generation (RAG)
pipelines. Our flexible and task-adaptable framework uses a universal feature
set derived from an ensemble of two frozen, off-the-shelf Natural Language
Inference (NLI) models and lightweight lexical signals. These features are used
to train a simple, calibrated, and task-adapted meta-classifier. Using a
rigorous 5-fold out-of-fold (OOF) training protocol to prevent data leakage and
produce unbiased estimates, we evaluate our system on the HaluEval benchmark.
By pairing our universal feature set with a lightweight, task-adapted
classifier and a precision-constrained decision policy, HALT-RAG achieves
strong OOF F1-scores of 0.7756, 0.9786, and 0.7391 on the summarization, QA,
and dialogue tasks, respectively. The system's well-calibrated probabilities
enable a practical abstention mechanism, providing a reliable tool for
balancing model performance with safety requirements.

</details>


### [96] [ALLabel: Three-stage Active Learning for LLM-based Entity Recognition using Demonstration Retrieval](https://arxiv.org/abs/2509.07512)
*Zihan Chen,Lei Shi,Weize Wu,Qiji Zhou,Yue Zhang*

Main category: cs.CL

TL;DR: 通过引入ALLabel框架，利用主动学习策略优化LLM的少样本学习，显著降低了科学领域实体识别的标注成本，同时保持了高精度。


<details>
  <summary>Details</summary>
Motivation: 当前数据驱动的科学研究（如化学、材料科学）需要大规模、高性能的实体识别能力，但现有基于LLM的方法通常需要昂贵的微调过程。

Method: 提出了一种名为ALLabel的三阶段框架，采用三种不同的主动学习策略来选择信息量大、代表性强的样本，用于构建LLM的少样本学习演示数据集。

Result: ALLabel在三个专业领域的数据集上，在相同标注预算下，始终优于所有基线方法。并且，ALLabel仅需标注5%-10%的数据即可达到标注整个数据集的性能水平。

Conclusion: ALLabel框架能够有效且泛化地在科学领域实现低成本、高精度的实体识别，为LLM的少样本学习提供了新的解决方案。

Abstract: Many contemporary data-driven research efforts in the natural sciences, such
as chemistry and materials science, require large-scale, high-performance
entity recognition from scientific datasets. Large language models (LLMs) have
increasingly been adopted to solve the entity recognition task, with the same
trend being observed on all-spectrum NLP tasks. The prevailing entity
recognition LLMs rely on fine-tuned technology, yet the fine-tuning process
often incurs significant cost. To achieve a best performance-cost trade-off, we
propose ALLabel, a three-stage framework designed to select the most
informative and representative samples in preparing the demonstrations for LLM
modeling. The annotated examples are used to construct a ground-truth retrieval
corpus for LLM in-context learning. By sequentially employing three distinct
active learning strategies, ALLabel consistently outperforms all baselines
under the same annotation budget across three specialized domain datasets.
Experimental results also demonstrate that selectively annotating only 5\%-10\%
of the dataset with ALLabel can achieve performance comparable to the method
annotating the entire dataset. Further analyses and ablation studies verify the
effectiveness and generalizability of our proposal.

</details>


### [97] [VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents](https://arxiv.org/abs/2509.07553)
*Zheng Wu,Heyuan Huang,Xingyu Lou,Xiangmou Qu,Pengzhou Cheng,Zongru Wu,Weiwen Liu,Weinan Zhang,Jun Wang,Zhaoxiang Wang,Zhuosheng Zhang*

Main category: cs.CL

TL;DR: VeriOS-Agent是一个查询驱动的人机交互框架，用于在不可信环境下提高操作系统（OS）代理的任务完成可靠性，通过在两种学习阶段训练，该代理能在正常情况下自主执行任务，在不可信情况下主动询问人类，实验证明其在不可信环境下成功率提高了20.64%。


<details>
  <summary>Details</summary>
Motivation: 现有操作系统代理在理想环境下工作良好，但在现实中常面临不可信条件，导致任务执行风险，需要一种能在不可信环境下提高任务完成可靠性的方法。

Method: 提出了一种查询驱动的人机GUI交互框架，并基于此框架开发了VeriOS-Agent，该代理采用两阶段学习范式，能在正常条件下自主执行操作，在不可信条件下主动查询人类。

Result: VeriOS-Agent在不可信环境下的平均分步成功率比现有技术提高了20.64%，且在正常性能下无下降，并表现出良好的合理性、通用性和可扩展性。

Conclusion: VeriOS-Agent通过引入查询驱动的人机交互和两阶段学习范式，有效解决了现实世界中不可信环境下操作系统代理的任务执行风险问题，提高了任务完成的可靠性。

Abstract: With the rapid progress of multimodal large language models, operating system
(OS) agents become increasingly capable of automating tasks through on-device
graphical user interfaces (GUIs). However, most existing OS agents are designed
for idealized settings, whereas real-world environments often present
untrustworthy conditions. To mitigate risks of over-execution in such
scenarios, we propose a query-driven human-agent-GUI interaction framework that
enables OS agents to decide when to query humans for more reliable task
completion. Built upon this framework, we introduce VeriOS-Agent, a trustworthy
OS agent trained with a two-stage learning paradigm that falicitate the
decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent
autonomously executes actions in normal conditions while proactively querying
humans in untrustworthy scenarios. Experiments show that VeriOS-Agent improves
the average step-wise success rate by 20.64\% in untrustworthy scenarios over
the state-of-the-art, without compromising normal performance. Analysis
highlights VeriOS-Agent's rationality, generalizability, and scalability. The
codes, datasets and models are available at
https://github.com/Wuzheng02/VeriOS.

</details>


### [98] [Avoiding Knowledge Edit Skipping in Multi-hop Question Answering with Guided Decomposition](https://arxiv.org/abs/2509.07555)
*Yi Liu,Xiangrong Zhu,Xiangyu Liu,Wei Wei,Wei Hu*

Main category: cs.CL

TL;DR: LLMs知识易过时，但重训成本高。现有基于RAG的知识编辑方法在处理单跳问题时效果尚可，但在多跳问答中存在“编辑跳过”问题，即模型在推理时会跳过已编辑的事实。这不仅因为知识表达的多样性，还因为模型解决问题时的粒度与编辑记忆中的事实不匹配。为此，我们提出了一种新颖的迭代式检索增强知识编辑方法（IRAKE），通过对单个编辑事实和整个编辑案例的引导来解决“编辑跳过”问题。实验证明，IRAKE能有效缓解因“编辑跳过”导致的编辑失败，并在多跳问答知识编辑任务上超越现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于检索增强生成（RAG）的知识编辑（KE）方法在处理多跳问答时存在“编辑跳过”问题，即模型在推理时会跳过已编辑的相关事实，导致编辑失败。这限制了其在知识快速更新场景下的应用，而重训大型语言模型（LLMs）成本过高，因此需要更有效的知识编辑方法。

Method: 提出了一种名为迭代式检索增强知识编辑（IRAKE）的新方法。该方法通过对单个编辑事实和整个编辑案例进行引导，以解决“编辑跳过”问题。IRAKE旨在通过更精细化的引导来确保模型在推理过程中能够正确利用已编辑的事实。

Result: 实验结果表明，IRAKE能够有效缓解“编辑跳过”导致的编辑失败问题，并在多跳问答的知识编辑任务上取得了优于现有最先进方法的性能。

Conclusion: IRAKE是一种有效的知识编辑方法，特别适用于多跳问答场景，能够克服现有方法的局限性，并显著提升知识编辑的准确性和鲁棒性。

Abstract: In a rapidly evolving world where information updates swiftly, knowledge in
large language models (LLMs) becomes outdated quickly. Retraining LLMs is not a
cost-effective option, making knowledge editing (KE) without modifying
parameters particularly necessary. We find that although existing
retrieval-augmented generation (RAG)-based KE methods excel at editing simple
knowledge, they struggle with KE in multi-hop question answering due to the
issue of "edit skipping", which refers to skipping the relevant edited fact in
inference. In addition to the diversity of natural language expressions of
knowledge, edit skipping also arises from the mismatch between the granularity
of LLMs in problem-solving and the facts in the edited memory. To address this
issue, we propose a novel Iterative Retrieval-Augmented Knowledge Editing
method with guided decomposition (IRAKE) through the guidance from single
edited facts and entire edited cases. Experimental results demonstrate that
IRAKE mitigates the failure of editing caused by edit skipping and outperforms
state-of-the-art methods for KE in multi-hop question answering.

</details>


### [99] [BALI: Enhancing Biomedical Language Representations through Knowledge Graph and Language Model Alignment](https://arxiv.org/abs/2509.07588)
*Andrey Sakhovskiy,Elena Tutubalina*

Main category: cs.CL

TL;DR: 现有的生物医学语言模型难以理解复杂的领域特定概念结构和知识图谱（KG）中编码的事实信息。我们提出了BALI（生物医学知识图谱和语言模型对齐）方法，通过联合训练专门的KG编码器并对齐语言模型（LM）和KG的表示来增强LM的外部知识。通过将生物医学概念提及链接到UMLS KG，并利用局部KG子图作为跨模态正样本，BALI能够提高PubMedBERT和BioLinkBERT等模型在多种语言理解任务上的性能以及实体表示的质量。


<details>
  <summary>Details</summary>
Motivation: 现有的生物医学语言模型在理解复杂、领域特定的概念结构和生物医学知识图谱（KG）中编码的事实信息方面存在局限性。

Method: 提出了一种新颖的联合语言模型（LM）和知识图谱（KG）预训练方法BALI（生物医学知识图谱和语言模型对齐）。该方法通过同时学习专门的KG编码器并对齐LM和KG的表示来增强LM的外部知识。具体来说，它将生物医学概念提及链接到UMLS KG，并利用局部KG子图作为这些提及的跨模态正样本。

Result: 在PubMedBERT和BioLinkBERT等几个领先的生物医学LM上实现BALI方法，可以提高它们在多种语言理解任务上的性能以及实体表示的质量，即使在仅使用从PubMed科学摘要中提取的小型对齐数据集进行少量预训练的情况下。

Conclusion: BALI通过联合LM和KG预训练，并利用KG子图作为跨模态监督信号，有效地增强了生物医学LM的知识和表示质量，提高了其在下游任务中的性能。

Abstract: In recent years, there has been substantial progress in using pretrained
Language Models (LMs) on a range of tasks aimed at improving the understanding
of biomedical texts. Nonetheless, existing biomedical LLMs show limited
comprehension of complex, domain-specific concept structures and the factual
information encoded in biomedical Knowledge Graphs (KGs). In this work, we
propose BALI (Biomedical Knowledge Graph and Language Model Alignment), a novel
joint LM and KG pre-training method that augments an LM with external knowledge
by the simultaneous learning of a dedicated KG encoder and aligning the
representations of both the LM and the graph. For a given textual sequence, we
link biomedical concept mentions to the Unified Medical Language System (UMLS)
KG and utilize local KG subgraphs as cross-modal positive samples for these
mentions. Our empirical findings indicate that implementing our method on
several leading biomedical LMs, such as PubMedBERT and BioLinkBERT, improves
their performance on a range of language understanding tasks and the quality of
entity representations, even with minimal pre-training on a small alignment
dataset sourced from PubMed scientific abstracts.

</details>


### [100] [MaLei at MultiClinSUM: Summarisation of Clinical Documents using Perspective-Aware Iterative Self-Prompting with LLMs](https://arxiv.org/abs/2509.07622)
*Libo Ren,Yee Man Ng,Lifeng Han*

Main category: cs.CL

TL;DR: 使用迭代式自问 (ISP) 技术和大型语言模型 (LLM) 总结临床报告，取得了优于 ROUGE 分数的 BERT 分数。


<details>
  <summary>Details</summary>
Motivation: 临床报告冗长且充满术语，难以让非专业人士理解，影响医患共同决策。

Method: 采用迭代式自问 (ISP) 技术，利用 LLM 生成和优化特定任务的提示，并结合词汇和嵌入空间指标（ROUGE 和 BERT-score）进行模型微调。

Result: 在 3,396 份临床报告上，使用 GPT-4 和 GPT-4o 的 ISP 模型取得了 ROUGE 分数 (46.53, 24.68, 30.77) 和 BERT 分数 (87.84, 83.25, 85.46)。高 BERT 分数表明生成的摘要在语义上与参考摘要相似，尽管词汇重叠度较低。

Conclusion: 视角感知 ISP (PA-ISP) 可用于临床报告摘要，以改善医患沟通。

Abstract: Efficient communication between patients and clinicians plays an important
role in shared decision-making. However, clinical reports are often lengthy and
filled with clinical jargon, making it difficult for domain experts to identify
important aspects in the document efficiently. This paper presents the
methodology we applied in the MultiClinSUM shared task for summarising clinical
case documents. We used an Iterative Self-Prompting technique on large language
models (LLMs) by asking LLMs to generate task-specific prompts and refine them
via example-based few-shot learning. Furthermore, we used lexical and embedding
space metrics, ROUGE and BERT-score, to guide the model fine-tuning with
epochs. Our submission using perspective-aware ISP on GPT-4 and GPT-4o achieved
ROUGE scores (46.53, 24.68, 30.77) and BERTscores (87.84, 83.25, 85.46) for (P,
R, F1) from the official evaluation on 3,396 clinical case reports from various
specialties extracted from open journals. The high BERTscore indicates that the
model produced semantically equivalent output summaries compared to the
references, even though the overlap at the exact lexicon level is lower, as
reflected in the lower ROUGE scores. This work sheds some light on how
perspective-aware ISP (PA-ISP) can be deployed for clinical report
summarisation and support better communication between patients and clinicians.

</details>


### [101] [MoLoRAG: Bootstrapping Document Understanding via Multi-modal Logic-aware Retrieval](https://arxiv.org/abs/2509.07666)
*Xixi Wu,Yanchao Tan,Nan Hou,Ruiyang Zhang,Hong Cheng*

Main category: cs.CL

TL;DR: MoLoRAG是一个用于多模态、多页文档理解的逻辑感知检索框架，通过构建页面图并结合语义和逻辑相关性来改进检索，并在DocQA数据集上实现了显著的准确率提升。


<details>
  <summary>Details</summary>
Motivation: 传统文档理解方法将文档转为文本，丢失了多模态信息；现有的大型视觉语言模型（LVLM）输入长度受限，无法处理多页文档；检索增强生成（RAG）方法仅依赖语义相关性，忽略了页面间的逻辑联系，而这对于推理至关重要。

Method: 提出MoLoRAG框架，构建一个捕捉页面间上下文关系的页面图，使用轻量级VLM进行图遍历以检索相关页面（包括具有逻辑连接的页面），结合语义和逻辑相关性进行检索，然后将检索到的页面输入任意LVLM进行问答。提供训练免费和微调两种版本。

Result: 在四个DocQA数据集上的实验表明，相比LVLM直接推理，准确率平均提升9.68%；相比基线方法，检索精度平均提升7.44%。

Conclusion: MoLoRAG通过引入逻辑感知检索，有效解决了多页、多模态文档理解中的挑战，并在DocQA任务上取得了优于现有方法的性能。

Abstract: Document Understanding is a foundational AI capability with broad
applications, and Document Question Answering (DocQA) is a key evaluation task.
Traditional methods convert the document into text for processing by Large
Language Models (LLMs), but this process strips away critical multi-modal
information like figures. While Large Vision-Language Models (LVLMs) address
this limitation, their constrained input size makes multi-page document
comprehension infeasible. Retrieval-augmented generation (RAG) methods mitigate
this by selecting relevant pages, but they rely solely on semantic relevance,
ignoring logical connections between pages and the query, which is essential
for reasoning.
  To this end, we propose MoLoRAG, a logic-aware retrieval framework for
multi-modal, multi-page document understanding. By constructing a page graph
that captures contextual relationships between pages, a lightweight VLM
performs graph traversal to retrieve relevant pages, including those with
logical connections often overlooked. This approach combines semantic and
logical relevance to deliver more accurate retrieval. After retrieval, the
top-$K$ pages are fed into arbitrary LVLMs for question answering. To enhance
flexibility, MoLoRAG offers two variants: a training-free solution for easy
deployment and a fine-tuned version to improve logical relevance checking.
Experiments on four DocQA datasets demonstrate average improvements of 9.68% in
accuracy over LVLM direct inference and 7.44% in retrieval precision over
baselines. Codes and datasets are released at
https://github.com/WxxShirley/MoLoRAG.

</details>


### [102] [M-BRe: Discovering Training Samples for Relation Extraction from Unlabeled Texts with Large Language Models](https://arxiv.org/abs/2509.07730)
*Zexuan Li,Hongliang Dai,Piji Li*

Main category: cs.CL

TL;DR: 该研究提出了一种名为M-BRe的框架，用于从无标签文本中提取关系抽取（RE）的训练实例，以解决手动标注成本高和利用大型语言模型（LLMs）进行RE时面临的多类别分类语义捕捉不足及二元分类计算开销大的问题。M-BRe结合了两种方法的优点，通过关系分组、关系抽取和标签决策三个模块，能够高效发现高质量的训练样本。


<details>
  <summary>Details</summary>
Motivation: 手动标注关系抽取（RE）的训练数据成本高昂，因为包含目标关系的句子稀少且难以寻找。因此，开发一种能从无标签文本自动提取训练实例以训练RE模型的方法非常有益。然而，在利用大型语言模型（LLMs）进行具有预定义关系类别的RE时，LLMs在多类别分类中难以全面捕捉每种关系，导致效果不佳；而采用二元分类虽然能缓解此问题，却带来巨大的计算开销，不适用于实际应用。

Method: 提出一个名为M-BRe的框架，该框架包含三个模块：关系分组（Relation Grouping）、关系抽取（Relation Extraction）和标签决策（Label Decision），旨在结合多类别分类和二元分类的优点，从无标签文本中提取RE训练实例。

Result: 通过大量实验证明，M-BRe在从无标签文本中为RE发现高质量训练样本方面具有出色的能力。

Conclusion: M-BRe框架能够有效地从无标签文本中提取高质量的训练实例，以应对关系抽取任务中手动标注成本高以及利用LLMs时遇到的挑战。

Abstract: For Relation Extraction (RE), the manual annotation of training data may be
prohibitively expensive, since the sentences that contain the target relations
in texts can be very scarce and difficult to find. It is therefore beneficial
to develop an efficient method that can automatically extract training
instances from unlabeled texts for training RE models. Recently, large language
models (LLMs) have been adopted in various natural language processing tasks,
with RE also benefiting from their advances. However, when leveraging LLMs for
RE with predefined relation categories, two key challenges arise. First, in a
multi-class classification setting, LLMs often struggle to comprehensively
capture the semantics of every relation, leading to suboptimal results. Second,
although employing binary classification for each relation individually can
mitigate this issue, it introduces significant computational overhead,
resulting in impractical time complexity for real-world applications.
Therefore, this paper proposes a framework called M-BRe to extract training
instances from unlabeled texts for RE. It utilizes three modules to combine the
advantages of both of the above classification approaches: Relation Grouping,
Relation Extraction, and Label Decision. Extensive experiments confirm its
superior capability in discovering high-quality training samples from unlabeled
texts for RE.

</details>


### [103] [Factuality Beyond Coherence: Evaluating LLM Watermarking Methods for Medical Texts](https://arxiv.org/abs/2509.07755)
*Rochana Prih Hastuti,Rian Adam Rajagede,Mansour Al Ghanim,Mengxin Zheng,Qian Lou*

Main category: cs.CL

TL;DR: LLM在医疗领域的应用存在安全风险，特别是在溯源和问责方面。水印技术可以通过嵌入可检测模式来降低这些风险，但其在医疗领域的可靠性尚未得到验证。现有的基准测试未能充分评估事实风险，尤其是在水印重加权策略常被利用的低熵环境下。本文提出了一个面向医疗领域的评估流程，联合评估事实准确性和连贯性。通过GPT-Judger和人类验证，我们引入了事实加权得分（FWS），这是一个优先考虑事实准确性而非连贯性的复合指标，以指导水印在医疗领域的部署。我们的评估表明，当前的水印方法会严重损害医疗事实的准确性，熵的变化会降低医疗实体的表示。这些发现强调了采用能够保持医疗内容完整性的领域感知水印方法的必要性。


<details>
  <summary>Details</summary>
Motivation: LLM在医疗领域的应用带来了安全风险，特别是溯源和问责方面。现有的水印技术虽然能降低这些风险，但其在医疗领域的可靠性尚未经过充分测试，且现有基准测试忽略了低熵环境下事实准确性这一关键问题。

Method: 提出一个面向医疗领域的评估流程，联合评估事实准确性和连贯性。使用GPT-Judger和人类验证，引入事实加权得分（FWS）作为复合指标，优先考虑事实准确性。

Result: 当前的水印方法严重损害了医疗事实的准确性，熵的变化会降低医疗实体表示。FWS指标能够指导水印在医疗领域的部署。

Conclusion: 需要开发能够保持医疗内容完整性的领域感知水印方法，以解决当前水印技术在医疗领域存在的准确性问题。

Abstract: As large language models (LLMs) adapted to sensitive domains such as
medicine, their fluency raises safety risks, particularly regarding provenance
and accountability. Watermarking embeds detectable patterns to mitigate these
risks, yet its reliability in medical contexts remains untested. Existing
benchmarks focus on detection-quality tradeoffs, overlooking factual risks
under low-entropy settings often exploited by watermarking's reweighting
strategy. We propose a medical-focused evaluation workflow that jointly
assesses factual accuracy and coherence. Using GPT-Judger and further human
validation, we introduce the Factuality-Weighted Score (FWS), a composite
metric prioritizing factual accuracy beyond coherence to guide watermarking
deployment in medical domains. Our evaluation shows current watermarking
methods substantially compromise medical factuality, with entropy shifts
degrading medical entity representation. These findings underscore the need for
domain-aware watermarking approaches that preserve the integrity of medical
content.

</details>


### [104] [Are LLMs Enough for Hyperpartisan, Fake, Polarized and Harmful Content Detection? Evaluating In-Context Learning vs. Fine-Tuning](https://arxiv.org/abs/2509.07768)
*Michele Joshua Maggini,Dhia Merzougui,Rabiraj Bandyopadhyay,Gaël Dias,Fabrice Maurel,Pablo Gamallo*

Main category: cs.CL

TL;DR: 大型语言模型在检测网络虚假、政治偏见和有害内容方面，微调（Fine-Tuning）的性能优于上下文学习（In-Context Learning），即使是较小的模型也是如此。


<details>
  <summary>Details</summary>
Motivation: 在线平台上的虚假新闻、两极分化、政治偏见和有害内容传播是一个严重问题，但缺乏对不同大型语言模型（LLM）在不同模型、使用方法和语言上的性能基准测试。

Method: 在10个数据集和5种语言（英语、西班牙语、葡萄牙语、阿拉伯语和保加利亚语）上，对包括参数高效微调（PEFT）和多种上下文学习策略（如零样本、码本、少样本和思维链）在内的大型语言模型适应范式进行了广泛实验。

Result: 在虚假新闻、有害推文和政治偏见检测任务中，上下文学习的性能通常不如微调。即使是最大的模型（如LlaMA3.1-8b-Instruct、Mistral-Nemo-Instruct-2407和Qwen2.5-7B-Instruct）在上下文学习设置下的表现也不如在特定任务上进行微调的较小模型。

Conclusion: 在网络内容审核等任务中，与上下文学习相比，微调（即使是较小的模型）在性能上更具优势，这凸显了针对特定任务进行微调的重要性。

Abstract: The spread of fake news, polarizing, politically biased, and harmful content
on online platforms has been a serious concern. With large language models
becoming a promising approach, however, no study has properly benchmarked their
performance across different models, usage methods, and languages. This study
presents a comprehensive overview of different Large Language Models adaptation
paradigms for the detection of hyperpartisan and fake news, harmful tweets, and
political bias. Our experiments spanned 10 datasets and 5 different languages
(English, Spanish, Portuguese, Arabic and Bulgarian), covering both binary and
multiclass classification scenarios. We tested different strategies ranging
from parameter efficient Fine-Tuning of language models to a variety of
different In-Context Learning strategies and prompts. These included zero-shot
prompts, codebooks, few-shot (with both randomly-selected and
diversely-selected examples using Determinantal Point Processes), and
Chain-of-Thought. We discovered that In-Context Learning often underperforms
when compared to Fine-Tuning a model. This main finding highlights the
importance of Fine-Tuning even smaller models on task-specific settings even
when compared to the largest models evaluated in an In-Context Learning setup -
in our case LlaMA3.1-8b-Instruct, Mistral-Nemo-Instruct-2407 and
Qwen2.5-7B-Instruct.

</details>


### [105] [SciNLP: A Domain-Specific Benchmark for Full-Text Scientific Entity and Relation Extraction in NLP](https://arxiv.org/abs/2509.07801)
*Decheng Duan,Yingyi Zhang,Jitong Peng,Chengzhi Zhang*

Main category: cs.CL

TL;DR: SciNLP是一个针对自然语言处理（NLP）领域的全文本实体和关系提取的基准数据集，包含60篇标注完整的NLP论文，旨在克服现有数据集在特定章节标注和高昂成本方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在标注科学文献时，由于领域复杂性和高昂的标注成本，大多局限于特定的论文章节。本研究旨在创建一个针对NLP领域全文本实体和关系提取的专用基准，以克服这一局限。

Method: 构建了一个包含60篇完整NLP论文的数据集，其中手动标注了7072个实体和1826个关系，并将其命名为SciNLP。对现有模型进行了评估，并与类似数据集进行了比较，同时利用SciNLP训练的模型自动构建了NLP领域的细粒度知识图谱。

Result: SciNLP是NLP领域首个提供全文本实体及其关系标注的数据集。实验结果表明，现有模型在不同长度的学术文本上的提取能力有所差异。与现有数据集的交叉比较显示，SciNLP在某些基线模型上取得了显著的性能提升。利用SciNLP训练的模型构建的知识图谱，每个实体平均有3.2个节点度，表明其丰富的语义拓扑信息能够增强下游应用。

Conclusion: SciNLP数据集的建立为NLP领域提供了全文本实体和关系提取的基准，并通过实验验证了其有效性，同时利用该数据集构建的知识图谱能够丰富下游应用。

Abstract: Structured information extraction from scientific literature is crucial for
capturing core concepts and emerging trends in specialized fields. While
existing datasets aid model development, most focus on specific publication
sections due to domain complexity and the high cost of annotating scientific
texts. To address this limitation, we introduce SciNLP - a specialized
benchmark for full-text entity and relation extraction in the Natural Language
Processing (NLP) domain. The dataset comprises 60 manually annotated full-text
NLP publications, covering 7,072 entities and 1,826 relations. Compared to
existing research, SciNLP is the first dataset providing full-text annotations
of entities and their relationships in the NLP domain. To validate the
effectiveness of SciNLP, we conducted comparative experiments with similar
datasets and evaluated the performance of state-of-the-art supervised models on
this dataset. Results reveal varying extraction capabilities of existing models
across academic texts of different lengths. Cross-comparisons with existing
datasets show that SciNLP achieves significant performance improvements on
certain baseline models. Using models trained on SciNLP, we implemented
automatic construction of a fine-grained knowledge graph for the NLP domain.
Our KG has an average node degree of 3.2 per entity, indicating rich semantic
topological information that enhances downstream applications. The dataset is
publicly available at https://github.com/AKADDC/SciNLP.

</details>


### [106] [Dual Knowledge-Enhanced Two-Stage Reasoner for Multimodal Dialog Systems](https://arxiv.org/abs/2509.07817)
*Xiaolin Chen,Xuemeng Song,Haokun Wen,Weili Guan,Xiangyu Zhao,Liqiang Nie*

Main category: cs.CL

TL;DR: 该研究提出了一种名为DK2R的新型框架，用于增强多模态任务导向对话系统的文本响应生成能力。该框架通过整合结构化属性知识和非结构化评论知识，并利用大型语言模型（LLMs）来解决现有方法中知识利用不足和LLMs利用不充分的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态任务导向对话系统在生成文本响应方面存在局限性，主要体现在未能充分利用非结构化的评论知识以及对大型语言模型（LLMs）的利用不足。因此，本研究旨在利用结构化属性知识和非结构化评论知识的对偶知识，结合LLMs来改进文本响应生成。

Method: 提出了一种新颖的、增强了对偶知识的两阶段推理器（DK2R），该推理器适配了LLMs用于多模态对话系统。具体来说，DK2R首先从外部知识库中提取结构化属性知识和非结构化评论知识。然后，利用LLM评估每种知识类型的效用，方法是分析LLM生成的临时探测响应。此外，DK2R通过专门的推理分离地总结面向意图的关键线索，并将这些线索作为辅助信号来增强基于LLM的文本响应生成。

Result: 在公开数据集上的大量实验验证了DK2R的优越性。

Conclusion: DK2R通过有效整合结构化属性知识和非结构化评论知识，并结合LLMs的强大能力，显著提升了多模态任务导向对话系统的文本响应生成效果，解决了动态知识类型选择和意图-响应解耦的挑战。

Abstract: Textual response generation is pivotal for multimodal \mbox{task-oriented}
dialog systems, which aims to generate proper textual responses based on the
multimodal context. While existing efforts have demonstrated remarkable
progress, there still exist the following limitations: 1) \textit{neglect of
unstructured review knowledge} and 2) \textit{underutilization of large
language models (LLMs)}. Inspired by this, we aim to fully utilize dual
knowledge (\textit{i.e., } structured attribute and unstructured review
knowledge) with LLMs to promote textual response generation in multimodal
task-oriented dialog systems. However, this task is non-trivial due to two key
challenges: 1) \textit{dynamic knowledge type selection} and 2)
\textit{intention-response decoupling}. To address these challenges, we propose
a novel dual knowledge-enhanced two-stage reasoner by adapting LLMs for
multimodal dialog systems (named DK2R). To be specific, DK2R first extracts
both structured attribute and unstructured review knowledge from external
knowledge base given the dialog context. Thereafter, DK2R uses an LLM to
evaluate each knowledge type's utility by analyzing LLM-generated provisional
probe responses. Moreover, DK2R separately summarizes the intention-oriented
key clues via dedicated reasoning, which are further used as auxiliary signals
to enhance LLM-based textual response generation. Extensive experiments
conducted on a public dataset verify the superiority of DK2R. We have released
the codes and parameters.

</details>


### [107] [Small Open Models Achieve Near Parity with Large Models in Low Resource Literary Translation at a Fraction of the Cost](https://arxiv.org/abs/2509.07829)
*Mihai Nadas,Laura Diosan,Andreea Tomescu,Andrei Piscoran*

Main category: cs.CL

TL;DR: TINYFABULIST TRANSLATION FRAMEWORK (TF2) 是一个用于英罗文学翻译的统一框架，发布了一个精调的 12B 参数语言模型 (TF2-12B) 和大规模合成平行数据集 (DS-TF2-EN-RO-3M 和 DS-TF2-EN-RO-15K)，旨在解决低资源语言（如罗马尼亚语）的文学翻译问题，并提供了一个可复现的、经济高效的翻译研究和开放模型应用流程。


<details>
  <summary>Details</summary>
Motivation: 目前的机器翻译研究在文学翻译领域，特别是使用小型开放模型进行翻译方面仍存在挑战，低资源语言（如罗马尼亚语）的高质量文学数据集尤为缺乏。

Method: 该研究提出了 TINYFABULIST TRANSLATION FRAMEWORK (TF2) 框架，包括：1. 数据集创建：基于已有的英文寓言数据集 (TF1)，生成 15,000 条高质量的罗马尼亚语译文。2. 模型微调：对一个 12B 参数的开放权重模型进行两阶段微调：首先进行指令微调以学习文学叙事风格，然后进行适配器压缩以实现高效部署。3. 评估：结合 BLEU 分数和基于 LLM 的五维度评估标准（准确性、流畅性、连贯性、风格、文化适应性）来评估翻译质量。

Result: 研究结果表明，TF2 框架微调后的模型在流畅性和充分性方面表现出色，可与顶尖的大型专有模型相媲美，并且具有开放、易于访问和成本效益高的优势。

Conclusion: TF2 提供了一个端到端的、可复现的流程，为经济高效的机器翻译、跨语言叙事生成以及在低资源环境下推广开放模型用于文学内容翻译提供了支持。

Abstract: Literary translation has recently gained attention as a distinct and complex
task in machine translation research. However, the translation by small open
models remains an open problem. We contribute to this ongoing research by
introducing TINYFABULIST TRANSLATION FRAMEWORK (TF2), a unified framework for
dataset creation, fine tuning, and evaluation in English-Romanian literary
translations, centred on the creation and open release of both a compact, fine
tuned language model (TF2-12B) and large scale synthetic parallel datasets
(DS-TF2-EN-RO-3M and DS-TF2-EN-RO-15K). Building on DS-TF1-EN-3M (TF1), the
largest collection of synthetic English fables to date, we address the need for
rich, high quality literary datasets in low resource languages such as
Romanian. Our pipeline first generates 15k high quality Romanian references
from the TF1 pool using a high performing LLM. We then apply a two stage fine
tuning process to a 12B parameter open weight model: (i) instruction tuning to
capture genre specific narrative style, and (ii) adapter compression for
efficient deployment. Evaluation combines corpus level BLEU and a five
dimension LLM based rubric (accuracy, fluency, coherence, style, cultural
adaptation) to provide a nuanced assessment of translation quality. Results
show that our fine tuned model achieves fluency and adequacy competitive with
top performing large proprietary models, while being open, accessible, and
significantly more cost effective. Alongside the fine tuned model and both
datasets, we publicly release all scripts and evaluation prompts. TF2 thus
provides an end-to-end, reproducible pipeline for research on cost efficient
translation, cross lingual narrative generation, and the broad adoption of open
models for culturally significant literary content in low resource settings.

</details>


### [108] [Are Humans as Brittle as Large Language Models?](https://arxiv.org/abs/2509.07869)
*Jiahui Li,Sean Papay,Roman Klinger*

Main category: cs.CL

TL;DR: LLM和人类在面对指令修改时都会表现出脆弱性，但对不同类型的修改敏感度不同。


<details>
  <summary>Details</summary>
Motivation: 探究LLM的提示脆弱性是否是其特有现象，以及人类标注者是否也表现出类似的对指令修改的敏感度。

Method: 系统性地对比了修改提示对LLM和人类标注者在文本分类任务上的影响，关注他们对提示扰动的敏感度。

Result: 研究发现，LLM和人类在面对标签集或标签格式的修改时都会增加脆弱性。然而，在处理印刷错误和标签顺序颠倒时，人类判断的分布受到的影响小于LLM。

Conclusion: LLM的提示脆弱性并非完全是其特有现象，人类标注者在特定情况下也会表现出类似的敏感度。

Abstract: The output of large language models (LLM) is unstable, due to both
non-determinism of the decoding process as well as to prompt brittleness. While
the intrinsic non-determinism of LLM generation may mimic existing uncertainty
in human annotations through distributional shifts in outputs, it is largely
assumed, yet unexplored, that the prompt brittleness effect is unique to LLMs.
This raises the question: do human annotators show similar sensitivity to
instruction changes? If so, should prompt brittleness in LLMs be considered
problematic? One may alternatively hypothesize that prompt brittleness
correctly reflects human annotation variances. To fill this research gap, we
systematically compare the effects of prompt modifications on LLMs and
identical instruction modifications for human annotators, focusing on the
question of whether humans are similarly sensitive to prompt perturbations. To
study this, we prompt both humans and LLMs for a set of text classification
tasks conditioned on prompt variations. Our findings indicate that both humans
and LLMs exhibit increased brittleness in response to specific types of prompt
modifications, particularly those involving the substitution of alternative
label sets or label formats. However, the distribution of human judgments is
less affected by typographical errors and reversed label order than that of
LLMs.

</details>


### [109] [From Detection to Mitigation: Addressing Gender Bias in Chinese Texts via Efficient Tuning and Voting-Based Rebalancing](https://arxiv.org/abs/2509.07889)
*Chengyan Wu,Yiqiang Cai,Yufei Cheng,Yun Xue*

Main category: cs.CL

TL;DR: 本研究提出了一种基于LLM和LoRA的中文句子性别偏见检测与缓解方法，通过构建平衡数据集、引入异构样本、采用多模型融合和多温度采样策略，在NLPCC-2025共享任务中取得第四名的成绩。


<details>
  <summary>Details</summary>
Motivation: 旨在解决中文自然语言生成中的公平性和可控性问题，自动检测、分类和缓解性别偏见。

Method: 采用基于大型语言模型（LLM）的微调方法，并利用低秩适配（LoRA）技术进行偏见检测任务的快速适应。通过构建更平衡的训练集和引入异构样本来处理类别不平衡和增强模型泛化能力。检测和分类子任务采用多模型集成和多数投票策略。偏见生成检测和缓解方面，设计了多温度采样机制。

Result: 实验结果证明了该方法在偏见检测、分类和缓解方面的有效性，最终在共享任务中取得了47.90%的平均分，排名第四。

Conclusion: 所提出的方法在中文句子性别偏见检测与缓解任务中表现出有效性。

Abstract: This paper presents our team's solution to Shared Task 7 of NLPCC-2025, which
focuses on sentence-level gender bias detection and mitigation in Chinese. The
task aims to promote fairness and controllability in natural language
generation by automatically detecting, classifying, and mitigating gender bias.
To address this challenge, we adopt a fine-tuning approach based on large
language models (LLMs), efficiently adapt to the bias detection task via
Low-Rank Adaptation (LoRA). In terms of data processing, we construct a more
balanced training set to alleviate class imbalance and introduce heterogeneous
samples from multiple sources to enhance model generalization. For the
detection and classification sub-tasks, we employ a majority voting strategy
that integrates outputs from multiple expert models to boost performance.
Additionally, to improve bias generation detection and mitigation, we design a
multi-temperature sampling mechanism to capture potential variations in bias
expression styles. Experimental results demonstrate the effectiveness of our
approach in bias detection, classification, and mitigation. Our method
ultimately achieves an average score of 47.90%, ranking fourth in the shared
task.

</details>


### [110] [Biased Tales: Cultural and Topic Bias in Generating Children's Stories](https://arxiv.org/abs/2509.07908)
*Donya Rooein,Vilém Zouhar,Debora Nozza,Dirk Hovy*

Main category: cs.CL

TL;DR: LLM生成的儿童故事包含文化和性别刻板印象，而Biased Tales数据集揭示了这些偏见。


<details>
  <summary>Details</summary>
Motivation: 随着父母越来越多地依赖LLM为孩子创作睡前故事，故事中存在的文化和性别刻板印象引起了人们的担忧。

Method: 创建了一个名为Biased Tales的数据集，用于分析偏见如何在LLM生成的故事中影响主角的属性和故事元素。

Result: 研究发现，与男孩相比，以女孩为主角的故事中与外貌相关的属性增加了55.26%。以非西方儿童为主角的故事比以西方儿童为主角的故事更倾向于强调文化遗产、传统和家庭主题。

Conclusion: 研究结果强调了社会文化偏见在使创意AI使用更加公平和多样化方面所起的作用。

Abstract: Stories play a pivotal role in human communication, shaping beliefs and
morals, particularly in children. As parents increasingly rely on large
language models (LLMs) to craft bedtime stories, the presence of cultural and
gender stereotypes in these narratives raises significant concerns. To address
this issue, we present Biased Tales, a comprehensive dataset designed to
analyze how biases influence protagonists' attributes and story elements in
LLM-generated stories. Our analysis uncovers striking disparities. When the
protagonist is described as a girl (as compared to a boy), appearance-related
attributes increase by 55.26%. Stories featuring non-Western children
disproportionately emphasize cultural heritage, tradition, and family themes
far more than those for Western children. Our findings highlight the role of
sociocultural bias in making creative AI use more equitable and diverse.

</details>


### [111] [GENUINE: Graph Enhanced Multi-level Uncertainty Estimation for Large Language Models](https://arxiv.org/abs/2509.07925)
*Tuo Wang,Adithya Kulkarni,Tyler Cody,Peter A. Beling,Yujun Yan,Dawei Zhou*

Main category: cs.CL

TL;DR: GENUINE是一个利用依赖解析树和层次图池化来改进LLM不确定性量化的结构感知框架，在NLP任务中取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有LLM不确定性估计方法忽视语义依赖，依赖于无法捕捉文本结构关系的token级概率度量。

Method: 提出GENUINE框架，利用依赖解析树和层次图池化，并通过监督学习来建模语义和结构关系，以改进不确定性量化。

Result: 在NLP任务上的实验表明，GENUINE的AUROC比基于语义熵的方法高出29%，并将校准误差降低了15%以上。

Conclusion: 基于图的不确定性建模在提高LLM的置信度评估方面是有效的。

Abstract: Uncertainty estimation is essential for enhancing the reliability of Large
Language Models (LLMs), particularly in high-stakes applications. Existing
methods often overlook semantic dependencies, relying on token-level
probability measures that fail to capture structural relationships within the
generated text. We propose GENUINE: Graph ENhanced mUlti-level uncertaINty
Estimation for Large Language Models, a structure-aware framework that
leverages dependency parse trees and hierarchical graph pooling to refine
uncertainty quantification. By incorporating supervised learning, GENUINE
effectively models semantic and structural relationships, improving confidence
assessments. Extensive experiments across NLP tasks show that GENUINE achieves
up to 29% higher AUROC than semantic entropy-based approaches and reduces
calibration errors by over 15%, demonstrating the effectiveness of graph-based
uncertainty modeling. The code is available at
https://github.com/ODYSSEYWT/GUQ.

</details>


### [112] [SimpleQA Verified: A Reliable Factuality Benchmark to Measure Parametric Knowledge](https://arxiv.org/abs/2509.07968)
*Lukas Haas,Gal Yona,Giovanni D'Antonio,Sasha Goldshtein,Dipanjan Das*

Main category: cs.CL

TL;DR: SimpleQA Verified是一个包含1000个提示的新基准，用于评估大型语言模型（LLM）的短期事实性，解决了OpenAI SimpleQA基准的局限性。Gemini 2.5 Pro在该基准上取得了55.6%的F1分数，优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLM）的短期事实性，并解决现有OpenAI SimpleQA基准的局限性，如标签错误、主题偏差和问题冗余。

Method: 通过多阶段过滤流程（包括去重、主题平衡和来源核对）创建SimpleQA Verified基准，并改进了自动评分提示。

Result: Gemini 2.5 Pro在该基准上取得了55.6%的F1分数，超过了包括GPT-5在内的其他前沿模型。

Conclusion: SimpleQA Verified为研究界提供了一个更高保真度的工具，用于追踪参数模型事实性的真实进展并减少幻觉。

Abstract: We introduce SimpleQA Verified, a 1,000-prompt benchmark for evaluating Large
Language Model (LLM) short-form factuality based on OpenAI's SimpleQA. It
addresses critical limitations in OpenAI's benchmark, including noisy and
incorrect labels, topical biases, and question redundancy. SimpleQA Verified
was created through a rigorous multi-stage filtering process involving
de-duplication, topic balancing, and source reconciliation to produce a more
reliable and challenging evaluation set, alongside improvements in the
autorater prompt. On this new benchmark, Gemini 2.5 Pro achieves a
state-of-the-art F1-score of 55.6, outperforming other frontier models,
including GPT-5. This work provides the research community with a
higher-fidelity tool to track genuine progress in parametric model factuality
and to mitigate hallucinations. The benchmark dataset, evaluation code, and
leaderboard are available at:
https://www.kaggle.com/benchmarks/deepmind/simpleqa-verified.

</details>


### [113] [Parallel-R1: Towards Parallel Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.07980)
*Tong Zheng,Hongming Zhang,Wenhao Yu,Xiaoyang Wang,Xinyu Yang,Runpeng Dai,Rui Liu,Huiwen Bao,Chengsong Huang,Heng Huang,Dong Yu*

Main category: cs.CL

TL;DR: 该研究提出了第一个基于强化学习（RL）的框架Parallel-R1，用于训练大型语言模型（LLM）的并行思考能力，以解决复杂推理任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于合成数据的监督微调（SFT），这限制了模型的探索和泛化能力。因此，需要一种新的方法来有效训练LLM的并行思考能力。

Method: Parallel-R1框架采用渐进式课程学习策略。首先，使用SFT在简单任务的提示生成轨迹上进行训练，以赋予模型并行思考的能力。然后，过渡到RL，在更复杂的任务上探索和泛化此技能。

Result: 在MATH、AMC23和AIME等数学基准测试中，Parallel-R1的准确率比直接在具有挑战性任务上进行RL训练的顺序思考模型提高了8.4%。该模型在早期阶段将并行思考用作探索策略，在后期则用于多角度验证。将并行思考作为一种中期探索支架，可以使RL后的性能上限提高42.9%。

Conclusion: Parallel-R1成功地为LLM注入了并行思考能力，并在数学推理任务上取得了显著的性能提升。并行思考可以作为一种临时的探索机制，以解锁更高的性能上限。

Abstract: Parallel thinking has emerged as a novel approach for enhancing the reasoning
capabilities of large language models (LLMs) by exploring multiple reasoning
paths concurrently. However, activating such capabilities through training
remains challenging, as existing methods predominantly rely on supervised
fine-tuning (SFT) over synthetic data, which encourages teacher-forced
imitation rather than exploration and generalization. Different from them, we
propose \textbf{Parallel-R1}, the first reinforcement learning (RL) framework
that enables parallel thinking behaviors for complex real-world reasoning
tasks. Our framework employs a progressive curriculum that explicitly addresses
the cold-start problem in training parallel thinking with RL. We first use SFT
on prompt-generated trajectories from easier tasks to instill the parallel
thinking ability, then transition to RL to explore and generalize this skill on
harder problems. Experiments on various math benchmarks, including MATH, AMC23,
and AIME, show that Parallel-R1 successfully instills parallel thinking,
leading to 8.4% accuracy improvements over the sequential thinking model
trained directly on challenging tasks with RL. Further analysis reveals a clear
shift in the model's thinking behavior: at an early stage, it uses parallel
thinking as an exploration strategy, while in a later stage, it uses the same
capability for multi-perspective verification. Most significantly, we validate
parallel thinking as a \textbf{mid-training exploration scaffold}, where this
temporary exploratory phase unlocks a higher performance ceiling after RL,
yielding a 42.9% improvement over the baseline on AIME25. Our model, data, and
code will be open-source at https://github.com/zhengkid/Parallel-R1.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [114] [Autonomous Code Evolution Meets NP-Completeness](https://arxiv.org/abs/2509.07367)
*Cunxi Yu,Rongjian Liang,Chia-Tung Ho,Haoxing Ren*

Main category: cs.AI

TL;DR: SATLUTION是一个将LLM代码进化扩展到整个代码库规模的框架，旨在解决布尔可满足性（SAT）问题，并成功进化出超越人类设计的SAT求解器。


<details>
  <summary>Details</summary>
Motivation: LLM在代码生成和自我进化方面展现了强大能力，但先前工作（如AlphaEvolve）仅限于孤立的内核。本研究旨在将LLM的代码进化能力扩展到整个代码库规模，以解决像SAT这样复杂的NP完全问题。

Method: SATLUTION框架协调LLM代理，在严格的正确性保证和分布式运行时反馈下，直接进化SAT求解器代码库。该框架还能同时自我进化其进化策略和规则。其起点是SAT竞赛2024的代码库和基准测试。

Result: SATLUTION进化出的SAT求解器在SAT竞赛2025的比赛中，显著优于人类设计的获胜者。此外，在2024年的基准测试上，其性能也超越了2024年和2025年的冠军求解器。

Conclusion: SATLUTION成功地将LLM驱动的代码进化扩展到了整个代码库的规模，并在SAT求解器领域取得了显著成果，超越了现有的人类设计和LLM进化的方法。

Abstract: Large language models (LLMs) have recently shown strong coding abilities,
enabling not only static code generation but also iterative code self-evolving
through agentic frameworks. Recently, AlphaEvolve \cite{novikov2025alphaevolve}
demonstrated that LLM-based coding agents can autonomously improve algorithms
and surpass human experts, with scopes limited to isolated kernels spanning
hundreds of lines of code. Inspired by AlphaEvolve, we present SATLUTION, the
first framework to extend LLM-based code evolution to the full repository
scale, encompassing hundreds of files and tens of thousands of lines of C/C++
code. Targeting Boolean Satisfiability (SAT), the canonical NP-complete problem
and a cornerstone of both theory and applications. SATLUTION orchestrates LLM
agents to directly evolve solver repositories under strict correctness
guarantees and distributed runtime feedback, while simultaneously self-evolving
its own evolution policies and rules. Starting from SAT Competition 2024
codebases and benchmark, SATLUTION evolved solvers that decisively outperformed
the human-designed winners of the SAT Competition 2025, and also surpassed both
2024 and 2025 champions on the 2024 benchmarks.

</details>


### [115] [Renewable Energy Sources Selection Analysis with the Maximizing Deviation Method](https://arxiv.org/abs/2509.07011)
*Kirisci Murat*

Main category: cs.AI

TL;DR: 本研究提出了一种基于偏差最大化方法的优化模型，用于在区间值费马范德蒙德模糊环境中确定部分已知的特征权重，并将其应用于可再生能源选择问题。


<details>
  <summary>Details</summary>
Motivation: 多标准决策制定方法为决策者提供了在不确定、复杂和冲突的情况下做出更好决策的工具。模糊集理论处理人类思维和感知中的不确定性。本研究利用费马范德蒙德模糊环境，并将其与偏差最大化方法和区间值费马范德蒙德模糊集相结合，以解决可再生能源选择这一关键问题，同时考虑了其技术、管理和政治方面。

Method: 本研究提出了一种基于偏差最大化方法的优化模型，利用区间值费马范德蒙德模糊集来确定部分已知的特征权重。

Result: 所提出的方法已成功应用于可再生能源选择问题，展示了其在处理此类复杂决策中的有效性。

Conclusion: 本研究成功地将偏差最大化方法与区间值费马范德蒙德模糊集相结合，提出了一种用于确定特征权重并应用于可再生能源选择问题的新方法，并讨论了该问题的管理和政治影响。

Abstract: Multi-criteria decision-making methods provide decision-makers with
appropriate tools to make better decisions in uncertain, complex, and
conflicting situations. Fuzzy set theory primarily deals with the uncertainty
inherent in human thoughts and perceptions and attempts to quantify this
uncertainty. Fuzzy logic and fuzzy set theory are utilized with multi-criteria
decision-making methods because they effectively handle uncertainty and
fuzziness in decision-makers' judgments, allowing for verbal judgments of the
problem. This study utilizes the Fermatean fuzzy environment, a generalization
of fuzzy sets. An optimization model based on the deviation maximization method
is proposed to determine partially known feature weights. This method is
combined with interval-valued Fermatean fuzzy sets. The proposed method was
applied to the problem of selecting renewable energy sources. The reason for
choosing renewable energy sources is that meeting energy needs from renewable
sources, balancing carbon emissions, and mitigating the effects of global
climate change are among the most critical issues of the recent period. Even
though selecting renewable energy sources is a technical issue, the managerial
and political implications of this issue are also important, and are discussed
in this study.

</details>


### [116] [Language Self-Play For Data-Free Training](https://arxiv.org/abs/2509.07414)
*Jakub Grudzien Kuba,Mengting Gu,Qi Ma,Yuandong Tian,Vijai Mohan*

Main category: cs.AI

TL;DR: 通过自我博弈，语言模型可以在无需额外数据的情况下提升能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的进步面临数据瓶颈，需要更多数据进行学习。

Method: 提出一种基于博弈论的自我博弈（LSP）方法，让模型通过与自身竞争来提升性能。

Result: 在指令遵循基准测试中，Llama-3.2-3B-Instruct 模型通过自我博弈，性能得到提升，且效果优于数据驱动的基线。

Conclusion: 自我博弈是 LLMs 在不依赖额外数据的情况下提升能力的有效途径。

Abstract: Large language models (LLMs) have advanced rapidly in recent years, driven by
scale, abundant high-quality training data, and reinforcement learning. Yet
this progress faces a fundamental bottleneck: the need for ever more data from
which models can continue to learn. In this work, we propose a reinforcement
learning approach that removes this dependency by enabling models to improve
without additional data. Our method leverages a game-theoretic framework of
self-play, where a model's capabilities are cast as performance in a
competitive game and stronger policies emerge by having the model play against
itself - a process we call Language Self-Play (LSP). Experiments with
Llama-3.2-3B-Instruct on instruction-following benchmarks show that pretrained
models can not only enhance their performance on challenging tasks through
self-play alone, but can also do so more effectively than data-driven
baselines.

</details>


### [117] [From Eigenmodes to Proofs: Integrating Graph Spectral Operators with Symbolic Interpretable Reasoning](https://arxiv.org/abs/2509.07017)
*Andrew Kiruluta,Priscilla Burity*

Main category: cs.AI

TL;DR: Spectral NSR是一个全谱神经符号推理框架，将逻辑规则嵌入为谱模板，直接在图谱域中进行推理，在推理准确性、速度、鲁棒性和可解释性方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 结合符号推理的可解释性与谱学习的可扩展性和适应性，为下一代推理系统提供一个可扩展且有原则的基础。

Method: 通过利用图信号处理（GSP）和基于知识图谱的拉普拉斯特征结构的频率选择性滤波器，将逻辑规则嵌入为谱模板，并在图谱域中进行推理。框架还包括动态图和基础学习、理性与扩散滤波器、谱专家混合、基于证明的训练以及不确定性量化等扩展。

Result: 在ProofWriter和CLUTRR等推理基准上，Spectral NSR实现了更高的准确性、更快的推理速度、对对抗性扰动的鲁棒性以及更高的可解释性，优于包括Transformer、消息传递神经网络和神经符号逻辑编程系统在内的领先基线。模型决策与符号证明结构高度一致，迁移实验验证了通过协同谱对齐实现的有效领域适应。

Conclusion: Spectral NSR是一个可扩展且有原则的框架，为下一代推理系统提供了透明度、鲁棒性和泛化能力。

Abstract: We introduce Spectral NSR, a fully spectral neuro-symbolic reasoning
framework that embeds logical rules as spectral templates and performs
inference directly in the graph spectral domain. By leveraging graph signal
processing (GSP) and frequency-selective filters grounded in the Laplacian
eigenstructure of knowledge graphs, the architecture unifies the
interpretability of symbolic reasoning with the scalability and adaptability of
spectral learning. Beyond the core formulation, we incorporate a comprehensive
set of extensions, including dynamic graph and basis learning, rational and
diffusion filters for sharper spectral selectivity, mixture-of-spectral-experts
for modular specialization, proof-guided training with spectral curricula, and
uncertainty quantification for calibrated confidence. Additional enhancements
such as large language model coupling, co-spectral transfer alignment,
adversarial robustness, efficient GPU kernels, generalized Laplacians, and
causal interventions further expand the versatility of the framework.
  Empirical evaluation on state-of-the-art reasoning benchmarks such as
ProofWriter and CLUTRR demonstrates that Spectral NSR achieves superior
accuracy, faster inference, improved robustness to adversarial perturbations,
and higher interpretability compared to leading baselines including
transformers, message-passing neural networks, and neuro-symbolic logic
programming systems. Spectral attribution and proof-band agreement analyses
confirm that model decisions align closely with symbolic proof structures,
while transfer experiments validate effective domain adaptation through
co-spectral alignment. These results establish Spectral NSR as a scalable and
principled foundation for the next generation of reasoning systems, offering
transparency, robustness, and generalization beyond conventional approaches.

</details>


### [118] [Statistical Methods in Generative AI](https://arxiv.org/abs/2509.07054)
*Edgar Dobriban*

Main category: cs.AI

TL;DR: 生成式AI具有变革潜力，但缺乏正确性、安全性和公平性等保证。统计方法有望提高生成式AI的可靠性、评估质量和效率，并用于干预和实验设计。本文回顾了相关工作、讨论了局限性和未来方向。


<details>
  <summary>Details</summary>
Motivation: 生成式AI技术有潜力在多个领域带来变革，但其基于概率模型采样，默认缺乏正确性、安全性、公平性等方面的保证。因此，需要提高其可靠性。

Method: 本文回顾了将统计方法应用于生成式AI的现有工作，解释了所使用的通用统计技术及其在生成式AI中的应用。

Result: 本文探讨了统计方法在提高生成式AI的可靠性、评估质量和效率方面的潜力，并讨论了其在干预和实验设计中的应用。

Conclusion: 统计方法为提高生成式AI的可靠性、评估质量和效率提供了有前景的途径，并将在干预和实验设计中发挥重要作用。然而，仍存在局限性，需要进一步的研究来探索未来方向。

Abstract: Generative Artificial Intelligence is emerging as an important technology,
promising to be transformative in many areas. At the same time, generative AI
techniques are based on sampling from probabilistic models, and by default,
they come with no guarantees about correctness, safety, fairness, or other
properties. Statistical methods offer a promising potential approach to improve
the reliability of generative AI techniques. In addition, statistical methods
are also promising for improving the quality and efficiency of AI evaluation,
as well as for designing interventions and experiments in AI.
  In this paper, we review some of the existing work on these topics,
explaining both the general statistical techniques used, as well as their
applications to generative AI. We also discuss limitations and potential future
directions.

</details>


### [119] [Instruction Agent: Enhancing Agent with Expert Demonstration](https://arxiv.org/abs/2509.07098)
*Yinheng Li,Hailey Hultquist,Justin Wagle,Kazuhito Koishida*

Main category: cs.AI

TL;DR: Instruction Agent是一个利用专家演示来解决复杂GUI任务的代理，通过提取指令并严格遵循演示轨迹来完成任务，并利用验证器和回溯器模块来提高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI代理在处理复杂任务、新UI元素、长序列动作和个性化轨迹时存在困难。

Method: 通过单一演示提取分步指令，并严格遵循演示轨迹执行。利用验证器和回溯器模块来理解动作结果和处理意外中断。

Result: 在OSWorld的一组实验任务中，Instruction Agent取得了60%的成功率，而其他排名靠前的代理均未能完成这些任务。

Conclusion: Instruction Agent是一个实用且可扩展的框架，弥合了当前GUI代理与可靠的现实世界GUI任务自动化之间的差距。

Abstract: Graphical user interface (GUI) agents have advanced rapidly but still
struggle with complex tasks involving novel UI elements, long-horizon actions,
and personalized trajectories. In this work, we introduce Instruction Agent, a
GUI agent that leverages expert demonstrations to solve such tasks, enabling
completion of otherwise difficult workflows. Given a single demonstration, the
agent extracts step-by-step instructions and executes them by strictly
following the trajectory intended by the user, which avoids making mistakes
during execution. The agent leverages the verifier and backtracker modules
further to improve robustness. Both modules are critical to understand the
current outcome from each action and handle unexpected interruptions(such as
pop-up windows) during execution. Our experiments show that Instruction Agent
achieves a 60% success rate on a set of tasks in OSWorld that all top-ranked
agents failed to complete. The Instruction Agent offers a practical and
extensible framework, bridging the gap between current GUI agents and reliable
real-world GUI task automation.

</details>


### [120] [Neuro-Symbolic Frameworks: Conceptual Characterization and Empirical Comparative Analysis](https://arxiv.org/abs/2509.07122)
*Sania Sinha,Tanawan Premsri,Danial Kamali,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: Neurosymbolic (NeSy) 框架结合了神经网络和符号表示与推理，但缺乏用户友好的工具和统一的框架。本文分析了现有 NeSy 框架的技术层面，并重点介绍了 DeepProbLog、Scallop 和 DomiKnowS 三个框架，旨在为该领域的研究提供基础，并激发新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 结合神经网络和符号推理的优势，以解决复杂问题，但现有方法存在学习曲线陡峭、工具匮乏等问题。

Method: 分析了现有 Neurosymbolic (NeSy) 框架的技术层面，包括符号表示语言、与神经网络模型的集成以及底层算法。重点介绍了 DeepProbLog、Scallop 和 DomiKnowS 三个框架，并识别了它们在各个方面的挑战。

Result: 对三个 NeSy 框架（DeepProbLog、Scallop 和 DomiKnowS）进行了分析，识别了它们在技术层面的优势和挑战，为评估其解决不同问题的能力奠定了基础。

Conclusion: 现有 NeSy 框架的研究主要集中在算法层面，而非提供通用的框架来实现声明式问题规约。本文的分析旨在为社区提供一个基础，以期激发新的思考和解决方案。

Abstract: Neurosymbolic (NeSy) frameworks combine neural representations and learning
with symbolic representations and reasoning. Combining the reasoning
capacities, explainability, and interpretability of symbolic processing with
the flexibility and power of neural computing allows us to solve complex
problems with more reliability while being data-efficient. However, this
recently growing topic poses a challenge to developers with its learning curve,
lack of user-friendly tools, libraries, and unifying frameworks. In this paper,
we characterize the technical facets of existing NeSy frameworks, such as the
symbolic representation language, integration with neural models, and the
underlying algorithms. A majority of the NeSy research focuses on algorithms
instead of providing generic frameworks for declarative problem specification
to leverage problem solving. To highlight the key aspects of Neurosymbolic
modeling, we showcase three generic NeSy frameworks - \textit{DeepProbLog},
\textit{Scallop}, and \textit{DomiKnowS}. We identify the challenges within
each facet that lay the foundation for identifying the expressivity of each
framework in solving a variety of problems. Building on this foundation, we aim
to spark transformative action and encourage the community to rethink this
problem in novel ways.

</details>


### [121] [Autoencoder-Based Denoising of Muscle Artifacts in ECG to Preserve Skin Nerve Activity (SKNA) for Cognitive Stress Detection](https://arxiv.org/abs/2509.07146)
*Farnoush Baghestani,Jihye Moon,Youngsun Kong,Ki Chon*

Main category: cs.AI

TL;DR: 本研究提出了一种基于深度学习的去噪方法，用于从受肌电图（EMG）污染的心电图（ECG）记录中提取皮肤神经活动（SKNA），以更准确地监测交感神经系统。


<details>
  <summary>Details</summary>
Motivation: 皮肤神经活动（SKNA）是监测交感神经系统（SNS）活动的重要指标，但其测量易受肌电图（EMG）污染，尤其是在有运动的情况下。现有的预处理方法在处理重叠的频谱成分时效果不佳。

Method: 提出了一种使用轻量级一维卷积自编码器（AE）和长短期记忆（LSTM）的去噪方法，用于从受EMG污染的ECG记录中重建干净的SKNA信号。该模型在留一法交叉验证框架下进行训练，并使用模拟的EMG噪声进行测试。

Result: 该方法在模拟噪声下提高了信噪比（最高可达9.65 dB），提高了SKNA的交叉相关性（从0.40提高到0.72），并能恢复具有生理意义的SKNA爆发特征（AUROC ≥ 0.96）。在区分基线和认知压力条件下，分类准确率达到91%-98%，与干净数据相当。

Conclusion: 基于深度学习的SKNA信号重建方法能够有效去除EMG干扰，保留关键的生理信息，从而在包含运动的真实环境中实现更鲁棒的SKNA监测。

Abstract: The sympathetic nervous system (SNS) plays a central role in regulating the
body's responses to stress and maintaining physiological stability. Its
dysregulation is associated with a wide range of conditions, from
cardiovascular disease to anxiety disorders. Skin nerve activity (SKNA)
extracted from high-frequency electrocardiogram (ECG) recordings provides a
noninvasive window into SNS dynamics, but its measurement is highly susceptible
to electromyographic (EMG) contamination. Traditional preprocessing based on
bandpass filtering within a fixed range (e.g., 500--1000 Hz) is susceptible to
overlapping EMG and SKNA spectral components, especially during sustained
muscle activity. We present a denoising approach using a lightweight
one-dimensional convolutional autoencoder with a long short-term memory (LSTM)
bottleneck to reconstruct clean SKNA from EMG-contaminated recordings. Using
clean ECG-derived SKNA data from cognitive stress experiments and EMG noise
from chaotic muscle stimulation recordings, we simulated contamination at
realistic noise levels (--4 dB, --8 dB signal-to-noise ratio) and trained the
model in the leave-one-subject-out cross-validation framework. The method
improved signal-to-noise ratio by up to 9.65 dB, increased cross correlation
with clean SKNA from 0.40 to 0.72, and restored burst-based SKNA features to
near-clean discriminability (AUROC $\geq$ 0.96). Classification of baseline
versus sympathetic stimulation (cognitive stress) conditions reached accuracies
of 91--98\% across severe noise levels, comparable to clean data. These results
demonstrate that deep learning--based reconstruction can preserve
physiologically relevant sympathetic bursts during substantial EMG
interference, enabling more robust SKNA monitoring in naturalistic,
movement-rich environments.

</details>


### [122] [PaVeRL-SQL: Text-to-SQL via Partial-Match Rewards and Verbal Reinforcement Learning](https://arxiv.org/abs/2509.07159)
*Heng Hao,Wenjun Hu,Oxana Verkholyak,Davoud Ataee Tarzanagh,Baruch Gutow,Sima Didari,Masoud Faraki,Hankyu Moon,Seungjai Min*

Main category: cs.AI

TL;DR: PaVeRL-SQL是一个结合了部分匹配奖励和口头强化学习的Text-to-SQL框架，通过两个独立的流水线（口头-RL和CoT-RL）在行业级数据库和复杂问题上提高了SQL执行的准确性，并在Spider、Spider 2.0和BIRD等基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 当前的Text-to-SQL方法在处理包含领域特定业务逻辑的行业级数据库和复杂问题时，其执行准确性仍然较低。PaVeRL-SQL旨在通过结合部分匹配奖励和口头强化学习来驱动语言模型（RLMs）在Text-to-SQL任务上的自我改进，以应对实际应用中的挑战。

Method: PaVeRL-SQL框架采用了两种流水线：（1）一个新设计的、带有分组自评估（口头-RL）的上下文学习框架，使用开源和闭源的大型语言模型（LLMs）作为基础模型；（2）一个思维链（CoT）强化学习流水线，使用一个小型基础模型（OmniSQL-7B），该模型通过特殊设计的奖励函数和两阶段强化学习进行训练。

Result: PaVeRL-SQL在Spider、Spider 2.0和BIRD等主流Text-to-SQL基准测试中取得了最先进（SOTA）的成果。在工业级的Spider2.0-SQLite基准测试中，口头-RL流水线比SOTA的准确性高出7.4%，CoT流水线则高出1.4%。使用混合SQL方言进行强化学习训练带来了显著的三倍收益，尤其是在训练数据有限的方言上。

Conclusion: PaVeRL-SQL框架在真实的工业约束条件下，提供了可靠的、最先进的Text-to-SQL能力。该框架通过结合部分匹配奖励和口头强化学习，有效地解决了现有Text-to-SQL方法的局限性，并在处理复杂SQL查询和行业级数据库方面表现出色。

Abstract: Text-to-SQL models allow users to interact with a database more easily by
generating executable SQL statements from natural-language questions. Despite
recent successes on simpler databases and questions, current Text-to-SQL
methods still suffer from low execution accuracy on industry-scale databases
and complex questions involving domain-specific business logic. We present
\emph{PaVeRL-SQL}, a framework that combines \emph{Partial-Match Rewards} and
\emph{Verbal Reinforcement Learning} to drive self-improvement in reasoning
language models (RLMs) for Text-to-SQL. To handle practical use cases, we adopt
two pipelines: (1) a newly designed in-context learning framework with group
self-evaluation (verbal-RL), using capable open- and closed-source large
language models (LLMs) as backbones; and (2) a chain-of-thought (CoT) RL
pipeline with a small backbone model (OmniSQL-7B) trained with a specially
designed reward function and two-stage RL. These pipelines achieve
state-of-the-art (SOTA) results on popular Text-to-SQL benchmarks -- Spider,
Spider 2.0, and BIRD. For the industrial-level Spider2.0-SQLite benchmark, the
verbal-RL pipeline achieves an execution accuracy 7.4\% higher than SOTA, and
the CoT pipeline is 1.4\% higher. RL training with mixed SQL dialects yields
strong, threefold gains, particularly for dialects with limited training data.
Overall, \emph{PaVeRL-SQL} delivers reliable, SOTA Text-to-SQL under realistic
industrial constraints. The code is available at
https://github.com/PaVeRL-SQL/PaVeRL-SQL.

</details>


### [123] [That's So FETCH: Fashioning Ensemble Techniques for LLM Classification in Civil Legal Intake and Referral](https://arxiv.org/abs/2509.07170)
*Quinten Steenhuis*

Main category: cs.AI

TL;DR: 该研究提出并评估了一种名为FETCH的法律问题分类器，并结合了混合LLM/ML模型和自动生成追问的功能，在419个真实案例数据上达到了97.37%的准确率（hits@2），优于GPT-5模型，有望降低法律服务成本并提高效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决法律援助申请者在寻求帮助时，因法律问题分类不准确而面临的延误、人身伤害、住房或子女监护权丧失等严重后果，本研究旨在提高法律问题分类的准确性。

Method: 本研究提出并评估了FETCH分类器，并采用了两种改进准确性的方法：1. 混合LLM/ML集成分类方法。 2. 自动生成追问以丰富初始问题描述。使用了419个真实世界的非营利律师推荐服务查询数据集。

Result: 在419个真实案例数据上，使用包含廉价模型的混合方法，实现了97.37%的分类准确率（hits@2），超越了当前最先进的GPT-5模型。

Conclusion: 本研究提出的FETCH分类器结合混合LLM/ML模型和自动追问生成技术，在法律问题分类方面取得了高准确率（hits@2为97.37%），优于GPT-5模型，显示出在降低用户引导成本和提高服务效率方面的巨大潜力。

Abstract: Each year millions of people seek help for their legal problems by calling a
legal aid program hotline, walking into a legal aid office, or using a lawyer
referral service. The first step to match them to the right help is to identify
the legal problem the applicant is experiencing. Misdirection has consequences.
Applicants may miss a deadline, experience physical abuse, lose housing or lose
custody of children while waiting to connect to the right legal help. We
introduce and evaluate the FETCH classifier for legal issue classification and
describe two methods for improving accuracy: a hybrid LLM/ML ensemble
classification method, and the automatic generation of follow-up questions to
enrich the initial problem narrative. We employ a novel data set of 419
real-world queries to a nonprofit lawyer referral service. Ultimately, we show
classification accuracy (hits@2) of 97.37\% using a mix of inexpensive models,
exceeding the performance of the current state-of-the-art GPT-5 model. Our
approach shows promise in significantly reducing the cost of guiding users of
the legal system to the right resource for their problem while achieving high
accuracy.

</details>


### [124] [A Hybrid CNN-LSTM Deep Learning Model for Intrusion Detection in Smart Grid](https://arxiv.org/abs/2509.07208)
*Abdulhakim Alsaiari,Mohammad Ilyas*

Main category: cs.AI

TL;DR: 本研究提出了一种结合CNN和LSTM的混合深度学习入侵检测系统（IDS），以提高智能电网的网络安全。


<details>
  <summary>Details</summary>
Motivation: 传统电网向智能电网的转变带来了可再生能源的整合和通信技术的应用，但也增加了智能电网遭受攻击的风险，可能导致隐私泄露、运行中断和大规模停电。SCADA协议对于实时数据收集和控制至关重要，但易受未经授权的访问和拒绝服务（DoS）等攻击。因此，提高智能电网的网络安全至关重要。

Method: 提出了一种混合深度学习模型，结合了卷积神经网络（CNN）的特征提取能力和长短期记忆（LSTM）网络的时序模式识别能力，用于构建入侵检测系统（IDS）。使用DNP3和IEC104入侵检测数据集对CNN-LSTM模型进行训练和测试，以识别和分类潜在的网络威胁。

Result: 与现有的深度学习方法相比，该CNN-LSTM模型在准确率、精确率、召回率和F1分数方面均有显著提升，检测准确率达到了99.70%。

Conclusion: 本研究提出的混合深度学习IDS在提高智能电网网络安全方面表现出色，能够有效检测和分类网络威胁。

Abstract: The evolution of the traditional power grid into the "smart grid" has
resulted in a fundamental shift in energy management, which allows the
integration of renewable energy sources with modern communication technology.
However, this interconnection has increased smart grids' vulnerability to
attackers, which might result in privacy breaches, operational interruptions,
and massive outages. The SCADA-based smart grid protocols are critical for
real-time data collection and control, but they are vulnerable to attacks like
unauthorized access and denial of service (DoS). This research proposes a
hybrid deep learning-based Intrusion Detection System (IDS) intended to improve
the cybersecurity of smart grids. The suggested model takes advantage of
Convolutional Neural Networks' (CNN) feature extraction capabilities as well as
Long Short-Term Memory (LSTM) networks' temporal pattern recognition skills.
DNP3 and IEC104 intrusion detection datasets are employed to train and test our
CNN-LSTM model to recognize and classify the potential cyber threats. Compared
to other deep learning approaches, the results demonstrate considerable
improvements in accuracy, precision, recall, and F1-score, with a detection
accuracy of 99.70%.

</details>


### [125] [BlendedNet: A Blended Wing Body Aircraft Dataset and Surrogate Model for Aerodynamic Predictions](https://arxiv.org/abs/2509.07209)
*Nicholas Sung,Steven Spreizer,Mohamed Elrefaie,Kaira Samuel,Matthew C. Jones,Faez Ahmed*

Main category: cs.AI

TL;DR: BlendedNet是一个包含999个混合体（BWB）几何模型的公开可用数据集，覆盖了约九种飞行条件，生成了8830个收敛的RANS模拟案例，每个案例包含9到1400万个单元。该数据集通过采样几何设计参数和飞行条件生成，并包含了研究升力和阻力所需的详细表面量。研究还引入了一个端到端的预测框架，首先使用PointNet回归器从表面点云预测几何参数，然后条件化一个FiLM网络来预测表面系数Cp、Cfx和Cfz。实验结果表明，在各种BWB模型上，表面预测误差较低。BlendedNet解决了非常规配置的数据稀缺性问题，并支持了用于空气动力学设计的、数据驱动的预测模型的研究。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决非常规空气动力学配置（如混合体）的数据稀缺性问题，并为数据驱动的空气动力学设计研究提供支持。

Method: 研究人员生成了一个名为BlendedNet的数据集，其中包含999个混合体（BWB）几何模型，并在约九种飞行条件下进行了模拟，生成了8830个收敛的RANS模拟案例。他们还开发了一个端到端的预测框架：首先使用PointNet回归器从表面点云预测几何参数，然后使用FiLM网络结合预测的几何参数和飞行条件来预测表面系数Cp、Cfx和Cfz。

Result: 实验结果表明，该预测框架在各种混合体模型上实现了较低的表面预测误差。

Conclusion: BlendedNet数据集解决了非常规配置的数据稀缺性问题，并且研究提出的端到端预测框架能够有效地进行空气动力学预测，为数据驱动的空气动力学设计研究开辟了道路。

Abstract: BlendedNet is a publicly available aerodynamic dataset of 999 blended wing
body (BWB) geometries. Each geometry is simulated across about nine flight
conditions, yielding 8830 converged RANS cases with the Spalart-Allmaras model
and 9 to 14 million cells per case. The dataset is generated by sampling
geometric design parameters and flight conditions, and includes detailed
pointwise surface quantities needed to study lift and drag. We also introduce
an end-to-end surrogate framework for pointwise aerodynamic prediction. The
pipeline first uses a permutation-invariant PointNet regressor to predict
geometric parameters from sampled surface point clouds, then conditions a
Feature-wise Linear Modulation (FiLM) network on the predicted parameters and
flight conditions to predict pointwise coefficients Cp, Cfx, and Cfz.
Experiments show low errors in surface predictions across diverse BWBs.
BlendedNet addresses data scarcity for unconventional configurations and
enables research on data-driven surrogate modeling for aerodynamic design.

</details>


### [126] [OmniAcc: Personalized Accessibility Assistant Using Generative AI](https://arxiv.org/abs/2509.07220)
*Siddhant Karki,Ethan Han,Nadim Mahmud,Suman Bhunia,John Femiani,Vaskar Raychoudhury*

Main category: cs.AI

TL;DR: OmniAcc是一个利用GPT-4、卫星图像和OpenStreetMap数据来识别、分类和绘制轮椅可达设施（如坡道和人行横道）的AI驱动导航系统。它提供个性化路线规划、实时免提导航和即时无障碍查询，准确率为97.5%，旨在帮助城市规划者和行动不便的用户，促进更具包容性的城市空间。


<details>
  <summary>Details</summary>
Motivation: 目前，有行动能力障碍的个体在城市环境中导航时，常常面临信息和工具缺乏的障碍。

Method: 利用GPT-4、卫星图像和OpenStreetMap数据，通过零样本学习和定制化提示，精确检测可达性设施，并支持通过结构化工作流进行验证。

Result: 该系统在人行横道检测方面实现了97.5%的准确率，并提供个性化路线规划、实时免提导航和即时可达性查询。

Conclusion: OmniAcc展示了人工智能在改善城市导航和创造更具包容性的城市空间方面的巨大潜力。

Abstract: Individuals with ambulatory disabilities often encounter significant barriers
when navigating urban environments due to the lack of accessible information
and tools. This paper presents OmniAcc, an AI-powered interactive navigation
system that utilizes GPT-4, satellite imagery, and OpenStreetMap data to
identify, classify, and map wheelchair-accessible features such as ramps and
crosswalks in the built environment. OmniAcc offers personalized route
planning, real-time hands-free navigation, and instant query responses
regarding physical accessibility. By using zero-shot learning and customized
prompts, the system ensures precise detection of accessibility features, while
supporting validation through structured workflows. This paper introduces
OmniAcc and explores its potential to assist urban planners and mobility-aid
users, demonstrated through a case study on crosswalk detection. With a
crosswalk detection accuracy of 97.5%, OmniAcc highlights the transformative
potential of AI in improving navigation and fostering more inclusive urban
spaces.

</details>


### [127] [HealthSLM-Bench: Benchmarking Small Language Models for Mobile and Wearable Healthcare Monitoring](https://arxiv.org/abs/2509.07260)
*Xin Wang,Ting Dang,Xinyu Zhang,Vassilis Kostakos,Michael J. Witbrock,Hong Jia*

Main category: cs.AI

TL;DR: SLMs在医疗预测任务上表现出与LLMs相当的性能，同时在效率和隐私方面有显著优势，但仍需解决类别不平衡和少样本学习的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于LLM的医疗解决方案在隐私、内存和延迟方面的挑战，探索小型语言模型（SLMs）在医疗预测任务中的潜力。

Method: 系统性地评估了SLMs在医疗预测任务中的零样本、少样本和指令微调方法，并将表现最佳的模型部署到移动设备上进行实际效率和性能评估。

Result: SLMs在医疗预测任务中取得了与LLMs相当的性能，并在效率和隐私方面实现了显著的提升。然而，在处理类别不平衡和少样本场景时仍存在挑战。

Conclusion: SLMs是下一代隐私保护医疗监控的有前景的解决方案，尽管目前仍存在一些不完善之处。

Abstract: Mobile and wearable healthcare monitoring play a vital role in facilitating
timely interventions, managing chronic health conditions, and ultimately
improving individuals' quality of life. Previous studies on large language
models (LLMs) have highlighted their impressive generalization abilities and
effectiveness in healthcare prediction tasks. However, most LLM-based
healthcare solutions are cloud-based, which raises significant privacy concerns
and results in increased memory usage and latency. To address these challenges,
there is growing interest in compact models, Small Language Models (SLMs),
which are lightweight and designed to run locally and efficiently on mobile and
wearable devices. Nevertheless, how well these models perform in healthcare
prediction remains largely unexplored. We systematically evaluated SLMs on
health prediction tasks using zero-shot, few-shot, and instruction fine-tuning
approaches, and deployed the best performing fine-tuned SLMs on mobile devices
to evaluate their real-world efficiency and predictive performance in practical
healthcare scenarios. Our results show that SLMs can achieve performance
comparable to LLMs while offering substantial gains in efficiency and privacy.
However, challenges remain, particularly in handling class imbalance and
few-shot scenarios. These findings highlight SLMs, though imperfect in their
current form, as a promising solution for next-generation, privacy-preserving
healthcare monitoring.

</details>


### [128] [Performative Thinking? The Brittle Correlation Between CoT Length and Problem Complexity](https://arxiv.org/abs/2509.07339)
*Vardhan Palod,Karthik Valmeekam,Kaya Stechly,Subbarao Kambhampati*

Main category: cs.AI

TL;DR: 中间令牌生成（ITG）或思维链（CoT）不一定反映问题难度，其长度可能与训练数据分布的距离相关，而非真正的“思考”努力。


<details>
  <summary>Details</summary>
Motivation: 探究中间令牌生成（ITG）在语言模型推理任务中的作用机制，特别是考察其是否真实反映问题难度。

Method: 训练Transformer模型处理A*搜索算法的派生轨迹，并使用A*算法计算出的操作数作为问题难度的精确度量。通过在不同难度和分布外的问题上评估模型，分析中间令牌长度与问题难度之间的相关性。

Result: 模型在简单问题上也会产生过长的推理轨迹，甚至失败。中间令牌长度与真实A*轨迹长度仅有松散的相关性，且相关性主要出现在接近训练分布的问题上，表明这可能是近似回忆而非自适应计算。

Conclusion: 中间令牌的长度并非问题难度的可靠指标，它更多地与问题实例的分布距离相关。这一发现挑战了关于ITG是“思考”的假设，并提醒我们不要将ITG系统（如R1）中较长的序列自动解读为“思考努力”。

Abstract: Intermediate token generation (ITG), where a model produces output before the
solution, has been proposed as a method to improve the performance of language
models on reasoning tasks. While these reasoning traces or Chain of Thoughts
(CoTs) are correlated with performance gains, the mechanisms underlying them
remain unclear. A prevailing assumption in the community has been to
anthropomorphize these tokens as "thinking", treating longer traces as evidence
of higher problem-adaptive computation. In this work, we critically examine
whether intermediate token sequence length reflects or correlates with problem
difficulty. To do so, we train transformer models from scratch on derivational
traces of the A* search algorithm, where the number of operations required to
solve a maze problem provides a precise and verifiable measure of problem
complexity. We first evaluate the models on trivial free-space problems,
finding that even for the simplest tasks, they often produce excessively long
reasoning traces and sometimes fail to generate a solution. We then
systematically evaluate the model on out-of-distribution problems and find that
the intermediate token length and ground truth A* trace length only loosely
correlate. We notice that the few cases where correlation appears are those
where the problems are closer to the training distribution, suggesting that the
effect arises from approximate recall rather than genuine problem-adaptive
computation. This suggests that the inherent computational complexity of the
problem instance is not a significant factor, but rather its distributional
distance from the training data. These results challenge the assumption that
intermediate trace generation is adaptive to problem difficulty and caution
against interpreting longer sequences in systems like R1 as automatically
indicative of "thinking effort".

</details>


### [129] [SheetDesigner: MLLM-Powered Spreadsheet Layout Generation with Rule-Based and Vision-Based Reflection](https://arxiv.org/abs/2509.07473)
*Qin Chen,Yuanyi Ren,Xiaojun Ma,Mugeng Liu,Han Shi,Dongmei Zhang*

Main category: cs.AI

TL;DR: 现有的电子表格布局自动化方法存在不足，本文提出了SheetDesigner框架，利用多模态大语言模型（MLLMs）结合规则和视觉推理来生成电子表格布局。


<details>
  <summary>Details</summary>
Motivation: 手动设计电子表格布局耗时耗力，需要自动化解决方案来提高效率，但现有方法未能很好地处理电子表格的离散网格结构和特有的数据依赖、上下文链接等语义关联。

Method: 本文首先对电子表格布局生成任务进行了形式化，并提出了包含七项标准的评估协议和包含3,326个电子表格的数据集。然后，介绍了一种名为SheetDesigner的框架，该框架使用多模态大语言模型（MLLMs），结合规则和视觉推理，实现了零样本、无需训练即可进行组件放置和内容填充。

Result: SheetDesigner在性能上超越了五个基线模型，效果提升至少22.6%。实验发现，MLLMs通过视觉模态能够很好地处理重叠和平衡问题，但在对齐方面存在不足，需要结合规则和视觉推理的混合策略。

Conclusion: SheetDesigner框架能够有效地生成电子表格布局，并且通过结合规则和视觉推理可以进一步提高性能。MLLMs在处理电子表格布局方面展现出巨大潜力，但仍需优化以应对特定挑战。

Abstract: Spreadsheets are critical to data-centric tasks, with rich, structured
layouts that enable efficient information transmission. Given the time and
expertise required for manual spreadsheet layout design, there is an urgent
need for automated solutions. However, existing automated layout models are
ill-suited to spreadsheets, as they often (1) treat components as axis-aligned
rectangles with continuous coordinates, overlooking the inherently discrete,
grid-based structure of spreadsheets; and (2) neglect interrelated semantics,
such as data dependencies and contextual links, unique to spreadsheets. In this
paper, we first formalize the spreadsheet layout generation task, supported by
a seven-criterion evaluation protocol and a dataset of 3,326 spreadsheets. We
then introduce SheetDesigner, a zero-shot and training-free framework using
Multimodal Large Language Models (MLLMs) that combines rule and vision
reflection for component placement and content population. SheetDesigner
outperforms five baselines by at least 22.6\%. We further find that through
vision modality, MLLMs handle overlap and balance well but struggle with
alignment, necessitates hybrid rule and visual reflection strategies. Our codes
and data is available at Github.

</details>


### [130] [Towards explainable decision support using hybrid neural models for logistic terminal automation](https://arxiv.org/abs/2509.07577)
*Riccardo DElia,Alberto Termine,Francesco Flammini*

Main category: cs.AI

TL;DR: 该研究提出了一种结合深度学习和系统动力学的方法，以提高交通物流的可解释性和预测准确性，同时保留因果关系和透明度。


<details>
  <summary>Details</summary>
Motivation: 深度学习在系统动力学建模中虽然提高了可扩展性和预测准确性，但牺牲了可解释性和因果可靠性，这在关键决策系统中是不可接受的。

Method: 提出了一种可解释的神经网络系统动力学建模框架，该框架结合了基于概念的可解释性、机械可解释性和因果机器学习技术，以构建在有意义且可操作的变量上运行的神经网络模型，同时保持传统系统动力学模型的因果基础和透明度。

Result: 通过将深度学习与可解释性技术相结合，实现了在保留因果关系和透明度的同时提高预测准确性和可扩展性。

Conclusion: 神经符号方法可以弥合黑盒预测模型与复杂动态环境中关键决策支持需求之间的差距，尤其是在工业物联网支持的系统动力学建模中。

Abstract: The integration of Deep Learning (DL) in System Dynamics (SD) modeling for
transportation logistics offers significant advantages in scalability and
predictive accuracy. However, these gains are often offset by the loss of
explainability and causal reliability $-$ key requirements in critical
decision-making systems. This paper presents a novel framework for
interpretable-by-design neural system dynamics modeling that synergizes DL with
techniques from Concept-Based Interpretability, Mechanistic Interpretability,
and Causal Machine Learning. The proposed hybrid approach enables the
construction of neural network models that operate on semantically meaningful
and actionable variables, while retaining the causal grounding and transparency
typical of traditional SD models. The framework is conceived to be applied to
real-world case-studies from the EU-funded project AutoMoTIF, focusing on
data-driven decision support, automation, and optimization of multimodal
logistic terminals. We aim at showing how neuro-symbolic methods can bridge the
gap between black-box predictive models and the need for critical decision
support in complex dynamical environments within cyber-physical systems enabled
by the industrial Internet-of-Things.

</details>


### [131] [Transferable Direct Prompt Injection via Activation-Guided MCMC Sampling](https://arxiv.org/abs/2509.07617)
*Minghui Li,Hao Zhang,Yechao Zhang,Wei Wan,Shengshan Hu,pei Xiaobing,Jing Wang*

Main category: cs.AI

TL;DR: 本研究提出了一种基于激活值的提示注入攻击框架，通过构建能量模型和使用马尔可夫链蒙特卡洛采样，实现了有效的黑盒攻击，提高了跨模型和跨任务的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 直接提示注入（DPI）攻击对大型语言模型（LLM）构成严重威胁，现有攻击方法存在局限性（白盒/灰盒方法不切实际，黑盒方法迁移性差）。

Method: 构建基于能量的模型（EBM），使用代理模型的激活值评估对抗性提示的质量。利用训练好的EBM，采用token级马尔可夫链蒙特卡洛（MCMC）采样来优化对抗性提示，实现无梯度黑盒攻击。

Result: 在五个主流LLM上实现了49.6%的攻击成功率（ASR），比人工构造的提示提高了34.6%，并且在未见过的任务场景中保持了36.6%的ASR。激活值与攻击有效性之间存在相关性。

Conclusion: 所提出的激活值引导的提示注入攻击框架能够实现有效的黑盒攻击，并具有良好的跨模型迁移性。激活值在利用可迁移漏洞方面起着关键作用。

Abstract: Direct Prompt Injection (DPI) attacks pose a critical security threat to
Large Language Models (LLMs) due to their low barrier of execution and high
potential damage. To address the impracticality of existing white-box/gray-box
methods and the poor transferability of black-box methods, we propose an
activations-guided prompt injection attack framework. We first construct an
Energy-based Model (EBM) using activations from a surrogate model to evaluate
the quality of adversarial prompts. Guided by the trained EBM, we employ the
token-level Markov Chain Monte Carlo (MCMC) sampling to adaptively optimize
adversarial prompts, thereby enabling gradient-free black-box attacks.
Experimental results demonstrate our superior cross-model transferability,
achieving 49.6% attack success rate (ASR) across five mainstream LLMs and 34.6%
improvement over human-crafted prompts, and maintaining 36.6% ASR on unseen
task scenarios. Interpretability analysis reveals a correlation between
activations and attack effectiveness, highlighting the critical role of
semantic patterns in transferable vulnerability exploitation.

</details>


### [132] [Getting In Contract with Large Language Models -- An Agency Theory Perspective On Large Language Model Alignment](https://arxiv.org/abs/2509.07642)
*Sascha Kaltenpoth,Oliver Müller*

Main category: cs.AI

TL;DR: LLM ATLAS是一个基于代理理论的框架，用于解决组织采用LLM时出现的AI对齐问题。


<details>
  <summary>Details</summary>
Motivation: 组织在采用LLM时可能面临信息不对称和LLM产生不当内容的风险，现有研究未能解决这些问题。

Method: 通过结合组织LLM采用阶段和代理理论进行概念文献分析。

Result: 1. 提出了一个针对组织LLM采用过程中AI对齐方法的扩展文献分析流程。 2. 提供了第一个LLM对齐问题的解决方案空间。

Conclusion: LLM ATLAS框架旨在通过解决信息不对称和提供对齐问题的解决方案来缓解组织在采用LLM时出现的AI对齐问题。

Abstract: Adopting Large language models (LLMs) in organizations potentially
revolutionizes our lives and work. However, they can generate off-topic,
discriminating, or harmful content. This AI alignment problem often stems from
misspecifications during the LLM adoption, unnoticed by the principal due to
the LLM's black-box nature. While various research disciplines investigated AI
alignment, they neither address the information asymmetries between
organizational adopters and black-box LLM agents nor consider organizational AI
adoption processes. Therefore, we propose LLM ATLAS (LLM Agency Theory-Led
Alignment Strategy) a conceptual framework grounded in agency (contract)
theory, to mitigate alignment problems during organizational LLM adoption. We
conduct a conceptual literature analysis using the organizational LLM adoption
phases and the agency theory as concepts. Our approach results in (1) providing
an extended literature analysis process specific to AI alignment methods during
organizational LLM adoption and (2) providing a first LLM alignment
problem-solution space.

</details>


### [133] [DeepGraphLog for Layered Neurosymbolic AI](https://arxiv.org/abs/2509.07665)
*Adem Kikaj,Giuseppe Marra,Floris Geerts,Robin Manhaeve,Luc De Raedt*

Main category: cs.AI

TL;DR: DeepGraphLog是一个新的神经符号AI框架，它通过图神经网络处理符号表示，实现了多层神经符号推理，可以处理任意顺序的神经和符号组件，并有效解决了现有神经符号系统在处理图结构数据时的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号AI框架（如DeepProbLog）存在固定的处理流程，即符号推理总是在神经网络处理之后进行，这限制了它们对复杂依赖关系，特别是在图等非结构化数据上的建模能力。

Method: 提出了一种名为DeepGraphLog的新型神经符号AI框架，该框架扩展了ProbLog，引入了图神经网络谓词，允许神经和符号组件以任意顺序进行多层推理。该框架将符号表示视为图，以便能够被图神经网络处理。

Result: 在规划、知识图谱补全（含远距离监督）和图神经网络表达能力的任务上展示了DeepGraphLog的能力，结果表明该框架能有效捕捉复杂的表示依赖关系，克服了现有神经符号系统的关键局限性。

Conclusion: DeepGraphLog通过将神经符号AI的应用扩展到图结构域，提供了一个更具表现力和灵活性的神经符号集成框架。

Abstract: Neurosymbolic AI (NeSy) aims to integrate the statistical strengths of neural
networks with the interpretability and structure of symbolic reasoning.
However, current NeSy frameworks like DeepProbLog enforce a fixed flow where
symbolic reasoning always follows neural processing. This restricts their
ability to model complex dependencies, especially in irregular data structures
such as graphs. In this work, we introduce DeepGraphLog, a novel NeSy framework
that extends ProbLog with Graph Neural Predicates. DeepGraphLog enables
multi-layer neural-symbolic reasoning, allowing neural and symbolic components
to be layered in arbitrary order. In contrast to DeepProbLog, which cannot
handle symbolic reasoning via neural methods, DeepGraphLog treats symbolic
representations as graphs, enabling them to be processed by Graph Neural
Networks (GNNs). We showcase the capabilities of DeepGraphLog on tasks in
planning, knowledge graph completion with distant supervision, and GNN
expressivity. Our results demonstrate that DeepGraphLog effectively captures
complex relational dependencies, overcoming key limitations of existing NeSy
systems. By broadening the applicability of neurosymbolic AI to
graph-structured domains, DeepGraphLog offers a more expressive and flexible
framework for neural-symbolic integration.

</details>


### [134] [Unleashing the True Potential of LLMs: A Feedback-Triggered Self-Correction with Long-Term Multipath Decoding](https://arxiv.org/abs/2509.07676)
*Jipeng Li,Zeyu Gao,Yubin Qi,Hande Dong,Weijian Chen,Qiang Lin*

Main category: cs.AI

TL;DR: LLM 的一个新框架 FTR，通过用户反馈和新的解码策略来提高准确性。


<details>
  <summary>Details</summary>
Motivation: LLM 在推理过程中容易生成不正确的内容，而现有的自我纠正方法受限于错误定位的指导信号和有限的推理深度。

Method: 提出了一种名为 FTR 的新框架，它结合了用户反馈和一种称为 LTM 解码的新解码策略。FTR 仅在收到用户负面反馈时才激活响应的重新生成，并采用 LTM 解码来系统地探索多个推理轨迹。

Result: 在数学推理和代码生成基准测试中，FTR 框架的性能持续且显著优于最先进的基于提示的自我纠正方法。

Conclusion: FTR 框架通过用户反馈和增强的解码策略有效地解决了 LLM 推理中的错误问题，并在各种基准测试中取得了显著的改进。

Abstract: Large Language Models (LLMs) have achieved remarkable performance across
diverse tasks, yet their susceptibility to generating incorrect content during
inference remains a critical unsolved challenge. While self-correction methods
offer potential solutions, their effectiveness is hindered by two inherent
limitations: (1) the absence of reliable guidance signals for error
localization, and (2) the restricted reasoning depth imposed by conventional
next-token decoding paradigms. To address these issues, we propose
Feedback-Triggered Regeneration (FTR), a novel framework that synergizes user
feedback with enhanced decoding dynamics. Specifically, FTR activates response
regeneration only upon receiving negative user feedback, thereby circumventing
error propagation from faulty self-assessment while preserving originally
correct outputs. Furthermore, we introduce Long-Term Multipath (LTM) decoding,
which enables systematic exploration of multiple reasoning trajectories through
delayed sequence evaluation, effectively overcoming the myopic decision-making
characteristic of standard next-token prediction. Extensive experiments on
mathematical reasoning and code generation benchmarks demonstrate that our
framework achieves consistent and significant improvements over
state-of-the-art prompt-based self-correction methods.

</details>


### [135] [FHIR-RAG-MEDS: Integrating HL7 FHIR with Retrieval-Augmented Large Language Models for Enhanced Medical Decision Support](https://arxiv.org/abs/2509.07706)
*Yildiray Kabak,Gokce B. Laleci Erturkmen,Mert Gencturk,Tuncay Namli,A. Anil Sinaci,Ruben Alcantud Corcoles,Cristina Gomez Ballesteros,Pedro Abizanda,Asuman Dogac*

Main category: cs.AI

TL;DR: FHIR-RAG-MEDS系统集成了HL7 FHIR和RAG，以改善基于证据的临床指南的个性化医疗决策支持。


<details>
  <summary>Details</summary>
Motivation: 现有医疗决策支持系统在集成RAG和HL7 FHIR等先进技术以增强临床决策方面有巨大潜力，但实际应用方面的研究有限。

Method: 提出FHIR-RAG-MEDS系统，该系统整合了HL7 FHIR和基于检索增强生成（RAG）的系统。

Result: 该系统旨在改善基于证据的临床指南的个性化医疗决策支持。

Conclusion: 在医疗决策支持系统中集成RAG和HL7 FHIR具有改善临床决策过程的潜力，但需要更多关于实际应用的关注。

Abstract: In this study, we propose FHIR-RAG-MEDS system that aims to integrate Health
Level 7 Fast Healthcare Interoperability Resources (HL7 FHIR) with a
Retrieval-Augmented Generation (RAG)-based system to improve personalized
medical decision support on evidence-based clinical guidelines, emphasizing the
need for research in practical applications. In the evolving landscape of
medical decision support systems, integrating advanced technologies such as RAG
and HL7 FHIR can significantly enhance clinical decision-making processes.
Despite the potential of these technologies, there is limited research on their
integration in practical applications.

</details>


### [136] [RIMO: An Easy-to-Evaluate, Hard-to-Solve Olympiad Benchmark for Advanced Mathematical Reasoning](https://arxiv.org/abs/2509.07711)
*Ziye Chen,Chengwei Qin,Yao Shu*

Main category: cs.AI

TL;DR: RIMO是一个新的奥数竞赛基准，它通过提供单一的整数答案或专家检查过的证明分解来解决现有基准的评估噪音问题，旨在更准确地评估大型语言模型（LLMs）的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的奥数竞赛基准存在评估噪音和潜在偏见（例如，答案格式不统一，依赖可能出错的解答），阻碍了对大型语言模型（LLMs）在奥数级别推理能力进行准确评估。

Method: RIMO包含两个部分：RIMO-N（将335个IMO问题改写为单一、唯一的整数答案，以便进行确定性正确性检查）和RIMO-P（包含456个证明题，其专家检查过的解答被分解为一系列子问题，通过自动化评分系统评估逐步推理过程）。

Result: 在对包括GPT-4o和Gemini 2.5 Flash在内的十种前沿LLMs进行基准测试后，发现尽管它们在旧的基准上表现出色，但在RIMO上的性能急剧下降，这表明当前LLMs的能力与真实的奥数推理水平之间存在显著差距。

Conclusion: RIMO通过提供一个具有挑战性且易于评估的基准，为未来的研究提供了一个高分辨率的衡量标准，明确了缩小我们发现的巨大推理差距的目标。

Abstract: As large language models (LLMs) reach high scores on established mathematical
benchmarks, such as GSM8K and MATH, the research community has turned to
International Mathematical Olympiad (IMO) problems to push the evaluation
frontier. However, existing Olympiad-level benchmarks suffer from practical
constraints that introduce grading noise and potential bias, such as
heterogeneous answer formats requiring model-based judges and a reliance on
potentially flawed solutions. We introduce RIMO, a two-track benchmark designed
to preserve peak Olympiad difficulty while eliminating this evaluation noise.
The first track, RIMO-N, rewrites 335 IMO problems to admit a single, unique
integer answer, allowing for deterministic correctness checking. The second
track, RIMO-P, features 456 proof problems with expert-checked solutions, which
are decomposed into a sequence of sub-problems to evaluate the step-by-step
reasoning process via an automated grading system. Our benchmarking of ten
frontier LLMs, including GPT-4o and Gemini 2.5 Flash, reveals that while these
systems excel on older benchmarks, their performance drops sharply on RIMO.
These results highlight a substantial gap between current LLM capabilities and
actual Olympiad-level reasoning. By providing a challenging yet
easy-to-evaluate suite, RIMO offers a high-resolution yardstick for future
research, presenting a clear target for closing the profound reasoning gap our
findings expose.

</details>


### [137] [BDPM: A Machine Learning-Based Feature Extractor for Parkinson's Disease Classification via Gut Microbiota Analysis](https://arxiv.org/abs/2509.07723)
*Bo Yu,Zhixiu Hua,Bo Zhao*

Main category: cs.AI

TL;DR: 该研究提出了一种基于肠道微生物组数据的机器学习方法BDPM，用于帕金森病的分类。


<details>
  <summary>Details</summary>
Motivation: 目前的帕金森病诊断方法存在误诊率高的问题，而肠道微生物组可能作为有潜力的生物标志物。现有的基于深度学习的方法存在局限性，因此需要更鲁棒的特征提取方法。

Method: 该研究首先识别差异丰度的分类群，然后提出了一种名为RFRE的特征选择框架，并设计了一个混合分类模型来捕捉微生物组数据中的时空模式。

Result: 研究成功提取了与帕金森病相关的肠道微生物组特征，并构建了一个分类模型。

Conclusion: 基于肠道微生物组的BDPM方法为帕金森病的早期预测和诊断提供了新的途径。

Abstract: Background: Parkinson's disease remains a major neurodegenerative disorder
with high misdiagnosis rates, primarily due to reliance on clinical rating
scales. Recent studies have demonstrated a strong association between gut
microbiota and Parkinson's disease, suggesting that microbial composition may
serve as a promising biomarker. Although deep learning models based ongut
microbiota show potential for early prediction, most approaches rely on single
classifiers and often overlook inter-strain correlations or temporal dynamics.
Therefore, there is an urgent need for more robust feature extraction methods
tailored to microbiome data. Methods: We proposed BDPM (A Machine
Learning-Based Feature Extractor for Parkinson's Disease Classification via Gut
Microbiota Analysis). First, we collected gut microbiota profiles from 39
Parkinson's patients and their healthy spouses to identify differentially
abundant taxa. Second, we developed an innovative feature selection framework
named RFRE (Random Forest combined with Recursive Feature Elimination),
integrating ecological knowledge to enhance biological interpretability.
Finally, we designed a hybrid classification model to capture temporal and
spatial patterns in microbiome data.

</details>


### [138] [The Carbon Footprint Wizard: A Knowledge-Augmented AI Interface for Streamlining Food Carbon Footprint Analysis](https://arxiv.org/abs/2509.07733)
*Mustafa Kaan Aslan,Reinout Heijungs,Filip Ilievski*

Main category: cs.AI

TL;DR: 该研究提出了一种结合生命周期评估（LCA）和知识增强人工智能（AI）的新方法，用于估算食品的“从摇篮到工厂”的碳足迹，并提供了一个可以与用户交互以探索食物碳影响的聊天机器人。


<details>
  <summary>Details</summary>
Motivation: 鉴于消费者、生产商和政策制定者对环境可持续性（特别是气候变化）日益增长的关注，以及传统生命周期评估（LCA）在处理复杂、不透明的供应链和碎片化数据时面临的挑战，本研究旨在开发一种更易于访问和交互的方法来量化食品的碳足迹。

Method: 本研究结合了生命周期评估（LCA）的最新进展、公开数据库以及知识增强人工智能技术（特别是检索增强生成），开发了一种估算食品从摇篮到工厂（cradle-to-gate）碳足迹的方法。此外，还设计了一个聊天机器人界面，允许用户与系统互动，探索复合餐的碳影响，并将结果与熟悉活动进行比较。

Result: 研究成功开发了一个概念验证系统，并通过一个实时网络演示展示了其能力，该系统能够处理任意食品项目并回答相关问题。演示突显了以易于理解的方式提供LCA见解的潜力和局限性，包括数据库的不确定性和AI可能出现的误解。

Conclusion: 本研究提出的方法通过结合LCA和AI技术，为食品碳足迹评估提供了一种更易于访问和交互的解决方案，尽管仍存在数据库不确定性和AI解释等方面的挑战，但该方法展示了在普及LCA信息方面的巨大潜力。

Abstract: Environmental sustainability, particularly in relation to climate change, is
a key concern for consumers, producers, and policymakers. The carbon footprint,
based on greenhouse gas emissions, is a standard metric for quantifying the
contribution to climate change of activities and is often assessed using life
cycle assessment (LCA). However, conducting LCA is complex due to opaque and
global supply chains, as well as fragmented data. This paper presents a
methodology that combines advances in LCA and publicly available databases with
knowledge-augmented AI techniques, including retrieval-augmented generation, to
estimate cradle-to-gate carbon footprints of food products. We introduce a
chatbot interface that allows users to interactively explore the carbon impact
of composite meals and relate the results to familiar activities. A live web
demonstration showcases our proof-of-concept system with arbitrary food items
and follow-up questions, highlighting both the potential and limitations - such
as database uncertainties and AI misinterpretations - of delivering LCA
insights in an accessible format.

</details>


### [139] [Certainty-Guided Reasoning in Large Language Models: A Dynamic Thinking Budget Approach](https://arxiv.org/abs/2509.07820)
*João Paulo Nogueira,Wentao Sun,Alonso Silva,Laith Zumot*

Main category: cs.AI

TL;DR: 研究提出了一种名为“Certainty-Guided Reasoning (CGR)”的新方法，通过引入一个“评论家”模型来评估模型的推理置信度，以在推理效率和准确性之间取得平衡，并在数学推理任务中取得了显著的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的LRLMs在解决复杂问题时有一个固定的思考额度，这可能导致效率低下或准确性不足。需要一种方法来动态调整推理过程，以平衡效率和可靠性。

Method: 提出了一种基于生成器/判别器框架的“评论家”模型。该模型会周期性地评估自身的推理过程，判断是否已达到足够高的置信度。如果置信度不足，则继续推理，直到满足预设的置信度阈值。这种机制允许在置信度高时提前终止，在置信度低时继续推理。

Result: 在AIME2024和AIME2025数据集上的实验表明，CGR方法在提高基线准确率的同时，减少了代币使用量。多种子评估结果显示CGR稳定可靠，降低了种子间的方差，并在基于惩罚的评分体系下提高了考试表现。代币节省分析表明CGR能够节省数百万代币，并且可以通过调整置信度阈值来实现效率和准确性之间的可调权衡。

Conclusion: 置信度是一个强大的信号，可以指示推理是否充分。通过将置信度整合到推理过程中，CGR使得大型推理语言模型更加适应、可信和资源高效，为在注重准确性和计算成本的领域中的实际应用铺平了道路。

Abstract: The rise of large reasoning language models (LRLMs) has unlocked new
potential for solving complex tasks. These models operate with a thinking
budget, that is, a predefined number of reasoning tokens used to arrive at a
solution. We propose a novel approach, inspired by the generator/discriminator
framework in generative adversarial networks, in which a critic model
periodically probes its own reasoning to assess whether it has reached a
confident conclusion. If not, reasoning continues until a target certainty
threshold is met. This mechanism adaptively balances efficiency and reliability
by allowing early termination when confidence is high, while encouraging
further reasoning when uncertainty persists. Through experiments on the
AIME2024 and AIME2025 datasets, we show that Certainty-Guided Reasoning (CGR)
improves baseline accuracy while reducing token usage. Importantly, extended
multi-seed evaluations over 64 runs demonstrate that CGR is stable, reducing
variance across seeds and improving exam-like performance under penalty-based
grading. Additionally, our token savings analysis shows that CGR can eliminate
millions of tokens in aggregate, with tunable trade-offs between certainty
thresholds and efficiency. Together, these findings highlight certainty as a
powerful signal for reasoning sufficiency. By integrating confidence into the
reasoning process, CGR makes large reasoning language models more adaptive,
trustworthy, and resource efficient, paving the way for practical deployment in
domains where both accuracy and computational cost matter.

</details>


### [140] [Aligning LLMs for the Classroom with Knowledge-Based Retrieval -- A Comparative RAG Study](https://arxiv.org/abs/2509.07846)
*Amay Jain,Liu Cui,Si Chen*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在教育中的应用需要解决信息准确性问题。本研究比较了两种检索增强生成（RAG）方法——基于向量的检索和基于图的检索——在课堂问答中的适用性，并考虑了教育因素和部署成本。


<details>
  <summary>Details</summary>
Motivation: 解决ChatGPT等大型语言模型在课堂上提供过时或错误信息的问题，探索更可靠的教育应用方式。

Method: 1. 建立了一个包含3176个问题的教育领域问答数据集EduScopeQA。
2. 评估了基于向量的检索（OpenAI Vector Search RAG）和基于图的检索（GraphRAG Global, GraphRAG Local）在不同类型教育问题上的表现。
3. 引入了一个包含经过系统性修改的教科书的数据集，以评估模型在面对不一致信息时的表现。
4. 设计了一个动态分支框架，根据问题类型动态选择最优的检索方法。

Result: 1. 基于向量的检索（OpenAI Vector Search RAG）作为低成本的通用模型，在快速事实检索方面表现良好。
2. 基于图的检索（GraphRAG Global）在回答主题性、具有教育意义的问题方面表现更优。
3. 在面对语料库完整性至关重要的场景（如修改后的教科书），GraphRAG Local 实现了最高的准确率。
4. 动态分支框架通过根据问题类型路由到最合适的检索方法，提高了整体的准确性和效率。

Conclusion: 在教育环境中，没有一种单一的RAG方法能完美适应所有场景。基于向量的检索适用于快速事实查询，而基于图的检索在处理复杂、主题性的问题以及确保信息准确性方面更胜一筹。通过采用动态分支框架，可以根据具体需求优化RAG在教育中的部署，从而在准确性和效率之间取得平衡。

Abstract: Large language models like ChatGPT are increasingly used in classrooms, but
they often provide outdated or fabricated information that can mislead
students. Retrieval Augmented Generation (RAG) improves reliability of LLMs by
grounding responses in external resources. We investigate two accessible RAG
paradigms, vector-based retrieval and graph-based retrieval to identify best
practices for classroom question answering (QA). Existing comparative studies
fail to account for pedagogical factors such as educational disciplines,
question types, and practical deployment costs. Using a novel dataset,
EduScopeQA, of 3,176 questions across academic subjects, we measure performance
on various educational query types, from specific facts to broad thematic
discussions. We also evaluate system alignment with a dataset of systematically
altered textbooks that contradict the LLM's latent knowledge. We find that
OpenAI Vector Search RAG (representing vector-based RAG) performs well as a
low-cost generalist, especially for quick fact retrieval. On the other hand,
GraphRAG Global excels at providing pedagogically rich answers to thematic
queries, and GraphRAG Local achieves the highest accuracy with the dense,
altered textbooks when corpus integrity is critical. Accounting for the 10-20x
higher resource usage of GraphRAG (representing graph-based RAG), we show that
a dynamic branching framework that routes queries to the optimal retrieval
method boosts fidelity and efficiency. These insights provide actionable
guidelines for educators and system designers to integrate RAG-augmented LLMs
into learning environments effectively.

</details>


### [141] [SCoder: Iterative Self-Distillation for Bootstrapping Small-Scale Data Synthesizers to Empower Code LLMs](https://arxiv.org/abs/2509.07858)
*Xinyu Zhang,Changzhi Zhou,Linmei Hu,Luhao Zhang,Xiancai Chen,Haomin Fu,Yang Yang,Mengdi Zhang*

Main category: cs.AI

TL;DR: 通过迭代自蒸馏方法，利用小规模开源语言模型（LLM）生成高质量代码指令数据，构建了SCoder模型，并在代码生成任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有代码大语言模型（LLMs）依赖昂贵的专有LLMs提取的指令数据进行微调，成本高昂。

Method: 提出一种新颖的迭代自蒸馏方法，利用小规模开源LLMs（如7B）作为高质量代码指令数据的合成器。通过多检查点采样、多方面评分策略以及基于梯度的影响估计方法来增强数据合成能力，并减少对专有LLMs的依赖。

Result: 基于小规模合成器生成的数据集，开发了SCoder模型系列，该系列模型在代码生成任务上达到了最先进的性能。

Conclusion: 该方法能有效利用小规模开源LLMs生成高质量代码指令数据，显著降低成本，并实现卓越的代码生成能力。

Abstract: Existing code large language models (LLMs) often rely on large-scale
instruction data distilled from proprietary LLMs for fine-tuning, which
typically incurs high costs. In this paper, we explore the potential of
small-scale open-source LLMs (e.g., 7B) as synthesizers for high-quality code
instruction data construction. We first observe that the data synthesis
capability of small-scale LLMs can be enhanced by training on a few superior
data synthesis samples from proprietary LLMs. Building on this, we propose a
novel iterative self-distillation approach to bootstrap small-scale LLMs,
transforming them into powerful synthesizers that reduce reliance on
proprietary LLMs and minimize costs. Concretely, in each iteration, to obtain
diverse and high-quality self-distilled data, we design multi-checkpoint
sampling and multi-aspect scoring strategies for initial data selection.
Furthermore, to identify the most influential samples, we introduce a
gradient-based influence estimation method for final data filtering. Based on
the code instruction datasets from the small-scale synthesizers, we develop
SCoder, a family of code generation models fine-tuned from DeepSeek-Coder.
SCoder models achieve state-of-the-art code generation capabilities,
demonstrating the effectiveness of our method.

</details>


### [142] [CP-Model-Zoo: A Natural Language Query System for Constraint Programming Models](https://arxiv.org/abs/2509.07867)
*Augustin Crespin,Ioannis Kostis,Hélène Verhaeghe,Pierre Schaus*

Main category: cs.AI

TL;DR: CP-Model-Zoo是一个利用专家模型库来辅助用户解决组合问题的新系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决约束编程（CP）领域中，建模语言复杂、全局约束众多以及模型构建困难等问题，使得非专家难以使用CP来解决组合问题。

Method: CP-Model-Zoo系统通过自然语言描述，检索数据库中最匹配的专家编写的源代码模型，以确保用户获得高质量的模型，并无需人工标注数据。

Result: 实验结果表明，该系统在根据用户输入的、不同复杂程度的问题描述检索正确模型方面，具有出色的准确性。

Conclusion: CP-Model-Zoo通过利用已有的专家模型库，降低了CP的使用门槛，提高了模型检索的准确性和效率。

Abstract: Constraint Programming and its high-level modeling languages have long been
recognized for their potential to achieve the holy grail of problem-solving.
However, the complexity of modeling languages, the large number of global
constraints, and the art of creating good models have often hindered
non-experts from choosing CP to solve their combinatorial problems. While
generating an expert-level model from a natural-language description of a
problem would be the dream, we are not yet there. We propose a tutoring system
called CP-Model-Zoo, exploiting expert-written models accumulated through the
years. CP-Model-Zoo retrieves the closest source code model from a database
based on a user's natural language description of a combinatorial problem. It
ensures that expert-validated models are presented to the user while
eliminating the need for human data labeling. Our experiments show excellent
accuracy in retrieving the correct model based on a user-input description of a
problem simulated with different levels of expertise.

</details>


### [143] [HiPhO: How Far Are (M)LLMs from Humans in the Latest High School Physics Olympiad Benchmark?](https://arxiv.org/abs/2509.07894)
*Fangchen Yu,Haiyuan Wan,Qianjia Cheng,Yuchen Zhang,Jiacheng Chen,Fujun Han,Yulun Wu,Junchi Yao,Ruilizhen Hu,Ning Ding,Yu Cheng,Tao Chen,Lei Bai,Dongzhan Zhou,Yun Luo,Ganqu Cui,Peng Ye*

Main category: cs.AI

TL;DR: HiPhO是一个新的物理竞赛基准，用于评估（M）LLM在高中物理竞赛中的表现，并与人类竞赛者进行比较。


<details>
  <summary>Details</summary>
Motivation: 现有的物理竞赛基准存在系统性不足和无法与人类直接比较的问题。HiPhO旨在弥补这些差距。

Method: HiPhO收集了最新的13场奥林匹克竞赛，采用官方评分标准进行细粒度评分，并根据官方奖牌标准对模型进行评级，以实现与人类竞赛者的直接比较。

Result: 评估结果显示，开源模型大多在铜牌水平或以下，闭源模型表现更好，但大多数模型仍与满分有显著差距。开源多模态模型表现不佳，开源语言模型有进步，闭源推理模型表现突出。

Conclusion: HiPhO揭示了开源模型与顶尖学生之间的显著差距，闭源推理模型强大的物理推理能力，以及模型仍有很大的改进空间。

Abstract: Recently, the physical capabilities of (M)LLMs have garnered increasing
attention. However, existing benchmarks for physics suffer from two major gaps:
they neither provide systematic and up-to-date coverage of real-world physics
competitions such as physics Olympiads, nor enable direct performance
comparison with humans. To bridge these gaps, we present HiPhO, the first
benchmark dedicated to high school physics Olympiads with human-aligned
evaluation. Specifically, HiPhO highlights three key innovations. (1)
Comprehensive Data: It compiles 13 latest Olympiad exams from 2024-2025,
spanning both international and regional competitions, and covering mixed
modalities that encompass problems spanning text-only to diagram-based. (2)
Professional Evaluation: We adopt official marking schemes to perform
fine-grained grading at both the answer and step level, fully aligned with
human examiners to ensure high-quality and domain-specific evaluation. (3)
Comparison with Human Contestants: We assign gold, silver, and bronze medals to
models based on official medal thresholds, thereby enabling direct comparison
between (M)LLMs and human contestants. Our large-scale evaluation of 30
state-of-the-art (M)LLMs shows that: across 13 exams, open-source MLLMs mostly
remain at or below the bronze level; open-source LLMs show promising progress
with occasional golds; closed-source reasoning MLLMs can achieve 6 to 12 gold
medals; and most models still have a significant gap from full marks. These
results highlight a substantial performance gap between open-source models and
top students, the strong physical reasoning capabilities of closed-source
reasoning models, and the fact that there is still significant room for
improvement. HiPhO, as a rigorous, human-aligned, and Olympiad-focused
benchmark for advancing multimodal physical reasoning, is open-source and
available at https://github.com/SciYu/HiPhO.

</details>


### [144] [Probing the Preferences of a Language Model: Integrating Verbal and Behavioral Tests of AI Welfare](https://arxiv.org/abs/2509.07961)
*Valen Tagliabue,Leonard Dung*

Main category: cs.AI

TL;DR: 本研究提出并测试了衡量语言模型（LM）福祉的新实验方法，通过比较模型对其偏好的口头报告与在虚拟环境中导航和选择对话主题时的行为表现。研究还考察了成本和奖励对行为的影响，以及模型对“幸福感”（衡量自主性和人生目标等状态）的福祉量表的响应是否在语义等价的提示中保持一致。


<details>
  <summary>Details</summary>
Motivation: 开发用于衡量语言模型（LM）福祉的新实验范式，并评估现有AI系统是否能以可衡量的福祉代理形式满足偏好。

Method: 比较模型对其偏好的口头报告与在虚拟环境中导航和选择对话主题时的行为表现。测试成本和奖励对行为的影响，并评估模型对幸福感量表的响应在语义等价提示中的一致性。

Result: 在不同模型和条件下，口头报告的偏好与行为表现之间存在一定程度的一致性，表明偏好满足可以作为AI系统福祉的经验衡量指标。然而，这种一致性在不同模型和条件下存在差异，并且对扰动不稳健。研究还提供了对模型行为的定性观察。

Conclusion: 本研究证明了在语言模型中进行福祉测量的可行性，尽管由于模型和条件之间的一致性差异以及对福祉和模型认知状态的不确定性，目前尚不确定所提出的方法是否成功衡量了模型的福祉状态。研究结果鼓励进一步探索这一领域。

Abstract: We develop new experimental paradigms for measuring welfare in language
models. We compare verbal reports of models about their preferences with
preferences expressed through behavior when navigating a virtual environment
and selecting conversation topics. We also test how costs and rewards affect
behavior and whether responses to an eudaimonic welfare scale - measuring
states such as autonomy and purpose in life - are consistent across
semantically equivalent prompts. Overall, we observed a notable degree of
mutual support between our measures. The reliable correlations observed between
stated preferences and behavior across conditions suggest that preference
satisfaction can, in principle, serve as an empirically measurable welfare
proxy in some of today's AI systems. Furthermore, our design offered an
illuminating setting for qualitative observation of model behavior. Yet, the
consistency between measures was more pronounced in some models and conditions
than others and responses were not consistent across perturbations. Due to
this, and the background uncertainty about the nature of welfare and the
cognitive states (and welfare subjecthood) of language models, we are currently
uncertain whether our methods successfully measure the welfare state of
language models. Nevertheless, these findings highlight the feasibility of
welfare measurement in language models, inviting further exploration.

</details>


### [145] [VISION: Robust and Interpretable Code Vulnerability Detection Leveraging Counterfactual Augmentation](https://arxiv.org/abs/2508.18933)
*David Egea,Barproda Halder,Sanghamitra Dutta*

Main category: cs.AI

TL;DR: VISION是一个统一的框架，用于通过生成反事实训练数据来增强图神经网络（GNNs）在源代码漏洞检测中的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 源代码漏洞检测至关重要，但现有的GNN方法受训练数据不平衡和标签噪声的限制，容易学习到虚假关联，泛化能力差。

Method: VISION框架通过以下方式运作：（1）利用大型语言模型（LLMs）生成反事实样本（即，经过少量语义修改但标签相反的样本）；（2）在配对的代码示例上进行有针对性的GNN训练；（3）利用基于图的可解释性来识别对漏洞预测至关重要的代码语句，同时忽略虚假语句。

Result: VISION框架显著提高了漏洞检测的性能，在CWE-20漏洞上，整体准确率从51.8%提升到97.8%，成对对比准确率从4.5%提升到95.8%，最差分组准确率从0.7%提升到85.5%。此外，还提出了新的评估指标，并发布了CWE-20-CFA基准数据集。框架还通过交互式可视化增强了透明度和可信度。

Conclusion: VISION通过生成反事实数据和利用图可解释性，成功解决了GNN在源代码漏洞检测中学习虚假关联的问题，实现了更鲁棒、更具泛化能力的检测，并提高了透明度和可信度。

Abstract: Automated detection of vulnerabilities in source code is an essential
cybersecurity challenge, underpinning trust in digital systems and services.
Graph Neural Networks (GNNs) have emerged as a promising approach as they can
learn structural and logical code relationships in a data-driven manner.
However, their performance is severely constrained by training data imbalances
and label noise. GNNs often learn 'spurious' correlations from superficial code
similarities, producing detectors that fail to generalize well to unseen
real-world data. In this work, we propose a unified framework for robust and
interpretable vulnerability detection, called VISION, to mitigate spurious
correlations by systematically augmenting a counterfactual training dataset.
Counterfactuals are samples with minimal semantic modifications but opposite
labels. Our framework includes: (i) generating counterfactuals by prompting a
Large Language Model (LLM); (ii) targeted GNN training on paired code examples
with opposite labels; and (iii) graph-based interpretability to identify the
crucial code statements relevant for vulnerability predictions while ignoring
spurious ones. We find that VISION reduces spurious learning and enables more
robust, generalizable detection, improving overall accuracy (from 51.8% to
97.8%), pairwise contrast accuracy (from 4.5% to 95.8%), and worst-group
accuracy (from 0.7% to 85.5%) on the Common Weakness Enumeration (CWE)-20
vulnerability. We further demonstrate gains using proposed metrics: intra-class
attribution variance, inter-class attribution distance, and node score
dependency. We also release CWE-20-CFA, a benchmark of 27,556 functions (real
and counterfactual) from the high-impact CWE-20 category. Finally, VISION
advances transparent and trustworthy AI-based cybersecurity systems through
interactive visualization for human-in-the-loop analysis.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [146] [Optimal streaming algorithm for detecting $\ell_2$ heavy hitters in random order streams](https://arxiv.org/abs/2509.07286)
*Santhoshini Velusamy,Huacheng Yu*

Main category: cs.DS

TL;DR: 对于随机排序流，我们提出了一种能够达到最优空间复杂度 $O((\log n)/\epsilon)$ 的算法，适用于 $\epsilon = \Omega(1/2^{\sqrt{\log n}})$ 的情况。我们还展示了对于部分随机排序流，在给定 $F_2$ 常数近似值的情况下，也可以实现相同的空间复杂度。


<details>
  <summary>Details</summary>
Motivation: 在流数据处理中，检测 $\ell_2$ 范数下的重度击打者是一个重要问题。现有的算法在空间复杂度方面存在提升空间，尤其是在 $\epsilon$ 较小的情况下。

Method: 本文提出的算法适用于随机排序流，并能在 $\epsilon = \Omega(1/2^{\sqrt{\log n}})$ 时达到最优空间复杂度 $O((\log n)/\epsilon)$。此外，还探讨了部分随机排序流的情况，并提出了在给定 $F_2$ 常数近似值下的解决方案。

Result: 对于随机排序流，算法在 $\epsilon = \Omega(1/2^{\sqrt{\log n}})$ 时实现了 $O((\log n)/\epsilon)$ 的最优空间复杂度。对于部分随机排序流，在附加条件下也达到了相同的空间复杂度。

Conclusion: 本文在 $\ell_2$ 重度击打者检测问题上取得了重要进展，尤其是在随机排序流和部分随机排序流方面，通过提出新的算法和分析，显著提升了空间效率，并逼近了理论下界。

Abstract: Given a stream $x_1,x_2,\dots,x_n$ of items from a Universe $U$ of size
$\mathsf{poly}(n)$, and a parameter $\epsilon>0$, an item $i\in U$ is said to
be an $\ell_2$ heavy hitter if its frequency $f_i$ in the stream is at least
$\sqrt{\epsilon F_2}$, where $F_2=\sqrt{\sum_{i\in U} f_i^2}$. The classical
$\mathsf{CountSketch}$ algorithm due to Charikar, Chen, and Farach-Colton
[2004], was the first algorithm to detect $\ell_2$ heavy hitters using
$O\left(\frac{\log^2 n}{\epsilon}\right)$ bits of space, and their algorithm is
optimal for streams with deletions. For insertion-only streams, Braverman,
Chestnut, Ivkin, Nelson, Wang, and Woodruff [2017] gave the $\mathsf{BPTree}$
algorithm which requires only $O\left(\frac{\log(1/\epsilon)}{\epsilon}\log n
\right)$ space. Note that any algorithm requires at least
$O\left(\frac{1}{\epsilon} \log n\right)$ space to output $O(1/\epsilon)$ heavy
hitters in the worst case. So for constant $\epsilon$, the space usage of the
$\mathsf{BPTree}$ algorithm is optimal but their bound could be sub-optimal for
$\epsilon=o(1)$. In this work, we show that for random order streams, where the
stream elements can be adversarial but their order of arrival is uniformly
random, it is possible to achieve the optimal space bound of
$O\left(\frac{1}{\epsilon} \log n\right)$ for every $\epsilon =
\Omega\left(\frac{1}{2^{\sqrt{\log n}}}\right)$. We also show that for
partially random order streams where only the heavy hitters are required to be
uniformly distributed in the stream, it is possible to achieve the same space
bound, but with an additional assumption that the algorithm is given a constant
approximation to $F_2$ in advance.

</details>


### [147] [Dimension Reduction for Clustering: The Curious Case of Discrete Centers](https://arxiv.org/abs/2509.07444)
*Shaofeng H. -C. Jiang,Robert Krauthgamer,Shay Sapir,Sandeep Silwal,Di Yue*

Main category: cs.DS

TL;DR: Johnson-Lindenstrauss 变换在欧氏空间中是一种基本降维方法，可以将 n 个点的任何数据集映射到 O(log n) 维度，同时保持距离的低失真。对于特定问题，我们可以绕过这个维度限制。对于聚类问题，特别是在可以从环境空间 $\mathbb{R}^d$ 中选择中心的连续情况下，已经取得了巨大的进展。特别是，对于 k-median 和 k-means，维度限制已提高到 O(log k)。


<details>
  <summary>Details</summary>
Motivation: 本文探索离散设置中的聚类降维，其中中心只能从数据集中选择。

Method: 本文提出了两种结果，都由数据集的加倍维度 dd ddim 参数化。第一个结果表明，维度 $O_{\epsilon}(\operatorname{ddim} + \log k + \log\log n)$ 就足够了，并且是紧的，可以保证每个中心集的成本在 $1 \pm \epsilon$ 因子内得到保留。第二个结果通过放宽保证（即仅为所有近似最优中心集保留成本）消除了维度中的 $\log\log n$ 项，这对于下游应用仍然有用。

Result: 我们实现了离散设置中的强降维，并发现它与连续设置不同，不仅在维度限制上（这取决于加倍维度），而且在保留最优值以外的保证方面（例如，保留哪些聚类）。

Conclusion: 本文在离散设置中实现了强降维，并发现其与连续设置不同，维度限制取决于加倍维度，并且在保留最优值以外的保证方面也存在差异。

Abstract: The Johnson-Lindenstrauss transform is a fundamental method for dimension
reduction in Euclidean spaces, that can map any dataset of $n$ points into
dimension $O(\log n)$ with low distortion of their distances. This dimension
bound is tight in general, but one can bypass it for specific problems. Indeed,
tremendous progress has been made for clustering problems, especially in the
\emph{continuous} setting where centers can be picked from the ambient space
$\mathbb{R}^d$. Most notably, for $k$-median and $k$-means, the dimension bound
was improved to $O(\log k)$ [Makarychev, Makarychev and Razenshteyn, STOC
2019].
  We explore dimension reduction for clustering in the \emph{discrete} setting,
where centers can only be picked from the dataset, and present two results that
are both parameterized by the doubling dimension of the dataset, denoted as
$\operatorname{ddim}$. The first result shows that dimension
$O_{\epsilon}(\operatorname{ddim} + \log k + \log\log n)$ suffices, and is
moreover tight, to guarantee that the cost is preserved within factor
$1\pm\epsilon$ for every set of centers. Our second result eliminates the
$\log\log n$ term in the dimension through a relaxation of the guarantee
(namely, preserving the cost only for all approximately-optimal sets of
centers), which maintains its usefulness for downstream applications.
  Overall, we achieve strong dimension reduction in the discrete setting, and
find that it differs from the continuous setting not only in the dimension
bound, which depends on the doubling dimension, but also in the guarantees
beyond preserving the optimal value, such as which clusterings are preserved.

</details>


### [148] [The General Expiration Streaming Model: Diameter, $k$-Center, Counting, Sampling, and Friends](https://arxiv.org/abs/2509.07587)
*Lotte Blank,Sergio Cabello,MohammadTaghi Hajiaghayi,Robert Krauthgamer,Sepideh Mahabadi,André Nusser,Jeff M. Phillips,Jonas Sauer*

Main category: cs.DS

TL;DR: 该论文提出了一种新的过期模型，并为几种基本问题（如近似计数、均匀采样和加权采样）设计了算法，以及用于直径和 k-中心问题的算法，该模型扩展了现有的滑动窗口模型。


<details>
  <summary>Details</summary>
Motivation: 研究数据流算法在项目仅在有限时间内有效的场景下的应用，并提出一种新的过期模型，其中每个项目都有自己的过期时间。

Method: 引入了一种新的过期模型，并为近似计数、均匀采样、加权采样、直径和 k-中心问题设计了算法。该方法包括有效跟踪活动项目而不存储它们，以及使用分解、协调和几何支配技术来过滤冗余点。

Result: 提出了适用于过期流模型的近似计数、均匀采样和加权采样算法。对于直径和 k-中心问题，提出的算法扩展了现有的滑动窗口流结果，并在高维欧几里得空间中为直径问题提供了更好的近似因子。

Conclusion: 所提出的过期模型和算法为数据流算法领域带来了新的进展，特别是在处理具有过期项目的场景时，并在直径和 k-中心问题上取得了改进的性能。

Abstract: An important thread in the study of data-stream algorithms focuses on
settings where stream items are active only for a limited time. We introduce a
new expiration model, where each item arrives with its own expiration time. The
special case where items expire in the order that they arrive, which we call
consistent expirations, contains the classical sliding-window model of Datar,
Gionis, Indyk, and Motwani [SICOMP 2002] and its timestamp-based variant of
Braverman and Ostrovsky [FOCS 2007].
  Our first set of results presents algorithms (in the expiration streaming
model) for several fundamental problems, including approximate counting,
uniform sampling, and weighted sampling by efficiently tracking active items
without explicitly storing them all. Naturally, these algorithms have many
immediate applications to other problems.
  Our second and main set of results designs algorithms (in the expiration
streaming model) for the diameter and $k$-center problems, where items are
points in a metric space. Our results significantly extend those known for the
special case of sliding-window streams by Cohen-Addad, Schwiegelshohn, and
Sohler [ICALP 2016], including also a strictly better approximation factor for
the diameter in the important special case of high-dimensional Euclidean space.
We develop new decomposition and coordination techniques along with a geometric
dominance framework, to filter out redundant points based on both temporal and
spatial proximity.

</details>


### [149] [Tight Bounds for Low-Error Frequency Moment Estimation and the Power of Multiple Passes](https://arxiv.org/abs/2509.07599)
*Naomi Green-Maimon,Or Zamir*

Main category: cs.DS

TL;DR: 该论文解决了在流数据处理中估计第二频率矩F2的小误差（ε < 1/√n）问题，确定了在ε ≥ 1/n^2时最优空间复杂度为Θ(min(n, 1/ε^2)·(1 + |log(ε^2n)|))比特。


<details>
  <summary>Details</summary>
Motivation: 解决流数据处理中估计第二频率矩F2在小误差（ε < 1/√n）情况下的最优空间复杂度问题，并探索了集合相交大小估计的双向通信复杂性。

Method: 通过分析集合相交大小估计的双向通信复杂性，推导出F2估计的小误差情况下的最优空间复杂度。提出了一种两遍流算法，可以在O(n log log n)比特空间内精确计算流的直方图。

Result: 确定了在ε ≥ 1/n^2时，F2估计的最优空间复杂度为Θ(min(n, 1/ε^2)·(1 + |log(ε^2n)|))比特。证明了当ε < n^{-1/2-Ω(1)}时，单向通信协议在估计集合相交大小方面具有Ω(n log n)的下界。提出了一种两遍流算法，使用O(n log log n)比特空间计算精确直方图。

Conclusion: 小误差下的F2估计需要存储几乎整个流。单向通信协议在集合相交大小估计方面比双向通信协议需要更多的空间。两遍流算法在空间复杂度上优于单遍流算法，实现了F2估计在单遍和多遍情况下的渐近分离。

Abstract: Estimating the second frequency moment $F_2$ of a data stream up to a $(1 \pm
\varepsilon)$ factor is a central problem in the streaming literature. For
errors $\varepsilon > \Omega(1/\sqrt{n})$, the tight bound
$\Theta\left(\log(\varepsilon^2 n)/\varepsilon^2\right)$ was recently
established by Braverman and Zamir. In this work, we complete the picture by
resolving the remaining regime of small error, $\varepsilon < 1/\sqrt{n}$,
showing that the optimal space complexity is $\Theta\left( \min\left(n,
\frac{1}{\varepsilon^2} \right) \cdot \left(1 + \left| \log(\varepsilon^2 n)
\right| \right) \right)$ bits for all $\varepsilon \geq 1/n^2$, assuming a
sufficiently large universe. This closes the gap between the best known
$\Omega(n)$ lower bound and the straightforward $O(n \log n)$ upper bound in
that range, and shows that essentially storing the entire stream is necessary
for high-precision estimation.
  To derive this bound, we fully characterize the two-party communication
complexity of estimating the size of a set intersection up to an arbitrary
additive error $\varepsilon n$. In particular, we prove a tight $\Omega(n \log
n)$ lower bound for one-way communication protocols when $\varepsilon <
n^{-1/2-\Omega(1)}$, in contrast to classical $O(n)$-bit protocols that use
two-way communication. Motivated by this separation, we present a two-pass
streaming algorithm that computes the exact histogram of a stream with high
probability using only $O(n \log \log n)$ bits of space, in contrast to the
$\Theta(n \log n)$ bits required in one pass even to approximate $F_2$ with
small error. This yields the first asymptotic separation between one-pass and
$O(1)$-passes space complexity for small frequency moment estimation.

</details>


### [150] [Proximity Graphs for Similarity Search: Fast Construction, Lower Bounds, and Euclidean Separation](https://arxiv.org/abs/2509.07732)
*Shangqi Lu,Yufei Tao*

Main category: cs.DS

TL;DR: 本论文提出了新的邻近图方法，用于近似最近邻搜索，该方法在边数、查询时间和构建时间方面均优于现有方法，并在欧氏空间中进一步优化了图的大小。


<details>
  <summary>Details</summary>
Motivation: 现有基于邻近图的近似最近邻搜索方法在构建时间和边数方面存在瓶颈，促使本研究探索更优的理论基础和算法。

Method: 提出了一种新的邻近图构建算法，用于$(1+\epsilon)$-ANN搜索，该算法的边数为 $O((1/\epsilon)^\lambda 
cdot n 	ext{ log } 
Delta)$，查询时间为 $(1/\epsilon)^\lambda 	ext{ polylog } 
Delta$。同时，论文还提供了最坏情况下的边数下界，并针对欧氏空间提出了进一步优化的图构建算法，将图的大小减少到 $O((1/\epsilon)^\lambda 
cdot n)$。

Result: 在$(1+\epsilon)$-ANN搜索方面，提出的邻近图算法的边数、查询时间和构建时间均优于先前方法。对于欧氏空间，算法将图的大小减至 $O((1/\epsilon)^\lambda 
cdot n)$，同时保持了接近的查询和构建时间。

Conclusion: 本研究为邻近图的近似最近邻搜索提供了新的理论见解和高效算法。虽然非几何输入的下界表明了邻近图的局限性，但通过利用欧氏空间的几何特性，成功地减小了图的大小，并保持了算法的效率。

Abstract: Proximity graph-based methods have emerged as a leading paradigm for
approximate nearest neighbor (ANN) search in the system community. This paper
presents fresh insights into the theoretical foundation of these methods. We
describe an algorithm to build a proximity graph for $(1+\epsilon)$-ANN search
that has $O((1/\epsilon)^\lambda \cdot n \log \Delta)$ edges and guarantees
$(1/\epsilon)^\lambda \cdot \text{polylog }\Delta$ query time. Here, $n$ and
$\Delta$ are the size and aspect ratio of the data input, respectively, and
$\lambda = O(1)$ is the doubling dimension of the underlying metric space. Our
construction time is near-linear to $n$, improving the $\Omega(n^2)$ bounds of
all previous constructions. We complement our algorithm with lower bounds
revealing an inherent limitation of proximity graphs: the number of edges needs
to be at least $\Omega((1/\epsilon)^\lambda \cdot n + n \log \Delta)$ in the
worst case, up to a subpolynomial factor. The hard inputs used in our
lower-bound arguments are non-geometric, thus prompting the question of whether
improvement is possible in the Euclidean space (a key subclass of metric
spaces). We provide an affirmative answer by using geometry to reduce the graph
size to $O((1/\epsilon)^\lambda \cdot n)$ while preserving nearly the same
query and construction time.

</details>


### [151] [Compressibility Measures and Succinct Data Structures for Piecewise Linear Approximations](https://arxiv.org/abs/2509.07827)
*Paolo Ferragina,Filippo Lari*

Main category: cs.DS

TL;DR: 为分段线性逼近（PLA）引入了新的压缩和索引存储数据结构，提供了理论下界和近乎最优的空间效率。


<details>
  <summary>Details</summary>
Motivation: 研究如何为分段线性逼近（PLA）导出可压缩性度量，以优化学习数据结构中的空间-时间权衡。

Method: 提出并证明了用于PLA的压缩和索引存储的下界，并设计了实现这些下界的数据结构。

Result: 实现了在空间上近乎最优且具有高效检索功能的数据结构，并提供了强大的理论保证。

Conclusion: 提供了对基于PLA的学习数据结构可实现的最大压缩率的首次理论分析，并提出了新的、具有理论保证且易于实现的PLA存储方案。

Abstract: We study the problem of deriving compressibility measures for \emph{Piecewise
Linear Approximations} (PLAs), i.e., error-bounded approximations of a set of
two-dimensional {\em increasing} data points using a sequence of segments. Such
approximations are widely used tools in implementing many \emph{learned data
structures}, which mix learning models with traditional algorithmic design
blocks to exploit regularities in the underlying data distribution, providing
novel and effective space-time trade-offs.
  We introduce the first lower bounds to the cost of storing PLAs in two
settings, namely {\em compression} and {\em indexing}. We then compare these
compressibility measures to known data structures, and show that they are
asymptotically optimal up to a constant factor from the space lower bounds.
Finally, we design the first data structures for the aforementioned settings
that achieve the space lower bounds plus small additive terms, which turn out
to be {\em succinct} in most practical cases. Our data structures support the
efficient retrieval and evaluation of a segment in the (compressed) PLA for a
given $x$-value, which is a core operation in any learned data structure
relying on PLAs.
  As a result, our paper offers the first theoretical analysis of the maximum
compressibility achievable by PLA-based learned data structures, and provides
novel storage schemes for PLAs offering strong theoretical guarantees while
also suggesting simple and efficient practical implementations.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [152] [HYLU: Hybrid Parallel Sparse LU Factorization](https://arxiv.org/abs/2509.07690)
*Xiaoming Chen*

Main category: cs.AR

TL;DR: HYLU是一种混合并行LU分解求解器，能高效处理稀疏线性系统，在多核共享内存架构上表现优于Intel MKL PARDISO。


<details>
  <summary>Details</summary>
Motivation: 为了在多核共享内存架构上高效地求解稀疏线性系统Ax=b。

Method: HYLU集成了混合数值核，以适应不同稀疏模式的系数矩阵，并基于混合并行LU分解。

Result: 在SuiteSparse Matrix Collection的34个稀疏矩阵上，HYLU在数值分解阶段的几何平均值比Intel MKL PARDISO快1.74倍（一次性求解）和2.26倍（重复求解）。

Conclusion: HYLU是一种高效的稀疏线性系统求解器，特别适用于多核共享内存环境，并在数值分解性能上超越了现有方案。

Abstract: This article introduces HYLU, a hybrid parallel LU factorization-based
general-purpose solver designed for efficiently solving sparse linear systems
(Ax=b) on multi-core shared-memory architectures. The key technical feature of
HYLU is the integration of hybrid numerical kernels so that it can adapt to
various sparsity patterns of coefficient matrices. Tests on 34 sparse matrices
from SuiteSparse Matrix Collection reveal that HYLU outperforms Intel MKL
PARDISO in the numerical factorization phase by geometric means of 1.74X (for
one-time solving) and 2.26X (for repeated solving). HYLU can be downloaded from
https://github.com/chenxm1986/hylu.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [153] [On design, analysis, and hybrid manufacturing of microstructured blade-like geometries](https://arxiv.org/abs/2509.07044)
*Pablo Antolin,Michael Barton,Georges-Pierre Bonneau,Annalisa Buffa,Amaia Calleja-Ochoa,Gershon Elber,Stefanie Elgeti,Gaizka Gómez Escudero,Alicia Gonzalez,Haizea González Barrio,Stefanie Hahmann,Thibaut Hirschler,Q Youn Honga,Konstantin Key,Myung-Soo Kim,Michael Kofler,Norberto Lopez de Lacalle,Silvia de la Maza,Kanika Rajain,Jacques Zwar*

Main category: cs.GR

TL;DR: 该研究提出了一种新的CAD对象生成方法，该方法允许对象包含异质的自由形态内部微结构，而不是传统的单一实体材料。这种方法利用了多材料3D打印等新技术，能够制造出更轻、更便宜但功能相同的对象。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在挑战传统的几何CAD范式，探索包含异质内部微结构的新一代CAD对象，以适应新的制造技术（如多材料3D打印）带来的可能性。

Method: 研究提出了一个包含设计、优化、制造和检测微结构自由形态几何体的统一制造流程。

Result: 该流程在叶轮叶片（blisk blade）的工业测试案例中得到了验证，该叶片在满足预定压力限制的同时，显著减少了材料使用量，与实心部件相比。

Conclusion: 新一代CAD对象可以通过包含异质内部微结构来优化性能和材料使用，这在多材料3D打印等先进制造技术的支持下是可行的。

Abstract: With the evolution of new manufacturing technologies such as multi-material
3D printing, one can think of new type of objects that consist of considerably
less, yet heterogeneous, material, consequently being porous, lighter and
cheaper, while having the very same functionality as the original object when
manufactured from one single solid material. We aim at questioning five decades
of traditional paradigms in geometric CAD and focus at new generation of CAD
objects that are not solid, but contain heterogeneous free-form internal
microstructures. We propose a unified manufacturing pipeline that involves all
stages, namely design, optimization, manufacturing, and inspection of
microstructured free-form geometries. We demonstrate our pipeline on an
industrial test case of a blisk blade that sustains the desired pressure
limits, yet requires significantly less material when compared to the solid
counterpart.

</details>


### [154] [SVGauge: Towards Human-Aligned Evaluation for SVG Generation](https://arxiv.org/abs/2509.07127)
*Leonardo Zini,Elia Frigieri,Sebastiano Aloscari,Marcello Generali,Lorenzo Dodi,Robert Dosen,Lorenzo Baraldi*

Main category: cs.GR

TL;DR: SVGauge是第一个用于文本到SVG生成的、与人类对齐的、基于参考的指标，它通过结合视觉保真度和语义一致性来评估SVG图像，并在SHE基准测试中表现出与人类判断的高度相关性。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成评估指标（如FID、LPIPS、CLIPScore）无法满足SVG图像的符号和矢量特性要求，因此需要开发新的评估标准。

Method: SVGauge结合了两种方法：1. 视觉保真度：提取SigLIP图像嵌入，并通过PCA和白化进行域对齐。2. 语义一致性：比较SVG图像生成的标题与原始提示在SBERT和TF-IDF联合空间中的相似度。

Result: 在SHE基准测试中，SVGauge与人类判断的相关性最高，并且比现有指标更忠实地重现了八个零样本LLM生成器的系统级排名。

Conclusion: 向量图生成需要特定的评估方法，SVGauge为此类生成模型的基准测试提供了一个实用的工具。

Abstract: Generated Scalable Vector Graphics (SVG) images demand evaluation criteria
tuned to their symbolic and vectorial nature: criteria that existing metrics
such as FID, LPIPS, or CLIPScore fail to satisfy. In this paper, we introduce
SVGauge, the first human-aligned, reference based metric for text-to-SVG
generation. SVGauge jointly measures (i) visual fidelity, obtained by
extracting SigLIP image embeddings and refining them with PCA and whitening for
domain alignment, and (ii) semantic consistency, captured by comparing
BLIP-2-generated captions of the SVGs against the original prompts in the
combined space of SBERT and TF-IDF. Evaluation on the proposed SHE benchmark
shows that SVGauge attains the highest correlation with human judgments and
reproduces system-level rankings of eight zero-shot LLM-based generators more
faithfully than existing metrics. Our results highlight the necessity of
vector-specific evaluation and provide a practical tool for benchmarking future
text-to-SVG generation models.

</details>


### [155] [Efficient Computation of Voronoi Diagrams Using Point-in-Cell Tests](https://arxiv.org/abs/2509.07175)
*Yanyang Xiao,Yao Li,Juan Cao,Zhonggui Chen*

Main category: cs.GR

TL;DR: 提出一种计算有界Voronoi图（裁剪或受限Voronoi图）的新型高效方法，通过基于边的搜索方案查找裁剪平面（平分线），并利用点在元胞测试来确定裁剪的必要性，从而仅执行对最终结果有贡献的裁剪。该方法可扩展到GPU并行计算，并在实验中显示出优于现有技术的性能。


<details>
  <summary>Details</summary>
Motivation: 提高Voronoi图计算的效率，特别是针对有界域的Voronoi图（裁剪或受限Voronoi图）。

Method: 提出一种基于边的搜索方案来查找裁剪平面（平分线）。首先设置一个点在元胞测试来判断空间点是否在目标Voronoi元胞内。然后，对于中间的域-元胞交集的每条边，仅当其两个端点分别在元胞内部和外部时，才启动裁剪，并且可以通过几次点在元胞测试找到用于裁剪的平分线。这种方法只涉及对最终结果有贡献的裁剪。

Result: 实验结果表明，无论站点分布如何，该方法在性能上都优于现有技术。

Conclusion: 所提出的方法通过只进行必要的裁剪，并且可以并行化到GPU上，显著提高了计算有界Voronoi图的效率和性能。

Abstract: Since the Voronoi diagram appears in many applications, the topic of
improving its computational efficiency remains attractive. We propose a novel
yet efficient method to compute Voronoi diagrams bounded by a given domain,
i.e., the clipped or restricted Voronoi diagrams. The intersection of the
domain and a Voronoi cell (domain-cell intersection) is generated by removing
the part outside the cell from the domain, which can be accomplished by several
clippings. Different from the existing methods, we present an edge-based search
scheme to find clipping planes (bisectors). A test called point-in-cell is
first set up to tell whether a space point is in a target Voronoi cell or not.
Then, for each edge of the intermediate domain-cell intersection, we will
launch a clipping only if its two endpoints are respectively inside and outside
the corresponding Voronoi cell, where the bisector for the clipping can be
found by using a few times of point-in-cell tests. Therefore, our method only
involves the clippings that contribute to the final results, which is a great
advantage over the state-of-the-art methods. Additionally, because each
domain-cell intersection can be generated independently, we extend the proposed
method to the GPUs for computing Voronoi diagrams in parallel. The experimental
results show the best performance of our method compared to state-of-the-art
ones, regardless of site distribution. This paper was first submitted to
SIGGRAPH Asia 2025.

</details>


### [156] [Neural Cone Radiosity for Interactive Global Illumination with Glossy Materials](https://arxiv.org/abs/2509.07522)
*Jierui Ren,Haojie Jin,Bo Pang,Yisong Chen,Guoping Wang,Sheng Li*

Main category: cs.GR

TL;DR: 神经辐射度方法难以捕捉高频、视线相关的光照分布，提出基于反射率感知的射线锥编码（神经锥辐射度）以改进。


<details>
  <summary>Details</summary>
Motivation: 现有的神经辐射度方法难以捕捉高频、视线相关的光照分布，尤其是在处理光滑材质时。

Method: 提出一种基于神经辐射度框架、通过反射率感知的射线锥编码（神经锥辐射度）。使用预过滤的多分辨率哈希网格来近似光滑BSDF瓣，并通过连续空间聚合将视线相关的反射率特征直接嵌入编码过程。

Result: 该方法显著提高了网络模拟高频反射分布的能力，并能有效处理各种光泽度表面的材质。同时，降低了网络拟合复杂光照分布的负担，使整体架构保持紧凑高效。实验证明，该方法在各种光泽度条件下都能实时生成高质量、无噪点的渲染图，并且保真度和真实感优于基线方法。

Conclusion: 神经锥辐射度通过反射率感知的射线锥编码，有效解决了现有神经辐射度方法在处理高频、视线相关光照分布方面的局限性，实现了高质量、实时的渲染。

Abstract: Modeling of high-frequency outgoing radiance distributions has long been a
key challenge in rendering, particularly for glossy material. Such
distributions concentrate radiative energy within a narrow lobe and are highly
sensitive to changes in view direction. However, existing neural radiosity
methods, which primarily rely on positional feature encoding, exhibit notable
limitations in capturing these high-frequency, strongly view-dependent radiance
distributions. To address this, we propose a highly-efficient approach by
reflectance-aware ray cone encoding based on the neural radiosity framework,
named neural cone radiosity. The core idea is to employ a pre-filtered
multi-resolution hash grid to accurately approximate the glossy BSDF lobe,
embedding view-dependent reflectance characteristics directly into the encoding
process through continuous spatial aggregation. Our design not only
significantly improves the network's ability to model high-frequency reflection
distributions but also effectively handles surfaces with a wide range of
glossiness levels, from highly glossy to low-gloss finishes. Meanwhile, our
method reduces the network's burden in fitting complex radiance distributions,
allowing the overall architecture to remain compact and efficient.
Comprehensive experimental results demonstrate that our method consistently
produces high-quality, noise-free renderings in real time under various
glossiness conditions, and delivers superior fidelity and realism compared to
baseline approaches.

</details>


### [157] [Topology-Aware Optimization of Gaussian Primitives for Human-Centric Volumetric Videos](https://arxiv.org/abs/2509.07653)
*Yuheng Jiang,Chengcheng Guo,Yize Wu,Yu Hong,Shengkun Zhu,Zhehao Shen,Yingliang Zhang,Shaohui Jiao,Zhuo Su,Lan Xu,Marc Habermann,Christian Theobalt*

Main category: cs.GR

TL;DR: TaoGS是一种新的拓扑感知动态高斯表示，可以解开运动和外观，以支持长期跟踪和拓扑适应。


<details>
  <summary>Details</summary>
Motivation: 对涉及拓扑变化的动态场景进行稳健建模，并保持长期跟踪仍然是一个基本挑战。

Method: TaoGS通过稀疏运动高斯表示场景运动，并利用局部外观高斯捕捉细节纹理。它还引入了一个全局高斯查找表，以便与编解码器集成。

Result: TaoGS能够进行高保真渲染，即使在具有挑战性的场景下也能保持时间连贯性，并且可以实现高达40倍的压缩。

Conclusion: TaoGS为具有拓扑变化的动态视频提供了一个统一、自适应的解决方案，能够捕捉“动态中的优雅”和“静止中的力量”，从而提供与物理世界和谐相处的沉浸式体验。

Abstract: Volumetric video is emerging as a key medium for digitizing the dynamic
physical world, creating the virtual environments with six degrees of freedom
to deliver immersive user experiences. However, robustly modeling general
dynamic scenes, especially those involving topological changes while
maintaining long-term tracking remains a fundamental challenge. In this paper,
we present TaoGS, a novel topology-aware dynamic Gaussian representation that
disentangles motion and appearance to support, both, long-range tracking and
topological adaptation. We represent scene motion with a sparse set of motion
Gaussians, which are continuously updated by a spatio-temporal tracker and
photometric cues that detect structural variations across frames. To capture
fine-grained texture, each motion Gaussian anchors and dynamically activates a
set of local appearance Gaussians, which are non-rigidly warped to the current
frame to provide strong initialization and significantly reduce training time.
This activation mechanism enables efficient modeling of detailed textures and
maintains temporal coherence, allowing high-fidelity rendering even under
challenging scenarios such as changing clothes. To enable seamless integration
into codec-based volumetric formats, we introduce a global Gaussian Lookup
Table that records the lifespan of each Gaussian and organizes attributes into
a lifespan-aware 2D layout. This structure aligns naturally with standard video
codecs and supports up to 40 compression. TaoGS provides a unified, adaptive
solution for scalable volumetric video under topological variation, capturing
moments where "elegance in motion" and "Power in Stillness", delivering
immersive experiences that harmonize with the physical world.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [158] [Free Elections in the Free State: Ensemble Analysis of Redistricting in New Hampshire](https://arxiv.org/abs/2509.07328)
*Atticus McWhorter,Daryl DeFord*

Main category: cs.SI

TL;DR: 新罕布什尔州在2020年人口普查周期内的立法重新划分过程，以及全国许多其他州的类似过程，都引起了极大的争议。本文通过对已颁布的选区进行集成分析，为诉讼中关于这些地图的说法提供数学背景。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为新罕布什尔州立法重新划分的争议提供数学依据，并评估选区划分标准与党派结果之间的权衡。

Method: 通过操作化新罕布什尔州的重新划分规则并算法化生成大量重新划分方案，构建了一个衡量选区划分方案预期行为的基准，并以此评估非党派理由和地理权衡。

Result: 研究结果展示了用于分析党派对称性指标的选举数据的选择和聚合的影响。

Conclusion: 本研究通过数学分析为新罕布什尔州的重新划分争议提供了背景，并强调了数据选择对党派对称性分析的重要性。

Abstract: The process of legislative redistricting in New Hampshire, along with many
other states across the country, was particularly contentious during the 2020
census cycle. In this paper we present an ensemble analysis of the enacted
districts to provide mathematical context for claims made about these maps in
litigation. Operationalizing the New Hampshire redistricting rules and
algorithmically generating a large collection of districting plans allows us to
construct a baseline for expected behavior of districting plans in the state
and evaluate non-partisan justifications and geographic tradeoffs between
districting criteria and partisan outcomes. In addition, our results
demonstrate the impact of selection and aggregation of election data for
analyzing partisan symmetry measures.

</details>


### [159] [Influence Maximization Considering Influence, Cost and Time](https://arxiv.org/abs/2509.07625)
*Mingyang Feng,Qi Zhao,Shan He,Yuhui Shi*

Main category: cs.SI

TL;DR: 该研究提出了一种新的多目标影响最大化问题，同时优化影响、成本和时间，并开发了一种名为 EVEA 的进化算法来解决该问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽略了影响传播、成本效率和时间紧迫性之间的相互作用，而这在实际应用中至关重要。

Method: 提出了一种新的多目标影响最大化问题，并开发了一种进化可变长度搜索（EVEA）算法来寻找最优节点组合。

Result: EVEA 算法在四个真实世界网络上表现优于所有基线算法，超体积最高可提高 19.3%，收敛速度提高 25% 至 40%，同时在影响、成本和时间目标之间保持了多样化和平衡的帕累托前沿。

Conclusion: 该研究证明了多目标影响最大化问题的可行性和必要性，并提出了一种有效的进化算法 EVEA 来解决该问题。

Abstract: Influence maximization has been studied for social network analysis, such as
viral marketing (advertising), rumor prevention, and opinion leader
identification. However, most studies neglect the interplay between influence
spread, cost efficiency, and temporal urgency. In practical scenarios such as
viral marketing and information campaigns, jointly optimizing Influence, Cost,
and Time is essential, yet remaining largely unaddressed in current literature.
To bridge the gap, this paper proposes a new multi-objective influence
maximization problem that simultaneously optimizes influence, cost, and time.
We show the intuitive and empirical evidence to prove the feasibility and
necessity of this multi-objective problem. We also develop an evolutionary
variable-length search algorithm that can effectively search for optimal node
combinations. The proposed EVEA algorithm outperforms all baselines, achieving
up to 19.3% higher hypervolume and 25 to 40% faster convergence across four
real-world networks, while maintaining a diverse and balanced Pareto front
among influence, cost, and time objectives.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [160] [First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping](https://arxiv.org/abs/2509.07162)
*Martin Matak,Mohanraj Devendran Ashanti,Karl Van Wyk,Tucker Hermans*

Main category: cs.RO

TL;DR: 自主多指抓取是机器人操作中的一项基本能力。我们提出了一种并行规划轨迹到一组生成的目标抓取的方法，并使用向量化运动规划器来高效地规划到不同目标的轨迹。实验表明，我们的方法在抓取成功率和效率方面优于传统的生成器-评估器-规划器框架。


<details>
  <summary>Details</summary>
Motivation: 传统的基于优化的抓取方法对初始化敏感且耗时。生成器-评估器-规划器框架虽然是一种替代方案，但在执行较低排名的抓取时会降低成功率，并且多次轨迹优化会耗费大量时间。放宽运动规划精度会降低抓取成功率估计的准确性，而提高精度则会增加计算时间，这是一个两难的局面。

Method: 提出了一种新的框架，该框架并行地将轨迹规划到一组生成的目标抓取。评估器估计由此产生的轨迹的抓取成功可能性，然后机器人执行最有可能成功的轨迹。为了高效地规划到不同目标的轨迹，提出使用向量化运动规划器。

Result: 我们的方法在不同的物体、生成器和运动规划器上都优于传统的生成器-评估器-规划器框架，并成功地推广到了真实世界中的新环境，包括不同的架子和桌子高度。

Conclusion: 所提出的框架能够通过并行规划和向量化运动规划器，在提高抓取成功率的同时，减少计算时间。该方法在各种物体和环境中都表现出良好的泛化能力。

Abstract: Autonomous multi-finger grasping is a fundamental capability in robotic
manipulation. Optimization-based approaches show strong performance, but tend
to be sensitive to initialization and are potentially time-consuming. As an
alternative, the generator-evaluator-planner framework has been proposed. A
generator generates grasp candidates, an evaluator ranks the proposed grasps,
and a motion planner plans a trajectory to the highest-ranked grasp. If the
planner doesn't find a trajectory, a new trajectory optimization is started
with the next-best grasp as the target and so on. However, executing
lower-ranked grasps means a lower chance of grasp success, and multiple
trajectory optimizations are time-consuming. Alternatively, relaxing the
threshold for motion planning accuracy allows for easier computation of a
successful trajectory but implies lower accuracy in estimating grasp success
likelihood. It's a lose-lose proposition: either spend more time finding a
successful trajectory or have a worse estimate of grasp success. We propose a
framework that plans trajectories to a set of generated grasp targets in
parallel, the evaluator estimates the grasp success likelihood of the resulting
trajectories, and the robot executes the trajectory most likely to succeed. To
plan trajectories to different targets efficiently, we propose the use of a
vectorized motion planner. Our experiments show our approach improves over the
traditional generator-evaluator-planner framework across different objects,
generators, and motion planners, and successfully generalizes to novel
environments in the real world, including different shelves and table heights.
Project website https://sites.google.com/view/fpte

</details>


### [161] [Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators](https://arxiv.org/abs/2509.07216)
*Hassen Nigatu,Shi Gaokun,Li Jituo,Wang Jin,Lu Guodong,Howard Li*

Main category: cs.RO

TL;DR: 该研究提出了一种量子原生框架，结合量子机器学习和Grover算法，用于高效解决机器人运动学优化问题，并在多自由度机器人任务中实现了显著的加速。


<details>
  <summary>Details</summary>
Motivation: 高自由度机器人控制中的复杂高维构型空间搜索对于经典方法来说计算上具有挑战性。

Method: 使用参数化量子电路逼近正向运动学模型，构建用于识别最优构型的Oracle，并利用Grover算法进行搜索。

Result: 在1-DoF、2-DoF和双臂机械臂任务中，与Nelder Mead等经典优化器相比，该方法实现了高达93倍的速度提升，尤其在高维问题中表现突出。

Conclusion: 该研究为机器人运动学优化提供了一个基础性的、量子原生的框架，有效地连接了量子计算和机器人学问题。

Abstract: Optimizing high-degree of freedom robotic manipulators requires searching
complex, high-dimensional configuration spaces, a task that is computationally
challenging for classical methods. This paper introduces a quantum native
framework that integrates quantum machine learning with Grover's algorithm to
solve kinematic optimization problems efficiently. A parameterized quantum
circuit is trained to approximate the forward kinematics model, which then
constructs an oracle to identify optimal configurations. Grover's algorithm
leverages this oracle to provide a quadratic reduction in search complexity.
Demonstrated on 1-DoF, 2-DoF, and dual-arm manipulator tasks, the method
achieves significant speedups-up to 93x over classical optimizers like Nelder
Mead as problem dimensionality increases. This work establishes a foundational,
quantum-native framework for robot kinematic optimization, effectively bridging
quantum computing and robotics problems.

</details>


### [162] [Safe Gap-based Planning in Dynamic Settings](https://arxiv.org/abs/2509.07239)
*Max Asselmeier,Abdel Zaro,Dhruv Ahuja,Ye Zhao,Patricio A. Vela*

Main category: cs.RO

TL;DR: 该研究提出了一种名为 dynamic gap 的动态环境感知感知型局部规划器，通过显式处理动态障碍物来避免碰撞。


<details>
  <summary>Details</summary>
Motivation: 现有动态环境下的感知感知型局部规划器通常依赖于应急或经验性鲁棒性来进行碰撞避免，而不是对动态障碍物进行形式化分析。本研究旨在解决这一问题。

Method: 1. 跟踪自由空间中的极性区域（称为“间隙”），并估计其动态变化以了解局部环境如何随时间演变。
2. 在规划时，通过新的间隙传播算法将间隙传播到未来，以了解哪些区域可以通行。
3. 利用追踪制导理论生成在理想条件下可保证无碰撞的局部轨迹。
4. 在不存在间隙的情况下，执行以障碍物为中心的“反间隙”处理，以增强整体规划框架的鲁棒性。

Result: 在动态环境中，将提出的 dynamic gap 规划器与一系列经典和学习型运动规划器进行了基准测试。结果表明，dynamic gap 在所有环境中均优于所有其他基线规划器。此外，dynamic gap 在 TurtleBot2 平台上进行了实际部署，以验证其碰撞避免行为。

Conclusion: dynamic gap 规划器能够显式处理动态障碍物，在动态环境中提供可靠且可保证的无碰撞路径规划。

Abstract: This chapter extends the family of perception-informed gap-based local
planners to dynamic environments. Existing perception-informed local planners
that operate in dynamic environments often rely on emergent or empirical
robustness for collision avoidance as opposed to performing formal analysis of
dynamic obstacles. This proposed planner, dynamic gap, explicitly addresses
dynamic obstacles through several steps in the planning pipeline. First, polar
regions of free space known as gaps are tracked and their dynamics are
estimated in order to understand how the local environment evolves over time.
Then, at planning time, gaps are propagated into the future through novel gap
propagation algorithms to understand what regions are feasible for passage.
Lastly, pursuit guidance theory is leveraged to generate local trajectories
that are provably collision-free under ideal conditions. Additionally,
obstacle-centric ungap processing is performed in situations where no gaps
exist to robustify the overall planning framework. A set of gap-based planners
are benchmarked against a series of classical and learned motion planners in
dynamic environments, and dynamic gap is shown to outperform all other
baselines in all environments. Furthermore, dynamic gap is deployed on a
TurtleBot2 platform in several real-world experiments to validate collision
avoidance behaviors.

</details>


### [163] [Performance Characterization of a Point-Cloud-Based Path Planner in Off-Road Terrain](https://arxiv.org/abs/2509.07321)
*Casey D. Majhor,Jeremy P. Bos*

Main category: cs.RO

TL;DR: MUONS是一个基于点云的自主越野导航系统，在模拟和实际测试中表现出色，成功率高达0.98，并确定了Bi-RRT扩展半径是影响性能的关键参数。


<details>
  <summary>Details</summary>
Motivation: 自主越野导航

Method: 基于点云的导航堆栈MUONS，进行30,000次模拟和实地测试，分析了20种路径规划参数组合。

Result: 在模拟中成功率达到0.98，在实地测试中无失败。Bi-RRT扩展半径与规划时间和路径长度最相关。

Conclusion: 蒙特卡洛模拟可用于性能评估和参数调整。

Abstract: We present a comprehensive evaluation of a point-cloud-based navigation
stack, MUONS, for autonomous off-road navigation. Performance is characterized
by analyzing the results of 30,000 planning and navigation trials in simulation
and validated through field testing. Our simulation campaign considers three
kinematically challenging terrain maps and twenty combinations of seven
path-planning parameters. In simulation, our MUONS-equipped AGV achieved a 0.98
success rate and experienced no failures in the field. By statistical and
correlation analysis we determined that the Bi-RRT expansion radius used in the
initial planning stages is most correlated with performance in terms of
planning time and traversed path length. Finally, we observed that the
proportional variation due to changes in the tuning parameters is remarkably
well correlated to performance in field testing. This finding supports the use
of Monte-Carlo simulation campaigns for performance assessment and parameter
tuning.

</details>


### [164] [Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark](https://arxiv.org/abs/2509.07362)
*Yandi Yang,Jianping Li,Youqi Liao,Yuhao Li,Yizhe Zhang,Zhen Dong,Bisheng Yang,Naser El-Sheimy*

Main category: cs.RO

TL;DR: 本文提出了一个大规模数据集，集成了来自移动测绘系统（MMS）的地面图像和来自武汉、香港和旧金山三个城市的航空激光扫描（ALS）点云，以解决在密集城市环境中准确进行视觉定位的挑战。


<details>
  <summary>Details</summary>
Motivation: 准确的视觉定位在密集的城市环境中是一个基本任务，但由于纹理缺失、视角变化大和长期漂移等问题，视觉里程计的效果常受限制。利用航空激光扫描（ALS）数据作为先验地图可以提高视觉定位的精度和可扩展性，但现有方法在跨平台（航空与地面）的视觉定位方面存在数据、真值生成和算法验证方面的不足。

Method: 构建了一个包含地面影像（来自MMS）和航空激光扫描（ALS）点云的大规模数据集，并将其应用于解决跨平台视觉定位问题。

Result: 生成了一个包含来自武汉、香港和旧金山三个城市的、融合了地面影像和ALS点云的大规模数据集，为解决跨平台视觉定位问题提供了基础。

Conclusion: 通过构建跨平台的大规模数据集，为未来在密集城市环境中进行更精确、更可靠的视觉定位研究奠定了基础，并克服了现有研究在数据多样性、真值生成和跨平台验证方面的局限性。

Abstract: Accurate visual localization in dense urban environments poses a fundamental
task in photogrammetry, geospatial information science, and robotics. While
imagery is a low-cost and widely accessible sensing modality, its effectiveness
on visual odometry is often limited by textureless surfaces, severe viewpoint
changes, and long-term drift. The growing public availability of airborne laser
scanning (ALS) data opens new avenues for scalable and precise visual
localization by leveraging ALS as a prior map. However, the potential of
ALS-based localization remains underexplored due to three key limitations: (1)
the lack of platform-diverse datasets, (2) the absence of reliable ground-truth
generation methods applicable to large-scale urban environments, and (3)
limited validation of existing Image-to-Point Cloud (I2P) algorithms under
aerial-ground cross-platform settings. To overcome these challenges, we
introduce a new large-scale dataset that integrates ground-level imagery from
mobile mapping systems with ALS point clouds collected in Wuhan, Hong Kong, and
San Francisco.

</details>


### [165] [TransMPC: Transformer-based Explicit MPC with Variable Prediction Horizon](https://arxiv.org/abs/2509.07381)
*Sichao Wu,Jiang Wu,Xingyu Cao,Fawang Zhang,Guangyuan Yu,Junjie Zhao,Yue Qu,Fei Ma,Jingliang Duan*

Main category: cs.RO

TL;DR: TransMPC是一种基于Transformer的显式MPC算法，通过预计算和直接策略优化，实现了高精度、低延迟的实时控制，适用于复杂动态系统。


<details>
  <summary>Details</summary>
Motivation: 传统在线MPC计算复杂度高，显式MPC精度受限，本文旨在解决复杂系统实时控制的计算效率和精度问题。

Method: 提出了一种基于Encoder-only Transformer的MPC策略，利用双向自注意力机制一次性生成整个控制序列。引入了直接策略优化框架，通过采样和学习交替进行，并使用随机视界采样和回放缓冲区来优化真实有限视界成本。

Result: TransMPC在模拟和真实车辆控制实验中，在解的准确性、适应不同视界的能力以及计算效率方面都表现出了有效性。

Conclusion: TransMPC是一种有效的方法，可以解决传统MPC方法在计算复杂性和精度方面的限制，尤其适用于复杂动态系统。

Abstract: Traditional online Model Predictive Control (MPC) methods often suffer from
excessive computational complexity, limiting their practical deployment.
Explicit MPC mitigates online computational load by pre-computing control
policies offline; however, existing explicit MPC methods typically rely on
simplified system dynamics and cost functions, restricting their accuracy for
complex systems. This paper proposes TransMPC, a novel Transformer-based
explicit MPC algorithm capable of generating highly accurate control sequences
in real-time for complex dynamic systems. Specifically, we formulate the MPC
policy as an encoder-only Transformer leveraging bidirectional self-attention,
enabling simultaneous inference of entire control sequences in a single forward
pass. This design inherently accommodates variable prediction horizons while
ensuring low inference latency. Furthermore, we introduce a direct policy
optimization framework that alternates between sampling and learning phases.
Unlike imitation-based approaches dependent on precomputed optimal
trajectories, TransMPC directly optimizes the true finite-horizon cost via
automatic differentiation. Random horizon sampling combined with a replay
buffer provides independent and identically distributed (i.i.d.) training
samples, ensuring robust generalization across varying states and horizon
lengths. Extensive simulations and real-world vehicle control experiments
validate the effectiveness of TransMPC in terms of solution accuracy,
adaptability to varying horizons, and computational efficiency.

</details>


### [166] [Attention and Risk-Aware Decision Framework for Safe Autonomous Driving](https://arxiv.org/abs/2509.07412)
*Zhen Tian,Fujiang Yuan,Yangfan He,Qinghao Li,Changlin Chen,Huilin Chen,Tianxiang Xu,Jianyu Duan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 本论文提出一种改进的近端策略优化（PPO）算法，通过引入风险感知机制、风险注意决策网络、平衡奖励函数和安全辅助机制，提高了自动驾驶的训练效率和安全性，有效避免碰撞，缩短了训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有PPO算法在自动驾驶任务中存在训练结果差、训练效率低以及在长序列中表现不佳的问题，并且训练结果差等同于实际驾驶中的碰撞。本研究旨在解决这些问题，提高自动驾驶的性能和安全性。

Method: 本研究提出了一种改进的PPO算法，结合了风险感知机制、风险注意决策网络、平衡奖励函数和安全辅助机制。风险感知机制用于识别潜在碰撞区域；风险注意网络增强了对输入图像高风险区域的通道和空间注意力；平衡奖励函数根据周围车辆数量调整奖励以促进探索；安全辅助机制则在车道保持和变道过程中监督和防止有碰撞风险的动作。

Result: 在物理引擎的仿真结果表明，所提出的算法在碰撞避免方面优于基准算法，在更短的训练时间内达到了更高的峰值奖励，并且在多种交通流场景下，风险区域的驾驶时间更短。

Conclusion: 本研究提出的改进PPO算法能够有效解决现有PPO在自动驾驶中的局限性，显著提高了碰撞规避能力、训练效率和学习性能，为实现更安全、高效的自动驾驶提供了有力的支持。

Abstract: Autonomous driving has attracted great interest due to its potential
capability in full-unsupervised driving. Model-based and learning-based methods
are widely used in autonomous driving. Model-based methods rely on pre-defined
models of the environment and may struggle with unforeseen events. Proximal
policy optimization (PPO), an advanced learning-based method, can adapt to the
above limits by learning from interactions with the environment. However,
existing PPO faces challenges with poor training results, and low training
efficiency in long sequences. Moreover, the poor training results are
equivalent to collisions in driving tasks. To solve these issues, this paper
develops an improved PPO by introducing the risk-aware mechanism, a
risk-attention decision network, a balanced reward function, and a
safety-assisted mechanism. The risk-aware mechanism focuses on highlighting
areas with potential collisions, facilitating safe-driving learning of the PPO.
The balanced reward function adjusts rewards based on the number of surrounding
vehicles, promoting efficient exploration of the control strategy during
training. Additionally, the risk-attention network enhances the PPO to hold
channel and spatial attention for the high-risk areas of input images.
Moreover, the safety-assisted mechanism supervises and prevents the actions
with risks of collisions during the lane keeping and lane changing. Simulation
results on a physical engine demonstrate that the proposed algorithm
outperforms benchmark algorithms in collision avoidance, achieving higher peak
reward with less training time, and shorter driving time remaining on the risky
areas among multiple testing traffic flow scenarios.

</details>


### [167] [Robust Docking Maneuvers for Autonomous Trolley Collection: An Optimization-Based Visual Servoing Scheme](https://arxiv.org/abs/2509.07413)
*Yuhan Pang,Bingyi Xia,Zhe Zhang,Zhirui Sun,Peijia Xie,Bike Zhu,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 本研究提出了一种基于优化的视觉伺服方案，结合主动红外标记，用于服务机器人精确可靠的对接任务，解决了传统视觉对接系统面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 为了提高机场或仓库等公共场所服务机器人自主收集和重新分配手推车的工作效率并降低成本，需要开发能够实现高精度和稳定性的机器人对接系统。

Method: 提出了一种基于优化的视觉伺服方案，集成了主动红外标记，用于鲁棒的特征提取。该框架在混合视觉伺服问题中显式地建模了非完整运动学和可见性约束，并辅以一个用于干扰抑制的观测器，以确保精确和稳定的对接。

Result: 实验结果表明，该系统在各种环境中都表现出鲁棒性，定量评估证实了对接精度高。

Conclusion: 所提出的基于优化的视觉伺服方法能够精确稳定地完成服务机器人的对接任务，即使在具有挑战性的环境下也能有效运行。

Abstract: Service robots have demonstrated significant potential for autonomous trolley
collection and redistribution in public spaces like airports or warehouses to
improve efficiency and reduce cost. Usually, a fully autonomous system for the
collection and transportation of multiple trolleys is based on a
Leader-Follower formation of mobile manipulators, where reliable docking
maneuvers of the mobile base are essential to align trolleys into organized
queues. However, developing a vision-based robotic docking system faces
significant challenges: high precision requirements, environmental
disturbances, and inherent robot constraints. To address these challenges, we
propose an optimization-based Visual Servoing scheme that incorporates active
infrared markers for robust feature extraction across diverse lighting
conditions. This framework explicitly models nonholonomic kinematics and
visibility constraints within the Hybrid Visual Servoing problem, augmented
with an observer for disturbance rejection to ensure precise and stable
docking. Experimental results across diverse environments demonstrate the
robustness of this system, with quantitative evaluations confirming high
docking accuracy.

</details>


### [168] [Timing the Message: Language-Based Notifications for Time-Critical Assistive Settings](https://arxiv.org/abs/2509.07438)
*Ya-Chuan Hsu,Jonathan DeCastro,Andrew Silva,Guy Rosman*

Main category: cs.RO

TL;DR: 该研究通过一个增强状态的马尔可夫决策过程来解决时间和信息之间的权衡问题，并结合强化学习和生成的离线分类数据集，以优化时间关键场景中的人机协作。


<details>
  <summary>Details</summary>
Motivation: 当前的人工智能助手在时间关键场景下，仅通过提示或触觉信号来提醒人类，存在延迟或歧义的风险。虽然语言助手可以提供更丰富的信息，但现有方法忽视了时间因素，如语音传递时间、人类理解和后续操作时间，这在时间关键场景下至关重要。

Method: 将时间和信息之间的权衡问题建模为一个序列决策问题，并采用增强状态的马尔可夫决策过程。设计了一个结合强化学习和生成的离线分类数据集的框架，以平衡时间和信息，并实现可扩展的数据集生成。

Result: 在与合成人类进行的实证评估中，该框架相比忽略时间延迟的方法，成功率提高了40%以上，并有效平衡了时间和信息。

Conclusion: 该研究揭示了时间和信息之间被忽视的权衡，为优化时间关键场景下的人机协作提供了新的方向。

Abstract: In time-critical settings such as assistive driving, assistants often rely on
alerts or haptic signals to prompt rapid human attention, but these cues
usually leave humans to interpret situations and decide responses
independently, introducing potential delays or ambiguity in meaning.
Language-based assistive systems can instead provide instructions backed by
context, offering more informative guidance. However, current approaches (e.g.,
social assistive robots) largely prioritize content generation while
overlooking critical timing factors such as verbal conveyance duration, human
comprehension delays, and subsequent follow-through duration. These timing
considerations are crucial in time-critical settings, where even minor delays
can substantially affect outcomes. We aim to study this inherent trade-off
between timeliness and informativeness by framing the challenge as a sequential
decision-making problem using an augmented-state Markov Decision Process. We
design a framework combining reinforcement learning and a generated offline
taxonomy dataset, where we balance the trade-off while enabling a scalable
taxonomy dataset generation pipeline. Empirical evaluation with synthetic
humans shows our framework improves success rates by over 40% compared to
methods that ignore time delays, while effectively balancing timeliness and
informativeness. It also exposes an often-overlooked trade-off between these
two factors, opening new directions for optimizing communication in
time-critical human-AI assistance.

</details>


### [169] [Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions](https://arxiv.org/abs/2509.07445)
*Harrison Field,Max Yang,Yijiong Lin,Efi Psomopoulou,David Barton,Nathan F. Lepora*

Main category: cs.RO

TL;DR: LLMs can design rewards for robot dexterity, and Text2Touch extends this to tactile sensing for multi-axis in-hand object rotation. It outperforms human-engineered baselines with simpler reward functions, enabling faster development of tactile skills.


<details>
  <summary>Details</summary>
Motivation: Prior work on LLM-based reward design for robots hasn't incorporated tactile sensing, which is crucial for human-like dexterity. This paper addresses that gap.

Method: The paper introduces Text2Touch, which uses LLM-crafted rewards with a prompt engineering strategy for multi-axis in-hand object rotation. It employs sim-to-real distillation for policy transfer to a tactile-enabled robot hand.

Result: Text2Touch significantly outperforms a human-engineered baseline in rotation speed and stability. The LLM-designed reward functions are much shorter and simpler than the baseline.

Conclusion: LLM-designed rewards can significantly speed up the development and deployment of dexterous tactile skills, facilitating more rapid and scalable multimodal robot learning.

Abstract: Large language models (LLMs) are beginning to automate reward design for
dexterous manipulation. However, no prior work has considered tactile sensing,
which is known to be critical for human-like dexterity. We present Text2Touch,
bringing LLM-crafted rewards to the challenging task of multi-axis in-hand
object rotation with real-world vision based tactile sensing in palm-up and
palm-down configurations. Our prompt engineering strategy scales to over 70
environment variables, and sim-to-real distillation enables successful policy
transfer to a tactile-enabled fully actuated four-fingered dexterous robot
hand. Text2Touch significantly outperforms a carefully tuned human-engineered
baseline, demonstrating superior rotation speed and stability while relying on
reward functions that are an order of magnitude shorter and simpler. These
results illustrate how LLM-designed rewards can significantly reduce the time
from concept to deployable dexterous tactile skills, supporting more rapid and
scalable multimodal robot learning. Project website:
https://hpfield.github.io/text2touch-website

</details>


### [170] [DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis](https://arxiv.org/abs/2509.07463)
*Sven Kirchner,Nils Purschke,Ross Greer,Alois C. Knoll*

Main category: cs.RO

TL;DR: DepthVision框架利用LiDAR点云合成RGB图像，并结合LAMA技术，提升了机器人再弱光、模糊等视觉信息不足情况下的场景理解能力，且无需微调现有视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人视觉输入退化或不足时操作不可靠的挑战。

Method: DepthVision框架通过条件生成对抗网络（GAN）和 refiner网络，利用稀疏的LiDAR点云合成RGB图像。然后，使用Luminance-Aware Modality Adaptation（LAMA）技术，根据环境光照条件动态融合合成的RGB图像和真实RGB数据。

Result: 在真实和模拟数据集的评估中，尤其是在安全关键任务上，DepthVision在弱光条件下提高了性能，相较于仅使用RGB输入的基线方法有显著提升，同时保持了与冻结的视觉语言模型的兼容性。

Conclusion: LiDAR引导的RGB合成技术有潜力实现机器人再真实环境中鲁棒的操作。

Abstract: Ensuring reliable robot operation when visual input is degraded or
insufficient remains a central challenge in robotics. This letter introduces
DepthVision, a framework for multimodal scene understanding designed to address
this problem. Unlike existing Vision-Language Models (VLMs), which use only
camera-based visual input alongside language, DepthVision synthesizes RGB
images from sparse LiDAR point clouds using a conditional generative
adversarial network (GAN) with an integrated refiner network. These synthetic
views are then combined with real RGB data using a Luminance-Aware Modality
Adaptation (LAMA), which blends the two types of data dynamically based on
ambient lighting conditions. This approach compensates for sensor degradation,
such as darkness or motion blur, without requiring any fine-tuning of
downstream vision-language models. We evaluate DepthVision on real and
simulated datasets across various models and tasks, with particular attention
to safety-critical tasks. The results demonstrate that our approach improves
performance in low-light conditions, achieving substantial gains over RGB-only
baselines while preserving compatibility with frozen VLMs. This work highlights
the potential of LiDAR-guided RGB synthesis for achieving robust robot
operation in real-world environments.

</details>


### [171] [Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers](https://arxiv.org/abs/2509.07464)
*Rui Yang,Lei Zheng,Shuzhi Sam Ge,Jun Ma*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Autonomous vehicles must navigate dynamically uncertain environments while
balancing the safety and driving efficiency. This challenge is exacerbated by
the unpredictable nature of surrounding human-driven vehicles (HVs) and
perception inaccuracies, which require planners to adapt to evolving
uncertainties while maintaining safe trajectories. Overly conservative planners
degrade driving efficiency, while deterministic approaches may encounter
serious issues and risks of failure when faced with sudden and unexpected
maneuvers. To address these issues, we propose a real-time contingency
trajectory optimization framework in this paper. By employing event-triggered
online learning of HV control-intent sets, our method dynamically quantifies
multi-modal HV uncertainties and refines the forward reachable set (FRS)
incrementally. Crucially, we enforce invariant safety through FRS-based barrier
constraints that ensure safety without reliance on accurate trajectory
prediction of HVs. These constraints are embedded in contingency trajectory
optimization and solved efficiently through consensus alternative direction
method of multipliers (ADMM). The system continuously adapts to the
uncertainties in HV behaviors, preserving feasibility and safety without
resorting to excessive conservatism. High-fidelity simulations on highway and
urban scenarios, as well as a series of real-world experiments demonstrate
significant improvements in driving efficiency and passenger comfort while
maintaining safety under uncertainty. The project page is available at
https://pathetiue.github.io/frscp.github.io/.

</details>


### [172] [Flexible Morphing Aerial Robot with Inflatable Structure for Perching-based Human-Robot Interaction](https://arxiv.org/abs/2509.07496)
*Ayano Miyamichi,Moju Zhao,Kazuki Sugihara,Junichiro Sugihara,Masanori Konishi,Kunio Kojima,Kei Okada,Masayuki Inaba*

Main category: cs.RO

TL;DR: 本研究提出了一种结合了单翼柔性臂和气动充气执行器的混合变形结构，实现了能够与人类进行互动的空中机器人，该机器人可在飞行时保持刚性，在着陆时变得柔软，并具有可调节的抓握力。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有空中机器人变形结构在飞行稳定性和与人类互动时的柔顺性与安全性方面的挑战，本研究旨在开发一种能够与人类进行高柔顺性、高抓握能力接触的变形空中机器人。

Method: 提出一种混合变形结构（单翼柔性臂+气动充气执行器），实现飞行时刚性、着陆时柔软；开发气动控制系统，优化压力调节，集成减震和可调节抓握力；分析单翼柔性臂的结构特性，确保四旋翼飞行器的稳定控制。

Result: 开发的样机成功实现了向人类的柔顺接触着陆，并在飞行中手臂变形后仍能稳健恢复，证明了该设计的可行性。

Conclusion: 本研究首次实现了能够与人类互动并进行接触着陆的空中机器人，解决了变形空中机器人的稳定性和交互性挑战。

Abstract: Birds in nature perform perching not only for rest but also for interaction
with human such as the relationship with falconers. Recently, researchers
achieve perching-capable aerial robots as a way to save energy, and deformable
structure demonstrate significant advantages in efficiency of perching and
compactness of configuration. However, ensuring flight stability remains
challenging for deformable aerial robots due to the difficulty of controlling
flexible arms. Furthermore, perching for human interaction requires high
compliance along with safety. Thus, this study aims to develop a deformable
aerial robot capable of perching on humans with high flexibility and grasping
ability. To overcome the challenges of stability of both flight and perching,
we propose a hybrid morphing structure that combines a unilateral flexible arm
and a pneumatic inflatable actuators. This design allows the robot's arms to
remain rigid during flight and soft while perching for more effective grasping.
We also develop a pneumatic control system that optimizes pressure regulation
while integrating shock absorption and adjustable grasping forces, enhancing
interaction capabilities and energy efficiency. Besides, we focus on the
structural characteristics of the unilateral flexible arm and identify
sufficient conditions under which standard quadrotor modeling and control
remain effective in terms of flight stability. Finally, the developed prototype
demonstrates the feasibility of compliant perching maneuvers on humans, as well
as the robust recovery even after arm deformation caused by thrust reductions
during flight. To the best of our knowledge, this work is the first to achieve
an aerial robot capable of perching on humans for interaction.

</details>


### [173] [OmniMap: A General Mapping Framework Integrating Optics, Geometry, and Semantics](https://arxiv.org/abs/2509.07500)
*Yinan Deng,Yufeng Yue,Jianyu Dou,Jingyu Zhao,Jiahui Wang,Yujie Tang,Yi Yang,Mengyin Fu*

Main category: cs.RO

TL;DR: OmniMap是一个在线三维环境感知框架，能同时捕捉照片级外观、精确的几何形状和开放词汇的语义理解，并保持实时性能和模型紧凑性。


<details>
  <summary>Details</summary>
Motivation: 机器人系统需要准确全面的三维环境感知，同时捕捉照片级外观（光学）、精确的布局形状（几何）和开放词汇的场景理解（语义）。现有方法通常只能部分满足这些要求，同时存在光学模糊、几何不规则和语义模糊的问题。

Method: OmniMap采用紧密集成的3DGS-Voxel混合表示，结合了细粒度建模和结构稳定性。通过自适应相机建模、带法线约束的混合增量表示以及用于鲁棒实例级理解的概率融合等创新来实现。

Result: 实验证明，OmniMap在渲染保真度、几何精度和零样本语义分割方面优于最先进的方法。此外，该框架在多领域场景问答、交互式编辑、感知引导操作和地图辅助导航等下游应用中也表现出通用性。

Conclusion: OmniMap是第一个同时捕捉光学、几何和语义场景属性的在线建图框架，同时保持实时性能和模型紧凑性，解决了现有方法的局限性。

Abstract: Robotic systems demand accurate and comprehensive 3D environment perception,
requiring simultaneous capture of photo-realistic appearance (optical), precise
layout shape (geometric), and open-vocabulary scene understanding (semantic).
Existing methods typically achieve only partial fulfillment of these
requirements while exhibiting optical blurring, geometric irregularities, and
semantic ambiguities. To address these challenges, we propose OmniMap. Overall,
OmniMap represents the first online mapping framework that simultaneously
captures optical, geometric, and semantic scene attributes while maintaining
real-time performance and model compactness. At the architectural level,
OmniMap employs a tightly coupled 3DGS-Voxel hybrid representation that
combines fine-grained modeling with structural stability. At the implementation
level, OmniMap identifies key challenges across different modalities and
introduces several innovations: adaptive camera modeling for motion blur and
exposure compensation, hybrid incremental representation with normal
constraints, and probabilistic fusion for robust instance-level understanding.
Extensive experiments show OmniMap's superior performance in rendering
fidelity, geometric accuracy, and zero-shot semantic segmentation compared to
state-of-the-art methods across diverse scenes. The framework's versatility is
further evidenced through a variety of downstream applications, including
multi-domain scene Q&A, interactive editing, perception-guided manipulation,
and map-assisted navigation.

</details>


### [174] [Improving Machine Learning-Based Robot Self-Collision Checking with Input Positional Encoding](https://arxiv.org/abs/2509.07542)
*Bartlomiej Kulecki,Dominik Belter*

Main category: cs.RO

TL;DR: 在二元分类模型的输入向量中加入位置编码，以提高自碰撞检测的准确性，并提出基于MLP的方法比传统方法更快地进行碰撞检测。


<details>
  <summary>Details</summary>
Motivation: 将广泛用于计算机图形学中的位置编码技术整合到二元分类模型的输入向量中，用于自碰撞检测，并提出使用轻量级多层感知机（MLP）在低维特征空间中操作，以提供比依赖几何方法的传统方法（如三角形到三角形交叉测试和用于网格模型的边界体积层次（BVH））更快的碰撞检测替代方案。

Method: 将位置编码整合到用于自碰撞检测的二元分类模型的输入向量中，并使用轻量级多层感知机（MLP）在低维特征空间中操作。

Result: 与传统方法相比，整合位置编码可提高分类准确性，并通过更好地捕捉高频变化来实现更详细、更精确的复杂碰撞模式表示。基于MLP的方法比基于几何的方法更快。

Conclusion: 基于MLP的方法比传统方法更快，并且整合位置编码可以提高自碰撞检测的准确性。

Abstract: This manuscript investigates the integration of positional encoding -- a
technique widely used in computer graphics -- into the input vector of a binary
classification model for self-collision detection. The results demonstrate the
benefits of incorporating positional encoding, which enhances classification
accuracy by enabling the model to better capture high-frequency variations,
leading to a more detailed and precise representation of complex collision
patterns. The manuscript shows that machine learning-based techniques, such as
lightweight multilayer perceptrons (MLPs) operating in a low-dimensional
feature space, offer a faster alternative for collision checking than
traditional methods that rely on geometric approaches, such as
triangle-to-triangle intersection tests and Bounding Volume Hierarchies (BVH)
for mesh-based models.

</details>


### [175] [Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?](https://arxiv.org/abs/2509.07593)
*Gavin Tao,Yinuo Wang,Jinzhao Zhou*

Main category: cs.RO

TL;DR: 使用SSD-Mamba2作为骨干，提出了一种端到端的强化学习框架，用于运动控制，实现了比现有方法更好的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端强化学习运动控制方法在处理多模态信息和长序列依赖时存在计算-内存效率和长远信用分配问题。特别是基于Transformer的方法计算成本高昂，限制了时空上下文的利用。

Method: 提出了一种基于SSD-Mamba2的视觉驱动的跨模态强化学习框架。SSD-Mamba2是一种选择性状态空间模型，结合了循环和卷积扫描，并具有硬件感知流式处理能力，实现了近乎线性的扩展。该框架将本体感觉状态和外感受器观测（如深度信息）编码成紧凑的token，并通过堆叠的SSD-Mamba2层进行融合。使用课程学习策略来训练策略，该策略随机化地形和外观，并逐步增加场景复杂度。同时，使用了一个以状态为中心的奖励函数来平衡任务进展、能源效率和安全性。

Result: 在各种运动控制场景中，该方法在回报、安全性（碰撞和跌倒）和样本效率方面持续超越最先进的方法，并且在相同的计算预算下收敛速度更快。

Conclusion: SSD-Mamba2提供了一个实用的融合骨干网络，适用于可扩展、有远见且高效的端到端运动控制。

Abstract: End-to-end reinforcement learning for motion control promises unified
perception-action policies that scale across embodiments and tasks, yet most
deployed controllers are either blind (proprioception-only) or rely on fusion
backbones with unfavorable compute-memory trade-offs. Recurrent controllers
struggle with long-horizon credit assignment, and Transformer-based fusion
incurs quadratic cost in token length, limiting temporal and spatial context.
We present a vision-driven cross-modal RL framework built on SSD-Mamba2, a
selective state-space backbone that applies state-space duality (SSD) to enable
both recurrent and convolutional scanning with hardware-aware streaming and
near-linear scaling. Proprioceptive states and exteroceptive observations
(e.g., depth tokens) are encoded into compact tokens and fused by stacked
SSD-Mamba2 layers. The selective state-space updates retain long-range
dependencies with markedly lower latency and memory use than quadratic
self-attention, enabling longer look-ahead, higher token resolution, and stable
training under limited compute. Policies are trained end-to-end under curricula
that randomize terrain and appearance and progressively increase scene
complexity. A compact, state-centric reward balances task progress, energy
efficiency, and safety. Across diverse motion-control scenarios, our approach
consistently surpasses strong state-of-the-art baselines in return, safety
(collisions and falls), and sample efficiency, while converging faster at the
same compute budget. These results suggest that SSD-Mamba2 provides a practical
fusion backbone for scalable, foresightful, and efficient end-to-end motion
control.

</details>


### [176] [Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network](https://arxiv.org/abs/2509.07646)
*Yanlong Peng,Zhigang Wang,Ziwen He,Pengxu Chang,Chuangchuang Zhou,Yu Yan,Ming Chen*

Main category: cs.RO

TL;DR: RobKiNet是一个利用运动学知识的神经网络，可以端到端地在多约束配置空间中进行采样，从而提高机器人任务与运动规划的效率。


<details>
  <summary>Details</summary>
Motivation: 传统的多约束配置空间采样方法效率低下，而RobKiNet通过引入运动学知识来解决这个问题。

Method: RobKiNet是一个运动学启发的神经网络，它将运动学知识融入模型，用于在多约束配置空间中进行端到端的采样，并建立了优化期望模型。

Result: RobKiNet在2-DOF空间和9-DOF机器人上进行了验证，显示出理论上的效率和在电池拆卸任务中的优越性。与传统方法和深度强化学习相比，RobKiNet的训练速度提高了74.29倍，采样精度高达99.25%，实际任务完成率达到97.33%。

Conclusion: RobKiNet通过融入运动学知识，显著提高了机器人任务与运动规划的采样效率和准确性，并在实际应用中取得了优异的表现。

Abstract: In robots task and motion planning (TAMP), it is crucial to sample within the
robot's configuration space to meet task-level global constraints and enhance
the efficiency of subsequent motion planning. Due to the complexity of joint
configuration sampling under multi-level constraints, traditional methods often
lack efficiency. This paper introduces the principle of RobKiNet, a
kinematics-informed neural network, for end-to-end sampling within the
Continuous Feasible Set (CFS) under multiple constraints in configuration
space, establishing its Optimization Expectation Model. Comparisons with
traditional sampling and learning-based approaches reveal that RobKiNet's
kinematic knowledge infusion enhances training efficiency by ensuring stable
and accurate gradient optimization.Visualizations and quantitative analyses in
a 2-DOF space validate its theoretical efficiency, while its application on a
9-DOF autonomous mobile manipulator robot(AMMR) demonstrates superior
whole-body and decoupled control, excelling in battery disassembly tasks.
RobKiNet outperforms deep reinforcement learning with a training speed 74.29
times faster and a sampling accuracy of up to 99.25%, achieving a 97.33% task
completion rate in real-world scenarios.

</details>


### [177] [Collaborative Exploration with a Marsupial Ground-Aerial Robot Team through Task-Driven Map Compression](https://arxiv.org/abs/2509.07655)
*Angelos Zacharia,Mihir Dharmadhikari,Kostas Alexis*

Main category: cs.RO

TL;DR: 该研究提出了一种用于火星地面-空中机器人协作的探索框架，通过结合机器人优势、图基路径规划和带宽高效的地图压缩策略，来提高未知环境的探索效率。


<details>
  <summary>Details</summary>
Motivation: 在未知、通信受限的封闭和大规模环境中，自主机器人的高效探索至关重要。

Method: 提出了一种协作探索框架，利用地面-空中机器人团队的互补能力。该框架采用基于图的路径规划算法，指导探索，并将空中机器人部署在预期收益远超地面机器人的区域（例如，大片开放空间或地面平台无法进入的区域）。引入了一种带宽高效、任务驱动的地图压缩策略，以实现大规模空间信息共享，使每个机器人能够以高压缩率重建特定分辨率的体积地图，同时保留探索关键细节。

Result: 仿真和真实世界实验验证了该方法，证明其在提高探索效率和显著减少数据传输方面是有效的。

Conclusion: 所提出的框架通过有效利用机器人能力、智能路径规划和优化的通信策略，成功解决了在具有挑战性的环境中进行高效协作探索的问题。

Abstract: Efficient exploration of unknown environments is crucial for autonomous
robots, especially in confined and large-scale scenarios with limited
communication. To address this challenge, we propose a collaborative
exploration framework for a marsupial ground-aerial robot team that leverages
the complementary capabilities of both platforms. The framework employs a
graph-based path planning algorithm to guide exploration and deploy the aerial
robot in areas where its expected gain significantly exceeds that of the ground
robot, such as large open spaces or regions inaccessible to the ground
platform, thereby maximizing coverage and efficiency. To facilitate large-scale
spatial information sharing, we introduce a bandwidth-efficient, task-driven
map compression strategy. This method enables each robot to reconstruct
resolution-specific volumetric maps while preserving exploration-critical
details, even at high compression rates. By selectively compressing and sharing
key data, communication overhead is minimized, ensuring effective map
integration for collaborative path planning. Simulation and real-world
experiments validate the proposed approach, demonstrating its effectiveness in
improving exploration efficiency while significantly reducing data
transmission.

</details>


### [178] [Temporal Counterfactual Explanations of Behaviour Tree Decisions](https://arxiv.org/abs/2509.07674)
*Tamlin Love,Antonio Andriella,Guillem Alenyà*

Main category: cs.RO

TL;DR: 本研究提出了一种自动生成行为树反事实解释的新方法，以回答机器人的“为什么”问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法为行为树提供因果、反事实的解释，而这种解释对于理解机器人的决策和行为至关重要。

Method: 该方法首先利用行为树结构和领域知识构建因果模型，然后查询该模型以生成多样化的反事实解释。

Result: 所提出的方法能够正确解释各种行为树结构和状态下的机器人行为。

Conclusion: 本研究通过提供因果解释的能力，朝着构建更透明、可理解和可信赖的机器人系统迈出了重要一步。

Abstract: Explainability is a critical tool in helping stakeholders understand robots.
In particular, the ability for robots to explain why they have made a
particular decision or behaved in a certain way is useful in this regard.
Behaviour trees are a popular framework for controlling the decision-making of
robots and other software systems, and thus a natural question to ask is
whether or not a system driven by a behaviour tree is capable of answering
"why" questions. While explainability for behaviour trees has seen some prior
attention, no existing methods are capable of generating causal, counterfactual
explanations which detail the reasons for robot decisions and behaviour.
Therefore, in this work, we introduce a novel approach which automatically
generates counterfactual explanations in response to contrastive "why"
questions. Our method achieves this by first automatically building a causal
model from the structure of the behaviour tree as well as domain knowledge
about the state and individual behaviour tree nodes. The resultant causal model
is then queried and searched to find a set of diverse counterfactual
explanations. We demonstrate that our approach is able to correctly explain the
behaviour of a wide range of behaviour tree structures and states. By being
able to answer a wide range of causal queries, our approach represents a step
towards more transparent, understandable and ultimately trustworthy robotic
systems.

</details>


### [179] [Robust Radar SLAM for Vehicle Parking Applications](https://arxiv.org/abs/2509.07683)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 提出一种基于雷达的SLAM方法，用于自动泊车中的自我运动估计，具有高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法（IMU和轮式编码器）需要标定，成本高且耗时。而自动泊车需要厘米级精度，并且空间狭窄，存在障碍物。

Method: 提出一种基于雷达的SLAM方法，该方法利用雷达的鲁棒性（不受恶劣天气影响）和在线标定能力。采用以机器人为中心的公式，融合特征点位置和多普勒速度，以实现鲁棒的数据关联和滤波收敛。具体包括：1. 多普勒增强雷达SLAM方法；2. 多雷达支持；3. 基于信息的特征修剪策略。

Result: 实验证明，该方法实现了高精度的定位，并且比现有最先进的方法具有更好的鲁棒性，满足了自动泊车的要求。

Conclusion: 所提出的基于雷达的SLAM方法可以满足自动泊车的高精度和鲁棒性要求。

Abstract: We address ego-motion estimation for automated parking, where
centimeter-level accuracy is crucial due to tight spaces and nearby obstacles.
Traditional methods using inertial-measurement units and wheel encoders require
calibration, making them costly and time-consuming. To overcome this, we
propose a radar-based simultaneous localization and mapping (SLAM) approach
that leverages the robustness of radar to adverse weather and support for
online calibration. Our robocentric formulation fuses feature positions and
Doppler velocities for robust data association and filter convergence. Key
contributions include a Doppler-augmented radar SLAM method, multi-radar
support and an information-based feature-pruning strategy. Experiments
demonstrate high-accuracy localization and improved robustness over
state-of-the-art methods, meeting the demands of automated parking.

</details>


### [180] [Fault Tolerant Control of a Quadcopter using Reinforcement Learning](https://arxiv.org/abs/2509.07707)
*Muzaffar Habib,Adnan Maqsood,Adnan Fayyaz ud Din*

Main category: cs.RO

TL;DR: 本研究提出了一种基于强化学习（RL）的控制框架，用于提高四旋翼飞行器的安全性和鲁棒性，特别是在单螺旋桨故障的情况下。该框架研究了动态规划（DP）和深度确定性策略梯度（DDPG）两种RL方法，并对现有算法进行了修改，以处理大规模状态和动作域，并在飞行中发生螺旋桨故障后实现期望状态。通过MATLAB仿真验证了该框架的鲁棒性，并对两种RL算法进行了比较分析。


<details>
  <summary>Details</summary>
Motivation: 为了应对四旋翼飞行器在实际应用中发生单螺旋桨故障时，维持期望高度的关键需求，以保护硬件和有效载荷。

Method: 研究了动态规划（DP）和深度确定性策略梯度（DDPG）两种强化学习方法。对DP和DDPG算法进行了修改，以处理大规模连续状态和动作域，并使其能够在发生飞行中螺旋桨故障后实现期望状态。

Result: 在MATLAB环境中进行了广泛的仿真，证明了所提出的控制框架在各种初始条件下的鲁棒性和可行性。对DP和DDPG算法进行了比较分析。

Conclusion: 所提出的强化学习控制框架能够有效应对四旋翼飞行器单螺旋桨故障的情况，保证飞行器和有效载荷的安全。DP和DDPG两种方法在处理此类故障方面各有优劣。

Abstract: This study presents a novel reinforcement learning (RL)-based control
framework aimed at enhancing the safety and robustness of the quadcopter, with
a specific focus on resilience to in-flight one propeller failure. Addressing
the critical need of a robust control strategy for maintaining a desired
altitude for the quadcopter to safe the hardware and the payload in physical
applications. The proposed framework investigates two RL methodologies Dynamic
Programming (DP) and Deep Deterministic Policy Gradient (DDPG), to overcome the
challenges posed by the rotor failure mechanism of the quadcopter. DP, a
model-based approach, is leveraged for its convergence guarantees, despite high
computational demands, whereas DDPG, a model-free technique, facilitates rapid
computation but with constraints on solution duration. The research challenge
arises from training RL algorithms on large dimensions and action domains. With
modifications to the existing DP and DDPG algorithms, the controllers were
trained not only to cater for large continuous state and action domain and also
achieve a desired state after an inflight propeller failure. To verify the
robustness of the proposed control framework, extensive simulations were
conducted in a MATLAB environment across various initial conditions and
underscoring its viability for mission-critical quadcopter applications. A
comparative analysis was performed between both RL algorithms and their
potential for applications in faulty aerial systems.

</details>


### [181] [Unlocking Stopped-Rotor Flight: Development and Validation of SPERO, a Novel UAV Platform](https://arxiv.org/abs/2509.07812)
*Kristan Hilby,Ian Hunter*

Main category: cs.RO

TL;DR: Spero无人机是一种新型的停止转子飞行器，解决了传统停止转子飞行器在不同飞行模式下存在的空气动力学和稳定性问题，实现了稳定、双向的垂直起降和前向飞行之间的转换。


<details>
  <summary>Details</summary>
Motivation: 停止转子飞行器被认为是理想的垂直起降（VTOL）飞行器，适用于在飞行两种模式下花费相等时间的任务，但实际应用因气动和稳定性冲突而受阻。

Method: 提出了一种名为SPERO（Stopped-Penta Rotor）的停止转子无人机，该无人机具有翻转和锁定的机翼、主动压力中心机制、推力矢量配重以及五旋翼结构。采用十一状态机的飞行控制器协调几何和控制器的重新配置。

Result: SPERO无人机克服了停止转子飞行中的长期挑战，实现了稳定的、双向的垂直起降和前向飞行之间的转换，并建立了一个可推广的设计和控制框架。

Conclusion: SPERO无人机通过创新的设计和控制方法，成功解决了停止转子飞行器长期存在的挑战，实现了在垂直起降和前向飞行模式之间的稳定转换，为停止转子无人机的实际应用铺平了道路。

Abstract: Stop-rotor aircraft have long been proposed as the ideal vertical takeoff and
landing (VTOL) aircraft for missions with equal time spent in both flight
regimes, such as agricultural monitoring, search and rescue, and last-mile
delivery. Featuring a central lifting surface that rotates in VTOL to generate
vertical thrust and locks in forward flight to generate passive lift, the
stop-rotor offers the potential for high efficiency across both modes. However,
practical implementation has remained infeasible due to aerodynamic and
stability conflicts between flight modes. In this work, we present SPERO
(Stopped-Penta Rotor), a stop-rotor uncrewed aerial vehicle (UAV) featuring a
flipping and latching wing, an active center of pressure mechanism, thrust
vectored counterbalances, a five-rotor architecture, and an eleven-state
machine flight controller coordinating geometric and controller
reconfiguration. Furthermore, SPERO establishes a generalizable design and
control framework for stopped-rotor UAVs. Together, these innovations overcome
longstanding challenges in stop-rotor flight and enable the first stable,
bidirectional transition between VTOL and forward flight.

</details>


### [182] [Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability](https://arxiv.org/abs/2509.07916)
*Jianshu Zhou,Wei Chen,Junda Huang,Boyuan Liang,Yunhui Liu,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 该论文提出了一种可编程锁定单元（PLC），这是一种模块化的、由绳索驱动的单元，通过机械互锁的关节和绳索张力驱动来实现离散的刚度调制。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中运行的机器人需要能够在顺从和刚性状态之间切换，以执行各种任务。然而，现有的可变刚度解决方案存在复杂性、持续输入功率需求或整体化设计等限制，这阻碍了它们的模块化和可扩展性。

Method: PLC 单元通过结构接合在顺从和固定状态之间转换，该单元提供高达 950% 的刚度变化，并且在固定状态下不易受高负载损坏。可以将多个 PLC 单元组装成具有空间可编程刚度的可重构机器人结构。

Result: 通过两个功能原型进行了设计验证：一个可变刚度抓手，能够进行自适应抓取、牢固抓取和手中操作；以及一个由串联 PLC 单元组成的管道穿越机器人，能够在密闭环境中实现形状适应性和刚度控制。

Conclusion: PLC 是一种可扩展的、以结构为中心的、可编程刚度和运动的机制，能够实现具有可重构形态和任务自适应交互的机器人系统。

Abstract: Robotic systems operating in unstructured environments require the ability to
switch between compliant and rigid states to perform diverse tasks such as
adaptive grasping, high-force manipulation, shape holding, and navigation in
constrained spaces, among others. However, many existing variable stiffness
solutions rely on complex actuation schemes, continuous input power, or
monolithic designs, limiting their modularity and scalability. This paper
presents the Programmable Locking Cell (PLC)-a modular, tendon-driven unit that
achieves discrete stiffness modulation through mechanically interlocked joints
actuated by cable tension. Each unit transitions between compliant and firm
states via structural engagement, and the assembled system exhibits high
stiffness variation-up to 950% per unit-without susceptibility to damage under
high payload in the firm state. Multiple PLC units can be assembled into
reconfigurable robotic structures with spatially programmable stiffness. We
validate the design through two functional prototypes: (1) a variable-stiffness
gripper capable of adaptive grasping, firm holding, and in-hand manipulation;
and (2) a pipe-traversing robot composed of serial PLC units that achieves
shape adaptability and stiffness control in confined environments. These
results demonstrate the PLC as a scalable, structure-centric mechanism for
programmable stiffness and motion, enabling robotic systems with reconfigurable
morphology and task-adaptive interaction.

</details>


### [183] [RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction](https://arxiv.org/abs/2509.07953)
*Zheyuan Hu,Robyn Wu,Naveen Enock,Jasmine Li,Riya Kadakia,Zackory Erickson,Aviral Kumar*

Main category: cs.RO

TL;DR: RaC是一种在模仿学习预训练后，对人类在环数据进行微调的机器人策略训练新阶段，通过学习人类的恢复和纠正行为，提高了机器人完成长期任务的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有机器人模仿学习方法在接触丰富、可变形物体和长周期任务上的性能受限于效率低下的专家数据收集程序。

Method: RaC在模仿学习预训练后，通过人类在环的回放来微调机器人策略。在策略回放过程中，当出现即将失败的情况时，人类操作员会介入，将机器人回溯到一个熟悉的、分布内的状态，然后提供一个完成当前子任务的纠正片段。

Result: RaC在现实世界的衬衫悬挂、密封容器盖密封、外卖盒打包等三个双臂控制任务和一项模拟装配任务中，相比于之前的最先进方法，数据收集时间减少了10倍，样本量也更少。此外，RaC还实现了测试时可扩展性，即所训练的RaC策略的性能与其展示的恢复操作的数量成线性关系。

Conclusion: RaC通过在人类干预轨迹上进行微调，学习恢复和纠正行为，显著提高了机器人完成长期任务的效率和鲁棒性，并减少了数据收集成本。

Abstract: Modern paradigms for robot imitation train expressive policy architectures on
large amounts of human demonstration data. Yet performance on contact-rich,
deformable-object, and long-horizon tasks plateau far below perfect execution,
even with thousands of expert demonstrations. This is due to the inefficiency
of existing ``expert'' data collection procedures based on human teleoperation.
To address this issue, we introduce RaC, a new phase of training on
human-in-the-loop rollouts after imitation learning pre-training. In RaC, we
fine-tune a robotic policy on human intervention trajectories that illustrate
recovery and correction behaviors. Specifically, during a policy rollout, human
operators intervene when failure appears imminent, first rewinding the robot
back to a familiar, in-distribution state and then providing a corrective
segment that completes the current sub-task. Training on this data composition
expands the robotic skill repertoire to include retry and adaptation behaviors,
which we show are crucial for boosting both efficiency and robustness on
long-horizon tasks. Across three real-world bimanual control tasks: shirt
hanging, airtight container lid sealing, takeout box packing, and a simulated
assembly task, RaC outperforms the prior state-of-the-art using 10$\times$ less
data collection time and samples. We also show that RaC enables test-time
scaling: the performance of the trained RaC policy scales linearly in the
number of recovery maneuvers it exhibits. Videos of the learned policy are
available at https://rac-scaling-robot.github.io/.

</details>


### [184] [Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation](https://arxiv.org/abs/2509.07957)
*Shunlei Li,Longsen Gao,Jiuwen Cao,Yingbai Hu*

Main category: cs.RO

TL;DR: GF-VLA是一个统一框架，使双臂机器人能够直接从RGB-D人类演示中执行任务级推理和执行，解决了传统方法在泛化性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的低级轨迹复制方法在跨不同物体、空间布局和机械臂配置时泛化性差，难以获取灵巧的机器人技能。

Method: GF-VLA利用信息论提取任务相关线索，构建时间有序的场景图，并与语言条件Transformer集成，生成行为树和笛卡尔运动原语。提出了一种跨臂分配策略来提高双臂执行效率。

Result: GF-VLA在双臂块组装基准测试中实现了超过95%的图准确率和93%的子任务分割率。在实际机器人部署中，任务成功率达到90%，抓取可靠性为94%，放置准确率为89%。

Conclusion: GF-VLA框架能够有效地从人类视频演示中学习和执行双臂机器人任务，展现出强大的泛化能力和鲁棒性，能够应对各种空间和语义变化。

Abstract: Acquiring dexterous robotic skills from human video demonstrations remains a
significant challenge, largely due to conventional reliance on low-level
trajectory replication, which often fails to generalize across varying objects,
spatial layouts, and manipulator configurations. To address this limitation, we
introduce Graph-Fused Vision-Language-Action (GF-VLA), a unified framework that
enables dual-arm robotic systems to perform task-level reasoning and execution
directly from RGB-D human demonstrations. GF-VLA employs an
information-theoretic approach to extract task-relevant cues, selectively
highlighting critical hand-object and object-object interactions. These cues
are structured into temporally ordered scene graphs, which are subsequently
integrated with a language-conditioned transformer to produce hierarchical
behavior trees and interpretable Cartesian motion primitives. To enhance
efficiency in bimanual execution, we propose a cross-arm allocation strategy
that autonomously determines gripper assignment without requiring explicit
geometric modeling. We validate GF-VLA on four dual-arm block assembly
benchmarks involving symbolic structure construction and spatial
generalization. Empirical results demonstrate that the proposed representation
achieves over 95% graph accuracy and 93% subtask segmentation, enabling the
language-action planner to generate robust, interpretable task policies. When
deployed on a dual-arm robot, these policies attain 94% grasp reliability, 89%
placement accuracy, and 90% overall task success across stacking,
letter-formation, and geometric reconfiguration tasks, evidencing strong
generalization and robustness under diverse spatial and semantic variations.

</details>


### [185] [TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models](https://arxiv.org/abs/2509.07962)
*Zongzheng Zhang,Haobo Xu,Zhuo Yang,Chenghao Yue,Zehao Lin,Huan-ang Gao,Ziwei Wang,Hao Zhao*

Main category: cs.RO

TL;DR: 当前VLA模型缺乏整合力矩等物理反馈的能力，本研究提出了力矩感知VLA模型，通过系统研究将力矩信号整合进VLA架构的设计空间，并提出将力矩作为辅助输出进行预测的策略，以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作任务需要感知和响应力矩等力信号以评估任务成功与否并实现闭环控制，但当前视觉-语言-动作（VLA）模型缺乏整合此类物理反馈的能力。

Method: 系统研究将力矩信号整合进现有VLA架构的设计空间，并提出将力矩作为辅助输出进行预测的策略。

Result: 研究发现，将力矩适配器插入解码器始终优于插入编码器；将力矩作为辅助输出进行预测可以进一步提升性能。

Conclusion: 本研究提出的力矩感知VLA模型，通过将力矩信号有效整合进VLA架构并结合辅助预测策略，能够提升模型在接触密集型操作任务上的表现。

Abstract: Many robotic manipulation tasks require sensing and responding to force
signals such as torque to assess whether the task has been successfully
completed and to enable closed-loop control. However, current
Vision-Language-Action (VLA) models lack the ability to integrate such subtle
physical feedback. In this work, we explore Torque-aware VLA models, aiming to
bridge this gap by systematically studying the design space for incorporating
torque signals into existing VLA architectures. We identify and evaluate
several strategies, leading to three key findings. First, introducing torque
adapters into the decoder consistently outperforms inserting them into the
encoder.Third, inspired by joint prediction and planning paradigms in
autonomous driving, we propose predicting torque as an auxiliary output, which
further improves performance. This strategy encourages the model to build a
physically grounded internal representation of interaction dynamics. Extensive
quantitative and qualitative experiments across contact-rich manipulation
benchmarks validate our findings.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [186] [Stratified Cohomological Quantum Codes via Colimits in Ch(R)](https://arxiv.org/abs/2509.06958)
*William Boone Samuels*

Main category: quant-ph

TL;DR: 介绍了一种新的量子编码方法“分层余极限码”，该方法通过对有限偏序集上的链复形函子取度数意义上的余极限来构建，无需参考环境胞腔复形即可恢复多种经典和新型量子码。该方法利用矩阵史密斯范式和稀疏高斯消元法直接计算同调群，得到具有稀疏参数的LDPC码。该方法还支持代码缝合和双复形域壁等操作，为设计、分类和解码拓扑和分形量子码提供了一个简洁的代数框架。


<details>
  <summary>Details</summary>
Motivation: 提出一种统一的、不依赖于具体几何表示的代数框架来构建和分析多种量子编码，包括表面码、色码、扭曲环面码和X-cube分形模型等。

Method: 定义了“分层余极限码”：通过对一个从有限偏序集到链复形范畴的函子取度数意义上的余极限来构造。利用链复形函子的传递性和边界兼容性保证了边界算子平方为零，从而自然地产生CSS型逻辑扇区。通过矩阵史密斯范式和稀疏高斯消元法直接计算同调群来获得LDPC参数。

Result: 证明了该方法可以统一地恢复多种已知的量子码（表面码、色码、扭曲环面码、X-cube分形模型等），并且能够自然地扩展到代码缝合和双复形域壁等操作。计算出的LDPC码具有与其构造函子相似的稀疏性。

Conclusion: 分层余极限码提供了一个简洁的代数框架，能够统一地设计、分类和解码拓扑和分形量子码，而无需依赖于具体的几何可视化。

Abstract: We introduce \emph{stratified colimit codes}: stabiliser codes obtained by
taking the degree-wise colimit $\mathcal
C_\bullet(X):=\operatorname*{colim}_{\sigma\in X}F(\sigma)$ of a functor
$F\colon X\to\mathbf{Ch}(R)$ from a finite poset into the category of chain
complexes over a commutative ring~$R$. Axioms requiring only transitivity and
boundary-compatibility of the morphisms in $F$ ensure that $\partial^2=0$, so
the homology $H_\bullet$ and cohomology $H^\bullet$ furnish the usual CSS $Z$-
and $X$-type logical sectors; torsion in $H_\bullet$ classifies qudit charges
via the universal coefficient sequence. Varying $F$ recovers classical surface
and color codes, $\mathbb{RP}^2$ torsion codes, twisted toric families with
rate $k\sim d$, and X-cube style fracton models, all without referencing an
ambient cell complex. Matrix Smith normal form (PID case) and sparse Gaussian
elimination (field case) compute $H_\bullet$ directly, giving LDPC parameters
that inherit the sparsity of $F$. Because the construction is ring agnostic and
functorial, it extends naturally to code surgery (push-outs) and, at the next
categorical level, to bicomplex domain walls. Stratified colimit codes
therefore supply a concise algebraic chassis for designing, classifying, and
decoding topological and fractal quantum codes without ever drawing a lattice.

</details>


### [187] [Quantum algorithms for general nonlinear dynamics based on the Carleman embedding](https://arxiv.org/abs/2509.07155)
*David Jennings,Kamil Korzekwa,Matteo Lostaglio,Andrew T Sornborger,Yigit Subasi,Guoming Wang*

Main category: quant-ph

TL;DR: 该研究扩展了量子计算在求解非线性动力学系统中的应用范围，并证明了某些非线性振荡器问题的BQP-完备性。


<details>
  <summary>Details</summary>
Motivation: 现有量子算法在求解非线性动力学系统方面存在局限性，特别是仅限于纯耗散系统，这限制了其在众多重要问题上的应用。本研究旨在克服这些限制，扩展量子模拟的适用范围。

Method: 研究扩展了现有算法，使其能够处理更广泛的稳定系统，并考虑存在守恒多项式量的物理相关场景。此外，还对非共振系统进行了广泛分析，并推导了与庞加莱-迪拉克定理和卡尔曼矩阵对角化相关的结果。

Result: 研究表明，对于更广泛的非线性系统，存在高效的量子算法，并证明了指数大小的非线性振荡器问题的BQP-完备性。该研究还为卡尔曼方案的收敛性提供了独立的R数判据。

Conclusion: 本工作显著扩展了可由量子计算机有效模拟的非线性动力学系统的范围，并为该领域带来了新的理论见解和实际应用前景。

Abstract: Important nonlinear dynamics, such as those found in plasma and fluid
systems, are typically hard to simulate on classical computers. Thus, if
fault-tolerant quantum computers could efficiently solve such nonlinear
problems, it would be a transformative change for many industries. In a recent
breakthrough [Liu et al., PNAS 2021], the first efficient quantum algorithm for
solving nonlinear differential equations was constructed, based on a single
condition $R<1$, where $R$ characterizes the ratio of nonlinearity to
dissipation. This result, however, is limited to the class of purely
dissipative systems with negative log-norm, which excludes application to many
important problems. In this work, we correct technical issues with this and
other prior analysis, and substantially extend the scope of nonlinear dynamical
systems that can be efficiently simulated on a quantum computer in a number of
ways. Firstly, we extend the existing results from purely dissipative systems
to a much broader class of stable systems, and show that every quadratic
Lyapunov function for the linearized system corresponds to an independent
$R$-number criterion for the convergence of the Carlemen scheme. Secondly, we
extend our stable system results to physically relevant settings where
conserved polynomial quantities exist. Finally, we provide extensive results
for the class of non-resonant systems. With this, we are able to show that
efficient quantum algorithms exist for a much wider class of nonlinear systems
than previously known, and prove the BQP-completeness of nonlinear oscillator
problems of exponential size. In our analysis, we also obtain several results
related to the Poincar\'{e}-Dulac theorem and diagonalization of the Carleman
matrix, which could be of independent interest.

</details>


### [188] [No Global Counterfactual Consistency: A Universal epsilon-Robust Quantum No-Go Principle](https://arxiv.org/abs/2509.07000)
*Maximilian Ralph Peter von Liechtenstein*

Main category: quant-ph

TL;DR: 在一个允许有界扰动（ε-反事实）测量的量子力学单世界解释中，不可能为反事实推理的闭合网络分配全局一致的结果，即使存在轻微的测量扰动。该研究提出了无全局反事实一致性（NGCC）原理，该原理推广了先前的圆周无相互作用悖论（CIFP），并引入了排他性不等式，量子力学违反了这些不等式，表明单世界、非情境模型无法复制量子预测。


<details>
  <summary>Details</summary>
Motivation: 引入一种新的、更普遍的 no-go 原理（NGCC），它推广了最近提出的圆周无相互作用悖论（CIFP），以解决量子力学单世界解释中反事实推理的一致性问题，特别是在存在有界扰动测量的情况下。

Method: 提出 NGCC 原理，将其形式化为圆周一致性定理和一系列排他性不等式。使用图论方法、半定对偶和多圈排他性结构进行严格证明，并推导出 NGCC 边界。

Result: 证明了 NGCC 原理，该原理对任何非情境的、单世界的隐变量模型施加了约束。证明了量子力学在足够小的 ε 下违反了这些约束，表明现有的单世界、非情境模型无法完全复制量子力学的预测。

Conclusion: NGCC 原理表明，在允许有界扰动测量的量子力学单世界解释中，闭合网络中的反事实推理存在根本的不一致性。量子力学违反了由 NGCC 导出的排他性不等式，这排除了任何单世界、非情境模型（即使允许有界扰动）能够完全解释这些现象的可能性。

Abstract: In this article, we introduce No Global Counterfactual Consistency (NGCC), a
new foundational no-go principle generalizing the recently proposed Circular
Interaction-Free Paradox (CIFP). NGCC asserts that in any single-world
interpretation of quantum mechanics that permits bounded-disturbance
(epsilon-counterfactual) measurements, one cannot have a globally consistent
assignment of outcomes for a closed network of counterfactual inferences. In
essence, if multiple observers perform nearly interaction-free measurements
around a closed loop (or any network containing cycles), their locally certain
conclusions cannot all be mutually consistent in a single classical narrative.
We formalize this as a circular consistency theorem and a family of exclusivity
inequalities that any non-contextual, single-world hidden-variable model must
satisfy. These constraints extend the CIFP beyond an n-lab ring to arbitrary
network topologies, enforcing an NGCC bound on joint outcome probabilities.
Quantum mechanics violates these bounds for sufficiently small epsilon,
implying that no single-world, non-contextual model (even one allowing slight
measurement disturbance) can reproduce the quantum predictions in such
scenarios. Rigorous proofs are provided using graph-theoretic methods,
semidefinite duality, and multi-cycle exclusivity structures.

</details>


### [189] [Performance enhancement in Josephson traveling wave parametric amplifiers by tailoring the relative distance between junctions](https://arxiv.org/abs/2509.07292)
*M. A. Gali Labarias,T. Yamada,Y. Nakashima,Y. Urade,J. Claramunt,K. Inomata*

Main category: quant-ph

TL;DR: Josephson traveling wave parametric amplifiers can achieve higher gain and bandwidth by spatially displacing junctions within unit cells, with an optimal configuration predicted to yield over 29 dB gain on a 4 GHz bandwidth using 1998 junctions, though fabrication challenges exist.


<details>
  <summary>Details</summary>
Motivation: Investigate Josephson traveling wave parametric amplifiers with heterogeneously spaced junctions to enhance gain and bandwidth.

Method: Define system action and apply variational principle to obtain static action and equations of motion for unit cells with three spatially displaced junctions. Analyze the effect of junction spacing on gain and bandwidth. Explore combining this method with resonant-phase matching.

Result: Gain and bandwidth can be increased by modifying junction spacing, with an optimal sub-unit-cell size ratio maximizing both. Equally spaced junctions show minimum performance. The method can achieve high gain (above 29 dB) with a large number of junctions (1998) and a 4 GHz bandwidth when combined with resonant-phase matching.

Conclusion: Heterogeneous junction spacing in Josephson traveling wave parametric amplifiers offers a viable route to increased gain and bandwidth. While optimal fabrication may be challenging, sub-optimal configurations still provide substantial improvements. Combining this approach with resonant-phase matching shows potential for significant performance gains.

Abstract: Josephson traveling wave parametric amplifiers with heterogeneously spaced
junctions are theoretically investigated. We consider unit cells with three
junctions and characterize their interaction by spatially displaced fields
defined by node fluxes. To solve this problem we define the system action and
apply the variational principle to obtain the static action, which determines
the equations of motion. This work shows that gain and bandwidth can be
increased by modifying the relative distance between junctions within the same
unit cell, thus increasing the effective nonlinear interaction. We find an
optimal sub-unit-cell size ratio, which maximizes both gain and bandwidth,
while equally spaced junctions offer minimum performance. Even though this
method does not rely on phase-matching, the same device can operate at
different pump frequencies, it requires a very large number of JJs to achieve
gains above 20 dB. We show that this method can be combined with resonant-phase
matching and predicts an ideal gain above 29 dB on a 4 GHz bandwidth with 1998
junctions. Despite possible challenges fabricating devices at the optimal
sub-unit-cell size with current technologies, substantial gain increase can
still be achieved at sub-optimal sizes.

</details>


### [190] [Variational Quantum Linear Solver for Simulating Quantum Transport in Nanoscale Semiconductor Devices](https://arxiv.org/abs/2509.07005)
*Qimao Yang,Jing Guo*

Main category: quant-ph

TL;DR: 本文提出了一种改进的变分量子线性求解器（VQLS）方法，用于模拟量子输运，解决了传统方法在处理复杂、非对称矩阵时的计算挑战，并有望克服经典计算在处理高维问题时的“维度灾难”。


<details>
  <summary>Details</summary>
Motivation: 解决在量子输运模拟中，变分量子线性求解器（VQLS）应用于求解复杂的、非对称的线性系统所面临的挑战，而这在之前的研究中大多集中于求解具有实部对称系数矩阵的泊松方程。

Method: 提出新的成本函数形式来求解复杂非对称线性系统，并开发了高效的成本函数评估分解方法，以降低量子电路复杂度和提高噪声鲁棒性，用于通过非平衡格林函数方法求解量子输运方程。

Result: 开发了能够将VQLS应用于纳米尺度半导体器件量子输运模拟的仿真方法，并且在计算复杂度方面，所提出的基于量子计算的方法相对于经典计算方法在网格尺寸方面具有对数缩放的优势。

Conclusion: 所提出的基于量子计算的方法为解决半导体器件中量子输运的计算挑战提供了一个有前景的方向，有望克服经典计算在处理高维问题时的“维度灾难”。

Abstract: This work develops simulation methods that enable the application of the
variational quantum linear solver (VQLS) to simulate quantum transport in
nanoscale semiconductor devices. Most previous work on VQLS applications in
semiconductor device simulations focuses on solving the Poisson equation, where
the coefficient matrix of the sparse linear system is real and symmetric.
Solving the quantum transport equation, however, leads to coefficient matrices
that are complex and non-symmetric. This work addresses the challenges of
applying VQLS to quantum transport simulations. We propose new forms of cost
functions to solve complex and non-symmetric linear systems with faster
computing speed. We further develop efficient decomposition methods for cost
function evaluation, which target reducing the quantum circuit complexity and
improving noise robustness when solving the quantum transport equation using
the non-equilibrium Green's function method. While classical computation faces
the challenge of the "curse of dimensionality" as the spatial-energy numerical
grid dimensions grow, the proposed quantum-computing-based method scales
logarithmically with the grid size, which offers a promising opportunity for
addressing the computational challenges of solving quantum transport in
semiconductor devices.

</details>


### [191] [Quantum Arithmetic Algorithms: Implementation, Resource Estimation, and Comparison](https://arxiv.org/abs/2509.07015)
*Dmytro Fedoriaka,Brian Goldsmith,Yingrong Chen*

Main category: quant-ph

TL;DR: 本论文实现并评估了一个量子算法库，包括加法、乘法、除法和模幂运算，并利用 Azure 量子资源估计器进行了分析。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算技术的发展，对优化的量子算术电路的需求日益增长。

Method: 使用 Azure 量子资源估计器，评估了运行时间、量子比特使用情况、时空权衡，并为每种算术运算确定了性能最佳的算法。探索了除法的设计空间，优化了窗口化模幂运算，并确定了乘法器之间的最佳平衡点。

Result: 实现了一个量子算法库，包括加法、乘法、除法和模幂运算，并提供了相应的资源估计。

Conclusion: 本研究提供了一个实用的量子算法库和知识库，可用于实际应用中量子算术算法的选择和优化，并强调了并行化、复位操作和反算等技术在资源估算中的影响。

Abstract: As quantum computing technology advances, the need for optimized arithmetic
circuits continues to grow. This paper presents the implementation and resource
estimation of a library of quantum arithmetic algorithms, including addition,
multiplication, division, and modular exponentiation. Using the Azure Quantum
Resource Estimator, we evaluate runtime, qubit usage, and space-time trade-offs
and identify the best-performing algorithm for each arithmetic operation. We
explore the design space for division, optimize windowed modular
exponentiation, and identify the tipping point between multipliers,
demonstrating effective applications of resource estimation in quantum
research. Additionally, we highlight the impact of parallelization, reset
operations, and uncomputation techniques on implementation and resource
estimation. Our findings provide both a practical library and a valuable
knowledge base for selecting and optimizing quantum arithmetic algorithms in
real-world applications.

</details>


### [192] [On-chip microwave sensing of quasiparticles in tantalum superconducting circuits on silicon for scalable quantum technologies](https://arxiv.org/abs/2509.07669)
*Shima Poorgholam-Khanjari,Paniz Foshat,Mingqi Zhang,Valentino Seferai,Martin Weides,Kaveh Delfanazari*

Main category: quant-ph

TL;DR: 非平衡准粒子限制超导量子电路性能，本研究通过微波传感技术在钽基谐振器中探测准粒子，发现其密度低于氮化铌，并提出优化超导电路的新途径。


<details>
  <summary>Details</summary>
Motivation: 非平衡准粒子是限制超导量子电路性能和可扩展性的关键因素，导致微波损耗并缩短相干时间，因此理解和缓解这些激发对于发展可扩展量子技术至关重要。

Method: 利用高质量α-钽共面波导谐振器（在硅基底上）在单光子体制下，通过片上微波传感技术来探测非平衡准粒子。通过测量不同温度下的谐振器性能，并与理论预期值对比，以及在不同材料间进行基准测试。

Result: 在毫开尔文温度下，持续存在非平衡准粒子，导致内部品质因子（Qi）相比理论预期值存在可测量的抑制。与氮化铌（NbN）相比，在等效归一化温度（T/Tc）下，α-钽（α-Ta）的准粒子密度约为其三分之一，且微波损耗也相应降低。

Conclusion: 本研究提出的微波传感方法为探测准粒子动力学提供了一个可扩展的平台，并为工程化具有改进相干性的超导电路指明了新方向，该方法可应用于量子比特读出谐振器、动力学感应探测器以及新兴的量子处理器和传感器。

Abstract: The performance and scalability of superconducting quantum circuits are
fundamentally constrained by non-equilibrium quasiparticles, which induce
microwave losses that limit resonator quality factors and qubit coherence
times. Understanding and mitigating these excitations is therefore central to
advancing scalable quantum technologies. Here, we demonstrate on-chip microwave
sensing of quasiparticles in high-Q {\alpha}-tantalum coplanar waveguide
resonators on silicon, operated in the single-photon regime.
Temperature-dependent measurements reveal persistent non-equilibrium
quasiparticles at millikelvin temperatures, producing a measurable suppression
of the internal quality factor (Qi) relative to theoretical expectations. By
benchmarking across materials, we find that the quasiparticle density in
{\alpha}-Ta is approximately one-third that of NbN at equivalent normalised
temperatures (T/Tc), directly correlating with reduced microwave loss. Our
methodology establishes a scalable platform for probing quasiparticle dynamics
and points towards new routes for engineering superconducting circuits with
improved coherence, with impact on qubit readout resonators, kinetic-inductance
detectors, and emerging quantum processors and sensors.

</details>


### [193] [A Quantum Bagging Algorithm with Unsupervised Base Learners for Label Corrupted Datasets](https://arxiv.org/abs/2509.07040)
*Neeshu Rathi,Sanjeev Kumar*

Main category: quant-ph

TL;DR: 提出了一种基于QMeans聚类的量子装袋框架，以提高对标签噪声的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂的中间规模量子（NISQ）时代，开发抗噪声的量子机器学习（QML）算法至关重要。

Method: 利用QMeans聚类作为基础学习器，通过量子引导采样和多数表决进行集成，构建量子装袋框架。

Result: 在有噪声的分类和回归任务的模拟中，该量子装袋算法表现与经典KMeans相当，且比监督装袋方法更能抵抗标签噪声。

Conclusion: 无监督量子装袋在从不可靠数据中学习方面具有潜力。

Abstract: The development of noise-resilient quantum machine learning (QML) algorithms
is critical in the noisy intermediate-scale quantum (NISQ) era. In this work,
we propose a quantum bagging framework that uses QMeans clustering as the base
learner to reduce prediction variance and enhance robustness to label noise.
Unlike bagging frameworks built on supervised learners, our method leverages
the unsupervised nature of QMeans, combined with quantum bootstrapping via
QRAM-based sampling and bagging aggregation through majority voting. Through
extensive simulations on both noisy classification and regression tasks, we
demonstrate that the proposed quantum bagging algorithm performs comparably to
its classical counterpart using KMeans while exhibiting greater resilience to
label corruption than supervised bagging methods. This highlights the potential
of unsupervised quantum bagging in learning from unreliable data.

</details>


### [194] [Nested Grover's Algorithm for Tree Search](https://arxiv.org/abs/2509.07041)
*Andreas Wichert*

Main category: quant-ph

TL;DR: 本研究提出一种嵌套Grover算法优化量子树搜索，通过扩展部分赋值树深度并在剩余赋值子集中进行量子搜索来提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了优化量子树搜索算法，并克服传统启发式函数在量子树搜索中的不兼容性，提出一种新的方法。

Method: 采用嵌套Grover算法，扩展部分赋值树到特定深度，并在剩余赋值子集中进行量子搜索。引入部分候选解作为节点，定义级联Oracle，将量子树搜索分解为Grover算法。

Result: 该方法有望在量子树搜索中获得比传统Grover算法更好的结果，为量子人工智能应用奠定基础。

Conclusion: 嵌套Grover算法提供了一种有效的方法来优化量子树搜索，并为量子人工智能的发展开辟了道路。

Abstract: We investigate optimizing quantum tree search algorithms by employing a
nested Grover Algorithm. This approach seeks to enhance results compared to
previous Grover-based methods by expanding the tree of partial assignments to a
specific depth and conducting a quantum search within the subset of remaining
assignments. The study explores the implications and constraints of this
approach, providing a foundation for quantum artificial intelligence
applications. Instead of utilizing conventional heuristic functions that are
incompatible with quantum tree search, we introduce the partial candidate
solution, which indicates a node at a specific depth of the tree. By employing
such a function, we define the concatenated oracle, which enables us to
decompose the quantum tree search using Grover algorithm.

</details>


### [195] [Fourier Neural Operators for Time-Periodic Quantum Systems: Learning Floquet Hamiltonians, Observable Dynamics, and Operator Growth](https://arxiv.org/abs/2509.07084)
*Zihao Qi,Yang Peng,Christopher Earls*

Main category: quant-ph

TL;DR: FNO在模拟非平衡量子动力学方面是一种高效、准确且可扩展的替代方法，在不同时间离散化和系统驱动频率下具有出色的泛化能力，并且可以外推到训练数据之外的时间窗口。


<details>
  <summary>Details</summary>
Motivation: 时间周期性量子系统在远离平衡的现象以及量子工程和控制方面具有重要应用，但传统的数值模拟方法难以处理希尔伯特空间维度的指数增长和纠缠的快速扩展。因此，需要一种更有效的方法来模拟这些系统的动力学。

Method: 本文提出使用傅里叶神经网络算子（FNO）作为一种高效、准确且可扩展的非平衡量子动力学替代方法。FNO在傅里叶空间进行参数化，能够自然地捕捉时间相关性，并且对时间的离散化依赖性很小。研究人员通过三种学习范式展示了FNO的多功能性：重构有效的Floquet哈密顿量、预测局部可观测量值以及学习量子信息扩展。

Result: FNO在所有学习任务中都达到了显著的精度，并且与精确数值方法相比，速度有了显著提升。此外，FNO在不同时间离散化和系统驱动频率之间具有出色的迁移学习能力。研究还表明，FNO能够外推到训练数据的时间窗口之外，从而可以获得难以获得的可观测量和算子扩展动力学。通过采用合适的局部基，FNO的计算成本仅随系统尺寸呈多项式增长。

Conclusion: FNO是一种多功能且可扩展的非平衡量子动力学预测替代方法，有潜力应用于处理近期量子计算机的数据。

Abstract: Time-periodic quantum systems exhibit a rich variety of far-from-equilibrium
phenomena and serve as ideal platforms for quantum engineering and control.
However, simulating their dynamics with conventional numerical methods remains
challenging due to the exponential growth of Hilbert space dimension and rapid
spreading of entanglement. In this work, we introduce Fourier Neural Operators
(FNO) as an efficient, accurate, and scalable surrogate for non-equilibrium
quantum dynamics. Parameterized in Fourier space, FNO naturally captures
temporal correlations and remains minimally dependent on discretization of
time. We demonstrate the versatility of FNO through three complementary
learning paradigms: reconstructing effective Floquet Hamiltonians, predicting
expectation values of local observables, and learning quantum information
spreading. For each learning task, FNO achieves remarkable accuracy, while
attaining a significant speedup, compared to exact numerical methods. Moreover,
FNO possesses a remarkable capacity to transfer learning across different
temporal discretizations and system driving frequencies. We also show that FNO
can extrapolate beyond the time window provided by training data, enabling
access to observables and operator-spreading dynamics that might otherwise be
difficult to obtain. By employing an appropriate local basis, we argue that the
computational cost of FNOs scales only polynomially with the system size. Our
results establish FNO as a versatile and scalable surrogate for predicting
non-equilibrium quantum dynamics, with potential applications to processing
data from near-term quantum computers.

</details>


### [196] [Scaling Bound Entanglement through Local Extensions](https://arxiv.org/abs/2509.07086)
*Robin Krebs,Mariami Gachechiladze*

Main category: quant-ph

TL;DR: 研究了高维纠缠态的结构，并提出了一种新的构造方法。


<details>
  <summary>Details</summary>
Motivation: 高维纠缠态的结构难以表征，需要新的方法来构造和理解。

Method: 提出局部延拓（local extensions）的概念，它是剥离投影（peel-off projections）的逆过程，用于从低维纠缠态构造高维纠缠态。在此基础上，推导了施密特数（Schmidt number）在投影和延拓下的变化界限，并发现了生成高维绑定纠缠态（bound entangled states）的新机制。

Result: 构建了一个在局部维度为 4x5 的系统中的三维施密特数的正偏转态（positive-partial-transpose state），这是已知最小的此类系统。此外，还识别了一个优雅的广义网格态（generalized grid states）家族，其施密特数递增，包括一个七维施密特数为四的 7x7 状态和一个九维施密特数为五的 9x9 状态，表明在奇数局部维度 dxd 中存在 (d+1)/2 的缩放关系。

Conclusion: 提出了一种构造性的工具集，用于探测高维绑定纠缠态的缩放行为。

Abstract: Entanglement is a central resource in quantum information science, yet its
structure in high dimensions remains notoriously difficult to characterize. One
of the few general results on high-dimensional entanglement is given by
peel-off theorems, which relate the entanglement of a state to that of its
lower-dimensional local projections. We build on this idea by introducing local
extensions, the inverse process to peel-off projections, which provide a
systematic way to construct higher-dimensional entangled states from
lower-dimensional ones. This dual perspective leads to general bounds on how
the Schmidt number can change under projections and extensions, and reveals new
mechanisms for generating bound entangled states of higher dimensionality. As a
concrete application, we construct a positive-partial-transpose state of
Schmidt number three in local dimensions $4\times 5$, the smallest system known
to host such entanglement. We further extend this approach to identify an
elegant family of generalized grid states with increasing Schmidt number,
including explicit examples of a $7\times 7$ state with Schmidt number four and
a $9\times 9$ state with Schmidt number five, suggesting $(d+1)/2$ scaling in
odd local dimensions $d\times d$. Taken together, our results provide a
constructive toolkit for probing the scaling of bound entanglement in high
dimensions.

</details>


### [197] [An Egorov Theorem for Wasserstein Distances](https://arxiv.org/abs/2509.07185)
*Jordan Cotler,Felipe Hernández*

Main category: quant-ph

TL;DR: 证明了一个新的量子力学薛定谔绘景下的Egorov定理，使用了p-Wasserstein距离应用于量子态的Husimi函数。


<details>
  <summary>Details</summary>
Motivation: 在量子力学薛定谔绘景下，对Egorov定理进行新的证明，并引入p-Wasserstein距离和Husimi函数。

Method: 使用p-Wasserstein距离应用于量子态的Husimi函数来证明Egorov定理。

Result: 得到了Egorov定理的一个新版本，当p=1时是“低正则性”Egorov定理，p>1时得到更强的估计。作为分析的副产品，证明了一个最优传输不等式。

Conclusion: 该研究在量子力学框架下，通过引入p-Wasserstein距离和Husimi函数，对Egorov定理进行了推广，并得到了相关的最优传输不等式。

Abstract: We prove a new version of Egorov's theorem formulated in the Schr\"{o}dinger
picture of quantum mechanics, using the $p$-Wasserstein metric applied to the
Husimi functions of quantum states. The special case $p=1$ corresponds to a
"low-regularity" Egorov theorem, while larger values $p>1$ yield progressively
stronger estimates. As a byproduct of our analysis, we prove an optimal
transport inequality analogous to a result of Golse and Paul in the context of
mean-field many-body quantum mechanics.

</details>


### [198] [Quantum Filtering and Stabilization of Dissipative Quantum Systems via Augmented Neural Ordinary Differential Equations](https://arxiv.org/abs/2509.07196)
*Shahid Qamar,Rana Imran Mushtaq,Bo Li,Ho-Kin Tang*

Main category: quant-ph

TL;DR: AQNODE框架通过学习量子轨迹和耗散参数来模拟开放量子动力学，即使在缺乏完整哈密顿量或噪声模型的情况下也能实现精确的状态预测和反馈控制。


<details>
  <summary>Details</summary>
Motivation: 在量子控制和量子态估计中，如何在不知道系统哈密顿量或噪声模型完整信息的情况下对开放量子动力学进行建模是一个关键挑战。

Method: 提出了一种增强型量子神经常微分方程（AQNODE）框架，该框架利用神经ODE在潜在空间中演化系统，并直接从部分的连续测量数据中学习量子轨迹和耗散参数。该方法结合了弱测量数据来重构量子比特状态和时间依赖的退相干率，并集成了比例-微分和时变线性二次调节器（LQR）等AQNODE反馈控制策略。

Result: AQNODE能够精确地重构量子比特状态和时间依赖的退相干率，实现低预测误差和鲁棒的量子滤波与控制。数值模拟表明，该框架具有良好的泛化能力，能够处理不同系统配置，并支持实时建模和控制。

Conclusion: AQNODE是一个可扩展、可微分且与实验兼容的框架，适用于开放量子系统的实时建模和控制，解决了在信息不完整的情况下进行量子动力学建模的挑战。

Abstract: Modeling open quantum dynamics without full knowledge of the system
Hamiltonian or noise model is a key challenge in quantum control and quantum
state estimation. We introduce an Augmented Quantum Neural Ordinary
Differential Equation (AQNODE) framework that learns quantum trajectories and
dissipation parameters directly from partial continuous measurement data. By
embedding the system into a latent space evolved via neural ODEs, AQNODE
captures both observable and hidden non-Markovian dynamics with temporal
smoothness and physical consistency. Our approach integrates weak measurement
data to reconstruct qubit states and time-dependent decoherence rates, enabling
accurate state prediction and parameter inference without explicit physical
equations. Furthermore, we incorporate AQNODE-based feedback control
techniques, including proportional-derivative and time-varying linear-quadratic
regulator (LQR) strategies, to steer the quantum system toward target states in
real time. Extensive numerical simulations demonstrate AQNODE's ability to
generalize across system configurations, achieve low prediction errors, and
perform robust quantum filtering and control. These results establish AQNODE as
a scalable, differentiable, and experimentally compatible framework for
real-time modeling and control of dissipative quantum systems.

</details>


### [199] [Quantum Approximate and Quantum Walk Optimization Approaches to Set Balancing](https://arxiv.org/abs/2509.07200)
*Nikhil Kowshik,Sayan Manna,Sudebkumar Prasant Pal*

Main category: quant-ph

TL;DR: 本文将变分量子算法应用于NP难的集合平衡问题，通过将问题映射到Ising模型，并设计QUBO和Pauli-Z形式的成本哈密顿量，实现了QAOA和QWOA的优化。


<details>
  <summary>Details</summary>
Motivation: 集合平衡问题在临床试验设计和实验调度中至关重要，具有NP难的挑战性。本文旨在探索使用变分量子算法解决此类问题。

Method: 将集合平衡问题映射到Ising模型，采用QUBO和Pauli-Z形式的成本哈密顿量。实现了QAOA和QWOA算法，并对QAOA的六种混合哈密顿量（X, XY, Full-SWAP, Ring-SWAP, Grover, Warm-Started）进行了比较分析，使用了Pauli-string实现混合酉算子，并引入了基于香农熵的后处理技术来优化解决方案。

Result: 与传统的量子电路分解相比，Pauli-string实现的混合酉算子在QAOA中表现出更优越的性能。所提出的基于香农熵的后处理技术能够通过最大化特征分布的均匀性来改进解决方案。

Conclusion: 混合哈密顿量的选择和量子电路的实现对于提高QAOA在组合优化问题上的性能至关重要。

Abstract: We explore the application of variational quantum algorithms to the NP-hard
set balancing problem, a critical challenge in clinical trial design and
experimental scheduling. The problem is mapped to an Ising model, with tailored
Quadratic Unconstrained Binary Optimization (QUBO) formulations and cost
Hamiltonians expressed in Pauli-Z form. We implement both the Quantum
Approximate Optimization Algorithm (QAOA) and the Quantum Walk Optimization
Algorithm (QWOA), evaluating them in separate experimental settings. For QAOA,
we perform a comparative analysis of six mixer Hamiltonians (X, XY, Full-SWAP,
Ring-SWAP, Grover, and Warm-Started), employing scaled-exponential Pauli-string
realizations of the mixer unitaries, which yield superior performance over
conventional circuit decompositions. Additionally, we introduce a
Shannon-entropy-based post-processing technique that refines solutions by
maximizing feature-distribution uniformity across partitions. These results
underscore the importance of mixer choice and circuit implementation in
enhancing QAOA performance for combinatorial optimization.

</details>


### [200] [Locality, Micro- vs. Macro-, Particle Interpretations and All That: A Lagrangian Approach to the Measurement Problem](https://arxiv.org/abs/2509.07206)
*W. David Wick*

Main category: quant-ph

TL;DR: 作者在2017年提出的薛定谔方程非线性化理论无法进行


<details>
  <summary>Details</summary>
Motivation: 受A. O. Barut关于电动力学的研究启发，分析哪些非线性理论可以通过积分掉某些场来从拉格朗日场论中导出。

Method: 通过积分掉某些场来从拉格朗日场论中导出非线性理论，并探讨“什么是局部相互作用？”和“是否存在微观场和宏观场？”等问题。

Result: 分析结果表明，作者2017年的理论无法进行“粒子”解释，也无法通过将场分为两类来导出。

Conclusion: 作者2017年的理论无法进行“粒子”解释，也无法通过将场分为微观场和宏观场两类来导出。

Abstract: In 2017, this author proposed, as a resolution of the Measurement Problem,
that terms be added to Schrodinger's wavefunction equation, rendering it
nonlinear. Said equation derived from a trick employed by S. Weinberg in 1989
which may be unfamiliar to most physicists, as well as uninterpretable in terms
of local ("particle") interactions. Motivated by A. O. Barut's work on
electrodynamics, here I analyze which kinds of nonlinear theories can be
derived from Lagrangian field-theory by integrating out some fields. The issues
of "What is a local interaction?" and "Might there be Micro- and Macro-fields?"
arise. In the end, I will argue that my 2017 theory cannot be given a
"particle" interpretation, nor be derived from a splitting into the two
categories of fields.

</details>


### [201] [Construction of the Jaynes-Cummings interaction over the finite two-dimensional oscillator](https://arxiv.org/abs/2509.07215)
*Alejandro R. Urzúa*

Main category: quant-ph

TL;DR: 本文研究了二维笛卡尔坐标系中有限两个能级原子与有限二维振荡器之间的相互作用，构建了原子能级与有限振荡器退化能态之间的耦合，从而识别出能量守恒的本征基。通过相互作用绘景，展示了由原子介导的场平均值演化的动力学方法，并以 su(2) 相干态和本征能量态为例进行了研究。最后，为原子系统与有限谐振子耦合的研究提供了前景和展望。


<details>
  <summary>Details</summary>
Motivation: 研究两个能级原子与有限二维振荡器之间的相互作用，构建耦合，识别能量守恒的本征基，并展示场平均值演化的动力学方法。

Method: 构建了耦合，识别了能量守恒的本征基，并通过相互作用绘景展示了场平均值演化的动力学方法。

Result: 以 su(2) 相干态和本征能量态为例进行了研究。

Conclusion: 为原子系统与有限谐振子耦合的研究提供了前景和展望。

Abstract: The interaction between a two-level atom and the finite two-dimensional
oscillator in the Cartesian coordinate system is addressed. The construction of
the coupling between the degenerate energy states of the finite oscillator and
the two levels of the atom allows the identification of an excitation-conserved
eigenbasis. A dynamical approach to the evolution of mean values of the fields
mediated by the atom is shown in the interaction picture. As an example, the
eigenenergies states and $\mathfrak{su}(2)$ coherent states are studied.
Perspectives and prospectives are given to settle a path in the study of atomic
systems coupled to finite versions of the harmonic oscillator.

</details>


### [202] [Time evolution of controlled many-body quantum systems with matrix product operators](https://arxiv.org/abs/2509.07228)
*Llorenç Balada Gaggioli,Jakub Mareček*

Main category: quant-ph

TL;DR: 本研究提出一种使用矩阵乘积算子 (MPO) 描述多体受控量子系统时变演化动力学的方法，该方法通过应用 Magnus 展开和 Chebyshev polynomials 来求解含 MPO 哈密顿量的含时薛定谔方程，避免了传统的时间离散化，能够高效处理大规模优化问题，并已成功应用于量子最优控制中的量子门合成。


<details>
  <summary>Details</summary>
Motivation: 现有求解含 MPO 哈密顿量的时间依赖薛定谔方程 (TDSE) 的方法通常依赖于时间离散化，而本研究旨在提出一种新的方法来更有效地处理多体受控量子系统的时变演化。

Method: 本研究使用 Magnus 展开和 Chebyshev polynomials 来模拟时间演化，并利用 MPO 表示来有效地编码系统动力学，以求解含 MPO 哈密顿量的时间依赖薛定谔方程 (TDSE)。

Result: 该方法能够高效地处理多体受控量子系统，并已成功应用于量子最优控制中的量子门合成问题，证明了其在处理大规模优化问题方面的潜力，这些问题在稠密矩阵表示中难以处理。

Conclusion: 本研究提出的基于 Magnus 展开、Chebyshev polynomials 和 MPO 的方法，为描述多体受控量子系统的时变演化提供了一种可扩展且高效的解决方案，尤其在量子最优控制和量子门合成等大规模优化问题中显示出重要应用价值。

Abstract: We present a method for describing the time evolution of many-body controlled
quantum systems using matrix product operators (MPOs). Existing techniques for
solving the time-dependent Schr\"odinger equation (TDSE) with an MPO
Hamiltonian often rely on time discretization. In contrast, our approach uses
the Magnus expansion and Chebyshev polynomials to model the time evolution, and
the MPO representation to efficiently encode the system's dynamics. This
results in a scalable method that can be used efficiently for many-body
controlled quantum systems. We apply this technique to quantum optimal control,
specifically for a gate synthesis problem, demonstrating that it can be used
for large-scale optimization problems that are otherwise impractical to
formulate in a dense matrix representation.

</details>


### [203] [Demonstrating an unconditional separation between quantum and classical information resources](https://arxiv.org/abs/2509.07255)
*William Kretschmer,Sabee Grewal,Matthew DeCross,Justin A. Gerber,Kevin Gilmore,Dan Gresh,Nicholas Hunter-Jones,Karl Mayer,Brian Neyenhuis,David Hayes,Scott Aaronson*

Main category: quant-ph

TL;DR: 量子计算机在所需信息资源方面超越了经典计算机，证明了无需依赖未经验证的猜想的量子信息优势。


<details>
  <summary>Details</summary>
Motivation: 为了在量子信息科学中实现量子计算，需要展示传统计算机无法有效模拟的量子计算，这标志着量子控制能力和未来有用量子计算能力的重要里程碑。

Method: 在 Quantinuum 的 H1-1 trapped-ion 量子计算机上，通过解决一个需要 62 到 382 位内存的计算任务，同时仅使用 12 个量子比特，来展示无条件的量子优势。

Result: 在计算任务中，量子计算机仅使用 12 个量子比特，而最节省空间的经典算法需要 62 到 382 位内存。

Conclusion: 该结果提供了迄今为止最有力的证据，证明现有的量子处理器能够生成和操纵复杂纠缠态，从而利用希尔伯特空间的指数级增长。这种被称为“量子信息至上”的量子优势是一种新的量子计算基准，不依赖于未经证实的猜想。

Abstract: A longstanding goal in quantum information science is to demonstrate quantum
computations that cannot be feasibly reproduced on a classical computer. Such
demonstrations mark major milestones: they showcase fine control over quantum
systems and are prerequisites for useful quantum computation. To date, quantum
advantage has been demonstrated, for example, through violations of Bell
inequalities and sampling-based quantum supremacy experiments. However, both
forms of advantage come with important caveats: Bell tests are not
computationally difficult tasks, and the classical hardness of sampling
experiments relies on unproven complexity-theoretic assumptions. Here we
demonstrate an unconditional quantum advantage in information resources
required for a computational task, realized on Quantinuum's H1-1 trapped-ion
quantum computer operating at a median two-qubit partial-entangler fidelity of
99.941(7)%. We construct a task for which the most space-efficient classical
algorithm provably requires between 62 and 382 bits of memory, and solve it
using only 12 qubits. Our result provides the most direct evidence yet that
currently existing quantum processors can generate and manipulate entangled
states of sufficient complexity to access the exponentiality of Hilbert space.
This form of quantum advantage -- which we call quantum information supremacy
-- represents a new benchmark in quantum computing, one that does not rely on
unproven conjectures.

</details>


### [204] [Generalized Quantum Stein's Lemma for Classical-Quantum Dynamical Resources](https://arxiv.org/abs/2509.07271)
*Masahito Hayashi,Hayata Yamasaki*

Main category: quant-ph

TL;DR: 本论文针对量子信道转换问题，提出了适用于经典-量子（CQ）信道的广义量子Stein引理，并构建了一个无需渐进连续性假设的可逆量子资源理论框架，解决了现有方法在传统信道编码场景下的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的量子资源理论（QRTs）在处理静态资源（量子态）方面取得了进展，例如广义量子Stein引理，但对于动态资源（量子信道）的转换，特别是经典-量子（CQ）信道的转换，缺乏适用的框架。现有的扩展方法依赖于状态基础技术并引入了渐进连续性假设，这限制了其在传统信道编码中的应用。

Method: 本研究通过开发经典-量子（CQ）信道版的证明技术，直接为CQ信道制定并证明了广义量子Stein引理。在此基础上，构建了一个适用于CQ信道转换的可逆量子资源理论框架，并且该框架不需要渐进连续性假设。

Result: 研究成功地为CQ信道转换构建了一个无需渐进连续性假设的可逆量子资源理论框架，并证明了该框架可以应用于信道编码场景的分析。这为CQ信道的判别和转换提供了一个通用的工具集。

Conclusion: 本研究提出的广义量子Stein引理和可逆量子资源理论框架，为经典-量子（CQ）信道的判别和转换提供了完整的解决方案，克服了现有方法的局限性，并能广泛应用于核心的信道转换问题。

Abstract: Channel conversion constitutes a pivotal paradigm in information theory and
its applications to quantum physics, providing a unified problem setting that
encompasses celebrated results such as Shannon's noisy-channel coding theorem.
Quantum resource theories (QRTs) offer a general framework to study such
problems under a prescribed class of operations, such as those for encoding and
decoding. In QRTs, quantum states serve as static resources, while quantum
channels give rise to dynamical resources. A recent major advance in QRTs is
the generalized quantum Stein's lemma, which characterizes the optimal error
exponent in hypothesis testing to discriminate resource states from free
states, enabling a reversible QRT framework for static resources where
asymptotic conversion rates are fully determined by the regularized relative
entropy of resource. However, applications of QRTs to channel conversion
require a framework for dynamical resources. The earlier extension of the
reversible framework to a fundamental class of dynamical resources, represented
by classical-quantum (CQ) channels, relied on state-based techniques and
imposed an asymptotic continuity assumption on operations, which prevented its
applicability to conventional channel coding scenarios. To overcome this
problem, we formulate and prove a generalized quantum Stein's lemma directly
for CQ channels, by developing CQ-channel counterparts of the core proof
techniques used in the state setting. Building on this result, we construct a
reversible QRT framework for CQ channel conversion that does not require the
asymptotic continuity assumption, and show that this framework applies to the
analysis of channel coding scenarios. These results establish a fully general
toolkit for CQ channel discrimination and conversion, enabling their broad
application to core conversion problems for this fundamental class of channels.

</details>


### [205] [Quantum Advantage via Solving Multivariate Polynomials](https://arxiv.org/abs/2509.07276)
*Pierre Briaud,Itai Dinur,Riddhi Ghosal,Aayush Jain,Paul Lou,Amit Sahai*

Main category: quant-ph

TL;DR: 该工作提出了一种通过解决特定分布下有限域F_2上的（欠定）常数次数多变量方程组的平均情况NP搜索问题来（非交互式地、可验证地）证明量子优势的新方法。


<details>
  <summary>Details</summary>
Motivation: 为了证明量子优势，提出了一种解决特定分布下有限域F_2上的常数次数多变量方程组平均情况NP搜索问题的新方法。

Method: 基于Yamakawa-Zhandry（FOCS 2022）的量子算法框架，通过分析满足2-wise独立和shift-invariance的F_2多变量多项式分布诱导的傅里叶谱，来解决欠定常数次数多变量方程组。

Result: 设计了一种适用于任意d>=2的常数次数多项式分布，并证明存在一个期望多项式时间的量子算法可以同时解决对应的方程组。该方法在d>2时，基于现有的经典密码分析，推测经典计算难以找到解。

Conclusion: 该工作表明，次数为3的多项式足以实例化随机预言机，以获得非相对论性的量子优势。同时，该工作提出的新分析方法也为其他多变量系统的量子密码分析开辟了新的方向。

Abstract: In this work, we propose a new way to (non-interactively, verifiably)
demonstrate quantum advantage by solving the average-case $\mathsf{NP}$ search
problem of finding a solution to a system of (underdetermined) constant degree
multivariate equations over the finite field $\mathbb{F}_2$ drawn from a
specified distribution. In particular, for any $d \geq 2$, we design a
distribution of degree up to $d$ polynomials $\{p_i(x_1,\ldots,x_n)\}_{i\in
[m]}$ for $m<n$ over $\mathbb{F}_2$ for which we show that there is a expected
polynomial-time quantum algorithm that provably simultaneously solves
$\{p_i(x_1,\ldots,x_n)=y_i\}_{i\in [m]}$ for a random vector
$(y_1,\ldots,y_m)$. On the other hand, while solutions exist with high
probability, we conjecture that for constant $d > 2$, it is classically hard to
find one based on a thorough review of existing classical cryptanalysis. Our
work thus posits that degree three functions are enough to instantiate the
random oracle to obtain non-relativized quantum advantage.
  Our approach begins with the breakthrough Yamakawa-Zhandry (FOCS 2022)
quantum algorithmic framework. In our work, we demonstrate that this quantum
algorithmic framework extends to the setting of multivariate polynomial
systems.
  Our key technical contribution is a new analysis on the Fourier spectra of
distributions induced by a general family of distributions over $\mathbb{F}_2$
multivariate polynomials -- those that satisfy $2$-wise independence and
shift-invariance. This family of distributions includes the distribution of
uniform random degree at most $d$ polynomials for any constant $d \geq 2$. Our
analysis opens up potentially new directions for quantum cryptanalysis of other
multivariate systems.

</details>


### [206] [Process Tensor Approaches to Non-Markovian Quantum Dynamics](https://arxiv.org/abs/2509.07661)
*Jonathan Keeling,E. Miles Stoudenmire,Mari-Carmen Bañuls,David R. Reichman*

Main category: quant-ph

TL;DR: 该论文提出了一种基于过程张量和张量网络方法来处理开放量子系统中的非马尔可夫过程的技术，克服了传统马尔可夫近似的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于马尔可夫近似的开放量子系统模型虽然简化，但在许多实际情况下（如强耦合、结构化环境、低频模式耦合等）不够准确。因此，需要更精确且实用的方法来处理非马尔可夫过程。

Method: 利用过程张量的通用性，并结合高效的张量网络方法，来描述开放量子系统中的非马尔可夫动力学。

Result: 展示了该方法能够处理更广泛的开放量子系统和非马尔可夫过程，克服了传统方法的局限性。

Conclusion: 过程张量和张量网络方法的结合为精确描述各种开放量子系统中的非马尔可夫现象提供了一个强大且可行的途径。

Abstract: The paradigm of considering open quantum systems -- i.e. focusing only on the
system of interest, and treating the rest of the world as an effective
environment -- has proven to be a highly effective way to understand a range of
quantum systems, across areas of study such as quantum optics, cold atoms,
superconducting qubits, and impurities in solid-state systems. A common
approach in many of these contexts has been to consider simplified approaches
based on the Born and Markov approximations. While these approximations are
indeed often appropriate in contexts such as quantum optics, the widespread
application of these approximations has been driven more by simplicity than by
accuracy. In particular, these Markovian treatments will fail in many cases,
such as when coupling to the environment is not weak, when the environment is
structured and has resonances, when the system couples to low-frequency modes
of the environment, or when the questions of interest involve the propagation
of information through the environment. Despite the fact that many real
problems are non-Markovian, the Markov approximation is still widely used, as
it is often assumed that a fully non-Markovian treatment is too complex to be
practical. In this perspective we discuss a recently developed set of
techniques that address this challenge. Centering our discussion around the
notion of the process tensor, we demonstrate that the generality of the process
tensor concept, coupled with efficient tensor-network methods, opens the door
to the description of a wide range of observable non-Markovian processes in a
wide range of open quantum systems.

</details>


### [207] [Recursive algorithm for constructing antisymmetric fermionic states in first quantization mapping](https://arxiv.org/abs/2509.07279)
*E. Rule,I. A. Chernyshev,I. Stetcu,J. Carlson,R. Weiss*

Main category: quant-ph

TL;DR: We present a deterministic quantum algorithm for creating antisymmetric states of single-particle orbitals, outperforming sorting-based methods in certain scenarios by avoiding ordered input states and reducing Clifford-gate overhead. The algorithm uses O(N^2*sqrt(Ns)) T-gates and requires O(sqrt(Ns)) dirty ancilla qubits, with potential for further optimization using knowledge of single-particle states or a measurement-based variant.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a more efficient deterministic quantum algorithm for producing antisymmetric states of single-particle orbitals, addressing the limitations of existing sorting-based algorithms which require ordered input states and have high Clifford-gate overhead.

Method: The algorithm initializes the state of each particle independently and uses O(N^2*sqrt(Ns)) T-gates to prepare antisymmetrized states of non-trivial localized orbitals. It requires O(sqrt(Ns)) dirty ancilla qubits. The paper also explores optimizations by leveraging knowledge of single-particle states and a measurement-based variant.

Result: The algorithm achieves a gate complexity of O(N^2*sqrt(Ns)) T-gates and outperforms alternative algorithms when N is less than or equal to sqrt(Ns). It requires O(sqrt(Ns)) dirty ancilla qubits. Example circuits for two- and three-particle systems are provided, and a discussion on generalization and noise impact is included.

Conclusion: The proposed deterministic quantum algorithm offers an efficient method for generating antisymmetric states, with advantages over existing approaches, particularly for certain system sizes. Further improvements and analysis under noise are discussed.

Abstract: We devise a deterministic quantum algorithm to produce antisymmetric states
of single-particle orbitals in the first quantization mapping. Unlike
sorting-based antisymmetrization algorithms, which require ordered input states
and high Clifford-gate overhead, our approach initializes the state of each
particle independently. For a system of $N$ particles and $N_s$ single-particle
states, our algorithm prepares antisymmetrized states of non-trivial localized
(e.g., Hartree-Fock) orbitals using $O(N^2\sqrt{N_s})$ $T$-gates, outperforming
alternative algorithms when $N\lesssim \sqrt{N_s}$. To achieve such scaling, we
require $O(\sqrt{N_s})$ dirty ancilla qubits for intermediate calculations.
Knowledge of the single-particle states to be antisymmetrized can be leveraged
to further improve the efficiency of the circuit, and a measurement-based
variant reduces gate cost by roughly a factor of two. We show example circuits
for two- and three-particle systems and discuss the generalization to an
arbitrary number of particles. For a specific three-particle example, we
decompose the circuit into Clifford$+T$ gates and study the impact of noise on
the prepared state.

</details>


### [208] [Compressing Syndrome Measurement Sequences](https://arxiv.org/abs/2509.07288)
*Benjamin Anker,Milad Marvian*

Main category: quant-ph

TL;DR: 本研究提出了一种构建容错测量调度的框架，该框架通过组合稳定器生成器来处理不同长度的调度，并利用经典编码的组合来证明调度距离的结果。


<details>
  <summary>Details</summary>
Motivation: 为量子编码设计容错测量调度，以实现高效的错误纠正。

Method: 结合稳定器生成器来构建测量调度，并利用经典编码的组合来分析调度距离。

Result: 对于LDPC码，仅需O(d log r)次测量；对于通过自连接构造的码，需O(d log d log r)次测量。这两种情况下的测量次数都可能少于定义码的稳定器生成器的数量。研究还表明，可以通过牺牲稳定器权重来减少测量次数，并对表面码进行了数值 পরীক্ষা。

Conclusion: 所提出的框架能够有效地构建容错测量调度，并且在测量次数上具有优势，尤其是在LDPC码和自连接码的情况下。研究结果在表面码上得到了数值验证，证明了其在错误抑制方面的有效性。

Abstract: In this work, we analyze a framework for constructing fault-tolerant
measurement schedules of varying lengths by combining stabilizer generators,
and prove results about the distance of such schedules by combining according
to classical codes. Using this framework, we produce explicit measurement
schedules sufficient for fault-tolerant error correction of quantum codes of
distance $d$ with $r$ independent stabilizer generators using only $O(d
\log{r})$ measurements if the code is LDPC, and $O(d \log d \log r)$
measurements if the code is produced via concatenating a smaller code with
itself $O(\log d)$ times. In both of these cases the number of measurements can
be asymptotically fewer than the number of stabilizer generators which define
the code. Although optimizing our construction to use the fewest measurements
produces high-weight stabilizers, we also show that we can reduce the number of
measurements used for specific examples while maintaining low-weight stabilizer
measurements. We numerically examine the performance of our construction on the
surface code under several noise models and demonstrate the exponential error
suppression with increasing distance which is characteristic of weak fault
tolerance.

</details>


### [209] [Quantization of the electromagnetic fields from single atomic or molecular radiators](https://arxiv.org/abs/2509.07359)
*Valerica Raicu*

Main category: quant-ph

TL;DR: 本文提出了一个用于表达单原子或分子发射体的电磁（EM）势和场的框架，将其建模为振荡偶极子。


<details>
  <summary>Details</summary>
Motivation: 本框架旨在解决标准电磁场量子化方法中的简化假设问题，并探讨这些假设对能量和动量量子化结果的影响。

Method: 使用新提出的求解任意时间依赖性电荷分布的非均匀波动方程的方法，来推导电磁势和场的精确表达式。

Result: 通过该框架得到的精确表达式，用于量化来自单发射体的电磁场，并恢复了与经典偶极子辐射模式的一致性，同时保持了量子力学对量子模式概率分布的描述。

Conclusion: 该分析有助于理解光或真空场涨落激发的原子或分子光子发射过程，并提出了可能的实验检验和实际应用。

Abstract: A framework is introduced for expressing electromagnetic (EM) potentials and
fields of single atomic or molecular emitters modeled as oscillating dipoles,
which follows a recently proposed method for solving inhomogeneous wave
equations for arbitrary, time-dependent distributions of charge. This framework
is first used to evaluate the physical implications of simplifying assumptions
made in the standard approach to quantization of the EM fields and the impact
of such assumptions on the results of energy and momentum quantization. Then,
the exact expressions for the EM potentials and fields, in relation to the
oscillating (transition) dipoles properties, afforded by the present framework
are used to quantize electromagnetic fields from single emitters and restore
the agreement with the well-known classical dipole radiation pattern, while
maintaining the quantum mechanical description of electromagnetic radiation in
terms of the probability distribution of quantum modes. Contributions of the
present analysis to the understanding of photon emission from excited atoms or
molecules stimulated by light or vacuum field fluctuations are highlighted, and
possible experimental tests and practical applications are proposed.

</details>


### [210] [Near optimal quantum algorithm for estimating Shannon entropy](https://arxiv.org/abs/2509.07452)
*Myeongjin Shin,Kabgyun Jeong*

Main category: quant-ph

TL;DR: 我们提出了一个近乎最优的量子算法，用于在量子概率预言机模型中估计香农熵。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是找到一个高效的量子算法来估计香农熵，并确定其查询复杂度的下限。

Method: 该方法结合了奇异值分离算法、量子幅度放大以及量子奇异值变换。为了建立查询下限，我们构造了通过预言机中的汉明权重编码的概率分布。

Result: 我们得到了估计香农熵的查询复杂度为 $\tilde{\Theta}\left(\tfrac{\sqrt{n}}{\epsilon}\right)$，其中 $\epsilon$ 是加性误差。

Conclusion: 研究表明，在量子概率预言机模型中，估计香农熵的精确查询复杂度（在 $\epsilon$-加性误差内）是 $\tilde{\Theta}\left(\tfrac{\sqrt{n}}{\epsilon}\right)$。

Abstract: We present a near-optimal quantum algorithm, up to logarithmic factors, for
estimating the Shannon entropy in the quantum probability oracle model. Our
approach combines the singular value separation algorithm with quantum
amplitude amplification, followed by the application of quantum singular value
transformation. On the lower bound side, we construct probability distributions
encoded via Hamming weights in the oracle, establishing a tight query lower
bound up to logarithmic factors. Consequently, our results show that the tight
query complexity for estimating the Shannon entropy within $\epsilon$-additive
error is given by $\tilde{\Theta}\left(\tfrac{\sqrt{n}}{\epsilon}\right)$.

</details>


### [211] [Large-scale Efficient Molecule Geometry Optimization with Hybrid Quantum-Classical Computing](https://arxiv.org/abs/2509.07460)
*Yajie Hao,Qiming Ding,Xiaoting Wang,Xiao Yuan*

Main category: quant-ph

TL;DR: 使用结合了密度矩阵嵌入理论（DMET）和变分量子特征求解器（VQE）的联合优化框架，大大减少了量子化学中大型分子几何结构预测所需的量子资源和计算成本。


<details>
  <summary>Details</summary>
Motivation: 准确有效地预测大分子的平衡几何结构是量子计算化学中的核心挑战，即使使用混合量子-经典算法也是如此。量子比特数量大和传统嵌套优化成本高是主要障碍。

Method: 提出了一种结合密度矩阵嵌入理论（DMET）和变分量子特征求解器（VQE）的联合优化框架。

Result: 该框架在H4和H2O2等基准系统上得到验证，并在乙醇酸（C2H4O3）的平衡几何结构确定方面显示出其有效性，该分子的大小以前被认为对于量子几何优化来说是难以处理的。结果表明，该方法在大幅降低计算成本的同时实现了高精度。

Conclusion: 该工作代表了实现实际、可扩展的量子模拟的重要一步，超越了历史上主导该领域的微小、概念验证分子。更广泛地说，该框架为利用量子优势进行复杂催化剂和药物的计算机辅助设计提供了切实可行的途径。

Abstract: Accurately and efficiently predicting the equilibrium geometries of large
molecules remains a central challenge in quantum computational chemistry, even
with hybrid quantum-classical algorithms. Two major obstacles hinder progress:
the large number of qubits required and the prohibitive cost of conventional
nested optimization. In this work, we introduce a co-optimization framework
that combines Density Matrix Embedding Theory (DMET) with Variational Quantum
Eigensolver (VQE) to address these limitations. This approach substantially
reduces the required quantum resources, enabling the treatment of molecular
systems significantly larger than previously feasible. We first validate our
framework on benchmark systems, such as H4 and H2O2, before demonstrating its
efficacy in determining the equilibrium geometry of glycolic acid C2H4O3, a
molecule of a size previously considered intractable for quantum geometry
optimization. Our results show the method achieves high accuracy while
drastically lowering computational cost. This work thus represents a
significant step toward practical, scalable quantum simulations, moving beyond
the small, proof-of-concept molecules that have historically dominated the
field. More broadly, our framework establishes a tangible path toward
leveraging quantum advantage for the in silico design of complex catalysts and
pharmaceuticals.

</details>


### [212] [Carrier-Assisted Entanglement Purification](https://arxiv.org/abs/2509.07514)
*Jaemin Kim,Karthik Mohan,Sung Won Yun,Joonwoo Bae*

Main category: quant-ph

TL;DR: 该工作提出了一种仅使用量子存储器和单量子比特通信的纠缠提纯方案，可以提纯共享的噪声纠缠态。


<details>
  <summary>Details</summary>
Motivation: 为了在量子网络中实现纠缠提纯，需要克服量子存储和相干量子操作等技术挑战。

Method: 提出了一种载体辅助的纠缠提纯协议，利用量子存储器存储单份共享纠缠态，并利用单量子比特在通信双方之间传输。研究了单量子比特传输无噪声和有噪声两种情况下的提纯效果，并通过引入多量子比特通信克服了噪声信道的限制。

Result: 在单量子比特传输无噪声时，该协议可以提纯噪声纠缠态。在单量子比特传输有噪声时，协议的提纯效果依赖于信道的类型，并给出了协议适用的噪声信道类型。当使用多量子比特通信时，只要信道不是破坏纠缠的信道，该协议就能在有噪声信道中实现提纯。

Conclusion: 该协议显著降低了纠缠提纯所需的实验开销，为实现长距离纯纠缠态提供了更实际的方案。

Abstract: Entanglement distillation, a fundamental building block of quantum networks,
enables the purification of noisy entangled states shared among distant nodes
by local operations and classical communication. Its practical realization
presents several technical challenges, including the storage of quantum states
in quantum memory and the execution of coherent quantum operations on multiple
copies of states within the quantum memory. In this work, we present an
entanglement purification protocol via quantum communication, namely a
carrier-assisted entanglement purification protocol, which utilizes two
elements only: i) quantum memory for a single-copy entangled state shared by
parties and ii) single qubits travelling between parties. We show that the
protocol, when single-qubit transmission is noiseless, can purify a noisy
entangled state shared by parties. When single-qubit transmission is noisy, the
purification relies on types of noisy qubit channels; we characterize qubit
channels such that the protocol works for the purification. We resolve the
limitation by applying multiple qubits over noisy channels, and show that the
purification protocol with multi-carrier qubits works through a noisy qubit
channel in general, provided that the channels are not entanglement-breaking,
i.e., channels that cannot be constructed as measure-and-prepare operations.
Our results significantly reduce the experimental overhead needed for
distilling entanglement, such as quantum memory and coherent operations, making
long-distance pure entanglement closer to a practical realization.

</details>


### [213] [Absorbing detectors meet scattering theory](https://arxiv.org/abs/2509.07518)
*Will Cavendish,Siddhant Das*

Main category: quant-ph

TL;DR: ABC 理论与散射理论在量子力学屏幕问题上的预测存在不一致，ABC 理论的预测与实验数据相矛盾。


<details>
  <summary>Details</summary>
Motivation: 量子力学中的“屏幕问题”是预测粒子到达时间和撞击位置的联合分布的挑战，任何解决方案都必须与散射实验的数据一致。本文旨在直接检验吸收边界条件（ABC）方法在解决屏幕问题上的有效性。

Method: 通过求解一维和二维的精确可解示例，对比 ABC 提案和散射理论（ST）的预测。

Result: ABC 提案预测了与现有实验数据相矛盾的、依赖于动量和屏幕方向的尖锐探测概率以及二次反射。

Conclusion: 虽然未来可能存在符合 ABC 提案的物理探测器，但该提案作为屏幕问题的通用解决方案在经验上是不充分的，因为它与标准实验设置中探测器的行为不一致。

Abstract: Any proposed solution to the "screen problem" in quantum mechanics -- the
challenge of predicting the joint distribution of particle arrival times and
impact positions -- must align with the extensive data obtained from scattering
experiments. In this paper, we conduct a direct consistency check of the
Absorbing Boundary Condition (ABC) proposal, a prominent approach to address
the screen problem, against the predictions derived from scattering theory
(ST). Through a series of exactly solvable one- and two-dimensional examples,
we demonstrate that the ABC proposal's predictions are in tension with the
well-established results of ST. Specifically, it predicts sharp momentum- and
screen-orientation-dependent detection probabilities, along with secondary
reflections that contradict existing experimental data. We conclude that while
it remains possible that physical detectors described by the ABC proposal could
be found in the future, the proposal is empirically inadequate as a general
solution to the screen problem, as it is inconsistent with the behavior of
detectors in standard experimental settings.

</details>


### [214] [Receiver Noise Calibration in CV-QKD accounting for Noise Dynamics](https://arxiv.org/abs/2509.07549)
*Guillaume Ricard,Yves Jaouën,Romain Alléaume*

Main category: quant-ph

TL;DR: 现有的连续变量量子密钥分发（CV-QKD）的噪声校准方法未能充分考虑本振（LO）噪声和噪声频谱特性，导致单光子探测器暗计数（SNC）校准不精确。本文提出了一个新的操作框架，用于推导给定实验的最佳校准持续时间，并引入了一种新的SNC方法，该方法考虑了噪声频谱特性。


<details>
  <summary>Details</summary>
Motivation: 传统的CV-QKD校准方法过于简化噪声特性，忽略了本振（LO）噪声和噪声频谱特性的影响，导致单光子探测器暗计数（SNC）校准不精确，影响了量子通信的安全性。

Method: 1) 提出一个基于平稳性概念的操作校准框架。2) 在此框架内，推导出给定实验的最佳校准持续时间。3) 利用噪声频谱特性的知识，引入一种新的SNC方法。

Result: 改进的校准技术具有更高的性能和对接收器缺陷的更高容忍度，可以提高CV-QKD系统的性能和成本效益。

Conclusion: 本文提出的新SNC方法考虑了噪声频谱特性，并优化了校准过程，提高了CV-QKD系统的性能和鲁棒性，为CV-QKD协议的认证提供了更好的基础。

Abstract: Continuous-Variable Quantum Key Distribution (CV-QKD) relies on accurate
noise calibration at the receiver to ensure the security of quantum
communication. Traditional calibration methods often oversimplify noise
characteristics, neglecting the impact of local oscillator (LO) noise and the
critical role of noise spectral properties, which can lead to imprecise Shot
Noise Calibration (SNC). Our contributions are threefold: 1) we propose an
operational framework for calibration, relying on the notion of stationarity 2)
in this framework, we give a method allowing us to derive the optimal
calibration duration for a given experiment 3) leveraging our knowledge of
noise spectral properties, we introduce a novel SNC method. This work also
formalizes the calibration procedures, addressing implicit assumptions and
providing a better foundation for the certification of CV-QKD protocols, of
which calibration is a fundamental part. We demonstrate that our improved
calibration technique offers higher performance and higher tolerance to
receiver imperfections, which can enhance the performance and
cost-effectiveness of CV-QKD systems.

</details>


### [215] [Path Integral Approach to Input-Output Theory](https://arxiv.org/abs/2509.07563)
*Aaron Daniel,Matteo Brunelli,Aashish A. Clerk,Patrick P. Potts*

Main category: quant-ph

TL;DR: We present a new approach to input-output theory using Schwinger-Keldysh path integrals, which simplifies the analysis of nonlinear quantum systems and provides access to full output field statistics. We applied this to a Kerr nonlinear oscillator and found a novel reduction in reflection associated with light squeezing.


<details>
  <summary>Details</summary>
Motivation: The existing input-output theory in quantum optics, while widely applicable, can be cumbersome for nonlinear systems. There is a need for a more streamlined approach that grants direct access to comprehensive output field statistics.

Method: We employ the Schwinger-Keldysh path integral formalism, a tool from non-equilibrium quantum field theory, to reformulate input-output theory. This allows for direct calculation of first and second-order coherence functions and simplifies the treatment of nonlinearities through diagrammatic techniques.

Result: We computed the output field statistics of a Kerr nonlinear oscillator at finite temperatures. Our results show a reduction in reflection that is not caused by photon loss but is instead related to the squeezing of the output light.

Conclusion: The Schwinger-Keldysh path integral formalism offers a powerful and simplified method for input-output theory, particularly for nonlinear quantum systems. It provides direct access to full output statistics and reveals new physical phenomena, such as reflection reduction due to light squeezing.

Abstract: Input-output theory is a well-known tool in quantum optics and ubiquitous in
the description of quantum systems probed by light. Owing to the generality of
the setup it describes, the theory finds application in a wide variety of
experiments in circuit and cavity QED. We present an approach to input-output
theory using the Schwinger-Keldysh path integral formalism that gives us direct
access to the full output field statistics such as the first and second order
coherence functions. By making the rich toolbox of non-equilibrium quantum
field theory accessible, our formalism greatly simplifies the treatment of
nonlinear systems and provides a uniform way of obtaining perturbative results.
We showcase this particular strength by computing the output field statistics
of a Kerr nonlinear oscillator at finite temperatures through the use of
diagrams and diagram summation techniques. We find a reduction in reflection
that is not due to photon leakage but rather associated to the squeezing of the
output light.

</details>


### [216] [On the Complexity of Quantum States and Circuits from the Orthogonal and Symplectic Groups](https://arxiv.org/abs/2509.07573)
*Oxana Shaya,Zoë Holmes,Christoph Hirche,Armando Angrisani*

Main category: quant-ph

TL;DR: 随机量子态和量子电路的复杂性对于量子信息科学至关重要。本研究探讨了从酉群的辛群和特殊正交群中提取的酉变换，并利用测度集中现象，得出随机量子态通常具有指数级强的状态复杂性，并且彼此之间几乎正交。此外，研究还表明，由这些经典酉群组成的电路在平均情况下学习是困难的。这些结果表明，结构子群的复杂性可能与整个酉群相当。


<details>
  <summary>Details</summary>
Motivation: 理解量子态和量子电路的复杂性是量子信息科学中的一个核心挑战，这在多体物理、高能物理和量子学习理论等领域具有广泛影响。

Method: 通过利用测度集中现象，研究从酉群的辛群和特殊正交群中提取的酉变换。

Result: 随机量子态通常具有指数级强的状态复杂性，并且彼此之间几乎正交。由这些经典酉群组成的电路在平均情况下学习是困难的。

Conclusion: 结构子群可以表现出与整个酉群相当的复杂性。

Abstract: Understanding the complexity of quantum states and circuits is a central
challenge in quantum information science, with broad implications in many-body
physics, high-energy physics and quantum learning theory. A common way to model
the behaviour of typical states and circuits involves sampling unitary
transformations from the Haar measure on the unitary group. In this work, we
depart from this standard approach and instead study structured unitaries drawn
from other compact connected groups, namely the symplectic and special
orthogonal groups. By leveraging the concentration of measure phenomenon, we
establish two main results. We show that random quantum states generated using
symplectic or orthogonal unitaries typically exhibit an exponentially large
strong state complexity, and are nearly orthogonal to one another. Similar
behavior is observed for designs over these groups. Additionally, we
demonstrate the average-case hardness of learning circuits composed of gates
drawn from such classical groups of unitaries. Taken together, our results
demonstrate that structured subgroups can exhibit a complexity comparable to
that of the full unitary group.

</details>


### [217] [Multiparameter quantum metrology at Heisenberg scaling for an arbitrary two-channel linear interferometer with squeezed light](https://arxiv.org/abs/2509.07574)
*Atmadev Rai,Danilo Triggiani,Paolo Facchi,Vincenzo Tamma*

Main category: quant-ph

TL;DR: 该论文提出了一种框架，用于以海森堡极限精度同时估计通用的双通道酉U(2)的所有四个实参数。


<details>
  <summary>Details</summary>
Motivation: 在量子计量学中，同时估计多参数的精度是一个关键挑战。该研究旨在解决通用双通道酉U(2)的四参数同时估计问题，并达到海森堡极限精度。

Method: 论文推导了量子费雪信息矩阵的解析表达式，并使用实验上可行的两模压缩态或单模压缩态等高斯探针，证明了所有参数均可达到1/N的海森堡极限精度。

Result: 所有参数均达到1/N的海森堡极限精度，该框架适用于通用的双通道酉U(2)系统。

Conclusion: 该研究将多参数计量学扩展到最通用的双模场景，为实现具有实验可行资源的海森堡极限多参数光学干涉测量提供了具体的设计原则。这不仅揭示了压缩光量子干涉与多参数估计中量子计量优势之间的基本联系，也为在任意光学网络中发展基于分布式量子计量的量子技术奠定了重要基石。

Abstract: We present a framework for simultaneously estimating all four real parameters
of a general two-channel unitary U(2) with Heisenberg-scaling precision. We
derive analytical expressions for the quantum Fisher information matrix and
show that all parameters attain the 1/N scaling in the precision by using
experimentally feasible Gaussian probes such as two-mode squeezed states or two
single-mode squeezed states. Our results extend multiparameter metrology to its
most general two-mode setting and establish concrete design principles for
experimental implementations of Heisenberg-scaling, multi-parameter optical
interferometry with experimentally feasible resources. It not only sheds light
on the fundamental interface between quantum interference of squeezed light and
quantum metrological advantage in multiparameter estimation, but it also
provides an important stepstone towards the development of a wide range of
quantum technologies based on distributed quantum metrology in arbitrary
optical networks.

</details>


### [218] [All you need is controlled-V: universality of a standard two-qubit gate by catalytic embedding](https://arxiv.org/abs/2509.07578)
*Robin Kaarsgaard*

Main category: quant-ph

TL;DR: controlled-V 门在计算上是通用的。


<details>
  <summary>Details</summary>
Motivation: 研究 controlled-V 门的计算能力，以及它在量子计算中的表达能力。

Method: 将 controlled-V 门与 Clifford+Toffoli 和 Clifford+T 门集进行比较，以评估其模拟能力。

Result: Controlled-V 门可以模拟 Clifford+Toffoli 门集，只需要最多两个干净的辅助量子比特和恒定的门计数开销；并且，只需要一个额外的辅助量子比特就可以模拟 Clifford+T。

Conclusion: 该结果解决了 De Vos 的基于 Negator 的门集的表达能力问题，并表明 Sleator 和 Weinfurter 的双量子比特门 $SU^{(	au)}$ 即使在 $	au$ 的有理数选择下也能够进行通用的量子计算。

Abstract: We present an encoding that renders the controlled-V gate (also known as
controlled-$\sqrt{X}$) computationally universal in isolation. Specifically, we
show that this gate can simulate the universal Clifford+Toffoli gate set with
at most two clean auxiliary qubits and a constant overhead in gate count, and
that an additional auxiliary qubit suffices to simulate Clifford+T. Our result
settles an open question on the expressiveness of De Vos' gate set based on
Negators, and shows that the two-qubit gate $SU^{(\tau)}$ due to Sleator and
Weinfurter is capable of universal quantum computation even for rational
choices of $\tau$.

</details>


### [219] [From Classical Data to Quantum Advantage -- Quantum Policy Evaluation on Quantum Hardware](https://arxiv.org/abs/2509.07614)
*Daniel Hein,Simon Wiedemann,Markus Baumann,Patrik Felbinger,Justin Klein,Maximilian Schieder,Jonas Stein,Daniëlle Schuman,Thomas Cope,Steffen Udluft*

Main category: quant-ph

TL;DR: 通过量子机器学习在量子硬件上学习环境参数，并将其应用于量子策略评估。


<details>
  <summary>Details</summary>
Motivation: 将量子机器学习（QML）与量子策略评估（QPE）相结合，实现在量子硬件上进行强化学习（RL）中的策略评估，并有望实现量子优势。

Method: 利用量子机器学习（QML）从经典观测数据中学习量子环境的参数，然后在量子硬件上实现学习到的量子环境，并将其应用于量子策略评估（QPE）。

Result: 在量子硬件上成功地进行了QML和QPE的实验，证明了将QML和QPE集成在量子硬件上进行策略评估的可行性，并显示出在RL中实现量子优势的潜力，尽管存在噪声和相干时间短等挑战。

Conclusion: 将QML和QPE集成在量子硬件上进行策略评估，在RL中具有实现量子优势的巨大潜力，尽管仍面临技术挑战。

Abstract: Quantum policy evaluation (QPE) is a reinforcement learning (RL) algorithm
which is quadratically more efficient than an analogous classical Monte Carlo
estimation. It makes use of a direct quantum mechanical realization of a finite
Markov decision process, in which the agent and the environment are modeled by
unitary operators and exchange states, actions, and rewards in superposition.
Previously, the quantum environment has been implemented and parametrized
manually for an illustrative benchmark using a quantum simulator. In this
paper, we demonstrate how these environment parameters can be learned from a
batch of classical observational data through quantum machine learning (QML) on
quantum hardware. The learned quantum environment is then applied in QPE to
also compute policy evaluations on quantum hardware. Our experiments reveal
that, despite challenges such as noise and short coherence times, the
integration of QML and QPE shows promising potential for achieving quantum
advantage in RL.

</details>


### [220] [Variational Quantum Circuits in Offline Contextual Bandit Problems](https://arxiv.org/abs/2509.07633)
*Lukas Schulte,Daniel Hein,Steffen Udluft,Thomas A. Runkler*

Main category: quant-ph

TL;DR: 量子模型可用于解决工业优化中的离线上下文老虎机问题。


<details>
  <summary>Details</summary>
Motivation: 探索在工业优化任务中应用变分量子电路（VQC）解决离线上下文老虎机问题。

Method: 使用工业基准（IB）环境，将量子回归模型与经典模型进行性能比较。

Result: 量子模型能有效拟合复杂奖励函数，通过粒子群优化（PSO）识别最优配置，并在噪声和稀疏数据集中具有良好的泛化能力。

Conclusion: 为在离线上下文老虎机问题中使用VQC提供了概念验证，并强调了其在工业优化任务中的潜力。

Abstract: This paper explores the application of variational quantum circuits (VQCs)
for solving offline contextual bandit problems in industrial optimization
tasks. Using the Industrial Benchmark (IB) environment, we evaluate the
performance of quantum regression models against classical models. Our findings
demonstrate that quantum models can effectively fit complex reward functions,
identify optimal configurations via particle swarm optimization (PSO), and
generalize well in noisy and sparse datasets. These results provide a proof of
concept for utilizing VQCs in offline contextual bandit problems and highlight
their potential in industrial optimization tasks.

</details>


### [221] [Simulation of one and two qubit superconducting quantum gates under the non-Markovian $1/f$ noise](https://arxiv.org/abs/2509.07693)
*Yinjia Chen,Shuocang Zhang,Qiang Shi*

Main category: quant-ph

TL;DR: HEOM框架可有效模拟1/f噪声对超导量子比特的影响，并为单比特和双比特门提供了新的错误机制见解。


<details>
  <summary>Details</summary>
Motivation: 由于1/f噪声是超导量子比特主要的退相干源，但其缓慢特性给精确模拟带来挑战，因此需要开发新的模拟方法。

Method: 开发了一种分级方程（HEOM）框架，用于在1/f噪声下对量子比特动力学和门操作进行有效且可靠的建模。对有限脉冲持续时间的动力学解耦序列进行了分析。将该框架扩展到双量子比特交叉共振（CR）门，并重建了完整的Choi矩阵和Pauli传输矩阵（PTM）。

Result: 结果表明，微扰量子主方程可能无法复制与慢浴耦合的量子比特的正确退相干动力学。不同的脉冲序列导致错误累积行为不同：所有X-CPMG序列都表现出与奇偶校验效应的线性缩放，Y-CPMG呈现二次增长，而交替的XY型序列可以显著抑制错误累积。最后，研究了1/f噪声引起的非相干误差。

Conclusion: HEOM框架被确立为模拟超导电路中环境噪声的稳健方法，并为理解单量子比特和双量子比特门中的错误机制提供了新的见解。

Abstract: Non-Markovian $1/f$ noise consists a dominant source of decoherence in
superconducting qubits, yet its slow nature poses a significant challenge for
accurate simulation. Here we develop a hierarchical equations of motion (HEOM)
framework that enables efficient and reliable modeling of qubit dynamics and
gate operations under $1/f$ noise. By using the approach, it is first shown
that perturbative quantum master equations may fail to reproduce the correct
dephasing dynamics of a qubit coupled to slow baths. We then analyze dynamical
decoupling sequences by including effects of finite pulse duration. It is found
that different pulse sequences results in different behavior in error
accumulation: all X-CPMG sequences exhibit linear scaling with parity effects,
Y-CPMG follows quadratic growth, and alternating XY-type sequences can suppress
the error accumulation significantly. Finally, we extend the framework to
two-qubit cross-resonance (CR) gates, reconstructing the full Choi matrix and
Pauli Transfer Matrix (PTM) to identify the incoherent error induced by $1/f$
noise. Together, these results establish HEOM as a robust methodology for
simulating the environmental noise in superconducting circuits and provide new
insights into error mechanisms in both single- and two-qubit gates.

</details>


### [222] [Weakly-Driven Quantum Walks for Memory-Constrained Pauli Channel Learning](https://arxiv.org/abs/2509.07702)
*Yuan-Zhuo Wang,Yi-Ran Xiao,Ming-Yang Li,Shengjun Wu,Zeng-Bing Chen*

Main category: quant-ph

TL;DR: 结合通道级联和量子记忆的协议可以指数级降低 Pauli 信道估计的测量复杂度，但需要高质量的量子记忆。


<details>
  <summary>Details</summary>
Motivation: Pauli 信道的准确表征对于构建容错量子计算机至关重要。现有协议效率虽高，但对量子记忆质量要求苛刻。

Method: 引入“弱驱动量子行走”机制，利用量子行走在有偏和无偏驱动下动力学特性的差异，降低量子记忆开销至常数阶，同时保持测量复杂度的指数优势。

Result: 所提出的弱驱动量子行走算法在保持测量复杂度指数优势的同时，将量子记忆的开销降低到常数阶。

Conclusion: “弱驱动”概念可以启发在资源受限的情况下设计新的量子算法和进行弱信号量子传感。

Abstract: Accurate characterization of quantum noise, exemplified by the Pauli channel,
is a cornerstone for building fault-tolerant quantum computers. A recent
protocol (PRX Quantum 6, 020323 (2025)) combining channel concatenation and
quantum memory has achieved an exponential reduction in measurement complexity
for Pauli channel estimation. This efficiency, however, hinges on using
logarithmic quantum memory to suppress hypothesis test errors. In this work, we
introduce a mechanism termed the ``weakly-driven quantum walk'' to mitigate the
demand for high-quality quantum memory. By exploiting the distinct dynamical
properties of quantum walks under biased versus unbiased driving, our algorithm
lowers the quantum memory overhead to a constant order while preserving the
exponential advantage in measurement complexity. By analogy with weak
measurement, our introduced concept of ``weak driving'' preserves pointer
coherence even when driven by classical probabilistic information, a principle
that may inspire new approaches to similar quantum algorithm design and quantum
sensing of weak signals in resource-constrained scenarios.

</details>


### [223] [A Tensor Network Framework for Lindbladian Spectra and Steady States](https://arxiv.org/abs/2509.07709)
*Philipp Westhoff,Mattia Moroder,Ulrich Schollwöck,Sebastian Paeckel*

Main category: quant-ph

TL;DR: 本研究提出了一种基于张量网络的框架，用于精确计算大型、驱动的开放量子多体系统的稳态和低能激发态。


<details>
  <summary>Details</summary>
Motivation: 需要系统地分析非平衡量子多体相，以探索诸如非常规非平衡相和环境辅助制备高纠缠态等现象，而传统方法在计算Lindbladians的低能本征态方面存在挑战。

Method: 提出一种基于张量网络的框架，利用复时间Krylov空间和求解非厄米特征值问题的工具箱，以计算开放量子多体系统的稳态和低能激发态。

Result: 在相互作用的Bose-Hubbard模型上，该框架能够高效精确地计算谱隙，并进行可靠的有限尺寸标度分析，揭示了异常弛豫的存在。

Conclusion: 该方法能够对通用的开放量子多体系统（包括非马尔可夫环境）进行谱分析，克服了传统方法的局限性。

Abstract: Quantum systems coupled to (non-)Markovian environments attract increasing
attention due to their peculiar physical properties. Exciting prospects such as
unconventional non-equilibrium phases beyond the Mermin-Wagner limit, or the
environment-assisted, robust preparation of highly entangled states, demand a
systematic analysis of quantum many-body phases out of equilibrium. Akin to the
equilibrium case, this requires the computation of the low-lying eigenstates of
Lindbladians, a problem challenging conventional approaches for simulating
quantum many-body systems. Here, we undertake a first step to overcome this
limitation and introduce a tensor-network-based framework to compute
systematically not only steady states, but also low-lying excited states with
unprecedented precision for large, driven quantum many-body systems. Our
framework is based on recent advances utilizing complex-time Krylov spaces, and
we leverage these ideas to create a toolbox tailored to solve the challenging
non-Hermitian eigenvalue problem ubiquitous in open quantum systems. At the
example of the interacting Bose-Hubbard model driven by dissipation-assisted
hopping, we demonstrate the high efficiency and accuracy, enabling us to
perform a reliable finite-size scaling analysis of the spectral gap and
demonstrating the existence of anomalous relaxation. This method unlocks the
capability of spectral analysis of generic open quantum many-body systems,
suitable also for non-Markovian environments.

</details>


### [224] [Measuring the non-Abelian Quantum Phase with the Algorithm of Quantum Phase Estimation](https://arxiv.org/abs/2509.07716)
*Seng Ghee Tan,Son Hsien Chen,Ying-Cheng Yang,Yen-Fu Chen,Yen-Lin Chen,Chia-Hsiu Hsieh*

Main category: quant-ph

TL;DR: This paper proposes using Quantum Phase Estimation (QPE) to measure the quantum phase of an electron in a non-Abelian system, avoiding the need for interferometric setups and leveraging standard quantum computing operations.


<details>
  <summary>Details</summary>
Motivation: To measure the quantum phase of an electron in a non-Abelian system.

Method: Utilizes the Quantum Phase Estimation (QPE) algorithm, which involves applying a sequence of quantum computing operations to map phase information into measurable qubit states. These operations are realizable with standard quantum computer gates and algorithms.

Result: The quantum phase is measured by reading off of the measurable qubit states of the QPE modules. This approach eliminates the need for an interferometric setup.

Conclusion: The proposed QPE-based approach offers a viable method for measuring quantum phases in non-Abelian systems within the standard quantum computational framework.

Abstract: We propose an approach to measure the quantum phase of an electron in a
non-Abelian system using the algorithm of Quantum Phase Estimation (QPE). The
discrete-path systems were previously studied in the context of square or
rectangular rings. Present focus is on measuring the quantum phases. The merit
of the algorithm approach is two-fold. First off, it eliminates the need for an
interferometric set up. Quantum phase is measured by reading off of measurable
qubit states of the QPE modules. Secondly, the QPE works by subjecting the
quantum state to a sequence of quantum computing operations that eventually map
the phase information into measurable qubit states. All the operations are
realizable by standard quantum computer gates and algorithms, placing the new
effort within the reach of standard quantum computational framework.

</details>


### [225] [Computation of the Smooth Max-Mutual Information via Semidefinite Programming](https://arxiv.org/abs/2509.07743)
*Christopher Popp,Tobias C. Sutter,Beatrix C. Hiesmayr*

Main category: quant-ph

TL;DR: We developed an iterative semidefinite programming (SDP) algorithm to compute the quantum smooth max-mutual information for bipartite quantum states. This method provides accurate results when a rank condition is met and an upper bound otherwise. It also extends SDP techniques in quantum information theory.


<details>
  <summary>Details</summary>
Motivation: To compute the quantum smooth max-mutual information $I^b{	ext{e}}_{	ext{max}}(ho_{AB})$ of bipartite quantum states, which has applications in quantum information processing tasks.

Method: An iterative algorithm based on semidefinite programming (SDP) is presented. A novel SDP with primal and dual formulations and strong duality is established.

Result: The algorithm provides accurate computation of $I^b{	ext{e}}_{	ext{max}}(ho_{AB})$ if a rank condition for marginal states within the smoothing environment is satisfied, and it provides an upper bound otherwise.

Conclusion: The contribution extends SDP-based techniques in quantum information theory for computing information measures, improving capabilities for various quantum information processing tasks. This is achieved by developing a novel SDP and an iterative algorithm for computing the quantum smooth max-mutual information, with direct applications to bounding the one-shot distillable key of a quantum state.

Abstract: We present an iterative algorithm based on semidefinite programming (SDP) for
computing the quantum smooth max-mutual information
$I^\varepsilon_{\max}(\rho_{AB})$ of bipartite quantum states in any dimension.
The algorithm is accurate if a rank condition for marginal states within the
smoothing environment is satisfied and provides an upper bound otherwise.
Central to our method is a novel SDP, for which we establish primal and dual
formulations and prove strong duality. With the direct application of bounding
the one-shot distillable key of a quantum state, this contribution extends
SDP-based techniques in quantum information theory. Thereby it improves the
capabilities to compute or estimate information measures with application to
various quantum information processing tasks.

</details>


### [226] [Toward Quantum Utility in Finance: A Robust Data-Driven Algorithm for Asset Clustering](https://arxiv.org/abs/2509.07766)
*Shivam Sharma,Supreeth Mysore Venkatesh,Pushkin Kachroo*

Main category: quant-ph

TL;DR: GCS-Q算法可以直接对带符号的加权图进行聚类，并在金融资产聚类方面优于经典算法，展示了近期量子计算在图学习中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 金融资产聚类在投资组合优化和统计套利中至关重要，但经典方法在处理带符号的相关性结构时存在局限性。

Method: 应用基于图的联盟结构生成算法（GCS-Q）直接对带符号的加权图进行聚类，利用量子退火解决QUBO问题，并与SPONGE和k-Medoids等经典算法进行基准测试。

Result: GCS-Q在合成和真实金融数据上均实现了更高的聚类质量（根据Adjusted Rand Index和结构平衡罚分衡量），并能动态确定聚类数量。

Conclusion: GCS-Q在图学习方面展示了近期量子计算的实际应用价值，特别是在金融领域。

Abstract: Clustering financial assets based on return correlations is a fundamental
task in portfolio optimization and statistical arbitrage. However, classical
clustering methods often fall short when dealing with signed correlation
structures, typically requiring lossy transformations and heuristic assumptions
such as a fixed number of clusters. In this work, we apply the Graph-based
Coalition Structure Generation algorithm (GCS-Q) to directly cluster signed,
weighted graphs without relying on such transformations. GCS-Q formulates each
partitioning step as a QUBO problem, enabling it to leverage quantum annealing
for efficient exploration of exponentially large solution spaces. We validate
our approach on both synthetic and real-world financial data, benchmarking
against state-of-the-art classical algorithms such as SPONGE and k-Medoids. Our
experiments demonstrate that GCS-Q consistently achieves higher clustering
quality, as measured by Adjusted Rand Index and structural balance penalties,
while dynamically determining the number of clusters. These results highlight
the practical utility of near-term quantum computing for graph-based
unsupervised learning in financial applications.

</details>


### [227] [Modeling Josephson traveling-wave parametric amplifiers with electromagnetic and circuit co-simulation](https://arxiv.org/abs/2509.07807)
*Likai Yang,Jennifer Wang,Mohamed Awida Hassan,Philip Krantz,Kevin P. O'Brien*

Main category: quant-ph

TL;DR: 本研究提出了一种基于电磁场和电路协同仿真的约瑟夫森 Traveling-Wave 参数放大器（JTWPA）的优化方法。


<details>
  <summary>Details</summary>
Motivation: 优化低温量子放大器的性能是实现高保真度和可扩展量子比特读出的关键。

Method: 该方法不依赖于JTWPA的等效集总参数电路模型，而是直接进行全电磁场分析以准确提取线性响应，并将提取的S参数输入到非线性谐波平衡模拟器中，其中约瑟夫森结表示为电路元件。

Result: 模拟的线性和增益特性与实验结果进行了比较，显示出良好的一致性。

Conclusion: 所提出的协同仿真方法能够有效地对JTWPA进行建模和优化，为实现高性能量子放大器提供了支持。

Abstract: Optimizing the performance of cryogenic quantum amplifiers is a key step
toward achieving high-fidelity and scalable qubit readout. In this work, we
present efficient and accurate modeling of a Josephson traveling-wave
parametric amplifier (JTWPA) based on electromagnetic (EM) and circuit
co-simulation. In contrast to conventional simulation methods where an
equivalent lumped-element circuit model of the JTWPA is required, we directly
perform full EM analysis of the device to faithfully determine the linear
response. The extracted S-parameters are then fed into a nonlinear harmonic
balance simulator with Josephson junctions represented as circuit elements. The
simulated linear and gain properties are compared with experimental results and
show good agreement.

</details>


### [228] [Nonlinear Co-simulation for Designing Kinetic Inductance Parametric Amplifiers](https://arxiv.org/abs/2509.07816)
*Likai Yang,Yufeng Wu,Chaofan Wang,Mingrui Xu,Hong X. Tang,Mohamed A. Hassan,Eric T. Holland*

Main category: quant-ph

TL;DR: 该研究使用电磁和电路协同仿真对基于铌氮化的KIPA进行了建模，并与实验结果进行了比较，证明了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 用于超导量子电路中的小信号检测。

Method: 首先对设备布局进行电磁分析，然后将结果集成到谐波平衡电路模拟器中，将纳米线建模为非线性电感器。

Result: 提取的器件的线性和非线性响应，包括温度相关的共振光谱和参数增益，与实验结果高度一致。此外，还精确地模拟了KIPA作为简并放大器运行时对其的相位敏感行为。

Conclusion: 所提出的技术可以作为模拟和设计量子参数放大器和超导动能电感器件的宝贵工具。

Abstract: Kinetic inductance parametric amplifiers (KIPAs) have been widely studied for
small-signal detection in superconducting quantum circuits. In this work, we
demonstrate the modeling of a niobium nitride nanowire based KIPA using
electromagnetic (EM) and circuit co-simulation, and compare the outcomes with
experimental results. EM analysis is first performed on the device layout,
taking into account the linear part of the kinetic inductance. The results are
then integrated into a harmonic balance circuit simulator, in which the
current-dependent inductance is modeled by representing the nanowire as a
nonlinear inductor. Both linear and nonlinear responses of the device,
including temperature-dependent resonance spectra and parametric gain, are
extracted and show good agreement with experiments. We further show that when
the KIPA operates as a degenerate amplifier, its phase-sensitive behavior can
be accurately reproduced by the simulation. Our technique can serve as a
valuable enabler for the simulation and design of quantum parametric amplifiers
and superconducting kinetic inductance devices.

</details>


### [229] [An analysis of Wigner's friend in the framework of quantum mechanics based on the principle of typicality](https://arxiv.org/abs/2509.07828)
*Kohtaro Tadaki*

Main category: quant-ph

TL;DR: 本篇论文提出了一种名为“典型性原理”的量化概率规则，用于在量子力学中操作性地描述测量结果的性质，并以此分析了维格纳朋友佯谬，得出了符合常识的结论，并对Deutsch提出的该佯谬变体进行了可检验的预测。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决量子力学中概率的运算化表征问题，并分析维格纳朋友佯谬。

Method: 在算法随机性的工具箱基础上，提出“典型性原理”，并在此框架下分析维格纳朋友佯谬。

Result: 得出了关于维格纳朋友佯谬的常识性结论，并对Deutsch提出的该佯谬变体进行了可检验的预测。

Conclusion: 本研究在“典型性原理”框架下对维格纳朋友佯谬进行了分析，并得出了新的见解和可检验的预测。

Abstract: The notion of probability plays a crucial role in quantum mechanics. It
appears in quantum mechanics as the Born rule. In modern mathematics which
describes quantum mechanics, however, probability theory means nothing other
than measure theory, and therefore any operational characterization of the
notion of probability is still missing in quantum mechanics. In our former
works [K. Tadaki, arXiv:1804.10174], based on the toolkit of algorithmic
randomness, we presented a refinement of the Born rule, called the principle of
typicality, for specifying the property of results of measurements in an
operational way. The Wigner's friend paradox is a Gedankenexperiment regarding
when and where the reduction of the state vector occurs in a chain of the
measurements by several observers where the state of the consciousness of each
observer is measured by the subsequent observer, except for the last observer
in the chain. It is one of the central open questions in the measurement
problem of quantum mechanics. In this paper, we make an analysis of the
Wigner's friend paradox in the framework of quantum mechanics based on the
principle of typicality. We then draw common sense conclusions about the
Wigner's friend paradox. In addition, we make a prediction, which is testable
in principle, about its variant proposed by Deutsch.

</details>


### [230] [Existence and nonexistence of commutativity gadgets for entangled CSPs](https://arxiv.org/abs/2509.07835)
*Eric Culf,Josse van Dobben de Bruyn,Matthijs Vernooij,Peter Zeman*

Main category: quant-ph

TL;DR: 研究了量子计算中的交换子句，为NP完全问题和k-着色问题（k>=4）提供了新的见解，并提出了一种判断是否存在交换子句的充分条件。


<details>
  <summary>Details</summary>
Motivation: 许多大于等于4的k-着色问题的NP完全性证明无法直接推广到纠缠问题，因为不知道是否存在交换子句。本研究旨在解决这个问题。

Method: 通过将图的量子自同构群推广到CSP的量子内同态幺半群，并证明具有非经典量子内同态幺半群的CSP不存在交换子句。此外，还提出了判断量子内同态幺半群是否为非经典的一个易于检查的充分条件。

Result: 证明了k-着色问题（k>=4）不存在交换子句。为k-着色问题的一种非局域游戏表示（预言机模型）构造了交换子句。提出了判断量子内同态幺半群是否为非经典的一个充分条件，并给出了不存在交换子句的CSP示例。证明了预言机交换子句的存在性在图的范畴幂下保持不变，并且预言机交换子句的存在性等价于无四环图的交换子句的存在性。最后，证明了奇圈和奇图具有交换量子内同态幺半群。

Conclusion: 本研究为理解NP完全问题和纠缠问题之间的关系提供了新的见解，并为未来研究纠缠CSP的可判定性奠定了基础。

Abstract: Commutativity gadgets allow NP-hardness proofs for classical constraint
satisfaction problems (CSPs) to be carried over to undecidability proofs for
the corresponding entangled CSPs. This has been done, for instance, for
NP-complete boolean CSPs and 3-colouring in the work of Culf and Mastel. For
many CSPs over larger alphabets, including $k$-colouring when $k \geq 4$, it is
not known whether or not commutativity gadgets exist, or if the entangled CSP
is decidable. In this paper, we study commutativity gadgets and prove the first
known obstruction to their existence. We do this by extending the definition of
the quantum automorphism group of a graph to the quantum endomorphism monoid of
a CSP, and showing that a CSP with non-classical quantum endomorphism monoid
does not admit a commutativity gadget. In particular, this shows that no
commutativity gadget exists for $k$-colouring when $k \geq 4$. However, we
construct a commutativity gadget for an alternate way of presenting
$k$-colouring as a nonlocal game, the oracular setting.
  Furthermore, we prove an easy to check sufficient condition for the quantum
endomorphism monoid to be non-classical, extending a result of Schmidt for the
quantum automorphism group of a graph, and use this to give examples of CSPs
that do not admit a commutativity gadget. We also show that existence of
oracular commutativity gadgets is preserved under categorical powers of graphs;
existence of commutativity gadgets and oracular commutativity gadgets is
equivalent for graphs with no four-cycle; and that the odd cycles and the odd
graphs have a commutative quantum endomorphism monoid, leaving open the
possibility that they might admit a commutativity gadget.

</details>


### [231] [Dynamic LOCC Circuits for Automated Entanglement Manipulation](https://arxiv.org/abs/2509.07841)
*Xia Liu,Jiayi Zhao,Benchi Zhao,Xin Wang*

Main category: quant-ph

TL;DR: 分布式量子计算可以通过互联量子处理器克服量子设备数量的限制，但LOCC协议的设计很困难。本文提出了DLOCCNet框架来模拟和设计LOCC协议，并在纠缠蒸馏和分布式状态判别任务中展示了其有效性，该框架可以解决更大规模的问题并减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 由于量子设备的量子比特数量有限，分布式量子计算被认为是克服这一限制的有前途的途径。在此范式中，多个量子处理器互联以形成一个内聚的计算网络，而最自然的自由操作集是局域操作和经典通信（LOCC）。然而，为特定任务设计实用的LOCC协议一直是一个难题。

Method: 提出一个名为动态LOCCNet（DLOCCNet）的通用灵活框架来模拟和设计LOCC协议。

Result: DLOCCNet的有效性在纠缠蒸馏和分布式状态判别两个关键应用中得到证明。与传统协议相比，DLOCCNet设计的协议可以解决更大规模的问题，并减少训练时间。

Conclusion: DLOCCNet框架是一个实用且可扩展的工具，适用于当前的量子设备。这项工作加深了我们对LOCC的能力和局限性的理解，并为协议设计提供了一种强大的方法。

Abstract: Due to the limited qubit number of quantum devices, distributed quantum
computing is considered a promising pathway to overcome this constraint. In
this paradigm, multiple quantum processors are interconnected to form a
cohesive computational network, and the most natural set of free operations is
local operations and classical communication (LOCC). However, designing a
practical LOCC protocol for a particular task has been a tough problem. In this
work, we propose a general and flexible framework called dynamic LOCCNet
(DLOCCNet) to simulate and design LOCC protocols. We demonstrate its
effectiveness in two key applications: entanglement distillation and
distributed state discrimination. The protocols designed by DLOCCNet, in
contrast to conventional ones, can solve larger-sized problems with reduced
training time, making the framework a practical and scalable tool for current
quantum devices. This work advances our understanding of the capabilities and
limitations of LOCC while providing a powerful methodology for protocol design.

</details>


### [232] [Improving fermionic variational quantum eigensolvers with Majorana swap networks](https://arxiv.org/abs/2509.07855)
*D. E. Fisher,S. A. Fldzhyan,D. V. Minaev,S. S. Straupe,M. Yu. Saygin*

Main category: quant-ph

TL;DR: 通过引入两种新的 Majorana 交换网络技术，减少了模拟费米子系统的量子计算电路深度和门计数，提高了在近期硬件上的可行性和抗噪声能力。


<details>
  <summary>Details</summary>
Motivation: 使用量子计算模拟费米子系统很有前景，但现有的将非局域费米子算子映射到量子比特的方法会产生过深的电路，这在近期硬件上不可行。

Method: 1. 开发了一种循环编译算法，使用 O(n^3) 个辅助 Majorana 交换门将包含 O(n^4) 个两体相互作用项的通用费米子哈密顿量本地化。 2. 为 UpCCGSD 变分ansatz设计了一种 Majorana 交换网络，在全连接下可将电路深度和门计数分别减少约 50% 和 20%，在 2xN 连接下分别减少约 55% 和 40%。

Result: 提出的 Majorana 交换网络技术在数值模拟中显示出更低的电路深度和门计数，从而提高了对硬件噪声的鲁棒性。

Conclusion: 所提出的 Majorana 交换网络技术能够有效减少模拟费米子系统的量子计算电路深度和门计数，提高近期量子硬件的模拟精度和效率。

Abstract: Simulating computationally hard fermionic systems is a promising application
of quantum computing. However, mapping nonlocal fermionic operators to qubits
often produces deep circuits, rendering such simulations impractical on
near-term hardware. We introduce two Majorana swap network techniques for
variational quantum eigensolvers that reduce circuit depth and two-qubit gate
count, thereby limiting error accumulation. First, we develop a cyclic
compilation algorithm that localizes all two-particle interaction terms in a
general fermionic Hamiltonian that contains $\mathcal{O}(n^4)$ such terms,
using only $\mathcal{O}(n^3)$ auxiliary Majorana-swap gates, where $n$ is the
number of fermionic modes. This algorithm targets all-to-all qubit connectivity
(e.g., trapped-ion processors) and can be used to compactify UCCGSD circuits.
Second, we design a Majorana swap network for the UpCCGSD variational ansatz,
which is already more compact than UCCGSD. Our network achieves asymptotic
reductions in circuit depth and gate count of approximately 50% and 20%,
respectively, under all-to-all connectivity. For the more restricted $2\times
N$ connectivity, the reductions are even larger -- about 55% (circuit depth)
and 40% (gate count). These improvements translate directly into increased
robustness to hardware noise, as demonstrated by numerical simulations on
representative examples.

</details>


### [233] [The Compressed Oracle is a Worthy (Multiplicative) Adversary](https://arxiv.org/abs/2509.07876)
*Stacey Jeffery,Sebastian Zur*

Main category: quant-ph

TL;DR: 量子密码分析中的压缩预言机技术是证明量子查询下界的最新方法，它将经典下界直觉引入量子领域，应用广泛。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在将压缩预言机技术置于已有的量子查询下界方法（多项式方法、对抗方法、乘法对抗方法）的框架中，并揭示其与这些方法的相对能力。

Method: 通过引入一个简化的乘法对抗方法（MLADV方法），证明压缩预言机技术是该方法的特例。MLADV方法足够强大，可以涵盖多项式方法并展示强大的直接积定理，同时更易于推理。

Result: 证明了压缩预言机技术是乘法对抗方法的一个特例。MLADV方法能够捕捉压缩预言机技术。

Conclusion: MLADV方法有望成为未来将压缩预言机技术扩展到非乘积分布的研究方向。

Abstract: The compressed oracle technique, introduced in the context of quantum
cryptanalysis, is the latest method for proving quantum query lower bounds, and
has had an impressive number of applications since its introduction, due in
part to the ease of importing classical lower bound intuition into the quantum
setting via this method. Previously, the main quantum query lower bound methods
were the polynomial method, the adversary method, and the multiplicative
adversary method, and their relative powers were well understood. In this work,
we situate the compressed oracle technique within this established landscape,
by showing that it is a special case of the multiplicative adversary method. To
accomplish this, we introduce a simplified restriction of the multiplicative
adversary method, the MLADV method, that remains powerful enough to capture the
polynomial method and exhibit a strong direct product theorem, but is much
simpler to reason about. We show that the compressed oracle technique is also
captured by the MLADV method. This might make the MLADV method a promising
direction in the current quest to extend the compressed oracle technique to
non-product distributions.

</details>


### [234] [Effective approach to open systems with probability currents and the Grothendieck formalism](https://arxiv.org/abs/2509.07882)
*A. Vourdas*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: An effective approach to open systems and irreversible phenomena is
presented, where an open system $\Sigma(d)$ with $d$-dimensional Hilbert space,
is a subsystem of a larger isolated system $\Sigma(2d)$ (the `full universe')
with $2d$-dimensional Hilbert space. A family of Bargmann-like representations
(called $z$-Bargmann representations) introduces naturally the larger space.
The $z$-Bargmann representations are defined through semi-unitary matrices
(which are a coherent states formalism in disguise). The `openness' of the
system is quantified with the probability current that flows from the system to
the external world. The Grothendieck quantity ${\cal Q}$ is shown to be related
to the probability current, and is used as a figure of merit for the `openness'
of a system. ${\cal Q}$ is expressed in terms of `rescaling transformations'
which change not only the phase but also the absolute value of the
wavefunction, and are intimately linked to irreversible phenomena (e.g.,
damping/amplification). It is shown that unitary transformations in the
isolated system $\Sigma(2d)$ (full universe), reduce to rescaling
transformations when projected to its open subsystem $\Sigma(d)$. The values of
the Grothendieck ${\cal Q}$ for various quantum states in an open system, are
compared with those for their counterpart states in an isolated system.

</details>


### [235] [Quantum Walks for Chemical Reaction Networks](https://arxiv.org/abs/2509.07890)
*Seenivasan Hariharan,Sebastian Zur,Sachin Kinge,Lucas Visscher,Kareljan Schoutens,Stacey Jeffery*

Main category: quant-ph

TL;DR: 我们提出了一个基于量子随机游走的化学反应网络分析框架。


<details>
  <summary>Details</summary>
Motivation: 研究如何使用量子算法分析固定结构的化学反应网络，特别是研究其受扰动后的行为。

Method: 利用量子随机游走和电路理论来模拟化学反应网络，并提出量子算法来解决可达性、采样、通量近似和能量估计算法。

Result: 开发了能够判定目标物种可达性、采样可达物种、近似稳态通量以及估算吉布斯自由能消耗的量子算法。

Conclusion: 该方法为分析复杂化学反应网络的结构和能量学提供了新工具，并为开发可扩展的化学和生物化学反应网络量子算法开辟了前景。

Abstract: We lay the foundation for a quantum algorithmic framework to analyse
fixed-structure chemical reaction networks (CRNs) using quantum random walks
(QRWs) via electrical circuit theory. We model perturbations to CRNs, such as,
species injections that shift steady-state concentrations, while keeping the
underlying species-reaction graph fixed. Under physically meaningful
mass-action constraints, we develop quantum algorithms that (i) decide
reachability of target species after perturbation, (ii) sample representative
reachable species, (iii) approximate steady-state fluxes through reactions, and
(iv) estimate total Gibbs free-energy consumption. Our approach offers new
tools for analysing the structure and energetics of complex CRNs, and opens up
the prospect of scalable quantum algorithms for chemical and biochemical
reaction networks.

</details>


### [236] [Quartz phononic crystal resonators for hybrid acoustic quantum memories](https://arxiv.org/abs/2509.07900)
*Yang Hu,Angad Gupta,Jacob Repicky,Michael Hatridge,Thomas P. Purdy*

Main category: quant-ph

TL;DR: 电路量子声动力学系统通过将超导量子比特耦合到机械谐振器来提供有前途的量子信息平台，其中长寿命的机械模式可作为量子存储器。我们演示了在 8 K 下具有毫秒寿命的 100 MHz 的悬浮石英声子晶体谐振器。通过抑制两能级系统损耗和其他电极引起的能量耗散的非接触电极几何结构，我们评估了机械模式与通量结量子比特（共振耦合）和 Transmon 量子比特（通过基于约瑟夫森结的三波混频器进行参数耦合）之间的压电耦合率。我们还讨论了用于增强这些耦合率的多周期缺陷几何结构。


<details>
  <summary>Details</summary>
Motivation: 电路量子声动力学系统利用超导量子比特和机械谐振器的耦合来实现量子信息处理，其中机械模式可用作量子存储器。

Method: 演示了在 8 K 下具有毫秒寿命的 100 MHz 的悬浮石英声子晶体谐振器。使用非接触电极几何结构来抑制损耗，并评估了机械模式与通量结量子比特（共振耦合）和 Transmon 量子比特（参数耦合）之间的压电耦合率。

Result: 在 8 K 下实现了具有毫秒寿命的 100 MHz 悬浮石英声子晶体谐振器。评估了机械模式与通量结量子比特和 Transmon 量子比特之间的压电耦合率。

Conclusion: 电路量子声动力学系统是量子信息的一个有前途的平台，并且可以通过优化谐振器设计和耦合方案来进一步增强其性能。

Abstract: Circuit quantum acoustodynamics systems have emerged as a promising platform
for quantum information by coupling superconducting qubits to mechanical
resonators, with their long-lived mechanical modes serving as quantum memories.
We demonstrate suspended quartz phononic crystal resonators at 100 MHz with
millisecond lifetimes at 8 K. With a contactless electrode geometry suppressing
both two-level system losses and other electrode-induced energy dissipation, we
evaluate the piezoelectric coupling rate between the mechanical modes and
fluxonium qubits (resonant coupling) and transmon qubits (parametric coupling
mediated by a Josephon-junction-based three-wave mixer). We further discuss
multi-period defect geometries for enhancing these coupling rates.

</details>


### [237] [Reply to "Comment(s) to "Consequences of the single-pair measurement of the Bell parameter""](https://arxiv.org/abs/2509.07922)
*Marco Genovese,Fabrizio Piacentini*

Main category: quant-ph

TL;DR: 该论文是对 Kupczynski 和 Lambare 对其关于单对测量贝尔参数的近期论文的评论的回复。


<details>
  <summary>Details</summary>
Motivation: 回应关于量子力学解释和替代理论的含义的质疑。

Method: 通过回复 M. Kupczynski 和 J. P. Lambare 的评论来阐述。

Result: 证明了在单对纠缠粒子上测量整个贝尔参数的可能性，并对其对量子力学解释的影响进行了讨论。

Conclusion: 重申了单对测量贝尔参数实验结果对量子力学解释的潜在影响。

Abstract: We reply to the comments made by M. Kupczynski and J. P. Lambare on our
recent paper titled ''Consequences of the single-pair measurement of the Bell
parameter'' [Phys. Rev. A 111, 022204 (2025)], questioning our claims on the
implications on Quantum Mechanics interpretations (and alternative theories)
generated by the results of a recent experiment [Quantum Sci. Technol. 9,
045027 (2024)] demonstrating the possibility of measuring the entire Bell
parameter on a single entangled pair.

</details>


### [238] [A Non-Monotonic Relationship: An Empirical Analysis of Hybrid Quantum Classifiers for Unseen Ransomware Detection](https://arxiv.org/abs/2509.07924)
*Huu Phu Le,Phuc Hao Do,Vo Hoang Long Nguyen,Nang Hung Van Nguyen*

Main category: quant-ph

TL;DR: QML在检测未知勒索软件方面存在数据维度、信息瓶颈和可训练性问题，需要改进数据压缩和量子优化。


<details>
  <summary>Details</summary>
Motivation: 检测未知的勒索软件是一个关键的网络安全挑战，传统的机器学习方法常常失效，而量子机器学习（QML）可能提供一种替代方案，但受到经典数据和量子硬件之间维度差距的限制。

Method: 提出了一种混合框架，利用主成分分析（PCA）将高维数据集与变分量子分类器（VQC）进行接口。

Result: 即使是性能最佳的12量子比特VQC，其召回率也未能达到经典基线的97.7%，这表明存在严重的信息瓶颈。此外，从4量子比特扩展到8量子比特时性能下降，然后在12量子比特时才有所提高，这表明存在可训练性问题。

Conclusion: 为了充分发挥QML的潜力，需要协同开发更有效的数据压缩技术和更强大的量子优化策略。

Abstract: Detecting unseen ransomware is a critical cybersecurity challenge where
classical machine learning often fails. While Quantum Machine Learning (QML)
presents a potential alternative, its application is hindered by the
dimensionality gap between classical data and quantum hardware. This paper
empirically investigates a hybrid framework using a Variational Quantum
Classifier (VQC) interfaced with a high-dimensional dataset via Principal
Component Analysis (PCA). Our analysis reveals a dual challenge for practical
QML. A significant information bottleneck was evident, as even the best
performing 12-qubit VQC fell short of the classical baselines 97.7\% recall.
Furthermore, a non-monotonic performance trend, where performance degraded when
scaling from 4 to 8 qubits before improving at 12 qubits suggests a severe
trainability issue. These findings highlight that unlocking QMLs potential
requires co-developing more efficient data compression techniques and robust
quantum optimization strategies.

</details>


### [239] [Cross-Resonant Gates in Hybrid Fluxonium-Transmon Systems](https://arxiv.org/abs/2509.07935)
*Nikola D. Dimitrov,Chen Wang,Vladimir E. Manucharyan,Maxim G. Vavilov*

Main category: quant-ph

TL;DR: 该研究提出了一种新型的“通量-隧结-通量” (FTF) 量子比特系统，使用中间的隧结量子比特来控制两个通量量子比特，实现了高保真度的门操作和奇偶校验，同时抑制了长程相互作用，为构建大规模容错量子计算机提供了新的途径。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有量子处理器中非局域相互作用带来的挑战，以及实现更大规模的量子计算，需要一种能够抑制不需要的长程相互作用的量子比特系统。

Method: 研究人员提出并分析了一种包含中心隧结和两个通量量子比特的FTF系统。他们首先分析了通量量子比特和隧结量子比特之间的交叉共振（CR）CNOT门保真度，即使存在旁观者量子比特，保真度也能达到10^-5。随后，他们证明了通过顺序应用这些门，可以实现高保真度的奇偶校验和通量-通量CNOT门。此外，中心隧结还可以用于读取相邻通量量子比特的状态，将多个关键功能整合到一个辅助量子比特中。

Result: FTF系统能够实现高保真度的CR CNOT门（相干误差在10^-5量级），即使存在旁观者量子比特。顺序应用这些门可以实现高保真度的奇偶校验和逻辑通量-通量CNOT门。中心隧结还可以同时执行读取功能。

Conclusion: FTF系统是一种可行的双种类量子比特架构，有望实现高保真度门操作、奇偶校验和读取功能，并且能够抑制长程相互作用，为构建容错量子计算机提供了有前景的解决方案。

Abstract: We propose a scalable fluxonium-transmon-fluxonium (FTF) system that utilizes
a central transmon to mediate high-fidelity gates and parity checks between two
fluxonium qubits without the need for strong non-local interactions. This
approach suppresses unwanted long-range interactions, which is critical for
developing larger quantum processors. First, we analyze the performance of
cross-resonance (CR) CNOT gates between a fluxonium and a transmon. We show
that even in the presence of a spectator qubit, these gates maintain high
fidelity with coherent errors on the order of $10^{-5}$. We then demonstrate
that these gates, when applied sequentially, enable high-fidelity parity checks
and logical fluxonium-fluxonium CNOT gates. In addition, the central transmon
can facilitate the readout of the neighboring fluxoniums, consolidating
multiple critical functions into a single ancilla. Our work establishes the
viability of a dual-species architecture as a promising path toward
fault-tolerant quantum computation.

</details>


### [240] [Improved Hamiltonian learning and sparsity testing through Bell sampling](https://arxiv.org/abs/2509.07937)
*Savar D. Sinha,Yu Tong*

Main category: quant-ph

TL;DR: 该研究提出了一种改进的M稀疏哈密顿量学习算法，将所需演化时间缩短了M倍，并提出了相应的哈密顿量稀疏性测试方法。


<details>
  <summary>Details</summary>
Motivation: 学习M稀疏哈密顿量和进行哈密顿量稀疏性测试。

Method: 通过对贝尔采样进行详细分析，将M稀疏哈密顿量学习的最优算法所需总演化时间减少到~O(M/ε)，并且只需要访问前向时间演化。然后，通过贝尔采样建立了哈密顿量学习与哈密顿量稀疏性测试之间的联系，从而提出了一种具有最优总演化时间缩放的哈密顿量稀疏性测试方法。

Result: 将M稀疏哈密顿量学习的最优算法所需总演化时间减少到~O(M/ε)，实现了M倍的改进（忽略对数因子）。

Conclusion: 成功将M稀疏哈密顿量学习的演化时间缩短了M倍，并提出了一种高效的哈密顿量稀疏性测试方法。

Abstract: We consider the problem of learning an $M$-sparse Hamiltonian and the related
problem of Hamiltonian sparsity testing. Through a detailed analysis of Bell
sampling, we reduce the total evolution time required by the state-of-the-art
algorithm for $M$-sparse Hamiltonian learning to
$\widetilde{\mathcal{O}}(M/\epsilon)$, where $\epsilon$ denotes the
$\ell^{\infty}$ error, achieving an improvement by a factor of $M$ (ignoring
the logarithmic factor) while only requiring access to forward time-evolution.
We then establish a connection between Hamiltonian learning and Hamiltonian
sparsity testing through Bell sampling, which enables us to propose a
Hamiltonian sparsity testing with state-of-the-art total evolution time
scaling.

</details>


### [241] [Iterative model of self-referential quantum evolution](https://arxiv.org/abs/2509.07940)
*Andrei Galiautdinov*

Main category: quant-ph

TL;DR: 该论文提出了一个量子物理设备的玩具模型，该设备能够通过迭代的、依赖分支的幺正演化进行内部的、自指的审议，并由控制、记忆和策略寄存器进行跟踪。


<details>
  <summary>Details</summary>
Motivation: 介绍并分析了一个能够进行内部、自指审议的量子物理设备的玩具模型。

Method: 通过迭代的、依赖分支的幺正演化进行审议，并由控制、记忆和策略寄存器跟踪。通过明确的量子电路实现、纠缠的记忆-策略动力学的详细分步推导，以及对量子不可克隆定理对相干信息流的限制的分析来构建模型。

Result: 提供了模型显式量子电路的实现，并进行了详细的数学推导，分析了量子不可克隆定理的限制。

Conclusion: 该模型为探索量子设备如何并行维护多种选择提供了合理的框架，并通过相干分支、纠缠和自修改幺正动力学为研究内部相干决策过程提供了形式框架。

Abstract: We introduce and analyze a toy model of a quantum physical device capable of
internal, self-referential deliberation, realized through iterative,
branch-dependent unitary evolution tracked by control, memory, and policy
registers. The key idea is to represent ``deliberation'' as a coherent
branching process, in which alternative candidate evolutions are maintained in
superposition across registers, rather than by placing the system itself under
a literal superposition of Hamiltonians. We provide explicit quantum circuit
realizations, carry through detailed step-by-step derivations of the entangled
memory--policy dynamics, and analyze the constraints imposed by the no-cloning
theorem on coherent information flow. We also briefly discuss categorical
reformulations and their conceptual implications. Taken together, this frames
the model as a plausible setting for exploring how such devices may maintain
multiple alternatives in parallel, providing a formal framework for
investigating internally coherent decision processes through coherent
branching, entanglement, and self-modifying unitary dynamics.

</details>


### [242] [Circuit Knitting for Continuous-Variable Quantum States](https://arxiv.org/abs/2509.07947)
*Shao-Hua Hu,Ray-Kuang Lee*

Main category: quant-ph

TL;DR: To simulate non-Gaussian states and operations in infinite-dimensional quantum systems using circuit knitting, overcoming limitations of finite-dimensional approaches.


<details>
  <summary>Details</summary>
Motivation: Extend circuit knitting to infinite-dimensional quantum systems for simulating non-Gaussian states and operations.

Method: Developed a theoretical framework for simulating non-Gaussian states from available states and established constraints on knitting multi-mode Gaussian operations using a no-go theorem, showing infinite sampling overhead for exact knitting with separable operations. Explored applications like approximate Fock states, GKP state generation, and cat-state amplification.

Result: Established a general theoretical framework and a no-go theorem for circuit knitting in infinite-dimensional systems. Demonstrated applications in simulating approximate Fock states, GKP state generation, and cat-state amplification.

Conclusion: Circuit knitting can be extended to infinite-dimensional quantum systems, providing a framework for simulating non-Gaussian states. However, exact knitting of multi-mode Gaussian operations faces fundamental constraints due to infinite sampling overhead, but approximate simulations are feasible and applicable to various tasks.

Abstract: In finite-dimensional systems, circuit knitting can be used to simulate
non-classical quantum operations using a limited set of resources. In this
work, we extend circuit knitting techniques to infinite-dimensional quantum
systems. We develop a general theoretical framework for simulating non-Gaussian
states from the given set of available states. Also, we establish fundamental
constraints with the no-go theorem on the circuit knitting of multi-mode
Gaussian operations, by showing that the exact knitting with separable
operations requires infinite sampling overhead. We further explore several
applications of our theory, including simulation of approximate Fock states,
GKP state generation, and cat-state amplification.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [243] [PSketch: A Priority-Aware Sketch Architecture for Real-Time Flow Monitoring via eBPF](https://arxiv.org/abs/2509.07338)
*Yuanjun Dai,Qingzhe Guo,Xiangren Wang*

Main category: cs.ET

TL;DR: PSKetch是一个基于eBPF的、内核态的、支持优先级感知的草图框架，用于SDN中的草图监控。它通过基于哈希的表无损跟踪高优先级流，并使用草图管道近似top-k流量。PSKetch支持TCP和UDP，并支持内核态的重传跟踪，且开销极小。它可以在普通的Linux系统上运行，无需硬件依赖。在CAIDA数据集上的评估显示，PSKetch在top-k检测准确率、重传召回率和吞吐量下降方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于SDN中草图监控存在管道耦合紧密和内存限制问题，导致算法灵活性受限且准确性下降。

Method: 提出PSKetch，一个在内核中实现的、基于eBPP的、支持优先级感知的草图框架。它通过基于哈希的表实现高优先级流的无损跟踪，并通过草图管道近似top-k流量。PSKetch支持TCP和UDP，并能以最小的开销实现内核态的重传跟踪。与SDN方法不同，它可以在标准的Linux系统上运行，无需硬件依赖。

Result: 在10 Gbps CAIDA数据集上的评估结果表明，PSKetch实现了96.0%的top-k检测准确率，96.4%的重传召回率，并且只带来了0.7%的吞吐量下降。

Conclusion: PSKetch通过其新颖的架构和eBPF实现，解决了SDN中草图监控的挑战，在保持高准确率的同时，降低了系统开销并消除了硬件依赖。

Abstract: Sketch-based monitoring in SDN often suffers from tightly coupled pipeline
and memory constraints, limiting algorithmic flexibility and reducing accuracy.
We propose PSketch, the first in-kernel priority-aware sketching framework
implemented with eBPF. It ensures lossless tracking of high-priority flows via
a hash-based table and approximates top-k elephant flows using a sketch pipe.
PSketch supports both TCP and UDP and enables in-kernel retransmission tracking
with minimal overhead. Unlike SDN-based approaches, it runs on commodity Linux
systems, removing hardware dependencies. We perform evaluation on 10 Gbps CAIDA
traces. Results show that PSketch achieves 96.0% top-k detection accuracy,
96.4% retransmission recall, and only 0.7% throughput degradation.

</details>


### [244] [Gut-Brain Axis as a Closed-Loop Molecular Communication Network](https://arxiv.org/abs/2509.07911)
*Beyza E. Ortlek,Ozgur B. Akan*

Main category: cs.ET

TL;DR: 该研究提出了一个用于肠-脑轴（GBA）的分子通讯（MC）框架，使用耦合的非线性延迟微分方程（DDEs）来模拟信息在肠道和大脑之间的双向传递。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是提供一个量化框架来分析生物系统内的信息传输，特别是针对肠-脑轴（GBA），并阐明在长期压力下，该轴如何从健康的昼夜节律转变为病理性的高皮质醇血症状态。

Method: 本研究采用了一个包含六个耦合的非线性延迟微分方程（DDEs）的MC框架来模拟GBA。该模型定义了一个双向反馈回路，包括一个从肠道到大脑的炎症通道和一个从大脑到肠道的神经内分泌通道。研究通过时域模拟、小信号频域表征和信息论容量分析来评估不同条件下的端到端信道。

Result: 研究发现在稳态下，系统具有稳定的昼夜节律动力学和更高的信息吞吐量。然而，在持续压力下，系统会转变为高皮质醇血症的病理状态。在这种状态下，由于神经内分泌延迟和细胞因子-激素动力学的饱和效应，有效带宽变窄，通带增益降低，导致频谱效率下降。

Conclusion: 该研究结果量化了肠-脑轴中的信号机制对系统稳定性和信息处理的影响，并阐明了从健康的昼夜节律向持续的高皮质醇血症病理状态的转变过程。MC框架为理解GBA的动力学和压力对信息处理的影响提供了新的见解。

Abstract: Molecular communication (MC) provides a quantitative framework for analyzing
information transfer within biological systems. This paper introduces a novel
and comprehensive MC framework for the gut-brain axis (GBA) as a system of six
coupled, nonlinear delay differential equations (DDEs). The proposed model
defines a bidirectional feedback loop with a gut-to-brain inflammatory channel
and a brain-to-gut neuroendocrine channel. Under prolonged stress, this
feedback loop becomes self-perpetuating and drives the system into a
pathological state. We evaluate the end-to-end channel across varying
conditions using time-domain simulations, small-signal frequency-domain
characterization, and an information-theoretic capacity analysis. At
homeostasis, the system maintains stable circadian dynamics with higher
information throughput, whereas sustained stress drives a shift to dysregulated
hypercortisolism. In this pathological state, spectral efficiency decreases due
to a narrowed effective bandwidth and a lower passband gain driven by
neuroendocrine delays and saturating cytokine-hormone kinetics. These results
quantify the impact of these signaling mechanisms on stability and information
processing, elucidating the transition from healthy circadian rhythms to a
persistent pathological state of hypercortisolism.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [245] [Persuading Agents in Opinion Formation Games](https://arxiv.org/abs/2509.07520)
*Martin Hoefer,Tim Koglin,Tolga Tel*

Main category: cs.GT

TL;DR: 本研究将贝叶斯说服方法应用于 Friedkin-Johnsen (FJ) 模型，分析了在信息披露和说服努力对公众舆论形成的影响。


<details>
  <summary>Details</summary>
Motivation: 在现有的意见形成模型（如 FJ 模型）主要关注同伴压力对公众舆论的影响时，本研究考虑了信息和说服努力在意见形成中的作用。

Method: 研究人员提出了一种将贝叶斯说服方法整合到 FJ 模型中的方法。在此模型中，存在一个未知的世界状态，该状态会影响 n 个代理人的先验信念。发送者 S 可以向所有代理人（部分）披露关于世界状态的信息，代理人会更新他们的先验信念，并最终形成公众舆论的均衡。研究人员提出了用于发送者披露信息以优化均衡的各种方面的算法，特别是关注基于范围的目标。

Result: 研究表明，对于许多常见的发送者目标，存在简单的最优策略。对于一类通用的基于范围的目标，研究人员提供了有效的算法，尤其是在先验信念矩阵在所有状态下具有恒定秩，或者只有多项式数量的范围组合能为发送者带来正价值的情况下。研究还表明，次可加范围目标允许进行简单的 n-近似，而即使是可加目标，获得 $n^{1-c}$-近似（对于任何常数 $c > 0$）也是 NP-hard 的。

Conclusion: 本研究成功地将贝叶斯说服方法扩展到 FJ 意见形成模型，并针对不同的发送者目标提出了有效的算法。研究结果揭示了在信息披露策略和意见形成均衡之间的复杂关系，并为在实际应用中优化这一过程提供了理论基础。

Abstract: Prominent opinion formation models such as the one by Friedkin and Johnsen
(FJ) concentrate on the effects of peer pressure on public opinions. In
practice, opinion formation is also based on information about the state of the
world and persuasion efforts. In this paper, we analyze an approach of Bayesian
persuasion in the FJ model. There is an unknown state of the world that
influences the preconceptions of n agents. A sender S can (partially) reveal
information about the state to all agents. The agents update their
preconceptions, and an equilibrium of public opinions emerges. We propose
algorithms for the sender to reveal information in order to optimize various
aspects of the emerging equilibrium. For many natural sender objectives, we
show that there are simple optimal strategies. We then focus on a general class
of range-based objectives with desired opinion ranges for each agent. We
provide efficient algorithms in several cases, e.g., when the matrix of
preconceptions in all states has constant rank, or when there is only a
polynomial number of range combinations that lead to positive value for S. This
generalizes, e.g., instances with a constant number of states and/or agents, or
instances with a logarithmic number of ranges. In general, we show that
subadditive range-based objectives allow a simple n-approximation, and even for
additive ones, obtaining an $n^{1-c}$-approximation is NP-hard, for any
constant $c > 0$.

</details>


### [246] [City Sampling for Citizens' Assemblies](https://arxiv.org/abs/2509.07557)
*Paul Gölz,Jan Maly,Ulrike Schmidt-Kraepelin,Markus Utke,Philipp C. Verpoort*

Main category: cs.GT

TL;DR: 该研究提出并评估了几种用于公民大会的抽样算法，旨在解决在市政层面存储联系信息时，在确保个体选择概率相等的前提下，最大限度地减少所接触城市数量的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决公民大会在实践中遇到的两阶段抽样问题，特别是在联系信息存储在市政层面时，如何在确保个体选择概率均等的前提下，最大限度地减少所接触城市的数量。

Method: 开发了几种算法，包括基于线性规划的伪多项式时间算法和加性1近似算法，一个贪婪算法（加性2近似），以及一个基于列生成和整数线性规划的最优算法和一个启发式算法，用于实现析后公平性。

Result: 通过对德国数据的评估，展示了不同算法在最小化城市数量、满足单调性以及实现公平性方面的效果。

Conclusion: 提出了一系列有效的算法来解决公民大会抽样中的复杂问题，并计划在实践中应用这些算法。

Abstract: In citizens' assemblies, a group of constituents is randomly selected to
weigh in on policy issues. We study a two-stage sampling problem faced by
practitioners in countries such as Germany, in which constituents' contact
information is stored at a municipal level. As a result, practitioners can only
select constituents from a bounded number of cities ex post, while ensuring
equal selection probability for constituents ex ante.
  We develop several algorithms for this problem. Although minimizing the
number of contacted cities is NP-hard, we provide a pseudo-polynomial time
algorithm and an additive 1-approximation, both based on separation oracles for
a linear programming formulation. Recognizing that practical objectives go
beyond minimizing city count, we further introduce a simple and more
interpretable greedy algorithm, which additionally satisfies an ex-post
monotonicity property and achieves an additive 2-approximation. Finally, we
explore a notion of ex-post proportionality, for which we propose two practical
algorithms: an optimal algorithm based on column generation and integer linear
programming and a simple heuristic creating particularly transparent
distributions. We evaluate these algorithms on data from Germany, and plan to
deploy them in cooperation with a leading nonprofit organization in this space.

</details>


### [247] [Inference of Intrinsic Rewards and Fairness in Multi-Agent Systems](https://arxiv.org/abs/2509.07650)
*Victor Villin,Christos Dimitrakakis*

Main category: cs.GT

TL;DR: 本研究将公平性挑战视为多智能体逆强化学习问题，通过构建反映个体对他方福祉重视程度的奖励结构，并引入新的贝叶斯策略来推断公平性。


<details>
  <summary>Details</summary>
Motivation: 探讨在缺乏明确偏好信息的情况下，如何理解个体的公平行为，并将其构建为多智能体逆强化学习问题。

Method: 提出新的贝叶斯策略，对演示的最优性进行推理，并表征一般和Markov对策中的均衡。

Result: 实验表明，可以从演示中可靠地推断出连贯的公平概念，并获得对个体偏好（尤其是公平性成分）的解纠缠理解。此外，通过将个体置于不同群体中，可以揭示其奖励结构的新的方面，从而消除歧义。

Conclusion: 通过将公平性建模为多智能体逆强化学习问题，并结合新的贝叶斯策略，可以从行为演示中推断出个体的公平性，即使在存在模糊性的情况下也能揭示其奖励结构。

Abstract: From altruism to antagonism, fairness plays a central role in social
interactions. But can we truly understand how fair someone is, especially
without explicit knowledge of their preferences? We cast this challenge as a
multi-agent inverse reinforcement learning problem, explicitly structuring
rewards to reflect how agents value the welfare of others. We introduce novel
Bayesian strategies, reasoning about the optimality of demonstrations and
characterisation of equilibria in general-sum Markov games. Our experiments,
spanning randomised environments and a collaborative cooking task, reveal that
coherent notions of fairness can be reliably inferred from demonstrations.
Furthermore, when isolating fairness components, we obtain a disentangled
understanding of agents preferences. Crucially, we unveil that by placing
agents in different groups, we can force them to exhibit new facets of their
reward structures, cutting through ambiguity to answer the central question:
who is being fair?

</details>


### [248] [Smart Fast Finish: Preventing Overdelivery via Daily Budget Pacing at DoorDash](https://arxiv.org/abs/2509.07929)
*Rohan Garg,Yongjin Xiao,Jason,Yang,Mandar Rahurkar*

Main category: cs.GT

TL;DR: SFF是一种新的预算竞价功能，通过动态更新参数来优化广告预算的消耗，并在DoorDash上成功应用。


<details>
  <summary>Details</summary>
Motivation: 介绍SFF（Smart Fast Finish）功能，该功能基于行业标准的FF（Fast Finish）功能，旨在优化广告预算在固定时间段内的消耗。SFF通过利用历史广告活动数据动态调整系统参数（如开始时间和节流速率）来改进预算竞价策略。

Method: SFF通过动态更新系统参数（如开始时间和节流速率），利用历史广告活动数据来优化预算竞价过程。

Result: SFF在DoorDash（美国最大的配送平台之一）的预算竞价系统中得到实际应用。通过在线预算拆分实验数据和离线模拟，证明了SFF在竞价预算时是一种有效的过量交付缓解方案。

Conclusion: SFF是一种稳健的预算竞价解决方案，能够有效缓解预算过量交付的问题，并在实际应用中表现出色。

Abstract: We present a budget pacing feature called Smart Fast Finish (SFF). SFF builds
upon the industry standard Fast Finish (FF) feature in budget pacing systems
that depletes remaining advertising budget as quickly as possible towards the
end of some fixed time period. SFF dynamically updates system parameters such
as start time and throttle rate depending on historical ad-campaign data. SFF
is currently in use at DoorDash, one of the largest delivery platforms in the
US, and is part of its budget pacing system. We show via online budget-split
experimentation data and offline simulations that SFF is a robust solution for
overdelivery mitigation when pacing budget.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [249] [Cross-device Zero-shot Label Transfer via Alignment of Time Series Foundation Model Embeddings](https://arxiv.org/abs/2509.06966)
*Neal G. Ravindra,Arijit Sehanobish*

Main category: eess.SP

TL;DR: 手动标注可穿戴设备数据成本高昂且难以扩展，本研究提出了一种新颖的框架，可在无需配对数据的情况下，将临床可穿戴设备（如Apple Watch）的高质量标签迁移到目标设备。


<details>
  <summary>Details</summary>
Motivation: 现有的高质量临床可穿戴设备标签无法直接用于Apple Watch等消费级可穿戴设备，手动标注成本高昂且难以扩展。

Method: 利用时间序列基础模型（TSFM）将源域（临床可穿戴设备）和目标域（Apple Watch）投影到共享的潜在嵌入空间，并提出一种名为“对抗性迁移TSFM嵌入”的新框架，以对齐跨设备表示，强制源域和目标域嵌入的分布在该空间内对齐，从而实现跨设备标签迁移。

Result: 成功地将源域（临床可穿戴设备）的标签迁移到了目标域（Apple Watch），实现了跨设备表示的对齐。

Conclusion: 该研究提出的框架能够有效地将临床可穿戴设备的高质量标签迁移到消费级可穿戴设备，解决了手动标注成本高和可扩展性差的问题。

Abstract: High-quality, medically validated labels exist for clinical actigraphy data
but not for ubiquitous consumer wearables like the Apple Watch. Manually
labeling wearables data is expensive and doesn't scale. This paper offers a
novel framework that transfers valuable labels from a source domain (e.g.,
actigraphy) to a target domain (e.g., Apple Watch) without requiring paired
data. Instead of working with raw time-series signals, we project both domains
into a shared latent embedding space using time-series foundation models
(TSFMs) and develop a new framework to align the cross-device representations.
Our method, Adversarial Alignment of TSFM Embeddings forces the distributions
of source and target embeddings to align within this space, facilitating label
transfer across device type.

</details>


### [250] [Cross-field SNR Analysis and Tensor Channel Estimation for Multi-UAV Near-field Communications](https://arxiv.org/abs/2509.06967)
*Tianyu Huo,Jian Xiong,Yiyan Wu,Songjie Yang,Bo Liu,Wenjun Zhang*

Main category: eess.SP

TL;DR: 本文研究了6G网络中分布式无人机（UAV）系统的分布式极大规模天线阵列（ELAA）信道估计问题，特别关注近场区域的空间稀疏性，并提出了一种混合球-平面波模型（HSPWM）和两种信道估计算法（SD-OMP和Tensor-OMP）。


<details>
  <summary>Details</summary>
Motivation: 6G网络中的ELAA是提高频谱效率的关键，而分布式多UAV系统能够形成ELAA，但它们在近场区域操作且具有空间稀疏性，传统的远场平面波假设不再适用，因此需要研究适用于该场景的信道估计方法。

Method: 首先，在分布式均匀平面阵列（UPA）场景下，推导了平面波模型（PWM）、球波模型（SWM）和混合球-平面波模型（HSPWM）下的信噪比（SNR）表达式。然后，基于HSPWM，提出了一种球域正交匹配追踪（SD-OMP）算法，该算法将极域推广到联合考虑仰角、方位角和距离。此外，利用HSPWM下信道的张量表示，提出了一种张量-OMP算法。

Result: 仿真结果表明，Tensor-OMP算法在归一化均方误差（NMSE）方面达到了与SD-OMP相当的性能，同时具有较低的计算复杂度和更好的可扩展性。

Conclusion: HSPWM在建模精度和分析可处理性之间取得了良好的平衡，提出的Tensor-OMP算法为分布式近场多UAV通信系统提供了一种高效且可扩展的信道估计算法。

Abstract: Extremely large antenna array (ELAA) is key to enhancing spectral efficiency
in 6G networks. Leveraging the distributed nature of multi-unmanned aerial
vehicle (UAV) systems enables the formation of distributed ELAA, which often
operate in the near-field region with spatial sparsity, rendering the
conventional far-field plane wave assumption invalid. This paper investigates
channel estimation for distributed near-field multi-UAV communication systems.
We first derive closed-form signal-to-noise ratio (SNR) expressions under the
plane wave model (PWM), spherical wave model (SWM), and a hybrid
spherical-plane wave model (HSPWM), also referred to as the cross-field model,
within a distributed uniform planar array (UPA) scenario. The analysis shows
that HSPWM achieves a good balance between modeling accuracy and analytical
tractability. Based on this, we propose two channel estimation algorithms: the
spherical-domain orthogonal matching pursuit (SD-OMP) and the tensor-OMP. The
SD-OMP generalizes the polar domain to jointly consider elevation, azimuth, and
range. Under the HSPWM, the channel is naturally formulated as a tensor,
enabling the use of tensor-OMP. Simulation results demonstrate that tensor-OMP
achieves normalized mean square error (NMSE) performance comparable to SD-OMP,
while offering reduced computational complexity and improved scalability.

</details>


### [251] [Asymmetric Modulation Design for Fluid-Antenna SWIPT Systems](https://arxiv.org/abs/2509.07610)
*Ahsan Mehmood,Ioannis Krikidis,Ghassan M. Kraidy*

Main category: eess.SP

TL;DR: 本论文提出了一种改进流体天线辅助的同步无线信息和电力传输（SWIPT）系统的速率-能量区域的调制方案设计。


<details>
  <summary>Details</summary>
Motivation: 考虑到实际能量收集电路的非线性特性，本研究旨在解决SWIPT系统的速率-能量（RE）区域优化问题，以联合最大化离散输入互信息（DIMI）和收集的电流。

Method: 本研究使用epsilon-约束法来解决RE区域优化问题，并为各种能量收集阈值设计了优化的星座图。此外，还评估了三种不同的流体天线（FA）端口选择策略（最佳端口、固定端口和随机端口）下优化星座图的性能。

Result: 仿真结果表明，与传统星座图相比，优化后的星座图在信息速率和能量收集方面均有显著的性能提升。

Conclusion: 所提出的调制方案设计能够有效改善流体天线辅助SWIPT系统的速率-能量区域性能。

Abstract: In this work, we propose the design of modulation schemes that improve the
rate-energy region of fluid antenna-assisted simultaneous wireless information
and power transfer (SWIPT) systems. By considering the nonlinear
characteristics of practical energy harvesting circuits, we formulate a
dual-objective rate-energy (RE) region optimization problem to jointly maximize
the discrete-input mutual information (DIMI) and harvested current. The problem
is solved using the epsilon-constraint method and optimized constellations are
designed for various energy harvesting thresholds. We then evaluate the
performance of the optimized constellations under three different fluid antenna
(FA) port selection strategies: (i) Best Port, (ii) Fixed Port, and (iii)
Random Port. Our simulation results demonstrate significant performance gains
of optimized constellations over conventional constellations in both
information rate and energy harvesting.

</details>


### [252] [Deep Learning-based Techniques for Integrated Sensing and Communication Systems: State-of-the-Art, Challenges, and Opportunities](https://arxiv.org/abs/2509.06968)
*Murat Temiz,Yongwei Zhang,Yanwei Fu,Chi Zhang,Chenfeng Meng,Orhan Kaplan,Christos Masouros*

Main category: eess.SP

TL;DR: 本文综述了基于深度学习（DL）的集成传感与通信（ISAC）技术，该技术是6G及未来网络的重要组成部分，能通过统一平台降低硬件复杂性、缓解频谱拥堵并提高能效。DL技术因其在复杂ISAC任务（如波形设计、信道估计、信号处理、数据解调和干扰抑制）中能以低计算复杂度提供近乎最优解，成为克服传统方法计算瓶颈的理想选择。


<details>
  <summary>Details</summary>
Motivation: ISAC系统结合了传感和通信功能，是6G及未来网络（如车联网、工业机器人）的关键技术，能降低硬件复杂性、缓解频谱拥堵并提高能效。但传统方法在ISAC系统设计中计算复杂度高，而DL技术能以较低计算复杂度提供高效的近似最优解，满足低延迟和资源限制的实时系统需求。

Method: 本文首先介绍了深度学习架构和ISAC基础知识，然后全面分类综述了ISAC领域最先进的基于DL的技术。

Result: 已对ISAC领域的各种基于DL的技术进行了全面且分类的综述，并强调了它们的关键优势和主要挑战。

Conclusion: DL技术为ISAC系统设计提供了有前景的方向，能够有效应对复杂任务并满足未来网络的需求，未来的研究应继续探索DL在ISAC中的应用潜力。

Abstract: This article comprehensively reviews recent developments and research on deep
learning-based (DL-based) techniques for integrated sensing and communication
(ISAC) systems. ISAC, which combines sensing and communication functionalities,
is regarded as a key enabler for 6G and beyond networks, as many emerging
applications, such as vehicular networks and industrial robotics, necessitate
both sensing and communication capabilities for effective operation. A unified
platform that provides both functions can reduce hardware complexity, alleviate
frequency spectrum congestion, and improve energy efficiency. However,
integrating these functionalities on the same hardware requires highly
optimized signal processing and system design, introducing significant
computational complexity when relying on conventional iterative or
optimization-based techniques. As an alternative to conventional techniques,
DL-based techniques offer efficient and near-optimal solutions with reduced
computational complexity. Hence, such techniques are well-suited for operating
under limited computational resources and low latency requirements in real-time
systems. DL-based techniques can swiftly and effectively yield near-optimal
solutions for a wide range of sophisticated ISAC-related tasks, including
waveform design, channel estimation, sensing signal processing, data
demodulation, and interference mitigation. Therefore, motivated by these
advantages, recent studies have proposed various DL-based approaches for ISAC
system design. After briefly introducing DL architectures and ISAC
fundamentals, this survey presents a comprehensive and categorized review of
state-of-the-art DL-based techniques for ISAC, highlights their key advantages
and major challenges, and outlines potential directions for future research.

</details>


### [253] [Modeling the Doppler Shift in Cislunar Environment with Gaussian Mixture Models](https://arxiv.org/abs/2509.07134)
*Baris Donmez,Sebastien Loranger,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 本文研究了不同倾角的月球南极（LSP）星间链路（ISL）的射频（RF）基于多普勒频移分布表征。


<details>
  <summary>Details</summary>
Motivation: 研究月球南极（LSP）星间链路（ISL）在不同倾角下的射频（RF）基于多普勒频移分布表征。

Method: 利用高斯混合模型（GMM）拟合不同倾角下的多普勒频移，并使用Kullback-Leibler（KL）散度和加权平均相对差（WMRD）作为拟合优度指标。

Result: 仿真结果显示，当倾角偏离参考轨道达80°时，ISL多普勒频移最大可达±1.89 ppm。GMM拟合的WMRD和KL散度值分别高达0.6575和2.2963。

Conclusion: 高斯混合模型（GMM）是拟合具有1°倾角间隔的多普勒频移的最佳分布，其拟合优度通过KL散度和WMRD量化。

Abstract: This study investigates the RF-based Doppler shift distribution
characterization of the Lunar South Pole (LSP) based inter-satellite link (ISL)
in varying inclination. Doppler shift in parts per million (ppm) is determined
and analyzed, as it provides an independence from the carrier frequency. Due to
unknown relative velocity states duration, the Gaussian Mixture Model (GMM) is
found to be the best fitting distribution for ISLs with $1^\circ$ inclination
interval Doppler shift with respect to a predetermined satellite.
Goodness-of-fit is investigated and quantified with Kullback-Leibler (KL)
divergence and weighted mean relative difference (WMRD) error metrics.
Simulation results show that ISL Doppler shifts reach up to $\pm1.89$ ppm as
the inclination of the other orbit deviates higher from the reference orbit,
inclining $80^\circ$. Regarding the error measurements of GMM fitting, the WMRD
and KL divergence metrics for ISL take values up to 0.6575 and 2.2963,
respectively.

</details>


### [254] [Impact of Fading Correlation on the High-SNR Regime of Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2509.07172)
*Paula Isabel Tilleria Lucero,Bryan Fernando Sarango Rodríguez,Fernando Darío Almeida García,José Cândido Silveira Santos Filho*

Main category: eess.SP

TL;DR: 本研究提出了一种精确的渐近分析方法，用于解决RIS辅助无线系统中固定分集增益、受限空间相关性和高信噪比（SNR）下近似失效等三个关键限制。通过分析SNR分布的左尾，并考虑任意相关的Nakagami-m衰落信道，研究发现衰落相关性会导致概率密度函数（PDF）和累积分布函数（CDF）在对数-dB尺度上的渐近行为（在左尾表现为直线）发生向左的水平移动。


<details>
  <summary>Details</summary>
Motivation: 克服现有RIS辅助无线系统分析中存在的固定分集增益、受限空间相关性以及高信噪比（SNR）下近似失效等三个关键局限性。

Method: 对SNR分布的左尾进行精确的渐近分析，并考虑任意相关的Nakagami-m衰落信道，以处理一般相关性以及可变分集和编码增益的衰落环境。

Result: 研究结果表明，衰落相关性会导致概率密度函数（PDF）和累积分布函数（CDF）在对数-dB尺度上的渐近行为（表现为直线）发生向左的水平移动。这种移动由渐近线性系数量化，而角度系数保持不变。此外，线性系数对相关性的高敏感性源于所有边缘渐近项的聚合贡献，这些项有效地捕捉了每个信道的相关性特征。

Conclusion: 本研究的分析结果揭示了衰落相关性对RIS辅助无线系统性能的影响，并为在高信噪比条件下更准确地评估系统性能提供了理论基础。

Abstract: This paper addresses three critical limitations in previous analyses of
RIS-aided wireless systems: propagation environments with fixed diversity gain,
restricted spatial correlation profiles, and approximation methods that fail to
capture the system behavior in the high signal-to-noise ratio (SNR) regime. To
overcome these challenges, we conduct an exact asymptotic analysis focused on
the left tail of the SNR distribution, which plays a critical role in high-SNR
system performance. Additionally, to account for general correlation profiles
and fading environments with variable diversity and coding gains, we consider
arbitrarily correlated Nakagami-m fading channels. The analytical results show
that fading correlation induces a horizontal shift in the asymptotic behavior
-- represented as a straight line in the log-dB scale -- of the PDF and CDF,
displacing these curves to the left. The asymptotic linear coefficient
quantifies this shift, while the angular coefficient remains unaffected.
Moreover, the results reveal that the high sensitivity of the linear
coefficient to correlation arises from the aggregated contribution of all
marginal asymptotic terms, effectively capturing each channel's correlation
characteristics.

</details>


### [255] [Joint Spatial and Spectral Hybrid Precoding for Multi-User MIMO-OFDM Systems](https://arxiv.org/abs/2509.07229)
*Navid Reyhanian,Reza Ghaderi Zefreh,Parisa Ramezani,Emil Björnson*

Main category: eess.SP

TL;DR: 混合波束成形是毫米波MIMO系统的潜在替代方案，但面临PAPR、OOB排放和PS损伤等挑战。本研究提出了一种基于WMMSE的BCD方法来优化数字-RF波束成形，以最大化混合MU-MIMO-OFDM系统的下行链路和速率。


<details>
  <summary>Details</summary>
Motivation: 由于硬件限制，毫米波（mmWave）大规模混合输入多输出（MIMO）系统不能仅依赖数字预编码。混合预编码结合了数字和射频（RF）技术，在性能和成本之间取得了平衡，解决了信号混频器和模数转换器的局限性。毫米波系统在宽带频率选择性信道中运行，需要使用正交频分复用（OFDM）来缓解色散信道。然而，OFDM存在高峰均功率比（PAPR）和带外（OOB）排放问题。此外，RF发射器预编码器和用户组合器处的移相器（PS）损伤会导致相位误差。

Method: 提出了一种基于加权最小均方误差（WMMSE）的块坐标下降（BCD）方法，用于迭代地优化发射器处的数字-RF预编码器和用户处的数字-RF组合器。还提出了一种低成本、可扩展的优化方法来解决BCD子问题。

Result: 模拟结果表明，所提出的方法是有效的，并且优于已知的基准。

Conclusion: 所提出的基于WMMSE的BCD方法可以有效地解决毫米波混合MU-MIMO-OFDM系统的鲁棒数字-RF预编码优化问题，同时满足功率、PAPR和OOB排放约束。

Abstract: The deployment of millimeter wave (mmWave) multiple-input multiple-output
(MIMO) systems cannot rely solely on digital precoding due to hardware
constraints. Instead, hybrid precoding, which combines digital and radio
frequency (RF) techniques, has emerged as a potential alternative. This
approach strikes a balance between performance and cost, addressing the
limitations of signal mixers and analog-to-digital converters in mmWave
systems. mmWave systems are designed to function in wideband channels with
frequency selectivity, necessitating the use of orthogonal frequency-division
multiplexing (OFDM) to mitigate dispersive channels. However, OFDM faces
several challenges. First, it suffers from a high peak-to-average power ratio
(PAPR) due to the linear combination of subcarriers. Second, it suffers from
out-of-band (OOB) emissions due to the sharp spectral transitions of OFDM
subcarriers and windowing-induced spectral leakage. Furthermore, phase shifter
(PS) impairments at the RF transmitter precoder and the user combiner represent
a limitation in practical mmWave systems, leading to phase errors. This work
addresses these challenges.
  We study the problem of robust digital-RF precoding optimization for the
downlink sum-rate maximization in hybrid multi-user (MU) MIMO-OFDM systems
under maximum transmit power, PAPR, and OOB emission constraints. The
formulated maximization problem is non-convex and difficult to solve. We
propose a weighted minimum mean squared error (WMMSE) based block coordinate
descent (BCD) method to iteratively optimize digital-RF precoders at the
transmitter and digital-RF combiners at the users. Low-cost and scalable
optimization approaches are proposed to efficiently solve the BCD subproblems.
Extensive simulation results are conducted to demonstrate the efficiency of the
proposed approaches and exhibit their superiority relative to well-known
benchmarks.

</details>


### [256] [Experimental Analysis of Biasing Voltage Generation in Wave-Controlled RIS](https://arxiv.org/abs/2509.07293)
*Miguel Saavedra-Melo,Benjamin Bradshaw,Vanessa Yao,Ender Ayanoglu,Lee Swindlehurst,Filippo Capolino*

Main category: eess.SP

TL;DR: 该论文提出了一种基于行波的智能反射面（RIS）新概念，通过在传输线上产生行波来生成所需的直流偏置，从而控制RIS的反射。实验证明了该方法的可行性，并揭示了阻抗匹配对理论模型精度的影响。此外，研究还探索了使用单一频率行波实现单波束赋形，并将波束指向了近处的宽面角。


<details>
  <summary>Details</summary>
Motivation: 为了降低传统RIS设计的复杂性和物理尺寸，提出了一种名为波控RIS的新概念。

Method: 设计了一种波控RIS及其偏置传输线，并通过理论建模和实验验证来分析其有效性。

Result: 理论和实验结果表明，该方法能够从单一行波频率生成正确的直流偏置，但存在与理论模型未考虑的阻抗匹配相关的依赖性。此外，还实现了使用单一频率行波进行单波束赋形，并将波束指向了近处的宽面角。

Conclusion: 波控RIS是一种有前途的技术，可以简化RIS设计并实现有效的无线通信。

Abstract: Reconfigurable intelligent surfaces (RISs), an emerging technology proposed
for inclusion in next generation wireless communication systems, are
programmable surfaces that can adaptively reflect incident electromagnetic
radiation in different desired directions. To reduce the complexity and
physical profile of conventional RIS designs, a novel concept known as
Wave-Controlled RIS has been proposed, in which standing waves along a
transmission line are used to generate the required dc bias for reflective
control. This paper shows the design of such a Wave-Controlled RIS and its
biasing transmission line. The effectiveness of this approach in generating the
correct dc bias from a single standing wave frequency is analyzed through both
theoretical modeling and experimental validation, which uncovered a dependence
on impedance matching not accounted for by the theory. Additionally, the
potential for reflective control using only a single standing wave frequency on
the biasing transmission line is explored, demonstrating the ability of
single-beam steering toward angles near broadside.

</details>


### [257] [Eye Movement Feature-Guided Signal De-Drifting in Electrooculography Systems](https://arxiv.org/abs/2509.07416)
*Lianming Hu,Xiaotong Zhang,Kamal Youcef-Toumi*

Main category: eess.SP

TL;DR: 本研究提出一种眼动特征引导的去基线漂移（FGD）方法，用于缓解眼电信号（EOG）中的漂移伪影，该方法通过识别眼动特征来重建和校正EOG基线漂移，并在模拟和真实数据中均显著减少了平均误差，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 眼电信号（EOG）在人机协作（HRC）中的眼动追踪有广泛应用，但低频噪声引起的基线漂移严重影响其准确性，给传感器融合带来挑战。

Method: 提出眼动特征引导的去基线漂移（FGD）方法，利用主动眼动特征识别来重建提取的EOG基线，并自适应地校正信号漂移，同时保持EOG波形的形态完整性。

Result: 在模拟数据中，平均误差降低至0.896度（减少36.29%）；在真实世界数据中，平均误差降低至1.033度（减少26.53%）。

Conclusion: FGD方法在模拟和真实数据中均能有效减少EOG信号的基线漂移，并且在存在不可预测噪声的真实数据中表现优于传统方法，证明了其在增强人类表现等实际应用中的有效性。

Abstract: Electrooculography (EOG) is widely used for gaze tracking in Human-Robot
Collaboration (HRC). However, baseline drift caused by low-frequency noise
significantly impacts the accuracy of EOG signals, creating challenges for
further sensor fusion. This paper presents an Eye Movement Feature-Guided
De-drift (FGD) method for mitigating drift artifacts in EOG signals. The
proposed approach leverages active eye-movement feature recognition to
reconstruct the feature-extracted EOG baseline and adaptively correct signal
drift while preserving the morphological integrity of the EOG waveform. The FGD
is evaluated using both simulation data and real-world data, achieving a
significant reduction in mean error. The average error is reduced to
0.896{\deg} in simulation, representing a 36.29% decrease, and to 1.033{\deg}
in real-world data, corresponding to a 26.53% reduction. Despite additional and
unpredictable noise in real-world data, the proposed method consistently
outperforms conventional de-drifting techniques, demonstrating its
effectiveness in practical applications such as enhancing human performance
augmentation.

</details>


### [258] [Multi-Modal Intelligent Channel Modeling Framework for 6G-Enabled Networked Intelligent Systems](https://arxiv.org/abs/2509.07422)
*Lu Bai,Zengrui Han,Xuesong Cai,Xiang Cheng*

Main category: eess.SP

TL;DR: 6G通信需要精确的实时信道模型，但传统方法存在局限。本文提出了一种基于多模态感知和人工智能的多模态智能信道建模（MMICM）框架，用于6G网络智能系统，建立了多模态感知与信道特征之间的非线性映射关系。


<details>
  <summary>Details</summary>
Motivation: 6G网络智能系统需要精确的实时信道模型，而传统信道建模方法面临诸多限制。多模态传感器为解决此问题提供了机会，可以通过人工智能技术实现通信与多模态感知的智能融合。

Method: 提出了一种新颖的多模态智能信道建模（MMICM）框架，该框架在多模态感知和信道特征之间建立非线性模型，以利用机器通感（SoM）来探索物理环境和电磁信道之间的映射关系。

Result: 该框架能够建立多模态感知与包括大尺度和小尺度信道特征在内的信道特征之间的非线性映射模型。

Conclusion: MMICM框架为6G网络智能系统提供了一种新的信道建模方法，并指出了其系统应用和未来研究方向。

Abstract: The design and technology development of 6G-enabled networked intelligent
systems needs an accurate real-time channel model as the cornerstone. However,
with the new requirements of 6G-enabled networked intelligent systems, the
conventional channel modeling methods face many limitations. Fortunately, the
multi-modal sensors equipped on the intelligent agents bring timely
opportunities, i.e., the intelligent integration and mutually beneficial
mechanism between communications and multi-modal sensing could be investigated
based on the artificial intelligence (AI) technologies. In this case, the
mapping relationship between physical environment and electromagnetic channel
could be explored via Synesthesia of Machines (SoM). This article presents a
novel multi-modal intelligent channel modeling (MMICM) framework for 6G-enabled
networked intelligent systems, which establishes a nonlinear model between
multi-modal sensing and channel characteristics, including large-scale and
small-scale channel characteristics. The architecture and features of proposed
intelligent modeling framework are expounded and the key technologies involved
are also analyzed. Finally, the system-engaged applications and potential
research directions of MMICM framework are outlined.

</details>


### [259] [Spectrotemporal Feature Extraction in EHG Signals and Tocograms for Enhanced Preterm Birth Prediction](https://arxiv.org/abs/2509.07432)
*Senith Jayakody,Kalana Jayasooriya,Sashini Liyanage,Roshan Godaliyadda,Parakrama Ekanayake,Chathura Rathnayake*

Main category: eess.SP

TL;DR: EHG信号结合KLT降噪和生理学特征提取，可实现高精度早产预测，且EHG信号优于EHG+TOCO信号。


<details>
  <summary>Details</summary>
Motivation: 早产是新生儿死亡和长期健康并发症的主要原因，需要及时的医疗干预，但现有的早产预测工具存在类别不平衡、过采样不当和特征生理学相关性有限等问题。

Method: 提出了一种包含鲁棒预处理、生理学特征提取和严格评估的机器学习流程。从EHG（和TOCO）信号中提取特征，包括MFCC、小波系数的统计描述和归一化功率谱的峰值。使用基于特征值的子空间分解的KLT进行降噪。在TPEHGT数据集上评估了多种分类器。

Result: CatBoost分类器结合KLT降噪在TPEHGT数据集的固定区间片段上达到了97.28%的准确率和0.9988的AUC。消融研究证实了KLT降噪和生理学信息特征的关键作用。EHG信号的预测效果优于EHG+TOCO信号。

Conclusion: 结合降噪和领域相关特征的机器学习模型可以实现高精度、鲁棒且临床可解释的早产预测，有助于在资源匮乏的医疗环境中开发成本效益高且易于使用的早产预测工具。

Abstract: Preterm birth (PTB), defined as delivery before 37 weeks of gestation, is a
leading cause of neonatal mortality and long term health complications. Early
detection is essential for enabling timely medical interventions.
Electrohysterography (EHG) and tocography (TOCO) are promising non invasive
tools for PTB prediction, but prior studies often suffer from class imbalance,
improper oversampling, and reliance on features with limited physiological
relevance. This work presents a machine learning pipeline incorporating robust
preprocessing, physiologically grounded feature extraction, and rigorous
evaluation. Features were extracted from EHG (and TOCO) signals using Mel
frequency cepstral coefficients, statistical descriptors of wavelet
coefficients, and peaks of the normalized power spectrum. Signal quality was
enhanced via Karhunen Lo\`eve Transform (KLT) denoising through eigenvalue
based subspace decomposition. Multiple classifiers, including Logistic
Regression, Support Vector Machines, Random Forest, Gradient Boosting,
Multilayer Perceptron, and CatBoost, were evaluated on the TPEHGT dataset. The
CatBoost classifier with KLT denoising achieved the highest performance on
fixed interval segments of the TPEHGT dataset, reaching 97.28% accuracy and an
AUC of 0.9988. Ablation studies confirmed the critical role of both KLT
denoising and physiologically informed features. Comparative analysis showed
that including TOCO signals did not substantially improve prediction over EHG
alone, highlighting the sufficiency of EHG for PTB detection. These results
demonstrate that combining denoising with domain relevant features can yield
highly accurate, robust, and clinically interpretable models, supporting the
development of cost effective and accessible PTB prediction tools, particularly
in low resource healthcare settings.

</details>


### [260] [SA-OOSC: A Multimodal LLM-Distilled Semantic Communication Framework for Enhanced Coding Efficiency with Scenario Understanding](https://arxiv.org/abs/2509.07436)
*Feifan Zhang,Yuyang Du,Yifan Xiang,Xiaoyan Liu,Soung Chang Liew*

Main category: eess.SP

TL;DR: SA-OOSC是一个利用多模态大语言模型（MLLM）蒸馏的语义通信框架，能够根据场景感知的重要性分配来实现高效的语义编码，解决了现有面向对象语义通信（OOSC）系统中固定分配对象类别重要性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有面向对象语义通信（OOSC）系统存在为特定对象类别分配静态重要性值而忽略其上下文相关性的局限性。

Method: 该框架利用MLLM识别图像中对象的场景增强（SA）语义重要性。通过对MLLM标注数据进行知识蒸馏，对向量化/去向量化网络和JSCC编码器/解码器进行训练，使其能够根据上下文重要性（例如，根据任务的SA场景信息区分高重要性对象和低重要性对象）动态分配编码资源。框架包含三个核心创新：MLLM引导的知识蒸馏流程、重要性加权的变长JSCC框架以及促进JSCC框架内知识蒸馏的新型损失函数设计。

Result: 实验验证表明，与传统的语义通信系统相比，该框架在编码效率方面表现更优，并且开源的MLLM标注和人工验证数据集为未来的语义通信研究树立了新的基准。

Conclusion: SA-OOSC通过引入MLLM引导的知识蒸馏，实现了场景感知的动态重要性分配，显著提高了语义通信的编码效率。

Abstract: This paper introduces SA-OOSC, a multimodal large language models
(MLLM)-distilled semantic communication framework that achieves efficient
semantic coding with scenario-aware importance allocations. This approach
addresses a critical limitation of existing object-oriented semantic
communication (OOSC) systems - assigning static importance values to specific
classes of objects regardless of their contextual relevance. Our framework
utilizes MLLMs to identify the scenario-augmented (SA) semantic importance for
objects within the image. Through knowledge distillation with the
MLLM-annotated data, our vectorization/de-vectorization networks and JSCC
encoder/decoder learn to dynamically allocate coding resources based on
contextual significance, i.e., distinguishing between high-importance objects
and low-importance according to the SA scenario information of the task. The
framework features three core innovations: a MLLM-guided knowledge distillation
pipeline, an importance-weighted variable-length JSCC framework, and novel loss
function designs that facilitate the knowledge distillation within the JSCC
framework. Experimental validation demonstrates our framework's superior coding
efficiency over conventional semantic communication systems, with open-sourced
MLLM-annotated and human-verified datasets established as new benchmarks for
future research in semantic communications.

</details>


### [261] [Node Position Estimation in Diffusion-Based Molecular Communications Using Multi-Layer Perceptron](https://arxiv.org/abs/2509.07441)
*Sangjun Hwang,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 本文提出了一种在扩散分子通信环境中精确估计未知节点间相对位置的方法，通过结合吸收接收器和多个发射器的特殊节点结构，释放示踪分子并测量其吸收时间和浓度，利用多层感知机（MLP）模型进行定位，显著提高了距离和方向估计的精度。


<details>
  <summary>Details</summary>
Motivation: 在扩散分子通信环境中，节点间的相对位置估计是一个重要但具有挑战性的问题，尤其是在节点位置未知的情况下。

Method: 设计了一种包含中心吸收接收器和预定球坐标系下的多个发射器的特殊节点结构。释放示踪分子，并测量其被吸收的时间和浓度。将这些空间上区分的测量值作为输入，训练多层感知机（MLP）模型来估计节点间的相对位置。

Result: 仿真结果表明，该方法能够显著提高距离和方向估计的精度，实现了较高的定位准确性，证明了所提出的神经网络模型在捕捉潜在物理特性方面的有效性。

Conclusion: 本文提出的基于MLP的节点相对位置估计算法，在扩散分子通信环境中展现出优越的性能，为解决未知节点定位问题提供了一种有效的方法。

Abstract: This paper proposes a method for accurately estimating the relative position
between two nodes with unknown locations in a diffusion-based molecular
communication environment. A specialized node structure is designed, combining
a central absorbing receiver with multiple transmitters placed at predefined
spherical coordinates. Pilot molecules are released, and their absorption time
and concentration are measured. By partitioning the spherical coordinate space,
these spatially distinct measurements serve as input to a multilayer perceptron
(MLP)-based model. The proposed method significantly improves the precision of
distance and direction estimation. Simulation results demonstrate localization
accuracy, confirming the effectiveness of the neural network model in capturing
the underlying physical characteristics.

</details>


### [262] [A Systematic Framework to Test the Resilience of Three-Fold Redundant Sparse Arrays Against Two Sensor Failures and Some Never-Before Findings](https://arxiv.org/abs/2509.07442)
*Ashish Patwari,Andrés Alayón Glazunov*

Main category: eess.SP

TL;DR: MESAs因传感器数量少而无法承受任何传感器故障。MFRSAs通过多重冗余提高了鲁棒性，但仍存在隐藏的依赖性。本文提出了一种系统性框架来评估TRSLAs对抗双传感器故障的鲁棒性，并分析了现有TRSLAs的故障情况，发现它们存在一些隐藏的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有的最大化经济稀疏阵列（MESAs）因其传感器数量少而无法承受传感器故障。多重冗余稀疏阵列（MFRSAs）虽然提高了鲁棒性，但仍存在隐藏的依赖性。因此，需要一种方法来评估和确保稀疏阵列，特别是三倍冗余稀疏线性阵列（TRSLAs）在传感器故障情况下的鲁棒性。

Method: 提出一个系统性的框架来评估三倍冗余稀疏线性阵列（TRSLAs）在所有可能的双传感器故障情况下的鲁棒性。对现有文献中代表性的TRSLAs进行了故障分析。

Result: 现有的TRSLAs在面对某些特定传感器对的故障时，表现出一些隐藏的脆弱性。提供了相应的MATLAB程序和数值模拟用于评估。

Conclusion: 提出的框架为评估TRSLAs的鲁棒性提供了一种客观的方法，具有重要的存档价值，可用于评估现有和未来的TRSLAs。

Abstract: As the field of sparse arrays progressed, numerous array designs have been
introduced with a focus on larger apertures and higher degrees of freedom
(DOFs), resulting in maximally economic sparse arrays (MESAs) that operate with
the least number of sensors required to provide a given aperture while ensuring
a hole-free difference coarray (DCA). Consequently, MESAs are least robust to
sensor failures and cannot afford the failure of even a single sensor.
Multifold redundant sparse arrays (MFRSAs) provide a practical solution to the
problem of sensor failures in sparse arrays by making sure that the array
contains enough sensor pairs necessary to produce each spatial lag multiple
times. Owing to this property, a \b{eta}-fold redundant array can withstand
simultaneous failure of at least \b{eta}-1 sensors without losing the hole-free
DCA property. Nevertheless, MFRSAs are also prone to hidden dependencies that
prevent them from being fully robust. In this work, we present a systematic
framework to evaluate the robustness of triple redundant sparse linear arrays
(TRSLAs) against all possible two-sensor failures. After detailing the proposed
approach, we present the failure analysis of representative TRSLAs available in
existing literature. It is found that existing TRSLAs have some hidden
vulnerabilities against the failure of some peculiar sensor pairs.
Corresponding MATLAB programs and numerical simulations are provided for
evaluation and use by the array processing community. The proposed approach has
a great archival value as it can evaluate the robustness of any present or
future TRSLAs through objective means.

</details>


### [263] [Integrated Communication and Computing in Time-Varying mmWave Channels](https://arxiv.org/abs/2509.07482)
*Joan Çollaku,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Takumi Takahashi*

Main category: eess.SP

TL;DR: 该论文提出了一种新颖的框架，用于在时变毫米波（mmWave）信道中进行通信和计算（ICC）收发器设计。该框架通过并行执行符号检测、空中计算（AirComp）操作和信道跟踪来应对时变信道的动态性，解决了现有技术通常假设信道知识完美的问题。具体来说，在单输入多输出（SIMO）上行链路场景中，用户设备（UE）进行预编码，基站（BS）进行接收波束成形。该框架使用双线性高斯信念传播（BiGaBP）算法联合估计信道状态信息（CSI）和数据符号，并通过信道预测（CP）算法进行辅助。AirComp操作通过对残差信号进行最优组合来执行。仿真结果表明，该方案在时变毫米波信道中执行ICC具有有效性，并且对通信和计算性能的损害最小。


<details>
  <summary>Details</summary>
Motivation: 应对时变毫米波信道中的通信和计算（ICC）设计挑战，解决现有技术通常假设信道知识完美的问题。

Method: 在单输入多输出（SIMO）上行链路场景中，提出了一种新颖的ICC收发器框架。该框架通过双线性高斯信念传播（BiGaBP）算法联合估计信道状态信息（CSI）和数据符号，并结合信道预测（CP）算法。空中计算（AirComp）操作通过对残差信号进行最优组合来执行。

Result: 仿真结果表明，所提出的方案在时变毫米波信道中执行ICC具有有效性，并且对通信和计算性能的损害最小。

Conclusion: 所提出的新颖框架能够有效地处理时变毫米波信道中的ICC问题，并在通信和计算性能方面实现了最小的性能下降。

Abstract: We propose a novel framework for integrated communication and computing (ICC)
transceiver design in time-varying millimeter-wave (mmWave) channels. In
particular, in order to cope with the dynamics of time-varying mmWave channels,
the detection of communication symbols and the execution of an over-the-air
computing (AirComp) operation are performed in parallel with channel tracking,
as opposed to existing state-of-the-art (SotA) on ICC where perfect knowledge
of the channel at all time instances is typically assumed. For clarity of
exposition, we consider a single-input multiple-output (SIMO) uplink scenario
where multiple single-antenna user equipment (UE) transmit to a base station
(BS) equipped with multiple antennas, such that each UE, or edge device (ED),
precodes its own transmit signal, while the BS, or access points (APs), also
performs receive beamforming. The proposed transceiver framework then estimates
channel state information (CSI) and data symbols in parallel, using a bilinear
Gaussian belief propagation (BiGaBP) algorithm for joint channel and data
detection (JCDE), aided by a channel prediction (CP) algorithm executed before
each estimation window at the BS. The AirComp operation is then executed by
means of an optimal combination of the residual signal. Simulation results
demonstrate the effectiveness of the proposed scheme in performing ICC in
challenging time-varying mmWave channels, with minimal degradation to both
communication and computing performance.

</details>


### [264] [A Methodological Framework for Positioning of Wireless Sensors in New Generation Launchers](https://arxiv.org/abs/2509.07483)
*Ivan Iudice,Domenico Pascarella,Sonia Zappia,Giovanni Cuciniello,Hernan M. R. Giannetta,Marta Albano,Enrico Cavallini*

Main category: eess.SP

TL;DR: 本研究提出一个用于可重复使用发射器无线传感器网络的框架，通过优化网络拓扑、收发器操作和总辐射功率来分析电磁环境。


<details>
  <summary>Details</summary>
Motivation: 鉴于可重复使用发射器在复杂且动态的电磁环境中运行，对其进行电磁特性和电磁兼容性分析至关重要。

Method: 该框架基于节点初步定位，规定了一个工作流程和相关工具集，以确定最佳网络拓扑，并利用计算电磁学策略模拟最优网络配置，以评估传感器网络本身引起的电磁环境。

Result: 研究结果包括针对特定发射器的案例研究。

Conclusion: 该框架能够为可重复使用发射器无线传感器网络的设计和电磁环境分析提供方法。

Abstract: In wireless sensor networks for reusable launchers, the electromagnetic
characterization and electromagnetic compatibility analyses are relevant due to
the reference operational scenario, which implies a complex, and sometimes
dynamic, electromagnetic environment. This work proposes a methodological
framework for the design of the network and for the analysis of the related
electromagnetic environment within the stages of a given launcher. Based on the
preliminary positioning of the network nodes, the framework prescribes a
workflow and the related toolset for determining the optimal network topology
focusing on the weights, the operation of the transceivers, and the overall
radiated power. The optimal network configuration is simulated by using
computational electromagnetics strategies in order to assess the
electromagnetic environment induced by the sensor network itself. The paper
provides some results concerning a case study for a specific launcher.

</details>


### [265] [Joint Antenna Positioning and Beamforming for Movable Antenna Array Aided Ground Station in Low-Earth Orbit Satellite Communication](https://arxiv.org/abs/2509.07511)
*Jinming Wang,Lipeng Zhu,Shuai Han,He Sun,Rui Zhang*

Main category: eess.SP

TL;DR: 提出了一种由可移动天线（MA）阵列辅助的新型低地球轨道（LEO）卫星地面站架构，以减轻干扰并提高通信性能。


<details>
  <summary>Details</summary>
Motivation: 为了在超密集LEO卫星网络中更有效地减轻干扰和提高通信性能，与传统的固定位置天线（FPA）不同，MA阵列可以灵活地调整天线位置以重新配置阵列几何形状。

Method: 通过联合优化天线位置矢量（APV）和时变波束成形权重（天线权重矢量 AWV）来最大化地面站的平均可实现速率。采用拉格朗日对偶变换和二次变换来处理非凸优化问题，并开发了一种基于块坐标下降的迭代算法来交替优化APV和AWV。

Result: 仿真结果表明，与传统的FPA相比，所提出的MA方案在各种系统设置下都能显著提高地面站的可实现速率。

Conclusion: 所提出的MA方案为未来超密集LEO卫星通信网络中的干扰缓解提供了一种有效的解决方案。

Abstract: This paper proposes a new architecture for the low-earth orbit (LEO)
satellite ground station aided by movable antenna (MA) array. Unlike
conventional fixed-position antenna (FPA), the MA array can flexibly adjust
antenna positions to reconfigure array geometry, for more effectively
mitigating interference and improving communication performance in ultra-dense
LEO satellite networks. To reduce movement overhead, we configure antenna
positions at the antenna initialization stage, which remain unchanged during
the whole communication period of the ground station. To this end, an
optimization problem is formulated to maximize the average achievable rate of
the ground station by jointly optimizing its antenna position vector (APV) and
time-varying beamforming weights, i.e., antenna weight vectors (AWVs). To solve
the resulting non-convex optimization problem, we adopt the Lagrangian dual
transformation and quadratic transformation to reformulate the objective
function into a more tractable form. Then, we develop an efficient block
coordinate descent-based iterative algorithm that alternately optimizes the APV
and AWVs until convergence is reached. Simulation results demonstrate that our
proposed MA scheme significantly outperforms traditional FPA by increasing the
achievable rate at ground stations under various system setups, thus providing
an efficient solution for interference mitigation in future ultra-dense LEO
satellite communication networks.

</details>


### [266] [Interference Mitigation for OFDM-based Integrated Sensing and Communications with Arbitrary Modulation Formats](https://arxiv.org/abs/2509.07754)
*Felix Artmann,Daniel Gil Gaviria,Benedikt Geiger,Laurent Schmalen*

Main category: eess.SP

TL;DR: 文章研究了在通信和传感一体化系统中，不同调制星座图对OFDM系统传感性能的影响，并提出了一种增强的干扰抑制算法，该算法在多目标和散射场景下，性能接近最优的恒模信号，同时实现了通信效率的提升。


<details>
  <summary>Details</summary>
Motivation: 为了探究未来6G通信网络中，通信和传感一体化系统（ISAC）在利用通信信号进行传感时，不同调制星座图对通信中心OFDM系统传感性能的影响，并提出有效的干扰抑制方法。

Method: 1. 分析了任意调制星座图对通信中心OFDM系统传感性能的影响。 2. 评估了现有的干扰抑制技术，如相干连续目标消除（coherent successive target cancellation）。 3. 提出了一种相干连续目标消除算法的增强版本。 4. 在多目标和散射场景下，对所提出的干扰抑制方法进行了系统性性能评估。

Result: 在多目标和散射场景下，所提出的干扰抑制方法实现了与传感最优的恒模信号相当的性能，并且能够利用更高阶的星座图以实现更高效的通信。

Conclusion: 所提出的增强型干扰抑制算法能够在保持通信效率的同时，实现与传感最优信号相当的传感性能，为未来6G通信网络中通信和传感一体化系统的设计提供了有价值的参考。

Abstract: Integrated sensing and communication will be a key feature of future mobile
networks, enabling highly efficient systems and numerous new applications by
leveraging communication signals for sensing. In this paper, we analyze the
impact of arbitrary modulation alphabets on the sensing performance of
communication-centric OFDM systems as expected in the next-generation 6G
networks. We evaluate existing interference mitigation techniques, such as
coherent successive target cancellation, and propose an enhanced version of
this algorithm. A systematic performance evaluation in multi-target scenarios,
including the effects of scattering, demonstrates that our proposed
interference mitigation methods achieve performance comparable to
sensing-optimal constant modulus signals while utilizing higher order
constellations for more efficient communications.

</details>


### [267] [Experimental Evaluation of Joint Clock Recovery and Equalization for Sub-Terahertz Links](https://arxiv.org/abs/2509.07758)
*Pietro Savazzi,Anna Vizziello,Sherif Badran,Josep M. Jornet*

Main category: eess.SP

TL;DR: 该论文提出并验证了一种联合时钟恢复（CR）和均衡架构，适用于高速亚太赫兹（sub-THz）无线通信链路。


<details>
  <summary>Details</summary>
Motivation: 在高速亚太赫兹无线通信中，需要一种无需判决引导（DD）反馈或导频符号即可实现鲁棒符号定时同步的方案，以应对具有挑战性的同步约束。

Method: 提出了一种结合恒模算法（CMA）均衡器和盲定时误差检测器（TED）的波特间隔数字接收机架构。该TED利用CMA滤波器系数来估计定时误差，并驱动工作在符号速率两倍的Farrow插值器。

Result: 在140 GHz无线测试平台和16-QAM调制下，结果表明该TED方案在比特错误率（BER）、误差向量幅度（EVM）和符号间干扰（ISI）抑制方面优于传统的盲TED（如Gardner和Mueller & Müller的盲实现）。

Conclusion: 所提出的联合CR和均衡架构能够满足下一代星载通信系统对超高数据速率、亚太赫兹链路的需求。

Abstract: This paper proposes and experimentally evaluates a joint clock recovery (CR)
and equalization architecture tailored for high-speed sub-terahertz (sub-THz)
wireless communication links. Specifically, a Baud-spaced digital receiver
architecture is investigated that combines a constant modulus algorithm (CMA)
equalizer with a blind timing error detector (TED), enabling robust symbol
timing synchronization without decision-directed (DD) feedback or pilot
symbols. The proposed TED leverages the CMA filter coefficients to estimate
timing errors, which are then used to drive a Farrow interpolator operating at
twice the symbol rate. The system is validated experimentally using a 140~GHz
wireless testbed with 16-QAM modulation over a 10~GHz bandwidth. Results show
that the proposed TED schemes outperform conventional blind TEDs, such as
Gardner and blind implementations of Mueller \& M\"uller, in terms of bit error
rate (BER), error vector magnitude (EVM), and intersymbol interference (ISI)
suppression. These capabilities are especially relevant to next-generation
spaceborne communication systems, where wideband sub-THz links are expected to
play a key role in enabling ultra-high-data-rate inter-satellite and deep-space
communications under challenging synchronization constraints.

</details>


### [268] [Sensing with Mobile Devices through Radio SLAM: Models, Methods, Opportunities, and Challenges](https://arxiv.org/abs/2509.07775)
*Yu Ge,Ossi Kaltiokallio,Elizaveta Rastorgueva-Foi,Musa Furkan Keskin,Hui Chen,Guillaume Jornod,Jukka Talvitie,Mikko Valkama,Frank Hofmann,Henk Wymeersch*

Main category: eess.SP

TL;DR: 本文探讨了6G中的无线电SLAM技术，将其作为一种关键的ISAC方法，用于同时进行环境感知和定位。研究了不同频段下的无线电SLAM，并讨论了其在覆盖范围、分辨率和硬件要求方面的权衡。此外，文章还强调了与传感、定位和协作网络的集成机会，为自动驾驶和工业机器人等6G应用铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 6G时代需要集成传感和通信（ISAC）技术，以实现环境感知和通信的同步。无线电SLAM（同步定位与地图构建）被认为是实现这一目标的关键技术，它利用无线电信号进行地图构建和定位。

Method: 本文分析了无线电SLAM在不同频段下的应用，并探讨了其在覆盖范围、分辨率和硬件要求方面的优缺点。同时，还考察了该技术与传感、定位和协作网络集成的可能性。

Result: 研究表明，无线电SLAM在不同频段下具有不同的性能表现，并存在覆盖范围、分辨率和硬件要求方面的权衡。与传感、定位和协作网络的集成将带来更广泛的应用前景。

Conclusion: 无线电SLAM是实现6G ISAC的关键技术，其在不同频段的应用及与其他技术的集成将为自动驾驶和工业机器人等应用提供标准化解决方案。

Abstract: The integration of sensing and communication (ISAC) is a cornerstone of 6G,
enabling simultaneous environmental awareness and communication. This paper
explores radio SLAM (simultaneous localization and mapping) as a key ISAC
approach, using radio signals for mapping and localization. We analyze radio
SLAM across different frequency bands, discussing trade-offs in coverage,
resolution, and hardware requirements. We also highlight opportunities for
integration with sensing, positioning, and cooperative networks. The findings
pave the way for standardized solutions in 6G applications such as autonomous
systems and industrial robotics.

</details>


### [269] [Enhancements in Score-based Channel Estimation for Real-Time Wireless Systems](https://arxiv.org/abs/2509.07839)
*Florian Strasser,Marion Bäro,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 本研究提出了用于点对点单载波MIMO无线系统低延迟导频辅助信道估计的基于分数的生成模型增强方法。


<details>
  <summary>Details</summary>
Motivation: 低延迟和高吞吐量是无线通信的关键要求，特别是在MIMO系统中，信道估计的延迟会严重影响系统性能。现有的信道估计方法在延迟和精度之间存在权衡，而基于分数的方法在生成建模方面显示出潜力，但其在信道估计中的应用仍需优化以满足低延迟需求。

Method: 研究人员提出并评估了两种改进方案：1. 优化基于分数的生成模型中的噪声表设计。 2. 通过跳过采样步骤来加速采样过程，从而减少去噪步骤的数量。作为跳过步骤方法的一个极端情况，还提出了一种单步信噪比感知的去噪器。

Result: 所提出的方法在合成的城市宏蜂窝MIMO通信场景数据集上进行了验证，结果表明，在不影响性能的情况下，显著降低了延迟。

Conclusion: 本研究成功地将基于分数的生成模型应用于低延迟导频辅助信道估计，并通过噪声表设计和采样加速实现了显著的延迟降低，而不会牺牲估计精度，为未来无线通信系统中的高效信道估计提供了有前景的解决方案。

Abstract: We propose enhancements to score-based generative modeling techniques for
low-latency pilot-based channel estimation in a point-to-point single-carrier
multiple-input multiple-output (MIMO) wireless system. Building on recent
advances in score-based models, we investigate a specific noise schedule design
and sampling acceleration by step-skipping to reduce the number of denoising
steps during inference. We additionally propose a single-step signal-to-noise
ratio informed denoiser as an extreme case of the step-skipping approach. Our
methods achieve significant latency reductions without performance degradation,
as demonstrated on a synthetic channel dataset representing an urban macrocell
MIMO communications scenario.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [270] [Quantum control of exciton motion in electric field](https://arxiv.org/abs/2509.07107)
*Yingjia Li,Jorge Casanova,Xi Chen,E. Ya. Sherman*

Main category: cond-mat.mes-hall

TL;DR: 研究人员提出了一种利用优化电场来精确控制二维激子运动的方法，该方法可以有效降低计算需求，并为激子通量、种群以及二维半导体结构中的光发射提供控制。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是控制二维激子运动，特别是其最终位置和速度，以便在二维半导体结构中实现激子通量、种群和光发射的可控性。

Method: 采用一种优化的、依赖时间的电场来控制激子的量子偶极矩，从而控制其经典运动。提出了一种优化的搜索方法，以减少计算需求并有效识别最佳控制参数。

Result: 通过所提出的优化方法，可以精确控制激子的最终位置和速度，并在指定的演化时间内实现。

Conclusion: 所提出的量子控制方法为控制激子通量、种群和实现二维半导体结构中的光发射提供了新的途径。

Abstract: We study quantum control of classical motion of a two-dimensional exciton by
optimizing the time-dependent electric field of a stripe-like gate acting on
the exciton and inducing its time-dependent quantum dipole moment. We propose a
search method that significantly reduces computational requirements while
efficiently identifying optimal control parameters. By leveraging this method,
one can precisely manipulate the exciton's final position and velocity over a
specified evolution time. These results can be applied for control of exciton
fluxes and population, and for spatially resolved light emission in
two-dimensional semiconducting structures.

</details>


### [271] [Quantum Theory of Exciton Magnetic Moment: Interaction and Topological Effects](https://arxiv.org/abs/2509.07284)
*Gurjyot Sethi,Jiawei Ruan,Fang Zhang,Weichen Tang,Chen Hu,Mit Naik,Steven G. Louie*

Main category: cond-mat.mes-hall

TL;DR: 将磁力测量与光学光谱相结合，可以揭示新颖的量子现象，并已成为量子信息科学的一个平台。然而，激子的磁响应理论（激子是半导体中相关的电子-空穴对）仍不完整，因为对电子-空穴相互作用和拓扑效应的处理不足。例如，在有偏置的双层石墨烯中，p-激子的谷g因子的理论预测与实验偏差近一个数量级。本文开发了一种激子轨道磁矩的量子理论，揭示了几个先前理论中不存在的概念上新的项，包括来自激子能带量子几何的意外贡献。我们的从头计算得出的结果与测量结果非常吻合，这表明了一个包含相互作用和拓扑效应的完整理论对于激子磁响应的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于电子-空穴相互作用和拓扑效应的处理不足，激子的磁响应理论仍然不完整，这阻碍了将磁力测量与光学光谱相结合的进展。

Method: 开发了一种新的量子理论，用于计算激子轨道磁矩，并包含了电子-空穴相互作用和拓扑效应的贡献。利用从头计算来验证该理论。

Result: 该理论在有偏置双层石墨烯的p-激子的谷g因子预测方面取得了与实验高度一致的结果，这与先前理论的重大偏差形成对比。

Conclusion: 包括电子-空穴相互作用和拓扑效应在内的完整理论对于准确描述激子的磁响应至关重要，这为包括磁力测量和光学光谱在内的量子信息科学开辟了新的途径。

Abstract: Combining magnetometry with optical spectroscopy has uncovered novel quantum
phenomena and is emerging as a platform for quantum information science. Yet,
the theory of magnetic response of excitons, correlated electron-hole pairs in
semiconductors, remains incomplete due to insufficient treatment of
electron-hole interaction and topological effects. In biased bilayer graphene,
for instance, theoretical predictions of valley g-factor for p-excitons deviate
from experiment by nearly an order of magnitude. Here, we develop a quantum
theory of exciton orbital magnetic moment that reveals several conceptually new
terms absent in prior theories, including an unforeseen contribution from
exciton band quantum geometry. Our ab initio calculations yield results in
excellent agreement with measurements, establishing the importance of a full
theory including interaction and topological effects for the magnetic response
of excitons.

</details>


### [272] [Spin-Orbit Coupling Effect on the Seebeck Coefficient in Dirac Electron Systems in $α$-(BETS)$_2$I$_3$](https://arxiv.org/abs/2509.07349)
*Yoshikazu Suzumura,Takao Tsumuraya,Masao Ogata*

Main category: cond-mat.mes-hall

TL;DR: 该论文研究了在三份之四填充的有机导体 α-(BETS)₂I₃ 中二维狄拉克电子的塞贝克系数，并考虑了杂质和电子-声子散射的影响。


<details>
  <summary>Details</summary>
Motivation: 研究有机导体中二维狄拉克电子的塞贝克系数，以理解其热电性质。

Method: 使用基于第一性原理密度泛函理论的紧束缚模型，计算了在杂质和电子-声子散射存在下的塞贝克系数。

Result: 发现塞贝克系数在不同方向（Sx < 0, Sy > 0）和温度下表现出不同的行为，包括符号变化。在低温下，自旋-轨道耦合增强了塞贝克系数的绝对值。电子和空穴的贡献相互竞争。

Conclusion: 通过分析塞贝克系数的能带分量和谱电导率，阐明了其温度依赖性，并解释了电子和空穴贡献的竞争关系。

Abstract: Seebeck coefficient, $S=L_{12}/(TL_{11})$, which is proportional to a ratio
of the thermoelectric conductivity $L_{12}$ to the electric conductivity
$L_{11}$ with $T$ being temperature is examined for two-dimensional Dirac
electrons in a three-quarter filled organic conductor,
$\alpha$-(BETS)$_2$I$_3$, [BETS = BEDT-TSeF =
bis(ethylenedithio)tetraselenafulvalene] at ambient pressure.Using a
tight-binding (TB) model obtained by first-principles relativistic
density-functi onal theory method [Eur. Phys. J. B 94, 17 (2021)], we calculate
$S$ in the presence of the impurity and electron--phonon (e--p) scatterings. It
is shown that $S_x < 0$ and $S_y >0$ at high temperatures, where $S_x$ ($S_y$)
denotes $S$ perpendicular (parallel) to the molecular stacking axis. There is a
sign change of $S_y$ with increasing $T$. It is found that, at low temperatures
the absolute value of $S$ is enhanced by the spin-orbit coupling. The Seebeck
coefficient is examined by dividing into components of the conduction and
valence bands to find that the electron and hole contributions compete each
other. Such $T$ dependence of $S$ is clarified using the spectral conductivity,
which determines $L_{12}$ and $L_{11}$.

</details>


### [273] [Janus Skyrmion: Interfacial Quasiparticle with Two-Faced Helicity](https://arxiv.org/abs/2509.07394)
*Xichao Zhang,Rui Zhang,Qiming Shao,Yan Zhou,Charles Reichhardt,Cynthia J. O. Reichhardt,Masahito Mochizuki*

Main category: cond-mat.mes-hall

TL;DR: Janus 粒子在具有不同反常交换相互作用的两个磁性区域的界面处出现，形成可以共存不同螺旋结构的拓扑准粒子，称为 Janus 斯格明子。


<details>
  <summary>Details</summary>
Motivation: 研究在具有不同反常交换相互作用的两个磁性区域的界面处，是否存在新的拓扑准粒子，并探究其性质。

Method: 理论研究了 Janus 粒子在磁性界面处的行为，并提出了 Janus 斯格明子的概念。

Result: 发现了 Janus 斯格明子，并研究了其尺寸随磁场的变化、在垂直自旋流中的运动以及布朗运动。

Conclusion: Janus 斯格明子是一种具有奇异螺旋结构的界面准粒子，其独特的动力学行为可能在界面工程磁层中实现。

Abstract: Janus particles are functional particles with at least two surfaces showing
asymmetric properties. We show at the interface between two magnetic regions
with different antisymmetric exchange interactions, a new species of
topological quasiparticles can emerge, in which different helicity structures
can coexist. We name such an interfacial quasiparticle a "Janus skyrmion", in
analogy to the Janus particle. As the Janus skyrmion shows helicity asymmetry,
its size could vary with both the in-plane and out-of-plane magnetic fields. A
vertical spin current could drive the Janus skyrmion into one-dimensional
motion along the interface without showing the skyrmion Hall effect, at a speed
which depends on both the spin polarization angle and current density. Thermal
fluctuations could also lead to one-dimensional random walk of a Brownian Janus
skyrmion. This work uncovers unique dynamics of interfacial quasiparticles with
exotic helicity structures, which may be realized in interface-engineered
magnetic layers.

</details>


### [274] [Anisotropic resistivity of a $p$-wave magnet candidate CeNiAsO](https://arxiv.org/abs/2509.07351)
*Honglin Zhou,Muyu Wang,Xiaoyan Ma,Gang Li,Ding-Fu Shao,Bo Liu,Shiliang Li*

Main category: cond-mat.mes-hall

TL;DR: CeNiAsO是一种反常磁体，具有p波对称性，有望用于自旋电子学。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索CeNiAsO是否具有p波磁性，并评估其在自旋电子学中的应用潜力。

Method: 通过测量CeNiAsO的电阻率并研究其在不同磁场方向下的行为来验证p波磁性的存在。

Result: 测量结果显示CeNiAsO的电阻率表现出强烈的面内各向异性，并且可以通过改变面内磁场的方向实现高低电阻状态之间的可逆和非易失性切换。

Conclusion: CeNiAsO是p波磁性的一个关键实验证据，并为基于电阻率各向异性的高性能反常磁性自旋电子学开辟了新的途径。

Abstract: Certain noncollinear antiferromagnets host momentum-dependent spin-splitting
bands with odd-parity $p$-wave symmetry, termed $p$-wave magnets. Metallic
$p$-wave magnets offer a unique platform for spintronic applications, yet
experimental realizations remain scarce. CeNiAsO, featuring a tetragonal
structure and developing a commensurate coplanar noncollinear antiferromagnetic
order at low temperatures, has been theoretically proposed as such a magnet.
Here, we show that its resistivity exhibits strong two-fold in-plane anisotropy
-- a key signature of its proposed $p$-wave magnetism. Reversible and
nonvolatile switching between high- and low-resistance states is achieved by
alternating the in-plane magnetic field direction, indicating potential for
field-controlled memory devices. Our results not only provide critical
experimental evidence for $p$-wave magnetism in CeNiAsO but also open new
avenues for high-performance antiferromagnetic spintronics based on resistivity
anisotropy.

</details>


### [275] [Longitudinal spin current absorption in bilayers composed of ferromagnetic and highly-resistive non-magnetic layers](https://arxiv.org/abs/2509.07390)
*Sosuke Hori,Kohei Ueda,Junichi Shiogai,Jobu Matsuno*

Main category: cond-mat.mes-hall

TL;DR: 本论文研究了由SrIrO3/CoFeB双层薄膜中的自旋霍尔磁电阻（SMR）现象，重点关注了磁性层对纵向自旋流的吸收对其SMR的影响。


<details>
  <summary>Details</summary>
Motivation: 研究SrIrO3/CoFeB双层薄膜中，磁性层（CoFeB）对纵向自旋流的吸收如何影响自旋霍尔磁电阻（SMR）现象，并探究了使用高阻 SrIrO3 作为自旋流源时的SMR机制。

Method: 通过实验测量SrIrO3/CoFeB双层薄膜的SMR信号，并与包含自旋流吸收的SMR模型进行比较，分析了CoFeB层厚度对SMR比率的影响，并计算了考虑自旋流吸收后的有效自旋霍尔角。

Result: 观察到清晰的SMR信号，并且随着CoFeB层厚度的增加，SMR比率增强，这与包含自旋流吸收的SMR模型定性一致。考虑自旋流吸收后，有效自旋霍尔角从0.07修正为0.12，相对修正约为71%。

Conclusion: 研究结果表明，当使用像SrIrO3这样的高阻非磁性层时，磁性层对自旋流的吸收对SMR机制有显著影响。这一发现对于理解和优化包含新兴量子材料的双层薄膜SMR器件具有重要意义。

Abstract: Spin Hall magnetoresistance (SMR) is an intriguing spin-dependent transport
phenomenon in bilayers consisting of non-magnetic and magnetic layers. Here, we
report on the influence of longitudinal spin current absorption by the magnetic
layer on SMR in bilayers composed of Co$_{20}$Fe$_{60}$B$_{20}$ (CoFeB) and
epitaxial SrIrO$_{3}$, where SrIrO$_{3}$ is used as a highly-resistive spin
current source. We observed a clear SMR signal and an enhancement in the SMR
ratio with increasing CoFeB layer thickness, in qualitative agreement with an
SMR model that incorporates the spin current absorption. The effective spin
Hall angle is corrected from 0.07 to 0.12 with consideration of the spin
current absorption, corresponding to a relative correction of ~71%. Our
findings highlight the pronounced impact of the spin current absorption by the
magnetic layer on the SMR mechanism when employing highly-resistive
non-magnetic layer such as SrIrO$_{3}$, as well as other emerging quantum
materials.

</details>


### [276] [Tunneling resonances through periodically driven quantum dots](https://arxiv.org/abs/2509.07539)
*Jan Mathis Giesen,Daniel Weber,Sebastian Eggert*

Main category: cond-mat.mes-hall

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Periodic driving of quantum dots is analyzed as a basis for developing
dynamic switching devices. We study transport through periodically modulated
energy levels which are coupled to leads via tunneling coefficients. Utilizing
Floquet theory a full analytic solution is found in terms of continued
fractions, enabling us to efficiently calculate and analyze the transmission
through the quantum dot in relevant parameter regimes. By considering levels at
higher energy outside the spectrum of the transmitted particles a resonant
switching effects is identified, where a very small oscillating control signal
on a weakly connected quantum dot can induce perfect transmission. We also find
closed form expressions using Bessel functions in the limit of small tunnel
couplings. The results predict and explain resonant tunneling in
nano-electronic devices as well as in corresponding setups using magnonic
systems, photonic waveguides, or ultra-cold gases in optical lattices.

</details>


### [277] [Fluctuation-dissipation bounds for time-dependently driven conductors](https://arxiv.org/abs/2509.07583)
*Ludovico Tesser,José Balduque,Janine Splettstoesser*

Main category: cond-mat.mes-hall

TL;DR: 该论文研究了多端点、多通道导体在任意时变驱动和静态电势/温度偏差下的噪声问题，并提出了两种新的噪声上界。


<details>
  <summary>Details</summary>
Motivation: 研究任意时变驱动和静态偏差下的导体噪声问题，特别是关注其在非平衡状态下的零频率噪声。

Method: 推导并分析了两种噪声上界：基于涨落-耗散定理的上界，以及一个依赖于电子分布形状的更紧的上界。

Result: 证明了在任意时变驱动和静态偏差下，零频率噪声受到涨落-耗散定理的约束，并提出了一个更紧的、依赖于电子分布形状的噪声上界。

Conclusion: 提出的两种噪声上界对于理解和分析复杂驱动下的导体噪声具有重要意义，尤其是在考虑实际实验中的交流偏压情况时。

Abstract: We analyze the noise in a multi-terminal multi-channel conductor under
arbitrary time-dependent driving and subject to -- possibly large -- static
potential and temperature biases. We show that the full out-of-equilibrium
zero-frequency noise is constrained by a fluctuation-dissipation bound. It
consists of an upper bound expressed in terms of weighted current components of
the separate Floquet bands arising from the time-dependent driving. In the
limit of large static temperature bias, it has an intuitive interpretation in
terms of the dissipated powers due to the static potential bias and due to the
time-dependent driving. Furthermore, we show the existence of a second bound
that relies on the specific shape of the electron distribution resulting from
the driving, which is often even tighter than the fluctuation-dissipation
bound. We show the implications of our bounds at the simple, but experimentally
relevant example of a two-terminal conductor in the presence of an ac bias.

</details>


### [278] [Chirality-Induced Orbital Selectivity through Linear-Orbital Coupling](https://arxiv.org/abs/2509.07675)
*Namgee Cho,James Lim,Martin B. Plenio*

Main category: cond-mat.mes-hall

TL;DR: 电子在手性静电势中的传输表现出显著的对映选择性，源于轨道角动量动力学和线性动量之间的耦合，且效应强于自旋相关相互作用。


<details>
  <summary>Details</summary>
Motivation: 研究手性静电势对电子传输的影响，特别是轨道角动量（OAM）状态如何影响电子的透射性，并与现有的自旋相关机制进行比较。

Method: 在三维空间中模拟电子在手性静电势中的传输，分析电子的OAM动力学、线性动量耦合、以及手性势反转、手性区域长度、静电无序和初始自旋-OAM相关性对传输行为的影响。

Result: 电子传输表现出显著的对映选择性，与电子的初始OAM状态和手性势的旋向性有关。轨道选择性随手性区域长度的增加而增强，且对静电无序具有鲁棒性。当初始OAM和自旋状态存在相关性时，轨道选择性可导致自旋选择性。

Conclusion: 轨道角动量在手性系统中的电子传输中起着重要作用，CIOS效应与现有的基于自旋的机制协同作用，是理解和利用手性电子传输特性的关键。

Abstract: This work investigates electron transport through chiral electrostatic
potentials by modeling the system in three spatial dimensions and demonstrates
that chirality-induced orbital selectivity (CIOS) produces pronounced
enantiospecific transmission, dependent on the electron's initial orbital
angular momentum (OAM) state. The results show that transverse electron motion
in a chiral environment, captured by OAM dynamics, gives rise to strong orbital
selectivity that reverses upon inversion of the handedness of the chiral
potential. This behavior originates from a coupling between the electron's
linear and orbital angular momenta, leading to effects that are significantly
stronger than those arising from spin-phonon and bare spin-orbit interactions
under realistic physical conditions. Moreover, the CIOS effect is shown to
increase with the length of the chiral region and remains robust against static
disorder. The orbital selectivity can give rise to spin selectivity when
initial correlations exist between spin and OAM states. These findings
underscore the importance of orbital contributions to enantiospecific electron
transport in chiral systems and suggest that CIOS plays a critical role
alongside existing spin-based mechanisms.

</details>


### [279] [Efficient Generation of Second-Harmonic Propagating Spin Waves in a Thin, Out-of-Plane-Magnetized Ferromagnetic Film](https://arxiv.org/abs/2509.07705)
*Mathieu Moalic,Youenn Patat,Mateusz Zelent,Maciej Krawczyk*

Main category: cond-mat.mes-hall

TL;DR: 利用混合铁磁纳米结构，通过泵浦场的二次谐波有效激发和调谐短波长、高频自旋波，用于人工智能神经网络。


<details>
  <summary>Details</summary>
Motivation: 实现短波长、高频自旋波的高效激发以及利用非线性效应仍然是一个挑战。

Method: 提出一种混合铁磁纳米结构，由小尺寸、面内磁化的边缘（磁子学纳米腔）和垂直磁化的区域组成，通过微磁模拟展示了如何用均匀的微波场激发边缘模式，并通过二次谐波将其发射到第二个区域，从而产生传播的自旋波。

Result: 该方法在条状或盘状几何结构中均可实现，可分别激发平面波或径向自旋波。转换效率随泵浦场幅度的增长而非线性增长，并且可以通过匹配纳米腔的高阶驻波频率与二次谐波频率来进一步提高。发射频率可通过偏置磁场或纳米腔宽度进行调谐。

Conclusion: 所提出的混合铁磁纳米结构为在芯片上实现短波长、高频自旋波源提供了一种紧凑的途径，可用于人工智能神经网络。

Abstract: Spin waves are attractive information carriers owing to their
gigahertz-to-terahertz frequencies, nanometric wavelengths, and negligible
Joule heating. Yet the efficient excitation of short-wavelength, high-frequency
spin waves and the exploitation of nonlinear effects remain challenging. We
propose a hybrid ferromagnetic nanostructure composed of a small,
in-plane-magnetized rim (a magnonic nanocavity) exchange-coupled to an
out-of-plane-magnetized region. Micromagnetic simulations show that a spatially
uniform out-of-plane microwave field excites the rim's fundamental mode; its
second harmonic is then coherently and efficiently launched into the second
region of the structure, yielding propagating spin waves. The process can be
realized in strip or disk geometries, providing excitation of plane-wave or
radial spin waves, respectively. The conversion efficiency grows nonlinearly
with the pump amplitude and can be further improved when the frequency of a
higher-order standing wave in the nanocavity matches the second-harmonic
frequency. The emission frequency is tunable via the bias magnetic field or the
width of the nanocavity, suggesting a compact route toward on-chip,
short-wavelength, high-frequency spin-wave sources for artificial neural
networks.

</details>


### [280] [Phonon-Limited Mobility in H/F-functionalized Nanotubes with 1D $π$-chains](https://arxiv.org/abs/2509.07714)
*V. L. Katkov,V. A. Osipov*

Main category: cond-mat.mes-hall

TL;DR: 电子-声子相互作用引起的电子迁移率在完全氟化/氢化之字形碳纳米管中进行了研究，这些碳纳米管包含具有π键的一维交替碳原子链。揭示了迁移率随管径、涂层类型（F/H）和温度变化的规律。特别是，证明了迁移率对直径的依赖性与手性指数呈周期性关系，这与镜面对称性导致偶数导电链管中不存在对TA声子的散射有关。获得的声子限制迁移率的小值表明，具有一维导电链的管子作为气体传感器的前景比作为电子器件元件更有前景。计算是在非正交紧束缚方法中，在自能弛豫时间近似（SERTA）的框架内进行的。


<details>
  <summary>Details</summary>
Motivation: 研究电子-声子相互作用对全氟化/氢化之字形碳纳米管电子迁移率的影响，以及管径、涂层类型和温度对其行为的影响。

Method: 使用非正交紧束缚方法和自能弛豫时间近似（SERTA）进行计算。

Result: 电子迁移率随管径、涂层类型和温度的变化规律被揭示。迁移率对直径的依赖性与手性指数呈周期性关系，偶数导电链管中不存在对TA声子的散射。声子限制迁移率值较小。

Conclusion: 具有一维导电链的碳纳米管作为气体传感器的应用前景优于电子器件。

Abstract: Electron mobility due to electron-phonon interaction is investigated for
fully fluorinated/hydrogenated zig-zag carbon nanotubes containing
one-dimensional alternating chains of carbon atoms with $\pi$-bonds. The
behavior of mobility associated with changes in the tube diameter, coating type
(F/H) and temperature is revealed. In particular, it is shown that the
dependence of mobility on the diameter in such tubes is periodic with the
chirality index, which is associated with the absence of scattering on TA
phonons in the tubes with an even number of conducting chains due to mirror
symmetry. The obtained small values of phonon-limited mobility indicate that
tubes with one-dimensional conducting chains are more promising for use as gas
sensors than as elements of electronic devices. Calculations are performed
within the self-energy relaxation time approximation (SERTA) using the
non-orthogonal tight-binding approach.

</details>


### [281] [Quantum Transport Reservoir Computing](https://arxiv.org/abs/2509.07778)
*Yecheng Jing,Pengfei Wang,Shuai Zhang,Zhoujie Zeng,Shi-Jun Liang,Wei Chen*

Main category: cond-mat.mes-hall

TL;DR: 我们提出通过介观电子系统中的量子输运来实现量子循环神经网络（RC），并在语音识别和时间序列预测任务上进行了数值验证。


<details>
  <summary>Details</summary>
Motivation: 量子循环神经网络（RC）在处理时间序列数据方面具有潜力，但面临物理实现、输出读出和测量反馈等挑战。本研究旨在克服这些挑战，并探索其在量子物理和量子技术中的应用。

Method: 利用介观电子系统中的量子输运来实现量子RC，并利用通用电导涨落进行数值模拟。

Result: 在语音识别和时间序列预测两个基准任务上成功验证了该方法的有效性。

Conclusion: 通过量子输运实现量子RC为片上量子计算提供了一种新颖的途径，并扩展了介观物理学的应用范围。

Abstract: Reservoir computing (RC), a neural network designed for temporal data,
enables efficient computation with low-cost training and direct physical
implementation. Recently, quantum RC has opened new possibilities for
conventional RC and introduced novel ideas to tackle open problems in quantum
physics and advance quantum technologies. Despite its promise, it faces
challenges, including physical realization, output readout, and
measurement-induced back-action. Here, we propose to implement quantum RC
through quantum transport in mesoscopic electronic systems. Our approach
possesses several advantages: compatibility with existing device fabrication
techniques, ease of output measurement, and robustness against measurement
back-action. Leveraging universal conductance fluctuations, we numerically
demonstrate two benchmark tasks, spoken-digit recognition and time-series
forecasting, to validate our proposal. This work establishes a novel pathway
for implementing on-chip quantum RC via quantum transport and expands the
mesoscopic physics applications.

</details>


### [282] [Valley Order in Moiré Topological Insulators](https://arxiv.org/abs/2509.07784)
*Bo Zou,Anzhuoer Li,Allan H. MacDonald*

Main category: cond-mat.mes-hall

TL;DR: Moiré materials with opposite Chern numbers can host novel interaction-induced insulating states at $
u=1$, including a superconducting vortex-lattice and a gapped state with broken parity symmetry, potentially related to the fractional quantum spin Hall effect.


<details>
  <summary>Details</summary>
Motivation: To explore the possibility of intervalley coherence in interaction-induced insulators at band filling $
u=1$ in moir'e materials, using Landau levels with opposite magnetic fields as a model.

Method: Utilizing Landau levels with opposite magnetic field signs as a generic model. Analyzing the mean-field ground state at $
u=1$ in the absence of intravalley interactions and observing the effects of increasing the ratio of intravalley to intervalley interactions ($\lambda$).

Result: In the absence of intravalley interactions, the ground state is a gapless intervalley coherent state. As $\lambda$ increases, gapped states emerge: one breaks time-reversal symmetry with a quantized Hall effect, and another breaks parity symmetry with zero Hall conductivity.

Conclusion: The parity-broken state at $\nu=1$ might be connected to the fractional quantum spin Hall effect observed in moir'e topological insulators. Correlations in bands with opposite Chern numbers are highlighted as potentially crucial in related systems.

Abstract: Moir\'e materials with opposite non-zero miniband Chern numbers in
time-reversal-partner valleys are two-dimensional topological insulators at
band filling $\nu=2$. We explore the possibility that in this class of moir'e
materials intervalley coherence can sometimes be present in interaction induced
insulators at band filling $\nu=1$ , using Landau levels with opposite signs of
the magnetic field as a convenient generic model. In the absence of intravalley
interactions the mean-field ground state at filling factor $\nu=1$ is a gapless
intervalley coherent state that maps under a particle-hole transformation of
one valley to a strong-field superconducting vortex-lattice state that has been
studied previously. When the ratio $\lambda$ of intravalley to intervalley
interactions is increased, gapped states appear, one with broken time-reversal
symmetry and a quantized Hall effect but no valley polarization and one with
broken parity symmetry and zero Hall conductivity. We discuss the possibility
that the latter state could be related to the fractional quantum spin Hall
effect recently observed at an odd filling factor in a moir'e topological
insulator and comment on related systems in which correlations between
electrons in bands with opposite Chern numbers might play a key role.

</details>


### [283] [Physical origin of current-induced switching angle shift in magnetic heterostructures](https://arxiv.org/abs/2509.07844)
*Xiaomiao Yin,Guanglei Han,Guowen Gong,Jun Kang,Changmin Xiong,Lijun Zhu*

Main category: cond-mat.mes-hall

TL;DR: 在铁磁/重金属异质结构中，基于开关角度偏移的自旋轨道力矩（SOT）评估被证明是不可靠的，因为它高估了SOT。


<details>
  <summary>Details</summary>
Motivation: 准确量化自旋轨道力矩（SOT）对于识别和应用新的自旋轨道电子学效应至关重要。

Method: 研究人员声称，开关角度偏移技术，即在旋转磁场下，通过畴壁钉扎解除和反畴扩展，线性比例地移动垂直磁化的开关角度，已被证明是评估SOT的常用技术。然而，作者认为这种技术对于铁磁/重金属异质结构中的SOT量化是不可靠的。

Result: 该研究证明，对于FeCoB、Co和Co/Ni多层膜等常用的垂直磁化异质结构，开关角度偏移严重高估了SOT。通过实验和模拟，作者发现开关角度偏移很可能主要由手性不对称成核而不是反畴扩展引起。施加的平面磁场和SOT降低了垂直成核场，从而降低了所需的开关角度，导致畴壁钉扎分析低估了SOT。

Conclusion: 这项研究揭示了开关角度偏移方法在评估SOT时存在系统性误差，并提出了新的见解，有助于更准确地理解和应用SOT。

Abstract: Accurate quantification of the spin-orbit torques (SOTs) is critical for the
identification and applications of new spin-orbitronic effects. One of the most
popular techniques to qualify the SOTs is the switching angle shift, where the
applied direct current was assumed to shift, via domain wall depinning during
the anti-domain expansion, the switching angle of a perpendicular magnetization
in a linear proportion manner under a large rotating magnetic field. Here, we
report that, for the most commonly employed perpendicular magnetization
heterostructures in spintronics (e.g., those based on FeCoB, Co, and Co/Ni
multilayers), the switching angle shift considerably misestimates the SOT
within the domain wall depinning analysis of the slope of the linear-in-current
scaling and may also have a non-zero residual value at zero direct current. Our
experiments and simulations unveil that the switching angle shift is most
likely dominated by the chiral asymmetric nucleation rather than the expansion
of the anti-domains. The in-plane field from external magnet and
current-induced SOTs lower the perpendicular nucleation field and thus the
required switching angle, ultimately leading to underestimation of the SOTs by
the domain wall depinning analysis. These results have advanced the
understanding of magnetization switching of spintronic devices.

</details>


### [284] [Hong-Ou-Mandel interferometry for fractional excitations: Unified framework and dip width scaling](https://arxiv.org/abs/2509.07875)
*Aleksander Latyshev,Imen Taktak,Ipsita Mandal,Ines Safi*

Main category: cond-mat.mes-hall

TL;DR: 通过结合非平衡玻色化边缘理论(NEBET)和统一非平衡微扰理论(UNEPT)，我们为量子霍尔系统中的时间分辨HOM干涉提供了一个通用理论，并分析了HOM峰宽的决定因素。


<details>
  <summary>Details</summary>
Motivation: 将HOM干涉扩展到FQHE以直接获取任意子统计，但面临整数电荷激发阻碍了任意子注入以及缺乏一致的理论框架的挑战。

Method: 结合NEBET和UNEPT，推导了适用于空间扩展的隧穿算子和通用的二次边缘动力学的交叉相关性关系。在Tomonaga-Luttinger液体(TLL)框架下，分析了携带整数和分数电荷的注入脉冲的HOM峰宽。

Result: HOM峰宽受脉冲宽度和分数电荷的非平凡幂律标度维数控制。

Conclusion: 为解释任意子统计和量子霍尔体系电子干涉的近期实验提供了一个稳健的理论基础。

Abstract: Extending Hong--Ou--Mandel (HOM) interferometry to the fractional quantum
Hall effect (FQHE) promises direct access to anyonic statistics, yet remains
challenging: on-demand anyon injection is hindered by integer-charged minimal
excitations, and recent HOM experiments in the FQHE lack a fully consistent
theoretical framework. Here we provide a general theory of time-resolved HOM
interferometry in quantum Hall systems. Combining the nonequilibrium bosonized
edge theory (NEBET) with the unifying non-equilibrium perturbative theory
(UNEPT), we derive exact and perturbative relations obeyed by the relevant
cross-correlations of chiral currents valid for spatially extended tunneling
operators and generic quadratic edge dynamics. Then, within the
Tomonaga--Luttinger liquid (TLL) framework, we analyze the width of the HOM dip
for injected pulses carrying integer and fractional charges. We show that it is
governed by the width of the pulses and, for the fractional charge, by a
non-trivial power-law behavior of the scaling dimension. Our results establish
a robust theoretical foundation for interpreting recent experiments on anyonic
statistics and electronic interferometry in the quantum Hall regime.

</details>


### [285] [Linking thermodynamic correlation signatures and superconductivity in twisted trilayer graphene](https://arxiv.org/abs/2509.07977)
*Jesse C. Hoke,Yifan Li,Yuwen Hu,Julian May-Mann,Kenji Watanabe,Takashi Taniguchi,Trithep Devakul,Aaron Sharpe,Benjamin E. Feldman*

Main category: cond-mat.mes-hall

TL;DR: 扭曲的石墨烯多层结构表现出强烈的电子相关性，但这些信号与微观基态的关系以及扭转角和能带结构如何重塑它们仍然知之甚少。本研究通过在具有不等角度和平坦电子能带的扭曲三层石墨烯（TTG）样品中关联局部热力学和输运测量来研究这种相互作用。研究人员使用扫描单电子晶体管来研究电子-电子相互作用在局部扭转角平滑变化的区域中的影响。他们观察到有隙的相关绝缘体和电子可压缩性的锯齿形，两者都表现出明显的电子-空穴（e-h）不对称性，并且具有不同的导带和价带魔角。随后的同一区域的输运测量揭示了具有相似e-h不对称性的稳健超导性。研究表明，超导性与相关绝缘体没有直接关系，但其临界温度与可压缩性中的锯齿形强度密切相关，表明两者之间存在共同的起源或联系。通过将局部探测与输运测量相结合，研究揭示了超导性与热力学相关性信号之间的联系，这些联系单独来看并不明显，突出了该双重方法的强大功能，并确定了它们在TTG中对层间扭转角的依赖性。


<details>
  <summary>Details</summary>
Motivation: 探索扭曲三层石墨烯（TTG）中电子相关性信号、超导性与扭转角和能带结构之间的相互作用。

Method: 使用扫描单电子晶体管进行局部热力学测量，并结合同一区域的输运测量。

Result: 观察到有隙的相关绝缘体和电子可压缩性的锯齿形，均表现出显著的电子-空穴（e-h）不对称性。同时发现稳健的超导性，其临界温度与可压缩性中的锯齿形强度相关，而非直接与相关绝缘体相关。

Conclusion: 超导性和热力学相关性信号之间存在联系，这种联系单独来看并不明显，并且依赖于TTG中的层间扭转角。该研究强调了结合局部探测和输运测量的双重方法的有效性。

Abstract: Twisted graphene multilayers exhibit strong electronic correlations, which
manifest in a range of experimental signatures. Yet how these signatures relate
to each other and the microscopic ground states-and how twist angle and band
structure reshape them-remains poorly understood. Here we study this interplay
by correlating local thermodynamic and transport measurements in a twisted
trilayer graphene (TTG) sample with unequal angles and flat electronic bands.
We use a scanning single-electron transistor to map the impact of
electron-electron interactions in a region of the sample where the local twist
angle evolves smoothly. We observe gapped correlated insulators and a sawtooth
in electronic compressibility, both exhibiting pronounced electron-hole (e-h)
asymmetry with distinct magic angles for conduction and valence bands.
Subsequent transport measurements in the same region reveal robust
superconductivity with a similar e-h asymmetry. Our measurements indicate that
superconductivity is not directly tied to the correlated insulators. Instead,
its critical temperature correlates closely with the strength of the sawtooth
in compressibility, suggesting a common origin or link between the two. By
combining a local probe with transport measurements, we uncover connections
between superconductivity and thermodynamic correlation signatures that are not
apparent from either technique in isolation, highlighting the power of our dual
approach and establishing their dependence on interlayer twist angles in TTG.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [286] [Multistable Curved-Crease Origami Blocks for Reconfigurable Modular Building System](https://arxiv.org/abs/2509.07337)
*Munkyun Lee,Joseph M. Gattas,Tomohiro Tachi*

Main category: physics.app-ph

TL;DR: 提出了一种可重构的模块化建筑系统，该系统组装了多稳态弯曲折纸块。


<details>
  <summary>Details</summary>
Motivation: 设计具有多稳态特性的弯曲折纸模块，并探索其在建筑应用中的灵活性和适应性。

Method: 设计了具有偶数顶点多边形轨迹和弹性体曲率的弯曲折纸；通过连接匹配的末端来赋予多稳态特性；使用有限元分析研究了模块的弹出和承载行为；设计了多层和准连续墙面的模块组装；引入张力绳以实现多重配置。

Result: 成功设计了各种模块，并研究了它们的弹出和承载行为；设计了多层和准连续墙面组装；制造了桌面和大型原型；通过引入张力绳实现了模块的多重配置。

Conclusion: 所提出的可重构模块化建筑系统能够实现具有多稳态特性的弯曲折纸块的组装，并展示了其在建筑应用中的灵活性和适应性。

Abstract: This study proposes a reconfigurable modular building system that assembles
multistable curved-crease origami blocks. Curved-crease origami is designed
with even-vertex polygonal trajectories and an elastica curvature profile. We
then connect the matching ends to impart multistability. Through this design
approach, we create various blocks and investigate their snapping and
load-bearing behavior using finite element analysis. We design block assemblies
of multi-story and quasi-continuous wall surfaces and fabricate a series of
desktop and large-scale prototypes to demonstrate the flexibility and
adaptability of our system for architectural use. Furthermore, by introducing a
tension cable to the assembly, the assembled modules can be snapped into
multiple configurations.

</details>


### [287] [Membrane phononic integrated circuits](https://arxiv.org/abs/2509.07547)
*Timothy M. F. Hirsch,Nicolas P. Mauranyapin,Erick Romero,Glen Harris,Xiaoya Jin,Nishta Arora,Warwick P. Bowen,Christopher G. Baker*

Main category: physics.app-ph

TL;DR: 基于高拉伸应力膜的声子电路具有高声学限制、可控非线性、低质量、占地面积小和易于制造等优点。本教程提出了一种系统化的方法来模拟和设计该平台上的声子集成电路，包括声学限制、波传播和色散、机械和驱动非线性以及谐振器动力学。通过将光电子学的耦合模式理论应用于悬浮膜，并使用几种数值技术（有限元建模、时域有限差分模拟和转移矩阵法）进行验证，我们提供了一个全面的框架来设计各种声子电路构建块。作为说明性示例，我们描述了基于倏逝隧道势垒的几种声学电路元件的实现，包括谐振和非谐振可变比例功率分配器、模式转换器、模式（解）复用器和串联法布里-珀罗腔。这些构建块为声子集成电路奠定了基础，声子集成电路在传感、声信号处理以及节能和抗辐射计算方面具有应用前景。


<details>
  <summary>Details</summary>
Motivation: 高拉伸应力膜声子电路具有高声学限制、可控非线性、低质量、占地面积小和易于制造等优点。

Method: 采用耦合模式理论，并使用有限元建模、时域有限差分模拟和转移矩阵法进行验证，以模拟和设计声子集成电路。

Result: 成功设计并实现了一系列声学电路元件，包括谐振和非谐振可变比例功率分配器、模式转换器、模式（解）复用器和串联法布里-珀罗腔。

Conclusion: 这些构建块为声子集成电路奠定了基础，声子集成电路在传感、声信号处理以及节能和抗辐射计算方面具有应用前景。

Abstract: Phononic circuits constructed from high tensile stress membranes offer a
range of desirable features such as high acoustic confinement, controllable
nonlinearities, low mass, compact footprint, and ease of fabrication. This
tutorial presents a systematic approach to modelling and designing phononic
integrated circuits on this platform, beginning with acoustic confinement, wave
propagation and dispersion, mechanical and actuation nonlinearities, as well as
resonator dynamics. By adapting coupled mode theory from optoelectronics to
suspended membranes, and validating this theory with several numerical
techniques (finite element modelling, finite difference time domain
simulations, and the transfer matrix method), we then provide a comprehensive
framework to engineer a broad variety of phononic circuit building blocks. As
illustrative examples, we describe the implementation of several acoustic
circuit elements including resonant and non-resonant variable-ratio power
splitters, mode converters, mode (de)multiplexers, and in-line Fabry-Perot
cavities based on evanescent tunnel barriers. These building blocks lay the
foundation for phononic integrated circuits with applications in sensing,
acoustic signal processing, and power-efficient and radiation-hard computing.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [288] [Record High Polarization at 2V and Imprint-free operation in Superlattice HfO2-ZrO2 by Proper Tuning of Ferro and Antiferroelectricity](https://arxiv.org/abs/2509.07045)
*Xinye Li,Sayani Majumdar*

Main category: cond-mat.mtrl-sci

TL;DR: 基于HfO2-ZrO2(HZO)超晶格电容器的铁电材料在神经拟态计算中实现了低压、高能效的突触器件，并表现出优异的线性调性和耐久性。


<details>
  <summary>Details</summary>
Motivation: 为了在神经拟态计算中实现低压、高能效的人工突触，需要解决铁电材料在CMOS兼容器件中低压运行的挑战。

Method: 通过调整HfO2-ZrO2(HZO)超晶格电容器中的铁电和反铁电相，实现了无印迹切换，并表征了其开关极化、线性调性、以及在脉冲操作下的耐久性，同时阐明了两种不同的疲劳机制。

Result: 实现了在2 MV cm-1外加电场下，具有76微库仑/平方厘米记录开关极化（2Pr）的无印迹切换。超晶格HZO的显著剩余极化在3 MV cm-1偏置窗口内实现了20的开/关比下的线性调强和调降。在脉冲操作下，器件表现出高达10^8次循环仍能保持极化（<10%退化）或在超过10^9次循环后仍可恢复疲劳的优异耐久性。

Conclusion: 通过优化铁电材料的铁电和反铁电相，可以实现满足神经拟态训练应用严苛要求的CMOS兼容铁电突触器件，并提出了两种疲劳机制以指导器件优化。

Abstract: Neuromorphic computing, inspired by biological intelligence, offers a pathway
to revolutionize artificial intelligence (AI) by unifying memory and processing
in an energy-efficient, sustainable framework for data-intensive tasks.
Ferroelectric (FE) materials have emerged as promising candidates for
implementing artificial synapses, yet achieving low-voltage operation in CMOS
back-end compatible devices remains a major challenge. In this work, we
demonstrate that proper tuning of ferro and antiferroelectric phases in
HfO2-ZrO2(HZO) superlattice based capacitors can lead to imprint-free switching
with record switchable polarization (2Pr) of 76 micro Coulomb cm-2 under an
external field of only 2 MV cm-1. The sizable remanent polarization of the
superlattice HZO further enables linear potentiation and depression with an on
to off ratio of 20 within a 3 MV cm-1 bias window. Under pulsed operation, the
devices show robust endurance, either maintaining polarization with less than
10 per cent degradation up to 10^8 cycles or surviving beyond 10^9 cycles with
recoverable fatigue. By elucidating two distinct fatigue mechanisms, this work
highlights strategies for optimizing FE devices to meet the stringent demands
of neuromorphic training applications.

</details>


### [289] [3D Mapping of Defects and Moiré Corrugations via Electron Ptychography Atomic Coordinate Retrieval](https://arxiv.org/abs/2509.07140)
*Jeffrey Huang,Yichao Zhang,Sang hyun Bae,Ballal Ahammed,Elif Ertekin,Pinshane Y. Huang*

Main category: cond-mat.mtrl-sci

TL;DR: 通过单取向多层电子衍射成像技术，首次实现了扭曲双层Tungsten Diselenide（WSe2）的三维原子结构可视化，精确到皮米级别。


<details>
  <summary>Details</summary>
Motivation: 实验上难以精确测量二维材料中的缺陷和形变对电子性质的影响，需要新的成像技术来解决此问题。

Method: 采用多层电子衍射（MEP）技术，在单个取向下收集数据，结合算法精确重建了扭曲双层WSe2的三维原子坐标。

Result: 成功可视化了WSe2的六个原子层，揭示了层曲率、层间距变化以及仅存在于外硒原子层的空位的三维位置。观察到了一种新的混合弯曲-呼吸型莫尔图案形变。

Conclusion: 该方法能在约30秒内从原子层面构建二维材料的三维模型，有望实现对二维材料三维原子信息的常规获取，并推动可控形变的材料设计。

Abstract: Defects and reconstructions in 2D moir\'e materials cause out-of-plane
deformations which strongly modify their electronic properties but are
difficult to experimentally access. Here, we solve the 3D atomic coordinates of
twisted bilayer WSe$_2$ with picometer-scale accuracy using multislice electron
ptychography (MEP) acquired from a single orientation. The resulting atomic
models individually visualize each of the six atomic planes, revealing the
curvature of each WSe$_2$ layer, variations in the interlayer spacing, and the
3D locations of individual vacancies -- which lie exclusively in the outer Se
planes. We also observe a new, unexpected type of structural disorder
consisting of mixed bending -- and breathing-type moir\'e-induced corrugations
that should strongly impact the emergent electronic properties. Broadly, our
methods generate 3D atom-by-atom models of a 2D heterointerface from data
acquired in about 30 seconds, methods that should unlock routine access to 3D
atomic information in 2D systems and catalyze design methods to control
out-of-plane deformations.

</details>


### [290] [Computational and Experimental Investigation of Chiral and Achiral 2D Organic Lead Bromide Perovskites: Octahedral Distortions and Electronic and Optical Properties](https://arxiv.org/abs/2509.07152)
*Md Mehdi Masud,Jarek Viera,Azza Ben-Akacha,Biwu Ma,David A. Strubbe*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究计算并实验研究了二维有机卤化铅钙钛矿的结构、电子和光学性质，重点对比了手性(R/S)-4-氟-α-甲基苄基铵(R/S-FMBA)和非手性4-氟苄基铵(FBA)基材料。


<details>
  <summary>Details</summary>
Motivation: 研究手性(R/S)-FMBA基钙钛矿与非手性FBA基钙钛矿的结构、电子和光学性质的差异，以理解其手性发光特性。

Method: 使用密度泛函理论(DFT)结合范德华(vdW)校正，计算了材料的结构（与X射线衍射XRD对比）、光学吸收光谱（与实验对比）、能带结构和轨道特征。开发了用于计算八面体畸变的Python代码。

Result: DFT计算结果与XRD和实验数据吻合良好，表明vdW校正对于精确计算很重要。DFT计算结果高估了八面体倾斜角度。手性(FMBA)$_2$PbBr$_4$材料表现出显著的(14°)八面体倾斜角度差($eta$)，表明其具有强烈的反转对称性破缺，从而能够实现手性发光。最低能量的光学跃迁仅涉及钙钛矿层，并且在层内偏振。

Conclusion: 该研究深入理解了二维有机卤化铅钙钛矿的结构-性质关系，特别是手性材料的反转对称性破缺对其光学性质的影响，为光电子和自旋电子学应用提供了基础。

Abstract: We present a computational investigation, in conjunction with synthesis and
experimental characterization, into the structural, electronic, and optical
properties of layered 2D organic lead bromide perovskites. We contrast
materials based on the chiral (R/S)-4-fluoro-$\alpha$-methylbenzylammonium
(R/S-FMBA), which have been shown to lead to bright room-temperature circularly
polarized luminescence, with the similar achiral 4-fluorobenzylammonium (FBA).
Using density functional theory (DFT) with van der Waals (vdW) corrections, we
study relaxed structures (compared with X-ray diffraction, XRD) and optical
absorption spectra (compared with experiments), as well as bandstructure and
orbital character of transitions. We develop and provide a Python code to
calculate octahedral distortions and compare DFT and XRD results, finding that
vdW corrections are important for accuracy and that DFT overestimates
octahedral tilt angles. (FMBA)$_2$PbBr$_4$ shows among the largest tilt angle
differences (often termed $\Delta \beta$) reported, $14^\circ$, indicating
strong inversion symmetry-breaking which enables its chiral emission. The
lowest-energy optical transitions involve the perovskite only and are polarized
within the layer. This work furthers understanding of structure-property
relations with applications to optoelectronics and spintronics.

</details>


### [291] [Ultrathin oxide freestanding membranes with large-scale continuity and structural perfection](https://arxiv.org/abs/2509.07176)
*Yuhao Hong,Yang Hu,Jianyao Zheng,Minh D. Nguyen,Jelle R. H. Ruiters,Daniel M. Cunha,Iris C. G. van den Bosch,Edwin Dollekamp,Mark Huijben,Yulin Gan,Nini Pryds,Daesung Park,Christoph Baeumer,Qinghua Zhang,Guus Rijnders,Zhaoliang Liao,Gertjan Koster*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究提出了一种基于水溶性牺牲层（Sr4Al2O7）的氧化物薄膜制备新方法，实现了厘米级大面积、无裂痕、无褶皱的氧化物薄膜。


<details>
  <summary>Details</summary>
Motivation: 为了将复杂的氧化物基础研究成果应用于实际器件，需要实现氧化物薄膜的可扩展制造，以满足柔性电子、硅基自旋电子学、神经形态计算和高性能能源技术等领域的需求。然而，目前制备的无裂痕、无褶皱的氧化物薄膜横向尺寸仅限于毫米级，这成为大面积器件制造的关键瓶颈。

Method: 使用超四方相的Sr4Al2O7作为水溶性牺牲层，通过水辅助剥离技术制备氧化物薄膜。

Result: 成功制备了厘米级大面积、无裂痕、无褶皱的超薄氧化物（SrRuO3）薄膜。然而，牺牲层的溶解在SrRuO3薄膜中引入了氧空位，扩散深度达六个单胞，导致了反常的“上-下”传输行为。后退火虽然可以消除氧空位，但所需温度与CMOS工艺不兼容。

Conclusion: 尽管该方法能够制备大面积的氧化物薄膜，但由于水辅助剥离引入的氧空位问题，对于集成到小型硅基氧化物器件中仍面临严峻挑战。

Abstract: Freestanding oxide membranes offer integration with advanced semiconductor
platforms, unlocking opportunities for flexible electronics, silicon-based
spintronics, neuromorphic computing, and high-performance energy technologies.
Scalable fabrication of such membranes is essential for bridging fundamental
discoveries in complex oxides with practical device deployment. However, the
lateral dimensions of crack- and wrinkle-free membranes remain limited to
millimeter scales, forming a critical bottleneck for large-area architectures.
Overcoming this challenge demands strategies that preserve crystalline quality
while suppressing defect transfer during release. Here, we demonstrate an
approach based on a water-soluble sacrificial layer of super-tetragonal
Sr4Al2O7, enabling the fabrication of ultrathin, crack-free, and wrinkle-free
free-standing oxide membranes spanning centimeter-scale areas. This method is
broadly applicable to a wide range of oxides and establishes a new pathway
toward large-scale silicon integration and flexible oxide technologies.
Nevertheless, dissolution of the sacrificial layer introduces oxygen vacancies
into the SrRuO3 membranes, with diffusion depths reaching six unit cells,
leading to anomalous "up-and-down" transport behavior. Although post-annealing
can eliminate these vacancies, the required temperatures are incompatible with
CMOS processes. Therefore, ultrathin freestanding membranes fabricated by
water-assisted lift-off still face critical challenges for integration into
miniaturized silicon-based oxide devices.

</details>


### [292] [Effective Atom Theory: Gradient-Driven ab initio Materials Design](https://arxiv.org/abs/2509.07180)
*Justin Tahmassebpur,Brandon Li,Boris Barron,Héctor Abruña,Peter Frazier,Tomás Arias*

Main category: cond-mat.mtrl-sci

TL;DR: Effective Atom Theory (EAT)将材料设计转化为平滑的、由密度泛函理论(DFT)驱动的优化过程，通过将原子表示为元素的概率混合物，大大减少了优化所需能量评估的次数，并成功应用于Co-Cr-Ni-V氧化物碱性析氧反应(OER)的设计。


<details>
  <summary>Details</summary>
Motivation: 将组合材料设计转化为平滑的、由密度泛函理论(DFT)驱动的优化过程，并大大减少优化所需能量评估的次数。

Method: 将原子表示为元素的概率混合物，使梯度优化器能够收敛到物理上可实现的材料，仅需约50次能量评估。

Result: 将EAT应用于Co-Cr-Ni-V氧化物碱性析氧反应(OER)，最终推荐组成为Co0.19Cr0.06V0.31Ni0.44O。

Conclusion: EAT框架能够有效地将组合材料设计转化为平滑的、由梯度驱动的优化过程，并在OER催化剂设计中取得了成功。

Abstract: We introduce Effective Atom Theory (EAT), a framework that transforms
combinatorial materials design into a smooth, gradient-driven optimization
within density functional theory (DFT). Atoms are represented as probabilistic
mixtures of elements, enabling gradient-based optimizers to converge to a
physically realizable material in about 50 energy evaluations -- far fewer than
combinatorial optimization methods. Applied to Co-Cr-Ni-V oxides for the
alkaline oxygen evolution reaction (OER), EAT leads to a final recommended
composition of Co0.19Cr0.06V0.31Ni0.44O.

</details>


### [293] [Innovative Oxide Transistor Satisfying Performance and Reliability Simultaneously by Understanding of Physics and Materials Properties](https://arxiv.org/abs/2509.07886)
*C. W. Cheng,J. Smith,P. Solomon,R. Watters,D. Piatek,C. Lavoie,M. Hopstaken,L. Gignac,D. Bishop,B. Khan,M. BrightSky,G. Gionta,P. Hashemi,V. Narayanan,M. M. Frank*

Main category: cond-mat.mtrl-sci

TL;DR: 我们提出了一种新的10nm氧化物半导体晶体管结构和工艺流程，在性能和可靠性方面均优于传统的IGZO晶体管。


<details>
  <summary>Details</summary>
Motivation: 打破传统IGZO晶体管中观察到的性能和可靠性之间的约束。

Method: 通过对积累模式晶体管物理和氧化物半导体材料特性进行全面分析，演示了一种创新的氧化物半导体晶体管结构和工艺流程。

Result: 新提出的10nm IGZO晶体管具有高开启电流、高外在迁移率（20 cm2V-1s-1）、近零迟滞现象，并且在室温下经过3 MV/cm的PBS测试1000秒后，Vt仅偏移15 mV。

Conclusion: 我们成功开发了一种创新的氧化物半导体晶体管，在保持高性能的同时显著提高了可靠性。

Abstract: Guided by a comprehensive analysis of accumulation mode transistor physics
and oxide semiconductor materials properties, we demonstrate an innovative
oxide semiconductor transistor structure and process flow that break the
constraint between performance and reliability observed in conventional
InGaZnO4 (IGZO) transistors. The newly proposed 10 nm innovative IGZO
transistor features high on-current, high extrinsic mobility (20 cm2V-1s-1),
near-zero hysteresis, and only 15 mV Vt shift after positive-bias-stress (PBS)
of 3 MV/cm stress for 1000s at room temperature.

</details>


### [294] [Direct determination of antiferroelectric-to-ferroelectric phase transition pathways in PbZrO$_3$ with Operando Electron Microscopy](https://arxiv.org/abs/2509.07194)
*Menglin Zhu,Michael Xu,Louis Alaerts,Hao Pan,Colin Gilgenbach,Geoffroy Hautier,Lane W. Martin,James M. LeBeau*

Main category: cond-mat.mtrl-sci

TL;DR: 高电场下，非极性反铁电材料PbZrO3可转变为极性铁电相，但其机制尚不明确。本研究利用原位扫描透射电子显微镜电场加载技术，直接解析了PbZrO3薄膜中的反铁电-铁电转变途径，揭示了包含多个亚稳相的多步转变过程。。


<details>
  <summary>Details</summary>
Motivation: 虽然铁电材料在储能和机电应用方面有潜力，但控制其相变的原子尺度机制仍不清楚。

Method: 通过在高电场下使用操作型扫描透射电子显微镜，研究了PbZrO3薄膜中的反铁电-铁电转变。

Result: 研究发现转变过程包括多个亚稳相，并且转变途径和最终状态会受到影响，导致在衬底附近形成具有抑制开关行为的“死层”。在动态转变前沿，通过竞争的内部和外部场驱动，观察到了反铁电相和亚稳铁电相之间的动态相变。

Conclusion: 该研究强调了局部能量在相稳定性中的关键作用，并为场致相变提供了重要的实验见解，为设计基于反铁电体的器件提供了指导。

Abstract: Under a sufficiently high applied electric field, a non-polar
antiferroelectric material, such as \ce{PbZrO3}, can undergo a rapid
transformation to a polar ferroelectric phase. While this behavior is promising
for energy storage and electromechanical applications, a complete understanding
of the atomic-scale mechanisms governing the phase transition remain elusive.
Here, we employ \textit{operando} scanning transmission electron microscopy
electric field biasing to directly resolve the
antiferroelectric-to-ferroelectric transition pathway in \ce{PbZrO3} thin films
under device-relevant conditions. Atomic-resolution imaging reveals a
multi-step transition that includes several metastable phases. Complementary
nano-beam electron diffraction and atomic scale analysis further show that this
pathway and its end states can be modulated, leading to the formation of a
\quotes{dead layer} near the substrate with suppressed switching behavior.
Taking advantage of this depth-dependent heterogeneity, dynamic phase
transformations are observed between coexisting antiferroelectric and
metastable ferroelectric phases. At this dynamic transition front, repeated
phase interconversion is shown to be driven by competing internal (due to
substrate clamping and extended defects) and external fields, allowing the
relative energies of intermediate phases to be compared as a function of
electric field. This work highlights the critical role of local energetics in
phase stability and provides key experimental insights into field-induced phase
transitions, guiding the design of antiferroelectric-based devices.

</details>


### [295] [Grain Boundary Anisotropy and Its Influence on Helium Bubble Nucleation, Growth, and Decohesion in Polycrystalline Iron](https://arxiv.org/abs/2509.07197)
*Yang Zhang,Peter Hatton,Blas P. Uberuaga,Jason R. Trelewicz*

Main category: cond-mat.mtrl-sci

TL;DR: 本文利用加速分子动力学模拟和柔性体积（V_f）指标，研究了氦气泡在体心立方铁晶界（GBs）的演化行为，揭示了晶界特性、氦气团聚和气泡生长之间的关系，并提出了两种应力释放机制。


<details>
  <summary>Details</summary>
Motivation: 核反应堆结构材料在氦气泡聚集于晶界时会严重影响其机械完整性。理解晶界结构各向异性导致的复杂氦气泡演化行为至关重要。

Method: 本研究结合了加速分子动力学模拟和一种新的原子尺度度量——柔性体积（V_f），来研究晶界特性、氦气团聚和气泡生长机制之间的相互作用。

Result: 柔性体积（V_f）能够定性预测材料的变形倾向。研究结果表明，原子尺度的氦气团聚能量景观决定了初始氦气团簇和后续气泡的形貌。低能通道（如Σ5倾斜晶界）有利于一维迁移，而孤立的深能陷阱（如Σ13扭转晶界）则促进更大、更圆的气泡形貌。除了通过陷阱突变机制逐渐生长外，还发现了两种独特的应力释放机制：Σ5倾斜晶界中的形变钉扎和Σ11扭转晶界中的界面剥离，其主导途径取决于气泡形貌和局部力学软硬度之间的相互作用。

Conclusion: 本研究建立了晶界晶体学和能量各向异性与氦气泡演化之间的基本联系，为了设计耐辐射的微观结构提供了关键见解。

Abstract: The accumulation of helium bubbles at grain boundaries (GBs) critically
degrades the mechanical integrity of structural materials in nuclear reactors.
While GBs act as sinks for radiation-induced defects, their inherent structural
anisotropy leads to complex helium bubble evolution behaviors that remain
poorly understood. This work integrates accelerated molecular dynamics
simulations and a novel atomic-scale metric, the flexibility volume (V_f), to
establish the interplay between GB character, helium segregation, and bubble
growth mechanisms in body-centered cubic iron. We demonstrate that V_f, which
incorporates both local atomic volume and vibrational properties, qualitatively
predicts deformation propensity. Our results reveal that the atomic-scale
segregation energy landscape dictates initial helium clustering and subsequent
bubble morphology, with low-energy channels in tilt {\Sigma}5 boundary
facilitating one-dimensional migration while isolated deep traps in twist
{\Sigma}13 boundary promote larger, rounder bubble morphology. Critically,
besides gradual bubble growth via trap mutation mechanism, we identify two
distinct stress-relief mechanisms: loop punching in anisotropic tilt {\Sigma}5
boundary and interfacial decohesion in twist {\Sigma}11 boundary, with the
dominant pathway determined by the interplay between bubble morphology and
local mechanical softness. This study establishes a fundamental connection
between GB crystallographic and energetical anisotropy and helium bubble
evolution, providing critical insights for designing radiation-tolerant
microstructures.

</details>


### [296] [Structural Phase Transition in CeMnSi under Pressure and Comparative Structural Properties of $R$MnSi ($R$ = La, Ce, Pr, Nd)](https://arxiv.org/abs/2509.07210)
*Yukihiro Kawamura,Sae Nishiyama,Jun-ichi Hayashi,Keiki Takeda,Chihiro Sekine,Hiroshi Tanida*

Main category: cond-mat.mtrl-sci

TL;DR: CeMnSi在~5.7 GPa时发生结构相变，而其他RMnSi（R=La, Ce, Pr, Nd）在相同压力范围内未观察到结构相变。CeMnSi在接近相变压力时c/a比值急剧下降，且其体积模量较低，表明存在价态不稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究铁磁性材料RMnSi（R=La, Ce, Pr, Nd）在压力下的结构响应，特别是CeMnSi的结构相变及其与电子自由度的耦合。

Method: 使用粉末X射线衍射实验，在高达~10 GPa的压力下对四方CeFeSi型RMnSi（R = La, Ce, Pr, Nd）进行研究。

Result: 在CeMnSi中观察到约5.7 GPa的结构相变，而LaMnSi, PrMnSi, NdMnSi则未发生相变。CeMnSi的c/a比值随压力接近相变点急剧减小，体积模量较低（~41.4 GPa和~32.8 GPa），表明存在价态不稳定性。相变后，CeMnSi转变为单斜结构（空间群P21/m）。

Conclusion: CeMnSi独特的压力响应归因于c/a比值的减小和较低的体积模量，这揭示了铈基金属间化合物中晶格与电子自由度之间的耦合关系。

Abstract: Powder X-ray diffraction experiments under pressure up to $\sim$10 GPa were
performed on tetragonal CeFeSi-type $R$MnSi ($R$ = La, Ce, Pr, Nd). A
structural phase transition was observed in CeMnSi at a critical pressure of
$P_{\rm s}$ $\sim$ 5.7 GPa. In contrast, LaMnSi, PrMnSi, and NdMnSi do not
exhibit any structural transitions within the same pressure range. The lattice
parameter ratio $c/a$ of CeMnSi decreases rapidly as pressure approaches
$P_{\rm s}$, whereas the $c/a$ ratios of the other $R$MnSi increase
monotonically with pressure. CeMnSi also shows a relatively small bulk modulus:
$B_0$ $\sim$ 41.4(4) GPa in the 0--2 GPa range and $B_0$ $\sim$ 32.8(2) GPa in
the 4--5 GPa range, suggesting valence instability under pressure. The
structural transition in CeMnSi is attributed to the pressure-induced decrease
in $c/a$ and its low bulk modulus. Above $P_{\rm s}$, the X-ray diffraction
pattern indicates a transition to a monoclinic structure with space group No.
11, $P2_1/m$. These findings highlight the unique pressure response of CeMnSi
and provide insight into the coupling between lattice and electronic degrees of
freedom in Ce-based intermetallic systems.

</details>


### [297] [Temperature-Dependent Dielectric Function of Calcium Fluoride](https://arxiv.org/abs/2509.07240)
*T. Das,D. Alam,C. A. Ullrich,U. D. Jentschura*

Main category: cond-mat.mtrl-sci

TL;DR: 钙氟石(CaF2)光学性能研究


<details>
  <summary>Details</summary>
Motivation: 研究光学元件制造中CaF2随温度变化的光学特性

Method: 使用改进的耦合振子模型和函数形式来描述其介电函数

Result: 得到0 < omega < 1.8 a.u.和22°C < T < 500°C温度范围内CaF2的介电函数，并计算了其与氢和氦原子表面相互作用的短程和长程渐近值

Conclusion: 提出了一个紧凑的函数形式来描述CaF2在一定频率和温度范围内的介电函数，并将其应用于计算原子表面相互作用

Abstract: Calcium fluoride (fluorspar, CaF2 ) is of consummate importance for the
manufacturing of optical components. In many cases, its wide transmission band
eliminates the need for antireflective coatings. It is thus of interest to
study its optical properties as a function of temperature. The optical
properties are mainly determined by a strongly temperature-dependent infrared
(IR) peak, and a series of nearly temperature-independent ultraviolet (UV)
peaks. We find that the temperature dependence of the IR peak can be modeled,
to good accuracy, by a radiation-reaction improved coupled-oscillator model,
with temperature-dependent parameters. For the UV peaks, we find a convenient
functional form which covers both the real as well as the imaginary parts of
the dielectric function and provide a comparison to first-principles
calculations. The result is a compact functional form for the dielectric
function of undoped CaF2 in the frequency range 0 < omega < 1.8 a.u., and in
the temperature range 22Celsius < T < 500Celsius. With the help of the
temperature-dependent dielectric function, we obtain temperature-dependent
values of the short-range and long-range asymptotics of atom-surface
interactions with CaF2, for hydrogen, as well as ground-state and metastable
helium.

</details>


### [298] [High-current p-type transistors from precursor-engineered synthetic monolayer WSe$_2$](https://arxiv.org/abs/2509.07299)
*Anh Tuan Hoang,Kathryn Neilson,Kaikui Xu,Yucheng Yang,Stephanie M. Ribet,Tara Peña,Giulio D'Acunto,Young Suh Song,Anton E. O. Persson,William Millsaps,Colin Ophus,Matthew R. Rosenberger,Eric Pop,Andrew J. Mannix*

Main category: cond-mat.mtrl-sci

TL;DR: 通过优化生长前驱体和最小化损伤的器件制造策略，成功制备了低缺陷密度（低于 5x10^9 cm^-2）的单层二硒化钨（WSe2）薄膜，实现了创纪录的 p-型晶体管性能（在 -1V 漏源电压下，p-型器件的开启态电流高达 888 μA·μm^-1），从而缩小了 p-型器件与 n-型器件的性能差距，为实现互补型二维半导体电路奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 单层二硒化钨（WSe2）是实现纳米尺度互补逻辑器件的理想材料，但薄膜生长和器件制造过程中引入的高缺陷密度严重限制了其 p-型晶体管的性能。

Method: 采用结合了前驱体工程化学气相沉积和最小化损伤的器件制造策略。具体方法包括：1. 在生长前将三氧化钨和残留的氧硒化物转化为活性的低氧化态前驱体。2. 精确控制生长过程中的硒供应。3. 采用损伤最小化的器件制造工艺。

Result: 成功制备出均匀、厘米级尺度的单层 WSe2 薄膜，其带电缺陷密度低至 5x10^9 cm^-2。采用该薄膜制造的晶体管实现了创纪录的 p-型器件性能，在 -1V 的漏源电压下，p-型器件的开启态电流高达 888 μA·μm^-1，与领先的 n-型器件性能相当。

Conclusion: 所提出的策略成功克服了 WSe2 p-型器件性能受缺陷限制的问题，实现了与 n-型器件相当的性能，且无需特殊的掺杂或接触材料，这是实现互补型二维半导体电路的关键一步。

Abstract: Monolayer tungsten diselenide (WSe$_2$) is a leading candidate for nanoscale
complementary logic. However, high defect densities introduced during thin-film
growth and device fabrication have limited p-type transistor performance. Here,
we report a combined strategy of precursor-engineered chemical vapor deposition
and damage-minimizing fabrication to overcome this limitation. By converting
tungsten trioxide and residual oxyselenides into reactive suboxides before
growth, and precisely regulating selenium delivery during deposition, we
synthesize uniform, centimeter-scale monolayer WSe$_2$ films with charged
defect densities as low as $5 \times 10^{9}$ cm$^{-2}$. Transistors fabricated
from these films achieve record p-type on-state current up to $888
\mu$A$\cdot\mu$m$^{-1}$ at $V_{\mathrm{DS}}=-1$ V, matching leading n-type
devices. This leap in material quality closes the p-type performance gap
without exotic doping or contact materials, marking a critical step towards
complementary two-dimensional semiconductor circuits.

</details>


### [299] [Alter-magnetic properties in the perovskite compounds](https://arxiv.org/abs/2509.07366)
*Sining Zhang,Zhengxuan Wang,Minping Zhang,Xilin Zhang,Guangtao Wang*

Main category: cond-mat.mtrl-sci

TL;DR: 文章通过高通量计算筛选了Materials Project数据库，发现了140种具有Pnma空间群的反铁磁性候选材料，其中91种优先稳定为altermagnetic基态，20种为钙钛矿结构。以NaCoF3为例，详细研究了其电子结构、磁有序和轨道构型，发现G-AFM是其基态，并且该相位的磁矩耦合受到时间反转和旋转对称操作的保护，从而产生各向异性光学电导率、显著的反常输运效应（AHE、ANE、ATHE）以及强的磁光响应（Kerr和Faraday效应）。


<details>
  <summary>Details</summary>
Motivation: 为了寻找具有反铁磁行为的新材料，并深入理解其独特的对称性保护下的物理现象。

Method: 使用高通量计算筛选Materials Project数据库，进行密度泛函理论计算，比较不同磁构型，并对NaCoF3进行详细的电子结构、磁有序、轨道构型和对称性分析。

Result: 筛选出140种候选反铁磁材料，91种稳定为altermagnetic基态，20种为钙钛矿结构。在NaCoF3中，G-AFM是基态，且其对称性保护导致了各向异性光学电导率、反常霍尔效应、Nernst效应、热霍尔效应以及Kerr和Faraday效应。

Conclusion: G-AFM基态的反铁磁材料，特别是NaCoF3，由于其独特的对称性保护，表现出丰富的物理现象，为新型电子和光电器件提供了潜在选择。

Abstract: Our high-throughput computational screening of the Materials Project database
has identified 140 candidate materials exhibiting antiferromagnetic behavior in
the $Pnma$ space group. Through systematic density functional theory
calculations comparing various magnetic configurations, we demonstrate that 91
of these compounds preferentially stabilize in altermagnetic ground states,
with 20 adopting the perovskite structure. Using NaCoF$_3$ as a prototypical
example, we perform a comprehensive investigation of its electronic structure,
magnetic ordering, and orbital configurations. Our analysis reveals that the
magnetic Co$^{2+}$ ions occupy the 4c Wyckoff position and support three
distinct antiferromagnetic (AFM) phases, among which the $G$-AFM configuration
emerges as the ground state. Detailed symmetry analysis uncovers that the
inter-sublattice coupling in the $G$-AFM phase is mediated by the combined
time-reversal and rotation operation
$\hat{T}\{R_{2x}|\frac{1}{2}\frac{1}{2}0\}$. This unique symmetry protection
gives rise to several remarkable physical phenomena: (i) anisotropic optical
conductivity, (ii) prominent anomalous transport effects including the
anomalous Hall effect (AHE), Nernst effect (ANE), and thermal Hall effect
(ATHE), and (iii) strong magneto-optical responses manifested through both Kerr
and Faraday effects.

</details>


### [300] [Benchmarking Universal Interatomic Potentials on Zeolite Structures](https://arxiv.org/abs/2509.07417)
*Shusuke Ito,Koki Muraoka,Akira Nakayama*

Main category: cond-mat.mtrl-sci

TL;DR: 通用机器学习势能（MLIP）在沸石结构模拟中表现优于通用解析势能，其中eSEN-30M-OAM模型表现最为稳定。


<details>
  <summary>Details</summary>
Motivation: 开发覆盖广泛元素且高精度的原子间势能（IPs）对于材料高通量发现至关重要。然而，现有通用IPs在特定化学体系中的适用性需要仔细评估。

Method: 使用沸石结构作为测试平台，对多种通用解析IPs（GFN-FF, UFF, Dreiding）和预训练通用MLIPs（CHGNet, ORB-v3, MatterSim, eSEN-30M-OAM, PFP-v7, EquiformerV2-lE4-lF100-S2EFS-OC22）进行了基准测试，并与定制IPs（SLC, ClayFF, BSFF）进行了比较，以实验数据和密度泛函理论（DFT）计算为参考。测试的沸石结构包括纯硅框架和含有铜、钾及有机阳离子的硅铝酸盐。

Result: 通用解析IPs中，GFN-FF表现最佳，但在高度应变硅环和硅铝酸盐体系中精度不足。所有MLIPs都能很好地重现实验或DFT层级的几何结构和能量学性质。在通用MLIPs中，eSEN-30M-OAM模型在所有研究的沸石结构中表现出最一致的性能。

Conclusion: 现代预训练通用MLIPs是沸石筛选工作流程中处理各种成分的实用工具。

Abstract: Interatomic potentials (IPs) with wide elemental coverage and high accuracy
are powerful tools for high-throughput materials discovery. While the past few
years witnessed the development of multiple new universal IPs that cover wide
ranges of the periodic table, their applicability to target chemical systems
should be carefully investigated. We benchmark several universal IPs using
equilibrium zeolite structures as testbeds. We select a diverse set of
universal IPs encompassing two major categories: (i) universal analytic IPs,
including GFN-FF, UFF, and Dreiding; (ii) pretrained universal machine learning
IPs (MLIPs), comprising CHGNet, ORB-v3, MatterSim, eSEN-30M-OAM, PFP-v7, and
EquiformerV2-lE4-lF100-S2EFS-OC22. We compare them with established tailor-made
IPs, SLC, ClayFF, and BSFF using experimental data and density functional
theory (DFT) calculations with dispersion correction as the reference. The
tested zeolite structures comprise pure silica frameworks and aluminosilicates
containing copper species, potassium, and organic cations. We found that GFN-FF
is the best among the tested universal analytic IPs, but it does not achieve
satisfactory accuracy for highly strained silica rings and aluminosilicate
systems. All MLIPs can well reproduce experimental or DFT-level geometries and
energetics. Among the universal MLIPs, the eSEN-30M-OAM model shows the most
consistent performance across all zeolite structures studied. These findings
show that the modern pretrained universal MLIPs are practical tools in zeolite
screening workflows involving various compositions.

</details>


### [301] [Temperature behavior of optical absorption spectra in HfO2 thin films](https://arxiv.org/abs/2509.07419)
*A. O. Shilov,S. S. Savchenko,A. S. Vokhmintsev,V. A. Gritsenko,I. A. Weinstein*

Main category: cond-mat.mtrl-sci

TL;DR: Hafnia薄膜在7-296 K温度范围内表现出非晶结构，研究其光学性质随温度的变化。


<details>
  <summary>Details</summary>
Motivation: Hafnia材料在光电和纳米电子学中具有广泛应用，需要了解其在不同热工作条件下的性能。

Method: 研究了非晶Hafnia薄膜在7-296 K宽温度范围内的光学性质，特别是能量隙随温度的变化，并估算了电子-声子相互作用对光学性质的影响。

Result: 首次研究了Hafnia薄膜能量隙的温度效应，估算出声子能量为30 meV。发现折射率随温度降低而降低，并且电子-声子相互作用主要发生在氧子系统中。

Conclusion: 研究结果对预测基于Hafnia薄膜的光电器件在宽温度范围内的行为至关重要。

Abstract: Hafnium dioxide, also known as hafnia, is an extremely sought-after material
in opto- and nanoelectronics for creating optical coatings and various
functional media to have stable performance characteristics under varying
thermal operating conditions. In this paper, we have investigated the behavior
of the optical properties of hafnia thin films exhibiting an amorphous
structure in a wide temperature range of 7-296 K. For the first time we have
examined the temperature effects in the energy gap of HfO2 films and estimated
the effective phonon energy of 30 meV responsible for observed thermally
assisted shift of electronic levels. It has been shown that the electron-phonon
interaction in the oxygen subsystem predominantly causes the observed changes.
The obtained refractive index values for the tested films are established to be
compatible with independent predicted data and to decrease as the temperature
drops. The energy structure and electron-phonon interaction features that have
been found are critical for forecasting how hafnia-thin-film-based
optoelectronic devices will behave across a wide temperature range.

</details>


### [302] [Ions leaving no tracks](https://arxiv.org/abs/2509.07440)
*Azat Abdullaev,Javier Garcia Fernandez,Chloe Nozais,Jacques O'Connell,Rustem Tlegenov,Kairolla Sekerbayev,Alexander Azarov,Aleksi Leino,Junlei Zhao,Aldo Artimez Pena,Nikita Medvedev,Zhandos Utegulov,Oystein Prytz,Flyura Djurabekova,Andrej Kuznetsov*

Main category: cond-mat.mtrl-sci

TL;DR: 在 gamma/beta-Ga2O3 异质结构中，与 beta-Ga2O3 不同，gamma-Ga2O3 不会留下重离子辐照的离子径迹。这是因为 gamma-Ga2O3 晶格自身具有多种构型，能够快速恢复辐照造成的无序，从而阻止了离子径迹的形成。这使得 gamma-Ga2O3 成为在恶劣辐射环境中运行的器件的有希望的半导体平台。


<details>
  <summary>Details</summary>
Motivation: 研究重离子辐照在固体材料中形成的离子径迹现象，并探索在 gamma/beta-Ga2O3 异质结构中是否存在离子径迹及其原因。

Method: 利用 gamma/beta-Ga2O3 异质结构，对比观察重离子辐照在 gamma-Ga2O3 和 beta-Ga2O3 中的影响，解释 gamma-Ga2O3 中离子径迹未形成的原因。

Result: 发现在 gamma-Ga2O3 中，重离子辐照不留下离子径迹，而在 beta-Ga2O3 中则留下离子径迹。解释了 gamma-Ga2O3 中快速的无序恢复机制，即由于其晶格的多重构型，离子撞击产生的无序能够被迅速消除。

Conclusion: gamma-Ga2O3 具有快速的无序恢复能力，不会留下重离子辐照的离子径迹，这使其成为在恶劣辐射环境中运行的器件的有希望的半导体平台。

Abstract: The paths of swift heavy ions are typically traceable in solids, because of
confined electronic interactions along the paths, inducing what is known in
literature as 'ion tracks', i.e. nano-sized in cross-section cylindrical zones
of modified material extending for microns in length. Such tracks readily form
in materials exhibiting low thermal conductivities, in particular insulators or
semiconductors, altering the homogeneity of materials. In this work, using
recently discovered gamma/beta-Ga2O3 polymorph heterostructures we show that,
in contrast to the trends in many other materials, including that in
beta-Ga2O3, swift heavy ions leave no tracks in gamma-Ga2O3. We explained this
trend in terms of amazingly fast disorder recovery, occurring because of
multiple configurations in the gamma-Ga2O3 lattice itself, so that the disorder
formed by ion impacts gets rapidly erased, giving a perception of ions leaving
no tracks. As such, gamma-Ga2O3, readily integrated with beta-Ga2O3 in
polymorph heterostructures, may become a promising semiconductor platform for
devices capable to operate in extremely harsh radiation environments.

</details>


### [303] [First-principles study of formic acid decomposition on single Pt atoms supported on heteroatom-doped graphene](https://arxiv.org/abs/2509.07494)
*Kazuma Sato,Norihito Sakaguchi,Yuji Kunisada*

Main category: cond-mat.mtrl-sci

TL;DR: 单原子Pt在掺杂石墨烯上可作为甲酸脱氢的催化剂


<details>
  <summary>Details</summary>
Motivation: 甲酸作为一种有潜力的储氢介质，其催化分解需要高活性和选择性。本研究旨在探索单原子Pt在原始及掺杂石墨烯上的催化性能。

Method: 利用密度泛函理论（DFT）的第一性原理计算，研究了单原子Pt在原始及杂原子（P、O）掺杂石墨烯上的催化活性和选择性。

Result: 计算结果表明，单原子Pt在P、O掺杂石墨烯上的催化活性与Pt(111)相当，并且所有体系均表现出对脱氢反应的高选择性。

Conclusion: 掺杂石墨烯有望作为贵金属催化剂的载体，以减少贵金属的使用量。

Abstract: Formic acid is a promising liquid hydrogen carrier, but its catalytic
decomposition requires both high activity and selectivity toward
dehydrogenation. Here, we investigated the catalytic activity and selectivity
of formic acid decomposition on single Pt atoms supported on pristine and
heteroatom-doped graphene using first-principles calculations based on the
density functional theory. Reaction energy profiles reveal that single Pt atoms
on P- and O-doped graphene show catalytic activity comparable to Pt(111), while
all systems maintain strong dehydrogenation selectivity. These findings
highlight doped graphene as a promising support for reducing precious metal
usage in dehydrogenation catalysts.

</details>


### [304] [Atomic Layer Etching of Aluminum Nitride: Mechanistic Insights from First-Principles Studies of Chlorine Chemistry](https://arxiv.org/abs/2509.07554)
*Sanjay Nayak,Nikolai Andrianov,Thomas Gruhn,Joaquin Miranda*

Main category: cond-mat.mtrl-sci

TL;DR: 原子氯和分子氯在氮化铝的Al终止0001表面上表现出化学吸附特性，Cl2的分解过程是无势垒且放热的。


<details>
  <summary>Details</summary>
Motivation: 研究原子氯和分子氯在氮化铝的Al终止0001表面的吸附、解吸和扩散行为，以了解卤素-绝缘体表面相互作用的微观机制，并为优化半导体制造中的AlN原子层刻蚀工艺提供新策略。

Method: 使用第一性原理密度泛函理论计算，并结合爬行图像捏合弹性带（CI-NEB）方法。

Result: 原子氯和分子氯在Al终止的AlN 0001表面上表现出化学吸附特性，具有较高的结合能。Cl2在Al终止的AlN 0001表面上的分解路径是无势垒且放热的过程。

Conclusion: 研究结果为理解卤素-绝缘体表面相互作用提供了新的微观尺度见解，并为优化AlN原子层刻蚀工艺提供了新的策略。

Abstract: Using first-principles density functional theory calculations in combination
with the climbing-image nudged elastic band method, we investigated the
adsorption, desorption, and diffusion of atomic chlorine and molecular chlorine
on the Al terminated 0001 surface of aluminum nitride. Our results reveal that
both atomic Cl and Cl2 exhibit a chemisorption character with high binding
energies. Calculations revealed that the splitting pathway of Cl2 on the Al
terminated AlN 0001 surface is a barrierless and exothermic process. These
findings provide new microscopic-scale insights into halogen-insulator surface
interactions and opportunities for new strategies in optimizing AlN atomic
layer etching process in semiconductor fabrication.

</details>


### [305] [Dispersed multi-walled carbon nanotubes in polyvinyl butyral matrix for transparent ionic conductive films](https://arxiv.org/abs/2509.07584)
*Mykola O. Semenenko,Sergii O. Kravchenko,Nadiia V. Siharova,Olha V. Pylypova,Mariya I. Terets,Oleksandr S. Pylypchuk,Mariia V. Voitovych,Tetiana Yu. Obukhova,Taisiia O. Kuzmenko,Andrey Sarikov*

Main category: cond-mat.mtrl-sci

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In this work, we develop methods for increasing the dispersion degree of
agglomerated multiwalled carbon nanotubes with subsequent introduction of them
into polyvinyl butyral to create transparent conductive films. The influence of
proton and a-proton solvents in combination with potassium triiodide (KI3) as a
redox component for oxidation of the multiwalled carbon nanotubes surface,
which reduces agglomeration due to electrostatic repulsion, is investigated. It
is demonstrated that a-proton solvent cyclohexanone ensures a smaller size of
the agglomerates (30-300 nm, with a maximum of ~145 nm) compared to proton
solvent propyl alcohol (100-3000 nm, with a maximum of ~920 nm). The reduced
aggregation is associated with the formation of oxygen-containing functional
groups (C=O, C-O, C-O-C, and COO), which increase electrostatic stabilization.
The impedance analysis showed that the constant component of the conductivity
in the samples with multiwalled carbon nanotubes and a-proton solvent shifts to
frequencies of ~104 rad/s after the addition of the redox component, which
indicates the formation of ion-conducting channels and stabilization of the
jump charge transfer.

</details>


### [306] [Unusual magnetic order in Eu$_{10}$Hg$_{55}$](https://arxiv.org/abs/2509.07589)
*Rachel Nixon,Nazar Zaremba,Samuel A. Adegboyega,Andreas Leithe-Jasper,Mitja Krnel,Yurii Prots,Ulrich Burkhardt,Jörg Sichelschmidt,Lucia Amidani,Fabio La Mattina,Michael Shatruk,Alexander Shengelaya,Manuel Brando,Eteri Svanidze*

Main category: cond-mat.mtrl-sci

TL;DR: Eu$_{10}$Hg$_{55}$ 是一种非中心对称的Eu基金属间化合物，其Eu原子可能存在两种价态，导致其磁性基态脆弱。该化合物具有笼状结构，Eu原子间距大，表现出弱铁磁耦合，在低至5.5 K时发生磁序，并在4.3 K时伴随自旋重取向。磁性有序导致磁极反转，呈现弱反铁磁基态。


<details>
  <summary>Details</summary>
Motivation: 研究Eu$_{10}$Hg$_{55}$这种Eu基非中心对称材料的磁性，特别是Eu原子可能存在的混合价态及其对磁性的影响。

Method: 通过对Eu$_{10}$Hg$_{55}$大单晶进行详细的磁性分析。

Result: Eu$_{10}$Hg$_{55}$表现出Eu原子可能存在两种价态，具有脆弱的磁性基态。该化合物在5.5 K以下发生磁序，并在4.3 K时发生自旋重取向，磁性有序导致磁极反转，呈现弱反铁磁基态。外加磁场可诱导额外的磁相。

Conclusion: Eu$_{10}$Hg$_{55}$表现出独特的磁性行为，包括混合价态的可能性、弱铁磁耦合、低温磁序、自旋重取向和弱反铁磁基态，这为研究含Eu化合物的磁性提供了新的视角。

Abstract: In solid-state compounds, the valence of europium can sometimes be mixed --
which is especially favored in structures with several positions for the
europium atoms. In this work, we study the Eu-based intermetallic
noncentrosymmetric system Eu$_{10}$Hg$_{55}$ which has 65 atoms per unit cell
and 4 distinct crystallographic positions for europium and 17 positions for
mercury. Our detailed analysis of magnetism of large single crystals suggests
that europium in Eu$_{10}$Hg$_{55}$ might be present in two valence states,
resulting in a fragile magnetic ground state. Due to the cage-like structure
with a large distance between the Eu atoms, those atoms are weakly
ferromagnetically coupled and Eu$_{10}$Hg$_{55}$ orders at low temperatures,
below $T_{1} = 5.5$ K, with a subsequent spin re-orientation at $T_{2} = 4.3$
K. There is no sign of magnetic frustration. Interestingly, the magnetic
ordering of europium sub-lattices results in a magnetization pole reversal with
a weak ferrimagnetic ground state. Additional magnetic phases can be induced by
application of a modest external magnetic field.

</details>


### [307] [First-principles approach to ultrafast pump-probe spectroscopy in solids](https://arxiv.org/abs/2509.07612)
*Lu Qiao,Ronaldo Rodrigues Pela,Claudia Draxl*

Main category: cond-mat.mtrl-sci

TL;DR: 泵浦-探测光谱是一种研究超快激子动力学、揭示电子尺度下复杂相互作用的有力工具。本研究提出了一种模拟泵浦-探测光谱的第一性原理方法，并将激子动力学中的电子和热学贡献分开。研究结果表明，(i) 光诱导的库仑屏蔽是主要的电子效应，导致激子共振蓝移；(ii) 泡利不相容原理起次要作用；(iii) 热晶格膨胀导致光谱红移。该方法为解释泵浦-探测实验提供了定量和预测性框架，并为通过激子工程设计能量选择性光电器件提供了可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 开发一个全面的理论框架来模拟和解释光激发材料中的瞬态响应，以解决当前实验技术进步与理论模型发展之间的差距。

Method: 提出并应用一种第一性原理方法来模拟泵浦-探测光谱，区分电子和热学贡献，并研究了三种代表性材料：WSe$_2$、CsPbBr$_3$和TiO$_2$。

Result: 该方法在三种材料（WSe$_2$、CsPbBr$_3$和TiO$_2$）上与实验结果高度一致。研究发现光诱导库仑屏蔽是主要的电子效应（导致蓝移），泡利不相容作用次之，而热膨胀导致红移。同时，证明了激发密度、泵浦光子能量和偏振等参数可调控瞬态吸收光谱。

Conclusion: 所提出的第一性原理方法为解释泵浦-探测实验提供了定量和预测性框架，并为通过激子工程设计光电器件提供了指导。

Abstract: Pump-probe spectroscopy is a powerful tool to study ultrafast exciton
dynamics, revealing the underlying complex interactions on the electronic
scale. Despite significant advances in experimental techniques, developing a
comprehensive and rigorous theoretical framework for modeling and interpreting
the transient response in photoexcited materials remains a challenge. Here, we
present a first-principles approach to simulating pump-probe spectroscopy and
disentangling the electronic and thermal contributions underlying exciton
dynamics. We showcase our method to three materials, representative for
different classes of solids: the transition-metal dichalcogenides WSe$_2$, the
halide perovskite CsPbBr$_3$, and the transition-metal oxide TiO$_2$, showing
remarkable agreement with experimental counterparts. We find that (i)
photoinduced Coulomb screening is the primary electronic effect, responsible
for a blue shift of exciton resonances, while (ii) Pauli blocking plays a minor
role, and (iii) thermal lattice expansion leads to a red shift of the spectra.
We further demonstrate how key parameters such as excitation density, pump
photon energy, and pump polarization modulate the transient absorption spectra,
offering direct control over the exciton-resonance energy. Our approach
establishes a quantitative and predictive framework for interpreting pump-probe
experiments, providing actionable insights for the design of energy-selective
optoelectronic devices through exciton engineering.

</details>


### [308] [Temperature and magnetic field dependent $g$-factors in electron spin resonance spectroscopy](https://arxiv.org/abs/2509.07859)
*Sebastian Kalhöfer*

Main category: cond-mat.mtrl-sci

TL;DR: 电子-声子相互作用影响电子自旋共振的g因子


<details>
  <summary>Details</summary>
Motivation: 解释电子自旋共振现象和测量结果，特别是g因子的温度依赖性

Method: 引入自旋-电子-声子相互作用，考虑自旋-轨道耦合

Result: g因子出现温度依赖性，与实验结果吻合；预测g因子在低温下具有磁场依赖性；预测声子在极高和极低温下影响可忽略

Conclusion: 电子-声子相互作用是理解电子自旋共振g因子行为的关键因素，特别是在温度依赖性方面。

Abstract: We propose that phonons coupled to electrons play an important role in both
the fundamental phenomenology of electron spin resonance as well as the
interpretation of such measurements. By including spin-dependent
electron-phonon interactions originating from spin-orbit coupling, we
demonstrate that the g-factor acquires emergent temperature dependencies that
are in excellent agreement with experimental observations. Moreover, we predict
that at low temperatures, the $g$-factor will exhibit a non-trivial dependence
on the magnetic field, indicating a dynamic property that has not been
previously considered in electron-phonon systems. We further predict the
influence of phonons to be negligible at very low and very high temperatures,
with the former requiring experimental verification.

</details>


### [309] [Investigation on Structural, Optical, Thermal, and Magnetic Properties of Bismuth Ferrite Nanoparticles Synthesized at Lower Annealing Temperature](https://arxiv.org/abs/2509.07626)
*Naresh Prajapati,G. Surya Prakash,Manoj Kumar,Himanshu Pandey*

Main category: cond-mat.mtrl-sci

TL;DR: 本文采用溶胶-凝胶法在较低退火温度下合成了纯相铋铁氧体纳米颗粒，并对其结构、光学、磁性和热稳定性进行了研究。


<details>
  <summary>Details</summary>
Motivation: 铋铁氧体因其多铁性和窄光学带隙，在自旋电子学、光伏和光催化领域具有广泛的应用前景，但其纯相合成具有挑战性。本研究旨在通过改进的溶胶-凝胶法在较低退火温度下合成纯相铋铁氧体。

Method: 采用溶胶-凝胶法，在450°C至650°C的温度范围内进行退火处理，并利用X射线衍射（XRD）、Rietveld分析、紫外-可见光谱（UV-Vis）、傅里叶变换红外光谱（FTIR）和差示扫描量热法（DSC）以及振动样品磁强计（VSM）分析材料的结构、光学、磁性和热稳定性。

Result: 所有样品均以纯铋铁氧体相（R3c空间群）结晶，但在600°C和650°C退火的样品除外。随着退火温度升高，应变和位错密度降低。紫外-可见光谱显示在600 nm以下有强烈的响应，带隙在2.26 - 2.60 eV之间。FTIR证实了金属-氧键的存在。DSC分析表明纳米颗粒具有良好的热稳定性。VSM分析显示纳米颗粒具有弱磁性。

Conclusion: 该研究成功地在较低退火温度下通过溶胶-凝胶法合成了纯相铋铁氧体纳米颗粒，并详细表征了其结构和光学性质。研究结果表明，铋铁氧体纳米颗粒具有潜在的光电应用价值。

Abstract: Due to its multiferroic properties and narrow optical bandgap, Bismuth
ferrite has been widely explored for spintronics, photovoltaics, and
photocatalysis applications. Bismuth ferrite can be synthesized in various
forms like bulk, thin films, and nanostructures using various synthesis
techniques. It is challenging to synthesize the pure BiFeO3 phase due to the
volatile nature of bismuth and the very narrow temperature range for forming
this phase. So, this work aims to synthesize the pure BiFeO3 phase at lower
annealing temperatures using an efficient sol-gel method. We have chosen the
annealing temperature from 450 to 650 C, and a detailed analysis of structural
and optical properties is performed here. X-ray diffraction is used to confirm
the crystalline nature of the material. Single-phase Rietveld analysis of XRD
patterns is carried out to study the effect of annealing temperature on
structural parameters. All the samples are crystalized in pure rhombohedral
BiFeO3 phase with the R3c space group symmetry, except those annealed at higher
temperatures, 600 C and 650 C. Strain and dislocation densities were decreasing
with an increase in the annealing temperature. From the UV-visible analysis, a
strong response is observed below 600 nm in the visible region, and the band
gap from the absorption behaviour is estimated in the range of 2.26 - 2.60 eV
for these Bismuth ferrite nanoparticles. Fourier transform infrared analysis
confirmed the existence of metal-oxygen bonds in Bismuth ferrite nanoparticles.
These nanoparticles were found to be thermally stable from the thermal analysis
performed using differential scanning calorimetry. Bismuth ferrite
nanoparticles were weakly magnetic from the vibrating sample magnetometry
analysis.

</details>


### [310] [Electronic structure and thermoelectric properties of CoTiSi half-Heusler alloy: Doping overtones](https://arxiv.org/abs/2509.07631)
*A. Shukla,Sadhana Matth,Raghavendra Pal,S. S. A. Warsi,Himanshu Pandey*

Main category: cond-mat.mtrl-sci

TL;DR: CoTiSi合金具有高塞贝克电压和热电势，P型掺杂效果优于N型掺杂，有望用于实际器件。


<details>
  <summary>Details</summary>
Motivation: 研究高居里系数的热电材料。

Method: 使用密度泛函理论（Wien2k）计算CoTiSi半赫斯勒合金的结构优化、晶格常数、原子位置，并采用恒定弛豫时间近似法分析其热传输性质。

Result: 计算结果显示CoTiSi合金具有显著的塞贝克电压和热电势，其中P型掺杂的性能优于N型掺杂。

Conclusion: P型掺杂的载流子能显著提高CoTiSi合金的热电性能，可为实验研究和实际器件应用提供参考。

Abstract: The quest for thermoelectric materials with high figures of merit is an
ongoing and significant area of research. In this study, we investigate the
thermoelectric properties of the CoTiSi half-Heusler alloy using density
functional theory calculations implemented via the Wien2k package. Our approach
begins with a thorough structural optimization to determine the equilibrium
lattice parameter and the atomic positions of the constituent elements within
the unit cell of CoTiSi. Following this, we analyze the thermal transport
properties of the alloy under the constant relaxation time approximation, which
allows us to gain insights into its thermoelectric performance. Our
calculations reveal a substantial Seebeck voltage and thermopower, with notably
higher values for P-type doping than N-type doping. This finding highlights the
enhanced thermoelectric performance of P-type carriers in this material,
providing a starting point for experimentalists to utilize this alloy for real
device applications.

</details>


### [311] [Structural analysis of co-sputtered Cu-Nb and Cu-Pd textured thin films](https://arxiv.org/abs/2509.07658)
*Claudia Cancellieri,Giacomo Lorenzin,Yeliz Unutulmazsoy,Andriy Lotnyk,Daniel Ariosa*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种用于分析纳米级双金属相体系结构的模型，解决了区分金属相、确定元素分布、量化元素含量和评估内部无序度的挑战。


<details>
  <summary>Details</summary>
Motivation: 分析纳米级双金属相体系的结构特性，特别是当与少量微量元素共溅射时，存在部分、完全或不混合的情况，这是极具挑战性的。共溅射两种金属在室温下会导致沉积薄膜内产生冻结的无序状态。通过衍射分析区分每种金属相的贡献、确定第二种构成元素在晶格内的分布和自组织、准确量化额外元素含量以及评估内部无序度，这些都非常复杂，需要开发一个合适的模型来拟合各种几何形状的衍射图。本研究的动机是解决这些挑战。

Method: 提出一个模型来描述磁控溅射 Cu 薄膜中合金元素的结构分布，并探讨了两种对比情况：1）与互不相容的 Nb；2）与 Pd（与 Cu 具有负混合热，形成稳定的合金）。

Result: 该模型能够描述纳米级双金属相体系的结构分布，并通过与 X 射线衍射数据和能量色散 X 射线光谱衍生的元素分布进行比较来验证。

Conclusion: 本研究提出的模型为分析纳米级双金属相体系的结构分布提供了一种有效的方法，并为理解合金元素的自组织和分布规律提供了见解。

Abstract: Structural characterization of nanoscale-two-metal-phase systems, which
exhibit partial, complete, or no mixing when co-sputtered with a few percent of
a minority element, is extremely challenging. Co-sputtering two metals at room
temperature results in frozen disorder within the deposited films.
Distinguishing the contribution of each metal phase, determining the
distribution and self-organization of the second constituent element within the
lattice, accurately quantifying the extra element content, and assessing
internal disorder through diffraction analysis are complex and require the
development of a suitable model to fit diffraction patterns from various
geometries. Here, we present a model to describe the structural distribution of
alloy elements in magnetron-sputtered Cu thin films, exploring two contrasting
cases: 1) with the mutually immiscible Nb and 2) with Pd, which has a negative
heat of mixing with Cu, forming stable alloys. A comparison between X-ray
diffraction data and energy-dispersive X-ray spectroscopy-derived elemental
distribution is discussed.

</details>


### [312] [Selective band engineering of Bi/Si(111) by boron segregation](https://arxiv.org/abs/2509.07668)
*E. Barre,J. Villalobos-Castro,T. Pierron,S. Pons,D. Roditchev,L. Sponza,S. Vlaic*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在二维Bi/Si(111)β相表面掺杂B，可以调控Bi诱导的Rashba能带，将其在能量上移动高达200 meV，而Rashba参数保持不变。


<details>
  <summary>Details</summary>
Motivation: 为了控制和调控二维金属/半导体异质结构的外来相和诱导新相，需要控制和调控这些异质结构的电子态能量。

Method: 使用基于B在表面偏析的调制掺杂方法，研究了二维Bi/Si(111)β相的能带结构的工程设计。

Result: Bi诱导的Rashba能带在能量上移动高达200 meV，而其强的Rashba参数保持不变。Bi能级向上移动，而下方的Si价带基本保持固定，排除了简单的能带弯曲的可能性。

Conclusion: 密度泛函理论计算表明，能带的位移源于B原子的存在引起了表面附近Si态杂化的变化。这种选择性机制使Rashba分裂态与费米能级的距离减半，为在输运和自旋电子器件中的利用铺平了道路，并凸显了调制掺杂作为二维金属/半导体能带工程策略的更广泛潜力。

Abstract: Atomically thin layers of metals deposited on semiconductors display a
variety of physical properties such as superconductivity, charge density waves,
topological phases, strong spin-orbit (Rashba) splitting, among others. To
access these exotic phases and induce new ones, it is necessary to control and
tune the energies of the electronic states of those heterostructures. In this
work we investigate the engineering of the band structure of the
two-dimensional Bi/Si(111) $\beta$-phase using a modulation doping approach
based on boron segregation at the surface. We demonstrate that the Bi-induced
Rashba bands can be displaced in energy by up to 200 meV without altering their
strong Rashba parameter. Importantly, while the Bi states shift upward, the
underlying Si valence states remain essentially fixed, which rules out a simple
band-bending scenario. Our density functional theory calculations reveal that
the displacement originates from changes in the hybridization of Si states near
the surface, induced by the presence of B atoms. This selective mechanism
halves the distance of the Rashba-split states from the Fermi level, opening
the way to their exploitation in transport and spintronic devices and
highlighting the broader potential of modulation doping as a band-engineering
strategy for two-dimensional metals on semiconductors.

</details>


### [313] [Magnetostriction as the origin of the magnetodielectric effect in La2CoMnO6](https://arxiv.org/abs/2509.07679)
*M. Boldrin,A. Bagri,D. Barlettani,E. Teather,L. Squillante,M. de Souza,R. B. Pontes,A. G. Silva,T. J. A. Mori,R. Perry,R. Lora-Serrano,E. Granado,E. M. Bittar,L. S. I. Veiga,L. Bufaiçal*

Main category: cond-mat.mtrl-sci

TL;DR: La2CoMnO6 (LCMO) 钙钛矿因其接近室温的磁介电效应而备受关注，但其磁耦合机理尚不明确。本研究通过对LCMO进行结构、电子和磁性耦合的详细研究，特别是利用磁场依赖的X射线粉末衍射和电容式膨胀仪测量，发现外加磁场会减小晶胞体积，改变八面体畸变。通过Co-L2,3边吸收光谱的温度和场依赖性实验，以及多重态和密度泛函理论计算，揭示了自旋-轨道相互作用和场诱导的共价效应是磁致伸缩的关键，而场诱导的轨道杂化和配体到金属的电荷转移则引起介电响应的变化，从而实现了LCMO中磁、弹、介电性质的直接耦合。


<details>
  <summary>Details</summary>
Motivation: La2CoMnO6 (LCMO) 钙钛矿的磁介电效应近室温，但其磁耦合机理不明确。

Method: 采用磁场依赖的X射线粉末衍射、电容式膨胀仪测量、Co-L2,3边吸收光谱以及多重态和密度泛函理论计算，研究了LCMO的结构、电子和磁性耦合。

Result: 外加磁场减小LCMO的晶胞体积，改变八面体畸变；自旋-轨道相互作用和场诱导的共价效应是磁致伸缩的关键；场诱导的轨道杂化和配体到金属的电荷转移导致介电响应变化。

Conclusion: La2CoMnO6中实现了磁、弹、介电性质的直接耦合，其机理是外加磁场通过改变结构和电子性质，最终影响介电响应。

Abstract: The La2CoMnO6 (LCMO) perovskite has received a lot of attention due to its
near room temperature magnetodielectric effect. Despite the recent efforts, the
mechanism ruling the correlation between its magnetic and dielectric properties
is not yet fully understood. In order to address this issue, we conducted a
detailed investigation of the coupling between the structural, electronic and
magnetic properties of a polycrystalline LCMO sample. Using magnetic
field-dependent x-ray powder diffraction and measurements with a capacitive
dilatometer, we show that applying an external magnetic field decreases the
unit cell volume, thereby modifying the octahedral distortions. Experiments
involving temperature and field-dependent x-ray absorption spectroscopy at the
Co-L2,3 edges provide further evidence that the spin-orbit interaction of
outermost Co 3d-orbital and the field-induced enhancement of covalence effects
are the key contributors to the magnetostrictive effects. From a detailed
analysis using multiplet and density functional theory calculations, we propose
that the field-induced modulations of the orbital hybridization and the
ligand-to-metal charge transfer are responsible for the changes in the
dielectric response of LCMO, thus enabling a direct coupling between magnetic,
elastic and dielectric properties in this material.

</details>


### [314] [Algorithmic differentiation for plane-wave DFT: materials design, error control and learning model parameters](https://arxiv.org/abs/2509.07785)
*Niklas Frederik Schmitz,Bruno Ploumhans,Michael F. Herbst*

Main category: cond-mat.mtrl-sci

TL;DR: 我们提出了一个结合了算法微分（AD）和密度泛函微扰理论（DFPT）的平面波密度泛函理论（DFT）微分框架，称为AD-DFPT。该框架能够自动计算任何DFT输出量相对于任何输入参数（如几何、密度泛函或赝势）的导数，无需手动推导梯度表达式。


<details>
  <summary>Details</summary>
Motivation: 手动推导DFT中各种输出量相对于输入参数的梯度表达式非常复杂且容易出错。AD-DFPT旨在自动化这一过程，提高计算效率和准确性。

Method: 结合算法微分（AD）和密度泛函微扰理论（DFPT）。AD技术自动计算导数，而DFPT提供计算导数所需的基础理论框架。AD-DFPT被实现到Density-Functional ToolKit (DFTK) 中。

Result: AD-DFPT框架可以精确计算DFT输出量关于输入参数的导数。通过将AD-DFPT集成到DFTK中，展示了其在半导体带隙逆设计、交换关联泛函参数学习以及DFT参数不确定性向弛豫结构传播等方面的广泛应用。

Conclusion: AD-DFPT框架为第一性原理材料建模中的梯度驱动工作流程开辟了新的研究途径，能够实现更精确、更高效的材料设计和性质预测。

Abstract: We present a differentiation framework for plane-wave density-functional
theory (DFT) that combines the strengths of algorithmic differentiation (AD)
and density-functional perturbation theory (DFPT). In the resulting AD-DFPT
framework derivatives of any DFT output quantity with respect to any input
parameter (e.g. geometry, density functional or pseudopotential) can be
computed accurately without deriving gradient expressions by hand. We implement
AD-DFPT into the Density-Functional ToolKit (DFTK) and show its broad
applicability. Amongst others we consider the inverse design of a semiconductor
band gap, the learning of exchange-correlation functional parameters, or the
propagation of DFT parameter uncertainties to relaxed structures. These
examples demonstrate a number of promising research avenues opened by
gradient-driven workflows in first-principles materials modeling.

</details>


### [315] [Dislocation Transmission Across Tilt Low-Angle Grain Boundaries in BCC Fe: The Role of Elastic Interactions](https://arxiv.org/abs/2509.07787)
*Shuai Zhang,Zhishun Chen,Zhuoming Xie,Jun Song,Huiqiu Deng,Wangyu Hu,Jie Hou*

Main category: cond-mat.mtrl-sci

TL;DR: 低角度晶界（LAGBs）对位错运动既有穿透性，也有阻碍性，其根源在于弹性和位错几何形状的相互作用，而非传统的位错反应。


<details>
  <summary>Details</summary>
Motivation: 低角度晶界（LAGBs）对位错运动的阻碍作用是双重的，但其根本原因，尤其是弹性相互作用的作用，仍存在争议。

Method: 利用大规模分子动力学模拟研究不同倾斜LAGBs中位错的传递行为，并建立分析模型进行定量预测。

Result: 研究表明，LAGBs对位错的阻碍作用因位错与晶界的几何形状而异。弹性相互作用，而非位错反应，是主要的控制因素。螺位错比刃位错更容易受到阻碍，并且阻碍强度随位错特征角的减小而增强。

Conclusion: 研究提出了LAGB-位错相互作用的力学框架，强调了弹性相互作用和位错几何形状在决定LAGB对位错阻碍作用中的关键作用，并为设计LAGB强化材料提供了指导。

Abstract: Low-angle grain boundaries (LAGBs) are often regarded as penetrable
interfaces to dislocation motion, yet recent studies suggest they can also act
as strong barriers. The origin of this duality remains debated, particularly
regarding the role of elastic interactions. Here, large-scale molecular
dynamics simulations are employed to investigate dislocation transmission
across various tilt LAGBs in BCC Fe. The results show that transmission
resistance varies widely with boundary-dislocation geometry. Contrary to the
prevailing view that dislocation reactions dominate, elastic interactions
between lattice and boundary dislocations emerge as the primary controlling
factor. Screw and screw-like dislocations generate shear stresses that bend GB
dislocations and produce strong barriers, whereas edge dislocations lack such
stresses and transmit more readily. Consequently, barrier strength increases as
the dislocation character angle decreases, with screw dislocations experiencing
the strongest resistance. An analytical model is developed that quantitatively
predicts the net transmission stress, in excellent agreement with simulations.
These findings establish a mechanistic framework for LAGB-dislocation
interactions and offer guidance for designing LAGB-strengthened materials.

</details>


### [316] [Decoratypes: An Extensible Crystal Taxonomy for Machine Learning-Guided Materials Discovery](https://arxiv.org/abs/2509.07853)
*Kyle D. Miller,Michele Campbell,Danilo Puggioni,James M. Rondinelli*

Main category: cond-mat.mtrl-sci

TL;DR: 基于结构类型分类化合物，结合主动学习方法进行铁电材料发现，并预测了六种新型铁电候选材料。


<details>
  <summary>Details</summary>
Motivation: 开发一种分类化合物的结构分类法（decoratypes），并在此基础上建立一个铁电材料发现框架，以加速材料探索。

Method: 引入decoratypes结构分类法，并结合主动学习方法来发现铁电材料。

Result: 预测了六种新型铁电候选材料，其中包括三种应变激活铁电体和三种应变激活超铁电体。

Conclusion: decoratype分类法能够增进对结构驱动的材料特性的理解，并有助于发现有前景的、未被充分探索的化学空间区域。

Abstract: We introduce decoratypes as a structure taxonomy that classifies compounds
based on site decorations of specific structural prototypes. Building on this
foundation, a ferroelectric materials discovery framework is developed,
integrating decoratypes with an active learning approach to accelerate
exploration. In addition, six novel ferroelectric candidates are predicted,
including three strain-activated ferroelectrics and three strain-activated
hyperferroelectrics. These findings highlight the potential of the decoratype
taxonomy to enhance our understanding of structure-driven material properties
and facilitate the discovery of promising yet underexplored regions of chemical
space.

</details>


### [317] [Phase engineering of 1T$'$ and 1T CrS2 and Cr2S3 by MOCVD](https://arxiv.org/abs/2509.07899)
*Haoyu Bai,Gareth R. M Tainton,Mauro Och,Max Rimmer,Indrajit Maity,Filippo Mione,Khagesh Tanwar,Rongsheng Cai,Joseph Parker,Kho Zhiquan,Ercin C Duran,Evan Tillotson,Sam Sullivan-Allsop,David Hopkinson,Siyuan Deng,Dan Bromley,Jack N. Carter-Gartside,Alex Vanstone,Sandrine Heutz,Will R. Branford,Efrén Navarro-Moratalla,Johannes C. Lischner,Sarah Haigh,Cecilia Mattevi*

Main category: cond-mat.mtrl-sci

TL;DR: 文章发现了CrS2的一种新的1T'晶相，并首次通过MOCVD方法成功合成。该晶相在低温下表现出软铁磁性，为二维磁性材料在逻辑内存和自旋电子学等领域的应用提供了新的可能性。


<details>
  <summary>Details</summary>
Motivation: Cr-硫族化物化合物存在多种具有不同磁性的物相，其中一些仅被理论预测。本文旨在探索并合成一种未被报道过的CrS2晶相，并研究其磁性。

Method: 通过金属有机化学气相沉积（MOCVD）方法可控合成1T' CrS2和1T CrS2。利用偏振拉曼光谱、密度泛函微扰理论（DFPT）和4D-STEM对合成的物相进行鉴定。通过磁光克尔显微成像技术表征1T' CrS2的磁性。

Result: 成功合成了1T' CrS2，并识别出其为一种新的晶相。1T' CrS2晶体在低温下表现出软铁磁性。4D-STEM表征揭示了从1T到1T'相变的复杂过程，形成了空间关联的畴结构。

Conclusion: 本文成功合成了2D CrS2的复杂且扭曲的物相，并实现了长程磁有序。该研究为可扩展合成2D磁性材料用于超薄磁存储器、逻辑内存储器应用和自旋电子学铺平了道路。

Abstract: Layered Cr-chalcogenides compounds offer a rich range of phases with
different magnetic properties some of which have been predicted only. Here we
demonstrate a not yet reported crystal phase of CrS2 which is the distorted
octahedral one (1T$'$) synthesized via metal-organic chemical vapour deposition
(MOCVD). We achieved the tuneable synthesis of either 1T$'$ CrS2, or 1T CrS2.
The phases were identified using polarized Raman spectroscopy, density
functional perturbation theory (DFPT) and 4D-scanning transmission electron
microscopy (STEM)-scanning electron diffraction. The phases of CrS2 were
uniquely identified also in contrast with Cr2S3 which was synthesized and
characterized by a Neel temperature of ~46 K. Using magneto-optic Kerr imaging,
the 1T$'$ CrS2 crystals have soft ferromagnetic nature at low temperature,
shedding light on the magnetic properties of this just predicated material. The
4DSTEM characterization reveals that the synthesis of the thermodynamically
stable 1T$'$ phase occurs via a complex transformation process from the 1T to
1T$'$ resulting in a spatially correlated domain structure of differently
oriented 1T$'$ crystals. Our MOCVD growth of complex and distorted phases of 2D
CrS2 with long-range magnetic order paves the way for the scalable synthesis of
2D magnets for ultrathin magnetic memories for logic-in-memory applications and
spintronics.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [318] [Efficient Multi-Agent Coordination via Dynamic Joint-State Graph Construction](https://arxiv.org/abs/2509.07234)
*Yanlin Zhou,Manshi Limbu,Xuesu Xiao*

Main category: cs.MA

TL;DR: 本文提出了一种名为TCGRE的新型多智能体路径寻找问题，并将其转化为3D匹配问题，然后通过JSG、CES和RHOCA*等方法进行求解。此外，还引入了动态图构造方法Dynamic-HJSG，在保持最优性的同时降低了计算复杂度，并在实验中验证了其在可扩展性和性能上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体路径寻找（MAPF）方法主要关注碰撞避免，而忽略了在许多实际应用中，智能体之间需要主动协作以提升团队整体表现。本文旨在解决需要智能体协作以降低高风险边 traversal costs 的问题。

Method: 将TCGRE问题重述为3D匹配问题（包含机器人对、支持对和时间步）。为了解决NP-hard问题，提出了JSG（将协调问题转化为单智能体最短路径问题）、CES（通过穷举配对优化支持分配）和RHOCA*（通过有限视野规划平衡最优性和可扩展性）。此外，还引入了动态图构造方法Dynamic-HJSG，利用智能体同质性剪枝冗余状态，并通过动态构建联合状态图来降低计算开销。

Result: 理论分析表明Dynamic-HJSG在保持最优性的同时，在关键情况下将复杂度从指数级降低到多项式级。实验结果证明了该方法的可扩展性，特别是在处理大规模团队和图时，HJSG在不同大小和类型的图上均显著优于基线方法，运行时间大大缩短。

Conclusion: 本文将组合优化与多智能体规划相结合，为具有可证明保证的协作路径寻找提供了一个原则性框架。TCGRE问题的解决方案核心思想可以广泛应用于其他协作优化问题，例如MAPF。

Abstract: Multi-agent pathfinding (MAPF) traditionally focuses on collision avoidance,
but many real-world applications require active coordination between agents to
improve team performance. This paper introduces Team Coordination on Graphs
with Risky Edges (TCGRE), where agents collaborate to reduce traversal costs on
high-risk edges via support from teammates. We reformulate TCGRE as a 3D
matching problem-mapping robot pairs, support pairs, and time steps-and
rigorously prove its NP-hardness via reduction from Minimum 3D Matching. To
address this complexity, (in the conference version) we proposed efficient
decomposition methods, reducing the problem to tractable subproblems:
Joint-State Graph (JSG): Encodes coordination as a single-agent shortest-path
problem. Coordination-Exhaustive Search (CES): Optimizes support assignments
via exhaustive pairing. Receding-Horizon Optimistic Cooperative A* (RHOCA*):
Balances optimality and scalability via horizon-limited planning. Further in
this extension, we introduce a dynamic graph construction method
(Dynamic-HJSG), leveraging agent homogeneity to prune redundant states and
reduce computational overhead by constructing the joint-state graph
dynamically. Theoretical analysis shows Dynamic-HJSG preserves optimality while
lowering complexity from exponential to polynomial in key cases. Empirical
results validate scalability for large teams and graphs, with HJSG
outperforming baselines greatly in runtime in different sizes and types of
graphs. This work bridges combinatorial optimization and multi-agent planning,
offering a principled framework for collaborative pathfinding with provable
guarantees, and the key idea of the solution can be widely extended to many
other collaborative optimization problems, such as MAPF.

</details>


### [319] [Adaptive Evolutionary Framework for Safe, Efficient, and Cooperative Autonomous Vehicle Interactions](https://arxiv.org/abs/2509.07411)
*Zhen Tian,Zhihao Lin*

Main category: cs.MA

TL;DR: 本文提出了一种基于进化博弈论（EGT）的自动驾驶汽车（AV）交互框架（CEGT），通过去中心化和自适应策略演化机制，并引入因果评估模块（CEGT）优化进化速率，以克服传统方法在复杂场景下的局限性，并在模拟结果中显示出比EGT、Nash和Stackelberg博弈更低的碰撞率、更佳的安全距离、更高的速度和整体性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对现代交通系统中自动驾驶汽车（AVs）交互的挑战，例如缺乏中心化控制、需要在乘客需求和整体交通效率之间取得平衡，以及传统方法（如基于规则、基于优化和基于博弈论的方法）的局限性。

Method: 提出了一种基于进化博弈论（EGT）的框架，并引入了一个因果评估模块（CEGT）来优化进化速率，通过学习历史交互来平衡变异和进化，实现去中心化和自适应的策略演化。

Result: 模拟结果表明，CEGT在碰撞率、安全距离、速度和整体性能方面优于EGT、Nash和Stackelberg博弈。

Conclusion: 所提出的CEGT框架能够有效解决AVs交互中的挑战，并在各种场景下提供优越的性能。

Abstract: Modern transportation systems face significant challenges in ensuring road
safety, given serious injuries caused by road accidents. The rapid growth of
autonomous vehicles (AVs) has prompted new traffic designs that aim to optimize
interactions among AVs. However, effective interactions between AVs remains
challenging due to the absence of centralized control. Besides, there is a need
for balancing multiple factors, including passenger demands and overall traffic
efficiency. Traditional rule-based, optimization-based, and game-theoretic
approaches each have limitations in addressing these challenges. Rule-based
methods struggle with adaptability and generalization in complex scenarios,
while optimization-based methods often require high computational resources.
Game-theoretic approaches, such as Stackelberg and Nash games, suffer from
limited adaptability and potential inefficiencies in cooperative settings. This
paper proposes an Evolutionary Game Theory (EGT)-based framework for AV
interactions that overcomes these limitations by utilizing a decentralized and
adaptive strategy evolution mechanism. A causal evaluation module (CEGT) is
introduced to optimize the evolutionary rate, balancing mutation and evolution
by learning from historical interactions. Simulation results demonstrate the
proposed CEGT outperforms EGT and popular benchmark games in terms of lower
collision rates, improved safety distances, higher speeds, and overall better
performance compared to Nash and Stackelberg games across diverse scenarios and
parameter settings.

</details>


### [320] [Bio-inspired decision making in swarms under biases from stubborn robots, corrupted communication, and independent discovery](https://arxiv.org/abs/2509.07561)
*Raina Zakir,Timoteo Carletti,Marco Dorigo,Andreagiovanni Reina*

Main category: cs.MA

TL;DR:  Minimalistic robot swarms can achieve reliable consensus despite individual errors, with bio-inspired cross-inhibition outperforming direct-switch mechanisms, especially under biased conditions.


<details>
  <summary>Details</summary>
Motivation: Coordinating minimalistic robot swarms for complex tasks is challenging due to communication, computation, and memory constraints, especially with individual robot errors. The study aims to find effective coordination mechanisms for such systems.

Method: The study compares two opinion dynamics mechanisms, direct-switch and cross-inhibition, generalizing mean-field models by including asocial biases. Performance is evaluated based on swarm consensus speed, reliability, accuracy, robustness, and scalability.

Result: Direct-switch mechanisms fail under asocial biases, leading to deadlocks. Cross-inhibition mechanisms demonstrate superior performance, enabling faster, more cohesive, accurate, robust, and scalable decisions across various biased conditions.

Conclusion: Bio-inspired cross-inhibition is a more effective mechanism than direct-switch for coordinating minimalistic robot swarms, particularly in the presence of asocial biases, offering valuable insights for decentralized decision-making systems in both biology and engineering.

Abstract: Minimalistic robot swarms offer a scalable, robust, and cost-effective
approach to performing complex tasks with the potential to transform
applications in healthcare, disaster response, and environmental monitoring.
However, coordinating such decentralised systems remains a fundamental
challenge, particularly when robots are constrained in communication,
computation, and memory. In our study, individual robots frequently make errors
when sensing the environment, yet the swarm can rapidly and reliably reach
consensus on the best among $n$ discrete options. We compare two canonical
mechanisms of opinion dynamics -- direct-switch and cross-inhibition -- which
are simple yet effective rules for collective information processing observed
in biological systems across scales, from neural populations to insect
colonies. We generalise the existing mean-field models by considering asocial
biases influencing the opinion dynamics. While swarms using direct-switch
reliably select the best option in absence of asocial dynamics, their
performance deteriorates once such biases are introduced, often resulting in
decision deadlocks. In contrast, bio-inspired cross-inhibition enables faster,
more cohesive, accurate, robust, and scalable decisions across a wide range of
biased conditions. Our findings provide theoretical and practical insights into
the coordination of minimal swarms and offer insights that extend to a broad
class of decentralised decision-making systems in biology and engineering.

</details>


### [321] [Towards Generalized Routing: Model and Agent Orchestration for Adaptive and Efficient Inference](https://arxiv.org/abs/2509.07571)
*Xiyu Guo,Shan Wang,Chunfang Ji,Xuefeng Zhao,Wenhao Xi,Yaoyao Liu,Qinglan Li,Chao Deng,Junlan Feng*

Main category: cs.MA

TL;DR: MoMA是一个处理多样化用户查询的路由框架，整合了大型语言模型（LLM）和基于代理的路由，以优化性能和效率。


<details>
  <summary>Details</summary>
Motivation: 处理因用户查询多样化、跨越多个领域和任务类型而带来的复杂路由挑战，以准确地将查询引导至合适的执行单元，同时优化性能和效率。

Method: 构建详细的训练数据集来分析不同LLM在不同路由模型结构下的能力，并识别最适合每个LLM的任务。在推理过程中，查询被动态地路由到成本效益最高的LLM。引入基于上下文感知状态机和动态掩码的高效代理选择策略。

Result: 实验结果表明，与现有方法相比，MoMA路由器在成本效益和可扩展性方面表现更优。

Conclusion: MoMA通过精确的意图识别和自适应路由策略，能够有效处理多样化的查询，并在效率和成本之间达到最佳平衡。

Abstract: The rapid advancement of large language models (LLMs) and domain-specific AI
agents has greatly expanded the ecosystem of AI-powered services. User queries,
however, are highly diverse and often span multiple domains and task types,
resulting in a complex and heterogeneous landscape. This diversity presents a
fundamental routing challenge: how to accurately direct each query to an
appropriate execution unit while optimizing both performance and efficiency. To
address this, we propose MoMA (Mixture of Models and Agents), a generalized
routing framework that integrates both LLM and agent-based routing. Built upon
a deep understanding of model and agent capabilities, MoMA effectively handles
diverse queries through precise intent recognition and adaptive routing
strategies, achieving an optimal balance between efficiency and cost.
Specifically, we construct a detailed training dataset to profile the
capabilities of various LLMs under different routing model structures,
identifying the most suitable tasks for each LLM. During inference, queries are
dynamically routed to the LLM with the best cost-performance efficiency. We
also introduce an efficient agent selection strategy based on a context-aware
state machine and dynamic masking. Experimental results demonstrate that the
MoMA router offers superior cost-efficiency and scalability compared to
existing approaches.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [322] [Optimizing Task Scheduling in Fog Computing with Deadline Awareness](https://arxiv.org/abs/2509.07378)
*Mohammad Sadegh Sirjani,Somayeh Sobati-Moghadam*

Main category: cs.DC

TL;DR: 该研究提出了一种名为RIGEO的混合算法，结合了改进的黄金鹰优化（IGEO）和强化学习（RL），用于优化物联网（IoT）任务在雾计算节点上的调度，以降低能耗并提高服务质量（QoS）。


<details>
  <summary>Details</summary>
Motivation: 物联网设备激增，需要低延迟和快速响应的应用，但雾计算在资源分配和任务调度方面面临挑战。因此，需要有效的任务分配和调度算法来降低能耗并提高响应时间。

Method: 将雾节点分为低流量和高流量两类。使用改进的黄金鹰优化（IGEO）算法（一种结合了遗传算子的黄金鹰优化算法）在低流量节点上调度低截止时间任务。使用强化学习（RL）在高流量节点上处理高截止时间任务。这种组合方法被称为强化改进黄金鹰优化（RIGEO）算法。

Result: 与现有算法相比，RIGEO算法在优化系统响应时间、总截止时间违规时间、资源和系统能耗方面表现更优。

Conclusion: RIGEO算法能够有效优化物联网任务在雾计算中的调度，实现能耗最小化和QoS的提升。

Abstract: The rise of Internet of Things (IoT) devices has led to the development of
numerous applications that require quick responses and low latency. Fog
computing has emerged as a solution for processing these IoT applications, but
it faces challenges such as resource allocation and job scheduling. Therefore,
it is crucial to determine how to assign and schedule tasks on Fog nodes. A
well-designed job scheduling algorithm can help decrease energy usage and
improve response times for application requests. This work aims to schedule
tasks in IoT while minimizing the total energy consumption of nodes and
enhancing the Quality of Service (QoS) requirements of IoT tasks, taking into
account task deadlines. Initially, this paper classifies the Fog nodes into two
categories based on their traffic level: low and high. It schedules
low-deadline tasks on low-traffic-level nodes using an Improved Golden Eagle
Optimization (IGEO) algorithm, an enhancement of the Golden Eagle Optimization
Algorithm that utilizes genetic operators for discretization. High-deadline
tasks are processed on high-traffic nodes using reinforcement learning (RL).
This combined approach is called the Reinforcement Improved Golden Eagle
Optimization (RIGEO) algorithm. Experimental results demonstrate that the
proposed algorithms optimize system response time, total deadline violation
time, and resource and system energy consumption compared to other
state-of-the-art algorithms.

</details>


### [323] [Crossword: Adaptive Consensus for Dynamic Data-Heavy Workloads](https://arxiv.org/abs/2509.07157)
*Guanzhou Hu,Yiwei Chen,Andrea Arpaci-Dusseau,Remzi Arpaci-Dusseau*

Main category: cs.DC

TL;DR: Crossword是一种灵活的共识协议，适用于动态数据密集型工作负载，通过实例化的纠删码和智能分片来优化数据传输，并能在动态负载下自适应地调整分片分配和法定人数大小，同时保持可用性。它还通过懒惰的关注者传播机制优雅地处理领导者故障转移。


<details>
  <summary>Details</summary>
Motivation: 云环境中动态数据密集型工作负载的挑战，其复制负载大小差异大且会带来偶发性带宽压力。

Method: Crossword应用实例化的纠删码，并将编码后的分片智能地分发，以显著减少关键路径的数据传输。它能根据动态工作负载和网络条件自适应地调整分片分配和法定人数大小，同时保持可用性。它还采用懒惰的关注者传播机制来处理领导者故障转移。

Result: Crossword在静态场景下的性能与其他协议相当，在动态工作负载和网络条件下性能提升高达2.3倍。与CockroachDB集成后，在5路复制的TPC-C基准测试中，吞吐量提高了1.32倍。

Conclusion: Crossword是一种有效的共识协议，能够显著提升动态数据密集型工作负载下的系统性能和吞吐量。

Abstract: We present Crossword, a flexible consensus protocol for dynamic data-heavy
workloads, a rising challenge in the cloud where replication payload sizes span
a wide spectrum and introduce sporadic bandwidth stress. Crossword applies
per-instance erasure coding and distributes coded shards intelligently to
reduce critical-path data transfer significantly when desirable. Unlike
previous approaches that statically assign shards to servers, Crossword enables
an adaptive tradeoff between the assignment of shards and quorum size in
reaction to dynamic workloads and network conditions, while always retaining
the availability guarantee of classic protocols. Crossword handles leader
failover gracefully by employing a lazy follower gossiping mechanism that
incurs minimal impact on critical-path performance. We implement Crossword
(along with relevant protocols) in Gazette, a distributed, replicated, and
protocol-generic key-value store written in async Rust. We evaluate Crossword
comprehensively to show that it matches the best performance among previous
protocols (MultiPaxos, Raft, RSPaxos, and CRaft) in static scenarios, and
outperforms them by up to 2.3x under dynamic workloads and network conditions.
Our integration of Crossword with CockroachDB brings 1.32x higher aggregate
throughput to TPC-C under 5-way replication. We will open-source Gazette upon
publication.

</details>


### [324] [Bodega: Serving Linearizable Reads Locally from Anywhere at Anytime via Roster Leases](https://arxiv.org/abs/2509.07158)
*Guanzhou Hu,Andrea Arpaci-Dusseau,Remzi Arpaci-Dusseau*

Main category: cs.DC

TL;DR: Bodega是一种新的共识协议，它通过创新的Roster Leases算法实现任意节点上的线性化本地读取，即使在有写入操作干扰的情况下也能保持一致性。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够实现任意节点本地线性化读取的共识协议，以提高读取性能，尤其是在存在写入操作干扰的情况下。

Method: 提出了一种新的Roster Leases算法，该算法维护一个称为Roster的集群元数据，该元数据跟踪副本子集作为本地读取的响应节点。通过Roster Leases算法建立Roster的一致性。协议还采用了乐观持有、早期接受通知、智能Roster覆盖和轻量级心跳等技术来优化性能和实用性。Bodega对写入操作没有特殊要求，只需要响应节点覆盖的法定人数。

Result: 在真实广域网集群上，Bodega的平均客户端读取请求速度比现有方法快5.6倍至13.1倍（在中度写入干扰下）。写入性能相当，支持快速主动的Roster更改和基于Leases的容错。在YCSB工作负载下的性能与etcd和ZooKeeper相当。

Conclusion: Bodega是一种有效的共识协议，能够显著提高读取性能，同时保持可比的写入性能和容错能力，并且易于集成。

Abstract: We present Bodega, the first consensus protocol that serves linearizable
reads locally from any desired node, regardless of interfering writes. Bodega
achieves this via a novel roster leases algorithm that safeguards the roster, a
new notion of cluster metadata. The roster is a generalization of leadership;
it tracks arbitrary subsets of replicas as responder nodes for local reads. A
consistent agreement on the roster is established through roster leases, an
all-to-all leasing mechanism that generalizes existing all-to-one leasing
approaches (Leader Leases, Quorum Leases), unlocking a new point in the
protocol design space. Bodega further employs optimistic holding and early
accept notifications to minimize interruption from interfering writes, and
incorporates smart roster coverage and lightweight heartbeats to maximize
practicality. Bodega is a non-intrusive extension to classic consensus; it
imposes no special requirements on writes other than a responder-covering
quorum. We implement Bodega and related works in Vineyard, a protocol-generic
replicated key-value store written in async Rust. We compare it to previous
protocols (Leader Leases, EPaxos, PQR, and Quorum Leases) and two production
coordination services (etcd and ZooKeeper). Bodega speeds up average client
read requests by 5.6x-13.1x on real WAN clusters versus previous approaches
under moderate write interference, delivers comparable write performance,
supports fast proactive roster changes as well as fault tolerance via leases,
and closely matches the performance of sequentially-consistent etcd and
ZooKeeper deployments across all YCSB workloads. We will open-source Vineyard
upon publication.

</details>


### [325] [A Study on Messaging Trade-offs in Data Streaming for Scientific Workflows](https://arxiv.org/abs/2509.07199)
*Anjus George,Michael J. Brim,Christopher Zimmer,Tyler J. Skluzacek,A. J. Ruckman,Gustav R. Jansen,Sarp Oral*

Main category: cs.DC

TL;DR: 该研究调查了消息队列参数如何影响科学工作流的数据流传输性能，并提供了配置建议。


<details>
  <summary>Details</summary>
Motivation: 现代科学工作流需要近乎实时的内存到内存数据流传输，以实现低延迟、高吞吐量和可靠的数据传输，从而支持实时分析和实验控制。

Method: 通过使用源自 Deleria 和 LCLS 工作流的合成工作负载，在 OLCF 的 Data Streaming to HPC 基础设施的背景下，利用 RabbitMQ 消息队列进行流式传输模拟。

Result: 研究结果揭示了影响数据流传输的关键消息参数及其配置选择，并强调了在可靠消息传输方面的吞吐量权衡。

Conclusion: 该研究通过模拟提供了关于如何配置消息队列以满足不同数据流传输工作负载需求的实用见解。

Abstract: Memory-to-memory data streaming is essential for modern scientific workflows
that require near real-time data analysis, experimental steering, and informed
decision-making during experiment execution. It eliminates the latency
bottlenecks associated with file-based transfers to parallel storage, enabling
rapid data movement between experimental facilities and HPC systems. These
tightly coupled experimental-HPC workflows demand low latency, high throughput,
and reliable data delivery to support on-the-fly analysis and timely feedback
for experimental control. Off-the-shelf messaging frameworks are increasingly
considered viable solutions for enabling such direct memory streaming due to
their maturity, broad adoption, and ability to abstract core messaging and
reliability functionalities from the application layer. However, effectively
meeting the workflows' requirements depends on utilizing the framework's
capabilities and carefully tuning its configurations.
  In this paper, we present a study that investigates the messaging parameters,
and their configuration choices that impact the streaming requirements of two
representative scientific workflows. We specifically characterize throughput
trade-offs associated with reliable message transmission for these workflows.
Our study is conducted through streaming simulations using synthetic workloads
derived from the Deleria and LCLS workflows, employing the RabbitMQ messaging
framework within the context of the Data Streaming to HPC infrastructure at
OLCF. Our simulations reveal several key observations and practical insights
that help users understand which configurations best meet the needs of their
streaming workloads.

</details>


### [326] [DuoServe-MoE: Dual-Phase Expert Prefetch and Cache Scheduling for Efficient MoE LLM Inference](https://arxiv.org/abs/2509.07379)
*Yuning Zhang,Grant Pinkert,Nan Yang,Yanli Li,Dong Yuan*

Main category: cs.DC

TL;DR: DuoServe-MoE是一个推理服务系统，通过分离预填充和解码阶段并采用定制的专家调度策略，显著提高了MoE LLM的推理效率，降低了内存占用。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE LLM推理方法在处理预填充和解码两个计算阶段时采用统一的策略，导致延迟和内存使用不理想，尤其是在资源受限的环境下。

Method: DuoServe-MoE在预填充阶段采用双流CUDA流水线，将专家权重预取与非MoE层计算重叠，以减少专家在GPU内存中的驻留；在解码阶段，利用一个轻量级的离线训练的层级预测器来预取最有可能被激活的专家。

Result: 在4位Mixtral-8x7B和8x22B模型上的实验表明，DuoServe-MoE将端到端延迟提高了1.42至7.54倍，同时将峰值内存使用量保持在模型总大小的15%。

Conclusion: DuoServe-MoE通过针对预填充和解码阶段的特定需求设计专门的专家调度策略，有效地解决了MoE LLM推理中的延迟和内存瓶颈问题。

Abstract: Large Language Models (LLMs) have demonstrated impressive performance across
a wide range of deep learning tasks. Mixture of Experts (MoE) further enhances
their capabilities by increasing model width through sparsely activated expert
branches, which keeps inference computation efficient. However, the large
number of expert weights introduces significant GPU memory pressure, especially
in resource-constrained environments such as single-GPU servers. More
importantly, MoE inference consists of two fundamentally different stages: a
prefill stage where most experts are activated densely, and a decode stage
where only a few experts are triggered sparsely. Treating these stages with a
uniform scheduling strategy often leads to suboptimal latency and memory usage.
To address this, we propose DuoServe-MoE, an inference serving system that
explicitly separates prefill and decode stages and applies tailored expert
scheduling strategies to each. In the prefill stage, DuoServe-MoE uses a
two-stream CUDA pipeline that overlaps expert weight prefetching with the
computation of non-MoE layers, limiting expert residency in GPU memory. In the
decode stage, a lightweight layer-level predictor trained offline from
activation traces is used to prefetch only the most likely activated experts,
without requiring any changes to the model. Experiments on 4-bit Mixtral-8x7B
and 8x22B models show that DuoServe-MoE improves end-to-end latency by 1.42 to
7.54 times while keeping peak memory usage at only 15 percent of the full model
size.

</details>


### [327] [Dependency-Aware Execution Mechanism in Hyperledger Fabric Architecture](https://arxiv.org/abs/2509.07425)
*Sanyam Kaul,Manaswini Piduguralla,Gayathri Shreeya Patnala,Sathya Peri*

Main category: cs.DC

TL;DR: 通过引入依赖感知执行模型，改进了 Hyperledger Fabric 的性能，提高了吞吐量并降低了交易拒绝率。


<details>
  <summary>Details</summary>
Motivation: Hyperledger Fabric 在高负载下存在交易吞吐量低和拒绝率高的问题，这归因于背书、排序和验证瓶颈，以及乐观并发控制和延迟验证导致的资源低效和冲突。

Method: 提出了一种依赖感知执行模型，包括：(a) 在背书阶段使用哈希图进行依赖标记；(b) 优化排序服务中的区块构造以优先处理独立交易；(c) 在每个区块中引入有向无环图（DAG）来表示依赖关系；(d) 并行执行独立交易，并根据 DAG 顺序处理依赖交易。

Result: 在 Hyperledger Fabric v2.5 中集成该框架，并在不同依赖级别和系统负载下进行了测试，结果显示吞吐量提高了 40%，高冲突场景下的拒绝率显著降低。

Conclusion: 依赖感知调度和基于 DAG 的执行可以显著提高 Fabric 的可扩展性，同时保持与现有共识和智能合约层的兼容性。

Abstract: Hyperledger Fabric is a leading permissioned blockchain framework for
enterprise use, known for its modular design and privacy features. While it
strongly supports configurable consensus and access control, Fabric can face
challenges in achieving high transaction throughput and low rejection rates
under heavy workloads. These performance limitations are often attributed to
endorsement, ordering, and validation bottlenecks. Further, optimistic
concurrency control and deferred validation in Fabric may lead to resource
inefficiencies and contention, as conflicting transactions are identified only
during the commit phase. To address these challenges, we propose a
dependency-aware execution model for Hyperledger Fabric. Our approach includes:
(a) a dependency flagging system during endorsement, marking transactions as
independent or dependent using a hashmap; (b) an optimized block construction
in the ordering service that prioritizes independent transactions; (c) the
incorporation of a Directed Acyclic Graph (DAG) within each block to represent
dependencies; and (d) parallel execution of independent transactions at the
committer, with dependent transactions processed according to DAG order.
Incorporated in Hyperledger Fabric v2.5, our framework was tested on workloads
with varying dependency levels and system loads. Results show up to 40% higher
throughput and significantly reduced rejection rates in high-contention
scenarios. This demonstrates that dependency-aware scheduling and DAG-based
execution can substantially enhance Fabric's scalability while remaining
compatible with its existing consensus and smart contract layers.

</details>


### [328] [DREAMS: Decentralized Resource Allocation and Service Management across the Compute Continuum Using Service Affinity](https://arxiv.org/abs/2509.07497)
*Hai Dinh-Tuan,Tien Hung Nguyen,Sanjeet Raj Pandey*

Main category: cs.DC

TL;DR: DREAMS是一个去中心化的框架，用于在计算连续体中优化微服务部署，特别适用于现代制造环境。


<details>
  <summary>Details</summary>
Motivation: 传统的集中式资源分配方法在响应动态工作负载和定制化生产需求方面存在扩展性、延迟和单点故障问题。

Method: 提出DREAMS框架，采用去中心化的方法，通过自主运行的代理、基于Raft共识算法和成本效益投票进行全局协调，以优化微服务在分布式、异构计算域中的部署。

Result: DREAMS实现了全局优化的服务部署，同时保持高容错性，并且协调操作（如LDM注册和迁移投票）具有亚线性扩展性。

Conclusion: DREAMS提供了一种响应迅速、保护隐私且容错的去中心化协调方法，能够有效应对计算连续体中日益增多的多方参与场景，特别是在现代制造环境中。

Abstract: Modern manufacturing systems require adaptive computing infrastructures that
can respond to highly dynamic workloads and increasingly customized production
demands. The compute continuum emerges as a promising solution, enabling
flexible deployment of microservices across distributed, heterogeneous domains.
However, this paradigm also requires a novel approach to resource allocation
and service placement, as traditional centralized solutions struggle to scale
effectively, suffer from latency bottlenecks, and introduce single points of
failure. In this paper, we present DREAMS, a decentralized framework that
optimizes microservice placement decisions collaboratively across different
computational domains. At its core, DREAMS introduces agents that operate
autonomously within each domain while coordinating globally through a
Raft-based consensus algorithm and cost-benefit voting. This decentralized
architecture enables responsive, privacy-preserving, and fault-tolerant
coordination, making it particularly suitable given the growing prevalence of
multi-stakeholder scenarios across the compute continuum. In particular, within
modern manufacturing environments, DREAMS achieves globally optimized service
placements while maintaining high fault tolerance. Further evaluations
demonstrate that key coordination operations, such as Local Domain Manager
(LDM) registration and migration voting, scale sub-linearly with the number of
domains, confirming the efficiency and scalability of our proposal.

</details>


### [329] [Astra: A Multi-Agent System for GPU Kernel Performance Optimization](https://arxiv.org/abs/2509.07506)
*Anjiang Wei,Tianran Sun,Yogesh Seenichamy,Hang Song,Anne Ouyang,Azalia Mirhoseini,Ke Wang,Alex Aiken*

Main category: cs.DC

TL;DR: Astra是一个多智能体LLM系统，用于优化GPU内核，通过迭代代码生成、测试、分析和规划，实现了1.32倍的平均加速。


<details>
  <summary>Details</summary>
Motivation: GPU内核优化对于加速大语言模型（LLM）的训练和 serving 至关重要，但手动优化耗时耗力。现有的编译器系统仍需大量手动设计，而先前基于LLM的方法主要集中在将PyTorch模块转换为CUDA代码。

Method: Astra是一个多智能体LLM系统，它以前沿的CUDA实现为起点，通过专门的LLM智能体协作，进行迭代的代码生成、测试、分析和规划，以生成正确且高性能的内核。

Result: Astra在SGLang的内核上实现了1.32倍的平均加速，并且能够自主地进行循环变换、优化内存访问模式、利用CUDA内置函数和快速数学运算。

Conclusion: 多智能体LLM系统为GPU内核优化提供了一个有前景的新范式。

Abstract: GPU kernel optimization has long been a central challenge at the intersection
of high-performance computing and machine learning. Efficient kernels are
crucial for accelerating large language model (LLM) training and serving, yet
attaining high performance typically requires extensive manual tuning.
Compiler-based systems reduce some of this burden, but still demand substantial
manual design and engineering effort. Recently, researchers have explored using
LLMs for GPU kernel generation, though prior work has largely focused on
translating high-level PyTorch modules into CUDA code. In this work, we
introduce Astra, the first LLM-based multi-agent system for GPU kernel
optimization. Unlike previous approaches, Astra starts from existing CUDA
implementations extracted from SGLang, a widely deployed framework for serving
LLMs, rather than treating PyTorch modules as the specification. Within Astra,
specialized LLM agents collaborate through iterative code generation, testing,
profiling, and planning to produce kernels that are both correct and
high-performance. On kernels from SGLang, Astra achieves an average speedup of
1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study
further demonstrates that LLMs can autonomously apply loop transformations,
optimize memory access patterns, exploit CUDA intrinsics, and leverage fast
math operations to yield substantial performance gains. Our work highlights
multi-agent LLM systems as a promising new paradigm for GPU kernel
optimization.

</details>


### [330] [Navigating Energy Doldrums: Modeling the Impact of Energy Price Volatility on HPC Cost of Ownership](https://arxiv.org/abs/2509.07567)
*Peter Arzt,Felix Wolf*

Main category: cs.DC

TL;DR: 通过动态调整计算资源以应对波动的电价，探索了可变容量作为管理高性能计算（HPC）能源成本的策略，并提出了一个模型来评估该策略的总体拥有成本（TCO）影响。


<details>
  <summary>Details</summary>
Motivation: 能源成本是高性能计算（HPC）系统总体拥有成本（TCO）的一个主要因素。间歇性绿色能源的兴起和对化石燃料依赖的减少导致电力市场波动，使能源预算复杂化。

Method: 提出一个简单的模型，利用关键系统参数帮助运算符评估可变容量策略的TCO影响，并将其应用于大学HPC集群的实际数据。

Result: 评估了不同场景下该方法在未来对成本效益的潜在影响。

Conclusion: 虽然可变容量策略可以通过降低能源费用来节省成本，但存在低估昂贵硬件利用率的风险。所提出的模型有助于量化这种权衡。

Abstract: Energy costs are a major factor in the total cost of ownership (TCO) for
high-performance computing (HPC) systems. The rise of intermittent green energy
sources and reduced reliance on fossil fuels have introduced volatility into
electricity markets, complicating energy budgeting. This paper explores
variable capacity as a strategy for managing HPC energy costs - dynamically
adjusting compute resources in response to fluctuating electricity prices.
While this approach can lower energy expenses, it risks underutilizing costly
hardware. To evaluate this trade-off, we present a simple model that helps
operators estimate the TCO impact of variable capacity strategies using key
system parameters. We apply this model to real data from a university HPC
cluster and assess how different scenarios could affect the cost-effectiveness
of this approach in the future.

</details>


### [331] [AgentX: Towards Orchestrating Robust Agentic Workflow Patterns with FaaS-hosted MCP Services](https://arxiv.org/abs/2509.07595)
*Shiva Sai Krishna Anand Tokal,Vaibhav Jha,Anand Eswaran,Praveen Jayachandran,Yogesh Simmhan*

Main category: cs.DC

TL;DR: GenAI 结合工具使用能力，AgentX 是一种新的 Agentic 系统，在性能、延迟和成本方面与 ReAct 和 Magentic One 相当或更优，并提出 FaaS 部署 MCP 服务器的方法。


<details>
  <summary>Details</summary>
Motivation: Agentic AI 虽然强大，但在面对多工具、复杂任务和长上下文时存在挑战，需要新的工作流模式来解决。

Method: 提出 AgentX 工作流模式，包含阶段设计者、规划者和执行者代理，并提出 FaaS 部署 MCP 服务器的两种方法，与 ReAct 和 Magentic One 进行实验对比。

Result: AgentX 在成功率、延迟和成本方面与 ReAct 和 Magentic One 相当或更优，展示了 FaaS 部署的有效性。

Conclusion: AgentX 是一种有竞争力的新型 Agentic 工作流模式，FaaS 部署 MCP 服务器是可行的，但仍存在设计和部署方面的机遇与挑战。

Abstract: Generative Artificial Intelligence (GenAI) has rapidly transformed various
fields including code generation, text summarization, image generation and so
on. Agentic AI is a recent evolution that further advances this by coupling the
decision making and generative capabilities of LLMs with actions that can be
performed using tools. While seemingly powerful, Agentic systems often struggle
when faced with numerous tools, complex multi-step tasks,and long-context
management to track history and avoid hallucinations. Workflow patterns such as
Chain-of-Thought (CoT) and ReAct help address this. Here, we define a novel
agentic workflow pattern, AgentX, composed of stage designer, planner, and
executor agents that is competitive or better than the state-of-the-art agentic
patterns. We also leverage Model Context Protocol (MCP) tools, and propose two
alternative approaches for deploying MCP servers as cloud Functions as a
Service (FaaS). We empirically evaluate the success rate, latency and cost for
AgentX and two contemporary agentic patterns, ReAct and Magentic One, using
these the FaaS and local MCP server alternatives for three practical
applications. This highlights the opportunities and challenges of designing and
deploying agentic workflows.

</details>


### [332] [Scaling atomic ordering in shared memory](https://arxiv.org/abs/2509.07781)
*Lorenzo Martignetti,Eliã Batista,Gianpaolo Cugola,Fernando Pedone*

Main category: cs.DC

TL;DR: TRAM是一个为共享内存系统设计的原子多播协议，性能优于现有协议。


<details>
  <summary>Details</summary>
Motivation: 开发用于共享内存系统的原子多播协议，以支持需要复制和分片的关键服务，实现容错和可扩展性。

Method: 设计了一个利用覆盖树结构的原子多播协议TRAM。

Result: 与最先进的共享内存协议相比，吞吐量提高超过3倍，延迟降低超过2.3倍。与基于消息传递的协议相比，吞吐量提高高达5.9倍，延迟降低高达106倍。

Conclusion: TRAM通过其简单实用的设计，在共享内存环境中实现了卓越的原子多播性能。

Abstract: Atomic multicast is a communication primitive used in dependable systems to
ensure consistent ordering of messages delivered to a set of replica groups.
This primitive enables critical services to integrate replication and sharding
(i.e., state partitioning) to achieve fault tolerance and scalability. While
several atomic multicast protocols have been developed for message-passing
systems, only a few are designed for the shared memory system model. This paper
introduces TRAM, an atomic multicast protocol specifically designed for shared
memory systems, leveraging an overlay tree architecture. Due to its simple and
practical design, TRAM delivers exceptional performance, increasing throughput
by more than 3$\times$ and reducing latency by more than 2.3$\times$ compared
to state-of-the-art shared memory-based protocols. Additionally, it
significantly outperforms message-passing-based protocols, boosting throughput
by up to 5.9$\times$ and reducing latency by up to 106$\times$.

</details>


### [333] [VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing for Energy-Efficient LLM Serving](https://arxiv.org/abs/2509.04827)
*Jiahuan Yu,Aryan Taneja,Junfeng Lin,Minjia Zhang*

Main category: cs.DC

TL;DR: VoltanaLLM通过结合频率调整和请求路由，在LLM服务中实现了高达36.3%的节能，同时保持了近乎完美的SLO（服务水平目标）达成率。


<details>
  <summary>Details</summary>
Motivation: LLM推理的高能耗给可持续和成本效益的部署带来了挑战，特别是在支持实时交互式应用程序方面。

Method: VoltanaLLM利用控制理论，协同设计了频率缩放和请求路由，特别是在预填充/解码分离的架构中。它包含一个反馈驱动的频率控制器，动态调整GPU频率，以及一个状态空间路由器，用于在不同频率的实例之间做出路由决策，以在延迟限制内最大限度地降低能耗。

Result: 在多种先进LLM和真实数据集上的评估显示，VoltanaLLM能够实现高达36.3%的节能，同时几乎完全满足SLO。

Conclusion: VoltanaLLM为实现可持续和智能的LLM服务提供了一种有效的方法，通过细粒度的、特定于阶段的控制来解决能耗问题。

Abstract: Modern Large Language Model (LLM) serving systems increasingly support
interactive applications, like real-time chat assistants, code generation
tools, and agentic workflows. However, the soaring energy cost of LLM inference
presents a growing challenge for sustainable and cost-effective deployment.
This paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM
serving, built from a control theory perspective. VoltanaLLM co-designs
frequency scaling and request routing in emerging prefill/decode disaggregated
architectures, leveraging their decoupled execution to enable fine-grained
phase-specific control. It consists of a feedback-driven frequency controller
that dynamically adapts GPU frequency for prefill and decode phases, and a
state-space router that explores routing decisions across frequency-scaled
instances to minimize energy under latency constraints. We implement VoltanaLLM
in SGLang and evaluate its performance over multiple state-of-the-art LLMs and
real-world datasets. The results demonstrate that VoltanaLLM achieves up to
36.3% energy savings while maintaining near-perfect SLO attainment rate, paving
the way for sustainable and intelligent LLM serving.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [334] [Design of Input-Output Observers for a Population of Systems with Bounded Frequency-Domain Variation using $DK$-iteration](https://arxiv.org/abs/2509.07201)
*Timothy Everett Adams,James Richard Forbes*

Main category: eess.SY

TL;DR: 该研究提出了一种用于系统群的线性输入-输出观测器设计方法，该方法能够为具有不同特性的设备合成一个单一的、鲁棒的校正滤波器，并保证给定的估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有的观测器设计方法通常需要针对每个系统模型单独设计校正器，对于具有模型变化（如机器人关节刚度变化）的系统群来说，这并不高效。本研究旨在提出一种能够处理模型不确定性的方法，为整个系统群设计一个通用的观测器。

Method: 通过在频域中表征系统模型的变化范围，并利用 $DK$-迭代技术求解一个鲁棒性能问题，来合成一个单一的、鲁棒的校正滤波器。该滤波器能够兼容所有满足变化表征的系统模型，并保证估计性能。

Result: 实验结果表明，该方法设计的单一校正滤波器在估计性能上可以与为每个特定关节刚度配置定制的校正器相媲美，证明了该方法的有效性。

Conclusion: 所提出的线性输入-输出观测器设计方法能够为具有模型不确定性的系统群生成一个单一的、鲁棒的校正滤波器，在保证估计性能的同时，提高了设计的效率和通用性。

Abstract: This paper proposes a linear input-output observer design methodology for a
population of systems in which each observer uses knowledge of the linear
time-invariant dynamics of the particular device. Observers are typically
composed of a known model of the system and a correction mechanism to produce
an estimate of the state. The proposed design procedure characterizes the
variation within the population in the frequency domain and synthesizes a
single robust correction filter. The correction filter is compatible with all
system models that satisfy the variation characterization such that a given
level of estimation performance is guaranteed. This is accomplished by posing a
robust performance problem using the observer error dynamics and solving it
using $DK$-iteration. The design procedure is experimentally demonstrated on a
flexible joint robotic manipulator with varied joint stiffnesses. It is shown
that the proposed method that uses a single correction filter achieves
comparable estimation performance to a method that uses a correction gain
tailored toward each joint stiffness configuration.

</details>


### [335] [Extended Version: Market-Driven Equilibria for Distributed Solar Panel Investment](https://arxiv.org/abs/2509.07203)
*Mehdi Davoudi,Junjie Qin,Xiaojun Lin*

Main category: eess.SY

TL;DR: 研究关注个体投资者在分布式太阳能电池板上的市场驱动的长期投资决策，重点分析了不同市场机制（单一产品实时能源市场、产品差异化实时能源市场、基于合同的电池板市场）对投资的影响，并通过理论分析和数值实验验证了产品差异化市场能支持社会最优投资，单一产品市场会导致投资不足，而基于合同的市场在用户对太阳能的额外估值较低时会导致投资过度。


<details>
  <summary>Details</summary>
Motivation: 分析在短期电力市场下，个体投资者在分布式太阳能电池板上的长期投资决策。

Method: 使用非原子博弈模型，构建一个连接短期市场均衡和长期投资均衡的框架，并分析三种不同的市场机制（单一产品实时能源市场、产品差异化实时能源市场、基于合同的电池板市场）。

Result: 推导了三种市场机制下的短期均衡和预期收入，并分析了相应的长期纳什均衡总容量。产品差异化市场支持社会最优投资，单一产品市场导致投资不足，基于合同的市场在某些条件下导致投资过度。

Conclusion: 产品差异化市场在支持社会最优投资方面表现最佳，而单一产品市场存在投资不足的问题。基于合同的市场在特定条件下可能导致投资过度，表明市场机制设计对分布式太阳能投资决策至关重要。

Abstract: This study investigates market-driven long-term investment decisions in
distributed solar panels by individual investors. We consider a setting where
investment decisions are driven by expected revenue from participating in
short-term electricity markets over the panel's lifespan. These revenues depend
on short-term markets equilibria, i.e., prices and allocations, which are
influenced by aggregate invested panel capacity participating in the markets.
We model the interactions among investors by a non-atomic game and develop a
framework that links short-term markets equilibria to the resulting long-term
investment equilibrium. Then, within this framework, we analyze three market
mechanisms: (a) a single-product real-time energy market, (b) a
product-differentiated real-time energy market that treats solar energy and
grid energy as different products, and (c) a contract-based panel market that
trades claims or rights to the production of certain panel capacity ex-ante,
rather than the realized solar production ex-post. For each, we derive
expressions for short-term equilibria and the associated expected revenues, and
analytically characterize the corresponding long-term Nash equilibrium
aggregate capacity. We compare the solutions of these characterizing equations
under different conditions and theoretically establish that the
product-differentiated market always supports socially optimal investment,
while the single-product market consistently results in under-investment. We
also establish that the contract-based market leads to over-investment when the
extra valuations of users for solar energy are small. Finally, we validate our
theoretical findings through numerical experiments.

</details>


### [336] [Multi-Topic Projected Opinion Dynamics for Resource Allocation](https://arxiv.org/abs/2509.07847)
*Prashil Wankhede,Nirabhra Mandal,Sonia Martínez,Pavankumar Tallapragada*

Main category: eess.SY

TL;DR: The paper proposes a model for opinion formation regarding resource allocation, considering multiple agents, topics, and budget constraints. It uses a projected dynamical system based on utility maximization and shows opinions converge to an equilibrium, with a unique equilibrium under specific network conditions. The opinion formation game is identified as a potential game, and its Nash equilibria are characterized.


<details>
  <summary>Details</summary>
Motivation: The paper aims to model opinion formation on resource allocation among multiple agents with budget constraints, exploring how social and resource constraints influence opinion evolution and equilibrium states.

Method: A projected dynamical system model is derived based on agents myopically maximizing utility under constraints. Inter-agent coupling is modeled via a social network, and inter-topic coupling via resource constraints. The opinion formation game is shown to be a potential game, and its Nash equilibria are analyzed.

Result: Opinions are shown to always converge to the equilibrium set. For certain networks with weak antagonistic relations, opinions converge to a unique equilibrium point. The unique Nash equilibrium is characterized for networks without antagonistic relations.

Conclusion: The study successfully models opinion formation under resource allocation constraints, demonstrating convergence to equilibrium. It highlights the role of network structure and identifies the game as a potential game, providing insights into equilibrium and Nash equilibrium characteristics.

Abstract: We propose a model of opinion formation on resource allocation among multiple
topics by multiple agents, who are subject to hard budget constraints. We
define a utility function for each agent and then derive a projected dynamical
system model of opinion evolution assuming that each agent myopically seeks to
maximize its utility subject to its constraints. Inter-agent coupling arises
from an undirected social network, while inter-topic coupling arises from
resource constraints. We show that opinions always converge to the equilibrium
set. For special networks with very weak antagonistic relations, the opinions
converge to a unique equilibrium point. We further show that the underlying
opinion formation game is a potential game. We relate the equilibria of the
dynamics and the Nash equilibria of the game and characterize the unique Nash
equilibrium for networks with no antagonistic relations. Finally, simulations
illustrate our findings.

</details>


### [337] [Electricity Demand and Grid Impacts of AI Data Centers: Challenges and Prospects](https://arxiv.org/abs/2509.07218)
*Xin Chen,Xiaoyang Wang,Ana Colacelli,Matt Lee,Le Xie*

Main category: eess.SY

TL;DR: AI数据中心耗电量激增给电网带来挑战，本文全面回顾了AI数据中心的电力需求特征、对电网的影响以及潜在解决方案，旨在促进AI和电网的可持续发展。


<details>
  <summary>Details</summary>
Motivation: AI的快速发展导致AI数据中心用电量激增，对电力系统造成了严峻挑战，因此理解AI数据中心负载的特征及其与电网的相互作用对于保障电力系统的可靠运行和AI的可持续发展至关重要。

Method: 本文对AI数据中心基础设施及其关键组成部分进行了概述，分析了模型准备、训练、微调和推理等不同阶段的用电特征和模式，并探讨了AI数据中心负载在长期规划、短期运行和实时动态三个时间尺度上对电力系统构成的挑战。最后，本文从电网、AI数据中心和AI终端用户的角度讨论了潜在的解决方案。

Result: 本文全面回顾了AI数据中心的电力需求特征、对电网的影响以及潜在解决方案，为AI数据中心和电力系统的协同发展提供了研究方向和发展蓝图。

Conclusion: 本文旨在通过综合现有知识并勾画未来方向，为AI数据中心和电力系统的可靠、高效和可持续运行提供指导。

Abstract: The rapid growth of artificial intelligence (AI) is driving an unprecedented
increase in the electricity demand of AI data centers, raising emerging
challenges for electric power grids. Understanding the characteristics of AI
data center loads and their interactions with the grid is therefore critical
for ensuring both reliable power system operation and sustainable AI
development. This paper provides a comprehensive review and vision of this
evolving landscape. Specifically, this paper (i) presents an overview of AI
data center infrastructure and its key components, (ii) examines the key
characteristics and patterns of electricity demand across the stages of model
preparation, training, fine-tuning, and inference, (iii) analyzes the critical
challenges that AI data center loads pose to power systems across three
interrelated timescales, including long-term planning and interconnection,
short-term operation and electricity markets, and real-time dynamics and
stability, and (iv) discusses potential solutions from the perspectives of the
grid, AI data centers, and AI end-users to address these challenges. By
synthesizing current knowledge and outlining future directions, this review
aims to guide research and development in support of the joint advancement of
AI data centers and power systems toward reliable, efficient, and sustainable
operation.

</details>


### [338] [Learning Neural Koopman Operators with Dissipativity Guarantees](https://arxiv.org/abs/2509.07294)
*Yuezhu Xu,S. Sivaranjani,Vijay Gupta*

Main category: eess.SY

TL;DR: 学习一个具有耗散性保证的神经库普曼模型来近似未知非线性动力学系统，并通过理论和仿真进行验证。


<details>
  <summary>Details</summary>
Motivation: 学习一个能够保证耗散性的神经库普曼模型，以处理已知的耗散非线性动力学系统。

Method: 提出一个两阶段方法：首先学习一个无约束的神经库普曼模型来近似系统动力学，然后微调参数以强制执行严格的耗散性，并推导出模型耗散性与真实系统耗散性之间的精确关系。

Result: 在杜芬振子模型上通过仿真验证了该方法的有效性。

Conclusion: 所提出的方法能够学习到具有耗散性保证的神经库普曼模型，并且该耗散性可以推广到原始的非线性系统中。

Abstract: We address the problem of learning a neural Koopman operator model that
provides dissipativity guarantees for an unknown nonlinear dynamical system
that is known to be dissipative. We propose a two-stage approach. First, we
learn an unconstrained neural Koopman model that closely approximates the
system dynamics. Then, we minimally perturb the parameters to enforce strict
dissipativity. Crucially, we establish theoretical guarantees that extend the
dissipativity properties of the learned model back to the original nonlinear
system. We realize this by deriving an exact relationship between the
dissipativity of the learned model and the true system through careful
characterization of the identification errors from the noisy data, Koopman
operator truncation, and generalization to unseen data. We demonstrate our
approach through simulation on a Duffing oscillator model.

</details>


### [339] [Distributed Leader-Follower Consensus for Uncertain Multiagent Systems with Time-Triggered Switching of the Communication Network](https://arxiv.org/abs/2509.07304)
*Armel Koulong,Ali Pakniyat*

Main category: eess.SY

TL;DR: 该研究提出了一种分布式自适应控制策略，用于处理具有时变通信拓扑的异构多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 为具有时变通信拓扑的异构多智能体系统设计一种能够保证安全性和达成共识的分布式自适应控制策略。

Method: 采用排斥势函数保证智能体与障碍物的安全性，利用神经网络估计器处理系统不确定性和扰动，并应用高阶控制障碍函数框架来认证安全集和控制输入的有界性。结合驻留时间要求，实现了分布式控制和自适应律。

Result: 成功实现了智能体的领导跟随共识，并在变化的通信拓扑下实现了同步编队和鲁棒的扰动抑制。

Conclusion: 所提出的集成化设计能够有效处理异构多智能体系统在时变拓扑下的安全性和一致性问题，并通过仿真验证了其有效性。

Abstract: A distributed adaptive control strategy is developed for heterogeneous
multiagent systems in nonlinear Brunovsky form with \({\pd}\)-dimensional
$n^{\text{th}}$-order dynamics, operating under time-triggered switching
communication topologies. The approach uses repulsive potential functions to
ensure agent-agent and obstacle safety, while neural network estimators
compensate for system uncertainties and disturbances. A high-order control
barrier function framework is then employed to certify the positive invariance
of the safe sets and the boundedness of the proposed control inputs. The
resulting distributed control and adaptive laws, together with dwell-time
requirements for topology transitions, achieve leader-following consensus. This
integrated design provides synchronized formation and robust disturbance
rejection in evolving network configurations, and its effectiveness is
demonstrated through numerical simulations.

</details>


### [340] [Data-knowledge fusion driven frequency security assessment: A robust framework for renewable-dominated power grids](https://arxiv.org/abs/2509.07320)
*Yurun Zhang,Wei Yao,Yutian Lan,Hang Shuai,Shanyang Wei,Wei Gan,Chao Duan,Jinyu Wen,Shijie Cheng*

Main category: eess.SY

TL;DR: 可再生能源主导的电网因惯量低和频率响应非线性而面临频率不安全的风险。本研究提出了一种数据-知识融合框架，通过结合物理引导知识和物理约束知识，利用双通道神经网络和融合训练算法来提高频率安全评估（FSA）的准确性、可靠性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现代以可再生能源为主的电网由于惯量低和频率响应非线性，面临日益增长的频率不安全风险。为了缓解这些风险，必须进行鲁棒的故障前频率安全评估（FSA），以便电网运营商能够实施预防性控制策略。

Method: 提出了一种数据-知识融合框架，该框架包含：1）物理引导知识，用于神经网络预训练，以确保预测与频率响应机制一致；2）物理约束知识，用于量化约束预测，使其在理论范围内；3）双通道神经网络架构，用于同时捕获电网的局部和全局特征；4）数据-知识融合训练算法，集成了引导学习和约束网络架构。

Result: 该框架在云南省电力系统进行了案例研究，平均预测误差降低到1.26%（比纯数据驱动方法提高了49.2%），在未训练场景下保持了97.60%的准确率（比纯数据驱动方法提高了3.85%）。

Conclusion: 所提出的框架提高了电网频率安全评估的准确性、可靠性和泛化能力，满足了实际电网的要求，并为跨领域安全评估提供了新的方法。

Abstract: Frequency security is critical for power grids, as deviations can trigger
widespread outages and result in substantial economic losses. However, modern
renewable-dominated power grids face an increased risk of insecurity due to low
inertia and nonlinear frequency responses. To mitigate these risks, robust
pre-fault frequency security assessment (FSA) is critical, which enables grid
operators to implement preventive control strategies. We propose a
data-knowledge fusion framework to achieve intelligent FSA in actual power
grids. First, we classify FSA domain knowledge into two distinct categories:
(1) physics-guided knowledge directs the neural network pre-training process,
ensuring that the fusion model's predictions consistent with frequency response
mechanisms, and (2) physics-constrained knowledge establishes quantitative
relationship on predictions, which forces them within theoretical ranges
defined by domain knowledge. Furthermore, we develop a dual-channel neural
network architecture to simultaneously capture both local and global
characteristics of the power system. Finally, we introduce a data-knowledge
fusion training algorithm that integrates guided learning with constrained
network architecture to enhance model reliability and generalization. Case
studies on China's Yunnan Provincial Power Grid validate the superior
performance of our framework: it reduces average prediction error to 1.26% (a
49.2% reduction over data-driven methods), and maintains 97.60% accuracy in
untrained scenarios (3.85% higher than data-driven methods), therefore
satisfies the accuracy, reliability, and generalization requirements for actual
power grids. The proposed methodology establishes a new paradigm for enhancing
robustness of FSA in power grids, with potential application to cross-domain
security assessment.

</details>


### [341] [Distributed Frequency Control for Multi-Area Power Systems Considering Transient Frequency Safety](https://arxiv.org/abs/2509.07345)
*Xiemin Mo,Tao Liu*

Main category: eess.SY

TL;DR: 该研究提出了一种新颖的分布式频率控制方法，用于解决高渗透率可再生能源引起的电网频率波动问题，该方法结合了反馈优化控制器和安全校正器，以确保瞬态频率安全、恢复稳态频率并满足容量约束，同时实现经济运行。


<details>
  <summary>Details</summary>
Motivation: 高渗透率可再生能源导致多区域电力系统频率波动加剧，对稳定性和运行安全构成挑战。

Method: 提出了一种结合反馈优化（FO）控制器和安全校正器的新颖分布式频率控制方法。FO控制器通过求解优化问题生成参考设定点，以实现最优稳态运行。安全校正器利用控制屏障函数修改参考设定点，以在瞬态过程中将频率维持在安全范围内，并遵守容量约束。

Result: 仿真研究表明，与传统的基于FO的方案相比，该方法能够始终强制执行频率安全和容量限制，实现更小的频率偏差和更快的恢复速度。

Conclusion: 该方法结合了低计算负担、改进的调控性能和增强的实用性。理论分析证明了闭环系统的最优性、渐近稳定性和瞬态频率安全性，仿真结果验证了其在实际应用中的有效性和优势。

Abstract: High penetration of renewable energy sources intensifies frequency
fluctuations in multi-area power systems, challenging both stability and
operational safety. This paper proposes a novel distributed frequency control
method that ensures transient frequency safety and enforces generation capacity
constraints, while achieving steady-state frequency restoration and optimal
economic operation. The method integrates a feedback optimization (FO)-based
controller and a safety corrector. The FO-based controller generates reference
setpoints by solving an optimization problem, driving the system to the steady
state corresponding to the optimal solution of this problem. The safety
corrector then modifies these references using control barrier functions to
maintain frequencies within prescribed safe bounds during transients while
respecting capacity constraints. The proposed method combines low computational
burden with improved regulation performance and enhanced practical
applicability. Theoretical analysis establishes optimality, asymptotic
stability, and transient frequency safety for the closed-loop system.
Simulation studies show that, compared with conventional FO-based schemes, the
method consistently enforces frequency safety and capacity limits, achieves
smaller frequency deviations and faster recovery, thereby demonstrating its
practical effectiveness and advantages.

</details>


### [342] [Anti-Disturbance Hierarchical Sliding Mode Controller for Deep-Sea Cranes with Adaptive Control and Neural Network Compensation](https://arxiv.org/abs/2509.07356)
*Qian Zuo,Shujie Wu,Yuzhe Qian*

Main category: eess.SY

TL;DR: 本文提出了一种用于深海起重机的抗干扰控制器，通过结合分层滑模控制、自适应控制和神经网络补偿技术，有效解决了复杂海洋环境中的非线性干扰和不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂海洋环境中深海起重机面临的非线性干扰和不确定性问题。

Method: 提出了一种结合分层滑模控制、自适应控制和神经网络补偿技术的抗干扰控制器。设计了全局滑模表面以实现驱动和非驱动子系统间的动态协调，并设计了子系统表面以减少振荡并提高跟踪精度。自适应控制用于动态调整系统参数以增强对外部不确定性的鲁棒性，神经网络用于通过实时学习补偿时变干扰。基于李亚普诺夫理论验证了控制方案的稳定性。

Result: 仿真结果表明，与传统的PID控制器相比，所提出的控制器在轨迹跟踪精度、响应速度和抗干扰能力方面表现出显著优势。

Conclusion: 所提出的控制器能够有效处理深海起重机中的非线性干扰和不确定性，并在精度、速度和鲁棒性方面优于传统PID控制。

Abstract: To address non-linear disturbances and uncertainties in complex marine
environments, this paper proposes a disturbance-resistant controller for
deep-sea cranes. The controller integrates hierarchical sliding mode control,
adaptive control, and neural network compensation techniques. By designing a
global sliding mode surface, the dynamic coordination between the driving and
non-driving subsystems is achieved, ensuring overall system stability. The
subsystem surfaces reduce oscillations and enhance tracking accuracy. Adaptive
control dynamically adjusts system parameters, enhancing robustness against
external uncertainties, while the neural network compensates for time-varying
disturbances through real-time learning. The stability of the control scheme is
verified on the basis of Lyapunov theory. The simulation results demonstrate
that, compared to traditional PID control, the proposed controller exhibits
significant advantages in trajectory tracking accuracy, response speed, and
disturbance rejection.

</details>


### [343] [Adaptive Event-Triggered MPC for Linear Parameter-Varying Systems with State Delays, Actuator Saturation and Disturbances](https://arxiv.org/abs/2509.07384)
*Aiping Zhong,Wanlin Lu,Langwen Zhang,Ziyang Bao*

Main category: eess.SY

TL;DR: 该研究提出了一种统一的自适应事件触发模型预测控制（ETMPC）方案，用于处理具有状态延迟、执行器饱和和外部干扰的线性参数变化（LPV）系统。


<details>
  <summary>Details</summary>
Motivation: 现有研究在处理状态延迟或执行器饱和方面的ETMPC方法有限，并且缺乏自适应事件触发机制与控制律之间的协同优化设计。

Method: 提出了一种基于Lyapunov-Krasovskii的自适应ETMPC策略，通过在Lyapunov-Krasovskii类函数中嵌入内部自适应变量来优化事件触发参数矩阵，并将执行器饱和非线性转化为凸包表示。将无限时间域鲁棒优化问题重构为具有线性矩阵不等式（LMI）约束的凸优化问题，并引入不变集约束确保递归可行性。

Result: 仿真结果表明，所提出的方法能够有效降低通信负载，并已严格证明了在多重不确定性下输入-状态稳定性（ISS）。

Conclusion: 所提出的自适应ETMPC方案能够有效地处理具有状态延迟、执行器饱和和外部干扰的LPV系统，并在降低通信负载的同时保证系统稳定性。

Abstract: This paper proposes a unified adaptive event-triggered model predictive
control (ETMPC) scheme for linear parameter-varying (LPV) systems subject to
state delays, actuator saturation, and external disturbances. In existing
studies, only a limited number of ETMPC methods have attempted to address
either state delays or actuator saturation, and even these few methods
typically lack co-design optimization between adaptive event-triggering
mechanisms and the control law. To overcome these limitations, this paper
presents a Lyapunov-Krasovskii-based adaptive ETMPC strategy that enables the
co-design optimization of both the triggering mechanism and the controller.
Specifically, the event-triggering parameter matrix is adaptively optimized by
embedding an internal adaptive variable within the Lyapunov-Krasovskii-like
function. Furthermore, the actuator saturation nonlinearity is transformed into
a convex hull representation. The infinite-horizon robust optimization problem
is reformulated as a convex optimization problem with linear matrix inequality
(LMI) constraints. Invariant set constraints are introduced to ensure recursive
feasibility, and mean-square input-to-state stability (ISS) under multiple
uncertainties is rigorously established. Simulations on an industrial electric
heating system validate the proposed method's effectiveness in reducing
communication load.

</details>


### [344] [A smart fridge with AI-enabled food computing](https://arxiv.org/abs/2509.07400)
*Khue Nong Thuc,Khoa Tran Nguyen Anh,Tai Nguyen Huy,Du Nguyen Hao Hong,Khanh Dinh Ba*

Main category: eess.SY

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The Internet of Things (IoT) plays a crucial role in enabling seamless
connectivity and intelligent home automation, particularly in food management.
By integrating IoT with computer vision, the smart fridge employs an ESP32-CAM
to establish a monitoring subsystem that enhances food management efficiency
through real-time food detection, inventory tracking, and temperature
monitoring. This benefits waste reduction, grocery planning improvement, and
household consumption optimization. In high-density inventory conditions,
capturing partial or layered images complicates object detection, as
overlapping items and occluded views hinder accurate identification and
counting. Besides, varied angles and obscured details in multi-layered setups
reduce algorithm reliability, often resulting in miscounts or
misclassifications. Our proposed system is structured into three core modules:
data pre-processing, object detection and management, and a web-based
visualization. To address the challenge of poor model calibration caused by
overconfident predictions, we implement a variant of focal loss that mitigates
over-confidence and under-confidence in multi-category classification. This
approach incorporates adaptive, class-wise error calibration via temperature
scaling and evaluates the distribution of predicted probabilities across
methods. Our results demonstrate that robust functional calibration
significantly improves detection reliability under varying lighting conditions
and scalability challenges. Further analysis demonstrates a practical,
user-focused approach to modern food management, advancing sustainable living
goals through reduced waste and more informed consumption.

</details>


### [345] [Electric Vehicle Routing Problem with Time Windows and Station-based or Route-based Charging Options](https://arxiv.org/abs/2509.07402)
*Tran Trung Duc,Vu Duc Minh,Nguyen Ngoc Doanh,Pham Gia Nguyen,Laurent El Ghaoui,Ha Minh Hoang*

Main category: eess.SY

TL;DR: 该研究提出了一个考虑时间窗、充电站和路线充电选项的电动汽车路径问题（EVRP-TW）模型，通过引入动态无线充电和分层多目标优化来提高车队效率。


<details>
  <summary>Details</summary>
Motivation: 在现有的电动汽车路径问题模型中，如何有效地整合两种不同的充电模式（充电站和无线充电），并在此基础上进行多目标优化，以实现车队运营效率的最大化，是一个重要的研究方向。

Method: 本研究在Schneider等人的EVRP-TW模型基础上，引入了基于弧的动态无线充电表示、部分覆盖建模以及分层多目标优化方法，并以最小化车队规模为首要目标。

Result: 计算实验表明，与现有模型相比，该模型在距离和时间方面取得了0.7%至35.9%的显著改进。研究还发现，20%的无线覆盖率可以立即带来效益，而60%的覆盖率则能在所有测试实例中实现最优的投资效益。

Conclusion: 该模型能够有效地解决电动汽车路径问题，并为充电基础设施的投资决策提供了有价值的见解。在实际应用中，根据具体需求和成本效益分析，可以灵活选择合适的无线充电覆盖率。

Abstract: The Electric Vehicle Routing Problem with Time Windows and Station-based or
Route-based Charging Options addresses fleet optimization incorporating both
conventional charging stations and continuous wireless charging infrastructure.
This paper extends Schneider et al.'s foundational EVRP-TW model with arc-based
dynamic wireless charging representation, partial coverage modeling, and
hierarchical multi-objective optimization prioritizing fleet minimization.
Computational experiments on Schneider benchmark instances demonstrate
substantial operational benefits, with distance and time improvements ranging
from 0.7% to 35.9% in secondary objective components. Analysis reveals that 20%
wireless coverage achieves immediate benefits, while 60% coverage delivers
optimal performance across all test instances for infrastructure investment
decisions.

</details>


### [346] [A kernel-based approach to physics-informed nonlinear system identification](https://arxiv.org/abs/2509.07634)
*Cesare Donati,Martina Mammarella,Giuseppe C. Calafiore,Fabrizio Dabbene,Constantino Lagoa,Carlo Novara*

Main category: eess.SY

TL;DR: 提出一种结合物理模型和核方法的新型非线性系统辨识框架，用于提升参数估计和模型准确性。


<details>
  <summary>Details</summary>
Motivation: 将部分已知的物理模型与核方法相结合，以改进参数估计和模型准确性。

Method: 提出一种结构化方法，将参数化的物理模型与核函数（用于处理未建模动力学）同时进行辨识，并采用非线性状态平滑技术来处理状态空间模型中不完全可测量的状态。

Result: 通过实验基准系统的数值模拟，证明了该方法的有效性，并与现有先进的辨识技术进行了性能比较。

Conclusion: 所提出的方法能够有效地进行非线性系统辨识，同时兼顾物理模型的可解释性和核方法的灵活性。

Abstract: This paper presents a kernel-based framework for physics-informed nonlinear
system identification. The key contribution is a structured methodology that
extends kernel-based techniques to seamlessly integrate partially known
physics-based models, improving parameter estimation and overall model
accuracy. The proposed method enhances traditional modeling approaches by
integrating a parametric model, which provides physical interpretability, with
a kernel-based function, which accounts for unmodelled dynamics. The two
model's components are identified from data simultaneously, minimizing a
suitable cost that balances the relative importance of the physical and the
black-box parts of the model. Additionally, nonlinear state smoothing is
employed to address scenarios involving state-space models with not fully
measurable states. Numerical simulations on an experimental benchmark system
demonstrate the effectiveness of the proposed approach, with performance
comparisons against state-of-the-art identification techniques.

</details>


### [347] [Prescribed-Time Event-Triggered Control for Matrix-Scaled Networks](https://arxiv.org/abs/2509.07703)
*Sunny K P,Rakesh R Warier*

Main category: eess.SY

TL;DR: 本文提出一种用于矩阵缩放多智能体网络的分布式控制方法，以实现用户定义的精确时间收敛。


<details>
  <summary>Details</summary>
Motivation: 针对矩阵缩放多智能体网络，需要一种能够实现预定义时间收敛的分布式控制方法。

Method: 提出一种分布式控制律，每个智能体仅依赖邻居信息并使用状态相关的触发函数进行离散更新。通过引入时变增益和时间伸缩技术将有限时间动力学转化为无限时间问题，并利用基于李亚普诺夫的分析推导出触发条件，以保证原系统的预定义时间收敛。

Result: 所提出的方法能够实现矩阵缩放多智能体网络的预定义时间收敛。

Conclusion: 通过结合时变增益、时间伸缩和李亚普诺夫分析，成功设计出一种分布式控制策略，用于在预定义时间内实现矩阵缩放多智能体网络的收敛。

Abstract: This article proposes a distributed control method for matrix-scaled
multi-agent networks aimed at achieving convergence within a user-defined time
frame. The control law of each individual agent relies only on information from
neighboring agents and is updated at discrete intervals determined by
state-dependent triggering functions, reducing the frequency of agent
interactions. To this end, first, the controller is augmented with a
time-varying gain. Then, the dynamics of the closed-loop system over the
finite-time interval is transformed into an infinite-time frame using time
scaling. Lyapunov-based analysis is employed to derive suitable triggering
conditions that guarantee the asymptotic convergence of the time-transformed
system, thereby ensuring the prescribed-time convergence of the original
system.

</details>


### [348] [Swarm-optimized Adaptive Augmentation of Missile Autopilot](https://arxiv.org/abs/2509.07748)
*Alexander Dorsey,Parham Oveissi,Jeffrey D. Barton,Ankit Goel*

Main category: eess.SY

TL;DR: 利用在线学习技术优化导弹三环自适应飞控


<details>
  <summary>Details</summary>
Motivation: 解决导弹自适应飞控参数优化问题

Method: 将学习控制器与经典三环飞控结构相结合，使用回顾性成本优化方法进行递归优化

Result: 数值模拟结果显示，在线学习方法在标称和非标称拦截场景下均提高了经典自适应飞控的跟踪性能

Conclusion: 在线学习技术能够有效提升导弹三环自适应飞控的性能

Abstract: This paper considers the problem of optimizing a missile autopilot. In
particular, the paper investigates the application of an online learning
technique to learn and optimize the gains of a three-loop topology autopilot
for a planar missile modeled with nonlinear dynamics and nonlinear aerodynamics
forces and moments. The classical autopilot for a missile is based on a
three-loop topology, where each loop consists of tunable proportional gains. An
adaptive three-loop autopilot is constructed by augmenting the classical
autopilot's fixed-gain controllers with a learning-based controller, which is
recursively optimized using retrospective cost optimization. Numerical
simulations show that online learning improves the tracking performance of the
classical autopilot in both nominal and off-nominal interception scenarios.

</details>


### [349] [Filtering in Multivariate Systems with Quantized Measurements using a Gaussian Mixture-Based Indicator Approximation](https://arxiv.org/abs/2509.07837)
*Angel L. Cedeño,Rodrigo A. González,Boris I. Godoy,Juan C. Agüero*

Main category: eess.SY

TL;DR: 针对量化输出现有状态估计方法的不足，提出了一种新的概率质量函数构造方法，通过高斯混合模型近似量化区域指示函数，实现了对任意数量量化输出的泛化，并在保持显著降低的计算成本的同时，在滤波分布保真度和均方误差方面实现了高精度状态估计。


<details>
  <summary>Details</summary>
Motivation: 现有状态估计方法在处理量化输出时存在不足，尤其是在传感器分辨率低或通信受限的场景下，需要更有效的解决方案。

Method: 提出了一种新颖的方法，通过使用高斯混合模型近似量化区域的指示函数来显式构造与量化测量相关的概率质量函数。该方法可以推广到任意数量的量化输出，无需特定情况的数值解。

Result: 仿真结果表明，该滤波器在滤波分布保真度和均方误差方面均实现了高精度状态估计，同时计算成本显著降低。

Conclusion: 所提出的方法能够精确地估计多变量动态系统中的状态，并且在计算效率上优于现有方法，适用于低分辨率传感器或通信受限等实际应用场景。

Abstract: This work addresses the problem of state estimation in multivariable dynamic
systems with quantized outputs, a common scenario in applications involving
low-resolution sensors or communication constraints. A novel method is proposed
to explicitly construct the probability mass function associated with the
quantized measurements by approximating the indicator function of each region
defined by the quantizer using Gaussian mixture models. Unlike previous
approaches, this technique generalizes to any number of quantized outputs
without requiring case-specific numerical solutions, making it a scalable and
efficient solution. Simulation results demonstrate that the proposed filter
achieves high accuracy in state estimation, both in terms of fidelity of the
filtering distributions and mean squared error, while maintaining significantly
reduced computational cost.

</details>


### [350] [Sensor Management in Multi-Stage Stochastic Control Problems with Imperfect State Information](https://arxiv.org/abs/2509.07840)
*Patrick Kreidl*

Main category: eess.SY

TL;DR: 本研究提出将传感器管理建模为具有不完美状态信息的_多阶段随机控制问题，并探讨了在部分可观察马尔可夫决策过程（PO-MDP）和线性二次高斯调节器（LQGR）等模型中的应用。


<details>
  <summary>Details</summary>
Motivation: 随着传感器技术的发展，传感器网络在决策支持中的应用越来越广泛，但如何有效管理传感器以优化决策是一个挑战。

Method: 将传感器管理问题建模为多阶段随机控制问题，其中环境状态无法直接获取，只能通过带有噪声的观测进行估计。在PO-MDP和LQGR框架下，通过动态规划求解，并分析了传感与行动之间的相互作用。

Result: 通过在PO-MDP和LQGR的简化示例中应用动态规划，验证了该模型能够处理传感器管理问题，并揭示了传感与行动之间的内在联系。

Conclusion: 动态规划是解决具有不完美状态信息的随机控制问题的有效方法，即使在计算成本高昂的情况下，也能为开发次优策略提供指导。传感器管理可以自然地融入到动态规划的解决方案中，实现传感与行动的协同优化。

Abstract: Technological advancements in miniaturization and wireless communications are
yielding more affordable and versatile sensors and, in turn, more applications
in which a network of sensors can be actively managed to best support overall
decision-making objectives. We propose modeling the opportunity for sensor
management within multi-stage stochastic control problems with imperfect state
information. Such formulations inherently assume the state of the modeled
environment cannot be accessed directly but instead the controller can observe
only noisy measurements of the state and, therefore, at each decision stage
some form of state estimation is required before a control is actuated. The
notion of sensor management arises when the modeled controls not only affect
the subsequent evolution of the state but can also affect the nature of future
measurements and, hence, the quality of state estimates that drive future
control decisions. In principle, the optimal strategy for any appropriately
modeled multi-stage stochastic control problem with imperfect state information
(with or without opportunity for sensor management) is the solution to a
dynamic program; in practice, the computational requirements are typically
prohibitive yet dynamic programming methods are still useful to guide the
development of effective suboptimal strategies. In this spirit, we model the
opportunity for sensor management within small-scale examples of two
well-studied dynamic programming formulations, namely (1) the
finite-state/finite-action Partially-Observable Markov Decision Process
(PO-MDP) and (2) the Linear-Quadratic-Gaussian Regulator (LQGR). These examples
admit solvable dynamic programs and confirm how the interplay between sensing
and acting is a natural by-product of a dynamic programming solution.

</details>


### [351] [Feedback Linearization-based Guidance Law for Guaranteed Interception](https://arxiv.org/abs/2509.07843)
*Alexander Dorsey,Ankit Goel*

Main category: eess.SY

TL;DR: 本研究提出一种基于输入-输出反馈线性化(IOL)的制导律，用于确保在追捕者-逃避者交战场景中的拦截。


<details>
  <summary>Details</summary>
Motivation: 解决经典比例制导律在某些条件下出现的奇异性以及LOS制导律的发散问题。

Method: 推导了基于范围和LOS率测量的IOL制导律，并使用模糊逻辑系统和修正函数来解决各自的问题。

Result: 蒙特卡洛模拟结果表明，两种改进的IOL制导律在施加控制限制的情况下都能实现拦截。

Conclusion: 改进的IOL制导律能够有效地解决奇异性和发散问题，确保拦截成功。

Abstract: This paper presents an input-output feedback linearization (IOL)-based
guidance law to ensure interception in a pursuer-evader engagement scenario. A
point-mass dynamic model for both the pursuer and the evader is considered. An
IOL guidance law is derived using range and line-of-sight (LOS) rate
measurements. It is found that the range-based IOL guidance law exhibits a
singularity under certain conditions. To address this issue, a fuzzy logic
system is employed to smoothly blend the IOL guidance with the classical
proportional guidance law, thereby avoiding the singularity. In contrast, the
LOS-based IOL guidance law is free of singularities but suffers from divergence
issues due to angle-related complications. To resolve this, a simple correction
function is introduced to ensure consistent interception behavior. Results from
Monte Carlo simulations indicate that both modifications of the IOL guidance
laws cause interception with control limits applied.

</details>


### [352] [Partitioning and Self-organization of Distributed Generation in Large Distribution Networks](https://arxiv.org/abs/2509.07918)
*Badr Al Faiya,Stephen McArthur,Ivana Kockar*

Main category: eess.SY

TL;DR: 该论文提出了一种基于社区检测的配电网划分技术，以分布式方式控制和管理分布式发电（DG）带来的挑战，如电压控制。


<details>
  <summary>Details</summary>
Motivation: 随着不可预测的分布式发电（DG）在配电网中的安装越来越多，需要更强的分布式控制和智能来有效应对电压控制等挑战。

Method: 通过社区检测技术将配电网划分为若干个社区（子集），使得每个社区可以利用本地的 DG 和测量信号进行分布式控制，并仅通过邻近的 DG 来管理电压。

Result: 模拟结果表明，该方法能够有效地将大型配电网划分为可管理的社区，并且每个社区能够独立地利用其本地 DG 来进行自组织和电压调节。

Conclusion: 该基于社区检测的划分技术能够有效地解决分布式发电带来的电压控制问题，使得配电网能够灵活适应 DG 条件的变化并保持稳定。

Abstract: Distribution networks will experience more installations of distributed
generation (DG) that is unpredictable and stochastic in nature. Greater
distributed control and intelligence will allow challenges such as voltage
control to be handled effectively. The partitioning of power networks into
smaller clusters provides a method to split the control problem into manageable
sub-problems. This paper presents a community detection-based partitioning
technique for distribution networks considering local DGs, allowing them to be
grouped and controlled in a distributed manner by using local signals and
measurements. This method also allows each community to control the voltage
using only neighboring DGs, and for each community to self-organize to reflect
varying DG conditions and to maintain stable control. Simulations demonstrate
that the partitioning of the large distribution network is effective, and each
community is able to self-organize and to regulate the voltage independently
using only its local DGs.

</details>


### [353] [A Markov Decision Process Model for Intrusion Tolerance Problems](https://arxiv.org/abs/2509.07919)
*Patrick Kreidl*

Main category: eess.SY

TL;DR: 该模型分析了在存在攻击的情况下，防御性响应和预防性恢复策略的有效性。


<details>
  <summary>Details</summary>
Motivation: 在网络安全领域，尤其是在面对持续的、多步骤的攻击时，如何有效地容忍入侵并维持系统可用性是一个关键问题。现有的防御策略可能无法充分应对攻击的复杂性和不确定性，因此需要新的分析模型来指导决策。

Method: 提出并分析了一个简化的马尔可夫决策过程模型，该模型考虑了攻击的阶段性、防御响应的概率性和恢复响应的有效性限制。通过数学分析，探讨了不同响应策略（防御性响应和预防性恢复）在不同攻击动态和响应效果下的优劣。

Result: 分析表明，即使在探测器完美的情况下，持续进行防御性响应也可能不是最优策略，因为其开销可能超过安全失败的风险。此外，模型还量化了预防性恢复与被动性恢复在可用性损失和风险降低方面的权衡，并识别了决定何时启动恢复的关键因素。

Conclusion: 研究结论指出，在入侵容忍问题中，最优的响应策略（包括防御和恢复）取决于具体的攻击动态、响应的有效性以及探测器的性能。在某些情况下，接受间歇性的安全失败可能比持续的防御开销更经济。模型为理解和设计更有效的入侵容忍策略提供了理论基础，并为未来的研究方向（如不完美的探测器、多类型攻击、连续时间动态和战略攻击者）提供了指导。

Abstract: We formulate and analyze a simplest Markov decision process model for
intrusion tolerance problems, assuming that (i) each attack proceeds through
one or more steps before the system's security fails, (ii) defensive responses
that target these intermediate steps may only sometimes thwart the attack and
(iii) reset responses that are sensible upon discovering an attack's completion
may not always recover from the security failure. The analysis shows that, even
in the ideal case of perfect detectors, it can be sub-optimal in the long run
to employ defensive responses while under attack; that is, depending on attack
dynamics and response effectiveness, the total overhead of ongoing defensive
countermeasures can exceed the total risk of intermittent security failures.
The analysis similarly examines the availability loss versus the risk reduction
of employing preemptive resets, isolating key factors that determine whether
system recovery is best initiated reactively or proactively. We also discuss
model extensions and related work looking towards intrusion tolerance
applications with (i) imperfect or controllable detectors, (ii) multiple types
of attacks, (iii) continuous-time dynamics or (iv) strategic attackers.

</details>


### [354] [Estimating Cellular Network Delays in Finnish Railways: A Machine Learning Enhanced Approach](https://arxiv.org/abs/2509.05003)
*Saeideh Mansouri,Mohamed Shamekh,Simon Indola,Petri Mahonen*

Main category: eess.SY

TL;DR: 芬兰的Digirail项目旨在使用公共4G/5G网络取代老化的GSM-R铁路通信系统。该研究通过在数据包复制模式下进行测量，并使用机器学习来模拟铁路网络延迟，以评估网络性能。


<details>
  <summary>Details</summary>
Motivation: 评估芬兰公共蜂窝网络在取代GSM-R的Digirail项目中的性能，满足铁路通信的严格要求。

Method: 在数据包复制模式下进行全国性网络测量，并使用机器学习模型来估计芬兰铁路网络的网络延迟。

Result: 已成功构建一个机器学习模型，可以根据数据包复制模式的测量结果准确估算芬兰铁路网络的网络延迟，并表明公共蜂窝网络能够满足铁路通信的性能要求。

Conclusion: 基于机器学习的网络性能预测是可行的，芬兰的公共蜂窝网络能够满足铁路网络控制的严格性能要求。

Abstract: There is growing interest in using public cellular networks for specialized
communication applications, replacing standalone sector-specific networks. One
such application is transitioning from the aging GSM-R railway network to
public 4G and 5G networks. Finland is modernizing its railway communication
system through the Digirail project, leveraging public cellular networks. To
evaluate network performance, a nationwide measurement campaign was conducted
in two modes: Best Quality and Packet Replication. However, Best Quality mode
introduces artificial delays, making it unsuitable for real-world assessments.
In this paper, railway network delays are modeled using machine learning based
on measurements from the Packet Replication mode. The best-performing model is
then employed to generate a dataset estimating network delays across Finland's
railway network. This dataset provides a more accurate representation of
network performance. Machine learning based network performance prediction is
shown to be feasible, and the results indicate that Finland's public cellular
network can meet the stringent performance requirements of railway network
control.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [355] [Contradictions](https://arxiv.org/abs/2509.07026)
*Yang Xu,Shuwei Chen,Xiaomei Zhong,Jun Liu,Xingxing He*

Main category: cs.LO

TL;DR: 本文提出了一种基于标准矛盾（standard contradiction）的自动化推理方法，用于解决经典二元归结（binary resolution）在处理复杂逻辑问题时的局限性。研究了最大三角标准矛盾和三角型标准矛盾的构造方法，并提出了通过最大标准矛盾判断子句集满足性与否的程序。此外，还推导了计算这两种标准矛盾中包含的标准子矛盾数量的公式。该方法旨在为动态多子句自动化推理提供理论基础，以扩展自动化推理系统的能力。


<details>
  <summary>Details</summary>
Motivation: 经典的二元归结方法在处理逻辑推理时存在局限性，限制了自动化推理系统的能力。因此，需要新的方法来克服这一瓶颈。

Method: 本文研究了最大三角标准矛盾和三角型标准矛盾的构造方法，并提出了一种利用最大标准矛盾来判断子句集满足性与否的程序。此外，还推导了计算标准子矛盾数量的公式。

Result: 提出了构造最大三角标准矛盾和三角型标准矛盾的方法，并提出了通过最大标准矛盾判断子句集满足性与否的程序。推导了计算这两种标准矛盾中包含的标准子矛盾数量的公式。

Conclusion: 本文提出的基于标准矛盾的方法为动态多子句自动化推理提供了方法论基础，扩展了自动化推理的能力，超越了经典的二元推理范式。

Abstract: Trustworthy AI requires reasoning systems that are not only powerful but also
transparent and reliable. Automated Theorem Proving (ATP) is central to formal
reasoning, yet classical binary resolution remains limited, as each step
involves only two clauses and eliminates at most two literals. To overcome this
bottleneck, the concept of standard contradiction and the theory of
contradiction-separation-based deduction were introduced in 2018. This paper
advances that framework by focusing on the systematic construction of standard
contradictions. Specially, this study investigates construction methods for two
principal forms of standard contradiction: the maximum triangular standard
contradiction and the triangular-type standard contradiction. Building on these
structures, we propose a procedure for determining the satisfiability and
unsatisfiability of clause sets via maximum standard contradiction.
Furthermore, we derive formulas for computing the number of standard
sub-contradictions embedded within both the maximum triangular standard
contradiction and the triangular-type standard contradiction. The results
presented herein furnish the methodological basis for advancing
contradiction-separation-based dynamic multi-clause automated deduction,
thereby extending the expressive and deductive capabilities of automated
reasoning systems beyond the classical binary paradigm.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [356] [Individualized and Interpretable Sleep Forecasting via a Two-Stage Adaptive Spatial-Temporal Model](https://arxiv.org/abs/2509.06974)
*Xueyi Wang,Elisabeth Wilhelm*

Main category: cs.LG

TL;DR: 该研究提出了一种可解释、个体化、两阶段自适应时空模型，用于预测睡眠质量得分，旨在为医疗保健提供者和个人提供可访问、可靠的预测工具。


<details>
  <summary>Details</summary>
Motivation: 鉴于睡眠质量对整体健康的重要影响，开发可访问且可靠的睡眠质量预测工具对于预防性干预至关重要。

Method: 该模型结合了多尺度卷积层（用于对跨多个输入变量的空间交互进行建模）、循环层和注意力机制（用于捕捉长期时间依赖性）以及两阶段域自适应策略（用于提高泛化能力）。第一阶段自适应在训练期间应用，以减轻训练集上的过拟合。第二阶段采用无源测试时自适应机制，无需标签即可将模型适应新用户。

Result: 在各种实验中，该模型始终优于包括LSTM、Informer、PatchTST和TimesNet在内的时间序列预测基线方法。输入窗口为三天、预测窗口为一天时，RMSE达到0.216。即使在更长的预测范围（例如，三天预测窗口的RMSE为0.257）下，模型也表现出良好的预测性能。此外，还进行了可解释性分析，考察了不同特征对睡眠质量的影响。

Conclusion: 该框架提供了一种强大、自适应且可解释的解决方案，能够使用来自商业可穿戴设备的稀疏数据进行个性化睡眠预测。

Abstract: Sleep quality significantly impacts well-being. Therefore, healthcare
providers and individuals need accessible and reliable forecasting tools for
preventive interventions. This paper introduces an interpretable,
individualized two-stage adaptive spatial-temporal model for predicting sleep
quality scores. Our proposed framework combines multi-scale convolutional
layers to model spatial interactions across multiple input variables, recurrent
layers and attention mechanisms to capture long-term temporal dependencies, and
a two-stage domain adaptation strategy to enhance generalization. The first
adaptation stage is applied during training to mitigate overfitting on the
training set. In the second stage, a source-free test-time adaptation mechanism
is employed to adapt the model to new users without requiring labels. We
conducted various experiments with five input window sizes (3, 5, 7, 9, and 11
days) and five prediction window sizes (1, 3, 5, 7, and 9 days). Our model
consistently outperformed time series forecasting baseline approaches,
including Long Short-Term Memory (LSTM), Informer, PatchTST, and TimesNet. The
best performance was achieved with a three-day input window and a one-day
prediction window, yielding a root mean square error (RMSE) of 0.216.
Furthermore, the model demonstrated good predictive performance even for longer
forecasting horizons (e.g, with a 0.257 RMSE for a three-day prediction
window), highlighting its practical utility for real-world applications. We
also conducted an explainability analysis to examine how different features
influence sleep quality. These findings proved that the proposed framework
offers a robust, adaptive, and explainable solution for personalized sleep
forecasting using sparse data from commercial wearable devices.

</details>


### [357] [GSTBench: A Benchmark Study on the Transferability of Graph Self-Supervised Learning](https://arxiv.org/abs/2509.06975)
*Yu Song,Zhigang Hua,Yan Xie,Jingzhe Liu,Bo Long,Hui Liu*

Main category: cs.LG

TL;DR: GSTBench 是一个用于评估图自监督学习（SSL）方法跨数据集迁移能力的新基准。


<details>
  <summary>Details</summary>
Motivation: 现有图 SSL 方法多在单一数据集上进行评估，忽略了跨数据集迁移能力，限制了知识迁移和大规模预训练，这对于实现超越训练数据拟合的通用智能至关重要。

Method: 通过在 ogbn-papers100M 数据集上进行大规模预训练，并在多种目标图上评估五种代表性 SSL 方法，来构建和评估 GSTBench。该基准通过标准化的实验设置，消除了模型架构、数据集特性和适应协议等混淆因素，专注于预训练目标。

Result: 大多数图 SSL 方法迁移能力不佳，甚至表现不如随机初始化。GraphMAE（一种掩码自编码器方法）在迁移性能上表现持续提升。研究分析了导致这些差异的根本原因。

Conclusion: GSTBench 为图学习中的“预训练-迁移”范式奠定了基础，并为开发可迁移的图 SSL 方法提供了指导。

Abstract: Self-supervised learning (SSL) has shown great promise in graph
representation learning. However, most existing graph SSL methods are developed
and evaluated under a single-dataset setting, leaving their cross-dataset
transferability largely unexplored and limiting their ability to leverage
knowledge transfer and large-scale pretraining, factors that are critical for
developing generalized intelligence beyond fitting training data. To address
this gap and advance foundation model research for graphs, we present GSTBench,
the first systematic benchmark for evaluating the transferability of graph SSL
methods. We conduct large-scale pretraining on ogbn-papers100M and evaluate
five representative SSL methods across a diverse set of target graphs. Our
standardized experimental setup decouples confounding factors such as model
architecture, dataset characteristics, and adaptation protocols, enabling
rigorous comparisons focused solely on pretraining objectives. Surprisingly, we
observe that most graph SSL methods struggle to generalize, with some
performing worse than random initialization. In contrast, GraphMAE, a masked
autoencoder approach, consistently improves transfer performance. We analyze
the underlying factors that drive these differences and offer insights to guide
future research on transferable graph SSL, laying a solid foundation for the
"pretrain-then-transfer" paradigm in graph learning. Our code is available at
https://github.com/SongYYYY/GSTBench.

</details>


### [358] [A Knowledge-Guided Cross-Modal Feature Fusion Model for Local Traffic Demand Prediction](https://arxiv.org/abs/2509.06976)
*Lingyu Zhang,Pengfei Xu,Guobin Wu,Jian Liang,Ruiyang Dong,Yunhai Wang,Xuan Song*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Traffic demand prediction plays a critical role in intelligent transportation
systems. Existing traffic prediction models primarily rely on temporal traffic
data, with limited efforts incorporating human knowledge and experience for
urban traffic demand forecasting. However, in real-world scenarios, traffic
knowledge and experience derived from human daily life significantly influence
precise traffic prediction. Such knowledge and experiences can guide the model
in uncovering latent patterns within traffic data, thereby enhancing the
accuracy and robustness of predictions. To this end, this paper proposes
integrating structured temporal traffic data with textual data representing
human knowledge and experience, resulting in a novel knowledge-guided
cross-modal feature representation learning (KGCM) model for traffic demand
prediction. Based on regional transportation characteristics, we construct a
prior knowledge dataset using a large language model combined with manual
authoring and revision, covering both regional and global knowledge and
experiences. The KGCM model then learns multimodal data features through
designed local and global adaptive graph networks, as well as a cross-modal
feature fusion mechanism. A proposed reasoning-based dynamic update strategy
enables dynamic optimization of the graph model's parameters, achieving optimal
performance. Experiments on multiple traffic datasets demonstrate that our
model accurately predicts future traffic demand and outperforms existing
state-of-the-art (SOTA) models.

</details>


### [359] [Toward Reproducible Cross-Backend Compatibility for Deep Learning: A Configuration-First Framework with Three-Tier Verification](https://arxiv.org/abs/2509.06977)
*Zehua Li*

Main category: cs.LG

TL;DR: 该框架通过解耦实验与代码、支持多种模型以及采用三层验证协议来评估深度学习系统在CPU、GPU和编译运行时上的跨后端兼容性。


<details>
  <summary>Details</summary>
Motivation: 评估深度学习系统在不同硬件后端（CPU、GPU、编译运行时）的兼容性，解决跨后端漂移问题。

Method: 提出一个配置优先的框架，使用YAML解耦实验与代码，支持库和仓库模型，并采用包含张量级别、激活对齐和任务级别指标的三层验证协议。

Result: 在672次检查中，72.0%的运行通过，大多数差异出现在更严格的阈值下。检测模型和编译后端尤其容易出现漂移，主要是由于非确定性的后处理。确定性适配器和选择性回退可以在不显著损失性能的情况下提高一致性。

Conclusion: 该框架是首个系统量化和缓解深度学习中跨后端漂移的统一框架，为在异构运行时中进行可复现的可靠部署提供了方法。

Abstract: This paper presents a configuration-first framework for evaluating
cross-backend compatibility in deep learning systems deployed on CPU, GPU, and
compiled runtimes. The framework decouples experiments from code using YAML,
supports both library and repository models, and employs a three-tier
verification protocol covering tensor-level closeness, activation alignment,
and task-level metrics. Through 672 checks across multiple models and tolerance
settings, we observe that 72.0% of runs pass, with most discrepancies occurring
under stricter thresholds. Our results show that detection models and compiled
backends are particularly prone to drift, often due to nondeterministic
post-processing. We further demonstrate that deterministic adapters and
selective fallbacks can substantially improve agreement without significant
performance loss. To our knowledge, this is the first unified framework that
systematically quantifies and mitigates cross-backend drift in deep learning,
providing a reproducible methodology for dependable deployment across
heterogeneous runtimes.

</details>


### [360] [Bringing Multi-Modal Multi-Task Federated Foundation Models to Education Domain: Prospects and Challenges](https://arxiv.org/abs/2509.07946)
*Kasra Borazjani,Naji Khosravan,Rajeev Sahay,Bita Akram,Seyyedali Hosseinalipour*

Main category: cs.LG

TL;DR: 多模态多任务（M3T）基础模型（FM）在教育领域的应用受到隐私、数据孤岛和数据可用性限制。本文提出M3T联邦基础模型（FedFMs），结合联邦学习（FL）和M3T FM，实现跨机构的协作和隐私保护训练。


<details>
  <summary>Details</summary>
Motivation: 解决在真实教育环境中部署M3T FM所面临的隐私法规、数据孤岛和领域特定数据可用性有限的挑战。

Method: 将联邦学习（FL）与M3T FM相结合，实现跨机构的协作和隐私保护训练，并提出M3T FedFMs作为一种有前景但未被充分探索的方法。

Result: M3T FedFMs可以促进隐私保护、个性化以及公平性和包容性，从而推动下一代智能教育系统的发展。

Conclusion: M3T FedFMs在教育领域具有巨大潜力，但仍面临跨机构隐私法规异质性、数据模态特征非均匀性、知识遗忘、持续学习和模型可解释性等方面的研究挑战。

Abstract: Multi-modal multi-task (M3T) foundation models (FMs) have recently shown
transformative potential in artificial intelligence, with emerging applications
in education. However, their deployment in real-world educational settings is
hindered by privacy regulations, data silos, and limited domain-specific data
availability. We introduce M3T Federated Foundation Models (FedFMs) for
education: a paradigm that integrates federated learning (FL) with M3T FMs to
enable collaborative, privacy-preserving training across decentralized
institutions while accommodating diverse modalities and tasks. Subsequently,
this position paper aims to unveil M3T FedFMs as a promising yet underexplored
approach to the education community, explore its potentials, and reveal its
related future research directions. We outline how M3T FedFMs can advance three
critical pillars of next-generation intelligent education systems: (i) privacy
preservation, by keeping sensitive multi-modal student and institutional data
local; (ii) personalization, through modular architectures enabling tailored
models for students, instructors, and institutions; and (iii) equity and
inclusivity, by facilitating participation from underrepresented and
resource-constrained entities. We finally identify various open research
challenges, including studying of (i) inter-institution heterogeneous privacy
regulations, (ii) the non-uniformity of data modalities' characteristics, (iii)
the unlearning approaches for M3T FedFMs, (iv) the continual learning
frameworks for M3T FedFMs, and (v) M3T FedFM model interpretability, which must
be collectively addressed for practical deployment.

</details>


### [361] [A Kriging-HDMR-based surrogate model with sample pool-free active learning strategy for reliability analysis](https://arxiv.org/abs/2509.06978)
*Wenxiong Li,Hanyu Liao,Suiyin Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种基于Kriging-HDMR的主动学习代理模型方法，用于高维可靠性分析，该方法通过构建低维子模型来处理高维问题，并优化样本选择以提高预测精度和计算效率。


<details>
  <summary>Details</summary>
Motivation: 高维可靠性分析中，传统代理模型面临“维度灾难”问题，而现有的主动学习Kriging-HDMR方法在可靠性分析领域的应用研究较少，尤其是在保证关键区域预测精度方面存在不足。

Method: 提出一种基于Kriging-HDMR的主动学习代理模型方法，构建包含单变量子模型、耦合变量子模型需求的识别以及耦合变量子模型构建的框架。该方法采用候选样本池无关的方法，并根据各阶段特点制定实验设计样本选择的优化数学模型，考虑了方差、预测均值、样本位置和样本间距离等因素。

Result: 数值实验表明，所提出的方法在高维可靠性问题求解中，在保持高预测精度的同时，实现了高计算效率。

Conclusion: 所提出的主动学习代理模型方法能够有效地解决高维可靠性分析问题，在保证预测精度的同时提高了计算效率。

Abstract: In reliability engineering, conventional surrogate models encounter the
"curse of dimensionality" as the number of random variables increases. While
the active learning Kriging surrogate approaches with high-dimensional model
representation (HDMR) enable effective approximation of high-dimensional
functions and are widely applied to optimization problems, there are rare
studies specifically focused on reliability analysis, which prioritizes
prediction accuracy in critical regions over uniform accuracy across the entire
domain. This study develops an active learning surrogate model method based on
the Kriging-HDMR modeling for reliability analysis. The proposed approach
facilitates the approximation of high-dimensional limit state functions through
a composite representation constructed from multiple low-dimensional
sub-surrogate models. The architecture of the surrogate modeling framework
comprises three distinct stages: developing single-variable sub-surrogate
models for all random variables, identifying the requirements for
coupling-variable sub-surrogate models, and constructing the coupling-variable
sub-surrogate models. Optimization mathematical models for selection of design
of experiment samples are formulated based on each stage's characteristics,
with objectives incorporating uncertainty variance, predicted mean, sample
location and inter-sample distances. A candidate sample pool-free approach is
adopted to achieve the selection of informative samples. Numerical experiments
demonstrate that the proposed method achieves high computational efficiency
while maintaining strong predictive accuracy in solving high-dimensional
reliability problems.

</details>


### [362] [Exploring Over-stationarization in Deep Learning-based Bus/Tram Arrival Time Prediction: Analysis and Non-stationary Effect Recovery](https://arxiv.org/abs/2509.06979)
*Zirui Li,Bin Yang,Meng Wang*

Main category: cs.LG

TL;DR: 该研究提出了一种名为非平稳公交到达时间预测（NSATP）的新方法，通过两阶段处理来平衡预测能力和非平稳性，旨在解决现有方法中过度平稳化的问题，并在实际公交数据上取得了比基线方法更好的预测精度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在多步公交车辆到达时间预测（ATP）中，由于非平稳数据会降低模型性能。虽然归一化可以消除非平稳性，但可能丢失数据固有的信息，导致过度平稳化。

Method: NSATP方法包含两个阶段：1. 序列平稳化：提高预测能力。2. 非平稳性效应恢复：将现有的一维方法扩展到二维模型，捕捉时间序列的隐藏周期性，并通过学习原始数据的缩放和平移因子来补偿过度平稳化。

Result: 在德累斯顿的公交运营数据上，NSATP相比基线方法，在有轨电车上可将RMSE、MAE和MAPE分别降低2.37%、1.22%和2.26%；在公交车上可降低1.72%、0.60%和1.17%。

Conclusion: NSATP方法通过两阶段处理，有效解决了现有方法在多步ATP中过度平稳化的问题，并在实际公交数据上验证了其优越的预测性能。

Abstract: Arrival time prediction (ATP) of public transport vehicles is essential in
improving passenger experience and supporting traffic management. Deep learning
has demonstrated outstanding performance in ATP due to its ability to model
non-linear and temporal dynamics. In the multi-step ATP, non-stationary data
will degrade the model performance due to the variation in variables' joint
distribution along the temporal direction. Previous studies mainly applied
normalization to eliminate the non-stationarity in time series, thereby
achieving better predictability. However, the normalization may obscure useful
characteristics inherent in non-stationarity, which is known as the
over-stationarization. In this work, to trade off predictability and
non-stationarity, a new approach for multi-step ATP, named non-stationary ATP (
NSATP), is proposed. The method consists of two stages: series stationarization
and non-stationarity effect recovery. The first stage aims at improving the
predictability. As for the latter, NSATP extends a state-of-the-art method from
one-dimensional to two dimensional based models to capture the hidden
periodicity in time series and designs a compensation module of
over-stationarization by learning scaling and shifting factors from raw data.
125 days' public transport operational data of Dresden is collected for
validation. Experimental results show that compared to baseline methods, the
proposed NSATP can reduce RMSE, MAE, and MAPE by 2.37%, 1.22%, and 2.26% for
trams and by 1.72%, 0.60%, and 1.17% for buses, respectively.

</details>


### [363] [RLFactory: A Plug-and-Play Reinforcement Learning Post-Training Framework for LLM Multi-Turn Tool-Use](https://arxiv.org/abs/2509.06980)
*Jiajun Chai,Guojun Yin,Zekun Xu,Chuhuai Yue,Yi Jia,Siyu Xia,Xiaohan Wang,Jiwen Jiang,Xiaoguang Li,Chengqi Dong,Hang He,Wei Lin*

Main category: cs.LG

TL;DR: RLFactory是一个用于增强大型语言模型（LLM）多轮工具使用能力的即插即用强化学习框架，通过异步调用和解耦的工具/训练架构解决工具调用稳定性和适应性问题，并支持多样化的评估需求，在Search-R1数据集上取得了优于更大模型的性能，同时大幅提高了训练吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型在需要与外部工具交互的任务中表现不佳，因此需要一种能够增强模型多轮工具使用能力的方法。

Method: RLFactory提出了一个基于asyncio的异步调用器和解耦的工具/训练架构来解决工具调用稳定性和适应性问题，并通过引入来自工具反馈的观察标记来重建MDP，实现了模型、工具和环境之间的闭环。它还实现了一个generate-parse-invoke-update工作流来实现动态策略优化，并设计了一个支持基于规则、模型判断和工具验证信号的奖励层来满足多样化的评估需求。

Result: 在Search-R1数据集上，使用Qwen3-4B模型，RLFactory取得了0.486的测试得分，优于使用类似技术训练的更大模型（如Qwen2.5-7B-Instruct-GRPO，得分0.473），并将训练吞吐量提高了6.8倍。

Conclusion: RLFactory提供了一个低门槛、高适应性的框架，能够有效提升大型语言模型在真实场景中的多轮工具使用能力。

Abstract: Large language models excel at basic reasoning but struggle with tasks that
require interaction with external tools. We present RLFactory, a plug-and-play
reinforcement learning post-training framework for multi-round tool use.
RLFactory tackles (i) tool-call stability and adaptability amid tool
heterogeneity and interface issues via an asyncio-based asynchronous caller and
a decoupled tool/training architecture, and (ii) diverse evaluation needs via a
reward layer supporting rule-based, model-judgment, and tool-verification
signals. It reconstructs the MDP by introducing observation markers from tool
feedback, closing the loop among model, tools, and environment, and implements
a generate-parse-invoke-update workflow for dynamic policy optimization. On
Search-R1 with Qwen3-4B, RLFactory achieves a 0.486 test score on the Natural
Questions (NQ) dataset, surpassing larger models trained with similar
techniques (e.g., Qwen2.5-7B-Instruct-GRPO at 0.473), and increases training
throughput by 6.8x. RLFactory provides a low-barrier, highly adaptable
framework for strengthening multi-round tool use of LLMs in real-world
scenarios. Code: https://github.com/Simple-Efficient/RL-Factory.

</details>


### [364] [CARE: Decoding Time Safety Alignment via Rollback and Introspection Intervention](https://arxiv.org/abs/2509.06982)
*Xiaomeng Hu,Fei Huang,Chenhan Yuan,Junyang Lin,Tsung-Yi Ho*

Main category: cs.LG

TL;DR: CARE是一个用于解码时安全对齐的新框架，它通过结合了保护模型、回滚机制和自我反省干预策略，实现了安全性和响应质量的良好平衡。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在现实世界中的广泛应用，确保其输出在解码过程中的安全性已成为一个关键挑战。然而，现有的解码时干预方法（如对比解码）往往在安全性和响应质量之间存在严重的权衡。

Method: CARE框架集成了三个关键组件：（1）一个保护模型，用于实时安全监控，检测潜在不安全内容；（2）一个带有令牌缓冲的回滚机制，能够及时有效地纠正不安全输出，且不影响用户体验；（3）一种新颖的基于自我反省的干预策略，模型会生成对先前输出的反思性批评，并将其纳入上下文以指导后续解码步骤。

Result: 实验结果表明，CARE框架在安全性、质量和效率方面取得了优于现有方法的平衡，实现了低有害响应率和对用户体验的最小干扰，同时保持了高质量的响应。

Conclusion: CARE框架通过其保护模型进行精确干预、回滚机制进行及时纠正以及新颖的自我反省方法进行有效自我校正，实现了优越的安全-质量权衡。

Abstract: As large language models (LLMs) are increasingly deployed in real-world
applications, ensuring the safety of their outputs during decoding has become a
critical challenge. However, existing decoding-time interventions, such as
Contrastive Decoding, often force a severe trade-off between safety and
response quality. In this work, we propose CARE, a novel framework for
decoding-time safety alignment that integrates three key components: (1) a
guard model for real-time safety monitoring, enabling detection of potentially
unsafe content; (2) a rollback mechanism with a token buffer to correct unsafe
outputs efficiently at an earlier stage without disrupting the user experience;
and (3) a novel introspection-based intervention strategy, where the model
generates self-reflective critiques of its previous outputs and incorporates
these reflections into the context to guide subsequent decoding steps. The
framework achieves a superior safety-quality trade-off by using its guard model
for precise interventions, its rollback mechanism for timely corrections, and
our novel introspection method for effective self-correction. Experimental
results demonstrate that our framework achieves a superior balance of safety,
quality, and efficiency, attaining a low harmful response rate and minimal
disruption to the user experience while maintaining high response quality.

</details>


### [365] [FediLoRA: Heterogeneous LoRA for Federated Multimodal Fine-tuning under Missing Modalities](https://arxiv.org/abs/2509.06984)
*Lishan Yang,Nam Kha Nguygen,Po Hu,Wei Emma Zhang,Yanjun Shu,Mong Yuan Sim,Weitong Chen*

Main category: cs.LG

TL;DR: FediLoRA是一个用于联邦多模态微调的框架，解决了异构LoRA秩和缺失模态的挑战，通过维度加权聚合和轻量级层编辑提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有联邦LoRA方法在处理异构客户端资源和多模态数据（尤其是缺失模态）方面存在不足，需要一种能适应这些挑战的框架。

Method: FediLoRA采用维度加权聚合策略来重新加权LoRA更新，并结合轻量级层编辑方法选择性地整合全局参数以修复本地组件。

Result: 实验结果表明，FediLoRA在三个多模态基准数据集上，尤其是在模态不完整的情况下，相比于基线方法在全局和个性化设置中都取得了更优越的性能。

Conclusion: FediLoRA成功应对了联邦多模态学习中的异构性和模态缺失问题，并显著提升了模型性能。

Abstract: Foundation models have demonstrated remarkable performance across a wide
range of tasks, yet their large parameter sizes pose challenges for practical
deployment, especially in decentralized environments. Parameter-efficient
fine-tuning (PEFT), such as Low-Rank Adaptation (LoRA), reduces local computing
and memory overhead, making it attractive for federated learning. However,
existing federated LoRA methods typically assume uniform rank configurations
and unimodal inputs, overlooking two key real-world challenges: (1)
heterogeneous client resources have different LoRA ranks, and (2) multimodal
data settings with potentially missing modalities. In this work, we propose
FediLoRA, a simple yet effective framework for federated multimodal fine-tuning
under heterogeneous LoRA ranks and missing modalities. FediLoRA introduces a
dimension-wise aggregation strategy that reweights LoRA updates without
information dilution during aggregation. It also includes a lightweight
layer-wise model editing method that selectively incorporates global parameters
to repair local components which improves both client and global model
performances. Experimental results on three multimodal benchmark datasets
demonstrate that FediLoRA achieves superior performance over competitive
baselines in both global and personalized settings, particularly in the
presence of modality incompleteness.

</details>


### [366] [Machine Generalize Learning in Agent-Based Models: Going Beyond Surrogate Models for Calibration in ABMs](https://arxiv.org/abs/2509.07013)
*Sima Najafzadehkhoei,George Vega Yon,Bernardo Modenesi,Derek S. Meyer*

Main category: cs.LG

TL;DR: 使用监督学习训练了一个双向LSTM来学习流行时间序列到SIR参数的反向映射，以提高流行病学模型的校准效率。


<details>
  <summary>Details</summary>
Motivation: 校准基于代理的流行病模型计算成本高昂，需要一种更有效的方法。

Method: 使用一个三层双向LSTM，输入60天的发病率、人口规模和恢复率，输出传播概率、接触率和基本再生数（R0）。训练过程包含一个鼓励R0 *恢复率等于传播概率 *接触率的符合性惩罚。

Result: 与近似贝叶斯计算（ABC）相比，该方法在所有目标（R0、传播概率、接触率）上都实现了更低的平均绝对误差（MAE），提供了更窄且覆盖范围接近名义值的预测区间，并将每次校准的实际运行时间从77.4秒减少到2.35秒。

Conclusion: 该监督学习方法能够快速有效地校准基于代理的流行病模型，即使在接触率和传播概率部分不可识别的情况下，也能比ABC更忠实地重现流行病曲线，从而实现快速实用的校准。

Abstract: Calibrating agent-based epidemic models is computationally demanding. We
present a supervised machine learning calibrator that learns the inverse
mapping from epidemic time series to SIR parameters. A three-layer
bidirectional LSTM ingests 60-day incidence together with population size and
recovery rate, and outputs transmission probability, contact rate, and R0.
Training uses a composite loss with an epidemiology-motivated consistency
penalty that encourages R0 \* recovery rate to equal transmission probability
\* contact rate.
  In a 1000-scenario simulation study, we compare the calibrator with
Approximate Bayesian Computation (likelihood-free MCMC). The method achieves
lower error across all targets (MAE: R0 0.0616 vs 0.275; transmission 0.0715 vs
0.128; contact 1.02 vs 4.24), produces tighter predictive intervals with near
nominal coverage, and reduces wall clock time from 77.4 s to 2.35 s per
calibration. Although contact rate and transmission probability are partially
nonidentifiable, the approach reproduces epidemic curves more faithfully than
ABC, enabling fast and practical calibration. We evaluate it on SIR agent based
epidemics generated with epiworldR and provide an implementation in R.

</details>


### [367] [An efficient deep reinforcement learning environment for flexible job-shop scheduling](https://arxiv.org/abs/2509.07019)
*Xinquan Wu,Xuefeng Yan,Mingqiang Wei,Donghai Guan*

Main category: cs.LG

TL;DR: 本文提出了一个用于柔性作业车间调度问题（FJSP）的简单时间顺序深度强化学习（DRL）环境，并结合近端策略优化（PPO）算法，设计了新的状态表示和奖励函数，在公开基准实例上取得了与现有方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习（DRL）调度方法主要关注DRL智能体本身的设计，而忽略了DRL环境的建模。本文旨在解决FJSP问题，并提出一个新的DRL环境和模型。

Method: 提出一个基于离散事件模拟的FJSP的简单时间顺序DRL环境，并基于近端策略优化（PPO）提出一个端到端的DRL调度模型。同时，设计了一种基于调度环境中的两个状态变量的新型状态表示，以及一种基于机器调度区域的新型可理解奖励函数。

Result: 在公开基准实例上的实验结果表明，在本文提出的调度环境中，简单的优先调度规则（PDR）性能得到提升。所提出的DRL调度模型在与OR-Tools、元启发式算法、DRL和PDR调度方法进行比较时，取得了具有竞争力的性能。

Conclusion: 本文提出的简单时间顺序DRL环境和端到端的DRL调度模型，在FJSP问题上能够取得与现有先进方法相媲美的性能，并且通过改进状态表示和奖励函数，优化了DRL在FJSP问题上的应用。

Abstract: The Flexible Job-shop Scheduling Problem (FJSP) is a classical combinatorial
optimization problem that has a wide-range of applications in the real world.
In order to generate fast and accurate scheduling solutions for FJSP, various
deep reinforcement learning (DRL) scheduling methods have been developed.
However, these methods are mainly focused on the design of DRL scheduling
Agent, overlooking the modeling of DRL environment. This paper presents a
simple chronological DRL environment for FJSP based on discrete event
simulation and an end-to-end DRL scheduling model is proposed based on the
proximal policy optimization (PPO). Furthermore, a short novel state
representation of FJSP is proposed based on two state variables in the
scheduling environment and a novel comprehensible reward function is designed
based on the scheduling area of machines. Experimental results on public
benchmark instances show that the performance of simple priority dispatching
rules (PDR) is improved in our scheduling environment and our DRL scheduling
model obtains competing performance compared with OR-Tools, meta-heuristic, DRL
and PDR scheduling methods.

</details>


### [368] [Fed-REACT: Federated Representation Learning for Heterogeneous and Evolving Data](https://arxiv.org/abs/2509.07198)
*Yiyue Chen,Usman Akram,Chianing Wang,Haris Vikalo*

Main category: cs.LG

TL;DR: Federated learning (FL) is efficient but struggles with heterogeneous and evolving client data. Fed-REACT addresses this by combining representation learning and evolutionary clustering. Clients learn local models for feature extraction, and the server clusters clients for coordinated training. Fed-REACT shows superior accuracy and robustness.


<details>
  <summary>Details</summary>
Motivation: Centralized machine learning has high resource costs and privacy concerns. Federated learning (FL) offers an alternative, but real-world data heterogeneity and evolution degrade its performance.

Method: Fed-REACT uses a two-stage process: 1) Clients learn local models for feature representation extraction. 2) The server dynamically clusters clients based on representations and coordinates cluster-wise training.

Result: Theoretical analysis of the representation learning stage and empirical demonstration of superior accuracy and robustness on real-world datasets.

Conclusion: Fed-REACT effectively handles heterogeneous and evolving client data in federated learning, outperforming standard algorithms in accuracy and robustness.

Abstract: Motivated by the high resource costs and privacy concerns associated with
centralized machine learning, federated learning (FL) has emerged as an
efficient alternative that enables clients to collaboratively train a global
model while keeping their data local. However, in real-world deployments,
client data distributions often evolve over time and differ significantly
across clients, introducing heterogeneity that degrades the performance of
standard FL algorithms. In this work, we introduce Fed-REACT, a federated
learning framework designed for heterogeneous and evolving client data.
Fed-REACT combines representation learning with evolutionary clustering in a
two-stage process: (1) in the first stage, each client learns a local model to
extracts feature representations from its data; (2) in the second stage, the
server dynamically groups clients into clusters based on these representations
and coordinates cluster-wise training of task-specific models for downstream
objectives such as classification or regression. We provide a theoretical
analysis of the representation learning stage, and empirically demonstrate that
Fed-REACT achieves superior accuracy and robustness on real-world datasets.

</details>


### [369] [1 bit is all we need: binary normalized neural networks](https://arxiv.org/abs/2509.07025)
*Eduardo Lobo Lustoda Cabral,Paulo Pirozelli,Larissa Driemeier*

Main category: cs.LG

TL;DR: 本文提出了一种仅使用单比特参数（0或1）的新型神经网络层（二值归一化层）和模型，可以显著减少内存需求（32倍）并保持与传统模型相当的性能，且易于在现有硬件上实现，有望用于移动设备或CPU等资源受限的场景。


<details>
  <summary>Details</summary>
Motivation: 随着大型神经网络模型（尤其是语言模型和基础图像模型）的规模不断增大，其部署面临内存需求大和计算效率低的挑战，因此需要降低模型的内存占用并提高计算效率，以实现实际部署和有效利用。

Method: 提出了一种新型神经网络层（二值归一化层）和模型，其中所有层（包括权重和偏置）的参数值仅限于0或1。这种二值归一化层可以应用于各种类型的层（如全连接层、卷积层、注意力层等），并且是对应常规层的轻微变体。

Result: 通过在一个解决多类别图像分类问题的模型和一个用于预测序列下一个词元的语言模型（基于Transformer块和多头注意力）上配置二值归一化层进行了实验。结果表明，使用二值归一化层的模型在性能上几乎与使用32位浮点数参数的等效模型相当。

Conclusion: 二值归一化层能够开发出内存占用仅为现有模型32倍且性能相当的模型。此外，这些层易于在当前计算机上使用1位数组实现，无需专用电子硬件。这种新型层有望开启一类新的大型神经网络模型，其内存需求较低，并能在如移动设备或仅CPU等简单且廉价的硬件上部署。

Abstract: The increasing size of large neural network models, specifically language
models and foundational image models, poses deployment challenges, prompting
efforts to reduce memory requirements and enhance computational efficiency.
These efforts are critical to ensure practical deployment and effective
utilization of these models across various applications. In this work, a novel
type of neural network layers and models is developed that uses only single-bit
parameters. In this novel type of models all parameters of all layers,
including kernel weights and biases, only have values equal to zero or one.
This novel type of models uses layers named as binary normalized layer. These
binary normalized layers can be of any type, such as fully connected,
convolutional, attention, etc., and they consist of slight variations of the
corresponding conventional layers. To show the effectiveness of the binary
normalized layers, two different models are configured to solve a multiclass
image classification problem and a language decoder to predict the next token
of a sequence. The model to solve the image classification has convolutional
and fully connected layers, and the language model is composed of transformer
blocks with multi-head attention. The results show that models with binary
normalized layers present almost the same results obtained by equivalent models
with real 32-bit parameters. The binary normalized layers allow to develop
models that use 32 times less memory than current models and have equivalent
performance. Besides, the binary normalized layers can be easily implemented on
current computers using 1-bit arrays, and do not require the development of
dedicated electronic hardware. This novel type of layers opens a new era for
large neural network models with reduced memory requirements that can be
deployed using simple and cheap hardware, such as mobile devices or only cpus.

</details>


### [370] [FedTeddi: Temporal Drift and Divergence Aware Scheduling for Timely Federated Edge Learning](https://arxiv.org/abs/2509.07342)
*Yuxuan Bai,Yuxuan Sun,Tan Chen,Wei Chen,Sheng Zhou,Zhisheng Niu*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 FedTeddi 的联邦边缘学习算法，用于解决动态、非独立同分布数据下的模型训练问题，通过量化数据的时间漂移和集体散度，并结合新颖的优化目标和联合调度与带宽分配算法，提高了模型的收敛速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有联邦边缘学习（FEEL）研究大多假设数据是静态的，但在实际应用中，客户端的数据是持续更新且具有时变和非独立同分布（non-i.i.d.）的特性。因此，需要一种能够及时有效地适应这些不断演变的数据的模型更新方法。

Method: 提出了一种名为 FedTeddi 的时间漂移和散度感知调度算法。首先，使用地球运动距离（EMD）量化数据的时间漂移和集体散度。然后，提出了一种新的优化目标，并开发了一个联合调度和带宽分配算法，使 FEEL 系统能够在不遗忘先前知识的情况下快速从新数据中学习。

Result: 实验结果表明，与随机调度等基准方法相比，FedTeddi 算法在 CIFAR-10 和 CIFAR-100 数据集上的测试准确率更高，收敛速度更快，收敛率分别提高了 58.4% 和 49.2%。

Conclusion: FedTeddi 算法能够有效地处理动态演变和非独立同分布的数据，在有限的通信资源下实现了联邦边缘学习的快速收敛和模型性能的提升。

Abstract: Federated edge learning (FEEL) enables collaborative model training across
distributed clients over wireless networks without exposing raw data. While
most existing studies assume static datasets, in real-world scenarios clients
may continuously collect data with time-varying and non-independent and
identically distributed (non-i.i.d.) characteristics. A critical challenge is
how to adapt models in a timely yet efficient manner to such evolving data. In
this paper, we propose FedTeddi, a temporal-drift-and-divergence-aware
scheduling algorithm that facilitates fast convergence of FEEL under dynamic
data evolution and communication resource limits. We first quantify the
temporal dynamics and non-i.i.d. characteristics of data using temporal drift
and collective divergence, respectively, and represent them as the Earth
Mover's Distance (EMD) of class distributions for classification tasks. We then
propose a novel optimization objective and develop a joint scheduling and
bandwidth allocation algorithm, enabling the FEEL system to learn from new data
quickly without forgetting previous knowledge. Experimental results show that
our algorithm achieves higher test accuracy and faster convergence compared to
benchmark methods, improving the rate of convergence by 58.4% on CIFAR-10 and
49.2% on CIFAR-100 compared to random scheduling.

</details>


### [371] [Recursive State Inference for Linear PASFA](https://arxiv.org/abs/2509.07028)
*Vishal Rishi*

Main category: cs.LG

TL;DR: 生成一个太长不看的摘要


<details>
  <summary>Details</summary>
Motivation: 比较了现有的方法，并指出了需要开发更有效的方法来从观察结果和模型中推断状态（慢特征）。

Method: 提出了一种线性 PASFA 的递归扩展，该算法在给定观测值和模型的情况下，对根据 ARMA 过程演变的状态执行 MMSE 估计。

Result: 该技术在合成数据集上进行了评估，以证明其正确性。

Conclusion: 尽管现有方法通过将 ARMA 过程转换为状态空间模型来解决此问题，但原始状态（或慢特征）难以恢复。所提出的技术可以恢复这些状态。

Abstract: Slow feature analysis (SFA), as a method for learning slowly varying features
in classification and signal analysis, has attracted increasing attention in
recent years. Recent probabilistic extensions to SFA learn effective
representations for classification tasks. Notably, the Probabilistic Adaptive
Slow Feature Analysis models the slow features as states in an ARMA process and
estimate the model from the observations. However, there is a need to develop
efficient methods to infer the states (slow features) from the observations and
the model. In this paper, a recursive extension to the linear PASFA has been
proposed. The proposed algorithm performs MMSE estimation of states evolving
according to an ARMA process, given the observations and the model. Although
current methods tackle this problem using Kalman filters after transforming the
ARMA process into a state space model, the original states (or slow features)
that form useful representations cannot be easily recovered. The proposed
technique is evaluated on a synthetic dataset to demonstrate its correctness.

</details>


### [372] [A Minimalist Bayesian Framework for Stochastic Optimization](https://arxiv.org/abs/2509.07030)
*Kaizheng Wang*

Main category: cs.LG

TL;DR: 我们提出了一个最小化的贝叶斯框架，仅对感兴趣的组件（例如最优值的位置）设置先验，并通过剖面似然消除 the nuisance parameters，以处理复杂约束。基于此框架，我们开发了 MINTS 算法，并证明了其在多臂老虎机问题上的近乎最优遗憾界限。


<details>
  <summary>Details</summary>
Motivation: 传统的贝叶斯方法在处理复杂结构约束时存在局限性，因为它们要求对所有参数进行概率建模。

Method: 提出一个最小化的贝叶斯框架，仅对感兴趣的组件（例如最优值的位置）设置先验，并使用剖面似然消除 the nuisance parameters，然后实例化了一个名为 MINTS 的 Thompson Sampling 算法。

Result: MINTS 算法可以处理包括连续臂老虎机和动态定价在内的结构化问题，并为中心法人和椭圆体方法等经典凸优化算法提供了概率视角。此外，在多臂老虎机问题上，MINTS 算法具有近乎最优的遗憾界限。

Conclusion: 所提出的最小化贝叶斯框架能够有效地处理具有复杂结构约束的序贯决策问题，并且MINTS算法在实践和理论上都表现出了优越的性能。

Abstract: The Bayesian paradigm offers principled tools for sequential decision-making
under uncertainty, but its reliance on a probabilistic model for all parameters
can hinder the incorporation of complex structural constraints. We introduce a
minimalist Bayesian framework that places a prior only on the component of
interest, such as the location of the optimum. Nuisance parameters are
eliminated via profile likelihood, which naturally handles constraints. As a
direct instantiation, we develop a MINimalist Thompson Sampling (MINTS)
algorithm. Our framework accommodates structured problems, including
continuum-armed Lipschitz bandits and dynamic pricing. It also provides a
probabilistic lens on classical convex optimization algorithms such as the
center of gravity and ellipsoid methods. We further analyze MINTS for
multi-armed bandits and establish near-optimal regret guarantees.

</details>


### [373] [MoE-Compression: How the Compression Error of Experts Affects the Inference Accuracy of MoE Model?](https://arxiv.org/abs/2509.07727)
*Songkai Ma,Zhaorui Zhang,Sheng Di,Benben Liu,Xiaodong Yu,Xiaoyi Lu,Dan Wang*

Main category: cs.LG

TL;DR: 为了解决LLM中MoE模型在有限GPU内存下的推理效率问题，本文提出使用有损压缩算法（如SZ3和CuSZp）来压缩非激活的专家，以减少内存和数据传输开销。实验表明，浅层专家的压缩误差对精度影响不大，中层专家对压缩误差敏感，而深层专家在一定误差下甚至可能提升精度。


<details>
  <summary>Details</summary>
Motivation: 混合专家（MoE）模型在大型语言模型（LLM）中得到广泛应用，但在有限的GPU内存下高效服务MoE模型是一个严峻的挑战。将非激活专家卸载到主内存是一种有效的解决方案，但这带来了专家在GPU内存和主内存之间传输的挑战。因此，需要探索一种有效的专家压缩方法，并分析压缩误差对推理性能的影响。

Method: 提出使用有误差边界的有损压缩算法（如SZ3和CuSZp）来压缩非激活的专家，以降低MoE推理过程中数据传输的开销。通过在各种基准测试上进行广泛的实验，全面分析了不同专家中的压缩误差对整体推理精度的影响。

Result: 实验结果表明，主要负责注意力机制和输入向量表示转换的浅层专家，在有界误差压缩下，推理精度下降最小。而对于模型推理至关重要的中层专家，压缩误差会显著降低推理精度。有趣的是，对主要负责指令遵循和输出整合的深层专家引入有界误差，有时反而能提高推理精度。

Conclusion: 有误差边界的有损压缩是一种有效的方法，可以减少MoE模型推理中的内存和数据传输开销。不同层级的专家对压缩误差的敏感度不同，浅层专家受影响最小，中层专家最敏感，而深层专家甚至可能从压缩误差中受益。

Abstract: With the widespread application of Mixture of Experts (MoE) reasoning models
in the field of LLM learning, efficiently serving MoE models under limited GPU
memory constraints has emerged as a significant challenge. Offloading the
non-activated experts to main memory has been identified as an efficient
approach to address such a problem, while it brings the challenges of
transferring the expert between the GPU memory and main memory. We need to
explore an efficient approach to compress the expert and analyze how the
compression error affects the inference performance.
  To bridge this gap, we propose employing error-bounded lossy compression
algorithms (such as SZ3 and CuSZp) to compress non-activated experts, thereby
reducing data transfer overhead during MoE inference. We conduct extensive
experiments across various benchmarks and present a comprehensive analysis of
how compression-induced errors in different experts affect overall inference
accuracy. The results indicate that experts in the shallow layers, which are
primarily responsible for the attention mechanism and the transformation of
input tokens into vector representations, exhibit minimal degradation in
inference accuracy when subjected to bounded errors. In contrast, errors in the
middle-layer experts, which are central to model reasoning, significantly
impair inference accuracy. Interestingly, introducing bounded errors in the
deep-layer experts, which are mainly responsible for instruction following and
output integration, can sometimes lead to improvements in inference accuracy.

</details>


### [374] [Methodological Insights into Structural Causal Modelling and Uncertainty-Aware Forecasting for Economic Indicators](https://arxiv.org/abs/2509.07036)
*Federico Cerutti*

Main category: cs.LG

TL;DR: 本研究结合因果发现和不确定性感知预测方法，分析了美国宏观经济时间序列数据（GDP、经济增长、通货膨胀、失业率）。研究发现了经济增长对GDP的单向因果关系，并利用大型语言模型Chronos对失业率进行了零样本预测，取得了较好的准确性和置信区间，有助于经济政策制定和预测。 


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于结合因果发现和不确定性感知预测方法，以更好地分析金融时间序列数据，并为经济政策制定提供信息和增强预测的稳健性。具体而言，研究关注美国四个关键宏观经济指标（GDP、经济增长、通货膨胀、失业率）之间的动态因果关系，并探索利用大型语言模型进行时间序列预测。

Method: 本研究采用LPCMCI框架结合高斯过程距离相关性（GPDC）来发现美国四个关键宏观经济指标（GDP、经济增长、通货膨胀、失业率）之间动态因果关系。数据为1970年至2021年的季度数据。对于预测部分，研究利用了为时间序列训练的大型语言模型Chronos进行失业率的零样本预测。

Result: 研究结果显示，经济增长与GDP之间存在稳健的单向因果关系。通货膨胀的连通性有限，暗示存在潜在因素的影响。失业率表现出强烈的自回归依赖性。利用Chronos模型进行的零样本预测，在预测一个和两个季度后失业率时，one- and two-quarters ahead，表现出准确性，并提供了90%的置信区间，可用于异常检测。

Conclusion: 本研究证明了结合因果结构学习和概率语言模型在经济政策制定和提高预测稳健性方面的价值。通过因果发现揭示经济指标间的关系，并利用大型语言模型进行不确定性感知预测，为理解和预测宏观经济动态提供了新的方法。

Abstract: This paper presents a methodological approach to financial time series
analysis by combining causal discovery and uncertainty-aware forecasting. As a
case study, we focus on four key U.S. macroeconomic indicators -- GDP, economic
growth, inflation, and unemployment -- and we apply the LPCMCI framework with
Gaussian Process Distance Correlation (GPDC) to uncover dynamic causal
relationships in quarterly data from 1970 to 2021. Our results reveal a robust
unidirectional causal link from economic growth to GDP and highlight the
limited connectivity of inflation, suggesting the influence of latent factors.
Unemployment exhibits strong autoregressive dependence, motivating its use as a
case study for probabilistic forecasting. Leveraging the Chronos framework, a
large language model trained for time series, we perform zero-shot predictions
on unemployment. This approach delivers accurate forecasts one and two quarters
ahead, without requiring task-specific training. Crucially, the model's
uncertainty-aware predictions yield 90\% confidence intervals, enabling
effective anomaly detection through statistically principled deviation
analysis. This study demonstrates the value of combining causal structure
learning with probabilistic language models to inform economic policy and
enhance forecasting robustness.

</details>


### [375] [Benchmarking Vision Transformers and CNNs for Thermal Photovoltaic Fault Detection with Explainable AI Validation](https://arxiv.org/abs/2509.07039)
*Serra Aksoy*

Main category: cs.LG

TL;DR: 本研究通过XRAI显著性分析，首次系统性地比较了卷积神经网络（CNN）和视觉Transformer（ViT）在光伏（PV）热故障检测中的性能和可解释性。结果表明，Swin Transformer在性能上优于CNN，并且两种模型在很大程度上学习了符合热物理原理的特征，但模型在区分不同类型的故障（特别是环境因素引起的故障）方面仍存在挑战。


<details>
  <summary>Details</summary>
Motivation: 在能源基础设施应用中，深度学习在光伏热故障检测方面虽然准确率高，但缺乏与热物理原理相符的验证，阻碍了其在自动化光伏监控中的广泛应用。

Method: 本研究系统性地比较了ResNet-18、EfficientNet-B0（CNN）和ViT-Tiny、Swin-Tiny（ViT）在热故障检测中的性能，并使用XRAI显著性分析来评估模型决策是否符合热物理原理。

Result: Swin Transformer在20,000张红外图像上表现最佳（二分类准确率94%；多分类准确率73%）。XRAI分析显示，模型能够学习到热物理上合理的特征，如单元缺陷的局部热点、二极管故障的线性热路径和植被遮蔽的热边界。然而，不同故障类型的检测性能差异很大，电气故障检测效果好（F1分数>0.90），而污垢等环境因素的检测则面临挑战（F1分数0.20-0.33）。

Conclusion: 本研究提出的热物理引导的可解释性方法为能源监控应用中AI决策的验证提供了方法论，解决了可再生能源基础设施部署中的障碍。

Abstract: Artificial intelligence deployment for automated photovoltaic (PV) monitoring
faces interpretability barriers that limit adoption in energy infrastructure
applications. While deep learning achieves high accuracy in thermal fault
detection, validation that model decisions align with thermal physics
principles remains lacking, creating deployment hesitancy where understanding
model reasoning is critical. This study provides a systematic comparison of
convolutional neural networks (ResNet-18, EfficientNet-B0) and vision
transformers (ViT-Tiny, Swin-Tiny) for thermal PV fault detection, using XRAI
saliency analysis to assess alignment with thermal physics principles. This
represents the first systematic comparison of CNNs and vision transformers for
thermal PV fault detection with physics-validated interpretability. Evaluation
on 20,000 infrared images spanning normal operation and 11 fault categories
shows that Swin Transformer achieves the highest performance (94% binary
accuracy; 73% multiclass accuracy) compared to CNN approaches. XRAI analysis
reveals that models learn physically meaningful features, such as localized
hotspots for cell defects, linear thermal paths for diode failures, and thermal
boundaries for vegetation shading, consistent with expected thermal signatures.
However, performance varies significantly across fault types: electrical faults
achieve strong detection (F1-scores >0.90) while environmental factors like
soiling remain challenging (F1-scores 0.20-0.33), indicating limitations
imposed by thermal imaging resolution. The thermal physics-guided
interpretability approach provides methodology for validating AI
decision-making in energy monitoring applications, addressing deployment
barriers in renewable energy infrastructure.

</details>


### [376] [Lookup multivariate Kolmogorov-Arnold Networks](https://arxiv.org/abs/2509.07103)
*Sergey Pozdnyakov,Philippe Schwaller*

Main category: cs.LG

TL;DR: lmKANs are a drop-in replacement for linear layers in deep learning models that offer a better trade-off between capacity and inference cost by using trainable low-dimensional multivariate functions implemented as spline lookup tables. They can reduce inference FLOPs by up to 6.0x and increase H100 throughput by over 10x at equal accuracy, with notable improvements also seen in CNNs on image datasets.


<details>
  <summary>Details</summary>
Motivation: Linear layers constitute a significant portion of the parameter count and computational cost in modern deep learning models. There is a need for efficient alternatives that maintain or improve model performance.

Method: The paper introduces lookup multivariate Kolmogorov-Arnold Networks (lmKANs) as a replacement for linear layers. lmKANs approximate high-dimensional mappings using trainable low-dimensional multivariate functions, which are implemented as spline lookup tables for efficient computation. The paper also mentions the availability of custom CUDA kernels for lmKANs.

Result: lmKANs reduce inference FLOPs by up to 6.0x while matching the flexibility of MLPs. In a feedforward benchmark on methane configurations, lmKANs achieve over 10x higher H100 throughput at equal accuracy. lmKAN-based CNNs show 1.6-2.1x reduction in inference FLOPs on CIFAR-10 and a 1.7x reduction on ImageNet-1k, all at matched accuracy.

Conclusion: lmKANs offer a substantially improved trade-off between model capacity and inference cost compared to traditional linear layers, demonstrating significant efficiency gains across various deep learning architectures and tasks.

Abstract: High-dimensional linear mappings, or linear layers, dominate both the
parameter count and the computational cost of most modern deep-learning models.
We introduce a general drop-in replacement, lookup multivariate
Kolmogorov-Arnold Networks (lmKANs), which deliver a substantially better
trade-off between capacity and inference cost. Our construction expresses a
general high-dimensional mapping through trainable low-dimensional multivariate
functions. These functions can carry dozens or hundreds of trainable parameters
each, and yet it takes only a few multiplications to compute them because they
are implemented as spline lookup tables. Empirically, lmKANs reduce inference
FLOPs by up to 6.0x while matching the flexibility of MLPs in general
high-dimensional function approximation. In another feedforward fully connected
benchmark, on the tabular-like dataset of randomly displaced methane
configurations, lmKANs enable more than 10x higher H100 throughput at equal
accuracy. Within frameworks of Convolutional Neural Networks, lmKAN-based CNNs
cut inference FLOPs at matched accuracy by 1.6-2.1x and by 1.7x on the CIFAR-10
and ImageNet-1k datasets, respectively. Our code, including dedicated CUDA
kernels, is available online at https://github.com/schwallergroup/lmkan.

</details>


### [377] [Riemannian Batch Normalization: A Gyro Approach](https://arxiv.org/abs/2509.07115)
*Ziheng Chen,Xiao-Jun Wu,Nicu Sebe*

Main category: cs.LG

TL;DR: GyroBN是一个基于陀螺结构的黎曼流形批量归一化框架，适用于机器学习中存在陀螺结构的黎曼流形。该框架通过伪约化和陀螺等距旋转两个条件，理论上控制样本统计量，并适用于所有已知的机器学习陀螺结构。GyroBN包含了现有的黎曼归一化方法，并在七种代表性几何空间上进行了实例化和实验验证。


<details>
  <summary>Details</summary>
Motivation: 深度学习中的归一化层对于处理流形数据至关重要，但现有的欧氏度量方法不足以处理此类数据。而许多机器学习中的黎曼流形具有陀螺结构，可以扩展欧氏神经网络到非欧氏域。

Method: 提出了一种名为GyroBN的黎曼批量归一化框架，该框架基于陀螺结构。通过引入伪约化和陀螺等距旋转两个必要条件，确保GyroBN能够理论上控制样本统计量。GyroBN还包含了现有的黎曼归一化方法作为特例。在七种代表性几何空间上进行了GyroBN的实例化，并推导了新的陀螺和黎曼结构。

Result: GyroBN框架在七种代表性几何空间（包括格拉斯曼流形、五种恒定曲率空间和相关流形）上的实验证明了其有效性。

Conclusion: GyroBN框架成功地将批量归一化推广到具有陀螺结构的黎曼流形上，并通过理论和实验证明了其有效性。

Abstract: Normalization layers are crucial for deep learning, but their Euclidean
formulations are inadequate for data on manifolds. On the other hand, many
Riemannian manifolds in machine learning admit gyro-structures, enabling
principled extensions of Euclidean neural networks to non-Euclidean domains.
Inspired by this, we introduce GyroBN, a principled Riemannian batch
normalization framework for gyrogroups. We establish two necessary conditions,
namely \emph{pseudo-reduction} and \emph{gyroisometric gyrations}, that
guarantee GyroBN with theoretical control over sample statistics, and show that
these conditions hold for all known gyrogroups in machine learning. Our
framework also incorporates several existing Riemannian normalization methods
as special cases. We further instantiate GyroBN on seven representative
geometries, including the Grassmannian, five constant curvature spaces, and the
correlation manifold, and derive novel gyro and Riemannian structures to enable
these instantiations. Experiments across these geometries demonstrate the
effectiveness of GyroBN. The code is available at
https://github.com/GitZH-Chen/GyroBN.git.

</details>


### [378] [Of Graphs and Tables: Zero-Shot Node Classification with Tabular Foundation Models](https://arxiv.org/abs/2509.07143)
*Adrian Hayler,Xingyue Huang,İsmail İlkan Ceylan,Michael Bronstein,Ben Finkelshtein*

Main category: cs.LG

TL;DR: 图基础模型（GFM）的泛化能力受限于训练数据，而表格基础模型（TFM）在多领域表现出色。本文提出TabGFM框架，将图节点表示为表格行，利用TFMs进行零样本节点分类，并通过实验验证了其在28个真实世界数据集上的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有图基础模型（GFM）的训练数据未能很好地代表真实世界图，限制了其泛化能力。而表格基础模型（TFM）在多个领域表现出强大的适用性。受此启发，本文提出将节点分类重新构建为表格问题，利用TFM的优势来提升图学习的泛化性和可扩展性。

Method: TabGFM框架首先通过特征和结构编码器将图转换为表格，然后将多个TFM应用于经过不同方式采样的表格，最后通过集成选择聚合它们的输出来进行节点分类。

Result: 通过在28个真实世界数据集上的实验，TabGFM在节点分类任务上取得了一致的改进，超越了特定任务的图神经网络（GNN）和最先进的GFM。

Conclusion: 本文提出的TabGFM框架通过将图数据转化为表格形式，并利用表格基础模型（TFM）进行学习，为实现可扩展且通用的图学习提供了一种有前景的新途径，突显了表格重构在图学习领域的潜力。

Abstract: Graph foundation models (GFMs) have recently emerged as a promising paradigm
for achieving broad generalization across various graph data. However, existing
GFMs are often trained on datasets that were shown to poorly represent
real-world graphs, limiting their generalization performance. In contrast,
tabular foundation models (TFMs) not only excel at classical tabular prediction
tasks but have also shown strong applicability in other domains such as time
series forecasting, natural language processing, and computer vision. Motivated
by this, we take an alternative view to the standard perspective of GFMs and
reformulate node classification as a tabular problem. Each node can be
represented as a row with feature, structure, and label information as columns,
enabling TFMs to directly perform zero-shot node classification via in-context
learning. In this work, we introduce TabGFM, a graph foundation model framework
that first converts a graph into a table via feature and structural encoders,
applies multiple TFMs to diversely subsampled tables, and then aggregates their
outputs through ensemble selection. Through experiments on 28 real-world
datasets, TabGFM achieves consistent improvements over task-specific GNNs and
state-of-the-art GFMs, highlighting the potential of tabular reformulation for
scalable and generalizable graph learning.

</details>


### [379] [Measuring Uncertainty in Transformer Circuits with Effective Information Consistency](https://arxiv.org/abs/2509.07149)
*Anatoly A. Krasnovsky*

Main category: cs.LG

TL;DR: 本研究提出了一种名为有效信息一致性得分（EICS）的新指标，用于量化 Transformer 电路（TCs）的可信度。EICS 结合了基于局部雅可比矩阵和激活值的归一化束不一致性，以及基于高斯 EI 代理的电路级因果涌现。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏一种形式化、单次评估的方法来量化 Transformer 电路（TCs）的激活是否与其预期算法一致，从而判断其可信度。

Method: 提出并实现了一种名为有效信息一致性得分（EICS）的度量方法。该方法结合了归一化束不一致性（基于局部雅可比矩阵和激活值）和高斯 EI 代理（用于电路级因果涌现），是一种白盒、单次、无量纲的计算方法。

Result: 提出了一种名为有效信息一致性得分（EICS）的新指标，并提供了关于分数解释、计算开销（包括快速和精确模式）的实用指南，以及一个玩具级别的验证分析。实际的 LLM 任务上的经验验证被推迟。

Conclusion: EICS 为量化 Transformer 电路（TCs）的可信度提供了一种新的、形式化的单次评估方法，有望用于提高 LLM 的可解释性和可靠性。

Abstract: Mechanistic interpretability has identified functional subgraphs within large
language models (LLMs), known as Transformer Circuits (TCs), that appear to
implement specific algorithms. Yet we lack a formal, single-pass way to
quantify when an active circuit is behaving coherently and thus likely
trustworthy. Building on prior systems-theoretic proposals, we specialize a
sheaf/cohomology and causal emergence perspective to TCs and introduce the
Effective-Information Consistency Score (EICS). EICS combines (i) a normalized
sheaf inconsistency computed from local Jacobians and activations, with (ii) a
Gaussian EI proxy for circuit-level causal emergence derived from the same
forward state. The construction is white-box, single-pass, and makes units
explicit so that the score is dimensionless. We further provide practical
guidance on score interpretation, computational overhead (with fast and exact
modes), and a toy sanity-check analysis. Empirical validation on LLM tasks is
deferred.

</details>


### [380] [PLaID++: A Preference Aligned Language Model for Targeted Inorganic Materials Design](https://arxiv.org/abs/2509.07150)
*Andy Xu,Rohan Desai,Larry Wang,Gabriel Hope,Ethan Ritz*

Main category: cs.LG

TL;DR: PLaID++是一个使用LLM加速新材料发现的工具，它通过一种新的基于Wyckoff的文本表示和直接偏好优化（DPO）技术，能够生成稳定且具有所需特性的晶体结构，其效率比先前方法提高了约50%。


<details>
  <summary>Details</summary>
Motivation: 新材料的发现对于太阳能电池、电池和碳捕获等技术进步至关重要，但传统的试错法过程缓慢且昂贵，因此需要加速新材料的研发流程。

Method: 通过一种新的基于Wyckoff的文本表示，对Qwen-2.5 7B大语言模型（LLM）进行微调，以生成晶体结构。并利用基于直接偏好优化（DPO）的强化学习技术，根据稳定性、新颖性和空间群对生成的结构进行分类和引导。

Result: PLaID++生成的热力学稳定、独特且新颖的晶体结构的比例比先前方法提高了约50%。此外，该模型能够有条件地生成具有所需空间群特性的晶体结构。迭代DPO技术在无条件和空间群条件生成方面分别实现了约115%和50%的提升。

Conclusion: PLaID++展示了将自然语言处理中的训练后技术应用于材料设计的潜力，为高效、有针对性地发现新材料铺平了道路。

Abstract: Discovering novel materials is critical for technological advancements such
as solar cells, batteries, and carbon capture. However, the development of new
materials is constrained by a slow and expensive trial-and-error process. To
accelerate this pipeline, we introduce PLaID++, a Large Language Model (LLM)
fine-tuned for stable and property-guided crystal generation. We fine-tune
Qwen-2.5 7B to generate crystal structures using a novel Wyckoff-based text
representation. We show that generation can be effectively guided with a
reinforcement learning technique based on Direct Preference Optimization (DPO),
with sampled structures categorized by their stability, novelty, and space
group. By encoding symmetry constraints directly into text and guiding model
outputs towards desirable chemical space, PLaID++ generates structures that are
thermodynamically stable, unique, and novel at a $\sim$50\% greater rate than
prior methods and conditionally generates structures with desired space group
properties. Our experiments highlight the effectiveness of iterative DPO,
achieving $\sim$115\% and $\sim$50\% improvements in unconditional and space
group conditioned generation, respectively, compared to fine-tuning alone. Our
work demonstrates the potential of adapting post-training techniques from
natural language processing to materials design, paving the way for targeted
and efficient discovery of novel materials.

</details>


### [381] [EMORF-II: Adaptive EM-based Outlier-Robust Filtering with Correlated Measurement Noise](https://arxiv.org/abs/2509.07415)
*Arslan Majal,Aamir Hussain Chughtai,Muhammad Tahir*

Main category: cs.LG

TL;DR: EMORF-II是一种基于学习的鲁棒滤波器，改进了EMORF，能够实时学习异常值特征，提高了异常值处理能力，计算开销略有增加但仍可接受。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于具有相关测量噪声的通用设置的学习型离群点鲁棒滤波器，并改进现有的EM算法离群点鲁棒滤波器（EMORF）。

Method: EMORF-II在推断过程中增加了学习离群点特征的功能，并结合离群点检测来提高离群点缓解能力。

Result: 与现有最先进的方法相比，EMORF-II在准确性方面表现出性能提升，但计算开销有所增加，然而计算复杂度保持与其他实际方法相当。

Conclusion: EMORF-II通过实时学习离群点特征，提高了离群点缓解能力，虽然计算开销有所增加，但由于其计算复杂度与其他实用方法相当，因此适用于各种应用。

Abstract: We present a learning-based outlier-robust filter for a general setup where
the measurement noise can be correlated. Since it is an enhanced version of
EM-based outlier robust filter (EMORF), we call it as EMORF-II. As it is
equipped with an additional powerful feature to learn the outlier
characteristics during inference along with outlier-detection, EMORF-II has
improved outlier-mitigation capability. Numerical experiments confirm
performance gains as compared to the state-of-the-art methods in terms of
accuracy with an increased computational overhead. However, thankfully the
computational complexity order remains at par with other practical methods
making it a useful choice for diverse applications.

</details>


### [382] [Predicting effect of novel treatments using molecular pathways and real-world data](https://arxiv.org/abs/2509.07204)
*Adrien Couetoux,Thomas Devenyns,Lise Diagne,David Champagne,Pierre-Yves Mousset,Chris Anagnostopoulos*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In pharmaceutical R&D, predicting the efficacy of a pharmaceutical in
treating a particular disease prior to clinical testing or any real-world use
has been challenging. In this paper, we propose a flexible and modular machine
learning-based approach for predicting the efficacy of an untested
pharmaceutical for treating a disease. We train a machine learning model using
sets of pharmaceutical-pathway weight impact scores and patient data, which can
include patient characteristics and observed clinical outcomes. The resulting
model then analyses weighted impact scores of an untested pharmaceutical across
human biological molecule-protein pathways to generate a predicted efficacy
value. We demonstrate how the method works on a real-world dataset with patient
treatments and outcomes, with two different weight impact score algorithms We
include methods for evaluating the generalisation performance on unseen
treatments, and to characterise conditions under which the approach can be
expected to be most predictive. We discuss specific ways in which our approach
can be iterated on, making it an initial framework to support future work on
predicting the effect of untested drugs, leveraging RWD clinical data and drug
embeddings.

</details>


### [383] [Explaining How Quantization Disparately Skews a Model](https://arxiv.org/abs/2509.07222)
*Abhimanyu Bellam,Jung-Eun Kim*

Main category: cs.LG

TL;DR: PTQ 虽有高压缩率和速度优势，但会加剧模型在少数群体上的准确性差异。本研究解释了 PTQ 如何通过改变权重和激活值，引发网络级联效应，导致 logits 方差降低、损失增加，并损害少数群体的准确性。我们进一步分析了这些影响对梯度范数和 Hessian 特征值的作用，并提出结合混合精度 QAT、数据集采样和加权损失函数的方法，以实现公平的量化模型部署。


<details>
  <summary>Details</summary>
Motivation: PTQ（后训练量化）虽然有高压缩率和速度优势，但会加剧模型在少数群体上的准确性差异。本研究旨在分析 PTQ 导致准确性差异的原因，并提出缓解措施。

Method: 我们分析了 PTQ 如何通过改变权重和激活值，引发网络级联效应，导致 logits 方差降低、损失增加，并损害少数群体的准确性。我们还研究了这些影响对梯度范数和 Hessian 特征值的作用。为缓解这些问题，我们提出结合混合精度 QAT、数据集采样和加权损失函数。

Result: PTQ 导致 logits 方差降低、损失增加，并损害少数群体的准确性。这些影响也体现在梯度范数和 Hessian 特征值上。

Conclusion: PTQ 会加剧模型在少数群体上的准确性差异。我们提出了一种结合混合精度 QAT、数据集采样和加权损失函数的方法，以实现公平的量化模型部署。

Abstract: Post Training Quantization (PTQ) is widely adopted due to its high
compression capacity and speed with minimal impact on accuracy. However, we
observed that disparate impacts are exacerbated by quantization, especially for
minority groups. Our analysis explains that in the course of quantization there
is a chain of factors attributed to a disparate impact across groups during
forward and backward passes. We explore how the changes in weights and
activations induced by quantization cause cascaded impacts in the network,
resulting in logits with lower variance, increased loss, and compromised group
accuracies. We extend our study to verify the influence of these impacts on
group gradient norms and eigenvalues of the Hessian matrix, providing insights
into the state of the network from an optimization point of view. To mitigate
these effects, we propose integrating mixed precision Quantization Aware
Training (QAT) with dataset sampling methods and weighted loss functions,
therefore providing fair deployment of quantized neural networks.

</details>


### [384] [Systematic Optimization of Open Source Large Language Models for Mathematical Reasoning](https://arxiv.org/abs/2509.07238)
*Pranav Pawar,Dhwaj Jain,Varun Gupta,Kaustav Dedhia,Dashrath Kale,Sudhir Dhekane*

Main category: cs.LG

TL;DR: 通过实验探索和优化模型参数，显著提升了数学推理任务的效率和性能，并提出了一个通用的优化框架。


<details>
  <summary>Details</summary>
Motivation: 为数学推理任务进行模型参数的实际调优，以提高效率和性能。

Method: 对Qwen2.5-72B、Llama-3.1-70B、DeepSeek-V3、Mixtral-8x22B和Yi-Lightning等五个SOTA模型，在温度、推理步数、规划周期和核采样等参数空间进行了系统优化，并在数学推理基准测试上进行了评估。

Result: 平均计算成本降低29.4%，推理速度提高23.9%。DeepSeek-V3准确率达98%，Mixtral-8x22B的每准确响应成本最低（361.5 tokens）。发现较低的温度（0.1-0.4）和较少的推理步数（4-6）能提高效率且不牺牲准确性。

Conclusion: 提出了一个生产导向的参数优化框架，发现了适用于不同模型架构的通用优化趋势，并为数学推理任务提供了生产就绪的配置。

Abstract: This paper presents a practical investigation into fine-tuning model
parameters for mathematical reasoning tasks through experimenting with various
configurations including randomness control, reasoning depth, and sampling
strategies, careful tuning demonstrates substantial improvements in efficiency
as well as performance. A holistically optimized framework is introduced for
five state-of-the-art models on mathematical reasoning tasks, exhibiting
significant performance boosts while maintaining solution correctness. Through
systematic parameter optimization across Qwen2.5-72B, Llama-3.1-70B,
DeepSeek-V3, Mixtral-8x22B, and Yi-Lightning, consistent efficiency gains are
demonstrated with 100% optimization success rate. The methodology achieves an
average 29.4% reduction in computational cost and 23.9% improvement in
inference speed across all tested models. This framework systematically
searches parameter spaces including temperature (0.1-0.5), reasoning steps
(4-12), planning periods (1-4), and nucleus sampling (0.85-0.98), determining
optimal configurations through testing on mathematical reasoning benchmarks.
Critical findings show that lower temperature regimes (0.1-0.4) and reduced
reasoning steps (4-6) consistently enhance efficiency without compromising
accuracy. DeepSeek-V3 achieves the highest accuracy at 98%, while Mixtral-8x22B
delivers the most cost-effective performance at 361.5 tokens per accurate
response. Key contributions include: (1) the first comprehensive optimization
study for five diverse SOTA models in mathematical reasoning, (2) a
standardized production-oriented parameter optimization framework, (3)
discovery of universal optimization trends applicable across model
architectures, and (4) production-ready configurations with extensive
performance characterization.

</details>


### [385] [IP-Basis PINNs: Efficient Multi-Query Inverse Parameter Estimation](https://arxiv.org/abs/2509.07245)
*Shalev Manor,Mohammad Kohandel*

Main category: cs.LG

TL;DR: IP-Basis PINNs 框架通过离线训练生成基函数，在线快速推断逆问题，显著降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于物理信息神经网络（PINNs）的逆问题求解方法在多查询场景下计算成本高昂，因为每次新的观测数据都需要进行昂贵的训练。本研究旨在提出一种能够实现快速、高效的逆问题推断的元学习框架。

Method: 本研究提出了逆问题参数基函数 PINNs（IP-Basis PINNs）框架。该框架采用离线-在线分解：首先离线训练一个深度网络以生成跨越参数微分方程解空间的基函数集合；然后对于每个新的在线逆问题，冻结该网络，仅训练一个轻量级的线性输出层来推断解和参数。关键创新包括：1）新颖的在线损失函数，用于同时进行解重建和参数识别；2）通过前向模式自动微分评估 PDE 损失，显著降低计算开销；3）用于稳健离线训练的非平凡验证和早停机制。

Result: IP-Basis PINNs 在三个不同的基准测试中表现出有效性，包括对具有未知函数项的通用 PINNs 的扩展。结果显示，该方法在常数和函数参数估计方面表现一致，与标准 PINNs 相比，每次查询速度显著提升，并且在稀疏和噪声数据下表现稳健。

Conclusion: IP-Basis PINNs 框架通过离线生成基函数和在线快速推断，能够高效、稳健地解决逆问题，尤其是在多查询场景下，相比标准 PINNs 具有显著的计算优势。

Abstract: Solving inverse problems with Physics-Informed Neural Networks (PINNs) is
computationally expensive for multi-query scenarios, as each new set of
observed data requires a new, expensive training procedure. We present
Inverse-Parameter Basis PINNs (IP-Basis PINNs), a meta-learning framework that
extends the foundational work of Desai et al. (2022) to enable rapid and
efficient inference for inverse problems. Our method employs an offline-online
decomposition: a deep network is first trained offline to produce a rich set of
basis functions that span the solution space of a parametric differential
equation. For each new inverse problem online, this network is frozen, and
solutions and parameters are inferred by training only a lightweight linear
output layer against observed data. Key innovations that make our approach
effective for inverse problems include: (1) a novel online loss formulation for
simultaneous solution reconstruction and parameter identification, (2) a
significant reduction in computational overhead via forward-mode automatic
differentiation for PDE loss evaluation, and (3) a non-trivial validation and
early-stopping mechanism for robust offline training. We demonstrate the
efficacy of IP-Basis PINNs on three diverse benchmarks, including an extension
to universal PINNs for unknown functional terms-showing consistent performance
across constant and functional parameter estimation, a significant speedup per
query over standard PINNs, and robust operation with scarce and noisy data.

</details>


### [386] [GCond: Gradient Conflict Resolution via Accumulation-based Stabilization for Large-Scale Multi-Task Learning](https://arxiv.org/abs/2509.07252)
*Evgeny Alves Limarenko,Anastasiia Alexandrovna Studenikina*

Main category: cs.LG

TL;DR: GCond通过结合梯度累积和自适应仲裁机制，解决了多任务学习中的梯度冲突问题，在保持优化质量的同时提高了计算速度，并在各种模型和数据集上表现出优越的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 多任务学习（MTL）中的梯度冲突是一个重大挑战，现有的解决方案（如PCGrad、CAGrad和GradNorm）在计算上成本高昂，限制了它们在现代大型模型和Transformer中的应用。

Method: GCond是一种基于PCGrad原理的方法，结合了梯度累积和自适应仲裁机制来解决梯度冲突。

Result: GCond的随机模式实现了两倍的计算速度提升，同时保持了优化质量，并在ImageNet 1K和CT扫描数据集上在所有评估指标上均表现出优越的性能，L1和SSIM损失均低于其他方法。GCond还表现出高可扩展性，可成功应用于紧凑型和大型模型，并与AdamW和Lion/LARS等现代优化器兼容。

Conclusion: GCond为多任务学习中的梯度冲突问题提供了一种可扩展且高效的解决方案。

Abstract: In multi-task learning (MTL), gradient conflict poses a significant
challenge. Effective methods for addressing this problem, including PCGrad,
CAGrad, and GradNorm, in their original implementations are computationally
demanding, which significantly limits their application in modern large models
and transformers. We propose Gradient Conductor (GCond), a method that builds
upon PCGrad principles by combining them with gradient accumulation and an
adaptive arbitration mechanism. We evaluated GCond on self-supervised learning
tasks using MobileNetV3-Small and ConvNeXt architectures on the ImageNet 1K
dataset and a combined head and neck CT scan dataset, comparing the proposed
method against baseline linear combinations and state-of-the-art gradient
conflict resolution methods. The stochastic mode of GCond achieved a two-fold
computational speedup while maintaining optimization quality, and demonstrated
superior performance across all evaluated metrics, achieving lower L1 and SSIM
losses compared to other methods on both datasets. GCond exhibited high
scalability, being successfully applied to both compact models
(MobileNetV3-Small) and large architectures (ConvNeXt-tiny and ConvNeXt-Base).
It also showed compatibility with modern optimizers such as AdamW and
Lion/LARS. Therefore, GCond offers a scalable and efficient solution to the
problem of gradient conflicts in multi-task learning.

</details>


### [387] [Learning Generalized Hamiltonian Dynamics with Stability from Noisy Trajectory Data](https://arxiv.org/abs/2509.07280)
*Luke McLennan,Yi Wang,Ryan Farell,Minh Nguyen,Chandrajit Bajaj*

Main category: cs.LG

TL;DR: 该研究提出了一种基于变分贝叶斯推断的框架，用于从嘈杂、稀疏的相空间数据中无监督地学习各种广义哈密顿动力学。


<details>
  <summary>Details</summary>
Motivation: 现有的哈密顿网络模型难以捕捉不同类别的保守、耗散和端口哈密顿系统中，相空间中独特的、变化的运动动力学和物理学，即使它们的初始总能量可能相同。本研究旨在解决这一复杂的哈密顿流形学习挑战。

Method: 本研究通过结合稀疏辛、随机傅里叶高斯过程学习，并利用广义状态和共轭动量哈密顿动力学，对哈密顿量进行预测性的连续数值估计，来扩展现有的学习方法。这种方法适用于不同类别的保守、耗散和端口哈密顿物理系统。

Result: 在损失函数中，除了用于数据保真度的核证据下限（ELBO）损失外，还加入了稳定性和守恒约束作为额外的超参数平衡损失项。这些约束用于正则化模型的多元梯度，强制执行物理正确性，以提高预测准确性和有界不确定性。

Conclusion: 本研究提出的框架能够从嘈杂、稀疏的数据中学习广义哈密顿动力学，并通过整合稳定性、守恒约束和有界不确定性，提高了模型的物理正确性和预测准确性。

Abstract: We introduce a robust framework for learning various generalized Hamiltonian
dynamics from noisy, sparse phase-space data and in an unsupervised manner
based on variational Bayesian inference. Although conservative, dissipative,
and port-Hamiltonian systems might share the same initial total energy of a
closed system, it is challenging for a single Hamiltonian network model to
capture the distinctive and varying motion dynamics and physics of a phase
space, from sampled observational phase space trajectories. To address this
complicated Hamiltonian manifold learning challenge, we extend sparse
symplectic, random Fourier Gaussian processes learning with predictive
successive numerical estimations of the Hamiltonian landscape, using a
generalized form of state and conjugate momentum Hamiltonian dynamics,
appropriate to different classes of conservative, dissipative and
port-Hamiltonian physical systems. In addition to the kernelized evidence lower
bound (ELBO) loss for data fidelity, we incorporate stability and conservation
constraints as additional hyper-parameter balanced loss terms to regularize the
model's multi-gradients, enforcing physics correctness for improved prediction
accuracy with bounded uncertainty.

</details>


### [388] [ALICE: An Interpretable Neural Architecture for Generalization in Substitution Ciphers](https://arxiv.org/abs/2509.07282)
*Jeff Shen,Lindsay Smith*

Main category: cs.LG

TL;DR: ALICE是一个创新的基于Transformer的编码器模型，通过引入双射解码头和Gumbel-Sinkhorn方法，实现了在密码分析任务上的高精度和高速度，并展现出在未见过的密码上的出色泛化能力，其内部工作机制也与人类的解密策略相似。


<details>
  <summary>Details</summary>
Motivation: 研究神经网路在组合复杂域中的泛化能力，以密码求解作为理想的测试平台。

Method: 提出ALICE（一个用于学习可解释密码解密的架构），一个简单的、仅编码器的Transformer模型，并引入了一个新颖的双射解码头，通过Gumbel-Sinkhorn方法明确地对排列进行建模。

Result: ALICE在密码求解任务上达到了新的准确度和速度的 최첨단水平。在仅训练了约1500个独特的密码后，ALICE能够泛化到未见过的密码，这仅占可能密码空间的极小一部分。早期退出分析揭示了ALICE的预测过程，从早期层的基于频率的启发式方法，到中间层的词结构形成，再到最后层的单个字符校正。

Conclusion: ALICE的架构创新和分析方法不仅适用于密码求解，还可以推广到任何具有双射映射和组合结构域的领域，为神经网路泛化和可解释性提供了新的见解。

Abstract: We present cryptogram solving as an ideal testbed for studying neural network
generalization in combinatorially complex domains. In this task, models must
decrypt text encoded with substitution ciphers, choosing from 26! possible
mappings without explicit access to the cipher. We develop ALICE (an
Architecture for Learning Interpretable Cryptogram dEcipherment): a simple
encoder-only Transformer that sets a new state-of-the-art for both accuracy and
speed on this decryption problem. Surprisingly, ALICE generalizes to unseen
ciphers after training on only ${\sim}1500$ unique ciphers, a minute fraction
($3.7 \times 10^{-24}$) of the possible cipher space. To enhance
interpretability, we introduce a novel bijective decoding head that explicitly
models permutations via the Gumbel-Sinkhorn method, enabling direct extraction
of learned cipher mappings. Through early exit analysis, we reveal how ALICE
progressively refines its predictions in a way that appears to mirror common
human strategies for this task: early layers employ frequency-based heuristics,
middle layers form word structures, and final layers correct individual
characters. Our architectural innovations and analysis methods extend beyond
cryptograms to any domain with bijective mappings and combinatorial structure,
offering new insights into neural network generalization and interpretability.

</details>


### [389] [CancerGUIDE: Cancer Guideline Understanding via Internal Disagreement Estimation](https://arxiv.org/abs/2509.07325)
*Alyssa Unell,Noel C. F. Codella,Sam Preston,Peniel Argaw,Wen-wai Yim,Zelalem Gero,Cliff Wong,Rajesh Jena,Eric Horvitz,Amanda K. Hall,Ruican Rachel Zhong,Jiachen Li,Shrey Jain,Mu Wei,Matthew Lungren,Hoifung Poon*

Main category: cs.LG

TL;DR: 该研究提出了一种基于大型语言模型（LLM）的非小细胞肺癌（NSCLC）治疗指南生成方法，旨在提高准确性并减少所需时间。


<details>
  <summary>Details</summary>
Motivation: 将复杂的患者情况转化为符合指南的治疗建议耗时、需要专业知识且易出错，LLM的进步有望解决这些问题。

Method: 研究构建了一个包含121个NSCLC病例的纵向数据集，并由肿瘤科专家标注了相应的NCCN指南治疗路径。在此基础上，研究者展示了现有LLM在生成高质量基准方面的能力，并开发了一种结合人工标注和模型一致性信息的混合方法，以创建预测指南的代理框架和验证预测准确性的元分类器。

Result: LLM在生成基准方面与专家标注的基准具有很强的相关性（Spearman系数r=0.88, RMSE = 0.08）。元分类器在验证预测准确性方面达到了AUROC=0.800。

Conclusion: 该工作建立了一个临床上可行的、基于LLM的指南一致性系统框架，该系统能够平衡准确性、可解释性和监管要求，同时降低标注成本，为自动临床决策支持提供了可扩展的途径。

Abstract: The National Comprehensive Cancer Network (NCCN) provides evidence-based
guidelines for cancer treatment. Translating complex patient presentations into
guideline-compliant treatment recommendations is time-intensive, requires
specialized expertise, and is prone to error. Advances in large language model
(LLM) capabilities promise to reduce the time required to generate treatment
recommendations and improve accuracy. We present an LLM agent-based approach to
automatically generate guideline-concordant treatment trajectories for patients
with non-small cell lung cancer (NSCLC). Our contributions are threefold.
First, we construct a novel longitudinal dataset of 121 cases of NSCLC patients
that includes clinical encounters, diagnostic results, and medical histories,
each expertly annotated with the corresponding NCCN guideline trajectories by
board-certified oncologists. Second, we demonstrate that existing LLMs possess
domain-specific knowledge that enables high-quality proxy benchmark generation
for both model development and evaluation, achieving strong correlation
(Spearman coefficient r=0.88, RMSE = 0.08) with expert-annotated benchmarks.
Third, we develop a hybrid approach combining expensive human annotations with
model consistency information to create both the agent framework that predicts
the relevant guidelines for a patient, as well as a meta-classifier that
verifies prediction accuracy with calibrated confidence scores for treatment
recommendations (AUROC=0.800), a critical capability for communicating the
accuracy of outputs, custom-tailoring tradeoffs in performance, and supporting
regulatory compliance. This work establishes a framework for clinically viable
LLM-based guideline adherence systems that balance accuracy, interpretability,
and regulatory requirements while reducing annotation costs, providing a
scalable pathway toward automated clinical decision support.

</details>


### [390] [General Demographic Foundation Models for Enhancing Predictive Performance Across Diseases](https://arxiv.org/abs/2509.07330)
*Li-Chin Chen,Ji-Tian Sheu,Yuh-Jue Chuang*

Main category: cs.LG

TL;DR: 本文提出了通用人口统计预训练（GDP）模型，用于学习年龄和性别的表示，以提高医疗保健预测模型的性能。


<details>
  <summary>Details</summary>
Motivation: 人口统计学属性（如年龄和性别）是电子健康记录中的重要预测因子，但现有模型对其表示的学习关注不足。

Method: GDP模型结合了排序策略和编码方法，将表格型人口统计学输入转换为潜在嵌入（latent embeddings），并在多样化的疾病和人口数据集上进行了预训练和评估。

Result: 实验结果表明，序贯排序能显著提升模型在区分度、校准度和决策树分裂信息增益方面的性能，尤其是在年龄和性别风险分层作用显著的疾病中。即使在人口统计学属性预测价值相对较低的数据集中，GDP也能增强其表示重要性，从而提高其在下游梯度提升模型中的影响力。

Conclusion: 针对表格型人口统计学属性的基础模型可以实现跨任务和跨人群的泛化，为提高医疗保健应用的预测性能提供了有前景的方向。

Abstract: Demographic attributes are universally present in electronic health records
and serve as vital predictors in clinical risk stratification and treatment
decisions. Despite their significance, these attributes are often relegated to
auxiliary roles in model design, with limited attention has been given to
learning their representations. This study proposes a General Demographic
Pre-trained (GDP) model as a foundational representation framework tailored to
age and gender. The model is pre-trained and evaluated using datasets with
diverse diseases and population compositions from different geographic regions.
The GDP architecture explores combinations of ordering strategies and encoding
methods to transform tabular demographic inputs into latent embeddings.
Experimental results demonstrate that sequential ordering substantially
improves model performance in discrimination, calibration, and the
corresponding information gain at each decision tree split, particularly in
diseases where age and gender contribute significantly to risk stratification.
Even in datasets where demographic attributes hold relatively low predictive
value, GDP enhances the representational importance, increasing their influence
in downstream gradient boosting models. The findings suggest that foundational
models for tabular demographic attributes can generalize across tasks and
populations, offering a promising direction for improving predictive
performance in healthcare applications.

</details>


### [391] [SBS: Enhancing Parameter-Efficiency of Neural Representations for Neural Networks via Spectral Bias Suppression](https://arxiv.org/abs/2509.07373)
*Qihu Xie,Yuan Li,Yi Kang*

Main category: cs.LG

TL;DR: SBS通过单向排序平滑和感知随机傅里叶特征技术，有效缓解了神经表征中的频谱偏差，显著提高了模型在CIFAR-10、CIFAR-100和ImageNet上的重构精度，同时减少了参数量。


<details>
  <summary>Details</summary>
Motivation: 标准的神经表征方法（用于神经网络参数压缩）存在频谱偏差问题，难以有效重建高频细节。

Method: 提出SBS（Spectral Bias Suppression）方法，包含两个技术：1. 单向排序-基于平滑（unidirectional ordering-based smoothing）处理输出空间核平滑度；2. 单向排序-基于平滑感知随机傅里叶特征（unidirectional ordering-based smoothing aware random fourier features）根据层参数量自适应调整输入编码的频率带宽。

Result: 在CIFAR-10、CIFAR-100和ImageNet数据集上，使用ResNet模型进行评估，SBS相比现有技术（SOTA）在参数更少的情况下实现了显著更高的重构精度。

Conclusion: SBS是一种有效的参数压缩方法，通过解决神经表征中的频谱偏差问题，提升了模型性能。

Abstract: Implicit neural representations have recently been extended to represent
convolutional neural network weights via neural representation for neural
networks, offering promising parameter compression benefits. However, standard
multi-layer perceptrons used in neural representation for neural networks
exhibit a pronounced spectral bias, hampering their ability to reconstruct
high-frequency details effectively. In this paper, we propose SBS, a
parameter-efficient enhancement to neural representation for neural networks
that suppresses spectral bias using two techniques: (1) a unidirectional
ordering-based smoothing that improves kernel smoothness in the output space,
and (2) unidirectional ordering-based smoothing aware random fourier features
that adaptively modulate the frequency bandwidth of input encodings based on
layer-wise parameter count. Extensive evaluations on various ResNet models with
datasets CIFAR-10, CIFAR-100, and ImageNet, demonstrate that SBS achieves
significantly better reconstruction accuracy with less parameters compared to
SOTA.

</details>


### [392] [EfficientNet in Digital Twin-based Cardiac Arrest Prediction and Analysis](https://arxiv.org/abs/2509.07388)
*Qasim Zia,Avais Jan,Zafar Iqbal,Muhammad Mumtaz Ali,Mukarram Ali,Murray Patterson*

Main category: cs.LG

TL;DR: 提出一个结合EfficientNet和数字孪生系统的新框架，用于早期检测和分析心脏骤停。


<details>
  <summary>Details</summary>
Motivation: 心脏骤停是全球健康面临的重大挑战，早期识别和管理对改善患者预后至关重要。

Method: 使用基于EfficientNet的深度学习模型学习心血管图像特征，并结合数字孪生系统创建个体化的心血管系统模型，以进行持续评估和治疗方案影响分析。

Result: 实验表明，该系统预测准确且高效。

Conclusion: 结合深度学习和数字孪生技术，为预测心脏病提供了主动和个体化的方法。

Abstract: Cardiac arrest is one of the biggest global health problems, and early
identification and management are key to enhancing the patient's prognosis. In
this paper, we propose a novel framework that combines an EfficientNet-based
deep learning model with a digital twin system to improve the early detection
and analysis of cardiac arrest. We use compound scaling and EfficientNet to
learn the features of cardiovascular images. In parallel, the digital twin
creates a realistic and individualized cardiovascular system model of the
patient based on data received from the Internet of Things (IoT) devices
attached to the patient, which can help in the constant assessment of the
patient and the impact of possible treatment plans. As shown by our
experiments, the proposed system is highly accurate in its prediction abilities
and, at the same time, efficient. Combining highly advanced techniques such as
deep learning and digital twin (DT) technology presents the possibility of
using an active and individual approach to predicting cardiac disease.

</details>


### [393] [Hybrid GCN-GRU Model for Anomaly Detection in Cryptocurrency Transactions](https://arxiv.org/abs/2509.07392)
*Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Soyoun Kim,Sunyoung Moon,Sua Lee,Jaeyoung Choi,Hyemin Lee,Sangmi Chai*

Main category: cs.LG

TL;DR: 本研究提出了一种混合GCN-GRU模型来检测比特币交易网络中的非法活动，该模型在2020-2024年的比特币交易数据上取得了0.9470的准确率和0.9807的AUC-ROC，优于所有基线模型。


<details>
  <summary>Details</summary>
Motivation: 检测区块链交易网络中的非法活动。

Method: 提出并应用了一个结合图卷积网络（GCN）和门控循环单元（GRU）的混合模型，以捕捉交易网络的结构和顺序特征。

Result: 在2020-2024年的比特币交易数据上，该模型实现了0.9470的准确率和0.9807的AUC-ROC，表现优于所有对比方法。

Conclusion: 所提出的混合GCN-GRU模型能够有效地识别区块链交易网络中的非法活动，并且在准确性和AUC-ROC方面取得了显著的性能提升。

Abstract: Blockchain transaction networks are complex, with evolving temporal patterns
and inter-node relationships. To detect illicit activities, we propose a hybrid
GCN-GRU model that captures both structural and sequential features. Using real
Bitcoin transaction data (2020-2024), our model achieved 0.9470 Accuracy and
0.9807 AUC-ROC, outperforming all baselines.

</details>


### [394] [The Choice of Divergence: A Neglected Key to Mitigating Diversity Collapse in Reinforcement Learning with Verifiable Reward](https://arxiv.org/abs/2509.07430)
*Long Li,Jiaran Hao,Jason Klein Liu,Zhijian Zhou,Xiaoyu Tan,Wei Chu,Zhe Wang,Shirui Pan,Chao Qu,Yuan Qi*

Main category: cs.LG

TL;DR: RLVR微调LLM时，尽管Pass@1提高，但Pass@k常下降且出现灾难性遗忘。现有方法未充分研究散度项的作用。我们提出DPH-RL框架，使用f散度（如前向KL和JS散度）作为“复习”机制，通过持续参考初始策略来保持广泛的解空间覆盖。实验证明DPH-RL解决了Pass@k下降问题，并同时提高了Pass@1和Pass@k。该方法训练更高效，只需从初始策略采样，无需在线参考模型。


<details>
  <summary>Details</summary>
Motivation: RLVR微调LLM时，Pass@k性能下降和灾难性遗忘是常见问题，而标准RLVR目标（使用反向KL散度或无散度项）缺乏知识保留机制。反向KL散度通过缩小策略来加速衰退，而无散度项则无法阻止模型偏离其知识库。

Method: 提出DPH-RL框架，利用质量覆盖f散度（如前向KL和JS散度）作为“复习”机制。通过持续参考初始策略，迫使模型保持广泛的解空间覆盖。

Result: 在数学和SQL生成任务上进行的大量实验表明，DPH-RL不仅解决了Pass@k性能下降问题，而且在训练和非训练领域都提高了Pass@1和Pass@k性能。此外，DPH-RL通过生成函数计算f散度，仅需从初始策略采样且无需在线参考模型，从而提高了训练效率。

Conclusion: 选择合适的散度度量是提高RLVR的关键，f散度可作为一种有效的“复习”机制，以保持模型的泛化性和多样性，解决LLM微调中的关键挑战。

Abstract: A central paradox in fine-tuning Large Language Models (LLMs) with
Reinforcement Learning with Verifiable Reward (RLVR) is the frequent
degradation of multi-attempt performance (Pass@k) despite improvements in
single-attempt accuracy (Pass@1). This is often accompanied by catastrophic
forgetting, where models lose previously acquired skills. While various methods
have been proposed, the choice and function of the divergence term have been
surprisingly unexamined as a proactive solution. We argue that standard RLVR
objectives -- both those using the mode-seeking reverse KL-divergence and those
forgoing a divergence term entirely -- lack a crucial mechanism for knowledge
retention. The reverse-KL actively accelerates this decay by narrowing the
policy, while its absence provides no safeguard against the model drifting from
its diverse knowledge base. We propose a fundamental shift in perspective:
using the divergence term itself as the solution. Our framework,
Diversity-Preserving Hybrid RL (DPH-RL), leverages mass-covering f-divergences
(like forward-KL and JS-divergence) to function as a rehearsal mechanism. By
continuously referencing the initial policy, this approach forces the model to
maintain broad solution coverage. Extensive experiments on math and SQL
generation demonstrate that DPH-RL not only resolves the Pass@k degradation but
improves both Pass@1 and Pass@k in- and out-of-domain. Additionally, DPH-RL is
more training-efficient because it computes f-divergence using generator
functions, requiring only sampling from the initial policy and no online
reference model. Our work highlights a crucial, overlooked axis for improving
RLVR, demonstrating that the proper selection of a divergence measure is a
powerful tool for building more general and diverse reasoning models.

</details>


### [395] [Conv4Rec: A 1-by-1 Convolutional AutoEncoder for User Profiling through Joint Analysis of Implicit and Explicit Feedbacks](https://arxiv.org/abs/2509.07499)
*Antoine Ledent,Petr Kasalický,Rodrigo Alves,Hady W. Lauw*

Main category: cs.LG

TL;DR: 提出了一种新的卷积自动编码器（AutoEncoder）架构，用于用户建模和推荐任务。


<details>
  <summary>Details</summary>
Motivation: 该模型能够学习不同交互类型之间的关联和组合，并同时从显式评分和隐式反馈中学习，还能分别预测消费概率和高评分的可能性。

Method: 使用卷积自动编码器架构，并结合显式评分和隐式反馈信息进行联合学习。

Result: 在多个真实数据集上的实验表明，该模型在隐式和显式反馈预测任务上均达到了最先进的性能。

Conclusion: 该模型在推荐系统领域提供了一种新颖且有效的用户建模和推荐方法，并且在理论上提供了泛化界限。

Abstract: We introduce a new convolutional AutoEncoder architecture for user modelling
and recommendation tasks with several improvements over the state of the art.
Firstly, our model has the flexibility to learn a set of associations and
combinations between different interaction types in a way that carries over to
each user and item. Secondly, our model is able to learn jointly from both the
explicit ratings and the implicit information in the sampling pattern (which we
refer to as `implicit feedback'). It can also make separate predictions for the
probability of consuming content and the likelihood of granting it a high
rating if observed. This not only allows the model to make predictions for both
the implicit and explicit feedback, but also increases the informativeness of
the predictions: in particular, our model can identify items which users would
not have been likely to consume naturally, but would be likely to enjoy if
exposed to them. Finally, we provide several generalization bounds for our
model, which to the best of our knowledge, are among the first generalization
bounds for auto-encoders in a Recommender Systems setting; we also show that
optimizing our loss function guarantees the recovery of the exact sampling
distribution over interactions up to a small error in total variation. In
experiments on several real-life datasets, we achieve state-of-the-art
performance on both the implicit and explicit feedback prediction tasks despite
relying on a single model for both, and benefiting from additional
interpretability in the form of individual predictions for the probabilities of
each possible rating.

</details>


### [396] [Water Demand Forecasting of District Metered Areas through Learned Consumer Representations](https://arxiv.org/abs/2509.07515)
*Adithya Ramachandran,Thorkil Flensmark B. Neergaard,Tomás Arias-Vergara,Andreas Maier,Siming Bayer*

Main category: cs.LG

TL;DR: 本文提出一种结合无监督对比学习和卷积神经网络的短期用水量预测方法，应用于分区计量区域（DMA），考虑了用户行为的多样性，并在实际数据上取得了显著的预测性能提升。


<details>
  <summary>Details</summary>
Motivation: 气候变化背景下，水资源安全日益重要，准确预测短期用水量对水务管理至关重要，但受非决定性因素（如气象条件）影响，预测仍具挑战性。

Method: 首先，利用无监督对比学习对DMA内的终端用户进行消费行为分类；然后，将分类后的消费行为作为特征，结合历史数据和消费行为的表示，使用包含交叉注意力机制的小波变换卷积网络进行短期用水量预测。

Result: 在实际DMA上进行了为期六个月的评估，与现有方法相比，平均绝对百分比误差（MAPE）在不同DMA上均有所提高，最高提升达4.9%。此外，该方法还能识别受社会经济因素影响的用户行为。

Conclusion: 所提出的方法能够有效提高DMA的短期用水量预测精度，并为理解影响用水量的决定性因素提供新的见解，有助于水务管理和规划。

Abstract: Advancements in smart metering technologies have significantly improved the
ability to monitor and manage water utilities. In the context of increasing
uncertainty due to climate change, securing water resources and supply has
emerged as an urgent global issue with extensive socioeconomic ramifications.
Hourly consumption data from end-users have yielded substantial insights for
projecting demand across regions characterized by diverse consumption patterns.
Nevertheless, the prediction of water demand remains challenging due to
influencing non-deterministic factors, such as meteorological conditions. This
work introduces a novel method for short-term water demand forecasting for
District Metered Areas (DMAs) which encompass commercial, agricultural, and
residential consumers. Unsupervised contrastive learning is applied to
categorize end-users according to distinct consumption behaviors present within
a DMA. Subsequently, the distinct consumption behaviors are utilized as
features in the ensuing demand forecasting task using wavelet-transformed
convolutional networks that incorporate a cross-attention mechanism combining
both historical data and the derived representations. The proposed approach is
evaluated on real-world DMAs over a six-month period, demonstrating improved
forecasting performance in terms of MAPE across different DMAs, with a maximum
improvement of 4.9%. Additionally, it identifies consumers whose behavior is
shaped by socioeconomic factors, enhancing prior knowledge about the
deterministic patterns that influence demand.

</details>


### [397] [RoseCDL: Robust and Scalable Convolutional Dictionary Learning for Rare-event Detection](https://arxiv.org/abs/2509.07523)
*Jad Yehya,Mansour Benbakoura,Cédric Allain,Benoît Malezieux,Matthieu Kowalski,Thomas Moreau*

Main category: cs.LG

TL;DR: RoseCDL是一种用于无监督稀有事件检测的卷积字典学习算法，通过随机窗口和内联异常值检测提高了效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在天文学、物理模拟和生物医学等领域，识别大规模信号中的重复模式和稀有事件是一个基本挑战。卷积字典学习（CDL）提供了一种模拟信号局部结构的强大框架，但其在检测稀有或异常事件方面的应用仍未得到充分探索。

Method: RoseCDL结合了随机窗口和内联异常值检测，以实现对长信号的无监督稀有事件检测。

Result: RoseCDL是一种可扩展且鲁棒的CDL算法，能够有效地处理大型数据集，并能识别异常模式。

Conclusion: RoseCDL将CDL重新定义为一个实用的事件发现和表征工具，适用于真实世界的信号，并将其应用范围扩展到传统的压缩或去噪任务之外。

Abstract: Identifying recurring patterns and rare events in large-scale signals is a
fundamental challenge in fields such as astronomy, physical simulations, and
biomedical science. Convolutional Dictionary Learning (CDL) offers a powerful
framework for modeling local structures in signals, but its use for detecting
rare or anomalous events remains largely unexplored. In particular, CDL faces
two key challenges in this setting: high computational cost and sensitivity to
artifacts and outliers. In this paper, we introduce RoseCDL, a scalable and
robust CDL algorithm designed for unsupervised rare event detection in long
signals. RoseCDL combines stochastic windowing for efficient training on large
datasets with inline outlier detection to enhance robustness and isolate
anomalous patterns. This reframes CDL as a practical tool for event discovery
and characterization in real-world signals, extending its role beyond
traditional tasks like compression or denoising.

</details>


### [398] [$ΔL$ Normalization: Rethink Loss Aggregation in RLVR](https://arxiv.org/abs/2509.07558)
*Zhiyuan He,Xufang Luo,Yike Zhang,Yuqing Yang,Lili Qiu*

Main category: cs.LG

TL;DR: RLHF 中的可验证奖励（RLVR）因响应长度变化大而导致梯度方差高和优化不稳定。我们提出了一种名为“ΔL 归一化”的新型损失聚合方法，该方法可以提供真实的策略损失的无偏估计，并从理论上最小化梯度方差。


<details>
  <summary>Details</summary>
Motivation: RLHF 中的可验证奖励（RLVR）在提高大型语言模型的推理能力方面显示出巨大潜力，但其主要挑战在于训练过程中响应长度的变化很大，这会导致高梯度方差和不稳定的优化。现有的方法，如 GRPO、DAPO 和 Dr. GRPO，虽然引入了不同的损失归一化项，但要么产生有偏估计，要么仍然存在高梯度方差的问题。

Method: 通过理论和实践分析可变长度对策略损失的影响，将问题重新表述为寻找最小方差无偏估计量。提出 ΔL 归一化方法，该方法不仅提供真实策略损失的无偏估计，而且在理论上最小化梯度方差。

Result: 实验表明，ΔL 归一化在不同模型大小、最大长度和任务上始终取得优越的结果。

Conclusion: ΔL 归一化是一种简单而有效的方法，可以解决 RLVR 中动态生成长度带来的挑战，并在实践中取得了优于现有方法的性能。

Abstract: We propose $\Delta L$ Normalization, a simple yet effective loss aggregation
method tailored to the characteristic of dynamic generation lengths in
Reinforcement Learning with Verifiable Rewards (RLVR). Recently, RLVR has
demonstrated strong potential in improving the reasoning capabilities of large
language models (LLMs), but a major challenge lies in the large variability of
response lengths during training, which leads to high gradient variance and
unstable optimization. Although previous methods such as GRPO, DAPO, and Dr.
GRPO introduce different loss normalization terms to address this issue, they
either produce biased estimates or still suffer from high gradient variance. By
analyzing the effect of varying lengths on policy loss both theoretically and
empirically, we reformulate the problem as finding a minimum-variance unbiased
estimator. Our proposed $\Delta L$ Normalization not only provides an unbiased
estimate of the true policy loss but also minimizes gradient variance in
theory. Extensive experiments show that it consistently achieves superior
results across different model sizes, maximum lengths, and tasks. Our code will
be made public at https://github.com/zerolllin/Delta-L-Normalization.

</details>


### [399] [uGMM-NN: Univariate Gaussian Mixture Model Neural Network](https://arxiv.org/abs/2509.07569)
*Zakeria Sharif Ali*

Main category: cs.LG

TL;DR: uGMM-NN是一种新型的神经网络架构，它将概率推理嵌入到深度网络的计算单元中，能够捕捉单个神经元层面的多模态和不确定性，同时保持了标准前馈网络的扩展性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是开发一种能够将概率推理直接嵌入到深度网络计算单元中的新型神经网络架构，以捕捉多模态和不确定性，并为不确定性感知组件提供基础。

Method: 提出了一种名为uGMM-NN的新型神经网络架构，其中每个节点都将其激活参数化为具有可学习的均值、方差和混合系数的单变量高斯混合模型。

Result: 实验证明，uGMM-NN在区分性性能方面与传统的多层感知机相当，并且能够提供激活的概率解释。

Conclusion: uGMM-NN为将不确定性感知组件集成到现代神经网络架构中提供了一个基础，为区分性和生成性建模开辟了新的方向。

Abstract: This paper introduces the Univariate Gaussian Mixture Model Neural Network
(uGMM-NN), a novel neural architecture that embeds probabilistic reasoning
directly into the computational units of deep networks. Unlike traditional
neurons, which apply weighted sums followed by fixed nonlinearities, each
uGMM-NN node parameterizes its activations as a univariate Gaussian mixture,
with learnable means, variances, and mixing coefficients. This design enables
richer representations by capturing multimodality and uncertainty at the level
of individual neurons, while retaining the scalability of standard feedforward
networks. We demonstrate that uGMM-NN can achieve competitive discriminative
performance compared to conventional multilayer perceptrons, while additionally
offering a probabilistic interpretation of activations. The proposed framework
provides a foundation for integrating uncertainty-aware components into modern
neural architectures, opening new directions for both discriminative and
generative modeling.

</details>


### [400] [Homogenization with Guaranteed Bounds via Primal-Dual Physically Informed Neural Networks](https://arxiv.org/abs/2509.07579)
*Liya Gaynutdinova,Martin Doškář,Ondřej Rokoš,Ivana Pultarová*

Main category: cs.LG

TL;DR: PINNs在处理材料不连续性方面存在挑战，本文提出的对偶形式化框架通过提供误差界限，增强了PINN在微力学均质化问题中的可靠性和诊断能力，尤其适用于双变分（弱）公式。


<details>
  <summary>Details</summary>
Motivation: 标准PINNs在处理具有不连续系数的材料（如分段常数材料属性）时，在求解多尺度模型相关的偏微分方程（PDE）方面常常会失败。因此，需要改进PINN框架以提高其在处理此类问题时的可靠性。

Method: 提出了一种用于PINN框架的对偶形式化方法，用于提高周期性热传导复合材料均质化的可靠性，并同时考虑强形式和变分（弱）形式。该方法能够推导出保证的上下误差界限，从而更可靠地检测PINN的失败。

Result: 与仅应用于平滑材料近似的标准PINNs相比，本文提出的对偶形式化框架能够更可靠地处理材料不连续性。尽管在受控环境下，强形式PINNs可能优于变分PINNs（VPINNs），但它们对材料不连续性敏感且可能在无明确诊断的情况下失败。相比之下，VPINNs可以直接处理分段常数材料参数，但需要仔细选择测试函数以避免不稳定性。对偶形式化可以作为收敛质量的可靠指标。

Conclusion: 对偶形式化作为PINN框架的可靠指标，增强了其在微力学均质化问题中的适用性。

Abstract: Physics-informed neural networks (PINNs) have shown promise in solving
partial differential equations (PDEs) relevant to multiscale modeling, but they
often fail when applied to materials with discontinuous coefficients, such as
media with piecewise constant properties. This paper introduces a dual
formulation for the PINN framework to improve the reliability of the
homogenization of periodic thermo-conductive composites, for both strong and
variational (weak) formulations. The dual approach facilitates the derivation
of guaranteed upper and lower error bounds, enabling more robust detection of
PINN failure. We compare standard PINNs applied to smoothed material
approximations with variational PINNs (VPINNs) using both spectral and neural
network-based test functions. Our results indicate that while strong-form PINNs
may outperform VPINNs in controlled settings, they are sensitive to material
discontinuities and may fail without clear diagnostics. In contrast, VPINNs
accommodate piecewise constant material parameters directly but require careful
selection of test functions to avoid instability. Dual formulation serves as a
reliable indicator of convergence quality, and its integration into PINN
frameworks enhances their applicability to homogenization problems in
micromechanics.

</details>


### [401] [Transformer-Based Approach to Optimal Sensor Placement for Structural Health Monitoring of Probe Cards](https://arxiv.org/abs/2509.07603)
*Mehdi Bejani,Marco Mauri,Daniele Acconcia,Simone Todaro,Stefano Mariani*

Main category: cs.LG

TL;DR: 本文提出了一种基于Transformer的深度学习策略，用于优化传感器在半导体测试探针台结构健康监测中的布局。


<details>
  <summary>Details</summary>
Motivation: 半导体测试探针台的失效（如基板裂纹、螺丝松动）会严重影响半导体制造的良率和可靠性。通过配置合适的传感器，可以检测到部分失效模式。

Method: 利用有限元模型仿真探针台在不同失效场景下的频率响应函数，并结合物理信息场景扩展和物理感知统计数据增强，构建了一个全面的数据集，用于训练混合卷积神经网络和Transformer模型。

Result: 该模型在区分探针台健康状态（基线、螺丝松动、裂纹）方面达到了99.83%的高准确率，在裂纹检测方面实现了99.73%的优秀召回率。通过3次10折分层交叉验证验证了模型的鲁棒性。注意力机制还精确定位了关键传感器位置，为设计高效、经济的监测系统提供了可操作的见解。

Conclusion: 该研究强调了基于注意力机制的深度学习在推进预防性维护、提高半导体制造运营可靠性和良率方面的潜力。

Abstract: This paper presents an innovative Transformer-based deep learning strategy
for optimizing the placement of sensors aiming at structural health monitoring
of semiconductor probe cards. Failures in probe cards, including substrate
cracks and loosened screws, would critically affect semiconductor manufacturing
yield and reliability. Some failure modes could be detected by equipping a
probe card with adequate sensors. Frequency response functions from simulated
failure scenarios are adopted within a finite element model of a probe card. A
comprehensive dataset, enriched by physics-informed scenario expansion and
physics-aware statistical data augmentation, is exploited to train a hybrid
Convolutional Neural Network and Transformer model. The model achieves high
accuracy (99.83%) in classifying the probe card health states (baseline, loose
screw, crack) and an excellent crack detection recall (99.73%). Model
robustness is confirmed through a rigorous framework of 3 repetitions of
10-fold stratified cross-validation. The attention mechanism also pinpoints
critical sensor locations: an analysis of the attention weights offers
actionable insights for designing efficient, cost-effective monitoring systems
by optimizing sensor configurations. This research highlights the capability of
attention-based deep learning to advance proactive maintenance, enhancing
operational reliability and yield in semiconductor manufacturing.

</details>


### [402] [K2-Think: A Parameter-Efficient Reasoning System](https://arxiv.org/abs/2509.07604)
*Zhoujun Cheng,Richard Fan,Shibo Hao,Taylor W. Killian,Haonan Li,Suqi Sun,Hector Ren,Alexander Moreno,Daqian Zhang,Tianjun Zhong,Yuxin Xiong,Yuanzhe Hu,Yutao Xie,Xudong Han,Yuqi Wang,Varad Pimpalkhute,Yonghao Zhuang,Aaryamonvikram Singh,Xuezhi Liang,Anze Xie,Jianshu She,Desai Fan,Chengqian Gao,Liqun Ma,Mikhail Yurochkin,John Maggs,Xuezhe Ma,Guowei He,Zhiting Hu,Zhengzhong Liu,Eric P. Xing*

Main category: cs.LG

TL;DR: K2-Think是一个320亿参数的推理系统，在数学推理方面表现出色，达到了最先进的水平，其表现可与更大的模型相媲美。该系统结合了先进的训练后技术和推理时计算技术，包括长链思维监督微调、可验证奖励强化学习、智能体规划、推理时扩展、推测解码和推理优化硬件，并且所有这些都使用了公开可用的开源数据集。K2-Think在数学推理方面取得了最先进的成绩，在代码和科学方面也表现出色。


<details>
  <summary>Details</summary>
Motivation: K2-Think旨在展示小型模型（如32B参数模型）如何通过结合先进的训练后技术和推理时计算技术，在推理能力上达到甚至超越更大的模型，从而使开源推理系统更易于访问和负担得起。

Method: K2-Think的构建基于六个关键技术支柱：长链思维监督微调、可验证奖励强化学习（RLVR）、推理前的智能体规划、推理时扩展、推测解码和推理优化硬件。这些技术都利用了公开可用的开源数据集。

Result: K2-Think在数学推理方面取得了最先进的成绩，在公开基准测试中得分最高。此外，该系统在代码和科学领域也表现强劲。K2-Think 32B的推理速度超过每秒2000个令牌/请求。

Conclusion: K2-Think 32B通过集成的训练后方法（包括长链思维训练和战略推理时增强）以及推理时优化，可以与最先进的系统竞争，证明了参数效率更高的模型可以取得优异的性能。这使得开源推理系统更加易于访问和负担得起。

Abstract: K2-Think is a reasoning system that achieves state-of-the-art performance
with a 32B parameter model, matching or surpassing much larger models like
GPT-OSS 120B and DeepSeek v3.1. Built on the Qwen2.5 base model, our system
shows that smaller models can compete at the highest levels by combining
advanced post-training and test-time computation techniques. The approach is
based on six key technical pillars: Long Chain-of-thought Supervised
Finetuning, Reinforcement Learning with Verifiable Rewards (RLVR), Agentic
planning prior to reasoning, Test-time Scaling, Speculative Decoding, and
Inference-optimized Hardware, all using publicly available open-source
datasets. K2-Think excels in mathematical reasoning, achieving state-of-the-art
scores on public benchmarks for open-source models, while also performing
strongly in other areas such as Code and Science. Our results confirm that a
more parameter-efficient model like K2-Think 32B can compete with
state-of-the-art systems through an integrated post-training recipe that
includes long chain-of-thought training and strategic inference-time
enhancements, making open-source reasoning systems more accessible and
affordable. K2-Think is freely available at k2think.ai, offering best-in-class
inference speeds of over 2,000 tokens per second per request via the Cerebras
Wafer-Scale Engine.

</details>


### [403] [Beyond Rebalancing: Benchmarking Binary Classifiers Under Class Imbalance Without Rebalancing Techniques](https://arxiv.org/abs/2509.07605)
*Ali Nawaz,Amir Ahmad,Shehroz S. Khan*

Main category: cs.LG

TL;DR: 在不进行显式类别再平衡的情况下，评估二元分类器在类别不平衡情况下的性能，并为不平衡学习提供模型选择指导。


<details>
  <summary>Details</summary>
Motivation: 在类别不平衡的背景下，特别是医学诊断和异常检测等关键领域，对二元分类器在不进行任何显式再平衡技术时性能的评估研究不足，本研究旨在填补这一空白。

Method: 系统地评估了各种二元分类器在真实世界和合成数据集上的鲁棒性，并通过生成合成决策边界来模拟不同数据复杂度。此外，还包含了对欠采样、过采样和单类分类（OCC）方法的实验，以检查它们在严重不平衡情况下的行为。

Result: 分类难度随数据复杂度的增加和少数类大小的减小而增加。虽然传统分类器在极端不平衡情况下性能下降，但像TabPFN和基于提升的集成模型等先进模型相比传统分类器仍能保持相对较高的性能和泛化能力。可视化可解释性和评估指标进一步验证了这些发现。

Conclusion: 在类别不平衡学习中，先进模型（如TabPFN和集成模型）在没有显式再平衡技术的情况下，相比传统模型表现出更强的鲁棒性。本研究为在不依赖显式再平衡技术的情况下选择模型提供了有价值的指导。

Abstract: Class imbalance poses a significant challenge to supervised classification,
particularly in critical domains like medical diagnostics and anomaly detection
where minority class instances are rare. While numerous studies have explored
rebalancing techniques to address this issue, less attention has been given to
evaluating the performance of binary classifiers under imbalance when no such
techniques are applied. Therefore, the goal of this study is to assess the
performance of binary classifiers "as-is", without performing any explicit
rebalancing. Specifically, we systematically evaluate the robustness of a
diverse set of binary classifiers across both real-world and synthetic
datasets, under progressively reduced minority class sizes, using one-shot and
few-shot scenarios as baselines. Our approach also explores varying data
complexities through synthetic decision boundary generation to simulate
real-world conditions. In addition to standard classifiers, we include
experiments using undersampling, oversampling strategies, and one-class
classification (OCC) methods to examine their behavior under severe imbalance.
The results confirm that classification becomes more difficult as data
complexity increases and the minority class size decreases. While traditional
classifiers deteriorate under extreme imbalance, advanced models like TabPFN
and boosting-based ensembles retain relatively higher performance and better
generalization compared to traditional classifiers. Visual interpretability and
evaluation metrics further validate these findings. Our work offers valuable
guidance on model selection for imbalanced learning, providing insights into
classifier robustness without dependence on explicit rebalancing techniques.

</details>


### [404] [Graph-based Integrated Gradients for Explaining Graph Neural Networks](https://arxiv.org/abs/2509.07648)
*Lachlan Simpson,Kyle Millar,Adriel Cheng,Cheng-Chew Lim,Hong Gunn Chew*

Main category: cs.LG

TL;DR: 本篇论文提出图基元积分梯度（GB-IG）方法，解决了现有积分梯度（IG）方法不适用于图数据的问题，并在实验中证明了GB-IG在识别图结构和节点分类任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的积分梯度（IG）方法不能直接应用于图数据，因为图数据是离散结构，而IG方法假设数据是连续的。

Method: 提出图基元积分梯度（GB-IG）方法，作为IG方法在图数据上的扩展。

Result: 在四个合成数据集上，GB-IG能够准确识别图中用于分类任务的关键结构组件。在三个实际的图数据集上，GB-IG在突出节点分类任务中的重要特征方面优于IG方法。

Conclusion: GB-IG是IG方法在图数据上的有效扩展，能够识别关键图结构并优于IG方法在节点分类任务中的性能。

Abstract: Integrated Gradients (IG) is a common explainability technique to address the
black-box problem of neural networks. Integrated gradients assumes continuous
data. Graphs are discrete structures making IG ill-suited to graphs. In this
work, we introduce graph-based integrated gradients (GB-IG); an extension of IG
to graphs. We demonstrate on four synthetic datasets that GB-IG accurately
identifies crucial structural components of the graph used in classification
tasks. We further demonstrate on three prevalent real-world graph datasets that
GB-IG outperforms IG in highlighting important features for node classification
tasks.

</details>


### [405] [FUnc-SNE: A flexible, Fast, and Unconstrained algorithm for neighbour embeddings](https://arxiv.org/abs/2509.07681)
*Pierre Lambert,Edouard Couplet,Michel Verleysen,John Aldo Lee*

Main category: cs.LG

TL;DR: 本文提出了一种新颖的加速节点嵌入（NE）的方法，在保持良好结构和灵活性的同时，提高了计算速度，并且不限制嵌入空间的维度。


<details>
  <summary>Details</summary>
Motivation: 现有的加速 NE 方法要么牺牲质量（如 UMAP 的负采样），要么速度慢且维度受限（如 FIt-SNE、BH-t-SNE），限制了 NE 的应用。本文旨在弥合这一差距，提供一种既快又能在高维空间中保持结构细节的方法。

Method: 本文提出了一种新的加速 NE 的方法，该方法每次迭代计算量小，能够保持良好的细粒度结构，并通过超参数调整提供灵活性，同时不限制嵌入空间的维度。该方法摒弃了传统 NE 的两阶段方法，实现了交互式数据探索，可以即时获得超参数调整的视觉反馈。算法的核心是一种新颖的迭代近似最近邻搜索方法。

Result: 通过使用公开可用、GPU 加速的 GUI 集成进行实验，证明了该方法在速度、提取结构方面的灵活性以及在更广泛的机器学习领域应用的潜力。

Conclusion: 本文提出的加速 NE 方法在速度、结构保持和维度灵活性方面取得了有希望的结果，并且通过其新颖的近似最近邻搜索方法，优于现有的方法。

Abstract: Neighbour embeddings (NE) allow the representation of high dimensional
datasets into lower dimensional spaces and are often used in data
visualisation. In practice, accelerated approximations are employed to handle
very large datasets. Accelerating NE is challenging, and two main directions
have been explored: very coarse approximations based on negative sampling (as
in UMAP) achieve high effective speed but may lack quality in the extracted
structures; less coarse approximations, as used in FIt-SNE or BH-t-SNE, offer
better structure preservation at the cost of speed, while also restricting the
target dimensionality to 2 or 3, limiting NE to visualisation. In some
variants, the precision of these costlier accelerations also enables
finer-grained control on the extracted structures through dedicated
hyperparameters.
  This paper proposes to bridge the gab between both approaches by introducing
a novel way to accelerate NE, requiring a small number of computations per
iteration while maintaining good fine-grained structure preservation and
flexibility through hyperparameter tuning, without limiting the dimensionality
of the embedding space. The method was designed for interactive exploration of
data; as such, it abandons the traditional two-phased approach of other NE
methods, allowing instantaneous visual feedback when changing hyperparameters,
even when these control processes happening on the high-dimensional side of the
computations. Experiments using a publicly available, GPU accelerated GUI
integration of the method show promising results in terms of speed, flexibility
in the structures getting extracted, and show potential uses in broader machine
learning contexts with minimal algorithmic modifications. Central to this
algorithm is a novel approach to iterative approximate nearest neighbour
search, which shows promising results compared to nearest neighbour descent.

</details>


### [406] [IBN: An Interpretable Bidirectional-Modeling Network for Multivariate Time Series Forecasting with Variable Missing](https://arxiv.org/abs/2509.07725)
*Shusen Ma,Tianhao Zhang,Qijiu Xia,Yun-Bo Zhao*

Main category: cs.LG

TL;DR: IBN网络通过不确定性感知插值和高斯核图卷积来解决多变量时间序列预测中的变量缺失问题，提高了性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的多变量时间序列预测方法在处理变量缺失时存在模型可解释性差、无法捕捉潜在时间模式等问题。GinAR虽然解决了变量缺失问题，但其简单的递归单元（RUs）限制了模型的性能。

Method: 提出了一种名为IBN（Interpretable Bidirectional-modeling Network）的网络，该网络集成了不确定性感知插值（UAI）和基于高斯核的图卷积（GGCN）。UAI利用蒙特卡洛Dropout来估计重建值的_不确定性_，并采用_不确定性加权_策略来规避高风险重建。GGCN显式地建模变量间的空间相关性，同时采用_双向_RU来增强_时间依赖性_建模。

Result: IBN在各种缺失率场景下均达到了最_先进_的预测性能，为_缺失变量_的多变量时间序列预测提供了一个更_可靠_和_可解释_的框架。

Conclusion: IBN网络通过引入不确定性感知插值和高斯核图卷积，有效解决了多变量时间序列预测中的变量缺失问题，并在性能和可解释性方面取得了显著的_进步_。

Abstract: Multivariate time series forecasting (MTSF) often faces challenges from
missing variables, which hinder conventional spatial-temporal graph neural
networks in modeling inter-variable correlations. While GinAR addresses
variable missing using attention-based imputation and adaptive graph learning
for the first time, it lacks interpretability and fails to capture more latent
temporal patterns due to its simple recursive units (RUs). To overcome these
limitations, we propose the Interpretable Bidirectional-modeling Network (IBN),
integrating Uncertainty-Aware Interpolation (UAI) and Gaussian kernel-based
Graph Convolution (GGCN). IBN estimates the uncertainty of reconstructed values
using MC Dropout and applies an uncertainty-weighted strategy to mitigate
high-risk reconstructions. GGCN explicitly models spatial correlations among
variables, while a bidirectional RU enhances temporal dependency modeling.
Extensive experiments show that IBN achieves state-of-the-art forecasting
performance under various missing-rate scenarios, providing a more reliable and
interpretable framework for MTSF with missing variables. Code is available at:
https://github.com/zhangth1211/NICLab-IBN.

</details>


### [407] [Uncovering Scaling Laws for Large Language Models via Inverse Problems](https://arxiv.org/abs/2509.07909)
*Arun Verma,Zhaoxuan Wu,Zijian Zhou,Xiaoqiang Lin,Zhiliang Chen,Rachael Hwee Ling Sim,Rui Qiao,Jingtan Wang,Nhung Bui,Xinyuan Niu,Wenyang Hu,Gregory Kang Ruey Lau,Zi-Yu Khoo,Zitong Zhao,Xinyi Xu,Apivich Hemachandra,See-Kiong Ng,Bryan Kian Hsiang Low*

Main category: cs.LG

TL;DR: LLMs 的大规模预训练模型在各个领域取得了显著成功，这得益于其前所未有的复杂性和规模。然而，由于训练成本高昂，通过试错法来改进 LLM 并不可行。受逆问题在揭示科学规律方面成功的启发，本文提出逆问题也可以有效地揭示 LLM 的扩展定律，以更具成本效益的方式指导 LLM 的构建，从而获得理想的性能。


<details>
  <summary>Details</summary>
Motivation: 由于训练 LLM 的成本高昂，无法通过试错法进行优化。

Method: 提出使用逆问题来发现指导 LLM 构建的扩展定律，以提高成本效益。

Result: 逆问题可以有效揭示 LLM 的扩展定律。

Conclusion: 逆问题为 LLM 的高效构建提供了新的方向。

Abstract: Large Language Models (LLMs) are large-scale pretrained models that have
achieved remarkable success across diverse domains. These successes have been
driven by unprecedented complexity and scale in both data and computations.
However, due to the high costs of training such models, brute-force
trial-and-error approaches to improve LLMs are not feasible. Inspired by the
success of inverse problems in uncovering fundamental scientific laws, this
position paper advocates that inverse problems can also efficiently uncover
scaling laws that guide the building of LLMs to achieve the desirable
performance with significantly better cost-effectiveness.

</details>


### [408] [Forecasting Russian Equipment Losses Using Time Series and Deep Learning Models](https://arxiv.org/abs/2509.07813)
*Jonathan Teagan*

Main category: cs.LG

TL;DR: 该研究使用 ARIMA、Prophet、LSTM、TCN 和 XGBoost 等多种预测技术，对乌克兰战争中俄罗斯装备损失进行建模和预测，重点关注 TCN 和 LSTM 模型在处理高时间粒度数据时的稳定性和一致性，并强调了集合预测和 OSINT 数据在冲突建模中的价值。


<details>
  <summary>Details</summary>
Motivation: 对乌克兰战争中俄罗斯装备损失的趋势进行评估，并预测未来的损失模式。

Method: 应用 ARIMA、Prophet、LSTM、TCN 和 XGBoost 等多种预测技术，利用每日和每月开源情报（OSINT）数据进行建模和预测。

Result: 深度学习模型（特别是 TCN 和 LSTM）在处理高时间粒度数据时，能够产生稳定且一致的预测。研究还强调了集合预测在冲突建模中的重要性。

Conclusion: 公共可用的 OSINT 数据对于量化材料随时间退化的价值，以及深度学习模型在预测冲突相关损失方面的有效性。

Abstract: This study applies a range of forecasting techniques,including ARIMA,
Prophet, Long Short Term Memory networks (LSTM), Temporal Convolutional
Networks (TCN), and XGBoost, to model and predict Russian equipment losses
during the ongoing war in Ukraine. Drawing on daily and monthly open-source
intelligence (OSINT) data from WarSpotting, we aim to assess trends in
attrition, evaluate model performance, and estimate future loss patterns
through the end of 2025. Our findings show that deep learning models,
particularly TCN and LSTM, produce stable and consistent forecasts, especially
under conditions of high temporal granularity. By comparing different model
architectures and input structures, this study highlights the importance of
ensemble forecasting in conflict modeling, and the value of publicly available
OSINT data in quantifying material degradation over time.

</details>


### [409] [Predicting person-level injury severity using crash narratives: A balanced approach with roadway classification and natural language process techniques](https://arxiv.org/abs/2509.07845)
*Mohammad Zana Majidi,Sajjad Karimi,Teng Wang,Robert Kluger,Reginald Souleyrette*

Main category: cs.LG

TL;DR: 结合非结构化碰撞叙述和结构化碰撞数据可以更准确地预测碰撞造成的伤害程度，其中TF-IDF与XGBoost的组合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为了提高道路安全、改善应急响应和指导公共卫生干预，本研究旨在探索在结构化碰撞数据的基础上，结合非结构化的碰撞叙述（警察在现场书写的记录）对于预测碰撞伤害严重程度的附加价值。

Method: 本研究采用了两种广泛使用的自然语言处理（NLP）技术：词频-逆文档频率（TF-IDF）和Word2Vec，来提取碰撞叙述中的语义信息，并对它们的效果进行了比较。为了解决类别不平衡的问题，在建模前对训练数据应用了基于K近邻的过采样方法。研究使用了2019年至2023年肯塔基州的碰撞记录数据集，并考虑了道路异质性，采用了三种道路分类方案：八种详细的功能类别、四种广泛的成对类别以及一个不加分类的统一数据集。通过结合结构化特征和基于叙述的特征，并使用TF-IDF和Word2Vec两种NLP技术，以及XGBoost、Random Forest和AdaBoost三种集成算法，共开发了102个机器学习模型。

Result: 结果表明，包含叙述数据的模型在预测准确性上持续优于仅依赖结构化数据的模型。在所有组合中，TF-IDF与XGBoost的组合在大多数子组中产生了最准确的预测。

Conclusion: 研究结果强调了整合文本和结构化碰撞信息在提高个人伤害预测方面的潜力。这项工作为交通安全专业人员提供了一个实用且可适应的框架，以改进碰撞严重性建模、指导政策制定和设计更有效的应对措施。

Abstract: Predicting injuries and fatalities in traffic crashes plays a critical role
in enhancing road safety, improving emergency response, and guiding public
health interventions. This study investigates the added value of unstructured
crash narratives (written by police officers at the scene) when combined with
structured crash data to predict injury severity. Two widely used Natural
Language Processing (NLP) techniques, Term Frequency-Inverse Document Frequency
(TF-IDF) and Word2Vec, were employed to extract semantic meaning from the
narratives, and their effectiveness was compared. To address the challenge of
class imbalance, a K-Nearest Neighbors-based oversampling method was applied to
the training data prior to modeling. The dataset consists of crash records from
Kentucky spanning 2019 to 2023. To account for roadway heterogeneity, three
road classification schemes were used: (1) eight detailed functional classes
(e.g., Urban Two-Lane, Rural Interstate, Urban Multilane Divided), (2) four
broader paired categories (e.g., Urban vs. Rural, Freeway vs. Non-Freeway), and
(3) a unified dataset without classification. A total of 102 machine learning
models were developed by combining structured features and narrative-based
features using the two NLP techniques alongside three ensemble algorithms:
XGBoost, Random Forest, and AdaBoost. Results demonstrate that models
incorporating narrative data consistently outperform those relying solely on
structured data. Among all combinations, TF-IDF coupled with XGBoost yielded
the most accurate predictions in most subgroups. The findings highlight the
power of integrating textual and structured crash information to enhance
person-level injury prediction. This work offers a practical and adaptable
framework for transportation safety professionals to improve crash severity
modeling, guide policy decisions, and design more effective countermeasures.

</details>


### [410] [Addressing the Cold-Start Problem for Personalized Combination Drug Screening](https://arxiv.org/abs/2509.07850)
*Antoine de Mathelin,Christopher Tosh,Wesley Tansey*

Main category: cs.LG

TL;DR: 该研究提出了一种利用预训练深度学习模型来个性化肿瘤学组合疗法的新策略，以解决药物和剂量组合选择的冷启动问题。


<details>
  <summary>Details</summary>
Motivation: 肿瘤学中个性化组合疗法的挑战在于，通过穷举实验来导航巨大的药物和剂量组合空间是不可行的。尽管患者来源模型能够进行高通量筛选，但可行实验数量有限。此外，狭窄的治疗窗口使得收集分子谱信息（如RNA-seq）来指导药物反应预测不切实际。因此，在没有患者先验信息的情况下，如何选择信息量最大的组合进行早期测试是一个严峻的冷启动问题。

Method: 本研究提出一种利用预训练深度学习模型来解决冷启动问题的策略。该模型基于历史药物反应数据构建，能够提供药物组合的嵌入和剂量重要性得分，从而能够对初始实验进行原则性选择。通过将药物嵌入进行聚类以确保功能多样性，并结合剂量加权机制来优先选择具有历史信息量的剂量，来实现实验效率的提升。

Result: 回顾性模拟表明，该方法在大型药物组合数据集上显著提高了初始筛选效率，与现有基线方法相比具有明显优势。

Conclusion: 该研究提出的策略为个性化组合药物筛选中的早期决策提供了一条可行的途径，能够更有效地选择信息量最大的药物和剂量组合进行测试。

Abstract: Personalizing combination therapies in oncology requires navigating an
immense space of possible drug and dose combinations, a task that remains
largely infeasible through exhaustive experimentation. Recent developments in
patient-derived models have enabled high-throughput ex vivo screening, but the
number of feasible experiments is limited. Further, a tight therapeutic window
makes gathering molecular profiling information (e.g. RNA-seq) impractical as a
means of guiding drug response prediction. This leads to a challenging
cold-start problem: how do we select the most informative combinations to test
early, when no prior information about the patient is available? We propose a
strategy that leverages a pretrained deep learning model built on historical
drug response data. The model provides both embeddings for drug combinations
and dose-level importance scores, enabling a principled selection of initial
experiments. We combine clustering of drug embeddings to ensure functional
diversity with a dose-weighting mechanism that prioritizes doses based on their
historical informativeness. Retrospective simulations on large-scale drug
combination datasets show that our method substantially improves initial
screening efficiency compared to baselines, offering a viable path for more
effective early-phase decision-making in personalized combination drug screens.

</details>


### [411] [Leveraging Support Vector Regression for Outcome Prediction in Personalized Ultra-fractionated Stereotactic Adaptive Radiotherapy](https://arxiv.org/abs/2509.07872)
*Yajun Yu,Steve Jiang,Robert Timmerman,Hao Peng*

Main category: cs.LG

TL;DR: 该研究开发了一种基于多组学数据的支持向量回归（SVR）模型，用于预测脑转移瘤的个体化超分次立体定向适形放疗（PULSAR）中的 gross tumor volume (GTV) 变化。


<details>
  <summary>Details</summary>
Motivation: 准确预测 GTV 变化对于 PULSAR 治疗具有重要的预后价值，本研究旨在开发一种基于多组学数据（放射组学和剂量组学）的 SVR 模型来实现这一预测。

Method: 研究人员分析了 39 名患者的 69 个脑转移瘤数据，提取了放射组学（MRI 图像）和剂量组学（剂量图）特征。通过计算时间点之间的相对变化（delta features），并使用 Lasso 算法进行特征选择。最终使用具有不同核函数的 SVR 模型进行评估，并采用五折交叉验证和 10 次重复来提高模型的鲁棒性。

Result: 整合了放射组学、剂量组学及其 delta 特征的多组学模型优于单独的组学模型，其中 delta 放射组学特征在提高预测准确性方面起着关键作用。性能最佳的模型达到了 0.743 的 R2 和 0.022 的 RRMSE。

Conclusion: 所提出的多组学 SVR 模型在预测 GTV 连续变化方面表现出有前景的性能，为 PULSAR 治疗的患者选择和治疗调整提供了更定量和个性化的方法。

Abstract: Personalized ultra-fractionated stereotactic adaptive radiotherapy (PULSAR)
is a novel treatment that delivers radiation in pulses of protracted intervals.
Accurate prediction of gross tumor volume (GTV) changes through regression
models has substantial prognostic value. This study aims to develop a
multi-omics based support vector regression (SVR) model for predicting GTV
change. A retrospective cohort of 39 patients with 69 brain metastases was
analyzed, based on radiomics (MRI images) and dosiomics (dose maps) features.
Delta features were computed to capture relative changes between two time
points. A feature selection pipeline using least absolute shrinkage and
selection operator (Lasso) algorithm with weight- or frequency-based ranking
criterion was implemented. SVR models with various kernels were evaluated using
the coefficient of determination (R2) and relative root mean square error
(RRMSE). Five-fold cross-validation with 10 repeats was employed to mitigate
the limitation of small data size. Multi-omics models that integrate radiomics,
dosiomics, and their delta counterparts outperform individual-omics models.
Delta-radiomic features play a critical role in enhancing prediction accuracy
relative to features at single time points. The top-performing model achieves
an R2 of 0.743 and an RRMSE of 0.022. The proposed multi-omics SVR model shows
promising performance in predicting continuous change of GTV. It provides a
more quantitative and personalized approach to assist patient selection and
treatment adjustment in PULSAR.

</details>


### [412] [A Survey of Graph Neural Networks for Drug Discovery: Recent Developments and Challenges](https://arxiv.org/abs/2509.07887)
*Katherine Berry,Liang Cheng*

Main category: cs.LG

TL;DR: GNNs在药物发现中得到广泛应用，该论文全面概述了GNN在分子性质预测、药物-靶点结合亲和力预测、药物-药物相互作用研究、微生物组相互作用预测、药物重定位、逆合成和新药设计等方面的研究进展，并为未来工作提供了指导。


<details>
  <summary>Details</summary>
Motivation: GNNs因能处理图结构数据（如药物分子模型）而在药物发现领域受到关注，已涌现出大量相关方法和模型。

Method: 对GNN在药物发现研究的各个方面进行了全面的文献综述。

Result: 论文涵盖了GNN在分子性质预测、药物-靶点结合亲和力预测、药物-药物相互作用研究、微生物组相互作用预测、药物重定位、逆合成和新药设计等方面的最新研究进展。

Conclusion: GNNs在药物发现领域展现出巨大潜力，未来应继续探索其在各个细分领域的应用和优化。

Abstract: Graph Neural Networks (GNNs) have gained traction in the complex domain of
drug discovery because of their ability to process graph-structured data such
as drug molecule models. This approach has resulted in a myriad of methods and
models in published literature across several categories of drug discovery
research. This paper covers the research categories comprehensively with recent
papers, namely molecular property prediction, including drug-target binding
affinity prediction, drug-drug interaction study, microbiome interaction
prediction, drug repositioning, retrosynthesis, and new drug design, and
provides guidance for future work on GNNs for drug discovery.

</details>


### [413] [Feasibility of In-Ear Single-Channel ExG for Wearable Sleep~Monitoring in Real-World Settings](https://arxiv.org/abs/2509.07896)
*Philipp Lepold,Jonas Leichtle,Tobias Röddiger,Michael Beigl*

Main category: cs.LG

TL;DR: 单通道耳内生物电信号可用于自动睡眠分期，准确度高，适合可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 现有的自动睡眠分期依赖于有侵入性的脑电图（EEG）设备，不适用于家庭等真实环境的长期监测。耳内EEG信号已被证明与头皮EEG信号相关，因此研究使用耳内ExG信号进行睡眠分期的可行性具有重要意义，特别是对于睡眠开始检测，可以支持如自动暂停媒体播放等消费级应用。

Method: 使用定制的耳戴式设备，在一只耳朵中使用干燥电极作为测量电极，另一只耳朵作为参考电极，收集11名参与者的单通道耳内电生理（ExG）信号。同时使用Apple Watch Ultra的睡眠分期作为地面真实参考。

Result: 该系统在进行二分类（清醒/睡眠）的睡眠检测时，准确率达到了90.5%；在进行四分类（清醒、REM、核心、深睡）的睡眠分期时，准确率为65.1%。采用留一法交叉验证。

Conclusion: 耳内电极作为一种低成本、舒适的睡眠监测方法具有巨大潜力，可用于开发自动睡眠分期等应用，例如在用户入睡时自动停止播放播客。

Abstract: Automatic sleep staging typically relies on gold-standard EEG setups, which
are accurate but obtrusive and impractical for everyday use outside sleep
laboratories. This limits applicability in real-world settings, such as home
environments, where continuous, long-term monitoring is needed. Detecting sleep
onset is particularly relevant, enabling consumer applications (e.g.
automatically pausing media playback when the user falls asleep). Recent
research has shown correlations between in-ear EEG and full-scalp EEG for
various phenomena, suggesting wearable, in-ear devices could allow unobtrusive
sleep monitoring. We investigated the feasibility of using single-channel
in-ear electrophysiological (ExG) signals for automatic sleep staging in a
wearable device by conducting a sleep study with 11~participants (mean age:
24), using a custom earpiece with a dry eartip electrode (D\"atwyler SoftPulse)
as a measurement electrode in one ear and a reference in the other. Ground
truth sleep stages were obtained from an Apple Watch Ultra, validated for sleep
staging. Our system achieved 90.5% accuracy for binary sleep detection (Awake
vs. Asleep) and 65.1% accuracy for four-class staging (Awake, REM, Core, Deep)
using leave-one-subject-out validation. These findings demonstrate the
potential of in-ear electrodes as a low-effort, comfortable approach to sleep
monitoring, with applications such as stopping podcasts when users fall asleep.

</details>


### [414] [A Modular Algorithm for Non-Stationary Online Convex-Concave Optimization](https://arxiv.org/abs/2509.07901)
*Qing-xin Meng,Xia Lei,Jian-wei Liu*

Main category: cs.LG

TL;DR: 该论文提出了一个新颖的模块化算法来解决在线凸凹优化问题，目标是最小化动态对偶差距（D-DGap）。


<details>
  <summary>Details</summary>
Motivation: 现有的在线凸凹优化算法在特定环境下（如平稳或可预测环境）表现不佳，无法实现最优性能。

Method: 提出了一种包含自适应模块、多预测器聚合器和集成模块的新颖模块化算法。自适应模块用于动态调整以应对变化，多预测器聚合器用于选择最佳预测器，集成模块用于整合各组件优势。

Result: 算法实现了接近minimax最优的D-DGap上界（相差一个对数因子），并提供了由预测误差驱动的D-DGap界限。

Conclusion: 所提出的模块化算法有效且适应性强，能够根据环境动态调整，并整合来自多个预测器的“先验知识”。

Abstract: This paper investigates the problem of Online Convex-Concave Optimization,
which extends Online Convex Optimization to two-player time-varying
convex-concave games. The goal is to minimize the dynamic duality gap (D-DGap),
a critical performance measure that evaluates players' strategies against
arbitrary comparator sequences. Existing algorithms fail to deliver optimal
performance, particularly in stationary or predictable environments. To address
this, we propose a novel modular algorithm with three core components: an
Adaptive Module that dynamically adjusts to varying levels of non-stationarity,
a Multi-Predictor Aggregator that identifies the best predictor among multiple
candidates, and an Integration Module that effectively combines their
strengths. Our algorithm achieves a minimax optimal D-DGap upper bound, up to a
logarithmic factor, while also ensuring prediction error-driven D-DGap bounds.
The modular design allows for the seamless replacement of components that
regulate adaptability to dynamic environments, as well as the incorporation of
components that integrate ``side knowledge'' from multiple predictors.
Empirical results further demonstrate the effectiveness and adaptability of the
proposed method.

</details>


### [415] [Bio-KGvec2go: Serving up-to-date Dynamic Biomedical Knowledge Graph Embeddings](https://arxiv.org/abs/2509.07905)
*Hamid Ahmad,Heiko Paulheim,Rita T. Sousa*

Main category: cs.LG

TL;DR: Bio-KGvec2go是一个用于生成和提供生物医学本体知识图谱嵌入的API，支持定期更新以适应本体版本发布。


<details>
  <summary>Details</summary>
Motivation: 现代AI应用的发展依赖于知识图谱和本体，但集成这些语义资源与机器学习模型通常需要重训练模型，耗费大量计算资源。因此，提供预训练模型，特别是针对生物医学领域，具有重要价值。

Method: Bio-KGvec2go是KGvec2go Web API的扩展，通过生成和提供广泛使用的生物医学本体的知识图谱嵌入来实现。它还支持根据本体版本发布进行定期更新。

Result: 提供最新的、用户只需最小计算量即可使用的生物医学本体知识图谱嵌入，从而促进高效和及时的生物医学研究。

Conclusion: Bio-KGvec2go通过提供最新的生物医学本体知识图谱嵌入，解决了生物医学研究中数据更新和计算资源需求的问题，有助于AI开发和可持续计算。

Abstract: Knowledge graphs and ontologies represent entities and their relationships in
a structured way, having gained significance in the development of modern AI
applications. Integrating these semantic resources with machine learning models
often relies on knowledge graph embedding models to transform graph data into
numerical representations. Therefore, pre-trained models for popular knowledge
graphs and ontologies are increasingly valuable, as they spare the need to
retrain models for different tasks using the same data, thereby helping to
democratize AI development and enabling sustainable computing.
  In this paper, we present Bio-KGvec2go, an extension of the KGvec2go Web API,
designed to generate and serve knowledge graph embeddings for widely used
biomedical ontologies. Given the dynamic nature of these ontologies,
Bio-KGvec2go also supports regular updates aligned with ontology version
releases. By offering up-to-date embeddings with minimal computational effort
required from users, Bio-KGvec2go facilitates efficient and timely biomedical
research.

</details>


### [416] [One Model for All Tasks: Leveraging Efficient World Models in Multi-Task Planning](https://arxiv.org/abs/2509.07945)
*Yuan Pu,Yazhe Niu,Jia Tang,Junyu Xiong,Shuai Hu,Hongsheng Li*

Main category: cs.LG

TL;DR: ScaleZero通过MoE架构和DPS策略解决了异构多任务学习中的梯度冲突和模型可塑性问题，在Atari、DMControl和Jericho等基准测试中达到了与专用单任务基线相当的性能，并显著提高了样本和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有异构多任务学习模型在处理大规模异构环境时，面临梯度冲突和模型可塑性下降的问题，限制了其样本和计算效率。本研究旨在解决这些挑战。

Method: 提出了一种名为ScaleZero的模型，该模型采用Mixture-of-Experts (MoE) 架构来缓解梯度冲突，并引入了一种基于LoRA的动态参数缩放 (DPS) 策略，以自适应地平衡计算负载和模型知识。ScaleZero仅使用在线强化学习和单个模型进行训练。

Result: ScaleZero在Atari、DMControl和Jericho基准测试中，仅使用在线强化学习和单个模型，达到了与专用单任务基线相当的性能。当采用DPS策略时，ScaleZero在交互步数减少20%的情况下，仍能获得具有竞争力的性能。

Conclusion: ScaleZero通过MoE架构和DPS策略，在异构多任务学习方面展现出巨大潜力，能够有效提升样本和计算效率，并达到与专用单任务方法相当的性能。

Abstract: In heterogeneous multi-task learning, tasks not only exhibit diverse
observation and action spaces but also vary substantially in intrinsic
difficulty. While conventional multi-task world models like UniZero excel in
single-task settings, we find that when handling large-scale heterogeneous
environments, gradient conflicts and the loss of model plasticity often
constrain their sample and computational efficiency. In this work, we address
these challenges from two perspectives: the single learning iteration and the
overall learning process. First, we investigate the impact of key design spaces
on extending UniZero to multi-task planning. We find that a Mixture-of-Experts
(MoE) architecture provides the most substantial performance gains by
mitigating gradient conflicts, leading to our proposed model,
\textit{ScaleZero}. Second, to dynamically balance the computational load
across the learning process, we introduce an online, LoRA-based \textit{dynamic
parameter scaling} (DPS) strategy. This strategy progressively integrates LoRA
adapters in response to task-specific progress, enabling adaptive knowledge
retention and parameter expansion. Empirical evaluations on standard benchmarks
such as Atari, DMControl (DMC), and Jericho demonstrate that ScaleZero, relying
exclusively on online reinforcement learning with one model, attains
performance on par with specialized single-task baselines. Furthermore, when
augmented with our dynamic parameter scaling strategy, our method achieves
competitive performance while requiring only 80\% of the single-task
environment interaction steps. These findings underscore the potential of
ScaleZero for effective large-scale multi-task learning. Our code is available
at \textcolor{magenta}{https://github.com/opendilab/LightZero}.

</details>


### [417] [ACE and Diverse Generalization via Selective Disagreement](https://arxiv.org/abs/2509.07955)
*Oliver Daniels,Stuart Armstrong,Alexandre Maranhão,Mahirah Fairuz Rahman,Benjamin M. Marlin,Rebecca Gorman*

Main category: cs.LG

TL;DR: 深度神经网络容易受到不完全或完全的虚假相关性影响。本文提出了ACE方法，通过学习与训练数据一致但对新未标记输入有不同预测的概念集，并利用自信和选择性分歧的自训练方法，来解决完全虚假相关性带来的欠指定问题。ACE在相关基准测试中表现优于现有方法，并且能够处理不完全虚假相关性。此外，ACE还提供了更强的可配置性，可以轻松地整合先验知识和进行无监督模型选择。在语言模型对齐的早期应用中，ACE在测量篡改检测基准测试中取得了有竞争力的性能，且无需访问不可信的测量数据。ACE在克服欠指定方面取得了重要进展，但仍存在一些局限性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在处理虚假相关性，特别是完全虚假相关性时存在欠指定问题，导致模型泛化能力不足。

Method: 提出了一种名为ACE（Agreement-based Concept learning）的方法，该方法通过学习与训练数据一致但对新未标记输入有不同预测的概念集，并结合自信和选择性分歧的自训练策略来解决欠指定问题。

Result: ACE方法在处理完全虚假相关性的基准测试中，性能与现有方法相当或更优，并且对不完全虚假相关性也保持鲁棒性。在语言模型对齐任务中，ACE在测量篡改检测方面取得了具有竞争力的性能。

Conclusion: ACE方法通过学习不确定性概念集并利用选择性分歧的自训练，成功解决了深度神经网络在完全虚假相关性下的欠指定问题，并在多个基准测试和实际应用中展现出优越的性能和鲁棒性，是克服欠指定问题的重要进展。

Abstract: Deep neural networks are notoriously sensitive to spurious correlations -
where a model learns a shortcut that fails out-of-distribution. Existing work
on spurious correlations has often focused on incomplete
correlations,leveraging access to labeled instances that break the correlation.
But in cases where the spurious correlations are complete, the correct
generalization is fundamentally \textit{underspecified}. To resolve this
underspecification, we propose learning a set of concepts that are consistent
with training data but make distinct predictions on a subset of novel unlabeled
inputs. Using a self-training approach that encourages \textit{confident} and
\textit{selective} disagreement, our method ACE matches or outperforms existing
methods on a suite of complete-spurious correlation benchmarks, while remaining
robust to incomplete spurious correlations. ACE is also more configurable than
prior approaches, allowing for straight-forward encoding of prior knowledge and
principled unsupervised model selection. In an early application to
language-model alignment, we find that ACE achieves competitive performance on
the measurement tampering detection benchmark \textit{without} access to
untrusted measurements. While still subject to important limitations, ACE
represents significant progress towards overcoming underspecification.

</details>


### [418] [Customizing the Inductive Biases of Softmax Attention using Structured Matrices](https://arxiv.org/abs/2509.07963)
*Yilun Kuang,Noah Amsel,Sanae Lotfi,Shikai Qiu,Andres Potapczynski,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 标准注意力机制存在信息丢失和计算效率问题，本文提出基于BTT和MLR结构化矩阵的新评分函数，在多项任务上优于标准注意力。


<details>
  <summary>Details</summary>
Motivation: 标准注意力机制在处理高维输入时会因低维投影造成信息丢失，且对所有输入对使用相同评分函数，未考虑序列中邻近标记的距离依赖计算偏差。

Method: 提出基于计算高效结构化矩阵（如块张量分解BTT和多层低秩MLR）的新评分函数。

Result: 在具有高维输入的上下文回归任务中，新评分函数在固定计算预算下优于标准注意力。在语言模型任务中，MLR注意力实现了比标准注意力和滑动窗口注意力更优的缩放规律。BTT和MLR可以编码全秩或距离依赖的计算偏差。MLR注意力在长期时间序列预测任务中表现出潜力。

Conclusion: 提出的BTT和MLR结构化矩阵评分函数能够克服标准注意力在信息丢失和计算效率上的不足，并在多项任务中展现出优越性能。

Abstract: The core component of attention is the scoring function, which transforms the
inputs into low-dimensional queries and keys and takes the dot product of each
pair. While the low-dimensional projection improves efficiency, it causes
information loss for certain tasks that have intrinsically high-dimensional
inputs. Additionally, attention uses the same scoring function for all input
pairs, without imposing a distance-dependent compute bias for neighboring
tokens in the sequence. In this work, we address these shortcomings by
proposing new scoring functions based on computationally efficient structured
matrices with high ranks, including Block Tensor-Train (BTT) and Multi-Level
Low Rank (MLR) matrices. On in-context regression tasks with high-dimensional
inputs, our proposed scoring functions outperform standard attention for any
fixed compute budget. On language modeling, a task that exhibits locality
patterns, our MLR-based attention method achieves improved scaling laws
compared to both standard attention and variants of sliding window attention.
Additionally, we show that both BTT and MLR fall under a broader family of
efficient structured matrices capable of encoding either full-rank or
distance-dependent compute biases, thereby addressing significant shortcomings
of standard attention. Finally, we show that MLR attention has promising
results for long-range time-series forecasting.

</details>


### [419] [Theoretical Analysis on how Learning Rate Warmup Accelerates Convergence](https://arxiv.org/abs/2509.07972)
*Yuxing Liu,Yuze Ge,Rui Pan,An Kang,Tong Zhang*

Main category: cs.LG

TL;DR: 学习率预热技术在训练大型深度神经网络方面非常实用，但其理论优势尚未完全阐明。本研究提出了新的广义平滑性假设，并研究了其在确定性和随机设置下的收敛性质，证明了学习率预热可以加速梯度下降，并在某些情况下收敛速度可提高 $\Theta(T)$ 倍。


<details>
  <summary>Details</summary>
Motivation: 学习率预热技术在大型深度神经网络训练中广泛应用，但理论依据不足，本研究旨在弥合理论与实践之间的差距。

Method: 提出了一种新的广义平滑性假设，并在确定性和随机设置下研究了梯度下降的收敛性质。

Result: 证明了学习率预热能够持续加速梯度下降，并且在某些特定情况下，采用预热的梯度下降比不采用预热的学习率衰减策略能收敛快最多 $\Theta(T)$ 倍。

Conclusion: 学习率预热技术通过加速梯度下降，为优化理论提供了新的见解，并解释了该策略的优势。

Abstract: Learning rate warmup is a popular and practical technique in training
large-scale deep neural networks. Despite the huge success in practice, the
theoretical advantages of this strategy of gradually increasing the learning
rate at the beginning of the training process have not been fully understood.
To resolve this gap between theory and practice, we first propose a novel
family of generalized smoothness assumptions, and validate its applicability
both theoretically and empirically. Under the novel smoothness assumption, we
study the convergence properties of gradient descent (GD) in both deterministic
and stochastic settings. It is shown that learning rate warmup consistently
accelerates GD, and GD with warmup can converge at most $\Theta(T)$ times
faster than with a non-increasing learning rate schedule in some specific
cases, providing insights into the benefits of this strategy from an
optimization theory perspective.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [420] [A multi-strategy improved gazelle optimization algorithm for solving numerical optimization and engineering applications](https://arxiv.org/abs/2509.07211)
*Qi Diao,Chengyue Xie,Yuchen Yin,Hoileong Lee,Haolong Yang*

Main category: cs.NE

TL;DR: 本文提出了一种多策略改进的瞪羚优化算法（MSIGOA），以解决原始算法探索与利用不平衡和种群内信息交换不足的问题。


<details>
  <summary>Details</summary>
Motivation: 原始瞪羚优化算法存在探索与利用不平衡和种群内信息交换不足的缺点。

Method: MSIGOA提出了一种基于迭代的更新框架，根据优化过程在开发和探索之间切换，增强了优化过程中的局部开发和全局探索之间的平衡，并提高了收敛速度。两种自适应参数调整策略提高了算法的适用性并促进了更平稳的优化过程。基于优势种群的重启策略增强了算法从局部最优中逃脱和避免过早收敛的能力。

Result: MSIGOA在CEC2017和CEC2022测试集上的测试结果和统计检验表明，MSIGOA在探索和利用能力、收敛性和效率方面优于基本GOA和其他先进算法。在CEC2017和CEC2022测试集上，MSIGOA不劣于GOA的函数比例分别为92.2%和83.3%，MSIGOA不劣于其他算法的函数比例分别为88.57%和87.5%。

Conclusion: MSIGOA通过引入迭代更新框架、自适应参数调整和基于优势种群的重启策略，显著提高了瞪羚优化算法的性能，在解决复杂问题方面表现出优越的收敛性和效率，并且在工程设计优化问题中也验证了其可扩展性。

Abstract: Aiming at the shortcomings of the gazelle optimization algorithm, such as the
imbalance between exploration and exploitation and the insufficient information
exchange within the population, this paper proposes a multi-strategy improved
gazelle optimization algorithm (MSIGOA). To address these issues, MSIGOA
proposes an iteration-based updating framework that switches between
exploitation and exploration according to the optimization process, which
effectively enhances the balance between local exploitation and global
exploration in the optimization process and improves the convergence speed. Two
adaptive parameter tuning strategies improve the applicability of the algorithm
and promote a smoother optimization process. The dominant population-based
restart strategy enhances the algorithms ability to escape from local optima
and avoid its premature convergence. These enhancements significantly improve
the exploration and exploitation capabilities of MSIGOA, bringing superior
convergence and efficiency in dealing with complex problems. In this paper, the
parameter sensitivity, strategy effectiveness, convergence and stability of the
proposed method are evaluated on two benchmark test sets including CEC2017 and
CEC2022. Test results and statistical tests show that MSIGOA outperforms basic
GOA and other advanced algorithms. On the CEC2017 and CEC2022 test sets, the
proportion of functions where MSIGOA is not worse than GOA is 92.2% and 83.3%,
respectively, and the proportion of functions where MSIGOA is not worse than
other algorithms is 88.57% and 87.5%, respectively. Finally, the extensibility
of MSIGAO is further verified by several engineering design optimization
problems.

</details>


### [421] [Breaking the Conventional Forward-Backward Tie in Neural Networks: Activation Functions](https://arxiv.org/abs/2509.07236)
*Luigi Troiano,Francesco Gissi,Vincenzo Benedetto,Genny Tortora*

Main category: cs.NE

TL;DR: 可以通过放宽前向-后向对称性来训练具有平坦或不可微激活函数的神经网络，从而提高训练稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统上，基于梯度的神经网络训练要求激活函数在某些区域是可微的（或次可微的）和严格单调的，以防止梯度变平。这种对称性限制了激活函数的选择。本研究旨在挑战这一假设。

Method: 通过数学分析，证明梯度方向比梯度大小更重要。在 MLP、CNN 和 BNN 等基础架构上进行实验，以展示替代梯度（简单或随机）的效果。

Result: 研究结果表明，放宽前向-后向对称性并使用替代梯度不会损害学习，反而可能提高训练稳定性和效率。具有平坦或不可微激活函数（如海维赛德阶跃函数）的神经网络可以被有效地训练。

Conclusion: 本研究表明，通过放宽前向-后向对称性，可以有效地训练具有平坦或不可微激活函数的神经网络，从而为神经网络设计提供了更大的灵活性和计算效率。未来的研究可以进一步在更复杂的架构上进行验证。

Abstract: Gradient-based neural network training traditionally enforces symmetry
between forward and backward propagation, requiring activation functions to be
differentiable (or sub-differentiable) and strictly monotonic in certain
regions to prevent flat gradient areas. This symmetry, linking forward
activations closely to backward gradients, significantly restricts the
selection of activation functions, particularly excluding those with
substantial flat or non-differentiable regions. In this paper, we challenge
this assumption through mathematical analysis, demonstrating that precise
gradient magnitudes derived from activation functions are largely redundant,
provided the gradient direction is preserved. Empirical experiments conducted
on foundational architectures - such as Multi-Layer Perceptrons (MLPs),
Convolutional Neural Networks (CNNs), and Binary Neural Networks (BNNs) -
confirm that relaxing forward-backward symmetry and substituting traditional
gradients with simpler or stochastic alternatives does not impair learning and
may even enhance training stability and efficiency. We explicitly demonstrate
that neural networks with flat or non-differentiable activation functions, such
as the Heaviside step function, can be effectively trained, thereby expanding
design flexibility and computational efficiency. Further empirical validation
with more complex architectures remains a valuable direction for future
research.

</details>


### [422] [Word2Spike: Poisson Rate Coding for Associative Memories and Neuromorphic Algorithms](https://arxiv.org/abs/2509.07361)
*Archit Kalra,Midhun Sadanand*

Main category: cs.NE

TL;DR: Word2Spike将连续词嵌入转换为脉冲表示，以实现节能的类脑联想记忆。


<details>
  <summary>Details</summary>
Motivation: 脉冲神经网络（SNN）在实现节能、类脑的联想记忆方面具有巨大潜力。

Method: 提出了一种名为Word2Spike的新型率编码机制，它结合了连续词嵌入和神经形态架构。通过泊松过程，将多维词向量一对一地映射到脉冲吸引子状态。并使用BitNet b1.58量化。

Result: 在SimLex-999数据集上，保持了97%的连续嵌入语义相似性。在OpenAI的text-embedding-3-large的10,000个单词上实现了100%的重建准确率。即使在故意引入噪声的情况下，仍保持了100%的原始嵌入的类比性能。

Conclusion: Word2Spike为神经形态系统中的语义编码提供了一种强大的、可恢复的机制。

Abstract: Spiking neural networks offer a promising path toward energy-efficient,
brain-like associative memory. This paper introduces Word2Spike, a novel rate
coding mechanism that combines continuous word embeddings and neuromorphic
architectures. We develop a one-to-one mapping that converts multi-dimensional
word vectors into spike-based attractor states using Poisson processes. Using
BitNet b1.58 quantization, we maintain 97% semantic similarity of continuous
embeddings on SimLex-999 while achieving 100% reconstruction accuracy on 10,000
words from OpenAI's text-embedding-3-large. We preserve analogy performance
(100% of original embedding performance) even under intentionally introduced
noise, indicating a resilient mechanism for semantic encoding in neuromorphic
systems. Next steps include integrating the mapping with spiking transformers
and liquid state machines (resembling Hopfield Networks) for further
evaluation.

</details>
