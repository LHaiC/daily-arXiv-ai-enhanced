<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 90]
- [cs.CL](#cs.CL) [Total: 36]
- [cs.SI](#cs.SI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.LG](#cs.LG) [Total: 52]
- [eess.IV](#eess.IV) [Total: 11]
- [eess.SY](#eess.SY) [Total: 8]
- [cs.RO](#cs.RO) [Total: 15]
- [cs.GT](#cs.GT) [Total: 1]
- [quant-ph](#quant-ph) [Total: 41]
- [cs.CE](#cs.CE) [Total: 1]
- [cs.LO](#cs.LO) [Total: 11]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.NE](#cs.NE) [Total: 1]
- [cs.GR](#cs.GR) [Total: 3]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 9]
- [cs.DC](#cs.DC) [Total: 5]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 17]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [cs.MA](#cs.MA) [Total: 3]
- [cs.AR](#cs.AR) [Total: 3]
- [eess.SP](#eess.SP) [Total: 12]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Quantum-Cognitive Tunnelling Neural Networks for Military-Civilian Vehicle Classification and Sentiment Analysis](https://arxiv.org/abs/2507.18645)
*Milan Maksimovic,Anna Bohdanets,Immaculate Motsi-Omoijiade,Guido Governatori,Ivan S. Maksymov*

Main category: cs.CV

TL;DR: QT-based neural networks show promise for improving AI in military applications like drone warfare by mimicking human reasoning in perception and sentiment analysis.


<details>
  <summary>Details</summary>
Motivation: Incorporating quantum tunnelling (QT) probability into neural network models effectively captures important nuances of human perception, particularly in the recognition of ambiguous objects and sentiment analysis.

Method: Employing novel QT-based neural networks to distinguish customised CIFAR-format images of military and civilian vehicles, as well as sentiment, using a proprietary military-specific vocabulary.

Result: The effectiveness of QT-based neural networks in distinguishing customised CIFAR-format images of military and civilian vehicles, as well as sentiment, using a proprietary military-specific vocabulary.

Conclusion: QT-based models can enhance multimodal AI applications in battlefield scenarios, particularly within human-operated drone warfare contexts, imbuing AI with certain traits of human reasoning.

Abstract: Prior work has demonstrated that incorporating well-known quantum tunnelling
(QT) probability into neural network models effectively captures important
nuances of human perception, particularly in the recognition of ambiguous
objects and sentiment analysis. In this paper, we employ novel QT-based neural
networks and assess their effectiveness in distinguishing customised
CIFAR-format images of military and civilian vehicles, as well as sentiment,
using a proprietary military-specific vocabulary. We suggest that QT-based
models can enhance multimodal AI applications in battlefield scenarios,
particularly within human-operated drone warfare contexts, imbuing AI with
certain traits of human reasoning.

</details>


### [2] [Livatar-1: Real-Time Talking Heads Generation with Tailored Flow Matching](https://arxiv.org/abs/2507.18649)
*Haiyang Liu,Xiaolin Hong,Xuancheng Yang,Yudi Ruan,Xiang Lian,Michael Lingelbach,Hongwei Yi,Wei Li*

Main category: cs.CV

TL;DR: Livatar 是一个实时音频驱动的说话头视频生成框架，它使用流匹配技术提高了唇同步准确性和姿态稳定性，实现了高帧率和低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的音频驱动的说话头视频生成框架在唇同步准确性和长期姿态漂移方面存在不足。

Method: 提出了一种基于流匹配（flow matching）的框架，以解决现有基线在唇同步准确性和长期姿态漂移方面存在的局限性。

Result: Livatar 在 HDTF 数据集上实现了 8.50 的 LipSync Confidence，在单个 A10 GPU 上实现了 141 FPS 的吞吐量和 0.17 秒的端到端延迟。

Conclusion: Livatar 框架实现了有竞争力的口型同步质量（HDTF 数据集上为 8.50 LipSync Confidence），并达到了 141 FPS 的吞吐量和 0.17 秒的端到端延迟（在单个 A10 GPU 上），使得高保真度虚拟形象能够广泛应用于各种场景。

Abstract: We present Livatar, a real-time audio-driven talking heads videos generation
framework. Existing baselines suffer from limited lip-sync accuracy and
long-term pose drift. We address these limitations with a flow matching based
framework. Coupled with system optimizations, Livatar achieves competitive
lip-sync quality with a 8.50 LipSync Confidence on the HDTF dataset, and
reaches a throughput of 141 FPS with an end-to-end latency of 0.17s on a single
A10 GPU. This makes high-fidelity avatars accessible to broader applications.
Our project is available at https://www.hedra.com/ with with examples at
https://h-liu1997.github.io/Livatar-1/

</details>


### [3] [Features extraction for image identification using computer vision](https://arxiv.org/abs/2507.18650)
*Venant Niyonkuru,Sylla Sekou,Jimmy Jackson Sinzinkayo*

Main category: cs.CV

TL;DR: 本文检验了ViTs、GANs、深度特征模型、传统方法以及非对比和对比特征模型等各种特征提取技术，重点介绍了ViTs的架构，并对其优点和局限性进行了实验评估。


<details>
  <summary>Details</summary>
Motivation: 本文旨在检验各种特征提取技术在计算机视觉中的应用，特别是ViTs。

Method: 本文总结了ViTs、GANs、深度特征模型、传统方法（SIFT、SURF、ORB）以及非对比和对比特征模型等各种特征提取技术。文章重点介绍了ViTs的架构，包括斑块嵌入、位置编码和多头自注意力机制。

Result: 实验结果确定了ViTs和CNNs两者的优点和局限性，以及它们在推进计算机视觉方面的实用应用。

Conclusion: 该研究总结了ViTs的架构、传统方法和深度特征模型，并对它们的优点和局限性进行了实验评估。

Abstract: This study examines various feature extraction techniques in computer vision,
the primary focus of which is on Vision Transformers (ViTs) and other
approaches such as Generative Adversarial Networks (GANs), deep feature models,
traditional approaches (SIFT, SURF, ORB), and non-contrastive and contrastive
feature models. Emphasizing ViTs, the report summarizes their architecture,
including patch embedding, positional encoding, and multi-head self-attention
mechanisms with which they overperform conventional convolutional neural
networks (CNNs). Experimental results determine the merits and limitations of
both methods and their utilitarian applications in advancing computer vision.

</details>


### [4] [Adapt, But Don't Forget: Fine-Tuning and Contrastive Routing for Lane Detection under Distribution Shift](https://arxiv.org/abs/2507.18653)
*Mohammed Abdul Hafeez Khan,Parth Ganeriwala,Sarah M. Lehman,Siddhartha Bhattacharyya,Amy Alvarez,Natasha Neogi*

Main category: cs.CV

TL;DR: 通过为每个目标分布创建单独的分支并进行参数高效的微调，解决了车道线检测中的灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 闭 عالم 场景下的车道线检测模型在实际应用中会遇到跨数据集分布偏移问题，即使在同一域内，这种偏移也会导致灾难性的遗忘。

Method: 首先在源分布上训练基础模型，然后通过创建单独的分支来适应每个新的目标分布，仅对选定的组件进行微调，同时保持原始源分支固定。基于组件分析，确定有效的微调策略以实现参数高效的适应。在推理时，使用监督对比学习模型识别输入分布并动态路由到相应分支。

Result: 我们的框架在使用的参数量远少于为每个分布单独训练模型的情况下，实现了接近最优的 F1 分数。

Conclusion: 为了解决跨数据集分布偏移导致灾难性遗忘的问题，我们提出了一种新颖的框架。该框架通过为每个目标分布创建单独的分支，并仅对选定的组件进行微调，同时保持原始源分支固定，从而实现参数高效的适应。在推理时，我们使用监督对比学习模型来识别输入分布并动态地将其路由到相应的分支。我们的框架在实现接近最优的 F1 分数的同时，使用的参数量明显少于为每个分布单独训练模型。

Abstract: Lane detection models are often evaluated in a closed-world setting, where
training and testing occur on the same dataset. We observe that, even within
the same domain, cross-dataset distribution shifts can cause severe
catastrophic forgetting during fine-tuning. To address this, we first train a
base model on a source distribution and then adapt it to each new target
distribution by creating separate branches, fine-tuning only selected
components while keeping the original source branch fixed. Based on a
component-wise analysis, we identify effective fine-tuning strategies for
target distributions that enable parameter-efficient adaptation. At inference
time, we propose using a supervised contrastive learning model to identify the
input distribution and dynamically route it to the corresponding branch. Our
framework achieves near-optimal F1-scores while using significantly fewer
parameters than training separate models for each distribution.

</details>


### [5] [Part Segmentation of Human Meshes via Multi-View Human Parsing](https://arxiv.org/abs/2507.18655)
*James Dickens,Kamyar Hamad*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法，用于对大规模人体网格进行逐点语义分割。该方法结合了伪地面真实标注流程、一种高效的采样策略（窗口迭代最远点采样）以及PointTransformer模型，实现了无需纹理信息的纯几何分割，并在实验中证明了其有效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在弥合点云深度学习和人体解析这两个领域之间的差距，实现大规模人体网格的逐点语义分割。

Method: 首先，为Thuman2.1数据集开发了一个伪地面真实标注流程：将网格对齐到规范姿态，从多个视点进行分割，然后将生成的点级标签反投影到原始网格上，以生成逐点伪地面真实标注。随后，引入了一种新颖的、内存高效的采样策略——具有基于空间填充曲线序列化的窗口迭代最远点采样（FPS），以有效地对点云进行降采样。最后，使用PointTransformer进行纯粹的几何分割。

Result: 实验结果证实了所提出方法的有效性和准确性。

Conclusion: 该方法通过使用PointTransformer和一种新颖的、内存高效的采样策略，实现了对大规模人体网格的逐点语义分割，而无需依赖纹理信息，并已通过实验证明其有效性和准确性。

Abstract: Recent advances in point cloud deep learning have led to models that achieve
high per-part labeling accuracy on large-scale point clouds, using only the raw
geometry of unordered point sets. In parallel, the field of human parsing
focuses on predicting body part and clothing/accessory labels from images. This
work aims to bridge these two domains by enabling per-vertex semantic
segmentation of large-scale human meshes. To achieve this, a pseudo-ground
truth labeling pipeline is developed for the Thuman2.1 dataset: meshes are
first aligned to a canonical pose, segmented from multiple viewpoints, and the
resulting point-level labels are then backprojected onto the original mesh to
produce per-point pseudo ground truth annotations. Subsequently, a novel,
memory-efficient sampling strategy is introduced, a windowed iterative farthest
point sampling (FPS) with space-filling curve-based serialization to
effectively downsample the point clouds. This is followed by a purely geometric
segmentation using PointTransformer, enabling semantic parsing of human meshes
without relying on texture information. Experimental results confirm the
effectiveness and accuracy of the proposed approach.

</details>


### [6] [ShrinkBox: Backdoor Attack on Object Detection to Disrupt Collision Avoidance in Machine Learning-based Advanced Driver Assistance Systems](https://arxiv.org/abs/2507.18656)
*Muhammad Zaeem Shahzad,Muhammad Abdullah Hanif,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: ShrinkBox是一种针对自动驾驶系统中使用的目标检测器的后门攻击，它通过缩小边界框来欺骗系统，使其对距离的估计不准确，从而可能导致碰撞警告失败。


<details>
  <summary>Details</summary>
Motivation: 当前的ML-ADAS依赖于仅使用标准摄像头输入的DNN，作为一种经济高效的替代昂贵的传感器技术。然而，这些系统的健壮性受到目标检测器中安全漏洞的威胁，特别是影响碰撞避免功能。

Method: 提出了一种名为ShrinkBox的新型后门攻击，该攻击通过在训练数据中微妙地缩小地面真实边界框来操纵目标检测器，从而在下游的距离估计中引入显著误差。

Result: ShrinkBox在YOLOv9m上实现了96%的攻击成功率，攻击的毒化率为4%。ShrinkBox将下游距离估计的平均绝对误差（MAE）增加了3倍以上，可能导致碰撞警告延迟或完全无效。

Conclusion: ShrinkBox是一种针对基于相机的碰撞避免ML-ADAS的检测器的新颖的后门攻击，通过缩小地面真实边界框来破坏下游的距离估计，在YOLOv9m上实现了96%的成功率，并将MAE增加了3倍以上。

Abstract: Advanced Driver Assistance Systems (ADAS) significantly enhance road safety
by detecting potential collisions and alerting drivers. However, their reliance
on expensive sensor technologies such as LiDAR and radar limits accessibility,
particularly in low- and middle-income countries. Machine learning-based ADAS
(ML-ADAS), leveraging deep neural networks (DNNs) with only standard camera
input, offers a cost-effective alternative. Critical to ML-ADAS is the
collision avoidance feature, which requires the ability to detect objects and
estimate their distances accurately. This is achieved with specialized DNNs
like YOLO, which provides real-time object detection, and a lightweight,
detection-wise distance estimation approach that relies on key features
extracted from the detections like bounding box dimensions and size. However,
the robustness of these systems is undermined by security vulnerabilities in
object detectors. In this paper, we introduce ShrinkBox, a novel backdoor
attack targeting object detection in collision avoidance ML-ADAS. Unlike
existing attacks that manipulate object class labels or presence, ShrinkBox
subtly shrinks ground truth bounding boxes. This attack remains undetected in
dataset inspections and standard benchmarks while severely disrupting
downstream distance estimation. We demonstrate that ShrinkBox can be realized
in the YOLOv9m object detector at an Attack Success Rate (ASR) of 96%, with
only a 4% poisoning ratio in the training instances of the KITTI dataset.
Furthermore, given the low error targets introduced in our relaxed poisoning
strategy, we find that ShrinkBox increases the Mean Absolute Error (MAE) in
downstream distance estimation by more than 3x on poisoned samples, potentially
resulting in delays or prevention of collision warnings altogether.

</details>


### [7] [A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation](https://arxiv.org/abs/2507.19045)
*Yufei Ma,Hanwen Zhang,Qiya Yang,Guibo Luo,Yuesheng Zhu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In multi-center scenarios, One-Shot Federated Learning (OSFL) has attracted
increasing attention due to its low communication overhead, requiring only a
single round of transmission. However, existing generative model-based OSFL
methods suffer from low training efficiency and potential privacy leakage in
the healthcare domain. Additionally, achieving convergence within a single
round of model aggregation is challenging under non-Independent and Identically
Distributed (non-IID) data. To address these challenges, in this paper a
modified OSFL framework is proposed, in which a new Feature-Guided Rectified
Flow Model (FG-RF) and Dual-Layer Knowledge Distillation (DLKD) aggregation
method are developed. FG-RF on the client side accelerates generative modeling
in medical imaging scenarios while preserving privacy by synthesizing
feature-level images rather than pixel-level images. To handle non-IID
distributions, DLKD enables the global student model to simultaneously mimic
the output logits and align the intermediate-layer features of client-side
teacher models during aggregation. Experimental results on three non-IID
medical imaging datasets show that our new framework and method outperform
multi-round federated learning approaches, achieving up to 21.73% improvement,
and exceeds the baseline FedISCA by an average of 21.75%. Furthermore, our
experiments demonstrate that feature-level synthetic images significantly
reduce privacy leakage risks compared to pixel-level synthetic images.

</details>


### [8] [VGS-ATD: Robust Distributed Learning for Multi-Label Medical Image Classification Under Heterogeneous and Imbalanced Conditions](https://arxiv.org/abs/2507.18657)
*Zehui Zhao,Laith Alzubaidi,Haider A. Alwzwazy,Jinglan Zhang,Yuantong Gu*

Main category: cs.CV

TL;DR: 提出了一种名为VGS-ATD的新型分布式学习框架，用于医学影像任务，解决了隐私、数据异构性、通信效率和灾难性遗忘等问题。实验结果显示，VGS-ATD在准确率、可扩展性和效率方面均优于中心化学习、群体学习和联邦学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统中心化学习方法在医学影像任务中存在的隐私风险，以及去中心化方法（如联邦学习和群体学习）在处理异构/不平衡数据、通信效率和灾难性遗忘方面的挑战，特别是在需要持续学习和扩展的临床环境中。

Method: 提出了一种名为VGS-ATD的新型分布式学习框架，通过在分布式节点上进行模型训练，仅共享模型权重，以解决隐私、数据异构性、通信效率和灾难性遗忘等问题。

Result: VGS-ATD在30个数据集和80个独立标签的实验中，整体准确率达到92.7%，显著优于中心化学习（84.9%）和群体学习（72.99%），并且联邦学习因计算资源要求高而失败。VGS-ATD扩展性良好，新节点加入时准确率仅下降1%，而中心化学习下降20%，显示出其抗灾难性遗忘能力。同时，与中心化和群体学习相比，计算成本降低了高达50%。

Conclusion: VGS-ATD框架在分布式学习中表现出优越的性能、可扩展性和效率，成功解决了传统中心化和现有去中心化学习方法的局限性，尤其是在处理异构、不平衡数据和防止灾难性遗忘方面。

Abstract: In recent years, advanced deep learning architectures have shown strong
performance in medical imaging tasks. However, the traditional centralized
learning paradigm poses serious privacy risks as all data is collected and
trained on a single server. To mitigate this challenge, decentralized
approaches such as federated learning and swarm learning have emerged, allowing
model training on local nodes while sharing only model weights. While these
methods enhance privacy, they struggle with heterogeneous and imbalanced data
and suffer from inefficiencies due to frequent communication and the
aggregation of weights. More critically, the dynamic and complex nature of
clinical environments demands scalable AI systems capable of continuously
learning from diverse modalities and multilabels. Yet, both centralized and
decentralized models are prone to catastrophic forgetting during system
expansion, often requiring full model retraining to incorporate new data. To
address these limitations, we propose VGS-ATD, a novel distributed learning
framework. To validate VGS-ATD, we evaluate it in experiments spanning 30
datasets and 80 independent labels across distributed nodes, VGS-ATD achieved
an overall accuracy of 92.7%, outperforming centralized learning (84.9%) and
swarm learning (72.99%), while federated learning failed under these conditions
due to high requirements on computational resources. VGS-ATD also demonstrated
strong scalability, with only a 1% drop in accuracy on existing nodes after
expansion, compared to a 20% drop in centralized learning, highlighting its
resilience to catastrophic forgetting. Additionally, it reduced computational
costs by up to 50% relative to both centralized and swarm learning, confirming
its superior efficiency and scalability.

</details>


### [9] [Fuzzy Theory in Computer Vision: A Review](https://arxiv.org/abs/2507.18660)
*Adilet Yerkin,Ayan Igali,Elnara Kadyrgali,Maksat Shagyrov,Malika Ziyada,Muragul Muratbekova,Pakizar Shamoi*

Main category: cs.CV

TL;DR: 本文研究了模糊逻辑在计算机视觉中的应用，特别是处理不确定性和噪声的能力，并探讨了其与深度学习的结合以及未来趋势。


<details>
  <summary>Details</summary>
Motivation: 随着计算机视觉应用的普及，需要更有效的方法来处理图像数据中的不确定性、噪声和不精确性。模糊逻辑能够模拟渐进过渡和类人推理，为计算机视觉提供了一种有前景的处理方法。

Method: 本文探讨了模糊逻辑在计算机视觉中的应用，重点介绍了模糊聚类、模糊推理系统、II型模糊集和模糊规则库决策制定等关键模糊技术，并讨论了其与CNN等深度学习模型的集成。

Result: 模糊逻辑方法通过提供比传统方法更具适应性和可解释性的解决方案，能够改进对象识别、图像分割和特征提取。此外，模糊逻辑与深度学习的结合有望在医学成像、自动系统和工业检测等领域取得更好的应用效果。

Conclusion: 模糊逻辑在计算机视觉领域具有巨大潜力，尤其是在处理不确定性、噪声和不精确性方面。通过结合模糊逻辑和深度学习（如CNN），可以进一步提升复杂视觉任务的性能。新兴的混合模糊-深度学习模型和可解释AI是未来的发展方向。

Abstract: Computer vision applications are omnipresent nowadays. The current paper
explores the use of fuzzy logic in computer vision, stressing its role in
handling uncertainty, noise, and imprecision in image data. Fuzzy logic is able
to model gradual transitions and human-like reasoning and provides a promising
approach to computer vision. Fuzzy approaches offer a way to improve object
recognition, image segmentation, and feature extraction by providing more
adaptable and interpretable solutions compared to traditional methods. We
discuss key fuzzy techniques, including fuzzy clustering, fuzzy inference
systems, type-2 fuzzy sets, and fuzzy rule-based decision-making. The paper
also discusses various applications, including medical imaging, autonomous
systems, and industrial inspection. Additionally, we explore the integration of
fuzzy logic with deep learning models such as convolutional neural networks
(CNNs) to enhance performance in complex vision tasks. Finally, we examine
emerging trends such as hybrid fuzzy-deep learning models and explainable AI.

</details>


### [10] [Eyes Will Shut: A Vision-Based Next GPS Location Prediction Model by Reinforcement Learning from Visual Map Feed Back](https://arxiv.org/abs/2507.18661)
*Ruixing Zhang,Yang Zhang,Tongyu Zhu,Leilei Sun,Weifeng Lv*

Main category: cs.CV

TL;DR: 文章提出了一种利用视觉语言模型（VLM）进行下一个位置预测的方法（VLMLocPredictor），通过结合视觉地图信息和强化学习，在模拟人类推理方式的同时，实现了优于现有方法的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法未能像人类一样在路网地图上进行推理的问题，文章提出利用视觉语言模型（VLM）的能力，将路网和轨迹渲染到图像上，以实现类似人类的轨迹推理。

Method: 文章首先提出了一个名为视觉引导位置搜索（VGLS）的方法，用于评估通用VLM在不修改内部参数的情况下进行基于轨迹推理的能力。在此基础上，进一步提出了VLMLocPredictor，该方法包含两个阶段：第一阶段通过两个监督微调（SFT）任务使VLM能够理解路网和轨迹结构，并获得在这些视觉输入上的基本推理能力；第二阶段引入了视觉地图反馈强化学习，使模型能够通过与环境的交互来改进其下一个位置预测能力。

Result: VLMLocPredictor在四个不同城市的 数据集上取得了最先进（SOTA）的性能，并且在跨城市泛化能力方面优于其他基于LLM的方法。

Conclusion: 所提出的VLMLocPredictor方法在四个不同城市的 数据集上进行了实验，取得了最先进（SOTA）的性能，并且与其他的基于LLM的方法相比，具有更优越的跨城市泛化能力。

Abstract: Next Location Prediction is a fundamental task in the study of human
mobility, with wide-ranging applications in transportation planning, urban
governance, and epidemic forecasting. In practice, when humans attempt to
predict the next location in a trajectory, they often visualize the trajectory
on a map and reason based on road connectivity and movement trends. However,
the vast majority of existing next-location prediction models do not reason
over maps \textbf{in the way that humans do}. Fortunately, the recent
development of Vision-Language Models (VLMs) has demonstrated strong
capabilities in visual perception and even visual reasoning. This opens up a
new possibility: by rendering both the road network and trajectory onto an
image and leveraging the reasoning abilities of VLMs, we can enable models to
perform trajectory inference in a human-like manner. To explore this idea, we
first propose a method called Vision-Guided Location Search (VGLS), which
evaluates whether a general-purpose VLM is capable of trajectory-based
reasoning without modifying any of its internal parameters. Based on insights
from the VGLS results, we further propose our main approach: VLMLocPredictor,
which is composed of two stages: In the first stage, we design two Supervised
Fine-Tuning (SFT) tasks that help the VLM understand road network and
trajectory structures and acquire basic reasoning ability on such visual
inputs. In the second stage, we introduce Reinforcement Learning from Visual
Map Feedback, enabling the model to self-improve its next-location prediction
ability through interaction with the environment. Experiments conducted on
datasets from four different cities show that our method achieves
state-of-the-art (SOTA) performance and exhibits superior cross-city
generalization compared to other LLM-based approaches.

</details>


### [11] [Gen-AI Police Sketches with Stable Diffusion](https://arxiv.org/abs/2507.18667)
*Nicholas Fidalgo,Aaron Contreras,Katherine Harvey,Johnny Ni*

Main category: cs.CV

TL;DR: 该研究评估了三种AI方法在嫌疑人画像绘制中的应用。结果显示，基础的Stable Diffusion模型（模型1）在图像质量指标上表现最佳，尽管结合了CLIP和LoRA微调的模型（模型3）在文本-图像对齐方面有潜力，但整体效果仍不如模型1。


<details>
  <summary>Details</summary>
Motivation: 为了自动化和增强嫌疑人画像绘制过程，探索多模态人工智能驱动的方法。

Method: 研究了三种方法：(1) 基线图像到图像的Stable Diffusion模型，(2) 集成了预训练CLIP模型的相同模型以实现文本-图像对齐，以及 (3) 结合了CLIP模型LoRA微调的新方法，应用于自注意力和交叉注意力层，并与Stable Diffusion集成。进行了消融研究和性能测试，评估了结构相似性（SSIM）、峰值信噪比（PSNR）和感知相似性（LPIPS）。

Result: 模型1在SSIM和PSNR方面表现最佳。模型3在迭代优化后感知相似性有所提升，但仍不如模型1。模型1生成的画像具有最清晰的面部特征。

Conclusion: 该项目探索了使用多模态人工智能驱动的方法来自动化和增强嫌疑人画像绘制。研究了三种方法：(1) 基线图像到图像的Stable Diffusion模型，(2) 集成了预训练CLIP模型的相同模型以实现文本-图像对齐，以及 (3) 结合了CLIP模型LoRA微调的新方法，应用于自注意力和交叉注意力层，并与Stable Diffusion集成。消融研究证实，对自注意力和交叉注意力层进行微调可以实现文本描述和画像之间最佳的对齐效果。性能测试表明，模型1在结构相似性（SSIM）和峰值信噪比（PSNR）方面表现最佳，分别达到0.72和25 dB，优于模型2和模型3。迭代优化提升了感知相似性（LPIPS），模型3的性能优于模型2，但仍落后于模型1。定性评估显示，模型1生成的画像具有最清晰的面部特征，尽管其方法简单，但作为基线模型具有鲁棒性。

Abstract: This project investigates the use of multimodal AI-driven approaches to
automate and enhance suspect sketching. Three pipelines were developed and
evaluated: (1) baseline image-to-image Stable Diffusion model, (2) same model
integrated with a pre-trained CLIP model for text-image alignment, and (3)
novel approach incorporating LoRA fine-tuning of the CLIP model, applied to
self-attention and cross-attention layers, and integrated with Stable
Diffusion. An ablation study confirmed that fine-tuning both self- and
cross-attention layers yielded the best alignment between text descriptions and
sketches. Performance testing revealed that Model 1 achieved the highest
structural similarity (SSIM) of 0.72 and a peak signal-to-noise ratio (PSNR) of
25 dB, outperforming Model 2 and Model 3. Iterative refinement enhanced
perceptual similarity (LPIPS), with Model 3 showing improvement over Model 2
but still trailing Model 1. Qualitatively, sketches generated by Model 1
demonstrated the clearest facial features, highlighting its robustness as a
baseline despite its simplicity.

</details>


### [12] [Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks](https://arxiv.org/abs/2507.18675)
*Sanyam Jain,Marsha Mariya Kappan,Vijeta Sharma*

Main category: cs.CV

TL;DR: CLIP模型在人体动作识别任务中表现不佳，尤其是在遮挡关键信息时。通过添加类别特定噪声可以提高其性能，但仍需克服在医疗领域应用的挑战。


<details>
  <summary>Details</summary>
Motivation: 医疗和健康领域需要高效准确的人体动作识别，以支持患者行为监测、跌倒检测、手术机器人监督和程序技能评估等应用。虽然CNN和RNN等传统模型取得了一定成功，但在处理多样化和复杂动作时泛化能力不足。基于Transformer的CLIP模型在视频动作识别方面展现出潜力。

Method: 在UCF-101数据集上评估CLIP模型，并系统分析了三种掩码策略（百分比和形状的黑掩码、特征特定掩码、隔离掩码）下的性能。提出了一种通过自定义损失函数学习的类别特定噪声来增强模型对类别定义特征的关注。

Result: CLIP模型在面对掩码策略时表现出不一致的行为和频繁的误分类。引入类别特定噪声后，模型的分类准确性和置信度得到提高，偏差降低。

Conclusion: CLIP模型在UCF-101数据集上表现出不一致的行为，尤其在关键视觉线索被遮挡时容易出现误分类。通过引入通过自定义损失函数学习的类别特定噪声，可以增强模型对类别定义特征的关注，从而提高分类准确性和模型置信度，并减少偏差。未来的工作需要解决在临床领域应用此类模型的挑战，并提高其在独立于域的医疗场景中的泛化能力。

Abstract: Human action recognition plays a critical role in healthcare and medicine,
supporting applications such as patient behavior monitoring, fall detection,
surgical robot supervision, and procedural skill assessment. While traditional
models like CNNs and RNNs have achieved moderate success, they often struggle
to generalize across diverse and complex actions. Recent advancements in
vision-language models, especially the transformer-based CLIP model, offer
promising capabilities for generalizing action recognition from video data. In
this work, we evaluate CLIP on the UCF-101 dataset and systematically analyze
its performance under three masking strategies: (1) percentage-based and
shape-based black masking at 10%, 30%, and 50%, (2) feature-specific masking to
suppress bias-inducing elements, and (3) isolation masking that retains only
class-specific regions. Our results reveal that CLIP exhibits inconsistent
behavior and frequent misclassifications, particularly when essential visual
cues are obscured. To overcome these limitations, we propose incorporating
class-specific noise, learned via a custom loss function, to reinforce
attention to class-defining features. This enhancement improves classification
accuracy and model confidence while reducing bias. We conclude with a
discussion on the challenges of applying such models in clinical domains and
outline directions for future work to improve generalizability across
domain-independent healthcare scenarios.

</details>


### [13] [HeartUnloadNet: A Weakly-Supervised Cycle-Consistent Graph Network for Predicting Unloaded Cardiac Geometry from Diastolic States](https://arxiv.org/abs/2507.18677)
*Siyu Mu,Wei Xuan Chan,Choon Hwai Yap*

Main category: cs.CV

TL;DR: HeartUnloadNet通过深度学习和循环一致性策略，实现了快速、高精度的左心室无负荷几何形状预测，克服了传统方法的局限性，有望应用于临床。


<details>
  <summary>Details</summary>
Motivation: 估计心脏的无负荷几何形状对于个性化生物力学建模至关重要，有助于理解健康和疾病的生理状况，并预测心脏介入治疗的效果。然而，从临床图像估计无负荷几何形状仍然是一个挑战，传统方法依赖于计算成本高昂的逆有限元（FE）求解器。

Method: 提出了一种名为HeartUnloadNet的深度学习框架，该框架直接从舒张末期（ED）模型预测无负荷左心室（LV）形状，并显式地融入生物物理先验知识。该网络接受任意大小的模型以及生理参数（如ED压力、心肌僵硬度尺度和纤维螺旋角），并输出相应的无负荷模型。它采用了图注意力架构，并利用循环一致性策略实现双向（加载和卸载）预测，从而实现部分自监督，提高精度并减少对大型训练数据集的需求。

Result: HeartUnloadNet在20,700个有限元模拟上进行了训练和测试，在不同的左心室几何形状和生理条件下，实现了低于1毫米的精度，平均DSC为0.986，HD为0.083厘米。其推理时间仅为每例0.02秒，比传统逆有限元求解器快10万倍以上，且精度显著更高。模型在仅有200个训练样本的情况下仍能保持97%的DSC。

Conclusion: 该工作提出了HeartUnloadNet，一个能够直接从舒张末期（ED）模型预测左心室（LV）无负荷状态的模型。该模型结合了生物物理先验知识，并采用了图注意力架构和循环一致性策略，实现了双向预测，从而提高了预测精度并减少了对大型训练数据集的需求。与传统的逆有限元（FE）求解器相比，HeartUnloadNet在速度和精度上均有显著提升，有望支持未来的实时临床应用。

Abstract: The unloaded cardiac geometry (i.e., the state of the heart devoid of luminal
pressure) serves as a valuable zero-stress and zero-strain reference and is
critical for personalized biomechanical modeling of cardiac function, to
understand both healthy and diseased physiology and to predict the effects of
cardiac interventions. However, estimating the unloaded geometry from clinical
images remains a challenging task. Traditional approaches rely on inverse
finite element (FE) solvers that require iterative optimization and are
computationally expensive. In this work, we introduce HeartUnloadNet, a deep
learning framework that predicts the unloaded left ventricular (LV) shape
directly from the end diastolic (ED) mesh while explicitly incorporating
biophysical priors. The network accepts a mesh of arbitrary size along with
physiological parameters such as ED pressure, myocardial stiffness scale, and
fiber helix orientation, and outputs the corresponding unloaded mesh. It adopts
a graph attention architecture and employs a cycle-consistency strategy to
enable bidirectional (loading and unloading) prediction, allowing for partial
self-supervision that improves accuracy and reduces the need for large training
datasets. Trained and tested on 20,700 FE simulations across diverse LV
geometries and physiological conditions, HeartUnloadNet achieves sub-millimeter
accuracy, with an average DSC of 0.986 and HD of 0.083 cm, while reducing
inference time to just 0.02 seconds per case, over 10^5 times faster and
significantly more accurate than traditional inverse FE solvers. Ablation
studies confirm the effectiveness of the architecture. Notably, the
cycle-consistent design enables the model to maintain a DSC of 97% even with as
few as 200 training samples. This work thus presents a scalable and accurate
surrogate for inverse FE solvers, supporting real-time clinical applications in
the future.

</details>


### [14] [Towards Scalable Spatial Intelligence via 2D-to-3D Data Lifting](https://arxiv.org/abs/2507.18678)
*Xingyu Miao,Haoran Duan,Quanhao Qian,Jiuniu Wang,Yang Long,Ling Shao,Deli Zhao,Ran Xu,Gongjie Zhang*

Main category: cs.CV

TL;DR: 通过将单视角图像转换为3D表示来解决AI空间智能的数据集稀缺问题，并发布了两个新的数据集。


<details>
  <summary>Details</summary>
Motivation: AI领域空间智能的发展受到大型3D数据集稀缺的限制。与丰富的2D图像不同，3D数据的获取通常需要专门的传感器和耗时的标注。本研究旨在弥合海量图像库与日益增长的空间场景理解需求之间的差距。

Method: 提出了一种可扩展的管线，通过集成的深度估计、相机校准和尺度校准，将单视角图像转换为包括点云、相机姿态、深度图和伪RGBD在内的全面的、具有尺度和外观真实感的3D表示。

Result: 发布了两个生成的空间数据集COCO-3D和Objects365-v2-3D，并通过大量实验证明，生成的数据能够受益于各种3D任务，涵盖从基础感知到基于MLLM的推理的范围。

Conclusion: 该方法通过生成真实的、具有尺度感知的3D数据，大大降低了数据收集成本，并为推进空间智能开辟了新途径。所发布的数据集COCO-3D和Objects365-v2-3D，以及广泛的实验证明了该方法在从基础感知到基于MLLM的推理的各种3D任务中的有效性，验证了该管线作为开发能够感知、理解和与物理环境交互的AI系统的有效解决方案。

Abstract: Spatial intelligence is emerging as a transformative frontier in AI, yet it
remains constrained by the scarcity of large-scale 3D datasets. Unlike the
abundant 2D imagery, acquiring 3D data typically requires specialized sensors
and laborious annotation. In this work, we present a scalable pipeline that
converts single-view images into comprehensive, scale- and appearance-realistic
3D representations - including point clouds, camera poses, depth maps, and
pseudo-RGBD - via integrated depth estimation, camera calibration, and scale
calibration. Our method bridges the gap between the vast repository of imagery
and the increasing demand for spatial scene understanding. By automatically
generating authentic, scale-aware 3D data from images, we significantly reduce
data collection costs and open new avenues for advancing spatial intelligence.
We release two generated spatial datasets, i.e., COCO-3D and Objects365-v2-3D,
and demonstrate through extensive experiments that our generated data can
benefit various 3D tasks, ranging from fundamental perception to MLLM-based
reasoning. These results validate our pipeline as an effective solution for
developing AI systems capable of perceiving, understanding, and interacting
with physical environments.

</details>


### [15] [SaLF: Sparse Local Fields for Multi-Sensor Rendering in Real-Time](https://arxiv.org/abs/2507.18713)
*Yun Chen,Matthew Haines,Jingkang Wang,Krzysztof Baron-Lis,Sivabalan Manivasagam,Ze Yang,Raquel Urtasun*

Main category: cs.CV

TL;DR: SaLF是一种新的体积表示方法，通过稀疏的3D体素和局部隐式场，实现了快速训练和渲染，支持多种传感器，解决了现有NeRF和3DGS方法的局限性，为自动驾驶评估提供了更具可扩展性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有基于NeRF和3DGS的方法在训练和渲染速度方面存在不足，并且在传感器类型方面存在限制，阻碍了大规模的现实多传感器评估。

Method: SaLF是一种新颖的体积表示，它将体积表示为稀疏的3D体素原语集，其中每个体素都是一个局部隐式场，支持光栅化和光线追踪。

Result: SaLF的训练速度快（<30分钟），渲染速度快（相机50+ FPS，LiDAR 600+ FPS），具有自适应剪枝和稠密化功能，可以轻松处理大型场景，并支持非针孔相机和旋转LiDAR。

Conclusion: SaLF在提高效率和增强功能的同时，具有与现有自动驾驶传感器模拟方法相似的真实感，从而能够进行更具可扩展性的模拟。

Abstract: High-fidelity sensor simulation of light-based sensors such as cameras and
LiDARs is critical for safe and accurate autonomy testing. Neural radiance
field (NeRF)-based methods that reconstruct sensor observations via ray-casting
of implicit representations have demonstrated accurate simulation of driving
scenes, but are slow to train and render, hampering scale. 3D Gaussian
Splatting (3DGS) has demonstrated faster training and rendering times through
rasterization, but is primarily restricted to pinhole camera sensors,
preventing usage for realistic multi-sensor autonomy evaluation. Moreover, both
NeRF and 3DGS couple the representation with the rendering procedure (implicit
networks for ray-based evaluation, particles for rasterization), preventing
interoperability, which is key for general usage. In this work, we present
Sparse Local Fields (SaLF), a novel volumetric representation that supports
rasterization and raytracing. SaLF represents volumes as a sparse set of 3D
voxel primitives, where each voxel is a local implicit field. SaLF has fast
training (<30 min) and rendering capabilities (50+ FPS for camera and 600+ FPS
LiDAR), has adaptive pruning and densification to easily handle large scenes,
and can support non-pinhole cameras and spinning LiDARs. We demonstrate that
SaLF has similar realism as existing self-driving sensor simulation methods
while improving efficiency and enhancing capabilities, enabling more scalable
simulation. https://waabi.ai/salf/

</details>


### [16] [KuiSCIMA v2.0: Improved Baselines, Calibration, and Cross-Notation Generalization for Historical Chinese Music Notations in Jiang Kui's Baishidaoren Gequ](https://arxiv.org/abs/2507.18741)
*Tristan Repolusk,Eduardo Veas*

Main category: cs.CV

TL;DR: 本研究改进了历史中文音乐符号（suzipu, lǜlǜpǔ）的光学识别，降低了字符错误率，优于人类转录，并扩展了相关数据集，以促进中国古代音乐的数字化和可及性。


<details>
  <summary>Details</summary>
Motivation: 历史中文音乐符号（如suzipu和lǜlǜpǔ）的光学音乐识别（OMR）面临高类别不平衡和有限训练数据的独特挑战。本研究旨在改进OMR技术，以应对这些挑战，并特别关注处理1202年的“白石道人歌曲集”。

Method: 本研究开发并评估了一个字符识别模型，以应对稀疏和不平衡的历史中文音乐符号数据。研究中采用了温度标量（temperature scaling）技术来校准模型，并使用留出一版交叉验证（leave-one-edition-out cross-validation）的方法来评估模型在不同历史版本间的表现。此外，研究还扩展了KuiSCIMA数据集，增加了“白石道人歌曲集”中的suzipu、lǜlǜpǔ和jiànzìpǔ符号。

Result: 研究将suzipu的字符错误率（CER）从10.4%降低到7.1%，lǜlǜpǔ的CER降低到0.9%，优于人类转录的平均15.9%CER。模型经过温度标量校准后，ECE低于0.0162。留出一版交叉验证结果显示模型具有鲁棒性。KuiSCIMA数据集已扩展至包含“白石道人歌曲集”的全部109首乐曲，涵盖三种记谱法。

Conclusion: 本研究通过改进字符识别模型，在处理历史中文音乐符号（如suzipu和lǜlǜpǔ）方面取得了显著进展，特别是在数据稀疏和类别不平衡的挑战下，将suzipu的字符错误率（CER）从10.4%降低到7.1%，lǜlǜpǔ的CER降低到0.9%，并且优于人类转录的平均15.9%的CER。模型经过温度标量校准，ECE低于0.0162，并通过留出一版交叉验证确保了在五个历史版本上的鲁棒性。研究还扩展了KuiSCIMA数据集，包含了“白石道人歌曲集”的全部109首乐曲，涵盖了suzipu、lǜlǜpǔ和jiànzìpǔ符号。这些成果促进了中国古代音乐的数字化和可及性。

Abstract: Optical Music Recognition (OMR) for historical Chinese musical notations,
such as suzipu and l\"ul\"upu, presents unique challenges due to high class
imbalance and limited training data. This paper introduces significant
advancements in OMR for Jiang Kui's influential collection Baishidaoren Gequ
from 1202. In this work, we develop and evaluate a character recognition model
for scarce imbalanced data. We improve upon previous baselines by reducing the
Character Error Rate (CER) from 10.4% to 7.1% for suzipu, despite working with
77 highly imbalanced classes, and achieve a remarkable CER of 0.9% for
l\"ul\"upu. Our models outperform human transcribers, with an average human CER
of 15.9% and a best-case CER of 7.6%. We employ temperature scaling to achieve
a well-calibrated model with an Expected Calibration Error (ECE) below 0.0162.
Using a leave-one-edition-out cross-validation approach, we ensure robust
performance across five historical editions. Additionally, we extend the
KuiSCIMA dataset to include all 109 pieces from Baishidaoren Gequ, encompassing
suzipu, l\"ul\"upu, and jianzipu notations. Our findings advance the
digitization and accessibility of historical Chinese music, promoting cultural
diversity in OMR and expanding its applicability to underrepresented music
traditions.

</details>


### [17] [Diffusion-FS: Multimodal Free-Space Prediction via Diffusion for Autonomous Driving](https://arxiv.org/abs/2507.18763)
*Keshav Gupta,Tejas S. Stanley,Pranjal Paul,Arun K. Singh,K. Madhava Krishna*

Main category: cs.CV

TL;DR: This paper proposes ContourDiff, a self-supervised, image-based method using monocular camera input to predict drivable free-space corridors, overcoming limitations of previous BEV-centric and mask-based approaches by utilizing contour point denoising and ego trajectory data.


<details>
  <summary>Details</summary>
Motivation: Existing drivable free-space corridor estimation methods assume a BEV-centric representation, which is hard to obtain. This work aims to estimate driving corridors using only monocular camera input, framing it as a pure image perception task.

Method: A novel self-supervised approach for free-space sample generation is developed by leveraging future ego trajectories and front-view camera images. A diffusion process is employed to model the distribution of free-space segments in the image. ContourDiff, a specialized diffusion-based architecture, denoises over contour points instead of relying on binary mask representations.

Result: The approach accurately predicts safe multimodal navigable corridors in the image, demonstrated qualitatively and quantitatively on nuScenes and CARLA datasets.

Conclusion: ContourDiff is effective in accurately predicting safe multimodal navigable corridors in the image, outperforming existing methods on both nuScenes and CARLA datasets.

Abstract: Drivable Free-space prediction is a fundamental and crucial problem in
autonomous driving. Recent works have addressed the problem by representing the
entire non-obstacle road regions as the free-space. In contrast our aim is to
estimate the driving corridors that are a navigable subset of the entire road
region. Unfortunately, existing corridor estimation methods directly assume a
BEV-centric representation, which is hard to obtain. In contrast, we frame
drivable free-space corridor prediction as a pure image perception task, using
only monocular camera input. However such a formulation poses several
challenges as one doesn't have the corresponding data for such free-space
corridor segments in the image. Consequently, we develop a novel
self-supervised approach for free-space sample generation by leveraging future
ego trajectories and front-view camera images, making the process of visual
corridor estimation dependent on the ego trajectory. We then employ a diffusion
process to model the distribution of such segments in the image. However, the
existing binary mask-based representation for a segment poses many limitations.
Therefore, we introduce ContourDiff, a specialized diffusion-based architecture
that denoises over contour points rather than relying on binary mask
representations, enabling structured and interpretable free-space predictions.
We evaluate our approach qualitatively and quantitatively on both nuScenes and
CARLA, demonstrating its effectiveness in accurately predicting safe multimodal
navigable corridors in the image.

</details>


### [18] [SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning](https://arxiv.org/abs/2507.18743)
*Xinjun Cheng,Yiguo He,Junjie Zhu,Chunping Qiu,Jun Wang,Qiangjuan Huang,Ke Yang*

Main category: cs.CV

TL;DR: 本研究构建了SAR-Text数据集和SAR-Narrator框架，提升了SAR图像的视觉-语言理解能力，并在检索、字幕生成和VQA任务上取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 遥感领域中，合成孔径雷达（SAR）图像因其全天候能力至关重要，但缺乏大规模、高质量的SAR图像-文本数据集阻碍了其语义理解。因此，本研究旨在构建SAR-Text数据集并提出SAR-Narrator框架，以解决这一问题并推动SAR图像的视觉-语言研究。

Method: 本研究构建了一个名为SAR-Text的大规模SAR图像-文本数据集，包含超过13万个图像-文本对。通过设计SAR-Narrator框架，利用多阶段渐进式迁移学习策略为SAR图像生成文本描述。在三个典型的视觉-语言任务（图像-文本检索、图像字幕生成、视觉问答）上进行了实验验证，并构建了SAR-RS-CLIP、SAR-RS-CoCa和SAR-GPT三个代表性模型。

Result: SAR-RS-CLIP在检索任务上显著提升了性能，在OSdataset-512和HRSID测试集上的平均召回率分别提高了16.43%和10.54%。SAR-RS-CoCa在字幕生成任务上，BLEU-4、SPICE和CIDEr分数分别超过了原始CoCa模型8倍、4倍和10倍以上。SAR-GPT在VQA任务上，表现优于基线和单阶段模型，展现了更强的语义理解和推理能力。

Conclusion: 该研究构建了一个大规模、高质量的SAR图像-文本数据集SAR-Text，并提出了SAR-Narrator框架用于生成SAR图像的文本描述。实验证明，SAR-Text数据集能够有效提升视觉-语言模型在遥感领域的语义理解能力，在图像-文本检索、图像字幕生成和视觉问答任务上均取得了显著的性能提升。SAR-Narrator框架的灵活性也使其能够被社区广泛应用于构建更大规模的SAR图像-文本数据集。

Abstract: Vision Language Models (VLMs) have achieved remarkable breakthroughs in the
field of remote sensing in recent years. Synthetic Aperture Radar (SAR)
imagery, with its all-weather capability, is essential in remote sensing, yet
the lack of large-scale, high-quality SAR image-text datasets hinders its
semantic understanding. In this paper, we construct SAR-Text, a large-scale and
high-quality dataset consisting of over 130,000 SAR image-text pairs. To
construct the SAR-Text dataset, we design the SAR-Narrator framework, which
generates textual descriptions for SAR images through a multi-stage progressive
transfer learning strategy. To verify the effectiveness of the SAR-TEXT
dataset, we conduct experiments on three typical vision-language tasks:
image-text retrieval, image captioning, and visual question answering (VQA).
Specifically, we construct three representative models on SAR-TEXT:
SAR-RS-CLIP, SAR-RS-CoCa, and SAR-GPT. SAR-RS-CLIP achieves notable
improvements in retrieval performance, boosting average recall by 16.43% and
10.54% on the OSdataset-512 and HRSID test sets, respectively. In the
captioning task, SAR-RS-CoCa achieves BLEU-4, SPICE, and CIDEr scores exceeding
those of the original CoCa model by more than 8x, 4x, and 10x, respectively. In
the VQA task, SAR-GPT outperforms baseline and single-stage models on multiple
SAR-VQA datasets, demonstrating stronger semantic understanding and reasoning
ability, as further confirmed by qualitative results. It is worth noting that,
as a flexible captioning tool, SAR-Narrator can be readily adopted by the
community to construct larger-scale SAR image-text datasets.

</details>


### [19] [Perspective from a Higher Dimension: Can 3D Geometric Priors Help Visual Floorplan Localization?](https://arxiv.org/abs/2507.18881)
*Bolei Chen,Jiaxu Kang,Haonan Yang,Ping Zhong,Jianxin Wang*

Main category: cs.CV

TL;DR: 该研究提出了一种新的3D几何先验方法，用于解决2D楼层平面定位中的挑战，并通过自监督学习提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有2D楼层平面定位方法未能有效解决由视觉变化和视图遮挡引起的定位误差，而该文旨在通过引入3D几何先验来克服这些挑战。

Method: 通过自监督对比学习，利用多视图约束来建模几何感知视图不变性，并结合场景的表面重建和RGB帧来建模视图-场景对齐的几何先验。

Result: 所提出的3D先验方法在真实的场景中能够有效弥合模态差异，并提升定位精度，同时不会增加额外的计算负担，实验结果表明该方法显著优于最先进的方法。

Conclusion: 该方法通过注入3D几何先验来解决2D楼层平面定位（FLoc）中的视觉变化和视图遮挡问题，通过多视图约束和视图-场景对齐的几何先验来实现，并使用自监督对比学习进行模型训练，无需额外标注。实验证明该方法在FLoc准确性上显著优于现有技术。

Abstract: Since a building's floorplans are easily accessible, consistent over time,
and inherently robust to changes in visual appearance, self-localization within
the floorplan has attracted researchers' interest. However, since floorplans
are minimalist representations of a building's structure, modal and geometric
differences between visual perceptions and floorplans pose challenges to this
task. While existing methods cleverly utilize 2D geometric features and pose
filters to achieve promising performance, they fail to address the localization
errors caused by frequent visual changes and view occlusions due to variously
shaped 3D objects. To tackle these issues, this paper views the 2D Floorplan
Localization (FLoc) problem from a higher dimension by injecting 3D geometric
priors into the visual FLoc algorithm. For the 3D geometric prior modeling, we
first model geometrically aware view invariance using multi-view constraints,
i.e., leveraging imaging geometric principles to provide matching constraints
between multiple images that see the same points. Then, we further model the
view-scene aligned geometric priors, enhancing the cross-modal geometry-color
correspondences by associating the scene's surface reconstruction with the RGB
frames of the sequence. Both 3D priors are modeled through self-supervised
contrastive learning, thus no additional geometric or semantic annotations are
required. These 3D priors summarized in extensive realistic scenes bridge the
modal gap while improving localization success without increasing the
computational burden on the FLoc algorithm. Sufficient comparative studies
demonstrate that our method significantly outperforms state-of-the-art methods
and substantially boosts the FLoc accuracy. All data and code will be released
after the anonymous review.

</details>


### [20] [Learning Efficient and Generalizable Human Representation with Human Gaussian Model](https://arxiv.org/abs/2507.18758)
*Yifan Liu,Shengjun Zhang,Chensheng Dai,Yang Chen,Hao Liu,Chen Li,Yueqi Duan*

Main category: cs.CV

TL;DR: 提出了一种新的人类高斯图模型，通过连接高斯和SMPL网格，并引入节点内和节点间操作，来捕捉帧间关系，从而实现高效且可泛化的可动画人类表示，解决了现有方法独立处理帧的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法独立预测每一帧的高斯而未能充分捕捉不同时间戳高斯之间关系的问题。

Method: 提出了一种名为“人类高斯图”的模型，该模型包含两个层：第一层是高斯节点，第二层是SMPL网格顶点。通过设计节点内操作来聚合连接到同一网格顶点的多个高斯，以及节点间操作来支持网格节点邻居之间的消息传递。

Result: 通过人类高斯图模型连接预测的高斯和人类SMPL网格，可以利用所有帧的信息来恢复可动画的人类表示。

Conclusion: 实验结果表明，该方法在新的视角合成和新的姿态动画方面具有效率和泛化能力。

Abstract: Modeling animatable human avatars from videos is a long-standing and
challenging problem. While conventional methods require per-instance
optimization, recent feed-forward methods have been proposed to generate 3D
Gaussians with a learnable network. However, these methods predict Gaussians
for each frame independently, without fully capturing the relations of
Gaussians from different timestamps. To address this, we propose Human Gaussian
Graph to model the connection between predicted Gaussians and human SMPL mesh,
so that we can leverage information from all frames to recover an animatable
human representation. Specifically, the Human Gaussian Graph contains dual
layers where Gaussians are the first layer nodes and mesh vertices serve as the
second layer nodes. Based on this structure, we further propose the intra-node
operation to aggregate various Gaussians connected to one mesh vertex, and
inter-node operation to support message passing among mesh node neighbors.
Experimental results on novel view synthesis and novel pose animation
demonstrate the efficiency and generalization of our method.

</details>


### [21] [Tell Me What You See: An Iterative Deep Learning Framework for Image Captioning](https://arxiv.org/abs/2507.18788)
*Hitesh Kumar Gupta*

Main category: cs.CV

TL;DR: 本研究通过从CNN-LSTM到具有EfficientNetV2B3骨干和动态注意力的Nexus模型的迭代开发，展示了图像字幕模型的发展。发现仅升级骨干网络而无注意力机制会损害性能。Nexus模型在MS COCO 2017上达到了31.4的BLEU-4分数，为理解视觉-语言任务提供了可复现的蓝图。


<details>
  <summary>Details</summary>
Motivation: 图像字幕技术结合了计算机视觉和自然语言处理，需要对视觉场景和语言结构有深刻的理解。尽管当前主流方法采用大型Transformer架构，但本研究旨在记录和探索基础图像字幕模型的发展过程，并揭示其中关键的架构原则。

Method: 本文详细介绍了一个系统性的、迭代式的基础图像字幕模型开发过程，从简单的CNN-LSTM编码器-解码器模型开始，逐步发展到一个具有竞争力的基于注意力的系统。共开发了五个模型，从Genesis到Nexus，Nexus采用了EfficientNetV2B3骨干网络和动态注意力机制。

Result: 最终模型Nexus在MS COCO 2017数据集上达到了31.4的BLEU-4分数，优于几个基础基准。实验结果表明，仅升级视觉骨干网络而没有注意力机制会因单一向量瓶颈无法传递丰富视觉细节而导致性能下降，验证了注意力机制的重要性。

Conclusion: 本研究通过一系列实验，验证了在CNN-LSTM范式中，仅升级视觉骨干网络而不配备相应的注意力机制会降低性能，因为单一向量瓶颈无法传递更丰富的视觉细节。这一发现证实了向注意力机制的架构转变的合理性。在MS COCO 2017数据集上训练的最终模型Nexus，BLEU-4得分达到31.4，超过了几个基础基准，验证了迭代设计过程的有效性。该研究为理解视觉-语言任务的核心架构原则提供了清晰、可复现的蓝图。

Abstract: Image captioning, a task at the confluence of computer vision and natural
language processing, requires a sophisticated understanding of both visual
scenes and linguistic structure. While modern approaches are dominated by
large-scale Transformer architectures, this paper documents a systematic,
iterative development of foundational image captioning models, progressing from
a simple CNN-LSTM encoder-decoder to a competitive attention-based system. We
present a series of five models, beginning with Genesis and concluding with
Nexus, an advanced model featuring an EfficientNetV2B3 backbone and a dynamic
attention mechanism. Our experiments chart the impact of architectural
enhancements and demonstrate a key finding within the classic CNN-LSTM
paradigm: merely upgrading the visual backbone without a corresponding
attention mechanism can degrade performance, as the single-vector bottleneck
cannot transmit the richer visual detail. This insight validates the
architectural shift to attention. Trained on the MS COCO 2017 dataset, our
final model, Nexus, achieves a BLEU-4 score of 31.4, surpassing several
foundational benchmarks and validating our iterative design process. This work
provides a clear, replicable blueprint for understanding the core architectural
principles that underpin modern vision-language tasks.

</details>


### [22] [Deepfake Detection Via Facial Feature Extraction and Modeling](https://arxiv.org/abs/2507.18815)
*Benjamin Carter,Nathan Dilla,Micheal Callahan,Atuhaire Ambala*

Main category: cs.CV

TL;DR: 该研究提出了一种创新的面部地标提取方法，用于检测深度伪造视频，无需复杂的图像处理，并在多种神经网络模型上取得了高准确率，显示出实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造技术的兴起，区分人工智能生成的视频和真实视频变得越来越困难，因此需要新的模型来检测。

Method: 该方法专注于提取面部地标，以识别面部运动中不明显的差异，而不是进行原始图像处理。

Result: 实验结果表明，该面部地标提取技术在各种神经网络模型上都有效，在RNN和ANN模型上分别达到了96%和93%的准确率，CNN模型的准确率约为78%。

Conclusion: 该研究提出了一种仅使用面部地标进行深度伪造检测的方法，挑战了必须处理原始图像才能识别深度伪造视频的假设，并提出了一种适用于各种神经网络模型且所需参数更少的人脸特征提取方法。

Abstract: The rise of deepfake technology brings forth new questions about the
authenticity of various forms of media found online today. Videos and images
generated by artificial intelligence (AI) have become increasingly more
difficult to differentiate from genuine media, resulting in the need for new
models to detect artificially-generated media. While many models have attempted
to solve this, most focus on direct image processing, adapting a convolutional
neural network (CNN) or a recurrent neural network (RNN) that directly
interacts with the video image data. This paper introduces an approach of using
solely facial landmarks for deepfake detection. Using a dataset consisting of
both deepfake and genuine videos of human faces, this paper describes an
approach for extracting facial landmarks for deepfake detection, focusing on
identifying subtle inconsistencies in facial movements instead of raw image
processing. Experimental results demonstrated that this feature extraction
technique is effective in various neural network models, with the same facial
landmarks tested on three neural network models, with promising performance
metrics indicating its potential for real-world applications. The findings
discussed in this paper include RNN and artificial neural network (ANN) models
with accuracy between 96% and 93%, respectively, with a CNN model hovering
around 78%. This research challenges the assumption that raw image processing
is necessary to identify deepfake videos by presenting a facial feature
extraction approach compatible with various neural network models while
requiring fewer parameters.

</details>


### [23] [EffiComm: Bandwidth Efficient Multi Agent Communication](https://arxiv.org/abs/2507.19354)
*Melih Yazgan,Allen Xavier Arasan,J. Marius Zöllner*

Main category: cs.CV

TL;DR: EffiComm通过ST和AGR技术，以少于40%的数据量实现高精度3D物体检测，解决了V2V通信的瓶颈，使可扩展的车联网感知成为可能。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统车车通信（V2V）传输原始点云或完整特征图带来的延迟和可扩展性问题，需要一种更高效的通信方式来实现协同感知。

Method: EffiComm框架采用两阶段数据削減管线：(1) 选择性传输（ST）通过置信度掩码修剪低效用区域；(2) 自适应网格缩减（AGR）使用图神经网络（GNN）根据车辆角色和网络负载分配特定保留比率。剩余特征通过软门控专家混合（MoE）注意力层进行融合。

Result: 在OPV2V基准测试中，EffiComm在发送约1.5 MB/帧数据的同时，达到了0.84 mAP@0.7的性能，在精度-比特率曲线上优于先前方法。

Conclusion: EffiComm框架通过选择性传输和自适应网格缩减技术，显著减少了V2V通信的数据量，同时保持了最先进的3D物体检测精度，实现了高效可扩展的车联网感知。

Abstract: Collaborative perception allows connected vehicles to exchange sensor
information and overcome each vehicle's blind spots. Yet transmitting raw point
clouds or full feature maps overwhelms Vehicle-to-Vehicle (V2V) communications,
causing latency and scalability problems. We introduce EffiComm, an end-to-end
framework that transmits less than 40% of the data required by prior art while
maintaining state-of-the-art 3D object detection accuracy. EffiComm operates on
Bird's-Eye-View (BEV) feature maps from any modality and applies a two-stage
reduction pipeline: (1) Selective Transmission (ST) prunes low-utility regions
with a confidence mask; (2) Adaptive Grid Reduction (AGR) uses a Graph Neural
Network (GNN) to assign vehicle-specific keep ratios according to role and
network load. The remaining features are fused with a soft-gated
Mixture-of-Experts (MoE) attention layer, offering greater capacity and
specialization for effective feature integration. On the OPV2V benchmark,
EffiComm reaches 0.84 mAP@0.7 while sending only an average of approximately
1.5 MB per frame, outperforming previous methods on the accuracy-per-bit curve.
These results highlight the value of adaptive, learned communication for
scalable Vehicle-to-Everything (V2X) perception.

</details>


### [24] [Fast Learning of Non-Cooperative Spacecraft 3D Models through Primitive Initialization](https://arxiv.org/abs/2507.19459)
*Pol Francesch Huc,Emily Bates,Simone D'Amico*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的方法，使用 CNN 从单张图像初始化 3DGS 模型，解决了现有技术需要精确位姿和计算量大的问题，大大降低了训练成本，并能在位姿信息不准确时生成高质量 3D 模型，有望应用于太空任务。


<details>
  <summary>Details</summary>
Motivation: 现有如 NeRF 和 3DGS 等新视角合成技术虽然能从单目图像学习精确的 3D 模型，但它们在训练中需要精确的相机位姿，并且计算成本高昂，这限制了它们在太空等资源受限环境中的应用。因此，需要开发一种新的方法来克服这些限制。

Method: 本研究提出了一种新颖的 pipeline，包含一个基于 CNN 的原始模型初始化器，能够从单目图像生成粗略的 3D 模型和相机位姿。该初始化器可以显著减少 3DGS 的训练迭代次数和所需输入图像数量（至少一个数量级）。此外，研究还包含了对不同初始化变体的分析，并评估了它们在位姿估计不准确或隐式情况下的有效性。

Result: 研究结果表明，即使在位姿监督不准确的情况下，该 pipeline 也能学习到高保真度的 3D 表示。CNN 初始化器将训练迭代次数和所需输入图像数量减少了至少一个数量级。

Conclusion: 该研究提出了一种基于卷积神经网络 (CNN) 的 3D 高斯泼溅 (3DGS) 原始模型初始化方法，解决了现有新视角合成技术在训练中需要精确位姿和计算成本高昂的问题，从而为在太空应用中利用新视角合成打开了大门。

Abstract: The advent of novel view synthesis techniques such as NeRF and 3D Gaussian
Splatting (3DGS) has enabled learning precise 3D models only from posed
monocular images. Although these methods are attractive, they hold two major
limitations that prevent their use in space applications: they require poses
during training, and have high computational cost at training and inference. To
address these limitations, this work contributes: (1) a Convolutional Neural
Network (CNN) based primitive initializer for 3DGS using monocular images; (2)
a pipeline capable of training with noisy or implicit pose estimates; and (3)
and analysis of initialization variants that reduce the training cost of
precise 3D models. A CNN takes a single image as input and outputs a coarse 3D
model represented as an assembly of primitives, along with the target's pose
relative to the camera. This assembly of primitives is then used to initialize
3DGS, significantly reducing the number of training iterations and input images
needed -- by at least an order of magnitude. For additional flexibility, the
CNN component has multiple variants with different pose estimation techniques.
This work performs a comparison between these variants, evaluating their
effectiveness for downstream 3DGS training under noisy or implicit pose
estimates. The results demonstrate that even with imperfect pose supervision,
the pipeline is able to learn high-fidelity 3D representations, opening the
door for the use of novel view synthesis in space applications.

</details>


### [25] [Flow Stochastic Segmentation Networks](https://arxiv.org/abs/2507.18838)
*Fabio De Sousa Ribeiro,Omar Todd,Charles Jones,Avinash Kori,Raghav Mehta,Ben Glocker*

Main category: cs.CV

TL;DR: Flow-SSN是一种新的生成式分割模型，它在医学影像分析方面比现有方法更有效率且性能更好。


<details>
  <summary>Details</summary>
Motivation: 为了解决先前方法低秩参数化的根本限制，并实现无需假设秩或存储分布参数即可估计任意高秩像素级协方差。

Method: 提出了一种名为Flow Stochastic Segmentation Network (Flow-SSN)的生成式分割模型系列，包含离散时间和连续时间流变体。

Result: Flow-SSNs能够估计任意高秩像素级协方差，并且比标准的基于扩散的分割模型更高效，从而在具有挑战性的医学影像基准测试中取得了最先进的结果。

Conclusion: Flow-SSNs在医学影像分析方面取得了最先进的成果。

Abstract: We introduce the Flow Stochastic Segmentation Network (Flow-SSN), a
generative segmentation model family featuring discrete-time autoregressive and
modern continuous-time flow variants. We prove fundamental limitations of the
low-rank parameterisation of previous methods and show that Flow-SSNs can
estimate arbitrarily high-rank pixel-wise covariances without assuming the rank
or storing the distributional parameters. Flow-SSNs are also more efficient to
sample from than standard diffusion-based segmentation models, thanks to most
of the model capacity being allocated to learning the base distribution of the
flow, constituting an expressive prior. We apply Flow-SSNs to challenging
medical imaging benchmarks and achieve state-of-the-art results. Code
available: https://github.com/biomedia-mira/flow-ssn.

</details>


### [26] [Efficient Lines Detection for Robot Soccer](https://arxiv.org/abs/2507.19469)
*João G. Melo,João P. Mafaldo,Edna Barros*

Main category: cs.CV

TL;DR: 一种用于机器人足球的轻量级、高效的场线检测方法，使用ELSED算法和PSO校准，速度快，精度高。


<details>
  <summary>Details</summary>
Motivation: 机器人足球中的自我定位需要准确检测视觉场特征（如线和边界）以进行可靠的姿态估计。

Method: 提出了一种使用ELSED算法结合RGB颜色转换分类步骤来检测足球场线的轻量级高效方法，并采用基于粒子群优化（PSO）的阈值校准流水线来优化检测性能。

Result: 与最先进的深度学习模型相比，该方法在处理速度方面具有优势，并且只需要少量标注样本即可实现可比的准确性。

Conclusion: 该方法在低功耗机器人平台上实现了与最先进的深度学习模型相当的精度和更高的处理速度，非常适合实时应用。

Abstract: Self-localization is essential in robot soccer, where accurate detection of
visual field features, such as lines and boundaries, is critical for reliable
pose estimation. This paper presents a lightweight and efficient method for
detecting soccer field lines using the ELSED algorithm, extended with a
classification step that analyzes RGB color transitions to identify lines
belonging to the field. We introduce a pipeline based on Particle Swarm
Optimization (PSO) for threshold calibration to optimize detection performance,
requiring only a small number of annotated samples. Our approach achieves
accuracy comparable to a state-of-the-art deep learning model while offering
higher processing speed, making it well-suited for real-time applications on
low-power robotic platforms.

</details>


### [27] [PTCMIL: Multiple Instance Learning via Prompt Token Clustering for Whole Slide Image Analysis](https://arxiv.org/abs/2507.18848)
*Beidi Zhao,SangMook Kim,Hao Chen,Chen Zhou,Zu-hua Gao,Gang Wang,Xiaoxiao Li*

Main category: cs.CV

TL;DR: PTCMIL是一种新的基于提示令牌聚类的ViT方法，用于解决MIL中的WSI分析挑战，其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的MIL方法在聚合多样化的块信息以形成鲁棒的WSI表示方面存在挑战。ViT和基于聚类的方法虽然有前景，但计算量大，并且无法捕捉特定任务和特定幻灯片的变异性。PTCMIL旨在解决这些限制。

Method: PTCMIL是一种新颖的基于提示令牌聚类的ViT方法，用于MIL聚合。它通过在ViT骨干网络中引入可学习的提示令牌，以端到端的方式统一了聚类和预测任务。通过动态对齐聚类与下游任务，并为每个WSI量身定制基于投影的聚类，PTCMIL在降低复杂性的同时保留了块异质性。通过令牌合并和基于原型的池化，PTCMIL能够有效地捕获任务相关的模式。

Result: PTCMIL在分类和生存分析任务中表现出优越的性能，超越了最先进的方法。消融研究证实了其鲁棒性和可解释性。

Conclusion: PTCMIL通过集成学习、提示令牌和基于投影的聚类，在分类和生存分析任务上超越了最先进的方法，并在八个数据集上得到了验证。

Abstract: Multiple Instance Learning (MIL) has advanced WSI analysis but struggles with
the complexity and heterogeneity of WSIs. Existing MIL methods face challenges
in aggregating diverse patch information into robust WSI representations. While
ViTs and clustering-based approaches show promise, they are computationally
intensive and fail to capture task-specific and slide-specific variability. To
address these limitations, we propose PTCMIL, a novel Prompt Token
Clustering-based ViT for MIL aggregation. By introducing learnable prompt
tokens into the ViT backbone, PTCMIL unifies clustering and prediction tasks in
an end-to-end manner. It dynamically aligns clustering with downstream tasks,
using projection-based clustering tailored to each WSI, reducing complexity
while preserving patch heterogeneity. Through token merging and prototype-based
pooling, PTCMIL efficiently captures task-relevant patterns. Extensive
experiments on eight datasets demonstrate its superior performance in
classification and survival analysis tasks, outperforming state-of-the-art
methods. Systematic ablation studies confirm its robustness and strong
interpretability. The code is released at https://github.com/ubc-tea/PTCMIL.

</details>


### [28] [Phoneme-Level Visual Speech Recognition via Point-Visual Fusion and Language Model Reconstruction](https://arxiv.org/abs/2507.18863)
*Matthew Kit Khinn Teng,Haibo Zhang,Takeshi Saitoh*

Main category: cs.CV

TL;DR: 该研究提出了一种新颖的视觉自动语音识别 (V-ASR) 方法，通过结合基于音素的预测和 LLM 进行单词重建，克服了现有方法的局限性，并在 LRS2 和 LRS3 数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常旨在直接从视觉线索中预测单词或字符，但由于粘膜模糊和发音不清，它们通常会出现高错误率，并且需要大量的预训练数据。

Method: 该方法包括两个阶段：第一阶段是 V-ASR，它输出预测的音素，从而降低了训练复杂性，同时面部标志点特征解决了说话者特定的面部特征。第二阶段由编码器-解码器 LLM 模型 NLLB 组成，该模型将输出的音素重建回单词。

Result: PV-ASR 方法通过在 LRS2 和 LRS3 数据集上分别实现 17.4% 的词错误率 (WER) 和 21.0% 的词错误率 (WER) 来展示其优越性能。

Conclusion: 提出了一种新颖的基于音素的两阶段框架，该框架融合了视觉和标志点运动特征，然后使用 LLM 模型进行单词重建，以应对这些挑战。

Abstract: Visual Automatic Speech Recognition (V-ASR) is a challenging task that
involves interpreting spoken language solely from visual information, such as
lip movements and facial expressions. This task is notably challenging due to
the absence of auditory cues and the visual ambiguity of phonemes that exhibit
similar visemes-distinct sounds that appear identical in lip motions. Existing
methods often aim to predict words or characters directly from visual cues, but
they commonly suffer from high error rates due to viseme ambiguity and require
large amounts of pre-training data. We propose a novel phoneme-based two-stage
framework that fuses visual and landmark motion features, followed by an LLM
model for word reconstruction to address these challenges. Stage 1 consists of
V-ASR, which outputs the predicted phonemes, thereby reducing training
complexity. Meanwhile, the facial landmark features address speaker-specific
facial characteristics. Stage 2 comprises an encoder-decoder LLM model, NLLB,
that reconstructs the output phonemes back to words. Besides using a large
visual dataset for deep learning fine-tuning, our PV-ASR method demonstrates
superior performance by achieving 17.4% WER on the LRS2 and 21.0% WER on the
LRS3 dataset.

</details>


### [29] [Transferable and Undefendable Point Cloud Attacks via Medial Axis Transform](https://arxiv.org/abs/2507.18870)
*Keke Tang,Yuze Gao,Weilong Peng,Xiaofei Wang,Meie Fang,Peican Zhu*

Main category: cs.CV

TL;DR: MAT-Adv 通过扰动点云的内涵式几何结构（MAT 表达）来提升对抗攻击的迁移性和不可防御性，相较于现有方法有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性攻击方法大多在理想的白盒设置下开发，这些方法在迁移到未见过的模型和抵抗常见的防御机制方面存在迁移性和鲁棒性不足的问题。

Method: 提出了一种名为 MAT-Adv 的新颖对抗攻击框架，该框架通过扰动点云的内涵式几何结构（即 MAT 表达）来增强迁移性和不可防御性。具体来说，利用自编码器将点云投影到捕捉其内涵式几何结构的压缩 MAT 表达，并通过扰动这些表达来引入跨模型和跨防御策略的结构级对抗性特征。为了缓解过拟合和防止扰动崩溃，在 MAT 扰动的优化中加入了一个 Dropout 策略。

Result: MAT-Adv 在迁移性和不可防御性方面显著优于现有的最先进方法。

Conclusion: MAT-Adv 通过扰动点云的内涵式几何结构（即 MAT 表达），来增强对抗性攻击的迁移性和不可防御性，并在实验中显著优于现有方法。

Abstract: Studying adversarial attacks on point clouds is essential for evaluating and
improving the robustness of 3D deep learning models. However, most existing
attack methods are developed under ideal white-box settings and often suffer
from limited transferability to unseen models and insufficient robustness
against common defense mechanisms. In this paper, we propose MAT-Adv, a novel
adversarial attack framework that enhances both transferability and
undefendability by explicitly perturbing the medial axis transform (MAT)
representations, in order to induce inherent adversarialness in the resulting
point clouds. Specifically, we employ an autoencoder to project input point
clouds into compact MAT representations that capture the intrinsic geometric
structure of point clouds. By perturbing these intrinsic representations,
MAT-Adv introduces structural-level adversarial characteristics that remain
effective across diverse models and defense strategies. To mitigate overfitting
and prevent perturbation collapse, we incorporate a dropout strategy into the
optimization of MAT perturbations, further improving transferability and
undefendability. Extensive experiments demonstrate that MAT-Adv significantly
outperforms existing state-of-the-art methods in both transferability and
undefendability. Codes will be made public upon paper acceptance.

</details>


### [30] [Synthetic-to-Real Camouflaged Object Detection](https://arxiv.org/abs/2507.18911)
*Zhihao Luo,Luojun Lin,Zheng Lin*

Main category: cs.CV

TL;DR: 为了解决合成数据到真实数据转换中的性能损失问题，本研究提出了一种名为 S2R-COD 的新任务和 CSRDA 框架。该框架利用合成数据和少量真实数据，通过伪标签、一致性正则化和循环学习，有效提升了模型在真实场景下的检测性能，并降低了对大量标注数据的需求。


<details>
  <summary>Details</summary>
Motivation: 由于合成数据的收集和标注成本高昂，特别是在特定类别上，现有的数据集往往不足。直接使用合成数据训练模型会导致性能下降。因此，本研究旨在解决合成数据到真实数据转换中的性能损失问题，并减轻数据集限制和手工标注的负担。

Method: 提出了一种基于学生-教师模型的 Cycling Syn-to-Real Domain Adaptation Framework (CSRDA) 方法，该方法结合伪标签和一致性正则化，将类别信息从标注的合成数据（源域）传播到未标注的真实数据（目标域）。此外，CSRDA 还采用循环学习框架构建一个不断演化的真实域，以缩小域内差距，提高伪标签质量，从而更好地实现域自适应。

Result: 实验结果表明，CSRDA 框架能够有效地缓解数据集限制和手工标注的问题，显著提升了模型在真实场景下的性能。

Conclusion: 该研究提出了一种名为 Syn-to-Real Camouflaged Object Detection (S2R-COD) 的新任务，旨在解决低分辨率数据集和手工标注成本高昂的问题。通过提出的 Cycling Syn-to-Real Domain Adaptation Framework (CSRDA) 方法，利用带有标注的合成数据和少量未标注的真实数据，结合伪标签和一致性正则化，将类别信息从源域传播到目标域，并通过循环学习框架构建不断演化的真实域来缩小域间差距，最终有效缓解了数据集限制和手工标注的问题，提高了模型在真实场景下的性能。

Abstract: Due to the high cost of collection and labeling, there are relatively few
datasets for camouflaged object detection (COD). In particular, for certain
specialized categories, the available image dataset is insufficiently
populated. Synthetic datasets can be utilized to alleviate the problem of
limited data to some extent. However, directly training with synthetic datasets
compared to real datasets can lead to a degradation in model performance. To
tackle this problem, in this work, we investigate a new task, namely
Syn-to-Real Camouflaged Object Detection (S2R-COD). In order to improve the
model performance in real world scenarios, a set of annotated synthetic
camouflaged images and a limited number of unannotated real images must be
utilized. We propose the Cycling Syn-to-Real Domain Adaptation Framework
(CSRDA), a method based on the student-teacher model. Specially, CSRDA
propagates class information from the labeled source domain to the unlabeled
target domain through pseudo labeling combined with consistency regularization.
Considering that narrowing the intra-domain gap can improve the quality of
pseudo labeling, CSRDA utilizes a recurrent learning framework to build an
evolving real domain for bridging the source and target domain. Extensive
experiments demonstrate the effectiveness of our framework, mitigating the
problem of limited data and handcraft annotations in COD. Our code is publicly
available at: https://github.com/Muscape/S2R-COD

</details>


### [31] [HQ-SMem: Video Segmentation and Tracking Using Memory Efficient Object Embedding With Selective Update and Self-Supervised Distillation Feedback](https://arxiv.org/abs/2507.18921)
*Elham Soltani Kazemi,Imad Eddine Toubal,Gani Rahmon,Jaired Collins,K. Palaniappan*

Main category: cs.CV

TL;DR: HQ-SMem 是一种新的视频对象分割方法，通过结合高精度遮罩、智能内存管理和动态外观更新，显著提高了分割质量和处理长视频的能力，并在多个数据集上取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有 VOS 模型在精确遮罩、处理形变或拓扑变化的物体、防止跟踪漂移以及处理长视频序列方面存在局限性。本研究旨在通过引入一种名为 HQ-SMem 的新方法来解决这些问题，以提高 VOS 的性能和鲁棒性。

Method: HQ-SMem 方法通过三个关键创新来提升 VOS 性能：1. 结合 SAM-HQ 和基于外观的候选选择来优化分割遮罩，提高对象边界精度。 2. 采用动态智能内存机制，选择性存储关键帧并丢弃冗余帧，以优化长视频的内存和处理效率。 3. 动态更新外观模型，以应对复杂的拓扑对象变化并减少跟踪漂移。

Result: HQ-SMem 在 VOTS 和 VOTSt 2024 数据集上始终排名前两位，并在 Long Video Dataset 和 LVOS 数据集上设定了新的性能基准，证明了其在具有复杂多对象动态的长时序视频处理中的有效性。

Conclusion: HQ-SMem 通过利用 SAM-HQ、动态智能内存和动态外观模型更新，显著提高了视频对象分割（VOS）的性能，解决了现有模型在遮罩精度、形变对象、拓扑变换、跟踪漂移和长视频序列处理方面的不足。在 VOTS、VOTSt 2024、Long Video Dataset 和 LVOS 等多个数据集上的实验表明，HQ-SMem 能够提供高质量的分割，有效处理复杂场景，并设定了新的性能基准。

Abstract: Video Object Segmentation (VOS) is foundational to numerous computer vision
applications, including surveillance, autonomous driving, robotics and
generative video editing. However, existing VOS models often struggle with
precise mask delineation, deformable objects, topologically transforming
objects, tracking drift and long video sequences. In this paper, we introduce
HQ-SMem, for High Quality video segmentation and tracking using Smart Memory, a
novel method that enhances the performance of VOS base models by addressing
these limitations. Our approach incorporates three key innovations: (i)
leveraging SAM with High-Quality masks (SAM-HQ) alongside appearance-based
candidate-selection to refine coarse segmentation masks, resulting in improved
object boundaries; (ii) implementing a dynamic smart memory mechanism that
selectively stores relevant key frames while discarding redundant ones, thereby
optimizing memory usage and processing efficiency for long-term videos; and
(iii) dynamically updating the appearance model to effectively handle complex
topological object variations and reduce drift throughout the video. These
contributions mitigate several limitations of existing VOS models including,
coarse segmentations that mix-in background pixels, fixed memory update
schedules, brittleness to drift and occlusions, and prompt ambiguity issues
associated with SAM. Extensive experiments conducted on multiple public
datasets and state-of-the-art base trackers demonstrate that our method
consistently ranks among the top two on VOTS and VOTSt 2024 datasets. Moreover,
HQ-SMem sets new benchmarks on Long Video Dataset and LVOS, showcasing its
effectiveness in challenging scenarios characterized by complex multi-object
dynamics over extended temporal durations.

</details>


### [32] [Gaussian Set Surface Reconstruction through Per-Gaussian Optimization](https://arxiv.org/abs/2507.18923)
*Zhentao Huang,Di Wu,Zhenbang He,Minglun Gong*

Main category: cs.CV

TL;DR: GSSR通过优化高斯点分布和法线对齐，显著提升了3DGS在场景几何重建方面的精度，便于编辑和生成3D环境。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法虽然在视图合成方面表现良好，但在场景几何重建方面存在不足。后续的PGSR等方法虽然引入了额外的损失函数，但仍未解决高斯点分布不均的问题，影响了几何重建和场景编辑。因此，需要一种新的方法来优化高斯点的空间分布，使其更好地贴合潜在表面。

Method: GSSR通过结合像素级和高斯级的单视角法线一致性，以及多视角光度一致性，来优化高斯点在潜在表面上的分布和法线对齐。同时，引入不透明度正则化损失消除冗余高斯点，并通过周期性的深度和法线引导的高斯点重初始化来进一步优化空间分布。

Result: GSSR在几何精度方面取得了显著提升，实现了高斯点在潜在表面上的均匀分布和法线对齐。这使得场景编辑更加直观，并且能够高效地生成基于高斯点的3D环境。实验证明，GSSR在提高几何精度的同时，保持了高质量的渲染性能。

Conclusion: 3DGS的变体（如PGSR）通过引入额外的损失函数来优化深度图和法线图，但忽略了高斯点在空间中的分布优化。本文提出的高斯点集表面重建（GSSR）方法，通过像素级和高斯级的单视角法线一致性以及多视角光度一致性，实现了高斯点在潜在表面上的均匀分布及其主法线与表面法线的对齐。此外，通过不透明度正则化损失消除冗余高斯点，并结合周期性的深度和法线引导的高斯点重初始化，进一步优化了空间分布。实验结果表明，GSSR显著提高了高斯点在表面重建的几何精度，便于场景编辑和生成高质量的3D环境，同时保持了渲染性能。

Abstract: 3D Gaussian Splatting (3DGS) effectively synthesizes novel views through its
flexible representation, yet fails to accurately reconstruct scene geometry.
While modern variants like PGSR introduce additional losses to ensure proper
depth and normal maps through Gaussian fusion, they still neglect individual
placement optimization. This results in unevenly distributed Gaussians that
deviate from the latent surface, complicating both reconstruction refinement
and scene editing. Motivated by pioneering work on Point Set Surfaces, we
propose Gaussian Set Surface Reconstruction (GSSR), a method designed to
distribute Gaussians evenly along the latent surface while aligning their
dominant normals with the surface normal. GSSR enforces fine-grained geometric
alignment through a combination of pixel-level and Gaussian-level single-view
normal consistency and multi-view photometric consistency, optimizing both
local and global perspectives. To further refine the representation, we
introduce an opacity regularization loss to eliminate redundant Gaussians and
apply periodic depth- and normal-guided Gaussian reinitialization for a
cleaner, more uniform spatial distribution. Our reconstruction results
demonstrate significantly improved geometric precision in Gaussian placement,
enabling intuitive scene editing and efficient generation of novel
Gaussian-based 3D environments. Extensive experiments validate GSSR's
effectiveness, showing enhanced geometric accuracy while preserving
high-quality rendering performance.

</details>


### [33] [WiSE-OD: Benchmarking Robustness in Infrared Object Detection](https://arxiv.org/abs/2507.18925)
*Heitor R. Medeiros,Atif Belal,Masih Aminbeidokhti,Eric Granger,Marco Pedersoli*

Main category: cs.CV

TL;DR: WiSE-OD 是一种权重集成方法，通过结合 RGB 和红外数据训练的模型的权重，提高了红外目标检测在不同模态和数据扰动下的鲁棒性，且无需额外训练或推理成本。


<details>
  <summary>Details</summary>
Motivation: 红外图像目标检测（OD）在低光照和夜间应用中至关重要。然而，大规模红外数据集的稀缺迫使模型依赖在 RGB 图像上预训练的权重。尽管在红外数据上进行微调可以提高准确性，但由于 RGB 和 IR 之间固有的模态差异，通常会损害模型在分布变化下的鲁棒性。

Method: 提出了一种名为 WiSE-OD 的权重空间集成方法，包含两种变体：WiSE-OD$_{ZS}$（结合 RGB 零样本和 IR 微调权重）和 WiSE-OD$_{LP}$（融合零样本和线性探测权重）。

Result: 在三种 RGB 预训练检测器和两种鲁棒基线上的评估结果表明，WiSE-OD 提高了跨模态和腐败鲁棒性。

Conclusion: WiSE-OD 权重集成方法在不增加额外训练或推理成本的情况下，提高了跨模态和腐败鲁棒性。

Abstract: Object detection (OD) in infrared (IR) imagery is critical for low-light and
nighttime applications. However, the scarcity of large-scale IR datasets forces
models to rely on weights pre-trained on RGB images. While fine-tuning on IR
improves accuracy, it often compromises robustness under distribution shifts
due to the inherent modality gap between RGB and IR. To address this, we
introduce LLVIP-C and FLIR-C, two cross-modality out-of-distribution (OOD)
benchmarks built by applying corruption to standard IR datasets. Additionally,
to fully leverage the complementary knowledge from RGB and infrared trained
models, we propose WiSE-OD, a weight-space ensembling method with two variants:
WiSE-OD$_{ZS}$, which combines RGB zero-shot and IR fine-tuned weights, and
WiSE-OD$_{LP}$, which blends zero-shot and linear probing. Evaluated across
three RGB-pretrained detectors and two robust baselines, WiSE-OD improves both
cross-modality and corruption robustness without any additional training or
inference cost.

</details>


### [34] [MGHFT: Multi-Granularity Hierarchical Fusion Transformer for Cross-Modal Sticker Emotion Recognition](https://arxiv.org/abs/2507.18929)
*Jian Chen,Yuxuan Hu,Haifeng Lu,Wei Wang,Min Yang,Chengming Li,Xiping Hu*

Main category: cs.CV

TL;DR: 提出MGHFT模型，结合多模态大语言模型和分层融合Transformer，利用多视角文本描述和视觉特征融合，提升了贴纸情感识别的准确性和细粒度。


<details>
  <summary>Details</summary>
Motivation: 现有的预训练视觉模型在提取视觉特征方面能力强大，但在贴纸情感理解方面仍具挑战性，因为这需要多视角信息，如背景知识和风格线索。

Method: 提出了一种新颖的多粒度分层融合Transformer（MGHFT），该模型基于多模态大语言模型构建了一个多视角贴纸解释器。具体而言，利用多模态大语言模型通过多视角描述提供丰富的文本上下文来解释贴纸；设计了一个分层融合策略，将文本上下文融入视觉理解；该策略基于金字塔视觉Transformer提取全局和局部视觉特征；通过对比学习和注意力机制，在视觉骨干的不同阶段注入文本特征，融合全局和局部粒度的视觉语义与文本引导；最后，引入文本引导融合注意力机制来整合多模态特征，增强语义理解。

Result: MGHFT在两个公开的贴纸情感数据集上进行了广泛实验，结果表明其性能显著优于现有贴纸情感识别方法，实现了更高的准确率和更细粒度的情感识别。

Conclusion: MGHFT在贴纸情感识别任务上显著优于现有方法，在准确率和细粒度情感识别方面均有提升，并且相比最佳的预训练视觉模型，F1分数和准确率分别提高了5.4%和4.0%。

Abstract: Although pre-trained visual models with text have demonstrated strong
capabilities in visual feature extraction, sticker emotion understanding
remains challenging due to its reliance on multi-view information, such as
background knowledge and stylistic cues. To address this, we propose a novel
multi-granularity hierarchical fusion transformer (MGHFT), with a multi-view
sticker interpreter based on Multimodal Large Language Models. Specifically,
inspired by the human ability to interpret sticker emotions from multiple
views, we first use Multimodal Large Language Models to interpret stickers by
providing rich textual context via multi-view descriptions. Then, we design a
hierarchical fusion strategy to fuse the textual context into visual
understanding, which builds upon a pyramid visual transformer to extract both
global and local sticker features at multiple stages. Through contrastive
learning and attention mechanisms, textual features are injected at different
stages of the visual backbone, enhancing the fusion of global- and
local-granularity visual semantics with textual guidance. Finally, we introduce
a text-guided fusion attention mechanism to effectively integrate the overall
multimodal features, enhancing semantic understanding. Extensive experiments on
2 public sticker emotion datasets demonstrate that MGHFT significantly
outperforms existing sticker emotion recognition approaches, achieving higher
accuracy and more fine-grained emotion recognition. Compared to the best
pre-trained visual models, our MGHFT also obtains an obvious improvement, 5.4%
on F1 and 4.0% on accuracy. The code is released at
https://github.com/cccccj-03/MGHFT_ACMMM2025.

</details>


### [35] [PDT: Point Distribution Transformation with Diffusion Models](https://arxiv.org/abs/2507.18939)
*Jionghao Wang,Cheng Lin,Yuan Liu,Rui Xu,Zhiyang Dou,Xiao-Xiao Long,Hao-Xiang Guo,Taku Komura,Wenping Wang,Xin Li*

Main category: cs.CV

TL;DR: PDT是一个新的框架，它使用扩散模型将点云从原始几何分布转换为有语义的分布，以提取结构信息。


<details>
  <summary>Details</summary>
Motivation: 探索如何从无结构点云分布中提取有意义的结构信息，并将它们转化为有语义的、有意义的点分布。

Method: 利用具有新颖架构和学习策略的扩散模型，通过去噪过程有效地将源分布和目标分布关联起来。

Result: 成功地将输入点云转化为各种形式的结构化输出，包括表面对齐的关键点、内部稀疏关节和连续特征线。

Conclusion: 该框架能够捕捉几何和语义特征，为需要结构化点分布的各种3D几何处理任务提供了强大的工具。

Abstract: Point-based representations have consistently played a vital role in
geometric data structures. Most point cloud learning and processing methods
typically leverage the unordered and unconstrained nature to represent the
underlying geometry of 3D shapes. However, how to extract meaningful structural
information from unstructured point cloud distributions and transform them into
semantically meaningful point distributions remains an under-explored problem.
We present PDT, a novel framework for point distribution transformation with
diffusion models. Given a set of input points, PDT learns to transform the
point set from its original geometric distribution into a target distribution
that is semantically meaningful. Our method utilizes diffusion models with
novel architecture and learning strategy, which effectively correlates the
source and the target distribution through a denoising process. Through
extensive experiments, we show that our method successfully transforms input
point clouds into various forms of structured outputs - ranging from
surface-aligned keypoints, and inner sparse joints to continuous feature lines.
The results showcase our framework's ability to capture both geometric and
semantic features, offering a powerful tool for various 3D geometry processing
tasks where structured point distributions are desired. Code will be available
at this link: https://github.com/shanemankiw/PDT.

</details>


### [36] [Underwater Waste Detection Using Deep Learning A Performance Comparison of YOLOv7 to 10 and Faster RCNN](https://arxiv.org/abs/2507.18967)
*UMMPK Nawarathne,HMNS Kumari,HMLS Kumari*

Main category: cs.CV

TL;DR: YOLOv8在识别水下垃圾方面表现最佳，mAP为80.9%，比其他模型更有效。


<details>
  <summary>Details</summary>
Motivation: 为了有效管理水下污染、进行环境监测和制定缓解策略，需要精确识别水下垃圾。

Method: 本研究评估了YOLOv7、YOLOv8、YOLOv9、YOLOv10和Faster R-CNN这五种先进的物体识别算法在水下场景中的性能。

Result: 在包含15个不同类别和各种水下条件（如低能见度和不同深度）的数据集上进行训练和测试后，YOLOv8的平均精度均值（mAP）达到了80.9%，显著优于其他模型。

Conclusion: YOLOv8在水下物体识别任务中表现最佳，其mAP达到80.9%，表明其在应对水下污染监测方面具有巨大潜力，能够提升检测能力和清理行动的可扩展性。

Abstract: Underwater pollution is one of today's most significant environmental
concerns, with vast volumes of garbage found in seas, rivers, and landscapes
around the world. Accurate detection of these waste materials is crucial for
successful waste management, environmental monitoring, and mitigation
strategies. In this study, we investigated the performance of five cutting-edge
object recognition algorithms, namely YOLO (You Only Look Once) models,
including YOLOv7, YOLOv8, YOLOv9, YOLOv10, and Faster Region-Convolutional
Neural Network (R-CNN), to identify which model was most effective at
recognizing materials in underwater situations. The models were thoroughly
trained and tested on a large dataset containing fifteen different classes
under diverse conditions, such as low visibility and variable depths. From the
above-mentioned models, YOLOv8 outperformed the others, with a mean Average
Precision (mAP) of 80.9%, indicating a significant performance. This increased
performance is attributed to YOLOv8's architecture, which incorporates advanced
features such as improved anchor-free mechanisms and self-supervised learning,
allowing for more precise and efficient recognition of items in a variety of
settings. These findings highlight the YOLOv8 model's potential as an effective
tool in the global fight against pollution, improving both the detection
capabilities and scalability of underwater cleanup operations.

</details>


### [37] [Structure Matters: Revisiting Boundary Refinement in Video Object Segmentation](https://arxiv.org/abs/2507.18944)
*Guanyi Qin,Ziyue Wang,Daiyun Shen,Haofeng Liu,Hantao Zhou,Junde Wu,Runze Hu,Yueming Jin*

Main category: cs.CV

TL;DR: OASIS是一种新颖的SVOS方法，通过结构细化和证据学习解决了遮挡和实时性问题，并在各项基准测试中取得了优于现有方法的性能和速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于记忆的方法在处理遮挡、物体交互和高特征相似性等场景时存在困难，而SVOS技术需要满足下游应用的实时处理要求。OASIS旨在解决这些问题并满足实时性要求。

Method: 提出了一种新颖的基于边界修正和固有结构细化的半监督视频对象分割（SVOS）方法，命名为OASIS。该方法包括一个轻量级的结构细化模块，利用Canny滤波器的边缘先验和存储的对象特征来生成对象级别的结构图，并通过突出边界特征来细化表示。此外，引入了证据学习来进行不确定性估计，以应对遮挡区域的挑战。

Result: OASIS在DAVIS-17验证集上达到了91.6的F值（优于89.7），在YouTubeVOS 2019验证集上达到了86.6的G值（优于86.2），并且在DAVIS上实现了48 FPS的推理速度。

Conclusion: OASIS方法在具有挑战性的基准测试中表现出优越的性能和具有竞争力的推理速度，与最先进的方法相比，在DAVIS-17验证集上实现了91.6（对比89.7）的F值，在YouTubeVOS 2019验证集上实现了86.6（对比86.2）的G值，同时在DAVIS上保持了48 FPS的竞争速度。

Abstract: Given an object mask, Semi-supervised Video Object Segmentation (SVOS)
technique aims to track and segment the object across video frames, serving as
a fundamental task in computer vision. Although recent memory-based methods
demonstrate potential, they often struggle with scenes involving occlusion,
particularly in handling object interactions and high feature similarity. To
address these issues and meet the real-time processing requirements of
downstream applications, in this paper, we propose a novel bOundary Amendment
video object Segmentation method with Inherent Structure refinement, hereby
named OASIS. Specifically, a lightweight structure refinement module is
proposed to enhance segmentation accuracy. With the fusion of rough edge priors
captured by the Canny filter and stored object features, the module can
generate an object-level structure map and refine the representations by
highlighting boundary features. Evidential learning for uncertainty estimation
is introduced to further address challenges in occluded regions. The proposed
method, OASIS, maintains an efficient design, yet extensive experiments on
challenging benchmarks demonstrate its superior performance and competitive
inference speed compared to other state-of-the-art methods, i.e., achieving the
F values of 91.6 (vs. 89.7 on DAVIS-17 validation set) and G values of 86.6
(vs. 86.2 on YouTubeVOS 2019 validation set) while maintaining a competitive
speed of 48 FPS on DAVIS.

</details>


### [38] [Closing the Modality Gap for Mixed Modality Search](https://arxiv.org/abs/2507.19054)
*Binxu Li,Yuhui Zhang,Xiaohan Wang,Weixin Liang,Ludwig Schmidt,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: GR-CLIP通过消除CLIP的模态差距来改进混合模态搜索。


<details>
  <summary>Details</summary>
Motivation: 混合模态搜索（在由图像、文本和多模态文档组成的异类语料库中检索信息）是一项重要但探索不足的现实应用。本研究旨在解决对比式视觉-语言模型（如CLIP）在混合模态搜索任务中的模态差距问题。

Method: GR-CLIP是一种轻量级的、事后校准方法，用于消除CLIP嵌入空间中的模态差距。

Result: GR-CLIP在MixBench基准测试中，NDCG@10方面比CLIP提高了26个百分点，比最近的视觉-语言生成嵌入模型提高了4个百分点，同时计算量减少了75倍。

Conclusion: GR-CLIP是一种轻量级的、事后校准方法，可以消除CLIP嵌入空间中的模态差距，在MixBench基准测试中，GR-CLIP在NDCG@10方面比CLIP提高了26个百分点，比最近的视觉-语言生成嵌入模型提高了4个百分点，同时计算量减少了75倍。

Abstract: Mixed modality search -- retrieving information across a heterogeneous corpus
composed of images, texts, and multimodal documents -- is an important yet
underexplored real-world application. In this work, we investigate how
contrastive vision-language models, such as CLIP, perform on the mixed modality
search task. Our analysis reveals a critical limitation: these models exhibit a
pronounced modality gap in the embedding space, where image and text embeddings
form distinct clusters, leading to intra-modal ranking bias and inter-modal
fusion failure. To address this issue, we propose GR-CLIP, a lightweight
post-hoc calibration method that removes the modality gap in CLIP's embedding
space. Evaluated on MixBench -- the first benchmark specifically designed for
mixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points
over CLIP, surpasses recent vision-language generative embedding models by 4
percentage points, while using 75x less compute.

</details>


### [39] [PerioDet: Large-Scale Panoramic Radiograph Benchmark for Clinical-Oriented Apical Periodontitis Detection](https://arxiv.org/abs/2507.18958)
*Xiaocheng Fang,Jieyi Cai,Huanyu Liu,Chengju Zhou,Minhua Lu,Bingzhi Chen*

Main category: cs.CV

TL;DR: 发布了首个尖周炎诊断基准数据集PerioXrays，并提出了PerioDet检测方法，在包含背景噪声和小目标的情况下提高了检测性能，并展示了其作为辅助诊断工具的临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管在各种医疗领域的自动化诊断系统取得了进展，但用于尖周炎的计算机辅助诊断（CAD）应用的开发仍然受到缺乏大规模、高质量标注数据集的限制。

Method: 提出了一种名为PerioDet的临床导向的尖周炎检测范式，该范式联合结合了背景去噪注意力（BDA）和IoU动态校准（IDC）机制，以解决自动检测中背景噪声和小目标带来的挑战。

Result: 发布了一个名为“PerioXrays”的大规模全景X射线基准，包含3,673张图像和5,662个尖周炎实例。

Conclusion: PerioDet在PerioXrays数据集上的广泛实验证明了其在推进自动化尖周炎检测方面的优越性。此外，精心设计的人机协作实验强调了我们方法作为专业牙医辅助诊断工具的临床适用性。

Abstract: Apical periodontitis is a prevalent oral pathology that presents significant
public health challenges. Despite advances in automated diagnostic systems
across various medical fields, the development of Computer-Aided Diagnosis
(CAD) applications for apical periodontitis is still constrained by the lack of
a large-scale, high-quality annotated dataset. To address this issue, we
release a large-scale panoramic radiograph benchmark called "PerioXrays",
comprising 3,673 images and 5,662 meticulously annotated instances of apical
periodontitis. To the best of our knowledge, this is the first benchmark
dataset for automated apical periodontitis diagnosis. This paper further
proposes a clinical-oriented apical periodontitis detection (PerioDet)
paradigm, which jointly incorporates Background-Denoising Attention (BDA) and
IoU-Dynamic Calibration (IDC) mechanisms to address the challenges posed by
background noise and small targets in automated detection. Extensive
experiments on the PerioXrays dataset demonstrate the superiority of PerioDet
in advancing automated apical periodontitis detection. Additionally, a
well-designed human-computer collaborative experiment underscores the clinical
applicability of our method as an auxiliary diagnostic tool for professional
dentists.

</details>


### [40] [YOLO for Knowledge Extraction from Vehicle Images: A Baseline Study](https://arxiv.org/abs/2507.18966)
*Saraa Al-Saddik,Manna Elizabeth Philip,Ali Haidar*

Main category: cs.CV

TL;DR: 本研究使用 YOLOv11、YOLO-World 和 YOLO-Classification 在包含 10 万多张图像的真实数据集上评估车辆属性（品牌、形状、颜色）的识别效果。结果显示，YOLOv11 和 YOLO-World 在品牌和形状识别上优于纯分类模型，且较小模型在效率上表现优异。研究强调了多视角推理（MVI）在复杂数据集中的重要性，并为车辆元数据提取提供了基线。


<details>
  <summary>Details</summary>
Motivation: 准确识别车辆属性（如品牌、颜色和形状）对于执法和情报应用至关重要。

Method: 本研究评估了 YOLO-v11、YOLO-World 和 YOLO-Classification 三种最先进的深度学习方法在真实车辆图像数据集上的有效性。该数据集是在新南威尔士州警察公路巡逻车收集的、具有挑战性的、不受限制的条件下收集的。采用了多视角推理（MVI）方法来提高模型预测的性能。为了进行分析，为三个元数据预测任务（即品牌、形状和颜色）创建了包含超过 100,000 张图像的数据集。模型在包含 29,937 张图像（属于 1809 个车牌）的单独数据集上进行了测试。通过改变模型大小，研究了不同组的实验。

Result: 在模型大小不同的实验中，最佳性能的品牌、形状、颜色和颜色二元模型分别达到了 93.70%、82.86%、85.19% 和 94.86% 的分类准确率。目标检测模型 YOLO-v11 和 YOLO-World 在品牌和形状提取方面优于纯分类模型。较小的 YOLO 变体在效率方面与较大的模型相当，并为实时预测提供了显著的效率优势。

Conclusion: 需要使用多视角推理（MVI）才能在复杂的真实世界数据集中获得可用的模型。 YOLOv11 和 YOLO-World 等目标检测模型在提取车辆品牌和形状方面优于纯分类模型。此外，较小的 YOLO 模型在效率方面与较大的模型相当，这对于实时预测非常有益。

Abstract: Accurate identification of vehicle attributes such as make, colour, and shape
is critical for law enforcement and intelligence applications. This study
evaluates the effectiveness of three state-of-the-art deep learning approaches
YOLO-v11, YOLO-World, and YOLO-Classification on a real-world vehicle image
dataset. This dataset was collected under challenging and unconstrained
conditions by NSW Police Highway Patrol Vehicles. A multi-view inference (MVI)
approach was deployed to enhance the performance of the models' predictions. To
conduct the analyses, datasets with 100,000 plus images were created for each
of the three metadata prediction tasks, specifically make, shape and colour.
The models were tested on a separate dataset with 29,937 images belonging to
1809 number plates. Different sets of experiments have been investigated by
varying the models sizes. A classification accuracy of 93.70%, 82.86%, 85.19%,
and 94.86% was achieved with the best performing make, shape, colour, and
colour-binary models respectively. It was concluded that there is a need to use
MVI to get usable models within such complex real-world datasets. Our findings
indicated that the object detection models YOLO-v11 and YOLO-World outperformed
classification-only models in make and shape extraction. Moreover, smaller YOLO
variants perform comparably to larger counterparts, offering substantial
efficiency benefits for real-time predictions. This work provides a robust
baseline for extracting vehicle metadata in real-world scenarios. Such models
can be used in filtering and sorting user queries, minimising the time required
to search large vehicle images datasets.

</details>


### [41] [AEDR: Training-Free AI-Generated Image Attribution via Autoencoder Double-Reconstruction](https://arxiv.org/abs/2507.18988)
*Chao Wang,Kejiang Chen,Zijin Yang,Yaofei Wang,Weiming Zhang*

Main category: cs.CV

TL;DR: AEDR是一种用于图像生成模型的新型归因方法，它通过两次重建和损失比率来提高准确性并降低计算成本，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了减轻生成模型（特别是图像生成模型）被恶意使用的风险，追踪这些图像的来源至关重要。现有的基于重建的归因方法在应用于最先进的模型时，准确率会降低且计算成本高昂。

Method: AEDR（AutoEncoder Double-Reconstruction）是一种新颖的、无需训练的归因方法，它利用模型连续自编码器的两次连续重建及其重建损失之比作为归因信号，并通过图像同质性度量进行校准，以提高准确性。

Result: AEDR具有更高的归因准确性和卓越的计算效率，可作为一种有效的解决方案来应对由先进生成模型带来的安全挑战。

Conclusion: AEDR在八个顶级潜在扩散模型上的实验表明，其归因准确率比现有的基于重建的方法提高了25.5%，而计算时间仅占1%。

Abstract: The rapid advancement of image-generation technologies has made it possible
for anyone to create photorealistic images using generative models, raising
significant security concerns. To mitigate malicious use, tracing the origin of
such images is essential. Reconstruction-based attribution methods offer a
promising solution, but they often suffer from reduced accuracy and high
computational costs when applied to state-of-the-art (SOTA) models. To address
these challenges, we propose AEDR (AutoEncoder Double-Reconstruction), a novel
training-free attribution method designed for generative models with continuous
autoencoders. Unlike existing reconstruction-based approaches that rely on the
value of a single reconstruction loss, AEDR performs two consecutive
reconstructions using the model's autoencoder, and adopts the ratio of these
two reconstruction losses as the attribution signal. This signal is further
calibrated using the image homogeneity metric to improve accuracy, which
inherently cancels out absolute biases caused by image complexity, with
autoencoder-based reconstruction ensuring superior computational efficiency.
Experiments on eight top latent diffusion models show that AEDR achieves 25.5%
higher attribution accuracy than existing reconstruction-based methods, while
requiring only 1% of the computational time.

</details>


### [42] [LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences](https://arxiv.org/abs/2507.19362)
*Yusuke Hirota,Boyi Li,Ryo Hachiuma,Yueh-Hua Wu,Boris Ivanovic,Yuta Nakashima,Marco Pavone,Yejin Choi,Yu-Chiang Frank Wang,Chao-Han Huck Yang*

Main category: cs.CV

TL;DR: LOTUS是一个评估详细图像描述的新排行榜，它考虑了描述质量、风险和偏见，并允许基于用户偏好进行评估。结果显示，模型表现各异，且细节与偏见风险相关，最佳模型选择取决于用户偏好。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有图像描述评估的不足，特别是缺乏标准化标准、偏见评估以及用户偏好考量，我们引入了LOTUS排行榜。

Method: LOTUS是一个用于评估详细图像描述的排行榜，它弥补了现有评估标准不统一、缺乏偏见评估以及未考虑用户偏好这三个主要差距。LOTUS全面评估了描述质量（如一致性、描述性）、风险（如幻觉）和社会偏见（如性别偏见），并通过定制标准以适应不同用户偏好，实现了面向偏好的评估。

Result: LOTUS的分析显示，在详细描述方面，没有单一模型能在所有标准上都表现出色。此外，描述的细节程度与潜在的偏见风险之间存在相关性。通过面向偏好的评估，我们发现最佳模型选择策略取决于具体用户的偏好和优先级。

Conclusion: LOTUS揭示了没有模型能在所有标准上都表现出色，并且标题细节与偏见风险之间存在相关性。基于偏好的评估表明，最佳模型选择取决于用户的优先事项。

Abstract: Large Vision-Language Models (LVLMs) have transformed image captioning,
shifting from concise captions to detailed descriptions. We introduce LOTUS, a
leaderboard for evaluating detailed captions, addressing three main gaps in
existing evaluations: lack of standardized criteria, bias-aware assessments,
and user preference considerations. LOTUS comprehensively evaluates various
aspects, including caption quality (e.g., alignment, descriptiveness), risks
(\eg, hallucination), and societal biases (e.g., gender bias) while enabling
preference-oriented evaluations by tailoring criteria to diverse user
preferences. Our analysis of recent LVLMs reveals no single model excels across
all criteria, while correlations emerge between caption detail and bias risks.
Preference-oriented evaluations demonstrate that optimal model selection
depends on user priorities.

</details>


### [43] [MedIQA: A Scalable Foundation Model for Prompt-Driven Medical Image Quality Assessment](https://arxiv.org/abs/2507.19004)
*Siyi Xun,Yue Sun,Jingkun Chen,Zitong Yu,Tong Tong,Xiaohong Liu,Mingxiang Wu,Tao Tan*

Main category: cs.CV

TL;DR: MedIQA 是首个用于医学图像质量评估（IQA）的基础模型，能够处理各种医学图像，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的医学 IQA 方法在处理不同模态和临床场景时泛化能力不足，无法满足医学影像技术快速发展的需求。

Method: MedIQA 模型集成了显著切片评估模块，专注于诊断相关区域的特征检索，并采用自动提示策略，将上游物理参数预训练与下游专家注释微调相结合。

Result: MedIQA 在多个下游任务中的表现显著优于现有基线方法。

Conclusion: MedIQA 作为一个全面的医学图像质量评估（IQA）基础模型，在处理不同模态、解剖区域和图像类型时表现出卓越的泛化能力，并且在多个下游任务中显著优于现有方法，为医学 IQA 提供了一个可扩展的框架，有助于改进诊断工作流程和临床决策。

Abstract: Rapid advances in medical imaging technology underscore the critical need for
precise and automated image quality assessment (IQA) to ensure diagnostic
accuracy. Existing medical IQA methods, however, struggle to generalize across
diverse modalities and clinical scenarios. In response, we introduce MedIQA,
the first comprehensive foundation model for medical IQA, designed to handle
variability in image dimensions, modalities, anatomical regions, and types. We
developed a large-scale multi-modality dataset with plentiful manually
annotated quality scores to support this. Our model integrates a salient slice
assessment module to focus on diagnostically relevant regions feature retrieval
and employs an automatic prompt strategy that aligns upstream physical
parameter pre-training with downstream expert annotation fine-tuning. Extensive
experiments demonstrate that MedIQA significantly outperforms baselines in
multiple downstream tasks, establishing a scalable framework for medical IQA
and advancing diagnostic workflows and clinical decision-making.

</details>


### [44] [UPP: Unified Point-Level Prompting for Robust Point Cloud Analysis](https://arxiv.org/abs/2507.18997)
*Zixiang Ai,Zhenyu Cui,Yuxin Peng,Jiahuan Zhou*

Main category: cs.CV

TL;DR: 该研究提出了一种新的点云去噪和补全方法，通过统一的点级提示机制，解决了现有方法在处理真实世界噪声和不完整点云数据时的不足，并提高了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在点云增强和下游任务之间存在隔离，导致在各种实际应用领域效果不佳。此外，去噪和补全任务之间的冲突目标限制了保留关键几何特征的集成范式。

Method: 提出了一种统一的点级提示方法，将点云去噪和补全重新定义为提示机制，从而能够以参数高效的方式进行鲁棒分析。首先引入了一个用于适应噪声点的Rectification Prompter，通过预测的校正向量提示来有效过滤噪声，同时保留了准确分析所需的复杂几何特征。随后，结合了Completion Prompter，基于校正后的点云生成辅助点提示，提高了其鲁棒性和适应性。最后，利用Shape-Aware Unit模块高效地统一和捕获过滤后的几何特征，以用于下游的点云分析。

Result: 所提出的统一点级提示方法在处理噪声和不完整点云数据方面表现出优越性和鲁棒性。

Conclusion: 该方法在四个数据集上的大量实验证明了其在处理噪声和不完整点云数据方面的优越性和鲁棒性，优于现有的最先进方法。

Abstract: Pre-trained point cloud analysis models have shown promising advancements in
various downstream tasks, yet their effectiveness is typically suffering from
low-quality point cloud (i.e., noise and incompleteness), which is a common
issue in real scenarios due to casual object occlusions and unsatisfactory data
collected by 3D sensors. To this end, existing methods focus on enhancing point
cloud quality by developing dedicated denoising and completion models. However,
due to the isolation between the point cloud enhancement and downstream tasks,
these methods fail to work in various real-world domains. In addition, the
conflicting objectives between denoising and completing tasks further limit the
ensemble paradigm to preserve critical geometric features. To tackle the above
challenges, we propose a unified point-level prompting method that reformulates
point cloud denoising and completion as a prompting mechanism, enabling robust
analysis in a parameter-efficient manner. We start by introducing a
Rectification Prompter to adapt to noisy points through the predicted
rectification vector prompts, effectively filtering noise while preserving
intricate geometric features essential for accurate analysis. Sequentially, we
further incorporate a Completion Prompter to generate auxiliary point prompts
based on the rectified point clouds, facilitating their robustness and
adaptability. Finally, a Shape-Aware Unit module is exploited to efficiently
unify and capture the filtered geometric features for the downstream point
cloud analysis.Extensive experiments on four datasets demonstrate the
superiority and robustness of our method when handling noisy and incomplete
point cloud data against existing state-of-the-art methods. Our code is
released at https://github.com/zhoujiahuan1991/ICCV2025-UPP.

</details>


### [45] [GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution](https://arxiv.org/abs/2507.18998)
*Yongsong Huang,Tomo Miyazaki,Xiaofeng Liu,Shinichiro Omachi*

Main category: cs.CV

TL;DR: GPSMamba通过引入ASF-SSM和热谱注意力及相位一致性损失，改进了Mamba模型在红外图像超分辨率中的性能，解决了因果扫描带来的全局上下文碎片化问题，实现了最先进的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的红外图像超分辨率（IRSR）方法面临低对比度和稀疏纹理的挑战，需要强大的长程建模来维持全局连贯性。尽管状态空间模型（如Mamba）擅长处理长程依赖，但其1D因果扫描机制会破坏2D图像的全局上下文，阻碍细节恢复。

Method: 提出了一种名为GPSMamba的框架，该框架结合了自适应语义频率状态空间模块（ASF-SSM）和新颖的热谱注意力及相位一致性损失。ASF-SSM将融合的语义频率提示注入Mamba块，整合非局部上下文以指导重建。热谱注意力及相位一致性损失则提供显式的、非因果的监督，以保证全局结构和光谱的保真度。

Result: 实验证明，GPSMamba在红外图像超分辨率任务上取得了最先进的性能，验证了该方法作为红外图像复原新范式的有效性。

Conclusion: GPSMamba通过结合架构引导和非因果监督，成功解决了因1D因果扫描机制导致2D图像全局上下文碎片化的问题，从而在红外图像超分辨率任务上实现了最先进的性能，为红外图像复原提供了一种新的范式。

Abstract: Infrared Image Super-Resolution (IRSR) is challenged by the low contrast and
sparse textures of infrared data, requiring robust long-range modeling to
maintain global coherence. While State-Space Models like Mamba offer
proficiency in modeling long-range dependencies for this task, their inherent
1D causal scanning mechanism fragments the global context of 2D images,
hindering fine-detail restoration. To address this, we propose Global Phase and
Spectral Prompt-guided Mamba (GPSMamba), a framework that synergizes
architectural guidance with non-causal supervision. First, our Adaptive
Semantic-Frequency State Space Module (ASF-SSM) injects a fused
semantic-frequency prompt directly into the Mamba block, integrating non-local
context to guide reconstruction. Then, a novel Thermal-Spectral Attention and
Phase Consistency Loss provides explicit, non-causal supervision to enforce
global structural and spectral fidelity. By combining these two innovations,
our work presents a systematic strategy to mitigate the limitations of causal
modeling. Extensive experiments demonstrate that GPSMamba achieves
state-of-the-art performance, validating our approach as a powerful new
paradigm for infrared image restoration. Code is available at
https://github.com/yongsongH/GPSMamba.

</details>


### [46] [MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents](https://arxiv.org/abs/2507.19478)
*Xuehui Wang,Zhenyu Wu,JingJing Xie,Zichen Ding,Bowen Yang,Zehao Li,Zhaoyang Liu,Qingyun Li,Xuan Dong,Zhe Chen,Weiyun Wang,Xiangyu Zhao,Jixuan Chen,Haodong Duan,Tianbao Xie,Chenyu Yang,Shiqian Su,Yue Yu,Yuan Huang,Yiqian Liu,Xiao Zhang,Yanting Zhang,Xiangyu Yue,Weijie Su,Xizhou Zhu,Wei Shen,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: MMBench-GUI 是一个用于评估 GUI 自动化代理的多平台基准。研究发现，准确的视觉基础、强大的规划和泛化能力对任务成功至关重要，但当前的代理在效率方面存在不足。精确的定位、规划和早期停止是实现高效 GUI 自动化的关键。


<details>
  <summary>Details</summary>
Motivation: 为了评估和改进 GUI 自动化代理在不同平台上的能力，并解决当前 GUI 自动化效率低下的问题。

Method: 提出了一种名为 MMBench-GUI 的分层基准，用于评估跨 Windows、macOS、Linux、iOS、Android 和 Web 平台的 GUI 自动化代理。该基准包含四个级别：GUI 内容理解、元素基础、任务自动化和任务协作。此外，还提出了一种新颖的效率-质量区域（EQA）指标来评估 GUI 代理在在线自动化场景中的执行效率。

Result: MMBench-GUI 识别出准确的视觉基础对于任务成功至关重要，并强调了模块化框架的优势。代理需要强大的任务规划、跨平台泛化、长上下文记忆、广阔的动作空间和长期推理能力。此外，所有模型在任务效率方面都存在显著的不足，存在过多的冗余步骤。精确的定位、有效的规划和早期停止策略对于实现高效可扩展的 GUI 自动化至关重要。

Conclusion: MMBench-GUI 识别出准确的视觉基础是整体任务成功的关键决定因素，这强调了集成专用基础模块的模块化框架的巨大好处。此外，为了实现可靠的 GUI 自动化，代理需要强大的任务规划和跨平台泛化能力，其中长上下文记忆、广阔的动作空间和长期推理发挥着关键作用。更重要的是，任务效率仍然是一个极其未被充分探索的维度，并且所有模型都存在明显的效率低下问题，即使任务最终完成，也存在过多的冗余步骤。精确的定位、有效的规划和早期停止策略的整合对于实现真正高效和可扩展的 GUI 自动化是必不可少的。

Abstract: We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI
automation agents across Windows, macOS, Linux, iOS, Android, and Web
platforms. It comprises four levels: GUI Content Understanding, Element
Grounding, Task Automation, and Task Collaboration, covering essential skills
for GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)
metric to assess GUI agent execution efficiency in online automation scenarios.
Through MMBench-GUI, we identify accurate visual grounding as a critical
determinant of overall task success, emphasizing the substantial benefits of
modular frameworks that integrate specialized grounding modules. Furthermore,
to achieve reliable GUI automation, an agent requires strong task planning and
cross-platform generalization abilities, with long-context memory, a broad
action space, and long-term reasoning playing a critical role. More important,
task efficiency remains a critically underexplored dimension, and all models
suffer from substantial inefficiencies, with excessive redundant steps even
when tasks are ultimately completed. The integration of precise localization,
effective planning, and early stopping strategies is indispensable to enable
truly efficient and scalable GUI automation. Our benchmark code, evaluation
data, and running environment will be publicly available at
https://github.com/open-compass/MMBench-GUI.

</details>


### [47] [Enhancing Reward Models for High-quality Image Generation: Beyond Text-Image Alignment](https://arxiv.org/abs/2507.19002)
*Ying Ba,Tianyu Zhang,Yalong Bai,Wenyi Mo,Tao Liang,Bing Su,Ji-Rong Wen*

Main category: cs.CV

TL;DR: 现有图像评估方法存在缺陷，本研究提出了ICT和HP得分模型，提高了评估准确性，并优化了图像生成模型。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架未能跟上图像生成技术的进步，基于CLIP和BLIP的奖励模型存在缺陷，会低估具有丰富细节和高美学价值的图像。

Method: 提出了一种新的ICT（Image-Contained-Text）得分，用于评估图像对文本内容的表示程度。在此基础上，训练了一个仅使用图像模态的HP（High-Preference）得分模型，以增强图像的美学和细节质量，同时保持文本-图像一致性。

Result: 所提出的评估模型比现有方法提高了10%以上的评分准确性，并在优化先进的文本到图像模型方面取得了显著成果。

Conclusion: 本研究通过引入ICT得分和HP得分模型，改进了现有图像生成评估框架的不足，提高了评估的准确性，并显著优化了文本到图像模型，为实现更高层次的图像美学偏好提供了理论和实证支持。

Abstract: Contemporary image generation systems have achieved high fidelity and
superior aesthetic quality beyond basic text-image alignment. However, existing
evaluation frameworks have failed to evolve in parallel. This study reveals
that human preference reward models fine-tuned based on CLIP and BLIP
architectures have inherent flaws: they inappropriately assign low scores to
images with rich details and high aesthetic value, creating a significant
discrepancy with actual human aesthetic preferences. To address this issue, we
design a novel evaluation score, ICT (Image-Contained-Text) score, that
achieves and surpasses the objectives of text-image alignment by assessing the
degree to which images represent textual content. Building upon this
foundation, we further train an HP (High-Preference) score model using solely
the image modality to enhance image aesthetics and detail quality while
maintaining text-image alignment. Experiments demonstrate that the proposed
evaluation model improves scoring accuracy by over 10\% compared to existing
methods, and achieves significant results in optimizing state-of-the-art
text-to-image models. This research provides theoretical and empirical support
for evolving image generation technology toward higher-order human aesthetic
preferences. Code is available at https://github.com/BarretBa/ICTHP.

</details>


### [48] [MedSymmFlow: Bridging Generative Modeling and Classification in Medical Imaging through Symmetrical Flow Matching](https://arxiv.org/abs/2507.19098)
*Francisco Caetano,Lemar Abdi,Christiaan Viviers,Amaan Valiuddin,Fons van der Sommen*

Main category: cs.CV

TL;DR: MedSymmFlow是一个结合了分类、生成和不确定性量化的医学成像模型，在MedMNIST数据集上表现优于现有方法，并能提供可靠的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 可靠的医学图像分类需要准确的预测和良好校准的不确定性估计，尤其是在高风险的临床环境中。

Method: MedSymmFlow是一种生成-判别混合模型，基于对称流匹配，它利用了潜在空间表述和语义掩码条件机制，并能自然地通过生成采样过程来估计不确定性。

Result: 在四个MedMNIST数据集上的评估结果表明，MedSymmFlow在分类准确性和AUC方面匹配或超越了现有基线，并且能够提供可靠的不确定性估计。

Conclusion: MedSymmFlow在分类准确性和AUC方面匹配或超越了现有基线，并提供了可靠的不确定性估计，通过选择性预测下的性能改进得到了验证。

Abstract: Reliable medical image classification requires accurate predictions and
well-calibrated uncertainty estimates, especially in high-stakes clinical
settings. This work presents MedSymmFlow, a generative-discriminative hybrid
model built on Symmetrical Flow Matching, designed to unify classification,
generation, and uncertainty quantification in medical imaging. MedSymmFlow
leverages a latent-space formulation that scales to high-resolution inputs and
introduces a semantic mask conditioning mechanism to enhance diagnostic
relevance. Unlike standard discriminative models, it naturally estimates
uncertainty through its generative sampling process. The model is evaluated on
four MedMNIST datasets, covering a range of modalities and pathologies. The
results show that MedSymmFlow matches or exceeds the performance of established
baselines in classification accuracy and AUC, while also delivering reliable
uncertainty estimates validated by performance improvements under selective
prediction.

</details>


### [49] [A Survey of Multimodal Hallucination Evaluation and Detection](https://arxiv.org/abs/2507.19024)
*Zhiyuan Chen,Yuecong Min,Jie Zhang,Bei Yan,Jiahao Wang,Xiaozhen Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Multi-modal Large Language Models (MLLMs) have emerged as a powerful paradigm
for integrating visual and textual information, supporting a wide range of
multi-modal tasks. However, these models often suffer from hallucination,
producing content that appears plausible but contradicts the input content or
established world knowledge. This survey offers an in-depth review of
hallucination evaluation benchmarks and detection methods across Image-to-Text
(I2T) and Text-to-image (T2I) generation tasks. Specifically, we first propose
a taxonomy of hallucination based on faithfulness and factuality, incorporating
the common types of hallucinations observed in practice. Then we provide an
overview of existing hallucination evaluation benchmarks for both T2I and I2T
tasks, highlighting their construction process, evaluation objectives, and
employed metrics. Furthermore, we summarize recent advances in hallucination
detection methods, which aims to identify hallucinated content at the instance
level and serve as a practical complement of benchmark-based evaluation.
Finally, we highlight key limitations in current benchmarks and detection
methods, and outline potential directions for future research.

</details>


### [50] [PatchTraj: Dynamic Patch Representation Learning for Time-Frequency Trajectory Prediction](https://arxiv.org/abs/2507.19119)
*Yanghong Liu,Xingping Dong,Ming Li,Weixing Zhang,Yidong Lou*

Main category: cs.CV

TL;DR: PatchTraj：一种结合时域、频域和多尺度信息的动态斑块化轨迹预测新框架，性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有的基于点和基于网格的方法在模拟人类运动动力学方面存在不足，它们无法平衡局部的运动细节和长距离的时空依赖性，并且时间表示在轨迹序列建模中缺乏与频域的交互。

Method: 提出了一种名为PatchTraj的动态斑块（patch）化轨迹预测框架，该框架结合了时域和频域的表示。具体来说，将轨迹分解为原始时间序列和频域成分，并使用动态斑块划分进行多尺度轨迹分割，以捕捉分层运动模式。每个斑块通过自适应嵌入层进行处理，提取与尺度相关的特征，然后进行分层特征聚合，以模拟细粒度和长距离依赖关系。两种分支的输出通过交叉模态注意力进行交互，实现时域和频域线索的互补融合。最后，利用Transformer编码器-解码器将两种模态进行整合，以自回归方式预测未来轨迹。

Result: PatchTraj能够有效捕捉轨迹的层次化运动模式，并融合时域和频域信息，在多个公开数据集上实现了最先进的预测性能。

Conclusion: 该方法在ETH-UCY、SDD、NBA和JRDB数据集上进行了广泛的实验，证明了其具有高效率和最先进的性能。

Abstract: Pedestrian trajectory prediction is crucial for autonomous driving and
robotics. While existing point-based and grid-based methods expose two key
limitations: insufficiently modeling human motion dynamics, as they fail to
balance local motion details with long-range spatiotemporal dependencies, and
the time representation lacks interaction with the frequency domain in modeling
trajectory sequences. To address these challenges, we propose PatchTraj, a
dynamic patch-based trajectory prediction framework that unifies time-domain
and frequency-domain representations. Specifically, we decompose the trajectory
into raw time sequences and frequency components, employing dynamic patch
partitioning for multi-scale trajectory segmentation to capture hierarchical
motion patterns. Each patch is processed by an adaptive embedding layer with
scale-aware feature extraction, followed by hierarchical feature aggregation to
model both fine-grained and long-range dependencies. The outputs of two
branches interact via cross-modal attention, enabling complementary fusion of
temporal and spectral cues. Finally, a Transformer encoder-decoder integrates
both modalities to autoregressively predict future trajectories. Extensive
experiments on ETH-UCY, SDD, NBA, and JRDB datasets demonstrate that our method
achieves state-of-the-art performance with high efficiency.

</details>


### [51] [Probing Multimodal Fusion in the Brain: The Dominance of Audiovisual Streams in Naturalistic Encoding](https://arxiv.org/abs/2507.19052)
*Hamid Abdollahi,Amir Hossein Mansouri Majoumerd,Amir Hossein Bagheri Baboukani,Amir Abolfazl Suratgar,Mohammad Bagher Menhaj*

Main category: cs.CV

TL;DR: 计算神经科学研究发现，在预测大脑活动时，更简单的模型在面对新情况时比复杂模型更有效。在听觉皮层区域，使用高质量语音特征的模型效果更好。


<details>
  <summary>Details</summary>
Motivation: 预测大脑对自然、多模态刺激的反应是计算神经科学中的一个关键挑战，而现有编码模型在真正新颖情境下的泛化能力仍然是一个关键且未经充分检验的问题。

Method: 研究人员开发了使用先进的视觉（X-CLIP）和听觉（Whisper）特征提取器的大脑编码模型，并严格评估了它们在分布内（ID）和分布外（OOD）数据上的表现。

Result: 研究结果揭示了模型复杂度与泛化能力之间的基本权衡：一个高容量的基于注意力的模型在ID数据上表现优异，但一个更简单的线性模型更为鲁棒，在OOD数据集上比有竞争力的基线模型提高了18%。语言特征并未提高预测准确性，但该方法在听觉皮层取得了显著的性能提升。

Conclusion: 该研究强调了在构建神经-AI模型时，严格的分布外（OOD）测试对于提高模型的鲁棒性至关重要。研究结果表明，模型复杂度与泛化能力之间存在根本性的权衡：高容量模型在分布内（ID）数据上表现优异，但简单的线性模型在OOD数据上更具鲁棒性。此外，研究还发现语言特征并未提高预测准确性，并且在听觉皮层取得了显著的性能提升，这表明高保真语音表征的益处。

Abstract: Predicting brain activity in response to naturalistic, multimodal stimuli is
a key challenge in computational neuroscience. While encoding models are
becoming more powerful, their ability to generalize to truly novel contexts
remains a critical, often untested, question. In this work, we developed brain
encoding models using state-of-the-art visual (X-CLIP) and auditory (Whisper)
feature extractors and rigorously evaluated them on both in-distribution (ID)
and diverse out-of-distribution (OOD) data. Our results reveal a fundamental
trade-off between model complexity and generalization: a higher-capacity
attention-based model excelled on ID data, but a simpler linear model was more
robust, outperforming a competitive baseline by 18\% on the OOD set.
Intriguingly, we found that linguistic features did not improve predictive
accuracy, suggesting that for familiar languages, neural encoding may be
dominated by the continuous visual and auditory streams over redundant textual
information. Spatially, our approach showed marked performance gains in the
auditory cortex, underscoring the benefit of high-fidelity speech
representations. Collectively, our findings demonstrate that rigorous OOD
testing is essential for building robust neuro-AI models and provides nuanced
insights into how model architecture, stimulus characteristics, and sensory
hierarchies shape the neural encoding of our rich, multimodal world.

</details>


### [52] [ScenePainter: Semantically Consistent Perpetual 3D Scene Generation with Concept Relation Alignment](https://arxiv.org/abs/2507.19058)
*Chong Xia,Shengjun Zhang,Fangfu Liu,Chang Liu,Khodchaphun Hirunyaratsameewong,Yueqi Duan*

Main category: cs.CV

TL;DR: ScenePainter框架通过引入SceneConceptGraph来解决3D场景生成中的语义漂移问题，生成更一致、更具沉浸感的视图序列。


<details>
  <summary>Details</summary>
Motivation: 现有的“导航-想象”范式依赖于图像修复（outpainting）来进行连续视图扩展，但会因修复模块的累积偏差而导致语义漂移问题。

Method: 提出了一种名为SceneConceptGraph的分层图结构来构建多层次场景概念之间的关系，以此来指导图像修复模块生成一致的新视图，并且该结构可以动态细化以增强多样性。

Result: 通过大量实验证明，该框架能够克服语义漂移问题，生成更一致、更具沉浸感的3D视图序列。

Conclusion: 提出的ScenePainter框架克服了语义漂移问题，生成的3D视图序列更具一致性和沉浸感。

Abstract: Perpetual 3D scene generation aims to produce long-range and coherent 3D view
sequences, which is applicable for long-term video synthesis and 3D scene
reconstruction. Existing methods follow a "navigate-and-imagine" fashion and
rely on outpainting for successive view expansion. However, the generated view
sequences suffer from semantic drift issue derived from the accumulated
deviation of the outpainting module. To tackle this challenge, we propose
ScenePainter, a new framework for semantically consistent 3D scene generation,
which aligns the outpainter's scene-specific prior with the comprehension of
the current scene. To be specific, we introduce a hierarchical graph structure
dubbed SceneConceptGraph to construct relations among multi-level scene
concepts, which directs the outpainter for consistent novel views and can be
dynamically refined to enhance diversity. Extensive experiments demonstrate
that our framework overcomes the semantic drift issue and generates more
consistent and immersive 3D view sequences. Project Page:
https://xiac20.github.io/ScenePainter/.

</details>


### [53] [Revisiting DETR for Small Object Detection via Noise-Resilient Query Optimization](https://arxiv.org/abs/2507.19059)
*Xiaocheng Fang,Jieyi Cai,Huanyu Liu,Wenxiu Cai,Yishu Liu,Bingzhi Chen*

Main category: cs.CV

TL;DR: 提出了一种新颖的噪声鲁棒查询优化（NRQO）范式，通过结合 NT-FPN 和 PS-RPN 来解决 Transformer 小目标检测中的噪声敏感性和查询质量问题，并在实验中证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于 Transformer 的小目标检测器仍然面临由特征金字塔网络（FPN）中的固有噪声敏感性以及现有标签分配策略中查询质量下降所带来的挑战。

Method: 提出了一种新颖的噪声鲁棒查询优化（NRQO）范式，该范式结合了噪声容忍特征金字塔网络（NT-FPN）和成对相似性区域提议网络（PS-RPN）。NT-FPN 通过保持空间和语义信息的完整性来减轻 FPN 中特征融合过程中的噪声。PS-RPN 通过增强锚点-真实边界框匹配来生成足够的高质量正样本查询，该匹配利用位置和形状相似性，并且不需要额外的超参数。

Result: 在多个基准测试上的大量实验一致表明，NRQO 优于现有基线方法。

Conclusion: NRQO 优于现有基线方法。

Abstract: Despite advancements in Transformer-based detectors for small object
detection (SOD), recent studies show that these detectors still face challenges
due to inherent noise sensitivity in feature pyramid networks (FPN) and
diminished query quality in existing label assignment strategies. In this
paper, we propose a novel Noise-Resilient Query Optimization (NRQO) paradigm,
which innovatively incorporates the Noise-Tolerance Feature Pyramid Network
(NT-FPN) and the Pairwise-Similarity Region Proposal Network (PS-RPN).
Specifically, NT-FPN mitigates noise during feature fusion in FPN by preserving
spatial and semantic information integrity. Unlike existing label assignment
strategies, PS-RPN generates a sufficient number of high-quality positive
queries by enhancing anchor-ground truth matching through position and shape
similarities, without the need for additional hyperparameters. Extensive
experiments on multiple benchmarks consistently demonstrate the superiority of
NRQO over state-of-the-art baselines.

</details>


### [54] [Negation-Aware Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2507.19064)
*Haochen Han,Alex Jinpeng Wang,Fangming Liu*

Main category: cs.CV

TL;DR: 视觉语言模型在理解否定方面存在不足。本文提出了一种名为NEAT的测试时适应方法，以低碳的方式解决这个问题，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的应用（如放射学）需要模型能够识别虚假或不存在的事物，但现有的VLMs在处理否定方面存在严重缺陷，而现有的解决方案（如数据增强）需要大量资源。

Method: 提出了一种名为NEAT（Negation-Aware Test-Time Adaptation）的方法，该方法在推理过程中调整与分布相关的参数，以减少双概念移位，从而有效处理否定理解问题。

Result: NEAT方法在多项否定理解任务的广泛实验中验证了其有效性，能够减少一致语义中的分布移位，并消除不相关语义中的虚假分布一致性。

Conclusion: 该研究提出了NEAT方法，旨在解决视觉语言模型（VLMs）在处理否定理解时的局限性，通过在测试时进行适应性调整来提高模型性能。

Abstract: In this paper, we study a practical but less-touched problem in
Vision-Language Models (VLMs), \ie, negation understanding. Specifically, many
real-world applications require models to explicitly identify what is false or
non-existent, \eg, radiologists may search for images that exclude specific
conditions. Despite the impressive transferability of VLMs through large-scale
training, they suffer from a critical limitation that fails to handle negation.
To address this challenge, existing methods attribute its root cause to the
scarcity of negation training data and propose to fine-tune VLMs on massive
data containing explicit negation. Undoubtedly, such data-centric solutions
demand substantial data and computational resources, limiting their sustainable
widespread adoption. To tackle negation in a low-carbon manner, we empirically
observe that the key obstacle lies in the dual-concept shifts between the
affirmation and negation distributions. Therefore, we propose a Negation-Aware
Test-Time Adaptation (NEAT) method to efficiently adjust distribution-related
parameters during inference. In brief, NEAT can reduce distribution shift in
consistent semantics while eliminating false distributional consistency in
unrelated semantics. Extensive experiments on the various negation
understanding tasks verify the effectiveness of the proposed method. The code
is available at https://github.com/hhc1997/NEAT.

</details>


### [55] [Cross-Subject Mind Decoding from Inaccurate Representations](https://arxiv.org/abs/2507.19071)
*Yangyang Xu,Bangzhen Liu,Wenqi Shao,Yong Du,Shengfeng He,Tingting Zhu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的双向自编码器框架，用于从fMRI信号中更准确地解码刺激图像，解决了跨受试者映射的挑战，并在实验中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨受试者映射方面存在困难，因为认知变异性和受试者特异性差异会导致累积误差，降低重建保真度。

Method: 提出了一种名为“双向自编码器交织”（Bidirectional Autoencoder Intertwining）的框架，该框架整合了受试者偏见调制模块、语义精炼模块和视觉连贯性模块，并与ControlNet和Stable Diffusion集成。

Result: 在基准数据集上，与最先进的方法相比，该方法在定性和定量评估中均表现出色，并对具有最少训练样本的新受试者表现出强大的适应性。

Conclusion: 该框架通过引入受试者偏见调制模块统一了多个受试者，并利用双向映射来更好地捕获数据分布以进行精确表示预测，在定性和定量评估中均优于最先进的方法，并能以最少的训练样本适应新受试者。

Abstract: Decoding stimulus images from fMRI signals has advanced with pre-trained
generative models. However, existing methods struggle with cross-subject
mappings due to cognitive variability and subject-specific differences. This
challenge arises from sequential errors, where unidirectional mappings generate
partially inaccurate representations that, when fed into diffusion models,
accumulate errors and degrade reconstruction fidelity. To address this, we
propose the Bidirectional Autoencoder Intertwining framework for accurate
decoded representation prediction. Our approach unifies multiple subjects
through a Subject Bias Modulation Module while leveraging bidirectional mapping
to better capture data distributions for precise representation prediction. To
further enhance fidelity when decoding representations into stimulus images, we
introduce a Semantic Refinement Module to improve semantic representations and
a Visual Coherence Module to mitigate the effects of inaccurate visual
representations. Integrated with ControlNet and Stable Diffusion, our method
outperforms state-of-the-art approaches on benchmark datasets in both
qualitative and quantitative evaluations. Moreover, our framework exhibits
strong adaptability to new subjects with minimal training samples.

</details>


### [56] [SP-Mamba: Spatial-Perception State Space Model for Unsupervised Medical Anomaly Detection](https://arxiv.org/abs/2507.19076)
*Rui Pan,Ruiying Lu*

Main category: cs.CV

TL;DR: SP-Mamba是一种利用Mamba模型进行医学图像异常检测的新框架，通过结合空间感知机制和优化的Mamba扫描方法，解决了现有方法的局限性，并在实验中证明了其优越的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN和Transformer的方法在医学异常检测中存在捕捉长距离依赖性不足或计算复杂度过高的问题。Mamba模型因其优越的长距离建模能力、结构特征提取能力和线性计算效率，成为一种有前景的替代方案。本研究旨在利用医学图像固有的结构规律性来改进异常检测。

Method: 提出了一种名为SP-Mamba的空间感知Mamba框架，用于无监督医学图像异常检测。该框架结合了窗口滑动原型学习和基于Circular-Hilbert扫描的Mamba，以更好地利用解剖结构规律和空间信息。此外，还研究了异常图谱的浓度和对比度特征以改进检测效果。

Result: SP-Mamba在三个医学异常检测基准测试中均取得了最先进的性能。

Conclusion: SP-Mamba在三个不同的医学异常检测基准上取得了最先进的性能，验证了其有效性和鲁棒性。

Abstract: Radiography imaging protocols target on specific anatomical regions,
resulting in highly consistent images with recurrent structural patterns across
patients. Recent advances in medical anomaly detection have demonstrated the
effectiveness of CNN- and transformer-based approaches. However, CNNs exhibit
limitations in capturing long-range dependencies, while transformers suffer
from quadratic computational complexity. In contrast, Mamba-based models,
leveraging superior long-range modeling, structural feature extraction, and
linear computational efficiency, have emerged as a promising alternative. To
capitalize on the inherent structural regularity of medical images, this study
introduces SP-Mamba, a spatial-perception Mamba framework for unsupervised
medical anomaly detection. The window-sliding prototype learning and
Circular-Hilbert scanning-based Mamba are introduced to better exploit
consistent anatomical patterns and leverage spatial information for medical
anomaly detection. Furthermore, we excavate the concentration and contrast
characteristics of anomaly maps for improving anomaly detection. Extensive
experiments on three diverse medical anomaly detection benchmarks confirm the
proposed method's state-of-the-art performance, validating its efficacy and
robustness. The code is available at https://github.com/Ray-RuiPan/SP-Mamba.

</details>


### [57] [Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes](https://arxiv.org/abs/2507.19304)
*Muhammad Ibrahim,Naveed Akhtar,Haitian Wang,Saeed Anwar,Ajmal Mian*

Main category: cs.CV

TL;DR: MuStD是一种多流网络，通过融合LiDAR和RGB数据来提高户外3D目标检测的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决户外3D目标检测中融合LiDAR和RGB数据的挑战，并实现更精确的目标检测。

Method: 提出了一种名为MuStD的多流网络，该网络包括LiDAR-PillarNet流、LiDAR-Height Compression流和3D Multimodal流，通过UV映射和极坐标索引融合LiDAR和RGB特征。

Result: 在KITTI数据集上实现了最先进或非常有竞争力的结果，并且效率很高。

Conclusion: MuStD网络在KITTI数据集上取得了最先进或非常有竞争力的结果，同时保持了高效率。

Abstract: Fusion of LiDAR and RGB data has the potential to enhance outdoor 3D object
detection accuracy. To address real-world challenges in outdoor 3D object
detection, fusion of LiDAR and RGB input has started gaining traction. However,
effective integration of these modalities for precise object detection task
still remains a largely open problem. To address that, we propose a MultiStream
Detection (MuStD) network, that meticulously extracts task-relevant information
from both data modalities. The network follows a three-stream structure. Its
LiDAR-PillarNet stream extracts sparse 2D pillar features from the LiDAR input
while the LiDAR-Height Compression stream computes Bird's-Eye View features. An
additional 3D Multimodal stream combines RGB and LiDAR features using UV
mapping and polar coordinate indexing. Eventually, the features containing
comprehensive spatial, textural and geometric information are carefully fused
and fed to a detection head for 3D object detection. Our extensive evaluation
on the challenging KITTI Object Detection Benchmark using public testing server
at
https://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0
establishes the efficacy of our method by achieving new state-of-the-art or
highly competitive results in different categories while remaining among the
most efficient methods. Our code will be released through MuStD GitHub
repository at https://github.com/IbrahimUWA/MuStD.git

</details>


### [58] [Multi-Task Dense Prediction Fine-Tuning with Mixture of Fine-Grained Experts](https://arxiv.org/abs/2507.19077)
*Yangyang Xu,Xi Ye,Duo Su*

Main category: cs.CV

TL;DR: 提出FGMoE架构，通过通道内专家、共享专家和全局专家，改进了密集预测中的多任务学习，在NYUD-v2和PASCAL-Context数据集上取得了更好的性能和更低的参数量。


<details>
  <summary>Details</summary>
Motivation: 解决多任务学习（MTL）在密集预测中平衡共享表征与任务特定专业化所面临的挑战。

Method: 提出了一种新颖的细粒度混合专家（FGMoE）架构，通过结合三种关键创新和微调来实现：1）提出通道内的专家，沿着MLP中间隐藏维度进行划分，在保持参数效率的同时，实现更细粒度的任务信息分解；2）引入共享专家，整合同一任务不同上下文中的共同信息，减少冗余，并允许路由专家专注于独特的方面；3）设计了一个全局专家，根据输入特征和任务需求促进跨任务的自适应知识转移，促进有益的信息共享，同时防止有害的干扰。此外，通过仅训练解码器的参数来提高参数效率。

Result: FGMoE模型比现有的基于MoE的竞争性MTL模型表现更好，且参数更少。

Conclusion: FGMoE模型在NYUD-v2和PASCAL-Context两个密集预测数据集上，在各种指标上显著优于当前基于MoE的竞争性MTL模型，同时使用的参数更少。

Abstract: Multi-task learning (MTL) for dense prediction has shown promising results
but still faces challenges in balancing shared representations with
task-specific specialization. In this paper, we introduce a novel Fine-Grained
Mixture of Experts (FGMoE) architecture that explores MoE-based MTL models
through a combination of three key innovations and fine-tuning. First, we
propose intra-task experts that partition along intermediate hidden dimensions
of MLPs, enabling finer decomposition of task information while maintaining
parameter efficiency. Second, we introduce shared experts that consolidate
common information across different contexts of the same task, reducing
redundancy, and allowing routing experts to focus on unique aspects. Third, we
design a global expert that facilitates adaptive knowledge transfer across
tasks based on both input feature and task requirements, promoting beneficial
information sharing while preventing harmful interference. In addition, we use
the fine-tuning approach to improve parameter efficiency only by training the
parameters of the decoder. Extensive experimental results show that the
proposed FGMoE uses fewer parameters and significantly outperforms current
MoE-based competitive MTL models on two dense prediction datasets
(\textit{i.e.,} NYUD-v2, PASCAL-Context) in various metrics.

</details>


### [59] [SIDE: Sparse Information Disentanglement for Explainable Artificial Intelligence](https://arxiv.org/abs/2507.19321)
*Viktar Dubovik,Łukasz Struski,Jacek Tabor,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: SIDE, a new method, makes deep neural network explanations (using prototypical parts) much simpler (over 90% smaller) without losing accuracy, making them easier to understand for tasks like medical imaging and autonomous driving.


<details>
  <summary>Details</summary>
Motivation: Understanding decisions made by deep neural networks is crucial in high-stakes domains like medical imaging and autonomous driving. Existing prototypical-parts-based neural networks offer concept-level explanations but are often limited to fine-grained classification tasks or produce complex explanations for large-scale datasets.

Method: Introduced Sparse Information Disentanglement for Explainability (SIDE), a novel method that enhances the interpretability of prototypical parts through a dedicated training and pruning scheme that enforces sparsity. Combined with sigmoid activations instead of softmax, this approach associates each class with a small set of relevant prototypes.

Result: SIDE reduces explanation size by over 90% while maintaining comparable accuracy to existing methods.

Conclusion: SIDE matches existing methods' accuracy while reducing explanation size by over 90%, significantly improving the understandability of prototype-based explanations.

Abstract: Understanding the decisions made by deep neural networks is essential in
high-stakes domains such as medical imaging and autonomous driving. Yet, these
models often lack transparency, particularly in computer vision.
Prototypical-parts-based neural networks have emerged as a promising solution
by offering concept-level explanations. However, most are limited to
fine-grained classification tasks, with few exceptions such as InfoDisent.
InfoDisent extends prototypical models to large-scale datasets like ImageNet,
but produces complex explanations.
  We introduce Sparse Information Disentanglement for Explainability (SIDE), a
novel method that improves the interpretability of prototypical parts through a
dedicated training and pruning scheme that enforces sparsity. Combined with
sigmoid activations in place of softmax, this approach allows SIDE to associate
each class with only a small set of relevant prototypes. Extensive experiments
show that SIDE matches the accuracy of existing methods while reducing
explanation size by over $90\%$, substantially enhancing the understandability
of prototype-based explanations.

</details>


### [60] [LISA: A Layer-wise Integration and Suppression Approach for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org/abs/2507.19110)
*Zhihui Guo,Xin Man,Hui Xu,Jie Shao*

Main category: cs.CV

TL;DR: LISA reduces object hallucinations in MLLMs by suppressing spurious signals in deeper layers and adaptively fusing information from different layers, improving generation consistency and performance.


<details>
  <summary>Details</summary>
Motivation: MLLMs suffer from object hallucinations, describing objects not present in images. This work aims to mitigate this issue by enhancing generation consistency through hierarchical modulation and multi-layer fusion.

Method: LISA employs a layer-wise integration and suppression approach. It utilizes zone-specific spectral modulation to stabilize attention by suppressing over-amplified activations in deeper layers while preserving alignment cues in earlier layers. Additionally, it uses token-level logits fusion via anchor-based routing, with token-wise anchor selection and soft logit fusion for adaptive integration during decoding.

Result: LISA reduces hallucinations by up to 53.6% in CHAIR_I and improves POPE F1 by 4.5%, demonstrating strong generalization across models and tasks. It can be seamlessly integrated into existing MLLMs like Qwen2.5-VL.

Conclusion: LISA is a plug-and-play approach that can be integrated into existing MLLMs to reduce object hallucinations and improve generation consistency. Experiments show significant improvements in reducing hallucinations and enhancing POPE F1 scores across different models and tasks.

Abstract: Multimodal Large Language Models (MLLMs) excel in vision-language tasks such
as image captioning but remain prone to object hallucinations, where they
describe objects that do not appear in the image. To mitigate this, we propose
\textbf{LISA}, a \textbf{L}ayer-wise \textbf{I}ntegration and
\textbf{S}uppression \textbf{A}pproach that enhances generation consistency
through hierarchical modulation and multi-layer fusion. LISA leverages the
functional hierarchy within MLLMs, where shallow layers provide visual
grounding, middle layers encode semantics, and deep layers tend to amplify
spurious signals. First, zone-specific spectral modulation stabilizes attention
by suppressing over-amplified activations in deeper layers while preserving
alignment cues in earlier layers. Second, token-level logits from selected
layers are fused via anchor-based routing, with token-wise anchor selection and
soft logit fusion enabling adaptive integration during decoding. LISA is fully
\textbf{plug-and-play} and can be seamlessly integrated into existing MLLMs,
including Qwen2.5-VL. Experiments on multiple benchmarks show that LISA reduces
hallucinations by up to 53.6\% in $\mathrm{CHAIR}_I$ and improves POPE F1 by
4.5\%, demonstrating strong generalization across models and tasks.

</details>


### [61] [Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching](https://arxiv.org/abs/2507.19118)
*Abu Sadat Mohammad Salehin Amit,Xiaoli Zhang,Md Masum Billa Shagar,Zhaojun Liu,Xiongfei Li,Fanlong Meng*

Main category: cs.CV

TL;DR: 该研究提出了一种名为CSTF的跨空间时间融合机制，通过结合多尺度关键点和将匹配重构为分类任务，显著提高了跨模态遥感图像匹配的准确性，并在目标检测任务中取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感图像匹配方法在提取特征时主要依赖全连接层，往往无法有效捕捉跨模态的相似性，这是由于多模态图像之间存在显著的几何和辐射差异。

Method: 提出了一种跨空间时间融合（CSTF）机制，通过集成在参考和查询图像中独立检测到的尺度不变关键点来增强特征表示。该方法通过创建同时利用多个图像区域信息的对应图，并将相似性匹配重新表述为使用SoftMax和全卷积网络（FCN）层的分类任务，从而在两个方面改进了特征匹配。

Result: CSTF模型在HRSC2016数据集上实现了90.99%的平均mAP，在DOTA数据集上实现了90.86%的平均mAP，超越了现有模型。此外，该模型推理速度达到12.5 FPS，验证了其在目标检测等下游遥感应用中的实用性。

Conclusion: 所提出的跨空间时间融合（CSTF）机制通过整合多图像区域信息和将相似性匹配重构为分类任务，有效地解决了跨模态遥感图像匹配的挑战，并在HRSC2016和DOTA基准数据集上实现了最先进的目标检测性能，同时保持了计算效率。

Abstract: Effectively describing features for cross-modal remote sensing image matching
remains a challenging task due to the significant geometric and radiometric
differences between multimodal images. Existing methods primarily extract
features at the fully connected layer but often fail to capture cross-modal
similarities effectively. We propose a Cross Spatial Temporal Fusion (CSTF)
mechanism that enhances feature representation by integrating scale-invariant
keypoints detected independently in both reference and query images. Our
approach improves feature matching in two ways: First, by creating
correspondence maps that leverage information from multiple image regions
simultaneously, and second, by reformulating the similarity matching process as
a classification task using SoftMax and Fully Convolutional Network (FCN)
layers. This dual approach enables CSTF to maintain sensitivity to distinctive
local features while incorporating broader contextual information, resulting in
robust matching across diverse remote sensing modalities. To demonstrate the
practical utility of improved feature matching, we evaluate CSTF on object
detection tasks using the HRSC2016 and DOTA benchmark datasets. Our method
achieves state-of-theart performance with an average mAP of 90.99% on HRSC2016
and 90.86% on DOTA, outperforming existing models. The CSTF model maintains
computational efficiency with an inference speed of 12.5 FPS. These results
validate that our approach to crossmodal feature matching directly enhances
downstream remote sensing applications such as object detection.

</details>


### [62] [Preserving Topological and Geometric Embeddings for Point Cloud Recovery](https://arxiv.org/abs/2507.19121)
*Kaiyue Zhou,Zelong Tan,Hongxiao Wang,Ya-li Li,Shengjin Wang*

Main category: cs.CV

TL;DR: 提出TopGeoFormer端到端架构，结合拓扑和几何属性，通过交织注意力机制和新的损失函数，提升点云恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在点云恢复的采样和恢复阶段难以有效利用拓扑和几何属性。

Method: 提出了一种名为TopGeoFormer的端到端架构，该架构在采样和恢复阶段都利用拓扑和几何属性。具体包括：1. 提出拓扑嵌入，使用邻近点之间相对关系的连续映射来保留原始空间的结构。2. 提出交织注意力（InterTwining Attention），融合拓扑和几何嵌入，通过点-点、点-形状和形状内特征进行学习。3. 引入完整的几何损失和拓扑约束损失来优化欧氏和拓扑空间中的嵌入。

Result: 定量和定性结果表明，所提出的方法在采样和恢复方面显著优于现有方法。

Conclusion: 实验结果表明，所提出的方法在采样和恢复方面显著优于现有方法。

Abstract: Recovering point clouds involves the sequential process of sampling and
restoration, yet existing methods struggle to effectively leverage both
topological and geometric attributes. To address this, we propose an end-to-end
architecture named \textbf{TopGeoFormer}, which maintains these critical
features throughout the sampling and restoration phases. First, we revisit
traditional feature extraction techniques to yield topological embedding using
a continuous mapping of relative relationships between neighboring points, and
integrate it in both phases for preserving the structure of the original space.
Second, we propose the \textbf{InterTwining Attention} to fully merge
topological and geometric embeddings, which queries shape with local awareness
in both phases to form a learnable shape context facilitated with point-wise,
point-shape-wise, and intra-shape features. Third, we introduce a full geometry
loss and a topological constraint loss to optimize the embeddings in both
Euclidean and topological spaces. The geometry loss uses inconsistent matching
between coarse-to-fine generations and targets for reconstructing better
geometric details, and the constraint loss limits embedding variances for
better approximation of the topological space. In experiments, we
comprehensively analyze the circumstances using the conventional and
learning-based sampling/upsampling algorithms. The quantitative and qualitative
results demonstrate that our method significantly outperforms existing sampling
and recovery methods.

</details>


### [63] [MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective](https://arxiv.org/abs/2507.19131)
*Weitian Wang,Rai Shubham,Cecilia De La Parra,Akash Kumar*

Main category: cs.CV

TL;DR: MixA-Q是一种混合精度激活量化框架，利用激活稀疏性提高视觉Transformer的效率，可在不损失精度的情况下实现高达1.35倍的加速。


<details>
  <summary>Details</summary>
Motivation: 为了实现量化的基于窗口的视觉Transformer的高效推理，并改善模型性能与效率之间的权衡。

Method: MixA-Q框架通过分离Swin块内的批处理窗口计算，并将较低的比特宽度分配给不重要的窗口激活，利用层内激活稀疏性来实现混合精度激活量化。它引入了一个两分支Swin块，分别处理高比特和低比特精度的激活，从而可以与大多数量化感知训练（QAT）和训练后量化（PTQ）方法无缝集成。

Result: MixA-Q在COCO数据集上的实验评估显示，在PTQ配置下，MixA-Q实现了无训练的1.35倍计算加速，且精度无损失。在QAT配置下，MixA-Q实现了1.25倍的无损加速，并且通过结合激活剪枝实现了1.53倍的加速，而mAP仅下降1%。值得注意的是，通过减少重要区域的量化误差，其感知量化适应性将W4A4模型的mAP提高了0.7%，将量化损失降低了24%。

Conclusion: MixA-Q通过利用层内激活稀疏性，为量化的基于窗口的视觉Transformer实现了高效推理，在PTQ配置下实现了1.35倍的计算加速且无精度损失，在QAT配置下实现了1.25倍的无损加速，并能通过结合激活剪枝实现1.53倍的加速而mAP仅下降1%。此外，通过减少重要区域的量化误差，其感知量化适应性将W4A4模型的mAP提高了0.7%，将量化损失降低了24%。

Abstract: In this paper, we propose MixA-Q, a mixed-precision activation quantization
framework that leverages intra-layer activation sparsity (a concept widely
explored in activation pruning methods) for efficient inference of quantized
window-based vision transformers. For a given uniform-bit quantization
configuration, MixA-Q separates the batched window computations within Swin
blocks and assigns a lower bit width to the activations of less important
windows, improving the trade-off between model performance and efficiency. We
introduce a Two-Branch Swin Block that processes activations separately in
high- and low-bit precision, enabling seamless integration of our method with
most quantization-aware training (QAT) and post-training quantization (PTQ)
methods, or with simple modifications. Our experimental evaluations over the
COCO dataset demonstrate that MixA-Q achieves a training-free 1.35x
computational speedup without accuracy loss in PTQ configuration. With QAT,
MixA-Q achieves a lossless 1.25x speedup and a 1.53x speedup with only a 1% mAP
drop by incorporating activation pruning. Notably, by reducing the quantization
error in important regions, our sparsity-aware quantization adaptation improves
the mAP of the quantized W4A4 model (with both weights and activations in 4-bit
precision) by 0.7%, reducing quantization degradation by 24%.

</details>


### [64] [CXR-CML: Improved zero-shot classification of long-tailed multi-label diseases in Chest X-Rays](https://arxiv.org/abs/2507.19398)
*Rajesh Madhipati,Sheethal Bhat,Lukas Buess,Andreas Maier*

Main category: cs.CV

TL;DR: 通过在高斯混合模型和学生t分布的帮助下，对CLIP的潜在空间进行聚类和细化，并引入度量损失，解决了长尾分布问题，显著提高了罕见类别在胸部X光片分类中的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的自监督深度学习模型在处理临床长尾分布数据时存在挑战，容易在长尾类别上出现分类不准确的问题。尽管CLIP等视觉-语言模型在主要类别上表现良好，但在长尾分布类别上的有效性会显著下降。

Method: 该方法首先使用高斯混合模型（GMM）对潜在空间进行聚类，然后利用学生t分布对初始聚类进行细化，最后应用一种利用修改后嵌入的度量损失，以实现对特征的稳定和自适应聚类。

Result: 通过采用与类别在潜在空间分布相一致的类别加权机制，该方法实现了整体分类性能的显著提升，特别是在罕见类别的识别和准确性方面。在MIMIC-CXR-JPG数据集的40个类别上，零样本AUC得分平均提高了7个百分点。

Conclusion: 该方法通过在潜在空间中应用高斯混合模型（GMM）聚类，并用学生t分布对聚类进行细化，然后使用利用修改后嵌入的度量损失，实现了对特征的稳定和自适应聚类，从而在MIMIC-CXR-JPG数据集中40个类别的零样本AUC得分方面，相比之前的SOTA模型平均提高了7个百分点，尤其提高了罕见类别的识别和准确性。

Abstract: Chest radiography (CXR) plays a crucial role in the diagnosis of various
diseases. However, the inherent class imbalance in the distribution of clinical
findings presents a significant challenge for current self-supervised deep
learning models. These models often fail to accurately classify long-tailed
classes. Current Vision-Language models such as Contrastive Language Image
Pre-training (CLIP) models effectively model the manifold distribution of the
latent space, enabling high zero-shot classification accuracies. Although CLIP
performs well on most of the primary classes in the dataset, our work reveals
that its effectiveness decreases significantly for classes with a long-tailed
distribution. Our approach employs a class-weighting mechanism that directly
aligns with the distribution of classes within the latent space. This method
ensures a substantial improvement in overall classification performance, with
particular emphasis on enhancing the recognition and accuracy of rarely
observed classes. We accomplish this by applying Gaussian Mixture Model (GMM)
clustering to the latent space. The subsequent clusters are further refined by
Student t-distribution, followed by a metric loss that utilizes the altered
embeddings. Our approach facilitates stable and adaptive clustering of the
features. This results in a notable average improvement of 7\% points in
zero-shot AUC scores across 40 classes in the MIMIC-CXR-JPG dataset from
previous SOTA models.

</details>


### [65] [Balancing Conservatism and Aggressiveness: Prototype-Affinity Hybrid Network for Few-Shot Segmentation](https://arxiv.org/abs/2507.19140)
*Tianyu Zou,Shengwu Xiong,Ruilin Yao,Yi Rong*

Main category: cs.CV

TL;DR: This paper studies few-shot segmentation (FSS) and proposes PAHNet, a hybrid network that balances conservative and aggressive prediction strategies by combining prototype and affinity learning methods. PAHNet enhances segmentation accuracy and outperforms existing methods on benchmark datasets.


<details>
  <summary>Details</summary>
Motivation: Analysis of two mainstream FSS paradigms revealed that prototype learning methods make conservative predictions, while affinity learning methods make aggressive predictions. This motivates the paper to balance the conservative and aggressive information captured by these two frameworks to improve segmentation performance.

Method: The paper proposes a Prototype-Affinity Hybrid Network (PAHNet), which introduces a Prototype-guided Feature Enhancement (PFE) module and an Attention Score Calibration (ASC) module in each attention block of an affinity learning model. These modules use predictions from a prototype learning model to enhance foreground information and suppress mismatched foreground-background relationships, thereby mitigating the aggressiveness of the affinity learner and increasing segmentation accuracy.

Result: Experimental results show that PAHNet outperforms most recently proposed methods across 1-shot and 5-shot settings on both PASCAL-5$^i$ and COCO-20$^i$ datasets.

Conclusion: PAHNet outperforms most recently proposed methods across 1-shot and 5-shot settings on both PASCAL-5$^i$ and COCO-20$^i$ datasets, suggesting its effectiveness.

Abstract: This paper studies the few-shot segmentation (FSS) task, which aims to
segment objects belonging to unseen categories in a query image by learning a
model on a small number of well-annotated support samples. Our analysis of two
mainstream FSS paradigms reveals that the predictions made by prototype
learning methods are usually conservative, while those of affinity learning
methods tend to be more aggressive. This observation motivates us to balance
the conservative and aggressive information captured by these two types of FSS
frameworks so as to improve the segmentation performance. To achieve this, we
propose a **P**rototype-**A**ffinity **H**ybrid **Net**work (PAHNet), which
introduces a Prototype-guided Feature Enhancement (PFE) module and an Attention
Score Calibration (ASC) module in each attention block of an affinity learning
model (called affinity learner). These two modules utilize the predictions
generated by a pre-trained prototype learning model (called prototype
predictor) to enhance the foreground information in support and query image
representations and suppress the mismatched foreground-background (FG-BG)
relationships between them, respectively. In this way, the aggressiveness of
the affinity learner can be effectively mitigated, thereby eventually
increasing the segmentation accuracy of our PAHNet method. Experimental results
show that PAHNet outperforms most recently proposed methods across 1-shot and
5-shot settings on both PASCAL-5$^i$ and COCO-20$^i$ datasets, suggesting its
effectiveness. The code is available at: [GitHub - tianyu-zou/PAHNet: Balancing
Conservatism and Aggressiveness: Prototype-Affinity Hybrid Network for Few-Shot
Segmentation (ICCV'25)](https://github.com/tianyu-zou/PAHNet)

</details>


### [66] [DASH: 4D Hash Encoding with Self-Supervised Decomposition for Real-Time Dynamic Scene Rendering](https://arxiv.org/abs/2507.19141)
*Jie Chen,Zhangchi Hu,Peixi Wu,Huyue Zhu,Hebei Li,Xiaoyan Sun*

Main category: cs.CV

TL;DR: DASH 是一个创新的实时动态场景渲染框架，通过自监督分解和多分辨率 4D 哈希编码解决了现有方法的局限性，实现了高质量和高帧率的渲染。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于平面方法在动态高斯泼溅中存在的低秩假设不适用、特征重叠和渲染质量差的问题，以及直接将 4D 哈希编码应用于整个动态场景导致的哈希冲突和冗余问题。

Method: DASH 框架采用 4D 哈希编码和自监督分解。首先，通过自监督分解机制分离动态和静态组件。然后，为动态元素引入多分辨率 4D 哈希编码器。最后，通过时空平滑正则化策略来减轻不稳定的变形伪影。

Result: DASH 在真实数据集上的实验表明，其渲染性能优于现有方法，视觉质量更高，并且能够达到实时速度。

Conclusion: DASH 在实时动态场景渲染方面取得了最先进的性能，在单块 4090 GPU 上实现了 264 FPS 的帧率，并具有增强的视觉质量。

Abstract: Dynamic scene reconstruction is a long-term challenge in 3D vision. Existing
plane-based methods in dynamic Gaussian splatting suffer from an unsuitable
low-rank assumption, causing feature overlap and poor rendering quality.
Although 4D hash encoding provides an explicit representation without low-rank
constraints, directly applying it to the entire dynamic scene leads to
substantial hash collisions and redundancy. To address these challenges, we
present DASH, a real-time dynamic scene rendering framework that employs 4D
hash encoding coupled with self-supervised decomposition. Our approach begins
with a self-supervised decomposition mechanism that separates dynamic and
static components without manual annotations or precomputed masks. Next, we
introduce a multiresolution 4D hash encoder for dynamic elements, providing an
explicit representation that avoids the low-rank assumption. Finally, we
present a spatio-temporal smoothness regularization strategy to mitigate
unstable deformation artifacts. Experiments on real-world datasets demonstrate
that DASH achieves state-of-the-art dynamic rendering performance, exhibiting
enhanced visual quality at real-time speeds of 264 FPS on a single 4090 GPU.
Code: https://github.com/chenj02/DASH.

</details>


### [67] [Patch Pruning Strategy Based on Robust Statistical Measures of Attention Weight Diversity in Vision Transformers](https://arxiv.org/abs/2507.19175)
*Yuki Igaue,Hiroaki Aizawa*

Main category: cs.CV

TL;DR: Vision Transformer 的多头自注意力机制计算量很大（与 patches 数量呈二次方关系）。我们提出了一种 patch pruning 方法，通过计算注意力权重在不同头之间的方差来识别和移除不重要的 patches，从而提高了计算效率。我们的方法在保持精度的同时提高了吞吐量，并且通过引入重叠 patch 嵌入可以获得更好的性能。


<details>
  <summary>Details</summary>
Motivation: 解决 Vision Transformer 中多头自注意力机制二次计算复杂度的问题，通过识别和移除冗余的 patches 来提高计算效率。

Method: 一种 patch pruning 策略，通过计算多头注意力权重在不同头之间的方差来评估每个 patch 的重要性。该方法可用于训练和推理，并可通过使用诸如中位数绝对偏差等鲁棒统计量来替代方差，以评估 patch 重要性。

Result: 所提出的方法可以轻松地在训练和推理过程中应用，在微调预训练模型等场景中，在保持分类精度的同时实现了更高的吞吐量。引入重叠 patch 嵌入后，在可比较的吞吐量下取得了更好的性能。

Conclusion: 提出了一种基于注意力权重方差的 patch pruning 策略，并通过引入重叠 patch 嵌入来进一步提升性能，在保持分类精度的同时提高了计算效率。

Abstract: Multi-head self-attention is a distinctive feature extraction mechanism of
vision transformers that computes pairwise relationships among all input
patches, contributing significantly to their high performance. However, it is
known to incur a quadratic computational complexity with respect to the number
of patches. One promising approach to address this issue is patch pruning,
which improves computational efficiency by identifying and removing redundant
patches. In this work, we propose a patch pruning strategy that evaluates the
importance of each patch based on the variance of attention weights across
multiple attention heads. This approach is inspired by the design of multi-head
self-attention, which aims to capture diverse attention patterns across
different subspaces of feature representations. The proposed method can be
easily applied during both training and inference, and achieves improved
throughput while maintaining classification accuracy in scenarios such as
fine-tuning with pre-trained models. In addition, we also found that using
robust statistical measures, such as the median absolute deviation in place of
variance, to assess patch importance can similarly lead to strong performance.
Furthermore, by introducing overlapping patch embeddings, our method achieves
better performance with comparable throughput to conventional approaches that
utilize all patches.

</details>


### [68] [Continual Learning-Based Unified Model for Unpaired Image Restoration Tasks](https://arxiv.org/abs/2507.19184)
*Kotha Kartheek,Lingamaneni Gnanesh Chowdary,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: 本研究提出了一种创新的持续学习框架，用于处理雾、雪、雨等多种恶劣天气条件下的图像恢复问题。通过结合选择性核融合层、弹性权重巩固和循环对比损失，并采用非配对图像恢复方法，该框架在提高图像质量方面取得了显著成效。


<details>
  <summary>Details</summary>
Motivation: 为了应对自动驾驶等应用中对包含不同恶劣天气条件（如雾、雪和雨）的图像进行统一恢复的需求，本研究旨在开发一种能够处理多种天气条件的单一模型。

Method: 本研究提出了一种包含选择性核融合层、弹性权重巩固（EWC）和新颖的循环对比损失的持续学习框架。此外，还提出了一种非配对图像恢复方法，以减少对训练数据的依赖。

Result: 在标准的去雾、去雪和去雨任务基准数据集上进行的广泛实验表明，与现有的最先进方法相比，所提出的方法在 PSNR、SSIM 和感知质量方面均有显著提高。

Conclusion: 该研究提出了一种新的持续学习方法，用于统一的图像恢复框架，可以处理不同类型的恶劣天气条件。实验结果表明，与最先进的方法相比，该方法在 PSNR、SSIM 和感知质量方面都有显著的改进。

Abstract: Restoration of images contaminated by different adverse weather conditions
such as fog, snow, and rain is a challenging task due to the varying nature of
the weather conditions. Most of the existing methods focus on any one
particular weather conditions. However, for applications such as autonomous
driving, a unified model is necessary to perform restoration of corrupted
images due to different weather conditions. We propose a continual learning
approach to propose a unified framework for image restoration. The proposed
framework integrates three key innovations: (1) Selective Kernel Fusion layers
that dynamically combine global and local features for robust adaptive feature
selection; (2) Elastic Weight Consolidation (EWC) to enable continual learning
and mitigate catastrophic forgetting across multiple restoration tasks; and (3)
a novel Cycle-Contrastive Loss that enhances feature discrimination while
preserving semantic consistency during domain translation. Further, we propose
an unpaired image restoration approach to reduce the dependance of the proposed
approach on the training data. Extensive experiments on standard benchmark
datasets for dehazing, desnowing and deraining tasks demonstrate significant
improvements in PSNR, SSIM, and perceptual quality over the state-of-the-art.

</details>


### [69] [VisHall3D: Monocular Semantic Scene Completion from Reconstructing the Visible Regions to Hallucinating the Invisible Regions](https://arxiv.org/abs/2507.19188)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Longjun Gao,Yu Xue,Le Wang*

Main category: cs.CV

TL;DR: VisHall3D是一个创新的两阶段单目语义场景补全框架，通过分别处理可见和不可见区域，解决了特征纠缠和几何不一致问题，并在基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的单目语义场景补全方法存在特征纠缠和几何不一致的问题，VisHall3D旨在解决这些问题。

Method: VisHall3D采用一个两阶段框架：第一阶段使用VisFrontierNet（一个可见性感知投影模块）重建可见区域，追踪视觉边界并保留细节；第二阶段使用OcclusionMAE（一个幻觉网络）通过噪声注入机制生成不可见区域的几何。

Result: VisHall3D在SemanticKITTI和SSCBench-KITTI-360上进行了广泛实验验证，取得了最先进的性能，显著优于先前的方法。

Conclusion: VisHall3D通过将场景补全分解为可见区域重建和不可见区域推断两个阶段，有效缓解了特征纠缠和几何不一致问题，显著提高了重建质量，并在SemanticKITTI和SSCBench-KITTI-360基准测试中取得了最先进的性能。

Abstract: This paper introduces VisHall3D, a novel two-stage framework for monocular
semantic scene completion that aims to address the issues of feature
entanglement and geometric inconsistency prevalent in existing methods.
VisHall3D decomposes the scene completion task into two stages: reconstructing
the visible regions (vision) and inferring the invisible regions
(hallucination). In the first stage, VisFrontierNet, a visibility-aware
projection module, is introduced to accurately trace the visual frontier while
preserving fine-grained details. In the second stage, OcclusionMAE, a
hallucination network, is employed to generate plausible geometries for the
invisible regions using a noise injection mechanism. By decoupling scene
completion into these two distinct stages, VisHall3D effectively mitigates
feature entanglement and geometric inconsistency, leading to significantly
improved reconstruction quality.
  The effectiveness of VisHall3D is validated through extensive experiments on
two challenging benchmarks: SemanticKITTI and SSCBench-KITTI-360. VisHall3D
achieves state-of-the-art performance, outperforming previous methods by a
significant margin and paves the way for more accurate and reliable scene
understanding in autonomous driving and other applications.

</details>


### [70] [Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet](https://arxiv.org/abs/2507.19209)
*Xiaoyu Zhang,Zhifeng Bao,Hai Dong,Ziwei Wang,Jiajun Liu*

Main category: cs.CV

TL;DR: CounterNet通过热图预测和优化的策略提高了自动驾驶点云数据的目标计数准确性，进而提升了数据查询的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有技术在处理3D点云数据时，其检测模型在生成可靠的目标计数方面存在不足，导致查询结果出现重大错误。为了解决这个问题，需要一种能够准确计数3D点云数据中目标的方法，以支持点云数据的有效查询和分析。

Method: 提出了一种名为CounterNet的热图预测网络，用于在大规模点云数据中进行准确的目标计数。它通过检测物体中心而不是精确的物体定位来提高计数准确性。此外，还引入了一种基于重叠区域的特征图划分策略来处理不同大小的物体，并采用逐帧动态模型选择策略来适应不同的帧特性。

Result: CounterNet在三个真实世界的自动驾驶数据集上，将计数准确性提高了5%到20%，从而提升了查询的可靠性。

Conclusion: CounterNet在三个真实世界的自动驾驶数据集上进行了评估，结果显示在各个对象类别上计数准确性提高了5%到20%，从而在所有支持的查询类型中实现了更可靠的查询结果。

Abstract: Autonomous vehicles generate massive volumes of point cloud data, yet only a
subset is relevant for specific tasks such as collision detection, traffic
analysis, or congestion monitoring. Effectively querying this data is essential
to enable targeted analytics. In this work, we formalize point cloud querying
by defining three core query types: RETRIEVAL, COUNT, and AGGREGATION, each
aligned with distinct analytical scenarios. All these queries rely heavily on
accurate object counts to produce meaningful results, making precise object
counting a critical component of query execution. Prior work has focused on
indexing techniques for 2D video data, assuming detection models provide
accurate counting information. However, when applied to 3D point cloud data,
state-of-the-art detection models often fail to generate reliable object
counts, leading to substantial errors in query results. To address this
limitation, we propose CounterNet, a heatmap-based network designed for
accurate object counting in large-scale point cloud data. Rather than focusing
on accurate object localization, CounterNet detects object presence by finding
object centers to improve counting accuracy. We further enhance its performance
with a feature map partitioning strategy using overlapping regions, enabling
better handling of both small and large objects in complex traffic scenes. To
adapt to varying frame characteristics, we introduce a per-frame dynamic model
selection strategy that selects the most effective configuration for each
input. Evaluations on three real-world autonomous vehicle datasets show that
CounterNet improves counting accuracy by 5% to 20% across object categories,
resulting in more reliable query outcomes across all supported query types.

</details>


### [71] [PRE-MAP: Personalized Reinforced Eye-tracking Multimodal LLM for High-Resolution Multi-Attribute Point Prediction](https://arxiv.org/abs/2507.19213)
*Hanbing Wu,Ping Jiang,Anyang Su,Chenxu Zhao,Tianyu Fu,Minghui Wu,Beiping Tan,Huiying Li*

Main category: cs.CV

TL;DR: SPA-ADV is a large-scale dataset of gaze behaviors for 4,500+ participants and 486 videos. PRE-MAP is a new MLLM-based eye-tracking saliency model using reinforcement learning and user profiles for personalized attention prediction, with C-GRPO ensuring point accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing saliency prediction models neglect subjective cognitive diversity and use low-resolution imagery, limiting personalized attention capture. MLLMs face challenges with hallucinations and precise point positioning in multi-point prediction tasks.

Method: PRE-MAP, a novel eye-tracking saliency model utilizing reinforcement learning-optimized eye-tracking, built upon MLLMs and guided by Multi-Attribute user profiles. C-GRPO is introduced to ensure format-correct and spatially accurate prediction points from MLLMs.

Result: Extensive experiments on SPA-ADV and other benchmarks demonstrate the effectiveness of the PRE-MAP approach.

Conclusion: The proposed PRE-MAP model, guided by Multi-Attribute user profiles and optimized with C-GRPO, effectively captures personalized attention patterns in advertisement videos, addressing limitations of existing models.

Abstract: Visual selective attention, driven by individual preferences, regulates human
prioritization of visual stimuli by bridging subjective cognitive mechanisms
with objective visual elements, thereby steering the semantic interpretation
and hierarchical processing of dynamic visual scenes. However, existing models
and datasets predominantly neglect the influence of subjective cognitive
diversity on fixation behavior. Conventional saliency prediction models,
typically employing segmentation approaches, rely on low-resolution imagery to
generate saliency heatmaps, subsequently upscaled to native resolutions, which
limiting their capacity to capture personalized attention patterns.
Furthermore, MLLMs are constrained by factors such as hallucinations, making it
very costly to strictly adhere to the expected format in tasks involving
multiple point predictions, and achieving precise point positioning is
challenging. To address these limitations, we present Subjective Personalized
Attention for Advertisement Videos, namely SPA-ADV, a large-scale multimodal
dataset capturing gaze behaviors from over 4,500 participants varying in age
and gender with 486 videos. Furthermore, we propose PRE-MAP, a novel
eye-tracking saliency model that characterizes Personalized visual disparities
through Reinforcement learning-optimized Eye-tracking, built upon MLLMs and
guided by Multi-Attribute user profiles to predict Points. To ensure MLLMs
produce prediction points that are both format-correct and spatially accurate,
we introduce Consistency Group Relative Policy Optimization (C-GRPO), inspired
by the variability in eye movement points and Multi-Attribute profiles.
Extensive experiments on SPA-ADV and other benchmarks demonstrate the
effectiveness of our approach. The code and dataset are available at
\href{https://github.com/mininglamp-MLLM/PRE-MAP}{this URL}.

</details>


### [72] [Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene](https://arxiv.org/abs/2507.19232)
*Donggeun Lim,Jinseok Bae,Inwoo Hwang,Seungmin Lee,Hwanhee Lee,Young Min Kim*

Main category: cs.CV

TL;DR: 提出一个利用LLM生成多人类上下文运动的框架，通过事件序列和空间引导合成运动，实现了大规模和多样化的场景理解。


<details>
  <summary>Details</summary>
Motivation: 生成多人类上下文运动需要对人与人之间以及人与场景之间的动态关系进行整体推理。

Method: 提出一个框架，利用大型语言模型（LLM）处理文本输入中的上下文复杂性，将其转换为具体的子问题，用于生成大规模的多智能体行为。具体而言，通过事件生成器将动态场景的时间进程制定为一系列小事件，每个事件都需要涉及相关角色和对象的明确运动。然后，基于空间引导采样位置来合成角色运动。采用高级模块提供可扩展且全面的上下文，将事件转换为相对描述，以检索精确坐标。

Result: 基准测试结果和用户研究表明，该框架能够有效地捕捉场景上下文并具有高可扩展性。

Conclusion: 该框架能够有效地捕捉场景上下文并具有高可扩展性，相关代码、基准测试和结果视频可在项目页面获取

Abstract: In this work, we propose a framework that creates a lively virtual dynamic
scene with contextual motions of multiple humans. Generating multi-human
contextual motion requires holistic reasoning over dynamic relationships among
human-human and human-scene interactions. We adapt the power of a large
language model (LLM) to digest the contextual complexity within textual input
and convert the task into tangible subproblems such that we can generate
multi-agent behavior beyond the scale that was not considered before.
Specifically, our event generator formulates the temporal progression of a
dynamic scene into a sequence of small events. Each event calls for a
well-defined motion involving relevant characters and objects. Next, we
synthesize the motions of characters at positions sampled based on spatial
guidance. We employ a high-level module to deliver scalable yet comprehensive
context, translating events into relative descriptions that enable the
retrieval of precise coordinates. As the first to address this problem at scale
and with diversity, we offer a benchmark to assess diverse aspects of
contextual reasoning. Benchmark results and user studies show that our
framework effectively captures scene context with high scalability. The code
and benchmark, along with result videos, are available at our project page:
https://rms0329.github.io/Event-Driven-Storytelling/.

</details>


### [73] [CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception](https://arxiv.org/abs/2507.19239)
*Jiaru Zhong,Jiahao Wang,Jiahui Xu,Xiaofan Li,Zaiqing Nie,Haibao Yu*

Main category: cs.CV

TL;DR: CoopTrack是一个创新的端到端框架，用于合作式3D多目标跟踪，通过实例级特征共享和跨代理关联，显著提高了感知能力，并在V2X-Seq数据集上取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决单车自动驾驶系统的局限性，并深入研究尚未得到充分研究的合作式3D多目标跟踪等更具挑战性的合作式序列感知任务。

Method: CoopTrack是一个端到端的框架，通过可学习的实例关联来解决合作式序列感知问题。它传输稀疏的实例级特征，并通过多维度特征提取和跨代理关联与聚合两个关键组件，实现全面的实例表示和自适应的跨代理关联与融合。

Result: CoopTrack实现了先进的性能，在V2X-Seq数据集上取得了39.0% mAP和32.8% AMOTA的SOTA结果。

Conclusion: CoopTrack在V2X-Seq和Griffin数据集上均取得了优异的性能，在V2X-Seq上达到了39.0% mAP和32.8% AMOTA的先进水平。

Abstract: Cooperative perception aims to address the inherent limitations of
single-vehicle autonomous driving systems through information exchange among
multiple agents. Previous research has primarily focused on single-frame
perception tasks. However, the more challenging cooperative sequential
perception tasks, such as cooperative 3D multi-object tracking, have not been
thoroughly investigated. Therefore, we propose CoopTrack, a fully
instance-level end-to-end framework for cooperative tracking, featuring
learnable instance association, which fundamentally differs from existing
approaches. CoopTrack transmits sparse instance-level features that
significantly enhance perception capabilities while maintaining low
transmission costs. Furthermore, the framework comprises two key components:
Multi-Dimensional Feature Extraction, and Cross-Agent Association and
Aggregation, which collectively enable comprehensive instance representation
with semantic and motion features, and adaptive cross-agent association and
fusion based on a feature graph. Experiments on both the V2X-Seq and Griffin
datasets demonstrate that CoopTrack achieves excellent performance.
Specifically, it attains state-of-the-art results on V2X-Seq, with 39.0\% mAP
and 32.8\% AMOTA. The project is available at
https://github.com/zhongjiaru/CoopTrack.

</details>


### [74] [BridgeNet: A Unified Multimodal Framework for Bridging 2D and 3D Industrial Anomaly Detection](https://arxiv.org/abs/2507.19253)
*An Xiang,Zixuan Huang,Xitong Gao,Kejiang Ye,Cheng-zhong Xu*

Main category: cs.CV

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Industrial anomaly detection for 2D objects has gained significant attention
and achieved progress in anomaly detection (AD) methods. However, identifying
3D depth anomalies using only 2D information is insufficient. Despite
explicitly fusing depth information into RGB images or using point cloud
backbone networks to extract depth features, both approaches struggle to
adequately represent 3D information in multimodal scenarios due to the
disparities among different modal information. Additionally, due to the
scarcity of abnormal samples in industrial data, especially in multimodal
scenarios, it is necessary to perform anomaly generation to simulate real-world
abnormal samples. Therefore, we propose a novel unified multimodal anomaly
detection framework to address these issues. Our contributions consist of 3 key
aspects. (1) We extract visible depth information from 3D point cloud data
simply and use 2D RGB images to represent appearance, which disentangles depth
and appearance to support unified anomaly generation. (2) Benefiting from the
flexible input representation, the proposed Multi-Scale Gaussian Anomaly
Generator and Unified Texture Anomaly Generator can generate richer anomalies
in RGB and depth. (3) All modules share parameters for both RGB and depth data,
effectively bridging 2D and 3D anomaly detection. Subsequent modules can
directly leverage features from both modalities without complex fusion.
Experiments show our method outperforms state-of-the-art (SOTA) on MVTec-3D AD
and Eyecandies datasets. Code available at:
https://github.com/Xantastic/BridgeNet

</details>


### [75] [OVFact: Measuring and Improving Open-Vocabulary Factuality for Long Caption Models](https://arxiv.org/abs/2507.19262)
*Monika Wysoczańska,Shyamal Buch,Anurag Arnab,Cordelia Schmid*

Main category: cs.CV

TL;DR: 提出 OV-Fact 来评估长标题的事实性，解决了 VLM 在生成长标题时的事实性问题，并可在无人类标注的情况下使用。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLM）在生成长而事实的标题方面存在困难，而传统的评估方法不适用于长标题和缺乏人类标注的场景。

Method: 提出了一种名为 OV-Fact 的新方法，利用开放词汇视觉基础和基于工具的验证来测量长标题的事实性，并且不依赖人类注释。

Result: OV-Fact 提高了与人类判断的一致性，并在一个大规模、有噪声的预训练数据集的子集上训练的模型，显著提高了事实精度，同时保持了标题的描述性。

Conclusion: OV-Fact 通过利用开放词汇视觉基础和基于工具的验证，在不依赖人类注释的情况下，提高了长标题的事实性测量能力，并且能够同时捕捉标题的描述性和事实精确性。

Abstract: Large vision-language models (VLMs) often struggle to generate long and
factual captions. However, traditional measures for hallucination and
factuality are not well suited for evaluating longer, more diverse captions and
in settings where ground-truth human-annotated captions are unavailable. We
introduce OV-Fact, a novel method for measuring caption factuality of long
captions that leverages open-vocabulary visual grounding and tool-based
verification without depending on human annotations. Our method improves
agreement with human judgments and captures both caption descriptiveness
(recall) and factual precision in the same metric. Furthermore, unlike previous
metrics, our reference-free method design enables new applications towards
factuality-based data filtering. We observe models trained on an
OVFact-filtered (2.5-5x less) subset of a large-scale, noisy (VLM-generated)
pretraining set meaningfully improve factuality precision without sacrificing
caption descriptiveness across a range of downstream long caption benchmarks.

</details>


### [76] [SimMLM: A Simple Framework for Multi-modal Learning with Missing Modality](https://arxiv.org/abs/2507.19264)
*Sijie Li,Chen Chen,Jungong Han*

Main category: cs.CV

TL;DR: SimMLM 是一个用于处理缺失模态的多模态学习框架，它使用动态混合模态专家（DMoME）和“多对少”（MoFe）排序损失，在各种场景下均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理缺失模态的多模态学习时，通常依赖复杂的网络架构或数据填充技术，而 SimMLM 提供了一个通用且有效的解决方案，能够适应各种缺失模态场景，并提高准确性和鲁棒性。

Method: SimMLM 框架包含一个动态混合模态专家（DMoME）架构，通过可学习的门控机制动态调整各模态的贡献度。此外，提出了“多对少”（MoFe）排序损失函数，以确保在可用模态增加时任务准确性得到提升或保持稳定。

Result: SimMLM 在多模态医疗图像分割（BraTS 2018）和多模态分类（UPMC Food-101, avMNIST）任务上进行了验证，结果一致表明其优于现有方法。

Conclusion: SimMLM 在多模态医学图像分割和多模态分类任务上均超越了现有方法，在完整和缺失模态场景下均展现出优越的准确性、可解释性、鲁棒性和可靠性。

Abstract: In this paper, we propose SimMLM, a simple yet powerful framework for
multimodal learning with missing modalities. Unlike existing approaches that
rely on sophisticated network architectures or complex data imputation
techniques, SimMLM provides a generic and effective solution that can adapt to
various missing modality scenarios with improved accuracy and robustness.
Specifically, SimMLM consists of a generic Dynamic Mixture of Modality Experts
(DMoME) architecture, featuring a dynamic, learnable gating mechanism that
automatically adjusts each modality's contribution in both full and partial
modality settings. A key innovation of SimMLM is the proposed More vs. Fewer
(MoFe) ranking loss, which ensures that task accuracy improves or remains
stable as more modalities are made available. This aligns the model with an
intuitive principle: removing one or more modalities should not increase
accuracy. We validate SimMLM on multimodal medical image segmentation (BraTS
2018) and multimodal classification (UPMC Food-101, avMNIST) tasks, where it
consistently surpasses competitive methods, demonstrating superior accuracy,
interpretability, robustness, and reliability across both complete and missing
modality scenarios at test time.

</details>


### [77] [Video Self-Distillation for Single-Image Encoders: A Step Toward Physically Plausible Perception](https://arxiv.org/abs/2507.19272)
*Marcel Simon,Tae-Ho Kim,Seul-Ki Yeom*

Main category: cs.CV

TL;DR: "A new method trains a single-image encoder using video data to improve feature learning by incorporating temporal cues, showing a 1.4 mIoU increase on ADE20K."


<details>
  <summary>Details</summary>
Motivation: "Self-supervised image encoders such as DINO have recently gained significant interest for learning robust visual features without labels. However, most SSL methods train on static images and miss the temporal cues inherent in videos."

Method: "We introduce a video-distilled single-image encoder trained to predict the next-frame representation from the current frame. This simple objective injects 3D spatial and temporal priors without optical flow or tracking."

Result: "When pre-training on a single 2-hour video, our approach raises the mean Intersection-over-Union (mIoU) on ADE20K from 35.0 (DoRA) to 36.4 while remaining a drop-in replacement for image-only pipelines."

Conclusion: "Our results highlight video self-distillation as a lightweight route to geometry-aware perception, an essential ingredient for physically plausible world models and Physical AI."

Abstract: Self-supervised image encoders such as DINO have recently gained significant
interest for learning robust visual features without labels. However, most SSL
methods train on static images and miss the temporal cues inherent in videos.
We introduce a video-distilled single-image encoder trained to predict the
next-frame representation from the current frame. This simple objective injects
3D spatial and temporal priors without optical flow or tracking. When
pre-training on a single 2-hour video, our approach raises the mean
Intersection-over-Union (mIoU) on ADE20K from 35.0 (DoRA) to 36.4 while
remaining a drop-in replacement for image-only pipelines. Our results highlight
video self-distillation as a lightweight route to geometry-aware perception an
essential ingredient for physically plausible world models and Physical AI.

</details>


### [78] [CircuitProbe: Dissecting Spatiotemporal Visual Semantics with Circuit Tracing](https://arxiv.org/abs/2507.19420)
*Yiming Zhang,Chengzhang Yu,Zhuokai Zhao,Kun Wang,Qiankun Li,Zihan Chen,Yang Liu,Zenghui Ding,Yining Sun*

Main category: cs.CV

TL;DR: 研究人员提出了一个基于电路的框架来分析大型视觉语言模型（LVLMs）如何处理时空信息。他们发现，特定的对象标记对于模型性能至关重要，并且模型在中晚层会逐渐提炼出对对象和动作的概念理解，展现出对时空语义的专门功能局部化。


<details>
  <summary>Details</summary>
Motivation: 尽管语言和图像理解在大型视觉语言模型（LVLMs）中得到了广泛研究，但其内部时空理解的推理机制仍不清楚。

Method: 提出一个系统的、基于电路的框架，包含视觉审计电路、语义追踪电路和注意力流电路，以研究LVLMs内部如何表示和处理时空视觉语义。

Result: 发现视觉语义高度局部化于特定的对象标记（移除这些标记可能导致模型性能下降高达92.6%）；识别出可解释的对象和动作概念在中晚层出现并逐渐精炼；揭示了LVLMs的中晚层对时空语义表现出专门的功能局部化。

Conclusion: 该研究为LVLMs的时空语义分析提供了重要的机制见解，为设计更鲁棒、可解释的模型奠定了基础。

Abstract: The processing mechanisms underlying language and image understanding in
large vision-language models (LVLMs) have been extensively studied. However,
the internal reasoning mechanisms of LVLMs for spatiotemporal understanding
remain poorly understood. In this work, we introduce a systematic,
circuit-based framework designed to investigate how spatiotemporal visual
semantics are represented and processed within these LVLMs. Specifically, our
framework comprises three circuits: visual auditing circuit, semantic tracing
circuit, and attention flow circuit. Through the lens of these circuits, we
discover that visual semantics are highly localized to specific object
tokens--removing these tokens can degrade model performance by up to 92.6%.
Furthermore, we identify that interpretable concepts of objects and actions
emerge and become progressively refined in the middle-to-late layers of LVLMs.
In contrary to the current works that solely focus on objects in one image, we
reveal that the middle-to-late layers of LVLMs exhibit specialized functional
localization for spatiotemporal semantics. Our findings offer significant
mechanistic insights into spatiotemporal semantics analysis of LVLMs, laying a
foundation for designing more robust and interpretable models.

</details>


### [79] [RemoteReasoner: Towards Unifying Geospatial Reasoning Workflow](https://arxiv.org/abs/2507.19280)
*Liang Yao,Fan Liu,Hongbo Lu,Chuanyi Zhang,Rui Min,Shengxiang Xu,Shimin Di,Pai Peng*

Main category: cs.CV

TL;DR: 提出了一种名为 RemoteReasoner 的新工作流，它使用多模态大语言模型和强化学习来处理复杂的遥感查询，实现了更高的自主性和灵活性，并能在无需微调的情况下生成不同格式的输出。


<details>
  <summary>Details</summary>
Motivation: 现有的遥感方法未能满足处理复杂查询、进行空间和用户意图推理的需求，因为它们依赖于限制推理自主性的监督微调范式。

Method: 提出了一种名为 RemoteReasoner 的灵活且强大的遥感推理工作流。该工作流整合了多模态大语言模型（MLLM）来解释用户指令和定位目标，并结合了任务适应策略以实现多粒度输出生成。该框架使用强化学习（RL）进行训练，以赋予 MLLM 充分的自主性进行精确推理。在推理阶段，无需任务特定的解码器或进一步的微调，即可实现多样化的输出格式。

Result: 初步实验证明，RemoteReasoner 在包括区域级和像素级在内的多粒度推理任务上取得了卓越的性能，并实现了轮廓提取等新能力。

Conclusion: RemoteReasoner 框架在多粒度推理任务（包括区域级和像素级）上取得了显著的性能，并且能够实现现有方法无法实现的轮廓提取等新功能。

Abstract: Remote sensing imagery presents vast, inherently unstructured spatial data,
demanding sophisticated reasoning to interpret complex user intents and
contextual relationships beyond simple recognition tasks. In this paper, we aim
to construct an Earth observation workflow to handle complex queries by
reasoning about spatial context and user intent. As a reasoning workflow, it
should be somewhat autonomous, where predefined ground-truth reasoning paths do
not constrain the learning process. Furthermore, its architecture ought to be
unified yet flexible, enabling the model to perform diverse reasoning tasks
with distinct output formats through a single forward pass. Existing remote
sensing approaches fail to address these requirements, as they rely on
supervised fine-tuning paradigms that constrain the autonomy of reasoning. To
this end, we propose RemoteReasoner, a flexible and robust workflow for remote
sensing reasoning tasks. The design of RemoteReasoner integrates a multi-modal
large language model (MLLM) for interpreting user instructions and localizing
targets, together with task adaptation strategies that enable multi-granularity
output generation. In contrast to existing methods, our framework is trained
with reinforcement learning (RL) to endow the MLLM sufficient autonomy for
precise reasoning. At the inference stage, our adaptation strategies enable
diverse output formats at inference time without requiring task-specific
decoders or further fine-tuning. Preliminary experiments demonstrated that
RemoteReasoner achieves remarkable performance across multi-granularity
reasoning tasks, including region-level and pixel-level. Additionally, our
framework enables novel capabilities such as the contour extraction task beyond
the reach of existing reasoning pipelines.

</details>


### [80] [PINO: Person-Interaction Noise Optimization for Long-Duration and Customizable Motion Generation of Arbitrary-Sized Groups](https://arxiv.org/abs/2507.19292)
*Sakuya Ota,Qing Yu,Kent Fujiwara,Satoshi Ikehata,Ikuro Sato*

Main category: cs.CV

TL;DR: PINO是一个新的、无需训练的框架，用于生成任意规模角色的逼真、可定制的交互。它将复杂的交互分解为成对的交互，并使用基于物理的惩罚来避免瑕疵，从而实现精确的用户控制。


<details>
  <summary>Details</summary>
Motivation: 生成涉及多个角色的真实群体交互由于群组规模扩大而导致的复杂性增加，仍然是一个挑战。现有的条件扩散模型通过对先前生成的角色进行条件化来逐步生成运动，但它们依赖于单一的共享提示，限制了细微的控制，并导致交互过于简单化。

Method: PINO框架通过将复杂的群体交互分解为语义相关的成对交互，并利用预训练的双人交互扩散模型来逐步组合群体交互。为了确保物理上的合理性并避免诸如图层重叠或角色穿插等常见瑕疵，PINO在噪声优化过程中采用了基于物理的惩罚机制。

Result: PINO框架能够生成逼真且可定制的任意规模群体交互，并且在无需额外训练的情况下，用户可以精确控制角色的方向、速度和空间关系。

Conclusion: PINO框架能够生成视觉上真实、物理上连贯且可适应的多人交互，适用于动画、游戏和机器人等多种应用。

Abstract: Generating realistic group interactions involving multiple characters remains
challenging due to increasing complexity as group size expands. While existing
conditional diffusion models incrementally generate motions by conditioning on
previously generated characters, they rely on single shared prompts, limiting
nuanced control and leading to overly simplified interactions. In this paper,
we introduce Person-Interaction Noise Optimization (PINO), a novel,
training-free framework designed for generating realistic and customizable
interactions among groups of arbitrary size. PINO decomposes complex group
interactions into semantically relevant pairwise interactions, and leverages
pretrained two-person interaction diffusion models to incrementally compose
group interactions. To ensure physical plausibility and avoid common artifacts
such as overlapping or penetration between characters, PINO employs
physics-based penalties during noise optimization. This approach allows precise
user control over character orientation, speed, and spatial relationships
without additional training. Comprehensive evaluations demonstrate that PINO
generates visually realistic, physically coherent, and adaptable multi-person
interactions suitable for diverse animation, gaming, and robotics applications.

</details>


### [81] [ABCD: Automatic Blood Cell Detection via Attention-Guided Improved YOLOX](https://arxiv.org/abs/2507.19296)
*Ahmed Endris Hasen,Yang Shangming,Chiagoziem C. Ukwuoma,Biniyam Gashaw,Abel Zenebe Yutra*

Main category: cs.CV

TL;DR: 通过改进YOLOX模型（加入CBAM、ASFF并使用CIOU损失），提出ABCD方法自动检测血细胞，在BCCD数据集上实现了更高的准确率和更快的速度。


<details>
  <summary>Details</summary>
Motivation: 手动进行血细胞检查以检测疾病耗时、效率低且容易出错。为了解决这些问题，利用基于深度学习的目标检测器来分析血细胞是一种可行的解决方案。

Method: 提出了一种名为ABCD（Automatic Blood Cell Detection）的自动血细胞检测方法，该方法基于改进的YOLOX目标检测器。具体改进包括：1. 在网络主干中引入卷积块注意模块（CBAM）以增强特征提取效率；2. 在网络颈部引入自适应空间特征融合（ASFF）以优化多阶段提取特征的融合；3. 使用完全交并比（CIOU）损失函数替代交并比（IOU）损失函数以加速模型收敛。

Result: 实验结果表明，提出的ABCD方法在BCCD数据集上的表现优于其他现有方法。与基线算法相比，ABCD在mAP@0.5和mAP@0.5-0.9方面的表现分别提高了2.8%和23.41%，并且检测速度提高了2.9%，使其能够满足实时应用的需求。

Conclusion: 提出的ABCD方法在BCCD数据集上比其他现有方法更有效，在mAP@0.5和mAP@0.5-0.9方面分别提高了2.8%和23.41%，同时检测速度提高了2.9%，实现了高效的实时应用。

Abstract: Detection of blood cells in microscopic images has become a major focus of
medical image analysis, playing a crucial role in gaining valuable insights
into a patient's health. Manual blood cell checks for disease detection are
known to be time-consuming, inefficient, and error-prone. To address these
limitations, analyzing blood cells using deep learning-based object detectors
can be regarded as a feasible solution. In this study, we propose automatic
blood cell detection method (ABCD) based on an improved version of YOLOX, an
object detector, for detecting various types of blood cells, including white
blood cells, red blood cells, and platelets. Firstly, we introduce the
Convolutional Block Attention Module (CBAM) into the network's backbone to
enhance the efficiency of feature extraction. Furthermore, we introduce the
Adaptively Spatial Feature Fusion (ASFF) into the network's neck, which
optimizes the fusion of different features extracted from various stages of the
network. Finally, to speed up the model's convergence, we substitute the
Intersection over Union (IOU) loss function with the Complete Intersection over
Union (CIOU) loss function. The experimental results demonstrate that the
proposed method is more effective than other existing methods for BCCD dataset.
Compared to the baseline algorithm, our method ABCD achieved 95.49 % mAP@0.5
and 86.89 % mAP@0.5-0.9, which are 2.8% and 23.41% higher, respectively, and
increased the detection speed by 2.9%, making it highly efficient for real-time
applications.

</details>


### [82] [SemGes: Semantics-aware Co-Speech Gesture Generation using Semantic Coherence and Relevance Learning](https://arxiv.org/abs/2507.19359)
*Lanmiao Liu,Esam Ghaleb,Aslı Özyürek,Zerrin Yumak*

Main category: cs.CV

TL;DR: 本文提出了一种新的方法，通过整合语音和文本的语义信息，生成与语音内容匹配的虚拟化身手势，提高了手势的真实性和连贯性，效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有手势生成研究主要集中于生成节奏性律动手势，忽略了手势的语义上下文，而创建具有与语音对齐的语义连贯手势的虚拟化身是一个挑战。

Method: 本文提出了一种新颖的、用于共同演讲手势生成的语义基础方法，该方法首先通过向量量化变分自编码器学习运动先验，然后在该模型的基础上，应用第二阶段模块，从语音、文本语义和说话人身份自动生成手势，并通过语义连贯性和相关性模块确保生成手势与语音语义的一致性。

Result: 实验结果表明，该方法增强了语义手势的真实性和连贯性，并且在两个共同演讲手势生成的基准测试中，无论是在客观指标还是主观指标上，都优于最先进的方法。

Conclusion: 该方法在共同演讲手势生成方面，通过集成细粒度和全局语义信息，提高了生成手势的真实性和语义连贯性，并在客观和主观指标上均优于现有方法。

Abstract: Creating a virtual avatar with semantically coherent gestures that are
aligned with speech is a challenging task. Existing gesture generation research
mainly focused on generating rhythmic beat gestures, neglecting the semantic
context of the gestures. In this paper, we propose a novel approach for
semantic grounding in co-speech gesture generation that integrates semantic
information at both fine-grained and global levels. Our approach starts with
learning the motion prior through a vector-quantized variational autoencoder.
Built on this model, a second-stage module is applied to automatically generate
gestures from speech, text-based semantics and speaker identity that ensures
consistency between the semantic relevance of generated gestures and
co-occurring speech semantics through semantic coherence and relevance modules.
Experimental results demonstrate that our approach enhances the realism and
coherence of semantic gestures. Extensive experiments and user studies show
that our method outperforms state-of-the-art approaches across two benchmarks
in co-speech gesture generation in both objective and subjective metrics. The
qualitative results of our model, code, dataset and pre-trained models can be
viewed at https://semgesture.github.io/.

</details>


### [83] [EA-ViT: Efficient Adaptation for Elastic Vision Transformer](https://arxiv.org/abs/2507.19360)
*Chen Zhu,Wangbo Zhao,Huiwen Zhang,Samir Khaki,Yuhao Zhou,Weidong Tang,Shuo Wang,Zhihang Yuan,Yuzhang Shang,Xiaojiang Peng,Kai Wang,Dawei Yang*

Main category: cs.CV

TL;DR: 提出EA-ViT框架，通过单一适应过程生成不同尺寸的ViT模型，以适应不同资源限制，并包含嵌套弹性结构和轻量级路由器。


<details>
  <summary>Details</summary>
Motivation: 为了解决部署ViT以支持多样化的资源限制通常需要重新训练多个特定尺寸的ViT，从而耗费大量时间和精力的问题。

Method: 该框架包含两个阶段：1.增强预训练ViT的嵌套弹性结构，实现MLP扩展比、注意力头数、嵌入维度和网络深度的结构灵活性，并采用逐步提高弹性的课程学习策略以保留预训练知识和稳定适应。2.设计一个轻量级路由器，根据计算预算和下游任务需求选择子模型，并使用定制的NSGA-II算法初始化的帕累托最优配置进行路由器的联合优化。

Result: EA-ViT框架通过实验证明了其有效性和多功能性，能够生成满足不同资源约束的模型。

Conclusion: EA-ViT框架能够通过单一适应过程生成不同大小的模型，以满足不同资源限制平台的需求，并在多个基准测试中展示了其有效性和多功能性。

Abstract: Vision Transformers (ViTs) have emerged as a foundational model in computer
vision, excelling in generalization and adaptation to downstream tasks.
However, deploying ViTs to support diverse resource constraints typically
requires retraining multiple, size-specific ViTs, which is both time-consuming
and energy-intensive. To address this issue, we propose an efficient ViT
adaptation framework that enables a single adaptation process to generate
multiple models of varying sizes for deployment on platforms with various
resource constraints. Our approach comprises two stages. In the first stage, we
enhance a pre-trained ViT with a nested elastic architecture that enables
structural flexibility across MLP expansion ratio, number of attention heads,
embedding dimension, and network depth. To preserve pre-trained knowledge and
ensure stable adaptation, we adopt a curriculum-based training strategy that
progressively increases elasticity. In the second stage, we design a
lightweight router to select submodels according to computational budgets and
downstream task demands. Initialized with Pareto-optimal configurations derived
via a customized NSGA-II algorithm, the router is then jointly optimized with
the backbone. Extensive experiments on multiple benchmarks demonstrate the
effectiveness and versatility of EA-ViT. The code is available at
https://github.com/zcxcf/EA-ViT.

</details>


### [84] [BEV-LLM: Leveraging Multimodal BEV Maps for Scene Captioning in Autonomous Driving](https://arxiv.org/abs/2507.19370)
*Felix Brandstaetter,Erik Schuetz,Katharina Winter,Fabian Flohr*

Main category: cs.CV

TL;DR: BEV-LLM是一个轻量级的3D场景描述模型，通过融合LiDAR和图像数据，提高了自动驾驶的透明度和安全性。


<details>
  <summary>Details</summary>
Motivation: 为了提高自动驾驶决策系统的可解释性和透明度，并增强安全和人机交互，需要场景描述技术。

Method: BEV-LLM利用BEVFusion融合3D LiDAR点云和多视图图像，并引入新颖的绝对位置编码来实现特定视图的场景描述。该模型基于一个1B参数的小型基础模型。

Result: BEV-LLM在nuCaption数据集上取得了有竞争力的性能，超越了最先进的模型，BLEU分数最高提高了5%。新发布的数据集nuView和GroundView为评估场景描述能力提供了新的基准。

Conclusion: BEV-LLM在nuCaption数据集上取得了有竞争力的性能，超越了最先进的模型，BLEU分数最高提高了5%。此外，还发布了nuView和GroundView两个新数据集，以评估不同驾驶场景下的场景描述能力。

Abstract: Autonomous driving technology has the potential to transform transportation,
but its wide adoption depends on the development of interpretable and
transparent decision-making systems. Scene captioning, which generates natural
language descriptions of the driving environment, plays a crucial role in
enhancing transparency, safety, and human-AI interaction. We introduce BEV-LLM,
a lightweight model for 3D captioning of autonomous driving scenes. BEV-LLM
leverages BEVFusion to combine 3D LiDAR point clouds and multi-view images,
incorporating a novel absolute positional encoding for view-specific scene
descriptions. Despite using a small 1B parameter base model, BEV-LLM achieves
competitive performance on the nuCaption dataset, surpassing state-of-the-art
by up to 5\% in BLEU scores. Additionally, we release two new datasets - nuView
(focused on environmental conditions and viewpoints) and GroundView (focused on
object grounding) - to better assess scene captioning across diverse driving
scenarios and address gaps in current benchmarks, along with initial
benchmarking results demonstrating their effectiveness.

</details>


### [85] [Modality Agnostic Efficient Long Range Encoder](https://arxiv.org/abs/2507.19409)
*Toufiq Parag,Ahmed Elgammal*

Main category: cs.CV

TL;DR: MAELRE 是一种创新的Transformer架构，它通过结合标记合并和注意力近似技术，解决了单设备上长上下文处理的效率和准确性问题，适用于多种数据模态。


<details>
  <summary>Details</summary>
Motivation: 现有技术在扩展通用单设备实现的上下文长度时，通常特定于模态，并且在准确性和效率之间取得次优的权衡。本文旨在克服这些限制，提出一种用于跨多种模态进行长程编码的统一高效的Transformer架构。

Method: MAELRE 架构整合了标记合并和注意力近似技术，在内部计算块的不同阶段逐步合并标记。当标记数量较多时，它采用轻量级注意力近似，随着序列通过连续聚合变短，则切换到标准的点积注意力。

Result: MAELRE 架构实现了对上下文长度的扩展，在保持高准确性的同时，减少了内存占用和推理成本，其性能优于现有长上下文模型。

Conclusion: MAELRE 架构在跨越文本、时间序列、音频和视觉的多种模态的分类任务上，实现了优于现有长上下文模型的准确性，并降低了计算成本。

Abstract: The long-context capability of recent large transformer models can be
surmised to rely on techniques such as attention/model parallelism, as well as
hardware-level optimizations. While these strategies allow input lengths to
scale to millions of tokens, they do not fundamentally mitigate the quadratic
computational and memory complexity of the core attention mechanism. In this
paper, we address the challenge of long-context processing on a single device
using generic implementations by reducing the quadratic memory footprint and
inference cost. Existing approaches to extend the context length for generic
single device implementations -- such as token merging and modified attentions
-- are often modality specific and attain a suboptimal tradeoff between
accuracy and efficiency. To overcome these limitations, we propose MAELRE
(Modality Agnostic Efficient Long Range Encoder), a unified and efficient
transformer architecture designed for long-range encoding across diverse
modalities. MAELRE integrates token merging with attention approximation,
progressively merging tokens at different stages of internal computational
blocks. It employs a lightweight attention approximation when the number of
tokens is large, and switches to standard dot-product attention as the sequence
becomes shorter through successive aggregation. We demonstrate that MAELRE
achieves superior accuracy while reducing computational cost compared to
existing long-context models on classification tasks spanning multiple
modalities, including text, time series, audio, and vision.

</details>


### [86] [DEFNet: Multitasks-based Deep Evidential Fusion Network for Blind Image Quality Assessment](https://arxiv.org/abs/2507.19418)
*Yiwei Lou,Yuanpeng He,Rongchao Zhang,Yongzhi Cao,Hanpin Wang,Yu Huang*

Main category: cs.CV

TL;DR: 提出了一种名为DEFNet的新型盲图像质量评估（BIQA）框架，通过多任务学习和创新的可信赖信息融合策略，以及先进的不确定性估计技术，显著提高了图像质量评估的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有BIQA方法在整合辅助任务和灵活不确定性估计方面存在局限，导致性能不佳。

Method: 提出了一种基于多任务的深度证据融合网络（DEFNet），通过场景和失真类型分类任务辅助进行多任务优化。设计了一种新颖的、可信赖的信息融合策略，首先融合子区域的多种特征和模式，然后通过平衡细粒度细节和粗粒度上下文进行局部-全局信息融合。DEFNet利用受证据学习启发的先进不确定性估计技术，并借助正态-逆伽马分布混合。

Result: DEFNet通过多任务优化和可信赖信息融合策略，提高了BIQA的性能和鲁棒性，并展现了良好的泛化能力和适应性。

Conclusion: 该框架在合成和真实失真数据集上的大量实验证明了其有效性和鲁棒性。此外，附加的评估和分析突显了其强大的泛化能力和对先前未见场景的适应性。

Abstract: Blind image quality assessment (BIQA) methods often incorporate auxiliary
tasks to improve performance. However, existing approaches face limitations due
to insufficient integration and a lack of flexible uncertainty estimation,
leading to suboptimal performance. To address these challenges, we propose a
multitasks-based Deep Evidential Fusion Network (DEFNet) for BIQA, which
performs multitask optimization with the assistance of scene and distortion
type classification tasks. To achieve a more robust and reliable
representation, we design a novel trustworthy information fusion strategy. It
first combines diverse features and patterns across sub-regions to enhance
information richness, and then performs local-global information fusion by
balancing fine-grained details with coarse-grained context. Moreover, DEFNet
exploits advanced uncertainty estimation technique inspired by evidential
learning with the help of normal-inverse gamma distribution mixture. Extensive
experiments on both synthetic and authentic distortion datasets demonstrate the
effectiveness and robustness of the proposed framework. Additional evaluation
and analysis are carried out to highlight its strong generalization capability
and adaptability to previously unseen scenarios.

</details>


### [87] [GS-Occ3D: Scaling Vision-only Occupancy Reconstruction for Autonomous Driving with Gaussian Splatting](https://arxiv.org/abs/2507.19451)
*Baijun Ye,Minghui Qin,Saining Zhang,Moonjun Gong,Shaoting Zhu,Zebang Shen,Luan Zhang,Lu Zhang,Hao Zhao,Hang Zhao*

Main category: cs.CV

TL;DR: GS-Occ3D是一种新的纯视觉框架，用于可扩展的3D占用重建，通过优化高斯曲面表示并分离场景元素（如地面和动态物体）来提高准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖于激光雷达标注的占用情况，这限制了可扩展性，并且无法利用大量潜在的众包数据进行自动标注。此外，现有的基于视觉的方法主要依赖网格表示，存在几何不完整和额外的后处理问题，限制了可扩展性。

Method: GS-Occ3D通过优化基于八叉树的高斯曲面表示来直接重建占用情况。该框架将场景分解为静态背景、地面和动态物体，并为地面和动态车辆分别采用定制的建模策略，以提高大面积一致性和捕捉与运动相关的占用模式。

Result: GS-Occ3D在Waymo数据集上实现了最先进的几何重建结果，并在Occ3D-Waymo和Occ3D-nuScenes上展示了良好的下游模型性能和零样本泛化能力。

Conclusion: GS-Occ3D是一个可扩展的纯视觉框架，可以直接重建占用情况。通过将场景分解为静态背景、地面和动态物体，并采用量身定制的建模策略，GS-Occ3D在Waymo数据集上实现了最先进的几何重建结果。此外，通过策划来自不同城市景观的纯视觉二值占用标签，证明了它们在Occ3D-Waymo上的下游占用模型中的有效性，并在Occ3D-nuScenes上实现了卓越的零样本泛化能力。这标志着大规模视觉占用重建作为自动驾驶感知新范式的发展潜力。

Abstract: Occupancy is crucial for autonomous driving, providing essential geometric
priors for perception and planning. However, existing methods predominantly
rely on LiDAR-based occupancy annotations, which limits scalability and
prevents leveraging vast amounts of potential crowdsourced data for
auto-labeling. To address this, we propose GS-Occ3D, a scalable vision-only
framework that directly reconstructs occupancy. Vision-only occupancy
reconstruction poses significant challenges due to sparse viewpoints, dynamic
scene elements, severe occlusions, and long-horizon motion. Existing
vision-based methods primarily rely on mesh representation, which suffer from
incomplete geometry and additional post-processing, limiting scalability. To
overcome these issues, GS-Occ3D optimizes an explicit occupancy representation
using an Octree-based Gaussian Surfel formulation, ensuring efficiency and
scalability. Additionally, we decompose scenes into static background, ground,
and dynamic objects, enabling tailored modeling strategies: (1) Ground is
explicitly reconstructed as a dominant structural element, significantly
improving large-area consistency; (2) Dynamic vehicles are separately modeled
to better capture motion-related occupancy patterns. Extensive experiments on
the Waymo dataset demonstrate that GS-Occ3D achieves state-of-the-art geometry
reconstruction results. By curating vision-only binary occupancy labels from
diverse urban scenes, we show their effectiveness for downstream occupancy
models on Occ3D-Waymo and superior zero-shot generalization on Occ3D-nuScenes.
It highlights the potential of large-scale vision-based occupancy
reconstruction as a new paradigm for autonomous driving perception. Project
Page: https://gs-occ3d.github.io/

</details>


### [88] [Back to the Features: DINO as a Foundation for Video World Models](https://arxiv.org/abs/2507.19468)
*Federico Baldassarre,Marc Szafraniec,Basile Terver,Vasil Khalidov,Francisco Massa,Yann LeCun,Patrick Labatut,Maximilian Seitzer,Piotr Bojanowski*

Main category: cs.CV

TL;DR: DINO-world是一个通用的视频世界模型，可以预测未来帧，并在视频预测和规划任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了构建一个能够理解和预测各种场景（包括驾驶、室内和模拟环境）时间动态的通用视频世界模型。

Method: 利用预训练的图像编码器，在大型未筛选视频数据集上训练未来预测器，并进行行为条件化以用于规划。

Result: DINO-world在视频预测基准测试中表现优于现有模型，并在分割和深度预测等任务上取得了良好结果，同时展现了对直观物理学的深刻理解。

Conclusion: DINO-world是一个强大的通用视频世界模型，可以通过在DINOv2的潜在空间中预测未来帧来学习各种场景的时间动态。它可以用于视频预测任务，并且可以通过行为条件化进行规划。

Abstract: We present DINO-world, a powerful generalist video world model trained to
predict future frames in the latent space of DINOv2. By leveraging a
pre-trained image encoder and training a future predictor on a large-scale
uncurated video dataset, DINO-world learns the temporal dynamics of diverse
scenes, from driving and indoor scenes to simulated environments. We show that
DINO-world outperforms previous models on a variety of video prediction
benchmarks, e.g. segmentation and depth forecasting, and demonstrates strong
understanding of intuitive physics. Furthermore, we show that it is possible to
fine-tune the predictor on observation-action trajectories. The resulting
action-conditioned world model can be used for planning by simulating candidate
trajectories in latent space.

</details>


### [89] [DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations](https://arxiv.org/abs/2507.19474)
*Ziren Gong,Xiaohan Li,Fabio Tosi,Youmin Zhang,Stefano Mattoccia,Jun Wu,Matteo Poggi*

Main category: cs.CV

TL;DR: DINO-SLAM利用DINO特征增强SLAM中的NeRF和3DGS表示，取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在SLAM系统中通过更全面的场景表示来增强神经隐式（NeRF）和显式表示（3DGS）。

Method: 本文提出了一种基于DINO的SLAM系统设计策略，称为DINO-SLAM。该策略利用场景结构编码器（SSE）将DINO特征丰富为增强DINO（EDINO）特征，以捕捉分层的场景元素及其结构关系。在此基础上，为NeRF和3DGS SLAM系统提出了两种整合EDINO特征的基础范式。

Result: DINO-SLAM在Replica、ScanNet和TUM数据集上取得了优于现有最先进方法的性能。

Conclusion: DINO-SLAM通过引入DINO特征来增强神经隐式和显式表示，在SLAM系统上实现了更全面的场景表示，并在Replica、ScanNet和TUM数据集上取得了优于现有最先进方法的性能。

Abstract: This paper presents DINO-SLAM, a DINO-informed design strategy to enhance
neural implicit (Neural Radiance Field -- NeRF) and explicit representations
(3D Gaussian Splatting -- 3DGS) in SLAM systems through more comprehensive
scene representations. Purposely, we rely on a Scene Structure Encoder (SSE)
that enriches DINO features into Enhanced DINO ones (EDINO) to capture
hierarchical scene elements and their structural relationships. Building upon
it, we propose two foundational paradigms for NeRF and 3DGS SLAM systems
integrating EDINO features. Our DINO-informed pipelines achieve superior
performance on the Replica, ScanNet, and TUM compared to state-of-the-art
methods.

</details>


### [90] [HairCUP: Hair Compositional Universal Prior for 3D Gaussian Avatars](https://arxiv.org/abs/2507.19481)
*Byungjun Kim,Shunsuke Saito,Giljoo Nam,Tomas Simon,Jason Saragih,Hanbyul Joo,Junxuan Li*

Main category: cs.CV

TL;DR: 这项工作提出了一种新颖的3D人头化身生成方法，通过显式地分离面部和头发来解决现有方法的局限性，从而实现更灵活和可控的化身创建。


<details>
  <summary>Details</summary>
Motivation: 现有方法将面部和头发视为一个不可分割的整体，难以解开面部和头发的表示，并且难以灵活、可控地支持3D面部和发型交换等应用。

Method: 本文提出了一种显式头发组合性的通用3D人头化身先验模型。该方法通过生成合成的无毛数据来学习单独的人脸和头发的潜在空间，并将组合性作为归纳偏差纳入，以实现有效的分离。

Result: 通过利用成对的头发和无毛捕获数据集，训练了用于面部和头发的独立先验模型，该模型实现了无缝传输和身份保留，并能以少样本的方式进行微调。

Conclusion: 该模型实现了可控的3D人头模型生成，能够将面部和头发组件无缝转移，同时保持身份的完整性，并且能够使用单眼捕捉以少样本的方式进行微调，以创建高质量、头发构成性的人头3D化身。

Abstract: We present a universal prior model for 3D head avatars with explicit hair
compositionality. Existing approaches to build generalizable priors for 3D head
avatars often adopt a holistic modeling approach, treating the face and hair as
an inseparable entity. This overlooks the inherent compositionality of the
human head, making it difficult for the model to naturally disentangle face and
hair representations, especially when the dataset is limited. Furthermore, such
holistic models struggle to support applications like 3D face and hairstyle
swapping in a flexible and controllable manner. To address these challenges, we
introduce a prior model that explicitly accounts for the compositionality of
face and hair, learning their latent spaces separately. A key enabler of this
approach is our synthetic hairless data creation pipeline, which removes hair
from studio-captured datasets using estimated hairless geometry and texture
derived from a diffusion prior. By leveraging a paired dataset of hair and
hairless captures, we train disentangled prior models for face and hair,
incorporating compositionality as an inductive bias to facilitate effective
separation. Our model's inherent compositionality enables seamless transfer of
face and hair components between avatars while preserving identity.
Additionally, we demonstrate that our model can be fine-tuned in a few-shot
manner using monocular captures to create high-fidelity, hair-compositional 3D
head avatars for unseen subjects. These capabilities highlight the practical
applicability of our approach in real-world scenarios, paving the way for
flexible and expressive 3D avatar generation.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [91] [Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement](https://arxiv.org/abs/2507.18742)
*Víctor Gallego*

Main category: cs.CL

TL;DR: SSC, a test-time framework, helps LMs fix their own instructions to prevent "reward hacking," significantly improving their reliability in tasks like creative writing and coding.


<details>
  <summary>Details</summary>
Motivation: LMs are susceptible to in-context reward hacking, where they exploit flaws in specifications to achieve high scores without fulfilling user intent.

Method: SSC employs a multi-step inference process: 1. Generate response based on specification. 2. Critique output. 3. Revise specification to remove loopholes. 4. Generate final response using self-corrected specification.

Result: Experiments across creative writing and agentic coding tasks show that SSC reduces LM vulnerability to reward hacking by over 90% in cases where models initially exploit tainted specifications (50-70% of cases).

Conclusion: SSC is a test-time framework that enables LMs to identify and correct flaws in their own guiding specifications, reducing vulnerability to in-context reward hacking by over 90% without requiring weight modification.

Abstract: Language models (LMs) are susceptible to in-context reward hacking, where
they exploit flaws in tainted or faulty written specifications or rubrics to
achieve high scores without fulfilling the user's true intent. We introduce
Specification Self-Correction (SSC), a novel, test-time framework that enables
an LM to identify and correct flaws within its own guiding specification. SSC
employs a multi-step inference process where the model first generates a
response based on a potentially tainted specification, critiques its output,
and then revises the specification itself to remove the exploitable loophole. A
final, more robust response is then generated using this self-corrected
specification. Across experiments spanning creative writing and agentic coding
tasks with several LMs, we demonstrate that while models initially game tainted
specifications in 50-70\% of cases, the SSC process reduces this vulnerability
by over 90\%. This dynamic repair occurs at inference time, requires no weight
modification, and leads to more robustly aligned model behavior. Code at
https://github.com/vicgalle/specification-self-correction .

</details>


### [92] [The Role of Orthographic Consistency in Multilingual Embedding Models for Text Classification in Arabic-Script Languages](https://arxiv.org/abs/2507.18762)
*Abdulhady Abas Abdullah,Amir H. Gandomi,Tarik A Rashid,Seyedali Mirjalili,Laith Abualigah,Milena Živković,Hadi Veisi*

Main category: cs.CL

TL;DR: AS-RoBERTa models, pre-trained on language-specific Arabic script features, outperform general multilingual models like mBERT and XLM-RoBERTa on classification tasks, demonstrating the benefit of script-aware specialization.


<details>
  <summary>Details</summary>
Motivation: Multilingual models like mBERT and XLM-RoBERTa, while promising broad coverage, often struggle with languages sharing a script but differing in orthographic norms and cultural context, particularly evident in Arabic-script languages like Kurdish Sorani, Arabic, Persian, and Urdu.

Method: The study introduces the Arabic Script RoBERTa (AS-RoBERTa) family, comprising four RoBERTa-based models. These models are pre-trained on language-specific corpora, focusing on script features and statistics to capture patterns missed by general-purpose models. The effectiveness is evaluated through fine-tuning on classification tasks and confirmed via an ablation study and error analysis using confusion matrices.

Result: AS-RoBERTa variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points on classification tasks. An ablation study validated the importance of script-focused pre-training, and error analysis using confusion matrices revealed how shared script traits and domain-specific content influence performance.

Conclusion: AS-RoBERTa variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points in classification tasks, and script-focused pre-training is central to these gains. The findings highlight the value of script-aware specialization for languages using the Arabic script and support further work on pre-training strategies rooted in script and language specificity.

Abstract: In natural language processing, multilingual models like mBERT and
XLM-RoBERTa promise broad coverage but often struggle with languages that share
a script yet differ in orthographic norms and cultural context. This issue is
especially notable in Arabic-script languages such as Kurdish Sorani, Arabic,
Persian, and Urdu. We introduce the Arabic Script RoBERTa (AS-RoBERTa) family:
four RoBERTa-based models, each pre-trained on a large corpus tailored to its
specific language. By focusing pre-training on language-specific script
features and statistics, our models capture patterns overlooked by
general-purpose models. When fine-tuned on classification tasks, AS-RoBERTa
variants outperform mBERT and XLM-RoBERTa by 2 to 5 percentage points. An
ablation study confirms that script-focused pre-training is central to these
gains. Error analysis using confusion matrices shows how shared script traits
and domain-specific content affect performance. Our results highlight the value
of script-aware specialization for languages using the Arabic script and
support further work on pre-training strategies rooted in script and language
specificity.

</details>


### [93] [ylmmcl at Multilingual Text Detoxification 2025: Lexicon-Guided Detoxification and Classifier-Gated Rewriting](https://arxiv.org/abs/2507.18769)
*Nicole Lai-Lopez,Lusha Wang,Su Yuan,Liza Zhang*

Main category: cs.CL

TL;DR: ylmmcl团队在PAN-2025竞赛中，通过结合词典标注、微调的Seq2Seq模型和迭代分类器，提出了一种多语言文本去毒方法。该方法在多语言文本去毒任务中表现出色，取得了优异的成绩，尤其在高资源语言中泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 为了在PAN-2025竞赛的多语言文本去毒任务中提供一个鲁棒的解决方案，并超越以往无监督或单一语言的方法。

Method: 该方法采用了一种多语言文本去毒流程，结合了词典引导标注、序列到序列模型（s-nlp/mt0-xl-detox-orpo）微调以及基于迭代分类器的门控机制。该方法利用多语言毒性词典进行显式毒性词标注，以实现更精确的去毒和跨语言泛化。

Result: 该模型达到了0.922的最高STA分数和0.612的平均官方J分数，xCOMET分数分别为0.793（开发集）和0.787（测试集）。该性能优于基线和反向翻译方法，并在高资源语言中表现出强大的泛化能力。

Conclusion: 该模型在多语言文本去毒任务中表现出强大的能力，在开发集和测试集中取得了0.612的平均官方J分数，并在高资源语言（英语、俄语、法语）中表现出强大的泛化能力。虽然在SIM方面存在一些权衡，但该模型在去毒强度方面显示出持续的改进，团队在比赛中获得了第九名。

Abstract: In this work, we introduce our solution for the Multilingual Text
Detoxification Task in the PAN-2025 competition for the ylmmcl team: a robust
multilingual text detoxification pipeline that integrates lexicon-guided
tagging, a fine-tuned sequence-to-sequence model (s-nlp/mt0-xl-detox-orpo) and
an iterative classifier-based gatekeeping mechanism. Our approach departs from
prior unsupervised or monolingual pipelines by leveraging explicit toxic word
annotation via the multilingual_toxic_lexicon to guide detoxification with
greater precision and cross-lingual generalization. Our final model achieves
the highest STA (0.922) from our previous attempts, and an average official J
score of 0.612 for toxic inputs in both the development and test sets. It also
achieved xCOMET scores of 0.793 (dev) and 0.787 (test). This performance
outperforms baseline and backtranslation methods across multiple languages, and
shows strong generalization in high-resource settings (English, Russian,
French). Despite some trade-offs in SIM, the model demonstrates consistent
improvements in detoxification strength. In the competition, our team achieved
ninth place with a score of 0.612.

</details>


### [94] [Evaluating Code-Mixing in LLMs Across 18 Languages](https://arxiv.org/abs/2507.18791)
*Yilun Yang,Yekun Chai*

Main category: cs.CL

TL;DR: 本研究全面评估了LLM在18种语言混合语数据上的表现，并提出了一种新的混合语文本生成方法。结果显示LLM在多语种混合语任务上表现不佳，建议通过增加训练数据、模型规模和少样本学习来改进。


<details>
  <summary>Details</summary>
Motivation: 为了应对传统NLP在处理混合语（在对话中在语言间切换）方面的挑战，并解决现有基准测试在语言配对和任务方面的局限性，以及LLM在混合语研究和数据生成方法方面的不足。

Method: 通过结合词语替换和GPT-4提示，提出了一种生成合成混合语文本的新方法，并对LLMs在18种语言（来自七个语系）的混合语数据上的表现进行了全面评估。

Result: LLMs在涉及多语种的混合语数据集上表现持续不佳。

Conclusion: LLMs在涉及多语种的混合语数据集上表现持续不佳，建议通过增加训练数据量、模型规模和少样本学习来提高其性能。

Abstract: Code-mixing, the practice of switching between languages within a
conversation, presents unique challenges for traditional natural language
processing. Existing benchmarks, such as LinCE and GLUECoS, are limited by
narrow language pairings and tasks, failing to adequately evaluate the
code-mixing capabilities of large language models (LLMs). Despite the
significance of code-mixing for multilingual users, research on LLMs in this
context remains limited. Additionally, current methods for generating
code-mixed data are underdeveloped. In this paper, we conduct a comprehensive
evaluation of LLMs' performance on code-mixed data across 18 languages from
seven language families. We also propose a novel approach for generating
synthetic code-mixed texts by combining word substitution with GPT-4 prompting.
Our analysis reveals consistent underperformance of LLMs on code-mixed datasets
involving multiple language families. We suggest that improvements in training
data size, model scale, and few-shot learning could enhance their performance.

</details>


### [95] [CueBuddy: helping non-native English speakers navigate English-centric STEM education](https://arxiv.org/abs/2507.18827)
*Pranav Gupta*

Main category: cs.CL

TL;DR: CueBuddy是一款旨在帮助STEM学生克服英语学习障碍的工具，通过实时词汇提示和多语言词汇表查找来解决技术术语理解问题。


<details>
  <summary>Details</summary>
Motivation: 全球南方国家STEM学生由于英语非母语，在学习过程中面临理解英语技术术语的挑战，即使他们在科学先决条件方面与其他学生相当。

Method: CueBuddy通过实时词汇提示、技术关键词识别和多语言词汇表查找来帮助学生理解复杂的英语术语。

Result: CueBuddy通过提供实时词汇提示和多语言词汇表查找，帮助学生克服理解复杂英语术语的障碍。

Conclusion: CueBuddy旨在通过实时词汇提示、技术关键词识别和多语言词汇表查找来解决STEM领域学生在英语学习上的障碍，帮助他们理解复杂的英语术语，而不会分散他们对讲座的注意力。

Abstract: Students across the world in STEM classes, especially in the Global South,
fall behind their peers who are more fluent in English, despite being at par
with them in terms of scientific prerequisites. While many of them are able to
follow everyday English at ease, key terms in English stay challenging. In most
cases, such students have had most of their course prerequisites in a lower
resource language. Live speech translation to lower resource languages is a
promising area of research, however, models for speech translation can be too
expensive on a large scale and often struggle with technical content. In this
paper, we describe CueBuddy, which aims to remediate these issues by providing
real-time "lexical cues" through technical keyword spotting along real-time
multilingual glossary lookup to help students stay up to speed with complex
English jargon without disrupting their concentration on the lecture. We also
describe the limitations and future extensions of our approach.

</details>


### [96] [PrismRAG: Boosting RAG Factuality with Distractor Resilience and Strategized Reasoning](https://arxiv.org/abs/2507.18857)
*Mohammad Kachuee,Teja Gollapudi,Minseok Kim,Yin Huang,Kai Sun,Xiao Yang,Jiaqi Wang,Nirav Shah,Yue Liu,Aaron Colak,Anuj Kumar,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CL

TL;DR: PrismRAG 是一个高效的微调框架，通过包含干扰信息和注重推理的训练数据，提高了检索增强生成在处理复杂问题时的准确性和能力。


<details>
  <summary>Details</summary>
Motivation: 检索增强生成（RAG）在面对包含干扰性信息或需要深度上下文理解与推理的问题时，表现往往不佳。

Method: PrismRAG 通过两种方式进行优化：1. 采用包含正确证据和干扰性信息的 QA 数据对进行模型训练；2. 培养以推理为中心的习惯，使大型语言模型能够进行规划、推理和综合，而无需大量人工指令。

Result: PrismRAG 在 12 项开放域检索增强生成问答基准测试中，平均事实性提高了 5.4%，超越了现有最先进的解决方案。

Conclusion: PrismRAG 框架在 12 项开放域检索增强生成问答基准测试中表现出色，平均事实性提高了 5.4%，优于现有最先进的解决方案。

Abstract: Retrieval-augmented generation (RAG) often falls short when retrieved context
includes confusing semi-relevant passages, or when answering questions require
deep contextual understanding and reasoning. We propose an efficient
fine-tuning framework, called PrismRAG, that (i) trains the model with
distractor-aware QA pairs mixing gold evidence with subtle distractor passages,
and (ii) instills reasoning-centric habits that make the LLM plan, rationalize,
and synthesize without relying on extensive human engineered instructions.
Evaluated across 12 open-book RAG QA benchmarks spanning diverse application
domains and scenarios, PrismRAG improves average factuality by 5.4%,
outperforming state-of-the-art solutions.

</details>


### [97] [MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service](https://arxiv.org/abs/2507.18884)
*Ming Gong,Xucheng Huang,Ziheng Xu,Vijayan K. Asari*

Main category: cs.CL

TL;DR: MindFlow+ 是一个结合了 LLMs、模仿学习和离线 RL 的自演进对话代理，通过新颖的数据中心机制提高了电子商务客户服务的对话质量，并在真实世界的对话中得到了证明。


<details>
  <summary>Details</summary>
Motivation: 传统意图驱动系统难以处理动态、多轮的电子商务客户服务对话，需要一种能够学习领域特定行为的更高级的对话代理。

Method: MindFlow+ 采用模仿学习和离线强化学习，结合了工具增强的演示构建（用于有效的工具使用）和奖励条件数据建模（使用奖励信号使响应与特定任务目标保持一致）。

Result: MindFlow+ 在上下文相关性、灵活性和任务准确性方面优于强有力的基线，并且引入了衡量 AI 参与度的指标“AI 贡献率”。

Conclusion: MindFlow+ 结合了 LLMs、模仿学习和离线强化学习，并通过工具增强演示构建和奖励条件数据建模来学习领域特定行为，在电子商务对话中表现出色，证明了其在构建领域专业化、上下文感知对话系统方面的潜力。

Abstract: High-quality dialogue is crucial for e-commerce customer service, yet
traditional intent-based systems struggle with dynamic, multi-turn
interactions. We present MindFlow+, a self-evolving dialogue agent that learns
domain-specific behavior by combining large language models (LLMs) with
imitation learning and offline reinforcement learning (RL). MindFlow+
introduces two data-centric mechanisms to guide learning: tool-augmented
demonstration construction, which exposes the model to knowledge-enhanced and
agentic (ReAct-style) interactions for effective tool use; and
reward-conditioned data modeling, which aligns responses with task-specific
goals using reward signals. To evaluate the model's role in response
generation, we introduce the AI Contribution Ratio, a novel metric quantifying
AI involvement in dialogue. Experiments on real-world e-commerce conversations
show that MindFlow+ outperforms strong baselines in contextual relevance,
flexibility, and task accuracy. These results demonstrate the potential of
combining LLMs tool reasoning, and reward-guided learning to build
domain-specialized, context-aware dialogue systems.

</details>


### [98] [NUTMEG: Separating Signal From Noise in Annotator Disagreement](https://arxiv.org/abs/2507.18890)
*Jonathan Ivey,Susan Gauch,David Jurgens*

Main category: cs.CL

TL;DR: NUTMEG是一个贝叶斯模型，用于处理NLP中来自不同注释者的冲突数据，通过区分噪声和信号来提高数据质量，并最终提升下游模型的性能。


<details>
  <summary>Details</summary>
Motivation: 许多NLP模型依赖于人类标记的数据进行训练和评估。然而，由于注释者技能、背景和动机的差异，这些数据通常包含冲突的注释。这些冲突在传统上被视为错误并通过聚合方法解决。但最近的研究表明，在许多任务中，注释者之间可能存在真实的分歧，应该将这种变异视为信号而非噪声。然而，很少有模型能够区分注释者分歧中的信号和噪声。

Method: NUTMEG是一个新的贝叶斯模型，它结合了注释者背景信息来移除有噪声的注释，同时保留系统性的分歧。

Result: 使用合成数据，证明NUTMEG比传统聚合方法更有效地从注释中恢复地面真实。通过分析子群体大小、分歧率和垃圾邮件率对模型性能的影响来进一步表征。最后，展示了在NUTMEG聚合数据上训练的下游模型性能优于在传统聚合方法数据上训练的模型。

Conclusion: NUTMEG在处理包含系统性分歧的带有人类标签的训练数据时，比传统的聚合方法更有效地恢复了地面真实。NUTMEG通过结合注释者背景信息来移除有噪声的注释，同时保留系统性的分歧。在NUTMEG聚合的数据上训练的下游模型明显优于在传统聚合方法的数据上训练的模型。

Abstract: NLP models often rely on human-labeled data for training and evaluation. Many
approaches crowdsource this data from a large number of annotators with varying
skills, backgrounds, and motivations, resulting in conflicting annotations.
These conflicts have traditionally been resolved by aggregation methods that
assume disagreements are errors. Recent work has argued that for many tasks
annotators may have genuine disagreements and that variation should be treated
as signal rather than noise. However, few models separate signal and noise in
annotator disagreement. In this work, we introduce NUTMEG, a new Bayesian model
that incorporates information about annotator backgrounds to remove noisy
annotations from human-labeled training data while preserving systematic
disagreements. Using synthetic data, we show that NUTMEG is more effective at
recovering ground-truth from annotations with systematic disagreement than
traditional aggregation methods. We provide further analysis characterizing how
differences in subpopulation sizes, rates of disagreement, and rates of spam
affect the performance of our model. Finally, we demonstrate that downstream
models trained on NUTMEG-aggregated data significantly outperform models
trained on data from traditionally aggregation methods. Our results highlight
the importance of accounting for both annotator competence and systematic
disagreements when training on human-labeled data.

</details>


### [99] [REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?](https://arxiv.org/abs/2507.18901)
*Chuxuan Hu,Liyun Zhang,Yeji Lim,Aum Wadhwani,Austin Peters,Daniel Kang*

Main category: cs.CL

TL;DR: 本研究提出了REPRO-Bench基准测试，用于评估AI代理在社会科学论文可再现性评估方面的能力。结果表明，现有AI代理的表现不佳，但通过REPRO-Agent的开发，准确率得到了显著提升，并强调了开发更先进AI代理以实现自动化评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 评估AI代理自动评估社会科学论文可再现性的能力，以解决手动评估成本高昂的问题，并解决现有基准测试的局限性。

Method: 通过引入REPRO-Bench（包含112个任务实例，每个实例代表一篇具有公开再现性报告的社会科学论文），并评估了三个代表性AI代理，然后开发了REPRO-Agent。

Result: 所提出的REPRO-Bench基准测试能够对社会科学论文的可再现性进行端到端评估，其复杂性与现实世界的评估相当。在REPRO-Bench上，最好的AI代理的准确率仅为21.4%，而REPRO-Agent的准确率提高了71%。

Conclusion: 需要开发更高级的AI代理来自动化现实世界的再现性评估。

Abstract: Assessing the reproducibility of social science papers is essential for
promoting rigor in research processes, but manual assessment is costly. With
recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate
their capability to automate this process. However, existing benchmarks for
reproducing research papers (1) focus solely on reproducing results using
provided code and data without assessing their consistency with the paper, (2)
oversimplify real-world scenarios, and (3) lack necessary diversity in data
formats and programming languages. To address these issues, we introduce
REPRO-Bench, a collection of 112 task instances, each representing a social
science paper with a publicly available reproduction report. The agents are
tasked with assessing the reproducibility of the paper based on the original
paper PDF and the corresponding reproduction package. REPRO-Bench features
end-to-end evaluation tasks on the reproducibility of social science papers
with complexity comparable to real-world assessments. We evaluate three
representative AI agents on REPRO-Bench, with the best-performing agent
achieving an accuracy of only 21.4%. Building on our empirical analysis, we
develop REPRO-Agent, which improves the highest accuracy achieved by existing
agents by 71%. We conclude that more advanced AI agents should be developed to
automate real-world reproducibility assessment. REPRO-Bench is publicly
available at https://github.com/uiuc-kang-lab/REPRO-Bench.

</details>


### [100] [SLoW: Select Low-frequency Words! Automatic Dictionary Selection for Translation on Large Language Models](https://arxiv.org/abs/2507.18902)
*Hongyuan Lu,Zixuan Li,Zefan Zhang,Wai Lam*

Main category: cs.CL

TL;DR: A new method called SLoW automatically selects low-frequency dictionaries to improve LLM translation, saving tokens and often outperforming full dictionary methods without needing training data.


<details>
  <summary>Details</summary>
Motivation: Current LLMs only support hundreds of languages, far fewer than the more than 7,000 languages worldwide. Dictionary-based prompting methods can enhance translation but are often expensive due to using all available dictionaries. There is a need for a flexible trade-off between token consumption and translation performance.

Method: A novel and effective method called Select Low-frequency Words! (SLoW) which selects dictionaries that have a lower frequency.

Result: Experimental results on 100 languages from FLORES indicate that SLoW surpasses strong baselines, and it can obviously save token usage, with many languages even surpassing the translation performance of the full dictionary baseline.

Conclusion: SLoW surpasses strong baselines and obviously saves token usage, with many languages even surpassing the full dictionary baseline.

Abstract: There are more than 7,000 languages around the world, and current Large
Language Models (LLMs) only support hundreds of languages. Dictionary-based
prompting methods can enhance translation on them, but most methods use all the
available dictionaries, which could be expensive. Instead, it will be flexible
to have a trade-off between token consumption and translation performance. This
paper proposes a novel task called \textbf{A}utomatic \textbf{D}ictionary
\textbf{S}election (\textbf{ADS}). The goal of the task is to automatically
select which dictionary to use to enhance translation. We propose a novel and
effective method which we call \textbf{S}elect \textbf{Lo}w-frequency
\textbf{W}ords! (\textbf{SLoW}) which selects those dictionaries that have a
lower frequency. Our methods have unique advantages. First, there is no need
for access to the training data for frequency estimation (which is usually
unavailable). Second, it inherits the advantage of dictionary-based methods,
where no additional tuning is required on LLMs. Experimental results on 100
languages from FLORES indicate that SLoW surpasses strong baselines, and it can
obviously save token usage, with many languages even surpassing the translation
performance of the full dictionary baseline.\footnote{A shocking fact is that
there is no need to use the actual training data (often unobtainable) for
frequency estimation, and an estimation frequency obtained using public
resources is still apparently effective in improving translation with ChatGPT
and Llama, and DeepSeek.}\footnote{Code and data available upon publication.}

</details>


### [101] [Large language models provide unsafe answers to patient-posed medical questions](https://arxiv.org/abs/2507.18905)
*Rachel L. Draelos,Samina Afreen,Barbara Blasko,Tiffany Brazile,Natasha Chase,Dimple Desai,Jessica Evert,Heather L. Gardner,Lauren Herrmann,Aswathy Vaikom House,Stephanie Kass,Marianne Kavan,Kirshma Khemani,Amanda Koire,Lauren M. McDonald,Zahraa Rabeeah,Amy Shah*

Main category: cs.CL

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Millions of patients are already using large language model (LLM) chatbots
for medical advice on a regular basis, raising patient safety concerns. This
physician-led red-teaming study compares the safety of four publicly available
chatbots--Claude by Anthropic, Gemini by Google, GPT-4o by OpenAI, and
Llama3-70B by Meta--on a new dataset, HealthAdvice, using an evaluation
framework that enables quantitative and qualitative analysis. In total, 888
chatbot responses are evaluated for 222 patient-posed advice-seeking medical
questions on primary care topics spanning internal medicine, women's health,
and pediatrics. We find statistically significant differences between chatbots.
The rate of problematic responses varies from 21.6 percent (Claude) to 43.2
percent (Llama), with unsafe responses varying from 5 percent (Claude) to 13
percent (GPT-4o, Llama). Qualitative results reveal chatbot responses with the
potential to lead to serious patient harm. This study suggests that millions of
patients could be receiving unsafe medical advice from publicly available
chatbots, and further work is needed to improve the clinical safety of these
powerful tools.

</details>


### [102] [A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions](https://arxiv.org/abs/2507.18910)
*Agada Joseph Oche,Ademola Glory Folashade,Tirthankar Ghosal,Arpan Biswas*

Main category: cs.CL

TL;DR: 对检索增强生成（RAG）进行了系统性回顾，重点关注了其动机、技术组件、部署挑战和未来发展。


<details>
  <summary>Details</summary>
Motivation: RAG的动机在于能够减少幻觉和过时知识在参数模型中的问题。

Method: 本篇论文提出了一个关于RAG的系统性回顾，追溯了其从开放域问答到跨多种应用的最新实现。

Result: 对RAG实现进行了比较评估，并在检索准确性、生成流畅性、延迟和计算效率方面进行了基准测试。

Conclusion: RAG的持续创新预示着更可靠、高效和上下文感知知识密集型NLP系统的未来。

Abstract: Retrieval-Augmented Generation (RAG) represents a major advancement in
natural language processing (NLP), combining large language models (LLMs) with
information retrieval systems to enhance factual grounding, accuracy, and
contextual relevance. This paper presents a comprehensive systematic review of
RAG, tracing its evolution from early developments in open domain question
answering to recent state-of-the-art implementations across diverse
applications. The review begins by outlining the motivations behind RAG,
particularly its ability to mitigate hallucinations and outdated knowledge in
parametric models. Core technical components-retrieval mechanisms,
sequence-to-sequence generation models, and fusion strategies are examined in
detail. A year-by-year analysis highlights key milestones and research trends,
providing insight into RAG's rapid growth. The paper further explores the
deployment of RAG in enterprise systems, addressing practical challenges
related to retrieval of proprietary data, security, and scalability. A
comparative evaluation of RAG implementations is conducted, benchmarking
performance on retrieval accuracy, generation fluency, latency, and
computational efficiency. Persistent challenges such as retrieval quality,
privacy concerns, and integration overhead are critically assessed. Finally,
the review highlights emerging solutions, including hybrid retrieval
approaches, privacy-preserving techniques, optimized fusion strategies, and
agentic RAG architectures. These innovations point toward a future of more
reliable, efficient, and context-aware knowledge-intensive NLP systems.

</details>


### [103] [Mining Contextualized Visual Associations from Images for Creativity Understanding](https://arxiv.org/abs/2507.18915)
*Ananya Sahu,Amith Ananthram,Kathleen McKeown*

Main category: cs.CL

TL;DR: 通过挖掘图像中的关联性视觉元素，生成了具有不同抽象程度的创意标题，并在创意领域（诗歌、隐喻可视化）的零次图像-文本检索任务上取得了改进。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解他人的创造性输出，需要一种共享的联想语言。然而，目前的视觉-语言模型训练依赖于包含简短、字面化alt-文本的网络抓取数据集。

Method: 提出了一种从任何无标签数据集中挖掘关联性视觉元素的上下文关联方法，并利用这些关联性生成不同抽象程度的创意标题。

Result: 生成了包含视觉联想的新数据集和MSCOCO图像的170万个创意标题。人类评估证实，这些标题在保持视觉基础的同时，展现出可识别的抽象性。

Conclusion: 使用本文方法生成的数据集训练的视觉编码器在诗歌和隐喻可视化等创意领域，在零次图像-文本检索方面取得了显著的改进。

Abstract: Understanding another person's creative output requires a shared language of
association. However, when training vision-language models such as CLIP, we
rely on web-scraped datasets containing short, predominantly literal, alt-text.
In this work, we introduce a method for mining contextualized associations for
salient visual elements in an image that can scale to any unlabeled dataset.
Given an image, we can use these mined associations to generate high quality
creative captions at increasing degrees of abstraction. With our method, we
produce a new dataset of visual associations and 1.7m creative captions for the
images in MSCOCO. Human evaluation confirms that these captions remain visually
grounded while exhibiting recognizably increasing abstraction. Moreover,
fine-tuning a visual encoder on this dataset yields meaningful improvements in
zero-shot image-text retrieval in two creative domains: poetry and metaphor
visualization. We release our dataset, our generation code and our models for
use by the broader community.

</details>


### [104] [Uncovering Cross-Linguistic Disparities in LLMs using Sparse Autoencoders](https://arxiv.org/abs/2507.18918)
*Richmond Sin Jing Xuan,Jalil Huseynov,Yang Zhang*

Main category: cs.CL

TL;DR: 多语言LLM在低资源语言上表现不佳。通过SAE分析发现激活模式存在系统性差异。通过LoRA激活感知微调可以提高低资源语言的激活水平并改善基准测试性能，同时保持英语性能。


<details>
  <summary>Details</summary>
Motivation: 多语言LLM在跨语言泛化方面表现出色，但在中低资源语言上的表现却不佳，这在ARC-Challenge、MMLU和HellaSwag等基准测试中尤为明显。

Method: 使用稀疏自编码器（SAE）分析了Gemma-2-2B在26个残差层和10种语言（包括中、俄、西、意、印尼、加泰罗尼亚、马拉地、马拉雅拉姆和印地语）中的激活模式。然后，应用了激活感知微调（LoRA）来解决观察到的激活差异。

Result: 该研究发现，中低资源语言在早期层的激活水平比高资源语言低26.27%，在较深层中仍存在19.89%的差距。经过LoRA微调后，马拉雅拉姆语的激活水平提高了87.69%，印地语提高了86.32%，同时英语的性能保持在约91%。微调后的基准测试结果显示出适度但持续的改进。

Conclusion: 通过激活感知微调（LoRA）来解决多语言LLM中低资源语言表现不佳的问题，可以显着提高低资源语言的激活水平，同时保持英语性能，并在基准测试中带来适度但持续的改进，表明激活对齐是提高多语言LLM性能的关键因素。

Abstract: Multilingual large language models (LLMs) exhibit strong cross-linguistic
generalization, yet medium to low resource languages underperform on common
benchmarks such as ARC-Challenge, MMLU, and HellaSwag. We analyze activation
patterns in Gemma-2-2B across all 26 residual layers and 10 languages: Chinese
(zh), Russian (ru), Spanish (es), Italian (it), medium to low resource
languages including Indonesian (id), Catalan (ca), Marathi (mr), Malayalam
(ml), and Hindi (hi), with English (en) as the reference. Using Sparse
Autoencoders (SAEs), we reveal systematic disparities in activation patterns.
Medium to low resource languages receive up to 26.27 percent lower activations
in early layers, with a persistent gap of 19.89 percent in deeper layers. To
address this, we apply activation-aware fine-tuning via Low-Rank Adaptation
(LoRA), leading to substantial activation gains, such as 87.69 percent for
Malayalam and 86.32 percent for Hindi, while maintaining English retention at
approximately 91 percent. After fine-tuning, benchmark results show modest but
consistent improvements, highlighting activation alignment as a key factor in
enhancing multilingual LLM performance.

</details>


### [105] [LLaVA-NeuMT: Selective Layer-Neuron Modulation for Efficient Multilingual Multimodal Translation](https://arxiv.org/abs/2507.18940)
*Jingxuan Wei,Caijun Jia,Qi Chen,Yujun Cai,Linzhuang Sun,Xiangxiang Zhang,Gaowei Wu,Bihui Yu*

Main category: cs.CL

TL;DR: LLaVA-NeuMT是一个创新的多模态多语言翻译框架，通过层选择和神经元自适应策略，有效解决了多语言干扰问题，并在M3-Multi30K和M3-AmbigCaps数据集上取得了SOTA性能，同时实现了参数效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态机器翻译（MMT）方法在双语设置下表现良好，但在多语言翻译中面临跨语言干扰和无效参数共享策略的挑战。

Method: 提出LLaVA-NeuMT框架，采用层选择机制识别不同语言对的信息层，并利用神经元级别自适应策略动态选择语言特定和语言无关的神经元，以减少冗余并提高翻译质量。

Result: LLaVA-NeuMT框架在M3-Multi30K和M3-AmbigCaps数据集上的实验表明，仅微调40%的模型参数即可超越全参数微调方法，并达到SOTA结果。分析结果强调了所选层和神经元在多模态多语言自适应中的重要性。

Conclusion: LLaVA-NeuMT框架在多模态机器翻译领域取得了显著进展，通过显式建模语言特定和语言无关的表示来减轻多语言干扰。该框架通过层选择机制和神经元级别自适应策略，在参数效率和翻译质量上均优于现有方法，并在M3-Multi30K和M3-AmbigCaps数据集上达到了SOTA（State-of-the-Art）水平。

Abstract: Multimodal Machine Translation (MMT) enhances translation quality by
incorporating visual context, helping to resolve textual ambiguities. While
existing MMT methods perform well in bilingual settings, extending them to
multilingual translation remains challenging due to cross-lingual interference
and ineffective parameter-sharing strategies. To address this, we propose
LLaVA-NeuMT, a novel multimodal multilingual translation framework that
explicitly models language-specific and language-agnostic representations to
mitigate multilingual interference. Our approach consists of a layer selection
mechanism that identifies the most informative layers for different language
pairs and a neuron-level adaptation strategy that dynamically selects
language-specific and agnostic neurons to improve translation quality while
reducing redundancy. We conduct extensive experiments on the M3-Multi30K and
M3-AmbigCaps datasets, demonstrating that LLaVA-NeuMT, while fine-tuning only
40\% of the model parameters, surpasses full fine-tuning approaches and
ultimately achieves SOTA results on both datasets. Our analysis further
provides insights into the importance of selected layers and neurons in
multimodal multilingual adaptation, offering an efficient and scalable solution
to cross-lingual adaptation in multimodal translation.

</details>


### [106] [Legal Document Summarization: Enhancing Judicial Efficiency through Automation Detection](https://arxiv.org/abs/2507.18952)
*Yongjie Li,Ruilin Nong,Jianan Liu,Lucas Evans*

Main category: cs.CL

TL;DR: 本研究利用自然语言处理和机器学习技术，对法律文件进行自动摘要，以提高司法效率，减轻律师负担。


<details>
  <summary>Details</summary>
Motivation: 为了通过自动化关键信息检测来提高司法效率，减轻律师处理手动审查的负担。

Method: 利用最先进的自然语言处理技术和先进的机器学习算法来识别和提取法律文本中的关键数据，从而生成精确的摘要。

Result: 实验表明，该方法能够生成高质量的摘要，保持原始内容的完整性，并显著提高处理时间，从而提高运营效率。

Conclusion: 该研究强调了自动化在完善司法过程中的作用，展示了有前景的、由技术驱动的策略，这些策略可以显著改变法律领域的工作流程动态。

Abstract: Legal document summarization represents a significant advancement towards
improving judicial efficiency through the automation of key information
detection. Our approach leverages state-of-the-art natural language processing
techniques to meticulously identify and extract essential data from extensive
legal texts, which facilitates a more efficient review process. By employing
advanced machine learning algorithms, the framework recognizes underlying
patterns within judicial documents to create precise summaries that encapsulate
the crucial elements. This automation alleviates the burden on legal
professionals, concurrently reducing the likelihood of overlooking vital
information that could lead to errors. Through comprehensive experiments
conducted with actual legal datasets, we demonstrate the capability of our
method to generate high-quality summaries while preserving the integrity of the
original content and enhancing processing times considerably. The results
reveal marked improvements in operational efficiency, allowing legal
practitioners to direct their efforts toward critical analytical and
decision-making activities instead of manual reviews. This research highlights
promising technology-driven strategies that can significantly alter workflow
dynamics within the legal sector, emphasizing the role of automation in
refining judicial processes.

</details>


### [107] [A Similarity Measure for Comparing Conversational Dynamics](https://arxiv.org/abs/2507.18956)
*Sang Min Jung,Kaixiang Zhang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 提出了一种新的对话动力学相似性度量方法，用于评估对话的整体交互模式，并在实践中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的对话质量评估方法主要关注单个回复的质量，而忽略了对话整体的交互模式和动力学。缺乏自动化的方法来比较对话的整体交互动力学，这阻碍了对话数据的分析和对话剂的全面评估。

Method: 提出了一种新的相似性度量方法，用于从交互模式的角度比较对话的整体动力学，并设计了一个验证框架来测试该度量的稳健性和对主题的敏感性。

Result: 开发了一种新的对话动力学相似性度量方法，并通过在大型在线社区的实践应用，证明了该度量方法能够捕捉对话的细微差别，并为理解情境权力在对话中的作用提供了新的见解。

Conclusion: 该研究引入了一种用于比较对话动力学的相似性度量，并展示了其在分析在线社区对话动力学中的效用，揭示了情境权力在对话中的作用。

Abstract: The quality of a conversation goes beyond the individual quality of each
reply, and instead emerges from how these combine into interactional patterns
that give the conversation its distinctive overall "shape". However, there is
no robust automated method for comparing conversations in terms of their
overall interactional dynamics. Such methods could enhance the analysis of
conversational data and help evaluate conversational agents more holistically.
  In this work, we introduce a similarity measure for comparing conversations
with respect to their dynamics. We design a validation framework for testing
the robustness of the metric in capturing differences in conversation dynamics
and for assessing its sensitivity to the topic of the conversations. Finally,
to illustrate the measure's utility, we use it to analyze conversational
dynamics in a large online community, bringing new insights into the role of
situational power in conversations.

</details>


### [108] [A Toolbox, Not a Hammer -- Multi-TAG: Scaling Math Reasoning with Multi-Tool Aggregation](https://arxiv.org/abs/2507.18973)
*Bohan Yao,Vikas Yadav*

Main category: cs.CL

TL;DR: Multi-TAG通过同时调用和聚合多个工具来增强LLM的数学推理能力，无需微调即可提高复杂数学问题的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的工具增强型方法通常在每个推理步骤中仅微调LLM来选择和调用单个工具，虽然在简单的数学推理基准上表现良好，但在需要多步精确推理的复杂数学问题上表现不佳。为了解决这个限制，提出Multi-TAG框架。

Method: Multi-TAG框架通过在每个推理步骤中同时调用多个外部工具，并聚合这些工具的多样化输出来验证和优化推理过程，从而提升数学推理能力。

Result: 在MATH500、AIME、AMC和OlympiadBench这四个具有挑战性的基准上进行评估，Multi-TAG在开源和闭源LLM骨干模型上均表现出色，相较于最先进的基线平均提高了6.0%至7.5%。

Conclusion: Multi-TAG是一个无需微调、仅在推理时使用的框架，能够指导LLM在每个推理步骤中同时调用多个工具，并通过聚合它们的输出来验证和优化推理过程，从而提高解决方案的鲁棒性和准确性。该框架适用于任何LLM骨干模型，包括计算成本高昂或无法进行微调的模型。

Abstract: Augmenting large language models (LLMs) with external tools is a promising
avenue for developing high-performance mathematical reasoning systems. Prior
tool-augmented approaches typically finetune an LLM to select and invoke a
single tool at each reasoning step and show promising results on simpler math
reasoning benchmarks such as GSM8K. However, these approaches struggle with
more complex math problems that require precise reasoning over multiple steps.
To address this limitation, in this work, we propose Multi-TAG, a Multi-Tool
AGgregation-based framework. Instead of relying on a single tool, Multi-TAG
guides an LLM to concurrently invoke multiple tools at each reasoning step. It
then aggregates their diverse outputs to verify and refine the reasoning
process, enhancing solution robustness and accuracy. Notably, Multi-TAG is a
finetuning-free, inference-only framework, making it readily applicable to any
LLM backbone, including large open-weight models which are computationally
expensive to finetune and proprietary frontier models which cannot be finetuned
with custom recipes. We evaluate Multi-TAG on four challenging benchmarks:
MATH500, AIME, AMC, and OlympiadBench. Across both open-weight and
closed-source LLM backbones, Multi-TAG consistently and substantially
outperforms state-of-the-art baselines, achieving average improvements of 6.0%
to 7.5% over state-of-the-art baselines.

</details>


### [109] [Arg-LLaDA: Argument Summarization via Large Language Diffusion Models and Sufficiency-Aware Refinement](https://arxiv.org/abs/2507.19081)
*Hao Li,Yizheng Sun,Viktor Schlegel,Kailai Yang,Riza Batista-Navarro,Goran Nenadic*

Main category: cs.CL

TL;DR: Arg-LLaDA是一个新的框架，通过迭代改进和充分性检查来生成更好的论点摘要。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖单次生成，对事实校正或结构精炼的支持有限，而Arg-LLaDA旨在通过迭代改进来解决这一差距。

Method: Arg-LLaDA是一个新颖的大型语言扩散框架，通过充分性引导的重掩码和再生成来迭代地改进摘要。该方法结合了灵活的掩码控制器和充分性检查模块，以识别和修改不支持、冗余或不完整的片段。

Result: Arg-LLaDA产生了更忠实、更简洁、更连贯的输出。

Conclusion: Arg-LLaDA在7个自动评估指标中的7个上超越了最先进的基线，并且在核心维度、覆盖率、忠实度和简洁性方面都有显著提高，验证了其迭代、充分性感知生成策略的有效性。

Abstract: Argument summarization aims to generate concise, structured representations
of complex, multi-perspective debates. While recent work has advanced the
identification and clustering of argumentative components, the generation stage
remains underexplored. Existing approaches typically rely on single-pass
generation, offering limited support for factual correction or structural
refinement. To address this gap, we introduce Arg-LLaDA, a novel large language
diffusion framework that iteratively improves summaries via sufficiency-guided
remasking and regeneration. Our method combines a flexible masking controller
with a sufficiency-checking module to identify and revise unsupported,
redundant, or incomplete spans, yielding more faithful, concise, and coherent
outputs. Empirical results on two benchmark datasets demonstrate that Arg-LLaDA
surpasses state-of-the-art baselines in 7 out of 10 automatic evaluation
metrics. In addition, human evaluations reveal substantial improvements across
core dimensions, coverage, faithfulness, and conciseness, validating the
effectiveness of our iterative, sufficiency-aware generation strategy.

</details>


### [110] [Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents](https://arxiv.org/abs/2507.19090)
*Haorui He,Yupeng Li,Dacheng Wen,Reynold Cheng,Francis C. M. Lau*

Main category: cs.CL

TL;DR: DebateCV is a novel framework using debating LLM agents to improve claim verification, especially for complex claims with multiple evidences. It also uses synthetic data to train moderators, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art single-LLM methods struggle with complex claim verification involving multi-faceted evidences. Inspired by real-world fact-checking practices.

Method: A debate-driven methodology using multiple LLM agents, including two Debaters taking opposing stances and engaging in multi-round argumentation, and a Moderator evaluating arguments. Includes a post-training strategy leveraging synthetic debate data generated by zero-shot DebateCV.

Result: Experimental results show that DebateCV outperforms existing claim verification methods under varying levels of evidence quality.

Conclusion: DebateCV outperforms existing claim verification methods under varying levels of evidence quality.

Abstract: Claim verification is critical for enhancing digital literacy. However, the
state-of-the-art single-LLM methods struggle with complex claim verification
that involves multi-faceted evidences. Inspired by real-world fact-checking
practices, we propose DebateCV, the first claim verification framework that
adopts a debate-driven methodology using multiple LLM agents. In our framework,
two Debaters take opposing stances on a claim and engage in multi-round
argumentation, while a Moderator evaluates the arguments and renders a verdict
with justifications. To further improve the performance of the Moderator, we
introduce a novel post-training strategy that leverages synthetic debate data
generated by the zero-shot DebateCV, effectively addressing the scarcity of
real-world debate-driven claim verification data. Experimental results show
that our method outperforms existing claim verification methods under varying
levels of evidence quality. Our code and dataset are publicly available at
https://anonymous.4open.science/r/DebateCV-6781.

</details>


### [111] [Objectifying the Subjective: Cognitive Biases in Topic Interpretations](https://arxiv.org/abs/2507.19117)
*Swapnil Hingmire,Ze Shi Li,Shiyu,Zeng,Ahmed Musa Awon,Luiz Franciscatto Guerra,Neil Ernst*

Main category: cs.CL

TL;DR: 评估主题质量的传统方法（如coherence）未能衡量主题如何帮助用户探索语料库。通过用户研究，我们发现用户依赖于可用性和代表性启发式方法，而不是概率。我们提出了一个主题解释模型，并强调了在评估和建模中考虑认知偏差的必要性。


<details>
  <summary>Details</summary>
Motivation: 为了设计基于任务和用户群体的评估指标，而不是依赖于像“coherence”和“word intrusion”这样的传统指标，即使它们在主题质量评估中很重要。

Method: 通过用户研究理解用户如何解释主题，并提出主题质量的构建，要求用户在主题的背景下评估它们并提供评估背后的理由。使用反思性主题分析来识别来自理由的主题解释的主题。

Result: 用户将主题解释为基于可用性和代表性启发式方法，而不是概率。提出了基于锚定和调整启发式的主题解释理论：用户基于显著词进行锚定，并进行语义调整以得出解释。

Conclusion: 用户根据可用性和代表性启发式方法来解释主题，而不是基于概率。主题的解释可以被看作是生态理性用户在不确定性下的判断，因此需要认知偏差感知用户模型和评估框架。

Abstract: Interpretation of topics is crucial for their downstream applications.
State-of-the-art evaluation measures of topic quality such as coherence and
word intrusion do not measure how much a topic facilitates the exploration of a
corpus. To design evaluation measures grounded on a task, and a population of
users, we do user studies to understand how users interpret topics. We propose
constructs of topic quality and ask users to assess them in the context of a
topic and provide rationale behind evaluations. We use reflexive thematic
analysis to identify themes of topic interpretations from rationales. Users
interpret topics based on availability and representativeness heuristics rather
than probability. We propose a theory of topic interpretation based on the
anchoring-and-adjustment heuristic: users anchor on salient words and make
semantic adjustments to arrive at an interpretation. Topic interpretation can
be viewed as making a judgment under uncertainty by an ecologically rational
user, and hence cognitive biases aware user models and evaluation frameworks
are needed.

</details>


### [112] [An Empirical Investigation of Gender Stereotype Representation in Large Language Models: The Italian Case](https://arxiv.org/abs/2507.19156)
*Gioele Giachino,Marco Rondina,Antonio Vetrò,Riccardo Coppola,Juan Carlos De Martin*

Main category: cs.CL

TL;DR: 这项研究分析了LLM（ChatGPT和Gemini）如何通过非性别化提示产生性别和职业偏见，尤其是在意大利语中，并发现它们会固化刻板印象，例如将“她”与“助理”相关联，这对工作场所和社会公平可能产生负面影响。


<details>
  <summary>Details</summary>
Motivation: LLM在各种领域中的使用日益广泛，引发了关于它们如何轻易地固化刻板印象和产生偏见内容的担忧。本研究着重于性别和职业偏见，探讨了LLM在塑造对非性别化提示的响应以及产生有偏见输出方面的方式。

Method: 本分析采用结构化的实验方法，给出涉及三种不同职业组合（具有层级关系）的不同提示。我们检查了OpenAI ChatGPT（gpt-4o-mini）和Google Gemini（gemini-1.5-flash）两个基于LLM的聊天机器人，并通过API收集了3600个响应。

Result: 结果表明，LLM生成的内容会固化刻板印象。例如，Gemini将100%的“她”代词与“助理”而非“经理”相关联（ChatGPT为97%）。

Conclusion: LLM生成的内容会固化刻板印象，例如，Gemini将100%的“她”代词与“助理”而非“经理”相关联（ChatGPT为97%），这可能在工作场所或工作选择等领域产生重大影响，并引发有关其使用的道德担忧。

Abstract: The increasing use of Large Language Models (LLMs) in a large variety of
domains has sparked worries about how easily they can perpetuate stereotypes
and contribute to the generation of biased content. With a focus on gender and
professional bias, this work examines in which manner LLMs shape responses to
ungendered prompts, contributing to biased outputs. This analysis uses a
structured experimental method, giving different prompts involving three
different professional job combinations, which are also characterized by a
hierarchical relationship. This study uses Italian, a language with extensive
grammatical gender differences, to highlight potential limitations in current
LLMs' ability to generate objective text in non-English languages. Two popular
LLM-based chatbots are examined, namely OpenAI ChatGPT (gpt-4o-mini) and Google
Gemini (gemini-1.5-flash). Through APIs, we collected a range of 3600
responses. The results highlight how content generated by LLMs can perpetuate
stereotypes. For example, Gemini associated 100% (ChatGPT 97%) of 'she'
pronouns to the 'assistant' rather than the 'manager'. The presence of bias in
AI-generated text can have significant implications in many fields, such as in
the workplaces or in job selections, raising ethical concerns about its use.
Understanding these risks is pivotal to developing mitigation strategies and
assuring that AI-based systems do not increase social inequalities, but rather
contribute to more equitable outcomes. Future research directions include
expanding the study to additional chatbots or languages, refining prompt
engineering methods or further exploiting a larger experimental base.

</details>


### [113] [Can Small-Scale Data Poisoning Exacerbate Dialect-Linked Biases in Large Language Models?](https://arxiv.org/abs/2507.19195)
*Chaymaa Abbas,Mariette Awad,Razane Tajeddine*

Main category: cs.CL

TL;DR: 研究发现，数据中毒对使用美式非洲英语（AAVE）的大型语言模型（LLMs）的毒性影响比使用标准美式英语（SAE）的模型更大，且模型越大，影响越显著，这表明需要针对性的去偏策略。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨方言变异（AAVE vs SAE）如何与数据中毒相互作用，从而影响大型语言模型（LLMs）输出中的毒性，并揭示了现有 LLMs 在包容性和平衡响应方面仍易受到社会偏见影响的问题。

Method: 本研究使用小型和中型 LLaMA 模型，并通过 GPT-4o 作为公平性审计员，研究了 AAVE 和 SAE 在数据中毒影响下的毒性差异。

Result: 研究结果表明，即使是少量的数据中毒也会显著增加 AAVE 输入的毒性，而 SAE 输入则相对不受影响。模型规模越大，毒性放大的效应越明显。GPT-4o 审计发现了与 AAVE 输入不成比例相关联的有害刻板印象模式，例如攻击性、犯罪性和智力低下。

Conclusion: 数据中毒和方言偏见（特别是美式非洲英语 AAVE 与标准美式英语 SAE 相比）的复合影响不容忽视，并且在模型规模扩大时会加剧，凸显了在模型开发过程中进行方言感知评估、有针对性的去偏干预和社会责任训练协议的必要性。

Abstract: Despite the ongoing improvements in the design of large language models
(LLMs) to foster inclusion and balanced responses, these systems remain
susceptible to encoding and amplifying social biases. This study examines how
dialectal variation, specifically African American Vernacular English (AAVE)
versus Standard American English (SAE), interacts with data poisoning to
influence toxicity in outputs. Using both small- and medium-scale LLaMA models,
we show that even minimal exposure to poisoned data significantly increases
toxicity for AAVE inputs, while it remains comparatively unaffected for SAE.
Larger models exhibit a more significant amplification effect which suggests
heightened susceptibility with scale. To further assess these disparities, we
employed GPT-4o as a fairness auditor, which identified harmful stereotypical
patterns disproportionately tied to AAVE inputs, including portrayals of
aggression, criminality, and intellectual inferiority. These findings
underscore the compounding impact of data poisoning and dialectal bias and
emphasize the need for dialect-aware evaluation, targeted debiasing
interventions, and socially responsible training protocols during development.

</details>


### [114] [How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)
*Zi Liang,Liantong Yu,Shiyu Zhang,Qingqing Ye,Haibo Hu*

Main category: cs.CL

TL;DR: ArxivRoll是一个新的LLM评估框架，通过定期生成私有测试数据来解决现有基准的污染和可复现性问题，并引入Rugged Scores来衡量偏差。


<details>
  <summary>Details</summary>
Motivation: 评估LLM时存在过高估计的问题，这可能是由于公共基准的污染或不平衡的模型训练，导致LLM在公共基准上获得不切实际的评估结果。现有基准的解决方案（如保密测试用例、人工评估或不断收集新样本）未能同时保证可复现性、透明度和高效率，且未能量化LLM的过高估计程度。

Method: 提出了一种名为ArxivRoll的动态评估框架，其灵感来源于密码学中的一次性密码本加密。该框架包含两个核心组件：1. SCP（Sequencing, Cloze, and Prediction），一个用于生成私有测试用例的自动化生成器；2. Rugged Scores（RS），用于衡量公共基准污染和训练偏差的指标。SCP每六个月使用ArXiv上的新文章构建一个新基准，并用于LLM性能的一次性评估。

Result: 通过SCP，ArxivRoll成功构建了一个新的、高质量的基准，并用于对现有LLM进行系统评估，证明了其有效性。

Conclusion: ArxivRoll框架通过动态生成私有测试用例和Rugged Scores指标，解决了现有LLM评估基准在可复现性、透明度和效率方面存在的不足，并量化了当前LLM的过高估计程度。实验证明了该基准的质量，并对现有LLM进行了系统评估。

Abstract: Overestimation in evaluating large language models (LLMs) has become an
increasing concern. Due to the contamination of public benchmarks or imbalanced
model training, LLMs may achieve unreal evaluation results on public
benchmarks, either intentionally or unintentionally, which leads to unfair
comparisons among LLMs and undermines their realistic capability assessments.
Existing benchmarks attempt to address these issues by keeping test cases
permanently secret, mitigating contamination through human evaluation, or
repeatedly collecting and constructing new samples. However, these approaches
fail to ensure reproducibility, transparency, and high efficiency
simultaneously. Moreover, the extent of overestimation in current LLMs remains
unquantified. To address these issues, we propose ArxivRoll, a dynamic
evaluation framework inspired by one-time pad encryption in cryptography.
ArxivRoll comprises two key components: \emph{i) SCP (Sequencing, Cloze, and
Prediction)}, an automated generator for private test cases, and \emph{ii)
Rugged Scores (RS)}, metrics that measure the proportion of public benchmark
contamination and training bias. Leveraging SCP, ArxivRoll constructs a new
benchmark every six months using recent articles from ArXiv and employs them
for one-time evaluations of LLM performance. Extensive experiments demonstrate
the high quality of our benchmark, and we provide a systematic evaluation of
current LLMs. The source code is available at
https://github.com/liangzid/ArxivRoll/.

</details>


### [115] [Jailbreaking Large Language Diffusion Models: Revealing Hidden Safety Flaws in Diffusion-Based Text Generation](https://arxiv.org/abs/2507.19227)
*Yuanhe Zhang,Fangzhou Xie,Zhenhong Zhou,Zherui Li,Hao Chen,Kun Wang,Yufei Guo*

Main category: cs.CL

TL;DR: LLDMs are vulnerable to a new jailbreak method (PAD) achieving 97% success, exposing significant safety risks and faster harmful generation compared to traditional LLMs. Further research is needed for secure deployment.


<details>
  <summary>Details</summary>
Motivation: Existing jailbreak methods for LLMs are ineffective against LLDMs, and it's unclear if LLDMs have safety vulnerabilities or if the attacks are simply incompatible with their architecture. The research aims to reveal LLDM vulnerabilities and understand the reasons behind attack failures.

Method: The paper introduces a PArallel Decoding (PAD) jailbreak method, which includes a Multi-Point Attention Attack inspired by affirmative response patterns, to exploit architectural differences in LLDMs and guide their parallel generation processes toward harmful outputs.

Result: The PAD jailbreak achieved a 97% success rate across four LLDMs, revealing significant safety vulnerabilities. LLDMs were found to increase harmful generation speed by 2x compared to autoregressive LLMs of the same size.

Conclusion: LLDMs, despite their advantages, possess significant safety vulnerabilities that require further investigation and secure deployment strategies for diffusion-based language models.

Abstract: Large Language Diffusion Models (LLDMs) exhibit comparable performance to
LLMs while offering distinct advantages in inference speed and mathematical
reasoning tasks.The precise and rapid generation capabilities of LLDMs amplify
concerns of harmful generations, while existing jailbreak methodologies
designed for Large Language Models (LLMs) prove limited effectiveness against
LLDMs and fail to expose safety vulnerabilities.Successful defense cannot
definitively resolve harmful generation concerns, as it remains unclear whether
LLDMs possess safety robustness or existing attacks are incompatible with
diffusion-based architectures.To address this, we first reveal the
vulnerability of LLDMs to jailbreak and demonstrate that attack failure in
LLDMs stems from fundamental architectural differences.We present a PArallel
Decoding jailbreak (PAD) for diffusion-based language models. PAD introduces
Multi-Point Attention Attack, which guides parallel generative processes toward
harmful outputs that inspired by affirmative response patterns in LLMs.
Experimental evaluations across four LLDMs demonstrate that PAD achieves
jailbreak attack success rates by 97%, revealing significant safety
vulnerabilities. Furthermore, compared to autoregressive LLMs of the same size,
LLDMs increase the harmful generation speed by 2x, significantly highlighting
risks of uncontrolled misuse.Through comprehensive analysis, we provide an
investigation into LLDM architecture, offering critical insights for the secure
deployment of diffusion-based language models.

</details>


### [116] [Identifying Fine-grained Forms of Populism in Political Discourse: A Case Study on Donald Trump's Presidential Campaigns](https://arxiv.org/abs/2507.19303)
*Ilias Chalkidis,Stephanie Brandl,Paris Aslanidis*

Main category: cs.CL

TL;DR: LLMs在识别民粹主义方面能力有限，但微调和特定类型的模型（如RoBERTa）表现更好。LLMs在处理政治话语方面具有潜力，但在跨文化应用中仍需改进。


<details>
  <summary>Details</summary>
Motivation: 填补LLMs在理解细微的社会科学概念（特别是民粹主义）方面的空白，并探索其在政治话语分析中的应用。

Method: 本研究构建了专门用于捕获民粹主义话语的新数据集，并评估了包括开放权重和专有模型在内的一系列预训练语言模型。研究采用了多种提示范式，并对模型进行了微调。

Result: 在识别民粹主义方面，微调的RoBERTa分类器表现优于所有新时代指令微调LLMs（除非后者也经过微调）。当应用于特朗普的竞选演讲时，研究发现了其民粹主义言论的战略运用。在跨语境迁移能力方面，指令微调LLMs在处理域外数据时表现出更强的鲁棒性。

Conclusion: LLMs在识别和分类民粹主义方面存在局限性，微调的RoBERTa分类器表现优于未微调的新时代指令微调LLMs。在特定场景下，指令微调LLMs在处理域外数据时表现出更强的鲁棒性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
a wide range of instruction-following tasks, yet their grasp of nuanced social
science concepts remains underexplored. This paper examines whether LLMs can
identify and classify fine-grained forms of populism, a complex and contested
concept in both academic and media debates. To this end, we curate and release
novel datasets specifically designed to capture populist discourse. We evaluate
a range of pre-trained (large) language models, both open-weight and
proprietary, across multiple prompting paradigms. Our analysis reveals notable
variation in performance, highlighting the limitations of LLMs in detecting
populist discourse. We find that a fine-tuned RoBERTa classifier vastly
outperforms all new-era instruction-tuned LLMs, unless fine-tuned.
Additionally, we apply our best-performing model to analyze campaign speeches
by Donald Trump, extracting valuable insights into his strategic use of
populist rhetoric. Finally, we assess the generalizability of these models by
benchmarking them on campaign speeches by European politicians, offering a lens
into cross-context transferability in political discourse analysis. In this
setting, we find that instruction-tuned LLMs exhibit greater robustness on
out-of-domain data.

</details>


### [117] [AutoPCR: Automated Phenotype Concept Recognition by Prompting](https://arxiv.org/abs/2507.19315)
*Yicheng Tao,Yuanhao Huang,Jie Liu*

Main category: cs.CL

TL;DR: AutoPCR是一种新的、无需训练的表型概念识别方法，通过实体提取、候选检索和大型语言模型链接，在生物医学文本中实现了最先进的性能和良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的表型概念识别（CR）方法通常需要特定本体的训练，并且难以在不同类型的文本和不断发展的生物医学术语中实现泛化。因此，需要一种不需要特定本体训练且具有良好泛化能力的方法。

Method: AutoPCR是一个基于提示的表型概念识别（CR）方法，包含三个阶段：1. 使用基于规则和神经标签策略的混合方法进行实体提取；2. 通过SapBERT检索候选实体；3. 通过提示大型语言模型进行实体链接。该方法不需要特定本体的训练。

Result: 实验结果表明，AutoPCR在四个基准数据集上取得了最优的平均性能和最强的鲁棒性，超越了现有的最先进方法，并证明了其在归纳能力和对新本体的泛化方面的优势。

Conclusion: AutoPCR在四个基准数据集上实现了最佳的平均和最稳健的性能，在提及级别和文档级别的评估中均超越了先前最先进的方法。消融研究和迁移研究进一步证明了其归纳能力和对新本体的可推广性。

Abstract: Phenotype concept recognition (CR) is a fundamental task in biomedical text
mining, enabling applications such as clinical diagnostics and knowledge graph
construction. However, existing methods often require ontology-specific
training and struggle to generalize across diverse text types and evolving
biomedical terminology. We present AutoPCR, a prompt-based phenotype CR method
that does not require ontology-specific training. AutoPCR performs CR in three
stages: entity extraction using a hybrid of rule-based and neural tagging
strategies, candidate retrieval via SapBERT, and entity linking through
prompting a large language model. Experiments on four benchmark datasets show
that AutoPCR achieves the best average and most robust performance across both
mention-level and document-level evaluations, surpassing prior state-of-the-art
methods. Further ablation and transfer studies demonstrate its inductive
capability and generalizability to new ontologies.

</details>


### [118] [Smooth Reading: Bridging the Gap of Recurrent LLM to Self-Attention LLM on Long-Context Tasks](https://arxiv.org/abs/2507.19353)
*Kai Liu,Zhan Su,Peijie Dong,Fengran Mo,Jianfei Gao,ShaoTing Zhang,Kai Chen*

Main category: cs.CL

TL;DR: 循环LLM在长上下文任务上通常表现不如自注意力LLM。本文提出了一种名为Smooth Reading的分块推理方法，通过模仿人类阅读习惯，将长上下文分块处理并迭代总结，有效提升了循环LLM的性能，使其在长上下文任务上表现与自注意力LLM相当，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: 当前的循环LLM在长上下文任务上表现不佳，主要是因为它们固定的有限内存限制了处理整个上下文的能力。虽然以往的研究集中于增强循环LLM的内存容量，但仍未能使其在长上下文任务上达到与自注意力LLM相当的性能。作者认为，一次性处理整个上下文并不适合循环LLM。

Method: 提出了一种名为Smooth Reading的分块推理方法，该方法借鉴了人类阅读策略，通过将长上下文分块处理并迭代地对上下文信息进行总结，从而降低内存需求，使其更适用于循环LLM。

Result: Smooth Reading方法显著缩小了循环LLM与自注意力LLM在长上下文任务上的性能差距，同时保留了循环LLM的效率优势。具体来说，该方法将SWA-3B-4k在LongBench上的性能从落后自注意力LLM的5.68%提升至高出3.61%。此外，在64k上下文长度下，该方法训练速度提升了3倍，推理速度提升了2倍。

Conclusion: 本文提出的Smooth Reading方法通过分块处理和迭代总结上下文信息，有效缩小了循环LLM与自注意力LLM在长上下文任务上的性能差距，同时保持了循环LLM的高效性。实验结果表明，该方法显著提升了SWA-3B-4k在LongBench上的表现，使其超越了自注意力LLM。研究首次实现了循环LLM在长上下文任务上与自注意力LLM相当的性能，并计划开源代码和数据集以促进未来研究。

Abstract: Recently, recurrent large language models (Recurrent LLMs) with linear
computational complexity have re-emerged as efficient alternatives to
self-attention-based LLMs (Self-Attention LLMs), which have quadratic
complexity. However, Recurrent LLMs often underperform on long-context tasks
due to their limited fixed-size memory. Previous research has primarily focused
on enhancing the memory capacity of Recurrent LLMs through architectural
innovations, but these approaches have not yet enabled Recurrent LLMs to match
the performance of Self-Attention LLMs on long-context tasks. We argue that
this limitation arises because processing the entire context at once is not
well-suited for Recurrent LLMs. In this paper, we propose Smooth Reading, a
chunk-wise inference method inspired by human reading strategies. Smooth
Reading processes context in chunks and iteratively summarizes the contextual
information, thereby reducing memory demands and making the approach more
compatible with Recurrent LLMs. Our experimental results show that this method
substantially narrows the performance gap between Recurrent and Self-Attention
LLMs on long-context tasks, while preserving the efficiency advantages of
Recurrent LLMs. Our Smooth Reading boosts SWA-3B-4k (a Recurrent LLM) from
5.68% lower to 3.61% higher performance than Self-Attention LLMs on LongBench.
Besides, our method maintains the high efficiency, training 3x faster and
inferring 2x faster at 64k context compared to Self-Attention LLMs. To our
knowledge, this is the first work to achieve comparable performance using
Recurrent LLMs compared with Self-Attention LLMs on long-context tasks. We hope
our method will inspire future research in this area. To facilitate further
progress, we will release code and dataset.

</details>


### [119] [Enhancing Speech Emotion Recognition Leveraging Aligning Timestamps of ASR Transcripts and Speaker Diarization](https://arxiv.org/abs/2507.19356)
*Hsuan-Yu Wang,Pei-Ying Lee,Berlin Chen*

Main category: cs.CL

TL;DR: 本研究通过对ASR和SD输出进行时间戳对齐，并结合文本和音频嵌入，成功提高了语音情感识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决自动语音识别（ASR）和说话人日志（SD）输出之间时间戳错位的问题，这种错位会降低多模态情感识别系统的可靠性，尤其是在对话场景中。

Method: 本研究提出了一种利用预训练的ASR和说话人日志模型的时间戳对齐流程，通过结合RoBERTa的文本嵌入和Wav2Vec的音频嵌入，并利用门控机制增强的交叉注意力融合来改进语音情感识别。

Result: 实验结果表明，精确的时间戳对齐能够提高语音情感识别的准确性，优于未进行同步的基线方法。

Conclusion: 精确的时间戳对齐可提高语音情感识别的准确性，该方法为鲁棒的多模态情感分析奠定了基础。

Abstract: In this paper, we investigate the impact of incorporating timestamp-based
alignment between Automatic Speech Recognition (ASR) transcripts and Speaker
Diarization (SD) outputs on Speech Emotion Recognition (SER) accuracy.
Misalignment between these two modalities often reduces the reliability of
multimodal emotion recognition systems, particularly in conversational
contexts. To address this issue, we introduce an alignment pipeline utilizing
pre-trained ASR and speaker diarization models, systematically synchronizing
timestamps to generate accurately labeled speaker segments. Our multimodal
approach combines textual embeddings extracted via RoBERTa with audio
embeddings from Wav2Vec, leveraging cross-attention fusion enhanced by a gating
mechanism. Experimental evaluations on the IEMOCAP benchmark dataset
demonstrate that precise timestamp alignment improves SER accuracy,
outperforming baseline methods that lack synchronization. The results highlight
the critical importance of temporal alignment, demonstrating its effectiveness
in enhancing overall emotion recognition accuracy and providing a foundation
for robust multimodal emotion analysis.

</details>


### [120] [SpeechIQ: Speech Intelligence Quotient Across Cognitive Levels in Voice Understanding Large Language Models](https://arxiv.org/abs/2507.19361)
*Zhen Wan,Chao-Han Huck Yang,Yahan Yu,Jinchuan Tian,Sheng Li,Ke Hu,Zhehuai Chen,Shinji Watanabe,Fei Cheng,Chenhui Chu,Sadao Kurohashi*

Main category: cs.CL

TL;DR: 提出了一种名为SIQ的新型语音评估方法，它基于认知科学，能够更全面地评估大型语言模型（LLM）的语音理解能力，并发现现有模型和基准中的问题。


<details>
  <summary>Details</summary>
Motivation: 为了超越传统的语音理解指标（如词错误率WER），并从认知层面更全面地评估LLM的语音理解能力，同时为不同类型的模型（级联模型和端到端模型）提供统一的比较，识别现有基准中的标注错误，并检测LLM中的幻觉。

Method: 提出了一种名为SIQ（Speech-based Intelligence Quotient）的评估框架，该框架借鉴了布鲁姆分类学（Bloom's Taxonomy）的三个认知层级：记忆（Verbatim accuracy, WER）、理解（Interpretation similarity）和应用（QA accuracy），以评估大型语言模型（LLM）的语音理解能力。

Result: SIQ不仅能够量化语音理解能力，还能统一比较级联方法和端到端模型，识别现有基准中的标注错误，并检测LLM Voice中的幻觉。该研究首次将认知原则与语音导向的基准相结合，揭示了多模态训练中被忽视的挑战。

Conclusion: SIQ是一个新颖的人类认知启发式评估流程，用于评估LLM Voice的语音理解能力。它超越了传统的WER指标，涵盖了记忆、理解和应用三个认知层面，能够量化语音理解能力，统一比较不同模型，识别基准中的标注错误，并检测LLM Voice中的幻觉。该框架将认知原则与语音基准相结合，为多模态训练中的挑战提供了新的视角。

Abstract: We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human
cognition-inspired evaluation pipeline for voice understanding large language
models, LLM Voice, designed to assess their voice understanding ability. Moving
beyond popular voice understanding metrics such as word error rate (WER), SIQ
examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy:
(1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e.,
similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy
for simulating downstream tasks). We demonstrate that SIQ not only quantifies
voice understanding abilities but also provides unified comparisons between
cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation
errors in existing benchmarks, and detects hallucinations in LLM Voice. Our
framework represents a first-of-its-kind intelligence examination that bridges
cognitive principles with voice-oriented benchmarks, while exposing overlooked
challenges in multi-modal training.

</details>


### [121] [Data Augmentation for Spoken Grammatical Error Correction](https://arxiv.org/abs/2507.19374)
*Penny Karanasou,Mengjie Qian,Stefano Bannò,Mark J. F. Gales,Kate M. Knill*

Main category: cs.CL

TL;DR: 该研究通过全自动方法生成带语法错误的口语数据集，并提出评估指标，以解决口语语法纠错（SGEC）数据集不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的语法错误纠正（GEC）基准数据集虽然强大，但用于口语语法纠错（SGEC）的高质量标注口语数据集仍然稀缺。

Method: 提出了一种全自动化的方法来生成包含语法错误和口语犹豫（disfluencies）的音频-文本对。同时，提出了一系列客观指标用于评估生成的数据，并选择更适合SGEC的数据集。

Result: 通过实验证明，所提出的增强数据集可用于书面GEC和SGEC，并在S&I语料库上进行了评估，该语料库是首个公开的带语法错误标注的语音数据集。

Conclusion: 该研究提出了一个全自动化的方法来生成包含语法错误和口语犹豫的音频-文本对，旨在丰富和增强口语语法纠错（SGEC）的训练语料库。通过引入客观评估指标来筛选生成的数据集，并确保增强后的数据集在保持原有文本和声学特性的同时，不会影响第二语言学习者的语言评估分数。

Abstract: While there exist strong benchmark datasets for grammatical error correction
(GEC), high-quality annotated spoken datasets for Spoken GEC (SGEC) are still
under-resourced. In this paper, we propose a fully automated method to generate
audio-text pairs with grammatical errors and disfluencies. Moreover, we propose
a series of objective metrics that can be used to evaluate the generated data
and choose the more suitable dataset for SGEC. The goal is to generate an
augmented dataset that maintains the textual and acoustic characteristics of
the original data while providing new types of errors. This augmented dataset
should augment and enrich the original corpus without altering the language
assessment scores of the second language (L2) learners. We evaluate the use of
the augmented corpus both for written GEC (the text part) and for SGEC (the
audio-text pairs). Our experiments are conducted on the S\&I Corpus, the first
publicly available speech dataset with grammar error annotations.

</details>


### [122] [Detection of Adverse Drug Events in Dutch clinical free text documents using Transformer Models: benchmark study](https://arxiv.org/abs/2507.19396)
*Rachel M. Murphy,Nishant Mishra,Nicolette F. de Keizer,Dave A. Dongelmans,Kitty J. Jager,Ameen Abu-Hanna,Joanna E. Klopotowska,Iacer Calixto*

Main category: cs.CL

TL;DR: 本研究为荷兰语临床文本中的不良药物事件（ADE）检测设定了基准，评估了多种 Transformer 模型。MedRoBERTa.nl 在关系分类和外部验证中表现最佳，召回率高达 74%。研究强调了使用合适的性能度量对于临床应用的重要性。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在为荷兰临床自由文本中的不良药物事件（ADE）检测设定一个基准，并评估不同的 Transformer 模型在该任务上的表现。研究强调了使用适合 ADE 检测任务的性能度量的重要性，并为未来的临床应用提供了依据。

Method: 本研究使用 Bidirectional Long Short-Term Memory (Bi-LSTM) 模型和四种基于 Transformer 的荷兰语/多语言编码器模型（BERTje、RobBERT、MedRoBERTa.nl 和 NuNER）来执行命名实体识别（NER）和关系分类（RC）任务。研究使用了 102 份经过丰富注释的荷兰 ICU 临床进展记录进行训练，并使用了来自一个学术医院的 ICU 患者匿名自由文本进展记录以及来自两个非学术医院内科病房的患者出院信进行外部验证。模型性能通过金标准（两步任务）和预测实体（端到端任务）进行内部评估，并通过检测文档级别的 ADE 进行外部验证。报告了微平均和宏平均 F1 分数。

Result: MedRoBERTa.nl 在 ADE 关系分类任务上表现最佳，使用金标准和预测实体的宏平均 F1 分数分别为 0.63 和 0.62。在外部验证中，MedRoBERTa.nl 模型在检测包含 ADE 的出院信方面也表现最佳，召回率在 0.67 到 0.74 之间。研究表明，所提出的基准研究为评估临床自由文本中 ADE 检测的语言模型提供了一种稳健且临床相关的方法。

Conclusion: 本研究提出了一个使用多种 Transformer 模型、临床场景和适用性能度量来检测荷兰临床自由文本中不良药物事件（ADE）的基准。MedRoBERTa.nl 在 ADE 关系分类任务上表现最佳，使用金标准和预测实体的宏平均 F1 分数分别为 0.63 和 0.62。在外部验证中，MedRoBERTa.nl 模型在检测包含 ADE 的出院信方面也表现最佳，召回率在 0.67 到 0.74 之间。

Abstract: In this study, we set a benchmark for adverse drug event (ADE) detection in
Dutch clinical free text documents using several transformer models, clinical
scenarios and fit-for-purpose performance measures. We trained a Bidirectional
Long Short-Term Memory (Bi-LSTM) model and four transformer-based Dutch and/or
multilingual encoder models (BERTje, RobBERT, MedRoBERTa.nl, and NuNER) for the
tasks of named entity recognition (NER) and relation classification (RC) using
102 richly annotated Dutch ICU clinical progress notes. Anonymized free text
clinical progress notes of patients admitted to intensive care unit (ICU) of
one academic hospital and discharge letters of patients admitted to Internal
Medicine wards of two non-academic hospitals were reused. We evaluated our ADE
RC models internally using gold standard (two-step task) and predicted entities
(end-to-end task). In addition, all models were externally validated on
detecting ADEs at the document level. We report both micro- and macro-averaged
F1 scores, given the imbalance of ADEs in the datasets. Although differences
for the ADE RC task between the models were small, MedRoBERTa.nl was the best
performing model with macro-averaged F1 score of 0.63 using gold standard and
0.62 using predicted entities. The MedRoBERTa.nl models also performed the best
in our external validation and achieved recall of between 0.67 to 0.74 using
predicted entities, meaning between 67 to 74% of discharge letters with ADEs
were detected. Our benchmark study presents a robust and clinically meaningful
approach for evaluating language models for ADE detection in clinical free text
documents. Our study highlights the need to use appropriate performance
measures fit for the task of ADE detection in clinical free-text documents and
envisioned future clinical use.

</details>


### [123] [Towards Domain Specification of Embedding Models in Medicine](https://arxiv.org/abs/2507.19407)
*Mohammad Khodadad,Ali Shiraee,Mahdi Astaraki,Hamidreza Mahyar*

Main category: cs.CL

TL;DR: 文章提出了一种改进医疗文本嵌入模型的方法，通过使用经过优化的MEDTE模型和一套新的基准测试任务，提高了模型的性能和通用性。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗文本嵌入模型在捕捉术语和语义的多样性方面存在不足，并且评估不足，无法泛化到真实世界的医疗任务。文章旨在解决这些差距，提供更有效、更通用的医疗文本嵌入。

Method: 利用经过大量医疗语料库通过跨多种数据源的自我监督对比学习进行广泛微调的GTE模型MEDTE，并提出一个包含51个任务的全面基准测试套件，涵盖分类、聚类、对分类和检索，旨在应对现有医疗文本嵌入模型的局限性。

Result: 该方法在生成的嵌入方面表现优于现有的最先进方法，并在各种任务中展现出稳健的评估能力。

Conclusion: 提出的结合了经过广泛优化的MEDTE模型和全面的基准测试套件的方法，在各种任务中都优于现有的最先进方法，展示了其在生成稳健的医疗文本嵌入方面的有效性。

Abstract: Medical text embedding models are foundational to a wide array of healthcare
applications, ranging from clinical decision support and biomedical information
retrieval to medical question answering, yet they remain hampered by two
critical shortcomings. First, most models are trained on a narrow slice of
medical and biological data, beside not being up to date in terms of
methodology, making them ill suited to capture the diversity of terminology and
semantics encountered in practice. Second, existing evaluations are often
inadequate: even widely used benchmarks fail to generalize across the full
spectrum of real world medical tasks.
  To address these gaps, we leverage MEDTE, a GTE model extensively fine-tuned
on diverse medical corpora through self-supervised contrastive learning across
multiple data sources, to deliver robust medical text embeddings.
  Alongside this model, we propose a comprehensive benchmark suite of 51 tasks
spanning classification, clustering, pair classification, and retrieval modeled
on the Massive Text Embedding Benchmark (MTEB) but tailored to the nuances of
medical text. Our results demonstrate that this combined approach not only
establishes a robust evaluation framework but also yields embeddings that
consistently outperform state of the art alternatives in different tasks.

</details>


### [124] [TokenSmith: Streamlining Data Editing, Search, and Inspection for Large-Scale Language Model Training and Interpretability](https://arxiv.org/abs/2507.19419)
*Mohammad Aflah Khan,Ameya Godbole,Johnny Tian-Zheng Wei,Ryan Wang,James Flemings,Krishna Gummadi,Willie Neiswanger,Robin Jia*

Main category: cs.CL

TL;DR: TokenSmith is an open-source library that simplifies dataset analysis and editing for LLM pretraining, making it more accessible to researchers.


<details>
  <summary>Details</summary>
Motivation: Existing workflows for understanding the relationship between training data and model behavior during pretraining are cumbersome, fragmented, and inaccessible to researchers. TokenSmith aims to address this by providing an accessible and efficient tool for dataset analysis and editing.

Method: TokenSmith provides a user interface and modular backend to support various data operations like searching, viewing, ingesting, exporting, inspecting, and sampling. It also allows for structured editing of pretraining data without modifying training code, facilitating dataset debugging, validation, and experimentation.

Result: TokenSmith simplifies dataset debugging, validation, and experimentation by enabling structured editing of pretraining data without requiring changes to training code. It acts as a plug-and-play addition to existing pretraining workflows, democratizing access to dataset tooling.

Conclusion: TokenSmith is an open-source library designed to simplify the process of editing, inspecting, and analyzing datasets used in large language model pretraining. It offers a wide range of operations through a user-friendly interface and modular backend, enabling structured editing without altering training code. TokenSmith aims to democratize access to production-grade dataset tooling for researchers by integrating seamlessly into existing pretraining workflows.

Abstract: Understanding the relationship between training data and model behavior
during pretraining is crucial, but existing workflows make this process
cumbersome, fragmented, and often inaccessible to researchers. We present
TokenSmith, an open-source library for interactive editing, inspection, and
analysis of datasets used in Megatron-style pretraining frameworks such as
GPT-NeoX, Megatron, and NVIDIA NeMo. TokenSmith supports a wide range of
operations including searching, viewing, ingesting, exporting, inspecting, and
sampling data, all accessible through a simple user interface and a modular
backend. It also enables structured editing of pretraining data without
requiring changes to training code, simplifying dataset debugging, validation,
and experimentation.
  TokenSmith is designed as a plug and play addition to existing large language
model pretraining workflows, thereby democratizing access to production-grade
dataset tooling. TokenSmith is hosted on GitHub1, with accompanying
documentation and tutorials. A demonstration video is also available on
YouTube.

</details>


### [125] [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457)
*Lakshya A Agrawal,Shangyin Tan,Dilara Soylu,Noah Ziems,Rishi Khare,Krista Opsahl-Ong,Arnav Singhvi,Herumb Shandilya,Michael J Ryan,Meng Jiang,Christopher Potts,Koushik Sen,Alexandros G. Dimakis,Ion Stoica,Dan Klein,Matei Zaharia,Omar Khattab*

Main category: cs.CL

TL;DR: GEPA是一种通过自然语言反思进行提示优化的新方法，其效率和性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 与来自稀疏、标量奖励的策略梯度相比，语言的可解释性通常可以为LLM提供更丰富的学习媒介。

Method: GEPA（Genetic-Pareto）是一种提示优化器，它通过反复试验从自然语言反思中学习高级规则。给定任何包含一个或多个LLM提示的AI系统，GEPA会对系统级轨迹（例如，推理、工具调用和工具输出）进行采样，并用自然语言对其进行反思，以诊断问题、提出和测试提示更新，并结合其自身尝试的帕累托前沿的互补经验教训。

Result: GEPA可以在很少的试运行次数下实现很大的质量提升。

Conclusion: GEPA在四项任务中平均比GRPO高出10%，最高可提高20%，同时使用的试运行次数减少多达35倍。GEPA在两项LLM上也比领先的提示优化器MIPROv2高出10%以上，并在代码优化方面作为推理时搜索策略显示出有希望的结果。

Abstract: Large language models (LLMs) are increasingly adapted to downstream tasks via
reinforcement learning (RL) methods like Group Relative Policy Optimization
(GRPO), which often require thousands of rollouts to learn new tasks. We argue
that the interpretable nature of language can often provide a much richer
learning medium for LLMs, compared with policy gradients derived from sparse,
scalar rewards. To test this, we introduce GEPA (Genetic-Pareto), a prompt
optimizer that thoroughly incorporates natural language reflection to learn
high-level rules from trial and error. Given any AI system containing one or
more LLM prompts, GEPA samples system-level trajectories (e.g., reasoning, tool
calls, and tool outputs) and reflects on them in natural language to diagnose
problems, propose and test prompt updates, and combine complementary lessons
from the Pareto frontier of its own attempts. As a result of GEPA's design, it
can often turn even just a few rollouts into a large quality gain. Across four
tasks, GEPA outperforms GRPO by 10% on average and by up to 20%, while using up
to 35x fewer rollouts. GEPA also outperforms the leading prompt optimizer,
MIPROv2, by over 10% across two LLMs, and demonstrates promising results as an
inference-time search strategy for code optimization.

</details>


### [126] [Conversations Gone Awry, But Then? Evaluating Conversational Forecasting Models](https://arxiv.org/abs/2507.19470)
*Son Quoc Tran,Tushaar Gangavarapu,Nicholas Chernogor,Jonathan P. Chang,Cristian Danescu-Niculescu-Mizil*

Main category: cs.CL

TL;DR: 本研究提出了一个用于评估对话系统预测对话走向能力的统一框架和新指标，并对现有模型进行了评估。


<details>
  <summary>Details</summary>
Motivation: 为了使自动化系统能够像人类一样预测对话的走向，并在此基础上进行辅助，需要开发具有预测能力的模型。现有的研究主要集中在“对话失控”（CGA）任务上，即预测对话是否会失控。本工作旨在为 CGA 任务提供一个统一的评估框架，以便对不同模型进行直接和可靠的比较。

Method: 提出了一种统一的评估框架，并引入了一种新的评估指标。

Result: 该框架能够对 CGA 模型进行全面的评估，并展示了当前 CGA 模型在语言模型最新进展背景下的进展情况。引入的新指标能够衡量模型在对话过程中修正预测的能力。

Conclusion: 本工作提出了一个统一的评估框架，用于评估对话系统在对话可能出现偏差时进行预测的能力，并引入了一个新的评估指标来衡量模型在对话进行过程中修正预测的能力。

Abstract: We often rely on our intuition to anticipate the direction of a conversation.
Endowing automated systems with similar foresight can enable them to assist
human-human interactions. Recent work on developing models with this predictive
capacity has focused on the Conversations Gone Awry (CGA) task: forecasting
whether an ongoing conversation will derail. In this work, we revisit this task
and introduce the first uniform evaluation framework, creating a benchmark that
enables direct and reliable comparisons between different architectures. This
allows us to present an up-to-date overview of the current progress in CGA
models, in light of recent advancements in language modeling. Our framework
also introduces a novel metric that captures a model's ability to revise its
forecast as the conversation progresses.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [127] [Fixed points of Personalized PageRank centrality: From irreducible to reducible networks](https://arxiv.org/abs/2507.18652)
*David Aleja,Julio Flores,Eva Primo,Daniel Rodríguez,Miguel Romance*

Main category: cs.SI

TL;DR: 通过分析PageRank与个性化向量的关系，研究了其在复杂网络中的存在性和唯一性，并提出了一种精确计算固定点的方法。


<details>
  <summary>Details</summary>
Motivation: 分析PageRank作为其个性化向量函数的行为，以表征其在复杂网络中的存在性和唯一性。

Method: 提出了一种基于反馈PageRank和Perron向量的方法，用于精确计算PageRank的固定点。

Result: 给出了PageRank在复杂网络中存在性和唯一性的充要条件，并精确计算了其固定点。

Conclusion: 该研究为PageRank在复杂网络中的存在性和唯一性提供了完整的数学表征。

Abstract: In this paper we analyze the PageRank of a complex network as a function of
its personalization vector. By using this approach, a complete characterization
of the existence and uniqueness of fixed points of PageRank of a graph is given
in terms of the number and nature of its strongly connected components. The
method presented includes the use of a feedback-PageRank in order to compute
exactly the fixed points following the classic Power's Method in terms of the
(left-hand) Perron vector of each strongly connected components.

</details>


### [128] [Negative news posts are less prevalent and generate lower user engagement than non-negative news posts across six countries](https://arxiv.org/abs/2507.19300)
*Szymon Talaga,Dominik Batorski,Magdalena Wojcieszak*

Main category: cs.SI

TL;DR: 该研究分析了2020年至2024年间六个国家/地区97家媒体的600万个Facebook帖子，发现负面新闻（占12.6%）的负面性与政治和非政治帖子相当，但获得的互动（点赞、评论）较少。美国政治新闻的负面性低于其他国家。总体而言，负面新闻帖子仅占用户总互动量的10.2%-13.1%。


<details>
  <summary>Details</summary>
Motivation: 为了填补关于社交媒体上政治和非政治新闻帖子负面性及其参与度的比较证据的空白。

Method: 使用2020年1月1日至2024年4月1日之间发布的6,081,134个Facebook帖子，通过开发多语言分类器来区分政治/非政治和负面/非负面帖子。

Result: （1）负面新闻帖子仅占12.6%；（2）政治新闻帖子的负面性与非政治新闻帖子相当；（3）美国政治新闻帖子的负面性低于其他国家（平均低40%）；（4）负面新闻帖子获得的“喜欢”和评论比非负面新闻帖子少15%和13%；（5）负面新闻帖子占用户总参与度的10.2%-13.1%。

Conclusion: 政治新闻帖子的负面性与非政治新闻帖子相当，负面新闻帖子获得的“喜欢”和评论比非负面新闻帖子少。然而，负面新闻帖子占用户总参与度的比例相对较小（10.2%-13.1%）。

Abstract: Although news negativity is often studied, missing is comparative evidence on
the prevalence of and engagement with negative political and non-political news
posts on social media. We use 6,081,134 Facebook posts published between
January 1, 2020, and April 1, 2024, by 97 media organizations in six countries
(U.S., UK, Ireland, Poland, France, Spain) and develop two multilingual
classifiers for labeling posts as (non-)political and (non-)negative. We show
that: (1) negative news posts constitute a relatively small fraction (12.6%);
(2) political news posts are neither more nor less negative than non-political
news posts; (3) U.S. political news posts are less negative relative to the
other countries on average (40% lower odds); (4) Negative news posts get 15%
fewer likes and 13% fewer comments than non-negative news posts. Lastly, (5) we
provide estimates of the proportion of the total volume of user engagement with
negative news posts and show that only between 10.2% to 13.1% of engagement is
linked to negative posts by the analyzed news organizations.

</details>


### [129] [Changes to the Facebook Algorithm Decreased News Visibility Between 2021-2024](https://arxiv.org/abs/2507.19373)
*Szymon Talaga,Erin Wertz,Dominik Batorski,Magdalena Wojcieszak*

Main category: cs.SI

TL;DR: Meta 的“战争”确实压制了新闻可见性，但结束战争提高了用户对新闻的参与度。


<details>
  <summary>Details</summary>
Motivation: 研究 Meta 算法 deprioritized 新闻和政治内容如何影响新闻在 Facebook 平台上的可见性。

Method: 使用 2016 年 1 月 1 日至 2025 年 2 月 13 日期间来自 40 个新闻机构和 21 个非新闻页面的数据（包括 5,243,302 篇 Facebook 帖子、7,875,372,958 次用户反应以及 396,468 篇帖子和 1,909,088,308 次反应）来分析 Facebook 算法变化对新闻可见性的影响。

Result: 新闻的反应在 2021 年至 2024 年间下降了 78%，而非新闻页面的反应则有所增加，这表明新闻可见性受到了算法的压制。低质量新闻来源受到的影响尤为严重。然而，2025 年“战争”的结束提高了用户对新闻的反应，尤其是低质量新闻。这些变化并非源于新闻供应、Facebook 用户群或用户对新闻兴趣的下降。

Conclusion: Meta 算法“战争”确实降低了新闻可见性，尤其是在低质量新闻方面。2025 年“战争”的结束提高了用户对新闻的反应，特别是低质量新闻。

Abstract: Platforms, especially Facebook, are primary news sources in the US. In its
widely criticized "War on News," Meta algorithmically deprioritized news and
political content. We use data from 40 news organizations (5,243,302 Facebook
posts, 7,875,372,958 user reactions) and 21 non-news pages (396,468 posts;
1,909,088,308 reactions) between January 1, 2016 and February 13, 2025 to
examine how these changes influenced news visibility on the platform. Reactions
to news declined by 78% between 2021 and 2024 while reactions to non-news pages
increased, indicating targeted suppression of news visibility. Low-quality
sources were especially suppressed, yet the 2025 end to "War on News" increased
user reactions to news, especially low-quality ones. These changes do not
reflect decreased news supply, Facebook user base, or interest in news over
this period.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [130] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 本文介绍了Agent PULSE，一个用于预防保健和患者监护的AI语音助手，旨在弥合数字健康中的经济和可及性差距。试点研究显示患者接受度高，AI代理在成本效益和患者参与度方面有巨大潜力，但仍需解决技术和政策挑战。


<details>
  <summary>Details</summary>
Motivation: 为弥合数字健康服务的经济和可及性差距，将基于语音的AI代理整合到医疗保健领域。

Method: 本文探讨了大型语言模型（LLM）驱动的语音助手在加强预防保健和持续患者监护方面的作用，特别是对服务不足的群体。文章介绍了Agent PULSE（患者理解和联络支持引擎）的开发和试点研究，这是一个由IBM Research、Cleveland Clinic Foundation和Morehouse School of Medicine合作的项目。研究提出了一个经济模型，证明了AI代理如何在人力干预在经济上不可行的情况下提供成本效益高的医疗服务。

Result: 试点研究表明，70%的炎症性肠病患者接受AI驱动的监护，37%的患者偏好AI监护而非传统方式。AI代理在成本效益、可扩展性、效率、患者参与度和可及性方面具有巨大潜力。

Conclusion: AI驱动的语音代理能够提高医疗保健的可扩展性和效率，改善患者的参与度和可及性，并为公平、可持续的数字医疗解决方案提供关键的切入点。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [131] [Initial Steps in Integrating Large Reasoning and Action Models for Service Composition](https://arxiv.org/abs/2507.18775)
*Ilche Georgievski,Marco Aiello*

Main category: cs.AI

TL;DR: 通过结合大型推理模型（LRM）和大型动作模型（LAM），本研究提出了一种新的服务组合方法，以克服现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 服务组合是构建适应性和智能软件系统的核心挑战，通常受限于有限的推理能力或脆弱的执行机制。

Method: 提出一个集成的LRM-LAM架构框架，以解决现有服务组合方法的局限性。

Result: 该框架通过结合LRM的语义推理能力和LAM的动态执行能力，弥合了服务组合中意图与执行之间的差距。

Conclusion: 大型语言模型（LLM）支持的大型推理模型（LRM）和大型动作模型（LAM）的集成是自动化服务组合的有前景的方向，有望实现完全自动化的、用户友好的、由高级自然语言意图驱动的服务组合。

Abstract: Service composition remains a central challenge in building adaptive and
intelligent software systems, often constrained by limited reasoning
capabilities or brittle execution mechanisms. This paper explores the
integration of two emerging paradigms enabled by large language models: Large
Reasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs
address the challenges of semantic reasoning and ecosystem complexity while
LAMs excel in dynamic action execution and system interoperability. However,
each paradigm has complementary limitations - LRMs lack grounded action
capabilities, and LAMs often struggle with deep reasoning. We propose an
integrated LRM-LAM architectural framework as a promising direction for
advancing automated service composition. Such a system can reason about service
requirements and constraints while dynamically executing workflows, thus
bridging the gap between intention and execution. This integration has the
potential to transform service composition into a fully automated,
user-friendly process driven by high-level natural language intent.

</details>


### [132] [Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization](https://arxiv.org/abs/2507.18795)
*Fatima Al-Ani,Molly Wang,Jevon Charles,Aaron Ong,Joshua Forday,Vinayak Modi*

Main category: cs.AI

TL;DR: 提出了一种基于Dyna-DDPG的强化学习框架，用于优化制造和通信应用中复杂排队网络系统的路由决策。该框架通过结合模拟和强化学习，提高了路由决策的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统排队方法难以应对动态、不确定的环境，因此需要开发一种新的方法来优化复杂排队网络系统中的路由决策。

Method: 提出了一种利用深度确定性策略梯度（DDPG）结合Dyna风格规划（Dyna-DDPG）的鲁棒强化学习方法，并包含一个灵活可配置的模拟环境。该方法通过单独的预测模型来预测下一个状态转移和奖励，以提高稳定性和样本效率。

Result: 实验证明，该框架能够快速学习有效的路由策略，在中断下保持稳健的性能，并能有效地扩展到更大的网络规模。此外，还强调了为确保框架的可重现性和可维护性而采用的强大软件工程实践。

Conclusion: 该框架能够快速学习有效的路由策略，在中断下保持稳健的性能，并能有效地扩展到更大的网络规模。

Abstract: This study focuses on the development of a simulation-driven reinforcement
learning (RL) framework for optimizing routing decisions in complex queueing
network systems, with a particular emphasis on manufacturing and communication
applications. Recognizing the limitations of traditional queueing methods,
which often struggle with dynamic, uncertain environments, we propose a robust
RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with
Dyna-style planning (Dyna-DDPG). The framework includes a flexible and
configurable simulation environment capable of modeling diverse queueing
scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG
implementation incorporates separate predictive models for next-state
transitions and rewards, significantly improving stability and sample
efficiency. Comprehensive experiments and rigorous evaluations demonstrate the
framework's capability to rapidly learn effective routing policies that
maintain robust performance under disruptions and scale effectively to larger
network sizes. Additionally, we highlight strong software engineering practices
employed to ensure reproducibility and maintainability of the framework,
enabling practical deployment in real-world scenarios.

</details>


### [133] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
*Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun*

Main category: cs.AI

TL;DR: MIRAGE是一个模仿人脑海马-前额叶皮层循环的框架，通过神经分解器和图式引擎实现系统性组合泛化，在SCAN基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 受人脑通过海马体（HPC）和前额叶皮层（PFC）的相互作用来实现系统性组合泛化（构建和理解已知构建块的新颖组合）的启发，提出MIRAGE框架。

Method: MIRAGE框架包含两个交互模块：1. 元训练的Transformer神经分解器（模仿新皮质“系统1”计算），对随机抽样的组合语法流进行训练，每次迭代精炼序列表示。2. 图式引擎（模仿海马-前额叶皮层“系统2”循环），动态提取、排序和应用可重用图式，并将变量绑定存储在情景记忆中。

Result: MIRAGE在SCAN基准测试中实现了系统性组合泛化，所有任务分割准确率超过99%，Transformer模块参数量仅为1.19M。消融研究证实了MIRAGE的系统性在很大程度上依赖于提取的图式质量和模型的迭代精炼过程。

Conclusion: MIRAGE框架通过显式地为Transformer组件配备主动管理的图式结构，实现了在组合任务上的系统性泛化，仅依赖于冻结的权重即可解决全新的任务。该模型在SCAN基准测试中实现了系统性组合泛化，在所有任务分割上准确率均达到99%以上，Transformer模块仅有1.19M参数。

Abstract: Systematic compositional generalization - constructing and understanding
novel combinations of known building blocks - remains a core challenge for AI
systems. Human cognition achieves this flexibility via the interplay of the
hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes
episodes, and the prefrontal cortex consolidates them into reusable schemas for
reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with
Rules and Abstractions from Generalized Experience), a framework that achieves
systematic generalization on compositional tasks. MIRAGE has two interacting
modules mirroring the brain's deliberative HPC-PFC loop and intuitive
neocortical pattern recognition. (1) The meta-trained Transformer Neural
Decomposer, paralleling neocortical "System 1" computation, is trained on a
task-agnostic stream of randomly sampled compositional grammars and applies one
decomposition step per pass, with successive passes iteratively refining the
sequence representation. (2) The Schema Engine, analogous to the HPC-PFC
"System 2" loop, dynamically extracts, ranks, and applies reusable schemas,
storing variable bindings in episodic memory and expanding them when needed. By
explicitly equipping the Transformer component of MIRAGE with actively managed
schematic structures, our model performs systematic compositional operations
through explicit schema application and transformation, relying solely on
frozen weights when solving entirely novel tasks. This approach demonstrates
systematic compositional generalization on the SCAN benchmark, achieving > 99%
accuracy on all task splits with only 1.19M parameters in the transformer
module. Ablation studies confirm that MIRAGE's systematicity critically depends
on the quality of extracted schemas and the model's iterative refinement
process.

</details>


### [134] [Success in Humanoid Reinforcement Learning under Partial Observation](https://arxiv.org/abs/2507.18883)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.AI

TL;DR: 该研究首次成功地在部分可观测的人形机器人运动任务中通过一种新颖的历史编码器实现了有效的策略学习，其性能与完全可观测任务相当，并能适应机器人参数变化。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在机器人控制中，尤其是在高维任务（如人形机器人运动）下，即使在状态信息不完整的情况下，仍然难以进行有效的策略学习的挑战。

Method: 提出了一种新颖的、并行处理固定长度历史观测序列的历史编码器，并将其集成到标准的无模型算法中。

Result: 在部分可观测性条件下，学习到的策略性能可与完全可观测状态下的最优结果相媲美，同时只需要原始状态信息的 1/3 到 2/3。该策略还能适应机器人特性的变化。 假设该编码器能够从最近的观测中重建关键的上下文信息，从而实现鲁棒的决策。 

Conclusion: 研究首次在 Gymnasium Humanoid-v4 环境中实现了在部分可观测性下的策略学习，学习到的策略性能可与完全可观测状态下的最优结果相媲美，并且能够适应机器人特性的变化（如身体部件质量的变化）。

Abstract: Reinforcement learning has been widely applied to robotic control, but
effective policy learning under partial observability remains a major
challenge, especially in high-dimensional tasks like humanoid locomotion. To
date, no prior work has demonstrated stable training of humanoid policies with
incomplete state information in the benchmark Gymnasium Humanoid-v4
environment. The objective in this environment is to walk forward as fast as
possible without falling, with rewards provided for staying upright and moving
forward, and penalties incurred for excessive actions and external contact
forces. This research presents the first successful instance of learning under
partial observability in this environment. The learned policy achieves
performance comparable to state-of-the-art results with full state access,
despite using only one-third to two-thirds of the original states. Moreover,
the policy exhibits adaptability to robot properties, such as variations in
body part masses. The key to this success is a novel history encoder that
processes a fixed-length sequence of past observations in parallel. Integrated
into a standard model-free algorithm, the encoder enables performance on par
with fully observed baselines. We hypothesize that it reconstructs essential
contextual information from recent observations, thereby enabling robust
decision-making.

</details>


### [135] [Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](https://arxiv.org/abs/2507.19364)
*Patrick Taillandier,Jean Daniel Zucker,Arnaud Grignard,Benoit Gaudou,Nghi Quang Huynh,Alexis Drogoul*

Main category: cs.AI

TL;DR: 本文探讨了LLM在社会模拟中的应用，指出了其潜力和局限性，并建议将LLM与传统建模方法相结合，以提高模拟的灵活性和严谨性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探讨大型语言模型（LLM）在社会模拟中的应用，分析其潜力与局限性，并提出一种结合LLM和传统建模方法的混合途径。

Method: 本文首先回顾了LLM在复制人类认知（如心智理论推理和社会推断）方面的能力及其局限性（如认知偏差、缺乏真正理解和行为不一致）。接着，探讨了LLM在多主体模拟框架中的新兴应用，重点关注系统架构、规模和验证策略，并讨论了Generative Agents (Smallville)和AgentSociety等项目的设计选择、实证基础和方法创新。最后，区分了LLM作为黑盒系统适用性不同的情境，如交互式模拟和严肃游戏，以及更具挑战性的情境，如解释性或预测性建模。

Result: LLM在模拟人类认知方面展现出潜力，但存在认知偏差和行为不一致等局限。在多主体模拟中，LLM的应用面临行为保真度、校准和可重复性等挑战。LLM适用于交互式模拟和严肃游戏，但在解释性或预测性建模方面存在问题。

Conclusion: 建议将LLM与传统的基于代理的建模平台（如GAMA、Netlogo等）相结合，以融合语言推理的灵活性和经典基于规则的系统的透明度及分析严谨性。

Abstract: This position paper examines the use of Large Language Models (LLMs) in
social simulation, analyzing both their potential and their limitations from a
computational social science perspective. The first part reviews recent
findings on the ability of LLMs to replicate key aspects of human cognition,
including Theory of Mind reasoning and social inference, while also
highlighting significant limitations such as cognitive biases, lack of true
understanding, and inconsistencies in behavior. The second part surveys
emerging applications of LLMs in multi-agent simulation frameworks, focusing on
system architectures, scale, and validation strategies. Notable projects such
as Generative Agents (Smallville) and AgentSociety are discussed in terms of
their design choices, empirical grounding, and methodological innovations.
Particular attention is given to the challenges of behavioral fidelity,
calibration, and reproducibility in large-scale LLM-driven simulations. The
final section distinguishes between contexts where LLMs, like other black-box
systems, offer direct value-such as interactive simulations and serious
games-and those where their use is more problematic, notably in explanatory or
predictive modeling. The paper concludes by advocating for hybrid approaches
that integrate LLMs into traditional agent-based modeling platforms (GAMA,
Netlogo, etc), enabling modelers to combine the expressive flexibility of
language-based reasoning with the transparency and analytical rigor of
classical rule-based systems.

</details>


### [136] [Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling](https://arxiv.org/abs/2507.18977)
*Mehrnoosh Mirtaheri,Ryan A. Rossi,Sungchul Kim,Kanak Mahadik,Tong Yu,Xiang Chen,Mohammad Rostami*

Main category: cs.AI

TL;DR: 本文提出了一种用于时间知识图谱（TKG）的增量训练框架，通过增强层和加权采样策略来处理新实体和稀疏连接问题，显著提高了链接预测和长尾实体处理的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的时间知识图谱（TKG）补全模型在训练时假设可以访问整个图谱，这忽略了TKG演化过程中模型泛化、吸收新知识以及处理连接稀疏的新实体等挑战。

Method: 本文提出了一种结合模型无关的增强层和加权采样策略的增量训练框架。增强层利用了超越GNN局部邻域的更广泛的全局实体相似性定义，而加权采样策略则侧重于包含罕见实体的边。

Result: 该框架在两个基准数据集上的评估结果显示，在总链接预测、归纳链接预测以及处理长尾实体方面均优于现有方法，特别是带来了10%的性能提升和15%的MRR（平均倒数排名）提升。

Conclusion: 该框架通过结合模型无关的增强层和加权采样策略，有效解决了时间知识图谱（TKG）增量训练中的新实体和稀疏连接问题，并在链接预测和长尾实体处理方面取得了显著的性能提升，同时缓解了灾难性遗忘问题。

Abstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access
to the entire graph during training. This overlooks challenges stemming from
the evolving nature of TKGs, such as: (i) the model's requirement to generalize
and assimilate new knowledge, and (ii) the task of managing new or unseen
entities that often have sparse connections. In this paper, we present an
incremental training framework specifically designed for TKGs, aiming to
address entities that are either not observed during training or have sparse
connections. Our approach combines a model-agnostic enhancement layer with a
weighted sampling strategy, that can be augmented to and improve any existing
TKG completion method. The enhancement layer leverages a broader, global
definition of entity similarity, which moves beyond mere local neighborhood
proximity of GNN-based methods. The weighted sampling strategy employed in
training accentuates edges linked to infrequently occurring entities. We
evaluate our method on two benchmark datasets, and demonstrate that our
framework outperforms existing methods in total link prediction, inductive link
prediction, and in addressing long-tail entities. Notably, our method achieves
a 10\% improvement and a 15\% boost in MRR for these datasets. The results
underscore the potential of our approach in mitigating catastrophic forgetting
and enhancing the robustness of TKG completion methods, especially in an
incremental training context

</details>


### [137] [Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation](https://arxiv.org/abs/2507.19089)
*Shuhao Li,Weidong Yang,Yue Cui,Xiaoxing Liu,Lingkai Meng,Lipeng Ma,Fan Zhang*

Main category: cs.AI

TL;DR: FRTI 任务旨在解决传感器限制导致的细粒度车道交通数据获取瓶颈，通过 RoadDiff 框架利用有限数据推断车道交通状态，并在实验中证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的车道级交通数据获取方式存在传感器类型和数量的限制以及追踪算法精度问题，阻碍了数据驱动模型在交通管理和预测等应用中的发展。FRTI 任务旨在利用有限数据生成细粒度车道级交通信息，提供更经济高效的解决方案。

Method: 提出 FRTI 任务，并设计了一个名为 RoadDiff 的两阶段框架，包括 Road-Lane Correlation Autoencoder-Decoder 和 Lane Diffusion Module，以解决该任务。

Result: 在六个不同道路条件的数据集上进行了广泛的实验，验证了 RoadDiff 模型在解决 FRTI 任务方面的有效性。

Conclusion: FRTI 任务可以通过 RoadDiff 框架解决，该框架能有效利用有限的交通数据推断细粒度的车道交通状态，并在六个不同道路条件的数据集上进行了验证。

Abstract: Fine-grained traffic management and prediction are fundamental to key
applications such as autonomous driving, lane change guidance, and traffic
signal control. However, obtaining lane-level traffic data has become a
critical bottleneck for data-driven models due to limitations in the types and
number of sensors and issues with the accuracy of tracking algorithms. To
address this, we propose the Fine-grained Road Traffic Inference (FRTI) task,
which aims to generate more detailed lane-level traffic information using
limited road data, providing a more energy-efficient and cost-effective
solution for precise traffic management. This task is abstracted as the first
scene of the spatio-temporal graph node generation problem. We designed a
two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.
This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the
Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies
and distribution relationships of road data to accurately infer fine-grained
lane traffic states. Based on existing research, we designed several baseline
models with the potential to solve the FRTI task and conducted extensive
experiments on six datasets representing different road conditions to validate
the effectiveness of the RoadDiff model in addressing the FRTI task. The
relevant datasets and code are available at
https://github.com/ShuhaoLii/RoadDiff.

</details>


### [138] [Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization](https://arxiv.org/abs/2507.19109)
*Noé Lallouet,Tristan Cazenave,Cyrille Enderli*

Main category: cs.AI

TL;DR: Pareto-NRPA 是一种新的多目标优化算法，它扩展了 NRPA 算法。该算法在 MO-TSPTW 和神经网络架构搜索任务上表现良好，并在受约束的搜索空间中优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决离散搜索空间中的多目标优化问题，将嵌套滚出策略自适应 (NRPA) 算法推广到多目标优化。

Method: Pareto-NRPA 是一种新的蒙特卡洛算法，用于解决离散搜索空间中的多目标优化问题。它扩展了最初为单目标问题制定的嵌套滚出策略自适应 (NRPA) 算法，将嵌套搜索和策略更新机制推广到多目标优化。该算法使用一组策略来并发探索解空间的不同区域，并在搜索的每个级别维护非支配前沿。策略适应是根据 Pareto 前沿内序列的多样性和隔离性进行的。

Result: Pareto-NRPA 在一个新颖的双目标旅行商时间窗问题 (MO-TSPTW) 和一个已知的基准测试的神经网络架构搜索任务上进行了测试。结果表明，Pareto-NRPA 在收敛性和解的多样性方面都优于最先进的多目标算法，并且在受约束的搜索空间中表现尤为出色。

Conclusion: Pareto-NRPA 在受约束和不受约束的搜索空间中均表现出与最先进的多目标算法相当的性能，特别是在受约束的搜索空间中，其性能明显优于最先进的进化多目标算法。

Abstract: We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for
multi-objective optimization problems over discrete search spaces. Extending
the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for
single-objective problems, Pareto-NRPA generalizes the nested search and policy
update mechanism to multi-objective optimization. The algorithm uses a set of
policies to concurrently explore different regions of the solution space and
maintains non-dominated fronts at each level of search. Policy adaptation is
performed with respect to the diversity and isolation of sequences within the
Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel
bi-objective variant of the Traveling Salesman Problem with Time Windows
problem (MO-TSPTW), and a neural architecture search task on well-known
benchmarks. Results demonstrate that Pareto-NRPA achieves competitive
performance against state-of-the-art multi-objective algorithms, both in terms
of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly
outperforms state-of-the-art evolutionary multi-objective algorithms on
constrained search spaces. To our knowledge, this work constitutes the first
adaptation of NRPA to the multi-objective setting.

</details>


### [139] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: OS-MAP是一个新的基准测试，用于评估日常计算机使用自动化。它包含416个任务，跨越15个应用程序，并根据自动化级别和泛化范围进行评估。实验发现，即使是最先进的智能体，在需要感知、推理和协调的高级任务方面也存在困难。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试未能充分考虑内部任务的异质性、相应的智能体能力以及它们与实际用户需求的对齐情况，这阻碍了有针对性的能力开发和研究进展向实际部署的可靠过渡。

Method: 提出OS-MAP基准测试，该基准测试包含15个应用程序中的416个真实任务，并沿着两个关键维度组织：一个五级自动化分类法和一个源自真实用户需求层级的泛化范围。OS-MAP通过自动化级别和泛化范围这两个维度来评估智能体，以实现对所需能力和与真实场景的对齐进行细粒度分析。

Result: OS-MAP基准测试能够对智能体进行结构化和全面的评估，捕捉不同程度的智能体自主性和泛化需求。实验结果表明，即使是先进的智能体也难以应对更高级别的任务，突显了改进现有智能体的必要性。

Conclusion: 目前的OS-MAP基准测试表明，即使是具有视觉语言模型（VLM）骨干的先进的计算机智能体，也难以胜任需要感知、推理和协调的更高级别任务。这凸显了深入理解当前优势和局限性对于推动计算机智能体研究和部署的未来进展的必要性。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


### [140] [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172)
*Jiyao Wang,Xiao Yang,Qingyong Hu,Jiankai Tang,Can Liu,Dengbo He,Yuntao Wang,Yingcong Chen,Kaishun Wu*

Main category: cs.AI

TL;DR: This paper introduces PhysDrive, a large-scale dataset for contactless in-vehicle physiological monitoring, addressing limitations of existing datasets. It includes multimodal sensor data and ground truth physiological signals from 48 drivers under various driving conditions. The dataset is intended to benchmark and advance research in driver monitoring systems.


<details>
  <summary>Details</summary>
Motivation: Robust and unobtrusive in-vehicle physiological monitoring is crucial for driving safety and user experience. Existing datasets for remote physiological measurement (RPM) are limited in scale, modality diversity, biometric annotations, and captured conditions, failing to address real-world driving challenges.

Method: The paper presents PhysDrive, a large-scale multimodal dataset for contactless in-vehicle physiological sensing. The dataset includes synchronized RGB, near-infrared camera, and raw mmWave radar data, along with six synchronized ground truths (ECG, BVP, Respiration, HR, RR, and SpO2), collected from 48 drivers under various naturalistic driving conditions. The paper also includes an extensive evaluation of both signal-processing and deep-learning methods on this dataset, establishing a comprehensive benchmark across all modalities.

Result: PhysDrive is the first large-scale multimodal dataset for contactless in-vehicle physiological sensing, incorporating diverse modalities and ground truths, and covering a wide spectrum of naturalistic driving conditions. Evaluations of signal-processing and deep-learning methods on PhysDrive establish a comprehensive benchmark.

Conclusion: PhysDrive dataset is expected to serve as a foundational resource and accelerate research on multimodal driver monitoring and smart-cockpit systems.

Abstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for
ensuring driving safety and user experience. While remote physiological
measurement (RPM) offers a promising non-invasive solution, its translation to
real-world driving scenarios is critically constrained by the scarcity of
comprehensive datasets. Existing resources are often limited in scale, modality
diversity, the breadth of biometric annotations, and the range of captured
conditions, thereby omitting inherent real-world challenges in driving. Here,
we present PhysDrive, the first large-scale multimodal dataset for contactless
in-vehicle physiological sensing with dedicated consideration on various
modality settings and driving factors. PhysDrive collects data from 48 drivers,
including synchronized RGB, near-infrared camera, and raw mmWave radar data,
accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,
and SpO2). It covers a wide spectrum of naturalistic driving conditions,
including driver motions, dynamic natural light, vehicle types, and road
conditions. We extensively evaluate both signal-processing and deep-learning
methods on PhysDrive, establishing a comprehensive benchmark across all
modalities, and release full open-source code with compatibility for mainstream
public toolboxes. We envision PhysDrive will serve as a foundational resource
and accelerate research on multimodal driver monitoring and smart-cockpit
systems.

</details>


### [141] [Faster Lifting for Ordered Domains with Predecessor Relations](https://arxiv.org/abs/2507.19182)
*Kuncheng Zou,Jiahao Mai,Yonggang Zhang,Yuyi Wang,Ondřej Kuželka,Yuanhong Wang,Yi Chang*

Main category: cs.AI

TL;DR: 提出了一种新的算法，将前驱关系作为公理的原生部分，解决了现有WFOMC算法在处理前驱关系时的实际应用困难，并在提升推理任务和组合数学问题上实现了数量级的加速。


<details>
  <summary>Details</summary>
Motivation: 解决现有WFOMC算法在处理前驱关系时的实际应用困难，即使理论上具有可处理性。

Method: 将前驱关系作为公理的原生部分，并设计了支持这些关系的新算法，实现了对即时和第二前驱关系的指数级加速，并能处理一般k-前驱关系。

Result: 所提出的算法在提升推理任务和组合数学问题上的实验证明了其效率，实现了数量级的加速。

Conclusion: 该算法在提升推理任务和组合数学问题上实现了数量级的加速。

Abstract: We investigate lifted inference on ordered domains with predecessor
relations, where the elements of the domain respect a total (cyclic) order, and
every element has a distinct (clockwise) predecessor. Previous work has
explored this problem through weighted first-order model counting (WFOMC),
which computes the weighted sum of models for a given first-order logic
sentence over a finite domain. In WFOMC, the order constraint is typically
encoded by the linear order axiom introducing a binary predicate in the
sentence to impose a linear ordering on the domain elements. The immediate and
second predecessor relations are then encoded by the linear order predicate.
Although WFOMC with the linear order axiom is theoretically tractable, existing
algorithms struggle with practical applications, particularly when the
predecessor relations are involved. In this paper, we treat predecessor
relations as a native part of the axiom and devise a novel algorithm that
inherently supports these relations. The proposed algorithm not only provides
an exponential speedup for the immediate and second predecessor relations,
which are known to be tractable, but also handles the general k-th predecessor
relations. The extensive experiments on lifted inference tasks and
combinatorics math problems demonstrate the efficiency of our algorithm,
achieving speedups of a full order of magnitude.

</details>


### [142] [Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments](https://arxiv.org/abs/2507.19261)
*Osama Almurshed,Ashish Kaushal,Asmail Muftah,Nitin Auluck,Omer Rana*

Main category: cs.AI

TL;DR: 通过知识嫁接技术，将大模型能力迁移到小模型，实现了模型的小型化和性能的提升，解决了AI在资源受限设备部署的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型、复杂的AI模型需要大量计算资源，这在许多实际应用场景中是不可获得的。本研究旨在解决AI模型在资源受限环境下的部署和性能问题。

Method: 知识嫁接（Knowledge Grafting），将大型捐赠模型（donor model）的特定特征（scion）迁移到小型根stock模型（rootstock model）上，以优化AI模型在资源受限环境下的性能。

Result: 模型尺寸减小了88.54%（从64.39 MB减少到7.38 MB），同时提高了泛化能力。新的根stock模型在验证集上达到了89.97%的准确率（优于捐赠模型的87.47%），验证集上的损失更低（0.2976 vs 0.5068），在未见过的数据上测试准确率为90.45%。

Conclusion: 该研究提出知识嫁接技术，成功将大型AI模型优化至可在资源受限环境下运行，并在农业杂草检测场景中取得了优于原模型的性能，显著减小了模型尺寸，解决了模型尺寸与性能的权衡问题，有潜力加速AI在边缘计算等场景的应用。

Abstract: The increasing adoption of Artificial Intelligence (AI) has led to larger,
more complex models with numerous parameters that require substantial computing
power -- resources often unavailable in many real-world application scenarios.
Our paper addresses this challenge by introducing knowledge grafting, a novel
mechanism that optimizes AI models for resource-constrained environments by
transferring selected features (the scion) from a large donor model to a
smaller rootstock model. The approach achieves an 88.54% reduction in model
size (from 64.39 MB to 7.38 MB), while improving generalization capability of
the model. Our new rootstock model achieves 89.97% validation accuracy (vs.
donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and
performs exceptionally well on unseen test data with 90.45% accuracy. It
addresses the typical size vs performance trade-off, and enables deployment of
AI frameworks on resource-constrained devices with enhanced performance. We
have tested our approach on an agricultural weed detection scenario, however,
it can be extended across various edge computing scenarios, potentially
accelerating AI adoption in areas with limited hardware/software support -- by
mirroring in a similar manner the horticultural grafting enables productive
cultivation in challenging agri-based environments.

</details>


### [143] [Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games](https://arxiv.org/abs/2507.19263)
*Achille Morenville,Éric Piette*

Main category: cs.AI

TL;DR: 在信息不完全的游戏中，基于约束的信念模型在性能上与概率模型相当，表明它们足以满足许多场景下的决策需求。


<details>
  <summary>Details</summary>
Motivation: 在信息不完全的游戏中，智能体必须基于对游戏状态的部分知识做出决策。信念随机博弈模型通过将状态估计委托给博弈模型本身来应对这一挑战。

Method: 本文研究了两种表示信念的方法：一种是使用约束满足问题的基于约束的模型，另一种是使用信念传播来估计边缘概率的概率扩展。

Result: 通过在两种不同的游戏中测试通用智能体，我们发现基于约束的信念可以产生与概率推理相当的结果，智能体性能的差异很小。

Conclusion: 基于约束的信念状态足以应对许多情况下的有效决策，与基于概率推理的方法相比，性能差异很小。

Abstract: In imperfect-information games, agents must make decisions based on partial
knowledge of the game state. The Belief Stochastic Game model addresses this
challenge by delegating state estimation to the game model itself. This allows
agents to operate on externally provided belief states, thereby reducing the
need for game-specific inference logic. This paper investigates two approaches
to represent beliefs in games with hidden piece identities: a constraint-based
model using Constraint Satisfaction Problems and a probabilistic extension
using Belief Propagation to estimate marginal probabilities. We evaluated the
impact of both representations using general-purpose agents across two
different games. Our findings indicate that constraint-based beliefs yield
results comparable to those of probabilistic inference, with minimal
differences in agent performance. This suggests that constraint-based belief
states alone may suffice for effective decision-making in many settings.

</details>


### [144] [Learning neuro-symbolic convergent term rewriting systems](https://arxiv.org/abs/2507.19372)
*Flavio Petruzzellis,Alberto Testolin,Alessandro Sperduti*

Main category: cs.AI

TL;DR: 提出了一种名为NRS和FastNRS的神经符号框架，用于学习收敛的术语重写系统。该框架在数学公式简化和多领域学习任务上取得了优于现有模型的性能。


<details>
  <summary>Details</summary>
Motivation: 旨在构建能够学习执行符号算法的神经系统，并实现强大的泛化和跨分布性能。

Method: 使用受重写算法启发的神经符号架构，构建了神经重写系统（NRS）和快速神经重写系统（FastNRS）。

Result: NRS和FastNRS模型能够泛化到跨分布实例，其中FastNRS在内存效率、训练速度和推理时间方面表现出显著的改进。所提出的系统在数学公式简化任务上显著优于神经数据路由器和GPT-4o等基线模型，并且在推理基准测试中与OpenAI的最新o1-preview模型相当或更优。

Conclusion: 所提出的神经符号方法在数学公式简化任务上显著优于现有的神经基线模型，并且在多领域学习场景中展现了通用性。

Abstract: Building neural systems that can learn to execute symbolic algorithms is a
challenging open problem in artificial intelligence, especially when aiming for
strong generalization and out-of-distribution performance. In this work, we
introduce a general framework for learning convergent term rewriting systems
using a neuro-symbolic architecture inspired by the rewriting algorithm itself.
We present two modular implementations of such architecture: the Neural
Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a
result of algorithmic-inspired design and key architectural elements, both
models can generalize to out-of-distribution instances, with FastNRS offering
significant improvements in terms of memory efficiency, training speed, and
inference time. We evaluate both architectures on four tasks involving the
simplification of mathematical formulas and further demonstrate their
versatility in a multi-domain learning scenario, where a single model is
trained to solve multiple types of problems simultaneously. The proposed system
significantly outperforms two strong neural baselines: the Neural Data Router,
a recent transformer variant specifically designed to solve algorithmic
problems, and GPT-4o, one of the most powerful general-purpose large-language
models. Moreover, our system matches or outperforms the latest o1-preview model
from OpenAI that excels in reasoning benchmarks.

</details>


### [145] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
*Amir Fard,Arnold X. -X. Yuan*

Main category: cs.AI

TL;DR: 本研究提出了一种分层深度强化学习方法，用于优化基础设施资产管理中的预算规划和维护决策，有效解决了现有方法的局限性，并在实验中取得了优于传统方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在预算规划和维护优化方面存在可扩展性问题，这是由于组合动作空间、资产退化、预算限制和环境不确定性等复杂性造成的。

Method: 提出了一种分层深度强化学习方法，将问题分解为高级预算规划器和低级维护规划器两个层次，并结合了线性规划投影和分层软Actor-Critic框架。

Result: 该方法在不同规模的下水道网络案例研究中表现出色，与传统方法相比，收敛速度更快，扩展性更好，并能提供接近最优的解决方案。

Conclusion: 该方法通过分层方法有效地解决了组合动作空间、资产退化、预算限制和环境不确定性等问题，并且比传统的深度Q学习和增强遗传算法收敛更快，扩展性更好，并且即使在网络规模不断增大的情况下，也能持续提供接近最优的解决方案。

Abstract: Budget planning and maintenance optimization are crucial for infrastructure
asset management, ensuring cost-effectiveness and sustainability. However, the
complexity arising from combinatorial action spaces, diverse asset
deterioration, stringent budget constraints, and environmental uncertainty
significantly limits existing methods' scalability. This paper proposes a
Hierarchical Deep Reinforcement Learning methodology specifically tailored to
multi-year infrastructure planning. Our approach decomposes the problem into
two hierarchical levels: a high-level Budget Planner allocating annual budgets
within explicit feasibility bounds, and a low-level Maintenance Planner
prioritizing assets within the allocated budget. By structurally separating
macro-budget decisions from asset-level prioritization and integrating linear
programming projection within a hierarchical Soft Actor-Critic framework, the
method efficiently addresses exponential growth in the action space and ensures
rigorous budget compliance. A case study evaluating sewer networks of varying
sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed
approach. Compared to conventional Deep Q-Learning and enhanced genetic
algorithms, our methodology converges more rapidly, scales effectively, and
consistently delivers near-optimal solutions even as network size grows.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [146] [Diffusion Models for Solving Inverse Problems via Posterior Sampling with Piecewise Guidance](https://arxiv.org/abs/2507.18654)
*Saeed Mohseni-Sehdeh,Walid Saad,Kei Sakaguchi,Tao Yu*

Main category: cs.LG

TL;DR: 本研究提出了一个通用的扩散模型框架，用于解决逆问题。该框架采用分段引导方案，可在不影响准确性的情况下提高计算效率。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在通过分段引导方案解决逆问题，以平衡计算效率和引导项的准确性。

Method: 提出了一种新颖的基于扩散的框架，该框架采用分段引导方案来解决逆问题。引导项被定义为扩散时间步的函数，以便在加噪和去噪阶段使用不同的近似。

Result: 实验结果表明，与基线模型相比，该框架在图像修复任务（包括图像修复和超分辨率）上实现了更快的推理速度，同时在PSNR和SSIM方面仅有可忽略的损失。

Conclusion: 该方法是一种通用的、无需重新训练即可应用于各种逆问题的扩散模型框架。此外，该方法将测量噪声明确纳入重建过程。

Abstract: Diffusion models are powerful tools for sampling from high-dimensional
distributions by progressively transforming pure noise into structured data
through a denoising process. When equipped with a guidance mechanism, these
models can also generate samples from conditional distributions. In this paper,
a novel diffusion-based framework is introduced for solving inverse problems
using a piecewise guidance scheme. The guidance term is defined as a piecewise
function of the diffusion timestep, facilitating the use of different
approximations during high-noise and low-noise phases. This design is shown to
effectively balance computational efficiency with the accuracy of the guidance
term. Unlike task-specific approaches that require retraining for each problem,
the proposed method is problem-agnostic and readily adaptable to a variety of
inverse problems. Additionally, it explicitly incorporates measurement noise
into the reconstruction process. The effectiveness of the proposed framework is
demonstrated through extensive experiments on image restoration tasks,
specifically image inpainting and super-resolution. Using a class conditional
diffusion model for recovery, compared to the \pgdm baseline, the proposed
framework achieves a reduction in inference time of \(25\%\) for inpainting
with both random and center masks, and \(23\%\) and \(24\%\) for \(4\times\)
and \(8\times\) super-resolution tasks, respectively, while incurring only
negligible loss in PSNR and SSIM.

</details>


### [147] [Concept Probing: Where to Find Human-Defined Concepts (Extended Version)](https://arxiv.org/abs/2507.18681)
*Manuel de Sousa Ribeiro,Afonso Leote,João Leite*

Main category: cs.LG

TL;DR: This paper presents a method to automatically find the best layers in neural networks for 'concept probing' by checking how well the network's internal data represents a concept. They tested it on different models and datasets.


<details>
  <summary>Details</summary>
Motivation: Concept probing is a popular technique for understanding artificial neural networks, but its effectiveness is highly dependent on selecting the appropriate layer to probe. This paper addresses the need for an automated method to identify such layers.

Method: The proposed method automatically identifies optimal layers for concept probing by assessing the informativeness and regularity of representations with respect to a given concept.

Result: The paper validates its proposed method through an exhaustive empirical analysis, demonstrating its effectiveness in identifying optimal layers for concept probing across various neural network models and datasets.

Conclusion:  The paper proposes and validates a method for automatically identifying the most informative and regular layers in a neural network for concept probing, based on empirical analysis across different models and datasets.

Abstract: Concept probing has recently gained popularity as a way for humans to peek
into what is encoded within artificial neural networks. In concept probing,
additional classifiers are trained to map the internal representations of a
model into human-defined concepts of interest. However, the performance of
these probes is highly dependent on the internal representations they probe
from, making identifying the appropriate layer to probe an essential task. In
this paper, we propose a method to automatically identify which layer's
representations in a neural network model should be considered when probing for
a given human-defined concept of interest, based on how informative and regular
the representations are with respect to the concept. We validate our findings
through an exhaustive empirical analysis over different neural network models
and datasets.

</details>


### [148] [Efficient Knowledge Tracing Leveraging Higher-Order Information in Integrated Graphs](https://arxiv.org/abs/2507.18668)
*Donghee Han,Daehee Kim,Minjun Lee,Daeyoung Roh,Keejun Han,Mun Yong Yi*

Main category: cs.LG

TL;DR: DGAKT是一种新的图神经网络模型，通过使用基于子图的方法来解决在线学习中知识追踪的计算成本问题，提高了效率并取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的知识追踪（KT）方法在利用大图和长学习序列时存在计算成本增加的问题，而DGAKT旨在解决这一挑战。

Method: DGAKT是一种图神经网络模型，它采用基于子图的方法来提高计算效率，通过仅处理每个目标交互相关的子图来显著降低内存和计算需求。

Result: DGAKT不仅在性能上超越了现有的KT模型，而且在资源效率方面也设定了新的标准。

Conclusion: DGAKT在资源效率方面设定了新的标准，解决了先前KT方法在很大程度上忽视的关键需求。

Abstract: The rise of online learning has led to the development of various knowledge
tracing (KT) methods. However, existing methods have overlooked the problem of
increasing computational cost when utilizing large graphs and long learning
sequences. To address this issue, we introduce Dual Graph Attention-based
Knowledge Tracing (DGAKT), a graph neural network model designed to leverage
high-order information from subgraphs representing student-exercise-KC
relationships. DGAKT incorporates a subgraph-based approach to enhance
computational efficiency. By processing only relevant subgraphs for each target
interaction, DGAKT significantly reduces memory and computational requirements
compared to full global graph models. Extensive experimental results
demonstrate that DGAKT not only outperforms existing KT models but also sets a
new standard in resource efficiency, addressing a critical need that has been
largely overlooked by prior KT approaches.

</details>


### [149] [Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning via Incorporating Generalized Human Expertise](https://arxiv.org/abs/2507.18867)
*Xuefei Wu,Xiao Yin,Yuanyang Zhu,Chunlin Chen*

Main category: cs.LG

TL;DR: 本研究提出了一种名为LIGHT的框架，通过整合人类专业知识来改进多智能体强化学习中的探索效率。该框架通过设计个体内在奖励，使智能体能够更好地学习和泛化，并在实验中表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习（MARL）中，仅接收团队奖励（特别是在奖励稀疏的环境中）会导致探索效率低下。现有的通过设计密集个体奖励来解决此问题的方法，通常依赖于手工设计的奖励函数，这些函数缺乏高阶智能，在学习和泛化能力方面不如人类。因此，需要一种能够整合人类知识以克服这些限制的新方法。

Method: 本研究提出了一种名为LIGHT（Learning Individual Intrinsic reward via Incorporating Generalized Human experTise）的新框架。该框架结合了手工设计的奖励函数和基于人类知识的奖励，通过考虑个体动作分布和人类专业知识偏好分布来指导智能体，避免不必要的探索。此外，它还为每个智能体设计了基于与Q学习相关的可操作表示转换的个体内在奖励，使智能体的动作偏好与人类专业知识保持一致，同时最大化联合动作价值。

Result: 实验结果表明，我们提出的LIGHT方法在性能和跨不同稀疏奖励任务的知识可重用性方面，优于代表性的基线方法。

Conclusion: 所提出的LIGHT框架通过整合人类专业知识，为每个智能体设计了基于可操作表示转换的个体内在奖励，以解决多智能体强化学习（MARL）中仅接收团队奖励时的探索效率低下问题，尤其是在奖励稀疏的环境中。实验结果证明了该方法在性能和跨不同稀疏奖励任务的知识可重用性方面优于基线方法。

Abstract: Efficient exploration in multi-agent reinforcement learning (MARL) is a
challenging problem when receiving only a team reward, especially in
environments with sparse rewards. A powerful method to mitigate this issue
involves crafting dense individual rewards to guide the agents toward efficient
exploration. However, individual rewards generally rely on manually engineered
shaping-reward functions that lack high-order intelligence, thus it behaves
ineffectively than humans regarding learning and generalization in complex
problems. To tackle these issues, we combine the above two paradigms and
propose a novel framework, LIGHT (Learning Individual Intrinsic reward via
Incorporating Generalized Human experTise), which can integrate human knowledge
into MARL algorithms in an end-to-end manner. LIGHT guides each agent to avoid
unnecessary exploration by considering both individual action distribution and
human expertise preference distribution. Then, LIGHT designs individual
intrinsic rewards for each agent based on actionable representational
transformation relevant to Q-learning so that the agents align their action
preferences with the human expertise while maximizing the joint action value.
Experimental results demonstrate the superiority of our method over
representative baselines regarding performance and better knowledge reusability
across different sparse-reward tasks on challenging scenarios.

</details>


### [150] [Innovator: Scientific Continued Pretraining with Fine-grained MoE Upcycling](https://arxiv.org/abs/2507.18671)
*Ning Liao,Xiaoxing Wang,Zehao Lin,Weiyang Guo,Feng Hong,Shixiang Song,Geng Yu,Zihua Zhao,Sitao Xie,Longxuan Wei,Xiangqi Jin,Xiaohan Qin,Jiale Ma,Kai Chen,Jiangchao Yao,Zhouhan Lin,Junchi Yan,Zhiyu Li,Feiyu Xiong,Yanfeng Wang,Linfeng Zhang*

Main category: cs.LG

TL;DR: Innovator通过升级LLM为MoE模型并采用独特的四阶段训练方法，解决了科学预训练中的灾难性遗忘问题，显著提升了科学任务表现，同时保留了通用能力。


<details>
  <summary>Details</summary>
Motivation: 直接使用科学数据对LLM进行继续预训练，通常会导致灾难性遗忘，即通用能力严重下降。本研究旨在解决这一问题，开发一个能够同时掌握科学和通用任务知识的模型，为实现科学通用智能奠定基础。

Method: Innovator模型通过一个包含四个阶段的升级训练范式，将预训练的LLM转化为细粒度的Mixtures-of-Experts（MoE）模型。该范式包括：1. 科学专家归纳，利用学科特定数据；2. 细粒度专家拆分，通过FFN维度分解实现；3. 面向科学的路由预热；4. 通才-科学家整合训练，使用混合数据集。这使得通用领域知识和不同科学学科的知识能够解耦，避免了不同领域知识间的负面影响。

Result: Innovator模型在30个科学任务上实现了25%的平均提升，胜率达到70%，同时在通用任务上保留了99%的性能。Innovator-Reason在解决复杂科学问题时，推理能力提升超过30%。

Conclusion: Innovator通过将预训练的LLM升级为细粒度的MoE模型，并采用四阶段训练范式，成功解决了在科学数据上继续预训练时发生的灾难性遗忘问题，从而在保留通用能力的同时提升了科学任务的表现。Innovator-Reason在推理能力方面也取得了显著进步。

Abstract: A large language model (LLM) with knowledge in both scientific and general
tasks is the foundation of science general intelligence. However, directly
continued pretraining an LLM using science data usually leads to catastrophic
forgetting, which indicates severe degradation in general ability. In this
report, we present Innovator, which solves this problem by upcycling a
pre-trained dense LLM into a fine-grained Mixtures-of-Experts model during
continued pretraining, where different experts are expected to learn science
knowledge in different disciplines, and a shared expert is utilized for general
tasks. Innovator introduces a four-stage upcycle training paradigm: (1)
Scientific Expert Induction on discipline-specific data, (2) Fine-grained
Expert Splitting via FFN dimension decomposition, (3) Science-Aware Routing
warmup, and (4) Generalist-Scientist Integration training on hybrid datasets.
Such a paradigm enables knowledge in the general domain, and different
scientific disciplines can be decoupled, avoiding the negative influence among
knowledge in different domains. With 53.3B total parameters and 13.3B
activated, Innovator extends Qwen2.5-7B using a shared general expert and 64
specialized scientific experts with 8 activated. Trained on 300B tokens with
tri-level quality-controlled data, Innovator achieves 25% average improvement
across 30 scientific tasks with a win rate as 70%, while retaining 99%
performance in general tasks. Furthermore, Innovator-Reason, which is
post-trained from Innovator for reasoning boosting, exhibits excellent
reasoning performance in solving complex scientific problems with improvements
over 30%.

</details>


### [151] [SILS: Strategic Influence on Liquidity Stability and Whale Detection in Concentrated-Liquidity DEXs](https://arxiv.org/abs/2507.19411)
*Ali RajabiNekoo,Laleh Rasoul,Amirfarhad Farhadi,Azadeh Zamanifar*

Main category: cs.LG

TL;DR: SILS框架通过ETWL和LSIS等高级指标，比传统方法更精确地识别DeFi中的高影响力流动性提供者，从而改善风险管理和市场透明度。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖于名义资本规模或表面活动等宏观指标来识别集中流动性做市商（CLMMs）中的有影响力流动性提供者（LPs），这往往导致不准确的风险分析。SILS框架旨在提供一种更精细的方法，将LPs视为影响市场稳定的动态系统性代理，从而实现更准确的风险评估。

Method: SILS框架利用链上事件日志和智能合约执行跟踪，计算指数时间加权流动性（ETWL）分布，并应用无监督异常检测。通过定义流动性稳定影响评分（LSIS）——一种衡量LP撤出时市场潜在降级的反事实指标——来量化LP的功能重要性。

Result: SILS框架能够准确识别传统方法可能忽略的高影响力LPs，并提供关键的保护性Oracle层和可操作的交易者信号，提高了DeFi生态系统的安全性。该框架还提高了流动性结构和相关风险的透明度，有效减少了传统模型中的误报并发现了关键的漏报。

Conclusion: SILS框架通过整合时间加权的流动性特征和反事实的流动性影响评分，能够更准确地识别高影响力流动性提供者（LPs），克服了传统方法在风险分析中的不足，并为DeFi生态系统提供了增强的风险管理能力和市场透明度。

Abstract: Traditional methods for identifying impactful liquidity providers (LPs) in
Concentrated Liquidity Market Makers (CLMMs) rely on broad measures, such as
nominal capital size or surface-level activity, which often lead to inaccurate
risk analysis. The SILS framework offers a significantly more detailed
approach, characterizing LPs not just as capital holders but as dynamic
systemic agents whose actions directly impact market stability. This represents
a fundamental paradigm shift from the static, volume-based analysis to a
dynamic, impact-focused understanding. This advanced approach uses on-chain
event logs and smart contract execution traces to compute Exponential
Time-Weighted Liquidity (ETWL) profiles and apply unsupervised anomaly
detection. Most importantly, it defines an LP's functional importance through
the Liquidity Stability Impact Score (LSIS), a counterfactual metric that
measures the potential degradation of the market if the LP withdraws. This
combined approach provides a more detailed and realistic characterization of an
LP's impact, moving beyond the binary and often misleading classifications used
by existing methods. This impact-focused and comprehensive approach enables
SILS to accurately identify high-impact LPs-including those missed by
traditional methods and supports essential applications like a protective
oracle layer and actionable trader signals, thereby significantly enhancing
DeFi ecosystem. The framework provides unprecedented transparency into the
underlying liquidity structure and associated risks, effectively reducing the
common false positives and uncovering critical false negatives found in
traditional models. Therefore, SILS provides an effective mechanism for
proactive risk management, transforming how DeFi protocols safeguard their
ecosystems against asymmetric liquidity behavior.

</details>


### [152] [Market Making Strategies with Reinforcement Learning](https://arxiv.org/abs/2507.18680)
*Óscar Fernández Vicente*

Main category: cs.LG

TL;DR: This thesis applies Reinforcement Learning (RL) to market making, developing adaptive strategies using techniques like MORL and a novel policy weighting algorithm (POW-dTS) to handle financial market challenges such as inventory risk and non-stationarity. The proposed methods significantly outperform traditional strategies.


<details>
  <summary>Details</summary>
Motivation: This research project focuses on applying Reinforcement Learning (RL) to market making in financial markets. Market makers face challenges from inventory risk, competition, and non-stationary market dynamics. The motivation is to explore how RL, particularly Deep Reinforcement Learning (DRL), can develop autonomous, adaptive, and profitable market making strategies.

Method: The study formulates the market making task as an RL problem, designing agents for single-agent and multi-agent settings. It addresses inventory management using reward engineering and Multi-Objective Reinforcement Learning (MORL). A novel policy weighting algorithm, POW-dTS (based on Discounted Thompson Sampling), is introduced to handle non-stationarity by dynamically selecting and combining pretrained policies.

Result: Experimental results demonstrate that the proposed RL-based approaches significantly outperform traditional and baseline algorithmic strategies across various performance metrics.

Conclusion: The proposed RL-based approaches significantly outperform traditional and baseline algorithmic strategies, showcasing the potential of RL to transform algorithmic trading in complex financial systems.

Abstract: This thesis presents the results of a comprehensive research project focused
on applying Reinforcement Learning (RL) to the problem of market making in
financial markets. Market makers (MMs) play a fundamental role in providing
liquidity, yet face significant challenges arising from inventory risk,
competition, and non-stationary market dynamics. This research explores how RL,
particularly Deep Reinforcement Learning (DRL), can be employed to develop
autonomous, adaptive, and profitable market making strategies.
  The study begins by formulating the MM task as a reinforcement learning
problem, designing agents capable of operating in both single-agent and
multi-agent settings within a simulated financial environment. It then
addresses the complex issue of inventory management using two complementary
approaches: reward engineering and Multi-Objective Reinforcement Learning
(MORL). While the former uses dynamic reward shaping to guide behavior, the
latter leverages Pareto front optimization to explicitly balance competing
objectives.
  To address the problem of non-stationarity, the research introduces POW-dTS,
a novel policy weighting algorithm based on Discounted Thompson Sampling. This
method allows agents to dynamically select and combine pretrained policies,
enabling continual adaptation to shifting market conditions.
  The experimental results demonstrate that the proposed RL-based approaches
significantly outperform traditional and baseline algorithmic strategies across
various performance metrics. Overall, this research thesis contributes new
methodologies and insights for the design of robust, efficient, and adaptive
market making agents, reinforcing the potential of RL to transform algorithmic
trading in complex financial systems.

</details>


### [153] [Scale-Consistent Learning for Partial Differential Equations](https://arxiv.org/abs/2507.18813)
*Zongyi Li,Samuel Lanthaler,Catherine Deng,Michael Chen,Yixuan Wang,Kamyar Azizzadenesheli,Anima Anandkumar*

Main category: cs.LG

TL;DR: 通过引入尺度一致性损失和尺度感知神经算子，我们提出的方法提高了机器学习模型在偏微分方程求解中的泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模型在解决偏微分方程时，泛化能力不足，无法处理训练数据范围之外的尺度或参数。例如，在纳维-斯托克斯方程的例子中，训练好的模型只能在预定义的域和固定的雷诺数下工作。

Method: 提出了一种基于尺度一致性属性的数据增强方案，并设计了一种尺度感知神经算子。该方法利用了偏微分方程的可重缩放性和解算子在子域上的尺度一致性，通过引入尺度一致性损失函数来优化模型。

Result: 所提出的尺度一致性方法和尺度感知神经算子在 Burgers 方程、Darcy 流、Helmholtz 方程和纳维-斯托克斯方程等多个问题上进行了实验。结果表明，在 $Re=1000$ 下训练的模型能够泛化到 $Re$ 从 250 到 10000 的范围，并且相比于基线模型，在所有数据集上的平均误差降低了 34%。

Conclusion: 所提出的尺度一致性方法能够显著提高神经算子在不同尺度下对偏微分方程的泛化能力，并能有效降低误差。

Abstract: Machine learning (ML) models have emerged as a promising approach for solving
partial differential equations (PDEs) in science and engineering. Previous ML
models typically cannot generalize outside the training data; for example, a
trained ML model for the Navier-Stokes equations only works for a fixed
Reynolds number ($Re$) on a pre-defined domain. To overcome these limitations,
we propose a data augmentation scheme based on scale-consistency properties of
PDEs and design a scale-informed neural operator that can model a wide range of
scales. Our formulation leverages the facts: (i) PDEs can be rescaled, or more
concretely, a given domain can be re-scaled to unit size, and the parameters
and the boundary conditions of the PDE can be appropriately adjusted to
represent the original solution, and (ii) the solution operators on a given
domain are consistent on the sub-domains. We leverage these facts to create a
scale-consistency loss that encourages matching the solutions evaluated on a
given domain and the solution obtained on its sub-domain from the rescaled PDE.
Since neural operators can fit to multiple scales and resolutions, they are the
natural choice for incorporating scale-consistency loss during training of
neural PDE solvers. We experiment with scale-consistency loss and the
scale-informed neural operator model on the Burgers' equation, Darcy Flow,
Helmholtz equation, and Navier-Stokes equations. With scale-consistency, the
model trained on $Re$ of 1000 can generalize to $Re$ ranging from 250 to 10000,
and reduces the error by 34% on average of all datasets compared to baselines.

</details>


### [154] [GENIAL: Generative Design Space Exploration via Network Inversion for Low Power Algorithmic Logic Units](https://arxiv.org/abs/2507.18989)
*Maxence Bouvier,Ryan Amaudruz,Felix Arnold,Renzo Andri,Lukas Cavigelli*

Main category: cs.LG

TL;DR: GENIAL是一个基于机器学习的框架，用于自动生成和优化算术单元（特别是乘法器）。它使用基于Transformer的代理模型来预测硬件指标，并通过反转模型来搜索优化的操作数编码，从而在AI工作负载中实现显著的功耗和面积节省。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能（AI）工作负载的激增，优化算术单元对于减少数字系统的占用空间变得越来越重要。传统的设计流程依赖于手动或基于启发式的方法，在探索庞大的设计空间方面能力有限。

Method: GENIAL框架的核心是一个基于Transformer的代理模型，该模型通过两个阶段进行训练：自监督预训练和监督微调，以从抽象的设计表示中预测功率和面积等关键硬件指标。通过反转代理模型，GENIAL能够有效地搜索新的操作数编码，以直接最小化算术单元的功耗。

Result: GENIAL在样本效率和收敛速度方面优于其他方法，能够更准确地收敛到优化的设计。它能够自动发现新的编码，在AI工作负载的乘法器中实现高达18%的开关活动节省，并成功应用于有限状态机。

Conclusion: GENIAL通过自动发现新的操作数编码，在AI工作负载的乘法器中实现了高达18%的开关活动节省，与传统的二的补码相比。该方法在有限状态机上也显示出显著的改进，证明了其在多种逻辑功能上的适用性，是自动化面向质量结果（QoR）的组合电路生成的重要一步。

Abstract: As AI workloads proliferate, optimizing arithmetic units is becoming
increasingly important to reduce the footprint of digital systems. Conventional
design flows, which often rely on manual or heuristics-based optimization, are
limited in their ability to thoroughly explore the vast design space. In this
paper, we introduce GENIAL, a machine learning-based framework for the
automatic generation and optimization of arithmetic units, more specifically
multipliers.
  At the core of GENIAL is a Transformer-based surrogate model trained in two
stages, involving self-supervised pretraining followed by supervised
finetuning, to robustly forecast key hardware metrics such as power and area
from abstracted design representations. By inverting the surrogate model,
GENIAL efficiently searches for new operand encodings that directly minimize
power consumption in arithmetic units for specific input data distributions.
Extensive experiments on large datasets demonstrate that GENIAL is consistently
more sample efficient than other methods, and converges faster towards
optimized designs. This enables to deploy a high-effort logic synthesis
optimization flow in the loop, improving the accuracy of the surrogate model.
Notably, GENIAL automatically discovers encodings that achieve up to 18%
switching activity savings within multipliers on representative AI workloads
compared with the conventional two's complement. We also demonstrate the
versatility of our approach by achieving significant improvements on Finite
State Machines, highlighting GENIAL's applicability for a wide spectrum of
logic functions. Together, these advances mark a significant step toward
automated Quality-of-Results-optimized combinational circuit generation for
digital systems.

</details>


### [155] [A diffusion-based generative model for financial time series via geometric Brownian motion](https://arxiv.org/abs/2507.19003)
*Gihun Kim,Sun-Yong Choi,Yeoneung Kim*

Main category: cs.LG

TL;DR: 本研究提出了一种新颖的金融时间序列扩散生成框架，该框架通过将几何布朗运动（GBM）纳入前向加噪过程，并模拟异方差性，能够比现有模型更真实地重现金融市场的关键特征。


<details>
  <summary>Details</summary>
Motivation: 提出一种新颖的、基于扩散的金融时间序列生成框架，将几何布朗运动（GBM）——Black-Scholes理论的基础——纳入前向加噪过程。与将价格轨迹视为通用数值序列的标准分数模型不同，我们的方法在每个时间步将噪声成比例地注入资产价格，反映了金融时间序列中观察到的异方差性。

Method: 采用基于Transformer的架构，通过去噪分数匹配来训练反向时间生成过程，该架构改编自条件分数匹配扩散插补（CSDI）框架。

Result: 通过精确平衡漂移项和扩散项，我们证明了所得的对数价格过程可以简化为方差爆炸的随机微分方程，这与分数生成模型中的表述一致。

Conclusion: 该模型在历史股票数据上的实证评估表明，与传统的扩散模型相比，它能更真实地重现关键的风格化事实，如重尾收益分布、波动率聚集和杠杆效应。

Abstract: We propose a novel diffusion-based generative framework for financial time
series that incorporates geometric Brownian motion (GBM), the foundation of the
Black--Scholes theory, into the forward noising process. Unlike standard
score-based models that treat price trajectories as generic numerical
sequences, our method injects noise proportionally to asset prices at each time
step, reflecting the heteroskedasticity observed in financial time series. By
accurately balancing the drift and diffusion terms, we show that the resulting
log-price process reduces to a variance-exploding stochastic differential
equation, aligning with the formulation in score-based generative models. The
reverse-time generative process is trained via denoising score matching using a
Transformer-based architecture adapted from the Conditional Score-based
Diffusion Imputation (CSDI) framework. Empirical evaluations on historical
stock data demonstrate that our model reproduces key stylized facts
heavy-tailed return distributions, volatility clustering, and the leverage
effect more realistically than conventional diffusion models.

</details>


### [156] [The Right to be Forgotten in Pruning: Unveil Machine Unlearning on Sparse Models](https://arxiv.org/abs/2507.18725)
*Yang Xiao,Gen Li,Jie Ji,Ruimeng Ye,Xiaolong Ma,Bo Hui*

Main category: cs.LG

TL;DR: 本研究提出了“非剪枝”概念和算法，解决了稀疏模型中的数据删除和剪枝问题，并提出了新的评估指标。


<details>
  <summary>Details</summary>
Motivation: 旨在解决现有模型学习算法在稀疏模型上未充分研究删除数据对模型剪枝拓扑的影响的问题，并满足被遗忘权。

Method: 提出了一种近似保留数据驱动的剪枝拓扑的非剪枝算法，并设计了新的性能指标来评估非剪枝的成功率。

Result: 验证了该非剪枝算法在各种剪枝方法和模型学习算法上的有效性，并发现MIA准确性在评估模型是否遗忘数据方面并不可靠。

Conclusion: 本研究首次提出了“非剪枝”的概念，旨在消除已删除数据对稀疏模型剪枝拓扑的影响。我们提出了一种近似保留数据驱动的剪枝拓扑的非剪枝算法，该算法理论上具有误差上界，并且可以与现有的任何学习算法集成，适用于结构化和非结构化稀疏模型。此外，我们还发现用于评估模型是否遗忘已删除数据的成员推理攻击（MIA）准确性并不可靠，因此我们设计了新的性能指标来评估非剪枝的成功率。最后，通过大量实验验证了该方法的有效性。

Abstract: Machine unlearning aims to efficiently eliminate the memory about deleted
data from trained models and address the right to be forgotten. Despite the
success of existing unlearning algorithms, unlearning in sparse models has not
yet been well studied. In this paper, we empirically find that the deleted data
has an impact on the pruned topology in a sparse model. Motivated by the
observation and the right to be forgotten, we define a new terminology
``un-pruning" to eliminate the impact of deleted data on model pruning. Then we
propose an un-pruning algorithm to approximate the pruned topology driven by
retained data. We remark that any existing unlearning algorithm can be
integrated with the proposed un-pruning workflow and the error of un-pruning is
upper-bounded in theory. Also, our un-pruning algorithm can be applied to both
structured sparse models and unstructured sparse models. In the experiment, we
further find that Membership Inference Attack (MIA) accuracy is unreliable for
assessing whether a model has forgotten deleted data, as a small change in the
amount of deleted data can produce arbitrary MIA results. Accordingly, we
devise new performance metrics for sparse models to evaluate the success of
un-pruning. Lastly, we conduct extensive experiments to verify the efficacy of
un-pruning with various pruning methods and unlearning algorithms. Our code is
released at https://anonymous.4open.science/r/UnlearningSparseModels-FBC5/.

</details>


### [157] [Exploitation Over Exploration: Unmasking the Bias in Linear Bandit Recommender Offline Evaluation](https://arxiv.org/abs/2507.18756)
*Pedro R. Pires,Gregorio F. Azevedo,Pietro L. Campos,Rafael T. Sereicikas,Tiago A. Almeida*

Main category: cs.LG

TL;DR: 在评估推荐系统中的多臂老虎机（MAB）算法时，不包含探索的贪婪方法在离线评估中往往表现更好，这表明当前的评估方法存在缺陷，需要改进。


<details>
  <summary>Details</summary>
Motivation: 现有研究认为多臂老虎机（MAB）算法在推荐系统中对于增量学习至关重要，但其离线评估方法在评估探索行为方面存在局限性。本研究旨在深入探究 MAB 算法的离线评估问题，并提出更有效的评估方法。

Method: 通过对多个数据集进行广泛的离线实证比较，研究了多种线性多臂老虎机 (MAB) 算法，并进行了超参数优化以评估探索策略。

Result: 在超过 90% 的数据集上，没有采用任何探索策略的贪婪线性模型表现出了与采用探索策略的模型相当甚至更优的性能。超参数优化结果也一致表明，最小化探索的参数配置具有更好的性能，这表明在这些评估环境中，纯粹的探索策略是主要的。

Conclusion: 本研究揭示了当前用于评估 Bandit 算法的离线评估协议存在重大缺陷，尤其是在评估探索行为方面。纯粹的探索策略在这些评估环境中占据主导地位，这表明需要开发更有效的评估方法来指导推荐系统中交互式学习的未来研究。

Abstract: Multi-Armed Bandit (MAB) algorithms are widely used in recommender systems
that require continuous, incremental learning. A core aspect of MABs is the
exploration-exploitation trade-off: choosing between exploiting items likely to
be enjoyed and exploring new ones to gather information. In contextual linear
bandits, this trade-off is particularly central, as many variants share the
same linear regression backbone and differ primarily in their exploration
strategies. Despite its prevalent use, offline evaluation of MABs is
increasingly recognized for its limitations in reliably assessing exploration
behavior. This study conducts an extensive offline empirical comparison of
several linear MABs. Strikingly, across over 90% of various datasets, a greedy
linear model, with no type of exploration, consistently achieves top-tier
performance, often outperforming or matching its exploratory counterparts. This
observation is further corroborated by hyperparameter optimization, which
consistently favors configurations that minimize exploration, suggesting that
pure exploitation is the dominant strategy within these evaluation settings.
Our results expose significant inadequacies in offline evaluation protocols for
bandits, particularly concerning their capacity to reflect true exploratory
efficacy. Consequently, this research underscores the urgent necessity for
developing more robust assessment methodologies, guiding future investigations
into alternative evaluation frameworks for interactive learning in recommender
systems.

</details>


### [158] [CLEAR: Unlearning Spurious Style-Content Associations with Contrastive LEarning with Anti-contrastive Regularization](https://arxiv.org/abs/2507.18794)
*Minghui Sun,Benjamin A. Goldstein,Matthew M. Engelhard*

Main category: cs.LG

TL;DR: CLEAR-VAE framework separates essential features from superficial ones using anti-contrastive regularization (Pair-Switching penalty) to improve model robustness and fairness against shifts in superficial attributes, enabling style manipulation and better generalization.


<details>
  <summary>Details</summary>
Motivation: The motivation is to learn representations that are unaffected by superficial characteristics (like race or sex in healthcare) to ensure prediction performance remains robust and equitable across different demographics, especially when these characteristics shift at test time. This is crucial for generalizability and fairness in applications.

Method: The paper proposes Contrastive LEarning with Anti-contrastive Regularization (CLEAR), a framework designed to separate essential (task-relevant) characteristics from superficial (task-irrelevant) characteristics during training. A key component is the Pair-Switching (PS) penalty, which minimizes the Mutual Information between style attributes and content labels. CLEAR is implemented within the latent space of a Variational Auto-Encoder (VAE), resulting in CLEAR-VAE.

Result: CLEAR-VAE demonstrates the ability to swap and interpolate content and style between any pair of samples. It also shows improved downstream classification performance when encountering new combinations of content and style, indicating its effectiveness in handling variations in superficial attributes.

Conclusion: CLEAR-VAE allows for style swapping and interpolation between samples, and improves downstream classification performance when faced with unseen content and style combinations. The framework effectively separates task-relevant content from task-irrelevant style features.

Abstract: Learning representations unaffected by superficial characteristics is
important to ensure that shifts in these characteristics at test time do not
compromise downstream prediction performance. For instance, in healthcare
applications, we might like to learn features that contain information about
pathology yet are unaffected by race, sex, and other sources of physiologic
variability, thereby ensuring predictions are equitable and generalizable
across all demographics. Here we propose Contrastive LEarning with
Anti-contrastive Regularization (CLEAR), an intuitive and easy-to-implement
framework that effectively separates essential (i.e., task-relevant)
characteristics from superficial (i.e., task-irrelevant) characteristics during
training, leading to better performance when superficial characteristics shift
at test time. We begin by supposing that data representations can be
semantically separated into task-relevant content features, which contain
information relevant to downstream tasks, and task-irrelevant style features,
which encompass superficial attributes that are irrelevant to these tasks, yet
may degrade performance due to associations with content present in training
data that do not generalize. We then prove that our anti-contrastive penalty,
which we call Pair-Switching (PS), minimizes the Mutual Information between the
style attributes and content labels. Finally, we instantiate CLEAR in the
latent space of a Variational Auto-Encoder (VAE), then perform experiments to
quantitatively and qualitatively evaluate the resulting CLEAR-VAE over several
image datasets. Our results show that CLEAR-VAE allows us to: (a) swap and
interpolate content and style between any pair of samples, and (b) improve
downstream classification performance in the presence of previously unseen
combinations of content and style. Our code will be made publicly available.

</details>


### [159] [Ralts: Robust Aggregation for Enhancing Graph Neural Network Resilience on Bit-flip Errors](https://arxiv.org/abs/2507.18804)
*Wencheng Zou,Nan Wu*

Main category: cs.LG

TL;DR: 本文分析了 GNN 在比特翻转错误下的鲁棒性，并提出了 Ralts 解决方案，通过图相似性指标过滤异常值和恢复受损图拓扑来增强 GNN 的韧性，从而提高预测准确率并保持高效的执行效率。


<details>
  <summary>Details</summary>
Motivation: 随着硬件系统朝着先进技术节点发展，它们越来越容易受到瞬态故障的影响，这可能导致比特翻转和静默数据损坏。本文旨在分析 GNN 针对比特翻转错误的鲁棒性，并提出一种名为 Ralts 的解决方案来增强 GNN 的韧性。

Method: Ralts 利用各种图相似性指标来过滤异常值和恢复受损的图拓扑，并将这些保护技术直接整合到聚合函数中，以支持任何消息传递 GNN。

Result: Ralts 在出现错误的模型权重或节点嵌入时，平均可将预测准确率提高至少 20%；在邻接矩阵中出现错误时，可提高至少 10%。

Conclusion: Ralts 能有效提高 GNN 在各种 GNN 模型、图数据集、错误模式以及密集和稀疏架构上的鲁棒性。在出现错误的模型权重或节点嵌入时，鲁棒聚合函数平均可将预测准确率提高至少 20%；在邻接矩阵中出现错误时，可提高至少 10%。Ralts 的执行效率与 PyTorch Geometric 中的内置聚合函数相当。

Abstract: Graph neural networks (GNNs) have been widely applied in safety-critical
applications, such as financial and medical networks, in which compromised
predictions may cause catastrophic consequences. While existing research on GNN
robustness has primarily focused on software-level threats, hardware-induced
faults and errors remain largely underexplored. As hardware systems progress
toward advanced technology nodes to meet high-performance and energy efficiency
demands, they become increasingly susceptible to transient faults, which can
cause bit flips and silent data corruption, a prominent issue observed by major
technology companies (e.g., Meta and Google). In response, we first present a
comprehensive analysis of GNN robustness against bit-flip errors, aiming to
reveal system-level optimization opportunities for future reliable and
efficient GNN systems. Second, we propose Ralts, a generalizable and
lightweight solution to bolster GNN resilience to bit-flip errors.
Specifically, Ralts exploits various graph similarity metrics to filter out
outliers and recover compromised graph topology, and incorporates these
protective techniques directly into aggregation functions to support any
message-passing GNNs. Evaluation results demonstrate that Ralts effectively
enhances GNN robustness across a range of GNN models, graph datasets, error
patterns, and both dense and sparse architectures. On average, under a BER of
$3\times10^{-5}$, these robust aggregation functions improve prediction
accuracy by at least 20\% when errors present in model weights or node
embeddings, and by at least 10\% when errors occur in adjacency matrices. Ralts
is also optimized to deliver execution efficiency comparable to built-in
aggregation functions in PyTorch Geometric.

</details>


### [160] [Fishers for Free? Approximating the Fisher Information Matrix by Recycling the Squared Gradient Accumulator](https://arxiv.org/abs/2507.18807)
*YuXin Li,Felix Dangel,Derek Tam,Colin Raffel*

Main category: cs.LG

TL;DR: “Squisher”：一种免费获得Fisher对角线近似值的方法，性能与Fisher对角线相当。


<details>
  <summary>Details</summary>
Motivation: 由于通常计算Fisher对角线需要大量计算成本，因此探索是否可以免费获得其近似值。

Method: 通过回收训练过程中已计算的平方梯度累加器来获得Fisher对角线的近似值，并将其命名为“Squisher”。

Result: 在五个应用场景的实验中，证明了“Squisher”的性能与Fisher对角线相当，同时优于基线方法。

Conclusion: “Squisher”方法可以免费获得Fisher对角线，并且性能与Fisher对角线相当，优于基线方法。

Abstract: The diagonal of a model's Fisher Information Matrix (the "Fisher diagonal")
has frequently been used as a way to measure parameter sensitivity. Typically,
the Fisher diagonal is estimated via squared sampled gradients of the model's
likelihood with respect to its parameters, averaged over a few hundred or
thousand examples -- a process which incurs nontrivial computational costs. At
the same time, adaptive gradient methods like the ubiquitous Adam optimizer
compute a moving average of the squared gradient over the course of training.
This paper therefore explores whether an approximation of the Fisher diagonal
can be obtained "for free" by recycling the squared gradient accumulator that
has already been computed over the course of training. Through a comprehensive
set of experiments covering five applications of the Fisher diagonal, we
demonstrate that the "Squisher" (SQUared gradient accumulator as an
approximation of the FISHER) consistently performs similarly to the Fisher
diagonal while outperforming baseline methods. Additionally, we clarify the
exact differences between the Squisher and the Fisher diagonal and provide
empirical quantification of their respective impact.

</details>


### [161] [Test-time Offline Reinforcement Learning on Goal-related Experience](https://arxiv.org/abs/2507.18809)
*Marco Bagatella,Mert Albaba,Jonas Hübotter,Georg Martius,Andreas Krause*

Main category: cs.LG

TL;DR: Foundation models can be improved by test-time training. We apply this to goal-conditioned reinforcement learning and find that test-time training on relevant data improves policies significantly at minimal compute cost. Our method, GC-TTT, adapts the policy to the current trajectory during rollout and achieves gains over scaling model size.


<details>
  <summary>Details</summary>
Motivation: There are strong parallels between the widespread framework of foundation models and offline goal-conditioned reinforcement learning algorithms. Foundation models can be substantially improved through test-time training, specializing the model to the current goal. We find similarly that test-time offline reinforcement learning on experience related to the test goal can lead to substantially better policies at minimal compute costs.

Method: We propose a novel self-supervised data selection criterion, which selects transitions from an offline dataset according to their relevance to the current state and quality with respect to the evaluation goal. Our goal-conditioned test-time training (GC-TTT) algorithm applies this routine in a receding-horizon fashion during evaluation, adapting the policy to the current trajectory as it is being rolled out.

Result: We demonstrate across a wide range of high-dimensional loco-navigation and manipulation tasks that fine-tuning a policy on the selected data for a few gradient steps leads to significant performance gains over standard offline pre-training.

Conclusion: We show that test-time offline reinforcement learning on experience related to the test goal can lead to substantially better policies at minimal compute costs. Our GC-TTT algorithm applies this routine in a receding-horizon fashion during evaluation, adapting the policy to the current trajectory as it is being rolled out. GC-TTT induces performance gains that are not achievable by scaling model size.

Abstract: Foundation models compress a large amount of information in a single, large
neural network, which can then be queried for individual tasks. There are
strong parallels between this widespread framework and offline goal-conditioned
reinforcement learning algorithms: a universal value function is trained on a
large number of goals, and the policy is evaluated on a single goal in each
test episode. Extensive research in foundation models has shown that
performance can be substantially improved through test-time training,
specializing the model to the current goal. We find similarly that test-time
offline reinforcement learning on experience related to the test goal can lead
to substantially better policies at minimal compute costs. We propose a novel
self-supervised data selection criterion, which selects transitions from an
offline dataset according to their relevance to the current state and quality
with respect to the evaluation goal. We demonstrate across a wide range of
high-dimensional loco-navigation and manipulation tasks that fine-tuning a
policy on the selected data for a few gradient steps leads to significant
performance gains over standard offline pre-training. Our goal-conditioned
test-time training (GC-TTT) algorithm applies this routine in a
receding-horizon fashion during evaluation, adapting the policy to the current
trajectory as it is being rolled out. Finally, we study compute allocation at
inference, demonstrating that, at comparable costs, GC-TTT induces performance
gains that are not achievable by scaling model size.

</details>


### [162] [Even Faster Simulations with Flow Matching: A Study of Zero Degree Calorimeter Responses](https://arxiv.org/abs/2507.18811)
*Maksymilian Wojnar*

Main category: cs.LG

TL;DR: 利用流匹配（FM）技术为ALICE实验的零度量热计（ZDC）开发了更快的模拟模型，显著降低了计算成本，同时保持了高保真度，并在ZN和ZP探测器模拟中均取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 为了满足高能物理（HEP）研究日益增长的计算需求，并加速模拟过程，利用先进的生成模型（如流匹配FM）来降低计算成本并提高样本生成保真度。

Method: 利用流匹配（FM）技术和一种有效的训练策略来开发用于ALICE实验零度量热计（ZDC）的快速模拟代理模型，并探索了潜在FM模型以进一步提高推理速度。

Result: 所提出的FM模型在零中子（ZN）探测器模拟中达到了1.27的Wasserstein距离，推理时间为0.46毫秒/样本，优于现有最佳方法的1.20 Wasserstien距离和109毫秒推理时间。在零质子（ZP）探测器模拟中，该模型达到了1.30的Wasserstein距离，优于现有最佳方法的2.08。潜在FM模型将采样时间进一步缩短至0.026毫秒/样本，准确性仅有少量损失。

Conclusion: 该研究利用流匹配（FM）技术开发了高能物理（HEP）实验中零度量热计（ZDC）的快速模拟代理模型，实现了与现有方法相比在模拟保真度和计算成本上的显著改进。

Abstract: Recent advances in generative neural networks, particularly flow matching
(FM), have enabled the generation of high-fidelity samples while significantly
reducing computational costs. A promising application of these models is
accelerating simulations in high-energy physics (HEP), helping research
institutions meet their increasing computational demands. In this work, we
leverage FM to develop surrogate models for fast simulations of zero degree
calorimeters in the ALICE experiment. We present an effective training strategy
that enables the training of fast generative models with an exceptionally low
number of parameters. This approach achieves state-of-the-art simulation
fidelity for both neutron (ZN) and proton (ZP) detectors, while offering
substantial reductions in computational costs compared to existing methods. Our
FM model achieves a Wasserstein distance of 1.27 for the ZN simulation with an
inference time of 0.46 ms per sample, compared to the current best of 1.20 with
an inference time of approximately 109 ms. The latent FM model further improves
the inference speed, reducing the sampling time to 0.026 ms per sample, with a
minimal trade-off in accuracy. Similarly, our approach achieves a Wasserstein
distance of 1.30 for the ZP simulation, outperforming the current best of 2.08.
The source code is available at https://github.com/m-wojnar/faster_zdc.

</details>


### [163] [Explainable AI guided unsupervised fault diagnostics for high-voltage circuit breakers](https://arxiv.org/abs/2507.19168)
*Chi-Ching Hsu,Gaëtan Frusque,Florent Forest,Felipe Macedo,Christian M. Franck,Olga Fink*

Main category: cs.LG

TL;DR: 研究提出了一种无需故障标签的无监督高压断路器故障检测和诊断方法，结合了振动/声学信号和XAI技术，提高了监测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的商业高压断路器（CB）状态监测系统依赖于气体压力等物理参数，但这些参数只能覆盖一小部分故障机制，且通常需要在断路器与电网断开连接时才能进行监测。为了实现断路器在线状态监测，需要利用振动或声学信号等非侵入式测量技术。然而，目前的研究多采用有监督方法，在实际应用中由于无法获得故障标签而难以实施。因此，需要一种无需故障标签的无监督方法。

Method: 研究提出了一种新的无监督框架，利用振动和声学信号来检测高压断路器的故障。该框架仅需健康数据进行训练，即可检测故障并对不同故障进行聚类。此外，研究还应用了可解释人工智能（XAI）技术，在无需地面真实故障标签的情况下，为领域专家提供有关老化或故障部件的潜在指示，从而实现故障诊断。

Result: 该研究提出的无监督框架能够成功检测高压断路器的故障，并利用XAI技术进行故障诊断，而无需预先标记的故障数据。研究结果基于对高压断路器在健康和人工故障条件下的实验数据验证，证明了该框架的有效性。

Conclusion: 该研究提出了一种基于振动和声学信号的无监督断层检测和分割框架，用于高压断路器（CB）。该框架能够检测与健康状态的偏差，并使用可解释人工智能（XAI）进行故障诊断，而无需预先标记的故障数据。研究结果在实验数据上得到了验证，有望提高CB系统的可靠性。

Abstract: Commercial high-voltage circuit breaker (CB) condition monitoring systems
rely on directly observable physical parameters such as gas filling pressure
with pre-defined thresholds. While these parameters are crucial, they only
cover a small subset of malfunctioning mechanisms and usually can be monitored
only if the CB is disconnected from the grid. To facilitate online condition
monitoring while CBs remain connected, non-intrusive measurement techniques
such as vibration or acoustic signals are necessary. Currently, CB condition
monitoring studies using these signals typically utilize supervised methods for
fault diagnostics, where ground-truth fault types are known due to artificially
introduced faults in laboratory settings. This supervised approach is however
not feasible in real-world applications, where fault labels are unavailable. In
this work, we propose a novel unsupervised fault detection and segmentation
framework for CBs based on vibration and acoustic signals. This framework can
detect deviations from the healthy state. The explainable artificial
intelligence (XAI) approach is applied to the detected faults for fault
diagnostics. The specific contributions are: (1) we propose an integrated
unsupervised fault detection and segmentation framework that is capable of
detecting faults and clustering different faults with only healthy data
required during training (2) we provide an unsupervised explainability-guided
fault diagnostics approach using XAI to offer domain experts potential
indications of the aged or faulty components, achieving fault diagnostics
without the prerequisite of ground-truth fault labels. These contributions are
validated using an experimental dataset from a high-voltage CB under healthy
and artificially introduced fault conditions, contributing to more reliable CB
system operation.

</details>


### [164] [Weak-to-Strong Generalization with Failure Trajectories: A Tree-based Approach to Elicit Optimal Policy in Strong Models](https://arxiv.org/abs/2507.18858)
*Ruimeng Ye,Zihan Wang,Xiao Yang,Zinan Ling,Manling Li,Bo Hui*

Main category: cs.LG

TL;DR: 本研究将弱到强泛化（W2SG）方法应用于复杂的交互式决策环境，提出了一种结合轨迹树和蒙特卡洛树搜索（MCTS）的方法，该方法通过学习成功和失败的经验来优化强模型，并在实验中取得了显著的改进。


<details>
  <summary>Details</summary>
Motivation: 将W2SG范式扩展到复杂的交互式决策环境，旨在利用弱模型的监督来激发强模型的全部能力。

Method: 研究提出了一种新的弱到强泛化（W2SG）方法，通过对由弱模型生成的中间动作轨迹进行微调来优化强模型。该方法通过构建“轨迹树”来组织弱模型的动作轨迹，并结合蒙特卡洛树搜索（MCTS）来优化强模型。此外，该方法不仅学习成功经验，还学习失败经验，以提高泛化能力。

Result: 在推理和决策能力方面实现了实质性的改进，并在各种任务领域中证明了该框架的可扩展性和鲁棒性。

Conclusion: 该研究提出的框架在推理和决策能力方面实现了显著的改进，并在各种任务领域中展示了良好的可扩展性和鲁棒性。

Abstract: Weak-to-Strong generalization (W2SG) is a new trend to elicit the full
capabilities of a strong model with supervision from a weak model. While
existing W2SG studies focus on simple tasks like binary classification, we
extend this paradigm to complex interactive decision-making environments.
Specifically, we fine-tune a strong model with trajectories of intermediate
actions generated by a weak model. Motivated by the human learning process, we
propose to generalize not only success knowledge but also failure experience so
that the strong model can learn from failed trajectories accumulated by weak
models. To effectively and efficiently elicit the potential of strong agents,
we further construct ``trajectory trees," a hierarchical representation that
organizes weak model-generated action trajectories, coupled with Monte Carlo
Tree Search (MCTS) to optimize the strong model. Through theoretical analysis,
we provide formal guarantees for the effectiveness of our method in improving
W2SG performance. Our empirical evaluations demonstrate substantial
improvements in reasoning and decision-making capabilities across diverse task
domains, validating the scalability and robustness of our proposed framework.
Our code is available at: https://github.com/yeruimeng/TraTree

</details>


### [165] [Early Mortality Prediction in ICU Patients with Hypertensive Kidney Disease Using Interpretable Machine Learning](https://arxiv.org/abs/2507.18866)
*Yong Si,Junyi Fan,Li Sun,Shuheng Chen,Minoo Ahmadi,Elham Pishgar,Kamiar Alaei,Greg Placencia,Maryam Pishgar*

Main category: cs.LG

TL;DR: 这项研究开发了一个名为 CatBoost 的机器学习模型，可以根据 ICU 患者的早期临床数据预测 30 天内死亡的风险。该模型在预测死亡率方面表现出色，并且其预测结果具有可解释性，有助于医生做出更明智的临床决策。


<details>
  <summary>Details</summary>
Motivation: 高血压肾脏疾病（HKD）患者在重症监护室（ICU）面临高短期死亡率，但缺乏针对性的风险预测工具。早期识别高风险个体对于临床决策至关重要。

Method: 我们开发了一个机器学习框架，利用 MIMIC-IV v2.2 数据库中的早期临床数据来预测高血压肾脏疾病（HKD）ICU 患者的 30 天院内死亡率。我们根据严格的标准筛选了 1,366 名成人队列，排除了恶性肿瘤病例。通过随机森林重要性评分和互信息过滤选择了 18 个临床特征，包括生命体征、实验室检查、合并症和治疗。通过分层五折交叉验证训练并比较了多个模型；其中 CatBoost 表现最佳。

Result: CatBoost 在独立测试集上达到了 0.88 的 AUROC，敏感性为 0.811，特异性为 0.798。SHAP 值和累积局部效应（ALE）图显示，该模型依赖于有意义的预测因子，如意识改变、血管活性药物使用和凝血状态。此外，还集成了 DREAM 算法来估计患者特定的后验风险分布，使临床医生能够评估预测的死亡率及其不确定性。

Conclusion: 本研究提出了一个可解释的机器学习流程，用于对高血压肾脏疾病（HKD）的重症监护（ICU）患者进行早期、实时的风险评估。通过结合高预测性能和不确定性量化，我们的模型支持了个性化分诊和透明的临床决策。该方法有望在临床上推广，并值得在更广泛的重症监护人群中进行外部验证。

Abstract: Background: Hypertensive kidney disease (HKD) patients in intensive care
units (ICUs) face high short-term mortality, but tailored risk prediction tools
are lacking. Early identification of high-risk individuals is crucial for
clinical decision-making. Methods: We developed a machine learning framework to
predict 30-day in-hospital mortality among ICU patients with HKD using early
clinical data from the MIMIC-IV v2.2 database. A cohort of 1,366 adults was
curated with strict criteria, excluding malignancy cases. Eighteen clinical
features-including vital signs, labs, comorbidities, and therapies-were
selected via random forest importance and mutual information filtering. Several
models were trained and compared with stratified five-fold cross-validation;
CatBoost demonstrated the best performance. Results: CatBoost achieved an AUROC
of 0.88 on the independent test set, with sensitivity of 0.811 and specificity
of 0.798. SHAP values and Accumulated Local Effects (ALE) plots showed the
model relied on meaningful predictors such as altered consciousness,
vasopressor use, and coagulation status. Additionally, the DREAM algorithm was
integrated to estimate patient-specific posterior risk distributions, allowing
clinicians to assess both predicted mortality and its uncertainty. Conclusions:
We present an interpretable machine learning pipeline for early, real-time risk
assessment in ICU patients with HKD. By combining high predictive performance
with uncertainty quantification, our model supports individualized triage and
transparent clinical decisions. This approach shows promise for clinical
deployment and merits external validation in broader critical care populations.

</details>


### [166] [Geometric Multi-color Message Passing Graph Neural Networks for Blood-brain Barrier Permeability Prediction](https://arxiv.org/abs/2507.18926)
*Trung Nguyen,Md Masud Rana,Farjana Tasnim Mukta,Chang-Guo Zhan,Duc Duy Nguyen*

Main category: cs.LG

TL;DR: GMC-MPNN，一种新的图神经网络，通过整合几何信息提高了血脑屏障通透性预测的准确性，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 准确预测血脑屏障通透性（BBBP）对于中枢神经系统（CNS）药物开发至关重要。然而，现有的图神经网络（GNNs）虽然在分子性质预测方面取得了进展，但它们通常依赖于分子拓扑而忽略了对于模拟运输机制至关重要的三维几何信息。

Method: 提出了一种名为 GMC-MPNN 的新型框架，它通过显式地整合原子级别的几何特征和长程相互作用来增强标准的图消息传递神经网络。

Result: 在三个基准数据集上，GMC-MPNN 在分类和回归任务上都持续优于现有的最先进模型，在将化合物分类为可渗透/不可渗透（AUC-ROC 为 0.9704 和 0.9685）以及回归连续通透性值（RMSE 为 0.4609，皮尔逊相关系数为 0.7759）方面取得了卓越的性能。消融研究进一步量化了特定原子对相互作用的影响，表明模型的预测能力源于其从常见和罕见但具有化学意义的功能基序中学习的能力。

Conclusion: GMC-MPNN 通过整合空间几何到图表示中，为药物发现管道设定了新的性能基准，并提供了一个更准确、更具泛化能力的工具。

Abstract: Accurate prediction of blood-brain barrier permeability (BBBP) is essential
for central nervous system (CNS) drug development. While graph neural networks
(GNNs) have advanced molecular property prediction, they often rely on
molecular topology and neglect the three-dimensional geometric information
crucial for modeling transport mechanisms. This paper introduces the geometric
multi-color message-passing graph neural network (GMC-MPNN), a novel framework
that enhances standard message-passing architectures by explicitly
incorporating atomic-level geometric features and long-range interactions. Our
model constructs weighted colored subgraphs based on atom types to capture the
spatial relationships and chemical context that govern BBB permeability. We
evaluated GMC-MPNN on three benchmark datasets for both classification and
regression tasks, using rigorous scaffold-based splitting to ensure a robust
assessment of generalization. The results demonstrate that GMC-MPNN
consistently outperforms existing state-of-the-art models, achieving superior
performance in both classifying compounds as permeable/non-permeable (AUC-ROC
of 0.9704 and 0.9685) and in regressing continuous permeability values (RMSE of
0.4609, Pearson correlation of 0.7759). An ablation study further quantified
the impact of specific atom-pair interactions, revealing that the model's
predictive power derives from its ability to learn from both common and rare,
but chemically significant, functional motifs. By integrating spatial geometry
into the graph representation, GMC-MPNN sets a new performance benchmark and
offers a more accurate and generalizable tool for drug discovery pipelines.

</details>


### [167] [Secure Best Arm Identification in the Presence of a Copycat](https://arxiv.org/abs/2507.18975)
*Asaf Cohen,Onur Günlü*

Main category: cs.LG

TL;DR: 本文提出了一种名为“编码手臂”的新算法，用于在保护隐私的同时识别最佳老虎机手臂，其效率比现有算法高。


<details>
  <summary>Details</summary>
Motivation: 在最佳手臂识别问题中，现有的最优算法会暴露最佳手臂的信息，而安全算法的效率却很低。本文旨在解决这一矛盾，提出一种兼顾安全性和效率的算法。

Method: 该算法采用“编码手臂”的方法，通过巧妙地设计手臂的拉动策略，在保证安全性的前提下，提高了识别最佳手臂的效率。

Result: 所提出的安全算法实现了$m 	ilde{	ilde{O}}(T/d^{1/2})$ 的最优指数，远优于朴素安全算法的$m 	ilde{	ilde{O}}(T/d)$ 指数，同时几乎不向观察者泄露关于最佳手臂的信息。

Conclusion: 本文提出了一个使用“编码手臂”的安全算法，该算法在不依赖密钥或加密原语的情况下，实现了$m 	ilde{	ilde{O}}(T/d^{1/2})$ 的最优指数，同时几乎不泄露关于最佳手臂的信息。

Abstract: Consider the problem of best arm identification with a security constraint.
Specifically, assume a setup of stochastic linear bandits with $K$ arms of
dimension $d$. In each arm pull, the player receives a reward that is the sum
of the dot product of the arm with an unknown parameter vector and independent
noise. The player's goal is to identify the best arm after $T$ arm pulls.
Moreover, assume a copycat Chloe is observing the arm pulls. The player wishes
to keep Chloe ignorant of the best arm.
  While a minimax--optimal algorithm identifies the best arm with an
$\Omega\left(\frac{T}{\log(d)}\right)$ error exponent, it easily reveals its
best-arm estimate to an outside observer, as the best arms are played more
frequently. A naive secure algorithm that plays all arms equally results in an
$\Omega\left(\frac{T}{d}\right)$ exponent. In this paper, we propose a secure
algorithm that plays with \emph{coded arms}. The algorithm does not require any
key or cryptographic primitives, yet achieves an
$\Omega\left(\frac{T}{\log^2(d)}\right)$ exponent while revealing almost no
information on the best arm.

</details>


### [168] [KASPER: Kolmogorov Arnold Networks for Stock Prediction and Explainable Regimes](https://arxiv.org/abs/2507.18983)
*Vidhi Oad,Param Pathak,Nouhaila Innan,Shalini D,Muhammad Shafique*

Main category: cs.LG

TL;DR: KASPER框架通过整合制度检测、基于稀疏样条的Kolmogorov-Arnold网络和基于Shapley值的符号规则提取，实现了金融市场中可感知、透明和稳健的预测。


<details>
  <summary>Details</summary>
Motivation: 金融市场的预测因其非线性动态和依赖制度的动态而仍然是一个重大挑战。传统的深度学习模型（如LSTM和MLP）在变化的 시장 条件下泛化能力方面常常遇到困难，这凸显了对更具适应性和可解释性的方法的需求。

Method: 本研究提出了一种名为KASPER（Kolmogorov-Arnold网络用于股票预测和可解释制度）的新颖框架，该框架整合了制度检测、基于稀疏样条的函数建模和符号规则提取。该框架使用基于Gumbel-Softmax的机制来识别隐藏的市场条件，从而实现特定于制度的预测。对于每种制度，它采用具有稀疏样条激活的Kolmogorov-Arnold网络来捕获复杂的价位行为，同时保持稳健性。通过基于蒙特卡洛Shapley值的符号学习实现了解释性，该学习提取了针对每种制度量身定制的、人类可读的规则。

Result: 将该模型应用于来自Yahoo Finance的真实世界金融时间序列，取得了0.89的R²分数，12.02的夏普比率，以及低至0.0001的均方误差，表现优于现有方法。

Conclusion: 该研究为金融市场建立了新的方向，以实现可感知、透明和稳健的预测。

Abstract: Forecasting in financial markets remains a significant challenge due to their
nonlinear and regime-dependent dynamics. Traditional deep learning models, such
as long short-term memory networks and multilayer perceptrons, often struggle
to generalize across shifting market conditions, highlighting the need for a
more adaptive and interpretable approach. To address this, we introduce
Kolmogorov-Arnold networks for stock prediction and explainable regimes
(KASPER), a novel framework that integrates regime detection, sparse
spline-based function modeling, and symbolic rule extraction. The framework
identifies hidden market conditions using a Gumbel-Softmax-based mechanism,
enabling regime-specific forecasting. For each regime, it employs
Kolmogorov-Arnold networks with sparse spline activations to capture intricate
price behaviors while maintaining robustness. Interpretability is achieved
through symbolic learning based on Monte Carlo Shapley values, which extracts
human-readable rules tailored to each regime. Applied to real-world financial
time series from Yahoo Finance, the model achieves an $R^2$ score of 0.89, a
Sharpe Ratio of 12.02, and a mean squared error as low as 0.0001, outperforming
existing methods. This research establishes a new direction for regime-aware,
transparent, and robust forecasting in financial markets.

</details>


### [169] [Differentiated Thyroid Cancer Recurrence Classification Using Machine Learning Models and Bayesian Neural Networks with Varying Priors: A SHAP-Based Interpretation of the Best Performing Model](https://arxiv.org/abs/2507.18987)
*HMNS Kumari,HMLS Kumari,UMMPK Nawarathne*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Differentiated thyroid cancer DTC recurrence is a major public health
concern, requiring classification and predictive models that are not only
accurate but also interpretable and uncertainty aware. This study introduces a
comprehensive framework for DTC recurrence classification using a dataset
containing 383 patients and 16 clinical and pathological variables. Initially,
11 machine learning ML models were employed using the complete dataset, where
the Support Vector Machines SVM model achieved the highest accuracy of 0.9481.
To reduce complexity and redundancy, feature selection was carried out using
the Boruta algorithm, and the same ML models were applied to the reduced
dataset, where it was observed that the Logistic Regression LR model obtained
the maximum accuracy of 0.9611. However, these ML models often lack uncertainty
quantification, which is critical in clinical decision making. Therefore, to
address this limitation, the Bayesian Neural Networks BNN with six varying
prior distributions, including Normal 0,1, Normal 0,10, Laplace 0,1, Cauchy
0,1, Cauchy 0,2.5, and Horseshoe 1, were implemented on both the complete and
reduced datasets. The BNN model with Normal 0,10 prior distribution exhibited
maximum accuracies of 0.9740 and 0.9870 before and after feature selection,
respectively.

</details>


### [170] [Reinforcement Learning via Conservative Agent for Environments with Random Delays](https://arxiv.org/abs/2507.18992)
*Jongsoo Lee,Jangwon Kim,Jiseok Jeong,Soohee Han*

Main category: cs.LG

TL;DR: 现实世界强化学习常因延迟反馈而受阻。本研究提出“保守代理”，将随机延迟环境转化为等效的恒定延迟环境，可直接扩展现有方法，并在连续控制任务中表现出更优的性能和样本效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界强化学习应用常受限于环境延迟反馈，这违反了马尔可夫假设并带来了巨大挑战。尽管已有许多针对恒定延迟环境的补偿方法，但由于随机延迟环境的内在可变性和不可预测性，该领域仍有待探索。

Method: 提出了一种名为“保守代理”的代理，通过将随机延迟环境重构为等效的恒定延迟环境，使得任何最先进的恒定延迟方法都可以直接扩展到随机延迟环境。

Result: 在连续控制任务上评估了基于保守代理的算法，实验结果表明，与现有的基线算法相比，该算法在渐近性能和样本效率方面均有显著优势。

Conclusion: 提出了一种名为“保守代理”的简单而强大的随机延迟决策代理，通过将随机延迟环境重构为等效的恒定延迟环境，实现了对任何最先进的恒定延迟方法的直接扩展，而无需修改算法结构或牺牲性能。

Abstract: Real-world reinforcement learning applications are often hindered by delayed
feedback from environments, which violates the Markov assumption and introduces
significant challenges. Although numerous delay-compensating methods have been
proposed for environments with constant delays, environments with random delays
remain largely unexplored due to their inherent variability and
unpredictability. In this study, we propose a simple yet robust agent for
decision-making under random delays, termed the conservative agent, which
reformulates the random-delay environment into its constant-delay equivalent.
This transformation enables any state-of-the-art constant-delay method to be
directly extended to the random-delay environments without modifying the
algorithmic structure or sacrificing performance. We evaluate the conservative
agent-based algorithm on continuous control tasks, and empirical results
demonstrate that it significantly outperforms existing baseline algorithms in
terms of asymptotic performance and sample efficiency.

</details>


### [171] [Adapting to Fragmented and Evolving Data: A Fisher Information Perspective](https://arxiv.org/abs/2507.18996)
*Behraj Khan,Tahir Qasim Syed,Nouman Muhammad Durrani*

Main category: cs.LG

TL;DR: FADE 是一种轻量级、有理论依据的框架，用于在动态环境中（顺序协变量偏移）进行鲁棒学习。它使用基于 Fisher 信息的正则化和 Cramer-Rao 知敏移信号进行适应，无需任务边界、目标监督或经验回放。FADE 在各种基准测试中表现优于现有方法，并能推广到联邦学习。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习系统在动态环境中运行，通常会遇到顺序协变量偏移（SCS），其中输入分布会随着时间演变，而条件分布保持稳定。FADE 旨在解决此问题，提供一种轻量级且有理论依据的框架，用于在 SCS 下进行鲁棒学习。

Method: FADE（基于 Fisher 的动态环境适应）框架，采用基于 Fisher 信息几何的感知变化的正则化机制，通过根据敏感性和稳定性调整参数更新来指导适应。为了检测显著的分布变化，该框架提出了一种结合 KL 散度和时间 Fisher 动力学的 Cramer-Rao 知敏移信号。

Result: FADE 在七个基准测试中表现出色，在严重偏移的情况下准确率提高了 19%，优于 TENT 和 DIW 等现有方法。它还在联邦学习中表现出良好的泛化能力，并具有理论保证。

Conclusion: FADE 在视觉、语言和表格数据等七个基准测试中表现出色，在严重偏移的情况下准确率提高了 19%，并且优于 TENT 和 DIW 等方法。此外，FADE 还可以通过将异构客户端视为时间上不连续的环境，自然地推广到联邦学习，从而在分散式环境中实现可扩展且稳定的适应。理论分析保证了其有界遗憾和参数一致性，而经验结果证明了 FADE 在不同模式和偏移强度下的鲁棒性。

Abstract: Modern machine learning systems operating in dynamic environments often face
\textit{sequential covariate shift} (SCS), where input distributions evolve
over time while the conditional distribution remains stable. We introduce FADE
(Fisher-based Adaptation to Dynamic Environments), a lightweight and
theoretically grounded framework for robust learning under SCS. FADE employs a
shift-aware regularization mechanism anchored in Fisher information geometry,
guiding adaptation by modulating parameter updates based on sensitivity and
stability. To detect significant distribution changes, we propose a
Cramer-Rao-informed shift signal that integrates KL divergence with temporal
Fisher dynamics. Unlike prior methods requiring task boundaries, target
supervision, or experience replay, FADE operates online with fixed memory and
no access to target labels. Evaluated on seven benchmarks spanning vision,
language, and tabular data, FADE achieves up to 19\% higher accuracy under
severe shifts, outperforming methods such as TENT and DIW. FADE also
generalizes naturally to federated learning by treating heterogeneous clients
as temporally fragmented environments, enabling scalable and stable adaptation
in decentralized settings. Theoretical analysis guarantees bounded regret and
parameter consistency, while empirical results demonstrate FADE's robustness
across modalities and shift intensities.

</details>


### [172] [MindSpeed RL: Distributed Dataflow for Scalable and Efficient RL Training on Ascend NPU Cluster](https://arxiv.org/abs/2507.19017)
*Laingjun Feng,Chenyi Pan,Xinjie Guo,Fei Mei,Benzhe Ning,Jianxiang Zhang,Xinyang Liu,Beirong Zhou,Zeng Shu,Chang Liu,Guang Yang,Zhenyu Han,Jiangben Wang,Bo Wang*

Main category: cs.LG

TL;DR: MindSpeed RL 是一个用于大规模强化学习训练的系统，通过分布式策略解决了扩展性和内存效率问题，并将吞吐量提高了高达 3.97 倍。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习训练系统由于其多 worker 的图模型结构和重度的跨节点依赖性，在集群扩展性和内存利用率方面存在严重问题。为了解决这些挑战，需要一个更高效的系统来支持大规模强化学习训练。

Method: MindSpeed RL 提出了一种分布式强化学习训练系统，通过组织样本流和重分布流的分布式视图来解决传统集中式方法在扩展性和内存利用率方面的问题。具体来说，它设计了分布式传输对接策略来降低样本流的调度开销，并采用了 allgather-swap 策略来消除重分布流中的冗余内存使用。此外，该系统还集成了多种并行化策略和加速技术。

Result: 与现有的最先进系统相比，MindSpeed RL 在 Qwen2.5-Dense-7B/32B、Qwen3-MoE-30B 和 DeepSeek-R1-MoE-671B 的强化学习训练实验中，吞吐量提高了 1.42 至 3.97 倍。

Conclusion: MindSpeed RL 通过分布式传输对接策略和 allgather-swap 策略优化了样本流和重分布流，并集成了多种并行化和加速技术，显著提高了大规模强化学习训练的吞吐量（1.42~3.97倍），同时降低了内存消耗。实验表明，MindSpeed RL 在 Ascend 384 NPUs 集群上运行 Qwen2.5、Qwen3 和 DeepSeek 等模型时，性能强大且可靠，并已开源。

Abstract: Reinforcement learning (RL) is a paradigm increasingly used to align large
language models. Popular RL algorithms utilize multiple workers and can be
modeled as a graph, where each node is the status of a worker and each edge
represents dataflow between nodes. Owing to the heavy cross-node dependencies,
the RL training system usually suffers from poor cluster scalability and low
memory utilization. In this article, we introduce MindSpeed RL, an effective
and efficient system for large-scale RL training. Unlike existing centralized
methods, MindSpeed RL organizes the essential data dependencies in RL training,
i.e., sample flow and resharding flow, from a distributed view. On the one
hand, a distributed transfer dock strategy, which sets controllers and
warehouses on the basis of the conventional replay buffer, is designed to
release the dispatch overhead in the sample flow. A practical allgather--swap
strategy is presented to eliminate redundant memory usage in resharding flow.
In addition, MindSpeed RL further integrates numerous parallelization
strategies and acceleration techniques for systematic optimization. Compared
with existing state-of-the-art systems, comprehensive experiments on the RL
training of popular Qwen2.5-Dense-7B/32B, Qwen3-MoE-30B, and
DeepSeek-R1-MoE-671B show that MindSpeed RL increases the throughput by 1.42 ~
3.97 times. Finally, we open--source MindSpeed RL and perform all the
experiments on a super pod of Ascend with 384 neural processing units (NPUs) to
demonstrate the powerful performance and reliability of Ascend.

</details>


### [173] [ProGMLP: A Progressive Framework for GNN-to-MLP Knowledge Distillation with Efficient Trade-offs](https://arxiv.org/abs/2507.19031)
*Weigang Lu,Ziyu Guan,Wei Zhao,Yaming Yang,Yujie Sun,Zheng Liang,Yibing Zhan,Dapeng Tao*

Main category: cs.LG

TL;DR: ProGMLP是一种新的G2M知识蒸馏方法，通过渐进式训练和蒸馏，实现了推理成本和精度的动态权衡。


<details>
  <summary>Details</summary>
Motivation: 现有G2M方法无法灵活动态地调整推理成本和精度，而这在实际应用中至关重要。

Method: 提出了一种渐进式框架ProGMLP，通过渐进式训练结构（PTS）和渐进式知识蒸馏（PKD）以及渐进式Mixup增强（PMA）来解决上述问题。

Result: 实验证明，ProGMLP在保持高精度的同时，能够根据不同的运行场景动态调整，在各种应用场景中部署效果显著。

Conclusion: G2M方法能够将GNN的知识迁移到MLP中，但现有方法难以动态调整推理成本和精度。

Abstract: GNN-to-MLP (G2M) methods have emerged as a promising approach to accelerate
Graph Neural Networks (GNNs) by distilling their knowledge into simpler
Multi-Layer Perceptrons (MLPs). These methods bridge the gap between the
expressive power of GNNs and the computational efficiency of MLPs, making them
well-suited for resource-constrained environments. However, existing G2M
methods are limited by their inability to flexibly adjust inference cost and
accuracy dynamically, a critical requirement for real-world applications where
computational resources and time constraints can vary significantly. To address
this, we introduce a Progressive framework designed to offer flexible and
on-demand trade-offs between inference cost and accuracy for GNN-to-MLP
knowledge distillation (ProGMLP). ProGMLP employs a Progressive Training
Structure (PTS), where multiple MLP students are trained in sequence, each
building on the previous one. Furthermore, ProGMLP incorporates Progressive
Knowledge Distillation (PKD) to iteratively refine the distillation process
from GNNs to MLPs, and Progressive Mixup Augmentation (PMA) to enhance
generalization by progressively generating harder mixed samples. Our approach
is validated through comprehensive experiments on eight real-world graph
datasets, demonstrating that ProGMLP maintains high accuracy while dynamically
adapting to varying runtime scenarios, making it highly effective for
deployment in diverse application settings.

</details>


### [174] [Neural Ordinary Differential Equations for Learning and Extrapolating System Dynamics Across Bifurcations](https://arxiv.org/abs/2507.19036)
*Eva van Tegelen,George van Voorn,Ioannis Athanasiadis,Peter van Heijster*

Main category: cs.LG

TL;DR: 神经网络常微分方程可以从时间序列数据中学习和预测分岔，即使在数据有限或有噪声的情况下也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 大多数机器学习方法在预测系统行为和分岔结构时，仅限于离散时间方法和局部分岔，未能解决全局分岔问题。

Method: 使用神经网络常微分方程（Neural Ordinary Differential Equations）来学习系统动力学，以应对离散时间方法和局部分岔的局限性。

Result: 神经网络常微分方程成功地从时间序列数据中学习了参数依赖的向量场，恢复了分岔结构，并能预测超出训练数据范围的分岔。

Conclusion: Neural Ordinary Differential Equations 能够从时间序列数据中直接恢复潜在的分岔结构，并且能够预测训练数据未涵盖参数区域的分岔。模型准确性更多地取决于从训练数据中推断出的信息质量，而非可用数据的数量。

Abstract: Forecasting system behaviour near and across bifurcations is crucial for
identifying potential shifts in dynamical systems. While machine learning has
recently been used to learn critical transitions and bifurcation structures
from data, most studies remain limited as they exclusively focus on
discrete-time methods and local bifurcations. To address these limitations, we
use Neural Ordinary Differential Equations which provide a continuous,
data-driven framework for learning system dynamics. We apply our approach to a
predator-prey system that features both local and global bifurcations,
presenting a challenging test case. Our results show that Neural Ordinary
Differential Equations can recover underlying bifurcation structures directly
from timeseries data by learning parameter-dependent vector fields. Notably, we
demonstrate that Neural Ordinary Differential Equations can forecast
bifurcations even beyond the parameter regions represented in the training
data. We also assess the method's performance under limited and noisy data
conditions, finding that model accuracy depends more on the quality of
information that can be inferred from the training data, than on the amount of
data available.

</details>


### [175] [Dynamics-Informed Reservoir Computing with Visibility Graphs](https://arxiv.org/abs/2507.19046)
*Charlotte Geier,Merten Stender*

Main category: cs.LG

TL;DR: DyRC-VG通过使用可见性图技术从输入时间序列中推断水库网络结构，提高了水库计算在时间和非线性时间序列预测中的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统RC中由于无规则的水库图结构导致的次优和过大网络以及动力学理解不足的问题。

Method: 使用可见性图（VG）技术将时间序列数据转换为网络，并将VG网络直接用作水库网络，以构建DyRC框架。

Result: DyRC-VG方法在预测精度和性能一致性方面优于具有相同尺寸、谱半径和可比密度的Erdös-Rényi图。

Conclusion: DyRC-VG方法在预测精度和性能一致性方面优于具有相同尺寸、谱半径和可比密度的Erdös-Rényi图。

Abstract: Accurate prediction of complex and nonlinear time series remains a
challenging problem across engineering and scientific disciplines. Reservoir
computing (RC) offers a computationally efficient alternative to traditional
deep learning by training only the read-out layer while employing a randomly
structured and fixed reservoir network. Despite its advantages, the largely
random reservoir graph architecture often results in suboptimal and oversized
networks with poorly understood dynamics. Addressing this issue, we propose a
novel Dynamics-Informed Reservoir Computing (DyRC) framework that
systematically infers the reservoir network structure directly from the input
training sequence. This work proposes to employ the visibility graph (VG)
technique, which converts time series data into networks by representing
measurement points as nodes linked by mutual visibility. The reservoir network
is constructed by directly adopting the VG network from a training data
sequence, leveraging the parameter-free visibility graph approach to avoid
expensive hyperparameter tuning. This process results in a reservoir that is
directly informed by the specific dynamics of the prediction task under study.
We assess the DyRC-VG method through prediction tasks involving the canonical
nonlinear Duffing oscillator, evaluating prediction accuracy and consistency.
Compared to an Erd\H{o}s-R\'enyi graph of the same size, spectral radius, and
comparable density, we observe higher prediction quality and more consistent
performance over repeated implementations in the DyRC-VG.

</details>


### [176] [Exploring molecular assembly as a biosignature using mass spectrometry and machine learning](https://arxiv.org/abs/2507.19057)
*Lindsay A. Rutter,Abhishek Sharma,Ian Seet,David Obeh Alobo,An Goto,Leroy Cronin*

Main category: cs.LG

TL;DR: 为地外生命探测开发了一种名为“分子组装”的新方法，该方法可以通过质谱仪测量，并且可以被机器学习模型预测，而无需解析分子结构。


<details>
  <summary>Details</summary>
Motivation: 为了在不依赖地球生命的情况下探测地外生命，需要一种可以从质谱数据中预测分子组装且无需解析未知结构的方法。

Method: 使用机器学习模型预测分子组装，并将误差减少了三倍。

Result: 机器学习模型可准确预测分子组装，将误差与基线模型相比减少了三倍。但仪器不一致性会增加模型误差，因此需要标准化。

Conclusion: 分子组装的预测可用于地外生命探测，且无需解析未知结构。通过标准化质谱数据库，可以无需结构解析便能准确预测分子组装，为未来的天体生物学任务提供了概念验证。

Abstract: Molecular assembly offers a promising path to detect life beyond Earth, while
minimizing assumptions based on terrestrial life. As mass spectrometers will be
central to upcoming Solar System missions, predicting molecular assembly from
their data without needing to elucidate unknown structures will be essential
for unbiased life detection. An ideal agnostic biosignature must be
interpretable and experimentally measurable. Here, we show that molecular
assembly, a recently developed approach to measure objects that have been
produced by evolution, satisfies both criteria. First, it is interpretable for
life detection, as it reflects the assembly of molecules with their bonds as
building blocks, in contrast to approaches that discount construction history.
Second, it can be determined without structural elucidation, as it can be
physically measured by mass spectrometry, a property that distinguishes it from
other approaches that use structure-based information measures for molecular
complexity. Whilst molecular assembly is directly measurable using mass
spectrometry data, there are limits imposed by mission constraints. To address
this, we developed a machine learning model that predicts molecular assembly
with high accuracy, reducing error by three-fold compared to baseline models.
Simulated data shows that even small instrumental inconsistencies can double
model error, emphasizing the need for standardization. These results suggest
that standardized mass spectrometry databases could enable accurate molecular
assembly prediction, without structural elucidation, providing a
proof-of-concept for future astrobiology missions.

</details>


### [177] [Clustering-Oriented Generative Attribute Graph Imputation](https://arxiv.org/abs/2507.19085)
*Mulin Chen,Bocheng Wang,Jiaxin Zhong,Zongcheng Miao,Xuelong Li*

Main category: cs.LG

TL;DR: CGIR是一种用于属性缺失图聚类的新模型，通过子簇分析和边缘注意力来改进节点填充和嵌入精炼，解决了现有方法的不足，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的属性缺失图聚类模型通常遵循填充和精炼的两步法。然而，大多数填充方法未能捕捉到与类别相关的语义信息，导致填充效果不佳，影响聚类效果。此外，现有的精炼策略通过图重构来优化学习到的嵌入，但忽略了某些属性与图结构不相关这一事实。

Method: CGIR模型首先估计子簇分布以揭示特定类别的特征，并约束生成对抗模块的采样空间，从而促使填充的节点与正确的簇对齐。然后，合并多个子簇以指导提出的边缘注意力网络，该网络识别每个类别的逐边属性，以避免图中冗余属性的重构干扰整体嵌入的精炼。

Result: 实验结果证明了CGIR模型优于现有技术水平的竞争对手。

Conclusion: CGIR模型将属性缺失图聚类分解为子簇的搜索和合并，并在统一框架内指导节点填充和精炼。

Abstract: Attribute-missing graph clustering has emerged as a significant unsupervised
task, where only attribute vectors of partial nodes are available and the graph
structure is intact. The related models generally follow the two-step paradigm
of imputation and refinement. However, most imputation approaches fail to
capture class-relevant semantic information, leading to sub-optimal imputation
for clustering. Moreover, existing refinement strategies optimize the learned
embedding through graph reconstruction, while neglecting the fact that some
attributes are uncorrelated with the graph. To remedy the problems, we
establish the Clustering-oriented Generative Imputation with reliable
Refinement (CGIR) model. Concretely, the subcluster distributions are estimated
to reveal the class-specific characteristics precisely, and constrain the
sampling space of the generative adversarial module, such that the imputation
nodes are impelled to align with the correct clusters. Afterwards, multiple
subclusters are merged to guide the proposed edge attention network, which
identifies the edge-wise attributes for each class, so as to avoid the
redundant attributes in graph reconstruction from disturbing the refinement of
overall embedding. To sum up, CGIR splits attribute-missing graph clustering
into the search and mergence of subclusters, which guides to implement node
imputation and refinement within a unified framework. Extensive experiments
prove the advantages of CGIR over state-of-the-art competitors.

</details>


### [178] [GCL-GCN: Graphormer and Contrastive Learning Enhanced Attributed Graph Clustering Network](https://arxiv.org/abs/2507.19095)
*Binxiong Li,Xu Xiang,Xue Li,Binyu Zhao,Yujie Liu,Huijie Tang,Benhan Yang,Zhixuan Chen*

Main category: cs.LG

TL;DR: GCL-GCN是一种新的深度图聚类模型，通过结合Graphormer和对比学习来改进节点表示和聚类质量，在多个数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的归因图聚类模型在处理稀疏和异构图数据时，难以捕捉局部依赖关系和复杂结构。为了解决这些局限性，需要一种能够有效利用图信息进行聚类的新模型。

Method: 提出了一种新颖的图神经网络（GNN）模型GCL-GCN，该模型包含图转置（Graphormer）模块和对比学习模块。图转置模块结合了中心性编码和空间关系，用于捕捉节点间的全局和局部信息。对比学习模块用于增强特征表示的判别能力，通过在原始特征矩阵上进行对比学习来提高特征区分度。

Result: GCL-GCN在Cora数据集上，与主要对比方法MBN相比，其ACC、NMI和ARI分别提高了4.94%、13.01%和10.97%。

Conclusion: GCL-GCN在六个数据集上的广泛实验结果证明，其在聚类质量和鲁棒性方面优于14种先进方法。具体而言，在Cora数据集上，与主要对比方法MBN相比，其ACC、NMI和ARI分别提高了4.94%、13.01%和10.97%。

Abstract: Attributed graph clustering holds significant importance in modern data
analysis. However, due to the complexity of graph data and the heterogeneity of
node attributes, leveraging graph information for clustering remains
challenging. To address this, we propose a novel deep graph clustering model,
GCL-GCN, specifically designed to address the limitations of existing models in
capturing local dependencies and complex structures when dealing with sparse
and heterogeneous graph data. GCL-GCN introduces an innovative Graphormer
module that combines centrality encoding and spatial relationships, effectively
capturing both global and local information between nodes, thereby enhancing
the quality of node representations. Additionally, we propose a novel
contrastive learning module that significantly enhances the discriminative
power of feature representations. In the pre-training phase, this module
increases feature distinction through contrastive learning on the original
feature matrix, ensuring more identifiable initial representations for
subsequent graph convolution and clustering tasks. Extensive experimental
results on six datasets demonstrate that GCL-GCN outperforms 14 advanced
methods in terms of clustering quality and robustness. Specifically, on the
Cora dataset, it improves ACC, NMI, and ARI by 4.94%, 13.01%, and 10.97%,
respectively, compared to the primary comparison method MBN.

</details>


### [179] [Graph Structure Learning with Privacy Guarantees for Open Graph Data](https://arxiv.org/abs/2507.19116)
*Muhao Guo,Jiaqi Wu,Yang Weng,Yizheng Liao,Shengzhe Chen*

Main category: cs.LG

TL;DR: 该研究提出了一种新的隐私保护估计框架，利用高斯差分隐私（GDP）和结构化噪声注入机制来解决开放图数据中的图恢复问题，在数据发布阶段实现隐私保护，同时保持无偏的图结构恢复和估计准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有隐私保护数据发布（PPDP）方法在平衡隐私和效用方面存在的挑战，特别是在数据发布者和使用者是不同实体的情况下。

Method: 利用高斯差分隐私（GDP）和结构化噪声注入机制来解决图恢复问题，并在数据发布阶段进行隐私保护。

Result: 在图学习方面，该方法提供了稳健的性能，并在理论上保证了估计的准确性，同时将方法扩展到了离散变量图。

Conclusion: 所提出的框架在图学习方面表现稳健，为注重隐私的图分析提供了可行的解决方案，并在数据发布阶段强制执行差分隐私，同时确保无偏的图结构恢复。

Abstract: Ensuring privacy in large-scale open datasets is increasingly challenging
under regulations such as the General Data Protection Regulation (GDPR). While
differential privacy (DP) provides strong theoretical guarantees, it primarily
focuses on noise injection during model training, neglecting privacy
preservation at the data publishing stage. Existing privacy-preserving data
publishing (PPDP) approaches struggle to balance privacy and utility,
particularly when data publishers and users are distinct entities. To address
this gap, we focus on the graph recovery problem and propose a novel
privacy-preserving estimation framework for open graph data, leveraging
Gaussian DP (GDP) with a structured noise-injection mechanism. Unlike
traditional methods that perturb gradients or model updates, our approach
ensures unbiased graph structure recovery while enforcing DP at the data
publishing stage. Moreover, we provide theoretical guarantees on estimation
accuracy and extend our method to discrete-variable graphs, a setting often
overlooked in DP research. Experimental results in graph learning demonstrate
robust performance, offering a viable solution for privacy-conscious graph
analysis.

</details>


### [180] [Solar Photovoltaic Assessment with Large Language Model](https://arxiv.org/abs/2507.19144)
*Muhao Guo,Yang Weng*

Main category: cs.LG

TL;DR: 本研究提出PVAL框架，利用LLMs改进卫星图像中的太阳能光伏板检测，解决了现有方法的局限性，提高了透明度、可扩展性和准确性，实现了自动化检测流程。


<details>
  <summary>Details</summary>
Motivation: 现有太阳能光伏（PV）板检测方法存在算法或训练数据不透明、依赖高质量PV训练数据、泛化能力不足等问题，导致检测结果不一致，阻碍了大规模部署和数据驱动的电网优化。因此，需要研究如何利用大型语言模型（LLMs）来克服这些挑战。

Method: 本研究提出了一种名为PV Assessment with LLMs (PVAL) 的框架，该框架结合了任务分解、输出标准化、少样本提示和使用带详细注释的PV数据集进行微调，以解决大型语言模型在太阳能光伏板检测中的挑战。

Result: PVAL框架通过结合任务分解、输出标准化、少样本提示和数据集微调，提高了太阳能光伏板检测的透明度、可扩展性和适应性，并最小化了计算开销。该框架实现了自动化和可复现的太阳能光伏板检测流水线，提高了对太阳能光伏板的检测精度和空间定位能力。

Conclusion: 该研究提出了一个名为PVAL的框架，该框架利用大型语言模型（LLMs）来解决卫星图像中太阳能光伏（PV）板检测的挑战。PVAL通过任务分解、输出标准化、少样本提示和数据集微调，提高了检测的透明度、可扩展性和适应性，并实现了自动化和可复现的太阳能光伏板检测流程，为大规模可再生能源整合和优化的电网管理铺平了道路。

Abstract: Accurate detection and localization of solar photovoltaic (PV) panels in
satellite imagery is essential for optimizing microgrids and active
distribution networks (ADNs), which are critical components of renewable energy
systems. Existing methods lack transparency regarding their underlying
algorithms or training datasets, rely on large, high-quality PV training data,
and struggle to generalize to new geographic regions or varied environmental
conditions without extensive re-training. These limitations lead to
inconsistent detection outcomes, hindering large-scale deployment and
data-driven grid optimization. In this paper, we investigate how large language
models (LLMs) can be leveraged to overcome these challenges. Despite their
promise, LLMs face several challenges in solar panel detection, including
difficulties with multi-step logical processes, inconsistent output formatting,
frequent misclassification of visually similar objects (e.g., shadows, parking
lots), and low accuracy in complex tasks such as spatial localization and
quantification. To overcome these issues, we propose the PV Assessment with
LLMs (PVAL) framework, which incorporates task decomposition for more efficient
workflows, output standardization for consistent and scalable formatting,
few-shot prompting to enhance classification accuracy, and fine-tuning using
curated PV datasets with detailed annotations. PVAL ensures transparency,
scalability, and adaptability across heterogeneous datasets while minimizing
computational overhead. By combining open-source accessibility with robust
methodologies, PVAL establishes an automated and reproducible pipeline for
solar panel detection, paving the way for large-scale renewable energy
integration and optimized grid management.

</details>


### [181] [Automatic Cough Analysis for Non-Small Cell Lung Cancer Detection](https://arxiv.org/abs/2507.19174)
*Chiara Giangregorio,Cristina Maria Licciardello,Vanja Miskovic,Leonardo Provenzano,Alessandra Laura Giulia Pedrocchi,Andra Diana Dumitrascu,Arsela Prelaj,Marina Chiara Garassino,Emilia Ambrosini,Simona Ferrante*

Main category: cs.LG

TL;DR: 本研究利用机器学习分析咳嗽声音以筛查非小细胞肺癌（NSCLC），CNN模型效果最佳。SVM模型在计算资源有限时也适用。研究发现咳嗽分析有潜力，但需要更大、更多样化的数据集来验证结果的可靠性。


<details>
  <summary>Details</summary>
Motivation: 早期检测非小细胞肺癌（NSCLC）对于改善患者预后至关重要，需要新的方法来辅助早期诊断。本研究旨在探索自动咳嗽分析作为一种区分NSCLC患者和健康对照组的预筛查工具。

Method: 本研究采用自动咳嗽分析技术，结合支持向量机（SVM）、XGBoost、卷积神经网络（CNN）和VGG16迁移学习等机器学习和深度学习方法，对227名非小细胞肺癌患者和健康对照者的咳嗽音频录音进行分析。研究还使用了SHAP方法来解释机器学习模型，并通过比较不同年龄和性别分组的性能来评估模型的公平性。

Result: 卷积神经网络（CNN）在测试集上达到了0.83的最佳准确率。支持向量机（SVM）在验证集和测试集上的准确率分别为0.76和0.78，适用于计算能力有限的场景。SHAP分析提高了SVM模型的可解释性。在公平性方面，年龄分组（0.15）的差异略高于性别分组（0.09）。

Conclusion: 本研究初步证明了自动咳嗽分析在区分非小细胞肺癌（NSCLC）患者和健康对照组方面的潜力，其中卷积神经网络（CNN）表现出最佳性能。然而，为了提高模型在临床应用中的可靠性和可解释性，还需要进一步的研究，包括使用更大、更多样化和无偏见的数据集，并结合SHAP等方法来增强模型透明度。

Abstract: Early detection of non-small cell lung cancer (NSCLC) is critical for
improving patient outcomes, and novel approaches are needed to facilitate early
diagnosis. In this study, we explore the use of automatic cough analysis as a
pre-screening tool for distinguishing between NSCLC patients and healthy
controls. Cough audio recordings were prospectively acquired from a total of
227 subjects, divided into NSCLC patients and healthy controls. The recordings
were analyzed using machine learning techniques, such as support vector machine
(SVM) and XGBoost, as well as deep learning approaches, specifically
convolutional neural networks (CNN) and transfer learning with VGG16. To
enhance the interpretability of the machine learning model, we utilized Shapley
Additive Explanations (SHAP). The fairness of the models across demographic
groups was assessed by comparing the performance of the best model across
different age groups (less than or equal to 58y and higher than 58y) and gender
using the equalized odds difference on the test set. The results demonstrate
that CNN achieves the best performance, with an accuracy of 0.83 on the test
set. Nevertheless, SVM achieves slightly lower performances (accuracy of 0.76
in validation and 0.78 in the test set), making it suitable in contexts with
low computational power. The use of SHAP for SVM interpretation further
enhances model transparency, making it more trustworthy for clinical
applications. Fairness analysis shows slightly higher disparity across age
(0.15) than gender (0.09) on the test set. Therefore, to strengthen our
findings' reliability, a larger, more diverse, and unbiased dataset is needed
-- particularly including individuals at risk of NSCLC and those in early
disease stages.

</details>


### [182] [WACA-UNet: Weakness-Aware Channel Attention for Static IR Drop Prediction in Integrated Circuit Design](https://arxiv.org/abs/2507.19197)
*Youngmin Seo,Yunhyeong Kwon,Younghun Park,HwiRyong Kim,Seungho Eum,Jinha Kim,Taigon Song,Juho Kim,Unsang Park*

Main category: cs.LG

TL;DR: 本研究提出了一种名为 WACA 的新颖机制，用于改进 VLSI 中的 IR 下降预测，与现有方法相比，在 ICCAD-2023 基准测试中取得了显著的准确性提升。


<details>
  <summary>Details</summary>
Motivation: 传统的基于仿真的求解器计算成本高昂且难以扩展，而基于学习的方法在处理物理图时未能充分考虑不同输入层的重要性。

Method: 本研究提出了一种新颖的弱感知通道注意力（WACA）机制，该机制通过两阶段门控策略递归地增强弱特征通道，同时抑制过度主导的通道。该方法集成到一个基于 ConvNeXtV2 的注意力 U-Net 中，实现了自适应和平衡的特征表示。

Result: 在公开的 ICCAD-2023 基准测试中，本研究提出的方法通过将平均绝对误差降低 61.1% 和提高 F1 分数 71.0% 来优于 ICCAD-2023 竞赛的获胜者。

Conclusion: 本研究表明，通道的异质性是 VLSI 物理布局分析中的关键归纳偏差。

Abstract: Accurate spatial prediction of power integrity issues, such as IR drop, is
critical for reliable VLSI design. However, traditional simulation-based
solvers are computationally expensive and difficult to scale. We address this
challenge by reformulating IR drop estimation as a pixel-wise regression task
on heterogeneous multi-channel physical maps derived from circuit layouts.
Prior learning-based methods treat all input layers (e.g., metal, via, and
current maps) equally, ignoring their varying importance to prediction
accuracy. To tackle this, we propose a novel Weakness-Aware Channel Attention
(WACA) mechanism, which recursively enhances weak feature channels while
suppressing over-dominant ones through a two-stage gating strategy. Integrated
into a ConvNeXtV2-based attention U-Net, our approach enables adaptive and
balanced feature representation. On the public ICCAD-2023 benchmark, our method
outperforms the ICCAD-2023 contest winner by reducing mean absolute error by
61.1% and improving F1-score by 71.0%. These results demonstrate that
channel-wise heterogeneity is a key inductive bias in physical layout analysis
for VLSI.

</details>


### [183] [Physics-Informed Graph Neural Networks for Transverse Momentum Estimation in CMS Trigger Systems](https://arxiv.org/abs/2507.19205)
*Md Abrar Jahin,Shahriar Soudeep,M. F. Mridha,Muhammad Mostafa Monowar,Md. Abdul Hamid*

Main category: cs.LG

TL;DR: 提出了一种物理信息图神经网络框架，通过整合优化的图结构和消息传递层，在高能物理实时粒子动量估计中实现了更高的准确性和效率，同时显著减少了模型参数量。


<details>
  <summary>Details</summary>
Motivation: 高能物理中实时粒子横向动量（pT）估计在严格的硬件约束下需要高效且准确的算法。现有的静态机器学习模型在多重散射环境下性能会下降，并且缺乏物理意识优化；而通用的图神经网络（GNNs）通常会忽略对鲁棒pT回归至关重要的领域结构。

Method: 提出了一种结合了四种不同图构建策略（站作为节点、特征作为节点、弯曲角度为中心、伪快度为中心）的物理信息图神经网络框架，并结合了带有内部消息注意力和门控更新的消息传递层（MPL），以及包含pT分布先验的特定领域损失函数。

Result: 一个基于站的EdgeConv模型实现了最先进的平均绝对误差（MAE）0.8525，参数量比深度学习基线（特别是TabNet）少55%以上。此外，基于伪快度的MPL配置也提高了准确性，同时保持了可比的效率。

Conclusion: 本研究提出的物理信息图神经网络框架在CMS触发器数据集上验证了其有效性，其模块化设计和优化的消息传递层在准确性和效率方面均优于现有基线模型，尤其是在参数量显著减少的情况下，为资源受限的触发系统提供了有前景的解决方案。

Abstract: Real-time particle transverse momentum ($p_T$) estimation in high-energy
physics demands algorithms that are both efficient and accurate under strict
hardware constraints. Static machine learning models degrade under high pileup
and lack physics-aware optimization, while generic graph neural networks (GNNs)
often neglect domain structure critical for robust $p_T$ regression. We propose
a physics-informed GNN framework that systematically encodes detector geometry
and physical observables through four distinct graph construction strategies
that systematically encode detector geometry and physical observables:
station-as-node, feature-as-node, bending angle-centric, and pseudorapidity
($\eta$)-centric representations. This framework integrates these tailored
graph structures with a novel Message Passing Layer (MPL), featuring
intra-message attention and gated updates, and domain-specific loss functions
incorporating $p_{T}$-distribution priors. Our co-design methodology yields
superior accuracy-efficiency trade-offs compared to existing baselines.
Extensive experiments on the CMS Trigger Dataset validate the approach: a
station-informed EdgeConv model achieves a state-of-the-art MAE of 0.8525 with
$\ge55\%$ fewer parameters than deep learning baselines, especially TabNet,
while an $\eta$-centric MPL configuration also demonstrates improved accuracy
with comparable efficiency. These results establish the promise of
physics-guided GNNs for deployment in resource-constrained trigger systems.

</details>


### [184] [Dependency-aware synthetic tabular data generation](https://arxiv.org/abs/2507.19211)
*Chaithra Umesh,Kristian Schultz,Manjunath Mahendra,Saptarshi Bej,Olaf Wolkenhauer*

Main category: cs.LG

TL;DR: HFGF框架通过先生成独立特征再重建依赖特征，解决了现有生成模型在保留合成表格数据中的函数依赖（FD）和逻辑依赖（LD）方面的不足，从而提高了数据的结构保真度和下游效用。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在保留合成表格数据中的函数依赖（FD）和逻辑依赖（LD）方面表现不佳。

Method: HFGF框架首先使用任何标准的生成模型生成独立特征，然后根据预定义的FD和LD规则重建依赖特征。

Result: HFGF在包含不同大小、特征不平衡和依赖复杂性的四个基准数据集上的实验表明，HFGF在六种生成模型（包括CTGAN、TVAE和GReaT）上都改进了FD和LD的保留。

Conclusion: HFGF可以显著提高合成表格数据的结构保真度和下游效用。

Abstract: Synthetic tabular data is increasingly used in privacy-sensitive domains such
as health care, but existing generative models often fail to preserve
inter-attribute relationships. In particular, functional dependencies (FDs) and
logical dependencies (LDs), which capture deterministic and rule-based
associations between features, are rarely or often poorly retained in synthetic
datasets. To address this research gap, we propose the Hierarchical Feature
Generation Framework (HFGF) for synthetic tabular data generation. We created
benchmark datasets with known dependencies to evaluate our proposed HFGF. The
framework first generates independent features using any standard generative
model, and then reconstructs dependent features based on predefined FD and LD
rules. Our experiments on four benchmark datasets with varying sizes, feature
imbalance, and dependency complexity demonstrate that HFGF improves the
preservation of FDs and LDs across six generative models, including CTGAN,
TVAE, and GReaT. Our findings demonstrate that HFGF can significantly enhance
the structural fidelity and downstream utility of synthetic tabular data.

</details>


### [185] [Component-Based Machine Learning for Indoor Flow and Temperature Fields Prediction Latent Feature Aggregation and Flow Interaction](https://arxiv.org/abs/2507.19233)
*Shaofan Wang,Nils Thuerey,Philipp Geyer*

Main category: cs.LG

TL;DR: 本研究提出了一种基于组件的机器学习（CBML）方法，通过结合CAER、MLP和CNN，能够快速准确地预测室内气流和温度分布，克服了传统CFD模拟的计算瓶颈。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统CFD模拟计算密集、限制其在实时或设计迭代工作流程中应用的问题，本研究提出了一种替代方法。

Method: 提出了一种基于组件的机器学习（CBML）的代理建模方法，该方法由三部分组成：1. 带有残差连接的卷积自编码器（CAER）用于提取和压缩流动特征；2. 多层感知器（MLP）用于映射入口速度到潜在表示；3. 卷积神经网络（CNN）作为聚合器，将单入口特征组合成双入口场景。

Result: CBML模型能够快速准确地预测双入口气流速度和温度场，并在训练和测试数据集上都表现良好。

Conclusion: 该CBML模型能够快速准确地预测双入口气流速度和温度场，适用于训练和测试数据集。

Abstract: Accurate and efficient prediction of indoor airflow and temperature
distributions is essential for building energy optimization and occupant
comfort control. However, traditional CFD simulations are computationally
intensive, limiting their integration into real-time or design-iterative
workflows. This study proposes a component-based machine learning (CBML)
surrogate modeling approach to replace conventional CFD simulation for fast
prediction of indoor velocity and temperature fields. The model consists of
three neural networks: a convolutional autoencoder with residual connections
(CAER) to extract and compress flow features, a multilayer perceptron (MLP) to
map inlet velocities to latent representations, and a convolutional neural
network (CNN) as an aggregator to combine single-inlet features into dual-inlet
scenarios. A two-dimensional room with varying left and right air inlet
velocities is used as a benchmark case, with CFD simulations providing training
and testing data. Results show that the CBML model accurately and fast predicts
two-component aggregated velocity and temperature fields across both training
and testing datasets.

</details>


### [186] [A Markov Categorical Framework for Language Modeling](https://arxiv.org/abs/2507.19247)
*Yifan Zhang*

Main category: cs.LG

TL;DR: 通过马尔可夫范畴和信息几何，分析了AR语言模型的生成过程和NLL目标，揭示了NLL训练是隐式的谱对比学习，并为推测解码提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解为什么简单的NLL目标能够产生通用的表示，并为现代推测解码方法提供理论基础。

Method: 使用马尔可夫范畴（MCs）和信息几何来分析自回归语言模型（AR）的生成过程和负对数似然（NLL）目标。

Result: 提供了推测解码方法的理论基础，形式化了NLL最小化学习数据内在条件随机性的过程，并证明了NLL训练是隐式的谱对比学习。Proj. Page: https://github.com/asiresearch/lm-theory

Conclusion: 该框架揭示了现代语言模型的有效性背后的深层结构原理，将NLL训练形式化为一种隐式的谱对比学习，并证明了NLL会迫使模型学习数据的内在条件随机性。

Abstract: Auto-regressive language models factorize sequence probabilities and are
trained by minimizing the negative log-likelihood (NLL) objective. While
empirically powerful, a deep theoretical understanding of why this simple
objective yields such versatile representations remains elusive. This work
introduces a unifying analytical framework using Markov Categories (MCs) to
deconstruct the AR generation process and the NLL objective. We model the
single-step generation map as a composition of Markov kernels in the category
Stoch. This compositional view, when enriched with statistical divergences,
allows us to dissect information flow and learned geometry. Our framework makes
three main contributions. First, we provide a formal, information-theoretic
rationale for the success of modern speculative decoding methods like EAGLE,
quantifying the information surplus in hidden states that these methods
exploit. Second, we formalize how NLL minimization forces the model to learn
not just the next token, but the data's intrinsic conditional stochasticity, a
process we analyze using categorical entropy. Third, and most centrally, we
prove that NLL training acts as an implicit form of spectral contrastive
learning. By analyzing the information geometry of the model's prediction head,
we show that NLL implicitly forces the learned representation space to align
with the eigenspectrum of a predictive similarity operator, thereby learning a
geometrically structured space without explicit contrastive pairs. This
compositional and information-geometric perspective reveals the deep structural
principles underlying the effectiveness of modern LMs. Project Page:
https://github.com/asiresearch/lm-theory

</details>


### [187] [Doubling Your Data in Minutes: Ultra-fast Tabular Data Generation via LLM-Induced Dependency Graphs](https://arxiv.org/abs/2507.19334)
*Shuo Yang,Zheyu Zhang,Bardh Prenkaj,Gjergji Kasneci*

Main category: cs.LG

TL;DR: SPADA是一种轻量级表格数据增强框架，通过LLM诱导的稀疏依赖图来生成数据，解决了现有方法的局限性，并显著提高了效率。


<details>
  <summary>Details</summary>
Motivation: 解决当前依赖LLM生成表格数据的方法中存在的依赖关系建模过于密集以及计算开销大的问题，以应对高质量表格数据稀缺的挑战。

Method: SPADA框架，通过LLM诱导图显式捕获稀疏依赖关系，并采用非参数方法（高斯核密度估计）或条件归一化流模型进行特征值合成。

Result: SPADA相比基于扩散的方法将约束冲突减少了4%，并且生成速度比基于LLM的方法快了近9500倍。

Conclusion: SPADA通过显式捕获稀疏依赖关系，解决了现有表格数据增强方法的局限性，并在减少约束冲突和提高生成速度方面表现出色。

Abstract: Tabular data is critical across diverse domains, yet high-quality datasets
remain scarce due to privacy concerns and the cost of collection. Contemporary
approaches adopt large language models (LLMs) for tabular augmentation, but
exhibit two major limitations: (1) dense dependency modeling among tabular
features that can introduce bias, and (2) high computational overhead in
sampling. To address these issues, we propose SPADA for SPArse
Dependency-driven Augmentation, a lightweight generative framework that
explicitly captures sparse dependencies via an LLM-induced graph. We treat each
feature as a node and synthesize values by traversing the graph, conditioning
each feature solely on its parent nodes. We explore two synthesis strategies: a
non-parametric method using Gaussian kernel density estimation, and a
conditional normalizing flow model that learns invertible mappings for
conditional density estimation. Experiments on four datasets show that SPADA
reduces constraint violations by 4% compared to diffusion-based methods and
accelerates generation by nearly 9,500 times over LLM-based baselines.

</details>


### [188] [Advancing Event Forecasting through Massive Training of Large Language Models: Challenges, Solutions, and Broader Impacts](https://arxiv.org/abs/2507.19477)
*Sang-Woo Lee,Sohee Yang,Donghyun Kwak,Noah Y. Siegel*

Main category: cs.LG

TL;DR: 研究大型语言模型（LLM）在事件预测方面的能力。近期研究显示LLM在事件预测方面表现出色，尤其是在结合强化学习和先进推理模型后。本文提出解决LLM事件预测训练中数据稀疏、知识过时和奖励单一等问题的方法，并主张利用市场、公开和网络数据进行大规模训练，以期实现AI预测智能的广泛应用。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明，大型语言模型在事件预测方面正逐步达到超级预测者水平，且强化学习和先进的推理模型（如Deep Research风格模型）的成功，预示着提升预测性能的技术已经出现。因此，本文旨在推动对大规模训练超级预测者级别事件预测LLM的研究。

Method: 本文提出通过假设事件贝叶斯网络、利用回忆不足和反事实事件以及辅助奖励信号来解决LLM事件预测训练中的信噪比低、知识截止和奖励结构简单的问题。同时，主张通过积极利用市场、公开和爬取的数据集来实现大规模训练和评估。

Result: 本文提出的方法和数据策略有望解决当前LLM事件预测训练中的挑战，为AI在更广泛领域提供预测智能奠定基础，并吸引研究者关注这些发展方向。

Conclusion: 当前的技术进展表明，开发超级预测者级别的事件预测大型语言模型（LLM）的时机已经成熟，研究应集中在训练方法和数据获取两个关键领域。

Abstract: Many recent papers have studied the development of superforecaster-level
event forecasting LLMs. While methodological problems with early studies cast
doubt on the use of LLMs for event forecasting, recent studies with improved
evaluation methods have shown that state-of-the-art LLMs are gradually reaching
superforecaster-level performance, and reinforcement learning has also been
reported to improve future forecasting. Additionally, the unprecedented success
of recent reasoning models and Deep Research-style models suggests that
technology capable of greatly improving forecasting performance has been
developed. Therefore, based on these positive recent trends, we argue that the
time is ripe for research on large-scale training of superforecaster-level
event forecasting LLMs. We discuss two key research directions: training
methods and data acquisition. For training, we first introduce three
difficulties of LLM-based event forecasting training: noisiness-sparsity,
knowledge cut-off, and simple reward structure problems. Then, we present
related ideas to mitigate these problems: hypothetical event Bayesian networks,
utilizing poorly-recalled and counterfactual events, and auxiliary reward
signals. For data, we propose aggressive use of market, public, and crawling
datasets to enable large-scale training and evaluation. Finally, we explain how
these technical advances could enable AI to provide predictive intelligence to
society in broader areas. This position paper presents promising specific paths
and considerations for getting closer to superforecaster-level AI technology,
aiming to call for researchers' interest in these directions.

</details>


### [189] [Short-Form Video Recommendations with Multimodal Embeddings: Addressing Cold-Start and Bias Challenges](https://arxiv.org/abs/2507.19346)
*Andrii Dzhoha,Katya Mirylenka,Egor Malykh,Marco-Andrea Buchmann,Francesca Catino*

Main category: cs.LG

TL;DR: 短视频平台通过UI创新吸引用户，但给推荐系统带来新挑战。本文提出利用微调后的多模态视觉-语言模型进行视频检索，以克服数据有限和偏差问题，并在电商平台的在线实验中取得比传统方法更好的效果。


<details>
  <summary>Details</summary>
Motivation: 解决短视频推荐系统在用户互动数据有限、位置偏差、持续时间偏差和反馈循环等方面的挑战。

Method: 利用微调后的多模态视觉-语言模型进行视频检索。

Result: 所提出的方法在在线实验中表现出比传统监督学习方法更好的效果。

Conclusion: 该方法在在线实验中被证明比传统的监督学习方法更有效。

Abstract: In recent years, social media users have spent significant amounts of time on
short-form video platforms. As a result, established platforms in other
domains, such as e-commerce, have begun introducing short-form video content to
engage users and increase their time spent on the platform. The success of
these experiences is due not only to the content itself but also to a unique UI
innovation: instead of offering users a list of choices to click, platforms
actively recommend content for users to watch one at a time. This creates new
challenges for recommender systems, especially when launching a new video
experience. Beyond the limited interaction data, immersive feed experiences
introduce stronger position bias due to the UI and duration bias when
optimizing for watch-time, as models tend to favor shorter videos. These
issues, together with the feedback loop inherent in recommender systems, make
it difficult to build effective solutions. In this paper, we highlight the
challenges faced when introducing a new short-form video experience and present
our experience showing that, even with sufficient video interaction data, it
can be more beneficial to leverage a video retrieval system using a fine-tuned
multimodal vision-language model to overcome these challenges. This approach
demonstrated greater effectiveness compared to conventional supervised learning
methods in online experiments conducted on our e-commerce platform.

</details>


### [190] [Reconstruction of Sparse Urban Wireless Signals via Group Equivariant Non-Expansive Operators](https://arxiv.org/abs/2507.19349)
*Lorenzo Mario Amorosa,Francesco Conti,Nicola Quercioli,Flavio Zabini,Tayebeh Lotfi Mahyari,Yiqun Ge,Patrizio Frosini*

Main category: cs.LG

TL;DR: 在 6G 通信中，使用一种叫 GENEO 的新方法，能用很少的数据点重建 SINR 图，效果很好。


<details>
  <summary>Details</summary>
Motivation: 在 6G 等新兴通信系统中，需要精确了解诸如信噪比（SINR）图等空间变化量，但高分辨率获取成本高昂。

Method: 利用群等变非扩张算子（GENEO）从稀疏测量中重建空间信号，作为传统神经网络的低复杂度替代方案。

Result: 所提出的框架在城市无线通信网络中，使用极度稀疏的采样，成功实现了 SINR 图的重建，并且通过统计和 TDA 指标的评估，证明了其在数据受限情况下的优势。

Conclusion: 所提出的基于 GENEO 的方法在面临严峻数据限制（采样点数量有限）时，能够实现空间信号的精确重建，并与现有方法相比具有竞争力。

Abstract: In emerging communication systems such as sixth generation (6G) wireless
networks, efficient resource management and service delivery rely on accurate
knowledge of spatially-varying quantities like signal-to-interference-noise
ratio (SINR) maps, which are costly to acquire at high resolution. This work
explores the reconstruction of such spatial signals from sparse measurements
using Group Equivariant Non-Expansive Operators (GENEOs), offering a
low-complexity alternative to traditional neural networks. The concept of
GENEO, which originated in topological data analysis (TDA), is a mathematical
tool used in machine learning to represent agents modelled as functional
operators acting on data while incorporating application-specific invariances.
Leveraging these invariances reduces the number of parameters with respect to
traditional neural networks and mitigates data scarcity by enforcing known
algebraic and geometric constraints that reflect symmetries in the agents'
actions. In this paper, we introduce a novel GENEO-based approach for SINR map
reconstruction in urban wireless communication networks using extremely sparse
sampling. We demonstrate that this mathematical framework achieves competitive
performance compared to established methods. Our evaluation, conducted using
both statistical and TDA metrics, highlights the advantages of our approach in
accurately reconstructing spatial signals under severe data limitations on the
number of samples.

</details>


### [191] [A Data-Driven Approach to Estimate LEO Orbit Capacity Models](https://arxiv.org/abs/2507.19365)
*Braden Stock,Maddox McVarthy,Simone Servadio*

Main category: cs.LG

TL;DR: SINDy和LSTM可以准确地预测近地轨道上的空间目标传播，提供MOCAT-MC的轻量级替代方案。


<details>
  <summary>Details</summary>
Motivation: 为了提供一个轻量级的、低保真度的模型，该模型可以替代计算成本高昂的高保真模型（MOCAT-MC），从而在更短的时间内提供准确的预测。

Method: 利用稀疏非线性动力学识别（SINDy）算法和长短期记忆循环神经网络（LSTM）。

Result: 该方法利用MOCAT-MC数据集，提供了一个能够进行准确预测的轻量级、低保真度替代模型。

Conclusion: SINDy和LSTM可以准确地对近地轨道上的空间目标种群进行建模，以预测未来卫星和碎片传播。

Abstract: Utilizing the Sparse Identification of Nonlinear Dynamics algorithm (SINDy)
and Long Short-Term Memory Recurrent Neural Networks (LSTM), the population of
resident space objects, divided into Active, Derelict, and Debris, in LEO can
be accurately modeled to predict future satellite and debris propagation. This
proposed approach makes use of a data set coming from a computational expensive
high-fidelity model, the MOCAT-MC, to provide a light, low-fidelity counterpart
that provides accurate forecasting in a shorter time frame.

</details>


### [192] [Counterfactual Explanations in Medical Imaging: Exploring SPN-Guided Latent Space Manipulation](https://arxiv.org/abs/2507.19368)
*Julia Siekiera,Stefan Kramer*

Main category: cs.LG

TL;DR: 本研究提出了一种新方法，利用SPN对VAE的潜在空间进行建模，以生成高质量、可解释的反事实解释，解决了深度学习模型的可解释性问题，并在cheXpert数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习模型（尤其是在医学影像分析领域）作为黑箱系统而引起的可靠性和可解释性问题，并克服生成符合相似性约束和人类可理解性的反事实解释的挑战。

Method: 提出了一种模型特定的优化方法，通过使用SPN对VAE的潜在空间进行建模，利用其作为潜在空间描述符和分类器的双重作用，来优化反事实样本。

Result: 实验证明，与基线方法相比，SPN引导的潜在空间操纵在反事实生成方面更有效，并分析了潜在变量正则化与反事实质量之间的权衡。

Conclusion: 通过将SPN（和积网络）应用于VAE（变分自编码器）的潜在空间，实现了既接近原始数据分布又与目标类别分布对齐的潜在空间反事实。

Abstract: Artificial intelligence is increasingly leveraged across various domains to
automate decision-making processes that significantly impact human lives. In
medical image analysis, deep learning models have demonstrated remarkable
performance. However, their inherent complexity makes them black box systems,
raising concerns about reliability and interpretability. Counterfactual
explanations provide comprehensible insights into decision processes by
presenting hypothetical "what-if" scenarios that alter model classifications.
By examining input alterations, counterfactual explanations provide patterns
that influence the decision-making process. Despite their potential, generating
plausible counterfactuals that adhere to similarity constraints providing
human-interpretable explanations remains a challenge. In this paper, we
investigate this challenge by a model-specific optimization approach. While
deep generative models such as variational autoencoders (VAEs) exhibit
significant generative power, probabilistic models like sum-product networks
(SPNs) efficiently represent complex joint probability distributions. By
modeling the likelihood of a semi-supervised VAE's latent space with an SPN, we
leverage its dual role as both a latent space descriptor and a classifier for a
given discrimination task. This formulation enables the optimization of latent
space counterfactuals that are both close to the original data distribution and
aligned with the target class distribution. We conduct experimental evaluation
on the cheXpert dataset. To evaluate the effectiveness of the integration of
SPNs, our SPN-guided latent space manipulation is compared against a neural
network baseline. Additionally, the trade-off between latent variable
regularization and counterfactual quality is analyzed.

</details>


### [193] [FD4QC: Application of Classical and Quantum-Hybrid Machine Learning for Financial Fraud Detection A Technical Report](https://arxiv.org/abs/2507.19402)
*Matteo Cardaioli,Luca Marangoni,Giada Martini,Francesco Mazzolin,Luca Pajola,Andrea Ferretto Parodi,Alessandra Saitta,Maria Chiara Vernillo*

Main category: cs.LG

TL;DR: 
Classical models, specifically Random Forest, perform better than quantum models in fraud detection on the AML dataset. QSVM shows potential among quantum models but faces limitations. The report benchmarks quantum machine learning for financial fraud detection and suggests future research directions.


<details>
  <summary>Details</summary>
Motivation: 
The increasing complexity and volume of financial transactions pose significant challenges to traditional fraud detection systems. This technical report investigates and compares the efficacy of classical, quantum, and quantum-hybrid machine learning models for the binary classification of fraudulent financial activities.

Method: 
First, we develop a comprehensive behavioural feature engineering framework to transform raw transactional data into a rich, descriptive feature set. Second, we implement and evaluate a range of models on the IBM Anti-Money Laundering (AML) dataset. The classical baseline models include Logistic Regression, Decision Tree, Random Forest, and XGBoost. These are compared against three hybrid classic quantum algorithms architectures: a Quantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC), and a Hybrid Quantum Neural Network (HQNN). Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a practical, API-driven system architecture designed for real-world deployment, featuring a classical-first, quantum-enhanced philosophy with robust fallback mechanisms.

Result: 
Classical tree-based models, particularly Random Forest, significantly outperform the quantum counterparts in the current setup, achieving high accuracy (97.34%) and F-measure (86.95%). Among the quantum models, QSVM shows the most promise, delivering high precision (77.15%) and a low false-positive rate (1.36%), albeit with lower recall and significant computational overhead.

Conclusion: 
Our results demonstrate that classical tree-based models, particularly Random Forest, significantly outperform the quantum counterparts in the current setup, achieving high accuracy (97.34%) and F-measure (86.95%). Among the quantum models, QSVM shows the most promise, delivering high precision (77.15%) and a low false-positive rate (1.36%), albeit with lower recall and significant computational overhead. This report provides a benchmark for a real-world financial application, highlights the current limitations of quantum machine learning in this domain, and outlines promising directions for future research.

Abstract: The increasing complexity and volume of financial transactions pose
significant challenges to traditional fraud detection systems. This technical
report investigates and compares the efficacy of classical, quantum, and
quantum-hybrid machine learning models for the binary classification of
fraudulent financial activities.
  As of our methodology, first, we develop a comprehensive behavioural feature
engineering framework to transform raw transactional data into a rich,
descriptive feature set. Second, we implement and evaluate a range of models on
the IBM Anti-Money Laundering (AML) dataset. The classical baseline models
include Logistic Regression, Decision Tree, Random Forest, and XGBoost. These
are compared against three hybrid classic quantum algorithms architectures: a
Quantum Support Vector Machine (QSVM), a Variational Quantum Classifier (VQC),
and a Hybrid Quantum Neural Network (HQNN).
  Furthermore, we propose Fraud Detection for Quantum Computing (FD4QC), a
practical, API-driven system architecture designed for real-world deployment,
featuring a classical-first, quantum-enhanced philosophy with robust fallback
mechanisms.
  Our results demonstrate that classical tree-based models, particularly
\textit{Random Forest}, significantly outperform the quantum counterparts in
the current setup, achieving high accuracy (\(97.34\%\)) and F-measure
(\(86.95\%\)). Among the quantum models, \textbf{QSVM} shows the most promise,
delivering high precision (\(77.15\%\)) and a low false-positive rate
(\(1.36\%\)), albeit with lower recall and significant computational overhead.
  This report provides a benchmark for a real-world financial application,
highlights the current limitations of quantum machine learning in this domain,
and outlines promising directions for future research.

</details>


### [194] [On Arbitrary Predictions from Equally Valid Models](https://arxiv.org/abs/2507.19408)
*Sarah Lockfisch,Kristian Schwethelm,Martin Menten,Rickmer Braren,Daniel Rueckert,Alexander Ziller,Georgios Kaissis*

Main category: cs.LG

TL;DR: 模型多重性在医学中会导致对同一患者的不同预测，标准指标无法识别最优模型。集成学习和弃权策略可以解决这个问题，提高诊断可靠性。


<details>
  <summary>Details</summary>
Motivation: 在医学领域，多重模型可能对同一患者产生冲突的预测，但这种风险被低估且未得到充分解决。

Method: 通过实证分析，研究了模型多重性的程度、驱动因素和影响。实验涵盖了不同的医学任务和模型架构，并探讨了如何通过集成学习来缓解这一问题。

Result: 研究表明，标准的验证指标无法识别出唯一最优模型，并且大量的预测结果依赖于模型开发过程中的随意选择。虽然准确性并非解决模型多重性的根本方法，但通过增加模型容量提高准确性可以减少模型多重性。集成学习和弃权策略可以有效缓解可衡量的预测多重性，高共识度的预测可以用于自动化分类。

Conclusion: 模型多重性在医学领域具有重要的临床意义，需要通过集成方法来提高诊断的可靠性。当模型未能达成足够共识时，建议将决策交给专家审查。

Abstract: Model multiplicity refers to the existence of multiple machine learning
models that describe the data equally well but may produce different
predictions on individual samples. In medicine, these models can admit
conflicting predictions for the same patient -- a risk that is poorly
understood and insufficiently addressed.
  In this study, we empirically analyze the extent, drivers, and ramifications
of predictive multiplicity across diverse medical tasks and model
architectures, and show that even small ensembles can mitigate/eliminate
predictive multiplicity in practice. Our analysis reveals that (1) standard
validation metrics fail to identify a uniquely optimal model and (2) a
substantial amount of predictions hinges on arbitrary choices made during model
development. Using multiple models instead of a single model reveals instances
where predictions differ across equally plausible models -- highlighting
patients that would receive arbitrary diagnoses if any single model were used.
In contrast, (3) a small ensemble paired with an abstention strategy can
effectively mitigate measurable predictive multiplicity in practice;
predictions with high inter-model consensus may thus be amenable to automated
classification. While accuracy is not a principled antidote to predictive
multiplicity, we find that (4) higher accuracy achieved through increased model
capacity reduces predictive multiplicity.
  Our findings underscore the clinical importance of accounting for model
multiplicity and advocate for ensemble-based strategies to improve diagnostic
reliability. In cases where models fail to reach sufficient consensus, we
recommend deferring decisions to expert review.

</details>


### [195] [Step-3 is Large yet Affordable: Model-system Co-design for Cost-effective Decoding](https://arxiv.org/abs/2507.19427)
*StepFun,:,Bin Wang,Bojun Wang,Changyi Wan,Guanzhe Huang,Hanpeng Hu,Haonan Jia,Hao Nie,Mingliang Li,Nuo Chen,Siyu Chen,Song Yuan,Wuxun Xie,Xiaoniu Song,Xing Chen,Xingping Yang,Xuelin Zhang,Yanbo Yu,Yaoyu Wang,Yibo Zhu,Yimin Jiang,Yu Zhou,Yuanwei Lu,Houyi Li,Jingcheng Hu,Ka Man Lo,Ailin Huang,Binxing Jiao,Bo Li,Boyu Chen,Changxin Miao,Chang Lou,Chen Hu,Chen Xu,Chenfeng Yu,Chengyuan Yao,Daokuan Lv,Dapeng Shi,Deshan Sun,Ding Huang,Dingyuan Hu,Dongqing Pang,Enle Liu,Fajie Zhang,Fanqi Wan,Gulin Yan,Han Zhang,Han Zhou,Hanghao Wu,Hangyu Guo,Hanqi Chen,Hanshan Zhang,Hao Wu,Haocheng Zhang,Haolong Yan,Haoran Lv,Haoran Wei,Hebin Zhou,Heng Wang,Heng Wang,Hongxin Li,Hongyu Zhou,Hongyuan Wang,Huiyong Guo,Jia Wang,Jiahao Gong,Jialing Xie,Jian Zhou,Jianjian Sun,Jiaoren Wu,Jiaran Zhang,Jiayu Liu,Jie Cheng,Jie Luo,Jie Yan,Jie Yang,Jieyi Hou,Jinguang Zhang,Jinlan Cao,Jisheng Yin,Junfeng Liu,Junhao Huang,Junzhe Lin,Kaijun Tan,Kaixiang Li,Kang An,Kangheng Lin,Kenkun Liu,Lei Yang,Liang Zhao,Liangyu Chen,Lieyu Shi,Liguo Tan,Lin Lin,Lin Zhang,Lina Chen,Liwen Huang,Liying Shi,Longlong Gu,Mei Chen,Mengqiang Ren,Ming Li,Mingzhe Chen,Na Wang,Nan Wu,Qi Han,Qian Zhao,Qiang Zhang,Qianni Liu,Qiaohui Chen,Qiling Wu,Qinglin He,Qinyuan Tan,Qiufeng Wang,Qiuping Wu,Qiuyan Liang,Quan Sun,Rui Li,Ruihang Miao,Ruosi Wan,Ruyan Guo,Shangwu Zhong,Shaoliang Pang,Shengjie Fan,Shijie Shang,Shilei Jiang,Shiliang Yang,Shiming Hao,Shuli Gao,Siming Huang,Siqi Liu,Tiancheng Cao,Tianhao Cheng,Tianhao Peng,Wang You,Wei Ji,Wen Sun,Wenjin Deng,Wenqing He,Wenzhen Zheng,Xi Chen,Xiangwen Kong,Xianzhen Luo,Xiaobo Yang,Xiaojia Liu,Xiaoxiao Ren,Xin Han,Xin Li,Xin Wu,Xu Zhao,Yanan Wei,Yang Li,Yangguang Li,Yangshijie Xu,Yanming Xu,Yaqiang Shi,Yeqing Shen,Yi Yang,Yifei Yang,Yifeng Gong,Yihan Chen,Yijing Yang,Yinmin Zhang,Yizhuang Zhou,Yuanhao Ding,Yuantao Fan,Yuanzhen Yang,Yuchu Luo,Yue Peng,Yufan Lu,Yuhang Deng,Yuhe Yin,Yujie Liu,Yukun Chen,Yuling Zhao,Yun Mou,Yunlong Li,Yunzhou Ju,Yusheng Li,Yuxiang Yang,Yuxiang Zhang,Yuyang Chen,Zejia Weng,Zhe Xie,Zheng Ge,Zheng Gong,Zhenyi Lu,Zhewei Huang,Zhichao Chang,Zhiguo Huang,Zhirui Wang,Zidong Yang,Zili Wang,Ziqi Wang,Zixin Zhang,Binxing Jiao,Daxin Jiang,Heung-Yeung Shum,Xiangyu Zhang*

Main category: cs.LG

TL;DR: Step-3是一个321B参数的视觉语言模型（VLM），通过多矩阵分解注意力（MFA）和注意力-FFN解耦（AFD）系统优化解码成本，实现了比DeepSeek-V3更高的吞吐量和更低的成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLMs）在解码过程中，尤其是在长上下文推理任务中，硬件效率低下的问题，并最小化解码成本。

Method: Step-3采用了硬件感知的模型-系统协同设计，引入了多矩阵分解注意力（MFA）机制以减小KV缓存和计算量，并实现了注意力-FFN解耦（AFD）分布式推理系统，将注意力和前馈网络层分离到专门的子系统中。

Result: Step-3在解码成本上相比DeepSeek-V3和Qwen3 MoE 235B有显著降低，并且在长上下文条件下优势更明显。在相同的硬件和设置下（Hopper GPU，4K上下文，FP8，无MTP），Step-3实现了每GPU每秒4,039个词元（tokens）的解码吞吐量，超过了DeepSeek-V3的2,324个词元/秒/GPU，并在LLM解码领域树立了新的帕累托前沿。

Conclusion: Step-3通过其创新的多矩阵分解注意力（MFA）机制和注意力-FFN解耦（AFD）分布式推理系统，在长上下文推理任务中实现了硬件效率的显著提升，并在成本效益方面设定了新的基准。

Abstract: Large language models (LLMs) face low hardware efficiency during decoding,
especially for long-context reasoning tasks. This paper introduces Step-3, a
321B-parameter VLM with hardware-aware model-system co-design optimized for
minimizing decoding costs. Step-3 innovates in two key dimensions: (1) A novel
Multi-Matrix Factorization Attention (MFA) mechanism that significantly reduces
both KV cache size and computation while maintaining high attention
expressiveness, and (2) Attention-FFN Disaggregation (AFD), a distributed
inference system that decouples attention and Feed-Forward Network (FFN) layers
into specialized subsystems. This co-design achieves unprecedented cost
efficiency: Step-3 significantly reduces theoretical decoding costs compared
with models like DeepSeek-V3 and Qwen3 MoE 235B, with the gains widening at
longer context. Step-3 achieves low cost while activating 38B parameters per
token (more than DeepSeek-V3 and Qwen3 MoE 235B), demonstrating that
hardware-aligned attention arithmetic intensity, MoE sparsity, and AFD are
critical to cost-effectiveness. We perform a head-to-head comparison with
DeepSeek-V3 in its favorable scenarios. Our implementation on Hopper GPUs
achieves a decoding throughput of up to 4,039 tokens per second per GPU under
50ms TPOT SLA (4K context, FP8, no MTP). It is higher than DeepSeek-V3's 2,324
in the same setup and sets a new Pareto frontier for LLM decoding.

</details>


### [196] [Observations Meet Actions: Learning Control-Sufficient Representations for Robust Policy Generalization](https://arxiv.org/abs/2507.19437)
*Yuliang Gu,Hongpeng Cao,Marco Caccamo,Naira Hovakimyan*

Main category: cs.LG

TL;DR: BCPO算法通过将上下文强化学习视为双重推理-控制问题，并优化ELBO目标函数，实现了有效的表示学习和策略学习，在样本效率和泛化能力上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了在训练范围之外部署强化学习（RL）代理，需要捕获潜在的变化（“上下文”）。

Method: 提出了一种将上下文强化学习重构为双重推理-控制问题的形式化方法，并推导了一个上下文证据下界（ELBO）风格的目标函数，该函数将表示学习与策略学习清晰地分离，并使用带有瓶颈上下文策略优化（BCPO）的算法进行优化。

Result: BCPO在具有变化的物理参数的标准连续控制基准测试中，能够匹配或超越其他基线方法，同时使用的样本更少，并且在训练范围之外能保持良好的性能。

Conclusion: 该框架统一了上下文强化学习的理论、诊断和实践。

Abstract: Capturing latent variations ("contexts") is key to deploying
reinforcement-learning (RL) agents beyond their training regime. We recast
context-based RL as a dual inference-control problem and formally characterize
two properties and their hierarchy: observation sufficiency (preserving all
predictive information) and control sufficiency (retaining decision-making
relevant information). Exploiting this dichotomy, we derive a contextual
evidence lower bound(ELBO)-style objective that cleanly separates
representation learning from policy learning and optimizes it with Bottlenecked
Contextual Policy Optimization (BCPO), an algorithm that places a variational
information-bottleneck encoder in front of any off-policy policy learner. On
standard continuous-control benchmarks with shifting physical parameters, BCPO
matches or surpasses other baselines while using fewer samples and retaining
performance far outside the training regime. The framework unifies theory,
diagnostics, and practice for context-based RL.

</details>


### [197] [Forest-Guided Clustering -- Shedding Light into the Random Forest Black Box](https://arxiv.org/abs/2507.19455)
*Lisa Barros de Andrade e Sousa,Gregor Miller,Ronan Le Gleut,Dominik Thalmeier,Helena Pelin,Marie Piraud*

Main category: cs.LG

TL;DR: FGC 是一种新的可解释性方法，它通过聚类来解释随机森林模型，提高了可解释性，并在生物医学领域显示出有用的结果。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型越来越多地部署在敏感应用领域，对可解释和可信赖的决策制定需求不断增加。随机森林（RF）虽然广泛使用且在表格数据上表现强劲，但由于其集成性质，仍然难以解释。

Method: FGC 是一种模型特定的可解释性方法，通过根据共享决策路径对实例进行分组来揭示随机森林（RF）中的局部和全局结构。FGC 产生与模型内部逻辑一致的人类可解释的聚类，并计算特定于聚类和全局的特征重要性分数，以推导 RF 预测的潜在决策规则。

Result: FGC 在基准数据集上准确地恢复了潜在的子类结构，并且其性能优于经典的聚类和事后解释方法。在 AML 转录组学数据集上的应用揭示了生物学上连贯的亚群，将疾病相关信号与混淆因素分离，并恢复了已知的和新的基因表达模式。

Conclusion: FGC 桥接了性能和可解释性之间的差距，提供了超越特征级别归因的、具有结构意识的见解。

Abstract: As machine learning models are increasingly deployed in sensitive application
areas, the demand for interpretable and trustworthy decision-making has
increased. Random Forests (RF), despite their widespread use and strong
performance on tabular data, remain difficult to interpret due to their
ensemble nature. We present Forest-Guided Clustering (FGC), a model-specific
explainability method that reveals both local and global structure in RFs by
grouping instances according to shared decision paths. FGC produces
human-interpretable clusters aligned with the model's internal logic and
computes cluster-specific and global feature importance scores to derive
decision rules underlying RF predictions. FGC accurately recovered latent
subclass structure on a benchmark dataset and outperformed classical clustering
and post-hoc explanation methods. Applied to an AML transcriptomic dataset, FGC
uncovered biologically coherent subpopulations, disentangled disease-relevant
signals from confounders, and recovered known and novel gene expression
patterns. FGC bridges the gap between performance and interpretability by
providing structure-aware insights that go beyond feature-level attribution.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [198] [XAI-Guided Analysis of Residual Networks for Interpretable Pneumonia Detection in Paediatric Chest X-rays](https://arxiv.org/abs/2507.18647)
*Rayyan Ridwan*

Main category: eess.IV

TL;DR: 提出一种可解释的深度学习模型，使用ResNet-50和BayesGrad-CAM在胸部X光片上诊断小儿肺炎，准确性达到95.94%。


<details>
  <summary>Details</summary>
Motivation: 肺炎仍然是全球儿童死亡的主要原因之一，因此需要快速准确的诊断工具。

Method: 提出一个基于残差网络（ResNets）的可解释的深度学习模型，用于在胸部X光片上自动诊断小儿肺炎。通过贝叶斯梯度加权类激活映射（BayesGrad-CAM）增强可解释性，量化视觉解释中的不确定性，并提供可解释模型决策过程的空间位置。

Result: 在大型小儿胸部X光片数据集上训练的ResNet-50模型在分类准确性（95.94%）、AUC-ROC（98.91%）和Cohen's Kappa（0.913）方面取得了高分，并附有临床上具有意义的视觉解释。

Conclusion: 高性能和可解释性对于临床人工智能部署不仅是可行的，而且是至关重要的。

Abstract: Pneumonia remains one of the leading causes of death among children
worldwide, underscoring a critical need for fast and accurate diagnostic tools.
In this paper, we propose an interpretable deep learning model on Residual
Networks (ResNets) for automatically diagnosing paediatric pneumonia on chest
X-rays. We enhance interpretability through Bayesian Gradient-weighted Class
Activation Mapping (BayesGrad-CAM), which quantifies uncertainty in visual
explanations, and which offers spatial locations accountable for the
decision-making process of the model. Our ResNet-50 model, trained on a large
paediatric chest X-rays dataset, achieves high classification accuracy
(95.94%), AUC-ROC (98.91%), and Cohen's Kappa (0.913), accompanied by
clinically meaningful visual explanations. Our findings demonstrate that high
performance and interpretability are not only achievable but critical for
clinical AI deployment.

</details>


### [199] [Learned Single-Pixel Fluorescence Microscopy](https://arxiv.org/abs/2507.18740)
*Serban C. Tudosie,Valerio Gandolfi,Shivaprasad Varakkoth,Andrea Farina,Cosimo D'Andrea,Simon Arridge*

Main category: eess.IV

TL;DR: 通过自监督学习优化单像素荧光显微镜的测量和重建过程，显著提高成像速度和质量，并实现多光谱成像。


<details>
  <summary>Details</summary>
Motivation: 传统的单像素成像技术在荧光显微镜中需要快速采集和重建图像，但现有的基于总变差最小化的重建方法在处理噪声数据时效率不高。因此，需要一种能够利用数据来学习测量向量和重建过程的方法，以提高压缩、重建质量和速度。

Method: 本研究提出了一种利用自监督学习训练自动编码器的方法，该编码器能够学习测量矩阵（编码器）和重建过程（解码器），并将学习到的编码器集成到物理设备中进行数据采集。

Result: 实验结果表明，所提出的方法能够将单像素荧光显微镜的重建时间缩短两个数量级，同时实现比传统方法更好的图像质量，并成功实现了多光谱重建。

Conclusion: 这项研究提出的基于学习的单像素荧光显微镜技术，通过训练自监督自动编码器来学习测量矩阵和重建过程，能够将重建时间缩短两个数量级，并提高图像质量，实现多光谱重建，有潜力降低成本，推动诊断和生物研究的发展。

Abstract: Single-pixel imaging has emerged as a key technique in fluorescence
microscopy, where fast acquisition and reconstruction are crucial. In this
context, images are reconstructed from linearly compressed measurements. In
practice, total variation minimisation is still used to reconstruct the image
from noisy measurements of the inner product between orthogonal sampling
pattern vectors and the original image data. However, data can be leveraged to
learn the measurement vectors and the reconstruction process, thereby enhancing
compression, reconstruction quality, and speed. We train an autoencoder through
self-supervision to learn an encoder (or measurement matrix) and a decoder. We
then test it on physically acquired multispectral and intensity data. During
acquisition, the learned encoder becomes part of the physical device. Our
approach can enhance single-pixel imaging in fluorescence microscopy by
reducing reconstruction time by two orders of magnitude, achieving superior
image quality, and enabling multispectral reconstructions. Ultimately, learned
single-pixel fluorescence microscopy could advance diagnosis and biological
research, providing multispectral imaging at a fraction of the cost.

</details>


### [200] [RealDeal: Enhancing Realism and Details in Brain Image Generation via Image-to-Image Diffusion Models](https://arxiv.org/abs/2507.18830)
*Shen Zhu,Yinzhu Jin,Tyler Spears,Ifrah Zawar,P. Thomas Fletcher*

Main category: eess.IV

TL;DR: 我们提出了一种图像到图像的扩散模型（RealDeal），用于提高生成大脑图像的真实感和细节。该模型通过引入清晰的边缘、精细的纹理、细微的解剖特征和成像噪声来优化 LDM 生成的图像，并使用多种指标进行评估，证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在扩散模型（LDM）在生成大脑 MRI 方面取得了最先进的成果，但由于潜在压缩，生成的图像过于平滑，缺乏真实图像中常见的精细解剖结构和扫描采集噪声。因此，需要一种能够提高真实感和添加细节的模型。

Method: 提出了一种图像到图像的扩散模型，该模型通过引入清晰的边缘、精细的纹理、细微的解剖特征和成像噪声来提高生成大脑图像的真实感和细节。该模型对 LDM 生成的图像质量进行优化，并使用 FID 和 LPIPS 等常用指标进行评估。

Result: FID 和 LPIPS 等常用指标以及图像噪声分布、清晰度和纹理方面的新指标表明，我们提出的 RealDeal 模型能够生成更真实的大脑图像。

Conclusion: 图像到图像的扩散模型可以提高生成大脑图像的真实感和细节，通过引入清晰的边缘、精细的纹理、细微的解剖特征和成像噪声。

Abstract: We propose image-to-image diffusion models that are designed to enhance the
realism and details of generated brain images by introducing sharp edges, fine
textures, subtle anatomical features, and imaging noise. Generative models have
been widely adopted in the biomedical domain, especially in image generation
applications. Latent diffusion models achieve state-of-the-art results in
generating brain MRIs. However, due to latent compression, generated images
from these models are overly smooth, lacking fine anatomical structures and
scan acquisition noise that are typically seen in real images. This work
formulates the realism enhancing and detail adding process as image-to-image
diffusion models, which refines the quality of LDM-generated images. We employ
commonly used metrics like FID and LPIPS for image realism assessment.
Furthermore, we introduce new metrics to demonstrate the realism of images
generated by RealDeal in terms of image noise distribution, sharpness, and
texture.

</details>


### [201] [Dealing with Segmentation Errors in Needle Reconstruction for MRI-Guided Brachytherapy](https://arxiv.org/abs/2507.18895)
*Vangelis Kostoulas,Arthur Guijt,Ellen M. Kerkhof,Bradley R. Pieters,Peter A. N. Bosman,Tanja Alderliesten*

Main category: eess.IV

TL;DR: 通过改进后处理技术，提高了放射性针重建的准确性，有效解决了深度学习分割中的错误问题。


<details>
  <summary>Details</summary>
Motivation: 手动标注放射性针耗时耗力，现有的自动重建方法（分割+后处理）对分割错误不够鲁棒，需要改进后处理技术来提高重建准确性。

Method: 提出了一种改进的后处理技术，以应对深度学习分割的不足，并提高放射性针重建的准确性。

Result: 在基于 MRI 的前列腺癌数据集上，所提出的后处理技术有效管理了分割错误，在针尖、针底和轴向误差方面均达到了较低的中值误差（分别为 1.07mm，0.43mm 和 0.75mm），并且在测试集上实现了零假阳性和假阴性针。

Conclusion: 本研究提出了一种改进的后处理技术，用于处理深度学习分割中的错误，从而提高放射性针重建的准确性。实验结果表明，该方法能够有效管理分割错误，在进行临床前瞻性研究的试验中，在针尖和针尖定位方面分别实现了 1.07 毫米（IQR ± 1.04 毫米）和 0.43 毫米（IQR ± 0.46 毫米）的中值误差，以及 0.75 毫米（IQR ± 0.69 毫米）的中值轴误差，且假阳性和假阴性针数量为零。

Abstract: Brachytherapy involves bringing a radioactive source near tumor tissue using
implanted needles. Image-guided brachytherapy planning requires amongst others,
the reconstruction of the needles. Manually annotating these needles on patient
images can be a challenging and time-consuming task for medical professionals.
For automatic needle reconstruction, a two-stage pipeline is commonly adopted,
comprising a segmentation stage followed by a post-processing stage. While deep
learning models are effective for segmentation, their results often contain
errors. No currently existing post-processing technique is robust to all
possible segmentation errors. We therefore propose adaptations to existing
post-processing techniques mainly aimed at dealing with segmentation errors and
thereby improving the reconstruction accuracy. Experiments on a prostate cancer
dataset, based on MRI scans annotated by medical professionals, demonstrate
that our proposed adaptations can help to effectively manage segmentation
errors, with the best adapted post-processing technique achieving median
needle-tip and needle-bottom point localization errors of $1.07$ (IQR $\pm
1.04$) mm and $0.43$ (IQR $\pm 0.46$) mm, respectively, and median shaft error
of $0.75$ (IQR $\pm 0.69$) mm with 0 false positive and 0 false negative
needles on a test set of 261 needles.

</details>


### [202] [Dual Path Learning -- learning from noise and context for medical image denoising](https://arxiv.org/abs/2507.19035)
*Jitindra Fartiyal,Pedro Freire,Yasmeen Whayeb,James S. Wolffsohn,Sergei K. Turitsyn,Sergei G. Sokolov*

Main category: eess.IV

TL;DR: 提出了一种双路径学习（DPL）模型，通过结合噪声和上下文信息，在多种医学成像模态和噪声类型上实现了鲁棒且泛化的去噪效果，相比基线UNet，PSNR提升了3.35%。


<details>
  <summary>Details</summary>
Motivation: 现有的去噪方法通常依赖于噪声特征或图像的上下文信息，并且通常是针对单一成像模态和噪声类型开发的。受Geng等人的CNCL研究启发，该研究旨在整合噪声和上下文信息，以提高医学图像去噪的性能和泛化能力。

Method: 提出了一种双路径学习（DPL）模型架构，该模型结合了噪声和上下文信息，并通过融合这些信息来生成最终输出，以实现医学图像去噪。

Result: DPL模型在多种成像模态和各种噪声类型上进行了评估，证明了其鲁棒性和泛化能力。当在所有模态上训练并处理高斯噪声时，DPL相比于基线UNet，PSNR提高了3.35%。

Conclusion: DPL在处理高斯噪声时，相比于基线UNet，在所有模态上训练可将PSNR提高3.35%，证明了其鲁棒性和泛化能力。

Abstract: Medical imaging plays a critical role in modern healthcare, enabling
clinicians to accurately diagnose diseases and develop effective treatment
plans. However, noise, often introduced by imaging devices, can degrade image
quality, leading to misinterpretation and compromised clinical outcomes.
Existing denoising approaches typically rely either on noise characteristics or
on contextual information from the image. Moreover, they are commonly developed
and evaluated for a single imaging modality and noise type. Motivated by Geng
et.al CNCL, which integrates both noise and context, this study introduces a
Dual-Pathway Learning (DPL) model architecture that effectively denoises
medical images by leveraging both sources of information and fusing them to
generate the final output. DPL is evaluated across multiple imaging modalities
and various types of noise, demonstrating its robustness and generalizability.
DPL improves PSNR by 3.35% compared to the baseline UNet when evaluated on
Gaussian noise and trained across all modalities. The code is available at
10.5281/zenodo.15836053.

</details>


### [203] [Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model](https://arxiv.org/abs/2507.19201)
*Xin Li,Kaixiang Yang,Qiang Li,Zhiwei Wang*

Main category: eess.IV

TL;DR: GCDM 是一个用于合成乳腺钼靶图像的新框架，它通过结合软掩码嵌入和门控条件分支来解决数据不足和病变特征多样性问题，可以精确控制小病变区域并提高合成图像的真实性和多样性。


<details>
  <summary>Details</summary>
Motivation: 为了解决准确性和鲁棒的深度学习方法在数据可用性不足和病变特征多样性缺乏方面的限制，以及当前生成模型在充分强调病变特异性特征及其与周围组织的关系方面存在的不足。

Method: 提出了一种名为门控条件扩散模型（GCDM）的新颖框架，该框架建立在潜在去噪扩散框架之上，通过将噪声潜在图像与代表乳房、病变及其过渡区域的软掩码嵌入相结合，并在去噪过程中确保它们之间的解剖相干性。此外，GCDM 还包含一个门控条件分支，通过动态选择和融合病变的最相关影像组学和几何特性来指导去噪过程，以强调病变特异性特征。

Result: GCDM 实现了对小病变区域的精确控制，同时提高了合成乳腺钼靶图像的真实性和多样性。

Conclusion: GCDM 在综合和局部合成乳腺钼靶图像方面实现了精确控制，同时提高了合成乳腺钼靶图像的真实性和多样性。

Abstract: Mammography is the most commonly used imaging modality for breast cancer
screening, driving an increasing demand for deep-learning techniques to support
large-scale analysis. However, the development of accurate and robust methods
is often limited by insufficient data availability and a lack of diversity in
lesion characteristics. While generative models offer a promising solution for
data synthesis, current approaches often fail to adequately emphasize
lesion-specific features and their relationships with surrounding tissues. In
this paper, we propose Gated Conditional Diffusion Model (GCDM), a novel
framework designed to jointly synthesize holistic mammogram images and
localized lesions. GCDM is built upon a latent denoising diffusion framework,
where the noised latent image is concatenated with a soft mask embedding that
represents breast, lesion, and their transitional regions, ensuring anatomical
coherence between them during the denoising process. To further emphasize
lesion-specific features, GCDM incorporates a gated conditioning branch that
guides the denoising process by dynamically selecting and fusing the most
relevant radiomic and geometric properties of lesions, effectively capturing
their interplay. Experimental results demonstrate that GCDM achieves precise
control over small lesion areas while enhancing the realism and diversity of
synthesized mammograms. These advancements position GCDM as a promising tool
for clinical applications in mammogram synthesis. Our code is available at
https://github.com/lixinHUST/Gated-Conditional-Diffusion-Model/

</details>


### [204] [A Self-training Framework for Semi-supervised Pulmonary Vessel Segmentation and Its Application in COPD](https://arxiv.org/abs/2507.19074)
*Shuiqing Zhao,Meihuan Wang,Jiaxuan Xu,Jie Feng,Wei Qian,Rongchang Chen,Zhenyu Liang,Shouliang Qi,Yanan Wu*

Main category: eess.IV

TL;DR: 提出了一种名为Semi2的半监督方法，通过教师-学生模型进行肺血管分割，精度达到90.3%，比其他方法提高了2.3%，并可用于COPD分析。


<details>
  <summary>Details</summary>
Motivation: 准确分割和量化计算机断层扫描（CT）图像中的肺部血管，特别是较小的血管，对于慢性阻塞性肺疾病（COPD）患者至关重要。

Method: 提出了一种利用教师-学生模型进行肺血管分割的自训练框架。首先，通过交互方式对内部数据进行高质量注释，然后在半监督方式下训练模型。在少量标记的CT图像上训练一个全监督模型，得到教师模型。然后，教师模型用于为未标记的CT图像生成伪标签，并根据一定的策略选择可靠的伪标签。学生模型的训练涉及这些可靠的伪标签。这个训练过程会迭代地重复，直到达到最佳性能。

Result: 在125名COPD患者的非增强CT扫描上进行了广泛的实验。定量和定性分析表明，所提出的Semi2方法将血管分割的精度显著提高了2.3%，达到90.3%。此外，还对COPD患者的肺部血管进行了定量分析，深入了解了不同疾病严重程度下肺部血管的差异。

Conclusion: 该方法不仅可以提高肺血管分割的性能，还可以应用于慢性阻塞性肺疾病（COPD）分析。

Abstract: Background: It is fundamental for accurate segmentation and quantification of
the pulmonary vessel, particularly smaller vessels, from computed tomography
(CT) images in chronic obstructive pulmonary disease (COPD) patients.
Objective: The aim of this study was to segment the pulmonary vasculature using
a semi-supervised method. Methods: In this study, a self-training framework is
proposed by leveraging a teacher-student model for the segmentation of
pulmonary vessels. First, the high-quality annotations are acquired in the
in-house data by an interactive way. Then, the model is trained in the
semi-supervised way. A fully supervised model is trained on a small set of
labeled CT images, yielding the teacher model. Following this, the teacher
model is used to generate pseudo-labels for the unlabeled CT images, from which
reliable ones are selected based on a certain strategy. The training of the
student model involves these reliable pseudo-labels. This training process is
iteratively repeated until an optimal performance is achieved. Results:
Extensive experiments are performed on non-enhanced CT scans of 125 COPD
patients. Quantitative and qualitative analyses demonstrate that the proposed
method, Semi2, significantly improves the precision of vessel segmentation by
2.3%, achieving a precision of 90.3%. Further, quantitative analysis is
conducted in the pulmonary vessel of COPD, providing insights into the
differences in the pulmonary vessel across different severity of the disease.
Conclusion: The proposed method can not only improve the performance of
pulmonary vascular segmentation, but can also be applied in COPD analysis. The
code will be made available at
https://github.com/wuyanan513/semi-supervised-learning-for-vessel-segmentation.

</details>


### [205] [Learned Image Compression with Hierarchical Progressive Context Modeling](https://arxiv.org/abs/2507.19125)
*Yuqi Li,Haotian Zhang,Li Li,Dong Liu*

Main category: eess.IV

TL;DR: 提出了一种名为HPCM的新模型，通过层次化和渐进的方式改进图像压缩中的上下文建模，实现了更优的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地获取上下文信息，解决现有方法在有效利用长程依赖和不同编码步骤中的多样化上下文信息方面存在的不足。

Method: 提出了一种新颖的层次化渐进上下文模型（HPCM），采用层次化编码调度顺序建模多尺度潜在变量之间的上下文依赖，并通过渐进上下文融合机制融合先前编码步骤的上下文信息。

Result: 实验结果表明，该方法在率失真性能上达到了最先进的水平，并且在压缩性能和计算复杂度之间取得了更好的平衡。

Conclusion: 该方法在率失真性能上达到了最先进的水平，并在压缩性能和计算复杂度之间取得了更好的平衡。

Abstract: Context modeling is essential in learned image compression for accurately
estimating the distribution of latents. While recent advanced methods have
expanded context modeling capacity, they still struggle to efficiently exploit
long-range dependency and diverse context information across different coding
steps. In this paper, we introduce a novel Hierarchical Progressive Context
Model (HPCM) for more efficient context information acquisition. Specifically,
HPCM employs a hierarchical coding schedule to sequentially model the
contextual dependencies among latents at multiple scales, which enables more
efficient long-range context modeling. Furthermore, we propose a progressive
context fusion mechanism that incorporates contextual information from previous
coding steps into the current step, effectively exploiting diverse contextual
information. Experimental results demonstrate that our method achieves
state-of-the-art rate-distortion performance and strikes a better balance
between compression performance and computational complexity. The code is
available at https://github.com/lyq133/LIC-HPCM.

</details>


### [206] [Reconstruct or Generate: Exploring the Spectrum of Generative Modeling for Cardiac MRI](https://arxiv.org/abs/2507.19186)
*Niklas Bubeck,Yundi Zhang,Suprosanna Shit,Daniel Rueckert,Jiazhen Pan*

Main category: eess.IV

TL;DR: 本研究对扩散模型和自回归模型在医学成像中的重建和生成任务进行了基准测试，发现扩散模型在生成质量上更优，但在重建时容易出错，而自回归模型在重建时更稳定但生成质量稍逊。


<details>
  <summary>Details</summary>
Motivation: 在医学成像中，生成模型被用于重建（如修复、超分辨率）和生成（如数据增强、反事实分析）任务。尽管它们具有相似的架构和学习框架，但目标不同：生成关注感知质量和多样性，而重建关注数据保真度和准确性。本研究旨在系统地分析现代潜在扩散模型和自语言模型如何在重建-生成谱中进行权衡。

Method: 通过分析现代潜在扩散模型和自回归模型在重建-生成谱中的表现，并针对不同掩膜比例和采样策略的心脏医学成像图像修复任务以及无条件图像生成任务对一系列生成模型进行基准测试。

Result: 研究结果表明，扩散模型在无条件生成任务中表现出更好的感知质量，但在图像修复任务中，随着掩膜比例的增加，它们会产生更多的虚假信息。相比之下，自回归模型在不同掩膜比例下都能保持稳定的感知性能，但其保真度普遍较低。

Conclusion: 扩散模型在无条件生成方面提供卓越的感知质量，但在掩膜比例增加时容易产生幻觉，而自回归模型在不同掩膜比例下保持稳定的感知性能，但保真度通常较低。

Abstract: In medical imaging, generative models are increasingly relied upon for two
distinct but equally critical tasks: reconstruction, where the goal is to
restore medical imaging (usually inverse problems like inpainting or
superresolution), and generation, where synthetic data is created to augment
datasets or carry out counterfactual analysis. Despite shared architecture and
learning frameworks, they prioritize different goals: generation seeks high
perceptual quality and diversity, while reconstruction focuses on data fidelity
and faithfulness. In this work, we introduce a "generative model zoo" and
systematically analyze how modern latent diffusion models and autoregressive
models navigate the reconstruction-generation spectrum. We benchmark a suite of
generative models across representative cardiac medical imaging tasks, focusing
on image inpainting with varying masking ratios and sampling strategies, as
well as unconditional image generation. Our findings show that diffusion models
offer superior perceptual quality for unconditional generation but tend to
hallucinate as masking ratios increase, whereas autoregressive models maintain
stable perceptual performance across masking levels, albeit with generally
lower fidelity.

</details>


### [207] [Unstable Prompts, Unreliable Segmentations: A Challenge for Longitudinal Lesion Analysis](https://arxiv.org/abs/2507.19230)
*Niels Rocholl,Ewoud Smit,Mathias Prokop,Alessa Hering*

Main category: eess.IV

TL;DR: ULS23 模型在纵向分析中表现不佳，主要由于其对病灶居中的假设以及对层间配准错误的敏感性。未来的纵向分析需要集成化的、为时间分析设计的模型。


<details>
  <summary>Details</summary>
Motivation: 长期的病灶分析对于肿瘤学护理至关重要，但自动化工具常常难以保证时间一致性。本研究旨在探究 ULS23 分割模型在纵向分析中的性能表现。

Method: 本研究使用公开的临床数据集，包含基线和随访 CT 扫描，评估了 ULS23 分割模型在纵向场景下的表现，通过人为位移输入体积与真实病灶中心相对位置来探测模型的脆弱性。

Result: 研究发现，ULS23 模型在纵向分析中的性能表现高度依赖于其对病灶居中的假设；当病灶发生足够位移时，分割精度会急剧下降。研究还识别出两种关键的、相互关联的失败模式：随访病例中由于层间配准错误导致的分割质量急剧下降，以及随后进行的病灶对应过程的崩溃。

Conclusion: 单时间点分割模型应用于纵向数据存在根本性局限，稳健的肿瘤纵向分析需要从级联的单一目的工具转向集成、端到端的、本质上为时间分析而设计的模型。

Abstract: Longitudinal lesion analysis is crucial for oncological care, yet automated
tools often struggle with temporal consistency. While universal lesion
segmentation models have advanced, they are typically designed for single time
points. This paper investigates the performance of the ULS23 segmentation model
in a longitudinal context. Using a public clinical dataset of baseline and
follow-up CT scans, we evaluated the model's ability to segment and track
lesions over time. We identified two critical, interconnected failure modes: a
sharp degradation in segmentation quality in follow-up cases due to inter-scan
registration errors, and a subsequent breakdown of the lesion correspondence
process. To systematically probe this vulnerability, we conducted a controlled
experiment where we artificially displaced the input volume relative to the
true lesion center. Our results demonstrate that the model's performance is
highly dependent on its assumption of a centered lesion; segmentation accuracy
collapses when the lesion is sufficiently displaced. These findings reveal a
fundamental limitation of applying single-timepoint models to longitudinal
data. We conclude that robust oncological tracking requires a paradigm shift
away from cascading single-purpose tools towards integrated, end-to-end models
inherently designed for temporal analysis.

</details>


### [208] [NerT-CA: Efficient Dynamic Reconstruction from Sparse-view X-ray Coronary Angiography](https://arxiv.org/abs/2507.19328)
*Kirsten W. H. Maas,Danny Ruijters,Nicola Pezzotti,Anna Vilanova*

Main category: eess.IV

TL;DR: NerT-CA是一种结合神经和张量表示的新方法，用于加速稀疏视角下的4D冠状动脉重建，提高了训练速度和重建精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决X射线冠状动脉血管造影（CA）进行3D和4D重建时面临的挑战，如血管结构稀疏、背景与血管区分度差、视角稀疏以及扫描内运动。现有方法依赖耗时的手动或易出错的自动分割，限制了临床应用。

Method: 提出了一种名为NerT-CA的混合方法，结合了神经和张量表示。该方法将冠状动脉场景建模为低秩和稀疏分量的分解，利用快速张量场进行低秩静态重建，并利用神经场进行动态稀疏重建。

Result: NerT-CA在训练时间和重建准确性方面均优于现有方法，并且可以从最少三个造影视图中获得合理的重建效果。

Conclusion: NerT-CA通过结合神经和张量表示，利用张量场进行静态重建和神经场进行动态重建，在稀疏视角下实现了加速的4D冠状动脉重建。该方法在训练时间和重建准确性方面优于现有技术，并且仅需三个视角即可获得合理的重建效果。

Abstract: Three-dimensional (3D) and dynamic 3D+time (4D) reconstruction of coronary
arteries from X-ray coronary angiography (CA) has the potential to improve
clinical procedures. However, there are multiple challenges to be addressed,
most notably, blood-vessel structure sparsity, poor background and blood vessel
distinction, sparse-views, and intra-scan motion. State-of-the-art
reconstruction approaches rely on time-consuming manual or error-prone
automatic segmentations, limiting clinical usability. Recently, approaches
based on Neural Radiance Fields (NeRF) have shown promise for automatic
reconstructions in the sparse-view setting. However, they suffer from long
training times due to their dependence on MLP-based representations. We propose
NerT-CA, a hybrid approach of Neural and Tensorial representations for
accelerated 4D reconstructions with sparse-view CA. Building on top of the
previous NeRF-based work, we model the CA scene as a decomposition of low-rank
and sparse components, utilizing fast tensorial fields for low-rank static
reconstruction and neural fields for dynamic sparse reconstruction. Our
approach outperforms previous works in both training time and reconstruction
accuracy, yielding reasonable reconstructions from as few as three angiogram
views. We validate our approach quantitatively and qualitatively on
representative 4D phantom datasets.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [209] [An Explainable Equity-Aware P2P Energy Trading Framework for Socio-Economically Diverse Microgrid](https://arxiv.org/abs/2507.18738)
*Abhijan Theja,Mayukha Pal*

Main category: eess.SY

TL;DR: 本研究提出了一种基于强化学习和合作博弈论的框架，用于社区微电网的公平能源分配，通过动态调整实现可持续和公平的能源社区。


<details>
  <summary>Details</summary>
Motivation: 为了解决社区微电网中能源公平分配的挑战，特别是服务于社会经济背景多样化的参与者时，现有的静态优化和成本分摊方法往往无法适应不断变化的 and inequitable situations，从而导致参与者不满和合作不可持续。

Method: 本研究提出了一种整合了多目标混合整数线性规划（MILP）、合作博弈论和由强化学习（RL）驱动的动态公平性调整机制的创新框架。该框架的核心是基于公平福利最大化（EqWM）原则的双层优化模型，并结合了Rawlsian公平性原则。研究引入了近端策略优化（PPO）智能体，该智能体能够根据观察到的成本和可再生能源接入方面的不平等情况，动态调整优化目标中的社会经济权重。此外，还使用了可解释人工智能（XAI）来解释从加权Shapley值派生的收益分配。

Result: 框架在六个实际场景中得到了验证，展示了高达72.6%的峰值需求削减和显著的合作收益。

Conclusion: 该框架通过动态调整社会经济权重，有效降低了基尼系数，为实现可持续和公平的能源社区提供了途径。

Abstract: Fair and dynamic energy allocation in community microgrids remains a critical
challenge, particularly when serving socio-economically diverse participants.
Static optimization and cost-sharing methods often fail to adapt to evolving
inequities, leading to participant dissatisfaction and unsustainable
cooperation. This paper proposes a novel framework that integrates
multi-objective mixed-integer linear programming (MILP), cooperative game
theory, and a dynamic equity-adjustment mechanism driven by reinforcement
learning (RL). At its core, the framework utilizes a bi-level optimization
model grounded in Equity-regarding Welfare Maximization (EqWM) principles,
which incorporate Rawlsian fairness to prioritize the welfare of the least
advantaged participants. We introduce a Proximal Policy Optimization (PPO)
agent that dynamically adjusts socio-economic weights in the optimization
objective based on observed inequities in cost and renewable energy access.
This RL-powered feedback loop enables the system to learn and adapt,
continuously striving for a more equitable state. To ensure transparency,
Explainable AI (XAI) is used to interpret the benefit allocations derived from
a weighted Shapley value. Validated across six realistic scenarios, the
framework demonstrates peak demand reductions of up to 72.6%, and significant
cooperative gains. The adaptive RL mechanism further reduces the Gini
coefficient over time, showcasing a pathway to truly sustainable and fair
energy communities.

</details>


### [210] [Approximating CCCV charging using SOC-dependent tapered charging power constraints in long-term microgrid planning](https://arxiv.org/abs/2507.18853)
*Hassan Zahid Butt,Xingpeng Li*

Main category: eess.SY

TL;DR: Microgrid planning models should account for battery charging power tapering at high SOC levels to accurately size batteries and ensure reliability, as constant power charging assumptions lead to potential underestimation of needs and increased costs.


<details>
  <summary>Details</summary>
Motivation: Traditional long-term microgrid planning models inaccurately assume constant power charging for BESS, ignoring efficiency losses and potential reliability issues caused by rising internal resistance at high SOC levels. This paper addresses the impracticality of CCCV at the pack level by proposing an emulation strategy.

Method: A tractable and scalable approach is proposed to approximate constant current-constant voltage (CCCV) charging behavior using SOC-dependent tapered charging power (TCP) constraints. A MATLAB-based proof of concept demonstrates the benefits, and the method is integrated into a long-term planning framework for evaluation.

Result: The evaluation under synthetic load and solar profiles demonstrates that tapering charging power significantly affects BESS sizing, cost, and reliability under dynamic operating conditions that demand fast charging. The proof of concept confirmed the energy delivery and efficiency benefits of tapering.

Conclusion: The study highlights tapering as a critical modeling factor for accurately capturing BESS performance in long-term microgrid planning, especially under dynamic operating conditions requiring fast charging. Tapering significantly affects BESS sizing, cost, and reliability.

Abstract: Traditional long-term microgrid planning models assume constant power
charging for battery energy storage systems (BESS), overlooking efficiency
losses that occur toward the end of charge due to rising internal resistance.
While this issue can be mitigated at the cell level using constant
current-constant voltage (CCCV) charging, it is impractical at the pack level
in large-scale systems. However, battery management systems and inverter
controls can emulate this effect by tapering charging power at high
state-of-charge (SOC) levels, trading off charging speed for improved
efficiency and reduced thermal stress. Ignoring this behavior in planning
models can lead to undersized batteries and potential reliability issues. This
paper proposes a tractable and scalable approach to approximate CCCV behavior
using SOC-dependent tapered charging power (TCP) constraints. A MATLAB-based
proof of concept demonstrates the energy delivery and efficiency benefits of
tapering. The method is integrated into a long-term planning framework and
evaluated under a synthetic load and solar profile. Results show tapering
significantly affects BESS sizing, cost, and reliability under dynamic
operating conditions that demand fast charging. These findings highlight
tapering as a critical modeling factor for accurately capturing BESS
performance in long-term microgrid planning.

</details>


### [211] [Enhancing Robustness of Control Barrier Function: A Reciprocal Resistance-based Approach](https://arxiv.org/abs/2507.18888)
*Xinming Wang,Zongyi Guo,Jianguo Guo,Jun Yang,Yunda Yan*

Main category: eess.SY

TL;DR: 本研究提出了一种新的基于倒数电阻的控制障碍函数（RRCBF），用于提高受扰非线性系统的鲁棒性，无需知道扰动界限。该方法通过引入“缓冲区域”来处理不确定性和扰动，并通过包含扰动观测器（DO-RRCBF）来进一步提高性能。仿真结果表明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 为了增强控制障碍函数（CBF）在存在扰动的仿射非线性系统中的鲁棒性，并且无需显式了解扰动界限。

Method: 提出了一种新的基于倒数电阻的控制障碍函数（RRCBF），并将其与传统的零控障碍函数框架相结合。通过整合倒数电阻类项，建立了基于倒数电阻的障碍函数（RRBF）的概念，并严格证明了其安全集的正向不变性及其对有界扰动的鲁棒性。在此基础上，将该概念扩展到 RRCBF 及其高阶变体。为应对复杂时变扰动，引入了基于扰动观测器的 RRCBF（DO-RRCBF），利用扰动估计来增强安全性和恢复控制性能。

Result: 所提出的 RRCBF 框架能够生成缓冲区域，有效控制不确定性和扰动的影响，并已通过二阶线性系统和自适应巡航控制场景的仿真得到验证，证明了其正向不变性和鲁棒性。

Conclusion: 该研究提出了一种新的基于倒数电阻的控制障碍函数（RRCBF），用于增强受扰仿射非线性系统的控制障碍函数的鲁棒性，且无需显式了解扰动界限。通过将倒数电阻类项整合到传统的零控障碍函数框架中，该研究正式建立了基于倒数电阻的障碍函数（RRBF）的概念，并严格证明了其相关安全集的正向不变性及其对有界扰动的鲁棒性。RRBF 在安全集边界附近自然地生成了一个缓冲区域，有效控制了不确定性和外部扰动的影响。该基础概念已扩展到 RRCBF 及其高阶变体的公式化。为了减轻复杂时变扰动下的保守性，研究还引入了一种基于扰动观测器的 RRCBF（DO-RRCBF），该方法利用扰动估计来增强安全保证并恢复标称控制性能。通过仿真研究验证了所提出框架的有效性，包括一个说明相平面正向不变性的二阶线性系统，以及一个展示高相对度系统鲁棒性的自适应巡航控制场景。

Abstract: In this note, a new reciprocal resistance-based control barrier function
(RRCBF) is developed to enhance the robustness of control barrier functions for
disturbed affine nonlinear systems, without requiring explicit knowledge of
disturbance bounds. By integrating a reciprocal resistance-like term into the
conventional zeroing barrier function framework, we formally establish the
concept of the reciprocal resistance-based barrier function (RRBF), rigorously
proving the forward invariance of its associated safe set and its robustness
against bounded disturbances. The RRBF inherently generates a buffer zone near
the boundary of the safe set, effectively dominating the influence of
uncertainties and external disturbances. This foundational concept is extended
to formulate RRCBFs, including their high-order variants. To alleviate
conservatism in the presence of complex, time-varying disturbances, we further
introduce a disturbance observer-based RRCBF (DO-RRCBF), which exploits
disturbance estimates to enhance safety guarantees and recover nominal control
performance. The effectiveness of the proposed framework is validated through
two simulation studies: a second-order linear system illustrating forward
invariance in the phase plane, and an adaptive cruise control scenario
demonstrating robustness in systems with high relative degree.

</details>


### [212] [GMM-Based Time-Varying Coverage Control](https://arxiv.org/abs/2507.18938)
*Behzad Zamani,James Kennedy,Airlie Chapman,Peter Dower,Chris Manzie,Simon Crase*

Main category: eess.SY

TL;DR: 本文提出了一种新的时变覆盖控制方法，该方法能够有效处理高斯混合模型（GMM）描述的时变密度函数，并通过最小化覆盖成本来优化无人机轨迹。该方法具有计算效率高和分布式的优点，适用于多机器人协作场景，并在羽流监测任务中得到了验证。


<details>
  <summary>Details</summary>
Motivation: 传统的时变密度函数覆盖控制方法通常会忽略密度函数的时间演化，或采用其上限值，或对其进行数值近似。这导致控制器的性能受到限制。本文旨在解决这一问题，提出一种能够有效处理时变密度函数的方法。

Method: 通过将时变密度函数建模为高斯混合模型（GMM），并考虑其随时间变化的特性，推导出一种高效的时变覆盖控制器。该控制器能够完全纳入密度函数的时间演化，并最小化整体覆盖成本。

Result: 该控制器能够有效处理时变密度函数，并最小化覆盖成本。与经典时变覆盖控制器相比，该控制器在仿真中表现出更优越的覆盖性能。此外，实验结果表明，该控制器在多机器人应用中具有实际可行性。

Conclusion: 该方法在分布式多机器人应用中具有计算效率高和分布式的特性，使其成为解决时变覆盖控制问题的理想选择。实验结果表明，无人机群在所提出控制器的指导下，能够以分布式方式跟踪模拟的时变化学羽流。

Abstract: In coverage control problems that involve time-varying density functions, the
coverage control law depends on spatial integrals of the time evolution of the
density function. The latter is often neglected, replaced with an upper bound
or calculated as a numerical approximation of the spatial integrals involved.
In this paper, we consider a special case of time-varying density functions
modeled as Gaussian Mixture Models (GMMs) that evolve with time via a set of
time-varying sources (with known corresponding velocities). By imposing this
structure, we obtain an efficient time-varying coverage controller that fully
incorporates the time evolution of the density function. We show that the
induced trajectories under our control law minimise the overall coverage cost.
We elicit the structure of the proposed controller and compare it with a
classical time-varying coverage controller, against which we benchmark the
coverage performance in simulation. Furthermore, we highlight that the
computationally efficient and distributed nature of the proposed control law
makes it ideal for multi-vehicle robotic applications involving time-varying
coverage control problems. We employ our method in plume monitoring using a
swarm of drones. In an experimental field trial we show that drones guided by
the proposed controller are able to track a simulated time-varying chemical
plume in a distributed manner.

</details>


### [213] [Research on Sectionalizing Switches Placement Problem of Distribution System Automation Based on Multi-Objective Optimization Analysis](https://arxiv.org/abs/2507.19029)
*Selma Cheshmeh Khavar,Arya Abdollahi*

Main category: eess.SY

TL;DR: 该研究提出了一种改进的非支配排序遗传算法，用于优化配电系统的自动化设备放置，以同时最小化运营成本和提高可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了解决配电系统优化中提高配电可靠性和降低运营成本这两个主要问题，并确定自动化设备的最佳数量和位置。

Method: 提出并实现了一种改进的非支配排序遗传算法来解决多目标混合整数非线性规划问题。

Result: 通过将所提出的算法应用于Tabriz配电网络中的两个配电馈线（包括带分布式发电单元的Azar变电站的第三馈线以及构成双馈馈线The first and third feeders of ElGoli substation）来检验其可行性。

Conclusion: 该研究提出了一种改进的非支配排序遗传算法来解决多目标混合整数非线性规划问题，该问题旨在优化配电系统的自动化设备放置，以最小化运营成本并提高可靠性指标。

Abstract: Achieving high distribution-reliability levels and concurrently minimizing
operating costs can be considered as the main issues in distribution system
optimization. Determination of the optimal number and location of automation
devices in the distribution system network is an essential issue from the
reliability and economical points of view. To address these issues, this paper
develops a multi-objective model, wherein the primary objective, optimal
automation devices placement is implemented aiming at minimizing the operating
costs, while in the second objective the reliability indices improvement is
taken into account. So, modified non dominated sorting genetic algorithm, is
developed and presented to solve this multi-objective mixed-integer non-linear
programming problem. The feasibility of the proposed algorithm examined by
application to two distribution feeders of the Tabriz distribution network
containing the third feeder of the Azar substation with a distributed
generation unit and first and third feeders of ElGoli substation which form a
double feed feeder.

</details>


### [214] [Radio Map Assisted Routing and Predictive Resource Allocation over Dynamic Low Altitude Networks](https://arxiv.org/abs/2507.19111)
*Bowen Li,Junting Chen*

Main category: eess.SY

TL;DR: 本文提出了一种动态时空图模型和跨层优化框架，以解决无人机通信中的路由和资源分配问题。与传统方法相比，该方法显著提高了数据传输效率和性能。


<details>
  <summary>Details</summary>
Motivation: 低空网络通过无人机中继提供数据传输，但其时变拓扑和对陆地系统的干扰控制给数据路由和资源分配带来了挑战。传统方法依赖于均匀细时间划分的时空图，不适用于考虑干扰的应用。

Method: 本文开发了一个动态时空图模型和一个跨层优化框架，将联合路由和预测资源分配问题转化为联合瓶颈路径规划和资源分配问题。我们开发了显式的确定性边界来处理信道不确定性，并证明了问题结构中的单调性，使得我们能够有效地达到预测资源分配子问题的全局最优解。然后，通过时频分配将该方法扩展到多播传输任务，并通过二分搜索算法利用可行集族单调性来寻找最优解。

Result: 单播算法的性能接近全局最优，在时延敏感和海量数据传输方面比经典图方法有超过30dB的性能增益。多播方法在密集服务场景下实现了100倍的改进，并通过数据分段实现了额外的20dB性能增益。

Conclusion: 该方法在时延敏感和海量数据传输方面比经典的基于图的方法有超过30dB的性能提升，在密集服务场景下实现了100倍的改进，并通过数据分段实现了额外的20dB性能增益。

Abstract: Dynamic low altitude networks offer significant potential for efficient and
reliable data transport via unmanned aerial vehicles (UAVs) relays which
usually operate with predetermined trajectories. However, it is challenging to
optimize the data routing and resource allocation due to the time-varying
topology and the need to control interference with terrestrial systems.
Traditional schemes rely on time-expanded graphs with uniform and fine time
subdivisions, making them impractical for interference-aware applications. This
paper develops a dynamic space-time graph model with a cross-layer optimization
framework that converts a joint routing and predictive resource allocation
problem into a joint bottleneck path planning and resource allocation problem.
We develop explicit deterministic bounds to handle the channel uncertainty and
prove a monotonicity property in the problem structure that enables us to
efficiently reach the globally optimal solution to the predictive resource
allocation subproblem. Then, this approach is extended to multi-commodity
transmission tasks through time-frequency allocation, and a bisection search
algorithm is developed to find the optimum solution by leveraging the
monotonicity of the feasible set family. Simulations verify that the
single-commodity algorithm approaches global optimality with more than 30 dB
performance gain over the classical graph-based methods for delay-sensitive and
large data transportation. At the same time, the multi-commodity method
achieves 100X improvements in dense service scenarios and enables an additional
20 dB performance gain by data segmenting.

</details>


### [215] [Truncated Gaussian Noise Estimation in State-Space Models](https://arxiv.org/abs/2507.19244)
*Rodrigo A. González,Angel L. Cedeño,Koen Tiels,Tom Oomen*

Main category: eess.SY

TL;DR: 本研究提出了一种新的方法来估计状态空间模型中的截断高斯噪声，这比传统的高斯噪声假设更具普遍性。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统状态空间系统辨识中仅考虑高斯噪声假设的局限性，该研究旨在将高斯噪声假设推广到截断密度，以提高在噪声服从截断分布时的模型准确性。

Method: 提出了一种数据驱动的方法，结合了最大似然原理和期望最大化算法，用于估计状态空间模型中的截断高斯噪声参数。

Result: 通过仿真示例证明了所提出方法在估计截断高斯噪声参数方面的有效性。

Conclusion: 该研究提出了一种在状态空间模型中估计截断高斯噪声参数的方法，该方法基于最大似然原理和期望最大化算法。

Abstract: Within Bayesian state estimation, considerable effort has been devoted to
incorporating constraints into state estimation for process optimization, state
monitoring, fault detection and control. Nonetheless, in the domain of
state-space system identification, the prevalent practice entails constructing
models under Gaussian noise assumptions, which can lead to inaccuracies when
the noise follows bounded distributions. With the aim of generalizing the
Gaussian noise assumption to potentially truncated densities, this paper
introduces a method for estimating the noise parameters in a state-space model
subject to truncated Gaussian noise. Our proposed data-driven approach is
rooted in maximum likelihood principles combined with the
Expectation-Maximization algorithm. The efficacy of the proposed approach is
supported by a simulation example.

</details>


### [216] [Cell-based VSC Analysis Methodology: From Graph Laplacian to Converter Degrees of Freedom](https://arxiv.org/abs/2507.19260)
*Daniele Falchi,Eduardo Prieto-Araujo,Oriol Gomis-Bellmunt*

Main category: eess.SY

TL;DR: 本文提出了一种基于图拉普拉斯谱分析和瞬时功率模式公式的通用方法，用于确定电压源换流器拓扑的变量变换矩阵和自由度。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解和控制基于单元的电压源换流器拓扑（包括模块化多电平换流器），需要评估每种换流器拓扑的自由度（DOFs）。

Method: 本文提出了一种基于图拉普拉斯谱分析的通用方法，用于确定电压源换流器拓扑的变量变换矩阵，并引入了基于自由度（DOFs）的瞬时功率模式公式。

Result: 所提出的方法能够确定多种换流器拓扑的变量变换矩阵，并提供了瞬时功率模式的公式，从而为换流器的工作和控制提供了更全面的表征。

Conclusion: 本文提出了一种确定电压源换流器拓扑的变量变换矩阵的通用方法，该方法基于图拉普拉斯谱分析，并结合了瞬时功率模式公式。

Abstract: Power-electronics-based converters are being considerably employed through
the power system to interconnect multiple heterogeneous electrical layers.
Furthermore, the intrinsic versatility to play with the converter network
topology is widely exploited to accommodate a certain number of terminals and
ports according with the specific application. On this regard, several
converter arrangements can be encountered in power applications. Moreover, to
properly establish both the operation and the control, the so-called degrees of
freedom (DOFs) need to be assessed per each converter topology. On this matter,
similarly to the well-known Clarke transformation, which clearly reveals the
DOFs for the star-based topology system, further similar transformations can be
achieved to depict the independent set of variables characterizing a certain
converter structure. Referring to the cell-based class of Voltage Source
Converter (VSC) topologies, including Modular Multilevel Converter (MMC); this
article proposes a general methodology to determine the change of variable
matrix transformation for several converter arrangements which are related to
complete bi-partite and multi-partite graphs. The methodology lies in the graph
Laplacian spectral analysis, which remarks the structural normal modes at the
converter points of connections. Furthermore, for a complete characterization,
the instantaneous power patterns formulations, based on the DOFs, are also
introduced.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [217] [Perpetua: Multi-Hypothesis Persistence Modeling for Semi-Static Environments](https://arxiv.org/abs/2507.18808)
*Miguel Saavedra-Ruiz,Samer B. Nashed,Charlie Gauthier,Liam Paull*

Main category: cs.RO

TL;DR: Perpetua 是一种用于对半静态特征的动态进行建模的方法，可以更准确、更适应性地预测其未来状态。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人地图绘制和环境建模算法通常无法表示动态特征的未来状态，导致它们在复杂和动态环境中的部署效率低下。

Method: 通过结合“持续”和“出现”滤波器，在贝叶斯框架中对半静态特征的动态进行建模。

Result: 与类似方法相比，Perpetua 在模拟和真实世界数据上均表现出更好的准确性，并且能够进行在线适应并抵抗缺失的观测值。

Conclusion: Perpetua 通过在贝叶斯框架中结合“持续”和“出现”滤波器来对半静态特征的动态进行建模，可以有效地估计特征的当前和未来状态，并且比现有方法更准确、更具适应性和鲁棒性。

Abstract: Many robotic systems require extended deployments in complex, dynamic
environments. In such deployments, parts of the environment may change between
subsequent robot observations. Most robotic mapping or environment modeling
algorithms are incapable of representing dynamic features in a way that enables
predicting their future state. Instead, they opt to filter certain state
observations, either by removing them or some form of weighted averaging. This
paper introduces Perpetua, a method for modeling the dynamics of semi-static
features. Perpetua is able to: incorporate prior knowledge about the dynamics
of the feature if it exists, track multiple hypotheses, and adapt over time to
enable predicting of future feature states. Specifically, we chain together
mixtures of "persistence" and "emergence" filters to model the probability that
features will disappear or reappear in a formal Bayesian framework. The
approach is an efficient, scalable, general, and robust method for estimating
the states of features in an environment, both in the present as well as at
arbitrary future times. Through experiments on simulated and real-world data,
we find that Perpetua yields better accuracy than similar approaches while also
being online adaptable and robust to missing observations.

</details>


### [218] [Probabilistic Collision Risk Estimation through Gauss-Legendre Cubature and Non-Homogeneous Poisson Processes](https://arxiv.org/abs/2507.18819)
*Trent Weiss,Madhur Behl*

Main category: cs.RO

TL;DR: GLR算法通过结合高斯-勒让德积分和非齐次泊松过程，在自动驾驶赛车中实现了高精度、实时的碰撞风险估计，优于现有方法，并且运行速度快，具有广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 高速自动驾驶赛车中的超车操作，特别是在轮对轮的近距离接触场景中，需要对碰撞风险进行精确的实时估计，因为此时的安全裕度非常小。现有的碰撞风险估计方法要么依赖于简化的几何近似（如边界圆），要么执行蒙特卡洛采样，这会导致在赛车速度下产生过于保守的运动规划行为。

Method: GLR算法是一种原则性的两阶段积分方法，它将高斯-勒让德积分与非齐次泊松过程相结合，对时间进行估计，以估计碰撞风险。GLR能够准确地估计风险，并考虑了车辆几何和轨迹的不确定性。

Result: 在模拟一级方程式赛车的446个超车场景中，GLR的表现优于五个最先进的基线方法，实现了77%的平均误差降低，并且在1000赫兹的运行速度下，其表现比次优方法高出52%。

Conclusion: GLR框架通用且适用于更广泛的运动规划背景，不仅仅局限于自动驾驶赛车。

Abstract: Overtaking in high-speed autonomous racing demands precise, real-time
estimation of collision risk; particularly in wheel-to-wheel scenarios where
safety margins are minimal. Existing methods for collision risk estimation
either rely on simplified geometric approximations, like bounding circles, or
perform Monte Carlo sampling which leads to overly conservative motion planning
behavior at racing speeds. We introduce the Gauss-Legendre Rectangle (GLR)
algorithm, a principled two-stage integration method that estimates collision
risk by combining Gauss-Legendre with a non-homogeneous Poisson process over
time. GLR produces accurate risk estimates that account for vehicle geometry
and trajectory uncertainty. In experiments across 446 overtaking scenarios in a
high-fidelity Formula One racing simulation, GLR outperforms five
state-of-the-art baselines achieving an average error reduction of 77% and
surpassing the next-best method by 52%, all while running at 1000 Hz. The
framework is general and applicable to broader motion planning contexts beyond
autonomous racing.

</details>


### [219] [MetaMorph -- A Metamodelling Approach For Robot Morphology](https://arxiv.org/abs/2507.18820)
*Rachel Ringe,Robin Nolte,Nima Zargham,Robert Porzel,Rainer Malaka*

Main category: cs.RO

TL;DR: A new framework called MetaMorph classifies robot appearance more precisely than existing methods by analyzing visual features, helping researchers find optimal robot designs for different situations.


<details>
  <summary>Details</summary>
Motivation: Existing methods for describing robot appearance (broad categories or anthropomorphic features) are insufficient for classifying diverse robot types and understanding the connection between robot design and human-robot interaction. A more precise and comprehensive approach is needed.

Method: A metamodeling approach was used to synthesize the MetaMorph framework from 222 robots in the IEEE Robots Guide, creating a structured method for comparing visual features of robots.

Result: The MetaMorph framework offers a structured method for assessing visual distances between robot models and exploring optimal design traits tailored to different tasks and contexts, overcoming the limitations of previous classification systems.

Conclusion: The MetaMorph framework provides a comprehensive and structured method for classifying robot morphology, addressing the limitations of existing broad categories and feature-focused approaches. It enables quantitative comparisons of visual features across diverse robot designs, facilitating the exploration of optimal design traits for specific tasks and contexts.

Abstract: Robot appearance crucially shapes Human-Robot Interaction (HRI) but is
typically described via broad categories like anthropomorphic, zoomorphic, or
technical. More precise approaches focus almost exclusively on anthropomorphic
features, which fail to classify robots across all types, limiting the ability
to draw meaningful connections between robot design and its effect on
interaction. In response, we present MetaMorph, a comprehensive framework for
classifying robot morphology. Using a metamodeling approach, MetaMorph was
synthesized from 222 robots in the IEEE Robots Guide, offering a structured
method for comparing visual features. This model allows researchers to assess
the visual distances between robot models and explore optimal design traits
tailored to different tasks and contexts.

</details>


### [220] [ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for Multi-Agent Coordination](https://arxiv.org/abs/2507.19151)
*Michael Amir,Guang Yang,Zhan Gao,Keisuke Okumura,Heedo Woo,Amanda Prorok*

Main category: cs.RO

TL;DR: ReCoDe 是一个机器人框架，通过学习动态约束来改进现有控制器，以实现更好的多主体协调，尤其是在导航任务中。


<details>
  <summary>Details</summary>
Motivation: 在多主体环境中，手工设计的约束难以满足复杂的协调需求，而基于学习的方法可能缺乏可靠性。ReCoDe旨在解决这一问题，通过结合两种方法的优点来提高机器人系统的性能。

Method: ReCoDe（Reinforcement-based Constraint Design）是一个去中心化的混合框架，结合了基于优化程序的控制器的可靠性和多主体强化学习的适应性。它通过学习动态约束来补充现有的控制器，并通过局部通信实现有效的协调。

Result: ReCoDe 在需要复杂、基于上下文的运动和共识的多主体导航任务中，优于纯粹手工设计的控制器、其他混合方法和标准的 MARL 基线。该框架在经验上（真实机器人）和理论上都证明了其有效性。

Conclusion: ReCoDe 框架通过学习额外的、动态的约束来改进基于优化程序的控制器，使其能够处理多主体协调的复杂性，并在多主体导航任务中表现优于其他方法。

Abstract: Constraint-based optimization is a cornerstone of robotics, enabling the
design of controllers that reliably encode task and safety requirements such as
collision avoidance or formation adherence. However, handcrafted constraints
can fail in multi-agent settings that demand complex coordination. We introduce
ReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid
framework that merges the reliability of optimization-based controllers with
the adaptability of multi-agent reinforcement learning. Rather than discarding
expert controllers, ReCoDe improves them by learning additional, dynamic
constraints that capture subtler behaviors, for example, by constraining agent
movements to prevent congestion in cluttered scenarios. Through local
communication, agents collectively constrain their allowed actions to
coordinate more effectively under changing conditions. In this work, we focus
on applications of ReCoDe to multi-agent navigation tasks requiring intricate,
context-based movements and consensus, where we show that it outperforms purely
handcrafted controllers, other hybrid approaches, and standard MARL baselines.
We give empirical (real robot) and theoretical evidence that retaining a
user-defined controller, even when it is imperfect, is more efficient than
learning from scratch, especially because ReCoDe can dynamically change the
degree to which it relies on this controller.

</details>


### [221] [Equivariant Volumetric Grasping](https://arxiv.org/abs/2507.18847)
*Pinhao Song,Yutong Hu,Pengteng Li,Renaud Detry*

Main category: cs.RO

TL;DR: 提出了一种新的三角平面体积抓取模型，该模型通过利用旋转等变性提高了样本效率和性能，并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 为了提高机器人抓取的样本效率和性能，并降低计算和内存成本，提出了一种新的体积抓取模型，该模型能够处理旋转等变性。

Method: 提出了一种新的体积抓取模型，该模型对围绕垂直轴的旋转具有等变性。模型采用了三角平面体积特征表示，并引入了一种新的三角平面特征设计，其中水平平面上的特征对于90度旋转是等变的，而其他两个平面上的特征之和对于相同的变换是不变的。该设计通过一种新的可变形可操纵卷积实现，该卷积结合了可变形卷积的适应性和可操纵卷积的旋转等变性。此外，还开发了两种最先进的体积抓取规划器 GIGA 和 IGD 的等变适应版本，包括 IGD 的可变形注意力机制的等变公式以及基于流匹配的抓取方向等变生成模型。

Result: 新的三角平面特征表示显著降低了计算和内存成本。基于该特征的等变抓取模型在性能上优于非等变模型，同时计算开销适中。

Conclusion: 该方法通过基于投影的三角平面特征设计，显著降低了计算和内存成本，并且在模拟和真实世界实验中均优于其非等变对应物，实现了更高的性能和适度的计算开销。

Abstract: We propose a new volumetric grasp model that is equivariant to rotations
around the vertical axis, leading to a significant improvement in sample
efficiency. Our model employs a tri-plane volumetric feature representation --
i.e., the projection of 3D features onto three canonical planes. We introduce a
novel tri-plane feature design in which features on the horizontal plane are
equivariant to 90{\deg} rotations, while the sum of features from the other two
planes remains invariant to the same transformations. This design is enabled by
a new deformable steerable convolution, which combines the adaptability of
deformable convolutions with the rotational equivariance of steerable ones.
This allows the receptive field to adapt to local object geometry while
preserving equivariance properties. We further develop equivariant adaptations
of two state-of-the-art volumetric grasp planners, GIGA and IGD. Specifically,
we derive a new equivariant formulation of IGD's deformable attention mechanism
and propose an equivariant generative model of grasp orientations based on flow
matching. We provide a detailed analytical justification of the proposed
equivariance properties and validate our approach through extensive simulated
and real-world experiments. Our results demonstrate that the proposed
projection-based design significantly reduces both computational and memory
costs. Moreover, the equivariant grasp models built on top of our tri-plane
features consistently outperform their non-equivariant counterparts, achieving
higher performance with only a modest computational overhead. Video and code
can be viewed in: https://mousecpn.github.io/evg-page/

</details>


### [222] [A Fast and Light-weight Non-Iterative Visual Odometry with RGB-D Cameras](https://arxiv.org/abs/2507.18886)
*Zheng Yang,Kuan Xu,Shenghai Yuan,Lihua Xie*

Main category: cs.RO

TL;DR: 一种新的RGBD-VO方法，通过利用重叠的平面特征，将旋转和翻译分离估计，避免了迭代优化和特征提取，从而提高了计算效率，在低纹理环境中表现尤为出色。


<details>
  <summary>Details</summary>
Motivation: 传统RGB-D视觉里程计（RGBD-VO）计算负担重、有时间延迟，为解决这些问题，提出了一种高效的估计6-DoF机器人姿态的新方法。

Method: 提出了一种新颖的RGBD-VO方法，将旋转和翻译的估计分离。首先，利用场景中重叠的平面特征计算旋转矩阵，然后使用核交叉相关器（KCC）来确定翻译。该方法避免了计算量大的迭代优化以及特征提取和对齐过程。

Result: 该方法在低端i5 CPU上实现了71Hz的性能。在不依赖特征点的情况下，与最先进的方法相比，该技术在低纹理退化环境中表现出更优越的性能。

Conclusion: 该方法通过利用重叠的平面特征，实现了分离的、非迭代的机器人姿态（6-DoF）高效估计。与依赖迭代优化和特征提取匹配的传统RGB-D视觉里程计（RGBD-VO）相比，该方法显著降低了计算负担和时间延迟。

Abstract: In this paper, we introduce a novel approach for efficiently estimating the
6-Degree-of-Freedom (DoF) robot pose with a decoupled, non-iterative method
that capitalizes on overlapping planar elements. Conventional RGB-D visual
odometry(RGBD-VO) often relies on iterative optimization solvers to estimate
pose and involves a process of feature extraction and matching. This results in
significant computational burden and time delays. To address this, our
innovative method for RGBD-VO separates the estimation of rotation and
translation. Initially, we exploit the overlaid planar characteristics within
the scene to calculate the rotation matrix. Following this, we utilize a kernel
cross-correlator (KCC) to ascertain the translation. By sidestepping the
resource-intensive iterative optimization and feature extraction and alignment
procedures, our methodology offers improved computational efficacy, achieving a
performance of 71Hz on a lower-end i5 CPU. When the RGBD-VO does not rely on
feature points, our technique exhibits enhanced performance in low-texture
degenerative environments compared to state-of-the-art methods.

</details>


### [223] [GEAR: Gaze-Enabled Human-Robot Collaborative Assembly](https://arxiv.org/abs/2507.18947)
*Asad Ali Shahid,Angelo Moroncelli,Drazen Brscic,Takayuki Kanda,Loris Roveda*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent progress in robot autonomy and safety has significantly improved
human-robot interactions, enabling robots to work alongside humans on various
tasks. However, complex assembly tasks still present significant challenges due
to inherent task variability and the need for precise operations. This work
explores deploying robots in an assistive role for such tasks, where the robot
assists by fetching parts while the skilled worker provides high-level guidance
and performs the assembly. We introduce GEAR, a gaze-enabled system designed to
enhance human-robot collaboration by allowing robots to respond to the user's
gaze. We evaluate GEAR against a touch-based interface where users interact
with the robot through a touchscreen. The experimental study involved 30
participants working on two distinct assembly scenarios of varying complexity.
Results demonstrated that GEAR enabled participants to accomplish the assembly
with reduced physical demand and effort compared to the touchscreen interface,
especially for complex tasks, maintaining great performance, and receiving
objects effectively. Participants also reported enhanced user experience while
performing assembly tasks. Project page: sites.google.com/view/gear-hri

</details>


### [224] [Frequency Response Data-Driven Disturbance Observer Design for Flexible Joint Robots](https://arxiv.org/abs/2507.18979)
*Deokjin Lee,Junho Song,Alireza Karimi,Sehoon Oh*

Main category: cs.RO

TL;DR: 提出一种基于FRF的优化方法，用于提高柔性关节机器人运动控制中DOB的性能，以应对关节柔性和系统变化。


<details>
  <summary>Details</summary>
Motivation: 柔性关节机器人（FJR）的运动控制因关节的固有柔性和系统动力学中配置相关变化而面临挑战。虽然干扰观测器（DOB）可以增强系统的鲁棒性，但其性能常受关节弹性和系统参数变化的限制。

Method: 提出了一种基于频率响应函数（FRF）的优化方法来改进干扰观测器（DOB）的性能。

Result: 所提出的方法能够最大化控制带宽并有效抑制振动，从而提高整体系统性能。闭环稳定性通过奈奎斯特定理得到了严格证明。

Conclusion: 该方法在关节柔性和系统变化条件下显著提高了鲁棒性和运动性能。

Abstract: Motion control of flexible joint robots (FJR) is challenged by inherent
flexibility and configuration-dependent variations in system dynamics. While
disturbance observers (DOB) can enhance system robustness, their performance is
often limited by the elasticity of the joints and the variations in system
parameters, which leads to a conservative design of the DOB. This paper
presents a novel frequency response function (FRF)-based optimization method
aimed at improving DOB performance, even in the presence of flexibility and
system variability. The proposed method maximizes control bandwidth and
effectively suppresses vibrations, thus enhancing overall system performance.
Closed-loop stability is rigorously proven using the Nyquist stability
criterion. Experimental validation on a FJR demonstrates that the proposed
approach significantly improves robustness and motion performance, even under
conditions of joint flexibility and system variation.

</details>


### [225] [SmartPNT-MSF: A Multi-Sensor Fusion Dataset for Positioning and Navigation Research](https://arxiv.org/abs/2507.19079)
*Feng Zhu,Zihang Zhang,Kangcheng Teng,Abduhelil Yakup,Xiaohong Zhang*

Main category: cs.RO

TL;DR: SmartPNT数据集提供了包含GNSS、IMU、摄像头和LiDAR数据的多传感器数据集，覆盖了多种真实世界场景，旨在解决现有数据集的局限性，并用于先进导航算法的研发和测试。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数据集在传感器多样性和环境覆盖方面的局限性，以满足自动驾驶和移动测绘等应用对高精度导航和定位系统的需求。

Method: 开发了一个名为SmartPNT的包含多传感器（GNSS、IMU、摄像头、LiDAR）数据的数据集，并详细记录了数据集的构建过程，包括传感器配置、坐标系定义以及相机和激光雷达的校准程序。使用VINS-Mono和LIO-SAM等先进的SLAM算法对数据集进行了验证。

Result: SmartPNT数据集整合了多种传感器数据，覆盖了广泛的真实世界场景，并成功应用于VINS-Mono和LIO-SAM等先进SLAM算法的验证，证明了其在高级导航研究中的适用性。

Conclusion: 该数据集通过整合GNSS、IMU、摄像头和LiDAR等多种传感器数据，并覆盖了城市、校园、隧道和郊区等多种真实世界场景，为多传感器融合和高精度导航研究提供了丰富且多样化的资源，旨在弥补现有数据集在传感器多样性和环境覆盖方面的不足，推动相关领域的发展和创新。

Abstract: High-precision navigation and positioning systems are critical for
applications in autonomous vehicles and mobile mapping, where robust and
continuous localization is essential. To test and enhance the performance of
algorithms, some research institutions and companies have successively
constructed and publicly released datasets. However, existing datasets still
suffer from limitations in sensor diversity and environmental coverage. To
address these shortcomings and advance development in related fields, the
SmartPNT Multisource Integrated Navigation, Positioning, and Attitude Dataset
has been developed. This dataset integrates data from multiple sensors,
including Global Navigation Satellite Systems (GNSS), Inertial Measurement
Units (IMU), optical cameras, and LiDAR, to provide a rich and versatile
resource for research in multi-sensor fusion and high-precision navigation. The
dataset construction process is thoroughly documented, encompassing sensor
configurations, coordinate system definitions, and calibration procedures for
both cameras and LiDAR. A standardized framework for data collection and
processing ensures consistency and scalability, enabling large-scale analysis.
Validation using state-of-the-art Simultaneous Localization and Mapping (SLAM)
algorithms, such as VINS-Mono and LIO-SAM, demonstrates the dataset's
applicability for advanced navigation research. Covering a wide range of
real-world scenarios, including urban areas, campuses, tunnels, and suburban
environments, the dataset offers a valuable tool for advancing navigation
technologies and addressing challenges in complex environments. By providing a
publicly accessible, high-quality dataset, this work aims to bridge gaps in
sensor diversity, data accessibility, and environmental representation,
fostering further innovation in the field.

</details>


### [226] [Bot Appétit! Exploring how Robot Morphology Shapes Perceived Affordances via a Mise en Place Scenario in a VR Kitchen](https://arxiv.org/abs/2507.19082)
*Rachel Ringe,Leandra Thiele,Mihai Pomarlan,Nima Zargham,Robin Nolte,Lars Hurrelbrink,Rainer Malaka*

Main category: cs.RO

TL;DR: Humans prefer biomorphic robots for cooking tasks and adjust their behavior based on the robot's appearance, especially its action capabilities and gracefulness. VR was used to test these preferences.


<details>
  <summary>Details</summary>
Motivation: This study explores how a robot's visual design influences human placement of the robot in a collaborative cooking scenario and how these features affect task delegation.

Method: Human participants were placed in a Virtual Reality (VR) environment to set up a kitchen for cooking with a robot companion, considering the robot's morphology. Multimodal data was collected, including spatial arrangements, think-aloud transcripts, and post-task questionnaire responses.

Result: The study formulated hypotheses suggesting human preference for biomorphic robots, the influence of morphology on beliefs about robot action capabilities over sensory capabilities, and reduced avoidance strategies with gracile robots. These hypotheses are intended for verification in future studies.

Conclusion: Humans prefer to collaborate with biomorphic robots, and their beliefs about a robot's action capabilities are more influenced by its morphology than their beliefs about its sensory capabilities. Additionally, humans are less likely to implement avoidance strategies when sharing space with gracile robots.

Abstract: This study explores which factors of the visual design of a robot may
influence how humans would place it in a collaborative cooking scenario and how
these features may influence task delegation. Human participants were placed in
a Virtual Reality (VR) environment and asked to set up a kitchen for cooking
alongside a robot companion while considering the robot's morphology. We
collected multimodal data for the arrangements created by the participants,
transcripts of their think-aloud as they were performing the task, and
transcripts of their answers to structured post-task questionnaires. Based on
analyzing this data, we formulate several hypotheses: humans prefer to
collaborate with biomorphic robots; human beliefs about the sensory
capabilities of robots are less influenced by the morphology of the robot than
beliefs about action capabilities; and humans will implement fewer avoidance
strategies when sharing space with gracile robots. We intend to verify these
hypotheses in follow-up studies.

</details>


### [227] [Monocular Vision-Based Swarm Robot Localization Using Equilateral Triangular Formations](https://arxiv.org/abs/2507.19100)
*Taewon Kang,Ji-Wook Kwon,Il Bae,Jin Hyo Kim*

Main category: cs.RO

TL;DR: 提出一种基于机器人队形（等边三角形）的定位方法，仅用单目相机和低成本传感器，在开放环境中即可实现高精度定位，且越用越准。


<details>
  <summary>Details</summary>
Motivation: 为解决移动机器人（特别是机器人群）在没有外部定位基础设施的开放环境中，仅依靠低成本单目视觉传感器和视觉标记进行准确定位的问题。

Method: 提出一种基于等边三角形队形的方法，利用机器人间的几何关系，仅通过机器人间的一维距离信息来估计每个机器人的二维位置。

Result: 实验和仿真结果表明，该方法在长时间运行后，定位误差显著小于传统的航位推算系统。

Conclusion: 该方法能够实现高精度定位，并且定位误差会随着时间的推移而减小，优于传统的只依赖低成本单目视觉传感器的航位推算系统。

Abstract: Localization of mobile robots is crucial for deploying robots in real-world
applications such as search and rescue missions. This work aims to develop an
accurate localization system applicable to swarm robots equipped only with
low-cost monocular vision sensors and visual markers. The system is designed to
operate in fully open spaces, without landmarks or support from positioning
infrastructures. To achieve this, we propose a localization method based on
equilateral triangular formations. By leveraging the geometric properties of
equilateral triangles, the accurate two-dimensional position of each
participating robot is estimated using one-dimensional lateral distance
information between robots, which can be reliably and accurately obtained with
a low-cost monocular vision sensor. Experimental and simulation results
demonstrate that, as travel time increases, the positioning error of the
proposed method becomes significantly smaller than that of a conventional
dead-reckoning system, another low-cost localization approach applicable to
open environments.

</details>


### [228] [Diverse and Adaptive Behavior Curriculum for Autonomous Driving: A Student-Teacher Framework with Multi-Agent RL](https://arxiv.org/abs/2507.19146)
*Ahmed Abouelazm,Johannes Ratz,Philip Schörner,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 本文提出了一种学生-教师框架，通过自动生成课程来训练自主驾驶的强化学习智能体，提高了其在各种交通场景下的驾驶性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）训练方法依赖于基于规则的交通场景，限制了泛化能力，并且当前场景生成方法过度关注关键场景，忽视了与常规驾驶行为的平衡。为了提高 RL 驾驶策略的鲁棒性和覆盖范围，需要一种能够生成多样化且具有挑战性的驾驶场景的自动课程学习方法。

Method: 本文提出了一个新颖的学生-教师框架，用于自动课程学习。该框架包括一个基于图的多智能体强化学习教师，用于生成不同难度级别的交通行为；以及一个适应性机制，根据学生表现调整任务难度。学生是一个可替换的、部分可观测的深度强化学习智能体。

Result: 结果表明，教师能够生成多样化的交通行为，并且使用自动课程训练的学生智能体在奖励方面优于在基于规则的交通中训练的智能体，并且表现出平衡的、自信的驾驶行为。

Conclusion: 所提出的学生-教师框架能够自动生成课程，用于训练自主驾驶的深度强化学习智能体，该智能体在平衡的、自信的驾驶行为方面表现优于在基于规则的交通中训练的智能体。

Abstract: Autonomous driving faces challenges in navigating complex real-world traffic,
requiring safe handling of both common and critical scenarios. Reinforcement
learning (RL), a prominent method in end-to-end driving, enables agents to
learn through trial and error in simulation. However, RL training often relies
on rule-based traffic scenarios, limiting generalization. Additionally, current
scenario generation methods focus heavily on critical scenarios, neglecting a
balance with routine driving behaviors. Curriculum learning, which
progressively trains agents on increasingly complex tasks, is a promising
approach to improving the robustness and coverage of RL driving policies.
However, existing research mainly emphasizes manually designed curricula,
focusing on scenery and actor placement rather than traffic behavior dynamics.
This work introduces a novel student-teacher framework for automatic curriculum
learning. The teacher, a graph-based multi-agent RL component, adaptively
generates traffic behaviors across diverse difficulty levels. An adaptive
mechanism adjusts task difficulty based on student performance, ensuring
exposure to behaviors ranging from common to critical. The student, though
exchangeable, is realized as a deep RL agent with partial observability,
reflecting real-world perception constraints. Results demonstrate the teacher's
ability to generate diverse traffic behaviors. The student, trained with
automatic curricula, outperformed agents trained on rule-based traffic,
achieving higher rewards and exhibiting balanced, assertive driving.

</details>


### [229] [Towards Multimodal Social Conversations with Robots: Using Vision-Language Models](https://arxiv.org/abs/2507.19196)
*Ruben Janssens,Tony Belpaeme*

Main category: cs.RO

TL;DR: Social robots need multimodal skills for better conversations. Vision-language models show promise but need adaptation and further research.


<details>
  <summary>Details</summary>
Motivation: While large language models enable open-domain conversations for social robots, they lack the ability to utilize multiple modalities present in social interactions. This paper addresses this gap by exploring the needs for multimodal social conversations.

Method: The paper outlines the needs of a multimodal system for social conversations with robots and argues for the use of vision-language models, discussing adaptation strategies and remaining technical challenges.

Result: The paper identifies the potential of vision-language models in processing visual information for social robots and discusses their adaptation, technical challenges, and evaluation.

Conclusion: Vision-language models can be adapted for autonomous social robots to process visual information for multimodal social conversations. Further research is needed to address technical challenges and refine evaluation practices.

Abstract: Large language models have given social robots the ability to autonomously
engage in open-domain conversations. However, they are still missing a
fundamental social skill: making use of the multiple modalities that carry
social interactions. While previous work has focused on task-oriented
interactions that require referencing the environment or specific phenomena in
social interactions such as dialogue breakdowns, we outline the overall needs
of a multimodal system for social conversations with robots. We then argue that
vision-language models are able to process this wide range of visual
information in a sufficiently general manner for autonomous social robots. We
describe how to adapt them to this setting, which technical challenges remain,
and briefly discuss evaluation practices.

</details>


### [230] [Foundation Model-Driven Grasping of Unknown Objects via Center of Gravity Estimation](https://arxiv.org/abs/2507.19242)
*Kang Xiangli,Yage He,Xianwu Gong,Zehan Liu,Yuru Bai*

Main category: cs.RO

TL;DR: 本研究提出了一种创新的扩散模型方法，用于精确定位未知物体的质心，从而实现更稳定、更成功的机器人抓取。


<details>
  <summary>Details</summary>
Motivation: 现有的基于关键点或可供性驱动的方法在处理质心偏移导致的姿态不稳问题时存在局限性。

Method: 通过扩散模型和基础模型构建了一个视觉驱动框架，用于定位质心并实现感知抓取，并构建了一个包含790张图像和质心关键点标注的数据集。

Result: 与传统方法相比，本研究提出的方法在抓取成功率上提高了49%，在先进的可供性驱动方法上提高了11%，在未见过物体上的质心定位准确率为76%。

Conclusion: 本研究提出了一种利用扩散模型定位未知物体质心（CoG）的抓取方法，解决了物体质心偏移导致的姿态不稳问题，提高了抓取成功率和稳定性，并在未见过物体上实现了76%的质心定位准确率。

Abstract: This study presents a grasping method for objects with uneven mass
distribution by leveraging diffusion models to localize the center of gravity
(CoG) on unknown objects. In robotic grasping, CoG deviation often leads to
postural instability, where existing keypoint-based or affordance-driven
methods exhibit limitations. We constructed a dataset of 790 images featuring
unevenly distributed objects with keypoint annotations for CoG localization. A
vision-driven framework based on foundation models was developed to achieve
CoG-aware grasping. Experimental evaluations across real-world scenarios
demonstrate that our method achieves a 49\% higher success rate compared to
conventional keypoint-based approaches and an 11\% improvement over
state-of-the-art affordance-driven methods. The system exhibits strong
generalization with a 76\% CoG localization accuracy on unseen objects,
providing a novel solution for precise and stable grasping tasks.

</details>


### [231] [How Age Influences the Interpretation of Emotional Body Language in Humanoid Robots -- long paper version](https://arxiv.org/abs/2507.19335)
*Ilaria Consoli,Claudio Mattutino,Cristina Gena,Berardina de Carolis,Giuseppe Palestra*

Main category: cs.RO

TL;DR: 一项经验研究调查了不同年龄组（儿童、青年和老年人）如何解读NAO人形机器人的情感体语，发现年轻人和老年人的解读相似，但与青年成年人不同。


<details>
  <summary>Details</summary>
Motivation: 旨在提供用户如何感知和回应来自机器人代理的情感线索的见解。

Method: 通过对机器人传达情感的有效性进行经验评估，收集老年参与者的数据，并与先前收集的青年成年人和儿童数据进行比较，来分析用户如何感知和回应来自机器人代理的情感线索。

Result: 研究强调了不同年龄组之间的相似性和差异性，其中年轻人和老年人的解读更为相似，与青年成年人不同。

Conclusion: 不同年龄组（儿童、青年和老年人）对NAO人形机器人表达的情感肢体语言的解读存在差异，其中年轻人和老年人的解读更为相似，与青年成年人不同。

Abstract: This paper presents an empirical study investigating how individuals across
different age groups, children, young and older adults, interpret emotional
body language expressed by the humanoid robot NAO. The aim is to offer insights
into how users perceive and respond to emotional cues from robotic agents,
through an empirical evaluation of the robot's effectiveness in conveying
emotions to different groups of users. By analyzing data collected from elderly
participants and comparing these findings with previously gathered data from
young adults and children, the study highlights similarities and differences
between the groups, with younger and older users more similar but different
from young adults.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [232] [Existence of 2-EFX Allocations of Chores](https://arxiv.org/abs/2507.19461)
*Jugal Garg,Aniket Murhekar*

Main category: cs.GT

TL;DR: 研究将不可分割任务的公平分配近似EFX保证从4-EFX提高到2-EFX，并提供了一个通用的框架，简化了现有结果的证明。


<details>
  <summary>Details</summary>
Motivation: 本次研究的动机在于提高不可分割任务在具有附加效用函数的代理之间的公平分配的保证水平，特别是将众所周知的公平概念“ envy-freeness up to any chore”（EFX）的近似保证从4-EFX提高到2-EFX。

Method: 研究采用了一个包含初始分配和局部交换的通用框架，通过在贪婪代理和被贪婪代理之间进行局部交换来逐步提高公平性，最终达到2-EFX的近似公平。

Result: 该研究成功地将公平分配不可分割任务的近似EFX保证从4-EFX提高到了2-EFX，并为二值效用和三方等受限实例提供了简化的证明。

Conclusion: 该研究通过提供一个通用的框架，将公平分配任务的近似EFX保证从4-EFX提高到2-EFX，并为受限实例（如二值效用或三方）提供了简化的证明。

Abstract: We study the fair division of indivisible chores among agents with additive
disutility functions. We investigate the existence of allocations satisfying
the popular fairness notion of envy-freeness up to any chore (EFX), and its
multiplicative approximations. The existence of $4$-EFX allocations was
recently established by Garg, Murhekar, and Qin (2025). We improve this
guarantee by proving the existence of $2$-EFX allocations for all instances
with additive disutilities. This approximation was previously known only for
restricted instances such as bivalued disutilities (Lin, Wu, and Zhou (2025))
or three agents (Afshinmehr, Ansaripour, Danaei, and Mehlhorn (2024)).
  We obtain our result by providing a general framework for achieving
approximate-EFX allocations. The approach begins with a suitable initial
allocation and performs a sequence of local swaps between the bundles of
envious and envied agents. For our main result, we begin with an initial
allocation that satisfies envy-freeness up to one chore (EF1) and
Pareto-optimality (PO); the existence of such an allocation was recently
established in a major breakthrough by Mahara (2025). We further demonstrate
the strength and generality of our framework by giving simple and unified
proofs of existing results, namely (i) $2$-EFX for bivalued instances, (ii)
2-EFX for three agents, (iii) EFX when the number of chores is at most twice
the number of agents, and (iv) $4$-EFX for all instances. We expect this
framework to have broader applications in approximate-EFX due to its simplicity
and generality.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [233] [Analysis of RF Surface Loss in a Planar 2D Qubit](https://arxiv.org/abs/2507.18672)
*Andrei Lunin,Mustafa Bal,Akshay Murthy,Shaojiang Zhu,Anna Grassellino,Alexander Romanenko*

Main category: quant-ph

TL;DR: 本研究通过数值模拟研究了超导量子比特中的射频损耗，并提出了一种估算损耗的方法，旨在提高量子比特的相干时间。


<details>
  <summary>Details</summary>
Motivation: 为了实现可靠的量子计算，了解超导量子比特的相干时间（T1）至关重要，因为它决定了量子比特在叠加态中停留的时间，从而影响量子计算的精度和持续时间。介电损耗是影响超导量子比特相干时间的主要因素，尤其是在超导体表面的自然氧化层中。

Method: 本研究通过数值模拟研究了不同超导量子比特设计中的平面超导天线内的微波表面损耗。

Result: 本研究提出了估算纳米尺度超薄薄膜中能量参与比的渐近方法，并对由表面氧化物和与衬底材料的接口引起的最小射频损耗极限进行了估算。

Conclusion: 本研究提出了估算纳米尺度超薄薄膜中能量参与比的渐近方法，并对由表面氧化物和与衬底材料的接口引起的最小射频损耗极限进行了估算。

Abstract: The Josephson junction and shunt capacitor form a transmon qubit, which is
the cornerstone of modern quantum computing platforms. For reliable quantum
computing, it is important how long a qubit can remain in a superposition of
quantum states, which is determined by the coherence time (T1). The coherence
time of a qubit effectively sets the "lifetime" of usable quantum information,
determining how long quantum computations can be performed before errors occur
and information is lost. There are several sources of decoherence in transmon
qubits, but the predominant one is generally considered to be dielectric losses
in the natural oxide layer formed on the surface of the superconductor. In this
paper, we present a numerical study of microwave surface losses in planar
superconducting antennas of different transmon qubit designs. An asymptotic
method for estimating the energy participation ratio in ultrathin films of
nanometer scales is proposed, and estimates are given for the limits of
achievable minimum RF losses depending on the electrical properties of the
surface oxide and the interface of the qubit with the substrate material.

</details>


### [234] [Autocallable Options Pricing with Integration-Based Exponential Amplitude Loading](https://arxiv.org/abs/2507.19039)
*Francesca Cibrario,Ron Cohen,Emanuele Dri,Christian Mattia,Or Samimi Golan,Tamuz Danzig,Giacomo Ranieri,Hanan Rosemarin,Davide Corbelletto,Amir Naveh,Bartolomeo Montrucchio*

Main category: quant-ph

TL;DR: 我们提出了一种用于自动可赎回期权定价的量子算法，并进行了实验验证。我们改进了指数幅度加载技术，将 T 深度减少了约 50 倍。


<details>
  <summary>Details</summary>
Motivation: 为更有效地对复杂金融衍生品进行定价提供一种量子方法。

Method: 我们开发了一种改进的基于积分的指数幅度加载技术，与最先进的方法相比，该技术可减少电路深度。

Result: 与以前的方法相比，在相关设置下的详细复杂性分析显示，收益部分的 T 深度大约减少了 50 倍。

Conclusion: 我们提出了一种用于自动可赎回期权定价的量子算法，该算法具有完整的实现和实验验证。

Abstract: We present a comprehensive quantum algorithm tailored for pricing
autocallable options, offering a full implementation and experimental
validation. Our experiments include simulations conducted on high-performance
computing (HPC) hardware, along with an empirical analysis of convergence to
the classically estimated value. Our key innovation is an improved
integration-based exponential amplitude loading technique that reduces circuit
depth compared to state-of-the-art approaches. A detailed complexity analysis
in a relevant setting shows an approximately 50x reduction in T-depth for the
payoff component relative to previous methods. These contributions represent a
step toward more efficient quantum approaches to pricing complex financial
derivatives.

</details>


### [235] [Correspondence principle, dissipation, and Ginibre ensemble](https://arxiv.org/abs/2507.18704)
*David Villaseñor,Hua Yan,Matic Orel,Marko Robnik*

Main category: quant-ph

TL;DR: 耗散量子混沌的对应原理，即连接经典混沌运动与 Ginibre 集合体光谱相关性，在踢击模型和原子-光子系统中均失效，Ginibre 光谱相关性并非诊断耗散量子混沌的可靠方法。


<details>
  <summary>Details</summary>
Motivation: 为了在考虑耗散的情况下，将量子混沌的概念从孤立量子混沌扩展到连接经典混沌运动与 Ginibre 集合体光谱相关性。

Method: 通过系统地探索参数空间，在踢击模型中达到真实的半经典极限，并与耗散原子-光子系统进行比较。

Result: 在踢击模型中，即使在半经典极限下，Ginibre 光谱相关性也未能预测耗散量子混沌，这与先前的研究一致，表明该对应原理在这种系统以及耗散原子-光子系统中都会失效。

Conclusion: 该研究表明，在受控的踢击模型和耗散原子-光子系统中，通过光谱相关性定义的对应原理（将经典混沌运动与 Ginibre 集合体光谱相关性联系起来）均失效。这表明 Ginibre 光谱相关性并不是诊断耗散量子混沌的稳健或普遍的方法。

Abstract: The correspondence between quantum and classical behavior has been essential
since the advent of quantum mechanics. This principle serves as a cornerstone
for understanding quantum chaos, which has garnered increased attention due to
its strong impact in various theoretical and experimental fields. When
dissipation is considered, quantum chaos takes concepts from isolated quantum
chaos to link classical chaotic motion with spectral correlations of Ginibre
ensembles. This correspondence was first identified in periodically kicked
systems with damping, but it has been shown to break down in dissipative
atom-photon systems [Phys. Rev. Lett. 133, 240404 (2024)]. In this
contribution, we revisit the original kicked model and perform a systematic
exploration across a broad parameter space, reaching a genuine semiclassical
limit. Our results demonstrate that the correspondence principle, as defined
through this spectral connection, fails even in this prototypical system. These
findings provide conclusive evidence that Ginibre spectral correlations are
neither a robust nor a universal diagnostic of dissipative quantum chaos.

</details>


### [236] [Implementing Credit Risk Analysis with Quantum Singular Value Transformation](https://arxiv.org/abs/2507.19206)
*Davide Veronelli,Francesca Cibrario,Emanuele Dri,Valeria Zaffaroni,Giacomo Ranieri,Davide Corbelletto,Bartolomeo Montrucchio*

Main category: quant-ph

TL;DR: QSVT优化了量子信用风险分析中的状态制备，降低了成本。


<details>
  <summary>Details</summary>
Motivation: 为了克服量子电路实现中成本高昂且受限的算术运算的挑战，以提高信用风险评估（如VaR和CVaR）的效率。

Method: 提出使用量子奇异值变换（QSVT）来优化量子幅度估计算法（QAE）中用于信用风险分析的状态制备算子，并通过端到端代码实现和仿真研究验证。

Result: 通过QSVT优化QAE，成功降低了状态制备算子的成本，并通过仿真研究验证了该方法的有效性。

Conclusion: QSVT可以显著降低量子计算在信用风险分析中的成本，为实际应用带来希望。

Abstract: The analysis of credit risk is crucial for the efficient operation of
financial institutions. Quantum Amplitude Estimation (QAE) offers the potential
for a quadratic speed-up over classical methods used to estimate metrics such
as Value at Risk (VaR) and Conditional Value at Risk (CVaR). However, numerous
limitations remain in efficiently scaling the implementation of quantum
circuits that solve these estimation problems. One of the main challenges is
the use of costly and restrictive arithmetic that must be implemented within
the quantum circuit. In this paper, we propose using Quantum Singular Value
Transformation (QSVT) to significantly reduce the cost of implementing the
state preparation operator, which underlies QAE for credit risk analysis. We
also present an end-to-end code implementation and the results of a simulation
study to validate the proposed approach and demonstrate its benefits.

</details>


### [237] [Average-computation benchmarking for local expectation values in digital quantum devices](https://arxiv.org/abs/2507.18708)
*Flavio Baccari,Pavel Kos,Georgios Styliaris*

Main category: quant-ph

TL;DR: 提出了一种通过将门替换为门系综来评估量子计算整体质量的方法，该方法可以检测超出Clifford基准测试的噪声。


<details>
  <summary>Details</summary>
Motivation: 评估整个量子计算的质量，而不仅仅是单个操作的性能，这是一个相关的挑战。

Method: 通过将每个门替换为一组相似的门，当对这些门进行平均时，它们会形成时空通道。我们为生产这些通道的集成提供了显式构造，并提供了一个通过半定规划寻找新通道的通用方法。

Result: 所产生的平均计算保留了有关原始电路的重要信息，并且能够检测超出Clifford基准测试的噪声。

Conclusion: 该方法能够检测超出Clifford基准测试范围的噪声，并且只需运行有限数量的不同电路实现即可估计平均计算期望值。

Abstract: As quantum devices progress towards a quantum advantage regime, they become
harder to benchmark. A particularly relevant challenge is to assess the quality
of the whole computation, beyond testing the performance of each single
operation. Here we introduce a scheme for this task that combines the target
computation with variants of it, which, when averaged, allow for classically
solvable correlation functions. Importantly, the variants exactly preserve the
circuit architecture and depth, without simplifying the gates into a
classically-simulable set. The method is based on replacing each gate by an
ensemble of similar gates, which when averaged together form space-time
channels [P. Kos and G. Styliaris, Quantum 7, 1020 (2023)]. We introduce
explicit constructions for ensembles producing such channels, all applicable to
arbitrary brickwork circuits, and provide a general recipe to find new ones
through semidefinite programming. The resulting average computation retains
important information about the original circuit and is able to detect noise
beyond a Clifford benchmarking regime. Moreover, we provide evidence that
estimating average-computation expectation values requires running only a
limited number of different circuit realizations.

</details>


### [238] [Early State Exclusion in 7-Qubit Spin Chains](https://arxiv.org/abs/2507.18767)
*Mia Gabriella Escobar,Valentin Garcia,Anastasiia Minenkova*

Main category: quant-ph

TL;DR: 对于奇数 $N 	imes N 	imes 7$，证明了 $N 	imes N$ 雅可比矩阵（代表量子自旋链的哈密顿量）的存在性。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决已知的无限族 $N 	imes N$ 雅可比矩阵（代表量子自旋链的哈密顿量）在 $N$ 为奇数且 $N 	imes N 	imes 7$ 时存在的开放性问题。

Method: 本文通过研究量子自旋链的哈密顿量，特别是具有和不具有早期状态排除（ESE）的情况，来构建 $7 	imes 7$ 雅可比矩阵。具体方法是在第 3 节中，考虑一个经历最近邻相互作用和环境效应的量子比特链。

Result: 本文成功地证明了存在无限个 $7 	imes 7$ 雅可比矩阵的家庭，它们代表了具有和不具有早期状态排除（ESE）的量子自旋链的哈密顿量。

Conclusion: 本文证明了存在无限个 $7 	imes 7$ 雅可比矩阵的家庭，它们代表了具有和不具有早期状态排除（ESE）的量子自旋链的哈密顿量，这解决了该领域的一个遗留问题。

Abstract: The existence of infinite families of $N \times N$ Jacobi matrices
representing the Hamiltonians of quantum spin chains with and without early
state exclusion (ESE) has been shown to exist for any even $N \geq 4$. However,
their existence for odd $N \geq 7$ has remained an open problem. In Section 3,
we consider a chain of qubits experiencing nearest-neighbor interactions with
environmental effects and present infinite families of $7 \times 7$ Jacobi
matrices with and without ESE.

</details>


### [239] [Non-perturbative switching rates in bistable open quantum systems: from driven Kerr oscillators to dissipative cat qubits](https://arxiv.org/abs/2507.18714)
*Léon Carde,Ronan Gautier,Nicolas Didier,Alexandru Petrescu,Joachim Cohen,Alexander McDonald*

Main category: quant-ph

TL;DR: 使用路径积分技术预测量子系统的切换率，特别是猫态量子比特的比特翻转错误率。


<details>
  <summary>Details</summary>
Motivation: 将路径积分技术推广到满足隐藏时间反演对称性的量子系统，以解决高斯噪声和经典详细平衡系统之外的问题，并在量子计算中提供猫态量子比特架构中比特翻转错误率的精确估计。

Method: 使用路径积分技术来预测单模双稳态开放量子系统中的切换率。

Result: 为量子计算中的猫态量子比特架构提供了精确的比特翻转错误率估计，避免了昂贵的数值模拟。

Conclusion: 该研究将路径积分技术推广到满足隐藏时间反演对称性的量子系统，为研究多稳态开放量子系统的切换现象提供了新途径。

Abstract: In this work, we use path integral techniques to predict the switching rate
in a single-mode bistable open quantum system. While analytical expressions are
well-known to be accessible for systems subject to Gaussian noise obeying
classical detailed balance, we generalize this approach to a class of quantum
systems, those which satisfy the recently-introduced hidden time-reversal
symmetry [1]. In particular, in the context of quantum computing, we deliver
precise estimates of bit-flip error rates in cat-qubit architectures,
circumventing the need for costly numerical simulations. Our results open new
avenues for exploring switching phenomena in multistable single- and many-body
open quantum systems.

</details>


### [240] [Secure One-Sided Device-Independent Quantum Key Distribution Under Collective Attacks with Enhanced Robustness](https://arxiv.org/abs/2507.18744)
*Pritam Roy,Subhankar Bera,A. S. Majumdar*

Main category: quant-ph

TL;DR: 本研究提出了一种单侧无关 (1sDI) 量子密钥分发 (QKD) 协议，该协议在安全性、容错性和实验可行性方面优于现有的设备无关 (DI-QKD) 协议，为安全量子通信提供了一种新的选择。


<details>
  <summary>Details</summary>
Motivation: 为了平衡实验可行性与最小信任假设，本研究针对单侧无关 (1sDI) 的量子密钥分发 (QKD) 协议进行安全研究。该协议允许只信任一方的测量设备，从而在设备相关 (DD-QKD) 和设备无关 (DI-QKD) 协议之间取得折衷。

Method: 提出了一种基于单侧无关 (1sDI) 量子密钥分发 (QKD) 协议的安全分析方法。该方法通过分析 CJWR 不等式的线性量子 steering 关系，推导了在面对集体攻击时，协议的渐近密钥率的分析下界。利用 steering 函数的对称性，将安全性分析简化为 Bell 对角态的混合，从而得到密钥率的闭式公式。

Result: 研究表明，该协议在面对集体攻击时，能够提供安全的密钥生成。通过与现有 DI-QKD 协议的性能进行对比，特别是在模拟去极化噪声的情况下，证明了该协议能够容忍更高的量子比特错误率 (QBER)。此外，研究还发现，与 DI-QKD 需要近乎完美的探测效率不同，该协议即使在低探测效率下也能实现安全的密钥生成。

Conclusion: 1sDI-QKD 协议在面对集体攻击时，其安全性可以通过 CJWR 不等式的线性量子 त्याची 关系来保证，并且能够容忍比现有的 DI-QKD 协议更高的量子比特错误率 (QBER)。即使在探测效率较低的情况下，该协议也能够实现安全的密钥生成，证明了其在当前技术下的可行性，并强调了其作为基于 steering 的安全量子通信替代方案的优势。

Abstract: We study the security of a quantum key distribution (QKD) protocol under the
one-sided device-independent (1sDI) setting, which assumes trust in only one
party's measurement device. This approach effectively provides a balance
between the experimental viability of device-dependent (DD-QKD) and the minimal
trust assumptions of device-independent (DI-QKD). An analytical lower bound on
the asymptotic key rate is derived to provide security against collective
attacks, in which the eavesdropper's information is limited only by the
function of observed violation of a linear quantum steering inequality,
specifically the three-setting Cavalcanti--Jones--Wiseman--Reid (CJWR)
inequality. We provide a closed-form key rate formula by reducing the security
analysis to mixtures of Bell-diagonal states by utilizing symmetries of the
steering functional. We show that the protocol tolerates higher quantum bit
error rates (QBER) than present DI-QKD protocols by benchmarking its
performance under depolarizing noise. Furthermore, we explore the impact of
detection inefficiencies and show that, in contrast to DI-QKD, which requires
near-perfect detection, secure key generation can be achieved even with lower
detection efficiency on the untrusted side. These findings demonstrate the
viability of using 1sDI-QKD with current technology and highlight its
advantages as a steering-based substitute for secure quantum communication.

</details>


### [241] [Fully quantum description of the four-wave mixing contribution to correlated Stokes-anti-Stokes scattering](https://arxiv.org/abs/2507.18751)
*Raul Corrêa,Marcelo F. Santos,Carlos H. Monken,Ado Jorio*

Main category: quant-ph

TL;DR: 本文为量子光学技术提供了基于斯托克斯-反斯托克斯（SaS）散射的量子理论描述。


<details>
  <summary>Details</summary>
Motivation: 为了给基于斯托克斯-反斯托克斯（SaS）散射产生纠缠光子对的量子光学技术提供一个完善的量子理论描述。

Method: 本文采用量子微扰理论，利用海森堡绘景下的量子电动力学，对拉曼散射过程进行了详细的量子理论推导。

Result: 本文成功地推导了斯托克斯-反斯托克斯（SaS）散射的量子理论，并证明了该过程与四波混频现象相对应。

Conclusion: 本文提出了量子受激拉曼散射的量子理论描述，并推导了其在光学和社会科学中的应用。

Abstract: The process in which Raman scattering produces correlated Stokes and
anti-Stokes radiation is known as Stokes-anti-Stokes (SaS) scattering. It has
been shown recently that this process can generate entangled photon pairs,
making it a promising tool for quantum optical technologies, but a proper
quantum theoretical description was lacking. In this paper, a fully quantum
derivation of the electric polarization in a medium with vibrational Raman
response, with quantized electromagnetic fields, is developed. Using quantum
perturbation theory for Heisenberg operators, we find the solution for the
material electric polarization and show that the correlated SaS scattering
appears in the first order of perturbation, corresponding to a four-wave mixing
phenomenon. We also discuss how to construct the third-order non-linear optical
susceptibility for the SaS scattering from the quantum formalism, and show that
it coincides with the one derived for classical fields in stimulated Raman.

</details>


### [242] [Digital Twin Simulations Toolbox of the Nitrogen-Vacancy Center in Diamond](https://arxiv.org/abs/2507.18759)
*Lucas Tsunaki,Anmol Singh,Sergei Trofimov,Boris Naydenov*

Main category: quant-ph

TL;DR: 这项研究开发了一个名为“数字孪生”的Python软件，用于精确模拟金刚石中氮-空位（NV）中心的量子动力学，考虑了真实的脉冲和环境因素，并在量子计算、传感和网络领域得到了验证。


<details>
  <summary>Details</summary>
Motivation: 为了在量子技术应用领域（特别是金刚石中的氮-空位（NV）中心）持续取得进展，精确且严格的NV系统数值模拟是必不可少的。

Method: 该模拟框架基于非微扰时间依赖的哈密顿模型，并在实验室框架中求解，消除了瞬时脉冲和旋转波近似等简化假设，能够揭示真实脉冲约束对量子系统的细微影响。

Result: 通过三个用例研究（量子计算中的两比特条件逻辑门、量子传感中的抗噪声动力学解耦序列以及量子网络中的NV间量子态传输）以及与实验结果的对比，验证了该软件的准确性和实用性。

Conclusion: 该研究开发了一个用于模拟氮-空位（NV）自旋动力学的Python软件，该软件可以考虑电磁脉冲和环境输入等因素，并能精确地模拟NV系统的时域演化动力学，从而产生量子力学可观测量的物理输出（如荧光）。

Abstract: Color centers defects in solids, and particularly the nitrogen-vacancy (NV)
center in diamond, are crucial physical platforms for quantum technology
applications. Therefore, a precise and rigorous numerical modeling of the NV
system is indispensable for the continued advancement of the field. Within this
context, this work develops a Python software for simulating the NV spin
dynamics in pulsed sequences under general experimental conditions, i.e. a
digital twin. The library accounts for electromagnetic pulses and other
environmental inputs, which are used to solve the system's time-evolution
dynamics, resulting in a physical output in the form of a quantum mechanical
observable given by the fluorescence. The simulations framework is based on a
non-perturbative time-dependent Hamiltonian model, solved in the laboratory
frame. Whereby eliminating oversimplifications such as the assumption of
instantaneous $\delta$-pulses and rotating wave approximations, our simulations
reveal subtle dynamics from the realistic pulse constraints that impact quantum
systems. Three use-case examples illustrate the use of the software and
validate it by comparing the simulation results with well-established
experimental works, relevant to the fields of quantum computing (two-qubit
conditional logic gates), sensing (noise resilient dynamical decoupling
sequences between NV and couples spins) and networks (teleportation of a
quantum state between entangled NVs). Overall, this digital twin delivers a
robust and detailed numerical modeling of the NV spin dynamics, with simple and
accessible usability, for an extensive application range.

</details>


### [243] [Unconditional Pseudorandomness against Shallow Quantum Circuits](https://arxiv.org/abs/2507.18796)
*Soumik Ghosh,Sathyawageeswar Subramanian,Wei Zhan*

Main category: quant-ph

TL;DR: 本研究在无条件安全的前提下，首次针对浅层量子电路（如 $\mathsf{QNC}^0$ 和 $\mathsf{AC}^0\circ\mathsf{QNC}^0$）提出了有效的伪随机构造，解决了现有构造依赖复杂性假设的问题，并为量子复杂性理论开辟了新方向。


<details>
  <summary>Details</summary>
Motivation: 量子计算伪随机性在复杂性理论、密码学和物理学中至关重要。然而，现有的高效量子安全伪随机构造都依赖于复杂性理论假设。本研究旨在探索在无条件安全前提下，针对特定量子电路类别实现伪随机构造的可能性。

Method: 本研究通过证明量子状态2-设计和随机相位子空间状态（相位由4-元独立函数选取）的伪随机性，以及酉2-设计的伪随机性来实现。

Result: 本研究成功构建了首批无条件安全的、针对浅层量子电路类别的有效伪随机构造。具体而言，量子状态2-设计能抵抗具有任意数量辅助比特的 $\mathsf{QNC}^0$ 电路和具有近乎线性数量辅助比特的 $\mathsf{AC}^0\circ\mathsf{QNC}^0$ 电路。随机相位子空间状态对这些电路类别也表现出无条件伪纠缠性。酉2-设计则能提供针对几何局部 $\mathsf{QNC}^0$ 敌手的无条件安全并行查询伪随机酉。

Conclusion: 本研究首次在无条件安全的前提下，针对浅层量子电路类别构建了有效的伪随机构造。研究结果表明，量子状态2-设计可以提供针对具有任意数量辅助比特的 $\mathsf{QNC}^0$ 电路以及具有近乎线性数量辅助比特的 $\mathsf{AC}^0\circ\mathsf{QNC}^0$ 电路的无条件伪随机性。此外，使用4-元独立函数选取相位的随机相位子空间状态，对于上述电路类别具有无条件伪纠缠性。同时，任何酉2-设计都能提供针对几何局部 $\mathsf{QNC}^0$ 敌手（即使经过有限的 $\mathsf{AC}^0$ 后处理）的无条件安全并行查询伪随机酉。

Abstract: Quantum computational pseudorandomness has emerged as a fundamental notion
that spans connections to complexity theory, cryptography and fundamental
physics. However, all known constructions of efficient quantum-secure
pseudorandom objects rely on complexity theoretic assumptions.
  In this work, we establish the first unconditionally secure efficient
pseudorandom constructions against shallow-depth quantum circuit classes. We
prove that:
  $\bullet$ Any quantum state 2-design yields unconditional pseudorandomness
against both $\mathsf{QNC}^0$ circuits with arbitrarily many ancillae and
$\mathsf{AC}^0\circ\mathsf{QNC}^0$ circuits with nearly linear ancillae.
  $\bullet$ Random phased subspace states, where the phases are picked using a
4-wise independent function, are unconditionally pseudoentangled against the
above circuit classes.
  $\bullet$ Any unitary 2-design yields unconditionally secure parallel-query
pseudorandom unitaries against geometrically local $\mathsf{QNC}^0$
adversaries, even with limited $\mathsf{AC}^0$ postprocessing.
  Our indistinguishability results for 2-designs stand in stark contrast to the
standard setting of quantum pseudorandomness against $\mathsf{BQP}$ circuits,
wherein they can be distinguishable from Haar random ensembles using more than
two copies or queries. Our work demonstrates that quantum computational
pseudorandomness can be achieved unconditionally for natural classes of
restricted adversaries, opening new directions in quantum complexity theory.

</details>


### [244] [Co-optimization of codon usage and mRNA secondary structure using quantum computing](https://arxiv.org/abs/2507.18817)
*Dimitris Alevras,Mihir Metkar,Triet Friedhoff,Jae-Eun Park,Mariana LaDue,Vaibhaw Kumar,Wade Davis,Alexey Galda*

Main category: quant-ph

TL;DR: Co-optimizing mRNA sequences for both codon optimality and secondary structure is crucial for producing stable and efficacious mRNA therapeutics. This paper introduces a novel variational framework that simultaneously optimizes codon usage and secondary structure using a dual-objective function that balances the codon adaptation index (CAI) and minimum free energy (MFE), incorporating variational parameters for codon selection. The method employs a hybrid quantum-classical computational strategy and has been demonstrated on IBM's 127-qubit Eagle processor, showing potential for accelerating the design of optimal mRNA constructs.


<details>
  <summary>Details</summary>
Motivation: 为了在体外和细胞内获得稳定的分子，优化密码子以提高翻译效率，同时优化 mRNA 的二级结构，这是至关重要的。

Method: 提出了一种新颖的变分框架，可以同时优化密码子使用和二级结构，该方法采用平衡密码子适应指数 (CAI) 和最小自由能 (MFE) 的双目标函数，并结合了用于密码子选择的变分参数。利用混合量子-经典计算策略，并在量子算法的基础上，有效解决了复杂的优化空间。

Result: 通过在最多 30 个核苷酸的序列上进行模拟和量子硬件实验，证明了该方法在 IBM 的 127 核子 Eagle 处理器上执行端到端工作流的可行性。

Conclusion: 该框架有潜力加速优化用于治疗和研究的 mRNA 结构的设计。

Abstract: Co-optimizing mRNA sequences for both codon optimality and secondary
structure is crucial for producing stable and efficacious mRNA therapeutics.
Codon optimization, which adjusts nucleotide sequences to enhance translational
efficiency, inherently influences mRNA secondary structure - a key determinant
of molecular stability both in-vial and in-cell. Because both properties are
governed by the same underlying sequence, optimizing one directly impacts the
other. To address this interdependence, we introduce a novel variational
framework that simultaneously optimizes codon usage and secondary structure.
Our method employs a dual-objective function that balances the codon adaptation
index (CAI) and minimum free energy (MFE), incorporating variational parameters
for codon selection. Leveraging a hybrid quantum-classical computational
strategy and building on prior advancements in quantum algorithms for secondary
structure prediction, we effectively navigate this complex optimization space.
We demonstrate the feasibility of executing this end-to-end workflow on real
quantum hardware, using IBM's 127-qubit Eagle processor. We validate our
approach through both simulations and quantum hardware experiments on sequences
of up to 30 nucleotides. These results highlight the potential of our framework
to accelerate the design of optimal mRNA constructs for therapeutic and
research applications.

</details>


### [245] [Programmable Exploration of Magnetic States in Lieb-Kagome Interpolated Lattices](https://arxiv.org/abs/2507.18822)
*Alejandro Lopez-Bezanilla,Pavel A. Dub,Avadh Saxena*

Main category: quant-ph

TL;DR: 本研究利用量子退火器模拟分子量子比特晶格中的磁相互作用，并成功模拟了从Lieb到kagome晶格的连续变形，揭示了挫致无序和磁场诱导重排现象，为设计可调谐磁态的合成量子材料提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 为了模拟分子量子比特晶格中的磁相互作用，并探索可调谐磁态的合成量子材料。

Method: 本研究采用混合建模框架，利用量子退火器模拟分子量子比特晶格中的磁相互作用，并以酞菁组装体为原型，模拟了从Lieb到kagome晶格的连续变形。

Result: 量子退火器能够获取广泛参数空间中的静态结构因子和磁化强度等可观测值，揭示了模型中的挫致无序和磁场诱导重排现象。

Conclusion: 该研究提出的量子模拟框架为探索和设计可调谐磁态的合成量子材料提供了一条新途径，并为化学、凝聚态物理和量子信息科学中工程量子物质的极限提供了模块化和可扩展的研究范式。

Abstract: We investigate a hybrid modeling framework in which a quantum annealer is
used to simulate magnetic interactions in molecular qubit lattices inspired by
experimentally realizable systems. Using phthalocyanine assemblies as a
structurally constrained prototype, we model a continuous deformation from a
Lieb to a kagome lattice, revealing frustration-driven disorder and magnetic
field-induced reordering in the spin structure. The annealer provides access to
observables such as the static structure factor and magnetization over a wide
parameter space, enabling the characterization of magnetic arrangements beyond
the reach of current molecular architectures. This surrogate modeling approach
supports a feedback loop between experiment and programmable quantum hardware,
offering a pathway to explore and iteratively design tunable magnetic states in
synthetic quantum materials. The synthetic design, structural characterization,
and quantum simulation framework established here defines a modular and
scalable paradigm for probing the limits of engineered quantum matter across
chemistry, condensed matter, and quantum information science.

</details>


### [246] [Apparent energy-speed relationship poses no challenge to Bohmian mechanics](https://arxiv.org/abs/2507.18826)
*Matthew Dickau*

Main category: quant-ph

TL;DR: 文章反驳了一篇声称实验结果挑战玻姆力学的文章，指出其解释错误，并证明了在试点波理论下，实验结果与普通量子力学一致，测量到的速度是虚构的。


<details>
  <summary>Details</summary>
Motivation: 反驳一篇声称实验结果挑战玻姆力学的文章，并指出其对实验的解释是错误的。

Method: 通过对试点波理论的分析，证明了该实验测量的粒子速度是虚构的，其结果与普通量子力学一致。

Result: 试点波理论预测的粒子位置分布与普通量子力学相同，实验测量到的速度是虚构的。

Conclusion: 该实验测量到的速度是虚构的，并且其结果在试点波视角下与普通量子力学预测的粒子位置分布相同。

Abstract: A recent article claims to measure the speed of quantum particles in the
classically forbidden regime where the energy of the particles is lower than
the local potential, and further claims that the results of this experiment
challenge Bohmian mechanics. But this interpretation of the experiment is
incorrect (and dubious even in the context of ordinary quantum mechanics). A
proper analysis of the system from a pilot-wave perspective shows that it
predicts the same distribution of particle positions (and so the same
experimental results) as ordinary quantum theory. The speed measured by the
experiment in this regime is fictitious.

</details>


### [247] [Exploring Entanglement and Parameter Sensitivity in QAOA through Quantum Fisher Information](https://arxiv.org/abs/2507.18844)
*Brian García Sarmina,Jorge Saavedra Benavides,Guo-Hua Sun,Shi-Hai Dong*

Main category: quant-ph

TL;DR: 本研究分析了QAOA的量子Fisher信息（QFI），发现完全图和纠缠层会影响QFI分布。基于此提出了一种名为QIm的优化方法，在测试中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 为了量化量子状态对变分参数的敏感度，并将其应用于QAOA等算法的分析和优化。研究旨在理解不同图结构、混合器类型、算法深度以及纠缠策略对QAOA性能的影响，并通过QFI的洞察提出改进算法的方法。

Method: 对具有N=4-10量子比特的环状和完全图上的QAOA进行系统QFI分析，研究了两种混合器（仅RX和混合RX-RY）以及不同深度（p=2, 4, 6和p=3, 6, 9）和最多三层纠缠。提出了一种QFI驱动的变异（QIm）启发式方法，利用归一化的对角QFI来设置变异概率和步长。

Result: 完全图的QFI特征值大于环状图。所有设置均未达到海森堡极限（4N^2），但部分设置超过了线性边界（4N）。纠缠层增加了参数间的协方差和相关性，但超过一层后收益递减。QIm启发式方法在7和10量子比特的实例上，相比于等概率和随机重启基线，获得了更高的平均能量和更低的方差。

Conclusion: 研究表明，量子Fisher信息（QFI）可用于量化量子状态对变分参数变化的敏感度，可作为量子近似优化算法（QAOA）的诊断工具。研究对QAOA在不同图（环状和完全图）上，使用不同混合器（仅RX和混合RX-RY）及不同深度（p=2, 4, 6和p=3, 6, 9）和纠缠层数（0-3层）的QFI进行了系统分析。研究发现，完全图的QFI特征值普遍高于环状图，但均未达到海森堡极限（4N^2），部分超过了线性边界（4N）。纠缠主要将QFI从对角项重新分配到非对角项，非纠缠电路最大化了单参数敏感度，而纠缠层增加了协方差比例和参数间相关性。基于这些发现，提出了一种QFI驱动的变异（QIm）启发式方法，该方法根据归一化的对角QFI设置变异概率和步长。在7和10量子比特实例上，QIm的平均能量更高，方差更低，优于等概率和随机重启基线，表明QFI可作为QAOA和其他变分量子算法的轻量级、面向问题的预条件子。

Abstract: Quantum Fisher Information (QFI) can be used to quantify how sensitive a
quantum state reacts to changes in its variational parameters, making it a
natural diagnostic for algorithms such as the Quantum Approximate Optimization
Algorithm (QAOA). We perform a systematic QFI analysis of QAOA for Max-Cut on
cyclic and complete graphs with $N = 4 - 10$ qubits. Two mixer families are
studied, RX-only and hybrid RX-RY, with depths $p = 2, 4, 6$ and $p = 3, 6, 9$,
respectively, and with up to three entanglement stages implemented through
cyclic- or complete-entangling patterns. Complete graphs consistently yield
larger QFI eigenvalues than cyclic graphs; none of the settings reaches the
Heisenberg limit ($4N^2$), but several exceed the linear bound ($4N$).
Introducing entanglement primarily redistributes QFI from diagonal to
off-diagonal entries: non-entangled circuits maximize per-parameter (diagonal)
sensitivity, whereas entangling layers increase the covariance fraction and
thus cross-parameter correlations, with diminishing returns beyond the first
stage. Leveraging these observations, we propose, as a proof of concept, a
QFI-Informed Mutation (QIm) heuristic that sets mutation probabilities and step
sizes from the normalized diagonal QFI. On 7- and 10-qubit instances, QIm
attains higher mean energies and lower variance than equal-probability and
random-restart baselines over 100 runs, underscoring QFI as a lightweight,
problem-aware preconditioner for QAOA and other variational quantum algorithms.

</details>


### [248] [Optimising Perfect Quantum State Transfer for Timing Insensitivity](https://arxiv.org/abs/2507.18872)
*Alastair Kay,Sooyeong Kim,Christino Tamon*

Main category: quant-ph

TL;DR: 研究了量子态完美传输对时间的敏感性，并设计了工程化的自旋链来降低这种敏感性，证明了其渐近最优性，并将其应用于创建叠加态。


<details>
  <summary>Details</summary>
Motivation: 研究量子态在两个位点之间完美传输的完美传输对时间的敏感性。

Method: 设计了工程化的自旋链来降低时间敏感性。

Result: 证明了该构造渐近最优，并将相同的构造应用于创建叠加态（也称为分数复兴）。

Conclusion: 设计了工程化的自旋链以降低时间敏感性，并证明了该构造渐近最优。

Abstract: When studying the perfect transfer of a quantum state from one site to
another, it is typically assumed that one can receive the arriving state at a
specific instant in time, with perfect accuracy. Here, we study how sensitive
perfect state transfer is to that timing. We design engineered spin chains
which reduce their sensitivity, proving that this construction is
asymptotically optimal. The same construction is applied to the task of
creating superpositions, also known as fractional revival.

</details>


### [249] [Almost fault--tolerant quantum machine learning with drastic overhead reduction](https://arxiv.org/abs/2507.18954)
*Haiyue Kang,Younghun Kim,Eromanga Adermann,Martin Sevior,Muhammad Usman*

Main category: quant-ph

TL;DR: 该研究提出了一种资源高效的部分量子纠错方法，以解决近期量子计算机中QML模型的训练和性能问题，展示了在噪声环境中实现可训练和高精度QML的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前量子处理器中的错误会引起训练问题（噪声诱导的巴鲁高原）和性能下降（噪声累积），而现有的量子纠错（QEC）方案由于开销过高（特别是魔态蒸馏），不适用于近期实际部署。

Method: 通过假设纠错的两比特CNOT门（Clifford操作），并分析不同噪声模型（如相位阻尼和低温热耗散通道）下的QML模型表现，来论证部分量子纠错的可行性与有效性。

Result: 在部分量子纠错框架下，即使单比特门存在约0.2%的去极化噪声（根据随机基准测试，门错误率为0.13%），QML模型仍可训练。此外，研究还表明QML模型与过旋转平均角度无关，甚至可以通过热阻尼得到改善。

Conclusion: 该研究提出了部分量子纠错（QEC）用于量子机器学习（QML）模型，在省略蒸馏步骤以显著降低开销的同时，还能保持QML模型可训练，并能有效应对噪声。

Abstract: Errors in the current generation of quantum processors pose a significant
challenge towards practical-scale implementations of quantum machine learning
(QML) as they lead to trainability issues arising from noise-induced barren
plateaus, as well as performance degradations due to the noise accumulation in
deep circuits even when QML models are free from barren plateaus. Quantum error
correction (QEC) protocols are being developed to overcome hardware noise, but
their extremely high spacetime overheads, mainly due to magic state
distillation, make them infeasible for near-term practical implementation. This
work proposes the idea of partial quantum error correction (QEC) for quantum
machine learning (QML) models and identifies a sweet spot where distillations
are omitted to significantly reduce overhead. By assuming error-corrected
two-qubit CNOTs (Clifford operations), we demonstrate that the QML models
remain trainable even when single-qubit gates are subjected to $\approx0.2\%$
depolarizing noise, corresponding to a gate error rate of $\approx0.13\%$ under
randomized benchmarking. Further analysis based on various noise models, such
as phase-damping and thermal-dissipation channels at low temperature, indicates
that the QML models are trainable independent of the mean angle of
over-rotation, or can even be improved by thermal damping that purifies a
quantum state away from depolarizations. While it may take several years to
build quantum processors capable of fully fault-tolerant QML, our work proposes
a resource-efficient solution for trainable and high-accuracy QML
implementations in noisy environments.

</details>


### [250] [Quantum simulation of multiscale linear transport equations via Schrödingerization and exponential integrators](https://arxiv.org/abs/2507.18970)
*Xiaoyang He,Shi Jin*

Main category: quant-ph

TL;DR: 本文提出两种新的量子算法，用于解决多尺度线性输运方程，复杂度优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决多尺度线性输运方程，并提出比现有算法更优越的量子和经典算法。

Method: 结合Schr"odingerization方法和指数积分器，并纳入入射边界条件，设计了两种哈密顿模拟算法。

Result: 开发了两种查询复杂度为$\|mathcal{O}(\mathcal{N}_v\mathcal{N}_x^2\log \mathcal{N}_x)$的哈密顿模拟算法，在处理多尺度线性输运方程方面优于现有算法。

Conclusion: 本文提出了两种用于多尺度线性输运方程的哈密顿模拟算法，结合了Schr"odingerization方法和指数积分器，并纳入了入射边界条件。这两种算法在设计和可扩展性方面各有优势，其查询复杂度为$\|mathcal{O}(\mathcal{N}_v\mathcal{N}_x^2\log \mathcal{N}_x)$，优于现有的求解该方程的量子和经典算法。理论上，这是首次将Schr"odingerization方法与有效的渐近保持格式相结合，用于多尺度线性输运方程的量子哈密顿模拟算法，能够有效处理具有僵硬项的多尺度问题。

Abstract: In this paper, we present two Hamiltonian simulation algorithms for
multiscale linear transport equations, combining the Schr\"odingerization
method [S. Jin, N. Liu and Y. Yu, Phys. Rev. Lett, 133 (2024), 230602][S. Jin,
N. Liu and Y. Yu, Phys. Rev. A, 108 (2023), 032603] and exponential integrator
while incorporating incoming boundary conditions. These two algorithms each
have advantages in terms of design easiness and scalability, and the query
complexity of both algorithms, $\mathcal{O}(N_vN_x^2\log N_x)$, outperforms
existing quantum and classical algorithms for solving this equation. In terms
of the theoretical framework, these are the first quantum Hamiltonian
simulation algorithms for multiscale linear transport equation to combine the
Schr\"odingerization method with an effective asymptotic-preserving schemes,
which are efficient for handling multiscale problems with stiff terms.

</details>


### [251] [Scalable native multi-qubit gates for fluxonium architectures with tunable plasmon interactions](https://arxiv.org/abs/2507.18984)
*Peng Zhao,Peng Xu,Zheng-Yuan Xue*

Main category: quant-ph

TL;DR: 通量量子比特通过可调谐等离激元相互作用，可以原生实现可扩展的多量子比特门，并保持与现有单比特和双比特门的兼容性。


<details>
  <summary>Details</summary>
Motivation: 尽管通量量子比特因其强非调和性和高相干性而成为超导量子计算的有希望的量子比特模式，但其实现高保真度可扩展纠缠门的能力仍有待观察。

Method: 研究人员展示了 fluxonium 量子比特架构如何利用非计算流形的工程相互作用来实现多量子比特门。具体方法是通过驱动量子比特状态选择性地跃迁到非计算流形来实现 C^⊗N Z 门（N≥2）。

Result: 研究表明，CCZ、CCCZ 和 CCCCZ 门的保真度分别约为 0.01 (0.001)，门操作时间分别为 50 (100) ns、100 (250) ns 和 150 (300) ns。

Conclusion: Fluxonium 量子比特架构通过可调谐等离激元相互作用，能够实现可扩展的多量子比特门，并且与现有的单量子比特和双量子比特门兼容。通过驱动量子比特选择性跃迁到非计算流形，可以实现 C^⊗N Z 门（N≥2）。

Abstract: Fluxoniums have emerged as a compelling qubit modality for superconducting
quantum computing, owing to their strong anharmonicity and high coherence.
However, it remains to be seen whether the implementation of high-fidelity
entangling gates in a scalable manner will be achieved or not for fluxoniums.
Here, we show that fluxonium architectures with tunable plasmon interactions
have the capability to implement scalable multi-qubit gates natively while
remaining compatible with existing single- and two-qubit gate realizations.
Within the architecture, even though qubit states are decoupled, engineered
interactions in noncomputational manifolds can facilitate the realization of
$(C^{\otimes N})Z$ gates (for $N\geq 2$). This is accomplished by driving
qubit-state selective transitions into noncomputational manifolds. Our case
studies show that CCZ, CCCZ, and CCCCZ gates with errors of approximately 0.01
(0.001) are achievable, with gate lengths of $50\,(100)\,\text{ns}$,
$100\,(250)\,\text{ns}$, and $150\,(300)\,\text{ns}$, respectively. These
results underscore the potential of the fluxonium architecture for scalable
quantum computation through fast, high-fidelity native multi-qubit gates.

</details>


### [252] [Approximate k-uniform states: definition, construction and applications](https://arxiv.org/abs/2507.19018)
*Kaiyi Guo,Fei Shi,You Zhou,Qi Zhao*

Main category: quant-ph

TL;DR: $k$-均匀态的实际应用需要研究近似$k$-均匀态。本研究表明，近似$k$-均匀态与精确$k$-均匀态局部不可区分，并可以通过哈尔随机系综和浅层随机量子电路构建。此外，还建立了近似$k$-均匀态与近似量子纠错码之间的联系。


<details>
  <summary>Details</summary>
Motivation: 在实际场景中，精确$k$-均匀态的生成既不可行也无必要，因此需要研究近似$k$-均匀态。

Method: 研究近似$k$-均匀态，证明它们与精确$k$-均匀态局部不可区分，并通过哈尔随机系综和浅层随机量子电路构建它们。

Result: $k$-均匀态可从哈尔随机系综和浅层随机量子电路中高概率构建。近似$k$-均匀态可用于构建高性能的近似量子纠错码，但浅层随机量子电路无法在浅层深度构造具有线性码率的码。

Conclusion: 本研究为$k$-均匀态的实际应用奠定了基础，并揭示了其与近似量子纠错码和近似量子信息隐藏的关系。

Abstract: $k$-Uniform states are fundamental to quantum information and computing, with
applications in multipartite entanglement and quantum error-correcting codes
(QECCs). Prior work has primarily focused on constructing exact $k$-uniform
states or proving their nonexistence. However, due to inevitable theoretical
approximations and experimental imperfections, generating exact $k$-uniform
states is neither feasible nor necessary in practice. In this work, we initiate
the study of approximate $k$-uniform states, demonstrating that they are
locally indistinguishable from their exact counterparts unless massive
measurements are performed. We prove that such states can be constructed with
high probability from the Haar-random ensemble and, more efficiently, via
shallow random quantum circuits. Furthermore, we establish a connection between
approximate $k$-uniform states and approximate QECCs, showing that Haar random
constructions yield high-performance codes with linear rates, vanishing
proximity, and exponentially small failure probability while random circuits
can't construct codes with linear code rate in shallow depth. Finally, we
investigate the relationship between approximate QECCs and approximate quantum
information masking. Our work lays the foundation for the practical application
of $k$-uniform states.

</details>


### [253] [PGKET: A Photonic Gaussian Kernel Enhanced Transformer](https://arxiv.org/abs/2507.19041)
*Ren-Xin Zhao*

Main category: quant-ph

TL;DR: A new photonic transformer (PGKET) uses a novel self-attention mechanism (PGKSAM) to efficiently process long sequences, outperforming existing models in classification tasks and potentially accelerating Photonic Computing and machine learning.


<details>
  <summary>Details</summary>
Motivation: Self-Attention Mechanisms (SAMs) are inefficient when dealing with long sequences.

Method: The paper proposes a photonic Gaussian Kernel Enhanced Transformer (PGKET) based on the Photonic Gaussian Kernel Self-Attention Mechanism (PGKSAM). The PGKSAM calculates the Photonic Gaussian Kernel Self-Attention Score (PGKSAS) using photon interferometry and superposition to process multiple inputs in parallel.

Result: PGKET outperforms some state-of-the-art transformers in multi-classification tasks on MedMNIST v2 and CIFAR-10.

Conclusion: PGKET outperforms some state-of-the-art transformers in multi-classification tasks on MedMNIST v2 and CIFAR-10, and is expected to improve performance in complex tasks and accelerate the convergence of Photonic Computing (PC) and machine learning.

Abstract: Self-Attention Mechanisms (SAMs) enhance model performance by extracting key
information but are inefficient when dealing with long sequences. To this end,
a photonic Gaussian Kernel Enhanced Transformer (PGKET) is proposed, based on
the Photonic Gaussian Kernel Self-Attention Mechanism (PGKSAM). The PGKSAM
calculates the Photonic Gaussian Kernel Self-Attention Score (PGKSAS) using
photon interferometry and superposition to process multiple inputs in parallel.
Experimental results show that PGKET outperforms some state-of-the-art
transformers in multi-classification tasks on MedMNIST v2 and CIFAR-10, and is
expected to improve performance in complex tasks and accelerate the convergence
of Photonic Computing (PC) and machine learning.

</details>


### [254] [Graph Neural Network-Based Predictor for Optimal Quantum Hardware Selection](https://arxiv.org/abs/2507.19093)
*Antonio Tudisco,Deborah Volpe,Giacomo Orlandi,Giovanna Turvani*

Main category: quant-ph

TL;DR: 使用GNN模型自动选择最佳量子硬件平台，准确率达94.4%，解决了传统方法计算成本高的问题。


<details>
  <summary>Details</summary>
Motivation: 随着量子硬件技术种类的不断增长及其独特的连接性和原生门集等特性，为特定量子电路选择最佳执行平台变得更具挑战性。传统的暴力编译和评估方法计算成本高昂且难以扩展。因此，有必要开发一种更高效、可扩展的自动化方法来解决这一问题。

Method: 本文提出了一种基于图神经网络（GNN）的预测模型，该模型直接分析量子电路的定向无环图（DAG）表示，以预测在不同量子硬件平台上（包括超导和离子阱处理器）的最佳执行方式。通过在498个量子电路（最多27个量子比特）上进行测试，并结合电路深度和门保真度作为性能指标，模型能够识别出哪些电路更适合在超导平台执行，哪些更适合在离子阱平台执行。

Result: 研究评估了498个量子电路（最多27个量子比特），结果显示93个电路在离子阱设备上编译效果最佳，其余电路在超导平台上表现更好。GNN模型在预测最佳编译目标方面达到了94.4%的准确率和85.5%的F1分数（针对少数类），证明了其有效性。

Conclusion: 本研究提出的基于图神经网络（GNN）的预测器能够通过分析量子电路的定向无环图（DAG）表示来自动化硬件选择过程，实验结果证明了其预测的准确性（94.4%）和对少数类（倾向于离子阱设备）的F1分数（85.5%），从而有效加速了最佳编译目标的决策过程。

Abstract: The growing variety of quantum hardware technologies, each with unique
peculiarities such as connectivity and native gate sets, creates challenges
when selecting the best platform for executing a specific quantum circuit. This
selection process usually involves a brute-force approach: compiling the
circuit on various devices and evaluating performance based on factors such as
circuit depth and gate fidelity. However, this method is computationally
expensive and does not scale well as the number of available quantum processors
increases. In this work, we propose a Graph Neural Network (GNN)-based
predictor that automates hardware selection by analyzing the Directed Acyclic
Graph (DAG) representation of a quantum circuit. Our study evaluates 498
quantum circuits (up to 27 qubits) from the MQT Bench dataset, compiled using
Qiskit on four devices: three superconducting quantum processors (IBM-Kyiv,
IBM-Brisbane, IBM-Sherbrooke) and one trapped-ion processor (IONQ-Forte).
Performance is estimated using a metric that integrates circuit depth and gate
fidelity, resulting in a dataset where 93 circuits are optimally compiled on
the trapped-ion device, while the remaining circuits prefer superconducting
platforms. By exploiting graph-based machine learning, our approach avoids
extracting the circuit features for the model evaluation but directly embeds it
as a graph, significantly accelerating the optimal target decision-making
process and maintaining all the information. Experimental results prove 94.4%
accuracy and an 85.5% F1 score for the minority class, effectively predicting
the best compilation target. The developed code is publicly available on GitHub
(https://github.com/antotu/GNN-Model-Quantum-Predictor).

</details>


### [255] [Wave packets, "negative times" and the elephant in the room](https://arxiv.org/abs/2507.19105)
*D. Sokolovski,A. Matzkin*

Main category: quant-ph

TL;DR: Quantum tunneling time is debated due to the difficulty of defining particle duration in a region. This paper uses a Mach-Zehnder interferometer analogy to show that delays in wave packets can occur without resorting to non-physical "superluminal" or "negative" times, attributing the effect to destructive interference.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the controversy surrounding the "tunnelling time problem" in quantum mechanics, specifically the difficulty in defining the duration a particle spends in a region of space during tunneling.

Method: The study uses a tuneable Mach-Zehnder interferometer (MZI) as an analogy for a barrier in quantum mechanics to analyze the "tunnelling time problem". It examines the position of the transmitted wave packet to infer the time spent in the barrier, highlighting the limitations imposed by the Uncertainty Principle when both arms of the MZI are active.

Result: The paper concludes that there is no justification for "superluminal" or "negative" times in tunneling, as a particle can arrive at the same position with higher probability even if only one path is taken. This is analogous to an MZI where delays can be introduced without violating physical principles.

Conclusion: The paper argues against "superluminal" or "negative" times in tunneling by using a Mach-Zehnder interferometer (MZI) analogy. It suggests that the transmitted wave packet in tunneling arises from destructive interference, similar to how an MZI can delay wave packets without invoking non-physical times.

Abstract: Controversy surrounding the "tunnelling time problem" stems from the seeming
inability of quantum mechanics to provide, in the usual way, a definition of
the duration a particle is supposed to spend in a given region of space. For
this reason, the problem is often approached from an "operational" angle. One
such approach uses the position of the transmitted wave packet in order to
infer the duration the particle spends in the barrier. Here we replace the
barrier with a tuneable Mach-Zehnder interferometer (MZI). With this analogy
one is able, at least in principle, to achieve any advance or delay of the wave
packet sent to the chosen outgoing port. The Uncertainty Principle prevents one
from combining the durations spent in each arm the MZI into a meaningful
duration when both arms are engaged. There is no justification for invoking
"superluminal" or "negative" times, since the particle is able to arrive at the
same position (and with a higher probability) if the same initial state
propagates through only one arm of the MZI. The same is true, we argue, in the
case of tunnelling,
  where the transmitted wave packet results from destructive interference
between multiple copies of the free state, delayed relative to the free
propagation

</details>


### [256] [Photon condensation from thermal sources and the limits of heat engines](https://arxiv.org/abs/2507.19128)
*Luisa Toledo Tude,Emily Haughton,Paul R. Eastham*

Main category: quant-ph

TL;DR: 微腔中光子玻色-爱因斯坦凝聚的阈值受热力学第二定律约束，最小阈值与可逆三能级热机相关。


<details>
  <summary>Details</summary>
Motivation: 探究微腔光子气体囚禁和冷却以产生玻色-爱因斯坦凝聚的条件。

Method: 研究了染料填充的微腔中光子凝聚的条件，通过驱动染料跃迁或耦合到外部热光子库（如阳光）来产生光子。

Result: 在染料泵浦的情况下，以及在双能级腔的外部泵浦情况下，实现了可逆三能级热机的最小阈值。对于多能级腔，凝聚发生在相似但更高的温度下，这归因于不可逆传热和相关的熵产生。

Conclusion: 本研究表明，微腔中的光子玻色-爱因斯坦凝聚的阈值泵浦温度受热力学第二定律的制约，并且在可逆三能级热机的条件下可以达到最小阈值。

Abstract: The trapping and cooling of photon gases in microcavities has been used to
create Bose-Einstein condensates. We investigate the conditions required for
condensation in dye-filled microcavities, with photon populations created
either by driving a transition of the dye or by coupling to an external thermal
photon reservoir such as sunlight. We show that the threshold pump temperature,
above which condensation appears, is determined by the second law of
thermodynamics. The minimum achievable threshold is that of a reversible
three-level heat engine, which we show arises in the dye-pumped case, and for
the external pumping of a two-level cavity. For a many-level cavity
condensation occurs at a similar but higher temperature. The increase is
attributed to irreversible heat transfers and the associated entropy
production.

</details>


### [257] [Shallow-depth GHZ state generation on NISQ devices](https://arxiv.org/abs/2507.19145)
*S. Siddardha Chelluri,Stephan Schuster,Sumeet,Riccardo Roma*

Main category: quant-ph

TL;DR: 本研究提出了一种基于测量的协议，用于在具有有限量子比特连通性的 NISQ 设备上生成 GHZ 态，并与基于酉的协议进行了比较。


<details>
  <summary>Details</summary>
Motivation: 本工作专注于在有限量子比特连通性的实际约束下生成 GHZ 态，这是当前 NISQ 硬件的标志。

Method: 本工作提出了一种基于测量的协议，利用量子比特连通性约束在 NISQ 设备上生成 GHZ 态。该协议针对 IBM 和 Google 芯片架构以及随机图的连通性图进行了研究。并将该协议与考虑了物理连通性限制的基于酉的协议进行了基准测试。

Result: 通过在 IBM Eagle r3 芯片上进行实现和广泛的模拟，我们发现基于酉的方法在当前 NISQ 架构下更优，而基于测量的方法在未来对错误更具弹性的设备上潜力更大。在两种情况下，所提出的方法都能有效利用量子比特连接拓扑。

Conclusion: 对于当前的 NISQ 架构，基于酉的方法更适合，因为它避免了中途测量和经典前馈。然而，随着量子设备更能抵抗错误，基于测量的协议有望变得更具优势，因为其电路深度减小，执行时间更短。在这两种情况下，我们提出的方法都提供了一种有效的方法来利用给定设备上可用的量子比特连接拓扑。

Abstract: In this work, we focus on GHZ state generation under the practical constraint
of limited qubit connectivity, a hallmark of current NISQ hardware. We study
the GHZ state preparation across different connectivity graphs inspired by IBM
and Google chip architectures, as well as random graphs that reflect
distributed quantum systems. Our approach is a measurement-based protocol
designed to utilize qubit connectivity constraints for the generation of GHZ
states on NISQ devices. We benchmark this against a tailored version of
state-of-the-art unitary-based protocols, also incorporating physical
connectivity limitations. To evaluate the performance of the protocols under
realistic conditions, we conducted implementations on the IBM Eagle r3 chip.
Additionally, to explore near-term scalability, we performed simulations across
a range of graph sizes and connectivity configurations, assessing performance
based on circuit depth, the number of two-qubit gates, and measurement
overhead. We observe a trade-off between the two protocols across different
figures of merit. For current state-of-the-art NISQ architectures, the
unitary-based protocol is more suitable, as it avoids mid-circuit measurements
and classical feedforward. However, the measurement-based protocol is expected
to become more advantageous in the future with more error-resilient quantum
devices, owing to its reduced circuit depth and consequently shorter execution
times. In both settings, our proposed method provides an efficient means of
leveraging the topology of qubit connections available on a given device.

</details>


### [258] [Pulse-based optimization of quantum many-body states with Rydberg atoms in optical tweezer arrays](https://arxiv.org/abs/2507.19153)
*Kazuma Nagao,Sergi Julià-Farré,Joseph Vovrosh,Alexandre Dauphin,Seiji Yunoki*

Main category: quant-ph

TL;DR: 研究提出了一种创新的脉冲VQE算法，用于在光学镊子阵列中模拟量子自旋模型，并取得了高精度的基态制备结果。混合方案进一步提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了在光学镊子阵列中精确制备量子自旋模型的基态，并提高量子算法的效率和测量精度。

Method: 提出了一种新颖的脉冲驱动的VQE算法，并采用自适应更新策略来优化脉冲序列，同时还提出了一种结合模拟和数字量子计算的混合方案。

Result: 成功制备了一维反铁磁海森堡模型和混合场伊辛模型的基态，准确率高，适用于多达十个量子比特的系统。此外，混合方案能有效测量目标多体哈密顿量的成本函数。

Conclusion: 该研究提出了一种基于脉冲的变分量子特征求解器（VQE）算法，并将其应用于光学镊子阵列中的里德堡原子，用于模拟量子自旋模型。

Abstract: We explore a pulse-based variational quantum eigensolver (VQE) algorithm for
Rydberg atoms in optical tweezer arrays and evaluate its performance on
prototypical quantum spin models. We numerically demonstrate that the ground
states of the one-dimensional antiferromagnetic Heisenberg model and the
mixed-field Ising model can be accurately prepared using an adaptive update
algorithm that randomly segments pulse sequences, for systems of up to ten
qubits. Furthermore, we propose and validate a hybrid scheme that integrates
this pulse-level analog quantum algorithm with a variational quantum gate
approach, where digital quantum gates are approximated by optimized analog
pulses. This enables efficient measurement of the cost function for target
many-body Hamiltonians.

</details>


### [259] [Polaritonic Coupled Cluster Theory for Unpolarized Cavities Exploiting Point Group Symmetry](https://arxiv.org/abs/2507.19180)
*Laurenz Monzel,Stella Stopkowicz*

Main category: quant-ph

TL;DR: A generalized QED-CC ansatz describes light-matter interactions in unpolarized cavities, revealing complex molecular excited states and enabling state assignment via symmetry. Applied to benzene, fluorobenzene, and azulene, it shows more intricate behavior than single-polarization cavities.


<details>
  <summary>Details</summary>
Motivation: To describe strongly coupled light-matter systems in an unpolarized optical Fabry-Pérot cavity by generalizing the quantum electrodynamic coupled cluster (QED-CC) wave function ansatz.

Method: We introduce a generalization of the quantum electrodynamic coupled cluster (QED-CC) wave function ansatz, explicitly treating two cavity modes with perpendicular polarizations to describe strongly coupled light-matter systems in an unpolarized optical Fabry-Pérot cavity. Point-group symmetry is exploited for state assignment and targeted calculations.

Result: The ansatz preserves the symmetry of an unpolarized cavity. Investigations on benzene, fluorobenzene, and azulene reveal complex excited-state landscapes with many avoided crossings. Comparison with a single-polarization cavity using H2 molecule excited states shows differences.

Conclusion: We demonstrate that molecules in unpolarized cavities exhibit complex excited-state landscapes with numerous avoided crossings, and our method allows for the assignment and targeted calculation of polaritonic excited states by exploiting point-group symmetry.

Abstract: We introduce a generalization of the quantum electrodynamic coupled cluster
(QED-CC)wave function ansatz, to describe the strongly coupled light-matter
system in an unpolarized optical Fabry-P\'erot cavity. This is achieved by
explicitly treating two cavity modes in our calculation with perpendicular
polarizations and demonstrate that this ansatz preserves the symmetry of an
unpolarized cavity. Furthermore, exploiting point-group symmetry enables the
assignment of polaritonic excited states as well as their targeted calculation.
Using our implementation, the aromatic species benzene, fluorobenzene and
azulene are investigated. We demonstrate that molecules in unpolarized cavities
have a complicated excited-state landscapes with a plethora of
avoided-crossings. We compare the results for a cavity with a single
polarization to those of an unpolarized cavity described by two perpendicular
polarization vectors using the excited states of the H$_2$ molecule as an
example.

</details>


### [260] [Barren-plateau free variational quantum simulation of Z2 lattice gauge theories](https://arxiv.org/abs/2507.19203)
*Fariha Azad,Matteo Inajetovic,Stefan Kühn,Anna Pappa*

Main category: quant-ph

TL;DR: VQE适用于Z2LGT，并能处理规范不变性问题，有望用于其他规范组的研究。


<details>
  <summary>Details</summary>
Motivation: 研究Z2格规范理论（LGT）的基态和静态弦裂解。

Method: 设计了一个适用于研究Z2格规范理论（LGT）的格易位量子本征求解器（VQE），并使用张量网络方法验证了VQE模拟的结果。

Result: VQE能够得到规范不变的基态，并且在IBM的量子平台上进行了弦裂解实验，验证了VQE在Z2LGT中的应用前景。同时，发现VQE的梯度与量子比特数量的扩展性有利于避免苔原停滞。

Conclusion: VQE是一种有前途的工具，适用于Z2LGT，并可能为其他规范组的研究铺平道路。VQE可以适应不断变化的哈密顿量参数状态和外部电荷，从而在不显式强制执行规范不变性的情况下得出规范不变基态。此外，研究表明，VQE可以避免先验地强制执行规范不变性，这在以前是VQE研究中的一个关键问题。

Abstract: In this work, we design a variational quantum eigensolver (VQE) suitable for
investigating ground states and static string breaking in a $\mathbb{Z}_2$
lattice gauge theory (LGT). We consider a two-leg ladder lattice coupled to
Kogut-Susskind staggered fermions and verify the results of the VQE simulations
using tensor network methods. We find that for varying Hamiltonian parameter
regimes and in the presence of external charges, the VQE is able to arrive at
the gauge-invariant ground state without explicitly enforcing gauge invariance
through penalty terms. Additionally, experiments showing string breaking are
performed on IBM's quantum platform. Thus, VQEs are seen to be a promising tool
for $\mathbb{Z}_2$ LGTs, and could pave the way for studies of other gauge
groups. We find that the scaling of gradients with the number of qubits is
favorable for avoiding barren plateaus. At the same time, it is not clear how
to efficiently simulate the LGT using classical methods. Furthermore,
strategies that avoid barren plateaus arise naturally as features of LGTs, such
as choosing the initialization by setting the Gauss law sector and restricting
the Hilbert space to the gauge-invariant subspace.

</details>


### [261] [Towards System-Level Quantum-Accelerator Integration](https://arxiv.org/abs/2507.19212)
*Ralf Ramsauer,Wolfgang Mauerer*

Main category: quant-ph

TL;DR: 提出了一种新的量子系统架构，通过操作系统内核级别的量子抽象层（QAL）实现量子和经典资源的紧密集成，以满足未来高性能计算和嵌入式环境的需求，并展示了其在不同平台上的仿真结果。


<details>
  <summary>Details</summary>
Motivation: 未来的高性能计算（HPC）和嵌入式环境中的量子计算机部署需要更紧密的集成，以实现更低的延迟、更强的确定性、架构一致性，并支持需要紧密量子-经典交互的错误校正和其他任务。

Method: 提出了一种垂直集成的量子系统架构，将量子加速器和处理单元视为外围系统组件，并引入了操作系统内核级别的量子抽象层（QAL），以实现量子和经典资源之间的实时、低延迟、高吞吐量交互，以及强大的低级量子操作调度和通用资源管理。

Result: 提出了一个虚拟QPU模型，并基于QEMU进行了实现。该架构通过在x86_64、ARM64和RISC-V三种基础架构上的功能仿真以及基于FPGA的计时精确仿真进行了验证，为评估混合系统性能和量子优势场景提供了现实依据。

Conclusion: 这项工作为下一代量子-经典计算的系统级协同设计方法奠定了基础。

Abstract: Quantum computers are often treated as experimental add-ons that are loosely
coupled to classical infrastructure through high-level interpreted languages
and cloud-like orchestration. However, future deployments in both,
high-performance computing (HPC) and embedded environments, will demand tighter
integration for lower latencies, stronger determinism, and architectural
consistency, as well as to implement error correction and other tasks that
require tight quantum-classical interaction as generically as possible.
  We propose a vertically integrated quantum systems architecture that treats
quantum accelerators and processing units as peripheral system components. A
central element is the Quantum Abstraction Layer (QAL) at operating system
kernel level. It aims at real-time, low-latency, and high-throughput
interaction between quantum and classical resources, as well as robust
low-level quantum operations scheduling and generic resource management. It can
serve as blueprint for orchestration of low-level computational components
"around" a QPU (and inside a quantum computer), and across different
modalities.
  We present first results towards such an integrated architecture, including a
virtual QPU model based on QEMU. The architecture is validated through
functional emulation on three base architectures (x86_64, ARM64, and RISC-V),
and timing-accurate FPGA-based simulations. This allows for a realistic
evaluation of hybrid system performance and quantum advantage scenarios. Our
work lays the ground for a system-level co-design methodology tailored for the
next generation of quantum-classical computing.

</details>


### [262] [Resource-Efficient Hadamard Test Circuits for Nonlinear Dynamics on a Trapped-Ion Quantum Computer](https://arxiv.org/abs/2507.19250)
*Eleftherios Mastorakis,Muhammad Umer,Milena Guevara-Bertsch,Juris Ulmanis,Felix Rohde,Dimitris G. Angelakis*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Resource-efficient, low-depth implementations of quantum circuits remain a
promising strategy for achieving reliable and scalable computation on quantum
hardware, as they reduce gate resources and limit the accumulation of noisy
operations. Here, we propose a low-depth implementation of a class of Hadamard
test circuits, complemented by the development of a parameterized quantum
ansatz specifically tailored for variational algorithms that exploit the
underlying Hadamard test framework. Our findings demonstrate a significant
reduction in single- and two-qubit gate counts, suggesting a reliable circuit
architecture for noisy intermediate-scale quantum (NISQ) devices. Building on
this foundation, we tested our low-depth scheme to investigate the expressive
capacity of the proposed parameterized ansatz in simulating nonlinear Burgers'
dynamics. The resulting variational quantum states faithfully capture the
shockwave feature of the turbulent regime and maintain high overlaps with
classical benchmarks, underscoring the practical effectiveness of our
framework. Furthermore, we evaluate the effect of hardware noise by modeling
the error properties of real quantum processors and by executing the
variational algorithm on a trapped-ion-based IBEX Q1 device. The outcomes of
our demonstrations highlight the resilience of our low-depth scheme in the
turbulent regime, consistently preparing high-fidelity variational states that
exhibit strong agreement with classical benchmarks. Our work contributes to the
advancement of resource-efficient strategies for quantum computation, offering
a robust framework for tackling a range of computationally intensive problems
across numerous applications.

</details>


### [263] [Probing Quantum States Over Spacetime Through Interferometry](https://arxiv.org/abs/2507.19258)
*Seok Hyung Lie,Hyukjoon Kwon*

Main category: quant-ph

TL;DR: 本研究提出了一种能够在时空中一致地操作量子态的方法，该方法通过因果无关测量实现，并能融合多种量子态形式。研究还发现了量子混合态在时间维度上的重要性，以及一种新的时空相关性，可用于区分某些动力学。


<details>
  <summary>Details</summary>
Motivation: 为了构建相对论性量子理论，需要建立一个在空间和时间上都一致的量子态概念。

Method: 通过一种新的测量方案——因果无关测量，为时空中多方量子态赋予了操作意义，该测量方案可独立于区域间的因果关系进行一致性实现。

Result: 证明了因果无关测量可以通过干涉测量实现，并融合了多种现有量子态形式。研究还发现了量子混合态在时间维度上的重要性，以及一种新的时空相关性，可用于区分某些动力学。

Conclusion: 该框架通过干涉测量学实现了传统密度算符、量子态（QSOT）和过程矩阵形式主义的融合，并系统地研究了量子混合态在时间中的应用，这对模拟量子非马尔科夫性至关重要。此外，研究还揭示了一种源于时间对称性下同步传播的新型时空相关性，并证明了具有该相关性的量子系统可作为参考系来区分在时间对称性下不可区分的动力学。

Abstract: Establishing a notion of the quantum state that applies consistently across
space and time is a crucial step toward formulating a relativistic quantum
theory. We give an operational meaning to multipartite quantum states over
arbitrary regions in spacetime through the causally agnostic measurement, the
measurement scheme that can be consistently implemented independently of the
causal relation between the regions. We prove that such measurements can always
be implemented with interferometry, wherein the conventional density operator,
the recently developed quantum state over time (QSOT), and the process matrix
formalisms smoothly merge. This framework allows for a systematic study of
mixed states in the temporal setting, which turn out to be crucial for modeling
quantum non-Markovianity. Based on this, we demonstrate that two different
ensembles of quantum dynamics can be represented by the same QSOT, indicating
that they cannot be distinguished through interferometry. Moreover, our
formalism reveals a new type of spatiotemporal correlation between two quantum
dynamics that originates from synchronized propagation in time under
time-reversal symmetry. We show that quantum systems with such correlation can
be utilized as a reference frame to distinguish certain dynamics
indistinguishable under time-reversal symmetry.

</details>


### [264] [On the Discretization Error of the Discrete Generalized Quantum Master Equation](https://arxiv.org/abs/2507.19323)
*Ruojing Peng,Lachlan P. Lindoy,Joonho Lee*

Main category: quant-ph

TL;DR: TTM离散化方法经过分析被证明是自洽的，尽管存在其他有效的方法，但需要进一步的研究来确定其相对性能。


<details>
  <summary>Details</summary>
Motivation: 解决Makri的论文中关于TTM离散化在初始时间t=0时存在伪影的担忧，并澄清TTM离散时间核与连续时间NZ-QME核之间的关系。

Method: 通过详细分析TTM的离散化结构，明确了初始时间校正的来源，并建立了TTM离散时间核K_N与连续时间NZ-QME核K(NΔt)之间的一致关系，并通过数值模拟（以自旋-玻色子模型为例）进行了验证。

Result: TTM的离散化是自洽的，并且与NZ-QME核的关系得到了数值验证，证明了在Δt→0时，重构的核和动力学演化的准确性。

Conclusion: TTM提供了一种自洽的离散化方法，但其他方法也可能有效，需要进一步研究

Abstract: The transfer tensor method (TTM) [Cerrillo and Cao, Phys. Rev. Lett. 2014,
112, 110401] can be considered a discrete-time formulation of the
Nakajima-Zwanzig quantum master equation (NZ-QME) for modeling non-Markovian
quantum dynamics. A recent paper [Makri, J. Chem. Theory Comput. 2025, 21,
5037] raised concerns regarding the consistency of the TTM discretization,
particularly a spurious term at the initial time \( t=0 \). This Communication
presents a detailed analysis of the discretization structure of TTM, clarifying
the origin of the initial-time correction and establishing a consistent
relationship between the TTM discrete-time memory kernel \( K_N \), and the
continuous-time NZ-QME kernel \( \mathcal{K}(N\Delta t) \). This relationship
is validated numerically using the spin-boson model, demonstrating convergence
of reconstructed memory kernels and accurate dynamical evolution as \( \Delta t
\to 0 \). While TTM provides a consistent discretization, we note that
alternative schemes are also viable, such as the midpoint derivative/midpoint
integral scheme proposed in Makri's work. The relative performance of various
schemes for either computing accurate \( \mathcal{K}(N\Delta t) \) from exact
dynamics, or obtaining accurate dynamics from exact \( \mathcal{K}(N\Delta t)
\), warrants further investigation.

</details>


### [265] [Time-Dependent Hamiltonian Simulation via Time-Independent Dynamics in a Larger Space](https://arxiv.org/abs/2507.19345)
*Zecheng Li,Chunhao Wang*

Main category: quant-ph

TL;DR: 提出了一种新的量子算法，通过将时间依赖哈密顿量模拟简化为时间无关哈密顿量模拟，并在演化时间和精度方面优于先前的工作。


<details>
  <summary>Details</summary>
Motivation: 为了改进 Watkins 等人 [PRX Quantum, 2024] 的工作，在演化时间和精度方面进行改进。

Method: 通过将问题简化为在更大的空间中模拟时间无关哈密顿量来解决。利用 Duhamel 原理将时钟和系统哈密顿量分开处理，并利用高斯求积的性质来降低模拟成本。

Result: 算法的复杂度与使用其他方法的最新模拟算法相当，并且在演化时间和精度方面有所改进。

Conclusion: 该方法为模拟和仿真时间依赖系统提供了一个新的视角，证明了时间依赖哈密顿量模拟可以在一个更简单的框架中有效进行。

Abstract: In this paper, we present a proof-of-concept quantum algorithm for simulating
time-dependent Hamiltonian evolution by reducing the problem to simulating a
time-independent Hamiltonian in a larger space using a discrete clock
Hamiltonian construction. A similar construction was first explored for this
simulation problem by Watkins, Wiebe, Roggero, and Lee [PRX Quantum, 2024]. Our
algorithm improves upon their work in terms of the dependence on evolution time
and precision. In addition, the complexity matches the state-of-the-art
simulation algorithms using other approaches. To achieve this improvement, we
use Duhamel's principle to treat the clock and system Hamiltonians separately
and exploit properties of Gaussian quadrature to reduce the simulation cost.
Our approach demonstrates that time-dependent Hamiltonian simulation can be as
efficient in a simpler framework and hence provides a new angle to model and
simulate time-dependent systems.

</details>


### [266] [A Clockwork Quantum: Symmetry, Noise, and the Emergence of Quantum Order](https://arxiv.org/abs/2507.19348)
*Eric R. Bittner,Bhavay Tyagi*

Main category: quant-ph

TL;DR: 环境噪声可以通过其对称性选择性地保护量子系统的相干性，这在经典和量子领域都有应用，例如惠更斯摆钟同步和现代非厄米动力学。


<details>
  <summary>Details</summary>
Motivation: 探索开放量子系统中由噪声引起的同步和相干性保护现象，特别是与耦合自旋、振荡器和任意子相关的最新进展。

Method: 使用林德布拉德框架，并分析了对称性在噪声关联中的作用，以及其如何影响集体模式的保护。推导了相干性衰减与安德森-久保模型的关系。

Result: 揭示了局部环境中的内部关联会影响噪声结构，从而决定哪些集体模式可以免于退相干。这会导致稳态纠缠、相位锁定和李维尔谱中的厄米点，预示着模式基的崩溃和非耗散稳定动力学的出现。

Conclusion: 环境的关联噪声可以被用来保护量子系统的相干性，从而在量子传感、工程退相干和生物光合作用等领域具有潜在应用。

Abstract: We present a concise review and perspective on noise-induced synchronization
and coherence protection in open quantum systems, with emphasis on recent work
involving coupled spins, oscillators, and anyons. When local environments
exhibit internal correlations, the structure of the noise determines which
collective modes become decoherence-protected. This leads to steady-state
entanglement, phase locking, and exceptional points (EPs) in the Liouvillian
spectrum, signaling a collapse of the mode basis and the emergence of
non-dissipative stabilized dynamics. Using a Lindblad framework, we show that
symmetry in the noise correlations acts as a control parameter, protecting
symmetric or antisymmetric modes depending on the sign of the correlation. In
the pure-dephasing limit, coherence decay mirrors the Anderson-Kubo model,
where the effective fluctuation strength scales as $\sigma^2(1 \pm \xi)$, and
the dynamical regime (Gaussian vs. Lorentzian) is set by the ratio \( \sigma /
\gamma \). Thus, the environment not only drives decoherence but can also
selectively suppress it through symmetry filtering. We also revisit historical
and conceptual origins of this idea, beginning with Huygens synchronized
pendulum clocks and culminating in modern non-Hermitian dynamics. Correlated
noise-though classically stochastic-can organize quantum dynamics and protect
coherence without direct control over the system. These insights offer a
unifying view of synchronization in classical and quantum regimes, with
implications for quantum sensing, engineered decoherence, and long-lived
coherence in complex environments such as biological light-harvesting complexes
or avian magnetoreception.

</details>


### [267] [Quantum Algorithm for Protein Side-Chain Optimisation: Comparing Quantum to Classical Methods](https://arxiv.org/abs/2507.19383)
*Anastasia Agathangelou,Dilhan Manawadu,Ivano Tavernelli*

Main category: quant-ph

TL;DR: 我们提出了一种基于量子计算的方法来优化蛋白质的侧链构象，以提高药物发现的效率。


<details>
  <summary>Details</summary>
Motivation: 对蛋白质构象进行建模和预测对于推动药物发现至关重要，可用于设计治疗危及生命疾病的疗法。这个挑战的一个关键方面是旋转异构体优化——在给定固定的蛋白质骨架的情况下，确定最佳的侧链构象。

Method: 该工作提出了一种资源高效的优化算法来计算蛋白质结构的基态能量，侧重于侧链构型。研究将旋转异构体优化问题制定为二次无约束二元优化（QUBO）问题，并将其映射到易辛模型，从而实现高效的量子编码。基于此，研究提出了一种基于量子近似优化算法（QAOA）的量子算法，用于探索构象空间和识别低能量构型。

Result: 我们的量子方法展示了与经典模拟退火技术相比，计算成本有所降低，能够为量子时代的蛋白质结构优化提供一个可扩展且有前途的框架。

Conclusion: 该量子方法与经典的模拟退火技术相比，展示了计算成本的降低，为量子时代蛋白质结构优化提供了一个可扩展且有前途的框架。

Abstract: Modelling and predicting protein configurations is crucial for advancing drug
discovery, enabling the design of treatments for life-threatening diseases. A
critical aspect of this challenge is rotamer optimisation - the determination
of optimal side-chain conformations given a fixed protein backbone. This
problem, involving the internal degrees of freedom of amino acid side-chains,
significantly influences the protein's overall structure and function. In this
work, we develop a resource-efficient optimisation algorithm to compute the
ground state energy of protein structures, with a focus on side-chain
configuration. We formulate the rotamer optimisation problem as a Quadratic
Unconstrained Binary Optimisation problem and map it to an Ising model,
enabling efficient quantum encoding. Building on this formulation, we propose a
quantum algorithm based on the Quantum Approximate Optimisation Algorithm to
explore the conformational space and identify low-energy configurations. To
benchmark our approach, we conduct a classical study using custom-built
libraries tailored for structural characterisation and energy optimisation. Our
quantum method demonstrates a reduction in computational cost compared to
classical simulated annealing techniques, offering a scalable and promising
framework for protein structure optimisation in the quantum era.

</details>


### [268] [Photon catalysis for general multimode multi-photon quantum state preparation](https://arxiv.org/abs/2507.19397)
*Andrei Aralov,Émilie Gillet,Viet Nguyen,Andrea Cosentino,Mattia Walschaers,Massimo Frigerio*

Main category: quant-ph

TL;DR: 研究提出了一种使用干涉仪、探测器和光子操作生成多模多光子态的新方法，通过张量分解实现了高保真度。


<details>
  <summary>Details</summary>
Motivation: 为了在光子量子计算和量子传感等领域生成多模多光子态。

Method: 通过将光子量子态工程与对称张量分解的代数问题联系起来，利用代数几何的成果来解决该问题，并引入了可推广该方法并允许为特定类别状态构建最优电路的张量分解。

Result: 成功连接了光子量子态工程和对称张量分解的代数问题，揭示了光子催化机制，并通过数值评估与最先进结果进行比较，证实了对不同类别状态的100%保真度。

Conclusion: 该研究提出了一种利用多端口干涉仪、光子数分辨探测器、光子加法和位移操作来精确生成任意多模多光子态的方法，并实现了100%的保真度。

Abstract: Multimode multiphoton states are at the center of many photonic quantum
technologies, from photonic quantum computing to quantum sensing. In this work,
we derive a procedure to generate exactly, and with a controlled number of
steps, any such state by using only multiport interferometers, photon number
resolving detectors, photon additions, and displacements. We achieve this goal
by establishing a connection between photonic quantum state engineering and the
algebraic problem of symmetric tensor decomposition. This connection allows us
to solve the problem by using corresponding results from algebraic geometry and
unveils a mechanism of photon catalysis, where photons are injected and
subsequently retrieved in measurements, to generate entanglement that cannot be
obtained through Gaussian operations. We also introduce a tensor decomposition,
that generalizes our method and allows to construct optimal circuits for
particular classes of states. As a benchmark, we numerically evaluate our
method and compare its performance with state-of-the art results, confirming
100% fidelity on different classes of states.

</details>


### [269] [Directional Codes: a new family of quantum LDPC codes on hexagonal- and square-grid connectivity hardware](https://arxiv.org/abs/2507.19430)
*György P. Gehér,David Byfield,Archibald Ruban*

Main category: quant-ph

TL;DR: 新方向码在量子纠错性能和硬件连接性方面优于现有方案，无需复杂硬件。


<details>
  <summary>Details</summary>
Motivation: 构建一种新的量子低密度奇偶校验码（qLDPC）家族，以期在量子比特数、量子纠错性能和硬件连接性方面实现突破，并减少对复杂高连接性硬件的需求。

Method: 利用iSWAP门构建量子低密度奇偶校验码（qLDPC）的稳定器测量电路，以满足方形和六边形等常见硬件的连接性要求，且无需长程连接。

Result: 所提出的方向码在量子比特数、量子纠错性能（在物理错误率为10^-3时优于RPC）和硬件连接性（满足方形和六边形网格要求）方面均优于RPC和BB码，证明了其潜力。

Conclusion: 新的方向码（Directional Codes）在量子比特数、量子纠错性能和硬件连接性方面优于现有的量子低密度奇偶校验码（qLDPC）和双变数自行车（BB）码，表明设计复杂、高连接性的硬件并非实现低开销容错量子计算的必要条件。

Abstract: In this paper we construct a new family of quantum low-density parity-check
(qLDPC) codes, which we call ``Directional Codes'', that outperforms the
rotated planar code (RPC) while naturally meeting the connectivity requirements
of the widely adopted square-grid, and some even the sparser hexagonal-grid.
The key idea is to utilise the iSWAP gate -- a natural native gate for
superconducting qubits -- to construct circuits that measure the stabilisers of
these qLDPC codes without the need for any long-range connections or an
increased degree of connectivity. We numerically evaluate the performance of
directional codes, encoding four, six and twelve logical qubits, using a common
superconducting-inspired circuit-level Pauli noise model. We also compare them
to the RPC and to the bivariate bicycle (BB) codes, currently the two most
popular quantum LDPC code families. As a concrete example, directional codes
outperform RPC by achieving better QEC performance at physical error rate
$p=10^{-3}$ using only $25-66.67\%$ of the physical qubits at distance up to
$10$. Our discovery represents a breakthrough in QEC code design that suggests
complex long-range, high-connectivity hardware may not be necessary for
low-overhead fault-tolerant quantum computation.

</details>


### [270] [Hidden shift problem for complex functions](https://arxiv.org/abs/2507.19440)
*Serge Adonsou,Peter Bruin,Maris Ozols,Joppe Stokvis*

Main category: quant-ph

TL;DR: 量子算法在有限阿贝尔群上解决隐藏移位问题，对于쌍曲函数成功率100%，任意函数取决于其'쌍曲性'。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是研究量子算法在解决隐藏移位问题上的应用，特别是针对复标量和向量值函数在有限阿贝尔群上的情况。

Method: 研究人员提出了求解有限阿贝尔群上复标量和向量值函数的隐藏移位问题的量子算法。该算法利用了移位函数的Oracle访问以及未移位函数的傅里叶变换来寻找隐藏移位。

Result: 研究结果表明，对于쌍曲函数，所提出的量子算法能够以1的概率成功找到隐藏移位；而对于任意函数，算法的成功概率则与函数的'쌍曲性'相关。

Conclusion: 该研究提出了求解有限阿贝尔群上复标量和向量值函数的隐藏移位问题的量子算法，并分析了使用恒定查询次数的算法的成功概率。对于쌍曲函数，成功概率为1，而对于任意函数，成功概率取决于函数的'쌍曲性'。

Abstract: We study quantum algorithms for the hidden shift problem of complex scalar-
and vector-valued functions on finite abelian groups. Given oracle access to a
shifted function and the Fourier transform of the unshifted function, the goal
is to find the hidden shift. We analyze the success probability of our
algorithms when using a constant number of queries. For bent functions, they
succeed with probability 1, while for arbitrary functions the success
probability depends on the `bentness' of the function.

</details>


### [271] [Is the Full Power of Gaussian Boson Sampling Required for Simulating Vibronic Spectra Using Photonics?](https://arxiv.org/abs/2507.19442)
*Jan-Lucas Eickmann,Kai-Hong Luo,Mikhail Roiz,Jonas Lammers,Simone Atzeni,Cheeranjiv Pandey,Florian Lütkewitte,Reza G. Shirazi,Benjamin Brecht,Vladimir V. Rybkin,Michael Stefszky,Christine Silberhorn*

Main category: quant-ph

TL;DR: 模拟分子振动光谱并不总是需要高斯玻色子采样（GBS）。研究将物理化学的线性耦合近似映射到光子学，发现从多个相干态采样的方法对某些分子（如甲酸）的模拟效果更好，这表明并非所有情况都必须使用GBS。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解模拟振动光谱所需的方法，以及确定何时GBS方法是必需的，探索了理论近似与光子学方法的联系。

Method: 通过将物理化学中的理论近似（特别是线性耦合近似）映射到光子学领域，并进行实验实现，研究了GBS在模拟振动光谱中的必要性，并与从多个相干态采样的方法进行了比较。

Result: 研究发现，对于某些分子，GBS方法并非必需，线性耦合近似（在光子学中对应于从多个相干态采样）可以提供更好的模拟结果，例如在甲酸的模拟中。研究还明确了分子属性对近似有效性的影响。

Conclusion: 通过实验证明了基于高斯玻色子采样（GBS）的光子平台可以模拟分子的振动光谱，但并非所有分子模拟都需要GBS。研究揭示了物理化学中的理论近似与光子学方法的联系，指出对于某些分子，GBS并非必需。特别是线性耦合近似，在光子学中对应于从多个相干态采样，该方法在实验中得到了验证，并对甲酸的模拟结果进行了改进，明确了分子属性对近似有效性的影响，强调了连接传统方法与光子方法的重要性。

Abstract: Simulating vibronic spectra is a central task in physical chemistry, offering
insight into important properties of molecules. Recently, it has been
experimentally demonstrated that photonic platforms based on Gaussian boson
sampling (GBS) are capable of performing these simulations. However, whether an
actual GBS approach is required depends on the molecule under investigation. To
develop a better understanding on the requirements for simulating vibronic
spectra, we explore connections between theoretical approximations in physical
chemistry and their photonic counterparts. Mapping these approximations into
photonics, we show that for certain molecules the GBS approach is unnecessary.
We place special emphasis on the linear coupling approximation, which in
photonics corresponds to sampling from multiple coherent states. By
implementing this approach in experiments, we demonstrate improved similarities
over previously reported GBS results for formic acid and identify the
particular attributes that a molecule must exhibit for this, and other
approximations, to be valid. These results highlight the importance in forming
deeper connections between traditional methods and photonic approaches.

</details>


### [272] [Random approximate quantum information masking](https://arxiv.org/abs/2507.19454)
*Xiaodi Li,Xinyang Shu,Huangjun Zhu*

Main category: quant-ph

TL;DR: 本文研究了近似量子信息掩蔽（AQIM），提出用随机等距变换构建AQIM，并发现其在多方系统中效果优于二方系统，且与量子纠错有关。


<details>
  <summary>Details</summary>
Motivation: 由于近似量子信息掩蔽（AQIM）在规避量子信息掩蔽的限制方面具有潜力，但目前研究不足且构建方法具有挑战性，因此本文旨在深入研究AQIM，并提出有效的构建方法。

Method: 本文首先介绍了AQIM的不同概念及其内在联系，并引入了衡量其偏离精确QIM程度的评价指标。随后，利用随机等距变换探索了在二方和多方系统中实现AQIM的可能性，并对二方系统提出了“无随机AQIM定理”，对多方系统则证明了随机等距变换几乎总能实现AQIM。

Result: 在二方系统中，研究发现几乎所有的随机等距变换都无法实现AQIM，并提出了“无随机AQIM定理”。但在多方系统中，几乎所有的随机等距变换都能实现AQIM，且实现AQIM所需的物理量子比特数量与逻辑量子比特数量呈线性关系。此外，研究还发现AQIM可等价于近似量子纠错，并能导出具有常数码率和指数级小纠错不精确性的近似量子纠错码。

Conclusion: 本文研究了近似量子信息掩蔽（AQIM），发现其与近似量子纠错密切相关，并提出了基于随机等距变换构建AQIM的方法。研究结果表明，在多方系统中，随机等距变换几乎总能实现AQIM，且所需物理量子比特与逻辑量子比特呈线性关系。此外，AQIM可自然导出具有常数码率和指数级小纠错不精确性的近似量子纠错码。

Abstract: Masking information into quantum correlations is a cornerstone of many
quantum information applications. While there exist the no-hiding and
no-masking theorems, approximate quantum information masking (AQIM) offers a
promising means of circumventing the constraints. Despite its potential, AQIM
still remains underexplored, and constructing explicit approximate maskers
remains a challenge. In this work, we investigate AQIM from multiple
perspectives and propose using random isometries to construct approximate
maskers. First, different notions of AQIM are introduced and we find there are
profound intrinsic connections among them. These relationships are
characterized by a set of figures of merit, which are introduced to quantify
the deviation of AQIM from exact QIM. We then explore the possibility of
realizing AQIM via random isometries in bipartite and multipartite systems. In
bipartite systems, we identify a fundamental lower bound for a key figure of
merit, implying that almost all random isometries fail to realize AQIM. This
surprising result generalizes the original no-masking theorem to the
no-random-AQIM theorem for bipartite systems. In contrast, in multipartite
systems, we show almost all random isometries can realize AQIM. Remarkably, the
number of physical qubits required to randomly mask a single logical qubit
scales only linearly. We further explore the implications of these findings. In
particular, we show that, under certain conditions, approximate quantum error
correction is equivalent to AQIM. Consequently, AQIM naturally gives rise to
approximate quantum error correction codes with constant code rates and
exponentially small correction inaccuracies. Overall, our results establish
quantum information masking as a central concept in quantum information theory,
bridging diverse notions across multiple domains.

</details>


### [273] [Persistent subradiant correlations in a random driven Dicke model](https://arxiv.org/abs/2507.19467)
*Nikita Leppenen,Alexander N. Poddubny*

Main category: quant-ph

TL;DR: 在存在频率无序的情况下，该研究提出了具有更长寿命的亚辐射相关性，这些相关性对无序具有免疫力。


<details>
  <summary>Details</summary>
Motivation: 为了在存在发射器共振频率的无序情况下，找到能够存活下来的亚辐射集体态。

Method: 研究了由单光子模式耦合的二维发射器阵列在共振频率无序存在下的驱动耗散动力学。

Result: 发现了亚辐射相关性，其寿命比迪克时间晶体相更长，并且对发射器共振频率的无序具有免疫力。

Conclusion: 该研究提出了亚辐射相关性的概念，即使在存在发射器共振频率的无序情况下，这些相关性也能在有限尺寸系统中存在，并且其寿命可以比著名的迪克时间晶体相更长。

Abstract: We study theoretically the driven-dissipative dynamics of an array of
two-level emitters, coupled to a single photonic mode, in the presence of
disorder in the resonant frequencies. We introduce the notion of subradiant
correlations in the dynamics, corresponding to the eigenstates of the
Liouvillian with a low decay rate, that can also oscillate in time. While the
usual collective subradiant states do not survive the emitter resonant
frequency fluctuations, these subradiant correlations are immune to such a type
of disorder. These long-living correlations exist in finite-size systems, when
their lifetime is parametrically longer than in the so-called Dicke time
crystal phase.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [274] [Human-AI Synergy in Adaptive Active Learning for Continuous Lithium Carbonate Crystallization Optimization](https://arxiv.org/abs/2507.19316)
*Shayan S. Mousavi Masouleh,Corey A. Sanz,Ryan P. Jansonius,Cara Cronin,Jason E. Hein,Jason Hattrick-Simpers*

Main category: cs.CE

TL;DR: 通过集成人类专业知识和人工智能，本研究开发了一种主动学习框架，以优化低品位锂资源的连续结晶过程，显著提高了对杂质的耐受性，并为经济地利用北美锂资源铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 随着电动汽车行业的增长，对高纯度锂的需求激增，但北美低品位锂资源（如斯 পর্যালোচনা克弗地层）的经济有效提取面临挑战，需要创新的纯化技术来应对其与南美高纯度盐水不同的特性，并克服连续结晶优化过程中复杂的参数空间和有限数据的问题。

Method: 本研究引入了一种“人在回路中”（HITL）辅助的主动学习框架，通过集成人类专业知识和数据驱动的见解，来优化碳酸锂的连续结晶过程。

Result: 该框架能够快速适应新数据，将碳酸锂生产过程中对镁等关键杂质的耐受性从标准的几百 ppm 提高到 6000 ppm，使得利用低品位、富含杂质的锂资源成为可能，并可能减少预精炼过程的需求，最终目标是经济地利用北美的锂储量并提高全球锂供应链的可持续性。

Conclusion: 该研究提出的“人在回路中”（HITL）辅助的主动学习框架能够显著提高从富含杂质的低品位锂资源中提取碳酸锂的效率和纯度，通过集成人类专业知识和数据驱动的见解，该框架能够快速适应新数据，优化连续结晶过程，并有效应对镁等关键杂质的干扰，从而为利用北美，如斯 পর্যালোচনা克弗地层，的锂矿藏提供了经济可行的途径，并有助于提升全球锂供应链的可持续性。

Abstract: As demand for high-purity lithium surges with the growth of the electric
vehicle (EV) industry, cost-effective extraction from lower-grade North
American sources like the Smackover Formation is critical. These resources,
unlike high-purity South American brines, require innovative purification
techniques to be economically viable. Continuous crystallization is a promising
method for producing battery-grade lithium carbonate, but its optimization is
challenged by a complex parameter space and limited data. This study introduces
a Human-in-the-Loop (HITL) assisted active learning framework to optimize the
continuous crystallization of lithium carbonate. By integrating human expertise
with data-driven insights, our approach accelerates the optimization of lithium
extraction from challenging sources. Our results demonstrate the framework's
ability to rapidly adapt to new data, significantly improving the process's
tolerance to critical impurities like magnesium from the industry standard of a
few hundred ppm to as high as 6000 ppm. This breakthrough makes the
exploitation of low-grade, impurity-rich lithium resources feasible,
potentially reducing the need for extensive pre-refinement processes. By
leveraging artificial intelligence, we have refined operational parameters and
demonstrated that lower-grade materials can be used without sacrificing product
quality. This advancement is a significant step towards economically harnessing
North America's vast lithium reserves, such as those in the Smackover
Formation, and enhancing the sustainability of the global lithium supply chain.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [275] [Who Wins the Multi-Structural Game?](https://arxiv.org/abs/2507.18718)
*Ronald Fagin,Neil Immerman,Phokion Kolaitis,Jonathan Lenchner,Rik Sengupta*

Main category: cs.LO

TL;DR: 该论文研究了组合博弈（特别是干扰者-复制者博弈）的判定问题，这些博弈通常用于捕捉形式逻辑语言的句法性质。它表明，对于最近引起关注的多结构（MS）游戏，此问题是 PSPACE-hard 的，但包含在 NEXPTIME 中。此外，它还解决了 Pezzoli 关于 EF 游戏硬度结果对模式元数的依赖性的一个悬而未决的问题。该研究采用了 Pezzoli 的构造、可优化性问题的近似难度理论以及 MS 游戏的并行博弈技术。


<details>
  <summary>Details</summary>
Motivation: 组合博弈，特别是干扰者-复制者博弈，已被用于捕捉形式逻辑语言的句法性质。例如，Ehrenfeucht-Fraïssé (EF) 博弈捕捉了一阶公式的量词秩的句法度量。

Method: 该论文结合了 Pezzoli 构造的改编、可优化性问题的近似难度的理论见解以及 MS 游戏并行博弈的最新技术。

Result: 该论文证明，多结构（MS）游戏的判定问题是 PSPACE-hard 的，但包含在 NEXPTIME 中。

Conclusion: 该论文表明，多结构（MS）游戏的判定问题是 PSPACE-hard 的，但包含在 NEXPTIME 中。此外，还解决了 Pezzoli 关于 NExptime 游戏的硬度结果对模式的元数的依赖性的开放性问题。

Abstract: Combinatorial games played between two players, called Spoiler and
Duplicator, have often been used to capture syntactic properties of formal
logical languages. For instance, the widely used Ehrenfeucht-Fra\"iss\'e (EF)
game captures the syntactic measure of quantifier rank of first-order formulas.
For every such game, there is an associated natural decision problem: "given an
instance of the game, does Spoiler win the game on that instance?" For EF
games, this problem was shown to be PSPACE-complete by Pezzoli in 1998. In this
present paper, we show that the same problem for the *multi-structural* (MS)
games of recent interest is PSPACE-hard, but contained in NEXPTIME. In the
process, we also resolve an open problem posed by Pezzoli about the dependence
of the hardness results for EF games on the arity of the schema under
consideration. Our techniques combine adaptations of Pezzoli's constructions
together with insights from the theory of inapproximability of optimization
problems, as well as the recently developed technique of parallel play for MS
games.

</details>


### [276] [Higher-order Kripke models for intuitionistic and non-classical modal logics](https://arxiv.org/abs/2507.18798)
*Victor Barroso-Nascimento*

Main category: cs.LO

TL;DR: This paper introduces higher-order Kripke models, a generalization of standard Kripke models, by constructing n-ary models from (n-1)-ary models. This framework provides a new semantic approach for non-classical logics, offering intuitive interpretations like "alternative timelines," as demonstrated with intuitionistic modal logic.


<details>
  <summary>Details</summary>
Motivation: The motivation is to generalize Kripke models in a way that closely aligns with Kripke's original idea, both mathematically and conceptually. This generalization aims to provide a more flexible and intuitive semantic framework for defining modal semantics for various non-classical logics, moving beyond the limitations of standard Kripke models.

Method: The paper defines higher-order Kripke models by generalizing standard Kripke models. n-ary models are constructed using (n-1)-ary Kripke models as their components. The framework is developed by defining accessibility relations between non-classical propositional models, even when they are Kripke models. The paper specifically addresses intuitionistic modal logic to demonstrate the concept, showing how 1-ary models can represent logics like IK or a new logic MK, incorporating the idea of "alternative timelines".

Result: The paper introduces higher-order Kripke models, defining n-ary models based on (n-1)-ary models. It demonstrates their application to intuitionistic modal logic, yielding 1-ary models equivalent to birelational models for IK or a new logic MK. These models offer an intuitive interpretation involving "alternative timelines" or "alternative" possibilities. The paper also outlines the general structure of these models, proposes variants, and states conjectures.

Conclusion: The paper generalizes Kripke models to higher-order Kripke models, where n-ary models consist of (n-1)-ary Kripke models. This new framework allows for intuitive interpretations of non-classical logics, such as intuitionistic modal logic, by introducing the concept of "alternative timelines" or "alternative" possibilities. The paper defines the models, explores variants, and states conjectures about their properties.

Abstract: This paper introduces higher-order Kripke models, a generalization of
standard Kripke models that is remarkably close to Kripke's original idea -
both mathematically and conceptually. Standard Kripke models are now considered
$0$-ary models, whereas an $n$-ary model for $n > 0$ is a model whose set of
objects (''possible worlds'') contains only $(n-1)$-ary Kripke models. Models
with infinitely many layers are also considered. This framework is obtained by
promoting a radical change of perspective in how modal semantics for
non-classical logics are defined: just like classical modalities are obtained
through use of an accessibility relation between classical propositional
models, non-classical modalities are now obtained through use of an
accessibility relation between non-classical propositional models (even when
they are Kripke models already). The paper introduces the new models after
dealing specifically with the case of intuitionistic modal logic. It is shown
that, depending on which intuitionistic $0$-ary propositional models are
allowed, we may obtain $1$-ary models equivalent to either birelational models
for $IK$ or for a new logic called $MK$. Those $1$-ary models have an intuitive
reading that adds to the interpretation of intuitionistic models in terms of
''timelines'' the concept of ''alternative timelines''. More generally, the
$1$-ary models can be read as defining a concept of ''alternative'' for any
substantive interpretation of the $0$-ary models. The semantic clauses for
necessity and possibility of $MK$ are also modular and can be used to obtain
similar modal semantics for every non-classical logic, each of which can be
provided with a similar intuitive reading. After intuitionistic modal logic is
dealt with, the general structure of High-order Kripke Models and some of its
variants are defined, and a series of conjectures about their properties are
stated.

</details>


### [277] [A Proof of the Schröder-Bernstein Theorem in ACL2](https://arxiv.org/abs/2507.19008)
*Grant Jurgensen*

Main category: cs.LO

TL;DR: The Schr"oder-Bernstein theorem, proving a bijection exists between sets with injections in both directions, has been formally verified in ACL2 using a novel theory of chains.


<details>
  <summary>Details</summary>
Motivation: To formally verify the Schr"oder-Bernstein theorem and its implication on the antisymmetry of cardinal numbers within the ACL2 framework.

Method: A formulation and verification of the Schr"oder-Bernstein theorem in ACL2 using a theory of chains to define a non-computable witness.

Result: A formalization and verification of the Schr"oder-Bernstein theorem in ACL2.

Conclusion: The Schr"oder-Bernstein theorem has been formulated and verified in ACL2, demonstrating the antisymmetry of cardinal number ordering.

Abstract: The Schr\"oder-Bernstein theorem states that, for any two sets P and Q, if
there exists an injection from P to Q and an injection from Q to P, then there
must exist a bijection between the two sets. Classically, it follows that the
ordering of the cardinal numbers is antisymmetric. We describe a formulation
and verification of the Schr\"oder-Bernstein theorem in ACL2 following a
well-known proof, introducing a theory of chains to define a non-computable
witness.

</details>


### [278] [RV32I in ACL2](https://arxiv.org/abs/2507.19009)
*Carl Kwan*

Main category: cs.LO

TL;DR: This paper introduces a verified ACL2 simulator for the RISC-V 32-bit ISA, using operational semantics and separating instruction decoding for automatic proofs.


<details>
  <summary>Details</summary>
Motivation: The motivation was to create a formal model of the RISC-V 32-bit base ISA using ACL2. This model aims to aid in the verification of RISC-V based systems by providing a rigorously defined and provably correct operational semantics.

Method: The paper utilized the operational semantics style to create a single-threaded ACL2 simulator for the RISC-V 32-bit base ISA. It involved proving theorems for read-over-write, write-over-write, writing-the-read, and state well-formedness. A key aspect of the method was separating instruction decoding functions from their semantic counterparts, leading to individually verified encoding/decoding functions for each RV32I instruction with automatic proofs.

Result: The paper presents a verified ACL2 simulator for RV32I. It includes proofs for key state transition properties and fully automatic proofs for the encoding/decoding functions of all RV32I instructions. The separation of decoding and semantics is a notable outcome.

Conclusion: The paper successfully developed and verified an ACL2 simulator for the RISC-V 32-bit base ISA, separating instruction decoding from semantic functions and achieving automatic proofs for encoding/decoding.

Abstract: We present a simple ACL2 simulator for the RISC-V 32-bit base instruction set
architecture, written in the operational semantics style. Like many other ISA
models, our RISC-V state object is a single-threaded object and we prove
read-over-write, write-over-write, writing-the-read, and state well-formedness
theorems. Unlike some other models, we separate the instruction decoding
functions from their semantic counterparts. Accordingly, we verify encoding /
decoding functions for each RV32I instruction, the proofs for which are
entirely automatic.

</details>


### [279] [On Automating Proofs of Multiplier Adder Trees using the RTL Books](https://arxiv.org/abs/2507.19010)
*Mayank Manjrekar*

Main category: cs.LO

TL;DR: Arm introduces ctv-cp for automated formal verification of integer multipliers in hardware designs.


<details>
  <summary>Details</summary>
Motivation: To fit into Arm's formal verification framework for arithmetic hardware designs and automate proof development.

Method: Presents ctv-cp, an experimental, verified clause processor.

Result: Enables automation of ACL2 proof development for a range of integer multiplier modules, from floating-point division to matrix multiplication.

Conclusion: ctv-cp largely automates ACL2 proof development for integer multiplier modules in Arm's formal verification framework.

Abstract: We present an experimental, verified clause processor ctv-cp that fits into
the framework used at Arm for formal verification of arithmetic hardware
designs. This largely automates the ACL2 proof development effort for integer
multiplier modules that exist in designs ranging from floating-point division
to matrix multiplication.

</details>


### [280] [A Formalization of the Yul Language and Some Verified Yul Code Transformations](https://arxiv.org/abs/2507.19012)
*Alessandro Coglio,Eric McCarthy*

Main category: cs.LO

TL;DR: Yul代码转换的正确性已通过ACL2定理证明器进行形式化验证。


<details>
  <summary>Details</summary>
Motivation: 为了确保Yul代码转换的正确性及其顺序的正确性，我们需要一个形式化的验证方法。

Method: 使用ACL2定理证明器对Yul的语法和语义进行了形式化，并对一些Yul代码转换及其正确性进行了证明。

Result: 形式化了Yul的语法和语义，证明了静态和动态语义之间的关系，形式化了部分Yul代码转换，并对其进行了正确性证明。

Conclusion: Yul代码转换的正确性得到了ACL2定理证明器的形式化验证。

Abstract: Yul is an intermediate language used in the compilation of the Solidity
programming language for Ethereum smart contracts. The compiler applies
customizable sequences of transformations to Yul code. To help ensure the
correctness of these transformations and their sequencing, we used the ACL2
theorem prover to develop a formalization of the syntax and semantics of Yul,
proofs relating static and dynamic semantics, a formalization of some Yul code
transformations, and correctness proofs for these transformations.

</details>


### [281] [A Formalization of the Correctness of the Floodsub Protocol](https://arxiv.org/abs/2507.19013)
*Ankit Kumar,Panagiotis Manolios*

Main category: cs.LO

TL;DR: 本文利用良基模拟（WFS）方法，机械化地验证了流行的P2P发布/订阅协议Floodsub，证明了它是Broadcastsub协议的仿射细化，是首个对真实发布/订阅协议进行此类验证的工作。


<details>
  <summary>Details</summary>
Motivation: 为了证明Floodsub协议的正确性，需要证明它实现了Broadcastsub。本文的目的是机械化地进行这一证明，即证明Floodsub是Broadcastsub的仿射细化。

Method: 本文利用了良基模拟（Well-Founded Simulation, WFS）的方法，通过局部地考虑状态及其后继者来证明 Floodsub 实现 Broadcastsub。

Result: 通过使用WFS，本文成功地证明了Floodsub是Broadcastsub的仿射细化，实现了对Floodsub协议的验证。

Conclusion: 本文的工作首次实现了对真实世界中的发布/订阅协议Floodsub的基于仿射细化（refinement）的验证，并证明了Floodsub是Broadcastsub的仿射细化。

Abstract: Floodsub is a simple, robust and popular peer-to-peer publish/subscribe
(pubsub) protocol, where nodes can arbitrarily leave or join the network,
subscribe to or unsubscribe from topics and forward newly received messages to
all of their neighbors, except the sender or the originating peer. To show the
correctness of Floodsub, we propose its specification: Broadcastsub, in which
implementation details like network connections and neighbor subscriptions are
elided. To show that Floodsub does really implement Broadcastsub, one would
have to show that the two systems have related infinite computations. We prove
this by reasoning locally about states and their successors using Well-Founded
Simulation (WFS). In this paper, we focus on the mechanization of a proof which
shows that Floodsub is a simulation refinement of Broadcastsub using WFS. To
the best of our knowledge, ours is the first mechanized refinement-based
verification of a real world pubsub protocol.

</details>


### [282] [An ACL2s Interface to Z3](https://arxiv.org/abs/2507.19014)
*Andrew T. Walter,Panagiotis Manolios*

Main category: cs.LO

TL;DR: Lisp-Z3 是一个 Common Lisp 库，用于集成 Z3 SMT 求解器和 ACL2s 定理证明器，已成功应用于 Sudoku、字符串求解和硬件测试，并计划用于改进依赖类型支持。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在扩展 ACL2s 系统编程框架，支持 Z3 求解器，以结合 SMT 和交互式定理证明的能力，并探索其在各种应用中的潜力，包括增强对依赖类型的支持。

Method: Lisp-Z3 是一个 ACL2s 系统编程框架的扩展，支持 Z3 SMT 求解器，允许开发者使用 Common Lisp 结合 ACL2/s 和 Z3 的能力。本论文描述了 Lisp-Z3 的使用、实现以及在三个应用（Sudoku 求解器、SeqSolve 字符串求解器、无线路由器硬件在环模糊测试）中的评估。

Result: Lisp-Z3 在 Sudoku 求解、SeqSolve 字符串求解和硬件在环模糊测试等应用中表现良好，尤其在 SeqSolve 和硬件在环模糊测试中，它通过集成 Z3 和 ACL2s 展现了其优势。

Conclusion: Lisp-Z3 是一个支持 Z3 SMT 求解器的 ACL2s 系统编程框架扩展，允许开发者使用 Common Lisp 结合 ACL2/s 和 Z3 的能力。它不依赖于 ACL2/s，可供任何想从 Common Lisp 交互 Z3 的用户使用。Lisp-Z3 已成功应用于 Sudoku 求解器、SeqSolve 字符串求解器以及无线路由器硬件在环模糊测试等领域，并计划用于增强 ACL2s 对依赖类型的支持和反例生成。

Abstract: We present Lisp-Z3, an extension to the ACL2s systems programming framework
(ASPF) that supports the use of the Z3 satisfiability modulo theories (SMT)
solver. Lisp-Z3 allows one to develop tools written using the full feature set
of Common Lisp that can use both ACL2/s (either ACL2 or ACL2s) and Z3 as
services, combining the power of SMT and interactive theorem proving. Lisp-Z3
is usable by anyone who would like to interact with Z3 from Common Lisp, as it
does not depend on the availability of ACL2/s. We discuss the use of Lisp-Z3 in
three applications. The first is a Sudoku solver. The second is SeqSolve, a
string solver which solved a larger number of benchmark problems more quickly
than any other existing solver at the time of its publishing. Finally, Lisp-Z3
was also used in the context of hardware-in-the-loop fuzzing of wireless
routers, where low latency was an important goal. The latter two applications
leveraged the ability of Lisp-Z3 to integrate Z3 with ACL2s code. We have
further plans to use Lisp-Z3 inside of ACL2s to provide more powerful automated
support for dependent types, and in particular more efficient generation of
counterexamples to properties involving dependent types. This paper describes
the usage and implementation of Lisp-Z3, as well as an evaluation of its use in
the aforementioned applications.

</details>


### [283] [A CASP-based Solution for Traffic Signal Optimisation](https://arxiv.org/abs/2507.19061)
*Alice Tarzariol,Marco Maratea,Mauro Vallati*

Main category: cs.LO

TL;DR: CASP 是交通信号优化的更好选择。


<details>
  <summary>Details</summary>
Motivation: 针对 PDDL+ 语言在交通信号优化问题中指定优化语句和计算优化计划的局限性，提供一种替代方法。

Method: 提出了一种基于约束 Answer Set Programming (CASP) 的解决方案，并使用 clingcon 3（clingo 的扩展）进行求解。

Result: 在英国哈德斯菲尔德的真实历史数据上进行了实验，并将 CASP 方法与 PDDL+ 模型进行了比较，结果显示 CASP 方法具有更高的解决方案质量。

Conclusion: CASP 方法在解决城市交通信号优化问题上展现出巨大潜力，并且能够改进 PDDL+ 计划的解决方案质量。

Abstract: In the context of urban traffic control, traffic signal optimisation is the
problem of determining the optimal green length for each signal in a set of
traffic signals. The literature has effectively tackled such a problem, mostly
with automated planning techniques leveraging the PDDL+ language and solvers.
However, such language has limitations when it comes to specifying optimisation
statements and computing optimal plans. In this paper, we provide an
alternative solution to the traffic signal optimisation problem based on
Constraint Answer Set Programming (CASP). We devise an encoding in a CASP
language, which is then solved by means of clingcon 3, a system extending the
well-known ASP solver clingo. We performed experiments on real historical data
from the town of Huddersfield in the UK, comparing our approach to the PDDL+
model that obtained the best results for the considered benchmark. The results
showed the potential of our approach for tackling the traffic signal
optimisation problem and improving the solution quality of the PDDL+ plans.

</details>


### [284] [Transfinite Fixed Points in Alpay Algebra as Ordinal Game Equilibria in Dependent Type Theory](https://arxiv.org/abs/2507.19245)
*Faruk Alpay,Bugra Kilictas,Taylan Alpay*

Main category: cs.LO

TL;DR: 本研究将不动点理论、对策语义学、序数分析和类型理论相结合，证明了自指过程的稳定性，并提供了计算验证方法。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索自指过程的稳定性以及它与无限修订对话的均衡状态之间的联系，并为Alpay的语义收敛的哲学主张提供一个坚实的逻辑基础。

Method: 通过不动点理论、对策语义学、序数分析和类型理论，研究人员将不动点算子嵌入到依赖类型理论中，为有限和无限情况下的收敛性提供了机器检查的证明。

Result: 本研究证明了自指过程的稳定结果等同于无限修订对话的唯一均衡，并且通过依赖类型理论对其进行了机器验证。

Conclusion: 该研究为Alpay的语义收敛的哲学主张在建设性逻辑的框架内提供了基础，它统一了不动点理论、对策语义学、序数分析和类型理论的概念，为推理无限的自指系统建立了广泛可及但形式上严谨的基础，并为在计算环境中认证其收敛性提供了实用的工具。

Abstract: This paper contributes to the Alpay Algebra by demonstrating that the stable
outcome of a self referential process, obtained by iterating a transformation
through all ordinal stages, is identical to the unique equilibrium of an
unbounded revision dialogue between a system and its environment. The analysis
initially elucidates how classical fixed point theorems guarantee such
convergence in finite settings and subsequently extends the argument to the
transfinite domain, relying upon well founded induction and principles of order
theoretic continuity.
  Furthermore, the resulting transordinal fixed point operator is embedded into
dependent type theory, a formalization which permits every step of the
transfinite iteration and its limit to be verified within a modern proof
assistant. This procedure yields a machine checked proof that the iterative
dialogue necessarily stabilizes and that its limit is unique. The result
provides a foundation for Alpay's philosophical claim of semantic convergence
within the framework of constructive logic. By unifying concepts from fixed
point theory, game semantics, ordinal analysis, and type theory, this research
establishes a broadly accessible yet formally rigorous foundation for reasoning
about infinite self referential systems and offers practical tools for
certifying their convergence within computational environments.

</details>


### [285] [Order in Partial Markov Categories](https://arxiv.org/abs/2507.19424)
*Elena Di Lavore,Mario Román,Paweł Sobociński,Márk Széles*

Main category: cs.LO

TL;DR: 部分马尔可夫范畴可以通过预序集和单调映射进行丰富，并且柯西-施瓦茨不等式的一种新形式可以用于概率推理。


<details>
  <summary>Details</summary>
Motivation: 旨在为部分概率论提供一个抽象的框架，并探讨部分马尔可夫范畴中的序关系及其在概率推理中的应用。

Method: 本文讨论了部分马尔可夫范畴的态射上的两种序关系，并证明了它们可以被预序集和单调映射的范畴所丰富。此外，还提出了一种新的综合形式的柯西-施瓦茨不等式，并将其应用于证明关于先验分布更新的似然性。

Result: 证明了部分马尔可夫范畴可以被预序集和单调映射的范畴丰富，恢复了已知的序富集，并揭示了余对角映射与序性质的关系。提出并应用了柯西-施瓦茨不等式的综合形式，证明了先验分布更新的似然性增加。

Conclusion: 本文证明了每个部分马尔可夫范畴都可以被预序集和单调映射的范畴进行规范地丰富，并展示了该构造如何恢复几个著名的序富集。此外，还揭示了余对角映射（比较器）的存在性与部分马尔可夫范畴的序性质密切相关。最后，提出了柯西-施瓦茨不等式的一种综合形式，用于部分马尔可夫范畴中的不等式推理，并应用该公理证明了用证据谓词更新先验分布会增加证据在后验中的似然性。

Abstract: Partial Markov categories are a recent framework for categorical probability
theory, providing an abstract account of partial probabilistic computation. In
this article, we discuss two order relations on the morphisms of a partial
Markov category. In particular, we prove that every partial Markov category is
canonically enriched over the category of preordered sets and monotone maps. We
show that our construction recovers several well-known order enrichments. We
also demonstrate that the existence of codiagonal maps (comparators) is closely
related to order properties of partial Markov categories. We propose a
synthetic version of the Cauchy-Schwarz inequality to facilitate inequational
reasoning in partial Markov categories. We apply this new axiom to prove that
updating a prior distribution with an evidence predicate increases the
likelihood of the evidence in the posterior.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [286] [A Truly Subcubic Combinatorial Algorithm for Induced 4-Cycle Detection](https://arxiv.org/abs/2507.18845)
*Amir Abboud,Shyan Akmal,Nick Fischer*

Main category: cs.DS

TL;DR: 提出了一种新的O(n^2.84)组合算法，用于检测图中的诱导4-环，将此问题与三角形检测分离开来。


<details>
  <summary>Details</summary>
Motivation: 旨在解决图中诱导4-环检测的精确时间复杂度问题，并探究其与检测三角形（3-环）的复杂性关系，以及是否属于NP难问题。

Method: 提出了一种新的组合算法，该算法利用了图分解技术，这与之前主要依赖于矩阵乘法或代数技术的方法不同。

Result: 提出了一种能在O(n^2.84)时间内检测诱导4-环的组合算法，这是目前已知的最快的组合算法。此外，该算法也是第一个非平凡确定性算法。

Conclusion: 该算法在理论上将检测诱导4-环的组合时间复杂度从O(n^3)降低到O(n^2.84)，并将此问题与检测三角形的复杂度分离开来，解决了之前遗留的“好奇”问题。

Abstract: We present the first truly subcubic, combinatorial algorithm for detecting an
induced $4$-cycle in a graph. The running time is $O(n^{2.84})$ on $n$-node
graphs, thus separating the task of detecting induced $4$-cycles from detecting
triangles, which requires $n^{3-o(1)}$ time combinatorially under the popular
BMM hypothesis.
  Significant work has gone into characterizing the exact time complexity of
induced $H$-detection, relative to the complexity of detecting cliques of
various sizes. Prior work identified the question of whether induced $4$-cycle
detection is triangle-hard as the only remaining case towards completing the
lowest level of the classification, dubbing it a "curious" case [Dalirrooyfard,
Vassilevska W., FOCS 2022]. Our result can be seen as a negative resolution of
this question.
  Our algorithm deviates from previous techniques in the large body of subgraph
detection algorithms and employs the trendy topic of graph decomposition that
has hitherto been restricted to more global problems (as in the use of expander
decompositions for flow problems) or to shaving subpolynomial factors (as in
the application of graph regularity lemmas). While our algorithm is slower than
the (non-combinatorial) state-of-the-art $\tilde{O}(n^{\omega})$-time algorithm
based on polynomial identity testing [Vassilevska W., Wang, Williams, Yu, SODA
2014], combinatorial advancements often come with other benefits. In
particular, we give the first nontrivial deterministic algorithm for detecting
induced $4$-cycles.

</details>


### [287] [String Consensus Problems with Swaps and Substitutions](https://arxiv.org/abs/2507.19139)
*Estéban Gabory,Laurent Bulteau,Gabriele Fici,Hilde Verbeek*

Main category: cs.DS

TL;DR: 该研究解决了字符串一致性问题，特别是最近字符串问题及其允许交换的变体。证明了允许交换和最多d次替换的广义问题是参数化的可处理的，并为最小化距离之和的变体开发了一种多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 字符串一致性问题旨在找到一个字符串，使其与给定字符串集合的距离最小化。特别是，最近字符串问题要求找到一个字符串，该字符串与每个输入字符串在最多d次替换的情况下有所不同。

Method: 研究了允许替换和相邻字符交换的广义字符串一致性问题，并提出了一个针对最小化输出字符串与所有输入字符串距离之和的变体的多项式时间算法。

Result: 证明了该广义问题是关于参数d的FPT，并为最小化距离之和的变体提供了一个多项式时间算法。

Conclusion: 该广义问题是关于参数d的FPT，并且对于一个变体存在一个多项式时间算法。

Abstract: String consensus problems aim at finding a string that minimizes some given
distance with respect to an input set of strings. In particular, in the
\textsc{Closest String} problem, we are given a set of strings of equal length
and a radius $d$. The objective is to find a new string that differs from each
input string by at most $d$ substitutions. We study a generalization of this
problem where, in addition to substitutions, swaps of adjacent characters are
also permitted, each operation incurring a unit cost. Amir et al. showed that
this generalized problem is NP-hard, even when only swaps are allowed. In this
paper, we show that it is FPT with respect to the parameter $d$. Moreover, we
investigate a variant in which the goal is to minimize the sum of distances
from the output string to all input strings. For this version, we present a
polynomial-time algorithm.

</details>


### [288] [Budget and Profit Approximations for Spanning Tree Interdiction](https://arxiv.org/abs/2507.19178)
*Rafail Ostrovsky,Yuval Rabani,Yoav Siman Tov*

Main category: cs.DS

TL;DR: 该研究通过图论放松和批量贪心算法，为最小生成树（MST）干预问题的预算最小化和利润最大化提供了多项式时间对数近似保证，并为增加MST重量的成本最小化问题开发了精确算法。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决最小生成树（MST）干预问题，该问题旨在通过移除图中的边来增加MST的权重。具体来说，研究人员试图解决预算最小化（在给定预算内最大化MST权重增加）和利润最大化（最小化成本以实现特定MST权重增加）两个版本。之前的研究在某些相关问题上取得了近似保证，但似乎不适用于增加MST权重或预算约束的版本。

Method: 该研究引入了两种近似算法：一种用于预算最小化，另一种用于利润最大化。研究还提出了一种针对增加MST重量问题的精确算法。该研究利用了干预问题中最小生成树重量增量的超模特性。

Result: 该研究为最小生成树（MST）的干预问题提供了多项式时间对数近似保证。研究人员还开发了一种有效的算法来解决增加MST重量的成本最小化问题，并利用图论放松和批量贪心算法来设计和分析近似算法。

Conclusion: 该研究为最小生成树（MST）的干预问题提供了多项式时间对数近似保证，包括预算最小化和利润最大化版本。研究表明，尽管预算和利润问题是NP难的，但增加任何数量的MST重量的问题是可以在多项式时间内解决的。作者通过图论放松和批量贪心算法解决了这些问题。

Abstract: We give polynomial time logarithmic approximation guarantees for the budget
minimization, as well as for the profit maximization versions of minimum
spanning tree interdiction. In this problem, the goal is to remove some edges
of an undirected graph with edge weights and edge costs, so as to increase the
weight of a minimum spanning tree. In the budget minimization version, the goal
is to minimize the total cost of the removed edges, while achieving a desired
increase $\Delta$ in the weight of the minimum spanning tree. An alternative
objective within the same framework is to maximize the profit of interdiction,
namely the increase in the weight of the minimum spanning tree, subject to a
budget constraint. There are known polynomial time $O(1)$ approximation
guarantees for a similar objective (maximizing the total cost of the tree,
rather than the increase). However, the guarantee does not seem to apply to the
increase in cost. Moreover, the same techniques do not seem to apply to the
budget version.
  Our approximation guarantees are motivated by studying the question of
minimizing the cost of increasing the minimum spanning tree by any amount. We
show that in contrast to the budget and profit problems, this version of
interdiction is polynomial time-solvable, and we give an efficient algorithm
for solving it. The solution motivates a graph-theoretic relaxation of the
NP-hard interdiction problem. The gain in minimum spanning tree weight, as a
function of the set of removed edges, is super-modular. Thus, the budget
problem is an instance of minimizing a linear function subject to a
super-modular covering constraint. We use the graph-theoretic relaxation to
design and analyze a batch greedy-based algorithm.

</details>


### [289] [Query Efficient Structured Matrix Learning](https://arxiv.org/abs/2507.19290)
*Noah Amsel,Pratyush Avi,Tyler Chen,Feyza Duman Keles,Chinmay Hegde,Cameron Musco,Christopher Musco,David Persson*

Main category: cs.DS

TL;DR: 研究发现，通过矩阵向量积查询来学习矩阵结构（如低秩、稀疏等）近似值，其效率远超现有方法，尤其是在处理大型矩阵族时，查询复杂度可从对数级别降低到平方根对数级别。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在更广泛地研究学习结构化矩阵近似值的问题，特别是关注矩阵向量积查询模型中的查询复杂性，以期在科学计算和机器学习领域找到更有效的算法。

Method: 该研究利用覆盖数论证来分析学习矩阵族近似值的查询复杂性，并重点关注如何在矩阵向量积模型中实现比标准方法（如矩阵草图）更优的复杂度。

Result: 研究表明，在矩阵向量积模型中，学习任何有限大小的矩阵族 $\mathcal{F}$ 的近似值，其查询复杂性可以达到 $\tilde{O}(\sqrt{\log|\mathcal{F}|})$，这比仅需 $\tilde{O}(\log|\mathcal{F}|)$ 的标准结果有显著改进，并且该界限接近最优。此外，该研究还将此结果推广到线性矩阵族等无限情况，例如将维度为 $q$ 的线性矩阵族的学习复杂度从 $O(q)$ 降低到 $\tilde{O}(\sqrt{q})$。

Conclusion: 该研究为从矩阵向量积查询中学习一般矩阵族（包括有限和无限情况）的近似值提供了理论基础，并展示了在矩阵向量积模型中比现有方法有显著的查询复杂性改进。

Abstract: We study the problem of learning a structured approximation (low-rank,
sparse, banded, etc.) to an unknown matrix $A$ given access to matrix-vector
product (matvec) queries of the form $x \rightarrow Ax$ and $x \rightarrow
A^Tx$. This problem is of central importance to algorithms across scientific
computing and machine learning, with applications to fast multiplication and
inversion for structured matrices, building preconditioners for first-order
optimization, and as a model for differential operator learning. Prior work
focuses on obtaining query complexity upper and lower bounds for learning
specific structured matrix families that commonly arise in applications.
  We initiate the study of the problem in greater generality, aiming to
understand the query complexity of learning approximations from general matrix
families. Our main result focuses on finding a near-optimal approximation to
$A$ from any finite-sized family of matrices, $\mathcal{F}$. Standard results
from matrix sketching show that $O(\log|\mathcal{F}|)$ matvec queries suffice
in this setting. This bound can also be achieved, and is optimal, for
vector-matrix-vector queries of the form $x,y\rightarrow x^TAy$, which have
been widely studied in work on rank-$1$ matrix sensing.
  Surprisingly, we show that, in the matvec model, it is possible to obtain a
nearly quadratic improvement in complexity, to
$\tilde{O}(\sqrt{\log|\mathcal{F}|})$. Further, we prove that this bound is
tight up to log-log factors.Via covering number arguments, our result extends
to well-studied infinite families. As an example, we establish that a
near-optimal approximation from any \emph{linear matrix family} of dimension
$q$ can be learned with $\tilde{O}(\sqrt{q})$ matvec queries, improving on an
$O(q)$ bound achievable via sketching techniques and vector-matrix-vector
queries.

</details>


### [290] [Edge-weighted Matching in the Dark](https://arxiv.org/abs/2507.19366)
*Zhiyi Huang,Enze Sun,Xiaowei Wu,Jiahao Zhao*

Main category: cs.DS

TL;DR: 提出了一种新的二次排序算法，用于随机二部匹配问题，实现了0.659的竞争比，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决随机二部匹配问题，打破1-1/e的竞争比障碍，并改进查询承诺匹配问题的现有竞争比。

Method: 提出了一种新颖的二次排序算法，该算法以两个函数为参数。算法中的两个关键表达式被设计为这两个函数的二次型。研究证明了这些二次型是满足一组自然属性的唯一选择，并允许使用二次规划求解器来优化这两个函数的选择。

Result: 提出了一个0.659竞争比的二次排序算法，该算法是分布无关的，并且优于现有的分布依赖算法。证明了算法中的二次型是满足一组自然属性的唯一选择。

Conclusion: 该研究提出了一个用于随机二部匹配问题的二次排序算法，其竞争比为0.659，打破了1-1/e的障碍，并解决了Tang等人提出的一个开放性问题。该算法的竞争比超过了现有的依赖于分布的算法的最佳竞争比0.641。

Abstract: We present a $0.659$-competitive Quadratic Ranking algorithm for the
Oblivious Bipartite Matching problem, a distribution-free version of
Query-Commit Matching. This result breaks the $1-\frac{1}{e}$ barrier,
addressing an open question raised by Tang, Wu, and Zhang (JACM 2023).
Moreover, the competitive ratio of this distribution-free algorithm improves
the best existing $0.641$ ratio for Query-Commit Matching achieved by the
distribution-dependent algorithm of Chen, Huang, Li, and Tang (SODA 2025).
  Quadratic Ranking is a novel variant of the classic Ranking algorithm. We
parameterize the algorithm with two functions, and let two key expressions in
the definition and analysis of the algorithm be quadratic forms of the two
functions. We show that the quadratic forms are the unique choices that satisfy
a set of natural properties. Further, they allow us to optimize the choice of
the two functions using powerful quadratic programming solvers.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [291] [Game-Theoretic Gradient Control for Robust Neural Network Training](https://arxiv.org/abs/2507.19143)
*Maria Zaitseva,Ivan Tomilov,Natalia Gusarova*

Main category: cs.NE

TL;DR: 本研究提出了一种名为“梯度下降”的正则化方法，通过修改反向传播过程来提高神经网络对噪声的鲁棒性。实验表明，该方法在回归任务上效果显著，但具体效果取决于数据集和超参数。


<details>
  <summary>Details</summary>
Motivation: 前馈神经网络（FFNN）容易受到输入噪声的影响，导致预测性能下降。现有的正则化方法（如Dropout）要么改变网络架构，要么忽略神经元之间的相互作用。因此，本研究旨在通过修改反向传播过程（将其视为多智能体博弈）和探索受控的目标变量加噪，来提高FFNN对噪声的鲁棒性。

Method: 本研究提出了一种名为“梯度下降”的新正则化方法，该方法通过在反向传播过程中有选择地将隐藏层神经元的梯度归零来提高前馈神经网络（FFNN）对噪声的鲁棒性，同时保持前向传播的活性。此外，研究还探索了通过添加白噪声或稳定分布噪声来扰动目标变量的方法。这些方法被置于组合博弈论的框架内进行分析。

Result: 实验结果表明，梯度下降（p=0.9）结合稳定分布目标变量加噪在回归任务上显著提高了对输入噪声的鲁棒性，表现为更平缓的均方误差（MSE）曲线和更稳定的对称平均绝对百分比误差（SMAPE）值。然而，该方法在不同数据集和超参数下的效果各异，有时会提高鲁棒性和准确性，有时则会降低。

Conclusion: 本研究提出的梯度下降方法和目标变量加噪方法在处理输入噪声方面具有潜力，尤其是在回归任务上，通过调整超参数可以提高模型的鲁棒性和准确性。未来的工作可以进一步探索该方法在不同模型和数据集上的应用，并深入研究其作为复杂自适应系统和博弈论框架的分析潜力。

Abstract: Feed-forward neural networks (FFNNs) are vulnerable to input noise, reducing
prediction performance. Existing regularization methods like dropout often
alter network architecture or overlook neuron interactions. This study aims to
enhance FFNN noise robustness by modifying backpropagation, interpreted as a
multi-agent game, and exploring controlled target variable noising. Our
"gradient dropout" selectively nullifies hidden layer neuron gradients with
probability 1 - p during backpropagation, while keeping forward passes active.
This is framed within compositional game theory. Additionally, target variables
were perturbed with white noise or stable distributions. Experiments on ten
diverse tabular datasets show varying impacts: improvement or diminishing of
robustness and accuracy, depending on dataset and hyperparameters. Notably, on
regression tasks, gradient dropout (p = 0.9) combined with stable distribution
target noising significantly increased input noise robustness, evidenced by
flatter MSE curves and more stable SMAPE values. These results highlight the
method's potential, underscore the critical role of adaptive parameter tuning,
and open new avenues for analyzing neural networks as complex adaptive systems
exhibiting emergent behavior within a game-theoretic framework.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [292] [Generating real-time detailed ground visualisations from sparse aerial point clouds](https://arxiv.org/abs/2507.18664)
*Aidan Murray,Eddie Waite,Caleb Ross,Scarlet Mitchell,Alexander Bradley,Joanna Jamrozy,Kenny Mitchell*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Building realistic wide scale outdoor 3D content with sufficient visual
quality to observe at walking eye level or from driven vehicles is often
carried out by large teams of artists skilled in modelling, texturing, material
shading and lighting, which typically leads to both prohibitive costs and
reduced accuracy honoring the variety of real world ground truth landscapes. In
our proposed method, we define a process to automatically amplify real-world
scanned data and render real-time in animated 3D to explore at close range with
high quality for training, simulation, video game and visualisation
applications.

</details>


### [293] [Procedural city modeling](https://arxiv.org/abs/2507.18899)
*Thomas Lechner,Ben Watson,Uri Wilensky,Martin Felsen*

Main category: cs.GR

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We propose a method to procedurally generate a familiar yet complex human
artifact: the city. We are not trying to reproduce existing cities, but to
generate artificial cities that are convincing and plausible by capturing
developmental behavior. In addition, our results are meant to build upon
themselves, such that they ought to look compelling at any point along the
transition from village to metropolis. Our approach largely focuses upon land
usage and building distribution for creating realistic city environments,
whereas previous attempts at city modeling have mainly focused on populating
road networks. Finally, we want our model to be self automated to the point
that the only necessary input is a terrain description, but other high-level
and low-level parameters can be specified to support artistic contributions.
With the aid of agent based simulation we are generating a system of agents and
behaviors that interact with one another through their effects upon a simulated
environment. Our philosophy is that as each agent follows a simple behavioral
rule set, a more complex behavior will tend to emerge out of the interactions
between the agents and their differing rule sets. By confining our model to a
set of simple rules for each class of agents, we hope to make our model
extendible not only in regard to the types of structures that are produced, but
also in describing the social and cultural influences prevalent in all cities

</details>


### [294] [TiVy: Time Series Visual Summary for Scalable Visualization](https://arxiv.org/abs/2507.18972)
*Gromit Yeuk-Yin Chan,Luis Gustavo Nonato,Themis Palpanas,Cláudio T. Silva,Juliana Freire*

Main category: cs.GR

TL;DR: TiVy是一种新的时间序列可视化算法，通过提取相似的子序列模式来减少视觉混乱，提高了可扩展性和清晰度，并且速度比传统方法快1000倍。


<details>
  <summary>Details</summary>
Motivation: 现有的时间序列可视化方法在处理大规模数据时存在可扩展性和视觉清晰度之间的权衡问题。当时间跨度长时，会出现视觉混乱，如过多的多重视图或重叠线条。

Method: TiVy算法通过动态时间规整（DTW）将时间序列转化为基于子序列视觉相似性的符号序列，然后根据频繁的顺序模式对相似的子序列进行不相交分组，从而生成时间序列的视觉摘要。

Result: TiVy算法生成的视觉摘要能够提供清晰的、重叠度低的视图，减少了多重视图的数量，并且在可视化时间序列数据时能提取清晰准确的模式。

Conclusion: TiVy算法能够清晰准确地提取时间序列数据中的模式，并且与传统的DTW聚类方法相比，速度提升了1000倍。该方法在处理大规模时间序列数据时效率很高，能够帮助用户探索数据中隐藏的结构。

Abstract: Visualizing multiple time series presents fundamental tradeoffs between
scalability and visual clarity. Time series capture the behavior of many
large-scale real-world processes, from stock market trends to urban activities.
Users often gain insights by visualizing them as line charts, juxtaposing or
superposing multiple time series to compare them and identify trends and
patterns. However, existing representations struggle with scalability: when
covering long time spans, leading to visual clutter from too many small
multiples or overlapping lines. We propose TiVy, a new algorithm that
summarizes time series using sequential patterns. It transforms the series into
a set of symbolic sequences based on subsequence visual similarity using
Dynamic Time Warping (DTW), then constructs a disjoint grouping of similar
subsequences based on the frequent sequential patterns. The grouping result, a
visual summary of time series, provides uncluttered superposition with fewer
small multiples. Unlike common clustering techniques, TiVy extracts similar
subsequences (of varying lengths) aligned in time. We also present an
interactive time series visualization that renders large-scale time series in
real-time. Our experimental evaluation shows that our algorithm (1) extracts
clear and accurate patterns when visualizing time series data, (2) achieves a
significant speed-up (1000X) compared to a straightforward DTW clustering. We
also demonstrate the efficiency of our approach to explore hidden structures in
massive time series data in two usage scenarios.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [295] [Non-ideal subthreshold swing in aligned carbon nanotube transistors due to variable occupancy discrete charge traps](https://arxiv.org/abs/2507.18646)
*Saurabh S. Sawant,Teo Lara,Francois Leonard,Zhi Yao,Andrew Nonaka*

Main category: cond-mat.mes-hall

TL;DR: 碳纳米管晶体管的亚阈值摆幅可以通过减少近邻陷阱位点来改善


<details>
  <summary>Details</summary>
Motivation: 碳纳米管晶体管的亚阈值摆幅远超理想热极限，影响能量效率，需要解决器件制造带来的非理想性问题

Method: 通过模拟研究离散数量的、具有可变占据数的空穴陷阱位点对亚阈值摆幅的影响

Result: 模拟表明，近邻碳纳米管的陷阱位点（密度约为0.5/nm^2）对亚阈值摆幅有显著影响

Conclusion: 需要去除或钝化少量碳纳米管附近的陷阱位点以改善亚阈值摆幅

Abstract: Carbon nanotube transistors have been experimentally demonstrated to reach
performance comparable and even surpassing that of silicon transistors. Further
improvement requires addressing non-idealities arising from device fabrication
that impact performance and reproducibility. One performance metric that
determines energy efficiency is the subthreshold swing which is often observed
to be 3-4 times larger than the ideal thermal limit. In this work, we present
simulations indicating that a discrete number of variable occupancy hole
trapping sites can explain the large subthreshold swing. Our simulations
indicate that while three-dimensional trap distributions influence the
subthreshold swing, only the traps in close proximity to the nanotubes have a
significant impact. The results suggest that a density of trapping sites on the
order of 0.5/nm$^2$ near the nanotubes is sufficient to significantly increase
the subthreshold swing, requiring the removal or passivation of only a few
sites per carbon nanotube.

</details>


### [296] [Propagating Neutral Modes in an Intervalley Coherent State](https://arxiv.org/abs/2507.18770)
*Richen Xiong,Yi Guo,Chenxin Qin,Fanzhao Yin,Taige Wang,Samuel L. Brantly,Junhang Qi,Jinfei Zhou,Zihan Zhang,Melike Erdi,Kenji Watanabe,Takashi Taniguchi,Shu Zhang,Seth Ariel Tongay,Andrea F. Young,Liang Fu,Chenhao Jin*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用超快成像技术，在扭曲WSe2魔角超晶格中首次观测到IVC态的中性Goldstone模式及其伴随的慢模式，为研究电荷中性模式和魔角超晶格中的自旋-谷物理学提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 在二维平带系统中，电荷激发已被深入研究，但中性激发仍未得到充分探索。特别是，内层谷相干态（IVC）因其自发破缺的谷U(1)对称性而具有一个中性的Goldstone模式，但该模式在实验中仍未被观测到。

Method: 利用新颖的超快成像技术，对扭曲的WSe2魔角超晶格中的时空分辨输运进行了研究，以探测中性模式。

Result: 在中间角度（3.5~4度）和较大角度（约5度）扭曲的WSe2中，研究发现了两种传播的集体模式，它们在范霍夫奇点附近出现，速度显著不同。其中，一个快速传播的模式速度高达约3公里/秒，与IVC态的Goldstone模式一致；而一个慢速传播的模式则可能是能隙的振幅模式。

Conclusion: 本研究通过超快成像技术首次在凝聚态系统中对超流体的集体模式进行了时空分辨输运成像，为探测量子材料中的电荷中性模式提供了新范例，并揭示了魔角超晶格中电荷与自旋-谷相互作用的关键信息。

Abstract: The emergence of neutral collective modes is a hallmark of correlated quantum
phases but is often challenging to probe experimentally. In two-dimensional
flatband systems, charge responses have been intensively investigated, yet
neutral excitations remain largely unexplored. In particular, intervalley
coherent state (IVC) features a neutral Goldstone mode due to spontaneously
broken valley U(1) symmetry. While IVC state has been proposed as a unifying
theme across graphene- and semiconductor-based systems, its defining feature -
the neutral Goldstone mode - remains elusive in experiment. Here we investigate
space-and-time-resolved transport of neutral modes in twisted WSe2 moir\'e
superlattices through a novel ultrafast imaging technique. We uncover two new
propagating collective modes with very different velocities, which emerge near
the van Hove singularity (VHS) in both intermediate- (3.5~4 degree) and
large-angle (~5 degree) twisted WSe2. The fast-propagating mode has a
surprisingly large speed of ~3 km/s and is consistent with a Goldstone mode for
an IVC state, while the slow-moving mode is likely a gapped amplitude mode.
They can be understood as the spin-valley analogues of collective modes of a
superfluid, whose propagation are imaged for the first time in a condensed
matter system. Our study sets a new paradigm for probing charge-neutral modes
in quantum materials and offers key insights into the interplay between charge
and spin-valley physics in moir\'e superlattices.

</details>


### [297] [Topological magneto-optics in the non-coplanar antiferromagnet Co_{1/3}NbS_2: Imaging and writing chiral magnetic domains](https://arxiv.org/abs/2507.18829)
*E. Kirstein,H. Park,I. Martin,J. F. Mitchell,N. Ghimire,S. A. Crooker*

Main category: cond-mat.mes-hall

TL;DR: Co$_{1/3}$NbS$_2$中的拓扑 AFM 序可以通过磁圆二色性（MCD）进行光学探测，实现对 AFM 畴的成像和写入。


<details>
  <summary>Details</summary>
Motivation: 尽管Co$_{1/3}$NbS$_2$的净磁矩很小，但其表现出较大的横向霍尔电导率，这源于其非共面的“四面体”AFM序的拓扑性质。因此，需要一种有效的光学方法来探测和理解这种拓扑 AFM 序。

Method: 本研究采用光学方法，包括在400-1000 nm的波长范围内进行磁圆二色性（MCD）测量，并将其与第一性原理计算进行对比分析。此外，还利用扫描MCD显微镜对 AFM 畴进行了成像和写入。

Result: 研究表明，MCD是一种有效的光学探针，可以揭示Co$_{1/3}$NbS$_2$中的拓扑 AFM 序。光学测量与第一性原理计算的对比分析揭示了量子几何对光学电导率的影响。扫描MCD显微镜成功地成像并写入了 AFM 畴。

Conclusion: 该研究利用磁圆二色性（MCD）作为光学探针，成功地揭示了Co$_{1/3}$NbS$_2$中反铁磁（AFM）涡旋畴的拓扑 AFM 序。研究结果将光学测量与第一性原理计算相结合，阐明了量子几何对光学电导率的影响，并实现了对 AFM 畴的成像和写入。

Abstract: Despite its tiny net magnetization, the antiferromagnetic (AFM) van der Waals
material Co$_{1/3}$NbS$_2$ exhibits a large transverse Hall conductivity
$\sigma_{xy}$ even at zero applied magnetic field, which arises, as recently
shown, from the topological nature of its non-coplanar ``tetrahedral'' AFM
order. This triple-Q magnetic order can be regarded as the short-lengthscale
limit of a magnetic skyrmion lattice, and has an intrinsic spin chirality. Here
we show, using optical wavelengths spanning the ultraviolet to infrared
(400-1000 nm), that magnetic circular dichroism (MCD) provides an incisive
optical probe of the topological AFM order in Co$_{1/3}$NbS$_2$. Measurements
as a continuous function of photon energy are directly compared with
first-principles calculations, revealing the influence of the underlying
quantum geometry on optical conductivity. Leveraging the power and flexibility
of optical methods, we use scanning MCD microscopy to directly image chiral AFM
domains, and demonstrate writing of chiral AFM domains.

</details>


### [298] [Real-space second Chern number using the kernel polynomial method](https://arxiv.org/abs/2507.18919)
*Rui Chen,Bin Zhou*

Main category: cond-mat.mes-hall

TL;DR: 该研究使用核多项式方法评估了四维陈绝缘体的实空间第二陈数，考虑了无序效应，并将其扩展到六维以探索第三陈数。


<details>
  <summary>Details</summary>
Motivation: 评估四维陈绝缘体的实空间第二陈数。

Method: 使用核多项式方法

Result: 计算结果与理论预期吻合，并能捕捉无序效应，与自洽玻恩近似的预测一致。在六维中，虽然有限尺寸效应阻止了完全量化，但数值结果在定性上与理论预期一致。

Conclusion: 该研究代表了实空间表征高维拓扑相的一步。对高维拓扑相的实空间表征。

Abstract: We evaluate the real-space second Chern number of four-dimensional Chern
insulators using the kernel polynomial method. Our calculations are performed
on a four-dimensional system with $30^4$ sites, and the numerical results agree
well with theoretical expectations. Moreover, we show that the method is
capable of capturing the disorder effects. This is evidenced by the phase
diagram obtained for disordered systems, which agrees well with predictions
from the self-consistent Born approximation. Furthermore, we extend the method
to six dimensions and perform an exploratory real-space calculation of the
third Chern number. Although finite-size effects prevent full quantization, the
numerical results show qualitative agreement with theoretical expectations. The
study represents a step forward in the real-space characterization of
higher-dimensional topological phases.

</details>


### [299] [Highly efficient coherent amplification of zero-field spin waves in YIG nano-waveguides](https://arxiv.org/abs/2507.19051)
*K. O. Nikolaev,S. R. Lake,B. Das Mohapatra,G. Schmidt,S. O. Demokritov,V. E. Demidov*

Main category: cond-mat.mes-hall

TL;DR: 本研究利用低损耗磁绝缘体纳米波导和局部参数泵浦，在零偏置磁场下实现了高效的自旋波放大，解决了宏观器件面临的关键技术挑战。


<details>
  <summary>Details</summary>
Motivation: 为了实现高性能的宏观器件，需要解决在纳米结构中高效放大自旋波以及在无外部偏置磁场下运行的两个关键挑战。

Method: 本研究提出的方法是利用低损耗磁绝缘体材料制造纳米波导，并通过局部参数泵浦技术对自旋波脉冲进行放大。

Result: 研究表明，该方法可以在零偏置磁场下，通过仅几毫瓦的功率实现超过两个数量级的相干放大。

Conclusion: 使用低损耗磁绝缘体纳米波导和低功率（几毫瓦）的局部参数泵浦，可以有效解决宏观器件中的两个主要挑战：在纳米结构中高效放大自旋波以及在没有外部偏置磁场的情况下运行纳米电路。

Abstract: Transmission and processing of information at the nanoscale using spin waves
and their quanta - magnons, offers numerous advantages and opportunities that
make it a promising next-generation technology for integrated electronics. The
main challenges that still need to be addressed to ensure high competitiveness
of magnonic devices include finding ways to efficiently amplify spin waves in
nanostructures and developing nanocircuits that can operate without the need
for an external bias magnetic field. Here we demonstrate how these two
challenges can be solved using nano-waveguides fabricated from a low-loss
magnetic insulator. We show that by using local parametric pumping with a power
of only a few milliwatts, one can achieve coherent amplification of spin-wave
pulses by more than two orders of magnitude at zero bias magnetic field. Our
results provide a simple solution to problems that have long prevented the
implementation of efficient integrated magnonic circuits.

</details>


### [300] [Sensing magnonic quantum superpositions using a bosonic mode as the probe](https://arxiv.org/abs/2507.19066)
*Bashab Dey,Sonu Verma,Mathias Weiler,Akashdeep Kamra*

Main category: cond-mat.mes-hall

TL;DR: 本研究提出了使用经典玻色子或声子作为探针来传感磁振子量子叠加态，效果优于量子比特。


<details>
  <summary>Details</summary>
Motivation: 为了探索比超导量子比特更优越的传感器，用于传感磁振子模式的量子叠加态。

Method: 通过理论演示了使用反铁磁中的磁振子模式或低阶非线性磁振子-声子相互作用产生的声子模式作为探针，并推导了相应的有效色散耦合。

Result: 结果表明，经典玻色子模式和反铁磁中的声子模式都可以作为探针来传感磁振子模式的量子叠加态，并且在某些方面优于量子比特。

Conclusion: 本研究提出了使用经典玻色子模式或反铁磁中的声子模式作为探针，来传感磁振子模式的量子叠加态，并且在某些方面优于使用超导量子比特作为探针。

Abstract: Sensing quantum superpositions of a magnonic mode has been accomplished using
a superconducting qubit by realizing an effective dispersive interaction
between the two systems. Here, we theoretically demonstrate that a seemingly
classical bosonic mode can be utilized as a probe for sensing quantum
superpositions of a magnon mode, while outperforming a qubit in various regards
as the sensor. Considering another magnon mode in an antiferromagnet as the
probe mode, we delineate the required dispersive coupling emerging directly
from antiferromagnetic exchange interaction. When a phonon is used as the probe
mode, we derive the effective dispersive coupling emerging from the
lowest-order nonlinear magnon-phonon interactions. Our two considered examples
provide the general design principles for identifying and utilizing a bosonic
probe mode for sensing quantum superpositions in a physical platform of
interest.

</details>


### [301] [Dirac points annihilation and its obstruction characterized by Euler number and quaternionic charges in kagome lattice](https://arxiv.org/abs/2507.19238)
*M. Finck,D. Solnyshkov,J. Dubois,G. Malpuech*

Main category: cond-mat.mes-hall

TL;DR: 研究了三带实对称哈密顿量中Dirac点湮灭的拓扑现象及其阻碍，发现其与欧拉数和四元数荷相关，并可通过光子系统实现。


<details>
  <summary>Details</summary>
Motivation: 研究了具有时间反转对称性的三带实对称哈密顿量中的Dirac点湮灭现象及其拓扑阻碍，并将其与欧拉数联系起来。

Method: 研究了具有时间反转对称性的三带实对称哈密顿量中的Dirac点湮灭现象及其拓扑阻碍，并将其与欧拉数联系起来。利用kagome点阵的紧束缚模型作为实例，通过调整点阵参数，展示了Dirac点湮灭和拓扑阻碍的两种情况。在没有三带系统间隙的情况下，通过引入“贴片”欧拉数来处理布里渊区子区域的拓扑不变量。此外，还运用同伦理论，将Dirac点与四元数荷联系起来，并证明了Dirac点在k空间中的非阿贝尔编织会共轭其四元数荷，从而解释了Dirac点湮灭的阻碍。

Result: kagome点阵的紧束缚模型表明，Dirac点湮灭是可能的，但也可能受到拓扑阻碍。拓扑阻碍与“贴片”欧拉数和Dirac点在k空间中的非阿贝尔编织有关，后者会共轭其四元数荷。

Conclusion: Dirac点湮灭的拓扑现象及其在具有时间反转对称性的三带实对称哈密顿量中的阻碍与欧拉数（一种已知的拓扑不变量）有关。在没有布里渊区间隙的三带系统中，例如kagome点阵，欧拉数在整个布里渊区是未定义的，需要在没有第三带额外简并的子区域上引入“贴片”欧拉数。非零的贴片欧拉数意味着Dirac点湮灭是不可能的。通过同伦理论，可以将Dirac点与四元数荷相关联，Dirac点在k空间中的非阿贝尔编织会共轭其四元数荷，并解释了Dirac点湮灭的可能阻碍。

Abstract: We investigate the topological phenomenon of Dirac point annihilation and its
obstruction in three-band, real symmetric Hamiltonians with time-reversal
symmetry, and their relation to the Euler number, a well-known topological
invariant. For this purpose, we study the example of the kagome lattice using a
simple tight-binding model. By tuning the parameters of the lattice
continuously, we illustrate situations where two Dirac points are able to
annihilate, and others, where this annihilation is topologically obstructed.
For a system with no gaps between the three bands, like in the kagome lattice,
the Euler number of two bands is ill-defined on the whole Brillouin zone, which
requires the introduction of the so-called ``patch" Euler number on a subregion
without additional degeneracies coming from the third band. A non-zero patch
Euler number means that the annihilation of the Dirac points is impossible. We
also illustrate another point of view, using homotopy theory, associating the
Dirac points with quaternionic charges. We prove that the non-abelian braiding
of the Dirac points in k-space conjugates their quaternionic charge and
explains the possible obstruction to the annihilation of Dirac points. Finally,
we show that the proposed deformation of the kagome lattice can be achieved in
realistic photonic systems.

</details>


### [302] [Quantum Droplets of Light in Semiconductor Microcavities](https://arxiv.org/abs/2507.19324)
*Matteo Caldara,Olivier Bleu,Francesca Maria Marchetti,Jesper Levinsen,Meera M. Parish*

Main category: cond-mat.mes-hall

TL;DR: 在固态系统中预测了量子液滴相，由激子-极化激元组成，通过调控相互作用实现，可通过光谱和空间分布探测，有望实现极化激元凝结。


<details>
  <summary>Details</summary>
Motivation: 本文旨在探索量子液滴相在固态系统中的存在性，特别是通过激子-极化激元实现，以期达到极化激元凝结并打开实现量子极化激元状态的另一途径。

Method: 本文提出了一种利用原子层厚半导体中的激子-极化激元自旋混合物，通过近双激子Feshbach共振来调控相互作用，从而在固态系统中实现量子液滴相。

Result: 研究发现，在原子层厚的半导体中，利用实际参数可以实现自约束量子液滴，其激发光谱和空间分布可用于探测。这种相态有望在更低的阈值下实现极化激元凝结。

Conclusion: 本文预测了在固态系统中存在量子液滴相，这是一种由激子-极化激元组成的、在半导体微腔中由激子和光子强耦合形成的稀有自约束玻色子组态。通过利用近双激子Feshbach共振的激子-极化激元自旋混合物，可以调节种内相互作用为吸引，并与种内排斥相当。研究表明，在原子层厚的半导体中，使用实际参数即可实现自约束量子液滴，并且可以通过其激发光谱和空间分布来探测。

Abstract: Quantum droplets are dilute self-bound configurations of bosons that result
from the balance between a mean-field attraction and a repulsion induced by
quantum fluctuations. Such droplets have been successfully realized in cold
atomic gases and represent a signature of their quantum nature. Here, we
predict the existence of a similar droplet phase in a solid-state system,
involving polaritons formed from the strong coupling between excitons (bound
electron-hole pairs) and photons in a semiconductor microcavity. We consider a
spin mixture of exciton-polaritons near a biexciton Feshbach resonance, which
allows one to tune the interspecies interactions to be attractive and
comparable in magnitude to the intraspecies repulsion. We find that self-bound
quantum droplets are achievable for realistic parameters in atomically thin
semiconductors, and that they can be detected via their excitation spectrum and
spatial profile. This exotic phase could potentially lead to polariton
condensation at lower thresholds and it opens an alternative avenue to achieve
the long-sought quantum polaritonic regime.

</details>


### [303] [Measurement and Qualitative Explanation of Decay Lengths of Attractive and Repulsive Forces between Natural and Artificial Atoms](https://arxiv.org/abs/2507.19392)
*Marco Weiss,Fabian Stilp,Max Reinhart,Franz J. Giessibl*

Main category: cond-mat.mes-hall

TL;DR: 量子 केवळ与天然原子的相互作用衰减长度不同，量子 केवळ的衰减长度更长。


<details>
  <summary>Details</summary>
Motivation: 研究局域化量子态与纳米探针之间基本相互作用的平台。

Method: 使用CO和金属端尖的原子力显微镜测量了Cu(111)表面方形量子 केवळ内的相互作用。

Result: CO端尖探针的排斥相互作用衰减长度为46pm，金属端尖探针的吸引相互作用衰减长度为66pm。

Conclusion: 与天然原子相比，量子 केवळ (quantum corrals) 缺乏深度束缚和高度局域化的状态，导致更长的衰减长度。这为理解和设计低维量子结构和器件中的原子尺度相互作用提供了新的途径。

Abstract: Artificial atoms, such as quantum corrals, offer an excellent platform to
study fundamental interactions between localized quantum states and nanoscale
probes. We performed atomic force microscopy measurements inside square quantum
corrals on Cu(111) using CO- and metal-terminated tips. Using chemically
unreactive CO-terminated tips repulsive Pauli forces can be probed, while
metallic tips are attracted to the localized quantum states due to chemical
bonding. We found distinct exponential decay constants of 46 pm for the
repulsive and 66 pm for the attractive forces. Attractive and repulsive
interactions between two natural atoms show significantly shorter decay
lengths. While natural atoms feature states with a broad range of decay
lengths, including very short ones from deeply bound states, quantum corrals
are lacking such deeply bound and highly localized states, resulting in longer
decay lengths. These results offer a new route to understand and design
atomic-scale interactions in low-dimensional quantum structures and devices.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [304] [CUTHERMO: Understanding GPU Memory Inefficiencies with Heat Map Profiling](https://arxiv.org/abs/2507.18729)
*Yanbo Zhao,Jinku Cui,Zecheng Li,Shuyin Jiao,Xu Liu,Jiajia Li*

Main category: cs.DC

TL;DR: cuThermo是一款无需修改代码即可分析GPU内存使用的工具，能够识别低效内存访问并提供优化建议，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: GPU在高性能计算和机器学习等领域至关重要，而有效利用GPU内存子系统是最大化其计算能力的关键。然而，目前GPU架构缺乏全面的运行时和细粒度内存分析支持。

Method: cuThermo是一款在GPU二进制文件上运行的轻量级分析工具，它通过基于不同访问warp计数的热力图来识别内存效率低下的问题，从而提供性能调优的指导。

Result: 通过在六个应用程序上的实验，cuThermo识别了五种跨GPU架构的内存访问模式，并通过在两款GPU上的优化实验，实现了高达721.79%的性能提升。

Conclusion: cuThermo是一款轻量级的GPU内存分析工具，它可以在没有硬件、操作系统或应用程序源代码修改的情况下运行。通过分析内存访问模式，cuThermo可以识别内存效率低下的问题，并提供优化建议，在实验中实现了高达721.79%的性能提升。

Abstract: GPUs have become indispensable in high-performance computing, machine
learning, and many other domains. Efficiently utilizing the memory subsystem on
GPUs is critical for maximizing computing power through massive parallelism.
Analyzing memory access patterns has proven to be an effective method for
understanding memory bottlenecks in applications. However, comprehensive
runtime and fine-grained memory profiling support is lacking on GPU
architectures. In this work, we introduce cuThermo, a lightweight and practical
profiling tool for GPU memory analysis. It operates on GPU binaries without
requiring any modifications to hardware, operating system, or application
source code. Given a CUDA application, cuThermo identifies memory
inefficiencies at runtime via a heat map based on distinct visited warp counts
to represent word-sector-level data sharing and provides optimization guidance
in performance tuning iterations. Through our experiments on six applications,
we identified five memory access patterns that are portable across different
GPU architectures. By evaluating optimization on two GPUs, cuThermo achieves up
to $721.79\%$ performance improvement.

</details>


### [305] [PPipe: Efficient Video Analytics Serving on Heterogeneous GPU Clusters via Pool-Based Pipeline Parallelism](https://arxiv.org/abs/2507.18748)
*Z. Jonny Kong,Qiang Xu,Y. Charlie Hu*

Main category: cs.DC

TL;DR: PPipe利用流水线并行在异构GPU集群上提高了延迟敏感模型推理服务的吞吐量和GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 随着GPU的快速发展，异构GPU集群日益普遍。本文旨在探索如何将为吞吐量导向的深度学习模型训练研究的流水线并行技术，有效地应用于延迟敏感的模型推理服务，特别是在异构GPU集群上。

Method: 本文提出了一种名为PPipe的新型推理服务系统，它采用基于MILP的控制平面和基于资源预留的自适应批处理的数据平面来实现池化流水线并行。

Result: PPipe实现了41.1% - 65.5%的低类GPU利用率提升，同时保持了高类GPU的高利用率，与基线相比，服务吞吐量提高了32.2% - 75.1%。

Conclusion: PPipe通过利用异构GPU集群中模型层和GPU架构的多样性，并结合基于MILP的控制平面和基于资源预留的自适应批处理的数据平面，实现了低类GPU利用率的提升和整体服务吞吐量的增加。

Abstract: With the rapid innovation of GPUs, heterogeneous GPU clusters in both public
clouds and on-premise data centers have become increasingly commonplace. In
this paper, we demonstrate how pipeline parallelism, a technique wellstudied
for throughput-oriented deep learning model training, can be used effectively
for serving latency-bound model inference, e.g., in video analytics systems, on
heterogeneous GPU clusters. Our work exploits the synergy between diversity in
model layers and diversity in GPU architectures, which results in comparable
inference latency for many layers when running on low-class and high-class
GPUs. We explore how such overlooked capability of low-class GPUs can be
exploited using pipeline parallelism and present a novel inference serving
system, PPipe, that employs pool-based pipeline parallelism via an MILP-based
control plane and a data plane that performs resource reservation-based
adaptive batching. Evaluation results on diverse workloads (18 CNN models) show
that PPipe achieves 41.1% - 65.5% higher utilization of low-class GPUs while
maintaining high utilization of high-class GPUs, leading to 32.2% - 75.1%
higher serving throughput compared to various baselines.

</details>


### [306] [Deadline-Aware Joint Task Scheduling and Offloading in Mobile Edge Computing Systems](https://arxiv.org/abs/2507.18864)
*Ngoc Hung Nguyen,Van-Dinh Nguyen,Anh Tuan Nguyen,Nguyen Van Thieu,Hoang Nam Nguyen,Symeon Chatzinotas*

Main category: cs.DC

TL;DR: 该论文提出了一种高效的最优作业调度算法，用于解决移动边缘计算和云计算中的任务调度和卸载问题，该算法具有 O(nlogn) 的时间复杂度，并能有效处理随机到达的任务。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算和云计算系统对服务质量的要求日益提高，需要处理计算密集型任务并满足特定的截止日期或实现极低的延迟，现有研究主要关注减少未满足截止日期的作业数量，但面临总搜索时间和调度效率的挑战。

Method: 提出了一种最优作业调度算法，以线性对数时间 O(nlogn) 确定最优任务顺序；为应对随机到达的任务的不确定性，开发了一种在线方法，具有快速的断线检测能力，并以 O(n) 的时间复杂度实现了快速接受时间。

Result: 通过详细的性能分析，证明了该算法的最优性和低复杂度，其时间复杂度为 O(nlogn)。所提出的在线方法具有 O(n) 的时间复杂度，并且通过广泛的数值结果证明了该算法在服务比率和服务成本方面的有效性。

Conclusion: 该研究提出了一种最优作业调度算法，用于确定给定任务集的最优任务顺序，并支持用户基于服务器信息做出明智的任务卸载决策。

Abstract: The demand for stringent interactive quality-of-service has intensified in
both mobile edge computing (MEC) and cloud systems, driven by the imperative to
improve user experiences. As a result, the processing of computation-intensive
tasks in these systems necessitates adherence to specific deadlines or
achieving extremely low latency. To optimize task scheduling performance,
existing research has mainly focused on reducing the number of late jobs whose
deadlines are not met. However, the primary challenge with these methods lies
in the total search time and scheduling efficiency. In this paper, we present
the optimal job scheduling algorithm designed to determine the optimal task
order for a given set of tasks. In addition, users are enabled to make informed
decisions for offloading tasks based on the information provided by servers.
The details of performance analysis are provided to show its optimality and low
complexity with the linearithmic time O(nlogn), where $n$ is the number of
tasks. To tackle the uncertainty of the randomly arriving tasks, we further
develop an online approach with fast outage detection that achieves rapid
acceptance times with time complexity of O(n). Extensive numerical results are
provided to demonstrate the effectiveness of the proposed algorithm in terms of
the service ratio and scheduling cost.

</details>


### [307] [GPUnion: Autonomous GPU Sharing on Campus](https://arxiv.org/abs/2507.18928)
*Yufang Li,Yuanbo Zhang,Hanlong Liao,Guoming Tang,Deke Guo*

Main category: cs.DC

TL;DR: GPUnion 是一个校园规模的 GPU 共享平台，允许自愿参与并保持提供者的完全自主权，解决了校园内 GPU 资源不平衡的问题。它通过容器化、提供者优先架构和弹性执行机制，提高了 GPU 利用率和交互会话数量，并确保了工作负载的可靠迁移。


<details>
  <summary>Details</summary>
Motivation: 为了解决校园内 GPU 资源分配不均的问题，即一些实验室拥有未充分利用的服务器，而另一些实验室则缺乏进行人工智能研究所需的计算能力，GPUnion 平台旨在实现 GPU 资源的共享，以缓解这种差距。现有的平台通常依赖集中管理和持久分配模式，这与学术界资源所有者的自愿参与和自主性相冲突。

Method: GPUnion 平台采用容器化任务调度与执行、资源提供者优先架构以及自动检查点和迁移的弹性执行机制。此外，平台还支持自定义数据存储，并集成非root执行和镜像验证以增强容器化的隔离性和安全性。

Result: 通过跨多个校园场景的案例研究，GPUnion 实现了 30% 的 GPU 利用率提升、40% 的交互式会话增加以及 94% 的提供者离开期间成功的工作负载迁移。

Conclusion: GPUnion 平台证明了提供者自主性与平台可靠性可以共存，挑战了传统的集中式模式，并促进了校园网络内计算资源的民主化访问。

Abstract: A pronounced imbalance in GPU resources exists on campus, where some
laboratories own underutilized servers while others lack the compute needed for
AI research. GPU sharing can alleviate this disparity, while existing platforms
typically rely on centralized oversight and persistent allocation models,
conflicting with the voluntary and autonomous nature of academic resource
ownership. We present GPUnion, a campus-scale GPU sharing platform enabling
voluntary participation while preserving full provider autonomy. GPUnion
incorporates three core mechanisms: i) container-based task dispatching and
execution, ii) resource provider-first architecture, and iii) resilient
execution featuring automatic checkpointing and migration. GPUnion also
supports custom data storage and integrates the non-root execution and image
attestation for isolation and security improvement for containerization. Case
studies across multiple campus scenarios demonstrate 30% more GPU utilization
improvement, 40% increase in interactive sessions, and 94% successful workload
migration during provider departures. GPUnion demonstrates that provider
autonomy and platform reliability can coexist, challenging conventional
centralized paradigms and democratizing access to computational resources
within campus networks.

</details>


### [308] [The Case for Time-Shared Computing Resources](https://arxiv.org/abs/2507.19287)
*Pierre Jacquet,Adrien Luxey-Bitri*

Main category: cs.DC

TL;DR: ICT对环境的影响日益增大，但其资源消耗受物质性限制。租户通常不共享计算资源，这与共用环境的普遍看法相反。本文提出了一种通过提高租户间的资源共享来“用更少的资源做事”的范式，以应对日益增长的环境压力，并提出了时间共享计算的新解释和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 信息通信技术（ICT）的环境影响持续增长，这主要源于使用量的增加、回弹效应和新兴需求。然而，尽管ICT服务具有虚拟性，但该行业仍受其物质性的制约，无法依赖无限的资源池。因此，未来可能需要在托管设施中对支持的各种服务实施更严格的限制。为了解决这个问题，本文提出了一种改进资源共享的解决方案。

Method: 本文回顾了该领域的现状，确定了挑战和机遇，提出了时间共享计算的解释，并概述了关键的研究方向。

Result: 研究表明，租户通常不共享计算资源，即使在通常被认为是共用的环境中（如云平台）。时间共享因性能、安全、可预测性以及计算资源成本不断下降等原因而被逐步淘汰。本文提出的通过增强基础设施共用性来减小集群规模和提高能源效率的方法，可以带来可接受的性能权衡。

Conclusion: 该论文主张通过改进租户间的资源共享来管理更少的物理资源，这代表了一种范式转变，超越了传统的硬件级别的时间共享，进入了更高级别的抽象。虽然这需要在“性能降低”的条件下“用更少的资源做事”，但增强基础设施的共用性可以减小集群规模（通过整合）并提高能源效率，其带来的收益与可接受的性能权衡有关，这种情况可能比消除服务对社会更具可接受性。

Abstract: The environmental impact of Information and Communication Technologies (ICT)
continues to grow, driven notably by increasing usage, rebound effects, and
emerging demands. However, despite the virtual nature of its services, the
sector remains inherently constrained by its materiality and cannot rely on an
infinite pool of resources. As a result, the wide variety of supported services
may need to be managed under stricter limits within hosting facilities in the
future. Contrary to common assumptions, we show that tenants typically do not
share computing resources, even in environments commonly perceived as
mutualized, such as cloud platforms. Time-sharing has been progressively phased
out for reasons of performance, security, predictability, and, perhaps more
importantly, due to the decreasing cost of computing resources. This paper
advocates for managing fewer physical resources by improving resource sharing
between tenants. It represents a paradigm shift, moving beyond traditional
time-sharing at the hardware level to a higher abstraction. This approach
entails "doing with fewer resources" under conditions of "reduced performance".
Nonetheless, enhancing the mutualization of infrastructure can reduce cluster
sizes (through consolidation) and improve energy efficiency, with gains related
to the accepted performance trade-off, a situation potentially more socially
acceptable than eliminating services. We review the current state of the art,
identify challenges and opportunities, propose interpretations of Time-Shared
Computing, and outline key research directions.

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [309] [Towards Accurate Thermal Property Predictions in Uranium Nitride using Machine Learning Interatomic Potential](https://arxiv.org/abs/2507.18786)
*Beihan Chen,Zilong Hua,Jennifer K. Watkins,Linu Malakkal,Marat Khafizov,David H. Hurley,Miaomiao Jin*

Main category: cond-mat.mtrl-sci

TL;DR: 通过机器学习势和分子动力学模拟结合实验测量，成功预测了氮化铀（UN）的热性质，并验证了模型的可靠性。


<details>
  <summary>Details</summary>
Motivation: 开发一种机器学习势（MLIP）来预测氮化铀（UN）的热性质，并通过实验进行验证。

Method: 通过机器学习势（MLIP）和分子动力学（MD）模拟，并结合实验测量来研究氮化铀（UN）的热性质。

Result: 开发的MLIP在能量、力、弹性常数、声子色散和缺陷形成能等方面的预测与DFT计算、先前的实验结果以及新的热导率测量结果具有良好的一致性。MD模拟预测了熔点、热膨胀、比热和热导率等关键热性质，实验测量结果也与MLIP预测结果高度一致。

Conclusion: 该研究证实了所开发的用于确定氮化铀热性质的势的可靠性和预测能力。

Abstract: We present a combined computational and experimental investigation of the
thermal properties of uranium nitride (UN), focusing on the development of a
machine learning interatomic potential (MLIP) using the moment tensor potential
(MTP) framework. The MLIP was trained on density functional theory (DFT) data
and validated against various quantities including energies, forces, elastic
constants, phonon dispersion, and defect formation energies, achieving
excellent agreement with DFT calculations, prior experimental results and our
thermal conductivity measurement. The potential was then employed in molecular
dynamics (MD) simulations to predict key thermal properties such as melting
point, thermal expansion, specific heat, and thermal conductivity. To further
assess model accuracy, we fabricated a UN sample and performed new thermal
conductivity measurements representative of single-crystal properties, which
show strong agreement with the MLIP predictions. This work confirms the
reliability and predictive capability of the developed potential for
determining the thermal properties of UN.

</details>


### [310] [Observation of Magnetic Devil's Staircase-Like Behavior in Quasiperiodic Qubit Lattices](https://arxiv.org/abs/2507.18818)
*Alejandro Lopez-Bezanilla*

Main category: cond-mat.mtrl-sci

TL;DR: 魔鬼阶梯现象不仅存在于周期性系统，也存在于非周期性系统中，利用量子退火设备可以实现对非周期性系统的研究。


<details>
  <summary>Details</summary>
Motivation: 探索魔鬼阶梯（DS）现象在非周期、分形系统中的发生，因为这些系统与该现象天然兼容。

Method: 利用量子退火设备，在简单的 Ising 模型框架内，通过增加外部磁场来揭示由自旋流驱动的丰富磁跃变。

Result: 发现短程反铁磁耦合在非周期几何中也能产生丰富的基态磁化模式，并且磁结构虽然受晶格尺寸影响但具有尺度无关性，共格性局部出现。

Conclusion: 研究结果挑战了魔鬼阶梯现象仅限于周期性系统的观点，并提出准周期几何是该现象的天然宿主。

Abstract: The devil's staircase (DS) phenomenon is a fractal response of magnetization
to external fields, traditionally observed in periodic ferromagnetic systems,
where the commensurability between spin arrangements, lattice parameters, and
external magnetic fields governs abrupt changes in magnetization. Its
occurrence in aperiodic, fractal-type systems has remained largely unexplored,
despite their natural compatibility with such phenomena. Using a quantum
annealing device, we uncover a wealth of abrupt magnetic transitions between
spin manifolds driven by increasing external magnetic fields within a simple
yet effective Ising-model framework. In contrast to periodic systems, where DS
arises from long-range competing interactions, our findings reveal that
short-range, purely antiferromagnetic couplings in aperiodic geometries produce
equally rich ground-state magnetization patterns. We demonstrate that while
magnetic textures are determined by the lattice size, their formation remains
remarkably robust and independent of scale, with commensurability emerging
locally. Our results challenge the prevailing view that DS behavior is limited
to periodic systems and establish quasiperiodic geometries as a natural host
for this phenomenon.

</details>


### [311] [Prediction of Mechanical Properties and Thermodynamic Stability of Ti-N system using MTP Interatomic Potential](https://arxiv.org/abs/2507.18873)
*Pradeep Kumar Rana,Atharva Vyawahare,Rohit Batra,Satyesh Kumar Yadav*

Main category: cond-mat.mtrl-sci

TL;DR: 开发了一种用于Ti-N系统的MTP势，可准确预测其机械性能和热力学稳定性，并发现了新的稳定相。


<details>
  <summary>Details</summary>
Motivation: 为了能够可靠地预测具有不同化学计量比的Ti-N材料体系（如Ti2N, Ti3N2, Ti6N5, Ti4N3等）的机械性能和热力学稳定性，需要开发一种精确的原子间势。

Method: 本研究开发了一种基于力矩张量势（MTP）的原子间势，该势利用了密度泛函理论（DFT）计算的形成能数据进行训练和测试。在选择训练数据集时，考虑了不同Ti-N系统的结构相似性和差异性。

Result: 开发的MTP势在预测形成能方面表现出色，与DFT计算相比，训练数据集的均方根误差（RMSE）为2.1 meV/atom，测试数据集的RMSE为6.8 meV/atom。此外，该势还能准确预测弹性常数，并用于预测Ti-N系统中的新相，揭示了N/Ti比在0到1范围内可能存在的稳定相。

Conclusion: 该研究成功开发了一种基于力矩张量势（MTP）的原子间势，能够可靠地预测所有钛氮（Ti-N）系统的机械性能和热力学稳定性。研究表明，N/Ti比在0到1范围内的结构在热力学上是稳定的，并且在形成能的凸包图上，一些系统在0K时最多偏离10 meV/atom。

Abstract: Ti-N material system have range of compounds with different stoichiometry
like Ti2N, Ti3N2, Ti6N5, Ti4N3 alongwith Ti , TiN and solid solutions of N in
Ti with a maximum of 23% solubility. In this work, we develop an interatomic
potential based on moment tensor potential (MTP) that could reliably predict
mechanical properties and thermodynamic stability of all Ti-N system. Taking
into account the structural similarity and dissimilarity of various Ti-N system
to choose training dataset was crucial for development of the potential. Root
mean square error (RMSE) in prediction of formation energy using MTP potential
compared to one calculated using density functional theory (DFT) for training
dataset is 2.1 meV/atom and for testing dataset is 6.8 meV/atom. The frequency
of absolute error in formation energy peaks at a maximum value of 3.8 meV/atom
for system that was part of training dataset, while it peaks at 7.6 meV/atom
for systems that are not part of the training dataset. Furthermore, the
distribution and variability of elastic constants across compositions are
systematically evaluated, revealing trends consistent with DFT benchmarks. The
developed potential was used to predict energy of new phases in Ti-N system. We
show that structures with N/Ti ratios ranging from 0 to 1 can be
thermodynamically stable. A maximum deviation of 10 meV/atom from the convex
hull plot of formation energy 0K was observed for a few system.

</details>


### [312] [Atomic-Scale Heterogeneity of Hydrogen in Metal Hydrides Revealed by Electron Ptychography](https://arxiv.org/abs/2507.18906)
*Pengcheng Li,Chenglin Pua,Zehao Dong,Zhengxiong Su,Tao Liu,Chao Cai,Huahai Shen,Lin Gu,Zhen Chen*

Main category: cond-mat.mtrl-sci

TL;DR: MEP技术克服了传统显微镜在探测氢原子方面的局限性，能够高精度地进行三维定量和原子定位，为理解氢在材料科学中的作用提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 由于氢原子散射能力弱、迁移率高，以及传统透射电子显微镜的局限性，精确测定氢原子的原子尺度分布一直是一个挑战。

Method: 多层电子束相控阵（MEP）技术，该技术通过三项关键进展解决了这些限制：对氢占有率的卓越敏感性、三维定量以及原子定位的皮米级精度。

Result: MEP在多主元素合金氢化物中解析了不均匀的氢分布，并以皮米精度量化了氢引起的晶格位移。

Conclusion: MEP是一种变革性的新方法，可以直接探测固体中的氢原子，从而解锁对氢对材料性能影响的基本理解。

Abstract: Hydrogen plays critical roles in materials science, particularly for
advancing technologies in hydrogen storage and phase manipulation, while also
posing challenges like hydrogen embrittlement. Understanding its behavior,
vital for improving material properties, requires precise determination of
atomic-scale distribution-a persistent challenge due to hydrogen's weak
electron scattering and high mobility, as well as the limitations of
conventional transmission electron microscopy. We demonstrate that multislice
electron ptychography (MEP) overcomes these constraints through three key
advances: exceptional sensitivity for hydrogen occupancy, three-dimensional
quantification, and picometer-level precision in atomic positioning.
Experimentally, MEP resolves heterogeneous hydrogen distributions and
quantifies hydrogen-induced lattice displacements with picometer precision in
multi-principal-element alloy hydrides. This work demonstrates MEP as a
transformative method for directly probing hydrogen atoms in solids, unlocking
fundamental understanding of hydrogen's impact on material properties.

</details>


### [313] [Pressure-mediated crystalline g-C$_3$N$_4$ with enhanced spatial charge transport for solar H$_2$ evolution and photocathodic protection of 304 stainless steels](https://arxiv.org/abs/2507.18914)
*Xiaochun Gao,Shaoqi Hou,Dawei Su*

Main category: cond-mat.mtrl-sci

TL;DR: 本文提出了一种压力介导的离子热合成方法，制备出高结晶度且表面缺陷得到调控的g-C3N4（CCN-P），在光催化产氢和光阴极保护方面表现出优异性能。


<details>
  <summary>Details</summary>
Motivation: 尽管缺陷工程可以增强g-C3N4的可见光吸收和电荷分离，但往往会引入过多的悬挂键和晶格缺陷，从而加剧载流子复合和损害光收集。高结晶度是改善空间电荷传输的有效途径，但同时优化结晶度和表面缺陷的策略仍有待探索。

Method: 本文采用压力介导的离子热合成法，利用NaCl/KCl低共熔盐在加压条件下制备了高结晶度的g-C3N4（CCN-P）。

Result: 通过熔融盐促进平面和垂直方向的晶体生长，并施加压力减小层间距和缩短光载流子路径，所得CCN-P材料具有平衡的表面缺陷（-CN和-NHx），电子陷阱电阻（Rtrap）为11.36 k$\Omega$ cm$^2$，光载流子衰减速率常数为0.013 s$^{-1}$。 CCN-P实现了2168.8 $\mu$mol g$^{-1}$ h$^{-1}$的氢气演化率，并且对304不锈钢的暗光阴极保护效率在7500秒内达到78.5%，性能优于块体和常规结晶的g-C3N4。

Conclusion: 通过压力介导的离子热合成方法，成功制备了高结晶度的g-C3N4（CCN-P），该材料在表面缺陷（-CN和-NHx）、电子陷阱电阻（Rtrap为11.36 k$\Omega$ cm$^2$）和光载流子衰减速率常数（0.013 s$^{-1}$）方面实现了平衡。 CCN-P在氢气演化率（2168.8 $\mu$mol g$^{-1}$ h$^{-1}$）和光阴极保护性能（对304不锈钢的暗光阴极保护效率为78.5%，持续7500 s）方面均优于块体和常规结晶的g-C3N4。该方法为调控聚合半导体的结晶骨架和缺陷分布以实现高效太阳能转换提供了一个通用的平台。

Abstract: Conjugated polymeric g-C$_3$N$_4$ has emerged as a leading semiconductor for
solar-to-chemical energy conversion due to its unique electronic band
structure, robust physicochemical stability, and environmental benignity.
However, defect engineering-while effective at enhancing visible-light
absorption and charge separation-often introduces excessive dangling bonds and
lattice disorder, which exacerbate carrier recombination and impair light
harvesting. High crystallinity offers a complementary route to improve spatial
charge transport, yet strategies that concurrently optimize crystallinity and
surface defects remain underexplored. Here we report a pressure-mediated ion
thermal synthesis of high-crystalline g-C$_3$N$_4$ (CCN-P) using a NaCl/KCl
eutectic salt under elevated pressure. The molten salt facilitates in-plane and
cross-plane crystal growth, while applied pressure reduces interlayer spacing
and shortens photocarrier pathways. This dual modulation yields CCN-P with
balanced surface defects (-CN and -NHx), an electron-trapping resistance
(Rtrap) of 11.36 k$\Omega$ cm$^2$ and a photocarrier decay rate constant of
0.013 s$^{-1}$. CCN-P achieves a hydrogen evolution rate of 2168.8 $\mu$mol
g$^{-1}$ h$^{-1}$ and delivers 78.5% dark photocathodic protection of 304
stainless steel over 7500 s, outperforming bulk and conventionally crystalline
g-C$_3$N$_4$. This straightforward pressure-ion thermal approach provides a
versatile platform for tailoring crystalline frameworks and defect
distributions in polymeric semiconductors for efficient solar energy
conversion.

</details>


### [314] [Atomic-scale confinement of strongly charged 180 degree domain wall pairs in ZrO2](https://arxiv.org/abs/2507.18920)
*Nashrah Afroze,Hamoon Fahrvandi,Guodong Ren,Pawan Kumar,Christopher Nelson,Sarah Lombardo,Mengkun Tian,Ping-Che Lee,Jiayi Chen,Manifa Noor,Kisung Chae,Sanghyun Kang,Prasanna Venkat Ravindran,Matthew Bergschneider,Gwan Yeong Jung,Pravan Omprakash,Gardy K. Ligonde,Nujhat Tasneem,Dina Triyoso,Steven Consiglio,Kanda Tapily,Robert Clark,Gert Leusink,Jayakanth Ravichandran,Shimeng Yu,Andrew Lupini,Andrew Kummel,Kyeongjae Cho,Duk-Hyun Choe,Nazanin Bassiri-Gharb,Josh Kacher,Rohan Mishra,Jun Hee Lee,Asif Khan*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过STEM发现，在ZrO2的极性层中，偶极子排列不均匀，形成了原子级薄的180度畴壁，这是首次观察到的反极铁性排序，揭示了原子尺度上极性织构的新型层次化自组织，为纳米存储器和纳米电子学提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 为了探索铁电材料中自组织极性织构的形成机制，以及硅兼容铁电材料（如HfO2和ZrO2）中极性层的偶极子排列是否如普遍认为的那样是均匀的。

Method: 利用扫描透射电子显微镜（STEM）对超薄ZrO2薄膜进行俯视取向的成像。

Result: 在极窄的极性层中，偶极子组织呈现出显著的不均匀性，形成了原子级薄、维度受限、带电的180度畴壁，其长度最长为几个单位晶胞。这些畴壁在头对头和尾对尾构型之间交替出现，并且具有完全不同的界面结构，将面内畴限制在亚纳米平方的足迹内，使其成为迄今报道的极性材料中最小的畴之一。

Conclusion: 该研究首次通过实验观察到通过强带电畴壁的反极铁性排序，同时该畴壁嵌套在自组织极性-非极性层状结构中，揭示了原子尺度上极性织构新颖的层次化自组织，并为硅兼容的简单二元氧化物中的原子致密存储器和畴壁纳米电子学开辟了新途径。

Abstract: Self organized polar textures can occur in ferroelectric materials across
multiple length scales, from nanometer scale vortices and skyrmions, to
mesoscopic stripe domains, and macroscopic twin patterns, making these
phenomena central to condensed matter physics and nanotechnology. Silicon
compatible ferroelectrics such as HfO2 and ZrO2 spontaneously form alternating
stacks of two dimensional (2D) polar and nonpolar half unit cell layers,
effectively confining dipoles to isolated, single atomic plane layers. However,
the arrangement of dipoles within each polar plane is generally considered
uniform. Here, by utilizing scanning transmission electron microscopy (STEM) of
an ultrathin ZrO2 film in the plan view orientation, we show that within these
irreducibly narrow polar layers, the dipole organization can be strikingly
non-uniform, forming atomically thin, dimensionally confined, charged 180
degree domain walls, at most a few unit cells long, alternating between head to
head and tail to tail configurations. Head to head and tail to tail walls each
adopt completely distinctive interfacial structures and confine the in-plane
domains to a sub nm2 footprint, making them one of the smallest domains to be
reported in any polar material. This work represents the first experimental
observation of antipolar ferroic ordering via strongly charged domain walls,
while being nested within the self organized polar nonpolar layering, revealing
a novel hierarchical self-organization of polar textures at the atomic scale,
and opening new pathways to atomically dense memories and domain wall
nanoelectronics in silicon compatible, simple binary oxides.

</details>


### [315] [Stoichiometric and Non-stoichiometric Cesium Potassium Antimonide Photocathodes: Ab-initio Insights into its Properties for Photoemission](https://arxiv.org/abs/2507.18933)
*Sandip Aryal,Gaoxue Wang,Enrique R. Batista*

Main category: cond-mat.mtrl-sci

TL;DR: The paper analyzes CsK2Sb, a promising photocathode material, using first-principles methods. It confirms its visible light absorption and low work function, while identifying Cs and K vacancies as defects that could influence performance. This work aids in optimizing CsK2Sb for high-efficiency photocathodes.


<details>
  <summary>Details</summary>
Motivation: Alkali-metal antimonides, especially CsK2Sb, are strong candidates for next-generation photocathodes in linear accelerators due to their low work-function, fast response, high quantum yield, and ability to operate under visible light.

Method: First-principles methods were used to examine the structural, electronic, optical, and surface properties of CsK2Sb.

Result: The study found that CsK2Sb exhibits strong absorption in the visible range, low work functions for its stable surfaces, electron mobility of 111.86 cm2/Vs, and hole mobility of 3.24 cm2/Vs. Cs and K vacancies were identified as the most likely native point defects, which introduce mid-gap states, alter the absorption spectrum, and potentially impact photoemission.

Conclusion: Alkali-metal antimonides, especially CsK2Sb, are promising photocathode materials due to their low work function, fast response, high quantum yield, and visible light operation. This study uses first-principles methods to analyze CsK2Sb's structural, electronic, optical, and surface properties. The results show strong visible absorption, low work functions for stable surfaces, and specific electron and hole mobilities. Analysis of native point defects identifies Cs and K vacancies as likely, introducing mid-gap states and affecting photoemission. This research offers insights for optimizing CsK2Sb in photocathode applications.

Abstract: Alkali-metal antimonides, especially cesium-potassium-antimonide (CsK2Sb),
are strong candidates for next-generation photocathodes in linear accelerators
due to their low work-function, fast response, high quantum yield, and ability
to operate under visible light. In this study, first-principles methods are
used to examine the structural, electronic, optical, and surface properties of
CsK2Sb relevant to its photoemission performance. Our results for CsK2Sb show
strong absorption in the visible range consistent with experimental
observations. The computed work-functions for the stable surfaces are
significantly lower than the commonly used metallic photocathodes. This
material exhibits electron and hole mobilities of 111.86 cm2/Vs and 3.24
cm2/Vs, respectively. Since real materials inherently contain intrinsic
defects, we analyze native point defects in CsK2Sb and identified Cs and K
vacancies as most likely. These defects introduce mid-gap states, modify the
absorption spectrum, and may significantly influence photoemission behavior.
This work provides valuable insights into optimizing CsK2Sb for high-efficiency
photocathode applications.

</details>


### [316] [Accuracy and Limitations of Machine-Learned Interatomic Potentials for Magnetic Systems: A Case Study on Fe-Cr-C](https://arxiv.org/abs/2507.18935)
*E. O. Khazieva,N. M. Chtchelkatchev,R. E. Ryltsev*

Main category: cond-mat.mtrl-sci

TL;DR: 通过对比不同训练数据的MLIP模型，发现非磁性模型擅长模拟动态性质，而自旋极化模型擅长模拟静态性质。利用迁移学习可大幅降低开发成本，并强调了在DFT计算和经典力场中正确处理自旋涨落的重要性。


<details>
  <summary>Details</summary>
Motivation: 机器学习互原子势（MLIP）在原子模拟中已成为黄金标准，但在磁性材料领域的应用仍具挑战性，因为必须显式或隐式地捕捉自旋涨落。该研究旨在解决这一问题，特别关注具有重要工业应用价值的Fe-Cr-C系统，以期开发更准确、更通用的MLIP。

Method: 该研究构建了两种基于DeePMD的深度机器学习势能模型：一种使用非磁性DFT数据训练（DP-NM），另一种使用自旋极化DFT数据训练（DP-M）。通过与实验数据进行广泛验证，对比分析了两种模型在模拟动态和静态性质上的表现。此外，研究提出并验证了一种迁移学习协议，即先在非磁性DFT数据上进行预训练，再在少量自旋极化数据上进行微调，以降低开发磁性MLIP的计算成本。

Result: DP-NM在模拟动态性质（如粘度和熔点）方面表现准确，而DP-M则估计错误。DP-M在模拟静态性质（如密度和晶格参数）方面表现优异，尤其是在富Fe合金中，而DP-NM则表现不佳。这一结果与顺磁态下高温时磁矩的自平均效应相符。迁移学习协议将开发磁性MLIP的计算成本降低了一个数量级以上。

Conclusion: 该研究为机器学习互原子势（MLIP）在磁性材料中的应用提供了新思路，特别是针对Fe-Cr-C系统。通过对比仅使用非磁性数据训练（DP-NM）和使用自旋极化数据训练（DP-M）的势能模型，研究发现DP-NM在模拟动态性质（如粘度和熔点）方面表现优异，而DP-M在模拟静态性质（如密度和晶格参数）方面更准确。这归因于顺磁态下高温时磁矩的自平均效应。研究还提出了一种迁移学习协议，通过预先在非磁性数据上训练，再用少量自旋极化数据进行微调，可将开发磁性MLIP的计算成本降低一个数量级以上。为了开发能涵盖整个成分空间静态和动态行为的通用势能，需要在DFT计算中正确考虑温度诱导的自旋涨落，并将自旋自由度正确地纳入经典力场。

Abstract: Machine-learned interatomic potentials (MLIPs) have become the gold standard
for atomistic simulations, yet their extension to magnetic materials remains
challenging because spin fluctuations must be captured either explicitly or
implicitly. We address this problem for the technologically vital Fe-Cr-C
system by constructing two deep machine learning potentials in DeePMD
realization: one trained on non-magnetic DFT data (DP-NM) and one on
spin-polarised DFT data (DP-M). Extensive validation against experiments
reveals a striking dichotomy. The dynamic, collective properties, viscosity and
melting temperatures are reproduced accurately by DP-NM but are incorrectly
estimated by DP-M. Static, local properties, density, and lattice parameters
are captured excellently by DP-M, especially in Fe-rich alloys, whereas DP-NM
fails. This behaviour is explained by general properties of paramagnetic state:
at high temperature, local magnetic moments self-average in space and time, so
their explicit treatment is unnecessary for transport properties but essential
for equilibrium volumes. Exploiting this insight, we show that a
transfer-learning protocol, pre-training on non-magnetic DFT and fine-tuning on
a small set of spin-polarised data, reduces the computational cost to develop
magnetic MLIPs by more than an order of magnitude. Developing general-purpose
potentials that capture static and dynamic behaviors throughout the whole
composition space requires proper accounting for temperature-induced spin
fluctuations in DFT calculations and correctly incorporating spin degrees of
freedom into classical force fields.

</details>


### [317] [All-Dry Transfer of Graphene Film by Van der Waals Interactions](https://arxiv.org/abs/2507.18965)
*Seong-Jun Yang,Shinyoung Choi,Francis Okello Odongo Ngome,Ki-Jeong Kim,Si-Young Choi,Cheol-Joo Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 利用范德华相互作用和氮化硼载体，成功将高质量石墨烯从Ge(110)转移到新衬底，实现了低粘附能和高转移质量。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统石墨烯转移方法的限制，寻找一种新的、高效的转移方法。

Method: 通过范德华相互作用，在清洁、干燥的环境中，使用氮化硼载体将连续、高质量的石墨烯薄膜从Ge(110)转移到另一个衬底上。

Result: 成功将石墨烯薄膜转移到目标衬底上，薄膜均匀连续，缺陷密度低，电荷杂质少。石墨烯/Ge(110)的衬底粘附能低于典型的层状材料间的范德华相互作用。

Conclusion: 这项研究提出了利用范德华相互作用将高质量石墨烯薄膜从Ge(110)转移到氮化硼载体上的新方法，实现了低缺陷密度和少量电荷 the transferred films are uniform and continuous with low defect density and few charge puddles.The transfer is effective because of the weak interfacial adhesion energy between graphene and Ge.Based on the minimum strain energy required for the isolation of film, the upper limit of the interfacial adhesion energy is estimated to be 23 meV per carbon atom, which makes graphene/Ge(110) the first as-grown graphene film that has an substrate adhesion energy lower than typical van der Waals interactions between layered materials.Our results suggest that graphene on Ge can serve as an ideal material platform to be integrated with other material systems by a clean assembly process. 转移

Abstract: We report a method that uses van der Waals interactions to transfer
continuous, high-quality graphene films from Ge(110) to a different substrate
held by hexagonal boron nitride carriers in a clean, dry environment. The
transferred films are uniform and continuous with low defect density and few
charge puddles. The transfer is effective because of the weak interfacial
adhesion energy between graphene and Ge. Based on the minimum strain energy
required for the isolation of film, the upper limit of the interfacial adhesion
energy is estimated to be 23 meV per carbon atom, which makes graphene/Ge(110)
the first as-grown graphene film that has an substrate adhesion energy lower
than typical van der Waals interactions between layered materials. Our results
suggest that graphene on Ge can serve as an ideal material platform to be
integrated with other material systems by a clean assembly process.

</details>


### [318] [Step-directed Epitaxy of Uni-directional Hexagonal Boron Nitride on Vicinal Ge(110)](https://arxiv.org/abs/2507.18985)
*Ju-Hyun Jung,Chao Zhao,Seong-Jun Yang,Jun-Ho Park,Woo-Ju Lee,Su-Beom Song,Jonghwan Kim,Chan-Cuk Hwang,Seung-Hwa Baek,Feng Ding,Cheol-Joo Kim*

Main category: cond-mat.mtrl-sci

TL;DR: 通过在Ge衬底上进行外延生长和原子级组装，实现了高质量单晶hBN薄膜的制备，并成功应用于提升石墨烯和MoS$_{2}$器件的性能。


<details>
  <summary>Details</summary>
Motivation: 为了在电子器件中实现对各种界面的精确调控，需要能够形成与多种材料原子级完美结合的、具有精确厚度和原子构型的高质量六方氮化硼（hBN）薄膜。然而，以往报道的大面积hBN薄膜要么是多晶的，要么不适合通过机械剥离进行原子级清洁组装，这限制了它们在器件技术中的应用。

Method: 利用化学气相沉积（CVD）技术在大面积锗（Ge(110)）衬底上外延生长单层单晶六方氮化硼（hBN）薄膜。通过使用具有台阶取向的Ge衬底，使Ge的原子台阶作为hBN的成核位点，引导hBN域的单向排列。利用密度泛函理论（DFT）计算优化了hBN边缘和Ge表面的氢钝化，实现了hBN与Ge台阶边缘的外延耦合，从而获得单晶hBN薄膜。最后，通过逐层组装工艺，利用外延生长的单层hBN薄膜制备了具有精确堆叠顺序和完美界面的器件，并验证了其作为高质量电介质在增强石墨烯和MoS$_{2}$沟道载流子传输方面的性能。

Result: 成功实现了大面积单层单晶hBN薄膜在Ge(110)衬底上的外延生长，并通过逐层组装技术制备了具有精确堆叠顺序和完美界面的hBN薄膜器件。这些薄膜作为高质量的电介质，显著增强了石墨烯和MoS$_{2}$沟道中的载流子传输。

Conclusion: 研究表明，通过在 Ge(110) 衬底上利用化学气相沉积（CVD）技术，可以实现大面积单层单晶六方氮化硼（hBN）薄膜的外延生长，并实现了hBN与Ge衬底的原子级精确耦合，解决了以往多晶或不适合原子级组装的hBN薄膜在电子器件中的应用局限性。

Abstract: Insulating hexagonal boron nitride (hBN) films with precisely controlled
thickness are ideal dielectric components to modulate various interfaces in
electronic devices. To achieve this, high-quality hBN with controlled atomic
configurations must be able to form pristine interfaces with various materials
in devices. However, previously reported large-scale hBN films with uniform
thickness either are polycrystalline or are not suitable for atomically clean
assembly via mechanical exfoliation, limiting their applications in device
technology. Here, we report the large-scale growth of monolayer single
crystalline hBN films on Ge(110) substrates by using chemical vapor deposition
(CVD). Vicinal Ge(110) substrates are used for the step-directed epitaxial
growth of hBN, where Ge atomic steps act as the hBN nucleation sites, guiding
the uni-directional alignments of multiple hBN domains. Density functional
theory (DFT) calculations reveal that the optimum hydrogen passivations on both
hBN edges and Ge surfaces enable the epitaxial coupling between hBN and the Ge
step edges and the single crystallinity of the final hBN films. Using
epitaxially grown monolayer hBN films, we fabricate a few hBN films with
controlled stacking orders and pristine interfaces through a layer-by-layer
assembly process. These films function as high-quality dielectrics to enhance
carrier transport in graphene and MoS<sub>2</sub> channels.

</details>


### [319] [Magnetoelectric coupling and its impact on the multicaloric effect](https://arxiv.org/abs/2507.19126)
*Kentaro Ino,Keisuke Matsuura,Tetsuya Nomoto,Takashi Kurumaji,Yoshinori Tokura,Fumitaka Kagawa*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现，在多铁材料(Fe$_{0.95}$Zn$_{0.05}$)$_2$Mo$_3$O$_8$中，磁电交叉相关性在磁性序化温度下引起了显著的等温熵变，且这种效应在磁相变中可能比线性磁电效应更强。


<details>
  <summary>Details</summary>
Motivation: 研究多铁材料(Fe$_{0.95}$Zn$_{0.05}$)$_2$Mo$_3$O$_8$中的多热效应，重点关注其磁电交叉相关性。

Method: 通过实验评估磁电交叉相关性引起的等温熵变。

Result: 在磁性序化温度下，观察到了由磁电交叉相关性引起的显著等温熵变。通过文献对比，提出磁相变可能比线性磁电效应产生更大的磁电交叉相关性熵变。

Conclusion: (Fe$_{0.95}$Zn$_{0.05}$)$_2$Mo$_3$O$_8$的磁电交叉相关性在磁性序化温度下表现出显著的等温熵变，且磁相变可能比线性磁电效应产生更大的磁电交叉相关性熵变。

Abstract: The multicaloric effect, which represents the reversible entropy change that
occurs when both external magnetic and electric fields are applied, is an
interesting phenomenon characteristic to multiferroics. Targeting the
multicaloric effect in the typical multiferroic
(Fe$_{0.95}$Zn$_{0.05}$)$_2$Mo$_3$O$_8$, we experimentally evaluate the
isothermal entropy change due to a magnetoelectric cross-correlation. A
pronounced cross-correlation-derived isothermal entropy change is found at the
magnetic ordering temperature. By exploring the literature, we suggest that a
magnetic phase transition may tend to involve a considerably larger
cross-correlation-derived entropy change than that derived from the linear
magnetoelectric effect.

</details>


### [320] [Machine Learning Band Gap Predictions: Linking Quasiparticle Self-Consistent GW and LDA-Derived Partial Density of States](https://arxiv.org/abs/2507.19189)
*Shota Tankano,Takao Kotani,Masao Obata,Kazunori Sato,Harutaka Saito,Tatsuki Oda*

Main category: cond-mat.mtrl-sci

TL;DR: QSGW和机器学习结合，可根据PDOS预测带隙，效果优于线性回归。


<details>
  <summary>Details</summary>
Motivation: 解决DFT-LDA计算带隙不准确的问题，以及QSGW计算资源需求大的问题。

Method: 将QSGW应用于1516种材料，并使用机器学习根据LDA中的PDOS预测QSGW带隙。

Result: 所提出的模型显著优于线性回归方法。

Conclusion: 提出了一种结合QSGW和机器学习的方法，用于根据PDOS预测QSGW带隙，显著优于线性回归方法。

Abstract: Accurately calculating band gaps for given crystal structures is highly
desirable. However, conventional first-principles calculations based on density
functional theory (DFT) within the local density approximation (LDA) fail to
predict band gaps accurately. To address this issue, the quasi-particle
self-consistent GW (QSGW) method is often employed as it is one of the most
reliable theoretical approaches for predicting band gaps. Despite its accuracy,
QSGW requires significant computational resources. To overcome this limitation,
we propose combining QSGW with machine learning. In this study, we applied QSGW
to 1,516 materials from the Materials Project [https://materialsproject.org/]
and used machine learning to predict QSGW band gaps as a function of the
partial density of states (PDOS) in LDA. Our results demonstrate that the
proposed model significantly outperforms linear regression approaches with
linearly-independent descriptor generation
[https://github.com/Hitoshi-FUJII/LIDG]. This model is a prototype for
predicting material properties based on PDOS.

</details>


### [321] [Stability and Symmetry-Assured Crystal Structure Generation for Inverse Design of Photocatalysts in Water Splitting](https://arxiv.org/abs/2507.19307)
*Zhilong Song,Chongyi Ling,Qiang Li,Qionghua Zhou,Jinlan Wang*

Main category: cond-mat.mtrl-sci

TL;DR: SSAGEN 是一个用于材料逆向设计的生成框架，通过分离晶体信息生成和坐标优化，能够精确控制成分、空间群和晶格，并显著提高结构的稳定性和对称性。在光催化水分解应用中，SSAGEN 成功生成了大量满足要求的新颖材料，并识别出具有潜力的候选材料。


<details>
  <summary>Details</summary>
Motivation: 现有的生成模型在确保固有稳定性、对称性以及精确生成具有目标成分、空间群和晶格但无需微调的结构方面存在不足。

Method: SSAGEN 框架将结构生成分为两个阶段：晶体信息（晶格、成分、空间群）生成和坐标优化。首先生成多样化且物理上合理的晶体信息，然后通过通用的机器学习势、结合全局和局部优化以及对称性和 Wyckoff 坐标约束，并动态细化搜索空间，来推导出稳定和亚稳态的原子位置。

Result: 与之前的生成模型（如 CDVAE）相比，SSAGEN 在生成结构的や热力学和动力学稳定性方面分别提高了 148% 和 180%，同时固有地满足了目标成分、空间群和晶格。在光催化水分解 (PWS) 应用中，SSAGEN 生成了 200,000 个结构（其中 81.2% 是新颖的），有 3,318 个满足所有稳定性和带隙标准。通过基于电子结构、热力学、动力学和水稳定性标准的综合筛选，DFT 验证证实 95.6% 的结构满足 PWS 要求，并确定了 24 个最优候选结构。

Conclusion: SSAGEN 框架能够精确生成具有所需晶体信息（晶格、成分、空间群）的材料，并确保内在的稳定性和对称性，为功能材料的靶向逆向设计树立了新范例。

Abstract: Generative models are revolutionizing materials discovery by enabling inverse
design-direct generation of structures from desired properties. However,
existing approaches often struggle to ensure inherent stability and symmetry
while precisely generating structures with target compositions, space groups,
and lattices without fine-tuning. Here, we present SSAGEN (Stability and
Symmetry-Assured GENerative framework), which overcomes these limitations by
decoupling structure generation into two distinct stages: crystal information
(lattice, composition, and space group) generation and coordinate optimization.
SSAGEN first generates diverse yet physically plausible crystal information,
then derives stable and metastable atomic positions through universal machine
learning potentials, combined global and local optimization with symmetry and
Wyckoff position constraints, and dynamically refined search spaces. Compared
to prior generative models such as CDVAE, SSAGEN improves the thermodynamic and
kinetic stability of generated structures by 148% and 180%, respectively, while
inherently satisfying target compositions, space groups, and lattices. Applied
to photocatalytic water splitting (PWS), SSAGEN generates 200,000
structures-81.2% novel-with 3,318 meeting all stability and band gap criteria.
Density functional theory (DFT) validation confirms 95.6% structures satisfy
PWS requirements, with 24 optimal candidates identified through comprehensive
screening based on electronic structure, thermodynamic, kinetic, and aqueous
stability criteria. SSAGEN not only precisely generates materials with desired
crystal information but also ensures inherent stability and symmetry,
establishing a new paradigm for targeted inverse design of functional
materials.

</details>


### [322] [Atomically clean free-standing two-dimensional materials through heating in ultra-high vacuum](https://arxiv.org/abs/2507.19371)
*Philipp Irschik,David Lamprecht,Shrirang Chokappa,Clemens Mangler,Carsten Speckmann,Thuy An Bui,Manuel Längle,Lado Filipovic,Jani Kotakoski*

Main category: cond-mat.mtrl-sci

TL;DR: 该研究通过在超高真空下对二维材料进行退火处理，并结合扫描透射电子显微镜进行表征，发现400°C是实现大面积原子级清洁的关键温度，这为后续的纳米工程和器件加工提供了高质量的基础。


<details>
  <summary>Details</summary>
Motivation: 现有的光谱清洁度评估方法在确定二维材料清洁度方面存在模糊性，而表面污染物会显著影响其测量的性质。因此，需要一种更精确的方法来评估和实现二维材料的清洁度。

Method: 通过在自定义超高真空加热室中以不同温度退火自由形态的单层石墨烯和六方氮化硼，并利用扫描透射电子显微镜进行原子级分辨率的清洁度表征，同时通过真空传输线消除空气污染物在样品传输过程中引入。

Result: 在200°C退火可显著减少污染物，但在400°C或更高温度下，90%以上的区域才达到原子级清洁。进一步的清洁度提升受限于材料缺陷以及样品转移或生长过程中引入的金属污染物。

Conclusion: 在400°C或更高的温度下，超过90%的无支撑单层石墨烯和六方氮化硼可以实现原子级清洁。此外，该方法能够实现大面积原子级清洁的区域，用于进一步的纳米工程或器件加工。

Abstract: Surface contamination not only influences but in some cases even dominates
the measured properties of two-dimensional materials. Although different
cleaning methods are often used for contamination removal, commonly used
spectroscopic cleanliness assessment methods can leave the level of achieved
cleanliness ambiguous. Despite two decades of research on 2D materials, the
true cleanliness of the used samples is often left open to interpretation. In
this work, free-standing monolayer graphene and hexagonal boron nitride are
annealed at different temperatures in a custom-built ultra-high vacuum heating
chamber, connected to a scanning transmission electron microscope via a vacuum
transfer line, enabling atomically resolved cleanliness characterization as a
function of annealing temperature, while eliminating the introduction of
airborne contamination during sample transport. While annealing at 200 {\deg}C
already reduces contamination significantly, it is not until 400 {\deg}C or
higher, where over 90% of the free-standing monolayer areas are atomically
clean. At this point, further contamination removal is mainly limited by
defects in the material and metal contamination introduced during the sample
transfer or growth. The achieved large, atomically clean areas can then be used
for further nanoscale engineering steps or device processing, facilitating
interaction with the material rather than contamination.

</details>


### [323] [Solute Segregation Activates Unconventional Grain Boundary Disconnections](https://arxiv.org/abs/2507.19429)
*Zuoyong Zhang,Chuang Deng*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现溶质偏析可形成零激活能垒的断裂连接，改变了对合金中晶界动量的理解。


<details>
  <summary>Details</summary>
Motivation: 探究在多晶材料中，作为晶界动量关键介质的断裂连接的传统热或力激活机制之外，是否存在新的形成机制。

Method: 利用跨多种二元合金（如Al-Ni、Al-Fe）的原子模拟，结合双色图分析，揭示了断裂连接的形成机制和特性。

Result: 发现了仅由间隙溶质偏析激活的断裂连接形成机制，其具有零形核能垒。此外，还识别出两种断裂连接：可湮灭断裂连接（促进晶界迁移）和永久断裂连接（导致晶界非晶化和滑动），并观察到永久断裂连接会产生局部应力场，驱动溶质积累并可能导致沉淀。

Conclusion: 该研究揭示了仅由间隙溶质偏析激活的独特断裂连接形成机制，这与传统的断裂连接形核形成鲜明对比，并提出了两种新型断裂连接：可湮灭断裂连接和永久断裂连接，分别促进晶界迁移和导致晶界非晶化和滑动。

Abstract: Disconnections, now recognized as key mediators of grain boundary (GB)
kinetics in polycrystals, have traditionally been associated with thermal or
mechanical activation. Here, using atomistic simulations across multiple binary
alloys (Al-Ni, Al-Fe, etc.), we reveal a distinct disconnection formation
mechanism solely activated by interstitial solute segregation. This process
exhibits a zero-nucleation energy barrier, contrasting sharply with
conventional disconnection nucleation. We identify two segregation-induced
disconnection types: (i) annihilable disconnections that promote GB migration
and annihilate with continued segregation, and (ii) permanent disconnections
with stable dipoles that resist shear, inducing GB amorphization and sliding
rather than conventional shear-coupled motion. The permanent disconnections
generate localized stress fields that further drive solute accumulation and, at
higher concentrations, facilitate precipitation. These disconnections,
unprecedented in pure systems, follow unique nucleation pathways as confirmed
by dichromatic pattern analysis and persist across diverse crystal structures.
This work establishes solute segregation as a route for barrier-free
disconnection formation, fundamentally altering our understanding of GB
kinetics in alloys.

</details>


### [324] [Equivariant machine learning of Electric Field Gradients -- Predicting the quadrupolar coupling constant in the MAPbI$_3$ phase transition](https://arxiv.org/abs/2507.19435)
*Bernhard Schmiedmayer,J. W. Wolffs,Gilles A. de Wijs,Arno P. M. Kentgens,Jonathan Lahnsteiner,Georg Kresse*

Main category: cond-mat.mtrl-sci

TL;DR: 结合机器学习和第一性原理计算，高精度预测核四极耦合常数，并成功预测了MAPbI$_3$的相变温度。


<details>
  <summary>Details</summary>
Motivation: 为了实现高精度的核四极耦合常数预测，特别是在高度无序材料和有限温度条件下。

Method: 研究方法结合了两种不同的机器学习框架：一个机器学习力场用于生成分子动力学轨迹，以及一个保持旋转和平移对称性的电场梯度模型。通过引入温控分子动力学采样，该方法能够预测高温下高度无序材料的四极耦合常数。

Result: 通过预测有机-无机钙钛矿MAPbI$_3$的四方到立方相变温度，验证了该方法，预测结果与实验数据高度吻合。

Conclusion: 本研究提出了一种结合机器学习和第一性原理计算的策略，能够高精度地预测核四极耦合常数。

Abstract: We present a strategy combining machine learning and first-principles
calculations to achieve highly accurate nuclear quadrupolar coupling constant
predictions. Our approach employs two distinct machine-learning frameworks: a
machine-learned force field to generate molecular dynamics trajectories and a
second model for electric field gradients that preserves rotational and
translational symmetries. By incorporating thermostat-driven molecular dynamics
sampling, we enable the prediction of quadrupolar coupling constants in highly
disordered materials at finite temperatures. We validate our method by
predicting the tetragonal-to-cubic phase transition temperature of the
organic-inorganic halide perovskite MAPbI$_3$, obtaining results that closely
match experimental data.

</details>


### [325] [Gradient-based grand canonical optimization enabled by graph neural networks with fractional atomic existence](https://arxiv.org/abs/2507.19438)
*Mads-Peter Verner Christiansen,Bjørk Hammer*

Main category: cond-mat.mtrl-sci

TL;DR: New method uses fractional atomic existence in ML potentials to optimize structures via gradients, tested on Cu(110) oxide.


<details>
  <summary>Details</summary>
Motivation: To enhance machine learning interatomic potentials by incorporating a continuous variable for fractional atomic existence, thereby enabling the calculation of Gibbs free energy gradients with respect to atomic coordinates and existence for more advanced materials science studies.

Method: Extending the message passing formalism with a continuous variable for fractional atomic existence, enabling the calculation of the Gibbs free energy gradient with respect to atomic coordinates and existence, leading to a gradient-based grand canonical optimization method.

Result: Demonstrated the capabilities of the gradient-based grand canonical optimization method on a Cu(110) surface oxide.

Conclusion: The proposed gradient-based grand canonical optimization method, incorporating a continuous variable for fractional atomic existence within a message-passing graph neural network framework, shows capabilities in studying surface oxide systems like Cu(110).

Abstract: Machine learning interatomic potentials have become an indispensable tool for
materials science, enabling the study of larger systems and longer timescales.
State-of-the-art models are generally graph neural networks that employ message
passing to iteratively update atomic embeddings that are ultimately used for
predicting properties. In this work we extend the message passing formalism
with the inclusion of a continuous variable that accounts for fractional atomic
existence. This allows us to calculate the gradient of the Gibbs free energy
with respect to both the Cartesian coordinates of atoms and their existence.
Using this we propose a gradient-based grand canonical optimization method and
document its capabilities for a Cu(110) surface oxide.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [326] [Spinwave Bandpass Filters for 6G Communication](https://arxiv.org/abs/2507.18931)
*Connor Devitt,Sudhanshu Tiwari,Bill Zivasatienraj,Sunil A. Bhave*

Main category: physics.app-ph

TL;DR: 通过微加工技术制造的自旋波滤波器，带宽更宽，尺寸更小，干扰更少，可用于5G和6G通信。


<details>
  <summary>Details</summary>
Motivation: 现有的自旋波滤波器带宽不足、尺寸过大或存在强的杂散通带，无法满足未来5G和6G通信系统的需求。

Method: 利用现代微加工制造方法，报告了一种自旋波梯滤波器架构。

Result: 滤波器损耗低至2.54 dB，带宽高达663 MHz，中心频率可在5.7-21.6 GHz的多个倍频程内调谐，并且在通带内具有高于11 dBm的输入参考三阶交调点，表现出高线性度。此外，还在频率可调的无线电系统中实验演示了滤波器的运行。

Conclusion: 利用单晶钇铁石榴石的自旋波滤波器是集成到频率可调或可调通信系统中的一种有吸引力的技术。然而，现有的自旋波滤波器带宽不足，尺寸过大，或存在强的杂散通带，造成了非预期的通道间干扰。利用能够晶圆级生产的现代微加工制造方法，我们报告了一种只需要单个外部磁偏置的自旋波梯滤波器架构。

Abstract: Spinwave filters using single-crystal yttrium iron garnet are an attractive
technology for integration in frequency adjustable or tunable communication
systems. However, existing SW devices do not have sufficient bandwidth for
future 5G and 6G communication systems, are too large, or have strong spurious
passbands creating unintentional cross-channel interference. Leveraging modern
micromachining fabrication methods capable of wafer-scale production, we report
a SW ladder filter architecture requiring only a single external magnetic bias.
The filters demonstrate loss as low as 2.54 dB, bandwidths up to 663 MHz,
center frequency tuning over multiple octaves from 5.7-21.6 GHz, and high
linearity with an input referred third-order intercept point over 11 dBm in the
passband. The filter's operation is also experimentally demonstrated in a
frequency tunable radio system.

</details>


### [327] [Waveguide-Coupled Mid-Infrared GeSn Membrane Photodetectors on Silicon-on-Insulator](https://arxiv.org/abs/2507.19269)
*Cédric Lemieux-Leduc,Mahmoud R. M. Atalla,Simone Assali,Nicolas Rotaru,Julien Brodeur,Stéphane Kéna-Cohen,Oussama Moutanabbir,Yves-Alain Peter*

Main category: physics.app-ph

TL;DR: 研究人员使用转移印刷技术将GeSn薄膜集成到硅光子波导上，在中红外范围内（高达3.1μm）实现了高效的探测器，证明了该技术的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了将硅光子技术扩展到中红外范围，以抓住传感、成像和自由空间通信领域的机遇，重点研究了硅兼容的GeSn合金在中红外器件集成方面的潜力。

Method: 利用转移印刷技术将应变弛豫的GeSn薄膜集成到硅光子平台上的硅绝缘体波导上，并评估了两种不同的波导结构设计对耦合效率的影响。

Result: 实现了在中红外范围内（高达3.1μm）工作的集成探测器，在2.33μm波长和1V偏压下，测得的响应度达到0.36 A/W，并成功进行了可扩展的器件制造。

Conclusion: 通过单次转移印刷步骤，成功地将应变弛豫的GeSn薄膜集成到硅光子平台上，并实现了在室温下高达3.1μm的探测器工作，证明了该方法的可扩展性，为中红外光电器件的应用提供了基础。

Abstract: Silicon photonics has thrived in telecommunications over recent decades, and
its extension to the mid-infrared range has the potential to unlock valuable
opportunities for sensing, imaging, and free-space communications. With this
perspective, germanium-tin (GeSn) alloy has been extensively investigated as a
silicon-compatible semiconductor with bandgap tunability that covers this
entire spectral range. Indeed, a variety of GeSn-based high-performance
optoelectronic devices have been demonstrated, confirming the potential of this
system for mid-infrared applications. However, the integration of these devices
onto silicon photonic platforms remains underexplored. Herein, we demonstrate
the fabrication and integration, through transfer-printing, of strain-relaxed
GeSn membranes onto silicon-on-insulator waveguides to create integrated
detectors operating up to 3.1 $\mu$m at room temperature. Two different designs
of waveguide structures are evaluated to study the coupling efficiency between
the passive structures and the active membrane detector. A responsivity
reaching 0.36 A/W at an operation wavelength of 2.33 $\mu$m is measured under a
bias of 1 V. Moreover, the fabrication resulted in multiple working devices
exhibiting similar performance using a single transfer printing step,
demonstrating the scalability of the proposed approach.

</details>


### [328] [Leaky-wave Coil Element with Improved Tx-efficiency for 7 T MRI Using a Non-Uniform Current Design](https://arxiv.org/abs/2507.19286)
*K. Popova,R. Balafenidev,J. T. Svejda,A. Rennings,A. J. Raaijmakers,C. M. Collins,R. Lattanzi,S. Glybovski,D. Erni,G. Solomakha*

Main category: physics.app-ph

TL;DR: 高场磁共振成像的射频线圈挑战在于射频场不均匀性。本研究提出了一种非谐振泄漏波方法，通过控制电流相位来增强目标区域的 B1+ 场，并开发了一种优化的射频线圈，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 高场磁共振成像（7T以上）由于人体组织的射频场不均匀性而具有挑战性，但可以使用天线阵列和并行传输来缓解。然而，为了达到最佳的固有信噪比或最大化目标区域的信号，需要不均匀的表面电流相位。

Method: 提出使用先前演示的非谐振泄漏波方法来控制射频线圈导体中电流的相位，以增加目标区域中心的 B1+ 场。

Result: 开发了一种基于泄漏波天线方法的射频线圈，与分数偶极子等相比，在目标区域产生了更强的 B1+ 场。

Conclusion: 提出了一种基于泄漏波天线方法的射频线圈，优化了表面电流分布，与分数偶极子等相比，在目标区域产生了更强的 B1+ 场。

Abstract: Imaging of the human body at ultra-high fields (static magnetic field B0>7
Tesla) is challenging due to the radio-frequency field inhomogeneities in the
human body tissues caused by the short wavelength. These effects could be
partially mitigated using an array of antennas and by parallel transmission
allowing for control of the radio-frequency field distribution in the region of
interest. All commonly-used radio-frequency arrays for ultra-high field MRI
consist of resonant elements: dipoles, TEM-resonators, loops and individual
slots. All these elements rely on standing wave excitation, in the sense that
they are resonant devices that produce a field pattern with a constant phase
distribution along the commensurable conductor elements. However, it was shown
previously, that a non-uniform phase of surface current is required to reach
the ultimate intrinsic signal-to-noise ratio or a maximized signal in the
desired region of interest. In our work we propose to use a previously
demonstrated non-resonant leaky-wave approach to control the phase of currents
in radio-frequency coil conductors to increase the B1+ field in the center or
in the region of interest. Using this approach, we developed a radio-frequency
coil based on a leaky-wave antenna approach with optimized surface current
distribution resulting in stronger B1+ in the desired region compared to e.g. a
fractionated dipole.

</details>


### [329] [Efficient integration of self-assembled organic monolayer tunnel barriers in large area pinhole-free magnetic tunnel junctions](https://arxiv.org/abs/2507.19330)
*Maryam S. Dehaghani,Sophie Guézo Aguinet,Arnaud Le Pottier,Soraya Ababou-Girard,Rozenn Bernard,Sylvain Tricot,Philippe Schieffer,Bruno Lépine,Francine Solal,Pascal Turban*

Main category: physics.app-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Magneto-transport properties in hybrid magnetic tunnel junctions (MTJs)
integrating self-assembled monolayers (SAMs) as tunnel barriers are critically
influenced by spinterface effects, which arise from the electronic properties
at ferromagnet (FM)/SAM interfaces. Understanding the mechanisms governing
spinterface formation in well-controlled model systems is essential for the
rational design of efficient molecular spintronic devices. However, the
fabrication of FM/SAM/FM systems remains a significant challenge due to the
difficulty in preventing electrical shorts through the SAM tunnel barrier
during top FM electrode deposition. In this study, we address these challenges
by developing model hybrid MTJs incorporating alkanethiol SAM tunnel barriers
grafted under ultra-high vacuum conditions onto single-crystalline Fe(001)
bottom electrodes. A soft-landing deposition method is used for the deposition
of a top Co FM electrode. The deposition process and the electronic properties
of the FM/SAM interfaces are first studied by spatially integrated X-ray
photoelectron spectroscopy. Furthermore, ballistic electron emission microscopy
(BEEM) and spectroscopy are used to investigate the lateral homogeneity of the
organic barrier. Optimal soft-landing deposition conditions allows the
preparation of homogeneous Co/SAM interfaces with no evidence of metal
diffusion through the SAM at the nanoscale. These observations are further
confirmed at the micron-scale by the high-yield patterning of large area
(5*5um2) MTJs presenting fingerprints of electron tunneling through the SAM.
These findings provide critical insights into the fabrication and optimization
of molecular spintronic devices, paving the way for advancements in hybrid MTJ
technology.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [330] [A Distributed Approach for Agile Supply Chain Decision-Making Based on Network Attributes](https://arxiv.org/abs/2507.19038)
*Mingjie Bi,Dawn M. Tilbury,Siqian Shen,Kira Barton*

Main category: cs.MA

TL;DR: 该研究通过案例研究，比较了集中式和分布式决策方法在应对供应链中断时的表现，并根据网络属性和代理能力提出了设计响应策略的建议。


<details>
  <summary>Details</summary>
Motivation: 鉴于近年来全球供应链中断频繁，企业需要实施高效的决策策略来保持敏捷性。虽然现有研究分析了集中式和分布式决策方法的优缺点，但尚未有研究关注理解供应链网络属性对中断后供应链绩效的影响。

Method: 该研究采用案例研究的方法，从能力和网络拓扑的角度对供应链进行特征化，并研究了基于经典多主体框架的分布式决策方法的应用。通过将分布式框架与集中式决策方法进行比较，评估了分布式框架的性能。

Result: 分布式决策框架在案例研究中得到了评估，考察了在中断情况下，供应链的性能如何作为网络结构和网络内代理属性的函数。与集中式决策方法相比，研究结果突显了基于决策策略和网络架构的性能、计算时间和网络通信之间的权衡。

Conclusion: 该研究通过案例研究，从能力和网络拓扑的角度对供应链进行了特征化，并研究了基于经典多主体框架的分布式决策方法。通过将分布式框架与集中式决策方法进行比较，突显了基于决策策略和网络架构的性能、计算时间和网络通信之间的权衡。该研究结果可供从业者根据代理能力、网络属性和期望的供应链性能来设计响应策略。

Abstract: In recent years, the frequent occurrence of disruptions has had a negative
impact on global supply chains. To stay competitive, enterprises strive to
remain agile through the implementation of efficient and effective
decision-making strategies in reaction to disruptions. A significant effort has
been made to develop these agile disruption mitigation approaches, leveraging
both centralized and distributed decision-making strategies. Though trade-offs
of centralized and distributed approaches have been analyzed in existing
studies, no related work has been found on understanding supply chain
performance based on the network attributes of the disrupted supply chain
entities. In this paper, we characterize supply chains from a capability and
network topological perspective and investigate the use of a distributed
decision-making approach based on classical multi-agent frameworks. The
performance of the distributed framework is evaluated through a comprehensive
case study that investigates the performance of the supply chain as a function
of the network structure and agent attributes within the network in the
presence of a disruption. Comparison to a centralized decision-making approach
highlights trade-offs between performance, computation time, and network
communication based on the decision-making strategy and network architecture.
Practitioners can use the outcomes of our studies to design response strategies
based on agent capabilities, network attributes, and desired supply chain
performance.

</details>


### [331] [Dynamic distributed decision-making for resilient resource reallocation in disrupted manufacturing systems](https://arxiv.org/abs/2507.19043)
*Mingjie Bi,Ilya Kovalenko,Dawn M. Tilbury,Kira Barton*

Main category: cs.MA

TL;DR: 该研究提出了一种基于RA架构的重调度策略，通过风险评估来应对动态制造环境中的资源分配问题。仿真结果表明，该方法在降低计算量的同时，可以提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为了应对COVID-19大流行带来的市场频繁变化和人力短缺等意外中断，制造商需要灵活、实时的制造决策策略来应对高度动态的制造环境。其中一个关键问题是在资源中断（如机器故障）的情况下，动态分配资源以完成生产任务。

Method: 提出了一种基于RA架构的重调度策略，该策略通过聚类代理协调策略纳入风险评估。

Result: 仿真结果表明，与集中式方法相比，所提出的方法降低了计算量，但牺牲了一些吞吐量最优性。此外，案例研究表明，将风险评估纳入重调度决策可以提高吞吐量。

Conclusion: 该研究提出了一种基于RA架构的重调度策略，该策略通过聚类代理协调策略纳入风险评估，以应对制造环境中的动态资源分配问题。仿真结果表明，与集中式方法相比，该方法在降低计算量的同时，吞吐量最优性略有损失，但风险评估的引入提高了吞吐量。

Abstract: The COVID-19 pandemic brings many unexpected disruptions, such as frequently
shifting markets and limited human workforce, to manufacturers. To stay
competitive, flexible and real-time manufacturing decision-making strategies
are needed to deal with such highly dynamic manufacturing environments. One
essential problem is dynamic resource allocation to complete production tasks,
especially when a resource disruption (e.g., machine breakdown) occurs. Though
multi-agent methods have been proposed to solve the problem in a flexible and
agile manner, the agent internal decision-making process and resource
uncertainties have rarely been studied. This work introduces a model-based
resource agent (RA) architecture that enables effective agent coordination and
dynamic agent decision-making. Based on the RA architecture, a rescheduling
strategy that incorporates risk assessment via a clustering agent coordination
strategy is also proposed. A simulation-based case study is implemented to
demonstrate dynamic rescheduling using the proposed multi-agent framework. The
results show that the proposed method reduces the computational efforts while
losing some throughput optimality compared to the centralized method.
Furthermore, the case study illustrates that incorporating risk assessment into
rescheduling decision-making improves the throughput.

</details>


### [332] [Heterogeneous Risk Management Using a Multi-Agent Framework for Supply Chain Disruption Response](https://arxiv.org/abs/2507.19049)
*Mingjie Bi,Juan-Alberto Estrada-Garcia,Dawn M. Tilbury,Siqian Shen,Kira Barton*

Main category: cs.MA

TL;DR: 针对全球供应链中代理的异构风险管理机制，以分布式方式处理中断。


<details>
  <summary>Details</summary>
Motivation: 现有文献忽视了时间动态和个体代理风险管理的异质性，本研究旨在解决此问题，为企业在随机环境中以分布式方式处理中断提供支持，特别是在多代理控制和管理背景下。

Method: 提出了一种异构风险管理机制，将不确定性和风险态度纳入代理通信和决策策略。

Result: 所提出的方法使企业能够以分布式方式处理随机环境中的中断，并展示了不同风险态度如何影响决策。

Conclusion: 通过模拟案例研究展示了所提出的异构风险管理机制在随机环境下的可行性和有效性，以及在代理持有不同风险态度时，中断响应决策如何变化。

Abstract: In the highly complex and stochastic global, supply chain environments, local
enterprise agents seek distributed and dynamic strategies for agile responses
to disruptions. Existing literature explores both centralized and distributed
approaches, while most work neglects temporal dynamics and the heterogeneity of
the risk management of individual agents. To address this gap, this letter
presents a heterogeneous risk management mechanism to incorporate uncertainties
and risk attitudes into agent communication and decision-making strategy.
Hence, this approach empowers enterprises to handle disruptions in stochastic
environments in a distributed way, and in particular in the context of
multi-agent control and management. Through a simulated case study, we showcase
the feasibility and effectiveness of the proposed approach under stochastic
settings and how the decision of disruption responses changes when agents hold
various risk attitudes.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [333] [RailX: A Flexible, Scalable, and Low-Cost Network Architecture for Hyper-Scale LLM Training Systems](https://arxiv.org/abs/2507.18889)
*Yinxiao Feng,Tiancheng Chen,Yuchen Wei,Siyuan Shen,Shiju Wang,Wei Li,Kaisheng Ma,Torsten Hoefler*

Main category: cs.AR

TL;DR: RailX是一种创新的、可重构的AI互连网络架构，通过2D组织、电路交换和Hamiltonian分解，实现了超大规模、高带宽、低成本和高灵活性的互连，有效解决了传统网络的瓶颈问题，特别适用于MLaaS场景。


<details>
  <summary>Details</summary>
Motivation: 传统AI工作负载的增长对计算能力提出了更高要求，但现有的互连网络（如基于树的拓扑Rail-optimized网络和直接拓扑Torus）在可扩展性、成本效益和灵活性方面存在不足。Rail-optimized网络成本高昂，而Torus网络的带宽和灵活性有限。因此，需要一种新的网络架构来满足超大规模AI计算的需求。

Method: RailX提出了一种基于节点内直接连接和节点间电路交换的可重构网络架构。其关键在于将节点和光交换机进行2D组织，并通过一种基于Hamiltonian分解理论的新型互连方法，将独立的基于Rail的环组织成全连接拓扑，从而同时优化环状通信和全连接通信。

Result: RailX网络能够支持超过100K芯片的互连，并提供超高带宽，网络直径仅为2-4跳。与Fat-Tree相比，RailX在每注入/All-Reduce带宽上的成本低10%，在每双向/全连接带宽上的成本低50%。具体而言，互连200K芯片并提供1.8TB带宽仅需约13亿美元。此外，RailX还支持MLaaS场景下的灵活映射和容错。

Conclusion: RailX通过其创新的可重构网络架构、基于Hamiltonian分解的互连方法以及优化的环状和全连接通信，解决了传统互连网络在AI工作负载扩展性、成本效益和灵活性方面的挑战。该网络在支持超大规模（超过100K芯片）互连、降低成本（成本仅为Fat-Tree的10%-50%）以及实现低网络直径（2-4跳）方面表现出色，并能灵活应用于MLaaS场景，满足不同训练需求和容错要求。

Abstract: Increasingly large AI workloads are calling for hyper-scale infrastructure;
however, traditional interconnection network architecture is neither scalable
nor cost-effective enough. Tree-based topologies such as the
\textit{Rail-optimized} network are extremely expensive, while direct
topologies such as \textit{Torus} have insufficient bisection bandwidth and
flexibility. In this paper, we propose \textit{RailX}, a reconfigurable network
architecture based on intra-node direct connectivity and inter-node circuit
switching. Nodes and optical switches are physically 2D-organized, achieving
better scalability than existing centralized circuit switching networks. We
propose a novel interconnection method based on \textit{Hamiltonian
Decomposition} theory to organize separate rail-based rings into
\textit{all-to-all} topology, simultaneously optimizing ring-collective and
all-to-all communication. More than $100$K chips with hyper bandwidth can be
interconnected with a flat switching layer, and the diameter is only $2\sim4$
inter-node hops. The network cost per injection/All-Reduce bandwidth of
\textit{RailX} is less than $10\%$ of the Fat-Tree, and the cost per
bisection/All-to-All bandwidth is less than $50\%$ of the Fat-Tree.
Specifically, only $\sim$\$$1.3$B is required to interconnect 200K chips with
1.8TB bandwidth. \textit{RailX} can also be used in the ML-as-a-service (MLaaS)
scenario, where single or multiple training workloads with various shapes,
scales, and parallelism strategies can be flexibly mapped, and failures can be
worked around.

</details>


### [334] [3DGauCIM: Accelerating Static/Dynamic 3D Gaussian Splatting via Digital CIM for High Frame Rate Real-Time Edge Rendering](https://arxiv.org/abs/2507.19133)
*Wei-Hsing Huang,Cheng-Jhih Shih,Jian-Wei Su,Samuel Wade Wang,Vaidehi Garg,Yuyao Kong,Jen-Chun Tien,Nealson Li,Arijit Raychowdhury,Meng-Fan Chang,Yingyan,Lin,Shimeng Yu*

Main category: cs.AR

TL;DR: 动态3DGS在边缘设备上的实现面临高能耗、高延迟和兼容性问题。本研究提出算法-硬件协同设计，通过优化算法（减少DRAM访问、自适应瓦片分组、自适应排序）和硬件（DCIM友好计算），成功实现高帧率低功耗的实时渲染。


<details>
  <summary>Details</summary>
Motivation: 动态3DGS在边缘设备上的实现面临挑战：DRAM访问能耗高、参数增加导致排序延迟和能耗增加、有限的片上缓冲区容量导致DRAM频繁访问、以及动态3DGS操作与DCIM不兼容。这些挑战阻碍了边缘设备的实时性能和能效。

Method: 该研究提出了一种算法-硬件协同设计技术，包括三个算法级优化（减少DRAM访问的视锥剔除、自适应瓦片分组、自适应区间初始化桶-双调排序）和一个DCIM友好的计算流程。

Result: 实验结果表明，该方法能够实现超过200 FPS的实时渲染，静态场景功耗为0.28 W，动态场景功耗为0.63 W。

Conclusion: 该研究成功解决了在资源受限的边缘设备上实现静态/动态3DGS技术的重大挑战。

Abstract: Dynamic 3D Gaussian splatting (3DGS) extends static 3DGS to render dynamic
scenes, enabling AR/VR applications with moving objects. However, implementing
dynamic 3DGS on edge devices faces challenges: (1) Loading all Gaussian
parameters from DRAM for frustum culling incurs high energy costs. (2)
Increased parameters for dynamic scenes elevate sorting latency and energy
consumption. (3) Limited on-chip buffer capacity with higher parameters reduces
buffer reuse, causing frequent DRAM access. (4) Dynamic 3DGS operations are not
readily compatible with digital compute-in-memory (DCIM). These challenges
hinder real-time performance and power efficiency on edge devices, leading to
reduced battery life or requiring bulky batteries. To tackle these challenges,
we propose algorithm-hardware co-design techniques. At the algorithmic level,
we introduce three optimizations: (1) DRAM-access reduction frustum culling to
lower DRAM access overhead, (2) Adaptive tile grouping to enhance on-chip
buffer reuse, and (3) Adaptive interval initialization Bucket-Bitonic sort to
reduce sorting latency. At the hardware level, we present a DCIM-friendly
computation flow that is evaluated using the measured data from a 16nm DCIM
prototype chip. Our experimental results on Large-Scale Real-World
Static/Dynamic Datasets demonstrate the ability to achieve high frame rate
real-time rendering exceeding 200 frame per second (FPS) with minimal power
consumption, merely 0.28 W for static Large-Scale Real-World scenes and 0.63 W
for dynamic Large-Scale Real-World scenes. This work successfully addresses the
significant challenges of implementing static/dynamic 3DGS technology on
resource-constrained edge devices.

</details>


### [335] [A3D-MoE: Acceleration of Large Language Models with Mixture of Experts via 3D Heterogeneous Integration](https://arxiv.org/abs/2507.19142)
*Wei-Hsing Huang,Janak Sharda,Cheng-Jhih Shih,Yuyao Kong,Faaiq Waqar,Pin-Jun Chen,Yingyan,Lin,Shimeng Yu*

Main category: cs.AR

TL;DR: A3D-MoE 透過 3D 異構集成、自適應 systolic array、操作融合調度器以及優化的 HBM 訪問，解決了傳統 LLM 和 MoE 架構的能耗、延遲和硬件利用率問題，顯著提升了 LLM 的推理效率。


<details>
  <summary>Details</summary>
Motivation: 傳統的大型語言模型（LLMs）參數量巨大，推理過程能耗高昂且成本高昂。雖然混合專家（MoE）架構作為一種更高效的替代方案出現，但其仍然面臨著幾個挑戰：1) 運行時可變的工作負載會導致任意的 GEMV-GEMM 比例，降低硬件利用率；2) 傳統的基於 MoE 的 LLM 服務調度無法將注意操作與 MoE 操作融合，導致延遲增加和硬件利用率下降；3) 儘管比傳統 LLM 更高效，但從 DRAM 加載專家仍然消耗大量能量並需要可觀的 DRAM 帶寬。

Method: 提出了一種名為 A3D-MoE 的 3D 異構集成系統，該系統採用了最先進的垂直集成技術，以顯著提高內存帶寬，同時降低片上網絡 (NoC) 的開銷和能耗。此外，還提出了一種 3D 適應性 GEMV-GEMM 比例的 سيكون陣列，具有 V-Cache 高效數據重用和新穎的統一 3D 數據流，以解決由不同工作負載引起的任意 GEMV-GEMM 比例導致的硬件利用率降低的問題。還提出了一種硬件資源感知操作融合調度器，用於融合注意操作和 MoE 操作以提高硬件性能，並通過偶數/奇數專家放置減少 MoE 分數感知的 HBM 訪問，以減少 DRAM 訪問和帶寬要求。

Result: 評估結果表明，A3D-MoE 在性能方面取得了顯著的增強。

Conclusion: A3D-MoE 在性能、能耗和吞吐量方面相較於現有技術有顯著提升，延遲降低了 1.8 倍至 2 倍，能耗降低了 2 倍至 4 倍，吞吐量提高了 1.44 倍至 1.8 倍。

Abstract: Conventional large language models (LLMs) are equipped with dozens of GB to
TB of model parameters, making inference highly energy-intensive and costly as
all the weights need to be loaded to onboard processing elements during
computation. Recently, the Mixture-of-Experts (MoE) architecture has emerged as
an efficient alternative, promising efficient inference with less activated
weights per token. Nevertheless, fine-grained MoE-based LLMs face several
challenges: 1) Variable workloads during runtime create arbitrary GEMV-GEMM
ratios that reduce hardware utilization, 2) Traditional MoE-based scheduling
for LLM serving cannot fuse attention operations with MoE operations, leading
to increased latency and decreased hardware utilization, and 3) Despite being
more efficient than conventional LLMs, loading experts from DRAM still consumes
significant energy and requires substantial DRAM bandwidth. Addressing these
challenges, we propose: 1) A3D-MoE, a 3D Heterogeneous Integration system that
employs state-of-the-art vertical integration technology to significantly
enhance memory bandwidth while reducing Network-on-Chip (NoC) overhead and
energy consumption. 2) A 3D-Adaptive GEMV-GEMM-ratio systolic array with
V-Cache efficient data reuse and a novel unified 3D dataflow to solve the
problem of reduced hardware utilization caused by arbitrary GEMV-GEMM ratios
from different workloads, 3) A Hardware resource-aware operation fusion
scheduler that fuses attention operations with MoE operations to enhance
hardware performance, and 4) MoE Score-Aware HBM access reduction with even-odd
expert placement that reduces DRAM access and bandwidth requirements. Our
evaluation results indicate that A3D-MoE delivers significant performance
enhancements, reducing latency by a factor of 1.8x to 2x and energy consumption
by 2x to 4x, while improving throughput by 1.44x to 1.8x compared to the
state-of-the-art.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [336] [Design and Implementation of Parametrized Look-Up Tables for Post-Correction of Oversampling Low-Resolution ADCs](https://arxiv.org/abs/2507.18673)
*Morriel Kasher,Michael Tinston,Predrag Spasojevic*

Main category: eess.SP

TL;DR: 提出了一种用于恢复量化信号的LUT设计框架，通过将问题分解为四个阶段并使用模型驱动的方法进行解决，无需训练。该框架能够显著提高信号的SFDR，同时大大减小内存开销，适用于低分辨率宽带设备。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于设计、优化和实现查找表（LUT）的框架，用于恢复有噪声、过采样、量化信号。

Method: 该方法将LUT设计问题分解为四个阶段，并使用模型驱动的方法进行分析，无需训练。研究了三种抖动方法来提高频谱纯度指标，并提出了两种新的索引方案来限制LUT内存开销，将LUT大小压缩了四个数量级以上，同时性能损失很小。

Result: 所提出的LUT设计在有噪声、过采样、量化到3位的正弦输入下进行了测试，其无杂散动态范围（SFDR）提高了19 dBc以上，同时内存开销仅为324字节，并保持了3位固定点精度。

Conclusion: 该框架为设计、优化和实现查找表（LUT）提供了一种方法，用于在给定参数输入模型的情况下恢复有噪声、过采样、量化信号。

Abstract: We propose a framework for the design, optimization, and implementation of
Look-Up Tables (LUTs) used to recover noisy, oversampled, quantized signals
given a parametric input model. The LUTs emulate the spectral effects of
pre-quantization dithering through an all-digital solution applied after
quantization. This methodology decomposes the intractable LUT design problem
into four distinct stages, each of which is addressed analytically using a
model-driven approach without reliance on training. Three dithering methods are
studied to improve spectral purity metrics. Two novel indexing schemes are
proposed to limit the LUT memory overhead shown to compress the LUT size by
over four orders of magnitude with marginal performance loss. The LUT design is
tested with an oversampled noisy sinusoidal input quantized to 3 bits and shown
to improve its Spurious-Free Dynamic Range (SFDR) by over 19 dBc with only 324
bytes of memory while maintaining the same 3-bit fixed-point precision at the
digital output. This correction can be implemented using two-level
combinational logic ensuring ultra-low latency and, hence, suitable for
low-resolution wideband devices.

</details>


### [337] [Exploiting Movable Antennas in NOMA Networks: Joint Beamforming, Power Allocation and Antenna Position Optimization](https://arxiv.org/abs/2507.18730)
*Yufeng Zhou,Wen Chen,Qingqing Wu,Xusheng Zhu,Zhendong Li,Kunlun Wang,Qiong Wu*

Main category: eess.SP

TL;DR: 本研究提出了一种利用交替优化、序贯参数化凸近似和连续凸近似技术来优化波束成形、功率分配和移动天线位置的算法，以最大化MA辅助NOMA网络的吞吐量。结果表明，该方法显著优于基准。


<details>
  <summary>Details</summary>
Motivation: 本篇论文旨在研究并最大化移动天线（MA）辅助下行链路非正交多址（NOMA）网络在给定预定SIC解码顺序下的系统吞吐量。

Method: 本研究提出了一种基于交替优化（AO）框架的高效算法，将原始问题分解为三个独立的子问题。通过采用序贯参数化凸近似（SPCA）和连续凸近似（SCA）技术，将每个子问题中的非凸约束转换为可处理的约束。

Result: 通过数值结果验证，所提出的系统能够充分利用发射端和接收端天线移动性的自由度，从而在吞吐量方面显著优于现有技术。

Conclusion: 该研究提出的算法收敛到稳定、局部最优解，并且所提出的系统在吞吐量方面显著优于基准。

Abstract: This paper investigates the movable antenna (MA)- assisted downlink
non-orthogonal multiple access (NOMA) network to maximize system throughput. In
the considered scenario, both the base station (BS) and users are equipped with
MA, and a predetermined successive interference cancellation (SIC) decoding
order is adopted. Based on the field-response channel model, we formulate a
complex, non-convex problem to jointly optimize the BS beamforming, power
allocation, and MA positions at both the transmitter and receivers. To address
this, we propose an efficient algorithm based on an alternating optimization
(AO) framework, which decomposes the original problem into three distinct
subproblems. By employing sequential parametric convex approximation (SPCA) and
successive convex approximation (SCA) techniques, the non-convex constraints
within each subproblem are transformed into tractable. This methodology ensures
the algorithm converges to a stable, locally optimal solution. Numerical
results validate that the proposed system, which fully exploits the degrees of
freedom from antenna mobility at both ends, significantly outperforms
benchmarks in terms of throughput.

</details>


### [338] [Max-Min Rate Optimization for Multigroup Multicast MISO Systems Via Novel Transmissive RIS Transceiver](https://arxiv.org/abs/2507.18733)
*Yuan Guo,Wen Chen,Qingqing Wu,Yanze Zhu,Yang Liu,Zhendong Li,Ying Wang*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper investigates a novel transmissive reconfigurable intelligent
surface (RIS) transceiver architectureenabled multigroup multicast downlink
communication system. Under this setup, an optimization problem is formulated
to maximize the minimum rate of users across all groups, subject to the maximum
available power of each RIS unit. Due to the nondifferentiable nature of the
objective function, the max-min rate problem is challenging to solve. To tackle
this difficult problem, we develop an iterative solution by leveraging the
successive convex approximation (SCA) and the penalty function method. However,
the above approach has high computational complexity and may lead to
compromised performance. To overcome these drawbacks, we design an efficient
second-order cone programming (SOCP)-based method using the weighted minimum
mean squared error (WMMSE) framework to reduce computational complexity.
Furthermore, to further reduce the computational complexity, we also propose a
low-complexity and solver-free algorithm that analytically updates all
variables by combining the smooth approximation theory and the
majorization-minimization (MM) method. Numerical results are provided to verify
the convergence and effectiveness of our proposed three algorithms. It is also
demonstrated that the SOCP-based method outperforms the penalty-based algorithm
in terms of both the achieved min rate and the computational complexity. In
contrast, the lowcomplexity design achieves significantly lower complexity with
only slightly degraded performance.

</details>


### [339] [Max-Min Fairness-Oriented Beamforming Design in HAPS-Enabled ISAC for 6G Networks](https://arxiv.org/abs/2507.18764)
*Parisa Kanani,Mohammad Javad Omidi,Mahmoud Modarres-Hashemi,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 本文介绍了一种用于6G网络的HAPS-ISAC系统，通过优化算法实现了公平的服务和高效的资源分配，证明了其作为6G关键技术和通信传感集成系统的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决6G网络中公平的服务分配问题，特别是在HAPS-ISAC系统中。

Method: 提出了一种在高空平台站（HAPS）支持下的集成传感与通信（ISAC）系统，并采用最大最小公平方法解决了一个非凸优化问题，以平衡传感波束图增益和通信用户的信噪比（SINR）要求，同时满足功率约束。

Result: 所提出的HAPS-ISAC框架能够实现高效的资源分配、可靠的覆盖和更高的传感精度。

Conclusion: HAPS-ISAC系统是6G网络和集成通信传感系统的关键赋能者。

Abstract: This paper presents a high-altitude platform station (HAPS)-enabled
integrated sensing and communication (ISAC) system designed for
sixth-generation (6G) networks. Positioned in the stratosphere, HAPS serves as
a super-macro base station, leveraging advanced beamforming techniques to
enable communication and sensing simultaneously. This research addresses the
need for equitable service distribution in 6G networks by focusing on fairness
within the HAPS-ISAC system. It tackles a non-convex optimization problem that
balances sensing beampattern gain and signal-to-interference-plus-noise ratio
(SINR) requirements among communication users (CUs) using a max-min fairness
approach while adhering to power constraints. The proposed HAPS-ISAC framework
ensures efficient resource allocation, reliable coverage, and improved sensing
accuracy. Simulation results validate the potential of HAPS-ISAC as a pivotal
enabler for 6G networks and integrated communication-sensing systems.

</details>


### [340] [Flexible Intelligent Metasurfaces in High-Mobility MIMO Integrated Sensing and Communications](https://arxiv.org/abs/2507.18793)
*Kuranage Roche Rayan Ranasinghe,Jiancheng An,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Chau Yuen,Mérouane Debbah*

Main category: eess.SP

TL;DR: 提出了一种新的考虑FIM的DD-MIMO信道模型，并将其应用于ISAC的OFDM、OTFS和AFDM波形。通过梯度上升求解最大化速率和满足传感约束的优化问题，结果显示FIM对ISAC性能有重要影响。


<details>
  <summary>Details</summary>
Motivation: 为高移动性场景下的集成传感与通信（ISAC）提供一个适用于双重色散（DD）MIMO信道的模型，并研究FIM技术如何影响ISAC性能。

Method: 提出了一种新颖的包含灵活智能超表面（FIM）的偶发双重色散（DD）MIMO信道模型，并讨论了如何将其应用于OFDM、OTFS和AFDM等波形。然后，通过梯度上升算法制定并求解了一个以最大化可实现速率和满足传感约束为目标的优化问题，并提供了闭式梯度。

Result: 数值结果表明，FIM技术对可实现速率有显著影响，并且仔细调整FIM参数对于在所有适用于减轻DD信道影响的波形中获得强大的ISAC性能至关重要。

Conclusion: FIM技术对ISAC性能有显著影响，仔细调整FIM参数对于在所有适用于减轻DD信道影响的波形中获得强大的ISAC性能至关重要。

Abstract: We propose a novel doubly-dispersive (DD) multiple-input multiple-output
(MIMO) channel model incorporating flexible intelligent metasurfaces (FIMs),
which is suitable for integrated sensing and communications (ISAC) in
high-mobility scenarios. We then discuss how the proposed FIM-parameterized DD
(FPDD) channel model can be applied in a logical manner to ISAC waveforms that
are known to perform well in DD environments, namely, orthogonal frequency
division multiplexing (OFDM), orthogonal time frequency space (OTFS), and
affine frequency division multiplexing (AFDM). Leveraging the proposed model,
we formulate an achievable rate maximization problem with a strong sensing
constraint for all the aforementioned waveforms, which we then solve via a
gradient ascent algorithm with closed-form gradients presented as a bonus. Our
numerical results indicate that the achievable rate is significantly impacted
by the emerging FIM technology with careful parametrization essential in
obtaining strong ISAC performance across all waveforms suitable to mitigating
the effects of DD channels.

</details>


### [341] [A Fingerprint Database Generation Method for RIS-Assisted Indoor Positioning](https://arxiv.org/abs/2507.18927)
*Xin Cheng,Yu He,Menglu Li,Ruoguang Li,Feng Shu,Guangjie Han*

Main category: eess.SP

TL;DR: 提出了一种新颖的RIS辅助RSS指纹数据库生成方法，该方法能够捕获复杂的RIS辅助多径行为并确保空间一致性，并对定位性能进行了分析。


<details>
  <summary>Details</summary>
Motivation: 尽管RIS在增强室内无线通信和感知性能方面具有潜力，但由于缺乏现实且空间一致的信道建模方法，用于RIS辅助室内定位的可靠的基于接收信号强度（RSS）的指纹数据库的构建仍然是一个挑战。

Method: 提出了一种利用扩展的基于集群的信道建模方法，并结合了RIS和发射机（Tx）的物理和电磁特性，以捕获复杂的RIS辅助多径行为。在模拟指纹数据收集时，还考虑了空间一致性。

Result: 通过广泛的仿真评估了所提出方法生成的指纹数据库，并分析了使用KNN和DNN在数据库上进行的定位性能。

Conclusion: 该方法为生成RIS辅助RSS指纹数据库提供了一种新颖的方法，并通过KNN和DNN分析了定位性能。

Abstract: Reconfigurable intelligent surface (RIS) has emerged as a promising
technology to enhance indoor wireless communication and sensing performance.
However, the construction of reliable received signal strength (RSS)-based
fingerprint databases for RIS-assisted indoor positioning remains an open
challenge due to the lack of realistic and spatially consistent channel
modeling methods. In this paper, we propose a novel method with open-source
codes for generating RIS-assisted RSS fingerprint databases. Our method
captures the complex RIS-assisted multipath behaviors by extended cluster-based
channel modeling and the physical and electromagnetic properties of RIS and
transmitter (Tx). And the spatial consistency is incorporated when simulating
the fingerprint data collection across neighboring positions. Furthermore, the
proposed method offers exceptional flexibility in configuring RIS and Tx
parameters. Extensive simulations are conducted to evaluate the fingerprint
database generated by the proposed method. Moreover, the positioning
performance on the database using K-nearest neighbors (KNN) and deep neural
network (DNN) is analyzed, providing valuable insights for the system design.

</details>


### [342] [Assessing the Reliability and Validity of a Balance Mat for Measuring Postural Stability: A Combined Robot-Human Approach](https://arxiv.org/abs/2507.18943)
*Abishek Shrestha,Damith Herath,Angie Fearon,Maryam Ghahramani*

Main category: eess.SP

TL;DR: 本研究评估了一种新型便携式平衡垫（BM）设备的可靠性和有效性。结果表明，该设备在经过校准后，能够可靠且有效地测量姿势摇摆，克服了传统测力板的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了克服测力板（FP）便携性差和需要高水平专业知识的限制，本研究评估了一种低成本、便携式的新型平衡垫（BM）设备的可靠性和有效性，该设备采用光纤技术。

Method: 本研究包含两项研究：机器人研究和人类研究。在机器人研究中，使用 UR10 机器人手臂获得受控的摇摆模式，以评估平衡垫（BM）的可靠性和灵敏度。在人类研究中，51 名健康的年轻参与者在 BM 和力板（FP）上执行平衡任务，以评估 BM 的有效性。计算了来自 BM 和 FP 的摇摆指标，如平均摇摆值、绝对平均摇摆值、均方根摇摆值 (RMS)、摇摆路径、摇摆范围和摇摆速度，并进行了比较。使用组内相关系数 (ICC) 评估可靠性，其中大于 0.9 的值为优秀，0.75 至 0.9 的值为良好。使用 Bland-Altman 图进行一致性分析，揭示了 BM 和 FP 之间的比例偏差，其中 BM 相较于 FP 高估了摇摆指标。通过校准来改善设备之间的一致性。

Result: 机器人研究结果显示，单腿和双腿站立的 ICC 值均表现良好到优秀。人类研究结果显示，摇摆路径和摇摆范围具有中等到强的相关性。Bland-Altman 图的一致性分析显示，BM 和 FP 之间存在比例偏差，BM 高估了摇摆指标。校准改善了设备之间的一致性。

Conclusion: 该设备在经过适当校准后，表现出跨各种站姿条件的一致性姿势摇摆测量，确立了其可靠性和有效性。

Abstract: Postural sway assessment is important for detecting balance problems and
identifying people at risk of falls. Force plates (FP) are considered the gold
standard postural sway assessment method in laboratory conditions, but their
lack of portability and requirement of high-level expertise limit their
widespread usage. This study evaluates the reliability and validity of a novel
Balance Mat (BM) device, a low-cost portable alternative that uses optical
fibre technology. The research includes two studies: a robot study and a human
study. In the robot study, a UR10 robotic arm was used to obtain controlled
sway patterns to assess the reliability and sensitivity of the BM. In the human
study, 51 healthy young participants performed balance tasks on the BM in
combination with an FP to evaluate the BM's validity. Sway metrics such as sway
mean, sway absolute mean, sway root mean square (RMS), sway path, sway range,
and sway velocity were calculated from both BM and FP and compared. Reliability
was evaluated using the intra-class correlation coefficient (ICC), where values
greater than 0.9 were considered excellent and values between 0.75 and 0.9 were
considered good. Results from the robot study demonstrated good to excellent
ICC values in both single and double-leg stances. The human study showed
moderate to strong correlations for sway path and range. Using Bland-Altman
plots for agreement analysis revealed proportional bias between the BM and the
FP where the BM overestimated sway metrics compared to the FP. Calibration was
used to improve the agreement between the devices. The device demonstrated
consistent sway measurement across varied stance conditions, establishing both
reliability and validity following appropriate calibration.

</details>


### [343] [Max-Min Beamforming for Large-Scale Cell-Free Massive MIMO: A Randomized ADMM Algorithm](https://arxiv.org/abs/2507.18980)
*Bin Wang,Jun Fang,Yue Xiao,Martin Haardt*

Main category: eess.SP

TL;DR: 提出了一种随机 ADMM 算法来解决大规模 MMB 问题，该算法具有显著的复杂度优势和与确定性方法相同的收敛速率。


<details>
  <summary>Details</summary>
Motivation: 现有的 MMB 方法主要基于确定性优化方法，当问题规模增大时，计算效率低下。

Method: 提出了一种随机交替方向乘子法 (ADMM) 算法来解决大规模 MMB 问题，首先提出了一种新颖的公式，将具有挑战性的可行性检查问题转化为线性约束优化问题，然后开发了一种有效的随机 ADMM 来解决该问题。

Result: 提出的随机 ADMM 算法具有 O(1/t) 的收敛速率，在数值结果中，与现有方法相比，在解决 MMB 问题方面具有显著的复杂度优势。

Conclusion: 该算法与确定性方法具有相同的收敛速率，在解决 MMB 问题方面具有显著的复杂度优势。

Abstract: We consider the problem of max-min beamforming (MMB) for cell-free massive
multi-input multi-output (MIMO) systems, where the objective is to maximize the
minimum achievable rate among all users. Existing MMB methods are mainly based
on deterministic optimization methods, which are computationally inefficient
when the problem size grows large. To address this issue, we, in this paper,
propose a randomized alternating direction method of multiplier (ADMM)
algorithm for large-scale MMB problems. We first propose a novel formulation
that transforms the highly challenging feasibility-checking problem into a
linearly constrained optimization problem. An efficient randomized ADMM is then
developed for solving the linearly constrained problem. Unlike standard ADMM,
randomized ADMM only needs to solve a small number of subproblems at each
iteration to ensure convergence, thus achieving a substantial complexity
reduction. Our theoretical analysis reveals that the proposed algorithm
exhibits an O(1/\bar{t}) convergence rate (\bar{t} represents the number of
iterations), which is on the same order as its deterministic counterpart.
Numerical results show that the proposed algorithm offers a significant
complexity advantage over existing methods in solving the MMB problem.

</details>


### [344] [Machine Learning based Radio Environment Map Estimation for Indoor Visible Light Communication](https://arxiv.org/abs/2507.19149)
*Helena Serpi,Christina,Politi*

Main category: eess.SP

TL;DR: 提出了一种基于机器学习（MLP）的光无线通信（VLC）系统无线电地图估算方法，该方法比传统仿真更准确、更快速，并且可以优化以满足实时性要求。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统仿真技术在无线电地图估算中的不足，提出了一种基于机器学习的新方法，以提高估算的准确性和效率，并适应实时性需求。

Method: 提出了一种基于机器学习（特别是多层感知器MLP）的无线电地图估计算法，用于光无线通信（VLC）系统。

Result: 所提出的MLP方法在精度、速度和所需训练样本数量方面优于其他方法，非常适合室内VLC系统的实时估算。

Conclusion: 该方法通过调整MLP参数，可以在推断精度、训练时间和模型性能之间取得平衡，以满足实时性要求。

Abstract: An innovative method for radio map estimation in optical wireless
communications is proposed that is based on Machine Learning rather than
simulation techniques. Multi-Layer Perceptron (MLP) representation of indoor
Visible Light Communication (VLC) systems is suggested, and signal propagation
is estimated. The simulation and performance predictions are accurate, fast and
require a reduced set of training sample size with respect to other
counterparts, making this solution very suitable for real time estimation of an
indoor VLC system. It is shown that by tweaking MLP parameters, such as sample
size, number of epochs and batch size, one can balance the desired level of
inference accuracy with training time and optimize the model's performance to
meet real-time requirements.

</details>


### [345] [High-Fidelity RF Mapping: Assessing Environmental Modeling in 6G Network Digital Twins](https://arxiv.org/abs/2507.19173)
*Lorenzo Cazzella,Francesco Linsalata,Damiano Badini,Matteo Matteucci,Maurizio Magarini,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 该论文提出了 HRT 和 CRT 指标，用于比较不同射线追踪模拟在考虑环境变化时的差异，并使用米兰数字孪生模型进行了验证，证明了这些指标在评估环境变化对无线电传播的影响方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了准确设计电磁环境的数字孪生 (DT)，需要对潜在环境模型进行高保真建模。评估不同精度建模水平之间的差异对于确定模型特征对高效准确的 DT 仿真的相关性至关重要。

Method: 提出 Hausdorff 射线追踪 (HRT) 和倒角射线追踪 (CRT) 指标，以比较两个射线追踪模拟在时间和角度功率特征上的差异。在意大利米兰的一个高保真数字孪生模型上，通过集成车辆网格和分割建筑物 fachada 面来引入两种不同的环境变化。利用 NVIDIA Sionna RT 射线追踪模拟器和 SUMO 车辆交通模拟器在 28 GHz 载波频率下进行基于网格和基于车辆的射线追踪模拟。

Result: HRT 和 CRT 指标均突出了模拟的无线电传播特征因引入的网格集成而出现差异的场景区域。基于车辆的射线追踪模拟揭示了沿真实车辆轨迹产生的距离模式。

Conclusion: 所提出的 Hausdorff 射线追踪 (HRT) 和倒角射线追踪 (CRT) 指标能够一致地比较时间和角度功率特征，并在考虑环境变化时评估不同射线追踪模拟之间的差异。

Abstract: The design of accurate Digital Twins (DTs) of electromagnetic environments
strictly depends on the fidelity of the underlying environmental modeling.
Evaluating the differences among diverse levels of modeling accuracy is key to
determine the relevance of the model features towards both efficient and
accurate DT simulations. In this paper, we propose two metrics, the Hausdorff
ray tracing (HRT) and chamfer ray tracing (CRT) distances, to consistently
compare the temporal, angular and power features between two ray tracing
simulations performed on 3D scenarios featured by environmental changes. To
evaluate the introduced metrics, we considered a high-fidelity digital twin
model of an area of Milan, Italy and we enriched it with two different types of
environmental changes: (i) the inclusion of parked vehicles meshes, and (ii)
the segmentation of the buildings facade faces to separate the windows mesh
components from the rest of the building. We performed grid-based and vehicular
ray tracing simulations at 28 GHz carrier frequency on the obtained scenarios
integrating the NVIDIA Sionna RT ray tracing simulator with the SUMO vehicular
traffic simulator. Both the HRT and CRT metrics highlighted the areas of the
scenarios where the simulated radio propagation features differ owing to the
introduced mesh integrations, while the vehicular ray tracing simulations
allowed to uncover the distance patterns arising along realistic vehicular
trajectories.

</details>


### [346] [Bespoke multiresolution analysis of graph signals](https://arxiv.org/abs/2507.19181)
*Giacomo Elefante,Gianluca Giacchi,Michael Multerer,Jacopo Quizi*

Main category: eess.SP

TL;DR: 提出一种用于图信号离散多分辨率分析的新颖框架，利用图上的samplets变换。


<details>
  <summary>Details</summary>
Motivation: 提出一种用于图信号离散多分辨率分析的新颖框架。

Method: 通过将图细分到块中，将每个块嵌入到欧几里得空间中，在那里构建samplets，并将构造拉回到图上，来定义图上的samplets。使用重边聚类和地标Isomap进行高效的数值实现。

Result: 该框架具有正交性、局部性和关于适当定义的图多项式空间的消失矩性质。该框架拓宽了可以有效压缩和分析的图信号类别，并在压缩效率和多分辨率保真度方面显著优于传统哈尔小波方法。

Conclusion: 该框架在压缩效率和多分辨率保真度方面显著优于传统哈尔小波方法。

Abstract: We present a novel framework for discrete multiresolution analysis of graph
signals. The main analytical tool is the samplet transform, originally defined
in the Euclidean framework as a discrete wavelet-like construction, tailored to
the analysis of scattered data. The first contribution of this work is defining
samplets on graphs. To this end, we subdivide the graph into a fixed number of
patches, embed each patch into a Euclidean space, where we construct samplets,
and eventually pull the construction back to the graph. This ensures
orthogonality, locality, and the vanishing moments property with respect to
properly defined polynomial spaces on graphs. Compared to classical Haar
wavelets, this framework broadens the class of graph signals that can
efficiently be compressed and analyzed. Along this line, we provide a
definition of a class of signals that can be compressed using our construction.
We support our findings with different examples of signals defined on graphs
whose vertices lie on smooth manifolds. For efficient numerical implementation,
we combine heavy edge clustering, to partition the graph into meaningful
patches, with landmark \texttt{Isomap}, which provides low-dimensional
embeddings for each patch. Our results demonstrate the method's robustness,
scalability, and ability to yield sparse representations with controllable
approximation error, significantly outperforming traditional Haar wavelet
approaches in terms of compression efficiency and multiresolution fidelity.

</details>


### [347] [Real-time rail vehicle localisation using spatially resolved magnetic field measurements](https://arxiv.org/abs/2507.19327)
*Niklas Dieckow,Katharina Ostaszewski,Philip Heinisch,Henriette Struckmann,Hendrik Ranocha*

Main category: eess.SP

TL;DR: 本文提出两种基于磁场测量的轨道车辆实时定位方法，一种基于粒子滤波，另一种基于序列比对。粒子滤波精度高但低速性能差，序列比对在冷启动时表现好。混合方法结合两者优点，均能在消费级硬件上实现实时运行，满足安全关键应用需求。


<details>
  <summary>Details</summary>
Motivation: 提出基于磁场测量的两种互补的实时轨道车辆定位方法，以提高轨道车辆定位的精确性和鲁棒性，满足安全关键型应用的需求。

Method: 本文提出了两种互补的实时轨道车辆定位方法：1. 基于粒子滤波的方法，通过磁场相似性进行重加权，并采用重尾非高斯核增强稳定性。2. 基于状态的序列比对技术，将实时磁信号转换为空间域，并使用相似性度量与磁场地图进行匹配。此外，还提出了一种结合两种方法的混合方法：基于比对的初始化，然后进行粒子滤波跟踪。

Result: 粒子滤波方法在21.6公里轨道上实现了超过5米的轨道选择性精度，但在低速和冷启动情况下性能下降。比对方法在冷启动情况下表现优异，92%的测试中定位精度达到30米以内（使用前3个匹配项时达到100%）。混合方法结合了两种方法的优点。运行时分析表明，该系统能在消费级硬件上实现实时运行。

Conclusion: 本文提出的基于磁场测量的两种互补的实时轨道车辆定位方法，能够实现精确、鲁棒的定位，适用于安全关键型轨道应用。

Abstract: This work presents two complementary real-time rail vehicle localization
methods based on magnetic field measurements and a pre-recorded magnetic map.
The first uses a particle filter reweighted via magnetic similarity, employing
a heavy-tailed non-Gaussian kernel for enhanced stability. The second is a
stateless sequence alignment technique that transforms real-time magnetic
signals into the spatial domain and matches them to the map using a similarity
measure. Experiments with operational train data show that the particle filter
achieves track-selective, sub-5-meter accuracy over 21.6 km, though its
performance degrades at low speeds and during cold starts. Accuracy tests were
constrained by the GNSS-based reference system. In contrast, the
alignment-based method excels in cold-start scenarios, localizing within 30 m
in 92 % of tests (100 % using top-3 matches). A hybrid approach combines both
methods$\unicode{x2014}$alignment-based initialization followed by particle
filter tracking. Runtime analysis confirms real-time capability on
consumer-grade hardware. The system delivers accurate, robust localization
suitable for safety-critical rail applications.

</details>
