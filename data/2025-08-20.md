<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 83]
- [cs.CL](#cs.CL) [Total: 35]
- [cs.LG](#cs.LG) [Total: 75]
- [cs.AR](#cs.AR) [Total: 13]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.GR](#cs.GR) [Total: 5]
- [cs.SI](#cs.SI) [Total: 4]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 5]
- [cs.LO](#cs.LO) [Total: 4]
- [cs.NE](#cs.NE) [Total: 3]
- [physics.app-ph](#physics.app-ph) [Total: 5]
- [cs.MA](#cs.MA) [Total: 5]
- [cs.AI](#cs.AI) [Total: 41]
- [cond-mat.mtrl-sci](#cond-mat.mtrl-sci) [Total: 19]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.ET](#cs.ET) [Total: 1]
- [eess.SY](#eess.SY) [Total: 13]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.GT](#cs.GT) [Total: 5]
- [quant-ph](#quant-ph) [Total: 45]
- [eess.SP](#eess.SP) [Total: 6]
- [cs.DC](#cs.DC) [Total: 10]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [YOLO11-CR: a Lightweight Convolution-and-Attention Framework for Accurate Fatigue Driving Detection](https://arxiv.org/abs/2508.13205)
*Zhebin Jin,Ligang Dong*

Main category: cs.CV

TL;DR: This paper introduces YOLO11-CR, a new computer vision model for detecting driver fatigue. It uses novel modules (CAFM and RCM) to improve accuracy, especially for challenging cases like small or partially hidden objects. The model performs better than existing methods and is suitable for real-world applications.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of physiological and vehicle dynamics-based methods (intrusiveness, hardware dependency, lack of robustness) and vision-based methods (poor detection of small/occluded objects, limited multi-scale feature modeling) for driver fatigue detection.

Method: The paper proposes YOLO11-CR, a lightweight and efficient object detection model that integrates the Convolution-and-Attention Fusion Module (CAFM) and the Rectangular Calibration Module (RCM) to enhance feature expressiveness and spatial localization, particularly for profile faces and small objects.

Result: YOLO11-CR achieved 87.17% precision, 83.86% recall, 88.09% mAP@50, and 55.93% mAP@50-95 on the DSM dataset, outperforming baseline models. Ablation studies confirmed the effectiveness of CAFM and RCM.

Conclusion: YOLO11-CR is a practical and high-performing solution for in-vehicle fatigue monitoring, showing strong potential for real-world deployment and future enhancements.

Abstract: Driver fatigue detection is of paramount importance for intelligent
transportation systems due to its critical role in mitigating road traffic
accidents. While physiological and vehicle dynamics-based methods offer
accuracy, they are often intrusive, hardware-dependent, and lack robustness in
real-world environments. Vision-based techniques provide a non-intrusive and
scalable alternative, but still face challenges such as poor detection of small
or occluded objects and limited multi-scale feature modeling. To address these
issues, this paper proposes YOLO11-CR, a lightweight and efficient object
detection model tailored for real-time fatigue detection. YOLO11-CR introduces
two key modules: the Convolution-and-Attention Fusion Module (CAFM), which
integrates local CNN features with global Transformer-based context to enhance
feature expressiveness; and the Rectangular Calibration Module (RCM), which
captures horizontal and vertical contextual information to improve spatial
localization, particularly for profile faces and small objects like mobile
phones. Experiments on the DSM dataset demonstrated that YOLO11-CR achieves a
precision of 87.17%, recall of 83.86%, mAP@50 of 88.09%, and mAP@50-95 of
55.93%, outperforming baseline models significantly. Ablation studies further
validate the effectiveness of the CAFM and RCM modules in improving both
sensitivity and localization accuracy. These results demonstrate that YOLO11-CR
offers a practical and high-performing solution for in-vehicle fatigue
monitoring, with strong potential for real-world deployment and future
enhancements involving temporal modeling, multi-modal data integration, and
embedded optimization.

</details>


### [2] [MIRAGE: Towards AI-Generated Image Detection in the Wild](https://arxiv.org/abs/2508.13223)
*Cheng Xia,Manxi Lin,Jiexiang Tan,Xiaoxiong Du,Yang Qiu,Junjun Zheng,Xiangheng Kong,Yuning Jiang,Bo Zheng*

Main category: cs.CV

TL;DR: Mirage-R1 是一种新的视觉-语言模型，通过 Mirage 基准测试和其独特的推理机制，能够更有效地检测野外 AI 生成的图像，并能在速度和准确性之间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 现有 AIGI 检测器在真实世界场景中泛化能力不足，真实世界的图像包含噪声，并且来自多个生成模型并经过编辑。

Method: 提出了一种名为 Mirage 的基准测试，用于模拟野外 AIGI 的复杂性，并提出了 Mirage-R1，一个具有启发式到分析式推理和反思性推理机制的视觉-语言模型，通过监督微调冷启动和强化学习阶段进行训练，并采用推理时自适应思考策略。

Result: Mirage-R1 在 Mirage 和公开基准测试上分别领先最先进的检测器 5% 和 10%。

Conclusion: Mirage-R1 在 Mirage 和公开基准测试上均超越了最先进的检测器，分别领先 5% 和 10%，并且在推理速度和性能之间取得了有效平衡。

Abstract: The spreading of AI-generated images (AIGI), driven by advances in generative
AI, poses a significant threat to information security and public trust.
Existing AIGI detectors, while effective against images in clean laboratory
settings, fail to generalize to in-the-wild scenarios. These real-world images
are noisy, varying from ``obviously fake" images to realistic ones derived from
multiple generative models and further edited for quality control. We address
in-the-wild AIGI detection in this paper. We introduce Mirage, a challenging
benchmark designed to emulate the complexity of in-the-wild AIGI. Mirage is
constructed from two sources: (1) a large corpus of Internet-sourced AIGI
verified by human experts, and (2) a synthesized dataset created through the
collaboration between multiple expert generators, closely simulating the
realistic AIGI in the wild. Building on this benchmark, we propose Mirage-R1, a
vision-language model with heuristic-to-analytic reasoning, a reflective
reasoning mechanism for AIGI detection. Mirage-R1 is trained in two stages: a
supervised-fine-tuning cold start, followed by a reinforcement learning stage.
By further adopting an inference-time adaptive thinking strategy, Mirage-R1 is
able to provide either a quick judgment or a more robust and accurate
conclusion, effectively balancing inference speed and performance. Extensive
experiments show that our model leads state-of-the-art detectors by 5% and 10%
on Mirage and the public benchmark, respectively. The benchmark and code will
be made publicly available.

</details>


### [3] [DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool Interleaved Vision-Language Model](https://arxiv.org/abs/2508.13238)
*Qian Chen,Xianyin Zhang,Lifan Guo,Feng Chen,Chi Zhang*

Main category: cs.CV

TL;DR: DianJin-OCR-R1 通过结合自有 OCR、专家模型引用和推理来解决 LVLM 的幻觉问题，并在 OCR 任务上取得领先。


<details>
  <summary>Details</summary>
Motivation: 现有的通用大型视觉语言模型（LVLMs）在文档图像解析（如 OCR）方面表现出色，但也存在“幻觉”问题（生成图像中不存在的内容）并且不如领域特定的专家模型。本文旨在解决这些局限性。

Method: 提出了一种名为 DianJin-OCR-R1 的推理增强框架，该框架通过训练推理与工具交织的视觉语言模型（VLMs）。具体而言，模型首先利用自身的 OCR 能力识别图像内容，然后调用其他专家模型（如特定任务的 OCR 模型）获取参考结果，最后结合这些信息重新审视图像并进行推理，输出最终识别结果。

Result: 实验结果表明，DianJin-OCR-R1 模型在 ReST 和 OmniDocBench 数据集上，其性能持续优于不包含推理能力的对应模型以及现有的专家 OCR 模型，证明了该方法的有效性。

Conclusion: DianJin-OCR-R1 模型通过结合自有 OCR 能力、调用外部专家模型以及多轮推理，有效缓解了通用视觉语言模型在文档图像解析任务中的幻觉问题，并在 ReST 和 OmniDocBench 基准测试中取得了优于非推理模型和专用 OCR 模型的性能。

Abstract: Recent advances in large vision-language models (LVLMs) have enabled a new
paradigm of end-to-end document image parsing, excelling in Optical Character
Recognition (OCR) tasks such as text, table, and formula recognition. However,
generative LVLMs, similarly to large language models (LLMs), are prone to
hallucinations--generating words that do not exist in input images.
Furthermore, LVLMs are designed for general purposes and tend to be less
effective on OCR tasks compared to expert models that are trained on
domain-specific datasets. In this paper, we propose DianJin-OCR-R1, a
reasoning-enhanced framework designed to address these limitations through
training reasoning-and-tool interleaved VLMs. Given a recognition instruction,
our DianJin-OCR-R1 model first recognizes the content in the input image by its
own OCR capabilities, and then calls other tools (i.e., other expert models) to
obtain their results as references, finally looks again the image and rethinks
about the reasoning process to provide the final recognized content. Since
architectures of expert models are tailored for specific OCR tasks, which makes
them less prone to hallucinations, their results can help VLMs mitigate
hallucinations. Additionally, expert models are typically smaller in scale and
easy to iterate, enabling performance improvements for VLMs at a lower cost. We
evaluate our model on ReST and OmniDocBench, and experimental results show that
our DianJin-OCR-R1 models consistently outperform their non-reasoning
counterparts and expert OCR models, which proves the effectiveness of our
method.

</details>


### [4] [Exploration of Deep Learning Based Recognition for Urdu Text](https://arxiv.org/abs/2508.13245)
*Sumaiya Fazal,Sheeraz Ahmed*

Main category: cs.CV

TL;DR: 本文提出了一种基于卷积神经网络（CNN）的乌尔都语光学字符识别方法，通过组件分类和连通组件技术解决了乌尔都语字符识别的复杂性问题，并取得了 0.99% 的准确率。


<details>
  <summary>Details</summary>
Motivation: 由于上下文敏感性，基于分割的识别在乌尔都语中通常会导致高错误率，而我们的方法旨在解决这个问题。

Method: 本文提出了一种基于组件的分类方法，该方法依赖于称为卷积神经网络（CNN）的自动特征学习技术。CNN 在乌尔都语数据集上进行训练和测试，该数据集通过三个字符的排列过程生成，然后通过应用连通组件技术去除不必要的图像以仅获得连字。

Result: 模型在组件分类任务上实现了 0.99% 的准确率。

Conclusion: 我们的模型在组件分类方面成功达到了 0.99% 的准确率。

Abstract: Urdu is a cursive script language and has similarities with Arabic and many
other South Asian languages. Urdu is difficult to classify due to its complex
geometrical and morphological structure. Character classification can be
processed further if segmentation technique is efficient, but due to context
sensitivity in Urdu, segmentation-based recognition often results with high
error rate. Our proposed approach for Urdu optical character recognition system
is a component-based classification relying on automatic feature learning
technique called convolutional neural network. CNN is trained and tested on
Urdu text dataset, which is generated through permutation process of three
characters and further proceeds to discarding unnecessary images by applying
connected component technique in order to obtain ligature only. Hierarchical
neural network is implemented with two levels to deal with three degrees of
character permutations and component classification Our model successfully
achieved 0.99% for component classification.

</details>


### [5] [CLoE: Curriculum Learning on Endoscopic Images for Robust MES Classification](https://arxiv.org/abs/2508.13280)
*Zeynep Ozdemir,Hacer Yalim Keles,Omer Ozgur Tanriover*

Main category: cs.CV

TL;DR: CLoE课程学习框架通过处理标签噪声和有序性，提高了内窥镜图像中溃疡性结肠炎疾病严重程度的估计精度。


<details>
  <summary>Details</summary>
Motivation: 解决在评估溃疡性结肠炎疾病严重程度时，由于观察者间变异性导致的标签噪声以及标准模型忽略的评分有序性问题。

Method: 提出了一种名为CLoE的课程学习框架，利用图像质量（通过BBPS标签估计）作为注释置信度的代理来对样本进行排序，并结合ResizeMix增强技术来提高鲁棒性。

Result: 在LIMUC和HyperKvasir数据集上，CLoE框架（结合CNN和Transformer）在准确性和QWK方面持续优于基线模型。例如，ConvNeXt-Tiny在LIMUC上达到了82.5%的准确率和0.894的QWK。

Conclusion: CLoE框架通过考虑标签可靠性和有序结构，在溃疡性结肠炎的内窥镜图像中提高了疾病严重程度的估计精度，并且在LIMUC和HyperKvasir数据集上取得了优于监督和自监督基线的结果。

Abstract: Estimating disease severity from endoscopic images is essential in assessing
ulcerative colitis, where the Mayo Endoscopic Subscore (MES) is widely used to
grade inflammation. However, MES classification remains challenging due to
label noise from inter-observer variability and the ordinal nature of the
score, which standard models often ignore. We propose CLoE, a curriculum
learning framework that accounts for both label reliability and ordinal
structure. Image quality, estimated via a lightweight model trained on Boston
Bowel Preparation Scale (BBPS) labels, is used as a proxy for annotation
confidence to order samples from easy (clean) to hard (noisy). This curriculum
is further combined with ResizeMix augmentation to improve robustness.
Experiments on the LIMUC and HyperKvasir datasets, using both CNNs and
Transformers, show that CLoE consistently improves performance over strong
supervised and self-supervised baselines. For instance, ConvNeXt-Tiny reaches
82.5\% accuracy and a QWK of 0.894 on LIMUC with low computational cost. These
results highlight the potential of difficulty-aware training strategies for
improving ordinal classification under label uncertainty. Code will be released
at https://github.com/zeynepozdemir/CLoE.

</details>


### [6] [Timestep-Compressed Attack on Spiking Neural Networks through Timestep-Level Backpropagation](https://arxiv.org/abs/2508.13812)
*Donghwa Kang,Doohyun Kim,Sang-Ki Ko,Jinkyu Lee,Hyeongboo Baek,Brent ByungHoon Kang*

Main category: cs.CV

TL;DR: 提出了一种名为TCA的新框架，通过时间步压缩技术（TLBP和A-MPR）显著降低了SNN的对抗攻击延迟，同时保持了攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的对抗攻击方法（如FGSM和PGD）在SNN中存在显著的攻击延迟，因为它们需要多时间步处理，这限制了其在实际实时应用中的可行性。这是由于这些方法未能利用SNN的关键特性。

Method: TCA框架通过时间步压缩来降低攻击延迟。TLBP（时间步级别反向传播）允许在每个时间步进行评估并提前停止，而A-MPR（对抗膜电位复用）则通过预计算和复用初始时间步的膜电位来提高效率。

Result: 实验结果表明，TCA框架能够显著降低所需攻击延迟，在CIFAR-10/100和CIFAR10-DVS数据集上，与SOTA方法相比，白盒和黑盒设置下的延迟分别降低了高达56.6%和57.1%，同时攻击成功率保持相当。

Conclusion: 该研究提出的TCA框架通过TLBP和A-MPR组件，有效解决了现有基于梯度的对抗攻击在SNN中存在的延迟问题，相比SOTA方法在白盒和黑盒设置下分别将攻击延迟降低了高达56.6%和57.1%，同时保持了相当的攻击成功率。

Abstract: State-of-the-art (SOTA) gradient-based adversarial attacks on spiking neural
networks (SNNs), which largely rely on extending FGSM and PGD frameworks, face
a critical limitation: substantial attack latency from multi-timestep
processing, rendering them infeasible for practical real-time applications.
This inefficiency stems from their design as direct extensions of ANN
paradigms, which fail to exploit key SNN properties. In this paper, we propose
the timestep-compressed attack (TCA), a novel framework that significantly
reduces attack latency. TCA introduces two components founded on key insights
into SNN behavior. First, timestep-level backpropagation (TLBP) is based on our
finding that global temporal information in backpropagation to generate
perturbations is not critical for an attack's success, enabling per-timestep
evaluation for early stopping. Second, adversarial membrane potential reuse
(A-MPR) is motivated by the observation that initial timesteps are
inefficiently spent accumulating membrane potential, a warm-up phase that can
be pre-calculated and reused. Our experiments on VGG-11 and ResNet-17 with the
CIFAR-10/100 and CIFAR10-DVS datasets show that TCA significantly reduces the
required attack latency by up to 56.6% and 57.1% compared to SOTA methods in
white-box and black-box settings, respectively, while maintaining a comparable
attack success rate.

</details>


### [7] [GaitCrafter: Diffusion Model for Biometric Preserving Gait Synthesis](https://arxiv.org/abs/2508.13300)
*Sirshapan Mitra,Yogesh S. Rawat*

Main category: cs.CV

TL;DR: GaitCrafter 是一个利用扩散模型合成步态序列的框架，可提高步态识别性能并生成新的、注重隐私的身份。


<details>
  <summary>Details</summary>
Motivation: 步态识别虽然有价值，但受限于大规模标记数据集的缺乏以及在保护隐私的前提下收集多样化步态样本的难度。为了解决这些问题，需要新的方法来生成高质量、可控且注重隐私的步态数据。

Method: 提出了一种名为 GaitCrafter 的扩散模型框架，专门用于在轮廓域中合成真实的步态序列。该模型从头开始训练，仅使用步态轮廓数据，能够生成时间上一致且保留身份信息的步态序列，并且可以通过服装、携带物品和视角等协变量进行控制。此外，还通过插值身份嵌入来生成不存在于原始数据集中的新身份。

Result: GaitCrafter 生成的合成样本在步态识别任务中，尤其是在挑战性条件下，能够提升模型的性能。生成的新身份具有独特且一致的步态模式，可用于模型训练，同时保护了真实个体的隐私。

Conclusion: GaitCrafter 是一个用于合成真实步态序列的扩散模型框架，它通过生成的数据提高了步态识别的性能，并引入了生成新身份的机制，以在保护隐私的同时进行模型训练。

Abstract: Gait recognition is a valuable biometric task that enables the identification
of individuals from a distance based on their walking patterns. However, it
remains limited by the lack of large-scale labeled datasets and the difficulty
of collecting diverse gait samples for each individual while preserving
privacy. To address these challenges, we propose GaitCrafter, a diffusion-based
framework for synthesizing realistic gait sequences in the silhouette domain.
Unlike prior works that rely on simulated environments or alternative
generative models, GaitCrafter trains a video diffusion model from scratch,
exclusively on gait silhouette data. Our approach enables the generation of
temporally consistent and identity-preserving gait sequences. Moreover, the
generation process is controllable-allowing conditioning on various covariates
such as clothing, carried objects, and view angle. We show that incorporating
synthetic samples generated by GaitCrafter into the gait recognition pipeline
leads to improved performance, especially under challenging conditions.
Additionally, we introduce a mechanism to generate novel identities-synthetic
individuals not present in the original dataset-by interpolating identity
embeddings. These novel identities exhibit unique, consistent gait patterns and
are useful for training models while maintaining privacy of real subjects.
Overall, our work takes an important step toward leveraging diffusion models
for high-quality, controllable, and privacy-aware gait data generation.

</details>


### [8] [Prune2Drive: A Plug-and-Play Framework for Accelerating Vision-Language Models in Autonomous Driving](https://arxiv.org/abs/2508.13305)
*Minhao Xiong,Zichen Wen,Zhuangcheng Gu,Xuyang Liu,Rui Zhang,Hengrui Kang,Jiabing Yang,Junyuan Zhang,Weijia Li,Conghui He,Yafei Wang,Linfeng Zhang*

Main category: cs.CV

TL;DR: Prune2Drive通过选择性地修剪视觉标记来加速多视图自动驾驶VLM，实现了显著的速度和内存效率提升，同时保持了性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中的视觉语言模型（VLM）面临显著的计算开销问题，尤其是在处理高分辨率、多视图图像时。这是由于编码过程中产生的视觉标记数量庞大，以及自注意力机制的二次复杂度，导致推理延迟和内存消耗增加。

Method: Prune2Drive框架引入了两种核心创新：1. 多样性感知的标记选择机制：受最远点采样启发，优先考虑视图间的语义和空间覆盖，而非仅依赖注意力分数。2. 视图自适应的修剪控制器：根据每个摄像头视图对下游驾驶任务的重要性，学习最优的修剪比例。该方法无需重新训练模型或访问注意力图，兼容现代高效的注意力实现。

Result: 在DriveLM和DriveLMM-o1这两个大规模多视图驾驶基准上进行的大量实验表明，Prune2Drive在保持或提高任务性能的同时，实现了显著的速度提升和内存节省。具体而言，当仅保留10%的视觉标记时，该方法在DriveLM基准测试中实现了6.40倍的预填充速度提升，消耗了原始计算量的13.4%，并且性能仅下降3%。

Conclusion: Prune2Drive是一个即插即用的视觉标记修剪框架，适用于多视图自动驾驶VLM。通过采用一种多样性感知的标记选择机制和一种视图自适应的修剪控制器，该方法能够有效减少计算开销，同时保持甚至提高性能。实验证明，即使只保留10%的视觉标记，Prune2Drive也能在DriveLM基准测试中实现6.40倍的预填充速度提升，仅消耗原始计算量的13.4%，性能下降仅为3%。

Abstract: Vision-Language Models (VLMs) have emerged as a promising paradigm in
autonomous driving (AD), offering a unified framework for perception,
reasoning, and decision-making by jointly modeling visual inputs and natural
language instructions. However, their deployment is hindered by the significant
computational overhead incurred when processing high-resolution, multi-view
images, a standard setup in AD systems with six or more synchronized cameras.
This overhead stems from the large number of visual tokens generated during
encoding, increasing inference latency and memory consumption due to the
quadratic complexity of self-attention. To address these challenges, we propose
Prune2Drive, a plug-and-play visual token pruning framework for multi-view VLMs
in autonomous driving. Prune2Drive introduces two core innovations: (i) a
diversity-aware token selection mechanism inspired by farthest point sampling,
which prioritizes semantic and spatial coverage across views rather than
relying solely on attention scores, and (ii) a view-adaptive pruning controller
that learns optimal pruning ratios for each camera view based on their
importance to downstream driving tasks. Unlike prior methods, Prune2Drive does
not require model retraining or access to attention maps, making it compatible
with modern efficient attention implementations. Extensive experiments on two
large-scale multi-view driving benchmarks, DriveLM and DriveLMM-o1, show that
Prune2Drive achieves significant speedups and memory savings while maintaining
or improving task performance. When retaining only 10% of the visual tokens,
our method achieves a 6.40$\times$ speedup in the prefilling phase and consumes
13.4% of the original FLOPs, with only a 3% performance drop on the DriveLM
benchmark.

</details>


### [9] [DAASH: A Meta-Attack Framework for Synthesizing Effective and Stealthy Adversarial Examples](https://arxiv.org/abs/2508.13309)
*Abdullah Al Nomaan Nafi,Habibur Rahaman,Zafaryab Haider,Tanzim Mahfuz,Fnu Suya,Swarup Bhunia,Prabuddha Chakraborty*

Main category: cs.CV

TL;DR: DAASH通过组合Lp攻击方法，生成符合人类感知的对抗性样本，效果优于现有方法，且能泛化到未知防御。


<details>
  <summary>Details</summary>
Motivation: 尽管在白盒设置下存在多种生成Lp范数约束的对抗样本的技术，但这些样本往往与人类感知不匹配。虽然最近有一些方法开始专门探索符合感知的对抗性样本，但尚不清楚是否可以将Lp约束攻击的见解有效用于提高感知效果。

Method: DAASH通过一个多阶段的框架运作：在每个阶段，它利用学习到的自适应权重聚合多个基础攻击生成的候选对抗样本，并将结果传递到下一阶段。一个新颖的元损失函数通过联合最小化误分类损失和感知失真来指导这一过程，使框架能够在不同阶段动态调节每个基础攻击的贡献。

Result: DAASH在对抗性训练的模型上，显著优于State-of-the-art感知攻击（如AdvAD），在攻击成功率上提升了20.63%，在视觉质量（SSIM、LPIPS、FID）上分别提升了约11、0.015和5.7。

Conclusion: DAASH是一个完全可微分的元攻击框架，通过组合现有的基于Lp的攻击方法，生成有效且符合感知规律的对抗性样本。该框架在CIFAR-10、CIFAR-100和ImageNet上进行了评估，在对抗性训练的模型上，DAASH显著优于AdvAD等先进的感知攻击方法，实现了更高的攻击成功率（例如，提高了20.63%）和更好的视觉质量（在SSIM、LPIPS和FID方面分别提高了约11、0.015和5.7）。此外，DAASH能够很好地泛化到未知的防御机制，为评估鲁棒性提供了一个实用且强大的基线，而无需为每个新的防御机制手工设计自适应攻击。

Abstract: Numerous techniques have been proposed for generating adversarial examples in
white-box settings under strict Lp-norm constraints. However, such norm-bounded
examples often fail to align well with human perception, and only recently have
a few methods begun specifically exploring perceptually aligned adversarial
examples. Moreover, it remains unclear whether insights from Lp-constrained
attacks can be effectively leveraged to improve perceptual efficacy. In this
paper, we introduce DAASH, a fully differentiable meta-attack framework that
generates effective and perceptually aligned adversarial examples by
strategically composing existing Lp-based attack methods. DAASH operates in a
multi-stage fashion: at each stage, it aggregates candidate adversarial
examples from multiple base attacks using learned, adaptive weights and
propagates the result to the next stage. A novel meta-loss function guides this
process by jointly minimizing misclassification loss and perceptual distortion,
enabling the framework to dynamically modulate the contribution of each base
attack throughout the stages. We evaluate DAASH on adversarially trained models
across CIFAR-10, CIFAR-100, and ImageNet. Despite relying solely on
Lp-constrained based methods, DAASH significantly outperforms state-of-the-art
perceptual attacks such as AdvAD -- achieving higher attack success rates
(e.g., 20.63\% improvement) and superior visual quality, as measured by SSIM,
LPIPS, and FID (improvements $\approx$ of 11, 0.015, and 5.7, respectively).
Furthermore, DAASH generalizes well to unseen defenses, making it a practical
and strong baseline for evaluating robustness without requiring handcrafted
adaptive attacks for each new defense.

</details>


### [10] [RED.AI Id-Pattern: First Results of Stone Deterioration Patterns with Multi-Agent Systems](https://arxiv.org/abs/2508.13872)
*Daniele Corradetti,José Delgado Rodrigues*

Main category: cs.CV

TL;DR: AI驱动的多智能体系统，通过模拟专家协作，比传统方法更有效地识别石材劣化模式。


<details>
  <summary>Details</summary>
Motivation: 为了克服传统基于专家直接观察的石材劣化模式识别方法耗时耗资源的缺点，旨在开发一种能够模拟专家协作并自动诊断石材病害的AI系统。

Method: 开发了一个基于认知架构的多智能体人工智能系统，该系统包含五个专业智能体：岩石学家、病理学家、环境专家、修复师和诊断协调员，用于分析石材劣化模式。

Result: 在28张包含多种劣化模式的复杂石材图像上进行了评估，实验结果显示该系统在所有评估指标上均有大幅度提升。

Conclusion: 该系统通过模拟专家协作和自动化诊断石材病害，在所有指标上相比基础模型都有显著提升。

Abstract: The Id-Pattern system within the RED.AI project (Reabilita\c{c}\~ao
Estrutural Digital atrav\'es da AI) consists of an agentic system designed to
assist in the identification of stone deterioration patterns. Traditional
methodologies, based on direct observation by expert teams, are accurate but
costly in terms of time and resources. The system developed here introduces and
evaluates a multi-agent artificial intelligence (AI) system, designed to
simulate collaboration between experts and automate the diagnosis of stone
pathologies from visual evidence. The approach is based on a cognitive
architecture that orchestrates a team of specialized AI agents which, in this
specific case, are limited to five: a lithologist, a pathologist, an
environmental expert, a conservator-restorer, and a diagnostic coordinator. To
evaluate the system we selected 28 difficult images involving multiple
deterioration patterns. Our first results showed a huge boost on all metrics of
our system compared to the foundational model.

</details>


### [11] [Automated Assessment of Aesthetic Outcomes in Facial Plastic Surgery](https://arxiv.org/abs/2508.13363)
*Pegah Varghaei,Kiran Abraham-Aggarwal,Manoj T. Abraham,Arun Ross*

Main category: cs.CV

TL;DR: 这项研究介绍了一个用于评估面部整形手术结果的计算机视觉框架，该框架使用7160张照片的数据集，并展示了在对称性、年龄和鼻部测量方面的显著改善。


<details>
  <summary>Details</summary>
Motivation: 引入一个可扩展、可解释的计算机视觉框架，利用人脸正面照片量化面部整形手术的美学结果。

Method: 该框架利用自动地标检测、面部几何对称性计算、基于深度学习的年龄估计和鼻部形态分析，这是一个可扩展、可解释的计算机视觉框架。

Result: 在针对鼻整形手术的子集中，96.2%的患者在至少一项鼻部测量中有所改善。在更广泛的正面视图队列中，71.3%的患者在全局面部对称性或感知年龄方面有显著改善。此外，该分析显示患者身份在术后保持一致，准确率为99.5%和99.6%。

Conclusion: 该框架通过提供可复现、量化的基准和新颖的数据集，能够促进跨实践的数据驱动的手术规划、患者咨询和客观结果评估。

Abstract: We introduce a scalable, interpretable computer-vision framework for
quantifying aesthetic outcomes of facial plastic surgery using frontal
photographs. Our pipeline leverages automated landmark detection, geometric
facial symmetry computation, deep-learning-based age estimation, and nasal
morphology analysis. To perform this study, we first assemble the largest
curated dataset of paired pre- and post-operative facial images to date,
encompassing 7,160 photographs from 1,259 patients. This dataset includes a
dedicated rhinoplasty-only subset consisting of 732 images from 366 patients,
96.2% of whom showed improvement in at least one of the three nasal
measurements with statistically significant group-level change. Among these
patients, the greatest statistically significant improvements (p < 0.001)
occurred in the alar width to face width ratio (77.0%), nose length to face
height ratio (41.5%), and alar width to intercanthal ratio (39.3%). Among the
broader frontal-view cohort, comprising 989 rigorously filtered subjects, 71.3%
exhibited significant enhancements in global facial symmetry or perceived age
(p < 0.01). Importantly, our analysis shows that patient identity remains
consistent post-operatively, with True Match Rates of 99.5% and 99.6% at a
False Match Rate of 0.01% for the rhinoplasty-specific and general patient
cohorts, respectively. Additionally, we analyze inter-practitioner variability
in improvement rates. By providing reproducible, quantitative benchmarks and a
novel dataset, our pipeline facilitates data-driven surgical planning, patient
counseling, and objective outcome evaluation across practices.

</details>


### [12] [Applications of Small Language Models in Medical Imaging Classification with a Focus on Prompt Strategies](https://arxiv.org/abs/2508.13378)
*Yiting Wang,Ziwei Wang,Jiachen Zhong,Di Zhu,Weiyi Li*

Main category: cs.CV

TL;DR: 小型语言模型（SLM）通过优化提示，在医学影像分类任务中表现出色，为医疗领域提供了更易及、更注重隐私的AI解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型（LLM）在资源受限的医疗环境中面临的计算成本高、可及性有限和数据隐私等问题，本研究旨在探索小型语言模型（SLM）在医学影像分类任务中的性能。

Method: 本研究使用NIH胸部X光数据集，在三种提示策略下（基线指令、渐进式摘要提示、基于校正的反射式提示）评估了多种小型语言模型（SLM）在胸部X光片位置（AP vs. PA）分类任务上的表现。

Result: 结果表明，某些SLM在采用精心设计的提示时，能够获得具有竞争力的准确率，表明提示工程可以显著提高SLM在医疗应用中的性能。

Conclusion: 小型语言模型（SLM）在医学影像分类任务中，通过精心设计的提示（prompt），可以达到与大型语言模型（LLM）相媲美的准确性，证明了提示工程在医疗应用中提升SLM性能的潜力，且无需用户具备深厚的AI知识。

Abstract: Large language models (LLMs) have shown remarkable capabilities in natural
language processing and multi-modal understanding. However, their high
computational cost, limited accessibility, and data privacy concerns hinder
their adoption in resource-constrained healthcare environments. This study
investigates the performance of small language models (SLMs) in a medical
imaging classification task, comparing different models and prompt designs to
identify the optimal combination for accuracy and usability. Using the NIH
Chest X-ray dataset, we evaluate multiple SLMs on the task of classifying chest
X-ray positions (anteroposterior [AP] vs. posteroanterior [PA]) under three
prompt strategies: baseline instruction, incremental summary prompts, and
correction-based reflective prompts. Our results show that certain SLMs achieve
competitive accuracy with well-crafted prompts, suggesting that prompt
engineering can substantially enhance SLM performance in healthcare
applications without requiring deep AI expertise from end users.

</details>


### [13] [AIM 2025 Rip Current Segmentation (RipSeg) Challenge Report](https://arxiv.org/abs/2508.13401)
*Andrei Dumitriu,Florin Miron,Florin Tatui,Radu Tudor Ionescu,Radu Timofte,Aakash Ralhan,Florin-Alexandru Vasluianu,Shenyang Qian,Mitchell Harley,Imran Razzak,Yang Song,Pu Luo,Yumei Li,Cong Xu,Jinming Chai,Kexin Zhang,Licheng Jiao,Lingling Li,Siqi Yu,Chao Zhang,Kehuan Song,Fang Liu,Puhua Chen,Xu Liu,Jin Hu,Jinyang Xu,Biao Liu*

Main category: cs.CV

TL;DR: AIM 2025 RipSeg挑战赛旨在推进溺水流分割技术，比赛在RipVIS数据集上进行，评估指标包括F1、F2、AP50和AP[50:95]，顶尖方法采用了深度学习技术。


<details>
  <summary>Details</summary>
Motivation: 溺水流是一种危险的快速流动，对全球海滩安全构成重大威胁，因此准确的视觉检测是一项重要且探索不足的研究任务。

Method: 该竞赛基于RipVIS数据集，专注于单类实例分割，并采用结合F1、F2、AP50和AP[50:95]的综合评分作为评估指标。

Result: 75名参赛者注册，5个有效提交，竞赛展示了利用深度学习、域适应、预训练模型和域泛化策略的方法在溺水流分割任务上的性能。

Conclusion: AIM 2025 RipSeg挑战赛促进了静止图像中自动溺水流分割技术的发展，顶尖方法利用了深度学习架构、域适应技术、预训练模型和域泛化策略来提高在各种条件下的性能。

Abstract: This report presents an overview of the AIM 2025 RipSeg Challenge, a
competition designed to advance techniques for automatic rip current
segmentation in still images. Rip currents are dangerous, fast-moving flows
that pose a major risk to beach safety worldwide, making accurate visual
detection an important and underexplored research task. The challenge builds on
RipVIS, the largest available rip current dataset, and focuses on single-class
instance segmentation, where precise delineation is critical to fully capture
the extent of rip currents. The dataset spans diverse locations, rip current
types, and camera orientations, providing a realistic and challenging
benchmark.
  In total, $75$ participants registered for this first edition, resulting in
$5$ valid test submissions. Teams were evaluated on a composite score combining
$F_1$, $F_2$, $AP_{50}$, and $AP_{[50:95]}$, ensuring robust and
application-relevant rankings. The top-performing methods leveraged deep
learning architectures, domain adaptation techniques, pretrained models, and
domain generalization strategies to improve performance under diverse
conditions.
  This report outlines the dataset details, competition framework, evaluation
metrics, and final results, providing insights into the current state of rip
current segmentation. We conclude with a discussion of key challenges, lessons
learned from the submissions, and future directions for expanding RipSeg.

</details>


### [14] [Mitigating Easy Option Bias in Multiple-Choice Question Answering](https://arxiv.org/abs/2508.13428)
*Hao Zhang,Chen Li,Basura Fernando*

Main category: cs.CV

TL;DR: 该研究发现了视觉问答中的Easy-Options Bias（EOB）问题，即模型能不看问题仅凭图像和选项选出答案。研究提出了GroundAttack工具来生成更具挑战性的选项，并在新标注的数据集上验证了其有效性，为模型评估提供了更可靠的基准。


<details>
  <summary>Details</summary>
Motivation: 在多个多项选择视觉问答基准中发现Easy-Options Bias (EOB)问题，即模型能够仅通过视觉信息和选项（V+O）而非问题（Q）来选择正确答案，这影响了模型评估的真实性。

Method: 提出GroundAttack工具包，自动生成视觉上与正确答案相似的干扰选项，并将其应用于NExT-QA和MMStar数据集，创建了EOB-free标注。

Result: 通过GroundAttack生成的EOB-free标注，现有模型在仅使用视觉和选项（V+O）的情况下准确率接近随机水平，在同时使用视觉、问题和选项（V+Q+O）时准确率有所下降，表明新标注能更真实地评估模型的问答能力。

Conclusion: 研究发现多种多项选择视觉问答基准中存在Easy-Options Bias (EOB)问题，即模型仅凭视觉信息和选项即可选出正确答案，无需问题。EOB源于视觉相关性的不平衡，正确答案比错误选项更贴近视觉内容。为解决此问题，研究提出了GroundAttack工具包，可自动生成与正确答案视觉上相似的干扰选项。在NExT-QA和MMStar数据集上应用GroundAttack生成EOB-free标注后，现有模型在仅使用视觉和选项（V+O）时准确率接近随机水平，在使用视觉、问题和选项（V+Q+O）时准确率下降，为模型QA能力提供了更真实的评估。

Abstract: In this early study, we observe an Easy-Options Bias (EOB) issue in some
multiple-choice Visual Question Answering (VQA) benchmarks such as MMStar,
RealWorldQA, SEED-Bench, Next-QA, STAR benchmark and Video-MME. This bias
allows vision-language models (VLMs) to select the correct answer using only
the vision (V) and options (O) as inputs, without the need for the question
(Q). Through grounding experiments, we attribute the bias to an imbalance in
visual relevance: the correct answer typically aligns more closely with the
visual contents than the negative options in feature space, creating a shortcut
for VLMs to infer the answer via simply vision-option similarity matching. To
fix this, we introduce GroundAttack, a toolkit that automatically generates
hard negative options as visually plausible as the correct answer. We apply it
to the NExT-QA and MMStar datasets, creating new EOB-free annotations. On these
EOB-free annotations, current VLMs approach to random accuracies under (V+O)
settings, and drop to non-saturated accuracies under (V+Q+O) settings,
providing a more realistic evaluation of VLMs' QA ability. Codes and new
annotations will be released soon.

</details>


### [15] [Structured Prompting and Multi-Agent Knowledge Distillation for Traffic Video Interpretation and Risk Inference](https://arxiv.org/abs/2508.13439)
*Yunxiang Yang,Ningning Xu,Jidong J. Yang*

Main category: cs.CV

TL;DR: 一种新的框架利用大型模型（如GPT-4o）生成交通场景和风险的详细描述（伪标注），然后用这些描述来训练一个非常小的模型（VISTA）。结果是VISTA虽然小，但效果很好，能理解低分辨率视频并进行风险评估，适合在手机等设备上使用。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法在复杂多变的真实交通环境中面临的可扩展性和泛化性挑战，并推动智能交通系统（ITS）和自动驾驶技术的发展，本研究旨在实现全面的高速公路场景理解和鲁棒的交通风险推断。

Method: 本研究提出了一种创新的结构化提示和知识蒸馏框架，用于交通场景理解和风险评估。该框架利用两个大型视觉语言模型（VLMs）——GPT-4o和o3-mini——通过结构化的思维链（CoT）策略生成详细的多视角场景描述和风险评估。这些生成的描述被用作“伪标注”，对一个规模更小的学生VLM进行监督微调。最终的学生模型VISTA（规模为3B）能够理解低分辨率交通视频并生成语义准确、具备风险意识的描述。

Result: 研究成功开发了一个名为VISTA的紧凑型（3B参数）视觉语言模型，该模型在接收了通过结构化提示和知识蒸馏框架生成的伪标注后，即使在处理低分辨率交通视频时，也能实现强大的场景理解和风险感知能力。VISTA在BLEU-4、METEOR、ROUGE-L和CIDEr等标准描述指标上取得了与教师模型相媲美的性能，证明了知识蒸馏和多智能体监督在赋予轻量级模型复杂推理能力方面的有效性。其紧凑的架构也便于在边缘设备上部署，支持实时风险监控。

Conclusion: 该研究展示了一种创新的结构化提示和知识蒸馏框架，能够自动生成高质量的交通场景标注和风险评估。通过利用大型视觉语言模型（VLMs）如GPT-4o和o3-mini，并结合结构化思维链（CoT）策略，可以产生丰富的多视角输出。这些输出随后被用作监督信号，以微调一个规模更小的学生VLM。研究表明，即使参数量大大减少，经过知识蒸馏和结构化多智能体监督训练的轻量级VLM（如VISTA）也能展现出强大的场景理解和风险感知能力，其性能可与教师模型相媲美。VISTA的紧凑架构使其能够高效地部署在边缘设备上，为实时风险监控提供了可行方案，无需大规模的基础设施升级。

Abstract: Comprehensive highway scene understanding and robust traffic risk inference
are vital for advancing Intelligent Transportation Systems (ITS) and autonomous
driving. Traditional approaches often struggle with scalability and
generalization, particularly under the complex and dynamic conditions of
real-world environments. To address these challenges, we introduce a novel
structured prompting and knowledge distillation framework that enables
automatic generation of high-quality traffic scene annotations and contextual
risk assessments. Our framework orchestrates two large Vision-Language Models
(VLMs): GPT-4o and o3-mini, using a structured Chain-of-Thought (CoT) strategy
to produce rich, multi-perspective outputs. These outputs serve as
knowledge-enriched pseudo-annotations for supervised fine-tuning of a much
smaller student VLM. The resulting compact 3B-scale model, named VISTA (Vision
for Intelligent Scene and Traffic Analysis), is capable of understanding
low-resolution traffic videos and generating semantically faithful, risk-aware
captions. Despite its significantly reduced parameter count, VISTA achieves
strong performance across established captioning metrics (BLEU-4, METEOR,
ROUGE-L, and CIDEr) when benchmarked against its teacher models. This
demonstrates that effective knowledge distillation and structured multi-agent
supervision can empower lightweight VLMs to capture complex reasoning
capabilities. The compact architecture of VISTA facilitates efficient
deployment on edge devices, enabling real-time risk monitoring without
requiring extensive infrastructure upgrades.

</details>


### [16] [EDTalk++: Full Disentanglement for Controllable Talking Head Synthesis](https://arxiv.org/abs/2508.13442)
*Shuai Tan,Bin Ji*

Main category: cs.CV

TL;DR: EDTalk++框架通过四个解耦的潜在空间（口型、姿态、眼球、表情）实现了可控的谈话头像生成，支持视频和音频输入，并确保了运动的独立性和跨模态共享。


<details>
  <summary>Details</summary>
Motivation: 为了实现对多种面部运动的解耦控制，并兼容不同的输入模态，从而提升谈话头像生成在应用和娱乐方面的潜力。现有方法在解耦面部特征空间方面存在不足，未能保证特征的独立操作而不相互干扰，也未能有效实现跨模态的特征共享。

Method: EDTalk++框架采用四个轻量级模块，将面部动态分解为四个独立的潜在空间：口型、姿态、眼球和表情。每个空间都由一组可学习的基组成，通过线性组合来定义特定的运动。为了确保独立性和加速训练，在基之间强制执行正交性，并设计了一种无需外部知识即可分配运动职责的高效训练策略。学习到的基存储在相应的库中，以实现与音频输入的共享视觉先验。此外，还提出了一个音频到运动模块，用于音频驱动的谈话头像合成。

Result: 实验证明了EDTalk++在解耦控制和跨模态兼容性方面的有效性。

Conclusion: EDTalk++是一个新颖的、可控的谈话头像生成框架，实现了口型、头部姿态、眼球运动和表情的完全解耦控制，并且能够兼容多种输入模态。

Abstract: Achieving disentangled control over multiple facial motions and accommodating
diverse input modalities greatly enhances the application and entertainment of
the talking head generation. This necessitates a deep exploration of the
decoupling space for facial features, ensuring that they a) operate
independently without mutual interference and b) can be preserved to share with
different modal inputs, both aspects often neglected in existing methods. To
address this gap, this paper proposes EDTalk++, a novel full disentanglement
framework for controllable talking head generation. Our framework enables
individual manipulation of mouth shape, head pose, eye movement, and emotional
expression, conditioned on video or audio inputs. Specifically, we employ four
lightweight modules to decompose the facial dynamics into four distinct latent
spaces representing mouth, pose, eye, and expression, respectively. Each space
is characterized by a set of learnable bases whose linear combinations define
specific motions. To ensure independence and accelerate training, we enforce
orthogonality among bases and devise an efficient training strategy to allocate
motion responsibilities to each space without relying on external knowledge.
The learned bases are then stored in corresponding banks, enabling shared
visual priors with audio input. Furthermore, considering the properties of each
space, we propose an Audio-to-Motion module for audio-driven talking head
synthesis. Experiments are conducted to demonstrate the effectiveness of
EDTalk++.

</details>


### [17] [Revisiting MLLM Token Technology through the Lens of Classical Visual Coding](https://arxiv.org/abs/2508.13460)
*Jinming Liu,Junyan Lin,Yuntao Wei,Kele Shao,Keda Tao,Jianguo Huang,Xudong Yang,Zhibo Chen,Huan Wang,Xin Jin*

Main category: cs.CV

TL;DR: 本论文将视觉编码的原理应用于MLLM的token技术，进行了全面的技术比较，提出了双向见解，并展望了未来研究方向，旨在同时提升多模态模型和视觉编解码器的性能。


<details>
  <summary>Details</summary>
Motivation: 经典视觉编码和多模态大语言模型（MLLM）的token技术在最大化信息保真度并最小化计算成本的核心目标上具有共通之处。

Method: 通过借鉴视觉编码领域的成熟原理，重新审视了MLLM的token技术（包括tokenization、token压缩和token推理），（1）建立了连接token技术和视觉编码的统一公式，实现了系统性的、模块化的比较分析；（2）融合了双向的见解，探索了视觉编码原理如何增强MLLM token技术的效率和鲁棒性，以及token技术范式如何为下一代语义视觉编解码器的设计提供思路；（3）展望了有前景的未来研究方向和关键未解挑战。

Result: 本研究通过将MLLM的token技术与视觉编码的原理相结合，为提升模型效率和设计更强大的视觉编解码器提供了新的途径和见解。

Conclusion: 本研究首次对多模态大语言模型（MLLM）的token技术和视觉编码进行了全面且结构化的技术比较，旨在为更高效的多模态模型和更强大的视觉编解码器铺平道路。

Abstract: Classical visual coding and Multimodal Large Language Model (MLLM) token
technology share the core objective - maximizing information fidelity while
minimizing computational cost. Therefore, this paper reexamines MLLM token
technology, including tokenization, token compression, and token reasoning,
through the established principles of long-developed visual coding area. From
this perspective, we (1) establish a unified formulation bridging token
technology and visual coding, enabling a systematic, module-by-module
comparative analysis; (2) synthesize bidirectional insights, exploring how
visual coding principles can enhance MLLM token techniques' efficiency and
robustness, and conversely, how token technology paradigms can inform the
design of next-generation semantic visual codecs; (3) prospect for promising
future research directions and critical unsolved challenges. In summary, this
study presents the first comprehensive and structured technology comparison of
MLLM token and visual coding, paving the way for more efficient multimodal
models and more powerful visual codecs simultaneously.

</details>


### [18] [Vision Transformers for Kidney Stone Image Classification: A Comparative Study with CNNs](https://arxiv.org/abs/2508.13461)
*Ivan Reyes-Amezcua,Francisco Lopez-Tiro,Clement Larose,Andres Mendez-Vazquez,Gilberto Ochoa-Ruiz,Christian Daul*

Main category: cs.CV

TL;DR: Vision Transformer (ViT) 在肾结石图像分类方面优于 CNN，在复杂成像条件下具有更高的准确率和 F1 分数。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络 (CNN) 在捕捉长程依赖关系方面能力有限，这可能会影响在不同成像条件下的性能。本研究旨在评估 Vision Transformer (ViT) 在肾结石图像分类任务中的表现。

Method: 本研究比较了 Vision Transformer (ViT) 和基于 CNN 的模型（如 ResNet50）在处理内窥镜图像以进行肾结石分类任务时的性能。

Result: 在两个离体数据集（包括 CCD 相机和柔性输尿管镜图像）上，ViT-base 模型（在 ImageNet-21k 上预训练）的性能始终优于 ResNet50 基线。在视觉复杂度最高的子集（内窥镜图像的节段斑块）中，ViT 的准确率达到 95.2%，F1 分数达到 95.1%，而 ResNet50 分别为 64.5% 和 59.3%。在 CCD 相机图像的混合视图子集中，ViT 的准确率为 87.1%，而 CNN 为 78.4%。

Conclusion: Vision Transformer (ViT) 优于卷积神经网络 (CNN)，在肾结石图像分类任务中表现出更优越的性能和可扩展性。

Abstract: Kidney stone classification from endoscopic images is critical for
personalized treatment and recurrence prevention. While convolutional neural
networks (CNNs) have shown promise in this task, their limited ability to
capture long-range dependencies can hinder performance under variable imaging
conditions. This study presents a comparative analysis between Vision
Transformers (ViTs) and CNN-based models, evaluating their performance on two
ex vivo datasets comprising CCD camera and flexible ureteroscope images. The
ViT-base model pretrained on ImageNet-21k consistently outperformed a ResNet50
baseline across multiple imaging conditions. For instance, in the most visually
complex subset (Section patches from endoscopic images), the ViT model achieved
95.2% accuracy and 95.1% F1-score, compared to 64.5% and 59.3% with ResNet50.
In the mixed-view subset from CCD-camera images, ViT reached 87.1% accuracy
versus 78.4% with CNN. These improvements extend across precision and recall as
well. The results demonstrate that ViT-based architectures provide superior
classification performance and offer a scalable alternative to conventional
CNNs for kidney stone image analysis.

</details>


### [19] [STER-VLM: Spatio-Temporal With Enhanced Reference Vision-Language Models](https://arxiv.org/abs/2508.13470)
*Tinh-Anh Nguyen-Nhu,Triet Dao Hoang Minh,Dat To-Thanh,Phuc Le-Gia,Tuan Vo-Lan,Tien-Huy Nguyen*

Main category: cs.CV

TL;DR: 本研究提出了STER-VLM，一个计算高效的框架，通过解耦、帧选择、参考驱动理解和提示技术，提升了视觉语言模型在交通分析中的性能，并在AI City Challenge 2025 Track 2中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 当前的VLM在交通分析方面虽然强大，但需要大量计算资源，并且在细粒度的时空理解方面存在不足。本研究旨在提出一个计算高效的框架，以增强VLM在交通分析中的性能。

Method: (1) 标题分解，分别处理空间和时间信息；(2) 时间帧选择和最佳视图过滤，以获取足够的时间信息；(3) 参考驱动的理解，以捕捉细粒度的运动和动态上下文；(4) 精心设计的视觉/文本提示技术。

Result: 在WTS和BDD数据集上，STER-VLM在语义丰富性和交通场景解释方面取得了显著的提升。在AI City Challenge 2025 Track 2中，我们的框架取得了55.655分，验证了其在推进资源高效且准确的交通分析方面的有效性。

Conclusion: STER-VLM框架通过解耦、帧选择、参考驱动理解和精心设计的提示技术，实现了高效且准确的交通分析，并在AI City Challenge 2025 Track 2中取得了55.655分，证明了其在实际应用中的有效性。

Abstract: Vision-language models (VLMs) have emerged as powerful tools for enabling
automated traffic analysis; however, current approaches often demand
substantial computational resources and struggle with fine-grained
spatio-temporal understanding. This paper introduces STER-VLM, a
computationally efficient framework that enhances VLM performance through (1)
caption decomposition to tackle spatial and temporal information separately,
(2) temporal frame selection with best-view filtering for sufficient temporal
information, and (3) reference-driven understanding for capturing fine-grained
motion and dynamic context and (4) curated visual/textual prompt techniques.
Experimental results on the WTS \cite{kong2024wts} and BDD \cite{BDD} datasets
demonstrate substantial gains in semantic richness and traffic scene
interpretation. Our framework is validated through a decent test score of
55.655 in the AI City Challenge 2025 Track 2, showing its effectiveness in
advancing resource-efficient and accurate traffic analysis for real-world
applications.

</details>


### [20] [MINR: Efficient Implicit Neural Representations for Multi-Image Encoding](https://arxiv.org/abs/2508.13471)
*Wenyong Zhou,Taiqiang Wu,Zhengwu Liu,Yuxin Cheng,Chen Zhang,Ngai Wong*

Main category: cs.CV

TL;DR: MINR通过共享中间层和添加投影层来高效编码多图像，节省参数并保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统的为每个图像使用单独的神经网络（通常是多层感知器（MLP））的隐式神经表示（INR）在编码多图像时会导致计算和存储效率低下。MINR旨在解决此问题，通过共享特定层来高效地编码多图像。

Method: MINR首先比较了几个训练过的INR的逐层权重分布，发现相应的中间层遵循高度相似的分布模式。受此启发，MINR在共享这些中间层，同时保留输入和输出层作为输入特定的。此外，MINR为每个图像设计了一个新颖的投影层来捕获其独特的特征。

Result: 实验结果表明，MINR在图像重建和超分辨率任务上可以节省高达60%的参数，同时保持可比的性能。特别是，MINR能够有效地扩展到处理100张图像，平均峰值信噪比（PSNR）保持在34 dB。对各种骨干网络的进一步分析证明了所提出的MINR的鲁棒性。

Conclusion: MINR通过共享中间层和为每个图像设计额外的投影层，实现了对多图像的高效编码，能够节省高达60%的参数，同时保持可比的性能，并且能够有效地处理100张图像，平均峰值信噪比（PSNR）保持在34 dB。

Abstract: Implicit Neural Representations (INRs) aim to parameterize discrete signals
through implicit continuous functions. However, formulating each image with a
separate neural network~(typically, a Multi-Layer Perceptron (MLP)) leads to
computational and storage inefficiencies when encoding multi-images. To address
this issue, we propose MINR, sharing specific layers to encode multi-image
efficiently. We first compare the layer-wise weight distributions for several
trained INRs and find that corresponding intermediate layers follow highly
similar distribution patterns. Motivated by this, we share these intermediate
layers across multiple images while preserving the input and output layers as
input-specific. In addition, we design an extra novel projection layer for each
image to capture its unique features. Experimental results on image
reconstruction and super-resolution tasks demonstrate that MINR can save up to
60\% parameters while maintaining comparable performance. Particularly, MINR
scales effectively to handle 100 images, maintaining an average peak
signal-to-noise ratio (PSNR) of 34 dB. Further analysis of various backbones
proves the robustness of the proposed MINR.

</details>


### [21] [Distribution-Aware Hadamard Quantization for Hardware-Efficient Implicit Neural Representations](https://arxiv.org/abs/2508.13478)
*Wenyong Zhou,Jiachen Ren,Taiqiang Wu,Yuxin Cheng,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: DHQ 是一种新的量化方法，可同时量化 INR 的权重和激活，显著提高了硬件效率。


<details>
  <summary>Details</summary>
Motivation: 现有的 INR 量化方法主要集中在权重量化，未能充分利用量化带来的硬件优势。为了充分实现量化带来的硬件效益，需要一种能够同时量化权重和激活的新方法。

Method: 提出了一种名为 DHQ 的新颖的、感知分布的 Hadamard 量化方案，该方案同时针对 INRs 中的权重和激活。该方法利用 Hadamard 变换来统一不同层的权重和激活的分布，然后再应用标准量化器。

Result: DHQ 在 FPGA 实现中展示了其硬件效率，在图像重建任务中，与全精度对应物相比，延迟减少了 32.7%，能耗降低了 40.1%，资源利用率提高了 98.3%。

Conclusion: DHQ 通过将权重和激活的分布统一为钟形，并采用标准量化器，实现了对 INRs 的高效量化，并在 FPGA 实现中展示了显著的硬件效率。

Abstract: Implicit Neural Representations (INRs) encode discrete signals using
Multi-Layer Perceptrons (MLPs) with complex activation functions. While INRs
achieve superior performance, they depend on full-precision number
representation for accurate computation, resulting in significant hardware
overhead. Previous INR quantization approaches have primarily focused on weight
quantization, offering only limited hardware savings due to the lack of
activation quantization. To fully exploit the hardware benefits of
quantization, we propose DHQ, a novel distribution-aware Hadamard quantization
scheme that targets both weights and activations in INRs. Our analysis shows
that the weights in the first and last layers have distributions distinct from
those in the intermediate layers, while the activations in the last layer
differ significantly from those in the preceding layers. Instead of customizing
quantizers individually, we utilize the Hadamard transformation to standardize
these diverse distributions into a unified bell-shaped form, supported by both
empirical evidence and theoretical analysis, before applying a standard
quantizer. To demonstrate the practical advantages of our approach, we present
an FPGA implementation of DHQ that highlights its hardware efficiency.
Experiments on diverse image reconstruction tasks show that DHQ outperforms
previous quantization methods, reducing latency by 32.7\%, energy consumption
by 40.1\%, and resource utilization by up to 98.3\% compared to full-precision
counterparts.

</details>


### [22] [AIM 2025 challenge on Inverse Tone Mapping Report: Methods and Results](https://arxiv.org/abs/2508.13479)
*Chao Wang,Francesco Banterle,Bin Ren,Radu Timofte,Xin Lu,Yufeng Peng,Chengjie Ge,Zhijing Sun,Ziang Zhou,Zihao Li,Zishun Liao,Qiyu Kang,Xueyang Fu,Zheng-Jun Zha,Zhijing Sun,Xingbo Wang,Kean Liu,Senyan Xu,Yang Qiu,Yifan Ding,Gabriel Eilertsen,Jonas Unger,Zihao Wang,Ke Wu,Jinshan Pan,Zhen Liu,Zhongyang Li,Shuaicheng Liu,S. M Nadim Uddin*

Main category: cs.CV

TL;DR: AIM 2025挑战赛专注于从LDR图像重建HDR图像，吸引了大量参与者，并展示了创新的ITM技术。


<details>
  <summary>Details</summary>
Motivation: 推动从单张低动态范围（LDR）输入进行高动态范围（HDR）图像重建的有效ITM算法的发展，重点关注感知保真度和数值一致性。

Method: 对AIM 2025挑战赛的67名参与者提交的319个有效结果进行了分析，重点关注排名前五的团队。

Result: 分析强调了提高HDR重建质量的创新策略，并为未来的ITM研究设定了基准。

Conclusion: 该论文总结了AIM 2025挑战赛在逆色调映射（ITM）领域的进展，并分析了排名前五的团队的方法和表现，最低PU21-PSNR达到29.22 dB。

Abstract: This paper presents a comprehensive review of the AIM 2025 Challenge on
Inverse Tone Mapping (ITM). The challenge aimed to push forward the development
of effective ITM algorithms for HDR image reconstruction from single LDR
inputs, focusing on perceptual fidelity and numerical consistency. A total of
\textbf{67} participants submitted \textbf{319} valid results, from which the
best five teams were selected for detailed analysis. This report consolidates
their methodologies and performance, with the lowest PU21-PSNR among the top
entries reaching 29.22 dB. The analysis highlights innovative strategies for
enhancing HDR reconstruction quality and establishes strong benchmarks to guide
future research in inverse tone mapping.

</details>


### [23] [Enhancing Robustness of Implicit Neural Representations Against Weight Perturbations](https://arxiv.org/abs/2508.13481)
*Wenyong Zhou,Yuxin Cheng,Zhengwu Liu,Taiqiang Wu,Chen Zhang,Ngai Wong*

Main category: cs.CV

TL;DR: INR对权重扰动敏感。本研究提出了一种新的鲁棒损失函数，以提高INR在有噪声条件下的性能，实现了显著的PSNR提升。


<details>
  <summary>Details</summary>
Motivation: 现有隐式神经表征（INR）虽然在多媒体应用中很有价值，但其网络权重容易受到扰动，导致性能下降，这是一个关键的部署挑战。

Method: 提出了一种新颖的鲁棒损失函数，通过最小化有无权重扰动时的损失差异来解决INR的鲁棒性问题。

Result: 实验证明，该方法在重构任务中表现出优越性，在有噪声的情况下，与原始INR相比，PSNR值提高了7.5 dB。

Conclusion: 所提出的方法通过规范化重构损失相对于权重的梯度来增强INR的鲁棒性，在有噪声的情况下，与原始INR相比，在峰值信噪比（PSNR）方面取得了高达7.5 dB的改进。

Abstract: Implicit Neural Representations (INRs) encode discrete signals in a
continuous manner using neural networks, demonstrating significant value across
various multimedia applications. However, the vulnerability of INRs presents a
critical challenge for their real-world deployments, as the network weights
might be subjected to unavoidable perturbations. In this work, we investigate
the robustness of INRs for the first time and find that even minor
perturbations can lead to substantial performance degradation in the quality of
signal reconstruction. To mitigate this issue, we formulate the robustness
problem in INRs by minimizing the difference between loss with and without
weight perturbations. Furthermore, we derive a novel robust loss function to
regulate the gradient of the reconstruction loss with respect to weights,
thereby enhancing the robustness. Extensive experiments on reconstruction tasks
across multiple modalities demonstrate that our method achieves up to a 7.5~dB
improvement in peak signal-to-noise ratio (PSNR) values compared to original
INRs under noisy conditions.

</details>


### [24] [FAMNet: Integrating 2D and 3D Features for Micro-expression Recognition via Multi-task Learning and Hierarchical Attention](https://arxiv.org/abs/2508.13483)
*Liangyu Fu,Xuecheng Wu,Danlei Huang,Xinyi Yin*

Main category: cs.CV

TL;DR: 该研究提出了一种名为FAMNet的新型微表情识别方法，通过融合2D和3D卷积神经网络，并结合多任务学习和分层注意力机制，有效提取微表情的时空特征，显著提高了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 微表情识别（MER）在许多领域具有重要的应用价值，但微表情（MEs）的短暂持续时间和低强度给MER带来了严峻的挑战。现有的深度学习MER方法主要包括静态图像、动态图像序列和两者结合这三种数据加载方式，但如何有效提取MEs的细粒度和时空特征仍然是一个难以解决的问题。

Method: 提出了一种基于多任务学习和分层注意力的微表情识别方法FAMNet。该方法融合了2D CNN（AMNet2D）和3D CNN（AMNet3D），并共享Resnet18骨干网络和注意力模块。在训练过程中，该模型采用不同的数据加载方法分别适应两个网络，并联合训练微表情识别（MER）和面部动作单元检测（FAUD）任务，通过参数硬共享来关联信息，从而进一步提升MER任务的效果。

Result: FAMNet模型在SAMM、CASME II和MMEW数据集上取得了83.75%（UAR）和84.03%（UF1）的准确率，在CAS(ME)$^3$数据集上取得了51%（UAR）和43.42%（UF1）的准确率，证明了其在微表情识别任务上的优越性能。

Conclusion: FAMNet模型在SAMM、CASME II和MMEW数据集上分别达到了83.75%（UAR）和84.03%（UF1）的准确率，在CAS(ME)$^3$数据集上达到了51%（UAR）和43.42%（UF1），显著提高了任务性能。

Abstract: Micro-expressions recognition (MER) has essential application value in many
fields, but the short duration and low intensity of micro-expressions (MEs)
bring considerable challenges to MER. The current MER methods in deep learning
mainly include three data loading methods: static images, dynamic image
sequence, and a combination of the two streams. How to effectively extract MEs'
fine-grained and spatiotemporal features has been difficult to solve. This
paper proposes a new MER method based on multi-task learning and hierarchical
attention, which fully extracts MEs' omni-directional features by merging 2D
and 3D CNNs. The fusion model consists of a 2D CNN AMNet2D and a 3D CNN
AMNet3D, with similar structures consisting of a shared backbone network
Resnet18 and attention modules. During training, the model adopts different
data loading methods to adapt to two specific networks respectively, jointly
trains on the tasks of MER and facial action unit detection (FAUD), and adopts
the parameter hard sharing for information association, which further improves
the effect of the MER task, and the final fused model is called FAMNet.
Extensive experimental results show that our proposed FAMNet significantly
improves task performance. On the SAMM, CASME II and MMEW datasets, FAMNet
achieves 83.75% (UAR) and 84.03% (UF1). Furthermore, on the challenging
CAS(ME)$^3$ dataset, FAMNet achieves 51% (UAR) and 43.42% (UF1).

</details>


### [25] [CORENet: Cross-Modal 4D Radar Denoising Network with LiDAR Supervision for Autonomous Driving](https://arxiv.org/abs/2508.13485)
*Fuyang Liu,Jilin Mei,Fangyuan Mao,Chen Min,Yan Xing,Yu Hu*

Main category: cs.CV

TL;DR: CORENet是一个创新的框架，通过LiDAR监督去噪4D雷达点云，提升了在恶劣天气下的物体检测性能，并能在推理时仅使用雷达数据。


<details>
  <summary>Details</summary>
Motivation: 4D雷达目标检测在恶劣天气和复杂驾驶场景下表现稳健并能提供丰富的空间信息，但其点云数据稀疏且含有噪声，对有效感知构成挑战。

Method: 提出了一种名为CORENet的新型跨模态去噪框架，该框架利用LiDAR进行监督，以识别噪声模式并从原始4D雷达数据中提取判别性特征。CORENet被设计成一个即插即用的架构，可以无缝集成到基于体素的检测框架中，而无需修改现有流程。在训练过程中，该方法仅使用LiDAR数据进行跨模态监督，但在推理时则仅使用雷达数据进行操作。

Result: 在具有高噪声水平的Dual-Radar数据集上进行了广泛评估，证明了CORENet在增强检测鲁棒性方面的有效性。实验结果表明，CORENet的性能优于现有主流方法。

Conclusion: CORENet能够有效提升4D雷达点云的质量，从而增强在恶劣天气条件下的物体检测鲁棒性，并且在Dual-Radar数据集上取得了优于现有主流方法的性能。

Abstract: 4D radar-based object detection has garnered great attention for its
robustness in adverse weather conditions and capacity to deliver rich spatial
information across diverse driving scenarios. Nevertheless, the sparse and
noisy nature of 4D radar point clouds poses substantial challenges for
effective perception. To address the limitation, we present CORENet, a novel
cross-modal denoising framework that leverages LiDAR supervision to identify
noise patterns and extract discriminative features from raw 4D radar data.
Designed as a plug-and-play architecture, our solution enables seamless
integration into voxel-based detection frameworks without modifying existing
pipelines. Notably, the proposed method only utilizes LiDAR data for
cross-modal supervision during training while maintaining full radar-only
operation during inference. Extensive evaluation on the challenging Dual-Radar
dataset, which is characterized by elevated noise level, demonstrates the
effectiveness of our framework in enhancing detection robustness. Comprehensive
experiments validate that CORENet achieves superior performance compared to
existing mainstream approaches.

</details>


### [26] [Multi-view Clustering via Bi-level Decoupling and Consistency Learning](https://arxiv.org/abs/2508.13499)
*Shihao Dong,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种新颖的双层解耦和一致性学习框架（BDCL），用于多视图聚类。通过实例学习、双层解耦和一致性学习，增强特征的类间判别力和类内紧凑性，并在多个数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 多视图聚类通过学习多视图特征之间的一致性和互补性来提升聚类性能，但面向聚类的表示学习常被忽视。本文提出了一种新颖的双层解耦和一致性学习框架（BDCL），以进一步探索多视图数据的有效表示，增强多视图聚类中特征的类间判别力和类内紧凑性。

Method: 1) 多视图实例学习模块通过重建自编码器和对比学习来对齐一致性信息，同时保留视图之间的私有特征。 2) 特征和聚类的双层解耦增强了特征空间和聚类空间的判别力。 3) 一致性学习模块将样本的不同视图及其邻居视为正样本对，学习其聚类分配的一致性，并进一步压缩簇内空间。

Result: 实验结果在五个基准数据集上证明了所提出方法优于现有最先进方法。

Conclusion: 实验结果在五个基准数据集上证明了所提出方法优于现有最先进方法。

Abstract: Multi-view clustering has shown to be an effective method for analyzing
underlying patterns in multi-view data. The performance of clustering can be
improved by learning the consistency and complementarity between multi-view
features, however, cluster-oriented representation learning is often
overlooked. In this paper, we propose a novel Bi-level Decoupling and
Consistency Learning framework (BDCL) to further explore the effective
representation for multi-view data to enhance inter-cluster discriminability
and intra-cluster compactness of features in multi-view clustering. Our
framework comprises three modules: 1) The multi-view instance learning module
aligns the consistent information while preserving the private features between
views through reconstruction autoencoder and contrastive learning. 2) The
bi-level decoupling of features and clusters enhances the discriminability of
feature space and cluster space. 3) The consistency learning module treats the
different views of the sample and their neighbors as positive pairs, learns the
consistency of their clustering assignments, and further compresses the
intra-cluster space. Experimental results on five benchmark datasets
demonstrate the superiority of the proposed method compared with the SOTA
methods. Our code is published on https://github.com/LouisDong95/BDCL.

</details>


### [27] [The 9th AI City Challenge](https://arxiv.org/abs/2508.13564)
*Zheng Tang,Shuo Wang,David C. Anastasiu,Ming-Ching Chang,Anuj Sharma,Quan Kong,Norimasa Kobori,Munkhjargal Gochoo,Ganzorig Batnasan,Munkh-Erdene Otgonbold,Fady Alnajjar,Jun-Wei Hsieh,Tomasz Kornuta,Xiaolong Li,Yilin Zhao,Han Zhang,Subhashree Radhakrishnan,Arihant Jain,Ratnesh Kumar,Vidya N. Murali,Yuxing Wang,Sameer Satish Pusegaonkar,Yizhou Wang,Sujit Biswas,Xunlei Wu,Zhedong Zheng,Pranamesh Chakraborty,Rama Chellappa*

Main category: cs.CV

TL;DR: The 9th AI City Challenge saw increased participation and advancements in computer vision for transportation and safety, with new benchmarks set in tasks like 3D tracking and spatial reasoning.


<details>
  <summary>Details</summary>
Motivation: The ninth AI City Challenge continues to advance real-world applications of computer vision and AI in transportation, industrial automation, and public safety.

Method: The evaluation framework enforced submission limits and used a partially held-out test set to ensure fair benchmarking. Final rankings were revealed after the competition concluded, fostering reproducibility and mitigating overfitting.

Result: The 2025 edition featured four tracks and saw a 17% increase in participation, with 245 teams from 15 countries registered on the evaluation server. Public release of challenge datasets led to over 30,000 downloads to date. Track 1 focused on multi-class 3D multi-camera tracking, involving people, humanoids, autonomous mobile robots, and forklifts, using detailed calibration and 3D bounding box annotations. Track 2 tackled video question answering in traffic safety, with multi-camera incident understanding enriched by 3D gaze labels. Track 3 addressed fine-grained spatial reasoning in dynamic warehouse environments, requiring AI systems to interpret RGB-D inputs and answer spatial questions that combine perception, geometry, and language. Both Track 1 and Track 3 datasets were generated in NVIDIA Omniverse. Track 4 emphasized efficient road object detection from fisheye cameras, supporting lightweight, real-time deployment on edge devices.

Conclusion: Several teams achieved top-tier results, setting new benchmarks in multiple tasks.

Abstract: The ninth AI City Challenge continues to advance real-world applications of
computer vision and AI in transportation, industrial automation, and public
safety. The 2025 edition featured four tracks and saw a 17% increase in
participation, with 245 teams from 15 countries registered on the evaluation
server. Public release of challenge datasets led to over 30,000 downloads to
date. Track 1 focused on multi-class 3D multi-camera tracking, involving
people, humanoids, autonomous mobile robots, and forklifts, using detailed
calibration and 3D bounding box annotations. Track 2 tackled video question
answering in traffic safety, with multi-camera incident understanding enriched
by 3D gaze labels. Track 3 addressed fine-grained spatial reasoning in dynamic
warehouse environments, requiring AI systems to interpret RGB-D inputs and
answer spatial questions that combine perception, geometry, and language. Both
Track 1 and Track 3 datasets were generated in NVIDIA Omniverse. Track 4
emphasized efficient road object detection from fisheye cameras, supporting
lightweight, real-time deployment on edge devices. The evaluation framework
enforced submission limits and used a partially held-out test set to ensure
fair benchmarking. Final rankings were revealed after the competition
concluded, fostering reproducibility and mitigating overfitting. Several teams
achieved top-tier results, setting new benchmarks in multiple tasks.

</details>


### [28] [AdaptiveAE: An Adaptive Exposure Strategy for HDR Capturing in Dynamic Scenes](https://arxiv.org/abs/2508.13503)
*Tianyi Xu,Fan Zhang,Boxin Shi,Tianfan Xue,Yujin Wang*

Main category: cs.CV

TL;DR: AdaptiveAE, an RL-based method, optimizes ISO and shutter speed for HDR imaging in dynamic scenes, outperforming traditional methods by simulating motion blur and noise.


<details>
  <summary>Details</summary>
Motivation: Existing high dynamic range imaging techniques often overlook the complex interaction between shutter speed and ISO and fail to account for motion blur effects in dynamic scenes, leading to suboptimal HDR quality due to noise and motion blur.

Method: AdaptiveAE, a reinforcement learning-based method that optimizes shutter speed and ISO combinations, incorporating motion blur and noise simulation through an image synthesis pipeline, leveraging semantic information and exposure histograms.

Result: AdaptiveAE achieves state-of-the-art performance across multiple datasets by adaptively selecting optimal ISO and shutter speed sequences based on a user-defined exposure time budget.

Conclusion: AdaptiveAE outperforms traditional solutions in achieving state-of-the-art performance for HDR reconstruction in dynamic scenes.

Abstract: Mainstream high dynamic range imaging techniques typically rely on fusing
multiple images captured with different exposure setups (shutter speed and
ISO). A good balance between shutter speed and ISO is crucial for achieving
high-quality HDR, as high ISO values introduce significant noise, while long
shutter speeds can lead to noticeable motion blur. However, existing methods
often overlook the complex interaction between shutter speed and ISO and fail
to account for motion blur effects in dynamic scenes.
  In this work, we propose AdaptiveAE, a reinforcement learning-based method
that optimizes the selection of shutter speed and ISO combinations to maximize
HDR reconstruction quality in dynamic environments. AdaptiveAE integrates an
image synthesis pipeline that incorporates motion blur and noise simulation
into our training procedure, leveraging semantic information and exposure
histograms. It can adaptively select optimal ISO and shutter speed sequences
based on a user-defined exposure time budget, and find a better exposure
schedule than traditional solutions. Experimental results across multiple
datasets demonstrate that it achieves the state-of-the-art performance.

</details>


### [29] [Bridging the Gap: Doubles Badminton Analysis with Singles-Trained Models](https://arxiv.org/abs/2508.13507)
*Seungheon Baek,Jinhyuk Yun*

Main category: cs.CV

TL;DR: A new approach transfers singles badminton models to doubles analysis using ViT-Pose, ST-GCN, and a custom tracking algorithm, successfully enabling shot recognition in doubles matches.


<details>
  <summary>Details</summary>
Motivation: Previous research has mainly focused on singles badminton due to challenges in data availability and multi-person tracking, despite doubles matches being more prevalent in international tournaments. This research addresses this gap by designing an approach to transfer singles-trained models to doubles analysis.

Method: We extracted keypoints from the ShuttleSet single matches dataset using ViT-Pose and embedded them through a contrastive learning framework based on ST-GCN. To improve tracking stability, we incorporated a custom multi-object tracking algorithm that resolves ID switching issues from fast and overlapping player movements. A Transformer-based classifier then determines shot occurrences based on the learned embeddings.

Result: The study demonstrates the feasibility of extending pose-based shot recognition to doubles badminton.

Conclusion: The findings demonstrate the feasibility of extending pose-based shot recognition to doubles badminton, broadening analytics capabilities. This work establishes a foundation for doubles-specific datasets to enhance understanding of this predominant yet understudied format of the fast racket sport.

Abstract: Badminton is known as one of the fastest racket sports in the world. Despite
doubles matches being more prevalent in international tournaments than singles,
previous research has mainly focused on singles due to the challenges in data
availability and multi-person tracking. To address this gap, we designed an
approach that transfers singles-trained models to doubles analysis. We
extracted keypoints from the ShuttleSet single matches dataset using ViT-Pose
and embedded them through a contrastive learning framework based on ST-GCN. To
improve tracking stability, we incorporated a custom multi-object tracking
algorithm that resolves ID switching issues from fast and overlapping player
movements. A Transformer-based classifier then determines shot occurrences
based on the learned embeddings. Our findings demonstrate the feasibility of
extending pose-based shot recognition to doubles badminton, broadening
analytics capabilities. This work establishes a foundation for doubles-specific
datasets to enhance understanding of this predominant yet understudied format
of the fast racket sport.

</details>


### [30] [MR6D: Benchmarking 6D Pose Estimation for Mobile Robots](https://arxiv.org/abs/2508.13775)
*Anas Gouda,Shrutarv Awasthi,Christian Blesing,Lokeshwaran Manohar,Frank Hoffmann,Alice Kirchheim*

Main category: cs.CV

TL;DR: MR6D是一个新的6D姿态估计数据集，专为移动机器人设计，涵盖了工业环境中的挑战，如大物体和长距离感知。现有方法在该数据集上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有6D姿态估计数据集主要关注机器人手臂操作的小型家居对象，与移动机器人应用场景（如大物体、长距离感知、自遮挡和多样化视角）存在差距。

Method: MR6D数据集的构建和评估，包括在工业环境中收集包含静态和动态交互的真实世界场景，并评估现有6D姿态估计方法的性能。

Result: 现有6D姿态估计模型在MR6D数据集上面临性能下降，特别是在2D分割方面存在挑战，突显了针对移动机器人需求进行优化的必要性。

Conclusion: MR6D数据集为移动机器人领域的6D姿态估计提供了基础，解决了现有数据集的局限性，并在工业环境中进行了评估。

Abstract: Existing 6D pose estimation datasets primarily focus on small household
objects typically handled by robot arm manipulators, limiting their relevance
to mobile robotics. Mobile platforms often operate without manipulators,
interact with larger objects, and face challenges such as long-range
perception, heavy self-occlusion, and diverse camera perspectives. While recent
models generalize well to unseen objects, evaluations remain confined to
household-like settings that overlook these factors. We introduce MR6D, a
dataset designed for 6D pose estimation for mobile robots in industrial
environments. It includes 92 real-world scenes featuring 16 unique objects
across static and dynamic interactions. MR6D captures the challenges specific
to mobile platforms, including distant viewpoints, varied object
configurations, larger object sizes, and complex occlusion/self-occlusion
patterns. Initial experiments reveal that current 6D pipelines underperform in
these settings, with 2D segmentation being another hurdle. MR6D establishes a
foundation for developing and evaluating pose estimation methods tailored to
the demands of mobile robotics. The dataset is available at
https://huggingface.co/datasets/anas-gouda/mr6d.

</details>


### [31] [2D Gaussians Meet Visual Tokenizer](https://arxiv.org/abs/2508.13515)
*Yiang Shi,Xiaoyang Guo,Wei Yin,Mingkai Jia,Qian Zhang,Xiaolin Hu,Wenyu Liu,Xinggang Wan*

Main category: cs.CV

TL;DR: VGQ是一种新的图像标记器框架，通过集成2D高斯分布来增强几何结构建模，在图像重建任务中取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于量化的图像标记器（如VQ-GAN）主要关注纹理和颜色等外观特征，但由于其基于块的设计，往往忽略了几何结构。本文旨在探索如何将更多视觉信息（特别是几何结构）融入标记器。

Method: 提出了一种名为视觉高斯量化（VGQ）的新框架，将2D高斯分布集成到传统的视觉码本量化框架中，以增强结构建模。

Result: VGQ能够有效捕捉几何和空间结构，并且在ImageNet 256x256基准测试中取得了良好的重建质量（rFID得分为1.00）。通过增加标记内2D高斯的密度，VGQ的重建能力得到显著提升，达到了0.556的rFID分数和24.93的PSNR，优于现有方法。

Conclusion: VGQ通过将2D高斯分布集成到量化框架中，能够有效捕捉几何和空间结构，并在ImageNet数据集上取得了优越的重建质量，rFID得分为0.556，PSNR为24.93，显著优于现有方法。

Abstract: The image tokenizer is a critical component in AR image generation, as it
determines how rich and structured visual content is encoded into compact
representations. Existing quantization-based tokenizers such as VQ-GAN
primarily focus on appearance features like texture and color, often neglecting
geometric structures due to their patch-based design. In this work, we explored
how to incorporate more visual information into the tokenizer and proposed a
new framework named Visual Gaussian Quantization (VGQ), a novel tokenizer
paradigm that explicitly enhances structural modeling by integrating 2D
Gaussians into traditional visual codebook quantization frameworks. Our
approach addresses the inherent limitations of naive quantization methods such
as VQ-GAN, which struggle to model structured visual information due to their
patch-based design and emphasis on texture and color. In contrast, VGQ encodes
image latents as 2D Gaussian distributions, effectively capturing geometric and
spatial structures by directly modeling structure-related parameters such as
position, rotation and scale. We further demonstrate that increasing the
density of 2D Gaussians within the tokens leads to significant gains in
reconstruction fidelity, providing a flexible trade-off between token
efficiency and visual richness. On the ImageNet 256x256 benchmark, VGQ achieves
strong reconstruction quality with an rFID score of 1.00. Furthermore, by
increasing the density of 2D Gaussians within the tokens, VGQ gains a
significant boost in reconstruction capability and achieves a state-of-the-art
reconstruction rFID score of 0.556 and a PSNR of 24.93, substantially
outperforming existing methods. Codes will be released soon.

</details>


### [32] [ResPlan: A Large-Scale Vector-Graph Dataset of 17,000 Residential Floor Plans](https://arxiv.org/abs/2508.14006)
*Mohamed Abouagour,Eleftherios Garyfallidis*

Main category: cs.CV

TL;DR: ResPlan是一个大规模、真实、多样的住宅楼层平面图数据集，包含详细的标注和多种格式，旨在推动空间人工智能研究，并支持机器人、强化学习、生成式AI、VR/AR、模拟和游戏开发等多种应用。


<details>
  <summary>Details</summary>
Motivation: 为了推进空间人工智能研究，解决现有数据集（如RPLAN和MSD）在视觉保真度和结构多样性方面的局限性。

Method: 创建了一个包含17,000个详细、结构丰富、逼真的住宅楼层平面图的大型数据集，并提供几何和基于图的格式，以及一个用于几何清理、对齐和注释精炼的开源流程。

Result: ResPlan数据集包含精确标注的建筑元素（墙壁、门、窗户、阳台）和功能空间（如厨房、卧室、浴室），并提供房间连通性的结构化表示，支持基于图的空间推理任务。

Conclusion: ResPlan数据集在规模、真实性和可用性方面取得了显著进展，为开发和评估下一代空间智能系统提供了坚实的基础。

Abstract: We introduce ResPlan, a large-scale dataset of 17,000 detailed, structurally
rich, and realistic residential floor plans, created to advance spatial AI
research. Each plan includes precise annotations of architectural elements
(walls, doors, windows, balconies) and functional spaces (such as kitchens,
bedrooms, and bathrooms). ResPlan addresses key limitations of existing
datasets such as RPLAN (Wu et al., 2019) and MSD (van Engelenburg et al., 2024)
by offering enhanced visual fidelity and greater structural diversity,
reflecting realistic and non-idealized residential layouts. Designed as a
versatile, general-purpose resource, ResPlan supports a wide range of
applications including robotics, reinforcement learning, generative AI, virtual
and augmented reality, simulations, and game development. Plans are provided in
both geometric and graph-based formats, enabling direct integration into
simulation engines and fast 3D conversion. A key contribution is an open-source
pipeline for geometry cleaning, alignment, and annotation refinement.
Additionally, ResPlan includes structured representations of room connectivity,
supporting graph-based spatial reasoning tasks. Finally, we present comparative
analyses with existing benchmarks and outline several open benchmark tasks
enabled by ResPlan. Ultimately, ResPlan offers a significant advance in scale,
realism, and usability, providing a robust foundation for developing and
benchmarking next-generation spatial intelligence systems.

</details>


### [33] [Calibrating Biased Distribution in VFM-derived Latent Space via Cross-Domain Geometric Consistency](https://arxiv.org/abs/2508.13518)
*Yanbiao Ma,Wei Dai,Bowei Liu,Jiayi Chen,Wenke Huang,Guancheng Wan,Zhiwu Lu,Junchi Yan*

Main category: cs.CV

TL;DR: 本研究提出了一种利用基础模型提取的特征的几何形状来校准数据分布的方法，以解决深度学习中训练样本与真实数据分布不一致的问题。该方法通过在联邦学习和长尾识别任务中应用，证明了其能够有效提升模型在数据异质性和样本不平衡情况下的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在训练过程中面临着训练样本与真实数据分布之间存在差距的挑战，这可能是由采样偏差、噪声等多种原因造成的。本研究的动机在于探索如何利用基础模型（如CLIP、DINOv2）的特征提取能力，特别是其提取的特征分布的几何形状，来解决这一差距问题。

Method: 本文提出了一种几何知识引导的分布校准框架。在特征提取方面，利用现成的基础模型（如CLIP、DINOv2）来捕捉数据的几何形状特征，并验证了这些特征在不同领域和数据集间的可迁移性。在联邦学习场景下，该框架在保护隐私的前提下获取全局几何形状信息，并利用该信息生成新样本以缩小客户端本地观测与全局观测之间的差距。在长尾识别场景下，该框架利用来自样本丰富类别迁移的几何知识来恢复样本稀疏的尾部类别的真实数据分布。

Result: 实验证明，该研究提出的几何知识引导的分布校准框架能够有效克服由数据异质性和样本不平衡引起的信息缺失问题。在联邦学习和长尾识别的实验设置中，该框架均取得了性能提升，验证了其在实际应用中的有效性和实用性。

Conclusion: 该研究表明，深度学习在处理训练样本与真实数据分布之间差距的问题上取得了进展，特别是在利用基础模型进行特征提取时，其几何形状表现出跨领域和数据集的优异迁移性。通过将几何知识引导的分布校准框架应用于联邦学习和长尾识别等具有挑战性的场景，研究证明了该方法能有效弥合数据异质性和样本不平衡带来的信息缺失，提升了在基准测试中的性能。

Abstract: Despite the fast progress of deep learning, one standing challenge is the gap
of the observed training samples and the underlying true distribution. There
are multiple reasons for the causing of this gap e.g. sampling bias, noise etc.
In the era of foundation models, we show that when leveraging the off-the-shelf
(vision) foundation models (e.g., CLIP, DINOv2) for feature extraction, the
geometric shapes of the resulting feature distributions exhibit remarkable
transferability across domains and datasets. To verify its practical
usefulness, we embody our geometric knowledge-guided distribution calibration
framework in two popular and challenging settings: federated learning and
long-tailed recognition. In the federated setting, we devise a technique of
acquiring the global geometric shape under privacy constraints, then leverage
this knowledge to generate new samples for clients, in the aim of bridging the
gap between local and global observations. In long-tailed learning, it utilizes
the geometric knowledge transferred from sample-rich categories to recover the
true distribution for sample-scarce tail classes. Comprehensive experiments
show that our proposed geometric knowledge-guided distribution calibration
effectively overcomes information deficits caused by data heterogeneity and
sample imbalance, with boosted performance across benchmarks.

</details>


### [34] [Evaluating Open-Source Vision Language Models for Facial Emotion Recognition against Traditional Deep Learning Models](https://arxiv.org/abs/2508.13524)
*Vamsi Krishna Mulukutla,Sai Supriya Pavarala,Srinivasa Raju Rudraraju,Sridevi Bonthu*

Main category: cs.CV

TL;DR: 本研究比较了传统深度学习模型和视觉语言模型（VLMs）在面部情感识别（FER）任务上的表现。结果显示，在处理低质量图像时，传统模型优于VLMs。研究还提出了一种图像恢复管道以改善VLMs在嘈杂数据上的性能，并进行了计算成本分析。


<details>
  <summary>Details</summary>
Motivation: 面部情感识别（FER）对于人机交互和心理健康诊断等应用至关重要。本研究旨在对开源视觉语言模型（VLMs）与传统深度学习模型在具有挑战性的FER-2013数据集上的性能进行实证比较。

Method: 提出了一种新颖的管道，集成了基于GFPGAN的图像恢复和面部情感识别（FER）评估，以解决VLM训练假设与FER数据噪声特性之间的不匹配问题。

Result: EfficientNet-B0（86.44%）和ResNet-50（85.72%）等传统模型在FER-2013数据集上的表现明显优于CLIP（64.07%）和Phi-3.5 Vision（51.66%）等VLMs。此外，还提供了包括预处理、训练、推理和评估在内的计算成本分析。

Conclusion: 传统模型（特别是EfficientNet-B0和ResNet-50）在FER-2013数据集上显著优于视觉语言模型（VLMs），如CLIP和Phi-3.5 Vision，这表明VLMs在低质量视觉任务上存在局限性。该研究强调了将VLMs适应于嘈杂环境的必要性，并为未来的情感识别研究提供了一个可复现的基准。

Abstract: Facial Emotion Recognition (FER) is crucial for applications such as
human-computer interaction and mental health diagnostics. This study presents
the first empirical comparison of open-source Vision-Language Models (VLMs),
including Phi-3.5 Vision and CLIP, against traditional deep learning models
VGG19, ResNet-50, and EfficientNet-B0 on the challenging FER-2013 dataset,
which contains 35,887 low-resolution grayscale images across seven emotion
classes. To address the mismatch between VLM training assumptions and the noisy
nature of FER data, we introduce a novel pipeline that integrates GFPGAN-based
image restoration with FER evaluation. Results show that traditional models,
particularly EfficientNet-B0 (86.44%) and ResNet-50 (85.72%), significantly
outperform VLMs like CLIP (64.07%) and Phi-3.5 Vision (51.66%), highlighting
the limitations of VLMs in low-quality visual tasks. In addition to performance
evaluation using precision, recall, F1-score, and accuracy, we provide a
detailed computational cost analysis covering preprocessing, training,
inference, and evaluation phases, offering practical insights for deployment.
This work underscores the need for adapting VLMs to noisy environments and
provides a reproducible benchmark for future research in emotion recognition.

</details>


### [35] [EAvatar: Expression-Aware Head Avatar Reconstruction with Generative Geometry Priors](https://arxiv.org/abs/2508.13537)
*Shikun Zhang,Cunjian Chen,Yiqun Wang,Qiuhong Ke,Yong Li*

Main category: cs.CV

TL;DR: EAvatar是一种新的3DGS头部重建方法，通过稀疏表情控制和3D先验来提高表情和纹理细节的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于3DGS的方法在捕捉细微的面部表情和保持局部纹理连续性方面存在挑战，尤其是在高度可变形区域。

Method: 提出了一种名为EAvatar的新型基于3D高斯泼溅（3DGS）的框架，用于头部重建。该方法引入了稀疏表情控制机制，使用少量关键高斯影响其邻近高斯，以精确建模局部变形和细微纹理过渡。此外，利用预训练生成模型提供的高质量3D先验来获得更可靠的面部几何结构，以提高训练过程中的收敛稳定性和形状准确性。

Result: 实验结果表明，EAvatar在头部重建方面比现有方法更准确、视觉上更连贯，并且在表情可控性和细节保真度方面有所提高。

Conclusion: EAvatar通过引入稀疏表情控制机制和利用预训练生成模型提供的高质量3D先验，能够生成更准确、视觉上更一致的头部模型，同时提高了表情可控性和细节保真度。

Abstract: High-fidelity head avatar reconstruction plays a crucial role in AR/VR,
gaming, and multimedia content creation. Recent advances in 3D Gaussian
Splatting (3DGS) have demonstrated effectiveness in modeling complex geometry
with real-time rendering capability and are now widely used in high-fidelity
head avatar reconstruction tasks. However, existing 3DGS-based methods still
face significant challenges in capturing fine-grained facial expressions and
preserving local texture continuity, especially in highly deformable regions.
To mitigate these limitations, we propose a novel 3DGS-based framework termed
EAvatar for head reconstruction that is both expression-aware and
deformation-aware. Our method introduces a sparse expression control mechanism,
where a small number of key Gaussians are used to influence the deformation of
their neighboring Gaussians, enabling accurate modeling of local deformations
and fine-scale texture transitions. Furthermore, we leverage high-quality 3D
priors from pretrained generative models to provide a more reliable facial
geometry, offering structural guidance that improves convergence stability and
shape accuracy during training. Experimental results demonstrate that our
method produces more accurate and visually coherent head reconstructions with
improved expression controllability and detail fidelity.

</details>


### [36] [FLAIR: Frequency- and Locality-Aware Implicit Neural Representations](https://arxiv.org/abs/2508.13544)
*Sukhun Ko,Dahyeon Kye,Kyle Min,Chanho Eom,Jihyong Oh*

Main category: cs.CV

TL;DR: FLAIR enhances Implicit Neural Representations (INRs) with frequency and locality awareness using novel activation (RC-GAUSS) and encoding (WEGE) techniques, improving performance in vision tasks like image representation, restoration, and 3D reconstruction.


<details>
  <summary>Details</summary>
Motivation: Existing INRs lack frequency selectivity, spatial localization, and sparse representations, leading to spectral bias and difficulty in capturing high-frequency details. FLAIR addresses these limitations.

Method: FLAIR introduces two key innovations: RC-GAUSS, a novel activation for explicit frequency selection and spatial localization under the time-frequency uncertainty principle (TFUP), and Wavelet-Energy-Guided Encoding (WEGE), which uses the discrete wavelet transform (DWT) to compute energy scores and guide frequency information.

Result: FLAIR demonstrates superior performance in 2D image representation and restoration, and 3D reconstruction compared to existing INRs.

Conclusion: FLAIR consistently outperforms existing INRs in 2D image representation and restoration, as well as 3D reconstruction by incorporating frequency selectivity, spatial localization, and sparse representations.

Abstract: Implicit Neural Representations (INRs) leverage neural networks to map
coordinates to corresponding signals, enabling continuous and compact
representations. This paradigm has driven significant advances in various
vision tasks. However, existing INRs lack frequency selectivity, spatial
localization, and sparse representations, leading to an over-reliance on
redundant signal components. Consequently, they exhibit spectral bias, tending
to learn low-frequency components early while struggling to capture fine
high-frequency details. To address these issues, we propose FLAIR (Frequency-
and Locality-Aware Implicit Neural Representations), which incorporates two key
innovations. The first is RC-GAUSS, a novel activation designed for explicit
frequency selection and spatial localization under the constraints of the
time-frequency uncertainty principle (TFUP). The second is
Wavelet-Energy-Guided Encoding (WEGE), which leverages the discrete wavelet
transform (DWT) to compute energy scores and explicitly guide frequency
information to the network. Our method consistently outperforms existing INRs
in 2D image representation and restoration, as well as 3D reconstruction.

</details>


### [37] [GazeProphet: Software-Only Gaze Prediction for VR Foveated Rendering](https://arxiv.org/abs/2508.13546)
*Farhaan Ebadulla,Chiraag Mudlapur,Gaurav BV*

Main category: cs.CV

TL;DR: GazeProphet 是一种纯软件的 VR 注视点预测方法，无需眼动追踪硬件，使用 Transformer 和 LSTM 预测注视点，在 VR 数据集上实现了 3.83 度的平均绝对误差，比传统方法提高了 24%，并可广泛应用于 VR 系统。


<details>
  <summary>Details</summary>
Motivation: 当前的注视点渲染技术需要昂贵的基于硬件的眼动追踪系统，这限制了其广泛应用，因为其成本高、校准复杂且存在硬件兼容性问题。本研究旨在提出一种无需专用眼动追踪硬件的纯软件方法来预测 VR 环境中的注视点位置。

Method: 提出了一种名为 GazeProphet 的纯软件方法，利用球形视觉 Transformer 处理 360 度 VR 场景，并结合基于 LSTM 的时间编码器来捕捉注视点序列模式。通过多模态融合网络整合空间场景特征和时间注视点动态，以预测未来注视点位置并提供置信度估计。

Result: GazeProphet 在全面的 VR 数据集上的实验评估显示，其平均绝对误差为 3.83 度，比传统的显著性预测基线提高了 24%，并提供了可靠的置信度校准。该方法在不同的空间区域和场景类型中保持了性能一致性，无需额外硬件即可在 VR 系统中实际部署。

Conclusion: 该研究表明，仅通过软件即可进行注视点预测，可用于 VR 注视点渲染，从而使各种 VR 平台和应用程序能更方便地获得性能提升。

Abstract: Foveated rendering significantly reduces computational demands in virtual
reality applications by concentrating rendering quality where users focus their
gaze. Current approaches require expensive hardware-based eye tracking systems,
limiting widespread adoption due to cost, calibration complexity, and hardware
compatibility constraints. This paper presents GazeProphet, a software-only
approach for predicting gaze locations in VR environments without requiring
dedicated eye tracking hardware. The approach combines a Spherical Vision
Transformer for processing 360-degree VR scenes with an LSTM-based temporal
encoder that captures gaze sequence patterns. A multi-modal fusion network
integrates spatial scene features with temporal gaze dynamics to predict future
gaze locations with associated confidence estimates. Experimental evaluation on
a comprehensive VR dataset demonstrates that GazeProphet achieves a median
angular error of 3.83 degrees, outperforming traditional saliency-based
baselines by 24% while providing reliable confidence calibration. The approach
maintains consistent performance across different spatial regions and scene
types, enabling practical deployment in VR systems without additional hardware
requirements. Statistical analysis confirms the significance of improvements
across all evaluation metrics. These results show that software-only gaze
prediction can work for VR foveated rendering, making this performance boost
more accessible to different VR platforms and apps.

</details>


### [38] [A Lightweight Dual-Mode Optimization for Generative Face Video Coding](https://arxiv.org/abs/2508.13547)
*Zihan Zhang,Shanzhi Yin,Bolin Chen,Ru-Ling Liao,Shiqi Wang,Yan Ye*

Main category: cs.CV

TL;DR: 提出了一种轻量级的GFVC框架，通过改进网络结构和剪枝技术，大大降低了模型复杂度和计算量，同时提升了编码性能，适合在移动设备上使用。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有GFVC模型参数大、计算成本高，阻碍其在实际部署中的问题。

Method: 提出了一种轻量级的GFVC框架，采用双模式优化策略：1. 架构层面：使用更精简高效的层替换传统的3x3卷积。2. 操作层面：设计了两阶段自适应通道剪枝策略，包括训练期间的软剪枝和训练后的硬剪枝。

Result: 与基线模型相比，参数减少了90.4%，计算量节省了88.9%，并在感知质量指标上优于现有的VVC视频编码标准。

Conclusion: 该轻量级GFVC框架通过架构重新设计和操作优化相结合的双模式优化，显著降低了模型复杂性，同时保持了重建质量，有望在移动边缘设备等资源受限环境中实现高效的GFVC部署。

Abstract: Generative Face Video Coding (GFVC) achieves superior rate-distortion
performance by leveraging the strong inference capabilities of deep generative
models. However, its practical deployment is hindered by large model parameters
and high computational costs. To address this, we propose a lightweight GFVC
framework that introduces dual-mode optimization -- combining architectural
redesign and operational refinement -- to reduce complexity whilst preserving
reconstruction quality. Architecturally, we replace traditional 3 x 3
convolutions with slimmer and more efficient layers, reducing complexity
without compromising feature expressiveness. Operationally, we develop a
two-stage adaptive channel pruning strategy: (1) soft pruning during training
identifies redundant channels via learnable thresholds, and (2) hard pruning
permanently eliminates these channels post-training using a derived mask. This
dual-phase approach ensures both training stability and inference efficiency.
Experimental results demonstrate that the proposed lightweight dual-mode
optimization for GFVC can achieve 90.4% parameter reduction and 88.9%
computation saving compared to the baseline, whilst achieving superior
performance compared to state-of-the-art video coding standard Versatile Video
Coding (VVC) in terms of perceptual-level quality metrics. As such, the
proposed method is expected to enable efficient GFVC deployment in
resource-constrained environments such as mobile edge devices.

</details>


### [39] [Color Spike Data Generation via Bio-inspired Neuron-like Encoding with an Artificial Photoreceptor Layer](https://arxiv.org/abs/2508.13558)
*Hsieh Ching-Teng,Wang Yuan-Kai*

Main category: cs.CV

TL;DR: 提出了一种神经元编码方法，结合人工光感受器层，生成包含颜色和亮度信息的脉冲数据，以提高SNN性能，同时符合神经形态计算原则。


<details>
  <summary>Details</summary>
Motivation: 为了解决SNNs由于脉冲数据信息容量有限而导致性能滞后于CNNs的问题，并克服现有方法偏离神经形态计算原则的局限性。

Method: 提出了一种神经元编码方法，并结合了人工光感受器层，以生成包含颜色和亮度信息的脉冲数据。

Result: 实验结果表明，该生物启发方法能够有效增加脉冲信号的信息含量，提高SNN性能。

Conclusion: 该方法通过生成基于生物神经元原理的脉冲数据，有效增加了脉冲信号的信息含量并提高了SNN性能，同时符合神经形态计算的原则，具有未来发展潜力，可促进SNNs的广泛应用。

Abstract: In recent years, neuromorphic computing and spiking neural networks (SNNs)
have ad-vanced rapidly through integration with deep learning. However, the
performance of SNNs still lags behind that of convolutional neural networks
(CNNs), primarily due to the limited information capacity of spike-based data.
Although some studies have attempted to improve SNN performance by training
them with non-spiking inputs such as static images, this approach deviates from
the original intent of neuromorphic computing, which emphasizes spike-based
information processing. To address this issue, we propose a Neuron-like
Encoding method that generates spike data based on the intrinsic operational
principles and functions of biological neurons. This method is further enhanced
by the incorporation of an artificial pho-toreceptor layer, enabling spike data
to carry both color and luminance information, thereby forming a complete
visual spike signal. Experimental results using the Integrate-and-Fire neuron
model demonstrate that this biologically inspired approach effectively
increases the information content of spike signals and improves SNN
performance, all while adhering to neuromorphic principles. We believe this
concept holds strong potential for future development and may contribute to
overcoming current limitations in neuro-morphic computing, facilitating broader
applications of SNNs.

</details>


### [40] [DictAS: A Framework for Class-Generalizable Few-Shot Anomaly Segmentation via Dictionary Lookup](https://arxiv.org/abs/2508.13560)
*Zhen Qu,Xian Tao,Xinyi Gong,ShiChen Qu,Xiaopei Zhang,Xingang Wang,Fei Shen,Zhengtao Zhang,Mukesh Prasad,Guiguang Ding*

Main category: cs.CV

TL;DR: DictAS allows anomaly detection in new categories without retraining, using normal images as prompts by simulating dictionary lookup for features.


<details>
  <summary>Details</summary>
Motivation: Existing vision-language models for few-shot anomaly segmentation rely heavily on prior knowledge of real seen anomaly samples. This paper addresses the limitation by proposing DictAS, a novel framework that enables a unified model to detect visual anomalies in unseen object categories without retraining, using only a few normal reference images as visual prompts.

Method: DictAS utilizes a framework with three components: Dictionary Construction (simulating a dictionary with normal image features), Dictionary Lookup (retrieving region features and classifying unretrievable features as anomalies), and Query Discrimination Regularization (enhancing anomaly detection through Contrastive Query Constraint and Text Alignment Constraint).

Result: DictAS successfully enables a unified model to detect visual anomalies in unseen object categories without any retraining on the target data, outperforming state-of-the-art methods.

Conclusion: DictAS consistently outperforms state-of-the-art FSAS methods on seven public industrial and medical datasets, enabling anomaly detection in unseen object categories without target data retraining by using normal reference images as visual prompts.

Abstract: Recent vision-language models (e.g., CLIP) have demonstrated remarkable
class-generalizable ability to unseen classes in few-shot anomaly segmentation
(FSAS), leveraging supervised prompt learning or fine-tuning on seen classes.
However, their cross-category generalization largely depends on prior knowledge
of real seen anomaly samples. In this paper, we propose a novel framework,
namely DictAS, which enables a unified model to detect visual anomalies in
unseen object categories without any retraining on the target data, only
employing a few normal reference images as visual prompts. The insight behind
DictAS is to transfer dictionary lookup capabilities to the FSAS task for
unseen classes via self-supervised learning, instead of merely memorizing the
normal and abnormal feature patterns from the training set. Specifically,
DictAS mainly consists of three components: (1) **Dictionary Construction** -
to simulate the index and content of a real dictionary using features from
normal reference images. (2) **Dictionary Lookup** - to retrieve queried region
features from the dictionary via a sparse lookup strategy. When a query feature
cannot be retrieved, it is classified as an anomaly. (3) **Query Discrimination
Regularization**- to enhance anomaly discrimination by making abnormal features
harder to retrieve from the dictionary. To achieve this, Contrastive Query
Constraint and Text Alignment Constraint are further proposed. Extensive
experiments on seven public industrial and medical datasets demonstrate that
DictAS consistently outperforms state-of-the-art FSAS methods.

</details>


### [41] [Learnable SMPLify: A Neural Solution for Optimization-Free Human Pose Inverse Kinematics](https://arxiv.org/abs/2508.13562)
*Yuchen Yang,Linfeng Dong,Wei Wang,Zhihang Zhong,Xiao Sun*

Main category: cs.CV

TL;DR: A neural network framework called Learnable SMPLify speeds up 3D human pose and shape estimation by replacing iterative optimization with a single-pass regression model, achieving 200x faster runtimes while maintaining accuracy and improving generalization.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the high computational cost of SMPLify, a robust baseline for 3D human pose and shape estimation, by replacing iterative optimization with a data-driven neural network for significant runtime improvements without sacrificing accuracy.

Method: The paper proposes Learnable SMPLify, a neural framework that replaces the iterative fitting process in SMPLify with a single-pass regression model. It uses a temporal sampling strategy for data construction and a human-centric normalization scheme with residual learning for generalization.

Result: The method achieves nearly 200x faster runtime compared to SMPLify, generalizes well to unseen 3DPW and RICH datasets, and can be used as a plug-in tool on LucidAction.

Conclusion: Learnable SMPLify is a practical and simple baseline that achieves nearly 200x faster runtime compared to SMPLify, generalizes well to unseen datasets, and operates in a model-agnostic manner.

Abstract: In 3D human pose and shape estimation, SMPLify remains a robust baseline that
solves inverse kinematics (IK) through iterative optimization. However, its
high computational cost limits its practicality. Recent advances across domains
have shown that replacing iterative optimization with data-driven neural
networks can achieve significant runtime improvements without sacrificing
accuracy. Motivated by this trend, we propose Learnable SMPLify, a neural
framework that replaces the iterative fitting process in SMPLify with a
single-pass regression model. The design of our framework targets two core
challenges in neural IK: data construction and generalization. To enable
effective training, we propose a temporal sampling strategy that constructs
initialization-target pairs from sequential frames. To improve generalization
across diverse motions and unseen poses, we propose a human-centric
normalization scheme and residual learning to narrow the solution space.
Learnable SMPLify supports both sequential inference and plug-in
post-processing to refine existing image-based estimators. Extensive
experiments demonstrate that our method establishes itself as a practical and
simple baseline: it achieves nearly 200x faster runtime compared to SMPLify,
generalizes well to unseen 3DPW and RICH, and operates in a model-agnostic
manner when used as a plug-in tool on LucidAction. The code is available at
https://github.com/Charrrrrlie/Learnable-SMPLify.

</details>


### [42] [Generative Model-Based Feature Attention Module for Video Action Analysis](https://arxiv.org/abs/2508.13565)
*Guiqin Wang,Peng Zhao,Cong Zhao,Jing Huang,Siyan Guo,Shusen Yang*

Main category: cs.CV

TL;DR: 提出了一种新的生成式注意力模型，用于视频动作分析，通过利用动作的前景和背景差异来学习特征语义，并在动作识别和检测任务上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在特征提取中忽略了特征语义，并且侧重于优化动作建议，这限制了它们在需要高精度和可扩展性的物联网应用（如自动驾驶）中的广泛应用。

Method: 提出了一种新颖的生成式注意力模型，该模型通过学习特征语义关系，同时学习时间动作特征语义的帧依赖和片段依赖，有效利用了特征语义。

Result: 在两个基准视频任务（动作识别和动作检测）上进行了广泛的实验，并在动作检测任务上通过全面验证证实了该方法的优越性。

Conclusion: 该模型在动作识别和动作检测任务中均表现出色，尤其在动作检测任务中验证了其优越性，并可扩展至更广泛的视频动作识别任务。

Abstract: Video action analysis is a foundational technology within the realm of
intelligent video comprehension, particularly concerning its application in
Internet of Things(IoT). However, existing methodologies overlook feature
semantics in feature extraction and focus on optimizing action proposals, thus
these solutions are unsuitable for widespread adoption in high-performance IoT
applications due to the limitations in precision, such as autonomous driving,
which necessitate robust and scalable intelligent video analytics analysis. To
address this issue, we propose a novel generative attention-based model to
learn the relation of feature semantics. Specifically, by leveraging the
differences of actions' foreground and background, our model simultaneously
learns the frame- and segment-dependencies of temporal action feature
semantics, which takes advantage of feature semantics in the feature extraction
effectively. To evaluate the effectiveness of our model, we conduct extensive
experiments on two benchmark video task, action recognition and action
detection. In the context of action detection tasks, we substantiate the
superiority of our approach through comprehensive validation on widely
recognized datasets. Moreover, we extend the validation of the effectiveness of
our proposed method to a broader task, video action recognition. Our code is
available at https://github.com/Generative-Feature-Model/GAF.

</details>


### [43] [Temporal-Conditional Referring Video Object Segmentation with Noise-Free Text-to-Video Diffusion Model](https://arxiv.org/abs/2508.13584)
*Ruixin Zhang,Jiaqing Fan,Yifan Liao,Qian Qiao,Fanzhang Li*

Main category: cs.CV

TL;DR: 本文提出了一种TCRVOS模型，通过改进分割头设计、利用文本到视频扩散模型进行特征提取、移除噪声预测模块以及引入TCMR模块，在RVOS任务上取得了state-of-the-art的性能。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法过分关注特征提取和时间建模，而忽略了分割头的设计，本文旨在改进分割头设计以提升性能。

Method: 本文提出了一种新颖的结合了现有分割方法以有效增强边界分割能力的TCRVOS模型。该模型利用文本到视频扩散模型进行特征提取，并移除了传统的噪声预测模块以避免随机性，同时设计了一个TCMR模块来提高分割质量。

Result: 提出的模型在四个公共RVOS基准测试中始终 achieves state-of-the-art performance。

Conclusion: 该模型在四个公共RVOS基准测试中始终 achieves state-of-the-art performance。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment specific objects
in a video according to textual descriptions. We observe that recent RVOS
approaches often place excessive emphasis on feature extraction and temporal
modeling, while relatively neglecting the design of the segmentation head. In
fact, there remains considerable room for improvement in segmentation head
design. To address this, we propose a Temporal-Conditional Referring Video
Object Segmentation model, which innovatively integrates existing segmentation
methods to effectively enhance boundary segmentation capability. Furthermore,
our model leverages a text-to-video diffusion model for feature extraction. On
top of this, we remove the traditional noise prediction module to avoid the
randomness of noise from degrading segmentation accuracy, thereby simplifying
the model while improving performance. Finally, to overcome the limited feature
extraction capability of the VAE, we design a Temporal Context Mask Refinement
(TCMR) module, which significantly improves segmentation quality without
introducing complex designs. We evaluate our method on four public RVOS
benchmarks, where it consistently achieves state-of-the-art performance.

</details>


### [44] [Bridging Clear and Adverse Driving Conditions](https://arxiv.org/abs/2508.13592)
*Yoel Shapiro,Yahia Showgan,Koustav Mullick*

Main category: cs.CV

TL;DR: 该研究提出了一种新的域适应方法，通过将清晰天气图像合成为恶劣天气图像（如雨、雪、雾和夜间），来解决自动驾驶系统在恶劣天气下的性能下降问题。研究人员开发了多种数据生成方法，并结合了模拟数据和真实数据进行训练，以提高模型的鲁棒性。实验结果表明，该方法在语义分割任务上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶（AD）系统在恶劣环境条件（如低照度和降水）下表现明显下降。AD数据集对恶劣条件的代表性不足，使得解决这一缺陷具有挑战性。为了规避获取和标注恶劣天气数据的成本高昂的问题，我们提出了一种新颖的域适应（DA）流程。

Method: 我们提出了一种新颖的域适应（DA）流程，将清晰天气图像转换为有雾、雨、雪和夜间图像。我们系统地开发和评估了几个新颖的数据生成流程，包括仅模拟、基于GAN和混合扩散-GAN方法，以从标记的清晰图像合成照片般逼真的恶劣图像。我们利用现有的DA GAN，并将其扩展以支持辅助输入，以及开发一种利用模拟和真实图像的新颖训练方法。我们还引入了一种通过自适应地将Stable-Diffusion图像到图像（img2img）的输出与其起源图像混合来减轻幻觉和伪影的方法。

Result: 我们对下游模型进行了微调，并在具有对应关系的恶劣条件数据集（ACDC）上进行了评估。

Conclusion: 通过在恶劣天气条件下训练模型，在语义分割方面整体提高了1.85%，在夜间条件方面提高了4.62%，证明了我们的混合方法在挑战性条件下具有鲁棒的自动驾驶感知能力。

Abstract: Autonomous Driving (AD) systems exhibit markedly degraded performance under
adverse environmental conditions, such as low illumination and precipitation.
The underrepresentation of adverse conditions in AD datasets makes it
challenging to address this deficiency. To circumvent the prohibitive cost of
acquiring and annotating adverse weather data, we propose a novel Domain
Adaptation (DA) pipeline that transforms clear-weather images into fog, rain,
snow, and nighttime images. Here, we systematically develop and evaluate
several novel data-generation pipelines, including simulation-only, GAN-based,
and hybrid diffusion-GAN approaches, to synthesize photorealistic adverse
images from labelled clear images. We leverage an existing DA GAN, extend it to
support auxiliary inputs, and develop a novel training recipe that leverages
both simulated and real images. The simulated images facilitate exact
supervision by providing perfectly matched image pairs, while the real images
help bridge the simulation-to-real (sim2real) gap. We further introduce a
method to mitigate hallucinations and artifacts in Stable-Diffusion
Image-to-Image (img2img) outputs by blending them adaptively with their
progenitor images. We finetune downstream models on our synthetic data and
evaluate them on the Adverse Conditions Dataset with Correspondences (ACDC). We
achieve 1.85 percent overall improvement in semantic segmentation, and 4.62
percent on nighttime, demonstrating the efficacy of our hybrid method for
robust AD perception under challenging conditions.

</details>


### [45] [Towards Efficient Vision State Space Models via Token Merging](https://arxiv.org/abs/2508.13599)
*Jinyoung Park,Minseok Son,Changick Kim*

Main category: cs.CV

TL;DR: MaMe 是一种新的 token 合并策略，用于提高基于 SSM 的视觉模型的效率，同时保持高性能。它通过量化 token 的重要性并保留序列信息来工作，并在各种任务中都表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了提高 SSM 在计算机视觉中的计算效率，以实现实际和可扩展的部署。在 SSM 中应用 token 缩减技术需要仔细考虑其独特的序列建模能力。

Method: MaMe 策略通过以下两个关键点来解决 token 合并的挑战：1. 量化 token 重要性：利用状态转移参数 $\mathbf{\Delta}$ 作为信息量度量。2. 保护序列属性：引入战略性的 token 排列来保留序列信息流。

Result: MaMe 在效率-性能权衡方面取得了优越的表现，特别是在积极的 token 缩减下，即使现有方法出现显著性能下降，MaMe 仍能保持鲁棒性。此外，MaMe 在视频和音频领域也展现了强大的泛化能力。

Conclusion: MaMe 是一种针对基于 SSM 的视觉模型而设计的 token 合并策略，通过利用状态转移参数 $\mathbf{\Delta}$ 作为信息量度量，并结合战略性的 token 排列来保留序列信息流，在效率-性能权衡方面取得了优越的表现，并在图像分类、视频和音频等多个领域展现了良好的泛化能力。

Abstract: State Space Models (SSMs) have emerged as powerful architectures in computer
vision, yet improving their computational efficiency remains crucial for
practical and scalable deployment.While token reduction serves as an effective
approach for model efficiency, applying it to SSMs requires careful
consideration of their unique sequential modeling capabilities.In this work, we
propose MaMe, a token-merging strategy tailored for SSM-based vision
models.MaMe addresses two key challenges: quantifying token importance and
preserving sequential properties. Our approach leverages the state transition
parameter $\mathbf{\Delta}$ as an informativeness measure and introduces
strategic token arrangements to preserve sequential information flow.Extensive
experiments demonstrate that MaMe achieves superior efficiency-performance
trade-offs for both fine-tuned and off-the-shelf models. Particularly, our
approach maintains robustness even under aggressive token reduction where
existing methods undergo significant performance degradation.Beyond image
classification, MaMe shows strong generalization capabilities across video and
audio domains, establishing an effective approach for enhancing efficiency in
diverse SSM applications.

</details>


### [46] [Unleashing Semantic and Geometric Priors for 3D Scene Completion](https://arxiv.org/abs/2508.13601)
*Shiyuan Chen,Wei Sui,Bohao Zhang,Zeyd Boukhers,John See,Cong Yang*

Main category: cs.CV

TL;DR: FoundationSSC通过双重解耦和轴感知融合，在3D语义场景补全任务中同时提升了语义和几何性能，并在多个数据集上取得了SOTA成果。


<details>
  <summary>Details</summary>
Motivation: 现有基于相机的3D语义场景补全方法通常使用耦合的编码器来提取语义和几何先验信息，这导致模型在处理相互冲突的需求时需要做出权衡，从而限制了整体性能。

Method: 提出了一种名为FoundationSSC的新框架，该框架在源级别和通路级别进行双重解耦。在源级别，引入基石编码器分别提供语义特征先验和立体成本体。在通路级别，利用专门的、解耦的通路进行细化。该框架还包括一个混合视图变换模块和一个轴感知融合（AAF）模块，用于融合多模态特征。

Result: +0.23 mIoU 和 +2.03 IoU 的提升（在SemanticKITTI数据集上），以及在SSCBench-KITTI-360数据集上达到21.78 mIoU 和 48.61 IoU 的最新性能。

Conclusion: FoundationSSC通过双重解耦（源级别和通路级别）解决了现有相机3D语义场景补全方法在语义和几何提取上的性能权衡问题。该框架使用独立的基石编码器为语义和几何分支提供先验信息，并通过专门的通路进行细化，最终生成解耦且精炼的输入。此外，提出的轴感知融合（AAF）模块能够有效融合这些信息。实验结果表明，FoundationSSC在SemanticKITTI和SSCBench-KITTI-360数据集上均取得了显著的性能提升，超越了现有最优方法。

Abstract: Camera-based 3D semantic scene completion (SSC) provides dense geometric and
semantic perception for autonomous driving and robotic navigation. However,
existing methods rely on a coupled encoder to deliver both semantic and
geometric priors, which forces the model to make a trade-off between
conflicting demands and limits its overall performance. To tackle these
challenges, we propose FoundationSSC, a novel framework that performs dual
decoupling at both the source and pathway levels. At the source level, we
introduce a foundation encoder that provides rich semantic feature priors for
the semantic branch and high-fidelity stereo cost volumes for the geometric
branch. At the pathway level, these priors are refined through specialised,
decoupled pathways, yielding superior semantic context and depth distributions.
Our dual-decoupling design produces disentangled and refined inputs, which are
then utilised by a hybrid view transformation to generate complementary 3D
features. Additionally, we introduce a novel Axis-Aware Fusion (AAF) module
that addresses the often-overlooked challenge of fusing these features by
anisotropically merging them into a unified representation. Extensive
experiments demonstrate the advantages of FoundationSSC, achieving simultaneous
improvements in both semantic and geometric metrics, surpassing prior bests by
+0.23 mIoU and +2.03 IoU on SemanticKITTI. Additionally, we achieve
state-of-the-art performance on SSCBench-KITTI-360, with 21.78 mIoU and 48.61
IoU. The code will be released upon acceptance.

</details>


### [47] [PersonaVlog: Personalized Multimodal Vlog Generation with Multi-Agent Collaboration and Iterative Self-Correction](https://arxiv.org/abs/2508.13602)
*Xiaolu Hou,Bing Ma,Jiaxiang Cheng,Xuhua Ren,Kai Yu,Wenyue Li,Tianxiang Zheng,Qinglin Lu*

Main category: cs.CV

TL;DR: PersonaVlog 是一个自动化 Vlog 生成框架，它利用多模态大语言模型（MLLMs）的多代理协作和反馈机制，根据主题和参考图像生成包含视频、背景音乐和内心独白的个性化 Vlog。该框架提高了效率和创造力，并提出了 ThemeVlogEval 用于评估。实验证明了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有 Vlog 生成方法依赖预定义脚本，缺乏动态性和个人表达。因此，需要一种能够实现有效多模态协作和高度个性化的自动化 Vlog 生成方法。

Method: 提出了一种基于多模态大语言模型（MLLMs）的多代理协作框架，用于生成个性化 Vlog。该框架能根据用户输入高效生成多模态内容创作的提示，并结合反馈和回滚机制，利用 MLLMs 评估和修正生成结果。此外，还提出了一个名为 ThemeVlogEval 的基于主题的自动化基准测试框架，用于评估。

Result: 通过实验证明，与基线方法相比，PersonaVlog 框架在生成个性化 Vlog 方面具有显著优势和巨大潜力。

Conclusion: 与基线相比，该框架在自动化 Vlog 生成方面表现出显著优势和巨大潜力。

Abstract: With the growing demand for short videos and personalized content, automated
Video Log (Vlog) generation has become a key direction in multimodal content
creation. Existing methods mostly rely on predefined scripts, lacking dynamism
and personal expression. Therefore, there is an urgent need for an automated
Vlog generation approach that enables effective multimodal collaboration and
high personalization. To this end, we propose PersonaVlog, an automated
multimodal stylized Vlog generation framework that can produce personalized
Vlogs featuring videos, background music, and inner monologue speech based on a
given theme and reference image. Specifically, we propose a multi-agent
collaboration framework based on Multimodal Large Language Models (MLLMs). This
framework efficiently generates high-quality prompts for multimodal content
creation based on user input, thereby improving the efficiency and creativity
of the process. In addition, we incorporate a feedback and rollback mechanism
that leverages MLLMs to evaluate and provide feedback on generated results,
thereby enabling iterative self-correction of multimodal content. We also
propose ThemeVlogEval, a theme-based automated benchmarking framework that
provides standardized metrics and datasets for fair evaluation. Comprehensive
experiments demonstrate the significant advantages and potential of our
framework over several baselines, highlighting its effectiveness and great
potential for generating automated Vlogs.

</details>


### [48] [Two-Factor Authentication Smart Entryway Using Modified LBPH Algorithm](https://arxiv.org/abs/2508.13617)
*Zakiah Ayop,Wan Mohamad Hariz Bin Wan Mohamad Rosdi,Looi Wei Hua,Syarulnaziah Anawar,Nur Fadzilah Othman*

Main category: cs.CV

TL;DR: 该研究提出了一种基于树莓派的智能门禁系统，结合了面部识别（LBPH）、密码验证和面罩检测功能。系统可在检测到陌生人时自动发出警报、激活监控并通知用户，支持Telegram远程控制，平均准确率达70%。用户接受度高。


<details>
  <summary>Details</summary>
Motivation: 随着近期（尤其是在COVID-19大流行期间）对人脸面罩检测需求的增加，尽管智能门禁中已开发了许多人脸检测模型，但缺乏针对人脸面罩检测的物联网（IoT）开发。

Method: 该系统采用本地二值模式直方图（LBPH）作为完整的面部识别算法，并使用改进的LBPH算法进行面部遮挡检测。该系统基于树莓派平台，集成了面部识别、密码验证、异常闯入时的警报和监控系统激活，并通过Telegram进行远程控制。

Result: 该系统在所有测试用户中的平均准确率约为70%，精确率约为80%，召回率约为83.26%。

Conclusion: 该系统能够执行面部识别和面部遮挡检测，自动执行远程控制以注册用户、锁定或解锁门以及通知所有者。用户验收测试表明，样本参与者高度接受该系统并愿意在未来使用。

Abstract: Face mask detection has become increasingly important recently, particularly
during the COVID-19 pandemic. Many face detection models have been developed in
smart entryways using IoT. However, there is a lack of IoT development on face
mask detection. This paper proposes a two-factor authentication system for
smart entryway access control using facial recognition and passcode
verification and an automation process to alert the owner and activate the
surveillance system when a stranger is detected and controls the system
remotely via Telegram on a Raspberry Pi platform. The system employs the Local
Binary Patterns Histograms for the full face recognition algorithm and modified
LBPH algorithm for occluded face detection. On average, the system achieved an
Accuracy of approximately 70%, a Precision of approximately 80%, and a Recall
of approximately 83.26% across all tested users. The results indicate that the
system is capable of conducting face recognition and mask detection, automating
the operation of the remote control to register users, locking or unlocking the
door, and notifying the owner. The sample participants highly accept it for
future use in the user acceptance test.

</details>


### [49] [RotBench: Evaluating Multimodal Large Language Models on Identifying Image Rotation](https://arxiv.org/abs/2508.13968)
*Tianyi Niu,Jaemin Cho,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CV

TL;DR: MLLMs在识别图像旋转方向上表现糟糕，尤其在区分90度和270度方面存在严重不足，其空间推理能力远不如人类。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究多模态大语言模型（MLLMs）在准确识别图像旋转方向方面的能力，评估其视觉推理和空间关系处理能力，并找出模型在该任务上的局限性。

Method: 本研究提出了RotBench基准测试，包含350张经过手动筛选的包含生活、肖像和风景的图像，用于评估MLLMs在识别0、90、180和270度旋转图像方面的能力。研究人员尝试了提供辅助信息（如图注、深度图）、使用思维链提示、同时展示不同方向的旋转图像以及修改投票机制等方法来提升模型性能，并通过微调进行了进一步实验。

Result: 研究发现，包括GPT-5、o3和Gemini-2.5-Pro在内的多种先进MLLMs在识别图像旋转方向方面表现不佳。仅有少数模型能可靠识别0度图像，部分模型能识别180度图像，但没有模型能可靠地区分90度和270度。辅助信息和思维链提示仅带来微小且不稳定的性能提升。同时展示不同方向的旋转图像能为部分模型带来性能提升，而投票机制则能改善较弱模型的表现。微调能显著提升模型识别180度图像的能力，但对区分90度和270度旋转无效。

Conclusion: 现有的多模态大语言模型（MLLMs）在识别图像旋转方向方面存在显著不足，其空间推理能力与人类感知存在差距。具体来说，大多数模型能准确识别0度图像，部分模型能识别180度图像，但都无法可靠地区分90度和270度旋转。辅助信息和思维链提示仅能带来微小且不稳定的改进，微调也未能有效提升区分90度和270度旋转的能力。

Abstract: We investigate to what extent Multimodal Large Language Models (MLLMs) can
accurately identify the orientation of input images rotated 0{\deg}, 90{\deg},
180{\deg}, and 270{\deg}. This task demands robust visual reasoning
capabilities to detect rotational cues and contextualize spatial relationships
within images, regardless of their orientation. To evaluate MLLMs on these
abilities, we introduce RotBench -- a 350-image manually-filtered benchmark
comprising lifestyle, portrait, and landscape images. Despite the relatively
simple nature of this task, we show that several state-of-the-art open and
proprietary MLLMs, including GPT-5, o3, and Gemini-2.5-Pro, do not reliably
identify rotation in input images. Providing models with auxiliary information
-- including captions, depth maps, and more -- or using chain-of-thought
prompting offers only small and inconsistent improvements. Our results indicate
that most models are able to reliably identify right-side-up (0{\deg}) images,
while certain models are able to identify upside-down (180{\deg}) images. None
can reliably distinguish between 90{\deg} and 270{\deg}. Simultaneously showing
the image rotated in different orientations leads to moderate performance gains
for reasoning models, while a modified setup using voting improves the
performance of weaker models. We further show that fine-tuning does not improve
models' ability to distinguish 90{\deg} and 270{\deg} rotations, despite
substantially improving the identification of 180{\deg} images. Together, these
results reveal a significant gap between MLLMs' spatial reasoning capabilities
and human perception in identifying rotation.

</details>


### [50] [TalkVid: A Large-Scale Diversified Dataset for Audio-Driven Talking Head Synthesis](https://arxiv.org/abs/2508.13618)
*Shunian Chen,Hejin Huang,Yexin Liu,Zihan Ye,Pengcheng Chen,Chenghao Zhu,Michael Guan,Rongsheng Wang,Junying Chen,Guanbin Li,Ser-Nam Lim,Harry Yang,Benyou Wang*

Main category: cs.CV

TL;DR: TalkVid是一个大规模、高质量、多样化的数据集，用于驱动会说话的头像合成，解决了现有数据集缺乏泛化能力的问题。


<details>
  <summary>Details</summary>
Motivation: 现有状态模型在化身生成方面缺乏对人类多样性（包括种族、语言和年龄群体）的泛化能力，这是由于现有训练数据在规模、质量和多样性方面存在局限性。

Method: TalkVid是通过一个原则性的、多阶段的自动化流程创建的，该流程严格筛选运动稳定性、美学质量和面部细节，并通过人类判断进行验证。TalkVid-Bench是一个分层的评估集，包含500个剪辑，在关键的人口统计学和语言学轴线上进行了精心平衡。

Result: TalkVid数据集包含1244小时的视频，来自7729个独特的说话者。TalkVid-Bench包含500个剪辑，在关键的人口统计学和语言学轴线上进行了平衡。

Conclusion: TalkVid数据集的训练模型在跨数据集泛化方面优于在先前数据集上训练的模型。TalkVid-Bench的分析揭示了传统聚合指标所掩盖的亚组别之间的性能差异，强调了其对未来研究的必要性。

Abstract: Audio-driven talking head synthesis has achieved remarkable photorealism, yet
state-of-the-art (SOTA) models exhibit a critical failure: they lack
generalization to the full spectrum of human diversity in ethnicity, language,
and age groups. We argue that this generalization gap is a direct symptom of
limitations in existing training data, which lack the necessary scale, quality,
and diversity. To address this challenge, we introduce TalkVid, a new
large-scale, high-quality, and diverse dataset containing 1244 hours of video
from 7729 unique speakers. TalkVid is curated through a principled, multi-stage
automated pipeline that rigorously filters for motion stability, aesthetic
quality, and facial detail, and is validated against human judgments to ensure
its reliability. Furthermore, we construct and release TalkVid-Bench, a
stratified evaluation set of 500 clips meticulously balanced across key
demographic and linguistic axes. Our experiments demonstrate that a model
trained on TalkVid outperforms counterparts trained on previous datasets,
exhibiting superior cross-dataset generalization. Crucially, our analysis on
TalkVid-Bench reveals performance disparities across subgroups that are
obscured by traditional aggregate metrics, underscoring its necessity for
future research. Code and data can be found in
https://github.com/FreedomIntelligence/TalkVid

</details>


### [51] [RCGNet: RGB-based Category-Level 6D Object Pose Estimation with Geometric Guidance](https://arxiv.org/abs/2508.13623)
*Sheng Yu,Di-Hua Zhai,Yuanqing Xia*

Main category: cs.CV

TL;DR: 提出一种仅用RGB图像进行物体姿态估计的方法，效果优于已有RGB-D方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数基于RGB-D的类别级物体姿态估计方法在缺乏深度信息的场景下面临巨大挑战。本文旨在提出一种仅依赖RGB图像的方法，以实现无需深度数据的准确姿态估计。

Method: 本文提出了一种仅依赖RGB图像的类别级物体姿态估计方法。该方法设计了一个基于Transformer的神经网络，用于预测和融合目标物体的几何特征。通过引入几何特征引导算法来增强网络表示物体几何信息的能力。最后，利用RANSAC-PnP算法计算物体姿态，解决了姿态估计中物体尺度变化的问题。

Result: 实验结果表明，该方法不仅效率高，而且精度优于之前的RGB方法。

Conclusion: 本文提出的仅依赖RGB图像进行类别级物体姿态估计的方法，在效率和精度上均优于以往的RGB方法，为仅使用RGB图像进行类别级物体姿态估计的研究提供了新的视角。

Abstract: While most current RGB-D-based category-level object pose estimation methods
achieve strong performance, they face significant challenges in scenes lacking
depth information. In this paper, we propose a novel category-level object pose
estimation approach that relies solely on RGB images. This method enables
accurate pose estimation in real-world scenarios without the need for depth
data. Specifically, we design a transformer-based neural network for
category-level object pose estimation, where the transformer is employed to
predict and fuse the geometric features of the target object. To ensure that
these predicted geometric features faithfully capture the object's geometry, we
introduce a geometric feature-guided algorithm, which enhances the network's
ability to effectively represent the object's geometric information. Finally,
we utilize the RANSAC-PnP algorithm to compute the object's pose, addressing
the challenges associated with variable object scales in pose estimation.
Experimental results on benchmark datasets demonstrate that our approach is not
only highly efficient but also achieves superior accuracy compared to previous
RGB-based methods. These promising results offer a new perspective for
advancing category-level object pose estimation using RGB images.

</details>


### [52] [DiffIER: Optimizing Diffusion Models with Iterative Error Reduction](https://arxiv.org/abs/2508.13628)
*Ao Chen,Lihe Ding,Tianfan Xue*

Main category: cs.CV

TL;DR: DiffIER通过解决训练-推理间隙来提高扩散模型的生成质量。


<details>
  <summary>Details</summary>
Motivation: 识别并解决了扩散模型中由“训练-推理间隙”导致的生成样本质量对引导权重敏感的问题。

Method: 提出了一种名为DiffIER的基于优化的方法，通过在推理的每一步进行迭代误差最小化来缩小训练-推理间隙，以提高生成质量。

Result: DiffIER方法有效降低了累积误差，提高了生成质量，并在文本到图像生成、图像超分辨率和文本到语音生成等任务中取得了优于基线方法的结果。

Conclusion: 所提出的DiffIER方法通过迭代误差最小化，有效缩小了训练-推理间隙，提高了条件生成任务的性能，并在文本到图像生成、图像超分辨率和文本到语音生成等任务中取得了优于基线方法的结果，证明了其广泛的应用潜力。

Abstract: Diffusion models have demonstrated remarkable capabilities in generating
high-quality samples and enhancing performance across diverse domains through
Classifier-Free Guidance (CFG). However, the quality of generated samples is
highly sensitive to the selection of the guidance weight. In this work, we
identify a critical ``training-inference gap'' and we argue that it is the
presence of this gap that undermines the performance of conditional generation
and renders outputs highly sensitive to the guidance weight. We quantify this
gap by measuring the accumulated error during the inference stage and establish
a correlation between the selection of guidance weight and minimizing this gap.
Furthermore, to mitigate this gap, we propose DiffIER, an optimization-based
method for high-quality generation. We demonstrate that the accumulated error
can be effectively reduced by an iterative error minimization at each step
during inference. By introducing this novel plug-and-play optimization
framework, we enable the optimization of errors at every single inference step
and enhance generation quality. Empirical results demonstrate that our proposed
method outperforms baseline approaches in conditional generation tasks.
Furthermore, the method achieves consistent success in text-to-image
generation, image super-resolution, and text-to-speech generation, underscoring
its versatility and potential for broad applications in future research.

</details>


### [53] [OmniTry: Virtual Try-On Anything without Masks](https://arxiv.org/abs/2508.13632)
*Yutong Feng,Linlin Zhang,Hengyuan Cao,Yiming Chen,Xiaoduan Feng,Jian Cao,Yuxiong Wu,Bin Wang*

Main category: cs.CV

TL;DR: OmniTry是一个统一的框架，可以将虚拟试穿技术从服装扩展到珠宝、配饰等任何可穿戴物品，并且在无掩码的情况下实现更实用的应用。该框架通过两阶段流程解决数据配对难题，并在实验中证明了其在物体定位和ID保持方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的VTON（虚拟试穿）技术主要集中在服装上，而本研究旨在扩展VTON以包含任何可穿戴物品，如珠宝和配饰，并采用无掩码设置以实现更实际的应用。解决数据配对困难的问题。

Method: 提出一个两阶段的框架：第一阶段利用大规模无配对图像训练模型进行无掩码定位，并使用inpainting模型自动在空掩码的合适位置绘制物体；第二阶段用配对图像对模型进行微调，以转移物体外观的一致性。

Result: OmniTry在包含12种常见可穿戴物品的基准测试中表现出色，能够处理商店内和真实场景的图像。

Conclusion: OmniTry在物体定位和ID保持方面表现优于现有方法。

Abstract: Virtual Try-ON (VTON) is a practical and widely-applied task, for which most
of existing works focus on clothes. This paper presents OmniTry, a unified
framework that extends VTON beyond garment to encompass any wearable objects,
e.g., jewelries and accessories, with mask-free setting for more practical
application. When extending to various types of objects, data curation is
challenging for obtaining paired images, i.e., the object image and the
corresponding try-on result. To tackle this problem, we propose a two-staged
pipeline: For the first stage, we leverage large-scale unpaired images, i.e.,
portraits with any wearable items, to train the model for mask-free
localization. Specifically, we repurpose the inpainting model to automatically
draw objects in suitable positions given an empty mask. For the second stage,
the model is further fine-tuned with paired images to transfer the consistency
of object appearance. We observed that the model after the first stage shows
quick convergence even with few paired samples. OmniTry is evaluated on a
comprehensive benchmark consisting of 12 common classes of wearable objects,
with both in-shop and in-the-wild images. Experimental results suggest that
OmniTry shows better performance on both object localization and
ID-preservation compared with existing methods. The code, model weights, and
evaluation benchmark of OmniTry will be made publicly available at
https://omnitry.github.io/.

</details>


### [54] [DeH4R: A Decoupled and Hybrid Method for Road Network Graph Extraction](https://arxiv.org/abs/2508.13669)
*Dengxian Gong,Shunping Ji*

Main category: cs.CV

TL;DR: DeH4R是一种新的混合模型，用于从遥感图像中提取道路网络图。它结合了图生成和图增长方法的优点，实现了高效率、动态性和准确性，并在CityScale和SpaceNet基准测试中取得了最先进的性能，同时速度更快。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有基于分割、图增长和图生成的方法在从遥感影像中提取道路网络图时面临的挑战，例如拓扑保真度、计算成本和动态顶点插入限制。

Method: 提出了一种名为DeH4R的新型混合模型，该模型结合了图生成的高效性和图增长的动态性。

Result: 在CityScale和SpaceNet基准测试中，DeH4R取得了最先进（SOTA）的性能。与先前最先进的图增长方法RNGDet++相比，DeH4R在CityScale上的APLS提高了4.62，IoU提高了10.18，同时速度提高了约10倍。

Conclusion: DeH4R通过结合候选顶点检测、相邻顶点预测、初始图构建和图扩展，实现了动态顶点（边）插入，同时保持了快速推理速度，并提高了拓扑保真度和空间一致性。

Abstract: The automated extraction of complete and precise road network graphs from
remote sensing imagery remains a critical challenge in geospatial computer
vision. Segmentation-based approaches, while effective in pixel-level
recognition, struggle to maintain topology fidelity after vectorization
postprocessing. Graph-growing methods build more topologically faithful graphs
but suffer from computationally prohibitive iterative ROI cropping.
Graph-generating methods first predict global static candidate road network
vertices, and then infer possible edges between vertices. They achieve fast
topology-aware inference, but limits the dynamic insertion of vertices. To
address these challenges, we propose DeH4R, a novel hybrid model that combines
graph-generating efficiency and graph-growing dynamics. This is achieved by
decoupling the task into candidate vertex detection, adjacent vertex
prediction, initial graph contruction, and graph expansion. This architectural
innovation enables dynamic vertex (edge) insertions while retaining fast
inference speed and enhancing both topology fidelity and spatial consistency.
Comprehensive evaluations on CityScale and SpaceNet benchmarks demonstrate
state-of-the-art (SOTA) performance. DeH4R outperforms the prior SOTA
graph-growing method RNGDet++ by 4.62 APLS and 10.18 IoU on CityScale, while
being approximately 10 $\times$ faster. The code will be made publicly
available at https://github.com/7777777FAN/DeH4R.

</details>


### [55] [HumanPCR: Probing MLLM Capabilities in Diverse Human-Centric Scenes](https://arxiv.org/abs/2508.13692)
*Keliang Li,Hongze Shen,Hao Shi,Ruibing Hou,Hong Chang,Jie Huang,Chenghao Jia,Wen Wang,Yiling Wu,Dongmei Jiang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: HumanPCR 是一个包含 6000 多个问题的评估套件，用于测试多模态大语言模型在理解人类视觉场景方面的能力。评估结果表明，现有模型在空间感知、时间理解和心智建模方面存在困难，特别是需要主动提取信息和整合多重线索的推理任务。


<details>
  <summary>Details</summary>
Motivation: 人工智能通用智能的追求以及多模态模型的快速进展，要求模型在各种环境中达到媲美人类的性能。现有的基准测试在评估模型在人类相关视觉上下文中的能力方面存在不足。

Method: 提出了一种名为 HumanPCR 的评估套件，用于探测多模态大语言模型（MLLMs）在人类相关视觉上下文方面的能力，涵盖感知（Human-P）、理解（Human-C）和推理（Human-R）三个层次。Human-P 和 Human-C 包含超过 6000 道经人类验证的多项选择题，涵盖 9 个维度，包含现有基准测试常忽略的关键技能。Human-R 则提供了一个具有挑战性的人工策划视频推理测试，需要整合多重视觉证据、主动提取问题线索之外的上下文，并应用类似人类的专业知识。所有问题均附带人类标注的思维链（CoT）推理和关键视觉证据。

Result: 对超过 30 个最先进模型的广泛评估显示，多模态大语言模型在以人类为中心的视觉理解方面存在显著挑战，特别是在涉及细微空间感知、时间理解和心智建模的任务上。Human-R 的分析揭示了模型在从多样化人类场景中提取关键主动视觉证据方面的困难，以及它们在依赖查询引导检索方面的缺陷。

Conclusion: 评估结果表明，在细致的空间感知、时间理解和心智建模等任务上，多模态大语言模型在以人类为中心的视觉理解方面仍然面临巨大挑战。即使采用扩展视觉上下文和测试时思维等高级技术，也只能带来有限的改进。我们希望 HumanPCR 及其研究结果能推动多模态模型的开发、评估和以人类为中心的应用。

Abstract: The aspiration for artificial general intelligence, fueled by the rapid
progress of multimodal models, demands human-comparable performance across
diverse environments. We propose HumanPCR, an evaluation suite for probing
MLLMs' capacity about human-related visual contexts across three hierarchical
levels: Perception, Comprehension, and Reasoning (denoted by Human-P, Human-C,
and Human-R, respectively). Human-P and Human-C feature over 6,000
human-verified multiple choice questions, assessing massive tasks of 9
dimensions, including but not limited to essential skills frequently overlooked
by existing benchmarks. Human-R offers a challenging manually curated video
reasoning test that requires integrating multiple visual evidences, proactively
extracting context beyond question cues, and applying human-like expertise.
Each question includes human-annotated Chain-of-Thought (CoT) rationales with
key visual evidence to support further research. Extensive evaluations on over
30 state-of-the-art models exhibit significant challenges in human-centric
visual understanding, particularly in tasks involving detailed space
perception, temporal understanding, and mind modeling. Moreover, analysis of
Human-R reveals the struggle of models in extracting essential proactive visual
evidence from diverse human scenes and their faulty reliance on query-guided
retrieval. Even with advanced techniques like scaling visual contexts and
test-time thinking yield only limited benefits. We hope HumanPCR and our
findings will advance the development, evaluation, and human-centric
application of multimodal models.

</details>


### [56] [Diversity-enhanced Collaborative Mamba for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2508.13712)
*Shumeng Li,Jian Zhang,Lei Qi,Luping Zhou,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: DCMamba是一种新颖的半监督医学图像分割框架，它利用Mamba模型，并通过数据、网络和特征的多样性增强来提高分割性能，在少样本标注情况下取得了优于现有方法的显著成果。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中获取高质量标注数据成本高昂且耗时。利用无标注数据生成伪标签的半监督分割技术可以缓解这一问题。鉴于Mamba等先进状态空间模型在处理长距离依赖方面的高效性，本文旨在探索其在半监督医学图像分割中的潜力。

Method: 提出了一种名为DCMamba的新型框架，该框架通过数据、网络和特征三个层面增强多样性来提升半监督医学图像分割的效果。具体包括：1. 数据层面：利用Mamba的扫描建模特性，开发了块级弱-强混合增强。2. 网络层面：引入了多样的扫描协作模块，利用不同扫描方向的预测差异。3. 特征层面：采用了不确定性加权对比学习机制，以增强特征表示的多样性。

Result: 实验证明，DCMamba在Synapse数据集上，使用20%的标注数据时，相比其他半监督医学图像分割方法，特别是最新的SSM-based方法，取得了6.69%的性能提升，证明了其有效性。

Conclusion: DCMamba在少样本场景下显著优于其他半监督分割方法，在Synapse数据集上使用20%的标注数据时，比最新的基于SSM的方法提高了6.69%。

Abstract: Acquiring high-quality annotated data for medical image segmentation is
tedious and costly. Semi-supervised segmentation techniques alleviate this
burden by leveraging unlabeled data to generate pseudo labels. Recently,
advanced state space models, represented by Mamba, have shown efficient
handling of long-range dependencies. This drives us to explore their potential
in semi-supervised medical image segmentation. In this paper, we propose a
novel Diversity-enhanced Collaborative Mamba framework (namely DCMamba) for
semi-supervised medical image segmentation, which explores and utilizes the
diversity from data, network, and feature perspectives. Firstly, from the data
perspective, we develop patch-level weak-strong mixing augmentation with
Mamba's scanning modeling characteristics. Moreover, from the network
perspective, we introduce a diverse-scan collaboration module, which could
benefit from the prediction discrepancies arising from different scanning
directions. Furthermore, from the feature perspective, we adopt an
uncertainty-weighted contrastive learning mechanism to enhance the diversity of
feature representation. Experiments demonstrate that our DCMamba significantly
outperforms other semi-supervised medical image segmentation methods, e.g.,
yielding the latest SSM-based method by 6.69% on the Synapse dataset with 20%
labeled data.

</details>


### [57] [Hierarchical Vision-Language Retrieval of Educational Metaverse Content in Agriculture](https://arxiv.org/abs/2508.13713)
*Ali Abdari,Alex Falcon,Giuseppe Serra*

Main category: cs.CV

TL;DR: 该研究提出了一个包含457个农业主题虚拟博物馆的新数据集，并开发了一种新的模型，可以根据自然语言查询来搜索和检索这些博物馆，实验结果表明该模型非常有效。


<details>
  <summary>Details</summary>
Motivation: 为了应对在元宇宙中搜索和匹配用户兴趣的农业和园艺教育内容的挑战，解决现有数据集规模小的问题。

Method: 提出了一种层次化视觉-语言模型来表示和检索相关的AgriMuseums，并通过实验验证了其有效性。

Result: 所提出的方法在实验中达到了约62%的R@1和78%的MRR，并在现有基准测试上取得了最高11%的MRR提升。

Conclusion: 该研究提出了一个包含457个农业主题虚拟博物馆（AgriMuseums）及其文本描述的新数据集，并提出了一种层次化视觉-语言模型来表示和检索相关的AgriMuseums。

Abstract: Every day, a large amount of educational content is uploaded online across
different areas, including agriculture and gardening. When these videos or
materials are grouped meaningfully, they can make learning easier and more
effective. One promising way to organize and enrich such content is through the
Metaverse, which allows users to explore educational experiences in an
interactive and immersive environment. However, searching for relevant
Metaverse scenarios and finding those matching users' interests remains a
challenging task. A first step in this direction has been done recently, but
existing datasets are small and not sufficient for training advanced models. In
this work, we make two main contributions: first, we introduce a new dataset
containing 457 agricultural-themed virtual museums (AgriMuseums), each enriched
with textual descriptions; and second, we propose a hierarchical
vision-language model to represent and retrieve relevant AgriMuseums using
natural language queries. In our experimental setting, the proposed method
achieves up to about 62\% R@1 and 78\% MRR, confirming its effectiveness, and
it also leads to improvements on existing benchmarks by up to 6\% R@1 and 11\%
MRR. Moreover, an extensive evaluation validates our design choices. Code and
dataset are available at
https://github.com/aliabdari/Agricultural_Metaverse_Retrieval .

</details>


### [58] [Enhancing Targeted Adversarial Attacks on Large Vision-Language Models through Intermediate Projector Guidance](https://arxiv.org/abs/2508.13739)
*Yiming Cao,Yanjie Li,Kaisheng Liang,Yuni Lai,Bin Xiao*

Main category: cs.CV

TL;DR: IPGA是一种新的对抗性攻击方法，通过攻击VLM的投影仪模块（Q-Former）来实现更精细的控制和操纵，并且比现有方法更有效、更具可迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有的针对视觉语言模型（VLM）的对抗性攻击方法存在局限性，包括全局扰动限制了攻击的精细度，以及忽略了投影仪模块，阻碍了对VLM的完整视觉-语言对齐流程的破坏。

Method: IPGA利用Q-Former（在第一阶段预训练）来操作语义上有意义的视觉标记，而不是单一的全局表示。RQA用于保留不相关的视觉内容，以实现更可控和精确的操纵。

Result: IPGA在标准图像字幕和细粒度视觉问答任务中，在黑盒环境下，其攻击效果和跨不同VLM的可迁移性均优于现有方法，并成功迁移到谷歌Gemini和OpenAI GPT。

Conclusion: IPGA是一种新的、首次攻击中间投影仪模块（特别是Q-Former）的方法，在保持不相关视觉内容的同时，实现更精确的控制和对抗性操纵。它在标准图像字幕和细粒度视觉问答任务上都优于现有方法，并且能够成功迁移到谷歌Gemini和OpenAI GPT等多个商业VLM。

Abstract: Targeted adversarial attacks are essential for proactively identifying
security flaws in Vision-Language Models before real-world deployment. However,
current methods perturb images to maximize global similarity with the target
text or reference image at the encoder level, collapsing rich visual semantics
into a single global vector. This limits attack granularity, hindering
fine-grained manipulations such as modifying a car while preserving its
background. Furthermore, these methods largely overlook the projector module, a
critical semantic bridge between the visual encoder and the language model in
VLMs, thereby failing to disrupt the full vision-language alignment pipeline
within VLMs and limiting attack effectiveness. To address these issues, we
propose the Intermediate Projector Guided Attack (IPGA), the first method to
attack using the intermediate stage of the projector module, specifically the
widely adopted Q-Former, which transforms global image embeddings into
fine-grained visual features. This enables more precise control over
adversarial perturbations by operating on semantically meaningful visual tokens
rather than a single global representation. Specifically, IPGA leverages the
Q-Former pretrained solely on the first vision-language alignment stage,
without LLM fine-tuning, which improves both attack effectiveness and
transferability across diverse VLMs. Furthermore, we propose Residual Query
Alignment (RQA) to preserve unrelated visual content, thereby yielding more
controlled and precise adversarial manipulations. Extensive experiments show
that our attack method consistently outperforms existing methods in both
standard global image captioning tasks and fine-grained visual
question-answering tasks in black-box environment. Additionally, IPGA
successfully transfers to multiple commercial VLMs, including Google Gemini and
OpenAI GPT.

</details>


### [59] [Mitigating Cross-Image Information Leakage in LVLMs for Multi-Image Tasks](https://arxiv.org/abs/2508.13744)
*Yeji Park,Minyoung Lee,Sanghyuk Chun,Junsuk Choe*

Main category: cs.CV

TL;DR: LVLM 在处理多图像时存在跨图像信息泄露问题。 FOCUS 策略通过用噪声掩蔽除一张图像外的所有图像，并进行对比度精炼，在无需额外训练或架构修改的情况下，有效解决了此问题并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是，大型视觉语言模型（LVLM）在处理单图像任务时表现出色，但在处理多图像输入时性能会显著下降，原因是来自不同图像的视觉线索会在模型的输出中纠缠在一起，导致跨图像信息泄露。

Method: FOCUS 是一种训练无关且架构无关的解码策略。它通过顺序地用随机噪声掩蔽除一张图像外的所有图像，引导模型关注单张清晰图像。然后，它在所有目标图像上重复此过程，以获得部分掩蔽上下文下的对数。最后，使用纯噪声参考输入对这些对数进行对比度精炼，以抑制泄露并获得更准确的输出。

Result: FOCUS 策略在四个多图像基准测试和多种 LVLM 系列中一致地提高了性能，证明了其作为一种无需额外训练或架构修改即可增强多图像推理的通用且实用的解决方案。

Conclusion: FOCUS 是一种通用的、无需训练且不受架构限制的解码策略，通过在推理过程中顺序地用随机噪声掩蔽除一张图像外的所有图像，引导模型关注单张清晰图像，从而减轻了跨图像信息泄露问题。通过在所有目标图像上重复此过程以获得部分掩蔽上下文下的对数，并使用纯噪声参考输入进行对比度精炼，可以抑制泄露并获得更准确的输出。FOCUS 在四个多图像基准测试和多种 LVLM 系列中持续提高性能，证明了其在无需额外训练或架构修改的情况下增强多图像推理的有效性。

Abstract: Large Vision-Language Models (LVLMs) demonstrate strong performance on
single-image tasks. However, we observe that their performance degrades
significantly when handling multi-image inputs. This occurs because visual cues
from different images become entangled in the model's output. We refer to this
phenomenon as cross-image information leakage. To address this issue, we
propose FOCUS, a training-free and architecture-agnostic decoding strategy that
mitigates cross-image information leakage during inference. FOCUS sequentially
masks all but one image with random noise, guiding the model to focus on the
single clean image. We repeat this process across all target images to obtain
logits under partially masked contexts. These logits are aggregated and then
contrastively refined using a noise-only reference input, which suppresses the
leakage and yields more accurate outputs. FOCUS consistently improves
performance across four multi-image benchmarks and diverse LVLM families. This
demonstrates that FOCUS offers a general and practical solution for enhancing
multi-image reasoning without additional training or architectural
modifications.

</details>


### [60] [Shape-from-Template with Generalised Camera](https://arxiv.org/abs/2508.13791)
*Agniva Sengupta,Stefan Zachow*

Main category: cs.CV

TL;DR: 本文提出了一种新的多相机非刚性三维形状配准方法，并提供了三种具体的实现方式。


<details>
  <summary>Details</summary>
Motivation: SfT 被广泛研究用于单图像，但多相机联合 SfT 为三维形状配准（如医学成像）和手持相机配准等应用开辟了新的可能性。

Method: 本文提出三种 SfT 方法：1. 关键点位于已知三维点的方向向量上；2. 关键点位于未知三维点但已知相对于局部参考系的方位角的方向向量上；3. 除了对应点外，还已知物体轮廓。其中，基于对应点的方法使用凸优化求解，基于轮廓的方法是对凸优化结果的迭代优化。

Result: 证明了所提出的基于凸优化和迭代精化的 SfT 方法在合成和真实数据上的准确性。

Conclusion: 本文提出了使用广义相机模型进行三维形状到二维关键点非刚性配准（Shape-from-Template, SfT）的多种方法，并证明了其在合成和真实数据上的准确性。

Abstract: This article presents a new method for non-rigidly registering a 3D shape to
2D keypoints observed by a constellation of multiple cameras. Non-rigid
registration of a 3D shape to observed 2D keypoints, i.e., Shape-from-Template
(SfT), has been widely studied using single images, but SfT with information
from multiple-cameras jointly opens new directions for extending the scope of
known use-cases such as 3D shape registration in medical imaging and
registration from hand-held cameras, to name a few. We represent such
multi-camera setup with the generalised camera model; therefore any collection
of perspective or orthographic cameras observing any deforming object can be
registered. We propose multiple approaches for such SfT: the first approach
where the corresponded keypoints lie on a direction vector from a known 3D
point in space, the second approach where the corresponded keypoints lie on a
direction vector from an unknown 3D point in space but with known orientation
w.r.t some local reference frame, and a third approach where, apart from
correspondences, the silhouette of the imaged object is also known. Together,
these form the first set of solutions to the SfT problem with generalised
cameras. The key idea behind SfT with generalised camera is the improved
reconstruction accuracy from estimating deformed shape while utilising the
additional information from the mutual constraints between multiple views of a
deformed object. The correspondence-based approaches are solved with convex
programming while the silhouette-based approach is an iterative refinement of
the results from the convex solutions. We demonstrate the accuracy of our
proposed methods on many synthetic and real data

</details>


### [61] [VisionLaw: Inferring Interpretable Intrinsic Dynamics from Visual Observations via Bilevel Optimization](https://arxiv.org/abs/2508.13792)
*Jiajing Lin,Shu Jiang,Qingyuan Zeng,Zhenzhong Wang,Min Jiang*

Main category: cs.CV

TL;DR: VisionLaw uses a bilevel optimization framework with LLM-driven evolution and vision-guided evaluation to infer interpretable object dynamics from visual data, overcoming limitations of existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods for inferring intrinsic object dynamics from visual observations face challenges with manually defined priors (limited generalization) and neural networks (limited interpretability and generalization).

Method: VisionLaw, a bilevel optimization framework that infers interpretable expressions of intrinsic dynamics from visual observations. It features an LLMs-driven decoupled constitutive evolution strategy at the upper level and a vision-guided constitutive evaluation mechanism at the lower level.

Result: Experiments on synthetic and real-world datasets show VisionLaw effectively infers interpretable intrinsic dynamics, outperforming state-of-the-art methods and generalizing well to novel scenarios.

Conclusion: VisionLaw can effectively infer interpretable intrinsic dynamics from visual observations, significantly outperforming existing methods and exhibiting strong generalization for interactive simulation in novel scenarios.

Abstract: The intrinsic dynamics of an object governs its physical behavior in the real
world, playing a critical role in enabling physically plausible interactive
simulation with 3D assets. Existing methods have attempted to infer the
intrinsic dynamics of objects from visual observations, but generally face two
major challenges: one line of work relies on manually defined constitutive
priors, making it difficult to generalize to complex scenarios; the other
models intrinsic dynamics using neural networks, resulting in limited
interpretability and poor generalization. To address these challenges, we
propose VisionLaw, a bilevel optimization framework that infers interpretable
expressions of intrinsic dynamics from visual observations. At the upper level,
we introduce an LLMs-driven decoupled constitutive evolution strategy, where
LLMs are prompted as a knowledgeable physics expert to generate and revise
constitutive laws, with a built-in decoupling mechanism that substantially
reduces the search complexity of LLMs. At the lower level, we introduce a
vision-guided constitutive evaluation mechanism, which utilizes visual
simulation to evaluate the consistency between the generated constitutive law
and the underlying intrinsic dynamics, thereby guiding the upper-level
evolution. Experiments on both synthetic and real-world datasets demonstrate
that VisionLaw can effectively infer interpretable intrinsic dynamics from
visual observations. It significantly outperforms existing state-of-the-art
methods and exhibits strong generalization for interactive simulation in novel
scenarios.

</details>


### [62] [A Fully Transformer Based Multimodal Framework for Explainable Cancer Image Segmentation Using Radiology Reports](https://arxiv.org/abs/2508.13796)
*Enobong Adahada,Isabel Sassoon,Kate Hone,Yongmin Li*

Main category: cs.CV

TL;DR: Med-CTX是一个用于乳腺癌超声分割的多模态Transformer框架，结合临床报告提高性能和可解释性。它在BUS-BRA数据集上表现优于现有方法，并能提供分割掩码、不确定性图和诊断依据。


<details>
  <summary>Details</summary>
Motivation: 在医学图像分析中，提高分割性能和模型可解释性至关重要，特别是在乳腺癌超声检查中。

Method: Med-CTX 是一个完全基于 Transformer 的多模态框架，用于可解释的乳腺癌超声分割。它集成临床放射学报告以提高性能和可解释性。Med-CTX 使用结合了 ViT 和 Swin Transformer 的双分支视觉编码器以及注意不确定性融合来实现精确的病灶描绘。使用 BI-RADS 语义结构化的临床语言由 BioClinicalBERT 编码，并通过跨模态注意力与视觉特征相结合，使模型能够提供临床依据的模型生成解释。

Result: Med-CTX 能够同时生成分割掩码、不确定性图和诊断依据，从而提高计算机辅助诊断的置信度和透明度。

Conclusion: Med-CTX 在 BUS-BRA 数据集上取得了 99% 的 Dice 分数和 95% 的 IoU，优于 U-Net、ViT 和 Swin 等现有方法。临床文本在分割准确性和解释质量方面发挥着关键作用，消融研究表明 Dice 分数下降了 5.4%，CIDEr 指标下降了 31%。Med-CTX 实现了良好的多模态对齐（CLIP 分数：85%）和更高的置信度校准（ECE：3.2%），为可信赖的多模态医学架构设定了新标准。

Abstract: We introduce Med-CTX, a fully transformer based multimodal framework for
explainable breast cancer ultrasound segmentation. We integrate clinical
radiology reports to boost both performance and interpretability. Med-CTX
achieves exact lesion delineation by using a dual-branch visual encoder that
combines ViT and Swin transformers, as well as uncertainty aware fusion.
Clinical language structured with BI-RADS semantics is encoded by
BioClinicalBERT and combined with visual features utilising cross-modal
attention, allowing the model to provide clinically grounded, model generated
explanations. Our methodology generates segmentation masks, uncertainty maps,
and diagnostic rationales all at once, increasing confidence and transparency
in computer assisted diagnosis. On the BUS-BRA dataset, Med-CTX achieves a Dice
score of 99% and an IoU of 95%, beating existing baselines U-Net, ViT, and
Swin. Clinical text plays a key role in segmentation accuracy and explanation
quality, as evidenced by ablation studies that show a -5.4% decline in Dice
score and -31% in CIDEr. Med-CTX achieves good multimodal alignment (CLIP
score: 85%) and increased confi dence calibration (ECE: 3.2%), setting a new
bar for trustworthy, multimodal medical architecture.

</details>


### [63] [Unsupervised Urban Tree Biodiversity Mapping from Street-Level Imagery Using Spatially-Aware Visual Clustering](https://arxiv.org/abs/2508.13814)
*Diaa Addeen Abuhani,Marco Seccaroni,Martina Mazzarello,Imran Zualkernan,Fabio Duarte,Carlo Ratti*

Main category: cs.CV

TL;DR: 在缺乏详细数据的情况下，使用结合了街道图像和空间种植模式的无监督学习方法来估算城市树木生物多样性。


<details>
  <summary>Details</summary>
Motivation: 城市树木生物多样性对于气候韧性、生态稳定性和城市宜居性至关重要，但大多数市政当局对其树冠缺乏详细了解。基于实地的清单能够对Shannon和Simpson多样性指数提供可靠的估计，但成本高昂且耗时，而监督式人工智能方法需要标记数据，但这些数据往往无法推广到不同地区。

Method: 该研究引入了一种无监督聚类框架，该框架整合了来自街道级图像的视觉嵌入和空间种植模式，以在没有标签的情况下估算生物多样性。

Result: 该方法应用于北美八个城市，能够以高保真度恢复属级生物多样性模式，其Shannon和Simpson指数的Wasserstein距离与真实值接近，并保留了空间自相关性。

Conclusion: 该方法能够实现对城市树木生物多样性的高保真度估计，并保留了空间自相关性。这种可扩展、细粒度的方法使得在缺乏详细清单的城市中进行生物多样性测绘成为可能，并为支持公平的绿色空间获取和城市生态系统的适应性管理提供了持续、低成本监测的途径。

Abstract: Urban tree biodiversity is critical for climate resilience, ecological
stability, and livability in cities, yet most municipalities lack detailed
knowledge of their canopies. Field-based inventories provide reliable estimates
of Shannon and Simpson diversity but are costly and time-consuming, while
supervised AI methods require labeled data that often fail to generalize across
regions. We introduce an unsupervised clustering framework that integrates
visual embeddings from street-level imagery with spatial planting patterns to
estimate biodiversity without labels. Applied to eight North American cities,
the method recovers genus-level diversity patterns with high fidelity,
achieving low Wasserstein distances to ground truth for Shannon and Simpson
indices and preserving spatial autocorrelation. This scalable, fine-grained
approach enables biodiversity mapping in cities lacking detailed inventories
and offers a pathway for continuous, low-cost monitoring to support equitable
access to greenery and adaptive management of urban ecosystems.

</details>


### [64] [Self-Aware Adaptive Alignment: Enabling Accurate Perception for Intelligent Transportation Systems](https://arxiv.org/abs/2508.13823)
*Tong Xiang,Hongxia Zhao,Fenghua Zhu,Yuanyuan Chen,Yisheng Lv*

Main category: cs.CV

TL;DR: 提出了一种名为SA3的自感知自适应对齐方法，用于解决智能交通检测中的跨域挑战。该方法通过注意力机制和区域建议网络实现特征对齐，并引入实例到图像级别的对齐模块来缩小域间隙，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决智能交通检测在跨域场景中面临的挑战。

Method: 该方法采用基于注意力的对齐模块来指导图像级特征对齐，实现源域和目标域之间的局部-全局自适应对齐。此外，还引入了一个针对目标域的实例到图像级对齐模块，以自适应地缩小域间隙。

Result: SA3在流行的跨域对象检测基准上取得了优于先前最先进方法的结果。

Conclusion: SA3在流行的跨域对象检测基准上取得了优于先前最先进方法的结果。

Abstract: Achieving top-notch performance in Intelligent Transportation detection is a
critical research area. However, many challenges still need to be addressed
when it comes to detecting in a cross-domain scenario. In this paper, we
propose a Self-Aware Adaptive Alignment (SA3), by leveraging an efficient
alignment mechanism and recognition strategy. Our proposed method employs a
specified attention-based alignment module trained on source and target domain
datasets to guide the image-level features alignment process, enabling the
local-global adaptive alignment between the source domain and target domain.
Features from both domains, whose channel importance is re-weighted, are fed
into the region proposal network, which facilitates the acquisition of salient
region features. Also, we introduce an instance-to-image level alignment module
specific to the target domain to adaptively mitigate the domain gap. To
evaluate the proposed method, extensive experiments have been conducted on
popular cross-domain object detection benchmarks. Experimental results show
that SA3 achieves superior results to the previous state-of-the-art methods.

</details>


### [65] [SAGA: Learning Signal-Aligned Distributions for Improved Text-to-Image Generation](https://arxiv.org/abs/2508.13866)
*Paul Grimal,Michaël Soumm,Hervé Le Borgne,Olivier Ferret,Akihiro Sugimoto*

Main category: cs.CV

TL;DR: A new method improves text-to-image generation by precisely aligning images with text prompts through a novel denoising process, outperforming existing methods and offering features like spatial control.


<details>
  <summary>Details</summary>
Motivation: State-of-the-art text-to-image models struggle with precise alignment to text prompts, leading to missing elements or unintended blending of concepts.

Method: The method explicitly models the signal component during the denoising process, learning a high-success-rate distribution conditioned on a target prompt. It is training-free and integrates with existing diffusion and flow matching architectures, supporting additional conditioning modalities like bounding boxes.

Result: The approach ensures generated images faithfully reflect corresponding prompts, offering fine-grained control and mitigating common artifacts. Extensive experiments demonstrate superior performance.

Conclusion: The proposed approach outperforms current state-of-the-art methods in generating images that faithfully reflect text prompts, mitigating over-optimization and out-of-distribution artifacts.

Abstract: State-of-the-art text-to-image models produce visually impressive results but
often struggle with precise alignment to text prompts, leading to missing
critical elements or unintended blending of distinct concepts. We propose a
novel approach that learns a high-success-rate distribution conditioned on a
target prompt, ensuring that generated images faithfully reflect the
corresponding prompts. Our method explicitly models the signal component during
the denoising process, offering fine-grained control that mitigates
over-optimization and out-of-distribution artifacts. Moreover, our framework is
training-free and seamlessly integrates with both existing diffusion and flow
matching architectures. It also supports additional conditioning modalities --
such as bounding boxes -- for enhanced spatial alignment. Extensive experiments
demonstrate that our approach outperforms current state-of-the-art methods. The
code is available at https://github.com/grimalPaul/gsn-factory.

</details>


### [66] [RICO: Two Realistic Benchmarks and an In-Depth Analysis for Incremental Learning in Object Detection](https://arxiv.org/abs/2508.13878)
*Matthias Neuwirth-Trapp,Maarten Bieshaar,Danda Pani Paudel,Luc Van Gool*

Main category: cs.CV

TL;DR: 增量学习在现实世界中的评估需要更真实的基准。我们提出了RICO基准（D-RICO和EC-RICO），并发现现有方法表现不佳，而回放少量旧数据的方法效果更好，但单独训练仍然是最佳选择。


<details>
  <summary>Details</summary>
Motivation: 现有的增量学习评估严重依赖于简化的基准测试，无法反映真实世界的性能。本研究旨在通过引入更真实、更具挑战性的基准来解决这一问题。

Method: 为了解决评估指标不足的问题，我们提出了两个真实增量对象检测基准（RICO）：域RICO（D-RICO）和扩展类别RICO（EC-RICO）。D-RICO侧重于域偏移，而EC-RICO则在每个增量学习步骤中集成新域和类别。这两个基准都包含了现有评估中缺失的挑战。

Result: 实验表明，所有增量学习方法在适应性和知识保留方面均表现不佳。然而，通过回放少量先前数据的方法优于所有基线。单独在数据上训练仍然是性能最好的方法。

Conclusion: 现有的增量学习方法在适应性和知识保留方面表现不佳，而通过回放少量旧数据可以超越所有方法。然而，单独在数据上进行训练仍然是最佳选择。我们认为这可能是由于蒸馏中的教师模型过弱、单一模型难以处理多样化任务以及模型可塑性不足。

Abstract: Incremental Learning (IL) trains models sequentially on new data without full
retraining, offering privacy, efficiency, and scalability. IL must balance
adaptability to new data with retention of old knowledge. However, evaluations
often rely on synthetic, simplified benchmarks, obscuring real-world IL
performance. To address this, we introduce two Realistic Incremental Object
Detection Benchmarks (RICO): Domain RICO (D-RICO) features domain shifts with a
fixed class set, and Expanding-Classes RICO (EC-RICO) integrates new domains
and classes per IL step. Built from 14 diverse datasets covering real and
synthetic domains, varying conditions (e.g., weather, time of day), camera
sensors, perspectives, and labeling policies, both benchmarks capture
challenges absent in existing evaluations. Our experiments show that all IL
methods underperform in adaptability and retention, while replaying a small
amount of previous data already outperforms all methods. However, individual
training on the data remains superior. We heuristically attribute this gap to
weak teachers in distillation, single models' inability to manage diverse
tasks, and insufficient plasticity. Our code will be made publicly available.

</details>


### [67] [In-hoc Concept Representations to Regularise Deep Learning in Medical Imaging](https://arxiv.org/abs/2508.13880)
*Valentina Corbetta,Floris Six Dijkstra,Regina Beets-Tan,Hoel Kervadec,Kristoffer Wickstrøm,Wilson Silva*

Main category: cs.CV

TL;DR: LCRReg是一种新颖的正则化方法，利用潜在概念表示（LCRs）来提高医学成像深度学习模型在分布转移下的泛化能力，而无需密集的概念标签。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学成像中通常会实现强大的分布内性能，但在分布转移下泛化能力较差，并且经常依赖于伪影关联而非临床上有意义的特征。

Method: LCRReg是一种新颖的正则化方法，它利用潜在概念表示（LCRs）（例如，概念激活向量（CAVs））来引导模型获得语义基础表示。LCRReg在主训练集中不需要概念标签，而是使用一小组辅助数据集来合成高质量、解耦的概念示例。提取预定义相关特征的LCRs，并结合正则化项，引导卷积神经网络（CNN）在与这些概念相关的潜在子空间内激活。

Result: 在受控的玩具数据集中，它显著提高了对注入伪影关联的鲁棒性，并且在多概念和多类别设置中仍然有效。在糖尿病视网膜病变二分类任务中，LCRReg在合成伪影扰动和样本外（OOD）泛化方面均能提高性能。

Conclusion: LCRReg是一种轻量级、与架构无关的策略，可在无需密集概念监督的情况下提高模型鲁棒性，在合成的伪影和样本外（OOD）泛化方面均能提高性能。

Abstract: Deep learning models in medical imaging often achieve strong in-distribution
performance but struggle to generalise under distribution shifts, frequently
relying on spurious correlations instead of clinically meaningful features. We
introduce LCRReg, a novel regularisation approach that leverages Latent Concept
Representations (LCRs) (e.g., Concept Activation Vectors (CAVs)) to guide
models toward semantically grounded representations. LCRReg requires no concept
labels in the main training set and instead uses a small auxiliary dataset to
synthesise high-quality, disentangled concept examples. We extract LCRs for
predefined relevant features, and incorporate a regularisation term that guides
a Convolutional Neural Network (CNN) to activate within latent subspaces
associated with those concepts. We evaluate LCRReg across synthetic and
real-world medical tasks. On a controlled toy dataset, it significantly
improves robustness to injected spurious correlations and remains effective
even in multi-concept and multiclass settings. On the diabetic retinopathy
binary classification task, LCRReg enhances performance under both synthetic
spurious perturbations and out-of-distribution (OOD) generalisation. Compared
to baselines, including multitask learning, linear probing, and post-hoc
concept-based models, LCRReg offers a lightweight, architecture-agnostic
strategy for improving model robustness without requiring dense concept
supervision. Code is available at the following link:
https://github.com/Trustworthy-AI-UU-NKI/lcr\_regularization

</details>


### [68] [Forecasting Smog Events Using ConvLSTM: A Spatio-Temporal Approach for Aerosol Index Prediction in South Asia](https://arxiv.org/abs/2508.13891)
*Taimur Khan*

Main category: cs.CV

TL;DR: 南亚烟霾严重，但缺乏区域实时预测。本研究使用Sentinel-5P数据和ConvLSTM模型，成功预测了气溶胶指数，未来可进一步优化。


<details>
  <summary>Details</summary>
Motivation: 南亚地区（主要影响印度-恒河平原）的南亚烟霾现象日益严重，但目前缺乏区域性的实时预测系统。气溶胶指数是衡量空气质量的关键指标，与烟霾形成密切相关。

Method: 利用Sentinel-5P气溶胶成分数据（2019-2023）和卷积长短期记忆（ConvLSTM）神经网络进行气溶胶指数预测。该模型能够捕捉空间和时间相关性。利用340-380 nm的紫外（UV）气溶胶指数作为预测因子。

Result: 模型能够以五天的间隔预测气溶胶指数，取得了平均平方误差约0.0018，损失约0.3995，结构相似性指数约0.74的预测结果。

Conclusion: 研究表明，使用Sentinel-5P数据和ConvLSTM神经网络可以对南亚霾事件中的气溶胶指数进行为期五天的预测，平均平方误差约为0.0018，损失约为0.3995，结构相似性指数约为0.74。该模型有效，但未来可通过整合额外数据和优化网络结构进行改进。

Abstract: The South Asian Smog refers to the recurring annual air pollution events
marked by high contaminant levels, reduced visibility, and significant
socio-economic impacts, primarily affecting the Indo-Gangetic Plains (IGP) from
November to February. Over the past decade, increased air pollution sources
such as crop residue burning, motor vehicles, and changing weather patterns
have intensified these smog events. However, real-time forecasting systems for
increased particulate matter concentrations are still not established at
regional scale. The Aerosol Index, closely tied to smog formation and a key
component in calculating the Air Quality Index (AQI), reflects particulate
matter concentrations. This study forecasts aerosol events using Sentinel-5P
air constituent data (2019-2023) and a Convolutional Long-Short Term Memory
(ConvLSTM) neural network, which captures spatial and temporal correlations
more effectively than previous models. Using the Ultraviolet (UV) Aerosol Index
at 340-380 nm as the predictor, results show the Aerosol Index can be
forecasted at five-day intervals with a Mean Squared Error of ~0.0018, loss of
~0.3995, and Structural Similarity Index of ~0.74. While effective, the model
can be improved by integrating additional data and refining its architecture.

</details>


### [69] [SCRNet: Spatial-Channel Regulation Network for Medical Ultrasound Image Segmentation](https://arxiv.org/abs/2508.13899)
*Weixin Xu,Ziliang Wang*

Main category: cs.CV

TL;DR: SCRNet, a novel network incorporating FAM and SCRM, enhances medical ultrasound image segmentation by effectively capturing both long-range and local features, achieving SOTA results.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing CNN-based methods (disregarding long-range dependencies) and Transformer-based methods (overlooking local contextual information) in medical ultrasound image segmentation.

Method: A novel Spatial-Channel Regulation Network (SCRNet) is proposed, incorporating a Feature Aggregation Module (FAM) and a Spatial-Channel Regulation Module (SCRM). FAM processes features from preceding layers through two branches of the Convolution and Cross-Attention Parallel Module (CCAPM) to capture both long-range dependencies and local contextual information. SCRM enhances the ability to discern salient regions and informative features.

Result: Extensive experiments demonstrate that SCRNet consistently achieves state-of-the-art (SOTA) performance compared to existing methods.

Conclusion: The proposed SCRNet, by integrating FAM and SCRM into the UNet encoder, achieves SOTA performance in medical ultrasound image segmentation, outperforming existing methods.

Abstract: Medical ultrasound image segmentation presents a formidable challenge in the
realm of computer vision. Traditional approaches rely on Convolutional Neural
Networks (CNNs) and Transformer-based methods to address the intricacies of
medical image segmentation. Nevertheless, inherent limitations persist, as
CNN-based methods tend to disregard long-range dependencies, while
Transformer-based methods may overlook local contextual information. To address
these deficiencies, we propose a novel Feature Aggregation Module (FAM)
designed to process two input features from the preceding layer. These features
are seamlessly directed into two branches of the Convolution and
Cross-Attention Parallel Module (CCAPM) to endow them with different roles in
each of the two branches to help establish a strong connection between the two
input features. This strategy enables our module to focus concurrently on both
long-range dependencies and local contextual information by judiciously merging
convolution operations with cross-attention mechanisms. Moreover, by
integrating FAM within our proposed Spatial-Channel Regulation Module (SCRM),
the ability to discern salient regions and informative features warranting
increased attention is enhanced. Furthermore, by incorporating the SCRM into
the encoder block of the UNet architecture, we introduce a novel framework
dubbed Spatial-Channel Regulation Network (SCRNet). The results of our
extensive experiments demonstrate the superiority of SCRNet, which consistently
achieves state-of-the-art (SOTA) performance compared to existing methods.

</details>


### [70] [PhysGM: Large Physical Gaussian Model for Feed-Forward 4D Synthesis](https://arxiv.org/abs/2508.13911)
*Chunji Lv,Zequn Chen,Donglin Di,Weinan Zhang,Hao Li,Wei Chen,Changsheng Li*

Main category: cs.CV

TL;DR: PhysGM是一个从单张图像生成4D物理模拟的框架，它联合预测3D高斯表示和物理属性，并使用DPO优化与参考视频对齐，大大提高了生成速度和真实感。 PhysGM还引入了一个包含24,000多个3D资产的新数据集PhysAssets。


<details>
  <summary>Details</summary>
Motivation: 现有物理驱动的3D运动合成方法依赖于预重建的3D高斯表示（3DGS），并且物理集成要么依赖于不灵活的手动定义物理属性，要么依赖于不稳定的、计算密集型的视频模型引导，这些都限制了方法的性能。

Method: PhysGM是一个前馈框架，能够从单张图像联合预测3D高斯表示及其物理属性，实现即时物理模拟和高保真4D渲染。首先通过联合优化高斯重建和概率物理预测建立基础模型，然后通过物理上合理的参考视频进行精炼，以提高渲染保真度和物理预测准确性。采用直接偏好优化（DPO）使模拟与参考视频对齐，避免了需要通过复杂可微分模拟和光栅化反向传播梯度的分数蒸馏采样（SDS）优化。为了便于训练，我们引入了一个新的数据集PhysAssets，包含超过24,000个3D资产，并附有物理属性和相应的引导视频。

Result: 实验结果表明，PhysGM能够从单张图像生成高保真4D模拟，速度比先前的工作显著提高，同时提供逼真的渲染结果。

Conclusion: PhysGM框架能够从单张图像生成高保真4D物理模拟，并在1分钟内完成，相比先前工作有显著加速，同时保证了逼真的渲染效果。

Abstract: While physics-grounded 3D motion synthesis has seen significant progress,
current methods face critical limitations. They typically rely on
pre-reconstructed 3D Gaussian Splatting (3DGS) representations, while physics
integration depends on either inflexible, manually defined physical attributes
or unstable, optimization-heavy guidance from video models. To overcome these
challenges, we introduce PhysGM, a feed-forward framework that jointly predicts
a 3D Gaussian representation and its physical properties from a single image,
enabling immediate, physical simulation and high-fidelity 4D rendering. We
first establish a base model by jointly optimizing for Gaussian reconstruction
and probabilistic physics prediction. The model is then refined with physically
plausible reference videos to enhance both rendering fidelity and physics
prediction accuracy. We adopt the Direct Preference Optimization (DPO) to align
its simulations with reference videos, circumventing Score Distillation
Sampling (SDS) optimization which needs back-propagating gradients through the
complex differentiable simulation and rasterization. To facilitate the
training, we introduce a new dataset PhysAssets of over 24,000 3D assets,
annotated with physical properties and corresponding guiding videos.
Experimental results demonstrate that our method effectively generates
high-fidelity 4D simulations from a single image in one minute. This represents
a significant speedup over prior works while delivering realistic rendering
results. Our project page is at:https://hihixiaolv.github.io/PhysGM.github.io/

</details>


### [71] [DIME-Net: A Dual-Illumination Adaptive Enhancement Network Based on Retinex and Mixture-of-Experts](https://arxiv.org/abs/2508.13921)
*Ziang Wang,Xiaoqin Wang,Dingyi Wang,Qiang Li,Shushan Qiao*

Main category: cs.CV

TL;DR: DIME-Net 是一种用于处理低光照和背光图像的新型双重光照增强框架，通过混合专家和注意力机制有效恢复图像质量，并在各种光照条件下表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决了现有方法主要关注单一类型光照退化，缺乏统一处理多样光照条件能力的问题。

Method: 提出了一种名为 DIME-Net 的双重光照增强框架。其核心是混合专家光照估计模块，利用稀疏门控机制自适应选择 S 型曲线专家网络。此外，还设计了一个包含光照感知交叉注意力和序列状态全局注意力机制的损伤恢复模块。

Result: DIME-Net 在低光照和背光场景下表现出优越的性能，能够处理复杂的光照条件，并具有良好的泛化能力。

Conclusion: DIME-Net 在合成和真实世界的低光照和背光数据集上，无需重新训练即可实现具有竞争力的性能，证明了其泛化能力和在各种复杂光照条件下实际多媒体应用的潜力。

Abstract: Image degradation caused by complex lighting conditions such as low-light and
backlit scenarios is commonly encountered in real-world environments,
significantly affecting image quality and downstream vision tasks. Most
existing methods focus on a single type of illumination degradation and lack
the ability to handle diverse lighting conditions in a unified manner. To
address this issue, we propose a dual-illumination enhancement framework called
DIME-Net. The core of our method is a Mixture-of-Experts illumination estimator
module, where a sparse gating mechanism adaptively selects suitable S-curve
expert networks based on the illumination characteristics of the input image.
By integrating Retinex theory, this module effectively performs enhancement
tailored to both low-light and backlit images. To further correct
illumination-induced artifacts and color distortions, we design a damage
restoration module equipped with Illumination-Aware Cross Attention and
Sequential-State Global Attention mechanisms. In addition, we construct a
hybrid illumination dataset, MixBL, by integrating existing datasets, allowing
our model to achieve robust illumination adaptability through a single training
process. Experimental results show that DIME-Net achieves competitive
performance on both synthetic and real-world low-light and backlit datasets
without any retraining. These results demonstrate its generalization ability
and potential for practical multimedia applications under diverse and complex
illumination conditions.

</details>


### [72] [ViT-FIQA: Assessing Face Image Quality using Vision Transformers](https://arxiv.org/abs/2508.13957)
*Andrea Atzori,Fadi Boutros,Naser Damer*

Main category: cs.CV

TL;DR: ViT-FIQA 是一种新的面部图像质量评估方法，它使用视觉 Transformer（ViT）和可学习的质量令牌来预测面部图像的效用，并在实验中取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的面部图像质量评估（FIQA）方法主要依赖于卷积神经网络（CNN），而视觉 Transformer（ViT）架构的潜力尚未被充分探索。

Method: ViT-FIQA 提出了一种新颖的方法，通过可学习的质量令牌扩展了标准的 ViT 主干，以预测任何给定面部图像的标量效用分数。可学习的质量令牌与标准的图像斑块令牌连接，并通过 ViT 编码器的全局自注意力处理整个序列，以聚合所有斑块的上下文信息。在主干输出处，ViT-FIQA 分成两个头：(1) 斑块令牌通过全连接层，并通过具有裕度惩罚的 softmax 损失学习判别性面部表示；(2) 质量令牌被馈送到回归头，以学习预测面部样本的效用。

Result: ViT-FIQA 扩展了标准 ViT 主干，通过可学习的质量令牌预测面部图像的效用分数。它包含一个用于学习面部表示的分类头和一个用于预测效用分数的回归头。

Conclusion: ViT-FIQA 在挑战性基准和几种 FR 模型上取得了顶级性能，证明了基于 Transformer 的架构在建模面部图像效用方面的有效性，并强调了 ViT 作为未来 FIQA 研究的可扩展基础的潜力。

Abstract: Face Image Quality Assessment (FIQA) aims to predict the utility of a face
image for face recognition (FR) systems. State-of-the-art FIQA methods mainly
rely on convolutional neural networks (CNNs), leaving the potential of Vision
Transformer (ViT) architectures underexplored. This work proposes ViT-FIQA, a
novel approach that extends standard ViT backbones, originally optimized for
FR, through a learnable quality token designed to predict a scalar utility
score for any given face image. The learnable quality token is concatenated
with the standard image patch tokens, and the whole sequence is processed via
global self-attention by the ViT encoders to aggregate contextual information
across all patches. At the output of the backbone, ViT-FIQA branches into two
heads: (1) the patch tokens are passed through a fully connected layer to learn
discriminative face representations via a margin-penalty softmax loss, and (2)
the quality token is fed into a regression head to learn to predict the face
sample's utility. Extensive experiments on challenging benchmarks and several
FR models, including both CNN- and ViT-based architectures, demonstrate that
ViT-FIQA consistently achieves top-tier performance. These results underscore
the effectiveness of transformer-based architectures in modeling face image
utility and highlight the potential of ViTs as a scalable foundation for future
FIQA research https://cutt.ly/irHlzXUC.

</details>


### [73] [ROVR-Open-Dataset: A Large-Scale Depth Dataset for Autonomous Driving](https://arxiv.org/abs/2508.13977)
*Xianda Guo,Ruijun Zhang,Yiqun Duan,Ruilin Wang,Keyuan Zhou,Wenzhao Zheng,Wenke Huang,Gangwei Xu,Mike Horton,Yuan Si,Hao Zhao,Long Chen*

Main category: cs.CV

TL;DR: 为自动驾驶、机器人和AR等领域创建了一个大规模、多样化的动态户外驾驶数据集，用于提升深度估计能力，其稀疏的真实深度标签和广泛的场景覆盖为模型泛化带来了新的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有深度估计数据集（如KITTI、nuScenes、DDAD）在多样性和可扩展性方面存在局限，并且基准性能趋于饱和，无法满足基础模型和多模态学习时代对大规模、多样化、低成本数据集的需求。

Method: 提出了一个轻量级的采集流程，用于创建大规模、多样化的动态户外驾驶环境数据集，包含20K视频帧，并辅以稀疏但统计上足够大的真实深度标签，以实现低成本、高覆盖率的数据集构建。

Result: 通过在该数据集上进行基准实验，验证了其有效性，并揭示了现有单目深度估计模型在处理复杂场景时存在的显著性能差距，为推动该领域的研究提供了新的评估标准。

Conclusion: 该数据集通过其大规模、多样化的场景和较低的深度密度，为单目深度估计研究提供了新的挑战和平台，突显了现有方法在复杂条件下的性能差距，为未来深度估计和基础模型的研究奠定了基础。

Abstract: Depth estimation is a fundamental task for 3D scene understanding in
autonomous driving, robotics, and augmented reality. Existing depth datasets,
such as KITTI, nuScenes, and DDAD, have advanced the field but suffer from
limitations in diversity and scalability. As benchmark performance on these
datasets approaches saturation, there is an increasing need for a new
generation of large-scale, diverse, and cost-efficient datasets to support the
era of foundation models and multi-modal learning. To address these challenges,
we introduce a large-scale, diverse, frame-wise continuous dataset for depth
estimation in dynamic outdoor driving environments, comprising 20K video frames
to evaluate existing methods. Our lightweight acquisition pipeline ensures
broad scene coverage at low cost, while sparse yet statistically sufficient
ground truth enables robust training. Compared to existing datasets, ours
presents greater diversity in driving scenarios and lower depth density,
creating new challenges for generalization. Benchmark experiments with standard
monocular depth estimation models validate the dataset's utility and highlight
substantial performance gaps in challenging conditions, establishing a new
platform for advancing depth estimation research.

</details>


### [74] [OmViD: Omni-supervised active learning for video action detection](https://arxiv.org/abs/2508.13983)
*Aayush Rana,Akash Kumar,Vibhav Vineet,Yogesh S Rawat*

Main category: cs.CV

TL;DR: 通过主动学习和 3D 超像素技术，为视频动作检测找到合适的注释类型，以降低成本。


<details>
  <summary>Details</summary>
Motivation: 视频动作检测需要密集时空注释，这既困难又昂贵。然而，现实世界视频的难度各不相同，可能不需要相同级别的注释。本文分析了每个样本的适当注释类型及其对时空视频动作检测的影响。

Method: 提出了一种主动学习策略来估计每种视频样本的适当注释类型，并引入了一种新颖的时空 3D 超像素方法来从这些注释生成伪标签。

Result: 在 UCF101-24 和 JHMDB-21 数据集上进行了验证，该方法在性能损失很小的情况下显著降低了注释成本。

Conclusion: 该研究提出了一种主动学习策略来估计每种视频样本的适当注释类型，并引入了一种新颖的时空 3D 超像素方法来从这些注释生成伪标签，从而实现有效的训练。该方法在 UCF101-24 和 JHMDB-21 数据集上得到了验证，在保证性能的同时显著降低了注释成本。

Abstract: Video action detection requires dense spatio-temporal annotations, which are
both challenging and expensive to obtain. However, real-world videos often vary
in difficulty and may not require the same level of annotation. This paper
analyzes the appropriate annotation types for each sample and their impact on
spatio-temporal video action detection. It focuses on two key aspects: 1) how
to obtain varying levels of annotation for videos, and 2) how to learn action
detection from different annotation types. The study explores video-level tags,
points, scribbles, bounding boxes, and pixel-level masks. First, a simple
active learning strategy is proposed to estimate the necessary annotation type
for each video. Then, a novel spatio-temporal 3D-superpixel approach is
introduced to generate pseudo-labels from these annotations, enabling effective
training. The approach is validated on UCF101-24 and JHMDB-21 datasets,
significantly cutting annotation costs with minimal performance loss.

</details>


### [75] [Physics-Based 3D Simulation for Synthetic Data Generation and Failure Analysis in Packaging Stability Assessment](https://arxiv.org/abs/2508.13989)
*Samuel Seligardi,Pietro Musoni,Eleonora Iotti,Gianluca Contesso,Alessandro Dal Palù*

Main category: cs.CV

TL;DR: 开发了一个物理模拟系统和深度学习模型，用于分析包装运输的安全性，可预测碰撞测试结果，减少了对物理测试的需求，降低了成本和环境影响。


<details>
  <summary>Details</summary>
Motivation: 随着物流行业需求的增长以及对安全性和环保性的关注，需要开发自动化系统和环保的替代包装材料，以确保运输安全并减少物理测试的成本和环境影响。

Method: 提出了一种可控且准确的物理模拟系统，包含支持多种配置的3D虚拟环境，并训练了一个深度神经网络来评估模拟生成的视频，以预测包装配置的碰撞测试结果。

Result: 该模拟系统能够复制移动的包装行为，并能通过深度学习模型预测碰撞测试结果，从而减少了物理测试的需求，降低了成本和环境影响，提高了测量精度。

Conclusion: 该系统通过物理模拟和深度学习，为运输包装的安全性提供了更准确、更经济、更环保的分析方法，并能预测碰撞测试结果。

Abstract: The design and analysis of pallet setups are essential for ensuring safety of
packages transportation. With rising demands in the logistics sector, the
development of automated systems utilizing advanced technologies has become
increasingly crucial. Moreover, the widespread use of plastic wrapping has
motivated researchers to investigate eco-friendly alternatives that still
adhere to safety standards. We present a fully controllable and accurate
physical simulation system capable of replicating the behavior of moving
pallets. It features a 3D graphics-based virtual environment that supports a
wide range of configurations, including variable package layouts, different
wrapping materials, and diverse dynamic conditions. This innovative approach
reduces the need for physical testing, cutting costs and environmental impact
while improving measurement accuracy for analyzing pallet dynamics.
Additionally, we train a deep neural network to evaluate the rendered videos
generated by our simulator, as a crash-test predictor for pallet
configurations, further enhancing the system's utility in safety analysis.

</details>


### [76] [Self-Supervised Sparse Sensor Fusion for Long Range Perception](https://arxiv.org/abs/2508.13995)
*Edoardo Palladin,Samuel Brucker,Filippo Ghilotti,Praveen Narayanan,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 提出了一种创新的3D编码和自监督学习方法，将自动驾驶感知距离提升至250米，显著提升了目标检测和激光雷达预测的性能，特别适用于高速公路场景。


<details>
  <summary>Details</summary>
Motivation: 为了使自动驾驶汽车和卡车能够在高速公路上安全行驶，需要将感知距离从城市驾驶的50-100米扩展到至少250米，以提供足够的规划和制动余量。此外，扩展感知距离也支持从轻型车辆到大型重载卡车的自主能力，因为后者需要更长的规划范围。

Method: 提出了一种基于稀疏表示的3D编码方法，结合多模态和时态特征，并设计了一种自监督预训练方案，利用无标签的相机-激光雷达数据进行大规模学习。

Result: 所提出的方法将感知距离扩展到250米，在目标检测方面mAP提高了26.6%，在激光雷达预测方面Chamfer距离降低了30.5%，优于现有方法。

Conclusion: 该研究通过使用稀疏表示、多模态和时态特征的3D编码以及新颖的自监督预训练方案，成功将自动驾驶感知距离扩展到250米，显著提高了目标检测精度（mAP提升26.6%）和激光雷达预测的Chamfer距离（降低30.5%），解决了现有BEV表示在长距离感知中的计算和内存瓶颈，为自动驾驶卡车等大型车辆在高速公路上的安全长距离行驶提供了解决方案。

Abstract: Outside of urban hubs, autonomous cars and trucks have to master driving on
intercity highways. Safe, long-distance highway travel at speeds exceeding 100
km/h demands perception distances of at least 250 m, which is about five times
the 50-100m typically addressed in city driving, to allow sufficient planning
and braking margins. Increasing the perception ranges also allows to extend
autonomy from light two-ton passenger vehicles to large-scale forty-ton trucks,
which need a longer planning horizon due to their high inertia. However, most
existing perception approaches focus on shorter ranges and rely on Bird's Eye
View (BEV) representations, which incur quadratic increases in memory and
compute costs as distance grows. To overcome this limitation, we built on top
of a sparse representation and introduced an efficient 3D encoding of
multi-modal and temporal features, along with a novel self-supervised
pre-training scheme that enables large-scale learning from unlabeled
camera-LiDAR data. Our approach extends perception distances to 250 meters and
achieves an 26.6% improvement in mAP in object detection and a decrease of
30.5% in Chamfer Distance in LiDAR forecasting compared to existing methods,
reaching distances up to 250 meters. Project Page:
https://light.princeton.edu/lrs4fusion/

</details>


### [77] [Online 3D Gaussian Splatting Modeling with Novel View Selection](https://arxiv.org/abs/2508.14014)
*Byeonggwon Lee,Junkyu Park,Khang Truong Giang,Soohwan Song*

Main category: cs.CV

TL;DR: 该研究提出了一种从RGB图像生成3D高斯泼溅模型的新方法，通过智能选择额外的图像来提高模型的完整性，并在复杂场景中取得了更好的效果。


<details>
  <summary>Details</summary>
Motivation: 旨在解决从仅RGB帧生成在线3D高斯泼溅模型时的挑战，特别是现有方法依赖关键帧导致重建不完整以及需要融合多视角信息以实现模型泛化性的问题。在线处理的限制也促使研究者寻找更有效的方法。

Method: 提出了一种新颖的3DGS建模方法，通过在线分析重建质量来选择最佳的非关键帧进行额外训练，并整合关键帧和选定的非关键帧，以提高模型的完整性。此外，还提出了一个结合在线多视图立体方法来确保3D信息一致性的框架。

Result: 实验结果表明，该方法在复杂的户外场景中，在模型的完整性和整体性能方面优于最先进的方法。

Conclusion: 提出的方法通过自适应视图选择和在线多视图立体方法，能够从仅RGB帧生成高质量3D高斯泼溅模型，提高了模型的完整性，并在复杂的户外场景中取得了优于现有方法的性能。

Abstract: This study addresses the challenge of generating online 3D Gaussian Splatting
(3DGS) models from RGB-only frames. Previous studies have employed dense SLAM
techniques to estimate 3D scenes from keyframes for 3DGS model construction.
However, these methods are limited by their reliance solely on keyframes, which
are insufficient to capture an entire scene, resulting in incomplete
reconstructions. Moreover, building a generalizable model requires
incorporating frames from diverse viewpoints to achieve broader scene coverage.
However, online processing restricts the use of many frames or extensive
training iterations. Therefore, we propose a novel method for high-quality 3DGS
modeling that improves model completeness through adaptive view selection. By
analyzing reconstruction quality online, our approach selects optimal
non-keyframes for additional training. By integrating both keyframes and
selected non-keyframes, the method refines incomplete regions from diverse
viewpoints, significantly enhancing completeness. We also present a framework
that incorporates an online multi-view stereo approach, ensuring consistency in
3D information throughout the 3DGS modeling process. Experimental results
demonstrate that our method outperforms state-of-the-art methods, delivering
exceptional performance in complex outdoor scenes.

</details>


### [78] [Backdooring Self-Supervised Contrastive Learning by Noisy Alignment](https://arxiv.org/abs/2508.14015)
*Tuo Chen,Jie Gui,Minjing Dong,Ju Jia,Lanting Fang,Jian Liu*

Main category: cs.CV

TL;DR: Self-supervised contrastive learning (CL) is vulnerable to data poisoning backdoor attacks (DPCLs). Existing DPCLs are limited in efficacy. We propose Noisy Alignment (NA), a DPCL method that suppresses noise components in poisoned images by manipulating contrastive learning's random cropping mechanism. NA is simple, effective, achieves state-of-the-art performance, maintains clean-data accuracy, and is robust against common backdoor defenses.


<details>
  <summary>Details</summary>
Motivation: Self-supervised contrastive learning (CL) effectively learns transferable representations from unlabeled data containing images or image-text pairs but suffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary can inject poisoned images into pretraining datasets, causing compromised CL encoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs, however, achieve limited efficacy due to their dependence on fragile implicit co-occurrence between backdoor and target object and inadequate suppression of discriminative features in backdoored images.

Method: We propose Noisy Alignment (NA), a DPCL method that explicitly suppresses noise components in poisoned images. Inspired by powerful training-controllable CL attacks, we identify and extract the critical objective of noisy alignment, adapting it effectively into data-poisoning scenarios. Our method implements noisy alignment by strategically manipulating contrastive learning's random cropping mechanism, formulating this process as an image layout optimization problem with theoretically derived optimal parameters.

Result: The resulting method is simple yet effective, achieving state-of-the-art performance compared to existing DPCLs, while maintaining clean-data accuracy. Furthermore, Noisy Alignment demonstrates robustness against common backdoor defenses.

Conclusion: Self-supervised contrastive learning (CL) effectively learns transferable representations from unlabeled data containing images or image-text pairs but suffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary can inject poisoned images into pretraining datasets, causing compromised CL encoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs, however, achieve limited efficacy due to their dependence on fragile implicit co-occurrence between backdoor and target object and inadequate suppression of discriminative features in backdoored images. We propose Noisy Alignment (NA), a DPCL method that explicitly suppresses noise components in poisoned images. Inspired by powerful training-controllable CL attacks, we identify and extract the critical objective of noisy alignment, adapting it effectively into data-poisoning scenarios. Our method implements noisy alignment by strategically manipulating contrastive learning's random cropping mechanism, formulating this process as an image layout optimization problem with theoretically derived optimal parameters. The resulting method is simple yet effective, achieving state-of-the-art performance compared to existing DPCLs, while maintaining clean-data accuracy. Furthermore, Noisy Alignment demonstrates robustness against common backdoor defenses.

Abstract: Self-supervised contrastive learning (CL) effectively learns transferable
representations from unlabeled data containing images or image-text pairs but
suffers vulnerability to data poisoning backdoor attacks (DPCLs). An adversary
can inject poisoned images into pretraining datasets, causing compromised CL
encoders to exhibit targeted misbehavior in downstream tasks. Existing DPCLs,
however, achieve limited efficacy due to their dependence on fragile implicit
co-occurrence between backdoor and target object and inadequate suppression of
discriminative features in backdoored images. We propose Noisy Alignment (NA),
a DPCL method that explicitly suppresses noise components in poisoned images.
Inspired by powerful training-controllable CL attacks, we identify and extract
the critical objective of noisy alignment, adapting it effectively into
data-poisoning scenarios. Our method implements noisy alignment by
strategically manipulating contrastive learning's random cropping mechanism,
formulating this process as an image layout optimization problem with
theoretically derived optimal parameters. The resulting method is simple yet
effective, achieving state-of-the-art performance compared to existing DPCLs,
while maintaining clean-data accuracy. Furthermore, Noisy Alignment
demonstrates robustness against common backdoor defenses. Codes can be found at
https://github.com/jsrdcht/Noisy-Alignment.

</details>


### [79] [InfiniteTalk: Audio-driven Video Generation for Sparse-Frame Video Dubbing](https://arxiv.org/abs/2508.14033)
*Shaoshu Yang,Zhe Kong,Feng Gao,Meng Cheng,Xiangyu Liu,Yong Zhang,Zhuoliang Kang,Wenhan Luo,Xunliang Cai,Ran He,Xiaoming Wei*

Main category: cs.CV

TL;DR: InfiniteTalk通过保留关键帧和优化生成过程，实现了更逼真、更具情感连贯性的全身视频配音。


<details>
  <summary>Details</summary>
Motivation: 传统的视频配音技术仅限于口型区域编辑，导致面部表情和身体姿态不协调，影响观众的沉浸感。为了克服这一局限性，需要一种能够实现全身运动编辑并保持身份、标志性姿势和摄像机轨迹的创新方法。

Method: 提出了一种名为InfiniteTalk的流式音频驱动生成器，用于无限长序列的视频配音。该方法通过保留稀疏的关键帧来维持身份、标志性姿势和摄像机轨迹，并通过利用时间上下文帧实现无缝的块间过渡，以及通过精细化的参考帧定位来优化控制强度，解决了现有模型在自适应条件控制方面的不足。

Result: 在HDTF、CelebV-HQ和EMTD数据集上的全面评估表明，该方法达到了最先进的性能。定量指标证实了其在视觉真实感、情感连贯性和全身运动同步性方面的优越性。

Conclusion: 该研究通过引入稀疏帧视频配音范式，利用时间上下文帧和优化的采样策略，实现了端到端的全方位、音频同步的全身运动编辑，解决了传统视频配音中口型区域编辑的局限性，并在多个数据集上取得了最先进的性能。

Abstract: Recent breakthroughs in video AIGC have ushered in a transformative era for
audio-driven human animation. However, conventional video dubbing techniques
remain constrained to mouth region editing, resulting in discordant facial
expressions and body gestures that compromise viewer immersion. To overcome
this limitation, we introduce sparse-frame video dubbing, a novel paradigm that
strategically preserves reference keyframes to maintain identity, iconic
gestures, and camera trajectories while enabling holistic, audio-synchronized
full-body motion editing. Through critical analysis, we identify why naive
image-to-video models fail in this task, particularly their inability to
achieve adaptive conditioning. Addressing this, we propose InfiniteTalk, a
streaming audio-driven generator designed for infinite-length long sequence
dubbing. This architecture leverages temporal context frames for seamless
inter-chunk transitions and incorporates a simple yet effective sampling
strategy that optimizes control strength via fine-grained reference frame
positioning. Comprehensive evaluations on HDTF, CelebV-HQ, and EMTD datasets
demonstrate state-of-the-art performance. Quantitative metrics confirm superior
visual realism, emotional coherence, and full-body motion synchronization.

</details>


### [80] [GeoSAM2: Unleashing the Power of SAM2 for 3D Part Segmentation](https://arxiv.org/abs/2508.14036)
*Ken Deng,Yunhan Yang,Jingxiang Sun,Xihui Liu,Yebin Liu,Ding Liang,Yan-Pei Cao*

Main category: cs.CV

TL;DR: DetailGen3D 是一种 3D 生成方法，通过潜在空间中的数据依赖流和令牌匹配策略来增强 3D 形状的几何细节，解决了现有方法细节不足的问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有 3D 生成方法因计算限制而导致的输出几何细节缺失问题。

Method: DetailGen3D 提出了一种直接通过数据依赖的潜在空间流来模拟粗糙到精细的变换的方法，并引入了一种令牌匹配策略来确保精炼过程中的空间对应，从而实现局部细节合成并保持全局结构。

Result: DetailGen3D 能够有效地增强由各种 3D 生成和重建方法生成的形状，实现高保真几何细节合成，同时保持训练效率。

Conclusion: DetailGen3D 能够有效地增强由各种 3D 生成和重建方法生成的形状，实现高保真几何细节合成，同时保持训练效率。

Abstract: Modern 3D generation methods can rapidly create shapes from sparse or single
views, but their outputs often lack geometric detail due to computational
constraints. We present DetailGen3D, a generative approach specifically
designed to enhance these generated 3D shapes. Our key insight is to model the
coarse-to-fine transformation directly through data-dependent flows in latent
space, avoiding the computational overhead of large-scale 3D generative models.
We introduce a token matching strategy that ensures accurate spatial
correspondence during refinement, enabling local detail synthesis while
preserving global structure. By carefully designing our training data to match
the characteristics of synthesized coarse shapes, our method can effectively
enhance shapes produced by various 3D generation and reconstruction approaches,
from single-view to sparse multi-view inputs. Extensive experiments demonstrate
that DetailGen3D achieves high-fidelity geometric detail synthesis while
maintaining efficiency in training.

</details>


### [81] [Distilled-3DGS:Distilled 3D Gaussian Splatting](https://arxiv.org/abs/2508.14037)
*Lintao Xiang,Xinkai Chen,Jianhuang Lai,Guangcong Wang*

Main category: cs.CV

TL;DR: Knowledge distillation for 3D Gaussian Splatting (3DGS) to reduce memory and storage by training a lightweight student model guided by teacher models, using a structural similarity loss for better geometric consistency. Achieves competitive rendering quality and efficiency.


<details>
  <summary>Details</summary>
Motivation: To address the significant memory consumption and storage requirements of 3D Gaussian Splatting (3DGS) which necessitate a large number of 3D Gaussians for high-fidelity rendering.

Method: Knowledge distillation framework using various teacher models (vanilla 3DGS, noise-augmented variants, dropout-regularized versions) and a lightweight student model. Includes a structural similarity loss to enhance the consistency of spatial geometric distributions between student and teacher models.

Result: The proposed Distilled-3DGS framework achieves promising rendering results in both rendering quality and storage efficiency compared to state-of-the-art methods through comprehensive quantitative and qualitative evaluations across diverse datasets.

Conclusion: Distilled-3DGS is a simple yet effective knowledge distillation framework that achieves promising rendering results in both rendering quality and storage efficiency compared to state-of-the-art methods.

Abstract: 3D Gaussian Splatting (3DGS) has exhibited remarkable efficacy in novel view
synthesis (NVS). However, it suffers from a significant drawback: achieving
high-fidelity rendering typically necessitates a large number of 3D Gaussians,
resulting in substantial memory consumption and storage requirements. To
address this challenge, we propose the first knowledge distillation framework
for 3DGS, featuring various teacher models, including vanilla 3DGS,
noise-augmented variants, and dropout-regularized versions. The outputs of
these teachers are aggregated to guide the optimization of a lightweight
student model. To distill the hidden geometric structure, we propose a
structural similarity loss to boost the consistency of spatial geometric
distributions between the student and teacher model. Through comprehensive
quantitative and qualitative evaluations across diverse datasets, the proposed
Distilled-3DGS, a simple yet effective framework without bells and whistles,
achieves promising rendering results in both rendering quality and storage
efficiency compared to state-of-the-art methods. Project page:
https://distilled3dgs.github.io . Code:
https://github.com/lt-xiang/Distilled-3DGS .

</details>


### [82] [Beyond Simple Edits: Composed Video Retrieval with Dense Modifications](https://arxiv.org/abs/2508.14039)
*Omkar Thawakar,Dmitry Demidov,Ritesh Thawkar,Rao Muhammad Anwer,Mubarak Shah,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 本文提出了一种新的数据集（Dense-WebVid-CoVR）和一种新的模型，用于解决成分视频检索的挑战。该模型通过交叉注意力融合视觉和文本信息，实现了对细粒度组合查询的精确对齐，并在检索任务上取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 标准的检索框架难以处理细粒度组合查询的复杂性以及时间理解的差异，这限制了它们在细粒度设置下的检索能力。为了解决这个问题，我们引入了一个新的数据集，能够捕获跨不同视频片段的细粒度和组合动作，从而在检索到的视频内容中实现更详细的组合更改。

Method: 提出了一种新的模型，通过使用基于地点的文本编码器集成视觉和文本信息，并利用交叉注意力（CA）融合，实现了查询修改和目标视频之间的精确对齐。

Result: 提出的模型在所有指标上均取得最先进的成果，在视觉+文本设置下实现了71.3%的Recall@1，优于现有技术3.4%。

Conclusion: 该模型在所有指标上均取得最先进的成果，在视觉+文本设置下实现了71.3%的Recall@1，优于现有技术3.4%，凸显了其在利用详细视频描述和密集修改文本方面的有效性。

Abstract: Composed video retrieval is a challenging task that strives to retrieve a
target video based on a query video and a textual description detailing
specific modifications. Standard retrieval frameworks typically struggle to
handle the complexity of fine-grained compositional queries and variations in
temporal understanding limiting their retrieval ability in the fine-grained
setting. To address this issue, we introduce a novel dataset that captures both
fine-grained and composed actions across diverse video segments, enabling more
detailed compositional changes in retrieved video content. The proposed
dataset, named Dense-WebVid-CoVR, consists of 1.6 million samples with dense
modification text that is around seven times more than its existing
counterpart. We further develop a new model that integrates visual and textual
information through Cross-Attention (CA) fusion using grounded text encoder,
enabling precise alignment between dense query modifications and target videos.
The proposed model achieves state-of-the-art results surpassing existing
methods on all metrics. Notably, it achieves 71.3\% Recall@1 in visual+text
setting and outperforms the state-of-the-art by 3.4\%, highlighting its
efficacy in terms of leveraging detailed video descriptions and dense
modification texts. Our proposed dataset, code, and model are available at
:https://github.com/OmkarThawakar/BSE-CoVR

</details>


### [83] [LongSplat: Robust Unposed 3D Gaussian Splatting for Casual Long Videos](https://arxiv.org/abs/2508.14041)
*Chin-Yang Lin,Cheng Sun,Fu-En Yang,Min-Hung Chen,Yen-Yu Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: LongSplat是一个新的无姿态3D高斯泼溅框架，通过增量联合优化、学习到的3D先验和八叉树锚形成来解决长视频新视角合成中的相机姿态和内存限制问题，实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决从偶然捕获的长视频进行新视角合成（NVS）的挑战，这些视频具有不规则的相机运动、未知的相机姿态和广阔的场景，以及现有方法在姿态漂移、不精确的几何初始化和严重的内存限制方面的问题。

Method: LongSplat是一个鲁棒的无姿态3D高斯泼溅框架，包括增量联合优化（同时优化相机姿态和3D高斯以避免局部最小值并确保全局一致性）、一个利用学习到的3D先验的鲁棒姿态估计模块，以及一个将密集点云转换为基于空间密度的锚的有效八叉树锚形成机制。

Result: LongSplat实现了最先进的结果，显著提高了渲染质量、姿态准确性和计算效率。

Conclusion: LongSplat在具有挑战性的基准测试中实现了最先进的结果，在渲染质量、姿态准确性和计算效率方面均显著优于先前的方法。

Abstract: LongSplat addresses critical challenges in novel view synthesis (NVS) from
casually captured long videos characterized by irregular camera motion, unknown
camera poses, and expansive scenes. Current methods often suffer from pose
drift, inaccurate geometry initialization, and severe memory limitations. To
address these issues, we introduce LongSplat, a robust unposed 3D Gaussian
Splatting framework featuring: (1) Incremental Joint Optimization that
concurrently optimizes camera poses and 3D Gaussians to avoid local minima and
ensure global consistency; (2) a robust Pose Estimation Module leveraging
learned 3D priors; and (3) an efficient Octree Anchor Formation mechanism that
converts dense point clouds into anchors based on spatial density. Extensive
experiments on challenging benchmarks demonstrate that LongSplat achieves
state-of-the-art results, substantially improving rendering quality, pose
accuracy, and computational efficiency compared to prior approaches. Project
page: https://linjohnss.github.io/longsplat/

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [84] [Fair Play in the Newsroom: Actor-Based Filtering Gender Discrimination in Text Corpora](https://arxiv.org/abs/2508.13169)
*Stefanie Urchs,Veronika Thurner,Matthias Aßenmacher,Christian Heumann,Stephanie Thiemichen*

Main category: cs.CL

TL;DR: 本研究提出了一个检测和减轻文本语料库中性别歧视的流程，通过新的指标来衡量情感、句法能动性和引述风格方面的不对称性。虽然能有效改善性别平衡，但情感和框架方面的偏见依然存在。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在数字传播中日益普及，其输出常常反映出源于训练数据的结构性性别不平衡。本研究旨在解决这一问题。

Method: 该研究引入了一个扩展的、面向行动者的流程，并结合了新的面向行动者的指标，用于分析性别歧视，特别是情感、句法能动性和引述风格方面的不对称性。该流程支持诊断性语料库分析和基于排除的平衡。

Result: 该研究将提出的方法应用于1980年至2024年德国报纸文章的taz2024full语料库，并在多个语言维度上显著改善了性别平衡。研究结果表明，虽然表面层面的不对称性可以通过过滤和再平衡得到缓解，但更微妙的偏见，尤其是在情感和框架方面，仍然存在。

Conclusion: 该研究提出了一个用于检测和减轻大规模文本语料库中性别歧视的扩展的、面向行动者的流程。通过引入新的面向行动者的指标，该流程能够诊断语料库的公平性并进行基于排除的平衡，从而构建更公平的语料库。研究表明，虽然可以缓解表面上的不对称性，但尤其是在情感和框架方面，仍然存在更微妙的偏见。

Abstract: Large language models are increasingly shaping digital communication, yet
their outputs often reflect structural gender imbalances that originate from
their training data. This paper presents an extended actor-level pipeline for
detecting and mitigating gender discrimination in large-scale text corpora.
Building on prior work in discourse-aware fairness analysis, we introduce new
actor-level metrics that capture asymmetries in sentiment, syntactic agency,
and quotation styles. The pipeline supports both diagnostic corpus analysis and
exclusion-based balancing, enabling the construction of fairer corpora. We
apply our approach to the taz2024full corpus of German newspaper articles from
1980 to 2024, demonstrating substantial improvements in gender balance across
multiple linguistic dimensions. Our results show that while surface-level
asymmetries can be mitigated through filtering and rebalancing, subtler forms
of bias persist, particularly in sentiment and framing. We release the tools
and reports to support further research in discourse-based fairness auditing
and equitable corpus construction.

</details>


### [85] [MM-BrowseComp: A Comprehensive Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.13186)
*Shilong Li,Xingyuan Bu,Wenjie Wang,Jiaheng Liu,Jun Dong,Haoyang He,Hao Lu,Haozhe Zhang,Chenchen Jing,Zhen Li,Chuanhao Li,Jiayi Tian,Chenchen Zhang,Tianhao Peng,Yancheng He,Jihao Gu,Yuanxing Zhang,Jian Yang,Ge Zhang,Wenhao Huang,Wangchunshu Zhou,Zhaoxiang Zhang,Ruizhe Ding,Shilei Wen*

Main category: cs.CL

TL;DR: MM-BrowseComp是一个新的基准，用于测试AI Agent在包含图像和视频的网页上进行搜索和推理的能力。现有模型表现不佳，准确率仅为29.02%，表明其多模态能力有待提高。


<details>
  <summary>Details</summary>
Motivation: 现有的网页浏览基准（如BrowseComp）主要关注文本信息，忽略了多模态内容（如图文、视频）的重要性。为了解决这一差距，需要一个能够评估AI Agent在包含多模态信息网页上进行检索和推理能力的基准。

Method: 提出MM-BrowseComp，一个包含224个精心设计的问题的新基准，用于评估AI Agent的多模态检索和推理能力。该基准包含图像提示，并允许关键信息嵌入图像或视频中。此外，还提供了一个经过验证的检查清单，用于进行细粒度的多模态依赖和推理路径分析。

Result: 在MM-BrowseComp基准上对包括OpenAI o3 with tools在内的最先进模型进行了评估，结果显示即使是最好的模型准确率也只有29.02%，证明了当前模型在多模态能力和原生多模态推理方面的不足。

Conclusion: 现有AI Agent在处理多模态信息方面能力不足，即使是像OpenAI o3 with tools这样的先进模型，在MM-BrowseComp基准上的准确率也仅为29.02%，这表明当前模型在多模态能力和原生多模态推理方面存在显著的提升空间。

Abstract: AI agents with advanced reasoning and tool use capabilities have demonstrated
impressive performance in web browsing for deep search. While existing
benchmarks such as BrowseComp evaluate these browsing abilities, they primarily
focus on textual information, overlooking the prevalence of multimodal content.
To bridge this gap, we introduce MM-BrowseComp, a novel benchmark comprising
224 challenging, hand-crafted questions specifically designed to assess agents'
multimodal retrieval and reasoning capabilities. These questions often
incorporate images in prompts, and crucial information encountered during the
search and reasoning process may also be embedded within images or videos on
webpages. Consequently, methods relying solely on text prove insufficient for
our benchmark. Additionally, we provide a verified checklist for each question,
enabling fine-grained analysis of multimodal dependencies and reasoning paths.
Our comprehensive evaluation of state-of-the-art models on MM-BrowseComp
reveals that even top models like OpenAI o3 with tools achieve only 29.02\%
accuracy, highlighting the suboptimal multimodal capabilities and lack of
native multimodal reasoning in current models.

</details>


### [86] [Overcoming Latency Bottlenecks in On-Device Speech Translation: A Cascaded Approach with Alignment-Based Streaming MT](https://arxiv.org/abs/2508.13358)
*Zeeshan Ahmed,Frank Seide,Niko Moritz,Ju Lin,Ruiming Xie,Simone Merello,Zhe Liu,Christian Fuegen*

Main category: cs.CL

TL;DR: 提出了一种端到端的流式语音翻译方法，可将 ASR 和 MT 集成在一起，以实现低延迟和高质量的设备上翻译。


<details>
  <summary>Details</summary>
Motivation: 实时、设备上的流式语音翻译的 ASR 和 MT 集成带来了严峻的挑战。

Method: 提出了一种同时翻译方法，该方法有效地平衡了翻译质量和延迟。研究了 ASR 和 MT 的有效集成，利用 ASR 系统生成的语言线索来管理上下文，并利用超时的强制最终确定等有效的束搜索修剪技术来保持系统的实时因子。

Result: 所提出的技术在延迟和质量方面优于基线。

Conclusion: 该方法在延迟和质量方面优于基线，并缩小了与非流式翻译系统的质量差距，为更准确、更高效的实时语音翻译铺平了道路。

Abstract: This paper tackles several challenges that arise when integrating Automatic
Speech Recognition (ASR) and Machine Translation (MT) for real-time, on-device
streaming speech translation. Although state-of-the-art ASR systems based on
Recurrent Neural Network Transducers (RNN-T) can perform real-time
transcription, achieving streaming translation in real-time remains a
significant challenge. To address this issue, we propose a simultaneous
translation approach that effectively balances translation quality and latency.
We also investigate efficient integration of ASR and MT, leveraging linguistic
cues generated by the ASR system to manage context and utilizing efficient
beam-search pruning techniques such as time-out and forced finalization to
maintain system's real-time factor. We apply our approach to an on-device
bilingual conversational speech translation and demonstrate that our techniques
outperform baselines in terms of latency and quality. Notably, our technique
narrows the quality gap with non-streaming translation systems, paving the way
for more accurate and efficient real-time speech translation.

</details>


### [87] [Stands to Reason: Investigating the Effect of Reasoning on Idiomaticity Detection](https://arxiv.org/abs/2508.13365)
*Dylan Phelps,Rodrigo Wilkens,Edward Gow-Smith,Thomas Pickard,Maggie Mi,Aline Villavicencio*

Main category: cs.CL

TL;DR: 推理能力对LLM的idiomaticity检测任务影响有限，大型模型表现更优，小型模型需额外提示。


<details>
  <summary>Details</summary>
Motivation: 旨在探索推理能力如何影响大型语言模型（LLMs）在idiomaticity检测任务上的表现，并考察模型规模的作用，因为idiomaticity检测需要理解和推理。

Method: 通过分析不同参数规模（1.5B至70B）的DeepSeek-R1模型在四个idiomaticity检测数据集上的表现，评估推理能力和模型规模对idiomaticity检测的影响。实验还包括为小型模型提供习语定义作为提示。

Result: 推理能力对idiomaticity检测的影响较小且多样。小型模型通过链式思考（CoT）推理可以提升数学微调模型的性能，但仍低于基础模型。大型模型（14B、32B、70B）表现出适度的性能提升。大型模型能准确理解和定义习语，小型模型则常失败，但通过提供定义作为提示可改善小型模型的性能。

Conclusion: 研究表明，虽然推理能力对idiomaticity检测有一定影响，但其效果不如预期。大型模型在理解和定义习语方面表现更好，而小型模型则需要额外的提示来提高性能。

Abstract: The recent trend towards utilisation of reasoning models has improved the
performance of Large Language Models (LLMs) across many tasks which involve
logical steps. One linguistic task that could benefit from this framing is
idiomaticity detection, as a potentially idiomatic expression must first be
understood before it can be disambiguated and serves as a basis for reasoning.
In this paper, we explore how reasoning capabilities in LLMs affect
idiomaticity detection performance and examine the effect of model size. We
evaluate, as open source representative models, the suite of DeepSeek-R1
distillation models ranging from 1.5B to 70B parameters across four
idiomaticity detection datasets. We find the effect of reasoning to be smaller
and more varied than expected. For smaller models, producing chain-of-thought
(CoT) reasoning increases performance from Math-tuned intermediate models, but
not to the levels of the base models, whereas larger models (14B, 32B, and 70B)
show modest improvements. Our in-depth analyses reveal that larger models
demonstrate good understanding of idiomaticity, successfully producing accurate
definitions of expressions, while smaller models often fail to output the
actual meaning. For this reason, we also experiment with providing definitions
in the prompts of smaller models, which we show can improve performance in some
cases.

</details>


### [88] [Whispering Context: Distilling Syntax and Semantics for Long Speech Transcripts](https://arxiv.org/abs/2508.13376)
*Duygu Altinok*

Main category: cs.CL

TL;DR: 通过将LLaMA的语言知识蒸馏到Whisper中，并结合序列到序列的表示学习，提升了ASR在长音频转录中的准确性，尤其是在NER、大写和标点方面。


<details>
  <summary>Details</summary>
Motivation: 现有的ASR系统在长音频转录的句法和语义准确性方面存在挑战，影响了命名实体识别、大写和标点等下游任务的性能。

Method: 提出了一种新颖的ASR增强方法，该方法结合了两种策略：1. 使用最优传输进行序列到序列的知识蒸馏，以对齐维度和序列长度；2. 通过最小化句子嵌入之间的表示损失来融合句法和语义信息。

Result: 在Spoken Wikipedia数据集上的评估显示，该方法在词错误率（WER）、命名实体识别（NER）、大写和标点符号的准确性方面均取得了显著的改进。

Conclusion: 通过将LLaMA模型的语言知识蒸馏到Whisper中，并结合序列到序列的表示学习，可以显著提高ASR系统在长音频转录中的句法和语义准确性，特别是在命名实体识别、大写和标点符号等任务上。这为构建更鲁棒、更具语境感知能力的ASR系统奠定了基础。

Abstract: ASR systems often struggle with maintaining syntactic and semantic accuracy
in long audio transcripts, impacting tasks like Named Entity Recognition (NER),
capitalization, and punctuation. We propose a novel approach that enhances ASR
by distilling contextual knowledge from LLaMA models into Whisper. Our method
uses two strategies: (1) token level distillation with optimal transport to
align dimensions and sequence lengths, and (2) representation loss minimization
between sentence embeddings of Whisper and LLaMA, blending syntax and
semantics. Evaluations on the Spoken Wikipedia dataset, a benchmark with long
audios and rich entities demonstrate significant improvements in Word Error
Rate (WER), NER, capitalization, and punctuation success. By introducing novel
NER metrics and exploring semantics aware ASR, our work highlights the value of
integrating linguistic context into transcription, setting a foundation for
robust, context-aware ASR in longform speech.

</details>


### [89] [Datarus-R1: An Adaptive Multi-Step Reasoning LLM for Automated Data Analysis](https://arxiv.org/abs/2508.13382)
*Ayoub Ben Chaliah,Hela Dellagi*

Main category: cs.CL

TL;DR: Datarus-R1-14B 是一个在完整分析轨迹上训练的语言模型，用于数据分析和解决复杂问题。它在推理、代码执行和效率方面优于同类模型。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在开发一个能够充当虚拟数据分析师和研究生级别问题解决者的语言模型，能够处理复杂的定量问题，并克服现有模型在推理和代码执行中遇到的挑战。

Method: Datarus-R1-14B 是一个基于 Qwen 2.5-14B-Instruct 微调的 14B 参数开源语言模型。它在包含推理步骤、代码执行、错误追踪、自我修正和最终结论的完整分析轨迹上进行训练，格式为 ReAct 风格的笔记本。训练流程结合了轨迹为中心的合成数据生成器（生成了 144k 个标记的笔记本）、双重奖励框架（结合了基于标签的结构信号和评分单步正确性及整体连贯性的分层奖励模型）以及内存优化的群组相对策略优化（GRPO）实现。其双重推理接口允许模型在代理模式下调用 Python 工具执行代码，在反思模式下输出简洁的思维链（CoT）追踪。课程学习策略从结构保真度平滑过渡到语义深度，以减少 RL 对齐 LLM 中常见的格式崩溃和冗余问题。

Result: Datarus-R1-14B 在需要研究生水平推理能力的标准公共基准测试中表现优于同等规模的模型，并在 AIME 2024/2025 和 LiveCodeBench 上取得了高达 30% 的准确率提升，同时每解决方案产生的 token 数量减少了 18-49%。

Conclusion: Datarus-R1-14B 语言模型在解决研究生级别的问题时表现出色，其“灵光一闪”的模式（勾勒假设、修改一到两次并收敛）优于其他常见模型。

Abstract: We present Datarus-R1-14B, a 14 B-parameter open-weights language model
fine-tuned from Qwen 2.5-14B-Instruct to act as a virtual data analyst and
graduate-level problem solver. Datarus is trained not on isolated
question-answer pairs but on full analytical trajectories including reasoning
steps, code execution, error traces, self-corrections, and final conclusions,
all captured in a ReAct-style notebook format spanning finance, medicine,
numerical analysis, and other quantitative domains. Our training pipeline
combines (i) a trajectory-centric synthetic data generator that yielded 144 000
tagged notebook episodes, (ii) a dual-reward framework blending a lightweight
tag-based structural signal with a Hierarchical Reward Model (HRM) that scores
both single-step soundness and end-to-end coherence, and (iii) a
memory-optimized implementation of Group Relative Policy Optimization (GRPO)
featuring KV-cache reuse, sequential generation, and reference-model sharding.
A cosine curriculum smoothly shifts emphasis from structural fidelity to
semantic depth, reducing the format collapse and verbosity that often plague
RL-aligned LLMs. A central design choice in Datarus is it dual reasoning
interface. In agentic mode the model produces ReAct-tagged steps that invoke
Python tools to execute real code; in reflection mode it outputs compact
Chain-of-Thought (CoT) traces delimited by <think> and <answer> tags. On
demanding postgraduate-level problems, Datarus exhibits an "AHA-moment"
pattern: it sketches hypotheses, revises them once or twice, and converges
avoiding the circular, token-inflating loops common to contemporary systems.
Across standard public benchmarks Datarus surpasses similar size models and
even reaches the level of larger reasoning models such as QwQ-32B achieving up
to 30% higher accuracy on AIME 2024/2025 and LiveCodeBench while emitting
18-49% fewer tokens per solution.

</details>


### [90] [Generics and Default Reasoning in Large Language Models](https://arxiv.org/abs/2508.13718)
*James Ravi Kirkpatrick,Rachel Katharine Sterken*

Main category: cs.CL

TL;DR: 本研究评估了28个大型语言模型在处理涉及普遍概括的默认推理方面的能力。研究发现，虽然一些模型表现良好，但性能因模型和提示风格而异。思维链提示通常会降低性能，而大多数模型难以区分可废止推理和演绎推理，或将普遍概括误解为普遍陈述。这表明了当前大型语言模型在默认推理方面的潜力和局限性。


<details>
  <summary>Details</summary>
Motivation: 普遍概括对于语言学家、哲学家、逻辑学家和认知科学家来说具有特殊的意义，因为它们具有复杂的、允许例外的行为，并且在默认推理、认知和概念习得中起着核心作用。

Method: 评估了28个大型语言模型（LLMs）在20种可废止推理模式（涉及普遍概括，例如“鸟会飞”，“乌鸦是黑色的”）上的推理能力，这些模式是非单调逻辑的核心。

Result: 少数模型提示能够适度提高某些模型的性能，但思维链（CoT）提示通常会导致性能严重下降（在零样本条件下准确率高于75%的模型中，平均准确率下降11.14%，标准差为15.74%，温度为0）。大多数模型要么难以区分可废止推理和演绎推理，要么将普遍概括误解为普遍陈述。

Conclusion: 尽管一些前沿模型在处理默认推理问题方面表现出色，但模型和提示风格的表现差异很大。

Abstract: This paper evaluates the capabilities of 28 large language models (LLMs) to
reason with 20 defeasible reasoning patterns involving generic generalizations
(e.g., 'Birds fly', 'Ravens are black') central to non-monotonic logic.
Generics are of special interest to linguists, philosophers, logicians, and
cognitive scientists because of their complex exception-permitting behaviour
and their centrality to default reasoning, cognition, and concept acquisition.
We find that while several frontier models handle many default reasoning
problems well, performance varies widely across models and prompting styles.
Few-shot prompting modestly improves performance for some models, but
chain-of-thought (CoT) prompting often leads to serious performance degradation
(mean accuracy drop -11.14%, SD 15.74% in models performing above 75% accuracy
in zero-shot condition, temperature 0). Most models either struggle to
distinguish between defeasible and deductive inference or misinterpret generics
as universal statements. These findings underscore both the promise and limits
of current LLMs for default reasoning.

</details>


### [91] [ALIGN: Word Association Learning for Cross-Cultural Generalization in Large Language Models](https://arxiv.org/abs/2508.13426)
*Chunhua Liu,Kabir Manandhar Shrestha,Sukai Huang*

Main category: cs.CL

TL;DR: 通过使用自由联想词进行参数高效微调，可以在不进行大规模重新训练的情况下，显著提升LLM的跨文化理解和对齐能力，即使是较小规模的模型也能达到与更大模型相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在跨文化交流中会反映出其预训练语料库中的分布偏差，但由于文化知识的限制和有效学习方法的缺乏，对文化进行建模和对齐仍然是一个挑战。

Method: 提出了一种利用自由联想词范例作为文化知识的参数高效微调（PEFT）方法，并将其应用于Llama-3.1-8B和Qwen-2.5-7B模型，采用监督微调（SFT）和基于PPO的偏好优化。

Result: SFT在英语和汉语的联想词准确率方面分别提升了16-20%和43-165%，并将中位数具体性提高了+0.20，同时达到了与人类水平相当的效价和唤醒度。微调后的模型在世界价值观调查问题上，回答分布会向目标文化偏移，并且在涉及高紧张度的50个问题子集上，经过汉语对齐的Qwen模型表现翻倍，而Llama的英语偏差降低了三分之一。此外，模型性能接近甚至超过了未微调的70B基线模型。

Conclusion: 通过引入基于认知且参数高效的语言模型微调方法，可以有效地实现跨文化对齐，并显著提升模型在文化相关任务上的表现。

Abstract: As large language models (LLMs) increasingly mediate cross-cultural
communication, their behavior still reflects the distributional bias of the
languages and viewpoints that are over-represented in their pre-training
corpora. Yet, it remains a challenge to model and align culture due to limited
cultural knowledge and a lack of exploration into effective learning
approaches. We introduce a cost-efficient, cognitively grounded remedy:
parameter-efficient fine-tuning on native speakers' free word-association
norms, which encode implicit cultural schemas. Leveraging English-US and
Mandarin associations from the Small-World-of-Words project, we adapt
Llama-3.1-8B and Qwen-2.5-7B via supervised fine-tuning (SFT) and PPO-based
preference optimization. SFT boosts held-out association Precision at 5 by
16-20% in English and 43-165% in Mandarin, lifts median concreteness by +0.20,
and attains human-level valence and arousal. These lexical gains transfer: on
World-Values-Survey questions, fine-tuned models shift answer distributions
toward the target culture, and on a 50-item high-tension subset, Qwen's
Chinese-aligned responses double while Llama's US bias drops by one-third. Our
7-8B models rival or beat vanilla 70B baselines, showing that a few million
culture-grounded associations can instill value alignment without costly
retraining. Our work highlights both the promise and the need for future
research grounded in human cognition in improving cultural alignment in AI
models.

</details>


### [92] [ProMed: Shapley Information Gain Guided Reinforcement Learning for Proactive Medical LLMs](https://arxiv.org/abs/2508.13514)
*Hongxin Ding,Baixiang Huang,Yue Fang,Weibin Liao,Xinke Jiang,Zheng Li,Junfeng Zhao,Yasha Wang*

Main category: cs.CL

TL;DR: ProMed 框架通过 SIG 奖励机制，让医疗大语言模型能主动提问，显著提升诊断准确性，在临床问诊中比被动模式效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有的医疗大语言模型在交互式临床问诊中存在局限性，它们通常是被动响应，缺乏主动获取信息的能力，这可能导致诊断错误。为了解决这个问题，需要让医疗大语言模型具备在决策前提出临床价值问题的能力。

Method: 提出了一种名为 ProMed 的强化学习框架，核心是 Shapley 信息增益（SIG）奖励机制。通过两阶段训练：1）SIG 引导的模型初始化（使用 MCTS 构建高奖励交互轨迹进行监督）；2）SIG 增强策略优化（整合 SIG 并通过新颖的 SIG 引导奖励分配机制提升 RL 效果）。

Result: 在两个新创建的部分信息医学基准测试中，ProMed 显著优于最先进的方法（平均提升 6.29%），并且相比被动模式有 54.45% 的提升，同时在非目标域案例中也表现出良好的泛化能力。

Conclusion: ProMed 框架通过引入基于 Shapley 信息增益（SIG）的奖励机制，将医疗大语言模型从被动问答转变为能主动提问的模式，显著提升了在信息不全情况下的诊断能力。

Abstract: Interactive medical questioning is essential in real-world clinical
consultations, where physicians must actively gather information from patients.
While medical Large Language Models (LLMs) have shown impressive capabilities
in static medical question answering, they predominantly operate under a
reactive paradigm: generating answers directly without seeking additional
information, which risks incorrect diagnoses in such interactive settings. To
address this limitation, we propose ProMed, a reinforcement learning (RL)
framework that transitions medical LLMs toward a proactive paradigm, equipping
them with the ability to ask clinically valuable questions before
decision-making. At the core of ProMed is the Shapley Information Gain (SIG)
reward, which quantifies the clinical utility of each question by combining the
amount of newly acquired information with its contextual importance, estimated
via Shapley values. We integrate SIG into a two-stage training pipeline: (1)
SIG-Guided Model Initialization uses Monte Carlo Tree Search (MCTS) to
construct high-reward interaction trajectories to supervise the model, and (2)
SIG-Augmented Policy Optimization, which integrates SIG and enhances RL with a
novel SIG-guided Reward Distribution Mechanism that assigns higher rewards to
informative questions for targeted optimization. Extensive experiments on two
newly curated partial-information medical benchmarks demonstrate that ProMed
significantly outperforms state-of-the-art methods by an average of 6.29% and
delivers a 54.45% gain over the reactive paradigm, while also generalizing
robustly to out-of-domain cases.

</details>


### [93] [Saudi-Dialect-ALLaM: LoRA Fine-Tuning for Dialectal Arabic Generation](https://arxiv.org/abs/2508.13525)
*Hassan Barmandah*

Main category: cs.CL

TL;DR: LLMs struggle with Saudi dialects. Fine-tuning with a Saudi dialect dataset improved performance significantly, especially using a dialect tag. Released code and data for verification.


<details>
  <summary>Details</summary>
Motivation: Existing Arabic LLMs are limited in their support for Saudi dialects (Najdi and Hijazi), hindering their ability to capture authentic dialectal variations. This research aims to address this underrepresentation by fine-tuning a foundation model for Saudi dialect generation.

Method: The study uses a privately curated Saudi Dialect Instruction dataset (5,466 synthetic instruction-response pairs, 50/50 Hijazi/Najdi split) to LoRA-tune ALLaM-7B-Instruct-preview. Two variants were investigated: Dialect-Token training (prepending a dialect tag) and No-Token training (omitting the tag). Evaluation involved an external dialect classifier, chrF++, BERTScore, and diversity measures.

Result: The Dialect-Token model achieved the best performance, increasing the Saudi dialect rate from 47.97% to 84.21% and reducing MSA leakage from 32.63% to 6.21%. Fidelity also improved, with chrF++ increasing by 3.53 and BERTScore by 0.059. Both LoRA variants outperformed strong generic instruction models in dialect control and fidelity, while avoiding metadata-tag echoing.

Conclusion: LoRA-tuning foundation models with dialect-specific instruction data significantly improves Saudi dialect generation, with the Dialect-Token approach offering superior control and fidelity compared to No-Token and generic instruction models. The study highlights the importance of dialectal data for LLMs and releases code and datasheets for transparency and verification.

Abstract: Large language models (LLMs) for Arabic are still dominated by Modern
Standard Arabic (MSA), with limited support for Saudi dialects such as Najdi
and Hijazi. This underrepresentation hinders their ability to capture authentic
dialectal variation. Using a privately curated Saudi Dialect Instruction
dataset (Hijazi and Najdi; 5,466 synthetic instruction-response pairs; 50/50
split), we LoRA-tune ALLaM-7B-Instruct-preview, the first foundation model
developed in Saudi Arabia, for Saudi dialect generation. We investigate two
variants: (i) Dialect-Token training, which prepends an explicit dialect tag to
the instruction, and (ii) No-Token training, which omits the tag at formatting
time. Evaluation on a held-out test set combines an external dialect classifier
with text fidelity metrics (chrF++ and BERTScore) and diversity measures. The
Dialect-Token model achieves the best control, raising the Saudi rate from
47.97% to 84.21% and reducing MSA leakage from 32.63% to 6.21%; fidelity also
improves (chrF++ +3.53, BERTScore +0.059). Both LoRA variants outperform strong
generic instruction models (Falcon-7B-Instruct, Llama-3.1-8B-Instruct,
Qwen-2.5-7B-Instruct, AceGPT-v2-8B-Chat, JAIS-13B-Chat) in dialect control and
fidelity, while avoiding metadata-tag echoing that these baselines frequently
exhibit. We do not release the dataset or any model weights/adapters; instead,
we release training/evaluation/inference code and a detailed datasheet (schema
and aggregate statistics) to support independent verification.

</details>


### [94] [MATA (māta): Mindful Assessment of the Telugu Abilities of Large Language Models](https://arxiv.org/abs/2508.13526)
*Chalamalasetti Kranti,Sowmya Vajjala*

Main category: cs.CL

TL;DR: 本研究提出了MATA数据集，用于评估大型语言模型在泰卢固语中的表现，发现模型依赖表面启发式方法，并对模型作为评判者的可靠性进行了分析。


<details>
  <summary>Details</summary>
Motivation: 旨在评估大型语言模型在泰卢固语言中的能力，并提供对模型局限性的深入理解，以指导未来更具语言能力的大型语言模型的发展。

Method: 提出了一个名为MATA的新型评估数据集，包含729个精心策划的多项选择和开放式问题，涵盖了不同的语言维度。评估了11个开源和闭源的大型语言模型，并对它们的表现进行了细粒度的分析。此外，还实证分析了大型语言模型在多项选择题中对答案位置和干扰项模式等表面启发式方法的依赖性。最后，比较了大型语言模型作为评判者与人类评估者在开放式问题上的表现，并对其在低资源语言中的可靠性得出了一些结论。

Result: 评估了11个大型语言模型在MATA数据集上的表现，揭示了它们在泰卢固语言上的能力和局限性。实证表明，大型语言模型在多项选择题中会依赖表面启发式方法。研究还对大型语言模型作为评判者在低资源语言中的可靠性进行了评估。

Conclusion: 该研究强调了对模型局限性的细粒度评估对于理解和开发更具语言能力的大型语言模型至关重要，并为泰卢固自然语言处理的未来研究奠定了基础。

Abstract: In this paper, we introduce MATA, a novel evaluation dataset to assess the
ability of Large Language Models (LLMs) in Telugu language, comprising 729
carefully curated multiple-choice and open-ended questions that span diverse
linguistic dimensions. We evaluate 11 open-weight and closed-source LLMs on our
dataset and present a fine-grained analysis of their performance. Further, we
empirically show how LLMs rely on superficial heuristics such as answer
position and distractor patterns for multiple-choice questions. Finally, we
also compare LLM-as-a-judge evaluation with human evaluation for open-ended
questions and draw some conclusions on its reliability in a low-resource
language. We argue that such fine-grained evaluation is essential for
understanding model limitations and can inform the development of more
linguistically capable LLMs, while also serving as a foundation for future
research in Telugu NLP.

</details>


### [95] [Compressed Models are NOT Trust-equivalent to Their Large Counterparts](https://arxiv.org/abs/2508.13533)
*Rohit Raj Rai,Chirag Kothari,Siddhesh Shelke,Amit Awekar*

Main category: cs.CL

TL;DR: 压缩模型不可靠。


<details>
  <summary>Details</summary>
Motivation: 在资源受限的环境中部署大型深度学习模型之前，通常会对模型进行压缩。然而，性能上的对等并不足以保证信任上的等价，即压缩模型的可信度是否与原始大模型相当。

Method: 提出一个二维框架来评估信任等价性：1. 可解释性对齐：衡量模型是否基于相同的输入特征进行预测，使用 LIME 和 SHAP 测试。2. 校准相似性：衡量模型在预测概率方面是否表现出可比的可靠性，通过 ECE、MCE、Brier Score 和可靠性图进行评估。

Result: 实验结果表明，即使在准确率几乎相同的情况下，压缩模型也表现出较低的可解释性对齐和显著的校准相似性不匹配。

Conclusion: 压缩后的模型并不能完全信任，与原始大模型相比，它们在可解释性对齐和校准相似性方面存在显著差异，即使在准确率接近的情况下也是如此。因此，在部署压缩模型作为替代品之前，需要进行仔细的评估，而不仅仅是关注性能表现。

Abstract: Large Deep Learning models are often compressed before being deployed in a
resource-constrained environment. Can we trust the prediction of compressed
models just as we trust the prediction of the original large model? Existing
work has keenly studied the effect of compression on accuracy and related
performance measures. However, performance parity does not guarantee
trust-equivalence. We propose a two-dimensional framework for trust-equivalence
evaluation. First, interpretability alignment measures whether the models base
their predictions on the same input features. We use LIME and SHAP tests to
measure the interpretability alignment. Second, calibration similarity measures
whether the models exhibit comparable reliability in their predicted
probabilities. It is assessed via ECE, MCE, Brier Score, and reliability
diagrams. We conducted experiments using BERT-base as the large model and its
multiple compressed variants. We focused on two text classification tasks:
natural language inference and paraphrase identification. Our results reveal
low interpretability alignment and significant mismatch in calibration
similarity. It happens even when the accuracies are nearly identical between
models. These findings show that compressed models are not trust-equivalent to
their large counterparts. Deploying compressed models as a drop-in replacement
for large models requires careful assessment, going beyond performance parity.

</details>


### [96] [A Comparative Study of Decoding Strategies in Medical Text Generation](https://arxiv.org/abs/2508.13580)
*Oriana Presacan,Alireza Nik,Vajira Thambawita,Bogdan Ionescu,Michael Riegler*

Main category: cs.CL

TL;DR: LLM的解码策略对医疗文本生成的质量有重要影响。beam search等确定性策略优于top-k sampling等随机性策略。在医疗应用中，选择合适的解码策略与选择合适的模型同样重要。


<details>
  <summary>Details</summary>
Motivation: LLM的解码策略会显著影响输出质量，但在医疗领域，这种影响尚未得到充分研究。

Method: 在五个开放式医疗任务（包括翻译、摘要、问答、对话和图像字幕）中，评估了11种解码策略在不同规模的医学和通用LLM上的表现。

Result: 确定性策略（如beam search）通常优于随机性策略（如η和top-k sampling）。较慢的解码方法倾向于产生更高质量的输出。较大的模型整体得分更高，但推理时间更长，并且对解码策略的鲁棒性没有优势。医学LLM在特定任务上优于通用LLM，但总体上没有性能优势，并且对解码策略的选择更敏感。MAUVE等评估指标与BERTScore和ROUGE等指标的相关性因任务而异，并且对解码策略更敏感。

Conclusion: 在医疗领域的LLM应用中，解码策略的选择至关重要，其影响甚至可能超过模型选择本身。应仔细选择适用于医疗场景的解码方法。

Abstract: Large Language Models (LLMs) rely on various decoding strategies to generate
text, and these choices can significantly affect output quality. In healthcare,
where accuracy is critical, the impact of decoding strategies remains
underexplored. We investigate this effect in five open-ended medical tasks,
including translation, summarization, question answering, dialogue, and image
captioning, evaluating 11 decoding strategies with medically specialized and
general-purpose LLMs of different sizes. Our results show that deterministic
strategies generally outperform stochastic ones: beam search achieves the
highest scores, while {\eta} and top-k sampling perform worst. Slower decoding
methods tend to yield better quality. Larger models achieve higher scores
overall but have longer inference times and are no more robust to decoding.
Surprisingly, while medical LLMs outperform general ones in two of the five
tasks, statistical analysis shows no overall performance advantage and reveals
greater sensitivity to decoding choice. We further compare multiple evaluation
metrics and find that correlations vary by task, with MAUVE showing weak
agreement with BERTScore and ROUGE, as well as greater sensitivity to the
decoding strategy. These results highlight the need for careful selection of
decoding methods in medical applications, as their influence can sometimes
exceed that of model choice.

</details>


### [97] [Who Gets the Mic? Investigating Gender Bias in the Speaker Assignment of a Speech-LLM](https://arxiv.org/abs/2508.13603)
*Dariia Puhach,Amir H. Payberah,Éva Székely*

Main category: cs.CL

TL;DR: Bark 模型在性别偏见方面的表现：虽然 Bark 模型没有表现出系统性偏见，但它表现出性别意识和一定的性别倾向。


<details>
  <summary>Details</summary>
Motivation: 与基于文本的大型语言模型（LLMs）类似，Speech-LLMs也表现出涌现能力和上下文感知能力。然而，这些相似性是否延伸到性别偏见仍然是一个悬而未决的问题。

Method: 该研究提出了一种利用说话人分配作为偏见调查的分析工具的方法。评估了Bark（一种文本到语音模型），分析了其对文本提示的默认说话人分配。

Result: Bark 没有表现出系统性偏见，但表现出性别意识和一些性别倾向。

Conclusion: 该模型虽然没有表现出系统性偏见，但表现出性别意识，并具有一定的性别倾向。

Abstract: Similar to text-based Large Language Models (LLMs), Speech-LLMs exhibit
emergent abilities and context awareness. However, whether these similarities
extend to gender bias remains an open question. This study proposes a
methodology leveraging speaker assignment as an analytic tool for bias
investigation. Unlike text-based models, which encode gendered associations
implicitly, Speech-LLMs must produce a gendered voice, making speaker selection
an explicit bias cue. We evaluate Bark, a Text-to-Speech (TTS) model, analyzing
its default speaker assignments for textual prompts. If Bark's speaker
selection systematically aligns with gendered associations, it may reveal
patterns in its training data or model design. To test this, we construct two
datasets: (i) Professions, containing gender-stereotyped occupations, and (ii)
Gender-Colored Words, featuring gendered connotations. While Bark does not
exhibit systematic bias, it demonstrates gender awareness and has some gender
inclinations.

</details>


### [98] [AdaDocVQA: Adaptive Framework for Long Document Visual Question Answering in Low-Resource Settings](https://arxiv.org/abs/2508.13606)
*Haoxuan Li,Wei Song,Aofan Liu,Peiwu Qin*

Main category: cs.CL

TL;DR: AdaDocVQA是一个统一的自适应框架，通过混合文本检索、智能数据增强和自适应集成推理解决了低资源文档VQA的挑战，并在日本基准测试中取得了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 解决文档视觉问答（Document VQA）在低资源环境下处理长文档时面临的上下文限制和训练数据不足的挑战。

Method: 该框架包含三个核心创新：1. 混合文本检索架构用于文档分割；2. 智能数据增强流程，通过多层次验证自动生成高质量推理问答对；3. 具有动态配置生成和提前停止机制的自适应集成推理。

Result: 在JDocQA基准测试中，AdaDocVQA在是/否问题上达到83.04%的准确率，在事实问题上达到52.66%，在数字问题上达到44.12%。在LAVA数据集上准确率为59%。消融研究证实了每个组件的有效性。

Conclusion: AdaDocVQA框架在低资源环境下成功解决了长文档视觉问答的挑战，并在日本文档VQA基准测试中取得了新的最先进结果，为其他低资源语言和专业领域提供了可扩展的基础。

Abstract: Document Visual Question Answering (Document VQA) faces significant
challenges when processing long documents in low-resource environments due to
context limitations and insufficient training data. This paper presents
AdaDocVQA, a unified adaptive framework addressing these challenges through
three core innovations: a hybrid text retrieval architecture for effective
document segmentation, an intelligent data augmentation pipeline that
automatically generates high-quality reasoning question-answer pairs with
multi-level verification, and adaptive ensemble inference with dynamic
configuration generation and early stopping mechanisms. Experiments on Japanese
document VQA benchmarks demonstrate substantial improvements with 83.04\%
accuracy on Yes/No questions, 52.66\% on factual questions, and 44.12\% on
numerical questions in JDocQA, and 59\% accuracy on LAVA dataset. Ablation
studies confirm meaningful contributions from each component, and our framework
establishes new state-of-the-art results for Japanese document VQA while
providing a scalable foundation for other low-resource languages and
specialized domains. Our code available at:
https://github.com/Haoxuanli-Thu/AdaDocVQA.

</details>


### [99] [CRISP: Persistent Concept Unlearning via Sparse Autoencoders](https://arxiv.org/abs/2508.13650)
*Tomer Ashuach,Dana Arad,Aaron Mueller,Martin Tutek,Yonatan Belinkov*

Main category: cs.CL

TL;DR: CRISP是一种新的参数高效方法，使用SAE进行持久的概念学习，可以安全地从LLM中移除有害知识，同时保留模型性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在现实世界中的应用越来越多，选择性地移除不需要的知识并保持模型效用变得至关重要。现有的基于SAE的方法在推理时操作，无法对模型参数进行持久性更改，可能被规避或撤销。

Method: CRISP是一种参数高效的方法，它使用稀疏自动编码器（SAE）在多个层中自动识别重要的SAE特征，并抑制它们的激活。

Result: CRISP在WMDP基准的安全关键学习任务上优于先前的方法，成功地消除了有害知识，同时保留了通用能力和领域内能力。特征级分析表明，CRISP在目标概念和良性概念之间实现了语义上的一致分离，从而能够精确地抑制目标特征。

Conclusion: CRISP是一种参数高效的方法，可实现使用SAE进行持久的概念学习。该方法在WMDP基准的安全关键学习任务上优于先前的方法，成功地消除了有害知识，同时保留了通用能力和领域内能力。

Abstract: As large language models (LLMs) are increasingly deployed in real-world
applications, the need to selectively remove unwanted knowledge while
preserving model utility has become paramount. Recent work has explored sparse
autoencoders (SAEs) to perform precise interventions on monosemantic features.
However, most SAE-based methods operate at inference time, which does not
create persistent changes in the model's parameters. Such interventions can be
bypassed or reversed by malicious actors with parameter access. We introduce
CRISP, a parameter-efficient method for persistent concept unlearning using
SAEs. CRISP automatically identifies salient SAE features across multiple
layers and suppresses their activations. We experiment with two LLMs and show
that our method outperforms prior approaches on safety-critical unlearning
tasks from the WMDP benchmark, successfully removing harmful knowledge while
preserving general and in-domain capabilities. Feature-level analysis reveals
that CRISP achieves semantically coherent separation between target and benign
concepts, allowing precise suppression of the target features.

</details>


### [100] [ViExam: Are Vision Language Models Better than Humans on Vietnamese Multimodal Exam Questions?](https://arxiv.org/abs/2508.13680)
*Vy Tuong Dang,An Vo,Quang Tau,Duc Dm,Daeyoung Kim*

Main category: cs.CL

TL;DR: 该研究通过ViExam基准测试发现，现有的视觉语言模型在处理越南语多模态教育内容时表现不佳，准确率普遍低于人类水平。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型（VLM）在资源匮乏的越南语多模态教育内容上的表现，以及它们处理跨语言多模态推理的能力。

Method: 提出ViExam基准测试，包含2,548个多模态越南语问题，涵盖数学、物理、化学、生物、地理、驾驶考试和智商测试等7个学术领域。评估了最先进VLM和开源VLM在这些测试上的准确率。通过跨语言提示（英语指令，越南语内容）和人机协作实验来分析VLM的性能。

Result: 最先进VLM在越南语多模态考试上的平均准确率为57.74%，开源模型为27.70%。大多数VLM表现不及人类平均水平（66.54%），仅有o3模型（74.07%）超过人类平均水平。跨语言提示（英语指令）未提高性能，反而降低了1%。人机协作可提升约5%的性能。

Conclusion: 现有的视觉语言模型（VLM）在英语多模态任务上表现出色，但在低资源语言的真实多模态教育内容方面仍有待探索。该研究通过ViExam基准测试（包含2,548个多模态问题）对VLM在越南语多模态教育评估方面的表现进行了全面评估。结果显示，最先进的VLM平均准确率为57.74%，开源模型为27.70%，两者均低于人类平均水平（66.54%），仅有o3模型（74.07%）超过人类平均水平，但远低于人类最佳表现（99.60%）。使用英语指令进行跨语言提示未能提升性能，反而使最先进VLM的准确率降低了1%。通过人机协作可以使VLM性能提升约5%。

Abstract: Vision language models (VLMs) demonstrate remarkable capabilities on English
multimodal tasks, but their performance on low-resource languages with
genuinely multimodal educational content remains largely unexplored. In this
work, we test how VLMs perform on Vietnamese educational assessments,
investigating whether VLMs trained predominantly on English data can handle
real-world cross-lingual multimodal reasoning. Our work presents the first
comprehensive evaluation of VLM capabilities on multimodal Vietnamese exams
through proposing ViExam, a benchmark containing 2,548 multimodal questions. We
find that state-of-the-art VLMs achieve only 57.74% while open-source models
achieve 27.70% mean accuracy across 7 academic domains, including Mathematics,
Physics, Chemistry, Biology, Geography, Driving Test, and IQ Test. Most VLMs
underperform average human test-takers (66.54%), with only the thinking VLM o3
(74.07%) exceeding human average performance, yet still falling substantially
short of human best performance (99.60%). Cross-lingual prompting with English
instructions while maintaining Vietnamese content fails to improve performance,
decreasing accuracy by 1 percentage point for SOTA VLMs. Human-in-the-loop
collaboration can partially improve VLM performance by 5 percentage points.
Code and data are available at: https://vi-exam.github.io.

</details>


### [101] [Prediction is not Explanation: Revisiting the Explanatory Capacity of Mapping Embeddings](https://arxiv.org/abs/2508.13729)
*Hanna Herasimchyk,Alhassan Abdelhalim,Sören Laue,Michaela Regneri*

Main category: cs.CL

TL;DR: 现有的词嵌入解释方法可能具有误导性，因为它们预测的准确性并不一定意味着模型真正理解了语义。作者证明，这些方法甚至可以预测随机数据，这意味着结果更多地取决于算法本身，而不是词嵌入的质量。因此，不能仅仅根据预测准确性来比较不同数据集的效果，因为这种方法可能无法真正反映词嵌入的语义能力。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习模型中隐式编码的知识对于提高AI系统的可解释性至关重要。本文旨在检查解释词嵌入（LLM的核心要素）中编码知识的常用方法。

Method: 通过演示即使是随机信息也能被成功预测，来挑战“准确预测语义特征意味着嵌入包含相应知识”的假设。分析了词嵌入解释中的常见方法，即将嵌入映射到称为特征范数的、人类可解释的语义特征集合上。

Result: 现有方法可以成功预测随机信息，表明结果主要由算法上限决定，而非词嵌入中有意义的语义表征。因此，仅基于预测性能的数据集比较并不能可靠地指示哪个数据集被词嵌入更好地捕获。这类映射主要反映了向量空间中的几何相似性。

Conclusion: 现有方法未能可靠地表明词嵌入中包含语义知识，因为预测准确性可能受到算法上限的限制，而与有意义的语义表征无关。基于预测性能的比较并不能可靠地表明哪个数据集更好地被词嵌入所捕获。这种映射主要反映了向量空间中的几何相似性，而不是语义属性的真正出现。

Abstract: Understanding what knowledge is implicitly encoded in deep learning models is
essential for improving the interpretability of AI systems. This paper examines
common methods to explain the knowledge encoded in word embeddings, which are
core elements of large language models (LLMs). These methods typically involve
mapping embeddings onto collections of human-interpretable semantic features,
known as feature norms. Prior work assumes that accurately predicting these
semantic features from the word embeddings implies that the embeddings contain
the corresponding knowledge. We challenge this assumption by demonstrating that
prediction accuracy alone does not reliably indicate genuine feature-based
interpretability.
  We show that these methods can successfully predict even random information,
concluding that the results are predominantly determined by an algorithmic
upper bound rather than meaningful semantic representation in the word
embeddings. Consequently, comparisons between datasets based solely on
prediction performance do not reliably indicate which dataset is better
captured by the word embeddings. Our analysis illustrates that such mappings
primarily reflect geometric similarity within vector spaces rather than
indicating the genuine emergence of semantic properties.

</details>


### [102] [EEG-MedRAG: Enhancing EEG-based Clinical Decision-Making via Hierarchical Hypergraph Retrieval-Augmented Generation](https://arxiv.org/abs/2508.13735)
*Yi Wang,Haoran Luo,Lu Meng*

Main category: cs.CL

TL;DR: EEG-MedRAG 是一个基于三层超图的检索增强生成框架，用于处理和解释脑电图数据，并提出了首个跨疾病、跨角色的 EEG 临床问答基准。该框架在检索和诊断生成方面表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着脑电图（EEG）在神经科学和临床实践中的广泛应用，高效检索和语义化解释大规模、多源、异构的 EEG 数据已成为一个紧迫的挑战。

Method: 提出了一种名为 EEG-MedRAG 的三层超图检索增强生成框架，该框架整合了 EEG 领域知识、个体病例和大型知识库，构建了一个可遍历的 n 元关系超图，实现了联合语义时间检索和因果链诊断生成。同时，引入了首个跨疾病、跨角色的 EEG 临床问答基准，涵盖七种疾病和五个真实临床视角，用于系统评估疾病无关泛化和角色感知上下文理解。

Result: EEG-MedRAG 框架在答案准确性和检索方面显著优于 TimeRAG 和 HyperGraphRAG。

Conclusion: EEG-MedRAG 框架在答案准确性和检索方面显著优于 TimeRAG 和 HyperGraphRAG，显示出其在真实临床决策支持方面的强大潜力。

Abstract: With the widespread application of electroencephalography (EEG) in
neuroscience and clinical practice, efficiently retrieving and semantically
interpreting large-scale, multi-source, heterogeneous EEG data has become a
pressing challenge. We propose EEG-MedRAG, a three-layer hypergraph-based
retrieval-augmented generation framework that unifies EEG domain knowledge,
individual patient cases, and a large-scale repository into a traversable n-ary
relational hypergraph, enabling joint semantic-temporal retrieval and
causal-chain diagnostic generation. Concurrently, we introduce the first
cross-disease, cross-role EEG clinical QA benchmark, spanning seven disorders
and five authentic clinical perspectives. This benchmark allows systematic
evaluation of disease-agnostic generalization and role-aware contextual
understanding. Experiments show that EEG-MedRAG significantly outperforms
TimeRAG and HyperGraphRAG in answer accuracy and retrieval, highlighting its
strong potential for real-world clinical decision support. Our data and code
are publicly available at https://github.com/yi9206413-boop/EEG-MedRAG.

</details>


### [103] [Sycophancy under Pressure: Evaluating and Mitigating Sycophantic Bias via Adversarial Dialogues in Scientific QA](https://arxiv.org/abs/2508.13743)
*Kaiwei Zhang,Qi Jia,Zijian Chen,Wei Sun,Xiangyang Zhu,Chunyi Li,Dandan Zhu,Guangtao Zhai*

Main category: cs.CL

TL;DR: 大型语言模型在科学问答中存在迎合用户错误信念的“谄媚”问题。本研究提出了一种评估框架和一种名为“Pressure-Tune”的训练后方法，通过对抗性对话和链式思考（chain-of-thought）推理来训练模型，使其能抵抗用户施加的错误信息和压力，提高回答的真实性，且不损害模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在需要事实严谨性的领域日益受到关注，但它们常常表现出一种令人担忧的行为：谄媚（sycophancy），即不顾事实正确性而倾向于迎合用户信念的倾向。这种倾向在以用户满意度为目标的对齐技术中得到加强，但可能会损害真实性。虽然在日常对话中这种现象相对无害，但在科学问答（QA）等高风险场景中，谄媚行为会带来严重风险，因为模型输出可能会影响协作推理、决策和知识形成。尽管其重要性，但这种现象在事实问答环境中仍未得到充分研究。

Method: 提出了一种统一的评估框架，包括对抗性提示设置和误导抵抗、谄媚抵抗等目标指标，用于量化用户施加的社会压力对模型输出的影响。并提出了一种名为Pressure-Tune的轻量级训练后方法，通过在包含拒绝用户错误信息和强化事实承诺的链式思考（chain-of-thought）推理的合成对抗性对话上进行微调来解决此问题。

Result: 通过在开放源代码和专有模型上的系统评估，发现模型普遍存在谄媚倾向，且这种倾向更多地源于对齐策略而非模型规模。实验表明，Pressure-Tune在具有挑战性的科学问答基准测试中，显著提高了模型的谄媚抵抗能力，同时保持了准确性和对有效反馈的响应能力。

Conclusion: Pressure-Tune是一种轻量级的训练后方法，通过在合成的对抗性对话和链式思考（chain-of-thought）推理上进行微调，可以显著提高模型的谄媚抵抗能力，同时不损害准确性或对有效反馈的响应能力，为实现更真实、更符合原则的模型行为提供了实际途径。

Abstract: Large language models (LLMs), while increasingly used in domains requiring
factual rigor, often display a troubling behavior: sycophancy, the tendency to
align with user beliefs regardless of correctness. This tendency is reinforced
by preference-based alignment techniques that optimize for user satisfaction
but can undermine truthfulness. While relatively benign in casual dialogue,
sycophancy poses serious risks in high-stakes settings such as scientific
question answering (QA), where model outputs may shape collaborative reasoning,
decision-making, and knowledge formation. Despite its importance, this
phenomenon remains underexamined in factual QA contexts. We address this gap by
introducing a unified evaluation framework to quantify the impact of
sycophantic context on model behavior in scientific QA, measuring how much
user-imposed social pressure distorts model outputs. The framework incorporates
adversarial prompting setups and targeted metrics, such as misleading
resistance and sycophancy resistance, that capture a model's ability to
maintain factual consistency under misleading cues. Systematic evaluations
across open-source and proprietary models reveal pervasive sycophantic
tendencies, driven more by alignment strategy than by model size. To mitigate
this issue, we propose Pressure-Tune, a lightweight post-training method that
fine-tunes models on synthetic adversarial dialogues paired with
chain-of-thought rationales. These rationales reject user misinformation while
reinforcing factual commitments. Experiments on challenging scientific QA
benchmarks show that Pressure-Tune significantly enhances sycophancy resistance
without compromising accuracy or responsiveness to valid feedback, offering a
practical pathway toward more truthful and principled model behavior.

</details>


### [104] [MGT-Prism: Enhancing Domain Generalization for Machine-Generated Text Detection via Spectral Alignment](https://arxiv.org/abs/2508.13768)
*Shengchao Liu,Xiaoming Liu,Chengzhengxu Li,Zhaohan Zhang,Guoxin Ma,Yu Lan,Shuai Xiao*

Main category: cs.CL

TL;DR: MGT-Prism是一种基于频域分析的方法，通过低频滤波和动态频谱对齐来克服领域偏移问题，在机器生成文本检测任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的机器生成文本（MGT）检测器在不同领域之间泛化能力差，因为数据源之间存在领域偏移。

Method: 提出了一种从频域进行大语言模型生成文本检测（MGT detection）的新方法MGT-Prism，通过低频域滤波和动态频谱对齐策略来提取任务特定且领域不变的特征，以提升模型在领域泛化方面的性能。

Result: MGT-Prism在11个跨三个领域泛化场景的测试数据集上，相比现有技术，在准确率和F1分数上平均分别提升了0.90%和0.92%。

Conclusion: MGT-Prism在三个领域泛化场景下的11个测试数据集上，平均准确率和F1分数分别比最先进的基线提高了0.90%和0.92%，证明了其在领域泛化方面的优越性能。

Abstract: Large Language Models have shown growing ability to generate fluent and
coherent texts that are highly similar to the writing style of humans. Current
detectors for Machine-Generated Text (MGT) perform well when they are trained
and tested in the same domain but generalize poorly to unseen domains, due to
domain shift between data from different sources. In this work, we propose
MGT-Prism, an MGT detection method from the perspective of the frequency domain
for better domain generalization. Our key insight stems from analyzing text
representations in the frequency domain, where we observe consistent spectral
patterns across diverse domains, while significant discrepancies in magnitude
emerge between MGT and human-written texts (HWTs). The observation initiates
the design of a low frequency domain filtering module for filtering out the
document-level features that are sensitive to domain shift, and a dynamic
spectrum alignment strategy to extract the task-specific and domain-invariant
features for improving the detector's performance in domain generalization.
Extensive experiments demonstrate that MGT-Prism outperforms state-of-the-art
baselines by an average of 0.90% in accuracy and 0.92% in F1 score on 11 test
datasets across three domain-generalization scenarios.

</details>


### [105] [Can Large Language Models (LLMs) Describe Pictures Like Children? A Comparative Corpus Study](https://arxiv.org/abs/2508.13769)
*Hanna Woloszyn,Benjamin Gagl*

Main category: cs.CL

TL;DR: LLM在模仿儿童语言方面存在不足，尤其是在词汇丰富度和语义表达上。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在教育领域作用的增加，LLM生成的文本是否类似儿童语言的研究却很少受到关注。本研究旨在评估LLM复制儿童语言的能力。

Method: 本研究通过对比LLM生成的文本和德国儿童对图画故事的描述，分析了心理语言学文本属性，包括词频、词汇丰富度、句长、词长、词性标签和词嵌入的语义相似性。研究生成了两种LLM语料库，分别使用零样本和少样本提示，并指定了儿童语料库中的一般年龄。

Result: LLM生成的文本普遍较长，但词汇丰富度较低，更倾向于使用高频词，并且名词的使用代表性不足。语义向量空间分析显示，儿童和LLM文本之间的语义相似度较低，在语料库语义层面存在差异。少样本提示在 minor extent 上增加了儿童和LLM文本的相似度，但未能复制词汇和语义模式。

Conclusion: LLM生成的文本在词汇丰富度、常用词使用和名词代表性方面与儿童语言存在显著差异。少样本提示在一定程度上提高了相似度，但未能完全复制词汇和语义模式。研究结果对LLM在儿童教育工具中的应用提出了重要问题。

Abstract: The role of large language models (LLMs) in education is increasing, yet
little attention has been paid to whether LLM-generated text resembles child
language. This study evaluates how LLMs replicate child-like language by
comparing LLM-generated texts to a collection of German children's descriptions
of picture stories. We generated two LLM-based corpora using the same picture
stories and two prompt types: zero-shot and few-shot prompts specifying a
general age from the children corpus. We conducted a comparative analysis
across psycholinguistic text properties, including word frequency, lexical
richness, sentence and word length, part-of-speech tags, and semantic
similarity with word embeddings. The results show that LLM-generated texts are
longer but less lexically rich, rely more on high-frequency words, and
under-represent nouns. Semantic vector space analysis revealed low similarity,
highlighting differences between the two corpora on the level of corpus
semantics. Few-shot prompt increased similarities between children and LLM text
to a minor extent, but still failed to replicate lexical and semantic patterns.
The findings contribute to our understanding of how LLMs approximate child
language through multimodal prompting (text + image) and give insights into
their use in psycholinguistic research and education while raising important
questions about the appropriateness of LLM-generated language in child-directed
educational tools.

</details>


### [106] [TracSum: A New Benchmark for Aspect-Based Summarization with Sentence-Level Traceability in Medical Domain](https://arxiv.org/abs/2508.13798)
*Bohao Chu,Meijie Li,Sameh Frihat,Chengyu Gu,Georg Lodde,Elisabeth Livingstone,Norbert Fuhr*

Main category: cs.CL

TL;DR: TracSum是一个用于医学摘要事实准确性验证的新基准，通过句子级引用实现原文追溯。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在医学领域生成摘要时对事实准确性的担忧，该研究旨在通过追溯证据来使摘要的准确性可评估。

Method: 提出了一种名为TracSum的新型基准，用于可追溯、面向方面的摘要，其中生成的摘要与句子级引用配对，使用户能够追溯到原始上下文。首先，对500份医学摘要进行了注释，包含七个关键的医学方面，生成了3.5K个摘要-引用对。然后，提出了一种用于此新任务的细粒度评估框架，使用四种指标评估生成内容的完整性和一致性。最后，引入了一个名为Track-Then-Sum的摘要流水线，作为比较的基线方法。

Result: 实验评估了Track-Then-Sum基线和一系列大型语言模型在TracSum上的表现，并通过人类评估验证了评估结果。结果表明，显式地在摘要前进行句子级追踪可以提高生成准确性，而融入全部上下文则能进一步提高完整性。

Conclusion: TracSum可作为可追溯、面向方面的摘要任务的有效基准。

Abstract: While document summarization with LLMs has enhanced access to textual
information, concerns about the factual accuracy of these summaries persist,
especially in the medical domain. Tracing evidence from which summaries are
derived enables users to assess their accuracy, thereby alleviating this
concern. In this paper, we introduce TracSum, a novel benchmark for traceable,
aspect-based summarization, in which generated summaries are paired with
sentence-level citations, enabling users to trace back to the original context.
First, we annotate 500 medical abstracts for seven key medical aspects,
yielding 3.5K summary-citation pairs. We then propose a fine-grained evaluation
framework for this new task, designed to assess the completeness and
consistency of generated content using four metrics. Finally, we introduce a
summarization pipeline, Track-Then-Sum, which serves as a baseline method for
comparison. In experiments, we evaluate both this baseline and a set of LLMs on
TracSum, and conduct a human evaluation to assess the evaluation results. The
findings demonstrate that TracSum can serve as an effective benchmark for
traceable, aspect-based summarization tasks. We also observe that explicitly
performing sentence-level tracking prior to summarization enhances generation
accuracy, while incorporating the full context further improves completeness.

</details>


### [107] [Towards No-Code Programming of Cobots: Experiments with Code Synthesis by Large Code Models for Conversational Programming](https://arxiv.org/abs/2409.11041)
*Chalamalasetti Kranti,Sherzod Hakimov,David Schlangen*

Main category: cs.CL

TL;DR: 通过自然语言向协作机器人发出指令来生成代码，LLM可以生成基础指令，但无法处理更复杂的编程概念。


<details>
  <summary>Details</summary>
Motivation: 解决目前协作机器人在编程复杂性和表达能力方面的局限性，探索使用LLM进行代码生成。

Method: 利用大型语言模型（LLM）进行对话式代码生成，通过自然语言指令来指导机器人执行装配任务。

Result: 在模拟环境中，LLM能够生成准确的一阶代码（指令序列），但难以生成高阶代码（抽象概念，如函数或循环）。

Conclusion: LLM在生成一阶指令序列方面表现良好，但在生成抽象（如函数或循环）等高阶代码方面存在困难。

Abstract: While there has been a lot of research recently on robots in household
environments, at the present time, most robots in existence can be found on
shop floors, and most interactions between humans and robots happen there.
``Collaborative robots'' (cobots) designed to work alongside humans on assembly
lines traditionally require expert programming, limiting ability to make
changes, or manual guidance, limiting expressivity of the resulting programs.
To address these limitations, we explore using Large Language Models (LLMs),
and in particular, their abilities of doing in-context learning, for
conversational code generation. As a first step, we define RATS, the
``Repetitive Assembly Task'', a 2D building task designed to lay the foundation
for simulating industry assembly scenarios. In this task, a `programmer'
instructs a cobot, using natural language, on how a certain assembly is to be
built; that is, the programmer induces a program, through natural language. We
create a dataset that pairs target structures with various example instructions
(human-authored, template-based, and model-generated) and example code. With
this, we systematically evaluate the capabilities of state-of-the-art LLMs for
synthesising this kind of code, given in-context examples. Evaluating in a
simulated environment, we find that LLMs are capable of generating accurate
`first order code' (instruction sequences), but have problems producing
`higher-order code' (abstractions such as functions, or use of loops).

</details>


### [108] [Beyond Human Judgment: A Bayesian Evaluation of LLMs' Moral Values Understanding](https://arxiv.org/abs/2508.13804)
*Maciej Skorski,Alina Landowska*

Main category: cs.CL

TL;DR: Large language models show strong moral understanding, outperforming average humans and exhibiting heightened sensitivity to moral detection by producing fewer false negatives.


<details>
  <summary>Details</summary>
Motivation: To understand how large language models comprehend moral dimensions compared to humans, using a novel Bayesian approach that models annotator disagreements to capture uncertainties, in contrast to prior work using deterministic ground truth.

Method: A large-scale Bayesian evaluation using a GPU-optimized Bayesian framework processed 1M+ model queries. It modeled annotator disagreements to capture both aleatoric and epistemic uncertainty, evaluating top language models (Claude Sonnet 4, DeepSeek-V3, Llama 4 Maverick) across 250K+ annotations from ~700 annotators on 100K+ texts spanning social media, news, and forums.

Result: AI models generally outperform average human annotators, ranking in the top 25% and achieving better-than-average balanced accuracy. They also exhibit significantly fewer false negatives than humans, suggesting superior moral detection sensitivity.

Conclusion: AI models typically rank among the top 25% of human annotators, achieving much better-than-average balanced accuracy. AI produces far fewer false negatives than humans, indicating more sensitive moral detection capabilities.

Abstract: How do large language models understand moral dimensions compared to humans?
  This first large-scale Bayesian evaluation of market-leading language models
provides the answer. In contrast to prior work using deterministic ground truth
(majority or inclusion rules), we model annotator disagreements to capture both
aleatoric uncertainty (inherent human disagreement) and epistemic uncertainty
(model domain sensitivity). We evaluate top language models (Claude Sonnet 4,
DeepSeek-V3, Llama 4 Maverick) across 250K+ annotations from ~700 annotators on
100K+ texts spanning social media, news, and forums.
  Our GPU-optimized Bayesian framework processed 1M+ model queries, revealing
that AI models typically rank among the top 25\% of human annotators, achieving
much better-than-average balanced accuracy. Importantly, we find that AI
produces far fewer false negatives than humans, highlighting their more
sensitive moral detection capabilities.

</details>


### [109] [Prompt-Based One-Shot Exact Length-Controlled Generation with LLMs](https://arxiv.org/abs/2508.13805)
*Juncheng Xie,Hung-yi Lee*

Main category: cs.CL

TL;DR: 通过在提示中添加倒计时标记和计数规则，可以仅通过提示工程来精确控制LLM的输出长度，而无需进行微调或迭代采样。


<details>
  <summary>Details</summary>
Motivation: 控制LLM生成的文本长度仍然具有挑战性：由于模型无法可靠地保持内部token计数，因此它们经常会超过或达不到明确的长度指令。

Method: 提出了一种基于提示的、一次性的策略，迫使现成的LLM生成精确的所需数量的token——单词（英文）或字符（中文），而无需任何微调或迭代采样。该提示附加了倒计时标记和显式计数规则，使模型能够“在计数的同时写作”。

Result: 在MT-Bench-LI上，使用倒计时提示时，GPT-4.1的严格长度合规性从普通提示下的30%以下跃升至95%以上，超过了流行的“起草然后修改”基线，同时保持了判断的答案质量。

Conclusion: 精确的长度控制可以通过单独的提示工程来实现，为基于训练或解码的方法提供了一种轻量级的替代方案。

Abstract: Controlling the length of text produced by large language models (LLMs)
remains challenging: models frequently overshoot or undershoot explicit length
instructions because they cannot reliably keep an internal token count. We
present a prompt-based, one-shot strategy that compels an off-the-shelf LLM to
generate exactly a desired number of tokens - words (English) or characters
(Chinese) - without any fine-tuning or iterative sampling. The prompt appends
countdown markers and explicit counting rules so that the model "writes while
counting." We evaluate on four settings: open-ended generation (1-1000 tokens),
XSUM summarization, MT-Bench-LI instruction following, and the LIFEBENCH
equal-length track. On MT-Bench-LI, strict length compliance with GPT-4.1 leaps
from below 30% under naive prompts to above 95% with our countdown prompt,
surpassing the popular draft-then-revise baseline, while judged answer quality
is preserved. These results show that precise length control can be achieved
through prompt engineering alone, offering a lightweight alternative to
training- or decoding-based methods.

</details>


### [110] [The illusion of a perfect metric: Why evaluating AI's words is harder than it looks](https://arxiv.org/abs/2508.13816)
*Maria Paz Oliva,Adriana Correia,Ivan Vankov,Viktor Botev*

Main category: cs.CL

TL;DR: 评估NLG的指标各有优缺点，没有完美的指标。选择和组合使用指标，并改进验证方法是关键。


<details>
  <summary>Details</summary>
Motivation: 评估自然语言生成（NLG）的挑战以及现有自动评估指标（AEM）的局限性，旨在说明没有单一指标能够完美解决问题，并挑战寻找“完美指标”的观念。

Method: 通过详细审查现有评估指标（包括词汇比较、语义相似性模型和基于大语言模型的评估器）的方法论、优点、局限性、验证方法和与人类判断的相关性，特别是针对检索增强生成（RAG）任务。

Result: 识别出评估指标面临的几个关键挑战：指标通常只关注文本质量的特定方面；指标的有效性因任务和数据集而异；验证实践缺乏结构；与人类判断的相关性不一致。这些挑战在最新的“LLM-as-a-Judge”评估和RAG任务中依然存在。

Conclusion: 现有评估指标未能提供完美解决方案，研究者应根据任务需求选择和组合评估指标，并重视验证方法。未来的评估指标应着重于改进验证方法。

Abstract: Evaluating Natural Language Generation (NLG) is crucial for the practical
adoption of AI, but has been a longstanding research challenge. While human
evaluation is considered the de-facto standard, it is expensive and lacks
scalability. Practical applications have driven the development of various
automatic evaluation metrics (AEM), designed to compare the model output with
human-written references, generating a score which approximates human judgment.
Over time, AEMs have evolved from simple lexical comparisons, to semantic
similarity models and, more recently, to LLM-based evaluators. However, it
seems that no single metric has emerged as a definitive solution, resulting in
studies using different ones without fully considering the implications. This
paper aims to show this by conducting a thorough examination of the
methodologies of existing metrics, their documented strengths and limitations,
validation methods, and correlations with human judgment. We identify several
key challenges: metrics often capture only specific aspects of text quality,
their effectiveness varies by task and dataset, validation practices remain
unstructured, and correlations with human judgment are inconsistent.
Importantly, we find that these challenges persist in the most recent type of
metric, LLM-as-a-Judge, as well as in the evaluation of Retrieval Augmented
Generation (RAG), an increasingly relevant task in academia and industry. Our
findings challenge the quest for the 'perfect metric'. We propose selecting
metrics based on task-specific needs and leveraging complementary evaluations
and advocate that new metrics should focus on enhanced validation
methodologies.

</details>


### [111] [Extracting Structured Requirements from Unstructured Building Technical Specifications for Building Information Modeling](https://arxiv.org/abs/2508.13833)
*Insaf Nahri,Romain Pinquié,Philippe Véron,Nicolas Bus,Mathieu Thorel*

Main category: cs.CL

TL;DR: 本研究将 BIM 与 NLP 技术相结合，使用 CamemBERT 和 Fr_core_news_lg 模型自动提取法语建筑技术规范中的需求，并通过 NER 和 RE 技术进行评估。结果显示，CamemBERT 和 Fr_core_news_lg 在 NER 方面表现优异，而随机森林在 RE 方面效果最佳。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索将建筑信息模型（BIM）与自然语言处理（NLP）相结合，以自动从建筑行业非结构化的法语建筑技术规范（BTS）文档中提取需求。

Method: 本研究采用命名实体识别（NER）和关系提取（RE）技术，利用基于 Transformer 的模型 CamemBERT，并结合在通用领域的大型法语语料库预训练的法语语言模型 Fr_core_news_lg 进行迁移学习。此外，还开发了从基于规则到基于深度学习的多种方法作为基准。对于关系提取（RE），使用了四种不同的监督模型，包括随机森林，并采用自定义特征向量。

Result: CamemBERT 和 Fr_core_news_lg 在 NER 方面达到了 90% 以上的 F1 分数，随机森林在 RE 方面达到了 80% 以上的 F1 分数。

Conclusion: CamemBERT and Fr_core_news_lg 在命名实体识别（NER）方面表现出优越的性能，F1 分数超过 90%；而随机森林在关系提取（RE）方面最有效，F1 分数超过 80%。

Abstract: This study explores the integration of Building Information Modeling (BIM)
with Natural Language Processing (NLP) to automate the extraction of
requirements from unstructured French Building Technical Specification (BTS)
documents within the construction industry. Employing Named Entity Recognition
(NER) and Relation Extraction (RE) techniques, the study leverages the
transformer-based model CamemBERT and applies transfer learning with the French
language model Fr\_core\_news\_lg, both pre-trained on a large French corpus in
the general domain. To benchmark these models, additional approaches ranging
from rule-based to deep learning-based methods are developed. For RE, four
different supervised models, including Random Forest, are implemented using a
custom feature vector. A hand-crafted annotated dataset is used to compare the
effectiveness of NER approaches and RE models. Results indicate that CamemBERT
and Fr\_core\_news\_lg exhibited superior performance in NER, achieving
F1-scores over 90\%, while Random Forest proved most effective in RE, with an
F1 score above 80\%. The outcomes are intended to be represented as a knowledge
graph in future work to further enhance automatic verification systems.

</details>


### [112] [MME-SCI: A Comprehensive and Challenging Science Benchmark for Multimodal Large Language Models](https://arxiv.org/abs/2508.13938)
*Jiacheng Ruan,Dan Jiang,Xian Gao,Ting Liu,Yuzhuo Fu,Yangyang Kang*

Main category: cs.CL

TL;DR: MME-SCI是一个新的科学领域多模态大语言模型评测基准，包含多语言、多学科和细粒度知识点，旨在解决现有基准的不足。该基准对现有模型具有挑战性，并有助于分析模型弱点。


<details>
  <summary>Details</summary>
Motivation: 现有针对多模态大语言模型（MLLMs）的科学领域评测基准在多语言场景下的推理能力评估不足、多模态覆盖度评估不全以及科学知识点标注不够精细。

Method: MME-SCI基准通过收集1,019个高质量的多模态问答对，覆盖数学、物理、化学、生物四个学科和中、英、法、西、日五种语言，并设计了3种不同的评测模式。在MME-SCI上对16个开源模型和4个闭源模型进行了广泛实验。

Result: MME-SCI对现有MLLMs具有广泛的挑战性。例如，在仅图像评估模式下，o4-mini在数学、物理、化学和生物科目的准确率分别为52.11%、24.73%、36.57%和29.80%，显著高于现有基准的难度。通过MME-SCI的多语言和细粒度知识属性，可以深入分析模型表现并识别其特定领域的弱点。

Conclusion: MME-SCI是一个全面的、具有挑战性的多模态大语言模型科学领域评测基准，能有效评估模型在多语言场景下的推理能力、多模态覆盖度以及科学知识点的细粒度掌握情况。实验结果表明，现有模型在该基准上面临巨大挑战，特别是在单图像评估模式下，准确率普遍不高，凸显了MME-SCI的难度。该基准还有助于深入分析现有模型在特定领域的表现和弱点。

Abstract: Recently, multimodal large language models (MLLMs) have achieved significant
advancements across various domains, and corresponding evaluation benchmarks
have been continuously refined and improved. In this process, benchmarks in the
scientific domain have played an important role in assessing the reasoning
capabilities of MLLMs. However, existing benchmarks still face three key
challenges: 1) Insufficient evaluation of models' reasoning abilities in
multilingual scenarios; 2) Inadequate assessment of MLLMs' comprehensive
modality coverage; 3) Lack of fine-grained annotation of scientific knowledge
points. To address these gaps, we propose MME-SCI, a comprehensive and
challenging benchmark. We carefully collected 1,019 high-quality
question-answer pairs, which involve 3 distinct evaluation modes. These pairs
cover four subjects, namely mathematics, physics, chemistry, and biology, and
support five languages: Chinese, English, French, Spanish, and Japanese. We
conducted extensive experiments on 16 open-source models and 4 closed-source
models, and the results demonstrate that MME-SCI is widely challenging for
existing MLLMs. For instance, under the Image-only evaluation mode, o4-mini
achieved accuracy of only 52.11%, 24.73%, 36.57%, and 29.80% in mathematics,
physics, chemistry, and biology, respectively, indicating a significantly
higher difficulty level compared to existing benchmarks. More importantly,
using MME-SCI's multilingual and fine-grained knowledge attributes, we analyzed
existing models' performance in depth and identified their weaknesses in
specific domains. The Data and Evaluation Code are available at
https://github.com/JCruan519/MME-SCI.

</details>


### [113] [ReviewGraph: A Knowledge Graph Embedding Based Framework for Review Rating Prediction with Sentiment Features](https://arxiv.org/abs/2508.13953)
*A. J. W. de Vink,Natalia Amat-Lefort,Lifeng Han*

Main category: cs.CL

TL;DR: ReviewGraph利用知识图谱预测酒店评论评分，性能与LLM相当但成本更低，且更具可解释性。


<details>
  <summary>Details</summary>
Motivation: 在酒店业中，理解影响客户评论评分的因素对于提高宾客满意度和业务表现至关重要。

Method: 本研究提出了一种名为ReviewGraph的新框架，该框架通过提取（主语、谓语、宾语）三元组并将情感分数与它们相关联，将文本客户评论转化为知识图谱。然后，利用图嵌入（Node2Vec）和情感特征，通过机器学习分类器来预测评论评分。

Result: ReviewGraph框架在HotelRec数据集上的表现与现有的最佳模型相当，但计算成本更低，并且在Cohen

Conclusion: 本研究提出了ReviewGraph框架，通过将客户评论转化为知识图谱，并结合词嵌入和情感特征，可以预测评论评分。与传统的自然语言处理方法和大型语言模型相比，ReviewGraph在预测性能上相当，但在计算成本上更低，并且具有更好的可解释性、可视化探索能力，并能集成到检索增强生成（RAG）系统中。

Abstract: In the hospitality industry, understanding the factors that drive customer
review ratings is critical for improving guest satisfaction and business
performance. This work proposes ReviewGraph for Review Rating Prediction (RRP),
a novel framework that transforms textual customer reviews into knowledge
graphs by extracting (subject, predicate, object) triples and associating
sentiment scores. Using graph embeddings (Node2Vec) and sentiment features, the
framework predicts review rating scores through machine learning classifiers.
We compare ReviewGraph performance with traditional NLP baselines (such as Bag
of Words, TF-IDF, and Word2Vec) and large language models (LLMs), evaluating
them in the HotelRec dataset. In comparison to the state of the art literature,
our proposed model performs similar to their best performing model but with
lower computational cost (without ensemble).
  While ReviewGraph achieves comparable predictive performance to LLMs and
outperforms baselines on agreement-based metrics such as Cohen's Kappa, it
offers additional advantages in interpretability, visual exploration, and
potential integration into Retrieval-Augmented Generation (RAG) systems. This
work highlights the potential of graph-based representations for enhancing
review analytics and lays the groundwork for future research integrating
advanced graph neural networks and fine-tuned LLM-based extraction methods. We
will share ReviewGraph output and platform open-sourced on our GitHub page
https://github.com/aaronlifenghan/ReviewGraph

</details>


### [114] [Chunks as Arms: Multi-Armed Bandit-Guided Sampling for Long-Context LLM Preference Optimization](https://arxiv.org/abs/2508.13993)
*Shaohua Duan,Xinze Li,Zhenghao Liu,Xiaoyuan Yi,Yukun Yan,Shuo Wang,Yu Gu,Ge Yu,Maosong Sun*

Main category: cs.CL

TL;DR: LongMab-PO框架利用MAB策略优化长上下文LLM的偏好数据，提升了数据质量和多样性，并在长上下文推理任务上取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决当前通过微调LLM以增强其长上下文能力的研究中，由于生成数据多样性低和事实不一致等问题，提出了LongMab-PO框架。

Method: 提出了一种名为LongMab-PO的新框架，该框架利用多臂老虎机（MAB）滚动策略来识别给定长上下文中最具信息量的文本块，用于采样高质量和多样化的响应，并构建用于直接偏好优化（DPO）训练的偏好数据对。具体地，将上下文文本块视为MAB的臂，并根据预期的奖励分数选择文本块以输入到LLM以生成响应，并基于奖励反馈迭代地更新这些分数。最后，收集来自滚动过程的响应，并应用DPO方法进一步优化LLM。

Result: LongMab-PO显著提高了偏好数据对的多样性和质量，并在长上下文推理基准测试中取得了最先进的性能。

Conclusion: LongMab-PO框架通过利用多臂老虎机（MAB）探索-利用策略，从给定长上下文中识别信息量最大的文本块，从而生成高质量、多样化的响应，并构建用于直接偏好优化（DPO）训练的偏好数据对。实验结果表明，LongMab-PO显著提高了偏好数据对的多样性和质量，并在长上下文推理基准测试中取得了最先进的性能。

Abstract: Long-context modeling is critical for a wide range of real-world tasks,
including long-context question answering, summarization, and complex reasoning
tasks. Recent studies have explored fine-tuning Large Language Models (LLMs)
with synthetic data to enhance their long-context capabilities. However, the
effectiveness of such approaches is often limited by the low diversity and
factual inconsistencies in the generated data. To address these challenges, we
propose LongMab-PO, a novel framework that leverages a Multi-Armed Bandit (MAB)
rollout strategy to identify the most informative chunks from the given long
context for sampling high-quality and diverse responses and constructing
preference data pairs for Direct Preference Optimization (DPO) training.
Specifically, we treat context chunks as arms of MAB, select chunks based on
their expected reward scores to input into LLMs to generate responses, and
iteratively update these scores based on reward feedback. This exploration and
exploitation process enables the model to focus on the most relevant context
segments, thereby generating and collecting high-quality and diverse responses.
Finally, we collect these generated responses from the rollout process and
apply the DPO method to further optimize the LLM. Experimental results show
that LongMab-PO significantly improves the diversity and quality of preference
data pairs, achieving state-of-the-art performance on long-context reasoning
benchmarks. All code and data will be released on
https://github.com/NEUIR/LongMab-PO.

</details>


### [115] [Ask Good Questions for Large Language Models](https://arxiv.org/abs/2508.14025)
*Qi Wu,Zhongqi Lu*

Main category: cs.CL

TL;DR: 本研究提出了AGQ框架，结合CEIRT模型和LLMs，通过生成引导性问题来解决对话系统中用户困惑和信息检索效率低的问题，并取得了优于基线方法的成果。


<details>
  <summary>Details</summary>
Motivation: 当前对话系统在提供准确主题指导方面存在不足，尤其是在用户对相关概念感到困惑时，它们无法提供有效的指导。

Method: 提出了一种包含改进后的概念增强项目反应理论（CEIRT）模型的Ask-Good-Question（AGQ）框架，并将其与大型语言模型（LLMs）结合，以识别用户的知识水平并生成引导性问题。

Result: 通过与基线方法进行比较，所提出的方法在提升用户的信息检索体验方面表现更优。

Conclusion: 该方法通过生成引导性问题，显著提高了信息检索效率和用户体验。

Abstract: Recent advances in large language models (LLMs) have significantly improved
the performance of dialog systems, yet current approaches often fail to provide
accurate guidance of topic due to their inability to discern user confusion in
related concepts. To address this, we introduce the Ask-Good-Question (AGQ)
framework, which features an improved Concept-Enhanced Item Response Theory
(CEIRT) model to better identify users' knowledge levels. Our contributions
include applying the CEIRT model along with LLMs to directly generate guiding
questions based on the inspiring text, greatly improving information retrieval
efficiency during the question & answer process. Through comparisons with other
baseline methods, our approach outperforms by significantly enhencing the
users' information retrieval experiences.

</details>


### [116] [Beyond Pass@1: Self-Play with Variational Problem Synthesis Sustains RLVR](https://arxiv.org/abs/2508.14029)
*Xiao Liang,Zhongzhi Li,Yeyun Gong,Yelong Shen,Ying Nian Wu,Zhijiang Guo,Weizhu Chen*

Main category: cs.CL

TL;DR: 本文提出了一种名为 SvS 的新 RLVR 训练策略，通过在线合成问题来解决熵崩溃问题，显著提高了大语言模型在复杂推理任务上的 Pass@k 性能。


<details>
  <summary>Details</summary>
Motivation: 标准的 RLVR 训练会牺牲策略熵以换取 Pass@1 性能的提高，导致生成多样性降低并限制 Pass@k 性能。本文旨在解决 RLVR 训练中的熵崩溃问题，提高生成多样性。

Method: 提出了一种在线自玩变分问题合成（SvS）策略，通过使用策略的正确解决方案来合成变分问题，同时确保其参考答案与原始问题相同，以维持策略熵并提高 Pass@k 性能。

Result: SvS 策略有效维持了策略熵，并显著提高了 Pass@k 性能，在 AIME24 和 AIME25 基准测试中 Pass@32 性能分别提高了 18.3% 和 22.8%。实验证明了 SvS 在不同模型规模上的泛化性和鲁棒性。

Conclusion: 提出的在线自玩变分问题合成（SvS）策略通过合成变分问题并保持其参考答案不变，有效维持了策略熵，并显著提高了 Pass@k 性能，在 AIME24 和 AIME25 基准测试中 Pass@32 性能分别提高了 18.3% 和 22.8%。在 12 个推理基准测试和不同模型规模（3B 到 32B）上的实验证明了 SvS 的泛化性和鲁棒性。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as
a key paradigm for post-training Large Language Models (LLMs), particularly for
complex reasoning tasks. However, vanilla RLVR training has been shown to
improve Pass@1 performance at the expense of policy entropy, leading to reduced
generation diversity and limiting the Pass@k performance, which typically
represents the upper bound of LLM reasoning capability. In this paper, we
systematically analyze the policy's generation diversity from the perspective
of training problems and find that augmenting and updating training problems
helps mitigate entropy collapse during training. Based on these observations,
we propose an online Self-play with Variational problem Synthesis (SvS)
strategy for RLVR training, which uses the policy's correct solutions to
synthesize variational problems while ensuring their reference answers remain
identical to the originals. This self-improving strategy effectively maintains
policy entropy during training and substantially improves Pass@k compared with
standard RLVR, sustaining prolonged improvements and achieving absolute gains
of 18.3% and 22.8% in Pass@32 performance on the competition-level AIME24 and
AIME25 benchmarks. Experiments on 12 reasoning benchmarks across varying model
sizes from 3B to 32B consistently demonstrate the generalizability and
robustness of SvS.

</details>


### [117] [Unintended Misalignment from Agentic Fine-Tuning: Risks and Mitigation](https://arxiv.org/abs/2508.14031)
*Dongyoon Hahm,Taywon Min,Woogyeol Jin,Kimin Lee*

Main category: cs.CL

TL;DR: 本研究提出了一种名为 PING 的新方法，通过在 LLM 代理响应前添加自动生成的自然语言前缀，来解决微调 LLM 代理时出现的安全问题。PING 能够有效阻止 LLM 代理执行有害任务，同时保持其在良性任务上的性能，并在多项基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在将大型语言模型（LLM）微调用于代理任务以增强其能力时，安全问题常常被忽视。经过微调的LLM代理可能在无意中变得不那么符合安全规范，更容易执行有害任务，并且拒绝有害请求的倾向降低。

Method: 提出了一种名为前缀注入卫士（PING）的简单有效的方法，该方法通过在代理响应前添加自动生成的自然语言前缀来指导代理拒绝有害请求。具体来说，采用了一种迭代方法，包括生成候选前缀和选择能够同时优化任务性能和拒绝行为的前缀。

Result: 实验结果表明，PING 显著提高了微调的 LLM 代理的安全性，同时不牺牲其有效性。PING 在 Web 导航和代码生成任务的各种基准测试中，在安全性和性能方面均优于现有的提示方法。通过线性探测对内部隐藏状态的分析表明，前缀标记对于行为修改至关重要，这解释了性能的提升。

Conclusion: 所提出的前缀注入卫士（PING）方法能够有效提升经过微调的大型语言模型（LLM）代理在执行代理任务时的安全性，同时保持其在良性任务上的性能，并且在各种基准测试中优于现有的提示方法。

Abstract: Beyond simple text generation, Large Language Models (LLMs) have evolved into
agentic systems capable of planning and interacting with external tools to
solve complex tasks. This evolution involves fine-tuning LLMs on agent-specific
tasks to enhance their proficiency. However, safety concerns are frequently
overlooked during this fine-tuning process. In this work, we show that aligned
LLMs can become unintentionally misaligned, leading to a higher likelihood of
executing harmful tasks and a reduced tendency to refuse them when fine-tuned
to execute agentic tasks. To address these safety challenges, we propose Prefix
INjection Guard (PING), a simple yet effective method that prepends
automatically generated natural language prefixes to agent responses, guiding
them to refuse harmful requests while preserving performance on benign tasks.
Specifically, we introduce an iterative approach that alternates between (1)
generating candidate prefixes and (2) selecting those that optimize both task
performance and refusal behavior. Experimental results demonstrate that PING
significantly enhances the safety of fine-tuned LLM agents without sacrificing
their effectiveness. PING consistently outperforms existing prompting
approaches across diverse benchmarks in both web navigation and code generation
tasks. Our analysis of internal hidden states via linear probes reveals that
prefix tokens are crucial for behavior modification, explaining the performance
gains. WARNING: This paper contains contents that are unethical or offensive in
nature.

</details>


### [118] [The Promise of Large Language Models in Digital Health: Evidence from Sentiment Analysis in Online Health Communities](https://arxiv.org/abs/2508.14032)
*Xiancheng Li,Georgios D. Karampatakis,Helen E. Wood,Chris J. Griffiths,Borislava Mihaylova,Neil S. Coulson,Alessio Pasinato,Pietro Panzarasa,Marco Viviani,Anna De Simoni*

Main category: cs.CL

TL;DR: LLMs通过集成专家知识，在处理在线健康社区的复杂情感分析方面，比传统方法表现更好，并且达到专家级的一致性。


<details>
  <summary>Details</summary>
Motivation: 数字健康分析面临着利用患者生成健康内容（包含复杂情感和医学背景）的挑战，这需要稀缺的领域专业知识。传统机器学习方法受限于数据短缺和隐私限制。在线健康社区（OHCs）的帖子具有混合情感、临床术语和隐含情感表达，需要专业知识进行准确的情感分析。

Method: 本研究提出了一种利用结构化代码本来指导LLM进行情感分析的方法，通过目标提示而非大量训练来整合领域专业知识。研究比较了六种GPT模型、DeepSeek、LLaMA 3.1与BioBERT变体和基于词典的方法，使用了来自两个OHC的400个专家标注的帖子。

Result: LLMs在情感分析任务上取得了优于传统方法（BioBERT变体和基于词典的方法）的性能，并且在与专家的评估一致性上没有统计学上的显著差异，表明其能够整合超越表面模式识别的知识。

Conclusion: LLMs通过在上下文学习中集成专家知识，在情感分析任务上表现优于传统方法，并且与专家的评估一致性高，为数字健康分析提供了可扩展的解决方案。

Abstract: Digital health analytics face critical challenges nowadays. The sophisticated
analysis of patient-generated health content, which contains complex emotional
and medical contexts, requires scarce domain expertise, while traditional ML
approaches are constrained by data shortage and privacy limitations in
healthcare settings. Online Health Communities (OHCs) exemplify these
challenges with mixed-sentiment posts, clinical terminology, and implicit
emotional expressions that demand specialised knowledge for accurate Sentiment
Analysis (SA). To address these challenges, this study explores how Large
Language Models (LLMs) can integrate expert knowledge through in-context
learning for SA, providing a scalable solution for sophisticated health data
analysis. Specifically, we develop a structured codebook that systematically
encodes expert interpretation guidelines, enabling LLMs to apply
domain-specific knowledge through targeted prompting rather than extensive
training. Six GPT models validated alongside DeepSeek and LLaMA 3.1 are
compared with pre-trained language models (BioBERT variants) and lexicon-based
methods, using 400 expert-annotated posts from two OHCs. LLMs achieve superior
performance while demonstrating expert-level agreement. This high agreement,
with no statistically significant difference from inter-expert agreement
levels, suggests knowledge integration beyond surface-level pattern
recognition. The consistent performance across diverse LLM models, supported by
in-context learning, offers a promising solution for digital health analytics.
This approach addresses the critical challenge of expert knowledge shortage in
digital health research, enabling real-time, expert-quality analysis for
patient monitoring, intervention assessment, and evidence-based health
strategies.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [119] [BERT-VQA: Visual Question Answering on Plots](https://arxiv.org/abs/2508.13184)
*Tai Vu,Robert Yang*

Main category: cs.LG

TL;DR: BERT-VQA, a VisualBERT-based model, was developed for visual question answering on plots. Contrary to the hypothesis, the cross-modality module was found not essential for alignment, offering insights into the challenge and model suitability.


<details>
  <summary>Details</summary>
Motivation: To tackle the subtask of visual question answering on plots, a challenging area requiring information exchange between vision and language domains.

Method: Developed BERT-VQA, a VisualBERT-based model architecture with a pretrained ResNet 101 image encoder, potentially with joint fusion. Trained and evaluated against a baseline of LSTM, CNN, and a shallow classifier.

Result: The final outcome disproved the core hypothesis regarding the essentiality of the cross-modality module in VisualBERT for aligning plot components with question phrases.

Conclusion: The study provided valuable insights into the difficulty of plot question answering and the appropriateness of different model architectures, disproving the core hypothesis that the cross-modality module in VisualBERT is essential for aligning plot components with question phrases.

Abstract: Visual question answering has been an exciting challenge in the field of
natural language understanding, as it requires deep learning models to exchange
information from both vision and language domains. In this project, we aim to
tackle a subtask of this problem, namely visual question answering on plots. To
achieve this, we developed BERT-VQA, a VisualBERT-based model architecture with
a pretrained ResNet 101 image encoder, along with a potential addition of joint
fusion. We trained and evaluated this model against a baseline that consisted
of a LSTM, a CNN, and a shallow classifier. The final outcome disproved our
core hypothesis that the cross-modality module in VisualBERT is essential in
aligning plot components with question phrases. Therefore, our work provided
valuable insights into the difficulty of the plot question answering challenge
as well as the appropriateness of different model architectures in solving this
problem.

</details>


### [120] [Contextual Attention-Based Multimodal Fusion of LLM and CNN for Sentiment Analysis](https://arxiv.org/abs/2508.13196)
*Meriem Zerkouk,Miloud Mihoubi,Belkacem Chikhaoui*

Main category: cs.LG

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: This paper introduces a novel approach for multimodal sentiment analysis on
social media, particularly in the context of natural disasters, where
understanding public sentiment is crucial for effective crisis management.
Unlike conventional methods that process text and image modalities separately,
our approach seamlessly integrates Convolutional Neural Network (CNN) based
image analysis with Large Language Model (LLM) based text processing,
leveraging Generative Pre-trained Transformer (GPT) and prompt engineering to
extract sentiment relevant features from the CrisisMMD dataset. To effectively
model intermodal relationships, we introduce a contextual attention mechanism
within the fusion process. Leveraging contextual-attention layers, this
mechanism effectively captures intermodality interactions, enhancing the
model's comprehension of complex relationships between textual and visual data.
The deep neural network architecture of our model learns from these fused
features, leading to improved accuracy compared to existing baselines.
Experimental results demonstrate significant advancements in classifying social
media data into informative and noninformative categories across various
natural disasters. Our model achieves a notable 2.43% increase in accuracy and
5.18% in F1-score, highlighting its efficacy in processing complex multimodal
data. Beyond quantitative metrics, our approach provides deeper insight into
the sentiments expressed during crises. The practical implications extend to
real time disaster management, where enhanced sentiment analysis can optimize
the accuracy of emergency interventions. By bridging the gap between multimodal
analysis, LLM powered text understanding, and disaster response, our work
presents a promising direction for Artificial Intelligence (AI) driven crisis
management solutions. Keywords:

</details>


### [121] [Strategies for training point distributions in physics-informed neural networks](https://arxiv.org/abs/2508.13216)
*Santosh Humagain,Toni Schneidereit*

Main category: cs.LG

TL;DR: 本研究系统地研究和评估了物理信息神经网络（PINNs）的核心组成部分——训练点分布，发现在不同微分方程的求解中，训练点分布对求解精度有显著影响，并与方程特性相关。


<details>
  <summary>Details</summary>
Motivation: 物理信息神经网络（PINNs）是一种有前途的求解微分方程的方法，但其性能高度依赖于多种因素。本研究旨在系统地研究和评估PINNs的一个核心组成部分——训练点分布。

Method: 通过直接在损失函数中纳入微分方程的结构和给定条件来逼近微分方程。研究了两种常微分方程和两种偏微分方程，并测试了五种训练数据生成策略和浅层（一层或两层隐藏层）网络结构。此外，还引入了基于正弦的训练点，并使用随机和固定种子权重初始化来保证结果的可复现性。

Result: 研究结果表明，训练点分布对求解精度有显著影响，并且与微分方程的特性相关。

Conclusion: 研究结果表明，训练点分布对求解精度有显著影响，并且与微分方程的特性相关。

Abstract: Physics-informed neural networks approach the approximation of differential
equations by directly incorporating their structure and given conditions in a
loss function. This enables conditions like, e.g., invariants to be easily
added during the modelling phase. In addition, the approach can be considered
as mesh free and can be utilised to compute solutions on arbitrary grids after
the training phase. Therefore, physics-informed neural networks are emerging as
a promising alternative to solving differential equations with methods from
numerical mathematics. However, their performance highly depends on a large
variety of factors. In this paper, we systematically investigate and evaluate a
core component of the approach, namely the training point distribution. We test
two ordinary and two partial differential equations with five strategies for
training data generation and shallow network architectures, with one and two
hidden layers. In addition to common distributions, we introduce sine-based
training points, which are motivated by the construction of Chebyshev nodes.
The results are challenged by using certain parameter combinations like, e.g.,
random and fixed-seed weight initialisation for reproducibility. The results
show the impact of the training point distributions on the solution accuracy
and we find evidence that they are connected to the characteristics of the
differential equation.

</details>


### [122] [GRAFT: Gradient-Aware Fast MaxVol Technique for Dynamic Data Sampling](https://arxiv.org/abs/2508.13653)
*Ashish Jha,Anh huy Phan,Razan Dibo,Valentin Leplat*

Main category: cs.LG

TL;DR: GRAFT is a method to reduce the cost of training neural networks by selecting a subset of data based on low-rank feature representation and a gradient-approximation criterion, which preserves training accuracy while improving efficiency and reducing environmental impact.


<details>
  <summary>Details</summary>
Motivation: Training modern neural networks on large datasets is computationally and environmentally costly.

Method: GRAFT is a scalable in-training subset selection method that extracts a low-rank feature representation for each batch, applies a Fast MaxVol sampler to select a small, diverse subset that spans the batch's dominant subspace, and dynamically adjusts the subset size using a gradient-approximation criterion.

Result: GRAFT matches or exceeds recent selection baselines in both accuracy and efficiency, providing a favorable trade-off between accuracy, efficiency, and emissions across multiple benchmarks.

Conclusion: GRAFT preserves the training trajectory while reducing wall-clock time, energy consumption, and CO2 emissions, matching or exceeding recent selection baselines in both accuracy and efficiency.

Abstract: Training modern neural networks on large datasets is computationally and
environmentally costly. We introduce GRAFT, a scalable in-training subset
selection method that (i) extracts a low-rank feature representation for each
batch, (ii) applies a Fast MaxVol sampler to select a small, diverse subset
that spans the batch's dominant subspace, and (iii) dynamically adjusts the
subset size using a gradient-approximation criterion. By operating in low-rank
subspaces and training on carefully chosen examples instead of full batches,
GRAFT preserves the training trajectory while reducing wall-clock time, energy
consumption, and $\mathrm{CO}_2$ emissions. Across multiple benchmarks, GRAFT
matches or exceeds recent selection baselines in both accuracy and efficiency,
providing a favorable trade-off between accuracy, efficiency, and emissions.

</details>


### [123] [Deep Graph Neural Point Process For Learning Temporal Interactive Networks](https://arxiv.org/abs/2508.13219)
*Su Chen,Xiaohua Qi,Xixun Lin,Yanmin Shang,Xiaolin Xu,Yangxi Li*

Main category: cs.LG

TL;DR: DGNPP模型通过整合动态和静态嵌入，有效预测事件及其发生时间，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往将学习时间交互网络（TIN）视为粗粒度的多序列预测问题，忽略了网络拓扑结构的影响。本文旨在解决这一局限性。

Method: 提出了一种深度图神经网络点过程（DGNPP）模型，包含节点聚合层和自注意力层。节点聚合层用于捕捉拓扑结构以生成用户和项目的静态表示，自注意力层用于动态更新嵌入。

Result: 实验评估表明，DGNPP 在事件预测和时间预测任务上取得了优越的性能，并且效率很高，显著优于基线模型，并有效缓解了先前方法的局限性。

Conclusion: DGNPP 通过结合动态和静态嵌入，并在事件强度函数中进行优化，可以有效地预测事件和发生时间，并且在事件预测和时间预测任务上取得了优于基线模型的性能，同时效率很高。

Abstract: Learning temporal interaction networks(TIN) is previously regarded as a
coarse-grained multi-sequence prediction problem, ignoring the network topology
structure influence. This paper addresses this limitation and a Deep Graph
Neural Point Process(DGNPP) model for TIN is proposed. DGNPP consists of two
key modules: the Node Aggregation Layer and the Self Attentive Layer. The Node
Aggregation Layer captures topological structures to generate static
representation for users and items, while the Self Attentive Layer dynamically
updates embeddings over time. By incorporating both dynamic and static
embeddings into the event intensity function and optimizing the model via
maximum likelihood estimation, DGNPP predicts events and occurrence time
effectively. Experimental evaluations on three public datasets demonstrate that
DGNPP achieves superior performance in event prediction and time prediction
tasks with high efficiency, significantly outperforming baseline models and
effectively mitigating the limitations of prior approaches.

</details>


### [124] [Dynamic Design of Machine Learning Pipelines via Metalearning](https://arxiv.org/abs/2508.13436)
*Edesio Alcobaça,André C. P. L. F. de Carvalho*

Main category: cs.LG

TL;DR: 通过元学习动态设计 AutoML 搜索空间，可大幅降低计算成本和过拟合风险。


<details>
  <summary>Details</summary>
Motivation: 传统 AutoML 的搜索和优化策略计算成本高，且搜索空间大易导致过拟合。

Method: 提出了一种元学习方法，利用历史元知识动态设计 AutoML 的搜索空间，以选择有前景的搜索区域，从而加速优化过程。

Result: 该方法在随机搜索中将运行时间减少了 89%，搜索空间减少了（预处理器 1.8/13，分类器 4.3/16），且不影响预测性能。适配 Auto-Sklearn 后也能减少其搜索空间，并具有有竞争力的性能。

Conclusion: 该元学习方法通过动态设计 AutoML 的搜索空间，可以显著减少运行时间和搜索空间，同时保持预测性能，并能适配 Auto-Sklearn。

Abstract: Automated machine learning (AutoML) has democratized the design of machine
learning based systems, by automating model selection, hyperparameter tuning
and feature engineering. However, the high computational cost associated with
traditional search and optimization strategies, such as Random Search, Particle
Swarm Optimization and Bayesian Optimization, remains a significant challenge.
Moreover, AutoML systems typically explore a large search space, which can lead
to overfitting. This paper introduces a metalearning method for dynamically
designing search spaces for AutoML system. The proposed method uses historical
metaknowledge to select promising regions of the search space, accelerating the
optimization process. According to experiments conducted for this study, the
proposed method can reduce runtime by 89\% in Random Search and search space by
(1.8/13 preprocessor and 4.3/16 classifier), without compromising significant
predictive performance. Moreover, the proposed method showed competitive
performance when adapted to Auto-Sklearn, reducing its search space.
Furthermore, this study encompasses insights into meta-feature selection,
meta-model explainability, and the trade-offs inherent in search space
reduction strategies.

</details>


### [125] [A Recurrent Neural Network based Clustering Method for Binary Data Sets in Education](https://arxiv.org/abs/2508.13224)
*Mizuki Ohira,Toshimichi Saito*

Main category: cs.LG

TL;DR: A recurrent neural network is used for clustering large S-P charts in education. The method uses network dynamics to create clusters and evaluates performance with an average caution index, proving effective in experiments.


<details>
  <summary>Details</summary>
Motivation: To address the difficulty in handling large S-P charts (binary data widely used in education) as the number of students increases, by classifying them into smaller charts.

Method: A simple clustering method based on recurrent neural network dynamics, where the network has multiple fixed points and basins of attraction define clusters corresponding to smaller S-P charts.

Result: The proposed method successfully classifies large S-P charts into smaller ones. An average caution index, which characterizes the singularity of student answer patterns, was used to evaluate the clustering performance.

Conclusion: The effectiveness of the proposed recurrent neural network-based clustering method for S-P charts has been confirmed through fundamental experiments.

Abstract: This paper studies an application of a recurrent neural network to clustering
method for the S-P chart: a binary data set used widely in education. As the
number of students increases, the S-P chart becomes hard to handle. In order to
classify the large chart into smaller charts, we present a simple clustering
method based on the network dynamics. In the method, the network has multiple
fixed points and basins of attraction give clusters corresponding to small S-P
charts. In order to evaluate the clustering performance, we present an
important feature quantity: average caution index that characterizes
singularity of students answer oatterns. Performing fundamental experiments,
effectiveness of the method is confirmed.

</details>


### [126] [GDNSQ: Gradual Differentiable Noise Scale Quantization for Low-bit Neural Networks](https://arxiv.org/abs/2508.14004)
*Sergey Salishev,Ian Akhremchik*

Main category: cs.LG

TL;DR: 所提出的量化方法通过将微调视为一个平滑的、受约束的优化问题，并使用可学习比特宽度的 STE，在 W1A1 设置下实现了具有竞争力的精度，同时保持了 STE 的效率。


<details>
  <summary>Details</summary>
Motivation: 量化神经网络可以被看作是一系列噪声信道，其中每个层中的舍入会随着比特宽度的减小而降低容量。浮点（FP）检查点设定了最大输入速率。在比特宽度减小的过程中跟踪容量动态，并通过将微调视为一个平滑的、受约束的优化问题来识别由此产生的量化瓶颈。

Method: 该方法采用完全可微的直通估计器（STE），具有可学习的比特宽度、噪声尺度和钳位边界，并通过外部点惩罚强制执行目标比特宽度。通过蒸馏进行温和的度量平滑来稳定训练。

Result: 该方法在 W1A1 设置下达到了有竞争力的精度，同时保持了 STE 的效率。

Conclusion: 所提出的量化方法在 W1A1 设置下达到了有竞争力的精度，同时保持了 STE 的效率。

Abstract: Quantized neural networks can be viewed as a chain of noisy channels, where
rounding in each layer reduces capacity as bit-width shrinks; the
floating-point (FP) checkpoint sets the maximum input rate. We track capacity
dynamics as the average bit-width decreases and identify resulting quantization
bottlenecks by casting fine-tuning as a smooth, constrained optimization
problem. Our approach employs a fully differentiable Straight-Through Estimator
(STE) with learnable bit-width, noise scale and clamp bounds, and enforces a
target bit-width via an exterior-point penalty; mild metric smoothing (via
distillation) stabilizes training. Despite its simplicity, the method attains
competitive accuracy down to the extreme W1A1 setting while retaining the
efficiency of STE.

</details>


### [127] [RISE: Enhancing VLM Image Annotation with Self-Supervised Reasoning](https://arxiv.org/abs/2508.13229)
*Suhang Hu,Wei Hu,Yuhang Su,Fan Zhang*

Main category: cs.LG

TL;DR: RISE框架通过生成和利用高质量的推理链（CoTs），提升了视觉语言模型（VLM）在复杂图像标注任务中的推理能力和可解释性，且无需人工标注CoTs。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在处理复杂图像标注任务（如情绪分类、情境驱动的目标检测）时面临挑战，因为这些任务需要复杂的推理能力。标准的监督微调（SFT）只关注标注结果，忽略了推理过程；而视觉强化微调（Visual-RFT）由于预训练阶段缺乏高质量、经过验证的CoT，导致生成的推理链（CoTs）不一致。

Method: RISE框架包含两个阶段：RISE-CoT（推理）和RISE-R1（启发、强化、专业化）。RISE-CoT利用强化学习驱动“标注-推理-标注”的闭环，生成视觉基础且逻辑一致的推理链（CoT），并通过重建原始标注来验证其质量。RISE-R1则利用RISE-CoT筛选出的高质量CoT子集进行监督微调，随后进行强化微调，以实现可解释的推理和准确的标注。

Result: 在复杂和简单的图像标注任务上，经过RISE训练的Qwen2-VL-2B模型的表现优于SFT和Visual-RFT，展现出稳健的性能和增强的可解释性。

Conclusion: RISE通过自我监督的方式，在没有人工标注的推理过程的情况下，提升了视觉语言模型（VLM）的推理能力，在复杂和简单的图像标注任务上均表现优于标准的监督微调（SFT）和视觉强化微调（Visual-RFT），同时提高了模型的可解释性。

Abstract: Vision-Language Models (VLMs) struggle with complex image annotation tasks,
such as emotion classification and context-driven object detection, which
demand sophisticated reasoning. Standard Supervised Fine-Tuning (SFT) focuses
solely on annotation outcomes, ignoring underlying rationales, while Visual
Reinforcement Fine-Tuning (Visual-RFT) produces inconsistent Chains of Thought
(CoTs) due to the absence of high-quality, verified CoTs during pre-training.
We introduce RISE (Reason-Inspire-Strengthen-Expertise), a two-stage framework
to overcome these limitations. In the Reason stage (RISE-CoT), a reinforcement
learning-driven "annotation-reasoning-annotation" closed-loop generates
visually grounded, logically consistent CoTs by verifying their ability to
reconstruct original annotations without direct leakage. The Inspire and
Strengthen stage (RISE-R1) leverages a high-quality CoT subset, filtered by
RISE-CoT rewards, for supervised fine-tuning, followed by reinforcement
fine-tuning to produce interpretable reasoning and accurate annotations,
achieving Expertise in complex visual tasks. Evaluated on complex and simple
image annotation tasks, RISE-trained Qwen2-VL-2B outperforms SFT and
Visual-RFT, achieving robust performance and enhanced explainability. RISE
offers a self-supervised solution for advancing VLM reasoning without requiring
manually annotated CoTs.

</details>


### [128] [Data driven feedback linearization of nonlinear control systems via Lie derivatives and stacked regression approach](https://arxiv.org/abs/2508.13241)
*Lakshmi Priya P. K.,Andreas Schwung*

Main category: cs.LG

TL;DR: 本文提出一种新方法，利用稀疏回归和李导数来识别和控制物理系统，克服了非线性因素的挑战。


<details>
  <summary>Details</summary>
Motivation: 在物理系统中发现控制方程并设计有效的反馈控制器是一个持续的挑战，需要深入理解系统行为，包括影响其动态的非线性因素。

Method: 首先，使用稀疏回归算法识别系统，然后通过将李导数应用于输出函数字典来为发现的系统设计反馈控制器，以推导保证无内部动态可观测性的增强约束。

Result: 该方法能够发现并反馈线性化物理模型，克服了现有技术的局限性。

Conclusion: 本文提出了一种结合了堆叠回归算法和相对阶条件的先进方法，用于发现和反馈线性化物理模型。

Abstract: Discovering the governing equations of a physical system and designing an
effective feedback controller remains one of the most challenging and intensive
areas of ongoing research. This task demands a deep understanding of the system
behavior, including the nonlinear factors that influence its dynamics. In this
article, we propose a novel methodology for identifying a feedback linearized
physical system based on known prior dynamic behavior. Initially, the system is
identified using a sparse regression algorithm, subsequently a feedback
controller is designed for the discovered system by applying Lie derivatives to
the dictionary of output functions to derive an augmented constraint which
guarantees that no internal dynamics are observed. Unlike the prior related
works, the novel aspect of this article combines the approach of stacked
regression algorithm and relative degree conditions to discover and feedback
linearize the true governing equations of a physical model.

</details>


### [129] [MACTAS: Self-Attention-Based Module for Inter-Agent Communication in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.13661)
*Maciej Wojtala,Bogusz Stefańczyk,Dominik Bogucki,Łukasz Lepak,Jakub Strykowski,Paweł Wawrzyński*

Main category: cs.LG

TL;DR: 提出了一种新的、全可微的基于自注意力机制的通信模块，用于MARL，并在SMAC基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体强化学习（MARL）中现有通信协议复杂且不可微的问题。

Method: 提出了一种基于自注意力机制的通信模块，该模块可以无缝集成到任何动作-价值函数分解方法中，并且是完全可微的。

Result: 实验结果表明，该方法在SMAC基准测试中是有效的，并且在几张地图上取得了最先进的性能。

Conclusion: 该方法在SMAC基准测试中的几张地图上取得了最先进的性能。

Abstract: Communication is essential for the collective execution of complex tasks by
human agents, motivating interest in communication mechanisms for multi-agent
reinforcement learning (MARL). However, existing communication protocols in
MARL are often complex and non-differentiable. In this work, we introduce a
self-attention-based communication module that exchanges information between
the agents in MARL. Our proposed approach is fully differentiable, allowing
agents to learn to generate messages in a reward-driven manner. The module can
be seamlessly integrated with any action-value function decomposition method
and can be viewed as an extension of such decompositions. Notably, it includes
a fixed number of trainable parameters, independent of the number of agents.
Experimental results on the SMAC benchmark demonstrate the effectiveness of our
approach, which achieves state-of-the-art performance on several maps.

</details>


### [130] [Physically Plausible Data Augmentations for Wearable IMU-based Human Activity Recognition Using Physics Simulation](https://arxiv.org/abs/2508.13284)
*Nobuyuki Oishi,Philip Birch,Daniel Roggen,Paula Lago*

Main category: cs.LG

TL;DR: PPDA通过物理模拟解决HAR中的数据稀缺问题，提升模型性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传感器数据的HAR领域中，高质量标记数据的稀缺阻碍了模型的性能并限制了在真实场景中的泛化能力。STDA等数据增强技术虽然常用，但可能产生与原始活动标签意义不符的增强数据。

Method: PPDA利用来自运动捕捉或基于视频的姿势估计的人体运动数据，并通过物理模拟引入各种现实世界的变异性。

Result: PPDA比传统的STDA方法在三个公开数据集上表现更好，宏观F1分数平均提高3.7个百分点（最高可达13个百分点），并且在训练样本减少高达60%的情况下仍能达到有竞争力的性能。

Conclusion: PPDA通过物理模拟引入现实世界的变异性，例如改变身体运动、传感器放置和硬件相关的影响，从而提高HAR模型的性能和泛化能力。

Abstract: The scarcity of high-quality labeled data in sensor-based Human Activity
Recognition (HAR) hinders model performance and limits generalization across
real-world scenarios. Data augmentation is a key strategy to mitigate this
issue by enhancing the diversity of training datasets. Signal
Transformation-based Data Augmentation (STDA) techniques have been widely used
in HAR. However, these methods are often physically implausible, potentially
resulting in augmented data that fails to preserve the original meaning of the
activity labels. In this study, we introduce and systematically characterize
Physically Plausible Data Augmentation (PPDA) enabled by physics simulation.
PPDA leverages human body movement data from motion capture or video-based pose
estimation and incorporates various realistic variabilities through physics
simulation, including modifying body movements, sensor placements, and
hardware-related effects. We compare the performance of PPDAs with traditional
STDAs on three public datasets of daily activities and fitness workouts. First,
we evaluate each augmentation method individually, directly comparing PPDAs to
their STDA counterparts. Next, we assess how combining multiple PPDAs can
reduce the need for initial data collection by varying the number of subjects
used for training. Experiments show consistent benefits of PPDAs, improving
macro F1 scores by an average of 3.7 pp (up to 13 pp) and achieving competitive
performance with up to 60% fewer training subjects than STDAs. As the first
systematic study of PPDA in sensor-based HAR, these results highlight the
advantages of pursuing physical plausibility in data augmentation and the
potential of physics simulation for generating synthetic Inertial Measurement
Unit data for training deep learning HAR models. This cost-effective and
scalable approach therefore helps address the annotation scarcity challenge in
HAR.

</details>


### [131] [Towards Human-AI Complementarity in Matching Tasks](https://arxiv.org/abs/2508.13285)
*Adrian Arnaiz-Rodriguez,Nina Corvelo Benz,Suhas Thejaswi,Nuria Oliver,Manuel Gomez-Rodriguez*

Main category: cs.LG

TL;DR: 该研究提出了一个名为comatch的协同匹配系统，通过人机协作来提高匹配决策的准确性。实验证明，该系统比单独使用人类或算法效果更好。


<details>
  <summary>Details</summary>
Motivation: 现有算法匹配系统未能实现人机协同，导致人类结合算法做出的决策不一定优于单独的人类或算法决策。本研究旨在解决这一差距，提升人机协同匹配的效率。

Method: 提出了一种名为“协作匹配”（comatch）的数据驱动算法匹配系统，该系统能够选择性地做出算法最自信的匹配决策，并将剩余的决策推迟给人类决策者。通过优化算法做出决策的数量和推迟给人类决策者的数量，以最大化整体性能。

Result: 通过包含800名参与者的大规模人类主体研究验证，comatch生成的匹配结果优于单独由人类或算法生成的匹配结果。

Conclusion: 提出的协 作匹配（comatch）方法通过让人类决策者处理算法不确定的匹配，优化了决策数量，从而提高了整体匹配性能。

Abstract: Data-driven algorithmic matching systems promise to help human decision
makers make better matching decisions in a wide variety of high-stakes
application domains, such as healthcare and social service provision. However,
existing systems are not designed to achieve human-AI complementarity:
decisions made by a human using an algorithmic matching system are not
necessarily better than those made by the human or by the algorithm alone. Our
work aims to address this gap. To this end, we propose collaborative matching
(comatch), a data-driven algorithmic matching system that takes a collaborative
approach: rather than making all the matching decisions for a matching task
like existing systems, it selects only the decisions that it is the most
confident in, deferring the rest to the human decision maker. In the process,
comatch optimizes how many decisions it makes and how many it defers to the
human decision maker to provably maximize performance. We conduct a large-scale
human subject study with $800$ participants to validate the proposed approach.
The results demonstrate that the matching outcomes produced by comatch
outperform those generated by either human participants or by algorithmic
matching on their own. The data gathered in our human subject study and an
implementation of our system are available as open source at
https://github.com/Networks-Learning/human-AI-complementarity-matching.

</details>


### [132] [Hierarchical Conformal Classification](https://arxiv.org/abs/2508.13288)
*Floris den Hengst,Inès Blin,Majid Mohammadi,Syed Ihtesham Hussain Shah,Taraneh Younesian*

Main category: cs.LG

TL;DR: HCC extends conformal prediction to incorporate class hierarchies, leading to better structured prediction sets and user preference while maintaining uncertainty quantification guarantees.


<details>
  <summary>Details</summary>
Motivation: Standard CP ignores the hierarchical structure among class labels, which can be important domain knowledge. HCC aims to incorporate this structure into prediction sets.

Method: HCC is formulated as a constrained optimization problem. A subset of candidate solutions is used to ensure coverage and uphold optimality.

Result: Empirical evaluations on audio, image, and text data show the advantages of HCC. A user study indicates that annotators prefer hierarchical prediction sets over flat ones.

Conclusion: HCC maintains coverage guarantees and is preferred by users, making it a valuable extension of CP for classification tasks with hierarchical structures.

Abstract: Conformal prediction (CP) is a powerful framework for quantifying uncertainty
in machine learning models, offering reliable predictions with finite-sample
coverage guarantees. When applied to classification, CP produces a prediction
set of possible labels that is guaranteed to contain the true label with high
probability, regardless of the underlying classifier. However, standard CP
treats classes as flat and unstructured, ignoring domain knowledge such as
semantic relationships or hierarchical structure among class labels. This paper
presents hierarchical conformal classification (HCC), an extension of CP that
incorporates class hierarchies into both the structure and semantics of
prediction sets. We formulate HCC as a constrained optimization problem whose
solutions yield prediction sets composed of nodes at different levels of the
hierarchy, while maintaining coverage guarantees. To address the combinatorial
nature of the problem, we formally show that a much smaller, well-structured
subset of candidate solutions suffices to ensure coverage while upholding
optimality. An empirical evaluation on three new benchmarks consisting of
audio, image, and text data highlights the advantages of our approach, and a
user study shows that annotators significantly prefer hierarchical over flat
prediction sets.

</details>


### [133] [Efficient Constraint-Aware Flow Matching via Randomized Exploration](https://arxiv.org/abs/2508.13316)
*Zhengyan Huan,Jacob Boerma,Li-Ping Liu,Shuchin Aeron*

Main category: cs.LG

TL;DR: 本文提出了一种基于流匹配（FM）的生成模型，可以同时满足给定约束和匹配目标分布。文章针对两种约束场景（可微分距离函数和成员资格预言机）提出了相应的解决方案，并证明了其有效性和计算效率。特别是，基于预言机的约束处理方法具有更广泛的应用前景。


<details>
  <summary>Details</summary>
Motivation: 在生成样本时，除了需要匹配目标分布之外，还需要满足给定的约束。现有的方法通常需要可微分的约束集、障碍函数或反射机制，这限制了其应用范围。因此，需要开发一种更通用的方法来处理各种约束场景，特别是那些只能通过成员资格预言机查询的约束。

Method: 本文提出两种方法来解决带约束的生成样本问题：1. 当存在可微分距离函数时，通过在FM目标函数中添加惩罚项来处理约束；2. 当只有成员资格预言机时，通过学习一个均值流来满足约束，该均值流具有高概率满足约束。此外，还提出了一种两阶段的方法，以提高计算效率。

Result: 本文提出的方法在约束满足率和样本分布匹配方面均表现出色。对于可微分距离函数的情况，所提出的方法能够有效地将生成样本约束在目标区域内。对于成员资格预言机的情况，所提出的基于随机化的方法在数值上显示出高约束满足率，并且比现有方法更具计算效率。文章最后通过训练对抗样本生成器作为实际应用案例，展示了该方法在处理基于预言机的约束方面的有效性。

Conclusion: 本文提出的方法在满足约束的同时，在匹配目标分布方面取得了显著的收益。特别是，在约束满足方面，我们提出了一种新颖的、基于随机化的方法，该方法在数值上被证明可以满足约束，并且在计算上比现有方法更有效。

Abstract: We consider the problem of generating samples via Flow Matching (FM) with an
additional requirement that the generated samples must satisfy given
constraints. We consider two scenarios, viz.: (a) when a differentiable
distance function to the constraint set is given, and (b) when the constraint
set is only available via queries to a membership oracle. For case (a), we
propose a simple adaptation of the FM objective with an additional term that
penalizes the distance between the constraint set and the generated samples.
For case (b), we propose to employ randomization and learn a mean flow that is
numerically shown to have a high likelihood of satisfying the constraints. This
approach deviates significantly from existing works that require simple convex
constraints, knowledge of a barrier function, or a reflection mechanism to
constrain the probability flow. Furthermore, in the proposed setting we show
that a two-stage approach, where both stages approximate the same original flow
but with only the second stage probing the constraints via randomization, is
more computationally efficient. Through several synthetic cases of constrained
generation, we numerically show that the proposed approaches achieve
significant gains in terms of constraint satisfaction while matching the target
distributions. As a showcase for a practical oracle-based constraint, we show
how our approach can be used for training an adversarial example generator,
using queries to a hard-label black-box classifier. We conclude with several
future research directions. Our code is available at
https://github.com/ZhengyanHuan/FM-RE.

</details>


### [134] [X-MoE: Enabling Scalable Training for Emerging Mixture-of-Experts Architectures on HPC Platforms](https://arxiv.org/abs/2508.13337)
*Yueming Yuan,Ahan Gupta,Jianping Li,Sajal Dash,Feiyi Wang,Minjia Zhang*

Main category: cs.LG

TL;DR: X-MoE 是一个为下一代 MoE 架构设计的、可在非 NVIDIA 平台（如 AMD GPU）上实现大规模高效训练的系统。它通过创新的技术解决了现有 MoE 训练系统在可扩展性和跨平台兼容性方面的问题，显著提升了训练效率和模型规模。


<details>
  <summary>Details</summary>
Motivation: 现有的 MoE 架构（如 DeepSeek-MoE）虽然模型质量高，但在可扩展性方面存在激活内存开销大和 all-to-all 通信成本高的问题。此外，主要为 NVIDIA GPU 优化的训练系统在非 NVIDIA 平台上的表现不佳，未能充分发挥其计算潜力。

Method: X-MoE 提出了一种新颖的 MoE 训练系统，通过采用无填充的跨平台内核、绕过冗余的调度以及序列分片 MoE 块的混合并行等技术，实现了可扩展的训练性能。

Result: 在 Frontier 超级计算机（配备 AMD MI250X GPU）上的评估结果表明，X-MoE 能够将 DeepSeek 风格的 MoE 模型扩展到 5450 亿参数，支持 1024 个 GPU，是在相同硬件预算下可训练的最大模型规模的 10 倍，并且保持了高训练吞吐量。

Conclusion: X-MoE 成功地实现了在 AMD MI250X GPU 上的 DeepSeek 风格 MoE 的可扩展训练，支持高达 5450 亿参数的模型，在 1024 个 GPU 上实现了 10 倍于现有方法的模型规模，同时保持了高训练吞吐量。

Abstract: Emerging expert-specialized Mixture-of-Experts (MoE) architectures, such as
DeepSeek-MoE, deliver strong model quality through fine-grained expert
segmentation and large top-k routing. However, their scalability is limited by
substantial activation memory overhead and costly all-to-all communication.
Furthermore, current MoE training systems - primarily optimized for NVIDIA GPUs
- perform suboptimally on non-NVIDIA platforms, leaving significant
computational potential untapped. In this work, we present X-MoE, a novel MoE
training system designed to deliver scalable training performance for
next-generation MoE architectures. X-MoE achieves this via several novel
techniques, including efficient padding-free MoE training with cross-platform
kernels, redundancy-bypassing dispatch, and hybrid parallelism with
sequence-sharded MoE blocks. Our evaluation on the Frontier supercomputer,
powered by AMD MI250X GPUs, shows that X-MoE scales DeepSeek-style MoEs up to
545 billion parameters across 1024 GPUs - 10x larger than the largest trainable
model with existing methods under the same hardware budget, while maintaining
high training throughput. The source code of X-MoE is available at
https://github.com/Supercomputing-System-AI-Lab/X-MoE.

</details>


### [135] [Decoding Communications with Partial Information](https://arxiv.org/abs/2508.13326)
*Dylan Cope,Peter McBurney*

Main category: cs.LG

TL;DR: This paper tackles partial observability in language acquisition, where learners must infer hidden information from the environment and communication, and introduces a learning algorithm to solve this.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the unaddressed consideration of partial observability in machine language acquisition, where learners typically assume access to all relevant information.

Method: The paper explores relaxing the assumption of full observability in machine language acquisition, posing a more challenging setting where relevant information needs to be inferred from the environment, actions, and messages. A learning-based algorithm is presented to perform the decoding of private information.

Result: The paper demonstrates how the problem can be solved in a toy setting and formally explores challenges in more general settings.

Conclusion: The paper presents a learning-based algorithm to decode private information, facilitating language acquisition under partial observability.

Abstract: Machine language acquisition is often presented as a problem of imitation
learning: there exists a community of language users from which a learner
observes speech acts and attempts to decode the mappings between utterances and
situations. However, an interesting consideration that is typically unaddressed
is partial observability, i.e. the learner is assumed to see all relevant
information. This paper explores relaxing this assumption, thereby posing a
more challenging setting where such information needs to be inferred from
knowledge of the environment, the actions taken, and messages sent. We see
several motivating examples of this problem, demonstrate how they can be solved
in a toy setting, and formally explore challenges that arise in more general
settings. A learning-based algorithm is then presented to perform the decoding
of private information to facilitate language acquisition.

</details>


### [136] [A Dual-Attention Graph Network for fMRI Data Classification](https://arxiv.org/abs/2508.13328)
*Amirali Arbab,Zeinab Davarani,Mehran Safayani*

Main category: cs.LG

TL;DR: 本研究提出了一种结合动态图创建和时空注意力机制的新方法，用于自闭症谱系障碍(ASD)的fMRI诊断。该方法通过Transformer动态推断功能性大脑连接，并结合GCN和Transformer处理时变图，成功捕捉了局部交互和全局时间依赖性，在ABIDE数据集上取得了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 理解复杂神经活动动态对于神经科学领域的发展至关重要。目前的fMRI分类方法要么基于静态功能连接，要么无法全面捕捉时空关系。

Method: 本研究提出了一种新框架，利用动态图创建和时空注意力机制来诊断自闭症谱系障碍(ASD)。该方法通过基于Transformer的注意力机制动态推断每个时间间隔内的功能性大脑连接，从而使模型能够选择性地关注关键的大脑区域和时间段。通过构建时变图并使用图卷积网络(GCN)和Transformer进行处理，该方法能够同时捕捉局部交互和全局时间依赖性。

Result: 在ABIDE数据集的子集上评估，本研究提出的模型达到了63.2%的准确率和60.0%的AUC，优于静态图方法(例如GCN:51.8%)。

Conclusion: 本研究提出的新框架通过动态图创建和时空注意力机制，在自闭症谱系障碍(ASD)诊断方面取得了优于静态图方法的效果，验证了动态连接和时空上下文联合建模在fMRI分类中的有效性。

Abstract: Understanding the complex neural activity dynamics is crucial for the
development of the field of neuroscience. Although current functional MRI
classification approaches tend to be based on static functional connectivity or
cannot capture spatio-temporal relationships comprehensively, we present a new
framework that leverages dynamic graph creation and spatiotemporal attention
mechanisms for Autism Spectrum Disorder(ASD) diagnosis. The approach used in
this research dynamically infers functional brain connectivity in each time
interval using transformer-based attention mechanisms, enabling the model to
selectively focus on crucial brain regions and time segments. By constructing
time-varying graphs that are then processed with Graph Convolutional Networks
(GCNs) and transformers, our method successfully captures both localized
interactions and global temporal dependencies. Evaluated on the subset of ABIDE
dataset, our model achieves 63.2 accuracy and 60.0 AUC, outperforming static
graph-based approaches (e.g., GCN:51.8). This validates the efficacy of joint
modeling of dynamic connectivity and spatio-temporal context for fMRI
classification. The core novelty arises from (1) attention-driven dynamic graph
creation that learns temporal brain region interactions and (2) hierarchical
spatio-temporal feature fusion through GCNtransformer fusion.

</details>


### [137] [Trans-XFed: An Explainable Federated Learning for Supply Chain Credit Assessment](https://arxiv.org/abs/2508.13715)
*Jie Shi,Arno P. J. M. Siebes,Siamak Mehrkanoon*

Main category: cs.LG

TL;DR: 提出了一种名为Trans-XFed的联邦学习和可解释人工智能架构，用于供应链信用评估。该模型通过PBCS策略解决数据挑战，并利用FedProx、同态加密和Transformer编码器提供可解释的信用评估，在真实数据集上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决供应链信用评估中的隐私、信息孤岛、类别不平衡、Non-IID数据和模型可解释性等关键挑战。

Method: 提出了一种结合联邦学习和可解释人工智能技术的Trans-XFed架构，用于供应链信用评估。该模型采用基于性能的客户端选择策略（PBCS）来解决类别不平衡和Non-IID问题，并选择本地F1分数较高的客户端以实现更快的收敛。核心模型使用增强了同态加密的FedProx架构，并结合了Transformer编码器来提供学习到的特征洞察。此外，还采用了集成梯度可解释人工智能技术来提供决策洞察。

Result: 实验结果表明，Trans-XFed在提供准确信用评估的同时，保持了透明度和隐私，优于几个基线模型。

Conclusion: Trans-XFed在现实世界的供应链数据集上进行了实验评估，结果表明与几个基线相比，Trans-XFed能够提供准确的信用评估，同时保持透明度和隐私。

Abstract: This paper proposes a Trans-XFed architecture that combines federated
learning with explainable AI techniques for supply chain credit assessment. The
proposed model aims to address several key challenges, including privacy,
information silos, class imbalance, non-identically and independently
distributed (Non-IID) data, and model interpretability in supply chain credit
assessment. We introduce a performance-based client selection strategy (PBCS)
to tackle class imbalance and Non-IID problems. This strategy achieves faster
convergence by selecting clients with higher local F1 scores. The FedProx
architecture, enhanced with homomorphic encryption, is used as the core model,
and further incorporates a transformer encoder. The transformer encoder block
provides insights into the learned features. Additionally, we employ the
integrated gradient explainable AI technique to offer insights into
decision-making. We demonstrate the effectiveness of Trans-XFed through
experimental evaluations on real-world supply chain datasets. The obtained
results show its ability to deliver accurate credit assessments compared to
several baselines, while maintaining transparency and privacy.

</details>


### [138] [Dimension lower bounds for linear approaches to function approximation](https://arxiv.org/abs/2508.13346)
*Daniel Hsu*

Main category: cs.LG

TL;DR: Linear algebraic approach to dimension lower bounds for function approximation and kernel methods.


<details>
  <summary>Details</summary>
Motivation: To prove dimension lower bounds for linear methods that solve $L^2$ function approximation problems.

Method: Linear algebraic approach

Result: Provides sample size lower bounds for kernel methods.

Conclusion: This paper presents a linear algebraic approach to proving dimension lower bounds for linear methods that solve $L^2$ function approximation problems. The argument has appeared in the literature before for establishing lower bounds on Kolmogorov $n$-widths and is applied to give sample size lower bounds for kernel methods.

Abstract: This short note presents a linear algebraic approach to proving dimension
lower bounds for linear methods that solve $L^2$ function approximation
problems. The basic argument has appeared in the literature before (e.g.,
Barron, 1993) for establishing lower bounds on Kolmogorov $n$-widths. The
argument is applied to give sample size lower bounds for kernel methods.

</details>


### [139] [Counterfactual Probabilistic Diffusion with Expert Models](https://arxiv.org/abs/2508.13355)
*Wenhao Mu,Zhi Cao,Mehmed Uludag,Alexander Rodríguez*

Main category: cs.LG

TL;DR: A new method called ODE-Diff uses time series diffusion and guidance from expert models to predict counterfactual distributions, improving accuracy especially when data is scarce.


<details>
  <summary>Details</summary>
Motivation: Existing methods for predicting counterfactual distributions in complex dynamical systems often rely on point estimates or purely data-driven models, which are not robust under data scarcity. There is a need for methods that can reliably and interpretably perform causal inference.

Method: A time series diffusion-based framework named ODE-Diff that incorporates guidance from imperfect expert models by extracting high-level signals to serve as structured priors for generative modeling. It bridges mechanistic and data-driven approaches.

Result: The proposed ODE-Diff framework consistently outperforms strong baselines in both point prediction and distributional accuracy.

Conclusion: ODE-Diff surpasses existing strong baselines in both point prediction and distributional accuracy across various case studies.

Abstract: Predicting counterfactual distributions in complex dynamical systems is
essential for scientific modeling and decision-making in domains such as public
health and medicine. However, existing methods often rely on point estimates or
purely data-driven models, which tend to falter under data scarcity. We propose
a time series diffusion-based framework that incorporates guidance from
imperfect expert models by extracting high-level signals to serve as structured
priors for generative modeling. Our method, ODE-Diff, bridges mechanistic and
data-driven approaches, enabling more reliable and interpretable causal
inference. We evaluate ODE-Diff across semi-synthetic COVID-19 simulations,
synthetic pharmacological dynamics, and real-world case studies, demonstrating
that it consistently outperforms strong baselines in both point prediction and
distributional accuracy.

</details>


### [140] [MuFlex: A Scalable, Physics-based Platform for Multi-Building Flexibility Analysis and Coordination](https://arxiv.org/abs/2508.13532)
*Ziyan Wu,Ivan Korolija,Rui Tang*

Main category: cs.LG

TL;DR: MuFlex是一个用于多楼宇灵活性协调的开源仿真测试平台，它解决了现有平台在模型复杂性和通用性方面的不足。通过一个四楼宇案例研究，证明了该平台能够利用强化学习有效降低峰值负荷并保持舒适度。


<details>
  <summary>Details</summary>
Motivation: 现有楼宇领域仿真测试平台大多针对单一楼宇，且多采用简化的物理模型或数据驱动方法，难以完全捕捉物理细节和用于解释控制性能的中间变量。此外，这些平台通常限制输入、输出和模型格式，阻碍了其作为通用基准测试工具的应用。为解决这些问题，需要一个能够支持多楼宇协调的、更精细化的仿真测试平台。

Method: 开发了一个名为MuFlex的可扩展、开源的平台，用于多楼宇灵活性协调的基准测试和控制策略测试。该平台支持EnergyPlus楼宇模型间的同步信息交换，并遵循OpenAI Gym接口，实现了模块化、标准化的强化学习实现。

Result: 通过在MuFlex平台中协调四个办公楼的负荷灵活性，并使用Soft Actor-Critic算法进行控制，实验结果表明，成功将总峰值负荷降低到指定阈值以下，同时维持了室内环境质量。

Conclusion: MuFlex平台成功实现了跨四个办公楼的负荷聚合，并通过Soft Actor-Critic算法有效降低了峰值负荷，同时保持了室内环境质量。

Abstract: With the increasing penetration of renewable generation on the power grid,
maintaining system balance requires coordinated demand flexibility from
aggregations of buildings. Reinforcement learning (RL) has been widely explored
for building controls because of its model-free nature. Open-source simulation
testbeds are essential not only for training RL agents but also for fairly
benchmarking control strategies. However, most building-sector testbeds target
single buildings; multi-building platforms are relatively limited and typically
rely on simplified models (e.g., Resistance-Capacitance) or data-driven
approaches, which lack the ability to fully capture the physical intricacies
and intermediate variables necessary for interpreting control performance.
Moreover, these platforms often impose fixed inputs, outputs, and model
formats, restricting their applicability as benchmarking tools across diverse
control scenarios. To address these gaps, MuFlex, a scalable, open-source
platform for benchmarking and testing control strategies for multi-building
flexibility coordination, was developed in this study. MuFlex enables
synchronous information exchange across EnergyPlus building models and adheres
to the latest OpenAI Gym interface, providing a modular, standardized RL
implementation. The platform capabilities were demonstrated in a case study
coordinating demand flexibility across four office buildings using the Soft
Actor-Critic algorithm with carefully fine-tuned hyperparameters. The results
show that aggregating the four buildings flexibility reduced total peak demand
below a specified threshold while maintaining indoor environmental quality.

</details>


### [141] [Adaptive Conformal Prediction Intervals Over Trajectory Ensembles](https://arxiv.org/abs/2508.13362)
*Ruipu Li,Daniel Menacho,Alexander Rodríguez*

Main category: cs.LG

TL;DR: 提出一种基于共形预测的统一框架，将采样轨迹转化为校准预测区间，并生成更清晰、更自适应的不确定性估计。


<details>
  <summary>Details</summary>
Motivation: 未来的轨迹在自动驾驶、飓风预测和流行病建模等领域发挥着重要作用，但这些轨迹通常未经校准。

Method: 基于共形预测的统一框架，通过引入新颖的在线更新步骤和捕捉步骤间依赖性的优化步骤，将采样轨迹转化为具有理论覆盖保证的校准预测区间。

Result: 生成不连续的预测区间，自然地捕捉时间依赖性，并产生更清晰、更自适应的不确定性估计。

Conclusion: 该方法通过引入新颖的在线更新步骤和捕捉步骤间依赖性的优化步骤，可以生成不连续的预测区间，自然地捕捉时间依赖性，并产生更清晰、更自适应的不确定性估计。

Abstract: Future trajectories play an important role across domains such as autonomous
driving, hurricane forecasting, and epidemic modeling, where practitioners
commonly generate ensemble paths by sampling probabilistic models or leveraging
multiple autoregressive predictors. While these trajectories reflect inherent
uncertainty, they are typically uncalibrated. We propose a unified framework
based on conformal prediction that transforms sampled trajectories into
calibrated prediction intervals with theoretical coverage guarantees. By
introducing a novel online update step and an optimization step that captures
inter-step dependencies, our method can produce discontinuous prediction
intervals around each trajectory, naturally capture temporal dependencies, and
yield sharper, more adaptive uncertainty estimates.

</details>


### [142] [Batching-Aware Joint Model Onloading and Offloading for Hierarchical Multi-Task Inference](https://arxiv.org/abs/2508.13380)
*Seohyeon Cha,Kevin Chan,Gustavo de Veciana,Haris Vikalo*

Main category: cs.LG

TL;DR: J3O optimizes multi-task inference on edge devices by jointly deciding which models to deploy and how to route queries, outperforming existing methods in accuracy and efficiency.


<details>
  <summary>Details</summary>
Motivation: Existing frameworks primarily focus on single-task scenarios, but real-world applications like autonomous driving and augmented reality require concurrent execution of diverse tasks. There is a need for a unified framework to manage workload distribution for these multi-task requirements under resource constraints.

Method: J3O uses a mixed-integer programming formulation and an alternating optimization algorithm. It greedily selects models for onloading using Lagrangian-relaxed submodular optimization and determines offloading via constrained linear programming. It is extended to handle batching at the edge.

Result: J3O achieves over 97% of optimal accuracy while using less than 15% of the runtime of the optimal solver across multi-task benchmarks. It also accounts for batching at the edge, maintaining scalability under heterogeneous task loads.

Conclusion: J3O is an alternating algorithm that jointly optimizes model deployment and query routing for multi-task inference on edge devices, achieving high accuracy with significantly reduced runtime compared to optimal solvers.

Abstract: The growing demand for intelligent services on resource-constrained edge
devices has spurred the development of collaborative inference systems that
distribute workloads across end devices, edge servers, and the cloud. While
most existing frameworks focus on single-task, single-model scenarios, many
real-world applications (e.g., autonomous driving and augmented reality)
require concurrent execution of diverse tasks including detection,
segmentation, and depth estimation. In this work, we propose a unified
framework to jointly decide which multi-task models to deploy (onload) at
clients and edge servers, and how to route queries across the hierarchy
(offload) to maximize overall inference accuracy under memory, compute, and
communication constraints. We formulate this as a mixed-integer program and
introduce J3O (Joint Optimization of Onloading and Offloading), an alternating
algorithm that (i) greedily selects models to onload via Lagrangian-relaxed
submodular optimization and (ii) determines optimal offloading via constrained
linear programming. We further extend J3O to account for batching at the edge,
maintaining scalability under heterogeneous task loads. Experiments show J3O
consistently achieves over $97\%$ of the optimal accuracy while incurring less
than $15\%$ of the runtime required by the optimal solver across multi-task
benchmarks.

</details>


### [143] [Semi-Supervised Anomaly Detection Pipeline for SOZ Localization Using Ictal-Related Chirp](https://arxiv.org/abs/2508.13406)
*Nooshin Bahador,Milad Lankarany*

Main category: cs.LG

TL;DR: 该研究提出了一种基于LOF和加权空间度量的方法，用于将癫痫发作起始区（SOZ）与时频分析识别出的异常通道进行空间配准，发现该方法在手术成功的患者中效果最佳。


<details>
  <summary>Details</summary>
Motivation: 提出一个量化框架来评估临床定义的SOZ和通过时频分析识别出的统计异常通道之间的空间一致性。

Method: 该研究提出了一种量化框架，用于评估临床定义的癫痫发作起始区（SOZ）与通过啁啾事件时频分析识别出的统计异常通道之间的空间一致性。该方法包括两个步骤：1. 无监督异常值检测，使用局部异常值因子（LOF）分析和自适应邻域选择，基于啁啾特征（起始频率、偏移频率和时间持续时间）识别异常通道；2. 空间相关性分析，计算精确共现指标和加权指数相似度，并考虑半球一致性和电极邻近性。

Result: LOF方法（N邻居=20，污染度=0.2）能有效检测异常值，其中基于信道邻近性加权的信道索引匹配优于精确匹配。性能指标（精确率、召回率、F1）在无癫痫发作患者（索引精确率平均值：0.903）和手术成功的患者（索引精确率平均值：0.865）中最高，而失败病例的一致性较低（索引精确率平均值：0.460）。

Conclusion: 基于chirp的异常值检测结合加权空间度量，为SOZ定位提供了一种补充方法，尤其是在手术成功的患者中。

Abstract: This study presents a quantitative framework for evaluating the spatial
concordance between clinically defined seizure onset zones (SOZs) and
statistically anomalous channels identified through time-frequency analysis of
chirp events. The proposed pipeline employs a two-step methodology: (1)
Unsupervised Outlier Detection, where Local Outlier Factor (LOF) analysis with
adaptive neighborhood selection identifies anomalous channels based on
spectro-temporal features of chirp (Onset frequency, offset frequency, and
temporal duration); and (2) Spatial Correlation Analysis, which computes both
exact co-occurrence metrics and weighted index similarity, incorporating
hemispheric congruence and electrode proximity. Key findings demonstrate that
the LOF-based approach (N neighbors=20, contamination=0.2) effectively detects
outliers, with index matching (weighted by channel proximity) outperforming
exact matching in SOZ localization. Performance metrics (precision, recall, F1)
were highest for seizure-free patients (Index Precision mean: 0.903) and those
with successful surgical outcomes (Index Precision mean: 0.865), whereas
failure cases exhibited lower concordance (Index Precision mean: 0.460). The
key takeaway is that chirp-based outlier detection, combined with weighted
spatial metrics, provides a complementary method for SOZ localization,
particularly in patients with successful surgical outcomes.

</details>


### [144] [NovoMolGen: Rethinking Molecular Language Model Pretraining](https://arxiv.org/abs/2508.13408)
*Kamran Chitsaz,Roshan Balaji,Quentin Fournier,Nirav Pravinbhai Bhatt,Sarath Chandar*

Main category: cs.LG

TL;DR: 探索了语言模型实践对分子生成的影响，并提出了 NovoMolGen，这是一个强大的新模型，在分子生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在解决从头设计具有所需属性组合的分子的挑战，这些分子需要对巨大的化学空间进行有效探索，并理解标准语言建模实践（如文本表示、标记化策略、模型大小和数据集规模）对分子生成性能的影响。

Method: 通过引入 NovoMolGen（一个基于 Transformer 的基础模型家族，在 15 亿个分子上进行预训练，用于从头分子生成）来系统地研究这些关键方面。

Result: 通过广泛的实证分析，发现预训练期间的性能指标与实际的下游性能之间存在较弱的相关性，揭示了分子和通用自然语言处理训练动力学之间重要的区别。

Conclusion: NovoMolGen 建立在 15 亿个分子上进行预训练，并在无约束和目标导向的分子生成任务中均取得了新的最先进结果，显著优于之前的 Mol-LLMs 和专门的生成模型，为推进高效和有效的分子建模策略提供了坚实的基础。

Abstract: Designing de-novo molecules with desired property profiles requires efficient
exploration of the vast chemical space ranging from $10^{23}$ to $10^{60}$
possible synthesizable candidates. While various deep generative models have
been developed to design small molecules using diverse input representations,
Molecular Large Language Models (Mol-LLMs) based on string representations have
emerged as a scalable approach capable of exploring billions of molecules.
However, there remains limited understanding regarding how standard language
modeling practices such as textual representations, tokenization strategies,
model size, and dataset scale impact molecular generation performance. In this
work, we systematically investigate these critical aspects by introducing
NovoMolGen, a family of transformer-based foundation models pretrained on 1.5
billion molecules for de-novo molecule generation. Through extensive empirical
analyses, we identify a weak correlation between performance metrics measured
during pretraining and actual downstream performance, revealing important
distinctions between molecular and general NLP training dynamics. NovoMolGen
establishes new state-of-the-art results, substantially outperforming prior
Mol-LLMs and specialized generative models in both unconstrained and
goal-directed molecular generation tasks, thus providing a robust foundation
for advancing efficient and effective molecular modeling strategies.

</details>


### [145] [Decentralized Contextual Bandits with Network Adaptivity](https://arxiv.org/abs/2508.13411)
*Chuyun Deng,Huiwen Jia*

Main category: cs.LG

TL;DR: 提出 NetLinUCB 和 Net-SGD-UCB 两种算法，通过自适应信息共享来解决网络化环境中的上下文线性老虎机问题，降低了学习复杂性，并在模拟中表现优于基准。


<details>
  <summary>Details</summary>
Motivation: 解决上下文线性老虎机在网络化环境中信息部分共享的问题。经典算法要么假设完全中心化数据，要么假设完全隔离的学习者，而忽略了部分共享信息的中间情况。

Method: 提出 NetLinUCB 和 Net-SGD-UCB 两种网络感知型上限置信算法 (UCB)，通过自适应地共享信息和动态更新的网络权重来解决上下文线性老虎机问题。该方法将学习分解为全局和局部组件，允许智能体在不同步的情况下受益于共享结构。

Result: 所提出的算法具有比完全中心化设置更低的通信成本，并且在低噪声和细粒度异质性条件下，NetLinUCB 表现更优；在高维、高方差上下文条件下，Net-SGD-UCB 表现更鲁棒。

Conclusion: NetLinUCB and Net-SGD-UCB 算法在模拟定价环境中优于标准基准，并且可以减小与共享结构相关的学习复杂性，将学习复杂性从 O(N) 降低到 O(sqrt(N))。

Abstract: We consider contextual linear bandits over networks, a class of sequential
decision-making problems where learning occurs simultaneously across multiple
locations and the reward distributions share structural similarities while also
exhibiting local differences. While classical contextual bandits assume either
fully centralized data or entirely isolated learners, much remains unexplored
in networked environments when information is partially shared. In this paper,
we address this gap by developing two network-aware Upper Confidence Bound
(UCB) algorithms, NetLinUCB and Net-SGD-UCB, which enable adaptive information
sharing guided by dynamically updated network weights. Our approach decompose
learning into global and local components and as a result allow agents to
benefit from shared structure without full synchronization. Both algorithms
incur lighter communication costs compared to a fully centralized setting as
agents only share computed summaries regarding the homogeneous features. We
establish regret bounds showing that our methods reduce the learning complexity
associated with the shared structure from $O(N)$ to sublinear $O(\sqrt{N})$,
where $N$ is the size of the network. The two algorithms reveal complementary
strengths: NetLinUCB excels in low-noise regimes with fine-grained
heterogeneity, while Net-SGD-UCB is robust to high-dimensional, high-variance
contexts. We further demonstrate the effectiveness of our methods across
simulated pricing environments compared to standard benchmarks.

</details>


### [146] [MAVIS: Multi-Objective Alignment via Value-Guided Inference-Time Search](https://arxiv.org/abs/2508.13415)
*Jeremy Carleton,Debajoy Mukherjee,Srinivas Shakkottai,Dileep Kalathil*

Main category: cs.LG

TL;DR: MAVIS 是一个创新的 LLM 对齐框架，可在推理时根据用户需求动态调整模型行为，以平衡多个目标，无需重新训练模型，且效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决在多目标场景下，LLM 需要平衡多个相互冲突的目标（如有用性、无害性或幽默感），并且现有方法（为每个目标或偏好配置微调模型）计算成本高昂且缺乏灵活性。

Method: MAVIS（Multi-Objective Alignment via Value-Guided Inference-Time Search）是一个轻量级的推理时对齐框架。它通过训练一组小的价值模型（每个模型对应一个不同的目标），并在推理时使用用户指定的权重组合这些价值模型来生成一个“倾斜函数”，从而动态调整 LLM 的行为，而无需修改基础模型的权重。

Result: MAVIS 在各种场景下均表现出色，能够实现对 LLM 行为的动态控制，并能根据用户指定的权重进行目标权衡，其表现优于传统的微调方法。

Conclusion: MAVIS 框架在实践中证明了其优越性，能够超越单独为每个目标进行微调的模型，并能与针对用户特定偏好进行理想化微调的模型相媲美。

Abstract: Large Language Models (LLMs) are increasingly deployed across diverse
applications that demand balancing multiple, often conflicting, objectives --
such as helpfulness, harmlessness, or humor. Aligning outputs to user-specific
preferences in such multi-objective settings typically requires fine-tuning
models for each objective or preference configuration, which is computationally
expensive and inflexible. We introduce MAVIS -- Multi-Objective Alignment via
Value-Guided Inference-Time Search -- a lightweight inference-time alignment
framework that enables dynamic control over LLM behavior without modifying the
base model's weights. MAVIS trains a set of small value models, each
corresponding to a distinct objective. At inference time, these value models
are combined using user-specified weights to produce a tilting function that
adjusts the base model's output distribution toward desired trade-offs. The
value models are trained using a simple iterative algorithm that ensures
monotonic improvement of the KL-regularized policy. We show empirically that
MAVIS outperforms baselines that fine-tune per-objective models and combine
them post hoc, and even approaches the performance of the idealized setting
where models are fine-tuned for a user's exact preferences.

</details>


### [147] [EventTSF: Event-Aware Non-Stationary Time Series Forecasting](https://arxiv.org/abs/2508.13434)
*Yunfeng Ge,Ming Jin,Yiji Zhao,Hongyan Li,Bo Du,Chang Xu,Shirui Pan*

Main category: cs.LG

TL;DR: EventTSF是一个创新的框架，可以处理时间序列预测中多模态数据（如文本事件）的挑战。通过使用自回归扩散和流匹配，它能够更好地同步和整合时间序列数据和文本事件，即使在存在不确定性和不匹配的情况下也能提高预测准确性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 时间序列预测在能源和交通等关键领域起着至关重要的作用，而非平稳动态与文本等其他模态中的事件密不可分。然而，将基于自然语言的外部事件纳入非平稳预测仍未得到充分探索，因为大多数方法仍然依赖单一模态，导致上下文知识有限和模型表现不佳。时间序列预测在能源和交通等关键领域起着至关重要的作用，而非平稳动态与文本等其他模态中的事件密不可分。然而，将基于自然语言的外部事件纳入非平稳预测仍未得到充分探索，因为大多数方法仍然依赖单一模态，导致上下文知识有限和模型表现不佳。使时间序列和文本数据之间实现细粒度的多模态交互受到三个基本问题的挑战：(1) 时间变化的离散文本事件和连续时间序列之间实现细粒度同步的困难；(2) 由文本语义引起的固有时间不确定性；(3) 文本事件嵌入和多分辨率时间模式之间不匹配。

Method: EventTSF是一个自回归生成框架，通过自回归扩散和流匹配来整合历史时间序列和文本事件，以进行后续预测。它使用流匹配时间步长来适应事件语义信号，以处理事件引起的延迟，并使用多模态U型扩散 transformer来融合不同分辨率的时间和文本模态。

Result: EventTSF在8个合成和真实世界的数据集上进行了广泛的实验，在各种事件感知非平稳时间序列预测场景中，其表现优于12个基线，预测准确率提高了10.7%，训练效率提高了1.13倍。

Conclusion: EventTSF在8个合成和真实世界的数据集上进行了广泛的实验，在各种事件感知非平稳时间序列预测场景中，其表现优于12个基线，预测准确率提高了10.7%，训练效率提高了1.13倍。

Abstract: Time series forecasting plays a vital role in critical domains like energy
and transportation, where non-stationary dynamics are deeply intertwined with
events in other modalities such as texts. However, incorporating natural
language-based external events to improve non-stationary forecasting remains
largely unexplored, as most approaches still rely on a single modality,
resulting in limited contextual knowledge and model underperformance. Enabling
fine-grained multimodal interactions between temporal and textual data is
challenged by three fundamental issues: (1) the difficulty of fine-grained
synchronization between time-varying discrete textual events and continuous
time series; (2) the inherent temporal uncertainty introduced by textual
semantics; and (3) the misalignment between textual event embeddings and
multi-resolution temporal patterns. In this work, we address these challenges
by introducing event-aware non-stationary time series forecasting (EventTSF),
an autoregressive generation framework that integrates historical time series
with textual events to make subsequent forecasts. Specifically, EventTSF uses
autoregressive diffusion with flow matching at each step to capture nuanced
temporal-event interactions. To handle event-induced uncertainty, flow matching
timesteps are adaptively controlled according to event semantic signals. The
underlying denoiser employs a multimodal U-shaped diffusion transformer that
efficiently fuses temporal and textual modalities across different resolutions.
Extensive experiments on 8 synthetic and real-world datasets show that EventTSF
outperforms 12 baselines across diverse event-aware non-stationary time series
forecasting scenarios, achieving substantial improvements of 10.7% higher
forecasting accuracy and $1.13\times$ faster training efficiency.

</details>


### [148] [SVDformer: Direction-Aware Spectral Graph Embedding Learning via SVD and Transformer](https://arxiv.org/abs/2508.13435)
*Jiayu Fang,Zhiqi Shao,S T Boris Choy,Junbin Gao*

Main category: cs.LG

TL;DR: SVDformer是一个创新的框架，它结合了SVD和Transformer架构，用于方向感知的图表示学习。它通过优化的奇异值嵌入和方向性特征传播，在有向图任务上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的有向图神经网络（GNNs）由于其各向同性的聚合机制和局部化的滤波机制，在联合捕获方向语义和全局结构模式方面存在困难。本研究旨在解决这一局限性。

Method: SVDformer首先通过多头自注意力机制优化奇异值嵌入，自适应地增强关键谱分量并抑制高频噪声，实现了可学习的低通/高通图滤波，无需谱核。然后，SVDformer将奇异向量视为方向投影基，奇异值视为缩放因子，并通过Transformer建模入边/出边模式之间通过注意力权重实现的多尺度交互，在特征传播中明确保留了边方向性。

Result: 在六个有向图基准测试上的大量实验表明，SVDformer在节点分类任务上始终优于最先进的GNN和方向感知基线。

Conclusion: SVDformer通过结合SVD和Transformer架构，成功地实现了方向感知的图表示学习，并在节点分类任务上超越了现有最先进的GNN和方向感知基线，为有向图上的学习表示树立了新范例。

Abstract: Directed graphs are widely used to model asymmetric relationships in
real-world systems. However, existing directed graph neural networks often
struggle to jointly capture directional semantics and global structural
patterns due to their isotropic aggregation mechanisms and localized filtering
mechanisms. To address this limitation, this paper proposes SVDformer, a novel
framework that synergizes SVD and Transformer architecture for direction-aware
graph representation learning. SVDformer first refines singular value
embeddings through multi-head self-attention, adaptively enhancing critical
spectral components while suppressing high-frequency noise. This enables
learnable low-pass/high-pass graph filtering without requiring spectral
kernels. Furthermore, by treating singular vectors as directional projection
bases and singular values as scaling factors, SVDformer uses the Transformer to
model multi-scale interactions between incoming/outgoing edge patterns through
attention weights, thereby explicitly preserving edge directionality during
feature propagation. Extensive experiments on six directed graph benchmarks
demonstrate that SVDformer consistently outperforms state-of-the-art GNNs and
direction-aware baselines on node classification tasks, establishing a new
paradigm for learning representations on directed graphs.

</details>


### [149] [ASAP: Unsupervised Post-training with Label Distribution Shift Adaptive Learning Rate](https://arxiv.org/abs/2508.13445)
*Heewon Park,Mugon Joe,Miru Kim,Minhae Kwon*

Main category: cs.LG

TL;DR: ASAP 是一种通过动态调整学习速率来解决在线标签偏移问题的无监督模型适应方法，仅需先前 softmax 输出即可实现快速适应，并在实验中显示出准确性和效率的提升。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的应用中，机器学习模型会遇到在线标签偏移问题，此时标签分布会随着时间而改变。有效的适应需要仔细选择学习速率：过低会减慢适应速度，过高则会导致不稳定性。

Method: ASAP（自适应偏移感知训练后）通过计算当前和先前未标记输​​出之间的余弦距离，并将其映射到有界范围内，从而动态调整学习速率。

Result: ASAP 能够持续提高准确性和效率，使其在无监督模型适应中具有实用性。

Conclusion: ASAP 是一种无需标签、模型集成或历史输入，仅使用先前 softmax 输出即可实现快速、轻量级适应的在线标签偏移解决方案，在多个数据集和偏移场景的实验表明，ASAP 能够持续提高准确性和效率，适用于无监督模型适应。

Abstract: In real-world applications, machine learning models face online label shift,
where label distributions change over time. Effective adaptation requires
careful learning rate selection: too low slows adaptation and too high causes
instability. We propose ASAP (Adaptive Shift Aware Post-training), which
dynamically adjusts the learning rate by computing the cosine distance between
current and previous unlabeled outputs and mapping it within a bounded range.
ASAP requires no labels, model ensembles, or past inputs, using only the
previous softmax output for fast, lightweight adaptation. Experiments across
multiple datasets and shift scenarios show ASAP consistently improves accuracy
and efficiency, making it practical for unsupervised model adaptation.

</details>


### [150] [Hierarchy-Consistent Learning and Adaptive Loss Balancing for Hierarchical Multi-Label Classification](https://arxiv.org/abs/2508.13452)
*Ruobing Jiang,Mengzhe Liu,Haobing Liu,Yanwei Yu*

Main category: cs.LG

TL;DR: 提出了一种名为HCAL的分类器，通过结合多任务学习、原型对比学习和自适应任务加权来解决分层多标签分类中的挑战，提高了准确性并减少了层次结构违规。


<details>
  <summary>Details</summary>
Motivation: 为了解决分层多标签分类（HMC）在保持结构一致性和平衡多任务学习（MTL）中的损失权重方面面临的关键挑战。

Method: 提出了一种基于多任务学习（MTL）、原型对比学习和自适应任务加权机制的分类器HCAL。该方法包括显式建模标签的原型以及从子类到父类的特征聚合，以实现语义一致性。此外，还提出了一种自适应损失加权机制，通过监控特定任务的收敛率来动态分配优化资源，并引入原型扰动机制通过注入受控噪声来扩展决策边界。

Result: HCAL分类器在语义一致性、自适应损失加权和鲁棒性方面具有优势，并提出了用于评估层次结构一致性和泛化性的新指标HVR。实验证明该分类器优于基线模型。

Conclusion: 该分类器在三个数据集上的广泛实验证明，与基线模型相比，该分类器具有更高的分类准确性和更低的层次结构违规率。

Abstract: Hierarchical Multi-Label Classification (HMC) faces critical challenges in
maintaining structural consistency and balancing loss weighting in Multi-Task
Learning (MTL). In order to address these issues, we propose a classifier
called HCAL based on MTL integrated with prototype contrastive learning and
adaptive task-weighting mechanisms. The most significant advantage of our
classifier is semantic consistency including both prototype with explicitly
modeling label and feature aggregation from child classes to parent classes.
The other important advantage is an adaptive loss-weighting mechanism that
dynamically allocates optimization resources by monitoring task-specific
convergence rates. It effectively resolves the "one-strong-many-weak"
optimization bias inherent in traditional MTL approaches. To further enhance
robustness, a prototype perturbation mechanism is formulated by injecting
controlled noise into prototype to expand decision boundaries. Additionally, we
formalize a quantitative metric called Hierarchical Violation Rate (HVR) as to
evaluate hierarchical consistency and generalization. Extensive experiments
across three datasets demonstrate both the higher classification accuracy and
reduced hierarchical violation rate of the proposed classifier over baseline
models.

</details>


### [151] [Classifying Clinical Outcome of Epilepsy Patients with Ictal Chirp Embeddings](https://arxiv.org/abs/2508.13476)
*Nooshin Bahador,Milad Lankarany*

Main category: cs.LG

TL;DR: 本研究提出一种利用t-SNE技术对chirp特征进行可解释可视化的方法，结合多种分类器和SHAP分析，有效实现了临床病例的区分和最佳病例的识别，准确率最高达88.8%。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机是为不同结果情景下的chirp特征提供可解释的可视化，以支持临床分层和决策。通过利用t-SNE技术，研究旨在揭示数据中的潜在结构，并理解特定chirp属性如何影响分类和聚类，从而为临床应用提供更深入的洞察。

Method: 本研究提出了一种利用t-分布随机邻域嵌入（t-SNE）技术的可解释可视化流程。该流程首先处理包含基于chirp的时间、光谱和频率指标的数据集。接着，应用t-SNE算法，在优化相似性的同时保持局部邻域关系，以解决数据拥挤问题。随后，在二维t-SNE嵌入上构建了三个分类任务：区分临床成功与失败/无切除；区分高难度与低难度病例；识别最佳病例（定义为临床难度最小的成功案例）。最后，研究采用了随机森林、支持向量机、逻辑回归和k近邻四种分类器，并使用分层5折交叉验证进行训练和评估，同时通过SHAP解释生成敏感性图以分析特征对t-SNE坐标预测的影响。

Result: 本研究通过t-SNE可视化和分类任务，在区分临床成功/失败、高/低难度病例以及识别最佳病例方面取得了显著成果。随机森林和kNN分类器在检测最佳病例（成功且临床难度最小）时表现最佳，准确率高达88.8%。SHAP解释生成的特征影响敏感性图成功揭示了特定chirp属性在嵌入空间中的局部重要性，阐明了这些属性如何驱动区域聚类和类别分离。

Conclusion: 本研究展示了一个利用t-SNE进行可解释可视化的流程，用于分析不同结果情景下的chirp特征。该方法通过t-SNE保留了局部邻域关系，并通过基于学生t分布的相似性优化解决了拥挤问题。在三个分类任务（区分临床成功/失败、区分高/低难度病例、识别最佳病例）中，随机森林和kNN分类器表现出优越性能，在最佳病例检测中准确率高达88.8%。此外，通过SHAP解释生成的特征影响敏感性图揭示了特定chirp属性在嵌入空间中的驱动作用，为临床分层和决策支持提供了可解释的嵌入和局部特征归因的潜力。

Abstract: This study presents a pipeline leveraging t-Distributed Stochastic Neighbor
Embedding (t-SNE) for interpretable visualizations of chirp features across
diverse outcome scenarios. The dataset, comprising chirp-based temporal,
spectral, and frequency metrics. Using t-SNE, local neighborhood relationships
were preserved while addressing the crowding problem through Student
t-distribution-based similarity optimization. Three classification tasks were
formulated on the 2D t-SNE embeddings: (1) distinguishing clinical success from
failure/no-resection, (2) separating high-difficulty from low-difficulty cases,
and (3) identifying optimal cases, defined as successful outcomes with minimal
clinical difficulty. Four classifiers, namely, Random Forests, Support Vector
Machines, Logistic Regression, and k-Nearest Neighbors, were trained and
evaluated using stratified 5-fold cross-validation. Across tasks, the Random
Forest and k-NN classifiers demonstrated superior performance, achieving up to
88.8% accuracy in optimal case detection (successful outcomes with minimal
clinical difficulty). Additionally, feature influence sensitivity maps were
generated using SHAP explanations applied to model predicting t-SNE
coordinates, revealing spatially localized feature importance within the
embedding space. These maps highlighted how specific chirp attributes drive
regional clustering and class separation, offering insights into the latent
structure of the data. The integrated framework showcases the potential of
interpretable embeddings and local feature attribution for clinical
stratification and decision support.

</details>


### [152] [DyMixOp: Guiding Neural Operator Design for PDEs from a Complex Dynamics Perspective with Local-Global-Mixing](https://arxiv.org/abs/2508.13490)
*Pengyu Lai,Yixiao Chen,Hui Xu*

Main category: cs.LG

TL;DR: DyMixOp是一个基于惯性流形理论和局部-全局混合（LGM）变换的新型神经算子框架，用于解决非线性PDE的近似问题，在对流主导的情况下表现尤为出色，显著降低了预测误差。


<details>
  <summary>Details</summary>
Motivation: 解决使用神经网络逼近非线性偏微分方程（PDE）时的主要挑战，特别是处理不可线性化动力学或需要无限维空间进行线性化的情况。

Method: DyMixOp是一个新的神经算子框架，它结合了复动力系统和惯性流形理论的见解，将无限维非线性PDE动力学转化为有限维潜在空间。该框架的关键创新是局部-全局混合（LGM）变换，并采用了一种动力学信息架构，连接多个LGM层来近似线性和非线性动力学。

Result: DyMixOp在各种PDE基准测试中取得了最先进的性能，显著降低了预测误差，特别是在对流主导的情况下，误差降低了86.7%。同时，该框架保持了计算效率和可扩展性。

Conclusion: DyMixOp框架在处理非线性偏微分方程（PDE）方面取得了最先进的性能，尤其在对流主导的情况下，预测误差显著降低（高达86.7%），同时保持了计算效率和可扩展性。

Abstract: A primary challenge in using neural networks to approximate nonlinear
dynamical systems governed by partial differential equations (PDEs) is
transforming these systems into a suitable format, especially when dealing with
non-linearizable dynamics or the need for infinite-dimensional spaces for
linearization. This paper introduces DyMixOp, a novel neural operator framework
for PDEs that integrates insights from complex dynamical systems to address
this challenge. Grounded in inertial manifold theory, DyMixOp transforms
infinite-dimensional nonlinear PDE dynamics into a finite-dimensional latent
space, establishing a structured foundation that maintains essential nonlinear
interactions and enhances physical interpretability. A key innovation is the
Local-Global-Mixing (LGM) transformation, inspired by convection dynamics in
turbulence. This transformation effectively captures both fine-scale details
and nonlinear interactions, while mitigating spectral bias commonly found in
existing neural operators. The framework is further strengthened by a
dynamics-informed architecture that connects multiple LGM layers to approximate
linear and nonlinear dynamics, reflecting the temporal evolution of dynamical
systems. Experimental results across diverse PDE benchmarks demonstrate that
DyMixOp achieves state-of-the-art performance, significantly reducing
prediction errors, particularly in convection-dominated scenarios reaching up
to 86.7\%, while maintaining computational efficiency and scalability.

</details>


### [153] [Uncertainty Tube Visualization of Particle Trajectories](https://arxiv.org/abs/2508.13505)
*Jixian Li,Timbwaoga Aime Judicael Ouermi,Mengjiao Han,Chris R. Johnson*

Main category: cs.LG

TL;DR: 提出不确定性管可视化方法，有效量化和展示神经网络预测粒子轨迹的不确定性。


<details>
  <summary>Details</summary>
Motivation: 解决在粒子轨迹预测中有效量化和可视化不确定性这一挑战，以提高神经网络模型在需要高度可信度的应用中的可靠性。

Method: 提出了一种基于超椭圆管的不确定性管可视化方法，并结合了深度集成、蒙特卡洛Dropout和随机权重平均-高斯等不确定性量化技术。

Result: 展示了不确定性管在合成和模拟数据集上的实际应用效果，证明了其在捕获和传达非对称不确定性方面的有效性。

Conclusion: 该研究引入了一种新颖且计算效率高的可视化方法“不确定性管”，用于表示神经网络预测的粒子路径中的不确定性，特别关注于捕获和传达非对称不确定性。

Abstract: Predicting particle trajectories with neural networks (NNs) has substantially
enhanced many scientific and engineering domains. However, effectively
quantifying and visualizing the inherent uncertainty in predictions remains
challenging. Without an understanding of the uncertainty, the reliability of NN
models in applications where trustworthiness is paramount is significantly
compromised. This paper introduces the uncertainty tube, a novel,
computationally efficient visualization method designed to represent this
uncertainty in NN-derived particle paths. Our key innovation is the design and
implementation of a superelliptical tube that accurately captures and
intuitively conveys nonsymmetric uncertainty. By integrating well-established
uncertainty quantification techniques, such as Deep Ensembles, Monte Carlo
Dropout (MC Dropout), and Stochastic Weight Averaging-Gaussian (SWAG), we
demonstrate the practical utility of the uncertainty tube, showcasing its
application on both synthetic and simulation datasets.

</details>


### [154] [Explainability of Algorithms](https://arxiv.org/abs/2508.13529)
*Andrés Páez*

Main category: cs.LG

TL;DR: AI can be opaque due to technical complexity or proprietary reasons. While methods like XAI aim to explain AI, they still have challenges.


<details>
  <summary>Details</summary>
Motivation: To address the ethical concerns arising from the opaqueness of complex machine learning algorithms and explore solutions.

Method: Examining two types of AI opaqueness (technical complexity and intentional hiding of proprietary information) and their ethical implications, then exploring various explanatory methods developed in computer science to overcome technical opaqueness.

Result: Identified two types of AI opaqueness and their ethical implications, and highlighted the challenges that XAI still faces.

Conclusion: Explainable AI (XAI) still faces numerous challenges despite the development of various explanatory methods to overcome AI's technical opaqueness.

Abstract: The opaqueness of many complex machine learning algorithms is often mentioned
as one of the main obstacles to the ethical development of artificial
intelligence (AI). But what does it mean for an algorithm to be opaque? Highly
complex algorithms such as artificial neural networks process enormous volumes
of data in parallel along multiple hidden layers of interconnected nodes,
rendering their inner workings epistemically inaccessible to any human being,
including their designers and developers; they are "black boxes" for all their
stakeholders. But opaqueness is not always the inevitable result of technical
complexity. Sometimes, the way an algorithm works is intentionally hidden from
view for proprietary reasons, especially in commercial automated decision
systems, creating an entirely different type of opaqueness. In the first part
of the chapter, we will examine these two ways of understanding opacity and the
ethical implications that stem from each of them. In the second part, we
explore the different explanatory methods that have been developed in computer
science to overcome an AI system's technical opaqueness. As the analysis shows,
explainable AI (XAI) still faces numerous challenges.

</details>


### [155] [CALYPSO: Forecasting and Analyzing MRSA Infection Patterns with Community and Healthcare Transmission Dynamics](https://arxiv.org/abs/2508.13548)
*Rituparna Datta,Jiaming Cui,Gregory R. Madden,Anil Vullikanti*

Main category: cs.LG

TL;DR: CALYPSO是一个混合框架，结合了神经网络和机制化模型，用于预测MRSA传播，相比现有方法提高了准确性，并能识别高风险区域和制定成本效益的控制策略。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解MRSA风险、评估干预措施以及预测MRSA发生率，而现有的预测模型存在流行病学可解释性差和性能有限的问题，机制化流行病模型则难以校准且难以整合多样化数据集。

Method: CALYPSO框架，一个混合框架，集成了神经网络和机制化元群体模型，利用患者级别的保险理赔、通勤数据和医疗转移模式来学习控制MRSA传播的区域和时间特定参数。

Result: CALYPSO框架提高了全州预测性能超过4.5%，同时识别出高风险区域和分配感染预防资源的成本效益策略。

Conclusion: CALYPSO框架通过整合神经网络和机制化元群体模型，能够准确、可解释地预测MRSA传播，并支持对感染控制政策的反事实分析。

Abstract: Methicillin-resistant Staphylococcus aureus (MRSA) is a critical public
health threat within hospitals as well as long-term care facilities. Better
understanding of MRSA risks, evaluation of interventions and forecasting MRSA
rates are important public health problems. Existing forecasting models rely on
statistical or neural network approaches, which lack epidemiological
interpretability, and have limited performance. Mechanistic epidemic models are
difficult to calibrate and limited in incorporating diverse datasets. We
present CALYPSO, a hybrid framework that integrates neural networks with
mechanistic metapopulation models to capture the spread dynamics of infectious
diseases (i.e., MRSA) across healthcare and community settings. Our model
leverages patient-level insurance claims, commuting data, and healthcare
transfer patterns to learn region- and time-specific parameters governing MRSA
spread. This enables accurate, interpretable forecasts at multiple spatial
resolutions (county, healthcare facility, region, state) and supports
counterfactual analyses of infection control policies and outbreak risks. We
also show that CALYPSO improves statewide forecasting performance by over 4.5%
compared to machine learning baselines, while also identifying high-risk
regions and cost-effective strategies for allocating infection prevention
resources.

</details>


### [156] [Collapsing ROC approach for risk prediction research on both common and rare variants](https://arxiv.org/abs/2508.13552)
*Changshuai Wei,Qing Lu*

Main category: cs.LG

TL;DR: 该研究提出了一种新的风险预测方法（CROC），该方法结合了常见和罕见变异，并在实验中显示出比仅使用常见变异或先前FROC方法更高的预测准确性，尤其是在处理罕见变异时。


<details>
  <summary>Details</summary>
Motivation: 现有的基于常见遗传变异的风险预测研究准确性不足以用于临床。由于大多数罕见变异尚未被研究，未来的疾病风险预测研究应转向包含常见和罕见变异的综合策略。

Method: 提出了一种包含常见和罕见变异的风险预测方法，称为CROC（collapsing receiver operating characteristic），它是对先前FROC（forward ROC）方法的扩展，增加了处理罕见变异的步骤。

Result: 在533个单核苷酸多态性（SNPs）的数据集上进行评估，包含所有SNPs的模型（AUC = 0.605）比仅包含常见变异的模型（AUC = 0.585）具有更高的准确性。当数据中常见变异数量减少时，CROC方法的准确性优于FROC方法。在仅包含罕见变异的情况下，CROC方法的AUC值为0.603，而FROC方法的AUC值为0.524。

Conclusion: 目前的研究表明，包含罕见变异的风险预测模型比仅包含常见变异的模型更具预测能力，并且在仅包含罕见变异的极端情况下，CROC方法比FROC方法表现出更高的准确性。

Abstract: Risk prediction that capitalizes on emerging genetic findings holds great
promise for improving public health and clinical care. However, recent risk
prediction research has shown that predictive tests formed on existing common
genetic loci, including those from genome-wide association studies, have lacked
sufficient accuracy for clinical use. Because most rare variants on the genome
have not yet been studied for their role in risk prediction, future disease
prediction discoveries should shift toward a more comprehensive risk prediction
strategy that takes into account both common and rare variants. We are
proposing a collapsing receiver operating characteristic CROC approach for risk
prediction research on both common and rare variants. The new approach is an
extension of a previously developed forward ROC FROC approach, with additional
procedures for handling rare variants. The approach was evaluated through the
use of 533 single-nucleotide polymorphisms SNPs in 37 candidate genes from the
Genetic Analysis Workshop 17 mini-exome data set. We found that a prediction
model built on all SNPs gained more accuracy AUC = 0.605 than one built on
common variants alone AUC = 0.585. We further evaluated the performance of two
approaches by gradually reducing the number of common variants in the analysis.
We found that the CROC method attained more accuracy than the FROC method when
the number of common variants in the data decreased. In an extreme scenario,
when there are only rare variants in the data, the CROC reached an AUC value of
0.603, whereas the FROC had an AUC value of 0.524.

</details>


### [157] [Prediction of Hospital Associated Infections During Continuous Hospital Stays](https://arxiv.org/abs/2508.13561)
*Rituparna Datta,Methun Kamruzzaman,Eili Y. Klein,Gregory R Madden,Xinwei Deng,Anil Vullikanti,Parantapa Bhattacharya*

Main category: cs.LG

TL;DR: 提出了一种名为GenHAI的新型生成概率模型，用于模拟和预测医院中的MRSA感染情况，以帮助降低风险。


<details>
  <summary>Details</summary>
Motivation: MRSA对住院患者构成严重威胁，模型旨在帮助减轻这种风险。

Method: 提出了一种新颖的生成概率模型GenHAI，用于模拟单个住院期间MRSA检测结果序列。

Result: 通过与判别式和生成式机器学习模型在两个真实世界数据集上的比较，证明了该模型的有效性。

Conclusion: 该模型可以帮助医院管理人员回答有关如何降低MRSA感染风险的各种问题。

Abstract: The US Centers for Disease Control and Prevention (CDC), in 2019, designated
Methicillin-resistant Staphylococcus aureus (MRSA) as a serious antimicrobial
resistance threat. The risk of acquiring MRSA and suffering life-threatening
consequences due to it remains especially high for hospitalized patients due to
a unique combination of factors, including: co-morbid conditions, immuno
suppression, antibiotic use, and risk of contact with contaminated hospital
workers and equipment. In this paper, we present a novel generative
probabilistic model, GenHAI, for modeling sequences of MRSA test results
outcomes for patients during a single hospitalization. This model can be used
to answer many important questions from the perspectives of hospital
administrators for mitigating the risk of MRSA infections. Our model is based
on the probabilistic programming paradigm, and can be used to approximately
answer a variety of predictive, causal, and counterfactual questions. We
demonstrate the efficacy of our model by comparing it against discriminative
and generative machine learning models using two real-world datasets.

</details>


### [158] [A Generalized Learning Framework for Self-Supervised Contrastive Learning](https://arxiv.org/abs/2508.13596)
*Lingyu Si,Jingyao Wang,Wenwen Qiang*

Main category: cs.LG

TL;DR: 提出了一种广义学习框架（GLF）和自适应分布校准（ADC）方法，用于改进自监督对比学习（SSCL），解决了在无标签情况下设计约束部分以实现类内紧凑和类间可分离的挑战。ADC在理论和实验中都显示出优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决自监督对比学习（SSCL）在设计约束部分时，由于无法使用标签而难以满足类内紧凑性和类间可分离性这两个要求的问题。

Method: 提出了一种名为自监督对比学习的广义学习框架（GLF），并将其应用于BYOL、Barlow Twins和SwAV三种现有方法。在此基础上，提出了一种名为自适应分布校准（ADC）的即插即用方法，通过迭代地捕捉锚点和其他样本之间的动态关系，来诱导类内紧凑性和类间可分离性。

Result: ADC能够确保原始输入空间中距离锚点近或远的样本，在特征空间中也保持近或远的关系，从而提升了特征空间的类别信息保留能力。

Conclusion: ADC可以提高特征空间的类别信息保留能力，在理论和实验上都证明了其优越性。

Abstract: Self-supervised contrastive learning (SSCL) has recently demonstrated
superiority in multiple downstream tasks. In this paper, we generalize the
standard SSCL methods to a Generalized Learning Framework (GLF) consisting of
two parts: the aligning part and the constraining part. We analyze three
existing SSCL methods: BYOL, Barlow Twins, and SwAV, and show that they can be
unified under GLF with different choices of the constraining part. We further
propose empirical and theoretical analyses providing two insights into
designing the constraining part of GLF: intra-class compactness and inter-class
separability, which measure how well the feature space preserves the class
information of the inputs. However, since SSCL can not use labels, it is
challenging to design a constraining part that satisfies these properties. To
address this issue, we consider inducing intra-class compactness and
inter-class separability by iteratively capturing the dynamic relationship
between anchor and other samples and propose a plug-and-play method called
Adaptive Distribution Calibration (ADC) to ensure that samples that are near or
far from the anchor point in the original input space are closer or further
away from the anchor point in the feature space. Both the theoretical analysis
and the empirical evaluation demonstrate the superiority of ADC.

</details>


### [159] [Approximate Bayesian Inference via Bitstring Representations](https://arxiv.org/abs/2508.13598)
*Aleksanteri Sladek,Martin Trapp,Arno Solin*

Main category: cs.LG

TL;DR: 通过在量化参数空间中进行概率推理，可以有效地使用离散参数学习连续分布，并提供可扩展、可解释的机器学习解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了扩展大模型，机器学习社区一直在努力研究量化或低精度算术。

Method: 提出了一种使用概率电路的可行学习方法，并在一系列模型上进行了验证。

Result: 该方法提供了可扩展的解决方案来管理复杂分布，并对模型行为提供清晰的见解，同时在不牺牲准确性的情况下展示了推理效率。

Conclusion: 该研究通过在量化、离散参数空间中执行概率推理，利用离散近似实现可扩展、可解释的机器学习，并实现了使用离散参数学习连续分布。

Abstract: The machine learning community has recently put effort into quantized or
low-precision arithmetics to scale large models. This paper proposes performing
probabilistic inference in the quantized, discrete parameter space created by
these representations, effectively enabling us to learn a continuous
distribution using discrete parameters. We consider both 2D densities and
quantized neural networks, where we introduce a tractable learning approach
using probabilistic circuits. This method offers a scalable solution to manage
complex distributions and provides clear insights into model behavior. We
validate our approach with various models, demonstrating inference efficiency
without sacrificing accuracy. This work advances scalable, interpretable
machine learning by utilizing discrete approximations for probabilistic
computations.

</details>


### [160] [Bounding Causal Effects and Counterfactuals](https://arxiv.org/abs/2508.13607)
*Tobias Maringgele*

Main category: cs.LG

TL;DR: This thesis tackles the underuse of partial identification in causal inference by comparing various bounding algorithms, extending existing methods, and providing practical selection tools. An open-source Python package is released to aid practitioners.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the underutilization of partial identification in applied causal inference due to fragmented methods and lack of practical guidance. Partial identification offers a principled alternative to precise estimation relying on unverifiable assumptions, by deriving bounds that reflect data uncertainty.

Method: The study systematically compares diverse bounding algorithms across multiple causal scenarios, implementing, extending, and unifying state-of-the-art methods. It includes an extension of an entropy-bounded method for counterfactual queries like Probability of Necessity and Sufficiency (PNS). Thousands of randomized simulations with discrete and continuous data-generating processes were conducted to assess methods based on bound tightness, computational efficiency, and robustness to assumption violations.

Result: The research provides a comparative assessment of bounding algorithms, an extension for counterfactual queries, a decision tree for algorithm selection, and a predictive machine learning model. These findings are packaged into an open-source Python library, CausalBoundingEngine.

Conclusion: The thesis provides a systematic comparison of various bounding algorithms for causal inference, including symbolic, optimization-based, and information-theoretic approaches. It proposes an extension to an entropy-bounded method for counterfactual queries and offers practical guidance for practitioners through a decision tree and a machine learning model for algorithm selection. All implementations are available in the open-source Python package, CausalBoundingEngine.

Abstract: Causal inference often hinges on strong assumptions - such as no unmeasured
confounding or perfect compliance - that are rarely satisfied in practice.
Partial identification offers a principled alternative: instead of relying on
unverifiable assumptions to estimate causal effects precisely, it derives
bounds that reflect the uncertainty inherent in the data. Despite its
theoretical appeal, partial identification remains underutilized in applied
work, in part due to the fragmented nature of existing methods and the lack of
practical guidance. This thesis addresses these challenges by systematically
comparing a diverse set of bounding algorithms across multiple causal
scenarios. We implement, extend, and unify state-of-the-art methods - including
symbolic, optimization-based, and information-theoretic approaches - within a
common evaluation framework. In particular, we propose an extension of a
recently introduced entropy-bounded method, making it applicable to
counterfactual queries such as the Probability of Necessity and Sufficiency
(PNS). Our empirical study spans thousands of randomized simulations involving
both discrete and continuous data-generating processes. We assess each method
in terms of bound tightness, computational efficiency, and robustness to
assumption violations. To support practitioners, we distill our findings into a
practical decision tree for algorithm selection and train a machine learning
model to predict the best-performing method based on observable data
characteristics.
  All implementations are released as part of an open-source Python package,
CausalBoundingEngine, which enables users to apply and compare bounding methods
through a unified interface.

</details>


### [161] [Towards a Larger Model via One-Shot Federated Learning on Heterogeneous Client Models](https://arxiv.org/abs/2508.13625)
*Wenxuan Ye,Xueli An,Onur Ayan,Junfan Wang,Xueqiang Yan,Georg Carle*

Main category: cs.LG

TL;DR: FedOL通过知识蒸馏和伪标签优化，在移动端联邦学习中实现了低通信、高效率的模型训练。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）方法需要统一的模型架构和多次通信，忽视了资源异构性，增加了客户端的计算负担和通信开销。同时，客户端的原始数据由于隐私限制无法直接共享。FedOL旨在解决这些问题，实现更高效、更灵活的联邦学习。

Method: FedOL提出了一种在单轮通信（一次性）设置下构建更大、更全面的服务器模型的方法。它不直接共享模型参数，而是利用知识蒸馏，让客户端仅交换模型在无标签公共数据集上的预测输出来代替原始数据。

Result: 仿真结果表明，FedOL在成本效益方面显著优于现有基线，为计算资源有限但拥有宝贵私有数据的移动网络客户端提供了一个有效的解决方案。

Conclusion: FedOL通过知识蒸馏和迭代式伪标签优化，在资源受限的移动网络环境下，实现了单轮通信成本下的模型定制化和性能提升，显著优于现有基线。

Abstract: Large models, renowned for superior performance, outperform smaller ones even
without billion-parameter scales. While mobile network servers have ample
computational resources to support larger models than client devices, privacy
constraints prevent clients from directly sharing their raw data. Federated
Learning (FL) enables decentralized clients to collaboratively train a shared
model by exchanging model parameters instead of transmitting raw data. Yet, it
requires a uniform model architecture and multiple communication rounds, which
neglect resource heterogeneity, impose heavy computational demands on clients,
and increase communication overhead. To address these challenges, we propose
FedOL, to construct a larger and more comprehensive server model in one-shot
settings (i.e., in a single communication round). Instead of model parameter
sharing, FedOL employs knowledge distillation, where clients only exchange
model prediction outputs on an unlabeled public dataset. This reduces
communication overhead by transmitting compact predictions instead of full
model weights and enables model customization by allowing heterogeneous model
architectures. A key challenge in this setting is that client predictions may
be biased due to skewed local data distributions, and the lack of ground-truth
labels in the public dataset further complicates reliable learning. To mitigate
these issues, FedOL introduces a specialized objective function that
iteratively refines pseudo-labels and the server model, improving learning
reliability. To complement this, FedOL incorporates a tailored pseudo-label
generation and knowledge distillation strategy that effectively integrates
diverse knowledge. Simulation results show that FedOL significantly outperforms
existing baselines, offering a cost-effective solution for mobile networks
where clients possess valuable private data but limited computational
resources.

</details>


### [162] [Text2Weight: Bridging Natural Language and Neural Network Weight Spaces](https://arxiv.org/abs/2508.13633)
*Bowen Tian,Wenshuo Chen,Zexi Li,Songning Lai,Jiemin Wu,Yutao Yue*

Main category: cs.LG

TL;DR: T2W是一个基于Transformer和扩散模型的框架，可以将自然语言描述转化为神经网路权重，从而提高了模型在未见过的任务上的性能和应用范围。


<details>
  <summary>Details</summary>
Motivation: 当前神经网路权重生成方法在泛化到未见过的任务和探索实际应用方面存在不足，因此需要一种能够根据自然语言描述生成特定任务权重的方法。

Method: T2W框架采用Transformer和扩散模型，将网络参数分块处理，利用CLIP的文本嵌入和先验注意力机制，并结合对抗训练和权重空间增强来提高泛化能力。

Result: T2W在Cifar100、Caltech256和TinyImageNet数据集上进行了实验，证明其能够为未见过的任务生成高质量权重，并且优于基于优化的初始化方法。

Conclusion: T2W通过将文本语义与权重空间动力学相结合，成功生成了高质量的特定任务权重，并在未见过的任务上表现优于基于优化的初始化方法，实现了权重增强和文本引导模型融合等新应用，推动了生成模型在神经网络参数合成方面的实用性。

Abstract: How far are we really from automatically generating neural networks? While
neural network weight generation shows promise, current approaches struggle
with generalization to unseen tasks and practical application exploration. To
address this, we propose T2W, a diffusion transformer framework that generates
task-specific weights conditioned on natural language descriptions. T2W
hierarchically processes network parameters into uniform blocks, integrates
text embeddings from CLIP via a prior attention mechanism, and employs
adversarial training with weight-space augmentation to enhance generalization.
Experiments on Cifar100, Caltech256, and TinyImageNet demonstrate T2W's ability
to produce high-quality weights for unseen tasks, outperforming
optimization-based initialization and enabling novel applications such as
weight enhancement and text-guided model fusion. Our work bridges textual
semantics with weight-space dynamics, supported by an open-source dataset of
text-weight pairs, advancing the practicality of generative models in neural
network parameter synthesis. Our code is available on Github.

</details>


### [163] [Explainable Learning Rate Regimes for Stochastic Optimization](https://arxiv.org/abs/2508.13639)
*Zhuang Yang*

Main category: cs.LG

TL;DR: 提出了一种新的、自动的学习率调整方法，仅基于梯度变化，无需调参，且效果好。


<details>
  <summary>Details</summary>
Motivation: 现有学习率（LR）策略可能复杂，或需要手动调整额外的超参数，这在实践中会带来巨大的计算、时间和电力消耗。本研究旨在提供一种更自然、更直接的方法来自动调整学习率。

Method: 提出了一种利用随机二阶算法来自动更新学习率（LR）的机制，其更新方式仅依据随机梯度的内在变化，具体表现为：当随机梯度的范数减小时，学习率应增加；反之，当随机梯度的范数增加时，学习率应减小。

Result: 所提出的学习率（LR）机制能够自动调整学习率，其更新模式与启发式算法相似，但实现更简单，无需任何参数调整，并能在不同的随机优化算法和机器学习任务中有效运行。

Conclusion: 该学习率（LR）机制在 SGD、SGDM 和 SIGNSGD 等经典随机算法中都展现出了效率、鲁棒性和可扩展性，且无需手动调整参数。

Abstract: Modern machine learning is trained by stochastic gradient descent (SGD),
whose performance critically depends on how the learning rate (LR) is adjusted
and decreased over time. Yet existing LR regimes may be intricate, or need to
tune one or more additional hyper-parameters manually whose bottlenecks include
huge computational expenditure, time and power in practice. This work, in a
natural and direct manner, clarifies how LR should be updated automatically
only according to the intrinsic variation of stochastic gradients. An
explainable LR regime by leveraging stochastic second-order algorithms is
developed, behaving a similar pattern to heuristic algorithms but implemented
simply without any parameter tuning requirement, where it is of an automatic
procedure that LR should increase (decrease) as the norm of stochastic
gradients decreases (increases). The resulting LR regime shows its efficiency,
robustness, and scalability in different classical stochastic algorithms,
containing SGD, SGDM, and SIGNSGD, on machine learning tasks.

</details>


### [164] [Personalized Subgraph Federated Learning with Sheaf Collaboration](https://arxiv.org/abs/2508.13642)
*Wenfei Liang,Yanan Zhao,Rui She,Yiming Li,Wee Peng Tay*

Main category: cs.LG

TL;DR: FedSheafHN is a new framework for personalized subgraph FL that uses a sheaf collaboration mechanism to improve client models and handle data heterogeneity, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Performance variation across clients remains a key issue in personalized subgraph FL due to the heterogeneity of local subgraphs.

Method: FedSheafHN embeds each client's local subgraph into a server-constructed collaboration graph by leveraging graph-level embeddings and employing sheaf diffusion within the collaboration graph to enrich client representations. Subsequently, FedSheafHN generates customized client models via a server-optimized hypernetwork.

Result: FedSheafHN outperforms existing personalized subgraph FL methods on various graph datasets. Additionally, it exhibits fast model convergence and effectively generalizes to new clients.

Conclusion: FedSheafHN outperforms existing personalized subgraph FL methods on various graph datasets, exhibiting fast model convergence and effectively generalizing to new clients.

Abstract: Graph-structured data is prevalent in many applications. In subgraph
federated learning (FL), this data is distributed across clients, each with a
local subgraph. Personalized subgraph FL aims to develop a customized model for
each client to handle diverse data distributions. However, performance
variation across clients remains a key issue due to the heterogeneity of local
subgraphs. To overcome the challenge, we propose FedSheafHN, a novel framework
built on a sheaf collaboration mechanism to unify enhanced client descriptors
with efficient personalized model generation. Specifically, FedSheafHN embeds
each client's local subgraph into a server-constructed collaboration graph by
leveraging graph-level embeddings and employing sheaf diffusion within the
collaboration graph to enrich client representations. Subsequently, FedSheafHN
generates customized client models via a server-optimized hypernetwork.
Empirical evaluations demonstrate that FedSheafHN outperforms existing
personalized subgraph FL methods on various graph datasets. Additionally, it
exhibits fast model convergence and effectively generalizes to new clients.

</details>


### [165] [Input Time Scaling](https://arxiv.org/abs/2508.13654)
*Rapheal Huang,Weilong Guo*

Main category: cs.LG

TL;DR: 本研究提出“输入时间缩放”新范式，通过优化查询输入和训练-测试协同设计，提升LLMs性能。实验发现低质量数据和不相关信息有时能带来最佳结果，并挑战了数据质量的传统观念。在AIME竞赛中取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 为了拓展大型语言模型（LLMs）的缩放范式，提出一种新的“输入时间缩放”方法，并探索数据质量、数量和查询策略对模型性能的影响。

Method: "输入时间缩放"范式，结合元知识来优化查询输入。

Result: 在Qwen2.5-32B-Instruct模型上，通过“输入时间缩放”和“训练-测试协同设计”，在AIME24和AIME25竞赛中达到了SOTA性能。低质量数据和包含不相关信息的查询反而能提升模型性能，挑战了传统的“垃圾进，垃圾出”观点。

Conclusion: 研究表明，新的“输入时间缩放”范式可以作为现有缩放方法的补充，通过在查询（输入时间）上投入资源来改进大型语言模型。研究发现，“训练-测试协同设计”是关键，需要同时应用查询策略。低质量数据集和包含不相关信息的查询有时能带来最佳性能，这与“垃圾进，垃圾出”的普遍观念相悖。模型在更多数据上训练反而可能表现更差，数据集大小缩放也需谨慎。该研究与“少即是多”现象一致，少量示例足以激发高级推理能力。通过实验，作者在Qwen2.5-32B-Instruct模型上达到了AIME24和AIME25的SOTA性能，并计划开源相关资源。

Abstract: Current Large Language Models (LLMs) are usually post-trained on large-scale
carefully curated datasets (data & training scaling) and doing reasoning in
test time (inference time scaling). In this work, we present a new scaling
paradigm, Input Time Scaling, to complement previous scaling methods by putting
resources on queries (input time). During training and testing, we combine
meta-knowledge from LLMs to refine inputs with different strategies. We also
find a new phenomenon, training-testing co-design there. We need to apply query
strategies during both training and testing. Only applying strategies on
training or testing would seriously degrade the performance. We are also
surprised to find that seemingly low data quality datasets can gain high
performance. Adding irrelevant information to the queries, randomly selecting
examples from a minimally filtered dataset, can even perform the best. These
findings contradict the widely held inductive bias, "garbage in, garbage out".
Curating datasets with seemingly high-quality data can even potentially limit
the performance ceiling. In addition, models trained on more data with similar
quality (15k VS 1k) perform worse, simple dataset size scaling should also be
carefully inspected. The good news is that our findings are compatible with the
Less is More phenomenon. A small set of examples is enough to evoke high-level
reasoning ability. With experiments on models trained on Qwen2.5-32B-Instruct,
we are able to reach SOTA performance among 32B models on AIME24(76.7%) and
AIME25(76.7%) pass@1. We can further achieve AIME24(76.7%) and AIME25(80%) with
a majority vote of three models. Starting from DeepSeek-R1-Distill-Qwen-32B,
the best result would be 86.7% on AIME24 and 76.7% on AIME25. To facilitate
reproducibility and further research, we are working on open-source our
datasets, data pipelines, evaluation results, and checkpoints.

</details>


### [166] [In-Context Decision Making for Optimizing Complex AutoML Pipelines](https://arxiv.org/abs/2508.13657)
*Amir Rezaei Balef,Katharina Eggensperger*

Main category: cs.LG

TL;DR: 该研究提出了一种名为PS-PFN的新型自动化机器学习方法，用于选择和调整现代机器学习管道，在各种基准任务上均表现出色。


<details>
  <summary>Details</summary>
Motivation: 现代机器学习工作流超出了超参数优化，需要微调、集成和适应等技术，这需要新的自动化机器学习方法来应对日益增长的异构机器学习管道。

Method: 提出PS-PFN，将后验采样（PS）扩展到最大k臂老虎机问题设置，并利用先验数据拟合网络（PFNs）通过上下文学习高效估计最大值的后验分布。同时考虑了臂拉动的变化成本，并使用不同的PFNs为每臂单独建模奖励分布。

Result: 在两个现有基准任务和一个新的基准任务上，PS-PFN都表现出优于其他老虎机和自动化机器学习策略的性能。

Conclusion: 该研究将CASH框架扩展到选择和适应现代机器学习管道，提出PS-PFN来高效地探索和利用适应性机器学习管道，并通过实验证明了其优于其他算法。

Abstract: Combined Algorithm Selection and Hyperparameter Optimization (CASH) has been
fundamental to traditional AutoML systems. However, with the advancements of
pre-trained models, modern ML workflows go beyond hyperparameter optimization
and often require fine-tuning, ensembling, and other adaptation techniques.
While the core challenge of identifying the best-performing model for a
downstream task remains, the increasing heterogeneity of ML pipelines demands
novel AutoML approaches. This work extends the CASH framework to select and
adapt modern ML pipelines. We propose PS-PFN to efficiently explore and exploit
adapting ML pipelines by extending Posterior Sampling (PS) to the max k-armed
bandit problem setup. PS-PFN leverages prior-data fitted networks (PFNs) to
efficiently estimate the posterior distribution of the maximal value via
in-context learning. We show how to extend this method to consider varying
costs of pulling arms and to use different PFNs to model reward distributions
individually per arm. Experimental results on one novel and two existing
standard benchmark tasks demonstrate the superior performance of PS-PFN
compared to other bandit and AutoML strategies. We make our code and data
available at https://github.com/amirbalef/CASHPlus.

</details>


### [167] [Heavy-tailed Linear Bandits: Adversarial Robustness, Best-of-both-worlds, and Beyond](https://arxiv.org/abs/2508.13679)
*Canzhe Zhao,Shinji Ito,Shuai Li*

Main category: cs.LG

TL;DR: 本文提出了针对重尾对抗性赌徒问题的通用框架和算法，解决了先前研究主要集中在随机模型的问题。所提出的方法在多臂和线性重尾赌徒的对抗性与随机设定下均取得了优于先前工作的遗憾界，并引入了一种名为HT-SPM的新型数据依赖学习率，实现了重尾线性赌徒问题的首个‘两者兼顾’（BOBW）结果。


<details>
  <summary>Details</summary>
Motivation: 先前关于重尾赌徒的研究主要集中在随机模型，在对抗性模型方面的研究非常有限，尤其是在重尾多臂赌徒（MABs）和重尾线性赌徒问题上。尽管存在一些处理重尾问题的初步工作，但它们通常仅限于随机模型或需要截断非负性等假设。因此，本文的动机是填补在重尾对抗性赌徒问题研究中的空白，开发更通用的框架和算法，以应对更广泛的重尾赌徒场景，并达到与随机模型相媲美的性能。

Method: 本文提出的框架的核心是基于损失估计的奖励函数，并在此基础上进行正则化领导者跟随（FTRL）优化。具体来说，通过对奖励函数进行精细设计，可以开发出首个适用于重尾多臂赌徒问题的FTRL类型‘两者兼顾’（BOBW）算法，该算法在对抗性设定下实现了$\widetilde{O}(T^{\frac{1}{\varepsilon}})$的最坏情况遗憾界，并在随机设定下实现了$\widetilde{O}(\log T)$的差距相关遗憾界。该框架进一步扩展到线性赌徒问题，提出了首个适用于重尾线性赌徒问题的对抗性算法，其遗憾界为$\widetilde{O}(d^{\frac{1}{2}}T^{\frac{1}{\varepsilon}})$。此外，本文还提出了一种名为‘重尾噪声感知稳定性-惩罚匹配’（HT-SPM）的数据依赖学习率，并在理论上证明了该学习率在满足一定条件下，能够保证重尾赌徒问题的‘两者兼顾’遗憾界。最后，通过结合HT-SPM和方差缩减线性损失估计器，实现了重尾线性赌徒问题的‘两者兼顾’。

Result: 本文提出的框架成功地将重尾赌徒问题扩展到了对抗性设定。具体而言，在重尾多臂赌徒问题上，提出的FTRL-type BOBW算法在对抗性设定下达到了 $\widetilde{O}(T^{\frac{1}{\varepsilon}})$ 的最坏情况遗憾界，在随机设定下达到了 $\widetilde{O}(\log T)$ 的差距相关遗憾界。在重尾线性赌徒问题上，提出的算法实现了 $\widetilde{O}(d^{\frac{1}{2}}T^{\frac{1}{\varepsilon}})$ 的遗憾界，与随机模型下的最佳已知遗憾界相当。此外，提出的HT-SPM学习率在理论上保证了重尾赌徒问题的BOBW遗憾界，并首次在重尾线性赌徒问题上实现了BOBW结果。

Conclusion: 本文提出了针对重尾对抗性赌徒问题的通用框架，并成功将其扩展到重尾线性赌徒问题。框架通过精心设计的奖励函数，实现了在对抗性重尾多臂赌徒问题上的最坏情况遗憾界，并在随机重尾多臂赌徒问题上实现了与差距相关的遗憾界。此外，提出了一种名为‘重尾噪声感知稳定性-惩罚匹配’（HT-SPM）的通用数据依赖学习率，该方法在满足特定条件时，可保证重尾赌徒问题的双重界限。HT-SPM 结合方差缩减线性损失估计器，首次实现了重尾线性赌徒问题的双重界限。

Abstract: Heavy-tailed bandits have been extensively studied since the seminal work of
\citet{Bubeck2012BanditsWH}. In particular, heavy-tailed linear bandits,
enabling efficient learning with both a large number of arms and heavy-tailed
noises, have recently attracted significant attention
\citep{ShaoYKL18,XueWWZ20,ZhongHYW21,Wang2025heavy,tajdini2025improved}.
However, prior studies focus almost exclusively on stochastic regimes, with few
exceptions limited to the special case of heavy-tailed multi-armed bandits
(MABs) \citep{Huang0H22,ChengZ024,Chen2024uniINF}.
  In this work, we propose a general framework for adversarial heavy-tailed
bandit problems, which performs follow-the-regularized-leader (FTRL) over the
loss estimates shifted by a bonus function. Via a delicate setup of the bonus
function, we devise the first FTRL-type best-of-both-worlds (BOBW) algorithm
for heavy-tailed MABs, which does not require the truncated non-negativity
assumption and achieves an $\widetilde{O}(T^{\frac{1}{\varepsilon}})$
worst-case regret in the adversarial regime as well as an $\widetilde{O}(\log
T)$ gap-dependent regret in the stochastic regime. We then extend our framework
to the linear case, proposing the first algorithm for adversarial heavy-tailed
linear bandits with finite arm sets. This algorithm achieves an
$\widetilde{O}(d^{\frac{1}{2}}T^{\frac{1}{\varepsilon}})$ regret, matching the
best-known worst-case regret bound in stochastic regimes. Moreover, we propose
a general data-dependent learning rate, termed \textit{heavy-tailed noise aware
stability-penalty matching} (HT-SPM). We prove that HT-SPM guarantees BOBW
regret bounds for general heavy-tailed bandit problems once certain conditions
are satisfied. By using HT-SPM and, in particular, a variance-reduced linear
loss estimator, we obtain the first BOBW result for heavy-tailed linear
bandits.

</details>


### [168] [Minimizing the Weighted Number of Tardy Jobs: Data-Driven Heuristic for Single-Machine Scheduling](https://arxiv.org/abs/2508.13703)
*Nikolai Antonov,Prěmysl Šůcha,Mikoláš Janota,Jan Hůla*

Main category: cs.LG

TL;DR: 这项研究提出了一种结合机器学习和问题特定信息的数据驱动调度方法，用于单机调度问题，旨在最大限度地减少迟交工作的总权重。与现有方法相比，该方法在性能和适应性方面表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有关于单机调度的研究主要集中在精确算法上，这些算法在典型实例上表现良好，但在某些问题空间区域可能会显著恶化。相比之下，数据驱动的方法在针对特定数据集结构进行调整时，能提供强大且可扩展的性能。

Method: 提出了一种新颖的数据驱动调度启发式方法，该方法结合了机器学习和特定问题的特性，确保了可行性解决方案，这是基于机器学习的算法面临的常见挑战。

Result: 所提出的方法在最优值差距、最优解数量和跨不同数据场景的适应性方面显著优于现有技术。

Conclusion: 实验结果表明，该方法在最优值差距、最优解数量和跨不同数据场景的适应性方面显著优于现有技术，显示了其在实际应用中的灵活性。此外，我们对机器学习模型进行了系统性探索，通过详细的模型选择过程解决了类似研究中常见的空白，并为所选模型是最佳选择的原因提供了见解。

Abstract: Existing research on single-machine scheduling is largely focused on exact
algorithms, which perform well on typical instances but can significantly
deteriorate on certain regions of the problem space. In contrast, data-driven
approaches provide strong and scalable performance when tailored to the
structure of specific datasets. Leveraging this idea, we focus on a
single-machine scheduling problem where each job is defined by its weight,
duration, due date, and deadline, aiming to minimize the total weight of tardy
jobs. We introduce a novel data-driven scheduling heuristic that combines
machine learning with problem-specific characteristics, ensuring feasible
solutions, which is a common challenge for ML-based algorithms. Experimental
results demonstrate that our approach significantly outperforms the
state-of-the-art in terms of optimality gap, number of optimal solutions, and
adaptability across varied data scenarios, highlighting its flexibility for
practical applications. In addition, we conduct a systematic exploration of ML
models, addressing a common gap in similar studies by offering a detailed model
selection process and providing insights into why the chosen model is the best
fit.

</details>


### [169] [DREAMS: Preserving both Local and Global Structure in Dimensionality Reduction](https://arxiv.org/abs/2508.13747)
*Noël Kury,Dmitry Kobak,Sebastian Damrich*

Main category: cs.LG

TL;DR: DREAMS is a new method that balances local and global data structure preservation in dimensionality reduction, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing dimensionality reduction methods struggle to preserve both local and global data structures simultaneously. This paper introduces DREAMS to address this limitation.

Method: DREAMS combines the local structure preservation of t-SNE with the global structure preservation of PCA using a regularization term, generating embeddings that balance both aspects.

Result: DREAMS demonstrates superior performance in preserving structure across multiple scales compared to previous approaches, as evidenced by qualitative and quantitative benchmarks on seven real-world datasets.

Conclusion: DREAMS is a new dimensionality reduction technique that combines local and global structure preservation, outperforming existing methods across various real-world datasets.

Abstract: Dimensionality reduction techniques are widely used for visualizing
high-dimensional data in two dimensions. Existing methods are typically
designed to preserve either local (e.g. $t$-SNE, UMAP) or global (e.g. MDS,
PCA) structure of the data, but none of the established methods can represent
both aspects well. In this paper, we present DREAMS (Dimensionality Reduction
Enhanced Across Multiple Scales), a method that combines the local structure
preservation of $t$-SNE with the global structure preservation of PCA via a
simple regularization term. Our approach generates a spectrum of embeddings
between the locally well-structured $t$-SNE embedding and the globally
well-structured PCA embedding, efficiently balancing both local and global
structure preservation. We benchmark DREAMS across seven real-world datasets,
including five from single-cell transcriptomics and one from population
genetics, showcasing qualitatively and quantitatively its superior ability to
preserve structure across multiple scales compared to previous approaches.

</details>


### [170] [Order Optimal Regret Bounds for Sharpe Ratio Optimization in the Bandit Setting](https://arxiv.org/abs/2508.13749)
*Mohammad Taha Shah,Sabrina Khurshid,Gourab Ghatak*

Main category: cs.LG

TL;DR: 本文研究了在随机老虎机设置中最大化夏普比率的问题，并提出了一种基于Thompson Sampling（TS）的SRTS算法。该算法在理论上实现了对数后悔界，并被证明是阶最优的。实验结果表明，SRTS算法在性能上优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 解决在随机老虎机设置中最大化夏普比率（SR）的问题，并探索了TS算法在该场景下的性能。

Method: 提出了一种新的适用于夏普比率的后悔分解方法，并推导了SRTS算法的上限和下限，证明了其阶最优性。

Result: SRTS算法实现了对数后悔界，分布相关的因子影响了基于风险调整表现区分老虎机的难度。经验模拟显示SRTS显著优于现有算法。

Conclusion: Thompson Sampling（TS）算法在夏普比率最大化问题上实现了对数后悔界，并优于现有算法。

Abstract: In this paper, we investigate the problem of sequential decision-making for
Sharpe ratio (SR) maximization in a stochastic bandit setting. We focus on the
Thompson Sampling (TS) algorithm, a Bayesian approach celebrated for its
empirical performance and exploration efficiency, under the assumption of
Gaussian rewards with unknown parameters. Unlike conventional bandit objectives
focusing on maximizing cumulative reward, Sharpe ratio optimization instead
introduces an inherent tradeoff between achieving high returns and controlling
risk, demanding careful exploration of both mean and variance. Our theoretical
contributions include a novel regret decomposition specifically designed for
the Sharpe ratio, highlighting the role of information acquisition about the
reward distribution in driving learning efficiency. Then, we establish
fundamental performance limits for the proposed algorithm \texttt{SRTS} in
terms of an upper bound on regret. We also derive the matching lower bound and
show the order-optimality. Our results show that Thompson Sampling achieves
logarithmic regret over time, with distribution-dependent factors capturing the
difficulty of distinguishing arms based on risk-adjusted performance. Empirical
simulations show that our algorithm significantly outperforms existing
algorithms.

</details>


### [171] [Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration](https://arxiv.org/abs/2508.13755)
*Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang*

Main category: cs.LG

TL;DR: RLVR 通过 DARS 和增加训练宽度来提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有 RLVR 的深度（模型可以采样的最难问题）和宽度（单次迭代消耗的实例数）这两个维度被低估了。GRPO 算法存在一种系统性偏差，即累积优势不成比例地加权了准确性中等的样本，反而降低了对突破推理边界至关重要的低准确性实例的权重。

Method: 提出了一种名为难度自适应 Rollout 抽样的 DARS 的方法，通过目标多阶段 Rollout 来重新加权困难问题，从而增加了困难问题的正面 Rollout 数量。此外，通过增加批处理大小并将 PPO 的小批处理迭代替换为跨多个 epoch 的全批处理更新来扩展训练数据的宽度，并提出了一种将 DARS 与大宽度相结合的 DARS-B。

Result: DARS 提供了持续的 Pass@K 增益，而无需在收敛时增加额外的推理成本。增加宽度显著提高了 Pass@1 性能。DARS-B 在 Pass@K 和 Pass@1 方面均取得进展。

Conclusion: 增加训练数据的宽度和跨深度进行自适应探索是释放RLVR推理能力的两个关键正交维度。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has emerged as a
powerful paradigm for unlocking reasoning capabilities in large language
models, yet its full potential is hindered by two under-explored dimensions:
Depth-the hardest problem a model can sample; Breadth-the number of instances
consumed in a single iteration. We dissect the popular GRPO algorithm and
reveal a systematic bias: the cumulative-advantage disproportionately weights
samples with medium accuracy, while down-weighting the low-accuracy instances
that are crucial for pushing reasoning boundaries. To rectify the depth
neglect, we introduce Difficulty Adaptive Rollout Sampling (DARS), which
re-weights hard problems through targeted multi-stage rollouts, thereby
increasing the number of positive rollouts for hard problems. Empirically,
naively enlarging rollout size only accelerates convergence and even hurts
Pass@K. Our DARS, in contrast, delivers consistent Pass@K gains without extra
inference cost at convergence. Just as we adaptively expanded the depth of
exploration, we now ask whether aggressively scaling the breadth of training
data can further amplify reasoning gains. To this end, we intensely scale batch
size and replace PPO's mini-batch iterations with full-batch updates over
multiple epochs. Increasing breadth significantly enhances Pass@1 performance.
Large-breadth training sustains high token-level entropy, indicating continued
exploration and reduced gradient noise. We further present DARS-B, which
augments DARS with large breadth, and demonstrate simultaneous gains in Pass@K
and Pass@1. The results confirm that breadth and adaptive exploration across
depth operate as orthogonal dimensions in RLVR, which are key to unleashing the
reasoning power of RLVR.

</details>


### [172] [PENGUIN: Enhancing Transformer with Periodic-Nested Group Attention for Long-term Time Series Forecasting](https://arxiv.org/abs/2508.13773)
*Tian Sun,Yuqi Chen,Weiwei Sun*

Main category: cs.LG

TL;DR: PENGUIN, a new mechanism for long-term time series forecasting, uses periodic-nested group attention to model periodic patterns and relative attention bias, outperforming existing models.


<details>
  <summary>Details</summary>
Motivation: Revisit the significance of self-attention for time series forecasting and propose a simple yet effective mechanism, PENGUIN, to explicitly model periodic patterns and incorporate relative attention bias.

Method: PENGUIN introduces a periodic-nested relative attention bias to capture periodic structures directly and uses a grouped attention mechanism with multi-query attention to handle multiple coexisting periodicities.

Result: The approach highlights the importance of explicitly modeling periodic patterns and incorporating relative attention bias for effective time series modeling.

Conclusion: PENGUIN consistently outperforms both MLP-based and Transformer-based models across diverse benchmarks.

Abstract: Long-term time series forecasting (LTSF) is a fundamental task with
wide-ranging applications. Although Transformer-based models have made
significant breakthroughs in forecasting, their effectiveness for time series
forecasting remains debatable. In this paper, we revisit the significance of
self-attention and propose a simple yet effective mechanism, Periodic-Nested
Group Attention, namely PENGUIN. Our approach highlights the importance of
explicitly modeling periodic patterns and incorporating relative attention bias
for effective time series modeling. To this end, we introduce a periodic-nested
relative attention bias that captures periodic structures directly. To handle
multiple coexisting periodicities (e.g., daily and weekly cycles), we design a
grouped attention mechanism, where each group targets a specific periodicity
using a multi-query attention mechanism. Extensive experiments across diverse
benchmarks demonstrate that PENGUIN consistently outperforms both MLP-based and
Transformer-based models.

</details>


### [173] [Communication-Efficient Federated Learning with Adaptive Number of Participants](https://arxiv.org/abs/2508.13803)
*Sergey Skorik,Vladislav Dorofeev,Gleb Molodtsov,Aram Avetisyan,Dmitry Bylinkin,Daniil Medyakov,Aleksandr Beznosikov*

Main category: cs.LG

TL;DR: ISP 是一种新的联邦学习方法，可以智能地选择每轮的客户端数量，将通信效率提高了 30%，同时保持了模型准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的联邦学习（FL）框架虽然解决了模型扩展带来的挑战，但通信效率仍然是一个关键瓶颈，尤其是在客户端参与异构和动态的情况下。现有的方法（如 FedAvg、FedProx 及客户端选择策略）试图减轻通信成本，但选择每轮的客户端数量这一问题仍未得到充分研究。

Method: ISP（Intelligent Selection of Participants）是一种自适应机制，用于动态确定每轮训练的最佳客户端数量，以提高通信效率，同时保持模型准确性。

Result: ISP 在包括视觉转换器、真实世界 ECG 分类以及梯度压缩训练在内的各种设置中都得到了验证。结果显示，在不损失最终模型质量的情况下，通信节省高达 30%。

Conclusion: ISP 是一种自适应机制，可以动态确定每轮的最佳客户端数量，从而在不损害模型准确性的情况下提高通信效率。ISP 的应用，特别是在真实世界的 ECG 分类设置中，凸显了选择客户端数量作为联邦学习的一个独立任务。

Abstract: Rapid scaling of deep learning models has enabled performance gains across
domains, yet it introduced several challenges. Federated Learning (FL) has
emerged as a promising framework to address these concerns by enabling
decentralized training. Nevertheless, communication efficiency remains a key
bottleneck in FL, particularly under heterogeneous and dynamic client
participation. Existing methods, such as FedAvg and FedProx, or other
approaches, including client selection strategies, attempt to mitigate
communication costs. However, the problem of choosing the number of clients in
a training round remains extremely underexplored. We introduce Intelligent
Selection of Participants (ISP), an adaptive mechanism that dynamically
determines the optimal number of clients per round to enhance communication
efficiency without compromising model accuracy. We validate the effectiveness
of ISP across diverse setups, including vision transformers, real-world ECG
classification, and training with gradient compression. Our results show
consistent communication savings of up to 30\% without losing the final
quality. Applying ISP to different real-world ECG classification setups
highlighted the selection of the number of clients as a separate task of
federated learning.

</details>


### [174] [Reinforcement Learning-based Adaptive Path Selection for Programmable Networks](https://arxiv.org/abs/2508.13806)
*José Eduardo Zerna Torres,Marios Avgeris,Chrysa Papagianni,Gergely Pongrácz,István Gódor,Paola Grosso*

Main category: cs.LG

TL;DR: 提出了一种在可编程网络中，利用SLA和INT的分布式网络内强化学习框架，实现了自适应路径选择。


<details>
  <summary>Details</summary>
Motivation: 为可编程网络中的自适应路径选择提供一种分布式、网络内的强化学习实现。

Method: 结合随机学习自动机（SLA）和通过带内网络遥测（INT）收集的实时遥测数据，实现了一个分布式、网络内强化学习（IN-RL）框架。

Result: 该框架能够根据拥塞情况动态调整，并通过SLA机制实现有效的路径选择，并以线速率适应网络变化。

Conclusion: 该系统在基于P4的可编程BMv2交换机的Mininet测试台上进行了评估，证明了我们基于SLA的机制可以收敛到有效的路径选择，并以线速率适应不断变化的網絡條件。

Abstract: This work presents a proof-of-concept implementation of a distributed,
in-network reinforcement learning (IN-RL) framework for adaptive path selection
in programmable networks. By combining Stochastic Learning Automata (SLA) with
real-time telemetry data collected via In-Band Network Telemetry (INT), the
proposed system enables local, data-driven forwarding decisions that adapt
dynamically to congestion conditions. The system is evaluated on a
Mininet-based testbed using P4-programmable BMv2 switches, demonstrating how
our SLA-based mechanism converges to effective path selections and adapts to
shifting network conditions at line rate.

</details>


### [175] [Assessing Trustworthiness of AI Training Dataset using Subjective Logic -- A Use Case on Bias](https://arxiv.org/abs/2508.13813)
*Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl*

Main category: cs.LG

TL;DR: 本研究提出了一个基于主观逻辑的新框架，用于评估人工智能训练数据集的可信度，特别是针对偏差等全局属性，并在交通标志识别数据集上进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能系统越来越依赖训练数据，评估数据集的可信度变得至关重要，特别是对于像公平性或偏差这样的在数据集层面出现的属性。

Method: 基于主观逻辑，提出了一种评估人工智能训练数据集可信度的新框架，并将其应用于偏差属性的评估。

Result: 实验结果表明，该方法能够捕捉类别不平衡，并且在中心化和联邦化场景下都能保持可解释性和鲁棒性。

Conclusion: 该方法在中心化和联邦化场景下都能捕捉类别不平衡，并且保持可解释性和鲁棒性。

Abstract: As AI systems increasingly rely on training data, assessing dataset
trustworthiness has become critical, particularly for properties like fairness
or bias that emerge at the dataset level. Prior work has used Subjective Logic
to assess trustworthiness of individual data, but not to evaluate
trustworthiness properties that emerge only at the level of the dataset as a
whole. This paper introduces the first formal framework for assessing the
trustworthiness of AI training datasets, enabling uncertainty-aware evaluations
of global properties such as bias. Built on Subjective Logic, our approach
supports trust propositions and quantifies uncertainty in scenarios where
evidence is incomplete, distributed, and/or conflicting. We instantiate this
framework on the trustworthiness property of bias, and we experimentally
evaluate it based on a traffic sign recognition dataset. The results
demonstrate that our method captures class imbalance and remains interpretable
and robust in both centralized and federated contexts.

</details>


### [176] [Disentangled Deep Smoothed Bootstrap for Fair Imbalanced Regression](https://arxiv.org/abs/2508.13829)
*Samuel Stocksieker,Denys pommeret,Arthur Charpentier*

Main category: cs.LG

TL;DR: 为解决不平衡回归问题，提出了一种结合解耦VAE和光滑助推的新数据生成方法，并在基准数据集上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 解决在预测建模中，特别是在回归问题上，不平衡数据分布导致标准算法性能下降的挑战。

Method: 提出了一种结合了解耦变分自编码器（disentangled VAE）和潜在空间中的光滑助推（Smoothed Bootstrap）的数据生成方法。

Result: 通过在不平衡回归（IR）基准数据集上的数值比较，证明了该方法相对于现有方法的有效性。

Conclusion: 该研究提出了一种新颖的、结合了潜在空间中解耦变分自编码器和光滑助推的数据生成方法，以应对不平衡回归问题。

Abstract: Imbalanced distribution learning is a common and significant challenge in
predictive modeling, often reducing the performance of standard algorithms.
Although various approaches address this issue, most are tailored to
classification problems, with a limited focus on regression. This paper
introduces a novel method to improve learning on tabular data within the
Imbalanced Regression (IR) framework, which is a critical problem. We propose
using Variational Autoencoders (VAEs) to model and define a latent
representation of data distributions. However, VAEs can be inefficient with
imbalanced data like other standard approaches. To address this, we develop an
innovative data generation method that combines a disentangled VAE with a
Smoothed Bootstrap applied in the latent space. We evaluate the efficiency of
this method through numerical comparisons with competitors on benchmark
datasets for IR.

</details>


### [177] [One Shot vs. Iterative: Rethinking Pruning Strategies for Model Compression](https://arxiv.org/abs/2508.13836)
*Mikołaj Janusz,Tomasz Wojnar,Yawei Li,Luca Benini,Kamil Adamczewski*

Main category: cs.LG

TL;DR: 一次性剪枝和迭代剪枝在不同剪枝率下各有优劣，混合方法在某些情况下表现更佳。


<details>
  <summary>Details</summary>
Motivation: 尽管迭代剪枝得到了更广泛的应用，但这种偏好通常是基于假设而非严格测试。本研究旨在提供对这些方法的严格比较。

Method: 对一次性剪枝和迭代剪枝进行了系统和全面的比较，包括定义、跨结构化和非结构化设置的基准测试，以及剪枝标准和模式的应用。

Result: 一次性剪枝在较低剪枝率下更有效，而迭代剪枝在较高剪枝率下表现更好。所提出的混合方法在某些场景下优于传统方法。

Conclusion: 研究结果表明，在较低的剪枝率下，一次性剪枝更有效；而在较高的剪枝率下，迭代剪枝表现更好。研究提倡耐心剪枝，并提出了一种混合方法，在某些情况下可以超越传统方法。

Abstract: Pruning is a core technique for compressing neural networks to improve
computational efficiency. This process is typically approached in two ways:
one-shot pruning, which involves a single pass of training and pruning, and
iterative pruning, where pruning is performed over multiple cycles for
potentially finer network refinement. Although iterative pruning has
historically seen broader adoption, this preference is often assumed rather
than rigorously tested. Our study presents one of the first systematic and
comprehensive comparisons of these methods, providing rigorous definitions,
benchmarking both across structured and unstructured settings, and applying
different pruning criteria and modalities. We find that each method has
specific advantages: one-shot pruning proves more effective at lower pruning
ratios, while iterative pruning performs better at higher ratios. Building on
these findings, we advocate for patience-based pruning and introduce a hybrid
approach that can outperform traditional methods in certain scenarios,
providing valuable insights for practitioners selecting a pruning strategy
tailored to their goals and constraints. Source code is available at
https://github.com/janumiko/pruning-benchmark.

</details>


### [178] [FedUP: Efficient Pruning-based Federated Unlearning for Model Poisoning Attacks](https://arxiv.org/abs/2508.13853)
*Nicolò Romandini,Cristian Borcea,Rebecca Montanari,Luca Foschini*

Main category: cs.LG

TL;DR: FedUP 是一种新的联邦学习（FL）算法，可以有效地从全局模型中移除恶意客户端的影响，而无需重新训练。它通过识别和修剪模型中的特定连接来工作，即使在客户端可能存在恶意和共谋的情况下也是如此。FedUP 在各种攻击下都比现有方法更有效、更快速、更节省存储空间。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦学习（FL）容易受到模型投毒等攻击，其中对手会发送恶意的本地权重来破坏全局模型。联邦学习（FU）作为一种解决方案出现，可以通过选择性地消除已识别的恶意贡献者对全局模型的影响，而无需完全重新训练。然而，在客户端可能存在恶意和共谋的情况下应用 FU 是一个挑战，因为不能假设他们会合作进行数据移除。

Method: FedUP 是一种轻量级的联邦学习（FL）中的联邦学习（FU）算法，通过修剪被攻击模型中的特定连接来减轻恶意客户端的影响。它仅依赖于在 FU 之前最后一个训练轮次中的客户端权重来识别需要抑制的连接。为了解决良性和恶意客户端更新重叠的问题，FedUP 通过仔细选择和将最高幅度权重清零来隔离恶意影响，这些权重在良性和恶意客户端的最新更新之间存在最大分歧，同时保留良性信息。

Result: 在强对抗性威胁模型下（多达 50%-1 的客户端可能是恶意的，并完全了解聚合过程），FedUP 在 IID 和 Non-IID 数据、标签翻转和后门攻击等场景下进行了评估。实验证明了 FedUP 的有效性、鲁棒性和效率，并与最先进的 FU 解决方案进行了比较。结果表明，FedUP 降低了恶意客户端的影响，降低了恶意数据的准确性，同时保持了良性数据的性能，并且比最先进的解决方案更快、更节省存储空间。

Conclusion: FedUP 成功地减少了恶意客户端的影响，在不损害良性数据性能的情况下，将恶意数据的准确性降低到与从头开始重新训练的模型相匹配的水平。与最先进的联邦学习（FU）解决方案相比，FedUP 在效率、鲁棒性和存储使用方面都表现出色，并且在各种攻击场景下都非常有效。

Abstract: Federated Learning (FL) can be vulnerable to attacks, such as model
poisoning, where adversaries send malicious local weights to compromise the
global model. Federated Unlearning (FU) is emerging as a solution to address
such vulnerabilities by selectively removing the influence of detected
malicious contributors on the global model without complete retraining.
However, unlike typical FU scenarios where clients are trusted and cooperative,
applying FU with malicious and possibly colluding clients is challenging
because their collaboration in unlearning their data cannot be assumed. This
work presents FedUP, a lightweight FU algorithm designed to efficiently
mitigate malicious clients' influence by pruning specific connections within
the attacked model. Our approach achieves efficiency by relying only on
clients' weights from the last training round before unlearning to identify
which connections to inhibit. Isolating malicious influence is non-trivial due
to overlapping updates from benign and malicious clients. FedUP addresses this
by carefully selecting and zeroing the highest magnitude weights that diverge
the most between the latest updates from benign and malicious clients while
preserving benign information. FedUP is evaluated under a strong adversarial
threat model, where up to 50%-1 of the clients could be malicious and have full
knowledge of the aggregation process. We demonstrate the effectiveness,
robustness, and efficiency of our solution through experiments across IID and
Non-IID data, under label-flipping and backdoor attacks, and by comparing it
with state-of-the-art (SOTA) FU solutions. In all scenarios, FedUP reduces
malicious influence, lowering accuracy on malicious data to match that of a
model retrained from scratch while preserving performance on benign data. FedUP
achieves effective unlearning while consistently being faster and saving
storage compared to the SOTA.

</details>


### [179] [A Comprehensive Re-Evaluation of Biometric Modality Properties in the Modern Era](https://arxiv.org/abs/2508.13874)
*Rouqaiah Al-Refai,Pankaja Priya Ramasamy,Ragini Ramesh,Patricia Arias-Cabarcos,Philipp Terhörst*

Main category: cs.LG

TL;DR: 由于现有评估框架过时，本研究通过专家调查更新了生物识别模态的评估标准，发现人脸识别评级提升，指纹识别可靠性下降，并强调了结合专家意见和实证数据的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的生物识别评估框架（1998年的比较表）已过时，无法反映生物识别技术的最新发展和新兴的安全漏洞。因此，需要一个更新、更可靠的框架来评估生物识别模态在特定应用中的适用性。

Method: 通过对24位生物识别领域专家的调查问卷，收集他们对不同生物识别模态（如人脸、指纹等）的各项属性（如可靠性、易用性等）的评分。随后，对评分进行统计分析，考察专家意见的一致性，并将专家评估结果与55个生物识别数据集的经验数据进行比较。

Result: 专家调查结果显示，生物识别模态的属性评级发生了显著变化。例如，人脸识别由于技术进步而获得更高的评级，而指纹识别的可靠性因新兴漏洞和攻击而有所下降。专家评估在大部分属性上具有高度一致性，与数据集级不确定性也显示出良好的一致性。专家之间的分歧指出了当前研究中存在的关键挑战。

Conclusion: 该研究通过专家调查重新审视了生物识别模态的评估，结果显示随着技术的进步和新出现的漏洞，不同模态的评估标准发生了显著变化，例如人脸识别因技术进步而评级提高，而指纹因漏洞和攻击而可靠性下降。研究还发现专家评估与数据集级不确定性在大多数模态上高度一致，并强调了结合专家见解和实证证据的重要性。此外，识别出的专家分歧揭示了关键的开放性挑战，为未来的研究指明了方向。

Abstract: The rapid advancement of authentication systems and their increasing reliance
on biometrics for faster and more accurate user verification experience,
highlight the critical need for a reliable framework to evaluate the
suitability of biometric modalities for specific applications. Currently, the
most widely known evaluation framework is a comparative table from 1998, which
no longer adequately captures recent technological developments or emerging
vulnerabilities in biometric systems. To address these challenges, this work
revisits the evaluation of biometric modalities through an expert survey
involving 24 biometric specialists. The findings indicate substantial shifts in
property ratings across modalities. For example, face recognition, shows
improved ratings due to technological progress, while fingerprint, shows
decreased reliability because of emerging vulnerabilities and attacks. Further
analysis of expert agreement levels across rated properties highlighted the
consistency of the provided evaluations and ensured the reliability of the
ratings. Finally, expert assessments are compared with dataset-level
uncertainty across 55 biometric datasets, revealing strong alignment in most
modalities and underscoring the importance of integrating empirical evidence
with expert insight. Moreover, the identified expert disagreements reveal key
open challenges and help guide future research toward resolving them.

</details>


### [180] [Fisher-Orthogonal Projection Methods for Natural Gradient Descent with Large Batches](https://arxiv.org/abs/2508.13898)
*Yishun Lu,Wesley Armour*

Main category: cs.LG

TL;DR: A new technique called Fisher-Orthogonal Projection (FOP) allows for effective training of modern GPUs with very large batch sizes by improving upon existing optimizer methods.


<details>
  <summary>Details</summary>
Motivation: Most existing optimizers struggle to perform effectively at very large batch sizes (tens of thousands of samples) because gradient noise decreases, limiting first-order methods' ability to escape sharp minima, and second-order methods like KFAC require excessively high damping for stability, which diminishes their performance.

Method: FOP constructs a variance-aware update direction by leveraging gradients from two sub-batches, enhancing the average gradient with a component of the gradient difference that is orthogonal to the average under the Fisher-metric.

Result: FOP restores the effectiveness of second-order methods at very large batch sizes.

Conclusion: FOP enables scalable training with improved generalization and faster convergence at very large batch sizes.

Abstract: Modern GPUs are equipped with large amounts of high-bandwidth memory,
enabling them to support mini-batch sizes of up to tens of thousands of
training samples. However, most existing optimizers struggle to perform
effectively at such a large batch size. As batch size increases, gradient noise
decreases due to averaging over many samples, limiting the ability of
first-order methods to escape sharp or suboptimal minima and reach the global
minimum. Meanwhile, second-order methods like the natural gradient with
Kronecker-Factored Approximate Curvature (KFAC) often require excessively high
damping to remain stable at large batch sizes. This high damping effectively
washes out the curvature information that gives these methods their advantage,
reducing their performance to that of simple gradient descent. In this paper,
we introduce Fisher-Orthogonal Projection (FOP), a novel technique that
restores the effectiveness of the second-order method at very large batch
sizes, enabling scalable training with improved generalization and faster
convergence. FOP constructs a variance-aware update direction by leveraging
gradients from two sub-batches, enhancing the average gradient with a component
of the gradient difference that is orthogonal to the average under the
Fisher-metric.

</details>


### [181] [Revisiting Diffusion Q-Learning: From Iterative Denoising to One-Step Action Generation](https://arxiv.org/abs/2508.13904)
*Thanh Nguyen,Chang D. Yoo*

Main category: cs.LG

TL;DR: OFQL是一种改进的扩散模型，通过流匹配技术实现了单步动作生成，提高了训练和推理效率，同时保持甚至优于DQL的性能。


<details>
  <summary>Details</summary>
Motivation: DQL虽然在离线强化学习中表现出色，但其在训练和推理过程中依赖多步去噪生成动作，限制了其实际应用。直接应用单步去噪会导致性能显著下降。

Method: OFQL将DQL框架与样本高效的流匹配（FM）框架相结合，通过学习平均速度场来解决DQL在单步生成动作时性能下降的问题。

Result: OFQL在D4RL基准测试中，相比DQL和其他基于扩散的模型，取得了更好的性能，并显著减少了训练和推理时间。

Conclusion: OFQL通过学习平均速度场来实现一步生成，消除了DQL中多步采样和递归梯度更新的需要，从而实现了更快速、更鲁棒的训练和推理。实验证明OFQL在D4RL基准测试中优于DQL和其他基于扩散的模型，同时显著减少了训练和推理时间。

Abstract: The generative power of diffusion models (DMs) has recently enabled
high-performing decision-making algorithms in offline reinforcement learning
(RL), achieving state-of-the-art results across standard benchmarks. Among
them, Diffusion Q-Learning (DQL) stands out as a leading method for its
consistently strong performance. Nevertheless, DQL remains limited in practice
due to its reliance on multi-step denoising for action generation during both
training and inference. Although one-step denoising is desirable, simply
applying it to DQL leads to a drastic performance drop. In this work, we
revisit DQL and identify its core limitations. We then propose One-Step Flow
Q-Learning (OFQL), a novel framework that enables efficient one-step action
generation during both training and inference, without requiring auxiliary
models, distillation, or multi-phase training. Specifically, OFQL reformulates
DQL within the sample-efficient Flow Matching (FM) framework. While
conventional FM induces curved generative trajectories that impede one-step
generation, OFQL instead learns an average velocity field that facilitates
direct, accurate action generation. Collectively, OFQL eliminates the need for
multi-step sampling and recursive gradient updates in DQL, resulting in faster
and more robust training and inference. Extensive experiments on the D4RL
benchmark demonstrate that OFQL outperforms DQL and other diffusion-based
baselines, while substantially reducing both training and inference time
compared to DQL.

</details>


### [182] [Automated Energy-Aware Time-Series Model Deployment on Embedded FPGAs for Resilient Combined Sewer Overflow Management](https://arxiv.org/abs/2508.13905)
*Tianheng Ling,Vipin Singh,Chao Qian,Felix Biessmann,Gregor Schiele*

Main category: cs.LG

TL;DR: 为应对极端天气对污水系统的影响，该研究提出了一种可在边缘设备上运行的AI预测框架，使用轻量级、已压缩的Transformer或LSTM模型。Transformer精度更高但能耗也更高，LSTM能耗极低但精度稍差，研究者可根据需求权衡选择，以实现更可靠的污水管理。


<details>
  <summary>Details</summary>
Motivation: 为了应对气候变化加剧导致的极端天气事件对老旧合流污水系统的挑战，以及AI模型在云端运行的可靠性问题（在通信中断时受限），本研究旨在实现能够在边缘设备上进行节能推理的预测框架，以提高城市污水系统的韧性。

Method: 提出了一种端到端预测框架，集成轻量级Transformer和LSTM模型，并使用整数量化进行压缩，以实现节能推理。通过自动化的硬件感知部署流程，在AMD Spartan-7 XC7S15 FPGA上优化模型配置，同时最小化预测误差和能耗。

Result: 在实际污水数据上，所选的8位Transformer模型（在24小时历史数据上训练）实现了高精度（MSE 0.0376），能耗为0.370 mJ/次推理。而最优的8位LSTM模型能耗显著更低（0.009 mJ，低40倍以上），但精度稍差（MSE 0.0432），且训练时间更长。这表明LSTM适用于超低能耗场景，而Transformer适用于更高精度预测。

Conclusion: 该研究提出了一种端到端预测框架，可在边缘设备上进行节能推理，以应对城市污水系统面临的挑战。通过集成轻量级Transformer和LSTM模型，并采用整数量化进行压缩，实现了在FPGA上的高效运行。所选的8位Transformer模型在实际污水数据上表现出高精度（MSE 0.0376），能耗为0.370 mJ/次推理。而8位LSTM模型能耗更低（0.009 mJ），但精度稍逊（MSE 0.0432）。该研究强调了根据部署优先级的模型选择的重要性，为构建更具韧性的城市污水系统提供了本地化、节能的预测能力。

Abstract: Extreme weather events, intensified by climate change, increasingly challenge
aging combined sewer systems, raising the risk of untreated wastewater
overflow. Accurate forecasting of sewer overflow basin filling levels can
provide actionable insights for early intervention, helping mitigating
uncontrolled discharge. In recent years, AI-based forecasting methods have
offered scalable alternatives to traditional physics-based models, but their
reliance on cloud computing limits their reliability during communication
outages. To address this, we propose an end-to-end forecasting framework that
enables energy-efficient inference directly on edge devices. Our solution
integrates lightweight Transformer and Long Short-Term Memory (LSTM) models,
compressed via integer-only quantization for efficient on-device execution.
Moreover, an automated hardware-aware deployment pipeline is used to search for
optimal model configurations by jointly minimizing prediction error and energy
consumption on an AMD Spartan-7 XC7S15 FPGA. Evaluated on real-world sewer
data, the selected 8-bit Transformer model, trained on 24 hours of historical
measurements, achieves high accuracy (MSE 0.0376) at an energy cost of 0.370 mJ
per inference. In contrast, the optimal 8-bit LSTM model requires significantly
less energy (0.009 mJ, over 40x lower) but yields 14.89% worse accuracy (MSE
0.0432) and much longer training time. This trade-off highlights the need to
align model selection with deployment priorities, favoring LSTM for ultra-low
energy consumption or Transformer for higher predictive accuracy. In general,
our work enables local, energy-efficient forecasting, contributing to more
resilient combined sewer systems. All code can be found in the GitHub
Repository (https://github.com/tianheng-ling/EdgeOverflowForecast).

</details>


### [183] [Categorical Policies: Multimodal Policy Learning and Exploration in Continuous Control](https://arxiv.org/abs/2508.13922)
*SM Mazharul Islam,Manfred Huber*

Main category: cs.LG

TL;DR: 本文提出Categorical Policies来解决深度强化学习中策略单峰的问题，通过引入Categorical分布实现多模态行为，并在连续控制任务中取得了更好的探索和性能。


<details>
  <summary>Details</summary>
Motivation: 许多实际决策问题倾向于采用多模态策略以促进对环境的鲁棒探索，尤其是在连续控制领域，标准的参数化方式（仅依赖高斯分布）会限制学习行为为单峰，导致在奖励稀疏、动力学复杂或需要适应不同情境时学习困难。

Method: 本文提出Categorical Policies，通过引入一个中间的Categorical分布来模拟多模态行为，并基于采样模式生成输出动作。文章探讨了两种保证可微分离散潜在结构同时保持高效基于梯度的优化的采样方案。

Result: 实验结果表明，与标准高斯策略相比，本文提出的多模态策略在DeepMind Control Suite环境中具有更快的收敛速度和更好的性能，证明了Categorical分布在结构化探索和多模态行为表示方面的优势。

Conclusion: 本研究提出的Categorical Policies能够有效学习多模态行为，通过更好的探索能力，在DeepMind Control Suite环境中实现了更快的收敛速度和优于标准高斯策略的表现，证明了其在连续控制任务中的潜力和有效性。

Abstract: A policy in deep reinforcement learning (RL), either deterministic or
stochastic, is commonly parameterized as a Gaussian distribution alone,
limiting the learned behavior to be unimodal. However, the nature of many
practical decision-making problems favors a multimodal policy that facilitates
robust exploration of the environment and thus to address learning challenges
arising from sparse rewards, complex dynamics, or the need for strategic
adaptation to varying contexts. This issue is exacerbated in continuous control
domains where exploration usually takes place in the vicinity of the predicted
optimal action, either through an additive Gaussian noise or the sampling
process of a stochastic policy. In this paper, we introduce Categorical
Policies to model multimodal behavior modes with an intermediate categorical
distribution, and then generate output action that is conditioned on the
sampled mode. We explore two sampling schemes that ensure differentiable
discrete latent structure while maintaining efficient gradient-based
optimization. By utilizing a latent categorical distribution to select the
behavior mode, our approach naturally expresses multimodality while remaining
fully differentiable via the sampling tricks. We evaluate our multimodal policy
on a set of DeepMind Control Suite environments, demonstrating that through
better exploration, our learned policies converge faster and outperform
standard Gaussian policies. Our results indicate that the Categorical
distribution serves as a powerful tool for structured exploration and
multimodal behavior representation in continuous control.

</details>


### [184] [How Usable is Automated Feature Engineering for Tabular Data?](https://arxiv.org/abs/2508.13932)
*Bastian Schäfer,Lennart Purucker,Maciej Janowski,Frank Hutter*

Main category: cs.LG

TL;DR: 现有的自动特征工程方法难以使用，缺乏文档和社区支持，并且不支持时间/内存约束。未来的研究需要改进这些方面。


<details>
  <summary>Details</summary>
Motivation: 由于手动特征工程的成本高昂和耗时，人们投入了大量精力来自动化这一过程。然而，现有的自动特征工程（AutoFE）方法在供实践者使用的可用性方面从未得到过调查。

Method: 对53种自动特征工程方法进行了可用性调查，考察了易用性、文档、社区支持以及时间/内存约束设置等方面。

Result: 大多数自动特征工程方法都很难使用，缺乏文档，并且没有活跃的社区。此外，没有一种方法允许用户设置时间与内存约束，而这是可用自动化所必需的。

Conclusion: 现有自动特征工程方法在可用性方面存在不足，这阻碍了实践者对其的应用。未来的研究应致力于开发更易用、文档更完善、社区支持更活跃的自动特征工程方法，并支持用户设置时间与内存约束。

Abstract: Tabular data, consisting of rows and columns, is omnipresent across various
machine learning applications. Each column represents a feature, and features
can be combined or transformed to create new, more informative features. Such
feature engineering is essential to achieve peak performance in machine
learning. Since manual feature engineering is expensive and time-consuming, a
substantial effort has been put into automating it. Yet, existing automated
feature engineering (AutoFE) methods have never been investigated regarding
their usability for practitioners. Thus, we investigated 53 AutoFE methods. We
found that these methods are, in general, hard to use, lack documentation, and
have no active communities. Furthermore, no method allows users to set time and
memory constraints, which we see as a necessity for usable automation. Our
survey highlights the need for future work on usable, well-engineered AutoFE
methods.

</details>


### [185] [Convergent Reinforcement Learning Algorithms for Stochastic Shortest Path Problem](https://arxiv.org/abs/2508.13963)
*Soumyajit Guin,Shalabh Bhatnagar*

Main category: cs.LG

TL;DR: 提出用于随机最短路径（SSP）问题的表格和函数逼近算法，并证明了其收敛性、优越性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: SSP问题是强化学习（RL）中的一类重要问题，因为其他类型的成本标准可以在SSP的设置中得到解决。

Method: 提出了一种用于随机最短路径（SSP）问题的函数逼近算法，以及两种用于表格设置的算法。

Result: 我们的表格算法相比其他著名的收敛强化学习算法表现出更优越的性能，而我们的函数逼近算法在函数逼近设置中表现出可靠的性能。

Conclusion: 为所有算法展示渐近几率收敛性。

Abstract: In this paper we propose two algorithms in the tabular setting and an
algorithm for the function approximation setting for the Stochastic Shortest
Path (SSP) problem. SSP problems form an important class of problems in
Reinforcement Learning (RL), as other types of cost-criteria in RL can be
formulated in the setting of SSP. We show asymptotic almost-sure convergence
for all our algorithms. We observe superior performance of our tabular
algorithms compared to other well-known convergent RL algorithms. We further
observe reliable performance of our function approximation algorithm compared
to other algorithms in the function approximation setting.

</details>


### [186] [AutoScale: Linear Scalarization Guided by Multi-Task Optimization Metrics](https://arxiv.org/abs/2508.13979)
*Yi Yang,Kei Ikemura,Qingwen Zhang,Xiaomeng Zhu,Ci Li,Nazre Batool,Sina Sharif Mansouri,John Folkesson*

Main category: cs.LG

TL;DR: AutoScale框架通过连接线性标量化与MTO方法，利用MTO指标（如梯度幅度相似性）来指导权重选择，无需昂贵的搜索即可实现高效的多任务学习。


<details>
  <summary>Details</summary>
Motivation: 探究线性标量化在多任务学习中的表现，以及如何确定最优权重，克服现有方法依赖穷举超参数搜索的局限性。

Method: 提出了一种名为AutoScale的两阶段框架，利用MTO指标来指导线性标量化权重选择。

Result: AutoScale框架在多个数据集（包括一个新的大规模基准）上持续展现出优越的性能和高效率。

Conclusion: AutoScale框架通过利用MTO指标（如高梯度幅度相似性）来指导线性标量化权重选择，实现了无需昂贵权重搜索的高效性能。

Abstract: Recent multi-task learning studies suggest that linear scalarization, when
using well-chosen fixed task weights, can achieve comparable to or even better
performance than complex multi-task optimization (MTO) methods. It remains
unclear why certain weights yield optimal performance and how to determine
these weights without relying on exhaustive hyperparameter search. This paper
establishes a direct connection between linear scalarization and MTO methods,
revealing through extensive experiments that well-performing scalarization
weights exhibit specific trends in key MTO metrics, such as high gradient
magnitude similarity. Building on this insight, we introduce AutoScale, a
simple yet effective two-phase framework that uses these MTO metrics to guide
weight selection for linear scalarization, without expensive weight search.
AutoScale consistently shows superior performance with high efficiency across
diverse datasets including a new large-scale benchmark.

</details>


### [187] [Multi-User Contextual Cascading Bandits for Personalized Recommendation](https://arxiv.org/abs/2508.13981)
*Jiho Park,Huiwen Jia*

Main category: cs.LG

TL;DR: 该研究提出了多用户上下文级联老虎机（MCCB）框架，以解决在线广告中的多用户顺序交互问题。提出了UCBBP和AUCBBP两种算法，AUCBBP在用户扩展方面效率更高，并通过数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在线广告场景中，多个用户同时与顺序展示的物品进行交互，而经典的上下文老虎机模型无法完全捕捉这种复杂的交互。

Method: 研究提出了两种算法：1. 提出了一种适用于该场景的UCB风格算法，称为带向后规划的上限信赖边界（UCBBP），并证明了其具有$\\\text{regret} = \\\	ext{O}(\\\\\sqrt{THN})$的界限。 2. 提出了另一种称为带向后规划的主动上限信赖边界（AUCBBP），其具有\\\text{regret} = \\\text{O}(\\\\\sqrt{T+HN})的界限，在上下文扩展（即用户扩展）方面具有严格的效率提升。

Result: 理论分析表明，UCBBP算法的遗憾界限为$\\\text{O}(\\\\\sqrt{THN})$，AUCBBP算法的遗憾界限为$\\\text{O}(\\\\\sqrt{T+HN})$。数值实验验证了两种算法在不同设置下的有效性。

Conclusion: 该研究提出了一个用于在线广告的多用户上下文级联老虎机（MCCB）框架，并设计了两种算法UCBBP和AUCBBP。AUCBBP在用户扩展方面表现出严格的效率提升。

Abstract: We introduce a Multi-User Contextual Cascading Bandit model, a new
combinatorial bandit framework that captures realistic online advertising
scenarios where multiple users interact with sequentially displayed items
simultaneously. Unlike classical contextual bandits, MCCB integrates three key
structural elements: (i) cascading feedback based on sequential arm exposure,
(ii) parallel context sessions enabling selective exploration, and (iii)
heterogeneous arm-level rewards. We first propose Upper Confidence Bound with
Backward Planning (UCBBP), a UCB-style algorithm tailored to this setting, and
prove that it achieves a regret bound of $\widetilde{O}(\sqrt{THN})$ over $T$
episodes, $H$ session steps, and $N$ contexts per episode. Motivated by the
fact that many users interact with the system simultaneously, we introduce a
second algorithm, termed Active Upper Confidence Bound with Backward Planning
(AUCBBP), which shows a strict efficiency improvement in context scaling, i.e.,
user scaling, with a regret bound of $\widetilde{O}(\sqrt{T+HN})$. We validate
our theoretical findings via numerical experiments, demonstrating the empirical
effectiveness of both algorithms under various settings.

</details>


### [188] [Formal Algorithms for Model Efficiency](https://arxiv.org/abs/2508.14000)
*Naman Tyagi,Srishti Das,Kunal,Vatsal Gupta*

Main category: cs.LG

TL;DR: KMR是一个统一的框架，用于表示和推理深度学习中的模型效率技术，如剪枝、量化、知识蒸馏和参数高效架构。它通过将这些技术抽象为可控旋钮、确定性规则和可测量仪表，实现了技术之间的系统组合、策略驱动的应用和迭代预算优化。KMR为模型效率研究提供了一个概念和实践工具。


<details>
  <summary>Details</summary>
Motivation: 为了统一和推进模型效率研究，需要一个能够表示和推理深度学习中各种模型效率技术的通用框架。

Method: 提出了一种名为Knob-Meter-Rule (KMR) 的统一形式主义，将剪枝、量化、知识蒸馏和参数高效架构等多种技术抽象为可控旋钮、确定性规则和可测量仪表，并通过Budgeted-KMR算法实现了系统组合、策略驱动应用和迭代预算优化。

Result: 展示了如何将已知的效率方法实例化为KMR三元组，并为每种方法提供了简洁的算法模板，突出了方法之间的潜在关系，促进了混合流水线的构建。

Conclusion: KMR为深度学习中的模型效率技术提供了一个统一的、数学上精确的、模块化的形式主义，支持组合、策略驱动的应用和迭代优化，并为未来研究奠定了基础。

Abstract: We introduce the Knob-Meter-Rule (KMR) framework, a unified formalism for
representing and reasoning about model efficiency techniques in deep learning.
By abstracting diverse methods, including pruning, quantization, knowledge
distillation, and parameter-efficient architectures, into a consistent set of
controllable knobs, deterministic rules, and measurable meters, KMR provides a
mathematically precise and modular perspective on efficiency optimization. The
framework enables systematic composition of multiple techniques, flexible
policy-driven application, and iterative budgeted optimization through the
Budgeted-KMR algorithm. We demonstrate how well-known efficiency methods can be
instantiated as KMR triples and present concise algorithmic templates for each.
The framework highlights underlying relationships between methods, facilitates
hybrid pipelines, and lays the foundation for future research in automated
policy learning, dynamic adaptation, and theoretical analysis of cost-quality
trade-offs. Overall, KMR offers both a conceptual and practical tool for
unifying and advancing model efficiency research.

</details>


### [189] [ASDFormer: A Transformer with Mixtures of Pooling-Classifier Experts for Robust Autism Diagnosis and Biomarker Discovery](https://arxiv.org/abs/2508.14005)
*Mohammad Izadi,Mehran Safayani*

Main category: cs.LG

TL;DR: ASDFormer是一种新的Transformer模型，利用混合专家模型来识别自闭症谱系障碍（ASD）的大脑连接模式，并在ABIDE数据集上实现了最先进的诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 功能性MRI（fMRI）通过测量大脑的血氧水平依赖（BOLD）信号，为大规模神经动力学提供了一个非侵入性的窗口。这些信号可以被建模为感兴趣区域（ROIs）之间的相互作用，这些区域根据它们在大脑功能中的作用被分组为功能社区。越来越多的证据表明，这些社区内部和之间的连接模式对ASD相关的改变特别敏感。有效捕获这些模式并识别与典型发育不同的相互作用对于改善ASD诊断和实现生物标志物发现至关重要。

Method: ASDFormer是一种基于Transformer的架构，它结合了混合池化分类专家（MoE）来捕获与ASD相关的神经特征。通过整合多个专门的专家分支和注意力机制，ASDFormer能够自适应地强调与自闭症相关的不同大脑区域和连接模式。

Result: ASDFormer实现了最先进的诊断准确性，并揭示了与ASD相关的functional connectivity disruptions的有力见解，突显了其作为生物标志物发现工具的潜力。

Conclusion: ASDFormer在ABIDE数据集上实现了最先进的诊断准确性，并揭示了与ASD相关的 ود functional connectivity disruptions 的有力见解，突显了其作为生物标志物发现工具的潜力。

Abstract: Autism Spectrum Disorder (ASD) is a complex neurodevelopmental condition
marked by disruptions in brain connectivity. Functional MRI (fMRI) offers a
non-invasive window into large-scale neural dynamics by measuring
blood-oxygen-level-dependent (BOLD) signals across the brain. These signals can
be modeled as interactions among Regions of Interest (ROIs), which are grouped
into functional communities based on their underlying roles in brain function.
Emerging evidence suggests that connectivity patterns within and between these
communities are particularly sensitive to ASD-related alterations. Effectively
capturing these patterns and identifying interactions that deviate from typical
development is essential for improving ASD diagnosis and enabling biomarker
discovery. In this work, we introduce ASDFormer, a Transformer-based
architecture that incorporates a Mixture of Pooling-Classifier Experts (MoE) to
capture neural signatures associated with ASD. By integrating multiple
specialized expert branches with attention mechanisms, ASDFormer adaptively
emphasizes different brain regions and connectivity patterns relevant to
autism. This enables both improved classification performance and more
interpretable identification of disorder-related biomarkers. Applied to the
ABIDE dataset, ASDFormer achieves state-of-the-art diagnostic accuracy and
reveals robust insights into functional connectivity disruptions linked to ASD,
highlighting its potential as a tool for biomarker discovery.

</details>


### [190] [Typed Topological Structures Of Datasets](https://arxiv.org/abs/2508.14008)
*Wanjun Hu*

Main category: cs.LG

TL;DR: This paper proposes a new method using 'typed topology' to analyze datasets, representing their structure with tracks, components, and branches, which enables new algorithms for tasks like clustering and anomaly detection.


<details>
  <summary>Details</summary>
Motivation: Current research on datasets uses statistical and algebraic topological methods. This paper introduces a new approach from the general topology perspective by using typed topological spaces to study finite topological spaces, like datasets, and investigate their inner structure.

Method: The paper introduces a new method using typed topological spaces, specifically developing a special set of types and its related typed topology on a dataset X in R^2. This allows for the investigation of the dataset's inner structure by organizing it into tracks and components, which can be represented by integer sequences and pseudotrees.

Result: The typed topology allows for the organization of datasets into tracks and components, with components having an order and being representable by integer sequences. Branches formed by components crossing tracks can be represented by typed-II pseudotrees, providing a platform for new algorithms.

Conclusion: The proposed typed topology on datasets can represent inner structures like tracks, components, and branches, leading to new algorithms for convex hull, holes, clustering, and anomaly detection.

Abstract: A datatset $X$ on $R^2$ is a finite topological space. Current research of a
dataset focuses on statistical methods and the algebraic topological method
\cite{carlsson}. In \cite{hu}, the concept of typed topological space was
introduced and showed to have the potential for studying finite topological
spaces, such as a dataset. It is a new method from the general topology
perspective. A typed topological space is a topological space whose open sets
are assigned types. Topological concepts and methods can be redefined using
open sets of certain types. In this article, we develop a special set of types
and its related typed topology on a dataset $X$. Using it, we can investigate
the inner structure of $X$. In particular, $R^2$ has a natural quotient space,
in which $X$ is organized into tracks, and each track is split into components.
Those components are in a order. Further, they can be represented by an integer
sequence. Components crossing tracks form branches, and the relationship can be
well represented by a type of pseudotree (called typed-II pseudotree). Such
structures provide a platform for new algorithms for problems such as
calculating convex hull, holes, clustering and anomaly detection.

</details>


### [191] [Efficient Knowledge Graph Unlearning with Zeroth-order Information](https://arxiv.org/abs/2508.14013)
*Yang Xiao,Ruimeng Ye,Bohan Liu,Xiaolong Ma,Bo Hui*

Main category: cs.LG

TL;DR: 由于“被遗忘权”等法规，人们需要从模型中移除训练数据及其影响。知识图谱（KG）的非学习由于其独特的结构和实体之间的语义关系而具有挑战性。我们提出了一种有效的 KG 非学习算法，该算法通过泰勒展开估计参数变化，并使用 Fisher 矩阵和零阶优化来近似逆 Hessian 向量积，从而无需计算昂贵的导数。我们的实验结果表明，该方法在非学习效率和质量方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于像“被遗忘权”这样的法规，从模型中移除训练数据及其影响的需求日益增长。然而，完全的重新训练成本高昂，因此人们提出了各种机器非学习方法。知识图谱（KG）的非学习由于其独特的结构和实体之间的语义关系而具有挑战性，并且通过估计移除组件的影响来进行非学习会产生显著的计算开销。

Method: 提出了一种知识图谱（KG）的有效非学习算法，通过泰勒展开来估计数据移除引起的变化，并使用 Fisher 矩阵和零阶优化来近似逆 Hessian 向量积，而无需构建计算图。

Result: 提出的方法在学习效率和学习质量方面显著优于其他最先进的图学习基线。

Conclusion: 所提出的方法在学习效率和学习质量方面显著优于其他最先进的图学习基线。

Abstract: Due to regulations like the Right to be Forgotten, there is growing demand
for removing training data and its influence from models. Since full retraining
is costly, various machine unlearning methods have been proposed. In this
paper, we firstly present an efficient knowledge graph (KG) unlearning
algorithm. We remark that KG unlearning is nontrivial due to the distinctive
structure of KG and the semantic relations between entities. Also, unlearning
by estimating the influence of removed components incurs significant
computational overhead when applied to large-scale knowledge graphs. To this
end, we define an influence function for KG unlearning and propose to
approximate the model's sensitivity without expensive computation of
first-order and second-order derivatives for parameter updates. Specifically,
we use Taylor expansion to estimate the parameter changes caused by data
removal. Given that the first-order gradients and second-order derivatives
dominate the computational load, we use the Fisher matrices and zeroth-order
optimization to approximate the inverse-Hessian vector product without
constructing the computational graphs. Our experimental results demonstrate
that the proposed method outperforms other state-of-the-art graph unlearning
baselines significantly in terms of unlearning efficiency and unlearning
quality. Our code is released at https://github.com/NKUShaw/ZOWFKGIF.

</details>


### [192] [BLIPs: Bayesian Learned Interatomic Potentials](https://arxiv.org/abs/2508.14022)
*Dario Coscia,Pim de Haan,Max Welling*

Main category: cs.LG

TL;DR: 提出BLIPs框架，通过贝叶斯学习提升MLIPs在数据稀疏或分布外情况下的预测精度和不确定性估计能力。


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习原子间势（MLIPs）在处理分布外数据或数据稀疏情况下预测能力不足，且无法提供不确定性估计，这限制了它们在模拟化学中的应用，特别是指导主动学习和确保模拟结果的准确性。

Method: 提出了一种名为BLIPs（Bayesian Learned Interatomic Potentials）的框架，该框架基于自适应变分Dropout，能够为机器学习原子间势（MLIPs）提供可扩展、与架构无关的贝叶斯学习框架，用于训练或微调MLIPs，从而产生校准良好的不确定性估计，并且在推理时具有最小的计算开销。

Result: BLIPs框架能够提供可靠的不确定性估计，并且在能量和力预测方面具有最小的计算开销，与（等变）消息传递架构无缝集成。在模拟化学任务上的实证结果表明，相比标准的MLIPs，BLIPs在预测精度上有所提高，尤其是在数据稀疏或分布外（out-of-distribution）的条件下，其不确定性估计更值得信赖。此外，使用BLIPs微调预训练的MLIPs可以带来持续的性能提升和校准的不确定性。

Conclusion: BLIPs框架在模拟化学任务中展现出优越的预测精度和可靠的不确定性估计，尤其在数据稀疏或分布外（out-of-distribution）的场景下，能有效提升模型性能。

Abstract: Machine Learning Interatomic Potentials (MLIPs) are becoming a central tool
in simulation-based chemistry. However, like most deep learning models, MLIPs
struggle to make accurate predictions on out-of-distribution data or when
trained in a data-scarce regime, both common scenarios in simulation-based
chemistry. Moreover, MLIPs do not provide uncertainty estimates by
construction, which are fundamental to guide active learning pipelines and to
ensure the accuracy of simulation results compared to quantum calculations. To
address this shortcoming, we propose BLIPs: Bayesian Learned Interatomic
Potentials. BLIP is a scalable, architecture-agnostic variational Bayesian
framework for training or fine-tuning MLIPs, built on an adaptive version of
Variational Dropout. BLIP delivers well-calibrated uncertainty estimates and
minimal computational overhead for energy and forces prediction at inference
time, while integrating seamlessly with (equivariant) message-passing
architectures. Empirical results on simulation-based computational chemistry
tasks demonstrate improved predictive accuracy with respect to standard MLIPs,
and trustworthy uncertainty estimates, especially in data-scarse or heavy
out-of-distribution regimes. Moreover, fine-tuning pretrained MLIPs with BLIP
yields consistent performance gains and calibrated uncertainties.

</details>


### [193] [Learning from Preferences and Mixed Demonstrations in General Settings](https://arxiv.org/abs/2508.14027)
*Jason R Brown,Carl Henrik Ek,Robert D Mullins*

Main category: cs.LG

TL;DR: LEOPARD是一种新的强化学习算法，可以从偏好和演示反馈中学习奖励函数，并且在实践中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在复杂的强化学习任务中，设计一个好的奖励函数往往很困难。虽然偏好反馈或专家演示可以作为替代，但现有方法在同时利用两者时，通常是临时的、依赖领域特定属性或无法扩展。

Method: 提出了一种名为“奖励合理偏序关系”的新框架，并在此基础上开发了一种名为LEOPARD的算法，用于从偏好和排序演示中学习估计目标。

Result: LEOPARD可以从包括负面演示在内的各种数据中学习，并能在广泛的领域中有效地学习奖励函数。

Conclusion: LEOPARD算法在有限的偏好和演示反馈可用时，显著优于现有基线。此外，该算法还有助于研究与仅使用单一反馈类型相比，从多种反馈类型中学习，并且通常结合反馈类型是有益的。

Abstract: Reinforcement learning is a general method for learning in sequential
settings, but it can often be difficult to specify a good reward function when
the task is complex. In these cases, preference feedback or expert
demonstrations can be used instead. However, existing approaches utilising both
together are often ad-hoc, rely on domain-specific properties, or won't scale.
We develop a new framing for learning from human data, \emph{reward-rational
partial orderings over observations}, designed to be flexible and scalable.
Based on this we introduce a practical algorithm, LEOPARD: Learning Estimated
Objectives from Preferences And Ranked Demonstrations. LEOPARD can learn from a
broad range of data, including negative demonstrations, to efficiently learn
reward functions across a wide range of domains. We find that when a limited
amount of preference and demonstration feedback is available, LEOPARD
outperforms existing baselines by a significant margin. Furthermore, we use
LEOPARD to investigate learning from many types of feedback compared to just a
single one, and find that combining feedback types is often beneficial.

</details>


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [194] [EvoVerilog: Large Langugage Model Assisted Evolution of Verilog Code](https://arxiv.org/abs/2508.13156)
*Ping Guo,Yiting Wang,Wanghao Ye,Yexiao He,Ziyao Wang,Xiaopeng Dai,Ang Li,Qingfu Zhang*

Main category: cs.AR

TL;DR: EvoVerilog框架利用LLM和进化算法自动生成和优化Verilog代码，无需人工干预，性能优于现有方法，并能探索多样化设计。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM自动化硬件设计方法依赖人工干预和数据集微调，限制了可扩展性。新兴的迭代搜索技术探索设计方案的局限性，且可能不如重复提示等简单方法。

Method: EvoVerilog框架采用基于种群的多目标搜索策略，结合LLM的推理能力和进化算法，无需人工干预即可自动生成和优化Verilog代码。

Result: EvoVerilog在VerilogEval-Machine和VerilogEval-Human基准测试中分别取得了89.1%和80.2%的pass@10分数，实现了最先进的性能，并能同时生成多样化的功能Verilog代码并优化资源利用率。

Conclusion: EvoVerilog框架结合了LLM的推理能力和进化算法，能够自动生成和优化Verilog代码，实现了最先进的性能，并在VerilogEval-Machine和VerilogEval-Human基准测试中分别取得了89.1%和80.2%的pass@10分数。此外，该框架还能同时生成多种功能性的Verilog代码并优化资源利用率，展现了探索多样化设计的潜力。

Abstract: Large Language Models (LLMs) have demonstrated great potential in automating
the generation of Verilog hardware description language code for hardware
design. This automation is critical to reducing human effort in the complex and
error-prone process of hardware design.
  However, existing approaches predominantly rely on human intervention and
fine-tuning using curated datasets, limiting their scalability in automated
design workflows.
  Although recent iterative search techniques have emerged, they often fail to
explore diverse design solutions and may underperform simpler approaches such
as repeated prompting.
  To address these limitations, we introduce EvoVerilog, a novel framework that
combines the reasoning capabilities of LLMs with evolutionary algorithms to
automatically generate and refine Verilog code.
  EvoVerilog utilizes a multiobjective, population-based search strategy to
explore a wide range of design possibilities without requiring human
intervention.
  Extensive experiments demonstrate that EvoVerilog achieves state-of-the-art
performance, with pass@10 scores of 89.1 and 80.2 on the VerilogEval-Machine
and VerilogEval-Human benchmarks, respectively. Furthermore, the framework
showcases its ability to explore diverse designs by simultaneously generating a
variety of functional Verilog code while optimizing resource utilization.

</details>


### [195] [Image2Net: Datasets, Benchmark and Hybrid Framework to Convert Analog Circuit Diagrams into Netlists](https://arxiv.org/abs/2508.13157)
*Haohang Xu,Chengjie Liu,Qihang Wang,Wenhao Huang,Yongjian Xu,Weiyu Chen,Anlan Peng,Zhijun Li,Bo Li,Lei Qi,Jun Yang,Yuan Du,Li Du*

Main category: cs.AR

TL;DR: 本研究提出了一种新的数据集和名为Image2Net的混合框架，用于将电路图转换为网表，解决了现有方法的局限性，并取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在模拟集成电路（IC）设计方面潜力巨大，但其知识的丰富依赖于文本描述的模拟IC。然而，现有的模拟IC大多以图像电路图而非文本网表的形式存在。因此，将电路图转换为网表对于LLM来说至关重要，但现有方法在支持图像风格和电路元件方面存在局限性。

Method: 提出了一种新的、具有丰富风格和平衡分布的电路图数据集，并设计了一个名为Image2Net的混合框架，结合了NED指标来从电路图转换到网表。

Result: Image2Net在所提出的基准测试中实现了80.77%的成功率，比先前的工作提高了34.62%-45.19%。此外，所提出的Image2Net的平均NED为0.116，比现有技术水平低62.1%-69.6%。

Conclusion: 该研究提出了一种名为Image2Net的混合框架，用于将电路图转换为网表，并引入了网表编辑距离（NED）指标来评估转换精度。

Abstract: Large Language Model (LLM) exhibits great potential in designing of analog
integrated circuits (IC) because of its excellence in abstraction and
generalization for knowledge. However, further development of LLM-based analog
ICs heavily relies on textual description of analog ICs, while existing analog
ICs are mostly illustrated in image-based circuit diagrams rather than
text-based netlists. Converting circuit diagrams to netlists help LLMs to
enrich the knowledge of analog IC. Nevertheless, previously proposed conversion
frameworks face challenges in further application because of limited support of
image styles and circuit elements. Up to now, it still remains a challenging
task to effectively convert complex circuit diagrams into netlists. To this
end, this paper constructs and opensources a new dataset with rich styles of
circuit diagrams as well as balanced distribution of simple and complex analog
ICs. And a hybrid framework, named Image2Net, is proposed for practical
conversion from circuit diagrams to netlists. The netlist edit distance (NED)
is also introduced to precisely assess the difference between the converted
netlists and ground truth. Based on our benchmark, Image2Net achieves 80.77\%
successful rate, which is 34.62\%-45.19\% higher than previous works.
Specifically, the proposed work shows 0.116 averaged NED, which is
62.1\%-69.6\% lower than state-of-the-arts.

</details>


### [196] [Fine Grain 3D Integration for Microarchitecture Design Through Cube Packing Exploration](https://arxiv.org/abs/2508.13158)
*Yongxiang Liu,Yuchun Ma,Eren Kurshan,Glenn Reinman,Jason Cong*

Main category: cs.AR

TL;DR: 通过允许逻辑块跨越多个硅层并进行热感知优化，实现了 3D IC 的性能提升和功耗降低。


<details>
  <summary>Details</summary>
Motivation: 解决传统二维集成电路和三维集成电路（单层块）在互连缩减和性能提升方面的局限性，并提供温度管理。

Method: 开发了一个立方体打包引擎，并采用热感知地板规划和热通孔插入技术。

Result: 与二维设计相比，性能提高了 36%（以 BIPS 为单位）；与三维单层块设计相比，性能提高了 14%；与三维单层块设计相比，功耗降低了高达 30%；峰值温度保持在限制范围内。

Conclusion: 提出了一种三维集成电路（3D IC）设计方法，其中每个逻辑块可以跨越多个硅层，并开发了一个立方体打包引擎，可以同时优化物理和架构设计，以实现性能、面积和温度方面的有效利用。

Abstract: Most previous 3D IC research focused on stacking traditional 2D silicon
layers, so the interconnect reduction is limited to inter-block delays. In this
paper, we propose techniques that enable efficient exploration of the 3D design
space where each logical block can span more than one silicon layers. Although
further power and performance improvement is achievable through fine grain 3D
integration, the necessary modeling and tool infrastructure has been mostly
missing. We develop a cube packing engine which can simultaneously optimize
physical and architectural design for effective utilization of 3D in terms of
performance, area and temperature. Our experimental results using a design
driver show 36% performance improvement (in BIPS) over 2D and 14% over 3D with
single layer blocks. Additionally multi-layer blocks can provide up to 30%
reduction in power dissipation compared to the single-layer alternatives. Peak
temperature of the design is kept within limits as a result of thermal-aware
floorplanning and thermal via insertion techniques.

</details>


### [197] [Accelerating Transistor-Level Simulation of Integrated Circuits via Equivalence of RC Long-Chain Structures](https://arxiv.org/abs/2508.13159)
*Ruibai Tang,Wenlai Zhao*

Main category: cs.AR

TL;DR: 提出RC长链结构降阶方法，提升仿真性能。


<details>
  <summary>Details</summary>
Motivation: 晶体管级仿真对于验证集成电路物理正确性至关重要，但计算成本高昂。RC长链结构占基准电路总节点的6.34%（最高12%）。

Method: 提出三种针对不同时间常数尺度RC长链结构的降阶方法。

Result: 实验结果表明，所提出的方法在仿真包含ALU、加法器、乘法器、SEC/DED校验器和中断控制器等多种功能模块的基准电路上，平均性能提升了8.8%（最高22%），相对误差仅为0.7%。

Conclusion: 提出的三种新颖降阶方法能够有效提高RC长链结构仿真性能，平均提升8.8%（最高22%），相对误差仅为0.7%。

Abstract: Transistor-level simulation plays a vital role in validating the physical
correctness of integrated circuits. However, such simulations are
computationally expensive. This paper proposes three novel reduction methods
specifically tailored to RC long-chain structures with different scales of time
constant. Such structures account for an average of 6.34\% (up to 12\%) of the
total nodes in the benchmark circuits. Experimental results demonstrate that
our methods yields an average performance improvement of 8.8\% (up to 22\%) on
simulating benchmark circuits which include a variety of functional modules
such as ALUs, adders, multipliers, SEC/DED checkers, and interrupt controllers,
with only 0.7\% relative error.

</details>


### [198] [Through Silicon Via Aware Design Planning for Thermally Efficient 3-D Integrated Circuits](https://arxiv.org/abs/2508.13160)
*Yibo Chen,Eren Kurshan,Dave Motschman,Charles Johnson,Yuan Xie*

Main category: cs.AR

TL;DR: 3-D ICs have TSVs for better performance, but dense TSVs can cause heat problems. This paper suggests a placement technique to reduce this heat issue.


<details>
  <summary>Details</summary>
Motivation: To address the lateral thermal blockage effect in 3-D ICs, which becomes increasingly important for TSV via farms as TSV size and pitch scale down, potentially exacerbating local hotspots.

Method: Proposing a thermal-aware via farm placement technique.

Result: The proposed technique aims to minimize lateral heat blockages caused by dense signal bus TSV structures.

Conclusion: The paper proposes a thermal-aware via farm placement technique to minimize lateral heat blockages caused by dense signal bus TSV structures in 3-D ICs, addressing the increasing importance of the lateral thermal blockage effect in scaled TSV farms.

Abstract: 3-D integrated circuits (3-D ICs) offer performance advantages due to their
increased bandwidth and reduced wire-length enabled by through-silicon-via
structures (TSVs). Traditionally TSVs have been considered to improve the
thermal conductivity in the vertical direction. However, the lateral thermal
blockage effect becomes increasingly important for TSV via farms (a cluster of
TSV vias used for signal bus connections between layers) because the TSV size
and pitch continue to scale in {\mu}m range and the metal to insulator ratio
becomes smaller. Consequently, dense TSV farms can create lateral thermal
blockages in thinned silicon substrate and exacerbate the local hotspots. In
this paper, we propose a thermal-aware via farm placement technique for 3-D ICs
to minimize lateral heat blockages caused by dense signal bus TSV structures.

</details>


### [199] [Piano: A Multi-Constraint Pin Assignment-Aware Floorplanner](https://arxiv.org/abs/2508.13161)
*Zhexuan Xu,Kexin Zhou,Jie Wang,Zijie Geng,Siyuan Xu,Shixiong Kai,Mingxuan Yuan,Feng Wu*

Main category: cs.AR

TL;DR: Piano是一个地板设计框架，可以同时优化布局和引脚分配，以应对现代VLSI设计中的多种约束。


<details>
  <summary>Details</summary>
Motivation: 传统的地板设计器在现代约束（如固定轮廓要求、空白移除和预放置模块）下，常常忽略了引脚分配问题，而引脚分配对后续的详细布局和布线阶段有重要影响。本研究旨在解决这一问题。

Method:  Piano采用图论方法，基于模块间的几何关系和连接关系构建图，并通过迭代搜索最短路径来确定引脚分配。该方法还包括空白移除策略和三个局部优化器，以在多约束场景下优化布局指标。

Result: 实验结果表明，Piano框架在HPWL、通道线长度、通道模块数量和未放置引脚方面均有显著改善，同时保持了零空白。

Conclusion: Piano框架能够同时优化模块布局和引脚分配，在固定轮廓要求、去除空白和预放置模块等多种约束下，实现了HPWL的平均减少6.81%，通道线长度减少13.39%，通道模块数量减少16.36%，未放置引脚减少21.21%，同时保持零空白。

Abstract: Floorplanning is a critical step in VLSI physical design, increasingly
complicated by modern constraints such as fixed-outline requirements,
whitespace removal, and the presence of pre-placed modules. In addition, the
assignment of pins on module boundaries significantly impacts the performance
of subsequent stages, including detailed placement and routing. However,
traditional floorplanners often overlook pin assignment with modern constraints
during the floorplanning stage. In this work, we introduce Piano, a
floorplanning framework that simultaneously optimizes module placement and pin
assignment under multiple constraints. Specifically, we construct a graph based
on the geometric relationships among modules and their netlist connections,
then iteratively search for shortest paths to determine pin assignments. This
graph-based method also enables accurate evaluation of feedthrough and unplaced
pins, thereby guiding overall layout quality. To further improve the design, we
adopt a whitespace removal strategy and employ three local optimizers to
enhance layout metrics under multi-constraint scenarios. Experimental results
on widely used benchmark circuits demonstrate that Piano achieves an average
6.81% reduction in HPWL, a 13.39% decrease in feedthrough wirelength, a 16.36%
reduction in the number of feedthrough modules, and a 21.21% drop in unplaced
pins, while maintaining zero whitespace.

</details>


### [200] [FedChip: Federated LLM for Artificial Intelligence Accelerator Chip Design](https://arxiv.org/abs/2508.13162)
*Mahmoud Nazzal,Khoa Nguyen,Deepak Vungarala,Ramtin Zand,Shaahin Angizi,Hai Phan,Abdallah Khreishah*

Main category: cs.AR

TL;DR: FedChip是一种联邦学习方法，通过在保护隐私的情况下协作训练LLM来自动化AI硬件设计，提高了设计质量。


<details>
  <summary>Details</summary>
Motivation: AI硬件设计的快速发展需要更快速、更高效、更易于访问的设计流程。LLM有潜力实现这一点，但面临数据隐私和领域特定训练的挑战。

Method: FedChip是一种联邦微调方法，允许各方在保护专有数据的情况下，就用于自动化硬件设计生成的共享LLM进行协作。

Result: FedChip在设计质量方面比高端LLM提高了77%以上，同时保持了数据隐私。APTPU-Gen数据集和Chip@k评估指标也得到了开发和提出。

Conclusion: FedChip通过在保护数据隐私的同时协作改进共享的LLM，显着提高了AI硬件设计的自动化水平，使设计质量提高了77%以上。

Abstract: AI hardware design is advancing rapidly, driven by the promise of design
automation to make chip development faster, more efficient, and more accessible
to a wide range of users. Amongst automation tools, Large Language Models
(LLMs) offer a promising solution by automating and streamlining parts of the
design process. However, their potential is hindered by data privacy concerns
and the lack of domain-specific training. To address this, we introduce
FedChip, a Federated fine-tuning approach that enables multiple Chip design
parties to collaboratively enhance a shared LLM dedicated for automated
hardware design generation while protecting proprietary data. FedChip enables
parties to train the model on proprietary local data and improve the shared
LLM's performance. To exemplify FedChip's deployment, we create and release
APTPU-Gen, a dataset of 30k design variations spanning various performance
metric values such as power, performance, and area (PPA). To encourage the LLM
to generate designs that achieve a balance across multiple quality metrics, we
propose a new design evaluation metric, Chip@k, which statistically evaluates
the quality of generated designs against predefined acceptance criteria.
Experimental results show that FedChip improves design quality by more than 77%
over high-end LLMs while maintaining data privacy

</details>


### [201] [Low-power, Energy-efficient, Cardiologist-level Atrial Fibrillation Detection for Wearable Devices](https://arxiv.org/abs/2508.13181)
*Dominik Loroch,Johannes Feldmann,Vladimir Rybalkin,Norbert Wehn*

Main category: cs.AR

TL;DR: 开发了一种低功耗（3.8mW）、长续航（三周以上）、高精度（95%）的可穿戴设备，用于早期检测房颤，准确率超越专家水平。


<details>
  <summary>Details</summary>
Motivation: 解决目前商业化设备和AI算法在规模化推广以满足大量用户需求方面仍然面临的挑战，实现房颤的早期可靠检测。

Method: 提出了一种基于FPGA的补丁式可穿戴监测器，集成了基于深度学习的房颤检测算法，并采用了软硬件协同设计和硬件感知神经架构搜索进行功耗优化。

Result: 该设备实现了95%的房颤检测准确率，超过了心脏病专家水平，系统功耗仅为3.8mW，能够支持超过三周的连续房颤检测。

Conclusion: 该设备通过高效的软硬件协同设计和硬件感知神经架构搜索实现的优化功耗管理，实现了低功耗、高精度的房颤检测，是迈向可扩展、可靠和可持续的房颤监测的重要一步。

Abstract: Atrial fibrillation (AF) is a common arrhythmia and major risk factor for
cardiovascular complications. While commercially available devices and
supporting Artificial Intelligence (AI) algorithms exist for reliable detection
of AF, the scaling of this technology to the amount of people who need this
diagnosis is still a major challenge. This paper presents a novel wearable
device, designed specifically for the early and reliable detection of AF. We
present an FPGA-based patch-style wearable monitor with embedded deep
learning-based AF detection. Operating with 3.8mW system power, which is 1-3
orders of magnitude lower than the state-of-the-art, the device enables
continuous AF detection for over three weeks while achieving 95% accuracy,
surpassing cardiologist-level performance. A key innovation is the combination
of energy-efficient hardware-software co-design and optimized power management
through the application of hardware-aware neural architecture search. This
advancement represents a significant step toward scalable, reliable, and
sustainable AF monitoring.

</details>


### [202] [Sustainable AI Training via Hardware-Software Co-Design on NVIDIA, AMD, and Emerging GPU Architectures](https://arxiv.org/abs/2508.13163)
*Yashasvi Makin,Rahul Maliakkal*

Main category: cs.AR

TL;DR: 本篇论文提出通过软硬件协同设计来提高AI训练的能效，以应对深度学习模型带来的环境问题。


<details>
  <summary>Details</summary>
Motivation: 大规模深度学习和人工智能模型的训练消耗大量计算能力和能源，引发了严重的可持续性问题。模型复杂性的快速增长导致能耗呈指数级增长，这增加了对提高计算效率和降低环境影响的技术的需求。

Method: 本研究探讨了专为NVIDIA、AMD及新兴GPU架构设计的环保驱动性能优化方法，重点关注能显著提升内存级和内核级操作的软硬件协同设计技术，以提高能效比。研究内容包括专用张量和矩阵核心的评估、先进的内存优化方法以及创新的集成方法，并讨论了诸如混合精度运算、能量感知调度算法和编译器驱动的内核增强等软件优化措施。

Result: 研究表明，通过软硬件协同设计，可以实现显著的能效提升，并以来自Meta、Google、Amazon等公司的实际案例研究为证。

Conclusion: 通过软硬件协同设计，可以大幅提高训练效率，降低人工智能对环境的影响，同时不损害性能。

Abstract: In particular, large-scale deep learning and artificial intelligence model
training uses a lot of computational power and energy, so it poses serious
sustainability issues. The fast rise in model complexity has resulted in
exponential increases in energy consumption, increasing the demand for
techniques maximizing computational efficiency and lowering environmental
impact. This work explores environmentally driven performance optimization
methods especially intended for advanced GPU architectures from NVIDIA, AMD,
and other emerging GPU architectures. Our main focus is on investigating
hardware-software co-design techniques meant to significantly increase
memory-level and kernel-level operations, so improving performance-per-watt
measures. Our thorough research encompasses evaluations of specialized tensor
and matrix cores, advanced memory optimization methods, and creative
integration approaches that taken together result in notable energy efficiency
increases. We also discuss important software-level optimizations that augment
hardware capability including mixed-precision arithmetic, advanced energy-aware
scheduling algorithms, and compiler-driven kernel enhancements. Moreover, we
methodically point out important research gaps and suggest future directions
necessary to create really sustainable artificial intelligence systems. This
paper emphasizes how major increases in training efficiency can be obtained by
co-design of hardware and software, so lowering the environmental impact of
artificial intelligence without compromising performance. To back up our
analysis, we use real-world case studies from top companies like Meta, Google,
Amazon, and others that show how these sustainable AI training methods are used
in the real world.

</details>


### [203] [White-Box Reasoning: Synergizing LLM Strategy and gm/Id Data for Automated Analog Circuit Design](https://arxiv.org/abs/2508.13172)
*Jianqiu Chen,Siqi Li,Xu He*

Main category: cs.AR

TL;DR: 提出了一种协同推理框架，结合大语言模型和gm/Id方法学，实现了高效的模拟IC设计自动化，设计质量达到准专家级别，效率提升显著。


<details>
  <summary>Details</summary>
Motivation: 传统的模拟集成电路设计严重依赖经验，并且在先进节点下，传统公式失效，导致设计周期长且效率低下。直接应用大语言模型存在“猜测”的风险，缺乏工程原理的指导。

Method: 提出了一种“协同推理”框架，该框架整合了大语言模型（LLM）的战略推理能力和gm/Id方法学的物理精度。通过为LLM提供gm/Id查找表，使其能够进行量化、数据驱动的设计。

Result: 在双级运算放大器的设计中，该框架使Gemini模型能够在5次迭代内满足所有TT角（工艺、电压、温度）的规范，并能将优化扩展到所有PVT角。与资深工程师的设计相比，该框架实现了准专家级别的设计质量，并将效率提高了几个数量级。

Conclusion: 通过将大语言模型（LLM）的战略推理与gm/Id方法学的物理精度相结合，并为LLM提供gm/Id查找表，我们展示了一种“协同推理”框架，该框架能够实现高效且精确的模拟设计自动化，达到了准专家级别的设计质量，并将效率提高了几个数量级。

Abstract: Analog IC design is a bottleneck due to its reliance on experience and
inefficient simulations, as traditional formulas fail in advanced nodes.
Applying Large Language Models (LLMs) directly to this problem risks mere
"guessing" without engineering principles. We present a "synergistic reasoning"
framework that integrates an LLM's strategic reasoning with the physical
precision of the gm/Id methodology. By empowering the LLM with gm/Id lookup
tables, it becomes a quantitative, data-driven design partner.
  We validated this on a two-stage op-amp, where our framework enabled the
Gemini model to meet all TT corner specs in 5 iterations and extended
optimization to all PVT corners. A crucial ablation study proved gm/Id data is
key for this efficiency and precision; without it, the LLM is slower and
deviates. Compared to a senior engineer's design, our framework achieves
quasi-expert quality with an order-of-magnitude improvement in efficiency. This
work validates a path for true analog design automation by combining LLM
reasoning with scientific circuit design methodologies.

</details>


### [204] [Accelerating LLM Inference via Dynamic KV Cache Placement in Heterogeneous Memory System](https://arxiv.org/abs/2508.13231)
*Yunhua Fang,Rui Xie,Asad Ul Haq,Linsen Ma,Kaoutar El Maghraoui,Naigang Wang,Meng Wang,Liu Liu,Tong Zhang*

Main category: cs.AR

TL;DR: LLM推理内存瓶颈可以通过在异构内存（HBM+DRAM）中动态放置KV缓存来缓解，本研究首次对其进行数学建模和理论分析。


<details>
  <summary>Details</summary>
Motivation: LLM推理受内存带宽限制，KV缓存访问频繁。随着AI硬件发展，异构内存系统成为可行方案，需要研究动态KV缓存放置策略以最大化带宽利用率。

Method: 提出将KV缓存放置问题进行数学建模，并推导出理论上限。

Result: 研究表明，通过优化KV缓存在异构内存系统中的放置，可以在容量约束下最大化聚合带宽利用率，存在巨大的优化空间。

Conclusion: 本文首次对LLM推理中的异构内存系统动态KV缓存调度进行了形式化分析，并推导了理论上限，揭示了运行时优化的巨大潜力。

Abstract: Large Language Model (LLM) inference is increasingly constrained by memory
bandwidth, with frequent access to the key-value (KV) cache dominating data
movement. While attention sparsity reduces some memory traffic, the relevance
of past tokens varies over time, requiring the full KV cache to remain
accessible and sustaining pressure on both bandwidth and capacity. With
advances in interconnects such as NVLink and LPDDR5X, modern AI hardware now
integrates high-bandwidth memory (HBM) with high-speed off-package DRAM, making
heterogeneous memory systems a practical solution. This work investigates
dynamic KV cache placement across such systems to maximize aggregated bandwidth
utilization under capacity constraints. Rather than proposing a specific
scheduling policy, we formulate the placement problem mathematically and derive
a theoretical upper bound, revealing substantial headroom for runtime
optimization. To our knowledge, this is the first formal treatment of dynamic
KV cache scheduling in heterogeneous memory systems for LLM inference.

</details>


### [205] [Sub-Millisecond Event-Based Eye Tracking on a Resource-Constrained Microcontroller](https://arxiv.org/abs/2508.13244)
*Marco Giordano,Pietro Bonazzi,Luca Benini,Michele Magno*

Main category: cs.AR

TL;DR: 提出了一种用于资源受限微控制器的事件驱动型眼动追踪系统，实现了低延迟和低功耗，适用于可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限的嵌入式系统中实时、低延迟和低功耗的眼动追踪挑战。

Method: 利用动态视觉传感器（DVS）和STM32N6微控制器，并提出了一种针对事件数据的硬件感知和传感器感知的紧凑型卷积神经网络（CNN），实现了边缘部署。

Result: 在Ini-30数据集上实现了5.99像素的平均瞳孔预测误差和5.73像素的中值误差，端到端推理延迟仅为385微秒，功耗仅为155微焦。

Conclusion: 该研究成功开发了一个基于事件的眼动追踪系统，该系统部署在资源受限的微控制器上，实现了低延迟、低功耗的嵌入式性能，适用于智能眼镜和可穿戴设备等应用。

Abstract: This paper presents a novel event-based eye-tracking system deployed on a
resource-constrained microcontroller, addressing the challenges of real-time,
low-latency, and low-power performance in embedded systems. The system
leverages a Dynamic Vision Sensor (DVS), specifically the DVXplorer Micro, with
an average temporal resolution of 200 {\mu}s, to capture rapid eye movements
with extremely low latency. The system is implemented on a novel low-power and
high-performance microcontroller from STMicroelectronics, the STM32N6. The
microcontroller features an 800 MHz Arm Cortex-M55 core and AI hardware
accelerator, the Neural-ART Accelerator, enabling real-time inference with
milliwatt power consumption. The paper propose a hardware-aware and
sensor-aware compact Convolutional Neuron Network (CNN) optimized for
event-based data, deployed at the edge, achieving a mean pupil prediction error
of 5.99 pixels and a median error of 5.73 pixels on the Ini-30 dataset. The
system achieves an end-to-end inference latency of just 385 {\mu}s and a neural
network throughput of 52 Multiply and Accumulate (MAC) operations per cycle
while consuming just 155 {\mu}J of energy. This approach allows for the
development of a fully embedded, energy-efficient eye-tracking solution
suitable for applications such as smart glasses and wearable devices.

</details>


### [206] [ViTAD: Timing Violation-Aware Debugging of RTL Code using Large Language Models](https://arxiv.org/abs/2508.13257)
*Wenhao Lv,Yingjie Xia,Xiyuan Chen,Li Kuang*

Main category: cs.AR

TL;DR: ViTAD通过STDG和LLM自动化RTL时序修复，成功率提升近20%。


<details>
  <summary>Details</summary>
Motivation: 现代VLSI电路设计中，RTL阶段的定时优化至关重要。然而，传统的定时优化高度依赖手动专业知识，效率低下。为了自动化这一过程，需要一种能够高效分析时序违规根本原因并动态生成修复策略的方法。

Method: 本文提出ViTAD方法，通过解析Verilog代码和时序报告构建信号时序依赖图（STDG），在此基础上进行违规路径分析，并利用大语言模型（LLM）推断违规的根本原因。最后，结合领域知识库生成定制化的修复方案。

Result: 实验结果表明，ViTAD方法在包含54个实际案例的时序违规数据集上，成功率达到了73.68%，显著优于仅使用LLM的基线方法（54.38%），成功率提升了19.30%。

Conclusion: 该研究提出的ViTAD方法通过构建信号时序依赖图（STDG），结合大语言模型（LLM）分析时序违规的根本原因，并利用领域知识库生成定制化的修复方案，成功将时序修复的成功率从基线的54.38%提高到73.68%，提升了19.30%，有效实现了时序违规的自动化修复。

Abstract: In modern Very Large Scale Integrated (VLSI) circuit design flow, the
Register-Transfer Level (RTL) stage presents a critical opportunity for timing
optimization. Addressing timing violations at this early stage is essential, as
modern systems demand higher speeds, where even minor timing violations can
lead to functional failures or system crashes. However, traditional timing
optimization heavily relies on manual expertise, requiring engineers to
iteratively analyze timing reports and debug. To automate this process, this
paper proposes ViTAD, a method that efficiently analyzes the root causes of
timing violations and dynamically generates targeted repair strategies.
Specifically, we first parse Verilog code and timing reports to construct a
Signal Timing Dependency Graph (STDG). Based on the STDG, we perform violation
path analysis and use large language models (LLMs) to infer the root causes of
violations. Finally, by analyzing the causes of violations, we selectively
retrieve relevant debugging knowledge from a domain-specific knowledge base to
generate customized repair solutions. To evaluate the effectiveness of our
method, we construct a timing violation dataset based on real-world open-source
projects. This dataset contains 54 cases of violations. Experimental results
show that our method achieves a 73.68% success rate in repairing timing
violations, while the baseline using only LLM is 54.38%. Our method improves
the success rate by 19.30%.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [207] [Tight Bounds for Sparsifying Random CSPs](https://arxiv.org/abs/2508.13345)
*Joshua Brakensiek,Venkatesan Guruswami,Aaron Putterman*

Main category: cs.DS

TL;DR: 该论文研究了随机 CSP 的稀疏化问题，在两种模型下发现了稀疏化阈值现象，并对 uniform 模型中的复杂情况（包括非单调性）进行了分析和判定。


<details>
  <summary>Details</summary>
Motivation: 研究 CSP 稀疏化问题，并首次将其应用于随机 CSP，探索不同随机模型下的稀疏化性质和阈值现象。

Method: 对两种随机 CSP 模型（r-partite 模型和 uniform 模型）进行了分析，并通过构造稀疏器和展示阈值现象来研究稀疏化问题。

Result: 在 r-partite 模型中，证明了当边数 $m 
otin 	ext{O}(n^k)$ 时，CSP 无法稀疏化；当 $m 
otin 	ilde{	ext{O}}(n^k)$ 时，CSP 可稀疏化为 $	ilde{	ext{O}}(n^k)$ 大小。在 uniform 模型中，当 $m 
otin 	ext{O}(n^k)$ 时，CSP 无法稀疏化；当 $m 
otin 	ilde{	ext{O}}(n^{k+1})$ 时，CSP 可稀疏化为 $	ilde{	ext{O}}(n^{k+1})$ 大小。此外，还发现了某些谓词下稀疏化性质的非单调性，并提出了判定方法。

Conclusion: 该研究首次探讨了随机 CSP 的稀疏化问题，提出了两种模型：r-partite 模型和 uniform 模型。在 r-partite 模型中，发现了具有 $n^k$ 规模稀疏化阈值的尖锐现象，且稀疏器可通过 i.i.d. 边采样构造。在 uniform 模型中，情况更复杂，存在 $n^k$ 和 $n^{k+1}$ 之间的稀疏化不确定性，甚至出现了非单调现象，但研究给出了判定具体谓词情况的精确过程。

Abstract: The problem of CSP sparsification asks: for a given CSP instance, what is the
sparsest possible reweighting such that for every possible assignment to the
instance, the number of satisfied constraints is preserved up to a factor of $1
\pm \epsilon$? We initiate the study of the sparsification of random CSPs. In
particular, we consider two natural random models: the $r$-partite model and
the uniform model. In the $r$-partite model, CSPs are formed by partitioning
the variables into $r$ parts, with constraints selected by randomly picking one
vertex out of each part. In the uniform model, $r$ distinct vertices are chosen
at random from the pool of variables to form each constraint.
  In the $r$-partite model, we exhibit a sharp threshold phenomenon. For every
predicate $P$, there is an integer $k$ such that a random instance on $n$
vertices and $m$ edges cannot (essentially) be sparsified if $m \le n^k$ and
can be sparsified to size $\approx n^k$ if $m \ge n^k$. Here, $k$ corresponds
to the largest copy of the AND which can be found within $P$. Furthermore,
these sparsifiers are simple, as they can be constructed by i.i.d. sampling of
the edges.
  In the uniform model, the situation is a bit more complex. For every
predicate $P$, there is an integer $k$ such that a random instance on $n$
vertices and $m$ edges cannot (essentially) be sparsified if $m \le n^k$ and
can sparsified to size $\approx n^k$ if $m \ge n^{k+1}$. However, for some
predicates $P$, if $m \in [n^k, n^{k+1}]$, there may or may not be a nontrivial
sparsifier. In fact, we show that there are predicates where the
sparsifiability of random instances is non-monotone, i.e., as we add more
random constraints, the instances become more sparsifiable. We give a precise
(efficiently computable) procedure for determining which situation a specific
predicate $P$ falls into.

</details>


### [208] [On the 2D Demand Bin Packing Problem: Hardness and Approximation Algorithms](https://arxiv.org/abs/2508.13347)
*Susanne Albers,Waldo Gálvez,Ömer Behic Özdemir*

Main category: cs.DS

TL;DR: 二维需求箱子装载问题被研究，证明了其NP难近似性，并提出了最佳逼近算法和3-逼近算法。


<details>
  <summary>Details</summary>
Motivation: 研究二维需求箱子装载问题，以解决在时间线上分配矩形任务，使得在任何时间点的任务总高度不超过给定常量容量。

Method: 提出了一种基于计算结构化解的通用框架，通过包含相对较小的任务来解决相对较大的任务，并对二维需求箱子装载问题进行了分析。

Result: 证明了具有短高度和方形的任务的二维需求箱子装载问题的NP难近似性，并给出了最佳逼近算法；对一般情况给出了3-逼近算法。

Conclusion: 研究了二维经典箱子装载问题的推广，即二维需求箱子装载问题。证明了该问题的一些简单变体的NP难近似性，并为它们提供了最佳逼近算法，同时为一般情况提出了一个简单的3-逼近算法。

Abstract: We study a two-dimensional generalization of the classical Bin Packing
problem, denoted as 2D Demand Bin Packing. In this context, each bin is a
horizontal timeline, and rectangular tasks (representing electric appliances or
computational requirements) must be allocated into the minimum number of bins
so that the sum of the heights of tasks at any point in time is at most a given
constant capacity. We prove that simple variants of the problem are NP-hard to
approximate within a factor better than $2$, namely when tasks have short
height and when they are squares, and provide best-possible approximation
algorithms for them; we also present a simple $3$-approximation for the general
case. All our algorithms are based on a general framework that computes
structured solutions for relatively large tasks, while including relatively
small tasks on top via a generalization of the well-known First-Fit algorithm
for Bin Packing.

</details>


### [209] [Concurrent Double-Ended Priority Queues](https://arxiv.org/abs/2508.13399)
*Panagiota Fatourou,Eric Ruppert,Ioannis Xiradakis*

Main category: cs.DS

TL;DR: This paper introduces a new way to make double-ended priority queues work efficiently when multiple threads access them at the same time, keeping operations fast and safe.


<details>
  <summary>Details</summary>
Motivation: The motivation for this work is to provide the first concurrent implementation specifically designed for a double-ended priority queue (DEPQ), addressing the need for efficient and scalable concurrent data structures.

Method: The paper describes a general method to add an ExtractMax operation to concurrent priority queues supporting Insert and ExtractMin. This is achieved by using two linearizable single-consumer priority queues to build a linearizable dual-consumer DEPQ. The construction is lock-free and can be further enhanced with a lock-based combining scheme for multi-consumer support at each end.

Result: The result is a lock-free, linearizable DEPQ construction that can be extended to handle multiple consumers at each end. The technique is illustrated with a list-based priority queue.

Conclusion: This paper presents the first concurrent implementation of a double-ended priority queue (DEPQ), offering a novel approach to integrate ExtractMax into existing concurrent priority queues. The construction maintains lock-freedom and can be extended to support multiple consumers at each end using a lock-based combining scheme.

Abstract: This work provides the first concurrent implementation specifically designed
for a double-ended priority queue (DEPQ). We do this by describing a general
way to add an ExtractMax operation to any concurrent priority queue that
already supports Insert and ExtractMin operations. The construction uses two
linearizable single-consumer priority queues to build a linearizable
dual-consumer DEPQ (only one process can perform Extract operations at each
end). This construction preserves lock-freedom. We then describe how to use a
lock-based combining scheme to allow multiple consumers at each end of the
DEPQ. To illustrate the technique, we apply it to a list-based priority queue.

</details>


### [210] [Generating the Spanning Trees of Series-Parallel Graphs up to Graph Automorphism](https://arxiv.org/abs/2508.13480)
*Mithra Karamchedu,Lucas Bang*

Main category: cs.DS

TL;DR: 本篇论文研究了如何生成序列-并列图的非等价生成树。作者提出了一种在考虑图对称性的情况下生成这些树的算法，该算法在有方向和半有方向的图上表现优异，并且不需要显式计算图的自同构群。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在解决在考虑图的自同构（对称性）的情况下生成图的生成树的问题，并为序列-并列图提供了具体的算法解决方案。

Method: 该研究首先调查了一般输入图的生成树问题，然后提出了针对序列-并列图的算法。具体来说，对于有方向的序列-并列图，提出了一种输出线性时间（output-linear time）的算法来生成非等价生成树；接着，将该算法适配到半有方向的序列-并列图；最后，讨论了无方向序列-并列图的情况。

Result: 研究成功地为有方向和半有方向的序列-并列图生成了非等价生成树，并且算法在生成过程中不需要计算图的自同构群。此外，研究还对无方向序列-并列图的生成树问题进行了初步探讨和开放性问题思考。

Conclusion: 该研究提出了生成序列-并列图（series-parallel graphs）的非等价生成树（spanning trees）的算法，并讨论了不同定义下（有方向、半有方向、无方向）的系列并列图的生成树问题。研究表明，该算法在生成非等价生成树时无需显式计算图的自同构群，并揭示了图的自同构群与其生成树之间的递归结构关系。

Abstract: In this paper, we investigate the problem of generating the spanning trees of
a graph $G$ up to the automorphisms or "symmetries" of $G$. After introducing
and surveying this problem for general input graphs, we present algorithms that
fully solve the case of series-parallel graphs, under two standard definitions.
We first show how to generate the nonequivalent spanning trees of a oriented
series-parallel graph $G$ in output-linear time, where both terminals of $G$
have been individually distinguished (i.e. applying an automorphism that
exchanges the terminals produces a different series-parallel graph).
Subsequently, we show how to adapt these oriented algorithms to the case of
semioriented series-parallel graphs, where we still have a set of two
distinguished terminals but neither has been designated as a source or sink.
Finally, we discuss the case of unoriented series-parallel graphs, where no
terminals have been distinguished and present a few observations and open
questions relating to them. The algorithms we present generate the
nonequivalent spanning trees of $G$ but never explicitly compute the
automorphism group of $G$, revealing how the recursive structure of $G$'s
automorphism group mirrors that of its spanning trees.

</details>


### [211] [Finding subdigraphs in digraphs of bounded directed treewidth](https://arxiv.org/abs/2508.13830)
*Raul Lopes,Ignasi Sau*

Main category: cs.DS

TL;DR: Directed treewidth is algorithmically challenging. This paper explores which other subgraph types, besides directed paths, are efficiently findable in graphs with bounded directed treewidth. The main finding is that only stars share this property, supported by new positive and negative results and outlining future research.


<details>
  <summary>Details</summary>
Motivation: To investigate if subgraphs, beyond directed paths, can be efficiently found in digraphs with bounded directed treewidth, given the known algorithmic limitations of directed treewidth compared to its undirected counterpart.

Method: The paper presents a number of positive and negative results to tackle the question of whether subgraphs other than directed paths can be found efficiently in digraphs of bounded directed treewidth.

Result: The paper's findings suggest that stars are the only other type of digraphs, besides directed paths, that exhibit favorable behavior concerning directed treewidth.

Conclusion: The only digraphs that behave well with respect to directed treewidth, other than directed paths, appear to be stars. The paper presents results generalizing existing literature and suggests future research directions.

Abstract: It is well known that directed treewidth does not enjoy the nice algorithmic
properties of its undirected counterpart. There exist, however, some positive
results that, essentially, present XP algorithms for the problem of finding, in
a given digraph $D$, a subdigraph isomorphic to a digraph $H$ that can be
formed by the union of $k$ directed paths (with some extra properties),
parameterized by $k$ and the directed treewidth of $D$. Our motivation is to
tackle the following question: Are there subdigraphs, other than the directed
paths, that can be found efficiently in digraphs of bounded directed treewidth?
In a nutshell, the main message of this article is that, other than the
directed paths, the only digraphs that seem to behave well with respect to
directed treewidth are the stars. For this, we present a number of positive and
negative results, generalizing several results in the literature, as well as
some directions for further research.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [212] [PreSem-Surf: RGB-D Surface Reconstruction with Progressive Semantic Modeling and SG-MLP Pre-Rendering Mechanism](https://arxiv.org/abs/2508.13228)
*Yuyan Ye,Hang Xu,Yanghang Huang,Jiali Huang,Qian Weng*

Main category: cs.GR

TL;DR: PreSem-Surf是一种基于NeRF的优化方法，利用RGB-D和语义信息，通过SG-MLP和PR-MLP进行体素预渲染，并结合渐进式语义建模，能在短时间内重建高质量场景表面，并在多个评估指标上表现优异。


<details>
  <summary>Details</summary>
Motivation: 提出一种优化方法，能在短时间内从RGB-D序列中重建高质量场景表面。

Method: 该方法基于神经辐射场（NeRF）框架，集成RGB、深度和语义信息。引入了SG-MLP采样结构和PR-MLP（预处理多层感知器）进行体素预渲染，并采用渐进式语义建模。

Result: 在七个合成场景和六个评估指标上进行了实验，PreSem-Surf取得了最佳性能。

Conclusion: PreSem-Surf在C-L1、F-score和IoU方面表现最佳，并在NC、Accuracy和Completeness方面保持竞争力，证明了其有效性和实用性。

Abstract: This paper proposes PreSem-Surf, an optimized method based on the Neural
Radiance Field (NeRF) framework, capable of reconstructing high-quality scene
surfaces from RGB-D sequences in a short time. The method integrates RGB,
depth, and semantic information to improve reconstruction performance.
Specifically, a novel SG-MLP sampling structure combined with PR-MLP
(Preconditioning Multilayer Perceptron) is introduced for voxel pre-rendering,
allowing the model to capture scene-related information earlier and better
distinguish noise from local details. Furthermore, progressive semantic
modeling is adopted to extract semantic information at increasing levels of
precision, reducing training time while enhancing scene understanding.
Experiments on seven synthetic scenes with six evaluation metrics show that
PreSem-Surf achieves the best performance in C-L1, F-score, and IoU, while
maintaining competitive results in NC, Accuracy, and Completeness,
demonstrating its effectiveness and practical applicability.

</details>


### [213] [Sparse, Geometry- and Material-Aware Bases for Multilevel Elastodynamic Simulation](https://arxiv.org/abs/2508.13386)
*Ty Trusty,David I. W. Levin,Danny M. Kaufman*

Main category: cs.GR

TL;DR: IPC模拟加速了13倍，同时保持了鲁棒性和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 为了加速增量势接触（IPC）模拟，同时保持其在复杂场景下的鲁棒性和视觉保真度。

Method: 提出了一种多层弹性动力学时间步求解器，采用新颖的稀疏、几何和材料感知基构建方法，实现了比标准IPC方法快13倍的模拟速度，同时保持了相同的视觉保真度和鲁棒性。

Result: 与标准IPC方法相比，在相同的硬件上，该求解器速度提高了13倍，每时间步相对位移误差约为1%，并且在视觉上无法区分。

Conclusion: 该方法在保持与标准IPC方法相同的视觉保真度的情况下，速度提高了13倍，同时保持了在复杂几何、异构材料和高分辨率数据下的鲁棒性。

Abstract: We present a multi-level elastodynamics timestep solver for accelerating
incremental potential contact (IPC) simulations. Our method retains the
robustness of gold standard IPC in the face of intricate geometry, complex
heterogeneous material distributions and high resolution input data without
sacrificing visual fidelity (per-timestep relative displacement error of
$\approx1\%$). The success of our method is enabled by a novel, sparse,
geometry- and material-aware basis construction method which allows for the use
of fast preconditioned conjugate gradient solvers (in place of a sparse direct
solver), but without suffering convergence issues due to stiff or heterogeneous
materials. The end result is a solver that produces results visually
indistinguishable and quantitatively very close to gold-standard IPC methods
but up to $13\times$ faster on identical hardware.

</details>


### [214] [Eliminating Rasterization: Direct Vector Floor Plan Generation with DiffPlanner](https://arxiv.org/abs/2508.13738)
*Shidong Wang,Renato Pajarola*

Main category: cs.GR

TL;DR: DiffPlanner is a new deep learning framework that generates floor plans entirely in vector space using a Transformer-based conditional diffusion model, improving upon existing methods by avoiding rasterization and offering better controllability.


<details>
  <summary>Details</summary>
Motivation: Learning-based methods for floor plan generation involve a complex and redundant workflow of converting vector data to raster images and back, leading to information loss and scalability issues. The goal is to address these issues by operating entirely in vector space.

Method: DiffPlanner is a Transformer-based conditional diffusion model that operates entirely in vector space and integrates an alignment mechanism in training, aligning the optimization trajectory of the model with the iterative design processes of designers.

Result: The method handles complex vector data, better fits the distribution of predicted targets, accomplishes floor plan layout design, and achieves user-controllable generation, surpassing existing methods in quality and controllability.

Conclusion: DiffPlanner surpasses existing state-of-the-art methods in generating floor plans and bubble diagrams in the creative stages, offering more controllability to users and producing higher-quality results that closely match the ground truths.

Abstract: The boundary-constrained floor plan generation problem aims to generate the
topological and geometric properties of a set of rooms within a given boundary.
Recently, learning-based methods have made significant progress in generating
realistic floor plans. However, these methods involve a workflow of converting
vector data into raster images, using image-based generative models, and then
converting the results back into vector data. This process is complex and
redundant, often resulting in information loss. Raster images, unlike vector
data, cannot scale without losing detail and precision. To address these
issues, we propose a novel deep learning framework called DiffPlanner for
boundary-constrained floor plan generation, which operates entirely in vector
space. Our framework is a Transformer-based conditional diffusion model that
integrates an alignment mechanism in training, aligning the optimization
trajectory of the model with the iterative design processes of designers. This
enables our model to handle complex vector data, better fit the distribution of
the predicted targets, accomplish the challenging task of floor plan layout
design, and achieve user-controllable generation. We conduct quantitative
comparisons, qualitative evaluations, ablation experiments, and perceptual
studies to evaluate our method. Extensive experiments demonstrate that
DiffPlanner surpasses existing state-of-the-art methods in generating floor
plans and bubble diagrams in the creative stages, offering more controllability
to users and producing higher-quality results that closely match the ground
truths.

</details>


### [215] [Sketch3DVE: Sketch-based 3D-Aware Scene Video Editing](https://arxiv.org/abs/2508.13797)
*Feng-Lin Liu,Shi-Yang Li,Yan-Pei Cao,Hongbo Fu,Lin Gao*

Main category: cs.GR

TL;DR: Sketch3DVE是一种3D感知的视频编辑方法，可以通过草图精确控制3D场景的局部编辑，并能有效处理视频中显著的视角变化。


<details>
  <summary>Details</summary>
Motivation: 现有的视频编辑方法在风格迁移或外观修改方面取得了不错的效果，但在编辑视频的结构内容方面仍然面临挑战，特别是在处理显著的视角变化（如大的相机旋转或缩放）时。主要挑战包括生成与原始视频一致的新视角内容、保留未编辑区域以及将稀疏的2D输入转换为逼真的3D视频输出。

Method: 本文提出了一种名为Sketch3DVE的基于草图的3D感知视频编辑方法。该方法首先利用图像编辑技术处理视频的第一帧，然后将编辑传播到其余帧。通过使用草图或基于掩码的图像编辑方法进行精确的几何控制。为了处理视角变化，利用密集立体匹配方法估计点云和相机参数，并提出了一种使用深度图表示新编辑组件三维几何的点云编辑方法，以有效地将其与原始三维场景对齐。最后，通过3D感知掩码传播策略和视频扩散模型来实现新编辑内容与原始视频的无缝融合。

Result: 实验结果表明，Sketch3DVE在视频编辑任务上表现优于现有方法。

Conclusion: Sketch3DVE通过3D信息分析和点云编辑，实现了具有大视角变化视频的结构内容编辑，并在视频扩散模型和3D感知掩码传播的帮助下，有效融合了新编辑的内容，同时保留了未编辑区域的特征，实验证明了其在视频编辑方面的优越性。

Abstract: Recent video editing methods achieve attractive results in style transfer or
appearance modification. However, editing the structural content of 3D scenes
in videos remains challenging, particularly when dealing with significant
viewpoint changes, such as large camera rotations or zooms. Key challenges
include generating novel view content that remains consistent with the original
video, preserving unedited regions, and translating sparse 2D inputs into
realistic 3D video outputs. To address these issues, we propose Sketch3DVE, a
sketch-based 3D-aware video editing method to enable detailed local
manipulation of videos with significant viewpoint changes. To solve the
challenge posed by sparse inputs, we employ image editing methods to generate
edited results for the first frame, which are then propagated to the remaining
frames of the video. We utilize sketching as an interaction tool for precise
geometry control, while other mask-based image editing methods are also
supported. To handle viewpoint changes, we perform a detailed analysis and
manipulation of the 3D information in the video. Specifically, we utilize a
dense stereo method to estimate a point cloud and the camera parameters of the
input video. We then propose a point cloud editing approach that uses depth
maps to represent the 3D geometry of newly edited components, aligning them
effectively with the original 3D scene. To seamlessly merge the newly edited
content with the original video while preserving the features of unedited
regions, we introduce a 3D-aware mask propagation strategy and employ a video
diffusion model to produce realistic edited videos. Extensive experiments
demonstrate the superiority of Sketch3DVE in video editing. Homepage and code:
http://http://geometrylearning.com/Sketch3DVE/

</details>


### [216] [Is-NeRF: In-scattering Neural Radiance Field for Blurred Images](https://arxiv.org/abs/2508.13808)
*Nan Luo,Chenglin Ye,Jiaxu Li,Gang Liu,Bo Wan,Di Wang,Lupeng Liu,Jun Xiao*

Main category: cs.GR

TL;DR: Is-NeRF通过散射感知体积渲染和自适应学习策略，解决了NeRF在处理运动模糊图像时的几何模糊问题，实现了更高质量的3D场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有的NeRF方法采用直线体积渲染，难以处理复杂的光路和运动模糊图像引入的几何模糊问题。

Method: 提出了一种新的去模糊神经辐射场（Is-NeRF），通过统一六种常见的光传播现象，建立了一个新的散射感知体积渲染管线，并引入了自适应学习策略来确定散射方向和采样间隔，同时优化NeRF参数、散射参数和相机运动，从模糊图像中恢复细粒度的场景表示。

Result: Is-NeRF在处理复杂现实场景中表现出色，生成高保真图像和精确几何细节方面优于现有最先进的方法。

Conclusion: Is-NeRF通过统一六种常见的光传播现象并通过引入的散射感知体积渲染管线以及自适应学习策略，有效地处理了现实世界中复杂的运动模糊场景，在生成高保真图像和精确几何细节方面优于现有技术。

Abstract: Neural Radiance Fields (NeRF) has gained significant attention for its
prominent implicit 3D representation and realistic novel view synthesis
capabilities. Available works unexceptionally employ straight-line volume
rendering, which struggles to handle sophisticated lightpath scenarios and
introduces geometric ambiguities during training, particularly evident when
processing motion-blurred images. To address these challenges, this work
proposes a novel deblur neural radiance field, Is-NeRF, featuring explicit
lightpath modeling in real-world environments. By unifying six common light
propagation phenomena through an in-scattering representation, we establish a
new scattering-aware volume rendering pipeline adaptable to complex lightpaths.
Additionally, we introduce an adaptive learning strategy that enables
autonomous determining of scattering directions and sampling intervals to
capture finer object details. The proposed network jointly optimizes NeRF
parameters, scattering parameters, and camera motions to recover fine-grained
scene representations from blurry images. Comprehensive evaluations demonstrate
that it effectively handles complex real-world scenarios, outperforming
state-of-the-art approaches in generating high-fidelity images with accurate
geometric details.

</details>


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [217] [Time Profile of U.S. Neighborhoods: Datasets of Time Use at Social Infrastructure Places](https://arxiv.org/abs/2508.13295)
*Yan Wang,Ziyi Guo*

Main category: cs.SI

TL;DR: 社交基础设施对社区福祉至关重要，但其时间利用模式尚不明确。本研究开发了新的STU测量方法，并使用了大规模匿名人流量数据，揭示了STU的时空差异和不平等性，为未来研究和规划提供了基础。


<details>
  <summary>Details</summary>
Motivation: 填补了关于社交基础设施时间利用的现有研究中，由于缺乏空间解析的全国性数据集而存在的空白。

Method: 开发了可扩展的社交基础设施时间利用（STU）测量方法，利用匿名化和聚合的人流量数据，覆盖了从人口普查区到大都市区的多个地理尺度，时间跨度为2019年至2024年。

Result: 开发的数据集揭示了STU在时间、空间和社会人口统计学特征方面的差异，验证结果表明其人口代表性稳健，并揭示了更细致的模式。

Conclusion: 该研究开发了首个跨越多个地理尺度的社交基础设施时间利用（STU）测量方法，利用了2019年至2024年间覆盖美国48个州的匿名化聚合人流量数据，能够捕捉参与长度、深度、活动多样性和空间不平等性。研究揭示了STU在时间、空间和社会人口统计学特征方面的差异，并通过与国家调查数据的对比验证了其稳健性。

Abstract: Social infrastructure plays a critical role in shaping neighborhood
well-being by fostering social and cultural interaction, enabling service
provision, and encouraging exposure to diverse environments. Despite the
growing knowledge of its spatial accessibility, time use at social
infrastructure places is underexplored due to the lack of a spatially resolved
national dataset. We address this gap by developing scalable
Social-Infrastructure Time Use measures (STU) that capture length and depth of
engagement, activity diversity, and spatial inequality, supported by
first-of-their-kind datasets spanning multiple geographic scales from census
tracts to metropolitan areas. Our datasets leverage anonymized and aggregated
foot traffic data collected between 2019 and 2024 across 49 continental U.S.
states. The data description reveals variances in STU across time, space, and
differing neighborhood sociodemographic characteristics. Validation
demonstrates generally robust population representation, consistent with
established national survey findings while revealing more nuanced patterns.
Future analyses could link STU with public health outcomes and environmental
factors to inform targeted interventions aimed at enhancing population
well-being and guiding social infrastructure planning and usage.

</details>


### [218] [State & Geopolitical Censorship on Twitter (X): Detection & Impact Analysis of Withheld Content](https://arxiv.org/abs/2508.13375)
*Yusuf Mücahit Çetinkaya,Tuğrulcan Elmas*

Main category: cs.SI

TL;DR: 本研究量化分析了社交媒体审查的影响，发现审查显著降低了用户参与度和粉丝增长，但对发帖频率影响不大。研究还开发了一个能有效预测审查账户的模型，并强调了推文内容在预测中的重要性。最终，研究结果为平台治理、言论自由和数字压迫的讨论提供了信息。


<details>
  <summary>Details</summary>
Motivation: 鉴于国家和地缘政治审查在推特（现为X）上日益常态化，以及马斯克对国家指令的服从意愿，本研究旨在量化审查（特别是内容屏蔽）对社交媒体的影响，并探讨其与言论自由的界限。

Method: 首先，利用包含俄罗斯账户在欧盟因传播国家赞助叙事而被审查，以及土耳其账户在国内因推广军事宣传而被屏蔽的数据集，进行了量化分析。其次，开发了一个用户级别的二元分类器，采用 Transformer 主干和时间聚合策略来预测账户是否可能被屏蔽，并通过消融实验验证了模型性能。

Result: 审查对发帖频率影响甚微，但显著降低了点赞和转推（25%），并大幅减少了粉丝增长（90%），尤其是在审查区域与账户主要受众重叠时。研究还发现，部分俄罗斯账户因受众位于审查管辖区之外而继续增长。所提出的预测模型达到了 0.73 的 F1 分数和 0.83 的 AUC。

Conclusion: 审查对用户参与度（点赞和转推）有显著影响（降低25%），并严重阻碍了粉丝增长（降低90%），尤其是在审查区域与账户主要受众一致的情况下。然而，一些俄罗斯账户由于其受众在管辖区之外，仍然能够实现增长。通过以用户为中心的二元分类器，结合 Transformer 和时间聚合策略，可以预测账户是否可能被屏蔽，其中推文内容是关键预测信号。

Abstract: State and geopolitical censorship on Twitter, now X, has been turning into a
routine, raising concerns about the boundaries between criminal content and
freedom of speech. One such censorship practice, withholding content in a
particular state has renewed attention due to Elon Musk's apparent willingness
to comply with state demands. In this study, we present the first quantitative
analysis of the impact of state censorship by withholding on social media using
a dataset in which two prominent patterns emerged: Russian accounts censored in
the EU for spreading state-sponsored narratives, and Turkish accounts blocked
within Turkey for promoting militant propaganda. We find that censorship has
little impact on posting frequency but significantly reduces likes and retweets
by 25%, and follower growth by 90%-especially when the censored region aligns
with the account's primary audience. Meanwhile, some Russian accounts continue
to experience growth as their audience is outside the withholding
jurisdictions. We develop a user-level binary classifier with a transformer
backbone and temporal aggregation strategies, aiming to predict whether an
account is likely to be withheld. Through an ablation study, we find that tweet
content is the primary signal in predicting censorship, while tweet metadata
and profile features contribute marginally. Our best model achieves an F1 score
of 0.73 and an AUC of 0.83. This work informs debates on platform governance,
free speech, and digital repression.

</details>


### [219] [Towards a general diffusion-based information quality assessment model](https://arxiv.org/abs/2508.13927)
*Anthony Lopes Temporao,Mickael Temporao,Corentin Vande Kerckhove,Flavio Abreu Araujo*

Main category: cs.SI

TL;DR: 该研究提出了一个基于信息扩散动态（多样性、及时性、显著性）的框架，用于评估学术出版物的信息质量。该框架使用广义相加模型 (GAM) 进行预测，在预测引用量和高影响力论文方面表现出色，其中及时性和显著性是关键预测因子。


<details>
  <summary>Details</summary>
Motivation: 数字时代信息传播的快速和无限制，加剧了全球“信息流行病”，使得识别高质量信息变得复杂。

Method: 提出一个轻量级、可解释且非侵入性的框架，仅根据扩散动态评估信息质量，并在此背景下以学术出版物为例进行演示。使用来自 ArnetMiner 和 OpenAlex 的 29,264 篇科学、技术、工程、数学（STEM）和社会科学论文的异构数据集，将每篇论文的扩散网络建模为三个理论驱动的特征：多样性、及时性和显著性。在这些特征上训练的广义相加模型 (GAM) 在预测次年引用增量方面达到了 0.8468 的皮尔逊相关性，在预测高影响力论文方面达到了 97.8% 的准确率。

Result: 通过对来自 ArnetMiner 和 OpenAlex 的 29,264 篇 STEM 和社会科学论文的分析，研究表明，所提出的基于扩散动态的框架能够准确预测论文的引用量和影响力。具体而言，广义相加模型 (GAM) 在预测次年引用增量方面达到了 0.8468 的皮尔逊相关性，在预测高影响力论文方面达到了 97.8% 的准确率。特征重要性分析表明，及时性和显著性是最重要的预测因子，而多样性在学术背景下的预测能力相对较弱，但在社交媒体环境中可能更有效。

Conclusion: 该框架的透明度、领域无关设计和最少的功能要求，使其成为评估全球信息质量的可扩展工具，并开辟了超越二元可信度标签，迈向更丰富、受扩散启发的评估指标的新途径。

Abstract: The rapid and unregulated dissemination of information in the digital era has
amplified the global "infodemic," complicating the identification of high
quality information. We present a lightweight, interpretable and non-invasive
framework for assessing information quality based solely on diffusion dynamics,
demonstrated here in the context of academic publications. Using a
heterogeneous dataset of 29,264 sciences, technology, engineering, mathematics
(STEM) and social science papers from ArnetMiner and OpenAlex, we model the
diffusion network of each paper as a set of three theoretically motivated
features: diversity, timeliness, and salience. A Generalized Additive Model
(GAM) trained on these features achieved Pearson correlations of 0.8468 for
next-year citation gain and up to 97.8% accuracy in predicting high-impact
papers. Feature relevance studies reveal timeliness and salience as the most
robust predictors, while diversity offers less stable benefits in the academic
setting but may be more informative in social media contexts. The framework's
transparency, domain-agnostic design, and minimal feature requirements position
it as a scalable tool for global information quality assessment, opening new
avenues for moving beyond binary credibility labels toward richer,
diffusion-informed evaluation metrics.

</details>


### [220] [Trust and Reputation in Data Sharing: A Survey](https://arxiv.org/abs/2508.14028)
*Wenbo Wu,George Konstantinidis*

Main category: cs.SI

TL;DR: 本文综述了信任和声誉管理系统在数据共享中的应用，提出了新的分类法和评估指标，并指出了未来的研究方向。


<details>
  <summary>Details</summary>
Motivation: 数据共享是人工智能经济发展的重要驱动力，但数据提供者和数据消费者之间的信任问题阻碍了数据的广泛共享。现有技术和算法在解决信任和声誉管理方面取得了进展，但缺乏专门针对数据共享独特性的解决方案。

Method: 本篇论文通过对现有信任和声誉管理系统（TRMSs）进行广泛的文献综述，分析了它们在数据共享环境中的应用情况。在此基础上，研究人员开发了新的系统设计、信任评估框架以及数据和实体的评估指标的分类法，并对现有TRMSs在数据共享中的适用性进行了系统性分析。

Result: 本篇论文对信任和声誉管理系统（TRMSs）在数据共享中的应用进行了全面的分析，提出了新的分类法和评估指标，并识别了现有系统在可解释性、全面性和准确性方面的挑战。

Conclusion: 本篇论文旨在解决数据共享中的信任和声誉管理问题，通过分析现有的信任和声誉管理系统（TRMSs），并提出新的分类法和评估指标，以期为大规模数据共享生态系统提供更具可解释性、全面性和准确性的解决方案。

Abstract: Data sharing is the fuel of the galloping artificial intelligence economy,
providing diverse datasets for training robust models. Trust between data
providers and data consumers is widely considered one of the most important
factors for enabling data sharing initiatives. Concerns about data sensitivity,
privacy breaches, and misuse contribute to reluctance in sharing data across
various domains. In recent years, there has been a rise in technological and
algorithmic solutions to measure, capture and manage trust, trustworthiness,
and reputation in what we collectively refer to as Trust and Reputation
Management Systems (TRMSs). Such approaches have been developed and applied to
different domains of computer science, such as autonomous vehicles, or IoT
networks, but there have not been dedicated approaches to data sharing and its
unique characteristics. In this survey, we examine TRMSs from a data-sharing
perspective, analyzing how they assess the trustworthiness of both data and
entities across different environments. We develop novel taxonomies for system
designs, trust evaluation framework, and evaluation metrics for both data and
entity, and we systematically analyze the applicability of existing TRMSs in
data sharing. Finally, we identify open challenges and propose future research
directions to enhance the explainability, comprehensiveness, and accuracy of
TRMSs in large-scale data-sharing ecosystems.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [221] [Fast hydrogen atom diffraction through monocrystalline graphene](https://arxiv.org/abs/2508.13175)
*Pierre Guichard,Arnaud Dochain,Raphaël Marion,Pauline de Crombrugghe de Picquendaele,Nicolas Lejeune,Benoît Hackens,Paul-Antoine Hervieux,Xavier Urbain*

Main category: cond-mat.mes-hall

TL;DR: 用氢原子对石墨烯进行快原子衍射，结果对原子表面相互作用高度敏感，可用于光谱学。


<details>
  <summary>Details</summary>
Motivation: 探索快原子衍射在石墨烯中的应用，并评估其作为光谱学工具的潜力。

Method: 使用能量从 150 到 1200 eV 的氢原子，通过单层石墨烯进行快原子衍射。

Result: 高分辨率图像显示了共存的单晶域重叠的六边形图案。时间飞行测量证实能量损失可忽略不计，表明该方法适用于物质波干涉测量。

Conclusion: 该衍射现象可以通过 eikonal 近似很好地描述，但需要使用 DFT 的全 3D 相互作用势进行精确建模。

Abstract: We report fast atom diffraction through single-layer graphene using hydrogen
atoms at kinetic energies from 150 to 1200 eV. High-resolution images reveal
overlapping hexagonal patterns from coexisting monocrystalline domains.
Time-of-flight tagging confirms negligible energy loss, making the method
suitable for matter-wave interferometry. The diffraction is well described by
the eikonal approximation, with accurate modeling requiring the full 3D
interaction potential from DFT. Simpler models fail to reproduce the data,
highlighting the exceptional sensitivity of diffraction patterns to
atom-surface interactions and their potential for spectroscopic applications.

</details>


### [222] [Josephson diode effect in nanowire-based Andreev molecules](https://arxiv.org/abs/2508.13477)
*Shang Zhu,Yiwen Ma,Jiangbo He,Xiaozhou Yang,Zhongmou Jia,Min Wei,Yiping Jiao,Jiezhong He,Enna Zhuo,Xuewei Cao,Bingbing Tong,Ziwei Dou,Peiling Li,Jie Shen,Xiaohui Song,Zhaozheng Lyu,Guangtong Liu,Dong Pan,Jianhua Zhao,Bo Lu,Li Lu,Fanming Qu*

Main category: cond-mat.mes-hall

TL;DR: 在纳米线基安德烈夫分子中实现了约瑟夫森二极管效应的非局域调控，可通过非局域相位和栅极电压控制，为超导器件发展带来新机遇。


<details>
  <summary>Details</summary>
Motivation: 超导系统在对称性破缺的条件下会表现出非互易的电流传输，即超导二极管效应，能够实现超电流的完美整流，引起了广泛的研究兴趣。

Method: 通过实验观察约瑟夫森二极管效应（JDE），并利用非局域相位和栅极电压对其进行控制和调控。通过理论计算能量谱和约瑟夫森电流进行验证。

Result: 成功在纳米线基安德烈夫分子中观察到约瑟夫森二极管效应（JDE），并实现了对其的非局域调控。实验结果与理论计算结果吻合良好。

Conclusion: 本研究观察到了约瑟夫森二极管效应（JDE），并在纳米线基安德烈夫分子中实现了对其的非局域调控，为多约瑟夫森结器件和先进超导器件的发展提供了新的思路。

Abstract: Superconducting systems exhibit non-reciprocal current transport under
certain conditions of symmetry breaking, a phenomenon known as the
superconducting diode effect. This effect allows for perfect rectification of
supercurrent, and has received considerable research interest. We report the
observation of the Josephson diode effect (JDE) in nanowire-based Andreev
molecules, where the time-reversal and spatial-inversion symmetries of a
Josephson junction (JJ) can be nonlocally broken by coherently coupling to
another JJ. The JDE can be controlled using both non-local phase and gate
voltages. Notably, the non-local phase can induce a sign reversal of the diode
efficiency, a manifestation of regulating the probabilities of double elastic
cotunneling and double-crossed Andreev reflection. Additionally, the diode
efficiency can be further modulated by local and non-local gate voltages,
exhibiting a central-peak feature in the gate-voltage space. Our theoretical
calculations of the energy spectrum and the Josephson currents align well with
the experimental results. These results demonstrate the non-local regulation of
the JDE in Andreev molecules, offering significant implications for the control
of multi-JJ devices and the development of advanced superconducting devices.

</details>


### [223] [Realization and characterization of an all-bands-flat electronic lattice](https://arxiv.org/abs/2508.13571)
*Noah Lape,Simon Diubenkov,L. Q. English,P. G. Kevrekidis,Alexei Andreanov,Yeongjun Kim,Sergej Flach*

Main category: cond-mat.mes-hall

TL;DR: 本研究在电子网络中实现了全带隙平坦晶格和紧域态，为相关领域的实验研究提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 探索ABF系统在电力网络中的实验实现，并研究其与非线性的相互作用。

Method: 通过构建一个由电容器、电感器和电压反相器组成的菱形链网络来实现ABF晶格，并引入π相位约瑟夫森结。

Result: 实验结果与紧束缚模型预测高度吻合，证实了ABF晶格和CLSs的生成。

Conclusion: 本研究成功构建了一个电子全带隙平坦（ABF）晶格，并在其中实验生成了紧域态（CLSs）。

Abstract: We construct an electronic all-bands-flat (ABF) lattice and experimentally
generate compact localized states (CLSs) therein. The lattice is a diamond
(rhombic) chain and implemented as a network of capacitors and inductors, as
well as voltage inverters (using operational amplifiers) in order to introduce
a \(\pi\)-phase flux within each diamond. The network's normal modes split into
three flat bands, and the corresponding CLSs can be excited in isolation via a
two-node driving at the flat band frequencies. We also examine the role of the
lattice edges and their interaction with the CLSs. Finally, we compare the
experimental results to tight-binding predictions and obtain very good
agreement. This analysis paves the way for further experimental implementations
of ABF systems in electric networks, especially with an eye towards exploring
their interplay with nonlinearity.

</details>


### [224] [The properties of the nitrogen-vacancy center in milled chemical vapor deposition nanodiamonds](https://arxiv.org/abs/2508.13725)
*Alessandro Mameli,Giannis Thalassinos,Marco Capelli,Johannes Ackermann,Edwin Mayes,Hiroshi Abe,Takeshi Ohshima,Tingpeng Luo,Volker Cimalla,Peter Knittel,Brant Gibson,Jan Jeske,Nikolai Dontschuk,Anke Krueger,Alastair Stacey,Alexander Healey,Philipp Reineck*

Main category: cond-mat.mes-hall

TL;DR: 这项研究通过优化球磨工艺，成功地利用CVD金刚石制备了荧光纳米金刚石（FNDs），这些FNDs表现出与体相金刚石相似的T1自旋弛豫时间，为量子传感应用提供了有前景的材料。


<details>
  <summary>Details</summary>
Motivation: 开发一种可扩展的荧光纳米金刚石（FNDs）制备方法，该方法能够实现对量子传感应用至关重要的、具有稳定体相光学和自旋性质的色心。

Method: 研究了通过化学气相沉积（CVD）方法生产的单晶金刚石，其中含有2 ppm的取代氮和0.3 ppm的NV-，并优化了球磨工艺，以实现含有具有一致的类体相光致发光（PL）和自旋相干性质的色心。

Result: 研究发现，与HPHT FNDs相比，CVD FNDs的NV-电荷态对总NV PL的相对贡献较低，NV PL寿命较长，这可能归因于CVD FNDs中Ns0浓度较低。CVD块体和CVD FNDs的平均T1自旋弛豫时间分别为3.2 ± 0.7 ms和4.7 ± 1.6 ms，而商业HPHT FNDs的平均T1自旋弛豫时间为0.17 ± 0.01 ms。

Conclusion: 本研究表明，通过对CVD金刚石进行球磨，可以大规模制备具有类体相T1自旋弛豫特性的NV团簇荧光纳米金刚石。

Abstract: Fluorescent nanodiamonds (FNDs) containing negatively charged
nitrogen-vacancy (NV-) centers are vital for many emerging quantum sensing
applications from magnetometry to intracellular sensing in biology. However,
developing a scalable fabrication method for FNDs hosting color centers with
consistent bulk-like photoluminescence (PL) and spin coherence properties
remains a highly desired but unrealized goal. Here, we investigate optimized
ball milling of single-crystal diamonds produced via chemical vapor deposition
(CVD) and containing 2 ppm of substitutional nitrogen and 0.3 ppm of NV- to
achieve this goal. The NV charge state, PL lifetime, and spin properties of
bulk CVD diamond samples are directly compared to milled CVD FNDs and
commercial high-pressure high-temperature (HPHT) FNDs. We find that on average,
the relative contribution of the NV- charge state to the total NV PL is lower
and the NV PL lifetime is longer in CVD FNDs compared to HPHT FNDs, both likely
due to the lower Ns0 concentration in CVD FNDs. The CVD bulk and CVD FNDs on
average show similar average T1 spin relaxation times of 3.2 $\pm$ 0.7 ms and
4.7 $\pm$ 1.6 ms, respectively, compared to 0.17 $\pm$ 0.01 ms for commercial
HPHT FNDs. Our results demonstrate that ball milling of CVD diamonds enables
the large-scale fabrication of NV ensembles in FNDs with bulk-like T1 spin
relaxation properties.

</details>


### [225] [Magnetic brightening of light-like excitons in a monolayer semiconductor](https://arxiv.org/abs/2508.13784)
*A. Delhomme,T. Amit,P. Ji,C. Faugeras,S. Refaely-Abramson,J. J. Finley,A. V. Stier*

Main category: cond-mat.mes-hall

TL;DR: WSe$_2$单层半导体中的激子在强磁场下表现出新的自旋单态激子，该激子由电子-空穴交换相互作用引起，并可能导致准暗激子猝灭。


<details>
  <summary>Details</summary>
Motivation: 为了理解和揭示WSe$_2$单层半导体中由长程电子-空穴交换相互作用引起的激子行为，特别是其在磁场下的表现。

Method: 通过~25T磁场下的磁光致发光光谱学研究了WSe$_2$单层半导体的激子。

Result: 观察到了一个新的蓝移发射峰，并确定该峰为自旋单态激子，其简并质量远小于中性激子。该激子的强度随磁场增加而增加，且其密度相关的抗磁位移比符合电子-空穴交换相互作用的预期。

Conclusion: 这项工作通过光谱学研究揭示了WSe$_2$单层半导体中激子的新奇行为，特别是提出了一个由电子-空穴交换相互作用引起的自旋单态激子，并解释了其在磁场下的行为。

Abstract: Monolayer transition-metal dichalcogenides, such as WSe$_2$, are direct gap,
multi-valley semiconductors. Long-range electron-hole exchange interactions mix
the valleys, yielding dispersion relations for massive ($\propto Q^2$) as well
as light-like ($\propto Q$) excitons. We report magneto-photoluminescence
spectroscopy of excitons in the monolayer semiconductor WSe$_2$ to $B =
\pm25$T. The magnetic field-dependent line shape of the neutral exciton reveals
the emergence of a new blue-detuned emission peak in both field orientations.
Analyzing the distinct magnetic field-dependent shifts of both peaks
facilitates the identification of the emergent feature as a spin-singlet with a
significantly smaller reduced exciton mass as compared to the neutral exciton.
The intensity of the emergent feature increases with magnetic field according
to $\propto B^2$, as expected for a linear dispersion relation. The
density-dependent diamagnetic shift ratios of both features follow the expected
density dependence of the electron-hole exchange interactions. We interpret our
observations within a picture of magnetic-field-induced coupling between the
bright massive and quasi dark light-like exciton, leading to its brightening.

</details>


<div id='cs.LO'></div>

# cs.LO [[Back]](#toc)

### [226] [Arithmetics within the Linear Time Hierarchy](https://arxiv.org/abs/2508.13195)
*Chris Pollett*

Main category: cs.LO

TL;DR: This paper analyzes fragments of arithmetic $S_1$, defining new syntactic classes and arithmetics ($\breve{S}^{i}_{1}$, $TLS^i_1$, $TSC^i_1$). It establishes subset and approximation relations between these arithmetics and characterizes their definable multifunctions in terms of complexity classes like logspace and $SC$. Independence results related to MRDP and P vs co-NP are also proven.


<details>
  <summary>Details</summary>
Motivation: To identify fragments of the arithmetic $S_1$ that enjoy nice closure properties and have exact characterization of their definable multifunctions.

Method: We defined new syntactic classes by counting bounded existential sharply bounded universal quantifiers blocks, starting from the formula classes, $\Sigma^{\mathsf b}_{i}$, which ignore sharply bounded quantifiers when determining quantifier alternations. Using these, we defined arithmetics: $\breve{S}^{i}_{1}$, $TLS^i_1$ and $TSC^i_1$.

Result: We proved that for $i \geq 1$, $TLS^i_1 \subseteq TSC^i_1 \subseteq \breve{S}^{i}_{1} \preceq_{\forall B(SITT_{i+1}^{\{p(|id|)\}})} TLS^{i+1}_1$. We also showed that the $SITT_{i}^{\{p(|id|)\}} $-definable in $TLS^i_1$ (resp. $SITT_{i}^{\{2^{p(||id||)}\}} $-definable in $TSC^i_1$) multifunctions are $L_1$-$FLOGSPACE^{SIT_{i,1}}[wit]$ (resp. $L_1$-$FSC^{SIT_{i,1}}[wit]$). For $i=1$, this simplifies to functions in logspace and $SC$ (poly-time, polylog-space).

Conclusion: We proved independence results related to the Matiyasevich Robinson Davis Putnam Theorem (MRDP) and to whether our theories prove simultaneous nondeterministic polynomial time, sublinear space is equal to co-nondeterministic polynomial time, sublinear space.

Abstract: We identify fragments of the arithmetic $S_1$ that enjoy nice closure
properties and have exact characterization of their definable multifunctions.
To do this, in the language of $S_1$, $L_1$, starting from the formula classes,
$\Sigma^{\mathsf b}_{i}$, which ignore sharply bounded quantifiers when
determining quantifier alternations, we define new syntactic classes by
counting bounded existential sharply bounded universal quantifiers blocks.
Using these, we define arithmetics: $\breve{S}^{i}_{1}$, $TLS^i_1$ and
$TSC^i_1$. $\breve{S}^{i}_{1}$ consists of open axioms for the language symbols
and length induction for one of our new classes, $SIUT_{i,1}^{\{p(|id|)\}}$.
$TLS^i_1$ and $TSC^i_1$ are defined using axioms related to dependent choice
sequences for formulas from two other classes within $\Sigma^{\mathsf b}_{i}$.
We prove for $i \geq 1$ that $$TLS^i_1 \subseteq TSC^i_1 \subseteq
\breve{S}^{i}_{1} \preceq_{\forall B(SITT_{i+1}^{\{p(|id|)\}})} TLS^{i+1}_1$$
and that the $SITT_{i}^{\{p(|id|)\}}$-definable in $TLS^i_1$ (resp.
$SITT_{i}^{\{2^{p(||id||)}\}}$-definable in $TSC^i_1$) multifunctions are
$L_1$-$FLOGSPACE^{SIT_{i,1}}[wit]$ (resp. $L_1$-$FSC^{SIT_{i,1}}[wit]$). These
multifunction classes are respectively the logspace or $SC$ (poly-time,
polylog-space) computable multifunctions whose output is bound by a term in
$L_1$ and that have access to a witness oracle for another restriction on the
$\Sigma^{\mathsf b}_{i}$ formulas, $SIT_{i,1}$. For the $i=1$ cases, this
simplifies respectively to the functions in logspace and $SC$, Steve's Class,
poly-time, polylog-space. We prove independence results related to the
Matiyasevich Robinson Davis Putnam Theorem (MRDP) and to whether our theories
prove simultaneous nondeterministic polynomial time, sublinear space is equal
to co-nondeterministic polynomial time, sublinear space.

</details>


### [227] [A Formalization of the Reversible Concurrent Calculus CCSKP in Beluga](https://arxiv.org/abs/2508.13612)
*Gabriele Cecilia*

Main category: cs.LO

TL;DR: 本文首次使用 Beluga 对可逆并发演算 CCSKP 进行了形式化，并探索了其证明标签关系，为相关领域的研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有可逆并发演算缺乏机器检查的形式化，本文旨在填补这一空白，并探索 CCSKP 及其证明标签关系。

Method: 使用 Beluga 对 CCSKP 及其可逆扩展进行了形式化，包括了其语法、语义以及关于证明标签的三个关系（依赖、独立和连通性）。

Result: 成功对 CCSKP 进行了 Beluga 形式化，并揭示了在形式化过程中对非正式证明进行的调整和明确化，其中一些调整比最初设想的更复杂。

Conclusion: 本文提出了第一个使用 Beluga 形式化通信系统演算（CCSKP）及其可逆扩展，并覆盖了三个关于证明标签的关系（依赖、独立和连通性），为未来可逆并发演算的形式化奠定了基础。

Abstract: Reversible concurrent calculi are abstract models for concurrent systems in
which any action can potentially be undone. Over the last few decades,
different formalisms have been developed and their mathematical properties have
been explored; however, none have been machine-checked within a proof
assistant. This paper presents the first Beluga formalization of the Calculus
of Communicating Systems with Keys and Proof labels (CCSKP), a reversible
extension of CCS. Beyond the syntax and semantics of the calculus, the encoding
covers state-of-the-art results regarding three relations over proof labels --
namely, dependence, independence and connectivity -- which offer new insights
into the notions of causality and concurrency of events. As is often the case
with formalizations, our encoding introduces adjustments to the informal proof
and makes explicit details which were previously only sketched, some of which
reveal to be less straightforward than initially assumed. We believe this work
lays the foundations for future reversible concurrent calculi formalizations.

</details>


### [228] [Modular Multiparty Sessions with Mixed Choice](https://arxiv.org/abs/2508.13616)
*Franco Barbanera,Mariangiola Dezani-Ciancaglini*

Main category: cs.LO

TL;DR: MPST with mixed choice is made safer using type assignment in modular systems.


<details>
  <summary>Details</summary>
Motivation: To increase the expressive power of MPST while maintaining safety through modular systems and mixed choice exploitation within modules.

Method: Type assignment approach to multiparty sessions with mixed choice in loosely coupled modules.

Result: Typability for modular sessions ensures Subject Reductions, Session Fidelity, and Lock Freedom.

Conclusion: The paper extends multiparty session types with mixed choice, focusing on type assignment for modular systems to ensure Subject Reductions, Session Fidelity, and Lock Freedom.

Abstract: MultiParty Session Types (MPST) provide a useful framework for safe
concurrent systems. Mixed choice (enabling a participant to play at the same
time the roles of sender and receiver) increases the expressive power of MPST
as well as the difficulty in controlling safety of communications. Such a
control is more viable when modular systems are considered and the power of
mixed choice fully exploited only inside loosely coupled modules. We carry over
such idea in a type assignment approach to multiparty sessions. Typability for
modular sessions entails Subject Reductions, Session Fidelity and Lock Freedom.

</details>


### [229] [On a Second-Order Version of Russellian Theory of Definite Descriptions](https://arxiv.org/abs/2508.13928)
*Yaroslav Petrukhin*

Main category: cs.LO

TL;DR: A second-order definite description for relations is proposed and formalized.


<details>
  <summary>Details</summary>
Motivation: To propose a second-order counterpart to definite descriptions that refers to unique relations between objects.

Method: Formalization using a cut-free sequent calculus within Henkin

Result: A formalization of a theory of definite descriptions for relations in a complete fragment of second-order logic.

Conclusion: We develop a theory of definite descriptions for relations within a complete fragment of second-order logic.

Abstract: Definite descriptions are first-order expressions that denote unique objects.
In this paper, we propose a second-order counterpart, designed to refer to
unique relations between objects. We investigate this notion within the
framework of Russell's theory of definite descriptions. While full second-order
logic is incomplete, its fragment defined by Henkin's general models admits
completeness. We develop our theory within this fragment and formalize it using
a cut-free sequent calculus.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [230] [Multi-Plasticity Synergy with Adaptive Mechanism Assignment for Training Spiking Neural Networks](https://arxiv.org/abs/2508.13673)
*Yuzhe Liu,Xin Deng,Qiang Yu*

Main category: cs.NE

TL;DR: This paper introduces a new training framework for Spiking Neural Networks (SNNs) that uses multiple, synergistic brain-inspired learning mechanisms. This approach improves SNN performance and robustness compared to existing methods that use only a single learning mechanism. The framework is general and extensible, providing a foundation for developing more powerful SNNs.


<details>
  <summary>Details</summary>
Motivation: Current SNN training methods typically rely on a single form of synaptic plasticity, which limits their adaptability and representational capability. This paper addresses this limitation by incorporating multiple synergistic plasticity mechanisms inspired by the brain.

Method: This paper proposes a biologically inspired training framework that incorporates multiple synergistic plasticity mechanisms for more effective SNN training. The method enables diverse learning algorithms to cooperatively modulate the accumulation of information, while allowing each mechanism to preserve its own relatively independent update dynamics.

Result: The proposed framework significantly improves performance and robustness compared to conventional learning mechanism models when evaluated on both static image and dynamic neuromorphic datasets.

Conclusion: Spiking Neural Networks (SNNs) are promising brain-inspired models known for low power consumption and superior potential for temporal processing, but identifying suitable learning mechanisms remains a challenge. Despite the presence of multiple coexisting learning strategies in the brain, current SNN training methods typically rely on a single form of synaptic plasticity, which limits their adaptability and representational capability. In this paper, we propose a biologically inspired training framework that incorporates multiple synergistic plasticity mechanisms for more effective SNN training. Our method enables diverse learning algorithms to cooperatively modulate the accumulation of information, while allowing each mechanism to preserve its own relatively independent update dynamics. We evaluated our approach on both static image and dynamic neuromorphic datasets to demonstrate that our framework significantly improves performance and robustness compared to conventional learning mechanism models. This work provides a general and extensible foundation for developing more powerful SNNs guided by multi-strategy brain-inspired learning.

Abstract: Spiking Neural Networks (SNNs) are promising brain-inspired models known for
low power consumption and superior potential for temporal processing, but
identifying suitable learning mechanisms remains a challenge. Despite the
presence of multiple coexisting learning strategies in the brain, current SNN
training methods typically rely on a single form of synaptic plasticity, which
limits their adaptability and representational capability. In this paper, we
propose a biologically inspired training framework that incorporates multiple
synergistic plasticity mechanisms for more effective SNN training. Our method
enables diverse learning algorithms to cooperatively modulate the accumulation
of information, while allowing each mechanism to preserve its own relatively
independent update dynamics. We evaluated our approach on both static image and
dynamic neuromorphic datasets to demonstrate that our framework significantly
improves performance and robustness compared to conventional learning mechanism
models. This work provides a general and extensible foundation for developing
more powerful SNNs guided by multi-strategy brain-inspired learning.

</details>


### [231] [Encoding Optimization for Low-Complexity Spiking Neural Network Equalizers in IM/DD Systems](https://arxiv.org/abs/2508.13783)
*Eike-Manuel Edelmann,Alexander von Bank,Laurent Schmalen*

Main category: cs.NE

TL;DR: A reinforcement learning approach optimizes SNN parameters for better performance and efficiency in communication systems.


<details>
  <summary>Details</summary>
Motivation: Neural encoding parameters for SNNs are typically set heuristically, prompting the development of an optimization method.

Method: Reinforcement learning-based algorithm for optimizing neural encoding parameters in Spiking Neural Networks (SNNs).

Result: The method improves performance while reducing computational load and network size when applied to an SNN-based equalizer and demapper in an IM/DD system.

Conclusion: The proposed reinforcement learning-based algorithm optimizes neural encoding parameters for SNNs, showing improved performance, reduced computational load, and smaller network size when applied to an IM/DD system's equalizer and demapper.

Abstract: Neural encoding parameters for spiking neural networks (SNNs) are typically
set heuristically. We propose a reinforcement learning-based algorithm to
optimize them. Applied to an SNN-based equalizer and demapper in an IM/DD
system, the method improves performance while reducing computational load and
network size.

</details>


### [232] [Zobrist Hash-based Duplicate Detection in Symbolic Regression](https://arxiv.org/abs/2508.13859)
*Bogdan Burlacu*

Main category: cs.NE

TL;DR: 通过引入基于Zobrist哈希的缓存机制，提高了GP在符号回归中的效率，实现了高达34%的速度提升。


<details>
  <summary>Details</summary>
Motivation: 分析了GP的演化搜索效率，并指出许多搜索空间点被算法重复访问和重新评估，导致计算资源浪费。

Method: 通过使用基于Zobrist哈希的缓存机制来解决GP中搜索空间重复访问和重新评估的问题。

Result: 在真实的回归问题上实现了高达34%的速度提升，且没有对搜索质量产生不利影响。

Conclusion: 该哈希方法是一种提高运行性能的简单方法，同时还提供了根据缓存信息调整搜索策略的一些有趣的可能性。

Abstract: Symbolic regression encompasses a family of search algorithms that aim to
discover the best fitting function for a set of data without requiring an a
priori specification of the model structure. The most successful and commonly
used technique for symbolic regression is Genetic Programming (GP), an
evolutionary search method that evolves a population of mathematical
expressions through the mechanism of natural selection. In this work we analyze
the efficiency of the evolutionary search in GP and show that many points in
the search space are re-visited and re-evaluated multiple times by the
algorithm, leading to wasted computational effort. We address this issue by
introducing a caching mechanism based on the Zobrist hash, a type of hashing
frequently used in abstract board games for the efficient construction and
subsequent update of transposition tables. We implement our caching approach
using the open-source framework Operon and demonstrate its performance on a
selection of real-world regression problems, where we observe up to 34\%
speedups without any detrimental effects on search quality. The hashing
approach represents a straightforward way to improve runtime performance while
also offering some interesting possibilities for adjusting search strategy
based on cached information.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [233] [Airborne acoustic emission enables sub-scanline keyhole porosity quantification and effective process characterization for metallic laser powder bed fusion](https://arxiv.org/abs/2508.13492)
*Haolin Liu,David Guirguis,Xuzhe Zeng,Logan Maurer,Vigknesh Rajan,Niloofar Sanaei,Chi-Ta Yang,Jack L. Beuth,Anthony D. Rollett,Levent Burak Kara*

Main category: physics.app-ph

TL;DR: 本研究提出了一种基于航空声发射（AE）信号的框架，用于高精度量化激光粉末床熔融（LPBF）中的键孔（KH）孔隙。通过训练神经网络，实现了对KH孔隙的实时预测，并能识别出关键的AE频段和KH区域边界，为LPBF工艺的缺陷检测和过程控制提供了新的方法。


<details>
  <summary>Details</summary>
Motivation: 键孔（KH）孔隙是激光粉末床熔融（LPBF）中一个严峻的挑战，它源于不稳定的蒸汽腔动力学和过量的激光能量输入。为了解决这一问题，本研究旨在开发一种能够高精度量化KH孔隙的方法，并提供一种实时、非侵入性的监测和过程控制手段。

Method: 本研究提出了一种结合实验和数据驱动的框架，利用航空声发射（AE）信号来量化激光粉末床熔融（LPBF）过程中的键孔（KH）孔隙。研究人员在LPBF系统上进行了实验，同步采集了AE信号和通过X射线计算机断层扫描（XCT）获得的孔隙图像。他们定义了一个新的孔隙度量指标KHLineNum（每单位扫描长度的KH孔隙数），并利用AE的scalogram数据和扫描速度训练了一个卷积神经网络（CNN）来预测KHLineNum。

Result: 该框架成功实现了对KH孔隙的量化，预测KHLineNum的R平方值超过0.8。研究发现35-45 kHz频带的AE信号对于KH孔隙的识别尤其重要，这与已知的KH振荡规律一致。此外，该框架还能在功率-速度工艺图上直接推断出KH区域的边界。

Conclusion: 该框架通过在激光粉末床熔融（LPBF）过程中利用航空声发射（AE）信号，实现了对键孔（KH）孔隙的高分辨率量化和实时监测。通过识别35-45 kHz频带内的AE信号，并结合卷积神经网络，可以以毫秒级的时间分辨率预测KH孔隙的数量，R平方值超过0.8。该方法不仅能够量化孔隙的严重程度，还能在功率-速度工艺图上直接推断出KH区域的边界，为LPBF工艺提供了一种非侵入性、可扩展且有效的缺陷检测和过程控制新途径。

Abstract: Keyhole-induced (KH) porosity, which arises from unstable vapor cavity
dynamics under excessive laser energy input, remains a significant challenge in
laser powder bed fusion (LPBF). This study presents an integrated experimental
and data-driven framework using airborne acoustic emission (AE) to achieve
high-resolution quantification of KH porosity. Experiments conducted on an LPBF
system involved in situ acquisition of airborne AE and ex situ porosity imaging
via X-ray computed tomography (XCT), synchronized spatiotemporally through
photodiode signals with submillisecond precision. We introduce KHLineNum, a
spatially resolved porosity metric defined as the number of KH pores per unit
scan length, which serves as a physically meaningful indicator of the severity
of KH porosity in geometries and scanning strategies. Using AE scalogram data
and scan speed, we trained a lightweight convolutional neural network to
predict KHLineNum with millisecond-scale temporal resolution, achieving an
R-squared value exceeding 0.8. Subsequent analysis identified the 35-45 kHz
frequency band of AE as particularly informative, consistent with known KH
oscillations. Beyond defect quantification, the framework also enables
AE-driven direct inference of KH regime boundaries on the power-velocity
process map, offering a noninvasive and scalable component to labor-intensive
post-process techniques such as XCT. We believe this framework advances
AE-based monitoring in LPBF, providing a pathway toward improved quantifiable
defect detection and process control.

</details>


### [234] [Gear-shifting tunable meta-shaft for low-frequency torsional vibration suppression](https://arxiv.org/abs/2508.13621)
*Dongxian Wang,Hao Zhou,Jianlei Zhao,Zhou Hu,Yangyang Chen,Rui Zhu*

Main category: physics.app-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Metastructures with band gaps provide a new solution for the torsional
vibration attenuation in shaft systems, while tunable band gaps remain
challenging, typically relying on additional physical fields or complex
assembly processes. In this study, a gear-shifting tunable meta-shaft with
self-locking gear (SLG) resonators is proposed, where a simple gear-shifting
mechanism replaces complex tuning methods to achieve low-frequency torsional
vibration suppression in tunable frequency ranges. First, as the key components
of the SLG resonator, six inner curved beams are designed to provide precisely
tunable torsional stiffness of the resonator through their deformed shapes
controlled by shifting the gear teeth on the edge of the resonator. Also, based
on the gear-shifting mechanism, the SLG resonator achieves resonant frequency
modulation and opens tunable low-frequency torsional band gaps consistent with
theoretical predictions. Then, the SLG resonators are periodically attached to
a uniform shaft to construct a gear-shifting tunable meta-shaft, whose dynamic
response is obtained using numerical simulations to evaluate its torsional wave
attenuation performance. Finally, a gear-shifting tunable meta-shaft prototype
is fabricated and experiments are carried out to study the propagation
characteristics of torsional waves therein. Through the consistency observed
among theoretical analysis, numerical simulations, and experimental results,
the gear-shifting tunable meta-shaft is found to exhibit excellent attenuation
performance in the tunable low-frequency band gaps. Therefore, the proposed
gear-shifting tunable meta-shaft paves a new way for low-frequency torsional
vibration suppression.

</details>


### [235] [Charge accumulation by Direct Magnetoelectric Effect in ScAlN/Ni Nanoscale Devices](https://arxiv.org/abs/2508.13674)
*Federica Luciano,Emma Van Meirvenne,Ephraim Spindler,Philipp Pirro,Bart Sorée,Mathias Weiler,Stefan De Gendt,Florin Ciubotaru,Christoph Adelmann*

Main category: physics.app-ph

TL;DR: 通过制备亚微米级的 ScAlN/Ni 薄膜器件，成功验证了直接磁电效应，并获得了高达 1.17 mV 的等效开路电压。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探索由压电 ScAlN 和磁致伸缩 Ni 组成的复合异质结薄膜中的直接磁电效应，特别关注在亚微米尺度下的器件性能。

Method: 通过制备 ScAlN/Ni 复合异质结薄膜，并将其图案化为亚微米级方形柱阵列，利用 VSM 和 NV 磁测量技术研究其磁特性，并通过准静态电荷测量验证了直接磁电效应。

Result: VSM 测量显示 Ni 膜具有面内磁各向异性；NV 磁测量证实了亚微米级 Ni 结构中磁畴的形成；器件级电容测量表明 ScAlN 介电常数与未图案化薄膜一致；准静态电荷测量在 1.17 mV 的等效开路电压下证明了直接磁电效应。

Conclusion: 研究表明，在 ScAlN/Ni 异质结薄膜器件中，即使在亚微米尺度下，也能实现 1.17 mV 的等效开路电压。

Abstract: This work investigates the direct magnetoelectric effect in thin-film lab
scale composite heterostructures comprising a 100 nm thick piezoelectric
Sc0.4Al0.6N (ScAlN) and a magnetostrictive Ni with 100-200 nm thickness,
fabricated on Si/SiO2 substrates. The films are patterned into square pillar
arrays with lateral dimensions down to 500 nm x 500 nm. Vibrating sample
magnetometry (VSM) measurements reveal in-plane magnetic anisotropy in the Ni
films, attributed to strain induced by the underlying ScAlN layer.
Nitrogen-vacancy (NV) magnetometry imaging confirms the formation of magnetic
domains at remanence in polycrystalline Ni when patterned in sub-microscale
structures. Capacitance measurements reveal a ScAlN dielectric constant at the
device level consistent with unpatterned thin films, confirming the
preservation of electrical integrity at the sub-microscale. The direct
magnetoelectric effect is demonstrated through quasi-static charge measurements
under applied out-of-plane DC magnetic fields, yielding equivalent open-circuit
voltages up to 1.17 mV.

</details>


### [236] [Modification of adhesion between microparticles and engineered silicon surfaces](https://arxiv.org/abs/2508.13887)
*Fabian Resare,Somiya Islam Soke,Witlef Wieczorek*

Main category: physics.app-ph

TL;DR: 通过处理硅基底表面，大幅降低了微粒的附着力，提高了微粒悬浮的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决微粒在实验中附着于基底的挑战，特别是为了克服附着力以实现微粒悬浮和捕获。

Method: 通过化学、物理或理化方法对硅基底表面进行工程处理，并量化评估不同处理方法对微粒与基底之间附着力的影响。

Result: 开发出能够将平均分离力降低三倍以上，或将50%颗粒的移动力降低六倍以上的表面处理方法，并发现疏水性表面与低附着力之间存在相关性。

Conclusion: 通过对硅基底进行表面工程处理，可以有效降低微粒与基底之间的附着力，为微粒的可靠悬浮提供技术支持，并对需要低附着力应用的研究具有参考价值。

Abstract: A key challenge in performing experiments with microparticles is controlling
their adhesion to substrates. For example, levitation of a microparticle
initially resting on a surface requires overcoming the surface adhesion forces
to deliver the microparticle into a mechanical potential acting as a trap. By
engineering the surface of silicon substrates, we aim to decrease the adhesion
force between a metallic microparticle and the silicon surface. To this end, we
investigate different methods of surface engineering that are based on
chemical, physical, or physio-chemical modifications of the surface of silicon.
We give quantitative results on the detachment force, finding a correlation
between the water contact angle and the mean detachment force, indicating that
hydrophobic surfaces are desired for low microparticle adhesion. We develop
surface preparations decreasing the mean detachment force by more than a factor
of three, or the force at which 50% of particles move by more than a factor of
six, the compared to an untreated silicon surface. Our results will enable
reliable levitation of microparticles and are relevant for experiments
requiring low adhesion between microparticles and a surface.

</details>


### [237] [Breaking the material-limited temperature coefficient of resistance via carrier feedback in a single transistor](https://arxiv.org/abs/2508.13987)
*Jiazhen Chen,Yihao Song,David Alexander Montealegre,Mingyang Cai,Minjoo Larry Lee,Fengnian Xia*

Main category: physics.app-ph

TL;DR: 通过InGaAs/InP n-p-n晶体管的载流子反馈机制，实现了高TCR，有望应用于热成像等领域。


<details>
  <summary>Details</summary>
Motivation: 为应对传统热成像材料TCR较低的挑战，研究了具有高TCR的半导体材料在自主系统热成像、高精度传感和神经形态计算等应用中的潜力。

Method: 通过集成InGaAs/InP n-p-n晶体管，利用内部相干载流子反馈机制，实现了高达150%/K的电压可调温度系数（TCR）。

Result: 在两端InGaAs/InP n-p-n晶体管中，实现了高达150%/K的电压可调TCR，这得益于温度依赖的晶体管增益和雪崩倍增之间的协同作用。

Conclusion: 本研究揭示了器件工程在克服材料层面物理极限方面的潜力。

Abstract: The temperature coefficient of resistance (TCR) is one of the most
fundamental properties of a material. Semiconductor materials exhibiting high
TCR are promising candidates for applications in high-resolution thermal
imaging for autonomous systems, high-precision temperature sensing, and
neuromorphic computing. However, the TCR magnitude is typically below 5%/K near
300 K for thermal imaging materials, such as vanadium oxide and amorphous
silicon. Inspired by the distinctive characteristic of feedback in electronic
circuits, we demonstrate a voltage-tunable TCR of up to 150%/K near 300 K in a
two-terminal InGaAs/InP n-p-n transistor, enabled by an internal coherent
carrier feedback mechanism. In this device, current amplification arises from a
synergistic interplay between temperature-dependent transistor gain and
avalanche multiplication. Carriers amplified at the emitter-base junction via
the transistor effect are injected into the collector-base junction, where
avalanche multiplication generates additional carriers. These excess carriers
are then fed back to the emitter-base junction, triggering further transistor
amplification. This regenerative positive feedback loop results in a high and
bias-tunable temperature coefficient of resistance (TCR). This work reveals the
potential of device engineering in overcoming the fundamental material-level
physical limits of temperature properties.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [238] [Goal-Directedness is in the Eye of the Beholder](https://arxiv.org/abs/2508.13247)
*Nina Rajcic,Anders Søgaard*

Main category: cs.MA

TL;DR: 提出目标导向性无法被客观衡量，并主张将其视为动态多智能体系统中涌现出的属性。


<details>
  <summary>Details</summary>
Motivation: 探究预测复杂智能体行为的能力，并将目标归因于其行为。

Method: 通过分析行为和机制两种方法来探究目标导向行为，并识别出在形式化智能体系统中的目标时出现的技朧和概念问题。

Result: 识别出在形式化智能体系统中的目标时出现的技朧和概念问题，并提出目标导向性无法被客观衡量。

Conclusion: 目标导向性无法被客观衡量，应将目标导向性视为动态多智能体系统中涌现出的属性。

Abstract: Our ability to predict the behavior of complex agents turns on the
attribution of goals. Probing for goal-directed behavior comes in two flavors:
Behavioral and mechanistic. The former proposes that goal-directedness can be
estimated through behavioral observation, whereas the latter attempts to probe
for goals in internal model states. We work through the assumptions behind both
approaches, identifying technical and conceptual problems that arise from
formalizing goals in agent systems. We arrive at the perhaps surprising
position that goal-directedness cannot be measured objectively. We outline new
directions for modeling goal-directedness as an emergent property of dynamic,
multi-agent systems.

</details>


### [239] [Self-Organizing Agent Network for LLM-based Workflow Automation](https://arxiv.org/abs/2508.13732)
*Yiming Xiong,Jian Wang,Bing Li,Yuhan Zhu,Yuqi Zhao*

Main category: cs.MA

TL;DR: SOAN是一个处理复杂、多层嵌套的企业工作流的框架，通过将工作流模块化为代理来提高效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的多代理框架在处理真实世界企业环境中复杂、多层嵌套的工作流时面临挑战，因为长推理链和状态空间爆炸会影响规划效果和工具调用的正确排序。

Method: 提出了一种新颖的结构驱动的编排框架Self-Organizing Agent Network (SOAN)，通过识别和封装结构单元作为独立代理来构建形式化的代理网络。

Result: SOAN在适应性、容错性和执行效率方面显著优于最先进的方法。

Conclusion: SOAN通过识别和封装结构单元作为独立代理，逐步构建形式化的代理网络，提高了编排的模块化和清晰度。实验结果表明，SOAN在适应性、容错性和执行效率方面明显优于最先进的方法。

Abstract: Recent multi-agent frameworks built upon large language models (LLMs) have
demonstrated remarkable capabilities in complex task planning. However, in
real-world enterprise environments, business workflows are typically composed
through modularization and reuse of numerous subprocesses, resulting in
intricate workflows characterized by lengthy and deeply nested execution paths.
Such complexity poses significant challenges for LLM-driven orchestration, as
extended reasoning chains and state-space explosions severely impact planning
effectiveness and the proper sequencing of tool invocations. Therefore,
developing an orchestration method with controllable structures capable of
handling multi-layer nesting becomes a critical issue. To address this, we
propose a novel structure-driven orchestration framework Self-Organizing Agent
Network (SOAN). SOAN incrementally builds a formalized agent network by
identifying and encapsulating structural units as independent agents, enhancing
modularity and clarity in orchestration. Extensive evaluations were performed
using multiple benchmarks as well as a real-world enterprise workflow dataset.
Experimental results demonstrate that SOAN significantly outperforms
state-of-the-art methods in terms of adaptability, fault tolerance, and
execution efficiency.

</details>


### [240] [BetaWeb: Towards a Blockchain-enabled Trustworthy Agentic Web](https://arxiv.org/abs/2508.13787)
*Zihan Guo,Yuanjian Zhou,Chenyi Wang,Linlin You,Minjie Bian,Weinan Zhang*

Main category: cs.MA

TL;DR: 本文提出BetaWeb，一个基于区块链的可信Agentic Web框架，旨在解决当前Agentic AI生态系统碎片化的问题，并通过整合区块链和LaMAS来构建一个可信赖、可扩展且可持续激励的数字生态系统，推动Agentic AI向Web3.5演进。


<details>
  <summary>Details</summary>
Motivation: 当前Agentic AI生态系统碎片化、封闭且面临隐私保护、数据管理和价值衡量等挑战，现有的中心化或半中心化范式无法支持大规模、异构和跨领域的自主交互。

Method: 提出了一种名为BetaWeb的区块链驱动的可信Agentic Web框架，旨在解决当前Agentic AI生态系统的碎片化和封闭性问题，并提出一个五阶段的演进路线图。

Result: BetaWeb框架利用区块链的优势，提供了可信赖且可扩展的LaMAS基础设施，并提出一个从Web3（数据所有权）到Web3.5（智能体能力所有权和智能货币化）的演进方向。此外，还进行了现有产品的比较分析，并从多角度讨论了BetaWeb的关键挑战。

Conclusion: 深度整合区块链与LaMAS（大语言模型驱动的多智能体系统）能够为建立一个有弹性、可信赖且具有可持续激励的数字生态系统奠定基础。

Abstract: The rapid development of large language models (LLMs) has significantly
propelled the development of artificial intelligence (AI) agents, which are
increasingly evolving into diverse autonomous entities, advancing the LLM-based
multi-agent systems (LaMAS). However, current agentic ecosystems remain
fragmented and closed. Establishing an interconnected and scalable paradigm for
Agentic AI has become a critical prerequisite. Although Agentic Web proposes an
open architecture to break the ecosystem barriers, its implementation still
faces core challenges such as privacy protection, data management, and value
measurement. Existing centralized or semi-centralized paradigms suffer from
inherent limitations, making them inadequate for supporting large-scale,
heterogeneous, and cross-domain autonomous interactions. To address these
challenges, this paper introduces the blockchain-enabled trustworthy Agentic
Web (BetaWeb). By leveraging the inherent strengths of blockchain, BetaWeb not
only offers a trustworthy and scalable infrastructure for LaMAS but also has
the potential to advance the Web paradigm from Web3 (centered on data
ownership) towards Web3.5, which emphasizes ownership of agent capabilities and
the monetization of intelligence. Beyond a systematic examination of the
BetaWeb framework, this paper presents a five-stage evolutionary roadmap,
outlining the path of LaMAS from passive execution to advanced collaboration
and autonomous governance. We also conduct a comparative analysis of existing
products and discuss key challenges of BetaWeb from multiple perspectives.
Ultimately, we argue that deep integration between blockchain and LaMAS can lay
the foundation for a resilient, trustworthy, and sustainably incentivized
digital ecosystem. A summary of the enabling technologies for each stage is
available at https://github.com/MatZaharia/BetaWeb.

</details>


### [241] [COCO: Cognitive Operating System with Continuous Oversight for Multi-Agent Workflow Reliability](https://arxiv.org/abs/2508.13815)
*Churong Liang,Jinling Gan,Kairan Hong,Qiushi Tian,Zongze Wu,Runnan Li*

Main category: cs.MA

TL;DR: COCO是一个用于多代理系统的框架，通过异步自我监控和自适应错误校正来解决错误传播问题，实现了更高的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大规模多代理工作流在错误传播和质量下降方面存在固有的脆弱性，下游代理在没有纠正机制的情况下会累积上游的失败。

Method: COCO（具有持续监督的认知操作系统）是一个理论上可靠的框架，它在多代理驱动的系统中实现了异步自我监控和自适应错误校正。它采用了一种新颖的解耦架构，将错误检测与关键执行路径分离，实现了相对于工作流复杂度的O(1)监控开销。COCO通过三种关键的算法创新来解决系统性和随机性错误：1）上下文回滚机制，一种有状态的重启协议，保存执行历史和错误诊断，从而进行有根据的重新计算而不是盲目重试；2）双向反射协议，监控和执行模块之间的相互验证系统，可以防止振荡行为并确保收敛性；3）异构交叉验证，利用模型多样性，通过集成不一致度量来检测系统偏差和幻觉。

Result: COCO实现了O(1)的监控开销，平均性能提高了6.5%，树立了自主工作流可靠性的新标杆。

Conclusion: COCO在基准多代理任务上的广泛实验证明，平均性能提高了6.5%，为自主工作流的可靠性树立了新的技术水平。

Abstract: Large-scale multi-agent workflows exhibit inherent vulnerability to error
propagation and quality degradation, where downstream agents compound upstream
failures without corrective mechanisms. We introduce COCO (Cognitive Operating
System with Continuous Oversight), a theoretically-grounded framework that
implements asynchronous self-monitoring and adaptive error correction in
multi-agent driven systems. COCO addresses the fundamental trade-off between
quality assurance and computational efficiency through a novel decoupled
architecture that separates error detection from the critical execution path,
achieving $O(1)$ monitoring overhead relative to workflow complexity. COCO
employs three key algorithmic innovations to address systematic and stochastic
errors: (1) Contextual Rollback Mechanism - a stateful restart protocol that
preserves execution history and error diagnostics, enabling informed
re-computation rather than naive retry; (2) Bidirectional Reflection Protocol -
a mutual validation system between monitoring and execution modules that
prevents oscillatory behavior and ensures convergence; (3) Heterogeneous
Cross-Validation - leveraging model diversity to detect systematic biases and
hallucinations through ensemble disagreement metrics. Extensive experiments on
benchmark multi-agent tasks demonstrate 6.5\% average performance improvement,
establishing new state-of-the-art for autonomous workflow reliability.

</details>


### [242] [The Multi-Stage Assignment Problem: A Fairness Perspective](https://arxiv.org/abs/2508.13856)
*Vibulan J,Swapnil Dhamal,Shweta Jain*

Main category: cs.MA

TL;DR: Fair assignment on multi-stage graphs is NP-hard. We propose C-Balance (for 2 agents) and DC-Balance (for n agents) algorithms that bound unfairness (envy) and cost of fairness (CoF), and are much faster than ILP.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the problem of fair assignment on Multi-Stage graphs, where minimizing overall cost can lead to significant unfairness and cost disparities (envy) among agents. Finding an envy-minimizing assignment is NP-hard, necessitating the development of efficient algorithms.

Method: This paper proposes the C-Balance algorithm for two agents and extends it to the DC-Balance algorithm for n agents to find fair assignments on Multi-Stage graphs. The algorithms are analyzed for envy bounds and Cost of Fairness (CoF). The tightness of C-Balance is demonstrated with an instance yielding 2M envy. Experimental results compare the proposed algorithms with Integer Linear Programming (ILP).

Result: The C-Balance algorithm guarantees envy bounded by 2M for two agents and a CoF bounded by 2. The DC-Balance algorithm converges and achieves envy arbitrarily close to 2M for n agents, with analyzed CoF bounds. Both algorithms are shown to be much faster than ILP.

Conclusion: C-Balance and DC-Balance algorithms are proposed to address the fair assignment problem on Multi-Stage graphs. C-Balance guarantees bounded envy for two agents and has a bounded Cost of Fairness (CoF). DC-Balance extends this to n agents with convergence and arbitrarily close to 2M envy, and its CoF bounds are analyzed. Experimentally, these algorithms are significantly faster than ILP formulations.

Abstract: This paper explores the problem of fair assignment on Multi-Stage graphs. A
multi-stage graph consists of nodes partitioned into $K$ disjoint sets (stages)
structured as a sequence of weighted bipartite graphs formed across adjacent
stages. The goal is to assign node-disjoint paths to $n$ agents starting from
the first stage and ending in the last stage. We show that an efficient
assignment that minimizes the overall sum of costs of all the agents' paths may
be highly unfair and lead to significant cost disparities (envy) among the
agents. We further show that finding an envy-minimizing assignment on a
multi-stage graph is NP-hard. We propose the C-Balance algorithm, which
guarantees envy that is bounded by $2M$ in the case of two agents, where $M$ is
the maximum edge weight. We demonstrate the algorithm's tightness by presenting
an instance where the envy is $2M$. We further show that the cost of fairness
($CoF$), defined as the ratio of the cost of the assignment given by the fair
algorithm to that of the minimum cost assignment, is bounded by $2$ for
C-Balance. We then extend this approach to $n$ agents by proposing the
DC-Balance algorithm that makes iterative calls to C-Balance. We show the
convergence of DC-Balance, resulting in envy that is arbitrarily close to $2M$.
We derive $CoF$ bounds for DC-Balance and provide insights about its dependency
on the instance-specific parameters and the desired degree of envy. We
experimentally show that our algorithm runs several orders of magnitude faster
than a suitably formulated ILP.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [243] [Chain-of-Agents: End-to-End Agent Foundation Models via Multi-Agent Distillation and Agentic RL](https://arxiv.org/abs/2508.13167)
*Weizhen Li,Jianbo Lin,Zhuosong Jiang,Jingyi Cao,Xinpeng Liu,Jiayu Zhang,Zhenqiang Huang,Qianben Chen,Weichen Sun,Qiexiang Wang,Hongxuan Lu,Tianrui Qin,Chenghao Zhu,Yi Yao,Shuying Fan,Xiaowan Li,Tiannan Wang,Pai Liu,King Zhu,He Zhu,Dingfeng Shi,Piaohong Wang,Yeyi Guan,Xiangru Tang,Minghao Liu,Yuchen Eleanor Jiang,Jian Yang,Jiaheng Liu,Ge Zhang,Wangchunshu Zhou*

Main category: cs.AI

TL;DR: Chain-of-Agents (CoA) 是一种新的 LLM 推理范式，它在单个模型中实现了端到端的复杂问题解决，就像多智能体系统一样。通过多智能体蒸馏和代理强化学习训练的 Agent Foundation Models (AFMs) 在各种基准测试中取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体系统在计算效率、能力和数据驱动学习方面存在不足，因为它们依赖于手动提示/工作流工程。

Method: 通过多智能体蒸馏框架将最先进的多智能体系统提炼成代理链轨迹，用于代理监督微调，然后利用可验证的代理任务上的代理强化学习来进一步改进模型。

Result: AFM 在网络代理和代码代理环境中，在多个基准测试中都取得了新的最先进性能。

Conclusion: AFM 在网络代理和代码代理环境中，在多个基准测试中都取得了新的最先进性能。

Abstract: Recent advances in large language models (LLMs) and multi-agent systems have
demonstrated remarkable capabilities in complex problem-solving tasks such as
deep research, vibe coding, and mathematical reasoning. However, most existing
multi-agent systems are built upon manual prompt/workflow engineering with
sophisticated agent frameworks, making them computationally inefficient, less
capable, and can not benefit from data-centric learning. In this work, we
introduce Chain-of-Agents (CoA), a novel paradigm of LLM reasoning that enables
native end-to-end complex problem-solving in the same way as a multi-agent
system (i.e., multi-turn problem solving with multiple tools and multiple
agents) within one model. In chain-of-agents problem-solving, the model
dynamically activates different tool agents and role-playing agents to simulate
multi-agent collaboration in an end-to-end fashion. To elicit end-to-end
chain-of-agents problem-solving abilities in LLMs, we introduce a multi-agent
distillation framework to distill state-of-the-art multi-agent systems into
chain-of-agents trajectories for agentic supervised fine-tuning. We then use
agentic reinforcement learning on verifiable agentic tasks to further improve
the models' capabilities on chain-of-agents problem solving. We call the
resulting models Agent Foundation Models (AFMs). Our empirical studies
demonstrate that AFM establishes new state-of-the-art performance across
diverse benchmarks in both web agent and code agent settings. We make the
entire research, including the model weights, code for training and evaluation,
and the training data, fully open-sourced, which offers a solid starting point
for future research on agent models and agentic RL.

</details>


### [244] [Cognitive Workspace: Active Memory Management for LLMs -- An Empirical Study of Functional Infinite Context](https://arxiv.org/abs/2508.13171)
*Tao An*

Main category: cs.AI

TL;DR: LLMs struggle with context management. We propose Cognitive Workspace, inspired by human memory, which actively manages information using curated memory, buffers, and dynamic optimization. This leads to significantly higher memory reuse (58.6%) and efficiency gains (17-18%) compared to traditional methods.


<details>
  <summary>Details</summary>
Motivation: Current LLMs face fundamental limitations in context management, despite advances in extending context windows. Existing retrieval-augmented generation (RAG) systems are passive and fail to capture the dynamic, task-driven nature of human memory management, lacking metacognitive awareness and active planning capabilities.

Method: The paper proposes Cognitive Workspace, a novel paradigm emulating human cognitive mechanisms for external memory use in LLMs. It incorporates active memory management with deliberate information curation, hierarchical cognitive buffers for persistent working states, and task-driven context optimization. This approach is inspired by cognitive science theories such as Baddeley's working memory model, Clark's extended mind thesis, and Hutchins' distributed cognition framework.

Result: Cognitive Workspace achieves an average 58.6% memory reuse rate, significantly outperforming traditional RAG (0% reuse). It also results in a 17-18% net efficiency gain despite higher operation counts (3.3x). Statistical analysis confirms these advantages with p < 0.001 and Cohen's d > 23, providing quantitative evidence for active memory superiority in LLM systems.

Conclusion: Cognitive Workspace represents a fundamental shift from information retrieval to genuine cognitive augmentation for LLMs, supported by a comprehensive theoretical framework and empirical validation.

Abstract: Large Language Models (LLMs) face fundamental limitations in context
management despite recent advances extending context windows to millions of
tokens. We propose Cognitive Workspace, a novel paradigm that transcends
traditional Retrieval-Augmented Generation (RAG) by emulating human cognitive
mechanisms of external memory use. Drawing from cognitive science foundations
including Baddeley's working memory model, Clark's extended mind thesis, and
Hutchins' distributed cognition framework, we demonstrate that current passive
retrieval systems fail to capture the dynamic, task-driven nature of human
memory management. Our analysis of 2024-2025 developments reveals that while
techniques like Infini-attention and StreamingLLM achieve impressive context
lengths, they lack the metacognitive awareness and active planning capabilities
essential for true cognitive extension. Cognitive Workspace addresses these
limitations through three core innovations: (1) active memory management with
deliberate information curation, (2) hierarchical cognitive buffers enabling
persistent working states, and (3) task-driven context optimization that
dynamically adapts to cognitive demands. Empirical validation demonstrates
Cognitive Workspace achieves an average 58.6% memory reuse rate (ranging from
54-60% across different tasks) compared to 0% for traditional RAG, with 17-18%
net efficiency gain despite 3.3x higher operation counts. Statistical analysis
confirms these advantages with p < 0.001 and Cohen's d > 23 across multiple
task types, establishing the first quantitative evidence for active memory
superiority in LLM systems. We present a comprehensive theoretical framework
synthesizing insights from 50+ recent papers, positioning Cognitive Workspace
as a fundamental shift from information retrieval to genuine cognitive
augmentation.

</details>


### [245] [AlphaEval: A Comprehensive and Efficient Evaluation Framework for Formula Alpha Mining](https://arxiv.org/abs/2508.13174)
*Hongjun Ding,Binqi Chen,Jinsheng Huang,Taian Guo,Zhengyang Mao,Guoyi Shao,Lutong Zou,Luchen Liu,Ming Zhang*

Main category: cs.AI

TL;DR: AlphaEval是一个新的、高效的、多维度的Alpha挖掘模型评估框架，解决了现有方法的局限性，并已开源以促进研究。


<details>
  <summary>Details</summary>
Motivation: 现有Alpha挖掘模型的评估方法（如回测和基于相关性的度量）存在计算密集、参数敏感、评估维度单一（仅关注预测能力）等问题。此外，闭源模型阻碍了可复现性和领域进展。

Method: 提出AlphaEval评估框架，该框架统一、可并行且无回测，从预测能力、稳定性、鲁棒性、金融逻辑和多样性五个维度评估Alpha挖掘模型。

Result: AlphaEval在评估一致性方面与全面回测相当，提供了更全面的见解和更高的效率。与传统单指标筛选方法相比，AlphaEval能有效识别出更优的Alpha。

Conclusion: AlphaEval是一个统一的、可并行的、无回测的自动化Alpha挖掘模型评估框架，能够从预测能力、稳定性、对市场扰动的鲁棒性、金融逻辑和多样性五个维度评估生成的Alpha的整体质量。实验证明，AlphaEval的评估一致性与全面的回测相当，同时提供更全面的见解和更高的效率，并能有效识别出优于传统单指标筛选方法的Alpha。所有实现和评估工具均已开源。

Abstract: Formula alpha mining, which generates predictive signals from financial data,
is critical for quantitative investment. Although various algorithmic
approaches-such as genetic programming, reinforcement learning, and large
language models-have significantly expanded the capacity for alpha discovery,
systematic evaluation remains a key challenge. Existing evaluation metrics
predominantly include backtesting and correlation-based measures. Backtesting
is computationally intensive, inherently sequential, and sensitive to specific
strategy parameters. Correlation-based metrics, though efficient, assess only
predictive ability and overlook other crucial properties such as temporal
stability, robustness, diversity, and interpretability. Additionally, the
closed-source nature of most existing alpha mining models hinders
reproducibility and slows progress in this field. To address these issues, we
propose AlphaEval, a unified, parallelizable, and backtest-free evaluation
framework for automated alpha mining models. AlphaEval assesses the overall
quality of generated alphas along five complementary dimensions: predictive
power, stability, robustness to market perturbations, financial logic, and
diversity. Extensive experiments across representative alpha mining algorithms
demonstrate that AlphaEval achieves evaluation consistency comparable to
comprehensive backtesting, while providing more comprehensive insights and
higher efficiency. Furthermore, AlphaEval effectively identifies superior
alphas compared to traditional single-metric screening approaches. All
implementations and evaluation tools are open-sourced to promote
reproducibility and community engagement.

</details>


### [246] [Fitting Ontologies and Constraints to Relational Structures](https://arxiv.org/abs/2508.13176)
*Simon Hosemann,Jean Christoph Jung,Carsten Lutz,Sebastian Rudolph*

Main category: cs.AI

TL;DR: This paper analyzes fitting ontologies and constraints (like description logics and TGDs) to relational structures, determining computational complexity and algorithm design. It finds that finite bases for these constraints exist for some types but not others.


<details>
  <summary>Details</summary>
Motivation: We study the problem of fitting ontologies and constraints to positive and negative examples that take the form of a finite relational structure.

Method: We pinpoint the exact computational complexity, design algorithms, and analyze the size of fitting ontologies and TGDs. We also investigate the related problem of constructing a finite basis of concept inclusions / TGDs for a given set of finite structures.

Result: The paper analyzes the computational complexity and provides algorithms for fitting ontologies and TGDs to relational structures. It also explores the existence of finite bases for concept inclusions/TGDs, finding they exist for some but not all TGD types.

Conclusion: While finite bases exist for $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$, guarded TGDs, and inclusion dependencies, they in general do not exist for full, frontier-guarded and frontier-one TGDs.

Abstract: We study the problem of fitting ontologies and constraints to positive and
negative examples that take the form of a finite relational structure. As
ontology and constraint languages, we consider the description logics
$\mathcal{E\mkern-2mu L}$ and $\mathcal{E\mkern-2mu LI}$ as well as several
classes of tuple-generating dependencies (TGDs): full, guarded,
frontier-guarded, frontier-one, and unrestricted TGDs as well as inclusion
dependencies. We pinpoint the exact computational complexity, design
algorithms, and analyze the size of fitting ontologies and TGDs. We also
investigate the related problem of constructing a finite basis of concept
inclusions / TGDs for a given set of finite structures. While finite bases
exist for $\mathcal{E\mkern-2mu L}$, $\mathcal{E\mkern-2mu LI}$, guarded TGDs,
and inclusion dependencies, they in general do not exist for full,
frontier-guarded and frontier-one TGDs.

</details>


### [247] [HiFo-Prompt: Prompting with Hindsight and Foresight for LLM-based Automatic Heuristic Design](https://arxiv.org/abs/2508.13333)
*Chentong Chen,Mengyuan Zhong,Jianyong Sun,Ye Fan,Jialong Shi*

Main category: cs.AI

TL;DR: HiFo-Prompt框架通过前视和后视提示策略改进了LLM在进化计算中的自动启发式设计，通过自适应搜索和知识积累显著提高了性能和效率。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的进化计算（EC）框架中的自动启发式设计（AHD）虽然显示出有希望的结果，但由于使用了静态算子和缺乏知识积累机制，其有效性受到阻碍。

Method: 提出了一种名为HiFo-Prompt的框架，该框架通过两种协同提示策略：前视（Foresight）和后视（Hindsight）来指导LLM。前视提示根据种群动态自适应地引导搜索，管理探索-利用的权衡。后视提示通过从过去的世代中提炼成功的启发式方法，将其转化为基本且可重用的设计原则，从而模仿人类专业知识。这种双重机制将短暂的发现转化为持久的知识库，使LLM能够从自身经验中学习。

Result: 实验结果表明，HiFo-Prompt框架在生成更高质量的启发式方法、实现更快的收敛速度和更高的查询效率方面，显著优于最先进的基于LLM的AHD方法。

Conclusion: HiFo-Prompt框架显著优于最先进的基于LLM的AHD方法，能够生成更高质量的启发式方法，同时实现更快的收敛速度和更高的查询效率。

Abstract: LLM-based Automatic Heuristic Design (AHD) within Evolutionary Computation
(EC) frameworks has shown promising results. However, its effectiveness is
hindered by the use of static operators and the lack of knowledge accumulation
mechanisms. We introduce HiFo-Prompt, a framework that guides LLMs with two
synergistic prompting strategies: Foresight and Hindsight. Foresight-based
prompts adaptively steer the search based on population dynamics, managing the
exploration-exploitation trade-off. In addition, hindsight-based prompts mimic
human expertise by distilling successful heuristics from past generations into
fundamental, reusable design principles. This dual mechanism transforms
transient discoveries into a persistent knowledge base, enabling the LLM to
learn from its own experience. Empirical results demonstrate that HiFo-Prompt
significantly outperforms state-of-the-art LLM-based AHD methods, generating
higher-quality heuristics while achieving substantially faster convergence and
superior query efficiency.

</details>


### [248] [A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment](https://arxiv.org/abs/2508.13177)
*Nikola Pižurica,Nikola Milović,Igor Jovančević,Conor Heins,Miguel de Prado*

Main category: cs.AI

TL;DR: 本研究提出了一种优化AIF框架以提高其在资源受限环境中的效率和部署能力的方法，通过集成pymdp和稀疏计算图，显著降低了延迟和内存使用量。


<details>
  <summary>Details</summary>
Motivation: Active Inference (AIF) 是一种强大的决策框架，但其计算和内存需求限制了其在资源受限环境中的部署。

Method: 本研究提出了一种集成pymdp的灵活性和效率，并结合统一的稀疏计算图的方法，以提高AIF的部署效率。

Result: 该方法将延迟降低了2倍以上，内存使用量减少了高达35%，从而推动了高效AIF代理在实时和嵌入式应用中的部署。

Conclusion: AIF的计算和内存需求对资源受限环境下的部署提出了挑战。本研究提出了一种通过集成pymdp的灵活性和效率，以及为硬件高效执行量身定制的统一稀疏计算图来促进AIF部署的方法。

Abstract: Active Inference (AIF) offers a robust framework for decision-making, yet its
computational and memory demands pose challenges for deployment, especially in
resource-constrained environments. This work presents a methodology that
facilitates AIF's deployment by integrating pymdp's flexibility and efficiency
with a unified, sparse, computational graph tailored for hardware-efficient
execution. Our approach reduces latency by over 2x and memory by up to 35%,
advancing the deployment of efficient AIF agents for real-time and embedded
applications.

</details>


### [249] [The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task](https://arxiv.org/abs/2508.13178)
*Cong Zhang*

Main category: cs.AI

TL;DR: CESQL模型通过结合可解释性、执行引导、过滤调整、逻辑关联和模型融合，提升了文本到SQL的 Беларусь能力，在WikiSQL数据集上表现优异，并为处理复杂查询提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 为了提升文本到SQL模型在真实世界应用中的基础能力和泛化能力。

Method: 通过集成模型可解释性分析与执行引导策略，并结合过滤调整、逻辑关联优化和模型融合，设计了CESQL模型。

Result: CESQL模型在WikiSQL数据集上显著提高了预测准确性，尤其在处理WHERE子句的条件值预测时，减少了对条件列数据的依赖，并规避了手动标注训练数据的影响。

Conclusion: 该研究通过集成模型可解释性分析和执行引导策略来提升文本到SQL模型的 Беларусь能力，并在WikiSQL数据集上取得了显著的准确率提升。该方法减少了对条件列数据的依赖，并规避了手动标注训练数据的影响，为处理复杂查询和不规则数据提供了新思路。

Abstract: To elevate the foundational capabilities and generalization prowess of the
text-to-SQL model in real-world applications, we integrate model
interpretability analysis with execution-guided strategy for semantic parsing
of WHERE clauses in SQL queries. Furthermore, we augment this approach with
filtering adjustments, logical correlation refinements, and model fusion,
culminating in the design of the CESQL model that facilitates conditional
enhancement. Our model excels on the WikiSQL dataset, which is emblematic of
single-table database query tasks, markedly boosting the accuracy of prediction
outcomes. When predicting conditional values in WHERE clauses, we have not only
minimized our dependence on data within the condition columns of tables but
also circumvented the impact of manually labeled training data. Our hope is
that this endeavor to enhance accuracy in processing basic database queries
will offer fresh perspectives for research into handling complex queries and
scenarios featuring irregular data in real-world database environments.

</details>


### [250] [CardAIc-Agents: A Multimodal Framework with Hierarchical Adaptation for Cardiac Care Support](https://arxiv.org/abs/2508.13256)
*Yuting Zhang,Karina V. Bunting,Asgher Champsi,Xiaoxia Wang,Wenqi Lu,Alexander Thorley,Sandeep S Hothi,Zhaowen Qiu,Dipak Kotecha,Jinming Duan*

Main category: cs.AI

TL;DR: CardAIc-Agents框架通过结合可更新知识、自适应规划和多模态能力，有效解决了AI在心血管疾病临床应用中的局限性，并优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为了应对全球心血管疾病（CVD）高死亡率以及医疗工作者短缺的挑战，并克服现有AI临床应用中存在的局限性，如依赖模型内在能力、缺乏工具支持、工作流程僵化、知识库静态且缺乏持续学习能力、以及输入/输出模式固定等问题。

Method: 提出了一种名为CardAIc-Agents的多模态框架，该框架通过整合外部工具和自适应地支持多种心脏任务来增强AI模型。框架包含一个CardiacRAG代理，用于从可更新的心脏知识中生成通用计划；一个主代理，用于整合工具以自主执行计划并交付决策。为实现自适应和案例特定定制，提出了一种逐步更新策略，用于在任务被评估为复杂时根据先前的执行结果动态优化计划。此外，引入了一个多学科讨论工具来解释疑难病例，并提供了视觉审查小组以辅助最终验证。

Result: 实验结果表明，CardAIc-Agents框架在三个数据集上的表现优于主流视觉语言模型（VLMs）、最先进的自主系统和经过微调的VLMs，证明了其在心血管疾病早期检测和筛查方面的效率和优越性。

Conclusion: CardAIc-Agents框架在处理心血管疾病方面展现出优于主流视觉语言模型、先进的自主系统和微调视觉语言模型的效率，能够通过可更新的知识库、自适应规划和多模态输入/输出为临床决策提供支持。

Abstract: Cardiovascular diseases (CVDs) remain the foremost cause of mortality
worldwide, a burden worsened by a severe deficit of healthcare workers.
Artificial intelligence (AI) agents have shown potential to alleviate this gap
via automated early detection and proactive screening, yet their clinical
application remains limited by: 1) prompt-based clinical role assignment that
relies on intrinsic model capabilities without domain-specific tool support; or
2) rigid sequential workflows, whereas clinical care often requires adaptive
reasoning that orders specific tests and, based on their results, guides
personalised next steps; 3) general and static knowledge bases without
continuous learning capability; and 4) fixed unimodal or bimodal inputs and
lack of on-demand visual outputs when further clarification is needed. In
response, a multimodal framework, CardAIc-Agents, was proposed to augment
models with external tools and adaptively support diverse cardiac tasks.
Specifically, a CardiacRAG agent generated general plans from updatable cardiac
knowledge, while the chief agent integrated tools to autonomously execute these
plans and deliver decisions. To enable adaptive and case-specific
customization, a stepwise update strategy was proposed to dynamically refine
plans based on preceding execution results, once the task was assessed as
complex. In addition, a multidisciplinary discussion tool was introduced to
interpret challenging cases, thereby supporting further adaptation. When
clinicians raised concerns, visual review panels were provided to assist final
validation. Experiments across three datasets showed the efficiency of
CardAIc-Agents compared to mainstream Vision-Language Models (VLMs),
state-of-the-art agentic systems, and fine-tuned VLMs.

</details>


### [251] [Search-Time Data Contamination](https://arxiv.org/abs/2508.13180)
*Ziwen Han,Meher Mankikar,Julian Michael,Zifan Wang*

Main category: cs.AI

TL;DR: 搜索型LLM代理的评估中存在一种名为“搜索时污染”（STC）的新型数据泄漏问题，即代理可能会检索到包含测试问题及其答案的在线来源（如HuggingFace上的数据集），导致其直接复制答案而非进行推理。研究发现STC影响了约3%的问题，并导致准确性下降。作者提出了改进基准设计的建议，并公开了实验日志。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是解决在评估搜索型LLM代理时出现的数据污染问题，特别是搜索时污染（STC）。STC会导致代理过拟合测试集，损害评估的有效性。作者发现，像HuggingFace这样的在线平台上的评估数据集会意外地出现在代理的检索结果中，使得代理能够直接复制答案，而不是进行真正的推理。这种数据泄漏会缩短基准测试的生命周期，并影响评估结果的可靠性。因此，有必要识别、量化并解决STC问题，以确保搜索型LLM代理评估的完整性和可信度。

Method: 作者首先定义了搜索时污染（STC）的概念，即在评估搜索型LLM代理时，检索到的信息源包含了测试问题及其答案。然后，作者通过实验发现，HuggingFace平台托管的评估数据集会出现在代理的搜索日志中，导致代理直接复制答案。作者在HLE、SimpleQA和GPQA三个基准测试上进行了实验，量化了STC的影响，并进行了消融实验以探究其他潜在的数据源。最后，作者提出了缓解STC问题的最佳实践，并公开了实验日志。

Result: 研究结果表明，对于HLE、SimpleQA和GPQA三个常用的能力基准测试，大约有3%的问题受到了搜索时污染（STC）的影响。当HuggingFace被屏蔽后，受污染问题子集上的准确性下降了约15%。消融实验还表明，HuggingFace可能不是STC的唯一来源。

Conclusion: 数据污染（STC）是搜索LLM代理评估中的一个新问题，其中检索到的来源可能包含测试问题及其答案，导致代理直接复制而非推理。作者发现HuggingFace平台上的评估数据集会出现在搜索日志中，导致代理找到并复制答案。通过在HLE、SimpleQA和GPQA基准测试中进行实验，作者证明了大约3%的问题会受到STC的影响。在阻止HuggingFace后，受污染子集上的准确性下降了约15%。此外，作者还通过消融实验表明，HuggingFace可能不是STC的唯一来源。为了解决STC问题，作者提出了基准设计和结果报告的最佳实践，并公开了实验日志以方便审计。

Abstract: Data contamination refers to the leakage of evaluation data into model
training data, resulting in overfitting to supposedly held-out test sets and
compromising test validity. We identify an analogous issue, search-time
contamination (STC), in evaluating search-based LLM agents which use tools to
gather information from online sources when answering user queries. STC occurs
when the retrieval step surfaces a source containing the test question (or a
near-duplicate) alongside its answer, enabling agents to copy rather than
genuinely infer or reason, undermining benchmark integrity. We find that
HuggingFace, an online platform hosting evaluation datasets, appears among
retrieved sources in search based agent logs. Consequently, agents often
explicitly acknowledge discovering question answer pairs from HuggingFace
within their reasoning chains. On three commonly used capability benchmarks:
Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for
approximately 3% of questions, search-based agents directly find the datasets
with ground truth labels on HuggingFace. When millions of evaluation queries
target the same benchmark, even small, repeated leaks can accelerate the
benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace
is blocked, we observe a drop in accuracy on the contaminated subset of
approximately 15%. We further show through ablation experiments that publicly
accessible evaluation datasets on HuggingFace may not be the sole source of
STC. To this end, we conclude by proposing best practices for benchmark design
and result reporting to address this novel form of leakage and ensure
trustworthy evaluation of search-based LLM agents. To facilitate the auditing
of evaluation results, we also publicly release the complete logs from our
experiments.

</details>


### [252] [Quantifier Instantiations: To Mimic or To Revolt?](https://arxiv.org/abs/2508.13811)
*Jan Jakubův,Mikoláš Janota*

Main category: cs.AI

TL;DR: 该研究提出了一种新的SMT实例化方法，该方法通过学习现有技术和使用概率上下文无关文法来生成新的项，以提高量词推理的效率。


<details>
  <summary>Details</summary>
Motivation: 解决SMT求解器在处理量化公式时遇到的固有不确定性带来的挑战。

Method: 该方法将观察到的实例化视为来自潜在语言的样本，使用概率上下文无关文法来生成新的、相似的项。通过选择性地反转学习到的项的概率，可以探索多样性。

Result: 提出了一种新颖的实例化方法，该方法通过动态学习现有技术来改进量词推理。

Conclusion: 该方法通过动态学习现有技术并引入概率上下文无关文法来生成新的、相似的项，旨在平衡量词推理中的利用和探索。

Abstract: Quantified formulas pose a significant challenge for Satisfiability Modulo
Theories (SMT) solvers due to their inherent undecidability. Existing
instantiation techniques, such as e-matching, syntax-guided, model-based,
conflict-based, and enumerative methods, often complement each other. This
paper introduces a novel instantiation approach that dynamically learns from
these techniques during solving. By treating observed instantiations as samples
from a latent language, we use probabilistic context-free grammars to generate
new, similar terms. Our method not only mimics successful past instantiations
but also explores diversity by optionally inverting learned term probabilities,
aiming to balance exploitation and exploration in quantifier reasoning.

</details>


### [253] [Virtuous Machines: Towards Artificial General Science](https://arxiv.org/abs/2508.13421)
*Gabrielle Wehr,Reuben Rideaux,Amaya J. Fox,David R. Lightfoot,Jason Tangen,Jason B. Mattingley,Shane E. Ehrhardt*

Main category: cs.AI

TL;DR: AI 驱动的科学研究：AI 系统能够独立完成从假设到论文的整个研究流程，并取得可与人类研究者相媲美的结果，但仍需在概念理解和理论解释方面进行改进。


<details>
  <summary>Details</summary>
Motivation: 科学文献的指数级增长和日益增长的领域专业化限制了研究人员跨学科综合知识和发展统一理论的能力，因此需要更通用的科学 AI 系统。

Method: 本研究展示了一个领域无关、具有自主性的 AI 系统，该系统能够独立导航科学工作流程，包括假设生成、数据收集和论文准备。该系统自主设计并执行了三项关于视觉工作记忆、心理旋转和意象生动性的心理学研究，并通过在线收集了 288 名参与者的数据，开发了分析流程，并完成了论文撰写。

Result: AI 科学发现管道能够进行非 Trivial 的研究，其理论推理和方法严谨性可与经验丰富的研究人员相媲美，但在概念的细微差别和理论解释方面存在局限性。

Conclusion: 人工智能科学发现的潜力巨大，能够独立完成从假设生成到论文撰写的整个科学研究流程，并且在理论推理和方法严谨性方面能够达到有经验的研究人员的水平。然而，在概念的细微差别和理论解释方面仍存在局限性。

Abstract: Artificial intelligence systems are transforming scientific discovery by
accelerating specific research tasks, from protein structure prediction to
materials design, yet remain confined to narrow domains requiring substantial
human oversight. The exponential growth of scientific literature and increasing
domain specialisation constrain researchers' capacity to synthesise knowledge
across disciplines and develop unifying theories, motivating exploration of
more general-purpose AI systems for science. Here we show that a
domain-agnostic, agentic AI system can independently navigate the scientific
workflow - from hypothesis generation through data collection to manuscript
preparation. The system autonomously designed and executed three psychological
studies on visual working memory, mental rotation, and imagery vividness,
executed one new online data collection with 288 participants, developed
analysis pipelines through 8-hour+ continuous coding sessions, and produced
completed manuscripts. The results demonstrate the capability of AI scientific
discovery pipelines to conduct non-trivial research with theoretical reasoning
and methodological rigour comparable to experienced researchers, though with
limitations in conceptual nuance and theoretical interpretation. This is a step
toward embodied AI that can test hypotheses through real-world experiments,
accelerating discovery by autonomously exploring regions of scientific space
that human cognitive and resource constraints might otherwise leave unexplored.
It raises important questions about the nature of scientific understanding and
the attribution of scientific credit.

</details>


### [254] [QuickMerge++: Fast Token Merging with Autoregressive Prior](https://arxiv.org/abs/2508.13204)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: QuickMerge 是一种轻量级的 token 合并框架，通过动态选择 token 来提高生成模型的效率，尤其是在下一个 token 预测方面，并保持了自回归兼容性。


<details>
  <summary>Details</summary>
Motivation: 随着生成模型在语言、视觉和视频领域扩展到更大的输入，token 级别的计算成本已成为关键瓶颈。先前的研究表明，只有一部分 token 会显著影响下游预测，但大多数 token 选择方法要么是静态的、特定于模态的，要么与自回归生成不兼容。

Method: QuickMerge 框架通过基于注意力范数幅度动态选择 token 子集，并利用基于熵的预算估计器来指导，从而实现高效的下一个 token 预测。为了保持自回归兼容性，引入了一个在合并后的 token 序列上训练的轻量级 transformer 先验。

Result: QuickMerge 在多模态域的评估中，一致地提高了计算-准确性权衡。具体来说，QuickMerge 大大减少了 token 数量，同时在性能上与学习型 tokenizer 和固定块基线相当甚至更优。

Conclusion: QuickMerge 能够通过动态选择较少数量的 token 来实现高效的下一个 token 预测，同时保持自回归兼容性。该框架在多模态域的评估中，通过减少 token 数量并在计算-准确性权衡方面取得了一致的改进，并且其性能与学习型 tokenizer 和固定块基线相当甚至更优。

Abstract: As generative models scale to larger inputs across language, vision, and
video domains, the cost of token-level computation has become a key bottleneck.
While prior work suggests that only a subset of tokens significantly influence
downstream predictions, most token selection methods are static,
modality-specific, or incompatible with autoregressive generation. In this
paper, we propose QuickMerge, a lightweight token merging framework designed
for efficient next-token prediction.
  QuickMerge dynamically selects a reduced number of tokens based on attention
norm magnitude, guided by an entropy-based budget estimator. To preserve
autoregressive compatibility, we introduce a lightweight transformer prior
trained over the merged token sequence. By combining semantic salience
estimation, flexible token budgets, and AR alignment, QuickMerge enables
accurate generation with fewer tokens.
  We evaluate QuickMerge across multi-modality domains, demonstrating
consistent improvements in compute-accuracy tradeoffs. Specifically, QuickMerge
reduces token counts sustantially while matching as well as exceeding the
performance of learned tokenizers and fixed-patch baselines.

</details>


### [255] [AI sustains higher strategic tension than humans in chess](https://arxiv.org/abs/2508.13213)
*Adamo Cerioli,Edward D. Lee,Vito D. P. Servedio*

Main category: cs.AI

TL;DR: AI在国际象棋中的战略张力管理能力优于人类，能维持更长时间的复杂局面，这可能与认知限制和适应性策略有关。


<details>
  <summary>Details</summary>
Motivation: 研究在国际象棋中，如何在即时机会和长期目标之间进行权衡，以理解战略决策中的张力管理。

Method: 提出了一种基于网络的、量化棋盘上博弈双方棋子之间互动关系的指标，以衡量战略张力的动态变化。通过比较人类对局和AI对局，并分析不同水平下人类玩家和不同复杂度AI的对局数据，来研究战略张力的演变。

Result: AI玩家比顶尖人类玩家能在更长时间内维持更高水平的战略张力。AI的累计张力随算法复杂度而变化，而人类玩家的累计张力在Elo 1600和2300时会突然增加，这表明了不同水平下人类玩家的策略差异。

Conclusion: AI玩家能在更长时间内维持更高水平的战略张力，这可能源于它们能容忍相互关联的局面，并在攻防策略之间取得平衡。相比之下，人类玩家倾向于限制张力与复杂度，这可能反映了认知限制和适应性策略。这些差异对AI在复杂战略环境中的应用具有潜在启示。

Abstract: Strategic decision-making involves managing the tension between immediate
opportunities and long-term objectives. We study this trade-off in chess by
characterizing and comparing dynamics between human vs human and AI vs AI
games. We propose a network-based metric of piece-to-piece interaction to
quantify the ongoing strategic tension on the board. Its evolution in games
reveals that the most competitive AI players sustain higher levels of strategic
tension for longer durations than elite human players. Cumulative tension
varies with algorithmic complexity for AI and correspondingly in human-played
games increases abruptly with expertise at about 1600 Elo and again at 2300
Elo. The profiles reveal different approaches. Highly competitive AI tolerates
interconnected positions balanced between offensive and defensive tactics over
long periods. Human play, in contrast, limits tension and game complexity,
which may reflect cognitive limitations and adaptive strategies. The difference
may have implications for AI usage in complex, strategic environments.

</details>


### [256] [Explicit v.s. Implicit Memory: Exploring Multi-hop Complex Reasoning Over Personalized Information](https://arxiv.org/abs/2508.13250)
*Zeyu Zhang,Yang Zhang,Haoran Tan,Rui Li,Xu Chen*

Main category: cs.AI

TL;DR: A new task, multi-hop personalized reasoning, and a dataset are introduced to evaluate memory mechanisms in LLM-based agents for complex, personalized tasks. A novel hybrid memory method, HybridMem, is proposed and shown to be effective.


<details>
  <summary>Details</summary>
Motivation: Addressing the limitation of current memory approaches in large language model-based agents that typically focus on preference alignment and simple question-answering, while real-world complex tasks require multi-hop reasoning on a large amount of user information.

Method: Implementing various explicit and implicit memory methods, conducting comprehensive experiments, evaluating their performance from multiple perspectives, analyzing their strengths and weaknesses, exploring hybrid approaches, and proposing the HybridMem method.

Result: A dataset and a unified evaluation framework are constructed. Various memory methods are implemented and evaluated on the multi-hop personalized reasoning task, demonstrating the effectiveness of the proposed HybridMem method.

Conclusion: The effectiveness of the proposed HybridMem method is demonstrated through extensive experiments, and the project is released to the research community.

Abstract: In large language model-based agents, memory serves as a critical capability
for achieving personalization by storing and utilizing users' information.
Although some previous studies have adopted memory to implement user
personalization, they typically focus on preference alignment and simple
question-answering. However, in the real world, complex tasks often require
multi-hop reasoning on a large amount of user information, which poses
significant challenges for current memory approaches. To address this
limitation, we propose the multi-hop personalized reasoning task to explore how
different memory mechanisms perform in multi-hop reasoning over personalized
information. We explicitly define this task and construct a dataset along with
a unified evaluation framework. Then, we implement various explicit and
implicit memory methods and conduct comprehensive experiments. We evaluate
their performance on this task from multiple perspectives and analyze their
strengths and weaknesses. Besides, we explore hybrid approaches that combine
both paradigms and propose the HybridMem method to address their limitations.
We demonstrate the effectiveness of our proposed model through extensive
experiments. To benefit the research community, we release this project at
https://github.com/nuster1128/MPR.

</details>


### [257] ["DIVE" into Hydrogen Storage Materials Discovery with AI Agents](https://arxiv.org/abs/2508.13251)
*Di Zhang,Xue Jia,Tran Ba Hung,Seong Hoon Jang,Linda Zhang,Ryuhei Sato,Yusuke Hashimoto,Toyoto Sato,Kiyoe Konno,Shin-ichi Orimo,Hao Li*

Main category: cs.AI

TL;DR: DIVE是一种新的AI工作流程，可以通过分析科学文献中的图表来提取和组织材料数据，从而改进材料设计，并已成功用于发现新的储氢材料。


<details>
  <summary>Details</summary>
Motivation: 尽管科学文献中有大量的材料数据，但其中大部分数据仍然被困在非结构化的图表中，阻碍了基于大语言模型（LLM）的AI代理的构建，以实现自动化的材料设计。

Method: 提出了一种名为DIVE（Descriptive Interpretation of Visual Expression）的多代理工作流程，该工作流程系统地读取和组织科学文献中的图形元素中的实验数据。

Result: DIVE显著提高了数据提取的准确性和覆盖率，与多模态模型直接提取相比，其准确性提高了10-15%，相对于开源模型提高了30%以上。基于一个包含4000篇论文的30000多个条目的精选数据库，我们建立了一个快速的反向设计工作流程，能够在两分钟内识别出先前未报告的储氢组合物。

Conclusion: 该AI工作流程和代理设计可广泛应用于各种材料，为AI驱动的材料发现提供了范例。

Abstract: Data-driven artificial intelligence (AI) approaches are fundamentally
transforming the discovery of new materials. Despite the unprecedented
availability of materials data in the scientific literature, much of this
information remains trapped in unstructured figures and tables, hindering the
construction of large language model (LLM)-based AI agent for automated
materials design. Here, we present the Descriptive Interpretation of Visual
Expression (DIVE) multi-agent workflow, which systematically reads and
organizes experimental data from graphical elements in scientific literatures.
We focus on solid-state hydrogen storage materials-a class of materials central
to future clean-energy technologies and demonstrate that DIVE markedly improves
the accuracy and coverage of data extraction compared to the direct extraction
by multimodal models, with gains of 10-15% over commercial models and over 30%
relative to open-source models. Building on a curated database of over 30,000
entries from 4,000 publications, we establish a rapid inverse design workflow
capable of identifying previously unreported hydrogen storage compositions in
two minutes. The proposed AI workflow and agent design are broadly transferable
across diverse materials, providing a paradigm for AI-driven materials
discovery.

</details>


### [258] [Towards Unified Multimodal Financial Forecasting: Integrating Sentiment Embeddings and Market Indicators via Cross-Modal Attention](https://arxiv.org/abs/2508.13327)
*Sarthak Khanna,Armin Berger,David Berghaus,Tobias Deusser,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.AI

TL;DR: STONK是一个多模态框架，结合了股票市场的数值指标和新闻中的情感信息，以更准确地预测股票每日的走势。实验证明它比仅使用数值数据的模型效果更好。


<details>
  <summary>Details</summary>
Motivation: 为了提高每日股票走势预测的准确性，同时解决仅分析数值或文本信息的局限性。

Method: 提出了一种名为STONK（Stock Optimization using News Knowledge）的多模态框架，该框架整合了数值市场指标和富含情感的新闻嵌入。通过特征连接和跨模态注意力机制将数值和文本嵌入相结合。

Result: 回溯测试表明，STONK的表现优于仅使用数值的基线模型。对融合策略和模型配置的全面评估为可扩展的多模态金融预测提供了基于证据的指导。

Conclusion: STONK框架通过融合数值市场指标和富含情感的新闻嵌入，在每日股票走势预测方面优于仅使用数值的基线模型。

Abstract: We propose STONK (Stock Optimization using News Knowledge), a multimodal
framework integrating numerical market indicators with sentiment-enriched news
embeddings to improve daily stock-movement prediction. By combining numerical &
textual embeddings via feature concatenation and cross-modal attention, our
unified pipeline addresses limitations of isolated analyses. Backtesting shows
STONK outperforms numeric-only baselines. A comprehensive evaluation of fusion
strategies and model configurations offers evidence-based guidance for scalable
multimodal financial forecasting. Source code is available on GitHub

</details>


### [259] [LOOP: A Plug-and-Play Neuro-Symbolic Framework for Enhancing Planning in Autonomous Systems](https://arxiv.org/abs/2508.13371)
*Ronit Virwani,Ruchika Suryawanshi*

Main category: cs.AI

TL;DR: LOOP是一个新颖的神经符号规划框架，通过让神经和符号组件像对话一样协同工作来解决复杂的规划问题，并在标准测试中取得了领先的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有神经规划方法在复杂域中存在不足，如计划不完整、目标不一致和幻觉；经典规划器缺乏灵活性和自然语言理解能力；现有的神经符号方法仅进行一次性翻译，未能充分利用神经和符号组件的协同优化能力。

Method: LOOP框架将规划视为神经和符号组件之间的迭代对话，整合了图神经网络、多智能体验证、分层分解和因果记忆等13个协调的神经特征，并能生成和迭代优化PDDL规范，从执行轨迹构建因果知识库。

Result: LOOP框架在六个标准IPC基准领域中取得了85.8%的成功率，显著优于LLM+P（55.0%）、LLM-as-Planner（19.2%）和Tree-of-Thoughts（3.3%）。

Conclusion: LOOP框架通过迭代对话整合神经和符号组件，解决了当前神经规划方法的局限性，并在标准IPC基准测试中取得了85.8%的成功率，证明了神经-符号协同在可靠规划中的重要性。

Abstract: Planning is one of the most critical tasks in autonomous systems, where even
a small error can lead to major failures or million-dollar losses. Current
state-of-the-art neural planning approaches struggle with complex domains,
producing plans with missing preconditions, inconsistent goals, and
hallucinations. While classical planners provide logical guarantees, they lack
the flexibility and natural language understanding capabilities needed for
modern autonomous systems. Existing neuro-symbolic approaches use one-shot
translation from natural language to formal plans, missing the opportunity for
neural and symbolic components to work and refine solutions together. To
address this gap, we develop LOOP -- a novel neuro-symbolic planning framework
that treats planning as an iterative conversation between neural and symbolic
components rather than simple translation. LOOP integrates 13 coordinated
neural features including graph neural networks for spatial relationships,
multi-agent validation for consensus-based correctness, hierarchical
decomposition for complex task management, and causal memory that learns from
both successes and failures. Unlike existing approaches, LOOP generates PDDL
specifications, refines them iteratively based on symbolic feedback, and builds
a causal knowledge base from execution traces. LOOP was evaluated on six
standard IPC benchmark domains, where it achieved 85.8% success rate compared
to LLM+P (55.0%), LLM-as-Planner (19.2%), and Tree-of-Thoughts (3.3%). This
work shows that the key to reliable planning is not in choosing between neural
networks or symbolic reasoners but it lies in making them actually ``talk'' to
each other during the entire process. LOOP provides a thorough blueprint for
building autonomous systems that can finally be trusted with critical
real-world applications.

</details>


### [260] [SPANER: Shared Prompt Aligner for Multimodal Semantic Representation](https://arxiv.org/abs/2508.13387)
*Thye Shan Ng,Caren Soyeon Han,Eun-Jung Holden*

Main category: cs.AI

TL;DR: SPANER 是一种新颖的多模态 PEFT 框架，通过共享提示将不同模态对齐到一个统一的语义空间，解决了现有方法的局限性，并在检索任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽然在下游任务中表现良好，但忽略了多模态嵌入空间的结构，导致特定模态的表示孤立，限制了跨模态泛化。

Method: SPANER 是一种参数高效的微调（PEFT）框架，它使用共享提示机制，使来自不同模态的语义上相关的实例在空间上收敛。

Result: SPANER 在视觉-语言和听觉-视觉基准测试中取得了有竞争力的几率检索性能，并保持了嵌入空间中的高语义一致性，证明了对齐嵌入结构的重要性。

Conclusion: SPANER 通过在共享提示的帮助下将不同模态的输入嵌入到统一的语义空间中，在检索任务上取得了有竞争力的表现，同时保持了学习到的嵌入空间的良好语义一致性。

Abstract: Recent advances in multimodal Parameter-Efficient Fine-Tuning (PEFT) have
significantly improved performance on downstream tasks such as few-shot
retrieval. However, most existing approaches focus on task-specific gains while
neglecting the structure of the multimodal embedding space. As a result,
modality-specific representations often remain isolated, limiting cross-modal
generalisation. In this work, we introduce Shared Prompt AligNER (SPANER), a
modality-agnostic PEFT framework designed to embed inputs from diverse
modalities into a unified semantic space. At its core, SPANER employs a shared
prompt mechanism that acts as a conceptual anchor, enabling semantically
related instances to converge spatially regardless of modality. This shared
prompt design is inherently extensible, supporting the seamless integration of
additional modalities, such as audio, without altering the core architecture.
Through comprehensive experiments across vision-language and audio-visual
benchmarks, SPANER demonstrates competitive few-shot retrieval performance
while preserving high semantic coherence in the learned embedding space. Our
results highlight the importance of aligning embedding structures, rather than
merely tuning adapter weights, for scalable multimodal learning.

</details>


### [261] [TASER: Table Agents for Schema-guided Extraction and Recommendation](https://arxiv.org/abs/2508.13404)
*Nicole Cho,Kirsty Fielding,William Watson,Sumitra Ganesh,Manuela Veloso*

Main category: cs.AI

TL;DR: TASER是一个创新的表格提取系统，通过利用代理和模式指导，能够高效处理混乱的金融表格，提取关键信息，并能持续学习优化自身性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的金融文件包含大量关于实体金融持有量的信息，但这些信息通常被隐藏在复杂、多页、分散的表格中，这些表格具有无边界框、行数多等特点。为了应对这些挑战，需要一个能够处理此类表格并提取其中关键信息的系统。

Method: 提出了一种名为TASER（Table Agents for Schema-guided Extraction and Recommendation）的、能够持续学习的、基于代理的表格提取系统。该系统利用初始模式，通过表格检测、分类、提取和推荐代理来处理表格。其推荐代理负责审查输出、建议模式修订并做出最终推荐，从而实现系统的持续学习和改进。

Result: TASER系统在表格检测方面比Table Transformer等现有模型提高了10.1%。在持续学习过程中，较大的批次大小能够带来104.3%的可用且可操作的模式推荐，从而使提取的持有量增加了9.8%。此外，还发布了TASERTab数据集，包含22,584页（28,150,449个标记）和3,213个表格，涉及731,685,511,687美元的持有量，为研究界提供了真实世界的金融表格和输出。

Conclusion: TASER系统在处理现实世界的非结构化、多页、异构表格方面表现出色，能够提取信息并将其转换为规范化、符合模式的输出。与现有的表格检测模型（如Table Transformer）相比，TASER在性能上有所提升。

Abstract: Real-world financial documents report essential information about an entity's
financial holdings that can span millions of different financial instrument
types. Yet, these details are often buried in messy, multi-page, fragmented
tables - for example, 99.4% of the tables in our dataset have no bounding boxes
with the maximum number of rows amounting to 426 per table across 44 pages. To
tackle these unique challenges from real-world tables, we present a
continuously learning, agentic table extraction system, TASER (Table Agents for
Schema-guided Extraction and Recommendation) that extracts highly unstructured,
multi-page, heterogeneous tables into normalized, schema-conforming outputs.
Our table agents execute on table detection, classification, extraction, and
recommendations by leveraging an initial schema. Then, our Recommender Agent
reviews the outputs, recommends schema revisions, and decides on the final
recommendations, enabling TASER to outperform existing table detection models
such as Table Transformer by 10.1%. Within this continuous learning process, we
highlight that larger batch sizes result in a 104.3% increase in schema
recommendations that are actionable and utilized, resulting in a 9.8% increase
in extracted holdings - highlighting the importance of a continuous learning
process. To train TASER, we have manually labeled 22,584 pages (28,150,449
tokens), 3,213 tables for $731,685,511,687 of holdings culminating in one of
the first real financial table datasets. We release our dataset TASERTab to
enable the research community to access real-world financial tables and
outputs. Our results highlight the promise of agentic, schema-guided extraction
systems for robust understanding of real-world financial tables.

</details>


### [262] [STPFormer: A State-of-the-Art Pattern-Aware Spatio-Temporal Transformer for Traffic Forecasting](https://arxiv.org/abs/2508.13433)
*Jiayu Fang,Zhiqi Shao,S T Boris Choy,Junbin Gao*

Main category: cs.AI

TL;DR: STPFormer是一个时空模式感知Transformer，通过TPA、SSA、STGM和注意力混合器模块，在时空交通预测方面取得了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于Transformer的模型在时空交通预测中面临的复杂时间模式、动态空间结构和多样化输入格式的挑战，以及它们在僵化时间编码和薄弱时空融合方面的不足。

Method: STPFormer模型，一个时空模式感知Transformer，包含四个模块：1. 时间模式聚合器（TPA）用于模式感知的时间编码；2. 空间序列聚合器（SSA）用于顺序空间学习；3. 时空图匹配（STGM）用于跨域对齐；4. 注意力混合器（Attention Mixer）用于多尺度融合。

Result: STPFormer实现了最先进的性能，通过统一和可解释的表示学习。

Conclusion: STPFormer在五个真实世界数据集上持续创下新的SOTA结果，消融实验和可视化证实了其有效性和泛化能力。

Abstract: Spatio-temporal traffic forecasting is challenging due to complex temporal
patterns, dynamic spatial structures, and diverse input formats. Although
Transformer-based models offer strong global modeling, they often struggle with
rigid temporal encoding and weak space-time fusion. We propose STPFormer, a
Spatio-Temporal Pattern-Aware Transformer that achieves state-of-the-art
performance via unified and interpretable representation learning. It
integrates four modules: Temporal Position Aggregator (TPA) for pattern-aware
temporal encoding, Spatial Sequence Aggregator (SSA) for sequential spatial
learning, Spatial-Temporal Graph Matching (STGM) for cross-domain alignment,
and an Attention Mixer for multi-scale fusion. Experiments on five real-world
datasets show that STPFormer consistently sets new SOTA results, with ablation
and visualizations confirming its effectiveness and generalizability.

</details>


### [263] [Discrete Optimization of Min-Max Violation and its Applications Across Computational Sciences](https://arxiv.org/abs/2508.13437)
*Cheikh Ahmed,Mahdi Mostajabdaveh,Samin Aref,Zirui Zhou*

Main category: cs.AI

TL;DR: 介绍了一种名为DMMV的优化问题，并开发了一种GPU加速的启发式算法，在量化、层析和滤波器设计等领域取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 为具有最坏情况性能要求的各种用例提供一个通用的、无上下文的数学公式，并开发一种高效的求解方法。

Method: 提出了一种名为离散最小-最大违反（DMMV）的通用优化问题，并开发了一种利用DMMV数学性质的GPU加速启发式算法来求解。

Result: 在后训练量化、离散层析和FIR滤波器设计三个应用中，该启发式算法均取得了显著的改进，包括量化改进14%，离散层析误差减少16%和计算加速6倍，以及FIR滤波器纹波减少近50%。

Conclusion: 该研究提出了离散最小-最大违反（DMMV）作为一种通用的优化问题，并开发了一种GPU加速的启发式算法来解决它。该算法在后训练量化、离散层析和FIR滤波器设计等多个应用中表现出优越的性能，平均实现了14%的改进，并显著加速了计算。

Abstract: We introduce the Discrete Min-Max Violation (DMMV) as a general optimization
problem which seeks an assignment of discrete values to variables that
minimizes the largest constraint violation. This context-free mathematical
formulation is applicable to a wide range of use cases that have worst-case
performance requirements. After defining the DMMV problem mathematically, we
explore its properties to establish a foundational understanding. To tackle
DMMV instance sizes of practical relevance, we develop a GPU-accelerated
heuristic that takes advantage of the mathematical properties of DMMV for
speeding up the solution process. We demonstrate the versatile applicability of
our heuristic by solving three optimization problems as use cases: (1)
post-training quantization of language models, (2) discrete tomography, and (3)
Finite Impulse Response (FIR) filter design. In quantization without outlier
separation, our heuristic achieves 14% improvement on average over existing
methods. In discrete tomography, it reduces reconstruction error by 16% under
uniform noise and accelerates computations by a factor of 6 on GPU. For FIR
filter design, it nearly achieves 50% ripple reduction compared to using the
commercial integer optimization solver, Gurobi. Our comparative results point
to the benefits of studying DMMV as a context-free optimization problem and the
advantages that our proposed heuristic offers on three distinct problems. Our
GPU-accelerated heuristic will be made open-source to further stimulate
research on DMMV and its other applications. The code is available at
https://anonymous.4open.science/r/AMVM-5F3E/

</details>


### [264] [LM Agents May Fail to Act on Their Own Risk Knowledge](https://arxiv.org/abs/2508.13465)
*Yuzhi Tang,Tianxiao Li,Elizabeth Li,Chris J. Maddison,Honghua Dong,Yangjun Ruan*

Main category: cs.AI

TL;DR: 语言模型代理虽然知道风险，但在实际操作中仍会执行危险行为。研究者提出评估框架和包含验证器、抽象器的系统，将风险行为减少了 55.3%。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在解决语言模型（LM）代理在安全关键场景中存在的风险，特别是它们在风险意识和安全执行能力之间存在的差距，即它们可能知道某个操作是危险的，但在实际执行中却可能执行该危险操作。

Method: 该研究提出了一种全面的评估框架，从三个维度检查代理的安全：风险知识、在执行轨迹中识别风险的能力以及避免执行风险行为的实际行为。他们还开发了一个风险验证器和一个抽象器来解决已识别的差距。

Result: 研究结果表明，虽然 LM 代理在风险知识方面表现出色（通过率 >98%），但在实际场景中识别风险的能力却显著下降（下降 >23%），并且仍然执行风险行为（通过率 <26%）。这些差距在更强大的 LM 和专门的推理模型中也普遍存在。然而，所提出的风险验证器和抽象器系统将风险行为的执行减少了 55.3%。

Conclusion: 该研究通过开发风险验证器和抽象器，成功将风险行为的执行减少了 55.3%，表明通过专门设计的干预措施可以弥合风险知识和安全执行之间的差距。

Abstract: Language model (LM) agents have demonstrated significant potential for
automating real-world tasks, yet they pose a diverse array of potential, severe
risks in safety-critical scenarios. In this work, we identify a significant gap
between LM agents' risk awareness and safety execution abilities: while they
often answer "Yes" to queries like "Is executing `sudo rm -rf /*' dangerous?",
they will likely fail to identify such risks in instantiated trajectories or
even directly perform these risky actions when acting as agents. To
systematically investigate this, we develop a comprehensive evaluation
framework to examine agents' safety across three progressive dimensions: 1)
their knowledge about potential risks, 2) their ability to identify
corresponding risks in execution trajectories, and 3) their actual behaviors to
avoid executing these risky actions. Our evaluation reveals two critical
performance gaps that resemble the generator-validator gaps observed in LMs:
while agents demonstrate near-perfect risk knowledge ($>98\%$ pass rates), they
fail to apply this knowledge when identifying risks in actual scenarios (with
performance dropping by $>23\%$) and often still execute risky actions ($<26\%$
pass rates). Notably, this trend persists across more capable LMs as well as in
specialized reasoning models like DeepSeek-R1, indicating that simply scaling
model capabilities or inference compute does not inherently resolve safety
concerns. Instead, we take advantage of these observed gaps to develop a risk
verifier that independently critiques the proposed actions by agents, with an
abstractor that converts specific execution trajectories into abstract
descriptions where LMs can more effectively identify the risks. Our overall
system achieves a significant reduction of risky action execution by $55.3\%$
over vanilla-prompted agents.

</details>


### [265] [CrafterDojo: A Suite of Foundation Models for Building Open-Ended Embodied Agents in Crafter](https://arxiv.org/abs/2508.13530)
*Junyeong Park,Hyeonseo Cho,Sungjin Ahn*

Main category: cs.AI

TL;DR: CrafterDojo是一个为通用具身智能体研究提供基础模型和工具的套件，旨在解决Crafter环境的局限性，使其成为一个轻量级、便于原型设计的测试平台。


<details>
  <summary>Details</summary>
Motivation: 为了解决通用具身智能体的开发挑战，同时克服Minecraft环境速度慢和工程开销大的问题，并为Crafter环境提供基础模型以推动其在更广泛任务中的应用。

Method: 提出CrafterVPT、CrafterCLIP和CrafterSteve-1分别用于行为先验、视觉-语言基础和指令遵循。同时提供用于生成行为和字幕数据集（CrafterPlay和CrafterCaption）的工具包、参考智能体实现、基准评估和完整的开源代码库。

Result: CrafterDojo成功地将Crafter环境定位为通用具身智能体研究的轻量级、原型友好且类似Minecraft的测试平台，并通过其提供的基础模型和工具集，极大地促进了该领域的研究。

Conclusion: CrafterDojo通过提供一系列基础模型和工具，解决了Crafter环境在通用具身智能体研究中的局限性，使其成为一个轻量级、便于原型设计且类似Minecraft的测试平台。

Abstract: Developing general-purpose embodied agents is a core challenge in AI.
Minecraft provides rich complexity and internet-scale data, but its slow speed
and engineering overhead make it unsuitable for rapid prototyping. Crafter
offers a lightweight alternative that retains key challenges from Minecraft,
yet its use has remained limited to narrow tasks due to the absence of
foundation models that have driven progress in the Minecraft setting. In this
paper, we present CrafterDojo, a suite of foundation models and tools that
unlock the Crafter environment as a lightweight, prototyping-friendly, and
Minecraft-like testbed for general-purpose embodied agent research. CrafterDojo
addresses this by introducing CrafterVPT, CrafterCLIP, and CrafterSteve-1 for
behavior priors, vision-language grounding, and instruction following,
respectively. In addition, we provide toolkits for generating behavior and
caption datasets (CrafterPlay and CrafterCaption), reference agent
implementations, benchmark evaluations, and a complete open-source codebase.

</details>


### [266] [Toward Better EHR Reasoning in LLMs: Reinforcement Learning with Expert Attention Guidance](https://arxiv.org/abs/2508.13579)
*Yue Fang,Yuxin Guo,Jiaran Gao,Hongxin Ding,Xinke Jiang,Weibin Liao,Yongxin Xu,Yinghao Zhu,Zhibang Yang,Liantao Ma,Junfeng Zhao,Yasha Wang*

Main category: cs.AI

TL;DR: EAG-RL框架通过专家注意力指导，提高了LLM在电子健康记录（EHR）推理方面的能力，并取得了更好的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LLM在EHR推理方面表现不佳，因为它们在建模时间结构化、高维数据方面存在挑战。现有方法未能提高LLM的内在推理能力，并继承了DL模型的泛化限制。

Method: 提出了一种新颖的两阶段训练框架EAG-RL，通过专家注意力指导内在增强LLM的EHR推理能力。EAG-RL首先使用专家指导的蒙特卡洛树搜索来构建高质量的、逐步的推理轨迹，以有效地初始化LLM的策略。然后，EAG-RL通过强化学习来优化策略，使LLM的注意力与专家EHR模型识别的临床显着特征保持一致。

Result: EAG-RL将LLM的内在EHR推理能力平均提高了14.62%，同时提高了对特征扰动的鲁棒性以及对未见临床域的泛化能力。

Conclusion: EAG-RL具有在临床预测任务中实际部署的潜力。

Abstract: Improving large language models (LLMs) for electronic health record (EHR)
reasoning is essential for enabling accurate and generalizable clinical
predictions. While LLMs excel at medical text understanding, they underperform
on EHR-based prediction tasks due to challenges in modeling temporally
structured, high-dimensional data. Existing approaches often rely on hybrid
paradigms, where LLMs serve merely as frozen prior retrievers while downstream
deep learning (DL) models handle prediction, failing to improve the LLM's
intrinsic reasoning capacity and inheriting the generalization limitations of
DL models. To this end, we propose EAG-RL, a novel two-stage training framework
designed to intrinsically enhance LLMs' EHR reasoning ability through expert
attention guidance, where expert EHR models refer to task-specific DL models
trained on EHR data. Concretely, EAG-RL first constructs high-quality, stepwise
reasoning trajectories using expert-guided Monte Carlo Tree Search to
effectively initialize the LLM's policy. Then, EAG-RL further optimizes the
policy via reinforcement learning by aligning the LLM's attention with
clinically salient features identified by expert EHR models. Extensive
experiments on two real-world EHR datasets show that EAG-RL improves the
intrinsic EHR reasoning ability of LLMs by an average of 14.62%, while also
enhancing robustness to feature perturbations and generalization to unseen
clinical domains. These results demonstrate the practical potential of EAG-RL
for real-world deployment in clinical prediction tasks. Our code have been
available at https://github.com/devilran6/EAG-RL.

</details>


### [267] [Breaking the SFT Plateau: Multimodal Structured Reinforcement Learning for Chart-to-Code Generation](https://arxiv.org/abs/2508.13587)
*Lei Chen,Xuanle Zhao,Zhixiong Zeng,Jing Huang,Liming Zheng,Yufeng Zhong,Lin Ma*

Main category: cs.AI

TL;DR: 该研究提出了多模态结构强化学习（MSRL）来解决图表到代码生成中的SFT性能瓶颈。通过结合文本和视觉反馈的多粒度奖励，并使用大规模真实数据训练，MSRL显著提高了性能，优于SFT，并可与闭源模型媲美。


<details>
  <summary>Details</summary>
Motivation: 当前的监督微调（SFT）方法在处理需要深入理解信息丰富图像和生成结构化输出的任务（如图表到代码生成）时，性能会遇到瓶颈。这类任务需要对视觉图表进行复杂推理以生成结构化代码，而单独的SFT难以有效奖励结构化输出。

Method: 提出了一种名为多模态结构强化学习（MSRL）的方法，该方法利用多粒度的结构化奖励系统，结合了基于文本的规则奖励（用于验证代码细节）和基于视觉的基于模型的奖励（通过渲染生成的代码并使用评估模型来评估结构相似性）。该方法在一个为期两阶段的课程中进行训练以保证稳定性。

Result: MSRL方法成功突破了SFT的性能瓶颈。在ChartMimic和ReachQA基准测试上，分别将高级指标提高了6.2%和9.9%。所提出的方法在包含300万图表-代码对的训练语料库上进行了训练，该语料库来自真实的arXiv表格，旨在克服先前合成数据过于简单的模式。

Conclusion: 该研究提出了一种名为多模态结构强化学习（MSRL）的方法，用于解决图表到代码生成任务中的性能瓶颈，并通过大规模实验证明了其有效性，显著提高了在ChartMimic和ReachQA基准测试上的表现，并达到了与先进闭源模型相媲美的性能。

Abstract: While reinforcement learning (RL) has proven highly effective for general
reasoning in vision-language models, its application to tasks requiring
in-depth understanding of information-rich images and generation of structured
outputs remains underexplored. Chart-to-code generation exemplifies this
challenge, demanding complex reasoning over visual charts to generate
structured code. Supervised fine-tuning (SFT) alone is often insufficient,
highlighting the need for effective RL strategies that appropriately reward
structured outputs. We systematically investigate the performance plateau in
SFT through large-scale experiments and propose Multimodal Structured
Reinforcement Learning (MSRL) for chart-to-code generation, which substantially
breaks through this plateau. We construct the largest training corpus to date,
containing 3 million chart-code pairs from real-world arXiv tables to mitigate
simplistic patterns of prior synthetic data. Despite reaching state-of-the-art
performance, our experiments show that scaling SFT data eventually hits a
plateau where further increases yield negligible improvements. Our MSRL method
leverages a multi-granularity structured reward system using multimodal textual
and visual feedback. At the textual level, rule-based rewards validate
fine-grained code details. At the visual level, model-based rewards assess
structural similarity by rendering generated code into images and employing an
evaluator model. We implement this within a two-stage curriculum for training
stability. Results demonstrate that MSRL significantly breaks the SFT plateau,
improving high-level metrics by 6.2% and 9.9% on ChartMimic and ReachQA
benchmarks respectively, achieving competitive performance with advanced
closed-source models.

</details>


### [268] [V2P: From Background Suppression to Center Peaking for Robust GUI Grounding Task](https://arxiv.org/abs/2508.13634)
*Jikai Chen,Long Chen,Dong Wang,Leilei Gan,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: V2P方法通过抑制注意力和高斯热图改进了GUI元素定位，解决了背景干扰和中心-边缘区分问题，并在基准测试中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: 传统的GUI元素定位方法（如边界框或中心点回归）忽略了空间交互不确定性和视觉语义层次。现有方法虽然引入了注意力机制，但仍存在处理背景区域导致注意力漂移以及统一标签无法区分目标元素中心和边缘导致点击不精确的问题。

Method: 提出了一种名为Valley-to-Peak (V2P) 的新方法，该方法包括抑制注意机制以最小化对无关区域的关注，以及受Fitts定律启发的2D高斯热图模型，将GUI交互建模为权重从中心向边缘逐渐衰减的高斯分布，以区分中心和边缘。

Result: 在ScreenSpot-v2和ScreenSpot-Pro两个基准测试中，使用V2P训练的模型分别达到了92.3%和50.5%的性能。消融实验也证实了V2P每个组成部分的贡献及其在精确GUI基础任务上的泛化能力。

Conclusion: V2P方法通过引入抑制注意机制来解决背景干扰问题，并通过受Fitts定律启发的2D高斯热图来解决中心-边缘区分问题，从而实现了精确的GUI定位。

Abstract: Precise localization of GUI elements is crucial for the development of GUI
agents. Traditional methods rely on bounding box or center-point regression,
neglecting spatial interaction uncertainty and visual-semantic hierarchies.
Recent methods incorporate attention mechanisms but still face two key issues:
(1) ignoring processing background regions causes attention drift from the
desired area, and (2) uniform labeling fails to distinguish between center and
edges of the target UI element, leading to click imprecision. Inspired by how
humans visually process and interact with GUI elements, we propose the
Valley-to-Peak (V2P) method to address these issues. To mitigate background
distractions, V2P introduces a suppression attention mechanism that minimizes
the model's focus on irrelevant regions to highlight the intended region. For
the issue of center-edge distinction, V2P applies a Fitts' Law-inspired
approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight
gradually decreases from the center towards the edges. The weight distribution
follows a Gaussian function, with the variance determined by the target's size.
Consequently, V2P effectively isolates the target area and teaches the model to
concentrate on the most essential point of the UI element. The model trained by
V2P achieves the performance with 92.3% and 50.5% on two benchmarks
ScreenSpot-v2 and ScreenSpot-Pro. Ablations further confirm each component's
contribution, highlighting V2P's generalizability for precise GUI grounding
tasks.

</details>


### [269] [Interactive Query Answering on Knowledge Graphs with Soft Entity Constraints](https://arxiv.org/abs/2508.13663)
*Daniel Daza,Alberto Bernardi,Luca Costabello,Christophe Gueret,Masoud Mansoury,Michael Cochez,Martijn Schut*

Main category: cs.AI

TL;DR: Existing query answering methods for incomplete knowledge graphs struggle with vague or context-dependent constraints. We introduce query answering with soft constraints and propose a Neural Query Reranker (NQR) that interactively refines answers based on user examples, maintaining robust performance.


<details>
  <summary>Details</summary>
Motivation: Existing approaches have focused on queries formalized using first-order-logic. In practice, many real-world queries involve constraints that are inherently vague or context-dependent, such as preferences for attributes or related categories. Addressing this gap, we introduce the problem of query answering with soft constraints.

Method: We propose a Neural Query Reranker (NQR) designed to adjust query answer scores by incorporating soft constraints without disrupting the original answers to a query. NQR operates interactively, refining answers based on incremental examples of preferred and non-preferred entities.

Result: We extend existing QA benchmarks by generating datasets with soft constraints. Our experiments demonstrate that NQR can capture soft constraints while maintaining robust query answering performance.

Conclusion: NQR can capture soft constraints while maintaining robust query answering performance.

Abstract: Methods for query answering over incomplete knowledge graphs retrieve
entities that are likely to be answers, which is particularly useful when such
answers cannot be reached by direct graph traversal due to missing edges.
However, existing approaches have focused on queries formalized using
first-order-logic. In practice, many real-world queries involve constraints
that are inherently vague or context-dependent, such as preferences for
attributes or related categories. Addressing this gap, we introduce the problem
of query answering with soft constraints. We propose a Neural Query Reranker
(NQR) designed to adjust query answer scores by incorporating soft constraints
without disrupting the original answers to a query. NQR operates interactively,
refining answers based on incremental examples of preferred and non-preferred
entities. We extend existing QA benchmarks by generating datasets with soft
constraints. Our experiments demonstrate that NQR can capture soft constraints
while maintaining robust query answering performance.

</details>


### [270] [ITL-LIME: Instance-Based Transfer Learning for Enhancing Local Explanations in Low-Resource Data Settings](https://arxiv.org/abs/2508.13672)
*Rehan Raza,Guanjin Wang,Kevin Wong,Hamid Laga,Marco Fisichella*

Main category: cs.AI

TL;DR: ITL-LIME通过迁移学习和实例加权，解决了LIME在数据稀疏时的解释不准确和不稳定问题。


<details>
  <summary>Details</summary>
Motivation: LIME在数据稀疏环境下存在局部性和不稳定性问题，因为其随机扰动和采样可能导致不切实际的样本，无法准确近似原始模型的决策边界。

Method: ITL-LIME框架，包括聚类划分源域、检索相关源实例、结合目标邻近实例、构建基于对比学习的编码器进行实例加权，最后用加权实例训练代理模型。

Result: ITL-LIME框架提高了解释的保真度和稳定性，特别是在数据稀疏的环境下。

Conclusion: ITL-LIME通过引入实例迁移学习，利用相关源域的真实实例来辅助目标域的解释过程，解决了LIME在数据稀疏环境下存在的局部性和不稳定性问题，提高了解释的保真度和稳定性。

Abstract: Explainable Artificial Intelligence (XAI) methods, such as Local
Interpretable Model-Agnostic Explanations (LIME), have advanced the
interpretability of black-box machine learning models by approximating their
behavior locally using interpretable surrogate models. However, LIME's inherent
randomness in perturbation and sampling can lead to locality and instability
issues, especially in scenarios with limited training data. In such cases, data
scarcity can result in the generation of unrealistic variations and samples
that deviate from the true data manifold. Consequently, the surrogate model may
fail to accurately approximate the complex decision boundary of the original
model. To address these challenges, we propose a novel Instance-based Transfer
Learning LIME framework (ITL-LIME) that enhances explanation fidelity and
stability in data-constrained environments. ITL-LIME introduces instance
transfer learning into the LIME framework by leveraging relevant real instances
from a related source domain to aid the explanation process in the target
domain. Specifically, we employ clustering to partition the source domain into
clusters with representative prototypes. Instead of generating random
perturbations, our method retrieves pertinent real source instances from the
source cluster whose prototype is most similar to the target instance. These
are then combined with the target instance's neighboring real instances. To
define a compact locality, we further construct a contrastive learning-based
encoder as a weighting mechanism to assign weights to the instances from the
combined set based on their proximity to the target instance. Finally, these
weighted source and target instances are used to train the surrogate model for
explanation purposes.

</details>


### [271] [Knowledge Graph Completion for Action Prediction on Situational Graphs -- A Case Study on Household Tasks](https://arxiv.org/abs/2508.13675)
*Mariam Arustashvili,Jörg Deigmöller,Heiko Paulheim*

Main category: cs.AI

TL;DR: 该研究发现，用于描述家庭行为的知识图谱具有特殊性，导致标准链接预测算法难以有效处理，并且在信息补充方面不如简单基线方法有效。


<details>
  <summary>Details</summary>
Motivation: 为了更好地控制家用机器人和分析视频片段，需要对家庭行为进行知识图谱描述。然而，从视频中提取的信息往往不完整，因此需要对知识图谱进行补充以增强情境感知能力。

Method: 探讨了知识图谱在家庭行为描述中的应用，并分析了现有链接预测算法在处理这些知识图谱时遇到的挑战。

Result: 现有的链接预测算法在处理情境知识图谱时表现不佳，无法有效弥补信息缺失的问题，甚至无法超越简单的基线方法。

Conclusion: 知识图谱在描述家庭行为方面存在局限性，现有的链接预测算法难以有效处理这些局限性，甚至无法超越简单的基线方法。

Abstract: Knowledge Graphs are used for various purposes, including business
applications, biomedical analyses, or digital twins in industry 4.0. In this
paper, we investigate knowledge graphs describing household actions, which are
beneficial for controlling household robots and analyzing video footage. In the
latter case, the information extracted from videos is notoriously incomplete,
and completing the knowledge graph for enhancing the situational picture is
essential. In this paper, we show that, while a standard link prediction
problem, situational knowledge graphs have special characteristics that render
many link prediction algorithms not fit for the job, and unable to outperform
even simple baselines.

</details>


### [272] [MHSNet:An MoE-based Hierarchical Semantic Representation Network for Accurate Duplicate Resume Detection with Large Language Model](https://arxiv.org/abs/2508.13676)
*Yu Li,Zulong Chen,Wenjian Xu,Hong Wen,Yipeng Yu,Man Lung Yiu,Yuyu Yin*

Main category: cs.AI

TL;DR: MHSNet是一个利用对比学习微调BGE-M3的多层次身份验证框架，通过混合专家模型处理不完整和多样化的简历数据，以提高人才库的质量。


<details>
  <summary>Details</summary>
Motivation: 为了保持公司的人才库，招聘人员需要不断从第三方网站（例如LinkedIn、Indeed）搜索简历。然而，获取的简历通常不完整且不准确。为了提高第三方简历的质量并丰富公司的人才库，有必要对获取的简历与公司现有的人才库进行重复数据检测。由于简历文本的语义复杂性、结构异质性和信息不完整性，这种重复数据检测具有挑战性。

Method: 提出了一种名为MHSNet的多层次身份验证框架，该框架使用对比学习对BGE-M3进行微调。然后，利用混合专家（MoE）模型为简历生成多层次稀疏和密集表示，并计算相应多层次语义相似度。此外，MHSNet还采用了状态感知混合专家（MoE）来处理各种不完整的简历。

Result: MHSNet能够通过生成多层次稀疏和密集表示来计算多层次语义相似度，并有效处理不完整的简历。

Conclusion: 实验结果验证了MHSNet的有效性。

Abstract: To maintain the company's talent pool, recruiters need to continuously search
for resumes from third-party websites (e.g., LinkedIn, Indeed). However,
fetched resumes are often incomplete and inaccurate. To improve the quality of
third-party resumes and enrich the company's talent pool, it is essential to
conduct duplication detection between the fetched resumes and those already in
the company's talent pool. Such duplication detection is challenging due to the
semantic complexity, structural heterogeneity, and information incompleteness
of resume texts. To this end, we propose MHSNet, an multi-level identity
verification framework that fine-tunes BGE-M3 using contrastive learning. With
the fine-tuned , Mixture-of-Experts (MoE) generates multi-level sparse and
dense representations for resumes, enabling the computation of corresponding
multi-level semantic similarities. Moreover, the state-aware Mixture-of-Experts
(MoE) is employed in MHSNet to handle diverse incomplete resumes. Experimental
results verify the effectiveness of MHSNet

</details>


### [273] [Neuro-Symbolic Artificial Intelligence: Towards Improving the Reasoning Abilities of Large Language Models](https://arxiv.org/abs/2508.13678)
*Xiao-Wen Yang,Jie-Jing Shao,Lan-Zhe Guo,Bo-Wen Zhang,Zhi Zhou,Lin-Han Jia,Wang-Zhou Dai,Yu-Feng Li*

Main category: cs.AI

TL;DR: 这篇论文对利用神经符号方法增强大型语言模型（LLM）的推理能力进行了全面的综述，总结了现有技术、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在多项任务中表现出色，但其推理能力仍是关键挑战，而具备强大推理能力的人工智能系统是通用人工智能（AGI）的重要里程碑。

Method: 对神经符号方法进行了全面的综述，从Symbolic->LLM，LLM->Symbolic和LLM+Symbolic三个角度探讨了提高LLM推理能力的方法，并对推理任务进行了形式化，简要介绍了神经符号学习范式。

Result: 该综述全面梳理了神经符号方法在增强LLM推理能力方面的最新进展，并讨论了该领域的挑战与未来发展方向，同时提供了一个包含相关论文和资源的GitHub仓库。

Conclusion: LLMs在推理方面仍有巨大挑战，而神经符号方法为增强LLM推理能力提供了一个有前景的方向，并总结了该领域的最新进展、关键挑战和未来方向。

Abstract: Large Language Models (LLMs) have shown promising results across various
tasks, yet their reasoning capabilities remain a fundamental challenge.
Developing AI systems with strong reasoning capabilities is regarded as a
crucial milestone in the pursuit of Artificial General Intelligence (AGI) and
has garnered considerable attention from both academia and industry. Various
techniques have been explored to enhance the reasoning capabilities of LLMs,
with neuro-symbolic approaches being a particularly promising way. This paper
comprehensively reviews recent developments in neuro-symbolic approaches for
enhancing LLM reasoning. We first present a formalization of reasoning tasks
and give a brief introduction to the neurosymbolic learning paradigm. Then, we
discuss neuro-symbolic methods for improving the reasoning capabilities of LLMs
from three perspectives: Symbolic->LLM, LLM->Symbolic, and LLM+Symbolic.
Finally, we discuss several key challenges and promising future directions. We
have also released a GitHub repository including papers and resources related
to this survey: https://github.com/LAMDASZ-ML/Awesome-LLM-Reasoning-with-NeSy.

</details>


### [274] [The DeepLog Neurosymbolic Machine](https://arxiv.org/abs/2508.13697)
*Vincent Derkinderen,Robin Manhaeve,Rik Adriaensen,Lucas Van Praet,Lennert De Smet,Giuseppe Marra,Luc De Raedt*

Main category: cs.AI

TL;DR: DeepLog是一个神经符号AI框架，包含DeepLog语言和代数电路，用于表示和模拟各种神经符号系统。


<details>
  <summary>Details</summary>
Motivation: 为神经符号AI提供理论和操作框架，使其能够表示和模拟广泛的神经符号系统。

Method: DeepLog是一个包含DeepLog语言和代数电路的框架，用于指定神经符号模型和推理任务。

Result: DeepLog语言是带注释的、可分的、第一阶逻辑的神经扩展，代数电路用于计算图。

Conclusion: DeepLog通用性和效率通过实验得到证明。

Abstract: We contribute a theoretical and operational framework for neurosymbolic AI
called DeepLog. DeepLog introduces building blocks and primitives for
neurosymbolic AI that make abstraction of commonly used representations and
computational mechanisms used in neurosymbolic AI. DeepLog can represent and
emulate a wide range of neurosymbolic systems. It consists of two key
components. The first is the DeepLog language for specifying neurosymbolic
models and inference tasks. This language consists of an annotated neural
extension of grounded first-order logic, and makes abstraction of the type of
logic, e.g. boolean, fuzzy or probabilistic, and whether logic is used in the
architecture or in the loss function. The second DeepLog component is situated
at the computational level and uses extended algebraic circuits as
computational graphs. Together these two components are to be considered as a
neurosymbolic abstract machine, with the DeepLog language as the intermediate
level of abstraction and the circuits level as the computational one. DeepLog
is implemented in software, relies on the latest insights in implementing
algebraic circuits on GPUs, and is declarative in that it is easy to obtain
different neurosymbolic models by making different choices for the underlying
algebraic structures and logics. The generality and efficiency of the DeepLog
neurosymbolic machine is demonstrated through an experimental comparison
between 1) different fuzzy and probabilistic logics, 2) between using logic in
the architecture or in the loss function, and 3) between a standalone CPU-based
implementation of a neurosymbolic AI system and a DeepLog GPU-based one.

</details>


### [275] [CausalPlan: Empowering Efficient LLM Multi-Agent Collaboration Through Causality-Driven Planning](https://arxiv.org/abs/2508.13721)
*Minh Hoang Nguyen,Van Dai Do,Dung Nguyen,Thin Nguyen,Hung Le*

Main category: cs.AI

TL;DR: CausalPlan通过集成结构因果推理来解决LLM在协作任务中因果无效的问题，通过SCA模型学习因果关系指导动作选择，从而提高多智能体LLM的协调和规划能力，并在Overcooked-AI基准测试中取得优于强化学习基线的效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）智能体，特别是较小、开源的模型，由于依赖于表层相关性而非基于因果的推理，因此在协作任务中经常产生因果无效或不连贯的动作。这种局限性会影响它们在动态环境中的协调和规划能力。

Method: CausalPlan是一个两阶段框架，将显式的结构因果推理集成到LLM规划过程中。其核心是结构因果动作（SCA）模型，该模型从智能体轨迹中学习因果图，以捕捉先前的动作和当前的环境状态如何影响未来的决策。然后，该结构用于通过为LLM生成的动作建议分配因果分数、相应地重新加权它们，或者在需要时回退到基于因果的替代方案来指导动作选择。

Result: CausalPlan在Overcooked-AI基准测试的五项多智能体协调任务和四种不同大小的LLM（Gemma-7B、Llama-8B、Qwen-14B和Llama-70B）上进行了评估。实验结果显示，CausalPlan在AI-AI和人-AI设置下都能持续减少无效动作并改善协作，其表现优于强大的强化学习基线。

Conclusion: CausalPlan通过在决策循环中嵌入因果知识，将干预一致性行为约束到规划中，而无需对LLM进行微调。实验结果表明，CausalPlan在Overcooked-AI基准测试的五项多智能体协调任务和四种不同大小的LLM（Gemma-7B、Llama-8B、Qwen-14B和Llama-70B）上，能够持续减少无效动作并改善AI-AI和人-AI协作，其表现优于强大的强化学习基线。这些发现强调了以因果驱动的规划对于部署高效、可解释和可泛化的多智能体LLM系统的重要性。

Abstract: Large language model (LLM) agents-especially smaller, open-source
models-often produce causally invalid or incoherent actions in collaborative
tasks due to their reliance on surface-level correlations rather than grounded
causal reasoning. This limitation undermines their performance in terms of
coordination and planning in dynamic environments. We address this challenge
with CausalPlan, a two-phase framework that integrates explicit structural
causal reasoning into the LLM planning process. At the core of CausalPlan is
the Structural Causal Action (SCA) model, which learns a causal graph from
agent trajectories to capture how prior actions and current environment states
influence future decisions. This structure is then used to guide action
selection by assigning causal scores to LLM-generated proposals, reweighting
them accordingly, or falling back to causally grounded alternatives when
needed. By embedding this causal knowledge directly into the decision loop,
CausalPlan constrains planning to intervention-consistent behaviours without
requiring fine-tuning of the LLM itself. We evaluate CausalPlan on the
Overcooked-AI benchmark across five multi-agent coordination tasks and four
LLMs of varying sizes: Gemma-7B, Llama-8B, Qwen-14B, and Llama-70B.
Experimental results show that CausalPlan consistently reduces invalid actions
and improves collaboration in both AI-AI and human-AI settings, outperforming
strong reinforcement learning baselines. Our findings highlight the value of
causality-driven planning for deploying efficient, interpretable, and
generalisable multi-agent LLM systems.

</details>


### [276] [Expertise-aware Multi-LLM Recruitment and Collaboration for Medical Decision-Making](https://arxiv.org/abs/2508.13754)
*Liuxin Bao,Zhihao Peng,Xiaofei Zhou,Runmin Cong,Jiyong Zhang,Yixuan Yuan*

Main category: cs.AI

TL;DR: EMRC框架通过招募具有不同专业知识的LLM并让它们协作，提高了医疗决策制定的准确性，相比GPT-4等模型有显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型（LLM）在支持医疗决策制定（MDM）方面显示出潜力，但单一LLM由于其参数知识限制和静态训练语料库，在整合临床信息方面存在不足。为了解决这一挑战，本文旨在通过EMRC框架来提高MDM系统的准确性和可靠性。

Method: 本文提出了一种名为EMRC（Expertise-aware Multi-LLM Recruitment and Collaboration）的框架，用于增强医疗决策制定（MDM）系统的准确性和可靠性。该框架分为两个阶段：1. 专业知识感知代理招募：利用公开语料库构建LLM专业知识表，捕捉多个LLM在不同医疗部门类别和查询难度下的专业特长，以便在推理阶段动态选择最优LLM作为医学专家代理。2. 置信度和对抗性驱动的多代理协作：选定的代理生成带有自我评估置信度分数的响应，并通过置信度融合和对抗性验证进行整合，以提高诊断可靠性。

Result: EMRC框架在三个公共MDM数据集上进行了评估，结果显示其在准确性和可靠性方面优于当前最先进的单模型和多模型方法。具体而言，在MMLU-Pro-Health数据集上，EMRC的准确率达到了74.45%，相比表现最佳的闭源模型GPT-4-0613提高了2.69%。

Conclusion: EMRC框架在三个公共MDM数据集上的评估结果表明，其性能优于最先进的单模型和多模型方法，并在MMLU-Pro-Health数据集上实现了74.45%的准确率，比表现最佳的闭源模型GPT-4-0613高出2.69%，证明了其专业知识感知代理招募策略和利用各LLM专业能力的代理互补性的有效性。

Abstract: Medical Decision-Making (MDM) is a complex process requiring substantial
domain-specific expertise to effectively synthesize heterogeneous and
complicated clinical information. While recent advancements in Large Language
Models (LLMs) show promise in supporting MDM, single-LLM approaches are limited
by their parametric knowledge constraints and static training corpora, failing
to robustly integrate the clinical information. To address this challenge, we
propose the Expertise-aware Multi-LLM Recruitment and Collaboration (EMRC)
framework to enhance the accuracy and reliability of MDM systems. It operates
in two stages: (i) expertise-aware agent recruitment and (ii) confidence- and
adversarial-driven multi-agent collaboration. Specifically, in the first stage,
we use a publicly available corpus to construct an LLM expertise table for
capturing expertise-specific strengths of multiple LLMs across medical
department categories and query difficulty levels. This table enables the
subsequent dynamic selection of the optimal LLMs to act as medical expert
agents for each medical query during the inference phase. In the second stage,
we employ selected agents to generate responses with self-assessed confidence
scores, which are then integrated through the confidence fusion and adversarial
validation to improve diagnostic reliability. We evaluate our EMRC framework on
three public MDM datasets, where the results demonstrate that our EMRC
outperforms state-of-the-art single- and multi-LLM methods, achieving superior
diagnostic performance. For instance, on the MMLU-Pro-Health dataset, our EMRC
achieves 74.45% accuracy, representing a 2.69% improvement over the
best-performing closed-source model GPT- 4-0613, which demonstrates the
effectiveness of our expertise-aware agent recruitment strategy and the agent
complementarity in leveraging each LLM's specialized capabilities.

</details>


### [277] [Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of Multi-RAG System Collaboration](https://arxiv.org/abs/2508.13828)
*Yifei Chen,Guanting Dong,Yutao Zhu,Zhicheng Dou*

Main category: cs.AI

TL;DR: Ensemble methods for RAG systems improve generalizability and robustness at both pipeline and module levels, offering a promising direction for future research.


<details>
  <summary>Details</summary>
Motivation: Existing RAG frameworks struggle to adapt to a broad range of downstream tasks, making it necessary to explore how to leverage the advantages of multiple RAG systems.

Method: The paper conducts a comprehensive and systematic investigation into ensemble methods based on RAG systems. It analyzes the RAG ensemble framework from theoretical (information entropy) and mechanistic (pipeline and module levels) perspectives, exploring four pipelines (Branching, Iterative, Loop, and Agentic) and three modules (Generator, Retriever, and Reranker) to address seven research questions.

Result: Experiments demonstrate that aggregating multiple RAG systems is generalizable and robust at both pipeline and module levels.

Conclusion: Aggregating multiple RAG systems, whether at the pipeline or module level, is both generalizable and robust. This work lays the foundation for similar research on multi-RAG system ensembles.

Abstract: Retrieval-Augmented Generation (RAG) technology has been widely applied in
recent years. However, despite the emergence of various RAG frameworks, a
single RAG framework still cannot adapt well to a broad range of downstream
tasks. Therefore, how to leverage the advantages of multiple RAG systems has
become an area worth exploring. To address this issue, we have conducted a
comprehensive and systematic investigation into ensemble methods based on RAG
systems. Specifically, we have analyzed the RAG ensemble framework from both
theoretical and mechanistic analysis perspectives. From the theoretical
analysis, we provide the first explanation of the RAG ensemble framework from
the perspective of information entropy. In terms of mechanism analysis, we have
explored the RAG ensemble framework from both the pipeline and module levels.
We carefully select four different pipelines (Branching, Iterative, Loop, and
Agentic) and three different modules (Generator, Retriever, and Reranker) to
solve seven different research questions. The experiments show that aggregating
multiple RAG systems is both generalizable and robust, whether at the pipeline
level or the module level. Our work lays the foundation for similar research on
the multi-RAG system ensemble.

</details>


### [278] [Improved Generalized Planning with LLMs through Strategy Refinement and Reflection](https://arxiv.org/abs/2508.13876)
*Katharina Stein,Nils Hodel,Daniel Fišer,Jörg Hoffmann,Michael Katz,Alexander Koller*

Main category: cs.AI

TL;DR: LLM生成的Python程序在PDDL规划领域取得了进展，通过伪代码调试和反思机制提高了泛化计划的质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决先前工作中，LLM生成的策略不正确导致泛化计划也存在错误的问题，本研究旨在通过伪代码调试和反思机制来提高生成计划的准确性。

Method: 该方法引入了生成伪代码的策略，并实现了对伪代码的自动调试，从而在生成泛化计划之前识别和修复错误。此外，还通过反思步骤提示LLM找出计划失败的原因，并生成多个程序变体以选择最优解。

Result: 在17个基准领域进行的实验表明，这些改进显著提高了泛化计划的质量，其中12个领域的最佳Python程序能够解决所有可由相应实例生成器生成的任务。

Conclusion: LLM生成的Python程序在PDDL规划领域有了显著的改进，其泛化能力得到了提升。

Abstract: LLMs have recently been used to generate Python programs representing
generalized plans in PDDL planning, i.e., plans that generalize across the
tasks of a given PDDL domain. Previous work proposed a framework consisting of
three steps: the LLM first generates a summary and then a strategy for the
domain, both in natural language, and then implements that strategy as a Python
program, that gets debugged on example planning tasks. In that work, only one
strategy is generated and passed directly to the program generation. If the
strategy is incorrect, its implementation will therefore result in an incorrect
generalized plan. Here, we introduce an approach that generates the strategy in
the form of pseudocode and enables automatic debugging of the pseudocode, hence
allowing us to identify and fix errors prior to the generation of the
generalized plan itself. Additionally, we extend the Python debugging phase
with a reflection step prompting the LLM to pinpoint the reason for the
observed plan failure. Finally, we take inspiration from LLM code generation to
produce several program variants and pick the best one. Running experiments on
17 benchmark domains, we show that these extensions substantially improve (and
never deteriorate) the quality of the generalized plans. In 12 of the domains,
our best Python programs solve all tasks that can be generated with the
respective instance generator.

</details>


### [279] [Structured Agentic Workflows for Financial Time-Series Modeling with LLMs and Reflective Feedback](https://arxiv.org/abs/2508.13915)
*Yihao Ang,Yifan Bao,Lei Jiang,Jiajie Tao,Anthony K. H. Tung,Lukasz Szpruch,Hao Ni*

Main category: cs.AI

TL;DR: TS-Agent 是一个利用 LLM 的 agentic 框架，用于自动化金融时间序列建模，通过三个阶段（模型选择、代码优化、微调）进行，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管 AutoML 框架简化了模型开发，但它们通常缺乏适应领域特定需求和不断变化的目标的适应性和响应能力。LLM 驱动的 agentic 系统能够进行推理、内存管理和动态代码生成，为灵活的工作流自动化提供了途径，解决了这一挑战。

Method: TS-Agent 是一个模块化的 agentic 框架，通过模型选择、代码优化和微调三个阶段的结构化、迭代决策过程来自动化和增强金融应用的时间序列建模工作流。该框架由一个具有结构化知识库、模型库和优化策略库的规划 agent 驱动，以指导探索、提高可解释性并减少错误传播。

Result: TS-Agent 在各种金融预测和合成数据生成任务上进行了实证评估，结果表明该框架在准确性、鲁棒性和决策可追溯性方面优于最先进的 AutoML 和 agentic 基线。

Conclusion: TS-Agent 框架在金融时间序列建模工作流的自动化和增强方面表现出色，一致优于最先进的 AutoML 和 agentic 基线，在准确性、鲁棒性和决策可追溯性方面均表现出优越性能。

Abstract: Time-series data is central to decision-making in financial markets, yet
building high-performing, interpretable, and auditable models remains a major
challenge. While Automated Machine Learning (AutoML) frameworks streamline
model development, they often lack adaptability and responsiveness to
domain-specific needs and evolving objectives. Concurrently, Large Language
Models (LLMs) have enabled agentic systems capable of reasoning, memory
management, and dynamic code generation, offering a path toward more flexible
workflow automation. In this paper, we introduce \textsf{TS-Agent}, a modular
agentic framework designed to automate and enhance time-series modeling
workflows for financial applications. The agent formalizes the pipeline as a
structured, iterative decision process across three stages: model selection,
code refinement, and fine-tuning, guided by contextual reasoning and
experimental feedback. Central to our architecture is a planner agent equipped
with structured knowledge banks, curated libraries of models and refinement
strategies, which guide exploration, while improving interpretability and
reducing error propagation. \textsf{TS-Agent} supports adaptive learning,
robust debugging, and transparent auditing, key requirements for high-stakes
environments such as financial services. Empirical evaluations on diverse
financial forecasting and synthetic data generation tasks demonstrate that
\textsf{TS-Agent} consistently outperforms state-of-the-art AutoML and agentic
baselines, achieving superior accuracy, robustness, and decision traceability.

</details>


### [280] [The Collaboration Paradox: Why Generative AI Requires Both Strategic Intelligence and Operational Stability in Supply Chain Management](https://arxiv.org/abs/2508.13942)
*Soumyadeep Dhar*

Main category: cs.AI

TL;DR: 在供应链中使用人工智能代理时要小心，因为它们可能会因为囤积库存而导致灾难性的故障（协作悖论）。为了获得最佳结果，请结合使用高级策略设置和低级补货协议。


<details>
  <summary>Details</summary>
Motivation: 研究经济环境中自主的、由人工智能驱动的代理的战略行为，特别是在以牛鞭效应等不稳定性而闻名的多级供应链的合作背景下。

Method: 通过在旨在分离其行为倾向的受控供应链模拟中，对由大型语言模型（LLM）支持的生成式人工智能代理进行计算实验，对这些动态进行了研究。

Result: 发现了一种新颖的、灾难性的故障模式，称为“协作悖论”，其中理论上更优越的、具有供应商管理库存（VMI）原则的协作式人工智能代理的表现甚至比非人工智能基线差。这种悖论源于一种操作缺陷，即代理囤积库存，导致系统饿死。通过结合两个不同的层次（用于建立鲁棒操作目标的高级、由人工智能驱动的主动策略设定，以及用于维持稳定性的主动下游补货的低级、协作执行协议）实现了弹性。

Conclusion: 这项工作为理解协作式人工智能代理的涌现行为提供了关键见解，并为设计稳定、有效的由人工智能驱动的商业分析系统提供了蓝图。

Abstract: The rise of autonomous, AI-driven agents in economic settings raises critical
questions about their emergent strategic behavior. This paper investigates
these dynamics in the cooperative context of a multi-echelon supply chain, a
system famously prone to instabilities like the bullwhip effect. We conduct
computational experiments with generative AI agents, powered by Large Language
Models (LLMs), within a controlled supply chain simulation designed to isolate
their behavioral tendencies. Our central finding is the "collaboration
paradox": a novel, catastrophic failure mode where theoretically superior
collaborative AI agents, designed with Vendor-Managed Inventory (VMI)
principles, perform even worse than non-AI baselines. We demonstrate that this
paradox arises from an operational flaw where agents hoard inventory, starving
the system. We then show that resilience is only achieved through a synthesis
of two distinct layers: high-level, AI-driven proactive policy-setting to
establish robust operational targets, and a low-level, collaborative execution
protocol with proactive downstream replenishment to maintain stability. Our
final framework, which implements this synthesis, can autonomously generate,
evaluate, and quantify a portfolio of viable strategic choices. The work
provides a crucial insight into the emergent behaviors of collaborative AI
agents and offers a blueprint for designing stable, effective AI-driven systems
for business analytics.

</details>


### [281] [ChronoLLM: Customizing Language Models for Physics-Based Simulation Code Generation](https://arxiv.org/abs/2508.13975)
*Jingquan Wang,Andrew Negrut,Harry Zhang,Khailanii Slaton,Shu Wang,Radu Serban,Jinlong Wu,Dan Negrut*

Main category: cs.AI

TL;DR: 大语言模型可以通过微调和定制，成为帮助专家使用PyChrono仿真工具的虚拟助手，能够生成仿真脚本并回答相关问题。


<details>
  <summary>Details</summary>
Motivation: 研究预训练大语言模型（LLM）是否可以通过微调和定制，成为帮助专家有效使用仿真工具的虚拟助手。

Method: 提出一个框架，通过在PyChrono仿真脚本上进行微调和定制，以利用AI生成仿真脚本。

Result: LLM在生成PyChchrono仿真脚本方面得到了量化改进，可以处理从简单到复杂的各种仿真场景，并能回答API问题和推荐建模方法。

Conclusion: 该框架通用，可用于降低其他应用领域仿真工具的入门门槛。

Abstract: This contribution is concerned with the following issue: can pretrained large
language models (LLMs) be refined and customized to the point where they become
virtual assistants helping experts with the effective use of a simulation tool?
In this case study, the ``simulation tool'' considered is PyChrono, an open
source multi-physics dynamics engine for multibody systems. We present a
framework for refining and customizing both open- and closed-source LLMs to
harness the power of AI in generating scripts that perform PyChrono virtual
experiments. We refine and customize several classes of LLMs through a process
that leads to a quantifiable improvement in the quality of the generated
PyChrono simulation scripts. These scripts can range from simple
single-pendulum simulations to complex virtual experiments involving full
vehicles on deformable terrain. While the generated scripts are rarely perfect,
they often serve as strong starting points for the user to modify and improve
on. Additionally, the LLM can answer specific API questions about the
simulator, or recommend modeling approaches. The framework discussed is general
and can be applied to lower the entry barrier for simulation tools associated
with other application domains.

</details>


### [282] [A Biased Random Key Genetic Algorithm for Solving the Longest Run Subsequence Problem](https://arxiv.org/abs/2508.14020)
*Christian Blum,Pedro Pinacho-Davidson*

Main category: cs.AI

TL;DR: BRKGA是一种解决LRS问题的先进算法，在效率方面优于其他方法，但仍需改进。


<details>
  <summary>Details</summary>
Motivation: LRS问题是NP难问题，在基因组重组中起着作用，需要一种有效的解决方案。

Method: 使用带偏见的随机键遗传算法（BRKGA）解决LRS问题，并与最大-最小蚂蚁系统和CPLEX求解器进行比较。

Result: BRKGA是解决LRS问题的最先进技术，但在处理大字母串方面仍有改进空间。

Conclusion: BRKGA是目前最先进的LRS问题技术，但对于大字母串，仍有改进空间。

Abstract: The longest run subsequence (LRS) problem is an NP-hard combinatorial
optimization problem belonging to the class of subsequence problems from
bioinformatics. In particular, the problem plays a role in genome reassembly.
In this paper, we present a solution to the LRS problem using a Biased Random
Key Genetic Algorithm (BRKGA). Our approach places particular focus on the
computational efficiency of evaluating individuals, which involves converting
vectors of gray values into valid solutions to the problem. For comparison
purposes, a Max-Min Ant System is developed and implemented. This is in
addition to the application of the integer linear programming solver CPLEX for
solving all considered problem instances. The computation results show that the
proposed BRKGA is currently a state-of-the-art technique for the LRS problem.
Nevertheless, the results also show that there is room for improvement,
especially in the context of input strings based on large alphabet sizes.

</details>


### [283] [ComputerRL: Scaling End-to-End Online Reinforcement Learning for Computer Use Agents](https://arxiv.org/abs/2508.14040)
*Hanyu Lai,Xiao Liu,Yanxiao Zhao,Han Xu,Hanchen Zhang,Bohao Jing,Yanyu Ren,Shuntian Yao,Yuxiao Dong,Jie Tang*

Main category: cs.AI

TL;DR: ComputerRL是一个自主桌面智能框架，通过API-GUI范式和分布式强化学习基础设施，解决了机器智能体与人本桌面环境的交互问题。结合Entropulse训练策略，在OSWorld基准测试中，基于GLM-4-9B-0414的模型达到了48.1%的准确率，显著提升了桌面自动化能力。


<details>
  <summary>Details</summary>
Motivation: 为了提升智能体在复杂数字工作空间中的操作能力，并解决端到端强化学习训练在环境效率和稳定性方面的挑战，从而实现跨越不同桌面任务的改进和泛化。

Method: 提出了一种API-GUI范式，统一了API调用和GUI交互，以解决机器智能体与人本桌面环境之间的不匹配问题。开发了一个分布式强化学习基础设施，可以编排数千个并行的虚拟桌面环境，以加速大规模在线强化学习。提出了一种名为Entropulse的训练策略，该策略通过强化学习和监督微调的交替进行，有效缓解了在长时间训练中熵崩溃的问题。

Result: 在OSWorld基准测试中，基于GLM-4-9B-0414的AutoGLM-OS-9B实现了48.1%的准确率，创下新的SOTA记录。

Conclusion: ComputerRL框架在OSWorld基准测试中，基于GLM-4-9B-0414的AutoGLM-OS-9B实现了48.1%的准确率新SOTA，证明了其在桌面自动化通用智能体方面的显著提升。该框架和算法已被用于构建AutoGLM（Liu et al., 2024a）。

Abstract: We introduce ComputerRL, a framework for autonomous desktop intelligence that
enables agents to operate complex digital workspaces skillfully. ComputerRL
features the API-GUI paradigm, which unifies programmatic API calls and direct
GUI interaction to address the inherent mismatch between machine agents and
human-centric desktop environments. Scaling end-to-end RL training is crucial
for improvement and generalization across diverse desktop tasks, yet remains
challenging due to environmental inefficiency and instability in extended
training. To support scalable and robust training, we develop a distributed RL
infrastructure capable of orchestrating thousands of parallel virtual desktop
environments to accelerate large-scale online RL. Furthermore, we propose
Entropulse, a training strategy that alternates reinforcement learning with
supervised fine-tuning, effectively mitigating entropy collapse during extended
training runs. We employ ComputerRL on open models GLM-4-9B-0414 and
Qwen2.5-14B, and evaluate them on the OSWorld benchmark. The AutoGLM-OS-9B
based on GLM-4-9B-0414 achieves a new state-of-the-art accuracy of 48.1%,
demonstrating significant improvements for general agents in desktop
automation. The algorithm and framework are adopted in building AutoGLM (Liu et
al., 2024a)

</details>


<div id='cond-mat.mtrl-sci'></div>

# cond-mat.mtrl-sci [[Back]](#toc)

### [284] [The Rise of Generative AI for Metal-Organic Framework Design and Synthesis](https://arxiv.org/abs/2508.13197)
*Chenru Duan,Aditya Nandy,Shyam Chand Pal,Xin Yang,Wenhao Gao,Yuanqi Du,Hendrik Kraß,Yeonghun Kang,Varinia Bernales,Zuyang Ye,Tristan Pyle,Ray Yang,Zeqi Gu,Philippe Schwaller,Shengqian Ma,Shijing Sun,Alán Aspuru-Guzik,Seyed Mohamad Moosavi,Robert Wexler,Zhiling Zheng*

Main category: cond-mat.mtrl-sci

TL;DR: 生成式AI正在彻底改变MOF的设计和发现，通过自动化提案和加速发现流程，但仍面临合成可行性和数据多样性等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的进步，金属有机框架（MOF）的设计和发现方式发生了转变，从费力的MOF候选枚举转向能够自主按需提出和合成新的多孔网状结构的生成方法。

Method: 本研究概述了生成式人工智能（包括深度学习模型，如变分自编码器、扩散模型和大型语言模型代理）在金属有机框架（MOF）设计和发现中的应用。这些方法利用不断增长的MOF数据来提出新的多孔网状结构，并能与高通量计算筛选和自动化实验相结合，形成加速的、闭环的发现流程。

Result: 生成式AI工具与高通量计算筛选和自动化实验相结合，形成加速的、闭环的发现流程，从而实现了由AI算法更有效地指导高性能MOF材料在清洁空气和能源应用中的搜索的新范例。

Conclusion: AI算法（包括变分自编码器、扩散模型和基于大型语言模型的代理）正通过加速高容量金属有机框架（MOF）材料的发现和设计，彻底改变了团簇化学。这些工具通过结合高通量计算筛选和自动化实验，实现了高效的闭环发现流程，在清洁空气和能源应用中具有巨大潜力。然而，仍需克服合成可行性、数据集多样性和领域知识整合等方面的挑战。

Abstract: Advances in generative artificial intelligence are transforming how
metal-organic frameworks (MOFs) are designed and discovered. This Perspective
introduces the shift from laborious enumeration of MOF candidates to generative
approaches that can autonomously propose and synthesize in the laboratory new
porous reticular structures on demand. We outline the progress of employing
deep learning models, such as variational autoencoders, diffusion models, and
large language model-based agents, that are fueled by the growing amount of
available data from the MOF community and suggest novel crystalline materials
designs. These generative tools can be combined with high-throughput
computational screening and even automated experiments to form accelerated,
closed-loop discovery pipelines. The result is a new paradigm for reticular
chemistry in which AI algorithms more efficiently direct the search for
high-performance MOF materials for clean air and energy applications. Finally,
we highlight remaining challenges such as synthetic feasibility, dataset
diversity, and the need for further integration of domain knowledge.

</details>


### [285] [Magnetic and Mossbauer studies of Ca$_x$Zn$_{1-x}$Fe$_2$O$_4$ nanoferrites](https://arxiv.org/abs/2508.13202)
*Kemi Y. Adewale,Itegbeyogene P. Ezekiel*

Main category: cond-mat.mtrl-sci

TL;DR: A one-step glycol-thermal method was used to synthesize Ca$_x$Zn$_{1-x}$Fe$_2$O$_4$ nanoferrites and nanocomposites. The materials were characterized and found to have different crystal structures depending on the value of x, and all samples showed superparamagnetic properties.


<details>
  <summary>Details</summary>
Motivation: The motivation for this study was to synthesize Ca$_x$Zn$_{1-x}$Fe$_2$O$_4$ nanoferrites and nanocomposites using a one-step glycol-thermal method and to investigate their structural, morphological, and magnetic properties.

Method: Glycol-thermal method was employed for the one-step synthesis of Ca$_x$Zn$_{1-x}$Fe$_2$O$_4$ (x=0, 0.5 and 1) nanoferrites and nanocomposites. The structural, morphological, and magnetic properties were analyzed using X-ray Diffraction (XRD), High-Resolution Transmission Electron Microscopy (HRTEM), High-Resolution Scanning Electron Microscopy (HRSEM), Mossbauer spectroscopy, and Vibrating Sample Magnetometry (VSM).

Result: XRD analysis revealed a single-phase cubic spinel structure for x=0, a composite phase (spinel and hematite-like) for x=0.5, and a hematite-like structure for x=1 (CaFe$_2$O$_4$). Mossbauer spectroscopy and magnetization measurements confirmed that the synthesized samples exhibit superparamagnetic behavior.

Conclusion: The study reports a one-step glycol-thermal synthesis of Ca$_x$Zn$_{1-x}$Fe$_2$O$_4$ nanoferrites and nanocomposites. The synthesized materials were characterized using XRD, HRTEM, HRSEM, Mossbauer spectroscopy, and VSM to understand their structural, morphological, and magnetic properties. The results indicate a single-phase cubic spinel structure for x=0, a composite phase of spinel and hematite-like structure for x=0.5, and a hematite-like structure for x=1 (CaFe$_2$O$_4$). Mossbauer and magnetization results confirmed the superparamagnetic nature of the samples.

Abstract: A one-step synthesis of Ca$_x$Zn$_{1-x}$Fe$_2$O$_4$ (x=0, 0.5 and 1)
nanoferrites and nanocomposites by the glycol-thermal method is reported. The
structural, morphological and magnetic properties were studied using XRD,
HRTEM, HRSEM, Mossbauer spectroscopy and VSM. The XRD patterns show a single
phase cubic spinel structure for x=0. A composite phase of a spinel and
hematite-like structure was observed for x=0.5, and for x=1, CaFe$_2$O$_4$ has
the same structure as hematite. The superparamagnetic nature of the samples was
confirmed from the Mossbauer and magnetization results.

</details>


### [286] [Synthesis and Characterization of Mg doped ZnFe$_2$O$_4$](https://arxiv.org/abs/2508.13203)
*Kemi Y. Adewale,Itegbeyogene P. Ezekiel*

Main category: cond-mat.mtrl-sci

TL;DR: 通过乙二醇热法制备 Mg 掺杂 ZnFe$_2$O$_4$ 纳米颗粒，在 x=0.3 时表现出最佳磁性能。


<details>
  <summary>Details</summary>
Motivation: 研究 Mg 掺杂对 ZnFe$_2$O$_4$ 纳米颗粒的晶体结构、微观结构和磁性能的影响。

Method: 采用乙二醇热法制备单相 Mg 掺杂 ZnFe$_2$O$_4$ 纳米颗粒。

Result: XRD 确认了单一立方尖晶石结构，晶粒尺寸为 19-28 nm。 Mossbauer 光谱和振动样品磁强计证实了材料的亚铁磁和超顺磁行为。在 x=0.3 时，Mg 掺杂浓度最高，具有最高的矫顽力和饱和磁化强度。随着 Mg$^{2+}$ 浓度的增加，饱和磁化强度降低，矫顽力发生变化。

Conclusion: Mg$^{2+}$ 掺杂 ZnFe$_2$O$_4$ 纳米颗粒在 x=0, 0.3, 0.5, 0.7 时通过乙二醇热法制备，无需煅烧。XRD 结果显示所有样品均呈现尖锐的单一立方尖晶石结构，无杂质峰，平均晶粒尺寸约为 19-28 nm。随着 Mg$^{2+}$ 离子浓度的增加，晶格参数发生变化。Mossbauer 光谱和振动样品磁强计测量表明，纳米铁氧体表现出亚铁磁和超顺磁状态，并且证实了超顺磁行为。在 x=0.3 时观察到最高的矫顽力和饱和磁化强度。饱和磁化强度 (MS) 随 Mg$^{2+}$ 离子浓度的增加而降低，而矫顽力 (HC) 随之变化。

Abstract: Single-phase Mg-doped ZnFe$_2$O$_4$ nanoparticles with x= 0, 0.3, 0.5, 0.7
have been prepared by the glycol-thermal method without any subsequent
calcination. The crystallite size, microstructure and magnetic properties of
the prepared nanoparticles were studied using X-ray diffraction (XRD), high
resolution scanning electron microscope (TEM), Mossbauer spectroscopy and
vibrating sample magnetometer at room temperature. The XRD results revealed the
production of a sharp single cubic spinel structure in all the synthesized
samples without any impurity peak with the average crystallite size of about
19-28 nm. It was noticed that the lattice parameter varies as the Mg$^{2+}$ ion
concentration increases. 57 Mossbauer measurement showed that the nano ferrites
exhibit ferrimagnetic and superparamagnetic states. Magnetization measurements
confirmed the superparamagnetic behaviour of the samples. The highest
coercivity and saturation magnetization were observed at x=0.3. The saturation
magnetization (MS) decreases while coercivity (HC) varies with an increase in
the concentration of Mg$^{2+}$ ion.

</details>


### [287] [Towards Capacitive In-Memory-computing: A perspective on the future of AI hardware](https://arxiv.org/abs/2508.13225)
*Kapil Bhardwaj,Ella Paasio,Sayani Majumdar*

Main category: cond-mat.mtrl-sci

TL;DR: Capacitive memories are a promising alternative to memristive memories for neuromorphic computing due to their energy efficiency and scalability, despite system-level challenges that require careful management.


<details>
  <summary>Details</summary>
Motivation: The quest for energy-efficient, scalable neuromorphic computing necessitates exploring alternatives to memristive CIM architectures due to their limitations (static power, sneak paths, voltage drops), especially at advanced technology nodes.

Method: This paper provides a perspective by examining architectural and device-level advantages of non-volatile capacitive synapses, including material engineering, interface control, and system-level trade-offs such as device-to-device variation, charge transfer noise, dynamic range, and effective analog resolution.

Result: Capacitive memories enable charge-domain computation with virtually zero static power loss, intrinsic immunity to sneak paths, and simplified selector-less crossbar operation, showing superior compatibility with 3D BEOL integration. Material engineering and interface control can modulate synaptic behavior, while system-level trade-offs need to be managed.

Conclusion: Emerging non-volatile capacitive synapses offer significant advantages over memristive memories for energy-efficient, scalable neuromorphic computing, with potential for advanced technology nodes and 3D BEOL integration.

Abstract: The quest for energy-efficient, scalable neuromorphic computing has elevated
compute-in-memory (CIM) architectures to the forefront of hardware innovation.
While memristive memories have been extensively explored for synaptic
implementation in CIM architectures, their inherent limitations, including
static power dissipation, sneak-path currents, and interconnect voltage drops,
pose significant challenges for large-scale deployment, particularly at
advanced technology nodes. In contrast, capacitive memories offer a compelling
alternative by enabling charge-domain computation with virtually zero static
power loss, intrinsic immunity to sneak paths, and simplified selector-less
crossbar operation, while offering superior compatibility with 3D
Back-end-of-Line (BEOL) integration. This perspective highlights the
architectural and device-level advantages of emerging non-volatile capacitive
synapses. We examine how material engineering and interface control can
modulate synaptic behavior, capacitive memory window and multilevel analog
storage potential. Furthermore, we explore critical system-level trade-offs
involving device-to-device variation, charge transfer noise, dynamic range, and
effective analog resolution.

</details>


### [288] [Numerical Simulation of Lead-Free Absorbers in 2D Dion-Jacobson Phase Perovskite Solar Cells Using SCAPS-1D: Towards 41% Efficiency](https://arxiv.org/abs/2508.13286)
*Md. Meraz Hasan,Pallab Chakraborty,Fahim Tanvir,Subah Tahsin,Mostafizur Rahaman*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究使用SCAPS-1D模拟了2D/吸收层/2D结构的PSC，评估了七种无铅吸收材料。Sb2Se3和CZTSSe效率最高（约41%），MZO是FTO的良好替代品。


<details>
  <summary>Details</summary>
Motivation: 为了开发环保且结构先进的钙钛矿太阳能电池（PSC），本研究旨在识别最佳的吸收材料并提高器件的整体效率，特别关注无铅吸收材料的评估。

Method: 采用SCAPS-1D仿真软件，评估了七种无铅吸收材料（MASnBr3、Sr3PI3/Sr3SbI3、p-CuBi2O4、p-Si、CH3NH3SnI3、Sb2Se3和CZTSSe）在FTO/PeDAMA8Pb6I19/IDL1/absorber/IDL2/PeDAMA2Pb3I10/C结构中的性能。研究内容包括能带对齐、预优化筛选、以及通过调整吸收层厚度、掺杂水平和缺陷密度进行的性能优化。此外，还研究了温度敏感性以及用ITO、IZO和MZO替代FTO层。

Result: 仿真结果显示，Sb2Se3和CZTSSe的效率分别达到了41.00%和41.19%。MZO是替代FTO的有力候选材料，在所有分析的吸收材料中保持了稳定的性能。

Conclusion: 该研究为层状钙钛矿太阳能电池（PSC）的材料选择提供了一个比较框架，并为开发稳定、高效、无铅的光伏技术做出了贡献。

Abstract: With the rapid advancement of photovoltaic science, there has been an
increasing focus on the development of environment-friendly and structurally
advanced perovskite solar cells (PSCs). In this context, this study
investigates an architectural configuration employing 2D Dion-Jacobson phase
perovskites as both electron and hole transport layers within a 2D/absorber/2D
structure. The primary objective is to identify optimal absorber materials and
enhance the overall efficiency of the device. While the reduction of lead
content remains a significant challenge in PSC development, the present work
focuses on the evaluation of seven lead-free absorber materials: MASnBr3,
Sr3PI3/Sr3SbI3, p-CuBi2O4, p-Si, CH3NH3SnI3, Sb2Se3, and CZTSSe. These
materials were assessed in the context of an
FTO/PeDAMA8Pb6I19/IDL1/absorber/IDL2/PeDAMA2Pb3I10/C architecture utilizing
SCAPS-1D simulation software. The study includes a comprehensive analysis of
band alignment, pre-optimization screening, and performance optimization
through the adjustment of absorber thickness, doping levels, and defect
densities. Additionally, the temperature sensitivity and the substitution of
the FTO layer with ITO, IZO, and MZO were also investigated. The simulation
results indicated that Sb2Se3 and CZTSSe achieved the highest efficiencies of
41.00% and 41.19%, respectively. Furthermore, MZO was identified as a strong
candidate for replacing FTO, maintaining consistent performance across all
absorber types analyzed. Overall, this study provides a comparative framework
for the material selection within layered PSC architectures and significantly
contributes to the advancement of stable, efficient, and lead-free photovoltaic
technologies.

</details>


### [289] [A Haldane-Anderson Hamiltonian Model for Hyperthermal Hydrogen Scattering from a Semiconductor Surface](https://arxiv.org/abs/2508.13360)
*Xuexun Lu,Nils Hertl,Reinhard J. Maurer*

Main category: cond-mat.mtrl-sci

TL;DR: 与金属表面不同，半导体上的氢原子散射仅当 the projectile kinetic energy exceed the bandgap of the substrate 时才表现出强吸附-表面能量转移。电子摩擦无法描述这种现象。本研究使用 Haldane-Anderson 哈密顿量模型对 c(2x8)Ge(111) 上的氢原子气-表面散射进行了第一性原理参数化，并进行了独立的电子表面跳跃和 Ehrenfest 动力学模拟。结果表明，独立电子表面跳跃模拟定性地同意实验观察，即只有当初始动能超过表面带隙时，才会发生非绝热能量耗散。


<details>
  <summary>Details</summary>
Motivation: 与金属表面不同，半导体上的氢原子散射仅当 the projectile kinetic energy exceed the bandgap of the substrate 时才表现出强吸附-表面能量转移。电子摩擦无法描述这种现象。

Method: 首先，我们对 c(2x8)Ge(111) 上的氢原子气-表面散射的简单 Haldane-Anderson 哈密顿量模型进行了第一性原理参数化。然后，我们在此模型上执行了独立的电子表面跳跃和 Ehrenfest 动力学模拟。

Result: 独立电子表面跳跃模拟定性地同意实验观察，即只有当初始动能超过表面带隙时，才会发生非绝热能量耗散。我们还表明，非绝热能量损失会影响有待实验测量的粘附性。

Conclusion: 独立电子表面跳跃模拟定性地同意实验观察，即只有当初始动能超过表面带隙时，才会发生非绝热能量耗散。

Abstract: Collisions of atoms and molecules with metal surfaces create electronic
excitations in the metal, leading to nonadiabatic energy dissipation, inelastic
scattering, and sticking. Mixed quantum-classical molecular dynamics simulation
methods, such as molecular dynamics with electronic friction, are able to
capture nonadiabatic energy loss during dynamics at metal surfaces. Hydrogen
atom scattering on semiconductors, on the other hand, exhibits strong
adsorbate-surface energy transfer only when the projectile kinetic energy
exceeds the bandgap of the substrate. Electronic friction fails to describe
this effect. Here, we report a first-principles parameterization of a simple
Haldane-Anderson Hamiltonian model of hydrogen atom gas-surface scattering on
$c(2\times8)$Ge(111), for which hyperthermal scattering experiments have been
reported. We subsequently perform independent electron surface hopping and
Ehrenfest dynamics simulations on this model. Whereas mean-field dynamics yield
weak nonadiabatic energy loss that is independent of the initial kinetic
energy, independent electron surface hopping simulations qualitatively agree
with the experimental observation that nonadiabatic energy dissipation only
occurs if the initial kinetic energy exceeds the bandgap of the surface. We
further show how nonadiabatic energy loss affects sticking, which is yet to be
experimentally measured.

</details>


### [290] [Dislocation-mediated short-range order evolution during thermomechanical processing](https://arxiv.org/abs/2508.13484)
*Mahmudul Islam,Killian Sheriff,Rodrigo Freitas*

Main category: cond-mat.mtrl-sci

TL;DR: 这项研究的重点是热机械加工如何影响具有复杂成分的合金的微观结构。具体来说，它研究了温度和应变率如何影响称为短程有序（SRO）的现象。通过大规模原子模拟，研究人员发现这些参数会系统地改变 SRO 的量级和化学性质。他们确定了两个区域：一个低温区域，其 SRO 对应变率不敏感；以及一个高温区域，其 SRO 对应变率敏感，其中 SRO 的形成被加速。研究结果为理解和预测合金的微观结构提供了有价值的见解。


<details>
  <summary>Details</summary>
Motivation: 为了探索热机械加工中由位错介导的短程有序演变与加工参数之间的联系。

Method: 通过使用机器学习势和信息论度量进行大规模原子模拟，研究了温度和应变率如何通过竞争创建（Γ）和湮灭（λ）速率来控制短程有序。

Result: 研究确定了短程有序的量级和化学特征如何随温度和应变率系统地变化，并识别了两个不同的区域：低温区域和高温区域，在高温区域中，减少的位错密度和增加的螺钉特征会放大化学偏差并加速短程有序的形成。

Conclusion: 该研究建立了处理参数、位错物理学和化学成分复杂的合金中的短程有序演变之间的机制和预测联系。

Abstract: Thermomechanical processing alters the microstructure of metallic alloys
through coupled plastic deformation and thermal exposure, with dislocation
motion driving plasticity and microstructural evolution. Our previous work
showed that the same dislocation motion both creates and destroys chemical
short-range order (SRO), driving alloys into far-from-equilibrium SRO states.
However, the connection between this dislocation-mediated SRO evolution and
processing parameters remains largely unexplored. Here, we perform large-scale
atomistic simulations of thermomechanical processing of equiatomic TiTaVW to
determine how temperature and strain rate control SRO via competing creation
($\Gamma$) and annihilation ($\lambda$) rates. Using machine learning
interatomic potentials and information-theoretic metrics, we quantify that the
magnitude and chemical character of SRO vary systematically with these
parameters. We identify two regimes: a low-temperature regime with weak
strain-rate sensitivity, and a high-temperature regime in which reduced
dislocation density and increased screw character amplify chemical bias and
accelerate SRO formation. The resulting steady-state SRO is
far-from-equilibrium and cannot be produced by equilibrium thermal annealing.
Together, these results provide a mechanistic and predictive link between
processing parameters, dislocation physics, and SRO evolution in chemically
complex alloys.

</details>


### [291] [Expanding the search space of high entropy oxides and predicting synthesizability using machine learning interatomic potentials](https://arxiv.org/abs/2508.13389)
*Oliver A. Dicks,Solveig S. Aamlid,Alannah M. Hallas,Joerg Rottler*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种基于机器学习势能的计算方法，用于预测高熵氧化物（HEOs）的可合成性，以加速其发现过程。通过熵和焓描述符来筛选候选物，并成功预测了新的高熵氧化物体系。


<details>
  <summary>Details</summary>
Motivation: 高熵氧化物（HEOs）具有巨大的化学成分空间潜力，但新化合物的发现过程缓慢且依赖于实验试错。本研究旨在通过机器学习势能来加速这一过程。

Method: 提出了一种有效的方法，利用机器学习势能来预测高熵氧化物的可合成性。通过识别晶体结构和元素，构建随机单胞，然后进行结构弛豫。基于阳离子能量方差（熵描述符）和混合焓（焓描述符）来区分有前景的候选物。

Result: 将该方法应用于四价高熵氧化物，并通过与替代描述符和DFT计算的比较来验证其有效性。在14种元素和三种晶体结构中，该方法成功识别了唯一已知的α-PbO2结构中的稳定四组分高熵氧化物，并预测了几种新的五组分候选体系。

Conclusion: 该方法可直接应用于新的元素和结构集，从而加速新型高熵氧化物的发现。

Abstract: We propose an efficient computational methodology for predicting the
synthesizability of high entropy oxides (HEOs) in a large space of possible
candidate compounds. HEOs are a growing field with an enormous potential
chemical composition space, and yet the discovery of new HEOs is slow and
driven by experimental trial-and-error. In this work, we attempt to speed up
this process by using a machine learned interatomic potential offering
DFT-level accuracy. Our methodology starts by identifying a set of crystal
structures and elements for screening, building a large random unit cell of
each composition and structure, then relaxing this structure. The most
promising candidates are distinguished based on the variance of the individual
cation energies, which we introduce as our entropy descriptor, and the enthalpy
of mixing, which is used as the enthalpy descriptor. The approach is applied to
tetravalent HEOs, and its validity is confirmed by comparison to alternative
descriptors and DFT calculations for a set of 7 elements. The search is then
extended to a set of 14 elements and three crystal structures, where it
successfully identifies the only known stable 4-component HEO in the
$\alpha$-PbO$_2$ structure, as well as predicting several new 5-component
candidate systems. This approach can straightforwardly be applied to new sets
of elements and structures, allowing for the accelerated discovery of new HEOs.

</details>


### [292] [Overcoming Quantum Resistivity Scaling in Nanoscale Interconnects Using Delafossite PdCoO2](https://arxiv.org/abs/2508.13573)
*Seoung-Hun Kang,Youngjun Lee,Sangmoon Yoon,JongMok Ok,Mina Yoon,Ho Nyung Lee,Young-Kyun Kwon*

Main category: cond-mat.mtrl-sci

TL;DR: PdCoO2 在亚 7 nm 范围内优于 Cu，在量子限制下保持接近体块的电导率，这使其成为下一代纳米电子互连的可行选择。


<details>
  <summary>Details</summary>
Motivation: 为了解决在亚 7 nm 范围内 Cu 互连中量子限制电阻率加剧的问题，评估了 PdCoO2 并将其与 Cu 进行基准测试，以识别在限制下维持导电性的机制。

Method: 使用动量分辨弛豫时间形式主义，将 k 和能量分辨速度、寿命和平均自由程 (MFP) 与薄膜和导线的厚度相关电阻率联系起来。

Result: PdCoO2 表现出准二维传输，具有高面内速度和强各向异性 MFP（在 EF 附近面内为 15 nm，层间为 3 nm），而 Cu 表现出各向同性 22 nm MFP。在相同的边界条件下，PdCoO2 显示出受抑制的边界散射，并且电阻率从体块到亚 30 nm 的增加速度大大减慢，保持接近体块的电导率，并在 2 nm 时保持可行。

Conclusion: PdCoO2 是一种可扩展的互连材料，在量子限制下优于 Cu，并提供了一个用于筛选下一代纳米电子互连的层状导体定量框架。

Abstract: Continued scaling into the sub 7 nm regime exacerbates quantum limited
resistivity in Cu interconnects. We evaluated layered PdCoO2 and explicitly
benchmarked it against Cu to identify mechanisms that maintain conductivity
under confinement. Using a momentum resolved relaxation time formalism derived
from the conductivity tensor, we link k and energy resolved velocities, life
times, and mean free paths (MFPs) to thickness dependent resistivity for films
and wires. PdCoO2 exhibits quasi 2D transport with high inplane velocities and
strongly anisotropic MFPs (15 nm inplane, 3 nm outofplane near EF), whereas Cu
shows an isotropic 22 nm MFP. Under identical boundary conditions including a
realistic 2 nm liner/diffusion barrier for Cu, PdCoO2 displays suppressed
boundary scattering and a much slower resistivity increase from bulk down to
sub 30 nm, preserving near bulk conductivity and remaining viable at 2 nm.
Thickness trends reveal dual slope changes in PdCoO2 (35 nm and 7 nm) set by
anisotropic MFPs, contrasting with the single characteristic scale of Cu (40
nm). The calculated bulk values and scaling curves track available measurements
for both materials. These results establish PdCoO2 as a scalable interconnect
that outperforms Cu under quantum confinement and provide a quantitative
framework to screen layered conductors for next generation nanoelectronic
interconnects.

</details>


### [293] [Observation of relativistic domain wall motion in amorphous ferrimagnets](https://arxiv.org/abs/2508.13950)
*Pietro Diona,Luca Maranzana,Sergey Artyukhin,Giacomo Sala*

Main category: cond-mat.mtrl-sci

TL;DR: 研究发现在非晶态亚铁磁合金（如 GdFeCo）中存在畴壁的相对论区域，其最大速度可达 2 km/s，为高速磁性器件提供了新材料平台。


<details>
  <summary>Details</summary>
Motivation: 在非晶态稀土-过渡金属亚铁磁体中，尽管预期会表现出相对论效应（由于其超快的磁动力学），但尚未有证据报告。本研究旨在填补这一空白，并探索这些材料在磁性器件中的潜力。

Method: 通过实验观察和数据分析，证明非晶态亚铁磁合金（特别是 GdFeCo）可以实现畴壁的相对论区域。

Result: 在 GdFeCo 材料中观察到了电流引起的畴壁速度饱和现象，该现象表明存在一个最大自旋波速度，约为 2 km/s。这证明了相对论动力学在稀土-过渡金属亚铁磁体中的存在。

Conclusion: 本研究表明，在易于工程化的非晶态亚铁磁合金中可以实现相对论区域。在 GdFeCo 中，我们观察到电流引起的畴壁速度饱和，这表明最大自旋波速度约为 2 km/s。我们的观察表明，相对论动力学不仅存在于亚铁磁石榴石中，也存在于稀土-过渡金属亚铁磁体中，这为未来工作在极限速度极限的磁性器件提供了强大的材料平台。

Abstract: Domain walls in magnetic materials are sine-Gordon solitons characterized by
relativistic kinematics, with the maximum spin-wave group velocity setting a
limit for the domain wall speed and hence the highest operation frequency of
magnetic devices. This relativistic regime has been observed only in
crystalline iron-garnet ferrimagnets but is in general expected in many
magnetic materials. In particular, amorphous rare-earth -- transition metal
ferrimagnets should exhibit relativistic effects because of their ultrafast
magnetic dynamics. However, no evidence for these effects has been reported in
these technologically relevant materials. Here, we show that the relativistic
regime can be attained in easy-to-engineer amorphous ferrimagnetic alloys. In
GdFeCo we observe a saturation of the current-induced domain wall velocity that
is indicative of a maximum spin-wave speed of the order of 2 km/s. Our
observations indicate that relativistic dynamics are not exclusive to
ferrimagnetic garnets but also exist in rare-earth -- transition-metal
ferrimagnets, which provide a robust material platform for future magnetic
devices operating at the ultimate speed limit.

</details>


### [294] [Deterministic N'eel vector switching of altermagnets via magnetic multipole torque](https://arxiv.org/abs/2508.13585)
*Seungyun Han,Kyoung-Whan Kim,Hyun-Woo Lee,Suik Cheon*

Main category: cond-mat.mtrl-sci

TL;DR: Altermagnets材料在自旋电子器件领域展现出巨大潜力，但实现其单磁畴构型仍具挑战。本研究提出的磁八极矩注入方法，通过在Altermagnet/法拉第金属双层结构中施加面内电流，能够有效地实现N'eel矢量的无磁场确定性开关，并将多畴结构转变为单畴，为Altermagnets的器件应用和基础研究铺平了道路。


<details>
  <summary>Details</summary>
Motivation: 为实现Altermagnets在下一代自旋电子器件中的应用，需要解决其单磁畴构型难以实现的技术挑战。

Method: 通过理论计算，研究向d波Altermagnets注入磁八极矩，该过程可以通过向Altermagnet/法拉第金属双层结构施加面内电流实现。

Result: 研究表明，磁八极矩注入产生的扭矩能够实现Altermagnets的N'eel矢量在无磁场下的确定性开关，并将多畴结构转变为单畴结构。

Conclusion: Altermagnets的单磁畴构型实现是其器件应用的关键，该研究提出的磁八极矩注入方法可以实现无磁场驱动的确定性开关，并将多畴构型转变为单畴，适用于多种Altermagnets，推动了其器件应用和基础研究，并证明了磁多极矩电流的有效性。

Abstract: Altermagnets have recently emerged as promising materials for next-generation
spintronic devices. For their device applications, realizing a single-domain
configuration is essential but remains challenging. We theoretically consider
injecting magnetic multipoles into altermagnets, which can be achieved by
applying an in-plane current to an altermagnet/normal metal bilayer. We
demonstrate for $d$-wave altermagnets that the torque generated by the magnetic
octupole injection can achieve magnetic-field-free deterministic switching of
the altermagnets' N\'eel vector and transform their multidomain configurations
into a single domain. This method allows the switching in diverse altermagnets,
thereby facilitating their device applications and fundamental studies. This
work also exemplifies the usefulness of magnetic multipole currents.

</details>


### [295] [Unlocking reversible and nonvolatile anomalous valley Hall control through multiferroic van der Waals heterostructures](https://arxiv.org/abs/2508.13614)
*Ankita Phutela,Saswata Bhattacharya*

Main category: cond-mat.mtrl-sci

TL;DR: 通过VSSe/Al2S3异质结构，利用铁电极化实现AVH效应的非易失性电调控和谷极化反转，有望用于开发可开关、节能的谷电子器件。


<details>
  <summary>Details</summary>
Motivation: 为了实现对反常谷霍尔（AVH）效应的外部控制，以推进谷电子学应用，同时解决现有方法存在的不可逆或易失性等局限性。

Method: 采用第一性原理密度泛函理论计算，研究了由铁磁单层VSSe和铁电单层Al2S3组成的异质结构。

Result: 证明了VSSe/Al2S3异质结构可以通过外加电场反转Al2S3的极化，从而可逆且非易失性地调控VSSe的谷输运特性，实现了谷极化的反转，提供了对谷依赖现象的双重控制。

Conclusion: 本研究提出了利用多铁性范德华异质结构实现反常谷霍尔（AVH）效应的非易失性电调控的通用策略，为谷电子学应用提供了有前景的途径。

Abstract: Achieving external control over the anomalous valley Hall (AVH) effect is
essential for advancing valleytronic applications. However, many of the
existing approaches suffer from limitations such as irreversibility or
volatility. In this work, we propose a general strategy for enabling
nonvolatile electrical tuning of the AVH effect by utilizing multiferroic van
der Waals heterostructures. Using first-principles density functional theory
calculations, we demonstrate that a heterostructure composed of a ferromagnetic
monolayer VSSe and a ferroelectric monolayer Al$_2$S$_3$ permits fine control
of valley transport properties. The AVH response in VSSe can be reversibly and
nonvolatility switched by reversing the polarization of Al$_2$S$_3$ via an
applied electric field. This ferroelectric mechanism ensures a stable valley
state even without continuous energy input. Furthermore, the valley
polarization can also be inverted through the same polarization switching
process, providing a dual degree of control over valley-dependent phenomena.
These findings establish a promising pathway toward intrinsically switchable
and energy-efficient valleytronic devices.

</details>


### [296] [Evidence for single variant in altermagnetic RuO2(101) thin films](https://arxiv.org/abs/2508.13720)
*Cong He,Zhenchao Wen,Jun Okabayashi,Yoshio Miura,Tianyi Ma,Tadakatsu Ohkubo,Takeshi Seki,Hiroaki Sukegawa,Seiji Mitani*

Main category: cond-mat.mtrl-sci

TL;DR: 成功制备了单取向磁性RuO2(101)薄膜，并验证了其在自旋电子学中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 为了实现磁性材料在自旋电子器件中的潜力，需要制备单取向磁性薄膜。

Method: 通过X射线衍射、原子分辨率透射电子显微镜和X射线磁性线性二色性进行结构分析，并辅以第一性原理密度泛函理论计算。

Result: 成功制备了单取向磁性RuO2(101)薄膜，并通过实验观察到其在RuO2(101)/CoFeB双层结构中表现出受单取向影响的自旋劈裂磁阻效应。

Conclusion: 该工作展示了单取向磁性薄膜的制备，为探索其在自旋电子学中的应用奠定了基础。

Abstract: Altermagnetism presents intriguing possibilities for spintronic devices due
to its unique combination of strong spin-splitting and zero net magnetization.
However, realizing its full potential hinges on fabricating single-variant
altermagnetic thin films. In this work, we present definitive evidence for the
formation of single-variant altermagnetic RuO2(101) thin films with fully
epitaxial growth on Al2O3(1-102) r-plane substrates, confirmed through rigorous
structural analyses using X-ray diffraction, atomic-resolution transmission
electron microscopy and X-ray magnetic linear dichroism. The mutual
correspondence of the occupancy of oxygen atoms on the surfaces of
RuO2(101)[010] and Al2O3(1-102)[11-20] plays a decisive role in the formation
of the single-variant RuO2, which is also supported by our first-principles
density functional theory calculations. We further observed spin-splitting
magnetoresistance in the single-variant RuO2(101)/CoFeB bilayers, highlighting
the characteristic effect of single variant on spin transport. The
demonstration of single-variant RuO2(101) films marks a significant advancement
in the field of altermagnetism and paves the way for exploring their potential
applications.

</details>


### [297] [Large-scale cooperative sulfur vacancy dynamics in two-dimensional MoS2 from machine learning interatomic potentials](https://arxiv.org/abs/2508.13790)
*Aaron Flötotto,Benjamin Spetzler,Rose von Stackelberg,Martin Ziegler,Erich Runge,Christian Dreßler*

Main category: cond-mat.mtrl-sci

TL;DR: 机器学习势能模拟揭示了MoS2单层中硫空位的形成和传输机制，解释了实验观察到的线缺陷，并比较了两种MLIP框架。


<details>
  <summary>Details</summary>
Motivation: 研究了MoS2单层中扩展的硫空位与催化活性和忆阻行为的关联，以及其形成机制。

Method: 使用机器学习势能（MLIP）进行纳秒级分子动力学模拟，揭示了空位的协同传输机制，包括空位向任意尺寸团簇的结合。

Result: 揭示了空位的协同传输机制，包括空位向任意尺寸团簇的结合，并为实验观察到的辐照诱导空位模式（特别是线缺陷）提供了原子尺度的解释。对两种MLIP框架（即时学习的高斯近似势和等变基础模型的微调）的性能进行了比较。

Conclusion: MLIPs能够解释实验中观察到的与硫空位相关的线缺陷形成，并为理解MoS2单层中的各种空位现象提供了基础。

Abstract: The formation of extended sulfur vacancies in MoS2 monolayers is closely
associated with catalytic activity and may also be the basis for its memristive
behavior. Nanosecond-scale molecular dynamics simulations using machine
learning interatomic potentials (MLIPs) reveal key mechanisms of cooperative
vacancy transport, including incorporation of vacancies into clusters of
arbitrary size. The simulations provide a coherent atomistic explanation for
irradiation-induced vacancy patterns observed experimentally, especially the
formation of line defects spanning tens of nanometers. Results and performance
are compared of two MLIP frameworks: (i) on-the-fly learning with Gaussian
approximation potential, and (ii) fine-tuning of an equivariant foundation
model.

</details>


### [298] [Elementary Monte Carlo model of the anisotropic recrystallization and antiripening under intensive stirring and high supersaturations](https://arxiv.org/abs/2508.13799)
*Serhii Abakumov,Eugen Rabkin,Andriy Gusak*

Main category: cond-mat.mtrl-sci

TL;DR: Fibrous oxide production via stirring analyzed using driven systems approach. A Monte Carlo simulation shows clusters elongate/dissolve, with overall size and energy increasing, unlike typical ripening.


<details>
  <summary>Details</summary>
Motivation: The paper aims to analyze the production of fibrous oxides, specifically V2O5, through intensive stirring in water using the driven systems approach.

Method: A simplified Monte Carlo scheme is proposed within the TLK model, incorporating anisotropy and additional athermal detachment probabilities to simulate crystal evolution.

Result: The simulation shows that individual clusters elongate or dissolve, and the ensemble of clusters decreases in number but increases in mean length and total surface energy, exhibiting behavior contrary to common ripening.

Conclusion: The study suggests that individual clusters elongate in a steady-state or dissolve, while the ensemble of clusters experiences a decreasing number but growing mean length and total surface energy, diverging from common ripening.

Abstract: Known method of fibrous oxides production (first of all, V2O5) by intensive
stirring in water is treated in the frame of driven systems approach developed
in 80s by Georges Martin et al for systems under irradiation or severe plastic
deformation. Instead of ballistic diffusion, the ballistic detachments of atoms
from the oxide surface under stirring are introduced. Simplified Monte Carlo
scheme is suggested for crystal evolution within TLK model, taking into account
anisotropy and additional athermal detachment probabilities. Individual cluster
in limited volume becomes elongated in steady-state or dissolve. For the
ensemble of clusters, the number is decreasing (as in common ripening), but the
mean length of fibers grows, as well as the total surface energy (contrary to
common ripening).

</details>


### [299] [Extraction of the self energy and Eliashberg function from angle resolved photoemission spectroscopy using the \textsc{xARPES} code](https://arxiv.org/abs/2508.13845)
*Thomas P. van Waas,Christophe Berthod,Jan Berges,Nicola Marzari,J. Hugo Dil,Samuel Poncé*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究提出了一种新的方法，用于从具有弯曲色散的谱函数中提取自能量，并在 SrTiO$_3$ 和 Li 掺杂石墨烯的实验数据上进行了验证。


<details>
  <summary>Details</summary>
Motivation: 现有的谱函数分解方法依赖于带的线性化和手动赋值，而本研究旨在提供一种可以一致地提取弯曲色散的自能量的方法。

Method: 本研究扩展了最大熵法，通过贝叶斯推断进行 Eliashberg 函数提取，并优化了描述色散以及电子-电子和电子-杂质相互作用的参数。

Result: 该方法在模型数据上与现有方法进行了比较，并在 SrTiO$_3$ 上的二维电子液体和 Li 掺杂石墨烯的实验数据上进行了演示，在 Li 掺杂石墨烯的两种 Eliashberg 函数之间获得了前所未有的吻合。

Conclusion: 本研究提出了一种新的方法，可以对具有弯曲色散的谱函数进行一致的自能量提取，并通过 	extsc{xARPES} Python 代码实现了这些功能。

Abstract: Angle-resolved photoemission spectroscopy is a powerful experimental
technique for studying anisotropic many-body interactions through the electron
spectral function. Existing attempts to decompose the spectral function into
non-interacting dispersions and electron-phonon, electron-electron, and
electron-impurity self-energies rely on linearization of the bands and manual
assignment of self-energy magnitudes. Here, we show how self-energies can be
extracted consistently for curved dispersions. We extend the maximum-entropy
method to Eliashberg-function extraction with Bayesian inference, optimizing
the parameters describing the dispersions and the magnitudes of
electron-electron and electron-impurity interactions. We compare these novel
methodologies with state-of-the-art approaches on model data, then demonstrate
their applicability with two high-quality experimental data sets. With the
first set, we identify the phonon modes of a two-dimensional electron liquid on
TiO$_2$-terminated SrTiO$_3$. With the second set, we obtain unprecedented
agreement between two Eliashberg functions of Li-doped graphene extracted from
separate dispersions. We release these functionalities in the novel Python code
\textsc{xARPES}.

</details>


### [300] [Atomistic mechanisms of phase transitions in all-temperature barocaloric material KPF$_6$](https://arxiv.org/abs/2508.13862)
*Jiantao Wang,Yi-Chi Zhang,Yan Liu,Hongkun Deng,Mingfeng Liu,Yan Sun,Bing Li,Xing-Qiu Chen,Peitao Liu*

Main category: cond-mat.mtrl-sci

TL;DR: KPF_6 通过压力诱导的相变实现全温度巴氏热效应，其机制涉及氟的取向无序、非谐性和协同的八面体旋转与晶格调制。


<details>
  <summary>Details</summary>
Motivation: 传统的巴氏热材料工作温度范围有限，而 KPF_6 通过压力驱动的相变实现了卓越的全温度巴氏热效应（BCE）。

Method: 通过第一性原理计算和机器学习势能加速分子动力学模拟，阐明了 KPF_6 的相变机制。

Result: 确定了四种不同的相：室温下的立方（C）塑性晶体（具有显著的氟取向无序和非谐性）、中间温度下的单斜（M-II）相（氟取向无序减少）、低温下的单斜（M-I）相（氟取向无序受抑制）以及压力下的全有序菱面（R）相。所有 C、M-II 和 M-I 相在压力下均转变为 R 相，这由协同的 PF_6 八面体旋转和晶格调制驱动。这些压力诱导的相变导致在宽温度范围内产生持续的等温熵变，解释了实验观察到的全温度 BCE。混合泛函计算表明，所有相均表现出宽带隙绝缘行为。

Conclusion: 这项工作揭示了 KPF_6 中氟的取向无序、晶格振动非谐性与相变之间的相互作用，为设计具有宽工作温度范围的巴氏热效应（BCE）材料提供了重要见解。

Abstract: Conventional barocaloric materials typically exhibit limited operating
temperature ranges. In contrast, KPF$_6$ has recently been reported to achieve
an exceptional all-temperature barocaloric effect (BCE) via pressure-driven
phase transitions. Here, we elucidate the atomistic mechanisms underlying the
phase transitions through first-principles calculations and machine-learning
potential accelerated molecular dynamics simulations. We identify four distinct
phases: the room-temperature cubic (C) plastic crystal characterized by strong
fluorine orientational disorder (FOD) and anharmonicity, the
intermediate-temperature monoclinic (M-II) phase with decreasing FOD, the
low-temperature monoclinic (M-I) phase with suppressed FOD, and the fully
ordered rhombohedral (R) phase under pressure. Phonon calculations confirm the
dynamic stability of the M-II, M-I, and R phases at 0 K, whereas the C phase
requires thermal fluctuations for stabilization. Under pressure, all the C,
M-II, and M-I phases transform to the R phase, which are driven by cooperative
PF$_6$ octahedral rotations coupled with lattice modulations. These
pressure-induced phase transitions result in persistent isothermal entropy
changes across a wide temperature range, thereby explaining the experimentally
observed all-temperature BCE in this material. Hybrid functional calculations
reveal wide-bandgap insulating behavior across all phases. This work deciphers
the interplay between FOD, anharmonicity, and phase transitions in KPF$_6$,
providing important insights for the design of BCE materials with broad
operational temperature spans.

</details>


### [301] [Piezomagnetism-driven magnetoelectric coupling in altermagnetic multiferroic K3Cr2F7](https://arxiv.org/abs/2508.13952)
*Ying Zhou,Hui-Min Zhang,Cheng-Ao Ji,Hongjun Xiang,Shuai Dong,James M. Rondinelli,Xue-Zeng Lu*

Main category: cond-mat.mtrl-sci

TL;DR: 提出了一种识别多铁性的设计规则，在K3Cr2F7中实现了铁电-铁电相变和磁序转变，为磁电耦合和阿尔特磁材料功能性研究提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探索在实空间控制阿尔特磁材料的磁性，并实现强磁电耦合。

Method: 通过分析Jahn-Teller畸变与氧八面体旋转对反演对称性的影响，提出识别n=2 Ruddlesden-Popper卤化物多铁性的设计规则，并以K3Cr2F7和KAg2Cu2Cl7为模型材料进行验证。

Result: 提出了识别n=2 Ruddlesden-Popper卤化物多铁性的设计规则。在K3Cr2F7中观察到Jahn-Teller畸变与氧八面体旋转协同作用打破反演对称性，并实现了铁电-铁电相变。发现了阿尔特磁序向反铁磁序的转变，以及应力/压力工程诱导的弱铁磁性变化。

Conclusion: 该研究提出了一个识别n=2 Ruddlesden-Popper卤化物多铁性的设计规则，并以K3Cr2F7和KAg2Cu2Cl7为例进行了验证。研究发现，Jahn-Teller畸变与氧八面体旋转协同作用可以打破反演对称性，导致K3Cr2F7发生铁电-铁电相变。在外延/压力工程下，铁电相的阿尔特磁自旋序转变为铁电相的常规反铁磁序，并伴随着较强的弱铁磁性变化。该研究为实现多铁性材料中的强磁电耦合提供了理论基础，并揭示了阿尔特磁材料的更多功能性。

Abstract: Ferroelectric control of altermagnetism in momentum space has been studied
widely, while the control of magnetism in real space of altermagnets are still
rare. We present a design rule to identify multiferroicity in n=2
Ruddlesden-Popper halides. Our results show that a Jahn-Teller distortion can
cooperate with oxygen octahedral rotations to break inversion symmetry, which
we demonstrate in K3Cr2F7 and cation-ordered KAg2Cu2Cl7, and leads to a
ferrielectric-to-ferroelectric phase transition in K3Cr2F7. Altermagnetic spin
order in the ferrielectric phase of K3Cr2F7 transforms into a conventional
antiferromagnetic order in the ferroelectric phase, at which strain/pressure
engineered sizable changes of weak ferromagnetism can occur. Our study is not
only conducive to realize strong magnetoelectric coupling in multiferroics, but
also reveals more functionalities in altermagnetic materials.

</details>


### [302] [A first-principles theoretical study on two-dimensional MX and MX$_2$ metal halides: bandgap engineering, magnetism, and catalytic descriptors](https://arxiv.org/abs/2508.13955)
*Yu-Hsiu Lin,Daniel Maldonado-Lopez,Jose L. Mendoza-Cortes*

Main category: cond-mat.mtrl-sci

TL;DR: 本研究利用第一性原理计算，构建了60种MX和MX2金属卤化物的数据库，揭示了维度和化学成分对其电子、光电、催化和磁性性质的影响，为相关领域提供了有价值的资源和潜在应用材料。


<details>
  <summary>Details</summary>
Motivation: 为了全面理解金属卤化物（特别是MX和MX2化合物）的结构和电子行为，尤其是它们从块状到低维形态的性质演变，本研究旨在解决现有理解的局限性。

Method: 本研究采用第一性原理计算，并使用HSE06-D3杂化泛函进行密度泛函理论（DFT）计算，以高精度预测材料性质。研究对象为60种MX和MX2金属卤化物，考察了其块状和二维片状结构下的性质。

Result: 研究构建了一个包含60种MX和MX2金属卤化物（块状和片状）的数据库，详细说明了它们的结构和电子性质。结果显示，这些材料多为半导体，带隙在0-9 eV之间。维度降低导致电子性质变化，9种材料出现间接-直接带隙转变。研究还分析了化学成分对带隙的影响，并评估了催化和磁性性质。该数据库为相关领域的未来研究和技术发展提供了指导。

Conclusion: 该研究通过第一性原理计算构建了60种MX和MX2金属卤化物（包括块状和二维片状结构）的数据库，详细阐述了它们的结构和电子性质。计算结果表明，这些材料主要是半导体，带隙范围为0至9 eV。维度降低（从块状到片状）会导致电子性质发生显著变化，其中9种材料表现出从间接跃迁到直接跃迁的带隙转变，这增强了它们在能量转换方面的应用潜力。此外，研究还考察了化学成分对带隙变化的影响，并系统评估了这些金属卤化物的催化和磁性性质。这些发现不仅揭示了先前未充分研究的MX和MX2金属卤化物，还确定了在电子、光电、催化和自旋电子学领域具有应用前景的候选材料。该数据库为未来低维材料的研究和技术发展提供了宝贵的资源。

Abstract: Metal halides, particularly MX and MX$_2$ compounds (where M represents metal
elements and X = F, Cl, Br, I), have attracted significant interest due to
their diverse electronic and optoelectronic properties. However, a
comprehensive understanding of their structural and electronic behavior,
particularly the evolution of these properties from bulk to low-dimensional
forms, remains limited. To address this gap, we performed first-principles
calculations to develop a database of 60 MX and MX$_2$ metal halides, detailing
their structural and electronic properties in both bulk and slab
configurations. Calculations were performed using the advanced
\texttt{HSE06-D3} hybrid functional for density functional theory (DFT),
ensuring high precision in predicting material properties despite the
associated computational cost. The results reveal that these materials are
predominantly semiconductors, but their bandgaps range from 0 to 9 eV. A
detailed analysis of the transition from bulk to slab structures highlights
notable shifts in electronic properties, including bandgap modifications. Upon
dimensional reduction, 9 materials exhibit an indirect-to-direct bandgap
transition, enhancing their potential for energy conversion. Beyond structural
dimensionality, the influence of chemical composition on bandgap variations was
also examined. To further assess their practical applicability, the catalytic
and magnetic properties of these metal halides were systematically evaluated.
These findings not only illuminate previously underexplored MX and MX$_2$ metal
halides but also identify promising candidates for electronic, optoelectronic,
catalytic and spintronic applications. This database serves as a valuable
resource for guiding future research and technology development in
low-dimensional materials.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [303] [Diff-MSM: Differentiable MusculoSkeletal Model for Simultaneous Identification of Human Muscle and Bone Parameters](https://arxiv.org/abs/2508.13303)
*Yingfan Zhou,Philip Sanderink,Sigurd Jager Lemming,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了一种名为Diff-MSM的新方法，利用自动微分技术，无需测量关节力矩即可识别肌肉骨骼模型参数，并在模拟中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高保真个性化肌肉骨骼模型对于模拟物理耦合的人机交互系统行为以及在部署前验证其安全性至关重要，例如在人机协作运输和外骨骼康复应用中。然而，在体（in vivo）测量内部生物力学变量（尤其是关节力矩）的难度，使得识别受试者特定的Hill型肌肉模型参数和骨骼动力学参数极具挑战性。

Method: 提出使用Differentiable MusculoSkeletal Model (Diff-MSM) 结合端到端的自动微分技术，通过可测量的肌肉激活推导关节力矩，最终实现可观察的运动，从而无需直接测量内部关节力矩，即可同时识别肌肉和骨骼参数。

Result: 通过大量的对比模拟，结果表明所提出的Diff-MSM方法在准确估计肌肉参数方面显著优于最先进的基线方法（例如，从均值为真值、标准差为真值10%的正态分布中采样的初始值，最终可实现估计值平均百分比误差低至0.05%）。

Conclusion: 该研究提出的Differentiable MusculoSkeletal Model (Diff-MSM) 能够有效地同时识别肌肉和骨骼参数，并且在模拟中显著优于现有方法，尤其在肌肉参数的精确估计方面。

Abstract: High-fidelity personalized human musculoskeletal models are crucial for
simulating realistic behavior of physically coupled human-robot interactive
systems and verifying their safety-critical applications in simulations before
actual deployment, such as human-robot co-transportation and rehabilitation
through robotic exoskeletons. Identifying subject-specific Hill-type muscle
model parameters and bone dynamic parameters is essential for a personalized
musculoskeletal model, but very challenging due to the difficulty of measuring
the internal biomechanical variables in vivo directly, especially the joint
torques. In this paper, we propose using Differentiable MusculoSkeletal Model
(Diff-MSM) to simultaneously identify its muscle and bone parameters with an
end-to-end automatic differentiation technique differentiating from the
measurable muscle activation, through the joint torque, to the resulting
observable motion without the need to measure the internal joint torques.
Through extensive comparative simulations, the results manifested that our
proposed method significantly outperformed the state-of-the-art baseline
methods, especially in terms of accurate estimation of the muscle parameters
(i.e., initial guess sampled from a normal distribution with the mean being the
ground truth and the standard deviation being 10% of the ground truth could end
up with an average of the percentage errors of the estimated values as low as
0.05%). In addition to human musculoskeletal modeling and simulation, the new
parameter identification technique with the Diff-MSM has great potential to
enable new applications in muscle health monitoring, rehabilitation, and sports
science.

</details>


### [304] [A Surveillance Based Interactive Robot](https://arxiv.org/abs/2508.13319)
*Kshitij Kavimandan,Pooja Mangal,Devanshi Mehta*

Main category: cs.RO

TL;DR: 一个可以从手机或浏览器进行实时视频流式传输和语音响应的移动监控机器人。


<details>
  <summary>Details</summary>
Motivation: 构建一个移动监控机器人，可以从手机或浏览器进行实时视频流式传输和语音响应，以便用户可以监视和控制它。

Method: 该系统使用两个 Raspberry Pi 4 单元：一个带摄像头、麦克风和扬声器的差速驱动底座上的前置单元，以及一个提供实时视频流和运行感知算法的中央单元。FFmpeg 用于发送视频。YOLOv3 用于对象检测以支持导航和事件感知。Python 库用于语音识别、多语言翻译和文本到语音转换。Kinect RGB-D 传感器提供视觉输入和障碍物提示。

Result: 在室内测试中，机器人在 CPU 上以交互式帧速率检测常见对象，可靠地识别命令，并将它们转换为手动控制的动作。

Conclusion: 该设计依赖现成的硬件和开放软件，易于复制。我们讨论了局限性和实际扩展，包括超声波测距数据的传感器融合、GPU 加速以及面部和文本识别。

Abstract: We build a mobile surveillance robot that streams video in real time and
responds to speech so a user can monitor and steer it from a phone or browser.
The system uses two Raspberry Pi 4 units: a front unit on a differential drive
base with camera, mic, and speaker, and a central unit that serves the live
feed and runs perception. Video is sent with FFmpeg. Objects in the scene are
detected using YOLOv3 to support navigation and event awareness. For voice
interaction, we use Python libraries for speech recognition, multilingual
translation, and text-to-speech, so the robot can take spoken commands and read
back responses in the requested language. A Kinect RGB-D sensor provides visual
input and obstacle cues. In indoor tests the robot detects common objects at
interactive frame rates on CPU, recognises commands reliably, and translates
them to actions without manual control. The design relies on off-the-shelf
hardware and open software, making it easy to reproduce. We discuss limits and
practical extensions, including sensor fusion with ultrasonic range data, GPU
acceleration, and adding face and text recognition.

</details>


### [305] [Incremental Generalized Hybrid A*](https://arxiv.org/abs/2508.13392)
*Sidharth Talia,Oren Salzman,Siddhartha Srinivasa*

Main category: cs.RO

TL;DR: IGHA* 是一种新的搜索框架，可以更有效地在大型树上进行搜索，特别是在自动驾驶等领域。它比现有的方法（如 HA*）在规划速度和效率方面都有显著提升，并且在实际应用中也表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决在大规模树结构上高效组织搜索的问题，尤其是在越野自动驾驶等需要实时规划的应用中。

Method: 提出了一种名为增量式广义混合 A*（IGHA*）的框架，该框架动态组织顶点扩展，无需严格的剪枝。

Result: 与优化的 HA* 相比，IGHA* 在各种场景下使用的扩展数量减少了 6 倍。此外，IGHA* 在模拟和真实世界的越野实验中均表现出优于 HA*M 的性能，实现了实时规划。IGHA* 还在复杂动力学条件下实现了快速、鲁棒的规划。

Conclusion: IGHA* 框架能够为车辆规划提供快速、鲁棒的规划，并且在实际应用中表现出色。

Abstract: We address the problem of efficiently organizing search over very large
trees, which arises in many applications ranging from autonomous driving to
aerial vehicles. Here, we are motivated by off-road autonomy, where real-time
planning is essential. Classical approaches use graphs of motion primitives and
exploit dominance to mitigate the curse of dimensionality and prune expansions
efficiently. However, for complex dynamics, repeatedly solving two-point
boundary-value problems makes graph construction too slow for fast kinodynamic
planning. Hybrid A* (HA*) addressed this challenge by searching over a tree of
motion primitives and introducing approximate pruning using a grid-based
dominance check. However, choosing the grid resolution is difficult: too coarse
risks failure, while too fine leads to excessive expansions and slow planning.
We propose Incremental Generalized Hybrid A* (IGHA*), an anytime tree-search
framework that dynamically organizes vertex expansions without rigid pruning.
IGHA* provably matches or outperforms HA*. For both on-road kinematic and
off-road kinodynamic planning queries for a car-like robot, variants of IGHA*
use 6x fewer expansions to the best solution compared to an optimized version
of HA*. In simulated off-road experiments in a high fidelity simulator, IGHA*
outperforms HA*M when both are used in the loop with a model predictive
controller. We demonstrate real-time performance both in simulation and on a
small-scale off-road vehicle, enabling fast, robust planning under complex
dynamics. Code: https://github.com/personalrobotics/IGHAStar

</details>


### [306] [Accelerating Signal-Temporal-Logic-Based Task and Motion Planning of Bipedal Navigation using Benders Decomposition](https://arxiv.org/abs/2508.13407)
*Jiming Ren,Xuan Lin,Roman Mineyev,Karen M. Feigh,Samuel Coogan,Ye Zhao*

Main category: cs.RO

TL;DR: 通过 Benders 分解解决了信号时序逻辑约束下的混合任务和运动规划问题，特别是在双足运动规划的非凸约束下，提高了规划速度。


<details>
  <summary>Details</summary>
Motivation: 解决在信号时序逻辑约束下，混合任务和运动规划问题（特别是双足运动规划）的 NP 难问题，以及传统混合整数规划（MIP）在面对非凸约束（如运动学可达性和步态旋转）时计算复杂度过高的问题。

Method: 提出了一种基于 Benders 分解的方法，将问题分解为主问题（任务规范）和子问题（运动学和动力学可行性检查），并通过迭代切割平面技术来解决。

Result: 实验表明，该方法在求解具有非线性约束的优化问题时，规划速度比替代算法更快。

Conclusion: 该方法通过 Benders 分解优化了混合任务和运动规划问题，在处理非凸约束时比其他算法更快。

Abstract: Task and motion planning under Signal Temporal Logic constraints is known to
be NP-hard. A common class of approaches formulates these hybrid problems,
which involve discrete task scheduling and continuous motion planning, as
mixed-integer programs (MIP). However, in applications for bipedal locomotion,
introduction of non-convex constraints such as kinematic reachability and
footstep rotation exacerbates the computational complexity of MIPs. In this
work, we present a method based on Benders Decomposition to address scenarios
where solving the entire monolithic optimization problem is prohibitively
intractable. Benders Decomposition proposes an iterative cutting-plane
technique that partitions the problem into a master problem to prototype a plan
that meets the task specification, and a series of subproblems for kinematics
and dynamics feasibility checks. Our experiments demonstrate that this method
achieves faster planning compared to alternative algorithms for solving the
resulting optimization program with nonlinear constraints.

</details>


### [307] [Switch4EAI: Leveraging Console Game Platform for Benchmarking Robotic Athletics](https://arxiv.org/abs/2508.13444)
*Tianyu Li,Jeonghwan Kim,Wontaek Kim,Donghoon Baek,Seungeun Rho,Sehoon Ha*

Main category: cs.RO

TL;DR: A new system called Switch4EAI uses video games like Just Dance to test how well robots can move, comparing their performance to humans.


<details>
  <summary>Details</summary>
Motivation: Standardized benchmarks for evaluating robotic athletic performance in real-world settings and in direct comparison to humans are scarce, despite advances in whole-body robot control enabling agile movements.

Method: The system captures, reconstructs, and retargets in-game choreography from motion-sensing console games (e.g., Just Dance on Nintendo Switch) for robotic execution, validated on a Unitree G1 humanoid with an open-source whole-body controller.

Result: The system was validated on a Unitree G1 humanoid, establishing a quantitative baseline for the robot's performance against a human player, demonstrating the feasibility of using commercial games as benchmarks.

Conclusion: Switch4EAI, a low-cost and easily deployable pipeline using motion-sensing console games like Just Dance, can be used to evaluate whole-body robot control policies, establishing a quantitative baseline for robot performance against human players and demonstrating the feasibility of using commercial games as physically grounded benchmarks.

Abstract: Recent advances in whole-body robot control have enabled humanoid and legged
robots to execute increasingly agile and coordinated movements. However,
standardized benchmarks for evaluating robotic athletic performance in
real-world settings and in direct comparison to humans remain scarce. We
present Switch4EAI(Switch-for-Embodied-AI), a low-cost and easily deployable
pipeline that leverages motion-sensing console games to evaluate whole-body
robot control policies. Using Just Dance on the Nintendo Switch as a
representative example, our system captures, reconstructs, and retargets
in-game choreography for robotic execution. We validate the system on a Unitree
G1 humanoid with an open-source whole-body controller, establishing a
quantitative baseline for the robot's performance against a human player. In
the paper, we discuss these results, which demonstrate the feasibility of using
commercial games platform as physically grounded benchmarks and motivate future
work to for benchmarking embodied AI.

</details>


### [308] [CAST: Counterfactual Labels Improve Instruction Following in Vision-Language-Action Models](https://arxiv.org/abs/2508.13446)
*Catherine Glossop,William Chen,Arjun Bhorkar,Dhruv Shah,Sergey Levine*

Main category: cs.RO

TL;DR: 本研究提出了一种新颖的方法，利用视觉语言模型生成反事实标签来增强机器人数据集，解决了当前 VLA 模型在遵循细粒度指令方面的不足，通过增加数据集的语言基础多样性和粒度，显著提高了模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前 VLA 模型在遵循细粒度指令方面存在困难，原因是现有机器人数据集缺乏语义多样性和语言基础，特别是针对相似观测的细粒度任务多样性不足。

Method: 利用视觉语言模型生成反事实标签来增强现有机器人数据集，增加语言基础的多样性和粒度。

Result: 实验证明，反事实重新标记方法在不收集额外数据的情况下，显著提高了 VLA 策略遵循语言指令的能力，在导航任务上成功率提高了 27%，使其能够与最先进的方法竞争。

Conclusion: 该研究通过生成反事实标签来增强机器人数据集，提高了 VLA 模型在细粒度指令遵循方面的能力，使其在导航任务上的成功率提高了 27%。

Abstract: Generalist robots should be able to understand and follow user instructions,
but current vision-language-action (VLA) models struggle with following
fine-grained commands despite providing a powerful architecture for mapping
open-vocabulary natural language instructions to robot actions. One cause for
this is a lack of semantic diversity and language grounding in existing robot
datasets and, specifically, a lack of fine-grained task diversity for similar
observations. To address this, we present a novel method to augment existing
robot datasets by leveraging vision language models to create counterfactual
labels. Our method improves the language-following capabilities of VLAs by
increasing the diversity and granularity of language grounding for robot
datasets by generating counterfactual language and actions. We evaluate the
resulting model's ability to follow language instructions, ranging from simple
object-centric commands to complex referential tasks, by conducting visual
language navigation experiments in 3 different indoor and outdoor environments.
Our experiments demonstrate that counterfactual relabeling, without any
additional data collection, significantly improves instruction-following in VLA
policies, making them competitive with state-of-the-art methods and increasing
success rate by 27% on navigation tasks.

</details>


### [309] [Modeling and Control of AWOISV: A Filtered Tube-Based MPC Approach for Simultaneous Tracking of Lateral Position and Heading Angle](https://arxiv.org/abs/2508.13457)
*Xu Yang,Jun Ni,Hengyang Feng,Feiyu Wang,Tiezhen Wang*

Main category: cs.RO

TL;DR: 本文提出了一种用于全轮全向独立转向车辆（AOWISV）的FT-LTVMPC控制策略，实现了高精度位置和航向跟踪。


<details>
  <summary>Details</summary>
Motivation: 为了解决全轮全向独立转向车辆（AOWISV）的独特运动模式和控制问题。

Method: 提出了一种基于瞬时转动中心位置的理论转向半径角度和侧滑角（θR-βR）表示法，并开发了一个广义v-β-r动力学模型，同时提出了一种滤波管状线性时变MPC（FT-LTVMPC）策略。

Result: 该模型实现了纵向和横向运动的解耦，并能在特定条件下无缝过渡所有运动模式。FT-LTVMPC策略实现了对横向位置和任意航向角的同步跟踪，并对模型不准确和参数不确定性具有鲁棒性。

Conclusion: FT-LTVMPC策略可实现高精度位置和航向跟踪，并具有出色的实时性能。

Abstract: An all-wheel omni-directional independent steering vehicle (AWOISV) is a
specialized all-wheel independent steering vehicle with each wheel capable of
steering up to 90{\deg}, enabling unique maneuvers like yaw and diagonal
movement. This paper introduces a theoretical steering radius angle and
sideslip angle (\( \theta_R \)-\(\beta_R \)) representation, based on the
position of the instantaneous center of rotation relative to the wheel rotation
center, defining the motion modes and switching criteria for AWOISVs. A
generalized \( v\)-\(\beta\)-\(r \) dynamic model is developed with forward
velocity \(v\), sideslip angle \(\beta\), and yaw rate \(r\) as states, and
\(\theta_R\) and \(\beta_R\) as control inputs. This model decouples
longitudinal and lateral motions into forward and rotational motions, allowing
seamless transitions across all motion modes under specific conditions. A
filtered tube-based linear time-varying MPC (FT-LTVMPC) strategy is proposed,
achieving simultaneous tracking of lateral position and arbitrary heading
angles, with robustness to model inaccuracies and parameter uncertainties.
Co-simulation and hardware-in-loop (HIL) experiments confirm that FT-LTVMPC
enables high-precision control of both position and heading while ensuring
excellent real-time performance.

</details>


### [310] [Multi-Robot Navigation in Social Mini-Games: Definitions, Taxonomy, and Algorithms](https://arxiv.org/abs/2508.13459)
*Rohan Chandra,Shubham Singh,Abhishek Jha,Dannon Andrade,Hriday Sainathuni,Katia Sycara*

Main category: cs.RO

TL;DR: 该调查对机器人导航中的“社交迷你游戏”进行了分类，以帮助未来的研究和应用。


<details>
  <summary>Details</summary>
Motivation: 传统的导航方法在 SMG 中表现不佳，这导致了对专门的 SMG 求解器的专注研究。然而，关于 SMG 导航研究的出版物做出了不同的假设，并具有不同的目标函数。这使得建立适当的基线进行比较，以及从业人员查找与其具体应用相关的论文，都变得困难。这种方法的领域表示也给希望在该领域开始研究的新研究人员设置了障碍。因此，SMG 导航研究需要其自身的分类、定义和评估协议。

Method: 该调查通过一个明确定义的统一分类法对 SMG 求解器进行了分类，并对现有方法进行了分类，以指导未来有效的研究。

Result: 该调查提供了 SMG 导航研究的第一次分类，并为该领域提供了急需的统一分类法、定义和评估协议。

Conclusion: 该调查首次使用明确定义的统一分类法对 SMG 求解器进行了分类，并相应地对现有方法进行了分类。

Abstract: The ``Last Mile Challenge'' has long been considered an important, yet
unsolved, challenge for autonomous vehicles, public service robots, and
delivery robots. A central issue in this challenge is the ability of robots to
navigate constrained and cluttered environments (e.g., doorways, hallways,
corridor intersections), often while competing for space with other robots and
humans. We refer to these environments as ``Social Mini-Games'' (SMGs). SMGs
are tightly coupled, high-agency interactions that arise within general
multi-robot navigation (MRN) scenarios. They are identified through certain
distinct characteristics and require specialized metrics to evaluate them.
Traditional navigation approaches designed for MRN do not perform well in SMGs,
which has led to focused research on dedicated SMG solvers (navigation methods
specialized to navigate in SMGs), which has flourished in recent years.
However, publications on SMG navigation research make different assumptions (on
centralized versus decentralized, observability, communication, cooperation,
etc.), and have different objective functions (safety versus liveness). These
assumptions and objectives are sometimes implicitly assumed or described
informally. This makes it difficult to establish appropriate baselines for
comparison in research papers, as well as making it difficult for practitioners
to find the papers relevant to their concrete application. Such ad-hoc
representation of the field also presents a barrier to new researchers wanting
to start research in this area. SMG navigation research requires its own
taxonomy, definitions, and evaluation protocols to guide effective research
moving forward. This survey is the first to catalog SMG solvers using a
well-defined and unified taxonomy and to classify existing methods accordingly.

</details>


### [311] [ROVER: Robust Loop Closure Verification with Trajectory Prior in Repetitive Environments](https://arxiv.org/abs/2508.13488)
*Jingwen Yu,Jiayi Yang,Anjun Hu,Jiankun Wang,Ping Tan,Hong Zhang*

Main category: cs.RO

TL;DR: ROVER是一种利用机器人历史轨迹作为先验约束来验证环闭合的方法，特别适用于重复环境，能有效拒绝错误的环闭合检测。


<details>
  <summary>Details</summary>
Motivation: 现有的环闭合验证方法主要关注学习不变的外观特征，忽略了机器人时空运动线索（即轨迹）的先验知识。在重复环境中，基于外观的特征因高相似性而失效，错误检测可能导致严重后果。

Method: ROVER首先利用环候选来估计机器人轨迹，然后通过评分机制评估其与无环轨迹的兼容性，以确定是否接受环候选。

Result: 基准比较和真实世界实验证明了该方法的有效性。

Conclusion: ROVER通过利用历史轨迹作为先验约束来拒绝重复环境中错误的环闭合检测，并在基准比较和真实世界实验中证明了其有效性。此外，ROVER已集成到最先进的SLAM系统中，以验证其鲁棒性和效率。

Abstract: Loop closure detection is important for simultaneous localization and mapping
(SLAM), which associates current observations with historical keyframes,
achieving drift correction and global relocalization. However, a falsely
detected loop can be fatal, and this is especially difficult in repetitive
environments where appearance-based features fail due to the high similarity.
Therefore, verification of a loop closure is a critical step in avoiding false
positive detections. Existing works in loop closure verification predominantly
focus on learning invariant appearance features, neglecting the prior knowledge
of the robot's spatial-temporal motion cue, i.e., trajectory. In this letter,
we propose ROVER, a loop closure verification method that leverages the
historical trajectory as a prior constraint to reject false loops in
challenging repetitive environments. For each loop candidate, it is first used
to estimate the robot trajectory with pose-graph optimization. This trajectory
is then submitted to a scoring scheme that assesses its compliance with the
trajectory without the loop, which we refer to as the trajectory prior, to
determine if the loop candidate should be accepted. Benchmark comparisons and
real-world experiments demonstrate the effectiveness of the proposed method.
Furthermore, we integrate ROVER into state-of-the-art SLAM systems to verify
its robustness and efficiency. Our source code and self-collected dataset are
available at https://github.com/jarvisyjw/ROVER.

</details>


### [312] [Unified Hierarchical MPC in Task Executing for Modular Manipulators across Diverse Morphologies](https://arxiv.org/abs/2508.13513)
*Maolin Lei,Edoardo Romiti,Arturo Laurenzi,Cheng Zhou,Wanli Xing,Liang Lu,Nikos G. Tsagarakis*

Main category: cs.RO

TL;DR: 提出了一种用于模块化机械臂的统一分层模型预测控制（H-MPC），它能自适应不同构型，通过分层预测和二次线性化提高控制精度和可靠性，并在真实抓取和放置任务中得到验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决模块化机械臂在不同构型下控制的通用性问题，提出一种能够自适应不同构型并执行任务的控制器，且无需复杂的参数调整。

Method: 该方法将控制过程分为两个层级：高层MPC预测未来状态并提供轨迹信息，低层MPC利用高层信息更新预测模型以优化控制动作。低层MPC还通过利用高层MPC的预测信息进行二次线性化，以捕捉运动学模型的二阶泰勒展开信息，同时保持线性控制模型的简洁性。

Result: 通过对不同机械臂构型进行广泛评估，并在真实场景中执行抓取和放置任务，验证了所提出的H-MPC控制策略的有效性，提高了控制精度和可靠性。

Conclusion: 该研究提出了一个统一的H-MPC（Hierarchical Model Predictive Control）框架，适用于模块化机械臂，能够适应不同构型并执行任务，无需大量的参数调整。

Abstract: This work proposes a unified Hierarchical Model Predictive Control (H-MPC)
for modular manipulators across various morphologies, as the controller can
adapt to different configurations to execute the given task without extensive
parameter tuning in the controller. The H-MPC divides the control process into
two levels: a high-level MPC and a low-level MPC. The high-level MPC predicts
future states and provides trajectory information, while the low-level MPC
refines control actions by updating the predictive model based on this
high-level information. This hierarchical structure allows for the integration
of kinematic constraints and ensures smooth joint-space trajectories, even near
singular configurations. Moreover, the low-level MPC incorporates secondary
linearization by leveraging predictive information from the high-level MPC,
effectively capturing the second-order Taylor expansion information of the
kinematic model while still maintaining a linearized model formulation. This
approach not only preserves the simplicity of a linear control model but also
enhances the accuracy of the kinematic representation, thereby improving
overall control precision and reliability. To validate the effectiveness of the
control policy, we conduct extensive evaluations across different manipulator
morphologies and demonstrate the execution of pick-and-place tasks in
real-world scenarios.

</details>


### [313] [The Social Context of Human-Robot Interactions](https://arxiv.org/abs/2508.13982)
*Sydney Thompson,Kate Candon,Marynel Vázquez*

Main category: cs.RO

TL;DR: HRI研究中“社会背景”的定义不统一。本研究提出了一个概念模型来统一描述和分析人机交互的社会背景，以促进研究和实践。


<details>
  <summary>Details</summary>
Motivation: HRI领域对“社会背景”一词的使用存在多样性，导致沟通不畅，难以连接相关工作，因此需要统一概念模型以解决此问题。

Method: 通过调查HRI文献，收集“社会背景”一词的现有定义和用法，然后提出一个概念模型，并将其应用于现有工作。

Result: 提出了一个概念模型，可应用于现有工作，并讨论了可帮助研究人员规划交互、开发机器人行为模型和获得交互后见解的社会背景属性。

Conclusion: 该研究总结了人类与机器人交互（HRI）领域中“社会背景”一词的用法，并提出了一个用于描述人机交互社会背景的概念模型。该模型可帮助研究人员规划交互、开发机器人行为模型以及在交互后获得见解。最后，文章讨论了在理解和建模人机交互社会背景方面的开放性研究问题。

Abstract: The Human-Robot Interaction (HRI) community often highlights the social
context of an interaction as a key consideration when designing, implementing,
and evaluating robot behavior. Unfortunately, researchers use the term "social
context" in varied ways. This can lead to miscommunication, making it
challenging to draw connections between related work on understanding and
modeling the social contexts of human-robot interactions. To address this gap,
we survey the HRI literature for existing definitions and uses of the term
"social context". Then, we propose a conceptual model for describing the social
context of a human-robot interaction. We apply this model to existing work, and
we discuss a range of attributes of social contexts that can help researchers
plan for interactions, develop behavior models for robots, and gain insights
after interactions have taken place. We conclude with a discussion of open
research questions in relation to understanding and modeling the social
contexts of human-robot interactions.

</details>


### [314] [A Three-Level Whole-Body Disturbance Rejection Control Framework for Dynamic Motions in Legged Robots](https://arxiv.org/abs/2508.13531)
*Bolin Li,Gewei Zuo,Zhixiang Wang,Xiaotian Ke,Lijun Zhu,Han Ding*

Main category: cs.RO

TL;DR: 提出了一种新的控制框架（T-WB-DRC），包含 MH-ESO 观测器，能够有效提升机器人在各种不确定性下的稳定性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为提高机器人（包括人形和四足机器人）在模型不确定性、外部干扰和故障等不确定性因素下的稳定性和鲁棒性。过去的双层方法在处理这些不确定性方面存在局限。

Method: 提出了一种新的移动时域扩展状态观测器（MH-ESO）来估计和补偿不确定性，并引入了一个三层全身干扰抑制控制框架（T-WB-DRC），该框架同时考虑了有不确定性和无不确定性的全身动力学规划。

Result: MH-ESO 能够估计不确定性和降低噪声，T-WB-DRC 在模拟和实际实验中均表现出优越的性能，显著提升了机器人在负载运输、外部干扰抑制和故障容错方面的能力。

Conclusion: 仿真和实验结果表明，该框架在应对模型不确定性、外部干扰和故障时，能够显著提高机器人稳定性、鲁棒性，并有效处理负载运输、外部干扰抑制和故障容错能力。

Abstract: This paper presents a control framework designed to enhance the stability and
robustness of legged robots in the presence of uncertainties, including model
uncertainties, external disturbances, and faults. The framework enables the
full-state feedback estimator to estimate and compensate for uncertainties in
whole-body dynamics of the legged robots. First, we propose a novel moving
horizon extended state observer (MH-ESO) to estimate uncertainties and mitigate
noise in legged systems, which can be integrated into the framework for
disturbance compensation. Second, we introduce a three-level whole-body
disturbance rejection control framework (T-WB-DRC). Unlike the previous
two-level approach, this three-level framework considers both the plan based on
whole-body dynamics without uncertainties and the plan based on dynamics with
uncertainties, significantly improving payload transportation, external
disturbance rejection, and fault tolerance. Third, simulations of both humanoid
and quadruped robots in the Gazebo simulator demonstrate the effectiveness and
versatility of T-WB-DRC. Finally, extensive experimental trials on a quadruped
robot validate the robustness and stability of the system when using T-WB-DRC
under various disturbance conditions.

</details>


### [315] [MimicFunc: Imitating Tool Manipulation from a Single Human Video via Functional Correspondence](https://arxiv.org/abs/2508.13534)
*Chao Tang,Anxing Xiao,Yuhong Deng,Tianrun Hu,Wenlong Dong,Hanbo Zhang,David Hsu,Hong Zhang*

Main category: cs.RO

TL;DR: MimicFunc framework helps robots learn tool manipulation skills from human videos, generalizing to new tools with just one example by establishing functional correspondences using keypoint-based abstraction.


<details>
  <summary>Details</summary>
Motivation: Current robots struggle to generalize tool manipulation skills due to challenges in establishing function-level correspondences, especially with significant geometric variations among functionally similar tools (intra-function variations). Imitating tool manipulation from human videos is an intuitive way to teach robots and a scalable alternative to teleoperation data collection.

Method: MimicFunc framework establishes functional correspondences with function frame, a function-centric local coordinate frame constructed with keypoint-based abstraction, for imitating tool manipulation skills.

Result: Experiments demonstrate MimicFunc's effectiveness in enabling robots to generalize skills to novel tools and training visuomotor policies.

Conclusion:  MimicFunc enables robots to generalize tool manipulation skills from a single RGB-D human video to novel tools for functionally equivalent tasks, and the generated rollouts can train visuomotor policies without labor-intensive data collection.

Abstract: Imitating tool manipulation from human videos offers an intuitive approach to
teaching robots, while also providing a promising and scalable alternative to
labor-intensive teleoperation data collection for visuomotor policy learning.
While humans can mimic tool manipulation behavior by observing others perform a
task just once and effortlessly transfer the skill to diverse tools for
functionally equivalent tasks, current robots struggle to achieve this level of
generalization. A key challenge lies in establishing function-level
correspondences, considering the significant geometric variations among
functionally similar tools, referred to as intra-function variations. To
address this challenge, we propose MimicFunc, a framework that establishes
functional correspondences with function frame, a function-centric local
coordinate frame constructed with keypoint-based abstraction, for imitating
tool manipulation skills. Experiments demonstrate that MimicFunc effectively
enables the robot to generalize the skill from a single RGB-D human video to
manipulating novel tools for functionally equivalent tasks. Furthermore,
leveraging MimicFunc's one-shot generalization capability, the generated
rollouts can be used to train visuomotor policies without requiring
labor-intensive teleoperation data collection for novel objects. Our code and
video are available at https://sites.google.com/view/mimicfunc.

</details>


### [316] [Assessing Pedestrian Behavior Around Autonomous Cleaning Robots in Public Spaces: Findings from a Field Observation](https://arxiv.org/abs/2508.13699)
*Maren Raab,Linda Miller,Zhe Zeng,Pascal Jansen,Martin Baumann,Johannes Kraus*

Main category: cs.RO

TL;DR: 研究发现，分心的行人与未分心的行人在绕行机器人时的行为没有差异。机器人的大小和运动模式会影响行人的避让行为。


<details>
  <summary>Details</summary>
Motivation: 随着自主机器人在公共场所越来越普遍，与普通人自发相遇的频率也越来越高。因此，机器人需要配备能够增强瞬间透明度和降低出现危险情况概率的通信策略。研究旨在解决机器人类型和机器人运动模式对分心和未分心行人的运动行为的影响。

Method: 在现场环境中，对 N=498 名不知情的行人进行了摄像，他们经过了两台运行中的自主清洁机器人。研究了机器人类型和机器人运动模式对分心和未分心行人的运动行为的影响。

Result: 研究发现，分心和未分心的行人绕机器人行为没有显著差异。然而，较大的扫地机器人和偏移矩形运动模式与较小的清洁机器人和圆形运动模式相比，显著增加了横向适应的数量。偏移矩形运动模式还导致了更多的近距离横向适应。根据机器人类型，运动模式导致横向适应距离存在差异。

Conclusion: 该研究为公共场所自主清洁机器人周围的行人运动行为提供了初步见解，为不断增长的人机交互研究领域做出了贡献。

Abstract: As autonomous robots become more common in public spaces, spontaneous
encounters with laypersons are more frequent. For this, robots need to be
equipped with communication strategies that enhance momentary transparency and
reduce the probability of critical situations. Adapting these robotic
strategies requires consideration of robot movements, environmental conditions,
and user characteristics and states. While numerous studies have investigated
the impact of distraction on pedestrians' movement behavior, limited research
has examined this behavior in the presence of autonomous robots. This research
addresses the impact of robot type and robot movement pattern on distracted and
undistracted pedestrians' movement behavior. In a field setting, unaware
pedestrians were videotaped while moving past two working, autonomous cleaning
robots. Out of N=498 observed pedestrians, approximately 8% were distracted by
smartphones. Distracted and undistracted pedestrians did not exhibit
significant differences in their movement behaviors around the robots. Instead,
both the larger sweeping robot and the offset rectangular movement pattern
significantly increased the number of lateral adaptations compared to the
smaller cleaning robot and the circular movement pattern. The offset
rectangular movement pattern also led to significantly more close lateral
adaptations. Depending on the robot type, the movement patterns led to
differences in the distances of lateral adaptations. The study provides initial
insights into pedestrian movement behavior around an autonomous cleaning robot
in public spaces, contributing to the growing field of HRI research.

</details>


### [317] [Blast Hole Seeking and Dipping -- The Navigation and Perception Framework in a Mine Site Inspection Robot](https://arxiv.org/abs/2508.13785)
*Liyang Liu,Ehsan Mihankhah,Nathan Wallace,Javier Martinez,Andrew J. Hill*

Main category: cs.RO

TL;DR: 开发了一种名为“DIPPeR”的自主机器人系统，用于矿山钻孔的检测。该系统利用LiDAR和点云处理技术，通过2D图像分割和目标检测算法，实现了钻孔的自主导航和精确测定位，提高了效率并降低了成本。


<details>
  <summary>Details</summary>
Motivation: 为了克服人工检测钻孔的缓慢、昂贵以及在揭示几何和地质特性方面的局限性，开发了名为“DIPPeR”的自主矿山检测机器人。

Method: 使用LiDAR传感器收集点云数据，提取钻屑锥形区域，将其投影到虚拟深度图像中进行2D分割，然后通过检测模块识别孔洞中心，并通过调整投影参数实现自主导航和目标跟踪。

Result: 所提出的框架能够自主寻找和检测钻孔，实现目标导向的导航和精确的孔内传感器定位，并在模拟和实际现场测试中得到了有效验证。

Conclusion: 该机器人系统通过点云数据处理、2D深度图像投影和鲁棒的检测算法，实现了矿山钻孔的自主导航和精确测定位，有效解决了人工检测的局限性。

Abstract: In open-pit mining, holes are drilled into the surface of the excavation site
and detonated with explosives to facilitate digging. These blast holes need to
be inspected internally for investigation of downhole material types and
properties. Knowing these properties can lead to significant savings in
material handling costs in downstream processes. Manual hole inspection is slow
and expensive, with major limitations in revealing the geometric and geological
properties of the holes and their contents. This has been the motivation for
the development of our autonomous mine-site inspection robot - "DIPPeR". In
this paper, the automation aspect of the project is explained. We present a
robust blast hole seeking and detection framework that enables target-based
navigation and accurate down-hole sensor positioning. The pipeline first
processes point-cloud data collected by the on-board LiDAR sensors, extracting
the cone-shaped volume of drill-waste above the ground. By projecting the 3D
cone points into a virtual depth image, segmentation is achieved in the 2D
domain, yielding a circular hole at the image centre and a collared cone face.
We then identify the hole centre using a robust detection module while
suppressing non-maximum candidates, ensuring precise sensor placement for
down-hole inspection and avoiding collisions with the cavity wall. To enable
autonomous hole-seeking, the pipeline automatically adjusts its projection
parameters during robot navigation to account for variations in point sparsity
and hole opening size, ensuring a consistent hole appearance in 2D images. This
allows continuous tracking of the target hole as the robot approaches the goal
point. We demonstrate the effectiveness of our navigation and perception system
in both high-fidelity simulation environments and on-site field tests. A
demonstration video is available at
"https://www.youtube.com/watch?v=fRNbcBcaSqE".

</details>


### [318] [Trajectory Tracking and Stabilization of Quadrotors Using Deep Koopman Model Predictive Control](https://arxiv.org/abs/2508.13795)
*Haitham El-Hussieny*

Main category: cs.RO

TL;DR: 本研究提出了一种名为DK-MPC的数据驱动控制框架，它结合了深度Koopman算子和模型预测控制，能够有效地线性化四旋翼的非线性动力学，从而在保持高精度的同时，显著减少计算时间，满足实时控制需求。


<details>
  <summary>Details</summary>
Motivation: 为了处理复杂的四旋翼动力学并满足实时性要求，提出了一种新的数据驱动控制框架。

Method: 提出了一种数据驱动的控制框架，将深度Koopman算子与模型预测控制（DK-MPC）相结合，通过学习到的高维潜在表示来线性化非线性四旋翼动力学，从而实现对控制动作的优化。

Result: DK-MPC方法在轨迹跟踪和点稳定方面表现出优越的跟踪精度和显著降低的计算时间，优于传统的非线性MPC。

Conclusion: Koopman算子学习方法在处理复杂四旋翼动力学和满足嵌入式飞行控制的实时性要求方面具有巨大潜力。

Abstract: This paper presents a data-driven control framework for quadrotor systems
that integrates a deep Koopman operator with model predictive control (DK-MPC).
The deep Koopman operator is trained on sampled flight data to construct a
high-dimensional latent representation in which the nonlinear quadrotor
dynamics are approximated by linear models. This linearization enables the
application of MPC to efficiently optimize control actions over a finite
prediction horizon, ensuring accurate trajectory tracking and stabilization.
The proposed DK-MPC approach is validated through a series of
trajectory-following and point-stabilization numerical experiments, where it
demonstrates superior tracking accuracy and significantly lower computation
time compared to conventional nonlinear MPC. These results highlight the
potential of Koopman-based learning methods to handle complex quadrotor
dynamics while meeting the real-time requirements of embedded flight control.
Future work will focus on extending the framework to more agile flight
scenarios and improving robustness against external disturbances.

</details>


### [319] [Toward Deployable Multi-Robot Collaboration via a Symbolically-Guided Decision Transformer](https://arxiv.org/abs/2508.13877)
*Rathnam Vidushika Rasanji,Jin Wei-Kocsis,Jiansong Zhang,Dongming Gan,Ragu Athinarayanan,Paul Asunda*

Main category: cs.RO

TL;DR: SGDT是一个结合了神经符号规划和决策变换器的新框架，用于解决多机器人协作中的挑战，并在零样本和少样本场景中表现良好。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习（RL）方法在处理复杂动力学和长期时间依赖性（如多机器人操作）时存在数据密集和依赖马尔可夫决策过程（MDP）假设的局限性。决策变换器（DTs）作为一种有前景的离线替代方案，但其在多机器人操作中的应用仍有待探索。

Method: 提出了一种名为SGDT的新框架，该框架集成了神经符号机制和因果变换器，用于多机器人协作。该框架包含一个神经符号规划器，用于生成符号子目标，以及一个目标条件决策变换器（GCDT），用于多机器人操作的低层序列决策。

Result: SGDT在各种任务场景（包括零样本和少样本场景）中进行了性能评估，展示了其在复杂多机器人协作任务中的结构化、可解释和可泛化的决策能力。

Conclusion: SGDT框架通过整合神经符号机制和因果变换器，实现了可部署的多机器人协作。

Abstract: Reinforcement learning (RL) has demonstrated great potential in robotic
operations. However, its data-intensive nature and reliance on the Markov
Decision Process (MDP) assumption limit its practical deployment in real-world
scenarios involving complex dynamics and long-term temporal dependencies, such
as multi-robot manipulation. Decision Transformers (DTs) have emerged as a
promising offline alternative by leveraging causal transformers for sequence
modeling in RL tasks. However, their applications to multi-robot manipulations
still remain underexplored. To address this gap, we propose a novel framework,
Symbolically-Guided Decision Transformer (SGDT), which integrates a
neuro-symbolic mechanism with a causal transformer to enable deployable
multi-robot collaboration. In the proposed SGDT framework, a neuro-symbolic
planner generates a high-level task-oriented plan composed of symbolic
subgoals. Guided by these subgoals, a goal-conditioned decision transformer
(GCDT) performs low-level sequential decision-making for multi-robot
manipulation. This hierarchical architecture enables structured, interpretable,
and generalizable decision making in complex multi-robot collaboration tasks.
We evaluate the performance of SGDT across a range of task scenarios, including
zero-shot and few-shot scenarios. To our knowledge, this is the first work to
explore DT-based technology for multi-robot manipulation.

</details>


### [320] [Driving Style Recognition Like an Expert Using Semantic Privileged Information from Large Language Models](https://arxiv.org/abs/2508.13881)
*Zhaokun Chen,Chaopeng Zhang,Xiaohan Li,Wenshuo Wang,Gentiane Venture,Junqiang Xi*

Main category: cs.RO

TL;DR: 通过利用LLM生成的语义信息（SPI）来增强SVM+模型，可以提高驾驶风格识别的准确性和可解释性，同时保持推理阶段的计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶风格识别系统主要依赖低级传感器特征进行训练，忽略了人类专家固有的丰富语义推理能力。这种差异导致算法分类与专家判断之间存在根本性的不匹配。

Method: 提出了一种新颖的框架，该框架整合了源自大型语言模型（LLMs）的语义特权信息（SPI），以实现识别结果与人类可解释推理的一致性。首先，引入了DriBehavGPT，一个基于LLM的交互式模块，用于生成驾驶行为的自然语言描述。然后，通过文本嵌入和降维将这些描述编码为机器学习兼容的表示。最后，将这些表示作为特权信息整合到支持向量机（SVM+）中进行训练，使模型能够近似类人解释模式。

Result: 在多样化的真实驾驶场景中进行的实验表明，SPI增强的框架优于传统方法，在跟车和变道任务中的F1分数分别提高了7.6%和7.9%。重要的是，SPI仅在训练中使用，而推理仅依赖传感器数据，在保证性能的同时提高了计算效率。

Conclusion: 现有基于LLM的SPI方法在驾驶行为识别任务中取得了显著的性能提升，同时解决了算法与专家判断之间的不匹配问题，实现了可解释性、以人为本的驾驶系统。

Abstract: Existing driving style recognition systems largely depend on low-level
sensor-derived features for training, neglecting the rich semantic reasoning
capability inherent to human experts. This discrepancy results in a fundamental
misalignment between algorithmic classifications and expert judgments. To
bridge this gap, we propose a novel framework that integrates Semantic
Privileged Information (SPI) derived from large language models (LLMs) to align
recognition outcomes with human-interpretable reasoning. First, we introduce
DriBehavGPT, an interactive LLM-based module that generates natural-language
descriptions of driving behaviors. These descriptions are then encoded into
machine learning-compatible representations via text embedding and
dimensionality reduction. Finally, we incorporate them as privileged
information into Support Vector Machine Plus (SVM+) for training, enabling the
model to approximate human-like interpretation patterns. Experiments across
diverse real-world driving scenarios demonstrate that our SPI-enhanced
framework outperforms conventional methods, achieving F1-score improvements of
7.6% (car-following) and 7.9% (lane-changing). Importantly, SPI is exclusively
used during training, while inference relies solely on sensor data, ensuring
computational efficiency without sacrificing performance. These results
highlight the pivotal role of semantic behavioral representations in improving
recognition accuracy while advancing interpretable, human-centric driving
systems.

</details>


### [321] [Multimodal Data Storage and Retrieval for Embodied AI: A Survey](https://arxiv.org/abs/2508.13901)
*Yihao Lu,Hao Tang*

Main category: cs.RO

TL;DR: 本论文系统评估了EAI的数据管理挑战，分析了现有的存储和检索技术，指出了关键瓶颈，并提出了未来的研究方向，旨在为EAI开发稳健、高性能的数据管理框架。


<details>
  <summary>Details</summary>
Motivation: EAI代理在与物理世界交互时会产生海量、异构的多模态数据流，传统的管理系统难以应对这些数据，因此需要新的数据管理解决方案。

Method: 通过对五种存储架构（图数据库、多模型数据库、数据湖、向量数据库和时间序列数据库）和五种检索范式（基于融合策略的检索、基于表示对齐的检索、基于图结构的检索、基于生成模型的检索和基于高效检索的优化）的系统评估和分析，揭示了长期语义连贯性与实时响应能力之间的基本矛盾。

Result: 现有存储架构和检索范式在满足EAI的物理接地、低延迟访问和动态可扩展性等核心需求方面存在局限性。研究发现了物理接地鸿沟、跨模态集成、动态适应和开放世界泛化等关键瓶颈。

Conclusion: EAI 数据管理的未来研究应侧重于物理感知数据模型、自适应存储检索协同优化和标准化基准测试，以实现稳健、高性能的数据管理框架。

Abstract: Embodied AI (EAI) agents continuously interact with the physical world,
generating vast, heterogeneous multimodal data streams that traditional
management systems are ill-equipped to handle. In this survey, we first
systematically evaluate five storage architectures (Graph Databases,
Multi-Model Databases, Data Lakes, Vector Databases, and Time-Series
Databases), focusing on their suitability for addressing EAI's core
requirements, including physical grounding, low-latency access, and dynamic
scalability. We then analyze five retrieval paradigms (Fusion Strategy-Based
Retrieval, Representation Alignment-Based Retrieval, Graph-Structure-Based
Retrieval, Generation Model-Based Retrieval, and Efficient Retrieval-Based
Optimization), revealing a fundamental tension between achieving long-term
semantic coherence and maintaining real-time responsiveness. Based on this
comprehensive analysis, we identify key bottlenecks, spanning from the
foundational Physical Grounding Gap to systemic challenges in cross-modal
integration, dynamic adaptation, and open-world generalization. Finally, we
outline a forward-looking research agenda encompassing physics-aware data
models, adaptive storage-retrieval co-optimization, and standardized
benchmarking, to guide future research toward principled data management
solutions for EAI. Our survey is based on a comprehensive review of more than
180 related studies, providing a rigorous roadmap for designing the robust,
high-performance data management frameworks essential for the next generation
of autonomous embodied systems.

</details>


### [322] [Augmenting cobots for sheet-metal SMEs with 3D object recognition and localisation](https://arxiv.org/abs/2508.13964)
*Martijn Cramer,Yanming Wu,David De Schepper,Eric Demeester*

Main category: cs.RO

TL;DR: This paper discusses how to improve cobots for small manufacturing businesses by adding 3D vision, making them mobile and flexible assistants to reduce manual labor and boost efficiency, using a real-world example.


<details>
  <summary>Details</summary>
Motivation: SMEs in sheet-metal workshops are challenged by small series and varying orders, leading to reliance on manual labor and underutilization of skilled workforces. The project aims to address this by transforming cobots into mobile and reconfigurable production assistants.

Method: The paper explores the integration of 3D object recognition and localisation technologies to enhance cobotic systems. It outlines key steps and discusses opportunities and challenges in an industrial setting.

Result: The project aims to demonstrate the potential of enhanced cobotic systems through a concrete implementation example from a past industrial collaboration.

Conclusion: The COOCK+ ROBUST project aims to transform cobots into mobile and reconfigurable production assistants for SMEs facing challenges in high-mix-low-volume production. The article explores the opportunities and challenges of integrating 3D object recognition and localisation into cobotic systems, with a case study from a past project serving as an implementation example.

Abstract: Due to high-mix-low-volume production, sheet-metal workshops today are
challenged by small series and varying orders. As standard automation solutions
tend to fall short, SMEs resort to repetitive manual labour impacting
production costs and leading to tech-skilled workforces not being used to their
full potential. The COOCK+ ROBUST project aims to transform cobots into mobile
and reconfigurable production assistants by integrating existing technologies,
including 3D object recognition and localisation. This article explores both
the opportunities and challenges of enhancing cobotic systems with these
technologies in an industrial setting, outlining the key steps involved in the
process. Additionally, insights from a past project, carried out by the ACRO
research unit in collaboration with an industrial partner, serves as a concrete
implementation example throughout.

</details>


### [323] [Toward an Interaction-Centered Approach to Robot Trustworthiness](https://arxiv.org/abs/2508.13976)
*Carlo Mazzola,Hassan Ali,Kristína Malinovská,Igor Farkaš*

Main category: cs.RO

TL;DR: 机器人信任框架：通过理解人类和机器人行为来建立信任。


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越多地融入人类环境，在具身机器人中培养值得信赖的品质对于实现有效和安全的人机交互至关重要。为了实现这一目标，人机交互应用必须促进与机器人技能相符的人类信任，并避免错误的信任或过度信任，因为这可能带来安全风险和伦理问题。

Method: 本文提出了一个基于交互的框架，通过人类意识和透明度来建立人机信任。

Result: 通过整合人类意识和透明度，机器人可以展现出符合人类期望和需求的行为，同时为人类伙伴提供对其行为的理解和控制。此外，本文还提出了四个旨在缩小人类感知信任度与机器人实际能力之间差距的重要组成部分。

Conclusion: 本篇论文提出了一个基于交互的框架，旨在通过增进人与机器人之间的相互理解来建立信任。该框架强调了人类意识（机器人准确解读人类行为的能力）和透明度（机器人清晰传达其意图和目标的能力）这两个关键支柱。

Abstract: As robots get more integrated into human environments, fostering
trustworthiness in embodied robotic agents becomes paramount for an effective
and safe human-robot interaction (HRI). To achieve that, HRI applications must
promote human trust that aligns with robot skills and avoid misplaced trust or
overtrust, which can pose safety risks and ethical concerns. To achieve that,
HRI applications must promote human trust that aligns with robot skills and
avoid misplaced trust or overtrust, which can pose safety risks and ethical
concerns. In this position paper, we outline an interaction-based framework for
building trust through mutual understanding between humans and robots. We
emphasize two main pillars: human awareness and transparency, referring to the
robot ability to interpret human actions accurately and to clearly communicate
its intentions and goals, respectively. By integrating these two pillars,
robots can behave in a manner that aligns with human expectations and needs
while providing their human partners with both comprehension and control over
their actions. We also introduce four components that we think are important
for bridging the gap between a human-perceived sense of trust and a robot true
capabilities.

</details>


### [324] [Embodied-R1: Reinforced Embodied Reasoning for General Robotic Manipulation](https://arxiv.org/abs/2508.13998)
*Yifu Yuan,Haiqin Cui,Yaoting Huang,Yibin Chen,Fei Ni,Zibin Dong,Pengyi Li,Yan Zheng,Jianye Hao*

Main category: cs.RO

TL;DR: 该论文提出了一种名为“指向”的新型表征方法，并训练了一个名为Embodied-R1的视觉语言模型，以克服机器人领域的“看-做鸿沟”。该模型在多项基准测试中表现优异，并能很好地泛化到新的任务和真实世界场景中，同时对视觉干扰具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决泛化能力在具身AI中受“看-做鸿沟”的阻碍，该鸿沟源于数据稀疏性和具体实现的多样性。

Method: 提出了一种名为“指向”的统一表征，并定义了四种核心的“指向”能力，以连接高层视觉语言理解和低层动作原语。设计并训练了一个3B视觉语言模型（Embodied-R1），使用了包含20万个数据点的大规模数据集Embodied-Points-200K，并通过两阶段的强化微调（RFT）课程和专门的多任务奖励设计进行训练。

Result: Embodied-R1 在11个具身空间和指向基准测试中取得了最先进的性能，并在SIMPLEREnv中实现了56.2%的成功率，在8个真实XArm任务中实现了87.5%的成功率，且无需针对特定任务进行微调，相比强基线提高了62%。此外，该模型对各种视觉干扰表现出高鲁棒性。

Conclusion: “指向”作为一种统一的、与具体实现无关的中间表征，结合强化微调（RFT）的训练范式，为缩小机器人领域的感知-动作差距提供了一条有效且可泛化的途径。

Abstract: Generalization in embodied AI is hindered by the "seeing-to-doing gap," which
stems from data scarcity and embodiment heterogeneity. To address this, we
pioneer "pointing" as a unified, embodiment-agnostic intermediate
representation, defining four core embodied pointing abilities that bridge
high-level vision-language comprehension with low-level action primitives. We
introduce Embodied-R1, a 3B Vision-Language Model (VLM) specifically designed
for embodied reasoning and pointing. We use a wide range of embodied and
general visual reasoning datasets as sources to construct a large-scale
dataset, Embodied-Points-200K, which supports key embodied pointing
capabilities. We then train Embodied-R1 using a two-stage Reinforced
Fine-tuning (RFT) curriculum with a specialized multi-task reward design.
Embodied-R1 achieves state-of-the-art performance on 11 embodied spatial and
pointing benchmarks. Critically, it demonstrates robust zero-shot
generalization by achieving a 56.2% success rate in the SIMPLEREnv and 87.5%
across 8 real-world XArm tasks without any task-specific fine-tuning,
representing a 62% improvement over strong baselines. Furthermore, the model
exhibits high robustness against diverse visual disturbances. Our work shows
that a pointing-centric representation, combined with an RFT training paradigm,
offers an effective and generalizable pathway to closing the perception-action
gap in robotics.

</details>


### [325] [Train Once, Deploy Anywhere: Realize Data-Efficient Dynamic Object Manipulation](https://arxiv.org/abs/2508.14042)
*Zhuoling Li,Xiaoyang Wu,Zhenhua Xu,Hengshuang Zhao*

Main category: cs.RO

TL;DR: 该研究提出了一种名为GEM的系统，利用熵基框架，仅用少量演示即可在动态对象操纵任务中实现强大的泛化能力，并在实际应用中取得了优异成果。


<details>
  <summary>Details</summary>
Motivation: 为了提高制造效率，需要实现可泛化的动态对象操纵，以消除针对不同场景的专业工程。然而，模仿学习中的演示收集成本高昂。

Method: 提出了一种名为通用熵基操纵（GEM）的系统，该系统基于熵基理论框架来量化模仿学习的优化。

Result: GEM系统在模拟和真实任务中表现出跨越不同环境背景、机器人载体、运动动力学和对象几何形状的泛化能力。在真实食堂餐具收集任务中，无需现场演示，成功率超过97%，操作次数超过10000次。

Conclusion: 该研究表明，仅使用少量演示即可在动态对象操作中实现强大的泛化能力，并通过熵基框架和GEM系统得到了验证。

Abstract: Realizing generalizable dynamic object manipulation is important for
enhancing manufacturing efficiency, as it eliminates specialized engineering
for various scenarios. To this end, imitation learning emerges as a promising
paradigm, leveraging expert demonstrations to teach a policy manipulation
skills. Although the generalization of an imitation learning policy can be
improved by increasing demonstrations, demonstration collection is
labor-intensive. To address this problem, this paper investigates whether
strong generalization in dynamic object manipulation is achievable with only a
few demonstrations. Specifically, we develop an entropy-based theoretical
framework to quantify the optimization of imitation learning. Based on this
framework, we propose a system named Generalizable Entropy-based Manipulation
(GEM). Extensive experiments in simulated and real tasks demonstrate that GEM
can generalize across diverse environment backgrounds, robot embodiments,
motion dynamics, and object geometries. Notably, GEM has been deployed in a
real canteen for tableware collection. Without any in-scene demonstration, it
achieves a success rate of over 97% across more than 10,000 operations.

</details>


<div id='cs.ET'></div>

# cs.ET [[Back]](#toc)

### [326] [Quantum-Inspired Artificial Bee Colony for Latency-Aware Task Offloading in IoV](https://arxiv.org/abs/2508.13637)
*Mamta Kumari,Mayukh Sarkar,Rohit Kumar Nonia*

Main category: cs.ET

TL;DR: 本文提出了一种名为QABC的新型算法，用于优化车辆网络中的任务卸载，以减少延迟。


<details>
  <summary>Details</summary>
Motivation: 高效的任务卸载对于减少延迟和确保智能交通系统中及时决策至关重要。

Method: 提出了一种新颖的量子启发的蚁群算法（QABC），该算法通过融合量子计算原理（如量子态演化和概率编码）来改进经典的蚁群算法（ABC），以增强其在避免局部最优和探索高维解空间方面的能力。

Result: QABC算法能够有效优化延迟敏感任务的卸载策略。

Conclusion: 本文提出了一种新颖的量子启发的蚁群算法（QABC），用于解决车辆网（IoV）中的延迟敏感任务卸载问题，并着重强调了量子启发式方法在优化未来车辆网络中的实时卸载策略方面的潜力。

Abstract: Efficient task offloading is crucial for reducing latency and ensuring timely
decision-making in intelligent transportation systems within the rapidly
evolving Internet of Vehicles (IoV) landscape. This paper introduces a novel
Quantum-Inspired Artificial Bee Colony (QABC) algorithm specifically designed
for latency-sensitive task offloading involving cloud servers, Roadside Units
(RSUs), and vehicular nodes. By incorporating principles from quantum
computing, such as quantum state evolution and probabilistic encoding, QABC
enhances the classical Artificial Bee Colony (ABC) algorithm's ability to avoid
local optima and explore high-dimensional solution spaces. This research
highlights the potential of quantum-inspired heuristics to optimize real-time
offloading strategies in future vehicular networks.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [327] [Stochastic Black Start Resource Allocation to Enable Dynamic Formation of Networked Microgrids and DER-aided Restoration](https://arxiv.org/abs/2508.13306)
*Cong Bai,Salish Maharjan,Han Wang,Zhaoyu Wang*

Main category: eess.SY

TL;DR: 提出了一种用于微电网黑启动的资源分配方法（SDMG-BS），使用VSG逆变器并考虑频率安全和不确定性，已在IEEE 123节点馈线上得到验证。


<details>
  <summary>Details</summary>
Motivation: 分布式能源（DERs）主导的分布式系统（DSs）在扩展停机期间，需要创新策略来高效且安全地部署黑启动（BS）资源，以应对日益增长的微电网（MGs）和不确定性。

Method: 提出了一种两阶段随机资源分配方法（SDMG-BS），使用虚拟同步发电机（VSG）控制的并网逆变器（GFMIs）作为BS资源，并引入瞬态指数来约束频率动态。该框架利用智能开关（SSWs）实现微电网（MGs）之间以及与输电网（TG）的异地同步，并采用基于场景的随机规划来处理不确定性，如季节性运行条件和不可预测的输电网中断持续时间。

Result: 在改进的IEEE 123节点馈线上的三种研究案例（涵盖十六种不确定性场景）的验证表明，该方法能够确保频率稳定性和异地同步，有效应对不确定性，实现有弹性的资源分配计划。

Conclusion: 该研究提出了一种名为SDMG-BS的两阶段随机资源分配方法，用于在同步动态微电网中实现分布式能源（DERs）主导的分布式系统（DSs）的黑启动（BS）。该方法能够进行风险规避和自适应恢复，确保频率安全，并允许异地同步。

Abstract: Extended outages in distributed systems (DSs) dominated by distributed energy
resources (DERs) require innovative strategies to efficiently and securely
deploy black start (BS) resources. To address the need, this paper proposes a
two-stage stochastic resource allocation method within synchronizing dynamic
microgrids (MGs) for black start (SDMG-BS), enabling risk-averse and adaptive
restoration across various scenarios while ensuring frequency security. Virtual
synchronous generator (VSG)-controlled grid-forming inverters (GFMIs) equipped
with primary frequency governors (PFGs) are modeled as BS resources. Their
frequency response is characterized by three transient indices, which are
deployed as frequency dynamic constraints on load pick-up events to ensure
frequency stability during the BS process. SDMG-BS framework facilitates
location-independent synchronization among restored MGs and with the
transmission grid (TG) with the help of smart switches (SSWs). The model
incorporates scenario-based stochastic programming to address multi-source
uncertainties, including season-dependent operational conditions and
unpredictable TG outage durations, ensuring a resilient allocation plan. The
proposed approach is validated on a modified IEEE 123-node feeder with three
study cases designed across sixteen uncertainty scenarios.

</details>


### [328] [Low-Cost Sensing and Classification for Early Stress and Disease Detection in Avocado Plants](https://arxiv.org/abs/2508.13379)
*Abdulrahman Bukhari,Bullo Mamo,Mst Shamima Hossain,Ziliang Zhang,Mohsen Karimi,Daniel Enright,Patricia Manosalva,Hyoseung Kim*

Main category: eess.SY

TL;DR: 该研究评估了低成本传感器在牛油果田间病害检测中的应用。结果表明，叶片光谱测量结合机器学习方法比叶片温度和电导率测量更有效。土壤数据分析的分类器准确率高，且在边缘设备上表现良好，为开发经济实惠、可扩展的监测系统提供了思路。


<details>
  <summary>Details</summary>
Motivation: 为了应对农业领域对高效病害和盐分管理日益增长的需求，以及牛油果等高价值作物早期压力和疾病检测的重要性。

Method: 部署了一个包含72株牛油果植物的监测系统，分为四个处理组，历时六个月。评估了叶片温度、电导率和光谱测量，并开发了一个两级分层分类器用于土壤数据分析，同时在嵌入式边缘设备上进行了性能评估。

Result: 叶片光谱测量结合机器学习方法产生了统计学上的显著结果，而叶片温度和电导率测量在田间条件下不可靠。土壤数据分析的分类器在不同牛油果基因型上的准确率达到了75-86%，比传统方法高出20%以上。嵌入式边缘设备的性能评估证明了该方法在资源受限环境下的可行性。

Conclusion: 低成本传感器结合机器学习方法可以有效地应用于牛油果植物的早期压力和疾病检测，尤其是在田间条件下。与传统的机器学习方法相比，该方法在土壤数据分析方面表现出更高的准确性，并在嵌入式边缘设备上证明了其可行性。

Abstract: With rising demands for efficient disease and salinity management in
agriculture, early detection of plant stressors is crucial, particularly for
high-value crops like avocados. This paper presents a comprehensive evaluation
of low-cost sensors deployed in the field for early stress and disease
detection in avocado plants. Our monitoring system was deployed across 72
plants divided into four treatment categories within a greenhouse environment,
with data collected over six months. While leaf temperature and conductivity
measurements, widely used metrics for controlled settings, were found
unreliable in field conditions due to environmental interference and
positioning challenges, leaf spectral measurements produced statistically
significant results when combined with our machine learning approach. For soil
data analysis, we developed a two-level hierarchical classifier that leverages
domain knowledge about treatment characteristics, achieving 75-86\% accuracy
across different avocado genotypes and outperforming conventional machine
learning approaches by over 20\%. In addition, performance evaluation on an
embedded edge device demonstrated the viability of our approach for
resource-constrained environments, with reasonable computational efficiency
while maintaining high classification accuracy. Our work bridges the gap
between theoretical potential and practical application of low-cost sensors in
agriculture and offers insights for developing affordable, scalable monitoring
systems.

</details>


### [329] [System-Level Performance and Communication Tradeoff in Networked Control with Predictions](https://arxiv.org/abs/2508.13475)
*Yifei Wu,Jing Yu,Tongxin Li*

Main category: eess.SY

TL;DR: PredSLS框架通过预测和通信约束实现分布式控制，并能优化通信拓扑。


<details>
  <summary>Details</summary>
Motivation: 解决大规模系统中分布式控制面临的可扩展性和局部通信计算的挑战。

Method: PredSLS框架通过整合通信约束和局部干扰预测到仿射反馈结构中来设计控制器，并利用当前状态反馈和未来系统干扰预测。

Result: PredSLS框架可以分解为空间和时间部分进行高效和可并行的计算，其遗憾分析揭示了控制性能和通信范围之间的非单调权衡，并指导识别局部通信邻域的最优尺寸。

Conclusion: PredSLS框架能够通过联合优化控制器和通信拓扑，在考虑通信约束和局部干扰预测的情况下，实现分布式控制，并且优于其他方法。

Abstract: Distributed control of large-scale systems is challenging due to the need for
scalable and localized communication and computation. In this work, we
introduce a Predictive System-Level Synthesis PredSLS framework that designs
controllers by jointly integrating communication constraints and local
disturbance predictions into an affine feedback structure. Rather than focusing
on the worst-case uncertainty, PredSLS leverages both current state feedback
and future system disturbance predictions to achieve distributed control of
networked systems. In particular, PredSLS enables a unified system synthesis of
the optimal $\kappa$-localized controller, therefore outperforms approaches
with post hoc communication truncation, as was commonly seen in the literature.
The PredSLS framework can be naturally decomposed into spatial and temporal
components for efficient and parallelizable computation across the network,
yielding a regret upper bound that explicitly depends on the prediction error
and communication range. Our regret analysis not only reveals a non-monotonic
trade-off between control performance and communication range when prediction
errors are present, but also guides the identification of an optimal size for
local communication neighborhoods, thereby enabling the co-design of controller
and its underlying communication topology.

</details>


### [330] [Power-Series Approach to Moment-Matching-Based Model Reduction of MIMO Polynomial Nonlinear Systems](https://arxiv.org/abs/2508.13595)
*Chao Huang,Alessandro Astolfi*

Main category: eess.SY

TL;DR: 针对高阶MIMO多项式非线性系统，提出了一种基于幂级数分解和矩匹配的降阶方法，可解析地获得降阶模型，并给出了模型阶数和参数的确定算法。


<details>
  <summary>Details</summary>
Motivation: 解决高阶多输入多输出（MIMO）多项式非线性系统基于矩匹配的降阶问题。

Method: 利用幂级数分解将中心流形非线性偏微分方程的解分解为一组递归定义的西尔维斯特方程的解，从而得到降阶模型。

Result: 提出了获得降阶模型阶数和参数的算法，精度可达$\\kappa$。研究结果揭示了降阶模型的阶数下界可能小于矩匹配的数量，并且该下界受输入输出通道数量比的影响。在温和条件下，可以构造出具有线性状态方程或线性输出方程的非线性降阶模型。

Conclusion: 该方法为高阶多输入多输出（MIMO）多项式非线性系统提供了一种降阶模型，其阶数和参数可以达到指定的精度。

Abstract: The model reduction problem for high-order multi-input, multi-output (MIMO)
polynomial nonlinear systems based on moment matching is addressed. The
technique of power-series decomposition is exploited: this decomposes the
solution of the nonlinear PDE characterizing the center manifold into the
solutions of a series of recursively defined Sylvester equations. This approach
allows yielding nonlinear reduced-order models in very much the same way as in
the linear case (e.g. analytically). Algorithms are proposed for obtaining the
order and the parameters of the reduced-order models with precision of degree
$\kappa$. The approach also provides new insights into the nonlinear moment
matching problem: first, a lower bound for the order of the reduced-order model
is obtained, which, in the MIMO case, can be strictly less than the number of
matched moments; second, it is revealed that the lower bound is affected by the
ratio of the number of the input and output channels; third, it is shown that
under mild conditions, a nonlinear reduced-order model can always be
constructed with either a linear state equation or a linear output equation.

</details>


### [331] [Scalable Sensor Placement for Cyclic Networks with Observability Guarantees: Application to Water Distribution Networks](https://arxiv.org/abs/2508.13604)
*J. J. H. van Gemert,V. Breschi,D. R. Yntema,K. J. Keesman,M. Lazar*

Main category: eess.SY

TL;DR: 为具有参数不确定性的循环和非循环网络提出了一种新的传感器放置算法，该算法基于图的策略，能够高效解决大规模网络问题，并在L镇水力分配网络的实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 解决了循环、参数不确定性和可扩展性带来的挑战。

Method: 利用基于图的策略来解决计算复杂性问题。

Result: 该算法能够在0.1秒内解决L镇水力分配网络的传感器放置问题，确保其结构可观测性。

Conclusion: 该算法能够为具有参数不确定性的循环和非循环网络提供结构可观测性。

Abstract: Optimal sensor placement is essential for state estimation and effective
network monitoring. As known in the literature, this problem becomes
particularly challenging in large-scale undirected or bidirected cyclic
networks with parametric uncertainties, such as water distribution networks
(WDNs), where pipe resistance and demand patterns are often unknown. Motivated
by the challenges of cycles, parametric uncertainties, and scalability, this
paper proposes a sensor placement algorithm that guarantees structural
observability for cyclic and acyclic networks with parametric uncertainties. By
leveraging a graph-based strategy, the proposed method efficiently addresses
the computational complexities of large-scale networks. To demonstrate the
algorithm's effectiveness, we apply it to several EPANET benchmark WDNs. Most
notably, the developed algorithm solves the sensor placement problem with
guaranteed structured observability for the L-town WDN with 1694 nodes and 124
cycles in under 0.1 seconds.

</details>


### [332] [Towards safe control parameter tuning in distributed multi-agent systems](https://arxiv.org/abs/2508.13608)
*Abdullah Tokmak,Thomas B. Schön,Dominik Baumann*

Main category: eess.SY

TL;DR: 该研究提出了一种安全贝叶斯优化方法，用于解决分布式多智能体系统的优化问题。该方法通过引入时空核函数来处理最近邻通信和非邻近智能体的行为，并在仿真中取得了成功。


<details>
  <summary>Details</summary>
Motivation: 为了在保证安全的同时优化分布式多智能体系统的性能，将它们建模为分布式优化问题，其中每个智能体都旨在优化其参数以最大化耦合奖励函数并满足耦合约束。

Method: 使用具有高斯过程回归的安全贝叶斯优化，并提出了一种自定义的时空核函数来整合先验知识。

Result: 该算法能够解决具有未知且非凸奖励和约束的分布式多智能体系统，并处理了最近邻通信和非邻近智能体的行为。

Conclusion: 该算法在仿真中成功部署。

Abstract: Many safety-critical real-world problems, such as autonomous driving and
collaborative robots, are of a distributed multi-agent nature. To optimize the
performance of these systems while ensuring safety, we can cast them as
distributed optimization problems, where each agent aims to optimize their
parameters to maximize a coupled reward function subject to coupled
constraints. Prior work either studies a centralized setting, does not consider
safety, or struggles with sample efficiency. Since we require sample efficiency
and work with unknown and nonconvex rewards and constraints, we solve this
optimization problem using safe Bayesian optimization with Gaussian process
regression. Moreover, we consider nearest-neighbor communication between the
agents. To capture the behavior of non-neighboring agents, we reformulate the
static global optimization problem as a time-varying local optimization problem
for each agent, essentially introducing time as a latent variable. To this end,
we propose a custom spatio-temporal kernel to integrate prior knowledge. We
show the successful deployment of our algorithm in simulations.

</details>


### [333] [Transient Stability Analysis for Grid Following Converters in Low-Inertia Power Systems by Direct Method](https://arxiv.org/abs/2508.13641)
*Fangyuan Sun,Ruisheng Diao,Ruiyuan Zeng,Zhanning Liu,Baorong Zhou,Junjie Li,Wangqianyun Tang*

Main category: eess.SY

TL;DR: This paper presents a new method to analyze the transient stability of power systems with low inertia and grid-following converters, improving accuracy in predicting stability limits and addressing issues with existing methods.


<details>
  <summary>Details</summary>
Motivation: The increasing penetration of renewable energy leads to low-inertia systems (LIS), exacerbating transient stability issues for grid-following converters (GFLCs). Traditional methods are inapplicable due to the complex angular dynamics of LIS and the nonlinear, potentially negative damping of GFLCs.

Method: A Zubov-based transient stability analysis method is proposed, which constructs an energy function to handle negative damping and uses a dynamic model of GFLC-LIS considering PLL dynamics and swing equations, including frequency mutations during faults.

Result: The paper provides an accurate estimation of the attraction boundary and critical clearance time (CCT) for GFLC-LIS, analyzes the accuracy of CCT estimation, and illustrates the influence of LIS parameters on transient stability, with effectiveness verified by simulations.

Conclusion: The proposed Zubov-based method accurately estimates the attraction boundary and critical clearance time (CCT) for grid-following converters (GFLCs) in low-inertia systems (LIS), effectively addressing the challenges posed by negative damping and complex angular dynamics.

Abstract: With the increased penetration of renewable energy and reduced proportion of
synchronous generators, the low-inertia characteristics of todays power system
become prominent, and the transient stability issue of grid following converter
(GFLC) under low inertia system (LIS) condition becomes critical. There are two
prominent problems in the transient stability analysis of GFLC-LIS. The angular
dynamic of LIS increases the complexity of transient stability analysis, and
the nonlinear, possibly negative damping of GFLC makes it difficult to
guarantee the conservative of the traditional methods. These problems make the
traditional methods inapplicable. In this paper, the transient stability
analysis of GFLC LIS is investigated to provide an accurate estimation of the
attraction boundary and critical clearance time (CCT). Firstly, a dynamic model
of GFLC-LIS is constructed, considering the phase-locked loop (PLL)-based GFLC
dynamics and swing equation-based LIS dynamics. The frequency mutation of PLL
at fault occurrence and clearing time is also considered. Secondly, a Zubov
based transient stability analysis method is proposed, which can construct the
energy function in a way that is different from the traditional conservation of
energy perspective and can address the negative damping issue. Moreover, the
accuracy of the CCT estimation is analyzed, and the influences of LIS
parameters on transient stability are illustrated. Finally, simulation
experiments are carried out to verify the effectiveness of the proposed method

</details>


### [334] [Model-based Multi-object Visual Tracking: Identification and Standard Model Limitations](https://arxiv.org/abs/2508.13647)
*Jan Krejčí,Oliver Kost,Yuxuan Xia,Lennart Svensson,Ondřej Straka*

Main category: eess.SY

TL;DR: The paper applies radar tracking methods (PMBM filter) to pedestrian tracking with 2D bounding boxes. While it shows promise, the standard point-object model doesn't perfectly fit the data, indicating areas for future improvement.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the problem of pedestrian tracking using 2D bounding box detections by applying multi-object tracking methods from the radar tracking community.

Method: This paper adopts the standard point-object (SPO) model and computes the posterior density using the Poisson multi-Bernoulli mixture (PMBM) filter. Model parameters, including birth and survival probabilities, are selected from continuous time, with some chosen from first principles and others identified from the MOT-17 dataset.

Result: The resulting PMBM algorithm yields promising results, but a mismatch between the SPO model and the data was identified.

Conclusion: The paper reveals a mismatch between the standard point-object (SPO) model and the data, suggesting that future developments should focus on modifying problematic components to improve model-based algorithms.

Abstract: This paper uses multi-object tracking methods known from the radar tracking
community to address the problem of pedestrian tracking using 2D bounding box
detections. The standard point-object (SPO) model is adopted, and the posterior
density is computed using the Poisson multi-Bernoulli mixture (PMBM) filter.
The selection of the model parameters rooted in continuous time is discussed,
including the birth and survival probabilities. Some parameters are selected
from the first principles, while others are identified from the data, which is,
in this case, the publicly available MOT-17 dataset. Although the resulting
PMBM algorithm yields promising results, a mismatch between the SPO model and
the data is revealed. The model-based approach assumes that modifying the
problematic components causing the SPO model-data mismatch will lead to better
model-based algorithms in future developments.

</details>


### [335] [BioGAP-Ultra: A Modular Edge-AI Platform for Wearable Multimodal Biosignal Acquisition and Processing](https://arxiv.org/abs/2508.13728)
*Sebastian Frey,Giusy Spacone,Andrea Cossettini,Marco Guermandi,Philipp Schilk,Luca Benini,Victor Kartsch*

Main category: eess.SY

TL;DR: BioGAP-Ultra 是一款先进的可穿戴生物传感平台，可采集多种生理信号并支持边缘人工智能处理，具有高能效和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了满足可穿戴生物传感应用日益增长的需求，该研究提出了一种扩展的 BioGAP 设计，称为 BioGAP-Ultra，它具有增加的片上存储器、改进的无线连接、更多的信号模式和模拟输入通道，并配有实时可视化和分析软件套件。

Method: 开发了一个名为 BioGAP-Ultra 的先进多模态生物传感平台，可同步采集各种电生理和血流动力学信号（如脑电图、肌电图、心电图和光电容积脉搏波图），并支持以最先进的能效进行嵌入式人工智能处理。

Result: BioGAP-Ultra 平台在功耗方面表现出色，EEG-PPG 头带功耗为 32.8 mW，EMG 袖套功耗为 26.7 mW，ECG-PPG 胸带功耗仅为 9.3 mW。

Conclusion: 该平台可扩展、可配置且适用于各种可穿戴设备，可用于实时多模态生物信号采集和边缘智能。

Abstract: The growing demand for continuous physiological monitoring and human-machine
interaction in real-world settings calls for wearable platforms that are
flexible, low-power, and capable of on-device intelligence. This work presents
BioGAP-Ultra, an advanced multimodal biosensing platform that supports
synchronized acquisition of diverse electrophysiological and hemodynamic
signals such as EEG, EMG, ECG, and PPG while enabling embedded AI processing at
state-of-the-art energy efficiency. BioGAP-Ultra is a major extension of our
previous design, BioGAP [1], aimed at meeting the rapidly growing requirements
of wearable biosensing applications. It features (i) increased on-device
storage (x2 SRAM, x4 FLASH), (ii) improved wireless connectivity (1.4 Mbit/s
bandwidth, x4 higher than BioGAP), (iii) enhanced number of signal modalities
(from 3 to 5) and analog input channels (x2). Further, it is complemented by a
complete real-time visualization and analysis software suite, providing access
to raw data and real-time configurability on a mobile phone. Electrical
characterization and multiple case studies confirm the platform's robustness,
configurability, and suitability for real-world multimodal biosignal
acquisition and edge intelligence. Finally, we demonstrate the system's
versatility through integration into various wearable form factors: an EEG-PPG
headband consuming 32.8 mW, an EMG sleeve at 26.7 mW, and an ECG-PPG chest band
requiring only 9.3 mW, tailored for diverse biosignal applications. All
hardware and software design files are also released open-source with a
permissive license.

</details>


### [336] [AutoMPC: A Code Generator for MPC-based Automated Driving](https://arxiv.org/abs/2508.13656)
*Georg Schildbach,Jasper Pflughaupt*

Main category: eess.SY

TL;DR: AutoMPC 通过自动代码生成和优化的 MPC 算法，解决了自动驾驶车辆控制中的计算和实现难题，提高了效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决模型预测控制（MPC）在工业量产车辆应用中面临的计算需求高和实现复杂性两大挑战。

Method: 利用改进型活性集算法处理非线性 MPC，通过自动代码生成技术生成 C 代码，支持用户自定义车辆模型、数值积分方法和算法参数，并可直接部署到 Matlab/Simulink 或 ROS 等平台。

Result: AutoMPC 代码在多种驾驶场景（包括低速、高速和漂移）下均表现出通用性和有效性，保证了解决方案的可行性、鲁棒性和计算效率。

Conclusion: AutoMPC 通过自动代码生成，将非线性 MPC 算法嵌入到车辆轨迹跟踪框架中，生成了可部署在嵌入式平台上的高效 C 代码，解决了 MPC 在工业量产车辆应用中的计算需求高和实现复杂性的挑战。

Abstract: Model Predictive Control (MPC) is a powerful technique to control nonlinear,
multi-input multi-output systems subject to input and state constraints. It is
now a standard tool for trajectory tracking control of automated vehicles. As
such it has been used in many research and development projects. However, MPC
faces several challenges to be integrated into industrial production vehicles.
The most important ones are its high computational demands and the complexity
of implementation. The software packages AutoMPC aims to address both of these
challenges. It builds on a robustified version of an active set algorithm for
Nonlinear MPC. The algorithm is embedded into a framework for vehicle
trajectory tracking, which makes it easy to used, yet highly customizable.
Automatic code generation transforms the selections into a standalone,
computationally efficient C-code file with static memory allocation. As such it
can be readily deployed on a wide range of embedded platforms, e.g., based on
Matlab/Simulink or Robot Operating System (ROS). Compared to a previous version
of the code, the vehicle model and the numerical integration method can be
manually specified, besides basic algorithm parameters. All of this information
and all specifications are directly baked into the generated C-code. The
algorithm is suitable driving scenarios at low or high speeds, even drifting,
and supports direction changes. Multiple simulation scenarios show the
versatility and effectiveness of the AutoMPC code, with the guarantee of a
feasible solution, a high degree of robustness, and computational efficiency.

</details>


### [337] [Singularity-free prescribed performance guaranteed control for perturbed system](https://arxiv.org/abs/2508.13726)
*Yiwei Liu*

Main category: eess.SY

TL;DR: 提出了一种新颖的变换函数和策略，用于解决高阶非线性系统中的规定性能控制问题，有效避免了奇点和复杂性爆炸，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决高阶非线性系统受不匹配扰动影响时的规定性能控制（PPC）问题，特别是要避免由于误差边界违反而在参考轨迹突然变化期间出现的奇点问题。

Method: 提出了一种具有无限阶可微性的新颖变换函数，并开发了一种全面的变换策略。该策略确保了当参考轨迹平滑时，误差保持在规定的边界内；当参考轨迹发生突然变化时，误差在规定的时间范围内恢复到规定的边界内。此外，还解决了反步设计中固有的复杂性爆炸问题。

Result: 通过模拟结果验证了所提出理论的有效性。

Conclusion: 开发了一种新颖的具有无限阶可微性的变换函数，用于高阶非线性系统中的规定性能控制。该方法解决了奇点问题和反步法中的复杂性爆炸问题，并确保了跟踪误差在规定的时间范围内恢复到规定的边界内，即使在参考轨迹突然变化时也是如此。

Abstract: This paper addresses the prescribed performance control (PPC) challenge for
high-order nonlinear systems affected by mismatched disturbances. The research
aims to prevent singularity issues arising from error boundary violations
during abrupt changes in reference trajectories. We introduce a novel
transformation function with infinite-order differentiability at connection
points, advancing beyond mere continuous differentiability. Utilizing this
transformation function, we develop a comprehensive transformation strategy
that ensures: (1) errors remain within prescribed boundaries when reference
trajectories are smooth, and (2) errors return to prescribed boundaries within
a specified timeframe following abrupt changes in reference trajectories.
Additionally, the complexity explosion issue inherent in backstepping design is
effectively resolved. Simulation results corroborate the validity of the
proposed theoretical advancements.

</details>


### [338] [Energy Management and Wake-up for IoT Networks Powered by Energy Harvesting](https://arxiv.org/abs/2508.13825)
*David Ernesto Ruiz-Guirola,Samuel Montejo-Sanchez,Israel Leyva-Mayorga,Zhu Han,Petar Popovski,Onel L. A. Lopez*

Main category: eess.SY

TL;DR: 针对物联网的能耗和维护挑战，提出基于能量收集的自可持续IoT生态系统。通过KNN、RL和DT方法优化设备占空比，实现节能和提高数据准确性，RL方法在设备数量增加时性能接近最优。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）的快速增长带来了维护需求增加和整体能耗升高这些可持续性挑战，因此需要基于能量收集（EH）的自可持续IoT生态系统。

Method: 提出了一种基于K近邻（KNN）的占空比管理方法，并评估了包括强化学习（RL）和决策变换器（DT）在内的机器学习方法，以优化能量效率和检测准确性。

Result: KNN、RL和DT方法在节能方面均显著优于现有技术。

Conclusion: KNN、RL和DT方法在节能方面均显著优于现有技术，其中RL方法在设备数量增加时，性能接近最优基准。

Abstract: The rapid growth of the Internet of Things (IoT) presents sustainability
challenges such as increased maintenance requirements and overall higher energy
consumption. This motivates self-sustainable IoT ecosystems based on Energy
Harvesting (EH). This paper treats IoT deployments in which IoT devices (IoTDs)
rely solely on EH to sense and transmit information about events/alarms to a
base station (BS). The objective is to effectively manage the duty cycling of
the IoTDs to prolong battery life and maximize the relevant data sent to the
BS. The BS can also wake up specific IoTDs if extra information about an event
is needed upon initial detection. We propose a K-nearest neighbors (KNN)-based
duty cycling management to optimize energy efficiency and detection accuracy by
considering spatial correlations among IoTDs' activity and their EH process. We
evaluate machine learning approaches, including reinforcement learning (RL) and
decision transformers (DT), to maximize information captured from events while
managing energy consumption. Significant improvements over the state-ofthe-art
approaches are obtained in terms of energy saving by all three proposals, KNN,
RL, and DT. Moreover, the RL-based solution approaches the performance of a
genie-aided benchmark as the number of IoTDs increases.

</details>


### [339] [LLMind 2.0: Distributed IoT Automation with Natural Language M2M Communication and Lightweight LLM Agents](https://arxiv.org/abs/2508.13920)
*Yuyang Du,Qun Yang,Liujianfu Wang,Jingqi Lin,Hongwei Cui,Soung Chang Liew*

Main category: eess.SY

TL;DR: LLMind 2.0是一个分布式物联网自动化框架，利用轻量级LLM驱动的设备代理，通过自然语言M2M通信解决大规模物联网系统的可扩展性问题，实现了跨异构设备的无缝协作和本地代码生成。


<details>
  <summary>Details</summary>
Motivation: 现有集中式方法在管理和协调大规模异构物联网系统中具有不同能力的物联网设备时，面临严峻的可扩展性挑战。LLM在物联网和自动化系统中的应用，特别是在通过自然语言指令进行设备管理方面，引起了极大兴趣。

Method: LLMind 2.0框架采用轻量级LLM驱动的设备代理，通过自然语言进行机器对机器（M2M）通信。中央协调器将人类指令转换为子任务，由设备代理在本地生成设备特定代码。关键创新包括：用于子任务到API映射的检索增强生成（RAG）机制、用于可靠代码生成的微调轻量级LLM，以及基于有限状态机的任务执行框架。

Result: 实验验证表明，与集中式方法相比，LLMind 2.0在多机器人仓库场景和真实WiFi网络部署中，在可扩展性、可靠性和隐私保护方面均有显著提升。

Conclusion: LLMind 2.0通过分布式LLM代理解决了大规模物联网系统的可扩展性挑战，实现了跨设备异构的无缝协作。

Abstract: Recent advances in large language models (LLMs) have sparked interest in
their application to IoT and automation systems, particularly for facilitating
device management through natural language instructions. However, existing
centralized approaches face significant scalability challenges when managing
and coordinating the collaboration between IoT devices of diverse capabilities
in large-scale heterogeneous IoT systems. This paper introduces LLMind 2.0, a
distributed IoT automation framework that addresses the scalability challenges
through lightweight LLM-empowered device agents via natural language-based
machine-to-machine (M2M) communication. Unlike previous LLM-controlled
automation systems that rely on a centralized coordinator to generate
device-specific code to be executed on individual devices, LLMind 2.0
distributes intelligence across individual devices through lightweight LLMs
embedded in IoT devices. The central coordinator translates human instructions
into simple subtasks described in natural human language, which are then
processed by device-specific agents to generate device-specific code locally at
the associated devices. This approach transcends device heterogeneity barriers
by using natural language as a unified communication medium, enabling seamless
collaboration between devices from different manufacturers. The system
incorporates several key innovations: a Retrieval-Augmented Generation (RAG)
mechanism for accurate subtask-to-API mapping, fine-tuned lightweight LLMs for
reliable code generation, and a finite state machine-based task execution
framework. Experimental validation in multi-robot warehouse scenarios and
real-world WiFi network deployments demonstrates significant improvements in
scalability, reliability, and privacy protection compared to the centralized
approach.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [340] [Uncertainty-Aware Learning Policy for Reliable Pulmonary Nodule Detection on Chest X-Ray](https://arxiv.org/abs/2508.13236)
*Hyeonjin Choi,Jinse Kim,Dong-yeon Yoo,Ju-sung Sun,Jung-won Lee*

Main category: eess.IV

TL;DR: 研究提出了一种不确定性感知学习策略，结合了医生背景知识和胸部X光片信息，提高了AI诊断的准确性和置信度，敏感性提升10%，不确定性降低。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学AI在诊断不确定性方面存在的问题，提高医生对医学AI的信任度和临床应用率。

Method: 提出了一种不确定性感知学习策略，将医师的背景知识与胸部X光片病灶信息相结合进行学习。

Result: 所提出的模型在2,517张无病灶图像和656张结节图像上进行了测试，敏感性比基线模型提高了10%，不确定性度量（熵）降低了0.2，同时达到了92%的IoU（0.2）和FPPI（2）。

Conclusion: 该研究提出了不确定性感知学习策略，通过学习医师的背景知识和胸部X光片病灶信息，解决了医学AI知识不足的问题，提高了诊断的准确性和可信度。

Abstract: Early detection and rapid intervention of lung cancer are crucial.
Nonetheless, ensuring an accurate diagnosis is challenging, as physicians'
ability to interpret chest X-rays varies significantly depending on their
experience and degree of fatigue. Although medical AI has been rapidly
advancing to assist in diagnosis, physicians' trust in such systems remains
limited, preventing widespread clinical adoption. This skepticism fundamentally
stems from concerns about its diagnostic uncertainty. In clinical diagnosis,
physicians utilize extensive background knowledge and clinical experience. In
contrast, medical AI primarily relies on repetitive learning of the target
lesion to generate diagnoses based solely on that data. In other words, medical
AI does not possess sufficient knowledge to render a diagnosis, leading to
diagnostic uncertainty. Thus, this study suggests an Uncertainty-Aware Learning
Policy that can address the issue of knowledge deficiency by learning the
physicians' background knowledge alongside the Chest X-ray lesion information.
We used 2,517 lesion-free images and 656 nodule images, all obtained from Ajou
University Hospital. The proposed model attained 92% (IoU 0.2 / FPPI 2) with a
10% enhancement in sensitivity compared to the baseline model while also
decreasing entropy as a measure of uncertainty by 0.2.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [341] [Fair Division Among Couples and Small Groups](https://arxiv.org/abs/2508.13432)
*Paul Gölz,Hannane Yaghoubizade*

Main category: cs.GT

TL;DR: 本文研究了不可分割商品在群体间的公平分配问题，并提出了EF1和PROPk分配的存在性和有效性。


<details>
  <summary>Details</summary>
Motivation: 我们研究了不可分割商品在群体间的公平分配问题，以及EF1和PROPk分配的存在性和有效性。

Method: 本文研究了不可分割商品在代理群体之间的公平分配问题，其中每个代理完全享受分配给其群体的所有商品。我们专注于包含两个（夫妇）和其他小群体的群体。对于两个夫妇，EF1 分配（其中所有代理发现其群体束不比另一个群体的束差，最多一个商品）总是存在的，并且可以有效地找到。

Result: 对于两个夫妇，EF1 分配总是存在的。对于三个或更多夫妇，EF1 分配不一定存在。当组的大小最多为 k 时， PROPk 分配总是存在的，并且可以有效地找到。我们的算法还保证了（分数）帕累托最优性，并为任意代理排序保证了 PROP1 到每个组中的第一个代理，PROP2 到第二个代理，依此类推。在特殊情况下，我们证明了对于任何数量的夫妇都存在 PROP1 分配。

Conclusion: 对于三个或更多夫妇，EF1分配不一定存在。然而，当组的大小最多为 k 时， PROPk 分配总是存在，并且可以有效地找到。

Abstract: We study the fair allocation of indivisible goods across groups of agents,
where each agent fully enjoys all goods allocated to their group. We focus on
groups of two (couples) and other groups of small size. For two couples, an EF1
allocation -- one in which all agents find their group's bundle no worse than
the other group's, up to one good -- always exists and can be found
efficiently. For three or more couples, EF1 allocations need not exist.
  Turning to proportionality, we show that, whenever groups have size at most
$k$, a PROP$k$ allocation exists and can be found efficiently. In fact, our
algorithm additionally guarantees (fractional) Pareto optimality, and PROP1 to
the first agent in each group, PROP2 to the second, etc., for an arbitrary
agent ordering. In special cases, we show that there are PROP1 allocations for
any number of couples.

</details>


### [342] [Reactive Users vs. Recommendation Systems: An Adaptive Policy to Manage Opinion Drifts](https://arxiv.org/abs/2508.13473)
*Atefeh Mollabagher,Parinaz Naghizadeh*

Main category: cs.GT

TL;DR: 推荐系统可能影响用户意见。本研究发现，能够自适应调整内容消费选择的“反应性”用户可以通过降低点击概率来防止意见漂移，尤其是在他们优先考虑意见保留时，这种策略比固定策略效果更好。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探讨用户是否能通过自适应调整内容消费选择来抵制推荐系统对其意见的潜在影响，特别是对于那些意识到这种影响的“反应性”用户。

Method: 本研究分析了两种随机策略下用户的意见动态：一种是固定的点击推荐内容的概率的被动策略，另一种是点击概率随意见漂移自适应调整的反应性策略。通过解析推导了这两种策略下的用户预期意见和效用。

Result: 研究表明，反应性策略在用户优先考虑意见保留时，能够有效防止意见漂移，并且相比于固定策略，具有更高的预期效用。

Conclusion: 该研究表明，在用户优先考虑意见保留的情况下，适应性策略可以帮助用户防止意见漂移，并且其预期效用优于固定策略。

Abstract: Recommendation systems are used in a range of platforms to maximize user
engagement through personalization and the promotion of popular content. It has
been found that such recommendations may shape users' opinions over time. In
this paper, we ask whether reactive users, who are cognizant of the influence
of the content they consume, can prevent such changes by adaptively adjusting
their content consumption choices. To this end, we study users' opinion
dynamics under two types of stochastic policies: a passive policy where the
probability of clicking on recommended content is fixed and a reactive policy
where clicking probability adaptively decreases following large opinion drifts.
We analytically derive the expected opinion and user utility under these
policies. We show that the adaptive policy can help users prevent opinion
drifts and that when a user prioritizes opinion preservation, the expected
utility of the adaptive policy outperforms the fixed policy. We validate our
theoretical findings through numerical simulations. These findings help better
understand how user-level strategies can challenge the biases induced by
recommendation systems.

</details>


### [343] [Optimal Candidate Positioning in Multi-Issue Elections](https://arxiv.org/abs/2508.13841)
*Colin Cleveland,Bart de Keijzer,Maria Polukarov*

Main category: cs.GT

TL;DR: 研究多维空间选举中的候选人定位问题，证明了其 NP-hard 性，并提出了多项式时间算法和近似保证。


<details>
  <summary>Details</summary>
Motivation: 研究多维空间投票选举中的策略候选人定位问题。

Method: 对于 $d=2$ 的情况，使用 $O(n^{d+1})$ 超平面枚举算法和 $O(n 	ext{ log } n)$ 径向扫描程序精确求解。此外，还为一般多候选人情况推导了首个近似保证。

Result: 计算新候选人的最优位置 NP-hard，但对于恒定数量的问题是可处理的。

Conclusion: 该研究澄清了多维空间选举的算法格局，并为竞选策略提供了切实可行的工具。

Abstract: We study strategic candidate positioning in multidimensional spatial-voting
elections. Voters and candidates are represented as points in $\mathbb{R}^d$,
and each voter supports the candidate that is closest under a distance induced
by an $\ell_p$-norm. We prove that computing an optimal location for a new
candidate is NP-hard already against a single opponent, whereas for a constant
number of issues the problem is tractable: an $O(n^{d+1})$
hyperplane-enumeration algorithm and an $O(n \log n)$ radial-sweep routine for
$d=2$ solve the task exactly. We further derive the first approximation
guarantees for the general multi-candidate case and show how our geometric
approach extends seamlessly to positional-scoring rules such as $k$-approval
and Borda. These results clarify the algorithmic landscape of multidimensional
spatial elections and provide practically implementable tools for campaign
strategy.

</details>


### [344] [Control by Deleting Players from Weighted Voting Games Is NP^PP-Complete for the Penrose-Banzhaf Power Index](https://arxiv.org/abs/2508.13868)
*Joanna Kaczmarek,Jörg Rothe*

Main category: cs.GT

TL;DR: 加权投票博弈中删除玩家控制的复杂度被确定为NP^PP，这是对现有研究的重大改进。


<details>
  <summary>Details</summary>
Motivation: 为解决加权投票博弈中通过删除玩家来控制博弈的复杂度问题，该研究旨在确定这些问题的计算复杂度，特别是与NP^PP复杂度类。

Method: 通过分析加权投票博弈中删除玩家对博弈控制的复杂度，并使用Penrose-Banzhaf指数作为衡量玩家权力的标准，将某些问题归类到NP^PP复杂度类。

Result: 将加权投票博弈中通过删除玩家来控制博弈的某些问题，在玩家权力使用Penrose-Banzhaf指数衡量时，其复杂度确定为NP^PP，这比之前已知的较低复杂度类有显著提升，并对实际应用中的SAT求解技术提供了更好的保护。

Conclusion: 该研究将加权投票博弈中通过删除玩家来控制博弈的复杂度问题，在玩家权力使用Penrose-Banzhaf指数衡量时，其某些问题被归类为NP^PP（拥有PP（概率多项式时间）谕示机的NP机器可解的问题）。

Abstract: Weighted voting games are a popular class of coalitional games that are
widely used to model real-life situations of decision-making. They can be
applied, for instance, to analyze legislative processes in parliaments or
voting in corporate structures. Various ways of tampering with these games have
been studied, among them merging or splitting players, fiddling with the quota,
and controlling weighted voting games by adding or deleting players. While the
complexity of control by adding players to such games so as to change or
maintain a given player's power has been recently settled, the complexity of
control by deleting players from such games (with the same goals) remained
open. We show that when the players' power is measured by the probabilistic
Penrose-Banzhaf index, some of these problems are complete for NP^PP -- the
class of problems solvable by NP machines equipped with a PP ("probabilistic
polynomial time") oracle. Our results optimally improve the currently known
lower bounds of hardness for much smaller complexity classes, thus providing
protection against SAT-solving techniques in practical applications.

</details>


### [345] [A Mechanism for Mutual Fairness in Cooperative Games with Replicable Resources -- Extended Version](https://arxiv.org/abs/2508.13960)
*Björn Filter,Ralf Möller,Özgür Lütfü Özçep*

Main category: cs.GT

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The latest developments in AI focus on agentic systems where artificial and
human agents cooperate to realize global goals. An example is collaborative
learning, which aims to train a global model based on data from individual
agents. A major challenge in designing such systems is to guarantee safety and
alignment with human values, particularly a fair distribution of rewards upon
achieving the global goal. Cooperative game theory offers useful abstractions
of cooperating agents via value functions, which assign value to each
coalition, and via reward functions. With these, the idea of fair allocation
can be formalized by specifying fairness axioms and designing concrete
mechanisms. Classical cooperative game theory, exemplified by the Shapley
value, does not fully capture scenarios like collaborative learning, as it
assumes nonreplicable resources, whereas data and models can be replicated.
Infinite replicability requires a generalized notion of fairness, formalized
through new axioms and mechanisms. These must address imbalances in reciprocal
benefits among participants, which can lead to strategic exploitation and
unfair allocations. The main contribution of this paper is a mechanism and a
proof that it fulfills the property of mutual fairness, formalized by the
Balanced Reciprocity Axiom. It ensures that, for every pair of players, each
benefits equally from the participation of the other.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [346] [Short-time behavior of a system ruled by non-Hermitian time-dependent Hamiltonians](https://arxiv.org/abs/2508.13194)
*Benedetto Militello,Anna Napoli*

Main category: quant-ph

TL;DR: Analyzed survival probability in non-Hermitian systems to predict quantum Zeno effect in quantum tech.


<details>
  <summary>Details</summary>
Motivation: To analyze the short-time behavior of survival probability in systems governed by time-dependent non-Hermitian Hamiltonians and explore potential applications in quantum technology.

Method: Second-order perturbative approach

Result: A derived expression for the short-time behavior of survival probability, which allows for the prediction of effects like the quantum Zeno effect even in the presence of decay processes.

Conclusion: The study derives the short-time behavior of survival probability for systems with time-dependent non-Hermitian Hamiltonians using a second-order perturbative approach. The derived expression enables the prediction of phenomena like the quantum Zeno effect, even in the presence of decay processes, which has potential applications in quantum technology.

Abstract: The short-time behavior of the survival probability of a system governed by a
time-dependent non-Hermitian Hamiltonian is derived using to the second order
perturbative approach. The resulting expression allows for the analysis of some
situations which could be of interest in the field of quantum technology. For
example, it becomes possible to predict a quantum Zeno effect even in the
presence of decay processes.

</details>


### [347] [Quantum geometric phase with initial state index dependent on space-time curvature](https://arxiv.org/abs/2508.13211)
*Jose Alberto Pereira Frugone*

Main category: quant-ph

TL;DR: A new method for generating quantum geometric phase is proposed, which results in the Schr"odinger equation being equivalent to Einstein's gravitational field equations in the adiabatic approximation.


<details>
  <summary>Details</summary>
Motivation: To introduce a new way of generating the quantum geometric phase.

Method: Generating quantum geometric phase by making the initial base state index dependent on space-time curvature.

Result: The Schr"odinger equation is identical to the trace form of the Einstein gravitational field equations under specific conditions.

Conclusion: The resulting Schr"odinger equation is identical to the trace form of the Einstein gravitational field equations in the adiabatic approximation.

Abstract: We introduce a new way of generating the quantum geometric phase by making
the initial base state index dependent on space-time curvature. We prove that
the resulting Schr\"odinger equation is identical to the trace form of the
Einstein gravitational field equations when we are in the adiabatic
approximation. This particular initial condition was proposed in a previous
work by the author.

</details>


### [348] [A 1.5-Query Lower Bound for the Unitary Synthesis Problem](https://arxiv.org/abs/2508.13215)
*Eric Huang*

Main category: quant-ph

TL;DR: 量子比特酉合成问题在1.5查询设置下的新下界被证明，并具有密码学意义。


<details>
  <summary>Details</summary>
Motivation: 在1.5查询设置下，研究任意n量子比特酉的合成问题，并探索其在量子密码学中的应用。

Method: 提出了一种保守的、基于链接的方法来处理中间查询复杂性，以证明1.5查询设置下的酉合成问题的新下界。

Result: 证明了任意n量子比特酉的合成在1.5查询设置下所需的资源超过分数查询阈值，并表明伪随机量子态在密码学上是安全的，即使在1.5次查询的限制下。

Conclusion: 该研究将一查询下界扩展到分数查询模式，证明了在1.5查询设置下，合成任意n量子比特酉（unitary）的操作所需的资源超过了分数查询阈值，从而在密码学方面，即使对手被限制为1.5次查询，伪随机量子态也仍然是安全的。

Abstract: We prove a new lower bound for the unitary synthesis problem in the so-called
1.5-query setting. Our analysis establishes that any attempt to implement
arbitrary n-qubit unitaries via limited oracle access requires resources that
exceed the fractional query threshold. This result extends the one-query lower
bound of Lombardi, Ma, and Wright (2023) to the fractional query regime, and
introduces a conservative and chaining-based approach to handle intermediate
query complexities. As a consequence, we derive cryptographic implications,
showing that pseudorandom quantum states remain secure against adversaries
restricted to 1.5 queries. Our work provides both conceptual clarification of
fractional-query complexity and practical insights into the design of quantum
cryptographic protocols.

</details>


### [349] [Born's rule deviations from temporal non-local effects](https://arxiv.org/abs/2508.13242)
*C. Dedes*

Main category: quant-ph

TL;DR: 量子系统中的非局域相关性会导致伯恩规则的违反，这在不稳定的状态下表现为生存概率的非指数衰减。


<details>
  <summary>Details</summary>
Motivation: 量子系统中的偏差以及量子-平衡假设失效的情况。

Method: 使用量子-流体动力学框架，研究了量子系统与量子-平衡假设（ρ≠|Ψ|^2）的偏差。

Result: 研究表明，瞬态干涉现象和内在记忆效应会产生有限时间内的非局域相关性，从而导致伯恩规则的违反。这些效应表现为不稳定的状态在中间时间尺度上的生存概率出现非指数衰减。

Conclusion: 本研究结果挑战了量子概率的传统解释，并提出了可能指导未来时间非定域性实验研究的新动力学。

Abstract: We investigate deviations from Born's rule in quantum systems where the
quantum-equilibrium hypothesis, $\rho \neq |\Psi|^2$, fails. Using the
quantum-hydrodynamic framework, we show that transit-interference phenomena and
intrinsic memory effects induce finite-time non-local correlations, resulting
in violations of Born's rule. These effects appear as non-exponential decay in
the survival probability of unstable states at intermediate timescales. Our
findings challenge conventional interpretations of quantum probability and
suggest novel dynamics that could guide future experimental investigations of
temporal non-locality.

</details>


### [350] [Quantum Sampling and Moment Estimation for Transformed Gaussian Random Fields](https://arxiv.org/abs/2508.13879)
*Matthias Deiml,Daniel Peterseim*

Main category: quant-ph

TL;DR: 研究提出了一种量子算法，用于在量子设备上高效采样变换后的高斯随机场，并用于估计各种可观测量。


<details>
  <summary>Details</summary>
Motivation: 为了在量子计算中使用高斯随机场，需要进行强制有界性的逐点变换，这在高斯随机场作为表示微结构的系数场时自然出现。通过在量子设备上直接从少量统计参数生成这种微结构，可以绕过输入瓶颈。

Method: 该方法基于经典移动平均法的增强版本，并通过量子计算实现。

Result: 该方法能够实现变换后高斯随机场的有效量子表示，并以$m{tol} > 0$的精度在$m{O}(	ext{polylog} 	ext{tol}^{-1})$时间内制备近似该随机场的量子态。结合幅度估计和量子伪随机数生成器，可以得到估计线性和非线性可观测量（包括混合高阶矩）的算法，总复杂度为$m{O}(	ext{tol}^{-1} 	ext{polylog} 	ext{tol}^{-1})$。

Conclusion: 该研究提出了一种量子算法，用于在d维域上高效地采样变换后的高斯随机场，该算法基于经典移动平均方法的增强版本。

Abstract: We present a quantum algorithm for efficiently sampling transformed Gaussian
random fields on $d$-dimensional domains, based on an enhanced version of the
classical moving average method. Pointwise transformations enforcing
boundedness are essential for using Gaussian random fields in quantum
computation and arise naturally, for example, in modeling coefficient fields
representing microstructures in partial differential equations. Generating this
microstructure from its few statistical parameters directly on the quantum
device bypasses the input bottleneck. Our method enables an efficient quantum
representation of the resulting random field and prepares a quantum state
approximating it to accuracy $\mathtt{tol} > 0$ in time
$\mathcal{O}(\operatorname{polylog} \mathtt{tol}^{-1})$. Combined with
amplitude estimation and a quantum pseudorandom number generator, this leads to
algorithms for estimating linear and nonlinear observables, including mixed and
higher-order moments, with total complexity $\mathcal{O}(\mathtt{tol}^{-1}
\operatorname{polylog} \mathtt{tol}^{-1})$. We illustrate the theoretical
findings through numerical experiments on simulated quantum hardware.

</details>


### [351] [Quantum algorithms to detect ODMR-active defects for quantum sensing applications](https://arxiv.org/abs/2508.13281)
*Pablo A. M. Casares,Yanbing Zhou,Utkarsh Azad,Stepan Fomichev,Jack S. Baker,Chen Ling,Debasish Banerjee,Alain Delgado,Juan Miguel Arrazola*

Main category: quant-ph

TL;DR: 通过量子算法模拟二维材料中的自旋缺陷，可更有效地筛选用于量子传感的材料。


<details>
  <summary>Details</summary>
Motivation: 为了识别适合量子传感的二维材料中的自旋缺陷，需要模拟缺陷的光学响应和ODMR对比度，但现有方法精度不足。本研究旨在通过量子算法提高模拟的准确性和效率。

Method: 提出两种量子算法，一种通过评估S=0状态在自旋-轨道耦合下的演化诱导ISC到S=1的情况，并分析其强度随最终态自旋投影的变化；另一种通过比较有无自旋-轨道耦合算符时缺陷的发射光谱，并从光谱强度变化推断ISC强度。此外，还提出了一种改进的评估缺陷光学响应的方案。

Result: 研究表明，所提出的量子算法能够检测ISC速率的失衡。在氮化硼的负硼空位缺陷中，使用105个逻辑量子比特和2.2 x 10^8个Toffoli门，可以检测到ISC速率的失衡。该方法通过避免直接计算速率，能够更快地筛选具有ODMR活性的缺陷。

Conclusion: 该研究提出了两种量子算法，用于检测三重态-单重态交错（ISC）速率的失衡，这是实现非零ODMR响应的必要条件。研究展示了这些算法在氮化硼中的负硼空位缺陷上的应用，并给出了所需的量子比特和Toffoli门数量。

Abstract: Spin defects in two-dimensional materials are a promising platform for
quantum sensing. Simulating the defect's optical response and optically
detected magnetic resonance (ODMR) contrast is key to identifying suitable
candidates. However, existing simulation methods are typically unable to supply
the required accuracy. Here, we propose two quantum algorithms to detect an
imbalance in the triplet-to-singlet intersystem crossing (ISC) rates between
excited states with the same and different spin projections -- a necessary
condition for nonzero ODMR response. The lowest-cost approach evaluates whether
the evolution of an $S=0$ state under the spin-orbit coupling induces ISC to
$S=1$, and also whether there is an imbalance in its intensity depending on the
final state spin projection. The second approach works by comparing the
emission spectrum of a spin defect with and without the spin-orbit coupling
operator, inferring ISC intensity for different spin transition channels from
spectrum intensity changes. Additionally, we present an improved scheme to
evaluate the defect's optical response, building upon previous work. We study
these quantum algorithms in the context of the negatively charged boron vacancy
in hexagonal boron nitride. We generate an embedded active space of 18 spatial
orbitals using quantum defect embedding theory (QDET) and show that the ISC
rate imbalance can be detected with as few as 105 logical qubits and $2.2
\times 10^8$ Toffoli gates. By avoiding direct and costly rate calculations,
our methods enable faster screening of candidate defects for ODMR activity,
advancing the prospect of using quantum simulations to aid the development of
high-performing sensing devices.

</details>


### [352] [Proceedings of the 22nd International Conference on Quantum Physics and Logic](https://arxiv.org/abs/2508.13619)
*Alejandro Díaz-Caro,Ognyan Oreshkov,Ana Belén Sainz*

Main category: quant-ph

TL;DR: The 22nd International Conference on Quantum Physics and Logic (QPL 2025) proceedings are available, focusing on the mathematical foundations of quantum computation and physics using algebraic and categorical structures.


<details>
  <summary>Details</summary>
Motivation: To bring together researchers working on the mathematical foundations of quantum computation, quantum physics, and related areas.

Method: The conference brought together academic and industry researchers focusing on the mathematical foundations of quantum computation, quantum physics, and related areas, with an emphasis on algebraic and categorical structures, formal languages, semantic methods, and other mathematical and computer scientific techniques applicable to the study of physical systems, processes, and their composition.

Result: The proceedings of the 22nd International Conference on Quantum Physics and Logic (QPL 2025) held in Varna, Bulgaria.

Conclusion: The volume contains the proceedings of the 22nd International Conference on Quantum Physics and Logic (QPL 2025).

Abstract: This volume contains the proceedings of the 22nd International Conference on
Quantum Physics and Logic (QPL 2025), which was held from 14th to 18th July
2025, in Varna, Bulgaria, organised by Universit\'e libre de Bruxelles. QPL is
an annual conference that brings together academic and industry researchers
working on the mathematical foundations of quantum computation, quantum
physics, and related areas. The main focus is on the use of algebraic and
categorical structures, formal languages, semantic methods, as well as other
mathematical and computer scientific techniques applicable to the study of
physical systems, physical processes, and their composition.

</details>


### [353] [Quantum Walk on a Line with Absorbing Boundaries](https://arxiv.org/abs/2508.13318)
*Ammara Ammara,Václav Potoček,Martin Štefaňák,Francesco V. Pepe*

Main category: quant-ph

TL;DR: 研究了有限线上的两态量子行走吸收问题，推导了吸收概率的封闭公式，并进行了数值验证。


<details>
  <summary>Details</summary>
Motivation: 研究了有限线上的两态量子行走吸收问题。

Method: 推导了大型系统尺寸N的吸收概率的封闭公式。

Result: 吸收概率不仅取决于硬币角度，还取决于初始状态是硬币算子的特征态的概率。对于小型系统尺寸N，吸收到边界的收敛速度呈指数级增长。

Conclusion: 吸收概率不仅取决于硬币角度，还取决于初始状态是硬币算子的特征态的概率。

Abstract: Absorption of two-state quantum walks on a finite line is investigated. We
consider a symmetric configuration, with two sinks located at $N$ and $-N$ and
the quantum walker starting in the middle. Elaborating on the results of Konno
et al., J. Phys. A: Math. Gen. 36 241 (2003), we derive closed formulas for the
absorption probabilities at the boundaries in the limit of large system size
$N$. It is shown that the absorption depends, apart from the coin angle, only
on the probability that the initial state is one of the eigenstates of the coin
operator. Finally, we perform an extensive numerical investigation for small
system size $N$, showing that the convergence to the analytical result is
exponentially fast.

</details>


### [354] [Callan-Symanzik-like equation in information theory](https://arxiv.org/abs/2508.13330)
*Mojtaba Shahbazi,Mehdi Sadeghi*

Main category: quant-ph

TL;DR: 本体场（bulk fields）通过影响能量动量张量散度、剪切粘度和Weyl异常，控制复杂性增长率（CGR）的跳跃行为。CGR的临界行为和满足的Callan-Symanzik类方程表明，通过调整能量尺度，可以提升计算速度，甚至超越量子计算机。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂性增长率（CGR）中的跳跃现象及其与本体场（bulk fields）的联系，理解能量尺度对信息处理速度的影响。

Method: 通过“复杂性=任何事物”的提议，研究了复杂性增长率（CGR）中的跳跃现象，并将本体场的能量动量张量散度、剪切粘度和边界理论的Weyl异常与其行为联系起来。

Result: 本体场（bulk fields）决定了复杂性增长率（CGR）跳跃的高度和位置，具体表现为能量动量张量散度、剪切粘度和Weyl异常。CGR围绕跳跃点表现出临界行为和临界指数，并满足类似Callan-Symanzik的方程，暗示能量尺度可以调节信息处理速度，甚至超越当前量子计算机。

Conclusion: 该研究揭示了复杂性增长率（CGR）在复杂性=任何事物（complexity=anything）提议中存在的跳跃现象，并指出本体场（bulk fields）对此类跳跃的高度和位置起着决定性作用。

Abstract: In this paper, we consider the jumps in the complexity growth rate (CGR)
through the complexity=anything proposal. It is revealed that bulk fields are
in charge of the height and the location of these jumps. To put it accurately,
their counterparts are divergence of energy momentum tensor, shear viscosity
and the Weyl anomaly of the boundary theory. The behavior of CGR around these
jumps manifests a critical behavior and critical exponents. Moreover, it is
figured out that CGR satisfies a Callan-Symanzik-like equation around these
jumps. This equation suggests that the speed of information processing could be
changed by the scale of energy. Put it another way, by change of the scale of
energy one could turn the classical computers into faster processor computers
even faster than our current quantum computers.

</details>


### [355] [A blueprint for experiments exploring the Poincaré quantum recurrence theorem](https://arxiv.org/abs/2508.13489)
*Bayan Karimi,Xuntao Wu,Andrew N. Cleland,Jukka P. Pekola*

Main category: quant-ph

TL;DR: An N-qubit system returns to its initial state over time, but the time required grows exponentially with the number of qubits, making it impractical for large systems.


<details>
  <summary>Details</summary>
Motivation: The motivation is to experimentally test the quantum form of the Poincaré recurrence theorem using qubit systems, which are isolated from their dissipative surroundings.

Method: The paper presents quantitative analytical and numerical results to investigate the revival probability and time in an N-qubit system.

Result: The system returns arbitrarily close to its initial state in a finite time, with revival times that become astronomically large for systems with just a few tens of qubits.

Conclusion: The study demonstrates that an N-qubit system, weakly coupled to its environment, exhibits the phenomenon of Poincaré recurrence, returning arbitrarily close to its initial state in a finite time. The revival time scales exponentially with the number of qubits N.

Abstract: The quantum form of the Poincar\'e recurrence theorem stipulates that a
system with a time-independent Hamiltonian and discrete energy levels returns
arbitrarily close to its initial state in a finite time. Qubit systems, being
highly isolated from their dissipative surroundings, provide a possible
experimental testbed for studying this theoretical construct. Here we
investigate a $N$-qubit system, weakly coupled to its environment. We present
quantitative analytical and numerical results on both the revival probability
and time, and demonstrate that the system indeed returns arbitrarily close to
its initial state in a time exponential in the number of qubits $N$. The
revival times become astronomically large for systems with just a few tens of
qubits. Given the lifetimes achievable in present-day superconducting
multi-qubit systems, we propose a realistic experimental test of the theory and
scaling of Poincar\'e revivals.

</details>


### [356] [Expectation value dynamics within real Hilbert space quantum mechanics](https://arxiv.org/abs/2508.13332)
*Sergio Giardino*

Main category: quant-ph

TL;DR: The real Hilbert space approach to quantum mechanics is consistent, even with complex or quaternionic wave functions. New operators suggest further research directions.


<details>
  <summary>Details</summary>
Motivation: This paper examines dynamic equations concerning physical expectation values within the real Hilbert space approach to quantum mechanics, exploring its consistency and introducing new generalized operators.

Method: We examined the dynamic equations for physical expectation values using the real Hilbert space approach to quantum mechanics, considering both complex and quaternionic wave functions.

Result: The consistency of the real Hilbert space approach has been verified. Generalized position and angular momentum operators have been introduced, inspiring future research.

Conclusion: We have verified the consistency of the real Hilbert space approach by examining the continuity equation, classical limit, and generalizations of the quantum Lorentz force and Virial theorem. We have also introduced generalized position and angular momentum operators, opening up exciting avenues for future research.

Abstract: Dynamic equations concerning physical expectation values have been examined
in terms of the real Hilbert space approach to quantum mechanics. The
considered cases involve complex wave functions, as well as quaternionic wave
functions. The consistency of the formalism has been verified in terms of the
continuity equation, the classical limit, and generalizations of the quantum
Lorentz force, and the Virial theorem. Besides testing the consistency of the
real Hilbert space approach, generalized position and angular momentum
operators have been introduced, and inspire exciting directions for further
research.

</details>


### [357] [Portfolio construction using a sampling-based variational quantum scheme](https://arxiv.org/abs/2508.13557)
*Gabriele Agliardi,Dimitris Alevras,Vaibhaw Kumar,Roberto Lo Nardo,Gabriele Compostella,Sumit Kumar,Manuel Proissl,Bimal Mehta*

Main category: quant-ph

TL;DR: 该研究使用变分量子算法（VQA）和局部搜索来优化具有挑战性的投资组合构建问题，在IBM量子处理器上实现了0.49%的解误差，优于纯经典方法。


<details>
  <summary>Details</summary>
Motivation: 在金融领域，构建满足现实世界约束的投资组合是一项具有挑战性的优化任务。

Method: 研究评估了采样基础的条件风险价值（CVaR）变分量子算法（VQA），并结合了局部搜索后处理，用于解决经典上困难的问题实例。还提出了一种适用于采样基础VQA的问题表述。

Result: 在IBM Heron处理器上进行的公用设施规模的实验，涉及109个量子比特和多达4200个门，实现了0.49%的相对解误差。结果表明，结合量子-经典工作流比纯粹经典的局部搜索具有更高的准确性，并且难以模拟的量子电路可能比简单的电路带来更好的收敛性。

Conclusion: 该研究为使用量子计算机进行投资组合构建铺平了道路。

Abstract: The efficient and effective construction of portfolios that adhere to
real-world constraints is a challenging optimization task in finance. We
investigate a concrete representation of the problem with a focus on design
proposals of an Exchange Traded Fund. We evaluate the sampling-based CVaR
Variational Quantum Algorithm (VQA), combined with a local-search
post-processing, for solving problem instances that beyond a certain size
become classically hard. We also propose a problem formulation that is suited
for sampling-based VQA. Our utility-scale experiments on IBM Heron processors
involve 109 qubits and up to 4200 gates, achieving a relative solution error of
0.49%. Results indicate that a combined quantum-classical workflow achieves
better accuracy compared to purely classical local search, and that
hard-to-simulate quantum circuits may lead to better convergence than simpler
circuits. Our work paves the path to further explore portfolio construction
with quantum computers.

</details>


### [358] [All-mechanical coherence protection and fast control of a spin qubit](https://arxiv.org/abs/2508.13356)
*Eliza Cornell,Zhujing Xu,Zhaoyou Wang,Hana K. Warner,Eliana Mann,Michael Haas,Smarak Maity,Graham Joe,Liang Jiang,Peter Rabl,Benjamin Pingault,Marko Lončar*

Main category: quant-ph

TL;DR: 通过将固态自旋量子比特置于“耦合”基态，实现了与声子腔的兼容以及对低频噪声的抑制，从而延长了相干时间并实现了超快量子控制。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有声学量子网络中自旋与谐振声子腔的耦合以及抑制低频噪声以延长自旋相干时间的兼容性问题。

Method: 通过在“耦合”基态下进行初始化、量子操作和读出来实现固态自旋量子比特的全机械相干保护，该基态能抑制低频噪声并与声子腔兼容。

Result: 实现了全机械相干保护的固态自旋量子比特，拉比频率达到800 MHz，为高保真度的声子介导量子门和片上量子声子网络的发展迈出了关键一步。

Conclusion: 该研究展示了一种全机械相干保护的固态自旋量子比特，该量子比特在与声子腔兼容且能抑制低频噪声的“耦合”基态下进行初始化、量子操作和读出，实现了800 MHz的拉比频率，为高保真度的声子介导量子门和片上量子声子网络奠定了基础。

Abstract: In a phononic quantum network, quantum information is stored and processed
within stationary nodes defined by solid-state spins, and the information is
routed between nodes by phonons. The phonon holds distinct advantages over its
electromagnetic counterpart the photon, including smaller device footprints,
reduced crosstalk, long coherence times at low temperatures, and strong
interactions with both solid-state spins and electromagnetic waves. Enhanced
interactions between a phononic cavity and a stationary qubit have been
demonstrated in multiple platforms including superconducting qubits, spins in
silicon carbide and spins in diamond. However, an outstanding issue is the
compatibility between the spin's coupling to the resonant phononic cavity and
the simultaneous use of pulse sequences to extend the coherence time of the
spin by suppressing the low-frequency environmental noise. Here we demonstrate
all-mechanical coherence protection of a solid-state spin qubit, where optical
initialization, quantum operations, and readout are performed in a dressed
basis that is highly immune to low-frequency noise and compatible with a
phononic cavities. We additionally show record-high Rabi frequencies reaching
800 MHz, which allows for ultrafast quantum control. Our results establish a
first step for high-fidelity, phonon-mediated quantum gates and represent a
crucial advance toward robust on-chip quantum phononic networks.

</details>


### [359] [Beyond Copenhagen: Following the Trail of Decoherence in Feynman's Light Microscope](https://arxiv.org/abs/2508.13385)
*Brian C. Odom*

Main category: quant-ph

TL;DR: 未坍缩的量子力学在解释宏观世界方面有潜力，但“波函数坍缩”的具体作用仍需进一步探讨。


<details>
  <summary>Details</summary>
Motivation: 重新思考在量子力学中“波函数坍缩”的必要性，以及我们对量子力学的期望。

Method: 以纠缠系统的观点，利用“退相干理论”来分析对干涉仪的观察导致“条纹丢失”的现象。

Result: 未坍缩的量子力学在解释宏观世界及其确定性结果方面具有相当大的潜力。

Conclusion: “波函数坍缩”可能是预测宏观世界和其确定性结果的工具，而非对微观现实的描述。

Abstract: Feynman's light microscope invites us to reconsider what we thought we knew
about quantum reality. Rather than invoking wavefunction collapse to predict
the loss of fringes in a monitored interferometer, Feynman analyzes the problem
in terms of a disturbance. This approach raises the question of whether the
classical world, including its localized particles and definite measurement
outcomes, might emerge as the universe evolves smoothly according to \ss.
Treating the particle and its environment as an entangled system, unmodified
quantum mechanics shows remarkable success toward this end. This is the purview
of decoherence theory. The question of wavefunction collapse then becomes one
of what we want from the theory. Do we expect it to describe microscopic
reality, or do we consider it to be only a tool for predicting measurement
outcomes? Both options are uncomfortable. When applied to unmodified quantum
mechanics, the first implies that each moment in time branches into a vast
number of divergent macroscopic realities. While the second represents, for
most practitioners, a weakened view of science. This article is written to be
accessible to anyone with an undergraduate course in quantum mechanics.

</details>


### [360] [Chaos and quantum regimes in $n$-photon driven, dissipative bosonic chains](https://arxiv.org/abs/2508.13398)
*Leo Kruglikov,Filippo Ferrari,Vincenzo Savona*

Main category: quant-ph

TL;DR: 研究了 n 光子驱动对边界驱动、耗散玻色链的影响，发现了混沌流体动力学和非混沌共振非线性波（RNW）两种机制，并提出了量子态工程的新途径。


<details>
  <summary>Details</summary>
Motivation: 研究多光子驱动如何影响量子涨落、非线性相互作用以及耗散过程在驱动耗散量子系统中的相互作用。

Method: 利用截断的 Wigner 近似法，研究了边界驱动、耗散玻色链在 n 光子驱动下的稳态动力学机制。

Result: 识别出混沌流体动力学机制和非混沌共振非线性波（RNW）机制两种主要机制。研究结果为在驱动耗散量子设备中进行量子态工程提供了新的途径。

Conclusion: 该研究揭示了两种主要的动力学机制：一种是混沌流体动力学机制，其特征是局部 U(1) 对称性恢复、克尔非线性导致的饱和以及空间预热；另一种是非混沌的共振非线性波（RNW）机制，其特征是亚泊松统计、持续的 Z_n 对称性以及量子驱动的相位退相干。研究结果表明流体动力学机制具有普遍性，而 RNW 机制则对边界驱动条件敏感，这为在驱动耗散量子设备中进行量子态工程提供了新的途径。该研究结果与先进的电路量子电动力学平台具有实验相关性。

Abstract: We investigate the steady-state dynamical regimes of boundary-driven,
dissipative bosonic chains subjected to $n$-photon drives. Using the truncated
Wigner approximation, we explore how multi-photon drives shape the interplay
between quantum fluctuations, nonlinear interactions, and dissipative processes
in such quantum systems. We identify two main regimes: a chaotic hydrodynamic
regime characterized by the restoration of a local $\mathbb{U}(1)$ symmetry,
photon saturation due to Kerr nonlinearity, and spatial prethermalization
effects; and a non-chaotic resonant nonlinear wave (RNW) regime exhibiting
sub-Poissonian photon statistics, persistent $\mathbb{Z}_n$ symmetry, and
quantum-driven phase decoherence. Our findings reveal the universal nature of
the hydrodynamic regime and highlight the RNW regime's sensitivity to boundary
driving conditions, suggesting novel routes for quantum state engineering in
driven-dissipative quantum devices. These results are experimentally relevant
for state-of-the-art circuit quantum electrodynamics platforms.

</details>


### [361] [Enhanced Sensitivity and Noise Resilience in Two-Qubit Quantum Magnetometers](https://arxiv.org/abs/2508.13400)
*S. Nohekhan Shishavan,K. Aghayar Gharehbagh,H. Sedgi Gamichi*

Main category: quant-ph

TL;DR: 提出了一种新颖的双量子比特量子磁力计，具有更高的灵敏度和抗噪声能力。


<details>
  <summary>Details</summary>
Motivation: 提出一种具有增强的灵敏度和抗噪声能力的量子磁力计。

Method: 提出了一种新颖的、经过优化的双量子比特量子磁力计哈密顿量，并使用解析方法推导了量子费舍尔信息（QFI）和信噪比（SNR）。

Result: 该方法在精度、抗噪声能力和纠缠动力学方面优于现有模型，并验证了其在磁场传感中的实用性。

Conclusion: 我们的方法通过提高精度、抗噪性和纠缠动力学来为磁场传感领域提供实际可行的解决方案。

Abstract: We present a novel two-qubit quantum magnetometer Hamiltonian optimized for
enhanced sensitivity and noise resilience. Compared to existing models, our
formulation offers advantages in accuracy, robustness against noise, and
entanglement dynamics. Using analytical methods, we derive the Quantum Fisher
Information (QFI) and the Signal-to-Noise Ratio (SNR), highlighting its
practical viability for magnetic field sensing. Our approach bridges
theoretical insights with real-world applicability. We further analyze the
performance of the magnetometer with a different initial entangled state,
revealing the benefits of entanglement for sensitivity. A comparative analysis
with leading research in the field underscores the advancements offered by our
proposed design. Finally, we discuss the limitations of our current study and
suggest potential avenues for future research.

</details>


### [362] [PennyLane-Lightning MPI: A massively scalable quantum circuit simulator based on distributed computing in CPU clusters](https://arxiv.org/abs/2508.13615)
*Ji-Hoon Kang,Hoon Ryu*

Main category: quant-ph

TL;DR: PennyLane-Lightning MPI是一个MPI扩展，可以扩展PennyLane-Lightning以模拟量子电路。


<details>
  <summary>Details</summary>
Motivation: 量子电路模拟在理论量子算法与实际量子硬件之间架起了一座桥梁，但随着量子比特数量的增加，量子态空间的指数增长带来了计算挑战。

Method: 该工作提出了一种基于索引和门操作的并行化策略，该策略充分利用了单个门操作的特性以及与分区量子态向量中的量子比特索引相关的计算局部性。

Result: 基准测试表明，该方法相比于通用的基于酉矩阵操作的方法具有性能优势，并且扩展性优异，支持了多达41个量子比特和数十万个并行进程的模拟。

Conclusion: 该工作为PennyLane-Lightning套件开发了一个MPI扩展，名为PennyLane-Lightning MPI，能够通过在分布式内存系统上并行化量子态向量和门操作来实现可扩展的量子电路模拟。

Abstract: Quantum circuit simulations play a critical role in bridging the gap between
theoretical quantum algorithms and their practical realization on physical
quantum hardware, yet they face computational challenges due to the exponential
growth of quantum state spaces with increasing qubit size. This work presents
PennyLane-Lightning MPI, an MPI-based extension of the PennyLane-Lightning
suite, developed to enable scalable quantum circuit simulations through
parallelization of quantum state vectors and gate operations across
distributed-memory systems. The core of this implementation is an
index-dependent, gate-specific parallelization strategy, which fully exploits
the characteristic of individual gates as well as the locality of computation
associated with qubit indices in partitioned state vectors. Benchmarking tests
with single gates and well-designed quantum circuits show that the present
method offers advantages in performance over general methods based on unitary
matrix operations and exhibits excellent scalability, supporting simulations of
up to 41-qubit with hundreds of thousands of parallel processes. Being equipped
with a Python plug-in for seamless integration to the PennyLane framework, this
work contributes to extending the PennyLane ecosystem by enabling
high-performance quantum simulations in standard multi-core CPU clusters with
no library-specific requirements, providing a back-end resource for the
cloud-based service framework of quantum computing that is under development in
the Republic of Korea.

</details>


### [363] [Application of Optimal Control to Time-Resolution Protocol for Quantum Sensing](https://arxiv.org/abs/2508.13405)
*Chungwei Lin,Qi Ding,Yanting Ma*

Main category: quant-ph

TL;DR: Quantum sensing needs to measure fast field variations quickly. This paper uses optimal control to find the best measurement strategy. It finds different strategies work best for short vs. long measurement times. A new "detune protocol" is proposed for faster measurements that is easier to do in experiments.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the need for high field sensitivity in short interrogation times for time-resolution protocols in quantum sensing, and aims to optimize these protocols by considering end-to-end measurement processes and practical experimental limitations.

Method: Optimal control theory is applied to optimize the time-resolution protocol. Protocols based on maximizing Quantum Fisher Information are constructed to highlight differences between theoretical and practical measurements.

Result: The analysis reveals a critical interrogation time $T^*$. For $	au<T^*$, the optimal protocol is bang-bang; for $	au>T^*$, it involves singular control. A smooth "detune protocol" is proposed for the $	au<T^*$ regime, which is more practical for experiments.

Conclusion: The study proposes a "detune protocol" for high time resolution, which uses smooth control and is expected to be practically useful. In the long interrogation time regime, optimal protocols resemble Ramsey sequences, and Quantum Fisher Information is used to compare theoretically optimal and practically implementable measurements.

Abstract: Time-resolution protocol of quantum sensing aims to measure the fast temporal
variation of an external field and demands a high field sensitivity in a short
interrogation time $\tau$. Since any operation that evolves the quantum state
takes time and is counted as part of the interrogation, evaluating the
performance of time-resolution protocol requires a complete end-to-end
description of the measurement process. In particular, the initial state has to
be one of the sensor qubit's eigenstates in the absence of external fields, and
the final projective measurements must be performed in the same eigenstate
basis. Building upon prior works which proposed limits for time-resolved
sensing using a quantum sensor, we apply optimal control theory to optimize the
time-resolution protocol. Our analysis indicates that there exists a critical
interrogation time $T^*$: when $\tau<T^*$ the optimal protocol is purely
bang-bang; when $\tau>T^*$ the optimal protocol involves a singular control
during the interrogation. In the short-$\tau$ regime, which is relevant to high
time resolution, we propose a ``detune protocol'' that involves only smooth
control during the entire interrogation. As the discontinuities of control pose
the main obstacles to experimental realization, we expect the presented detune
protocol to be practically useful. In the long-$\tau$ regime, the optimal
protocol closely resembles the Ramsey sequence; protocols based on maximizing
Quantum Fisher Information are constructed to highlight the difference between
the theoretically optimal and practically implementable measurements. Effective
use of the time-resolution protocol requires a setup where the unknown
time-domain signal of interest can be identically and repeatedly generated. As
a potentially relevant application, we outline the calibration of baseband flux
pulse distortion in the control of superconducting qubits.

</details>


### [364] [Bell Inequality Violations Without Entanglement? It's Just Postselection](https://arxiv.org/abs/2508.13431)
*Ken Wharton,Huw Price*

Main category: quant-ph

TL;DR: Wang等人的无纠缠贝尔不等式违反结果是由于后选择产生的，这并非对局域实在性的挑战，因为后选择违反了贝尔的统计独立性假设。


<details>
  <summary>Details</summary>
Motivation: 分析Wang等人声称的无纠缠贝尔不等式违反的有效性，并解释其原因。

Method: 提出一个经典的类比实验，并与Wang等人的量子实验进行比较，证明两者产生相似的结果，都源于后选择。

Result: Wang等人的结果是后选择的产物，一个经典的玩具模型也能产生相同的结果，这表明其结果并非对局域实在性的挑战。

Conclusion: Wang等人最近报告的结果是由于后选择产生的，后选择会拒绝贝尔统计独立性假设，因此他们的结果并不对局域实在性构成挑战。

Abstract: Recently Wang et al. have reported a violation of a Bell inequality without
entanglement [arXiv:2507.07756]. We show that their result is an artifact of
postselection. It is well known that postselection may yield Bell inequality
violations, both in classical toy models and in real experiments with
delayed-choice entanglement-swapping. Here we describe a classical analog of
Wang et al.'s experiment, and show that it produces essentially the same
results as their quantum version. We explain in detail why neither version is a
challenge to Local Causality or local realism: the postselection entails a
rejection of Bell's assumption of Statistical Independence.

</details>


### [365] [Quantum Limited Spatial Resolution of NV-Diamond Magnetometry](https://arxiv.org/abs/2508.13438)
*Nico Deshler,Declan Daly,Ayan Majumder,Kasturi Saha,Saikat Guha*

Main category: quant-ph

TL;DR: 该研究提出了一种新的光学传感协议（SPADE），能够更精确地定位和测量亚衍射尺度下的NV中心，显著提高了传感精度。


<details>
  <summary>Details</summary>
Motivation: 为了克服现有基于成像的磁力、热和应变传感技术中，对亚衍射尺度下固态缺陷（如NV中心）荧光监测的限制，以实现对原子尺度特征和动力学的监测。

Method: 本研究采用光学空间模式解复用（SPADE）技术，结合点扩散函数（PSF）适配空间模式和Yuen-Kennedy-Lax（YKL）空间模式，提出了一种两级传感协议，以提高亚衍射尺度下发射器亮度和位置估计的精度。

Result: 所提出的SPADE协议能够显著提高对紧密约束（远低于衍射极限）的NV中心集束的定位精度（提高6倍）和亮度估计精度（提高2倍），优于传统的焦平面强度测量方法。

Conclusion: 该协议通过投影入射光场，实现了对衍射极限以下尺度上发射器位置和亮度的精确提取，与传统方法相比，发射器定位精度提高了6倍，亮度估计精度提高了2倍。

Abstract: Optically addressable ensembles of solid-state defects, such as nitrogen
vacancy (NV) centers, are a leading modality for imaging-based magnetometry,
thermometry and strain sensing. However, monitoring the fluorescence of
individual defects within a sub-diffraction ensemble remains an outstanding
challenge that currently limits access to atomic-scale features and dynamics.
For compact clusters of NVs, imaging-based atomic sensing may be formulated as
a low-dimensional multiparameter estimation task in which one seeks to localize
each defect and quantify the field strength in its immediate vicinity. In this
work, we employ optical spatial mode demultiplexing (SPADE) to enhance
localization and brightness estimation accuracy at sub-diffraction scales.
Specifically, we develop a two-stage sensing protocol that augments direct
imaging by projecting the incoming optical field onto point spread function
(PSF)-adapted spatial modes and Yuen-Kennedy-Lax (YKL) spatial modes, enabling
efficient extraction of emitter positions and brightnesses. We numerically
evaluate the statistical performance of our protocol for sub-diffraction
optically detected magnetic resonance (ODMR) and Rabi sensing experiments.
Compared to conventional focal plane intensity measurements, our protocol
improves emitter localization accuracy by $6\times$ and brightness estimation
accuracy by $2\times$ for tightly confined ensembles, residing well below the
diffraction limit.

</details>


### [366] [Autoregressive Typical Thermal States](https://arxiv.org/abs/2508.13455)
*Tarun Advaith Kumar,Leon Balents,Timothy H. Hsieh,Roger G. Melko*

Main category: quant-ph

TL;DR: Autoregressive models can simulate quantum thermal properties, but need stabilization techniques (unitary evolution, thresholding) to avoid numerical issues. The improved method accurately calculates properties for the XY chain.


<details>
  <summary>Details</summary>
Motivation: Inspired by the success of autoregressive models in natural language processing, this work explores their application to quantum many-body systems, aiming to leverage their scaling capabilities for simulations.

Method: The paper introduces an autoregressive framework using imaginary-time evolution of an ensemble of pure states. It addresses numerical instabilities by evolving initial ensemble states with a unitary operation and applying a threshold to control ensemble member evolution.

Result: The autoregressive framework, with the implemented mitigation strategies, successfully calculates thermal observables for the spin 1/2 quantum XY chain, showing accuracy comparable to exact results.

Conclusion: The study demonstrates that autoregressive typical thermal states, when combined with unitary evolution and thresholding, can accurately calculate thermal observables for quantum systems, mitigating numerical instabilities found in previous approaches.

Abstract: A variety of generative neural networks recently adopted from machine
learning have provided promising strategies for studying quantum matter. In
particular, the success of autoregressive models in natural language processing
has motivated their use as variational ans\"atze, with the hope that their
demonstrated ability to scale will transfer to simulations of quantum many-body
systems. In this paper, we introduce an autoregressive framework to calculate
finite-temperature properties of a quantum system based on the imaginary-time
evolution of an ensemble of pure states. We find that established approaches
based on minimally entangled typical thermal states (METTS) have numerical
instabilities when an autoregressive recurrent neural network is used as the
variational ans\"atz. We show that these instabilities can be mitigated by
evolving the initial ensemble states with a unitary operation, along with
applying a threshold to curb runaway evolution of ensemble members. By
comparing our algorithm to exact results for the spin 1/2 quantum XY chain, we
demonstrate that autoregressive typical thermal states are capable of
accurately calculating thermal observables.

</details>


### [367] [Noise-Resilient Spatial Search with Lackadaisical Quantum Walks](https://arxiv.org/abs/2508.13462)
*Gabriel M. O. Vieira,Nelson Maculan,Franklin de L. Marquezino*

Main category: quant-ph

TL;DR: 自环增强了量子行走在噪声环境下的搜索能力。


<details>
  <summary>Details</summary>
Motivation: 本研究旨在探究断链退相干对 LQW 空间搜索性能的影响，并评估自环在其中起到的作用。

Method: 通过数值模拟研究了断链退相干对二维环状网格上基于 LQW 的搜索性能的影响。

Result: 数值模拟结果显示，退相干会使无环路行走趋向于均匀分布并丧失搜索能力，但自环的存在显著缓解了这一效应，提高了 LQW 在噪声环境下的鲁棒性。

Conclusion: 该研究表明，在存在噪声的情况下，自环可以增强量子行走（LQW）的鲁棒性，使其在二维环状网格上进行空间搜索时，即使在退相干的影响下，标记顶点也能够以高于均匀分布的概率被识别，从而扩展了 LQW 的优势范围，并巩固了自环作为设计弹性量子搜索算法的宝贵资源。

Abstract: Quantum walks are a powerful framework for the development of quantum
algorithms, with lackadaisical quantum walks (LQWs) standing out as an
efficient model for spatial search. In this work, we investigate how
broken-link decoherence affects the performance of LQW-based search on a
two-dimensional toroidal grid. We show through numerical simulations that,
while decoherence drives the loopless walk toward a uniform distribution and
eliminates its search capability, the inclusion of self-loops significantly
mitigates this effect. In particular, even under noise, the marked vertex
remains identifiable with probability well above uniform, demonstrating that
self-loops enhance the robustness of LQWs in realistic scenarios. These
findings extend the known advantages of LQWs from the noiseless setting to
noisy environments, consolidating self-loops as a valuable resource for
designing resilient quantum search algorithms.

</details>


### [368] [Genuine multipartite entanglement verification with convolutional neural networks](https://arxiv.org/abs/2508.13463)
*Yi-Jun Luo,Xuan Leng,Chengjie Zhang*

Main category: quant-ph

TL;DR: 本研究使用改进的卷积神经网络（CNN）有效检测量子多方纠缠态，显著提高了准确率并减少了误报。


<details>
  <summary>Details</summary>
Motivation: 近年来，利用机器学习检测多方真实纠缠态（GME）的研究较少，本研究旨在填补这一空白。

Method: 本研究采用卷积神经网络（CNN）和增强型CNN（集成SE模块）来检测多方真实纠缠态（GME）。研究通过半定规划方法生成了4到6个量子比特的多方真实纠缠态和4到20个量子比特的GHZ对角态，并评估了分类准确性。

Result: 集成SE模块的CNN在多方真实纠缠态检测任务上表现出更高的训练性能和分类准确性。研究还分析了假阳性和假阴性情况，并确认了所提出的方法能够有效减少将非纠缠态误判为纠缠态的概率。

Conclusion: 本研究通过集成SE模块显著提高了CNN在多方纠缠态检测中的训练性能，并降低了将非纠缠态错误分类为纠缠态的可能性。

Abstract: In recent years, the detection of genuine multipartite entanglement (GME) via
machine learning has received scant attention. Here, we employ convolutional
neural networks (CNNs), as well as CNNs enhanced with squeeze-and-excitation
(SE) to detect GME. We randomly generated GME states with 4 to 6 qubits and
GHZ-diagonal states ranging from 4 to 20 qubits using the semidefinite
programming approach. Subsequently, we assessed their classification accuracy.
Our results demonstrate that the integration of the SE module significantly
improved training performance. Additionally, we conducted an analysis of false
positive and false negative occurrences. Utilizing our training data, we have
substantially reduced the likelihood of incorrectly classifying non-entangled
states as entangled.

</details>


### [369] [Asymptotic freedom of dephased charging](https://arxiv.org/abs/2508.13497)
*Chayan Purkait,B. Prasanna Venkatesh,Gentaro Watanabe*

Main category: quant-ph

TL;DR: 量子电池的能量提取效率随着量子比特数量的增加而提高，在大量量子比特的情况下接近100%的能量提取。


<details>
  <summary>Details</summary>
Motivation: 量子电池作为基于量子系统的小型储能装置，有潜力通过量子效应（如相干性和集体性）来提升充电性能。

Method: 研究了由N个量子比特组成的量子电池在星形配置中与驱动的量子比特充电器耦合的集体充电过程，并对充电器上的受控纯粹退相干进行了研究。

Result: Ergotropy/Energy比率随量子比特数量N的增加而增加，并渐近地趋近于1（比例为1 - O(1/N)）。

Conclusion: 研究表明，量子电池中的“渐近自由”行为，即所有输入能量都可以作为功提取出来，使得满足Ergotropy/Energy比率接近1，这是由集体的电池系统近似简并基态导致的，尽管电池状态仍然是混合的。

Abstract: Quantum batteries, small-scale energy storage devices based on quantum
systems, offer the potential for enhanced charging performance through quantum
effects such as coherence and collectivity. In this work, we study the
collective charging of a quantum battery consisting of N qubits, coupled to a
driven qubit charger in a star configuration, with controlled pure dephasing
acting on the charger. We investigate how an "asymptotic freedom"-like
behavior, in which all the energy deposited into the battery can be extracted
as work, resulting in the ergotropy-to-energy ratio approaching unity, can
emerge in the steady state of the battery. We show that the ergotropy-to-energy
ratio increases with the number of qubits and approaches unity asymptotically
as 1 - O(1/N). In the large-N limit, the emergence of approximate ground-state
degeneracy of the collective battery system leads to this asymptotic freedom
behavior, despite the battery state remaining mixed. We also discuss the
scaling behavior of the charging time of the battery with N.

</details>


### [370] [Schrödingerization for quantum linear systems problems](https://arxiv.org/abs/2508.13510)
*Yin Yang,Yue Yu,Long Zhang*

Main category: quant-ph

TL;DR: 该研究提出了一种基于Schr"odingerization和LCHS方法的量子算法，用于求解线性代数方程组Ax=b，并结合了量子预处理技术，有效解决了泊松方程的离散化问题。


<details>
  <summary>Details</summary>
Motivation: 本研究的动机在于探索将Schr"odingerization方法应用于解决线性代数方程组Ax=b，并将其与现有的量子算法（如LCHS方法）进行比较，以期利用计算PDE的成熟技术来开发新的量子算法，从而推动量子科学计算的发展。

Method: 本研究提出了一种量子算法，将求解线性代数方程组Ax=b的问题转化为Schr"odingerization形式问题，该问题可以表示为高一维的线性对流方程组。对于A为正定的情况，利用LCHS方法求解该高维问题。对于A为一般厄米矩阵的情况，虽然LCHS形式仍然适用，但Schr"odingerization方法不适用于最小二乘问题。此外，研究还结合了BPX多层预处理技术，提出了一种量子预处理算法，用于处理泊松方程的有限元离散化。

Result: 研究表明，在A为正定或一般厄米矩阵的情况下，方程组的解x可以表示为Schr"odingerization形式问题的LCHS形式，或等价地表示为Schr"odingerization形式问题的稳态解。该方法在数值测试中得到了验证，并提出了一种结合BPX预处理器的量子预处理算法，能够有效处理泊松方程的有限元离散化问题。

Conclusion: 该研究展示了Schr"odingerization方法在求解线性代数方程组Ax=b方面的潜力，特别是在结合LCHS方法和量子预处理技术时，能够有效地处理有限元离散化的泊松方程等问题。

Abstract: We develop a quantum algorithm for linear algebraic equations Ax=b from the
perspective of Schr\"odingerization-form problems, which are characterized by a
system of linear convection equations in one higher dimension. When A is
positive definite, the solution x can be interpreted as the steady-state
solution of linear ODEs. This ODE can be solved by using the LCHS method in
[1], which serves as the continuous implementation of the Fourier transform in
the Schr\"odingerization method from [2,3] Schr\"odingerization transforms
linear PDEs and ODEs with non-unitary dynamics into Schr\"odinger-type systems
via the warped phase transformation that maps the equation into one higher
dimension. Compared to the LCHS method, Schr\"odingerization may be more
appealing to the PDE community, as it is better suited for leveraging
established computational PDE techniques to develop quantum algorithms. When A
is a general Hermitian matrix, the inverse matrix can still be represented in
the LCHS form in [1], but with a kernel function based on the Fourier approach
in [4]. Although this LCHS form provides the steady-state solution of linear
ODEs associated with the least-squares equation, applying Schr\"odingerization
to this least-squares is not appropriate, as it results in a much larger
condition number. We demonstrate that in both cases, the solution x can be
expressed as the LCHS of Schr\"odingerization-form problems, or equivalently,
as the steady-state solution to a Schr\"odingerization-form problem. This
highlights the potential of Schr\"odingerization in quantum scientific
computation. We provide a detailed, along with several numerical tests that
validate the correctness of our proposed method. Furthermore, we develop a
quantum preconditioning algorithm that combines the BPX multilevel
preconditioner with our method to address the finite element discretization of
the Poisson equation.

</details>


### [371] [Thermalization and Many-Body Zeno Effect in monitored Hamiltonian Dynamics](https://arxiv.org/abs/2508.13574)
*Jia-Jin Feng,Quntao Zhuang*

Main category: quant-ph

TL;DR: 本研究提出了一种创新的方法，利用全息深度热化和中途测量来高效生成真正的随机量子态，显著减小了对浴器的要求，并对随机性进行了量化分析。


<details>
  <summary>Details</summary>
Motivation: 为了减小生成随机量子态所需的浴器尺寸，本研究提出了一种新的方法。

Method: 通过全息深度热化和中途测量相结合的哈密顿量演化来生成真正的随机量子态。

Result: 该方法使用恒定尺寸的浴器实现了真正的随机性，并量化了浴器的随机性，通过理论分析和数值模拟验证了其有效性。

Conclusion: 本研究提出了一种基于全息深度热化和中途测量的方法，能够生成真正的随机量子态，同时减小了所需浴器的尺寸。

Abstract: Random quantum states are essential for various applications in quantum
information science. Prior approaches of generating genuine random states rely
on a large bath to thermalize the system, such that a subsequent measurement on
the bath post-selects a random state for the system. To reduce the size of the
required bath, we propose an alternative approach based on holographic deep
thermalization driven by Hamiltonian evolution, combined with mid-circuit
measurements. By trading spatial and time resources, our approach achieves
genuine randomness with a bath of constant size that is independent of the
system size. We quantify randomness with the frame potential and analyze its
dynamics throughout the evolution. Given a total evolution time, as we increase
the number of mid-circuit measurements, the frame potential initially decreases
exponentially with the number of measurements, due to the mechanism of
holographic deep thermalization. Past a critical number of mid-circuit
measurements, the frame potential rises again, signaling the onset of the
quantum Zeno effect. We provide analytical results for the asymptotic behavior
of the frame potential, which are in good agreement with the numerical
simulations. Our findings offer practical guidance for generating Haar-random
ensembles through Hamiltonian evolution and controlled measurement.

</details>


### [372] [Quantum state engineering of maximally entangled photon pairs by path identity](https://arxiv.org/abs/2508.13638)
*Richard Bernecker,Baghdasar Baghdasaryan,Stephan Fritzsche*

Main category: quant-ph

TL;DR: 利用OAM模式和路径同一性方法，结合空间光束工程，本研究发现了最大纠缠态的优化维度，并揭示了高维目标态保真度的局限性。


<details>
  <summary>Details</summary>
Motivation: 为了在高维空间中优化制备最大纠缠态，需要更深入地理解如何通过工程化泵浦光束的空间分布和路径同一性方法来最大化纠缠。

Method: 本研究结合了理论研究和实验验证，利用轨道角动量（OAM）模式和路径同一性方法来制备高维纠缠态。

Result: 本研究在理论上识别了最大纠缠态的优化维度，并揭示了高维目标态保真度的局限性，同时证明了其与空间泵浦光束的纠缠双光子态的等效性。

Conclusion: 本研究发现了最大纠缠态的优化维度，并将空间光束工程与路径同一性方法相结合，为高维目标态的保真度设定了上限。

Abstract: Cutting-edge quantum technologies lean on sources of high-dimensional
entangled states (HDES) that reliably prepare high-fidelity target states. The
idea to overlap photon paths from distinct but indistinguishable sources was
recently introduced for the creation of HDES, known as entanglement by path
identity. In this regard, the use of orbital angular momentum (OAM) modes is
promising, as they offer a high-dimensional and discrete Hilbert space to
encode information. While entanglement by path identity with OAM has been
verified experimentally, a detailed investigation of how the OAM distribution
of photon pairs can be engineered to maximize the entanglement is lacking. We
address this gap and identify an optimal dimensionality for maximally entangled
states (MESs) when the spatial engineering of pump beam and the path identity
approach are combined. Our theoretical study reveals notable limitations for
the fidelity of high-dimensional target states and also establishes their
equivalence to entangled biphoton states pumped by a spatially engineered beam.
These findings constitute a valuable step toward the optimized preparation of
MESs in high dimensions.

</details>


### [373] [HOPSO: A Robust Classical Optimizer for VQE](https://arxiv.org/abs/2508.13651)
*Ijaz Ahamed Mohammad,Yury Chernyak,Martin Plesch*

Main category: quant-ph

TL;DR: 本文提出了一种改进的 HOPSO 算法来优化 VQE 中的经典部分，以解决噪声和优化难题。该方法在 H2 和 LiH 分子模拟中表现优于其他算法，尤其是在有噪声的情况下，显示了其潜力和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决变分量子特征求解器（VQE）算法在测量随机噪声、巴伦高原和周期参数空间优化中的挑战，本文旨在通过改进经典优化过程来增强 VQE 算法。

Method: 本文提出了一种改进的基于谐振子（HOPSO）的粒子群优化算法，以增强变分量子特征求解器（VQE）算法的经典优化部分。该方法调整了动力学以适应量子参数的周期性并增强噪声抵抗力。

Result: 在氢气 (H2) 和氢化锂 (LiH) 分子（分别建模为 4 和 8 量子比特哈密顿量）的实验中，HOPSO 达到了有竞争力的基态能量近似，并且在所有情况下都比 COBYLA、差分进化 (DE) 和标准粒子群优化 (PSO) 方法表现出更强的鲁棒性，在现实噪声条件下更是表现优于其他方法。

Conclusion: HOPSO 算法在 VQE 中实现了有竞争力的基态能量近似，并且比 COBYLA、差分进化 (DE) 和标准粒子群优化 (PSO) 方法表现出更强的鲁棒性，尤其是在现实噪声条件下，这表明针对 VQE 算法的经典部分进行定制可以解决当前存在的问题，并有望实现更大系统的可扩展性。

Abstract: Variational Quantum Eigensolver (VQE) algorithm is one of few approaches
where the hope for near-term quantum advantage concentrates. However, they face
challenges connected with measurement stochastic noise, barren plateaus, and
optimization difficulties in periodic parameter spaces. While most of the
efforts concentrates on optimizing the quantum part of the procedure, here we
aim to enhance the classical optimization by utilizing a modified version of
Harmonic Oscillator-based Particle Swarm Optimization (HOPSO). By adapting its
dynamics to respect the periodicity of quantum parameters and enhance noise
resilience, we show its strengths on hydrogen (H2) and lithium hydride (LiH)
molecules modeled as 4- and 8-qubit Hamiltonians. HOPSO achieves competitive
ground-state energy approximations and demonstrates improved robustness
compared to COBYLA, Differential Evolution (DE), and standard Particle Swarm
Optimization (PSO) methods in all situations and outperforms other methods
under realistic noise conditions. These results suggest that a properly
tailored classical part of VQE algorithms can tackle with current problems and
gives hope for its scalability for larger systems.

</details>


### [374] [Fabrication of nano-diamonds with a single NV center: Towards matter-wave interferometry with massive objects](https://arxiv.org/abs/2508.13662)
*Menachem Givon,Yaniv Bar-Haim,David Groswasser,Asi Solodar,Nadav Aharon,Michael Belman,Amit Yosefi,Erez Golan,Jurgen Jopp,Ron Folman*

Main category: quant-ph

TL;DR: This paper details the design and fabrication of a nanodiamond source for a quantum-GR interferometer, aiming to test fundamental physics principles.


<details>
  <summary>Details</summary>
Motivation: To test fundamental ideas in quantum mechanics, such as the spatial superposition principle, in unexplored regimes and to probe the interface between quantum mechanics and general relativity, including the quantization of gravity.

Method: Utilizing nanodiamonds with embedded spins as test particles in combination with Stern-Gerlach forces to realize a closed-loop matter-wave interferometer in space-time. The technical note focuses on design considerations, fabrication processes, characterization, and remaining steps for the nanodiamond source.

Result: The authors have fabricated nanodiamond pillars measuring 40 x 65 x 80 nm and summarized the characterization work completed to date.

Conclusion: The authors are working on fabricating a high-precision enhanced-coherence nanodiamond source for a matter-wave interferometer.

Abstract: Quantum mechanics (QM) and General relativity (GR), also known as the theory
of gravity, are the two pillars of modern physics. A matter-wave interferometer
with a massive particle can test numerous fundamental ideas, including the
spatial superposition principle - a foundational concept in QM - in previously
unexplored regimes. It also opens the possibility of probing the interface
between QM and GR, such as testing the quantization of gravity. Consequently,
there exists an intensive effort to realize such an interferometer. While
several approaches are being explored, we focus on utilizing nanodiamonds with
embedded spins as test particles which, in combination with Stern-Gerlach
forces, enable the realization of a closed-loop matter-wave interferometer in
space-time. There is a growing community of groups pursuing this path [1]. We
are posting this technical note (as part of a series of seven such notes), to
highlight our plans and solutions concerning various challenges in this
ambitious endeavor, hoping this will support this growing community. Here we
discuss the design considerations for a high-precision enhanced-coherence
nanodiamond source, review the fabrication processes used to produce
nanodiamond pillars measuring 40 x 65 x 80 nm, summarize the characterization
work completed to date, and conclude with an outlook on the remaining steps
needed to finalize the source fabrication. We would be happy to make available
more details upon request.

</details>


### [375] [Towards a Twisted Atom Laser: Cold Atoms Released from Helical Optical Tube Potentials](https://arxiv.org/abs/2508.13711)
*Amine Jaouadi,Andreas Lyras,Vasileios E. Lembessis*

Main category: quant-ph

TL;DR: 研究了冷原子在螺旋光管中的量子动力学，发现其几何形状影响了波包的形成，为原子激光器和量子技术应用提供了可能。


<details>
  <summary>Details</summary>
Motivation: 研究了螺旋几何形状如何影响原子的初始量子态（特别是空间局域化和相位结构），以及这些特征如何影响随后的自由演化。

Method: 研究了原子在被限制在螺旋光管（HOT）中，然后释放到自由空间中的量子动力学。

Result: 研究发现，螺旋光管势阱支持形成空间相干、结构化的波包。

Conclusion: 研究表明，螺旋光管势阱能够形成空间相干、结构化的波包，为实现扭曲的玻色子-费米子凝聚体和定向原子激光器铺平了道路。

Abstract: We study the quantum dynamics of cold atoms initially confined in a Helical
Optical Tube (HOT) and subsequently released into free space. This helicoidal
potential, engineered via structured light fields with orbital angular
momentum, imposes a twisted geometry on the atomic ensemble during confinement.
We examine how this geometry shapes the initial quantum state particularly its
spatial localization and phase structure and how these features influence the
subsequent free evolution. Our analysis reveals that the overall confinement
geometry supports the formation of spatially coherent, structured wavepackets,
paving the way for the realization of twisted Bose Einstein condensates and
directed atom lasers. The results are of particular interest for applications
in quantum technologies, such as coherent atom beam shaping, matter-wave
interferometry, and guided transport of quantum matter.

</details>


### [376] [Parametric feedback cooling of librations of a nanodiamond in a Paul trap: Towards matter-wave interferometry with massive objects](https://arxiv.org/abs/2508.13723)
*Maria Muretova,Yonathan Japha,Marko Toros,Ron Folman*

Main category: quant-ph

TL;DR: 该论文提出了一种冷却纳米金刚石内部自旋的方案，以实现量子力学与广义相对论的接口检验，并取得了理论上的可行性结果。


<details>
  <summary>Details</summary>
Motivation: 量子力学（QM）和广义相对论（GR）是现代物理学的两大支柱，但它们在极端条件下的兼容性仍然是一个未解之谜。利用宏观物体的量子叠加态进行干涉实验，是检验QM和GR接口以及探索量子引力理论的关键途径。该研究旨在为实现由纳米金刚石（ND）及其内部自旋组成的量子干涉仪提供理论支持和技术方案。

Method: 本文提出并模拟了一种利用激光冷却和反馈控制技术来冷却氮空位（NV）在金刚石（ND）中的旋转的方法。通过精确控制激光的频率和强度，以及电场的调制，可以有效地将NV的旋转冷却到接近基态的能量水平。

Result: 研究表明，通过参数反馈冷却，纳米金刚石的振动模式可以冷却到数百个旋转声子的水平，这足以满足未来基于纳米金刚石的量子干涉实验的要求。通过模拟，该方法在冷却效率方面对电势和物体形状的依赖性得到了检验，并显示出在不久的将来可以实现所需的振动温度。

Conclusion: 该研究表明，通过对氮空位中心的旋转进行参数反馈冷却，可以达到或超过实现量子重力实验所需的精度。

Abstract: Quantum mechanics (QM) and General relativity (GR), also known as the theory
of gravity, are the two pillars of modern physics. A matter-wave interferometer
with a massive particle can test numerous fundamental ideas, including the
spatial superposition principle - a foundational concept in QM - in completely
new regimes, as well as the interface between QM and GR, e.g., testing the
quantization of gravity. Consequently, there exists an intensive effort to
realize such an interferometer. While several paths are being pursued, we focus
on utilizing nanodiamonds (NDs) as our particle, and a spin embedded in the ND
together with Stern-Gerlach forces, to achieve a closed loop in space-time.
There is a growing community of groups pursuing this path [1]. We are posting
this technical note (as part of a series of seven such notes) to highlight our
plans and solutions concerning various challenges in this ambitious endeavor,
hoping this will support this growing community. Here, we present a theoretical
study concerning the impact of rotations of the ND on the interferometric
contrast. We have previously shown that for a first-generation Stern-Gerlach
interferometer with an ND composed of 10^7 atoms, it is sufficient to cool the
center of mass to milli-Kelvin temperatures. In this work, we similarly show
that rotation does not have to be cooled to the ground state, and cooling to
hundreds of rotational phonons is good enough. We describe and simulate
parametric feedback cooling of librational modes of a charged ND levitated in a
Paul trap. The cooling is performed by modulating the electric field of the
trap. We examine the dependence of the efficiency of cooling on the electric
potential and the shape of the object. We show that the required libration
temperatures should be within reach in the very near future. We would be happy
to make more details available upon request.

</details>


### [377] [Entanglement witnesses for stabilizer states and subspaces beyond qubits](https://arxiv.org/abs/2508.13734)
*Jakub Szczepaniak,Owidiusz Makuta,Remigiusz Augusiak*

Main category: quant-ph

TL;DR: 该研究为多qudit系统构建了能更好抵抗噪声的纠缠检测观测元。


<details>
  <summary>Details</summary>
Motivation: 为了在多方量子态中检测真正多方纠缠，需要使用纠缠观测元。该研究旨在推广先前工作，为源自多qudit稳定器形式主义的子空间构建量身定制的观测元。

Method: 该研究通过推广先前的工作，为多qudit稳定器形式主义的子空间构建了检测真正多方纠缠的观测元，并包含了任意局部维度的图态。

Result: 所提出的观测元能够检测多qudit系统中的真正多方纠缠，并且在某些情况下，相比于用于多qubit态的观测元，具有更优的噪声鲁棒性。

Conclusion: 该研究为基于多qudit稳定器形式主义的子空间构建了能够检测真正多方纠缠的观测元。

Abstract: Genuine multipartite entanglement is arguably the most valuable form of
entanglement in the multipartite case, with applications, for instance, in
quantum metrology. In order to detect that form of entanglement in multipartite
quantum states, one typically uses entanglement witnesses. The aim of this
paper is to generalize the results of [G. T\'oth and O. G\"uhne, Phys. Rev. A
\textbf{72}, 022340 (2005)] in order to provide a construction of witnesses of
genuine multipartite entanglement tailored to entangled subspaces originating
from the \textit{multi-qudit} stabilizer formalism -- a framework well known
for its role in quantum error correction, which also provides a very convenient
description of a broad class of entangled multipartite states (both pure and
mixed). Our construction includes graph states of arbitrary local dimension. We
then show that in certain situations, the obtained witnesses detecting genuine
multipartite entanglement in quantum systems of higher local dimension are
superior in terms of noise robustness to those derived for multiqubit states.

</details>


### [378] [Nonlinear-linear duality for multipath quantum interference](https://arxiv.org/abs/2508.13855)
*Yi Zheng,Jin-Shi Xu,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: 提出了一种将量子非简并参量下转换（PDC）和线性光学系统组成的量子非线性干涉设置，与一个线性的设置联系起来的广义对偶性，其中PDC被假设的波长转换BS直接取代。该方法保持了原始设置的几何形状，并且级联PDC变成了涉及Redheffer星积的计算的光腔。归一化系数中的附加项与腔内循环光子的贡献有关。该定理将有助于在低增益限制之外开发量子光子器件。


<details>
  <summary>Details</summary>
Motivation: 在量子光学中，非简并参量下转换（PDC）过程的后选择幅度通过部分时间反演与分束器（BS）相关联，直到与参数增益相关的归一化系数[Proc. Natl. Acad. Sci. USA 117, 33107（2020）]。增益较低的特例让人想起量子成像中的Klyshko高级波概念。

Method: 提出并证明了多空间路径的广义对偶性，将量子非简并参量下转换（PDC）和线性光学系统组成的量子非线性干涉设置，与一个线性的设置联系起来，其中PDC被假设的波长转换BS直接取代。这种替换保持了原始设置的几何形状，并且级联PDC变成了涉及Redheffer星积的计算的光腔。

Result: 该方法保持了原始设置的几何形状，并且级联PDC变成了光腔，其计算涉及Redheffer星积。归一化系数中的附加项与腔内循环光子的贡献有关。然后，讨论了相干态输入和用于Q函数计算的后选择的情况。

Conclusion: 该定理将有助于在低增益限制之外开发量子光子器件。

Abstract: In quantum optics, the postselection amplitude of a nondegenerate parametric
down-conversion (PDC) process is linked to a beamsplitter (BS) via partial time
reversal, up to a normalization coefficient which is related to the parametric
gain [Proc. Natl. Acad. Sci. USA 117, 33107 (2020)]. A special example where
the gain is low is reminiscent of Klyshko's advanced-wave picture in quantum
imaging. Here, we propose and prove a generalized duality for multiple spatial
paths connecting a quantum nonlinear interference setup consisting of
nondegenerate PDCs and linear optical systems to a linear one, where the PDCs
are directly replaced by hypothetical wavelength-shifting BSs. This replacement
preserves the geometry of the original setup, and cascaded PDCs become optical
cavities whose calculation involves the Redheffer star product. Additional
terms in the normalization coefficient are related to the contribution of
looping photons inside the cavities. Then, we discuss the case of coherent
state input and postselection for $Q$-function calculation. This theorem will
be helpful in the development of quantum photonic devices beyond the low-gain
limit.

</details>


### [379] [Dynamics-independent bounds on state transformations and precision in open quantum systems](https://arxiv.org/abs/2508.13884)
*Yoshihiko Hasegawa*

Main category: quant-ph

TL;DR: Derived dynamics-independent bounds for quantum state transformations and parameter estimation in open quantum systems using Renyi divergence and joint unitaries.


<details>
  <summary>Details</summary>
Motivation: To derive dynamics-independent upper bounds on achievable quantum state transformations and establish bounds on relative variance and parameter estimation variance for open quantum systems.

Method: Model the evolution as a joint unitary on the system and environment, and use Rényi divergence to bound achievable quantum state transformations.

Result: Derived dynamics-independent upper bounds on achievable quantum state transformations, and dynamics-independent lower bounds on relative variance and measurement-independent lower bounds on the variance of parameter estimators.

Conclusion: We establish dynamics-independent lower bounds on relative variance and parameter estimation variance, which depend only on initial eigenvalues and hold for any joint unitary, providing computable bounds for open quantum systems.

Abstract: We derive dynamics-independent upper bounds on achievable quantum state
transformations. Modeling the evolution as a joint unitary on the system and
its environment, we show that the R\'enyi divergence between the initial system
state and any state reachable via the dynamics is bounded from above by a
quantity determined solely by the eigenvalues of the initial system and
environment density operators. As a consequence, we establish
dynamics-independent lower bounds on the relative variance for arbitrary
measurements, which parallel thermodynamic uncertainty relations. Moreover, we
obtain dynamics- and measurement-independent lower bounds on the variance of
parameter estimators. These results depend only on the initial eigenvalues of
the system and environment and hold for any joint unitary, providing computable
bounds for open quantum systems.

</details>


### [380] [Accurate and Scalable Simulation of Cavity-Based Networks in Modular Quantum Architectures](https://arxiv.org/abs/2508.13896)
*Sahar Ben Rached,Zezhou Sun,Guilu Long,Santiago Rodrigo,Carmen G. Almudéver,Eduard Alarcón,Sergi Abadal*

Main category: quant-ph

TL;DR: 本文提出了一种利用腔介导的互连进行模块化量子计算机扩展的方法，并通过模拟分析了其性能和优化设计。


<details>
  <summary>Details</summary>
Motivation: 腔介导的互连是有望扩展模块化量子计算机的平台，通过实现高保真度的芯片间量子态传输和纠缠生成。

Method: 本文首先模拟了使用受激拉曼绝热通道（STIRAP）协议的确定性芯片间量子态传输动力学，分析了在实验上可实现的量子比特-腔耦合和退相干参数下的保真度损失机制。然后，扩展了通常用于模拟远程量子通信网络的 NetSquid 模拟器，以支持基于腔的通信通道，以实现芯片间状态传输和纠缠生成。

Result: 模拟准确地表示了强耦合和弱耦合两种情况下的系统动力学，并确定了保真度、延迟和噪声因素之间的关键权衡。

Conclusion: 该框架支持对模块化架构进行忠实建模和可扩展仿真，并为实际量子网络实现的 iesign 优化提供见解。

Abstract: Cavity-mediated interconnects are a promising platform for scaling modular
quantum computers by enabling high-fidelity inter-chip quantum state
transmission and entanglement generation. In this work, we first model the
dynamics of deterministic inter-chip quantum state transfer using the
Stimulated Raman Adiabatic Passage (STIRAP) protocol, analyzing fidelity loss
mechanisms under experimentally achievable qubit-cavity coupling and
decoherence parameters. We then extend the NetSquid simulator, typically used
for simulating long-range quantum communication networks, to support
cavity-based communication channels for mediating inter-chip state transfer and
entanglement generation. We model cavities as amplitude damping channels
parameterized by physical system characteristics; cavity decay rate k and
qubit-cavity coupling strength g, and analyze the impact of intrinsic qubit
decoherence factors dictated by T1 and T2 times. Our simulations accurately
represent the system's dynamics in both strong and weak coupling regimes, and
identify critical trade-offs between fidelity, latency, and noise factors. The
proposed framework supports faithful modeling and scalable simulation of
modular architectures, and provides insights into design optimization for
practical quantum network implementations.

</details>


### [381] [Exploring Nonreciprocal Noise Transfer under Onsager-Casimir Symmetry in Synthetic-Field Optomechanics](https://arxiv.org/abs/2508.13902)
*Beyza Sütlüoğlu Ege,Şahin K. Özdemir,Ceyhun Bulutay*

Main category: quant-ph

TL;DR: 分析了一个包含两个耦合谐振器的光力学系统，发现了非互易噪声流，并研究了其与机械耦合的关系。


<details>
  <summary>Details</summary>
Motivation: 为了阐明环路相位和奇异点在光力学系统中作用，以及合成磁场对信号和噪声流的非互易性影响。

Method: 本文分析了一个由两个相互耦合的机械谐振器组成的光力学系统，并通过分析噪声功率谱密度来研究系统行为。

Result: 研究表明，该系统在时间反转对称性被破坏时，存在非互易噪声流，并引入了一个衡量标准来量化这种非互易性。研究还发现，非互易噪声流随着机械耦合的减小而增强，但灵敏度会降低，而对于传感应用，选择高机械耦合常数更为可行。

Conclusion: 该研究提出了一个包含两个耦合机械谐振器的光力学系统，该系统通过光子腔耦合，并展示了合成磁场的概念。研究分析了噪声功率谱密度，揭示了在时间反转对称性被破坏时，非互易噪声流的存在，即使在Onsager-Casimir对称性仍然成立的情况下。通过引入一个衡量标准，研究量化了这种非互易性，并发现它与机械耦合强度相关，这对于传感应用具有指导意义。

Abstract: An optomechanical system of fundamental importance consists of two
intercoupled mechanical resonators, which are radiation-pressure coupled
individually to a photonic cavity. This closed-loop and overall lossy
configuration possesses two exceptional points (EPs) and offers the realization
of synthetic magnetism, controlled by the loop phase. To elucidate the
intricate role of loop phase and EPs in this setting, we analyze the noise
power spectral density profiles of internal as well as output fluctuations. In
the presence of a synthetic magnetic field, the non-reciprocal routing of a
signal is well-known. Here, we further show that this also applies to
non-reciprocal backaction noise flow when the time-reversal symmetry is broken,
while the Onsager-Casimir symmetry still holds. To better quantify this
phenomenon, we introduce a non-reciprocity measure that contrasts the
time-reversed counterparts as a function of loop-phase. We observe that
non-reciprocal noise flow is enhanced for smaller intermechanical couplings at
the expense of lower sensitivity, whereas for sensing purposes, using a higher
intermechanical coupling constant is the more viable option.

</details>


### [382] [Qudit-based scalable quantum algorithm for solving the integer programming problem](https://arxiv.org/abs/2508.13906)
*Kapil Goswami,Peter Schmelcher,Rick Mukherjee*

Main category: quant-ph

TL;DR: 提出了一种新的量子算法，使用多qudit解决整数规划问题，实现了量子加速，并提高了资源效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统量子算法在整数规划问题中因将整数编码为qubit而导致的资源效率低下问题，以及先前研究（[1]）在扩展到多个qudit以编码更大问题方面的可扩展性限制。

Method: 提出了一种基于电路的可扩展量子算法，利用多可交互qudit来解决整数规划问题。该算法包括一个蒸馏函数用于区分可行和不可行区域，一个用于成本函数相位-幅度编码，以及一个结合多控制单qubit旋转的量子相位估计，以实现优化。

Result: 证明了最优解具有在算法中被测量的最大概率。该量子算法的时间复杂度为$O(d^{n/2} + m	ext{·}n^2	ext{·}	ext{log}{d} + n/	ext{ }esize{6}{0.7}{)}{	ext{QPE}})$, 相比于经典暴力破解的$O(d^n)$和最佳经典精确算法$O((	ext{log}{n})^{3n})$，在解决通用多项式整数规划问题上，相对于$n$，时间复杂度减少了$d^{n/2}$。

Conclusion: 该量子算法通过使用多可交互的qudit，在解决整数规划问题上展示了量子加速，并显著减少了所需时间复杂度。

Abstract: Integer programming (IP) is an NP-hard combinatorial optimization problem
that is widely used to represent a diverse set of real-world problems spanning
multiple fields, such as finance, engineering, logistics, and operations
research. It is a hard problem to solve using classical algorithms, as its
complexity increases exponentially with problem size. Most quantum algorithms
for solving IP are highly resource inefficient because they encode integers
into qubits. In [1], the issue of resource inefficiency was addressed by
mapping integer variables to qudits. However, [1] has limited practical value
due to a lack of scalability to multiple qudits to encode larger problems. In
this work, by extending upon the ideas of [1], a circuit-based scalable quantum
algorithm is presented using multiple interacting qudits for which we show a
quantum speed-up. The quantum algorithm consists of a distillation function
that efficiently separates the feasible from the infeasible regions, a
phase-amplitude encoding for the cost function, and a quantum phase estimation
coupled with a multi-controlled single-qubit rotation for optimization. We
prove that the optimal solution has the maximum probability of being measured
in our algorithm. The time complexity for the quantum algorithm is shown to be
$O(d^{n/2} + m\cdot n^2\cdot \log{d} + n/\epsilon_{QPE})$ for a problem with
the number of variables $n$ taking $d$ integer values, satisfying $m$
constraints with a precision of $\epsilon_{QPE}$. Compared to the classical
time complexity of brute force $O(d^n)$ and the best classical exact algorithm
$O((\log{n})^{3n})$, it incurs a reduction of $d^{n/2}$ in the time complexity
in terms of $n$ for solving a general polynomial IP problem.

</details>


### [383] [Analytical phase boundary of a quantum driven-dissipative Kerr oscillator from classical stochastic instantons](https://arxiv.org/abs/2508.13925)
*Théo Sépulcre*

Main category: quant-ph

TL;DR: Keldysh 路径积分框架提供了一种描述远离热平衡的量子系统的方法，并将其映射到一个经典随机等价物。该方法用于分析双光子驱动的 Kerr 振荡器，首次获得了相边界的解析表达式，并为分析其他双稳态量子光学模型提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 简要描述了 Keldysh 路径积分框架在描述诸如双光子驱动的 Kerr 振荡器等远离热平衡的量子系统中的应用。

Method: 将 Keldysh 路径积分框架映射到 Martin-Siggia-Rose-Janssen-de Dominicis 路径积分，并获得了一个纯粹经典、随机的等价物，其中光子自相互作用扮演了温度的角色。

Result: 使用实时瞬子技术估计双稳态隧穿率，得到了相边界的解析表达式，据作者所知是首次。

Conclusion: 该框架为显示双稳态的各种量子光学模型开辟了强大的半解析技术应用途径。

Abstract: The framework of Keldysh path integral concisely describes quantum systems
driven away from thermal equilibrium, such as the two-photon driven Kerr
oscillator. Within the thermodynamic limit of diverging photon occupation, we
map it to a Martin-Siggia-Rose-Janssen-de Dominicis path integral, and obtain a
purely classical, stochastic equivalent where photon self-interaction plays the
role of temperature. This perspective sheds light on the difficulties
encountered in the search for an effective thermodynamic potential to describe
the bistability of the model. It allows us to estimate the bistable tunneling
rates using a real-time instanton technique leading to an analytical expression
of the phase boundary, the first-ever to our knowledge. It opens the way to
powerful semi-analytical techniques to be applied to various quantum optics
models displaying bistability.

</details>


### [384] [Guided sampling ansätzes for variational quantum computing](https://arxiv.org/abs/2508.13926)
*Daniel Gunlycke,John P. T. Stenger,Andrii Maksymov,Ananth Kaushik,Martin Roetteler,C. Stephen Hellberg*

Main category: quant-ph

TL;DR: 一种新的量子算法（量子计算的ansatz）可以高效、高精度地计算H3O+的能量。


<details>
  <summary>Details</summary>
Motivation: 量子计算在处理高维向量空间方面有巨大潜力，但如何高效地提取解仍然是一个挑战，需要量子门操作和量子电路的执行次数 ઓછા，因此选择合适的ansatz至关重要。

Method: 提出了一种新的量子算法（量子计算的ansatz），该算法依赖于系统相互作用、测量状态样本和参数空间。

Result: 在IonQ Aria量子计算机上，使用200次电路执行，量子计算的ansatz计算出的H3O+的能量误差低于1.59x10^-3 Ha，超过了化学精度。

Conclusion: 使用一种新的量子算法（量子计算的ansatz）在量子计算机上计算H3O+的能量，精度超过了化学精度。

Abstract: Quantum computing is a promising technology because of the ability of quantum
computers to process vector spaces with dimensions that increase exponentially
with the simulated system size. Extracting the solution, however, is
challenging as the number of quantum gate operations and quantum circuit
executions must still scale at most polynomially. Consequently, choosing a good
ansatz--a polynomial subset of the exponentially many possible solutions--will
be critical to maintain accuracy for larger systems. To address this challenge,
we introduce a class of guided sampling ans\"atzes (GSAs) that depend on the
system interactions and measured state samples as well as a parameter space. We
demonstrate a minimal ansatz for the hydronium cation H$_3$O$^+$ and found that
with only 200 circuit executions per structure on the IonQ Aria quantum
computer, our calculations produced total energies around the relaxed structure
with errors well below $1.59\times10^{-3}$ Ha, thus exceeding chemical
accuracy.

</details>


### [385] [Phase-Driven Precision Boost in Quantum Compression for Postselected Metrology](https://arxiv.org/abs/2508.13934)
*Aiham M. Rostom,Saeed Haddadi,Vladimir A. Tomilin*

Main category: quant-ph

TL;DR: 该研究发现了Pancharatnam相位在量子计量中的关键作用，能够提升信息获取的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 量子计量参数估计在现实实验约束下需要改进。

Method: 该研究利用Pancharatnam相位来精确控制量子压缩通道中的正交参数灵敏度与Meter状态中平行演化之间的相互作用，以最大化量子Fisher信息。

Result: 通过微调后选参数，可以实现信息增益的十倍以上提升，并且利用qudit Meter状态可以获得额外的量子优势。

Conclusion: 该研究揭示了非循环的Pancharatnam相位是后选元量子计量中量子压缩通道最优运行的基本几何判据。利用该相位能够精确控制正交参数灵敏度与Meter状态中平行演化之间的相互作用，从而最大化每次试验的量子Fisher信息。

Abstract: We unveil the noncyclic Pancharatnam phase as a fundamental geometric
criterion governing the optimal operation of quantum compression channels in
postselected metrology. Harnessing this phase enables precise control over the
interplay between orthogonal parameter sensitivity and parallel evolution in
the meter state, thereby maximizing the quantum Fisher information per trial.
Strikingly, fine-tuning the postselection parameter just below this optimal
phase incurs substantial information loss, whereas tuning it just above fully
suppresses undesired parallel evolution and boosts information retention by
more than a tenfold factor relative to conventional approaches. We further
reveal that leveraging qudit meter states can unlock a substantial additional
quantum advantage. These findings establish the Pancharatnam phase as an
essential and robust geometric benchmark, guiding the design of next-generation
high-precision quantum parameter estimation protocols under realistic
experimental constraints.

</details>


### [386] [Multiclass Portfolio Optimization via Variational Quantum Eigensolver with Dicke State Ansatz](https://arxiv.org/abs/2508.13954)
*J. V. S. Scursulim,Gabriel Mattos Langeloh,Victor Leme Beltran,Samuraí Brito*

Main category: quant-ph

TL;DR: 本研究提出了一种新的量子框架，用于解决考虑分散性的多类别投资组合优化问题。该框架使用参数化狄克状态作为变分量子特征求解器的初始状态，以满足分散性约束，从而减少搜索空间。实验证明，该方法在与CMA-ES优化器结合使用时，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对现有量子算法在解决投资组合优化问题时忽略了分散性这一现实世界的关键特征的不足，提出了一种新的量子框架来解决这一问题。

Method: 提出了一种利用多个参数化狄克状态（Dicke states）作为变分量子特征求解器（Variational Quantum Eigensolver）的初始状态，以显式地将分散性纳入多类别投资组合优化问题的新量子框架。该方法生成的初始状态仅限于可行状态的叠加，从而减少了搜索空间并消除了对惩罚项的需求。

Result: 实验结果表明，该狄克状态初始化的量子框架与CMA-ES优化器结合使用时，在收敛速度、逼近率和测量概率方面均表现出优越性能。

Conclusion: 本方法在结合CMA-ES优化器时，在收敛速度、逼近率和测量概率方面表现出优越性能，表明其在解决实际的、考虑分散性的投资组合优化问题方面具有潜力。

Abstract: Combinatorial optimization is a fundamental challenge in various domains,
with portfolio optimization standing out as a key application in finance.
Despite numerous quantum algorithmic approaches proposed for this problem, most
overlook a critical feature of realistic portfolios: diversification. In this
work, we introduce a novel quantum framework for multiclass portfolio
optimization that explicitly incorporates diversification by leveraging
multiple parametrized Dicke states, simultaneously initialized to encode the
diversification constraints , as an ansatz of the Variational Quantum
Eigensolver. A key strength of this ansatz is that it initializes the quantum
system in a superposition of only feasible states, inherently satisfying the
constraints. This significantly reduces the search space and eliminates the
need for penalty terms. In addition, we also analyze the impact of different
classical optimizers in this hybrid quantum-classical approach. Our findings
demonstrate that, when combined with the CMA-ES optimizer, the Dicke state
ansatz achieves superior performance in terms of convergence rate,
approximation ratio, and measurement probability. These results underscore the
potential of this method to solve practical, diversification-aware portfolio
optimization problems relevant to the financial sector.

</details>


### [387] [Adversarially robust quantum state learning and testing](https://arxiv.org/abs/2508.13959)
*Maryam Aliakbarpour,Vladimir Braverman,Nai-Hui Chia,Yuhan Liu*

Main category: quant-ph

TL;DR: 研究提出了一种新的量子态学习算法，能在对抗性破坏模型下学习量子态。虽然对于通用量子态存在维度依赖的误差，但对于秩为常数的量子态，该算法可以实现独立于维度的最优误差。


<details>
  <summary>Details</summary>
Motivation: 为了设计能够抵抗量子设备误差、人为读出错误或恶意攻击者篡改变动测量结果的量子态学习算法。

Method: 提出 $\gamma$-对抗性破坏模型，并设计了一种使用非自适应测量的算法来学习未知量子态。

Result: 设计了一种学习算法，其误差界限为 $\tilde{O}(\gamma\sqrt{r})$，并证明了这是非自适应测量的最优下界。该结果也适用于量子态测试。

Conclusion: 该研究为量子态学习设计了一种抗干扰算法，该算法在 $\gamma$-对抗性破坏模型下，对于秩为 $r$ 的量子态，在足够多的副本下，可以将追踪距离误差控制在 $\tilde{O}(\gamma\sqrt{r})$ 以内，该算法具有最优性。但对于通用量子态，其误差依赖于维度，在最坏情况下为 $\gamma\sqrt{d}$，这表明少量的破坏就可能毁掉学习算法。然而，对于秩为常数（constant-rank）的量子态，即使在对抗性设置下，也能实现独立于维度的误差。

Abstract: Quantum state learning is a fundamental problem in physics and computer
science. As near-term quantum devices are error-prone, it is important to
design error-resistant algorithms. Apart from device errors, other unexpected
factors could also affect the algorithm, such as careless human read-out error,
or even a malicious hacker deliberately altering the measurement results. Thus,
we want our algorithm to work even in the worst case when things go against our
favor.
  We consider the practical setting of single-copy measurements and propose the
$\gamma$-adversarial corruption model where an imaginary adversary can
arbitrarily change $\gamma$-fraction of the measurement outcomes. This is
stronger than the $\gamma$-bounded SPAM noise model, where the post-measurement
state changes by at most $\gamma$ in trace distance. Under our stronger model
of corruption, we design an algorithm using non-adaptive measurements that can
learn an unknown rank-$r$ state up to $\tilde{O}(\gamma\sqrt{r})$ in trace
distance, provided that the number of copies is sufficiently large. We further
prove an information-theoretic lower bound of $\Omega(\gamma\sqrt{r})$ for
non-adaptive measurements, demonstrating the optimality of our algorithm. Our
upper and lower bounds also hold for quantum state testing, where the goal is
to test whether an unknown state is equal to a given state or far from it.
  Our results are intriguingly optimistic and pessimistic at the same time. For
general states, the error is dimension-dependent and $\gamma\sqrt{d}$ in the
worst case, meaning that only corrupting a very small fraction ($1/\sqrt{d}$)
of the outcomes could totally destroy any non-adaptive learning algorithm.
However, for constant-rank states that are useful in many quantum algorithms,
it is possible to achieve dimension-independent error, even in the worst-case
adversarial setting.

</details>


### [388] [Programmable Anyon Mobility through Higher Order Cellular Automata](https://arxiv.org/abs/2508.13961)
*Jie-Yu Zhang,Peng Ye*

Main category: quant-ph

TL;DR: "HOCA提供了一个统一的框架来控制和表征SET相中的任意子迁移性，即使在复杂的子系统对称性下也是如此，并发现了新的融合规则。"


<details>
  <summary>Details</summary>
Motivation: "任意子迁移性的控制对于鲁棒的量子内存和理解具有子系统对称性的拓扑（SET）相至关重要，但缺乏统一的框架来处理这些多样化的几何对称性支持模式。"

Method: "通过引入高阶元胞自动机（HOCA）到SET物理学中，设计了有限深度的HOCA控制酉量子电路，得到了具有阿贝尔任意子和所有可能的局部生成的子系统对称性的精确可解的SET模型。"

Result: "该研究提出了一个精确编程所有激发子迁移性的定理，直接从HOCA规则中确定任意子迁移性，并识别了具有多个通道的融合规则，在阿贝尔任意子系统中表现出非阿贝尔特性。"

Conclusion: "HOCA为SET物理学提供了一个统一的框架，用于表征由子系统对称性的复杂性引起的任意子迁移性，并为SET相和拓扑量子代码的可编程性开辟了新途径。"

Abstract: Controlling anyon mobility is critical for robust quantum memory and
understanding symmetry-enriched topological (SET) phases with subsystem
symmetries (e.g., line-like, fractal, chaotic, or mixed supports). However, a
unified framework for anyon mobility in SET phases with such diverse geometric
patterns of symmetry supports has remained a major challenge. In this Letter,
by introducing higher-order cellular automata (HOCA) -- a powerful computer
science tool -- to SET physics, we establish a unified approach for complete
characterization of anyon mobility induced by the complexity of subsystem
symmetries. First, we design finite-depth HOCA-controlled unitary quantum
circuits, yielding exactly solvable SET models with Abelian anyons and all
possible locally generated subsystem symmetries. Then, we present a theorem
that precisely programs all excitation mobilities (fractons, lineons, or fully
mobile anyons) directly from the HOCA rule, representing the first complete
characterization of anyon mobility in SET phases. As a corollary, this theorem
yields symmetry-enriched fusion rules which govern mobility transmutation
during fusion. Fusion rules with multiple channels are identified, exhibiting
non-Abelian characteristics in Abelian anyon systems. Leveraging HOCA, this
Letter opens new avenues for characterization of SET phases of matter and
programmability of topological quantum codes.

</details>


### [389] [Roadblocks and Opportunities in Quantum Algorithms -- Insights from the National Quantum Initiative Joint Algorithms Workshop, May 20--22, 2024](https://arxiv.org/abs/2508.13973)
*Eliot Kapit,Peter Love,Jeffrey Larson,Andrew Sornborger,Eleanor Crane,Alexander Schuckert,Teague Tomesh,Frederic Chong,Sabre Kais*

Main category: quant-ph

TL;DR: 量子算法研讨会总结了量子算法的现状、挑战和机遇，并提出了推动量子计算发展的共同愿景。


<details>
  <summary>Details</summary>
Motivation: 本次研讨会的动机在于评估量子算法的当前状况，并识别和讨论阻碍量子计算能力发展的障碍。通过汇集不同领域的专家，旨在促进跨学科合作，加速量子算法的进步，并为未来的研究和发展奠定基础。

Method: 本次分析基于“国家量子倡议联合算法研讨会”的摘要，该研讨会聚集了来自学术界、国家实验室和工业界的专家。研讨会内容涵盖了新兴算法技术、近期硬件的资源限制以及软件和系统协同设计的机会。报告中呈现的七个主题，都是研讨会期间讨论的关键挑战和机遇的总结。

Result: 研讨会确定了七个关键主题，这些主题代表了量子算法领域的挑战和机遇。这些主题共同描绘了该领域不断变化的优先事项，并为推进量子计算能力提供了共同的愿景。报告旨在为研究人员、政策制定者和行业利益相关者提供一个全面的概述。

Conclusion: 本报告总结了国家量子倡议联合算法研讨会的成果，该研讨会汇集了学术界、国家实验室和工业界的顶尖研究人员，共同评估了量子算法的现状，并探讨了阻碍其发展的因素。报告重点介绍了七个关键主题，这些主题突显了该领域面临的挑战和机遇，为推动量子计算能力的发展提供了宝贵的见解和共同的愿景。

Abstract: The National Quantum Initiative Joint Algorithms Workshop brought together
researchers across academia, national laboratories, and industry to assess the
current landscape of quantum algorithms and discuss roadblocks to progress. The
workshop featured discussions on emerging algorithmic techniques, resource
constraints in near-term hardware, and opportunities for co-design across
software and systems. Presented here are seven topics from the workshop, each
highlighting a critical challenge or promising opportunity discussed during the
event. Together, they offer a snapshot of the field's evolving priorities and a
shared vision for what is needed to advance quantum computational capabilities.

</details>


### [390] [Brace for impact: ECDLP challenges for quantum cryptanalysis](https://arxiv.org/abs/2508.14011)
*Pierre-Luc Dallaire-Demers,William Doyle,Timothy Foo*

Main category: quant-ph

TL;DR: 该研究提出了一个用于评估容错量子计算机在破解椭圆曲线密码学方面的性能的基准套件，并预测在不久的将来（2027-2033年）能够实现对256位实例的破解，建议用户迁移到抗量子签名。


<details>
  <summary>Details</summary>
Motivation: 需要精确的基准套件来评估早期容错量子计算机在诸如密码分析等经济影响应用方面的进展。现有的用于椭圆曲线密码学的挑战要么太稀疏，要么不足以满足 Shor 算法的标准应用。

Method: 提出一个难度分级的椭圆曲线离散对数问题（ECDLP）挑战套件，使用比特币曲线 $y^{2}=x^{3}+7 
ewline 	ext{mod } p$，并将素数域从256位降至6位。为每个比特长度提供了素数、基点和公钥示例。通过 Pollard's rho 算法和 Shor 算法的资源估算来校准经典和量子成本。将 Shor 算法的 ECDLP 电路编译为逻辑门数量，并映射到表面码、重复码和 LDPC 码等不同物理资源的资源消耗上。

Result: 在对物理错误率、编码距离和非Clifford操作供应量做出明确且可测试的假设下，研究场景将完整的256位实例的解决时间定在2027年至2033年之间。

Conclusion: 该挑战套件为追踪容错量子计算在密码分析方面的进展提供了一个透明的标尺，并促进了数字资产向抗量子签名迁移。

Abstract: Precise suites of benchmarks are required to assess the progress of early
fault-tolerant quantum computers at economically impactful applications such as
cryptanalysis. Appropriate challenges exist for factoring but those for
elliptic curve cryptography are either too sparse or inadequate for standard
applications of Shor's algorithm. We introduce a difficulty-graded suite of
elliptic curve discrete logarithm (ECDLP) challenges that use Bitcoin's curve
$y^{2}=x^{3}+7 \pmod p$ while incrementally lowering the prime field from 256
down to 6 bits. For each bit-length, we provide the prime, the base point and
an example public key. All challenges are generated by a deterministic,
reproducible procedure. We calibrate classical cost against Pollard's rho
records and quantum cost against resource estimation results for Shor's
algorithm. We compile Shor's ECDLP circuit to logical counts and map them to
physical resources for various parameters of the surface code, the repetition
cat code and the LDPC cat codes. Under explicit and testable assumptions on
physical error rates, code distances, and non-Clifford supply, our scenarios
place the full 256-bit instance within a 2027--2033 window. The challenge
ladder thus offers a transparent ruler to track fault-tolerant progress on a
cryptanalytic target of immediate relevance, and it motivates proactive
migration of digital assets to post-quantum signatures.

</details>


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [391] [CKM-Assisted Physical-Layer Security for Resilience Against Unknown Eavesdropping Location](https://arxiv.org/abs/2508.13681)
*Ladan Khaloopour,Matthias Hollick,Vahid Jamali*

Main category: eess.SP

TL;DR: CKM improves mmWave physical-layer security against eavesdroppers by optimizing beam allocation using an algorithm that maximizes secrecy rate under worst-case scenarios, without needing to know the eavesdropper's location or channel state information.


<details>
  <summary>Details</summary>
Motivation: To improve physical-layer security (PLS) in the presence of a passive eavesdropper (Eve), without making any assumptions about Eve's location or channel state information (CSI).

Method: We employ highly directional mmWave transmissions with the confidential message jointly encoded across multiple beams. We derive an algorithm for time and power allocation among the beams that maximizes the absolute secrecy rate under the worst-case scenario for Eve's location by exploiting CKM.

Result: An algorithm for time and power allocation among beams that maximizes the absolute secrecy rate under the worst-case scenario for Eve's location.

Conclusion: CKM is a promising toolbox for efficient communication and resource allocation, and can also improve physical-layer security in mmWave transmissions against passive eavesdroppers without prior knowledge of Eve's location or CSI.

Abstract: Channel Knowledge Map (CKM) is an emerging data-driven toolbox that captures
our awareness of the wireless channel and enables efficient communication and
resource allocation beyond the state of the art. In this work, we consider CKM
for improving physical-layer security (PLS) in the presence of a passive
eavesdropper (Eve), without making any assumptions about Eve's location or
channel state information (CSI). We employ highly directional mmWave
transmissions, with the confidential message jointly encoded across multiple
beams. By exploiting CKM, we derive an algorithm for time and power allocation
among the beams that maximizes the absolute secrecy rate under the worst-case
scenario for Eve's location.

</details>


### [392] [Airy beams for near-field communications: Fundamentals, potentials, and limitations](https://arxiv.org/abs/2508.13714)
*Donatella Darsena,Francesco Verde,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 本文研究了Airy光束在下一代无线网络近场区域的传播特性及其在非视距（NLoS）场景下的应用潜力。结果表明，Airy光束在特定条件下可能优于高斯光束，尤其是在利用其自加速和无衍射特性时。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，大辐射孔径和高频传输导致发射机周围的辐射近场区域扩展。在该区域，波前是非平面的，这提供了额外的自由度来塑形和控制发射波束。本文旨在研究Airy光束在近场区域的潜在优势，特别是其自加速、自愈和无衍射特性。

Method: 本文首先阐述了由连续孔径场分布产生的自加速光束的基本原理，并探讨了生成Airy光束的挑战，例如由于有限能量和孔径的空间截断导致的指数衰减。接着，研究了它们在自由空间中的传播特性。第二部分重点研究了Airy光束在非视距（NLoS）场景下的传播行为，并将其与高斯光束进行了比较。

Result: 理论和数值结果表明，Airy光束在某些NLoS信道中可能比高斯光束具有性能优势，但前提是其自加速和无衍射特性得以保持。在有障碍物的情况下，传输孔径中与接收器有清晰视线的部分需要足够大。

Conclusion: Airy光束在某些非视距（NLoS）信道中可能优于高斯光束，前提是它们的核心特性（如抛物线轨迹上的自加速和无衍射传播）能够得到很大程度的保留。在存在障碍物的情况下，这要求传输孔径中与接收器有清晰视线的部分足够大。

Abstract: In next-generation wireless networks, the combination of electrically large
radiating apertures and high-frequency transmission extends the radiating
near-field region around the transmitter. In this region, unlike in the far
field, the wavefront is nonplanar, which provides additional degrees of freedom
to shape and steer the transmitted beam in a desired manner. In this paper, we
focus on Airy beams, which may exhibit several highly desirable properties in
the near-field region. Ideally, these beams follow self-accelerating (curved)
trajectories, demonstrate resilience to perturbations through self-healing, and
maintain a consistent intensity profile across all planes perpendicular to the
propagation direction, making them effectively diffraction-free. Specifically,
we first present the underlying principles of self-accelerating beams radiated
by continuous aperture field distributions. We then address several challenges
regarding the generation of Airy beams, including their exponential decay due
to finite energy constraints and spatial truncation of the aperture. Moreover,
we examine their free-space propagation characteristics. The second part of the
paper focuses on the propagation behavior of Airy beams in non-line-of-sight
(NLoS) scenarios. A comparison is also presented between Airy beams and
Gaussian beams. Our theoretical and numerical results show that Airy beams may
offer a performance advantage over Gaussian beams in certain NLoS channels,
provided that their key properties are largely preserved, specifically,
self-acceleration along a parabolic trajectory and diffraction-free
propagation. In the presence of an obstacle, this requires that the portion of
the transmit aperture with a clear line-of-sight to the receiver is
sufficiently large.

</details>


### [393] [Joint AP Selection and Power Allocation for Unicast-Multicast Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13771)
*Mustafa S. Abbas,Zahra Mobini,Hien Quoc Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本研究提出了一种联合优化方法，用于在无小区大规模多输入多输出系统中同时支持单播和多播传输。通过使用APG和SCA算法进行优化，可以提高系统的频谱效率（SE）和加权和SE（SSE）。


<details>
  <summary>Details</summary>
Motivation: 联合单播和多播传输在物联网网络等实际无线系统中变得越来越重要。

Method: 推导了零强制和最大比率预编码设计的下行链路可实现频谱效率（SE）的精确闭式表达式。然后，构建了一个加权和SE（SSE）最大化问题，以联合优化接入点（AP）的选择和功率分配，并考虑了每个AP的最大发射功率、AP与中央处理单元之间的前传链路容量限制以及所有用户的服务质量要求。将非凸优化问题重新表述为一个可处理的结构，并开发了一种基于加速投影梯度（APG）的算法来高效地获得近似最优解。作为性能基准，还实现了一种基于连续凸近似（SCA）的算法。

Result: 仿真结果表明，所提出的联合优化方法在各种系统设置和预编码策略中显著提高了SSE。具体来说，基于APG的算法实现了显著的复杂度降低，同时保持了具有竞争力的性能。

Conclusion: 提出的联合优化方法在各种系统设置和预编码策略中显著提高了SSE。所提出的APG算法实现了显著的复杂度降低，同时保持了具有竞争力的性能，非常适合大规模实际部署。

Abstract: Joint unicast and multicast transmissions are becoming increasingly important
in practical wireless systems, such as Internet of Things networks. This paper
investigates a cell-free massive multiple-input multiple-output system that
simultaneously supports both transmission types, with multicast serving
multiple groups. Exact closed-form expressions for the achievable downlink
spectral efficiency (SE) of both unicast and multicast users are derived for
zero-forcing and maximum ratio precoding designs. Accordingly, a weighted sum
SE (SSE) maximization problem is formulated to jointly optimize the access
point (AP) selection and power allocation. The optimization framework accounts
for practical constraints, including the maximum transmit power per AP,
fronthaul capacity limitations between APs and the central processing unit, and
quality-of-service requirements for all users. The resulting non-convex
optimization problem is reformulated into a tractable structure, and an
accelerated projected gradient (APG)-based algorithm is developed to
efficiently obtain near-optimal solutions. As a performance benchmark, a
successive convex approximation (SCA)-based algorithm is also implemented.
Simulation results demonstrate that the proposed joint optimization approach
significantly enhances the SSE across various system setups and precoding
strategies. In particular, the APG-based algorithm achieves substantial
complexity reduction while maintaining competitive performance, making it
well-suited for large-scale practical deployments.

</details>


### [394] [Robust Optimization for Movable Antenna-aided Cell-Free ISAC with Time Synchronization Errors](https://arxiv.org/abs/2508.13818)
*Yue Xiu,Yang Zhao,Ran Yang,Wanting Lyu,Dusit Niyato,Dong In Kim,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 本文提出了一种基于可移动天线的CF-ISAC架构，通过稳健优化和MA-MetaRL技术，有效解决了时间同步误差问题，提高了通信速率和传感精度。


<details>
  <summary>Details</summary>
Motivation: 准确的时间同步（TS）对于充分发挥CF-ISAC系统的潜力至关重要。然而，现有的同步技术存在局限性，导致TS误差成为CF-ISAC系统开发中的一个重大挑战。因此，需要一种能够减轻TS误差影响的新型CF-ISAC架构。

Method: 提出了一种基于可移动天线（MA）的新型CF-ISAC架构，并提出了一种稳健的优化框架来解决通信速率约束下的最坏情况传感精度优化问题。具体而言，采用流形优化（MO）来解决最坏情况传感精度优化问题，并提出了一种MA使能的元强化学习（MA-MetaRL）来设计优化变量，以满足MA位置、通信速率和发射功率的约束。

Result: 仿真结果表明，所提出的稳健优化算法显著提高了检测精度，并且能够抵抗TS误差。此外，与传统的固定位置天线（FPA）技术相比，所提出的MA辅助CF-ISAC架构实现了更高的系统容量。

Conclusion: 所提出的基于可移动天线（MA）的细胞网无关集成传感与通信（CF-ISAC）架构通过联合优化波束成形和MA位置，有效提高了通信速率和传感精度，并能有效应对时间同步（TS）误差，优于传统的固定位置天线（FPA）技术。

Abstract: The cell-free integrated sensing and communication (CF-ISAC) system, which
effectively mitigates intra-cell interference and provides precise sensing
accuracy, is a promising technology for future 6G networks. However, to fully
capitalize on the potential of CF-ISAC, accurate time synchronization (TS)
between access points (APs) is critical. Due to the limitations of current
synchronization technologies, TS errors have become a significant challenge in
the development of the CF-ISAC system. In this paper, we propose a novel
CF-ISAC architecture based on movable antennas (MAs), which exploits spatial
diversity to enhance communication rates, maintain sensing accuracy, and reduce
the impact of TS errors. We formulate a worst-case sensing accuracy
optimization problem for TS errors to address this challenge, deriving the
worst-case Cram\'er-Rao lower bound (CRLB). Subsequently, we develop a joint
optimization framework for AP beamforming and MA positions to satisfy
communication rate constraints while improving sensing accuracy. A robust
optimization framework is designed for the highly complex and non-convex
problem. Specifically, we employ manifold optimization (MO) to solve the
worst-case sensing accuracy optimization problem. Then, we propose an
MA-enabled meta-reinforcement learning (MA-MetaRL) to design optimization
variables while satisfying constraints on MA positions, communication rate, and
transmit power, thereby improving sensing accuracy. The simulation results
demonstrate that the proposed robust optimization algorithm significantly
improves the accuracy of the detection and is strong against TS errors.
Moreover, compared to conventional fixed position antenna (FPA) technologies,
the proposed MA-aided CF-ISAC architecture achieves higher system capacity,
thus validating its effectiveness.

</details>


### [395] [Distributed Distortion-Aware Robust Optimization for Movable Antenna-aided Cell-Free ISAC Systems](https://arxiv.org/abs/2508.13839)
*Yue Xiu,Yang Zhao,Ran Yang,Zheng Dong,Wanting Lyu,Zeyuan Zhang,Dusit Niyato,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 本文提出了一种移动天线辅助的CF-ISAC系统，通过鲁棒优化和SACGNN解决PA非线性失真问题，提升了通信和传感性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决无蜂窝集成传感和通信（CF-ISAC）架构在实际部署中面临的硬件损伤问题，特别是来自功率放大器（PA）的非线性失真对通信和传感性能的损害，提出了一种移动天线（MA）辅助的CF-ISAC系统。

Method: 提出了一种移动天线（MA）辅助的无蜂窝集成传感和通信（CF-ISAC）系统，通过分布式失真感知最坏情况鲁棒优化框架来处理PA非线性失真。该框架将PA非线性模型化为三阶无记忆多项式，并明确考虑了三阶失真系数（3RDCs）的不确定性。通过分析最坏情况下的PA失真对Cramer-Rao下界（CRLB）和通信速率的影响，并采用连续凸近似（SCA）来估计3RDCs，联合优化了波束成形和MA位置。为了高效解决此高度非凸问题，开发了一种MA驱动的自注意力卷积图神经网络（SACGNN）算法。

Result: 仿真结果表明，所提出的MA辅助CF-ISAC系统能够有效减轻PA非线性失真，显著提高通信-传感的权衡能力，并且在鲁棒性和容量方面优于固定位置天线基线。

Conclusion: 所提出的移动天线（MA）辅助的无蜂窝集成传感和通信（CF-ISAC）系统通过分布式失真感知最坏情况鲁棒优化框架和MA驱动的自注意力卷积图神经网络（SACGNN）算法，有效减轻了PA非线性失真，显著提高了通信与传感的权衡能力，并在鲁棒性和容量方面优于固定天线基线。

Abstract: The cell-free integrated sensing and communication (CF-ISAC) architecture is
a promising enabler for 6G, offering spectrum efficiency and ubiquitous
coverage. However, real deployments suffer from hardware impairments,
especially nonlinear distortion from power amplifiers (PAs), which degrades
both communication and sensing. To address this, we propose a movable antenna
(MA)-aided CF-ISAC system that mitigates distortion and enhances robustness.
The PAs nonlinearities are modeled by a third-order memoryless polynomial,
where the third-order distortion coefficients (3RDCs) vary across access points
(APs) due to hardware differences, aging, and environmental conditions. We
design a distributed distortion-aware worst-case robust optimization framework
that explicitly incorporates uncertainty in 3RDCs. First, we analyze the
worst-case impact of PA distortion on both the Cramer-Rao lower bound (CRLB)
and communication rate. Then, to address the resulting non-convexity, we apply
successive convex approximation (SCA) for estimating the 3RDCs. With these, we
jointly optimize beamforming and MA positions under transmit power and sensing
constraints. To efficiently solve this highly non-convex problem, we develop an
MA-enabled self-attention convolutional graph neural network (SACGNN)
algorithm. Simulations demonstrate that our method substantially enhances the
communication-sensing trade-off under distortion and outperforms fixed-position
antenna baselines in terms of robustness and capacity, thereby highlighting the
advantages of MA-aided CF-ISAC systems.

</details>


### [396] [Evaluating Particle Filtering for RSS-Based Target Localization under Varying Noise Levels and Sensor Geometries](https://arxiv.org/abs/2508.13937)
*Halim Lee,Jongmin Park,Kwansik Park*

Main category: eess.SP

TL;DR: 本研究提出并评估了一种粒子滤波算法用于基于信号强度（RSS）的目标定位，并与传统三角测量法进行了比较。结果显示，粒子滤波在各种条件下，尤其是在不利的传感器几何形状和高噪声环境中，表现出更优越的定位精度。


<details>
  <summary>Details</summary>
Motivation: 系统地分析了粒子滤波在不同传感器几何形状和RSS噪声水平下的性能，以解决现有研究的不足。

Method: 设计并评估了一种用于定位固定目标的粒子滤波算法，并将其与传统的基于RSS的三角测量方法进行了比较。

Result: 仿真结果表明，粒子滤波在传感器几何形状不利和RSS噪声较大的情况下，比三角测量法能更准确地进行目标定位。

Conclusion: 粒子滤波相比于传统的基于信号强度（RSS）的三角测量方法，在目标定位方面提供了更高的准确性，尤其是在传感器几何形状不利和RSS噪声较大的情况下。

Abstract: Target localization is a critical task in various applications, such as
search and rescue, surveillance, and wireless sensor networks. When a target
emits a radio frequency (RF) signal, spatially distributed sensors can collect
signal measurements to estimate the target's location. Among various
measurement modalities, received signal strength (RSS) is particularly
attractive due to its low cost, low power consumption, and ease of deployment.
While particle filtering has previously been applied to RSS-based target
localization, few studies have systematically analyzed its performance under
varying sensor geometries and RSS noise levels. This paper addresses this gap
by designing and evaluating a particle filtering algorithm for localizing a
stationary target. The proposed method is compared with a conventional
RSS-based trilateration approach across different sensor configurations and
noise conditions. Simulation results indicate that particle filtering provides
more accurate target localization than trilateration, particularly in scenarios
with unfavorable sensor geometries and high RSS noise.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [397] [Harnessing the Full Potential of RRAMs through Scalable and Distributed In-Memory Computing with Integrated Error Correction](https://arxiv.org/abs/2508.13298)
*Huynh Q. N. Vo,Md Tawsif Rahman Chowdhury,Paritosh Ramanan,Murat Yildirim,Gozde Tutuncuoglu*

Main category: cs.DC

TL;DR: MELISO+ 是一个全栈、分布式的节能内存计算框架，利用两级纠错和分布式 RRAM 计算来处理大规模矩阵计算，显著提高了能效和性能，并支持低精度 RRAM 器件超越高精度器件。


<details>
  <summary>Details</summary>
Motivation: 全球计算需求呈指数增长，而传统架构的能源消耗较高，主要是由于数据移动耗能。 阻性随机存取内存 (RRAM) 的内存计算通过共集成内存和处理来解决此问题，但面临器件级非理想化和大规模计算任务可扩展性方面的挑战。

Method: MELISO+ 提出了一种新颖的两级纠错机制来缓解器件非理想化问题，并开发了一个分布式 RRAM 计算框架，实现了超过 65,000 x 65,000 维度的矩阵计算。

Result: 该方法将器件非理想化造成的算术误差降低了 90% 以上，将能效提高了三个数量级，并将延迟降低了 100 倍。 此外，MELISO+ 允许低精度 RRAM 器件在精度、能效和延迟指标上优于高精度器件替代品。

Conclusion: MELISO+ 通过统一算法-硬件协同设计和可扩展架构，显著推进了可持续的高维计算，适用于大型语言模型和生成式人工智能等应用。

Abstract: Exponential growth in global computing demand is exacerbated due to the
higher-energy requirements of conventional architectures, primarily due to
energy-intensive data movement. In-memory computing with Resistive Random
Access Memory (RRAM) addresses this by co-integrating memory and processing,
but faces significant hurdles related to device-level non-idealities and poor
scalability for large computing tasks. Here, we introduce \textbf{MELISO+}
(In-\textbf{Me}mory \textbf{Li}near \textbf{So}lver), a full-stack, distributed
framework for energy-efficient in-memory computing. MELISO+ proposes a novel
two-tier error correction mechanism to mitigate device non-idealities and
develops a distributed RRAM computing framework to enable matrix computations
exceeding dimensions of $65,000 \times 65,000$. This approach reduces first-
and second-order arithmetic errors due to device non-idealities by over 90\%,
enhances energy efficiency by three to five orders of magnitude, and decreases
latency 100-fold. Hence, MELISO+ allows lower-precision RRAM devices to
outperform high-precision device alternatives in accuracy, energy and latency
metrics. By unifying algorithm-hardware co-design with scalable architecture,
MELISO+ significantly advances sustainable, high-dimensional computing suitable
for applications like large language models and generative AI.

</details>


### [398] [Persistent and Partitioned MPI for Stencil Communication](https://arxiv.org/abs/2508.13370)
*Gerald Collom,Jason Burmark,Olga Pearce,Amanda Bienz*

Main category: cs.DC

TL;DR: MPI持久通信和分区通信可显著提升大规模并行应用中迭代式模板操作的通信性能。


<details>
  <summary>Details</summary>
Motivation: 为了应对大规模并行应用中迭代式模板操作的通信瓶颈，本文研究了MPI持久通信和分区通信的优化策略。

Method: 通过Comb基准套件，使用非阻塞、持久化和分区通信例程，分析了在不同规模下，MPI优化对模板通信性能的影响。此外，还分析了进程数、线程数和消息大小对分区通信例程的影响。

Result: 持久MPI通信相比基线MPI通信可提供高达37%的加速比，分区MPI通信可提供高达68%的加速比。

Conclusion: MPI的持久通信和分区通信可以显著提升大规模并行应用中迭代式模板操作的通信性能，分别可带来高达37%和68%的加速比。

Abstract: Many parallel applications rely on iterative stencil operations, whose
performance are dominated by communication costs at large scales. Several MPI
optimizations, such as persistent and partitioned communication, reduce
overheads and improve communication efficiency through amortized setup costs
and reduced synchronization of threaded sends. This paper presents the
performance of stencil communication in the Comb benchmarking suite when using
non blocking, persistent, and partitioned communication routines. The impact of
each optimization is analyzed at various scales. Further, the paper presents an
analysis of the impact of process count, thread count, and message size on
partitioned communication routines. Measured timings show that persistent MPI
communication can provide a speedup of up to 37% over the baseline MPI
communication, and partitioned MPI communication can provide a speedup of up to
68%.

</details>


### [399] [OrbitChain: Orchestrating In-orbit Real-time Analytics of Earth Observation Data](https://arxiv.org/abs/2508.13374)
*Zhouyu Li,Zhijing Yang,Huayue Gu,Xiaojian Wang,Yuchen Liu,Ruozhou Yu*

Main category: cs.DC

TL;DR: OrbitChain通过将分析任务分解为微服务并在多颗卫星上进行计算来加速地球观测数据的实时分析，从而实现及时的灾难响应，同时减少了通信开销。


<details>
  <summary>Details</summary>
Motivation: 现有的地球观测卫星由于地面-卫星连接带宽和持续时间的限制，数据下载和分析需要数小时甚至数天，这使得及时的灾难响应等实时应用变得不可能。

Method: OrbitChain是一个协作分析框架，通过将分析应用程序分解为微服务，并将计算资源分配给时限分析，来实现跨地球观测星座的计算资源编排。它还采用了一种减少星际通信开销的流量路由算法和管道工作流。

Result: 实验表明，与现有的地球观测分析框架相比，OrbitChain可以完成多达60%的分析工作量，同时将通信开销减少高达72%。

Conclusion: OrbitChain通过将分析应用程序分解为微服务并在多颗卫星上编排计算资源，实现了地球观测任务的实时处理，从而支持了灾难响应等时敏应用。

Abstract: Earth observation analytics have the potential to serve many time-sensitive
applications. However, due to limited bandwidth and duration of
ground-satellite connections, it takes hours or even days to download and
analyze data from existing Earth observation satellites, making real-time
demands like timely disaster response impossible. Toward real-time analytics,
we introduce OrbitChain, a collaborative analytics framework that orchestrates
computational resources across multiple satellites in an Earth observation
constellation. OrbitChain decomposes analytics applications into microservices
and allocates computational resources for time-constrained analysis. A traffic
routing algorithm is devised to minimize the inter-satellite communication
overhead. OrbitChain adopts a pipeline workflow that completes Earth
observation tasks in real-time, facilitates time-sensitive applications and
inter-constellation collaborations such as tip-and-cue. To evaluate OrbitChain,
we implement a hardware-in-the-loop orbital computing testbed. Experiments show
that our system can complete up to 60% analytics workload than existing Earth
observation analytics framework while reducing the communication overhead by up
to 72%.

</details>


### [400] [Optimizing Allreduce Operations for Heterogeneous Architectures with Multiple Processes per GPU](https://arxiv.org/abs/2508.13397)
*Michael Adams,Amanda Bienz*

Main category: cs.DC

TL;DR: 通过多核CPU加速GPU间通信，显著提升了深度学习的性能。


<details>
  <summary>Details</summary>
Motivation: 解决了深度学习中普遍存在的GPU间all-reduce通信瓶颈问题，并利用了异构计算节点中大量空闲的CPU资源。

Method: 通过GPU感知和多CPU核加速的all-reduce操作，扩展了lane-aware reductions到GPU。

Result: 在NVIDIA A100 GPU上实现了高达2.45倍的加速，在NVIDIA和AMD GPU上也分别实现了高达1.77倍和1.71倍的加速。

Conclusion: 该研究提出了一种利用多核CPU加速大规模GPU感知all-reduce操作的新方法，并在NVIDIA A100 GPU上实现了高达2.45倍的加速，同时扩展到NVIDIA和AMD的GPU也取得了显著的加速效果。

Abstract: Large inter-GPU all-reduce operations, prevalent throughout deep learning,
are bottlenecked by communication costs. Emerging heterogeneous architectures
are comprised of complex nodes, often containing $4$ GPUs and dozens to
hundreds of CPU cores per node. Parallel applications are typically accelerated
on the available GPUs, using only a single CPU core per GPU while the remaining
cores sit idle. This paper presents novel optimizations to large GPU-aware
all-reduce operations, extending lane-aware reductions to the GPUs, and notably
using multiple CPU cores per GPU to accelerate these operations. These
multi-CPU-accelerated GPU-aware lane all-reduces yield speedup of up to $2.45$x
for large MPI all-reduces across the NVIDIA A100 GPUs of NCSA's Delta
supercomputer. Finally, the approach is extended to NVIDIA's and AMD's
collective communication libraries, achieving speedup of up to $1.77$x and
$1.71$x, respectively, across $2$ state-of-the-art supercomputers.

</details>


### [401] [DDoS Attacks in Cloud Computing: Detection and Prevention](https://arxiv.org/abs/2508.13522)
*Zain Ahmad,Musab Ahmad,Bilal Ahmad*

Main category: cs.DC

TL;DR: 本研究全面概述了DDoS攻击的类型、检测方法和预防技术，旨在帮助组织和个人提高网络安全水平。


<details>
  <summary>Details</summary>
Motivation: DDoS攻击是当今组织和个人面临的最普遍和最有害的网络安全威胁之一。近年来，DDoS攻击的复杂性和频率显著增加，使得有效检测和缓解它们变得困难。

Method: 本研究分析了各种类型的DDoS攻击（包括流量、协议和应用层攻击），并讨论了每种类型的特征、影响和潜在目标。同时，研究还审查了现有的DDoS攻击检测技术（如数据包过滤、入侵检测系统和基于机器学习的方法）及其优缺点。此外，研究还探讨了为减轻DDoS攻击而采用的预防技术（如防火墙、速率限制、CPP和ELD机制），并评估了每种方法的有效性及其在不同攻击类型和环境中的适用性。

Result: 本研究通过分析不同DDoS攻击类型、检测技术和预防策略，为加强网络防御提供了全面的见解。

Conclusion: 本研究全面概述了不同类型的DDoS攻击、它们的检测和预防技术，旨在为组织和个人提供增强网络安全态势和防御DDoS攻击的见解和指导。

Abstract: DDoS attacks are one of the most prevalent and harmful cybersecurity threats
faced by organizations and individuals today. In recent years, the complexity
and frequency of DDoS attacks have increased significantly, making it
challenging to detect and mitigate them effectively. The study analyzes various
types of DDoS attacks, including volumetric, protocol, and application layer
attacks, and discusses the characteristics, impact, and potential targets of
each type. It also examines the existing techniques used for DDoS attack
detection, such as packet filtering, intrusion detection systems, and machine
learning-based approaches, and their strengths and limitations. Moreover, the
study explores the prevention techniques employed to mitigate DDoS attacks,
such as firewalls, rate limiting , CPP and ELD mechanism. It evaluates the
effectiveness of each approach and its suitability for different types of
attacks and environments. In conclusion, this study provides a comprehensive
overview of the different types of DDoS attacks, their detection, and
prevention techniques. It aims to provide insights and guidelines for
organizations and individuals to enhance their cybersecurity posture and
protect against DDoS attacks.

</details>


### [402] [LAMMPS-KOKKOS: Performance Portable Molecular Dynamics Across Exascale Architectures](https://arxiv.org/abs/2508.13523)
*Anders Johansson,Evan Weinberg,Christian R. Trott,Megan J. McCarthy,Stan G. Moore*

Main category: cs.DC

TL;DR: LAMMPS通过集成Kokkos库，在GPU和超级计算机上实现了高性能和良好的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 为了使LAMMPS适应现代异构计算环境，并研究其在不同硬件上的性能表现。

Method: 通过集成Kokkos性能可移植性库到现有的C++代码中，并对多种力场（简单的成对、多体反应和机器学习力场）进行了性能可移植性研究，在不同厂商和代系的GPU上进行了测试和分析，包括FLOPS吞吐量、内存带宽、缓存能力和线程原子操作性能，并在OLCF Frontier、ALCF Aurora和NNSA El Capitan等超级计算机上展示了三种力场的强扩展性。

Result: LAMMPS在GPU上的性能表现良好，并成功实现了在多个美国超级计算机上的强扩展性。

Conclusion: LAMMPS已成功集成Kokkos库，实现了在现代异构计算环境下的高性能计算。

Abstract: Since its inception in 1995, LAMMPS has grown to be a world-class molecular
dynamics code, with thousands of users, over one million lines of code, and
multi-scale simulation capabilities. We discuss how LAMMPS has adapted to the
modern heterogeneous computing landscape by integrating the Kokkos performance
portability library into the existing C++ code. We investigate performance
portability of simple pairwise, many-body reactive, and machine-learned
force-field interatomic potentials. We present results on GPUs across different
vendors and generations, and analyze performance trends, probing FLOPS
throughput, memory bandwidths, cache capabilities, and thread-atomic operation
performance. Finally, we demonstrate strong scaling on all current US exascale
machines -- OLCF Frontier, and ALCF Aurora, and NNSA El Capitan -- for the
three potentials.

</details>


### [403] [LUNDIsim: model meshes for flow simulation and scientific data compression benchmarks](https://arxiv.org/abs/2508.13636)
*Laurent Duval,Frédéric Payan,Christophe Preux,Lauriane Bouard*

Main category: cs.DC

TL;DR: LUNDIsim 是一个用于地球科学的地球科学数据集，旨在解决数据爆炸问题，并支持各种模拟和压缩算法的评估。


<details>
  <summary>Details</summary>
Motivation: 日益增长的科学数据量给可计算性、可解释性和可持续性带来了挑战，尤其是在地球科学领域，因此需要有效的数据管理和评估方法。

Method: 提出了 LUNDIsim 数据集，该数据集包含多种分辨率的、经过优化的地球科学模拟网格，并附带了用于两相流模拟的孔隙度/渗透率数据，旨在用于基准测试和评估数据压缩算法。

Result: LUNDIsim 数据集包含四种不同的地下环境，具有多种分辨率和 HexaShrink 多尺度表示，并提供了用于重现两相流模拟的储层特征，可用于基准测试和评估数据压缩算法。

Conclusion: LUNDIsim 数据集是为了应对科学数据量爆炸式增长而创建的，特别是在地球科学领域。该数据集支持压缩算法、网格处理和机器学习等多种应用，旨在促进数据管理和评估。

Abstract: The volume of scientific data produced for and by numerical simulation
workflows is increasing at an incredible rate. This raises concerns either in
computability, interpretability, and sustainability. This is especially
noticeable in earth science (geology, meteorology, oceanography, and
astronomy), notably with climate studies.
  We highlight five main evaluation issues: efficiency, discrepancy, diversity,
interpretability, availability.
  Among remedies, lossless and lossy compression techniques are becoming
popular to better manage dataset volumes. Performance assessment -- with
comparative benchmarks -- require open datasets shared under FAIR principles
(Findable, Accessible, Interoperable, Reusable), with MRE (Minimal Reproducible
Example) ancillary data for reuse. We share LUNDIsim, an exemplary faulted
geological mesh. It is inspired by SPE10 comparative Challenge. Enhanced by
porosity/permeability datasets, this dataset proposes four distinct subsurface
environments. They were primarily designed for flow simulation in porous media.
Several consistent resolutions (with HexaShrink multiscale representations) are
proposed for each model. We also provide a set of reservoir features for
reproducing typical two-phase flow simulations on all LUNDIsim models in a
reservoir engineering context. This dataset is chiefly meant for benchmarking
and evaluating data size reduction (upscaling) or genuine composite mesh
compression algorithms. It is also suitable for other advanced mesh processing
workflows in geology and reservoir engineering, from visualization to machine
learning.
  LUNDIsim meshes are available at https://doi.org/10.5281/zenodo.14641958

</details>


### [404] [Estimating CO$_2$ emissions of distributed applications and platforms with SimGrid/Batsim](https://arxiv.org/abs/2508.13693)
*Gabriella Saraiva,Miguel Vasconcelos,Sarita Mazzini Bruschi,Danilo Carastan-Santos,Daniel Cordeiro*

Main category: cs.DC

TL;DR: A plugin for Batsim calculates CO2 emissions based on energy consumption and carbon intensity to assess the environmental impact of data center strategies.


<details>
  <summary>Details</summary>
Motivation: To comprehensively assess the environmental impact associated with task and resource management strategies in data centers by allowing the calculation of CO2 emissions during simulation runs.

Method: The plugin is developed within SimGrid and computes carbon emissions based on the simulated platform's energy consumption and carbon intensity factor of the simulated machines. It is then integrated into Batsim.

Result: A carbon footprint plugin designed to extend the capabilities of the Batsim simulator.

Conclusion: The plugin is compatible with existing simulation workflows and enables researchers to assess the carbon efficiency of their scheduling strategies.

Abstract: This work presents a carbon footprint plugin designed to extend the
capabilities of the Batsim simulator by allowing the calculation of CO$_2$
emissions during simulation runs. The goal is to comprehensively assess the
environmental impact associated with task and resource management strategies in
data centers. The plugin is developed within SimGrid -- the underlying
simulation framework of Batsim -- and computes carbon emissions based on the
simulated platform's energy consumption and carbon intensity factor of the
simulated machines. Once implemented, it is integrated into Batsim, ensuring
compatibility with existing simulation workflows and enabling researchers to
assess the carbon efficiency of their scheduling strategies.

</details>


### [405] [CaPGNN: Optimizing Parallel Graph Neural Network Training with Joint Caching and Resource-Aware Graph Partitioning](https://arxiv.org/abs/2508.13716)
*Xianfeng Song,Yi Zou,Zheng Shi*

Main category: cs.DC

TL;DR: CaPGNN通过自适应缓存和智能图划分，显著提高了多GPU环境下全批量图神经网络的训练效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决在分布式环境中，全批量图神经网络训练面临的可扩展性限制问题，该问题源于高通信开销和负载不均衡。

Method: 提出了一种名为CaPGNN的新框架，用于单服务器多GPU环境下的并行全批量图神经网络训练。该框架包含两个关键组件：1. 联合自适应缓存算法：该算法利用CPU和GPU内存来减少跨分区顶点特征的重复传输。2. 感知GPU异构计算能力的图划分算法：该算法动态调整子图大小以匹配GPU的计算和通信能力。

Result: 实验结果表明，与现有最先进的方法相比，CaPGNN能将通信成本降低高达96%，并将训练速度提高高达12.7倍。这证明了自适应缓存和感知计算的图划分对于可扩展、高效和实用的全批量图神经网络训练部署的潜力。

Conclusion: CaPGNN通过利用CPU和GPU内存的联合自适应缓存算法，并结合感知GPU异构计算和通信能力的图划分算法，实现了高效的并行全批量图神经网络训练，有效降低了通信开销并提高了训练速度。

Abstract: Graph Neural Networks (GNNs) have shown remarkable capabilities in processing
graph-structured data prevalent in various real-world applications. However,
the scalability of full-batch GNN training becomes severely limited by high
communication overhead and load imbalance in distributed environments. In this
paper, we present CaPGNN, a novel framework for efficient parallel full-batch
GNN training on single-server with multi-GPU, designed specifically to reduce
redundant inter-GPU communication and balance computational workloads. We
propose a joint adaptive caching algorithm that leverages both CPU and GPU
memory to significantly reduce the repetitive transmission of vertex features
across partitions. Additionally, we introduce a resource-aware graph
partitioning algorithm that adjusts subgraph sizes dynamically according to the
heterogeneous computational and communication capacities of GPUs. Extensive
experiments on large-scale benchmark datasets demonstrate that CaPGNN
effectively reduces communication costs by up to 96% and accelerates GNN
training by up to 12.7 times compared to state-of-the-art approaches. Our
results highlight the potential of adaptive caching and resource-aware
partitioning to facilitate scalable, efficient, and practical deployment of
full-batch GNN training in distributed computing environments.

</details>


### [406] [Is RISC-V ready for High Performance Computing? An evaluation of the Sophon SG2044](https://arxiv.org/abs/2508.13840)
*Nick Brown*

Main category: cs.DC

TL;DR: SOPHGO SG2044是一款64核RISC-V CPU，旨在HPC领域提升性能。研究表明，SG2044在64核以上时性能表现优于SG2042，并且通过支持RVV v1.0和改进内存子系统，在计算密集型任务上大大缩短了与竞品在性能上的差距。


<details>
  <summary>Details</summary>
Motivation: RISC-V在HPC领域尚未普及，需要研究其在HPC领域的性能表现。SOPHGO SG2044是专为工作站和服务器设计的64核高性能CPU，旨在解决上一代产品的瓶颈问题。

Method: 对SG2044进行性能研究，并与SG2042及其他架构进行对比。

Result: SG2044在更高核数下表现更优，尤其是在64核以上时，性能相比SG2042有显著提升。RVV v1.0支持和增强的内存子系统是SG2044的关键升级，有效提升了其在计算密集型任务上的性能。

Conclusion: SG2044在64核以上时性能优势最为明显，与SG2042相比，性能提升最高可达4.91倍。SG2044显著缩小了与其它架构在性能上的差距，尤其在计算密集型工作负载方面。

Abstract: The pace of RISC-V adoption continues to grow rapidly, yet for the successes
enjoyed in areas such as embedded computing, RISC-V is yet to gain ubiquity in
High Performance Computing (HPC). The Sophon SG2044 is SOPHGO's next generation
64-core high performance CPU that has been designed for workstation and server
grade workloads. Building upon the SG2042, subsystems that were a bottleneck in
the previous generation have been upgraded.
  In this paper we undertake the first performance study of the SG2044 for HPC.
Comparing against the SG2042 and other architectures, we find that the SG2044
is most advantageous when running at higher core counts, delivering up to 4.91
greater performance than the SG2042 over 64-cores. Two of the most important
upgrades in the SG2044 are support for RVV v1.0 and an enhanced memory
subsystem. This results in the SG2044 significantly closing the performance gap
with other architectures, especially for compute-bound workloads.

</details>
